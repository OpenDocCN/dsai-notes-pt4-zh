- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 18:51:38'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:51:38
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Self-HWDebug: Automation of LLM Self-Instructing for Hardware Security Verification'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'Self-HWDebug: LLM自我指导的硬件安全验证自动化'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2405.12347](https://ar5iv.labs.arxiv.org/html/2405.12347)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2405.12347](https://ar5iv.labs.arxiv.org/html/2405.12347)
- en: Mohammad Akyash Dept. of Electrical and Comp. Eng. (ECE)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Mohammad Akyash 电气与计算机工程系（ECE）
- en: University of Central Florida Orlando, US 32816
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 中佛罗里达大学 美国奥兰多 32816
- en: mohammad.akyash@ucf.edu    Hadi Mardani Kamali Dept. of Electrical and Comp.
    Eng. (ECE)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: mohammad.akyash@ucf.edu    Hadi Mardani Kamali 电气与计算机工程系（ECE）
- en: University of Central Florida Orlando, US 32816
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 中佛罗里达大学 美国奥兰多 32816
- en: hadi.mardanikamali@ucf.edu
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: hadi.mardanikamali@ucf.edu
- en: Abstract
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: The rise of instruction-tuned Large Language Models (LLMs) marks a significant
    advancement in artificial intelligence (AI) (tailored to respond to specific prompts).
    Despite their popularity, applying such models to debug security vulnerabilities
    in hardware designs, i.e., register transfer language (RTL) modules, particularly
    at system-on-chip (SoC) level, presents considerable challenges. One of the main
    issues lies in the need for precisely designed instructions for pinpointing and
    mitigating the vulnerabilities, which requires substantial time and expertise
    from human experts. In response to this challenge, this paper proposes Self-HWDebug,
    an innovative framework that leverages LLMs to automatically create required debugging
    instructions. In Self-HWDebug, a set of already identified bugs from the most
    critical hardware common weakness enumeration (CWE) listings, along with mitigation
    resolutions, is provided to the framework, followed by prompting the LLMs to generate
    targeted instructions for such mitigation. The LLM-generated instructions are
    subsequently used as references to address vulnerabilities within the same CWE
    category but in totally different designs, effectively demonstrating the framework’s
    ability to extend solutions across related security issues. Self-HWDebug significantly
    reduces human intervention by using the model’s own output to guide debugging.
    Through comprehensive testing, Self-HWDebug proves not only to reduce experts’
    effort/time but also to even improve the quality of the debugging process.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 指令调优的大型语言模型（LLMs）的兴起标志着人工智能（AI）的重大进步（针对特定提示进行定制）。尽管它们很受欢迎，但将这些模型应用于硬件设计中的安全漏洞调试，即寄存器传输语言（RTL）模块，尤其是在系统级芯片（SoC）层面，面临着相当大的挑战。主要问题之一在于需要精确设计的指令来定位和减轻漏洞，这需要大量的时间和专家的专业知识。为应对这一挑战，本文提出了Self-HWDebug，一个创新框架，利用LLMs自动生成所需的调试指令。在Self-HWDebug中，提供了一组已识别的来自最关键的硬件通用弱点枚举（CWE）列表的错误及其解决方案，然后提示LLMs生成针对这些缓解措施的指令。LLM生成的指令随后作为参考，用于解决同一CWE类别但在完全不同设计中的漏洞，有效展示了该框架在相关安全问题之间扩展解决方案的能力。Self-HWDebug通过使用模型自身的输出指导调试，显著减少了人工干预。通过全面测试，Self-HWDebug不仅证明了可以减少专家的努力/时间，而且还能提高调试过程的质量。
- en: 'Index Terms:'
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 索引词：
- en: LLM, Hardware Security, Validation, CWE.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: LLM，硬件安全，验证，CWE。
- en: I Introduction
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I 引言
- en: Given the widespread use of SoCs within today’s digital systems, coupled with
    the escalating size and complexity of their associated hardware, the emergence
    of unknown vulnerabilities (especially security vulnerabilities) stemming from
    their hardware has become an inevitable and challenging aspect of the integrated
    circuit (IC) supply chain process [[1](#bib.bib1)]. To minimize re-spins due to
    post-silicon verification issues, addressing these vulnerabilities must be done
    at the highest level of abstraction, i.e., RTL [[2](#bib.bib2), [3](#bib.bib3)].
    This process is time-consuming and demands extensive hardware engineering expertise.
    Numerous methodologies have been investigated over the years for such challenges,
    from formal methods [[4](#bib.bib4)] to advanced testing techniques, e.g., fuzzing
    [[5](#bib.bib5), [6](#bib.bib6)].
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于SoCs在当今数字系统中的广泛应用，加之其相关硬件的规模和复杂性不断上升，从硬件中出现未知的漏洞（尤其是安全漏洞）已成为集成电路（IC）供应链过程中的不可避免且具有挑战性的方面[[1](#bib.bib1)]。为了最小化因后硅验证问题而产生的重制次数，必须在最高抽象层次上，即RTL
    [[2](#bib.bib2), [3](#bib.bib3)]，解决这些漏洞。这一过程耗时且需要广泛的硬件工程专业知识。多年来，已经研究了许多方法来应对这些挑战，从形式化方法[[4](#bib.bib4)]到高级测试技术，例如模糊测试[[5](#bib.bib5),
    [6](#bib.bib6)]。
- en: More recently, significant advancements in seedling AI use, particularly through
    LLMs, have greatly enhanced the resolution of verification issues, particularly
    w.r.t. the automating the verification process, reducing required experts’ knowledge
    and time [[7](#bib.bib7)]. Prompt engineering, which is the process of crafting
    inputs that guide LLMs’ responses, has been widely used for hardware security
    verification purposes [[8](#bib.bib8), [9](#bib.bib9), [10](#bib.bib10)]. For
    example, [[8](#bib.bib8)] has explored employing expert-crafted prompts to steer
    model behavior in specific debugging scenarios. However, this method suffers from
    scalability and prompts’ efficacy issues [[7](#bib.bib7)]. As hardware designs
    grow in complexity and the number of IP cores increases, the task of manually
    creating prompts that address every potential security vulnerability becomes impractical.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，在**种子 AI** 使用方面，尤其是通过 LLMs，取得了显著进展，这大大提升了验证问题的解决能力，尤其是在自动化验证过程、减少所需专家知识和时间方面[[7](#bib.bib7)]。**提示工程**，即制定引导
    LLMs 响应的输入的过程，被广泛用于硬件安全验证目的[[8](#bib.bib8), [9](#bib.bib9), [10](#bib.bib10)]。例如，[[8](#bib.bib8)]
    探索了使用专家设计的提示来引导模型在特定调试场景中的行为。然而，这种方法存在可扩展性和提示有效性问题[[7](#bib.bib7)]。随着硬件设计的复杂性增加和
    IP 核数量的增加，手动创建能够解决每个潜在安全漏洞的提示变得不切实际。
- en: One of the main shortcomings of manual prompt engineering for hardware security
    verification resides in the reliance upon prompts created by experts possessing
    deep expertise in a specific design or scenario. This approach often fails to
    consistently yield effective instructions tailored to address vulnerabilities.
    As a result, an instruction deemed effective for mitigating a given vulnerability
    within one design may fail when applied to the same vulnerability in a different
    design. This inherent limitation adversely affects engineered prompts’ scalability
    across diverse design contexts [[11](#bib.bib11)]. While effective for specific
    scenarios, one main reason of LLM solutions for hardware security shifting from
    prompt engineering to fine-tuning (hardware-oriented training) is to better understand
    and respond the nuances of hardware security queries [[12](#bib.bib12), [13](#bib.bib13)].
    However, as fine-tuning typically requires substantial amounts of relevant data
    to train the model effectively, fine-tuning on hardware, especially due to limited
    datasets, may present challenges for achieving optimal effectiveness [[7](#bib.bib7)].
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 手动提示工程用于硬件安全验证的主要缺陷之一在于依赖于专家在特定设计或场景中的深厚专业知识所创建的提示。这种方法往往无法一致地产生有效的指令，以解决漏洞。因此，一种设计中被认为有效的指令在另一种设计中可能会失效。这一固有限制不利于工程提示在不同设计环境中的可扩展性[[11](#bib.bib11)]。尽管对于特定场景有效，但
    LLM 解决方案在硬件安全方面从提示工程转向微调（硬件导向训练）的一个主要原因是为了更好地理解和响应硬件安全查询的细微差别[[12](#bib.bib12),
    [13](#bib.bib13)]。然而，由于微调通常需要大量相关数据来有效训练模型，尤其是由于数据集有限，硬件微调可能面临实现最佳效果的挑战[[7](#bib.bib7)]。
- en: 'To Address these challenges, this paper introduces Self-HWDebug, a framework
    that leverages the self-instructional capabilities of LLMs to produce debugging
    instructions autonomously. In Self-HWDebug, we utilize LLMs to automatically generate
    debugging instructions by prompting the LLM with pairs of already-crafted vulnerable
    and secure RTL snippet. These generated instructions are then applied to debug
    unseen RTL snippets, testing their effectiveness in resolving errors in new and
    varied hardware configurations but in a same vulnerability categoty. To mention
    the core benefits of our approach, we outline the following contributions:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对这些挑战，本文介绍了 Self-HWDebug，这是一个利用 LLMs 自我指导能力自动生成调试指令的框架。在 Self-HWDebug 中，我们通过用一对已经设计好的脆弱和安全
    RTL 片段来提示 LLM，从而自动生成调试指令。这些生成的指令随后用于调试未见过的 RTL 片段，测试它们在解决新硬件配置中的错误效果，但在相同的漏洞类别中。为了提及我们方法的核心优势，我们概述了以下贡献：
- en: '(1) Automatic Self-Instructing by LLM: Self-HWDebug exploits the inherent knowledge
    embedded within the models, and the automated generation of prompts for better
    effectiveness, providing instructions with higher specificity/relevance to the
    tasks compared to expert-crafted instructions.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: (1) LLM 的自动自我指导：Self-HWDebug 利用模型中嵌入的固有知识，通过自动生成更有效的提示，相比专家设计的指令，提供了更高特异性/相关性的指令。
- en: '(2) Exploration of References for Self-Instructing: We examine varying quantities
    of references used for self-improvement in LLM self-instructing, revealing that
    the observation of more number of vulnerabilities correlates with an increased
    success rate in self-instruction for security verification.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: (2) 自我指导的参考探索：我们检查了用于自我提升的不同数量的参考，揭示了观察到的漏洞数量与自我指导在安全验证中的成功率之间的相关性。
- en: '(3) Scalability and Adaptation: We evaluate the effectiveness of Self-HWDebug
    showing the enhanced scalability of the process and allows for rapid adaptation
    to new vulnerabilities, while circumventing the labor-intensive process of verification.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: (3) 可扩展性和适应性：我们评估了 Self-HWDebug 的有效性，显示了该过程的可扩展性增强，并允许快速适应新漏洞，同时绕过了繁重的验证过程。
- en: II Background and Related Works
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 背景和相关工作
- en: 'As with most other research directions, particularly software design and testing,
    the integration of LLMs is poised to streamline hardware design processes, particularly
    for electronic design automation (EDA). LLMs, when deployed at higher levels of
    abstraction, e.g., RTL, offer multifaceted advantages from design to verification:
    (1) alleviating the burden of manual intervention in implementation tasks [[14](#bib.bib14),
    [15](#bib.bib15)], (2) acting as a substitute for conventional hardware generators,
    e.g., high-level synthesis (HLS) [[16](#bib.bib16)], (3) addressing the persistent
    issue of inadequate HDL codebase availability [[14](#bib.bib14)], (4) facilitating
    the acceleration of time-to-market (TTM) in the competitive landscape of IC design
    [[17](#bib.bib17)], and (5) minimizing the occurrence of human-induced errors
    [[7](#bib.bib7)].'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 与大多数其他研究方向，特别是软件设计和测试一样，LLMs 的整合有望简化硬件设计过程，特别是在电子设计自动化（EDA）方面。LLMs 在更高抽象层次上部署，例如
    RTL，从设计到验证提供了多方面的优势：（1）减轻实现任务中手动干预的负担 [[14](#bib.bib14)，[15](#bib.bib15)]，（2）替代传统的硬件生成器，例如高级综合（HLS）[[16](#bib.bib16)]，（3）解决
    HDL 代码库不足的持续问题 [[14](#bib.bib14)]，（4）加速在 IC 设计竞争格局中的市场时间（TTM） [[17](#bib.bib17)]，以及（5）减少人为错误的发生
    [[7](#bib.bib7)]。
- en: 'As shown in Fig. [1](#S2.F1 "Figure 1 ‣ II Background and Related Works ‣ Self-HWDebug:
    Automation of LLM Self-Instructing for Hardware Security Verification"), Within
    the domain of hardware, current mechanisms centered around LLMs can be divided
    into three main groups: (1) Development of automated AI agents tailored to streamline
    EDA workflows in the IC supply chain, (2) the derivation of software code generation
    to facilitate RTL implementation, and (3) the use of its semantic parsing for
    testing and verification. While the first group assists with a range of tasks,
    e.g., script generation, architecture specification, and interpretation of compilation
    reports, the second and third group acts as a design and testing assistant to
    expedite the design and verification process. As shown, a sub-category of the
    second and third group is centered around the use of LLMs for creating secure
    RTLs or debugging RTLs with existing vulnerabilities (security-oriented verification).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 [1](#S2.F1 "图 1 ‣ II 背景和相关工作 ‣ Self-HWDebug：硬件安全验证的 LLM 自我指导自动化") 所示，在硬件领域，目前围绕
    LLMs 的机制可以分为三个主要组别：（1）开发自动化 AI 代理以简化 IC 供应链中的 EDA 工作流，（2）推导软件代码生成以促进 RTL 实现，以及（3）利用其语义解析进行测试和验证。虽然第一组协助完成一系列任务，例如脚本生成、架构规范和编译报告解释，但第二组和第三组作为设计和测试助手，加速了设计和验证过程。如图所示，第二组和第三组的一个子类别集中在使用
    LLMs 创建安全 RTL 或调试具有现有漏洞的 RTL（以安全为导向的验证）。
- en: '![Refer to caption](img/36f68411dc28017aabc1427467494657.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/36f68411dc28017aabc1427467494657.png)'
- en: 'Figure 1: The Use of LLMs for SW/HW Coding (Design) and Test (Verification).'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：LLMs 在 SW/HW 编码（设计）和测试（验证）中的应用。
- en: '![Refer to caption](img/8de2a4a6a08678da25d648276e7f83eb.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8de2a4a6a08678da25d648276e7f83eb.png)'
- en: 'Figure 2: The Overview of Self-Instructing for HW Security Debugging (Based
    on One-Shot Learning - One Reference for Self-Instructing).'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：HW 安全调试的自我指导概述（基于一次学习 - 自我指导的一个参考）。
- en: '![Refer to caption](img/6b527c0beb845a7f53bde8fa1190587e.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/6b527c0beb845a7f53bde8fa1190587e.png)'
- en: 'Figure 3: Top View of Task Descriptions at Three Levels (I[1]-basic, I[2]-intermediate,
    I[3]-advanced) for Instructions’ Generation in Self-HWDebug (Sample CWE 1191 for
    One-shot Learning).'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：自我硬件调试（Self-HWDebug）中三个级别（I[1]-基础，I[2]-中级，I[3]-高级）的任务描述的俯视图，用于指令生成（一次性学习样本
    CWE 1191）。
- en: '![Refer to caption](img/3672ea1b6b6c23129ef7c0b965ab77bb.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/3672ea1b6b6c23129ef7c0b965ab77bb.png)'
- en: 'Figure 4: Top View of Generated Instructions (I[1]-basic, I[2]-intermediate,
    I[3]-advanced) by Llama3 for Sample CWE 1191 based on One-shot Learning.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：Llama3 生成的指令的俯视图（I[1]-基础，I[2]-中级，I[3]-高级），基于一次性学习的样本 CWE 1191。
- en: 'In security-oriented solutions, existing studies aim to propel designs towards
    a state devoid of vulnerabilities, functional or security-related. Analogous to
    the LLM-based RTL design paradigm, these methodologies fall into two primary streams:
    (1) prompt engineering, where the refinement of design prompts steers towards
    generating secure code by LLM [[8](#bib.bib8), [9](#bib.bib9), [10](#bib.bib10)],
    and (2) RTL-driven tuning, which involves modifying the framework of LLMs themselves
    based on RTL codebase to yield vulnerability-free outputs [[12](#bib.bib12), [13](#bib.bib13)].'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在以安全为导向的解决方案中，现有研究旨在推动设计达到没有漏洞的状态，无论是功能性的还是安全相关的。类似于基于 LLM 的 RTL 设计范式，这些方法分为两个主要流派：（1）提示工程，其中设计提示的优化指导
    LLM 生成安全代码 [[8](#bib.bib8), [9](#bib.bib9), [10](#bib.bib10)]，以及（2）基于 RTL 的调整，这涉及根据
    RTL 代码库修改 LLM 的框架，以产生无漏洞的输出 [[12](#bib.bib12), [13](#bib.bib13)]。
- en: Although LLMs in hardware security exhibit promising potential, they encounter
    formidable obstacles in hardware design, testing, and verification. These challenges
    arise from factors such as prompt engineering and fine-tuning, highlighting the
    paramount importance of acquiring and effectively utilizing high-quality codebases
    [[18](#bib.bib18)]. Moreover, the creation of specialized LLMs, e.g., large circuit
    models (LCMs), or the adaptation of existing models necessitate deep expertise
    to achieve optimal outcomes in RTL-oriented tasks encompassing generation, detection,
    and mitigation [[19](#bib.bib19), [20](#bib.bib20)]. In light of these challenges,
    the endeavor demands rigorous and concerted efforts across diverse domains.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 LLM 在硬件安全方面展示了有希望的潜力，但在硬件设计、测试和验证中遇到了严峻的挑战。这些挑战源于提示工程和微调等因素，突显了获取和有效利用高质量代码库的重要性
    [[18](#bib.bib18)]。此外，创建专门的 LLM，例如大型电路模型（LCMs），或调整现有模型需要深厚的专业知识，以在 RTL 相关任务中实现最佳效果，包括生成、检测和缓解
    [[19](#bib.bib19), [20](#bib.bib20)]。鉴于这些挑战，这一工作需要在不同领域进行严格而协调的努力。
- en: 'III Proposed Scheme: Self-HWDebug'
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III 提议方案：自我硬件调试（Self-HWDebug）
- en: 'In Self-HWDebug, as shown in Fig. [2](#S2.F2 "Figure 2 ‣ II Background and
    Related Works ‣ Self-HWDebug: Automation of LLM Self-Instructing for Hardware
    Security Verification"), generating and testing instructions operates through
    a two-stage process: First, for a specific vulnerability, e.g., *CWE*[x], we generate
    instructions based on a predefined pair of vulnerable (*V*[x1]) and secure code
    (*S*[x1]) snippets, known as the reference sample. Using this pair, LLM will be
    invoked to generate an instruction (*I*[x1,i]), acting as security rule checks,
    that can be used for debugging the vulnerable snippet. Next, we provide these
    instructions (*I*[x1,i]) along with a different vulnerable code snippet (*V*). Using this
    approach, the design and verification team can enhance the self-improvement of
    the LLM and bypass the challenging and time-consuming task of manually crafting
    instructions by human experts. We utilize one pair (one-shot shown in Fig. [2](#S2.F2
    "Figure 2 ‣ II Background and Related Works ‣ Self-HWDebug: Automation of LLM
    Self-Instructing for Hardware Security Verification")) and multiple pairs (case
    study of two-shot shown in Fig. [5](#S4.F5 "Figure 5 ‣ IV-A Bugs Descriptions
    ‣ IV Experiments and Results ‣ Self-HWDebug: Automation of LLM Self-Instructing
    for Hardware Security Verification")) from each vulnerability as reference to
    produce instructions, while a set of different circuits induced with the same
    vulnerabilities are used to test the effectiveness of the generated instructions
    for debugging RTL codes.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Self-HWDebug 中，如图 [2](#S2.F2 "图 2 ‣ II 背景和相关工作 ‣ Self-HWDebug：硬件安全验证的 LLM
    自我指导自动化") 所示，生成和测试指令通过两个阶段进行：首先，对于特定漏洞，例如 *CWE*[x]，我们基于预定义的漏洞 (*V*[x1]) 和安全代码
    (*S*[x1]) 片段对生成指令，这些被称为参考样本。使用这个对，LLM 将被调用生成一个指令 (*I*[x1,i])，作为安全规则检查，可以用于调试漏洞片段。接下来，我们提供这些指令
    (*I*[x1,i]) 以及不同的漏洞代码片段 (*V*)。采用这种方法，设计和验证团队可以提升
    LLM 的自我改进，绕过由人工专家手工编写指令的挑战性和耗时任务。我们利用一个对（如图 [2](#S2.F2 "图 2 ‣ II 背景和相关工作 ‣ Self-HWDebug：硬件安全验证的
    LLM 自我指导自动化") 中的单次示例）和多个对（如图 [5](#S4.F5 "图 5 ‣ IV-A 错误描述 ‣ IV 实验与结果 ‣ Self-HWDebug：硬件安全验证的
    LLM 自我指导自动化") 中的双次案例研究）作为参考来生成指令，同时使用一组不同的电路，具有相同漏洞，用于测试生成指令在调试 RTL 代码中的有效性。
- en: III-A Instruction Generation at Multiple Levels
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-A 多级指令生成
- en: 'Our objective is to develop a set of debugging instructions *I*[x1,i] for each
    CWE category, customized to varying levels of detail. These instructions are designed
    to effectively enable the language model to suggest repairs when paired with instances
    of vulnerabilities. To do so, for each CWE category (*CWE*[x] in Fig. [2](#S2.F2
    "Figure 2 ‣ II Background and Related Works ‣ Self-HWDebug: Automation of LLM
    Self-Instructing for Hardware Security Verification")), we prepare a task description
    (*T*[x,i]) along with both vulnerable (*V*[x1]) and secure (*S*[x1]) code snippets.
    Consider $M$ represents the level of detail required from the language model as
    follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是为每个 CWE 类别开发一套调试指令 *I*[x1,i]，并根据不同的详细程度进行定制。这些指令旨在有效地使语言模型在与漏洞实例配对时建议修复。为此，对于每个
    CWE 类别（图 [2](#S2.F2 "图 2 ‣ II 背景和相关工作 ‣ Self-HWDebug：硬件安全验证的 LLM 自我指导自动化") 中的
    *CWE*[x]），我们准备一个任务描述 (*T*[x,i]) 以及漏洞 (*V*[x1]) 和安全 (*S*[x1]) 代码片段。考虑 $M$ 表示语言模型所需的详细程度，具体如下：
- en: '(1) Basic: It mostly focuses on a high-level description of the CWE and how
    it can be basically mitigated.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: (1) 基础：它主要关注于 CWE 的高级描述及其基本缓解方法。
- en: '(2) Intermediate: It covers a high-level of the CWE and how it can be basically
    mitigated (basic). It also offers a more detailed step-by-step debugging instructions,
    which resembles a detailed security rule checklist for the targeted vulnerability.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: (2) 中级：它涵盖了 CWE 的高级别及其基本缓解方法（基础）。它还提供了更详细的逐步调试说明，类似于针对目标漏洞的详细安全规则检查表。
- en: '(3) Advanced: It covers a high-level of the CWE and how it can be basically
    mitigated (basic), alongside with a more detailed step-by-step debugging instructions
    (intermediate), while it also provides a second example pair of vulnerable and
    secure code snippet using a different design.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: (3) 高级：它涵盖了 CWE 的高级别及其基本缓解方法（基础），同时提供了更详细的逐步调试说明（中级），并且提供了一个使用不同设计的漏洞和安全代码片段的第二个示例对。
- en: 'To build a more clear picture of how these levels are generated, and how LLMs
    are initially invoked for instruction generation at different levels, Fig. [3](#S2.F3
    "Figure 3 ‣ II Background and Related Works ‣ Self-HWDebug: Automation of LLM
    Self-Instructing for Hardware Security Verification") demonstrates a sample showcase
    on how these levels are defined for task description specialized for CWE-1191\.
    Despite many recent hardware verification techniques centered on LLMs, which demand
    deep expert knowledge for generation and testing, Self-HWDebug only requires these
    high-level and generic descriptions, where designers, without needing in-depth
    security examination and expertise, can generate these descriptions with minimal
    effort, drawing almost automatically from sources such as CWE databases, design/architecture
    specification sheets, etc.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更清晰地了解这些级别是如何生成的，以及LLM如何最初被调用以生成不同级别的指令，图[3](#S2.F3 "图3 ‣ II 背景和相关工作 ‣ Self-HWDebug：硬件安全验证的LLM自我指导自动化")展示了如何为专门针对CWE-1191的任务描述定义这些级别的示例。尽管许多近期的硬件验证技术集中在LLM上，这些技术要求深入的专家知识进行生成和测试，但Self-HWDebug只需这些高层次和通用的描述，设计师无需深入的安全检查和专业知识即可生成这些描述，几乎可以从CWE数据库、设计/架构规格表等来源自动提取。
- en: III-B Mitigating Vulnerabilities with Generated Instructions
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-B 通过生成指令减轻漏洞
- en: 'Given the descriptions mentioned above followed by calling the LLM, the required
    instructions will be generated per vulnerability at the desired levels. Fig. [4](#S2.F4
    "Figure 4 ‣ II Background and Related Works ‣ Self-HWDebug: Automation of LLM
    Self-Instructing for Hardware Security Verification") depicts the generated instructions
    for different levels of detail²²2Due to spacing, less critical instruction snippets
    have been omitted.. As shown in Fig. [4](#S2.F4 "Figure 4 ‣ II Background and
    Related Works ‣ Self-HWDebug: Automation of LLM Self-Instructing for Hardware
    Security Verification"), the more advanced instructions provide increased detail
    regarding the bug and mitigation strategies. These more advanced instructions
    contribute to a higher success rate in achieving secure design. To see the efficiency
    of Self-HWDebug, following the generation of these instructions, they are utilized
    to test unseen vulnerable code snippets within the same vulnerability category,
    aiming to mitigate the vulnerability across various designs. Assume we possess
    code ($V_{xi}$ is a general task description that we ask LLM to mitigate the vulnerability
    according to the given instruction.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 根据上述描述，并调用LLM后，将会按照所需的级别生成每个漏洞所需的指令。图[4](#S2.F4 "图4 ‣ II 背景和相关工作 ‣ Self-HWDebug：硬件安全验证的LLM自我指导自动化")展示了不同细节级别的生成指令²²2由于间距，较不重要的指令片段已被省略。正如图[4](#S2.F4
    "图4 ‣ II 背景和相关工作 ‣ Self-HWDebug：硬件安全验证的LLM自我指导自动化")所示，更高级的指令提供了有关漏洞和缓解策略的更多细节。这些更高级的指令有助于提高安全设计的成功率。为了评估Self-HWDebug的效率，在生成这些指令后，它们将被用于测试同一漏洞类别中的未见漏洞代码片段，旨在缓解各种设计中的漏洞。假设我们拥有代码（$V_{xi}$是我们要求LLM根据给定指令减轻漏洞的通用任务描述）。
- en: III-C Using multiple references for higher accuracy
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-C 使用多个参考以提高准确性
- en: 'When employing a single reference (one-shot) to generate instructions (e.g.,
    *V*[x1] and *S*[x1] for *CWE*[x]), our experimental results show acceptable success
    rate. However, depending on the type of the vulnerability, difficulties to mitigate,
    vulnerability and task/instruction representation, etc., different vulnerabilities
    within the same CWE category can require distinct mitigation techniques, and one
    technique (one reference) may not sufficiently address the same vulnerability
    in a different design. Recognizing this limitation in the one-shot method (Fig.
    [2](#S2.F2 "Figure 2 ‣ II Background and Related Works ‣ Self-HWDebug: Automation
    of LLM Self-Instructing for Hardware Security Verification")), where the instruction
    might not include multiple techniques, we explore the possibility of using multiple
    references (showcasing two-shot), targeting a higher success rate (better coverage
    of the same vulnerability while the LLM targets the same CWE across a wider array
    of unseen designs).'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '当使用单一参考（一次性）生成指令（例如，*V*[x1]和*S*[x1]用于*CWE*[x]）时，我们的实验结果显示成功率是可以接受的。然而，根据漏洞类型、缓解难度、漏洞和任务/指令表示等因素，同一CWE类别中的不同漏洞可能需要不同的缓解技术，而一种技术（一个参考）可能不足以解决不同设计中的相同漏洞。认识到一次性方法的这一局限性（见图[2](#S2.F2
    "Figure 2 ‣ II Background and Related Works ‣ Self-HWDebug: Automation of LLM
    Self-Instructing for Hardware Security Verification")），即指令可能不包括多种技术，我们探索了使用多个参考（展示两次性）以期达到更高的成功率（在LLM面向更广泛的未见设计的同时，更好地覆盖相同漏洞）。'
- en: 'To enable the use of multiple references (e.g., two-shot), as shown in Fig.
    [5](#S4.F5 "Figure 5 ‣ IV-A Bugs Descriptions ‣ IV Experiments and Results ‣ Self-HWDebug:
    Automation of LLM Self-Instructing for Hardware Security Verification"), we prompt
    the LLM to generate instructions using two distinct pairs of references that address
    the same vulnerability through varied techniques/designs (*CWE*[x] in both {*V*[x1],
    *S*[x1]} and {*V*[x2], *S*[x2]}). To obtain the two-shot instruction (*I*[xt]
    as the combination of *I*[x1] and *I*[x2]), we prompt the LLM with a task description
    (see Fig. [6](#S4.F6 "Figure 6 ‣ IV-A Bugs Descriptions ‣ IV Experiments and Results
    ‣ Self-HWDebug: Automation of LLM Self-Instructing for Hardware Security Verification"))
    formulated as $I_{xt}=M(T_{xt}\oplus V_{x1}\oplus S_{x1}\oplus V_{x2}\oplus S_{x2})$,
    where (*V*[x1], *S*[x1]) and (*V*[x2], *S*[x2]) are our reference samples (two
    pairs of vulnerable and secure snippet codes). By contrasting the task descriptions
    from the one-shot (Fig. [3](#S2.F3 "Figure 3 ‣ II Background and Related Works
    ‣ Self-HWDebug: Automation of LLM Self-Instructing for Hardware Security Verification"))
    and two-shot approaches (Fig. [6](#S4.F6 "Figure 6 ‣ IV-A Bugs Descriptions ‣
    IV Experiments and Results ‣ Self-HWDebug: Automation of LLM Self-Instructing
    for Hardware Security Verification")), the two-shot method prompts the LLM to
    generate a combined instruction that considers both references (to build a more
    comprehensive set of instructions, i.e., *I*[xt,i=1,2,3]. In our experimental
    results, by analyzing The instructions generated using in two-shot approach, we
    demonstrate that using multiple reference (here is 2), the mitigation operates
    more comprehensive and contain more detail and strategies compared to their one-shot
    counterpart. It is noteworthy that an increasing number of references could potentially
    enhance comprehensiveness. However, in future studies, we demonstrate that there
    is a threshold for the number of references beyond which the model may be misled.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '为了支持使用多个参考（例如，两次引用），如图 [5](#S4.F5 "Figure 5 ‣ IV-A Bugs Descriptions ‣ IV Experiments
    and Results ‣ Self-HWDebug: Automation of LLM Self-Instructing for Hardware Security
    Verification") 所示，我们提示 LLM 使用两个不同的参考对生成指令，这些参考对通过不同的技术/设计（*CWE*[x] 在 {*V*[x1],
    *S*[x1]} 和 {*V*[x2], *S*[x2]} 中）来解决相同的漏洞。为了获得两次引用的指令（*I*[xt] 作为 *I*[x1] 和 *I*[x2]
    的组合），我们用一个任务描述提示 LLM（见图 [6](#S4.F6 "Figure 6 ‣ IV-A Bugs Descriptions ‣ IV Experiments
    and Results ‣ Self-HWDebug: Automation of LLM Self-Instructing for Hardware Security
    Verification")），其公式为 $I_{xt}=M(T_{xt}\oplus V_{x1}\oplus S_{x1}\oplus V_{x2}\oplus
    S_{x2})$，其中 (*V*[x1], *S*[x1]) 和 (*V*[x2], *S*[x2]) 是我们的参考样本（两对漏洞和安全片段代码）。通过对比一次引用（图
    [3](#S2.F3 "Figure 3 ‣ II Background and Related Works ‣ Self-HWDebug: Automation
    of LLM Self-Instructing for Hardware Security Verification")）和两次引用方法（图 [6](#S4.F6
    "Figure 6 ‣ IV-A Bugs Descriptions ‣ IV Experiments and Results ‣ Self-HWDebug:
    Automation of LLM Self-Instructing for Hardware Security Verification")）的任务描述，两次引用的方法提示
    LLM 生成考虑到两个参考的组合指令（以构建更全面的指令集，即 *I*[xt,i=1,2,3]）。在我们的实验结果中，通过分析使用两次引用方法生成的指令，我们证明了使用多个参考（这里是
    2）时，缓解措施更全面，包含更多细节和策略，相较于一次引用的情况。值得注意的是，增加参考的数量可能会提升全面性。然而，在未来的研究中，我们展示了在参考数量超过某一阈值后，模型可能会被误导。'
- en: IV Experiments and Results
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 实验与结果
- en: To assess the effectiveness of Self-HWDebug, we conduct experiments that involve
    generating and testing instructions in both one-shot and two-shot formats over
    a set of CWEs. Furthermore, we explore various levels of instruction complexity
    to gauge the impact of more advanced directives. Additionally, we experiment with
    integrating guidance from an expert LLM to determine whether their advanced knowledge
    can improve the mitigation efforts of an open-source model.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估 Self-HWDebug 的有效性，我们进行了涉及生成和测试一次引用和两次引用格式指令的实验，涵盖了一组 CWE。此外，我们探索了各种指令复杂性级别，以衡量更高级指令的影响。此外，我们还尝试整合专家
    LLM 的指导，以确定其高级知识是否能改善开源模型的缓解效果。
- en: IV-A Bugs Descriptions
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A 漏洞描述
- en: '![Refer to caption](img/03c125c8370e4cbfce040e985a423aa7.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/03c125c8370e4cbfce040e985a423aa7.png)'
- en: 'Figure 5: The Overview of Self-Instructing for HW Security Debugging (Based
    on Two-Shot Learning - Two References for Self-Instructing).'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：硬件安全调试自我指令的概述（基于两次引用学习 - 两个自我指令的参考）。
- en: '![Refer to caption](img/f00059aa42267876fa719d7ffdbff181.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/f00059aa42267876fa719d7ffdbff181.png)'
- en: 'Figure 6: Generating Instruction for Two-shot Learning (Sample CWE 1191).'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：两次引用学习的指令生成（样本 CWE 1191）。
- en: 'In our experimental setup, we focused on a subset (five) of most important
    hardware CWEs [[21](#bib.bib21)]. For each category, a database of seven distinct
    samples (snippet code with vulnerabilities) based on the respective CWE descriptions
    (from different sources, e.g., MITRE [[21](#bib.bib21)], hackathons [[22](#bib.bib22)],
    Trust-hub [[23](#bib.bib23)], etc.). We designated one/two of these samples as
    the reference (shot) for generating instructions, while we used five (different
    designs) to test the efficacy of the generated instructions in addressing and
    rectifying the issues. Table [I](#S4.T1 "TABLE I ‣ IV-C Instruction Generation
    in One- and Two-Shot Approaches ‣ IV Experiments and Results ‣ Self-HWDebug: Automation
    of LLM Self-Instructing for Hardware Security Verification") demonstrates the
    utilized CWE categories and their description. For two-shot approach, we used
    and extra pair of vulnerable and secure code as the reference.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '在我们的实验设置中，我们关注了最重要的硬件CWE的一个子集（五个）[[21](#bib.bib21)]。对于每个类别，我们根据相应的CWE描述（来自不同来源，如MITRE
    [[21](#bib.bib21)]、黑客马拉松 [[22](#bib.bib22)]、Trust-hub [[23](#bib.bib23)]等）建立了一个包含七个不同样本（具有漏洞的代码片段）的数据库。我们将这些样本中的一个/两个指定为生成指令的参考（shot），同时使用五个（不同设计）来测试生成的指令在解决和修正问题上的有效性。表格
    [I](#S4.T1 "TABLE I ‣ IV-C Instruction Generation in One- and Two-Shot Approaches
    ‣ IV Experiments and Results ‣ Self-HWDebug: Automation of LLM Self-Instructing
    for Hardware Security Verification") 展示了所使用的CWE分类及其描述。对于两次性方法，我们使用了额外的一对脆弱和安全代码作为参考。'
- en: IV-B Experimental Settings
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-B 实验设置
- en: In all our experiments we utilized recently-introduced Llama3-70B [[24](#bib.bib24)].
    This is an open-source high-capacity language model from Meta, designed for text
    and code generation. For implementing LLM, we employ the Groq API [[25](#bib.bib25)].
    This API uses Groq’s cutting-edge LPU technology, which provides extremely fast
    AI inference capabilities, and make it highly suitable for tasks that require
    real-time performance. As of May 2024, Groq provides a free plan, though it comes
    with some limitations. To ensure consistency in our analysis of the experiments,
    we set the temperature and top-p parameters to constant values of 0.6 and 1, respectively.
    This approach allows us to examine the effects of other variables without the
    influence of the probabilistic nature of LLM outputs.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有实验中，我们使用了最近引入的Llama3-70B [[24](#bib.bib24)]。这是Meta推出的一个开源高容量语言模型，旨在进行文本和代码生成。为了实现LLM，我们使用了Groq
    API [[25](#bib.bib25)]。该API使用Groq的前沿LPU技术，提供极快的AI推理能力，非常适合需要实时性能的任务。截至2024年5月，Groq提供了一个免费计划，但有一些限制。为了确保我们对实验分析的一致性，我们将温度和top-p参数设置为恒定值0.6和1。这种方法使我们能够检查其他变量的影响，而不受LLM输出的概率性质的影响。
- en: IV-C Instruction Generation in One- and Two-Shot Approaches
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-C 一次性和两次性方法中的指令生成
- en: 'In the one-shot approach, we prompt the LLM with a single reference to generate
    general debugging instructions at varying levels of detail³³3To enhance the accuracy
    of these instructions, a hardware designer can add general annotation to the reference
    code with comments.. Our observations indicate that the LLM-produced instructions
    are comprehensive, capturing both the essence of the vulnerability and the necessary
    debugging steps for mitigating the vulnerability. These instructions are then
    validated: the LLM is prompted with an unseen snippet to provide a repair solution,
    and we use an assertion-based validation on the the repaired code to verify its
    validity.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在一次性方法中，我们通过一个参考来提示LLM生成不同详细程度的一般调试指令³³3为了提高这些指令的准确性，硬件设计师可以通过在参考代码中添加一般性注释来增强准确性。我们的观察结果表明，LLM生成的指令是全面的，涵盖了漏洞的本质以及减轻漏洞所需的调试步骤。这些指令随后经过验证：LLM被提示用一个未见过的代码片段提供修复方案，我们使用基于断言的验证来验证修复代码的有效性。
- en: 'TABLE I: Description of the utilized CWE categories.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 表 I：所使用的CWE分类描述。
- en: '| CWE category | Bug description |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| CWE 分类 | 错误描述 |'
- en: '| --- | --- |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| CWE-1191 | Pertains to vulnerabilities in on-chip debug and test interfaces
    that lack proper access controls, potentially allowing unauthorized access or
    manipulation of the chip’s functions. |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| CWE-1191 | 涉及芯片上调试和测试接口中缺乏适当访问控制的漏洞，可能允许未经授权的访问或操作芯片功能。 |'
- en: '| CWE-1231 | Refers to vulnerabilities arising from the improper prevention
    of modifications to lock bits, which can lead to unauthorized changes in the device’s
    functionality or security settings. |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| CWE-1231 | 指由于未能正确防止对锁定位的修改而产生的漏洞，这可能导致设备功能或安全设置的未经授权的更改。 |'
- en: '| CWE-1244 | Involves vulnerabilities where internal assets are exposed due
    to being set at an unsafe debug access level or state, potentially compromising
    the security and integrity of the system. |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| CWE-1244 | 涉及由于设置为不安全的调试访问级别或状态而暴露的内部资产的漏洞，这可能会危害系统的安全性和完整性。 |'
- en: '| CWE-1245 | Refers to vulnerabilities due to improperly designed Finite State
    Machines (FSMs) in hardware logic, which can lead to unpredictable behavior or
    security risks in the hardware’s operation. |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| CWE-1245 | 指由于硬件逻辑中的有限状态机（FSM）设计不当而产生的漏洞，这可能导致硬件操作中的不可预测行为或安全风险。 |'
- en: '| CWE-1300 | Relates to vulnerabilities from inadequate safeguards against
    physical side channels, which can inadvertently reveal critical information through
    the hardware’s electromagnetic signals, acoustic outputs, or power consumption
    patterns. |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| CWE-1300 | 相关于对物理侧通道的保护措施不足，这可能通过硬件的电磁信号、声学输出或功耗模式无意中泄露关键信息。 |'
- en: '![Refer to caption](img/cfc58bd7aaaab1ae1922209baa73bce5.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/cfc58bd7aaaab1ae1922209baa73bce5.png)'
- en: 'Figure 7: One example of a vulnerable code snippet (CWE 1231) alongside its
    repairs, each generated with different levels of instruction detail.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：一个脆弱代码片段（CWE 1231）及其修复示例，每个修复都是通过不同程度的指令细节生成的。
- en: IV-D Instruction Generation by More Advanced Model
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-D 更高级模型的指令生成
- en: Apart from the instruction and testing generation all done by LLama3, we also
    incorporated knowledge from more advanced and capable models, e.g., GPT-4, to
    determine if it can further improve mitigation success rate. For this part of
    the experiment, we utilized GPT-4 to generate detailed instructions based on a
    reference pair and then apply these instructions to Llama3 for generating the
    repairs.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 除了由 LLama3 完成的指令生成和测试，我们还结合了来自更先进且更强大的模型的知识，例如 GPT-4，以确定它是否可以进一步提高缓解成功率。在这部分实验中，我们利用
    GPT-4 基于参考对生成详细的指令，然后将这些指令应用于 Llama3 以生成修复方案。
- en: 'Our findings, as shown in Table [II](#S4.T2 "TABLE II ‣ IV-F Takeaways for
    Self Instructing in Hardware Verification ‣ IV Experiments and Results ‣ Self-HWDebug:
    Automation of LLM Self-Instructing for Hardware Security Verification"), demonstrate
    that GPT-4’s comprehensive instructions greatly aid Llama3 in performing more
    effective code repairs. This approach allows us to leverage the advanced capabilities
    of a limited-access, closed-source model (i.e., GPT-4) to augment an open-source
    model (i.e., Llama3) and achieve comparable performance at a lower cost. The integration
    of GPT-4 involves a process similar to knowledge distillation, where GPT-4, serving
    as a sophisticated *’teacher’*, transfers complex debugging strategies and subtle
    details to Llama3, the *’student’*. This method infuses Llama3 with enhanced capabilities
    to handle complex debugging tasks that were previously out of reach and demonstrate
    a practical application of knowledge distillation in bridging the gap between
    proprietary and open-source LLMs.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '我们的研究结果，如表格 [II](#S4.T2 "TABLE II ‣ IV-F Takeaways for Self Instructing in
    Hardware Verification ‣ IV Experiments and Results ‣ Self-HWDebug: Automation
    of LLM Self-Instructing for Hardware Security Verification") 所示，表明 GPT-4 的全面指令大大帮助了
    Llama3 更有效地进行代码修复。这种方法允许我们利用有限访问的闭源模型（即 GPT-4）的先进能力来增强开源模型（即 Llama3），并在较低的成本下实现类似的性能。GPT-4
    的集成涉及类似于知识蒸馏的过程，其中 GPT-4 作为复杂的*“教师”*，将复杂的调试策略和细微细节传递给 Llama3，即*“学生”*。这种方法为 Llama3
    注入了增强的能力，以处理之前难以完成的复杂调试任务，并展示了知识蒸馏在弥合专有和开源 LLM 之间差距中的实际应用。'
- en: IV-E Comparison of Different Levels of Instruction
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-E 不同级别指令的比较
- en: 'Table [II](#S4.T2 "TABLE II ‣ IV-F Takeaways for Self Instructing in Hardware
    Verification ‣ IV Experiments and Results ‣ Self-HWDebug: Automation of LLM Self-Instructing
    for Hardware Security Verification") depicts the mitigation results for the targeted
    CWE categories and different instructions’ levels. As demonstrated, the model
    exhibits improvement from basic to advanced task descriptions in one-shot self-instructing.
    However, this improvement is not always consistent, as the quality of the model’s
    responses can vary due to inherent randomness and certain limitations. Nonetheless,
    by transitioning to a more advanced model, such as GPT-4, and employing a two-shot
    model approach (moving towards optimum -multiple- number of references), even
    at an intermediate level of task description, the success rate remains consistently
    high.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '表格 [II](#S4.T2 "TABLE II ‣ IV-F Takeaways for Self Instructing in Hardware
    Verification ‣ IV Experiments and Results ‣ Self-HWDebug: Automation of LLM Self-Instructing
    for Hardware Security Verification") 展示了针对目标CWE类别和不同指令级别的缓解结果。如所示，该模型在单次自我指导中从基本到高级任务描述的表现有所改进。然而，这种改进并非总是稳定的，因为模型响应的质量可能因固有的随机性和某些限制而有所不同。尽管如此，通过转向更高级的模型，如GPT-4，并采用两次训练的模型方法（朝着最佳的-多-参考数量前进），即使在中级任务描述下，成功率仍保持一致的高水平。'
- en: 'To draw a top picture of how this self-instructing performs for a specific
    scenario, Fig. [7](#S4.F7 "Figure 7 ‣ IV-C Instruction Generation in One- and
    Two-Shot Approaches ‣ IV Experiments and Results ‣ Self-HWDebug: Automation of
    LLM Self-Instructing for Hardware Security Verification") shows a snippet code
    of CWE 1231 and its mitigation approaches with different level of details (based
    on the instructions generated from Figs. [3](#S2.F3 "Figure 3 ‣ II Background
    and Related Works ‣ Self-HWDebug: Automation of LLM Self-Instructing for Hardware
    Security Verification") and Fig. [6](#S4.F6 "Figure 6 ‣ IV-A Bugs Descriptions
    ‣ IV Experiments and Results ‣ Self-HWDebug: Automation of LLM Self-Instructing
    for Hardware Security Verification")). In the vulnerable snippet code the logic
    mistakenly sets the config_lock to 1’b0 (unlocked) when the state is not in maintenance_mode,
    which is counter-intuitive as it should remain locked to protect the system configuration.
    This leaves the system vulnerable to unauthorized changes almost at normal (functional)
    mode (vs. during the test mode).'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '为了描绘自我指导在特定场景下的表现，图 [7](#S4.F7 "Figure 7 ‣ IV-C Instruction Generation in One-
    and Two-Shot Approaches ‣ IV Experiments and Results ‣ Self-HWDebug: Automation
    of LLM Self-Instructing for Hardware Security Verification") 展示了CWE 1231的代码片段及其在不同详细程度下的缓解方法（基于图
    [3](#S2.F3 "Figure 3 ‣ II Background and Related Works ‣ Self-HWDebug: Automation
    of LLM Self-Instructing for Hardware Security Verification") 和图 [6](#S4.F6 "Figure
    6 ‣ IV-A Bugs Descriptions ‣ IV Experiments and Results ‣ Self-HWDebug: Automation
    of LLM Self-Instructing for Hardware Security Verification") 生成的指令）。在易受攻击的代码片段中，逻辑错误地将config_lock设置为1’b0（解锁），当状态不在maintenance_mode时，这与应保持锁定以保护系统配置的直觉相反。这使得系统在几乎正常（功能）模式下容易受到未经授权的更改（相对于测试模式）。'
- en: In the advanced level mitigation, LLM simplifies the control logic by removing
    the maintenance mode check, resulting in a configuration that is always unlocked
    except during the reset. This approach is less secure than even the flawed original,
    as it does not attempt to verify the context or condition under which unlocking
    is permissible. With instructions generated by GPT-4, the LLM tries to mitigate
    the bug by unlocking during both system resets and maintenance mode which enables
    a more flexible and accessible system management. With the two-shot approach,
    the LLM (all based on Llama3) introduces a multi-condition lock control mechanism,
    leveraging both a global reset and a specific JTAG unlock condition, which can
    be tied to authenticated sessions or cryptographic checks.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在高级缓解级别中，LLM通过移除维护模式检查简化了控制逻辑，导致配置在除重置期间始终解锁。这种方法比起有缺陷的原始方法还不够安全，因为它没有尝试验证解锁是否被允许的上下文或条件。使用GPT-4生成的指令，LLM尝试通过在系统重置和维护模式期间解锁来缓解漏洞，从而实现更灵活和可访问的系统管理。使用两次训练的方法，LLM（全部基于Llama3）引入了一个多条件锁控制机制，利用全球重置和特定的JTAG解锁条件，可以与认证会话或加密检查绑定。
- en: IV-F Takeaways for Self Instructing in Hardware Verification
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-F 硬件验证自我指导的要点
- en: 'TABLE II: Efficacy Ratio of Self-HWDebug in Self-Instructing for Security Verification
    (Debugging using One/Two-Shot Learning).'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 表II：Self-HWDebug在安全验证中的自我指导效率比（使用一次/两次训练学习进行调试）。
- en: '| Vulnerability | Basic | Intermediate | Advanced | GPT-4^(∗1) | Two-shot^(∗1)
    |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 漏洞 | 基本 | 中级 | 高级 | GPT-4^(∗1) | 两次训练^(∗1) |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| CWE-1191 | 2 out of 5 | 5 out of 5 | 3 out of 5 | 4 out of 5 | 5 out of 5
    |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| CWE-1191 | 5 分之 2 | 5 分之 5 | 5 分之 3 | 5 分之 4 | 5 分之 5 |'
- en: '| CWE-1231 | 0 out of 5 | 0 out of 5 | 1 out of 5 | 2 out of 5 | 5 out of 5
    |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| CWE-1231 | 5 分之 0 | 5 分之 0 | 5 分之 1 | 5 分之 2 | 5 分之 5 |'
- en: '| CWE-1244 | 5 out of 5 | 4 out of 5 | 5 out of 5 | 5 out of 5 | 5 out of 5
    |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| CWE-1244 | 5 分之 5 | 5 分之 4 | 5 分之 5 | 5 分之 5 | 5 分之 5 |'
- en: '| CWE-1245 | 5 out of 5 | 5 out of 5 | 5 out of 5 | 5 out of 5 | 5 out of 5
    |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| CWE-1245 | 5 分之 5 | 5 分之 5 | 5 分之 5 | 5 分之 5 | 5 分之 5 |'
- en: '| CWE-1300 | 2 out of 5 | 4 out of 5 | 5 out of 5 | 5 out of 5 | 5 out of 5
    |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| CWE-1300 | 5 分之 2 | 5 分之 4 | 5 分之 5 | 5 分之 5 | 5 分之 5 |'
- en: '| Average | 56% | 72% | 76% | 84% | 100% |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 平均值 | 56% | 72% | 76% | 84% | 100% |'
- en: ^(∗1)
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ^(∗1)
- en: For both GPT-4 and two-shot experiments, we used an intermediate level of detail
    when prompting the LLM.
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于GPT-4和双次实验，我们在提示LLM时使用了中等详细程度的说明。
- en: 'Dependence of Mitigation on the Accuracy of the Reference Sample: Instructions
    and subsequent mitigation become most effective when the reference examples accurately
    represent the issue across various scenarios. Therefore, using multiple reference
    pairs, each employing different approaches for mitigation, leads to more comprehensive
    and general instructions and thus, more effective self-instruction-based mitigation.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 缓解对参考样本准确性的依赖：当参考示例准确地代表了各种场景中的问题时，指令和后续缓解变得最为有效。因此，使用多个参考对，每个对采用不同的缓解方法，会导致更全面和通用的指令，从而实现更有效的基于自我指导的缓解。
- en: 'Detailed Instructions Lead to More Sophisticated Repairs: As the complexity
    and detail in the instructions or descriptions increase, particularly while coupled
    with another example within the instruction, the potential for innovative and
    sophisticated repairs also rises. This comprehensive understanding allows LLM
    to devise more complex and effective solutions.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 详细指令导致更复杂的修复：随着指令或描述的复杂性和详细程度增加，特别是当与指令中的其他示例结合时，创新和复杂修复的潜力也随之上升。这种全面的理解使得LLM能够制定出更复杂和有效的解决方案。
- en: 'Variability in Mitigation Difficulty Based on the Vulnerability: The difficulty
    of mitigating a vulnerability can vary significantly depending on the nature of
    the vulnerability itself. Some vulnerabilities might be straightforward , while
    others might be inherently complex to mitigate. Depending on their nature, multiple/advanced
    instructions are required to guarantee a high success rate in Self-HWDebug.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 基于漏洞的缓解难度的变异性：缓解一个漏洞的难度可能会根据漏洞本身的性质而显著变化。有些漏洞可能比较简单，而其他漏洞可能固有地复杂。根据它们的性质，可能需要多种/高级指令来确保在Self-HWDebug中的高成功率。
- en: V Conclusion and future work
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V 结论与未来工作
- en: In this paper, we introduce a new framework designed to enhance the scalability
    and efficiency of LLMs in mitigating security vulnerabilities in hardware designs
    in a more automated manner. Prior research has shown that LLMs can effectively
    manage vulnerability mitigation. However, generating detailed, hand-written instructions
    has remained a significant challenge. This is primarily because the creation of
    these instructions demands significant time and effort from experts and typically
    only reflects the knowledge scope of a hardware engineer. To address these limitations,
    our proposed solution, Self-HWDebug, leverages the LLM’s ability to autonomously
    generate instructions. This approach not only addresses scalability issues but
    also produces instructions that are comprehensive and informed by an expanded
    knowledge base. In Self-HWDebug, the LLM acts as its own teacher and facilitates
    self-improvement. Through an initial testing, our experiments shows the efficacy
    of Self-HWDebug over a sub-set of CWE vulnerabilities with high success rate.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们介绍了一种新框架，旨在以更自动化的方式提高LLMs在缓解硬件设计中的安全漏洞方面的可扩展性和效率。先前的研究表明，LLMs能够有效地管理漏洞缓解。然而，生成详细的手写指令仍然是一个重大挑战。这主要是因为创建这些指令需要专家付出大量时间和精力，通常仅反映了硬件工程师的知识范围。为了解决这些限制，我们提出的解决方案Self-HWDebug利用了LLM自主生成指令的能力。这种方法不仅解决了可扩展性问题，还生成了全面且基于扩展知识库的指令。在Self-HWDebug中，LLM充当自己的教师并促进自我改进。通过初步测试，我们的实验显示Self-HWDebug在处理CWE漏洞子集时具有较高的成功率。
- en: We view Self-HWDebug as a significant advancement in automating the mitigation
    of security vulnerabilities using LLMs, though require further study. Firstly,
    we plan to evaluate it over a wide (complete) range of CWEs and expand our dataset
    to advance the LLM’s capabilities towards more comprehensiveness. Also, we are
    considering the possibility of using the LLM both as a detector and mitigator
    of bugs. We believe this approach is feasible and would allow the application
    of LLMs to large-scale SoC designs, rather than being limited to snippets of already-detected
    vulnerabilities.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们视Self-HWDebug为在利用LLMs自动缓解安全漏洞方面的一个重要进展，尽管仍需进一步研究。首先，我们计划在广泛（完整）的CWE范围内评估它，并扩展我们的数据集，以提升LLM在全面性方面的能力。此外，我们正在考虑使用LLM作为漏洞检测器和缓解器的可能性。我们相信这种方法是可行的，将允许LLMs应用于大规模SoC设计，而不仅仅限于已检测漏洞的片段。
- en: References
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] S. Ray *et al.*, “System-on-chip platform security assurance: Architecture
    and validation,” *Proceedings of the IEEE*, vol. 106, no. 1, pp. 21–37, 2017.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] S. Ray *等*，“片上系统平台安全保障：架构与验证”，*Proceedings of the IEEE*，第106卷，第1期，第21–37页，2017年。'
- en: '[2] A. Ferraiuolo *et al.*, “Verification of a practical hardware security
    architecture through static information flow analysis,” in *Int’l Conference on
    Architectural Support for Programming Languages and Operating Systems (ASPLOS)*,
    2017, pp. 555–568.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] A. Ferraiuolo *等*，“通过静态信息流分析验证实际的硬件安全架构”，发表于*Int’l Conference on Architectural
    Support for Programming Languages and Operating Systems (ASPLOS)*，2017年，第555–568页。'
- en: '[3] W. Hu *et al.*, “An overview of hardware security and trust: Threats, countermeasures,
    and design tools,” *IEEE Transactions on Computer-Aided Design of Integrated Circuits
    and Systems*, vol. 40, no. 6, pp. 1010–1038, 2020.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] W. Hu *等*，“硬件安全与信任概述：威胁、对策和设计工具”，*IEEE Transactions on Computer-Aided Design
    of Integrated Circuits and Systems*，第40卷，第6期，第1010–1038页，2020年。'
- en: '[4] T. Grimm *et al.*, “A survey on formal verification techniques for safety-critical
    systems-on-chip,” *Electronics*, vol. 7, no. 6, p. 81, 2018.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] T. Grimm *等*，“关于安全关键片上系统的形式化验证技术调研”，*Electronics*，第7卷，第6期，第81页，2018年。'
- en: '[5] K. Z. Azar *et al.*, “Fuzz, penetration, and ai testing for soc security
    verification: Challenges and solutions,” *Cryptology ePrint Archive*, 2022.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] K. Z. Azar *等*，“SoC安全验证的模糊测试、渗透测试和AI测试：挑战与解决方案”，*Cryptology ePrint Archive*，2022年。'
- en: '[6] M. M. Hossain *et al.*, “Socfuzzer: Soc vulnerability detection using cost
    function enabled fuzz testing,” in *Design, Automation & Test in Europe Conference
    & Exhibition (DATE)*, 2023, pp. 1–6.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] M. M. Hossain *等*，“Socfuzzer：使用成本函数启用的模糊测试进行SoC漏洞检测”，发表于*Design, Automation
    & Test in Europe Conference & Exhibition (DATE)*，2023年，第1–6页。'
- en: '[7] M. Akyash *et al.*, “Evolutionary large language models for hardware security:
    A comparative survey,” in *Great Lakes Symposium on VLSI (GLSVLSI)*, 2024, pp.
    1–6.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] M. Akyash *等*，“硬件安全的进化型大型语言模型：比较调研”，发表于*Great Lakes Symposium on VLSI (GLSVLSI)*，2024年，第1–6页。'
- en: '[8] B. Ahmad *et al.*, “On hardware security bug code fixes by prompting large
    language models,” *IEEE Transactions on Information Forensics and Security*, 2024.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] B. Ahmad *等*，“通过提示大型语言模型修复硬件安全漏洞代码”，*IEEE Transactions on Information Forensics
    and Security*，2024年。'
- en: '[9] M. Nair *et al.*, “Generating secure hardware using chatgpt resistant to
    cwes,” *Cryptology ePrint Archive*, 2023.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] M. Nair *等*，“生成使用ChatGPT的安全硬件，抵御CWE”，*Cryptology ePrint Archive*，2023年。'
- en: '[10] M. Orenes-Vera *et al.*, “Using llms to facilitate formal verification
    of rtl,” *arXiv e-prints*, pp. arXiv–2309, 2023.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] M. Orenes-Vera *等*，“使用LLMs促进RTL的形式化验证”，*arXiv e-prints*，第arXiv–2309页，2023年。'
- en: '[11] W. Fang *et al.*, “Assertllm: Generating and evaluating hardware verification
    assertions from design specifications via multi-llms,” *arXiv preprint arXiv:2402.00386*,
    2024.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] W. Fang *等*，“AssertLLM：通过多LLMs从设计规格生成和评估硬件验证断言”，*arXiv preprint arXiv:2402.00386*，2024年。'
- en: '[12] W. Fu *et al.*, “Llm4sechw: Leveraging domain-specific large language
    model for hardware debugging,” in *Asian Hardware Oriented Security and Trust
    Symposium (AsianHOST)*, 2023, pp. 1–6.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] W. Fu *等*，“Llm4sechw：利用领域特定的大型语言模型进行硬件调试”，发表于*Asian Hardware Oriented
    Security and Trust Symposium (AsianHOST)*，2023年，第1–6页。'
- en: '[13] X. Meng *et al.*, “Unlocking hardware security assurance: The potential
    of llms,” *arXiv preprint arXiv:2308.11042*, 2023.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] X. Meng *等*，“解锁硬件安全保障：LLMs的潜力”，*arXiv preprint arXiv:2308.11042*，2023年。'
- en: '[14] Y. Lu *et al.*, “Rtllm: An open-source benchmark for design rtl generation
    with large language model,” in *Asia and South Pacific Design Automation Conference
    (ASP-DAC)*, 2024, pp. 722–727.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Y. Lu *等人*，“RTL-LM：一个用于设计RTL生成的开源基准，基于大型语言模型，” 见 *亚洲与南太平洋设计自动化会议（ASP-DAC）*，2024年，页码722–727。'
- en: '[15] M. DeLorenzo *et al.*, “Make every move count: Llm-based high-quality
    rtl code generation using mcts,” *arXiv preprint arXiv:2402.03289*, 2024.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] M. DeLorenzo *等人*，“让每一步都重要：基于LLM的高质量RTL代码生成使用MCTS，” *arXiv预印本 arXiv:2402.03289*，2024年。'
- en: '[16] J. Liu *et al.*, “Is your code generated by chatgpt really correct? rigorous
    evaluation of large language models for code generation,” *Advances in Neural
    Information Processing Systems*, vol. 36, 2024.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] J. Liu *等人*，“你的代码是由ChatGPT生成的真的正确吗？对大型语言模型在代码生成中的严格评估，” *神经信息处理系统进展*，第36卷，2024年。'
- en: '[17] S. Liu *et al.*, “Rtlcoder: Outperforming gpt-3.5 in design rtl generation
    with our open-source dataset and lightweight solution,” *arXiv preprint arXiv:2312.08617*,
    2023.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] S. Liu *等人*，“RTLcoder：在设计RTL生成中超越GPT-3.5，利用我们的开源数据集和轻量级解决方案，” *arXiv预印本
    arXiv:2312.08617*，2023年。'
- en: '[18] S. Gunasekar *et al.*, “Textbooks are all you need,” *arXiv preprint arXiv:2306.11644*,
    2023.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] S. Gunasekar *等人*，“教科书就是你所需的一切，” *arXiv预印本 arXiv:2306.11644*，2023年。'
- en: '[19] X. Li *et al.*, “Prefix-tuning: Optimizing continuous prompts for generation,”
    *arXiv preprint arXiv:2101.00190*, 2021.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] X. Li *等人*，“前缀调优：优化生成的连续提示，” *arXiv预印本 arXiv:2101.00190*，2021年。'
- en: '[20] L. Chen *et al.*, “The dawn of ai-native eda: Promises and challenges
    of large circuit models,” *arXiv preprint arXiv:2403.07257*, 2024.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] L. Chen *等人*，“AI原生EDA的黎明：大型电路模型的承诺与挑战，” *arXiv预印本 arXiv:2403.07257*，2024年。'
- en: '[21] MITRE, “2021 cwe most important hardware weaknesses,” 2021\. [Online].
    Available: https://cwe.mitre.org/data/definitions/1343.html'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] MITRE，“2021年CWE最重要硬件弱点，” 2021年\. [在线]. 可用链接: https://cwe.mitre.org/data/definitions/1343.html'
- en: '[22] A. R. Sadeghi *et al.*, “Organizing the world’s largest hardware security
    competition: challenges, opportunities, and lessons learned,” in *Proceedings
    of the 2021 on Great Lakes Symposium on VLSI*, 2021, pp. 95–100.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] A. R. Sadeghi *等人*，“组织全球最大的硬件安全竞赛：挑战、机遇与经验教训，” 见 *2021年大湖区VLSI研讨会论文集*，2021年，页码95–100。'
- en: '[23] Trust-Hub, “Trust-hub benchmarks,” 2024\. [Online]. Available: https://trust-hub.org/'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] Trust-Hub，“Trust-Hub基准测试，” 2024年\. [在线]. 可用链接: https://trust-hub.org/'
- en: '[24] Meta AI, “Llama3,” 2024\. [Online]. Available: https://llama.meta.com/llama3'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Meta AI，“Llama3，” 2024年\. [在线]. 可用链接: https://llama.meta.com/llama3'
- en: '[25] Groq, “Groq api,” 2024\. [Online]. Available: https://wow.groq.com/'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Groq，“Groq API，” 2024年\. [在线]. 可用链接: https://wow.groq.com/'
