- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 17:34:23'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 17:34:23
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Enhancing Trust in LLMs: Algorithms for Comparing and Interpreting LLMs'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 增强对LLMs的信任：LLMs比较和解释的算法
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.01943](https://ar5iv.labs.arxiv.org/html/2406.01943)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2406.01943](https://ar5iv.labs.arxiv.org/html/2406.01943)
- en: Nik Bear Brown
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 尼克·贝尔·布朗
- en: Northeastern University and Bear Brown & Company
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 东北大学与贝尔·布朗公司
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: This paper presents a survey of evaluation techniques aimed at enhancing the
    trustworthiness and understanding of Large Language Models (LLMs). Amidst growing
    reliance on LLMs across various sectors, ensuring their reliability, fairness,
    and transparency has become paramount. We explore a range of algorithmic methods
    and metrics designed to assess LLMs’ performance, identify weaknesses, and guide
    their development towards more trustworthy and effective applications. Key evaluation
    metrics discussed include Perplexity Measurement, Natural Language Processing
    (NLP) evaluation metrics (BLEU, ROUGE, METEOR, BERTScore, GLEU, Word Error Rate,
    and Character Error Rate), Zero-Shot Learning Performance, Few-Shot Learning Performance,
    Transfer Learning Evaluation, Adversarial Testing, and Fairness and Bias Evaluation.
    We also introduce innovative approaches such as LLMMaps for stratified evaluation,
    Benchmarking and Leaderboards for competitive assessment, Stratified Analysis
    for in-depth understanding, Visualization of Bloom’s Taxonomy for cognitive level
    accuracy distribution, Hallucination Score for quantifying inaccuracies, Knowledge
    Stratification Strategy for hierarchical analysis, and the use of Machine Learning
    Models for Hierarchy Generation. Furthermore, we highlight the indispensable role
    of Human Evaluation in capturing nuances that automated metrics may overlook.
    Together, these techniques form a robust framework for evaluating LLMs, aiming
    to enhance transparency, guide development, and align assessments with the goal
    of establishing user trust in these advanced language models. In future papers,
    we will describe the visualization of these metrics as well as demonstrate the
    use of each approach on practical examples.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本文对旨在增强大型语言模型（LLMs）可信度和理解度的评估技术进行了综述。随着对LLMs在各个领域的依赖日益增加，确保其可靠性、公平性和透明性变得至关重要。我们探讨了一系列算法方法和指标，这些方法和指标旨在评估LLMs的性能、识别其弱点，并引导其向更可信和有效的应用方向发展。讨论的关键评估指标包括困惑度测量、自然语言处理（NLP）评估指标（BLEU、ROUGE、METEOR、BERTScore、GLEU、单词错误率和字符错误率）、零样本学习性能、少样本学习性能、迁移学习评估、对抗测试以及公平性和偏见评估。我们还介绍了创新的方法，如用于分层评估的LLMMaps、用于竞争性评估的基准测试和排行榜、用于深入理解的分层分析、用于认知水平准确性分布的布鲁姆分类法可视化、用于量化不准确性的幻觉评分、用于分层分析的知识分层策略以及用于生成层次结构的机器学习模型。此外，我们还强调了人工评估在捕捉自动化指标可能忽视的细微差别中的不可或缺的作用。这些技术共同构成了一个强大的LLMs评估框架，旨在提高透明度、指导开发，并使评估与建立用户对这些先进语言模型的信任的目标一致。在未来的论文中，我们将描述这些指标的可视化以及演示每种方法在实际示例中的应用。
- en: 1 Introduction
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 介绍
- en: Evaluating Large Language Models (LLMs) is a nuanced process that extends beyond
    technical metrics to encompass considerations of social alignment, transparency,
    safety, and trustworthiness. Liu (2023) stresses the significance of ensuring
    LLMs align with human intentions, adhering to societal norms and regulations.
    Liao (2023) advocates for a human-centered transparency approach, focusing on
    the varied needs of all stakeholders involved. Huang (2023) delves into the safety
    and reliability of LLMs, suggesting the adoption of Verification and Validation
    (V&V) techniques to mitigate risks and conduct thorough assessments. Karabacak
    (2023) highlights the unique challenges in the medical sector, calling for comprehensive
    strategies that include clinical validation, ethical considerations, and adherence
    to regulatory standards. Together, these perspectives emphasize the essential
    roles of transparency and trust in evaluating LLMs, especially for their application
    in real-world scenarios.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 评估大型语言模型（LLMs）是一个复杂的过程，不仅涉及技术指标，还包括社会对齐、透明度、安全性和可信赖性的考量。Liu（2023）强调了确保LLMs符合人类意图、遵守社会规范和法规的重要性。Liao（2023）提倡以人为本的透明度方法，关注所有相关方的多样化需求。Huang（2023）深入探讨了LLMs的安全性和可靠性，建议采用验证与确认（V&V）技术来降低风险并进行全面评估。Karabacak（2023）突出医学领域面临的独特挑战，呼吁包括临床验证、伦理考量和遵守监管标准在内的综合策略。这些观点共同强调了透明度和信任在评估LLMs中的关键角色，尤其是在实际应用中。
- en: The evaluation of LLMs is fundamental to building trust and ensuring transparency
    in these advanced AI systems. As LLMs increasingly permeate various sectors such
    as education, healthcare, and legal advising, the importance of their careful
    assessment becomes paramount. This discussion explores the complexities of LLM
    evaluation, underscoring transparency and trust as pivotal elements for their
    successful integration and acceptance in society.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 评估LLMs对于建立信任和确保这些先进AI系统的透明度是基础。随着LLMs越来越多地渗透到教育、医疗和法律咨询等各个领域，它们的审慎评估变得尤为重要。此讨论探讨了LLM评估的复杂性，强调透明度和信任是它们成功融入和被社会接受的关键要素。
- en: 2 The Imperative for Transparency
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 透明度的必要性
- en: 'Transparency in LLMs refers to the clarity and openness regarding how models
    are trained, how they operate, and how they make decisions. This transparency
    is pivotal for several reasons:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs中的透明度指的是关于模型如何训练、如何运作以及如何做出决策的清晰度和开放性。这种透明度至关重要，原因有几个：
- en: •
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Understanding Model Decisions: Stakeholders, including users, developers, and
    regulators, must understand the basis of an LLM’s outputs. Transparent models
    allow for the identification of the data and algorithms that drive decisions,
    facilitating insights into their reliability.'
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 理解模型决策：包括用户、开发者和监管者在内的利益相关者必须了解LLM输出的基础。透明的模型允许识别驱动决策的数据和算法，促进对其可靠性的洞察。
- en: •
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Detecting and Mitigating Biases: Transparent evaluation processes enable the
    identification of biases in LLM outputs. By understanding how and why biases occur—whether
    due to training data or model architecture—developers can implement targeted interventions
    to mitigate them.'
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 检测和缓解偏见：透明的评估过程能够识别LLM输出中的偏见。通过理解偏见的发生原因——无论是由于训练数据还是模型结构——开发者可以实施有针对性的干预措施来缓解这些偏见。
- en: •
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Facilitating Model Improvements: A transparent evaluation framework helps pinpoint
    specific areas where LLMs excel or falter. This clarity is crucial for guiding
    ongoing model refinement and ensuring that improvements are aligned with ethical
    standards and societal needs.'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 促进模型改进：透明的评估框架有助于 pinpoint LLMs在某些领域的优缺点。这种清晰度对于指导持续的模型改进至关重要，并确保改进符合伦理标准和社会需求。
- en: •
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Selecting the Right Model: Transparency aids in choosing the best LLM for specific
    tasks by comparing models on performance, training, and ethical standards. This
    ensures compatibility with user needs and regulatory requirements.'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 选择合适的模型：透明度有助于通过比较模型的性能、训练和伦理标准来选择最适合特定任务的LLM。这确保了与用户需求和监管要求的兼容性。
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Ensuring Compliance and Trust: Transparent evaluations and decision-making
    processes help meet regulatory standards and build user trust, highlighting a
    commitment to ethical AI.'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 确保合规性和信任：透明的评估和决策过程有助于满足监管标准并建立用户信任，突显对伦理AI的承诺。
- en: •
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Promoting Collaborative Development: Openness in model evaluation encourages
    shared problem-solving, leading to innovative solutions and model enhancements.'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 促进协作开发：模型评估的开放性鼓励共享问题解决，推动创新解决方案和模型改进。
- en: •
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Supporting Lifelong Learning and Adaptation: Transparent evaluation facilitates
    ongoing model monitoring and updates, keeping LLMs relevant and aligned with evolving
    standards and needs.'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 支持终身学习和适应：透明的评估有助于持续监控和更新模型，使大型语言模型（LLMs）保持相关性并与不断发展的标准和需求保持一致。
- en: 3 The Quest for Trust
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 信任的追求
- en: 'Trust in LLMs hinges on their ability to perform tasks accurately, ethically,
    and reliably. Trustworthiness is built through establishing the right metrics.
    In this survey paper, we will focus on the following metrics:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 对LLMs的信任依赖于它们准确、伦理和可靠地执行任务的能力。可信度通过建立正确的指标来构建。在本次调查论文中，我们将重点关注以下指标：
- en: •
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Perplexity Measurement: Evaluates model fluency by measuring how well a model
    predicts a sample. While perplexity is a valuable metric, it’s not without limitations.
    It primarily focuses on the probabilistic prediction of words without directly
    measuring semantic accuracy or coherence.'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 困惑度测量：通过测量模型预测样本的准确性来评估模型的流畅性。虽然困惑度是一个有价值的指标，但它并非没有局限性。它主要关注对单词的概率预测，而没有直接测量语义准确性或连贯性。
- en: •
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'NLP evaluation metrics: BLEU, ROUGE, METEOR, BERTScore, GLEU, Word Error Rate
    (WER), and Character Error Rate (CER). These metrics are used to assess various
    aspects of machine-generated text, such as translation quality, summarization
    effectiveness, semantic similarity, and transcription accuracy, in the context
    of natural language processing tasks. Each metric focuses on different elements
    of text generation and comprehension, providing a comprehensive framework for
    evaluating the performance of NLP models and systems.'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自然语言处理评估指标：BLEU、ROUGE、METEOR、BERTScore、GLEU、词错误率（WER）和字符错误率（CER）。这些指标用于评估机器生成文本的各个方面，如翻译质量、摘要效果、语义相似性和转录准确性，具体涉及自然语言处理任务。每个指标侧重于文本生成和理解的不同元素，为评估自然语言处理模型和系统的性能提供了全面的框架。
- en: •
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Zero-Shot Learning Performance: Assesses the model’s ability to understand
    tasks without explicit training.'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 零样本学习表现：评估模型在没有明确训练的情况下理解任务的能力。
- en: •
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Few-Shot Learning Performance: Evaluates how well a model performs tasks with
    minimal examples.'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 少样本学习表现：评估模型在使用最少示例的情况下执行任务的能力。
- en: •
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Transfer Learning Evaluation: Tests the model’s ability to apply learned knowledge
    to different but related tasks.'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 转移学习评估：测试模型将学到的知识应用于不同但相关任务的能力。
- en: •
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Adversarial Testing: Identifies model vulnerabilities by evaluating performance
    against inputs designed to confuse or trick the model.'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对抗测试：通过评估模型在设计来混淆或欺骗模型的输入下的表现来识别模型的脆弱性。
- en: •
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Fairness and Bias Evaluation: Measures model outputs for biases and fairness
    across different demographics.'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 公平性和偏见评估：衡量模型输出在不同人群中的偏见和公平性。
- en: •
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Robustness Evaluation: Assesses model performance under varied or challenging
    conditions.'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 鲁棒性评估：在不同或具有挑战性的条件下评估模型的表现。
- en: •
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'LLMMaps: A novel visualization technique for stratified evaluation across subfields,
    emphasizing the identification of areas where LLMs excel or require improvement,
    particularly in reducing hallucinations.'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LLMMaps：一种新颖的可视化技术，用于跨子领域的分层评估，强调识别LLMs表现出色或需要改进的领域，特别是在减少虚假信息方面。
- en: •
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Benchmarking and Leaderboards: Common tools that involve LLMs answering questions
    from large Q&A datasets to test their accuracy.'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基准测试和排行榜：常用工具，通过让LLMs回答来自大型问答数据集的问题来测试其准确性。
- en: •
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Stratified Analysis: A detailed, stratified analysis across various knowledge
    subfields for a comprehensive understanding of LLMs’ strengths and weaknesses.'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 分层分析：对各种知识子领域进行详细的分层分析，以全面了解LLMs的优缺点。
- en: •
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Visualization of Bloom’s Taxonomy: Displays accuracy for each level of Bloom’s
    Taxonomy in a pyramidal fashion to understand the distribution of accuracy across
    different cognitive levels.'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 布鲁姆分类学可视化：以金字塔形展示布鲁姆分类学每个层级的准确性，以便理解在不同认知层级中的准确性分布。
- en: •
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Hallucination Score: A metric introduced within LLMMaps to quantify instances
    where the model provides inaccurate or unsupported responses.'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 虚假信息评分：LLMMaps中引入的一个指标，用于量化模型提供不准确或未经支持的响应的实例。
- en: •
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Knowledge Stratification Strategy: A top-down approach for creating a hierarchical
    knowledge structure within Q&A datasets, enabling nuanced analysis and interpretation.'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 知识分层策略：一种自上而下的方法，用于在问答数据集中创建层级知识结构，实现细致的分析和解释。
- en: •
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Utilization of Machine Learning Models for Hierarchy Generation: Employing
    LLMs to generate and categorize each question into the most fitting subfield,
    based on overarching topics derived from the dataset.'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用机器学习模型进行层级生成：运用LLMs将每个问题生成并分类到最适合的子领域，基于从数据集中得出的总体主题。
- en: •
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Sensitivity Analysis: This involves altering inputs slightly and observing
    the changes in the model’s output. For LLMs, sensitivity analysis can reveal how
    changes in word choice or sentence structure affect the generated text, highlighting
    the model’s responsiveness to specific linguistic features.'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 敏感性分析：这涉及轻微改变输入并观察模型输出的变化。对于LLMs，敏感性分析可以揭示单词选择或句子结构的变化如何影响生成的文本，突显模型对特定语言特征的响应能力。
- en: •
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Feature Importance Methods: These methods identify which parts of the input
    data are most influential in determining the model’s output. In the context of
    LLMs, feature importance can show which words or phrases in a sentence contribute
    most significantly to the model’s predictions or decisions.'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 特征重要性方法：这些方法识别哪些输入数据的部分在决定模型输出时最具影响力。在LLMs的背景下，特征重要性可以展示句子中的哪些单词或短语对模型的预测或决策贡献最大。
- en: •
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Shapley Values: Originating from cooperative game theory, Shapley values provide
    a way to distribute a ”payout” (i.e., the output prediction) among the ”players”
    (i.e., input features) based on their contribution. Applying Shapley values to
    LLMs can quantify the contribution of each word or token to the model’s output,
    offering a fair and robust measure of feature importance.'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Shapley值：源于合作博弈论，Shapley值提供了一种将“奖金”（即输出预测）在“玩家”（即输入特征）之间分配的方法，基于它们的贡献。将Shapley值应用于LLMs可以量化每个单词或标记对模型输出的贡献，提供对特征重要性的公平且稳健的度量。
- en: •
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Attention Visualization: Many LLMs, especially those based on the Transformer
    architecture, use attention mechanisms to weigh the importance of different parts
    of the input data. Visualizing these attention weights can illustrate how the
    model focuses on specific parts of the input text when generating responses, revealing
    patterns in how it processes information.'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力可视化：许多LLMs，特别是基于Transformer架构的LLMs，使用注意力机制来权衡输入数据的不同部分的重要性。可视化这些注意力权重可以展示模型在生成响应时如何关注输入文本的特定部分，揭示其处理信息的模式。
- en: •
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Counterfactual Explanations: This involves modifying parts of the input data
    to see how these changes alter the model’s output, essentially asking ”what if”
    questions. For LLMs, counterfactual explanations can help understand the conditions
    under which the model’s decisions or predictions change, shedding light on its
    reasoning process.'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 反事实解释：这涉及修改输入数据的部分，以查看这些变化如何改变模型的输出，实质上是在问“如果”问题。对于LLMs，反事实解释可以帮助理解模型决策或预测变化的条件，揭示其推理过程。
- en: •
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Language-Based Explanations: These are natural language explanations generated
    by the model itself or another model to explain the reasoning behind a given output.
    In LLMs, generating language-based explanations can make the model’s decision-making
    process more accessible and interpretable to humans.'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于语言的解释：这些是由模型本身或其他模型生成的自然语言解释，用于解释给定输出背后的推理过程。在LLMs中，生成基于语言的解释可以使模型的决策过程对人类更易于理解和解释。
- en: •
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Embedding Space Analysis: This technique explores the vector representations
    (embeddings) of words or phrases used by the model to understand semantic and
    syntactic relationships. Analyzing the embedding space of LLMs can reveal how
    the model organizes and relates concepts, offering insights into its understanding
    of language.'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 嵌入空间分析：这一技术探索模型使用的单词或短语的向量表示（嵌入），以理解语义和句法关系。分析LLMs的嵌入空间可以揭示模型如何组织和关联概念，提供对其语言理解的见解。
- en: •
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Computational Efficiency and Resource Utilization: Peak Memory Consumption,
    Memory Bandwidth Utilization, CPU/GPU Utilization Percentage, FLOPS (Floating
    Point Operations Per Second), Inference Time, Number of Parameters, Model Storage
    Size, Compression Ratio, Watts per Inference/Training Hour, Parallelization Efficiency,
    Batch Processing Capability.'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 计算效率和资源利用：峰值内存消耗、内存带宽利用、CPU/GPU 利用率、FLOPS（每秒浮点运算次数）、推理时间、参数数量、模型存储大小、压缩比、每次推理/训练小时的瓦特数、并行化效率、批处理能力。
- en: •
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Human Evaluation: Involves human judges assessing the quality, relevance, or
    coherence of model-generated text.'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 人工评估：涉及人工评审员评估模型生成文本的质量、相关性或连贯性。
- en: 4 Perplexity Measurement
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 困惑度测量
- en: Perplexity Measurement serves as a fundamental metric in the evaluation of Language
    Models (LMs), including Large Language Models (LLMs), by quantifying their fluency
    and predictive capabilities. Sundareswara (2008) highlights its importance in
    assessing model fluency, emphasizing its role in measuring how effectively a model
    can predict a sequence of words. The methodology for perplexity estimation has
    seen various innovations; notably, Bimbot (1997, 2001) introduced a novel scheme
    based on a gambling approach and entropy bounds, offering an alternative perspective
    that enriches the metric’s applicability. This approach was further validated
    through comparative evaluations, underscoring its relevance. Additionally, Golland
    (2003) proposed the use of permutation tests for estimating statistical significance
    in discriminative analysis, suggesting a potential avenue for applying statistical
    rigor to the evaluation of language models, including their perplexity assessments.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 困惑度测量作为评估语言模型（LMs），包括大型语言模型（LLMs）的基本指标，通过量化它们的流畅性和预测能力来服务。Sundareswara（2008）强调了其在评估模型流畅性方面的重要性，强调了它在衡量模型预测单词序列的有效性方面的作用。困惑度估计的方法论经历了各种创新；特别是，Bimbot（1997，2001）引入了一种基于赌博方法和熵界限的新方案，提供了一种丰富指标适用性的替代视角。这一方法通过比较评估进一步得到了验证，突显了其相关性。此外，Golland（2003）建议使用排列测试来估计区分分析中的统计显著性，提出了一种将统计严谨性应用于语言模型评估，包括其困惑度评估的潜在途径。
- en: While perplexity is invaluable for gauging a model’s fluency, it is not without
    its limitations. Its primary focus on the probabilistic prediction of words means
    that it does not directly measure semantic accuracy or coherence, areas that are
    crucial for the comprehensive evaluation of LMs, especially in complex applications.
    This metric, deeply rooted in information theory, remains a critical tool for
    understanding how well a probability model or distribution can anticipate a sample,
    providing essential insights into the model’s understanding of language.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然困惑度在衡量模型流畅性方面是非常宝贵的，但它也有其局限性。它主要关注于对单词的概率预测，这意味着它并不能直接衡量语义准确性或连贯性，这些都是对语言模型进行全面评估时至关重要的领域。这个指标深深根植于信息理论，仍然是理解概率模型或分布如何预测样本的关键工具，为模型对语言的理解提供了重要见解。
- en: 4.1 Understanding Perplexity
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 理解困惑度
- en: Perplexity is calculated as the exponentiated average negative log-likelihood
    of a sequence of words, given a language model. A lower perplexity score indicates
    a better performing model, as it suggests the model is more confident (assigns
    higher probability) in its predictions. Conversely, a higher perplexity score
    suggests the model is less certain about its predictions, equating to less fluency.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 困惑度是通过对给定语言模型的单词序列的平均负对数似然进行指数化计算得出的。较低的困惑度得分表明模型表现更好，因为这表明模型在其预测中更有信心（分配更高的概率）。相反，较高的困惑度得分表明模型对其预测的不确定性较高，即流畅性较差。
- en: 4.2 Application in Evaluating LLMs
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 大型语言模型的应用评估
- en: •
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Model Comparison: Perplexity allows researchers and developers to compare the
    performance of different LLMs on the same test datasets. It helps in determining
    which model has a better understanding of language syntax and structure, thereby
    predicting sequences more accurately.'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型比较：困惑度允许研究人员和开发者在相同的测试数据集上比较不同大型语言模型的性能。它有助于确定哪个模型对语言的语法和结构有更好的理解，从而更准确地预测序列。
- en: •
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Training Diagnostics: During the training phase, perplexity is used as a diagnostic
    tool to monitor the model’s learning progress. A decreasing perplexity trend over
    training epochs indicates that the model is improving in predicting the training
    data.'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 训练诊断：在训练阶段，困惑度被用作诊断工具来监控模型的学习进展。训练周期中困惑度趋势的下降表明模型在预测训练数据方面有所改善。
- en: •
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Model Tuning: Perplexity can guide the hyperparameter tuning process by indicating
    how changes in model architecture or training parameters affect model fluency.
    For instance, adjusting the size of the model, learning rate, or the number of
    layers can have a significant impact on perplexity, helping developers optimize
    their models.'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型调优：困惑度可以通过指示模型架构或训练参数的变化如何影响模型流畅性，来指导超参数调优过程。例如，调整模型的大小、学习率或层数可以显著影响困惑度，从而帮助开发者优化他们的模型。
- en: •
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Domain Adaptation: In scenarios where LLMs are adapted for specific domains
    (e.g., legal, medical, or technical fields), perplexity can help evaluate how
    well the adapted model performs in the new domain. A lower perplexity in the target
    domain indicates successful adaptation.'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 域适应：在语言模型（LLMs）适应于特定领域（例如法律、医学或技术领域）的场景中，困惑度可以帮助评估适应后的模型在新领域的表现。目标领域中的较低困惑度表明适应成功。
- en: •
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Language Coverage: Perplexity can also shed light on the model’s coverage and
    understanding of various languages, especially for multilingual models. It helps
    in identifying languages that the model performs well in and those that may require
    further data or tuning for improvement.'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 语言覆盖：困惑度还可以揭示模型对各种语言的覆盖和理解，特别是对于多语言模型。它有助于识别模型表现良好的语言以及那些可能需要更多数据或调优以改进的语言。
- en: 4.3 Limitations
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 局限性
- en: 'While perplexity is a valuable metric, it’s not without limitations. It primarily
    focuses on the probabilistic prediction of words without directly measuring semantic
    accuracy or coherence. Therefore, it’s often used in conjunction with other evaluation
    metrics (like those mentioned earlier: BLEU, ROUGE, etc.) that can assess semantic
    similarity and relevance to provide a more holistic evaluation of LLMs.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管困惑度是一个有价值的指标，但它也有局限性。它主要关注单词的概率预测，而不直接测量语义准确性或连贯性。因此，它通常与其他评估指标（如前面提到的：BLEU、ROUGE
    等）结合使用，这些指标可以评估语义相似性和相关性，从而提供对语言模型的更全面评估。
- en: In summary, perplexity is a foundational metric in NLP for evaluating the fluency
    and predictive accuracy of language models, playing a critical role in the development
    and refinement of LLMs.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，困惑度是自然语言处理（NLP）中用于评估语言模型流畅性和预测准确性的基础指标，在语言模型的开发和优化中发挥着重要作用。
- en: 5 Natural Language Processing (NLP) Evaluation Metrics
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 自然语言处理（NLP）评估指标
- en: A range of NLP evaluation metrics, including BLEU, ROUGE, METEOR, BERTScore,
    GLEU, WER, and CER, are used to assess LLMs in various tasks (Blagec, 2022). However,
    these metrics have been found to have low correlation with human judgment and
    lack transferability to other tasks and languages. This raises concerns about
    the adequacy of these metrics in reflecting model performance (Blagec, 2022).
    Despite these limitations, LLMs have shown promise in radiology NLP, with some
    models demonstrating strengths in interpreting radiology reports (Liu, 2023).
    However, in domain-specific applications, such as Wikipedia-style survey generation,
    LLMs have exhibited shortcomings, including incomplete information and factual
    inaccuracies (Gao, 2023). Similarly, in medical evidence summarization, LLMs have
    been found to struggle with identifying salient information and generating factually
    inconsistent summaries (Tang, 2023). These studies highlight the need for more
    robust evaluation metrics and the importance of considering the limitations of
    existing ones.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 一系列自然语言处理（NLP）评估指标，包括 BLEU、ROUGE、METEOR、BERTScore、GLEU、WER 和 CER，用于评估语言模型在各种任务中的表现（Blagec,
    2022）。然而，这些指标与人类判断的相关性较低，并且在其他任务和语言上的转移性不足。这引发了对这些指标在反映模型性能方面 adequacy 的担忧（Blagec,
    2022）。尽管存在这些局限性，语言模型在放射学 NLP 中展现出一定的前景，一些模型在解释放射学报告方面表现出优势（Liu, 2023）。然而，在领域特定应用中，如维基百科风格的调查生成，语言模型表现出不足，包括信息不完整和事实不准确（Gao,
    2023）。同样，在医学证据总结中，语言模型在识别重要信息和生成事实不一致的总结方面也存在困难（Tang, 2023）。这些研究突显了对更强健评估指标的需求，并且强调了考虑现有指标局限性的重要性。
- en: 5.1 BLEU (Bilingual Evaluation Understudy)
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 BLEU（双语评估指标）
- en: 'Use: Primarily for machine translation quality assessment.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 使用：主要用于机器翻译质量评估。
- en: 'How It Works: Compares machine-generated translations to one or more reference
    translations, focusing on the precision of n-grams (contiguous sequences of n
    items from a given sample of text).'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 工作原理：将机器生成的翻译与一个或多个参考翻译进行比较，重点关注n-gram（从给定文本样本中提取的连续n项序列）的精度。
- en: 'Strengths: Simple, widely used, correlates well with human judgment at the
    corpus level.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 优点：简单、广泛使用，在语料库级别与人类判断的相关性较好。
- en: 'Limitations: Lacks sensitivity to meaning preservation, grammatical correctness,
    and does not consider recall.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 局限性：缺乏对意义保留、语法正确性的敏感性，并且不考虑召回率。
- en: 5.2 ROUGE (Recall-Oriented Understudy for Gisting Evaluation)
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 ROUGE（面向召回的摘要评估指标）
- en: 'Use: Evaluates summarization quality, including both extractive and abstractive
    methods.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 用途：评估摘要质量，包括提取式和抽象式方法。
- en: 'How It Works: Measures the overlap of n-grams, word sequences, and word pairs
    between the generated summaries and reference summaries, emphasizing recall.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 工作原理：测量生成的摘要与参考摘要之间的n-gram、词序列和词对的重叠，强调召回率。
- en: 'Strengths: Captures content selection effectiveness, supports multiple reference
    summaries.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 优点：捕捉内容选择的有效性，支持多个参考摘要。
- en: 'Limitations: May not fully represent the quality of summaries (e.g., coherence,
    readability).'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 局限性：可能无法完全代表摘要的质量（例如，连贯性、可读性）。
- en: 5.3 METEOR (Metric for Evaluation of Translation with Explicit ORdering)
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 METEOR（具有显式排序的翻译评估指标）
- en: 'Use: Another metric for translation assessment that extends beyond BLEU’s capabilities.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 用途：另一种翻译评估指标，扩展了BLEU的能力。
- en: 'How It Works: Aligns generated text to reference texts considering exact matches,
    synonyms, stemming, and paraphrasing, with penalties for incorrect word order.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 工作原理：将生成的文本与参考文本对齐，考虑精确匹配、同义词、词干提取和释义，并对错误的词序进行惩罚。
- en: 'Strengths: Better correlation with human judgment on sentence-level evaluation,
    compensates for some of BLEU’s shortcomings.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 优点：在句子级别评估中与人类判断的相关性更好，弥补了BLEU的一些不足。
- en: 'Limitations: More complex computation, potential for overfitting specific test
    sets.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 局限性：计算更复杂，可能会对特定测试集过拟合。
- en: 5.4 BERTScore
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 BERTScore
- en: 'Use: Evaluates semantic similarity between generated text and reference text.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 用途：评估生成文本与参考文本之间的语义相似性。
- en: 'How It Works: Utilizes contextual embeddings from models like BERT to compute
    similarity scores between words in generated and reference texts, aggregating
    these scores for an overall measurement.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 工作原理：利用像BERT这样的模型中的上下文嵌入来计算生成文本和参考文本中单词之间的相似性分数，并将这些分数汇总为总体测量。
- en: 'Strengths: Captures deeper semantic meanings not evident in surface-level matches;
    robust to paraphrasing.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 优点：捕捉到表面匹配中不明显的更深层次的语义意义；对释义具有较强的鲁棒性。
- en: 'Limitations: Computationally intensive, interpretation of scores can be less
    intuitive.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 局限性：计算量大，得分的解释可能不够直观。
- en: 5.5 GLEU (Google BLEU)
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5 GLEU（Google BLEU）
- en: 'Use: Tailored for evaluating shorter texts, such as those in machine translation
    and language understanding tasks.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 用途：针对较短文本的评估，如机器翻译和语言理解任务中的文本。
- en: 'How It Works: Similar to BLEU but adapted to work better on shorter sentences,
    often used internally by Google.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 工作原理：类似于BLEU，但适用于较短的句子，谷歌内部经常使用。
- en: 'Strengths: More sensitive to errors in short texts.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 优点：对短文本中的错误更为敏感。
- en: 'Limitations: Like BLEU, may not fully account for semantic accuracy.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 局限性：与BLEU类似，可能无法完全考虑语义准确性。
- en: 5.6 Word Error Rate (WER)
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.6 词错误率（WER）
- en: 'Use: Commonly used in speech recognition to evaluate the accuracy of transcribed
    text.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 用途：在语音识别中常用来评估转录文本的准确性。
- en: 'How It Works: Compares the transcribed text with a reference text, calculating
    the proportion of errors (substitutions, deletions, insertions).'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 工作原理：将转录文本与参考文本进行比较，计算错误（替换、删除、插入）的比例。
- en: 'Strengths: Straightforward, intuitive metric for transcription accuracy.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 优点：直观、简单的转录准确性指标。
- en: 'Limitations: Does not account for semantic meaning or grammatical correctness.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 局限性：不考虑语义意义或语法正确性。
- en: 5.7 Character Error Rate (CER)
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.7 字符错误率（CER）
- en: 'Use: Similar to WER but evaluates transcription accuracy at the character level.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 用途：类似于WER，但在字符级别评估转录准确性。
- en: 'How It Works: Measures the minimum number of character insertions, deletions,
    and substitutions required to change the transcribed text into the reference text.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 工作原理：测量将转录文本更改为参考文本所需的最小字符插入、删除和替换次数。
- en: 'Strengths: Useful for languages where character-level evaluation is more indicative
    of transcription quality.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 优势：对字符级评估更能反映转录质量的语言特别有用。
- en: 'Limitations: Like WER, focuses on surface errors without accounting for semantic
    content.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 局限性：类似于WER，关注表面错误而不考虑语义内容。
- en: 5.8 Application in LLM Evaluation
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8 LLM评估中的应用
- en: In evaluating LLMs, these metrics are often used together to provide a multifaceted
    view of model performance across various tasks. For instance, while BLEU and METEOR
    might be used to evaluate translation models, ROUGE could be applied to summarization
    tasks, and BERTScore for tasks requiring semantic evaluation. WER and CER are
    particularly relevant for voice-driven applications where speech-to-text accuracy
    is critical.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估LLMs时，这些指标通常一起使用，以提供对模型在各种任务中表现的多方面视图。例如，虽然BLEU和METEOR可能用于评估翻译模型，但ROUGE可以应用于摘要任务，而BERTScore则用于需要语义评估的任务。WER和CER对于语音驱动的应用特别相关，其中语音转文本的准确性至关重要。
- en: 5.9 Challenges and Considerations
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.9 挑战与考虑因素
- en: No single metric can capture all aspects of language model performance. It’s
    crucial to select metrics that align with the specific goals of the task at hand.
    Moreover, the interpretation of these metrics should consider their limitations
    and the context of their application. For comprehensive evaluation, combining
    these metrics with qualitative analysis and human judgment often yields the most
    insightful assessments of LLM capabilities.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 没有单一的度量指标能够捕捉语言模型性能的所有方面。选择与具体任务目标相符的度量指标至关重要。此外，这些指标的解释应考虑其局限性和应用背景。为了进行全面评估，将这些指标与定性分析和人工判断相结合，通常能提供对LLM能力最具洞察力的评估。
- en: 6 Zero-Shot Learning Performance
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 零样本学习性能
- en: Recent studies have shown that large language models (LLMs) like GPT-3 can achieve
    strong zero-shot learning performance, even without task-specific fine-tuning
    datasets (Brown, 2020). This is further supported by the work of Meng (2022),
    who demonstrated the potential of using both unidirectional and bidirectional
    PLMs for zero-shot learning of natural language understanding tasks. Puri (2019)
    also highlighted the use of natural language descriptions for zero-shot model
    adaptation, achieving significant improvements in classification accuracy. These
    findings collectively underscore the impressive zero-shot learning capabilities
    of LLMs, which are crucial for their generalization and adaptability to a wide
    range of tasks.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究表明，像GPT-3这样的巨大语言模型（LLMs）即使没有特定任务的微调数据集，也能取得强大的零样本学习表现（Brown, 2020）。Meng（2022）的研究进一步支持了使用单向和双向PLMs进行自然语言理解任务的零样本学习的潜力。Puri（2019）也强调了使用自然语言描述进行零样本模型适配，取得了分类准确性的显著提升。这些发现共同突显了LLMs令人印象深刻的零样本学习能力，这对于它们在广泛任务中的泛化和适应性至关重要。
- en: 6.1 Understanding Zero-Shot Learning Performance
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 理解零样本学习性能
- en: 'Concept: Zero-shot learning involves evaluating the model’s performance on
    tasks it has not seen during its training phase. It relies on the model’s pre-existing
    knowledge and its ability to generalize from that knowledge to new, unseen tasks.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 概念：零样本学习涉及评估模型在训练阶段未见过的任务上的表现。它依赖于模型的预先知识以及从这些知识中泛化到新的、未见过的任务的能力。
- en: 'Evaluation: This is done by presenting the model with a task description or
    a prompt that specifies a task, along with inputs that the model has not been
    explicitly prepared for. The model’s output is then assessed for accuracy, relevance,
    or appropriateness, depending on the task.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 评估：通过向模型提供任务描述或指定任务的提示，以及模型未被明确准备的输入来完成评估。然后根据任务，评估模型的输出是否准确、相关或恰当。
- en: 6.2 Application in Evaluating LLMs
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 评估LLM的应用
- en: •
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Task Understanding: Zero-shot learning performance evaluates an LLM’s ability
    to understand the instructions or the task presented in natural language. This
    demonstrates the model’s grasp of language nuances and its ability to infer the
    required actions without prior examples.'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 任务理解：零样本学习性能评估LLM理解自然语言指令或任务的能力。这展示了模型对语言细微差别的掌握以及在没有先前示例的情况下推断所需操作的能力。
- en: •
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Generalization Capabilities: It highlights the model’s ability to apply its
    learned knowledge to new and diverse tasks. A high performance in zero-shot learning
    indicates strong generalization capabilities, a key feature for practical applications
    of LLMs across various domains.'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 泛化能力：它突显了模型将所学知识应用于新任务和多样任务的能力。在零样本学习中表现出色表明强大的泛化能力，这是LLM在各个领域的实际应用中的关键特性。
- en: •
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Flexibility and Adaptability: By assessing how well an LLM performs in a zero-shot
    setting, we can gauge its flexibility and adaptability to a broad spectrum of
    tasks. This is particularly valuable in real-world scenarios where it’s impractical
    to fine-tune models for every possible task.'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 灵活性和适应性：通过评估LLM在零样本环境中的表现，我们可以衡量其对广泛任务的灵活性和适应性。这在现实世界的场景中尤其重要，因为在每个可能的任务上微调模型是不切实际的。
- en: •
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Semantic Understanding and Reasoning: Zero-shot learning performance also sheds
    light on the model’s semantic understanding and reasoning abilities. It tests
    whether the model can comprehend complex instructions and generate coherent, contextually
    appropriate responses.'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 语义理解和推理：零样本学习表现还揭示了模型的语义理解和推理能力。它测试模型是否能理解复杂的指令并生成连贯的、语境适当的响应。
- en: 6.3 Challenges and Considerations
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3 挑战与考虑事项
- en: •
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Variability in Performance: Zero-shot learning performance can vary significantly
    across different tasks and domains. Some tasks may inherently align more closely
    with the model’s training data, leading to better performance, while others may
    pose greater challenges.'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 性能的变异性：零样本学习表现可能在不同任务和领域之间显著变化。一些任务可能本质上更符合模型的训练数据，从而导致更好的表现，而其他任务可能面临更大的挑战。
- en: •
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Evaluation Criteria: Establishing clear, objective criteria for evaluating
    zero-shot learning performance can be challenging, especially for subjective or
    open-ended tasks. It often requires carefully designed prompts and a nuanced understanding
    of expected outcomes.'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 评估标准：建立明确、客观的零样本学习表现评估标准可能具有挑战性，特别是对于主观或开放性任务。这通常需要精心设计的提示和对预期结果的细致理解。
- en: •
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Comparison with Few-Shot and Fine-Tuned Models: Zero-shot learning performance
    is often compared against few-shot learning (where the model is given a few examples
    of the task) and fully fine-tuned models. This comparison helps in understanding
    the trade-offs between generalization and task-specific optimization.'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与少样本和微调模型的比较：零样本学习表现通常与少样本学习（即模型获得少量任务示例）和完全微调模型进行比较。这种比较有助于理解泛化与任务特定优化之间的权衡。
- en: In summary, zero-shot learning performance is a vital metric for evaluating
    the sophistication and applicability of LLMs. It not only underscores the models’
    ability to generalize across tasks without specific training but also highlights
    their potential for wide-ranging applications, from natural language understanding
    and generation to complex problem-solving across disciplines.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，零样本学习表现是评估大语言模型（LLMs）复杂性和适用性的关键指标。它不仅强调了模型在没有特定训练的情况下跨任务泛化的能力，还突显了它们在从自然语言理解和生成到跨学科复杂问题解决等广泛应用中的潜力。
- en: 7 Few-Shot Learning Performance
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 少样本学习表现
- en: Few-Shot Learning Performance is a pivotal metric for evaluating the adaptability
    and efficiency of Large Language Models (LLMs), such as those in the GPT series,
    by measuring their ability to learn and perform tasks from a minimal set of examples.
    This metric underscores the models’ capacity to quickly generalize from limited
    data, a crucial attribute in scenarios with sparse training resources or when
    models need to adapt to new domains swiftly.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 少样本学习表现是评估大型语言模型（如GPT系列）适应性和效率的关键指标，通过测量它们从少量示例中学习和执行任务的能力。该指标突显了模型从有限数据中快速泛化的能力，这在训练资源稀缺或模型需要迅速适应新领域的场景中尤为重要。
- en: Peng (2020) introduces FewshotWOZ, a benchmark specifically designed for assessing
    NLG systems in task-oriented dialog contexts, showcasing the SC-GPT model’s significant
    superiority over existing methods. Cheng (2019) explores a meta metric learning
    approach tailored for unbalanced classes and diverse multi-domain tasks, achieving
    exemplary performance in both standard and realistic few-shot learning environments.
    Simon (2020) discusses a dynamic classifier-based framework for few-shot learning,
    noting its robustness to perturbations and competitive edge in both supervised
    and semi-supervised few-shot classification scenarios. Additionally, Tang (2020)
    presents DPSN, an interpretable neural framework for few-shot time-series classification,
    which notably surpasses contemporary methods, especially in data-limited situations.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 彭（2020）介绍了FewshotWOZ，这是一个专门用于评估面向任务对话上下文中的自然语言生成（NLG）系统的基准，展示了SC-GPT模型在现有方法中的显著优势。程（2019）探索了一种针对不平衡类别和多领域任务的元度量学习方法，在标准和现实的少样本学习环境中都取得了出色的表现。西蒙（2020）讨论了一种基于动态分类器的少样本学习框架，指出其在扰动下的鲁棒性和在有监督和半监督少样本分类场景中的竞争优势。此外，唐（2020）提出了DPSN，一个可解释的少样本时间序列分类神经框架，显著超越了当代方法，特别是在数据有限的情况下。
- en: These contributions collectively highlight the importance and applicability
    of Few-Shot Learning Performance as a measure for LLMs, emphasizing the ongoing
    innovations and methodologies enhancing model performance under constrained learning
    conditions.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 这些贡献共同突显了少样本学习表现作为衡量大型语言模型（LLMs）的重要性和适用性，强调了在有限学习条件下提升模型性能的持续创新和方法。
- en: 7.1 Understanding Few-Shot Learning Performance
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1 理解少样本学习表现
- en: 'Concept: Few-shot learning involves evaluating the model’s ability to leverage
    a small number of examples to perform a task. These examples are provided to the
    model at inference time, typically as part of the prompt, instructing the model
    on the task requirements and demonstrating the desired output format or content.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 概念：少样本学习涉及评估模型利用少量示例来执行任务的能力。这些示例在推理时提供给模型，通常作为提示的一部分，指导模型任务要求，并展示所需的输出格式或内容。
- en: 'Evaluation: The model’s outputs are then compared against reference outputs
    or evaluated based on accuracy, relevance, and quality, depending on the specific
    task. The key is that the model uses these few examples to understand and generalize
    the task requirements to new, unseen instances.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 评估：模型的输出将与参考输出进行比较，或根据准确性、相关性和质量进行评估，具体取决于任务。关键在于模型使用这些少量示例来理解并概括任务要求，以便对新出现的实例进行处理。
- en: 7.2 Application in Evaluating LLMs
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2 评估LLMs的应用
- en: •
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Rapid Adaptation: Few-shot learning performance showcases an LLM’s ability
    to rapidly adapt to new tasks or domains with very little data. This is crucial
    for practical applications where generating or collecting large datasets for every
    possible task is impractical or impossible.'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 快速适应：少样本学习表现展示了LLM在仅有少量数据的情况下快速适应新任务或领域的能力。这对于实际应用至关重要，因为为每个可能的任务生成或收集大规模数据集是不切实际或不可能的。
- en: •
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Data Efficiency: This metric highlights a model’s data efficiency, an important
    factor in scenarios where data is scarce, expensive to obtain, or when privacy
    concerns limit the availability of data.'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据效率：这一指标突出了模型的数据效率，这是在数据稀缺、获取成本高或隐私问题限制数据可用性时的重要因素。
- en: •
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Generalization from Minimal Cues: Few-shot learning evaluates how well a model
    can generalize from minimal cues. It tests the model’s understanding of language
    and task structures, requiring it to apply its pre-existing knowledge in novel
    ways based on a few examples.'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从最小线索中泛化：少样本学习评估模型从最小线索中泛化的能力。它测试模型对语言和任务结构的理解，要求模型根据少量示例以新的方式应用其现有知识。
- en: •
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Versatility and Flexibility: High few-shot learning performance indicates a
    model’s versatility and flexibility, essential traits for deploying LLMs across
    a wide range of tasks and domains without needing extensive task-specific data
    or fine-tuning.'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 多样性和灵活性：高少样本学习表现表明模型的多样性和灵活性，这是在无需大量任务特定数据或微调的情况下在广泛任务和领域中部署LLMs的关键特征。
- en: 7.3 Challenges and Considerations
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3 挑战与考虑
- en: •
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Consistency Across Tasks: Few-shot learning performance can vary widely across
    different tasks and domains. Some tasks might naturally align with the model’s
    pre-trained knowledge, leading to better performance, while others might be more
    challenging, requiring careful prompt design to achieve good results.'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 任务间一致性：少量学习性能在不同任务和领域之间可能差异很大。一些任务可能自然与模型的预训练知识对接，从而导致更好的表现，而其他任务可能更具挑战性，需要精心设计提示才能取得良好结果。
- en: •
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Quality of Examples: The quality and representativeness of the few-shot examples
    significantly impact performance. Poorly chosen examples can lead to incorrect
    generalizations, highlighting the importance of example selection.'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 示例质量：少量示例的质量和代表性对性能有显著影响。选择不当的示例可能导致错误的泛化，这突显了示例选择的重要性。
- en: •
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Comparison with Zero-Shot and Fine-Tuned Models: Few-shot learning performance
    is often compared to zero-shot learning (where the model receives no task-specific
    examples) and fully fine-tuned models. This comparison helps in understanding
    the balance between adaptability and the need for task-specific optimization.'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与零样本和微调模型的比较：少量学习性能通常与零样本学习（模型未接收到任务特定的示例）和完全微调模型进行比较。这种比较有助于理解适应性与任务特定优化需求之间的平衡。
- en: •
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Prompt Engineering: The effectiveness of few-shot learning can heavily depend
    on the skill of prompt engineering—the process of designing the prompt and examples
    given to the model. This skill can vary significantly among practitioners, potentially
    affecting the reproducibility and fairness of evaluations.'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提示工程：少量学习的有效性可能严重依赖于提示工程的技能——即设计给模型的提示和示例的过程。这种技能在实践者之间可能差异显著，可能影响评估的可重复性和公平性。
- en: In summary, few-shot learning performance is a critical metric for evaluating
    the adaptability, data efficiency, and generalization capabilities of LLMs. It
    reflects the practical utility of these models in real-world scenarios, where
    the ability to perform well with limited examples is a valuable asset.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，少量学习性能是评估LLMs适应性、数据效率和泛化能力的关键指标。它反映了这些模型在现实场景中的实际效用，其中有限示例下的良好表现是一项宝贵资产。
- en: 8 Transfer Learning Evaluation
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 迁移学习评估
- en: Transfer Learning Evaluation is a key method for gauging the adaptability and
    efficiency of Large Language Models (LLMs) like those in the GPT series and BERT.
    This approach assesses an LLM’s proficiency in applying pre-learned knowledge
    to new, related tasks without substantial additional training, highlighting the
    model’s capability to generalize beyond its initial training parameters. Hajian
    (2019) underscores the significance of this evaluation, emphasizing its role in
    measuring a model’s flexibility in applying acquired knowledge across different
    contexts. This method aligns with the broader educational strategies of coaching,
    scaffolding, and reflection in situated learning environments, further supported
    by Hajian (2019).
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习评估是衡量大型语言模型（LLMs）如GPT系列和BERT适应性和效率的关键方法。该方法评估LLM在无需大量额外训练的情况下，将预先学习的知识应用于新相关任务的能力，突显了模型在超越初始训练参数方面的泛化能力。**Hajian**（2019）强调了这种评估的重要性，突出了其在测量模型在不同背景下应用获得知识的灵活性方面的作用。这种方法与教学环境中的辅导、支架和反思的广泛教育策略相一致，进一步得到了**Hajian**（2019）的支持。
- en: Furthermore, the evaluation extends to learning management systems (LMS) in
    e-learning, where factors like instruction management and screen design play critical
    roles (Kim, 2008). The principle of transfer of training, important for training
    policy and enhancing transferability, is also relevant here (Annett, 1985). Recently,
    the Log Expected Empirical Prediction (LEEP) metric was introduced by Nguyen (2020)
    as a novel measure to evaluate the transferability of learned representations,
    showing potential in predicting model performance and convergence speed across
    tasks.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，评估还扩展到电子学习中的学习管理系统（LMS），其中指令管理和屏幕设计等因素起着关键作用（**Kim**，2008）。培训转移原则对培训政策和提高转移性也很重要（**Annett**，1985）。最近，**Nguyen**（2020）引入了**Log
    Expected Empirical Prediction**（LEEP）度量作为一种新颖的衡量学习表征转移性的指标，展示了预测模型性能和任务收敛速度的潜力。
- en: This comprehensive perspective on Transfer Learning Evaluation illustrates its
    essential role in understanding and enhancing the utility of LLMs for a wide array
    of applications, from personalized learning environments to the efficient adaptation
    of models to new domains.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 对迁移学习评估的这种全面视角阐明了其在理解和提升LLM在广泛应用中的效用的核心作用，从个性化学习环境到模型高效适应新领域。
- en: 8.1 Understanding Transfer Learning Evaluation
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1 理解迁移学习评估
- en: 'Concept: Transfer learning involves a model applying its learned knowledge
    from one task (source task) to improve performance on a different but related
    task (target task). This process often requires minimal adjustments or fine-tuning
    to the model’s parameters with a small dataset specific to the target task.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 概念：迁移学习涉及一个模型将从一个任务（源任务）中学到的知识应用于不同但相关的任务（目标任务）以提高性能。这个过程通常需要对模型参数进行最少的调整或微调，并使用针对目标任务的小数据集。
- en: 'Evaluation: The model’s performance on the target task is measured, typically
    using task-specific metrics such as accuracy, F1 score, BLEU score for translation
    tasks, or ROUGE score for summarization tasks. The improvement in performance,
    as compared to the model’s baseline performance without transfer learning, highlights
    the effectiveness of the transfer learning process.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 评估：模型在目标任务上的表现被测量，通常使用任务特定的指标，如准确率、F1分数、翻译任务中的BLEU分数，或总结任务中的ROUGE分数。与没有迁移学习的模型基线性能相比，性能的改进突显了迁移学习过程的有效性。
- en: 8.2 Application in Evaluating LLMs
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2 在评估LLMs中的应用
- en: •
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Domain Adaptation: Transfer learning evaluation showcases an LLM’s ability
    to adapt to specific domains or industries, such as legal, medical, or financial
    sectors, by applying its general language understanding to domain-specific tasks.'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 域适应：迁移学习评估展示了大型语言模型（LLM）在特定领域或行业（如法律、医疗或金融领域）的适应能力，通过将其通用语言理解应用于领域特定任务。
- en: •
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Efficiency in Learning: This evaluation method highlights the model’s efficiency
    in learning new tasks. A model that performs well in transfer learning evaluations
    can achieve high levels of performance on new tasks with minimal additional data
    or fine-tuning, indicating efficient learning and adaptation capabilities.'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 学习效率：这种评估方法突出了模型在学习新任务方面的效率。在迁移学习评估中表现良好的模型可以在新任务上实现高水平的性能，且仅需少量额外数据或微调，表明其具有高效的学习和适应能力。
- en: •
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Model Generalization: Transfer learning evaluation tests the generalization
    ability of LLMs across tasks and domains. High performance in transfer learning
    indicates that the model has not only memorized the training data but has also
    developed a broader understanding of language and tasks that can be generalized
    to new challenges.'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型泛化：迁移学习评估测试了LLM在任务和领域之间的泛化能力。高性能的迁移学习表明，模型不仅记住了训练数据，还发展了更广泛的语言和任务理解能力，这可以推广到新的挑战中。
- en: •
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Resource Optimization: By demonstrating how well a model can adapt to new tasks
    with minimal intervention, transfer learning evaluation also points to the potential
    for resource optimization in terms of data, computational power, and time required
    for model training and adaptation.'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 资源优化：通过展示模型如何在最少干预的情况下适应新任务，迁移学习评估还指出了在数据、计算能力和模型训练与适应所需时间方面优化资源的潜力。
- en: 8.3 Challenges and Considerations
  id: totrans-203
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3 挑战与考虑因素
- en: •
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Selection of Source and Target Tasks: The choice of source and target tasks
    can significantly influence the evaluation outcome. Tasks that are too similar
    may not adequately test the transfer capabilities, while tasks that are too dissimilar
    may unfairly challenge the model’s ability to transfer knowledge.'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 源任务和目标任务的选择：源任务和目标任务的选择会显著影响评估结果。过于相似的任务可能无法充分测试迁移能力，而过于不同的任务可能会不公平地挑战模型的知识迁移能力。
- en: •
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Measurement of Improvement: Quantifying the improvement and attributing it
    specifically to the transfer learning process can be challenging. It requires
    careful baseline comparisons and might need to account for variations in task
    difficulty and data availability.'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 改进的测量：量化改进并将其特定归因于迁移学习过程可能具有挑战性。这需要仔细的基线比较，并可能需要考虑任务难度和数据可用性的变化。
- en: •
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Balancing Generalization and Specialization: Transfer learning evaluation must
    balance the model’s ability to generalize across tasks with its ability to specialize
    in specific tasks. Overemphasis on either aspect can lead to misleading conclusions
    about the model’s overall effectiveness.'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 平衡泛化与专业化：迁移学习评估必须平衡模型在各任务间的泛化能力与在特定任务中的专业化能力。过分强调其中一个方面可能会导致对模型整体效果的误导性结论。
- en: •
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Dependency on Fine-Tuning: The extent and method of fine-tuning for the target
    task can affect transfer learning performance. Over-fine-tuning may lead to overfitting
    on the target task, while under-fine-tuning may not fully leverage the model’s
    transfer capabilities.'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 依赖于微调：目标任务的微调程度和方法会影响迁移学习的表现。过度微调可能导致对目标任务的过拟合，而微调不足可能无法充分利用模型的迁移能力。
- en: In summary, Transfer Learning Evaluation is a comprehensive approach to assess
    the adaptability and efficiency of LLMs in applying their pre-learned knowledge
    to new and related tasks. It highlights the models’ potential for wide-ranging
    applications across various domains and tasks, demonstrating their practical utility
    and flexibility in real-world scenarios.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，迁移学习评估是一种全面的方法，用于评估 LLMs 将其预学习的知识应用于新的相关任务的适应性和效率。它突显了模型在各个领域和任务中广泛应用的潜力，展示了它们在实际场景中的实用性和灵活性。
- en: 9 Adversarial Testing
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9 对抗测试
- en: Adversarial testing, a method used to evaluate the robustness of large language
    models (LLMs) against inputs designed to confuse them, has been the focus of recent
    research. Wang (2021) introduced Adversarial GLUE, a benchmark for assessing LLM
    vulnerabilities, and found that existing attack methods often produce invalid
    or misleading examples. Dinakarrao (2018) explored the use of adversarial training
    to enhance the robustness of machine learning models, achieving up to 97.65% accuracy
    against attacks. Ford (2019) established a link between adversarial and corruption
    robustness in image classifiers, suggesting that improving one should enhance
    the other. Chen (2022) provided a comprehensive overview of adversarial robustness
    in deep learning models, covering attacks, defenses, verification, and applications.
    These studies collectively highlight the importance of adversarial testing in
    identifying and addressing vulnerabilities in LLMs and other machine learning
    models.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗测试是一种用于评估大型语言模型（LLMs）在面对旨在混淆它们的输入时的鲁棒性的方法，近年来成为研究的重点。Wang（2021）引入了对抗 GLUE，一个用于评估
    LLM 漏洞的基准，发现现有攻击方法常常产生无效或误导性的示例。Dinakarrao（2018）探索了对抗训练在增强机器学习模型鲁棒性方面的应用，取得了高达
    97.65% 的攻击准确率。Ford（2019）建立了图像分类器中对抗鲁棒性与腐蚀鲁棒性之间的联系，建议提高一种应改善另一种。Chen（2022）提供了深度学习模型中对抗鲁棒性的全面概述，包括攻击、防御、验证和应用。这些研究共同突显了对抗测试在识别和解决
    LLMs 和其他机器学习模型漏洞方面的重要性。
- en: 9.1 Understanding Adversarial Testing
  id: totrans-215
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1 理解对抗测试
- en: 'Concept: Adversarial testing involves creating or identifying inputs that are
    near-misses to valid inputs but are designed to cause the model to make mistakes.
    These inputs can exploit the model’s inherent biases, over-reliance on certain
    data patterns, or other weaknesses.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 概念：对抗测试涉及创建或识别接近有效输入的输入，但这些输入旨在使模型出错。这些输入可以利用模型固有的偏见、对某些数据模式的过度依赖或其他弱点。
- en: 'Evaluation: The performance of LLMs against adversarial inputs is measured,
    often focusing on the model’s error rates, the severity of mistakes, and the model’s
    ability to maintain coherence, relevance, and factual accuracy. The goal is to
    identify the model’s vulnerabilities and assess its resilience.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 评估：LLMs 在对抗输入下的表现被测量，通常关注模型的错误率、错误的严重性以及模型保持连贯性、相关性和事实准确性的能力。目标是识别模型的漏洞并评估其抗压能力。
- en: 9.2 Application in Evaluating LLMs
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2 在评估 LLMs 中的应用
- en: •
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Robustness Evaluation: Adversarial testing is key to evaluating the robustness
    of LLMs, highlighting how well the model can handle unexpected or challenging
    inputs without compromising the quality of its outputs.'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 鲁棒性评估：对抗测试是评估 LLMs 鲁棒性的关键，突显模型在处理意外或具有挑战性的输入时如何保持输出质量。
- en: •
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Security Assessment: By identifying vulnerabilities, adversarial testing can
    inform security measures needed to protect the model from potential misuse, such
    as generating misleading information, bypassing content filters, or exploiting
    the model in harmful ways.'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 安全评估：通过识别漏洞，对抗性测试可以为保护模型免受潜在滥用提供安全措施，如生成误导性信息、绕过内容过滤器或以有害方式利用模型。
- en: •
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Bias Detection: Adversarial inputs can reveal biases in LLMs, showing how the
    model might respond differently to variations in input that reflect gender, ethnicity,
    or other sensitive attributes, thereby guiding efforts to mitigate these biases.'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 偏见检测：对抗性输入可以揭示LLMs中的偏见，展示模型如何对反映性别、种族或其他敏感属性的输入变化做出不同反应，从而指导减少这些偏见的努力。
- en: •
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Improvement of Model Generalization: Identifying specific weaknesses through
    adversarial testing allows for targeted improvements to the model, enhancing its
    ability to generalize across a wider range of inputs and reducing overfitting
    to the training data.'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型泛化能力的改进：通过对抗性测试识别具体的弱点，允许对模型进行有针对性的改进，从而增强其在更广泛输入范围内的泛化能力，并减少对训练数据的过拟合。
- en: 9.3 Challenges and Considerations
  id: totrans-227
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3 挑战与考虑
- en: •
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Generation of Adversarial Inputs: Crafting effective adversarial inputs requires
    a deep understanding of the model’s architecture and training data, as well as
    creativity to identify potential vulnerabilities. This process can be both technically
    challenging and time-consuming.'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对抗性输入的生成：创建有效的对抗性输入需要对模型的架构和训练数据有深刻的理解，以及识别潜在漏洞的创造力。这个过程既具有技术挑战性，又耗时。
- en: •
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Measurement of Impact: Quantifying the impact of adversarial inputs on model
    performance can be complex, as it may vary widely depending on the nature of the
    task, the model’s architecture, and the specific vulnerabilities being tested.'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 影响的测量：量化对抗性输入对模型性能的影响可能非常复杂，因为这可能会因任务的性质、模型的架构和具体测试的漏洞而差异很大。
- en: •
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Balance Between Robustness and Performance: Enhancing a model’s robustness
    to adversarial inputs can sometimes lead to trade-offs with its overall performance
    on standard inputs. Finding the right balance is crucial for maintaining the model’s
    effectiveness and usability.'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 鲁棒性与性能之间的平衡：增强模型对对抗性输入的鲁棒性有时可能会与其在标准输入上的整体性能产生权衡。找到正确的平衡对于保持模型的有效性和可用性至关重要。
- en: •
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Ethical Considerations: The use of adversarial testing must be guided by ethical
    considerations, ensuring that the insights gained are used to improve model safety
    and reliability, rather than for malicious purposes.'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 伦理考虑：对抗性测试的使用必须遵循伦理考虑，确保获得的洞察用于改善模型的安全性和可靠性，而不是用于恶意目的。
- en: In summary, Adversarial Testing is an indispensable tool for evaluating and
    enhancing the robustness, security, and fairness of LLMs. By systematically challenging
    the models with adversarial inputs, developers can identify and address vulnerabilities,
    improving the models’ resilience and trustworthiness in handling a wide variety
    of real-world applications.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，对抗性测试是评估和提升大型语言模型（LLMs）鲁棒性、安全性和公平性不可或缺的工具。通过系统地用对抗性输入挑战模型，开发者可以识别和解决漏洞，提高模型在处理各种实际应用时的弹性和可信度。
- en: 10 Fairness and Bias Evaluation
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10 公平性与偏差评估
- en: Fairness and Bias Evaluation is crucial for assessing Large Language Models
    (LLMs) to ensure their outputs are equitable and free from biases that could lead
    to discrimination across demographics such as gender, ethnicity, age, and disability.
    This process not only aids in identifying biases inherent in training data or
    algorithms but also plays a pivotal role in mitigating potential unfair treatment.
    Through this evaluation, developers and researchers gain insights into the societal
    implications of LLMs, guiding the development of more ethical AI systems.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 公平性和偏差评估对于评估大型语言模型（LLMs）至关重要，以确保其输出公正且不带有可能导致性别、种族、年龄和残疾等群体歧视的偏见。这个过程不仅有助于识别训练数据或算法中固有的偏见，还在减轻潜在的不公平对待方面发挥了关键作用。通过这种评估，开发者和研究人员能够了解LLMs的社会影响，从而指导更具伦理的人工智能系统的发展。
- en: The significance of fairness and bias evaluation in machine learning, underscored
    by Mehrabi (2019) and Caton (2020), encompasses a comprehensive analysis of fairness
    definitions and the categorization of fairness-enhancing approaches. While Mehrabi
    offers a detailed taxonomy of fairness, Caton focuses on stratifying methods to
    promote fairness into pre-processing, in-processing, and post-processing stages.
    Corbett-Davies (2018) critiques these fairness definitions’ statistical foundations,
    advocating for equitable treatment of individuals with similar risk profiles.
    Additionally, Pessach (2022) delves into the root causes of algorithmic bias and
    reviews mechanisms to improve fairness, highlighting the critical need for objective
    and unbiased ML algorithms. This collective body of work emphasizes the importance
    of rigorous fairness and bias evaluation in creating AI systems that are just
    and equitable.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，**公平性**和**偏差评估**的意义由Mehrabi（2019年）和Caton（2020年）强调，涵盖了对公平性定义的全面分析以及公平性增强方法的分类。虽然Mehrabi提供了详细的公平性分类法，Caton则关注将促进公平性的方法分为预处理、处理中和后处理阶段。Corbett-Davies（2018年）批评了这些公平性定义的统计基础，倡导对具有相似风险概况的个体进行公平对待。此外，Pessach（2022年）**深入探讨**了算法偏见的根源，并回顾了改善公平性的机制，突出了客观和无偏见的ML算法的关键需求。这些工作集体强调了在创建公正公平的AI系统中严格进行公平性和偏差评估的重要性。
- en: 10.1 Understanding Fairness and Bias Evaluation
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1 理解公平性和偏差评估
- en: 'Concept: This evaluation method involves analyzing the model’s outputs to check
    for biases that may disadvantage or favor certain groups over others. It looks
    at how the model’s predictions and responses vary across different demographic
    groups to identify disparities.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 概念：这种评估方法涉及分析模型输出，以检查可能使某些群体处于不利地位或偏袒某些群体的偏差。它考察模型的预测和响应在不同人口统计群体中的变化，以识别差异。
- en: 'Evaluation: Various statistical and qualitative methods are used to measure
    biases in model outputs. This can include disaggregated performance metrics (such
    as accuracy, precision, recall) across groups, analysis of language and sentiment
    bias, and the use of fairness metrics like equality of opportunity, demographic
    parity, and others.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 评估：使用各种统计和定性方法来衡量模型输出中的偏差。这可能包括跨组的性能指标（如准确性、精确度、召回率）、语言和情感偏见分析以及使用公平性指标，如机会平等、人口统计学平等和其他指标。
- en: 10.2 Application in Evaluating LLMs
  id: totrans-243
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2 评估LLM的应用
- en: •
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Identifying and Quantifying Biases: Fairness and bias evaluation helps in identifying
    both explicit and implicit biases within LLM outputs. By quantifying these biases,
    developers can understand their extent and the specific areas where the model
    may need improvement.'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 识别和量化偏差：公平性和偏差评估有助于识别LLM输出中的显性和隐性偏差。通过量化这些偏差，开发者可以了解其范围以及模型可能需要改进的具体领域。
- en: •
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Improving Model Generalization: Evaluating and mitigating biases is essential
    for improving the generalization of LLMs. Models that perform equitably across
    a wide range of demographic groups are likely to be more effective and reliable
    in diverse real-world applications.'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 改善模型泛化能力：评估和缓解偏差对于提高LLM的泛化能力至关重要。在各种人口统计群体中表现公平的模型在多样化的现实应用中更可能有效和可靠。
- en: •
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Enhancing Model Trustworthiness: By addressing fairness and bias issues, developers
    can enhance the trustworthiness and societal acceptance of LLMs. This is particularly
    important for applications in sensitive areas such as healthcare, finance, and
    legal systems, where biased outputs can have significant consequences.'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提升模型可信度：通过解决公平性和偏差问题，开发者可以提高LLM的可信度和社会接受度。这对于敏感领域如医疗保健、金融和法律系统中的应用尤为重要，因为偏见输出可能会产生重大后果。
- en: •
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Regulatory Compliance and Ethical Standards: Fairness and bias evaluation is
    critical for meeting ethical standards and regulatory requirements related to
    AI and machine learning. It helps ensure that LLMs adhere to principles of fairness,
    accountability, and transparency.'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 法规遵从和伦理标准：公平性和偏差评估对于满足与AI和机器学习相关的伦理标准和法规要求至关重要。它帮助确保LLM遵循公平、问责和透明的原则。
- en: 10.3 Challenges and Considerations
  id: totrans-252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.3 挑战和考虑因素
- en: •
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Complexity of Bias Mitigation: Identifying biases is only the first step; effectively
    mitigating them without introducing new biases or significantly impacting the
    model’s performance is a complex challenge. It often requires iterative testing
    and refinement of both the model and its training data.'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 偏差缓解的复杂性：识别偏差只是第一步；有效地缓解这些偏差而不引入新的偏差或显著影响模型性能是一项复杂的挑战。这通常需要对模型及其训练数据进行迭代测试和调整。
- en: •
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Multidimensional Nature of Fairness: Fairness is a multidimensional concept
    that may mean different things in different contexts. Balancing various fairness
    criteria and understanding their implications for diverse groups can be challenging.'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 公平性的多维特性：公平性是一个多维概念，在不同的背景下可能意味着不同的东西。平衡各种公平性标准并理解它们对不同群体的影响可能具有挑战性。
- en: •
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Data Representation and Model Transparency: Evaluating fairness and bias often
    requires a deep understanding of the model’s training data, algorithms, and decision-making
    processes. Issues of data representation and model transparency can complicate
    these evaluations.'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据表示和模型透明度：评估公平性和偏差通常需要深入理解模型的训练数据、算法和决策过程。数据表示和模型透明度的问题可能会使这些评估变得复杂。
- en: •
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Evolving Standards and Societal Norms: Standards of what constitutes fairness
    and bias evolve over time and differ across cultures and communities. Continuous
    monitoring and updating of LLMs are necessary to align with these evolving standards.'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 标准和社会规范的演变：关于公平性和偏差的标准会随着时间的推移而变化，并且在不同的文化和社区中有所不同。需要持续监测和更新LLMs，以与这些不断发展的标准保持一致。
- en: In summary, Fairness and Bias Evaluation is critical for ensuring that LLMs
    are developed and deployed in a way that promotes equity and avoids harm. Through
    careful evaluation and ongoing efforts to mitigate identified biases, developers
    can contribute to the creation of more ethical and socially responsible AI systems.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，公平性和偏差评估对确保LLMs的开发和部署方式促进公平性并避免伤害至关重要。通过仔细评估和持续努力缓解已识别的偏差，开发人员可以为创建更具伦理性和社会责任感的AI系统做出贡献。
- en: 11 Robustness Evaluation
  id: totrans-262
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11 鲁棒性评估
- en: Robustness Evaluation is vital for determining the durability and reliability
    of Large Language Models (LLMs) across diverse and challenging conditions, including
    scenarios not covered during training. This evaluation critically examines the
    model’s capacity to sustain consistent performance amidst variations in input,
    adversarial attacks, and exposure to noisy data, emphasizing the importance of
    robustness for the safe and effective deployment of LLMs in real-world settings.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 鲁棒性评估对确定大型语言模型（LLMs）在各种不同且具有挑战性的条件下的耐用性和可靠性至关重要，包括训练过程中未涵盖的情境。这种评估关键地检查了模型在输入变化、对抗攻击和噪声数据暴露下维持一致性能的能力，强调了鲁棒性在实际环境中安全有效部署LLMs的重要性。
- en: Lei (2010) and Wang (2021) underscore the significance of robustness evaluation
    in the LLM domain, with a focus on assessing model performance against a spectrum
    of challenging conditions. Wang (2021) offers an extensive survey on robustness
    in natural language processing (NLP), detailing various definitions, evaluation
    methodologies, and strategies for enhancing model robustness. Huang (2007) discusses
    the broader implications of robustness in product design, reinforcing the role
    of robust evaluation in ensuring high-quality outcomes. Additionally, Goel (2021)
    introduces the Robustness Gym, a unified toolkit designed for evaluating model
    robustness, facilitating the comparison of different evaluation approaches and
    contributing to the development of more resilient LLMs.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: Lei (2010) 和 Wang (2021) 强调了在LLM领域鲁棒性评估的重要性，重点评估模型在各种具有挑战性条件下的表现。Wang (2021)
    提供了关于自然语言处理（NLP）中鲁棒性的广泛调查，详细说明了各种定义、评估方法和增强模型鲁棒性的策略。Huang (2007) 讨论了鲁棒性在产品设计中的更广泛影响，强调了鲁棒性评估在确保高质量结果中的作用。此外，Goel
    (2021) 介绍了鲁棒性训练营（Robustness Gym），这是一个统一的工具包，用于评估模型的鲁棒性，促进不同评估方法的比较，并有助于开发更具韧性的LLMs。
- en: 11.1 Understanding Robustness Evaluation
  id: totrans-265
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.1 理解鲁棒性评估
- en: 'Concept: Robustness in the context of LLMs refers to the model’s stability
    and reliability across diverse and unpredictable inputs. A robust model can handle
    variations in input data, resist manipulation through adversarial examples, and
    perform reliably across different domains or languages without significant degradation
    in performance.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 概念：在LLMs的背景下，鲁棒性指的是模型在多样和不可预测的输入下的稳定性和可靠性。一个鲁棒的模型可以处理输入数据的变化，抵抗通过对抗样本进行的操控，并在不同领域或语言中可靠地执行，而不会显著降低性能。
- en: 'Evaluation: Robustness is assessed through a series of tests designed to challenge
    the model in various ways. This may include:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 评估：鲁棒性通过一系列旨在以不同方式挑战模型的测试来评估。这可能包括：
- en: •
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Input Perturbations: Testing the model’s performance on data that has been
    slightly altered or corrupted in ways that should not affect the interpretation
    for a human reader.'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输入扰动：测试模型在稍微被修改或损坏的数据上的性能，这些修改不应影响人类读者的理解。
- en: •
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Adversarial Examples: Evaluating the model against inputs specifically designed
    to trick or mislead it, as a way to probe for vulnerabilities.'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对抗样本：评估模型在特意设计来欺骗或误导它的输入上的表现，以探查漏洞。
- en: •
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Stress Testing: Subjecting the model to extreme conditions, such as very long
    inputs, out-of-distribution data, or highly ambiguous queries, to assess its limits.'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 压力测试：将模型置于极端条件下，如非常长的输入、分布外的数据或高度模糊的查询，以评估其极限。
- en: •
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Cross-Domain Evaluation: Testing the model’s performance on data from domains
    or topics not covered in its training set, to assess its generalization capabilities.'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 跨领域评估：在模型的训练集未覆盖的领域或主题的数据上测试模型的性能，以评估其泛化能力。
- en: 11.2 Application in Evaluating LLMs
  id: totrans-276
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.2 评估LLMs的应用
- en: •
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Ensuring Reliability in Diverse Conditions: Robustness evaluation helps ensure
    that LLMs can be deployed in a wide range of applications and environments, maintaining
    high performance even under conditions that differ from their training data.'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 确保在多样化条件下的可靠性：鲁棒性评估有助于确保大语言模型（LLMs）可以在各种应用和环境中部署，即使在与训练数据不同的条件下也能保持高性能。
- en: •
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Protecting Against Malicious Use: By identifying and addressing vulnerabilities
    through robustness evaluation, developers can make it more difficult for malicious
    actors to exploit LLMs, enhancing the security of these systems.'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 保护免受恶意使用：通过识别和解决漏洞，开发人员可以使恶意行为者更难利用LLMs，从而增强这些系统的安全性。
- en: •
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Improving User Experience: Ensuring robustness contributes to a better user
    experience by providing consistent and reliable outputs, even when users interact
    with the model in unexpected ways or provide noisy input data.'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 改善用户体验：确保鲁棒性通过提供一致且可靠的输出，即使用户以意外的方式与模型互动或提供噪声输入数据，也能提高用户体验。
- en: •
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Facilitating Responsible Deployment: A thorough robustness evaluation is crucial
    for responsibly deploying LLMs, particularly in critical applications where errors
    or inconsistencies could have serious consequences.'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 促进负责任的部署：彻底的鲁棒性评估对于负责任地部署LLMs至关重要，特别是在错误或不一致可能带来严重后果的关键应用中。
- en: 11.3 Challenges and Considerations
  id: totrans-285
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3 挑战与考虑
- en: •
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Balancing Performance and Robustness: Increasing a model’s robustness can sometimes
    come at the cost of overall performance or efficiency. Finding the optimal balance
    is a key challenge in model development.'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 性能与鲁棒性的平衡：提高模型的鲁棒性有时可能会以整体性能或效率为代价。找到最佳平衡点是模型开发中的一个关键挑战。
- en: •
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Comprehensive Testing: Designing a robustness evaluation that comprehensively
    covers all possible challenges and conditions the model might face in real-world
    applications is complex and resource-intensive.'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 综合测试：设计一个全面覆盖模型在实际应用中可能遇到的所有挑战和条件的鲁棒性评估是复杂且资源密集的。
- en: •
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Continuous Evaluation: The robustness of LLMs may need to be re-evaluated over
    time as new vulnerabilities are discovered, usage patterns evolve, or the model
    is applied in new contexts.'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 持续评估：LLMs的鲁棒性可能需要随着新漏洞的发现、使用模式的演变或模型在新环境中的应用而重新评估。
- en: •
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Interpretability and Diagnostics: Understanding why a model fails under certain
    conditions is essential for improving robustness. However, the complexity and
    opacity of LLMs can make diagnosing and addressing weaknesses challenging.'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可解释性和诊断：了解模型在某些条件下失败的原因对于提高鲁棒性至关重要。然而，LLMs的复杂性和不透明性可能使得诊断和解决弱点变得困难。
- en: In summary, Robustness Evaluation is a multifaceted approach to ensuring that
    LLMs are reliable, secure, and effective across a wide array of conditions and
    applications. By rigorously testing and improving the robustness of these models,
    developers can enhance their utility and safety, paving the way for their successful
    integration into various aspects of society and industry.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，鲁棒性评估是一种多方面的方法，用于确保大型语言模型在各种条件和应用中的可靠性、安全性和有效性。通过严格测试和改善这些模型的鲁棒性，开发者可以增强其实用性和安全性，为它们成功融入社会和工业的各个方面铺平道路。
- en: 12 LLMMaps
  id: totrans-295
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12 LLMMaps
- en: LLMMaps is a pioneering visualization technique crafted for the nuanced evaluation
    of Large Language Models (LLMs) within various NLP subfields. It seeks to offer
    an all-encompassing assessment of an LLM’s performance, highlighting both its
    strengths and areas requiring improvement, particularly focusing on reducing hallucinations—where
    models erroneously present incorrect information as accurate. Puchert (2023) underscores
    the value of LLMMaps in detecting performance discrepancies and susceptibility
    to hallucinations in LLMs. Complementing this, CRITIC, introduced by Gou (2023),
    enables LLMs to self-correct via interactions with external tools. Furthermore,
    Peng (2023) proposes enhancing LLMs with external knowledge and automated feedback
    to further curb hallucinations. Collectively, these strategies aim to bolster
    the precision and dependability of LLMs, marking significant progress in NLP technology.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: LLMMaps 是一种开创性的可视化技术，旨在对大型语言模型（LLMs）在各种自然语言处理子领域进行细致评估。它旨在提供对大型语言模型性能的全面评估，突出其优势和需要改进的领域，特别是关注减少幻觉——即模型错误地将不准确的信息呈现为准确的信息。Puchert（2023）强调了
    LLMMaps 在检测大型语言模型性能差异和幻觉易感性方面的价值。与此相辅的是，Gou（2023）提出的 CRITIC 使大型语言模型通过与外部工具互动进行自我纠正。此外，Peng（2023）建议通过外部知识和自动反馈来进一步遏制幻觉。这些策略共同致力于提高大型语言模型的精确性和可靠性，标志着自然语言处理技术的重要进步。
- en: 12.1 Understanding LLMMaps
  id: totrans-297
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1 理解 LLMMaps
- en: 'Concept: LLMMaps organizes and visualizes the performance of LLMs across a
    spectrum of NLP tasks and domains in a structured manner. This stratification
    allows researchers and developers to pinpoint specific areas of excellence and
    those in need of refinement.'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 概念：LLMMaps 以结构化的方式组织和可视化大型语言模型在各种自然语言处理任务和领域中的表现。这种分层使研究人员和开发者能够精准定位优秀领域和需要改进的地方。
- en: 'Visualization: The technique could involve graphical representations, such
    as heatmaps or multidimensional plots, where each axis or dimension corresponds
    to different evaluation criteria or NLP subfields. Performance metrics, such as
    accuracy, fairness, robustness, or the propensity for hallucinations, can be represented
    in this multidimensional space.'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化：该技术可能涉及图形表示，如热力图或多维图，其中每个轴或维度对应不同的评估标准或自然语言处理子领域。性能指标，如准确性、公平性、鲁棒性或幻觉倾向，可以在这种多维空间中表示。
- en: 'Hallucination Focus: A significant aspect of LLMMaps is its emphasis on identifying
    and reducing hallucinations. By visualizing areas where hallucinations are more
    prevalent, developers can target improvements more effectively.'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 幻觉关注：LLMMaps 的一个重要方面是其对识别和减少幻觉的强调。通过可视化幻觉更为普遍的区域，开发者可以更有效地针对改进。
- en: 12.2 Application in Evaluating LLMs
  id: totrans-301
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.2 在评估大型语言模型中的应用
- en: •
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Comprehensive Performance Overview: LLMMaps can provide a holistic view of
    an LLM’s performance, highlighting how well it performs across a variety of tasks,
    such as translation, summarization, question-answering, and more. This overview
    helps in understanding the model’s general capabilities and limitations.'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 综合性能概述：LLMMaps 可以提供大型语言模型在各种任务中的整体表现，突出其在翻译、总结、问答等方面的表现。这种概述有助于理解模型的总体能力和局限性。
- en: •
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Targeted Improvements: By visually identifying areas requiring improvement,
    such as those prone to hallucinations or biases, LLMMaps enables developers to
    focus their efforts more effectively on enhancing model quality and reliability.'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 针对性改进：通过可视化识别需要改进的区域，例如那些容易出现幻觉或偏见的区域，LLMMaps 使开发者能够更有效地集中精力提升模型的质量和可靠性。
- en: •
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Benchmarking and Comparison: LLMMaps can be used as a benchmarking tool, allowing
    for the comparison of different models or versions of a model over time. This
    can track progress and inform the development of more advanced, less error-prone
    models.'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基准测试和比较：LLMMaps可以用作基准测试工具，允许对不同模型或模型版本进行比较。这可以跟踪进展并为开发更先进、错误更少的模型提供信息。
- en: •
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Facilitating Research and Collaboration: The visual and stratified nature of
    LLMMaps makes it an excellent tool for facilitating discussions and collaborations
    within the research community, helping to align efforts towards addressing common
    challenges.'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 促进研究和合作：LLMMaps的可视化和分层特性使其成为促进研究界讨论和合作的优秀工具，有助于将努力对齐以解决共同挑战。
- en: 12.3 Challenges and Considerations
  id: totrans-310
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3 挑战和考虑因素
- en: •
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Data and Metric Selection: The effectiveness of LLMMaps depends on the selection
    of relevant data and metrics for evaluation. Ensuring these are comprehensive
    and accurately reflect model performance is crucial.'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据和指标选择：LLMMaps的有效性依赖于相关数据和评估指标的选择。确保这些数据全面且准确反映模型性能至关重要。
- en: •
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Complexity in Interpretation: While LLMMaps can provide a detailed overview
    of model performance, interpreting these visualizations, especially in highly
    multidimensional spaces, can be complex and require expertise in data analysis
    and visualization techniques.'
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解释的复杂性：虽然LLMMaps可以提供模型性能的详细概述，但解释这些可视化图形，尤其是在高度多维的空间中，可能会很复杂，需要数据分析和可视化技术方面的专业知识。
- en: •
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Updating and Maintenance: As the field of NLP evolves, maintaining LLMMaps
    to reflect new subfields, evaluation metrics, and challenges will be necessary
    to keep them relevant and useful.'
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 更新和维护：随着自然语言处理领域的发展，保持LLMMaps以反映新的子领域、评估指标和挑战将是必要的，以保持其相关性和实用性。
- en: •
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Subjectivity and Bias: The design and interpretation of LLMMaps might introduce
    subjectivity, especially in how performance areas are defined and prioritized.
    Ensuring objectivity and inclusiveness in these evaluations is important to avoid
    reinforcing existing biases.'
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 主观性和偏见：LLMMaps的设计和解释可能引入主观性，特别是在定义和优先排序性能领域时。确保这些评估的客观性和包容性对于避免强化现有偏见非常重要。
- en: In summary, LLMMaps represent a novel and potentially powerful approach to evaluating
    LLMs, offering detailed insights into their performance across various dimensions.
    By highlighting specific areas for improvement, especially in reducing hallucinations,
    LLMMaps can guide the development of more accurate, reliable, and fair LLMs.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，LLMMaps代表了一种新颖且潜在强大的评估LLMs的方法，提供了对其在各个维度上的性能的详细见解。通过突显具体的改进领域，特别是在减少虚假信息方面，LLMMaps可以指导开发更准确、可靠和公平的LLMs。
- en: 13 Benchmarking and Leaderboards
  id: totrans-320
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13 基准测试和排行榜
- en: Benchmarking and Leaderboards serve as crucial instruments for systematically
    assessing the performance of Large Language Models (LLMs), particularly in their
    ability to address queries from extensive Q&A datasets. Hockney (1993) emphasizes
    the importance of selecting appropriate performance metrics, cautioning against
    the reliance on speedup and MMop/s measures due to their potential limitations
    in capturing the nuanced capabilities of LLMs. In response to the demand for more
    rigorous benchmarks, Arora (2023) introduced JEEBench, a collection of intricate
    problems demanding extended reasoning and specialized knowledge. This benchmark
    has highlighted the advancements in newer LLMs, while also pointing out areas
    needing further development. Additionally, Vestal (1990) suggested a method for
    benchmarking language features through multiple sampling loops and linear regression,
    a technique that could offer detailed performance insights for various LLM parameters.
    Collectively, these approaches underscore the role of Benchmarking and Leaderboards
    in evaluating LLMs, pushing the envelope for accuracy and proficiency in complex
    language understanding tasks.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 基准测试和排行榜作为系统评估大型语言模型（LLM）性能的重要工具，特别是在处理大量问答数据集的能力方面。Hockney（1993）强调了选择适当性能指标的重要性，提醒不要仅依赖于加速和MMop/s测量，因为这些指标可能无法全面捕捉LLM的细微能力。为了应对对更严格基准的需求，Arora（2023）引入了JEEBench，这是一系列复杂问题，要求进行扩展的推理和专门的知识。这一基准突显了新型LLM的进展，同时也指出了需要进一步发展的领域。此外，Vestal（1990）提出了一种通过多次采样循环和线性回归对语言特性进行基准测试的方法，这种技术可能为各种LLM参数提供详细的性能见解。总的来说，这些方法强调了基准测试和排行榜在评估LLM中的作用，推动了在复杂语言理解任务中的准确性和能力的提升。
- en: 13.1 Understanding Benchmarking and Leaderboards
  id: totrans-322
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.1 理解基准测试和排行榜
- en: 'Benchmarking: This involves evaluating LLMs against a standardized set of tasks
    or datasets to measure their performance. In the context of Q&A, benchmark datasets
    consist of a large number of questions paired with correct answers, covering various
    topics and difficulty levels. The model’s responses are compared to the correct
    answers to assess accuracy, comprehension, and relevance.'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 基准测试：这涉及将LLM与一套标准化任务或数据集进行评估，以测量其性能。在问答背景下，基准数据集由大量问题和正确答案配对组成，涵盖各种主题和难度级别。将模型的回答与正确答案进行比较，以评估准确性、理解力和相关性。
- en: 'Leaderboards: Leaderboards rank LLMs based on their performance on benchmark
    tasks. They provide a comparative view of different models, highlighting which
    models perform best on specific tasks or datasets. Leaderboards are often hosted
    by academic conferences, research institutions, or industry groups, and they are
    updated regularly as new models are developed and evaluated.'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 排行榜：排行榜根据LLM在基准任务中的表现对其进行排名。它们提供了不同模型的比较视图，突显出哪些模型在特定任务或数据集上表现最佳。排行榜通常由学术会议、研究机构或行业团体主办，并在新模型开发和评估时定期更新。
- en: 13.2 Application in Evaluating LLMs
  id: totrans-325
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.2 在评估大语言模型中的应用
- en: •
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Performance Assessment: Benchmarking and leaderboards offer a clear, quantitative
    measure of an LLM’s ability to understand and process natural language queries,
    providing insights into its comprehension, reasoning, and language generation
    capabilities.'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 性能评估：基准测试和排行榜提供了LLM理解和处理自然语言查询的能力的清晰、量化的衡量标准，提供了对其理解、推理和语言生成能力的洞察。
- en: •
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Model Comparison: By placing models in a competitive context, leaderboards
    help identify the most advanced LLMs in terms of Q&A accuracy and other metrics,
    fostering a healthy competition among researchers and developers to improve their
    models.'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型比较：通过将模型置于竞争环境中，排行榜帮助识别在问答准确性和其他指标方面最先进的LLM，促进研究人员和开发者之间的健康竞争，以提升他们的模型。
- en: •
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Progress Tracking: Benchmarking allows for the tracking of progress in the
    field of NLP and LLM development over time. It shows how models evolve and improve,
    indicating advancements in technology and methodologies.'
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 进展跟踪：基准测试允许跟踪NLP和LLM开发领域的进展，展示模型如何随着时间演变和改进，指示技术和方法的进步。
- en: •
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Identifying Strengths and Weaknesses: Through detailed analysis of benchmarking
    results, developers can identify specific areas where their models excel or fall
    short, informing targeted improvements and research directions.'
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 识别优势与劣势：通过对基准测试结果的详细分析，开发者可以识别模型的具体优势或不足，从而为有针对性的改进和研究方向提供信息。
- en: 13.3 Challenges and Considerations
  id: totrans-334
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.3 挑战和考虑事项
- en: •
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Diversity and Representativeness: Ensuring that benchmark datasets are diverse
    and representative of real-world questions is crucial for meaningful evaluation.
    Biases or limitations in the datasets can lead to skewed assessments of model
    capabilities.'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 多样性和代表性：确保基准数据集具有多样性，并且能够代表现实世界中的问题，对于有意义的评估至关重要。数据集中的偏差或限制可能会导致对模型能力的评估失真。
- en: •
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Beyond Accuracy: While accuracy is a critical metric, it does not capture all
    aspects of an LLM’s performance. Other factors like response time, resource efficiency,
    and the ability to generate nuanced, context-aware responses are also important.'
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 超越准确性：尽管准确性是一个关键指标，但它并不能涵盖LLM（大语言模型）性能的所有方面。响应时间、资源效率以及生成细致、上下文感知的回应的能力也是重要的因素。
- en: •
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Dynamic Nature of Leaderboards: As new models are constantly being developed,
    leaderboards are always changing. Staying at the top of a leaderboard can be fleeting,
    emphasizing the need for continuous improvement and adaptation.'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 排行榜的动态特性：随着新模型的不断开发，排行榜总是在变化。保持在排行榜顶部的状态可能是短暂的，这突显了持续改进和适应的必要性。
- en: •
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Overemphasis on Competition: While competition can drive innovation, excessive
    focus on leaderboard rankings may lead to over-optimization for specific benchmarks
    at the expense of generalizability and ethical considerations.'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对竞争的过度强调：虽然竞争可以推动创新，但过度关注排行榜排名可能会导致针对特定基准的过度优化，从而牺牲模型的普适性和伦理考虑。
- en: In summary, Benchmarking and Leaderboards are invaluable tools for evaluating
    LLMs, especially in the domain of question answering. They provide a structured
    and competitive environment for assessing model performance, driving advancements
    in the field. However, it’s important to consider these tools as part of a broader
    evaluation strategy that also includes qualitative assessments, ethical considerations,
    and real-world applicability to fully understand and improve the capabilities
    of LLMs.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，基准测试和排行榜是评估LLM的宝贵工具，特别是在问答领域。它们提供了一个结构化和竞争的环境来评估模型性能，推动了该领域的进步。然而，重要的是将这些工具视为更广泛评估策略的一部分，策略中还应包括定性评估、伦理考虑和现实世界的适用性，以全面理解和提升LLM的能力。
- en: 14 Stratified Analysis
  id: totrans-344
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14 分层分析
- en: Stratified Analysis is a versatile evaluation method that dissects Large Language
    Models’ (LLMs) performance into distinct layers or strata, each representing various
    domains, topics, or task types. This granular approach allows for a detailed understanding
    of LLMs’ strengths and weaknesses across different knowledge subfields. The concept
    of stratified analysis, while diverse in application, shares a common goal of
    providing in-depth insights within specific contexts. Moutinho (1994) introduced
    Stratlogic, a strategic marketing tool that analyzes competitive positioning through
    a data-driven lens. Kumar (1997) assessed data formats in layered manufacturing,
    detailing their advantages and limitations. Rahwan (2007) developed STRATUM, a
    strategy for designing heuristic negotiation tactics in automated negotiations,
    underscoring the need to account for agent capabilities. Jongman (2005) applied
    statistical environmental stratification across Europe, aiming to streamline environmental
    patterns for improved biodiversity assessment and monitoring. Together, these
    applications underscore the broad utility and adaptability of stratified analysis
    in enhancing domain-specific understanding and strategy development.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 分层分析是一种多用途的评估方法，它将大语言模型（LLMs）的性能分解为不同的层级或层次，每个层级代表不同的领域、主题或任务类型。这种细化的方法允许对LLMs在不同知识子领域的优势和劣势进行详细理解。分层分析的概念，尽管在应用上有所不同，但都有一个共同目标，即在特定背景下提供深入的见解。Moutinho（1994年）引入了Stratlogic，这是一种通过数据驱动的视角分析竞争定位的战略营销工具。Kumar（1997年）评估了分层制造中的数据格式，详细说明了其优缺点。Rahwan（2007年）开发了STRATUM，一种用于设计自动化谈判中的启发式谈判策略的策略，强调了考虑代理能力的必要性。Jongman（2005年）在欧洲应用了统计环境分层，旨在优化环境模式以改进生物多样性评估和监测。这些应用共同强调了分层分析在提升特定领域理解和战略开发中的广泛实用性和适应性。
- en: 14.1 Understanding Stratified Analysis
  id: totrans-346
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.1 理解分层分析
- en: 'Concept: Stratified analysis breaks down the evaluation of LLMs into smaller,
    more manageable segments based on predefined criteria such as content domains
    (e.g., science, literature, technology), task types (e.g., question answering,
    summarization, translation), or complexity levels. This allows for a detailed
    assessment of the model’s performance in each area.'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 概念：分层分析将对大语言模型（LLMs）的评估分解成基于预定义标准（如内容领域（例如科学、文学、技术）、任务类型（例如问答、总结、翻译）或复杂性级别）的小而易管理的部分。这允许对模型在每个领域的表现进行详细评估。
- en: 'Application: The performance of an LLM is assessed within each stratum using
    relevant metrics, such as accuracy, precision, recall, or domain-specific evaluation
    standards. This detailed assessment helps in understanding how well the model
    handles different types of information and tasks.'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 应用：大语言模型的表现通过相关指标（如准确性、精确度、召回率或领域特定评估标准）在每个层次上进行评估。这种详细评估有助于了解模型如何处理不同类型的信息和任务。
- en: 14.2 Application in Evaluating LLMs
  id: totrans-349
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.2 在评估LLMs中的应用
- en: •
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Identifying Domain-Specific Performance: Stratified analysis enables the identification
    of which domains or topics an LLM excels in and which it struggles with. For instance,
    a model might perform exceptionally well in technical domains but poorly in creative
    writing or ethical reasoning.'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 识别领域特定表现：分层分析使得识别大语言模型在哪些领域或主题上表现优异，哪些领域或主题上表现不佳成为可能。例如，一个模型可能在技术领域表现出色，但在创意写作或伦理推理方面表现较差。
- en: •
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Guiding Model Improvements: By pinpointing specific areas of weakness, this
    analysis directs researchers and developers towards targeted improvements, whether
    by adjusting training data, refining model architectures, or incorporating specialized
    knowledge sources.'
  id: totrans-353
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 指导模型改进：通过定位特定的弱点，这种分析可以指导研究人员和开发者进行有针对性的改进，无论是通过调整训练数据、优化模型架构，还是整合专业知识来源。
- en: •
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Enhancing Generalization and Specialization: Understanding a model’s performance
    across various strata can inform strategies for enhancing its generalization capabilities
    while also developing specialized models tailored for specific domains or tasks.'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提升泛化能力和专业化：了解模型在不同层次上的表现可以为提升其泛化能力的策略提供信息，同时也可以开发针对特定领域或任务的专业化模型。
- en: •
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Benchmarking and Comparative Analysis: Stratified analysis facilitates more
    nuanced benchmarking and comparison between models, allowing for a deeper understanding
    of each model’s unique strengths and limitations in a variety of contexts.'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基准测试和比较分析：分层分析促进了模型之间更细致的基准测试和比较，允许对每个模型在不同背景下的独特优点和局限性有更深刻的理解。
- en: 14.3 Challenges and Considerations
  id: totrans-358
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.3 挑战与考虑
- en: •
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Selection of Strata: Determining the appropriate strata for analysis can be
    challenging. The criteria for stratification need to be carefully chosen to ensure
    that the analysis is meaningful and covers the breadth of knowledge and tasks
    relevant to LLMs.'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 层次选择：确定适当的分析层次可能具有挑战性。分层的标准需要仔细选择，以确保分析有意义，并覆盖与大语言模型相关的知识和任务的广度。
- en: •
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Comprehensive Evaluation: Conducting a thorough stratified analysis requires
    significant resources, including diverse datasets and domain-specific evaluation
    metrics. Ensuring comprehensiveness while managing these resources is a key challenge.'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 综合评估：进行全面的分层分析需要大量资源，包括多样的数据集和领域特定的评估指标。在管理这些资源的同时确保全面性是一个关键挑战。
- en: •
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Balancing Depth and Breadth: While stratified analysis offers depth in specific
    areas, it’s essential to balance this with a broad overview to avoid missing the
    bigger picture of the model’s capabilities.'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 深度与广度的平衡：虽然分层分析在特定领域提供了深度，但需要与广泛的概述相平衡，以避免忽视模型能力的全貌。
- en: •
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Evolving Knowledge Fields: As knowledge and technology evolve, the strata used
    for analysis may need to be updated or expanded, requiring ongoing adjustments
    to evaluation frameworks.'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 知识领域的演变：随着知识和技术的发展，用于分析的层次可能需要更新或扩展，这需要对评估框架进行持续的调整。
- en: In summary, Stratified Analysis offers a detailed and nuanced approach to evaluating
    LLMs, shedding light on their varied capabilities across different domains and
    tasks. This method provides valuable insights that can guide the development of
    more capable, versatile, and targeted LLMs, ultimately advancing the field of
    natural language processing and artificial intelligence.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，分层分析提供了一种详细且细致的方法来评估LLM，揭示了它们在不同领域和任务中的多样能力。这种方法提供了宝贵的见解，可以指导开发更具能力、更灵活和更有针对性的LLM，最终推动自然语言处理和人工智能领域的发展。
- en: 15 Visualization of Bloom’s Taxonomy
  id: totrans-368
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 15 布鲁姆分类法的可视化
- en: A range of studies have explored the application of Bloom’s Taxonomy in different
    contexts. Granello (2001) and Köksal (2018) both emphasize the importance of this
    framework in education, with Granello focusing on its use in graduate-level writing
    and Köksal in language assessment. Kelly (2006) and Yusof (2010) delve into the
    practical aspects of applying Bloom’s Taxonomy, with Kelly proposing a context-aware
    analysis scheme and Yusof developing a classification model for question items
    in examinations. These studies collectively highlight the versatility and potential
    of Bloom’s Taxonomy as a tool for enhancing cognitive complexity and evaluating
    performance.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 一系列研究探讨了布鲁姆分类法在不同背景下的应用。Granello（2001）和Köksal（2018）都强调了这一框架在教育中的重要性，其中Granello专注于其在研究生写作中的应用，Köksal则关注于语言评估。Kelly（2006）和Yusof（2010）探讨了应用布鲁姆分类法的实际方面，Kelly提出了一个情境感知的分析方案，而Yusof开发了一个用于考试题目分类的模型。这些研究共同突显了布鲁姆分类法作为提升认知复杂性和评估表现工具的多样性和潜力。
- en: 15.1 Understanding the Visualization of Bloom’s Taxonomy
  id: totrans-370
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.1 理解布鲁姆分类法的可视化
- en: 'Concept: This approach visualizes the model’s performance in a pyramidal (or
    hierarchical) fashion, reflecting the structure of Bloom’s Taxonomy itself. Each
    level of the pyramid represents a level of cognitive skill, with the base indicating
    tasks that require basic memory (Remember) and the apex representing tasks that
    require creative abilities (Create).'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 概念：这种方法以金字塔（或层级）方式可视化模型的表现，反映了布鲁姆分类法本身的结构。金字塔的每一层代表一个认知技能层次，底层表示需要基本记忆（记住）的任务，而顶层表示需要创造能力（创造）的任务。
- en: 'Application: The accuracy or performance metric for the LLM is calculated for
    tasks aligned with each of Bloom’s levels. These metrics are then plotted on the
    pyramid, allowing for a clear visual representation of where the model excels
    or struggles.'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 应用：LLM的准确性或性能指标是针对每个布鲁姆层次的任务计算的。这些指标随后被绘制在金字塔上，清晰地展示了模型在哪些方面表现优异或遇到困难。
- en: 15.2 Application in Evaluating LLMs
  id: totrans-373
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.2 在评估LLM中的应用
- en: •
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Assessing Cognitive Capabilities: This visualization helps in understanding
    the range and depth of cognitive tasks an LLM can handle. For instance, a model
    may perform well in tasks that require understanding and applying knowledge but
    struggle with tasks requiring evaluation and creation.'
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 评估认知能力：此可视化帮助理解一个语言模型（LLM）能够处理的认知任务的范围和深度。例如，一个模型可能在理解和应用知识的任务中表现良好，但在需要评估和创造的任务中则表现不佳。
- en: •
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Guiding Model Development: By identifying specific cognitive levels where the
    LLM’s performance is lacking, developers can focus their efforts on improving
    these areas, whether through training on more diverse datasets, incorporating
    advanced algorithms, or integrating additional knowledge sources.'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 指导模型开发：通过识别LLM在特定认知层次上的表现不足，开发者可以集中精力改进这些领域，无论是通过训练更多样化的数据集、整合先进的算法，还是整合额外的知识来源。
- en: •
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Educational Applications: For LLMs intended for educational purposes, visualization
    of Bloom’s Taxonomy can be particularly useful in aligning the model’s capabilities
    with educational goals and standards, ensuring it supports learning across all
    cognitive levels.'
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 教育应用：对于用于教育目的的LLM，布鲁姆分类法的可视化特别有用，可以将模型的能力与教育目标和标准对齐，确保它在所有认知层次上支持学习。
- en: •
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Benchmarking Complexity Handling: This method provides a standardized way to
    benchmark and compare the sophistication of different LLMs in handling tasks of
    varying cognitive complexity, offering a comprehensive view of their intellectual
    capabilities.'
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基准测试复杂性处理：这种方法提供了一种标准化的方式来基准测试和比较不同LLM在处理各种认知复杂性任务方面的复杂程度，提供了对其智力能力的全面视角。
- en: 15.3 Challenges and Considerations
  id: totrans-382
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15.3 挑战和考虑事项
- en: •
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Task Alignment: Aligning tasks with the appropriate level of Bloom’s Taxonomy
    can be subjective and requires a deep understanding of both the taxonomy and the
    tasks being evaluated. Misalignment could lead to inaccurate assessments of model
    capabilities.'
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 任务对齐：将任务与布鲁姆分类学的适当层次对齐可能具有主观性，需要对分类学和所评估任务有深入了解。不匹配可能导致对模型能力的评估不准确。
- en: •
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Complexity of Evaluation: Tasks at higher cognitive levels (e.g., Evaluate,
    Create) are inherently more complex and subjective, making them challenging to
    evaluate accurately. Developing reliable metrics for these tasks is crucial for
    meaningful visualization.'
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 评估的复杂性：较高认知层次的任务（例如，评估、创造）本质上更复杂和主观，准确评估这些任务具有挑战性。为这些任务开发可靠的指标对于有意义的可视化至关重要。
- en: •
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Interpretation of Results: While the visualization provides a clear overview
    of performance across cognitive levels, interpreting these results and translating
    them into actionable insights requires careful consideration of the model’s intended
    applications and limitations.'
  id: totrans-388
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果解释：虽然可视化提供了各认知层次表现的清晰概述，但解释这些结果并将其转化为可操作的见解需要仔细考虑模型的预期应用和局限性。
- en: •
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Dynamic Nature of LLM Capabilities: As LLMs evolve and improve, their capabilities
    at different levels of Bloom’s Taxonomy may change. Ongoing evaluation and updating
    of the visualization are necessary to maintain an accurate representation of their
    performance.'
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LLM能力的动态特性：随着LLM的演变和改进，它们在布鲁姆分类学的不同层次上的能力可能会发生变化。持续的评估和更新可视化内容是保持其性能准确表示的必要条件。
- en: In summary, Visualization of Bloom’s Taxonomy offers a unique and insightful
    method for evaluating LLMs, highlighting their capabilities and limitations across
    a spectrum of cognitive tasks. This approach not only aids in the targeted development
    of LLMs but also in their application in educational and complex problem-solving
    contexts, pushing the boundaries of what these models can achieve.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，布鲁姆分类学的可视化提供了一种独特且富有洞察力的方法来评估LLM，突出了它们在各种认知任务中的能力和局限性。这种方法不仅有助于LLM的有针对性开发，也有助于它们在教育和复杂问题解决环境中的应用，推动了这些模型的成就边界。
- en: 16 Hallucination Score
  id: totrans-392
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 16 幻觉评分
- en: The phenomenon of hallucinations in Large Language Models (LLMs)—where models
    generate unfounded or entirely fictional responses—has emerged as a significant
    concern, compromising the reliability and trustworthiness of AI systems. Highlighted
    by researchers like Ye (2023) and Lee (2018), these inaccuracies can severely
    impact LLM applications, from educational tools to critical news dissemination.
    In response, Zhou (2020) introduced a novel technique for identifying hallucinated
    content in neural sequence generation, marking a pivotal step towards enhancing
    sentence-level hallucination detection and significantly improving the reliability
    of LLM outputs.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）中出现的幻觉现象——即模型生成无根据或完全虚构的响应——已成为一个重要问题，影响了AI系统的可靠性和可信度。研究者如Ye（2023）和Lee（2018）指出，这些不准确性可能严重影响LLM应用，从教育工具到重要新闻传播。作为回应，Zhou（2020）提出了一种新技术，用于识别神经序列生成中的幻觉内容，标志着在句子级别幻觉检测方面的一项重要进展，并显著提高了LLM输出的可靠性。
- en: Within this context, the Hallucination Score, a metric developed as part of
    the LLMMaps framework, plays a crucial role by measuring the frequency and severity
    of hallucinations in LLM outputs. This metric enables a systematic assessment
    of how often and to what extent LLMs produce unsupported or incorrect responses,
    guiding efforts to mitigate such issues and bolster the models’ applicability
    in sensitive and critical domains.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一背景下，**幻觉评分**，作为LLMMaps框架的一部分开发的指标，通过测量LLM输出中幻觉的频率和严重程度，发挥着关键作用。这个指标使得能够系统地评估LLM产生不支持或错误响应的频率和程度，从而指导减少这些问题的努力，并增强模型在敏感和关键领域的适用性。
- en: 16.1 Understanding the Hallucination Score
  id: totrans-395
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.1 理解幻觉评分
- en: 'Concept: The Hallucination Score measures the extent to which an LLM produces
    hallucinated content. It is quantified based on the analysis of the model’s outputs
    against verified information or established facts, considering both the frequency
    of hallucinations and their potential impact.'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 概念：幻觉评分衡量LLM产生幻觉内容的程度。它基于对模型输出与已验证信息或既定事实的分析进行量化，考虑幻觉的频率及其潜在影响。
- en: 'Application: To calculate this score, responses from the LLM are evaluated
    against a benchmark set of questions or prompts that have known, factual answers.
    The score might be derived from the proportion of responses that contain hallucinations,
    weighted by the severity or potential harm of the inaccuracies.'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 应用：为了计算这一得分，将LLM的回应与已知的、事实性的答案的基准问题或提示进行对比。得分可能来源于包含幻觉的回应的比例，按不准确的严重程度或潜在危害加权。
- en: 16.2 Application in Evaluating LLMs
  id: totrans-398
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.2 评估 LLM 的应用
- en: •
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Identifying Reliability Issues: By quantifying hallucinations, the score helps
    in identifying how often and under what conditions an LLM might produce unreliable
    outputs. This is crucial for assessing the model’s suitability for various applications.'
  id: totrans-400
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 识别可靠性问题：通过量化幻觉，得分有助于识别 LLM 可能产生不可靠输出的频率和条件。这对于评估模型在各种应用中的适用性至关重要。
- en: •
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Guiding Model Improvements: A high Hallucination Score signals a need for model
    refinement, possibly through better training data curation, improved model architecture,
    or enhanced post-processing checks to minimize inaccuracies.'
  id: totrans-402
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 指导模型改进：高“幻觉得分”表明需要对模型进行改进，可能通过更好的训练数据策划、改进的模型架构或增强的后处理检查来减少不准确性。
- en: •
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Benchmarking and Comparison: The Hallucination Score provides a standardized
    metric for comparing different models or versions of a model over time, offering
    insights into progress in reducing hallucinations and improving output accuracy.'
  id: totrans-404
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基准测试与比较：“幻觉得分”提供了一个标准化的指标，用于比较不同模型或模型版本在时间上的变化，提供了减少幻觉和提高输出准确性的进展洞察。
- en: •
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Enhancing User Trust: By actively monitoring and working to reduce the Hallucination
    Score, developers can enhance user trust in LLM applications, ensuring that the
    information provided is accurate and reliable.'
  id: totrans-406
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 增强用户信任：通过积极监控并努力降低“幻觉得分”，开发人员可以增强用户对 LLM 应用的信任，确保提供的信息准确可靠。
- en: 16.3 Challenges and Considerations
  id: totrans-407
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.3 挑战与考虑
- en: •
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Subjectivity in Evaluation: Determining what constitutes a hallucination can
    be subjective, especially in areas where information is ambiguous or rapidly evolving.
    Developing clear criteria for identifying and categorizing hallucinations is essential.'
  id: totrans-409
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 评估中的主观性：确定什么构成幻觉可能是主观的，尤其是在信息模糊或迅速变化的领域。制定明确的标准以识别和分类幻觉是至关重要的。
- en: •
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Complexity of Measurement: Accurately measuring the Hallucination Score requires
    comprehensive evaluation across a wide range of topics and contexts, necessitating
    significant resources and expert knowledge.'
  id: totrans-411
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 测量的复杂性：准确测量“幻觉得分”需要在广泛的主题和背景下进行全面评估，这需要大量资源和专业知识。
- en: •
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Balancing Creativity and Accuracy: In some applications, such as creative writing
    or idea generation, a certain level of ”hallucination” might be desirable. Balancing
    the need for creativity with the need for factual accuracy is a nuanced challenge.'
  id: totrans-413
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 创造力与准确性的平衡：在某些应用中，如创意写作或创意生成，某种程度的“幻觉”可能是可取的。平衡创造力的需求与事实准确性的需求是一个微妙的挑战。
- en: •
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Dynamic Nature of Knowledge: As new information becomes available and the world
    changes, responses that were once considered accurate may become outdated or incorrect.
    Continuous updating and re-evaluation are necessary to maintain the validity of
    the Hallucination Score.'
  id: totrans-415
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 知识的动态性质：随着新信息的出现和世界的变化，以前被认为准确的回应可能会变得过时或不正确。为了保持“幻觉得分”的有效性，需要不断更新和重新评估。
- en: In summary, the Hallucination Score within the LLMMaps framework provides a
    valuable metric for evaluating the accuracy and reliability of LLM outputs. By
    quantifying the extent of hallucinated content, it offers a clear indicator of
    a model’s current performance and areas for improvement, contributing to the development
    of more trustworthy and effective LLMs.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，LLMMaps 框架中的“幻觉得分”提供了一个宝贵的指标，用于评估 LLM 输出的准确性和可靠性。通过量化幻觉内容的程度，它提供了一个清晰的模型当前表现和改进领域的指示，有助于开发更可靠和有效的
    LLM。
- en: 17 Knowledge Stratification Strategy
  id: totrans-417
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 17 知识分层策略
- en: The Knowledge Stratification Strategy is a systematic evaluative method aimed
    at enhancing the analysis of Large Language Models (LLMs) through the organization
    of Q&A datasets into a hierarchical knowledge structure. This approach categorizes
    questions and answers by their knowledge complexity and specificity, arranging
    them from broad, general knowledge at the top to highly specialized knowledge
    at the bottom. Such stratification facilitates a detailed analysis of an LLM’s
    performance across various levels of knowledge depth and domain specificity, providing
    insights into the model’s proficiency in different areas.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 知识分层策略是一种系统性的评估方法，旨在通过将问答数据集组织成分层的知识结构来增强对大型语言模型（LLMs）的分析。这种方法按照知识复杂性和专门化程度对问题和答案进行分类，从广泛的常识到高度专业化的知识分布在不同层级。这样的分层有助于详细分析LLM在不同知识深度和领域专门性方面的表现，为模型在不同领域的能力提供见解。
- en: Drawing parallels with established methodologies in other fields, this strategy
    echoes the Knowledge Partitioning approach in Product Lifecycle Management (PLM)
    described by Therani (2005), which organizes organizational knowledge into distinct
    categories. It also aligns with the method used for the statistical environmental
    stratification of Europe by Jongman (2005), aimed at delineating environmental
    gradients for better assessment. In the context of the service sector, specifically
    IT services, Gulati (2014) highlights its importance for effective knowledge retention
    and management. Furthermore, Folkens (2004) discusses its application in evaluating
    Knowledge Management Systems (KMS) within organizations, underscoring the strategy’s
    versatility and utility across diverse domains.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他领域已建立的方法进行类比，这一策略类似于Therani（2005）在产品生命周期管理（PLM）中描述的知识分割方法，该方法将组织知识分类到不同类别中。它也与Jongman（2005）用于欧洲统计环境分层的方法相一致，该方法旨在划定环境梯度以便于更好的评估。在服务行业，特别是IT服务方面，Gulati（2014）强调了其对有效知识保留和管理的重要性。此外，Folkens（2004）讨论了其在评估组织内知识管理系统（KMS）中的应用，强调了这一策略在各种领域中的多样性和实用性。
- en: 17.1 Understanding Knowledge Stratification Strategy
  id: totrans-420
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 17.1 理解知识分层策略
- en: 'Concept: This strategy creates a layered framework within Q&A datasets, where
    each layer represents a different level of knowledge complexity and domain specialization.
    The top layers might include questions that require common knowledge and understanding,
    while lower layers would contain questions necessitating deep, specific expertise.'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 概念：该策略在问答数据集中创建了一个分层框架，每一层代表不同的知识复杂性和领域专门化水平。顶层可能包括需要常识和理解的问题，而底层则包含需要深入、具体专业知识的问题。
- en: 'Application: In evaluating LLMs, questions from different strata of the hierarchy
    are posed to the model. The model’s performance on these questions is then analyzed
    to determine how well it handles various types of knowledge, from the most general
    to the most specialized.'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 应用：在评估LLMs时，从不同层级提出问题，分析模型对这些问题的表现，以确定其在处理各种类型知识（从最一般到最专业）的能力。
- en: 17.2 Application in Evaluating LLMs
  id: totrans-423
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 17.2 评估LLMs的应用
- en: •
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Comprehensive Performance Insight: The Knowledge Stratification Strategy offers
    a comprehensive view of an LLM’s performance spectrum, showcasing its proficiency
    in handling both general and specialized queries. This insight is crucial for
    applications requiring a broad range of knowledge.'
  id: totrans-425
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 综合性能洞察：知识分层策略提供了对LLM性能范围的全面视图，展示其在处理一般性和专业性查询方面的能力。这种洞察对需要广泛知识范围的应用至关重要。
- en: •
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Identifying Areas for Improvement: By pinpointing the levels of knowledge where
    the LLM’s performance dips, this strategy guides targeted improvements, whether
    in training data augmentation, model fine-tuning, or incorporating external knowledge
    bases.'
  id: totrans-427
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 确定改进领域：通过确定LLM表现较差的知识层级，这一策略指导有针对性的改进，无论是数据训练增强、模型微调还是整合外部知识库。
- en: •
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Enhancing Domain-Specific Applications: For LLMs intended for domain-specific
    applications, this approach helps in assessing and enhancing their expertise in
    the relevant knowledge areas, ensuring they meet the required standards of accuracy
    and reliability.'
  id: totrans-429
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提升特定领域应用：对于旨在特定领域应用的大型语言模型（LLMs），这种方法有助于评估和提升其在相关知识领域的专业水平，确保其满足所需的准确性和可靠性标准。
- en: •
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Benchmarking and Comparison: Knowledge Stratification enables a more detailed
    benchmarking process, allowing for the comparison of LLMs not just on overall
    accuracy but on their ability to navigate and respond across a spectrum of knowledge
    depths.'
  id: totrans-431
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基准测试与比较：知识分层使得基准测试过程更加详细，不仅可以比较LLM的整体准确性，还可以评估其在不同知识深度范围内的导航和响应能力。
- en: 17.3 Challenges and Considerations
  id: totrans-432
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 17.3 挑战与考虑事项
- en: •
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Hierarchy Design: Designing an effective knowledge hierarchy requires a deep
    understanding of the subject matter and the relevant domains, posing a challenge
    in ensuring the stratification is meaningful and accurately reflects varying knowledge
    depths.'
  id: totrans-434
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 层级设计：设计有效的知识层级结构需要对主题和相关领域有深刻的理解，这对确保分层有意义并准确反映不同的知识深度提出了挑战。
- en: •
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Evaluation Consistency: Ensuring consistent evaluation across different knowledge
    strata can be challenging, especially when dealing with specialized knowledge
    areas where expert validation may be necessary.'
  id: totrans-436
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 评估一致性：确保在不同知识层次间的一致评估可能具有挑战性，尤其是在处理需要专家验证的专业知识领域时。
- en: •
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Adaptation to Evolving Knowledge: The knowledge landscape is constantly evolving,
    particularly in specialized fields. The stratification strategy must be adaptable
    to incorporate new developments and discoveries, requiring ongoing updates to
    the hierarchy.'
  id: totrans-438
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 适应不断发展的知识：知识领域不断演变，尤其是在专业领域。分层策略必须适应这些变化，以纳入新的发展和发现，需要对层级结构进行持续更新。
- en: •
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Balance Between Generalization and Specialization: While stratification helps
    in assessing specialized knowledge, it’s also important to maintain a balance,
    ensuring the LLM remains versatile and effective across a wide range of topics
    and not just narrowly focused areas.'
  id: totrans-440
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一般化与专业化的平衡：虽然分层有助于评估专业知识，但保持平衡也很重要，以确保大型语言模型（LLM）在各种主题领域中保持多样性和有效性，而不仅仅是狭窄的专注领域。
- en: In summary, the Knowledge Stratification Strategy offers a structured and in-depth
    approach to evaluating LLMs, allowing for a detailed assessment of their capabilities
    across a hierarchical spectrum of knowledge. By leveraging this strategy, developers
    and researchers can gain valuable insights into the strengths and weaknesses of
    LLMs, guiding the development of models that are both versatile and deeply knowledgeable
    in specific domains.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，知识分层策略提供了一种结构化且深入的方法来评估LLM，允许对其在知识层级范围内的能力进行详细评估。通过利用这一策略，开发者和研究人员可以深入了解LLM的优势和劣势，从而指导开发出在特定领域既多才多艺又深具知识的模型。
- en: 18 Utilization of Machine Learning Models for Hierarchy Generation
  id: totrans-442
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 18 机器学习模型生成层级结构的利用
- en: Utilizing Machine Learning Models for Hierarchy Generation offers a sophisticated
    method for structuring and analyzing Q&A datasets to evaluate Large Language Models
    (LLMs). This technique employs LLMs and other machine learning models to autonomously
    classify and arrange questions into a coherent hierarchy of topics and subfields,
    ensuring each question is accurately categorized by its content and the overarching
    themes of the dataset. This process enhances the systematic and detailed evaluation
    of LLMs.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 利用机器学习模型生成层级结构提供了一种复杂的方法，用于构建和分析问答数据集，以评估大型语言模型（LLM）。该技术利用LLM和其他机器学习模型自动分类和排列问题，将其组织成一个连贯的主题和子领域的层级结构，确保每个问题根据其内容和数据集的整体主题被准确分类。这个过程增强了对LLM系统化和详细的评估。
- en: Research in this domain includes Gaussier (2002), who introduced a hierarchical
    generative model aimed at clustering and document categorization, aligning with
    the goals of hierarchy generation. Xu (2018) expanded on this by integrating prior
    knowledge into building topic hierarchies, offering a more refined approach. Dorr
    (1998) contributed a thematic hierarchy designed for efficient generation from
    lexical-conceptual structures, aiding in the organization of information. Ruiz
    (2004) explored text categorization using a hierarchical array of neural networks,
    showcasing the approach’s utility in bolstering categorization performance. Together,
    these studies underscore the effectiveness and versatility of machine learning
    models in creating structured hierarchies for enhancing LLM evaluation and beyond.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 这一领域的研究包括 Gaussier (2002)，他引入了一种层次生成模型，旨在进行聚类和文档分类，与层次生成的目标一致。Xu (2018) 通过将先验知识整合进构建主题层次中，提供了一种更精细的方法。Dorr
    (1998) 提出了一个用于从词汇概念结构中高效生成的主题层次，帮助信息的组织。Ruiz (2004) 探索了使用神经网络的层次数组进行文本分类，展示了这一方法在增强分类性能中的作用。这些研究共同强调了机器学习模型在创建结构化层次以提升
    LLM 评估等方面的有效性和多样性。
- en: 18.1 Understanding Utilization of Machine Learning Models for Hierarchy Generation
  id: totrans-445
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 18.1 了解机器学习模型在层次生成中的应用
- en: 'Concept: This approach uses machine learning algorithms, including LLMs themselves,
    to analyze the content and context of questions in a dataset. The model identifies
    key themes, topics, and the complexity level of each question, using this information
    to generate a hierarchical structure that organizes questions'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 概念：这一方法利用包括 LLMs 在内的机器学习算法，分析数据集中问题的内容和背景。模型识别每个问题的关键主题、话题和复杂性级别，利用这些信息生成一个层次结构，以组织问题。
- en: 19 Shapley Values for LLMs
  id: totrans-447
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 19 Shapley 值在 LLMs 中的应用
- en: Shapley Values, derived from cooperative game theory, present a refined method
    for assessing the contribution of individual input features, like words or tokens,
    to the outputs of Large Language Models (LLMs). This technique assigns a quantifiable
    value to each feature based on its impact on the model’s predictions, enabling
    a detailed examination of feature importance. By applying Shapley values to LLMs,
    we can achieve a deeper understanding of how each element of input data influences
    the model’s outputs, providing a fair and robust measure of the significance of
    different aspects of the input.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: Shapley 值源于合作博弈论，为评估单个输入特征（如单词或标记）对大型语言模型（LLMs）输出的贡献提供了一种精细的方法。这一技术根据特征对模型预测的影响，为每个特征分配一个可量化的值，从而实现对特征重要性的详细检验。通过将
    Shapley 值应用于 LLMs，我们可以深入理解输入数据的每个元素如何影响模型的输出，提供一种公平且可靠的衡量输入不同方面重要性的方法。
- en: The utility of Shapley values extends beyond LLMs, finding applications in various
    machine learning facets, including feature selection, model explainability, and
    data valuation, as explored by Rozemberczki (2022). This approach not only enhances
    our grasp of feature importance in LLMs but also contributes to equitable solutions
    in other sectors, such as fair transmission cost allocation in competitive power
    markets (Tan, 2002), and broadens its applicability to scenarios involving both
    transferable and non-transferable utility (Aumann, 1994). Through these applications,
    Shapley values offer a comprehensive framework for dissecting and understanding
    the intricate dynamics at play in LLMs and other complex systems.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: Shapley 值的效用超越了 LLMs，在特征选择、模型可解释性和数据估值等各种机器学习方面找到了应用，如 Rozemberczki (2022) 所探讨的。这一方法不仅增强了我们对
    LLMs 中特征重要性的理解，还对其他领域中的公平解决方案有所贡献，如竞争电力市场中的公平传输成本分配（Tan, 2002），并扩大了其在可转移和不可转移效用的情境下的适用性（Aumann,
    1994）。通过这些应用，Shapley 值提供了一个全面的框架，用于剖析和理解 LLMs 及其他复杂系统中复杂的动态。
- en: 19.1 Understanding Shapley Values in the Context of LLMs
  id: totrans-450
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 19.1 了解 Shapley 值在 LLMs 上下文中的作用
- en: 'Equitable Distribution of Contribution: Shapley values calculate the average
    marginal contribution of each feature across all possible combinations of features.
    This ensures that the contribution of each input feature is fairly assessed, taking
    into account the presence or absence of other features.'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 公平分配贡献：Shapley 值计算每个特征在所有可能的特征组合中的平均边际贡献。这确保了每个输入特征的贡献得到公平评估，考虑到其他特征的存在或缺失。
- en: 'Quantifying Feature Importance: By applying Shapley values to LLMs, researchers
    can quantitatively determine how much each word or token in the input text contributes
    to the model’s output. This is particularly valuable in tasks where understanding
    the influence of specific linguistic elements is crucial, such as sentiment analysis,
    text classification, or machine translation.'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 特征重要性量化：通过将 Shapley 值应用于 LLMs，研究人员可以定量确定输入文本中每个词或标记对模型输出的贡献。这在理解特定语言元素的影响至关重要的任务中尤其有价值，如情感分析、文本分类或机器翻译。
- en: 'Insights into Model Behavior: Shapley values can reveal insights into the model’s
    behavior, such as dependencies between features or the significance of specific
    words in context. This can help identify whether the model is focusing on relevant
    information or being swayed by irrelevant details.'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 对模型行为的洞察：Shapley 值可以揭示模型行为的洞察，例如特征之间的依赖关系或特定词语在上下文中的重要性。这有助于识别模型是否专注于相关信息或被无关细节所影响。
- en: 19.2 Application in LLM Evaluation
  id: totrans-454
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 19.2 在 LLM 评估中的应用
- en: •
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Model Interpretability: Enhancing the interpretability of LLMs is one of the
    key applications of Shapley values. By providing a clear and fair attribution
    of output contributions to input features, they help demystify the model’s decision-making
    process, making it more accessible and understandable to humans.'
  id: totrans-456
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型可解释性：提高 LLMs 的可解释性是 Shapley 值的关键应用之一。通过提供对输出贡献到输入特征的明确而公平的归因，它们有助于揭示模型的决策过程，使其对人类更加可理解和易于接触。
- en: •
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Bias Detection and Mitigation: Shapley values can help identify biases in model
    predictions by highlighting input features that disproportionately affect the
    output. This can guide efforts to mitigate these biases, either by adjusting the
    training data or modifying the model architecture.'
  id: totrans-458
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 偏差检测与缓解：Shapley 值可以通过突出那些不成比例地影响输出的输入特征来帮助识别模型预测中的偏差。这可以指导缓解这些偏差的工作，无论是通过调整训练数据还是修改模型架构。
- en: •
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Improving Model Robustness: Understanding feature contributions can inform
    the development of more robust LLMs. If certain innocuous features are found to
    have an outsized impact on predictions, this may indicate vulnerabilities to adversarial
    attacks or overfitting, which can then be addressed.'
  id: totrans-460
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 改善模型鲁棒性：理解特征贡献可以为开发更鲁棒的 LLMs 提供信息。如果发现某些无害的特征对预测有过大的影响，这可能表明存在对抗攻击或过拟合的漏洞，从而可以加以解决。
- en: 19.3 Techniques and Considerations
  id: totrans-461
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 19.3 技术与注意事项
- en: •
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Computational Complexity: One of the challenges of applying Shapley values
    to LLMs is their computational intensity. Calculating the contribution of each
    feature requires evaluating the model’s output across all possible subsets of
    features, which can be prohibitively expensive for large models and inputs.'
  id: totrans-463
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 计算复杂性：将 Shapley 值应用于大语言模型（LLMs）的一大挑战是其计算强度。计算每个特征的贡献需要评估模型在所有可能的特征子集上的输出，这对于大型模型和输入来说可能是极其昂贵的。
- en: •
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Approximation Methods: To mitigate computational challenges, various approximation
    algorithms have been developed. These methods aim to provide accurate estimations
    of Shapley values without exhaustive computation, making the approach more feasible
    for practical applications.'
  id: totrans-465
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 近似方法：为了缓解计算挑战，已经开发了各种近似算法。这些方法旨在提供 Shapley 值的准确估计，而无需进行详尽的计算，从而使这一方法在实际应用中更加可行。
- en: •
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Integration with Other Interpretability Tools: Shapley values can be used in
    conjunction with other interpretability tools, such as attention visualization
    or sensitivity analysis, to provide a more comprehensive understanding of model
    behavior. Combining methods can offer both detailed feature-level insights and
    broader overviews of model dynamics.'
  id: totrans-467
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与其他可解释性工具的集成：Shapley 值可以与其他可解释性工具一起使用，例如注意力可视化或敏感性分析，以提供对模型行为的更全面理解。结合这些方法可以提供详细的特征级洞察和对模型动态的更广泛概述。
- en: Shapley values represent a powerful tool for dissecting and understanding the
    contributions of individual features in LLM outputs. Despite their computational
    demands, the depth and fairness of the insights they provide make them an invaluable
    asset for enhancing the transparency, fairness, and interpretability of LLMs.
    As LLMs continue to evolve and their applications become increasingly widespread,
    techniques like Shapley values will play a crucial role in ensuring these models
    are both understandable and accountable.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: Shapley 值代表了一种强大的工具，用于剖析和理解 LLM 输出中各个特征的贡献。尽管其计算要求较高，但它们提供的深度和公平性使其成为提升 LLM
    透明度、公平性和可解释性的宝贵资产。随着 LLMs 的不断发展及其应用的日益广泛，像 Shapley 值这样的技术将在确保这些模型既可理解又负责任方面发挥关键作用。
- en: 20 Attention Visualization
  id: totrans-469
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 20 注意力可视化
- en: Attention Visualization serves as a key technique for interpreting Large Language
    Models (LLMs), particularly those built on the Transformer architecture, by revealing
    how these models allocate importance to various parts of the input data through
    attention mechanisms. This visualization helps elucidate the model’s focus areas
    within the input text, offering a window into its information processing strategies
    and decision-making patterns.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力可视化是解释大语言模型（LLMs），特别是基于 Transformer 架构的模型的关键技术，通过揭示这些模型如何通过注意力机制分配重要性来解释输入数据的各个部分。这种可视化有助于阐明模型在输入文本中的关注区域，提供了对其信息处理策略和决策模式的洞察。
- en: The concept of visual attention, as initially proposed by Tsotsos (1995) through
    a selective tuning model, underscores the efficiency of focusing on specific parts
    of the visual field. This foundational idea parallels the selective focus enabled
    by attention mechanisms in LLMs, especially Transformers, which adjust their focus
    dynamically across the input data to enhance processing efficiency. Yang (2021)
    advanced this concept within vision transformer models, addressing local region
    prediction inconsistencies by refining self-attention mechanisms. Ilinykh (2022)
    delved into multi-modal transformers, analyzing how cross-attention layers capture
    syntactic, semantic, and visual grounding information. Furthermore, Gao (2022)
    introduced an Attention in Attention (AiA) module aimed at refining attention
    correlations, thereby boosting visual tracking performance.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉注意力的概念最初由 Tsotsos（1995年）通过选择性调节模型提出，强调了专注于视觉领域特定部分的效率。这一基础理念与大语言模型（LLMs），特别是
    Transformers 中的注意力机制的选择性聚焦相呼应，这些机制在输入数据中动态调整其焦点，以提高处理效率。Yang（2021年）在视觉 Transformer
    模型中推进了这一概念，通过优化自注意力机制来解决局部区域预测的不一致问题。Ilinykh（2022年）深入研究了多模态 Transformers，分析了交叉注意力层如何捕捉句法、语义和视觉基础信息。此外，Gao（2022年）引入了一个注意力中的注意力（AiA）模块，旨在优化注意力相关性，从而提升视觉跟踪性能。
- en: Collectively, these contributions from Tsotsos (1995), Yang (2021), Ilinykh
    (2022), and Gao (2022) enrich our understanding of attention mechanisms’ role
    in both human cognition and artificial intelligence, highlighting the evolution
    and optimization of these systems in LLMs. By visualizing attention weights, researchers
    can dissect and improve how LLMs prioritize information, enhancing model interpretability
    and effectiveness.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: Tsotsos（1995年）、Yang（2021年）、Ilinykh（2022年）和 Gao（2022年）这些贡献共同丰富了我们对注意力机制在人工智能和人类认知中的作用的理解，突出了这些系统在
    LLMs 中的发展和优化。通过可视化注意力权重，研究人员可以解剖和改进 LLMs 如何优先考虑信息，提高模型的可解释性和有效性。
- en: 20.1 Understanding Attention Visualization in LLMs
  id: totrans-473
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 20.1 理解 LLMs 中的注意力可视化
- en: 'Mechanics of Attention: In the context of LLMs, the attention mechanism allows
    the model to allocate varying degrees of ”focus” or ”importance” to different
    input elements when performing a task. This mechanism is key to the model’s ability
    to handle long-range dependencies and contextual nuances in text.'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力机制：在 LLMs 的背景下，注意力机制允许模型在执行任务时对不同输入元素分配不同程度的“焦点”或“重要性”。这一机制是模型处理长程依赖和文本上下文细微差别的关键。
- en: 'Visualization Techniques: Attention visualization typically involves creating
    heatmaps or other graphical representations that show the attention scores between
    different parts of the input text or between the input and output tokens. High
    attention scores are often highlighted in warmer colors (e.g., reds), indicating
    areas of the text that the model pays more attention to during its processing.'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化技术：注意力可视化通常涉及创建热图或其他图形表示，展示输入文本中不同部分之间或输入与输出令牌之间的注意力分数。高注意力分数通常用较暖的颜色（例如红色）突出显示，表示模型在处理过程中对文本的某些区域给予更多关注。
- en: 20.2 Application in LLM Evaluation
  id: totrans-476
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 20.2 LLM评估中的应用
- en: •
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Insights into Model Decision-making: Visualization of attention weights provides
    a direct window into the decision-making process of LLMs. It can reveal how the
    model prioritizes certain words or phrases over others, offering clues about its
    understanding of language and context.'
  id: totrans-478
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对模型决策过程的洞察：注意力权重的可视化提供了对LLM决策过程的直接窗口。它可以揭示模型如何优先考虑某些词语或短语，相对于其他词语，提供关于其语言和上下文理解的线索。
- en: •
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Understanding Contextual Processing: Attention patterns can demonstrate how
    the model handles context, showing whether and how it integrates contextual information
    from different parts of the text to generate coherent and contextually appropriate
    responses.'
  id: totrans-480
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 理解上下文处理：注意力模式可以展示模型如何处理上下文，显示模型是否以及如何整合来自文本不同部分的上下文信息，以生成连贯且符合上下文的响应。
- en: •
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Improving Model Interpretability: By making the model’s focus areas explicit,
    attention visualization enhances the interpretability of LLMs. This can be particularly
    useful for developers and researchers looking to debug or improve model performance,
    as well as for end-users seeking explanations for model outputs.'
  id: totrans-482
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提高模型可解释性：通过使模型的关注区域明确，注意力可视化增强了LLM的可解释性。这对于希望调试或改进模型性能的开发者和研究人员，以及寻求模型输出解释的最终用户特别有用。
- en: •
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Identifying Biases and Artifacts: Analyzing attention distributions can also
    help identify potential biases or training artifacts that the model may have learned.
    For instance, if the model consistently pays undue attention to specific tokens
    or phrases that are not relevant to the task, it might indicate a bias introduced
    during training.'
  id: totrans-484
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 识别偏差和伪影：分析注意力分布还可以帮助识别模型可能学到的潜在偏差或训练伪影。例如，如果模型一贯对与任务不相关的特定令牌或短语给予过多关注，这可能表明训练过程中引入了偏差。
- en: 20.3 Techniques and Considerations
  id: totrans-485
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 20.3 技术和注意事项
- en: •
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Layer-wise and Head-wise Visualization: Modern Transformer-based LLMs contain
    multiple layers and heads within their attention mechanisms. Visualizing attention
    across different layers and heads can provide a more granular understanding of
    how information is processed and integrated at various stages of the model.'
  id: totrans-487
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 层级和头级可视化：现代基于Transformer的LLM包含多个层和头部在其注意力机制中。可视化不同层和头部的注意力可以提供对信息如何在模型的各个阶段被处理和整合的更细致理解。
- en: •
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Quantitative Analysis: Beyond visual inspection, quantitative analysis of attention
    weights can offer additional insights. For instance, aggregating attention scores
    across a dataset can highlight general patterns or biases in how the model processes
    different types of input.'
  id: totrans-489
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 定量分析：除了视觉检查，注意力权重的定量分析可以提供额外的见解。例如，聚合数据集中的注意力分数可以突出显示模型处理不同类型输入的总体模式或偏差。
- en: •
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Interpretation Challenges: While attention visualization is a powerful tool,
    interpreting these visualizations can be challenging. High attention does not
    always equate to causal importance, and the relationship between attention patterns
    and model outputs can be complex.'
  id: totrans-491
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解释挑战：虽然注意力可视化是一个强大的工具，但解释这些可视化图像可能具有挑战性。高注意力分数不总是等同于因果重要性，注意力模式与模型输出之间的关系可能非常复杂。
- en: •
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Complementary Tools: To gain a comprehensive understanding of LLM behavior,
    attention visualization is often used in conjunction with other interpretability
    and evaluation techniques, such as feature importance methods, Shapley values,
    and sensitivity analysis.'
  id: totrans-493
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 互补工具：为了全面理解LLM行为，注意力可视化通常与其他可解释性和评估技术一起使用，例如特征重要性方法、Shapley值和敏感性分析。
- en: Attention Visualization stands out as a valuable technique for demystifying
    the complex processing mechanisms of LLMs, offering both researchers and practitioners
    a way to visually interrogate and understand the model’s focus and decision-making
    processes. Through careful analysis and interpretation of attention patterns,
    one can derive actionable insights to enhance model performance, fairness, and
    user trust.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力可视化作为一种有价值的技术，突显了揭示 LLM 复杂处理机制的价值，为研究人员和从业者提供了一种以可视化方式审视和理解模型的关注点和决策过程的方法。通过对注意力模式的仔细分析和解释，可以得出可操作的见解，以提高模型性能、公平性和用户信任。
- en: 21 Counterfactual Explanations for LLMs
  id: totrans-495
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 21 反事实解释用于 LLMs
- en: Counterfactual Explanations are a pivotal interpretability technique for Large
    Language Models (LLMs), focusing on how slight modifications to input data affect
    the model’s outputs. This method, which entails exploring ”what if” scenarios,
    is instrumental in unveiling the conditions that prompt changes in the model’s
    decisions or predictions, thereby illuminating its underlying reasoning and causal
    mechanisms.
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 反事实解释是大型语言模型（LLMs）的一种关键可解释性技术，重点在于输入数据的轻微修改如何影响模型的输出。这种方法涉及探讨“如果……会怎样”情景，对于揭示促使模型决策或预测变化的条件极为重要，从而阐明其基本推理和因果机制。
- en: Galles (1998) and Roese (1997) highlight the importance of counterfactual explanations
    in understanding an LLM’s decision-making process by observing the outcomes of
    minor changes to inputs. Höfler (2005) emphasizes the significance of a causal
    interpretation of counterfactuals, especially in recursive models, for gaining
    insights into the model’s logic. Meanwhile, Briggs (2012) discusses the ongoing
    debate around the causal modeling semantics for counterfactuals versus the similarity-based
    semantics proposed by Lewis, indicating the complexity and depth of understanding
    required to effectively apply counterfactual explanations to LLMs.
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: Galles（1998）和 Roese（1997）强调了通过观察对输入进行微小修改的结果，反事实解释在理解 LLM 决策过程中的重要性。Höfler（2005）强调了对反事实的因果解释的重要性，特别是在递归模型中，以获取对模型逻辑的见解。同时，Briggs（2012）讨论了反事实的因果建模语义与
    Lewis 提出的基于相似性的语义之间的持续争论，表明有效应用反事实解释于 LLMs 需要复杂且深入的理解。
- en: Through these references, the value of counterfactual explanations in dissecting
    and comprehending the decision-making processes of LLMs is underscored, showcasing
    their role in enhancing model transparency and interpretability.
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些参考文献，反事实解释在剖析和理解 LLM 决策过程中的价值得到了强调，展示了其在提升模型透明度和可解释性方面的作用。
- en: 21.1 Application in LLM Evaluation
  id: totrans-499
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 21.1 LLM 评估中的应用
- en: •
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Unveiling Model Sensitivity: Counterfactual explanations reveal the sensitivity
    of LLMs to different parts of the input text. By changing certain words or phrases
    and observing the impact on the output, evaluators can identify which aspects
    of the input are most influential in the model’s decisions or predictions.'
  id: totrans-501
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 揭示模型敏感性：反事实解释揭示了 LLM 对输入文本不同部分的敏感性。通过改变某些词汇或短语并观察对输出的影响，评估者可以识别输入中哪些方面对模型的决策或预测最具影响力。
- en: •
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Understanding Decision Boundaries: This technique helps delineate the conditions
    and boundaries within which the model’s output changes. It can highlight the thresholds
    of change necessary for the model to alter its response, offering insights into
    the model’s internal logic and how it discriminates between different inputs.'
  id: totrans-503
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 理解决策边界：这一技术帮助界定模型输出变化的条件和边界。它可以突出模型改变响应所需的变化阈值，提供关于模型内部逻辑及其如何区分不同输入的见解。
- en: •
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Identifying Bias and Ethical Concerns: By creating counterfactuals that alter
    demographic or contextually sensitive aspects of the input, researchers can uncover
    biases in the model’s outputs. This is instrumental in evaluating the fairness
    of LLMs and identifying potential ethical issues arising from biased or stereotypical
    responses.'
  id: totrans-505
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 识别偏见和伦理问题：通过创建改变输入的 demographic 或 contextually sensitive 方面的反事实，研究人员可以揭示模型输出中的偏见。这对评估
    LLM 的公平性以及识别由于偏见或刻板反应而可能出现的伦理问题至关重要。
- en: •
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Enhancing Model Robustness: Counterfactual explanations can also be used to
    test the robustness of LLMs against adversarial inputs or to ensure consistency
    in the model’s reasoning across similar yet slightly varied inputs. This can guide
    efforts to improve the model’s resilience to input variations and adversarial
    attacks.'
  id: totrans-507
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提升模型鲁棒性：反事实解释还可以用于测试LLM对对抗性输入的鲁棒性，或确保模型在类似但略微不同的输入下的一致性。这可以指导提升模型对输入变化和对抗攻击的韧性。
- en: 21.2 Techniques and Considerations
  id: totrans-508
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 21.2 技术和考虑事项
- en: •
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Minimal and Relevant Changes: Effective counterfactual explanations typically
    involve minimal but meaningful changes to the input, ensuring that the observed
    differences in output are attributable to specific modifications. This requires
    a careful selection of input alterations that are relevant to the model’s task
    and the aspect of performance being evaluated.'
  id: totrans-510
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最小化和相关性变化：有效的反事实解释通常涉及对输入的最小但有意义的变化，确保观察到的输出差异归因于特定的修改。这需要精心选择与模型任务和性能评估方面相关的输入更改。
- en: •
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Systematic Generation of Counterfactuals: Generating counterfactuals can be
    approached systematically by using algorithms that identify or create variations
    of the input data, which are likely to produce significant changes in the output.
    Techniques such as gradient-based optimization or genetic algorithms can automate
    the generation of impactful counterfactuals.'
  id: totrans-512
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 系统生成反事实：生成反事实可以通过使用算法系统地识别或创建输入数据的变体来实现，这些变体可能会产生显著的输出变化。基于梯度的优化或遗传算法等技术可以自动生成有影响力的反事实。
- en: •
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Qualitative and Quantitative Analysis: The evaluation of counterfactual explanations
    involves both qualitative analysis (e.g., assessing changes in the sentiment or
    theme of the output) and quantitative measures (e.g., differences in output probabilities
    or confidence scores). Combining these approaches provides a richer understanding
    of the model’s behavior.'
  id: totrans-514
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 定性和定量分析：反事实解释的评估涉及定性分析（例如，评估输出情感或主题的变化）和定量指标（例如，输出概率或置信度分数的差异）。结合这些方法可以提供对模型行为的更丰富理解。
- en: •
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Contextual and Cultural Considerations: When creating counterfactuals, it’s
    crucial to consider the context and cultural implications of the input changes.
    Misinterpretations or oversights in these areas can lead to misleading conclusions
    about the model’s performance and decision-making process.'
  id: totrans-516
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上下文和文化考量：在创建反事实时，必须考虑输入变化的上下文和文化影响。对这些领域的误解或忽视可能导致对模型性能和决策过程的误导性结论。
- en: 21.3 Challenges
  id: totrans-517
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 21.3 挑战
- en: •
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Interpretation Complexity: Interpreting the results of counterfactual explanations
    can be challenging, especially when dealing with complex or ambiguous inputs and
    outputs. It requires a nuanced understanding of both the domain and the model’s
    capabilities.'
  id: totrans-519
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解释复杂性：解释反事实解释的结果可能具有挑战性，尤其是在处理复杂或模糊的输入和输出时。这需要对领域和模型能力的细致理解。
- en: •
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Scalability: Manually creating and analyzing counterfactuals for a large number
    of inputs can be time-consuming and may not be scalable for extensive evaluations.
    Automation techniques can help, but they require careful design to ensure the
    relevance and effectiveness of the generated counterfactuals.'
  id: totrans-521
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可扩展性：手动创建和分析大量输入的反事实可能耗时且难以扩展。自动化技术可以提供帮助，但需要仔细设计以确保生成的反事实的相关性和有效性。
- en: Counterfactual Explanations offer a powerful means to probe the inner workings
    of LLMs, providing valuable insights into their sensitivity, decision-making boundaries,
    and potential biases. By methodically exploring how changes in the input influence
    the output, evaluators can enhance their understanding of LLM behavior, leading
    to more transparent, fair, and robust language models.
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 反事实解释提供了探测LLM内部工作原理的强大手段，提供了对其敏感性、决策边界和潜在偏见的宝贵洞见。通过系统地探讨输入变化如何影响输出，评估者可以增强对LLM行为的理解，从而实现更透明、公平和鲁棒的语言模型。
- en: 22 Language-Based Explanations for LLMs
  id: totrans-523
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 22 基于语言的LLM解释
- en: Language-Based Explanations (LBEs) are a vital method for making Large Language
    Models (LLMs) more understandable by translating their decision-making processes
    into natural language, accessible to humans. This approach, which can involve
    either the LLM itself or a dedicated model, breaks down the complex operations
    of machine learning into explanations that are easy for non-experts to grasp,
    enhancing transparency and trust in AI applications.
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 基于语言的解释（LBE）是一种重要方法，通过将大型语言模型（LLM）的决策过程转化为自然语言，使其更易于理解。这种方法可以涉及LLM本身或专门的模型，将复杂的机器学习操作分解为易于非专家理解的解释，从而增强透明度和对AI应用的信任。
- en: Celikyilmaz (2012) highlights the significance of LBEs in improving LLM interpretability.
    Further, the Language Interpretability Tool (LIT) introduced by Tenney (2020)
    offers a practical solution for visualizing and dissecting the workings of NLP
    models, including LLMs. Additionally, knowledge representation systems like LLILOG
    (Pletat, 1992) facilitate the conversion of natural language texts into formats
    that machines can process, underpinning the generation of language-based explanations.
    Wen (2015) demonstrates the impact of semantically conditioned LSTM-based natural
    language generation on enhancing spoken dialogue systems, illustrating a key area
    where LLMs benefit from improved performance through interpretability.
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: Celikyilmaz（2012）强调了语言基础解释（LBE）在提升大型语言模型（LLM）可解释性方面的重要性。此外，Tenney（2020）提出的语言可解释性工具（LIT）提供了可视化和剖析自然语言处理模型（包括LLM）工作原理的实用解决方案。此外，像LLILOG（Pletat，1992）这样的知识表示系统促进了自然语言文本向机器可处理格式的转换，支持基于语言的解释生成。Wen（2015）展示了语义条件LSTM基础自然语言生成在提升语音对话系统方面的影响，说明了LLM在通过可解释性提升性能的关键领域。
- en: Together, these references emphasize the crucial role of LBEs in bridging the
    gap between the advanced computational abilities of LLMs and the need for their
    outputs to be understandable and actionable for human users, thereby making AI
    technologies more accessible and interpretable.
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 这些参考文献共同强调了LBE在弥合LLM的先进计算能力与其输出对人类用户可理解和可操作之间的差距，从而使AI技术更具可访问性和可解释性。
- en: 22.1 Application in LLM Evaluation
  id: totrans-527
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 22.1 LLM评估中的应用
- en: •
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Enhancing Interpretability and Transparency: By generating explanations in
    natural language, LLMs become more transparent, allowing users and developers
    to understand the rationale behind specific outputs. This transparency is crucial
    for building trust and facilitating the broader adoption of LLM technologies in
    sensitive or critical applications.'
  id: totrans-529
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提升可解释性和透明度：通过生成自然语言解释，LLM变得更加透明，使用户和开发者能够理解特定输出背后的理由。这种透明度对于建立信任和促进LLM技术在敏感或关键应用中的广泛采用至关重要。
- en: •
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Facilitating Debugging and Model Improvement: Language-based explanations can
    highlight unexpected or erroneous reasoning patterns, serving as a valuable tool
    for debugging and refining LLMs. Understanding why a model produces a particular
    output enables targeted interventions to correct biases, improve accuracy, and
    enhance overall performance.'
  id: totrans-531
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 促进调试和模型改进：基于语言的解释可以突出意外或错误的推理模式，作为调试和改进LLM的宝贵工具。了解模型为何产生特定输出，能够有针对性地干预以纠正偏差，提高准确性，并增强整体性能。
- en: •
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Supporting Ethical AI Practices: Generating explanations for model decisions
    is a step towards accountable AI, allowing for the scrutiny of model behavior
    and the identification of ethical issues such as biases or privacy concerns. It
    supports compliance with regulations and ethical guidelines that demand transparency
    and explainability in AI systems.'
  id: totrans-533
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 支持伦理AI实践：生成模型决策的解释是迈向负责任AI的一步，允许对模型行为进行审查，并识别诸如偏差或隐私问题等伦理问题。它支持符合要求和伦理准则，要求AI系统具备透明度和可解释性。
- en: •
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Improving User Experience: For end-users, especially those without technical
    expertise, language-based explanations demystify AI operations, making LLMs more
    approachable and their outputs more trustworthy. This can significantly improve
    user experience and satisfaction in applications ranging from customer service
    chatbots to AI-assisted decision-making tools.'
  id: totrans-535
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 改善用户体验：对于最终用户，尤其是那些没有技术背景的人，基于语言的解释使AI操作变得更清晰，使LLM更易于接近，其输出更值得信赖。这可以显著提升用户体验和满意度，适用于从客户服务聊天机器人到AI辅助决策工具的各种应用。
- en: 22.2 Techniques and Considerations
  id: totrans-536
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 22.2 技术和考虑因素
- en: •
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Self-Explanation Models: Some LLMs are designed or fine-tuned to generate explanations
    for their own predictions or decisions as part of their output. This self-explanation
    capability requires careful training and validation to ensure that the explanations
    are accurate, relevant, and genuinely reflective of the model’s decision-making
    process.'
  id: totrans-538
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自我解释模型：一些LLMs被设计或微调以生成其自身预测或决策的解释作为其输出的一部分。这种自我解释能力需要经过仔细的训练和验证，以确保解释的准确性、相关性和真正反映模型的决策过程。
- en: •
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Dedicated Explanation Models: Alternatively, a separate model can be trained
    to generate explanations for the outputs of an LLM. This approach allows for flexibility
    and specialization in explanation generation but requires careful coordination
    to ensure that the explanation model accurately captures and communicates the
    reasoning of the primary LLM.'
  id: totrans-540
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 专用解释模型：另一种方法是训练一个单独的模型来生成LLM输出的解释。这种方法允许在解释生成上具有灵活性和专业化，但需要仔细协调，以确保解释模型准确捕捉并传达主要LLM的推理过程。
- en: •
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Evaluation of Explanation Quality: Assessing the quality of language-based
    explanations involves evaluating their accuracy (do they correctly reflect the
    model’s reasoning?), completeness (do they cover all relevant aspects of the decision?),
    and comprehensibility (are they easily understood by humans?). Developing metrics
    and methodologies for this evaluation is an ongoing challenge in the field.'
  id: totrans-542
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解释质量评估：评估基于语言的解释的质量涉及评估其准确性（是否正确反映了模型的推理？）、完整性（是否涵盖了决策的所有相关方面？）和可理解性（是否易于被人类理解？）。为此评估开发指标和方法是该领域的一个持续挑战。
- en: •
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Bias and Misinterpretation: There’s a risk that language-based explanations
    might introduce or perpetuate biases, or be misinterpreted by users. Ensuring
    that explanations are clear, unbiased, and accurately represent the model’s operations
    is crucial.'
  id: totrans-544
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 偏见和误解：存在基于语言的解释可能引入或延续偏见，或被用户误解的风险。确保解释清晰、公正，并准确代表模型的操作至关重要。
- en: 22.3 Challenges
  id: totrans-545
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 22.3 挑战
- en: •
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Complexity of Generating High-Quality Explanations: Producing explanations
    that are both accurate and easily understandable by non-experts is challenging,
    especially for complex decisions or abstract concepts.'
  id: totrans-547
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 生成高质量解释的复杂性：生成既准确又易于非专家理解的解释具有挑战性，特别是对于复杂决策或抽象概念。
- en: •
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Scalability: Generating tailored explanations for every output can be computationally
    intensive, particularly for large-scale or real-time applications.'
  id: totrans-549
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可扩展性：为每个输出生成量身定制的解释可能计算密集，特别是对于大规模或实时应用。
- en: •
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Alignment with Human Reasoning: Ensuring that machine-generated explanations
    align with human reasoning and expectations requires deep understanding of both
    the domain and human communication patterns.'
  id: totrans-551
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与人类推理的一致性：确保机器生成的解释与人类的推理和期望一致，需要对领域和人类沟通模式有深入的理解。
- en: Language-Based Explanations serve as a vital tool for making LLMs more interpretable,
    accountable, and user-friendly. By articulating the reasoning behind their outputs
    in natural language, LLMs can achieve greater transparency, fostering trust and
    enabling more effective human-machine collaboration. Developing effective strategies
    for generating and evaluating these explanations remains a key focus for advancing
    the field of AI interpretability and ethics.
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 基于语言的解释作为一种重要工具，可以使大型语言模型（LLMs）更加可解释、负责任和用户友好。通过以自然语言表达其输出背后的推理，LLMs 可以实现更大的透明度，促进信任并增强人机合作的效果。开发生成和评估这些解释的有效策略仍然是推进人工智能可解释性和伦理领域的关键焦点。
- en: 23 Embedding Space Analysis
  id: totrans-553
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 23 嵌入空间分析
- en: Embedding Space Analysis is an essential method for delving into the high-dimensional
    vector spaces (embeddings) utilized by Large Language Models (LLMs) to represent
    linguistic elements such as words and phrases. This analysis sheds light on the
    semantic and syntactic relationships encoded within these embeddings, offering
    valuable insights into the models’ language processing and representation capabilities.
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入空间分析是一种重要的方法，用于深入研究大型语言模型（LLMs）用于表示语言元素（如单词和短语）的高维向量空间（嵌入）。这种分析揭示了这些嵌入中编码的语义和句法关系，为模型的语言处理和表示能力提供了宝贵的见解。
- en: Liu (2019) delves into latent space cartography, a pioneering approach to mapping
    semantic dimensions within vector space embeddings, which holds significant implications
    for understanding the intricate semantic and syntactic interplay in LLMs. Saul
    (2001) introduces locally linear embedding (LLE), a dimensionality reduction algorithm
    with potential applications in analyzing LLM embedding spaces, suggesting a pathway
    to uncover the underlying structures within these complex models. Further, Almeida
    (2019) and Ruder (2017) offer thorough surveys on word embeddings, a foundational
    component of LLMs’ vector spaces, providing insights into the construction and
    cross-lingual evaluation of word embeddings. These contributions collectively
    underscore the importance of Embedding Space Analysis in unpacking the nuanced
    ways LLMs understand and represent language, highlighting the technique’s role
    in advancing our grasp of artificial linguistic intelligence.
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 刘（2019）深入探讨了潜在空间制图，这是一种开创性的方式，用于在向量空间嵌入中映射语义维度，这对理解大型语言模型（LLMs）中复杂的语义和句法相互作用具有重要意义。索尔（2001）介绍了局部线性嵌入（LLE），这是一种降维算法，具有分析LLM嵌入空间的潜在应用，提供了一条揭示这些复杂模型中潜在结构的路径。此外，阿尔梅达（2019）和鲁德（2017）提供了关于词嵌入的全面调查，词嵌入是LLMs向量空间的基础组成部分，提供了关于词嵌入构建和跨语言评估的见解。这些贡献共同强调了嵌入空间分析在解开LLMs理解和表示语言的细微方式中的重要性，突显了该技术在推进我们对人工语言智能理解中的作用。
- en: 23.1 Application in LLM Evaluation
  id: totrans-556
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 23.1 在LLM评估中的应用
- en: •
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Discovering Semantic Relationships: Embedding space analysis allows for the
    exploration of semantic relationships encoded by the LLM. By examining the distances
    and directions between vectors, researchers can identify clusters of related words
    or phrases, uncover synonyms and antonyms, and even detect more complex relationships
    like analogies.'
  id: totrans-558
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 发现语义关系：嵌入空间分析允许探索LLM编码的语义关系。通过检查向量之间的距离和方向，研究人员可以识别相关词语或短语的簇，发现同义词和反义词，甚至检测更复杂的关系，如类比。
- en: •
  id: totrans-559
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Understanding Model Generalization: The way embeddings are organized within
    the vector space can also offer clues about the model’s ability to generalize
    across different contexts. A well-organized embedding space, where similar concepts
    are grouped together in a consistent manner, suggests that the model has a robust
    understanding of the underlying language structure.'
  id: totrans-560
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 理解模型泛化：向量空间中嵌入的组织方式也可以提供关于模型在不同上下文中泛化能力的线索。一个组织良好的嵌入空间，其中类似的概念以一致的方式分组在一起，表明模型对基础语言结构有着稳健的理解。
- en: •
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Evaluating Contextual Understanding: Modern LLMs, especially those based on
    Transformer architectures, generate context-dependent embeddings. Analyzing these
    context-specific embeddings can reveal how the model’s representation of a word
    changes with its context, highlighting the model’s capacity for nuanced language
    understanding.'
  id: totrans-562
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 评估上下文理解：现代LLMs，特别是基于Transformer架构的模型，生成上下文相关的嵌入。分析这些特定上下文的嵌入可以揭示模型如何根据上下文变化其对单词的表示，突出模型对细微语言理解的能力。
- en: •
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Bias Detection: Embedding spaces can inadvertently capture and amplify biases
    present in the training data. By analyzing embeddings, researchers can detect
    biases in how concepts are represented and related, which is crucial for developing
    more fair and unbiased models.'
  id: totrans-564
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 偏见检测：嵌入空间可能会无意中捕捉并放大训练数据中存在的偏见。通过分析嵌入，研究人员可以检测概念表示和关联中的偏见，这对开发更公平和无偏见的模型至关重要。
- en: 23.2 Techniques and Considerations
  id: totrans-565
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 23.2 技术与考虑事项
- en: •
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Dimensionality Reduction: Given the high-dimensional nature of embeddings,
    dimensionality reduction techniques (such as t-SNE or PCA) are often employed
    to visualize the embedding space in two or three dimensions. This visualization
    can make patterns and relationships more accessible and interpretable.'
  id: totrans-567
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 降维：由于嵌入的高维特性，通常使用降维技术（如t-SNE或PCA）来在二维或三维空间中可视化嵌入空间。这种可视化可以使模式和关系更加易于访问和解释。
- en: •
  id: totrans-568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Cosine Similarity Analysis: Cosine similarity is a common measure used to assess
    the similarity between two vectors in the embedding space. It allows for the quantitative
    comparison of semantic similarity between words or phrases, facilitating the systematic
    exploration of linguistic relationships.'
  id: totrans-569
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 余弦相似度分析：余弦相似度是一种常用的度量方法，用于评估嵌入空间中两个向量之间的相似性。它允许对词语或短语之间的语义相似性进行定量比较，促进了语言关系的系统探索。
- en: •
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Cluster Analysis: Clustering algorithms can identify groups of similar embeddings,
    helping to uncover underlying structures or themes in the data. This analysis
    can highlight how the model categorizes concepts and whether these categorizations
    align with human understanding.'
  id: totrans-571
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 聚类分析：聚类算法可以识别相似的嵌入组，帮助揭示数据中的潜在结构或主题。这种分析可以突出模型如何分类概念，以及这些分类是否与人类理解一致。
- en: •
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Probing Tasks: Probing tasks are designed to directly test specific properties
    of embeddings, such as grammatical tense, number, or entity type. By evaluating
    the model’s performance on these tasks, researchers can assess the depth and specificity
    of the linguistic information captured by the embeddings.'
  id: totrans-573
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 探测任务：探测任务旨在直接测试嵌入的特定属性，例如语法时态、数量或实体类型。通过评估模型在这些任务上的表现，研究人员可以评估嵌入捕获的语言信息的深度和具体性。
- en: 23.3 Challenges
  id: totrans-574
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 23.3 挑战
- en: •
  id: totrans-575
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Interpretability: While embedding space analysis can reveal complex patterns,
    interpreting these patterns and relating them back to model behavior or linguistic
    theory can be challenging. It requires a nuanced understanding of both the model
    architecture and the linguistic phenomena being investigated.'
  id: totrans-576
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可解释性：虽然嵌入空间分析可以揭示复杂的模式，但解释这些模式并将其与模型行为或语言理论联系起来可能具有挑战性。这需要对模型架构和正在研究的语言现象有细致的理解。
- en: •
  id: totrans-577
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'High-Dimensional Complexity: The high-dimensional nature of embeddings means
    that much of the structure and information in the embedding space can be lost
    or obscured when using dimensionality reduction techniques for visualization.'
  id: totrans-578
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 高维复杂性：嵌入的高维特性意味着，当使用降维技术进行可视化时，嵌入空间中的结构和信息可能会丧失或被掩盖。
- en: •
  id: totrans-579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Contextual Embeddings: For models that generate context-dependent embeddings,
    the analysis becomes more complex, as the representation of a word or phrase can
    vary significantly across different contexts. This variability can make it harder
    to draw general conclusions about the model’s linguistic understanding.'
  id: totrans-580
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上下文嵌入：对于生成上下文相关嵌入的模型，分析变得更加复杂，因为词或短语的表示可能在不同上下文中有显著差异。这种变异性使得对模型的语言理解做出普遍结论变得更加困难。
- en: Embedding Space Analysis provides a powerful window into the inner workings
    of LLMs, offering insights into how these models process, understand, and represent
    language. By carefully examining the structures and patterns within embedding
    spaces, researchers and developers can enhance their understanding of LLM capabilities,
    biases, and potential areas for improvement, contributing to the development of
    more sophisticated, fair, and transparent language models.
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入空间分析提供了一个强大的窗口，可以深入了解 LLM 的内部工作机制，揭示这些模型如何处理、理解和表示语言。通过仔细检查嵌入空间中的结构和模式，研究人员和开发人员可以提升对
    LLM 能力、偏见和潜在改进领域的理解，有助于开发更复杂、公正和透明的语言模型。
- en: 24 Computational Efficiency and Resource Utilization of LLMs
  id: totrans-582
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 24 LLM 的计算效率和资源利用
- en: The evaluation of Large Language Models (LLMs) extends beyond their linguistic
    prowess to include critical assessments of computational efficiency and resource
    utilization. Key performance indicators such as memory usage, CPU/GPU utilization,
    and model size are essential for optimizing LLM operations.
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: 对大型语言模型（LLMs）的评估不仅限于其语言能力，还包括计算效率和资源利用的关键评估。内存使用、CPU/GPU 利用率和模型大小等关键性能指标对于优化
    LLM 操作至关重要。
- en: Gao (2002) and Heafield (2013) both contribute to enhancing language model efficiency,
    with Gao underscoring the significance of pruning criteria and Heafield pioneering
    efficient algorithms for language modeling challenges. Chilkuri (2021) introduces
    the Legendre Memory Unit, a novel architecture that markedly decreases the memory
    and computation demands for language modeling. Zhang (2023) shifts the focus to
    the strategic importance of instruction tuning, as opposed to merely increasing
    model size, for improving zero-shot summarization capabilities in LLMs.
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: Gao (2002) 和 Heafield (2013) 都对提高语言模型效率做出了贡献，Gao 强调了修剪标准的重要性，Heafield 开创了应对语言建模挑战的高效算法。Chilkuri
    (2021) 介绍了 Legendre Memory Unit，这是一种显著减少语言建模记忆和计算需求的新型架构。Zhang (2023) 转向关注指令调整的战略重要性，而不仅仅是增加模型大小，以提高
    LLM 的零样本总结能力。
- en: These contributions highlight the ongoing imperative for advancements in the
    computational efficiency and judicious resource use of LLMs, underscoring the
    balance between model performance and operational sustainability.
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: 这些因素突显了在计算效率和资源使用的合理性方面的持续需求，强调了模型性能与运营可持续性之间的平衡。
- en: 24.1 Memory Usage
  id: totrans-586
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 24.1 内存使用
- en: •
  id: totrans-587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Peak Memory Consumption: The maximum amount of RAM required by the model during
    training or inference. This metric is crucial for understanding the scalability
    of the model across different hardware environments.'
  id: totrans-588
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 峰值内存消耗：模型在训练或推理期间所需的最大RAM量。这个指标对理解模型在不同硬件环境中的可扩展性至关重要。
- en: •
  id: totrans-589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Memory Bandwidth Utilization: Measures how efficiently the model uses the available
    memory bandwidth. High bandwidth utilization can indicate optimized memory access
    patterns, crucial for high-performance computing environments.'
  id: totrans-590
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 内存带宽利用率：衡量模型如何高效使用可用内存带宽。高带宽利用率可能表示优化的内存访问模式，对高性能计算环境至关重要。
- en: 24.2 CPU/GPU Usage
  id: totrans-591
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 24.2 CPU/GPU 使用
- en: •
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'CPU/GPU Utilization Percentage: The proportion of CPU or GPU resources utilized
    during model operations. High utilization rates can indicate efficient use of
    hardware resources but may also signal potential bottlenecks if consistently at
    capacity.'
  id: totrans-593
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: CPU/GPU 利用率百分比：模型操作期间CPU或GPU资源的使用比例。高利用率可能表示硬件资源的高效使用，但如果始终处于满负荷状态，也可能表明潜在的瓶颈。
- en: •
  id: totrans-594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'FLOPS (Floating Point Operations Per Second): A measure of the computational
    power used by the model. Higher FLOPS indicate more intensive computation, which
    can be a double-edged sword—indicating either complex model capabilities or inefficiencies
    in computation.'
  id: totrans-595
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: FLOPS（每秒浮点运算次数）：衡量模型使用的计算能力。较高的FLOPS表明更密集的计算，这可能是双刃剑——既表示复杂的模型能力，也可能表明计算效率低下。
- en: •
  id: totrans-596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Inference Time: The time it takes for the model to generate an output given
    an input. Faster inference times are preferred for real-time applications, reflecting
    efficient CPU/GPU usage.'
  id: totrans-597
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 推理时间：模型生成输出所需的时间。实时应用中优先考虑更快的推理时间，这反映了高效的CPU/GPU使用。
- en: 24.3 Size of the Model
  id: totrans-598
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 24.3 模型大小
- en: •
  id: totrans-599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Number of Parameters: Reflects the complexity and potential capacity of the
    model. Larger models, with billions or even trillions of parameters, can capture
    more nuanced patterns but are more demanding in terms of storage and computation.'
  id: totrans-600
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 参数数量：反映了模型的复杂性和潜在能力。具有数十亿甚至数万亿参数的较大模型可以捕捉更细微的模式，但在存储和计算上要求更高。
- en: •
  id: totrans-601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Model Storage Size: The disk space required to store the model. This is directly
    influenced by the number of parameters and the precision of the weights (e.g.,
    using 16-bit vs. 32-bit floating-point numbers).'
  id: totrans-602
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型存储大小：存储模型所需的磁盘空间。这直接受参数数量和权重精度（例如，使用16位与32位浮点数）的影响。
- en: •
  id: totrans-603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Compression Ratio: After model pruning or quantization, the compression ratio
    indicates the efficiency of reducing the model size without significantly impacting
    performance. Higher ratios suggest effective size reduction while maintaining
    model accuracy.'
  id: totrans-604
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 压缩比：经过模型修剪或量化后的压缩比表示在不显著影响性能的情况下减少模型大小的效率。较高的比率表明有效的尺寸缩减，同时保持模型准确性。
- en: 24.4 Energy Consumption
  id: totrans-605
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 24.4 能耗
- en: •
  id: totrans-606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Watts per Inference/Training Hour: Measures the energy required to perform
    a single inference or for an hour of model training. Lower energy consumption
    is desirable for reducing operational costs and environmental impact.'
  id: totrans-607
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每次推理/训练小时的瓦特数：衡量进行单次推理或一小时模型训练所需的能量。较低的能耗有助于降低运营成本和环境影响。
- en: 24.5 Scalability
  id: totrans-608
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 24.5 可扩展性
- en: •
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Parallelization Efficiency: Indicates how well the model training or inference
    scales across multiple CPUs or GPUs. High efficiency means that adding more hardware
    resources proportionally decreases training/inference time.'
  id: totrans-610
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 并行化效率：表示模型训练或推理在多个CPU或GPU上扩展的效果。高效率意味着增加更多硬件资源会按比例减少训练/推理时间。
- en: •
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Batch Processing Capability: The ability of the model to process data in batches
    efficiently, impacting throughput and latency. Larger batch sizes can improve
    throughput but may also increase memory and computational requirements.'
  id: totrans-612
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 批处理能力：模型高效处理数据批次的能力，影响吞吐量和延迟。较大的批次尺寸可以提高吞吐量，但也可能增加内存和计算需求。
- en: Understanding and optimizing these performance metrics are crucial for deploying
    LLMs effectively, especially in resource-constrained environments or applications
    requiring high throughput and low latency.
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
  zh: 理解和优化这些性能指标对于有效部署LLMs至关重要，尤其是在资源有限的环境或需要高吞吐量和低延迟的应用中。
- en: 25 Human Evaluation of LLMs
  id: totrans-614
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 25 人类评估大型语言模型（LLMs）
- en: Human Evaluation stands as an indispensable method for appraising Large Language
    Models (LLMs), complementing automated metrics with the discernment of human judges.
    This process involves evaluators, ranging from experts to general audiences, scrutinizing
    the generated text’s quality, relevance, coherence, and ethical dimensions. Such
    evaluations tap into the subtleties and complexities of language that automated
    systems might miss, emphasizing the importance of subjective judgment and contextual
    understanding.
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
  zh: 人类评估作为评估大型语言模型（LLMs）不可或缺的方法，补充了自动化指标和人类评审的洞察。这一过程涉及从专家到普通观众的评估者，审查生成文本的质量、相关性、连贯性和伦理维度。这些评估触及了自动化系统可能遗漏的语言细微差别和复杂性，强调了主观判断和背景理解的重要性。
- en: Turchi (2013) and Manning (2020) both underscore the significance of human judgment
    in evaluating LLM outputs, highlighting the nuanced insights human evaluators
    bring to the table. Lee (2021) points out the necessity for establishing standardized
    practices in human evaluation to ensure consistency and reliability across assessments.
    Addressing this, An (2023) introduces L-Eval, a framework aimed at standardizing
    the evaluation of long-context language models. This framework proposes a comprehensive
    evaluation suite, advocating for the use of Length-Instruction-Enhanced (LIE)
    evaluation methods and the incorporation of LLM judges, thereby advancing the
    methodologies for human evaluation of LLMs.
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: Turchi (2013) 和 Manning (2020) 都强调了人类判断在评估LLM输出中的重要性，突显了人类评估者所带来的细致见解。Lee (2021)
    指出需要建立标准化的人类评估实践，以确保评估的一致性和可靠性。为此，An (2023) 提出了L-Eval，一个旨在标准化长上下文语言模型评估的框架。该框架提出了一个全面的评估套件，倡导使用长度-指令-增强（LIE）评估方法并引入LLM评审，从而推动了人类评估LLMs的方法学进步。
- en: 25.1 Understanding Human Evaluation
  id: totrans-617
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 25.1 理解人类评估
- en: 'Concept: Human evaluation relies on individuals assessing the outputs of LLMs
    based on criteria such as linguistic quality (grammar, syntax), relevance to a
    prompt, coherence of the text, creativity, and alignment with ethical standards.
    This can involve direct rating scales, comparative assessments, or qualitative
    feedback.'
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: 概念：人类评估依赖于个人根据语言质量（语法、句法）、与提示的相关性、文本的连贯性、创造力和道德标准等标准评估LLM的输出。这可能涉及直接评分、比较评估或定性反馈。
- en: 'Application: Evaluators are typically presented with outputs from the LLM alongside
    tasks or prompts. They might also compare these outputs against a reference standard
    or across different models to gauge performance. The evaluation can be structured
    around specific tasks (e.g., translation, summarization) or more open-ended assessments
    of generative text.'
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: 应用：评估者通常会收到LLM生成的输出以及任务或提示。他们也可能会将这些输出与参考标准或不同模型进行比较，以衡量性能。评估可以围绕具体任务（例如翻译、总结）或对生成文本的更开放式评估来构建。
- en: 25.2 Application in Evaluating LLMs
  id: totrans-620
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 25.2 在评估LLMs中的应用
- en: •
  id: totrans-621
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Qualitative Insights: Human evaluation captures the subtleties of language
    and communication that automated metrics might miss, such as cultural nuances,
    emotional tone, and implicit meanings. This can be particularly important in applications
    like storytelling, content creation, and sensitive communications.'
  id: totrans-622
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 定性洞察：人类评估能够捕捉语言和交流中的微妙之处，这些是自动化指标可能忽略的，例如文化细微差别、情感语调和隐含意义。这在讲故事、内容创作和敏感沟通等应用中尤为重要。
- en: •
  id: totrans-623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Benchmarking Real-World Usability: By assessing how well model-generated text
    meets human expectations and needs, evaluators can determine the model’s readiness
    for real-world applications. This includes understanding user satisfaction and
    potential areas of improvement for better alignment with human users.'
  id: totrans-624
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基准测试现实世界的可用性：通过评估模型生成的文本满足人类期望和需求的程度，评估者可以确定模型在现实世界应用中的准备程度。这包括理解用户满意度和改进领域，以便更好地与人类用户对接。
- en: •
  id: totrans-625
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Identifying Ethical and Societal Impacts: Human judges can evaluate text for
    biases, stereotypes, or potentially harmful content, providing insights into the
    ethical and societal implications of deploying LLMs at scale.'
  id: totrans-626
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 识别伦理和社会影响：人类评审者可以评估文本中的偏见、刻板印象或潜在的有害内容，提供有关大规模部署LLMs的伦理和社会影响的见解。
- en: •
  id: totrans-627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Enhancing Model Training and Development: Feedback from human evaluation can
    guide further model training and refinement, especially in improving the model’s
    handling of complex, nuanced, or culturally specific content.'
  id: totrans-628
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提升模型训练和开发：来自人工评估的反馈可以指导进一步的模型训练和改进，特别是在提升模型处理复杂、微妙或文化特定内容方面的能力。
- en: 25.3 Challenges and Considerations
  id: totrans-629
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 25.3 挑战与考虑
- en: •
  id: totrans-630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Subjectivity and Variability: Human judgments can vary significantly between
    individuals, influenced by personal experiences, cultural backgrounds, and subjective
    preferences. Establishing consistent evaluation criteria and training evaluators
    can help mitigate this variability.'
  id: totrans-631
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 主观性和变异性：人类判断可能因个人经历、文化背景和主观偏好而大相径庭。建立一致的评估标准和培训评估人员可以帮助减少这种变异性。
- en: •
  id: totrans-632
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Scalability and Cost: Human evaluation is resource-intensive, requiring significant
    time and effort from skilled individuals. Balancing thoroughness with practical
    constraints is a key challenge, especially for large-scale models and datasets.'
  id: totrans-633
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可扩展性和成本：人工评估资源密集，需要大量时间和熟练人员的努力。平衡全面性与实际约束是一个关键挑战，尤其是对于大规模模型和数据集。
- en: •
  id: totrans-634
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Bias and Fairness: Evaluators’ biases can influence their assessments, potentially
    introducing subjective biases into the evaluation process. Diverse and representative
    panels of evaluators can help address this concern.'
  id: totrans-635
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 偏见与公平性：评估者的偏见可能会影响他们的评估，可能将主观偏见引入评估过程。多样化和具有代表性的评估小组可以帮助解决这一问题。
- en: •
  id: totrans-636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Integration with Automated Metrics: For a comprehensive evaluation, human assessments
    should be integrated with automated metrics, balancing the depth of human insight
    with the scalability and consistency of automated evaluations.'
  id: totrans-637
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与自动化指标的集成：为了全面评估，人工评估应与自动化指标集成，平衡人工洞察的深度与自动化评估的可扩展性和一致性。
- en: 26 Conclusion and Future Work
  id: totrans-638
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 26 结论与未来工作
- en: Our investigation into evaluation methodologies for Large Language Models (LLMs)
    underscores the critical need for transparent, understandable, and ethical AI
    systems, particularly within educational contexts such as the AI for Education
    Project (AI4ED) at Northeastern University. This initiative exemplifies the potential
    of AI to revolutionize educational practices by providing adaptive and personalized
    learning experiences.
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对大型语言模型（LLMs）评估方法的调查突显了对透明、易懂和伦理的人工智能系统的关键需求，特别是在教育背景下，如东北大学的教育人工智能项目（AI4ED）。这一倡议展示了人工智能在提供适应性和个性化学习体验方面彻底改变教育实践的潜力。
- en: 'Key points from our study include:'
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究的关键点包括：
- en: •
  id: totrans-641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'LLMMaps: This innovative visualization technique offers a nuanced evaluation
    of LLMs across various NLP subfields, highlighting performance strengths and areas
    needing improvement, with a focus on reducing hallucinations.'
  id: totrans-642
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LLMMaps：这种创新的可视化技术提供了对LLMs在各个自然语言处理（NLP）子领域的细致评估，突出表现的优点和需要改进的领域，重点减少幻觉现象。
- en: •
  id: totrans-643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Benchmarking and Leaderboards: These tools provide systematic assessments of
    LLM performance on extensive Q&A datasets, promoting competition and progress
    in model development.'
  id: totrans-644
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基准测试和排行榜：这些工具系统地评估大型语言模型（LLM）在广泛问答数据集上的表现，促进了模型开发中的竞争和进步。
- en: •
  id: totrans-645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Stratified Analysis: This method dissects LLM performance into distinct layers
    or strata, enabling detailed insights into model strengths and weaknesses across
    different knowledge subfields.'
  id: totrans-646
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 分层分析：这种方法将LLM性能分解为不同的层次或层级，提供对模型在不同知识子领域的优缺点的详细见解。
- en: •
  id: totrans-647
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Visualization of Bloom’s Taxonomy: This approach visualizes model performance
    across cognitive skill levels, aiding in the assessment of LLM capabilities in
    handling tasks of varying complexity.'
  id: totrans-648
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 布卢姆分类法的可视化：这种方法可视化模型在认知技能水平上的表现，帮助评估LLM在处理不同复杂任务的能力。
- en: •
  id: totrans-649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Hallucination Score: This metric measures the frequency and severity of hallucinations
    in LLM outputs, guiding efforts to mitigate inaccuracies and enhance model reliability.'
  id: totrans-650
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 幻觉评分：该指标衡量LLM输出中幻觉的频率和严重性，指导减轻不准确性和增强模型可靠性的努力。
- en: •
  id: totrans-651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Knowledge Stratification Strategy: This method organizes Q&A datasets into
    hierarchical knowledge structures, facilitating detailed analysis of LLM performance
    across various levels of complexity and domain specificity.'
  id: totrans-652
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 知识分层策略：这种方法将问答数据集组织成层级知识结构，便于对LLM在不同复杂性和领域特定性层次上的性能进行详细分析。
- en: •
  id: totrans-653
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Utilization of Machine Learning Models for Hierarchy Generation: This approach
    employs machine learning algorithms to classify and arrange questions into coherent
    hierarchies, enhancing systematic LLM evaluation.'
  id: totrans-654
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 机器学习模型用于层次生成：这种方法利用机器学习算法将问题分类并排列成连贯的层次结构，从而增强系统化的LLM评估。
- en: •
  id: totrans-655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Sensitivity Analysis: This technique assesses LLM responsiveness to input variations,
    revealing insights into model robustness and decision-making patterns.'
  id: totrans-656
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 敏感性分析：这种技术评估LLM对输入变化的响应，揭示模型鲁棒性和决策模式的见解。
- en: •
  id: totrans-657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Feature Importance Methods: These methods pinpoint crucial input features influencing
    model outputs, enhancing transparency and guiding model improvement efforts.'
  id: totrans-658
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 特征重要性方法：这些方法确定影响模型输出的关键输入特征，增强透明度并指导模型改进工作。
- en: •
  id: totrans-659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Shapley Values: Derived from cooperative game theory, Shapley values provide
    a fair and robust measure of individual input feature contributions, offering
    deep insights into LLM decision-making processes.'
  id: totrans-660
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Shapley值：源于合作博弈论，Shapley值提供了一个公平且稳健的单个输入特征贡献度量，深入洞察LLM的决策过程。
- en: •
  id: totrans-661
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Attention Visualization: This technique elucidates how LLMs allocate importance
    to various input elements, enhancing understanding of model focus and decision-making
    strategies.'
  id: totrans-662
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意力可视化：这种技术阐明LLM如何分配对各种输入元素的重要性，增强对模型焦点和决策策略的理解。
- en: •
  id: totrans-663
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Counterfactual Explanations: This method explores how slight input modifications
    affect model outputs, revealing underlying causal mechanisms and enhancing transparency.'
  id: totrans-664
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 反事实解释：这种方法探讨轻微输入修改如何影响模型输出，揭示潜在的因果机制并增强透明度。
- en: •
  id: totrans-665
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Language-Based Explanations: These explanations translate LLM decision-making
    processes into natural language, making model outputs more understandable and
    accessible.'
  id: totrans-666
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于语言的解释：这些解释将LLM的决策过程转化为自然语言，使模型输出更易于理解和获取。
- en: •
  id: totrans-667
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Embedding Space Analysis: This method examines high-dimensional vector spaces
    used by LLMs to represent linguistic elements, offering insights into semantic
    and syntactic relationships.'
  id: totrans-668
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 嵌入空间分析：这种方法检查LLM用于表示语言元素的高维向量空间，提供关于语义和句法关系的见解。
- en: •
  id: totrans-669
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Computational Efficiency and Resource Utilization: Key performance indicators
    such as memory usage, CPU/GPU utilization, and model size are crucial for optimizing
    LLM operations.'
  id: totrans-670
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 计算效率和资源利用：关键性能指标如内存使用、CPU/GPU利用率和模型大小对于优化LLM操作至关重要。
- en: •
  id: totrans-671
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Human Evaluation: Involving human judges to assess LLM outputs provides qualitative
    insights that complement automated metrics, capturing nuances and ethical considerations.'
  id: totrans-672
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 人工评估：涉及人工评审者评估LLM输出，提供补充自动化指标的定性见解，捕捉细微差别和伦理考虑。
- en: Future work should prioritize the evaluation of these methodologies within AI4ED,
    focusing on their applicability and effectiveness in educational settings. Additionally,
    there is a pressing need for further research on visualizing these evaluation
    techniques in a manner that is accessible to students, administrators, and faculty
    alike. By bridging the gap between complex AI technologies and their practical
    application in education, we can foster a deeper understanding and integration
    of AI tools in enhancing learning outcomes, aligning with Northeastern University’s
    mission to lead in innovative educational methodologies.
  id: totrans-673
  prefs: []
  type: TYPE_NORMAL
  zh: 未来的工作应优先考虑在AI4ED中评估这些方法，重点关注其在教育环境中的适用性和有效性。此外，亟需进一步研究如何以学生、管理员和教职工都能理解的方式可视化这些评估技术。通过弥合复杂AI技术与教育实际应用之间的差距，我们可以促进对AI工具在提升学习成果中的更深刻理解和整合，与东北大学在创新教育方法上的使命相一致。
- en: References
  id: totrans-674
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Almeida, M. (2019). Word embeddings: A survey. Computer Speech & Language.'
  id: totrans-675
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Almeida, M. (2019). 词嵌入：综述。计算机语音与语言。'
- en: '[2] Alvarez-Melis, D., & Jaakkola, T. (2018). On the Robustness of Interpretability
    Methods. arXiv preprint arXiv:1806.08049.'
  id: totrans-676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Alvarez-Melis, D., & Jaakkola, T. (2018). 关于解释性方法的鲁棒性。arXiv 预印本 arXiv:1806.08049。'
- en: '[3] Annett, J. (2013). Transfer of Training: A Review of Research and Practical
    Implications. Human Resource Management.'
  id: totrans-677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Annett, J. (2013). 培训转移：研究回顾及实际应用。人力资源管理。'
- en: '[4] Bellamy, R., Dey, K., & Kannan, K. (2018). AI Fairness 360: An Extensible
    Toolkit for Detecting, Understanding, and Mitigating Unwanted Algorithmic Bias.
    Proceedings of the 2018 Conference on Fairness, Accountability, and Transparency.'
  id: totrans-678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Bellamy, R.，Dey, K.，& Kannan, K.（2018）。AI Fairness 360：一个可扩展的工具包，用于检测、理解和减轻不希望的算法偏差。2018年公平性、问责制和透明度会议论文集。'
- en: '[5] Bimbot, F. (1997). An alternative scheme for perplexity estimation. Interspeech.'
  id: totrans-679
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Bimbot, F.（1997）。困惑度估计的替代方案。Interspeech。'
- en: '[6] Bimbot, F., & Allauzen, A. (2001). An alternative scheme for perplexity
    estimation and its assessment for the evaluation of language models. Interspeech.'
  id: totrans-680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Bimbot, F.，& Allauzen, A.（2001）。困惑度估计的替代方案及其在语言模型评估中的应用。Interspeech。'
- en: '[7] Blagec, K., & Schlangen, D. (2022). A global analysis of metrics used for
    measuring performance in natural language processing. arXiv preprint arXiv:2201.01152.'
  id: totrans-681
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Blagec, K.，& Schlangen, D.（2022）。自然语言处理性能度量指标的全球分析。arXiv 预印本 arXiv:2201.01152。'
- en: '[8] Box, G. E. P. (1976). Robustness in the Strategy of Scientific Model Building.
    In Robustness in Statistics.'
  id: totrans-682
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Box, G. E. P.（1976）。科学模型建造策略中的鲁棒性。在《统计学中的鲁棒性》一书中。'
- en: '[9] Brown, T. B., Mann, B., & Ryder, N. (2020). Language Models are Few-Shot
    Learners. arXiv preprint arXiv:2005.14165.'
  id: totrans-683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Brown, T. B.，Mann, B.，& Ryder, N.（2020）。语言模型是少样本学习者。arXiv 预印本 arXiv:2005.14165。'
- en: '[10] Bruner, J. S., & Postman, L. (1957). On the perception of incongruity:
    A paradigm. Journal of Personality.'
  id: totrans-684
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Bruner, J. S.，& Postman, L.（1957）。不一致感知：一种范式。个性心理学杂志。'
- en: '[11] Caton, S., & Haas, C. (2020). Fairness in Machine Learning: A Survey.
    arXiv preprint arXiv:2010.04053.'
  id: totrans-685
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Caton, S.，& Haas, C.（2020）。机器学习中的公平性：一项调查。arXiv 预印本 arXiv:2010.04053。'
- en: '[12] Chen, P.-Y., & Hsieh, C.-Y. (2020). Holistic Adversarial Robustness of
    Deep Learning Models. arXiv preprint arXiv:2002.03418.'
  id: totrans-686
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] 陈佩毅，& 谢志勇。（2020）。深度学习模型的整体对抗鲁棒性。arXiv 预印本 arXiv:2002.03418。'
- en: '[13] Cheng, Y., & Xie, L. (2019). Few-shot Learning with Meta Metric Learners.
    arXiv preprint arXiv:1911.12264.'
  id: totrans-687
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] 程艳，& 谢琳。（2019）。基于元度量学习者的少样本学习。arXiv 预印本 arXiv:1911.12264。'
- en: '[14] Corbett-Davies, S., & Goel, S. (2018). The Measure and Mismeasure of Fairness:
    A Critical Review of Fair Machine Learning. Communications of the ACM.'
  id: totrans-688
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Corbett-Davies, S.，& Goel, S.（2018）。公平性的衡量与误测：对公平机器学习的批判性审查。ACM 通讯。'
- en: '[15] Critchlow, D. E. (1990). Probability models on rankings. Journal of Classification.'
  id: totrans-689
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Critchlow, D. E.（1990）。排名上的概率模型。分类学杂志。'
- en: '[16] Dinakarrao, S. M. P., & Prasad, M. (2021). Efficient Utilization of Adversarial
    Training towards Robust Machine Learners and its Analysis. arXiv preprint arXiv:2103.15285.'
  id: totrans-690
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Dinakarrao, S. M. P.，& Prasad, M.（2021）。有效利用对抗训练提升鲁棒机器学习者及其分析。arXiv 预印本
    arXiv:2103.15285。'
- en: '[17] Donovan, P., & Radosevich, D. J. (2001). The learning transfer system
    approach to estimating the benefits of training: Empirical evidence. Journal of
    Applied Psychology.'
  id: totrans-691
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Donovan, P.，& Radosevich, D. J.（2001）。学习转移系统方法用于估计培训的效益：实证证据。应用心理学杂志。'
- en: '[18] Dong, Y., & Liao, F. (2020). Benchmarking Adversarial Robustness. arXiv
    preprint arXiv:2010.04825.'
  id: totrans-692
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Dong, Y.，& Liao, F.（2020）。对抗鲁棒性的基准测试。arXiv 预印本 arXiv:2010.04825。'
- en: '[19] Ford, N., & Gilmer, J. (2019). Adversarial Examples Are a Natural Consequence
    of Test Error in Noise. arXiv preprint arXiv:1906.09555.'
  id: totrans-693
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Ford, N.，& Gilmer, J.（2019）。对抗样本是噪声测试误差的自然结果。arXiv 预印本 arXiv:1906.09555。'
- en: '[20] Francopoulo, G., & George, M. (2008). Lexical Markup Framework (LMF) for
    NLP Multilingual Resources. Language Resources and Evaluation.'
  id: totrans-694
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Francopoulo, G.，& George, M.（2008）。用于NLP多语言资源的词汇标记框架（LMF）。语言资源与评估。'
- en: '[21] Gao, F., & Liu, Z. (2022). SKILL: Structured Knowledge Infusion for Large
    Language Models. Proceedings of the 2022 Conference of the North American Chapter
    of the Association for Computational Linguistics: Human Language Technologies.'
  id: totrans-695
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] Gao, F.，& Liu, Z.（2022）。SKILL：大规模语言模型的结构化知识注入。2022年北美计算语言学协会人类语言技术会议论文集。'
- en: '[22] Gao, F., & Zhu, Z. (2023). Large Language Models on Wikipedia-Style Survey
    Generation: An Evaluation in NLP Concepts. arXiv preprint arXiv:2305.13687.'
  id: totrans-696
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Gao, F.，& Zhu, Z.（2023）。维基百科风格的调查生成中的大规模语言模型：NLP概念的评估。arXiv 预印本 arXiv:2305.13687。'
- en: '[23] Golland, P., & Fischl, B. (2003). Permutation Tests for Classification:
    Towards Statistical Significance in Image-Based Studies. IEEE Transactions on
    Medical Imaging.'
  id: totrans-697
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] Golland, P.，& Fischl, B.（2003）。分类的置换检验：图像研究中的统计显著性。IEEE 医学影像学会刊。'
- en: '[24] Gou, Z., & Wang, W. (2023). CRITIC: Large Language Models Can Self-Correct
    with Tool-Interactive Critiquing. arXiv preprint arXiv:2301.13768.'
  id: totrans-698
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Gou, Z., & Wang, W. (2023). CRITIC：大型语言模型可以通过工具互动批评进行自我修正。arXiv预印本 arXiv:2301.13768。'
- en: '[25] Goyal, S., & Gupta, P. (2021). A Survey of Adversarial Defences and Robustness
    in NLP. arXiv preprint arXiv:2104.08654.'
  id: totrans-699
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Goyal, S., & Gupta, P. (2021). 对抗防御和NLP鲁棒性的调查。arXiv预印本 arXiv:2104.08654。'
- en: '[26] Grosse, K., & Papernot, N. (2017). On the (Statistical) Detection of Adversarial
    Examples. arXiv preprint arXiv:1702.06280.'
  id: totrans-700
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Grosse, K., & Papernot, N. (2017). 对对抗样本的（统计）检测。arXiv预印本 arXiv:1702.06280。'
- en: '[27] Goel, K., & Swayamdipta, S. (2021). Robustness Gym: Unifying the NLP Evaluation
    Landscape. Proceedings of the 59th Annual Meeting of the Association for Computational
    Linguistics.'
  id: totrans-701
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Goel, K., & Swayamdipta, S. (2021). 鲁棒性健身房：统一NLP评估领域。第59届计算语言学协会年会会议记录。'
- en: '[28] Hajian, S., & Meyer, G. (2020). Transfer of Learning and Teaching: A Review
    of Transfer Theories and Effective Instructional Practices. Journal of Education.'
  id: totrans-702
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] Hajian, S., & Meyer, G. (2020). 学习和教学的转移：对转移理论和有效教学实践的回顾。教育杂志。'
- en: '[29] Hassan, M. M., & Succi, G. (2020). Testability and Software Robustness:
    A Systematic Literature Review. Journal of Systems and Software.'
  id: totrans-703
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Hassan, M. M., & Succi, G. (2020). 可测试性和软件鲁棒性：系统文献综述。系统与软件杂志。'
- en: '[30] Hothorn, T., & Lausen, B. (2006). A Lego System for Conditional Inference.
    Journal of Computational and Graphical Statistics.'
  id: totrans-704
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Hothorn, T., & Lausen, B. (2006). 用于条件推断的乐高系统。计算与图形统计学杂志。'
- en: '[31] Huang, B., & Fu, W. (2019). Analytical robustness assessment for robust
    design. Computers & Operations Research.'
  id: totrans-705
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Huang, B., & Fu, W. (2019). 针对稳健设计的分析鲁棒性评估。计算机与运筹研究。'
- en: '[32] Huang, X., & Wang, J. (2023). A Survey of Safety and Trustworthiness of
    Large Language Models through the Lens of Verification and Validation. arXiv preprint
    arXiv:2302.06164.'
  id: totrans-706
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] Huang, X., & Wang, J. (2023). 从验证和验证的视角审视大型语言模型的安全性和可信度。arXiv预印本 arXiv:2302.06164。'
- en: '[33] Jiang, W., & Liang, L. (2019). Multi-Scale Metric Learning for Few-Shot
    Learning. arXiv preprint arXiv:1905.13544.'
  id: totrans-707
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] Jiang, W., & Liang, L. (2019). 用于少样本学习的多尺度度量学习。arXiv预印本 arXiv:1905.13544。'
- en: '[34] Karabacak, M., & Etemad, A. (2023). Embracing Large Language Models for
    Medical Applications: Opportunities and Challenges. arXiv preprint arXiv:2305.11167.'
  id: totrans-708
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] Karabacak, M., & Etemad, A. (2023). 拥抱大型语言模型用于医疗应用：机遇与挑战。arXiv预印本 arXiv:2305.11167。'
- en: '[35] Kim, S.-W., & Lee, J. (2020). Validation of an evaluation model for learning
    management systems. Computers & Education.'
  id: totrans-709
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] Kim, S.-W., & Lee, J. (2020). 学习管理系统评估模型的验证。计算机与教育。'
- en: '[36] Liao, Q., & Binns, R. (2023). AI Transparency in the Age of LLMs: A Human-Centered
    Research Roadmap. arXiv preprint arXiv:2303.08232.'
  id: totrans-710
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] Liao, Q., & Binns, R. (2023). 在LLMs时代的AI透明性：以人为本的研究路线图。arXiv预印本 arXiv:2303.08232。'
- en: '[37] Liu, Y., & Zhang, Y. (2019). Latent space cartography: A method for describing
    semantic dimensions in high-dimensional data. Journal of Machine Learning Research.'
  id: totrans-711
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] Liu, Y., & Zhang, Y. (2019). 潜在空间制图：描述高维数据中的语义维度的方法。机器学习研究杂志。'
- en: '[38] Liu, Z., & Park, D. (2023). Evaluating Large Language Models for Radiology
    Natural Language Processing. arXiv preprint arXiv:2305.12485.'
  id: totrans-712
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] Liu, Z., & Park, D. (2023). 评估大型语言模型在放射学自然语言处理中的表现。arXiv预印本 arXiv:2305.12485。'
- en: '[39] Liu, Y., & Wang, T. (2023). Trustworthy LLMs: A Survey and Guideline for
    Evaluating Large Language Models’ Alignment. arXiv preprint arXiv:2301.06422.'
  id: totrans-713
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] Liu, Y., & Wang, T. (2023). 可信赖的LLMs：评估大型语言模型对齐的调查与指南。arXiv预印本 arXiv:2301.06422。'
- en: '[40] Maegaard, B., & Choukri, K. (2007). Evaluation of NLP systems. Language
    Resources and Evaluation.'
  id: totrans-714
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] Maegaard, B., & Choukri, K. (2007). NLP系统评估。语言资源与评估。'
- en: '[41] Mekala, D., & Dingliwal, M. (2021). ZEROTOP: Zero-Shot Task-Oriented Semantic
    Parsing using Large Language Models. arXiv preprint arXiv:2109.07098.'
  id: totrans-715
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] Mekala, D., & Dingliwal, M. (2021). ZEROTOP：使用大型语言模型的零样本任务导向语义解析。arXiv预印本
    arXiv:2109.07098。'
- en: '[42] Meng, Y., & He, D. (2022). Generating Training Data with Language Models:
    Towards Zero-Shot Language Understanding. arXiv preprint arXiv:2204.01232.'
  id: totrans-716
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] Meng, Y., & He, D. (2022). 使用语言模型生成训练数据：迈向零样本语言理解。arXiv预印本 arXiv:2204.01232。'
- en: '[43] Miaschi, A., & Brunato, D. (2021). What Makes My Model Perplexed? A Linguistic
    Investigation on Neural Language Models Perplexity. In Proceedings of the 2021
    Conference on Empirical Methods in Natural Language Processing (EMNLP).'
  id: totrans-717
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] Miaschi, A., & Brunato, D. (2021). 什么使我的模型感到困惑？对神经语言模型困惑度的语言学调查。见于2021年自然语言处理实证方法会议（EMNLP）的会议记录。'
- en: '[44] Mehrabi, N., & Morstatter, F. (2019). A Survey on Bias and Fairness in
    Machine Learning. arXiv preprint arXiv:1908.09635.'
  id: totrans-718
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] Mehrabi, N., & Morstatter, F. (2019). 机器学习中的偏见与公平性调查。arXiv 预印本 arXiv:1908.09635。'
- en: '[45] Neal, J., & Liu, H. (2021). An Evaluation Methodology for Natural Language
    Processing Systems. arXiv preprint arXiv:2101.01026.'
  id: totrans-719
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] Neal, J., & Liu, H. (2021). 自然语言处理系统的评估方法论。arXiv 预印本 arXiv:2101.01026。'
- en: '[46] Nguyen, C. V., & Tay, Y. (2020). LEEP: A New Measure to Evaluate Transferability
    of Learned Representations. arXiv preprint arXiv:2003.04271.'
  id: totrans-720
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] Nguyen, C. V., & Tay, Y. (2020). LEEP：评估学习表示的可转移性的新度量。arXiv 预印本 arXiv:2003.04271。'
- en: '[47] Olsen, J. H. Jr., & McAllister, S. M. (2016). The Evaluation and Enhancement
    of Training Transfer. Journal of Applied Psychology.'
  id: totrans-721
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] Olsen, J. H. Jr., & McAllister, S. M. (2016). 培训转移的评估与增强。应用心理学杂志。'
- en: '[48] Oreshkin, B. N., & Ollivier, Y. (2018). TADAM: Task Dependent Adaptive
    Metric for Improved Few-Shot Learning. arXiv preprint arXiv:1805.10123.'
  id: totrans-722
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] Oreshkin, B. N., & Ollivier, Y. (2018). TADAM：改进少样本学习的任务依赖自适应度量。arXiv
    预印本 arXiv:1805.10123。'
- en: '[49] Peng, B., & Li, J. (2020). Few-shot Natural Language Generation for Task-Oriented
    Dialog. arXiv preprint arXiv:2010.06215.'
  id: totrans-723
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] Peng, B., & Li, J. (2020). 面向任务的对话的少样本自然语言生成。arXiv 预印本 arXiv:2010.06215。'
- en: '[50] Peng, B., & Poesia, G. (2023). Check Your Facts and Try Again: Improving
    Large Language Models with External Knowledge and Automated Feedback. arXiv preprint
    arXiv:2304.12421.'
  id: totrans-724
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] Peng, B., & Poesia, G. (2023). 检查你的事实并再试一次：通过外部知识和自动反馈改进大型语言模型。arXiv 预印本
    arXiv:2304.12421。'
- en: '[51] Pessach, D., & Shmueli, E. (2022). Algorithmic Fairness. arXiv preprint
    arXiv:2201.11667.'
  id: totrans-725
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] Pessach, D., & Shmueli, E. (2022). 算法公平性。arXiv 预印本 arXiv:2201.11667。'
- en: '[52] Pimm, C., & Sanders, L. (2017). Natural Language Processing (NLP) tools
    for the analysis of incident and accident reports. Safety Science.'
  id: totrans-726
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] Pimm, C., & Sanders, L. (2017). 自然语言处理（NLP）工具用于分析事件和事故报告。安全科学。'
- en: '[53] Puchert, P., & Kirchhoff, T. (2023). LLMMaps: A Visual Metaphor for Stratified
    Evaluation of Large Language Models. arXiv preprint arXiv:2303.13562.'
  id: totrans-727
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] Puchert, P., & Kirchhoff, T. (2023). LLMMaps：用于分层评估大型语言模型的视觉隐喻。arXiv 预印本
    arXiv:2303.13562。'
- en: '[54] Puri, R., & Catanzaro, B. (2019). Zero-shot Text Classification With Generative
    Language Models. arXiv preprint arXiv:1906.08301.'
  id: totrans-728
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] Puri, R., & Catanzaro, B. (2019). 使用生成语言模型的零样本文本分类。arXiv 预印本 arXiv:1906.08301。'
- en: '[55] Ruder, S., & Peters, M. (2017). A survey on word embeddings. arXiv preprint
    arXiv:1706.05020.'
  id: totrans-729
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] Ruder, S., & Peters, M. (2017). 词嵌入的调查。arXiv 预印本 arXiv:1706.05020。'
- en: '[56] Saul, L. K., & Roweis, S. T. (2001). Locally linear embedding for analyzing
    high-dimensional data. Science.'
  id: totrans-730
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] Saul, L. K., & Roweis, S. T. (2001). 用于分析高维数据的局部线性嵌入。科学。'
- en: '[57] Simon, C., & Lampert, C. (2020). Adaptive Subspaces for Few-Shot Learning.
    arXiv preprint arXiv:2006.07889.'
  id: totrans-731
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] Simon, C., & Lampert, C. (2020). 少样本学习的自适应子空间。arXiv 预印本 arXiv:2006.07889。'
- en: '[58] Sundareswara, R., & Schrater, P. (2008). Perceptual multistability predicted
    by search model for Bayesian decisions. Journal of Vision.'
  id: totrans-732
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] Sundareswara, R., & Schrater, P. (2008). 由贝叶斯决策的搜索模型预测的感知多稳定性。视觉杂志。'
- en: '[59] Tang, W., & Wang, J. (2020). Interpretable Time-series Classification
    on Few-shot Samples. arXiv preprint arXiv:2007.13855.'
  id: totrans-733
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] Tang, W., & Wang, J. (2020). 对少样本的可解释时间序列分类。arXiv 预印本 arXiv:2007.13855。'
- en: '[60] Tang, L., & Xu, Y. (2023). Evaluating Large Language Models on Medical
    Evidence Summarization. arXiv preprint arXiv:2303.10486.'
  id: totrans-734
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] Tang, L., & Xu, Y. (2023). 在医学证据摘要上评估大型语言模型。arXiv 预印本 arXiv:2303.10486。'
- en: '[61] Triantafillou, E., & Zemel, R. (2021). Few-shot Learning Through an Information
    Retrieval Lens. arXiv preprint arXiv:2102.06620.'
  id: totrans-735
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] Triantafillou, E., & Zemel, R. (2021). 通过信息检索视角的少样本学习。arXiv 预印本 arXiv:2102.06620。'
- en: '[62] Wang, W., & Ji, Z. (2021). Adversarial GLUE: A Multi-Task Benchmark for
    Robustness Evaluation of Language Models. arXiv preprint arXiv:2109.07359.'
  id: totrans-736
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] Wang, W., & Ji, Z. (2021). 对抗性GLUE：一种用于语言模型鲁棒性评估的多任务基准。arXiv 预印本 arXiv:2109.07359。'
- en: '[63] Wang, W., & Zhou, L. (2022). A Survey on Adversarial Attacks and Defenses
    in Text. arXiv preprint arXiv:2203.04995.'
  id: totrans-737
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] Wang, W., & Zhou, L. (2022). 关于文本中的对抗攻击与防御的调查。arXiv 预印本 arXiv:2203.04995。'
- en: '[64] Zhao, X., & Lau, J. H. (2020). Pre-trained Language Models Can be Fully
    Zero-Shot Learners. arXiv preprint arXiv:2011.10566.'
  id: totrans-738
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] Zhao, X., & Lau, J. H. (2020). 预训练语言模型可以完全成为零样本学习者。arXiv 预印本 arXiv:2011.10566。'
- en: '[65] Zhong, R., & Tang, J. (2021). Adapting Language Models for Zero-shot Learning
    by Meta-tuning on Dataset and Prompt Collections. arXiv preprint arXiv:2106.01769.'
  id: totrans-739
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] Zhong, R., & Tang, J. (2021). 通过在数据集和提示集合上的元调优来适应语言模型进行零样本学习。arXiv 预印本
    arXiv:2106.01769。'
- en: '[66] Zhu, Z., & Gupta, A. (2020). Transfer Learning in Deep Reinforcement Learning:
    A Survey. IEEE Transactions on Neural Networks and Learning Systems.'
  id: totrans-740
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] 朱智华，& 古普塔，A. (2020)。深度强化学习中的迁移学习：一项综述。IEEE神经网络与学习系统汇刊。'
