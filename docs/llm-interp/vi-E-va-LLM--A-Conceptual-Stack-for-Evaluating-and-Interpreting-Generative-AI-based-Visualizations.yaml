- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 17:34:55'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 17:34:55
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: vi(E)va LLM! A Conceptual Stack for Evaluating and Interpreting Generative AI-based
    Visualizations
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: vi(E)va LLM! 一种用于评估和解释基于生成 AI 的可视化的概念框架
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2402.02167](https://ar5iv.labs.arxiv.org/html/2402.02167)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2402.02167](https://ar5iv.labs.arxiv.org/html/2402.02167)
- en: \useunder
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \useunder
- en: \ul \BibtexOrBiblatex\electronicVersion\PrintedOrElectronic
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: \ul \BibtexOrBiblatex\electronicVersion\PrintedOrElectronic
- en: L. Podo¹\orcid0000-0001-8780-6848, M. Ishmal¹ and M. Angelini^(2,1)\orcid0000-0001-9051-6972
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: L. Podo¹\orcid0000-0001-8780-6848, M. Ishmal¹ 和 M. Angelini^(2,1)\orcid0000-0001-9051-6972
- en: ¹Sapienza University of Rome, Italy ²Link Campus University, Rome, Italy
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ¹罗马萨皮恩扎大学，意大利 ²连线校园大学，罗马，意大利
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: The automatic generation of visualizations is an old task that, through the
    years, has shown more and more interest from the research and practitioner communities.
    Recently, large language models (LLM) have become an interesting option for supporting
    generative tasks related to visualization, demonstrating initial promising results.
    At the same time, several pitfalls, like the multiple ways of instructing an LLM
    to generate the desired result, the different perspectives leading the generation
    (code-based, image-based, grammar-based), and the presence of hallucinations even
    for the visualization generation task, make their usage less affordable than expected.
    Following similar initiatives for benchmarking LLMs, this paper copes with the
    problem of modeling the evaluation of a generated visualization through an LLM.
    We propose a theoretical evaluation stack, EvaLLM, that decomposes the evaluation
    effort in its atomic components, characterizes their nature, and provides an overview
    of how to implement and interpret them. We also designed and implemented an evaluation
    platform that provides a benchmarking resource for the visualization generation
    task. The platform supports automatic and manual scoring conducted by multiple
    assessors to support a fine-grained and semantic evaluation based on the EvaLLM
    stack. Two case studies on GPT3.5-turbo with Code Interpreter and Llama2-70-b
    models show the benefits of EvaLLM and illustrate interesting results on the current
    state-of-the-art LLM-generated visualizations.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化的自动生成是一个古老的任务，随着时间的推移，越来越受到研究界和实践界的关注。最近，大型语言模型（LLM）已成为支持与可视化相关的生成任务的有趣选择，显示出初步的良好结果。同时，多个挑战，如指导
    LLM 生成所需结果的多种方式、生成过程中的不同视角（基于代码、基于图像、基于语法）以及即使在可视化生成任务中也存在的幻觉，使得其使用比预期的更具挑战性。继类似的
    LLM 基准测试计划之后，本文处理了通过 LLM 对生成的可视化进行评估的问题。我们提出了一个理论评估框架 EvaLLM，分解评估工作中的原子组件，描述它们的性质，并提供了如何实施和解释它们的概述。我们还设计并实现了一个评估平台，为可视化生成任务提供了基准资源。该平台支持由多个评估人员进行的自动和手动评分，以基于
    EvaLLM 框架支持精细化和语义化的评估。两个关于 GPT3.5-turbo 代码解释器和 Llama2-70-b 模型的案例研究展示了 EvaLLM 的好处，并说明了当前最先进的
    LLM 生成的可视化的有趣结果。
- en: 1 Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: 'In the last year, Large Language Models (LLMs) have become everywhere across
    various disciplines, demonstrating remarkable efficacy and capabilities in performing
    different tasks. Noteworthy applications span from finance  [[WIL^∗23](#bib.bibx65)]
    to coding  [[CTJ^∗21](#bib.bibx10)], exhibiting tangible impacts in disparate
    domains and presenting a valuable opportunity for human augmentation. For example,
    Github reports an enhancement in developer productivity by a 55% increasing in
    writing code, attributed to the introduction of Copilot [[Gitnt](#bib.bibx21)],
    an LLM model fine-tuned to generate code. The relentless advancements in research
    contribute to the widespread usage of LLMs, thanks to the evolving proficiency
    in comprehending the underlying semantics in human instructions [[HQS^∗23](#bib.bibx26)].
    This results in diverse implications across different sectors, opening the research
    to new opportunities. In the visualization field, LLMs exhibit promising capabilities
    in generating visualization as images and code [[WYKN20](#bib.bibx68), [TCD^∗23](#bib.bibx59)],
    using libraries such as D3.js [[Bcnt](#bib.bibx3)] and Matplotlib [[Hun07](#bib.bibx27)].
    A significant implication of this capability is that these models may empower
    non-expert users to generate insightful visualizations without prior data visualization
    expertise, offering a distinct advantage in creating visualizations through natural
    language queries [[CLM^∗22](#bib.bibx9), [MS23](#bib.bibx40)]. In this direction,
    the LLMs find a potential fit in the field of Visualization Recommendation Systems [[PPV23](#bib.bibx46)],
    representing a valuable solution to the contemporary challenges posed by the large
    amount of data available in the different fields. These opportunities open a new
    research track: LLM 4 Data visualization (LLM4VIS). A promising use case is represented
    by OpenAI’s CodeInterpreter, a sophisticated solution capable of generating visualization
    and delineating complex problems into logical steps for a more meaningful response [[FBRK23](#bib.bibx16)].
    Despite the prevalence of models (e.g., GPT-4 [[Ope23](#bib.bibx45)], LLama [[TMS^∗23](#bib.bibx61)])
    and their continuous improvement, a significant portion of their behavior remains
    ripe for exploration and further scrutiny. To bridge this knowledge gap, researchers
    are investigating their capabilities across diverse benchmark datasets [[WSM^∗18](#bib.bibx66),
    [ZHB^∗19](#bib.bibx72), [CCE^∗18](#bib.bibx6), [ZCG^∗23](#bib.bibx71)]. While
    natural language processing, general knowledge, common sense, problem-solving,
    advanced reasoning, and coding tasks have undergone thorough examination, visualization
    skills remain an area demanding further exploration due to its preliminary results.
    Although LLMs can generate visualizations, a comprehensive analysis of their visualization
    capabilities is lacking, prompting research questions such as Do LLMs adhere to
    visualization best practices? or Can the LLM-generated visualizations be trusted?.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去一年中，大型语言模型（LLMs）已在各个学科中普及，展示了在执行不同任务方面的显著效果和能力。值得注意的应用包括从金融[[WIL^∗23](#bib.bibx65)]到编码[[CTJ^∗21](#bib.bibx10)]，在不同领域产生了实际影响，并为人类增强提供了宝贵的机会。例如，Github报告了开发者生产力的提高，代码编写效率提高了55%，这归功于Copilot[[Gitnt](#bib.bibx21)]的引入，这是一个经过微调的LLM模型，用于生成代码。研究的持续进步促进了LLMs的广泛应用，得益于在理解人类指令的潜在语义方面的不断提高[[HQS^∗23](#bib.bibx26)]。这在不同领域产生了多样的影响，为研究开辟了新机会。在可视化领域，LLMs展示了在生成图像和代码作为可视化的有前景的能力[[WYKN20](#bib.bibx68),
    [TCD^∗23](#bib.bibx59)]，使用如D3.js[[Bcnt](#bib.bibx3)]和Matplotlib[[Hun07](#bib.bibx27)]等库。这种能力的重要含义是，这些模型可能使非专家用户能够生成有洞察力的可视化，而无需事先的数据可视化专业知识，通过自然语言查询创建可视化提供了独特的优势[[CLM^∗22](#bib.bibx9),
    [MS23](#bib.bibx40)]。在这一方向上，LLMs在可视化推荐系统领域找到潜在的契合[[PPV23](#bib.bibx46)]，代表了对各种领域中大量数据所带来的当代挑战的宝贵解决方案。这些机会开辟了一个新的研究方向：LLM
    4 数据可视化（LLM4VIS）。一个有前景的用例是OpenAI的CodeInterpreter，这是一个复杂的解决方案，能够生成可视化并将复杂问题划分为逻辑步骤，以获得更有意义的回应[[FBRK23](#bib.bibx16)]。尽管模型（如GPT-4[[Ope23](#bib.bibx45)]，LLama[[TMS^∗23](#bib.bibx61)]）的普遍存在及其持续改进，但其行为的相当一部分仍待探索和进一步审查。为了弥合这一知识空白，研究人员正在调查其在各种基准数据集上的能力[[WSM^∗18](#bib.bibx66),
    [ZHB^∗19](#bib.bibx72), [CCE^∗18](#bib.bibx6), [ZCG^∗23](#bib.bibx71)]。虽然自然语言处理、一般知识、常识、问题解决、高级推理和编码任务已经经过彻底检查，但由于初步结果，可视化技能仍然是一个需要进一步探索的领域。尽管LLMs可以生成可视化，但对其可视化能力的全面分析仍然缺乏，提出了如LLMs是否遵循可视化最佳实践？或LLM生成的可视化是否可信？等研究问题。
- en: In this paper, we cope with the problem of modeling the evaluation of LLM-generated
    visualizations and informing specific benchmarks for LLM-based visualizations
    to foster quantitative multi-faceted evaluation and comparability. We introduce
    EvaLLM, a conceptual stack to evaluate LLM-generated visualization. It decomposes
    the evaluation effort in its atomic components, characterizes their nature, and
    provides an overview of how to implement and interpret their results. Moreover,
    we propose a user-friendly web-based platform that provides a benchmarking resource
    for the visualization generation task. The platform supports automatic and manual
    scoring and implements solutions for the EvaLLM composing layers and levels. In
    addition to automated assessments, the platform incorporates human-based evaluation
    features, supporting multiple users in identifying potential pitfalls or semantic
    errors. Finally, we present two qualitative use cases that evaluate GPT-3.5-turbo
    and Llama2-70b models on 50 samples from the NvBench dataset [[LTL21a](#bib.bibx37)]
    against the EvaLLM stack. The analysis of the use case results shows common errors
    in visualization generation, from the more structural to the more semantic errors,
    allowing their identification at specific levels of the EvaLLM stack. This evaluation
    not only showcases the capabilities of the proposed conceptual stack but also
    sheds light on the limits and pitfalls of GPT-3.5-turbo and Llama-70b in a practical
    setting.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们处理了对LLM生成可视化的评估建模问题，并为LLM基础的可视化制定了具体的基准，以促进定量的多方面评估和可比性。我们引入了EvaLLM，一个用于评估LLM生成可视化的概念框架。它将评估工作分解为其基本组成部分，描述它们的性质，并提供了如何实施和解释其结果的概述。此外，我们提出了一个用户友好的基于网络的平台，为可视化生成任务提供基准资源。该平台支持自动评分和手动评分，并实现了EvaLLM的组成层级和层面的解决方案。除了自动化评估，平台还包括基于人工的评估功能，支持多个用户识别潜在的缺陷或语义错误。最后，我们展示了两个定性用例，评估了GPT-3.5-turbo和Llama2-70b模型在来自NvBench数据集的50个样本上[[LTL21a](#bib.bibx37)]，并与EvaLLM框架进行了比较。用例结果的分析显示了可视化生成中的常见错误，从更结构化的错误到更语义化的错误，允许在EvaLLM框架的特定层级上识别这些错误。这种评估不仅展示了所提概念框架的能力，还揭示了GPT-3.5-turbo和Llama-70b在实际应用中的局限性和陷阱。
- en: 'Summarizing, the main contributions of this work are:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，本工作的主要贡献包括：
- en: '1.'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: 'EvaLLM: a conceptual stack for evaluating LLM capabilities in visualization
    generation task;'
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: EvaLLM：用于评估LLM在可视化生成任务中能力的概念框架；
- en: '2.'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: a web-based platform for visualization evaluation providing an implementation
    of EvaLLM;
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一个用于可视化评估的基于网络的平台，提供了EvaLLM的实施；
- en: '3.'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: two use cases involving GPT-3.5-turbo and Llama 70-b to show insights and opportunities
    obtainable by using EvaLLM.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 两个涉及GPT-3.5-turbo和Llama 70-b的用例，展示了使用EvaLLM获得的见解和机会。
- en: 'This paper is structured as follows: Section 2 reviews diverse prominent language
    model approaches and the research about their usage for visualization generation
    tasks. Section 3 introduces the proposed conceptual stack for assessing LLM-based
    visualizations and their composing layers. Section 4 illustrates possibilities
    for implementing EvaLLM levels of evaluation and their meanings. Section 5 discusses
    the design and implementation of a platform to instruct benchmarking activities
    leveraging EvaLLM. Section 6 shows the results of two use cases on GPT-3.5-turbo
    and Llama 70-b. Limitations and opportunities are presented in Section 7, with
    Section 8 concluding the paper.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 本文结构如下：第2节回顾了各种主要语言模型方法及其在可视化生成任务中的应用研究。第3节介绍了用于评估LLM基础可视化及其组成层级的概念框架。第4节说明了实施EvaLLM评估层级及其含义的可能性。第5节讨论了用于指导基准活动的EvaLLM平台的设计和实施。第6节展示了在GPT-3.5-turbo和Llama
    70-b上的两个用例结果。第7节呈现了局限性和机会，第8节总结了全文。
- en: 2 Related work
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: A Visual Recommendation System (VRS) is an automated system that can generate
    insightful visualizations from a given dataset. As outlined by Podo et al. [[PPV23](#bib.bibx46)],
    VRS can be broadly categorized into task-agnostic and task-aware. The former relies
    solely on the dataset as input, requiring the system to learn how to generate
    insightful visualizations autonomously. In contrast, the latter involves user
    guidance through queries or utterances in addition to the dataset, facilitating
    a more interactive and user-informed approach to data visualization. This section
    delves into the contributions coping with task-aware VRSs. It offers a comprehensive
    overview of how methods based on Large Language Models (LLMs) are employed and
    the potential enhancements they could bring. Furthermore, it explores also more
    classic approaches, including rule-based and machine-learning methods [[SBT^∗16](#bib.bibx48),
    [LTL^∗21b](#bib.bibx38), [SS23a](#bib.bibx54), [KLSC21](#bib.bibx30), [NSS20](#bib.bibx44),
    [SZWJ22](#bib.bibx58), [GDA^∗15](#bib.bibx20)]. Finally, it addresses existing
    research investigating the capabilities and quality of an LLM-based VRS.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化推荐系统（VRS）是一种自动化系统，可以从给定的数据集中生成有洞察力的可视化。如Podo等人所述[[PPV23](#bib.bibx46)]，VRS可以大致分为任务无关型和任务相关型。前者仅依赖于数据集作为输入，要求系统自主学习如何生成有洞察力的可视化。相比之下，后者除了数据集外，还涉及用户通过查询或言语进行引导，促进了更加互动和用户知情的数据可视化方法。本节将深入探讨处理任务相关VRS的贡献。它提供了基于大型语言模型（LLMs）的方法的综合概述，并探讨了它们可能带来的潜在改进。此外，它还探讨了更经典的方法，包括基于规则和机器学习的方法[[SBT^∗16](#bib.bibx48)，[LTL^∗21b](#bib.bibx38)，[SS23a](#bib.bibx54)，[KLSC21](#bib.bibx30)，[NSS20](#bib.bibx44)，[SZWJ22](#bib.bibx58)，[GDA^∗15](#bib.bibx20)]。最后，它讨论了现有的研究，调查了基于LLM的VRS的能力和质量。
- en: 2.1 VRS task-aware benchmarks
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 VRS任务相关基准
- en: 'As discussed, the task-aware VRSs require user utterance and the dataset as
    input. To assess a model’s performance on the given task, several datasets are
    available, each with its unique characteristics: nvBench dataset [[LTL21a](#bib.bibx37)]
    presents 25,750 triplets (data, utterance, chart) sourced from 105 domains of
    tabular data. Despite its comprehensive nature, it is worth noting that many utterances
    in the nvBench dataset provide explicit visualization specifications, including
    exact details about the expected visualization, like the data columns, the chart
    type, or other visualization properties. For instance, the following example:
    "A pie chart showing the number of faculty members for each rank." precisely communicates
    the user’s visualization expectations regarding the chart type. Moreover, it covers
    only the most frequent visualization types, such as bar, pie, line, scatter, stacked
    bar, grouping line, and grouping scatter. The NLVCorpus [[SNL^∗21](#bib.bibx52)]
    comprises 893 utterances related to ten types of charts. However, the NLVCorpus
    is constrained by its reliance on only three data tables. In the work by Tian
    et al. [[TCD^∗23](#bib.bibx59)], a new dataset is proposed based on the nvBench
    dataset. The authors curate this new dataset by initially selecting utterances
    involving only one data table, eliminating pairs requiring multiple tables. They
    then employ GPT-3 to abstract the utterances, thereby reducing explicitness. While
    this dataset is an essential resource in the field, it is important to note that
    it relies on synthetic pairs. Quda [[FXG^∗20](#bib.bibx18)] encompasses 14,035
    user utterance queries spanning various analytical tasks. However, it lacks associated
    charts, which limits its utility for visualization evaluation scenarios. This
    diversity in datasets provides researchers with options for evaluating models,
    each dataset bringing its strengths and limitations. At the same time, none copes
    with the problem of defining a granular set of metrics and elements to consider
    for comparing the tested approaches.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，任务感知的VRSs需要用户发言和数据集作为输入。为了评估模型在给定任务上的表现，提供了多个数据集，每个数据集都有其独特的特征：nvBench
    数据集 [[LTL21a](#bib.bibx37)] 提供了来自105个表格数据领域的25,750个三元组（数据、发言、图表）。尽管其内容全面，但值得注意的是，nvBench
    数据集中的许多发言提供了明确的可视化规格，包括有关预期可视化的详细信息，如数据列、图表类型或其他可视化属性。例如，以下示例：“显示每个等级教师人数的饼图。”精确传达了用户对图表类型的可视化期望。此外，它仅涵盖了最常见的可视化类型，如条形图、饼图、折线图、散点图、堆积条形图、分组折线图和分组散点图。NLVCorpus [[SNL^∗21](#bib.bibx52)]
    包含与十种图表类型相关的893个发言。然而，NLVCorpus 受到仅依赖三个数据表的限制。在 Tian 等人的研究中 [[TCD^∗23](#bib.bibx59)]，基于
    nvBench 数据集提出了一个新的数据集。作者通过最初选择仅涉及一个数据表的发言来整理这个新数据集，排除需要多个表的对。然后，他们使用GPT-3对发言进行抽象，从而减少明确性。尽管这个数据集在该领域是一个重要资源，但需要注意的是，它依赖于合成对。Quda [[FXG^∗20](#bib.bibx18)]
    包含了14,035个用户发言查询，涉及各种分析任务。然而，它缺乏相关的图表，这限制了它在可视化评估场景中的实用性。这些数据集的多样性为研究人员提供了评估模型的选项，每个数据集都有其优点和局限性。同时，没有一个数据集能够解决定义用于比较测试方法的细致指标和要素的问题。
- en: 2.2 Traditional visualization generation methods
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 传统可视化生成方法
- en: 'In the literature, the task-aware VRS models predominantly rely on traditional
    methodologies. For example, in  [[SBT^∗16](#bib.bibx48)], the authors introduce
    an interactive visualization tool that employs a hybrid approach integrating Natural
    Language Processing (NLP) and decision rules. This system combines a probabilistic
    grammar approach with predefined rules that can be dynamically updated based on
    the underlying data. This approach offers the advantage of reduced computational
    complexity compared to machine/deep learning methods, resulting in a faster interaction.
    In  [[SS23a](#bib.bibx54)], the authors present BOLT, a web-based platform for
    multi-dashboard authoring using natural language. The authors propose a system
    based on traditional NLP techniques to map user utterances to prevalent dashboard
    objectives and generate appropriate visualizations. The novelty of this paper
    lies in the focus on higher dashboard objectives that focus on the overall problem
    the user is trying to solve (e.g., change analysis) rather than lower ones that
    involve simpler visualization operations (e.g., sorting). Although user validation
    demonstrates the positive impact of natural language on interaction, the inherent
    challenge of handling ambiguous user utterances persists, posing difficulties
    for classical NLP methods. In contrast,  [[NSS20](#bib.bibx44)] introduces a method
    for interacting with a dataset based on NLP, focusing on generating a single visualization
    rather than suggesting a complete dashboard. The emphasis here is on providing
    tailored visualizations through NLP techniques. Moving beyond rule-based approaches,
     [[LTL^∗21b](#bib.bibx38)] proposes ncNet, a seq2seq model that translates Natural
    Language Queries (NLQs) into a custom visualization grammar, Vega-Zero. This transformer-based
    encoder-decoder architecture employs an attention-forcing method and is trained
    on the nvBench dataset. While ncNet represents a breakthrough in processing the
    user inputs as free text, it still faces challenges in handling ambiguous and
    ill-posed natural queries. To address these limitations,  [[SZWJ22](#bib.bibx58)]
    introduced RGVisNet, a retrieval and generation-based approach. Instead of directly
    translating NLQs into the visualization grammar, the network is divided into two
    components: (i) a data visualizations query retrieval network and (ii) a data
    visualizations query revision network. Based on a Graph Neural Network (GNN),
    the retrieval network retrieves relevant data visualizations from a database.
    In contrast, the revision network adjusts the candidate based on the expected
    data visualization outcomes through a decoder structure. Despite the effectiveness
    of these non-LLM-based systems, they grapple with the challenge of capturing underlying
    semantics in user utterances, mainly when dealing with ambiguous expressions.
    This may not lead to an ideal generated visualization as a result.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 文献中，任务感知的VRS模型主要依赖传统方法。例如，在[[SBT^∗16](#bib.bibx48)]中，作者介绍了一种互动可视化工具，采用了集成自然语言处理（NLP）和决策规则的混合方法。该系统将概率语法方法与预定义规则相结合，这些规则可以基于底层数据动态更新。这种方法相比于机器/深度学习方法具有减少计算复杂度的优势，从而实现更快的交互。在[[SS23a](#bib.bibx54)]中，作者展示了BOLT，一个基于网页的多仪表板创作平台，利用自然语言进行操作。作者提出了一种基于传统NLP技术的系统，将用户的言语映射到流行的仪表板目标上并生成适当的可视化。这篇论文的创新之处在于关注于更高层次的仪表板目标，集中于用户试图解决的整体问题（例如，变化分析），而不是涉及简单可视化操作的较低目标（例如，排序）。尽管用户验证展示了自然语言对交互的积极影响，但处理模糊用户言语的固有挑战依然存在，这对传统NLP方法造成困难。相比之下，[[NSS20](#bib.bibx44)]介绍了一种基于NLP与数据集交互的方法，重点是生成单一可视化，而不是建议完整仪表板。这里的重点是通过NLP技术提供定制化的可视化。超越基于规则的方法，[[LTL^∗21b](#bib.bibx38)]提出了ncNet，一个seq2seq模型，将自然语言查询（NLQs）翻译成自定义可视化语法Vega-Zero。该基于变换器的编码器-解码器架构采用了注意力强制方法，并在nvBench数据集上进行了训练。虽然ncNet在将用户输入处理为自由文本方面代表了一项突破，但在处理模糊和不明确的自然查询时仍面临挑战。为了应对这些限制，[[SZWJ22](#bib.bibx58)]引入了RGVisNet，一种基于检索和生成的方法。该网络并非直接将NLQs翻译成可视化语法，而是将网络分为两个组件：（i）数据可视化查询检索网络和（ii）数据可视化查询修订网络。基于图神经网络（GNN），检索网络从数据库中检索相关的数据可视化。相比之下，修订网络通过解码器结构根据预期的数据可视化结果调整候选项。尽管这些非LLM方法系统有效，但在捕捉用户言语中的潜在语义，特别是处理模糊表达时仍面临挑战。这可能导致生成的可视化效果不尽理想。
- en: 2.3 LLM-based visualization generation methods
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 基于LLM的可视化生成方法
- en: 'As discussed, the rise of the LLMs has posed new research questions in different
    fields, including the data visualization field. New approaches have been proposed
    in this direction. In [[HC23](#bib.bibx23)], the authors propose AI Thread, a
    chatbot for multi-threaded analytic conversations. Using the chain-of-thoughts
    reasoning technique [[WWS^∗22](#bib.bibx67)], the system leverages GPT-3.5 capabilities
    in Python to map the user utterance into a visualization using Matplot and Seaborn
    libraries. Moreover, the tool proposes a two-view interface: the main chat, that
    is, the chat view interaction, and the threaded panel that allows for edits on
    the visualizations in the main board. A different approach is proposed in [[CLM^∗22](#bib.bibx9)].
    The authors discuss a method based on few-shot learning [[WYKN20](#bib.bibx68)]
    at inference time on the Codex LLM model by OpenAI [[FADB^∗22](#bib.bibx15)].
    The model is fed with natural language-SQL (NL2SQL) pairs examples and the user’s
    natural language query to aid in task understanding. The result is then converted
    into Vega-Lite specifications using a rule-based approach [[CW22](#bib.bibx11)].
    The authors emphasize that their approach can achieve valuable results without
    requiring model tuning. However, the study’s evaluation is conducted on a limited
    number of examples without providing any findings about the quality of the explored
    samples, raising questions about the generalizability of the approach. Similarly,
    Maddigan et al. [[MS23](#bib.bibx40)] present a comparable study involving Codex,
    GPT -3, and ChatGPT. Like the previous work, the study lacks a comprehensive discussion
    of results and relies on a small number of evaluation samples. Finally, Tian et
    al. [[TCD^∗23](#bib.bibx59)] recently introduced ChartGPT, a multi-step pipeline
    incorporating LLMs into various stages, breaking down the visualization generation
    problem into logical steps. The authors fine-tune FLAN-t5 [[CHL^∗22](#bib.bibx7)]
    to align the model with the intended task. The evaluation is extensive in the
    number of tests but is still executed using a custom evaluation scheme. This problem
    is common even to other papers presented in this section, leading us to study
    deeply how a general framework could support LLM-generated visualizations.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 正如讨论的那样，LLMs的崛起在不同领域提出了新的研究问题，包括数据可视化领域。在这个方向上提出了新的方法。在[[HC23](#bib.bibx23)]中，作者提出了AI
    Thread，一个用于多线程分析对话的聊天机器人。利用链式思维推理技术[[WWS^∗22](#bib.bibx67)]，该系统利用Python中的GPT-3.5能力，通过Matplot和Seaborn库将用户的发言映射到可视化中。此外，该工具提供了一个双视图界面：主聊天，即聊天视图互动，以及线程面板，允许在主板上的可视化上进行编辑。在[[CLM^∗22](#bib.bibx9)]中提出了一种不同的方法。作者讨论了一种基于少量学习[[WYKN20](#bib.bibx68)]的推理时间方法，该方法使用OpenAI的Codex
    LLM模型[[FADB^∗22](#bib.bibx15)]。该模型接受自然语言-SQL (NL2SQL)对示例和用户的自然语言查询，以帮助理解任务。结果然后使用基于规则的方法[[CW22](#bib.bibx11)]转换为Vega-Lite规范。作者强调，他们的方法可以在不需要模型调优的情况下取得有价值的结果。然而，该研究的评估是在有限数量的示例上进行的，并且没有提供有关所探索样本质量的任何发现，这引发了对方法普遍性的质疑。类似地，Maddigan等人[[MS23](#bib.bibx40)]提出了一项涉及Codex、GPT-3和ChatGPT的类似研究。与之前的工作一样，该研究缺乏对结果的全面讨论，并依赖于少量的评估样本。最后，Tian等人[[TCD^∗23](#bib.bibx59)]最近推出了ChartGPT，一个将LLMs融入各个阶段的多步骤流程，将可视化生成问题分解为逻辑步骤。作者对FLAN-t5[[CHL^∗22](#bib.bibx7)]进行了微调，以使模型与预期任务对齐。评估在测试数量上很全面，但仍使用了自定义评估方案。这一问题也普遍存在于本节中其他论文中，促使我们深入研究通用框架如何支持LLM生成的可视化。
- en: 2.4 Evaluating LLMs visualizations
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 评估LLMs可视化
- en: Despite the impressive performances demonstrated by these new approaches, there
    needs to be more evaluation approaches and standard methodologies to assess the
    understating capabilities in the data visualization domain. To fill this gap,
    some researchers have started to map these capabilities, proposing evaluation
    methods. For example, [[CZW^∗23](#bib.bibx12)] presents an evaluation study focusing
    on GPT-3.4 and GPT-4, examining these models beyond the conventional visualization
    generation task considered from just the code generation perspective. Instead,
    the study delves into multiple facets, such as data interpretation, visualization
    design, visual data exploration support, and insight communication. To assess
    the model’s proficiency, they tasked GPT with completing various quizzes and producing
    visualizations based on the data visualization course of Harvard CS171\. GPT was
    asked to perform random tasks from the dataset, including quizzes and homework,
    and a group of fellows evaluated the results. This study introduces an initial
    evaluation approach to understand how well GPT can address challenges closely
    tied to visualization tasks. While using general categories of elements considered
    during a visualization evaluation, the work focuses more on their application
    than the conceptual modeling what it means to evaluate an LLM-generated visualization.
    It also presents interesting considerations on this topic, and they inspired us
    to define our evaluation conceptual stack. Another in-depth study is conducted
    by Kim et al. [[KMB23](#bib.bibx31)], where the authors thoroughly explore the
    capabilities and limitations of ChatGPT in visualization tasks. They pose a series
    of questions from the VisGuides forum and compare the answers with human responses
    from the original questions on the blog. The study observes that ChatGPT performs
    similarly to human responses and, in some cases, even outperforms them. The authors
    then asked a group of data visualization experts to evaluate visualizations provided
    by both ChatGPT and domain experts without revealing the source. The study concludes
    that users prefer human feedback over LLM feedback, highlighting the main disadvantages
    of ChatGPT’s lack of discussion and emphasizing the potential advantage of a design
    knowledge agent. We identified similar needs in including human assessment even
    for LLM-based visualizations, which informed the creation of EvaLLM. Finally,
    Tao et al. [[TX23](#bib.bibx62)] investigate ChatGPT’s capability to generate
    abstract maps through two main experiments. The first experiment assesses the
    model’s ability to create thematic maps based on specified map styles and data
    sources in the prompts. The second experiment involves generating mental maps
    from the data. The study concludes that ChatGPT can assist in developing maps
    and enhance productivity. Nonetheless, it underscores the model’s dependence on
    external tools for visualization generation, highlighting challenges in achieving
    the desired output. While these works contribute to integrating LLMs into existing
    data visualization pipelines, few have systematically studied the main characteristics
    needed to evaluate a generated visualization and how to organize and leverage
    them to benchmark automatic generators, creating a taxonomy of recurring errors.
    To fill this gap, this paper proposes a conceptual stack that includes automatic
    quantitative and human-based evaluation metrics and investigates its application
    to LLM-based visualizations.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些新方法展示了令人印象深刻的表现，但在数据可视化领域，仍需要更多的评估方法和标准化方法来评估理解能力。为了填补这一空白，一些研究人员已开始绘制这些能力图谱，提出评估方法。例如，[[CZW^∗23](#bib.bibx12)]
    进行了一项评估研究，专注于 GPT-3.4 和 GPT-4，超越了仅从代码生成角度考虑的传统可视化生成任务。相反，该研究深入探讨了多个方面，如数据解释、可视化设计、视觉数据探索支持和洞察传达。为了评估模型的熟练程度，他们要求
    GPT 完成各种测验并根据哈佛 CS171 的数据可视化课程生成可视化图形。GPT 被要求从数据集中执行随机任务，包括测验和作业，一组研究员对结果进行了评估。这项研究引入了一种初步评估方法，以了解
    GPT 如何应对与可视化任务紧密相关的挑战。尽管在可视化评估过程中使用了一般元素类别，但该研究更关注其应用，而非概念建模，即如何评估 LLM 生成的可视化。它还提出了一些有趣的考虑，并激发我们定义了自己的评估概念堆栈。另一项由
    Kim 等人 [[KMB23](#bib.bibx31)] 进行的深入研究，作者彻底探讨了 ChatGPT 在可视化任务中的能力和局限性。他们从 VisGuides
    论坛中提出了一系列问题，并将答案与博客中原始问题的人类回答进行了比较。研究观察到 ChatGPT 的表现与人类回答类似，在某些情况下甚至优于人类回答。然后，作者要求一组数据可视化专家在不透露来源的情况下评估
    ChatGPT 和领域专家提供的可视化。研究结论是，用户更喜欢人类反馈而非 LLM 反馈，突出了 ChatGPT 缺乏讨论的主要缺点，并强调了设计知识代理的潜在优势。我们在
    LLM 基于的可视化中识别出类似的需求，这些需求促成了 EvaLLM 的创建。最后，Tao 等人 [[TX23](#bib.bibx62)] 通过两个主要实验研究了
    ChatGPT 生成抽象地图的能力。第一个实验评估了模型根据提示中的指定地图样式和数据源创建专题地图的能力。第二个实验涉及从数据中生成思维地图。研究得出结论，ChatGPT
    可以协助地图开发并提高生产力。然而，它也强调了模型对外部工具进行可视化生成的依赖，突出了实现期望输出的挑战。虽然这些工作有助于将 LLM 整合到现有的数据可视化流程中，但很少有研究系统地研究评估生成可视化所需的主要特征，以及如何组织和利用这些特征来基准自动生成器，创建重复错误的分类法。为填补这一空白，本文提出了一个概念堆栈，包括自动定量和基于人类的评估指标，并研究了其在
    LLM 基于的可视化中的应用。
- en: '3 EvaLLM: Characterizing the evaluation of LLM-generated visualizations'
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '3 EvaLLM: 描述LLM生成可视化的评估'
- en: 3.1 Preliminaries
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 初步准备
- en: 'In the domain of LLMs applied to visualization generation task (LLM4VIS), the
    challenge is represented by creating a solution capable of accurately generating
    a visualization given a dataset $\mathcal{D}$ and a user query $\mathcal{Q}$.
    In the forthcoming discussion, it is crucial first to provide a formulation of
    the problem, as formalized in the following definition:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用于可视化生成任务的LLM领域（LLM4VIS）中，挑战在于创建一个能够准确生成给定数据集$\mathcal{D}$和用户查询$\mathcal{Q}$的可视化的解决方案。在随后的讨论中，首先提供问题的定义至关重要，如下所示：
- en: Problem definition
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 问题定义
- en: Given a tabular dataset $\mathcal{D}$ of $n$ features $\Phi=\{\phi_{1},\dots,\phi_{n}\}$
    and a user query $\mathcal{Q}$, an LLM-based visualization recommender system,
    generates a visualization $V$ that provide the best accuracy concerning $\mathcal{Q}$.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个包含$n$个特征$\Phi=\{\phi_{1},\dots,\phi_{n}\}$的表格数据集$\mathcal{D}$和一个用户查询$\mathcal{Q}$，一个基于LLM的可视化推荐系统生成一个与$\mathcal{Q}$相关的最佳准确性可视化$V$。
- en: 'A task-aware LLM-VRS should be able to discern and understand the user’s intent
    as conveyed in the input query and generate a visualization that closely aligns
    with the user’s expectations. Building upon the existing literature for interactive
    visualizations in this domain, we can categorize the output visualization $\mathcal{V}$
    into three classes: image-based visualization, code-based visualization, and grammar-based
    visualization. In the first case, the visualization is directly generated as an
    image, representing the only output of the generation process. A code snippet
    is generated and then used to render the visualization in the code-based case.
    Rendering such output necessitates a specific environment for code execution relative
    to the language of the generated code. Conversely, the grammar-based case relies
    on visualization grammars, such as VegaLite, enabling direct rendering by mapping
    the grammar with one or multiple code environments. Based on these assumptions,
    we propose EvaLLM, a conceptual stack that allows the evaluation of all these
    classes of generated visualizations.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 一个任务感知的LLM-VRS应该能够辨别和理解输入查询中传达的用户意图，并生成一个与用户期望紧密对齐的可视化。在现有的交互式可视化文献基础上，我们可以将输出的可视化$\mathcal{V}$分为三类：基于图像的可视化、基于代码的可视化和基于语法的可视化。在第一种情况下，可视化直接生成图像，代表生成过程的唯一输出。在基于代码的情况下，生成一个代码片段，然后用它来渲染可视化。渲染这种输出需要一个特定的代码执行环境，具体取决于生成代码的语言。相反，基于语法的情况依赖于可视化语法，如VegaLite，通过将语法映射到一个或多个代码环境来实现直接渲染。基于这些假设，我们提出了EvaLLM，一个允许评估所有这些生成可视化类别的概念性堆栈。
- en: '3.2 Structuring the evaluation: the EvaLLM layers'
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 结构化评估：EvaLLM的层次
- en: 'EvaLLM is a conceptual stack to model the evaluation for LLM-generated visualization,
    as shown in Figure [1](#S3.F1 "Figure 1 ‣ 3.2 Structuring the evaluation: the
    EvaLLM layers ‣ 3 EvaLLM: Characterizing the evaluation of LLM-generated visualizations
    ‣ vi(E)va LLM! A Conceptual Stack for Evaluating and Interpreting Generative AI-based
    Visualizations"). Due to the early stage of the LLM models for the visualization
    field, there is a lack of standard methods for assessing the quality of generated
    visualization, from what their quality depends, or which design elements of visualization
    the LLMs are better at accurately generating. Drawing inspiration from the ISO/OSI
    model [[DZ83](#bib.bibx14)], EvaLLM involves abstract layers to evaluate specific
    visualization properties and derive a corresponding quality measure. From bottom
    to top, each layer transitions towards a higher level of abstraction. As illustrated
    in Figure [1](#S3.F1 "Figure 1 ‣ 3.2 Structuring the evaluation: the EvaLLM layers
    ‣ 3 EvaLLM: Characterizing the evaluation of LLM-generated visualizations ‣ vi(E)va
    LLM! A Conceptual Stack for Evaluating and Interpreting Generative AI-based Visualizations"),
    EvaLLM comprises five primary layers. Each layer is subdivided into levels, where
    the focus is directed explicitly toward assessing distinct visualization properties
    of the same layer. The rationale for this structure is to allow for an initial
    set of homogeneous categories specialized internally in further detail inside
    each of them (through levels) and support in this way a fine-grained evaluation
    of the generated visualization properties, better characterizing the LLMs’ expressive
    power.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: EvaLLM 是一个概念堆栈，用于建模LLM生成可视化的评估，如图[1](#S3.F1 "图 1 ‣ 3.2 评估结构：EvaLLM 层 ‣ 3 EvaLLM：特征化LLM生成可视化的评估
    ‣ vi(E)va LLM！用于评估和解释生成型AI基础可视化的概念堆栈")所示。由于LLM模型在可视化领域仍处于早期阶段，缺乏评估生成可视化质量的标准方法，以及这些质量依赖于什么，或LLM在哪些可视化设计元素上更能准确生成。EvaLLM借鉴了ISO/OSI模型[[DZ83](#bib.bibx14)]，涉及抽象层次以评估特定的可视化属性，并推导出相应的质量度量。从底层到顶层，每个层次向更高层次的抽象过渡。如图[1](#S3.F1
    "图 1 ‣ 3.2 评估结构：EvaLLM 层 ‣ 3 EvaLLM：特征化LLM生成可视化的评估 ‣ vi(E)va LLM！用于评估和解释生成型AI基础可视化的概念堆栈")所示，EvaLLM包括五个主要层次。每个层次被细分为若干级别，重点明确地评估同一层次的不同可视化属性。这种结构的
    rationale 是允许一组初始的同质类别，在每个类别内部进一步详细分解（通过级别），从而支持对生成可视化属性的细致评估，更好地特征化LLM的表达能力。
- en: '![Refer to caption](img/b1cb4e49c581d767fd58f8452276d783.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/b1cb4e49c581d767fd58f8452276d783.png)'
- en: 'Figure 1: EvaLLMStack: concept evaluation stack for evaluating the LLM-generated
    visualizations'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：EvaLLMStack：用于评估LLM生成的可视化的概念评估堆栈
- en: 'At the base of the EvaLLM stack lies the Code layer, which plays a role in
    evaluating the fundamental structural properties of a visualization. The primary
    question that the Code layer seeks to address is RQ.1: "Is the visualization consistent
    within the code environment it is created with?". This inquiry delves into the
    coherence of the visualization within the structure of the related environment
    (e.g., a generic programming language, a specialized one, or a grammar), checking
    whether the generated code aligns with the expected structure or evaluating which
    differences may be present. These differences are mostly syntactical, but they
    can already present interesting cases that strongly affect the final result quality
    (i.e., different syntactic structures that give birth to similar visual results
    or slightly different codes that produce very different results). In other words,
    the Code layer focuses on verifying the syntactical correctness and integrity
    of the visualization’s underlying code, laying the groundwork for subsequent layers
    to delve into more nuanced aspects of evaluation. Immediately above the Code layer,
    the visualization evaluation is moved to the Representation layer. At this stage,
    the focus shifts to semantic aspects of the visualization representation, focusing
    on the core properties of the visualization related to the representation rules
    defined by the literature [[Spe01](#bib.bibx53), [Mun09](#bib.bibx41)]. We distilled
    from the literature three prominent aspects: the data mapping rules, the choice
    of the appropriate visual encodings (i.e., marks), and the representation properties
    of eventual axes or reference visual elements. The evaluation question behind
    this layer is RQ.2 Are the data representation rules correctly generated in the
    visualization?. We notice that already at this layer, it is not granted that some
    of these aspects are directly captured in the user query (i.e., the query may
    or may not include a direct reference to these aspects). At the same time, they
    are an integral part of a correct and accurate visualization. For this reason,
    at this layer, a more fine-grained and quantitative evaluation is needed concerning
    a coarse one based only, for example, on evaluating the correctness of the visual
    encoding. This evaluation should focus on quantitative distances between the generated
    and expected content. On top of this layer, there is the Presentation layer. This
    layer is the third layer in the stack, and it assesses the data presentation quality
    of the visualization from the perceptual standpoint [[War19](#bib.bibx63)]. This
    layer aims to model the design choices for perceptual aspects made by the LLM
    on the generated visualization to answer the question RQ.3 Is the visualization
    correctly presented, comprehensible by a human user, and not giving a perceptual
    error or illusions hindering the human interpretation of its content?. For example,
    it evaluates aspects such as the quality and appropriateness of the color mappings,
    the distinguishability of visual elements, or the perceptual comprehensibility
    of the visualized information. The fourth layer of the stack is the Informativeness
    layer. It is responsible for measuring the more intrinsic quality of the visualization
    in terms of its insightfulness and adherence to best practices in visualization
    literacy, answering the question RQ.4 Is the visualization insightful, and how
    well it supports the user in answering its information needs?. This involves an
    evaluation that examines the capability of the visualization to convey meaningful
    insights concerning the user query and to be aligned with best practices of visualization
    literacy to ease the visualization understanding by the user as much as possible.
    Lastly, the last layer on top of the stack is the LLM layer. The LLM layer contributes
    twofold at the end of the stack. Its first goal is to evaluate the strategy for
    generating the specific visualization. Possible choices relate to single prompting
    the LLM, applying prompt engineering [[WFH^∗23](#bib.bibx64)], or more sophisticated
    strategies like Chain-of-thought [[WWS^∗22](#bib.bibx67)]. Evaluate the configuration
    elements to discern between different models (i.e., plain foundation model, zero-shot/few-shot
    approaches, fine-tuning, or a trained-from-scratch new model). In this way, it
    is possible to evaluate the effort for the generation process on top of the quality
    of the generated visualization. The second goal is evaluating the visualization
    by assessing its significance and adherence to best practices in the visualization
    literature, but this time, trying to measure the insightfulness of a visualization
    regarding the LLM knowledge and answering the questions RQ.5 What is the cost
    of the generated visualization? and RQ.6 Is the visualization insightful, based
    on the LLM knowledge?.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: EvaLLM 堆栈的基础层是 Code 层，该层在评估可视化的基本结构属性方面发挥作用。Code 层主要要解决的问题是 RQ.1：“可视化在其创建的代码环境中是否一致？”。这一问题探讨了可视化在相关环境结构中的一致性（例如，通用编程语言、专用语言或语法），检查生成的代码是否与预期结构一致，或评估可能存在的差异。这些差异主要是语法上的，但它们已经可能呈现出有趣的情况，这些情况会显著影响最终结果的质量（即，不同的语法结构产生相似的视觉效果，或略微不同的代码产生截然不同的结果）。换句话说，Code
    层侧重于验证可视化底层代码的语法正确性和完整性，为后续层深入评估更细微的方面奠定基础。在 Code 层之上，是 Representation 层。在这个阶段，评估重点转向可视化表示的语义方面，关注于与文献定义的表示规则相关的可视化核心属性 [[Spe01](#bib.bibx53),
    [Mun09](#bib.bibx41)]。我们从文献中提炼出了三个显著方面：数据映射规则、适当的视觉编码（即标记）选择以及可能的坐标轴或参考视觉元素的表示属性。这个层次上的评估问题是
    RQ.2 数据表示规则在可视化中是否正确生成？。我们注意到，即使在这一层，某些方面也不一定直接体现在用户查询中（即查询可能包含也可能不包含这些方面的直接引用）。与此同时，它们是正确和准确可视化的不可或缺的部分。因此，在这一层，需要比仅仅基于视觉编码正确性评估的粗略评估更细致和定量的评估。这种评估应集中于生成内容和预期内容之间的定量差异。在这个层次之上，是
    Presentation 层。这个层次是堆栈中的第三层，它从感知的角度评估可视化的数据呈现质量 [[War19](#bib.bibx63)]。这一层的目标是建模
    LLM 对生成可视化在感知方面所做的设计选择，以回答问题 RQ.3 可视化是否正确呈现，是否易于人类用户理解，并且没有给出感知错误或幻觉，阻碍人类对其内容的解读？。例如，它评估颜色映射的质量和适当性、视觉元素的可区分性或可视化信息的感知可理解性。堆栈的第四层是
    Informativeness 层。它负责衡量可视化在洞察力方面的内在质量以及对可视化素养最佳实践的遵循，回答问题 RQ.4 可视化是否具有洞察力，它在多大程度上支持用户回答其信息需求？。这涉及对可视化能力的评估，以传达有关用户查询的有意义的见解，并尽可能与可视化素养的最佳实践保持一致，以便用户更好地理解可视化。最后，堆栈最上面的最后一层是
    LLM 层。LLM 层在堆栈的末端贡献双重目标。其第一个目标是评估生成特定可视化的策略。可能的选择涉及单次提示 LLM、应用提示工程 [[WFH^∗23](#bib.bibx64)]，或更复杂的策略，如
    Chain-of-thought [[WWS^∗22](#bib.bibx67)]。评估配置元素，以区分不同的模型（即，普通基础模型、零-shot/few-shot
    方法、微调或从头训练的新模型）。通过这种方式，可以在评估生成的可视化质量的基础上评估生成过程的努力。第二个目标是通过评估可视化的意义和对可视化文献最佳实践的遵循来评估可视化，但这次试图测量可视化在
    LLM 知识方面的洞察力，并回答问题 RQ.5 生成的可视化的成本是多少？和 RQ.6 基于 LLM 知识，这个可视化是否具有洞察力？
- en: '4 Implementing layers: the EvaLLM levels'
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实施层级：EvaLLM级别
- en: While the EvaLLM layers provide the overall structure of the fine-grained evaluation
    supported by the stack, they are still too coarse to be implemented. For this
    reason, EvaLLM presents a set of levels for each layer that better supports the
    implementation of the evaluation process and specifies how to interpret the evaluation
    results for each of them.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然EvaLLM层提供了堆栈支持的细粒度评估的总体结构，但仍然过于粗略，难以实施。因此，EvaLLM为每个层级提出了一组更好支持评估过程实施的级别，并指定了如何解释每个级别的评估结果。
- en: 'In this section, we delve into the exploration of such levels using the strategy
    of What, Why and How - what is the scope of the level, why it is essential and
    how it could be implemented. Each level is characterized by three dimensions,
    orthogonal to all the levels, and necessary to describe the interpretation of
    evaluation results: evaluation affordability, semantics, and human-machine ratio.
    Evaluation affordability serves as a qualitative measure of the concrete feasibility
    of each level and the trust that can be put in the obtained indicator. For instance,
    the syntax correctness level is high on the proposed scale as shown in Figure
    [8(a)](#S7.F8.sf1 "In Figure 8 ‣ 7.4 Use case 2: Evaluating Llama-70b ‣ 7 Use
    cases ‣ vi(E)va LLM! A Conceptual Stack for Evaluating and Interpreting Generative
    AI-based Visualizations"), because it is straightforward to implement and presents
    a clear-cut meaning, leaving little space for interpretation. On the other hand,
    the significance level could be implemented in multiple ways and leave a large
    space for interpreting its results; for this reason, it offers a low score on
    this aspect. Semantic defines the degree to which an EvaLLM level provides a semantic
    evaluation of the visualization. For example, the syntax correctness level provides
    a minimal semantic evaluation, limiting itself to express if the generated code
    is syntactically correct or not, compared to the visualization literacy level,
    which instead provides a much higher level of semantics for evaluating how much
    a generated visualization is compliant with visualization best practices (i.e.,
    the visualization could be accurately generated, but its efficacy for the user
    could be hindered by not following visualization best practices). Finally, Human-machine
    ratio gauges whether a level undergoes a fully automated evaluation process, relies
    on human-based assessment, or a mix of the two. The 5-level Likert rating scale
    ranges from low (violet) to high (dark green), with intermediate levels of medium-low
    (pink), medium(white), and medium-high (light green), offering a qualitative overview
    for each EvaLLM level. For the sake of clarity, we categorize the levels into
    two main classes: the one denoted by the asterisk (*) in the name requires a ground
    truth or a reference visualization to provide the quality measure against the
    generated one; differently, layers lacking this symbol entail quality metrics
    that do not rely on a predefined reference.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们将深入探讨这些级别，使用“什么、为什么和如何”的策略——什么是这个级别的范围，为什么它很重要，以及如何实施它。每个级别都由三个维度构成，这些维度与所有级别正交，并且必要用于描述评估结果的解释：评估可负担性、语义和人机比。评估可负担性作为每个级别具体可行性和对获得指标的信任的定性度量。例如，语法正确性级别在所提议的尺度上很高，如图[8(a)](#S7.F8.sf1
    "在图8 ‣ 7.4 用例2: 评估Llama-70b ‣ 7 用例 ‣ vi(E)va LLM! 用于评估和解释生成AI视觉化的概念堆栈")所示，因为它易于实现，并且具有明确的含义，几乎没有解释的空间。另一方面，重要性级别可以通过多种方式实现，并且留有较大的解释结果的空间；因此，在这一方面得分较低。语义定义了EvaLLM级别在多大程度上提供了对视觉化的语义评估。例如，语法正确性级别提供了最小的语义评估，仅限于表示生成的代码是否语法正确，而视觉化素养级别则提供了更高的语义评估，用于评估生成的视觉化在多大程度上符合最佳实践（即，视觉化可能被准确生成，但其对用户的有效性可能由于未遵循最佳实践而受到影响）。最后，人机比衡量了一个级别是否经过完全自动化的评估过程、依赖于基于人类的评估，还是两者的混合。5级李克特评分尺度从低（紫色）到高（深绿色），具有中低（粉色）、中等（白色）和中高（浅绿色）水平，为每个EvaLLM级别提供了定性的概述。为了清晰起见，我们将这些级别分为两个主要类别：名称中带有星号（*）的类别需要一个真实的参考视觉化来提供与生成视觉化的质量衡量；而缺少此符号的层级涉及的质量度量不依赖于预定义的参考。'
- en: 4.1 \faSquare Syntax correctness level
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 \faSquare 语法正确性级别
- en: What. The syntax correctness level is designed to verify whether or not an LLM-generated
    visualization is consistent within the syntax structure it is created with, i.e.,
    code-based or grammar-based, and it is executable in the related environment to
    render the visualization. Why. As it can be deducted, this level is pivotal in
    the stack to start evaluating a visualization. If the visualization code or the
    generated image has some structural errors and cannot be rendered, all the other
    levels are disabled in the evaluation process, and it stops here. How. Considering
    a grammar-based visualization, e.g., VegaLite, the syntax correctness level verifies
    that the generated visualization specification respects the grammar rules and,
    subsequently, can be executed. An additional check concerns the capability to
    render a visualization (e.g., the grammar specification could be correct for the
    data part but not presenting a rendering part). For instance, if the grammar choice
    is VegaLite, a straightforward implementation could involve the Altair library
    [[alt](#bib.bibx2)] to verify the correctness of generated specifications. Differently,
    if the grammar is VegaZero [[LTL^∗21b](#bib.bibx38)], the generated grammar could
    be verified using the method of sanity check proposed by the authors. For this
    level, the affordability is high (green) because the expected result can be shaped
    as a binary result - correct or not, leaving no space for the interpretation of
    the evaluation. Differently, the semantic dimension is low (violet) since this
    level involves only syntactic visualization properties. Like the previous dimension,
    the human-machine ratio is also low (violet), meaning these checks can be executed
    automatically.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 什么。语法正确性水平旨在验证LLM生成的可视化是否在其创建的语法结构内一致，即基于代码或基于语法，并且它是否在相关环境中可执行以呈现可视化。为什么。可以推断出，这个水平在评估可视化时至关重要。如果可视化代码或生成的图像存在一些结构性错误并且无法渲染，那么在评估过程中所有其他水平将被禁用，评估也会在此停止。如何。考虑基于语法的可视化，例如VegaLite，语法正确性水平验证生成的可视化规范是否遵守语法规则，并且随后是否可以执行。额外的检查涉及渲染可视化的能力（例如，语法规范可能对数据部分正确但未呈现渲染部分）。例如，如果语法选择是VegaLite，一种直接的实现方法可能涉及Altair库[[alt](#bib.bibx2)]来验证生成规范的正确性。相反，如果语法是VegaZero
    [[LTL^∗21b](#bib.bibx38)]，生成的语法可以使用作者提出的合理性检查方法进行验证。对于这一水平，其可行性很高（绿色），因为预期结果可以呈现为二元结果——正确或不正确，不留评估解释的空间。与前面的维度不同，语义维度较低（紫色），因为这个水平仅涉及语法可视化属性。与前一个维度类似，人机比例也很低（紫色），意味着这些检查可以自动执行。
- en: 4.2 \faSquare Code similarity level
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 \faSquare 代码相似性水平
- en: What. The Code Similarity level processes the visualizations from the previous
    level, treating both the generated and the ground truth as code snippets and evaluating
    their similarity. Why. This step is needed as, most of the time, the same or similar
    visualizations can be generated through quite different code constructs. On the
    other hand, small code changes may produce big changes in the final visualization.
    LLMs are tested at this level for their capability to construct a visualization
    code similar to what a human user would do or to evaluate the differences and
    eventually the reasons behind them (e.g., better generalizability, better usage
    of coding practices, more efficient code). How. Haq and Caballero [[HC21](#bib.bibx22)]
    propose an extensive review of more than 70 binary code similarity approaches
    that can be leveraged for this level depending on the chosen code environment.
    Another example in the coding realm that can be transposed in the visualization
    one is discussed in [[LPX^∗18](#bib.bibx35)]. The authors propose a method to
    compare two code snippets to get commonalities and differences between them. Then,
    this information is visualized using a graph highlighting the relationships between
    the two codes. Finally, in such a context where slight variations in syntax can
    lead to semantically equivalent outputs, fuzzy matches like BLUE [[Dod02](#bib.bibx13)]
    could overcome the problem of the other rigidity in comparing the code. In this
    case, the human-machine ratio is rated low, as the process can be entirely automated.
    On the semantic ratio, the score is medium-low as, while on the pure similarity,
    there is not much semantic involved, some semantic aspects can be captured by
    the patterns in which the LLM generates a specific visualization code. Analyzing
    them could improve the overall capability of the LLM to align with human specifications.
    Finally, the affordability is scored as high, as the structural construction can
    provide an initial level of assessment of the characteristics of the visualization
    (e.g., identifying missing code for specific parts of the generated visualization)
    and support a qualitative analysis of the compliance of the generated code with
    the ground truth.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 什么。代码相似度级别处理前一层级的可视化，将生成的和实际的代码片段作为代码片段进行处理，并评估它们的相似度。为什么。这一步骤是必要的，因为通常情况下，通过不同的代码构造可以生成相同或相似的可视化。另一方面，小的代码更改可能会导致最终可视化的重大变化。在这一层级，LLM被测试其构建与人类用户类似的可视化代码的能力，或者评估差异及其背后的原因（例如，更好的泛化能力、更好的编码实践、更高效的代码）。如何。Haq和Caballero
    [[HC21](#bib.bibx22)] 提出了对70多种二进制代码相似度方法的广泛综述，这些方法可以根据所选择的代码环境用于这一层级。在编码领域的另一个例子可以转化到可视化领域，讨论见
    [[LPX^∗18](#bib.bibx35)]。作者提出了一种比较两个代码片段以找出它们之间的共同点和差异的方法。然后，这些信息通过图形可视化，突出显示两个代码之间的关系。最后，在这样的背景下，语法的轻微变化可能导致语义上等效的输出，像BLUE
    [[Dod02](#bib.bibx13)] 这样的模糊匹配可以克服其他在代码比较中的刚性问题。在这种情况下，人机比率较低，因为该过程可以完全自动化。在语义比率方面，评分为中低，因为在纯相似性方面涉及的语义不多，但某些语义方面可以通过LLM生成特定可视化代码的模式来捕获。分析这些模式可以提高LLM与人类规格对齐的整体能力。最后，经济性评分为高，因为结构构造可以提供对可视化特征的初步评估（例如，识别生成的可视化特定部分缺失的代码），并支持对生成代码与实际情况的符合性进行定性分析。
- en: 4.3 \faSquare Grammar similarity level
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 \faSquare 语法相似度级别
- en: What. This level is tasked with measuring the similarity of the generated visualization’s
    grammar structure compared to the ground truth structure. This level focuses mainly
    on the represented structure and values and less on the single identifiers given
    to the structure keys. Why. The primary goal is to assess how effectively the
    model translates user query requests into a correct grammar structure. This structure
    should firlty align with the expected structure within the chosen grammar. Then,
    the assessment involves a comparison with the ground truth to check for efficiency
    in representation. Additionally, it aims to highlight structural differences in
    how a Language Model (LLM) represents the user query in the given grammar, comparing
    the results with the human-provided ground truth or with other LLMs.. How. A conceivable
    implementation utilizing a JSON-based grammar would focus on comparing only the
    keywords of the generated grammar with their ground truth counterparts, omitting
    consideration of the values assigned to the keywords, which are reserved for higher
    levels. A practical implementation is represented by Playwright [[Mic20](#bib.bibx39)]
    that easily allows the comparison of JSON structures and highlights possible differences.
    The affordability of this level is rated as high because the process results in
    a numerical similarity score between syntactical structures. At the same time,
    human analysis can isolate blocks for which, for example, the same semantic is
    captured but with very different structural forms. Furthermore, this process involves
    semantic analysis only for structural differences, leading to a medium-low semantic
    score. Finally, the human-machine ratio is set to medium-low, given the fully
    automated process that could be employed to generate the similarity score, with
    a human intervention only in analyzing the differences.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 什么。这个层级的任务是测量生成的可视化的语法结构与实际结构的相似性。这个层级主要关注所表示的结构和数值，而较少关注赋予结构键的单一标识符。为什么。主要目标是评估模型将用户查询请求翻译成正确语法结构的有效性。这个结构首先应与选择的语法中的预期结构对齐。然后，评估包括与实际结构的比较，以检查表示的效率。此外，它还旨在突出语言模型（LLM）在给定语法中表示用户查询的结构差异，并将结果与人类提供的实际结构或其他LLM的结果进行比较。如何。一个可行的实现方案是利用基于JSON的语法，这将专注于仅比较生成的语法中的关键字与其实际结构对应物，省略对关键字分配的值的考虑，这些值保留给更高层级。实际实施由
    Playwright [[Mic20](#bib.bibx39)] 表示，它可以轻松比较JSON结构并突出可能的差异。这个层级的可负担性被评为高，因为这个过程产生了语法结构之间的数值相似性分数。同时，人类分析可以隔离出例如捕捉到相同语义但具有非常不同结构形式的块。此外，这个过程仅涉及结构差异的语义分析，因此语义分数中等偏低。最后，考虑到完全自动化的过程可以生成相似性分数，而人类仅在分析差异时介入，因此人机比被设置为中等偏低。
- en: 4.4 \faSquare Data mapping level
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 \faSquare 数据映射层级
- en: What. This level measures how well the generated visualization encodes the right
    data from the dataset compared to the ground truth. It assesses whether the columns
    chosen from the dataset align with the ground truth and if the model adeptly maps
    them according to their correct types, for example, ordinal or temporal. Why.
    The main challenge is represented by ambiguous queries that could lead the model
    to select incorrect columns from the dataset, encode them in the wrong types on
    the axes, or hallucinate and select non-existing columns. How. A possible metric
    is the data axes accuracy proposed by Podo et al.[[PPV23](#bib.bibx46)]. The authors
    propose to use the accuracy defined as the number of data columns correctly predicted
    on the axes over all the instances evaluated. A similar approach to the previous,
    taken from the text-to-SQL field, is the Query match accuracy [[XLS17](#bib.bibx69)].
    This metric considers a prediction correct only if all the expected matches, axes
    values and types, are correct. The main limitation of this metric is related to
    the zero score problem. To overcome this problem, in [[HMB21](#bib.bibx24)], the
    authors propose the Partial Component Match F1. Unlike the previous accuracy metric,
    this metric considers each data mapping match alone and calculates the F1 score.
    The final PCMF1 score of a predicted output is actually the average F1 score of
    all the single matches. An other approach, specifically designed for D3, is proposed
    in [[HPM^∗23](#bib.bibx25)]. The authors propose an automatic approach for evaluating
    data bindings, visual encodings and other properties of a D3 visualization that
    could be involved to return a quality measure of a D3 LLM generated visualization.
    For this level, the affordability is medium due to the multiple data columns to
    consider and the possibility of defining a distance between different data types
    and evaluating the errors in non-binary form. Unlike affordability, semantics
    is scored medium-low since the data mapped conveys data semantics and analysis
    goals in isolation (i.e., single data columns) and in combination (e.g., correlation,
    trend analysis, etc.). Finally, the human-machine ratio is also medium-low. While
    the process is mainly automatic, it could benefit human evaluation to verify the
    resulting data mapped into the visualization, as discussed in [[KMK23](#bib.bibx32)].
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 什么。这个级别衡量生成的可视化如何准确地从数据集中编码正确的数据，相对于真实情况。它评估从数据集中选择的列是否与真实情况对齐，以及模型是否能熟练地将这些列映射到其正确的类型，例如，序数型或时间型。为什么。主要挑战在于模糊的查询可能导致模型选择错误的数据列，将其编码为错误的轴类型，或虚构并选择不存在的列。如何。一个可能的度量是
    Podo 等人提出的数据轴准确度[[PPV23](#bib.bibx46)]。作者建议使用准确度来定义为所有评估实例中在轴上正确预测的数据列数量。类似的做法，来自于文本到
    SQL 领域，是查询匹配准确度 [[XLS17](#bib.bibx69)]。该度量认为，只有当所有预期的匹配项、轴值和类型都正确时，预测才被认为是正确的。这个度量的主要限制与零分问题相关。为了解决这个问题，在
    [[HMB21](#bib.bibx24)] 中，作者提出了部分组件匹配 F1。与之前的准确度度量不同，这个度量单独考虑每个数据映射匹配并计算 F1 分数。预测输出的最终
    PCMF1 分数实际上是所有单个匹配的平均 F1 分数。另一个专门为 D3 设计的方法在 [[HPM^∗23](#bib.bibx25)] 中提出。作者提出了一种自动化方法，用于评估
    D3 可视化的数据绑定、视觉编码和其他属性，以返回 D3 LLM 生成的可视化的质量度量。对于这个级别，由于需要考虑多个数据列以及定义不同数据类型之间的距离和评估非二元形式的错误，负担中等。与负担不同，语义评分为中低，因为数据映射传达的数据语义和分析目标既可以单独（即单个数据列）也可以组合（例如，相关性、趋势分析等）呈现。最后，人机比例也是中低。虽然过程主要是自动化的，但它可能受益于人工评估，以验证映射到可视化中的数据，如
    [[KMK23](#bib.bibx32)] 中讨论的那样。
- en: 4.5 \faSquare Mark correctness level
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 \faSquare 标记正确性级别
- en: 'What. This level assesses the similarity between the visualization mark of
    the generated output and the corresponding ground truth and its usage of the chosen
    mark(s). Why. When a model produces a visualization, errors extend beyond simple
    mislabeling of the mark type, such as mistaking a bar for a line. The model may
    also introduce errors in how the mark is used in the overall structure of the
    visualization, creating what we labeled “visual hallucinations”. An example is
    illustrated in Figure [5](#S7.F5 "Figure 5 ‣ 7.3 Use case 1: Evaluating Codeinterpreter
    ‣ 7 Use cases ‣ vi(E)va LLM! A Conceptual Stack for Evaluating and Interpreting
    Generative AI-based Visualizations")-g, where the model correctly recognizes the
    bar mark as the one to use. Still, it fabricates an uncommon and not usual representation
    of a bar chart. How. A potential implementation could adopt a hybrid methodology:
    automated checks could verify the accuracy of the mark while identifying hallucinations
    might necessitate human scrutiny. Consequently, affordability is rated as medium-high,
    primarily because the evaluation of the used mark helps evaluate the correctness
    of the visual representation. At the same time, its wrong usage could hinder the
    quality of the final outcome. Similarly, the human-machine ratio is medium, as
    human reviewers may be needed and should manually annotate eventual strange usage
    of a well-known mark, describing its characteristics. On the other hand, the semantic
    aspect is medium-low, given that the analysis relies on syntactic properties.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '什么。此水平评估生成输出的可视化标记与相应真实值之间的相似性及其所使用的标记。为什么。当模型生成可视化时，错误不仅仅是标记类型的简单错误，比如把条形图误认为是折线图。模型还可能在标记在整体可视化结构中的使用上引入错误，产生我们称之为“视觉幻觉”的现象。一个例子如图[5](#S7.F5
    "图 5 ‣ 7.3 用例 1: 评估 Codeinterpreter ‣ 7 用例 ‣ vi(E)va LLM! 用于评估和解释生成性 AI 基于可视化的概念堆栈")-g
    所示，模型正确识别了使用的条形标记，但却生成了一种不常见的条形图表示。如何。潜在的实施方案可以采用混合方法：自动检查可以验证标记的准确性，而识别幻觉可能需要人工审查。因此，可承受性评分为中高，因为评估所使用的标记有助于评估视觉表示的正确性。同时，其错误使用可能会影响最终结果的质量。类似地，人机比为中等，因为可能需要人工审查员手动注释标记的奇怪使用情况，并描述其特征。另一方面，由于分析依赖于语法属性，语义方面为中低。'
- en: 4.6 \faSquare Axes quality level
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.6 \faSquare 轴质量水平
- en: What. The Axes Quality Level is structured to assess the quality of the axes’
    properties in a visualization. Why. The efficacy of a visualization hinges on
    its ability to clearly convey information to the users, with the axes playing
    a pivotal role. Optimal selection of these properties, such as axes orientation,
    scale, and ticks selection, is essential for delivering meaningful insights to
    users. How. One plausible implementation strategy entails an evaluation approach
    that compares the axes of the generated visualization with its ground truth. Alternatively,
    a set of rules defined by domain experts could be employed to assess the quality
    of the axes. For more complex axes properties, like axes arrangement, different
    methods and complexity could potentially be used for axes-based representation
    like parallel coordinates, radar chart, Radviz, or star coordinates. For this
    level, we assign a medium affordability score since the diverse approaches used
    can influence the interpretation of the results. Conversely, both the human-machine
    ratio and semantics are rated low. The assessment of axes quality relies predominantly
    on syntactic properties, and the evaluation process is mostly automatic.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 什么。轴质量水平的结构旨在评估可视化中轴的属性质量。为什么。可视化的效果依赖于其清晰传达信息的能力，其中轴扮演着关键角色。对这些属性的最佳选择，如轴的方向、刻度和刻度线选择，对于向用户提供有意义的见解至关重要。如何。一种可行的实施策略是通过将生成的可视化轴与其真实值进行比较的评估方法。或者，可以使用领域专家定义的一套规则来评估轴的质量。对于更复杂的轴属性，如轴的排列，可能需要不同的方法和复杂度用于基于轴的表示，如平行坐标图、雷达图、Radviz
    或星坐标图。对于这一水平，我们分配了中等的可承受性评分，因为所使用的不同方法可能会影响结果的解释。相反，人机比和语义的评分较低。轴质量的评估主要依赖于语法属性，评估过程大多是自动化的。
- en: 4.7 \faSquare Color mapping level
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.7 \faSquare 颜色映射水平
- en: What. This level examines the efficacy of color usage in encoding data attributes
    to convey data features. Why. The selection of a color palette depends on the
    nature of the data being represented. Evaluating how the model employs colors
    based on the data type and the chosen mark is pivotal for effective visualization
    and correct user interpretation. How. For example, Szafir et al. [[Sza17](#bib.bibx57)]
    provide a set of perceptual data results from crowd-sourced studies that could
    be used to create probabilistic models to provide support and evaluate the color
    properties of the visualizations. Another possible implementation is discussed
    by Liu et al. [[LH18](#bib.bibx33)] that, based on a set of experiments, provide
    methods to generate color recommendations that could be used to design quantitative
    color evaluation metrics. In Szafir et al. [[SG16](#bib.bibx50)], the authors
    propose a framework for optimizing the color choices in a data visualization that
    could be used to implement quantitative measures. The type of implementation significantly
    influences the process, leading to a medium rating for both the human-machine
    ratio and semantics. Users are tasked with characterizing results in this domain.
    In contrast, affordability is marked as medium-low, as the interpretation of results
    heavily connotates visualization quality.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 什么。这个层级考察了颜色使用在编码数据属性中以传达数据特征的效果。为什么。颜色调色板的选择取决于所表示数据的性质。评估模型如何基于数据类型和所选标记使用颜色对于有效可视化和正确用户解读至关重要。如何。例如，Szafir
    等人 [[Sza17](#bib.bibx57)] 提供了一组来自众包研究的感知数据结果，这些结果可以用于创建概率模型，以支持和评估可视化的颜色属性。另一个可能的实现方案由
    Liu 等人 [[LH18](#bib.bibx33)] 讨论，该方案基于一组实验，提供了生成颜色推荐的方法，这些方法可用于设计定量颜色评估指标。在 Szafir
    等人 [[SG16](#bib.bibx50)] 的研究中，作者提出了一个框架，用于优化数据可视化中的颜色选择，可以用于实现定量衡量。实现类型对过程的影响很大，导致人机比和语义的评分均为中等。用户需在此领域中对结果进行表征。相比之下，经济性被标记为中低，因为结果的解释与可视化质量密切相关。
- en: 4.8 \faSquare Image similarity level
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.8 \faSquare 图像相似度层级
- en: What. This level involves a pixel-level comparison between the generated visualization
    and the ground truth. Why. Conducting a pixel-level comparison abstracts the assessment
    of the generated visualization from the specific generating environment or evaluates
    its characteristics by the final generated image, offering a direct and perceptual
    evaluation of how well the image aligns with the ground truth. How. An effective
    strategy entails applying computer vision techniques to quantify the structural
    similarity between the images, such as SSIM [[RH08](#bib.bibx47)] or LPIPS [[KHL19](#bib.bibx29)].
    A different approach involves using the Siamese neural network [[AC17](#bib.bibx1)]
    for image comparison. Similar to the previous level, the affordability of the
    results is low, warranting a medium rating for similar reasons. The medium-high
    score also holds for the semantic and human-machine ratio, emphasizing the importance
    of the strategy in play.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 什么。这个层级涉及生成的可视化与真实数据之间的像素级比较。为什么。进行像素级比较将生成的可视化评估从特定生成环境中抽象出来，或通过最终生成的图像评估其特征，提供了图像与真实数据对齐的直接感知评估。如何。有效的策略包括应用计算机视觉技术来量化图像之间的结构相似性，如
    SSIM [[RH08](#bib.bibx47)] 或 LPIPS [[KHL19](#bib.bibx29)]。另一种方法是使用 Siamese 神经网络
    [[AC17](#bib.bibx1)] 进行图像比较。与前一层级类似，结果的经济性较低，原因类似，评分为中等。语义和人机比的评分也为中高，强调了所采用策略的重要性。
- en: 4.9 \faSquare Perceptual quality level
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.9 \faSquare 感知质量层级
- en: What. This level examines the visualization from a perceptual standpoint, focusing
    on ensuring that all perceptual properties are effectively encoded in the visualization
    and that it does not break any of the perceptual rules that are listed in visualization
    research (e.g., [[War19](#bib.bibx63)]). Why. Leveraging principles of visual
    perception, such as position along a common scale, length, direction, angle, area,
    and color hue, can help the visual interpretation from a human user and design
    more informative graphics. It is important to consider the effectiveness of visual
    encoding, ensuring that the importance of the attribute matches the salience of
    the channel used for them and avoid perceptual pitfalls like watchdog effects
    or usage of wrong visual channels. How. The control could be based on a stop list
    of perceptual pitfalls, eventually organized by visual marks, to be tested against
    the generated visualization to check for their presence automatically. On the
    contrary, assessing a human assessor is crucial at this level, as it can help
    identify more high-level problems faster. We have characterized this level as
    low for affordability as it can describe aspects of the visualization that strongly
    affect its final quality. At the same time, some of the proposed methods could
    introduce uncertainty in their evaluation and require human intervention. The
    same score is assigned to the Human-machine ratio (predominance of human judgment
    over automatic approaches) and semantics.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 什么。这个水平从感知的角度审视可视化，重点是确保所有感知属性在可视化中被有效编码，并且不违反可视化研究中列出的任何感知规则（例如，[[War19](#bib.bibx63)]）。为什么。利用视觉感知的原则，例如沿共同尺度的位置、长度、方向、角度、面积和颜色色调，可以帮助用户更好地进行视觉解释并设计更具信息性的图形。重要的是要考虑视觉编码的有效性，确保属性的重要性与用于这些属性的通道的显著性匹配，并避免如监视效应或使用错误视觉通道等感知陷阱。如何。控制可以基于感知陷阱的停止列表，最终按视觉标记组织，以便对生成的可视化进行测试以自动检查其存在。相反，在这一水平上评估人工评估者是至关重要的，因为它可以帮助更快地识别出更高层次的问题。我们将这一水平描述为低可负担性，因为它可以描述那些强烈影响最终质量的可视化方面。与此同时，一些提出的方法可能在其评估中引入不确定性并需要人工干预。相同的评分也分配给人机比例（人工判断优于自动方法）和语义。
- en: 4.10 \faSquare Visualization literacy level
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.10 \faSquare 可视化素养水平
- en: What. This evaluation level seeks to determine whether the model adhered to
    best practices in visualization literacy while generating the visualization. Why.
    After the model produces a visualization that excels in other previous evaluation
    criteria, it does not automatically imply optimal configuration. The visualization
    could be requested to comply with best practices tailored to fit the task or particular
    analysis on top of the visual representation and presentation choices. Therefore,
    assessing how the model incorporates best practices in generating the visualization
    is crucial. How. In this direction, different works have been proposed in the
    literature, such as the work by Boy et al. [[BRBF14](#bib.bibx5)] that proposes
    a series of visualization best practices for line charts, bar charts, and scatterplots.
    Another possible approach is discussed by Lee et al. [[LKK16](#bib.bibx34)] that
    introduces a visualization literacy assessment test (Vlat) exploitable for assessing
    the compliance of LLM-based visualizations. Finally, an other implementation is
    proposed in [[JSFL](#bib.bibx28)]. The authors propose an evaluation study of
    LLMs on Parallel Coordinate Plots, evaluating how well the models were able to
    adhere to the based practices, based on Bloom’s taxonomy. We classify the Semantic
    dimension as medium-high, as it demands a significant level of semantic understanding.
    While certain semantic aspects can be captured through patterns based on expert
    design rules, its overall complexity leans towards the higher end. Affordability
    is rated medium-low, primarily attributed to the absence of a well-defined output
    structure. Lastly, the human-machine ratio is set to high, necessitating the involvement
    of a human evaluator for effective processing.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 什么。这个评估级别旨在确定模型在生成可视化时是否遵循了最佳实践。为什么。在模型生成了在其他先前评估标准上表现出色的可视化之后，并不自动意味着最佳配置。可视化可能需要遵循量身定制的最佳实践，以适应任务或特定分析，这些实践基于视觉表示和展示选择。因此，评估模型在生成可视化时如何融入最佳实践是至关重要的。如何。在这个方向上，文献中提出了不同的研究工作，例如Boy等人的工作[[BRBF14](#bib.bibx5)]，提出了一系列用于折线图、条形图和散点图的可视化最佳实践。另一个可能的方法由Lee等人[[LKK16](#bib.bibx34)]讨论，介绍了一个可用于评估LLM基础可视化合规性的可视化素养评估测试（Vlat）。最后，[[JSFL](#bib.bibx28)]中提出了另一种实现方案。作者提出了对LLMs在平行坐标图上的评估研究，评估模型在遵循基于Bloom分类法的最佳实践方面的能力。我们将语义维度归类为中高，因为它要求较高的语义理解水平。虽然某些语义方面可以通过基于专家设计规则的模式来捕捉，但其整体复杂性偏向较高。适用性被评为中低，主要是由于缺乏明确的输出结构。最后，人机比例被设定为高，需要人工评估者的参与以有效处理。
- en: 4.11 \faSquare Significance level
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.11 \faSquare 显著性水平
- en: What. The significance layer represents the layer in the EvaLLM to measure the
    insightfulness [[BO23](#bib.bibx4)] of a visualization. Why. The significance
    is essential for analyzing complex data, identifying patterns, and extracting
    valuable insights. By simplifying complex information and presenting it visually,
    decision-makers can make informed and effective decisions quickly and accurately.
    How. As the visualization literacy level, this level should be implemented by
    involving a human reviewer using a dedicated platform. Performing this task automatically
    is extremely complex because the insightfulness lacks a mathematical formulation
    that could make the evaluation automatic. Interestingly, very recently, some work
    emerged in the Visual Analytics literature trying to mathematically formulate
    the relation between task support and insights generation, such as Suh et al. [[SMWC23](#bib.bibx51)]
    for hypotheses testing using a visualization system or the works by North et al. [[Nor06](#bib.bibx42),
    [NSD11](#bib.bibx43)] looking at most established literature. We have characterized
    this level as high for semantics and human machine ration dimensions. The considerable
    degree of interpretation required for the visualization assessment necessitates
    human intervention, and the outcome is inherently semantic. Unlike the previous,
    the output lacks a clearly defined structure, as seen in binary or quantitative
    evaluations, contributing to low affordability on the scale.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 什么。意义层表示 EvaLLM 中用于衡量可视化洞察力的层[[BO23](#bib.bibx4)]。为什么。意义层对于分析复杂数据、识别模式和提取有价值的见解至关重要。通过简化复杂的信息并以可视化方式呈现，决策者可以快速准确地做出明智且有效的决策。如何。作为可视化素养水平，这一层级应通过使用专用平台的人工审查者来实施。自动执行这项任务非常复杂，因为洞察力缺乏可以使评估自动化的数学公式。有趣的是，最近在视觉分析文献中出现了一些工作，尝试将任务支持与洞察生成之间的关系数学化，例如
    Suh 等人[[SMWC23](#bib.bibx51)] 使用可视化系统进行假设测试，或 North 等人的研究[[Nor06](#bib.bibx42),
    [NSD11](#bib.bibx43)]，关注大多数已建立的文献。我们将这一层级在语义和人机比率维度上定义为高。对可视化评估所需的广泛解释程度需要人工干预，结果本质上是语义性的。与之前不同，输出缺乏像二进制或定量评估那样明确的结构，这使得在尺度上的可承受性较低。
- en: 4.12 \faSquare LLM effort
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.12 \faSquare LLM 努力
- en: What. This level focuses on assessing the effort of generating a visualization
    considering computational and methodological factors. Looking at the former, such
    as the computational costs, the inference time (real-time versus quasi-real-time),
    and the size of the models, they return a quantitative assessment of the efficiency
    of the generative model. Looking at the latter, we list plain prompting (e.g.,
    a single prompt representing the full user query, as in the case of the queries
    present in the NVBench), degree of prompt engineering, Chain-of-thoughts [[WWS^∗22](#bib.bibx67)]
    (where the user split in a strategic way the sequence of prompts, enriching it
    with examples and counter-examples, to get a better-fit result) or by chaining
    results of multiple models or the same model multiple times. These different strategies
    present an increasing effort to be implemented, having as benefits potentially
    more precise results. The government of this trade-off between raised precision
    and incurring cost is what this level aims at measuring. Why. Generating a visualization
    using an LLM is not only a matter of visualization quality but also of the strategy’s
    performance and costs. For instance, even if using the same model with two different
    learning strategies could still generate the same expected visualization, the
    computational costs could be extremely different. Involving a zero-shot strategy
    is much computationally cheaper than fine-tuning a model, resulting in a minor
    effort. Hence, it cannot be concluded that one approach is better than another
    based only on the visual quality of the output, because also the effort is crucial
    to be considered. How? This level could be developed as a scoring function considering
    all the factors described to return an effort score. Based on the computational
    effort required, it could provide a normalized score - 0 low effort, 1 high effort.
    For example, if we consider the learning strategies, zero-shot would have a lower
    effort and consequently a low value, compared to fine-tuning, which requires a
    higher effort, resulting in a higher score. However, evaluating the effort associated
    with quantifying methodological factors poses challenges. For instance, generating
    an image with CoT may entail a different effort than using chaining methods. Moreover,
    even if the methodology remains constant, its implementation can vary among users,
    making automatic quantification more challenging. In light of these complexities,
    we assign a medium-low score for semantics. It’s important to note that this score
    isn’t a standalone numerical representation of effort but must be interpreted
    in the context of non-standard methodologies that differ based on user implementation.
    This nuanced approach also applies to the human-machine ratio, where human intervention
    may be necessary to quantify the effort involved in the user’s developed methodology.
    Ultimately, the affordability score is deemed medium-high due to the potential
    for human intervention in estimating the method, as opposed to automatically quantifying
    the effort for computational costs.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 什么。这一层级侧重于评估生成可视化的努力程度，考虑计算和方法论因素。就计算方面而言，如计算成本、推断时间（实时与准实时）以及模型的大小，它们会返回生成模型效率的定量评估。就方法论方面而言，我们列出了普通提示（例如，代表完整用户查询的单个提示，如
    NVBench 中的查询情况）、提示工程的程度、链式思维 [[WWS^∗22](#bib.bibx67)]（用户以战略性方式拆分提示序列，通过添加示例和反例来获得更符合需求的结果）或通过多次使用多个模型或同一模型的结果链。这些不同的策略在实施上呈现出越来越高的努力程度，可能带来更精确的结果。此层级旨在衡量这种提高精度与产生成本之间的权衡。为什么。使用
    LLM 生成可视化不仅仅涉及可视化质量，还涉及策略的表现和成本。例如，即使使用相同的模型和两种不同的学习策略可能仍会生成相同的期望可视化，但计算成本可能会有极大的差异。采用零-shot
    策略在计算上比微调模型便宜得多，因此需要的努力较少。因此，不能仅根据输出的视觉质量来得出一种方法优于另一种的方法，因为努力程度也是一个关键考虑因素。如何？这一层级可以通过考虑所有描述的因素来开发为评分函数，返回一个努力分数。根据所需的计算努力，它可以提供一个标准化的分数
    - 0 代表低努力，1 代表高努力。例如，如果考虑学习策略，零-shot 将具有较低的努力，因此分数较低，相比之下，微调需要更高的努力，因此分数较高。然而，评估与量化方法论因素相关的努力会面临挑战。例如，使用
    CoT 生成图像可能涉及不同于使用链式方法的努力。此外，即使方法论保持不变，其实施在不同用户中也可能有所不同，使得自动量化更加具有挑战性。考虑到这些复杂性，我们为语义分配了中低分数。需要注意的是，这个分数并不是对努力的独立数字表示，而必须在基于用户实施的非标准方法论的背景下进行解释。这种细致的方法也适用于人机比例，其中可能需要人工干预来量化用户开发方法中的努力。最终，鉴于在估算方法时可能需要人工干预，与自动量化计算成本的努力相比，价格评分被认为是中高的。
- en: 5 LLM as evaluator
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 LLM 作为评估者
- en: 'In the previous section, we have proposed the implementation of evaluation
    operations through a reasoned mix of automatic approaches and human involvement.
    For instance, we advocate for a fully automatic evaluation using a deterministic
    approach at the Syntax Correctness level. Conversely, for the Significance level,
    we have highlighted how human evaluation is better for assessing the visual quality
    of the presented data than automatic approaches. While existing literature presents
    various automatic approaches, they are limited to a fixed number of EvaLLM levels
    and present more difficulty in being applied for the higher levels in the stack.
    Conversely, human evaluators can cover them, but their activities introduce not
    negligible cost in terms of time and effort needed. In this context, we identify
    a new opportunity by involving the LLM as an additional evaluator, presenting
    a favorable trade-off between automatic and human evaluation. The LLM is orthogonal
    to all EvaLLM levels and represents an opportunity for implementing or supplementing
    existing approaches and for evaluation techniques, as discussed in recent contributions
    in the literature [[CL23](#bib.bibx8), [SSZ^∗23](#bib.bibx56), [FNJL23](#bib.bibx17)].
    However, while the LLM can potentially contribute to each level, a nuanced evaluation
    of its application at different levels becomes crucial, identifying the best fit,
    risks, and opportunities (see Figure [2](#S5.F2 "Figure 2 ‣ 5 LLM as evaluator
    ‣ vi(E)va LLM! A Conceptual Stack for Evaluating and Interpreting Generative AI-based
    Visualizations")). For instance, introducing the LLM at the Syntax Correctness
    level could result in an over-engineered solution, adding complexity and increasing
    evaluation costs for a task more efficiently addressed by classic automatic techniques.
    Differently, involving an LLM at the Significance level, where automatic approaches
    face challenges and human evaluation is costly and time-consuming, represents
    a valuable opportunity, to complement with risk indicators and explanations of
    the LLM decisions. In the middle of these two extremes, we identify best-fit scenarios:
    for example, considering the image similarity level, assessing the benefits against
    costs is essential: despite the LLM’s capacity to interpret images, it is critical
    to quantify its advantages against alternatives such as diffusion models or traditional
    computer vision techniques.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一部分中，我们提出了通过自动方法与人工参与的合理混合来实施评估操作。例如，我们提倡在语法正确性层面使用确定性方法进行完全自动化评估。相反，对于重要性层面，我们强调了人类评估在评估呈现数据的视觉质量方面优于自动方法。尽管现有文献提出了各种自动方法，但它们仅限于固定数量的EvaLLM层级，并且在应用于栈中的更高层级时存在更多困难。相反，人类评估者可以涵盖这些层级，但他们的活动在时间和精力上引入了不可忽视的成本。在这种情况下，我们通过引入LLM作为额外的评估者来发现了一种新机会，提供了自动评估与人工评估之间有利的权衡。LLM与所有EvaLLM层级正交，代表了实现或补充现有方法和评估技术的机会，如文献中最近的贡献所讨论的[[CL23](#bib.bibx8)、[SSZ^∗23](#bib.bibx56)、[FNJL23](#bib.bibx17)]。然而，尽管LLM可以对每个层级做出潜在贡献，但对其在不同层级应用的细致评估变得至关重要，以确定最佳适配、风险和机会（见图[2](#S5.F2
    "图 2 ‣ 5 LLM 作为评估者 ‣ vi(E)va LLM! 评估和解释生成式 AI 基于可视化的概念栈")）。例如，将LLM引入语法正确性层级可能导致过度工程化的解决方案，为经典自动化技术更有效解决的任务增加复杂性和评估成本。不同的是，将LLM引入面临挑战的自动方法和成本高昂且耗时的人工评估的显著性层级，代表了一种有价值的机会，可以与LLM的风险指标和决策解释进行补充。在这两个极端之间，我们识别出最佳适配的场景：例如，考虑图像相似性层级，评估效益与成本是至关重要的：尽管LLM具有解释图像的能力，但量化其相对于扩散模型或传统计算机视觉技术的优势是关键的。
- en: Exploring this new prospect lies beyond the scope of this paper, not affecting
    the EvaLLM stack definition but complementing its implementation with a new possibility,
    that will be the subject of future research activities.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 探索这一新前景超出了本文的范围，但它不会影响EvaLLM栈的定义，而是通过提供一种新的可能性来补充其实现，这将成为未来研究活动的主题。
- en: '![Refer to caption](img/cacd189878a55a6f562c7816d5bd9884.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/cacd189878a55a6f562c7816d5bd9884.png)'
- en: 'Figure 2: TThe image depicts the LLM’s potential involvement at each level,
    with colors indicating impact in the three scenarios discussed. Red signifies
    suboptimal integration, yellow prompts further evaluation, and green denotes positive
    impacts.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：该图描绘了LLM在每个层级的潜在参与情况，颜色表示在讨论的三个场景中的影响。红色表示集成不佳，黄色提示进一步评估，绿色表示积极影响。
- en: 6 EvaLLM assisting evaluation platform
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 EvaLLM 辅助评估平台
- en: '| Level | Description | Formula(s) | Human-Ratio |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 级别 | 描述 | 公式 | 人工比例 |'
- en: '| Syntax Correctness | Outputs 1 if the visualization is rendered successfully,
    0 if not. | - | \faCogs |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 语法正确性 | 如果可视化成功渲染，则输出 1；否则输出 0。 | - | \faCogs |'
- en: '| Code Similarity | Returns the similarity between G.T and Generated Viz. in
    terms of code plagiarism | PyCode Similarity Library | \faCogs |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 代码相似度 | 返回 G.T 和生成的可视化在代码抄袭方面的相似度 | PyCode 相似度库 | \faCogs |'
- en: '| Grammar Similarity | Calculates the similarity between the schemas of the
    G.T and Generated Viz. | Jaccard Similarity between the sets of keys in schema
    of the two visualizations | \faCogs |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 语法相似度 | 计算 G.T 和生成的可视化之间模式的相似度。 | 两个可视化模式中键的集合之间的 Jaccard 相似度 | \faCogs |'
- en: '| Data Mapping | Assesses the data correctness of the Generated Viz. against
    G.T. | $\left\{\begin{matrix}100&amp;ifData_{\text{G.T}}=Data_{\text{Gen}}\\ \frac{\text{Matched
    Data Count}}{\text{Total Data Keys}}\times 100&amp;ow.\end{matrix}\right.$ | \faCogs
    |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 数据映射 | 评估生成的可视化与 G.T. 之间的数据正确性。 | $\left\{\begin{matrix}100\ &\text{if }Data_{\text{G.T}}=Data_{\text{Gen}}\\
    \frac{\text{匹配的数据计数}}{\text{总数据键}}\times 100\ &\text{otherwise.}\end{matrix}\right.$
    | \faCogs |'
- en: '| Mark Correctness | Outputs 1 if mark type of Generated Viz. is same as that
    of G.T, 0 if not. | $\text{if Mark}_{\text{Gen}}=\text{Mark}_{\text{G.T}}\ \text{return}\
    1\ \text{else}\ 0$ | \faCogs |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 标记正确性 | 如果生成的可视化的标记类型与 G.T 的标记类型相同，则输出 1；否则输出 0。 | $\text{if 标记}_{\text{Gen}}=\text{标记}_{\text{G.T}}\
    \text{return}\ 1\ \text{else}\ 0$ | \faCogs |'
- en: '| Axes Quality | Measures the quality of axes of visualization based on the
    axes in G.T and context of user query. | Strict comparison of encoding properties
    (axes) and human interpretation | \faUserCog |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 坐标轴质量 | 根据 G.T 中的坐标轴和用户查询的上下文来衡量可视化坐标轴的质量。 | 编码属性（坐标轴）和人工解读的严格比较 | \faUserCog
    |'
- en: '| Color Mapping | Quality of the color mapping is measured against type of
    data in G.T and user query | Human Interpretation and Evaluation | \faUser |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 颜色映射 | 颜色映射的质量与 G.T 中的数据类型和用户查询进行比较 | 人工解读和评估 | \faUser |'
- en: '| Image Similarity | Returns pixel level similarity/distance between the two
    visualizations | $\text{Image Similarity}_{\text{LPIPS}}=100-\text{LPIPS Distance(G.T,
    Gen)}$ $\text{Image Similarity}_{\text{SSI}}=\text{SSI(G.T, Gen)}\times 100$ |
    \faCogs |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 图像相似度 | 返回两个可视化之间的像素级相似度/距离 | $\text{图像相似度}_{\text{LPIPS}}=100-\text{LPIPS
    距离(G.T, Gen)}$ $\text{图像相似度}_{\text{SSI}}=\text{SSI(G.T, Gen)}\times 100$ | \faCogs
    |'
- en: '| Perceptual Similarity | Perceptual accuracy is determined in this level |
    Human Interpretation and Evaluation | \faUser |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 感知相似度 | 在此级别上确定感知准确性 | 人工解读和评估 | \faUser |'
- en: '| Visualization Literacy | Assesses the visualization on the basis of best
    standards of visualizations | Human Interpretation and Evaluation | \faUser |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 可视化素养 | 根据最佳可视化标准评估可视化 | 人工解读和评估 | \faUser |'
- en: '| Significance | Measures the insightfulness of the visualization | Human Interpretation
    and Evaluation | \faUser |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 重要性 | 测量可视化的洞察力 | 人工解读和评估 | \faUser |'
- en: 'Table 1: Enhancing EvaLLM Stack Levels: Approach and Design choice for evaluation
    at each stack level. In human terms, \faCogssymbolizes a fully automatic approach,
    \faUserCogrefers to the hybrid approach, and \faUserrepresents a fully human evaluation
    approach.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：增强 EvaLLM 堆栈级别：每个堆栈级别的评估方法和设计选择。用人类术语来说，\faCogssymbolizes 完全自动的方法，\faUserCogrefers
    于混合方法，而 \faUser 代表完全人工评估方法。
- en: 'To prove the EvaLLM stack’s implementation and support the automatic and manual
    evaluation activities that the stack implies, we developed an online evaluation
    platform based on it. The platform’s design supports an incremental workflow where
    a generated visualization passes through it, and it is evaluated on the different
    EvaLLM levels using a selection of possible evaluation metrics implemented at
    each level. To implement the platform, we report design choices at each level
    of the EvaLLM stack in Table [1](#S6.T1 "Table 1 ‣ 6 EvaLLM assisting evaluation
    platform ‣ vi(E)va LLM! A Conceptual Stack for Evaluating and Interpreting Generative
    AI-based Visualizations"). Moreover, the assessments are categorized into two
    distinct methods: automated processes, where the platform furnishes direct scoring,
    and manual activities, wherein the platform facilitates the collaboration of multiple
    users (referred to as assessors) engaged in manual evaluation tasks. The evaluation
    platform uses a Python code base and an Angular frontend. The instance we provide
    is available at the following link: [https://github.com/lucapodo/evallm.git](https://github.com/lucapodo/evallm.git).
    It represents an exemplification of how EvaLLM can be put into practice, It has
    been effectively used to populate the evaluation data discussed for the presented
    use cases in Section [7](#S7 "7 Use cases ‣ vi(E)va LLM! A Conceptual Stack for
    Evaluating and Interpreting Generative AI-based Visualizations").'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 为了证明EvaLLM堆栈的实现并支持堆栈所涉及的自动和手动评估活动，我们开发了一个基于该堆栈的在线评估平台。该平台的设计支持递增的工作流程，其中生成的可视化通过平台，并在不同的EvaLLM级别上使用每个级别实现的一系列可能的评估指标进行评估。为了实现该平台，我们在表格[1](#S6.T1
    "Table 1 ‣ 6 EvaLLM assisting evaluation platform ‣ vi(E)va LLM! A Conceptual
    Stack for Evaluating and Interpreting Generative AI-based Visualizations")中报告了EvaLLM堆栈每个级别的设计选择。此外，评估被分为两种不同的方法：自动化过程，其中平台提供直接评分；以及手动活动，其中平台促进多个用户（称为评估人员）参与手动评估任务。评估平台使用Python代码库和Angular前端。我们提供的实例可以在以下链接访问：[https://github.com/lucapodo/evallm.git](https://github.com/lucapodo/evallm.git)。这代表了EvaLLM如何付诸实践的一个示例，它已被有效地用于填充第[7](#S7
    "7 Use cases ‣ vi(E)va LLM! A Conceptual Stack for Evaluating and Interpreting
    Generative AI-based Visualizations")节中讨论的评估数据。
- en: '![Refer to caption](img/9b79618bf7eb2d33d23f9fd002998128.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/9b79618bf7eb2d33d23f9fd002998128.png)'
- en: 'Figure 3: EvaLLMStack: concept evaluation stack for evaluating the LLM-generated
    visualizations'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：EvaLLMStack：用于评估LLM生成的可视化的概念评估堆栈
- en: 6.1 Platform Interface
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 平台接口
- en: 'An overview of the EvaLLM platform is visible in Figure [3](#S6.F3 "Figure
    3 ‣ 6 EvaLLM assisting evaluation platform ‣ vi(E)va LLM! A Conceptual Stack for
    Evaluating and Interpreting Generative AI-based Visualizations"). The visual design
    organizes the view into two main areas: the data and filter environment (Figure [3](#S6.F3
    "Figure 3 ‣ 6 EvaLLM assisting evaluation platform ‣ vi(E)va LLM! A Conceptual
    Stack for Evaluating and Interpreting Generative AI-based Visualizations").A)
    and the visual evaluation environment (Figure [3](#S6.F3 "Figure 3 ‣ 6 EvaLLM
    assisting evaluation platform ‣ vi(E)va LLM! A Conceptual Stack for Evaluating
    and Interpreting Generative AI-based Visualizations").B). Focusing on the former
    lets the human assessor review and explore the sets of experiments run through
    the LLM under evaluation. The assessor can upload the results of the tests run
    for the LLM into the system and study them. Through this view, specific filters
    can be used to retrieve particular instances, or a filter search bar allows retrieving
    them by keywords present in the tested prompts. This design choice has been taken
    to decouple the automatic testing phase from the human-based evaluation and analysis
    of results, as the first phase could be pretty long and could be run in a different
    environment (e.g., Google Colab, local machine, AWS Sagemaker). The visual evaluation
    environment allows instead to explore single instances of the run experiments
    for manual inspection: the rationale is permitting a pool of assessors to (a)
    review the set of automatic scores computed at the different levels of the EvaLLM
    stack (e.g., evaluate the syntax correctness, or the mark correctness), and (b)
    allowing manual labeling for the stack level for which manual activities have
    been designed (e.g., evaluating the significance of a generated visualization,
    or the adherence to visualization literacy). For this reason, it reports the rendered
    visualizations coming from the ground truth (on the left) and the one generated
    from the tested LLM (on the right) in the central area. Above them is reported
    the text of the original prompt used for generating the visualization to provide
    contextual information for the human assessor. Where present in the ground truth,
    the task’s degree of difficulty is reported, too, along with additional contextual
    information. The human assessor can manually review and inspect the differences
    between the two visualizations and, related to the mostly manual levels of the
    EvaLLM stack (e.g., the presentation layer), annotate potential anomalies/errors
    discovered using the platform. The inserted annotations report the error’s name
    and the number of votes that different human assessors have expressed for that
    error. An assessor can even insert a new type of error or retain the ones already
    inserted by other assessors to minimize duplication and ambiguity. The interface
    to execute this operation is at the far side of the generated visualization and
    the ground truth. The explanation for supporting this task and the ground truth
    could seem counter-intuitive. Still, we chose to keep it as, during our preliminary
    test with NVbench data, we were confronted multiple times with situations in which
    even the ground truth seemed to present some minor errors on perceptual quality
    or visualization literacy levels. In contrast, the LLM-based one did not give
    these errors. To avoid penalizing this case for not adhering entirely to the ground
    truth, we choose to allow manual labeling for them. Finally, in the bottom part
    of the interface, the scores for the automatic evaluation functions defined for
    EvaLLM levels can be reviewed. They are organized using a small multiples visualization
    technique, where each score is reported, and the name, numerical value, and simple
    progress bar are colored according to how good the score is. A pool of human assessors
    can independently traverse the tested cases, review the automatic scores, complete
    the manual labeling, be supported in commuting final consensus, and complete the
    evaluation campaign for one LLM or a set of LLMs. When the activity is finished,
    all the data can be exported as a JSON file for further analysis or communication.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: EvaLLM平台的概述见图[3](#S6.F3 "Figure 3 ‣ 6 EvaLLM assisting evaluation platform ‣
    vi(E)va LLM! A Conceptual Stack for Evaluating and Interpreting Generative AI-based
    Visualizations")。视觉设计将视图分为两个主要区域：数据和过滤环境（图[3](#S6.F3 "Figure 3 ‣ 6 EvaLLM assisting
    evaluation platform ‣ vi(E)va LLM! A Conceptual Stack for Evaluating and Interpreting
    Generative AI-based Visualizations").A）和视觉评估环境（图[3](#S6.F3 "Figure 3 ‣ 6 EvaLLM
    assisting evaluation platform ‣ vi(E)va LLM! A Conceptual Stack for Evaluating
    and Interpreting Generative AI-based Visualizations").B）。关注前者可以让人工评估者审查和探索通过待评估的LLM运行的一组实验。评估者可以将LLM运行测试的结果上传到系统中并进行研究。通过该视图，可以使用特定的过滤器检索特定实例，或者使用过滤器搜索栏通过测试提示中的关键词进行检索。这一设计选择旨在将自动测试阶段与基于人工的结果评估和分析解耦，因为第一个阶段可能非常长，并且可能在不同的环境中运行（例如，Google
    Colab，本地机器，AWS Sagemaker）。而视觉评估环境则允许探索运行实验的单个实例以进行人工检查：其理由是允许一组评估者（a）审查EvaLLM堆栈不同级别计算的自动评分（例如，评估语法正确性或标记正确性），以及（b）允许手动标注针对设计了手动活动的堆栈级别（例如，评估生成的可视化的意义或遵循可视化素养）。因此，它在中央区域报告来自地面真实情况（左侧）和测试LLM生成的（右侧）的渲染可视化。在它们上方报告了生成可视化所使用的原始提示文本，以为人工评估者提供上下文信息。在地面真实情况中，如果存在任务的难度级别，也会报告，并附上额外的上下文信息。人工评估者可以手动审查和检查两个可视化之间的差异，并且与EvaLLM堆栈中主要手动级别（例如，展示层）相关，标注通过平台发现的潜在异常/错误。插入的注释报告了错误的名称和不同人工评估者对该错误表达的投票数量。评估者甚至可以插入一种新的错误类型或保留其他评估者已经插入的错误，以最小化重复和歧义。执行此操作的界面位于生成的可视化和地面真实情况的远侧。支持此任务的解释和地面真实情况可能看起来直觉不强。然而，我们选择保留它，因为在我们对NVbench数据的初步测试中，我们多次遇到即使是地面真实情况也似乎在感知质量或可视化素养级别上存在一些小错误的情况，而基于LLM的则没有这些错误。为了避免因为完全不符合地面真实情况而惩罚这种情况，我们选择允许对其进行手动标注。最后，在界面的底部，可以审查为EvaLLM级别定义的自动评估函数的分数。这些分数使用小倍数可视化技术组织，每个分数都有报告，名称、数值和简单进度条根据分数的好坏进行着色。一组人工评估者可以独立遍历测试案例，审查自动分数，完成手动标注，协助达成最终共识，并完成对一个LLM或一组LLM的评估活动。当活动结束时，所有数据可以导出为JSON文件以供进一步分析或交流。
- en: This paper investigated the elements to consider for evaluating in a comprehensive
    and fine-grained way an LLM-based generated visualization. Those elements were
    condensed and structured formally into the proposed EvaLLM stack, the first proposal
    targeted at LLMs. To make the stack applicable and useful for instructing benchmarking
    activities, we contributed a web-based platform that can support implementing,
    testing and reviewing the results of the evaluation using EvaLLM. Additionally,
    it also supports the implementation of manual labelling from multiple assessors.
    Two use cases, based on Code Interpreter and Llama-70b show the benefits and results
    obtainable by using the proposed evaluation stack and platform.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 本文研究了全面且细致地评估 LLM 基于生成的可视化时需要考虑的元素。这些元素被浓缩并正式构建成所提出的 EvaLLM 堆栈，这是针对 LLM 的第一个提案。为了使堆栈适用于和有助于指导基准活动，我们贡献了一个基于网络的平台，可以支持使用
    EvaLLM 实施、测试和审查评估结果。此外，它还支持多评估者的手动标注。基于代码解释器和 Llama-70b 的两个使用案例展示了使用所提议的评估堆栈和平台所能获得的好处和结果。
- en: In future works, we plan to extend the experimental setup to more samples from
    the used datasets, additional datasets and models. We also foresee providing a
    survey on existing techniques that in visualization and visual analytics literature
    can support the implementation of the evaluation at the different levels of EvaLLM.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在未来的工作中，我们计划将实验设置扩展到更多来自已用数据集的样本、额外的数据集和模型。我们还预见到提供对现有技术的调查，这些技术在可视化和视觉分析文献中可以支持在不同级别的
    EvaLLM 实现评估。
- en: 7 Use cases
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 个使用案例
- en: This section shows the advantages that using EvaLLM enables through two practical
    use cases. Our chosen scenarios involve evaluating the capabilities of GPT-3.5-Turbo
    Codeinterpreter and Llama2-70b ¹¹1[https://platform.openai.com/docs/models](https://platform.openai.com/docs/models),
    [https://ai.meta.com/llama/](https://ai.meta.com/llama/) to generate VegaLite
    visualizations from a given dataset, and a user query. The dataset is a reduced
    version of the well-known NVBench dataset that remains representative of its visualization
    general characteristics.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 本节展示了使用 EvaLLM 通过两个实际使用案例所带来的优势。我们选择的场景涉及评估 GPT-3.5-Turbo Codeinterpreter 和
    Llama2-70b ¹¹1[https://platform.openai.com/docs/models](https://platform.openai.com/docs/models)、[https://ai.meta.com/llama/](https://ai.meta.com/llama/)
    在从给定数据集和用户查询中生成 VegaLite 可视化的能力。数据集是著名 NVBench 数据集的简化版，仍然代表其可视化的一般特征。
- en: 7.1 Methodology
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1 方法论
- en: The primary objective of these use cases is to provide an example of how to
    assess the capabilities of Llama2-70b and GPT-3.5-turbo, two real and used LLMs,
    in generating a visualization grammar based on the input of a dataset and a user
    query. The interaction with the LLMs is facilitated through the zero-shot prompt
    engineering technique in both scenarios. Zero-shot prompting [[XLSA18](#bib.bibx70)]
    entails querying the LLM to produce task-specific output without providing any
    examples or additional context in input. An example is to ask the model to generate
    a VegaLite visualization based solely on a dataset and a user utterance.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这些使用案例的主要目标是提供一个如何评估 Llama2-70b 和 GPT-3.5-turbo 这两个真实且使用中的 LLM 的能力的示例，以生成基于数据集输入和用户查询的可视化语法。与
    LLM 的互动通过零样本提示工程技术在这两种情况下得以实现。零样本提示 [[XLSA18](#bib.bibx70)] 涉及查询 LLM 以生成特定任务的输出，而不提供任何示例或额外的上下文输入。例如，可以要求模型仅基于数据集和用户的发言生成
    VegaLite 可视化。
- en: 'This approach takes advantage of the inherent knowledge embedded in the LLM
    during the training phase to solve the proposed task. More sophisticated approaches,
    but requiring more effort, may involve few-shot learning or fine-tuning the model
    on the specific task. To generate responses, the models are queried with a user
    utterance and a dataset mapped into a predefined prompt template. In the first
    use case, a code wrapper is employed to facilitate the model’s processing of the
    visualization as code, subsequently returning it as a grammar structure. Conversely,
    the second use case involves the raw model without any intermediary wrapper. Irrespective
    of the interaction type, the models share a common objective: returning the most
    pertinent VegaLite grammar visualization for the provided user utterance and dataset.
    The quality of the generated visualization is evaluated against ground truth using
    the EvaLLM platform to produce the final evaluation outcome. The methodology employs
    an automatic analysis for the code and representation layer, complemented by a
    human-based evaluation focusing on the presentation, and application layers. Following
    classic benchmarks for LLM performances, qualitative aggregate results are summarized
    using a radar chart, considering only the automatic measure score'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法利用了在训练阶段嵌入在LLM中的固有知识来解决提出的任务。更复杂的方法，但需要更多的努力，可能涉及少量学习（few-shot learning）或在特定任务上对模型进行微调。为了生成响应，模型会以用户的发言和映射到预定义提示模板的数据集作为查询。在第一个用例中，使用代码包装器来帮助模型处理作为代码的可视化，然后将其返回为语法结构。相反，第二个用例涉及没有任何中介包装器的原始模型。无论交互类型如何，模型共享一个共同的目标：为提供的用户发言和数据集返回最相关的VegaLite语法可视化。生成的可视化质量通过EvaLLM平台与真实值进行比较，以产生最终的评估结果。该方法论采用自动分析代码和表示层，辅以针对呈现和应用层的人为评估。根据LLM性能的经典基准，定性综合结果通过雷达图进行总结，仅考虑自动测量分数。
- en: 7.2 Setup
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2 设置
- en: 'As outlined in the methodology, the setup for both use cases is generally consistent,
    differing primarily in the model employed and the utilization of a code model
    wrapper. The experimental models include Meta’s Llama2-70b and OpenAI’s GPT-3.5-turbo.
    Specifically, for Llama2-70b, we utilized the plain model without any wrapper.
    In contrast, for GPT-3.5-turbo, we employed the open-source CodeInterpreterAPI [[Scnt](#bib.bibx49)].
    This wrapper seamlessly integrates with the OpenAI GPT API, offering a fully integrated
    interface. For Llama, we opted for the cloud service DeepInfra  [[Ltd23](#bib.bibx36)],
    allowing us to query the model through API calls and maintain the model’s operation
    on A100 GPUs. To direct the models towards the defined objectives, we used the
    nvBench dataset  [[LTL21a](#bib.bibx37)], considering a qualitative subset of
    50 instances. As discussed, nvBench serves as a benchmark dataset for Natural
    Language to Visualization (NL2VIS) applications, providing instances that include
    user utterances for visualization generation, related datasets, and the corresponding
    visualizations in VegaLite. Each instance passed to the models is reshaped using
    the prompt template based on the one proposed by Alpaca [[TGZ^∗23](#bib.bibx60)].
    Subsequently, we evaluated the code layer and representation quality measures
    using an automatic approach, ensuring the essential structure of Json Vega-Lite
    matched. Human reviewers were also engaged for the presentation and application
    layers. More in detail, each level of EvaLLM was managed using the following approach:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如方法论所述，两种用例的设置一般是一致的，主要区别在于所使用的模型和代码模型包装器的利用。实验模型包括Meta的Llama2-70b和OpenAI的GPT-3.5-turbo。具体而言，对于Llama2-70b，我们使用了不带任何包装器的普通模型。相比之下，对于GPT-3.5-turbo，我们使用了开源的CodeInterpreterAPI
    [[Scnt](#bib.bibx49)]。该包装器与OpenAI GPT API无缝集成，提供了一个完全集成的接口。对于Llama，我们选择了云服务DeepInfra
    [[Ltd23](#bib.bibx36)]，允许我们通过API调用查询模型，并在A100 GPUs上维持模型的运行。为了将模型引导到定义的目标，我们使用了nvBench数据集
    [[LTL21a](#bib.bibx37)]，考虑了一个由50个实例组成的定性子集。如前所述，nvBench作为自然语言到可视化（NL2VIS）应用的基准数据集，提供了包括生成可视化的用户发言、相关数据集和对应VegaLite可视化的实例。每个传递给模型的实例都使用基于Alpaca
    [[TGZ^∗23](#bib.bibx60)] 提出的提示模板进行重塑。随后，我们使用自动方法评估了代码层和表示质量措施，确保Json Vega-Lite的基本结构匹配。也有人工评审员参与了呈现和应用层的评估。更详细地说，EvaLLM的每一层使用以下方法进行管理：
- en: •
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Syntactic correctness level: Altair was employed to verify the correctness
    of the JSON structure.'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 语法正确性等级：使用了 Altair 来验证 JSON 结构的正确性。
- en: •
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Code similarity: The [[Fyr20](#bib.bibx19)] Python library was utilized.'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 代码相似性：使用了[[Fyr20](#bib.bibx19)] Python 库。
- en: •
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Grammar similarity: A custom function was defined to compare two JSON structures
    without involving the values for the keys.'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 语法相似性：定义了一个自定义函数来比较两个 JSON 结构，而不涉及键的值。
- en: •
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Data mapping, mark correctness, axes quality: Custom JSON functions were implemented
    to compare corresponding fields between the ground truth and predictions.'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据映射、标记正确性、坐标轴质量：实现了自定义 JSON 函数，以比较地面真相与预测之间的对应字段。
- en: •
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Color, image, perceptual, visualization, and significance levels: These aspects
    were evaluated based on a human reviewer approach, involving two users who reviewed
    the generated visualizations and provided labels corresponding to potential errors
    generated by the models.'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 颜色、图像、感知、可视化和重要性等级：这些方面基于人工审查方法进行了评估，涉及两名用户，他们审查了生成的可视化内容并提供了与模型生成的潜在错误相对应的标签。
- en: The full setup is summarized in Table [1](#S6.T1 "Table 1 ‣ 6 EvaLLM assisting
    evaluation platform ‣ vi(E)va LLM! A Conceptual Stack for Evaluating and Interpreting
    Generative AI-based Visualizations"). All the code and the platform will be accessible
    on this link [https://github.com/lucapodo/evallm](https://github.com/lucapodo/evallm),for
    running the experiment.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的设置总结见表 [1](#S6.T1 "表 1 ‣ 6 EvaLLM 辅助评估平台 ‣ vi(E)va LLM! 一个用于评估和解释生成性 AI 基于可视化的概念堆栈")。所有代码和平台将通过此链接
    [https://github.com/lucapodo/evallm](https://github.com/lucapodo/evallm) 提供，以便进行实验。
- en: '7.3 Use case 1: Evaluating Codeinterpreter'
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3 用例 1：评估 Codeinterpreter
- en: 'In our investigation, we initially delved into the nvBench dataset, focusing
    our evaluation on a representative subset of 50 instances randomly sampled from
    the full dataset. Focusing on code and representation layers, the analysis of
    the results indicates that the model successfully generated 48 valid visualizations
    out of the 50 proposed samples from the dataset. These visualizations are deemed
    valid due to their compatibility with the VegaLite rendering. Figure [4](#S7.F4
    "Figure 4 ‣ 7.3 Use case 1: Evaluating Codeinterpreter ‣ 7 Use cases ‣ vi(E)va
    LLM! A Conceptual Stack for Evaluating and Interpreting Generative AI-based Visualizations")
    provides an overview of the model’s performance for three dimensions: mark type,
    x-axis field, and y-axis field accuracy. It can be observed how the model exhibited
    an adequate mark accuracy rate, with only 5 instances out of the 48 valid visualizations
    incurring erroneous generation. However, nuanced scrutiny of the results uncovered
    a relative weakness in the model’s capability to discern the appropriate columns
    from the dataset when populating the x-axis and y-axis fields. Notably, the model’s
    proficiency waned, especially concerning the accurate selection of the y-axis
    field, where the model correctly selected 25 out of 48 instances, compared to
    its performance with the x-axis where the model improved the performance by selecting
    33 out of 48 instances, exhibiting a lower accuracy for the former.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的调查中，我们最初深入研究了 nvBench 数据集，重点评估了从完整数据集中随机抽样的 50 个代表性实例。专注于代码和表示层，结果分析表明，该模型成功生成了
    50 个样本中 48 个有效的可视化。这些可视化被认为是有效的，因为它们与 VegaLite 渲染兼容。图 [4](#S7.F4 "图 4 ‣ 7.3 用例
    1：评估 Codeinterpreter ‣ 7 用例 ‣ vi(E)va LLM! 一个用于评估和解释生成性 AI 基于可视化的概念堆栈") 展示了模型在三个维度上的表现：标记类型、x
    轴字段和 y 轴字段准确性。可以观察到模型表现出适当的标记准确率，48 个有效可视化中仅有 5 个实例出现了错误生成。然而，对结果的细致审查揭示了模型在填充
    x 轴和 y 轴字段时，从数据集中识别适当列的能力相对较弱。特别是，模型在准确选择 y 轴字段方面的能力有所下降，模型在 48 个实例中正确选择了 25 个
    y 轴字段，而在 x 轴方面的表现有所提升，选择了 48 个实例中的 33 个，显示了前者的准确性较低。
- en: '![Refer to caption](img/0ef026968d8cc33185b6a3e7e3c7bcea.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0ef026968d8cc33185b6a3e7e3c7bcea.png)'
- en: 'Figure 4: GPT-3.5-Turbo performance on 50 nvBench samples along mark and axes
    fields accuracy.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：GPT-3.5-Turbo 在 50 个 nvBench 样本中的表现，涵盖标记和坐标轴字段的准确性。
- en: 'Looking now at presentation and application layers, the samples have been analyzed
    using the platform, involving a human evaluator to label errors. This analysis
    has returned the identification of four classes of error that were not detected
    by the automated approach:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在看一下展示层和应用层，样本已经通过平台进行了分析，并由人工评估者标记了错误。这项分析发现了四类自动化方法未检测出的错误：
- en: •
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Missed Ordering Error: The model misinterprets the user’s explicit ordering
    instruction in the query. For instance, as illustrated in Figure [5](#S7.F5 "Figure
    5 ‣ 7.3 Use case 1: Evaluating Codeinterpreter ‣ 7 Use cases ‣ vi(E)va LLM! A
    Conceptual Stack for Evaluating and Interpreting Generative AI-based Visualizations")-c,
    despite a clear user directive (A bar chart about the number of faults for different
    fault short names, sort from low to high by the y-axis), the model fails to adhere
    to the specified ordering. The second type is the absence of ordering specification
    in the query, which results in the model’s inability to arrange the data in accordance
    with visualization literacy when it chooses a default sorting strategy.'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '错过排序错误：模型误解了用户在查询中的明确排序指令。例如，如图[5](#S7.F5 "图 5 ‣ 7.3 用例 1: 评估代码解释器 ‣ 7 用例 ‣
    vi(E)va LLM! 评估和解释生成式 AI 视觉化的概念性堆栈")-c 所示，尽管用户明确指示（关于不同故障短名称的故障数量的条形图，按 y 轴从低到高排序），模型仍未按照指定的排序执行。第二类错误是在查询中缺少排序规范，这导致模型在选择默认排序策略时无法根据可视化素养安排数据。'
- en: •
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Wrong Stacked Bar Chart: Instances were observed where the model encountered
    challenges in accurately generating the VegaLite specification for a stacked bar
    chart, as exemplified in Figure  [5](#S7.F5 "Figure 5 ‣ 7.3 Use case 1: Evaluating
    Codeinterpreter ‣ 7 Use cases ‣ vi(E)va LLM! A Conceptual Stack for Evaluating
    and Interpreting Generative AI-based Visualizations")-h. Instead of stacking the
    data as expected in the ground truth, the model diverged and fragmented the chart
    into multiple sub-charts. Moreover, each sub-chart presents only one value, missing
    the complementary one.'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '错误的堆叠条形图：观察到模型在准确生成堆叠条形图的 VegaLite 规范时遇到了挑战，如图[5](#S7.F5 "图 5 ‣ 7.3 用例 1: 评估代码解释器
    ‣ 7 用例 ‣ vi(E)va LLM! 评估和解释生成式 AI 视觉化的概念性堆栈")-h 所示。模型没有按预期将数据堆叠到地面真实数据中，而是将图表分裂成多个子图。此外，每个子图仅展示一个值，缺少了补充值。'
- en: •
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Visualization Hallucination: This class of error manifests when the model invents
    an entirely different visual design for a well-known visualization technique requested
    in the query. Figure  [5](#S7.F5 "Figure 5 ‣ 7.3 Use case 1: Evaluating Codeinterpreter
    ‣ 7 Use cases ‣ vi(E)va LLM! A Conceptual Stack for Evaluating and Interpreting
    Generative AI-based Visualizations")-g and  [5](#S7.F5 "Figure 5 ‣ 7.3 Use case
    1: Evaluating Codeinterpreter ‣ 7 Use cases ‣ vi(E)va LLM! A Conceptual Stack
    for Evaluating and Interpreting Generative AI-based Visualizations")-h demonstrate
    a scenario where the model completely misinterprets a stacked bar chart, deviating
    from established norms, and creates new representations that do not seem to follow
    any established rationale (e.g., the two distant bars reported in  [5](#S7.F5
    "Figure 5 ‣ 7.3 Use case 1: Evaluating Codeinterpreter ‣ 7 Use cases ‣ vi(E)va
    LLM! A Conceptual Stack for Evaluating and Interpreting Generative AI-based Visualizations")-h).'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '视觉幻觉：这种错误在模型为查询中请求的已知视觉化技术发明了完全不同的视觉设计时表现出来。图[5](#S7.F5 "图 5 ‣ 7.3 用例 1: 评估代码解释器
    ‣ 7 用例 ‣ vi(E)va LLM! 评估和解释生成式 AI 视觉化的概念性堆栈")-g 和[5](#S7.F5 "图 5 ‣ 7.3 用例 1: 评估代码解释器
    ‣ 7 用例 ‣ vi(E)va LLM! 评估和解释生成式 AI 视觉化的概念性堆栈")-h 展示了模型完全误解堆叠条形图的场景，偏离了既定规范，创建了看起来似乎不遵循任何已建立的逻辑的新表示（例如，图[5](#S7.F5
    "图 5 ‣ 7.3 用例 1: 评估代码解释器 ‣ 7 用例 ‣ vi(E)va LLM! 评估和解释生成式 AI 视觉化的概念性堆栈")-h 中报告的两个遥远的条形）。'
- en: •
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Unnecessary Color coding: Errors in this category involve the addition of color
    coding, gradients, or other color properties that contravene best practices in
    visualization. Figure [5](#S7.F5 "Figure 5 ‣ 7.3 Use case 1: Evaluating Codeinterpreter
    ‣ 7 Use cases ‣ vi(E)va LLM! A Conceptual Stack for Evaluating and Interpreting
    Generative AI-based Visualizations")-d illustrates instances where the model introduces
    unnecessary colors, detracting from the visual clarity recommended by best practices.'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 不必要的颜色编码：此类别的错误涉及添加颜色编码、渐变或其他颜色属性，这些违反了可视化的最佳实践。图[5](#S7.F5 "图5 ‣ 7.3 使用案例1：评估Codeinterpreter
    ‣ 7 使用案例 ‣ vi(E)va LLM! 生成性AI可视化的概念堆栈评估与解释")-d展示了模型引入不必要颜色的实例，影响了最佳实践推荐的视觉清晰度。
- en: '![Refer to caption](img/c8541a33d7774fdcdc25b42719a99a3f.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/c8541a33d7774fdcdc25b42719a99a3f.png)'
- en: 'Figure 5: Examples of wrong generation by GPT-3.5 split by EvaLLM levels. Where
    the levels are purely numerical, the example is not reported.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：GPT-3.5按EvaLLM级别拆分的错误生成示例。当级别纯粹是数字时，该示例不会被报告。
- en: '7.4 Use case 2: Evaluating Llama-70b'
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4 使用案例2：评估Llama-70b
- en: 'This section illustrates the exploration of Meta LlaMA2-70b-chat  [[TMS^∗23](#bib.bibx61)]
    as the second use case, with a focus on comparing it to GPT-3.5 Turbo [[Ope23](#bib.bibx45)]
    using again a subset of 50 instances from the NvBench dataset [[LTL21a](#bib.bibx37)].
    It revealed interesting insights as depicted in Figure[6](#S7.F6 "Figure 6 ‣ 7.4
    Use case 2: Evaluating Llama-70b ‣ 7 Use cases ‣ vi(E)va LLM! A Conceptual Stack
    for Evaluating and Interpreting Generative AI-based Visualizations"): out of the
    50 samples, 34 visualizations were successfully generated without any errors in
    adherence to the VegaLite schema. This is a worse result than what we experienced
    with ChatGPT 3.6-turbo CodeInterpreter, showing a worse capability of a non-fine-tuned
    model to support even the base level of code generation. The performance of the
    LLM was evaluated across three dimensions for the representation layer: mark type
    accuracy, x-axis field accuracy, and y-axis field accuracy as demonstrated in
    Figure [6](#S7.F6 "Figure 6 ‣ 7.4 Use case 2: Evaluating Llama-70b ‣ 7 Use cases
    ‣ vi(E)va LLM! A Conceptual Stack for Evaluating and Interpreting Generative AI-based
    Visualizations"). Notably, there was a slight dip in mark type accuracy, with
    the LLM correctly identifying the mark type in 29 out of 34 visualizations, as
    opposed to 43 out of 48 by GPT-3.5 Turbo. This discrepancy suggests a similar
    difference in the models’ capabilities even accounting for the lower number of
    tests.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 本节展示了Meta LlaMA2-70b-chat [[TMS^∗23](#bib.bibx61)]作为第二个使用案例的探索，重点是将其与GPT-3.5
    Turbo [[Ope23](#bib.bibx45)]进行比较，再次使用NvBench数据集中的50个实例子集[[LTL21a](#bib.bibx37)]。这揭示了一些有趣的见解，如图[6](#S7.F6
    "图6 ‣ 7.4 使用案例2：评估Llama-70b ‣ 7 使用案例 ‣ vi(E)va LLM! 生成性AI可视化的概念堆栈评估与解释")所示：在50个样本中，34个可视化成功生成且符合VegaLite模式，没有任何错误。这一结果不如我们在ChatGPT
    3.6-turbo CodeInterpreter中获得的结果，显示出未经过微调的模型在支持基本代码生成方面的能力较差。LLM的性能在表示层面上通过三维进行评估：标记类型准确性、x轴字段准确性和y轴字段准确性，如图[6](#S7.F6
    "图6 ‣ 7.4 使用案例2：评估Llama-70b ‣ 7 使用案例 ‣ vi(E)va LLM! 生成性AI可视化的概念堆栈评估与解释")所示。值得注意的是，标记类型准确性略有下降，LLM在34个可视化中正确识别标记类型的数量为29个，而GPT-3.5
    Turbo为48个中的43个。这种差异表明，即使考虑到测试数量较少，模型的能力仍存在类似差异。
- en: '![Refer to caption](img/aa79af2a7a64df08b37ba83d3273178b.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/aa79af2a7a64df08b37ba83d3273178b.png)'
- en: 'Figure 6: Llama2-70b performance on 50 nvBench samples along mark and axes
    fields accuracy.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：Llama2-70b在50个nvBench样本上的性能，标记和轴字段准确性。
- en: 'Further analysis revealed a challenge for the LLM in handling largely structured
    prompts. Some visualizations generated were either blank or presented visual hallucinations,
    lacking any meaningful insight (see for reference the big blue square in Figure [7](#S7.F7
    "Figure 7 ‣ 7.4 Use case 2: Evaluating Llama-70b ‣ 7 Use cases ‣ vi(E)va LLM!
    A Conceptual Stack for Evaluating and Interpreting Generative AI-based Visualizations")
    [h]). This limitation points to the model’s struggle with certain types of input
    structures, affecting its ability to produce informative visualizations.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步分析揭示了LLM在处理高度结构化提示方面的挑战。一些生成的可视化要么为空白，要么呈现视觉幻觉，缺乏任何有意义的见解（参见图[7](#S7.F7 "图7
    ‣ 7.4 使用案例2：评估Llama-70b ‣ 7 使用案例 ‣ vi(E)va LLM! 生成性AI可视化的概念堆栈评估与解释") [h]中的大蓝色方块）。这一局限性表明模型在处理某些输入结构时存在困难，影响了其生成信息丰富的可视化的能力。
- en: '![Refer to caption](img/8e2e466a6d23fbca099b2a40b47702fc.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/8e2e466a6d23fbca099b2a40b47702fc.png)'
- en: 'Figure 7: Examples of wrong generation by LlaMA2-70b split by EvaLLM levels.
    Where the levels are purely numerical, the example is not reported.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：由 EvaLLM 等级划分的 LlaMA2-70b 错误生成示例。如果等级仅为纯数字，则该示例未报告。
- en: Moreover, it was observed that the LLM faced difficulties in correlating NL-instructions,
    data, and sorting techniques. This led to the generation of visualizations that
    were incorrectly sorted and disoriented, similar to what was observed for use
    case 1, highlighting a potential area for improvement in the model’s comprehension
    and synthesis of complex instructions.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，观察到 LLM 在关联自然语言指令、数据和排序技术方面存在困难。这导致了生成了排序错误和混乱的可视化，类似于使用案例 1 中观察到的情况，突出显示了模型在理解和综合复杂指令方面的潜在改进领域。
- en: •
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Inability of Incorporation of Data Values: While the automated performance
    evaluation revealed a major dip in the performance of the model, a following human
    evaluation uncovered a few more inabilities of the model. Such is the inability
    of the model to correctly understand and incorporate the data values in the visualization
    based on user query. In some cases, the model was observed generating no data
    values at all as can be seen in Figure [7](#S7.F7 "Figure 7 ‣ 7.4 Use case 2:
    Evaluating Llama-70b ‣ 7 Use cases ‣ vi(E)va LLM! A Conceptual Stack for Evaluating
    and Interpreting Generative AI-based Visualizations") [a,g]. A few other generated
    visualizations were found to have data values ignored but had data linked to a
    separate data file, which was quite strange behavior.'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据值整合的能力不足：虽然自动化性能评估显示模型性能有显著下降，但后续的人为评估揭示了模型的一些其他能力不足。例如，模型无法正确理解和整合基于用户查询的可视化中的数据值。在一些情况下，如图
    [7](#S7.F7 "图 7 ‣ 7.4 使用案例 2：评估 Llama-70b ‣ 7 使用案例 ‣ vi(E)va LLM! 评估和解释生成 AI 基于可视化的概念堆栈")
    [a,g] 所示，模型生成了没有数据值的结果。还有一些生成的可视化被发现忽略了数据值，但数据链接到一个单独的数据文件，这种行为相当奇怪。
- en: •
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Largely Structured Prompts Ignored: Investigating why the model was generating
    visualizations with no data values plotted at all unearthed some findings on the
    cause for the missing generation: in particular, in a few of the cases where the
    prompt structure was rather simple but with a lot of data, the model sent back
    as response the prompt and sometimes just blank strings without any text or warning
    of some kind.'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 大多数结构化提示被忽略：调查发现模型生成的可视化没有绘制数据值的原因，揭示了一些关于缺失生成的原因的发现：特别是在提示结构相对简单但数据量很大的几个案例中，模型回应了提示，有时只是空白字符串，没有任何文本或警告。
- en: •
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Low Visualization Significance: In several visualizations generated by the
    model, there was little to no significance to the visualization in terms of the
    user query and data. Such examples can be seen, to different degrees, in Figure
    [7](#S7.F7 "Figure 7 ‣ 7.4 Use case 2: Evaluating Llama-70b ‣ 7 Use cases ‣ vi(E)va
    LLM! A Conceptual Stack for Evaluating and Interpreting Generative AI-based Visualizations")
    [a,c,f,g,h]. Specifically, the visualization in Figure [7](#S7.F7 "Figure 7 ‣
    7.4 Use case 2: Evaluating Llama-70b ‣ 7 Use cases ‣ vi(E)va LLM! A Conceptual
    Stack for Evaluating and Interpreting Generative AI-based Visualizations")-h is
    the most common visualization in terms of the lack of significance the model was
    found to be generating. In this aspect, LlaMA2-70b seems to perform significantly
    worse than GPT 3.5-turbo.'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可视化意义低：在模型生成的几个可视化中，与用户查询和数据相关的意义很小或几乎没有。这些示例可以在图 [7](#S7.F7 "图 7 ‣ 7.4 使用案例
    2：评估 Llama-70b ‣ 7 使用案例 ‣ vi(E)va LLM! 评估和解释生成 AI 基于可视化的概念堆栈") [a,c,f,g,h] 中看到。具体来说，图
    [7](#S7.F7 "图 7 ‣ 7.4 使用案例 2：评估 Llama-70b ‣ 7 使用案例 ‣ vi(E)va LLM! 评估和解释生成 AI 基于可视化的概念堆栈")-h
    中的可视化在模型生成的缺乏意义方面最为常见。在这一方面，LlaMA2-70b 的表现明显低于 GPT 3.5-turbo。
- en: •
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Incorrect or missing Sorting: In cases where the user query explicitly identified
    the nature of the sorting, the model was unable to understand it, resulting in
    unordered or incorrectly ordered data values. One instance of this can be seen
    in Figure  [7](#S7.F7 "Figure 7 ‣ 7.4 Use case 2: Evaluating Llama-70b ‣ 7 Use
    cases ‣ vi(E)va LLM! A Conceptual Stack for Evaluating and Interpreting Generative
    AI-based Visualizations")-e.'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '排序错误或缺失：在用户查询明确识别排序性质的情况下，模型无法理解，导致数据值无序或排序错误。这一点可以在图 [7](#S7.F7 "Figure 7
    ‣ 7.4 Use case 2: Evaluating Llama-70b ‣ 7 Use cases ‣ vi(E)va LLM! A Conceptual
    Stack for Evaluating and Interpreting Generative AI-based Visualizations")-e中看到。'
- en: In conclusion, while the Llama2-70b demonstrated competence in generating valid
    visualizations, it exhibited challenges in code (generation), representation (mark
    type accuracy), presentation (correlation between instructions and data sorting),
    and application(significance for structured prompts) layers. These findings provide
    valuable insights for future enhancements and optimizations in the development
    of LLM for visualization generation tasks.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，虽然Llama2-70b在生成有效可视化方面表现出色，但在代码（生成）、表示（标记类型准确性）、呈现（指令与数据排序之间的关联）和应用（结构化提示的意义）层面上存在挑战。这些发现为未来在可视化生成任务中的LLM开发提供了宝贵的见解和优化方向。
- en: 'We conclude the analysis of both use cases hinting at a potential use of EvaLLM
    in the form of a benchmark for analyzing and comparing the performances of multiple
    LLMs. Figure [8](#S7.F8 "Figure 8 ‣ 7.4 Use case 2: Evaluating Llama-70b ‣ 7 Use
    cases ‣ vi(E)va LLM! A Conceptual Stack for Evaluating and Interpreting Generative
    AI-based Visualizations") shows the result for the two tested models. The evaluation
    is centered on five key dimensions: Mark Correctness, Data Mapping Correctness,
    Syntax Correctness, Grammar Similarity, and Code Similarity, covering in this
    example five levels and two layers of the stack. We choose to report just the
    automatic analyses given the explorative nature of the conducted use cases, which
    are not complete. This focused approach ensured a rigorous and measurable analysis,
    allowing for a concrete comparison of the LLMs’ performance.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '我们总结了两种使用案例的分析，暗示了EvaLLM在作为基准来分析和比较多个LLM性能方面的潜在用途。图 [8](#S7.F8 "Figure 8 ‣
    7.4 Use case 2: Evaluating Llama-70b ‣ 7 Use cases ‣ vi(E)va LLM! A Conceptual
    Stack for Evaluating and Interpreting Generative AI-based Visualizations") 显示了两个测试模型的结果。评估集中在五个关键维度上：标记正确性、数据映射正确性、语法正确性、语法相似性和代码相似性，在这个例子中覆盖了五个层次和两个层。我们选择仅报告自动分析，因为所进行的使用案例是探索性的，尚不完整。这种集中方法确保了严格和可测量的分析，使得LLM性能的比较更加具体。'
- en: '![Refer to caption](img/88716501af89e672616f83ac79a226dc.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/88716501af89e672616f83ac79a226dc.png)'
- en: (a) Llama2-70b
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: (a) Llama2-70b
- en: '![Refer to caption](img/08b7d283e8a7dacccf332b87e470e3bb.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/08b7d283e8a7dacccf332b87e470e3bb.png)'
- en: (b) GPT-3.5 Turbo
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: (b) GPT-3.5 Turbo
- en: 'Figure 8: Comparative analysis of the two tested LLM'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '图 8: 对两个测试LLM的比较分析'
- en: 8 Threats to validity and Opportunities
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 可靠性威胁与机遇
- en: The primary objective of this work was to identify a comprehensive evaluation
    stack for a standard and multi-faceted assessment of LLMs for their use in visualization
    generation tasks. This objective focused the work on the generality and applicability
    of the proposed framework, more than on the evaluation of single LLMs. The presented
    framework represents a first contribution to initiate a set of evaluation activities
    in the data visualization domain for this new technology and help researchers
    in quantitative comparisons of their proposed approaches. The paper presents altogether
    a set of threats to its validity that can ask for further investigation, and that
    we report in the following.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作的主要目标是确定一个全面的评估框架，用于对LLM在可视化生成任务中的应用进行标准化和多方面的评估。这个目标使工作更专注于所提出框架的一般性和适用性，而非单一LLM的评估。所提出的框架代表了一个初步贡献，旨在启动在数据可视化领域的一系列评估活动，以帮助研究人员对其提出的方法进行定量比较。本文总结了一系列威胁其有效性的因素，需要进一步调查，我们在下文中报告这些因素。
- en: Limited number of experiments This paper explores a limited number of samples
    from nvBench to demonstrate the EvaLLM applicability and benefits. While the chosen
    examples come from a state-of-the-art benchmarking dataset, their number is still
    on the low end. The reason behind this limitation is the low availability of free
    resources for testing many LLM models, resulting in the need for high-end computing
    machines or significant expenses even for a limited number of tests. We plan to
    integrate tests as future activity, exploiting the live nature of the contributed
    evaluation platform, and we foresee this limitation to be overcome as more open
    source models become available.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 实验数量有限 本论文探索了来自 nvBench 的有限样本，以展示 EvaLLM 的适用性和好处。尽管选择的示例来自最先进的基准数据集，但其数量仍然较少。这一限制的原因在于测试多个
    LLM 模型的免费资源稀缺，即使是有限数量的测试也需要高端计算机或巨额开支。我们计划将测试整合为未来的活动，利用所贡献的评估平台的实时性质，并预计随着更多开源模型的出现，这一限制将得到克服。
- en: Coverage of visualization techniques Among the used and existing benchmarking
    datasets, one limitation is represented by the narrow coverage of visualization
    techniques, with a high presence of simple visualizations (e.g., bar charts, pie
    charts, scatterplots) and a little to non-existant presence of more complex ones
    (e.g., RadViz, Sankey Diagrams, graphs, parallel coordinates, etc.). An essential
    enhancement would involve the creation of a more structured dataset incorporating
    complex visualizations such as geo maps or matrix-based visualizations, challenging
    LLMs to generate more sophisticated outputs. This expansion would better reflect
    the diverse landscape of visualization and foster a more comprehensive understanding
    of LLM capabilities and limitations. Expansion toward full dashboard evaluation
    could be followed too, according to what was recently proposed by Srinivasan and
    Setlur [[SS23b](#bib.bibx55)] for natural language rule-based approaches.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化技术的覆盖 在使用和现有的基准数据集中，一个限制是可视化技术的覆盖范围狭窄，简单可视化（例如，条形图、饼图、散点图）的出现频率很高，而更复杂的可视化（例如，RadViz、桑基图、图形、平行坐标等）的出现频率则几乎不存在。一个重要的改进将是创建一个更结构化的数据集，纳入复杂的可视化技术，如地理地图或基于矩阵的可视化，挑战
    LLM 生成更复杂的输出。这一扩展将更好地反映可视化的多样化格局，并促进对 LLM 能力和限制的更全面理解。还可以跟进全仪表盘评估的扩展，参考 Srinivasan
    和 Setlur 最近提出的自然语言规则基础方法[[SS23b](#bib.bibx55)]。
- en: 'On the other hand, EvaLLM can foster further research to overcome these limitations,
    and going beyond them in the following directions:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，EvaLLM 可以促进进一步研究以克服这些限制，并在以下方向上超越它们：
- en: Characterization of LLMs errors EvaLLM stack can be leveraged to develop an
    extensive taxonomy of errors during the generation, relating them to the proposed
    layers and levels, encompassing a broader description of common mistakes in tested
    LLMs. This taxonomy can be utilized to assess existing and forthcoming models,
    gauge their evolution in visualization generation tasks, and inform the creation
    of an overview at the error level useful to hypothesize potential causes and mitigations.
    Even in our little exploration, we were already able to identify common types
    of errors shared by the two tested models.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 错误的特征化 EvaLLM 堆栈可以用于开发一个广泛的错误分类体系，将错误与提出的层级相关联，涵盖对测试 LLM 中常见错误的更广泛描述。该分类体系可用于评估现有和即将出现的模型，衡量它们在可视化生成任务中的演变，并提供一个在错误层面有用的概述，用于假设潜在的原因和缓解措施。即使在我们的有限探索中，我们已经能够识别出两个测试模型共享的常见错误类型。
- en: Inform comparative benchmarking on Visualization Capabilities of LLM EvaLLM
    establishes the groundwork for a standardized evaluation methodology and benchmarking
    tailored for the visualization task across different LLMs. Currently, existing
    quantitative methods lack the ability to effectively compare the performance of
    diverse models in generating visualizations. EvaLLM seeks to address this shortage
    by introducing an approach that can be seamlessly incorporated into quantitative
    comparative analyses, mirroring methodologies successfully employed for other
    generic tasks like math proficiency or conversational capabilities.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLM EvaLLM的可视化能力的比较基准测试中，提供了一个标准化的评估方法和基准测试的基础，专门针对不同LLMs中的可视化任务。目前，现有的定量方法缺乏有效比较不同模型生成可视化效果的能力。EvaLLM旨在通过引入一种可以无缝融入定量比较分析的方法来解决这一不足，这种方法与用于其他通用任务（如数学能力或对话能力）的成功方法类似。
- en: 9 Conlusion
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9 结论
- en: This paper investigated the elements to consider for evaluating in a comprehensive
    and fine-grained way an LLM-based generated visualization. Those elements were
    condensed and structured formally into the proposed EvaLLM stack, the first proposal
    targeted at LLMs. To make the stack applicable and useful for instructing benchmarking
    activities, we contributed a web-based platform that can support implementing,
    testing and reviewing the results of the evaluation using EvaLLM. Additionally,
    it also supports the implementation of manual labelling from multiple assessors.
    Two use cases, based on ChatGPT 3.5-turbo CodeInterpreter and Llama2-70b show
    the benefits and results obtainable by using the proposed evaluation stack and
    platform.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 本文研究了对LLM生成的可视化进行全面和细致评估时需要考虑的要素。这些要素被浓缩并正式结构化为提出的EvaLLM堆栈，这是第一个针对LLMs的提案。为了使堆栈适用于指导基准测试活动，我们贡献了一个基于网络的平台，该平台可以支持使用EvaLLM进行评估的实施、测试和结果审查。此外，它还支持多评估者的手动标记。基于ChatGPT
    3.5-turbo CodeInterpreter和Llama2-70b的两个用例展示了使用提出的评估堆栈和平台所获得的好处和结果。
- en: In future works, we plan to extend the experimental setup to more samples from
    the used dataset and consider additional datasets and models. We also foresee
    providing a survey on existing techniques that in visualization and visual analytics
    literature can support the implementation of the evaluation at the different levels
    of EvaLLM.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在未来的工作中，我们计划将实验设置扩展到更多的样本，并考虑额外的数据集和模型。我们还预见将提供关于现有技术的调查，这些技术可以支持在EvaLLM的不同层级上实施评估。
- en: References
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[AC17] Appalaraju S., Chaoji V.: Image similarity using deep cnn and curriculum
    learning. *arXiv preprint arXiv:1709.08761* (2017).'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AC17] Appalaraju S., Chaoji V.：使用深度CNN和课程学习的图像相似度。*arXiv预印本arXiv:1709.08761*（2017年）。'
- en: '[alt] Altair | Discover Continuously. Advance Infinitely - Only Forward. —
    altair.com. [https://altair.com/](https://altair.com/). [Accessed 18-12-2023].'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[alt] Altair | 不断探索。无限进步 - 只向前进。 — altair.com。 [https://altair.com/](https://altair.com/)。
    [访问日期：2023年12月18日]。'
- en: '[Bcnt] Bostock M., contributors: D3.js - data-driven documents, 2009–present.
    Accessed: . URL: [https://d3js.org/](https://d3js.org/).'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Bcnt] Bostock M., 贡献者：D3.js - 数据驱动文档，2009年至今。访问：。网址：[https://d3js.org/](https://d3js.org/)。'
- en: '[BO23] Battle L., Ottley A.: What do we mean when we say “insight”? a formal
    synthesis of existing theory. *IEEE Transactions on Visualization and Computer
    Graphics* (2023), 1–14. [doi:10.1109/TVCG.2023.3326698](https://doi.org/10.1109/TVCG.2023.3326698).'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BO23] Battle L., Ottley A.：我们说“洞察力”时是什么意思？对现有理论的正式综合。*IEEE视觉化与计算机图形学汇刊*（2023年），1–14。
    [doi:10.1109/TVCG.2023.3326698](https://doi.org/10.1109/TVCG.2023.3326698)。'
- en: '[BRBF14] Boy J., Rensink R. A., Bertini E., Fekete J.-D.: A principled way
    of assessing visualization literacy. *IEEE transactions on visualization and computer
    graphics 20*, 12 (2014), 1963–1972.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BRBF14] Boy J., Rensink R. A., Bertini E., Fekete J.-D.：一种评估可视化素养的原则性方法。*IEEE视觉化与计算机图形学汇刊
    20*，12（2014年），1963–1972。'
- en: '[CCE^∗18] Clark P., Cowhey I., Etzioni O., Khot T., Sabharwal A., Schoenick
    C., Tafjord O.: Think you have solved question answering? try arc, the ai2 reasoning
    challenge. *arXiv preprint arXiv:1803.05457* (2018).'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CCE^∗18] Clark P., Cowhey I., Etzioni O., Khot T., Sabharwal A., Schoenick
    C., Tafjord O.：你认为你已经解决了问答问题？试试arc，AI2推理挑战。*arXiv预印本arXiv:1803.05457*（2018年）。'
- en: '[CHL^∗22] Chung H. W., Hou L., Longpre S., Zoph B., Tay Y., Fedus W., Li Y.,
    Wang X., Dehghani M., Brahma S., et al.: Scaling instruction-finetuned language
    models. *arXiv preprint arXiv:2210.11416* (2022).'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CHL^∗22] Chung H. W., Hou L., Longpre S., Zoph B., Tay Y., Fedus W., Li Y.,
    Wang X., Dehghani M., Brahma S., 等: 扩展指令微调语言模型。*arXiv预印本 arXiv:2210.11416* (2022).'
- en: '[CL23] Chiang C.-H., Lee H.-y.: Can large language models be an alternative
    to human evaluations? *arXiv preprint arXiv:2305.01937* (2023).'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CL23] Chiang C.-H., Lee H.-y.: 大型语言模型能否替代人工评估？*arXiv预印本 arXiv:2305.01937*
    (2023).'
- en: '[CLM^∗22] Chen Y., Li R., Mac A., Xie T., Yu T., Wu E.: Nl2interface: Interactive
    visualization interface generation from natural language queries. *arXiv preprint
    arXiv:2209.08834* (2022).'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CLM^∗22] Chen Y., Li R., Mac A., Xie T., Yu T., Wu E.: Nl2interface：从自然语言查询生成互动可视化界面。*arXiv预印本
    arXiv:2209.08834* (2022).'
- en: '[CTJ^∗21] Chen M., Tworek J., Jun H., Yuan Q., Pinto H. P. d. O., Kaplan J.,
    Edwards H., Burda Y., Joseph N., Brockman G., et al.: Evaluating large language
    models trained on code. *arXiv preprint arXiv:2107.03374* (2021).'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CTJ^∗21] Chen M., Tworek J., Jun H., Yuan Q., Pinto H. P. d. O., Kaplan J.,
    Edwards H., Burda Y., Joseph N., Brockman G., 等: 评估基于代码训练的大型语言模型。*arXiv预印本 arXiv:2107.03374*
    (2021).'
- en: '[CW22] Chen Y., Wu E.: Pi2: End-to-end interactive visualization interface
    generation from queries. In *Proceedings of the 2022 International Conference
    on Management of Data* (2022), pp. 1711–1725.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CW22] Chen Y., Wu E.: Pi2：从查询生成端到端互动可视化界面。在*2022年国际数据管理会议论文集* (2022), 页1711–1725.'
- en: '[CZW^∗23] Chen Z., Zhang C., Wang Q., Troidl J., Warchol S., Beyer J., Gehlenborg
    N., Pfister H.: Beyond generating code: Evaluating gpt on a data visualization
    course. *arXiv preprint arXiv:2306.02914* (2023).'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CZW^∗23] Chen Z., Zhang C., Wang Q., Troidl J., Warchol S., Beyer J., Gehlenborg
    N., Pfister H.: 超越代码生成：评估GPT在数据可视化课程中的表现。*arXiv预印本 arXiv:2306.02914* (2023).'
- en: '[Dod02] Doddington G.: Automatic evaluation of machine translation quality
    using n-gram co-occurrence statistics. In *Proceedings of the second international
    conference on Human Language Technology Research* (2002), pp. 138–145.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Dod02] Doddington G.: 使用n-gram共现统计进行机器翻译质量的自动评估。在*第二届国际人类语言技术研究会议论文集* (2002),
    页138–145.'
- en: '[DZ83] Day J. D., Zimmermann H.: The osi reference model. *Proceedings of the
    IEEE 71*, 12 (1983), 1334–1340.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DZ83] Day J. D., Zimmermann H.: OSI参考模型。*IEEE学报 71*, 12 (1983), 1334–1340.'
- en: '[FADB^∗22] Finnie-Ansley J., Denny P., Becker B. A., Luxton-Reilly A., Prather
    J.: The robots are coming: Exploring the implications of openai codex on introductory
    programming. In *Proceedings of the 24th Australasian Computing Education Conference*
    (2022), pp. 10–19.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FADB^∗22] Finnie-Ansley J., Denny P., Becker B. A., Luxton-Reilly A., Prather
    J.: 机器人来了：探索OpenAI Codex对入门编程的影响。在*第24届澳大利亚计算教育会议论文集* (2022), 页10–19.'
- en: '[FBRK23] Firdous F., Bashir S., Rufai S. Z., Kumar S.: Openai chatgpt as a
    logical interpreter of code. In *2023 2nd International Conference on Edge Computing
    and Applications (ICECAA)* (2023), IEEE, pp. 1192–1197.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FBRK23] Firdous F., Bashir S., Rufai S. Z., Kumar S.: OpenAI ChatGPT作为代码的逻辑解释器。在*2023年第二届边缘计算与应用国际会议（ICECAA）*
    (2023), IEEE, 页1192–1197.'
- en: '[FNJL23] Fu J., Ng S.-K., Jiang Z., Liu P.: Gptscore: Evaluate as you desire.
    *arXiv preprint arXiv:2302.04166* (2023).'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FNJL23] Fu J., Ng S.-K., Jiang Z., Liu P.: Gptscore：按需评估。*arXiv预印本 arXiv:2302.04166*
    (2023).'
- en: '[FXG^∗20] Fu S., Xiong K., Ge X., Tang S., Chen W., Wu Y.: Quda: Natural language
    queries for visual data analytics. *arXiv preprint arXiv:2005.03257* (2020).'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FXG^∗20] Fu S., Xiong K., Ge X., Tang S., Chen W., Wu Y.: Quda：用于视觉数据分析的自然语言查询。*arXiv预印本
    arXiv:2005.03257* (2020).'
- en: '[Fyr20] Fyrestone: Pycode similar, 2020. URL: [https://pypi.org/project/pycode-similar/](https://pypi.org/project/pycode-similar/).'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Fyr20] Fyrestone: Pycode similar, 2020. URL: [https://pypi.org/project/pycode-similar/](https://pypi.org/project/pycode-similar/).'
- en: '[GDA^∗15] Gao T., Dontcheva M., Adar E., Liu Z., Karahalios K. G.: Datatone:
    Managing ambiguity in natural language interfaces for data visualization. In *Proceedings
    of the 28th annual acm symposium on user interface software & technology* (2015),
    pp. 489–500.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GDA^∗15] Gao T., Dontcheva M., Adar E., Liu Z., Karahalios K. G.: Datatone：在数据可视化的自然语言界面中管理模糊性。在*第28届ACM用户界面软件与技术年会论文集*
    (2015), 页489–500.'
- en: '[Gitnt] GitHub: Github copilot, 2021–present. Accessed: . URL: [https://github.com/features/copilot](https://github.com/features/copilot).'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Gitnt] GitHub: Github copilot, 2021–至今. 访问时间: . URL: [https://github.com/features/copilot](https://github.com/features/copilot).'
- en: '[HC21] Haq I. U., Caballero J.: A survey of binary code similarity. *ACM Computing
    Surveys (CSUR) 54*, 3 (2021), 1–38.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[HC21] Haq I. U., Caballero J.: 二进制代码相似性调查。*ACM计算机调查（CSUR）54*, 3 (2021), 1–38.'
- en: '[HC23] Hong M.-H., Crisan A.: Conversational ai threads for visualizing multidimensional
    datasets. *arXiv preprint arXiv:2311.05590* (2023).'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[HC23] 洪敏浩，克里桑 A.: 用于可视化多维数据集的对话 AI 线程。*arXiv 预印本 arXiv:2311.05590*（2023年）。'
- en: '[HMB21] Hazoom M., Malik V., Bogin B.: Text-to-sql in the wild: a naturally-occurring
    dataset based on stack exchange data. *arXiv preprint arXiv:2106.05006* (2021).'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[HMB21] 哈祖姆 M., 马利克 V., 博金 B.: 现实中的文本到 SQL: 基于 Stack Exchange 数据的自然发生数据集。*arXiv
    预印本 arXiv:2106.05006*（2021年）。'
- en: '[HPM^∗23] Hull M., Pednekar V., Murray H., Roy N., Tung E., Routray S., Guerin
    C., Chen J., Wang Z. J., Lee S., et al.: Visgrader: Automatic grading of d3 visualizations.
    *IEEE Transactions on Visualization and Computer Graphics* (2023).'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[HPM^∗23] 赫尔 M., 佩德尼卡尔 V., 莫雷 H., 罗伊 N., 汤恩 E., 鲁特雷 S., 格雷恩 C., 陈杰, 王志杰, 李松，等.:
    Visgrader: 自动评分 D3 可视化。*IEEE 视觉化与计算机图形学学报*（2023年）。'
- en: '[HQS^∗23] Hadi M. U., Qureshi R., Shah A., Irfan M., Zafar A., Shaikh M. B.,
    Akhtar N., Wu J., Mirjalili S., et al.: Large language models: a comprehensive
    survey of its applications, challenges, limitations, and future prospects.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[HQS^∗23] 哈迪 M. U., 卡雷希 R., 沙赫 A., 伊尔凡 M., 扎法尔 A., 沙伊赫 M. B., 阿赫塔尔 N., 吴 J.,
    米尔贾利利 S., 等.: 大型语言模型：其应用、挑战、限制和未来前景的综合调查。'
- en: '[Hun07] Hunter J. D.: Matplotlib: A 2d graphics environment. *Computing in
    Science & Engineering 9*, 3 (2007), 90–95. [doi:10.1109/MCSE.2007.55](https://doi.org/10.1109/MCSE.2007.55).'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Hun07] 亨特 J. D.: Matplotlib: 一个二维图形环境。*计算科学与工程 9*，3（2007年），第90–95页。[doi:10.1109/MCSE.2007.55](https://doi.org/10.1109/MCSE.2007.55)。'
- en: '[JSFL] Joshi A., Srinivas C., Firat E. E., Laramee R. S.: Evaluating the recommendations
    of llms to teach a visualiza-tion technique using bloom’s taxonomy.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[JSFL] 乔希 A., 斯里尼瓦斯 C., 菲拉特 E. E., 拉拉梅 R. S.: 评估 LLMs 对教授可视化技术的建议，使用布鲁姆分类法。'
- en: '[KHL19] Kettunen M., Härkönen E., Lehtinen J.: E-lpips: robust perceptual image
    similarity via random transformation ensembles. *arXiv preprint arXiv:1906.03973*
    (2019).'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KHL19] 凯图嫩 M., 哈尔科宁 E., 莱赫蒂宁 J.: E-lpips: 通过随机变换集实现稳健的感知图像相似性。*arXiv 预印本 arXiv:1906.03973*（2019年）。'
- en: '[KLSC21] Kim Y.-H., Lee B., Srinivasan A., Choe E. K.: Data@ hand: Fostering
    visual exploration of personal data on smartphones leveraging speech and touch
    interaction. In *Proceedings of the 2021 CHI Conference on Human Factors in Computing
    Systems* (2021), pp. 1–17.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KLSC21] 金英浩，李炳，斯里尼瓦森 A., 崔恩·凯.: Data@ hand: 利用语音和触摸交互促进智能手机个人数据的可视化探索。见于*2021年计算系统人因会议论文集*（2021年），第1–17页。'
- en: '[KMB23] Kim N. W., Myers G., Bach B.: How good is chatgpt in giving advice
    on your visualization design? *arXiv preprint arXiv:2310.09617* (2023).'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KMB23] 金南文，迈耶斯 G., 巴赫 B.: ChatGPT 在提供可视化设计建议方面的表现如何？*arXiv 预印本 arXiv:2310.09617*（2023年）。'
- en: '[KMK23] Katsogiannis-Meimarakis G., Koutrika G.: A survey on deep learning
    approaches for text-to-sql. *The VLDB Journal* (2023), 1–32.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KMK23] 卡索基安尼斯-梅马拉基斯 G., 库特里卡 G.: 文本到 SQL 的深度学习方法调查。*VLDB 学报*（2023年），第1–32页。'
- en: '[LH18] Liu Y., Heer J.: Somewhere over the rainbow: An empirical assessment
    of quantitative colormaps. In *Proceedings of the 2018 CHI conference on human
    factors in computing systems* (2018), pp. 1–12.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LH18] 刘勇，赫尔 J.: 彩虹之上：定量色彩图的实证评估。见于*2018年计算系统人因会议论文集*（2018年），第1–12页。'
- en: '[LKK16] Lee S., Kim S.-H., Kwon B. C.: Vlat: Development of a visualization
    literacy assessment test. *IEEE transactions on visualization and computer graphics
    23*, 1 (2016), 551–560.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LKK16] 李晟，金世浩，权炳炫.: Vlat: 可视化素养评估测试的开发。*IEEE 视觉化与计算机图形学学报 23*，1（2016年），第551–560页。'
- en: '[LPX^∗18] Liu W., Peng X., Xing Z., Li J., Xie B., Zhao W.: Supporting exploratory
    code search with differencing and visualization. In *2018 IEEE 25th International
    Conference on Software Analysis, Evolution and Reengineering (SANER)* (2018),
    IEEE, pp. 300–310.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LPX^∗18] 刘威，彭旭，邢志，李佳，谢斌，赵伟.: 通过差异化和可视化支持探索性代码搜索。见于*2018年IEEE第25届软件分析、演化与重构国际会议（SANER）*（2018年），IEEE，第300–310页。'
- en: '[Ltd23] Ltd D. P.: Deepinfra, 2023. URL: [https://deepinfra.com/](https://deepinfra.com/).'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Ltd23] Ltd D. P.: Deepinfra, 2023年。网址：[https://deepinfra.com/](https://deepinfra.com/)。'
- en: '[LTL21a] Luo Y., Tang J., Li G.: nvbench: A large-scale synthesized dataset
    for cross-domain natural language to visualization task. *arXiv preprint arXiv:2112.12926*
    (2021).'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LTL21a] 罗耀，唐俊，李刚.: nvbench: 一个大规模合成数据集，用于跨域自然语言到可视化任务。*arXiv 预印本 arXiv:2112.12926*（2021年）。'
- en: '[LTL^∗21b] Luo Y., Tang N., Li G., Tang J., Chai C., Qin X.: Natural language
    to visualization by neural machine translation. *IEEE Transactions on Visualization
    and Computer Graphics 28*, 1 (2021), 217–226.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LTL^∗21b] 罗耀，唐宁，李刚，唐俊，柴晨，秦晓.: 通过神经机器翻译实现自然语言到可视化。*IEEE 视觉化与计算机图形学学报 28*，1（2021年），第217–226页。'
- en: '[Mic20] Microsoft: Playwright, 2020. URL: [https://playwright.dev/](https://playwright.dev/).'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Mic20] 微软: Playwright, 2020. URL: [https://playwright.dev/](https://playwright.dev/)。'
- en: '[MS23] Maddigan P., Susnjak T.: Chat2vis: Generating data visualisations via
    natural language using chatgpt, codex and gpt-3 large language models. *IEEE Access*
    (2023).'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MS23] Maddigan P., Susnjak T.: Chat2vis: 通过自然语言使用 ChatGPT、Codex 和 GPT-3 大型语言模型生成数据可视化。*IEEE
    Access* (2023)。'
- en: '[Mun09] Munzner T.: A nested model for visualization design and validation.
    *IEEE transactions on visualization and computer graphics 15*, 6 (2009), 921–928.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Mun09] Munzner T.: 用于可视化设计和验证的嵌套模型。*IEEE Transactions on Visualization and
    Computer Graphics 15*, 6 (2009), 921–928。'
- en: '[Nor06] North C.: Toward measuring visualization insight. *IEEE Computer Graphics
    and Applications 26*, 3 (2006), 6–9. [doi:10.1109/MCG.2006.70](https://doi.org/10.1109/MCG.2006.70).'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Nor06] North C.: 朝着测量可视化洞察的方向前进。*IEEE Computer Graphics and Applications 26*,
    3 (2006), 6–9. [doi:10.1109/MCG.2006.70](https://doi.org/10.1109/MCG.2006.70)。'
- en: '[NSD11] North C., Saraiya P., Duca K.: A comparison of benchmark task and insight
    evaluation methods for information visualization. *Information Visualization 10*,
    3 (2011), 162–181. URL: [https://doi.org/10.1177/1473871611415989](https://doi.org/10.1177/1473871611415989),
    [arXiv:https://doi.org/10.1177/1473871611415989](http://arxiv.org/abs/https://doi.org/10.1177/1473871611415989),
    [doi:10.1177/1473871611415989](https://doi.org/10.1177/1473871611415989).'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NSD11] North C., Saraiya P., Duca K.: 基准任务与信息可视化洞察评估方法的比较。*Information Visualization
    10*, 3 (2011), 162–181. URL: [https://doi.org/10.1177/1473871611415989](https://doi.org/10.1177/1473871611415989),
    [arXiv:https://doi.org/10.1177/1473871611415989](http://arxiv.org/abs/https://doi.org/10.1177/1473871611415989),
    [doi:10.1177/1473871611415989](https://doi.org/10.1177/1473871611415989)。'
- en: '[NSS20] Narechania A., Srinivasan A., Stasko J.: Nl4dv: A toolkit for generating
    analytic specifications for data visualization from natural language queries.
    *IEEE Transactions on Visualization and Computer Graphics 27*, 2 (2020), 369–379.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NSS20] Narechania A., Srinivasan A., Stasko J.: Nl4dv: 一个用于从自然语言查询生成数据可视化分析规范的工具包。*IEEE
    Transactions on Visualization and Computer Graphics 27*, 2 (2020), 369–379。'
- en: '[Ope23] OpenAI R.: Gpt-4 technical report. *arXiv* (2023), 2303–08774.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Ope23] OpenAI R.: GPT-4技术报告。*arXiv* (2023), 2303–08774。'
- en: '[PPV23] Podo L., Prenkaj B., Velardi P.: Machine learning for visualization
    recommendation systems: Open challenges and future directions. *arXiv preprint
    arXiv:2302.00569* (2023).'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PPV23] Podo L., Prenkaj B., Velardi P.: 用于可视化推荐系统的机器学习：开放挑战与未来方向。*arXiv 预印本
    arXiv:2302.00569* (2023)。'
- en: '[RH08] Rouse D. M., Hemami S. S.: Understanding and simplifying the structural
    similarity metric. In *2008 15th IEEE international conference on image processing*
    (2008), IEEE, pp. 1188–1191.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RH08] Rouse D. M., Hemami S. S.: 理解和简化结构相似性度量。在 *2008年第15届IEEE国际图像处理会议* (2008),
    IEEE, pp. 1188–1191。'
- en: '[SBT^∗16] Setlur V., Battersby S. E., Tory M., Gossweiler R., Chang A. X.:
    Eviza: A natural language interface for visual analysis. In *Proceedings of the
    29th annual symposium on user interface software and technology* (2016), pp. 365–377.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SBT^∗16] Setlur V., Battersby S. E., Tory M., Gossweiler R., Chang A. X.:
    Eviza: 一个用于视觉分析的自然语言接口。在 *第29届用户界面软件与技术年会论文集* (2016), pp. 365–377。'
- en: '[Scnt] Shroominic, contributors: Codeinterpreter api. GitHub Repository, 2023–present.
    Accessed: . URL: [https://github.com/shroominic/codeinterpreter-api](https://github.com/shroominic/codeinterpreter-api).'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Scnt] Shroominic, 贡献者: Codeinterpreter api. GitHub Repository, 2023–至今。访问时间：URL:
    [https://github.com/shroominic/codeinterpreter-api](https://github.com/shroominic/codeinterpreter-api)。'
- en: '[SG16] Szafir D. A., Gleicher M.: Visualization-aware color design. In *EuroVis
    (Posters)* (2016), pp. 97–99.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SG16] Szafir D. A., Gleicher M.: 关注可视化的颜色设计。在 *EuroVis (Posters)* (2016),
    pp. 97–99。'
- en: '[SMWC23] Suh A., Mosca A., Wu E., Chang R.: A grammar of hypotheses for visualization,
    data, and analysis, 2023. [arXiv:2204.14267](http://arxiv.org/abs/2204.14267).'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SMWC23] Suh A., Mosca A., Wu E., Chang R.: 2023年用于可视化、数据和分析的假设语法。[arXiv:2204.14267](http://arxiv.org/abs/2204.14267)。'
- en: '[SNL^∗21] Srinivasan A., Nyapathy N., Lee B., Drucker S. M., Stasko J.: Collecting
    and characterizing natural language utterances for specifying data visualizations.
    In *Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems*
    (2021), pp. 1–10.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SNL^∗21] Srinivasan A., Nyapathy N., Lee B., Drucker S. M., Stasko J.: 收集和表征自然语言表述以指定数据可视化。在
    *2021年CHI人机交互系统会议论文集* (2021), pp. 1–10。'
- en: '[Spe01] Spence R.: *Information visualization*, vol. 1. Springer, 2001.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Spe01] Spence R.: *信息可视化*, 第1卷. Springer, 2001。'
- en: '[SS23a] Srinivasan A., Setlur V.: Bolt: A natural language interface for dashboard
    authoring.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SS23a] Srinivasan A., Setlur V.: Bolt: 一个用于仪表盘创建的自然语言接口。'
- en: '[SS23b] Srinivasan A., Setlur V.: BOLT: A Natural Language Interface for Dashboard
    Authoring. In *EuroVis 2023 - Short Papers* (2023), Hoellt T., Aigner W., Wang
    B., (Eds.), The Eurographics Association. [doi:10.2312/evs.20231035](https://doi.org/10.2312/evs.20231035).'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SS23b] Srinivasan A., Setlur V.: BOLT: 一个用于仪表板编写的自然语言接口。见 *EuroVis 2023 -
    短文集* (2023), Hoellt T., Aigner W., Wang B., (编), Eurographics 协会. [doi:10.2312/evs.20231035](https://doi.org/10.2312/evs.20231035)。'
- en: '[SSZ^∗23] Sun Z., Shen Y., Zhou Q., Zhang H., Chen Z., Cox D., Yang Y., Gan
    C.: Principle-driven self-alignment of language models from scratch with minimal
    human supervision. *arXiv preprint arXiv:2305.03047* (2023).'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SSZ^∗23] Sun Z., Shen Y., Zhou Q., Zhang H., Chen Z., Cox D., Yang Y., Gan
    C.: 基于原则的语言模型自对齐方法，几乎不需要人工监督。*arXiv 预印本 arXiv:2305.03047* (2023)。'
- en: '[Sza17] Szafir D. A.: Modeling color difference for visualization design. *IEEE
    transactions on visualization and computer graphics 24*, 1 (2017), 392–401.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Sza17] Szafir D. A.: 视觉设计中的颜色差异建模。*IEEE 视觉化与计算机图形学交易 24*, 1 (2017), 392–401。'
- en: '[SZWJ22] Song Y., Zhao X., Wong R. C.-W., Jiang D.: Rgvisnet: A hybrid retrieval-generation
    neural framework towards automatic data visualization generation. In *Proceedings
    of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining* (2022),
    pp. 1646–1655.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SZWJ22] Song Y., Zhao X., Wong R. C.-W., Jiang D.: Rgvisnet: 一种混合检索-生成神经框架用于自动数据可视化生成。见
    *第28届 ACM SIGKDD 知识发现与数据挖掘大会论文集* (2022), 页1646–1655。'
- en: '[TCD^∗23] Tian Y., Cui W., Deng D., Yi X., Yang Y., Zhang H., Wu Y.: Chartgpt:
    Leveraging llms to generate charts from abstract natural language. *arXiv preprint
    arXiv:2311.01920* (2023).'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TCD^∗23] Tian Y., Cui W., Deng D., Yi X., Yang Y., Zhang H., Wu Y.: ChartGPT:
    利用大型语言模型从抽象自然语言生成图表。*arXiv 预印本 arXiv:2311.01920* (2023)。'
- en: '[TGZ^∗23] Taori R., Gulrajani I., Zhang T., Dubois Y., Li X., Guestrin C.,
    Liang P., Hashimoto T. B.: Alpaca: A strong, replicable instruction-following
    model. *Stanford Center for Research on Foundation Models. https://crfm. stanford.
    edu/2023/03/13/alpaca. html 3*, 6 (2023), 7.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TGZ^∗23] Taori R., Gulrajani I., Zhang T., Dubois Y., Li X., Guestrin C.,
    Liang P., Hashimoto T. B.: Alpaca: 一个强大且可复现的指令跟随模型。*斯坦福基础模型研究中心. https://crfm.stanford.edu/2023/03/13/alpaca.html
    3*, 6 (2023), 7。'
- en: '[TMS^∗23] Touvron H., Martin L., Stone K., Albert P., Almahairi A., Babaei
    Y., Bashlykov N., Batra S., Bhargava P., Bhosale S., et al.: Llama 2: Open foundation
    and fine-tuned chat models. *arXiv preprint arXiv:2307.09288* (2023).'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TMS^∗23] Touvron H., Martin L., Stone K., Albert P., Almahairi A., Babaei
    Y., Bashlykov N., Batra S., Bhargava P., Bhosale S., 等：Llama 2: 开放的基础和微调聊天模型。*arXiv
    预印本 arXiv:2307.09288* (2023)。'
- en: '[TX23] Tao R., Xu J.: Mapping with chatgpt. *ISPRS International Journal of
    Geo-Information 12*, 7 (2023), 284.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TX23] Tao R., Xu J.: 使用 ChatGPT 进行映射。*ISPRS 国际地理信息期刊 12*, 7 (2023), 284。'
- en: '[War19] Ware C.: *Information visualization: perception for design*. Morgan
    Kaufmann, 2019.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[War19] Ware C.: *信息可视化：设计中的感知*。Morgan Kaufmann, 2019。'
- en: '[WFH^∗23] White J., Fu Q., Hays S., Sandborn M., Olea C., Gilbert H., Elnashar
    A., Spencer-Smith J., Schmidt D. C.: A prompt pattern catalog to enhance prompt
    engineering with chatgpt. *arXiv preprint arXiv:2302.11382* (2023).'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[WFH^∗23] White J., Fu Q., Hays S., Sandborn M., Olea C., Gilbert H., Elnashar
    A., Spencer-Smith J., Schmidt D. C.: 一个提示模式目录以增强与 ChatGPT 的提示工程。*arXiv 预印本 arXiv:2302.11382*
    (2023)。'
- en: '[WIL^∗23] Wu S., Irsoy O., Lu S., Dabravolski V., Dredze M., Gehrmann S., Kambadur
    P., Rosenberg D., Mann G.: Bloomberggpt: A large language model for finance. *arXiv
    preprint arXiv:2303.17564* (2023).'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[WIL^∗23] Wu S., Irsoy O., Lu S., Dabravolski V., Dredze M., Gehrmann S., Kambadur
    P., Rosenberg D., Mann G.: BloombergGPT: 一个用于金融的大型语言模型。*arXiv 预印本 arXiv:2303.17564*
    (2023)。'
- en: '[WSM^∗18] Wang A., Singh A., Michael J., Hill F., Levy O., Bowman S. R.: Glue:
    A multi-task benchmark and analysis platform for natural language understanding.
    *arXiv preprint arXiv:1804.07461* (2018).'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[WSM^∗18] Wang A., Singh A., Michael J., Hill F., Levy O., Bowman S. R.: Glue:
    一个用于自然语言理解的多任务基准和分析平台。*arXiv 预印本 arXiv:1804.07461* (2018)。'
- en: '[WWS^∗22] Wei J., Wang X., Schuurmans D., Bosma M., Xia F., Chi E., Le Q. V.,
    Zhou D., et al.: Chain-of-thought prompting elicits reasoning in large language
    models. *Advances in Neural Information Processing Systems 35* (2022), 24824–24837.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[WWS^∗22] Wei J., Wang X., Schuurmans D., Bosma M., Xia F., Chi E., Le Q. V.,
    Zhou D., 等：链式思维提示引发大型语言模型中的推理。*神经信息处理系统进展 35* (2022), 24824–24837。'
- en: '[WYKN20] Wang Y., Yao Q., Kwok J. T., Ni L. M.: Generalizing from a few examples:
    A survey on few-shot learning. *ACM computing surveys (csur) 53*, 3 (2020), 1–34.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[WYKN20] Wang Y., Yao Q., Kwok J. T., Ni L. M.: 从少量示例中推广：关于少样本学习的调查。*ACM 计算调查
    (csur) 53*, 3 (2020), 1–34。'
- en: '[XLS17] Xu X., Liu C., Song D.: Sqlnet: Generating structured queries from
    natural language without reinforcement learning. *arXiv preprint arXiv:1711.04436*
    (2017).'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLS17] 许轩、刘聪、宋达：Sqlnet：从自然语言生成结构化查询而无需强化学习。*arXiv预印本 arXiv:1711.04436*（2017）。'
- en: '[XLSA18] Xian Y., Lampert C. H., Schiele B., Akata Z.: Zero-shot learning—a
    comprehensive evaluation of the good, the bad and the ugly. *IEEE transactions
    on pattern analysis and machine intelligence 41*, 9 (2018), 2251–2265.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLSA18] 现勇、兰帕特 C. H.、施列 B.、阿卡塔 Z.：零样本学习——对优缺点的全面评估。*IEEE模式分析与机器智能交易 41*，9（2018），2251–2265。'
- en: '[ZCG^∗23] Zhong W., Cui R., Guo Y., Liang Y., Lu S., Wang Y., Saied A., Chen
    W., Duan N.: Agieval: A human-centric benchmark for evaluating foundation models.
    *arXiv preprint arXiv:2304.06364* (2023).'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ZCG^∗23] 钟伟、崔然、郭颖、梁洋、陆书、王勇、赛义德 A.、陈伟、段宁：Agieval：一个以人为本的基准，用于评估基础模型。*arXiv预印本
    arXiv:2304.06364*（2023）。'
- en: '[ZHB^∗19] Zellers R., Holtzman A., Bisk Y., Farhadi A., Choi Y.: Hellaswag:
    Can a machine really finish your sentence? *arXiv preprint arXiv:1905.07830* (2019).'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ZHB^∗19] 泽勒斯 R.、霍尔茨曼 A.、比斯克 Y.、法赫迪 A.、蔡 Y.：Hellaswag：机器真的能完成你的句子吗？ *arXiv预印本
    arXiv:1905.07830*（2019）。'
