- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 17:34:52'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 17:34:52
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Improving Cross-Domain Low-Resource Text Generation through LLM Post-Editing:
    A Programmer-Interpreter Approach'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过 LLM 后期编辑提高跨领域低资源文本生成：一种程序员-解释器方法
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2402.04609](https://ar5iv.labs.arxiv.org/html/2402.04609)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2402.04609](https://ar5iv.labs.arxiv.org/html/2402.04609)
- en: Zhuang Li, Levon Haroutunian,
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 庄李、列文·哈鲁图尼安、
- en: Raj Tumuluri, Philip Cohen, Gholamreza Haffari
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 拉杰·图穆鲁里、菲利普·科恩、戈拉姆雷扎·哈法里
- en: Openstream.ai
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Openstream.ai
- en: '{zhuang.li, levon, raj, phil.cohen, reza.haffari}@openstream.com'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '{zhuang.li, levon, raj, phil.cohen, reza.haffari}@openstream.com'
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Post-editing has proven effective in improving the quality of text generated
    by large language models (LLMs) such as GPT-3.5 or GPT-4, particularly when direct
    updating of their parameters to enhance text quality is infeasible or expensive.
    However, relying solely on smaller language models for post-editing can limit
    the LLMs’ ability to generalize across domains. Moreover, the editing strategies
    in these methods are not optimally designed for text-generation tasks. To address
    these limitations, we propose a neural programmer-interpreter approach that preserves
    the domain generalization ability of LLMs when editing their output. The editing
    actions in this framework are specifically devised for text generation. Extensive
    experiments demonstrate that the programmer-interpreter significantly enhances
    GPT-3.5’s performance in logical form-to-text conversion and low-resource machine
    translation, surpassing other state-of-the-art (SOTA) LLM post-editing methods
    in cross-domain settings.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 后期编辑在提高大语言模型（LLMs）如 GPT-3.5 或 GPT-4 生成文本的质量方面已被证明是有效的，特别是当直接更新其参数以提升文本质量不可行或成本昂贵时。然而，单独依赖较小的语言模型进行后期编辑可能会限制
    LLM 的领域泛化能力。此外，这些方法中的编辑策略并非针对文本生成任务进行最佳设计。为了解决这些限制，我们提出了一种神经程序员-解释器方法，该方法在编辑 LLM
    输出时保持了 LLM 的领域泛化能力。该框架中的编辑动作专门为文本生成设计。大量实验表明，程序员-解释器显著提升了 GPT-3.5 在逻辑形式到文本转换和低资源机器翻译中的表现，超过了其他最先进（SOTA）的
    LLM 后期编辑方法在跨领域设置中的表现。
- en: 'Improving Cross-Domain Low-Resource Text Generation through LLM Post-Editing:
    A Programmer-Interpreter Approach'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 LLM 后期编辑提高跨领域低资源文本生成：一种程序员-解释器方法
- en: Zhuang Li, Levon Haroutunian, Raj Tumuluri, Philip Cohen, Gholamreza Haffari
    Openstream.ai {zhuang.li, levon, raj, phil.cohen, reza.haffari}@openstream.com
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 庄李、列文·哈鲁图尼安、拉杰·图穆鲁里、菲利普·科恩、戈拉姆雷扎·哈法里 Openstream.ai {zhuang.li, levon, raj, phil.cohen,
    reza.haffari}@openstream.com
- en: 1 Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: '![Refer to caption](img/c816e18cb92b9d894f04f8214909b45d.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c816e18cb92b9d894f04f8214909b45d.png)'
- en: 'Figure 1: The diagram of our post-editing architecture.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：我们的后期编辑架构图。
- en: Large pre-trained language models like GPT-3.5¹¹1https://platform.openai.com/docs/models/gpt-3-5-turbo
    or GPT-4²²2https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo have
    gained significant attention in natural language research. However, fine-tuning
    these models for specific tasks is challenging due to limited computational resources
    or inaccessible parameters. Consequently, many researchers resort to using web
    APIs for instructing LLMs, leveraging zero-shot or few-shot in-context learning,
    enabling the LLMs to tackle tasks they weren’t explicitly trained for. Unfortunately,
    this approach falls short when tackling some low-resource sequence generation
    tasks in machine translation (MT), and logical form (LF)-to-text translation,
    as shown in Lai et al. ([2023](#bib.bib5)); Haroutunian et al. ([2023](#bib.bib4)).
    In such cases, minimal task-specific data was available during the LLMs’ pre-training
    phase. The output quality of LLMs for such tasks is compromised due to the absence
    of task-specific knowledge.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 像 GPT-3.5¹¹1https://platform.openai.com/docs/models/gpt-3-5-turbo 或 GPT-4²²2https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo
    这样的大型预训练语言模型在自然语言研究中引起了广泛关注。然而，由于计算资源有限或参数不可访问，为特定任务微调这些模型具有挑战性。因此，许多研究人员转向使用
    web API 来指导 LLM，利用零样本或少样本上下文学习，使 LLM 能够处理它们未明确训练过的任务。不幸的是，当处理一些低资源序列生成任务中的机器翻译（MT）和逻辑形式（LF）到文本翻译时，这种方法表现不佳，如
    Lai et al. ([2023](#bib.bib5))；Haroutunian et al. ([2023](#bib.bib4)) 所示。在这种情况下，LLM
    预训练阶段没有足够的任务特定数据。由于缺乏任务特定知识，LLM 在这些任务上的输出质量受到影响。
- en: To address this challenge, a promising set of solutions suggests integrating
    task-specific knowledge into language models through post-editing the generated
    text using a smaller model fine-tuned on task-specific data. Yet, these methods
    are not without their drawbacks. Our findings indicate that exclusive reliance
    on a smaller model for editing, e.g. Self-Correct Welleck et al. ([2022](#bib.bib14)),
    results in suboptimal performance in domain generalization scenarios, likely due
    to the inherently limited domain knowledge within these smaller models.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为应对这一挑战，一些有前景的解决方案建议通过使用在任务特定数据上微调的小型模型对生成的文本进行后编辑，将任务特定知识集成到语言模型中。然而，这些方法也并非没有缺陷。我们的研究表明，单独依赖于小型模型进行编辑（例如，Self-Correct
    Welleck et al. ([2022](#bib.bib14))）在领域泛化场景中的表现不尽如人意，这可能是由于这些小型模型在领域知识上的固有限制。
- en: As LLMs (i.e. GPT-3.5 or GPT-4) have shown superior domain generalization ability Wang
    et al. ([2023](#bib.bib13)); Yang et al. ([2023](#bib.bib16)) over the fine-tuned
    model, we introduce an innovative approach based on the programmer-interpreter
    framework Reed and de Freitas ([2016](#bib.bib10)), which benefits from the domain
    generalization ability from LLMs. The programmer component - a smaller language
    model fine-tuned on task-specific data - delivers precise edit instructions to
    the larger language model, thus infusing the large model with task-specific knowledge.
    The interpreter, in turn, edits the large model’s output given the provided instructions.
    Contrary to the Self-Correct Welleck et al. ([2022](#bib.bib14)) approach that
    utilizes smaller, fine-tuned models for editing, our interpreter is also an LLM.
    The editing is accomplished through the use of prompts that include editing instructions,
    eliminating the need for any additional fine-tuning. This distinct framework guarantees
    the preservation of the LLM’s domain generalization ability while simultaneously
    benefiting from the task-specific knowledge encoded by the programmer. Our method
    distinguishes itself from approaches like PiVe Han et al. ([2023](#bib.bib3)),
    which also employ an LLM as the interpreter but focus on graph generation tasks.
    In contrast, our approach specifically designs word-level editing actions in the
    instructions, tailored to enhance text generation. This targeted strategy renders
    our method more effective for text-generation tasks.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 由于LLMs（即GPT-3.5或GPT-4）在领域泛化能力上表现优于微调模型 Wang et al. ([2023](#bib.bib13))；Yang
    et al. ([2023](#bib.bib16))，我们提出了一种基于程序员-解释器框架的创新方法 Reed and de Freitas ([2016](#bib.bib10))，该方法利用LLMs的领域泛化能力。程序员组件——一个在任务特定数据上微调的小型语言模型——向较大的语言模型提供精确的编辑指令，从而将任务特定知识注入大模型中。解释器则根据提供的指令编辑大模型的输出。与利用小型微调模型进行编辑的Self-Correct
    Welleck et al. ([2022](#bib.bib14)) 方法不同，我们的解释器也是一个LLM。编辑通过包含编辑指令的提示完成，无需任何额外的微调。这一独特的框架保证了LLM领域泛化能力的保留，同时也从程序员编码的任务特定知识中获益。我们的方法不同于像PiVe
    Han et al. ([2023](#bib.bib3))等方法，后者同样使用LLM作为解释器，但重点是图生成任务。相比之下，我们的方法专门设计了针对文本生成的词级编辑操作。这一有针对性的策略使得我们的方法在文本生成任务中更为有效。
- en: 'Overall, our key contributions are as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，我们的关键贡献如下：
- en: •
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We introduce a novel programmer-interpreter method that enhances LLM in low-resource
    cross-domain text generation tasks. This approach capitalizes on the programmer’s
    ability to encode task-specific knowledge and the interpreter’s prowess in domain
    generalization.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们介绍了一种新颖的程序员-解释器方法，旨在增强在低资源跨领域文本生成任务中的LLM。这种方法利用程序员编码任务特定知识的能力以及解释器在领域泛化方面的专长。
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We design editing operations optimized for text generation tasks, leading to
    substantial text quality improvements by simply prompting the LLMs with action
    instructions.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们设计了针对文本生成任务优化的编辑操作，通过简单地给LLMs提供操作指令，显著提高了文本质量。
- en: •
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: In scenarios where training and test data span different domains, our comprehensive
    empirical studies confirm that the method outperforms all existing LLM post-editing
    baselines in low-resource MT and LF-to-Text.
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在训练和测试数据跨越不同领域的情况下，我们的全面实证研究证实，该方法在低资源机器翻译和LF-to-Text任务中优于所有现有的LLM后编辑基准。
- en: 2 Programmer-Interpreter Approach
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 程序员-解释器方法
- en: 'The objective in LF-to-text and MT tasks using LLMs is to generate a high-quality
    output text ${\bm{y}}$, denoted as ${\bm{y}}^{\prime}=\operatorname*{arg\,max}_{{\bm{y}}\in\mathcal{Y}}P({\bm{y}}|{\bm{x}},\mathcal{C})$,
    given an input ${\bm{x}}$ (e.g., LF, source-language utterance) and an exemplar
    pool $\mathcal{C}=\{({\bm{x}}_{j},{\bm{y}}_{j},{\bm{y}}^{*}_{j},{\bm{a}}^{*}_{j})\}^{|\mathcal{C}|}_{j=1}$.
    Here, ${\bm{x}}_{i}$ and ${\bm{y}}_{j}$ are the ground truth input-output pairs,
    ${\bm{y}}^{*}_{j}$ is the imperfect translation of ${\bm{x}}_{i}$, and ${\bm{a}}^{*}_{j}$
    represents the Oracle edit actions that can modify ${\bm{y}}^{*}_{j}$ into ${\bm{y}}_{j}$.
    Our approach focuses on achieving high-quality generation through iterative refinement
    of the initial output text produced by an LLM. Specifically, the iterative refinement
    framework includes three-parameterized modules: a Generator, a Programmer, and
    an Interpreter,³³3To save space, we simplify the marginalization notation.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LLMs进行LF-to-text和MT任务的目标是生成高质量的输出文本${\bm{y}}$，记作${\bm{y}}^{\prime}=\operatorname*{arg\,max}_{{\bm{y}}\in\mathcal{Y}}P({\bm{y}}|{\bm{x}},\mathcal{C})$，给定输入${\bm{x}}$（例如，LF，源语言话语）和示例池$\mathcal{C}=\{({\bm{x}}_{j},{\bm{y}}_{j},{\bm{y}}^{*}_{j},{\bm{a}}^{*}_{j})\}^{|\mathcal{C}|}_{j=1}$。这里，${\bm{x}}_{i}$和${\bm{y}}_{j}$是真实的输入-输出对，${\bm{y}}^{*}_{j}$是${\bm{x}}_{i}$的不完美翻译，而${\bm{a}}^{*}_{j}$表示可以将${\bm{y}}^{*}_{j}$修改为${\bm{y}}_{j}$的Oracle编辑操作。我们的方法专注于通过对LLM生成的初始输出文本进行迭代优化，来实现高质量生成。具体而言，迭代优化框架包括三个参数化模块：生成器、程序员和解释器³³3为节省空间，我们简化了边际化符号。
- en: '|  | $\displaystyle P({\bm{y}}^{t}&#124;{\bm{x}},\mathcal{C})=\overbrace{P({\bm{y}}^{0}&#124;{\bm{x}},M(\cdot))}^{Generator}\times$
    |  | (1) |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle P({\bm{y}}^{t}&#124;{\bm{x}},\mathcal{C})=\overbrace{P({\bm{y}}^{0}&#124;{\bm{x}},M(\cdot))}^{生成器}\times$
    |  | (1) |'
- en: '|  | $\displaystyle\sum^{t-1}_{\{{\bm{a}},{\bm{y}}\}}\prod^{t-1}_{i=0}(\overbrace{P({\bm{y}}^{i+1}&#124;{\bm{a}}^{i},{\bm{y}}^{i},{\bm{x}},A(\cdot))}^{Interpreter}\times\overbrace{P({\bm{a}}^{i}&#124;{\bm{y}}^{i},{\bm{x}}))}^{Programmer}$
    |  | (2) |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\sum^{t-1}_{\{{\bm{a}},{\bm{y}}\}}\prod^{t-1}_{i=0}(\overbrace{P({\bm{y}}^{i+1}&#124;{\bm{a}}^{i},{\bm{y}}^{i},{\bm{x}},A(\cdot))}^{解释器}\times\overbrace{P({\bm{a}}^{i}&#124;{\bm{y}}^{i},{\bm{x}}))}^{程序员}$
    |  | (2) |'
- en: 'The Generator corresponds to the LLM (e.g. GPT-3.5, GPT-4). It produces the
    initial output text, ${\bm{y}}^{0}$, given the input ${\bm{x}}$, a set of examples
    retrieved by the function $M({\bm{x}},\mathcal{C})$ when performing in-context
    learning. The Programmer, a module that creates editing actions ${\bm{a}}^{i}$
    given ${\bm{x}}$ and the current imperfect output ${\bm{y}}^{i}$, is a pre-trained
    Sequence-to-Sequence Sutskever et al. ([2014](#bib.bib11)) language model, such
    as mT5 Xue et al. ([2021](#bib.bib15)) or flan-T5 Chung et al. ([2022](#bib.bib1)),
    fine-tuned on a synthetic dataset. The Interpreter, essentially also an LLM, refines
    the imperfect intermediate output ${\bm{y}}^{i}$ by processing instructions that
    incorporate predicted editing actions and few-shot editing examples, retrieved
    via the function $A({\bm{x}},\mathcal{C})$. Please note that the Programmer has
    much fewer parameters than the LLM used by the Generator and Interpreter. After
    several iterative refinements, we arrive at the final output ${\bm{y}}^{t}$ generated
    by the LLM. During generation, we assume no access to the parameters of the LLMs
    but only obtain the output text by providing prompting instructions. The implementation
    details of each module are as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器对应于LLM（例如，GPT-3.5，GPT-4）。它在给定输入${\bm{x}}$的情况下，生成初始输出文本${\bm{y}}^{0}$，并且在进行上下文学习时，通过函数$M({\bm{x}},\mathcal{C})$检索的示例集合。程序员是一个模块，给定${\bm{x}}$和当前不完美的输出${\bm{y}}^{i}$，创建编辑操作${\bm{a}}^{i}$，是一个预训练的序列到序列模型，如mT5
    Xue et al. ([2021](#bib.bib15))或flan-T5 Chung et al. ([2022](#bib.bib1))，在合成数据集上进行微调。解释器，本质上也是LLM，通过处理包含预测编辑操作和少量编辑示例的指令，来优化不完美的中间输出${\bm{y}}^{i}$，这些指令通过函数$A({\bm{x}},\mathcal{C})$检索。请注意，程序员的参数远少于生成器和解释器使用的LLM。经过几次迭代优化，我们得到了LLM生成的最终输出${\bm{y}}^{t}$。在生成过程中，我们假设无法访问LLMs的参数，只能通过提供提示指令获得输出文本。各模块的实现细节如下：
- en: Generator.
  id: totrans-32
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 生成器。
- en: To generate the initial output, we supply a prompt composed of a few-shot set
    of exemplar pairs, denoted as $M({\bm{x}},\mathcal{C})=\{({\bm{x}}_{j},{\bm{y}}_{j})\}^{m}_{j=1}$,
    selected from a pool of reference pairs $\mathcal{C}$. This is accompanied by
    an instruction prompting the LLM to produce output ${\bm{y}}^{0}$ based on the
    input ${\bm{x}}$. The retrieval function identifies the closest pairs by calculating
    the cosine similarity of TF-IDF features between ${\bm{x}}$ and other instances
    of ${\bm{x}}$ in $\mathcal{C}$.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了生成初始输出，我们提供一个由几个示例对组成的提示，记作 $M({\bm{x}},\mathcal{C})=\{({\bm{x}}_{j},{\bm{y}}_{j})\}^{m}_{j=1}$，从参考对池
    $\mathcal{C}$ 中选择。这还伴随有一条指令，提示LLM根据输入 ${\bm{x}}$ 生成输出 ${\bm{y}}^{0}$。检索功能通过计算
    ${\bm{x}}$ 和 $\mathcal{C}$ 中其他 ${\bm{x}}$ 实例的TF-IDF特征的余弦相似度来识别最接近的对。
- en: Programmer.
  id: totrans-34
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 程序员。
- en: After obtaining the initial or intermediate output ${\bm{y}}^{i}$ from either
    the Generator or the Interpreter, we combine the input ${\bm{x}}$ and ${\bm{y}}^{i}$
    into a single sequence and feed it to the Programmer to generate a sequence of
    edit actions ${\bm{a}}^{i}$. We create a synthetic training set $\mathcal{T}$,
    extracted from the example pool $\mathcal{C}$, for fine-tuning the Programmer.
    Each pair in $\mathcal{T}$ is defined as $({\bm{x}}_{concat},{\bm{a}}^{*})$, where
    ${\bm{x}}_{concat}$ is the concatenated sequence of ${\bm{x}}$ and ${\bm{y}}^{*}$,
    serving as the input for the Programmer. The output ${\bm{a}}^{*}$ is the sequence
    of Oracle edit actions, synthetically generated based on the reference pairs in
    $\mathcal{C}$. For each reference ${\bm{y}}\in\mathcal{C}$, we calculate the word-level
    edit distance to the imperfect translation ${\bm{y}}^{*}$, generating intermediate
    edit actions. Only INSERT-word and DELETE-word actions are retained in the sequence,
    forming the final training sequence ${\bm{a}}^{*}$ for the Programmer. If ${\bm{y}}^{*}$
    is identical to the reference ${\bm{y}}$, the action is labeled as “NoAction”,
    indicating that no refinement is needed for that instance. Unlike PiVe, which
    generates the imperfect translation ${\bm{y}}^{*}$ by scrambling the original
    ${\bm{y}}$, we directly use the initial output ${\bm{y}}^{0}$ from the Generator
    as ${\bm{y}}^{*}$ in both $\mathcal{C}$ and $\mathcal{T}$. This approach enables
    the Programmer to learn an action distribution that more effectively corrects
    translation errors from LLMs. In practice, to address the rarity of “NoAction”
    instances, we supplement these cases by creating augmented pairs, each consisting
    of two identical ${\bm{y}}$ sequences.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在从生成器或解释器获取初始或中间输出 ${\bm{y}}^{i}$ 后，我们将输入 ${\bm{x}}$ 和 ${\bm{y}}^{i}$ 合并成一个单一序列，并将其输入程序员以生成一系列编辑操作
    ${\bm{a}}^{i}$。我们创建一个合成训练集 $\mathcal{T}$，从示例池 $\mathcal{C}$ 中提取，用于微调程序员。$\mathcal{T}$
    中的每对定义为 $({\bm{x}}_{concat},{\bm{a}}^{*})$，其中 ${\bm{x}}_{concat}$ 是 ${\bm{x}}$
    和 ${\bm{y}}^{*}$ 的连接序列，作为程序员的输入。输出 ${\bm{a}}^{*}$ 是基于 $\mathcal{C}$ 中参考对合成生成的Oracle编辑操作序列。对于每个参考
    ${\bm{y}}\in\mathcal{C}$，我们计算到不完美翻译 ${\bm{y}}^{*}$ 的单词级编辑距离，生成中间编辑操作。仅保留INSERT-word和DELETE-word操作，形成程序员的最终训练序列
    ${\bm{a}}^{*}$。如果 ${\bm{y}}^{*}$ 与参考 ${\bm{y}}$ 相同，则将该操作标记为“NoAction”，表示该实例无需精炼。与通过打乱原始
    ${\bm{y}}$ 生成不完美翻译 ${\bm{y}}^{*}$ 的PiVe不同，我们直接使用生成器的初始输出 ${\bm{y}}^{0}$ 作为 $\mathcal{C}$
    和 $\mathcal{T}$ 中的 ${\bm{y}}^{*}$。这种方法使程序员能够学习更有效纠正LLM翻译错误的操作分布。在实践中，为了解决“NoAction”实例稀少的问题，我们通过创建增强对来补充这些情况，每对包括两个相同的
    ${\bm{y}}$ 序列。
- en: '|  | MT (Kashmiri to English) | LF-to-Text (AMR to English) |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '|  | MT（克什米尔语到英语） | LF-to-Text（AMR到英语） |'
- en: '| --- | --- | --- |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '|  | GEN | CONV | Bio-AMR |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '|  | GEN | CONV | Bio-AMR |'
- en: '| Method | BLEU | BERT | ChrF++ | BLEU | BERT | ChrF++ | BLEU | BERT | ChrF++
    |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | BLEU | BERT | ChrF++ | BLEU | BERT | ChrF++ | BLEU | BERT | ChrF++ |'
- en: '| Fine-tuned mT5/flan-T5 | 16.58 | 89.32 | 41.77 | 13.19 | 88.83 | 33.03 |
    9.27 | 87.90 | 41.06 |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 微调mT5/flan-T5 | 16.58 | 89.32 | 41.77 | 13.19 | 88.83 | 33.03 | 9.27 | 87.90
    | 41.06 |'
- en: '| GPT-3.5 |  |  |  |  |  |  |  |  |  |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 |  |  |  |  |  |  |  |  |  |'
- en: '|       Initial | 9.21 | 87.29 | 34.30 | 5.92 | 87.24 | 26.23 | 9.63 | 88.57
    | 43.98 |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '|       初始 | 9.21 | 87.29 | 34.30 | 5.92 | 87.24 | 26.23 | 9.63 | 88.57 | 43.98
    |'
- en: '|       Self-Correct | 13.11 | 89.02 | 38.98 | 12.73 | 89.61 | 33.76 | 11.64
    | 89.44 | 46.05 |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '|       自我修正 | 13.11 | 89.02 | 38.98 | 12.73 | 89.61 | 33.76 | 11.64 | 89.44
    | 46.05 |'
- en: '|       Algo-Refine | 8.40 | 86.92 | 39.66 | 6.29 | 87.31 | 32.21 | 7.72 |
    86.64 | 43.39 |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '|       算法精炼 | 8.40 | 86.92 | 39.66 | 6.29 | 87.31 | 32.21 | 7.72 | 86.64 |
    43.39 |'
- en: '|       Self-Refine | 8.13 | 86.54 | 31.78 | 4.73 | 86.55 | 24.13 | 8.67 |
    87.34 | 39.63 |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '|       自我精炼 | 8.13 | 86.54 | 31.78 | 4.73 | 86.55 | 24.13 | 8.67 | 87.34 |
    39.63 |'
- en: '| \hdashline    Prog-Refine (Zero-shot Act.) | 13.81 | 88.58 | 39.00 | 12.09
    | 89.41 | 33.41 | 11.43 | 89.30 | 45.44 |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| \hdashline    Prog-Refine (Zero-shot Act.) | 13.81 | 88.58 | 39.00 | 12.09
    | 89.41 | 33.41 | 11.43 | 89.30 | 45.44 |'
- en: '|       Prog-Refine (Few-shot Act.) | 16.32 | 90.36 | 42.44 | 14.78 | 90.19
    | 35.48 | 13.64 | 89.27 | 47.69 |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '|       Prog-Refine (Few-shot Act.) | 16.32 | 90.36 | 42.44 | 14.78 | 90.19
    | 35.48 | 13.64 | 89.27 | 47.69 |'
- en: '| \hdashline    Prog-Refine (ORACLE) | 43.48 | 92.11 | 65.29 | 42.42 | 93.00
    | 42.42 | 27.77 | 90.01 | 52.86 |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| \hdashline    Prog-Refine (ORACLE) | 43.48 | 92.11 | 65.29 | 42.42 | 93.00
    | 42.42 | 27.77 | 90.01 | 52.86 |'
- en: 'Table 1: The main results of MT on GEN and CONV test sets, and LF-to-Text on
    Bio-AMR test set.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：GEN 和 CONV 测试集上的 MT 主要结果，以及 Bio-AMR 测试集上的 LF-to-Text 主要结果。
- en: Interpreter.
  id: totrans-50
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 解释器。
- en: 'To edit the intermediate output ${\bm{y}}^{i}$, we engage the LLM in the Interpreter
    role by providing it with prompting instructions. Given the edit instructions
    ${\bm{a}}^{i}$ and a pair $({\bm{y}}^{i},{\bm{x}})$, the LLM can INSERT or DELETE
    words in order to generate the modified text ${\bm{y}}^{i+1}$. We also incorporate
    a few-shot examples that demonstrate editing procedures, extracted from $\mathcal{C}$
    and denoted as $A({\bm{x}},\mathcal{C})=\{({\bm{x}}_{j},{\bm{y}}_{j},{\bm{y}}^{*}_{j},{\bm{a}}^{*}_{j})\}_{j=1}^{n}$.
    These examples are selected based on the cosine similarity between the TF-IDF
    features of ${\bm{x}}$ and those in $\mathcal{C}$. Furthermore, to mimic action
    prediction errors from the Programmer, we adopt an adversarial in-context learning
    strategy, similar to the approach in Zhuo et al. ([2023](#bib.bib18)). This involves
    corrupting the action sequence by deleting Oracle actions with a certain probability
    $d\%$. If an action is not deleted, we swap it with other actions from $\mathcal{C}$
    at the same probability $d\%$. Through this manipulation, we have discovered that
    the LLM’s exceptional text generalization ability enables it to effectively comprehend
    the editing instructions. As a result, it can generate high-quality text after
    performing the necessary edits, even if the predicted actions from the Programmer
    are not completely accurate. See Figures [2](#A1.F2 "Figure 2 ‣ A.1 Prompt Example
    for Editing Text ‣ Appendix A Appendix ‣ Improving Cross-Domain Low-Resource Text
    Generation through LLM Post-Editing: A Programmer-Interpreter Approach") and [3](#A1.F3
    "Figure 3 ‣ A.1 Prompt Example for Editing Text ‣ Appendix A Appendix ‣ Improving
    Cross-Domain Low-Resource Text Generation through LLM Post-Editing: A Programmer-Interpreter
    Approach") in the Appendix for zero/few-shot instruction examples.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 要编辑中间输出 ${\bm{y}}^{i}$，我们通过提供提示指令来使 LLM 扮演解释器角色。给定编辑指令 ${\bm{a}}^{i}$ 和一对 $({\bm{y}}^{i},{\bm{x}})$，LLM
    可以插入或删除词语，以生成修改后的文本 ${\bm{y}}^{i+1}$。我们还结合了几个示例，这些示例展示了编辑过程，从 $\mathcal{C}$ 中提取并表示为
    $A({\bm{x}},\mathcal{C})=\{({\bm{x}}_{j},{\bm{y}}_{j},{\bm{y}}^{*}_{j},{\bm{a}}^{*}_{j})\}_{j=1}^{n}$。这些示例是基于
    ${\bm{x}}$ 的 TF-IDF 特征与 $\mathcal{C}$ 中特征之间的余弦相似度进行选择的。此外，为了模拟程序员的动作预测错误，我们采用了一种对抗性上下文学习策略，类似于
    Zhuo 等人（[2023](#bib.bib18)）的方法。这涉及通过以一定概率 $d\%$ 删除 Oracle 动作来破坏动作序列。如果动作未被删除，我们以相同的概率
    $d\%$ 用 $\mathcal{C}$ 中的其他动作进行替换。通过这种操控，我们发现 LLM 出色的文本泛化能力使其能够有效理解编辑指令。因此，即使程序员预测的动作不完全准确，它也能够在进行必要的编辑后生成高质量的文本。有关零样本/少样本指令示例，请参见附录中的图
    [2](#A1.F2 "图 2 ‣ A.1 编辑文本的提示示例 ‣ 附录 A 附录 ‣ 通过 LLM 后期编辑改进跨领域低资源文本生成：程序员-解释器方法")
    和 [3](#A1.F3 "图 3 ‣ A.1 编辑文本的提示示例 ‣ 附录 A 附录 ‣ 通过 LLM 后期编辑改进跨领域低资源文本生成：程序员-解释器方法")。
- en: 3 Experiments
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 实验
- en: Setup.
  id: totrans-53
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 设置。
- en: In our experiments, we default to using GPT-3.5-turbo-0301 as the LLM for the
    Generator in both the zero-shot and few-shot settings. For the Interpreter, we
    use GPT-3.5-turbo-0301 in the zero-shot setting and GPT-3.5-turbo-16k⁴⁴4https://platform.openai.com/docs/models/gpt-3-5-turbo
    in the few-shot setting. For the Generator used across all settings and baselines,
    we consistently use 0 and 5 shots for MT and LF-to-Text, respectively. For the
    Interpreter in the few-shot setting, we apply 10 and 5 action examples for MT
    and LF-to-Text, respectively, with a 50% action corruption probability. For the
    MT and LF-to-Text tasks, we employ mT5-base and flan-T5-base as the backbones
    of the Programmers, respectively. These backbone choices are driven by a computationally
    efficient setup, ensuring the models fit within an Nvidia V100 with 16GB memory.
    We train our programmers with a dev set to select the optimal model. Our search
    for the best learning rate includes [5e-5, 1e-4, 2e-4], while the range of epochs
    considered is [5, 10, 20], with batch sizes 4\. GPTs require no fine-tuning. Each
    generation of 1096 tokens costs approximately $0.0015\. We limit Self-Correct
    and Self-Refine to five editing iterations, as their performance typically stabilizes
    within this range. Conversely, Prog-Refine and Algo-Refine may require additional
    iterations for convergence, especially when ‘NoAction’ instances are infrequent.
    Thus, we continue for up to 15 iterations, ceasing only if over 95% of actions
    are ‘NoAction’.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的实验中，我们默认使用GPT-3.5-turbo-0301作为生成器的LLM，无论是在零-shot还是少-shot设置中。对于解释器，我们在零-shot设置中使用GPT-3.5-turbo-0301，在少-shot设置中使用GPT-3.5-turbo-16k⁴⁴4https://platform.openai.com/docs/models/gpt-3-5-turbo。对于所有设置和基准使用的生成器，我们始终使用0和5
    shots分别用于MT和LF-to-Text。在少-shot设置下的解释器中，我们分别应用10和5个行动示例用于MT和LF-to-Text，行动腐败概率为50%。对于MT和LF-to-Text任务，我们分别使用mT5-base和flan-T5-base作为程序员的主干。这些主干选择是基于计算效率高的设置，确保模型适合在16GB内存的Nvidia
    V100中运行。我们使用开发集训练程序员以选择最佳模型。我们对最佳学习率的搜索包括[5e-5, 1e-4, 2e-4]，而考虑的周期范围为[5, 10, 20]，批量大小为4。GPT无需微调。每生成1096个标记的成本约为$0.0015。我们将Self-Correct和Self-Refine限制为五次编辑迭代，因为它们的性能通常在此范围内稳定。相反，Prog-Refine和Algo-Refine可能需要额外的迭代以实现收敛，特别是当‘NoAction’实例较少时。因此，我们最多进行15次迭代，仅在超过95%的行动是‘NoAction’时才停止。
- en: Datasets.
  id: totrans-55
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据集。
- en: To simulate low-data scenarios, in the context of MT, we utilize a Kashmiri-English
    dataset from IndicTrans2 Gala et al. ([2023](#bib.bib2)). Since Kashmiri is a
    notably low-resource language, translating it poses a formidable challenge for
    LLMs. The dataset provides 26,016 training pairs, which we use to generate synthetic
    data for action generation. The development set consists of 997 pairs. The dataset
    includes two distinct test sets, GEN and CONV, with 1,024 and 1,503 pairs, respectively.
    Each of the training, development, and test sets originates from different domains.
    For LF-to-Text, we employ the AMR-LDC2.0⁵⁵5https://catalog.ldc.upenn.edu/LDC2017T10
    dataset, which contains 22,550 AMR-English pairs for training and 1,368 pairs
    for development. For testing, we turn to a separate dataset, Bio-AMR⁶⁶6https://amr.isi.edu/download.html,
    which offers 500 pairs in a different domain. Likewise, the AMR-to-Text task poses
    a low-resource challenge for LLMs.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟低数据场景，在MT的背景下，我们利用来自IndicTrans2 Gala等人（[2023](#bib.bib2)）的Kashmiri-English数据集。由于Kashmiri是一种显著低资源语言，翻译它对LLM提出了巨大的挑战。该数据集提供了26,016个训练对，我们用来生成行动生成的合成数据。开发集包含997对。数据集包括两个不同的测试集，GEN和CONV，分别有1,024和1,503对。训练、开发和测试集均来自不同领域。对于LF-to-Text，我们使用AMR-LDC2.0⁵⁵5https://catalog.ldc.upenn.edu/LDC2017T10数据集，该数据集包含22,550个AMR-English对用于训练和1,368个对用于开发。测试时，我们转向另一个数据集Bio-AMR⁶⁶6https://amr.isi.edu/download.html，它在不同领域提供了500个对。同样，AMR-to-Text任务对LLM构成了低资源挑战。
- en: Baselines.
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基准。
- en: We evaluate our approach, Prog-Refine, which utilizes zero-shot action exemplars
    (Zero-shot Act.) and few-shot action exemplars (Few-shot Act.) for Interpreters,
    against five baseline methods and an ORACLE setting
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们评估了我们的方法Prog-Refine，该方法利用零-shot行动示例（Zero-shot Act.）和少-shot行动示例（Few-shot Act.）用于解释器，与五种基准方法和一个ORACLE设置进行比较。
- en: i) Fine-tuned Models include mT5-base for MT and flan-T5-base for LF-to-Text
    generation, both of which are fine-tuned on the training set consisting of pairs
    $({\bm{x}},{\bm{y}})\in\mathcal{C}$. These baseline models do not perform any
    refinement.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: i) 微调模型包括用于MT的mT5-base和用于LF-to-Text生成的flan-T5-base，这些模型均在由对(${\bm{x}},{\bm{y}})\in\mathcal{C}$对组成的训练集上进行微调。这些基准模型不进行任何精细化。
- en: ii) GPT-3.5 + Initial simply applies the GPT-3.5 as the Generator to obtain
    the text without any further refinement.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ii) GPT-3.5 + Initial 简单地应用GPT-3.5作为生成器以获得文本，而不进行进一步的优化。
- en: iii) GPT-3.5 + Self-Correct Welleck et al. ([2022](#bib.bib14)) fine-tunes smaller
    models to be the Interpreter, fixing the output errors of the large models given
    the feedback. Here, we supply the edit actions produced by our Programmer as feedback
    to the fine-tuned Interpreters. These Interpreters are also built upon mT5-base
    or flan-T5-base.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: iii) GPT-3.5 + Self-Correct Welleck等（[2022](#bib.bib14)）微调较小的模型作为解释器，修正大型模型输出的错误，基于反馈进行调整。在这里，我们将程序员生成的编辑操作作为反馈提供给微调后的解释器。这些解释器也建立在mT5-base或flan-T5-base之上。
- en: iv) GPT-3.5 + Algo-Refine directly ‘Insert’ or ‘Delete’ specific words in certain
    positions of the generated text instead of using an Interpreter to rewrite. Therefore,
    in this baseline, we also apply the Interpreter to predict the indices of words
    for actions. This method is prevalent in the MT literature; e.g. see  Vu and Haffari
    ([2018](#bib.bib12)).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: iv) GPT-3.5 + Algo-Refine 直接在生成文本的特定位置‘插入’或‘删除’特定单词，而不是使用解释器进行重写。因此，在这个基线中，我们也应用解释器来预测单词的索引以进行操作。这种方法在MT文献中很常见；例如，参见
    Vu和Haffari（[2018](#bib.bib12)）。
- en: v) GPT-3.5 + Self-Refine Madaan et al. ([2023](#bib.bib6)) leverages an LLM
    to provide feedback for its own output, enabling self-refinement without the need
    for additional fine-tuning.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: v) GPT-3.5 + Self-Refine Madaan等（[2023](#bib.bib6)）利用LLM对其自身输出进行反馈，从而实现自我优化，无需额外的微调。
- en: vi) GPT-3.5 + Prog-Refine (ORACLE) applies the ORACLE actions generated by comparing
    the reference in the test set with the initial output of the Generator, allowing
    for optimal refinement after one iteration in the Zero-shot Act. setting.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: vi) GPT-3.5 + Prog-Refine（ORACLE）通过将测试集中的参考与生成器的初始输出进行比较，应用生成的ORACLE操作，在Zero-shot
    Act.设置下进行一次迭代后的最佳优化。
- en: Evaluation Metrics.
  id: totrans-65
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 评估指标。
- en: 'For LF-to-Text and MT tasks, we utilize three evaluation metrics to assess
    the quality of the final output text generated by the Programmer-Interpreter framework:
    BLEU Papineni et al. ([2002](#bib.bib7)), BERTScore [Zhang et al.](#bib.bib17)
    and Chrf++ Popović ([2017](#bib.bib9)).'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 对于LF-to-Text和MT任务，我们利用三种评估指标来评估由程序员-解释器框架生成的最终输出文本的质量：BLEU Papineni等（[2002](#bib.bib7)）、BERTScore
    [Zhang等](#bib.bib17)和Chrf++ Popović（[2017](#bib.bib9)）。
- en: 3.1 Main Results and Analysis
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 主要结果与分析
- en: 'Table [1](#S2.T1 "Table 1 ‣ Programmer. ‣ 2 Programmer-Interpreter Approach
    ‣ Improving Cross-Domain Low-Resource Text Generation through LLM Post-Editing:
    A Programmer-Interpreter Approach") shows that GPT-3.5 + Prog-Refine notably boosts
    the Generator’s performance (i.e., GPT-3.5 + Initial), underlining our method’s
    effectiveness in cross-domain scenarios by enhancing initial GPT-3.5 outputs.
    Moreover, the few-shot setting (Few-shot Act.) significantly outperforms both
    the zero-shot (Zero-shot Act.) setting and all other refinement baselines. It’s
    also noteworthy that applying ORACLE action to our method can lead to a roughly
    30-point increase in BLEU score, suggesting substantial potential for improvement
    in our approach. In comparison, Self-Refine shows minimal improvement, possibly
    due to its limited integration of task-specific knowledge. Algo-Refine inconsistently
    improves the initial text, lacking the robustness seen in our method. We note
    that rewriting Interpreters, as in our approach and Self-Correct, can eliminate
    invalid actions, thus enhancing editing quality. However, Algo-Refine does not
    possess this capability and is susceptible to incorrect feedback actions. The
    Self-Correct method, using a fine-tuned Interpreter, along with fine-tuned mT5/flan-T5
    models, demonstrates better performance than other baselines across various tasks.
    This underscores the importance of learning task-specific knowledge, especially
    in low-resource scenarios. Nonetheless, these methods face significant challenges
    in cross-domain applications, as further evidenced by our analysis in Table [4](#S3.T4
    "Table 4 ‣ Domain Discrepancy. ‣ 3.2 Ablation Study ‣ 3 Experiments ‣ Improving
    Cross-Domain Low-Resource Text Generation through LLM Post-Editing: A Programmer-Interpreter
    Approach").'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '表 [1](#S2.T1 "表 1 ‣ 程序员。 ‣ 2 程序员-翻译员方法 ‣ 通过 LLM 后编辑改进跨领域低资源文本生成: 程序员-翻译员方法")显示，GPT-3.5
    + Prog-Refine 显著提升了生成器的性能（即 GPT-3.5 + 初始），突显了我们方法在跨领域场景中的有效性，通过提升初始 GPT-3.5 输出。此外，few-shot
    设置（Few-shot Act.）明显优于零-shot（Zero-shot Act.）设置和所有其他微调基准。值得注意的是，将 ORACLE 操作应用于我们的方法可以使
    BLEU 得分提高约 30 分，表明我们方法有显著的改进潜力。相比之下，Self-Refine 显示出最小的改进，可能是由于其任务特定知识的有限集成。Algo-Refine
    不一致地改善初始文本，缺乏我们方法所见的鲁棒性。我们注意到，重写翻译员（如我们的方法和 Self-Correct）可以消除无效操作，从而提高编辑质量。然而，Algo-Refine
    不具备此能力，并且容易受到不正确反馈操作的影响。Self-Correct 方法，使用微调的翻译员以及微调的 mT5/flan-T5 模型，在各种任务中表现优于其他基准。这突显了学习任务特定知识的重要性，特别是在低资源场景中。尽管如此，这些方法在跨领域应用中面临重大挑战，正如我们在表 [4](#S3.T4
    "表 4 ‣ 领域差异。 ‣ 3.2 消融研究 ‣ 3 实验 ‣ 通过 LLM 后编辑改进跨领域低资源文本生成: 程序员-翻译员方法")中的分析所证明的。'
- en: '| MT (Kashmiri to English) |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| MT（克什米尔语到英语） |'
- en: '| --- |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| #Iter | BLEU | BERT | ChrF++ | NoAct% |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| #迭代 | BLEU | BERT | ChrF++ | NoAct% |'
- en: '| Iter 0 | 5.92 | 87.24 | 26.23 | 17.70 |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 迭代 0 | 5.92 | 87.24 | 26.23 | 17.70 |'
- en: '| Iter 1 | 11.01 | 89.18 | 33.05 | 79.71 |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 迭代 1 | 11.01 | 89.18 | 33.05 | 79.71 |'
- en: '| Iter 2 | 11.87 | 89.36 | 33.41 | 90.67 |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 迭代 2 | 11.87 | 89.36 | 33.41 | 90.67 |'
- en: '| Iter 3 | 12.09 | 89.41 | 33.41 | 95.28 |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 迭代 3 | 12.09 | 89.41 | 33.41 | 95.28 |'
- en: '| Iter 4 | 12.26 | 89.45 | 33.43 | 97.21 |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 迭代 4 | 12.26 | 89.45 | 33.43 | 97.21 |'
- en: '| Iter 5 | 12.36 | 89.47 | 33.39 | - |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 迭代 5 | 12.36 | 89.47 | 33.39 | - |'
- en: 'Table 2: The influence of 5 iterations on main results of MT using Prog-Refine
    (Zero-shot Act.) on CONV test set. NoAct%: The percentage of utterances requiring
    no refinement, as indicated by ‘NoAction’.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '表 2: 使用 Prog-Refine（零-shot 操作）在 CONV 测试集上 5 次迭代对主要结果的影响。NoAct%: 不需要微调的发言比例，如“NoAction”所示。'
- en: 3.2 Ablation Study
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 消融研究
- en: '| MT (Kashmiri to English) |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| MT（克什米尔语到英语） |'
- en: '| --- |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '|  | BLEU | BERT | ChrF++ |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '|  | BLEU | BERT | ChrF++ |'
- en: '| Initial | 5.92 | 87.24 | 26.23 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 初始 | 5.92 | 87.24 | 26.23 |'
- en: '| Edit: DEL, INS | 12.36 | 89.47 | 33.39 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 编辑: DEL, INS | 12.36 | 89.47 | 33.39 |'
- en: '| Edit: DEL | 12.27 | 89.42 | 33.21 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 编辑: DEL | 12.27 | 89.42 | 33.21 |'
- en: '| Edit: INS | 12.18 | 89.45 | 33.42 |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 编辑: INS | 12.18 | 89.45 | 33.42 |'
- en: '| Unordered: DEL, INS | 7.12 | 87.86 | 29.21 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 无序: DEL, INS | 7.12 | 87.86 | 29.21 |'
- en: '| Unordered: DEL | 6.52 | 87.51 | 26.46 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 无序: DEL | 6.52 | 87.51 | 26.46 |'
- en: '| Unordered: INS | 7.14 | 88.04 | 30.38 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 无序: INS | 7.14 | 88.04 | 30.38 |'
- en: 'Table 3: The results of MT using Prog-Refine (Zero-shot Act.) on CONV test
    set at 5th iteration with different types of actions. Edit: Actions are generated
    based on edit distance. Unordered: Actions without any specific order. INS: Insertion.
    DEL: Deletion.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '表 3: 使用 Prog-Refine（零-shot 操作）在 CONV 测试集上第 5 次迭代的 MT 结果，涵盖不同类型的操作。编辑: 操作基于编辑距离生成。无序:
    无特定顺序的操作。INS: 插入。DEL: 删除。'
- en: Refinement Iterations.
  id: totrans-91
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 微调迭代。
- en: 'In Table [2](#S3.T2 "Table 2 ‣ 3.1 Main Results and Analysis ‣ 3 Experiments
    ‣ Improving Cross-Domain Low-Resource Text Generation through LLM Post-Editing:
    A Programmer-Interpreter Approach"), we observe that Prog-Refine significantly
    improves the initial output generated by the Generator. However, it only demonstrates
    marginal improvements in the subsequent outputs from the Interpreter, even after
    four additional iterations. We hypothesize that this limited improvement may be
    attributed to training the model solely on synthetic data generated by the Generator,
    so the action distribution might be different to the ones for modifying the output
    of the Interpreter in the subsequent iterations.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '在表格 [2](#S3.T2 "Table 2 ‣ 3.1 Main Results and Analysis ‣ 3 Experiments ‣ Improving
    Cross-Domain Low-Resource Text Generation through LLM Post-Editing: A Programmer-Interpreter
    Approach")中，我们观察到Prog-Refine显著改善了生成器生成的初始输出。然而，即使在经过四次额外迭代后，它在解释器生成的后续输出中只表现出边际改进。我们假设这种有限的改进可能是由于模型仅在生成器生成的合成数据上进行训练，因此动作分布可能与修改解释器输出的动作分布不同。'
- en: Action Types.
  id: totrans-93
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 动作类型。
- en: 'We further examine the impact of solely utilizing one type of action and the
    influences of disregarding the sequence of these actions. In the setting with
    unordered actions, oracle actions are generated by simply contrasting the differences
    within two sentences’ unordered sets of words. As depicted in Table [3](#S3.T3
    "Table 3 ‣ 3.2 Ablation Study ‣ 3 Experiments ‣ Improving Cross-Domain Low-Resource
    Text Generation through LLM Post-Editing: A Programmer-Interpreter Approach"),
    the Delete and Insert actions, when used individually, can deliver performance
    metrics on par with when they are combined. However, ignoring the order of actions
    can lead to a substantial decline in the refinement performance. This highlights
    that LLM editing methods like PiVe, which utilize unordered insertions, are not
    optimally suited for our tasks. Further analysis is in Appendix [A.5](#A1.SS5
    "A.5 F1 for Action Prediction ‣ Appendix A Appendix ‣ Improving Cross-Domain Low-Resource
    Text Generation through LLM Post-Editing: A Programmer-Interpreter Approach").'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '我们进一步检验了仅使用一种动作类型和忽略这些动作顺序的影响。在无序动作设置中，oracle动作通过简单对比两个句子的无序词集之间的差异来生成。如表 [3](#S3.T3
    "Table 3 ‣ 3.2 Ablation Study ‣ 3 Experiments ‣ Improving Cross-Domain Low-Resource
    Text Generation through LLM Post-Editing: A Programmer-Interpreter Approach")所示，单独使用删除和插入动作时，它们的性能指标可以与组合使用时相当。然而，忽略动作的顺序会导致精炼性能显著下降。这表明像PiVe这样的LLM编辑方法，使用无序插入，不适合我们的任务。进一步分析见附录
    [A.5](#A1.SS5 "A.5 F1 for Action Prediction ‣ Appendix A Appendix ‣ Improving
    Cross-Domain Low-Resource Text Generation through LLM Post-Editing: A Programmer-Interpreter
    Approach")。'
- en: Domain Discrepancy.
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 领域差异。
- en: 'As shown in Table [4](#S3.T4 "Table 4 ‣ Domain Discrepancy. ‣ 3.2 Ablation
    Study ‣ 3 Experiments ‣ Improving Cross-Domain Low-Resource Text Generation through
    LLM Post-Editing: A Programmer-Interpreter Approach"), a domain shift dramatically
    impacts the performance of flan-T5 and Self-Correct. While both baseline models
    show markedly superior performance on the in-domain test set relative to our model,
    ours either surpasses or equals their performance in the cross-domain MT and AMR-to-Text
    test sets. This disparity in performance is likely due to the smaller models’
    limited cross-domain generalization. Similarly, in MT tasks, our preliminary experiments
    show that fine-tuned mT5 achieves 30 points of BLEU on the in-domain test but
    only 16 and 13 on out-of-domain tests. For further details on domain discrepancies,
    see Appendix [A.3](#A1.SS3 "A.3 Measures of Domain Discrepancy ‣ Appendix A Appendix
    ‣ Improving Cross-Domain Low-Resource Text Generation through LLM Post-Editing:
    A Programmer-Interpreter Approach").'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '如表 [4](#S3.T4 "Table 4 ‣ Domain Discrepancy. ‣ 3.2 Ablation Study ‣ 3 Experiments
    ‣ Improving Cross-Domain Low-Resource Text Generation through LLM Post-Editing:
    A Programmer-Interpreter Approach")所示，领域转移对flan-T5和Self-Correct的性能有着显著影响。尽管这两个基线模型在领域内测试集上的性能明显优于我们的模型，但在跨领域MT和AMR到文本测试集上，我们的模型要么超越，要么与它们的性能持平。这种性能差异可能是由于较小模型在跨领域泛化能力有限。类似地，在MT任务中，我们的初步实验显示，微调后的mT5在领域内测试集上取得了30分的BLEU，但在领域外测试集上仅为16和13。有关领域差异的更多细节，请参见附录
    [A.3](#A1.SS3 "A.3 Measures of Domain Discrepancy ‣ Appendix A Appendix ‣ Improving
    Cross-Domain Low-Resource Text Generation through LLM Post-Editing: A Programmer-Interpreter
    Approach")。'
- en: '| LF-to-Text (AMR to English) |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| LF-to-Text (AMR到英语) |'
- en: '| --- |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| Method | BLEU | BERT | ChrF++ |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | BLEU | BERT | ChrF++ |'
- en: '| Fine-tuned flan-T5 | 34.63 | 95.05 | 66.97 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 微调flan-T5 | 34.63 | 95.05 | 66.97 |'
- en: '| GPT-3.5 |  |  |  |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 |  |  |  |'
- en: '|       Initial | 19.67 | 92.10 | 55.98 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '|       初始 | 19.67 | 92.10 | 55.98 |'
- en: '|       Self-Correct | 34.49 | 94.68 | 66.81 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '|       Self-Correct | 34.49 | 94.68 | 66.81 |'
- en: '|       Self-Refine | 16.16 | 91.08 | 52.78 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '|       Self-Refine | 16.16 | 91.08 | 52.78 |'
- en: '|       Prog-Refine | 29.12 | 94.01 | 64.85 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '|       Prog-Refine | 29.12 | 94.01 | 64.85 |'
- en: 'Table 4: LF-to-Text results using Prog-Refine (Zero-shot Act.) on the in-domain
    LDC test.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '表 4: 在领域内 LDC 测试中使用 Prog-Refine（零样本操作）的 LF-to-Text 结果。'
- en: Adversarial In-context Learning.
  id: totrans-107
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 对抗性上下文学习。
- en: 'Table [5](#S3.T5 "Table 5 ‣ Adversarial In-context Learning. ‣ 3.2 Ablation
    Study ‣ 3 Experiments ‣ Improving Cross-Domain Low-Resource Text Generation through
    LLM Post-Editing: A Programmer-Interpreter Approach") indicates 0.0 for no corruption
    and 1.0 for complete discarding of exemplar actions, leaving only ${({\bm{x}}_{j},{\bm{y}}^{*}_{j},{\bm{y}}_{j})}_{j=1}^{n}$.
    Rates between 0.0 and 1.0 represent partial corruption of Oracle actions. The
    results suggest that neither full application nor total corruption of Oracle actions
    is optimal. However, partial corruption leads to improved performance. Additionally,
    across all corruption rates, few-shot settings consistently outperform zero-shot
    settings.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [5](#S3.T5 "表 5 ‣ 对抗性上下文学习。 ‣ 3.2 消融研究 ‣ 3 实验 ‣ 通过 LLM 后处理改进跨领域低资源文本生成：一种程序员-解释器方法")
    显示 0.0 表示无腐败，1.0 表示完全丢弃示例操作，仅保留 ${({\bm{x}}_{j},{\bm{y}}^{*}_{j},{\bm{y}}_{j})}_{j=1}^{n}。速率在
    0.0 和 1.0 之间表示 Oracle 操作的部分腐败。结果表明，无论是完全应用还是完全腐败 Oracle 操作都不是最佳的。然而，部分腐败导致了性能的提升。此外，在所有腐败率下，少样本设置始终优于零样本设置。
- en: '| LF-to-Text (AMR to English) |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| LF-to-Text (AMR 到英语) |'
- en: '| --- |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| Rate | BLEU | BERT | ChrF++ |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 速率 | BLEU | BERT | ChrF++ |'
- en: '| 0.0 | 12.06 | 89.31 | 46.23 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 0.0 | 12.06 | 89.31 | 46.23 |'
- en: '| 0.2 | 12.35 | 89.36 | 46.49 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 0.2 | 12.35 | 89.36 | 46.49 |'
- en: '| 0.5 | 13.64 | 89.27 | 47.69 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 0.5 | 13.64 | 89.27 | 47.69 |'
- en: '| 1.0 | 11.97 | 89.32 | 46.13 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 1.0 | 11.97 | 89.32 | 46.13 |'
- en: 'Table 5: LF-to-Text results using Prog-Refine (Few-shot Act.) vary with different
    corruption probabilities for the action sequence in the adversarial in-context
    examples used for the Interpreter.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '表 5: 使用 Prog-Refine（少样本操作）进行 LF-to-Text 结果，在对抗性上下文示例中，不同的操作序列腐败概率不同。'
- en: 4 Conclusions
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 结论
- en: We present a programmer-interpreter method that iteratively refines LLM outputs
    using edit actions from a fine-tuned programmer and an LLM interpreter. Our approach
    combines the task-specific encoding capacity of a fine-tuned model with the domain
    generalization strength of the LLM, incorporating specifically designed actions
    for text generation. The experiments confirm its efficacy, showing significant
    improvements in LLM-generated text quality for low-resource MT and LF-to-Text
    tasks. Moreover, our approach outperforms established baselines in cross-domain
    scenarios.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出了一种程序员-解释器方法，该方法通过来自微调程序员和 LLM 解释器的编辑操作迭代改进 LLM 输出。我们的方法结合了微调模型的任务特定编码能力与
    LLM 的领域泛化强度，并结合了专门设计的文本生成操作。实验确认了其有效性，显示在低资源机器翻译和 LF-to-Text 任务中，LLM 生成的文本质量有显著提升。此外，我们的方法在跨领域场景中优于既定基准。
- en: 5 Limitations
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 限制
- en: This work has two primary limitations. First, in in-domain tests, our approach
    does not outperform smaller models, such as mT5 and flan-T5\. Considering the
    performance improvements we observed when using ORACLE actions, we believe there
    is substantial potential to further enhance our method for text generation in
    the in-domain evaluation setting. Second, our approach requires internet transmission
    of prompt instructions to the servers of ChatGPT. This could potentially lead
    to a risk of privacy leakage, which is a critical concern in data-sensitive applications.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究有两个主要限制。首先，在领域内测试中，我们的方法没有优于较小的模型，如 mT5 和 flan-T5。考虑到我们观察到使用 ORACLE 操作时性能的改善，我们认为在领域内评估设置中还有大量潜力进一步提升我们的方法。其次，我们的方法需要将提示指令传输到
    ChatGPT 的服务器，这可能会带来隐私泄露的风险，这是数据敏感应用中的一个关键问题。
- en: References
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Chung et al. (2022) Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay,
    William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al.
    2022. Scaling instruction-finetuned language models. *arXiv preprint arXiv:2210.11416*.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chung 等人（2022） Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay,
    William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma 等人。2022年。扩展指令微调语言模型。
    *arXiv 预印本 arXiv:2210.11416*。
- en: 'Gala et al. (2023) Jay Gala, Pranjal A Chitale, Raghavan AK, Sumanth Doddapaneni,
    Varun Gumma, Aswanth Kumar, Janki Nawale, Anupama Sujatha, Ratish Puduppully,
    Vivek Raghavan, et al. 2023. Indictrans2: Towards high-quality and accessible
    machine translation models for all 22 scheduled indian languages. *arXiv preprint
    arXiv:2305.16307*.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gala等（2023）Jay Gala, Pranjal A Chitale, Raghavan AK, Sumanth Doddapaneni, Varun
    Gumma, Aswanth Kumar, Janki Nawale, Anupama Sujatha, Ratish Puduppully, Vivek
    Raghavan, 等. 2023. Indictrans2: Towards high-quality and accessible machine translation
    models for all 22 scheduled indian languages. *arXiv预印本 arXiv:2305.16307*。'
- en: 'Han et al. (2023) Jiuzhou Han, Nigel Collier, Wray Buntine, and Ehsan Shareghi.
    2023. Pive: Prompting with iterative verification improving graph-based generative
    capability of llms. *arXiv preprint arXiv:2305.12392*.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Han等（2023）Jiuzhou Han, Nigel Collier, Wray Buntine, 和 Ehsan Shareghi. 2023.
    Pive: Prompting with iterative verification improving graph-based generative capability
    of llms. *arXiv预印本 arXiv:2305.12392*。'
- en: 'Haroutunian et al. (2023) Levon Haroutunian, Zhuang Li, Lucian Galescu, Philip
    Cohen, Raj Tumuluri, and Gholamreza Haffari. 2023. Reranking for natural language
    generation from logical forms: A study based on large language models. *arXiv
    preprint arXiv:2309.12294*.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Haroutunian等（2023）Levon Haroutunian, Zhuang Li, Lucian Galescu, Philip Cohen,
    Raj Tumuluri, 和 Gholamreza Haffari. 2023. Reranking for natural language generation
    from logical forms: A study based on large language models. *arXiv预印本 arXiv:2309.12294*。'
- en: 'Lai et al. (2023) Viet Dac Lai, Nghia Trung Ngo, Amir Pouran Ben Veyseh, Hieu
    Man, Franck Dernoncourt, Trung Bui, and Thien Huu Nguyen. 2023. Chatgpt beyond
    english: Towards a comprehensive evaluation of large language models in multilingual
    learning. *arXiv preprint arXiv:2304.05613*.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lai等（2023）Viet Dac Lai, Nghia Trung Ngo, Amir Pouran Ben Veyseh, Hieu Man,
    Franck Dernoncourt, Trung Bui, 和 Thien Huu Nguyen. 2023. Chatgpt beyond english:
    Towards a comprehensive evaluation of large language models in multilingual learning.
    *arXiv预印本 arXiv:2304.05613*。'
- en: 'Madaan et al. (2023) Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan,
    Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang,
    et al. 2023. Self-refine: Iterative refinement with self-feedback. *arXiv preprint
    arXiv:2303.17651*.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Madaan等（2023）Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu
    Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang,
    等. 2023. Self-refine: Iterative refinement with self-feedback. *arXiv预印本 arXiv:2303.17651*。'
- en: 'Papineni et al. (2002) Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing
    Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In
    *Proceedings of the 40th annual meeting of the Association for Computational Linguistics*,
    pages 311–318.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Papineni等（2002）Kishore Papineni, Salim Roukos, Todd Ward, 和 Wei-Jing Zhu. 2002.
    Bleu: a method for automatic evaluation of machine translation. 在 *第40届计算语言学协会年会论文集*,
    页码 311–318。'
- en: 'Pillutla et al. (2021) Krishna Pillutla, Swabha Swayamdipta, Rowan Zellers,
    John Thickstun, Sean Welleck, Yejin Choi, and Zaïd Harchaoui. 2021. MAUVE: measuring
    the gap between neural text and human text using divergence frontiers. In *Advances
    in Neural Information Processing Systems (NeurIPS)*, pages 4816–4828.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Pillutla等（2021）Krishna Pillutla, Swabha Swayamdipta, Rowan Zellers, John Thickstun,
    Sean Welleck, Yejin Choi, 和 Zaïd Harchaoui. 2021. MAUVE: measuring the gap between
    neural text and human text using divergence frontiers. 在 *神经信息处理系统的进展 (NeurIPS)*,
    页码 4816–4828。'
- en: 'Popović (2017) Maja Popović. 2017. chrf++: words helping character n-grams.
    In *Proceedings of the second conference on machine translation*, pages 612–618.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Popović（2017）Maja Popović. 2017. chrf++: words helping character n-grams. 在
    *第二届机器翻译会议论文集*, 页码 612–618。'
- en: Reed and de Freitas (2016) Scott E. Reed and Nando de Freitas. 2016. Neural
    programmer-interpreters. In *International Conference on Learning Representations
    (ICLR)*.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Reed 和 de Freitas（2016）Scott E. Reed 和 Nando de Freitas. 2016. Neural programmer-interpreters.
    在 *国际学习表征会议（ICLR）*。
- en: Sutskever et al. (2014) Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.
    Sequence to sequence learning with neural networks. *Advances in neural information
    processing systems*, 27.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sutskever等（2014）Ilya Sutskever, Oriol Vinyals, 和 Quoc V Le. 2014. Sequence to
    sequence learning with neural networks. *神经信息处理系统的进展*, 27。
- en: 'Vu and Haffari (2018) Thuy Vu and Gholamreza Haffari. 2018. Automatic post-editing
    of machine translation: A neural programmer-interpreter approach. In *Proceedings
    of the 2018 conference on empirical methods in natural language processing*, pages
    3048–3053.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Vu 和 Haffari（2018）Thuy Vu 和 Gholamreza Haffari. 2018. Automatic post-editing
    of machine translation: A neural programmer-interpreter approach. 在 *2018年自然语言处理实证方法会议论文集*,
    页码 3048–3053。'
- en: 'Wang et al. (2023) Jindong Wang, HU Xixu, Wenxin Hou, Hao Chen, Runkai Zheng,
    Yidong Wang, Linyi Yang, Wei Ye, Haojun Huang, Xiubo Geng, et al. 2023. On the
    robustness of chatgpt: An adversarial and out-of-distribution perspective. In
    *ICLR 2023 Workshop on Trustworthy and Reliable Large-Scale Machine Learning Models*.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等（2023）Jindong Wang、HU Xixu、Wenxin Hou、Hao Chen、Runkai Zheng、Yidong Wang、Linyi
    Yang、Wei Ye、Haojun Huang、Xiubo Geng 等。2023年。关于 ChatGPT 的鲁棒性：一个对抗性和分布外的视角。发表于 *ICLR
    2023 信任和可靠的大规模机器学习模型研讨会*。
- en: Welleck et al. (2022) Sean Welleck, Ximing Lu, Peter West, Faeze Brahman, Tianxiao
    Shen, Daniel Khashabi, and Yejin Choi. 2022. Generating sequences by learning
    to self-correct. *arXiv preprint arXiv:2211.00053*.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Welleck 等（2022）Sean Welleck、Ximing Lu、Peter West、Faeze Brahman、Tianxiao Shen、Daniel
    Khashabi 和 Yejin Choi。2022年。通过学习自我修正生成序列。*arXiv 预印本 arXiv:2211.00053*。
- en: 'Xue et al. (2021) Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami
    Al-Rfou, Aditya Siddhant, Aditya Barua, and Colin Raffel. 2021. mt5: A massively
    multilingual pre-trained text-to-text transformer. In *Proceedings of the 2021
    Conference of the North American Chapter of the Association for Computational
    Linguistics: Human Language Technologies*, pages 483–498.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xue 等（2021）Linting Xue、Noah Constant、Adam Roberts、Mihir Kale、Rami Al-Rfou、Aditya
    Siddhant、Aditya Barua 和 Colin Raffel。2021年。mt5：一种大规模多语言预训练文本到文本转换器。发表于 *2021年北美计算语言学学会人类语言技术会议论文集*，第483–498页。
- en: 'Yang et al. (2023) Jingfeng Yang, Hongye Jin, Ruixiang Tang, Xiaotian Han,
    Qizhang Feng, Haoming Jiang, Bing Yin, and Xia Hu. 2023. Harnessing the power
    of llms in practice: A survey on chatgpt and beyond. *arXiv preprint arXiv:2304.13712*.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等（2023）Jingfeng Yang、Hongye Jin、Ruixiang Tang、Xiaotian Han、Qizhang Feng、Haoming
    Jiang、Bing Yin 和 Xia Hu。2023年。实践中利用 LLM 的力量：关于 ChatGPT 及其后续的调查。*arXiv 预印本 arXiv:2304.13712*。
- en: '(17) Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, and Yoav
    Artzi. Bertscore: Evaluating text generation with bert. In *International Conference
    on Learning Representations*.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （17）Tianyi Zhang、Varsha Kishore、Felix Wu、Kilian Q Weinberger 和 Yoav Artzi。Bertscore：用
    BERT 评估文本生成。发表于 *国际学习表示会议*。
- en: 'Zhuo et al. (2023) Terry Yue Zhuo, Zhuang Li, Yujin Huang, Fatemeh Shiri, Weiqing
    Wang, Gholamreza Haffari, and Yuan-Fang Li. 2023. On robustness of prompt-based
    semantic parsing with large pre-trained language model: An empirical study on
    codex. In *Proceedings of the 17th Conference of the European Chapter of the Association
    for Computational Linguistics*, pages 1090–1102.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhuo 等（2023）Terry Yue Zhuo、Zhuang Li、Yujin Huang、Fatemeh Shiri、Weiqing Wang、Gholamreza
    Haffari 和 Yuan-Fang Li。2023年。基于提示的语义解析在大型预训练语言模型下的鲁棒性：关于 Codex 的实证研究。发表于 *第17届欧洲计算语言学学会会议论文集*，第1090–1102页。
- en: Appendix A Appendix
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 附录
- en: A.1 Prompt Example for Editing Text
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 编辑文本的示例
- en: 'Figures [2](#A1.F2 "Figure 2 ‣ A.1 Prompt Example for Editing Text ‣ Appendix
    A Appendix ‣ Improving Cross-Domain Low-Resource Text Generation through LLM Post-Editing:
    A Programmer-Interpreter Approach") and [3](#A1.F3 "Figure 3 ‣ A.1 Prompt Example
    for Editing Text ‣ Appendix A Appendix ‣ Improving Cross-Domain Low-Resource Text
    Generation through LLM Post-Editing: A Programmer-Interpreter Approach") depict
    the exemplary zero/few-shot prompt employed in LF-to-Text.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [2](#A1.F2 "图 2 ‣ A.1 编辑文本的示例 ‣ 附录 A 附录 ‣ 通过 LLM 后编辑改进跨领域低资源文本生成：程序员-解释器方法")
    和 [3](#A1.F3 "图 3 ‣ A.1 编辑文本的示例 ‣ 附录 A 附录 ‣ 通过 LLM 后编辑改进跨领域低资源文本生成：程序员-解释器方法")
    描述了 LF-to-Text 中使用的示例性零样本/少样本提示。
- en: '![Refer to caption](img/cf47e875d57fdd1628b0eb43deefa0cb.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/cf47e875d57fdd1628b0eb43deefa0cb.png)'
- en: 'Figure 2: The zero-shot exemplary prompt for LF-to-Text.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：LF-to-Text 的零样本示例提示。
- en: '![Refer to caption](img/b232658e787b249fca4bc0c9c630c102.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/b232658e787b249fca4bc0c9c630c102.png)'
- en: 'Figure 3: The few-shot exemplary prompt for LF-to-Text.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：LF-to-Text 的少样本示例提示。
- en: A.2 Adaption of Self-Corrector
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 自我修正器的适应
- en: 'In our experiment, we adapted the implementation of the Self-Corrector to better
    suit our specific requirements. To customize it for our context, we constructed
    the training set for the Self-Corrector’s Interpreter as follows: the input consists
    of a concatenation of Kashrimi/AMR, text produced by the Generator, and edit actions.
    The output, on the other hand, is the ground truth text. For a fair comparison
    with our approach and to minimize training and data collection expenses, models
    are trained only during the first iteration. Additionally, the generation of the
    training set solely utilizes text from the Generator in the initial iteration,
    without using text from the Interpreter in subsequent refinement iterations.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的实验中，我们调整了 Self-Corrector 的实现以更好地适应我们的具体需求。为了将其定制化，我们为 Self-Corrector 的 Interpreter
    构建了如下训练集：输入由 Kashrimi/AMR、生成器产生的文本和编辑操作的拼接组成。另一方面，输出是正确的文本。为了公平地与我们的方法进行比较，并且降低训练和数据收集的费用，模型仅在第一次迭代中进行训练。此外，训练集的生成仅利用初始迭代中的生成器文本，不使用后续细化迭代中的
    Interpreter 文本。
- en: A.3 Measures of Domain Discrepancy
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.3 领域差异度量
- en: 'Tables [6](#A1.T6 "Table 6 ‣ A.3 Measures of Domain Discrepancy ‣ Appendix
    A Appendix ‣ Improving Cross-Domain Low-Resource Text Generation through LLM Post-Editing:
    A Programmer-Interpreter Approach") and [7](#A1.T7 "Table 7 ‣ A.3 Measures of
    Domain Discrepancy ‣ Appendix A Appendix ‣ Improving Cross-Domain Low-Resource
    Text Generation through LLM Post-Editing: A Programmer-Interpreter Approach")
    present domain discrepancies for the training/development/testing sets for the
    MT and LF-to-text generation tasks. The domain discrepancy measures include the
    KL-divergence (based on the unigram distributions) and MAUVE Pillutla et al. ([2021](#bib.bib8)).
    KL-divergence scores are higher when two distributions are more different from
    each other. MAUVE scores, which have a range (0,1), are lower when two distributions
    are more different from each other.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '表[6](#A1.T6 "Table 6 ‣ A.3 Measures of Domain Discrepancy ‣ Appendix A Appendix
    ‣ Improving Cross-Domain Low-Resource Text Generation through LLM Post-Editing:
    A Programmer-Interpreter Approach") 和 [7](#A1.T7 "Table 7 ‣ A.3 Measures of Domain
    Discrepancy ‣ Appendix A Appendix ‣ Improving Cross-Domain Low-Resource Text Generation
    through LLM Post-Editing: A Programmer-Interpreter Approach") 展示了 MT 和 LF-to-text
    生成任务的训练/开发/测试集领域差异。领域差异度量包括 KL 散度（基于单词分布）和 MAUVE Pillutla 等人 ([2021](#bib.bib8))。当两个分布之间的差异更大时，KL
    散度分数更高。MAUVE 分数的范围是 (0,1)，当两个分布之间的差异更大时，MAUVE 分数更低。'
- en: '| splits compared | KL-div $\downarrow$ |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 比较拆分 | KL 散度 $\downarrow$ |'
- en: 'Table 6: Measures of domain difference across different splits of the machine
    translation datasets. KL-divergence scores are calculated for the English sentences
    in each data split, with additive smoothing ($\alpha=1\times 10^{-4}$). For MAUVE,
    5000 sentences are sampled from the training set.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6：不同拆分的机器翻译数据集中领域差异的度量。KL 散度分数是对每个数据拆分中的英文句子计算的，使用加法平滑（$\alpha=1\times 10^{-4}$）。对于
    MAUVE，从训练集中抽取了 5000 个句子。
- en: '| splits compared | KL-div $\downarrow$ |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 比较拆分 | KL 散度 $\downarrow$ |'
- en: 'Table 7: Measures of domain difference across different splits of the AMR dataset.
    KL-divergence scores are calculated for the English sentences in each data split,
    with additive smoothing ($\alpha=1\times 10^{-4}$). For MAUVE, 5000 sentences
    are sampled from the training set.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7：不同拆分的 AMR 数据集中领域差异的度量。KL 散度分数是对每个数据拆分中的英文句子计算的，使用加法平滑（$\alpha=1\times 10^{-4}$）。对于
    MAUVE，从训练集中抽取了 5000 个句子。
- en: 'Based on Table [6](#A1.T6 "Table 6 ‣ A.3 Measures of Domain Discrepancy ‣ Appendix
    A Appendix ‣ Improving Cross-Domain Low-Resource Text Generation through LLM Post-Editing:
    A Programmer-Interpreter Approach"), we observe that the domain of test-gen is
    closer to the training set compared to that of the test-conv. This is pronounced
    in higher KL-divergence and lower MAUVE numbers for the test-conv compared to
    test-gen, with respect to the training set.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '基于表[6](#A1.T6 "Table 6 ‣ A.3 Measures of Domain Discrepancy ‣ Appendix A Appendix
    ‣ Improving Cross-Domain Low-Resource Text Generation through LLM Post-Editing:
    A Programmer-Interpreter Approach")，我们观察到 test-gen 的领域与训练集更接近，相比之下，test-conv 的领域则较远。这在
    test-conv 相对于 test-gen 的 KL 散度较高和 MAUVE 数字较低中表现得尤为明显。'
- en: 'Based on Table [7](#A1.T7 "Table 7 ‣ A.3 Measures of Domain Discrepancy ‣ Appendix
    A Appendix ‣ Improving Cross-Domain Low-Resource Text Generation through LLM Post-Editing:
    A Programmer-Interpreter Approach") , we observe a higher difference for the domain
    of the biology-AMR test compared to the LDC2.0-AMR test set, with respect to the
    training/development sets of the LDC2.0-AMR dataset. This is pronounced in larger
    KL divergence and lower MAUVE numbers compared to those for the LDC2.0-AMR test
    set.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '基于表 [7](#A1.T7 "Table 7 ‣ A.3 Measures of Domain Discrepancy ‣ Appendix A Appendix
    ‣ Improving Cross-Domain Low-Resource Text Generation through LLM Post-Editing:
    A Programmer-Interpreter Approach")，我们观察到生物-AMR 测试领域与 LDC2.0-AMR 测试集相比，训练/开发集的差异更大。与
    LDC2.0-AMR 测试集相比，这在更大的 KL 散度和较低的 MAUVE 数字中表现突出。'
- en: A.4 F1 Definition for Action Prediction
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.4 行动预测的 F1 定义
- en: '|  | $\displaystyle F1$ | $\displaystyle=2\times\frac{P_{act}\times R_{act}}{P_{act}+R_{act}}$
    |  | (3) |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle F1$ | $\displaystyle=2\times\frac{P_{act}\times R_{act}}{P_{act}+R_{act}}$
    |  | (3) |'
- en: Here, $P_{act}$ represents action precision, defined as the ratio of predicted
    actions present in the reference action sequence to the total number of predicted
    actions. $R_{act}$ denotes action recall, which is the ratio of predicted actions
    that appear in the reference action sequence to the total number of actions in
    the reference sequence. The F1 score, thus, provides a harmonious mean of these
    two metrics.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，$P_{act}$ 表示行动精度，定义为参考行动序列中预测的行动与总预测行动数的比率。$R_{act}$ 表示行动召回率，即参考行动序列中出现的预测行动与参考序列中总行动数的比率。因此，F1
    得分提供了这两个指标的和谐均值。
- en: A.5 F1 for Action Prediction
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.5 行动预测的 F1
- en: 'Table [8](#A1.T8 "Table 8 ‣ A.5 F1 for Action Prediction ‣ Appendix A Appendix
    ‣ Improving Cross-Domain Low-Resource Text Generation through LLM Post-Editing:
    A Programmer-Interpreter Approach") reveals that predicting INSERT actions is
    a relatively easier task compared to predicting DELETE actions. This observation
    is reasonable since the Programmer only needs to learn how to DELETE words from
    the text with a fixed vocabulary, whereas, for INSERT actions, the Programmer
    must learn to INSERT arbitrary words.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '表 [8](#A1.T8 "Table 8 ‣ A.5 F1 for Action Prediction ‣ Appendix A Appendix
    ‣ Improving Cross-Domain Low-Resource Text Generation through LLM Post-Editing:
    A Programmer-Interpreter Approach") 显示，相比于预测 DELETE 行动，预测 INSERT 行动相对较为容易。这一观察是合理的，因为程序员只需学习如何从文本中删除单词，而对于
    INSERT 行动，程序员必须学习插入任意单词。'
- en: '|  | INSERT | DELETE | Total |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '|  | INSERT | DELETE | Total |'
- en: '| --- | --- | --- | --- |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| MT | 33.64 | 83.73 | 62.57 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| MT | 33.64 | 83.73 | 62.57 |'
- en: '| NLG | 24.52 | 60.48 | 44.90 |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| NLG | 24.52 | 60.48 | 44.90 |'
- en: 'Table 8: The F1 scores of comparing the predicted actions with the ORACLE actions
    in the GEN test set.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8：与 ORACLE 行动在 GEN 测试集中的预测行动 F1 得分比较。
- en: A.6 Comparing GPT-4 and GPT-3.5 as Interpreters
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.6 比较 GPT-4 和 GPT-3.5 作为解释器
- en: '| LF-to-Text (AMR to English) |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| LF-to-Text（AMR 到英语） |'
- en: '| --- |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '|  | BLEU | BERT | ChrF++ |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '|  | BLEU | BERT | ChrF++ |'
- en: '| GPT-3.5-turbo-16k | 11.43 | 89.30 | 45.44 |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5-turbo-16k | 11.43 | 89.30 | 45.44 |'
- en: '| GPT-4-turbo | 11.72 | 89.36 | 45.58 |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4-turbo | 11.72 | 89.36 | 45.58 |'
- en: 'Table 9: LF-to-Text results of Prog-Refine (Zero-shot Act.) in zero-shot setting
    with different LLMs as Interpreters.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 表 9：不同 LLM 作为解释器在零样本设置下的 Prog-Refine（零样本行动） LF-to-Text 结果。
- en: 'Table [9](#A1.T9 "Table 9 ‣ A.6 Comparing GPT-4 and GPT-3.5 as Interpreters
    ‣ Appendix A Appendix ‣ Improving Cross-Domain Low-Resource Text Generation through
    LLM Post-Editing: A Programmer-Interpreter Approach") illustrates the performance
    differences in the LF-to-Text task when using GPT-4 and GPT-3.5 as Interpreters
    for Prog-Refine (Zero-shot Act.). While GPT-4 offers a slight performance boost,
    the improvement is not substantial, amounting to only a 0.3 increase in BLEU score.
    Moreover, this comes at a higher cost of 0.06 per 1000 characters, compared to
    0.0015 for GPT-3.5.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '表 [9](#A1.T9 "Table 9 ‣ A.6 Comparing GPT-4 and GPT-3.5 as Interpreters ‣ Appendix
    A Appendix ‣ Improving Cross-Domain Low-Resource Text Generation through LLM Post-Editing:
    A Programmer-Interpreter Approach") 说明了在将 GPT-4 和 GPT-3.5 用作 Prog-Refine（零样本行动）解释器时，LF-to-Text
    任务的性能差异。虽然 GPT-4 提供了略微的性能提升，但改进不大，仅增加了 0.3 的 BLEU 得分。此外，与 GPT-3.5 的 0.0015 相比，这一提升的成本为每
    1000 个字符 0.06。'
