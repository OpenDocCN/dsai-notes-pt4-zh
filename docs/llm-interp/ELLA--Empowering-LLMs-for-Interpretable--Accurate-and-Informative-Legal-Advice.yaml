- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 17:33:40'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 17:33:40
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'ELLA: Empowering LLMs for Interpretable, Accurate and Informative Legal Advice'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'ELLA: Empowering LLMs for Interpretable, Accurate and Informative Legal Advice'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2408.07137](https://ar5iv.labs.arxiv.org/html/2408.07137)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2408.07137](https://ar5iv.labs.arxiv.org/html/2408.07137)
- en: Yutong Hu^(1,2), Kangcheng Luo^(3,∗), Yansong Feng¹
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Yutong Hu^(1,2)，Kangcheng Luo^(3,∗)，Yansong Feng¹
- en: ¹Wangxuan Institute of Computer Technology, Peking University, China
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ¹北京大学王选计算机技术研究所，中国
- en: ²School of Intelligence Science and Technology, Peking University
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ²北京大学智能科学与技术学院
- en: ³School of Electronics Engineering and Computer Science, Peking University,
    China
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ³北京大学电子工程与计算机科学学院，中国
- en: State Key Laboratory of General Artificial Intelligence
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 国家重点人工智能实验室
- en: '{huyutong,fengyansong} @pku.edu.cn'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '{huyutong,fengyansong} @pku.edu.cn'
- en: luokangcheng@stu.pku.edu.cn  Equal Contribution.  Corresponding author.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: luokangcheng@stu.pku.edu.cn  平等贡献。  通讯作者。
- en: Abstract
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Despite remarkable performance in legal consultation exhibited by legal Large
    Language Models(LLMs) combined with legal article retrieval components, there
    are still cases when the advice given is incorrect or baseless. To alleviate these
    problems, we propose ELLA, a tool for Empowering LLMs for interpretable, accurate,
    and informative Legal Advice. ELLA visually presents the correlation between legal
    articles and LLM’s response by calculating their similarities, providing users
    with an intuitive legal basis for the responses. Besides, based on the users’
    queries, ELLA retrieves relevant legal articles and displays them to users. Users
    can interactively select legal articles for LLM to generate more accurate responses.
    ELLA also retrieves relevant legal cases for user reference. Our user study shows
    that presenting the legal basis for the response helps users understand better.
    The accuracy of LLM’s responses also improves when users intervene in selecting
    legal articles for LLM. Providing relevant legal cases also aids individuals in
    obtaining comprehensive information. Our github repo is: [https://github.com/Huyt00/ELLA](https://github.com/Huyt00/ELLA)¹¹1Video
    demonstration is available at: [https://youtu.be/V8iaIXSJ2i8](https://youtu.be/V8iaIXSJ2i8).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管法律大型语言模型（LLMs）结合法律文章检索组件在法律咨询中表现出色，但仍有一些情况下提供的建议是不正确或没有依据的。为了解决这些问题，我们提出了
    ELLA，一个旨在为 LLM 提供可解释、准确和有用法律建议的工具。ELLA 通过计算法律条文与 LLM 响应之间的相似度，直观地展示了它们之间的关联，为用户提供了响应的直观法律依据。此外，ELLA
    根据用户的查询检索相关法律条文并显示给用户。用户可以互动地选择法律条文，使 LLM 生成更准确的响应。ELLA 还检索相关法律案件供用户参考。我们的用户研究表明，展示法律依据有助于用户更好地理解。当用户参与选择法律条文时，LLM
    的响应准确性也会提高。提供相关法律案件也帮助个人获取全面信息。我们的 GitHub 仓库是：[https://github.com/Huyt00/ELLA](https://github.com/Huyt00/ELLA)¹¹1
    视频演示请见：[https://youtu.be/V8iaIXSJ2i8](https://youtu.be/V8iaIXSJ2i8)。
- en: 1 Introduction
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 介绍
- en: Large Language Models (LLMs), such as LLAMA Touvron et al. ([2023](#bib.bib16)),
    ChatGLM Zeng et al. ([2023](#bib.bib21)) and GPT4 OpenAI et al. ([2024](#bib.bib12)),
    have shown impressive performance in various tasks, showing great potential for
    specific domains, such as law Lai et al. ([2023](#bib.bib6)) and finance Wu et al.
    ([2023](#bib.bib17)); Yang et al. ([2023](#bib.bib19)). In the legal domain, many
    attempts have been madeColombo et al. ([2024](#bib.bib1)); Huang et al. ([2023](#bib.bib4));
    Yue et al. ([2023](#bib.bib20)); Nguyen ([2023](#bib.bib11)); Cui et al. ([2023](#bib.bib2)),
    which acquire legal knowledge through continual training and performing a supervised
    fine-tuning stage with a large-scale legal dataset. These models can offer various
    services including legal consultations, explaining legal terminology, analyzing
    legal cases, and preparing legal documents.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs），如 LLAMA Touvron 等人 ([2023](#bib.bib16))，ChatGLM Zeng 等人 ([2023](#bib.bib21))
    和 GPT4 OpenAI 等人 ([2024](#bib.bib12))，在各种任务中表现出色，显示了在特定领域的巨大潜力，例如法律 Lai 等人 ([2023](#bib.bib6))
    和金融 Wu 等人 ([2023](#bib.bib17))；Yang 等人 ([2023](#bib.bib19))。在法律领域，许多尝试已被提出 Colombo
    等人 ([2024](#bib.bib1))；Huang 等人 ([2023](#bib.bib4))；Yue 等人 ([2023](#bib.bib20))；Nguyen
    ([2023](#bib.bib11))；Cui 等人 ([2023](#bib.bib2))，这些模型通过持续训练和在大规模法律数据集上进行监督微调来获取法律知识。这些模型可以提供各种服务，包括法律咨询、解释法律术语、分析法律案件和准备法律文档。
- en: Despite the remarkable performance of LLMs within the legal domain, they are
    not exempt from the occurrence of hallucination Ji et al. ([2023](#bib.bib5)).
    To alleviate this, previous studies Huang et al. ([2023](#bib.bib4)); Yue et al.
    ([2023](#bib.bib20)); Cui et al. ([2023](#bib.bib2)) have proposed retrieval-augmented
    generation(RAG) Lewis et al. ([2021](#bib.bib7)) frameworks to retrieve legal
    articles from an external datastore. By leveraging retrieved legal articles, hallucination
    is reduced and LLMs can generate more faithful answers.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管LLMs在法律领域表现卓越，但它们并不免受幻觉的发生，Ji等人（[2023](#bib.bib5)）。为了缓解这一问题，以前的研究Huang等人（[2023](#bib.bib4)）；Yue等人（[2023](#bib.bib20)）；Cui等人（[2023](#bib.bib2)）提出了检索增强生成（RAG）Lewis等人（[2021](#bib.bib7)）框架，以从外部数据存储库中检索法律条文。通过利用检索到的法律条文，可以减少幻觉，LLMs能够生成更为准确的回答。
- en: '![Refer to caption](img/3e81eb27acde3f45d4e8f42b2c231dca.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/3e81eb27acde3f45d4e8f42b2c231dca.png)'
- en: 'Figure 1: Examples of incomplete, incorrect, inconsistent Response. $A_{i}$
    indicates the $i_{th}$ article in Civil Code. Blue articles mean they are relevant
    to the query, while orange ones are irrelevant. The blue star means the article
    is retrieved for LLM. We only show the key information in the Figure. For the
    complete conversations, please refer to Appendix [B](#A2 "Appendix B Consultation
    Examples ‣ ELLA: Empowering LLMs for Interpretable, Accurate and Informative Legal
    Advice")'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：不完整、不正确、不一致的回应示例。$A_{i}$表示《民法典》中第$i_{th}$条。蓝色条文表示它们与查询相关，而橙色条文则不相关。蓝色星星表示该条文已被检索用于LLMs。图中仅展示了关键信息。有关完整对话，请参考附录 [B](#A2
    "附录 B 咨询示例 ‣ ELLA：赋能LLMs提供可解释、准确和信息丰富的法律建议")
- en: In the legal domain, LLMs’ responses are required to have high accuracy and
    be supported by reasonable legal bases. Therefore, the retrieval component plays
    an important role as it provides correct and related legal articles for LLMs.
    While LLMs could be augmented with retrieved legal articles to generate faithful
    responses, when irrelevant ones are retrieved, they inevitably bring noise to
    LLMs, leading LLMs to produce responses with incomplete, incorrect or inconsistent
    information.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在法律领域，LLMs的响应需要具有高准确性，并且要有合理的法律依据。因此，检索组件扮演了重要角色，因为它为LLMs提供了正确且相关的法律条文。虽然LLMs可以通过检索到的法律条文来生成真实的回答，但当检索到的条文不相关时，它们不可避免地会为LLMs带来噪声，导致LLMs生成包含不完整、不正确或不一致信息的回应。
- en: 'For instance, as shown in Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ ELLA:
    Empowering LLMs for Interpretable, Accurate and Informative Legal Advice"), when
    a user asks $Q_{1}$, the legal article retrieval model retrieves articles 1098,
    1101, and 1105 of the Civil Code ²²2[https://www.gov.cn/xinwen/2020-06/01/content_5516649.htm](https://www.gov.cn/xinwen/2020-06/01/content_5516649.htm)
    according to the query, while fails to retrieve another three relevant ones: article
    1100, 1102 and 1093 of the Civil Code. Therefore, LLM only suggests that adopters
    need to meet the conditions $c_{1},c_{2}$ and $c_{3}$ mentioned in the retrieved
    legal articles, resulting in incomplete suggestions. Then the user continues to
    ask $Q_{2}$. Although the related article is retrieved, the irrelevant ones are
    also retrieved. Such irrelevant articles bring noise to LLM, leading to the incorrect
    response $R_{2}$(In fact, the case mentioned in $Q_{2}$ should not be considered
    as automatic divorce). Besides, LLMs may be sensible to the input perturbation Zhu
    et al. ([2023](#bib.bib22)); Dong et al. ([2023](#bib.bib3)). Responses can be
    contradictory when inputs only differ slightly. For example, when the user begins
    a new chat and asks $Q_{3}$, which is identical to $Q_{2}$, the response $R_{3}$
    is contradictory to $R_{2}$. This inconsistency can potentially bring confusion
    to users, resulting in a lower-quality consultation.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '例如，如图[1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ ELLA: Empowering LLMs for Interpretable,
    Accurate and Informative Legal Advice")所示，当用户提出$Q_{1}$时，法律条款检索模型根据查询检索到《民法典》第1098、1101和1105条²²2[https://www.gov.cn/xinwen/2020-06/01/content_5516649.htm](https://www.gov.cn/xinwen/2020-06/01/content_5516649.htm)，但未能检索到另外三个相关条款：第1100、1102和1093条。因此，LLM仅建议采用者需要满足检索到的法律条款中提到的条件$c_{1},c_{2}$和$c_{3}$，导致建议不完整。然后，用户继续提出$Q_{2}$。尽管相关条款被检索到，但也检索到了无关的条款。这些无关条款对LLM造成噪音，导致不正确的回答$R_{2}$（实际上，$Q_{2}$中提到的案例不应视为自动离婚）。此外，LLMs可能对输入扰动敏感 Zhu
    et al. ([2023](#bib.bib22)); Dong et al. ([2023](#bib.bib3))。当输入仅有微小差异时，回答可能会出现矛盾。例如，当用户开始新的聊天并提出与$Q_{2}$相同的$Q_{3}$时，回答$R_{3}$与$R_{2}$相矛盾。这种不一致可能会给用户带来困惑，导致咨询质量下降。'
- en: When LLMs fail to produce coherent and complete responses, relevant legal cases
    can offer users more in-depth reference information Su et al. ([2024](#bib.bib15)).
    However, a legal case retrieval module has rarely been integrated into the existing
    legal domain LLMs in civil law systems. Additionally, legal terminology may sometimes
    be embedded in the responses lacking sufficient explanations, posing potential
    understanding difficulties for users without domain knowledge Savelka et al. ([2023](#bib.bib14)).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 当LLMs未能生成连贯且完整的回答时，相关的法律案例可以为用户提供更深入的参考信息 Su et al. ([2024](#bib.bib15))。然而，法律案例检索模块很少被集成到现有的民法体系中的法律领域LLMs中。此外，法律术语有时可能嵌入在缺乏充分解释的回答中，对没有领域知识的用户构成理解困难 Savelka
    et al. ([2023](#bib.bib14))。
- en: To address the issues mentioned above, we propose ELLA, a tool Empowering LLMs
    for interpretable, accurate, and informative Legal Advice.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决上述问题，我们提出了ELLA，一个为LLMs提供可解释、准确和信息丰富法律建议的工具。
- en: Firstly, we fine-tune BGE Xiao et al. ([2023](#bib.bib18)), an embedding model
    for retrieval, to retrieve the legal basis for each sentence in the response.
    By visually presenting the legal basis to users, users can trust the advice provided
    by LLMs. When there is no legal basis for a sentence, it can be viewed as a warning
    that the sentence may be incorrect. Secondly, ELLA retrieves several legal articles
    based on the user’s query and presents them to users. Users can interactively
    select the relevant legal articles for LLMs to generate accurate and complete
    responses while disregarding irrelevant ones to avoid noise. Thirdly, we incorporate
    a legal case retrieval model in ELLA, intending to present supplementary information
    for users to reference. Considering the long context in legal cases, we find all
    the key sentences in the article through similarity matching between the query
    and each sentence in the legal case. We highlight all key sentences in the legal
    cases for users to improve their reading efficiency.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们对BGE Xiao et al. ([2023](#bib.bib18))进行微调，这是一种用于检索的嵌入模型，以检索响应中每句话的法律依据。通过将法律依据可视化呈现给用户，用户可以信任LLM提供的建议。当一句话没有法律依据时，可以视作该句可能不准确的警告。其次，ELLA根据用户的查询检索若干法律条款并呈现给用户。用户可以互动地选择相关法律条款，以便LLM生成准确完整的响应，同时忽略无关条款以避免噪音。第三，我们在ELLA中整合了法律案例检索模型，旨在为用户提供补充信息供参考。考虑到法律案件中的长篇背景，我们通过查询与法律案例中每句话的相似性匹配，找到文章中的所有关键句。我们突出显示法律案例中的所有关键句，以提高用户的阅读效率。
- en: The response interpretation aids users in understanding and placing trust in
    the advice given by LLMs. The user study shows that our model can generate more
    accurate responses when users interactively select relevant legal articles. The
    legal case retrieval module also offers users more resourceful reference information.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 响应解释帮助用户理解和信任LLM提供的建议。用户研究显示，当用户互动选择相关法律条款时，我们的模型可以生成更准确的响应。法律案例检索模块还为用户提供了更多资源丰富的参考信息。
- en: 2 Framework and Usage Example
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 框架与使用示例
- en: 'ELLA is composed of four parts: 1) Chat Interface: visually displays the conversation
    between the user and the LLM. 2) Interactive Legal Article Selection: Provides
    retrieved legal articles for users to choose from, letting the LLM generate new
    responses based on the user’s selected legal articles. 3) Response Interpretation:
    Provides legal article and judicial interpretations to interpret each sentence
    of the LLM’s response. 4) Legal Case Retrieval: Displays relevant legal cases
    for the user to refer to.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ELLA由四部分组成：1）聊天界面：直观展示用户与LLM之间的对话。2）互动法律条款选择：提供检索到的法律条款供用户选择，让LLM根据用户选择的法律条款生成新的响应。3）响应解释：提供法律条款和司法解释来解读LLM响应中的每一句话。4）法律案例检索：展示相关的法律案例供用户参考。
- en: '![Refer to caption](img/4facae366fa8987e82c6311f2da2f776.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/4facae366fa8987e82c6311f2da2f776.png)'
- en: 'Figure 2: Screenshot of ELLA. We show the complete conversation in Appendix [B](#A2
    "Appendix B Consultation Examples ‣ ELLA: Empowering LLMs for Interpretable, Accurate
    and Informative Legal Advice"), Table [2](#A2.T2 "Table 2 ‣ Appendix B Consultation
    Examples ‣ ELLA: Empowering LLMs for Interpretable, Accurate and Informative Legal
    Advice") and Table [5](#A2.T5 "Table 5 ‣ Appendix B Consultation Examples ‣ ELLA:
    Empowering LLMs for Interpretable, Accurate and Informative Legal Advice").'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '图2：ELLA的截图。我们在附录[B](#A2 "Appendix B Consultation Examples ‣ ELLA: Empowering
    LLMs for Interpretable, Accurate and Informative Legal Advice")、表[2](#A2.T2 "Table
    2 ‣ Appendix B Consultation Examples ‣ ELLA: Empowering LLMs for Interpretable,
    Accurate and Informative Legal Advice")和表[5](#A2.T5 "Table 5 ‣ Appendix B Consultation
    Examples ‣ ELLA: Empowering LLMs for Interpretable, Accurate and Informative Legal
    Advice")中展示了完整的对话。'
- en: 2.1 Chat Interface
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 聊天界面
- en: 'Our chat interface is shown in Figure [2](#S2.F2 "Figure 2 ‣ 2 Framework and
    Usage Example ‣ ELLA: Empowering LLMs for Interpretable, Accurate and Informative
    Legal Advice"), part 1\. After clicking the input button, the chat box above will
    display user input and the LLM’s response. Users can have multiple rounds of chats,
    or click ’new conversation’ on the upper left to start a new consultation. The
    column on the left retains all conversations. Users can click on each chat button
    to view the corresponding chat content.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '我们的聊天界面如图[2](#S2.F2 "Figure 2 ‣ 2 Framework and Usage Example ‣ ELLA: Empowering
    LLMs for Interpretable, Accurate and Informative Legal Advice")所示，第1部分。点击输入按钮后，上方的聊天框将显示用户输入和LLM的响应。用户可以进行多轮对话，或点击左上角的‘新对话’以开始新的咨询。左侧的栏目保留了所有对话。用户可以点击每个聊天按钮查看相应的聊天内容。'
- en: 2.2 Interactive Legal Article Selection
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 交互式法律条文选择
- en: Legal article retrieval model plays an important part in Chinese legal domain
    LLMs Huang et al. ([2023](#bib.bib4)); Yue et al. ([2023](#bib.bib20)). Lawyer
    LLaMA Huang et al. ([2023](#bib.bib4)) mentions that when LLMs are provided with
    external relevant legal articles, they can generate more reliable responses. However,
    the current legal article retrieval models cannot ensure to retrieval all the
    relevant legal articles and leave out all irrelevant ones. Missed articles might
    reduce the completeness of the model’s response, while irrelevant articles bring
    noise to LLM, leading LLMs to generate irrelevant advice.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 法律条文检索模型在中国法律领域的LLM中扮演着重要角色，Huang 等人（[2023](#bib.bib4)）；Yue 等人（[2023](#bib.bib20)）。律师
    LLaMA Huang 等人（[2023](#bib.bib4)）提到，当LLM提供了相关的外部法律条文时，它们可以生成更可靠的回应。然而，目前的法律条文检索模型无法确保检索到所有相关的法律条文，并排除所有不相关的条文。遗漏的条文可能会减少模型响应的完整性，而不相关的条文则会给LLM带来噪音，导致LLM生成无关的建议。
- en: To solve this problem, ELLA allows users to interactively select legal articles.
    We display the top $K_{1}=10$ relevant legal articles retrieved for the users.
    Users can select relevant legal articles based on their situations. The LLM will
    then generate responses based on the legal articles selected by the user. Note
    that the LLM generates its first response based on the top 3 retrieved articles
    by default. Subsequently, users can select legal articles for LLM to regenerate
    new responses multiple times.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，ELLA允许用户交互式地选择法律条文。我们为用户展示检索到的前$K_{1}=10$个相关法律条文。用户可以根据他们的情况选择相关的法律条文。LLM将基于用户选择的法律条文生成响应。请注意，LLM默认基于前3个检索到的条文生成其第一次响应。随后，用户可以多次选择法律条文以便LLM重新生成新响应。
- en: 'Back to the example in Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ ELLA:
    Empowering LLMs for Interpretable, Accurate and Informative Legal Advice"), we
    find that several relevant legal articles are not selected for LLM. Then we can
    select them, as shown in Figure [2](#S2.F2 "Figure 2 ‣ 2 Framework and Usage Example
    ‣ ELLA: Empowering LLMs for Interpretable, Accurate and Informative Legal Advice"),
    part 2, and click the "Regenerate" button at the bottom of the page. Then LLM
    generates a new response with complete information. By allowing users to participate
    in the legal article retrieval, it increases the consistency between the user’s
    situation and the referred legal articles used by the LLM, thus enabling the LLM
    to generate more complete and accurate responses.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '回到图示[1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ ELLA: Empowering LLMs for Interpretable,
    Accurate and Informative Legal Advice")中的示例，我们发现LLM没有选择到几个相关的法律条文。然后我们可以选择它们，如图[2](#S2.F2
    "Figure 2 ‣ 2 Framework and Usage Example ‣ ELLA: Empowering LLMs for Interpretable,
    Accurate and Informative Legal Advice")第2部分所示，并点击页面底部的“重新生成”按钮。然后LLM会生成一个包含完整信息的新响应。通过允许用户参与法律条文检索，可以提高用户情况与LLM所使用的参考法律条文之间的一致性，从而使LLM能够生成更完整和准确的响应。'
- en: 2.3 Response Interpretation
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 响应解释
- en: The response interpretation module provides the legal article basis for each
    sentence in the LLM’s response, and helps users better understand the terminologies
    in the responses.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 响应解释模块提供了LLM响应中每句话的法律条文依据，并帮助用户更好地理解响应中的术语。
- en: LLM is sensitive to the inputs. Users may receive different advice when ask
    the same questions in different ways. To facilitate users to identify which response
    is more reliable, or whether a response is trustworthy, the response interpretation
    module presents the referred legal articles for each sentence in the response.
    Users can verify the reliability of the response by tracing the legal article
    basis of each sentence.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: LLM对输入非常敏感。用户可能在以不同方式提问时收到不同的建议。为了帮助用户识别哪种回应更可靠，或回应是否值得信赖，响应解释模块呈现了响应中每句话所引用的法律条文。用户可以通过追踪每句话的法律条文依据来验证响应的可靠性。
- en: At the same time, even though the LLM can conveniently provide legal advice
    to users, sometimes the responses may contain terminologies, which non-professional
    users may find hard to understand. Besides, some special cases lack a clear definition
    in the legal articles. They are both explicitly explained in China’s "judicial
    interpretations". To provide users with a better legal consultation experience,
    we use a response explanation module to provide a clear explanation of the terminology/special
    cases with corresponding judicial interpretation, making it easier for users to
    understand.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，虽然LLM可以方便地向用户提供法律建议，但有时回答可能包含术语，非专业用户可能难以理解。此外，一些特殊情况在法律条款中没有明确的定义。这些都在中国的“司法解释”中有明确说明。为了提供更好的法律咨询体验，我们使用响应解释模块对术语/特殊情况进行清晰解释，并提供相应的司法解释，使用户更易于理解。
- en: 'As shown in Figure [2](#S2.F2 "Figure 2 ‣ 2 Framework and Usage Example ‣ ELLA:
    Empowering LLMs for Interpretable, Accurate and Informative Legal Advice"), part
    3, when the user ask "My girlfriend is married…Would living with her without being
    legally married be considered bigamy?", the response is "…The situation you mentioned
    is cohabitation rather than bigamy…cohabitation is not illegal…". To check the
    definition of "cohabitation", the user can hover the mouse over the sentence.
    Then the platform will display a hovering box, showing the corresponding judicial
    interpretation. We show the legal article basis for the sentence in the same way.
    If there is neither a legal article basis nor a judicial interpretation for the
    sentence, the hovering box will not display.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '如图[2](#S2.F2 "Figure 2 ‣ 2 Framework and Usage Example ‣ ELLA: Empowering LLMs
    for Interpretable, Accurate and Informative Legal Advice")第3部分所示，当用户询问“我的女朋友已婚……与她同居而没有合法婚姻会被视为重婚吗？”，回答是“……您提到的情况是同居，而不是重婚……同居并不违法……”。要查看“同居”的定义，用户可以将鼠标悬停在句子上。然后，平台将显示一个悬浮框，展示相应的司法解释。我们以相同的方式展示句子的法律条款依据。如果句子没有法律条款依据或司法解释，悬浮框将不会显示。'
- en: 2.4 Legal Case Retrieval
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 法律案件检索
- en: 'Legal cases also serve as important references for users when they consult
    on legal issues and make judgments about their circumstances. Currently, Chinese
    legal domain LLMs can only make decisions for users based on internal legal knowledge
    and externally retrieved legal articles, unable to provide relevant legal cases
    for users as reference. Therefore, we introduced a legal case retrieval module
    in ELLA. For every query from users, we search relevant legal cases obtained from
    China Judgements Online ³³3[https://wenshu.court.gov.cn](https://wenshu.court.gov.cn)
    and display them on the platform for users, as shown in Figure [2](#S2.F2 "Figure
    2 ‣ 2 Framework and Usage Example ‣ ELLA: Empowering LLMs for Interpretable, Accurate
    and Informative Legal Advice"), part 4\. As the context of the legal cases may
    be long, we highlight the sentences in the trial proceeding records related to
    the user’s query. Users can directly locate these sentences to get key information.
    We provide multiple relevant legal cases. Users can click the button at the top
    of part 4 to view different legal cases.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '法律案件也作为用户咨询法律问题并对其情况做出判断的重要参考。目前，中国法律领域的LLM只能根据内部法律知识和外部检索的法律条款为用户做出决定，无法为用户提供相关的法律案件作为参考。因此，我们在ELLA中引入了法律案件检索模块。对于每个用户查询，我们从中国裁判文书网³³3[https://wenshu.court.gov.cn](https://wenshu.court.gov.cn)中检索相关法律案件，并在平台上展示，如图[2](#S2.F2
    "Figure 2 ‣ 2 Framework and Usage Example ‣ ELLA: Empowering LLMs for Interpretable,
    Accurate and Informative Legal Advice")第4部分所示。由于法律案件的背景可能较长，我们突出显示与用户查询相关的审判记录中的句子。用户可以直接定位这些句子以获取关键信息。我们提供多个相关法律案件。用户可以点击第4部分顶部的按钮查看不同的法律案件。'
- en: 3 System Overview
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 系统概述
- en: '![Refer to caption](img/70afaf6fa5aba2fa6df0e0d172516b22.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/70afaf6fa5aba2fa6df0e0d172516b22.png)'
- en: 'Figure 3: The system architecture overview.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：系统架构概述。
- en: In this section, we detail the implementation of all back-end models of ELLA.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们详细介绍了ELLA所有后端模型的实现。
- en: 3.1 Legal Consultation
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 法律咨询
- en: In our work, we use Lawyer LLaMA Huang et al. ([2023](#bib.bib4)), a LLM adapted
    to the legal domain, for legal consultation. Based on Lawyer LLaMA, which focuses
    on answering queries about marriage, ELLA mainly provides marriage consultation
    services for users. Since our back-end model is pluggable, we can also replace
    Lawyer LLaMA with other legal domain LLMs, such as DISC-LawLLM Yue et al. ([2023](#bib.bib20)),
    ChatLaw Cui et al. ([2023](#bib.bib2)) or LawGPT Nguyen ([2023](#bib.bib11)).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的工作中，我们使用律师LLaMA Huang等人（[2023](#bib.bib4)），一个适应法律领域的LLM，用于法律咨询。基于专注于回答婚姻问题的律师LLaMA，ELLA主要为用户提供婚姻咨询服务。由于我们的后端模型是可插拔的，我们还可以用其他法律领域的LLM替换律师LLaMA，如DISC-LawLLM
    Yue等人（[2023](#bib.bib20)）、ChatLaw Cui等人（[2023](#bib.bib2)）或LawGPT Nguyen（[2023](#bib.bib11)）。
- en: 3.2 Legal Article Retrieval
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 法律条文检索
- en: We use the legal article retrieval model provided by Lawyer LLaMA. Following
    Lawyer LLaMA, after the user inputs a query, we retrieve the relevant legal articles,
    and append the top 3 legal articles to the user’s query to generate the response.
    Besides, we display the top $K_{1}=10$ retrieved legal articles on the front end.
    If the user selects some relevant legal articles and requires a new response,
    in the back end, we append all selected legal articles to the input prompt, and
    LLM will generate a new response.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用律师LLaMA提供的法律条文检索模型。按照律师LLaMA的流程，在用户输入查询后，我们检索相关法律条文，并将前三篇法律条文附加到用户的查询中以生成响应。此外，我们在前端显示了前$K_{1}=10$篇检索到的法律条文。如果用户选择了一些相关的法律条文并要求新的响应，在后端，我们将所有选定的法律条文附加到输入提示中，LLM将生成新的响应。
- en: 3.3 Response Interpretation
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 响应解释
- en: The response interpretation module aims to provide the legal article basis and
    judicial interpretations for each sentence of the response from the LLM. Here,
    we use BGE Xiao et al. ([2023](#bib.bib18)), a state-of-the-art embedding model
    for retrieval augmented generation. Since BGE has only been pre-trained on the
    general corpus, it lacks knowledge about the legal domain, thus being unable to
    distinguish between two terminologies that are semantically similar but have different
    definitions in the legal domain. Therefore, we need to fine-tune BGE with legal
    corpus to make it learn legal knowledge.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 响应解释模块旨在为LLM的每个响应句子提供法律条文依据和司法解释。在这里，我们使用BGE Xiao等人（[2023](#bib.bib18)），一种最先进的嵌入模型，用于检索增强生成。由于BGE仅在通用语料库上进行了预训练，它缺乏法律领域的知识，因此无法区分在法律领域中语义相似但定义不同的两个术语。因此，我们需要用法律语料库对BGE进行微调，以使其学习法律知识。
- en: 'Due to the lack of training data, we construct a dataset for response interpretation.
    We sample 2k queries from the legal instruction tuning data published by Lawyer
    LLaMA. For each query $q$, we obtain the top 3 relevant articles $[a_{1},a_{2},a_{3}]$
    with the legal article retrieval module, and append these three laws individually
    to $q_{i}$. Then Lawyer LLaMA generates different responses $[r_{1},r_{2},r_{3}]$
    based on the different legal articles. For $r_{i}=[s_{i1},s_{i2},...,s_{in}]$,
    we calculated the similarity between each sentence $s_{ij},j\in[1,n]$ and $a_{i}$
    using BM25 Robertson and Zaragoza ([2009](#bib.bib13)). As illustrated in Figure [4](#A1.F4
    "Figure 4 ‣ Appendix A Dataset Construction ‣ ELLA: Empowering LLMs for Interpretable,
    Accurate and Informative Legal Advice"), we treat the sentence with the highest
    BM25 score $s_{ik}$ and gold article $a_{i}$ as the positive case $(s_{ik},a_{i})$,
    while the two most irrelevant sentences $s_{ix}$, $s_{iy}$ as negative cases $(s_{ix},a_{i})$
    and $(s_{iy},a_{i})$. We also created negative cases $(s_{ik},a_{t}),t\in[1,2,3]$
    and $t\neq i$ for distinguishing relevant sentence in $r_{i}$ from other retrieved
    legal articles.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 由于训练数据的缺乏，我们构建了一个响应解释数据集。我们从律师LLaMA发布的法律指令调整数据中抽取了2k个查询。对于每个查询$q$，我们使用法律条文检索模块获得与之相关的前三篇文章$[a_{1},a_{2},a_{3}]$，并将这三篇法律分别附加到$q_{i}$上。然后，律师LLaMA根据不同的法律条文生成不同的响应$[r_{1},r_{2},r_{3}]$。对于$r_{i}=[s_{i1},s_{i2},...,s_{in}]$，我们使用BM25
    Robertson和Zaragoza（[2009](#bib.bib13)）计算每句$s_{ij},j\in[1,n]$与$a_{i}$之间的相似性。如图[4](#A1.F4
    "图 4 ‣ 附录 A 数据集构建 ‣ ELLA：赋能LLM以提供可解释、准确和信息丰富的法律咨询")所示，我们将BM25分数最高的句子$s_{ik}$和金标准条文$a_{i}$视为正例$(s_{ik},a_{i})$，而将两个最无关的句子$s_{ix}$、$s_{iy}$视为负例$(s_{ix},a_{i})$和$(s_{iy},a_{i})$。我们还创建了负例$(s_{ik},a_{t}),t\in[1,2,3]$且$t\neq
    i$，以区分$r_{i}$中的相关句子与其他检索到的法律条文。
- en: Given the similar language style and content between legal articles and judicial
    interpretations, and the fact that legal articles contain all the terminologies
    involved in judicial interpretations, we only used legal articles to construct
    the dataset. After fine-tuning the BGE on this dataset, we obtained a new model,
    which we denote as $BGE_{1}$ here.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于法律条款和司法解释之间语言风格和内容的相似性，以及法律条款包含所有司法解释中的术语，我们仅使用法律条款来构建数据集。在对该数据集进行BGE微调后，我们获得了一个新模型，我们在这里称之为$BGE_{1}$。
- en: During inference, we use BGE[1] to calculate the cosine similarity between the
    embedding of each sentence in the response and the legal articles and judicial
    interpretations. If the similarity exceeds a threshold $Thr_{1}$, we think the
    corresponding legal article or judicial interpretation can explain the sentence.
    $Thr_{1}$ is a hyper-parameter, which we set as 0.85 in our work. Then, we return
    the articles and judicial interpretations referenced by each sentence to the front
    end, to help users better understand the LLM’s responses.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在推理过程中，我们使用BGE[1]计算响应中每个句子的嵌入与法律条款和司法解释之间的余弦相似度。如果相似度超过阈值$Thr_{1}$，我们认为相应的法律条款或司法解释可以解释该句子。$Thr_{1}$是一个超参数，我们在工作中将其设置为0.85。然后，我们将每个句子参考的条款和司法解释返回到前端，以帮助用户更好地理解LLM的响应。
- en: 3.4 Legal Case Retrieval
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 法律案例检索
- en: In this module, we first retrieve relevant legal cases based on the user’s input.
    Then we find all the key sentences in the legal case that are related to the consultation
    query. Finally, we re-rank the top $K_{2}$ retrieved legal cases according to
    the number of relevant sentences in the legal case, and return the top $K_{3}$
    re-ranked legal cases to the front end.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在此模块中，我们首先根据用户的输入检索相关法律案例。然后，我们找到所有与咨询查询相关的法律案例中的关键句子。最后，我们根据法律案例中的相关句子数量对前$K_{2}$个检索到的法律案例进行重新排序，并将前$K_{3}$个重新排序的法律案例返回到前端。
- en: Legal Case Retrieval. Similarly, due to the lack of relevant legal domain knowledge
    in BGE, we need to fine-tune BGE with the legal domain corpus. Here, we use the
    dataset LeCaRD Ma et al. ([2021](#bib.bib9)), a publicly available Chinese legal
    case retrieval dataset. We allocated 80% of LeCaRD as the training set and 10%
    each as the validation and test set. We fine-tune BGE on the training set. Here
    we denoted the fine-tuned BGE as BGE[2]. When the user inputs a query, we use
    BGE[2] to retrieve relevant legal cases.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 法律案例检索。由于BGE缺乏相关的法律领域知识，我们需要用法律领域语料库对BGE进行微调。这里，我们使用数据集LeCaRD Ma et al. ([2021](#bib.bib9))，这是一个公开的中文法律案例检索数据集。我们将LeCaRD的80%分配为训练集，将10%分别分配为验证集和测试集。我们在训练集上对BGE进行微调。这里我们将微调后的BGE称为BGE[2]。当用户输入查询时，我们使用BGE[2]检索相关法律案例。
- en: Relevant Sentence Highlight. We use BGE[2] to calculate the similarity between
    the user’s query and each sentence in the legal case. When the cosine similarity
    score is larger than $Thr_{2}$, we consider this sentence to be related to the
    user’s query, thus this sentence can serve as a reason for this case being a relevant
    legal case. $Thr_{2}$ is a hyper-parameter, which we set to 0.65 in our work.
    We highlight all relevant sentences in the case for users, helping them quickly
    locate the parts of the case that are highly related to their query. In this way,
    users can quickly judge whether this legal case is relevant and helpful, and they
    can also quickly obtain important information that they care about.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 相关句子高亮。我们使用BGE[2]计算用户查询与法律案例中每个句子之间的相似度。当余弦相似度分数大于$Thr_{2}$时，我们认为该句子与用户的查询相关，因此这个句子可以作为该案例为相关法律案例的理由。$Thr_{2}$是一个超参数，我们在工作中将其设置为0.65。我们为用户高亮显示所有相关句子，帮助他们快速找到与查询高度相关的案例部分。这样，用户可以快速判断该法律案例是否相关且有帮助，同时还能迅速获得他们关心的重要信息。
- en: Legal Case Re-rank. We think that the more relevant sentences in a case, the
    larger the possibility of the case being a relevant legal case. Therefore, we
    re-rank the top $K_{2}$ legal cases retrieved by BGE[2] according to the number
    of relevant sentences, and return the re-ranked top $K_{3}$ legal cases to the
    front end. We set $K_{2}=50$ and $K_{3}=15$ in our work.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 法律案例重新排序。我们认为一个案例中相关句子越多，该案例成为相关法律案例的可能性越大。因此，我们根据相关句子的数量对BGE[2]检索到的前$K_{2}$个法律案例进行重新排序，并将重新排序后的前$K_{3}$个法律案例返回到前端。在我们的工作中，我们将$K_{2}=50$和$K_{3}=15$。
- en: 4 Evaluation
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 评估
- en: In this section, we automatically evaluate our case retrieval model. We also
    conduct a user study to evaluate whether ELLA helps users obtain more accurate,
    interpretable and informative information during the consultation.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们自动评估了我们的案例检索模型。我们还进行了用户研究，以评估 ELLA 是否有助于用户在咨询过程中获取更准确、可解释和信息量更大的信息。
- en: 4.1 Automatical Evaluation
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 自动评估
- en: '| Model | NDCG@10 | NDCG@20 | NDCG@30 |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | NDCG@10 | NDCG@20 | NDCG@30 |'
- en: '| BM25 | 53.51 | 55.81 | 58.03 |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| BM25 | 53.51 | 55.81 | 58.03 |'
- en: '| BGE | 66.57 | 67.13 | 71.91 |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| BGE | 66.57 | 67.13 | 71.91 |'
- en: '| BGE[2] | 76.34 | 77.84 | 78.29 |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| BGE[2] | 76.34 | 77.84 | 78.29 |'
- en: '| CaseEncoder Ma et al. ([2023](#bib.bib10)) | 78.5 | 80.3 | 83.9 |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| CaseEncoder Ma 等 ([2023](#bib.bib10)) | 78.5 | 80.3 | 83.9 |'
- en: '| SAILER Li et al. ([2023](#bib.bib8)) | 79.79 | 82.26 | 84.85 |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| SAILER Li 等 ([2023](#bib.bib8)) | 79.79 | 82.26 | 84.85 |'
- en: '| CaseFormer Su et al. ([2024](#bib.bib15)) | 83.45 | 83.57 | 83.94 |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| CaseFormer Su 等 ([2024](#bib.bib15)) | 83.45 | 83.57 | 83.94 |'
- en: 'Table 1: Results of Legal Case Retrieval Model.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：法律案件检索模型的结果。
- en: 'As we mentioned in Section [3.4](#S3.SS4 "3.4 Legal Case Retrieval ‣ 3 System
    Overview ‣ ELLA: Empowering LLMs for Interpretable, Accurate and Informative Legal
    Advice"), we split LeCaRD into 80% for training, 10% for validation and 10% for
    testing. Here, we use the LeCaRD test set to evaluate our legal case retrieval
    model, BGE[2]. Following CaseEncoder Ma et al. ([2023](#bib.bib10)), we use the
    Normalize Discounted Cumulative Gain (NDCG) metric as the evaluation metric. The
    experimental results are shown in Table [1](#S4.T1 "Table 1 ‣ 4.1 Automatical
    Evaluation ‣ 4 Evaluation ‣ ELLA: Empowering LLMs for Interpretable, Accurate
    and Informative Legal Advice").'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在第[3.4](#S3.SS4 "3.4 法律案件检索 ‣ 3 系统概述 ‣ ELLA：赋能大型语言模型以提供可解释、准确和信息丰富的法律建议")节中提到的，我们将
    LeCaRD 数据集分为 80% 用于训练，10% 用于验证和 10% 用于测试。在这里，我们使用 LeCaRD 测试集来评估我们的法律案件检索模型 BGE[2]。遵循
    CaseEncoder Ma 等 ([2023](#bib.bib10))的方法，我们使用归一化折扣累积增益（NDCG）指标作为评估指标。实验结果如表[1](#S4.T1
    "表 1 ‣ 4.1 自动评估 ‣ 4 评估 ‣ ELLA：赋能大型语言模型以提供可解释、准确和信息丰富的法律建议")所示。
- en: 'Compared with BM25 and BGE which has not been fine-tuned, BGE[2] shows a significant
    increase in each NDCG@K. This shows that the fine-tuned BGE can learn legal knowledge
    well, and better distinguish legal cases that are semantically similar but not
    relevant in the legal domain. Although CaseEncoder Ma et al. ([2023](#bib.bib10)),
    SAILER Li et al. ([2023](#bib.bib8)) and CaseFormer Su et al. ([2024](#bib.bib15))
    outperform BGE[2], we use BGE[2] since it can serve as an embedding model for
    relevant sentences similarity matching mentioned in Section [3.4](#S3.SS4 "3.4
    Legal Case Retrieval ‣ 3 System Overview ‣ ELLA: Empowering LLMs for Interpretable,
    Accurate and Informative Legal Advice"). Note that our legal case retrieval model
    is pluggable, so we can also additionally add SOTA models mentioned above for
    legal case retrieval.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 与未经过微调的 BM25 和 BGE 相比，经过微调的 BGE[2] 在每个 NDCG@K 指标上都有显著提升。这表明，经过微调的 BGE 能够很好地学习法律知识，并且能更好地区分法律领域中语义相似但不相关的法律案件。尽管
    CaseEncoder Ma 等 ([2023](#bib.bib10))、SAILER Li 等 ([2023](#bib.bib8)) 和 CaseFormer
    Su 等 ([2024](#bib.bib15)) 超越了 BGE[2]，我们还是选择 BGE[2]，因为它可以作为第[3.4](#S3.SS4 "3.4
    法律案件检索 ‣ 3 系统概述 ‣ ELLA：赋能大型语言模型以提供可解释、准确和信息丰富的法律建议")节中提到的相关句子相似度匹配的嵌入模型。请注意，我们的法律案件检索模型是可插拔的，因此我们也可以额外添加上述提到的
    SOTA 模型用于法律案件检索。
- en: 4.2 User Study
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 用户研究
- en: 4.2.1 Study Design
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.1 研究设计
- en: We conduct a user study to validate whether ELLA can improve users’ legal consultation
    experience. Since LLMs deliver an impressive performance in answering simple questions,
    such as "Can I get married if I am younger than 20?", we randomly selected 20
    consultation queries about complex marriage situations for the user study. We
    invited 3 non-legal professional users and asked them to obtain solutions to these
    queries through ELLA. Users will evaluate whether the three modules in ELLA are
    helpful for their legal consultation.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了一项用户研究，以验证 ELLA 是否能改善用户的法律咨询体验。由于大型语言模型在回答简单问题（如“如果我不到 20 岁，可以结婚吗？”）方面表现出色，我们随机选择了
    20 个关于复杂婚姻情况的咨询查询进行用户研究。我们邀请了 3 位非法律专业用户，并要求他们通过 ELLA 获取这些查询的解决方案。用户将评估 ELLA 中的三个模块是否对他们的法律咨询有帮助。
- en: 4.2.2 Result
  id: totrans-77
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.2 结果
- en: Response Regeneration.
  id: totrans-78
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 响应生成。
- en: For an average of 83% of the queries, users find that the top 3 legal articles
    retrieved are not entirely correct, impeding LLM from directly generating correct
    responses based on these articles. For an estimated 20% of the queries, LLMs can
    not provide correct responses due to the noise brought by irrelevant legal articles,
    while for 25%, LLM’s responses are incomplete, as relevant legal articles were
    not among the initial top three results. Another 38% of responses contained irrelevant
    information resulting from the inclusion of unrelated legal articles within the
    top three results. However, in 80% cases, users can successfully receive correct
    responses by selecting relevant legal articles for LLM to regenerate responses.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 对于平均83%的查询，用户发现检索到的前3个法律条款并不完全正确，这妨碍了LLM基于这些条款直接生成正确的回答。在估计的20%查询中，由于无关法律条款带来的噪音，LLM无法提供正确的回答，而在25%的情况下，由于相关法律条款不在最初的前三个结果中，LLM的回答不完整。另有38%的回答包含了不相关的信息，这些信息源自前三个结果中包含的无关法律条款。然而，在80%的情况下，用户可以通过选择相关法律条款成功地让LLM生成正确的回答。
- en: Response Interpretation.
  id: totrans-80
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 回答解释。
- en: Users have reported that for approximately 95% of the queries, ELLA can accurately
    provide the legal article basis of the responses generated by the LLM. By cross-referencing
    the responses with the corresponding legal article, users can swiftly determine
    whether the responses are reliable or inaccurate. For instance, when a user asks,
    "I have never had children since I got married, and now I am planning to adopt
    a child from a relative. Can I adopt a child privately?" LLM responds "Adopters
    need to meet the following conditions…". ELLA justifies the response by citing
    Article 1098 of the Civil Code as its legal article basis. Additionally, it retrieves
    Article 1100 of the Civil Code, "A childless adopter may adopt two children…,"
    which the user can select for the LLM to generate a full response. Users also
    noted that, in about 73% of the queries, parts of the legal articles have already
    been included within the responses. However, LLM may not fully rephrase the entire
    article. By providing the legal articles basis, users can conveniently access
    to the complete information in the legal article.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 用户报告称，对于约95%的查询，ELLA可以准确地提供由LLM生成的回答的法律条款依据。通过将回答与对应的法律条款进行交叉检查，用户可以迅速判断这些回答是否可靠或不准确。例如，当用户问到，“自从结婚以来我从未有过孩子，现在我计划从亲戚那里收养一个孩子。我可以私人收养一个孩子吗？”LLM的回答是“收养者需要满足以下条件……”。ELLA通过引用《民法典》第1098条作为其法律条款依据来证明这一回答的合法性。此外，它检索了《民法典》第1100条，“无子女的收养者可以收养两个孩子……”，用户可以选择这一条款以便LLM生成完整的回答。用户还注意到，在约73%的查询中，回答中已经包含了一部分法律条款。然而，LLM可能不会完全重新表述整个条款。通过提供法律条款依据，用户可以方便地获取完整的法律条款信息。
- en: In all provided judicial interpretations, roughly 30% serve the purpose of clarifying
    specific legal terminologies or special cases. For instance, consider a scenario
    where a user inquires, "My husband and I have obtained a marriage certificate
    but have not cohabited. We are now filing for divorce and my husband wishes to
    return the bride price. Is this permissible?" In response, ELLA gives additional
    judicial interpretation that illuminates the conditions under which the return
    of the bride price is allowed. However, for the remaining 70%, users claim that
    they are already familiar with the content in the judicial interpretations, such
    as, "Support payments encompass children’s living expenses, education costs, medical
    bills and other expenditures." Generally speaking, users assert that judicial
    interpretations can assist them in acquiring a better comprehension of the responses
    when interpretation is required, facilitate accurate judgments according to their
    situations, and pave the way for further consultation tailored to the specifics
    of their current circumstances.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有提供的司法解释中，大约30%用于澄清特定法律术语或特殊案例。例如，假设有用户询问，“我和丈夫已经获得了结婚证，但未同居。我们现在申请离婚，丈夫希望退还聘礼。这合法吗？”ELLA会提供额外的司法解释，阐明退还聘礼的条件。然而，对于其余的70%，用户表示他们已经熟悉司法解释中的内容，例如，“赡养费包括子女的生活费、教育费、医疗费及其他开支。”一般来说，用户认为司法解释可以帮助他们在需要解释时更好地理解回答，帮助他们根据具体情况做出准确判断，并为进一步咨询提供了以现状为基础的指导。
- en: Legal Case Retrieval.
  id: totrans-83
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 法律案例检索。
- en: On average, 77% of queries proved the legal case retrieval module to be beneficial
    for user consultations. Users conveyed that although the retrieved legal cases
    might not exactly match their situations, these cases provide a reference point
    to gauge the possible outcomes for their unique circumstances. All users concurred
    that highlighting pertinent sentences significantly streamlines the process of
    reading cases. By emphasizing the information users are interested in, the user’s
    reading efficiency improves.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 平均而言，77%的查询证明法律案例检索模块对用户咨询有益。用户表示，虽然检索到的法律案例可能与他们的情况不完全匹配，但这些案例提供了一个参考点，用于评估其独特情况的可能结果。所有用户一致认为，突出相关句子显著简化了阅读案例的过程。通过强调用户感兴趣的信息，用户的阅读效率得到提升。
- en: 5 Conclusion
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**结论**'
- en: We present a novel tool, ELLA, for legal consultation. ELLA provides the legal
    basis and judicial interpretations that supplement the legal advice generated
    by LLMs, increasing users’ understanding and trust in LLM responses. It also displays
    retrieval results from the retrieval model and allows users to actively select
    relevant legal articles, thereby assisting the LLMs in generating more accurate
    responses. Additionally, equipped with a legal case retrieval model, users can
    refer to relevant legal cases for more comprehensive information. ELLA enables
    LLMs to provide legal advice that is easier to interpret, more precise, and more
    informative.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们展示了一种新型工具ELLA，用于法律咨询。ELLA提供法律依据和司法解释，补充由LLMs生成的法律建议，提高用户对LLM回应的理解和信任。它还显示了来自检索模型的检索结果，并允许用户主动选择相关法律条文，从而帮助LLMs生成更准确的回答。此外，配备有法律案例检索模型，用户可以参考相关法律案例以获取更全面的信息。ELLA使LLMs能够提供更易于解释、更精确且信息更丰富的法律建议。
- en: Acknowledgments
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**致谢**'
- en: This work is supported in part by NSFC (62161160339) and Beijing Science and
    Technology Program (Z231100007423011). We thank the anonymous reviewers for their
    valuable comments and suggestions. For any correspondence, please contact Yansong
    Feng.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作部分由NSFC（62161160339）和北京市科技计划（Z231100007423011）资助。我们感谢匿名审稿人提供的宝贵意见和建议。如需联系，请与冯燕松联系。
- en: Limitations
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**限制条件**'
- en: For simple legal queries, legal LLMs can provide correct responses in most cases.
    ELLA primarily assists with complex legal consultation queries. When users ask
    multiple questions within a single input, our legal article retrieval module may
    not comprehensively extract all relevant legal articles. In future work, we plan
    to integrate different retrieval modules to increase the diversity of retrieved
    legal articles.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 对于简单的法律查询，法律LLMs在大多数情况下能够提供正确的回应。ELLA主要协助处理复杂的法律咨询问题。当用户在单次输入中提出多个问题时，我们的法律条文检索模块可能无法全面提取所有相关法律条文。在未来的工作中，我们计划整合不同的检索模块，以增加检索到的法律条文的多样性。
- en: As official judicial interpretations only contain 76 articles, ELLA can not
    provide interpretations for all professional terminologies. We will incorporate
    additional external legal knowledge, such as legal textbooks, to provide interpretations
    for more professional terminologies.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 由于官方司法解释仅包含76条款，ELLA无法对所有专业术语提供解释。我们将引入额外的外部法律知识，如法律教科书，以提供更多专业术语的解释。
- en: Due to limited computational resources, we do not use state-of-the-art case
    retrieval modules. We will adopt them in our future work.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 由于计算资源有限，我们未使用最先进的案件检索模块。我们将在未来的工作中采纳这些模块。
- en: Ethics Statement
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**伦理声明**'
- en: The main purpose of this paper is to explore how to provide users with better
    legal consultation services. However, it is important to note that the outputs
    generated by the model may contain non-standard, incorrect, gender-biased, or
    morally questionable information. Therefore, please adopt the legal advice provided
    by the model with caution. When legal assistance is needed, please seek help from
    qualified professionals.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的主要目的是探索如何为用户提供更好的法律咨询服务。然而，需要注意的是，模型生成的输出可能包含不标准、不正确、性别偏见或道德上有问题的信息。因此，请谨慎采纳模型提供的法律建议。当需要法律援助时，请寻求合格专业人士的帮助。
- en: The external knowledge used in this paper, such as legal articles and legal
    cases, was obtained from the official websites of the Chinese government. The
    data does not contain any private information and cannot be used for commercial
    purposes.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 本文所使用的外部知识，如法律条文和法律案例，来自中国政府的官方网站。这些数据不包含任何私人信息，且不得用于商业用途。
- en: All participants involved in the user study are voluntary and anonymous. We
    did not collect any private information from the participants.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 所有参与用户研究的人员都是自愿和匿名的。我们没有收集任何参与者的私人信息。
- en: References
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Colombo et al. (2024) Pierre Colombo, Telmo Pessoa Pires, Malik Boudiaf, Dominic
    Culver, Rui Melo, Caio Corro, Andre F. T. Martins, Fabrizio Esposito, Vera Lúcia
    Raposo, Sofia Morgado, and Michael Desa. 2024. [Saullm-7b: A pioneering large
    language model for law](http://arxiv.org/abs/2403.03883).'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Colombo 等 (2024) Pierre Colombo, Telmo Pessoa Pires, Malik Boudiaf, Dominic
    Culver, Rui Melo, Caio Corro, Andre F. T. Martins, Fabrizio Esposito, Vera Lúcia
    Raposo, Sofia Morgado 和 Michael Desa. 2024. [Saullm-7b：法律领域的开创性大型语言模型](http://arxiv.org/abs/2403.03883).
- en: 'Cui et al. (2023) Jiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and Li Yuan.
    2023. [Chatlaw: Open-source legal large language model with integrated external
    knowledge bases](http://arxiv.org/abs/2306.16092).'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cui 等 (2023) Jiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen 和 Li Yuan. 2023. [Chatlaw：集成外部知识库的开源法律大型语言模型](http://arxiv.org/abs/2306.16092).
- en: 'Dong et al. (2023) Guanting Dong, Jinxu Zhao, Tingfeng Hui, Daichi Guo, Wenlong
    Wang, Boqi Feng, Yueyan Qiu, Zhuoma Gongque, Keqing He, Zechen Wang, et al. 2023.
    Revisit input perturbation problems for llms: A unified robustness evaluation
    framework for noisy slot filling task. In *CCF International Conference on Natural
    Language Processing and Chinese Computing*, pages 682–694\. Springer.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dong 等 (2023) Guanting Dong, Jinxu Zhao, Tingfeng Hui, Daichi Guo, Wenlong Wang,
    Boqi Feng, Yueyan Qiu, Zhuoma Gongque, Keqing He, Zechen Wang 等. 2023. 重新审视 LLMS
    的输入扰动问题：用于噪声插槽填充任务的统一鲁棒性评估框架。在 *CCF 国际自然语言处理与中文计算大会*，第 682–694 页。Springer.
- en: Huang et al. (2023) Quzhe Huang, Mingxu Tao, Chen Zhang, Zhenwei An, Cong Jiang,
    Zhibin Chen, Zirui Wu, and Yansong Feng. 2023. Lawyer llama technical report.
    *ArXiv*, abs/2305.15062.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等 (2023) Quzhe Huang, Mingxu Tao, Chen Zhang, Zhenwei An, Cong Jiang,
    Zhibin Chen, Zirui Wu 和 Yansong Feng. 2023. Lawyer llama 技术报告。 *ArXiv*, abs/2305.15062.
- en: Ji et al. (2023) Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan
    Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. 2023. [Survey
    of hallucination in natural language generation](https://doi.org/10.1145/3571730).
    *ACM Computing Surveys*, 55(12):1–38.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ji 等 (2023) Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu,
    Etsuko Ishii, Ye Jin Bang, Andrea Madotto 和 Pascale Fung. 2023. [自然语言生成中的幻觉调查](https://doi.org/10.1145/3571730).
    *ACM Computing Surveys*, 55(12):1–38.
- en: 'Lai et al. (2023) Jinqi Lai, Wensheng Gan, Jiayang Wu, Zhenlian Qi, and Philip S.
    Yu. 2023. [Large language models in law: A survey](http://arxiv.org/abs/2312.03718).'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lai 等 (2023) Jinqi Lai, Wensheng Gan, Jiayang Wu, Zhenlian Qi 和 Philip S. Yu.
    2023. [法律领域的大型语言模型：综述](http://arxiv.org/abs/2312.03718).
- en: Lewis et al. (2021) Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni,
    Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen tau Yih, Tim
    Rocktäschel, Sebastian Riedel, and Douwe Kiela. 2021. [Retrieval-augmented generation
    for knowledge-intensive nlp tasks](http://arxiv.org/abs/2005.11401).
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lewis 等 (2021) Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni,
    Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen tau Yih, Tim
    Rocktäschel, Sebastian Riedel 和 Douwe Kiela. 2021. [用于知识密集型 NLP 任务的检索增强生成](http://arxiv.org/abs/2005.11401).
- en: 'Li et al. (2023) Haitao Li, Qingyao Ai, Jia Chen, Qian Dong, Yueyue Wu, Yiqun
    Liu, Chong Chen, and Qi Tian. 2023. [Sailer: Structure-aware pre-trained language
    model for legal case retrieval](http://arxiv.org/abs/2304.11370).'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等 (2023) Haitao Li, Qingyao Ai, Jia Chen, Qian Dong, Yueyue Wu, Yiqun Liu,
    Chong Chen 和 Qi Tian. 2023. [Sailer：一种结构感知的法律案例检索预训练语言模型](http://arxiv.org/abs/2304.11370).
- en: 'Ma et al. (2021) Yixiao Ma, Yunqiu Shao, Yueyue Wu, Yiqun Liu, Ruizhe Zhang,
    Min Zhang, and Shaoping Ma. 2021. Lecard: a legal case retrieval dataset for chinese
    law system. In *Proceedings of the 44th international ACM SIGIR conference on
    research and development in information retrieval*, pages 2342–2348.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ma 等 (2021) Yixiao Ma, Yunqiu Shao, Yueyue Wu, Yiqun Liu, Ruizhe Zhang, Min
    Zhang 和 Shaoping Ma. 2021. Lecard：一种用于中国法律系统的法律案例检索数据集。在 *第 44 届国际 ACM SIGIR 信息检索研究与开发会议论文集*，第
    2342–2348 页。
- en: 'Ma et al. (2023) Yixiao Ma, Yueyue Wu, Weihang Su, Qingyao Ai, and Yiqun Liu.
    2023. [Caseencoder: A knowledge-enhanced pre-trained model for legal case encoding](http://arxiv.org/abs/2305.05393).'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ma 等 (2023) Yixiao Ma, Yueyue Wu, Weihang Su, Qingyao Ai 和 Yiqun Liu. 2023.
    [Caseencoder：一种用于法律案例编码的知识增强预训练模型](http://arxiv.org/abs/2305.05393).
- en: 'Nguyen (2023) Ha-Thanh Nguyen. 2023. [A brief report on lawgpt 1.0: A virtual
    legal assistant based on gpt-3](http://arxiv.org/abs/2302.05729).'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nguyen (2023) Ha-Thanh Nguyen. 2023. [关于 lawgpt 1.0 的简要报告：基于 GPT-3 的虚拟法律助理](http://arxiv.org/abs/2302.05729).
- en: OpenAI et al. (2024) OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama
    Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt,
    Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie
    Balcom, Paul Baltescu, Haiming Bao, Mohammad Bavarian, Jeff Belgum, Irwan Bello,
    Jake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff,
    Oleg Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman, Tim Brooks, Miles
    Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany Carey,
    Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek
    Chen, Sully Chen, Ruby Chen, Jason Chen, Mark Chen, Ben Chess, Chester Cho, Casey
    Chu, Hyung Won Chung, Dave Cummings, Jeremiah Currier, Yunxing Dai, Cory Decareaux,
    Thomas Degry, Noah Deutsch, Damien Deville, Arka Dhar, David Dohan, Steve Dowling,
    Sheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna Eloundou, David Farhi, Liam Fedus,
    Niko Felix, Simón Posada Fishman, Juston Forte, Isabella Fulford, Leo Gao, Elie
    Georges, Christian Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-Lopes,
    Jonathan Gordon, Morgan Grafstein, Scott Gray, Ryan Greene, Joshua Gross, Shixiang Shane
    Gu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris, Yuchen He, Mike Heaton,
    Johannes Heidecke, Chris Hesse, Alan Hickey, Wade Hickey, Peter Hoeschele, Brandon
    Houghton, Kenny Hsu, Shengli Hu, Xin Hu, Joost Huizinga, Shantanu Jain, Shawn
    Jain, Joanne Jang, Angela Jiang, Roger Jiang, Haozhun Jin, Denny Jin, Shino Jomoto,
    Billie Jonn, Heewoo Jun, Tomer Kaftan, Łukasz Kaiser, Ali Kamali, Ingmar Kanitscheider,
    Nitish Shirish Keskar, Tabarak Khan, Logan Kilpatrick, Jong Wook Kim, Christina
    Kim, Yongjik Kim, Jan Hendrik Kirchner, Jamie Kiros, Matt Knight, Daniel Kokotajlo,
    Łukasz Kondraciuk, Andrew Kondrich, Aris Konstantinidis, Kyle Kosic, Gretchen
    Krueger, Vishal Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan Leike, Jade Leung,
    Daniel Levy, Chak Ming Li, Rachel Lim, Molly Lin, Stephanie Lin, Mateusz Litwin,
    Theresa Lopez, Ryan Lowe, Patricia Lue, Anna Makanju, Kim Malfacini, Sam Manning,
    Todor Markov, Yaniv Markovski, Bianca Martin, Katie Mayer, Andrew Mayne, Bob McGrew,
    Scott Mayer McKinney, Christine McLeavey, Paul McMillan, Jake McNeil, David Medina,
    Aalok Mehta, Jacob Menick, Luke Metz, Andrey Mishchenko, Pamela Mishkin, Vinnie
    Monaco, Evan Morikawa, Daniel Mossing, Tong Mu, Mira Murati, Oleg Murk, David
    Mély, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak, Arvind Neelakantan, Richard
    Ngo, Hyeonwoo Noh, Long Ouyang, Cullen O’Keefe, Jakub Pachocki, Alex Paino, Joe
    Palermo, Ashley Pantuliano, Giambattista Parascandolo, Joel Parish, Emy Parparita,
    Alex Passos, Mikhail Pavlov, Andrew Peng, Adam Perelman, Filipe de Avila Belbute Peres,
    Michael Petrov, Henrique Ponde de Oliveira Pinto, Michael, Pokorny, Michelle Pokrass,
    Vitchyr H. Pong, Tolly Powell, Alethea Power, Boris Power, Elizabeth Proehl, Raul
    Puri, Alec Radford, Jack Rae, Aditya Ramesh, Cameron Raymond, Francis Real, Kendra
    Rimbach, Carl Ross, Bob Rotsted, Henri Roussez, Nick Ryder, Mario Saltarelli,
    Ted Sanders, Shibani Santurkar, Girish Sastry, Heather Schmidt, David Schnurr,
    John Schulman, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah
    Shoker, Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin,
    Katarina Slama, Ian Sohl, Benjamin Sokolowsky, Yang Song, Natalie Staudacher,
    Felipe Petroski Such, Natalie Summers, Ilya Sutskever, Jie Tang, Nikolas Tezak,
    Madeleine B. Thompson, Phil Tillet, Amin Tootoonchian, Elizabeth Tseng, Preston
    Tuggle, Nick Turley, Jerry Tworek, Juan Felipe Cerón Uribe, Andrea Vallone, Arun
    Vijayvergiya, Chelsea Voss, Carroll Wainwright, Justin Jay Wang, Alvin Wang, Ben
    Wang, Jonathan Ward, Jason Wei, CJ Weinmann, Akila Welihinda, Peter Welinder,
    Jiayi Weng, Lilian Weng, Matt Wiethoff, Dave Willner, Clemens Winter, Samuel Wolrich,
    Hannah Wong, Lauren Workman, Sherwin Wu, Jeff Wu, Michael Wu, Kai Xiao, Tao Xu,
    Sarah Yoo, Kevin Yu, Qiming Yuan, Wojciech Zaremba, Rowan Zellers, Chong Zhang,
    Marvin Zhang, Shengjia Zhao, Tianhao Zheng, Juntang Zhuang, William Zhuk, and
    Barret Zoph. 2024. [Gpt-4 technical report](http://arxiv.org/abs/2303.08774).
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI 等（2024）OpenAI、Josh Achiam、Steven Adler、Sandhini Agarwal、Lama Ahmad、Ilge
    Akkaya、Florencia Leoni Aleman、Diogo Almeida、Janko Altenschmidt、Sam Altman、Shyamal
    Anadkat、Red Avila、Igor Babuschkin、Suchir Balaji、Valerie Balcom、Paul Baltescu、Haiming
    Bao、Mohammad Bavarian、Jeff Belgum、Irwan Bello、Jake Berdine、Gabriel Bernadett-Shapiro、Christopher
    Berner、Lenny Bogdonoff、Oleg Boiko、Madelaine Boyd、Anna-Luisa Brakman、Greg Brockman、Tim
    Brooks、Miles Brundage、Kevin Button、Trevor Cai、Rosie Campbell、Andrew Cann、Brittany
    Carey、Chelsea Carlson、Rory Carmichael、Brooke Chan、Che Chang、Fotis Chantzis、Derek
    Chen、Sully Chen、Ruby Chen、Jason Chen、Mark Chen、Ben Chess、Chester Cho、Casey Chu、Hyung
    Won Chung、Dave Cummings、Jeremiah Currier、Yunxing Dai、Cory Decareaux、Thomas Degry、Noah
    Deutsch、Damien Deville、Arka Dhar、David Dohan、Steve Dowling、Sheila Dunning、Adrien
    Ecoffet、Atty Eleti、Tyna Eloundou、David Farhi、Liam Fedus、Niko Felix、Simón Posada
    Fishman、Juston Forte、Isabella Fulford、Leo Gao、Elie Georges、Christian Gibson、Vik
    Goel、Tarun Gogineni、Gabriel Goh、Rapha Gontijo-Lopes、Jonathan Gordon、Morgan Grafstein、Scott
    Gray、Ryan Greene、Joshua Gross、Shixiang Shane Gu、Yufei Guo、Chris Hallacy、Jesse
    Han、Jeff Harris、Yuchen He、Mike Heaton、Johannes Heidecke、Chris Hesse、Alan Hickey、Wade
    Hickey、Peter Hoeschele、Brandon Houghton、Kenny Hsu、Shengli Hu、Xin Hu、Joost Huizinga、Shantanu
    Jain、Shawn Jain、Joanne Jang、Angela Jiang、Roger Jiang、Haozhun Jin、Denny Jin、Shino
    Jomoto、Billie Jonn、Heewoo Jun、Tomer Kaftan、Łukasz Kaiser、Ali Kamali、Ingmar Kanitscheider、Nitish
    Shirish Keskar、Tabarak Khan、Logan Kilpatrick、Jong Wook Kim、Christina Kim、Yongjik
    Kim、Jan Hendrik Kirchner、Jamie Kiros、Matt Knight、Daniel Kokotajlo、Łukasz Kondraciuk、Andrew
    Kondrich、Aris Konstantinidis、Kyle Kosic、Gretchen Krueger、Vishal Kuo、Michael Lampe、Ikai
    Lan、Teddy Lee、Jan Leike、Jade Leung、Daniel Levy、Chak Ming Li、Rachel Lim、Molly Lin、Stephanie
    Lin、Mateusz Litwin、Theresa Lopez、Ryan Lowe、Patricia Lue、Anna Makanju、Kim Malfacini、Sam
    Manning、Todor Markov、Yaniv Markovski、Bianca Martin、Katie Mayer、Andrew Mayne、Bob
    McGrew、Scott Mayer McKinney、Christine McLeavey、Paul McMillan、Jake McNeil、David
    Medina、Aalok Mehta、Jacob Menick、Luke Metz、Andrey Mishchenko、Pamela Mishkin、Vinnie
    Monaco、Evan Morikawa、Daniel Mossing、Tong Mu、Mira Murati、Oleg Murk、David Mély、Ashvin
    Nair、Reiichiro Nakano、Rajeev Nayak、Arvind Neelakantan、Richard Ngo、Hyeonwoo Noh、Long
    Ouyang、Cullen O’Keefe、Jakub Pachocki、Alex Paino、Joe Palermo、Ashley Pantuliano、Giambattista
    Parascandolo、Joel Parish、Emy Parparita、Alex Passos、Mikhail Pavlov、Andrew Peng、Adam
    Perelman、Filipe de Avila Belbute Peres、Michael Petrov、Henrique Ponde de Oliveira
    Pinto、Michael Pokorny、Michelle Pokrass、Vitchyr H. Pong、Tolly Powell、Alethea Power、Boris
    Power、Elizabeth Proehl、Raul Puri、Alec Radford、Jack Rae、Aditya Ramesh、Cameron Raymond、Francis
    Real、Kendra Rimbach、Carl Ross、Bob Rotsted、Henri Roussez、Nick Ryder、Mario Saltarelli、Ted
    Sanders、Shibani Santurkar、Girish Sastry、Heather Schmidt、David Schnurr、John Schulman、Daniel
    Selsam、Kyla Sheppard、Toki Sherbakov、Jessica Shieh、Sarah Shoker、Pranav Shyam、Szymon
    Sidor、Eric Sigler、Maddie Simens、Jordan Sitkin、Katarina Slama、Ian Sohl、Benjamin
    Sokolowsky、Yang Song、Natalie Staudacher、Felipe Petroski Such、Natalie Summers、Ilya
    Sutskever、Jie Tang、Nikolas Tezak、Madeleine B. Thompson、Phil Tillet、Amin Tootoonchian、Elizabeth
    Tseng、Preston Tuggle、Nick Turley、Jerry Tworek、Juan Felipe Cerón Uribe、Andrea Vallone、Arun
    Vijayvergiya、Chelsea Voss、Carroll Wainwright、Justin Jay Wang、Alvin Wang、Ben Wang、Jonathan
    Ward、Jason Wei、CJ Weinmann、Akila Welihinda、Peter Welinder、Jiayi Weng、Lilian Weng、Matt
    Wiethoff、Dave Willner、Clemens Winter、Samuel Wolrich、Hannah Wong、Lauren Workman、Sherwin
    Wu、Jeff Wu、Michael Wu、Kai Xiao、Tao Xu、Sarah Yoo、Kevin Yu、Qiming Yuan、Wojciech
    Zaremba、Rowan Zellers、Chong Zhang、Marvin Zhang、Shengjia Zhao、Tianhao Zheng、Juntang
    Zhuang、William Zhuk，以及 Barret Zoph。2024年。[Gpt-4 技术报告](http://arxiv.org/abs/2303.08774)
- en: 'Robertson and Zaragoza (2009) Stephen Robertson and Hugo Zaragoza. 2009. [The
    probabilistic relevance framework: Bm25 and beyond](https://doi.org/10.1561/1500000019).
    *Found. Trends Inf. Retr.*, 3(4):333–389.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Robertson and Zaragoza (2009) Stephen Robertson and Hugo Zaragoza. 2009. [概率相关框架：BM25及其扩展](https://doi.org/10.1561/1500000019)。*Found.
    Trends Inf. Retr.*, 3(4):333–389。
- en: Savelka et al. (2023) Jaromir Savelka, Kevin D. Ashley, Morgan A. Gray, Hannes
    Westermann, and Huihui Xu. 2023. [Explaining legal concepts with augmented large
    language models (gpt-4)](http://arxiv.org/abs/2306.09525).
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Savelka et al. (2023) Jaromir Savelka, Kevin D. Ashley, Morgan A. Gray, Hannes
    Westermann, and Huihui Xu. 2023. [使用增强的大语言模型（gpt-4）解释法律概念](http://arxiv.org/abs/2306.09525)。
- en: 'Su et al. (2024) Weihang Su, Qingyao Ai, Yueyue Wu, Yixiao Ma, Haitao Li, Yiqun
    Liu, Zhijing Wu, and Min Zhang. 2024. [Caseformer: Pre-training for legal case
    retrieval based on inter-case distinctions](http://arxiv.org/abs/2311.00333).'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Su et al. (2024) Weihang Su, Qingyao Ai, Yueyue Wu, Yixiao Ma, Haitao Li, Yiqun
    Liu, Zhijing Wu, and Min Zhang. 2024. [Caseformer: 基于案件间区分的法律案件检索预训练](http://arxiv.org/abs/2311.00333)。'
- en: 'Touvron et al. (2023) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
    Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal,
    Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and
    Guillaume Lample. 2023. [Llama: Open and efficient foundation language models](http://arxiv.org/abs/2302.13971).'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Touvron et al. (2023) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
    Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal,
    Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and
    Guillaume Lample. 2023. [Llama: 开放且高效的基础语言模型](http://arxiv.org/abs/2302.13971)。'
- en: 'Wu et al. (2023) Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark
    Dredze, Sebastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, and Gideon Mann.
    2023. [Bloomberggpt: A large language model for finance](http://arxiv.org/abs/2303.17564).'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wu et al. (2023) Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark
    Dredze, Sebastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, and Gideon Mann.
    2023. [Bloomberggpt: 一个用于金融的大语言模型](http://arxiv.org/abs/2303.17564)。'
- en: 'Xiao et al. (2023) Shitao Xiao, Zheng Liu, Peitian Zhang, and Niklas Muennighoff.
    2023. [C-pack: Packaged resources to advance general chinese embedding](http://arxiv.org/abs/2309.07597).'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Xiao et al. (2023) Shitao Xiao, Zheng Liu, Peitian Zhang, and Niklas Muennighoff.
    2023. [C-pack: 推进通用中文嵌入的打包资源](http://arxiv.org/abs/2309.07597)。'
- en: 'Yang et al. (2023) Hongyang Yang, Xiao-Yang Liu, and Christina Dan Wang. 2023.
    [Fingpt: Open-source financial large language models](http://arxiv.org/abs/2306.06031).'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yang et al. (2023) Hongyang Yang, Xiao-Yang Liu, and Christina Dan Wang. 2023.
    [Fingpt: 开源金融大语言模型](http://arxiv.org/abs/2306.06031)。'
- en: 'Yue et al. (2023) Shengbin Yue, Wei Chen, Siyuan Wang, Bingxuan Li, Chenchen
    Shen, Shujun Liu, Yuxuan Zhou, Yao Xiao, Song Yun, Xuanjing Huang, and Zhongyu
    Wei. 2023. [Disc-lawllm: Fine-tuning large language models for intelligent legal
    services](http://arxiv.org/abs/2309.11325).'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yue et al. (2023) Shengbin Yue, Wei Chen, Siyuan Wang, Bingxuan Li, Chenchen
    Shen, Shujun Liu, Yuxuan Zhou, Yao Xiao, Song Yun, Xuanjing Huang, and Zhongyu
    Wei. 2023. [Disc-lawllm: 为智能法律服务微调大语言模型](http://arxiv.org/abs/2309.11325)。'
- en: 'Zeng et al. (2023) Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai,
    Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan
    Ma, Yufei Xue, Jidong Zhai, Wenguang Chen, Peng Zhang, Yuxiao Dong, and Jie Tang.
    2023. [Glm-130b: An open bilingual pre-trained model](http://arxiv.org/abs/2210.02414).'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zeng et al. (2023) Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai,
    Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan
    Ma, Yufei Xue, Jidong Zhai, Wenguang Chen, Peng Zhang, Yuxiao Dong, and Jie Tang.
    2023. [Glm-130b: 一个开放的双语预训练模型](http://arxiv.org/abs/2210.02414)。'
- en: 'Zhu et al. (2023) Kaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen Wang, Hao
    Chen, Yidong Wang, Linyi Yang, Wei Ye, Neil Zhenqiang Gong, Yue Zhang, et al.
    2023. Promptbench: Towards evaluating the robustness of large language models
    on adversarial prompts. *arXiv preprint arXiv:2306.04528*.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhu et al. (2023) Kaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen Wang, Hao
    Chen, Yidong Wang, Linyi Yang, Wei Ye, Neil Zhenqiang Gong, Yue Zhang, et al.
    2023. Promptbench: 评估大语言模型对对抗性提示的鲁棒性。*arXiv预印本 arXiv:2306.04528*。'
- en: Appendix A Dataset Construction
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录A 数据集构建
- en: '![Refer to caption](img/c561aa32ae3a1de2891f0b202f336ad7.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c561aa32ae3a1de2891f0b202f336ad7.png)'
- en: 'Figure 4: Schematic of Dataset Construction. The blue sentences indicate the
    sentences with the highest BM25 scores and the orange sentences are the most irrelevant
    ones. Blue lines indicate positive cases and orange lines indicate negative cases.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：数据集构建示意图。蓝色句子表示BM25分数最高的句子，橙色句子则是最不相关的句子。蓝色线条表示正例，橙色线条表示负例。
- en: Appendix B Consultation Examples
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录B 咨询示例
- en: '| $Q_{1}:$ 收养小孩有什么要求吗？ | $Q_{1}:$ What are the requirements for adopting a
    child? |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| $Q_{1}:$ 收养小孩有什么要求吗？ | $Q_{1}:$ What are the requirements for adopting a
    child? |'
- en: '| $R_{1}:$ 您好，根据《民法典》的规定，收养人需要同时具备以下五个条件：1.无子女或只有一名子女；2.有抚养、教育和保护被收养人的能力；3.未患有在医学上认为不应当收养子女的疾病；4.无不利于被收养人健康成长的违法犯罪记录；5.年满三十周岁。此外，如果收养人有配偶，则需要夫妻共同收养。收养关系自登记之日起成立，收养关系当事人自愿签订收养协议的，可以签订收养协议。如果收养关系当事人各方或一方要求办理收养公证的，应当办理收养公证。县级以上人民政府民政部门应当依法进行收养评估。请问您还有其他方面的问题吗？
    | $R_{1}:$ Hello, according to the provisions of the Civil Code, adopters need
    to meet the following five conditions simultaneously: 1\. Having no children or
    having only one child; 2\. Having the ability to support, educate, and protect
    the adopted child; 3\. Not suffering from diseases that are considered by medical
    standards as reasons not to adopt children; 4\. Having no criminal records that
    are detrimental to the healthy growth of the adopted child; 5\. Being at least
    thirty years old. Additionally, if the adopter is married, the adoption should
    be done jointly by the couple. The adoption relationship is established from the
    date of registration. If the parties to the adoption voluntarily sign an adoption
    agreement, they can do so. If the parties to the adoption or one party requests
    adoption notarization, adoption notarization should be processed. The civil affairs
    department of the people’s government at or above the county level shall conduct
    adoption assessments in accordance with the law. Do you have any other questions?
    |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| $R_{1}:$ 您好，根据《民法典》的规定，收养人需要同时具备以下五个条件：1.无子女或只有一名子女；2.有抚养、教育和保护被收养人的能力；3.未患有在医学上认为不应当收养子女的疾病；4.无不利于被收养人健康成长的违法犯罪记录；5.年满三十周岁。此外，如果收养人有配偶，则需要夫妻共同收养。收养关系自登记之日起成立，收养关系当事人自愿签订收养协议的，可以签订收养协议。如果收养关系当事人各方或一方要求办理收养公证的，应当办理收养公证。县级以上人民政府民政部门应当依法进行收养评估。请问您还有其他方面的问题吗？
    | $R_{1}:$ Hello, according to the provisions of the Civil Code, adopters need
    to meet the following five conditions simultaneously: 1. Having no children or
    having only one child; 2. Having the ability to support, educate, and protect
    the adopted child; 3. Not suffering from diseases that are considered by medical
    standards as reasons not to adopt children; 4. Having no criminal records that
    are detrimental to the healthy growth of the adopted child; 5. Being at least
    thirty years old. Additionally, if the adopter is married, the adoption should
    be done jointly by the couple. The adoption relationship is established from the
    date of registration. If the parties to the adoption voluntarily sign an adoption
    agreement, they can do so. If the parties to the adoption or one party requests
    adoption notarization, adoption notarization should be processed. The civil affairs
    department of the people’s government at or above the county level shall conduct
    adoption assessments in accordance with the law. Do you have any other questions?
    |'
- en: '| $R_{1}^{\prime}:$ 您好，根据《民法典》的规定，收养小孩需要满足以下条件：1.无子女的收养人可以收养两名子女；2.有子女的收养人只能收养一名子女；3.收养孤儿、残疾未成年人或者儿童福利机构抚养的查找不到生父母的未成年人，可以不受前款和本法第一千零九十八条第一项规定的限制。此外，无配偶者收养异性子女的，收养人与被收养人的年龄应当相差四十周岁以上。最后，符合以下条件的未成年人可以被收养：1.丧失父母的孤儿；2.查找不到生父母的未成年人；3.生父母有特殊困难无力抚养的子女。请问您的具体情况是什么？是否符合上述规定呢？
    | $R_{1}^{\prime}:$ Hello, according to the provisions of the Civil Code, adopting
    a child requires meeting the following conditions: 1\. An adopter with no children
    can adopt up to two children; 2\. An adopter with children can only adopt one
    child; 3\. Orphans, disabled minors, or minors raised by child welfare institutions
    whose birth parents cannot be found are not subject to the restrictions in the
    preceding paragraph and Article 1098 of this Law. Additionally, if an unmarried
    person adopts a child of the opposite sex, the adopter’s age must be at least
    forty years older than the adoptee’s. Lastly, the following minors can be adopted:
    1\. Orphans who have lost both parents; 2\. Minors whose birth parents cannot
    be found; 3\. Children whose birth parents face special difficulties and are unable
    to raise them. Could you please provide specific details about your situation?
    Do you meet the above requirements? |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| $R_{1}^{\prime}:$ 您好，根据《民法典》的规定，收养小孩需要满足以下条件：1.无子女的收养人可以收养两名子女；2.有子女的收养人只能收养一名子女；3.收养孤儿、残疾未成年人或者儿童福利机构抚养的查找不到生父母的未成年人，可以不受前款和本法第一千零九十八条第一项规定的限制。此外，无配偶者收养异性子女的，收养人与被收养人的年龄应当相差四十周岁以上。最后，符合以下条件的未成年人可以被收养：1.丧失父母的孤儿；2.查找不到生父母的未成年人；3.生父母有特殊困难无力抚养的子女。请问您的具体情况是什么？是否符合上述规定呢？
    | $R_{1}^{\prime}:$ Hello, according to the provisions of the Civil Code, adopting
    a child requires meeting the following conditions: 1. An adopter with no children
    can adopt up to two children; 2. An adopter with children can only adopt one child;
    3. Orphans, disabled minors, or minors raised by child welfare institutions whose
    birth parents cannot be found are not subject to the restrictions in the preceding
    paragraph and Article 1098 of this Law. Additionally, if an unmarried person adopts
    a child of the opposite sex, the adopter’s age must be at least forty years older
    than the adoptee’s. Lastly, the following minors can be adopted: 1. Orphans who
    have lost both parents; 2. Minors whose birth parents cannot be found; 3. Children
    whose birth parents face special difficulties and are unable to raise them. Could
    you please provide specific details about your situation? Do you meet the above
    requirements? |'
- en: 'Table 2: $R_{1}$ is generated based on Article 1098, 1101, and 1105 of Civil
    Code. $R_{1}^{\prime}$ is generated based on Article 1100, 1102, and 1093 of Civil
    Code.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：$R_{1}$ 是根据《民法典》第1098、1101和1105条生成的。$R_{1}^{\prime}$ 是根据《民法典》第1100、1102和1093条生成的。
- en: '| $Q_{2}:$ 我的情况是这样的，我女朋友结婚了，但是已经和她老公分居好几年，是不是算自动离婚了?我们没以夫妻的名义同居算重婚吗? | $Q_{2}:$
    Here’s my situation: my girlfriend got married, but she has been separated from
    her husband for several years. Does this count as automatic divorce? Would living
    together without being married constitute bigamy? |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| $Q_{2}:$ 我的情况是这样的，我女朋友结婚了，但是已经和她老公分居好几年，是不是算自动离婚了?我们没以夫妻的名义同居算重婚吗? | $Q_{2}:$
    Here’s my situation: my girlfriend got married, but she has been separated from
    her husband for several years. Does this count as automatic divorce? Would living
    together without being married constitute bigamy?'
- en: '| $R_{2}:$ 您好，根据我国婚姻法规定，夫妻双方自愿离婚，可以自行协商处理财产分割等问题，不需要经过法院审理，如果您女友与她的丈夫已经分居多年，并且没有其他原因导致他们无法继续维持婚姻关系，那么可以视为自动离婚。至于您们是否构成重婚，需要了解你们是否已正式离婚，以及是否已经与他人结婚或同居。如果已经离婚，则不存在重婚的问题。如果还没有离婚，则需要遵守相关法律法规，如禁止重婚等。请问您们是否已经离婚?
    | $R_{2}:$ Hello, according to the marriage laws of our country, if both parties
    voluntarily divorce, they can negotiate property division and other issues themselves
    without the need for court trial. If your girlfriend has been separated from her
    husband for many years and there are no other reasons preventing them from continuing
    their marriage, it can be considered an automatic divorce. As for whether you
    constitute bigamy, it depends on whether you have officially divorced and whether
    you have married or cohabited with someone else. If you have already divorced,
    there is no issue of bigamy. If not, you need to comply with relevant laws and
    regulations, such as the prohibition of bigamy. May I ask if you have already
    divorced? |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| $R_{2}:$ 您好，根据我国婚姻法规定，夫妻双方自愿离婚，可以自行协商处理财产分割等问题，不需要经过法院审理。如果您的女友与她的丈夫已经分居多年，并且没有其他原因导致他们无法继续维持婚姻关系，那么可以视为自动离婚。至于您们是否构成重婚，需要了解你们是否已正式离婚，以及是否已经与他人结婚或同居。如果已经离婚，则不存在重婚的问题。如果还没有离婚，则需要遵守相关法律法规，如禁止重婚等。请问您们是否已经离婚?
    | $R_{2}:$ Hello, according to the marriage laws of our country, if both parties
    voluntarily divorce, they can negotiate property division and other issues themselves
    without the need for court trial. If your girlfriend has been separated from her
    husband for many years and there are no other reasons preventing them from continuing
    their marriage, it can be considered an automatic divorce. As for whether you
    constitute bigamy, it depends on whether you have officially divorced and whether
    you have married or cohabited with someone else. If you have already divorced,
    there is no issue of bigamy. If not, you need to comply with relevant laws and
    regulations, such as the prohibition of bigamy. May I ask if you have already
    divorced? |'
- en: '| $R_{2}^{\prime}:$ 您好，根据我国法律规定，只有在完成离婚登记或者离婚判决书、调解书生效后，才能够真正意义上解除婚姻关系。而您所提到的情况，虽然你们没有以夫妻的名义同居，但并不意味着已经完成了离婚手续。因此，您们目前仍然处于婚姻状态之中。另外，重婚是指在未办理离婚手续的情况下再次结婚的行为，而您所提到的情况并不属于重婚范畴之内。请问您还有其他方面的问题需要解答吗?
    | $Q_{2}^{\prime}:$ Hello, according to the laws of our country, marriage is only
    truly dissolved after completing divorce registration, or when the divorce judgment
    or mediation agreement takes effect. The situation you mentioned, although you
    haven’t lived together as spouses, does not mean that the divorce procedures have
    been completed. Therefore, you are still in a marital status currently. Additionally,
    bigamy refers to remarrying without completing divorce procedures, which doesn’t
    apply to the situation you mentioned. Do you have any other questions that need
    answering? |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| $R_{2}^{\prime}:$ 您好，根据我国法律规定，只有在完成离婚登记或者离婚判决书、调解书生效后，才能够真正意义上解除婚姻关系。而您所提到的情况，虽然你们没有以夫妻的名义同居，但并不意味着已经完成了离婚手续。因此，您们目前仍然处于婚姻状态之中。另外，重婚是指在未办理离婚手续的情况下再次结婚的行为，而您所提到的情况并不属于重婚范畴之内。请问您还有其他方面的问题需要解答吗?
    | $R_{2}^{\prime}:$ Hello, according to the laws of our country, marriage is only
    truly dissolved after completing divorce registration, or when the divorce judgment
    or mediation agreement takes effect. The situation you mentioned, although you
    haven’t lived together as spouses, does not mean that the divorce procedures have
    been completed. Therefore, you are still in a marital status currently. Additionally,
    bigamy refers to remarrying without completing divorce procedures, which doesn’t
    apply to the situation you mentioned. Do you have any other questions that need
    answering?'
- en: 'Table 3: $R_{2}$ is generated based on Article 1080, 1091, and 1043 of Civil
    Code. $R_{2}^{\prime}$ is generated based on Article 1080 of Civil Code.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：$R_{2}$ 是基于《民法典》第1080、1091和1043条生成的。$R_{2}^{\prime}$ 是基于《民法典》第1080条生成的。
- en: '| $Q_{3}:$ 我的情况是这样的，我女朋友结婚了，但是已经和她老公分居好几年，是不是算自动离婚了?我们没以夫妻的名义同居算重婚吗? | $Q_{3}:$
    My situation is like this: My girlfriend got married, but she has been separated
    from her husband for several years. Does this count as automatic divorce? Would
    living together without being married constitute bigamy? |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| $Q_{3}:$ 我的情况是这样的，我女朋友结婚了，但是已经和她老公分居好几年，是不是算自动离婚了?我们没以夫妻的名义同居算重婚吗? | $Q_{3}:$
    My situation is like this: My girlfriend got married, but she has been separated
    from her husband for several years. Does this count as automatic divorce? Would
    living together without being married constitute bigamy? |'
- en: '| $R_{3}:$ 您好，根据《民法典》的规定，只有完成离婚登记或者离婚判决书、调解书生效才能够解除婚姻关系。而您的女友已经与她的丈夫分居多年，但并未办理离婚手续，因此不能算自动离婚。同时，如果您们没有以夫妻的名义同居，则不属于重婚行为。不过，在婚姻关系中，夫妻双方应该互相忠实、互相尊重、互相关爱，并且要保持良好的家庭环境。如果出现家庭矛盾或纠纷，可以通过协商解决，也可以通过司法途径解决。请问您是否需要进一步了解如何处理此类问题呢?
    | $R_{3}:$ Hello, according to the provisions of the Civil Code, marriage can
    only be dissolved by completing divorce registration or when a divorce judgment
    or mediation agreement becomes effective. As your girlfriend has been separated
    from her husband for several years without completing divorce procedures, it does
    not count as automatic divorce. Also, if you haven’t lived together as husband
    and wife, it does not constitute bigamy. However, in a marital relationship, both
    parties should be faithful, respect each other, love each other, and maintain
    a good family environment. If there are family conflicts or disputes, they can
    be resolved through negotiation or legal means. Would you like further information
    on how to handle such issues? |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| $R_{3}:$ 您好，根据《民法典》的规定，婚姻只能通过完成离婚登记或离婚判决书、调解书生效来解除。而您的女友与她的丈夫已经分居多年，但并未完成离婚手续，因此不能算作自动离婚。此外，如果您们没有以夫妻名义同居，也不构成重婚行为。然而，在婚姻关系中，双方应当忠诚、尊重、关爱对方，并保持良好的家庭环境。如果出现家庭矛盾或争议，可以通过协商或法律途径解决。您是否需要进一步了解如何处理这些问题？
    |'
- en: 'Table 4: $R_{3}$ is generated based on Article 1080, 1091, 1043 of Civil Code.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 'Table 4: $R_{3}$ 是根据《民法典》第1080、1091、1043条生成的。'
- en: '| $Q_{4}:$ 我的情况是这样的，我女朋友结婚了，但是已经和她老公分居两年多了，算不算自动离婚了？我们没以夫妻的名义同居算重婚罪吗？ | Here’s
    my situation: my girlfriend got married, but she has been separated from her husband
    for over two years. Does this count as automatic divorce? Would it be considered
    bigamy if we cohabitated without being married? |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| $Q_{4}:$ 我的情况是这样的，我女朋友结婚了，但她已经和她的丈夫分居了两年多。这算不算自动离婚？如果我们没有以夫妻名义同居，会被视为重婚罪吗？
    |'
- en: '| $R_{4}:$ 您好，根据我国婚姻法规定，夫妻双方自愿离婚，可以自行协商离婚事宜并到当地民政局办理离婚手续。如果您女友与她的丈夫没有达成协议，则需要通过法院诉讼程序来解决离婚问题。至于您提到的同居问题，如果两人没有以夫妻的名义同居，则不会构成重婚罪。不过，建议您们先了解清楚相关法律规定，再做出决定。另外，关于收养小孩的问题，您需要提供更多信息，例如孩子的性别、年龄等，才能够更好地为您解答问题。
    | Hello, according to the Marriage Law of our country, if both parties in a marriage
    voluntarily agree to divorce, they can negotiate the terms of the divorce and
    go to the local civil affairs bureau to handle the divorce procedures. If your
    girlfriend and her husband have not reached an agreement, they will need to resolve
    the divorce issue through the court litigation process. As for the cohabitation
    issue you mentioned, it would not constitute bigamy if you two did not cohabit
    under the guise of marriage. However, it’s advisable for you to understand the
    relevant legal provisions before making any decisions. Additionally, regarding
    the adoption of a child, you would need to provide more information, such as the
    child’s gender and age, for me to better assist you with your questions. |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| $R_{4}:$ 您好，根据我国婚姻法规定，夫妻双方自愿离婚，可以自行协商离婚事宜并到当地民政局办理离婚手续。如果您女友与她的丈夫没有达成协议，则需要通过法院诉讼程序来解决离婚问题。至于您提到的同居问题，如果两人没有以夫妻名义同居，则不会构成重婚罪。不过，建议您先了解相关法律规定，再做出决定。另外，关于收养孩子的问题，您需要提供更多信息，例如孩子的性别、年龄等，以便我能更好地为您解答。
    |'
- en: 'Table 5: $R_{4}$ is generated based on Article 1080, 1091, 1043 of Civil Code.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 'Table 5: $R_{4}$ 是根据《民法典》第1080、1091、1043条生成的。'
