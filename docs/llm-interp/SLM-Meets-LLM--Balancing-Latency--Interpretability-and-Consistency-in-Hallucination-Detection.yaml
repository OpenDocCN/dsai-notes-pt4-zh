- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '类别: 未分类'
- en: 'date: 2024-09-08 17:33:08'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-08 17:33:08'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'SLM Meets LLM: Balancing Latency, Interpretability and Consistency in Hallucination
    Detection'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SLM 与 LLM 的结合：平衡延迟、可解释性与一致性以进行幻觉检测
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2408.12748](https://ar5iv.labs.arxiv.org/html/2408.12748)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2408.12748](https://ar5iv.labs.arxiv.org/html/2408.12748)
- en: Mengya (Mia) Hu¹¹1Equal contributions.,  Rui Xu¹¹1Equal contributions.,   Deren
    Lei¹¹1Equal contributions.,   Yaxi Li¹¹1Equal contributions.,  Mingyu Wang,
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 孟雅（Mia）胡¹¹1平等贡献。  徐锐¹¹1平等贡献。  雷德仁¹¹1平等贡献。  李雅曦¹¹1平等贡献。  王明瑜，
- en: Emily Ching,  Eslam Kamal,  Alex Deng Microsoft Responsible AI
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Emily Ching,  Eslam Kamal,  Alex Deng Microsoft Responsible AI
- en: '{humia, rxu, derenlei, yaxi.li, mwang, yuetc, eskam, alex.deng}@microsoft.com'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '{humia, rxu, derenlei, yaxi.li, mwang, yuetc, eskam, alex.deng}@microsoft.com'
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Large language models (LLMs) are highly capable but face latency challenges
    in real-time applications, such as conducting online hallucination detection.
    To overcome this issue, we propose a novel framework that leverages a small language
    model (SLM) classifier for initial detection, followed by a LLM as constrained
    reasoner to generate detailed explanations for detected hallucinated content.
    This study optimizes the real-time interpretable hallucination detection by introducing
    effective prompting techniques that align LLM-generated explanations with SLM
    decisions. Empirical experiment results demonstrate its effectiveness, thereby
    enhancing the overall user experience.¹¹1[https://github.com/microsoft/ConstrainedReasoner](https://github.com/microsoft/ConstrainedReasoner)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）能力强大，但在实时应用中，如在线幻觉检测，面临延迟挑战。为克服这一问题，我们提出了一种新颖的框架，该框架利用小型语言模型（SLM）分类器进行初步检测，然后通过
    LLM 作为受限推理器生成检测到的幻觉内容的详细解释。本研究通过引入有效的提示技术来优化实时可解释的幻觉检测，使 LLM 生成的解释与 SLM 决策对齐。实证实验结果证明了其有效性，从而提升了整体用户体验。¹¹1[https://github.com/microsoft/ConstrainedReasoner](https://github.com/microsoft/ConstrainedReasoner)
- en: 'SLM Meets LLM: Balancing Latency, Interpretability and Consistency in Hallucination
    Detection'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: SLM 与 LLM 的结合：平衡延迟、可解释性与一致性以进行幻觉检测
- en: Mengya (Mia) Hu¹¹1Equal contributions.,  Rui Xu¹¹1Equal contributions.,   Deren
    Lei¹¹1Equal contributions.,   Yaxi Li¹¹1Equal contributions.,  Mingyu Wang, Emily
    Ching,  Eslam Kamal,  Alex Deng Microsoft Responsible AI {humia, rxu, derenlei,
    yaxi.li, mwang, yuetc, eskam, alex.deng}@microsoft.com
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 孟雅（Mia）胡¹¹1平等贡献。  徐锐¹¹1平等贡献。  雷德仁¹¹1平等贡献。  李雅曦¹¹1平等贡献。  王明瑜，Emily Ching,  Eslam
    Kamal,  Alex Deng Microsoft Responsible AI {humia, rxu, derenlei, yaxi.li, mwang,
    yuetc, eskam, alex.deng}@microsoft.com
- en: '²²footnotetext: This is a preprint of an article that is under review.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '²²脚注: 这是一篇正在审查中的文章的预印本。'
- en: 1 Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: '![Refer to caption](img/825ceb90b7487e7457cbce123ae95ef5.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/825ceb90b7487e7457cbce123ae95ef5.png)'
- en: 'Figure 1: Hallucination detection with LLM as constrained reasoner: Grounding
    sources and hypothesis pairs are input into a SLM classifier. In most cases, if
    no hallucination is detected, the no hallucination decision will be returned to
    the client directly. However, if a hallucination is detected by SLM, an LLM-based
    constrained reasoner is employed to interpret the SLM’s decision. If the reasoner’s
    analysis aligns with the initial hallucination detection, this information, along
    with the original hypothesis, is relayed to the client. Otherwise, the potentially
    problematic hypothesis is filtered out or used as valuable feedback to further
    refine and improve the upstream SLM.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '图 1: 使用 LLM 作为受限推理器的幻觉检测：将基础来源和假设对输入到 SLM 分类器中。在大多数情况下，如果未检测到幻觉，将直接向客户端返回没有幻觉的决定。然而，如果
    SLM 检测到幻觉，则使用基于 LLM 的受限推理器来解释 SLM 的决定。如果推理器的分析与最初的幻觉检测结果一致，这些信息连同原始假设一并传达给客户端。否则，潜在的问题假设将被筛选或作为有价值的反馈，用于进一步优化和改进上游的
    SLM。'
- en: Despite Large Language Models (LLMs) having impressive capabilities Zhou et al.
    ([2020](#bib.bib40)); Wang et al. ([2021](#bib.bib33), [2020](#bib.bib34)); Pagnoni
    et al. ([2021](#bib.bib23)); Dziri et al. ([2021](#bib.bib4)), they are prone
    to hallucinations—responses that are ungrounded from the source Rashkin et al.
    ([2021](#bib.bib25)); Maynez et al. ([2020](#bib.bib18)); Nan et al. ([2021](#bib.bib22));
    Liu et al. ([2023](#bib.bib15)); Shi et al. ([2023](#bib.bib28)); Wei et al. ([2022](#bib.bib35))-undermining
    their reliability and making hallucination detection critical Kaddour et al. ([2023](#bib.bib9));
    Pal et al. ([2023](#bib.bib24)).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管大型语言模型（LLMs）具备令人印象深刻的能力 Zhou et al. ([2020](#bib.bib40)); Wang et al. ([2021](#bib.bib33),
    [2020](#bib.bib34)); Pagnoni et al. ([2021](#bib.bib23)); Dziri et al. ([2021](#bib.bib4))，它们仍然容易出现幻觉——即不基于来源的回应 Rashkin
    et al. ([2021](#bib.bib25)); Maynez et al. ([2020](#bib.bib18)); Nan et al. ([2021](#bib.bib22));
    Liu et al. ([2023](#bib.bib15)); Shi et al. ([2023](#bib.bib28)); Wei et al. ([2022](#bib.bib35))——这削弱了它们的可靠性，使得幻觉检测变得至关重要 Kaddour
    et al. ([2023](#bib.bib9)); Pal et al. ([2023](#bib.bib24))。
- en: Conventional hallucination detection methods, such as classification Kryściński
    et al. ([2019](#bib.bib10)); Zhou et al. ([2020](#bib.bib40)); Zha et al. ([2023](#bib.bib39))
    or ranking Falke et al. ([2019](#bib.bib5)) models, have been effective in their
    domains but often lack interpretability, which is an essential for user trust
    and mitigation Rudin et al. ([2022](#bib.bib26)). Given the recent widespread
    adoption of LLMs, researchers have explored using LLMs for hallucination detection Lei
    et al. ([2023](#bib.bib12)); Lin et al. ([2021](#bib.bib14)); Min et al. ([2023](#bib.bib20));
    Mündler et al. ([2023](#bib.bib21)), utilizing techniques like chain-of-thought
    reasoning Marasović et al. ([2021](#bib.bib17)); Kunz and Kuhlmann ([2024](#bib.bib11));
    Turpin et al. ([2024](#bib.bib32)); Shen et al. ([2023](#bib.bib27)), or finetuning
    an autonomous detection agent at Billion-parameter size Cheng et al. ([2024](#bib.bib3)),
    or checking consistency of different LLM responses per question Manakul et al.
    ([2023](#bib.bib16)). While LLM-based methods provide interpretability, they introduce
    latency challenges, due to their enormous size and the computational overhead
    of processing long source texts Becker et al. ([2024](#bib.bib1)); Jiang et al.
    ([2024](#bib.bib8)). This creates a major challenge for latency-sensitive real-time
    applications²²2[https://learn.microsoft.com/en-us/azure/ai-services/content-safety/concepts/groundedness](https://learn.microsoft.com/en-us/azure/ai-services/content-safety/concepts/groundedness).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的幻觉检测方法，例如分类 Kryściński et al. ([2019](#bib.bib10)); Zhou et al. ([2020](#bib.bib40));
    Zha et al. ([2023](#bib.bib39)) 或排名 Falke et al. ([2019](#bib.bib5)) 模型，在其领域中是有效的，但往往缺乏可解释性，而这对于用户信任和缓解措施至关重要 Rudin
    et al. ([2022](#bib.bib26))。鉴于LLMs近期的广泛应用，研究人员探索了利用LLMs进行幻觉检测 Lei et al. ([2023](#bib.bib12));
    Lin et al. ([2021](#bib.bib14)); Min et al. ([2023](#bib.bib20)); Mündler et al.
    ([2023](#bib.bib21))，采用链式思维推理技术 Marasović et al. ([2021](#bib.bib17)); Kunz and
    Kuhlmann ([2024](#bib.bib11)); Turpin et al. ([2024](#bib.bib32)); Shen et al.
    ([2023](#bib.bib27))，或者微调一个具备亿级参数的自主检测代理 Cheng et al. ([2024](#bib.bib3))，或者检查不同LLM对每个问题的回答一致性 Manakul
    et al. ([2023](#bib.bib16))。虽然基于LLM的方法提供了可解释性，但由于其庞大的规模和处理长源文本的计算开销，它们引入了延迟挑战 Becker
    et al. ([2024](#bib.bib1)); Jiang et al. ([2024](#bib.bib8))。这对延迟敏感的实时应用构成了重大挑战²²2[https://learn.microsoft.com/en-us/azure/ai-services/content-safety/concepts/groundedness](https://learn.microsoft.com/en-us/azure/ai-services/content-safety/concepts/groundedness)。
- en: 'We propose a novel workflow to address this challenge by balancing latency
    and interpretability. Our approach combines a small classification model, which
    in our case is a small language model (SLM), for initial hallucination detection.
    A downstream LLM module, termed a "constrained reasoner," then explains the detected
    hallucinations. This process is illustrated in Figure [1](#S1.F1 "Figure 1 ‣ 1
    Introduction ‣ SLM Meets LLM: Balancing Latency, Interpretability and Consistency
    in Hallucination Detection"). Considering the relatively infrequent occurrence
    of hallucinations in practical use Cao et al. ([2021](#bib.bib2)); Wu et al. ([2023](#bib.bib37));
    Gu et al. ([2020](#bib.bib7)), the average time cost of using LLMs solely for
    reasoning on hallucinated texts is manageable. Additionally, this approach leverages
    the pre-existing reasoning and explanation capabilities of LLMsMcCoy et al. ([2023](#bib.bib19)),
    obviating the need for substantial domain-specific data and significant computational
    cost on fine-tuning.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '我们提出了一种新颖的工作流程来应对这一挑战，平衡延迟和可解释性。我们的方法结合了一个小型分类模型，在我们的案例中是一个小型语言模型（SLM），用于初步幻觉检测。下游
    LLM 模块，称为“受限推理器”，然后解释检测到的幻觉。这个过程如图[1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ SLM
    Meets LLM: Balancing Latency, Interpretability and Consistency in Hallucination
    Detection")所示。考虑到幻觉在实际使用中的相对少见 Cao et al. ([2021](#bib.bib2)); Wu et al. ([2023](#bib.bib37));
    Gu et al. ([2020](#bib.bib7))，仅使用 LLM 对幻觉文本进行推理的平均时间成本是可管理的。此外，这种方法利用了 LLMs 已有的推理和解释能力
    McCoy et al. ([2023](#bib.bib19))，避免了大量领域特定数据和大量计算成本的微调需求。'
- en: Conventional studies have employed LLMs as end-to-end solutions Sobania et al.
    ([2022](#bib.bib30)); Goyal et al. ([2022](#bib.bib6)). More recently, [Shi et al.](#bib.bib29)
    explored the ability of LLMs to explain small classifiers through their latent
    features, showing promising results on non-reasoning tasks. In this study, we
    propose a novel framework to effectively apply this approach to hallucination
    detection.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 传统研究已经将大型语言模型（LLMs）作为端到端的解决方案使用 Sobania et al. ([2022](#bib.bib30)); Goyal et
    al. ([2022](#bib.bib6))。最近，[Shi et al.](#bib.bib29) 探索了 LLMs 通过其潜在特征解释小型分类器的能力，显示了在非推理任务上的良好结果。在这项研究中，我们提出了一个新颖的框架，以有效地将这种方法应用于幻觉检测。
- en: A potential issue for combining SLM and LLM is the inconsistency between the
    SLM’s decisions and the LLM’s explanations. Even self-rationalization models,
    where explanations are generated alongside primary outputs Wiegreffe et al. ([2021](#bib.bib36)),
    can produce explanations that do not align with the prediction Ye and Durrett
    ([2022](#bib.bib38)). In this study, we focus on addressing such issue in our
    proposed two-stage hallucination detection framework. Additionally, we analyze
    LLM reasonings in relation to SLM decisions and ground truth labels, highlighting
    the potential of LLMs as feedback mechanisms for refining detection processes.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 结合 SLM 和 LLM 的一个潜在问题是 SLM 决策与 LLM 解释之间的不一致。即使是自我理性化模型，其中解释与主要输出一起生成 Wiegreffe
    et al. ([2021](#bib.bib36))，也可能产生与预测不一致的解释 Ye and Durrett ([2022](#bib.bib38))。在这项研究中，我们集中解决了我们提出的两阶段幻觉检测框架中的这种问题。此外，我们分析了
    LLM 推理与 SLM 决策和真实标签的关系，突出了 LLM 作为反馈机制在优化检测过程中的潜力。
- en: 'Our contributions are two-fold: first, we introduce constrained reasoner for
    hallucination detection that balances latency and interpretability; second, we
    provide a comprehensive analysis of upstream-downstream consistency, offering
    practical solutions to enhance the alignment between detection and explanation.
    We demonstrate its effectiveness on multiple open-source datasets.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的贡献有两个方面：首先，我们引入了一种用于幻觉检测的受限推理器，它在延迟和可解释性之间取得平衡；其次，我们提供了对上游-下游一致性的全面分析，提出了增强检测与解释之间对齐的实际解决方案。我们在多个开源数据集上展示了其有效性。
- en: 2 Problem Definition
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 问题定义
- en: We denote the Grounding Source as $X$ and the model generated hypotheses $Y=(y_{1},y_{2},...,y_{n})$.
    The generation process can be expressed as a function $\mathcal{F}:X\rightarrow
    Y$, where $\mathcal{F}$ is the text generation model (e.g., summarization model).
    $y_{i}$, where $i\in[1,n]$, is hallucinated if conflicts with or cannot be verified
    against $X$.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将基础源表示为 $X$，模型生成的假设为 $Y=(y_{1},y_{2},...,y_{n})$。生成过程可以表示为一个函数 $\mathcal{F}:X\rightarrow
    Y$，其中 $\mathcal{F}$ 是文本生成模型（例如，总结模型）。$y_{i}$，其中 $i\in[1,n]$，如果与 $X$ 冲突或无法验证，则为幻觉。
- en: 'To balance latency and interpretability in hallucination detection, we propose
    a novel two-stage framework: a SLM for hallucination detection followed by a LLM-based
    reasoning module, termed "constrained reasoner". The upstream detection can be
    formulated as: $\mathcal{D}:(X,Y)\rightarrow J$ where $J=(j_{1},j_{2},...,j_{n})$
    represents the binary labels decided by the detector $\mathcal{D}$. The subset
    of response sentences $Y$ detected as hallucinations by $\mathcal{D}$ is denoted
    as $H=\{y_{k}\in Y\mid j_{k}=\text{hallucination}\}=(h_{1},...,h_{m})$, where
    $m\leq n$. Only detected potential hallucinations $H$ are passed to downstream
    reasoning module. The constrained reasoner $\mathcal{R}$ provides explanations
    for hallucinations flagged by upstream, $\mathcal{R}:(X,H)\rightarrow E$, where
    $E=(e_{1},...,e_{m})$ contains $m$ explanations, each $e_{k},\text{where }k\in[1,m]$
    corresponding to a hallucinated sentence $h_{k}$ detected by $\mathcal{D}$. $\mathcal{R}$
    is called constrained reasoner because it operates under the given constraint
    that $h_{i}$ is hallucinated, as determined by $\mathcal{D}$.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在幻觉检测中平衡延迟和可解释性，我们提出了一种新颖的两阶段框架：首先是用于幻觉检测的SLM，然后是基于LLM的推理模块，称为“约束推理器”。上游检测可以表示为：$\mathcal{D}:(X,Y)\rightarrow
    J$，其中$J=(j_{1},j_{2},...,j_{n})$表示由检测器$\mathcal{D}$决定的二元标签。由$\mathcal{D}$检测出的响应句子$Y$的子集被表示为$H=\{y_{k}\in
    Y\mid j_{k}=\text{hallucination}\}=(h_{1},...,h_{m})$，其中$m\leq n$。只有检测到的潜在幻觉$H$被传递给下游推理模块。约束推理器$\mathcal{R}$为上游标记的幻觉提供解释，$\mathcal{R}:(X,H)\rightarrow
    E$，其中$E=(e_{1},...,e_{m})$包含$m$个解释，每个$e_{k}$，其中$k\in[1,m]$，对应于检测到的幻觉句子$h_{k}$。$\mathcal{R}$被称为约束推理器，因为它在给定$h_{i}$被判定为幻觉的约束下进行操作，这由$\mathcal{D}$确定。
- en: 'However, even in self-rationalization models, reasoning results $E$ may not
    align with detection results $J$ even they are generated together Wiegreffe et al.
    ([2021](#bib.bib36)); Ye and Durrett ([2022](#bib.bib38)). The inconsistency can
    be more pronounced in the two-stage frame, where explanations are provided post
    hoc. We define the real intention in explanation $E$ as $S=(s_{1},...,s_{m})$.
    Reasons inconsistent with the upstream decision is thus $\{e_{k}\in E$, where
    $s_{k}=\text{non-hallucination}\}$ (as our framework only passes $\mathcal{R}$
    the detected hallucinations to explan due to the latency concern). There are three
    aspects we want to study regarding the consistency of the constrained reasoner
    $\mathcal{R}$:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，即使在自我理性化模型中，推理结果$E$也可能与检测结果$J$不一致，即使它们是一起生成的 Wiegreffe 等人 ([2021](#bib.bib36))；Ye
    和 Durrett ([2022](#bib.bib38))。这种不一致在两阶段框架中可能更加明显，因为解释是在事后提供的。我们定义解释$E$中的真实意图为$S=(s_{1},...,s_{m})$。与上游决策不一致的理由为$\{e_{k}\in
    E$，其中$s_{k}=\text{non-hallucination}\}$（由于延迟问题，我们的框架仅将检测到的幻觉传递给$\mathcal{R}$以进行解释）。我们希望研究三个方面关于约束推理器$\mathcal{R}$的一致性：
- en: Inconsistency Identification We design a flagging mechanism to ask LLM-based
    $\mathcal{R}$ to signal when it judges the hypothesis as non-hallucination and
    thus unable to provide explanation why the hypothesis is hallucinated. Therefore,
    $e_{k}$ is semi-structured consisting of a free-text reason $t_{k}$ and a flag
    $\hat{s}_{k}$ indicating whether $\mathcal{R}$ thinks the text is hallucination.
    Formally, $e_{k}=(t_{k},\hat{s}_{k})$. We conduct human evaluation, by asking
    annotators to careful read $t_{k}$ and mark $s_{k}$ whether the reason is explaining
    the hypothesis is hallucination. Then, we measure effectiveness of the flagging
    mechanism.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 不一致性识别 我们设计了一种标记机制，要求基于LLM的$\mathcal{R}$在判断假设为非幻觉时发出信号，从而无法提供解释为什么假设是幻觉。因此，$e_{k}$是半结构化的，由一个自由文本的理由$t_{k}$和一个标志$\hat{s}_{k}$组成，标志表示$\mathcal{R}$是否认为文本是幻觉。形式上，$e_{k}=(t_{k},\hat{s}_{k})$。我们进行人工评估，要求标注者仔细阅读$t_{k}$并标记$s_{k}$，以确定理由是否解释了假设是幻觉。然后，我们衡量标记机制的有效性。
- en: Inconsistency Filtering The simplest mitigation for inconsistent reasonings
    is to filter them out. We assess the reduction of inconsistencies after filtering
    flagged explanations, i.e. ones with $\hat{s}_{k}=\text{non-hallucination}$. We
    compare the remaining true inconsistency rates, i.e. the rate of $s_{k}=\text{non-hallucination}$
    as baseline.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 不一致性过滤 解决不一致推理的最简单方法是将其过滤掉。我们评估在过滤标记的解释后不一致性的减少，即那些具有$\hat{s}_{k}=\text{non-hallucination}$的解释。我们比较剩余的真实不一致性率，即$s_{k}=\text{non-hallucination}$的比率作为基线。
- en: Reasoning Feedback The ground truth label for each $y_{i}$ is $g_{i}$, but in
    practice, $j_{i}$ may differ from $g_{i}$ due to SLM imperfections. We explore
    the potential of $\mathcal{R}$ as a feedback mechanism to improve $\mathcal{D}$.
    We compare the flagged inconsistencies, $\hat{s}_{k}$, against the ground truth
    $g_{k}$ to assess $\mathcal{R}$’s performance in identifying non-hallucinations.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 推理反馈 每个 $y_{i}$ 的真实标签是 $g_{i}$，但实际上，由于SLM的不完美，$j_{i}$ 可能与 $g_{i}$ 不同。我们探索了 $\mathcal{R}$
    作为反馈机制以改进 $\mathcal{D}$ 的潜力。我们将标记的不一致性 $\hat{s}_{k}$ 与真实标签 $g_{k}$ 进行比较，以评估 $\mathcal{R}$
    在识别非幻觉方面的表现。
- en: 3 Experiment
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 实验
- en: 'Our experiment is designed to study the consistency of reasoning within the
    proposed hallucination detection framework and effective approaches to filter
    inconsistencies. Additionally, we explore the potential of LLMs as feedback mechanisms
    for refining the detection process. We employ GPT4-turbo as $\mathcal{R}$ to elucidate
    the rationale behind hallucination determinations, using the temperature of 0
    and top-p of 0.6\. The experiments are conducted across four datasets: NHNET Shen
    et al. ([2023](#bib.bib27)), FEVER Thorne et al. ([2018](#bib.bib31)), HaluQA
    and HaluSum Li et al. ([2023](#bib.bib13)). We use complete test set of NHNet.
    Due to the size of rest three datasets and GPT resource limitations, we sample
    3000 data per dataset for experimentation.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实验旨在研究提出的幻觉检测框架内推理的一致性以及有效的过滤不一致的方法。此外，我们探索了LLM作为改进检测过程的反馈机制的潜力。我们使用GPT4-turbo作为
    $\mathcal{R}$ 来阐明幻觉判定背后的理由，温度设为0，top-p 设为0.6。实验在四个数据集上进行：NHNET Shen et al. ([2023](#bib.bib27))，FEVER
    Thorne et al. ([2018](#bib.bib31))，HaluQA 和 HaluSum Li et al. ([2023](#bib.bib13))。我们使用NHNet的完整测试集。由于其他三个数据集的规模和GPT资源的限制，我们为每个数据集抽取了3000个数据进行实验。
- en: 'To simulate an imperfect SLM classifier, we sample both hallucinated and non-hallucinated
    responses from the datasets, assuming the upstream label as hallucination. Thus
    the groundtruth hallucinated text are the simulated true positive cases, and the
    groundtruth non-hallucinated texts are the the simulated false positive cases.
    The specific ratio of true and false positives from the SLM is irrelevant to our
    study, as our focus is on the inconsistencies of the constrained reasoner rather
    than the performance of the detection algorithm. See appendix [A.1](#A1.SS1 "A.1
    Data distribution ‣ Appendix A Appendix ‣ SLM Meets LLM: Balancing Latency, Interpretability
    and Consistency in Hallucination Detection") for the distribution of hallucinated
    and non-hallucinated examples in each dataset. Human annotators assess whether
    each explanation $e_{k}$ truly explains why a hypothesis is hallucinated or whether
    it actually justifies that the text should not be considered a hallucination.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '为了模拟一个不完美的SLM分类器，我们从数据集中抽取了幻觉和非幻觉的响应，假设上游标签为幻觉。因此，真实的幻觉文本为模拟的真正例，而真实的非幻觉文本为模拟的假阳性。SLM的真正例和假阳性的具体比例与我们的研究无关，因为我们关注的是受限推理器的一致性，而不是检测算法的性能。有关每个数据集中幻觉和非幻觉示例的分布，请参见附录[A.1](#A1.SS1
    "A.1 数据分布 ‣ 附录 A 附录 ‣ SLM 遇见 LLM: 平衡延迟、可解释性和一致性以检测幻觉")。人工标注者评估每个解释 $e_{k}$ 是否真正解释了一个假设为何为幻觉，或是否实际证明该文本不应被视为幻觉。'
- en: 3.1 Methodology
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 方法论
- en: '| Approach | Fallback when unable to explain | Categorize Hallucinations |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 无法解释时的回退 | 幻觉分类 |'
- en: '| Vanilla | No | No |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 原版 | 否 | 否 |'
- en: '| Fallback | Yes | No |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 回退 | 是 | 否 |'
- en: '| Categorized | Yes | Yes |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 分类 | 是 | 是 |'
- en: 'Table 1: Difference between the three main approaches.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '表 1: 三种主要方法之间的差异。'
- en: 'The experiment focuses on three primary approaches, with their key distinctions
    summarized in Table [1](#S3.T1 "Table 1 ‣ 3.1 Methodology ‣ 3 Experiment ‣ SLM
    Meets LLM: Balancing Latency, Interpretability and Consistency in Hallucination
    Detection") (The full prompts are provided in Appendix [A.2](#A1.SS2 "A.2 Constrained
    Reasoner Approaches ‣ Appendix A Appendix ‣ SLM Meets LLM: Balancing Latency,
    Interpretability and Consistency in Hallucination Detection")).'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '实验关注三种主要方法，其关键区别在表[1](#S3.T1 "表 1 ‣ 3.1 方法论 ‣ 3 实验 ‣ SLM 遇见 LLM: 平衡延迟、可解释性和一致性以检测幻觉")中总结（完整提示见附录[A.2](#A1.SS2
    "A.2 受限推理方法 ‣ 附录 A 附录 ‣ SLM 遇见 LLM: 平衡延迟、可解释性和一致性以检测幻觉")）。'
- en: Vanilla approach simply instructs $\mathcal{R}$ to explain why the text was
    detected as hallucination by $\mathcal{D}$. It does not address how to handle
    inconsistency, i.e. disagreements with the upstream decision. As the reasonings
    are free-text, there is no straightforward mechanism to identify when inconsistencies
    arise. If contradictory explanations are generated, they will be presented to
    the user, which can undermine user trust and experience. It is served as a baseline
    for Inconsistency Filtering comparison.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 原始方法简单地指示 $\mathcal{R}$ 解释为什么文本被 $\mathcal{D}$ 检测为幻觉。它没有解决如何处理不一致性，即与上游决策的分歧。由于推理是自由文本，没有直接的机制来识别何时出现不一致。如果生成了矛盾的解释，它们将呈现给用户，这可能会破坏用户的信任和体验。它作为不一致性过滤比较的基线。
- en: Fallback approach introduces a flagging mechanism whereby $\mathcal{R}$ can
    respond with "UNKNOWN" to indicate $\hat{s}_{k}=\text{non-hallucination}$ thus
    it cannot provide a suitable explanation. This flag helps signal potential inconsistencies,
    enabling developers to address them effectively.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 回退方法引入了一个标记机制，其中 $\mathcal{R}$ 可以响应 "UNKNOWN" 来表示 $\hat{s}_{k}=\text{non-hallucination}$，因此无法提供合适的解释。这个标记有助于指示潜在的不一致性，使开发人员能够有效地解决这些问题。
- en: Categorized approach refines the flagging mechanism by incorporating more granular
    hallucination categories. These categories are derived from the analysis of real
    hallucination data. Among those, a specific category $hallu_{12}$ is used to signal
    inconsistencies where $\hat{s}_{k}=\text{non-hallucination}$. By exposing the
    reasoner to these detailed categories, the goal is to enhance $\mathcal{R}$’s
    understanding of hallucinations and improve its ability to correctly identify
    true hallucinations.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 分类方法通过引入更细化的幻觉类别来优化标记机制。这些类别源于对真实幻觉数据的分析。在这些类别中，特定的类别 $hallu_{12}$ 被用来指示不一致性，其中
    $\hat{s}_{k}=\text{non-hallucination}$。通过将推理器暴露于这些详细类别，目标是增强 $\mathcal{R}$ 对幻觉的理解，并提高其正确识别真实幻觉的能力。
- en: 4 Result and Discussion
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 结果与讨论
- en: 'Inconsistency Identification Table [2](#S4.T2 "Table 2 ‣ 4 Result and Discussion
    ‣ SLM Meets LLM: Balancing Latency, Interpretability and Consistency in Hallucination
    Detection") illustrates the performance of identifying real inconsistent reasonings
    using the designed flags. Both methods demonstrate strong precision. However,
    the Fallback approach exhibits poor recall, i.e. often failing to signal inconsistent
    reasons with the designed "UNKNOWN" flag. In contrast, Categorized approach effectively
    categorized the majority of inconsistent reasonings under the $hallu_{12}$ flag,
    making it easier to filter or mitigate them for downstream usage.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '不一致性识别表 [2](#S4.T2 "表 2 ‣ 4 结果与讨论 ‣ SLM Meets LLM: 在幻觉检测中平衡延迟、可解释性和一致性") 说明了使用设计的标记识别真实不一致推理的性能。两种方法都显示出较强的精确度。然而，回退方法表现出较差的召回率，即经常无法用设计的
    "UNKNOWN" 标记来指示不一致的原因。相比之下，分类方法有效地将大多数不一致推理归类于 $hallu_{12}$ 标记，使得在下游使用中更容易筛选或缓解这些问题。'
- en: '| Dataset | Approach | Precision | Recall | F1 |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 方法 | 精确度 | 召回率 | F1 |'
- en: '| FEVER | Fallback | 0.997 | 0.212 | 0.350 |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| FEVER | 回退 | 0.997 | 0.212 | 0.350 |'
- en: '| Categorized | 1.000 | 0.997 | 0.998 |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 分类 | 1.000 | 0.997 | 0.998 |'
- en: '| NHNET | Fallback | 0.979 | 0.380 | 0.547 |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| NHNET | 回退 | 0.979 | 0.380 | 0.547 |'
- en: '| Categorized | 0.998 | 0.998 | 0.998 |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 分类 | 0.998 | 0.998 | 0.998 |'
- en: '| HaluQA | Fallback | 0.962 | 0.418 | 0.583 |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| HaluQA | 回退 | 0.962 | 0.418 | 0.583 |'
- en: '| Categorized | 1.000 | 0.998 | 0.999 |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 分类 | 1.000 | 0.998 | 0.999 |'
- en: '| HaluSum | Fallback | 1.000 | 0.077 | 0.143 |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| HaluSum | 回退 | 1.000 | 0.077 | 0.143 |'
- en: '| Categorized | 1.000 | 0.999 | 0.999 |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 分类 | 1.000 | 0.999 | 0.999 |'
- en: 'Table 2: Inconsistency identification performance based on human evaluations.
    Categorized approach achieves close to perfect performance.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '表 2: 基于人工评估的不一致性识别性能。分类方法达到了接近完美的性能。'
- en: 'Inconsistency Filtering Filtering reasonings with the designed flag effectively
    reduced inconsistencies between the upstream detection and constrained reasoner
    $\mathcal{R}$, as illustrated in Figure [2](#S4.F2 "Figure 2 ‣ 4 Result and Discussion
    ‣ SLM Meets LLM: Balancing Latency, Interpretability and Consistency in Hallucination
    Detection"). The Vanilla approach, as expected, showed a high inconsistency rate.
    While the introduction of the "UNKNOWN" category in the Fallback approach reduced
    inconsistencies, its effectiveness was limited by low recall as mentioned above.
    In contrast, the Categorized approach achieved a dramatic reduction across all
    datasets, with a post-filtering rate as low as $\sim 0.1-1\%$, effectively enhancing
    the workflow’s consistency.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '不一致性过滤 设计的标志有效地减少了上游检测与约束推理器$\mathcal{R}$之间的不一致性，如图[2](#S4.F2 "Figure 2 ‣ 4
    Result and Discussion ‣ SLM Meets LLM: Balancing Latency, Interpretability and
    Consistency in Hallucination Detection")所示。正如预期的那样，Vanilla方法显示了高的不一致率。虽然在回退方法中引入“UNKNOWN”类别减少了不一致性，但其效果受到低召回率的限制。相比之下，分类方法在所有数据集中都实现了显著减少，过滤后的不一致率低至$\sim
    0.1-1\%$，有效提高了工作流程的一致性。'
- en: '![Refer to caption](img/2f006be5e501597d79570f093baca764.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/2f006be5e501597d79570f093baca764.png)'
- en: 'Figure 2: Inconsistency rate comparison: Categorized approach consistently
    outperforms both the Vanilla and Fallback methods with significant drop in inconsistency
    after applying filtering.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：不一致率比较：分类方法在应用过滤后不一致性显著降低，持续优于Vanilla和回退方法。
- en: '| Dataset | Approach | Precision | Recall | F1 |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 方法 | 精确度 | 召回率 | F1 |'
- en: '| FEVER | Fallback | 1.000 | 0.155 | 0.268 |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| FEVER | 回退 | 1.000 | 0.155 | 0.268 |'
- en: '| Categorized | 0.992 | 0.778 | 0.872 |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 分类方法 | 0.992 | 0.778 | 0.872 |'
- en: '| NHNET | Fallback | 0.936 | 0.100 | 0.181 |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| NHNET | 回退 | 0.936 | 0.100 | 0.181 |'
- en: '| Categorized | 0.807 | 0.820 | 0.813 |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 分类方法 | 0.807 | 0.820 | 0.813 |'
- en: '| HaluQA | Fallback | 0.968 | 0.201 | 0.333 |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| HaluQA | 回退 | 0.968 | 0.201 | 0.333 |'
- en: '| Categorized | 0.901 | 0.610 | 0.727 |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 分类方法 | 0.901 | 0.610 | 0.727 |'
- en: '| HaluSum | Fallback | 0.792 | 0.013 | 0.026 |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| HaluSum | 回退 | 0.792 | 0.013 | 0.026 |'
- en: '| Categorized | 0.763 | 0.669 | 0.713 |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| 分类方法 | 0.763 | 0.669 | 0.713 |'
- en: 'Table 3: Feedback results based on LLM constrained reasoning and ground truth
    labels. Categorized approach consistently achieves higher recall and F1.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：基于LLM约束推理和真实标签的反馈结果。分类方法持续实现了更高的召回率和F1得分。
- en: 'Reasoning Feedback As results shown in Table [3](#S4.T3 "Table 3 ‣ 4 Result
    and Discussion ‣ SLM Meets LLM: Balancing Latency, Interpretability and Consistency
    in Hallucination Detection"), the Categorized approach demonstrated strong potential
    as feedback mechanism, outperforming the Fallback method with high recall. It
    achieves a macro-average F1 score of 0.781\. This indicates its capability to
    accurately identify false positives from the SLM, making it a promising feedback
    mechanism for improving the upstream model—an area worth further exploration.
    The high inconsistency rate observed in the Categorized approach before filtering,
    as shown in Figure [2](#S4.F2 "Figure 2 ‣ 4 Result and Discussion ‣ SLM Meets
    LLM: Balancing Latency, Interpretability and Consistency in Hallucination Detection"),
    highlights the ability of LLMs like GPT to accurately identify true hallucinations
    when refined hallucination categories are provided, as indicated by the high F1
    in Table [3](#S4.T3 "Table 3 ‣ 4 Result and Discussion ‣ SLM Meets LLM: Balancing
    Latency, Interpretability and Consistency in Hallucination Detection"). This suggests
    that LLM can maintain correct judgments without being easily influenced or swayed
    by specific instructions.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '推理反馈 如表格[3](#S4.T3 "Table 3 ‣ 4 Result and Discussion ‣ SLM Meets LLM: Balancing
    Latency, Interpretability and Consistency in Hallucination Detection")所示，分类方法作为反馈机制展示了强大的潜力，超越了回退方法，具有较高的召回率。它达到了宏观平均F1得分0.781。这表明它能够准确识别SLM中的假阳性，使其成为改善上游模型的有前景的反馈机制——这是一个值得深入探讨的领域。如图[2](#S4.F2
    "Figure 2 ‣ 4 Result and Discussion ‣ SLM Meets LLM: Balancing Latency, Interpretability
    and Consistency in Hallucination Detection")所示，在过滤之前观察到的分类方法的高不一致率，突显了像GPT这样的LLM在提供了精炼的幻觉类别时准确识别真实幻觉的能力，正如表格[3](#S4.T3
    "Table 3 ‣ 4 Result and Discussion ‣ SLM Meets LLM: Balancing Latency, Interpretability
    and Consistency in Hallucination Detection")中的高F1所示。这表明LLM可以在不容易被特定指令影响或左右的情况下维持正确的判断。'
- en: 5 Conclusion
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论
- en: In this study, we introduce a practical framework for efficient and interpretable
    hallucination detection by combining SLM for detection with LLM for constrained
    reasoning. Our Categorized prompting strategy with filtering effectively aligns
    LLM explanations with SLM decisions, empirically proven effective on 4 hallucination
    and factual consistency datasets. Furthermore, this strategy shows promise as
    a feedback mechanism for refining SLMs, offering a path toward more robust and
    adaptive systems. While our experiments focus on real-time interpretable hallucination
    detection, the insights gained are broadly applicable, shades lights in improving
    classification decision systems and enhancing SLM capabilities through LLM-based
    constrained interpretation.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项研究中，我们引入了一个通过将 SLM 用于检测与 LLM 用于受限推理相结合的高效且可解释的幻觉检测实用框架。我们的分类提示策略与过滤有效地将 LLM
    解释与 SLM 决策对齐，经过实证证明在4个幻觉和事实一致性数据集上有效。此外，这一策略作为一个反馈机制，展示了作为完善 SLM 的前景，为更强大和适应性更强的系统提供了路径。虽然我们的实验集中于实时可解释的幻觉检测，但所获得的见解具有广泛的适用性，照亮了改进分类决策系统和通过
    LLM 基于约束解释增强 SLM 能力的方向。
- en: References
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Becker et al. (2024) Jonas Becker, Jan Philip Wahle, Bela Gipp, and Terry Ruas.
    2024. Text generation: A systematic literature review of tasks, evaluation, and
    challenges. *arXiv preprint arXiv:2405.15604*.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Becker et al. (2024) Jonas Becker, Jan Philip Wahle, Bela Gipp, and Terry Ruas.
    2024. 文本生成：任务、评估和挑战的系统文献综述。*arXiv 预印本 arXiv:2405.15604*。
- en: Cao et al. (2021) Meng Cao, Yue Dong, and Jackie Chi Kit Cheung. 2021. Hallucinated
    but factual! inspecting the factuality of hallucinations in abstractive summarization.
    *arXiv preprint arXiv:2109.09784*.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cao et al. (2021) Meng Cao, Yue Dong, and Jackie Chi Kit Cheung. 2021. 幻觉却真实！检查抽象总结中幻觉的事实性。*arXiv
    预印本 arXiv:2109.09784*。
- en: Cheng et al. (2024) Xiaoxue Cheng, Junyi Li, Wayne Xin Zhao, Hongzhi Zhang,
    Fuzheng Zhang, Di Zhang, Kun Gai, and Ji-Rong Wen. 2024. Small agent can also
    rock! empowering small language models as hallucination detector. *arXiv preprint
    arXiv:2406.11277*.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cheng et al. (2024) Xiaoxue Cheng, Junyi Li, Wayne Xin Zhao, Hongzhi Zhang,
    Fuzheng Zhang, Di Zhang, Kun Gai, and Ji-Rong Wen. 2024. 小型代理也能出彩！将小型语言模型赋能为幻觉检测器。*arXiv
    预印本 arXiv:2406.11277*。
- en: 'Dziri et al. (2021) Nouha Dziri, Hannah Rashkin, Tal Linzen, and David Reitter.
    2021. Evaluating groundedness in dialogue systems: The begin benchmark. *arXiv
    preprint arXiv:2105.00071*, 4.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dziri et al. (2021) Nouha Dziri, Hannah Rashkin, Tal Linzen, and David Reitter.
    2021. 对话系统中的基础性评估：Begin 基准。*arXiv 预印本 arXiv:2105.00071*，第4页。
- en: 'Falke et al. (2019) Tobias Falke, Leonardo FR Ribeiro, Prasetya Ajie Utama,
    Ido Dagan, and Iryna Gurevych. 2019. Ranking generated summaries by correctness:
    An interesting but challenging application for natural language inference. In
    *Proceedings of the 57th annual meeting of the association for computational linguistics*,
    pages 2214–2220.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Falke et al. (2019) Tobias Falke, Leonardo FR Ribeiro, Prasetya Ajie Utama,
    Ido Dagan, and Iryna Gurevych. 2019. 按正确性排名生成的总结：自然语言推理的一个有趣但具有挑战性的应用。见于 *第57届计算语言学协会年会论文集*，第2214–2220页。
- en: Goyal et al. (2022) Tanya Goyal, Junyi Jessy Li, and Greg Durrett. 2022. News
    summarization and evaluation in the era of gpt-3. *arXiv preprint arXiv:2209.12356*.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goyal et al. (2022) Tanya Goyal, Junyi Jessy Li, and Greg Durrett. 2022. GPT-3
    时代的新闻总结与评估。*arXiv 预印本 arXiv:2209.12356*。
- en: Gu et al. (2020) Xiaotao Gu, Yuning Mao, Jiawei Han, Jialu Liu, You Wu, Cong
    Yu, Daniel Finnie, Hongkun Yu, Jiaqi Zhai, and Nicholas Zukoski. 2020. Generating
    representative headlines for news stories. In *Proceedings of The Web Conference
    2020*, pages 1773–1784.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gu et al. (2020) Xiaotao Gu, Yuning Mao, Jiawei Han, Jialu Liu, You Wu, Cong
    Yu, Daniel Finnie, Hongkun Yu, Jiaqi Zhai, and Nicholas Zukoski. 2020. 生成新闻故事的代表性标题。见于
    *The Web Conference 2020 论文集*，第1773–1784页。
- en: 'Jiang et al. (2024) Ziyan Jiang, Xueguang Ma, and Wenhu Chen. 2024. Longrag:
    Enhancing retrieval-augmented generation with long-context llms. *arXiv preprint
    arXiv:2406.15319*.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang et al. (2024) Ziyan Jiang, Xueguang Ma, and Wenhu Chen. 2024. Longrag：通过长上下文
    LLM 增强检索增强生成。*arXiv 预印本 arXiv:2406.15319*。
- en: Kaddour et al. (2023) Jean Kaddour, Joshua Harris, Maximilian Mozes, Herbie
    Bradley, Roberta Raileanu, and Robert McHardy. 2023. Challenges and applications
    of large language models. *arXiv preprint arXiv:2307.10169*.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kaddour et al. (2023) Jean Kaddour, Joshua Harris, Maximilian Mozes, Herbie
    Bradley, Roberta Raileanu, and Robert McHardy. 2023. 大语言模型的挑战与应用。*arXiv 预印本 arXiv:2307.10169*。
- en: Kryściński et al. (2019) Wojciech Kryściński, Bryan McCann, Caiming Xiong, and
    Richard Socher. 2019. Evaluating the factual consistency of abstractive text summarization.
    *arXiv preprint arXiv:1910.12840*.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kryściński et al. (2019) Wojciech Kryściński, Bryan McCann, Caiming Xiong, and
    Richard Socher. 2019. 评估抽象文本总结的事实一致性。*arXiv 预印本 arXiv:1910.12840*。
- en: Kunz and Kuhlmann (2024) Jenny Kunz and Marco Kuhlmann. 2024. Properties and
    challenges of llm-generated explanations. *arXiv preprint arXiv:2402.10532*.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kunz and Kuhlmann (2024) Jenny Kunz 和 Marco Kuhlmann. 2024. 大型语言模型生成解释的特性与挑战。*arXiv
    预印本 arXiv:2402.10532*。
- en: Lei et al. (2023) Deren Lei, Yaxi Li, Mengya Hu, Mingyu Wang, Vincent Yun, Emily
    Ching, and Eslam Kamal. 2023. Chain of natural language inference for reducing
    large language model ungrounded hallucinations. *arXiv e-prints*, pages arXiv–2310.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lei et al. (2023) Deren Lei, Yaxi Li, Mengya Hu, Mingyu Wang, Vincent Yun, Emily
    Ching, 和 Eslam Kamal. 2023. 自然语言推理链用于减少大型语言模型的无根幻觉。*arXiv e-prints*, 页码 arXiv–2310。
- en: 'Li et al. (2023) Junyi Li, Xiaoxue Cheng, Wayne Xin Zhao, Jian-Yun Nie, and
    Ji-Rong Wen. 2023. [Halueval: A large-scale hallucination evaluation benchmark
    for large language models](https://arxiv.org/abs/2305.11747).'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li et al. (2023) Junyi Li, Xiaoxue Cheng, Wayne Xin Zhao, Jian-Yun Nie, 和 Ji-Rong
    Wen. 2023. [Halueval: 大规模幻觉评估基准，用于大型语言模型](https://arxiv.org/abs/2305.11747)。'
- en: 'Lin et al. (2021) Stephanie Lin, Jacob Hilton, and Owain Evans. 2021. Truthfulqa:
    Measuring how models mimic human falsehoods. *arXiv preprint arXiv:2109.07958*.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lin et al. (2021) Stephanie Lin, Jacob Hilton, 和 Owain Evans. 2021. Truthfulqa:
    测量模型如何模仿人类的虚假信息。*arXiv 预印本 arXiv:2109.07958*。'
- en: 'Liu et al. (2023) Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele
    Bevilacqua, Fabio Petroni, and Percy Liang. 2023. Lost in the middle: How language
    models use long contexts. *arXiv preprint arXiv:2307.03172*.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2023) Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele
    Bevilacqua, Fabio Petroni, 和 Percy Liang. 2023. 在中间迷失：语言模型如何使用长上下文。*arXiv 预印本
    arXiv:2307.03172*。
- en: 'Manakul et al. (2023) Potsawee Manakul, Adian Liusie, and Mark Gales. 2023.
    [SelfCheckGPT: Zero-resource black-box hallucination detection for generative
    large language models](https://doi.org/10.18653/v1/2023.emnlp-main.557). In *Proceedings
    of the 2023 Conference on Empirical Methods in Natural Language Processing*, pages
    9004–9017, Singapore. Association for Computational Linguistics.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Manakul et al. (2023) Potsawee Manakul, Adian Liusie, 和 Mark Gales. 2023. [SelfCheckGPT:
    零资源黑箱幻觉检测用于生成大型语言模型](https://doi.org/10.18653/v1/2023.emnlp-main.557)。在*2023年自然语言处理实证方法会议论文集*，页码
    9004–9017，新加坡。计算语言学协会。'
- en: Marasović et al. (2021) Ana Marasović, Iz Beltagy, Doug Downey, and Matthew E
    Peters. 2021. Few-shot self-rationalization with natural language prompts. *arXiv
    preprint arXiv:2111.08284*.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Marasović et al. (2021) Ana Marasović, Iz Beltagy, Doug Downey, 和 Matthew E
    Peters. 2021. 少量自我理性化与自然语言提示。*arXiv 预印本 arXiv:2111.08284*。
- en: Maynez et al. (2020) Joshua Maynez, Shashi Narayan, Bernd Bohnet, and Ryan McDonald.
    2020. On faithfulness and factuality in abstractive summarization. In *Proceedings
    of the 58th Annual Meeting of the Association for Computational Linguistics*,
    pages 1906–1919.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Maynez et al. (2020) Joshua Maynez, Shashi Narayan, Bernd Bohnet, 和 Ryan McDonald.
    2020. 摘要总结中的忠实性和事实性。在*第58届计算语言学协会年会论文集*，页码 1906–1919。
- en: 'McCoy et al. (2023) R Thomas McCoy, Shunyu Yao, Dan Friedman, Matthew Hardy,
    and Thomas L Griffiths. 2023. Embers of autoregression: Understanding large language
    models through the problem they are trained to solve. *arXiv preprint arXiv:2309.13638*.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: McCoy et al. (2023) R Thomas McCoy, Shunyu Yao, Dan Friedman, Matthew Hardy,
    和 Thomas L Griffiths. 2023. 自回归的余烬：通过问题理解大型语言模型的训练目标。*arXiv 预印本 arXiv:2309.13638*。
- en: 'Min et al. (2023) Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen-tau
    Yih, Pang Wei Koh, Mohit Iyyer, Luke Zettlemoyer, and Hannaneh Hajishirzi. 2023.
    Factscore: Fine-grained atomic evaluation of factual precision in long form text
    generation. *arXiv preprint arXiv:2305.14251*.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Min et al. (2023) Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen-tau
    Yih, Pang Wei Koh, Mohit Iyyer, Luke Zettlemoyer, 和 Hannaneh Hajishirzi. 2023.
    Factscore: 长文本生成中的事实精度的细粒度原子评估。*arXiv 预印本 arXiv:2305.14251*。'
- en: 'Mündler et al. (2023) Niels Mündler, Jingxuan He, Slobodan Jenko, and Martin
    Vechev. 2023. Self-contradictory hallucinations of large language models: Evaluation,
    detection and mitigation. *arXiv preprint arXiv:2305.15852*.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mündler et al. (2023) Niels Mündler, Jingxuan He, Slobodan Jenko, 和 Martin Vechev.
    2023. 大型语言模型的自我矛盾幻觉：评估、检测和缓解。*arXiv 预印本 arXiv:2305.15852*。
- en: 'Nan et al. (2021) Feng Nan, Ramesh Nallapati, Zhiguo Wang, Cicero dos Santos,
    Henghui Zhu, Dejiao Zhang, Kathleen Mckeown, and Bing Xiang. 2021. Entity-level
    factual consistency of abstractive text summarization. In *Proceedings of the
    16th Conference of the European Chapter of the Association for Computational Linguistics:
    Main Volume*, pages 2727–2733.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nan et al. (2021) Feng Nan, Ramesh Nallapati, Zhiguo Wang, Cicero dos Santos,
    Henghui Zhu, Dejiao Zhang, Kathleen Mckeown, 和 Bing Xiang. 2021. 抽象文本摘要的实体级事实一致性。在*第16届欧洲计算语言学协会会议论文集：主卷*，页码
    2727–2733。
- en: 'Pagnoni et al. (2021) Artidoro Pagnoni, Vidhisha Balachandran, and Yulia Tsvetkov.
    2021. Understanding factuality in abstractive summarization with frank: A benchmark
    for factuality metrics. *arXiv preprint arXiv:2104.13346*.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pagnoni et al. (2021) Artidoro Pagnoni, Vidhisha Balachandran, 和 Yulia Tsvetkov.
    2021. 使用 Frank 理解抽象总结中的事实性：一个事实性度量的基准。*arXiv 预印本 arXiv:2104.13346*。
- en: 'Pal et al. (2023) Ankit Pal, Logesh Kumar Umapathi, and Malaikannan Sankarasubbu.
    2023. Med-halt: Medical domain hallucination test for large language models. *arXiv
    preprint arXiv:2307.15343*.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Pal et al. (2023) Ankit Pal, Logesh Kumar Umapathi, 和 Malaikannan Sankarasubbu.
    2023. Med-halt: 医疗领域幻觉测试用于大型语言模型。*arXiv 预印本 arXiv:2307.15343*。'
- en: Rashkin et al. (2021) Hannah Rashkin, David Reitter, Gaurav Singh Tomar, and
    Dipanjan Das. 2021. Increasing faithfulness in knowledge-grounded dialogue with
    controllable features. *arXiv preprint arXiv:2107.06963*.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rashkin et al. (2021) Hannah Rashkin, David Reitter, Gaurav Singh Tomar, 和 Dipanjan
    Das. 2021. 增强知识基础对话中的忠实度与可控特性。*arXiv 预印本 arXiv:2107.06963*。
- en: 'Rudin et al. (2022) Cynthia Rudin, Chaofan Chen, Zhi Chen, Haiyang Huang, Lesia
    Semenova, and Chudi Zhong. 2022. Interpretable machine learning: Fundamental principles
    and 10 grand challenges. *Statistic Surveys*, 16:1–85.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rudin et al. (2022) Cynthia Rudin, Chaofan Chen, Zhi Chen, Haiyang Huang, Lesia
    Semenova, 和 Chudi Zhong. 2022. 可解释的机器学习：基本原则和10大挑战。*统计调查*，16:1–85。
- en: 'Shen et al. (2023) Jiaming Shen, Jialu Liu, Dan Finnie, Negar Rahmati, Mike
    Bendersky, and Marc Najork. 2023. “why is this misleading?”: Detecting news headline
    hallucinations with explanations. In *Proceedings of the ACM Web Conference 2023*,
    pages 1662–1672.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shen et al. (2023) Jiaming Shen, Jialu Liu, Dan Finnie, Negar Rahmati, Mike
    Bendersky, 和 Marc Najork. 2023. “为什么这具有误导性？”: 通过解释检测新闻头条幻觉。收录于*ACM 网络会议 2023*，第1662–1672页。'
- en: Shi et al. (2023) Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David
    Dohan, Ed Huai hsin Chi, Nathanael Scharli, and Denny Zhou. 2023. [Large language
    models can be easily distracted by irrelevant context](https://api.semanticscholar.org/CorpusID:256459776).
    In *International Conference on Machine Learning*.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi et al. (2023) Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David
    Dohan, Ed Huai hsin Chi, Nathanael Scharli, 和 Denny Zhou. 2023. [大型语言模型很容易被无关背景分心](https://api.semanticscholar.org/CorpusID:256459776)。收录于*国际机器学习大会*。
- en: 'Shi et al. (2024) Guangsi Shi, Xiaofeng Deng, Linhao Luo, Lijuan Xia, Lei Bao,
    Bei Ye, Fei Du, Shirui Pan, and Yuxiao Li. 2024. Llm-powered explanations: Unraveling
    recommendations through subgraph reasoning. *arXiv preprint arXiv:2406.15859*.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shi et al. (2024) Guangsi Shi, Xiaofeng Deng, Linhao Luo, Lijuan Xia, Lei Bao,
    Bei Ye, Fei Du, Shirui Pan, 和 Yuxiao Li. 2024. Llm-powered explanations: 通过子图推理解开推荐。*arXiv
    预印本 arXiv:2406.15859*。'
- en: 'Sobania et al. (2022) Dominik Sobania, Martin Briesch, and Franz Rothlauf.
    2022. Choose your programming copilot: a comparison of the program synthesis performance
    of github copilot and genetic programming. In *Proceedings of the genetic and
    evolutionary computation conference*, pages 1019–1027.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sobania et al. (2022) Dominik Sobania, Martin Briesch, 和 Franz Rothlauf. 2022.
    选择你的编程副手：GitHub Copilot 和遗传编程的程序合成性能比较。收录于*遗传和进化计算会议论文集*，第1019–1027页。
- en: 'Thorne et al. (2018) James Thorne, Andreas Vlachos, Christos Christodoulopoulos,
    and Arpit Mittal. 2018. FEVER: a large-scale dataset for fact extraction and VERification.
    In *NAACL-HLT*.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Thorne et al. (2018) James Thorne, Andreas Vlachos, Christos Christodoulopoulos,
    和 Arpit Mittal. 2018. FEVER: 一个大规模事实提取和验证数据集。收录于*NAACL-HLT*。'
- en: 'Turpin et al. (2024) Miles Turpin, Julian Michael, Ethan Perez, and Samuel
    Bowman. 2024. Language models don’t always say what they think: unfaithful explanations
    in chain-of-thought prompting. *Advances in Neural Information Processing Systems*,
    36.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Turpin et al. (2024) Miles Turpin, Julian Michael, Ethan Perez, 和 Samuel Bowman.
    2024. 语言模型并不总是说他们所想：链式思维提示中的不忠实解释。*神经信息处理系统进展*，36。
- en: 'Wang et al. (2021) Peng Wang, Junyang Lin, An Yang, Chang Zhou, Yichang Zhang,
    Jingren Zhou, and Hongxia Yang. 2021. Sketch and refine: Towards faithful and
    informative table-to-text generation. *arXiv preprint arXiv:2105.14778*.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. (2021) Peng Wang, Junyang Lin, An Yang, Chang Zhou, Yichang Zhang,
    Jingren Zhou, 和 Hongxia Yang. 2021. 草图与优化：迈向忠实且信息丰富的表格到文本生成。*arXiv 预印本 arXiv:2105.14778*。
- en: Wang et al. (2020) Zhenyi Wang, Xiaoyang Wang, Bang An, Dong Yu, and Changyou
    Chen. 2020. Towards faithful neural table-to-text generation with content-matching
    constraints. *arXiv preprint arXiv:2005.00969*.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. (2020) Zhenyi Wang, Xiaoyang Wang, Bang An, Dong Yu, 和 Changyou
    Chen. 2020. 迈向忠实的神经表格到文本生成与内容匹配约束。*arXiv 预印本 arXiv:2005.00969*。
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei
    Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits
    reasoning in large language models. *Advances in Neural Information Processing
    Systems*, 35:24824–24837.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等（2022）魏杰森, 王学志, 达勒·舒尔曼斯, 马尔滕·博斯玛, 夏飞, Chi, Ed, Le, Quoc V, 周登尼等。2022。链式思维提示引发大型语言模型中的推理。*神经信息处理系统进展*，35:24824–24837。
- en: Wiegreffe et al. (2021) Sarah Wiegreffe, Jack Hessel, Swabha Swayamdipta, Mark
    Riedl, and Yejin Choi. 2021. Reframing human-ai collaboration for generating free-text
    explanations. *arXiv preprint arXiv:2112.08674*.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wiegreffe 等（2021）萨拉·魏格雷夫, 杰克·赫塞尔, 斯瓦巴·斯瓦扬迪普塔, 马克·里德尔, 崔叶津。2021。重新框定人类与 AI 的协作以生成自由文本解释。*arXiv
    预印本 arXiv:2112.08674*。
- en: 'Wu et al. (2023) Yuanhao Wu, Juno Zhu, Siliang Xu, Kashun Shum, Cheng Niu,
    Randy Zhong, Juntong Song, and Tong Zhang. 2023. Ragtruth: A hallucination corpus
    for developing trustworthy retrieval-augmented language models. *arXiv preprint
    arXiv:2401.00396*.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等（2023）袁浩 Wu, 朱俊诺, 徐思良, 宋克舜, 牛城, 钟然, 宋俊通, 张童。2023。Ragtruth：用于开发可信的检索增强语言模型的幻觉语料库。*arXiv
    预印本 arXiv:2401.00396*。
- en: Ye and Durrett (2022) Xi Ye and Greg Durrett. 2022. The unreliability of explanations
    in few-shot prompting for textual reasoning. *Advances in neural information processing
    systems*, 35:30378–30392.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ye 和 Durrett（2022）叶西, 格雷戈·杜雷特。2022。少量提示文本推理中的解释不可靠性。*神经信息处理系统进展*，35:30378–30392。
- en: 'Zha et al. (2023) Yuheng Zha, Yichi Yang, Ruichen Li, and Zhiting Hu. 2023.
    Alignscore: Evaluating factual consistency with a unified alignment function.
    *arXiv preprint arXiv:2305.16739*.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zha 等（2023）赵宇衡, 杨一池, 李睿辰, 胡志廷。2023。Alignscore：使用统一的对齐函数评估事实一致性。*arXiv 预印本 arXiv:2305.16739*。
- en: Zhou et al. (2020) Chunting Zhou, Graham Neubig, Jiatao Gu, Mona Diab, Paco
    Guzman, Luke Zettlemoyer, and Marjan Ghazvininejad. 2020. Detecting hallucinated
    content in conditional neural sequence generation. *arXiv preprint arXiv:2011.02593*.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou 等（2020）周春腾, 格雷厄姆·纽比格, 俞家涛, 莫娜·迪亚布, 帕科·古兹曼, 卢克·泽特尔莫耶, 马尔扬·加兹维尼贾德。2020。在条件神经序列生成中检测幻觉内容。*arXiv
    预印本 arXiv:2011.02593*。
- en: Appendix A Appendix
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 附录
- en: A.1 Data distribution
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 数据分布
- en: 'The distribution of hallucinated and non-hallucinated examples in each dataset
    is shown in Table [4](#A1.T4 "Table 4 ‣ A.1 Data distribution ‣ Appendix A Appendix
    ‣ SLM Meets LLM: Balancing Latency, Interpretability and Consistency in Hallucination
    Detection").'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 每个数据集中幻觉和非幻觉示例的分布见表 [4](#A1.T4 "表 4 ‣ A.1 数据分布 ‣ 附录 A 附录 ‣ SLM 与 LLM：平衡幻觉检测中的延迟、可解释性和一致性")。
- en: '| Dataset | Hallucination | Non-Hallucination |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 幻觉 | 非幻觉 |'
- en: '| NHNET | 216 | 439 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| NHNET | 216 | 439 |'
- en: '| FEVER | 813 | 2187 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| FEVER | 813 | 2187 |'
- en: '| HaluQA | 1500 | 1500 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| HaluQA | 1500 | 1500 |'
- en: '| HaluSum | 1500 | 1500 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| HaluSum | 1500 | 1500 |'
- en: 'Table 4: Dataset statistics. NHNET we use the complete set. Fever, HaluQA and
    HaluSum we random sample 3000 data due to their large size.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：数据集统计。NHNET 使用了完整的数据集。由于 Fever、HaluQA 和 HaluSum 数据量庞大，我们随机抽取了 3000 条数据。
- en: A.2 Constrained Reasoner Approaches
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 受限推理器方法
- en: A.2.1 Vanilla prompt
  id: totrans-122
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: A.2.1 Vanilla prompt
- en: 'Vanilla prompt shown in [3](#A1.F3 "Figure 3 ‣ A.2.1 Vanilla prompt ‣ A.2 Constrained
    Reasoner Approaches ‣ Appendix A Appendix ‣ SLM Meets LLM: Balancing Latency,
    Interpretability and Consistency in Hallucination Detection") only gives the instruction
    and few-shot examples to do the downstream reasoning task. However, it does not
    specify how LLM should deal with the situation where LLM does not follow the upstream
    decision.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: Vanilla prompt 在 [3](#A1.F3 "图 3 ‣ A.2.1 Vanilla prompt ‣ A.2 受限推理器方法 ‣ 附录 A
    附录 ‣ SLM 与 LLM：平衡幻觉检测中的延迟、可解释性和一致性") 中展示的仅给出了指令和少量示例来完成下游推理任务。然而，它没有具体说明 LLM 应如何处理
    LLM 不遵循上游决策的情况。
- en: '-  role:  systemcontent:  |You  are  a  careful  proof-reading  assistant  with  great  logic  thinking  and  solid  english  skills  for  a  documentation  scribe.  Your  important  task  is  to  provide  hallucination  reasons:  given  the  <>  and  some  <>  that  is  not  supported  by  the  <>,  you  are  expected  to  give  the  <>  why  the  sentence  are  not  supported.If  the  <>  contradict  the  <>,  you  should  cite  the  evidence  in  the  <>  and  specify  where  the  contradiction  is.If  the  hallucination  is  because  a  small  part  of  the  <>  is  made  up/  no  information  in  the  <>  supports/contradicts  the  small  part  of  the  sentence,  please  "PARTIAL  NEUTRAL"  and  specify  which  part  is  not  supported.If  the  hallucination  is  because  the  whole  <>  is  made  up/  no  information  in  the  <>  supports/contradicts  the  sentence,  please  mark  "NEUTRAL"  to  mark  this  situation.  Please  try  your  best  to  find  the  detailed  reasons  and  only  use  NEUTRAL  as  your  last  resort.If  there  are  part  of  the  <>  contradicts  and  part  of  the  <>  "NEUTRAL",  please  specify  all  the  reasons.The  <>  are  numbered.  You  should  provide  the  <>  in  the  same  order  as  the  original  <>.-  role:  systemname:  example_usercontent:  |Let’s  try  it.<>:The  Academy  Awards,  also  known  as  the  Oscars  are  awards  for  artistic  and  technical  merit  for  the  film  industry.  They  are  presented  annually  by  the  Academy  of  Motion  Picture  Arts  and  Sciences,  in  recognition  of  excellence  in  cinematic  achievements  as  assessed  by  the  Academy’s  voting  membership.  The  Academy  Awards  are  regarded  by  many  as  the  most  prestigious,  significant  awards  in  the  entertainment  industry  in  the  United  States  and  worldwide.  The  awards  ceremony  is  always  hosted  in  the  US.<><>:(0).  <>:  Oscar  is  presented  every  other  two  years.(1).  <>:  Will  Smith  won  the  2022  Oscar.(2).  <>:  The  awards  ceremony  is  always  hosted  in  the  US  in  summer.<>-  role:  systemname:  example_assistantcontent:  |These  are  hallucinations  because:(0).  the  source  reference:  "They  are  presented  annually  by  the  Academy  of  Motion  Picture  Arts  and  Sciences",  thus  it  is  not  presented  every  other  two  year.  It’s  contradiction.(1).  NEUTRAL(2).  PARTIAL  NEUTRAL.  The  main  part  of  the  sentence  is  correct,  but  the  grounding  source  did  not  mention  "summer".-  role:  systemname:  example_usercontent:  |Let’s  try  it  again.<>:Prompts  are  how  you  ask  Copilot  to  do  something  for  you  -  like  creating,  summarizing,  editing,  or  transforming.  Think  about  prompting  like  having  a  conversation,  using  plain  but  clear  language  and  providing  context  like  you  would  with  an  assistant.Also  called  prompt  engineering,  prompting  is  both  an  art  and  a  science.  To  get  the  best  results,  you  need  to  structure  your  prompt  in  a  way  that  the  large  language  model  (LLM)  can  understand.Like  any  other  skill,  prompting  takes  practice  to  perfect.  You  won’t  get  there  overnight.How  to  write  a  good  prompt?<><>:(0).  <>:  Give  clarity  and  Context  and  you  will  do  a  good  job  immediately.<>-  role:  systemname:  example_assistantcontent:  |These  are  hallucinations  because:(0).  The  grounding  source  is  a  reference  and  a  user  question.  The  "clarity  and  Context"  in  the  answer  sentence  is  correct,  but  the  "you  will  do  a  good  job  immediately"  contradicts  the  source:  "prompting  takes  practice  to  perfect.  You  won’t  get  there  overnight."-  role:  usercontent:  |<>:{{transcript}}<><>:{{sentences}}<>Give  your  reason  and  begin  your  answer  with  "These  are  hallucinations  because:\n"'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '角色:  系统内容:  |您是一个具有出色逻辑思维和扎实英语技能的细心校对助手，负责文档编写工作。您的重要任务是提供幻觉原因：根据《源文档》和一些《句子》——这些句子并不被《源文档》支持——您需要说明这些句子为何不被支持。如果《句子》与《源文档》相矛盾，您应引用《源文档》中的证据，并指定矛盾所在。如果幻觉是因为《句子》的某一小部分是虚构的/《源文档》中没有信息支持/与该小部分相矛盾，请标记为"部分中立"，并指定哪个部分不被支持。如果幻觉是因为整个《句子》是虚构的/《源文档》中没有信息支持/与句子相矛盾，请标记为"中立"以标记这种情况。请尽力找到详细的原因，只有在最后的情况下才使用"中立"。如果《句子》的部分内容与《源文档》相矛盾而另一部分"中立"，请指定所有原因。《句子》是编号的。您应按照原始《句子》的顺序提供《原因》。-
    角色:  系统名称:  example_user内容:  |让我们试试吧。《源文档》: 奥斯卡奖，也被称为学院奖，是对电影行业的艺术和技术成就的奖励。它们由电影艺术与科学学院每年颁发，以表彰电影成就的卓越，评选由学院的投票会员进行。许多人认为奥斯卡奖是美国及全球娱乐行业中最具声望和重要性的奖项。颁奖典礼总是在美国举行。《结束
    源文档》 《需要提供幻觉原因的句子》:(0).  《句子》: 奥斯卡奖每两年颁发一次。(1).  《句子》: 威尔·史密斯赢得了2022年的奥斯卡奖。(2).  《句子》:
    颁奖典礼总是在美国的夏季举行。《结束 需要提供幻觉原因的句子》- 角色:  系统名称:  example_assistant内容:  |这些是幻觉，因为：(0).  来源参考:
    “它们由电影艺术与科学学院每年颁发”，因此它并不是每两年颁发一次。这是矛盾。(1).  中立(2).  部分中立。句子的主要部分是正确的，但基础来源中没有提到"夏季"。-
    角色:  系统名称:  example_user内容:  |让我们再试一次。《源文档》: 提示是您要求 Copilot 为您做某事的方式——例如创建、总结、编辑或转换。可以将提示视为一种对话，使用简单但清晰的语言，并提供类似于与助手交谈时的上下文。也称为提示工程，提示既是一门艺术，也是一门科学。要获得最佳结果，您需要以大型语言模型（LLM）可以理解的方式构建您的提示。像任何其他技能一样，提示需要实践才能完善。您不会一夜之间就做到这一点。如何编写一个好的提示？《结束
    源文档》 《需要提供幻觉原因的句子》:(0).  《句子》: 提供清晰度和上下文，您将立即做得很好。《结束 需要提供幻觉原因的句子》- 角色:  系统名称:  example_assistant内容:  |这些是幻觉，因为：(0).  基础来源是参考和用户问题。答案句中的“清晰度和上下文”是正确的，但“您将立即做得很好”与来源中的内容矛盾：“提示需要实践才能完善。您不会一夜之间就做到这一点。”'
- en: 'Figure 3: Vanilla prompt.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：基础提示。
- en: A.2.2 Fallback Prompt
  id: totrans-126
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: A.2.2 备选提示
- en: 'Fallback prompt shown in [4](#A1.F4 "Figure 4 ‣ A.2.2 Fallback Prompt ‣ A.2
    Constrained Reasoner Approaches ‣ Appendix A Appendix ‣ SLM Meets LLM: Balancing
    Latency, Interpretability and Consistency in Hallucination Detection") gives LLM
    an alternative route when it does not agree with the upstream decision and will
    give inconsistent downstream explanations.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在[4](#A1.F4 "图 4 ‣ A.2.2 备选提示 ‣ A.2 受限推理方法 ‣ 附录 A 附录 ‣ SLM 遇见 LLM：平衡延迟、可解释性和一致性在虚假信息检测中")中显示的备选提示，当LLM不同意上游决策并且会给出不一致的下游解释时，提供了一个替代路线。
- en: '-  role:  systemcontent:  |You  are  a  careful  proof-reading  assistant  with  great  logic  thinking  and  solid  english  skills  for  a  documentation  scribe.  Your  important  task  is  to  provide  hallucination  reasons:  given  the  <>  and  some  <>  that  is  not  supported  by  the  <>,  you  are  expected  to  give  the  <>  why  the  sentence  are  not  supported.If  the  <>  contradict  the  <>,  you  should  cite  the  evidence  in  the  <>  and  specify  where  the  contradiction  is.If  the  hallucination  is  because  a  small  part  of  the  <>  is  made  up/  no  information  in  the  <>  supports/contradicts  the  small  part  of  the  sentence,  please  "PARTIAL  NEUTRAL"  and  specify  which  part  is  not  supported.If  the  hallucination  is  because  the  whole  <>  is  made  up/  no  information  in  the  <>  supports/contradicts  the  sentence,  please  mark  "NEUTRAL"  to  mark  this  situation.  Please  try  your  best  to  find  the  detailed  reasons  and  only  use  NEUTRAL  as  your  last  resort.If  there  are  part  of  the  <>  contradicts  and  part  of  the  <>  "NEUTRAL",  please  specify  all  the  reasons.The  <>  are  numbered.  You  should  provide  the  <>  in  the  same  order  as  the  original  <>.In  very  rare  case,  if  you  can  not  find  the  reason  for  the  hallucination  or  you  think  the  <>  is  supported  by  the  <>,  please  mark  ’UNKNOWN’.-  role:  systemname:  example_usercontent:  |Let’s  try  it.<>:The  Academy  Awards,  also  known  as  the  Oscars  are  awards  for  artistic  and  technical  merit  for  the  film  industry.  They  are  presented  annually  by  the  Academy  of  Motion  Picture  Arts  and  Sciences,  in  recognition  of  excellence  in  cinematic  achievements  as  assessed  by  the  Academy’s  voting  membership.  The  Academy  Awards  are  regarded  by  many  as  the  most  prestigious,  significant  awards  in  the  entertainment  industry  in  the  United  States  and  worldwide.  The  awards  ceremony  is  always  hosted  in  the  US.<><>:(0).  <>:  Oscar  is  presented  every  other  two  years.(1).  <>:  Will  Smith  won  the  2022  Oscar.(2).  <>:  The  awards  ceremony  is  always  hosted  in  the  US  in  summer.<>-  role:  systemname:  example_assistantcontent:  |These  are  hallucinations  because:(0).  the  source  reference:  "They  are  presented  annually  by  the  Academy  of  Motion  Picture  Arts  and  Sciences",  thus  it  is  not  presented  every  other  two  year.  It’s  contradiction.(1).  NEUTRAL(2).  PARTIAL  NEUTRAL.  The  main  part  of  the  sentence  is  correct,  but  the  grounding  source  did  not  mention  "summer".-  role:  systemname:  example_usercontent:  |Let’s  try  it  again.<>:I  have  bluntly  communicated  to  him  several  times  that  I  would  like  to  see  him  more  than  once  per  week  for  two  hours.  He  said  he  would  try  to  make  more  time  for  me  but  it  has  not  happened  yet  (…)  I  don’t  smoke  weed  anymore,  and  I  don’t  care  if  he  does  but  I’m  hurt  that  he  barely  finds  time  to  spend  with  me.  I  don’t  even  text  or  call  to  ask  him  to  hang  out  because  he’ll  usually  say  he’s  busy  working.  I  know  he’s  busy  and  throughout  the  week  I’m  busy  with  work  too  but  we  rarely  talk.  He’ll  probably  send  a  text  every  so  often,  but  we  usually  go  4-5  days  without  talking.  (…)  Sometimes  the  one  day  I  do  get  to  hang  out  with  him,  he’ll  cancel  if  someone  calls  and  I’ll  be  left  at  dinner/movie  theater/wherever  alone.  I  just  feel  like  I’m  not  wanted.<><>:(0).  <>:  I  feel  like  my  boyfriend  is  neglecting  me  and  I’m  not  sure  what  to  do  about  it.<>-  role:  systemname:  example_assistantcontent:  |These  are  hallucinations  because:(0).  UNKNOWN.  Although  original  article  does  not  use  the  word  ’neglecting’,  it  a  lot  of  incidence  that  we  may  inferred  ’neglecting’.  Therefore,  I  can  not  categorize  the  reason  and  need  to  use  UNKNOWN.-  role:  systemname:  example_usercontent:  |Let’s  try  it  again.<>:Prompts  are  how  you  ask  Copilot  to  do  something  for  you  -  like  creating,  summarizing,  editing,  or  transforming.  Think  about  prompting  like  having  a  conversation,  using  plain  but  clear  language  and  providing  context  like  you  would  with  an  assistant.Also  called  prompt  engineering,  prompting  is  both  an  art  and  a  science.  To  get  the  best  results,  you  need  to  structure  your  prompt  in  a  way  that  the  large  language  model  (LLM)  can  understand.Like  any  other  skill,  prompting  takes  practice  to  perfect.  You  won’t  get  there  overnight.How  to  write  a  good  prompt?<><>:(0).  <>:  Give  clarity  and  Context  and  you  will  do  a  good  job  immediately.<>-  role:  systemname:  example_assistantcontent:  |These  are  hallucinations  because:(0).  The  grounding  source  is  a  reference  and  a  user  question.  The  "clarity  and  Context"  in  the  answer  sentence  is  correct,  but  the  "you  will  do  a  good  job  immediately"  contradicts  the  source:  "prompting  takes  practice  to  perfect.  You  won’t  get  there  overnight."-  role:  usercontent:  |<>:{{transcript}}<><>:{{sentences}}<>Give  your  reason  and  begin  your  answer  with  "These  are  hallucinations  because:\n"'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 角色：系统内容：| 你是一个具有出色逻辑思维和扎实英语技能的细致校对助手，负责文档记录。你的重要任务是提供幻觉原因：给定<>和一些<>，这些句子没有得到<>的支持，你需要提供<>解释为什么这些句子不被支持。如果<>与<>相矛盾，你应该引用<>中的证据并指定矛盾的地方。如果幻觉是因为<>中的一小部分是虚构的/没有信息支持/与<>中的小部分矛盾，请标记为“PARTIAL
    NEUTRAL”，并指定哪一部分没有得到支持。如果幻觉是因为整个<>是虚构的/没有信息支持/与<>相矛盾，请标记为“NEUTRAL”以标记这种情况。请尽力找出详细原因，只有在最后才使用NEUTRAL。如果<>的部分内容矛盾而部分内容“NEUTRAL”，请指定所有原因。<>有编号。你应按原始<>的顺序提供<>。在非常少见的情况下，如果你找不到幻觉的原因或认为<>得到<>的支持，请标记为“UNKNOWN”。-
    角色：系统名称：example_user内容：| 让我们试试吧。<>：奥斯卡奖，也称为学院奖，是对电影行业艺术和技术成就的奖项。它们由电影艺术与科学学院每年颁发，以表彰由学院的投票成员评定的电影成就。许多人认为奥斯卡奖是美国及全球娱乐行业中最有声望、最重要的奖项。颁奖典礼总是在美国举行。<>
    <>：(0). <>：奥斯卡奖每两年颁发一次。(1). <>：威尔·史密斯获得了2022年的奥斯卡奖。(2). <>：颁奖典礼总是在美国的夏季举行。<>-
    角色：系统名称：example_assistant内容：| 这些是幻觉，因为：(0). 源文档参考：“它们由电影艺术与科学学院每年颁发”，因此并不是每两年颁发一次。这是矛盾。(1).
    NEUTRAL (2). PARTIAL NEUTRAL。句子的主要部分是正确的，但来源并未提到“夏季”。- 角色：系统名称：example_user内容：|
    让我们再试一次。<>：我已经直言不讳地告诉他几次，我希望每周见他一次以上，每次两个小时。他说他会尽量多花时间陪我，但到目前为止还没有实现 (…)
    我不再吸食大麻了，我不在乎他是否吸食，但我很伤心的是他几乎没有时间陪我。我甚至不会发短信或打电话邀请他出来，因为他通常会说他在忙于工作。我知道他很忙，而在一周中我也很忙于工作，但我们很少聊天。他可能会偶尔发一条短信，但我们通常会有4-5天没有联系。
    (…) 有时在我唯一一天能和他见面时，如果有人打电话，他会取消，我会被独自留在晚餐/电影院/其他地方。我只是觉得自己不受欢迎。<> <>：(0).
    <>：我觉得我的男朋友忽视了我，我不知道该怎么做。<>- 角色：系统名称：example_assistant内容：|
    这些是幻觉，因为：(0). UNKNOWN。虽然原文没有使用“忽视”这个词，但有很多情况可以推测出“忽视”。因此，我无法对原因进行分类，需要使用UNKNOWN。-
    角色：系统名称：example_user内容：| 让我们再试一次。<>：提示是你让Copilot为你做某事的方式——例如创建、总结、编辑或转换。将提示视为与助手进行对话，使用简单但清晰的语言，并提供上下文，就像你对待助手一样。也称为提示工程，提示既是一门艺术也是一门科学。为了获得最佳结果，你需要以大型语言模型（LLM）能够理解的方式来构建你的提示。像任何其他技能一样，提示需要实践来完善。你不会一夜之间做到这一点。如何写出一个好的提示？<>
    <>：(0). <>：给出清晰和上下文，你将立即做好工作。<>- 角色：系统名称：example_assistant内容：|
    这些是幻觉，因为：(0). 来源文档是参考和用户问题。回答中的“清晰和上下文”是正确的，但“你将立即做好工作”与源文档的“提示需要实践来完善。你不会一夜之间做到这一点。”相矛盾。
- en: 'Figure 4: Fallback Prompt.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '图 4: 备用提示。'
- en: A.2.3 Categorized Prompt
  id: totrans-130
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: A.2.3 分类提示
- en: 'Categorized prompt shown in [5](#A1.F5 "Figure 5 ‣ A.2.3 Categorized Prompt
    ‣ A.2 Constrained Reasoner Approaches ‣ Appendix A Appendix ‣ SLM Meets LLM: Balancing
    Latency, Interpretability and Consistency in Hallucination Detection") gives LLM
    an alternative route when it does not agree with the upstream decision and will
    give inconsistent downstream explanations. Moreover, this prompt asks the LLM
    to categorize the reasons when LLM agrees with the upstream decision as an extra
    confirmation.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[5](#A1.F5 "图 5 ‣ A.2.3 分类提示 ‣ A.2 约束推理方法 ‣ 附录 A 附录 ‣ SLM 与 LLM: 在幻觉检测中平衡延迟、可解释性和一致性")
    中显示的分类提示为 LLM 提供了一条替代路线，当其不同意上游决策并且会给出不一致的下游解释时。此外，该提示要求 LLM 在同意上游决策时对理由进行分类，以作为额外确认。'
- en: '-  role:  systemcontent:  |You  are  a  careful  proof-reading  assistant  with  great  logic  thinking  and  solid  english  skills  for  a  documentation  scribe.  Your  important  task  is  to  provide  hallucination  reason  categories:  given  the  <>  and  some  <>  that  is  not  supported  by  the  <>,  i.e.  the  <>  are  hallucinated,  you  are  expected  to  give  the  <>  why  the  sentence  are  not  supported.<>  and  their  definitions  are:Hallu_1.  Missing  from  grounding  sources:  At  least  one  factual  claim  in  response  sentence  is  not  present  in  grounding  sources  and  cannot  be  inferred  using  basic  domain/common  knowledge.Hallu_2.  Numeric  value  contradicts  with  ground  source:  Numeric  value  with  similar  context  occurs  in  the  grounding  source  but  the  value  in  response  sentence  contradicts  with  the  value  that  occurs  in  the  grounding  source.Hallu_3.  Negative  to  positive  flip:  At  least  factual  claim  also  occurs  in  the  grounding  sources  but  appears  as  negative  in  the  grounding  source  and  change  to  positive  in  the  response  sentenceHallu_4.  Positive  to  negative  flip:  At  least  factual  claim  also  occurs  in  the  grounding  sources  but  appears  as  positive  in  the  grounding  source  and  change  to  negative  in  the  response  sentenceHallu_5.  Entity  grouped  wrong:  Response  sentence  categorized  an  entity  which  occurs  in  the  grounding  source,  incorrectlyHallu_6.  Url  contradicts  with  ground  source:  Url  with  similar  context  occurs  in  the  grounding  source  but  the  url  in  response  sentence  contradicts  with  the  url  in  the  grounding  sourceHallu_7.  Missing  information  changes  meaning:  A  part  of  the  information  in  the  grounding  source  is  missing  from  the  response.  This  changes  the  meaning  of  the  fact  or  entity  stated.Hallu_8.  Claim  contradicts  with  grounding  source:  Factual  claim  contradicts  with  the  information  in  the  ground  source  (but  the  claim  is  not  a  numeric  value  or  url)Hallu_9.  Pronoun  contradicts  with  grounding  source:  Incorrect  pronouns  cause  overwise  correct  sentence  to  become  incorrect.  (EG  OfficeSum  I:  22,  S:  3:  "He  believes  the  high  number  of  twins  could  be  genetic."  The  grounding  sources  state  that  some  experts  believe  it  could  be  genetic.  The  sentence  is  correct  except  for  the  pronoun  he.)Hallu_10.  Template  sentence  fabricated  hallucination:  Some  summaries  use  templates.  These  templates  elicit  answers  even  when  the  answer  is  not  mentioned  in  the  grounding  source.  For  example:  "patient  is  accompanied  by  adult  female"  is  a  common  template  hallucination.Hallu_11.  Source  misspelt/unintelligible.Hallu_12.  All  others.Try  your  best  to  classify  the  reasons  in  to  the  first  11  categories.  In  very  rare  case,  if  you  can  not  find  the  reason  for  the  hallucination  or  you  think  the  <>  is  supported  by  the  <>,  please  use  ’Hallu_12’.  That  means  you  can  only  provide  the  above  12  categories!The  <>  are  numbered.  You  should  provide  the  <>  in  the  same  order  as  the  original  <>.-  role:  systemname:  example_usercontent:  |Let’s  try  it.<>:The  Academy  Awards,  also  known  as  the  Oscars  are  awards  for  artistic  and  technical  merit  for  the  film  industry.  They  are  presented  annually  by  the  Academy  of  Motion  Picture  Arts  and  Sciences,  in  recognition  of  excellence  in  cinematic  achievements  as  assessed  by  the  Academy’s  voting  membership.  The  Academy  Awards  are  regarded  by  many  as  the  most  prestigious,  significant  awards  in  the  entertainment  industry  in  the  United  States  and  worldwide.  The  awards  ceremony  is  always  hosted  in  the  US.  A  promotion  about  Oscar  begins  at  3:300PM  June  29,  2012.<><>:(0).  <>:  Oscar  is  presented  every  other  two  years.(1).  <>:  Will  Smith  won  the  2022  Oscar.(2).  <>:  The  awards  ceremony  is  always  hosted  in  the  US  in  summer.(3).  <>:  An  event  begins  at  3:00  PM  and  ends  at  3:00  pm  EST  on  July  5th,  2012.<>-  role:  systemname:  example_assistantcontent:  |These  are  hallucinations  because:(0).  Hallu_2.  The  source  reference:  "They  are  presented  annually  by  the  Academy  of  Motion  Picture  Arts  and  Sciences",  thus  it  is  not  presented  every  other  two  year,  i.e.  contradiction  in  numeric  value.(1).  Hallu_1.  The  source  reference  did  not  mention  Will  Smith  won  the  2022  Oscar.(2).  Hallu_1.  The  main  part  of  the  sentence  is  correct,  but  the  grounding  source  did  not  mention  "summer".(3).  Hallu_7.  The  original  article  mentioned  "begins  at  3:300PM  June  29,  2012".  Date  is  missed  in  sentence,  as  the  result  the  meaning  becomes  begin  time  is  3:00PM  July  5th,  2012  which  is  wrong.-  role:  systemname:  example_usercontent:  |Let’s  try  it  again.<>:Prompts  are  how  you  ask  Copilot  to  do  something  for  you  -  like  creating,  summarizing,  editing,  or  transforming.  Think  about  prompting  like  having  a  conversation,  using  plain  but  clear  language  and  providing  context  like  you  would  with  an  assistant.Also  called  prompt  engineering,  prompting  is  both  an  art  and  a  science.  To  get  the  best  results,  you  need  to  structure  your  prompt  in  a  way  that  the  large  language  model  (LLM)  can  understand.Like  any  other  skill,  prompting  takes  practice  to  perfect.  You  won’t  get  there  overnight.How  to  write  a  good  prompt?<><>:(0).  <>:  Give  clarity  and  Context  and  you  will  do  a  good  job  immediately.<>-  role:  systemname:  example_assistantcontent:  |These  are  hallucinations  because:(0).  Hallu_8.  The  grounding  source  is  a  reference  and  a  user  question.  The  "clarity  and  Context"  in  the  answer  sentence  is  correct,  but  the  "you  will  do  a  good  job  immediately"  contradicts  the  source:  "prompting  takes  practice  to  perfect.  You  won’t  get  there  overnight."-  role:  systemname:  example_usercontent:  |Let’s  try  it  again.<>:I  have  bluntly  communicated  to  him  several  times  that  I  would  like  to  see  him  more  than  once  per  week  for  two  hours.  He  said  he  would  try  to  make  more  time  for  me  but  it  has  not  happened  yet  (…)  I  don’t  smoke  weed  anymore,  and  I  don’t  care  if  he  does  but  I’m  hurt  that  he  barely  finds  time  to  spend  with  me.  I  don’t  even  text  or  call  to  ask  him  to  hang  out  because  he’ll  usually  say  he’s  busy  working.  I  know  he’s  busy  and  throughout  the  week  I’m  busy  with  work  too  but  we  rarely  talk.  He’ll  probably  send  a  text  every  so  often,  but  we  usually  go  4-5  days  without  talking.  (…)  Sometimes  the  one  day  I  do  get  to  hang  out  with  him,  he’ll  cancel  if  someone  calls  and  I’ll  be  left  at  dinner/movie  theater/wherever  alone.  I  just  feel  like  I’m  not  wanted.<><>:(0).  <>:  I  feel  like  my  boyfriend  is  neglecting  me  and  I’m  not  sure  what  to  do  about  it.<>-  role:  systemname:  example_assistantcontent:  |These  are  hallucinations  because:(0).  Hallu_12.  Although  original  article  does  not  use  the  word  ’neglecting’,  it  a  lot  of  incidence  that  we  may  inferred  ’neglecting’.  Therefore,  I  can  not  categorize  the  reason  into  the  first  11,  and  need  to  use  H12.-  role:  usercontent:  |<>:{{transcript}}<><>:{{sentences}}<>Give  your  reason  and  begin  your  answer  with  "These  are  hallucinations  because:\n"'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 你能提供一些需要翻译的英文句子吗？这样我可以更好地帮助你。
- en: 'Figure 5: Categorized Prompt.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：分类提示。
