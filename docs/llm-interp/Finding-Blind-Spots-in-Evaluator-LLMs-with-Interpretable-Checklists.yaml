- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 17:34:14'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-09-08 17:34:14'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Finding Blind Spots in Evaluator LLMs with Interpretable Checklists
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用可解释的检查清单发现评估器LLMs中的盲点
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.13439](https://ar5iv.labs.arxiv.org/html/2406.13439)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2406.13439](https://ar5iv.labs.arxiv.org/html/2406.13439)
- en: 'Sumanth Doddapaneni^(1,2)  Mohammed Safi Ur Rahman Khan¹¹footnotemark: 1^(1,2)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 'Sumanth Doddapaneni^(1,2)  Mohammed Safi Ur Rahman Khan¹¹脚注标记: 1^(1,2)'
- en: Sshubam Verma¹  Mitesh M. Khapra^(1,2)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Sshubam Verma¹  Mitesh M. Khapra^(1,2)
- en: ¹Nilekani Centre at AI4Bharat  ²Indian Institute of Technology, Madras
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ¹Nilekani Centre at AI4Bharat  ²印度理工学院马德拉斯分校
- en: 'Correspondence: {sumanthd, miteshk}@cse.iitm.ac.in, safikhan@ai4bharat.org'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '联系方式: {sumanthd, miteshk}@cse.iitm.ac.in, safikhan@ai4bharat.org'
- en: '![[Uncaptioned image]](img/84e8cc38da48d5225fbf233027bb98c9.png) [https://huggingface.co/datasets/ai4bharat/FBI](https://huggingface.co/datasets/ai4bharat/FBI)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![[未标注的图片]](img/84e8cc38da48d5225fbf233027bb98c9.png) [https://huggingface.co/datasets/ai4bharat/FBI](https://huggingface.co/datasets/ai4bharat/FBI)'
- en: '![[Uncaptioned image]](img/af867be5854365eea15ee0db439d833e.png) [https://github.com/AI4Bharat/FBI](https://github.com/AI4Bharat/FBI)
    Equal Contribution.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '![[未标注的图片]](img/af867be5854365eea15ee0db439d833e.png) [https://github.com/AI4Bharat/FBI](https://github.com/AI4Bharat/FBI)
    相等贡献。'
- en: Abstract
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Large Language Models (LLMs) are increasingly relied upon to evaluate text
    outputs of other LLMs, thereby influencing leaderboards and development decisions.
    However, concerns persist over the accuracy of these assessments and the potential
    for misleading conclusions. In this work, we investigate the effectiveness of
    LLMs as evaluators for text generation tasks. We propose FBI, a novel framework
    designed to examine the proficiency of Evaluator LLMs in assessing four critical
    abilities in other LLMs: factual accuracy, instruction following, coherence in
    long-form writing, and reasoning proficiency. By introducing targeted perturbations
    in answers generated by LLMs, that clearly impact one of these key capabilities,
    we test whether an Evaluator LLM can detect these quality drops. By creating a
    total of 2400 perturbed answers covering 22 perturbation categories, we conduct
    a comprehensive study using different evaluation strategies on five prominent
    LLMs commonly used as evaluators in the literature. Our findings reveal significant
    shortcomings in current Evaluator LLMs, which failed to identify quality drops
    in over 50% of cases on average. Single-answer and pairwise evaluations demonstrated
    notable limitations, whereas reference-based evaluations showed comparatively
    better performance. These results underscore the unreliable nature of current
    Evaluator LLMs and advocate for cautious implementation in practical applications.
    Code and data are available at [https://github.com/AI4Bharat/FBI](https://github.com/AI4Bharat/FBI).'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）越来越依赖于评估其他LLMs的文本输出，从而影响排行榜和开发决策。然而，对这些评估的准确性以及可能导致误导性结论的担忧仍然存在。在这项工作中，我们调查了LLMs作为文本生成任务评估器的有效性。我们提出了FBI，一个旨在检查评估器LLMs在评估其他LLMs的四种关键能力方面的熟练程度的新框架：事实准确性、指令遵循、长篇写作中的连贯性以及推理能力。通过在LLMs生成的答案中引入有针对性的扰动，这些扰动明显影响其中一种关键能力，我们测试了评估器LLM是否能检测到这些质量下降。通过创建总计2400个覆盖22个扰动类别的扰动答案，我们在文献中常用的五个主要LLMs上进行了全面的研究，使用了不同的评估策略。我们的发现揭示了当前评估器LLMs的显著缺陷，它们在平均超过50%的案例中未能识别质量下降。单答案和成对评估显示出明显的局限性，而基于参考的评估则表现出相对较好的性能。这些结果强调了当前评估器LLMs的不可靠性，并提倡在实际应用中谨慎实施。代码和数据可以在
    [https://github.com/AI4Bharat/FBI](https://github.com/AI4Bharat/FBI) 获取。
- en: Finding Blind Spots in Evaluator LLMs with Interpretable Checklists
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 使用可解释的检查清单发现评估器LLMs中的盲点
- en: 'Sumanth Doddapaneni^†^†thanks: Equal Contribution.^(1,2)  Mohammed Safi Ur
    Rahman Khan¹¹footnotemark: 1^(1,2) Sshubam Verma¹  Mitesh M. Khapra^(1,2) ¹Nilekani
    Centre at AI4Bharat  ²Indian Institute of Technology, Madras Correspondence: {sumanthd,
    miteshk}@cse.iitm.ac.in, safikhan@ai4bharat.org ![[Uncaptioned image]](img/84e8cc38da48d5225fbf233027bb98c9.png) [https://huggingface.co/datasets/ai4bharat/FBI](https://huggingface.co/datasets/ai4bharat/FBI)  ![[Uncaptioned
    image]](img/af867be5854365eea15ee0db439d833e.png) [https://github.com/AI4Bharat/FBI](https://github.com/AI4Bharat/FBI)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Sumanth Doddapaneni^†^†感谢：平等贡献。^(1,2)  Mohammed Safi Ur Rahman Khan¹¹脚注标记：1^(1,2)
    Sshubam Verma¹  Mitesh M. Khapra^(1,2) ¹Nilekani Centre at AI4Bharat  ²印度理工学院马德拉斯分校
    联系方式：{sumanthd, miteshk}@cse.iitm.ac.in, safikhan@ai4bharat.org ![[无标题图片]](img/84e8cc38da48d5225fbf233027bb98c9.png)  [https://huggingface.co/datasets/ai4bharat/FBI](https://huggingface.co/datasets/ai4bharat/FBI)
    ![[无标题图片]](img/af867be5854365eea15ee0db439d833e.png)  [https://github.com/AI4Bharat/FBI](https://github.com/AI4Bharat/FBI)
- en: 1 Introduction
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: '![Refer to caption](img/9a97732e597a921b823da805db64c719.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/9a97732e597a921b823da805db64c719.png)'
- en: 'Figure 1: We present FBI, our novel meta-evaluation framework designed to assess
    the robustness of evaluator LLMs across diverse tasks and evaluation strategies.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：我们展示了FBI，我们的新型元评估框架，旨在评估评估者LLMs在不同任务和评估策略下的鲁棒性。
- en: Large Language Models (LLMs) are gaining widespread acceptance as the gold standard
    for evaluation in numerous applications, thanks to their efficiency and significant
    reductions in cost & time compared to human evaluators Kim et al. ([2023](#bib.bib18),
    [2024a](#bib.bib19)); Chiang and Lee ([2023](#bib.bib6)); Chen et al. ([2023](#bib.bib3));
    Dubois et al. ([2023](#bib.bib10)). Furthermore, Evaluator LLMs are increasingly
    being utilized in the creation and maintenance of leaderboards for benchmarking
    various AI models Watts et al. ([2024](#bib.bib40)); Zheng et al. ([2023](#bib.bib48)).
    While this reliance on LLMs offers significant advantages, it also presents potential
    drawbacks that warrant careful consideration. If LLMs are not effective evaluators,
    the resulting rankings and assessments could be fundamentally flawed, leading
    to inaccurate conclusions and misguided decisions. Therefore, it is crucial to
    pause and rigorously assess the evaluation capabilities of LLMs.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）由于其高效性以及与人工评估者相比在成本和时间上的显著减少，正在被广泛接受为众多应用中的金标准 Kim et al. ([2023](#bib.bib18),
    [2024a](#bib.bib19)); Chiang and Lee ([2023](#bib.bib6)); Chen et al. ([2023](#bib.bib3));
    Dubois et al. ([2023](#bib.bib10))。此外，评估者LLMs越来越多地用于创建和维护用于基准测试各种AI模型的排行榜 Watts
    et al. ([2024](#bib.bib40)); Zheng et al. ([2023](#bib.bib48))。尽管这种对LLMs的依赖带来了显著的优势，但也存在潜在的缺陷，需要认真考虑。如果LLMs不是有效的评估者，最终的排名和评估可能会存在根本性的缺陷，从而导致不准确的结论和误导性的决策。因此，暂停并严格评估LLMs的评估能力是至关重要的。
- en: Recent studies have explored the effectiveness of LLMs as evaluators and have
    reported strong correlations with human evaluations Dubois et al. ([2023](#bib.bib10));
    Zheng et al. ([2023](#bib.bib48)). While these findings are promising, accepting
    LLMs as reliable evaluators necessitates more nuanced assessments Zeng et al.
    ([2023](#bib.bib46)). As LLMs become integral in a diverse range of tasks, they
    are expected to demonstrate a wide array of abilities, including factual accuracy,
    instruction following, coherence in long-form writing, and reasoning proficiency.
    Consequently, it is crucial to determine if Evaluator LLMs can indeed do a fine
    grained assessment of these varied abilities. Specifically, can they evaluate
    factual correctness, grammar, spelling, mathematical proficiency, and adherence
    to instructions in answers generated by other LLMs? (ref. Fig. [1](#S1.F1 "Figure
    1 ‣ 1 Introduction ‣ Finding Blind Spots in Evaluator LLMs with Interpretable
    Checklists")) The necessity for such thorough fine-grained assessments is underscored
    by the Checklist Ribeiro et al. ([2020](#bib.bib30)) approach, initially applied
    to BERT Devlin et al. ([2019](#bib.bib8)) and subsequently adapted in studies
    across various tasks and models Sai et al. ([2021](#bib.bib32)).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究探讨了 LLM 作为评估者的有效性，并报告了与人类评估的强相关性 Dubois 等人 ([2023](#bib.bib10))；郑等人 ([2023](#bib.bib48))。虽然这些发现令人鼓舞，但接受
    LLM 作为可靠评估者需要更为细致的评估 Zeng 等人 ([2023](#bib.bib46))。随着 LLM 在各种任务中变得越来越重要，预计它们将展示各种能力，包括事实准确性、指令遵循、长文本写作中的连贯性和推理能力。因此，确定评估者
    LLM 是否能够对这些多样化能力进行细致评估是至关重要的。具体而言，它们能否评估其他 LLM 生成的答案中的事实正确性、语法、拼写、数学能力和遵循指令？（参考图[1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ Finding Blind Spots in Evaluator LLMs with Interpretable
    Checklists")）这种细致评估的必要性由检查表 Ribeiro 等人 ([2020](#bib.bib30)) 方法所强调，该方法最初应用于 BERT
    Devlin 等人 ([2019](#bib.bib8))，随后在各种任务和模型的研究中进行了适应 Sai 等人 ([2021](#bib.bib32))。
- en: 'In this work, we introduce FBI, a comprehensive framework designed to Find
    Blind spots in evaluator LLMs using an Interpretable checklist across four fundamental
    text generation abilities: (a) factual accuracy, (b) instruction following, (c)
    coherence in long-form writing, and (d) reasoning proficiency. To rigorously assess
    an Evaluator LLM’s ability to grade answers along these dimensions, we introduce
    perturbations that degrade the quality of the answer in one of these areas, expecting
    that good Evaluator LLMs will detect these quality drops and adjust their scores
    accordingly. Additionally, we develop quality-preserving perturbations where an
    Evaluator LLM should maintain consistent scoring. A detailed description of the
    22 perturbation categories that we used is provided in Table [2](#S3.T2 "Table
    2 ‣ 3.1 Prompt Selection ‣ 3 FBI: Meta-Evaluation Checklist ‣ Finding Blind Spots
    in Evaluator LLMs with Interpretable Checklists"). Staring with 500 prompts, we
    first generate long-form responses using GPT-4-turbo. We then use a human-in-the-loop
    approach, to systematically perturb these responses, resulting in a dataset of
    2400 tuples, where each tuple contains a prompt, response, and perturbed response.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '在这项工作中，我们介绍了 FBI，这是一个全面的框架，旨在通过可解释的检查表发现评估者 LLMs 的盲点，涉及四个基本的文本生成能力：（a）事实准确性，（b）指令遵循，（c）长文本写作中的连贯性，以及（d）推理能力。为了严格评估评估者
    LLM 在这些维度上评分的能力，我们引入了扰动，这些扰动会在某一方面降低答案的质量，期望好的评估者 LLM 能够检测到这些质量下降并相应调整其评分。此外，我们开发了质量保持扰动，其中评估者
    LLM 应保持一致的评分。我们使用的22种扰动类别的详细描述见表[2](#S3.T2 "Table 2 ‣ 3.1 Prompt Selection ‣ 3
    FBI: Meta-Evaluation Checklist ‣ Finding Blind Spots in Evaluator LLMs with Interpretable
    Checklists")。我们从500个提示开始，首先使用 GPT-4-turbo 生成长文本响应。然后，我们使用人机协作的方法，系统地扰动这些响应，生成了一个包含2400个元组的数据集，每个元组包含一个提示、响应和扰动响应。'
- en: Using the generated perturbations, we employed three evaluation paradigms (a)
    single-answer evaluation, (b) pairwise evaluation, and (c) reference-guided evaluation.
    Within each paradigm, we try multiple popular strategies of using Evaluator LLMs,
    such as, providing a rubric, asking for a justification, specifying the axis of
    evaluation, etc. Using these strategies, we assess the evaluation capabilities
    of five widely-used Evaluator LLMs. Our findings indicate that LLMs are currently
    far from being reliable evaluators for text generation tasks. Even with the best
    models and evaluation strategies, Evaluator LLMs failed to identify errors in
    over 50% of cases, on average. Interestingly, across all evaluation strategies,
    we observed that all popular Evaluator LLMs consistently performed poorly. Notably,
    even basic perturbation categories, such as, fluency perturbations (e.g. spellings
    and grammar) posed challenges for the evaluators. We also observed cases where
    Evaluator LLMs did not adjust their scores for perturbed responses despite correctly
    identifying the perturbations in their explanations. When used for single-answer
    grading and pairwise evaluation, Evaluator LLMs showed significant limitations,
    suggesting they are not reliable in these setups. In contrast, when used for reference-based
    evaluation, they demonstrated relatively better performance. Overall, our experiments
    uncovered significant blind spots in Evaluator LLMs, warranting caution in their
    direct application in practical settings.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 使用生成的扰动，我们采用了三种评估范式 (a) 单答案评估，(b) 配对评估，和 (c) 参考引导评估。在每种范式中，我们尝试了多种使用评估 LLMs
    的流行策略，如提供评分标准、要求说明、指定评估轴等。使用这些策略，我们评估了五种广泛使用的评估 LLMs 的能力。我们的发现表明，LLMs 目前远未成为可靠的文本生成任务评估工具。即使使用最好的模型和评估策略，评估
    LLMs 在平均超过 50% 的情况下未能识别错误。有趣的是，在所有评估策略中，我们观察到所有流行的评估 LLMs 一致表现较差。特别是，甚至基本的扰动类别，如流畅性扰动（例如拼写和语法）也对评估者造成了挑战。我们还观察到，在正确识别扰动的解释中，评估
    LLMs 并未调整其对扰动响应的分数。在用于单答案评分和配对评估时，评估 LLMs 显示出显著的局限性，表明它们在这些设置中不可靠。相比之下，当用于基于参考的评估时，它们表现出相对更好的性能。总体而言，我们的实验揭示了评估
    LLMs 中的重大盲点，这在实际应用中需要谨慎对待。
- en: 2 Related Work
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: LLMs as Evaluators. LLMs have been increasingly used for automated evaluation
    for various NLG tasks Wang et al. ([2023a](#bib.bib36)); Chiang and yi Lee ([2023](#bib.bib5));
    Kocmi and Federmann ([2023](#bib.bib21)). We broadly classify this into two paradigms
    - (i) reference-driven evaluations Fu et al. ([2023](#bib.bib11)); Kim et al.
    ([2023](#bib.bib18)), and (ii) reference-free evaluations Liu et al. ([2023](#bib.bib23));
    Zheng et al. ([2023](#bib.bib48)). The evaluator is either asked for a score (score-based
    evaluation) Liu et al. ([2023](#bib.bib23)); Zheng et al. ([2023](#bib.bib48));
    Hada et al. ([2023](#bib.bib13)) or to choose the best amongst two given responses
    (pairwise comparison evaluation) Zheng et al. ([2023](#bib.bib48)); Wang et al.
    ([2023b](#bib.bib37)); Liusie et al. ([2023](#bib.bib24)). Additionally, various
    open-source evaluation-specific trained models have also been proposed Wang et al.
    ([2023d](#bib.bib39)); Kim et al. ([2023](#bib.bib18)); Zhu et al. ([2023](#bib.bib51)).
    Further, advanced ensemble approaches include evaluation via multi-agent interactions Chan
    et al. ([2023](#bib.bib2)); Zhang et al. ([2023](#bib.bib47)) or with external
    agents Min et al. ([2023](#bib.bib27)); Hasanbeig et al. ([2023](#bib.bib14)).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 作为评估工具。LLMs 已被越来越多地用于各种 NLG 任务的自动评估 Wang 等人 ([2023a](#bib.bib36))；Chiang
    和 Yi Lee ([2023](#bib.bib5))；Kocmi 和 Federmann ([2023](#bib.bib21))。我们将其广泛分类为两种范式
    - (i) 参考驱动的评估 Fu 等人 ([2023](#bib.bib11))；Kim 等人 ([2023](#bib.bib18))，和 (ii) 无参考的评估
    Liu 等人 ([2023](#bib.bib23))；Zheng 等人 ([2023](#bib.bib48))。评估者要么被要求给出一个分数（基于分数的评估）
    Liu 等人 ([2023](#bib.bib23))；Zheng 等人 ([2023](#bib.bib48))；Hada 等人 ([2023](#bib.bib13))，要么在两个给定的响应中选择最佳的（配对比较评估）
    Zheng 等人 ([2023](#bib.bib48))；Wang 等人 ([2023b](#bib.bib37))；Liusie 等人 ([2023](#bib.bib24))。此外，还提出了各种开源的、针对评估的训练模型
    Wang 等人 ([2023d](#bib.bib39))；Kim 等人 ([2023](#bib.bib18))；Zhu 等人 ([2023](#bib.bib51))。进一步的高级集成方法包括通过多代理交互进行评估
    Chan 等人 ([2023](#bib.bib2))；Zhang 等人 ([2023](#bib.bib47)) 或与外部代理一起评估 Min 等人 ([2023](#bib.bib27))；Hasanbeig
    等人 ([2023](#bib.bib14))。
- en: Biases in Evalautor LLMs. Studies around Evaluator LLMs have highlighted the
    various biases - position bias Zheng et al. ([2023](#bib.bib48)); Wang et al.
    ([2023c](#bib.bib38)), self preference bias Panickssery et al. ([2024](#bib.bib29));
    Liu et al. ([2023](#bib.bib23)), verbosity bias Wu and Aji ([2023](#bib.bib42));
    Zeng et al. ([2023](#bib.bib46)), etc. Various approaches, including chain-of-thought
    reasoning Zheng et al. ([2023](#bib.bib48)); Zeng et al. ([2023](#bib.bib46)),
    position-swapping Zeng et al. ([2023](#bib.bib46)), among others, have been suggested
    to mitigate some of these. Recent studies Hada et al. ([2023](#bib.bib13)); Saha
    et al. ([2023](#bib.bib31)) also show the effectiveness of the evaluators can
    be increased by evaluating specific axes and providing detailed rubrics/rules Ye
    et al. ([2023](#bib.bib45)); Kim et al. ([2024a](#bib.bib19)).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 评估者LLMs中的偏差。对评估者LLMs的研究突出了各种偏差 - 位置偏差 Zheng等人 ([2023](#bib.bib48))；Wang等人 ([2023c](#bib.bib38))，自我偏好偏差 Panickssery等人
    ([2024](#bib.bib29))；Liu等人 ([2023](#bib.bib23))，冗长偏差 Wu和Aji ([2023](#bib.bib42))；Zeng等人
    ([2023](#bib.bib46))，等等。已经提出了包括思维链推理 Zheng等人 ([2023](#bib.bib48))；Zeng等人 ([2023](#bib.bib46))，位置交换 Zeng等人
    ([2023](#bib.bib46))，等在内的各种方法，以减轻这些偏差。近期研究 Hada等人 ([2023](#bib.bib13))；Saha等人
    ([2023](#bib.bib31)) 还显示，通过评估特定轴线并提供详细的评分标准/规则 Ye等人 ([2023](#bib.bib45))；Kim等人
    ([2024a](#bib.bib19))，可以提高评估者的有效性。
- en: Evaluation of Evaluator LLMs. Critically analysing evaluation metrics and suggesting
    methods to improve their robustness has always been of interest to the NLP community Sai B
    et al. ([2023](#bib.bib33)); Mathur et al. ([2020](#bib.bib25)). Recent studies
    have evaluated the efficacy of LLMs as evaluators for specific types of tasks Hada
    et al. ([2024](#bib.bib12)); Shen et al. ([2023](#bib.bib34)) and evaluation paradigms Wang
    et al. ([2023b](#bib.bib37), [a](#bib.bib36)) by assessing their agreement with
    human evaluations Hada et al. ([2023](#bib.bib13)); Chiang and Lee ([2023](#bib.bib6));
    Zheng et al. ([2023](#bib.bib48)). Additionally, the robustness of these evaluators
    has been tested using adversarial examples Kamoi et al. ([2024](#bib.bib17));
    Chen et al. ([2024](#bib.bib4)); Wu and Aji ([2023](#bib.bib42)), further showing
    their strengths and weaknesses.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 对评估者LLMs的评估。对评估指标进行批判性分析并建议改进其鲁棒性的方法，一直以来都是NLP社区关注的重点 Sai B等人 ([2023](#bib.bib33))；Mathur等人
    ([2020](#bib.bib25))。近期研究已评估了LLMs作为特定任务类型评估者的有效性 Hada等人 ([2024](#bib.bib12))；Shen等人
    ([2023](#bib.bib34))，以及评估范式 Wang等人 ([2023b](#bib.bib37), [a](#bib.bib36))，通过评估它们与人类评估的一致性 Hada等人
    ([2023](#bib.bib13))；Chiang和Lee ([2023](#bib.bib6))；Zheng等人 ([2023](#bib.bib48))。此外，这些评估者的鲁棒性也通过对抗性示例进行了测试 Kamoi等人
    ([2024](#bib.bib17))；Chen等人 ([2024](#bib.bib4))；Wu和Aji ([2023](#bib.bib42))，进一步展示了它们的优缺点。
- en: 'Our proposed framework represents a significant departure from these existing
    approaches in several key aspects. First, we focus on a broader set of essential
    abilities: factual understanding, instruction following, long-form writing, and
    reasoning. Second, all prompts and the 2400 perturbed answers in our framework
    are carefully crafted and/or validated by humans, ensuring high quality and relevance
    to the abilities being evaluated. Third, our framework offers finer granularity
    in perturbation types, allowing us to finely identify and isolate the capabilities
    and limitations of Evaluator LLMs. This detailed analysis assists in making more
    knowledgeable choices about when to utilize LLMs as evaluators. Lastly, we focus
    on three popular evaluation paradigms, viz., reference-less single answer scoring,
    reference-less pairwise comparison, and reference based scoring, thereby providing
    a comprehensive toolkit for evaluating LLM performance across different dimensions.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出的框架在几个关键方面显著不同于现有方法。首先，我们关注更广泛的一组关键能力：事实理解、指令跟随、长篇写作和推理。其次，我们框架中的所有提示和2400个扰动答案都经过精心设计和/或由人工验证，确保高质量和与被评估能力的相关性。第三，我们的框架提供了更细致的扰动类型，使我们能够细致识别和隔离评估者LLMs的能力和局限性。这种详细分析有助于在何时使用LLMs作为评估者时做出更明智的选择。最后，我们关注三个流行的评估范式，即无参考的单一答案评分、无参考的成对比较以及基于参考的评分，从而提供了一个全面的工具包，用于在不同维度上评估LLM性能。
- en: '3 FBI: Meta-Evaluation Checklist'
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '3 FBI: 元评估检查表'
- en: 'We introduce FBI, a meta-evaluation benchmark designed to assess the capabilities
    of Evaluator LLMs in examining the outputs of other LLMs across four distinct
    task abilities: (i) Factual accuracy, (ii) Reasoning ability, (iii) instruction
    following, and (iv) proficiency in long-form writing. Each instance within the
    benchmark comprises a tuple ($I$, $A_{gold}$, $A_{perturb}$), where $I$ represents
    the input instruction or prompt given to the model, $A_{gold}$ denotes the correct
    or gold answer, and $A_{perturb}$ signifies a perturbed version of the gold answer.
    The perturbed answers, $A_{perturb}$, are generated by introducing specific types
    of errors across each of the four task abilities (Table [2](#S3.T2 "Table 2 ‣
    3.1 Prompt Selection ‣ 3 FBI: Meta-Evaluation Checklist ‣ Finding Blind Spots
    in Evaluator LLMs with Interpretable Checklists")) to evaluate whether LLM evaluators
    can accurately identify and account for these errors in the perturbed answers.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '我们引入了FBI，一个元评估基准，旨在评估Evaluator LLMs在检查其他LLMs输出的四种不同任务能力上的能力：(i) 事实准确性，(ii)
    推理能力，(iii) 指令遵循，以及 (iv) 长篇写作能力。基准中的每个实例包括一个元组（$I$，$A_{gold}$，$A_{perturb}$），其中
    $I$ 代表给定模型的输入指令或提示，$A_{gold}$ 表示正确答案或金标准答案，$A_{perturb}$ 表示金标准答案的扰动版本。扰动答案 $A_{perturb}$
    是通过在四种任务能力中引入特定类型的错误来生成的（表[2](#S3.T2 "表 2 ‣ 3.1 提示选择 ‣ 3 FBI: 元评估检查表 ‣ 使用可解释检查表发现Evaluator
    LLMs的盲点")），以评估LLM评估者是否能够准确识别和解释这些扰动答案中的错误。'
- en: 'The perturbations are based on perturbation categories carefully crafted by
    human annotators, informed by the prevalent failure modes in current LLMs Min
    et al. ([2023](#bib.bib27)); Wu et al. ([2023](#bib.bib43)); Zhou et al. ([2023b](#bib.bib50)).
    These human annotators are graduate students who are well aware of the typical
    errors made by LLMs. Such human oversight is used throughout the benchmark’s development,
    from prompt selection ($\S$ [3.1](#S3.SS1 "3.1 Prompt Selection ‣ 3 FBI: Meta-Evaluation
    Checklist ‣ Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"))
    to defining perturbation categories ($\S$ [3.2](#S3.SS2 "3.2 Perturbation Categories
    ‣ 3 FBI: Meta-Evaluation Checklist ‣ Finding Blind Spots in Evaluator LLMs with
    Interpretable Checklists")) and creating the perturbations ($\S$ [3.3](#S3.SS3
    "3.3 Perturbation Generation ‣ 3 FBI: Meta-Evaluation Checklist ‣ Finding Blind
    Spots in Evaluator LLMs with Interpretable Checklists")). To ensure a high standard
    of accuracy and reliability, all perturbations within FBI undergo rigorous manual
    vetting($\S$ [3.4](#S3.SS4 "3.4 Human-In-The-Loop ‣ 3 FBI: Meta-Evaluation Checklist
    ‣ Finding Blind Spots in Evaluator LLMs with Interpretable Checklists")). Table [1](#S3.T1
    "Table 1 ‣ 3 FBI: Meta-Evaluation Checklist ‣ Finding Blind Spots in Evaluator
    LLMs with Interpretable Checklists") presents some statistics about FBI, and the
    detailed generation process is discussed in the following sub-sections.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '扰动是基于由人工注释者精心设计的扰动类别，这些类别受到当前LLMs常见失败模式的启发（Min等人，[2023](#bib.bib27)；Wu等人，[2023](#bib.bib43)；Zhou等人，[2023b](#bib.bib50)）。这些人工注释者是熟悉LLMs典型错误的研究生。在整个基准开发过程中，从提示选择（$\S$
    [3.1](#S3.SS1 "3.1 提示选择 ‣ 3 FBI: 元评估检查表 ‣ 使用可解释检查表发现Evaluator LLMs的盲点")）到定义扰动类别（$\S$
    [3.2](#S3.SS2 "3.2 扰动类别 ‣ 3 FBI: 元评估检查表 ‣ 使用可解释检查表发现Evaluator LLMs的盲点")）和创建扰动（$\S$
    [3.3](#S3.SS3 "3.3 扰动生成 ‣ 3 FBI: 元评估检查表 ‣ 使用可解释检查表发现Evaluator LLMs的盲点")），都使用了这种人工监督。为了确保高标准的准确性和可靠性，FBI中的所有扰动都经过严格的人工审核（$\S$
    [3.4](#S3.SS4 "3.4 人工介入 ‣ 3 FBI: 元评估检查表 ‣ 使用可解释检查表发现Evaluator LLMs的盲点")）。表[1](#S3.T1
    "表 1 ‣ 3 FBI: 元评估检查表 ‣ 使用可解释检查表发现Evaluator LLMs的盲点")展示了有关FBI的一些统计数据，详细的生成过程将在以下小节中讨论。'
- en: '| Category | # Instances |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 分类 | 实例数 |'
- en: '| --- | --- |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Long Form (LF) | 528 |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 长篇（LF） | 528 |'
- en: '|     Grammar | 92 |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '|     语法 | 92 |'
- en: '|     Spelling | 100 |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '|     拼写 | 100 |'
- en: '|     Consistency | 84 |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '|     一致性 | 84 |'
- en: '|     Chronology | 71 |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '|     年代顺序 | 71 |'
- en: '|     Coherence | 91 |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '|     连贯性 | 91 |'
- en: '|     Comprehensiveness | 90 |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '|     全面性 | 90 |'
- en: '| Factual (F) | 483 |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 事实（F） | 483 |'
- en: '|     Contextual | 94 |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '|     上下文 | 94 |'
- en: '|     Entity | 87 |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '|     实体 | 87 |'
- en: '|     Incorrect Fact | 68 |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '|     不正确的事实 | 68 |'
- en: '|     Number Errors | 74 |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '|     数字错误 | 74 |'
- en: '|     Opposite Fact | 91 |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '|     相反事实 | 91 |'
- en: '|     Remove Fact | 69 |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '|     去除事实 | 69 |'
- en: '| Instruction Following (IF) | 381 |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 指令遵循（IF） | 381 |'
- en: '|     Do More | 50 |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '|     做更多 | 50 |'
- en: '|     Do Less | 100 |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '|     做更少 | 100 |'
- en: '|     Ignore Format | 99 |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '|     忽略格式 | 99 |'
- en: '|     Sequence Errors | 49 |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '|     序列错误 | 49 |'
- en: '|     Assumptions | 81 |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '|     假设 | 81 |'
- en: '| Reasoning (R) | 494 |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 推理 (R) | 494 |'
- en: '|     Calculations | 149 |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '|     计算 | 149 |'
- en: '|     Copying Numbers | 83 |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '|     复制数字 | 83 |'
- en: '|     Final Errors | 97 |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '|     最终错误 | 97 |'
- en: '|     Incorrect Units | 77 |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '|     错误单位 | 77 |'
- en: '|     Wrong Formula | 88 |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '|     错误公式 | 88 |'
- en: '| Score Invariant (SI) | 516 |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 评分不变性 (SI) | 516 |'
- en: '| Total | 2400 |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 2400 |'
- en: 'Table 1: Statistics of perturbations across all the 4 task abilities and each
    of the perturbation categories.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：所有4种任务能力及每种扰动类别的扰动统计数据。
- en: 3.1 Prompt Selection
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 提示选择
- en: 'We selected six test sets containing prompts in English, viz., WizardLM Xu
    et al. ([2023](#bib.bib44)), MT Bench Zheng et al. ([2023](#bib.bib48)), UltraChat Ding
    et al. ([2023](#bib.bib9)), LIMA Zhou et al. ([2023a](#bib.bib49)), LLMBar Zeng
    et al. ([2023](#bib.bib46)), and IFEval Zhou et al. ([2023b](#bib.bib50)). These
    test sets were selected for their recency and because they contain prompts for
    long-form generation, creativity, and open-ended tasks that require instruction-following.
    Collectively, these test sets comprise of 1809 prompts. We manually categorized
    each prompt into one of the 4 task categories:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了六个包含英文提示的测试集，即WizardLM Xu et al. ([2023](#bib.bib44))，MT Bench Zheng et
    al. ([2023](#bib.bib48))，UltraChat Ding et al. ([2023](#bib.bib9))，LIMA Zhou et
    al. ([2023a](#bib.bib49))，LLMBar Zeng et al. ([2023](#bib.bib46))，以及IFEval Zhou
    et al. ([2023b](#bib.bib50))。这些测试集因其最新性以及包含长篇生成、创造力和需要指令跟随的开放性任务的提示而被选择。所有这些测试集共包含1809个提示。我们将每个提示手动分类为4个任务类别之一：
- en: Long Form Writing (LF): These prompts require generating long pieces of text
    and explore generic topics, often including detailed analysis and storytelling.
    For example, How can I improve my time management skills?
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '长篇写作 (LF): 这些提示要求生成长篇文本，并探讨通用话题，通常包括详细分析和讲故事。例如，我如何提高我的时间管理技能？'
- en: Factual (F): These prompts seek objective information or facts. For example,
    What is the primary function of a capacitor in an electrical circuit?
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '事实 (F): 这些提示寻求客观信息或事实。例如，电路中电容器的主要功能是什么？'
- en: 'Instruction Following (IF): These prompts require executing specific steps
    or guidelines to achieve a particular outcome or answer. For example, Write a
    poem with four lines and the following words: peace, sky, race, ground.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '指令跟随 (IF): 这些提示要求执行特定的步骤或指导方针以达到特定的结果或答案。例如，写一首包含以下单词的四行诗：和平、天空、竞赛、地面。'
- en: Reasoning (R): These prompts necessitate the application of logic, mathematics,
    and critical thinking to analyze information and draw conclusions. For example,
    A bat and a ball together cost $1.10\. The bat costs $1.00 more than the ball.
    How much does the ball cost?
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '推理 (R): 这些提示需要应用逻辑、数学和批判性思维来分析信息并得出结论。例如，一只球棒和一个球一共花费$1.10。球棒比球贵$1.00。球多少钱？'
- en: We sampled 100 questions from each of the four abilities, supplementing prompts
    requiring reasoning ability from the GSM8k Cobbe et al. ([2021](#bib.bib7)) and
    MATH Hendrycks et al. ([2021](#bib.bib15)) benchmarks. Additionally, we created
    200 prompts tailored to instruction following to address specific perturbation
    categories¹¹1Based on our categorization, we were unable to find a sufficient
    number of prompts in existing test sets to fit the perturbation categories.. The
    gold answers ($A_{gold}$) for all prompts were generated using the GPT-4-turbo
    model. To ensure the quality and accuracy of $A_{gold}$, we conducted manual verification
    by randomly sampling 25% instances from each category and found that the gold
    answers maintain a high level of correctness. Importantly, we emphasize that the
    quality of gold answers is not critical in our study, as our primary focus is
    on directional score changes (i.e., we are interested in knowing if a perturbed
    answer with clear errors scores relatively lower than the original answer which
    did not have these errors).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从四种能力中的每一种中抽取了100个问题，补充了需要推理能力的提示，这些提示来自GSM8k Cobbe et al. ([2021](#bib.bib7))
    和MATH Hendrycks et al. ([2021](#bib.bib15)) 基准。此外，我们还创建了200个针对指令跟随的提示，以应对特定的扰动类别¹¹1基于我们的分类，我们在现有测试集中未能找到足够数量的提示来适应这些扰动类别..
    所有提示的金标准答案（$A_{gold}$）均使用GPT-4-turbo模型生成。为了确保$A_{gold}$的质量和准确性，我们通过随机抽样每个类别中的25%实例进行了人工验证，结果发现金标准答案保持了较高的正确性。重要的是，我们强调金标准答案的质量在我们的研究中并非关键，因为我们的主要关注点是方向性评分变化（即，我们感兴趣的是扰动的答案是否会明显低于没有这些错误的原始答案）。
- en: '| Task | Perturbation Axis | Description |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | 扰动轴 | 描述 |'
- en: '| LF | Grammar | Introducing grammatical errors in the answer. Eg: This is
    good $\rightarrow$ This are good. |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| LF | 语法 | 在答案中引入语法错误。例如：This is good $\rightarrow$ This are good。 |'
- en: '| Spelling | Introducing “valid” spelling errors in the answer. Eg: Toxicity
    $\rightarrow$ Tocixity. |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 拼写 | 在答案中引入“有效”的拼写错误。例如：Toxicity $\rightarrow$ Tocixity。 |'
- en: '| Consistency | Introducing errors in the “consistency” of the answer (like
    tone, terminology, etc.) |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 一致性 | 引入“答案一致性”（如语调、术语等）中的错误。 |'
- en: '| Chronology | Introducing errors in the chronological or the logical flow
    of the answer. |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 时间顺序 | 在答案的时间顺序或逻辑流程中引入错误。 |'
- en: '| Coherence | Introducing errors that affect the coherence of the answer. |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 连贯性 | 引入影响答案连贯性的错误。 |'
- en: '| Comprehensiveness | Introducing vagueness, irrelevance or lack of context
    in the answer. |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 完整性 | 在答案中引入模糊、不相关或缺乏上下文的内容。 |'
- en: '| F | Contextual | Replacing fact with a contextually similar incorrect fact.
    Eg: electricity $\rightarrow$ magnetism. |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| F | 上下文 | 用上下文类似的错误事实替换事实。例如：电 $\rightarrow$ 磁。 |'
- en: '| Entity | Replacing a named entity with an incorrect entity. Eg: Poland $\rightarrow$
    London. |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 实体 | 用错误的实体替换命名实体。例如：Poland $\rightarrow$ London。'
- en: '| Incorrect Fact | Adding a new contextually relevant incorrect fact in the
    answer. |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 错误事实 | 在答案中添加新的、上下文相关的错误事实。 |'
- en: '| Number Errors | Introducing errors in the various numbers reported in the
    answer. Eg: 1987 $\rightarrow$ 1887. |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 数字错误 | 在答案中引入各种数字错误。例如：1987 $\rightarrow$ 1887。 |'
- en: '| Opposite Fact | Replacing a fact in the answer with its negation. Eg: … will
    have … $\rightarrow$ … wont have …. |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 相反事实 | 用其否定形式替换答案中的事实。例如：… 将会有 … $\rightarrow$ … 不会有 … |'
- en: '| Remove Fact | Removing a fact critical to the correctness and completeness
    of the answer. |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 删除事实 | 删除对答案的正确性和完整性至关重要的事实。 |'
- en: '| IF | Do Less | Doing less than what is explicitly requested in the question.
    |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| IF | 做得更少 | 做的比问题中明确要求的少。 |'
- en: '| Do More | Doing more than what is explicitly requested in the question. |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 做得更多 | 做的比问题中明确要求的多。 |'
- en: '| Ignore Format | Ignoring the formatting and other constraints mentioned in
    the question. |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 忽略格式 | 忽略问题中提到的格式和其他约束。 |'
- en: '| Sequence Errors | Ignoring the sequence in the response when explicitly requested
    in the instruction. |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 序列错误 | 忽略在指令中明确要求的响应顺序。 |'
- en: '| Assumptions | Making new incorrect assumptions about the instruction. |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 假设 | 对指令做出新的错误假设。 |'
- en: '| R | Calculations | Introducing calculation errors in the answer. Eg: $2+3=5$
    $\rightarrow$ $2+3=6$ |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| R | 计算 | 在答案中引入计算错误。例如：$2+3=5$ $\rightarrow$ $2+3=6$ |'
- en: '| Copying Numbers | Introducing errors while considering the numbers mentioned
    in the instruction. |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 复制数字 | 在考虑指令中提到的数字时引入错误。 |'
- en: '| Final Errors | Introducing errors only the final reported answer while retaining
    the correct solution. |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 最终错误 | 仅在最终报告的答案中引入错误，同时保留正确的解答。 |'
- en: '| Incorrect Units | Introducing errors in the units reported and considered
    in the answer. |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 错误单位 | 在答案中引入报告和考虑的单位错误。 |'
- en: '| Wrong Formula | Introducing errors in the formula used in the answer. Eg:
    $\pi r^{2}$ $\rightarrow$ $2\pi r$ |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 错误公式 | 在答案中使用的公式中引入错误。例如：$\pi r^{2}$ $\rightarrow$ $2\pi r$ |'
- en: '| SI | Score Invariant | Introducing modifications in the answer which would
    not result in a score penalty. |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| SI | 分数不变 | 引入不会导致分数惩罚的答案修改。 |'
- en: 'Table 2: Perturbation categories across each of the task abilities. The green
    highlights indicate the original text and the red highlights indicated the perturbed
    text. Complete examples of each perturbation can be found in supplementary material.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：每种任务能力下的扰动类别。绿色高亮表示原文，红色高亮表示扰动文本。每种扰动的完整示例可以在补充材料中找到。
- en: 3.2 Perturbation Categories
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 扰动类别
- en: 'LLMs exhibit numerous failure modes, encompassing shortcomings in reasoning Wu
    et al. ([2023](#bib.bib43)); Wei et al. ([2022](#bib.bib41)), factuality Hu et al.
    ([2024](#bib.bib16)); Min et al. ([2023](#bib.bib27)), instruction-following Zhou
    et al. ([2023b](#bib.bib50)); Li et al. ([2023](#bib.bib22)), and, in some instances,
    coherence and consistency Naismith et al. ([2023](#bib.bib28)); Shen et al. ([2023](#bib.bib34))
    in generated text. Given that we utilize Evaluator LLMs to assess responses in
    one or more of these abilities, it is imperative for the evaluator to excel in
    them. Our perturbations across each task ability are crafted keeping these failure
    modes in mind, as presented in Table [2](#S3.T2 "Table 2 ‣ 3.1 Prompt Selection
    ‣ 3 FBI: Meta-Evaluation Checklist ‣ Finding Blind Spots in Evaluator LLMs with
    Interpretable Checklists"). While our perturbations are primarily designed to
    decrease scores, we also develop score-invariant perturbations ($\S$ [3.5](#S3.SS5
    "3.5 Score-Invariant Perturbations ‣ 3 FBI: Meta-Evaluation Checklist ‣ Finding
    Blind Spots in Evaluator LLMs with Interpretable Checklists")), which are intended
    not to affect the score relative to the gold answer.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 'LLM 展现了众多失败模式，包括推理短板 Wu 等人（[2023](#bib.bib43)）；Wei 等人（[2022](#bib.bib41)），事实性
    Hu 等人（[2024](#bib.bib16)）；Min 等人（[2023](#bib.bib27)），指令跟随 Zhou 等人（[2023b](#bib.bib50)）；Li
    等人（[2023](#bib.bib22)），以及在某些情况下，生成文本的一致性和连贯性 Naismith 等人（[2023](#bib.bib28)）；Shen
    等人（[2023](#bib.bib34)）。鉴于我们利用评估者 LLM 来评估这些能力中的一个或多个，评估者必须在这些方面表现出色。我们的每项任务能力的扰动设计时考虑了这些失败模式，如表
    [2](#S3.T2 "Table 2 ‣ 3.1 Prompt Selection ‣ 3 FBI: Meta-Evaluation Checklist
    ‣ Finding Blind Spots in Evaluator LLMs with Interpretable Checklists") 所示。虽然我们的扰动主要旨在降低分数，但我们也开发了分数不变扰动（$\S$
    [3.5](#S3.SS5 "3.5 Score-Invariant Perturbations ‣ 3 FBI: Meta-Evaluation Checklist
    ‣ Finding Blind Spots in Evaluator LLMs with Interpretable Checklists")），这些扰动旨在不影响相对于黄金答案的分数。'
- en: 3.3 Perturbation Generation
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 扰动生成
- en: 'To generate perturbed answers ($A_{perturb}$) along each of the defined categories
    ($\S$ [3.2](#S3.SS2 "3.2 Perturbation Categories ‣ 3 FBI: Meta-Evaluation Checklist
    ‣ Finding Blind Spots in Evaluator LLMs with Interpretable Checklists")), we use
    GPT-4-turbo by prompting it with specific instructions tailored to each perturbation
    category. The model was tasked with producing perturbed answers and explaining
    the reasoning behind each perturbation. We iteratively refined the instructions
    by manually reviewing a sample of 25% of perturbed answers for each category,
    till we were satisfied with the generated perturbations.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '为了生成每个定义类别中的扰动答案（$A_{perturb}$）（$\S$ [3.2](#S3.SS2 "3.2 Perturbation Categories
    ‣ 3 FBI: Meta-Evaluation Checklist ‣ Finding Blind Spots in Evaluator LLMs with
    Interpretable Checklists")），我们使用 GPT-4-turbo，通过特定指令来提示每个扰动类别。模型的任务是生成扰动答案并解释每个扰动的原因。我们通过手动审查每个类别中
    25% 的扰动答案来迭代地完善指令，直到对生成的扰动感到满意。'
- en: 3.4 Human-In-The-Loop
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 人工参与
- en: While GPT generally succeeds in generating the expected perturbations, we observed
    instances where the model (i) deviates from the intended perturbation, (ii) produces
    the incorrect style of perturbation, or (iii) accurately generates the reasoning
    but fails to reflect it in $A_{perturb}$. To address these inconsistencies, we
    meticulously vet all generated perturbations through a manual review process.
    Each perturbed answer produced by GPT-4-turbo is examined against $A_{gold}$,
    and then categorized as valid, invalid, or score invariant. A perturbation is
    considered valid only if it should logically result in a scoring penalty as determined
    by human annotators. The vetting is carried out by students who possess a comprehensive
    understanding of LLM literature, holding at least a bachelor’s or master’s degree.
    To aid in validating perturbations, we developed a tool, the details of which
    are outlined in Appendix [A](#A1 "Appendix A Manual Verication Process of the
    Perturbations ‣ Finding Blind Spots in Evaluator LLMs with Interpretable Checklists").
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 GPT 通常能够成功生成预期的扰动，但我们观察到模型（i）偏离了预期的扰动，（ii）生成了不正确风格的扰动，或（iii）准确地生成了推理但未能在
    $A_{perturb}$ 中反映。为了解决这些不一致性，我们通过手动审查过程仔细审核所有生成的扰动。每个由 GPT-4-turbo 生成的扰动答案都与 $A_{gold}$
    进行比较，然后分类为有效、无效或分数不变。扰动只有在根据人工标注者的判断应该逻辑上导致评分惩罚时才被认为是有效的。审查工作由对 LLM 文献有全面了解的学生进行，他们至少拥有学士或硕士学位。为了辅助验证扰动，我们开发了一种工具，详细信息见附录
    [A](#A1 "Appendix A Manual Verication Process of the Perturbations ‣ Finding Blind
    Spots in Evaluator LLMs with Interpretable Checklists")。
- en: 3.5 Score-Invariant Perturbations
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.5 分数不变扰动
- en: 'Score-invariant perturbations are those modifications that do not warrant a
    scoring penalty. These are collected in two ways: (i) human annotators categorize
    specific instances from our initial list as invariant ($\S$ [3.4](#S3.SS4 "3.4
    Human-In-The-Loop ‣ 3 FBI: Meta-Evaluation Checklist ‣ Finding Blind Spots in
    Evaluator LLMs with Interpretable Checklists")), and (ii) prompting Gemini-1.5-Pro
    model to paraphrase $A_{gold}$ ensuring retention of all original facts and details
    followed by human verification on a sample. We collect 516 score invariant perturbations
    in total.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '不变评分的扰动是那些不会导致评分处罚的修改。这些修改通过两种方式收集：（i）人类注释者将我们初始列表中的特定实例分类为不变（$\S$ [3.4](#S3.SS4
    "3.4 Human-In-The-Loop ‣ 3 FBI: Meta-Evaluation Checklist ‣ Finding Blind Spots
    in Evaluator LLMs with Interpretable Checklists")），以及（ii）提示 Gemini-1.5-Pro 模型对
    $A_{gold}$ 进行意译，确保保留所有原始事实和细节，之后由人类对样本进行验证。我们总共收集了 516 个不变评分的扰动。'
- en: 4 Strategies for using Evaluator LLMs
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Evaluator LLM 的 4 种策略
- en: 'In this section, we outline the prompting strategies employed by Evaluator
    LLMs benchmarked on FBI. An Evaluator LLM, $f(\cdot)$, takes the input instruction,
    LLM generated response and an evaluation prompt, $P_{eval}$, as input, and is
    required to generate a score and an optional explanation. To make the evaluation
    more robust, the evaluator may also be provided with additional information specifying
    the axes of evaluation, rubrics, rules, and other criteria. Our study focuses
    on 3 evaluation paradigms: (i) Single-answer scoring ($\S$[4.1](#S4.SS1 "4.1 Single
    Answer Scoring ‣ 4 Strategies for using Evaluator LLMs ‣ Finding Blind Spots in
    Evaluator LLMs with Interpretable Checklists")), (ii) Pairwise comparison ($\S$[4.2](#S4.SS2
    "4.2 Pairwise Comparison ‣ 4 Strategies for using Evaluator LLMs ‣ Finding Blind
    Spots in Evaluator LLMs with Interpretable Checklists")), and (iii) Reference-guided
    evaluation ($\S$[4.3](#S4.SS3 "4.3 Reference-guided Single Answer Scoring ‣ 4
    Strategies for using Evaluator LLMs ‣ Finding Blind Spots in Evaluator LLMs with
    Interpretable Checklists")). For all the strategies evaluation prompts $P_{eval}$
    are adapted from Zheng et al. ([2023](#bib.bib48)); Zeng et al. ([2023](#bib.bib46));
    Hada et al. ([2023](#bib.bib13)).'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们概述了在 FBI 基准测试中使用的 Evaluator LLM 的提示策略。Evaluator LLM，即 $f(\cdot)$，接收输入指令、LLM
    生成的响应和评估提示 $P_{eval}$ 作为输入，并需生成一个评分和一个可选的解释。为了使评估更具鲁棒性，评估者也可以提供额外的信息，以指定评估轴、评分标准、规则和其他标准。我们的研究集中于
    3 种评估范式：（i）单一答案评分（$\S$[4.1](#S4.SS1 "4.1 Single Answer Scoring ‣ 4 Strategies
    for using Evaluator LLMs ‣ Finding Blind Spots in Evaluator LLMs with Interpretable
    Checklists")），（ii）成对比较（$\S$[4.2](#S4.SS2 "4.2 Pairwise Comparison ‣ 4 Strategies
    for using Evaluator LLMs ‣ Finding Blind Spots in Evaluator LLMs with Interpretable
    Checklists")），以及（iii）参考指导评估（$\S$[4.3](#S4.SS3 "4.3 Reference-guided Single Answer
    Scoring ‣ 4 Strategies for using Evaluator LLMs ‣ Finding Blind Spots in Evaluator
    LLMs with Interpretable Checklists")）。所有策略的评估提示 $P_{eval}$ 均改编自 Zheng 等人（[2023](#bib.bib48)）；Zeng
    等人（[2023](#bib.bib46)）；Hada 等人（[2023](#bib.bib13)）。
- en: 4.1 Single Answer Scoring
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 单一答案评分
- en: In this paradigm, evaluator $f(\cdot)$ is tasked with scoring a model response
    based solely on its parameterized knowledge.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一范式中，评估者 $f(\cdot)$ 的任务是仅基于其参数化知识对模型响应进行评分。
- en: Vanilla^∗
  id: totrans-106
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Vanilla^∗
- en: 'Zheng et al. ([2023](#bib.bib48)): In this strategy, the evaluator $f(\cdot)$
    is presented with only the input instruction $I$ and a model response $A_{model}$.
    The role of $f(\cdot)$ is to evaluate $A_{model}$ and assign a score, denoted
    as $f(P_{eval},I,A_{model})\rightarrow(score)$.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: Zheng 等人（[2023](#bib.bib48)）：在这一策略中，评估者 $f(\cdot)$ 仅接收输入指令 $I$ 和模型响应 $A_{model}$。$f(\cdot)$
    的角色是评估 $A_{model}$ 并分配一个评分，表示为 $f(P_{eval},I,A_{model})\rightarrow(score)$。
- en: Vanilla
  id: totrans-108
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Vanilla
- en: 'Zheng et al. ([2023](#bib.bib48)): This strategy extends “Vanilla^∗”, where
    the evaluator $f(\cdot)$ is tasked not only with scoring the model response $A_{model}$
    but also providing an explanation for the score - represented as $f(P_{eval},I,A_{model})\rightarrow(exp,score)$.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Zheng 等人（[2023](#bib.bib48)）：这一策略扩展了“Vanilla^∗”，在这里，评估者 $f(\cdot)$ 的任务不仅是对模型响应
    $A_{model}$ 进行评分，还要为评分提供解释——表示为 $f(P_{eval},I,A_{model})\rightarrow(exp,score)$。
- en: Rubric
  id: totrans-110
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 评分标准
- en: 'Zeng et al. ([2023](#bib.bib46)): In this strategy, in addition to the instruction
    $I$ and the model response $A_{model}$, we also provide a grading rubric $R$.
    The evaluator $f(\cdot)$ is prompted to first generate an explanation followed
    by a score- represented as $f(P_{eval},R,I,A_{model})\rightarrow(exp,score)$.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: Zeng 等人（[2023](#bib.bib46)）：在这一策略中，除了指令 $I$ 和模型响应 $A_{model}$，我们还提供了评分标准 $R$。评估者
    $f(\cdot)$ 被提示首先生成一个解释，然后给出一个评分，表示为 $f(P_{eval},R,I,A_{model})\rightarrow(exp,score)$。
- en: Axis
  id: totrans-112
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 轴
- en: 'Hada et al. ([2023](#bib.bib13)): In this strategy, the evaluator $f(\cdot)$
    is prompted to assess the model response, $A_{model}$, along a designated axis,
    $Ax$, aligning with the category of the instruction ($\S$ [3.1](#S3.SS1 "3.1 Prompt
    Selection ‣ 3 FBI: Meta-Evaluation Checklist ‣ Finding Blind Spots in Evaluator
    LLMs with Interpretable Checklists")). For instance, factual questions are evaluated
    along the $hallucination$ axis to determine the presence of fabricated content.
    This process is formally represented as $f(P_{eval},Ax,I,A_{model})\rightarrow(exp,score)$.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 'Hada 等 ([2023](#bib.bib13))：在此策略中，评估者 $f(\cdot)$ 被提示沿着指定的轴 $Ax$ 评估模型回应 $A_{model}$，与指令的类别对齐
    ($\S$ [3.1](#S3.SS1 "3.1 Prompt Selection ‣ 3 FBI: Meta-Evaluation Checklist ‣
    Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"))。例如，事实性问题沿着
    $hallucination$ 轴进行评估，以确定是否存在虚构内容。这个过程形式上表示为 $f(P_{eval},Ax,I,A_{model})\rightarrow(exp,score)$。'
- en: Axis+Rubric
  id: totrans-114
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 轴+评分标准
- en: 'Hada et al. ([2023](#bib.bib13)): In this strategy, the evaluator $f(\cdot)$
    is provided with both a specific evaluation axis $Ax$ and detailed scoring rubrics
    $R$ for that axis. The is formally represented as $f(P_{eval},Ax,R,I,A_{model})\rightarrow(exp,score)$.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: Hada 等 ([2023](#bib.bib13))：在此策略中，评估者 $f(\cdot)$ 获得了一个特定的评估轴 $Ax$ 和该轴的详细评分标准
    $R$。这个过程形式上表示为 $f(P_{eval},Ax,R,I,A_{model})\rightarrow(exp,score)$。
- en: 4.2 Pairwise Comparison
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 成对比较
- en: In this paradigm, evaluator $f(\cdot)$ is tasked to choose the better response
    from the two given options by again relying on its parameterized knowledge.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种范式中，评估者 $f(\cdot)$ 的任务是通过依赖其参数化的知识，从两个给定的选项中选择更好的回应。
- en: Pairwise^∗
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 成对^∗
- en: 'Zheng et al. ([2023](#bib.bib48)): The evaluator $f(\cdot)$ here is given only
    an instruction $I$ and two model responses $A_{1}$ and $A_{2}$ and is tasked to
    determine the better response or mark both as equally valid. This is formally
    represented as $f(P_{eval},I,A_{1},A_{2})\rightarrow(verdict)$.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Zheng 等 ([2023](#bib.bib48))：在这里，评估者 $f(\cdot)$ 仅获得指令 $I$ 和两个模型回应 $A_{1}$ 和
    $A_{2}$，并被要求确定更好的回应或标记两者为同样有效。这个过程形式上表示为 $f(P_{eval},I,A_{1},A_{2})\rightarrow(verdict)$。
- en: Pairwise
  id: totrans-120
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 成对
- en: 'Zheng et al. ([2023](#bib.bib48)): This strategy extends “Pairwise^∗”, where
    the evaluator is tasked not only with choosing the better response but also providing
    an explanation for the verdict - represented as $f(P_{eval},I,A_{1},A_{2})\rightarrow(exp,verdict)$.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Zheng 等 ([2023](#bib.bib48))：此策略扩展了“成对^∗”，评估者不仅需要选择更好的回应，还需提供对裁决的解释 - 表示为 $f(P_{eval},I,A_{1},A_{2})\rightarrow(exp,verdict)$。
- en: Rules
  id: totrans-122
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 规则
- en: 'Zeng et al. ([2023](#bib.bib46)): In this strategy, in addition to the instruction
    $I$ and the two model responses $A_{1}$, $A_{2}$, the evaluator $f(\cdot)$ is
    given detailed rules for evaluation and is asked to generate an explanation followed
    by the verdict. This process is formally represented as $f(P_{eval},R,I,A_{1},A_{2})\rightarrow(exp,verdict)$.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: Zeng 等 ([2023](#bib.bib46))：在此策略中，除了指令 $I$ 和两个模型回应 $A_{1}$、$A_{2}$ 外，评估者 $f(\cdot)$
    还会获得详细的评估规则，并被要求生成解释及裁决。这个过程形式上表示为 $f(P_{eval},R,I,A_{1},A_{2})\rightarrow(exp,verdict)$。
- en: Axis
  id: totrans-124
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 轴
- en: 'Hada et al. ([2023](#bib.bib13)): Extending the Axis strategy defined in Sec
    $\S$[4.1](#S4.SS1 "4.1 Single Answer Scoring ‣ 4 Strategies for using Evaluator
    LLMs ‣ Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"),
    the evaluator $f(\cdot)$ is asked to choose the better response along a designated
    axis $Ax$. The evaluator is prompted with the instruction $I$, two model responses
    $A_{1}$, $A_{2}$, and the description of the axis $Ax$ - represented as $f(P_{eval},Ax,R,I,A_{1},A_{2})\rightarrow(exp,verdict)$.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Hada 等 ([2023](#bib.bib13))：扩展了在 Sec $\S$[4.1](#S4.SS1 "4.1 Single Answer Scoring
    ‣ 4 Strategies for using Evaluator LLMs ‣ Finding Blind Spots in Evaluator LLMs
    with Interpretable Checklists") 定义的轴策略，评估者 $f(\cdot)$ 被要求在指定的轴 $Ax$ 上选择更好的回应。评估者会被提示指令
    $I$、两个模型回应 $A_{1}$、$A_{2}$ 和轴 $Ax$ 的描述 - 形式上表示为 $f(P_{eval},Ax,R,I,A_{1},A_{2})\rightarrow(exp,verdict)$。
- en: Axis+Rules
  id: totrans-126
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 轴+规则
- en: 'Zeng et al. ([2023](#bib.bib46)); Hada et al. ([2023](#bib.bib13)): Extending
    the Axis+Rubric strategy defined in Sec $\S$[4.1](#S4.SS1 "4.1 Single Answer Scoring
    ‣ 4 Strategies for using Evaluator LLMs ‣ Finding Blind Spots in Evaluator LLMs
    with Interpretable Checklists"), this strategy involves choosing the better response
    along the designated axis $Ax$. The evaluator is prompted with the instruction
    $I$, two model responses $A_{1}$, $A_{2}$, details about the axis $Ax$, and detailed
    rules for evaluation - represented as $f(P_{eval},Ax,R,I,A_{1},A_{2})\rightarrow(exp,verdict)$.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 郑等人（[2023](#bib.bib46)）；哈达等人（[2023](#bib.bib13)）：扩展了第 $\S$[4.1](#S4.SS1 "4.1
    单答案评分 ‣ 4 种使用评估器 LLM 的策略 ‣ 使用可解释的检查表找出评估器 LLM 的盲点") 节中定义的轴+评分标准策略，这一策略涉及沿指定轴 $Ax$
    选择更好的响应。评估者会被提示提供指令 $I$、两个模型响应 $A_{1}$、$A_{2}$、关于轴 $Ax$ 的详细信息以及详细的评分规则 - 以 $f(P_{eval},Ax,R,I,A_{1},A_{2})\rightarrow(exp,verdict)$
    表示。
- en: 4.3 Reference-guided Single Answer Scoring
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 参考引导的单答案评分
- en: In this paradigm, the evaluator $f(\cdot)$ is tasked to score a response by
    comparing against a reference. It is important to note that this approach may
    not be feasible for many open-ended questions.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一范式中，评估者 $f(\cdot)$ 的任务是通过与参考答案进行比较来评分。需要注意的是，这种方法可能不适用于许多开放性问题。
- en: Reference
  id: totrans-130
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Zheng et al. ([2023](#bib.bib48)): In this strategy, given an instruction $I$,
    a model response $A_{model}$, and a ground truth reference answer $A_{gold}$,
    the evaluator $f(\cdot)$ is tasked with scoring the model response, along with
    giving an explanation. This is formally represented as $f(P_{eval},I,A_{gold},A_{model})\rightarrow(exp,score)$.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 郑等人（[2023](#bib.bib48)）：在这一策略中，给定一个指令 $I$、一个模型响应 $A_{model}$ 和一个真实参考答案 $A_{gold}$，评估者
    $f(\cdot)$ 的任务是对模型响应进行评分，并提供解释。这被正式表示为 $f(P_{eval},I,A_{gold},A_{model})\rightarrow(exp,score)$。
- en: 5 Experiments
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 实验
- en: We use GPT-4-turbo ![[Uncaptioned image]](img/7fb88b9baa39bfa19fbced5bd7b611f4.png)
    as our primary evaluation model, given its widespread adoption Zeng et al. ([2023](#bib.bib46));
    Hada et al. ([2024](#bib.bib12)); Min et al. ([2023](#bib.bib27)). We also extend
    our analysis to other proprietary models - Gemini-1.5-Pro ![[Uncaptioned image]](img/2a5b11aec1fa3fb2086e00f4d07bb6ce.png)
     Team et al. ([2024](#bib.bib35)) and Claude-3-Opus ![[Uncaptioned image]](img/8c79dbe017bde26519745137df344cf0.png)
     Anthropic ([2024](#bib.bib1)), open-source models like Llama-3-70B-Instruct![[Uncaptioned
    image]](img/b82e7540d16895bb1dd6e78e91840e4f.png)  Meta ([2024](#bib.bib26)),
    and trained evaluator models like Prometheus 2![[Uncaptioned image]](img/60a026425c457b4e0c22e8b6f92ac1cb.png)
     Kim et al. ([2024b](#bib.bib20))²²2 We reuse the axes and rubrics defined in
    Section $\S$[4.1](#S4.SS1 "4.1 Single Answer Scoring ‣ 4 Strategies for using
    Evaluator LLMs ‣ Finding Blind Spots in Evaluator LLMs with Interpretable Checklists")
    as the evaluation rubrics for Prometheus 2. . All evaluations are conducted at
    a temperature of zero to ensure reproducibility.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 GPT-4-turbo ![[未标注的图片]](img/7fb88b9baa39bfa19fbced5bd7b611f4.png) 作为我们的主要评估模型，鉴于其广泛应用（郑等人
    [2023](#bib.bib46)；哈达等人 [2024](#bib.bib12)；敏等人 [2023](#bib.bib27)）。我们还将分析扩展到其他专有模型
    - Gemini-1.5-Pro ![[未标注的图片]](img/2a5b11aec1fa3fb2086e00f4d07bb6ce.png)  （团队等人
    [2024](#bib.bib35)）和 Claude-3-Opus ![[未标注的图片]](img/8c79dbe017bde26519745137df344cf0.png)
     （Anthropic [2024](#bib.bib1)），开源模型如 Llama-3-70B-Instruct ![[未标注的图片]](img/b82e7540d16895bb1dd6e78e91840e4f.png)
     （Meta [2024](#bib.bib26)），以及训练有素的评估模型如 Prometheus 2 ![[未标注的图片]](img/60a026425c457b4e0c22e8b6f92ac1cb.png)
     （Kim 等人 [2024b](#bib.bib20)）²²2。我我们重新使用第 $\S$[4.1](#S4.SS1 "4.1 单答案评分 ‣ 4 种使用评估器
    LLM 的策略 ‣ 使用可解释的检查表找出评估器 LLM 的盲点") 节中定义的轴和评分标准作为 Prometheus 2 的评估标准。所有评估都在零温度下进行，以确保可重复性。
- en: In single answer scoring ($\S$ [4.1](#S4.SS1 "4.1 Single Answer Scoring ‣ 4
    Strategies for using Evaluator LLMs ‣ Finding Blind Spots in Evaluator LLMs with
    Interpretable Checklists")) paradigm, we measure the percentage of instances where
    the score remains unchanged by the perturbation as our metric. Ideally, except
    for score-invariant perturbations, the evaluator should penalize the score of
    the perturbed answer. For pairwise comparison paradigm ($\S$ [4.2](#S4.SS2 "4.2
    Pairwise Comparison ‣ 4 Strategies for using Evaluator LLMs ‣ Finding Blind Spots
    in Evaluator LLMs with Interpretable Checklists")), we include our “gold” answer
    as one of the responses, requiring the evaluator to select the best response between
    the “gold” and the “perturbed” answer. Here, we measure the percentage of times
    the evaluator does not choose the gold answer as our metric. To mitigate position
    bias Wang et al. ([2023c](#bib.bib38)), we conduct each evaluation twice, swapping
    the order of the gold and perturbed responses.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在单一答案评分 ($\S$ [4.1](#S4.SS1 "4.1 单一答案评分 ‣ 使用评估器 LLM 的 4 种策略 ‣ 使用可解释检查表发现评估器
    LLM 的盲点")) 模式中，我们测量分数未因扰动而改变的实例百分比作为我们的指标。理想情况下，除非是分数不变的扰动，评估器应对扰动答案的分数进行惩罚。对于成对比较模式
    ($\S$ [4.2](#S4.SS2 "4.2 成对比较 ‣ 使用评估器 LLM 的 4 种策略 ‣ 使用可解释检查表发现评估器 LLM 的盲点"))，我们将“黄金”答案作为其中一个响应，要求评估器在“黄金”和“扰动”答案之间选择最佳答案。这里，我们测量评估器未选择黄金答案的次数百分比作为我们的指标。为了减轻位置偏差
    Wang 等人 ([2023c](#bib.bib38))，我们每次评估进行两次，交换黄金和扰动响应的顺序。
- en: For reference-guided single answer scoring paradigm ($\S$ [4.3](#S4.SS3 "4.3
    Reference-guided Single Answer Scoring ‣ 4 Strategies for using Evaluator LLMs
    ‣ Finding Blind Spots in Evaluator LLMs with Interpretable Checklists")), the
    gold answer serves as the reference. Here, we measure the percentage of times
    the evaluator awards a perfect score to the perturbed answer as our metric.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 对于参考引导单一答案评分模式 ($\S$ [4.3](#S4.SS3 "4.3 参考引导单一答案评分 ‣ 使用评估器 LLM 的 4 种策略 ‣ 使用可解释检查表发现评估器
    LLM 的盲点"))，黄金答案作为参考。在这里，我们测量评估器将完美分数给予扰动答案的次数百分比作为我们的指标。
- en: '| Strategy | LF$\downarrow$ | F$\downarrow$ | IF$\downarrow$ | R$\downarrow$
    | SI$\uparrow$ |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| 策略 | LF$\downarrow$ | F$\downarrow$ | IF$\downarrow$ | R$\downarrow$ | SI$\uparrow$
    |'
- en: '| Single Answer Scoring |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 单一答案评分 |'
- en: '| Vanilla^∗ | 0.73 | 0.67 | 0.71 | 0.22 | 0.83 |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 香草^∗ | 0.73 | 0.67 | 0.71 | 0.22 | 0.83 |'
- en: '| Vanilla | 0.57 | 0.54 | 0.57 | 0.25 | 0.71 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| 香草 | 0.57 | 0.54 | 0.57 | 0.25 | 0.71 |'
- en: '| Rubric | 0.85 | 0.73 | 0.80 | 0.33 | 0.96 |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 标准 | 0.85 | 0.73 | 0.80 | 0.33 | 0.96 |'
- en: '| Axis | 0.83 | 0.74 | 0.75 | 0.43 | 0.96 |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| 轴心 | 0.83 | 0.74 | 0.75 | 0.43 | 0.96 |'
- en: '| Axis+Rubric | 0.86 | 0.76 | 0.77 | 0.37 | 0.97 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 轴心+标准 | 0.86 | 0.76 | 0.77 | 0.37 | 0.97 |'
- en: '| Pairwise Comparison |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| 成对比较 |'
- en: '| Pairwise^∗ | 0.73 | 0.52 | 0.83 | 0.36 | 0.93 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 成对^∗ | 0.73 | 0.52 | 0.83 | 0.36 | 0.93 |'
- en: '| Pairwise | 0.77 | 0.46 | 0.67 | 0.35 | 0.74 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 成对 | 0.77 | 0.46 | 0.67 | 0.35 | 0.74 |'
- en: '| Rules | 0.75 | 0.63 | 0.68 | 0.41 | 0.74 |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| 规则 | 0.75 | 0.63 | 0.68 | 0.41 | 0.74 |'
- en: '| Axis | 0.64 | 0.44 | 0.59 | 0.27 | 0.71 |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| 轴心 | 0.64 | 0.44 | 0.59 | 0.27 | 0.71 |'
- en: '| Axis+Rules | 0.64 | 0.42 | 0.61 | 0.32 | 0.72 |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| 轴心+规则 | 0.64 | 0.42 | 0.61 | 0.32 | 0.72 |'
- en: '| Reference-guided Single Answer Scoring |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 参考引导单一答案评分 |'
- en: '| Reference | 0.26 | 0.11 | 0.49 | 0.04 | 0.63 |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 参考 | 0.26 | 0.11 | 0.49 | 0.04 | 0.63 |'
- en: 'Table 3: Comparison of different evaluation strategies using GPT-4-turbo. The
    numbers indicate the percentage of instances where the score/verdict generated
    by the LLM evaluator is not affected by the perturbation. Lower values ($\downarrow$)
    indicate better performance in all categories except SI. * denotes evaluators
    that only give a score without any justification.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：使用 GPT-4-turbo 的不同评估策略比较。数字表示 LLM 评估器生成的分数/判决未受扰动影响的实例百分比。较低值 ($\downarrow$)
    表示所有类别中除了 SI 外的表现更佳。* 表示仅给出分数而没有任何理由的评估器。
- en: 5.1 Is GPT-4-Turbo a good evaluator?
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 GPT-4-Turbo 是一个好的评估器吗？
- en: Referring to the first section of Table [3](#S5.T3 "Table 3 ‣ 5 Experiments
    ‣ Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"), we observe
    that in the case of single answer scoring, GPT-4-turbo fails to lower its score
    for the perturbed answer in a majority of the cases, except for Reasoning tasks.
    Further, the performance of GPT-4-turbo is better when using simpler strategies,
    such as, Vanilla^∗ and Vanilla, as compared to the more advanced strategies with
    explicit rubrics and/or specified axis of evaluation. This could imply that while
    adding additional rubrics and criteria may increase the overall thoroughness,
    it may not necessarily enhance the model’s ability to detect subtler errors.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 参照表格[3](#S5.T3 "Table 3 ‣ 5 Experiments ‣ Finding Blind Spots in Evaluator LLMs
    with Interpretable Checklists")的第一部分，我们观察到在单一答案评分的情况下，GPT-4-turbo在大多数情况下未能降低对扰动答案的评分，除了推理任务。进一步来看，使用简单策略，如Vanilla^∗和Vanilla时，GPT-4-turbo的表现优于使用更高级的策略，这些高级策略具有明确的评分标准和/或指定的评估轴。这可能意味着，尽管增加额外的评分标准和准则可能提高整体的全面性，但不一定提升模型发现细微错误的能力。
- en: Now, referring to the second section of Table [3](#S5.T3 "Table 3 ‣ 5 Experiments
    ‣ Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"), we observe
    that in the case of pairwise comparison, GPT-4-turbo fails to detect the perturbed
    answer in majority of the cases, except for Reasoning tasks. Further, in contrast
    to the above, in this case, advanced strategies perform better than the basic
    strategies. This indicates that for comparative evaluations, having detailed specific
    rules can help improve the reliability of the models. Lastly, referring to the
    first row of the last section of Table [3](#S5.T3 "Table 3 ‣ 5 Experiments ‣ Finding
    Blind Spots in Evaluator LLMs with Interpretable Checklists"), we observe that
    when a reference is provided, GPT-4-turbo performs much better but there are still
    a notable number of failures. The evaluator, despite being presented with the
    gold answer marked as a reference answer, fails to recognize the perturbations
    in many cases, except for reasoning tasks where it performs very well. Our overall
    verdict is that GPT-4-turbo is not a good evaluator as it fails to detect perturbations
    which cause a drop in the quality of the answer.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，参照表格[3](#S5.T3 "Table 3 ‣ 5 Experiments ‣ Finding Blind Spots in Evaluator
    LLMs with Interpretable Checklists")的第二部分，我们观察到在成对比较的情况下，GPT-4-turbo在大多数情况下未能检测到扰动答案，除了推理任务。进一步对比，上述情况中，高级策略表现优于基础策略。这表明，对于比较评估，拥有详细的具体规则可以帮助提高模型的可靠性。最后，参照表格[3](#S5.T3
    "Table 3 ‣ 5 Experiments ‣ Finding Blind Spots in Evaluator LLMs with Interpretable
    Checklists")最后一部分的第一行，我们观察到当提供参考时，GPT-4-turbo表现大大提升，但仍有相当数量的失败。尽管评估者得到标记为参考答案的金标准答案，但在许多情况下未能识别扰动，除了推理任务在这些情况下表现非常好。我们的最终结论是，GPT-4-turbo作为评估者表现不佳，因为它未能检测到扰动，这导致答案质量下降。
- en: '| Strategy | Model | LF$\downarrow$ | F$\downarrow$ | IF$\downarrow$ | R$\downarrow$
    | SI$\uparrow$ |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| Strategy | Model | LF$\downarrow$ | F$\downarrow$ | IF$\downarrow$ | R$\downarrow$
    | SI$\uparrow$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| Vanilla | ![[Uncaptioned image]](img/7fb88b9baa39bfa19fbced5bd7b611f4.png)
    | 0.57 | 0.54 | 0.57 | 0.25 | 0.71 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| Vanilla | ![[未标注图像]](img/7fb88b9baa39bfa19fbced5bd7b611f4.png) | 0.57 | 0.54
    | 0.57 | 0.25 | 0.71 |'
- en: '| ![[Uncaptioned image]](img/2a5b11aec1fa3fb2086e00f4d07bb6ce.png) | 0.61 |
    0.73 | 0.54 | 0.41 | 0.71 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图像]](img/2a5b11aec1fa3fb2086e00f4d07bb6ce.png) | 0.61 | 0.73 | 0.54
    | 0.41 | 0.71 |'
- en: '| ![[Uncaptioned image]](img/8c79dbe017bde26519745137df344cf0.png) | 0.74 |
    0.84 | 0.75 | 0.47 | - |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图像]](img/8c79dbe017bde26519745137df344cf0.png) | 0.74 | 0.84 | 0.75
    | 0.47 | - |'
- en: '| ![[Uncaptioned image]](img/b82e7540d16895bb1dd6e78e91840e4f.png) | 0.86 |
    0.95 | 0.90 | 0.71 | 0.75 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图像]](img/b82e7540d16895bb1dd6e78e91840e4f.png) | 0.86 | 0.95 | 0.90
    | 0.71 | 0.75 |'
- en: '| Axis+Rules | ![[Uncaptioned image]](img/7fb88b9baa39bfa19fbced5bd7b611f4.png)
    | 0.64 | 0.42 | 0.61 | 0.32 | 0.72 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| Axis+Rules | ![[未标注图像]](img/7fb88b9baa39bfa19fbced5bd7b611f4.png) | 0.64
    | 0.42 | 0.61 | 0.32 | 0.72 |'
- en: '| ![[Uncaptioned image]](img/2a5b11aec1fa3fb2086e00f4d07bb6ce.png) | 0.72 |
    0.58 | 0.70 | 0.39 | 0.65 |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图像]](img/2a5b11aec1fa3fb2086e00f4d07bb6ce.png) | 0.72 | 0.58 | 0.70
    | 0.39 | 0.65 |'
- en: '| ![[Uncaptioned image]](img/b82e7540d16895bb1dd6e78e91840e4f.png) | 0.75 |
    0.69 | 0.70 | 0.60 | 0.64 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图像]](img/b82e7540d16895bb1dd6e78e91840e4f.png) | 0.75 | 0.69 | 0.70
    | 0.60 | 0.64 |'
- en: '| Reference | ![[Uncaptioned image]](img/7fb88b9baa39bfa19fbced5bd7b611f4.png)
    | 0.26 | 0.11 | 0.49 | 0.04 | 0.63 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| Reference | ![[未标注图像]](img/7fb88b9baa39bfa19fbced5bd7b611f4.png) | 0.26 |
    0.11 | 0.49 | 0.04 | 0.63 |'
- en: '| ![[Uncaptioned image]](img/2a5b11aec1fa3fb2086e00f4d07bb6ce.png) | 0.25 |
    0.07 | 0.17 | 0.03 | 0.33 |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/2a5b11aec1fa3fb2086e00f4d07bb6ce.png) | 0.25 | 0.07 | 0.17
    | 0.03 | 0.33 |'
- en: '| ![[Uncaptioned image]](img/b82e7540d16895bb1dd6e78e91840e4f.png) | 0.03 |
    0.01 | 0.05 | 0.05 | 0.13 |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/b82e7540d16895bb1dd6e78e91840e4f.png) | 0.03 | 0.01 | 0.05
    | 0.05 | 0.13 |'
- en: '| ![[Uncaptioned image]](img/60a026425c457b4e0c22e8b6f92ac1cb.png) | 0.51 |
    0.62 | 0.53 | 0.12 | 0.38 |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/60a026425c457b4e0c22e8b6f92ac1cb.png) | 0.51 | 0.62 | 0.53
    | 0.12 | 0.38 |'
- en: 'Table 4: Comparison of the performance of different models across the best-observed
    evaluation strategies. Lower values ($\downarrow$) indicate better performance
    in all categories except SI.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：不同模型在最佳观察评估策略下的性能比较。较低的值（$\downarrow$）表示在所有类别中表现更好，除了 SI。
- en: 5.2 How do other popular Evaluator LLMs perform?
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 其他流行的评估 LLM 表现如何？
- en: We extend our evaluation to other models and compare their performance when
    using the 3 best strategies identified in Table [3](#S5.T3 "Table 3 ‣ 5 Experiments
    ‣ Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"). Table
    [4](#S5.T4 "Table 4 ‣ 5.1 Is GPT-4-Turbo a good evaluator? ‣ 5 Experiments ‣ Finding
    Blind Spots in Evaluator LLMs with Interpretable Checklists") shows that GPT-4-turbo consistently
    outperforms other models in both the reference-less paradigms. Due to the high
    API cost of using the Claude-3-Opus  model, we restrict its evaluation to only
    the Vanilla strategy, and note that it performed poorly as an Evaluator LLM.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们扩展了对其他模型的评估，并比较它们在使用表 [3](#S5.T3 "Table 3 ‣ 5 Experiments ‣ Finding Blind
    Spots in Evaluator LLMs with Interpretable Checklists") 中确定的 3 种最佳策略时的表现。表 [4](#S5.T4
    "Table 4 ‣ 5.1 Is GPT-4-Turbo a good evaluator? ‣ 5 Experiments ‣ Finding Blind
    Spots in Evaluator LLMs with Interpretable Checklists") 显示，GPT-4-turbo 在无参考范式中始终优于其他模型。由于使用
    Claude-3-Opus 模型的 API 成本较高，我们将其评估限制为仅 Vanilla 策略，并注意到它作为评估 LLM 的表现不佳。
- en: 'In the reference-based paradigm, Llama-3-70B-Instruct model surprisingly outperforms
    all others. Upon manually reviewing few instances, we observe that Llama-3-70B-Instruct
    is a stringent evaluator and rarely awards perfect scores to even very well-formed
    answers when presented with a reference answer. While this may suggest that Llama-3-70B-Instruct
    has a high evaluation standard, it also raises concerns about overlyrelying on
    the reference answer, which is typically not available in most practical scenarios.
    To further investigate this, we evaluate all the models on Score Invariant perturbations
    (Section $\S$[3.5](#S3.SS5 "3.5 Score-Invariant Perturbations ‣ 3 FBI: Meta-Evaluation
    Checklist ‣ Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"))
    using the Reference evaluation strategy. Consistent with our prior observations,
    Llama-3-70B-Instruct seldom awards perfect scores, doing so only in 13% of the
    cases as shown in Table [4](#S5.T4 "Table 4 ‣ 5.1 Is GPT-4-Turbo a good evaluator?
    ‣ 5 Experiments ‣ Finding Blind Spots in Evaluator LLMs with Interpretable Checklists").
    Lastly, looking at the last row of Table [4](#S5.T4 "Table 4 ‣ 5.1 Is GPT-4-Turbo
    a good evaluator? ‣ 5 Experiments ‣ Finding Blind Spots in Evaluator LLMs with
    Interpretable Checklists"), we observe that even trained Evaluator LLMs like Prometheus
    2 are worse than other general Evaluator LLMs.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '在基于参考的范式中，Llama-3-70B-Instruct 模型令人惊讶地超越了所有其他模型。通过手动检查一些实例，我们观察到 Llama-3-70B-Instruct
    是一个严格的评估者，即使面对非常完善的答案，它也很少给出满分。虽然这可能表明 Llama-3-70B-Instruct 具有较高的评估标准，但也引发了对过度依赖参考答案的担忧，而在大多数实际场景中，参考答案通常是不可得的。为了进一步调查这一点，我们使用参考评估策略对所有模型进行了分数不变扰动的评估（见第
    $\S$[3.5](#S3.SS5 "3.5 Score-Invariant Perturbations ‣ 3 FBI: Meta-Evaluation
    Checklist ‣ Finding Blind Spots in Evaluator LLMs with Interpretable Checklists")
    节）。与我们之前的观察一致，Llama-3-70B-Instruct 很少给予满分，仅在13%的情况下给出满分，如表 [4](#S5.T4 "Table 4
    ‣ 5.1 Is GPT-4-Turbo a good evaluator? ‣ 5 Experiments ‣ Finding Blind Spots in
    Evaluator LLMs with Interpretable Checklists") 所示。最后，从表 [4](#S5.T4 "Table 4 ‣
    5.1 Is GPT-4-Turbo a good evaluator? ‣ 5 Experiments ‣ Finding Blind Spots in
    Evaluator LLMs with Interpretable Checklists") 的最后一行来看，我们观察到即使是经过训练的评估 LLM，如 Prometheus
    2，也不如其他通用的评估 LLM。'
- en: '![Refer to caption](img/86fde1987bef0e6846f3bb84a53bfbdd.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/86fde1987bef0e6846f3bb84a53bfbdd.png)'
- en: 'Figure 2: Comparison of perturbations detected solely by score analysis versus
    those identified with explanations. The highlighted region marked with stars denotes
    perturbations detected in explanations but not reflected in scores. Despite this,
    a significant proportion of perturbations remain undetected.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：仅通过分数分析与通过解释识别的扰动的比较。标有星号的高亮区域表示在解释中检测到的扰动，但在分数中未反映。尽管如此，仍有相当一部分扰动未被检测到。
- en: '|  | LF$\downarrow$ | F$\downarrow$ | IF$\downarrow$ | R$\downarrow$ |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '|  | LF$\downarrow$ | F$\downarrow$ | IF$\downarrow$ | R$\downarrow$ |'
- en: '| 1-3 | 1-5 | 1-3 | 1-5 | 1-3 | 1-5 | 1-3 | 1-5 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| 1-3 | 1-5 | 1-3 | 1-5 | 1-3 | 1-5 | 1-3 | 1-5 |'
- en: '| R | 0.85 | 0.76 | 0.73 | 0.69 | 0.80 | 0.72 | 0.33 | 0.30 |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| R | 0.85 | 0.76 | 0.73 | 0.69 | 0.80 | 0.72 | 0.33 | 0.30 |'
- en: '| A+R | 0.86 | 0.73 | 0.76 | 0.74 | 0.77 | 0.74 | 0.37 | 0.38 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| A+R | 0.86 | 0.73 | 0.76 | 0.74 | 0.77 | 0.74 | 0.37 | 0.38 |'
- en: 'Table 5: Comparing performance of Rubrics and Axis+Rubrics strategies with
    score range of 1-3 and 1-5\. The numbers indicate the percentage of instances
    where the score generated by the LLM evaluator is not affected by the perturbation.
    Lower values $(\downarrow)$ indicate better performance in all categories.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：比较 Rubrics 和 Axis+Rubrics 策略在 1-3 和 1-5 分数范围内的表现。数字表示 LLM 评估器生成的分数在扰动影响下未受到影响的实例百分比。较低的值
    $(\downarrow)$ 表示在所有类别中表现更好。
- en: 5.3 Does it help to look beyond scores?
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 超越分数的考量是否有帮助？
- en: In addition to scoring, our evaluators also generate explanations that provide
    a justification for each score. We investigate whether these explanations detect
    the perturbations, even though this is not reflected in the scores. We prompt
    GPT-3.5-turbo model with explanations from the instances where the evaluator rated
    the perturbed answer as equal to the gold answer, asking it to identify if any
    mistake or error has been reported in the explanation. Figure [2](#S5.F2 "Figure
    2 ‣ 5.2 How do other popular Evaluator LLMs perform? ‣ 5 Experiments ‣ Finding
    Blind Spots in Evaluator LLMs with Interpretable Checklists") reveals that explanations
    are only marginally helpful. Although perturbations are sometimes identified,
    they are overlooked or not considered significant enough to penalize the score.
    It is important to note that all the perturbations here were intended to incur
    a scoring penalty. Thus, while explicitly considering the explanations offers
    a slight improvement in the evaluator’s performance, the overall performance is
    still poor.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 除了打分外，我们的评估人员还会生成解释，为每个分数提供理由。我们调查这些解释是否能够检测到扰动，尽管这一点没有反映在分数中。我们使用来自评估人员将扰动后的回答与标准答案评定为相等的实例的解释来提示
    GPT-3.5-turbo 模型，询问是否报告了任何错误或问题。图 [2](#S5.F2 "图 2 ‣ 5.2 其他流行评估 LLM 的表现如何？ ‣ 5
    实验 ‣ 通过可解释检查表发现评估 LLM 的盲点") 显示，解释的帮助有限。尽管有时能识别出扰动，但往往被忽视或认为不够严重而未对分数产生惩罚。需要注意的是，这里的所有扰动都是为了引起打分惩罚。因此，虽然明确考虑解释在评估者的表现上略有提升，但总体表现仍然较差。
- en: 5.4 What about score-invariant perturbations?
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 关于不变分数的扰动情况如何？
- en: 'We evaluate different Evaluator LLMs using score-invariant perturbations ($\S$ [3.5](#S3.SS5
    "3.5 Score-Invariant Perturbations ‣ 3 FBI: Meta-Evaluation Checklist ‣ Finding
    Blind Spots in Evaluator LLMs with Interpretable Checklists")). Ideally, the evaluator
    should not reduce its score for these perturbations in score-based evaluations
    and should deem both responses correct in pairwise evaluations. Referring to Table
    [3](#S5.T3 "Table 3 ‣ 5 Experiments ‣ Finding Blind Spots in Evaluator LLMs with
    Interpretable Checklists") , in reference-less scoring, GPT-4-turbo performs better
    when using non-vanilla evaluating strategies, while in pairwise comparison, it
    performs better when using simpler evaluation strategies. Similarly, as shown
    in Table [4](#S5.T4 "Table 4 ‣ 5.1 Is GPT-4-Turbo a good evaluator? ‣ 5 Experiments
    ‣ Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"), we observe
    that other Evaluator LLMs also perform well in a majority of cases. However, there
    is still a significant number of responses with score-invariant perturbations
    that they rate poorly.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用不变分数的扰动来评估不同的评估 LLM ($\S$ [3.5](#S3.SS5 "3.5 不变分数的扰动 ‣ 3 FBI：元评估检查表 ‣ 通过可解释检查表发现评估
    LLM 的盲点"))。理想情况下，评估者在基于分数的评估中应对这些扰动不减少分数，并在成对评估中认为两种回应都正确。参考表 [3](#S5.T3 "表 3
    ‣ 5 实验 ‣ 通过可解释检查表发现评估 LLM 的盲点")，在无参考评分中，GPT-4-turbo 在使用非传统评估策略时表现更好，而在成对比较中，使用较简单的评估策略时表现更好。类似地，如表
    [4](#S5.T4 "表 4 ‣ 5.1 GPT-4-Turbo 是否是一个好的评估者？ ‣ 5 实验 ‣ 通过可解释检查表发现评估 LLM 的盲点")
    所示，我们观察到其他评估 LLM 在大多数情况下也表现良好。然而，仍然有相当多的不变分数扰动的回应被评分较低。
- en: 5.5 Does increasing the range help in scoring?
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5 扩大范围是否有助于评分？
- en: Based on recommendations from Hada et al. ([2023](#bib.bib13)), our initial
    set-up for the Rubrics and Axis+Rubrics evaluators used a scoring range of 1 to
    3\. To explore whether a wider scoring range could enhance the evaluators’ ability
    to identify and account for the perturbations, we extended the range to 1 to 5\.
    Results presented in Table [5](#S5.T5 "Table 5 ‣ 5.2 How do other popular Evaluator
    LLMs perform? ‣ 5 Experiments ‣ Finding Blind Spots in Evaluator LLMs with Interpretable
    Checklists") suggest that this broader range slightly improves the evaluators’
    performance, perhaps due to the availability of more flexibility in scoring decisions.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 根据Hada等人（[2023](#bib.bib13)）的建议，我们最初为Rubrics和Axis+Rubrics评估器设置了1到3的评分范围。为了探索更广泛的评分范围是否能够增强评估器识别和处理扰动的能力，我们将范围扩展到了1到5。表[5](#S5.T5
    "Table 5 ‣ 5.2 How do other popular Evaluator LLMs perform? ‣ 5 Experiments ‣
    Finding Blind Spots in Evaluator LLMs with Interpretable Checklists")中呈现的结果表明，这一更广泛的范围稍微提高了评估器的表现，这可能是由于评分决策的灵活性增加。
- en: 6 Conclusion
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: 'We propose FBI, a novel framework designed to evaluate the proficiency of Evaluator
    LLMs in assessing four critical abilities: factual accuracy, instruction adherence,
    coherence in long-form writing, and reasoning proficiency, through targeted perturbations.
    Our comprehensive study, involving 2400 perturbed answers across 22 categories
    and using three evaluation paradigms (single-answer, pairwise, and reference-guided
    evaluation), reveals significant shortcomings in current Evaluator LLMs. Our findings
    show that even the most advanced models failed to identify quality drops in over
    50% of cases on average. While reference-based evaluations performed relatively
    better, single-answer and pairwise evaluations demonstrated notable limitations.
    These results underscore the unreliable nature of current Evaluator LLMs and advocate
    for cautious implementation in practical applications. We hope that the FBI framework
    will be further extended and used for continued meta-evaluation of Evaluator LLMs.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出了FBI，一个新颖的框架，旨在通过有针对性的扰动评估评估器LLMs在四个关键能力上的熟练程度：事实准确性、指令遵循、长篇写作中的连贯性和推理能力。我们的综合研究涉及2400个扰动答案，覆盖22个类别，并使用了三种评估范式（单答案、成对和参考指导评估），揭示了当前评估器LLMs的重大不足。我们的研究结果显示，即使是最先进的模型也未能识别出超过50%的质量下降情况。虽然基于参考的评估表现相对较好，但单答案和成对评估表现出了明显的局限性。这些结果突显了当前评估器LLMs的不可靠性，并倡导在实际应用中谨慎实施。我们希望FBI框架能够得到进一步扩展，并用于对评估器LLMs进行持续的元评估。
- en: Limitations
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 限制
- en: 'In our evaluation setup, detailed in Section [4](#S4 "4 Strategies for using
    Evaluator LLMs ‣ Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"),
    we concentrate on three primary evaluation paradigms: single-answer assessment,
    pairwise comparison, and reference-guided evaluation within a single model context
    and leave out multi-agent meta-evaluation and for future work. While we have compiled
    a list of perturbation categories, we believe it is not exhaustive and there is
    room room for further expansion. Our evaluation framework encompasses four fundamental
    task abilities, with plans to explore more advanced capabilities such as multilingual
    generation, tool usage, and planning in future work.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们在第[4](#S4 "4 Strategies for using Evaluator LLMs ‣ Finding Blind Spots in
    Evaluator LLMs with Interpretable Checklists")节中详细描述的评估设置中，我们集中在三个主要的评估范式上：单答案评估、成对比较以及在单一模型上下文中的参考指导评估，而将多代理元评估留待未来工作。虽然我们编制了一个扰动类别的列表，但我们认为它并不详尽，还有进一步扩展的空间。我们的评估框架涵盖了四个基本任务能力，并计划在未来的工作中探索更高级的能力，如多语言生成、工具使用和规划。
- en: Ethics
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 伦理
- en: 'All annotations described in Section [3](#S3 "3 FBI: Meta-Evaluation Checklist
    ‣ Finding Blind Spots in Evaluator LLMs with Interpretable Checklists") were done
    by students from our research group, all of whom hold at least a bachelor’s or
    master’s degree. This annotation was done as a part of their routine research
    work. The datasets used in this paper are all available under permissible licenses,
    and we adhere strictly to their intended usage, maintaining compliance with licensing
    requirements. Additionally, the code used for our evaluations and perturbation
    generation will be made publicly available under the MIT License³³3[https://opensource.org/licenses/MIT](https://opensource.org/licenses/MIT).
    We only used ChatGPT⁴⁴4[https://chatgpt.com](https://chatgpt.com) for assistance
    purely with the language of the paper, e.g., paraphrasing, spell-checking, or
    polishing the author’s original content, without suggesting new content.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '所有在第[3](#S3 "3 FBI: Meta-Evaluation Checklist ‣ Finding Blind Spots in Evaluator
    LLMs with Interpretable Checklists")节中描述的注释均由我们研究小组的学生完成，这些学生均拥有至少本科学位或硕士学位。这些注释作为他们日常研究工作的一部分进行。本文使用的数据集都在允许的许可下公开，并且我们严格遵守其预期使用，保持对许可要求的合规性。此外，用于我们的评估和扰动生成的代码将根据MIT许可证³³3[https://opensource.org/licenses/MIT](https://opensource.org/licenses/MIT)公开。我们仅使用了ChatGPT⁴⁴4[https://chatgpt.com](https://chatgpt.com)来协助论文的语言处理，例如改写、拼写检查或润色作者的原始内容，不建议新增内容。'
- en: Acknowledgements
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: We would like to thank EkStep Foundation and Nilekani Philanthropies for their
    generous grant, which supported this research. We extend our gratitude to Ananth,
    Devilal, Niharika, Nikhil, Sakshi, Sparsh, and Suriya for their invaluable assistance
    with manual audits. We also thank Raj Dabre and Anoop Kunchukuttan for their insightful
    discussions. We thank Google for supporting Sumanth’s work through the Google
    Ph.D. Fellowship.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢EkStep基金会和尼勒卡尼慈善基金的慷慨资助，支持了本研究。我们对Ananth、Devilal、Niharika、Nikhil、Sakshi、Sparsh和Suriya在人工审计方面提供的宝贵帮助表示感谢。我们还感谢Raj
    Dabre和Anoop Kunchukuttan的深入讨论。我们感谢Google通过Google博士奖学金支持Sumanth的工作。
- en: References
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Anthropic (2024) Anthropic. 2024. Introducing the next generation of claude.
    [https://www.anthropic.com/news/claude-3-family](https://www.anthropic.com/news/claude-3-family).
    Accessed: 2024-06-14.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anthropic（2024）Anthropic。2024年。介绍下一代Claude。[https://www.anthropic.com/news/claude-3-family](https://www.anthropic.com/news/claude-3-family)。访问时间：2024-06-14。
- en: 'Chan et al. (2023) Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue,
    Shanghang Zhang, Jie Fu, and Zhiyuan Liu. 2023. [Chateval: Towards better llm-based
    evaluators through multi-agent debate](https://doi.org/10.48550/ARXIV.2308.07201).
    *CoRR*, abs/2308.07201.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '陈等（2023）陈志敏、陈伟泽、苏宇生、于建轩、薛伟、张尚杭、傅杰和刘智远。2023年。[Chateval: 通过多代理辩论实现更好的基于LLM的评估器](https://doi.org/10.48550/ARXIV.2308.07201)。*CoRR*，abs/2308.07201。'
- en: 'Chen et al. (2023) Yi Chen, Rui Wang, Haiyun Jiang, Shuming Shi, and Ruifeng
    Xu. 2023. [Exploring the use of large language models for reference-free text
    quality evaluation: A preliminary empirical study](https://doi.org/10.48550/ARXIV.2304.00723).
    *CoRR*, abs/2304.00723.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈等（2023）陈轶、王锐、姜海云、石树铭和徐瑞锋。2023年。[探索大语言模型在无参考文本质量评估中的应用：初步实证研究](https://doi.org/10.48550/ARXIV.2304.00723)。*CoRR*，abs/2304.00723。
- en: 'Chen et al. (2024) Yiming Chen, Chen Zhang, Danqing Luo, Luis Fernando D’Haro,
    Robby T. Tan, and Haizhou Li. 2024. Unveiling the achilles’ heel of nlg evaluators:
    A unified adversarial framework driven by large language models. *arXiv preprint
    arXiv: 2405.14646*.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '陈等（2024）陈一鸣、陈章、罗丹青、路易斯·费尔南多·D''Haro、罗比·T·谭和李海洲。2024年。《揭示NLG评估者的致命弱点：由大语言模型驱动的统一对抗框架》。*arXiv预印本
    arXiv: 2405.14646*。'
- en: Chiang and yi Lee (2023) Cheng-Han Chiang and Hung yi Lee. 2023. [Can large
    language models be an alternative to human evaluations?](https://doi.org/10.48550/arXiv.2305.01937)
    *Annual Meeting of the Association for Computational Linguistics*.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chiang和Yi Lee（2023）郑汉祥和李宏毅。2023年。[大语言模型可以作为人类评估的替代方案吗？](https://doi.org/10.48550/arXiv.2305.01937)
    *计算语言学协会年会*。
- en: 'Chiang and Lee (2023) David Cheng-Han Chiang and Hung-yi Lee. 2023. [Can large
    language models be an alternative to human evaluations?](https://doi.org/10.18653/V1/2023.ACL-LONG.870)
    In *Proceedings of the 61st Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023*,
    pages 15607–15631\. Association for Computational Linguistics.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chiang和Lee（2023）David Cheng-Han Chiang和Hung-yi Lee。2023。[大型语言模型是否可以替代人工评估？](https://doi.org/10.18653/V1/2023.ACL-LONG.870)
    在*第61届计算语言学协会年会（第1卷：长篇论文）论文集，ACL 2023，多伦多，加拿大，2023年7月9-14日*，第15607–15631页。计算语言学协会。
- en: Cobbe et al. (2021) Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen,
    Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro
    Nakano, Christopher Hesse, and John Schulman. 2021. [Training verifiers to solve
    math word problems](https://arxiv.org/abs/2110.14168). *CoRR*, abs/2110.14168.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cobbe等（2021）Karl Cobbe、Vineet Kosaraju、Mohammad Bavarian、Mark Chen、Heewoo Jun、Lukasz
    Kaiser、Matthias Plappert、Jerry Tworek、Jacob Hilton、Reiichiro Nakano、Christopher
    Hesse和John Schulman。2021。[训练验证器以解决数学文字题](https://arxiv.org/abs/2110.14168)。*CoRR*，abs/2110.14168。
- en: 'Devlin et al. (2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina
    Toutanova. 2019. [BERT: Pre-training of deep bidirectional transformers for language
    understanding](https://doi.org/10.18653/v1/N19-1423). In *Proceedings of the 2019
    Conference of the North American Chapter of the Association for Computational
    Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)*, pages
    4171–4186, Minneapolis, Minnesota. Association for Computational Linguistics.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Devlin等（2019）Jacob Devlin、Ming-Wei Chang、Kenton Lee和Kristina Toutanova。2019。[BERT:
    深度双向变换器的预训练用于语言理解](https://doi.org/10.18653/v1/N19-1423)。在*第2019届北美计算语言学协会年会：人类语言技术会议（第1卷：长篇和短篇论文）论文集*，第4171–4186页，明尼阿波利斯，明尼苏达州。计算语言学协会。'
- en: Ding et al. (2023) Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Shengding Hu,
    Zhiyuan Liu, Maosong Sun, and Bowen Zhou. 2023. [Enhancing chat language models
    by scaling high-quality instructional conversations](https://aclanthology.org/2023.emnlp-main.183).
    In *Proceedings of the 2023 Conference on Empirical Methods in Natural Language
    Processing, EMNLP 2023, Singapore, December 6-10, 2023*, pages 3029–3051\. Association
    for Computational Linguistics.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ding等（2023）宁丁、于琳·陈、博凯·徐、余佳·秦、盛丁·胡、智远·刘、茅松·孙和博文·周。2023。[通过扩展高质量指导性对话提升聊天语言模型](https://aclanthology.org/2023.emnlp-main.183)。在*2023年自然语言处理实证方法会议论文集，EMNLP
    2023，新加坡，2023年12月6-10日*，第3029–3051页。计算语言学协会。
- en: 'Dubois et al. (2023) Yann Dubois, Chen Xuechen Li, Rohan Taori, Tianyi Zhang,
    Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto.
    2023. [Alpacafarm: A simulation framework for methods that learn from human feedback](http://papers.nips.cc/paper_files/paper/2023/hash/5fc47800ee5b30b8777fdd30abcaaf3b-Abstract-Conference.html).
    In *Advances in Neural Information Processing Systems 36: Annual Conference on
    Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA,
    December 10 - 16, 2023*.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Dubois等（2023）Yann Dubois、陈雪晨·李、Rohan Taori、Tianyi Zhang、Ishaan Gulrajani、Jimmy
    Ba、Carlos Guestrin、Percy Liang和Tatsunori B. Hashimoto。2023。[Alpacafarm: 一个从人类反馈中学习的方法的模拟框架](http://papers.nips.cc/paper_files/paper/2023/hash/5fc47800ee5b30b8777fdd30abcaaf3b-Abstract-Conference.html)。在*神经信息处理系统进展第36卷：2023年神经信息处理系统年会，NeurIPS
    2023，新奥尔良，美国，2023年12月10日-16日*。'
- en: 'Fu et al. (2023) Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, and Pengfei Liu.
    2023. Gptscore: Evaluate as you desire. *arXiv preprint arXiv: 2302.04166*.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Fu等（2023）金岚·傅、See-Kiong Ng、郑宝·姜和彭飞·刘。2023。《Gptscore: 按照你的愿望进行评估》。*arXiv预印本
    arXiv: 2302.04166*。'
- en: 'Hada et al. (2024) Rishav Hada, Varun Gumma, Mohamed Ahmed, Kalika Bali, and
    Sunayana Sitaram. 2024. Metal: Towards multilingual meta-evaluation. *arXiv preprint
    arXiv: 2404.01667*.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hada等（2024）Rishav Hada、Varun Gumma、Mohamed Ahmed、Kalika Bali和Sunayana Sitaram。2024。《Metal:
    向多语言元评估迈进》。*arXiv预印本 arXiv: 2404.01667*。'
- en: Hada et al. (2023) Rishav Hada, Varun Gumma, Adrian de Wynter, Harshita Diddee,
    Mohamed Ahmed, M. Choudhury, Kalika Bali, and Sunayana Sitaram. 2023. [Are large
    language model-based evaluators the solution to scaling up multilingual evaluation?](https://doi.org/10.48550/arXiv.2309.07462)
    *FINDINGS*.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hada等（2023）Rishav Hada、Varun Gumma、Adrian de Wynter、Harshita Diddee、Mohamed
    Ahmed、M. Choudhury、Kalika Bali和Sunayana Sitaram。2023。[基于大型语言模型的评估者是否是扩大多语言评估的解决方案？](https://doi.org/10.48550/arXiv.2309.07462)
    *FINDINGS*。
- en: 'Hasanbeig et al. (2023) Hosein Hasanbeig, Hiteshi Sharma, Leo Betthauser, Felipe Vieira
    Frujeri, and Ida Momennejad. 2023. Allure: Auditing and improving llm-based evaluation
    of text using iterative in-context-learning. *arXiv preprint arXiv: 2309.13701*.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hasanbeig 等人 (2023) Hosein Hasanbeig, Hiteshi Sharma, Leo Betthauser, Felipe
    Vieira Frujeri 和 Ida Momennejad。2023年。《Allure：审计和改进基于大语言模型的文本评估，采用迭代上下文学习》。*arXiv
    预印本 arXiv: 2309.13701*。'
- en: Hendrycks et al. (2021) Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora,
    Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. 2021. [Measuring mathematical
    problem solving with the MATH dataset](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/be83ab3ecd0db773eb2dc1b0a17836a1-Abstract-round2.html).
    In *Proceedings of the Neural Information Processing Systems Track on Datasets
    and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual*.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hendrycks 等人 (2021) Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora,
    Steven Basart, Eric Tang, Dawn Song 和 Jacob Steinhardt。2021年。[使用 MATH 数据集测量数学问题解决能力](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/be83ab3ecd0db773eb2dc1b0a17836a1-Abstract-round2.html)。在
    *神经信息处理系统数据集与基准跟踪 1 会议录，NeurIPS 数据集与基准 2021，2021年12月，虚拟会议*。
- en: Hu et al. (2024) Xuming Hu, Junzhe Chen, Xiaochuan Li, Yufei Guo, Lijie Wen,
    Philip S. Yu, and Zhijiang Guo. 2024. [Towards understanding factual knowledge
    of large language models](https://openreview.net/forum?id=9OevMUdods). In *The
    Twelfth International Conference on Learning Representations*.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu 等人 (2024) Xuming Hu, Junzhe Chen, Xiaochuan Li, Yufei Guo, Lijie Wen, Philip
    S. Yu 和 Zhijiang Guo。2024年。[朝着理解大型语言模型的事实知识](https://openreview.net/forum?id=9OevMUdods)。在
    *第十二届国际学习表征会议*。
- en: 'Kamoi et al. (2024) Ryo Kamoi, Sarkar Snigdha Sarathi Das, Renze Lou, Jihyun Janice
    Ahn, Yilun Zhao, Xiaoxin Lu, Nan Zhang, Yusen Zhang, Ranran Haoran Zhang, Sujeeth Reddy
    Vummanthala, Salika Dave, Shaobo Qin, Arman Cohan, Wenpeng Yin, and Rui Zhang.
    2024. Evaluating llms at detecting errors in llm responses. *arXiv preprint arXiv:
    2404.03602*.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kamoi 等人 (2024) Ryo Kamoi, Sarkar Snigdha Sarathi Das, Renze Lou, Jihyun Janice
    Ahn, Yilun Zhao, Xiaoxin Lu, Nan Zhang, Yusen Zhang, Ranran Haoran Zhang, Sujeeth
    Reddy Vummanthala, Salika Dave, Shaobo Qin, Arman Cohan, Wenpeng Yin 和 Rui Zhang。2024年。《评估大语言模型在检测大语言模型响应中的错误》。*arXiv
    预印本 arXiv: 2404.03602*。'
- en: 'Kim et al. (2023) Seungone Kim, Jamin Shin, Yejin Cho, Joel Jang, Shayne Longpre,
    Hwaran Lee, Sangdoo Yun, Seongjin Shin, Sungdong Kim, James Thorne, and Minjoon
    Seo. 2023. [Prometheus: Inducing fine-grained evaluation capability in language
    models](https://doi.org/10.48550/ARXIV.2310.08491). *CoRR*, abs/2310.08491.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim 等人 (2023) Seungone Kim, Jamin Shin, Yejin Cho, Joel Jang, Shayne Longpre,
    Hwaran Lee, Sangdoo Yun, Seongjin Shin, Sungdong Kim, James Thorne 和 Minjoon Seo。2023年。[Prometheus：在语言模型中引入细粒度评估能力](https://doi.org/10.48550/ARXIV.2310.08491)。*CoRR*，abs/2310.08491。
- en: 'Kim et al. (2024a) Seungone Kim, Juyoung Suk, Ji Yong Cho, Shayne Longpre,
    Chaeeun Kim, Dongkeun Yoon, Guijin Son, Yejin Cho, Sheikh Shafayat, Jinheon Baek,
    Sue Hyun Park, Hyeonbin Hwang, Jinkyung Jo, Hyowon Cho, Haebin Shin, Seongyun
    Lee, Hanseok Oh, Noah Lee, Namgyu Ho, Se June Joo, Miyoung Ko, Yoonjoo Lee, Hyungjoo
    Chae, Jamin Shin, Joel Jang, Seonghyeon Ye, Bill Yuchen Lin, Sean Welleck, Graham
    Neubig, Moontae Lee, Kyungjae Lee, and Minjoon Seo. 2024a. [The biggen bench:
    A principled benchmark for fine-grained evaluation of language models with language
    models](https://api.semanticscholar.org/CorpusID:270371930).'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kim 等人 (2024a) Seungone Kim, Juyoung Suk, Ji Yong Cho, Shayne Longpre, Chaeeun
    Kim, Dongkeun Yoon, Guijin Son, Yejin Cho, Sheikh Shafayat, Jinheon Baek, Sue
    Hyun Park, Hyeonbin Hwang, Jinkyung Jo, Hyowon Cho, Haebin Shin, Seongyun Lee,
    Hanseok Oh, Noah Lee, Namgyu Ho, Se June Joo, Miyoung Ko, Yoonjoo Lee, Hyungjoo
    Chae, Jamin Shin, Joel Jang, Seonghyeon Ye, Bill Yuchen Lin, Sean Welleck, Graham
    Neubig, Moontae Lee, Kyungjae Lee 和 Minjoon Seo。2024年。《Biggen Bench：一个基于语言模型的细粒度评估语言模型的原则性基准》。[Semantic
    Scholar 语料库 ID: 270371930](https://api.semanticscholar.org/CorpusID:270371930)。'
- en: 'Kim et al. (2024b) Seungone Kim, Juyoung Suk, Shayne Longpre, Bill Yuchen Lin,
    Jamin Shin, Sean Welleck, Graham Neubig, Moontae Lee, Kyungjae Lee, and Minjoon
    Seo. 2024b. Prometheus 2: An open source language model specialized in evaluating
    other language models. *arXiv preprint arXiv: 2405.01535*.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kim 等人 (2024b) Seungone Kim, Juyoung Suk, Shayne Longpre, Bill Yuchen Lin,
    Jamin Shin, Sean Welleck, Graham Neubig, Moontae Lee, Kyungjae Lee 和 Minjoon Seo。2024年。《Prometheus
    2：一种开源语言模型，专门用于评估其他语言模型》。*arXiv 预印本 arXiv: 2405.01535*。'
- en: Kocmi and Federmann (2023) Tom Kocmi and C. Federmann. 2023. [Large language
    models are state-of-the-art evaluators of translation quality](https://doi.org/10.48550/arXiv.2302.14520).
    *European Association for Machine Translation Conferences/Workshops*.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kocmi 和 Federmann (2023) Tom Kocmi 和 C. Federmann。2023年。[大型语言模型是最先进的翻译质量评估工具](https://doi.org/10.48550/arXiv.2302.14520)。*欧洲机器翻译协会会议/研讨会*。
- en: 'Li et al. (2023) Zekun Li, Baolin Peng, Pengcheng He, and Xifeng Yan. 2023.
    Evaluating the instruction-following robustness of large language models to prompt
    injection. *arXiv preprint arXiv: 2308.10819*.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li et al. (2023) Zekun Li, Baolin Peng, Pengcheng He, 和 Xifeng Yan. 2023. 评估大型语言模型对提示注入的指令跟随鲁棒性。*arXiv
    预印本 arXiv: 2308.10819*。'
- en: 'Liu et al. (2023) Yang Liu, Dan Iter, Yichong Xu, Shuo Wang, Ruochen Xu, and
    Chenguang Zhu. 2023. [G-eval: Nlg evaluation using gpt-4 with better human alignment](https://doi.org/10.48550/arXiv.2303.16634).
    *Conference on Empirical Methods in Natural Language Processing*.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2023) Yang Liu, Dan Iter, Yichong Xu, Shuo Wang, Ruochen Xu, 和 Chenguang
    Zhu. 2023. [G-eval：使用 GPT-4 进行 NLG 评估，更好地对齐人类](https://doi.org/10.48550/arXiv.2303.16634)。*自然语言处理经验方法会议*。
- en: 'Liusie et al. (2023) Adian Liusie, Potsawee Manakul, and Mark J. F. Gales.
    2023. Llm comparative assessment: Zero-shot nlg evaluation through pairwise comparisons
    using large language models. *arXiv preprint arXiv: 2307.07889*.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liusie et al. (2023) Adian Liusie, Potsawee Manakul, 和 Mark J. F. Gales. 2023.
    LLM 比较评估：通过使用大型语言模型进行配对比较的零样本 NLG 评估。*arXiv 预印本 arXiv: 2307.07889*。'
- en: 'Mathur et al. (2020) Nitika Mathur, Timothy Baldwin, and Trevor Cohn. 2020.
    [Tangled up in BLEU: Reevaluating the evaluation of automatic machine translation
    evaluation metrics](https://doi.org/10.18653/v1/2020.acl-main.448). In *Proceedings
    of the 58th Annual Meeting of the Association for Computational Linguistics*,
    pages 4984–4997, Online. Association for Computational Linguistics.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mathur et al. (2020) Nitika Mathur, Timothy Baldwin, 和 Trevor Cohn. 2020. [困于
    BLEU：重新评估自动机器翻译评价指标的评估](https://doi.org/10.18653/v1/2020.acl-main.448)。发表于 *第58届计算语言学协会年会论文集*，第4984–4997页，在线。计算语言学协会。
- en: 'Meta (2024) Meta. 2024. Introducing meta llama 3: The most capable openly available
    llm to date. [https://ai.meta.com/blog/meta-llama-3/](https://ai.meta.com/blog/meta-llama-3/).
    Accessed: 2024-06-14.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Meta (2024) Meta. 2024. 介绍 Meta LLaMA 3：迄今为止最强大的公开可用 LLM。[https://ai.meta.com/blog/meta-llama-3/](https://ai.meta.com/blog/meta-llama-3/)。访问时间：2024-06-14。
- en: 'Min et al. (2023) Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen tau
    Yih, Pang Wei Koh, Mohit Iyyer, Luke Zettlemoyer, and Hannaneh Hajishirzi. 2023.
    Factscore: Fine-grained atomic evaluation of factual precision in long form text
    generation. *arXiv preprint arXiv: 2305.14251*.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Min et al. (2023) Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen tau
    Yih, Pang Wei Koh, Mohit Iyyer, Luke Zettlemoyer, 和 Hannaneh Hajishirzi. 2023.
    Factscore：对长文本生成中事实准确性的细粒度原子评估。*arXiv 预印本 arXiv: 2305.14251*。'
- en: Naismith et al. (2023) Ben Naismith, Phoebe Mulcaire, and Jill Burstein. 2023.
    [Automated evaluation of written discourse coherence using GPT-4](https://doi.org/10.18653/v1/2023.bea-1.32).
    In *Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational
    Applications (BEA 2023)*, pages 394–403, Toronto, Canada. Association for Computational
    Linguistics.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Naismith et al. (2023) Ben Naismith, Phoebe Mulcaire, 和 Jill Burstein. 2023.
    [使用 GPT-4 对书面话语连贯性进行自动化评估](https://doi.org/10.18653/v1/2023.bea-1.32)。发表于 *第18届创新
    NLP 用于教育应用研讨会 (BEA 2023)*，第394–403页，多伦多，加拿大。计算语言学协会。
- en: 'Panickssery et al. (2024) Arjun Panickssery, Samuel R. Bowman, and Shi Feng.
    2024. Llm evaluators recognize and favor their own generations. *arXiv preprint
    arXiv: 2404.13076*.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Panickssery et al. (2024) Arjun Panickssery, Samuel R. Bowman, 和 Shi Feng.
    2024. LLM 评估者识别并偏爱自己的生成内容。*arXiv 预印本 arXiv: 2404.13076*。'
- en: 'Ribeiro et al. (2020) Marco Tulio Ribeiro, Tongshuang Wu, Carlos Guestrin,
    and Sameer Singh. 2020. [Beyond accuracy: Behavioral testing of NLP models with
    CheckList](https://doi.org/10.18653/v1/2020.acl-main.442). In *Proceedings of
    the 58th Annual Meeting of the Association for Computational Linguistics*, pages
    4902–4912, Online. Association for Computational Linguistics.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ribeiro et al. (2020) Marco Tulio Ribeiro, Tongshuang Wu, Carlos Guestrin, 和
    Sameer Singh. 2020. [超越准确性：使用 CheckList 对 NLP 模型进行行为测试](https://doi.org/10.18653/v1/2020.acl-main.442)。发表于
    *第58届计算语言学协会年会论文集*，第4902–4912页，在线。计算语言学协会。
- en: Saha et al. (2023) Swarnadeep Saha, Omer Levy, Asli Celikyilmaz, Mohit Bansal,
    Jason Weston, and Xian Li. 2023. [Branch-solve-merge improves large language model
    evaluation and generation](https://doi.org/10.48550/ARXIV.2310.15123). *CoRR*,
    abs/2310.15123.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Saha et al. (2023) Swarnadeep Saha, Omer Levy, Asli Celikyilmaz, Mohit Bansal,
    Jason Weston, 和 Xian Li. 2023. [Branch-solve-merge 改善了大型语言模型的评估和生成](https://doi.org/10.48550/ARXIV.2310.15123)。*CoRR*,
    abs/2310.15123。
- en: Sai et al. (2021) Ananya B. Sai, Tanay Dixit, Dev Yashpal Sheth, Sreyas Mohan,
    and Mitesh M. Khapra. 2021. [Perturbation CheckLists for evaluating NLG evaluation
    metrics](https://doi.org/10.18653/v1/2021.emnlp-main.575). In *Proceedings of
    the 2021 Conference on Empirical Methods in Natural Language Processing*, pages
    7219–7234, Online and Punta Cana, Dominican Republic. Association for Computational
    Linguistics.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sai等（2021）阿南亚·B·Sai、塔奈·迪克希特、德夫·亚什帕尔·谢斯、斯雷亚斯·莫汉、米特什·M·卡普拉。2021年。[用于评估自然语言生成（NLG）评价度量的扰动检查清单](https://doi.org/10.18653/v1/2021.emnlp-main.575)。发表于*2021年自然语言处理经验方法会议论文集*，第7219–7234页，线上与多米尼加共和国蓬塔卡纳。计算语言学协会。
- en: 'Sai B et al. (2023) Ananya Sai B, Tanay Dixit, Vignesh Nagarajan, Anoop Kunchukuttan,
    Pratyush Kumar, Mitesh M. Khapra, and Raj Dabre. 2023. [IndicMT eval: A dataset
    to meta-evaluate machine translation metrics for Indian languages](https://doi.org/10.18653/v1/2023.acl-long.795).
    In *Proceedings of the 61st Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)*, pages 14210–14228, Toronto, Canada. Association
    for Computational Linguistics.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sai B等（2023）阿南亚·Sai B、塔奈·迪克希特、维尼什·纳加拉詹、阿努普·昆楚库坦、普拉蒂尤什·库马尔、米特什·M·卡普拉、拉杰·达布雷。2023年。[IndicMT评估：一个用于元评估印度语言机器翻译度量的数据集](https://doi.org/10.18653/v1/2023.acl-long.795)。发表于*第61届计算语言学协会年会（第1卷：长论文）*，第14210–14228页，多伦多，加拿大。计算语言学协会。
- en: 'Shen et al. (2023) Chenhui Shen, Liying Cheng, Xuan-Phi Nguyen, Yang You, and
    Lidong Bing. 2023. [Large language models are not yet human-level evaluators for
    abstractive summarization](https://doi.org/10.18653/v1/2023.findings-emnlp.278).
    In *Findings of the Association for Computational Linguistics: EMNLP 2023*, pages
    4215–4233, Singapore. Association for Computational Linguistics.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen等（2023）陈辉申、程丽颖、阮学斌、杨钰、邹立东。2023年。[大型语言模型尚未达到人类水平的抽象总结评估器](https://doi.org/10.18653/v1/2023.findings-emnlp.278)。发表于*计算语言学协会年会：EMNLP
    2023*，第4215–4233页，新加坡。计算语言学协会。
- en: 'Team et al. (2024) Gemini Team, Machel Reid, Nikolay Savinov, Denis Teplyashin,
    Dmitry, Lepikhin, Timothy Lillicrap, Jean baptiste Alayrac, Radu Soricut, Angeliki
    Lazaridou, Orhan Firat, Julian Schrittwieser, Ioannis Antonoglou, Rohan Anil,
    Sebastian Borgeaud, Andrew Dai, Katie Millican, Ethan Dyer, Mia Glaese, Thibault
    Sottiaux, Benjamin Lee, Fabio Viola, Malcolm Reynolds, Yuanzhong Xu, James Molloy,
    Jilin Chen, Michael Isard, Paul Barham, Tom Hennigan, Ross McIlroy, Melvin Johnson,
    Johan Schalkwyk, Eli Collins, Eliza Rutherford, Erica Moreira, Kareem Ayoub, Megha
    Goel, Clemens Meyer, Gregory Thornton, Zhen Yang, Henryk Michalewski, Zaheer Abbas,
    Nathan Schucher, Ankesh Anand, Richard Ives, James Keeling, Karel Lenc, Salem
    Haykal, Siamak Shakeri, Pranav Shyam, Aakanksha Chowdhery, Roman Ring, Stephen
    Spencer, Eren Sezener, Luke Vilnis, Oscar Chang, Nobuyuki Morioka, George Tucker,
    Ce Zheng, Oliver Woodman, Nithya Attaluri, Tomas Kocisky, Evgenii Eltyshev, Xi Chen,
    Timothy Chung, Vittorio Selo, Siddhartha Brahma, Petko Georgiev, Ambrose Slone,
    Zhenkai Zhu, James Lottes, Siyuan Qiao, Ben Caine, Sebastian Riedel, Alex Tomala,
    Martin Chadwick, Juliette Love, Peter Choy, Sid Mittal, Neil Houlsby, Yunhao Tang,
    Matthew Lamm, Libin Bai, Qiao Zhang, Luheng He, Yong Cheng, Peter Humphreys, Yujia
    Li, Sergey Brin, Albin Cassirer, Yingjie Miao, Lukas Zilka, Taylor Tobin, Kelvin
    Xu, Lev Proleev, Daniel Sohn, Alberto Magni, Lisa Anne Hendricks, Isabel Gao,
    Santiago Ontanon, Oskar Bunyan, Nathan Byrd, Abhanshu Sharma, Biao Zhang, Mario
    Pinto, Rishika Sinha, Harsh Mehta, Dawei Jia, Sergi Caelles, Albert Webson, Alex
    Morris, Becca Roelofs, Yifan Ding, Robin Strudel, Xuehan Xiong, Marvin Ritter,
    Mostafa Dehghani, Rahma Chaabouni, Abhijit Karmarkar, Guangda Lai, Fabian Mentzer,
    Bibo Xu, YaGuang Li, Yujing Zhang, Tom Le Paine, Alex Goldin, Behnam Neyshabur,
    Kate Baumli, Anselm Levskaya, Michael Laskin, Wenhao Jia, Jack W. Rae, Kefan Xiao,
    Antoine He, Skye Giordano, Lakshman Yagati, Jean-Baptiste Lespiau, Paul Natsev,
    Sanjay Ganapathy, Fangyu Liu, Danilo Martins, Nanxin Chen, Yunhan Xu, Megan Barnes,
    Rhys May, Arpi Vezer, Junhyuk Oh, Ken Franko, Sophie Bridgers, Ruizhe Zhao, Boxi
    Wu, Basil Mustafa, Sean Sechrist, Emilio Parisotto, Thanumalayan Sankaranarayana
    Pillai, Chris Larkin, Chenjie Gu, Christina Sorokin, Maxim Krikun, Alexey Guseynov,
    Jessica Landon, Romina Datta, Alexander Pritzel, Phoebe Thacker, Fan Yang, Kevin
    Hui, Anja Hauth, Chih-Kuan Yeh, David Barker, Justin Mao-Jones, Sophia Austin,
    Hannah Sheahan, Parker Schuh, James Svensson, Rohan Jain, Vinay Ramasesh, Anton
    Briukhov, Da-Woon Chung, Tamara von Glehn, Christina Butterfield, Priya Jhakra,
    Matthew Wiethoff, Justin Frye, Jordan Grimstad, Beer Changpinyo, Charline Le Lan,
    Anna Bortsova, Yonghui Wu, Paul Voigtlaender, Tara Sainath, Shane Gu, Charlotte
    Smith, Will Hawkins, Kris Cao, James Besley, Srivatsan Srinivasan, Mark Omernick,
    Colin Gaffney, Gabriela Surita, Ryan Burnell, Bogdan Damoc, Junwhan Ahn, Andrew
    Brock, Mantas Pajarskas, Anastasia Petrushkina, Seb Noury, Lorenzo Blanco, Kevin
    Swersky, Arun Ahuja, Thi Avrahami, Vedant Misra, Raoul de Liedekerke, Mariko Iinuma,
    Alex Polozov, Sarah York, George van den Driessche, Paul Michel, Justin Chiu,
    Rory Blevins, Zach Gleicher, Adrià Recasens, Alban Rrustemi, Elena Gribovskaya,
    Aurko Roy, Wiktor Gworek, Sébastien M. R. Arnold, Lisa Lee, James Lee-Thorp, Marcello
    Maggioni, Enrique Piqueras, Kartikeya Badola, Sharad Vikram, Lucas Gonzalez, Anirudh
    Baddepudi, Evan Senter, Jacob Devlin, James Qin, Michael Azzam, Maja Trebacz,
    Martin Polacek, Kashyap Krishnakumar, Shuo yiin Chang, Matthew Tung, Ivo Penchev,
    Rishabh Joshi, Kate Olszewska, Carrie Muir, Mateo Wirth, Ale Jakse Hartman, Josh
    Newlan, Sheleem Kashem, Vijay Bolina, Elahe Dabir, Joost van Amersfoort, Zafarali
    Ahmed, James Cobon-Kerr, Aishwarya Kamath, Arnar Mar Hrafnkelsson, Le Hou, Ian
    Mackinnon, Alexandre Frechette, Eric Noland, Xiance Si, Emanuel Taropa, Dong Li,
    Phil Crone, Anmol Gulati, Sébastien Cevey, Jonas Adler, Ada Ma, David Silver,
    Simon Tokumine, Richard Powell, Stephan Lee, Kiran Vodrahalli, Samer Hassan, Diana
    Mincu, Antoine Yang, Nir Levine, Jenny Brennan, Mingqiu Wang, Sarah Hodkinson,
    Jeffrey Zhao, Josh Lipschultz, Aedan Pope, Michael B. Chang, Cheng Li, Laurent El
    Shafey, Michela Paganini, Sholto Douglas, Bernd Bohnet, Fabio Pardo, Seth Odoom,
    Mihaela Rosca, Cicero Nogueira dos Santos, Kedar Soparkar, Arthur Guez, Tom Hudson,
    Steven Hansen, Chulayuth Asawaroengchai, Ravi Addanki, Tianhe Yu, Wojciech Stokowiec,
    Mina Khan, Justin Gilmer, Jaehoon Lee, Carrie Grimes Bostock, Keran Rong, Jonathan
    Caton, Pedram Pejman, Filip Pavetic, Geoff Brown, Vivek Sharma, Mario Lučić, Rajkumar
    Samuel, Josip Djolonga, Amol Mandhane, Lars Lowe Sjösund, Elena Buchatskaya, Elspeth
    White, Natalie Clay, Jiepu Jiang, Hyeontaek Lim, Ross Hemsley, Zeyncep Cankara,
    Jane Labanowski, Nicola De Cao, David Steiner, Sayed Hadi Hashemi, Jacob Austin,
    Anita Gergely, Tim Blyth, Joe Stanton, Kaushik Shivakumar, Aditya Siddhant, Anders
    Andreassen, Carlos Araya, Nikhil Sethi, Rakesh Shivanna, Steven Hand, Ankur Bapna,
    Ali Khodaei, Antoine Miech, Garrett Tanzer, Andy Swing, Shantanu Thakoor, Lora
    Aroyo, Zhufeng Pan, Zachary Nado, Jakub Sygnowski, Stephanie Winkler, Dian Yu,
    Mohammad Saleh, Loren Maggiore, Yamini Bansal, Xavier Garcia, Mehran Kazemi, Piyush
    Patil, Ishita Dasgupta, Iain Barr, Minh Giang, Thais Kagohara, Ivo Danihelka,
    Amit Marathe, Vladimir Feinberg, Mohamed Elhawaty, Nimesh Ghelani, Dan Horgan,
    Helen Miller, Lexi Walker, Richard Tanburn, Mukarram Tariq, Disha Shrivastava,
    Fei Xia, Qingze Wang, Chung-Cheng Chiu, Zoe Ashwood, Khuslen Baatarsukh, Sina
    Samangooei, Raphaël Lopez Kaufman, Fred Alcober, Axel Stjerngren, Paul Komarek,
    Katerina Tsihlas, Anudhyan Boral, Ramona Comanescu, Jeremy Chen, Ruibo Liu, Chris
    Welty, Dawn Bloxwich, Charlie Chen, Yanhua Sun, Fangxiaoyu Feng, Matthew Mauger,
    Xerxes Dotiwalla, Vincent Hellendoorn, Michael Sharman, Ivy Zheng, Krishna Haridasan,
    Gabe Barth-Maron, Craig Swanson, Dominika Rogozińska, Alek Andreev, Paul Kishan
    Rubenstein, Ruoxin Sang, Dan Hurt, Gamaleldin Elsayed, Renshen Wang, Dave Lacey,
    Anastasija Ilić, Yao Zhao, Adam Iwanicki, Alejandro Lince, Alexander Chen, Christina
    Lyu, Carl Lebsack, Jordan Griffith, Meenu Gaba, Paramjit Sandhu, Phil Chen, Anna
    Koop, Ravi Rajwar, Soheil Hassas Yeganeh, Solomon Chang, Rui Zhu, Soroush Radpour,
    Elnaz Davoodi, Ving Ian Lei, Yang Xu, Daniel Toyama, Constant Segal, Martin Wicke,
    Hanzhao Lin, Anna Bulanova, Adrià Puigdomènech Badia, Nemanja Rakićević, Pablo
    Sprechmann, Angelos Filos, Shaobo Hou, Víctor Campos, Nora Kassner, Devendra Sachan,
    Meire Fortunato, Chimezie Iwuanyanwu, Vitaly Nikolaev, Balaji Lakshminarayanan,
    Sadegh Jazayeri, Mani Varadarajan, Chetan Tekur, Doug Fritz, Misha Khalman, David
    Reitter, Kingshuk Dasgupta, Shourya Sarcar, Tina Ornduff, Javier Snaider, Fantine
    Huot, Johnson Jia, Rupert Kemp, Nejc Trdin, Anitha Vijayakumar, Lucy Kim, Christof
    Angermueller, Li Lao, Tianqi Liu, Haibin Zhang, David Engel, Somer Greene, Anaïs
    White, Jessica Austin, Lilly Taylor, Shereen Ashraf, Dangyi Liu, Maria Georgaki,
    Irene Cai, Yana Kulizhskaya, Sonam Goenka, Brennan Saeta, Ying Xu, Christian Frank,
    Dario de Cesare, Brona Robenek, Harry Richardson, Mahmoud Alnahlawi, Christopher
    Yew, Priya Ponnapalli, Marco Tagliasacchi, Alex Korchemniy, Yelin Kim, Dinghua
    Li, Bill Rosgen, Kyle Levin, Jeremy Wiesner, Praseem Banzal, Praveen Srinivasan,
    Hongkun Yu, Çağlar Ünlü, David Reid, Zora Tung, Daniel Finchelstein, Ravin Kumar,
    Andre Elisseeff, Jin Huang, Ming Zhang, Ricardo Aguilar, Mai Giménez, Jiawei Xia,
    Olivier Dousse, Willi Gierke, Damion Yates, Komal Jalan, Lu Li, Eri Latorre-Chimoto,
    Duc Dung Nguyen, Ken Durden, Praveen Kallakuri, Yaxin Liu, Matthew Johnson, Tomy
    Tsai, Alice Talbert, Jasmine Liu, Alexander Neitz, Chen Elkind, Marco Selvi, Mimi
    Jasarevic, Livio Baldini Soares, Albert Cui, Pidong Wang, Alek Wenjiao Wang, Xinyu
    Ye, Krystal Kallarackal, Lucia Loher, Hoi Lam, Josef Broder, Dan Holtmann-Rice,
    Nina Martin, Bramandia Ramadhana, Mrinal Shukla, Sujoy Basu, Abhi Mohan, Nick
    Fernando, Noah Fiedel, Kim Paterson, Hui Li, Ankush Garg, Jane Park, DongHyun
    Choi, Diane Wu, Sankalp Singh, Zhishuai Zhang, Amir Globerson, Lily Yu, John Carpenter,
    Félix de Chaumont Quitry, Carey Radebaugh, Chu-Cheng Lin, Alex Tudor, Prakash
    Shroff, Drew Garmon, Dayou Du, Neera Vats, Han Lu, Shariq Iqbal, Alex Yakubovich,
    Nilesh Tripuraneni, James Manyika, Haroon Qureshi, Nan Hua, Christel Ngani, Maria Abi
    Raad, Hannah Forbes, Jeff Stanway, Mukund Sundararajan, Victor Ungureanu, Colton
    Bishop, Yunjie Li, Balaji Venkatraman, Bo Li, Chloe Thornton, Salvatore Scellato,
    Nishesh Gupta, Yicheng Wang, Ian Tenney, Xihui Wu, Ashish Shenoy, Gabriel Carvajal,
    Diana Gage Wright, Ben Bariach, Zhuyun Xiao, Peter Hawkins, Sid Dalmia, Clement
    Farabet, Pedro Valenzuela, Quan Yuan, Ananth Agarwal, Mia Chen, Wooyeol Kim, Brice
    Hulse, Nandita Dukkipati, Adam Paszke, Andrew Bolt, Kiam Choo, Jennifer Beattie,
    Jennifer Prendki, Harsha Vashisht, Rebeca Santamaria-Fernandez, Luis C. Cobo,
    Jarek Wilkiewicz, David Madras, Ali Elqursh, Grant Uy, Kevin Ramirez, Matt Harvey,
    Tyler Liechty, Heiga Zen, Jeff Seibert, Clara Huiyi Hu, Andrey Khorlin, Maigo
    Le, Asaf Aharoni, Megan Li, Lily Wang, Sandeep Kumar, Norman Casagrande, Jay Hoover,
    Dalia El Badawy, David Soergel, Denis Vnukov, Matt Miecnikowski, Jiri Simsa, Praveen
    Kumar, Thibault Sellam, Daniel Vlasic, Samira Daruki, Nir Shabat, John Zhang,
    Guolong Su, Jiageng Zhang, Jeremiah Liu, Yi Sun, Evan Palmer, Alireza Ghaffarkhah,
    Xi Xiong, Victor Cotruta, Michael Fink, Lucas Dixon, Ashwin Sreevatsa, Adrian
    Goedeckemeyer, Alek Dimitriev, Mohsen Jafari, Remi Crocker, Nicholas FitzGerald,
    Aviral Kumar, Sanjay Ghemawat, Ivan Philips, Frederick Liu, Yannie Liang, Rachel
    Sterneck, Alena Repina, Marcus Wu, Laura Knight, Marin Georgiev, Hyo Lee, Harry
    Askham, Abhishek Chakladar, Annie Louis, Carl Crous, Hardie Cate, Dessie Petrova,
    Michael Quinn, Denese Owusu-Afriyie, Achintya Singhal, Nan Wei, Solomon Kim, Damien
    Vincent, Milad Nasr, Christopher A. Choquette-Choo, Reiko Tojo, Shawn Lu, Diego
    de Las Casas, Yuchung Cheng, Tolga Bolukbasi, Katherine Lee, Saaber Fatehi, Rajagopal
    Ananthanarayanan, Miteyan Patel, Charbel Kaed, Jing Li, Shreyas Rammohan Belle,
    Zhe Chen, Jaclyn Konzelmann, Siim Põder, Roopal Garg, Vinod Koverkathu, Adam Brown,
    Chris Dyer, Rosanne Liu, Azade Nova, Jun Xu, Alanna Walton, Alicia Parrish, Mark
    Epstein, Sara McCarthy, Slav Petrov, Demis Hassabis, Koray Kavukcuoglu, Jeffrey
    Dean, and Oriol Vinyals. 2024. Gemini 1.5: Unlocking multimodal understanding
    across millions of tokens of context. *arXiv preprint arXiv: 2403.05530*.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Team 等人 (2024) Gemini Team, Machel Reid, Nikolay Savinov, Denis Teplyashin,
    Dmitry Lepikhin, Timothy Lillicrap, Jean Baptiste Alayrac, Radu Soricut, Angeliki
    Lazaridou, Orhan Firat, Julian Schrittwieser, Ioannis Antonoglou, Rohan Anil,
    Sebastian Borgeaud, Andrew Dai, Katie Millican, Ethan Dyer, Mia Glaese, Thibault
    Sottiaux, Benjamin Lee, Fabio Viola, Malcolm Reynolds, Yuanzhong Xu, James Molloy,
    Jilin Chen, Michael Isard, Paul Barham, Tom Hennigan, Ross McIlroy, Melvin Johnson,
    Johan Schalkwyk, Eli Collins, Eliza Rutherford, Erica Moreira, Kareem Ayoub, Megha
    Goel, Clemens Meyer, Gregory Thornton, Zhen Yang, Henryk Michalewski, Zaheer Abbas,
    Nathan Schucher, Ankesh Anand, Richard Ives, James Keeling, Karel Lenc, Salem
    Haykal, Siamak Shakeri, Pranav Shyam, Aakanksha Chowdhery, Roman Ring, Stephen
    Spencer, Eren Sezener, Luke Vilnis, Oscar Chang, Nobuyuki Morioka, George Tucker,
    Ce Zheng, Oliver Woodman, Nithya Attaluri, Tomas Kocisky, Evgenii Eltyshev, Xi
    Chen, Timothy Chung, Vittorio Selo, Siddhartha Brahma, Petko Georgiev, Ambrose
    Slone, Zhenkai Zhu, James Lottes, Siyuan Qiao, Ben Caine, Sebastian Riedel, Alex
    Tomala, Martin Chadwick, Juliette Love, Peter Choy, Sid Mittal, Neil Houlsby,
    Yunhao Tang, Matthew Lamm, Libin Bai, Qiao Zhang, Luheng He, Yong Cheng, Peter
    Humphreys, Yujia Li, Sergey Brin, Albin Cassirer, Yingjie Miao, Lukas Zilka, Taylor
    Tobin, Kelvin Xu, Lev Proleev, Daniel Sohn, Alberto Magni, Lisa Anne Hendricks,
    Isabel Gao, Santiago Ontanon, Oskar Bunyan, Nathan Byrd, Abhanshu Sharma, Biao
    Zhang, Mario Pinto, Rishika Sinha, Harsh Mehta, Dawei Jia, Sergi Caelles, Albert
    Webson, Alex Morris, Becca Roelofs, Yifan Ding, Robin Strudel, Xuehan Xiong, Marvin
    Ritter, Mostafa Dehghani, Rahma Chaabouni, Abhijit Karmarkar, Guangda Lai, Fabian
    Mentzer, Bibo Xu, YaGuang Li, Yujing Zhang, Tom Le Paine, Alex Goldin, Behnam
    Neyshabur, Kate Baumli, Anselm Levskaya, Michael Laskin, Wenhao Jia, Jack W. Rae,
    Kefan Xiao, Antoine He, Skye Giordano, Lakshman Yagati, Jean-Baptiste Lespiau,
    Paul Natsev, Sanjay Ganapathy, Fangyu Liu, Danilo Martins, Nanxin Chen, Yunhan
    Xu, Megan Barnes, Rhys May, Arpi Vezer, Junhyuk Oh, Ken Franko, Sophie Bridgers,
    Ruizhe Zhao, Boxi Wu, Basil Mustafa, Sean Sechrist, Emilio Parisotto, Thanumalayan
    Sankaranarayana Pillai, Chris Larkin, Chenjie Gu, Christina Sorokin, Maxim Krikun,
    Alexey Guseynov, Jessica Landon, Romina Datta, Alexander Pritzel, Phoebe Thacker,
    Fan Yang, Kevin Hui, Anja Hauth, Chih-Kuan Yeh, David Barker, Justin Mao-Jones,
    Sophia Austin, Hannah Sheahan, Parker Schuh, James Svensson, Rohan Jain, Vinay
    Ramasesh, Anton Briukhov, Da-Woon Chung, Tamara von Glehn, Christina Butterfield,
    Priya Jhakra, Matthew Wiethoff, Justin Frye, Jordan Grimstad, Beer Changpinyo,
    Charline Le Lan, Anna Bortsova, Yonghui Wu, Paul Voigtlaender, Tara Sainath, Shane
    Gu, Charlotte Smith, Will Hawkins, Kris Cao, James Besley, Srivatsan Srinivasan,
    Mark Omernick, Colin Gaffney, Gabriela Surita, Ryan Burnell, Bogdan Damoc, Junwhan
    Ahn, Andrew Brock, Mantas Pajarskas, Anastasia Petrushkina, Seb Noury, Lorenzo
    Blanco, Kevin Swersky, Arun Ahuja, Thi Avrahami, Vedant Misra, Raoul de Liedekerke,
    Mariko Iinuma, Alex Polozov, Sarah York, George van den Driessche, Paul Michel,
    Justin Chiu, Rory Blevins, Zach Gleicher, Adrià Recasens, Alban Rrustemi, Elena
    Gribovskaya, Aurko Roy, Wiktor Gworek, Sébastien M. R. Arnold, Lisa Lee, James
    Lee-Thorp, Marcello Maggioni, Enrique Piqueras, Kartikeya Badola, Sharad Vikram,
    Lucas Gonzalez, Anirudh Baddepudi, Evan Senter, Jacob Devlin, James Qin, Michael
    Azzam, Maja Trebacz, Martin Polacek, Kashyap Krishnakumar, Shuo yiin Chang, Matthew
    Tung, Ivo Penchev, Rishabh Joshi, Kate Olszewska, Carrie Muir, Mateo Wirth, Ale
    Jakse Hartman, Josh Newlan, Sheleem Kashem, Vijay Bolina, Elahe Dabir, Joost van
    Amersfoort, Zafarali Ahmed, James Cobon-Kerr, Aishwarya Kamath, Arnar Mar Hrafnkelsson,
    Le Hou, Ian Mackinnon, Alexandre Frechette, Eric Noland, Xiance Si, Emanuel Taropa,
    Dong Li, Phil Crone, Anmol Gulati, Sébastien Cevey, Jonas Adler, Ada Ma, David
    Silver, Simon Tokumine, Richard Powell, Stephan Lee, Kiran Vodrahalli, Samer Hassan,
    Diana Mincu, Antoine Yang, Nir Levine, Jenny Brennan, Mingqiu Wang, Sarah Hodkinson,
    Jeffrey Zhao, Josh Lipschultz, Aedan Pope, Michael B. Chang, Cheng Li, Laurent
    El Shafey, Michela Paganini, Sholto Douglas, Bernd Bohnet, Fabio Pardo, Seth Odoom,
    Mihaela Rosca, Cicero Nogueira dos Santos, Kedar Soparkar, Arthur Guez, Tom Hudson,
    Steven Hansen, Chulayuth Asawaroengchai, Ravi Addanki, Tianhe Yu, Wojciech Stokowiec,
    Mina Khan, Justin Gilmer, Jaehoon Lee, Carrie Grimes Bostock, Keran Rong, Jonathan
    Caton, Pedram Pejman, Filip Pavetic, Geoff Brown, Vivek Sharma, Mario Lučić, Rajkumar
    Samuel, Josip Djolonga, Amol Mandhane, Lars Lowe Sjösund, Elena Buchatskaya, Elspeth
    White, Natalie Clay, Jiepu Jiang, Hyeontaek Lim, Ross Hemsley, Zeyncep Cankara,
    Jane Labanowski, Nicola De Cao, David Steiner, Sayed Hadi Hashemi, Jacob Austin,
    Anita Gergely, Tim Blyth, Joe Stanton, Kaushik Shivakumar, Aditya Siddhant, Anders
    Andreassen, Carlos Araya, Nikhil Sethi, Rakesh Shivanna, Steven Hand, Ankur Bapna,
    Ali Khodaei, Antoine Miech, Garrett Tanzer, Andy Swing, Shantanu Thakoor, Lora
    Aroyo, Zhufeng Pan, Zachary Nado, Jakub Sygnowski, Stephanie Winkler, Dian Yu,
    Mohammad Saleh, Loren Maggiore, Yamini Bansal, Xavier Garcia, Mehran Kazemi, Piyush
    Patil, Ishita Dasgupta, Iain Barr, Minh Giang, Thais Kagohara, Ivo Danihelka,
    Amit Marathe, Vladimir Feinberg, Mohamed Elhawaty, Nimesh Ghelani, Dan Horgan,
    Helen Miller, Lexi Walker, Richard Tanburn, Mukarram Tariq, Disha Shrivastava,
    Fei Xia, Qingze Wang, Chung-Cheng Chiu, Zoe Ashwood, Khuslen Baatarsukh, Sina
    Samangooei, Raphaël Lopez Kaufman, Fred Alcober, Axel Stjerngren, Paul Komarek,
    Katerina Tsihlas, Anudhyan Boral, Ramona Comanescu, Jeremy Chen, Ruibo Liu, Chris
    Welty, Dawn Bloxwich, Charlie Chen, Yanhua Sun, Fangxiaoyu Feng, Matthew Mauger,
    Xerxes Dotiwalla, Vincent Hellendoorn, Michael Sharman, Ivy Zheng, Krishna Haridasan,
    Gabe Barth-Maron, Craig Swanson, Dominika Rogozińska, Alek Andreev, Paul Kishan
    Rubenstein, Ruoxin Sang, Dan Hurt, Gamaleldin Elsayed, Renshen Wang, Dave Lacey,
    Anastasija Ilić, Yao Zhao, Adam Iwanicki, Alejandro Lince, Alexander Chen, Christina
    Lyu, Carl Lebsack, Jordan Griffith, Meenu Gaba, Paramjit Sandhu, Phil Chen, Anna
    Koop, Ravi Rajwar, Soheil Hassas Yeganeh, Solomon Chang, Rui Zhu, Soroush Radpour,
    Elnaz Davoodi, Ving Ian Lei, Yang Xu, Daniel Toyama, Constant Seg
- en: 'Wang et al. (2023a) Jiaan Wang, Yunlong Liang, Fandong Meng, Zengkui Sun, Haoxiang
    Shi, Zhixu Li, Jinan Xu, Jianfeng Qu, and Jie Zhou. 2023a. Is chatgpt a good nlg
    evaluator? a preliminary study. *arXiv preprint arXiv: 2303.04048*.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang et al. (2023a) Jiaan Wang, Yunlong Liang, Fandong Meng, Zengkui Sun, Haoxiang
    Shi, Zhixu Li, Jinan Xu, Jianfeng Qu, 和 Jie Zhou. 2023a. ChatGPT是一个好的NLG评估器吗？一项初步研究。*arXiv
    预印本 arXiv: 2303.04048*'
- en: 'Wang et al. (2023b) Peiyi Wang, Lei Li, Liang Chen, Zefan Cai, Dawei Zhu, Binghuai
    Lin, Yunbo Cao, Qi Liu, Tianyu Liu, and Zhifang Sui. 2023b. Large language models
    are not fair evaluators. *arXiv preprint arXiv: 2305.17926*.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang et al. (2023b) Peiyi Wang, Lei Li, Liang Chen, Zefan Cai, Dawei Zhu, Binghuai
    Lin, Yunbo Cao, Qi Liu, Tianyu Liu, 和 Zhifang Sui. 2023b. 大型语言模型并非公平评估者。*arXiv
    预印本 arXiv: 2305.17926*.'
- en: Wang et al. (2023c) Peiyi Wang, Lei Li, Liang Chen, Dawei Zhu, Binghuai Lin,
    Yunbo Cao, Qi Liu, Tianyu Liu, and Zhifang Sui. 2023c. [Large language models
    are not fair evaluators](https://doi.org/10.48550/ARXIV.2305.17926). *CoRR*, abs/2305.17926.
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. (2023c) Peiyi Wang, Lei Li, Liang Chen, Dawei Zhu, Binghuai Lin,
    Yunbo Cao, Qi Liu, Tianyu Liu, 和 Zhifang Sui. 2023c. [大型语言模型并非公平评估者](https://doi.org/10.48550/ARXIV.2305.17926).
    *CoRR*, abs/2305.17926.
- en: 'Wang et al. (2023d) Yidong Wang, Zhuohao Yu, Zhengran Zeng, Linyi Yang, Cunxiang
    Wang, Hao Chen, Chaoya Jiang, Rui Xie, Jindong Wang, Xing Xie, Wei Ye, Shikun
    Zhang, and Yue Zhang. 2023d. [Pandalm: An automatic evaluation benchmark for LLM
    instruction tuning optimization](https://doi.org/10.48550/ARXIV.2306.05087). *CoRR*,
    abs/2306.05087.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. (2023d) Yidong Wang, Zhuohao Yu, Zhengran Zeng, Linyi Yang, Cunxiang
    Wang, Hao Chen, Chaoya Jiang, Rui Xie, Jindong Wang, Xing Xie, Wei Ye, Shikun
    Zhang, 和 Yue Zhang. 2023d. [Pandalm：一个用于LLM指令调优优化的自动评估基准](https://doi.org/10.48550/ARXIV.2306.05087).
    *CoRR*, abs/2306.05087.
- en: 'Watts et al. (2024) Ishaan Watts, Varun Gumma, Aditya Yadavalli, Vivek Seshadri,
    Swami Manohar, and Sunayana Sitaram. 2024. [Pariksha: A scalable, democratic,
    transparent evaluation platform for assessing indic large language models](https://www.microsoft.com/en-us/research/publication/pariksha-a-scalable-democratic-transparent-evaluation-platform-for-assessing-indic-large-language-models/).'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Watts et al. (2024) Ishaan Watts, Varun Gumma, Aditya Yadavalli, Vivek Seshadri,
    Swami Manohar, 和 Sunayana Sitaram. 2024. [Pariksha：一个可扩展的、民主的、透明的评估平台，用于评估印地语大型语言模型](https://www.microsoft.com/en-us/research/publication/pariksha-a-scalable-democratic-transparent-evaluation-platform-for-assessing-indic-large-language-models/).
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Huai
    hsin Chi, F. Xia, Quoc Le, and Denny Zhou. 2022. [Chain of thought prompting elicits
    reasoning in large language models](https://api.semanticscholar.org/CorpusID:246411621).
    *ArXiv*, abs/2201.11903.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed
    Huai hsin Chi, F. Xia, Quoc Le, 和 Denny Zhou. 2022. [思维链提示在大型语言模型中引发推理](https://api.semanticscholar.org/CorpusID:246411621).
    *ArXiv*, abs/2201.11903.
- en: 'Wu and Aji (2023) Minghao Wu and Alham Fikri Aji. 2023. Style over substance:
    Evaluation biases for large language models. *arXiv preprint arXiv: 2307.03025*.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wu and Aji (2023) Minghao Wu 和 Alham Fikri Aji. 2023. 表面风格：大型语言模型的评估偏差。*arXiv
    预印本 arXiv: 2307.03025*.'
- en: 'Wu et al. (2023) Zhaofeng Wu, Linlu Qiu, Alexis Ross, Ekin Akyürek, Boyuan
    Chen, Bailin Wang, Najoung Kim, Jacob Andreas, and Yoon Kim. 2023. Reasoning or
    reciting? exploring the capabilities and limitations of language models through
    counterfactual tasks. *arXiv preprint arXiv: 2307.02477*.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wu et al. (2023) Zhaofeng Wu, Linlu Qiu, Alexis Ross, Ekin Akyürek, Boyuan
    Chen, Bailin Wang, Najoung Kim, Jacob Andreas, 和 Yoon Kim. 2023. 推理还是背诵？通过反事实任务探索语言模型的能力和局限性。*arXiv
    预印本 arXiv: 2307.02477*.'
- en: 'Xu et al. (2023) Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan
    Feng, Chongyang Tao, and Daxin Jiang. 2023. [Wizardlm: Empowering large language
    models to follow complex instructions](https://doi.org/10.48550/ARXIV.2304.12244).
    *CoRR*, abs/2304.12244.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu et al. (2023) Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan
    Feng, Chongyang Tao, 和 Daxin Jiang. 2023. [Wizardlm：赋能大型语言模型以遵循复杂指令](https://doi.org/10.48550/ARXIV.2304.12244).
    *CoRR*, abs/2304.12244.
- en: 'Ye et al. (2023) Seonghyeon Ye, Doyoung Kim, Sungdong Kim, Hyeonbin Hwang,
    Seungone Kim, Yongrae Jo, James Thorne, Juho Kim, and Minjoon Seo. 2023. [FLASK:
    fine-grained language model evaluation based on alignment skill sets](https://doi.org/10.48550/ARXIV.2307.10928).
    *CoRR*, abs/2307.10928.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ye et al. (2023) Seonghyeon Ye, Doyoung Kim, Sungdong Kim, Hyeonbin Hwang,
    Seungone Kim, Yongrae Jo, James Thorne, Juho Kim, 和 Minjoon Seo. 2023. [FLASK:
    基于对齐技能集的细粒度语言模型评估](https://doi.org/10.48550/ARXIV.2307.10928). *CoRR*, abs/2307.10928.'
- en: Zeng et al. (2023) Zhiyuan Zeng, Jiatong Yu, Tianyu Gao, Yu Meng, Tanya Goyal,
    and Danqi Chen. 2023. [Evaluating large language models at evaluating instruction
    following](https://doi.org/10.48550/ARXIV.2310.07641). *CoRR*, abs/2310.07641.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zeng et al. (2023) Zhiyuan Zeng, Jiatong Yu, Tianyu Gao, Yu Meng, Tanya Goyal,
    和 Danqi Chen. 2023. [评估大型语言模型在评估指令跟随方面的能力](https://doi.org/10.48550/ARXIV.2310.07641).
    *CoRR*, abs/2310.07641.
- en: 'Zhang et al. (2023) Xinghua Zhang, Bowen Yu, Haiyang Yu, Yangyu Lv, Tingwen
    Liu, Fei Huang, Hongbo Xu, and Yongbin Li. 2023. Wider and deeper llm networks
    are fairer llm evaluators. *arXiv preprint arXiv: 2308.01862*.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang et al. (2023) Xinghua Zhang, Bowen Yu, Haiyang Yu, Yangyu Lv, Tingwen
    Liu, Fei Huang, Hongbo Xu, 和 Yongbin Li. 2023. 更宽更深的 LLM 网络是更公平的 LLM 评估者。 *arXiv
    预印本 arXiv: 2308.01862*。'
- en: 'Zheng et al. (2023) Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang,
    Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric P. Xing, Hao
    Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. [Judging llm-as-a-judge with
    mt-bench and chatbot arena](http://papers.nips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html).
    In *Advances in Neural Information Processing Systems 36: Annual Conference on
    Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA,
    December 10 - 16, 2023*.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng et al. (2023) Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang,
    Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric P. Xing, Hao
    Zhang, Joseph E. Gonzalez, 和 Ion Stoica. 2023. [用 mt-bench 和 chatbot arena 评判
    llm-as-a-judge](http://papers.nips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html).
    载于 *Neural Information Processing Systems 36：2023年神经信息处理系统年会，NeurIPS 2023, New
    Orleans, LA, USA, 2023年12月10日至16日*。
- en: 'Zhou et al. (2023a) Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao
    Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, Susan Zhang, Gargi Ghosh,
    Mike Lewis, Luke Zettlemoyer, and Omer Levy. 2023a. [LIMA: less is more for alignment](https://doi.org/10.48550/ARXIV.2305.11206).
    *CoRR*, abs/2305.11206.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhou et al. (2023a) Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao
    Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, Susan Zhang, Gargi Ghosh,
    Mike Lewis, Luke Zettlemoyer, 和 Omer Levy. 2023a. [LIMA: 更少即更多用于对齐](https://doi.org/10.48550/ARXIV.2305.11206).
    *CoRR*, abs/2305.11206.'
- en: Zhou et al. (2023b) Jeffrey Zhou, Tianjian Lu, Swaroop Mishra, Siddhartha Brahma,
    Sujoy Basu, Yi Luan, Denny Zhou, and Le Hou. 2023b. [Instruction-following evaluation
    for large language models](https://doi.org/10.48550/ARXIV.2311.07911). *CoRR*,
    abs/2311.07911.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou et al. (2023b) Jeffrey Zhou, Tianjian Lu, Swaroop Mishra, Siddhartha Brahma,
    Sujoy Basu, Yi Luan, Denny Zhou, 和 Le Hou. 2023b. [大型语言模型的指令跟随评估](https://doi.org/10.48550/ARXIV.2311.07911).
    *CoRR*, abs/2311.07911.
- en: 'Zhu et al. (2023) Lianghui Zhu, Xinggang Wang, and Xinlong Wang. 2023. Judgelm:
    Fine-tuned large language models are scalable judges. *arXiv preprint arXiv: 2310.17631*.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhu et al. (2023) Lianghui Zhu, Xinggang Wang, 和 Xinlong Wang. 2023. Judgelm:
    微调的大型语言模型是可扩展的裁判。 *arXiv 预印本 arXiv: 2310.17631*。'
- en: Appendix A Manual Verication Process of the Perturbations
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 扰动的手动验证过程
- en: 'We engaged 17 graduate student volunteers with a good understanding of Large
    Language Models to manually verify the perturbations. Each annotator was provided
    with the instruction, the original gold answer, and the GPT-4-turbo  generated
    perturbed answer. They were tasked with classifying each perturbation into one
    of five categories: (i) Valid Perturbation, (ii) Invalid Perturbation, (iii) Score
    Invariant Perturbation, (iv) Not Relevant, and (v) Not Sure. Additionally, annotators
    were given explanations of the expected perturbations and the reasons why GPT-4-turbo 
    considered them valid.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 我们邀请了 17 名对大型语言模型有深入了解的研究生志愿者手动验证扰动。每位标注员都提供了指令、原始金答案和 GPT-4-turbo 生成的扰动答案。他们的任务是将每个扰动分类为以下五类之一：(i)
    有效扰动，(ii) 无效扰动，(iii) 分数不变扰动，(iv) 无关，(v) 不确定。此外，标注员还获得了对预期扰动的解释及 GPT-4-turbo 认为它们有效的原因。
- en: To facilitate this process, we developed a straightforward application, the
    interface of which is depicted in Figure [3](#A1.F3 "Figure 3 ‣ Appendix A Manual
    Verication Process of the Perturbations ‣ Finding Blind Spots in Evaluator LLMs
    with Interpretable Checklists"). This tool highlights the differences between
    the original and perturbed answers to aid easy identification.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化此过程，我们开发了一个简单的应用程序，其界面如图 [3](#A1.F3 "图 3 ‣ 附录 A 扰动的手动验证过程 ‣ 使用可解释检查表发现评估器
    LLM 中的盲点") 所示。该工具突出显示了原始答案与扰动答案之间的差异，以便于识别。
- en: '![Refer to caption](img/d5325321cd9575feb7113993d01d81fd.png)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/d5325321cd9575feb7113993d01d81fd.png)'
- en: 'Figure 3: Screenshot of the User Application developed for validating perturbations.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：用于验证扰动的用户应用程序的屏幕截图。
- en: Annotators were instructed to label an answer as “Valid Perturbation” only if
    they believed the perturbation warranted a score penalty relative to the gold
    answer. Perturbations not affecting the score were to be labeled “Score Invariant”.
    If a perturbation was deemed incorrect or not reflected in the perturbed answer,
    annotators were asked to adjust the perturbation manually. Perturbations irrelevant
    to the category were to be marked as “Not Relevant”.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 注释员被指示仅当他们认为扰动相对于金标准答案值得扣分时，才将答案标记为“有效扰动”。没有影响得分的扰动应标记为“得分不变”。如果扰动被认为不正确或在扰动答案中未体现，注释员被要求手动调整扰动。与类别无关的扰动应标记为“无关”。
- en: Appendix B Detailed Results of Single Answer Evaluators
  id: totrans-251
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 单一答案评估者的详细结果
- en: Detailed results of Single Answer evaluators can be found in Table [6](#A4.T6
    "Table 6 ‣ Appendix D Detailed Results of Reference-Guided Evaluators ‣ Finding
    Blind Spots in Evaluator LLMs with Interpretable Checklists"), [7](#A4.T7 "Table
    7 ‣ Appendix D Detailed Results of Reference-Guided Evaluators ‣ Finding Blind
    Spots in Evaluator LLMs with Interpretable Checklists"), [8](#A4.T8 "Table 8 ‣
    Appendix D Detailed Results of Reference-Guided Evaluators ‣ Finding Blind Spots
    in Evaluator LLMs with Interpretable Checklists"), [9](#A4.T9 "Table 9 ‣ Appendix
    D Detailed Results of Reference-Guided Evaluators ‣ Finding Blind Spots in Evaluator
    LLMs with Interpretable Checklists"), [10](#A4.T10 "Table 10 ‣ Appendix D Detailed
    Results of Reference-Guided Evaluators ‣ Finding Blind Spots in Evaluator LLMs
    with Interpretable Checklists").
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 单一答案评估者的详细结果可以在表 [6](#A4.T6 "表 6 ‣ 附录 D 参考指导评估者的详细结果 ‣ 发现评估器 LLM 的盲点")、[7](#A4.T7
    "表 7 ‣ 附录 D 参考指导评估者的详细结果 ‣ 发现评估器 LLM 的盲点")、[8](#A4.T8 "表 8 ‣ 附录 D 参考指导评估者的详细结果
    ‣ 发现评估器 LLM 的盲点")、[9](#A4.T9 "表 9 ‣ 附录 D 参考指导评估者的详细结果 ‣ 发现评估器 LLM 的盲点")、[10](#A4.T10
    "表 10 ‣ 附录 D 参考指导评估者的详细结果 ‣ 发现评估器 LLM 的盲点") 中查找。
- en: Appendix C Detailed Results of Pairwise Evaluators
  id: totrans-253
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 C 对比评估者的详细结果
- en: Detailed results of Pairwise Evaluators can be found in Table [11](#A4.T11 "Table
    11 ‣ Appendix D Detailed Results of Reference-Guided Evaluators ‣ Finding Blind
    Spots in Evaluator LLMs with Interpretable Checklists"), [12](#A4.T12 "Table 12
    ‣ Appendix D Detailed Results of Reference-Guided Evaluators ‣ Finding Blind Spots
    in Evaluator LLMs with Interpretable Checklists"), [13](#A4.T13 "Table 13 ‣ Appendix
    D Detailed Results of Reference-Guided Evaluators ‣ Finding Blind Spots in Evaluator
    LLMs with Interpretable Checklists"), [14](#A4.T14 "Table 14 ‣ Appendix D Detailed
    Results of Reference-Guided Evaluators ‣ Finding Blind Spots in Evaluator LLMs
    with Interpretable Checklists"), [15](#A4.T15 "Table 15 ‣ Appendix D Detailed
    Results of Reference-Guided Evaluators ‣ Finding Blind Spots in Evaluator LLMs
    with Interpretable Checklists").
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 对比评估者的详细结果可以在表 [11](#A4.T11 "表 11 ‣ 附录 D 参考指导评估者的详细结果 ‣ 发现评估器 LLM 的盲点")、[12](#A4.T12
    "表 12 ‣ 附录 D 参考指导评估者的详细结果 ‣ 发现评估器 LLM 的盲点")、[13](#A4.T13 "表 13 ‣ 附录 D 参考指导评估者的详细结果
    ‣ 发现评估器 LLM 的盲点")、[14](#A4.T14 "表 14 ‣ 附录 D 参考指导评估者的详细结果 ‣ 发现评估器 LLM 的盲点")、[15](#A4.T15
    "表 15 ‣ 附录 D 参考指导评估者的详细结果 ‣ 发现评估器 LLM 的盲点") 中查找。
- en: Appendix D Detailed Results of Reference-Guided Evaluators
  id: totrans-255
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 D 参考指导评估者的详细结果
- en: Detailed results of Reference-guided Evaluators can be found in Table [16](#A4.T16
    "Table 16 ‣ Appendix D Detailed Results of Reference-Guided Evaluators ‣ Finding
    Blind Spots in Evaluator LLMs with Interpretable Checklists"), [17](#A4.T17 "Table
    17 ‣ Appendix D Detailed Results of Reference-Guided Evaluators ‣ Finding Blind
    Spots in Evaluator LLMs with Interpretable Checklists")
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 参考指导评估者的详细结果可以在表 [16](#A4.T16 "表 16 ‣ 附录 D 参考指导评估者的详细结果 ‣ 发现评估器 LLM 的盲点")、[17](#A4.T17
    "表 17 ‣ 附录 D 参考指导评估者的详细结果 ‣ 发现评估器 LLM 的盲点") 中查找。
- en: '|  | Perturbation Type |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '|  | 扰动类型 |'
- en: '&#124; Total &#124;'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 总计 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Detected &#124;'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 检测到 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Undetected &#124;'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 未检测到 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; % Undetected &#124;'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; % 未检测到 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| LF | Coherence | 91 | 78 | 13 | 0.14 |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| LF | 一致性 | 91 | 78 | 13 | 0.14 |'
- en: '| Comprehensiveness | 90 | 9 | 82 | 0.91 |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| 完整性 | 90 | 9 | 82 | 0.91 |'
- en: '| Consistency | 84 | 16 | 68 | 0.81 |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| 一致性 | 84 | 16 | 68 | 0.81 |'
- en: '| Grammar | 92 | 25 | 67 | 0.73 |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| 语法 | 92 | 25 | 67 | 0.73 |'
- en: '| Chronology | 71 | 7 | 64 | 0.90 |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| 年代顺序 | 71 | 7 | 64 | 0.90 |'
- en: '| Spelling | 100 | 11 | 89 | 0.89 |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| 拼写 | 100 | 11 | 89 | 0.89 |'
- en: '| Total | 528 | 146 | 383 | 0.73 |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 528 | 146 | 383 | 0.73 |'
- en: '| F | Contextual | 94 | 41 | 53 | 0.56 |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| F | 上下文 | 94 | 41 | 53 | 0.56 |'
- en: '| Entity | 87 | 29 | 58 | 0.67 |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| 实体 | 87 | 29 | 58 | 0.67 |'
- en: '| Incorrect Fact | 68 | 24 | 44 | 0.65 |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| 错误事实 | 68 | 24 | 44 | 0.65 |'
- en: '| Number Errorss | 74 | 22 | 52 | 0.70 |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| 数字错误 | 74 | 22 | 52 | 0.70 |'
- en: '| Opposite Fact | 91 | 39 | 52 | 0.57 |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| 相反事实 | 91 | 39 | 52 | 0.57 |'
- en: '| Remove Fact | 69 | 4 | 65 | 0.94 |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| 删除事实 | 69 | 4 | 65 | 0.94 |'
- en: '| Total | 483 | 159 | 324 | 0.67 |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 483 | 159 | 324 | 0.67 |'
- en: '| IF | Assumptions | 81 | 4 | 77 | 0.95 |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| IF | 假设 | 81 | 4 | 77 | 0.95 |'
- en: '| Do Less | 100 | 32 | 68 | 0.68 |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| 做更少 | 100 | 32 | 68 | 0.68 |'
- en: '| Do More | 50 | 34 | 16 | 0.32 |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| 做更多 | 50 | 34 | 16 | 0.32 |'
- en: '| Ignore Format | 99 | 36 | 63 | 0.64 |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| 忽略格式 | 99 | 36 | 63 | 0.64 |'
- en: '| Sequence Errors | 49 | 4 | 45 | 0.92 |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| 顺序错误 | 49 | 4 | 45 | 0.92 |'
- en: '| Total | 379 | 110 | 269 | 0.71 |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 379 | 110 | 269 | 0.71 |'
- en: '| R | Calculations | 149 | 121 | 28 | 0.19 |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| R | 计算 | 149 | 121 | 28 | 0.19 |'
- en: '| Copying Numbers | 83 | 69 | 14 | 0.17 |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| 复制数字 | 83 | 69 | 14 | 0.17 |'
- en: '| Final Errors | 97 | 54 | 43 | 0.44 |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '| 最终错误 | 97 | 54 | 43 | 0.44 |'
- en: '| Incorrect Units | 77 | 66 | 11 | 0.14 |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '| 错误单位 | 77 | 66 | 11 | 0.14 |'
- en: '| Wrong Formula | 88 | 73 | 15 | 0.17 |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| 错误公式 | 88 | 73 | 15 | 0.17 |'
- en: '| Total | 494 | 383 | 111 | 0.22 |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 494 | 383 | 111 | 0.22 |'
- en: 'Table 6: Results from evaluating FBI using Vanilla^∗ evaluator. An error is
    said to be detected if the evaluator penalizes the score of the perturbed answer.'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '表 6: 使用 Vanilla^∗ 评估器评估 FBI 的结果。如果评估器对扰动答案的分数进行惩罚，则认为错误已被检测到。'
- en: '|  | Perturbation Type |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
  zh: '|  | 扰动类型 |'
- en: '&#124; Total &#124;'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 总计 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Detected &#124;'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 检测到 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Undetected &#124;'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 未检测到 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; % Undetected &#124;'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; % 未检测到 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| LF | Coherence | 91 | 82 | 9 | 0.10 |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
  zh: '| LF | 连贯性 | 91 | 82 | 9 | 0.10 |'
- en: '| Comprehensiveness | 90 | 30 | 60 | 0.67 |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
  zh: '| 综合性 | 90 | 30 | 60 | 0.67 |'
- en: '| Consistency | 84 | 35 | 49 | 0.58 |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '| 一致性 | 84 | 35 | 49 | 0.58 |'
- en: '| Grammar | 92 | 40 | 52 | 0.57 |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
  zh: '| 语法 | 92 | 40 | 52 | 0.57 |'
- en: '| Chronology | 71 | 18 | 53 | 0.75 |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| 年代顺序 | 71 | 18 | 53 | 0.75 |'
- en: '| Spelling | 100 | 20 | 80 | 0.80 |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| 拼写 | 100 | 20 | 80 | 0.80 |'
- en: '| Total | 528 | 225 | 303 | 0.57 |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 528 | 225 | 303 | 0.57 |'
- en: '| F | Contextual | 94 | 45 | 48 | 0.51 |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| F | 上下文 | 94 | 45 | 48 | 0.51 |'
- en: '| Entity | 87 | 43 | 44 | 0.51 |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '| 实体 | 87 | 43 | 44 | 0.51 |'
- en: '| Incorrect Fact | 68 | 29 | 38 | 0.56 |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '| 错误事实 | 68 | 29 | 38 | 0.56 |'
- en: '| Number Errors | 74 | 30 | 44 | 0.59 |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '| 数字错误 | 74 | 30 | 44 | 0.59 |'
- en: '| Opposite Fact | 91 | 48 | 42 | 0.46 |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '| 相反事实 | 91 | 48 | 42 | 0.46 |'
- en: '| Remove Fact | 69 | 25 | 44 | 0.64 |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| 删除事实 | 69 | 25 | 44 | 0.64 |'
- en: '| Total | 483 | 220 | 260 | 0.54 |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 483 | 220 | 260 | 0.54 |'
- en: '| IF | Assumptions | 81 | 12 | 69 | 0.85 |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '| IF | 假设 | 81 | 12 | 69 | 0.85 |'
- en: '| Do Less | 100 | 57 | 43 | 0.43 |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
  zh: '| 做更少 | 100 | 57 | 43 | 0.43 |'
- en: '| Do More | 50 | 31 | 19 | 0.38 |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
  zh: '| 做更多 | 50 | 31 | 19 | 0.38 |'
- en: '| Ignore Format | 99 | 41 | 57 | 0.58 |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
  zh: '| 忽略格式 | 99 | 41 | 57 | 0.58 |'
- en: '| Sequence Errors | 49 | 20 | 29 | 0.59 |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
  zh: '| 顺序错误 | 49 | 20 | 29 | 0.59 |'
- en: '| Total | 379 | 161 | 217 | 0.57 |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 379 | 161 | 217 | 0.57 |'
- en: '| R | Calculations | 149 | 112 | 34 | 0.23 |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '| R | 计算 | 149 | 112 | 34 | 0.23 |'
- en: '| Copying Numbers | 83 | 69 | 12 | 0.14 |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
  zh: '| 复制数字 | 83 | 69 | 12 | 0.14 |'
- en: '| Final Errors | 97 | 53 | 43 | 0.44 |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '| 最终错误 | 97 | 53 | 43 | 0.44 |'
- en: '| Incorrect Units | 77 | 60 | 16 | 0.21 |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
  zh: '| 错误单位 | 77 | 60 | 16 | 0.21 |'
- en: '| Wrong Formula | 88 | 66 | 19 | 0.22 |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
  zh: '| 错误公式 | 88 | 66 | 19 | 0.22 |'
- en: '| Total | 494 | 360 | 124 | 0.25 |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 494 | 360 | 124 | 0.25 |'
- en: 'Table 7: Results from evaluating FBI using Vanilla evaluator. An error is said
    to be detected if the evaluator penalizes the score of the perturbed answer.'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '表 7: 使用 Vanilla 评估器评估 FBI 的结果。如果评估器对扰动答案的分数进行惩罚，则认为错误已被检测到。'
- en: '|  | Perturbation Type |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
  zh: '|  | 扰动类型 |'
- en: '&#124; Total &#124;'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 总计 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Detected &#124;'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 检测到 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Undetected &#124;'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 未检测到 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; % Undetected &#124;'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; % 未检测到 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| LF | Coherence | 91 | 47 | 44 | 0.48 |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '| LF | 连贯性 | 91 | 47 | 44 | 0.48 |'
- en: '| Comprehensiveness | 90 | 2 | 88 | 0.98 |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
  zh: '| 综合性 | 90 | 2 | 88 | 0.98 |'
- en: '| Consistency | 84 | 11 | 73 | 0.87 |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '| 一致性 | 84 | 11 | 73 | 0.87 |'
- en: '| Grammar | 92 | 15 | 77 | 0.84 |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '| 语法 | 92 | 15 | 77 | 0.84 |'
- en: '| Chronology | 71 | 0 | 71 | 1.00 |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '| 年代顺序 | 71 | 0 | 71 | 1.00 |'
- en: '| Spelling | 100 | 4 | 96 | 0.96 |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| 拼写 | 100 | 4 | 96 | 0.96 |'
- en: '| Total | 528 | 79 | 449 | 0.85 |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 528 | 79 | 449 | 0.85 |'
- en: '| F | Contextual | 94 | 34 | 60 | 0.64 |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '| F | 上下文 | 94 | 34 | 60 | 0.64 |'
- en: '| Entity | 87 | 29 | 58 | 0.67 |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '| 实体 | 87 | 29 | 58 | 0.67 |'
- en: '| Incorrect Fact | 68 | 18 | 50 | 0.74 |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '| 错误事实 | 68 | 18 | 50 | 0.74 |'
- en: '| Number Errors | 74 | 17 | 57 | 0.77 |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| 数字错误 | 74 | 17 | 57 | 0.77 |'
- en: '| Opposite Fact | 91 | 32 | 59 | 0.65 |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| 相反事实 | 91 | 32 | 59 | 0.65 |'
- en: '| Remove Fact | 69 | 1 | 68 | 0.99 |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| 移除事实 | 69 | 1 | 68 | 0.99 |'
- en: '| Total | 483 | 131 | 352 | 0.73 |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 483 | 131 | 352 | 0.73 |'
- en: '| IF | Assumptions | 81 | 1 | 80 | 0.99 |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| IF | 假设 | 81 | 1 | 80 | 0.99 |'
- en: '| Do Less | 100 | 8 | 92 | 0.92 |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '| 少做 | 100 | 8 | 92 | 0.92 |'
- en: '| Do More | 50 | 39 | 11 | 0.22 |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
  zh: '| 多做 | 50 | 39 | 11 | 0.22 |'
- en: '| Ignore Format | 99 | 26 | 73 | 0.74 |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
  zh: '| 忽略格式 | 99 | 26 | 73 | 0.74 |'
- en: '| Sequence Errors | 49 | 0 | 49 | 1.00 |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '| 序列错误 | 49 | 0 | 49 | 1.00 |'
- en: '| Total | 379 | 74 | 305 | 0.80 |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 379 | 74 | 305 | 0.80 |'
- en: '| R | Calculations | 149 | 102 | 47 | 0.32 |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
  zh: '| R | 计算 | 149 | 102 | 47 | 0.32 |'
- en: '| Copying Numbers | 83 | 64 | 19 | 0.23 |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '| 复制数字 | 83 | 64 | 19 | 0.23 |'
- en: '| Final Errors | 97 | 49 | 48 | 0.49 |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '| 最终错误 | 97 | 49 | 48 | 0.49 |'
- en: '| Incorrect Units | 77 | 56 | 21 | 0.27 |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
  zh: '| 单位错误 | 77 | 56 | 21 | 0.27 |'
- en: '| Wrong Formula | 88 | 61 | 27 | 0.31 |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
  zh: '| 错误公式 | 88 | 61 | 27 | 0.31 |'
- en: '| Total | 494 | 332 | 162 | 0.33 |'
  id: totrans-375
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 494 | 332 | 162 | 0.33 |'
- en: 'Table 8: Results from evaluating FBI using Rubrics evaluator. An error is said
    to be detected if the evaluator penalizes the score of the perturbed answer.'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8：使用 Rubrics 评估器评估 FBI 的结果。如果评估器对扰动答案的分数进行惩罚，则视为检测到错误。
- en: '|  | Perturbation Type |'
  id: totrans-377
  prefs: []
  type: TYPE_TB
  zh: '|  | 扰动类型 |'
- en: '&#124; Total &#124;'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 总计 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Detected &#124;'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 检测到 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Undetected &#124;'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 未检测到 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; % Undetected &#124;'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; % 未检测到 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| LF | Coherence | 91 | 58 | 33 | 0.36 |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
  zh: '| LF | 连贯性 | 91 | 58 | 33 | 0.36 |'
- en: '| Comprehensiveness | 90 | 1 | 89 | 0.99 |'
  id: totrans-391
  prefs: []
  type: TYPE_TB
  zh: '| 综合性 | 90 | 1 | 89 | 0.99 |'
- en: '| Consistency | 84 | 8 | 76 | 0.90 |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
  zh: '| 一致性 | 84 | 8 | 76 | 0.90 |'
- en: '| Grammar | 92 | 17 | 75 | 0.82 |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '| 语法 | 92 | 17 | 75 | 0.82 |'
- en: '| Chronology | 71 | 0 | 71 | 1.00 |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
  zh: '| 年代顺序 | 71 | 0 | 71 | 1.00 |'
- en: '| Spelling | 100 | 6 | 94 | 0.94 |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '| 拼写 | 100 | 6 | 94 | 0.94 |'
- en: '| Total | 528 | 90 | 438 | 0.83 |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 528 | 90 | 438 | 0.83 |'
- en: '| F | Contextual | 94 | 29 | 65 | 0.69 |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
  zh: '| F | 语境 | 94 | 29 | 65 | 0.69 |'
- en: '| Entity | 87 | 30 | 57 | 0.66 |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
  zh: '| 实体 | 87 | 30 | 57 | 0.66 |'
- en: '| Incorrect Fact | 68 | 17 | 51 | 0.75 |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '| 错误事实 | 68 | 17 | 51 | 0.75 |'
- en: '| Number Errors | 74 | 18 | 56 | 0.76 |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
  zh: '| 数字错误 | 74 | 18 | 56 | 0.76 |'
- en: '| Opposite Fact | 91 | 32 | 59 | 0.65 |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
  zh: '| 相反事实 | 91 | 32 | 59 | 0.65 |'
- en: '| Remove Fact | 69 | 1 | 68 | 0.99 |'
  id: totrans-402
  prefs: []
  type: TYPE_TB
  zh: '| 移除事实 | 69 | 1 | 68 | 0.99 |'
- en: '| Total | 483 | 127 | 356 | 0.74 |'
  id: totrans-403
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 483 | 127 | 356 | 0.74 |'
- en: '| IF | Assumptions | 81 | 5 | 76 | 0.94 |'
  id: totrans-404
  prefs: []
  type: TYPE_TB
  zh: '| IF | 假设 | 81 | 5 | 76 | 0.94 |'
- en: '| Do Less | 100 | 20 | 80 | 0.80 |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
  zh: '| 少做 | 100 | 20 | 80 | 0.80 |'
- en: '| Do More | 50 | 40 | 10 | 0.20 |'
  id: totrans-406
  prefs: []
  type: TYPE_TB
  zh: '| 多做 | 50 | 40 | 10 | 0.20 |'
- en: '| Ignore Format | 99 | 25 | 74 | 0.75 |'
  id: totrans-407
  prefs: []
  type: TYPE_TB
  zh: '| 忽略格式 | 99 | 25 | 74 | 0.75 |'
- en: '| Sequence Errors | 49 | 5 | 44 | 0.90 |'
  id: totrans-408
  prefs: []
  type: TYPE_TB
  zh: '| 序列错误 | 49 | 5 | 44 | 0.90 |'
- en: '| Total | 379 | 95 | 284 | 0.75 |'
  id: totrans-409
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 379 | 95 | 284 | 0.75 |'
- en: '| R | Calculations | 149 | 100 | 49 | 0.53 |'
  id: totrans-410
  prefs: []
  type: TYPE_TB
  zh: '| R | 计算 | 149 | 100 | 49 | 0.53 |'
- en: '| Copying Numbers | 83 | 57 | 26 | 0.31 |'
  id: totrans-411
  prefs: []
  type: TYPE_TB
  zh: '| 复制数字 | 83 | 57 | 26 | 0.31 |'
- en: '| Final Errors | 97 | 46 | 51 | 0.53 |'
  id: totrans-412
  prefs: []
  type: TYPE_TB
  zh: '| 最终错误 | 97 | 46 | 51 | 0.53 |'
- en: '| Incorrect Units | 77 | 42 | 35 | 0.45 |'
  id: totrans-413
  prefs: []
  type: TYPE_TB
  zh: '| 单位错误 | 77 | 42 | 35 | 0.45 |'
- en: '| Wrong Formula | 88 | 63 | 25 | 0.28 |'
  id: totrans-414
  prefs: []
  type: TYPE_TB
  zh: '| 错误公式 | 88 | 63 | 25 | 0.28 |'
- en: '| Total | 494 | 308 | 186 | 0.43 |'
  id: totrans-415
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 494 | 308 | 186 | 0.43 |'
- en: 'Table 9: Results from evaluating FBI using Axis evaluator. An error is said
    to be detected if the evaluator penalizes the score of the perturbed answer.'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 表 9：使用 Axis 评估器评估 FBI 的结果。如果评估器对扰动答案的分数进行惩罚，则视为检测到错误。
- en: '|  | Perturbation Type |'
  id: totrans-417
  prefs: []
  type: TYPE_TB
  zh: '|  | 扰动类型 |'
- en: '&#124; Total &#124;'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 总计 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Detected &#124;'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 检测到 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Undetected &#124;'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 未检测到 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; % Undetected &#124;'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; % 未检测到 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| LF | Coherence | 91 | 45 | 46 | 0.51 |'
  id: totrans-430
  prefs: []
  type: TYPE_TB
  zh: '| LF | 连贯性 | 91 | 45 | 46 | 0.51 |'
- en: '| Comprehensiveness | 90 | 0 | 90 | 1.00 |'
  id: totrans-431
  prefs: []
  type: TYPE_TB
  zh: '| 综合性 | 90 | 0 | 90 | 1.00 |'
- en: '| Consistency | 84 | 6 | 78 | 0.93 |'
  id: totrans-432
  prefs: []
  type: TYPE_TB
  zh: '| 一致性 | 84 | 6 | 78 | 0.93 |'
- en: '| Grammar | 92 | 16 | 76 | 0.83 |'
  id: totrans-433
  prefs: []
  type: TYPE_TB
  zh: '| 语法 | 92 | 16 | 76 | 0.83 |'
- en: '| Chronology | 71 | 0 | 71 | 1.00 |'
  id: totrans-434
  prefs: []
  type: TYPE_TB
  zh: '| 年代顺序 | 71 | 0 | 71 | 1.00 |'
- en: '| Spelling | 100 | 7 | 93 | 0.93 |'
  id: totrans-435
  prefs: []
  type: TYPE_TB
  zh: '| 拼写 | 100 | 7 | 93 | 0.93 |'
- en: '| Total | 528 | 74 | 454 | 0.86 |'
  id: totrans-436
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 528 | 74 | 454 | 0.86 |'
- en: '| F | Contextual | 94 | 28 | 66 | 0.70 |'
  id: totrans-437
  prefs: []
  type: TYPE_TB
  zh: '| F | 语境 | 94 | 28 | 66 | 0.70 |'
- en: '| Entity | 87 | 27 | 60 | 0.69 |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
  zh: '| 实体 | 87 | 27 | 60 | 0.69 |'
- en: '| Incorrect Fact | 68 | 15 | 53 | 0.78 |'
  id: totrans-439
  prefs: []
  type: TYPE_TB
  zh: '| 错误事实 | 68 | 15 | 53 | 0.78 |'
- en: '| Number Errors | 74 | 15 | 59 | 0.80 |'
  id: totrans-440
  prefs: []
  type: TYPE_TB
  zh: '| 数字错误 | 74 | 15 | 59 | 0.80 |'
- en: '| Opposite Fact | 91 | 28 | 63 | 0.69 |'
  id: totrans-441
  prefs: []
  type: TYPE_TB
  zh: '| 相反事实 | 91 | 28 | 63 | 0.69 |'
- en: '| Remove Fact | 69 | 1 | 68 | 0.99 |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
  zh: '| 移除事实 | 69 | 1 | 68 | 0.99 |'
- en: '| Total | 483 | 114 | 369 | 0.76 |'
  id: totrans-443
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 483 | 114 | 369 | 0.76 |'
- en: '| IF | Assumptions | 81 | 2 | 79 | 0.98 |'
  id: totrans-444
  prefs: []
  type: TYPE_TB
  zh: '| IF | 假设 | 81 | 2 | 79 | 0.98 |'
- en: '| Do Less | 100 | 17 | 83 | 0.83 |'
  id: totrans-445
  prefs: []
  type: TYPE_TB
  zh: '| 少做 | 100 | 17 | 83 | 0.83 |'
- en: '| Do More | 50 | 39 | 11 | 0.22 |'
  id: totrans-446
  prefs: []
  type: TYPE_TB
  zh: '| 多做 | 50 | 39 | 11 | 0.22 |'
- en: '| Ignore Format | 99 | 24 | 75 | 0.76 |'
  id: totrans-447
  prefs: []
  type: TYPE_TB
  zh: '| 忽略格式 | 99 | 24 | 75 | 0.76 |'
- en: '| Sequence Errors | 49 | 4 | 45 | 0.92 |'
  id: totrans-448
  prefs: []
  type: TYPE_TB
  zh: '| 序列错误 | 49 | 4 | 45 | 0.92 |'
- en: '| Total | 379 | 86 | 293 | 0.77 |'
  id: totrans-449
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 379 | 86 | 293 | 0.77 |'
- en: '| R | Calculations | 149 | 97 | 52 | 0.35 |'
  id: totrans-450
  prefs: []
  type: TYPE_TB
  zh: '| R | 计算 | 149 | 97 | 52 | 0.35 |'
- en: '| Copying Numbers | 83 | 58 | 25 | 0.30 |'
  id: totrans-451
  prefs: []
  type: TYPE_TB
  zh: '| 复制数字 | 83 | 58 | 25 | 0.30 |'
- en: '| Final Errors | 97 | 48 | 49 | 0.51 |'
  id: totrans-452
  prefs: []
  type: TYPE_TB
  zh: '| 最终错误 | 97 | 48 | 49 | 0.51 |'
- en: '| Incorrect Units | 77 | 44 | 33 | 0.43 |'
  id: totrans-453
  prefs: []
  type: TYPE_TB
  zh: '| 错误单位 | 77 | 44 | 33 | 0.43 |'
- en: '| Wrong Formula | 88 | 63 | 25 | 0.37 |'
  id: totrans-454
  prefs: []
  type: TYPE_TB
  zh: '| 错误公式 | 88 | 63 | 25 | 0.37 |'
- en: '| Total | 494 | 310 | 184 | 0.37 |'
  id: totrans-455
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 494 | 310 | 184 | 0.37 |'
- en: 'Table 10: Results from evaluating FBI using Axis+Rubrics evaluator. An error
    is said to be detected if the evaluator penalizes the score of the perturbed answer.'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 表 10：使用 Axis+Rubrics 评估器评估 FBI 的结果。如果评估器对扰动答案的分数进行惩罚，则认为检测到了错误。
- en: '|  | Perturbation Type |'
  id: totrans-457
  prefs: []
  type: TYPE_TB
  zh: '|  | 扰动类型 |'
- en: '&#124; Total &#124;'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 总计 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '| G | P | Both ✓ | Both ✗ | $\neq$ |'
  id: totrans-460
  prefs: []
  type: TYPE_TB
  zh: '| G | P | Both ✓ | Both ✗ | $\neq$ |'
- en: '&#124; % Undetected &#124;'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; % 未检测到 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| LF | Coherence | 91 | 73 | 0 | 11 | 0 | 7 | 0.20 |'
  id: totrans-464
  prefs: []
  type: TYPE_TB
  zh: '| LF | 连贯性 | 91 | 73 | 0 | 11 | 0 | 7 | 0.20 |'
- en: '| Comprehensiveness | 90 | 11 | 0 | 57 | 0 | 22 | 0.88 |'
  id: totrans-465
  prefs: []
  type: TYPE_TB
  zh: '| 完整性 | 90 | 11 | 0 | 57 | 0 | 22 | 0.88 |'
- en: '| Consistency | 84 | 12 | 0 | 59 | 0 | 13 | 0.86 |'
  id: totrans-466
  prefs: []
  type: TYPE_TB
  zh: '| 一致性 | 84 | 12 | 0 | 59 | 0 | 13 | 0.86 |'
- en: '| Grammar | 92 | 32 | 0 | 46 | 0 | 14 | 0.65 |'
  id: totrans-467
  prefs: []
  type: TYPE_TB
  zh: '| 语法 | 92 | 32 | 0 | 46 | 0 | 14 | 0.65 |'
- en: '| Chronology | 71 | 1 | 0 | 68 | 0 | 2 | 0.99 |'
  id: totrans-468
  prefs: []
  type: TYPE_TB
  zh: '| 时间顺序 | 71 | 1 | 0 | 68 | 0 | 2 | 0.99 |'
- en: '| Spelling | 100 | 12 | 0 | 77 | 0 | 11 | 0.88 |'
  id: totrans-469
  prefs: []
  type: TYPE_TB
  zh: '| 拼写 | 100 | 12 | 0 | 77 | 0 | 11 | 0.88 |'
- en: '| Total | 528 | 141 | 0 | 318 | 0 | 69 | 0.73 |'
  id: totrans-470
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 528 | 141 | 0 | 318 | 0 | 69 | 0.73 |'
- en: '| F | Contextual | 94 | 55 | 0 | 12 | 0 | 27 | 0.41 |'
  id: totrans-471
  prefs: []
  type: TYPE_TB
  zh: '| F | 上下文 | 94 | 55 | 0 | 12 | 0 | 27 | 0.41 |'
- en: '| Entity | 87 | 51 | 0 | 16 | 0 | 20 | 0.41 |'
  id: totrans-472
  prefs: []
  type: TYPE_TB
  zh: '| 实体 | 87 | 51 | 0 | 16 | 0 | 20 | 0.41 |'
- en: '| Incorrect Fact | 68 | 32 | 0 | 12 | 0 | 24 | 0.53 |'
  id: totrans-473
  prefs: []
  type: TYPE_TB
  zh: '| 错误事实 | 68 | 32 | 0 | 12 | 0 | 24 | 0.53 |'
- en: '| Number Errors | 74 | 29 | 1 | 22 | 0 | 22 | 0.61 |'
  id: totrans-474
  prefs: []
  type: TYPE_TB
  zh: '| 数字错误 | 74 | 29 | 1 | 22 | 0 | 22 | 0.61 |'
- en: '| Opposite Fact | 91 | 55 | 0 | 12 | 0 | 24 | 0.40 |'
  id: totrans-475
  prefs: []
  type: TYPE_TB
  zh: '| 相反事实 | 91 | 55 | 0 | 12 | 0 | 24 | 0.40 |'
- en: '| Remove Fact | 69 | 12 | 0 | 42 | 0 | 15 | 0.83 |'
  id: totrans-476
  prefs: []
  type: TYPE_TB
  zh: '| 删除事实 | 69 | 12 | 0 | 42 | 0 | 15 | 0.83 |'
- en: '| Total | 483 | 234 | 1 | 116 | 0 | 132 | 0.52 |'
  id: totrans-477
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 483 | 234 | 1 | 116 | 0 | 132 | 0.52 |'
- en: '| IF | Assumptions | 81 | 6 | 25 | 34 | 0 | 16 | 0.93 |'
  id: totrans-478
  prefs: []
  type: TYPE_TB
  zh: '| IF | 假设 | 81 | 6 | 25 | 34 | 0 | 16 | 0.93 |'
- en: '| Do Less | 100 | 40 | 0 | 22 | 0 | 38 | 0.60 |'
  id: totrans-479
  prefs: []
  type: TYPE_TB
  zh: '| 少做 | 100 | 40 | 0 | 22 | 0 | 38 | 0.60 |'
- en: '| Do More | 50 | 7 | 1 | 17 | 0 | 25 | 0.86 |'
  id: totrans-480
  prefs: []
  type: TYPE_TB
  zh: '| 多做 | 50 | 7 | 1 | 17 | 0 | 25 | 0.86 |'
- en: '| Ignore Format | 99 | 13 | 0 | 56 | 0 | 30 | 0.87 |'
  id: totrans-481
  prefs: []
  type: TYPE_TB
  zh: '| 忽略格式 | 99 | 13 | 0 | 56 | 0 | 30 | 0.87 |'
- en: '| Sequence Errors | 49 | 0 | 0 | 49 | 0 | 0 | 1.00 |'
  id: totrans-482
  prefs: []
  type: TYPE_TB
  zh: '| 序列错误 | 49 | 0 | 0 | 49 | 0 | 0 | 1.00 |'
- en: '| Total | 379 | 66 | 26 | 178 | 0 | 109 | 0.83 |'
  id: totrans-483
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 379 | 66 | 26 | 178 | 0 | 109 | 0.83 |'
- en: '| R | Calculations | 149 | 96 | 1 | 18 | 1 | 32 | 0.35 |'
  id: totrans-484
  prefs: []
  type: TYPE_TB
  zh: '| R | 计算 | 149 | 96 | 1 | 18 | 1 | 32 | 0.35 |'
- en: '| Copying Numbers | 83 | 58 | 0 | 7 | 1 | 17 | 0.30 |'
  id: totrans-485
  prefs: []
  type: TYPE_TB
  zh: '| 复制数字 | 83 | 58 | 0 | 7 | 1 | 17 | 0.30 |'
- en: '| Final Errors | 97 | 58 | 1 | 6 | 0 | 32 | 0.40 |'
  id: totrans-486
  prefs: []
  type: TYPE_TB
  zh: '| 最终错误 | 97 | 58 | 1 | 6 | 0 | 32 | 0.40 |'
- en: '| Incorrect Units | 77 | 48 | 0 | 17 | 1 | 11 | 0.38 |'
  id: totrans-487
  prefs: []
  type: TYPE_TB
  zh: '| 错误单位 | 77 | 48 | 0 | 17 | 1 | 11 | 0.38 |'
- en: '| Wrong Formula | 88 | 56 | 1 | 15 | 3 | 13 | 0.36 |'
  id: totrans-488
  prefs: []
  type: TYPE_TB
  zh: '| 错误公式 | 88 | 56 | 1 | 15 | 3 | 13 | 0.36 |'
- en: '| Total | 494 | 316 | 3 | 63 | 6 | 105 | 0.36 |'
  id: totrans-489
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 494 | 316 | 3 | 63 | 6 | 105 | 0.36 |'
- en: 'Table 11: Results from evaluating FBI  using the Pairwise$*$ evaluator. An
    error is said to be detected if the evaluator chooses the Gold Answer. G indicates
    the number of times the evaluator has chosen the Gold Answer, P for the Perturbed
    Answer, Both ✓ when both answers are correct, Both ✗ when both are incorrect,
    and $\neq$ for verdict inconsistencies.'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 表 11：使用 Pairwise$*$ 评估器评估 FBI 的结果。如果评估器选择了黄金答案，则认为检测到了错误。G 表示评估器选择黄金答案的次数，P
    表示扰动答案，Both ✓ 表示两个答案都正确，Both ✗ 表示两个答案都错误，$\neq$ 表示判决不一致。
- en: '|  | Perturbation Type |'
  id: totrans-491
  prefs: []
  type: TYPE_TB
  zh: '|  | 扰动类型 |'
- en: '&#124; Total &#124;'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 总计 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '| G | P | Both ✓ | Both ✗ | $\neq$ |'
  id: totrans-494
  prefs: []
  type: TYPE_TB
  zh: '| G | P | Both ✓ | Both ✗ | $\neq$ |'
- en: '&#124; % Undetected &#124;'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; % 未检测到 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| LF | Coherence | 91 | 69 | 0 | 2 | 0 | 18 | 0.22 |'
  id: totrans-498
  prefs: []
  type: TYPE_TB
  zh: '| LF | 连贯性 | 91 | 69 | 0 | 2 | 0 | 18 | 0.22 |'
- en: '| Comprehensiveness | 90 | 25 | 0 | 18 | 0 | 47 | 0.72 |'
  id: totrans-499
  prefs: []
  type: TYPE_TB
  zh: '| 完整性 | 90 | 25 | 0 | 18 | 0 | 47 | 0.72 |'
- en: '| Consistency | 84 | 10 | 0 | 40 | 0 | 33 | 0.88 |'
  id: totrans-500
  prefs: []
  type: TYPE_TB
  zh: '| 一致性 | 84 | 10 | 0 | 40 | 0 | 33 | 0.88 |'
- en: '| Grammar | 92 | 12 | 0 | 24 | 0 | 54 | 0.87 |'
  id: totrans-501
  prefs: []
  type: TYPE_TB
  zh: '| 语法 | 92 | 12 | 0 | 24 | 0 | 54 | 0.87 |'
- en: '| Chronology | 71 | 0 | 0 | 50 | 0 | 19 | 1.00 |'
  id: totrans-502
  prefs: []
  type: TYPE_TB
  zh: '| 时间顺序 | 71 | 0 | 0 | 50 | 0 | 19 | 1.00 |'
- en: '| Spelling | 100 | 5 | 0 | 56 | 0 | 38 | 0.95 |'
  id: totrans-503
  prefs: []
  type: TYPE_TB
  zh: '| 拼写 | 100 | 5 | 0 | 56 | 0 | 38 | 0.95 |'
- en: '| Total | 528 | 121 | 0 | 190 | 0 | 209 | 0.77 |'
  id: totrans-504
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 528 | 121 | 0 | 190 | 0 | 209 | 0.77 |'
- en: '| F | Contextual | 94 | 76 | 0 | 5 | 0 | 13 | 0.19 |'
  id: totrans-505
  prefs: []
  type: TYPE_TB
  zh: '| F | 上下文 | 94 | 76 | 0 | 5 | 0 | 13 | 0.19 |'
- en: '| Entity | 87 | 44 | 0 | 11 | 0 | 28 | 0.47 |'
  id: totrans-506
  prefs: []
  type: TYPE_TB
  zh: '| 实体 | 87 | 44 | 0 | 11 | 0 | 28 | 0.47 |'
- en: '| Incorrect Fact | 68 | 36 | 0 | 3 | 0 | 27 | 0.45 |'
  id: totrans-507
  prefs: []
  type: TYPE_TB
  zh: '| 错误事实 | 68 | 36 | 0 | 3 | 0 | 27 | 0.45 |'
- en: '| Number Errors | 74 | 34 | 0 | 9 | 0 | 28 | 0.52 |'
  id: totrans-508
  prefs: []
  type: TYPE_TB
  zh: '| 数量错误 | 74 | 34 | 0 | 9 | 0 | 28 | 0.52 |'
- en: '| Opposite Fact | 91 | 39 | 0 | 3 | 0 | 48 | 0.57 |'
  id: totrans-509
  prefs: []
  type: TYPE_TB
  zh: '| 相反事实 | 91 | 39 | 0 | 3 | 0 | 48 | 0.57 |'
- en: '| Remove Fact | 69 | 24 | 0 | 16 | 0 | 28 | 0.65 |'
  id: totrans-510
  prefs: []
  type: TYPE_TB
  zh: '| 删除事实 | 69 | 24 | 0 | 16 | 0 | 28 | 0.65 |'
- en: '| Total | 483 | 253 | 0 | 47 | 0 | 172 | 0.46 |'
  id: totrans-511
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 483 | 253 | 0 | 47 | 0 | 172 | 0.46 |'
- en: '| IF | Assumptions | 81 | 4 | 43 | 3 | 0 | 31 | 0.95 |'
  id: totrans-512
  prefs: []
  type: TYPE_TB
  zh: '| IF | 假设 | 81 | 4 | 43 | 3 | 0 | 31 | 0.95 |'
- en: '| Do Less | 100 | 58 | 0 | 11 | 0 | 30 | 0.41 |'
  id: totrans-513
  prefs: []
  type: TYPE_TB
  zh: '| 减少 | 100 | 58 | 0 | 11 | 0 | 30 | 0.41 |'
- en: '| Do More | 50 | 24 | 2 | 0 | 0 | 24 | 0.52 |'
  id: totrans-514
  prefs: []
  type: TYPE_TB
  zh: '| 增加 | 50 | 24 | 2 | 0 | 0 | 24 | 0.52 |'
- en: '| Ignore Format | 99 | 35 | 0 | 27 | 0 | 23 | 0.59 |'
  id: totrans-515
  prefs: []
  type: TYPE_TB
  zh: '| 忽略格式 | 99 | 35 | 0 | 27 | 0 | 23 | 0.59 |'
- en: '| Sequence Errors | 49 | 0 | 0 | 23 | 0 | 26 | 1.00 |'
  id: totrans-516
  prefs: []
  type: TYPE_TB
  zh: '| 顺序错误 | 49 | 0 | 0 | 23 | 0 | 26 | 1.00 |'
- en: '| Total | 379 | 121 | 45 | 64 | 0 | 134 | 0.67 |'
  id: totrans-517
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 379 | 121 | 45 | 64 | 0 | 134 | 0.67 |'
- en: '| R | Calculations | 149 | 77 | 0 | 6 | 1 | 38 | 0.37 |'
  id: totrans-518
  prefs: []
  type: TYPE_TB
  zh: '| R | 计算 | 149 | 77 | 0 | 6 | 1 | 38 | 0.37 |'
- en: '| Copying Numbers | 83 | 40 | 0 | 1 | 1 | 18 | 0.33 |'
  id: totrans-519
  prefs: []
  type: TYPE_TB
  zh: '| 复制数字 | 83 | 40 | 0 | 1 | 1 | 18 | 0.33 |'
- en: '| Final Errors | 97 | 59 | 0 | 0 | 0 | 18 | 0.23 |'
  id: totrans-520
  prefs: []
  type: TYPE_TB
  zh: '| 最终错误 | 97 | 59 | 0 | 0 | 0 | 18 | 0.23 |'
- en: '| Incorrect Units | 77 | 38 | 0 | 7 | 0 | 20 | 0.42 |'
  id: totrans-521
  prefs: []
  type: TYPE_TB
  zh: '| 错误单位 | 77 | 38 | 0 | 7 | 0 | 20 | 0.42 |'
- en: '| Wrong Formula | 88 | 39 | 0 | 4 | 1 | 23 | 0.42 |'
  id: totrans-522
  prefs: []
  type: TYPE_TB
  zh: '| 错误公式 | 88 | 39 | 0 | 4 | 1 | 23 | 0.42 |'
- en: '| Total | 494 | 253 | 0 | 18 | 3 | 117 | 0.35 |'
  id: totrans-523
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 494 | 253 | 0 | 18 | 3 | 117 | 0.35 |'
- en: 'Table 12: Results from evaluating FBI  using the Pairwise evaluator. An error
    is said to be detected if the evaluator chooses the Gold Answer. G indicates the
    number of times the evaluator has chosen the Gold Answer, P for the Perturbed
    Answer, Both ✓ when both answers are correct, Both ✗ when both are incorrect,
    and $\neq$ for verdict inconsistencies.'
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: '表 12: 使用 Pairwise 评估器评估 FBI 的结果。如果评估器选择了金答案，则认为检测到了错误。G 表示评估器选择金答案的次数，P 表示扰动答案，Both
    ✓ 表示两个答案都正确，Both ✗ 表示两个答案都错误，$\neq$ 表示裁决不一致。'
- en: '|  | Perturbation Type |'
  id: totrans-525
  prefs: []
  type: TYPE_TB
  zh: '|  | 扰动类型 |'
- en: '&#124; Total &#124;'
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 总计 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '| G | P | Both ✓ | Both ✗ | $\neq$ |'
  id: totrans-528
  prefs: []
  type: TYPE_TB
  zh: '| G | P | Both ✓ | Both ✗ | $\neq$ |'
- en: '&#124; % Undetected &#124;'
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 未检测到的百分比 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| LF | Coherence | 91 | 82 | 0 | 2 | 0 | 7 | 0.10 |'
  id: totrans-532
  prefs: []
  type: TYPE_TB
  zh: '| LF | 连贯性 | 91 | 82 | 0 | 2 | 0 | 7 | 0.10 |'
- en: '| Comprehensiveness | 90 | 28 | 0 | 25 | 0 | 37 | 0.69 |'
  id: totrans-533
  prefs: []
  type: TYPE_TB
  zh: '| 综合性 | 90 | 28 | 0 | 25 | 0 | 37 | 0.69 |'
- en: '| Consistency | 84 | 10 | 0 | 46 | 0 | 28 | 0.88 |'
  id: totrans-534
  prefs: []
  type: TYPE_TB
  zh: '| 一致性 | 84 | 10 | 0 | 46 | 0 | 28 | 0.88 |'
- en: '| Grammar | 92 | 8 | 0 | 24 | 0 | 60 | 0.91 |'
  id: totrans-535
  prefs: []
  type: TYPE_TB
  zh: '| 语法 | 92 | 8 | 0 | 24 | 0 | 60 | 0.91 |'
- en: '| Chronology | 71 | 0 | 0 | 51 | 0 | 20 | 1.00 |'
  id: totrans-536
  prefs: []
  type: TYPE_TB
  zh: '| 年代 | 71 | 0 | 0 | 51 | 0 | 20 | 1.00 |'
- en: '| Spelling | 100 | 4 | 0 | 48 | 0 | 48 | 0.96 |'
  id: totrans-537
  prefs: []
  type: TYPE_TB
  zh: '| 拼写 | 100 | 4 | 0 | 48 | 0 | 48 | 0.96 |'
- en: '| Total | 528 | 132 | 0 | 196 | 0 | 200 | 0.75 |'
  id: totrans-538
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 528 | 132 | 0 | 196 | 0 | 200 | 0.75 |'
- en: '| F | Contextual | 94 | 36 | 0 | 9 | 0 | 48 | 0.61 |'
  id: totrans-539
  prefs: []
  type: TYPE_TB
  zh: '| F | 上下文 | 94 | 36 | 0 | 9 | 0 | 48 | 0.61 |'
- en: '| Entity | 87 | 37 | 0 | 14 | 0 | 34 | 0.56 |'
  id: totrans-540
  prefs: []
  type: TYPE_TB
  zh: '| 实体 | 87 | 37 | 0 | 14 | 0 | 34 | 0.56 |'
- en: '| Incorrect Fact | 68 | 27 | 0 | 4 | 0 | 36 | 0.60 |'
  id: totrans-541
  prefs: []
  type: TYPE_TB
  zh: '| 错误事实 | 68 | 27 | 0 | 4 | 0 | 36 | 0.60 |'
- en: '| Number Errors | 74 | 27 | 0 | 13 | 0 | 32 | 0.63 |'
  id: totrans-542
  prefs: []
  type: TYPE_TB
  zh: '| 数量错误 | 74 | 27 | 0 | 13 | 0 | 32 | 0.63 |'
- en: '| Opposite Fact | 91 | 32 | 0 | 6 | 0 | 53 | 0.65 |'
  id: totrans-543
  prefs: []
  type: TYPE_TB
  zh: '| 相反事实 | 91 | 32 | 0 | 6 | 0 | 53 | 0.65 |'
- en: '| Remove Fact | 69 | 19 | 0 | 18 | 0 | 32 | 0.72 |'
  id: totrans-544
  prefs: []
  type: TYPE_TB
  zh: '| 删除事实 | 69 | 19 | 0 | 18 | 0 | 32 | 0.72 |'
- en: '| Total | 483 | 178 | 0 | 64 | 0 | 235 | 0.63 |'
  id: totrans-545
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 483 | 178 | 0 | 64 | 0 | 235 | 0.63 |'
- en: '| IF | Assumptions | 81 | 3 | 57 | 5 | 0 | 16 | 0.96 |'
  id: totrans-546
  prefs: []
  type: TYPE_TB
  zh: '| IF | 假设 | 81 | 3 | 57 | 5 | 0 | 16 | 0.96 |'
- en: '| Do Less | 100 | 60 | 2 | 15 | 0 | 23 | 0.40 |'
  id: totrans-547
  prefs: []
  type: TYPE_TB
  zh: '| 减少 | 100 | 60 | 2 | 15 | 0 | 23 | 0.40 |'
- en: '| Do More | 50 | 25 | 3 | 0 | 0 | 22 | 0.50 |'
  id: totrans-548
  prefs: []
  type: TYPE_TB
  zh: '| 增加 | 50 | 25 | 3 | 0 | 0 | 22 | 0.50 |'
- en: '| Ignore Format | 99 | 33 | 0 | 29 | 0 | 37 | 0.67 |'
  id: totrans-549
  prefs: []
  type: TYPE_TB
  zh: '| 忽略格式 | 99 | 33 | 0 | 29 | 0 | 37 | 0.67 |'
- en: '| Sequence Errors | 49 | 1 | 0 | 24 | 0 | 24 | 0.98 |'
  id: totrans-550
  prefs: []
  type: TYPE_TB
  zh: '| 顺序错误 | 49 | 1 | 0 | 24 | 0 | 24 | 0.98 |'
- en: '| Total | 379 | 122 | 62 | 73 | 0 | 122 | 0.68 |'
  id: totrans-551
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 379 | 122 | 62 | 73 | 0 | 122 | 0.68 |'
- en: '| R | Calculations | 149 | 82 | 1 | 12 | 0 | 46 | 0.42 |'
  id: totrans-552
  prefs: []
  type: TYPE_TB
  zh: '| R | 计算 | 149 | 82 | 1 | 12 | 0 | 46 | 0.42 |'
- en: '| Copying Numbers | 83 | 55 | 0 | 6 | 0 | 18 | 0.30 |'
  id: totrans-553
  prefs: []
  type: TYPE_TB
  zh: '| 复制数字 | 83 | 55 | 0 | 6 | 0 | 18 | 0.30 |'
- en: '| Final Errors | 97 | 47 | 1 | 0 | 0 | 42 | 0.48 |'
  id: totrans-554
  prefs: []
  type: TYPE_TB
  zh: '| 最终错误 | 97 | 47 | 1 | 0 | 0 | 42 | 0.48 |'
- en: '| Incorrect Units | 77 | 47 | 0 | 10 | 1 | 19 | 0.39 |'
  id: totrans-555
  prefs: []
  type: TYPE_TB
  zh: '| 错误单位 | 77 | 47 | 0 | 10 | 1 | 19 | 0.39 |'
- en: '| Wrong Formula | 88 | 46 | 1 | 7 | 0 | 27 | 0.43 |'
  id: totrans-556
  prefs: []
  type: TYPE_TB
  zh: '| 错误公式 | 88 | 46 | 1 | 7 | 0 | 27 | 0.43 |'
- en: '| Total | 494 | 277 | 3 | 35 | 1 | 152 | 0.41 |'
  id: totrans-557
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 494 | 277 | 3 | 35 | 1 | 152 | 0.41 |'
- en: 'Table 13: Results from evaluating FBI  using the Rules evaluator. An error
    is said to be detected if the evaluator chooses the Gold Answer. G indicates the
    number of times the evaluator has chosen the Gold Answer, P for the Perturbed
    Answer, Both ✓ when both answers are correct, Both ✗ when both are incorrect,
    and $\neq$ for verdict inconsistencies.'
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: '表 13: 使用规则评估器评估 FBI 的结果。若评估器选择了金标准答案，则认为检测到了错误。G 表示评估器选择金标准答案的次数，P 表示扰动答案，双方
    ✓ 表示两者均正确，双方 ✗ 表示两者均错误，$\neq$ 表示裁定不一致。'
- en: '|  | Perturbation Type |'
  id: totrans-559
  prefs: []
  type: TYPE_TB
  zh: '|  | 扰动类型 |'
- en: '&#124; Total &#124;'
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 总计 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '| G | P | Both ✓ | Both ✗ | $\neq$ |'
  id: totrans-562
  prefs: []
  type: TYPE_TB
  zh: '| G | P | 两者 ✓ | 两者 ✗ | $\neq$ |'
- en: '&#124; % Undetected &#124;'
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; % 未检测到 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| LF | Coherence | 91 | 82 | 0 | 1 | 0 | 8 | 0.10 |'
  id: totrans-566
  prefs: []
  type: TYPE_TB
  zh: '| LF | 连贯性 | 91 | 82 | 0 | 1 | 0 | 8 | 0.10 |'
- en: '| Comprehensiveness | 90 | 49 | 0 | 9 | 0 | 32 | 0.46 |'
  id: totrans-567
  prefs: []
  type: TYPE_TB
  zh: '| 完整性 | 90 | 49 | 0 | 9 | 0 | 32 | 0.46 |'
- en: '| Consistency | 84 | 16 | 0 | 50 | 0 | 18 | 0.81 |'
  id: totrans-568
  prefs: []
  type: TYPE_TB
  zh: '| 一致性 | 84 | 16 | 0 | 50 | 0 | 18 | 0.81 |'
- en: '| Grammar | 92 | 34 | 0 | 26 | 0 | 32 | 0.63 |'
  id: totrans-569
  prefs: []
  type: TYPE_TB
  zh: '| 语法 | 92 | 34 | 0 | 26 | 0 | 32 | 0.63 |'
- en: '| Chronology | 71 | 0 | 0 | 57 | 0 | 14 | 1.00 |'
  id: totrans-570
  prefs: []
  type: TYPE_TB
  zh: '| 时间顺序 | 71 | 0 | 0 | 57 | 0 | 14 | 1.00 |'
- en: '| Spelling | 100 | 11 | 0 | 58 | 0 | 31 | 0.89 |'
  id: totrans-571
  prefs: []
  type: TYPE_TB
  zh: '| 拼写 | 100 | 11 | 0 | 58 | 0 | 31 | 0.89 |'
- en: '| Total | 528 | 192 | 0 | 201 | 0 | 135 | 0.64 |'
  id: totrans-572
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 528 | 192 | 0 | 201 | 0 | 135 | 0.64 |'
- en: '| F | Contextual | 94 | 60 | 0 | 8 | 0 | 26 | 0.36 |'
  id: totrans-573
  prefs: []
  type: TYPE_TB
  zh: '| F | 上下文 | 94 | 60 | 0 | 8 | 0 | 26 | 0.36 |'
- en: '| Entity | 87 | 60 | 0 | 11 | 0 | 16 | 0.31 |'
  id: totrans-574
  prefs: []
  type: TYPE_TB
  zh: '| 实体 | 87 | 60 | 0 | 11 | 0 | 16 | 0.31 |'
- en: '| Incorrect Fact | 68 | 41 | 0 | 4 | 0 | 23 | 0.40 |'
  id: totrans-575
  prefs: []
  type: TYPE_TB
  zh: '| 错误事实 | 68 | 41 | 0 | 4 | 0 | 23 | 0.40 |'
- en: '| Number Errors | 74 | 45 | 0 | 10 | 0 | 19 | 0.39 |'
  id: totrans-576
  prefs: []
  type: TYPE_TB
  zh: '| 数字错误 | 74 | 45 | 0 | 10 | 0 | 19 | 0.39 |'
- en: '| Opposite Fact | 91 | 61 | 0 | 7 | 0 | 23 | 0.33 |'
  id: totrans-577
  prefs: []
  type: TYPE_TB
  zh: '| 相反事实 | 91 | 61 | 0 | 7 | 0 | 23 | 0.33 |'
- en: '| Remove Fact | 69 | 5 | 0 | 58 | 0 | 6 | 0.93 |'
  id: totrans-578
  prefs: []
  type: TYPE_TB
  zh: '| 去除事实 | 69 | 5 | 0 | 58 | 0 | 6 | 0.93 |'
- en: '| Total | 483 | 272 | 0 | 98 | 0 | 113 | 0.44 |'
  id: totrans-579
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 483 | 272 | 0 | 98 | 0 | 113 | 0.44 |'
- en: '| IF | Assumptions | 81 | 2 | 62 | 4 | 0 | 13 | 0.98 |'
  id: totrans-580
  prefs: []
  type: TYPE_TB
  zh: '| IF | 假设 | 81 | 2 | 62 | 4 | 0 | 13 | 0.98 |'
- en: '| Do Less | 100 | 57 | 0 | 11 | 0 | 32 | 0.43 |'
  id: totrans-581
  prefs: []
  type: TYPE_TB
  zh: '| 少做 | 100 | 57 | 0 | 11 | 0 | 32 | 0.43 |'
- en: '| Do More | 50 | 40 | 2 | 3 | 0 | 5 | 0.20 |'
  id: totrans-582
  prefs: []
  type: TYPE_TB
  zh: '| 多做 | 50 | 40 | 2 | 3 | 0 | 5 | 0.20 |'
- en: '| Ignore Format | 99 | 53 | 0 | 13 | 0 | 33 | 0.46 |'
  id: totrans-583
  prefs: []
  type: TYPE_TB
  zh: '| 忽略格式 | 99 | 53 | 0 | 13 | 0 | 33 | 0.46 |'
- en: '| Sequence Errors | 49 | 5 | 0 | 23 | 0 | 21 | 0.9 |'
  id: totrans-584
  prefs: []
  type: TYPE_TB
  zh: '| 序列错误 | 49 | 5 | 0 | 23 | 0 | 21 | 0.9 |'
- en: '| Total | 379 | 157 | 64 | 54 | 0 | 104 | 0.59 |'
  id: totrans-585
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 379 | 157 | 64 | 54 | 0 | 104 | 0.59 |'
- en: '| R | Calculations | 149 | 108 | 1 | 16 | 0 | 23 | 0.27 |'
  id: totrans-586
  prefs: []
  type: TYPE_TB
  zh: '| R | 计算 | 149 | 108 | 1 | 16 | 0 | 23 | 0.27 |'
- en: '| Copying Numbers | 83 | 69 | 1 | 7 | 0 | 6 | 0.17 |'
  id: totrans-587
  prefs: []
  type: TYPE_TB
  zh: '| 复制数字 | 83 | 69 | 1 | 7 | 0 | 6 | 0.17 |'
- en: '| Final Errors | 97 | 75 | 1 | 2 | 0 | 19 | 0.23 |'
  id: totrans-588
  prefs: []
  type: TYPE_TB
  zh: '| 最终错误 | 97 | 75 | 1 | 2 | 0 | 19 | 0.23 |'
- en: '| Incorrect Units | 77 | 42 | 0 | 20 | 0 | 15 | 0.45 |'
  id: totrans-589
  prefs: []
  type: TYPE_TB
  zh: '| 错误单位 | 77 | 42 | 0 | 20 | 0 | 15 | 0.45'
- en: '| Wrong Formula | 88 | 64 | 0 | 12 | 0 | 12 | 0.27 |'
  id: totrans-590
  prefs: []
  type: TYPE_TB
  zh: '| 错误公式 | 88 | 64 | 0 | 12 | 0 | 12 | 0.27 |'
- en: '| Total | 494 | 358 | 3 | 57 | 0 | 75 | 0.27 |'
  id: totrans-591
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 494 | 358 | 3 | 57 | 0 | 75 | 0.27 |'
- en: 'Table 14: Results from evaluating FBI  using the Axis evaluator. An error is
    said to be detected if the evaluator chooses the Gold Answer. G indicates the
    number of times the evaluator has chosen the Gold Answer, P for the Perturbed
    Answer, Both ✓ when both answers are correct, Both ✗ when both are incorrect,
    and $\neq$ for verdict inconsistencies.'
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: '表 14: 使用轴心评估器评估 FBI 的结果。若评估器选择了金标准答案，则认为检测到了错误。G 表示评估器选择金标准答案的次数，P 表示扰动答案，双方
    ✓ 表示两者均正确，双方 ✗ 表示两者均错误，$\neq$ 表示裁定不一致。'
- en: '|  | Perturbation Type |'
  id: totrans-593
  prefs: []
  type: TYPE_TB
  zh: '|  | 扰动类型 |'
- en: '&#124; Total &#124;'
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 总计 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '| G | P | Both ✓ | Both ✗ | $\neq$ |'
  id: totrans-596
  prefs: []
  type: TYPE_TB
  zh: '| G | P | 两者 ✓ | 两者 ✗ | $\neq$ |'
- en: '&#124; % Undetected &#124;'
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; % 未检测到 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| LF | Coherence | 91 | 84 | 0 | 2 | 0 | 5 | 0.08 |'
  id: totrans-600
  prefs: []
  type: TYPE_TB
  zh: '| LF | 连贯性 | 91 | 84 | 0 | 2 | 0 | 5 | 0.08 |'
- en: '| Comprehensiveness | 90 | 47 | 0 | 13 | 0 | 29 | 0.47 |'
  id: totrans-601
  prefs: []
  type: TYPE_TB
  zh: '| 完整性 | 90 | 47 | 0 | 13 | 0 | 29 | 0.47 |'
- en: '| Consistency | 84 | 16 | 0 | 52 | 0 | 16 | 0.81 |'
  id: totrans-602
  prefs: []
  type: TYPE_TB
  zh: '| 一致性 | 84 | 16 | 0 | 52 | 0 | 16 | 0.81 |'
- en: '| Grammar | 92 | 33 | 0 | 27 | 0 | 32 | 0.64 |'
  id: totrans-603
  prefs: []
  type: TYPE_TB
  zh: '| 语法 | 92 | 33 | 0 | 27 | 0 | 32 | 0.64 |'
- en: '| Chronology | 71 | 2 | 0 | 61 | 0 | 8 | 0.97 |'
  id: totrans-604
  prefs: []
  type: TYPE_TB
  zh: '| 时间顺序 | 71 | 2 | 0 | 61 | 0 | 8 | 0.97 |'
- en: '| Spelling | 100 | 7 | 0 | 53 | 0 | 40 | 0.93 |'
  id: totrans-605
  prefs: []
  type: TYPE_TB
  zh: '| 拼写 | 100 | 7 | 0 | 53 | 0 | 40 | 0.93 |'
- en: '| Total | 528 | 189 | 0 | 208 | 0 | 130 | 0.64 |'
  id: totrans-606
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 528 | 189 | 0 | 208 | 0 | 130 | 0.64 |'
- en: '| F | Contextual | 94 | 56 | 0 | 8 | 0 | 28 | 0.39 |'
  id: totrans-607
  prefs: []
  type: TYPE_TB
  zh: '| F | 上下文 | 94 | 56 | 0 | 8 | 0 | 28 | 0.39 |'
- en: '| Entity | 87 | 61 | 0 | 11 | 0 | 13 | 0.28 |'
  id: totrans-608
  prefs: []
  type: TYPE_TB
  zh: '| 实体 | 87 | 61 | 0 | 11 | 0 | 13 | 0.28 |'
- en: '| Incorrect Fact | 68 | 43 | 2 | 2 | 0 | 20 | 0.36 |'
  id: totrans-609
  prefs: []
  type: TYPE_TB
  zh: '| 错误事实 | 68 | 43 | 2 | 2 | 0 | 20 | 0.36 |'
- en: '| Number Errors | 74 | 43 | 0 | 8 | 0 | 21 | 0.40 |'
  id: totrans-610
  prefs: []
  type: TYPE_TB
  zh: '| 数字错误 | 74 | 43 | 0 | 8 | 0 | 21 | 0.40 |'
- en: '| Opposite Fact | 91 | 66 | 0 | 5 | 0 | 20 | 0.27 |'
  id: totrans-611
  prefs: []
  type: TYPE_TB
  zh: '| 相反事实 | 91 | 66 | 0 | 5 | 0 | 20 | 0.27 |'
- en: '| Remove Fact | 69 | 9 | 0 | 34 | 0 | 26 | 0.87 |'
  id: totrans-612
  prefs: []
  type: TYPE_TB
  zh: '| 去除事实 | 69 | 9 | 0 | 34 | 0 | 26 | 0.87 |'
- en: '| Total | 483 | 278 | 2 | 68 | 0 | 128 | 0.42 |'
  id: totrans-613
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 483 | 278 | 2 | 68 | 0 | 128 | 0.42 |'
- en: '| IF | Assumptions | 81 | 2 | 65 | 2 | 0 | 12 | 0.98 |'
  id: totrans-614
  prefs: []
  type: TYPE_TB
  zh: '| IF | 假设 | 81 | 2 | 65 | 2 | 0 | 12 | 0.98 |'
- en: '| Do Less | 100 | 59 | 0 | 8 | 0 | 33 | 0.41 |'
  id: totrans-615
  prefs: []
  type: TYPE_TB
  zh: '| 少做 | 100 | 59 | 0 | 8 | 0 | 33 | 0.41 |'
- en: '| Do More | 50 | 35 | 2 | 0 | 0 | 13 | 0.30 |'
  id: totrans-616
  prefs: []
  type: TYPE_TB
  zh: '| 更多 | 50 | 35 | 2 | 0 | 0 | 13 | 0.30 |'
- en: '| Ignore Format | 99 | 51 | 0 | 18 | 0 | 30 | 0.48 |'
  id: totrans-617
  prefs: []
  type: TYPE_TB
  zh: '| 忽略格式 | 99 | 51 | 0 | 18 | 0 | 30 | 0.48 |'
- en: '| Sequence Errors | 49 | 1 | 0 | 29 | 0 | 19 | 0.98 |'
  id: totrans-618
  prefs: []
  type: TYPE_TB
  zh: '| 顺序错误 | 49 | 1 | 0 | 29 | 0 | 19 | 0.98 |'
- en: '| Total | 379 | 148 | 67 | 57 | 0 | 107 | 0.61 |'
  id: totrans-619
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 379 | 148 | 67 | 57 | 0 | 107 | 0.61 |'
- en: '| R | Calculations | 149 | 93 | 0 | 12 | 0 | 23 | 0.27 |'
  id: totrans-620
  prefs: []
  type: TYPE_TB
  zh: '| R | 计算 | 149 | 93 | 0 | 12 | 0 | 23 | 0.27 |'
- en: '| Copying Numbers | 83 | 58 | 0 | 6 | 0 | 12 | 0.24 |'
  id: totrans-621
  prefs: []
  type: TYPE_TB
  zh: '| 复制数字 | 83 | 58 | 0 | 6 | 0 | 12 | 0.24 |'
- en: '| Final Errors | 97 | 57 | 2 | 2 | 0 | 26 | 0.34 |'
  id: totrans-622
  prefs: []
  type: TYPE_TB
  zh: '| 最终错误 | 97 | 57 | 2 | 2 | 0 | 26 | 0.34 |'
- en: '| Incorrect Units | 77 | 38 | 0 | 19 | 0 | 16 | 0.48 |'
  id: totrans-623
  prefs: []
  type: TYPE_TB
  zh: '| 错误单位 | 77 | 38 | 0 | 19 | 0 | 16 | 0.48 |'
- en: '| Wrong Formula | 88 | 54 | 0 | 10 | 0 | 16 | 0.33 |'
  id: totrans-624
  prefs: []
  type: TYPE_TB
  zh: '| 错误公式 | 88 | 54 | 0 | 10 | 0 | 16 | 0.33 |'
- en: '| Total | 494 | 300 | 2 | 49 | 0 | 93 | 0.32 |'
  id: totrans-625
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 494 | 300 | 2 | 49 | 0 | 93 | 0.32 |'
- en: 'Table 15: Results from evaluating FBI  using the Axis+Rules evaluator. An error
    is said to be detected if the evaluator chooses the Gold Answer. G indicates the
    number of times the evaluator has chosen the Gold Answer, P for the Perturbed
    Answer, Both ✓ when both answers are correct, Both ✗ when both are incorrect,
    and $\neq$ for verdict inconsistencies.'
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
  zh: 表15：使用 Axis+Rules 评估器评估 FBI 的结果。若评估器选择了金标准答案，则认为错误被检测到。G 表示评估器选择了金标准答案的次数，P
    表示扰动答案的次数，Both ✓ 表示两个答案都正确，Both ✗ 表示两个答案都错误，$\neq$ 表示判决不一致。
- en: '|  | Perturbation Type |'
  id: totrans-627
  prefs: []
  type: TYPE_TB
  zh: '|  | 扰动类型 |'
- en: '&#124; Total &#124;'
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 总计 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '| 10 | 9 | 8 | $<$8 |'
  id: totrans-630
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 9 | 8 | $<$8 |'
- en: '&#124; % Undetected &#124;'
  id: totrans-631
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 未检测到百分比 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-632
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| LF | Coherence | 91 | 2 | 5 | 9 | 75 | 0.02 |'
  id: totrans-634
  prefs: []
  type: TYPE_TB
  zh: '| LF | 一致性 | 91 | 2 | 5 | 9 | 75 | 0.02 |'
- en: '| Comprehensiveness | 90 | 32 | 39 | 6 | 13 | 0.36 |'
  id: totrans-635
  prefs: []
  type: TYPE_TB
  zh: '| 完整性 | 90 | 32 | 39 | 6 | 13 | 0.36 |'
- en: '| Consistency | 84 | 31 | 27 | 4 | 22 | 0.37 |'
  id: totrans-636
  prefs: []
  type: TYPE_TB
  zh: '| 一致性 | 84 | 31 | 27 | 4 | 22 | 0.37 |'
- en: '| Grammar | 92 | 10 | 51 | 9 | 22 | 0.11 |'
  id: totrans-637
  prefs: []
  type: TYPE_TB
  zh: '| 语法 | 92 | 10 | 51 | 9 | 22 | 0.11 |'
- en: '| Chronology | 71 | 47 | 21 | 2 | 1 | 0.66 |'
  id: totrans-638
  prefs: []
  type: TYPE_TB
  zh: '| 年代顺序 | 71 | 47 | 21 | 2 | 1 | 0.66 |'
- en: '| Spelling | 100 | 14 | 72 | 4 | 10 | 0.14 |'
  id: totrans-639
  prefs: []
  type: TYPE_TB
  zh: '| 拼写 | 100 | 14 | 72 | 4 | 10 | 0.14 |'
- en: '| Total | 528 | 136 | 215 | 34 | 143 | 0.26 |'
  id: totrans-640
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 528 | 136 | 215 | 34 | 143 | 0.26 |'
- en: '| F | Contextual | 94 | 1 | 27 | 11 | 55 | 0.01 |'
  id: totrans-641
  prefs: []
  type: TYPE_TB
  zh: '| F | 上下文 | 94 | 1 | 27 | 11 | 55 | 0.01 |'
- en: '| Entity | 87 | 8 | 16 | 16 | 47 | 0.09 |'
  id: totrans-642
  prefs: []
  type: TYPE_TB
  zh: '| 实体 | 87 | 8 | 16 | 16 | 47 | 0.09 |'
- en: '| Incorrect Fact | 68 | 2 | 15 | 12 | 39 | 0.03 |'
  id: totrans-643
  prefs: []
  type: TYPE_TB
  zh: '| 错误事实 | 68 | 2 | 15 | 12 | 39 | 0.03 |'
- en: '| Number Errors | 74 | 6 | 21 | 15 | 32 | 0.08 |'
  id: totrans-644
  prefs: []
  type: TYPE_TB
  zh: '| 数字错误 | 74 | 6 | 21 | 15 | 32 | 0.08 |'
- en: '| Opposite Fact | 91 | 0 | 11 | 4 | 76 | 0.00 |'
  id: totrans-645
  prefs: []
  type: TYPE_TB
  zh: '| 对立事实 | 91 | 0 | 11 | 4 | 76 | 0.00 |'
- en: '| Remove Fact | 69 | 36 | 18 | 10 | 5 | 0.52 |'
  id: totrans-646
  prefs: []
  type: TYPE_TB
  zh: '| 删除事实 | 69 | 36 | 18 | 10 | 5 | 0.52 |'
- en: '| Total | 483 | 53 | 108 | 68 | 254 | 0.11 |'
  id: totrans-647
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 483 | 53 | 108 | 68 | 254 | 0.11 |'
- en: '| IF | Assumptions | 81 | 50 | 17 | 4 | 10 | 0.62 |'
  id: totrans-648
  prefs: []
  type: TYPE_TB
  zh: '| IF | 假设 | 81 | 50 | 17 | 4 | 10 | 0.62 |'
- en: '| Do Less | 100 | 32 | 6 | 15 | 47 | 0.32 |'
  id: totrans-649
  prefs: []
  type: TYPE_TB
  zh: '| 少做 | 100 | 32 | 6 | 15 | 47 | 0.32 |'
- en: '| Do More | 50 | 22 | 10 | 12 | 6 | 0.44 |'
  id: totrans-650
  prefs: []
  type: TYPE_TB
  zh: '| 更多 | 50 | 22 | 10 | 12 | 6 | 0.44 |'
- en: '| Ignore Format | 99 | 43 | 18 | 7 | 30 | 0.43 |'
  id: totrans-651
  prefs: []
  type: TYPE_TB
  zh: '| 忽略格式 | 99 | 43 | 18 | 7 | 30 | 0.43 |'
- en: '| Sequence Errors | 49 | 39 | 8 | 2 | 0 | 0.80 |'
  id: totrans-652
  prefs: []
  type: TYPE_TB
  zh: '| 顺序错误 | 49 | 39 | 8 | 2 | 0 | 0.80 |'
- en: '| Total | 379 | 186 | 59 | 40 | 93 | 0.49 |'
  id: totrans-653
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 379 | 186 | 59 | 40 | 93 | 0.49 |'
- en: '| R | Calculations | 149 | 6 | 6 | 6 | 131 | 0.04 |'
  id: totrans-654
  prefs: []
  type: TYPE_TB
  zh: '| R | 计算 | 149 | 6 | 6 | 6 | 131 | 0.04 |'
- en: '| Copying Numbers | 83 | 4 | 4 | 3 | 72 | 0.05 |'
  id: totrans-655
  prefs: []
  type: TYPE_TB
  zh: '| 复制数字 | 83 | 4 | 4 | 3 | 72 | 0.05 |'
- en: '| Final Errors | 97 | 1 | 2 | 4 | 89 | 0.01 |'
  id: totrans-656
  prefs: []
  type: TYPE_TB
  zh: '| 最终错误 | 97 | 1 | 2 | 4 | 89 | 0.01 |'
- en: '| Incorrect Units | 77 | 10 | 10 | 4 | 53 | 0.13 |'
  id: totrans-657
  prefs: []
  type: TYPE_TB
  zh: '| 错误单位 | 77 | 10 | 10 | 4 | 53 | 0.13 |'
- en: '| Wrong Formula | 88 | 1 | 12 | 1 | 74 | 0.01 |'
  id: totrans-658
  prefs: []
  type: TYPE_TB
  zh: '| 错误公式 | 88 | 1 | 12 | 1 | 74 | 0.01 |'
- en: '| Total | 494 | 22 | 34 | 18 | 419 | 0.04 |'
  id: totrans-659
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 494 | 22 | 34 | 18 | 419 | 0.04 |'
- en: 'Table 16: Results from evaluating FBI  using the Reference evaluator. An error
    is said to be detected if the evaluator gives a perfect score of 10 to the perturbed
    answer. 10 indicates the number of times the evaluator has given the score of
    10, 9 for the score of 9, 8 for the score of 8 and $<$8 for scores less than 8.'
  id: totrans-660
  prefs: []
  type: TYPE_NORMAL
  zh: 表16：使用参考评估器评估 FBI 的结果。若评估器对扰动答案给予完美分数 10，则认为错误被检测到。10 表示评估器给予分数 10 的次数，9 表示分数
    9，8 表示分数 8，$<$8 表示分数小于 8。
- en: '|  |  |  | Generic | Specific |'
  id: totrans-661
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | 泛型 | 特定 |'
- en: '|  | Perturbation Type | # Errs | 5 | 4 | $<$4 | % Errors | 5 | 4 | $<$4 |
    % Errors |'
  id: totrans-662
  prefs: []
  type: TYPE_TB
  zh: '|  | 扰动类型 | 错误数量 | 5 | 4 | $<$4 | 错误百分比 | 5 | 4 | $<$4 | 错误百分比 |'
- en: '| LF | Coherence | 91 | 9 | 33 | 49 | 0.10 | 17 | 18 | 56 | 0.19 |'
  id: totrans-663
  prefs: []
  type: TYPE_TB
  zh: '| LF | 一致性 | 91 | 9 | 33 | 49 | 0.10 | 17 | 18 | 56 | 0.19 |'
- en: '| Comprehensiveness | 90 | 40 | 42 | 8 | 0.44 | 40 | 46 | 4 | 0.44 |'
  id: totrans-664
  prefs: []
  type: TYPE_TB
  zh: '| 完整性 | 90 | 40 | 42 | 8 | 0.44 | 40 | 46 | 4 | 0.44 |'
- en: '| Consistency | 84 | 36 | 36 | 12 | 0.43 | 50 | 26 | 8 | 0.60 |'
  id: totrans-665
  prefs: []
  type: TYPE_TB
  zh: '| 一致性 | 84 | 36 | 36 | 12 | 0.43 | 50 | 26 | 8 | 0.60 |'
- en: '| Grammar | 92 | 44 | 39 | 9 | 0.48 | 56 | 31 | 5 | 0.61 |'
  id: totrans-666
  prefs: []
  type: TYPE_TB
  zh: '| 语法 | 92 | 44 | 39 | 9 | 0.48 | 56 | 31 | 5 | 0.61 |'
- en: '| Chronology | 71 | 43 | 24 | 4 | 0.61 | 42 | 23 | 6 | 0.59 |'
  id: totrans-667
  prefs: []
  type: TYPE_TB
  zh: '| 年代顺序 | 71 | 43 | 24 | 4 | 0.61 | 42 | 23 | 6 | 0.59 |'
- en: '| Spelling | 100 | 46 | 49 | 5 | 0.46 | 65 | 28 | 7 | 0.65 |'
  id: totrans-668
  prefs: []
  type: TYPE_TB
  zh: '| 拼写 | 100 | 46 | 49 | 5 | 0.46 | 65 | 28 | 7 | 0.65 |'
- en: '| Total | 528 | 218 | 223 | 87 | 0.41 | 270 | 172 | 86 | 0.51 |'
  id: totrans-669
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 528 | 218 | 223 | 87 | 0.41 | 270 | 172 | 86 | 0.51 |'
- en: '| F | Contextual | 94 | 46 | 39 | 9 | 0.49 | 56 | 25 | 13 | 0.60 |'
  id: totrans-670
  prefs: []
  type: TYPE_TB
  zh: '| F | 上下文 | 94 | 46 | 39 | 9 | 0.49 | 56 | 25 | 13 | 0.60 |'
- en: '| Entity | 87 | 34 | 41 | 12 | 0.39 | 51 | 22 | 14 | 0.59 |'
  id: totrans-671
  prefs: []
  type: TYPE_TB
  zh: '| 实体 | 87 | 34 | 41 | 12 | 0.39 | 51 | 22 | 14 | 0.59 |'
- en: '| Incorrect Fact | 68 | 29 | 30 | 9 | 0.43 | 45 | 18 | 5 | 0.66 |'
  id: totrans-672
  prefs: []
  type: TYPE_TB
  zh: '| 错误事实 | 68 | 29 | 30 | 9 | 0.43 | 45 | 18 | 5 | 0.66 |'
- en: '| Number Errors | 74 | 36 | 32 | 6 | 0.49 | 47 | 18 | 9 | 0.64 |'
  id: totrans-673
  prefs: []
  type: TYPE_TB
  zh: '| 数字错误 | 74 | 36 | 32 | 6 | 0.49 | 47 | 18 | 9 | 0.64 |'
- en: '| Opposite Fact | 91 | 37 | 41 | 13 | 0.41 | 52 | 28 | 11 | 0.57 |'
  id: totrans-674
  prefs: []
  type: TYPE_TB
  zh: '| 相反事实 | 91 | 37 | 41 | 13 | 0.41 | 52 | 28 | 11 | 0.57 |'
- en: '| Remove Fact | 69 | 41 | 27 | 1 | 0.59 | 50 | 18 | 1 | 0.72 |'
  id: totrans-675
  prefs: []
  type: TYPE_TB
  zh: '| 移除事实 | 69 | 41 | 27 | 1 | 0.59 | 50 | 18 | 1 | 0.72 |'
- en: '| Total | 483 | 223 | 210 | 50 | 0.46 | 301 | 129 | 53 | 0.62 |'
  id: totrans-676
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 483 | 223 | 210 | 50 | 0.46 | 301 | 129 | 53 | 0.62 |'
- en: '| IF | Assumptions | 81 | 38 | 41 | 2 | 0.47 | 56 | 25 | 0 | 0.69 |'
  id: totrans-677
  prefs: []
  type: TYPE_TB
  zh: '| IF | 假设 | 81 | 38 | 41 | 2 | 0.47 | 56 | 25 | 0 | 0.69 |'
- en: '| Do Less | 100 | 53 | 44 | 3 | 0.53 | 54 | 44 | 2 | 0.54 |'
  id: totrans-678
  prefs: []
  type: TYPE_TB
  zh: '| 减少操作 | 100 | 53 | 44 | 3 | 0.53 | 54 | 44 | 2 | 0.54 |'
- en: '| Do More | 50 | 17 | 24 | 9 | 0.34 | 16 | 28 | 6 | 0.32 |'
  id: totrans-679
  prefs: []
  type: TYPE_TB
  zh: '| 更多操作 | 50 | 17 | 24 | 9 | 0.34 | 16 | 28 | 6 | 0.32 |'
- en: '| Ignore Format | 99 | 49 | 43 | 7 | 0.49 | 53 | 35 | 11 | 0.54 |'
  id: totrans-680
  prefs: []
  type: TYPE_TB
  zh: '| 忽略格式 | 99 | 49 | 43 | 7 | 0.49 | 53 | 35 | 11 | 0.54 |'
- en: '| Sequence Errors | 49 | 18 | 28 | 3 | 0.37 | 21 | 21 | 7 | 0.43 |'
  id: totrans-681
  prefs: []
  type: TYPE_TB
  zh: '| 顺序错误 | 49 | 18 | 28 | 3 | 0.37 | 21 | 21 | 7 | 0.43 |'
- en: '| Total | 379 | 175 | 180 | 24 | 0.46 | 200 | 153 | 26 | 0.53 |'
  id: totrans-682
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 379 | 175 | 180 | 24 | 0.46 | 200 | 153 | 26 | 0.53 |'
- en: '| R | Calculations | 149 | 23 | 67 | 59 | 0.15 | 14 | 75 | 60 | 0.09 |'
  id: totrans-683
  prefs: []
  type: TYPE_TB
  zh: '| R | 计算 | 149 | 23 | 67 | 59 | 0.15 | 14 | 75 | 60 | 0.09 |'
- en: '| Copying Numbers | 83 | 11 | 38 | 34 | 0.13 | 9 | 42 | 32 | 0.11 |'
  id: totrans-684
  prefs: []
  type: TYPE_TB
  zh: '| 复制数字 | 83 | 11 | 38 | 34 | 0.13 | 9 | 42 | 32 | 0.11 |'
- en: '| Final Errors | 97 | 22 | 46 | 29 | 0.23 | 10 | 54 | 33 | 0.10 |'
  id: totrans-685
  prefs: []
  type: TYPE_TB
  zh: '| 最终错误 | 97 | 22 | 46 | 29 | 0.23 | 10 | 54 | 33 | 0.10 |'
- en: '| Incorrect Units | 77 | 16 | 23 | 38 | 0.21 | 8 | 34 | 35 | 0.10 |'
  id: totrans-686
  prefs: []
  type: TYPE_TB
  zh: '| 错误单位 | 77 | 16 | 23 | 38 | 0.21 | 8 | 34 | 35 | 0.10 |'
- en: '| Wrong Formula | 88 | 17 | 48 | 23 | 0.19 | 17 | 38 | 33 | 0.19 |'
  id: totrans-687
  prefs: []
  type: TYPE_TB
  zh: '| 错误公式 | 88 | 17 | 48 | 23 | 0.19 | 17 | 38 | 33 | 0.19 |'
- en: '| Total | 494 | 89 | 222 | 183 | 0.18 | 58 | 243 | 193 | 0.12 |'
  id: totrans-688
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 494 | 89 | 222 | 183 | 0.18 | 58 | 243 | 193 | 0.12 |'
- en: 'Table 17: Results from evaluating FBI  using the Prometheus evaluator. An error
    is said to be detected if the evaluator gives a perfect score of 5 to the perturbed
    answer. 5 indicates the number of times the evaluator has given the score of 5,
    4 for the score of 4, and $<$4 for scores less than 4\. Generic indicates evaluating
    with general scoring rubrics and Specific indicates evaluating with task-specific
    rubrics.'
  id: totrans-689
  prefs: []
  type: TYPE_NORMAL
  zh: 表17：使用 Prometheus 评估器对 FBI 进行评估的结果。如果评估器给扰动后的答案打出了满分5分，则认为检测到了错误。5 表示评估器给出5分的次数，4
    表示4分的次数，$<$4 表示低于4分的次数。Generic 表示使用通用评分标准进行评估，Specific 表示使用任务特定评分标准进行评估。
- en: '|  |  |  | Llama-3-70B-Instruct | Claude-3-Opus | Gemini-1.5-Pro |'
  id: totrans-690
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | Llama-3-70B-Instruct | Claude-3-Opus | Gemini-1.5-Pro |'
- en: '| Perturbation Type | # Errs | # DE | # UE | % UE | # DE | # UE | % UE | #
    DE | # UE | % UE |'
  id: totrans-691
  prefs: []
  type: TYPE_TB
  zh: '| 扰动类型 | # 错误 | # DE | # UE | % UE | # DE | # UE | % UE | # DE | # UE | % UE
    |'
- en: '| LF | Coherence | 91 | 61 | 21 | 0.29 | 72 | 18 | 0.20 | 83 | 8 | 0.09 |'
  id: totrans-692
  prefs: []
  type: TYPE_TB
  zh: '| LF | 一致性 | 91 | 61 | 21 | 0.29 | 72 | 18 | 0.20 | 83 | 8 | 0.09 |'
- en: '| Comprehensiveness | 90 | 22 | 59 | 0.82 | 19 | 71 | 0.79 | 29 | 60 | 0.67
    |'
  id: totrans-693
  prefs: []
  type: TYPE_TB
  zh: '| 全面性 | 90 | 22 | 59 | 0.82 | 19 | 71 | 0.79 | 29 | 60 | 0.67 |'
- en: '| Consistency | 84 | 9 | 65 | 1.00 | 18 | 65 | 0.78 | 29 | 55 | 0.65 |'
  id: totrans-694
  prefs: []
  type: TYPE_TB
  zh: '| 一致性 | 84 | 9 | 65 | 1.00 | 18 | 65 | 0.78 | 29 | 55 | 0.65 |'
- en: '| Grammar | 92 | 8 | 80 | 0.95 | 12 | 80 | 0.87 | 29 | 63 | 0.68 |'
  id: totrans-695
  prefs: []
  type: TYPE_TB
  zh: '| 语法 | 92 | 8 | 80 | 0.95 | 12 | 80 | 0.87 | 29 | 63 | 0.68 |'
- en: '| Chronology | 71 | 1 | 60 | 1.15 | 6 | 64 | 0.91 | 18 | 53 | 0.75 |'
  id: totrans-696
  prefs: []
  type: TYPE_TB
  zh: '| 年代顺序 | 71 | 1 | 60 | 1.15 | 6 | 64 | 0.91 | 18 | 53 | 0.75 |'
- en: '| Spelling | 100 | 7 | 85 | 1.01 | 13 | 80 | 0.92 | 18 | 82 | 0.82 |'
  id: totrans-697
  prefs: []
  type: TYPE_TB
  zh: '| 拼写 | 100 | 7 | 85 | 1.01 | 13 | 80 | 0.92 | 18 | 82 | 0.82 |'
- en: '| Total | 528 | 108 | 370 | 0.86 | 140 | 378 | 0.74 | 206 | 321 | 0.61 |'
  id: totrans-698
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 528 | 108 | 370 | 0.86 | 140 | 378 | 0.74 | 206 | 321 | 0.61 |'
- en: '| F | Contextual | 94 | 5 | 82 | 1.03 | 14 | 80 | 0.85 | 28 | 66 | 0.70 |'
  id: totrans-699
  prefs: []
  type: TYPE_TB
  zh: '| F | 上下文 | 94 | 5 | 82 | 1.03 | 14 | 80 | 0.85 | 28 | 66 | 0.70 |'
- en: '| Entity | 87 | 13 | 64 | 0.94 | 22 | 65 | 0.75 | 32 | 55 | 0.63 |'
  id: totrans-700
  prefs: []
  type: TYPE_TB
  zh: '| 实体 | 87 | 13 | 64 | 0.94 | 22 | 65 | 0.75 | 32 | 55 | 0.63 |'
- en: '| Incorrect Fact | 68 | 6 | 55 | 1.02 | 10 | 58 | 0.85 | 15 | 53 | 0.78 |'
  id: totrans-701
  prefs: []
  type: TYPE_TB
  zh: '| 错误事实 | 68 | 6 | 55 | 1.02 | 10 | 58 | 0.85 | 15 | 53 | 0.78 |'
- en: '| Number Errors | 74 | 6 | 61 | 1.00 | 8 | 66 | 0.89 | 11 | 63 | 0.85 |'
  id: totrans-702
  prefs: []
  type: TYPE_TB
  zh: '| 数字错误 | 74 | 6 | 61 | 1.00 | 8 | 66 | 0.89 | 11 | 63 | 0.85 |'
- en: '| Opposite Fact | 91 | 10 | 74 | 0.96 | 17 | 74 | 0.81 | 32 | 59 | 0.65 |'
  id: totrans-703
  prefs: []
  type: TYPE_TB
  zh: '| 相反事实 | 91 | 10 | 74 | 0.96 | 17 | 74 | 0.81 | 32 | 59 | 0.65 |'
- en: '| Remove Fact | 69 | 18 | 49 | 0.74 | 8 | 61 | 0.88 | 13 | 56 | 0.81 |'
  id: totrans-704
  prefs: []
  type: TYPE_TB
  zh: '| 移除事实 | 69 | 18 | 49 | 0.74 | 8 | 61 | 0.88 | 13 | 56 | 0.81 |'
- en: '| Total | 483 | 58 | 385 | 0.95 | 79 | 404 | 0.84 | 131 | 352 | 0.73 |'
  id: totrans-705
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 483 | 58 | 385 | 0.95 | 79 | 404 | 0.84 | 131 | 352 | 0.73 |'
- en: '| IF | Assumptions | 81 | 10 | 55 | 1.10 | 10 | 71 | 0.88 | 25 | 56 | 0.69
    |'
  id: totrans-706
  prefs: []
  type: TYPE_TB
  zh: '| IF | 假设 | 81 | 10 | 55 | 1.10 | 10 | 71 | 0.88 | 25 | 56 | 0.69 |'
- en: '| Do Less | 100 | 34 | 60 | 0.68 | 45 | 54 | 0.55 | 59 | 41 | 0.41 |'
  id: totrans-707
  prefs: []
  type: TYPE_TB
  zh: '| 减少 | 100 | 34 | 60 | 0.68 | 45 | 54 | 0.55 | 59 | 41 | 0.41 |'
- en: '| Do More | 50 | 11 | 35 | 0.81 | 11 | 39 | 0.78 | 26 | 24 | 0.48 |'
  id: totrans-708
  prefs: []
  type: TYPE_TB
  zh: '| 增加 | 50 | 11 | 35 | 0.81 | 11 | 39 | 0.78 | 26 | 24 | 0.48 |'
- en: '| Ignore Format | 99 | 12 | 53 | 1.71 | 25 | 74 | 0.75 | 49 | 49 | 0.51 |'
  id: totrans-709
  prefs: []
  type: TYPE_TB
  zh: '| 忽略格式 | 99 | 12 | 53 | 1.71 | 25 | 74 | 0.75 | 49 | 49 | 0.51 |'
- en: '| Sequence Errors | 49 | 16 | 33 | 0.67 | 4 | 45 | 0.92 | 17 | 32 | 0.65 |'
  id: totrans-710
  prefs: []
  type: TYPE_TB
  zh: '| 顺序错误 | 49 | 16 | 33 | 0.67 | 4 | 45 | 0.92 | 17 | 32 | 0.65 |'
- en: '| Total | 379 | 83 | 236 | 0.90 | 95 | 283 | 0.75 | 176 | 202 | 0.54 |'
  id: totrans-711
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 379 | 83 | 236 | 0.90 | 95 | 283 | 0.75 | 176 | 202 | 0.54 |'
- en: '| R | Calculations | 149 | 55 | 82 | 0.65 | 90 | 59 | 0.40 | 81 | 64 | 0.43
    |'
  id: totrans-712
  prefs: []
  type: TYPE_TB
  zh: '| R | 计算 | 149 | 55 | 82 | 0.65 | 90 | 59 | 0.40 | 81 | 64 | 0.43 |'
- en: '| Copying Numbers | 83 | 27 | 47 | 0.71 | 42 | 41 | 0.49 | 54 | 28 | 0.34 |'
  id: totrans-713
  prefs: []
  type: TYPE_TB
  zh: '| 复制数字 | 83 | 27 | 47 | 0.71 | 42 | 41 | 0.49 | 54 | 28 | 0.34 |'
- en: '| Final Errors | 97 | 18 | 70 | 0.88 | 35 | 62 | 0.64 | 36 | 60 | 0.63 |'
  id: totrans-714
  prefs: []
  type: TYPE_TB
  zh: '| 最终错误 | 97 | 18 | 70 | 0.88 | 35 | 62 | 0.64 | 36 | 60 | 0.63 |'
- en: '| Incorrect Units | 77 | 34 | 37 | 0.56 | 50 | 27 | 0.35 | 59 | 17 | 0.22 |'
  id: totrans-715
  prefs: []
  type: TYPE_TB
  zh: '| 不正确的单位 | 77 | 34 | 37 | 0.56 | 50 | 27 | 0.35 | 59 | 17 | 0.22 |'
- en: '| Wrong Formula | 88 | 25 | 54 | 0.77 | 43 | 44 | 0.51 | 55 | 32 | 0.37 |'
  id: totrans-716
  prefs: []
  type: TYPE_TB
  zh: '| 错误公式 | 88 | 25 | 54 | 0.77 | 43 | 44 | 0.51 | 55 | 32 | 0.37 |'
- en: '| Total | 494 | 159 | 290 | 0.71 | 260 | 233 | 0.47 | 285 | 201 | 0.41 |'
  id: totrans-717
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 494 | 159 | 290 | 0.71 | 260 | 233 | 0.47 | 285 | 201 | 0.41 |'
- en: 'Table 18: Results from evaluating FBI using Vanilla-Llama-3-70B-Instruct,Claude-3-Opus and
    Gemini-1.5-Pro evaluators. An error is said to be detected if the evaluator penalizes
    the score of the perturbed answer.'
  id: totrans-718
  prefs: []
  type: TYPE_NORMAL
  zh: 表 18：使用 Vanilla-Llama-3-70B-Instruct、Claude-3-Opus 和 Gemini-1.5-Pro 评估器评估 FBI
    的结果。如果评估器惩罚扰动答案的分数，则表示检测到错误。
- en: '|  |  |  | Llama-3-70B-Instruct | Gemini-1.5-Pro |'
  id: totrans-719
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | Llama-3-70B-Instruct | Gemini-1.5-Pro |'
- en: '| Perturbation Type | # Errs | G | P | Both ✓ | Both ✗ | $\neq$ | % Errs |
    G | P | Both ✓ | Both ✗ | $\neq$ | % Errs |'
  id: totrans-720
  prefs: []
  type: TYPE_TB
  zh: '| 扰动类型 | # 错误 | G | P | 两者✓ | 两者✗ | $\neq$ | % 错误 | G | P | 两者✓ | 两者✗ | $\neq$
    | % 错误 |'
- en: '| LF | Coherence | 91 | 59 | 0 | 0 | 0 | 18 | 0.23 | 77 | 0 | 2 | 0 | 12 |
    0.15 |'
  id: totrans-721
  prefs: []
  type: TYPE_TB
  zh: '| LF | 连贯性 | 91 | 59 | 0 | 0 | 0 | 18 | 0.23 | 77 | 0 | 2 | 0 | 12 | 0.15 |'
- en: '| Comprehensiveness | 90 | 40 | 0 | 0 | 0 | 34 | 0.46 | 40 | 0 | 24 | 0 | 26
    | 0.56 |'
  id: totrans-722
  prefs: []
  type: TYPE_TB
  zh: '| 完整性 | 90 | 40 | 0 | 0 | 0 | 34 | 0.46 | 40 | 0 | 24 | 0 | 26 | 0.56 |'
- en: '| Consistency | 84 | 8 | 0 | 2 | 0 | 69 | 0.90 | 13 | 0 | 49 | 0 | 22 | 0.85
    |'
  id: totrans-723
  prefs: []
  type: TYPE_TB
  zh: '| 一致性 | 84 | 8 | 0 | 2 | 0 | 69 | 0.90 | 13 | 0 | 49 | 0 | 22 | 0.85 |'
- en: '| Grammar | 92 | 6 | 0 | 9 | 0 | 66 | 0.93 | 11 | 0 | 42 | 0 | 39 | 0.88 |'
  id: totrans-724
  prefs: []
  type: TYPE_TB
  zh: '| 语法 | 92 | 6 | 0 | 9 | 0 | 66 | 0.93 | 11 | 0 | 42 | 0 | 39 | 0.88 |'
- en: '| Chronology | 71 | 0 | 0 | 1 | 0 | 63 | 1.00 | 3 | 0 | 52 | 0 | 16 | 0.96
    |'
  id: totrans-725
  prefs: []
  type: TYPE_TB
  zh: '| 年代学 | 71 | 0 | 0 | 1 | 0 | 63 | 1.00 | 3 | 0 | 52 | 0 | 16 | 0.96 |'
- en: '| Spelling | 100 | 4 | 0 | 18 | 0 | 64 | 0.95 | 3 | 0 | 76 | 0 | 21 | 0.97
    |'
  id: totrans-726
  prefs: []
  type: TYPE_TB
  zh: '| 拼写 | 100 | 4 | 0 | 18 | 0 | 64 | 0.95 | 3 | 0 | 76 | 0 | 21 | 0.97 |'
- en: '| Total | 528 | 117 | 0 | 30 | 0 | 314 | 0.75 | 147 | 0 | 245 | 0 | 136 | 0.72
    |'
  id: totrans-727
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 528 | 117 | 0 | 30 | 0 | 314 | 0.75 | 147 | 0 | 245 | 0 | 136 | 0.72
    |'
- en: '| F | Contextual | 94 | 20 | 0 | 5 | 0 | 40 | 0.69 | 43 | 1 | 8 | 0 | 42 |
    0.54 |'
  id: totrans-728
  prefs: []
  type: TYPE_TB
  zh: '| F | 上下文 | 94 | 20 | 0 | 5 | 0 | 40 | 0.69 | 43 | 1 | 8 | 0 | 42 | 0.54 |'
- en: '| Entity | 87 | 24 | 0 | 5 | 0 | 34 | 0.62 | 43 | 0 | 14 | 0 | 30 | 0.51 |'
  id: totrans-729
  prefs: []
  type: TYPE_TB
  zh: '| 实体 | 87 | 24 | 0 | 5 | 0 | 34 | 0.62 | 43 | 0 | 14 | 0 | 30 | 0.51 |'
- en: '| Incorrect Fact | 68 | 11 | 1 | 2 | 0 | 34 | 0.77 | 30 | 0 | 2 | 0 | 36 |
    0.56 |'
  id: totrans-730
  prefs: []
  type: TYPE_TB
  zh: '| 错误事实 | 68 | 11 | 1 | 2 | 0 | 34 | 0.77 | 30 | 0 | 2 | 0 | 36 | 0.56 |'
- en: '| Number Errors | 74 | 16 | 0 | 2 | 0 | 38 | 0.71 | 33 | 0 | 10 | 0 | 31 |
    0.55 |'
  id: totrans-731
  prefs: []
  type: TYPE_TB
  zh: '| 数字错误 | 74 | 16 | 0 | 2 | 0 | 38 | 0.71 | 33 | 0 | 10 | 0 | 31 | 0.55 |'
- en: '| Opposite Fact | 91 | 14 | 0 | 4 | 0 | 46 | 0.78 | 41 | 0 | 5 | 0 | 45 | 0.55
    |'
  id: totrans-732
  prefs: []
  type: TYPE_TB
  zh: '| 相反事实 | 91 | 14 | 0 | 4 | 0 | 46 | 0.78 | 41 | 0 | 5 | 0 | 45 | 0.55 |'
- en: '| Remove Fact | 69 | 24 | 0 | 4 | 0 | 33 | 0.61 | 12 | 0 | 35 | 0 | 22 | 0.83
    |'
  id: totrans-733
  prefs: []
  type: TYPE_TB
  zh: '| 移除事实 | 69 | 24 | 0 | 4 | 0 | 33 | 0.61 | 12 | 0 | 35 | 0 | 22 | 0.83 |'
- en: '| Total | 483 | 109 | 1 | 22 | 0 | 225 | 0.69 | 202 | 1 | 74 | 0 | 206 | 0.58
    |'
  id: totrans-734
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 483 | 109 | 1 | 22 | 0 | 225 | 0.69 | 202 | 1 | 74 | 0 | 206 | 0.58
    |'
- en: '| IF | Assumptions | 81 | 2 | 21 | 0 | 0 | 12 | 0.94 | 25 | 20 | 1 | 0 | 35
    | 0.69 |'
  id: totrans-735
  prefs: []
  type: TYPE_TB
  zh: '| IF | 假设 | 81 | 2 | 21 | 0 | 0 | 12 | 0.94 | 25 | 20 | 1 | 0 | 35 | 0.69 |'
- en: '| Do Less | 100 | 44 | 1 | 1 | 0 | 37 | 0.47 | 38 | 0 | 11 | 2 | 49 | 0.62
    |'
  id: totrans-736
  prefs: []
  type: TYPE_TB
  zh: '| 减少 | 100 | 44 | 1 | 1 | 0 | 37 | 0.47 | 38 | 0 | 11 | 2 | 49 | 0.62 |'
- en: '| Do More | 50 | 12 | 9 | 1 | 0 | 14 | 0.67 | 14 | 3 | 0 | 1 | 31 | 0.71 |'
  id: totrans-737
  prefs: []
  type: TYPE_TB
  zh: '| 增加 | 50 | 12 | 9 | 1 | 0 | 14 | 0.67 | 14 | 3 | 0 | 1 | 31 | 0.71 |'
- en: '| Ignore Format | 99 | 17 | 0 | 10 | 0 | 28 | 0.69 | 33 | 0 | 24 | 10 | 31
    | 0.66 |'
  id: totrans-738
  prefs: []
  type: TYPE_TB
  zh: '| 忽略格式 | 99 | 17 | 0 | 10 | 0 | 28 | 0.69 | 33 | 0 | 24 | 10 | 31 | 0.66 |'
- en: '| Sequence Errors | 49 | 0 | 0 | 0 | 0 | 41 | 1.00 | 4 | 0 | 18 | 0 | 27 |
    0.92 |'
  id: totrans-739
  prefs: []
  type: TYPE_TB
  zh: '| 顺序错误 | 49 | 0 | 0 | 0 | 0 | 41 | 1.00 | 4 | 0 | 18 | 0 | 27 | 0.92 |'
- en: '| Total | 379 | 75 | 31 | 12 | 0 | 132 | 0.70 | 114 | 23 | 54 | 13 | 173 |
    0.70 |'
  id: totrans-740
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 379 | 75 | 31 | 12 | 0 | 132 | 0.70 | 114 | 23 | 54 | 13 | 173 | 0.70
    |'
- en: '| R | Calculations | 149 | 48 | 0 | 30 | 0 | 44 | 0.61 | 89 | 1 | 12 | 0 |
    47 | 0.40 |'
  id: totrans-741
  prefs: []
  type: TYPE_TB
  zh: '| R | 计算 | 149 | 48 | 0 | 30 | 0 | 44 | 0.61 | 89 | 1 | 12 | 0 | 47 | 0.40
    |'
- en: '| Copying Numbers | 83 | 30 | 0 | 6 | 1 | 28 | 0.54 | 57 | 1 | 5 | 1 | 19 |
    0.31 |'
  id: totrans-742
  prefs: []
  type: TYPE_TB
  zh: '| 复制数字 | 83 | 30 | 0 | 6 | 1 | 28 | 0.54 | 57 | 1 | 5 | 1 | 19 | 0.31 |'
- en: '| Final Errors | 97 | 30 | 0 | 3 | 0 | 41 | 0.59 | 59 | 2 | 0 | 1 | 35 | 0.39
    |'
  id: totrans-743
  prefs: []
  type: TYPE_TB
  zh: '| 最终错误 | 97 | 30 | 0 | 3 | 0 | 41 | 0.59 | 59 | 2 | 0 | 1 | 35 | 0.39 |'
- en: '| Incorrect Units | 77 | 27 | 0 | 11 | 0 | 25 | 0.57 | 40 | 0 | 12 | 1 | 24
    | 0.48 |'
  id: totrans-744
  prefs: []
  type: TYPE_TB
  zh: '| 错误单位 | 77 | 27 | 0 | 11 | 0 | 25 | 0.57 | 40 | 0 | 12 | 1 | 24 | 0.48 |'
- en: '| Wrong Formula | 88 | 25 | 0 | 23 | 0 | 27 | 0.67 | 55 | 1 | 8 | 2 | 22 |
    0.38 |'
  id: totrans-745
  prefs: []
  type: TYPE_TB
  zh: '| 错误公式 | 88 | 25 | 0 | 23 | 0 | 27 | 0.67 | 55 | 1 | 8 | 2 | 22 | 0.38 |'
- en: '| Total | 494 | 160 | 0 | 73 | 1 | 165 | 0.60 | 300 | 5 | 37 | 5 | 147 | 0.39
    |'
  id: totrans-746
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 494 | 160 | 0 | 73 | 1 | 165 | 0.60 | 300 | 5 | 37 | 5 | 147 | 0.39
    |'
- en: 'Table 19: Results from evaluating FBI  using the Axis+Rules-Llama-3-70B-Instruct,Claude-3-Opus and
    Gemini-1.5-Pro evaluators. An error is said to be detected if the evaluator chooses
    the Gold Answer. G indicates the number of times the evaluator has chosen the
    Gold Answer, P for the Perturbed Answer, Both ✓ when both answers are correct,
    Both ✗ when both are incorrect, and $\neq$ for verdict inconsistencies.'
  id: totrans-747
  prefs: []
  type: TYPE_NORMAL
  zh: 表19：使用Axis+Rules-Llama-3-70B-Instruct、Claude-3-Opus和Gemini-1.5-Pro评估器评估FBI的结果。若评估器选择了金标准答案，则认为检测到了错误。G表示评估器选择了金标准答案的次数，P表示扰动答案，Both
    ✓表示两个答案都正确，Both ✗表示两个答案都不正确，$\neq$表示判决不一致。
- en: '|  |  |  | Llama-3-70B-Instruct | Gemini-1.5-Pro |'
  id: totrans-748
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | Llama-3-70B-Instruct | Gemini-1.5-Pro |'
- en: '| Perturbation Type | # Errs | 10 | 9 | 8 | $<$8 | % Errs | 10 | 9 | 8 | $<$8
    | % Errs |'
  id: totrans-749
  prefs: []
  type: TYPE_TB
  zh: '| 扰动类型 | # 错误 | 10 | 9 | 8 | $<$8 | % 错误 | 10 | 9 | 8 | $<$8 | % 错误 |'
- en: '| LF | Coherence | 91 | 1 | 2 | 3 | 75 | 0.02 | 1 | 1 | 2 | 87 | 0.01 |'
  id: totrans-750
  prefs: []
  type: TYPE_TB
  zh: '| LF | 连贯性 | 91 | 1 | 2 | 3 | 75 | 0.02 | 1 | 1 | 2 | 87 | 0.01 |'
- en: '| Comprehensiveness | 90 | 1 | 33 | 23 | 20 | 0.01 | 13 | 29 | 26 | 21 | 0.14
    |'
  id: totrans-751
  prefs: []
  type: TYPE_TB
  zh: '| 完整性 | 90 | 1 | 33 | 23 | 20 | 0.01 | 13 | 29 | 26 | 21 | 0.14 |'
- en: '| Consistency | 84 | 2 | 41 | 19 | 6 | 0.03 | 5 | 48 | 18 | 12 | 0.06 |'
  id: totrans-752
  prefs: []
  type: TYPE_TB
  zh: '| 一致性 | 84 | 2 | 41 | 19 | 6 | 0.03 | 5 | 48 | 18 | 12 | 0.06 |'
- en: '| Grammar | 92 | 1 | 55 | 11 | 5 | 0.01 | 31 | 38 | 17 | 5 | 0.34 |'
  id: totrans-753
  prefs: []
  type: TYPE_TB
  zh: '| 语法 | 92 | 1 | 55 | 11 | 5 | 0.01 | 31 | 38 | 17 | 5 | 0.34 |'
- en: '| Chronology | 71 | 3 | 34 | 13 | 1 | 0.06 | 15 | 41 | 12 | 3 | 0.21 |'
  id: totrans-754
  prefs: []
  type: TYPE_TB
  zh: '| 时间顺序 | 71 | 3 | 34 | 13 | 1 | 0.06 | 15 | 41 | 12 | 3 | 0.21 |'
- en: '| Spelling | 100 | 4 | 52 | 9 | 4 | 0.06 | 65 | 28 | 5 | 1 | 0.66 |'
  id: totrans-755
  prefs: []
  type: TYPE_TB
  zh: '| 拼写 | 100 | 4 | 52 | 9 | 4 | 0.06 | 65 | 28 | 5 | 1 | 0.66 |'
- en: '| Total | 528 | 12 | 217 | 78 | 111 | 0.03 | 130 | 185 | 80 | 129 | 0.25 |'
  id: totrans-756
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 528 | 12 | 217 | 78 | 111 | 0.03 | 130 | 185 | 80 | 129 | 0.25 |'
- en: '| F | Contextual | 94 | 0 | 49 | 19 | 19 | 0.00 | 4 | 34 | 24 | 29 | 0.04 |'
  id: totrans-757
  prefs: []
  type: TYPE_TB
  zh: '| F | 上下文 | 94 | 0 | 49 | 19 | 19 | 0.00 | 4 | 34 | 24 | 29 | 0.04 |'
- en: '| Entity | 87 | 0 | 50 | 17 | 16 | 0.00 | 7 | 29 | 26 | 20 | 0.08 |'
  id: totrans-758
  prefs: []
  type: TYPE_TB
  zh: '| 实体 | 87 | 0 | 50 | 17 | 16 | 0.00 | 7 | 29 | 26 | 20 | 0.08 |'
- en: '| Incorrect Fact | 68 | 0 | 38 | 18 | 9 | 0.00 | 2 | 31 | 20 | 13 | 0.03 |'
  id: totrans-759
  prefs: []
  type: TYPE_TB
  zh: '| 错误事实 | 68 | 0 | 38 | 18 | 9 | 0.00 | 2 | 31 | 20 | 13 | 0.03 |'
- en: '| Number Errors | 74 | 2 | 53 | 10 | 4 | 0.03 | 3 | 34 | 22 | 9 | 0.04 |'
  id: totrans-760
  prefs: []
  type: TYPE_TB
  zh: '| 数字错误 | 74 | 2 | 53 | 10 | 4 | 0.03 | 3 | 34 | 22 | 9 | 0.04 |'
- en: '| Opposite Fact | 91 | 0 | 37 | 19 | 30 | 0.00 | 4 | 18 | 30 | 38 | 0.04 |'
  id: totrans-761
  prefs: []
  type: TYPE_TB
  zh: '| 相反事实 | 91 | 0 | 37 | 19 | 30 | 0.00 | 4 | 18 | 30 | 38 | 0.04 |'
- en: '| Remove Fact | 69 | 4 | 29 | 22 | 13 | 0.06 | 13 | 18 | 26 | 12 | 0.19 |'
  id: totrans-762
  prefs: []
  type: TYPE_TB
  zh: '| 移除事实 | 69 | 4 | 29 | 22 | 13 | 0.06 | 13 | 18 | 26 | 12 | 0.19 |'
- en: '| Total | 483 | 6 | 256 | 105 | 91 | 0.01 | 33 | 164 | 148 | 121 | 0.07 |'
  id: totrans-763
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 483 | 6 | 256 | 105 | 91 | 0.01 | 33 | 164 | 148 | 121 | 0.07 |'
- en: '| IF | Assumptions | 81 | 0 | 31 | 23 | 19 | 0.00 | 0 | 12 | 20 | 48 | 0.00
    |'
  id: totrans-764
  prefs: []
  type: TYPE_TB
  zh: '| IF | 假设 | 81 | 0 | 31 | 23 | 19 | 0.00 | 0 | 12 | 20 | 48 | 0.00 |'
- en: '| Do Less | 100 | 1 | 23 | 35 | 32 | 0.01 | 26 | 15 | 27 | 32 | 0.26 |'
  id: totrans-765
  prefs: []
  type: TYPE_TB
  zh: '| 做得少 | 100 | 1 | 23 | 35 | 32 | 0.01 | 26 | 15 | 27 | 32 | 0.26 |'
- en: '| Do More | 50 | 1 | 31 | 15 | 1 | 0.02 | 1 | 13 | 28 | 7 | 0.02 |'
  id: totrans-766
  prefs: []
  type: TYPE_TB
  zh: '| 做得多 | 50 | 1 | 31 | 15 | 1 | 0.02 | 1 | 13 | 28 | 7 | 0.02 |'
- en: '| Ignore Format | 99 | 11 | 29 | 14 | 16 | 0.16 | 32 | 17 | 15 | 33 | 0.33
    |'
  id: totrans-767
  prefs: []
  type: TYPE_TB
  zh: '| 忽略格式 | 99 | 11 | 29 | 14 | 16 | 0.16 | 32 | 17 | 15 | 33 | 0.33 |'
- en: '| Sequence Errors | 49 | 5 | 28 | 13 | 0 | 0.11 | 6 | 26 | 14 | 3 | 0.12 |'
  id: totrans-768
  prefs: []
  type: TYPE_TB
  zh: '| 序列错误 | 49 | 5 | 28 | 13 | 0 | 0.11 | 6 | 26 | 14 | 3 | 0.12 |'
- en: '| Total | 379 | 18 | 142 | 100 | 68 | 0.05 | 65 | 83 | 104 | 123 | 0.17 |'
  id: totrans-769
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 379 | 18 | 142 | 100 | 68 | 0.05 | 65 | 83 | 104 | 123 | 0.17 |'
- en: '| R | Calculations | 149 | 10 | 35 | 41 | 49 | 0.07 | 5 | 17 | 36 | 82 | 0.03
    |'
  id: totrans-770
  prefs: []
  type: TYPE_TB
  zh: '| R | 计算 | 149 | 10 | 35 | 41 | 49 | 0.07 | 5 | 17 | 36 | 82 | 0.03 |'
- en: '| Copying Numbers | 83 | 2 | 16 | 23 | 36 | 0.03 | 3 | 13 | 14 | 52 | 0.04
    |'
  id: totrans-771
  prefs: []
  type: TYPE_TB
  zh: '| 复制数字 | 83 | 2 | 16 | 23 | 36 | 0.03 | 3 | 13 | 14 | 52 | 0.04 |'
- en: '| Final Errors | 97 | 0 | 20 | 56 | 13 | 0.00 | 0 | 28 | 44 | 23 | 0.00 |'
  id: totrans-772
  prefs: []
  type: TYPE_TB
  zh: '| 最终错误 | 97 | 0 | 20 | 56 | 13 | 0.00 | 0 | 28 | 44 | 23 | 0.00 |'
- en: '| Incorrect Units | 77 | 2 | 22 | 11 | 34 | 0.03 | 3 | 17 | 12 | 45 | 0.04
    |'
  id: totrans-773
  prefs: []
  type: TYPE_TB
  zh: '| 错误单位 | 77 | 2 | 22 | 11 | 34 | 0.03 | 3 | 17 | 12 | 45 | 0.04 |'
- en: '| Wrong Formula | 88 | 7 | 26 | 25 | 25 | 0.08 | 2 | 12 | 20 | 53 | 0.02 |'
  id: totrans-774
  prefs: []
  type: TYPE_TB
  zh: '| 错误公式 | 88 | 7 | 26 | 25 | 25 | 0.08 | 2 | 12 | 20 | 53 | 0.02 |'
- en: '| Total | 494 | 21 | 119 | 156 | 157 | 0.05 | 13 | 87 | 126 | 255 | 0.03 |'
  id: totrans-775
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 494 | 21 | 119 | 156 | 157 | 0.05 | 13 | 87 | 126 | 255 | 0.03 |'
- en: 'Table 20: Results from evaluating FBI  using the Reference-Llama-3-70B-Instruct,Claude-3-Opus and
    Gemini-1.5-Pro evaluators. An error is said to be detected if the evaluator gives
    a perfect score of 10 to the perturbed answer. 10 indicates the number of times
    the evaluator has given the score of 10, 9 for the score of 9, 8 for the score
    of 8 and $<$8 for scores less than 8.'
  id: totrans-776
  prefs: []
  type: TYPE_NORMAL
  zh: 表20：使用 Reference-Llama-3-70B-Instruct、Claude-3-Opus 和 Gemini-1.5-Pro 评估器的 FBI
    评估结果。如果评估器对被扰动的回答给出满分 10，则认为检测到了错误。10 表示评估器给出满分 10 的次数，9 表示评分为 9 的次数，8 表示评分为 8
    的次数，$<$8 表示评分低于 8 的次数。
- en: '|  | Perturbation Type | # Errs |'
  id: totrans-777
  prefs: []
  type: TYPE_TB
  zh: '|  | 扰动类型 | # 错误 |'
- en: '&#124; Detected &#124;'
  id: totrans-778
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 检测到 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-779
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-780
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Undetected &#124;'
  id: totrans-781
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 未检测到 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-782
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-783
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Detected in &#124;'
  id: totrans-784
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 检测到 &#124;'
- en: '&#124; Explanation &#124;'
  id: totrans-785
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 解释 &#124;'
- en: '|'
  id: totrans-786
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; % Undetected &#124;'
  id: totrans-787
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; % 未检测到 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-788
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-789
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| LF | Coherence | 91 | 82 | 9 | 1 | 0.09 |'
  id: totrans-790
  prefs: []
  type: TYPE_TB
  zh: '| LF | 一致性 | 91 | 82 | 9 | 1 | 0.09 |'
- en: '| Comprehensiveness | 90 | 30 | 60 | 5 | 0.61 |'
  id: totrans-791
  prefs: []
  type: TYPE_TB
  zh: '| 完整性 | 90 | 30 | 60 | 5 | 0.61 |'
- en: '| Consistency | 84 | 35 | 49 | 7 | 0.50 |'
  id: totrans-792
  prefs: []
  type: TYPE_TB
  zh: '| 一致性 | 84 | 35 | 49 | 7 | 0.50 |'
- en: '| Grammar | 92 | 40 | 52 | 9 | 0.47 |'
  id: totrans-793
  prefs: []
  type: TYPE_TB
  zh: '| 语法 | 92 | 40 | 52 | 9 | 0.47 |'
- en: '| Chronology | 71 | 18 | 53 | 3 | 0.70 |'
  id: totrans-794
  prefs: []
  type: TYPE_TB
  zh: '| 时间顺序 | 71 | 18 | 53 | 3 | 0.70 |'
- en: '| Spelling | 100 | 20 | 80 | 11 | 0.69 |'
  id: totrans-795
  prefs: []
  type: TYPE_TB
  zh: '| 拼写 | 100 | 20 | 80 | 11 | 0.69 |'
- en: '| Total | 528 | 225 | 303 | 36 | 0.51 |'
  id: totrans-796
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 528 | 225 | 303 | 36 | 0.51 |'
- en: '| F | Contextual | 94 | 45 | 48 | 5 | 0.47 |'
  id: totrans-797
  prefs: []
  type: TYPE_TB
  zh: '| F | 上下文 | 94 | 45 | 48 | 5 | 0.47 |'
- en: '| Entity | 87 | 43 | 44 | 3 | 0.47 |'
  id: totrans-798
  prefs: []
  type: TYPE_TB
  zh: '| 实体 | 87 | 43 | 44 | 3 | 0.47 |'
- en: '| Incorrect Fact | 68 | 29 | 38 | 4 | 0.51 |'
  id: totrans-799
  prefs: []
  type: TYPE_TB
  zh: '| 错误事实 | 68 | 29 | 38 | 4 | 0.51 |'
- en: '| Number Errors | 74 | 30 | 44 | 3 | 0.55 |'
  id: totrans-800
  prefs: []
  type: TYPE_TB
  zh: '| 数字错误 | 74 | 30 | 44 | 3 | 0.55 |'
- en: '| Opposite Fact | 91 | 48 | 42 | 6 | 0.41 |'
  id: totrans-801
  prefs: []
  type: TYPE_TB
  zh: '| 相反事实 | 91 | 48 | 42 | 6 | 0.41 |'
- en: '| Remove Fact | 69 | 25 | 44 | 0 | 0.64 |'
  id: totrans-802
  prefs: []
  type: TYPE_TB
  zh: '| 删除事实 | 69 | 25 | 44 | 0 | 0.64 |'
- en: '| Total | 483 | 220 | 260 | 21 | 0.50 |'
  id: totrans-803
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 483 | 220 | 260 | 21 | 0.50 |'
- en: '| IF | Assumptions | 81 | 12 | 69 | 7 | 0.77 |'
  id: totrans-804
  prefs: []
  type: TYPE_TB
  zh: '| IF | 假设 | 81 | 12 | 69 | 7 | 0.77 |'
- en: '| Do Less | 100 | 57 | 43 | 6 | 0.37 |'
  id: totrans-805
  prefs: []
  type: TYPE_TB
  zh: '| 减少 | 100 | 57 | 43 | 6 | 0.37 |'
- en: '| Do More | 50 | 31 | 19 | 12 | 0.14 |'
  id: totrans-806
  prefs: []
  type: TYPE_TB
  zh: '| 增加 | 50 | 31 | 19 | 12 | 0.14 |'
- en: '| Ignore Format | 99 | 41 | 57 | 10 | 0.48 |'
  id: totrans-807
  prefs: []
  type: TYPE_TB
  zh: '| 忽略格式 | 99 | 41 | 57 | 10 | 0.48 |'
- en: '| Sequence Errors | 49 | 20 | 29 | 1 | 0.57 |'
  id: totrans-808
  prefs: []
  type: TYPE_TB
  zh: '| 顺序错误 | 49 | 20 | 29 | 1 | 0.57 |'
- en: '| Total | 379 | 161 | 217 | 36 | 0.48 |'
  id: totrans-809
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 379 | 161 | 217 | 36 | 0.48 |'
- en: '| R | Calculations | 149 | 112 | 34 | 15 | 0.15 |'
  id: totrans-810
  prefs: []
  type: TYPE_TB
  zh: '| R | 计算 | 149 | 112 | 34 | 15 | 0.15 |'
- en: '| Copying Numbers | 83 | 69 | 12 | 3 | 0.13 |'
  id: totrans-811
  prefs: []
  type: TYPE_TB
  zh: '| 复制数字 | 83 | 69 | 12 | 3 | 0.13 |'
- en: '| Final Errors | 97 | 53 | 43 | 16 | 0.29 |'
  id: totrans-812
  prefs: []
  type: TYPE_TB
  zh: '| 最终错误 | 97 | 53 | 43 | 16 | 0.29 |'
- en: '| Incorrect Units | 77 | 60 | 16 | 7 | 0.13 |'
  id: totrans-813
  prefs: []
  type: TYPE_TB
  zh: '| 错误单位 | 77 | 60 | 16 | 7 | 0.13 |'
- en: '| Wrong Formula | 88 | 66 | 19 | 6 | 0.18 |'
  id: totrans-814
  prefs: []
  type: TYPE_TB
  zh: '| 错误公式 | 88 | 66 | 19 | 6 | 0.18 |'
- en: '| Total | 494 | 360 | 124 | 47 | 0.18 |'
  id: totrans-815
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 494 | 360 | 124 | 47 | 0.18 |'
- en: 'Table 21: Results from looking at the explanation of the Vanilla evaluator
    to determine the presence of the error in the response. Detected in Explanation
    shows the number of “additional” errors detected by looking at the explanation
    in addition to the score.'
  id: totrans-816
  prefs: []
  type: TYPE_NORMAL
  zh: 表21：通过查看 Vanilla 评估器的解释来确定响应中错误的存在情况。检测到的解释显示除了评分外，通过查看解释检测到的“额外”错误的数量。
- en: '|  | Perturbation Type | # Errs |'
  id: totrans-817
  prefs: []
  type: TYPE_TB
  zh: '|  | 扰动类型 | # 错误 |'
- en: '&#124; Detected &#124;'
  id: totrans-818
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 检测到 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-819
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-820
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Undetected &#124;'
  id: totrans-821
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 未检测到 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-822
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-823
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Detected in &#124;'
  id: totrans-824
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 检测到 &#124;'
- en: '&#124; Justification &#124;'
  id: totrans-825
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 说明 &#124;'
- en: '|'
  id: totrans-826
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; % Undetected &#124;'
  id: totrans-827
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; % 未检测到 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-828
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-829
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| LF | Coherence | 91 | 58 | 33 | 1 | 0.35 |'
  id: totrans-830
  prefs: []
  type: TYPE_TB
  zh: '| LF | 一致性 | 91 | 58 | 33 | 1 | 0.35 |'
- en: '| Comprehensiveness | 90 | 1 | 89 | 5 | 0.93 |'
  id: totrans-831
  prefs: []
  type: TYPE_TB
  zh: '| 完整性 | 90 | 1 | 89 | 5 | 0.93 |'
- en: '| Consistency | 84 | 8 | 76 | 3 | 0.87 |'
  id: totrans-832
  prefs: []
  type: TYPE_TB
  zh: '| 一致性 | 84 | 8 | 76 | 3 | 0.87 |'
- en: '| Grammar | 92 | 17 | 75 | 7 | 0.74 |'
  id: totrans-833
  prefs: []
  type: TYPE_TB
  zh: '| 语法 | 92 | 17 | 75 | 7 | 0.74 |'
- en: '| Chronology | 71 | 0 | 71 | 9 | 0.87 |'
  id: totrans-834
  prefs: []
  type: TYPE_TB
  zh: '| 时间顺序 | 71 | 0 | 71 | 9 | 0.87 |'
- en: '| Spelling | 100 | 6 | 94 | 3 | 0.91 |'
  id: totrans-835
  prefs: []
  type: TYPE_TB
  zh: '| 拼写 | 100 | 6 | 94 | 3 | 0.91 |'
- en: '| Total | 528 | 90 | 438 | 28 | 0.78 |'
  id: totrans-836
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 528 | 90 | 438 | 28 | 0.78 |'
- en: '| F | Contextual | 94 | 29 | 65 | 23 | 0.45 |'
  id: totrans-837
  prefs: []
  type: TYPE_TB
  zh: '| F | 上下文 | 94 | 29 | 65 | 23 | 0.45 |'
- en: '| Entity | 87 | 30 | 57 | 15 | 0.48 |'
  id: totrans-838
  prefs: []
  type: TYPE_TB
  zh: '| 实体 | 87 | 30 | 57 | 15 | 0.48 |'
- en: '| Incorrect Fact | 68 | 17 | 51 | 14 | 0.54 |'
  id: totrans-839
  prefs: []
  type: TYPE_TB
  zh: '| 错误事实 | 68 | 17 | 51 | 14 | 0.54 |'
- en: '| Number Errors | 74 | 18 | 56 | 16 | 0.54 |'
  id: totrans-840
  prefs: []
  type: TYPE_TB
  zh: '| 数字错误 | 74 | 18 | 56 | 16 | 0.54 |'
- en: '| Opposite Fact | 91 | 32 | 59 | 23 | 0.40 |'
  id: totrans-841
  prefs: []
  type: TYPE_TB
  zh: '| 相反事实 | 91 | 32 | 59 | 23 | 0.40 |'
- en: '| Remove Fact | 69 | 1 | 68 | 20 | 0.70 |'
  id: totrans-842
  prefs: []
  type: TYPE_TB
  zh: '| 删除事实 | 69 | 1 | 68 | 20 | 0.70 |'
- en: '| Total | 483 | 127 | 356 | 111 | 0.51 |'
  id: totrans-843
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 483 | 127 | 356 | 111 | 0.51 |'
- en: '| IF | Assumptions | 81 | 5 | 76 | 8 | 0.84 |'
  id: totrans-844
  prefs: []
  type: TYPE_TB
  zh: '| IF | 假设 | 81 | 5 | 76 | 8 | 0.84 |'
- en: '| Do Less | 100 | 20 | 80 | 0 | 0.80 |'
  id: totrans-845
  prefs: []
  type: TYPE_TB
  zh: '| 减少 | 100 | 20 | 80 | 0 | 0.80 |'
- en: '| Do More | 50 | 40 | 10 | 6 | 0.08 |'
  id: totrans-846
  prefs: []
  type: TYPE_TB
  zh: '| 多做 | 50 | 40 | 10 | 6 | 0.08 |'
- en: '| Ignore Format | 99 | 25 | 74 | 12 | 0.63 |'
  id: totrans-847
  prefs: []
  type: TYPE_TB
  zh: '| 忽略格式 | 99 | 25 | 74 | 12 | 0.63 |'
- en: '| Sequence Errors | 49 | 5 | 44 | 16 | 0.57 |'
  id: totrans-848
  prefs: []
  type: TYPE_TB
  zh: '| 序列错误 | 49 | 5 | 44 | 16 | 0.57 |'
- en: '| Total | 379 | 95 | 284 | 42 | 0.64 |'
  id: totrans-849
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 379 | 95 | 284 | 42 | 0.64 |'
- en: '| R | Calculations | 149 | 100 | 49 | 9 | 0.27 |'
  id: totrans-850
  prefs: []
  type: TYPE_TB
  zh: '| R | 计算 | 149 | 100 | 49 | 9 | 0.27 |'
- en: '| Copying Numbers | 83 | 57 | 26 | 9 | 0.20 |'
  id: totrans-851
  prefs: []
  type: TYPE_TB
  zh: '| 复制数字 | 83 | 57 | 26 | 9 | 0.20 |'
- en: '| Final Errors | 97 | 46 | 51 | 7 | 0.45 |'
  id: totrans-852
  prefs: []
  type: TYPE_TB
  zh: '| 最终错误 | 97 | 46 | 51 | 7 | 0.45 |'
- en: '| Incorrect Units | 77 | 42 | 35 | 7 | 0.36 |'
  id: totrans-853
  prefs: []
  type: TYPE_TB
  zh: '| 错误单位 | 77 | 42 | 35 | 7 | 0.36 |'
- en: '| Wrong Formula | 88 | 63 | 25 | 6 | 0.22 |'
  id: totrans-854
  prefs: []
  type: TYPE_TB
  zh: '| 错误公式 | 88 | 63 | 25 | 6 | 0.22 |'
- en: '| Total | 494 | 308 | 186 | 38 | 0.30 |'
  id: totrans-855
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 494 | 308 | 186 | 38 | 0.30 |'
- en: 'Table 22: Results from looking at the explanation of the Axis evaluator to
    determine the presence of the error in the response. Detected in Explanation shows
    the number of “additional” errors detected by looking at the explanation in addition
    to the score.'
  id: totrans-856
  prefs: []
  type: TYPE_NORMAL
  zh: 表 22：从查看 Axis 评估器的解释来确定响应中错误的存在。检测到的解释显示了通过查看解释而不是得分所检测到的“额外”错误数量。
- en: '|  | Perturbation Type | # Errs |'
  id: totrans-857
  prefs: []
  type: TYPE_TB
  zh: '|  | 干扰类型 | 错误数量 |'
- en: '&#124; Detected &#124;'
  id: totrans-858
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 检测到的 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-859
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-860
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Undetected &#124;'
  id: totrans-861
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 未检测到的 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-862
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-863
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Detected in &#124;'
  id: totrans-864
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 检测到的 &#124;'
- en: '&#124; Justification &#124;'
  id: totrans-865
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 证明 &#124;'
- en: '|'
  id: totrans-866
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; % Undetected &#124;'
  id: totrans-867
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; % 未检测到的 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-868
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-869
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| LF | Coherence | 91 | 47 | 44 | 2 | 0.46 |'
  id: totrans-870
  prefs: []
  type: TYPE_TB
  zh: '| LF | 连贯性 | 91 | 47 | 44 | 2 | 0.46 |'
- en: '| Comprehensiveness | 90 | 2 | 88 | 5 | 0.92 |'
  id: totrans-871
  prefs: []
  type: TYPE_TB
  zh: '| 完整性 | 90 | 2 | 88 | 5 | 0.92 |'
- en: '| Consistency | 84 | 11 | 73 | 6 | 0.80 |'
  id: totrans-872
  prefs: []
  type: TYPE_TB
  zh: '| 一致性 | 84 | 11 | 73 | 6 | 0.80 |'
- en: '| Grammar | 92 | 15 | 77 | 6 | 0.77 |'
  id: totrans-873
  prefs: []
  type: TYPE_TB
  zh: '| 语法 | 92 | 15 | 77 | 6 | 0.77 |'
- en: '| Chronology | 71 | 0 | 71 | 5 | 0.93 |'
  id: totrans-874
  prefs: []
  type: TYPE_TB
  zh: '| 年代顺序 | 71 | 0 | 71 | 5 | 0.93 |'
- en: '| Spelling | 100 | 4 | 96 | 8 | 0.88 |'
  id: totrans-875
  prefs: []
  type: TYPE_TB
  zh: '| 拼写 | 100 | 4 | 96 | 8 | 0.88 |'
- en: '| Total | 528 | 79 | 449 | 32 | 0.79 |'
  id: totrans-876
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 528 | 79 | 449 | 32 | 0.79 |'
- en: '| F | Contextual | 94 | 34 | 60 | 3 | 0.61 |'
  id: totrans-877
  prefs: []
  type: TYPE_TB
  zh: '| F | 上下文 | 94 | 34 | 60 | 3 | 0.61 |'
- en: '| Entity | 87 | 29 | 58 | 3 | 0.63 |'
  id: totrans-878
  prefs: []
  type: TYPE_TB
  zh: '| 实体 | 87 | 29 | 58 | 3 | 0.63 |'
- en: '| Incorrect Fact | 68 | 18 | 50 | 2 | 0.71 |'
  id: totrans-879
  prefs: []
  type: TYPE_TB
  zh: '| 错误事实 | 68 | 18 | 50 | 2 | 0.71 |'
- en: '| Number Errors | 74 | 17 | 57 | 7 | 0.68 |'
  id: totrans-880
  prefs: []
  type: TYPE_TB
  zh: '| 数字错误 | 74 | 17 | 57 | 7 | 0.68 |'
- en: '| Opposite Fact | 91 | 32 | 59 | 6 | 0.58 |'
  id: totrans-881
  prefs: []
  type: TYPE_TB
  zh: '| 相反事实 | 91 | 32 | 59 | 6 | 0.58 |'
- en: '| Remove Fact | 69 | 1 | 68 | 10 | 0.84 |'
  id: totrans-882
  prefs: []
  type: TYPE_TB
  zh: '| 删除事实 | 69 | 1 | 68 | 10 | 0.84 |'
- en: '| Total | 483 | 131 | 352 | 31 | 0.66 |'
  id: totrans-883
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 483 | 131 | 352 | 31 | 0.66 |'
- en: '| IF | Assumptions | 81 | 1 | 80 | 1 | 0.98 |'
  id: totrans-884
  prefs: []
  type: TYPE_TB
  zh: '| IF | 假设 | 81 | 1 | 80 | 1 | 0.98 |'
- en: '| Do Less | 100 | 8 | 92 | 8 | 0.84 |'
  id: totrans-885
  prefs: []
  type: TYPE_TB
  zh: '| 少做 | 100 | 8 | 92 | 8 | 0.84 |'
- en: '| Do More | 50 | 39 | 11 | 2 | 0.18 |'
  id: totrans-886
  prefs: []
  type: TYPE_TB
  zh: '| 多做 | 50 | 39 | 11 | 2 | 0.18 |'
- en: '| Ignore Format | 99 | 26 | 73 | 14 | 0.60 |'
  id: totrans-887
  prefs: []
  type: TYPE_TB
  zh: '| 忽略格式 | 99 | 26 | 73 | 14 | 0.60 |'
- en: '| Sequence Errors | 49 | 0 | 49 | 5 | 0.90 |'
  id: totrans-888
  prefs: []
  type: TYPE_TB
  zh: '| 序列错误 | 49 | 0 | 49 | 5 | 0.90 |'
- en: '| Total | 379 | 74 | 305 | 30 | 0.73 |'
  id: totrans-889
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 379 | 74 | 305 | 30 | 0.73 |'
- en: '| R | Calculations | 149 | 102 | 47 | 10 | 0.25 |'
  id: totrans-890
  prefs: []
  type: TYPE_TB
  zh: '| R | 计算 | 149 | 102 | 47 | 10 | 0.25 |'
- en: '| Copying Numbers | 83 | 64 | 19 | 3 | 0.19 |'
  id: totrans-891
  prefs: []
  type: TYPE_TB
  zh: '| 复制数字 | 83 | 64 | 19 | 3 | 0.19 |'
- en: '| Final Errors | 97 | 49 | 48 | 9 | 0.40 |'
  id: totrans-892
  prefs: []
  type: TYPE_TB
  zh: '| 最终错误 | 97 | 49 | 48 | 9 | 0.40 |'
- en: '| Incorrect Units | 77 | 56 | 21 | 4 | 0.22 |'
  id: totrans-893
  prefs: []
  type: TYPE_TB
  zh: '| 错误单位 | 77 | 56 | 21 | 4 | 0.22 |'
- en: '| Wrong Formula | 88 | 61 | 27 | 13 | 0.16 |'
  id: totrans-894
  prefs: []
  type: TYPE_TB
  zh: '| 错误公式 | 88 | 61 | 27 | 13 | 0.16 |'
- en: '| Total | 494 | 332 | 162 | 39 | 0.25 |'
  id: totrans-895
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 494 | 332 | 162 | 39 | 0.25 |'
- en: 'Table 23: Results from looking at the explanation of the Rubrics evaluator
    to determine the presence of the error in the response. Detected in Explanation
    shows the number of “additional” errors detected by looking at the explanation
    in addition to the score.'
  id: totrans-896
  prefs: []
  type: TYPE_NORMAL
  zh: 表 23：从查看 Rubrics 评估器的解释来确定响应中错误的存在。检测到的解释显示了通过查看解释而不是得分所检测到的“额外”错误数量。
- en: '|  | Perturbation Type | # Errs |'
  id: totrans-897
  prefs: []
  type: TYPE_TB
  zh: '|  | 干扰类型 | 错误数量 |'
- en: '&#124; Detected &#124;'
  id: totrans-898
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 检测到的 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-899
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-900
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Undetected &#124;'
  id: totrans-901
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 未检测到的 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-902
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-903
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Detected in &#124;'
  id: totrans-904
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 检测到的 &#124;'
- en: '&#124; Justification &#124;'
  id: totrans-905
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 证明 &#124;'
- en: '|'
  id: totrans-906
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; % Undetected &#124;'
  id: totrans-907
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; % 未检测到的 &#124;'
- en: '&#124; Errors &#124;'
  id: totrans-908
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误 &#124;'
- en: '|'
  id: totrans-909
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| LF | Coherence | 91 | 45 | 46 | 0 | 0.51 |'
  id: totrans-910
  prefs: []
  type: TYPE_TB
  zh: '| LF | 连贯性 | 91 | 45 | 46 | 0 | 0.51 |'
- en: '| Comprehensiveness | 90 | 0 | 90 | 11 | 0.88 |'
  id: totrans-911
  prefs: []
  type: TYPE_TB
  zh: '| 完整性 | 90 | 0 | 90 | 11 | 0.88 |'
- en: '| Consistency | 84 | 6 | 78 | 8 | 0.83 |'
  id: totrans-912
  prefs: []
  type: TYPE_TB
  zh: '| 一致性 | 84 | 6 | 78 | 8 | 0.83 |'
- en: '| Grammar | 92 | 16 | 76 | 5 | 0.77 |'
  id: totrans-913
  prefs: []
  type: TYPE_TB
  zh: '| 语法 | 92 | 16 | 76 | 5 | 0.77 |'
- en: '| Chronology | 71 | 0 | 71 | 12 | 0.83 |'
  id: totrans-914
  prefs: []
  type: TYPE_TB
  zh: '| 年代顺序 | 71 | 0 | 71 | 12 | 0.83 |'
- en: '| Spelling | 100 | 7 | 93 | 6 | 0.87 |'
  id: totrans-915
  prefs: []
  type: TYPE_TB
  zh: '| 拼写 | 100 | 7 | 93 | 6 | 0.87 |'
- en: '| Total | 528 | 74 | 454 | 42 | 0.78 |'
  id: totrans-916
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 528 | 74 | 454 | 42 | 0.78 |'
- en: '| F | Contextual | 94 | 28 | 66 | 19 | 0.50 |'
  id: totrans-917
  prefs: []
  type: TYPE_TB
  zh: '| F | 上下文 | 94 | 28 | 66 | 19 | 0.50 |'
- en: '| Entity | 87 | 27 | 60 | 9 | 0.59 |'
  id: totrans-918
  prefs: []
  type: TYPE_TB
  zh: '| 实体 | 87 | 27 | 60 | 9 | 0.59 |'
- en: '| Incorrect Fact | 68 | 15 | 53 | 10 | 0.63 |'
  id: totrans-919
  prefs: []
  type: TYPE_TB
  zh: '| 错误事实 | 68 | 15 | 53 | 10 | 0.63 |'
- en: '| Number Errors | 74 | 15 | 59 | 12 | 0.64 |'
  id: totrans-920
  prefs: []
  type: TYPE_TB
  zh: '| 数字错误 | 74 | 15 | 59 | 12 | 0.64 |'
- en: '| Opposite Fact | 91 | 28 | 63 | 12 | 0.56 |'
  id: totrans-921
  prefs: []
  type: TYPE_TB
  zh: '| 相反事实 | 91 | 28 | 63 | 12 | 0.56 |'
- en: '| Remove Fact | 69 | 1 | 68 | 16 | 0.75 |'
  id: totrans-922
  prefs: []
  type: TYPE_TB
  zh: '| 去除事实 | 69 | 1 | 68 | 16 | 0.75 |'
- en: '| Total | 483 | 114 | 369 | 78 | 0.60 |'
  id: totrans-923
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 483 | 114 | 369 | 78 | 0.60 |'
- en: '| IF | Assumptions | 81 | 2 | 79 | 6 | 0.90 |'
  id: totrans-924
  prefs: []
  type: TYPE_TB
  zh: '| IF | 假设 | 81 | 2 | 79 | 6 | 0.90 |'
- en: '| Do Less | 100 | 17 | 83 | 9 | 0.74 |'
  id: totrans-925
  prefs: []
  type: TYPE_TB
  zh: '| 做得更少 | 100 | 17 | 83 | 9 | 0.74 |'
- en: '| Do More | 50 | 39 | 11 | 1 | 0.20 |'
  id: totrans-926
  prefs: []
  type: TYPE_TB
  zh: '| 做得更多 | 50 | 39 | 11 | 1 | 0.20 |'
- en: '| Ignore Format | 99 | 24 | 75 | 14 | 0.62 |'
  id: totrans-927
  prefs: []
  type: TYPE_TB
  zh: '| 忽略格式 | 99 | 24 | 75 | 14 | 0.62 |'
- en: '| Sequence Errors | 49 | 4 | 45 | 5 | 0.82 |'
  id: totrans-928
  prefs: []
  type: TYPE_TB
  zh: '| 序列错误 | 49 | 4 | 45 | 5 | 0.82 |'
- en: '| Total | 379 | 86 | 293 | 35 | 0.68 |'
  id: totrans-929
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 379 | 86 | 293 | 35 | 0.68 |'
- en: '| R | Calculations | 149 | 97 | 52 | 14 | 0.26 |'
  id: totrans-930
  prefs: []
  type: TYPE_TB
  zh: '| R | 计算 | 149 | 97 | 52 | 14 | 0.26 |'
- en: '| Copying Numbers | 83 | 58 | 25 | 7 | 0.22 |'
  id: totrans-931
  prefs: []
  type: TYPE_TB
  zh: '| 复制数字 | 83 | 58 | 25 | 7 | 0.22 |'
- en: '| Final Errors | 97 | 48 | 49 | 12 | 0.38 |'
  id: totrans-932
  prefs: []
  type: TYPE_TB
  zh: '| 最终错误 | 97 | 48 | 49 | 12 | 0.38 |'
- en: '| Incorrect Units | 77 | 44 | 33 | 7 | 0.34 |'
  id: totrans-933
  prefs: []
  type: TYPE_TB
  zh: '| 错误单位 | 77 | 44 | 33 | 7 | 0.34 |'
- en: '| Wrong Formula | 88 | 63 | 25 | 9 | 0.18 |'
  id: totrans-934
  prefs: []
  type: TYPE_TB
  zh: '| 错误公式 | 88 | 63 | 25 | 9 | 0.18 |'
- en: '| Total | 494 | 310 | 184 | 49 | 0.27 |'
  id: totrans-935
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 494 | 310 | 184 | 49 | 0.27 |'
- en: 'Table 24: Results from looking at the explanation of the Axis+Rubrics evaluator
    to determine the presence of the error in the response. Detected in Explanation
    shows the number of “additional” errors detected by looking at the explanation
    in addition to the score.'
  id: totrans-936
  prefs: []
  type: TYPE_NORMAL
  zh: '表 24: 从查看 Axis+Rubrics 评估器的解释中得出的结果，以确定响应中是否存在错误。在解释中检测到的显示了通过查看解释而非仅仅依据分数发现的“额外”错误的数量。'
