- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 17:34:44'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 17:34:44
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Can LLMs Converse Formally? Automatically Assessing LLMs in Translating and
    Interpreting Formal Specifications
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLMs能正式交流吗？自动评估LLMs在翻译和解释正式规格中的表现
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2403.18327](https://ar5iv.labs.arxiv.org/html/2403.18327)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2403.18327](https://ar5iv.labs.arxiv.org/html/2403.18327)
- en: '[![[Uncaptioned image]](img/11a4d9c7a39bb532e8984d70b648b2ff.png) Rushang Karia](https://orcid.org/0000-0002-8421-1133)
    School of Computing and Augmented Intelligence'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[![[未标注的图像]](img/11a4d9c7a39bb532e8984d70b648b2ff.png) Rushang Karia](https://orcid.org/0000-0002-8421-1133)
    计算与增强智能学院'
- en: Arizona State University
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 亚利桑那州立大学
- en: Tempe AZ USA 85281
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Tempe AZ USA 85281
- en: '{rushang.karia,ddobhal,drbrambl,verma.pulkit,siddharths}@asu.edu Daksh Dobhal
    School of Computing and Augmented Intelligence'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '{rushang.karia,ddobhal,drbrambl,verma.pulkit,siddharths}@asu.edu Daksh Dobhal
    计算与增强智能学院'
- en: Arizona State University
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 亚利桑那州立大学
- en: Tempe AZ USA 85281
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Tempe AZ USA 85281
- en: '{rushang.karia,ddobhal,drbrambl,verma.pulkit,siddharths}@asu.edu Daniel Bramblett
    School of Computing and Augmented Intelligence'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '{rushang.karia,ddobhal,drbrambl,verma.pulkit,siddharths}@asu.edu Daniel Bramblett
    计算与增强智能学院'
- en: Arizona State University
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 亚利桑那州立大学
- en: Tempe AZ USA 85281
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Tempe AZ USA 85281
- en: '{rushang.karia,ddobhal,drbrambl,verma.pulkit,siddharths}@asu.edu Pulkit Verma
    School of Computing and Augmented Intelligence'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '{rushang.karia,ddobhal,drbrambl,verma.pulkit,siddharths}@asu.edu Pulkit Verma
    计算与增强智能学院'
- en: Arizona State University
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 亚利桑那州立大学
- en: Tempe AZ USA 85281
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Tempe AZ USA 85281
- en: '{rushang.karia,ddobhal,drbrambl,verma.pulkit,siddharths}@asu.edu Siddharth
    Srivastava School of Computing and Augmented Intelligence'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '{rushang.karia,ddobhal,drbrambl,verma.pulkit,siddharths}@asu.edu Siddharth
    Srivastava 计算与增强智能学院'
- en: Arizona State University
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 亚利桑那州立大学
- en: Tempe AZ USA 85281
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Tempe AZ USA 85281
- en: '{rushang.karia,ddobhal,drbrambl,verma.pulkit,siddharths}@asu.edu'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '{rushang.karia,ddobhal,drbrambl,verma.pulkit,siddharths}@asu.edu'
- en: Abstract
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Stakeholders often describe system requirements using natural language which
    are then converted to formal syntax by a domain-expert leading to increased design
    costs. This paper assesses the capabilities of Large Language Models (LLMs) in
    converting between natural language descriptions and formal specifications. Existing
    work has evaluated the capabilities of LLMs in generating formal syntax such as
    source code but such experiments are typically hand-crafted and use problems that
    are likely to be in the training set of LLMs, and often require human-annotated
    datasets. We propose an approach that can use two copies of an LLM in conjunction
    with an off-the-shelf verifier to automatically evaluate its translation abilities
    without any additional human input. Our approach generates formal syntax using
    language grammars to automatically generate a dataset. We conduct an empirical
    evaluation to measure the accuracy of this translation task and show that SOTA
    LLMs cannot adequately solve this task, limiting their current utility in the
    design of complex systems.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 利益相关者通常使用自然语言描述系统需求，然后由领域专家将其转换为正式语法，从而增加了设计成本。本文评估了大型语言模型（LLMs）在自然语言描述与正式规格之间转换的能力。现有工作评估了LLMs在生成正式语法（如源代码）方面的能力，但这些实验通常是手工制作的，使用的问题可能在LLMs的训练集中，并且通常需要人工标注的数据集。我们提出了一种方法，可以利用两个LLM副本结合现成的验证工具自动评估其翻译能力，而无需额外的人力输入。我们的方法使用语言语法生成正式语法，以自动生成数据集。我们进行了实证评估，以衡量这一翻译任务的准确性，并展示了SOTA
    LLMs无法充分解决该任务，限制了它们在复杂系统设计中的当前实用性。
- en: '*Keywords* Large Language Models  $\cdot$ Formal Syntax Translation  $\cdot$
    Truth Assessment'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*关键词* 大型语言模型  $\cdot$ 正式语法翻译  $\cdot$ 真值评估'
- en: 1 Introduction
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 介绍
- en: Automatic system synthesis and verification often require specifications to
    be provided in a formal language such as propositional logic (Haubelt and Feldmann,
    [2003](#bib.bib1); Scholl and Becker, [2001](#bib.bib2)). Typically, human experts
    serve as middlemen that can (a) translate natural language (NL) specifications
    of stakeholders to formal syntax, or (b) explain or interpret the system’s functionality
    by translating the system manual into NL.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 自动系统合成和验证通常需要使用形式语言（如命题逻辑）提供规格（Haubelt 和 Feldmann，[2003](#bib.bib1)；Scholl 和
    Becker，[2001](#bib.bib2)）。通常，人类专家充当中介，(a) 将利益相关者的自然语言（NL）规格翻译为正式语法，或 (b) 通过将系统手册翻译为NL来解释或解释系统功能。
- en: Given the success of Large Language Models (LLMs) in translation tasks (Xue
    et al., [2021](#bib.bib3)), utilizing LLMs as middlemen can help in reducing overall
    system design costs. Thus, it is vital to develop an evaluation methodology that
    can assess the capabilities of LLMs in such settings. However, developing such
    a methodology is quite difficult. Firstly, obtaining high-quality datasets – such
    as those that contain ground truth data that LLMs have not been trained on – is
    difficult. As LLMs evolve, the dataset would need to evolve as well since it would
    likely be included as a part of the next-gen LLMs training process. Scaling up
    existing datasets is challenging since they require human annotators to encode
    NL text and their formal specifications. Finally, the assessment task must consider
    both the directions of translation; formal-to-natural and natural-to-formal. Existing
    approaches for evaluating LLMs often lack in one of these dimensions. For example,
    there has been plenty of work on SAT reasoning using LLMs (Fan et al., [2023](#bib.bib4);
    Pan et al., [2023](#bib.bib5); Tian et al., [2021a](#bib.bib6)). These methods
    demonstrate that LLMs are not accurate in applications but they do not assess
    LLMs w.r.t. truth maintenance.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于大型语言模型（LLMs）在翻译任务中的成功（Xue 等，[2021](#bib.bib3)），利用LLMs作为中介可以帮助降低整体系统设计成本。因此，开发一种评估LLMs在此类设置中的能力的方法至关重要。然而，开发这种方法相当困难。首先，获取高质量的数据集——如包含LLMs未经过训练的真实数据的数据集——是困难的。随着LLMs的发展，数据集也需要随之发展，因为它可能会被纳入下一代LLMs的训练过程。扩展现有的数据集具有挑战性，因为它们需要人工标注者对NL文本及其形式规范进行编码。最后，评估任务必须考虑翻译的两个方向；形式到自然和自然到形式。现有的评估LLMs的方法通常在这些维度之一上存在不足。例如，已有大量关于使用LLMs进行SAT推理的工作（Fan
    等，[2023](#bib.bib4)；Pan 等，[2023](#bib.bib5)；Tian 等，[2021a](#bib.bib6)）。这些方法展示了LLMs在应用中的不准确性，但它们并未评估LLMs在真值维护方面的能力。
- en: 'Our Contributions   We present, to the best of our knowledge, the first systematic
    approach for evaluating truth maintenance in LLMs. We develop a scalable approach
    for assessing LLMs w.r.t. their capabilities in translating formal syntax in a
    hands-free fashion. Our key contributions are:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的贡献：我们呈现了我们所知的第一个系统评估LLMs真值维护的 approach。我们开发了一种可扩展的方法，以免手动方式评估LLMs在翻译形式语法方面的能力。我们的主要贡献包括：
- en: '1.'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Inspired by real-world system specifications, we propose the generation of scalable
    datasets that can be generated randomly using formal syntax grammars and can be
    categorized by complexity.
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 受到现实世界系统规范的启发，我们建议生成可扩展的数据集，这些数据集可以通过形式语法语法随机生成，并且可以按复杂性进行分类。
- en: '2.'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: We propose an automatic, hands-free approach that allows the bidirectional assessment
    of the translation task using two copies of an LLM by using off-the-shelf verifiers
    to evaluate the translation accuracy.
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了一种自动、免手动的方法，通过使用两份LLM以及现成的验证工具来评估翻译准确性，从而实现双向评估。
- en: '3.'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: We motivate research in this area by conducting an empirical evaluation and
    showcasing that current SOTA LLMs are lacking even on simple formal specifications
    such as boolean satisfiability (SAT) and first-order logic (FOL).
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们通过进行实证评估并展示当前的SOTA LLM在简单的形式规范如布尔满足性（SAT）和一阶逻辑（FOL）方面的不足，激励了这一领域的研究。
- en: 2 Automatically Assessing LLM Capabilities in Translation and Interpretation
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 自动评估LLM在翻译和解释方面的能力
- en: '![Refer to caption](img/e0e376b21e3e13f1ca37db7a7f769f79.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e0e376b21e3e13f1ca37db7a7f769f79.png)'
- en: 'Figure 1: Our overall process for *NL$\leftrightarrow$FS* for a given formula
    $f$.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：我们针对给定公式 $f$ 的 *NL$\leftrightarrow$FS* 的整体过程。
- en: 2.1 Formal Framework
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 形式框架
- en: Definition 2.1  (LLM Formal Syntax Translation Task (NL$\rightarrow$FS)).
  id: totrans-39
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 2.1（LLM形式语法翻译任务（NL$\rightarrow$FS））。
- en: Given an LLM $L$, a prompt $P$, and a natural language representation NL of
    formal syntax FS, NL$\rightarrow$FS is defined as converting NL to formal syntax
    FS^′ using $L$ and $P$ s.t. FS$\equiv$FS^′.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个LLM $L$，一个提示 $P$ 和形式语法 FS 的自然语言表示 NL，NL$\rightarrow$FS 被定义为使用 $L$ 和 $P$
    将 NL 转换为形式语法 FS^′，使 FS$\equiv$FS^′。
- en: Definition 2.2  (LLM Formal Syntax Interpretation Task (FS$\rightarrow$NL)).
  id: totrans-41
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 2.2（LLM形式语法解释任务（FS$\rightarrow$NL））。
- en: Given an LLM $L$, a prompt $P$, and formal syntax FS, FS$\rightarrow$NL is defined
    as converting FS to natural language NL using $L$ and $P$ s.t. NL is an accurate
    representation of FS.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个LLM $L$，一个提示 $P$ 和形式语法 FS，FS$\rightarrow$NL 被定义为使用 $L$ 和 $P$ 将 FS 转换为自然语言
    NL，使 NL 成为 FS 的准确表示。
- en: In this paper, we consider formal specifications that are expressed as boolean
    satisfiability (B-SAT) formulae using propositional logic (Biere et al., [2021](#bib.bib7)).
    Given a set of $n$ boolean variables $\mathcal{X}=\{x_{1},\ldots,x_{n}\}$ and
    boolean operators representing negation $(\neg)$, disjunction $(\lor)$, and conjunction
    $(\land)$, a SAT formula $f$ is obtained by recursively applying the grammar $\mathcal{G}_{\textit{sat}}\rightarrow
    x|p\lor p^{\prime}|p\land p^{\prime}|\neg p$ where $x\in\mathcal{X}$. The canonical
    representation of formulae obtained using $\mathcal{G}_{\textit{sat}}$ is the
    conjunctive normal form (CNF). A formula $f$ is in $(k,m)-$CNF form if $f\equiv
    f_{1}\land\ldots\land f_{m}$ where $f_{i}=p_{1}\lor\ldots\lor p_{k}$ and $p_{i}=\{x_{j},\neg
    x_{j}\}$ with $x_{j}\in\mathcal{X}$. Given an assignment $X$ of truth values to
    every variable in $\mathcal{X}$, $f(X)$ is the truth value of the formula. Two
    formulae $f_{1},f_{2}$ are equivalent $f_{1}\equiv f_{2}$ if they have the same
    truth value for all possible assignments using $\mathcal{X}$, i.e. $\forall Xf_{1}(X)=f_{2}(X)$.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们考虑以布尔可满足性（B-SAT）公式形式表示的形式化规范，使用命题逻辑（Biere 等，[2021](#bib.bib7)）。给定一组 $n$
    个布尔变量 $\mathcal{X}=\{x_{1},\ldots,x_{n}\}$ 和表示否定 $(\neg)$、析取 $(\lor)$ 和合取 $(\land)$
    的布尔运算符，通过递归应用语法 $\mathcal{G}_{\textit{sat}}\rightarrow x|p\lor p^{\prime}|p\land
    p^{\prime}|\neg p$ 其中 $x\in\mathcal{X}$，得到 SAT 公式 $f$。使用 $\mathcal{G}_{\textit{sat}}$
    获得的公式的标准表示形式是合取范式（CNF）。如果公式 $f$ 为 $(k,m)-$CNF 形式，则 $f\equiv f_{1}\land\ldots\land
    f_{m}$ 其中 $f_{i}=p_{1}\lor\ldots\lor p_{k}$ 和 $p_{i}=\{x_{j},\neg x_{j}\}$ 且 $x_{j}\in\mathcal{X}$。给定将每个变量赋予真值的赋值
    $X$，$f(X)$ 是公式的真值。如果两个公式 $f_{1},f_{2}$ 对所有可能的赋值具有相同的真值，即 $\forall Xf_{1}(X)=f_{2}(X)$，则它们等价
    $f_{1}\equiv f_{2}$。
- en: 2.2 Our Approach
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 我们的方法
- en: Let $\iota$ be a non-deterministic function that interprets formal syntax $f$
    as a natural language string $s$. Similarly, let $\tau$ be a non-deterministic
    function that translates $s$ to $f$. $\iota$ and $\tau$ thus serve as a interpreter
    and translator that can perform *FS$\rightarrow$NL* and *NL$\rightarrow$FS* respectively.
    In general, there are many possible correct interpretations $\iota(f)$ and translations
    $\tau(s)$ for a given $f$ and $s$. Thus, the functions $\iota^{-1}$ and $\tau^{-1}$
    are not well-defined.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 设 $\iota$ 为一个非确定性函数，将形式语法 $f$ 解释为自然语言字符串 $s$。类似地，设 $\tau$ 为一个非确定性函数，将 $s$ 翻译为
    $f$。因此，$\iota$ 和 $\tau$ 分别作为执行 *FS$\rightarrow$NL* 和 *NL$\rightarrow$FS* 的解释器和翻译器。一般而言，对于给定的
    $f$ 和 $s$，存在许多可能的正确解释 $\iota(f)$ 和翻译 $\tau(s)$。因此，函数 $\iota^{-1}$ 和 $\tau^{-1}$
    并不被很好地定义。
- en: Our key observation is that if $\iota$ and $\tau$ come from the same system
    (e.g. a neural network or LLM), then we can check the accuracy of the system by
    composing $\iota$ and $\tau$. Let $f$ be a SAT formula. Now, if the system preserves
    truth in both translations, then $\tau(s)$ will be a factual representation of
    $f$ and $f^{\prime}=\tau(\iota(f))$ will be equivalent to $f$ even if $f$ and
    $f^{\prime}$ are not syntactically identical. Since $\iota(f)$ produces natural
    language description it is quite challenging to check whether $\iota(f)$ is a
    factual representation of $f$ without human intervention. However, we can use
    off-the-shelf SAT solvers like Z3 (de Moura and Bjørner, [2008](#bib.bib8)) to
    check if $f\equiv\tau(\iota(f))$.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的关键观察是，如果 $\iota$ 和 $\tau$ 来自同一系统（例如，一个神经网络或LLM），那么我们可以通过组合 $\iota$ 和 $\tau$
    来检查系统的准确性。设 $f$ 为一个 SAT 公式。现在，如果系统在两个翻译中都保持真实，那么 $\tau(s)$ 将是 $f$ 的一个事实性表示，而 $f^{\prime}=\tau(\iota(f))$
    将等同于 $f$，即使 $f$ 和 $f^{\prime}$ 在语法上不完全相同。由于 $\iota(f)$ 生成自然语言描述，因此在没有人工干预的情况下，很难检查
    $\iota(f)$ 是否是 $f$ 的事实性表示。然而，我们可以使用现成的 SAT 求解器，如 Z3（de Moura 和 Bjørner，[2008](#bib.bib8)），来检查
    $f\equiv\tau(\iota(f))$。
- en: We use the above insights to automatically assess the *FS$\rightarrow$NL* and
    *NL$\rightarrow$FS* capabilities of LLMs (i.e. $\iota$ and $\tau$ are represented
    by the same LLM). Since LLMs utilize context windows to change their output, we
    use two different copies of the same LLM so that there is no contextual knowledge
    being exchanged between the encode-decode process.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们利用上述见解来自动评估LLMs的 *FS$\rightarrow$NL* 和 *NL$\rightarrow$FS* 能力（即 $\iota$ 和
    $\tau$ 由相同的LLM表示）。由于LLMs利用上下文窗口来改变它们的输出，我们使用两个不同的相同LLM副本，以确保在编码-解码过程中没有上下文知识的交换。
- en: Fig. [1](#S2.F1 "Figure 1 ‣ 2 Automatically Assessing LLM Capabilities in Translation
    and Interpretation ‣ Can LLMs Converse Formally? Automatically Assessing LLMs
    in Translating and Interpreting Formal Specifications") illustrates our overall
    process. Given a formula $f$, we use an LLM to convert $f$ to NL using a prompt
    designed for *FS$\rightarrow$NL*. Next, the NL description is input to another
    LLM which is simply a copy of the previous LLM. We use a prompt designed for *NL$\rightarrow$FS*
    to get a formula $f^{\prime}$. Now, $f^{\prime}$ may be syntactically quite different
    from $f$. However, we can use a theorem prover such as Z3 to check whether $f\equiv
    f^{\prime}$.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图[1](#S2.F1 "图 1 ‣ 2 自动评估LLM在翻译和解释中的能力 ‣ LLM能否正式对话？自动评估LLM在翻译和解释正式规范中的能力")展示了我们的整体过程。给定一个公式$f$，我们使用一个LLM将$f$转换为NL，使用为*FS$\rightarrow$NL*设计的提示。接下来，将NL描述输入到另一个LLM，该LLM仅是前一个LLM的副本。我们使用为*NL$\rightarrow$FS*设计的提示来得到一个公式$f^{\prime}$。现在，$f^{\prime}$可能在语法上与$f$有很大不同。然而，我们可以使用诸如Z3之类的定理证明器来检查$f\equiv
    f^{\prime}$。
- en: Dataset Generation   We create high-quality datasets by using generators that
    use the formal language’s grammar $\mathcal{G}$ to generate formulae. One key
    benefit of using such generators is that can they can generate formal syntax with
    a certain structure or complexity class. For example, $(k,m)-$CNF generators generate
    structured CNF formulae and it is well-known that for a formula with $n$ variables,
    there is a ratio $r=m/n$ where the difficulty of the problem increases (Selman
    et al., [1996](#bib.bib9)).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集生成  我们通过使用利用正式语言语法$\mathcal{G}$生成公式的生成器来创建高质量的数据集。使用这些生成器的一个关键好处是，它们能够生成具有特定结构或复杂性类别的正式语法。例如，$(k,m)-$CNF生成器生成结构化的CNF公式，并且众所周知，对于具有$n$个变量的公式，有一个比率$r=m/n$，在该比率下，问题的难度增加（Selman
    et al., [1996](#bib.bib9)）。
- en: 3 Empirical Evaluation
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 实证评估
- en: We used GPT-4 (OpenAI, [2023a](#bib.bib10)), GPT-3.5-turbo (OpenAI, [2023b](#bib.bib11)),
    Mistral-7B-Instruct (Mistral AI, [2023](#bib.bib12)), and Gemini Pro (Google,
    [2023](#bib.bib13)) as the SOTA LLMs in our evaluation. We evaluate whether they
    are effective for *NL$\leftrightarrow$FS*. As a result, we used a simple setting
    $k=n=3$ in creating our dataset. Real-world systems use values for $k,n$ that
    are much higher.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了GPT-4（OpenAI, [2023a](#bib.bib10)），GPT-3.5-turbo（OpenAI, [2023b](#bib.bib11)），Mistral-7B-Instruct（Mistral
    AI, [2023](#bib.bib12)），和Gemini Pro（Google, [2023](#bib.bib13)）作为我们评估中的SOTA LLM。我们评估它们在*NL$\leftrightarrow$FS*上的有效性。因此，我们在创建数据集时使用了简单的设置$k=n=3$。实际系统使用的$k,n$值要高得多。
- en: 3.1 Propositional Logic
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 命题逻辑
- en: '![Refer to caption](img/8806911c4dd05b98114227e8ad7527ce.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/8806911c4dd05b98114227e8ad7527ce.png)'
- en: 'Figure 2: Accuracies (higher values better) of various SOTA LLMs on *NL$\leftrightarrow$FS*
    on randomly generated formulae. The top y-axis plots the accuracy of the LLM generated
    formulae compared to the ground truty. The bottom y-axis plots the total percent
    of the truth table that is consistent with the ground truth.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：各种SOTA LLM在随机生成公式上的*NL$\leftrightarrow$FS*的准确率（值越高越好）。顶部的y轴绘制了LLM生成的公式与真实值的准确率。底部的y轴绘制了与真实值一致的真值表的总百分比。
- en: Prompts are critical to the performance of LLMs. To ensure that our prompts
    are correct and facilitate translation/interpretation w.r.t. formal syntax, we
    tested our prompts by generating a dataset $\mathcal{D}_{\textit{cnf}}$ of 400
    different $(k,m=rn)-$CNF formulae by varying $r$ from $1.0$ to $7.0$ using a step
    size of $0.5$. CNF formulae are structured and easy to describe making them a
    good benchmark for testing the efficacy of our prompts. The *FS$\rightarrow$NL*
    prompt asks an LLM to convert a SAT formula to an NL description whereas the *NL$\rightarrow$FS*
    prompt asks to convert the NL description to a SAT formula and output only the
    SAT formula with no other text. We iteratively modified our prompts until at least
    one LLM (GPT-4 in our case) was able to achieve $\geq 95\%$ accuracy in *NL$\leftrightarrow$FS*
    on $\mathcal{D}_{\textit{cnf}}$.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 提示对于LLMs的表现至关重要。为了确保我们的提示是正确的，并促进相对于正式语法的翻译/解释，我们通过生成一个包含400个不同的$(k,m=rn)-$CNF公式的数据集$\mathcal{D}_{\textit{cnf}}$来测试我们的提示，$r$的范围从$1.0$到$7.0$，步长为$0.5$。CNF公式结构明确且易于描述，使其成为测试提示有效性的良好基准。*FS$\rightarrow$NL*提示要求LLM将SAT公式转换为NL描述，而*NL$\rightarrow$FS*提示则要求将NL描述转换为SAT公式，并仅输出SAT公式而不包含其他文本。我们迭代地修改了提示，直到至少一个LLM（在我们的案例中为GPT-4）能够在$\mathcal{D}_{\textit{cnf}}$上实现*NL$\leftrightarrow$FS*的准确率达到$\geq
    95\%$。
- en: CNF formulae serve as a good test bed for prompts but human stakeholders are
    unlikely to understand or describe system capabilities in such a format. Thus,
    our evaluation tests the efficacy of SOTA LLMs on *NL$\leftrightarrow$FS* using
    randomly generated formulae for propositional logic. To do this, we randomly generated
    400 different formulae by recursively applying $\mathcal{G}_{\textit{sat}}$. For
    a CNF formula in $\mathcal{D}_{\textit{cnf}}$ with ratio $r$, we generated a comparable
    random formula such that the total number of operators ($\land$, $\lor$) are equal
    in both.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: CNF 公式作为提示的良好测试场景，但人工利益相关者不太可能以这种格式理解或描述系统能力。因此，我们的评估测试了最先进（SOTA）LLMs 在 *NL$\leftrightarrow$FS*
    任务上的有效性，使用随机生成的命题逻辑公式。为此，我们通过递归应用 $\mathcal{G}_{\textit{sat}}$ 随机生成了 400 个不同的公式。对于比例为
    $r$ 的 $\mathcal{D}_{\textit{cnf}}$ 中的 CNF 公式，我们生成了一个可比的随机公式，使得两个公式中的运算符总数（$\land$,
    $\lor$）相等。
- en: We used the same prompts for all LLMs. Finally, we used a temperature of $0.1$
    for all models. The temperature influences the randomness of the models.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对所有 LLM 使用了相同的提示。最后，我们对所有模型使用了 $0.1$ 的温度。温度影响模型的随机性。
- en: Results   Our results are presented in Fig.[2](#S3.F2 "Figure 2 ‣ 3.1 Propositional
    Logic ‣ 3 Empirical Evaluation ‣ Can LLMs Converse Formally? Automatically Assessing
    LLMs in Translating and Interpreting Formal Specifications"). It is clear from
    our results that current SOTA LLMs are not performant in the *NL$\leftrightarrow$FS*
    task. As the size of the formula (the total number of conjunctions and disjunctions)
    increases, the performance degrades across all LLMs that we tested. These results
    are even surprising for GPT-4 whose accuracy on comparable CNF formulae was always
    $\geq 95\%$. We describe some of the errors that cause the low accuracy of the
    LLMs.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 结果  我们的结果展示在图 [2](#S3.F2 "图 2 ‣ 3.1 命题逻辑 ‣ 3 实证评估 ‣ LLM 能够正式对话吗？自动评估 LLM 在翻译和解释形式规格中的表现")
    中。结果清楚地表明，当前的最先进 LLM 在 *NL$\leftrightarrow$FS* 任务中的表现不佳。随着公式大小（联结和析取的总数）的增加，我们测试的所有
    LLM 的性能均有所下降。这些结果对于 GPT-4 来说尤为令人惊讶，因为 GPT-4 在可比 CNF 公式上的准确率始终为 $\geq 95\%$。我们描述了一些导致
    LLM 准确率低的错误。
- en: '*FS$\rightarrow$NL Errors:* One of the most common errors in this translation
    was messing the order of the parentheses. The LLMs were not able to effectively
    describe the formulae taking into account the parentheses. For example, for GPT-3.5-turbo,
    as the size of the formula increased, we noticed that the description did not
    correctly capture the semantics of the formula and the parentheses in expressions
    were often ignored. Gemini and Mistral were not able to correctly describe the
    formula accurately and often missed complete parts of the formula in their description.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '*FS$\rightarrow$NL 错误：* 在这次翻译中最常见的错误之一是括号的顺序混乱。大型语言模型（LLMs）无法有效地描述公式中的括号。例如，对于
    GPT-3.5-turbo，当公式的大小增加时，我们注意到描述未能正确捕捉公式的语义，并且表达式中的括号常常被忽略。Gemini 和 Mistral 无法准确地描述公式，常常在描述中遗漏了公式的完整部分。'
- en: '*NL$\rightarrow$FS Errors:* Hallucinations and negating propositions were common
    errors even when the NL sentence was sufficient for a human to correctly decode
    it to a SAT formula. One of the common issues in GPT-4, which was the best model,
    on larger formulae was that even if the NL description was correct, it would often
    use a different propositional symbol in the formula. For correct NL descriptions,
    GPT-3.5-turbo had trouble reconstructing the formula since similar to *FS$\rightarrow$NL*,
    the parentheses were often misplaced in the translated formula. Finally, Mistral
    and Gemini were not able to correctly decode the formula, often hallucinating
    new expressions or using different propositional symbols. Another big issue with
    Mistral and Gemini was their inability to translate correctly. The prompt instructions
    clearly stated that when converting from *NL$\rightarrow$FS*, the final response
    should only the the formula and no other text. However, both these LLMs consistently
    failed to generate only a formula and would often try to describe the formula
    again before providing the desired response.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*NL$\rightarrow$FS 错误：* 即使 NL 句子对人类来说足够明确可以正确解码为 SAT 公式，虚假信息和否定命题仍然是常见的错误。在
    GPT-4 这种最佳模型处理更大公式时的一个常见问题是，即使 NL 描述正确，它也经常在公式中使用不同的命题符号。对于正确的 NL 描述，GPT-3.5-turbo
    在重建公式时遇到困难，因为类似于 *FS$\rightarrow$NL*，翻译后的公式中的括号经常放错位置。最后，Mistral 和 Gemini 无法正确解码公式，经常出现虚假新表达式或使用不同的命题符号。Mistral
    和 Gemini 的另一个大问题是它们无法正确翻译。提示指令明确指出，从 *NL$\rightarrow$FS* 转换时，最终响应应该仅包含公式而没有其他文本。然而，这两种
    LLM 一直无法只生成公式，通常在提供所需响应之前会尝试再次描述公式。'
- en: 3.2 First Order Logic
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 一阶逻辑
- en: '![Refer to caption](img/6e43b1a3a87e480806b7f1bf9830877d.png)![Refer to caption](img/5e3a0d8d69e002f78cb056c8c878aaec.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/6e43b1a3a87e480806b7f1bf9830877d.png)![参考标题](img/5e3a0d8d69e002f78cb056c8c878aaec.png)'
- en: 'Figure 3: Accuracies (higher values better) of various SOTA LLMs on *NL$\leftrightarrow$FS*
    on randomly generated FOL formulae. The top figure plots accuracies w.r.t. FOL
    formulae with randomized, symbolic versions of predicates and constants (e.g.
    $p_{1}(o_{1},o_{2})$) whereas the bottom figure plots accuracies w.r.t. human
    versions of predicates and constants like Friend(John, Mary) etc.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：各种 SOTA LLM 在 *NL$\leftrightarrow$FS* 上的准确率（数值越高越好），基于随机生成的 FOL 公式。上图绘制了关于
    FOL 公式的准确率，涉及谓词和常量的随机化符号版本（例如 $p_{1}(o_{1},o_{2})$），而下图则绘制了关于人类版本的谓词和常量（如 Friend(John,
    Mary) 等）的准确率。
- en: We generated a dataset $\mathcal{D}_{\textit{fol}}$ of 400 different $n$-operator
    first-order logic formulae constructed from a fixed vocabulary. Extended from
    the CNF prompts, both the *FS$\rightarrow$NL* and *NL$\rightarrow$FS* prompts
    provide the LLM with a description of the predicates. Additionally, the *NL$\rightarrow$FS*
    prompt provides the LLM with FOL grammar and prompts for the FOL formula constructed
    from the NL description to be placed at the end of the response. The prompts were
    refactored til they covered all the translation failure cases detected from each
    LLM using a different random seed.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们生成了一个数据集 $\mathcal{D}_{\textit{fol}}$，其中包含 400 个不同的 $n$-运算符一阶逻辑公式，这些公式由固定词汇构建。基于
    CNF 提示扩展，*FS$\rightarrow$NL* 和 *NL$\rightarrow$FS* 提示为 LLM 提供了谓词描述。此外，*NL$\rightarrow$FS*
    提示提供了 FOL 语法，并要求将从 NL 描述构建的 FOL 公式放在响应的末尾。提示经过重构，直到覆盖了使用不同随机种子从每个 LLM 检测到的所有翻译失败情况。
- en: We randomly generated 400 FOL formulae of the prenex normal form by recursively
    applying $\mathcal{G}_{sat}$ till $n$ operators ($\neg$, $\wedge$, $\lor$) had
    been generated. Then, a quantifier was randomly selected for each variable in
    the vocabulary. The grounded predicates were randomly selected. We used two such
    datasets; the first one had randomized versions of predicates and constants whereas
    the predicates and constants in the second dataset were pulled from an English
    vocabulary.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过递归应用 $\mathcal{G}_{sat}$ 生成了 400 个具有前束范式的 FOL 公式，直到生成了 $n$ 个运算符（$\neg$，$\wedge$，$\lor$）。然后，为词汇中的每个变量随机选择一个量词。基础谓词也是随机选择的。我们使用了两个这样的数据集；第一个数据集包含谓词和常量的随机化版本，而第二个数据集中的谓词和常量则来自英语词汇。
- en: We used the same prompt for each LLM and evaluated the equivalence of the generated
    formulae compared to the originals using Prover9 (McCune, [2005–2010](#bib.bib14)).
    The solver had a 10-minute timeout, and examples that hit it were thrown out.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对每个 LLM 使用相同的提示，并使用 Prover9（McCune，[2005–2010](#bib.bib14)）评估生成公式与原始公式的等价性。求解器有
    10 分钟的超时限制，超时的示例会被丢弃。
- en: Results   Our results are presented in Fig.[3](#S3.F3 "Figure 3 ‣ 3.2 First
    Order Logic ‣ 3 Empirical Evaluation ‣ Can LLMs Converse Formally? Automatically
    Assessing LLMs in Translating and Interpreting Formal Specifications"). Note that
    with far fewer operators than CNF results, SOTA LLMs are not performant in the
    *NL$\leftrightarrow$FS* task. Even with a single operator, GPT-4 barely achieved
    80% accuracy with diminishing performance. The increase at the end is due to GPT-4
    results having a higher number of timeouts that, while visually incorrect, are
    thrown out. We observed all the same problems raised in the CNF results.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 结果   我们的结果见图[3](#S3.F3 "Figure 3 ‣ 3.2 First Order Logic ‣ 3 Empirical Evaluation
    ‣ Can LLMs Converse Formally? Automatically Assessing LLMs in Translating and
    Interpreting Formal Specifications")。请注意，与 CNF 结果相比，SOTA LLM 在 *NL$\leftrightarrow$FS*
    任务中的表现较差。即使使用单一运算符，GPT-4 的准确率也仅略超 80%，且性能逐渐下降。末尾的增加是因为 GPT-4 的结果有更多超时示例，虽然视觉上不正确，但被丢弃了。我们观察到
    CNF 结果中提出的所有相同问题。
- en: '*FS$\rightarrow$NL Errors:* The same lack of detail for formula explanations
    was observed, resulting in incorrect formulas being generated. Additionally, it
    was quite common for the LLM to introduce different constants as examples for
    variables, resulting in LLM using them when generating the formulae.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*FS$\rightarrow$NL 错误:* 观察到公式解释缺乏细节，导致生成了错误的公式。此外，LLM 在生成公式时常常将不同的常量作为变量示例引入。'
- en: '*NL$\rightarrow$FS Errors:* The most common mistakes were using the wrong predicate
    arities and changing predicate arguments. GPT-4, in particular, often denoted
    the named constants as other symbols changing the formula’s meaning. Gemini often
    hallucinated different named constants. LLMs struggled with the negation operator
    by either messing up simplifying or distributing them. The most concerning cases
    were when LLM failed to produce a FOL formula. GPT-4 sometimes failed to recognize
    its own explanation as an explanation of a FOL formula. The LLMs often ignored
    the grammar provided and used additional operators, including $\rightarrow,\leftrightarrow,=,$
    and $\neq$. While we parsed these operators, we observed that there was a significantly
    higher likelihood for the LLM messing up.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '*NL$\rightarrow$FS 错误:* 最常见的错误是使用了错误的谓词算术和改变谓词参数。特别是，GPT-4 经常将命名常量表示为其他符号，从而改变公式的意义。Gemini
    经常幻想出不同的命名常量。LLMs 在处理否定运算符时表现不佳，要么简化出错，要么分配出错。最令人担忧的情况是 LLM 无法生成 FOL 公式。GPT-4
    有时无法将自己的解释识别为 FOL 公式的解释。LLMs 经常忽略提供的语法，并使用额外的运算符，包括 $\rightarrow,\leftrightarrow,=,$
    和 $\neq$。虽然我们解析了这些运算符，但我们观察到 LLM 出错的可能性显著增加。'
- en: 4 Related Work
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 相关工作
- en: There is a large body of work for using LLMs for tasks using formal languages.
    Similarly, there exist several datasets that allow the analysis of LLMs in such
    tasks.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 LLM 进行形式语言任务有大量的工作。同样，存在几个数据集可以分析 LLM 在这些任务中的表现。
- en: Datasets RuleTaker (Clark et al., [2020](#bib.bib15)) creates a dataset by applying
    a limited grammar consisting of only conjunctions and disjunctions to generate
    formulae. This makes it quite limited in the types of formulae it can generate.
    FOLIO (Han et al., [2022](#bib.bib16)) comprises first-order logic statements
    that can be used to test the reasoning capabilities of LLMs. The data consists
    of premises and annotated conclusions that can be drawn from the premises thus
    enabling the testing of reasoning capabilities of LLMs. One of the key disadvantages
    of this dataset is that the data was generated using human-experts. LogicNLI (Tian
    et al., [2021b](#bib.bib17)) is a reasoning dataset that generates first-order
    logic formulae from a set of templates and then uses rule-based templates for
    NL generation. Since they utilize a set of templates their datasets are limited
    in the kinds of expressions they can generate.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集 RuleTaker（Clark等，[2020](#bib.bib15)）通过应用仅包含合取和析取的有限语法生成数据集。这使得它在生成公式的类型上相当有限。FOLIO（Han等，[2022](#bib.bib16)）包括可用于测试LLM推理能力的第一阶逻辑陈述。数据由前提和从前提中可以得出的标注结论组成，从而能够测试LLM的推理能力。该数据集的一个主要缺点是数据是使用人类专家生成的。LogicNLI（Tian等，[2021b](#bib.bib17)）是一个推理数据集，通过从一组模板生成第一阶逻辑公式，然后使用基于规则的模板生成NL。由于他们利用了一组模板，他们的数据集在生成表达式的种类上有限。
- en: In contrast to existing datasets, our approach can generate arbitrarily complex
    formulae and does not require any human intervention making our approach scalable.
    Furthermore, our datasets can be partitioned into definite classes of hardness
    from a reasoning perspective making them well suited for reasoning-based testing
    as well.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 与现有的数据集相比，我们的方法可以生成任意复杂的公式，并且不需要任何人工干预，使我们的方法具有可扩展性。此外，我们的数据集可以从推理角度分成明确的难度类别，因此也非常适合基于推理的测试。
- en: First-order Logic Translation LogicLLaMa (Yang et al., [2023](#bib.bib18)) is
    an LLM trained specifically for the *NL$\rightarrow$FS* task. Inorder to evaluate
    its efficacy, the authors proposed MALLS, a custom generated dataset that can
    be used to evaluate the efficacy of LogicLLaMa. Their approach does not provide
    an automatic way to test the efficacy of LLMs in the translation task and requires
    hand-coded datasets. Moreover, their evaluation metric considers logical equivalence
    using truth tables which can be inefficient. Autoformalization (Wu et al., [2022](#bib.bib19))
    uses pre-trained LLMs together with few-shot prompting to convert NL descriptions
    to formal syntax. This approach requires expert prompting and relevant examples
    to boost performance. Furthermore, this approach relies on existing, annotated
    datasets and thus can be susceptible to LLMs having memorized the answers.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 第一阶逻辑翻译逻辑LLaMa（Yang等，[2023](#bib.bib18)）是专门为*NL$\rightarrow$FS*任务训练的LLM。为了评估其有效性，作者提出了MALLS，这是一个自定义生成的数据集，可以用来评估LogicLLaMa的有效性。他们的方法未提供自动测试LLM在翻译任务中的有效性的方法，需要手工编码的数据集。此外，他们的评估指标考虑使用真值表的逻辑等价性，这可能效率低下。自动形式化（Wu等，[2022](#bib.bib19)）使用预训练的LLM和少量示例提示将NL描述转换为形式语法。这种方法需要专家提示和相关示例来提升性能。此外，这种方法依赖于现有的标注数据集，因此可能会受到LLM记住答案的影响。
- en: PDDL Translation Simon and Muise ([2021](#bib.bib20)) train Recurrent Neural
    Networks (RNNs) to automatically translate a fragment of formal syntax expressed
    in PDDL to a complete PDDL problem. They train the RNN on publicly available PDDL
    problems using supervised learning. However, their approach cannot use general
    purpose NL descriptions and requires inputs in a formal syntax. Xie et al. ([2023](#bib.bib21))
    use few-shot prompting to translate NL descriptions to PDDL goals and assess them
    using manually designed, domain-dependent metrics. Moreover, their approach cannot
    perform *FS$\rightarrow$NL* translations.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: PDDL翻译 Simon和Muise（[2021](#bib.bib20)）训练了递归神经网络（RNNs），以自动将用PDDL表达的形式语法片段翻译为完整的PDDL问题。他们使用监督学习在公开的PDDL问题上训练RNN。然而，他们的方法不能使用通用的NL描述，且需要以形式语法输入。Xie等（[2023](#bib.bib21)）使用少量示例提示将NL描述翻译为PDDL目标，并使用手工设计的领域相关指标进行评估。此外，他们的方法无法执行*FS$\rightarrow$NL*翻译。
- en: RTL Translation AutoSVA2 (Orenes-Vera et al., [2023](#bib.bib22)) is a framework
    for verification of RTL syntax from NL descriptions. The framework involves manually
    refining prompts iteratively. Next, an LLM is used to generate the RTL syntax
    and an RTL engine is used to validate the result. One key weakness is that their
    approach is not generalizable and requires an engineer-in-the-loop to iteratively
    refine the prompts or different kinds of RTL designs within the same language.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: RTL Translation AutoSVA2 (Orenes-Vera 等，[2023](#bib.bib22)) 是一个用于从自然语言描述验证 RTL
    语法的框架。该框架涉及手动迭代地优化提示。接下来，使用 LLM 生成 RTL 语法，RTL 引擎用于验证结果。一个关键的弱点是他们的方法不可推广，并且需要工程师循环迭代地优化提示或处理同一语言中的不同类型的
    RTL 设计。
- en: Code Translation Codex (Chen et al., [2021](#bib.bib23)) is an LLM that is capable
    of converting NL descriptions to code and vice versa. However, this approach does
    not provide any automatic way to assess the accuracy of the LLM and it often relies
    on human annotators to verify the results. Furthermore, their testing process
    cannot accurately check whether the translate code matches the NL description
    correctly since they use sampling of input cases in their evaluation. Bhattacharya
    et al. ([2023](#bib.bib24)) evaluate the capability of LLMs to explain code by
    assessing their performance when used with zero-shot, few-shot prompts and instruction
    finetuning. Their approach requires access to hand-coded prompts and cannot work
    with different formal languages. MacNeil et al. ([2023](#bib.bib25)) conduct user-studies
    to evaluate the effectiveness of LLMs in generating code. Their approach requires
    the recruitment of expert humans who know code to assess the quality of the generated
    LLMs.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Code Translation Codex (Chen 等，[2021](#bib.bib23)) 是一个能够将自然语言描述转换为代码及其逆过程的 LLM。然而，这种方法没有提供任何自动方式来评估
    LLM 的准确性，通常依赖人工标注者来验证结果。此外，他们的测试过程无法准确检查翻译的代码是否与自然语言描述匹配，因为他们在评估中使用了输入案例的抽样。Bhattacharya
    等 ([2023](#bib.bib24)) 通过评估 LLM 在零样本、少样本提示和指令微调下的表现，来评估 LLM 解释代码的能力。他们的方法需要访问手工编写的提示，并且无法处理不同的正式语言。MacNeil
    等 ([2023](#bib.bib25)) 进行用户研究，以评估 LLM 生成代码的有效性。他们的方法需要招募懂代码的专家来评估生成的 LLM 的质量。
- en: Our framework provides a general, automatic, handsfree way of assessing LLMs
    in both *NL$\rightarrow$FS* and *FS$\rightarrow$NL* without requiring any expert
    knowledge. Our approach can be easily transferred to other formal languages with
    an appropriate critic.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的框架提供了一种通用的、自动的、免手动的方式来评估 LLM 在 *NL$\rightarrow$FS* 和 *FS$\rightarrow$NL*
    中的表现，而无需任何专家知识。我们的方法可以轻松转移到其他正式语言中，只需适当的批评者。
- en: 5 Conclusions and Future Work
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论和未来工作
- en: We develop an approach that allows for effective assessment in the formal translation
    capabilities of SOTA LLMs. Our approach does not require human annotations to
    verify the accuracy of translation. Our results show that there is much to be
    done before LLMs can be deployed in translating formal syntax. We plan to investigate
    the performance of LLMs using different formal languages in future work.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开发了一种方法，用于有效评估 SOTA LLM 在正式翻译能力方面的表现。我们的方法不需要人工标注来验证翻译的准确性。我们的结果表明，在 LLM 可以用于翻译正式语法之前，还有许多工作要做。我们计划在未来的工作中调查
    LLM 在不同正式语言中的表现。
- en: References
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Haubelt and Feldmann [2003] C. Haubelt and R. Feldmann. SAT-based techniques
    in system synthesis. In *Proc DATE*, 2003.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Haubelt 和 Feldmann [2003] C. Haubelt 和 R. Feldmann。基于 SAT 的系统合成技术。在 *Proc DATE*，2003。
- en: Scholl and Becker [2001] Christoph Scholl and Bernd Becker. Checking equivalence
    for partial implementations. In *Proc. DAC*, 2001.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Scholl 和 Becker [2001] Christoph Scholl 和 Bernd Becker。检查部分实现的等价性。在 *Proc. DAC*，2001。
- en: 'Xue et al. [2021] Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami
    Al-Rfou, Aditya Siddhant, Aditya Barua, and Colin Raffel. mT5: A massively multilingual
    pre-trained text-to-text transformer. In *Proc. NAACL-HLT*, 2021.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xue 等 [2021] Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya
    Siddhant, Aditya Barua 和 Colin Raffel。mT5：一种大规模多语言预训练文本到文本的变换器。在 *Proc. NAACL-HLT*，2021。
- en: 'Fan et al. [2023] Lizhou Fan, Wenyue Hua, Lingyao Li, Haoyang Ling, Yongfeng
    Zhang, and Libby Hemphill. NPHardEval: Dynamic benchmark on reasoning ability
    of large language models via complexity classes, 2023.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fan 等 [2023] Lizhou Fan, Wenyue Hua, Lingyao Li, Haoyang Ling, Yongfeng Zhang
    和 Libby Hemphill。NPHardEval：通过复杂性类对大型语言模型推理能力的动态基准，2023。
- en: 'Pan et al. [2023] Liangming Pan, Alon Albalak, Xinyi Wang, and William Yang
    Wang. Logic-LM: Empowering large language models with symbolic solvers for faithful
    logical reasoning. In *Proc. EMNLP Findings*, 2023.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Pan et al. [2023] Liangming Pan, Alon Albalak, Xinyi Wang, 和 William Yang Wang.
    Logic-LM: 通过符号求解器增强大型语言模型的忠实逻辑推理能力。见 *Proc. EMNLP Findings*，2023年。'
- en: Tian et al. [2021a] Jidong Tian, Yitian Li, Wenqing Chen, Liqiang Xiao, Hao
    He, and Yaohui Jin. Diagnosing the first-order logical reasoning ability through
    LogicNLI. In *Proc. EMNLP*, 2021a.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tian et al. [2021a] Jidong Tian, Yitian Li, Wenqing Chen, Liqiang Xiao, Hao
    He, 和 Yaohui Jin. 通过 LogicNLI 诊断一阶逻辑推理能力。见 *Proc. EMNLP*，2021年。
- en: Biere et al. [2021] Armin Biere, Marijn Heule, Hans van Maaren, and Toby Walsh,
    editors. *Handbook of Satisfiability - Second Edition*. IOS Press, 2021. ISBN
    978-1-64368-160-3.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Biere et al. [2021] Armin Biere, Marijn Heule, Hans van Maaren, 和 Toby Walsh,
    编辑. *Handbook of Satisfiability - Second Edition*. IOS Press，2021年。ISBN 978-1-64368-160-3。
- en: 'de Moura and Bjørner [2008] Leonardo Mendonça de Moura and Nikolaj S. Bjørner.
    Z3: An efficient SMT solver. In *Proc. TACAS*, 2008.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'de Moura 和 Bjørner [2008] Leonardo Mendonça de Moura 和 Nikolaj S. Bjørner.
    Z3: 一种高效的 SMT 求解器。见 *Proc. TACAS*，2008年。'
- en: Selman et al. [1996] Bart Selman, David G. Mitchell, and Hector J. Levesque.
    Generating hard satisfiability problems. *AIJ*, 81(1-2):17–29, 1996.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Selman et al. [1996] Bart Selman, David G. Mitchell, 和 Hector J. Levesque. 生成困难的可满足性问题。*AIJ*，81(1-2):17–29，1996年。
- en: 'OpenAI [2023a] OpenAI. Gpt-4-1106-preview. [https://arxiv.org/pdf/2303.08774.pdf](https://arxiv.org/pdf/2303.08774.pdf),
    2023a. Accessed: 2023-01-10.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI [2023a] OpenAI. Gpt-4-1106-preview. [https://arxiv.org/pdf/2303.08774.pdf](https://arxiv.org/pdf/2303.08774.pdf)，2023年。访问日期：2023-01-10。
- en: 'OpenAI [2023b] OpenAI. Gpt-3.5-turbo-0613. [https://platform.openai.com/docs/models/gpt-3-5](https://platform.openai.com/docs/models/gpt-3-5),
    2023b. Accessed: 2023-01-10.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI [2023b] OpenAI. Gpt-3.5-turbo-0613. [https://platform.openai.com/docs/models/gpt-3-5](https://platform.openai.com/docs/models/gpt-3-5)，2023年。访问日期：2023-01-10。
- en: 'Mistral AI [2023] Mistral AI. Mistral-7b instruct v0.2. [https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2),
    2023. Accessed: 2023-01-10.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mistral AI [2023] Mistral AI. Mistral-7b instruct v0.2. [https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2)，2023年。访问日期：2023-01-10。
- en: 'Google [2023] Google. Gemini pro. [https://arxiv.org/pdf/2312.11805.pdf](https://arxiv.org/pdf/2312.11805.pdf),
    2023. Accessed: 2023-01-10.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google [2023] Google. Gemini pro. [https://arxiv.org/pdf/2312.11805.pdf](https://arxiv.org/pdf/2312.11805.pdf)，2023年。访问日期：2023-01-10。
- en: McCune [2005–2010] W. McCune. Prover9 and mace4. `http://www.cs.unm.edu/~mccune/prover9/`,
    2005–2010.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: McCune [2005–2010] W. McCune. Prover9 和 mace4. `http://www.cs.unm.edu/~mccune/prover9/`，2005–2010年。
- en: Clark et al. [2020] Peter Clark, Oyvind Tafjord, and Kyle Richardson. Transformers
    as soft reasoners over language. In *Proc. IJCAI*, 2020.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Clark et al. [2020] Peter Clark, Oyvind Tafjord, 和 Kyle Richardson. 变换器作为语言的软推理器。见
    *Proc. IJCAI*，2020年。
- en: 'Han et al. [2022] Simeng Han, Hailey Schoelkopf, Yilun Zhao, Zhenting Qi, Martin
    Riddell, Luke Benson, Lucy Sun, Ekaterina Zubova, Yujie Qiao, Matthew Burtell,
    David Peng, Jonathan Fan, Yixin Liu, Brian Wong, Malcolm Sailor, Ansong Ni, Linyong
    Nan, Jungo Kasai, Tao Yu, Rui Zhang, Shafiq R. Joty, Alexander R. Fabbri, Wojciech
    Kryscinski, Xi Victoria Lin, Caiming Xiong, and Dragomir Radev. FOLIO: natural
    language reasoning with first-order logic. *CoRR*, abs/2209.00840, 2022.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Han et al. [2022] Simeng Han, Hailey Schoelkopf, Yilun Zhao, Zhenting Qi, Martin
    Riddell, Luke Benson, Lucy Sun, Ekaterina Zubova, Yujie Qiao, Matthew Burtell,
    David Peng, Jonathan Fan, Yixin Liu, Brian Wong, Malcolm Sailor, Ansong Ni, Linyong
    Nan, Jungo Kasai, Tao Yu, Rui Zhang, Shafiq R. Joty, Alexander R. Fabbri, Wojciech
    Kryscinski, Xi Victoria Lin, Caiming Xiong, 和 Dragomir Radev. FOLIO: 通过一阶逻辑进行自然语言推理。*CoRR*，abs/2209.00840，2022年。'
- en: Tian et al. [2021b] Jidong Tian, Yitian Li, Wenqing Chen, Liqiang Xiao, Hao
    He, and Yaohui Jin. Diagnosing the first-order logical reasoning ability through
    logicnli. In *Proc. EMNLP*, 2021b.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tian et al. [2021b] Jidong Tian, Yitian Li, Wenqing Chen, Liqiang Xiao, Hao
    He, 和 Yaohui Jin. 通过 logicnli 诊断一阶逻辑推理能力。见 *Proc. EMNLP*，2021年。
- en: Yang et al. [2023] Yuan Yang, Siheng Xiong, Ali Payani, Ehsan Shareghi, and
    Faramarz Fekri. Harnessing the power of large language models for natural language
    to first-order logic translation. *CoRR*, abs/2305.15541, 2023. doi:[10.48550/ARXIV.2305.15541](https://doi.org/10.48550/ARXIV.2305.15541).
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang et al. [2023] Yuan Yang, Siheng Xiong, Ali Payani, Ehsan Shareghi, 和 Faramarz
    Fekri. 利用大型语言模型进行自然语言到一阶逻辑的翻译。*CoRR*，abs/2305.15541，2023年。doi:[10.48550/ARXIV.2305.15541](https://doi.org/10.48550/ARXIV.2305.15541)。
- en: Wu et al. [2022] Yuhuai Wu, Albert Qiaochu Jiang, Wenda Li, Markus N. Rabe,
    Charles Staats, Mateja Jamnik, and Christian Szegedy. Autoformalization with large
    language models. In *Proc. NeurIPS*, 2022.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu et al. [2022] Yuhuai Wu, Albert Qiaochu Jiang, Wenda Li, Markus N. Rabe,
    Charles Staats, Mateja Jamnik, 和 Christian Szegedy. 使用大型语言模型进行自动形式化。见 *Proc. NeurIPS*，2022年。
- en: Simon and Muise [2021] Nisha Simon and Christian Muise. A natural language model
    for generating pddl. In *ICAPS KEPS workshop*, 2021.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Simon 和 Muise [2021] Nisha Simon 和 Christian Muise. 用于生成 pddl 的自然语言模型。 在 *ICAPS
    KEPS workshop*, 2021。
- en: Xie et al. [2023] Yaqi Xie, Chen Yu, Tongyao Zhu, Jinbin Bai, Ze Gong, and Harold
    Soh. Translating natural language to planning goals with large-language models.
    *CoRR*, abs/2302.05128, 2023.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie 等人 [2023] Yaqi Xie, Chen Yu, Tongyao Zhu, Jinbin Bai, Ze Gong, 和 Harold
    Soh. 使用大型语言模型将自然语言转换为规划目标。 *CoRR*, abs/2302.05128, 2023。
- en: Orenes-Vera et al. [2023] Marcelo Orenes-Vera, Margaret Martonosi, and David
    Wentzlaff. Using llms to facilitate formal verification of RTL. *CoRR*, abs/2309.09437,
    2023.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Orenes-Vera 等人 [2023] Marcelo Orenes-Vera, Margaret Martonosi, 和 David Wentzlaff.
    利用大语言模型促进 RTL 的形式验证。 *CoRR*, abs/2309.09437, 2023。
- en: Chen et al. [2021] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Pondé
    de Oliveira Pinto, Jared Kaplan, Harrison Edwards, Yuri Burda, Nicholas Joseph,
    Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf,
    Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov,
    Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet,
    Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth
    Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas
    Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders,
    Christopher Hesse, Andrew N. Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan
    Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer,
    Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and
    Wojciech Zaremba. Evaluating large language models trained on code. *CoRR*, abs/2107.03374,
    2021.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人 [2021] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Pondé
    de Oliveira Pinto, Jared Kaplan, Harrison Edwards, Yuri Burda, Nicholas Joseph,
    Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf,
    Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov,
    Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet,
    Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth
    Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas
    Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders,
    Christopher Hesse, Andrew N. Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan
    Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer,
    Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, 和 Wojciech
    Zaremba. 评估在代码上训练的大型语言模型。 *CoRR*, abs/2107.03374, 2021。
- en: Bhattacharya et al. [2023] Paheli Bhattacharya, Manojit Chakraborty, Kartheek
    N. S. N. Palepu, Vikas Pandey, Ishan Dindorkar, Rakesh Rajpurohit, and Rishabh
    Gupta. Exploring large language models for code explanation. In *Proceedings of
    the 15th Annual Meeting of the Forum for Information Retrieval Evaluation*, 2023.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bhattacharya 等人 [2023] Paheli Bhattacharya, Manojit Chakraborty, Kartheek N.
    S. N. Palepu, Vikas Pandey, Ishan Dindorkar, Rakesh Rajpurohit, 和 Rishabh Gupta.
    探索用于代码解释的大型语言模型。 在 *Proceedings of the 15th Annual Meeting of the Forum for Information
    Retrieval Evaluation*, 2023。
- en: MacNeil et al. [2023] Stephen MacNeil, Andrew Tran, Arto Hellas, Joanne Kim,
    Sami Sarsa, Paul Denny, Seth Bernstein, and Juho Leinonen. Experiences from using
    code explanations generated by large language models in a web software development
    e-book. In *Proc. SIGCSE*, 2023.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MacNeil 等人 [2023] Stephen MacNeil, Andrew Tran, Arto Hellas, Joanne Kim, Sami
    Sarsa, Paul Denny, Seth Bernstein, 和 Juho Leinonen. 使用大型语言模型生成的代码解释在 Web 软件开发电子书中的应用经验。
    在 *Proc. SIGCSE*, 2023。
