- en: æ–¯å¦ç¦ GPTï¼Transformer åŸç†ä»‹ç» (ä¸­è‹±æ–‡åŒå­—å¹•) - P14ï¼š14.Strategic Games - life_code - BV1X84y1Q7wV
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ–¯å¦ç¦ GPT/Transformer åŸç†ä»‹ç» (ä¸­è‹±æ–‡åŒå­—å¹•) - P14ï¼š14.æˆ˜ç•¥æ¸¸æˆ - life_code - BV1X84y1Q7wV
- en: '![](img/e3abef98963297997c09e5d05b736a64_0.png)'
  id: totrans-1
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e3abef98963297997c09e5d05b736a64_0.png)'
- en: '![](img/e3abef98963297997c09e5d05b736a64_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e3abef98963297997c09e5d05b736a64_1.png)'
- en: So it spend sometimes like two months training the botsã€‚On thousands of CPUsã€‚Tabytes
    and memory sometimesï¼Œ but when it came time to actually play against the humansã€‚they
    would act almost instantlyï¼Œ it was just a lookup tableã€‚And the humansã€‚when they
    were in a tough spotï¼Œ they would not act instantlyã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æœ‰æ—¶å€™éœ€è¦ä¸¤ä¸ªæœˆæ¥è®­ç»ƒè¿™äº›æœºå™¨äººã€‚åœ¨æˆåƒä¸Šä¸‡çš„CPUä¸Šï¼Œæœ‰æ—¶å€™éœ€è¦æ•°TBçš„å†…å­˜ï¼Œä½†å½“çœŸæ­£ä¸äººç±»å¯¹æˆ˜æ—¶ï¼Œä»–ä»¬å‡ ä¹æ˜¯ç¬é—´è¡ŒåŠ¨çš„ï¼Œè¿™åªæ˜¯ä¸€ä¸ªæŸ¥æ‰¾è¡¨ã€‚è€Œäººç±»åœ¨å›°å¢ƒä¸­å¹¶ä¸ä¼šç«‹å³è¡ŒåŠ¨ã€‚
- en: they would think they would sit there and they would think for five secondsã€‚maybe
    five minutes if it was a really difficult decision and it was clear that that
    was allowing them to come up with better strategiesã€‚And so I wanted to investigate
    this behavior in our bots like if we could add this to our botsã€‚how much of a
    difference would it makeï¼Œ the ability to instead of acting instantly to take some
    time and compute a better strategy for the spot that the agent was inã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ä»–ä»¬ä¼šååœ¨é‚£é‡Œæ€è€ƒäº”ç§’é’Ÿï¼Œå¯èƒ½åœ¨éå¸¸å›°éš¾çš„å†³å®šä¸­æ€è€ƒäº”åˆ†é’Ÿï¼Œå¾ˆæ˜æ˜¾ï¼Œè¿™ä½¿ä»–ä»¬èƒ½å¤Ÿæƒ³å‡ºæ›´å¥½çš„ç­–ç•¥ã€‚æ‰€ä»¥æˆ‘æƒ³åœ¨æˆ‘ä»¬çš„æœºå™¨äººä¸­è°ƒæŸ¥è¿™ç§è¡Œä¸ºï¼Œçœ‹çœ‹å¦‚æœæˆ‘ä»¬èƒ½å¤Ÿå°†å…¶æ·»åŠ åˆ°æˆ‘ä»¬çš„æœºå™¨äººä¸­ï¼Œä¼šæœ‰å¤šå¤§ä¸åŒï¼Œèƒ½å¤Ÿä¸æ˜¯ç«‹å³è¡ŒåŠ¨ï¼Œè€Œæ˜¯èŠ±äº›æ—¶é—´è®¡ç®—å‡ºæ›´å¥½çš„ç­–ç•¥ã€‚
- en: And this is what I foundã€‚So on the X axis here we have like the number of bucketsã€‚the
    number you can think of this as like the number of parameters in your model and
    on the Y axis we have distance from national equilibrium so this is basically
    like how much you would lose towards worstk's adversary so the lower this number
    is the better your poker bot is and you can see as you scale the number of parametersã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘å‘ç°çš„ã€‚å› æ­¤ï¼Œåœ¨Xè½´ä¸Šæˆ‘ä»¬æœ‰æ¡¶çš„æ•°é‡ï¼Œä½ å¯ä»¥æŠŠè¿™ä¸ªæƒ³è±¡æˆæ¨¡å‹ä¸­çš„å‚æ•°æ•°é‡ï¼Œè€Œåœ¨Yè½´ä¸Šæˆ‘ä»¬æœ‰è·ç¦»çº³ä»€å‡è¡¡çš„è·ç¦»ï¼Œè¿™åŸºæœ¬ä¸Šæ˜¯ä½ åœ¨æœ€åå¯¹æ‰‹é¢å‰æŸå¤±å¤šå°‘ï¼Œæ‰€ä»¥è¿™ä¸ªæ•°å­—è¶Šä½ï¼Œä½ çš„æ‰‘å…‹æœºå™¨äººå°±è¶Šå¥½ï¼Œä½ å¯ä»¥çœ‹åˆ°éšç€å‚æ•°æ•°é‡çš„å¢åŠ ã€‚
- en: your performance improves and as you increase the number of parameters by about100
    x you know your exploitability goes down by about half and indeed you're getting
    a much better poker botã€‚But you can see the blue line here is if you don't have
    search and the orange line is if you do add searchã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ çš„è¡¨ç°æœ‰æ‰€æé«˜ï¼Œå½“ä½ å°†å‚æ•°æ•°é‡å¢åŠ çº¦100å€æ—¶ï¼Œä½ ä¼šå‘ç°å¯åˆ©ç”¨æ€§é™ä½äº†å¤§çº¦ä¸€åŠï¼Œå®é™…ä¸Šä½ å¾—åˆ°äº†ä¸€ä¸ªæ›´å¥½çš„æ‰‘å…‹æœºå™¨äººã€‚ä½†ä½ å¯ä»¥çœ‹åˆ°è¿™é‡Œçš„è“çº¿æ˜¯å¦‚æœæ²¡æœ‰æœç´¢ï¼Œæ©™çº¿æ˜¯å¦‚æœä½ æ·»åŠ äº†æœç´¢ã€‚
- en: ğŸ˜¡ï¼ŒAnd you can see just adding searchï¼Œ adding the ability to sit there and think
    for a bitã€‚improve the performance of these modelsã€‚And it reduced the exploitabilityã€‚the
    distance from ra equilibrium by about 7 xã€‚And if you were to extend that blue
    line and see how many prim would you need in order to be comparable to adding
    searchã€‚the answer is you would need to scale up your model by about 100ï¼Œ000 xã€‚Okayã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜¡ï¼Œä½ å¯ä»¥çœ‹åˆ°ï¼Œä»…ä»…æ·»åŠ æœç´¢ï¼Œå¢åŠ åä¸‹æ¥æ€è€ƒçš„èƒ½åŠ›ï¼Œå°±æå‡äº†è¿™äº›æ¨¡å‹çš„è¡¨ç°ã€‚å®ƒå‡å°‘äº†å¯åˆ©ç”¨æ€§ï¼Œè·ç¦»çº³ä»€å‡è¡¡å¤§çº¦é™ä½äº†7å€ã€‚å¦‚æœä½ æƒ³å»¶é•¿é‚£æ¡è“çº¿ï¼Œçœ‹çœ‹éœ€è¦å¤šå°‘ä¸ªå‚æ•°æ‰èƒ½ä¸æ·»åŠ æœç´¢ç›¸åª²ç¾ï¼Œç­”æ¡ˆæ˜¯ä½ éœ€è¦å°†æ¨¡å‹çš„è§„æ¨¡æ‰©å¤§çº¦100,000å€ã€‚å¥½çš„ã€‚
- en: So this was pretty mind blowlowing to me when I saw thisï¼Œ I meanï¼Œ over the course
    of my PhDã€‚the first three yearsï¼Œ first three or four years of my PhDã€‚I' managed
    to scale up these models by about 100 xã€‚å—¯ã€‚And I was proud of thatï¼Œ I meanã€‚that's
    like a pretty pretty impressive resultï¼Œ I thinkã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘çœ‹åˆ°è¿™ä¸€ç‚¹æ—¶ï¼Œæˆ‘æ„Ÿåˆ°éå¸¸éœ‡æ’¼ï¼Œæ„æ€æ˜¯ï¼Œåœ¨æˆ‘åšå£«å­¦ä½çš„è¿‡ç¨‹ä¸­ï¼Œå‰ä¸‰å¹´ï¼Œå‰ä¸‰åˆ°å››å¹´ï¼Œæˆ‘æˆåŠŸåœ°å°†è¿™äº›æ¨¡å‹çš„è§„æ¨¡æ‰©å¤§äº†çº¦100å€ã€‚å—¯ã€‚æˆ‘å¯¹æ­¤æ„Ÿåˆ°è‡ªè±ªï¼Œæˆ‘è®¤ä¸ºè¿™çœŸæ˜¯ä¸€ä¸ªç›¸å½“ç›¸å½“ä»¤äººå°è±¡æ·±åˆ»çš„ç»“æœã€‚
- en: But what this plot was showing me was that just adding searchã€‚Was the equivalent
    of scaling things up by about 100ï¼Œ000 xã€‚and so all of my previous research up
    until this pointã€‚Would just be a footnote compared to adding searchã€‚Soã€‚When I
    saw thisï¼Œ it became clearã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¿™å¼ å›¾è¡¨å‘æˆ‘å±•ç¤ºçš„æ˜¯ï¼Œä»…ä»…æ·»åŠ æœç´¢ï¼Œç›¸å½“äºå°†è§„æ¨¡æ‰©å¤§çº¦100,000å€ã€‚æ‰€ä»¥æˆ‘ä¹‹å‰çš„æ‰€æœ‰ç ”ç©¶åˆ°è¿™ä¸€ç‚¹ä¸ºæ­¢ï¼Œåªèƒ½ç®—ä½œè„šæ³¨ï¼Œè·Ÿæ·»åŠ æœç´¢ç›¸æ¯”ã€‚å› æ­¤ï¼Œå½“æˆ‘çœ‹åˆ°è¿™ä¸€ç‚¹æ—¶ï¼Œå˜å¾—æ¸…æ™°èµ·æ¥ã€‚
- en: this was the answer to beating top humans in pokerï¼Œ and so for the next yearï¼Œ
    basically nonstopã€‚I worked on scaling searchã€‚Now there's a question that naturally
    comes up which is why wasn't this considered before there's a few factors so first
    of all I should say like the search had been considered in poker before and it's
    actually quite natural to say like well you know if you had search and chess and
    search and go like why would you not consider search in pokerã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯æˆ˜èƒœé¡¶å°–äººç±»æ‰‘å…‹é€‰æ‰‹çš„ç­”æ¡ˆï¼Œå› æ­¤åœ¨æ¥ä¸‹æ¥çš„ä¸€å¹´é‡Œï¼Œæˆ‘å‡ ä¹ä¸é—´æ–­åœ°è‡´åŠ›äºæ‰©å±•æœç´¢ã€‚ç°åœ¨è‡ªç„¶ä¼šå‡ºç°ä¸€ä¸ªé—®é¢˜ï¼Œé‚£å°±æ˜¯ä¸ºä»€ä¹ˆä¹‹å‰æ²¡æœ‰è€ƒè™‘åˆ°è¿™ä¸€ç‚¹ã€‚é¦–å…ˆï¼Œæˆ‘åº”è¯¥è¯´æ‰‘å…‹ä¸­çš„æœç´¢åœ¨ä¹‹å‰æ˜¯è¢«è€ƒè™‘è¿‡çš„ï¼Œå®é™…ä¸Šå¯ä»¥è¯´åœ¨å›½é™…è±¡æ£‹å’Œå›´æ£‹ä¸­éƒ½æœ‰æœç´¢ï¼Œé‚£ä¹ˆä¸ºä»€ä¹ˆåœ¨æ‰‘å…‹ä¸­ä¸è€ƒè™‘æœç´¢å‘¢ï¼Ÿ
- en: There's a few reasonsï¼Œ one is thatã€‚Culturally like the poker research grew out
    of game theory and reinforcement learning and so it wasn't really from the same
    background as like the people are working on chess and working on goã€‚When you
    scale search scaling test time compute it makes all your experiments much more
    expensive and just like more unpleasant to work with and there are just like incentive
    structures I mean people are always thinking about winning the next annual computer
    poker competition and the ACPC limited the resources that you could use at test
    time so search wasn't really possible effectively in the ACPCã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å‡ ä¸ªåŸå› ï¼Œå…¶ä¸€æ˜¯æ–‡åŒ–æ–¹é¢ï¼Œæ‰‘å…‹ç ”ç©¶èµ·æºäºåšå¼ˆè®ºå’Œå¼ºåŒ–å­¦ä¹ ï¼Œå¹¶ä¸æ˜¯ä¸ä»äº‹å›½é™…è±¡æ£‹å’Œå›´æ£‹ç ”ç©¶çš„äººç›¸åŒçš„èƒŒæ™¯ã€‚å½“ä½ æ‰©å±•æœç´¢ï¼Œæ‰©å±•æµ‹è¯•æ—¶é—´çš„è®¡ç®—æ—¶ï¼Œä¼šä½¿ä½ çš„å®éªŒæˆæœ¬å¤§å¹…å¢åŠ ï¼Œä¹Ÿè®©å·¥ä½œå˜å¾—æ›´åŠ ä¸æ„‰å¿«ã€‚è¿˜æœ‰ä¸€äº›æ¿€åŠ±ç»“æ„ï¼Œæ¯•ç«Ÿäººä»¬æ€»æ˜¯æƒ³ç€èµ¢å¾—ä¸‹ä¸€ä¸ªå¹´åº¦è®¡ç®—æœºæ‰‘å…‹æ¯”èµ›ï¼Œè€ŒACPCé™åˆ¶äº†ä½ åœ¨æµ‹è¯•æ—¶å¯ä»¥ä½¿ç”¨çš„èµ„æºï¼Œå› æ­¤åœ¨ACPCä¸­å®é™…ä¸Šæ˜¯æ— æ³•æœ‰æ•ˆè¿›è¡Œæœç´¢çš„ã€‚
- en: And I think the biggest factor is that people just didn't think it would make
    such a huge difference I mean I think it's reasonable to look at something like
    search and think like oh yeah that might make like a 10 X difference you probably
    wouldnt think it makes a 10000 x difference and so there were some people working
    on it but it wasn't really the focus of a lot of people's researchã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºæœ€å¤§çš„å› ç´ æ˜¯äººä»¬æ ¹æœ¬æ²¡æœ‰æƒ³åˆ°è¿™ä¼šäº§ç”Ÿå¦‚æ­¤å·¨å¤§çš„å·®å¼‚ã€‚æˆ‘è®¤ä¸ºåˆç†åœ°çœ‹å¾…åƒæœç´¢è¿™æ ·çš„ä¸œè¥¿ï¼Œè®¤ä¸ºå®ƒå¯èƒ½ä¼šå¸¦æ¥10å€çš„å·®å¼‚ï¼Œä½†ä½ å¯èƒ½ä¸ä¼šæƒ³åˆ°å®ƒä¼šäº§ç”Ÿ10,000å€çš„å·®å¼‚ï¼Œå› æ­¤è™½ç„¶æœ‰ä¸€äº›äººåœ¨ç ”ç©¶è¿™ä¸ªï¼Œä½†å®ƒå¹¶ä¸æ˜¯å¾ˆå¤šäººç ”ç©¶çš„é‡ç‚¹ã€‚
- en: So anywayï¼Œ focused on scaling search and that led to the 2017 Bras versus AIT
    competition where we again played our bot against four top poker prosã€‚120ï¼Œ000
    hands of poker $200ï¼Œ0000 prize money and this time the bot won by 15 big blinds
    per100 instead of nine big blinds per100ã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æ— è®ºå¦‚ä½•ï¼Œä¸“æ³¨äºæ‰©å±•æœç´¢ï¼Œè¿™å¯¼è‡´äº†2017å¹´Brasä¸AITçš„æ¯”èµ›ï¼Œæˆ‘ä»¬å†æ¬¡å°†æˆ‘ä»¬çš„æœºå™¨äººä¸å››ä½é¡¶çº§æ‰‘å…‹é«˜æ‰‹å¯¹æˆ˜ã€‚120,000æ‰‹æ‰‘å…‹ï¼Œ$200,000çš„å¥–é‡‘ï¼Œè¿™æ¬¡æœºå™¨äººæ¯100æ‰‹èµ¢äº†15ä¸ªå¤§ç›²æ³¨ï¼Œè€Œä¸æ˜¯ä¹‹å‰çš„9ä¸ªå¤§ç›²æ³¨ã€‚
- en: This was a crushing victoryï¼Œ each human lost individually to the bot andã€‚![](img/e3abef98963297997c09e5d05b736a64_3.png)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€åœºæ¯ç­æ€§çš„èƒœåˆ©ï¼Œæ¯ä½äººç±»é€‰æ‰‹éƒ½å•ç‹¬è¾“ç»™äº†æœºå™¨äººã€‚![](img/e3abef98963297997c09e5d05b736a64_3.png)
- en: Four standard deviations of statistical significanceã€‚We followed this up in
    2019 with six player poke AI competitionã€‚The big difference here is that we figured
    out how to do depth limited searchã€‚so before the 2017 bot it would always have
    the search to the end of the game here it only had to do search a few moves ahead
    and it could stop thereã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: å››ä¸ªæ ‡å‡†å·®çš„ç»Ÿè®¡æ˜¾è‘—æ€§ã€‚æˆ‘ä»¬åœ¨2019å¹´è¿›è¡Œäº†å…­äººæ‰‘å…‹äººå·¥æ™ºèƒ½æ¯”èµ›ã€‚æœ€å¤§çš„åŒºåˆ«åœ¨äºæˆ‘ä»¬æ‰¾åˆ°äº†å¦‚ä½•è¿›è¡Œæ·±åº¦é™åˆ¶æœç´¢ã€‚å› æ­¤ï¼Œåœ¨2017å¹´çš„æœºå™¨äººæ¯”èµ›ä¸­ï¼Œå®ƒæ€»æ˜¯éœ€è¦æœç´¢åˆ°æ¸¸æˆçš„å°½å¤´ï¼Œè€Œè¿™æ¬¡åªéœ€æœç´¢å‡ æ­¥ä¹‹åå°±å¯ä»¥åœæ­¢ã€‚
- en: And so this time againï¼Œ it wont with statistical significanceã€‚and what's really
    surprising about this spot is that despite it being a much larger gameã€‚the six
    player Pokerbot Plebuvis cost under $150 to train on cloud computing resources
    and it runs on 28 CPU cores at inference timeã€‚there's no GPUsã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™æ¬¡å†æ¬¡è·å¾—äº†ç»Ÿè®¡æ˜¾è‘—æ€§ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œå°½ç®¡è¿™æ˜¯ä¸€ä¸ªæ›´å¤§çš„æ¸¸æˆï¼Œè¿™ä¸ªå…­äººæ‰‘å…‹æœºå™¨äººPlebuvisåœ¨äº‘è®¡ç®—èµ„æºä¸Šè®­ç»ƒçš„è´¹ç”¨ä¸è¶³150ç¾å…ƒï¼Œå¹¶ä¸”åœ¨æ¨ç†æ—¶è¿è¡Œäº28ä¸ªCPUæ ¸å¿ƒä¸Šï¼Œæ²¡æœ‰ä½¿ç”¨GPUã€‚
- en: '![](img/e3abef98963297997c09e5d05b736a64_5.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e3abef98963297997c09e5d05b736a64_5.png)'
- en: So I think what this shows is thatã€‚This really wasn an algorithmic improvementã€‚I
    mean this would have been doable 20 years ago if if people knew how to do itã€‚And
    I think it also shows the power of searchï¼Œ you knowã€‚if you can figure out how
    to scale that compute at test timeã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘è®¤ä¸ºè¿™è¡¨æ˜ï¼Œè¿™å®é™…ä¸Šå¹¶ä¸æ˜¯ç®—æ³•ä¸Šçš„æ”¹è¿›ã€‚æˆ‘æ˜¯è¯´ï¼Œå¦‚æœäººä»¬çŸ¥é“æ€ä¹ˆåšï¼Œ20å¹´å‰å°±èƒ½åšåˆ°è¿™ä¸€ç‚¹ã€‚æˆ‘è®¤ä¸ºè¿™ä¹Ÿæ˜¾ç¤ºäº†æœç´¢çš„å¨åŠ›ï¼Œå¦‚æœä½ èƒ½æ‰¾å‡ºå¦‚ä½•åœ¨æµ‹è¯•æ—¶æ‰©å±•è®¡ç®—ã€‚
- en: it really can make a huge difference and bring down your your training costs
    by a huge amountã€‚è¯¶ã€‚ğŸ˜Šã€‚Okayï¼Œ anywayï¼Œ yeahï¼Œ so I wanted to say also this is not limited
    to poker if you look at go you see a similar patternã€‚so this is a plot from the
    alphago zero paperã€‚On the X axisã€‚we have different versions of alphaphago and
    on the y axisï¼Œ we have elo ratingã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™çœŸçš„å¯ä»¥å¸¦æ¥å·¨å¤§çš„å·®å¼‚ï¼Œå¹¶å¤§å¹…é™ä½ä½ çš„è®­ç»ƒæˆæœ¬ã€‚è¯¶ã€‚ğŸ˜Šã€‚å¥½çš„ï¼Œæ— è®ºå¦‚ä½•ï¼Œæˆ‘è¿˜æƒ³è¯´ï¼Œè¿™ä¸ä»…é™äºæ‰‘å…‹ï¼Œå¦‚æœä½ çœ‹çœ‹å›´æ£‹ï¼Œä½ ä¼šçœ‹åˆ°ç±»ä¼¼çš„æ¨¡å¼ã€‚è¿™æ˜¯æ¥è‡ªAlphaGo
    Zeroè®ºæ–‡çš„ä¸€ä¸ªå›¾ã€‚Xè½´æ˜¯ä¸åŒç‰ˆæœ¬çš„AlphaGoï¼ŒYè½´æ˜¯eloè¯„åˆ†ã€‚
- en: which is a way of comparing different botsï¼Œ but also a way of comparing bots
    to humansã€‚And you can see ifã€‚Okayï¼Œ so superhuid performance is around 3ï¼Œ600 eloã€‚And
    you can see Alpha Go Leeã€‚the version that played against Li Addal in 2016ï¼Œ that's
    right over the line of superhuman performanceã€‚Alphago is zeroï¼Œ the strongest version
    of alphaphago is around 5ï¼Œ200 eloã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ç§æ¯”è¾ƒä¸åŒæœºå™¨äººï¼Œä»¥åŠå°†æœºå™¨äººä¸äººç±»è¿›è¡Œæ¯”è¾ƒçš„æ–¹æ³•ã€‚ä½ å¯ä»¥çœ‹åˆ°ï¼Œå¦‚æœä½ æŸ¥çœ‹è¶…çº§äººç±»çš„è¡¨ç°ï¼Œå¤§çº¦æ˜¯3600 eloã€‚ä½ å¯ä»¥çœ‹åˆ°Alpha Go Leeï¼Œ2016å¹´ä¸æä¸–çŸ³å¯¹å¼ˆçš„ç‰ˆæœ¬ï¼Œæ­£å¥½è¶…è¿‡è¶…çº§äººç±»è¡¨ç°çš„çº¿ã€‚æœ€å¼ºçš„AlphaGoç‰ˆæœ¬å¤§çº¦æ˜¯5200
    eloã€‚
- en: But if you take out the test time searchï¼Œ if you just play according to the
    policy net and not do any modc research in alphago was zero at test timeã€‚then
    the eO rating drops to around 3ï¼Œ000ï¼Œ which is substantially below expert human
    performanceã€‚So what this shows is that if you take out Montegli research at test
    timeã€‚ğŸ˜¡ã€‚The alphaphaGo zero is not superhuman and in fact nobody has made a superhuman
    gobot that does not use search in some formã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯å¦‚æœä½ å»æ‰æµ‹è¯•æ—¶é—´çš„æœç´¢ï¼Œå¦‚æœä½ åªæ˜¯æ ¹æ®ç­–ç•¥ç½‘ç»œè¿›è¡Œæ¸¸æˆï¼Œè€Œä¸åœ¨AlphaGo Zeroçš„æµ‹è¯•æ—¶é—´è¿›è¡Œä»»ä½•è’™ç‰¹å¡æ´›ç ”ç©¶ï¼Œé‚£ä¹ˆeloè¯„åˆ†ä¼šé™åˆ°å¤§çº¦3000ï¼Œè¿™è¿œä½äºä¸“å®¶äººç±»çš„è¡¨ç°ã€‚è¿™æ˜¾ç¤ºï¼Œå¦‚æœåœ¨æµ‹è¯•æ—¶é—´å»æ‰è’™ç‰¹å¡æ´›ç ”ç©¶ï¼ŒğŸ˜¡ï¼ŒAlphaGo
    Zeroå¹¶ä¸æ˜¯è¶…çº§äººç±»çš„ï¼Œå®é™…ä¸Šæ²¡æœ‰äººåˆ¶ä½œå‡ºä¸ä½¿ç”¨æŸç§å½¢å¼æœç´¢çš„è¶…çº§äººç±»å›´æ£‹æœºå™¨äººã€‚
- en: nobody has made a raw neural network that can beat top humans in goã€‚And I should
    say alsoã€‚this is just if you're taking out the search at test timeã€‚I'm not even
    talking about taking it out of training timeï¼Œ if you took it out of training timeã€‚we
    wouldn't even got off the groundã€‚Now there's a question of like okay wellã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æ²¡æœ‰äººåˆ¶ä½œå‡ºèƒ½å‡»è´¥é¡¶çº§äººç±»çš„åŸå§‹ç¥ç»ç½‘ç»œã€‚å¦‚æœæˆ‘è¿˜è¦è¯´ï¼Œè¿™æ˜¯å¦‚æœåœ¨æµ‹è¯•æ—¶é—´å»æ‰æœç´¢ã€‚æˆ‘ç”šè‡³ä¸è°ˆåœ¨è®­ç»ƒæ—¶é—´å»æ‰æœç´¢ï¼Œå¦‚æœä½ åœ¨è®­ç»ƒæ—¶é—´å»æ‰å®ƒï¼Œæˆ‘ä»¬ç”šè‡³æ— æ³•èµ·æ­¥ã€‚ç°åœ¨æœ‰ä¸€ä¸ªé—®é¢˜å°±æ˜¯ï¼Œå¥½å§ã€‚
- en: surely you could just scale up the modelï¼Œ scale up the matter of training and
    you would eventually you know surpass the humanment performance and match the
    performance if you added search and that's true yesã€‚if you scale up the models
    and if you scale up the trainingã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œä½ å¯ä»¥æ‰©å¤§æ¨¡å‹ï¼Œå¢åŠ è®­ç»ƒçš„é‡ï¼Œæœ€ç»ˆè¶…è¶Šäººç±»çš„è¡¨ç°ï¼Œå¦‚æœä½ æ·»åŠ æœç´¢ï¼Œè¿™ä¹Ÿæ˜¯æ­£ç¡®çš„ã€‚å¦‚æœä½ æ‰©å¤§æ¨¡å‹å’Œè®­ç»ƒè§„æ¨¡ã€‚
- en: then you would eventually match the performance with searchã€‚but there's a question
    of like how much would you have to scale it up byã€‚Nowã€‚a rough rule of thumb is
    that in order to increase your eO rating by about 120 pointsã€‚you either have to
    double the amount of model size and training or you have to double the amount
    of test time searchã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åä½ æœ€ç»ˆä¼šé€šè¿‡æœç´¢åŒ¹é…è¡¨ç°ã€‚ä½†æ˜¯æœ‰ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œä½ éœ€è¦æ‰©å¤§å¤šå°‘è§„æ¨¡ã€‚å¤§è‡´ç»éªŒæ³•åˆ™æ˜¯ï¼Œè¦å°†ä½ çš„eloè¯„åˆ†æé«˜çº¦120ç‚¹ï¼Œä½ è¦ä¹ˆéœ€è¦å°†æ¨¡å‹å¤§å°å’Œè®­ç»ƒé‡ç¿»å€ï¼Œè¦ä¹ˆéœ€è¦å°†æµ‹è¯•æ—¶é—´çš„æœç´¢ç¿»å€ã€‚
- en: And so if you look at that gap of around 2000 elow points and you calculate
    the number of deadlings that you would needã€‚the answer is that in order to get
    the raw policy net from 3ï¼Œ000 e to 5200 elowã€‚you would need to scale your model
    and your training by about 100ï¼Œ00xã€‚Okayã€‚so why is this importantï¼ŸğŸ˜¡ï¼ŒI think you
    look at what's happening today with large language models and transformers and
    and you see something similarã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ çœ‹é‚£å¤§çº¦2000 eloç‚¹çš„å·®è·ï¼Œè®¡ç®—ä¸€ä¸‹ä½ éœ€è¦çš„deadlingsæ•°é‡ï¼Œç­”æ¡ˆæ˜¯ä¸ºäº†è®©åŸå§‹ç­–ç•¥ç½‘ç»œä»3000 eloæå‡åˆ°5200 eloï¼Œä½ éœ€è¦å°†æ¨¡å‹å’Œè®­ç»ƒæ‰©å¤§å¤§çº¦100000å€ã€‚å¥½çš„ã€‚é‚£ä¹ˆè¿™ä¸ºä»€ä¹ˆé‡è¦å‘¢ï¼ŸğŸ˜¡ï¼Œæˆ‘è®¤ä¸ºçœ‹çœ‹ä»Šå¤©çš„å¤§å‹è¯­è¨€æ¨¡å‹å’Œå˜æ¢å™¨ï¼Œä½ ä¼šçœ‹åˆ°ç±»ä¼¼çš„æƒ…å†µã€‚
- en: I meanï¼Œ you're gettingã€‚Huge there's a question of like what do I mean by search
    there's a specific kinds of search like multiult researchã€‚the ability to just
    like plan ahead what you're going to do instead of just like acting instantly
    based on your precomputed policyã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘çš„æ„æ€æ˜¯ï¼Œä½ å¾—åˆ°äº†ã€‚å·¨å¤§çš„é—®é¢˜æ˜¯ï¼Œæˆ‘æ‰€è¯´çš„æœç´¢æ˜¯ä»€ä¹ˆæ„æ€ï¼Œæœ‰ä¸€ç§ç‰¹å®šçš„æœç´¢ç±»å‹ï¼Œæ¯”å¦‚å¤šç›®æ ‡æœç´¢ï¼Œèƒ½å¤Ÿæå‰è§„åˆ’ä½ å°†è¦åšçš„äº‹æƒ…ï¼Œè€Œä¸æ˜¯ä»…ä»…æ ¹æ®é¢„å…ˆè®¡ç®—çš„ç­–ç•¥ç¬é—´è¡ŒåŠ¨ã€‚
- en: but really what I mean by search more broadly is the ability to scale the amount
    of computation to get better performanceã€‚I think that's the real value that search
    is adding instead of just like acting according to your precomputdã€‚You knowï¼Œ front
    loading all of your computations so you're doing everything all your computation
    ahead of time and then like at inference time acting basically instantlyã€‚Could
    you get a better solution if you had five minutes to output an action instead
    of 100 millisecondsï¼Ÿ
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘æ›´å¹¿ä¹‰ä¸Šæ‰€æŒ‡çš„æœç´¢æ˜¯èƒ½å¤Ÿæ‰©å±•è®¡ç®—é‡ä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½ã€‚æˆ‘è®¤ä¸ºè¿™æ‰æ˜¯çœŸæ­£çš„ä»·å€¼ï¼Œè€Œä¸ä»…ä»…æ˜¯æ ¹æ®ä½ çš„é¢„è®¡ç®—æ¥è¡ŒåŠ¨ã€‚ä½ çŸ¥é“ï¼ŒæŠŠæ‰€æœ‰è®¡ç®—éƒ½æå‰å®Œæˆï¼Œç„¶ååœ¨æ¨ç†æ—¶å‡ ä¹ç¬é—´è¡ŒåŠ¨ã€‚å¦‚æœä½ æœ‰äº”åˆ†é’Ÿè¾“å‡ºä¸€ä¸ªåŠ¨ä½œï¼Œè€Œä¸æ˜¯100æ¯«ç§’ï¼Œèƒ½å¦å¾—åˆ°æ›´å¥½çš„è§£å†³æ–¹æ¡ˆï¼Ÿ
- en: Okayã€‚Soã€‚Yeahï¼Œ I think you look atã€‚I'm sorryï¼Œ there's a questionã€‚does a transformer
    with a search circuit count as searchã€‚or do you mean and engineering search algorithmsï¼ŸI
    don't want to get bogged down into like the details of like how to do this because
    like the answer is nobody really knows yetã€‚nobody really has a general way of
    doing search and all the domains that we've done search successfully like poker
    and go it's done in a fairly domain specific wayã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½å§ã€‚æ‰€ä»¥ã€‚æ˜¯çš„ï¼Œæˆ‘è§‰å¾—ä½ è¦çœ‹ä¸€ä¸‹ã€‚æŠ±æ­‰ï¼Œæœ‰ä¸ªé—®é¢˜ã€‚å¸¦æœ‰æœç´¢ç”µè·¯çš„å˜å‹å™¨ç®—ä½œæœç´¢å—ï¼Ÿè¿˜æ˜¯ä½ æŒ‡çš„æ˜¯å·¥ç¨‹æœç´¢ç®—æ³•ï¼Ÿæˆ‘ä¸æƒ³æ·±å…¥æ¢è®¨å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹ï¼Œå› ä¸ºç­”æ¡ˆæ˜¯ç›®å‰æ²¡äººçœŸæ­£çŸ¥é“ã€‚æˆ‘ä»¬åœ¨æ‰‘å…‹å’Œå›´æ£‹ç­‰é¢†åŸŸæˆåŠŸè¿›è¡Œæœç´¢çš„æ–¹å¼éƒ½æ˜¯ç›¸å½“ç‰¹å®šäºé¢†åŸŸçš„ã€‚
- en: you know go use this algorithm called multiola researchã€‚And yeahã€‚you could think
    of beamS searcharch as like one simple form of searchï¼Œ butã€‚it does seem like there
    should be betterï¼Œ better ways in the futureã€‚Yeahã€‚So anywayã€‚where I'm going with
    this is like you look at how large language models are being trained today and
    you knowã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ çŸ¥é“ï¼Œå»ä½¿ç”¨è¿™ä¸ªå«åšå¤šå±‚ç ”ç©¶çš„ç®—æ³•ã€‚æ˜¯çš„ã€‚ä½ å¯ä»¥æŠŠæŸæœç´¢çœ‹ä½œä¸€ç§ç®€å•çš„æœç´¢å½¢å¼ï¼Œä½†çœ‹èµ·æ¥æœªæ¥åº”è¯¥ä¼šæœ‰æ›´å¥½çš„æ–¹æ³•ã€‚æ˜¯çš„ã€‚æ‰€ä»¥ï¼Œæ— è®ºå¦‚ä½•ï¼Œæˆ‘çš„æ„æ€æ˜¯ï¼Œä½ è¦çœ‹çœ‹ä»Šå¤©å¤§å‹è¯­è¨€æ¨¡å‹æ˜¯å¦‚ä½•è®­ç»ƒçš„ã€‚
- en: you're seeing millions of dollars being thrown at pre training likeã€‚I wouldn't
    be surprised if we see a large language model that would cost like $100 million
    to trainã€‚We might even get to a billion dollarsã€‚Butã€‚The inference cost is still
    going to be very smallã€‚And so there's a question of likeï¼Œ could you do substantially
    better if you couldï¼Ÿ
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¼šçœ‹åˆ°æ•°ç™¾ä¸‡ç¾å…ƒè¢«æŠ•å…¥åˆ°é¢„è®­ç»ƒä¸­ã€‚ æˆ‘ä¸ä¼šæƒŠè®¶å¦‚æœæˆ‘ä»¬çœ‹åˆ°ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹è®­ç»ƒæˆæœ¬è¾¾åˆ°1äº¿ç¾å…ƒã€‚æˆ‘ä»¬ç”šè‡³å¯èƒ½è¾¾åˆ°10äº¿ç¾å…ƒã€‚ä½†æ¨ç†æˆæœ¬ä»ç„¶ä¼šéå¸¸å°ã€‚å› æ­¤æœ‰ä¸ªé—®é¢˜ï¼šå¦‚æœå¯ä»¥çš„è¯ï¼Œä½ èƒ½å¦åšå¾—æ›´å¥½ï¼Ÿ
- en: Scall the amount of inference cost as wellã€‚Maybe that could like amortize some
    of your training costã€‚Yeahã€‚Okayï¼Œ so there's thisã€‚There's this lecture called the
    Bi lessons by Richard Sutton that says the biggest lesson that can be learnedã€‚and
    so it's a really great essay I recommend reading itã€‚but one of the big takeaways
    is like he says the biggest lesson that can be learned from over 70 years of AI
    research is that general methods that leverage computation are ultimately the
    most effectiveã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹Ÿè¦è€ƒè™‘æ¨ç†æˆæœ¬çš„è§„æ¨¡ã€‚ä¹Ÿè®¸è¿™å¯ä»¥æ‘Šé”€ä½ çš„ä¸€äº›è®­ç»ƒæˆæœ¬ã€‚æ˜¯çš„ã€‚å¥½å§ï¼Œæœ‰ä¸€åœºè®²åº§å«åšç†æŸ¥å¾·Â·è¨é¡¿çš„ã€ŠBiæ•™è®­ã€‹ï¼Œå®ƒè¯´æœ€å¤§çš„æ•™è®­å°±æ˜¯å¯ä»¥å­¦åˆ°çš„ã€‚æ‰€ä»¥è¿™æ˜¯ç¯‡å¾ˆå¥½çš„æ–‡ç« ï¼Œæˆ‘æ¨èé˜…è¯»ã€‚ä½†å…¶ä¸­ä¸€ä¸ªä¸»è¦çš„æ”¶è·æ˜¯ï¼Œä»–è¯´ä»70å¤šå¹´AIç ”ç©¶ä¸­å­¦åˆ°çš„æœ€å¤§æ•™è®­æ˜¯ï¼Œåˆ©ç”¨è®¡ç®—çš„é€šç”¨æ–¹æ³•æœ€ç»ˆæ˜¯æœ€æœ‰æ•ˆçš„ã€‚
- en: The two methods that seem to scale arbitrarily in this way are search and learningã€‚Nowã€‚I
    think we've done a great job with generalizing searchï¼Œ sorryï¼Œ generalizing learningã€‚and
    I think there's still room for improvement when it comes to searchã€‚U and yeahã€‚the
    next goal really is about generalityï¼Œ like can we develop a truly general way
    of scaling inference compute instead of just doing things like Montecalo research
    that are specific to a better domain to a specific domainã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼¼ä¹ä»¥è¿™ç§æ–¹å¼æ— é™æ‰©å±•çš„ä¸¤ç§æ–¹æ³•æ˜¯æœç´¢å’Œå­¦ä¹ ã€‚ç°åœ¨ã€‚æˆ‘è®¤ä¸ºæˆ‘ä»¬åœ¨æ¨å¹¿æœç´¢æ–¹é¢åšå¾—å¾ˆå¥½ï¼ŒæŠ±æ­‰ï¼Œæ¨å¹¿å­¦ä¹ æ–¹é¢ã€‚æˆ‘è®¤ä¸ºåœ¨æœç´¢æ–¹é¢ä»ç„¶æœ‰æ”¹è¿›çš„ç©ºé—´ã€‚ä½ çŸ¥é“ï¼Œæ¥ä¸‹æ¥çš„ç›®æ ‡çœŸçš„å°±æ˜¯é€šç”¨æ€§ï¼šæˆ‘ä»¬èƒ½å¦å¼€å‘ä¸€ç§çœŸæ­£é€šç”¨çš„æ–¹æ³•æ¥æ‰©å±•æ¨ç†è®¡ç®—ï¼Œè€Œä¸ä»…ä»…æ˜¯åšè¯¸å¦‚è’™ç‰¹å¡æ´›ç ”ç©¶é‚£æ ·ç‰¹å®šäºæŸä¸€é¢†åŸŸçš„äº‹æƒ…ã€‚
- en: And also better than things like chain of thoughtã€‚å—¯ã€‚What this would look like
    is that you have much higher test time computeã€‚But you have much more capable
    modelsã€‚And I think for certain domains that trade off is worth itã€‚like if you
    think about what inference cost we're willing to pay for proof of the Raymond
    hypothesisã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œä¸”è¿™æ¯”è¯¸å¦‚æ€ç»´é“¾ä¹‹ç±»çš„ä¸œè¥¿è¦å¥½ã€‚å—¯ã€‚è¿™çœ‹èµ·æ¥ä¼šæ˜¯ä½ æœ‰æ›´é«˜çš„æµ‹è¯•æ—¶é—´è®¡ç®—ï¼Œä½†ä½ æœ‰æ›´å¼ºå¤§çš„æ¨¡å‹ã€‚æˆ‘è®¤ä¸ºåœ¨æŸäº›é¢†åŸŸï¼Œè¿™ç§æƒè¡¡æ˜¯å€¼å¾—çš„ã€‚å¦‚æœä½ è€ƒè™‘åˆ°æˆ‘ä»¬æ„¿æ„ä¸ºâ€œé›·è’™å¾·å‡è®¾â€çš„è¯æ˜æ”¯ä»˜çš„æ¨ç†æˆæœ¬ã€‚
- en: I think we'd be willing to pay a lotã€‚Or you knowï¼Œ the cost ofã€‚What cost were
    we want to pay for new life saving drugsï¼Œ I think we'd be willing to pay a lotã€‚So
    I think that there is an opportunity hereã€‚Okayï¼Œ anywayï¼Œ so that's why I preludeã€‚I
    guess any questions about that before I move on to Ciceroï¼ŸBy the wayã€‚
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºæˆ‘ä»¬æ„¿æ„æ”¯ä»˜å¾ˆå¤šé’±ã€‚æˆ–è€…ä½ çŸ¥é“ï¼Œè¿™ä¸ªæˆæœ¬ã€‚æˆ‘ä»¬æ„¿æ„ä¸ºæ–°çš„æ•‘å‘½è¯ç‰©æ”¯ä»˜å¤šå°‘æˆæœ¬ï¼Œæˆ‘è®¤ä¸ºæˆ‘ä»¬æ„¿æ„æ”¯ä»˜å¾ˆå¤šã€‚æ‰€ä»¥æˆ‘è§‰å¾—è¿™é‡Œæœ‰ä¸€ä¸ªæœºä¼šã€‚å¥½å§ï¼Œåæ­£ï¼Œè¿™å°±æ˜¯æˆ‘å‰é¢çš„é“ºå«ã€‚æˆ‘æƒ³åœ¨æˆ‘ç»§ç»­è°ˆè®ºè¥¿å¡ç½—ä¹‹å‰ï¼Œæœ‰ä»€ä¹ˆé—®é¢˜å—ï¼Ÿé¡ºä¾¿è¯´ä¸€ä¸‹ã€‚
- en: the reason why I'm talking about this is because it's going to informã€‚ğŸ˜¡ã€‚The
    approach that we took to Ciceroï¼Œ which I think is quite different from the approach
    that a lot of other the researchers might have taken to this problemã€‚Someone asked
    can you give an example of search well multicarural research is one form of searchã€‚you
    could also think of like breadth for search depth for search these kinds of things
    they're all search I would also argue that like chain of thought is doing something
    similar to search where it it's allowing the model to like leverage extra compute
    at test time to get better performancesã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è°ˆè®ºè¿™ä¸ªçš„åŸå› æ˜¯å› ä¸ºå®ƒå°†å½±å“ã€‚ğŸ˜¡ã€‚æˆ‘ä»¬å¯¹è¥¿å¡ç½—çš„å¤„ç†æ–¹å¼ï¼Œæˆ‘è®¤ä¸ºä¸å…¶ä»–è®¸å¤šç ”ç©¶äººå‘˜å¯èƒ½é‡‡å–çš„æ–¹å¼æœ‰å¾ˆå¤§ä¸åŒã€‚æœ‰äººé—®ï¼Œèƒ½å¦ä¸¾ä¸€ä¸ªå¤šæ¨¡æ€ç ”ç©¶çš„æœç´¢ä¾‹å­ã€‚ä½ ä¹Ÿå¯ä»¥æƒ³è±¡åƒå¹¿åº¦ä¼˜å…ˆæœç´¢ã€æ·±åº¦ä¼˜å…ˆæœç´¢è¿™äº›ç±»å‹çš„æœç´¢ï¼Œå®ƒä»¬éƒ½æ˜¯æœç´¢ã€‚æˆ‘è¿˜æƒ³è¯´ï¼Œæ€ç»´é“¾åœ¨æŸç§ç¨‹åº¦ä¸Šç±»ä¼¼äºæœç´¢ï¼Œå› ä¸ºå®ƒå…è®¸æ¨¡å‹åœ¨æµ‹è¯•æ—¶åˆ©ç”¨é¢å¤–çš„è®¡ç®—èµ„æºï¼Œä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½ã€‚
- en: But I think that that's the main thing that you wantã€‚the ability to like leverage
    extra compute at a test timeã€‚What's the search what's the space that you are searching
    over again like in in a game like go it's like different board positionsã€‚but you
    could also imagine searching over like you know different sentences that you could
    say things like thatã€‚
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘è®¤ä¸ºè¿™å°±æ˜¯ä½ æƒ³è¦çš„ä¸»è¦å†…å®¹ã€‚èƒ½å¤Ÿåœ¨æµ‹è¯•æ—¶åˆ©ç”¨é¢å¤–çš„è®¡ç®—èµ„æºã€‚æœç´¢çš„ç©ºé—´æ˜¯ä»€ä¹ˆï¼Ÿä½ åœ¨æœç´¢ä»€ä¹ˆï¼Ÿåœ¨å›´æ£‹è¿™æ ·ä¸€ä¸ªæ¸¸æˆä¸­ï¼Œå°±æ˜¯ä¸åŒçš„æ£‹ç›˜ä½ç½®ã€‚ä½†ä½ ä¹Ÿå¯ä»¥æƒ³è±¡æœç´¢åƒä¸åŒçš„å¥å­ä¹‹ç±»çš„ä¸œè¥¿ã€‚
- en: There's a lot of flexibility there as wellã€‚Okayï¼Œ so now I want to get into Cicero
    so first thing I should say when it comes to Ciceroã€‚this isã€‚A big team effortã€‚This
    was like this is actually one of the great things about working on this project
    that there was just such a diverse talent poolã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œä¹Ÿæœ‰å¾ˆå¤šçµæ´»æ€§ã€‚å¥½å§ï¼Œç°åœ¨æˆ‘æƒ³è°ˆè°ˆè¥¿å¡ç½—ã€‚é¦–å…ˆæˆ‘åº”è¯¥è¯´ï¼Œå…³äºè¥¿å¡ç½—ã€‚è¿™æ˜¯ä¸€ä¸ªå¤§å‹å›¢é˜Ÿåˆä½œã€‚è¿™å®é™…ä¸Šæ˜¯å‚ä¸è¿™ä¸ªé¡¹ç›®çš„ä¸€ä¸ªä¼Ÿå¤§ä¹‹å¤„ï¼Œå› ä¸ºè¿™é‡Œæœ‰å¦‚æ­¤å¤šæ ·çš„äººæ‰ã€‚
- en: experts in reinforcement learningï¼Œ planningï¼Œ game theoryï¼Œ natural language processingã€‚all
    working together on this and it would not have been possible without without everybodyã€‚So
    the motivation for diplomacy actually came from 2019ã€‚we were looking at all the
    breakthroughs that were happening at the time and I think a good example of this
    is this XKCD comic that came out in 2012 that shows like different categories
    gamesã€‚
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¼ºåŒ–å­¦ä¹ ã€è§„åˆ’ã€åšå¼ˆè®ºå’Œè‡ªç„¶è¯­è¨€å¤„ç†æ–¹é¢çš„ä¸“å®¶ï¼Œå¤§å®¶ä¸€èµ·åˆä½œï¼Œè¿™ä¸€åˆ‡éƒ½æ˜¯ä¸å¯èƒ½çš„ï¼Œæ²¡æœ‰æ¯ä¸ªäººçš„åŠªåŠ›ã€‚å› æ­¤ï¼Œå¤–äº¤çš„åŠ¨æœºå®é™…ä¸Šæ¥è‡ª2019å¹´ã€‚æˆ‘ä»¬å½“æ—¶åœ¨å…³æ³¨æ‰€æœ‰çš„çªç ´ï¼Œæˆ‘è®¤ä¸ºä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­æ˜¯2012å¹´å‘å¸ƒçš„è¿™å¹…XKCDæ¼«ç”»ï¼Œå±•ç¤ºäº†ä¸åŒç±»åˆ«çš„æ¸¸æˆã€‚
- en: games that are solvedï¼Œ games where computers can beat documentsã€‚games where
    computers still lose documents and games where computers may never outplay documentsã€‚And
    in this categoryï¼Œ computer still lose to top humans you had four gamesï¼Œ go Arimaã€‚poker
    and Starcraftftã€‚In 2015ã€‚ğŸ˜Šï¼ŒActuallyï¼Œ one of my colleaguesã€‚
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: å·²ç»è§£å†³çš„æ¸¸æˆï¼Œè®¡ç®—æœºå¯ä»¥å‡»è´¥æ–‡æ¡£çš„æ¸¸æˆã€‚è®¡ç®—æœºä»ç„¶ä¼šè¾“ç»™æ–‡æ¡£çš„æ¸¸æˆï¼Œä»¥åŠè®¡ç®—æœºå¯èƒ½æ°¸è¿œæ— æ³•è¶…è¶Šæ–‡æ¡£çš„æ¸¸æˆã€‚åœ¨è¿™ä¸€ç±»åˆ«ä¸­ï¼Œè®¡ç®—æœºä»ç„¶è¾“ç»™é¡¶çº§äººç±»çš„å››ä¸ªæ¸¸æˆï¼ŒåŒ…æ‹¬å›´æ£‹ã€é˜¿é‡Œé©¬ã€æ‰‘å…‹å’Œæ˜Ÿé™…äº‰éœ¸ã€‚åœ¨2015å¹´ã€‚ğŸ˜Šå®é™…ä¸Šï¼Œæˆ‘çš„ä¸€ä½åŒäº‹ã€‚
- en: David Wu made the first day out to beat Top humans in aremaã€‚in 2016 we have
    Algo beating Lisa do and Goã€‚In 2017ã€‚you have the work that I just described where
    we beattop humans in pokerã€‚And in 2019ã€‚we had Alpha star beating X humans in Starcraftftã€‚So
    that shows the incredible amount of progress that had happened in strategic reasoning
    over the past several yearsã€‚leading up to 2019ã€‚And at the same timeï¼Œ we also had
    GP2 come out in 2019ã€‚and it showed that language model likeã€‚And natural language
    processing was progressing much faster than I think a lot of peopleã€‚including
    us expectedã€‚And so we were thinking about what after the sixth player poker work
    I was discussing with my colleaguesã€‚
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§å«Â·å´åœ¨2016å¹´é¦–æ¬¡çªç ´ï¼Œæˆ˜èƒœäº†é¡¶å°–äººç±»é€‰æ‰‹ã€‚åœ¨2016å¹´ï¼Œæˆ‘ä»¬çš„ç®—æ³•æˆ˜èƒœäº†Lisaåœ¨å›´æ£‹ä¸­çš„è¡¨ç°ã€‚åœ¨2017å¹´ï¼Œæˆ‘åˆšåˆšæè¿°çš„å·¥ä½œä¸­ï¼Œæˆ‘ä»¬åœ¨æ‰‘å…‹æ¯”èµ›ä¸­å‡»è´¥äº†é¡¶å°–äººç±»ã€‚è€Œåœ¨2019å¹´ï¼Œæˆ‘ä»¬çš„AlphaStaræˆ˜èƒœäº†å¤šåäººç±»é€‰æ‰‹åœ¨ã€Šæ˜Ÿé™…äº‰éœ¸ã€‹ä¸­ã€‚è¿™æ˜¾ç¤ºäº†åœ¨æˆ˜ç•¥æ¨ç†æ–¹é¢ï¼Œåœ¨è¿‡å»å‡ å¹´ä¸­å‘ç”Ÿçš„æƒŠäººè¿›å±•ï¼Œç›´è‡³2019å¹´ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬åœ¨2019å¹´ä¹Ÿæ¨å‡ºäº†GP2ï¼Œè¿™è¡¨æ˜è¯­è¨€æ¨¡å‹å’Œè‡ªç„¶è¯­è¨€å¤„ç†çš„è¿›å±•é€Ÿåº¦è¿œè¶…è®¸å¤šäººçš„é¢„æœŸï¼ŒåŒ…æ‹¬æˆ‘ä»¬è‡ªå·±ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åœ¨æ€è€ƒç¬¬å…­ä½æ‰‘å…‹é€‰æ‰‹å·¥ä½œçš„ä¸‹ä¸€æ­¥ã€‚
- en: what should we work on nextï¼ŸAnd we were throwing around like different domains
    to work onã€‚Given the incredible amount of progress in AIï¼Œ we wanted to pick something
    really ambitiousã€‚something that we thoughtã€‚You couldn't just tackle by scaling
    up the existing approaches that you really needed something new in order to addressã€‚And
    we landed on diplomacy because we thought that it would be the hardest game to
    make an AI forã€‚
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸‹ä¸€æ­¥åº”è¯¥åšä»€ä¹ˆï¼Ÿæˆ‘ä»¬è®¨è®ºäº†ä¸åŒçš„é¢†åŸŸã€‚è€ƒè™‘åˆ°äººå·¥æ™ºèƒ½çš„æƒŠäººè¿›å±•ï¼Œæˆ‘ä»¬å¸Œæœ›é€‰æ‹©ä¸€ä¸ªéå¸¸é›„å¿ƒå‹ƒå‹ƒçš„é¡¹ç›®ï¼Œä¸€é¡¹æˆ‘ä»¬è®¤ä¸ºæ— æ³•ä»…é€šè¿‡æ‰©å¤§ç°æœ‰æ–¹æ³•æ¥è§£å†³çš„ä»»åŠ¡ï¼Œå› æ­¤æˆ‘ä»¬é€‰æ‹©äº†å¤–äº¤ï¼Œå› ä¸ºæˆ‘ä»¬è®¤ä¸ºè¿™æ˜¯ä¸ºäººå·¥æ™ºèƒ½å¼€å‘çš„æœ€å›°éš¾çš„æ¸¸æˆã€‚
- en: So what is diplomacyï¼ŸDiploomacy is a natural language strategy gameã€‚it takes
    place right before World War I you play as one of the seven great powers of Europeã€‚Englandï¼Œ
    Franceï¼Œ Germanyï¼Œ Austriaï¼Œ Russia and Turkeyã€‚and your goal is to control a majority
    of the map in practice that rarely happens like if you control a majority of a
    majority of the map and you've won in practice nobody ends up winning outright
    and so your scoreã€‚
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œä»€ä¹ˆæ˜¯å¤–äº¤ï¼Ÿå¤–äº¤æ˜¯ä¸€ç§è‡ªç„¶è¯­è¨€ç­–ç•¥æ¸¸æˆã€‚æ¸¸æˆå‘ç”Ÿåœ¨ç¬¬ä¸€æ¬¡ä¸–ç•Œå¤§æˆ˜å‰ï¼Œä½ å°†ä½œä¸ºæ¬§æ´²ä¸ƒå¤§å¼ºå›½ä¹‹ä¸€è¿›è¡Œæ¸¸æˆï¼šè‹±æ ¼å…°ã€æ³•å›½ã€å¾·å›½ã€å¥¥åœ°åˆ©ã€ä¿„ç½—æ–¯å’ŒåœŸè€³å…¶ã€‚ä½ çš„ç›®æ ‡æ˜¯åœ¨åœ°å›¾ä¸Šæ§åˆ¶å¤§å¤šæ•°åŒºåŸŸï¼Œå®é™…ä¸Šï¼Œè¿™ç§æƒ…å†µå¾ˆå°‘å‘ç”Ÿï¼›å¦‚æœä½ æ§åˆ¶äº†å¤§å¤šæ•°åŒºåŸŸï¼Œå®é™…ä¸Šå°±æ„å‘³ç€ä½ èµ¢äº†ï¼Œä½†é€šå¸¸æ²¡æœ‰äººèƒ½å½»åº•è·èƒœï¼Œå› æ­¤ä½ çš„å¾—åˆ†ä¼šå—åˆ°å½±å“ã€‚
- en: Is proportional to the percentage of the map that you controlï¼Ÿ
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸æ‚¨æ§åˆ¶çš„åœ°å›¾ç™¾åˆ†æ¯”æˆæ­£æ¯”å—ï¼Ÿ
- en: Now what's really interesting about diplomacy is that it is a natural language
    negotiation gameã€‚so you have these conversations like what you're seeing here
    between Germany and England where they will probably communicate with each other
    before making their moves and so you can have Germany ask like want to support
    Swedenã€‚
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œå¤–äº¤æ¸¸æˆä¸­çœŸæ­£æœ‰è¶£çš„æ˜¯ï¼Œå®ƒæ˜¯ä¸€ç§è‡ªç„¶è¯­è¨€çš„è°ˆåˆ¤æ¸¸æˆã€‚å› æ­¤ï¼Œä½ ä¼šçœ‹åˆ°å¾·å›½å’Œè‹±æ ¼å…°ä¹‹é—´çš„å¯¹è¯ï¼Œä»–ä»¬ä¼šåœ¨è¡ŒåŠ¨å‰è¿›è¡Œäº¤æµï¼Œæ¯”å¦‚å¾·å›½å¯èƒ½ä¼šé—®ï¼šâ€œä½ æƒ³æ”¯æŒç‘å…¸å—ï¼Ÿâ€
- en: England says let me think on that and so onã€‚So this is a popular strategy game
    developed in the 1950sã€‚it was JFK and Kisser's favorite game actuallyã€‚And like
    I saidã€‚each chart involves sophisticated private natural language negotiationsã€‚and
    I want to make clear like this is notã€‚Negotiations like you would see in a game
    like Sotos and Katanã€‚
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: è‹±æ ¼å…°è¯´ï¼šâ€œè®©æˆ‘æƒ³æƒ³ã€‚â€æ‰€ä»¥è¿™æ˜¯ä¸€ä¸ªåœ¨1950å¹´ä»£å¼€å‘çš„å—æ¬¢è¿çš„ç­–ç•¥æ¸¸æˆã€‚å®é™…ä¸Šï¼Œè¿™ä¹Ÿæ˜¯JFKå’ŒåŸºè¾›æ ¼çš„æœ€çˆ±ã€‚æ­£å¦‚æˆ‘æ‰€è¯´ï¼Œæ¯ä¸€å±€éƒ½æ¶‰åŠå¤æ‚çš„ç§äººè‡ªç„¶è¯­è¨€è°ˆåˆ¤ã€‚æˆ‘æƒ³æ˜ç¡®æŒ‡å‡ºï¼Œè¿™å¹¶ä¸æ˜¯åƒä½ åœ¨æ¸¸æˆã€Šå¡å¦å²›ã€‹ä¸­çœ‹åˆ°çš„é‚£ç§è°ˆåˆ¤ã€‚
- en: for exampleï¼Œ you're seeingã€‚It's much more like survivorï¼Œ if you've ever seen
    a TV show survivorã€‚you have discussions around like alliances that you'd like
    to build discussions around like specific tactics that you'd like to execute on
    the current current and also you know like more long- term strategy around like
    where do we go from here and how do we divide resourcesã€‚
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œä½ ä¼šçœ‹åˆ°ï¼Œè¿™æ›´åƒæ˜¯ä¸€åœºç”Ÿå­˜æ¸¸æˆï¼Œå¦‚æœä½ çœ‹è¿‡çœŸäººç§€ã€Šå¹¸å­˜è€…ã€‹ã€‚ä½ ä¼šå›´ç»•æƒ³è¦å»ºç«‹çš„è”ç›Ÿè¿›è¡Œè®¨è®ºï¼Œå›´ç»•æƒ³è¦åœ¨å½“å‰å±€åŠ¿ä¸­æ‰§è¡Œçš„å…·ä½“æˆ˜æœ¯è¿›è¡Œè®¨è®ºï¼Œè¿˜ä¼šè®¨è®ºæ›´é•¿æœŸçš„ç­–ç•¥ï¼Œæ¯”å¦‚æˆ‘ä»¬ä»è¿™é‡Œå¾€å“ªé‡Œå»ï¼Œä»¥åŠå¦‚ä½•åˆ†é…èµ„æºã€‚
- en: Now the way the game worksï¼Œ you have these negotiations that last between five
    and 15 minutes depending on the version of the gameã€‚and then on each term and
    all these negotiations are done privately in parawise negotiationã€‚also I think
    that you are not mutedï¼Œ okay thank youã€‚And then after the negotiation period completesã€‚everybody
    will simultaneously write down their movesã€‚ğŸ˜¡ã€‚
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ¸¸æˆçš„è¿ä½œæ–¹å¼æ˜¯ï¼Œè°ˆåˆ¤æŒç»­æ—¶é—´åœ¨äº”åˆ°åäº”åˆ†é’Ÿä¹‹é—´ï¼Œå…·ä½“å–å†³äºæ¸¸æˆçš„ç‰ˆæœ¬ã€‚è€Œä¸”æ‰€æœ‰è¿™äº›è°ˆåˆ¤éƒ½æ˜¯ä»¥å¯¹ç­‰çš„æ–¹å¼ç§ä¸‹è¿›è¡Œçš„ã€‚æˆ‘è¿˜è®¤ä¸ºä½ æ²¡æœ‰è¢«é™éŸ³ï¼Œè°¢è°¢ä½ ã€‚ç„¶ååœ¨è°ˆåˆ¤æœŸç»“æŸåï¼Œå¤§å®¶ä¼šåŒæ—¶å†™ä¸‹ä»–ä»¬çš„è¡ŒåŠ¨ã€‚ğŸ˜¡
- en: And so a player could promise you something like I'm going to support you into
    this territory this termã€‚but then when people actually write down their movesã€‚they
    might not write that down and so you only find out if they were true to their
    word when all the moves are revealed simultaneouslyã€‚And so for this reasonï¼Œ alliances
    and trust building is keyã€‚
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œä¸€ä¸ªç©å®¶å¯èƒ½ä¼šæ‰¿è¯ºä½ ï¼Œæ¯”å¦‚è¯´ï¼Œæˆ‘ä¼šåœ¨è¿™ä¸ªå›åˆæ”¯æŒä½ è¿›å…¥è¿™ä¸ªé¢†åœŸã€‚ä½†æ˜¯å½“äººä»¬å®é™…å†™ä¸‹ä»–ä»¬çš„è¡ŒåŠ¨æ—¶ï¼Œä»–ä»¬å¯èƒ½ä¸ä¼šè¿™æ ·å†™ï¼Œæ‰€ä»¥ä½ åªæœ‰åœ¨æ‰€æœ‰çš„è¡ŒåŠ¨åŒæ—¶æ­æ™“æ—¶æ‰èƒ½çŸ¥é“ä»–ä»¬æ˜¯å¦éµå®ˆäº†è¯ºè¨€ã€‚å› æ­¤ï¼Œè”ç›Ÿå’Œå»ºç«‹ä¿¡ä»»è‡³å…³é‡è¦ã€‚
- en: the ability to trust that somebody's going to follow through on their promisesã€‚that's
    really what this game is all about and the ability to convince people that you
    are going to follow through on your promises is really what this game is all aboutã€‚And
    so for this reasonã€‚Diploacy has long been considered a challenge problem for AIã€‚There
    research in the game going back to the 80sï¼Œ the research really only picked upã€‚
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ç›¸ä¿¡æœ‰äººä¼šå±¥è¡Œæ‰¿è¯ºçš„èƒ½åŠ›ï¼Œè¿™å®é™…ä¸Šå°±æ˜¯è¿™ä¸ªæ¸¸æˆçš„æ ¸å¿ƒï¼Œè€Œè¯´æœä»–äººä½ ä¼šå±¥è¡Œæ‰¿è¯ºçš„èƒ½åŠ›åŒæ ·æ˜¯è¿™ä¸ªæ¸¸æˆçš„æ ¸å¿ƒã€‚å› æ­¤ï¼Œå‡ºäºè¿™ä¸ªåŸå› ï¼Œå¤–äº¤é•¿æœŸä»¥æ¥è¢«è®¤ä¸ºæ˜¯äººå·¥æ™ºèƒ½çš„æŒ‘æˆ˜æ€§é—®é¢˜ã€‚å…³äºè¿™ä¸ªæ¸¸æˆçš„ç ”ç©¶å¯ä»¥è¿½æº¯åˆ°80å¹´ä»£ï¼Œç ”ç©¶çœŸæ­£å¼€å§‹å¾—åˆ°é‡è§†ã€‚
- en: It picked up like quite intensely in starting in 2019 when researchers from
    DeepMdï¼Œ ourselvesï¼Œ MiAã€‚other places started working on thisã€‚Now a lot of that
    researchã€‚the vast majority of that research actually was focused on the non languageguage
    version of the gameã€‚which was seen as a stepping stone into the full natural language
    versionã€‚
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ–¹é¢çš„ç ”ç©¶åœ¨2019å¹´å¼€å§‹æ—¶éå¸¸æ¿€çƒˆï¼Œå½“æ—¶DeepMindçš„ç ”ç©¶äººå‘˜ï¼Œä»¥åŠæˆ‘ä»¬è‡ªå·±å’Œå…¶ä»–åœ°æ–¹çš„äººå¼€å§‹è¿›è¡Œè¿™æ–¹é¢çš„å·¥ä½œã€‚ç°åœ¨å¾ˆå¤šç ”ç©¶ï¼Œç»å¤§å¤šæ•°ç ”ç©¶å®é™…ä¸Šé›†ä¸­åœ¨æ¸¸æˆçš„éè¯­è¨€ç‰ˆæœ¬ä¸Šï¼Œè¿™è¢«è§†ä¸ºé€šå‘å®Œæ•´è‡ªç„¶è¯­è¨€ç‰ˆæœ¬çš„å«è„šçŸ³ã€‚
- en: though we decided to focus from the start on the full natural language version
    of the gameã€‚So to give you a sense of like what these negotiations and dialogue
    look likeã€‚here is one example so hereã€‚Englandï¼Œ you can see they move their fleet
    in Norway to Stã€‚Petersburg and that occupies the Russian territoryã€‚
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡æˆ‘ä»¬å†³å®šä»ä¸€å¼€å§‹å°±ä¸“æ³¨äºæ¸¸æˆçš„å®Œæ•´è‡ªç„¶è¯­è¨€ç‰ˆæœ¬ã€‚ä¸ºäº†è®©ä½ äº†è§£è¿™äº›è°ˆåˆ¤å’Œå¯¹è¯çš„æ ·å­ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªä¾‹å­ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œè‹±æ ¼å…°ï¼Œä½ å¯ä»¥çœ‹åˆ°ä»–ä»¬å°†èˆ°é˜Ÿä»æŒªå¨ç§»åŠ¨åˆ°åœ£å½¼å¾—å ¡ï¼Œè¿™å é¢†äº†ä¿„ç½—æ–¯çš„é¢†åœŸã€‚
- en: And so this is what the board state looks like after that move and now there's
    this conversation between Austria and Russiaã€‚Austria saysï¼Œ well what happened
    up north Russia says England stabbed I'm afraid the end may be close from you
    my friend Austria says yeah that's rough are you going to be okay up there Russia
    says I hope so England seems to still want to work together Austria says can you
    make a deal with Germany so the players are now discussing like what should be
    discussed with other players Russia says good idea then Austria says if we find
    as long as you can defend Sevetopol so Sevesttopol is this territory down to the
    south you can see that Turkey has a fleet and an army in the Black Sea in Armen
    next to Sevestoppo and so they could potentially attack that territory next turnã€‚
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™å°±æ˜¯åœ¨é‚£æ¬¡è¡ŒåŠ¨åçš„æ£‹ç›˜çŠ¶æ€ï¼Œç°åœ¨å¥¥åœ°åˆ©å’Œä¿„ç½—æ–¯ä¹‹é—´æœ‰è¿™æ ·çš„å¯¹è¯ã€‚å¥¥åœ°åˆ©è¯´ï¼ŒåŒ—è¾¹å‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿä¿„ç½—æ–¯è¯´ï¼Œè‹±æ ¼å…°èƒŒå›äº†ï¼Œæˆ‘æ‹…å¿ƒä½ æˆ‘æœ‹å‹çš„ç»“å±€å¯èƒ½è¦æ¥äº†ã€‚å¥¥åœ°åˆ©è¯´ï¼Œæ˜¯çš„ï¼Œé‚£å¾ˆç³Ÿç³•ï¼Œä½ èƒ½åœ¨é‚£è¾¹æ’‘å¾—ä½å—ï¼Ÿä¿„ç½—æ–¯è¯´ï¼Œæˆ‘å¸Œæœ›å¦‚æ­¤ï¼Œè‹±æ ¼å…°ä¼¼ä¹ä»ç„¶æƒ³è¦åˆä½œã€‚å¥¥åœ°åˆ©è¯´ï¼Œä½ èƒ½å’Œå¾·å›½è¾¾æˆåè®®å—ï¼Ÿæ‰€ä»¥ç©å®¶ä»¬ç°åœ¨åœ¨è®¨è®ºåº”è¯¥å’Œå…¶ä»–ç©å®¶è®¨è®ºä»€ä¹ˆã€‚ä¿„ç½—æ–¯è¯´ï¼Œå¥½ä¸»æ„ï¼Œç„¶åå¥¥åœ°åˆ©è¯´ï¼Œå¦‚æœæˆ‘ä»¬èƒ½æ‰¾åˆ°ï¼Œåªè¦ä½ èƒ½ä¿ä½å¡ç“¦æ–¯æ‰˜æ³¢å°”å°±è¡Œã€‚å¡ç“¦æ–¯æ‰˜æ³¢å°”æ˜¯å—è¾¹çš„ä¸€ä¸ªé¢†åœŸï¼Œä½ å¯ä»¥çœ‹åˆ°åœŸè€³å…¶åœ¨é»‘æµ·å’Œå¡ç“¦æ–¯æ‰˜æ³¢å°”æ—è¾¹æœ‰ä¸€æ”¯èˆ°é˜Ÿå’Œä¸€æ”¯å†›é˜Ÿï¼Œä»–ä»¬å¯èƒ½ä¼šåœ¨ä¸‹ä¸€è½®æ”»å‡»é‚£ä¸ªé¢†åœŸã€‚
- en: å—¯ã€‚ğŸ˜Šï¼ŒAustria says can you support hold Sevetooles Ukraine and Romania I'll support
    hold Romaniaã€‚Russia says yepï¼Œ they'm already doing soï¼Œ Austria says awesomeã€‚hopefully
    we can start getting you back on your feetã€‚So this is an example of the kinds
    of conversations that you'll see in a game of diplomacy in this conversationã€‚
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: å—¯ã€‚ğŸ˜Šï¼Œå¥¥åœ°åˆ©è¯´ï¼Œä½ èƒ½æ”¯æŒä¿ä½å¡ç“¦æ–¯æ‰˜æ³¢å°”ã€ä¹Œå…‹å…°å’Œç½—é©¬å°¼äºšå—ï¼Ÿæˆ‘ä¼šæ”¯æŒä¿ä½ç½—é©¬å°¼äºšã€‚ä¿„ç½—æ–¯è¯´ï¼Œæ˜¯çš„ï¼Œä»–ä»¬å·²ç»åœ¨è¿™æ ·åšï¼Œå¥¥åœ°åˆ©è¯´ï¼Œå¤ªå¥½äº†ã€‚å¸Œæœ›æˆ‘ä»¬èƒ½å¼€å§‹è®©ä½ æ¢å¤å…ƒæ°”ã€‚è¿™æ˜¯ä½ åœ¨å¤–äº¤æ¸¸æˆä¸­ä¼šçœ‹åˆ°çš„å¯¹è¯çš„ä¸€ç§ä¾‹å­ã€‚
- en: Austria is actually our bot Ciceroã€‚ğŸ˜Šï¼ŒSo that kind of gives you a sense of the
    sophistication of the agent dialogueã€‚è¯¶ã€‚Okay I'll skip this for okay so I guess
    I'll go into this I don't want to take up too much time really what makes diplomacy
    interesting is that support is key so here for exampleã€‚
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: å¥¥åœ°åˆ©å®é™…ä¸Šæ˜¯æˆ‘ä»¬çš„æœºå™¨äººè¥¿å¡ç½—ã€‚ğŸ˜Šï¼Œè¿™è®©ä½ å¯¹ä»£ç†å¯¹è¯çš„å¤æ‚æ€§æœ‰äº†ä¸€äº›äº†è§£ã€‚è¯¶ã€‚å¥½çš„ï¼Œæˆ‘ä¼šè·³è¿‡è¿™ä¸€ç‚¹ï¼Œæ‰€ä»¥æˆ‘æƒ³æˆ‘ä¼šè¿›å…¥è¿™ä¸ªï¼Œæˆ‘ä¸æƒ³å ç”¨å¤ªå¤šæ—¶é—´ï¼Œå®é™…ä¸Šè®©å¤–äº¤å˜å¾—æœ‰è¶£çš„æ˜¯æ”¯æŒæ˜¯å…³é”®ï¼Œæ‰€ä»¥è¿™é‡Œä¸¾ä¸ªä¾‹å­ã€‚
- en: Budapest and Warsaw the red and the purple units both try to move into glacia
    and so since it's a one verse one they both bounce back and now they was into
    the territory in the middle panel you can see Vienna supports Budapest into glacciia
    and so now it's a two verse one and that red unit will indeed enter Galacciiaã€‚
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¸ƒè¾¾ä½©æ–¯å’Œåæ²™ï¼Œçº¢è‰²å’Œç´«è‰²å•ä½éƒ½è¯•å›¾è¿›å…¥æ ¼æ‹‰å¥‡äºšï¼Œç”±äºè¿™æ˜¯ä¸€ä¸ªä¸€å¯¹ä¸€çš„å¯¹æŠ—ï¼Œä»–ä»¬éƒ½åå¼¹å›å»ã€‚ç°åœ¨åœ¨ä¸­é—´é¢æ¿ä¸Šï¼Œä½ å¯ä»¥çœ‹åˆ°ç»´ä¹Ÿçº³æ”¯æŒå¸ƒè¾¾ä½©æ–¯è¿›å…¥æ ¼æ‹‰å¥‡äºšï¼Œå› æ­¤ç°åœ¨æ˜¯ä¸¤ä¸ªå¯¹ä¸€ä¸ªï¼Œé‚£ä¸ªçº¢è‰²å•ä½ç¡®å®ä¼šè¿›å…¥æ ¼æ‹‰å¥‡äºšã€‚
- en: And what's really interesting about the po is that it doesn't just have to be
    your own units that are supporting youã€‚it could be another player's units as wellï¼Œ
    so for exampleã€‚the green player could support the red player into glacciia and
    then that ready unit would still go in thereã€‚So support is really what the game
    is all about negotiating over support and so for that reason diplomacy has this
    reputation as the game that ruins friendships it's really difficult to have an
    alliance with somebody for three or four hours and then have thatã€‚
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œå…³äºè¿™ä¸ªåè®®çœŸæ­£æœ‰è¶£çš„æ˜¯ï¼Œä¸ä»…ä»…æ˜¯ä½ è‡ªå·±çš„å•ä½åœ¨æ”¯æŒä½ ï¼Œå…¶ä»–ç©å®¶çš„å•ä½ä¹Ÿå¯ä»¥æ”¯æŒä½ ã€‚ä¾‹å¦‚ï¼Œç»¿è‰²ç©å®¶å¯ä»¥æ”¯æŒçº¢è‰²ç©å®¶è¿›å…¥æ ¼æ‹‰å¥‡äºšï¼Œé‚£ä¹ˆé‚£ä¸ªçº¢è‰²å•ä½ä»ç„¶ä¼šè¿›å…¥é‚£é‡Œã€‚æ‰€ä»¥æ”¯æŒå®é™…ä¸Šå°±æ˜¯æ¸¸æˆçš„å…¨éƒ¨ï¼Œè°ˆåˆ¤å…³äºæ”¯æŒçš„äº‹æƒ…ï¼Œå› æ­¤ï¼Œå¤–äº¤æœ‰äº†â€œæ¯æ‰å‹è°Šçš„æ¸¸æˆâ€çš„åå£°ï¼Œå’ŒæŸäººç»´æŒä¸‰åˆ°å››ä¸ªå°æ—¶çš„è”ç›ŸçœŸçš„å¾ˆå›°éš¾ï¼Œç„¶åå†æœ‰è¿™æ ·çš„æƒ…å†µã€‚
- en: ğŸ˜Šï¼ŒHave them backstb you and basically is ruining your gameã€‚But if you talk to
    expert diplomacy playersï¼Œ they view it differentlyã€‚They say diplomacy is ultimately
    about building trust in an environment that encourages you to not trust anyoneã€‚And
    that's why we decided to work on the gameï¼Œ you knowã€‚
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šï¼Œè®©ä»–ä»¬èƒŒå›ä½ ï¼Œè¿™åŸºæœ¬ä¸Šæ˜¯åœ¨æ¯æ‰ä½ çš„æ¸¸æˆã€‚ä½†å¦‚æœä½ å’Œä¸“ä¸šå¤–äº¤ç©å®¶äº¤è°ˆï¼Œä»–ä»¬çš„çœ‹æ³•ä¼šæœ‰æ‰€ä¸åŒã€‚ä»–ä»¬è®¤ä¸ºï¼Œå¤–äº¤æœ€ç»ˆæ˜¯å»ºç«‹ä¿¡ä»»çš„è¿‡ç¨‹ï¼Œè€Œç¯å¢ƒå´ä¿ƒä½¿ä½ ä¸å»ä¿¡ä»»ä»»ä½•äººã€‚è¿™å°±æ˜¯æˆ‘ä»¬å†³å®šè‡´åŠ›äºè¿™ä¸ªæ¸¸æˆçš„åŸå› ï¼Œä½ çŸ¥é“çš„ã€‚
- en: could we make an AI that is able to build trust with players in an environment
    that encourages them to not trust anybody can thebo like honestly communicate
    that it's going to do something and and evaluate whether another person is being
    honest when they are saying that they're going to do somethingã€‚
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬èƒ½å¦åˆ›é€ ä¸€ä¸ªèƒ½å¤Ÿåœ¨ä¸€ä¸ªé¼“åŠ±ç©å®¶ä¸ä¿¡ä»»ä»»ä½•äººçš„ç¯å¢ƒä¸­å»ºç«‹ä¿¡ä»»çš„AIï¼Ÿå®ƒèƒ½å¦è¯šå®åœ°æ²Ÿé€šè‡ªå·±å°†è¦åšçš„äº‹æƒ…ï¼Œå¹¶è¯„ä¼°å¦ä¸€ä¸ªäººåœ¨è¯´ä»–ä»¬è¦åšæŸäº‹æ—¶æ˜¯å¦è¯šå®ï¼Ÿ
- en: Okay soã€‚W diplomacyï¼Œ it sits in this nice intersection of reinforcement learning
    and planningã€‚and also natural languageã€‚There's two perspectives that we can take
    on why diplomacy is a really interesting domain one is the multiedging perspective
    so hereã€‚
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œæ‰€ä»¥ã€‚åœ¨å¤–äº¤æ¸¸æˆä¸­ï¼Œå®ƒæ°å¥½ä½äºå¼ºåŒ–å­¦ä¹ å’Œè§„åˆ’çš„äº¤æ±‡ç‚¹ä¸Šï¼Œè¿˜æœ‰è‡ªç„¶è¯­è¨€ã€‚æˆ‘ä»¬å¯ä»¥ä»ä¸¤ä¸ªè§’åº¦æ¥çœ‹ä¸ºä»€ä¹ˆå¤–äº¤æ˜¯ä¸€ä¸ªéå¸¸æœ‰è¶£çš„é¢†åŸŸï¼Œä¸€ä¸ªæ˜¯å¤šè¾¹çš„è§†è§’ã€‚
- en: ğŸ˜¡ï¼ŒAll the previous game we have results like chess go pokerã€‚these have all been
    in purely zero sum two player zero sum domainsã€‚and in these domains selfplay is
    guaranteed to converge to an optimal solution basically what this means is you
    can start to having the bot play completely from scratch with no human dataã€‚And
    by playing against itself repeatedlyï¼Œ it will eventually converge to this unbeatable
    optimal solution called the mini Max equilibriumã€‚
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜¡ï¼Œä¹‹å‰çš„æ‰€æœ‰æ¸¸æˆï¼Œæ¯”å¦‚å›½é™…è±¡æ£‹ã€å›´æ£‹å’Œæ‰‘å…‹ï¼Œè¿™äº›éƒ½æ˜¯çº¯ç²¹çš„é›¶å’Œä¸¤ä¸ªç©å®¶çš„é¢†åŸŸã€‚åœ¨è¿™äº›é¢†åŸŸï¼Œè‡ªæˆ‘å¯¹å¼ˆå¯ä»¥ä¿è¯æ”¶æ•›åˆ°æœ€ä¼˜è§£ï¼ŒåŸºæœ¬ä¸Šè¿™æ„å‘³ç€ä½ å¯ä»¥è®©æœºå™¨äººå®Œå…¨ä»å¤´å¼€å§‹æ¸¸æˆï¼Œæ²¡æœ‰ä»»ä½•äººç±»æ•°æ®ã€‚é€šè¿‡åå¤è‡ªæˆ‘å¯¹å¼ˆï¼Œå®ƒæœ€ç»ˆä¼šæ”¶æ•›åˆ°è¿™ä¸ªæ— ä¸ä¼¦æ¯”çš„æœ€ä¼˜è§£ï¼Œç§°ä¸ºè¿·ä½ æœ€å¤§å‡è¡¡ã€‚
- en: But that result only holds in two players zero sumã€‚that whole paradigm only
    holds in two players zero sum gamesã€‚When you go to domains that involve cooperationï¼Œ
    in addition to competitionã€‚Then success requires understanding human behavior
    and conventions you can't just treat the other players like machines anymoreã€‚
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¿™ä¸ªç»“æœä»…åœ¨ä¸¤ä¸ªç©å®¶çš„é›¶å’Œæ¸¸æˆä¸­æˆç«‹ã€‚è¿™æ•´ä¸ªèŒƒå¼ä»…é€‚ç”¨äºä¸¤ä¸ªç©å®¶çš„é›¶å’Œæ¸¸æˆã€‚å½“ä½ è¿›å…¥éœ€è¦åˆä½œçš„é¢†åŸŸæ—¶ï¼Œé™¤äº†ç«äº‰ï¼ŒæˆåŠŸå°±éœ€è¦ç†è§£äººç±»è¡Œä¸ºå’Œçº¦å®šï¼Œä½ ä¸èƒ½å†æŠŠå…¶ä»–ç©å®¶å½“ä½œæœºå™¨å¯¹å¾…ã€‚
- en: you have to treat them like humansï¼Œ you have to modelã€‚ğŸ˜¡ï¼ŒHuman irrationalityï¼Œ
    human subbotalityã€‚one example of this is actually language likeã€‚You can imagine
    if you were to train a bo completely from scratch in the game of diplomacyã€‚Like
    the full natural language version of the gameã€‚there's no reason why the bot would
    learn to communicate in Englishã€‚
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¿…é¡»åƒå¯¹å¾…äººç±»ä¸€æ ·å¯¹å¾…å®ƒä»¬ï¼Œä½ å¿…é¡»å»ºæ¨¡ã€‚ğŸ˜¡äººç±»çš„ä¸ç†æ€§ï¼Œäººç±»çš„æœ‰é™æ€§ã€‚å…¶ä¸­ä¸€ä¸ªä¾‹å­å®é™…ä¸Šæ˜¯è¯­è¨€ã€‚ä½ å¯ä»¥æƒ³è±¡ï¼Œå¦‚æœä½ ä»é›¶å¼€å§‹è®­ç»ƒä¸€ä¸ªæœºå™¨äººè¿›è¡Œå¤–äº¤æ¸¸æˆï¼Œåƒè¿™ä¸ªæ¸¸æˆçš„å®Œæ•´è‡ªç„¶è¯­è¨€ç‰ˆæœ¬ï¼Œæœºå™¨äººæ²¡æœ‰ç†ç”±ä¼šå­¦ä¼šç”¨è‹±è¯­äº¤æµã€‚
- en: it would learn to communicate in some weird gibberish robot languageã€‚and then
    when you stick it in a game with six humansã€‚it's not going to be able to cooperate
    with themã€‚ğŸ˜¡ï¼Œå—¯ã€‚So we have to find a way to incorporate human data and be able to
    learn how humans behave in order to succeed in this gameã€‚
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä¼šå­¦ä¼šç”¨ä¸€äº›å¥‡æ€ªçš„æœºå™¨äººè¯­è¨€è¿›è¡Œäº¤æµï¼Œå½“ä½ æŠŠå®ƒæ”¾å…¥ä¸å…­ä¸ªäººç±»çš„æ¸¸æˆä¸­æ—¶ï¼Œå®ƒæ— æ³•ä¸ä»–ä»¬åˆä½œã€‚ğŸ˜¡å—¯ã€‚æ‰€ä»¥æˆ‘ä»¬å¿…é¡»æ‰¾åˆ°ä¸€ç§æ–¹æ³•æ¥æ•´åˆäººç±»æ•°æ®ï¼Œå¹¶èƒ½å¤Ÿå­¦ä¹ äººç±»çš„è¡Œä¸ºï¼Œä»¥ä¾¿åœ¨è¿™ä¸ªæ¸¸æˆä¸­å–å¾—æˆåŠŸã€‚
- en: ğŸ˜¡ï¼Œè¯¶ ok k ã€‚There's also the NLP perspectiveã€‚Which is that current language modelsã€‚Are
    essentially just imitating human like textã€‚Now there's been some progress with
    things like RLHFã€‚butã€‚That's still like not really the way that humans communicate
    they communicate with an intention in minds right they come up with this intention
    and then they communicate with the goal of communicating that intention and they
    understand that others are trying to do the sameã€‚
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜¡è¯¶ï¼Œå¥½çš„ã€‚è¿˜æœ‰ä¸€ä¸ªNLPçš„è§†è§’ã€‚å½“å‰çš„è¯­è¨€æ¨¡å‹åŸºæœ¬ä¸Šåªæ˜¯æ¨¡ä»¿äººç±»çš„æ–‡æœ¬ã€‚è™½ç„¶åœ¨RLHFç­‰æ–¹é¢å–å¾—äº†ä¸€äº›è¿›å±•ï¼Œä½†è¿™ä»ç„¶ä¸æ˜¯äººç±»äº¤æµçš„æ–¹å¼ï¼Œäººç±»æ˜¯æœ‰æ„å›¾åœ°è¿›è¡Œäº¤æµï¼Œä»–ä»¬æƒ³å‡ºè¿™ä¸ªæ„å›¾ï¼Œç„¶åä»¥ä¼ è¾¾è¿™ä¸ªæ„å›¾ä¸ºç›®æ ‡è¿›è¡Œäº¤æµï¼Œå¹¶ç†è§£å…¶ä»–äººä¹Ÿåœ¨å°è¯•åšåˆ°è¿™ä¸€ç‚¹ã€‚
- en: ğŸ˜¡ï¼ŒAnd so there's a question of likeï¼Œ can we move beyond shitt chatï¼ŸTo grounded
    intentional dialogueã€‚So Cicero is an AI agent for diplomaacy that integrates high
    level strategic play and open domain dialogueã€‚And we use 50ï¼Œ000 human games of
    diplomacy acquired through a partnership with the website webdplomacyã€‚netã€‚So we
    entered Cicero in an online diplomacy league just to give you the results up frontã€‚
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜¡æ‰€ä»¥æœ‰ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯æˆ‘ä»¬èƒ½å¦è¶…è¶Šç³Ÿç³•çš„èŠå¤©ï¼Ÿå®ç°æœ‰ç›®çš„çš„å¯¹è¯ã€‚å› æ­¤ï¼ŒCiceroæ˜¯ä¸€ä¸ªå¤–äº¤AIä»£ç†ï¼Œå®ƒç»“åˆäº†é«˜æ°´å¹³çš„æˆ˜ç•¥ç©æ³•å’Œå¼€æ”¾é¢†åŸŸçš„å¯¹è¯ã€‚æˆ‘ä»¬ä½¿ç”¨äº†é€šè¿‡ä¸ç½‘ç«™webdplomacy.netåˆä½œè·å¾—çš„50,000åœºäººç±»å¤–äº¤æ¸¸æˆã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†CiceroæŠ•å…¥ä¸€ä¸ªåœ¨çº¿å¤–äº¤è”ç›Ÿï¼Œæå‰ç»™ä½ ç»“æœã€‚
- en: Cicero was not detected as an AI agent for 40 games with 828 playersã€‚there was
    one player that mentioned after the fact that like they kind of like made a joke
    about us being a bot but they didn't really follow up on it and nobody else followed
    up on it and they later accuseduse somebody else of also being a bot so we weren't
    sure how seriously to take that accusation but I think it's sad to say it made
    it through all 40 games not being detected as bot and then we in fact we told
    the players afterwards that it was a bot the whole time these are the kinds of
    responses that we got people were quite surprisedã€‚
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Ciceroåœ¨828åç©å®¶çš„40åœºæ¯”èµ›ä¸­æœªè¢«è¯†åˆ«ä¸ºAIä»£ç†ã€‚æœ‰ä¸€ä½ç©å®¶äº‹åæåˆ°ä»–ä»¬å¼€ç©ç¬‘è¯´æˆ‘ä»¬æ˜¯æœºå™¨äººï¼Œä½†ä»–ä»¬å¹¶æ²¡æœ‰çœŸæ­£è·Ÿè¿›ï¼Œå…¶ä»–äººä¹Ÿæ²¡æœ‰è·Ÿè¿›ï¼Œåæ¥ä»–ä»¬è¿˜æŒ‡æ§å…¶ä»–äººä¹Ÿæ˜¯æœºå™¨äººï¼Œå› æ­¤æˆ‘ä»¬ä¸ç¡®å®šè¯¥å¦‚ä½•è®¤çœŸå¯¹å¾…è¿™ä¸ªæŒ‡æ§ï¼Œä½†æˆ‘è§‰å¾—å¾ˆé—æ†¾çš„æ˜¯ï¼Œå®ƒåœ¨40åœºæ¯”èµ›ä¸­éƒ½æ²¡æœ‰è¢«è¯†åˆ«ä¸ºæœºå™¨äººï¼Œäº‹å®ä¸Šæˆ‘ä»¬åœ¨èµ›åå‘Šè¯‰ç©å®¶å®ƒä¸€ç›´æ˜¯æœºå™¨äººï¼Œè¿™å°±æ˜¯æˆ‘ä»¬å¾—åˆ°çš„å›åº”ï¼Œäººä»¬ç›¸å½“æƒŠè®¶ã€‚
- en: pleasantly surprised fortunatelyï¼Œ nobody was was upset with us but they were
    quite surprised thatã€‚There was a bot that had been playing this game with them
    the whole timeã€‚So in terms of resultsã€‚Cicero placed in the top 10% of playersï¼Œ
    it's a high variance game and so if you look at players that played five or more
    games that played second out of 19ã€‚and it achieved more than double the average
    human scoreã€‚
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¸è¿çš„æ˜¯ï¼Œæ²¡æœ‰äººå¯¹æˆ‘ä»¬æ„Ÿåˆ°ä¸æ»¡ï¼Œä½†ä»–ä»¬éå¸¸æƒŠè®¶ï¼Œç«Ÿç„¶æœ‰ä¸€ä¸ªæœºå™¨äººä¸€ç›´åœ¨ä¸ä»–ä»¬ä¸€èµ·ç©è¿™ä¸ªæ¸¸æˆã€‚å°±ç»“æœè€Œè¨€ï¼ŒCiceroæ’åœ¨å‰10%çš„ç©å®¶ä¸­ï¼Œè¿™æ˜¯ä¸€ä¸ªé«˜å˜å¼‚æ€§çš„æ¸¸æˆï¼Œå¦‚æœä½ çœ‹çœ‹ç©äº†äº”åœºæˆ–æ›´å¤šæ¯”èµ›çš„ç©å®¶ï¼Œå®ƒåœ¨19äººä¸­æ’ç¬¬äºŒï¼Œè¾¾åˆ°äº†è¶…è¿‡ä¸¤å€äºå¹³å‡äººç±»å¾—åˆ†çš„æˆç»©ã€‚
- en: So I would describe this as a strong level of human performanceã€‚I wouldn't go
    as far as to say that this is superhuman by any meansã€‚but it is currently quite
    a strong resultã€‚Nowï¼Œ to give you a picture of how Cicero worksã€‚Soã€‚The input that
    we feed into the model is the board state and the recent action history that's
    shown on the top left hereã€‚
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¼šå°†å…¶æè¿°ä¸ºä¸€ç§å¼ºå¤§çš„äººçš„è¡¨ç°æ°´å¹³ã€‚æˆ‘ä¸ä¼šè¯´è¿™ç»å¯¹æ˜¯è¶…äººï¼Œä½†è¿™ç›®å‰ç¡®å®æ˜¯ä¸€ä¸ªå¾ˆå¼ºçš„ç»“æœã€‚ç°åœ¨ï¼Œä¸ºäº†è®©ä½ äº†è§£Ciceroæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œæˆ‘ä»¬è¾“å…¥åˆ°æ¨¡å‹ä¸­çš„ä¿¡æ¯æ˜¯æ£‹ç›˜çŠ¶æ€å’Œå·¦ä¸Šè§’æ˜¾ç¤ºçš„æœ€è¿‘è¡ŒåŠ¨å†å²ã€‚
- en: and also the dialogue that it's had with all the players up until nowã€‚So that's
    going to get fed into a dialogue conditional action model that's going to predict
    what Cicero thinks all the players are going to do this turn and what they think
    we will do this termã€‚
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰ä¸æ‰€æœ‰ç©å®¶è¿›è¡Œçš„å¯¹è¯ç›´åˆ°ç°åœ¨ã€‚å› æ­¤ï¼Œè¿™å°†è¢«è¾“å…¥åˆ°ä¸€ä¸ªå¯¹è¯æ¡ä»¶è¡ŒåŠ¨æ¨¡å‹ä¸­ï¼Œè¯¥æ¨¡å‹å°†é¢„æµ‹ Cicero è®¤ä¸ºæ‰€æœ‰ç©å®¶åœ¨è¿™ä¸€è½®å°†è¦åšçš„äº‹æƒ…ï¼Œä»¥åŠä»–ä»¬è®¤ä¸ºæˆ‘ä»¬å°†åœ¨è¿™ä¸€è½®åšä»€ä¹ˆã€‚
- en: Theseã€‚These lead to what we call anchor policies that are then used for planningã€‚ğŸ˜¡ï¼Œå—¯ã€‚Nowã€‚planning
    hereã€‚Againï¼Œ this is like the part where we leverage extra compute at test time
    in order to get better performanceã€‚So essentially we take these initial predictions
    of what everybody's going to doã€‚what are called anchor policiesã€‚And we improve
    upon these predictions using this planning process called pickleã€‚
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å¯¼è‡´äº†æˆ‘ä»¬æ‰€ç§°çš„é”šå®šç­–ç•¥ï¼Œè¿™äº›ç­–ç•¥éšåç”¨äºè§„åˆ’ã€‚ğŸ˜¡ï¼Œå—¯ã€‚ç°åœ¨ï¼Œè§„åˆ’åœ¨è¿™é‡Œã€‚å†æ¬¡å¼ºè°ƒï¼Œè¿™æ˜¯æˆ‘ä»¬åœ¨æµ‹è¯•æ—¶åˆ©ç”¨é¢å¤–è®¡ç®—èµ„æºä»¥è·å¾—æ›´å¥½æ€§èƒ½çš„éƒ¨åˆ†ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åŸºæœ¬ä¸Šä¼šå¯¹å¤§å®¶å°†è¦åšçš„åˆå§‹é¢„æµ‹ï¼Œå³æ‰€è°“çš„é”šå®šç­–ç•¥è¿›è¡Œæ”¹è¿›ï¼Œä½¿ç”¨è¿™ä¸€åä¸º
    pickle çš„è§„åˆ’è¿‡ç¨‹ã€‚
- en: where basically we account for the fact that playersã€‚Willll pick actions that
    have higher expected value with higher probability we're essentially adding this
    like rationality prior to all the players to assume that they're not going to
    blunder as often as the model might suggest and they're going to pick smarter
    actions with higher probability than the initial model might suggestã€‚
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºæœ¬ä¸Šï¼Œæˆ‘ä»¬è€ƒè™‘åˆ°ç©å®¶å°†ä»¥æ›´é«˜çš„æ¦‚ç‡é€‰æ‹©æœŸæœ›å€¼æ›´é«˜çš„è¡ŒåŠ¨ã€‚æˆ‘ä»¬æœ¬è´¨ä¸Šæ˜¯ä¸ºæ‰€æœ‰ç©å®¶æ·»åŠ äº†ä¸€ç§ç†æ€§å‡è®¾ï¼Œå‡è®¾ä»–ä»¬ä¸ä¼šåƒæ¨¡å‹æ‰€æš—ç¤ºçš„é‚£æ ·ç»å¸¸å¤±è¯¯ï¼Œå¹¶ä¸”ä»–ä»¬ä¼šä»¥æ¯”åˆå§‹æ¨¡å‹æ‰€æš—ç¤ºçš„æ›´é«˜çš„æ¦‚ç‡é€‰æ‹©æ›´èªæ˜çš„è¡ŒåŠ¨ã€‚
- en: And what we find is that this actually gives us a better prediction of what
    all the players will do than just relying on the raw neural net itselfã€‚This gives
    us the action that we actually play in the gameã€‚and it also gives us what we call
    intenseã€‚So intents are an action for ourselves and an action for the dialogue
    partner that we're speaking toã€‚And now we have this dialogue conditional so we
    have we have this dialogue model that conditions on these intentsã€‚
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å‘ç°ï¼Œè¿™å®é™…ä¸Šæ¯”ä»…ä»…ä¾èµ–åŸå§‹ç¥ç»ç½‘ç»œç»™å‡ºäº†æ›´å¥½çš„å¯¹æ‰€æœ‰ç©å®¶å°†è¦åšçš„äº‹æƒ…çš„é¢„æµ‹ã€‚è¿™ç»™å‡ºäº†æˆ‘ä»¬åœ¨æ¸¸æˆä¸­å®é™…é‡‡å–çš„è¡ŒåŠ¨ï¼Œä¹Ÿç»™å‡ºäº†æˆ‘ä»¬æ‰€ç§°çš„æ„å›¾ã€‚å› æ­¤ï¼Œæ„å›¾æ˜¯æˆ‘ä»¬è‡ªå·±å’Œæˆ‘ä»¬æ­£åœ¨å¯¹è¯çš„å¯¹è¯ä¼™ä¼´çš„è¡ŒåŠ¨ã€‚ç°åœ¨æˆ‘ä»¬æœ‰è¿™ä¸ªå¯¹è¯æ¡ä»¶ï¼Œå› æ­¤æˆ‘ä»¬æœ‰ä¸€ä¸ªå¯¹è¯æ¨¡å‹ï¼Œä»¥è¿™äº›æ„å›¾ä¸ºæ¡ä»¶ã€‚
- en: so the intents are fed into the dialogue model along with the board state and
    action history and also the dialogue that we've had so so far and that dialogue
    model will then generateã€‚Candidate messages thatã€‚Are conditional on those intentsã€‚These
    candidate messages go through a series of filters that filter out nonsenseï¼Œ grounding
    issuesã€‚and also like value action low expected value messagesã€‚And ultimatelyã€‚
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæ„å›¾ä¸æ£‹ç›˜çŠ¶æ€ã€è¡ŒåŠ¨å†å²ä»¥åŠåˆ°ç›®å‰ä¸ºæ­¢çš„å¯¹è¯ä¸€èµ·è¾“å…¥åˆ°å¯¹è¯æ¨¡å‹ä¸­ï¼Œè¿™ä¸ªå¯¹è¯æ¨¡å‹éšåå°†ç”Ÿæˆã€‚åŸºäºè¿™äº›æ„å›¾çš„å€™é€‰æ¶ˆæ¯ã€‚è¿™äº›å€™é€‰æ¶ˆæ¯ä¼šé€šè¿‡ä¸€ç³»åˆ—è¿‡æ»¤å™¨ï¼Œè¿‡æ»¤æ‰æ— æ„ä¹‰ã€åŸºç¡€é—®é¢˜ï¼Œä»¥åŠåƒä½é¢„æœŸå€¼æ¶ˆæ¯è¿™æ ·çš„ä»·å€¼è¡ŒåŠ¨ã€‚æœ€ç»ˆã€‚
- en: we get out a message to send to our dialogue partnerã€‚Now every time we send
    or receive a messageã€‚we will repeat this whole processã€‚So there's actually a lot
    that is quite novel in Cicero and I'm going to try to talk aboutã€‚The contributions
    as much as possibleï¼Œ I might go through this a little quickly just so we have
    time for questionsã€‚The first one is a controllable dialogue model that conditions
    on the game state and a set of intended actions for the speaker and the recipientã€‚
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å‘å¯¹è¯ä¼™ä¼´å‘é€æ¶ˆæ¯ã€‚ç°åœ¨æ¯æ¬¡æˆ‘ä»¬å‘é€æˆ–æ¥æ”¶æ¶ˆæ¯æ—¶ï¼Œéƒ½ä¼šé‡å¤æ•´ä¸ªè¿‡ç¨‹ã€‚å› æ­¤ï¼ŒCicero ä¸­æœ‰å¾ˆå¤šæ–°é¢–çš„åœ°æ–¹ï¼Œæˆ‘ä¼šå°½é‡è°ˆè®ºã€‚è´¡çŒ®å°½å¯èƒ½å¤šï¼Œæˆ‘å¯èƒ½ä¼šç¨å¾®å¿«ä¸€ç‚¹ï¼Œä»¥ä¾¿æˆ‘ä»¬æœ‰æ—¶é—´è¿›è¡Œæé—®ã€‚ç¬¬ä¸€ä¸ªæ˜¯ä¸€ä¸ªå¯æ§å¯¹è¯æ¨¡å‹ï¼Œå®ƒä»¥æ¸¸æˆçŠ¶æ€å’Œè¯´è¯è€…åŠæ¥æ”¶è€…çš„ä¸€ç»„æ„å›¾è¡ŒåŠ¨ä¸ºæ¡ä»¶ã€‚
- en: So we have a questionï¼Œ what is the action space here for the modelï¼Ÿè¯¶ã€‚And the
    action spaceã€‚For the action prediction model is like all the actions that you
    could take in the game that a player could take in the gameã€‚For the dialogue modelï¼Œ
    it's like messages that you can sendã€‚Got itï¼Œ so oh the sickã€‚Hã€‚ğŸ˜Šï¼ŒOkayã€‚so we try
    what we call an intent model that predicts what actions people will take at the
    end of truthful turnsã€‚
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ‰ä¸€ä¸ªé—®é¢˜ï¼Œæ¨¡å‹çš„è¡ŒåŠ¨ç©ºé—´æ˜¯ä»€ä¹ˆï¼Ÿè¯¶ã€‚è¡ŒåŠ¨é¢„æµ‹æ¨¡å‹çš„è¡ŒåŠ¨ç©ºé—´æ˜¯ç©å®¶åœ¨æ¸¸æˆä¸­å¯ä»¥é‡‡å–çš„æ‰€æœ‰è¡ŒåŠ¨ã€‚å¯¹äºå¯¹è¯æ¨¡å‹ï¼Œå®ƒæ˜¯ä½ å¯ä»¥å‘é€çš„æ¶ˆæ¯ã€‚æ˜ç™½äº†ï¼Œæ‰€ä»¥å“¦ï¼Œé‚£ä¸ªç—…ã€‚Hã€‚ğŸ˜Šï¼Œå¥½çš„ã€‚æˆ‘ä»¬å°è¯•ä¸€ä¸ªæˆ‘ä»¬ç§°ä¹‹ä¸ºæ„å›¾æ¨¡å‹çš„æ¨¡å‹ï¼Œé¢„æµ‹äººä»¬åœ¨çœŸå®è½®æ¬¡ç»“æŸæ—¶å°†é‡‡å–çš„è¡ŒåŠ¨ã€‚
- en: basically where we're trying to predict what are people intending to do when
    they communicate a certain messageã€‚Andã€‚Then we use this to automatically annotate
    the data set with basically what we expect people's intentions were when they
    sent that message and we filter outã€‚
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºæœ¬ä¸Šï¼Œæˆ‘ä»¬è¯•å›¾é¢„æµ‹äººä»¬åœ¨ä¼ è¾¾æŸæ¡æ¶ˆæ¯æ—¶çš„æ„å›¾ã€‚ç„¶åï¼Œæˆ‘ä»¬ç”¨è¿™ä¸ªè‡ªåŠ¨æ³¨é‡Šæ•°æ®é›†ï¼ŒåŸºæœ¬ä¸Šè®°å½•æˆ‘ä»¬æœŸæœ›äººä»¬å‘é€è¯¥æ¶ˆæ¯æ—¶çš„æ„å›¾ï¼Œå¹¶è¿‡æ»¤æ‰ã€‚
- en: We filter out as much as possible lies from the data set so that the text in
    the data is annotated with the truthful intentionã€‚And then during play Cicero
    conditions the dialogue model on the truthful intention that it intends to takeã€‚and
    the goal then is that the hope then is that it will generate a message consistent
    with that intentionã€‚And that is then fed intoã€‚Into everything else that' that's
    you knowã€‚
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°½å¯èƒ½ä»æ•°æ®é›†ä¸­è¿‡æ»¤æ‰è°è¨€ï¼Œä»¥ä¾¿æ•°æ®ä¸­çš„æ–‡æœ¬æ³¨é‡ŠçœŸå®æ„å›¾ã€‚ç„¶åï¼Œåœ¨æ¸¸æˆä¸­ï¼Œè¥¿å¡ç½—å°†å¯¹è¯æ¨¡å‹åŸºäºå…¶æ‰“ç®—é‡‡å–çš„çœŸå®æ„å›¾è¿›è¡Œæ¡ä»¶åŒ–ã€‚ç›®æ ‡æ˜¯ç”Ÿæˆä¸è¯¥æ„å›¾ä¸€è‡´çš„æ¶ˆæ¯ã€‚è¿™åˆè¢«è¾“å…¥åˆ°å…¶ä»–æ‰€æœ‰å†…å®¹ä¸­ã€‚
- en: sorry that the intentions that we generate through planning are fed into the
    dial modelã€‚So to give you an example of what this looks likeï¼Œ this gives us a
    way to control the dialogue model through a set of intentionsã€‚ğŸ˜¡ï¼ŒLikeï¼Œ hereã€‚è¯¶ã€‚We
    are Cicero England in pinkï¼Œ and their action is to move to Belgiumã€‚among other
    thingsã€‚And so if we feed this attention into the dialogue modelã€‚
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: æŠ±æ­‰ï¼Œæˆ‘ä»¬é€šè¿‡è§„åˆ’ç”Ÿæˆçš„æ„å›¾è¢«è¾“å…¥åˆ°å¯¹è¯æ¨¡å‹ä¸­ã€‚æ‰€ä»¥ç»™ä½ ä¸€ä¸ªä¾‹å­ï¼Œè¿™è®©æˆ‘ä»¬é€šè¿‡ä¸€ç»„æ„å›¾æ¥æ§åˆ¶å¯¹è¯æ¨¡å‹ã€‚ğŸ˜¡ï¼Œå°±åƒè¿™é‡Œã€‚å˜¿ã€‚æˆ‘ä»¬æ˜¯è¥¿å¡ç½—è‹±æ ¼å…°ï¼Œç©¿ç²‰è‰²ï¼Œä»–ä»¬çš„è¡ŒåŠ¨æ˜¯ç§»åŠ¨åˆ°æ¯”åˆ©æ—¶ï¼Œå…¶ä»–äº‹é¡¹ä¹Ÿæ˜¯å¦‚æ­¤ã€‚å¦‚æœæˆ‘ä»¬å°†è¿™ä¸ªæ„å›¾è¾“å…¥å¯¹è¯æ¨¡å‹ã€‚
- en: then the message that might get generated is something like England saying to
    Franceã€‚do you mind supporting meï¼Œ do you mind supporting Eddie to Belgiumï¼ŸOn the
    other handã€‚let's say Cicero's action is to support France to Belgiumã€‚Then if you
    feed that into the dial modelã€‚then the message that's generated might say something
    likeã€‚
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œå¯èƒ½ç”Ÿæˆçš„æ¶ˆæ¯å°±åƒæ˜¯è‹±æ ¼å…°å¯¹æ³•å›½è¯´ï¼šâ€œä½ ä»‹æ„æ”¯æŒæˆ‘å—ï¼Ÿä½ ä»‹æ„æ”¯æŒåŸƒè¿ªå»æ¯”åˆ©æ—¶å—ï¼Ÿâ€å¦ä¸€æ–¹é¢ï¼Œå‡è®¾è¥¿å¡ç½—çš„è¡ŒåŠ¨æ˜¯æ”¯æŒæ³•å›½å»æ¯”åˆ©æ—¶ã€‚é‚£ä¹ˆï¼Œå¦‚æœä½ å°†å…¶è¾“å…¥å¯¹è¯æ¨¡å‹ï¼Œç”Ÿæˆçš„æ¶ˆæ¯å¯èƒ½ä¼šæ˜¯è¿™æ ·çš„ã€‚
- en: let me know if you want me to support you to Belgiumï¼Œ otherwise I'll probably
    poke Holã€‚Nowã€‚what we find is that conditioning the dialogue model on these intentions
    in this wayã€‚it makes the model more controllableï¼Œ but it also leads to higher
    quality dialogue with less nonsenseã€‚So we found that it led to dialogue that was
    more consistent with the stateã€‚
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³è®©æˆ‘æ”¯æŒä½ å»æ¯”åˆ©æ—¶ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼Œå¦åˆ™æˆ‘å¯èƒ½ä¼šæ‰“æ‰°éœå°”ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å‘ç°ä»¥è¿™ç§æ–¹å¼å°†å¯¹è¯æ¨¡å‹ä¸è¿™äº›æ„å›¾ç»“åˆèµ·æ¥ï¼Œå¯ä»¥ä½¿æ¨¡å‹æ›´åŠ å¯æ§ï¼ŒåŒæ—¶ä¹Ÿæé«˜äº†å¯¹è¯è´¨é‡ï¼Œå‡å°‘äº†æ— è°“çš„å†…å®¹ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å‘ç°è¿™å¯¼è‡´äº†æ›´ç¬¦åˆçŠ¶æ€çš„å¯¹è¯ã€‚
- en: more consistent with the planï¼Œ higher qualityï¼Œ lower perplexityï¼Œ and I think
    the argumentã€‚the reasoning for why this is the case is that we're kind of like
    relieving the dialogue model of the burden of having to come up withã€‚A good strategy
    we're allowing the dialogue model to do what it does best to focus on what it
    does bestã€‚which is dialogueã€‚And we're relieving it of the strategic components
    of the game because we're feeding that strategy into the dialect modelã€‚
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´ç¬¦åˆè®¡åˆ’ï¼Œè´¨é‡æ›´é«˜ï¼Œå›°æƒ‘åº¦æ›´ä½ï¼Œæˆ‘è®¤ä¸ºåŸå› åœ¨äºï¼Œæˆ‘ä»¬åƒæ˜¯è§£æ”¾äº†å¯¹è¯æ¨¡å‹ï¼Œä¸å†éœ€è¦è€ƒè™‘åˆ¶å®šå¥½çš„ç­–ç•¥ã€‚æˆ‘ä»¬è®©å¯¹è¯æ¨¡å‹ä¸“æ³¨äºå®ƒæœ€æ“…é•¿çš„å¯¹è¯ï¼Œå¹¶å°†æˆ˜ç•¥ç»„ä»¶çš„è´Ÿæ‹…ç§»äº¤ç»™å¯¹è¯æ¨¡å‹ã€‚
- en: Okayï¼Œ so that's one main contributionï¼Œ this controllable dialogue model that
    conditions on a planã€‚The second is a planning engine that accounts for dialogue
    and human behaviorã€‚Soã€‚Okayã€‚I mentioned that a lot ofã€‚Previous work on gamesã€‚Was
    done using self play in two players here or some settingsã€‚Nowï¼Œ the problem with
    like pure self playã€‚Is that it can learn strong policiesï¼Œ but it doesn'tã€‚
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸»è¦è´¡çŒ®ï¼Œè¿™ä¸ªå¯æ§çš„å¯¹è¯æ¨¡å‹åŸºäºä¸€ä¸ªè®¡åˆ’ã€‚ç¬¬äºŒä¸ªè´¡çŒ®æ˜¯ä¸€ä¸ªè§„åˆ’å¼•æ“ï¼Œå®ƒè€ƒè™‘äº†å¯¹è¯å’Œäººç±»è¡Œä¸ºã€‚æ‰€ä»¥ï¼Œå¥½çš„ã€‚æˆ‘æåˆ°ä¹‹å‰å…³äºæ¸¸æˆçš„è®¸å¤šå·¥ä½œéƒ½æ˜¯åœ¨ä¸¤ä¸ªç©å®¶çš„è‡ªæˆ‘å¯¹æˆ˜æˆ–æŸäº›è®¾ç½®ä¸‹è¿›è¡Œçš„ã€‚ç°åœ¨ï¼Œçº¯è‡ªæˆ‘å¯¹æˆ˜çš„é—®é¢˜åœ¨äºï¼Œå®ƒèƒ½å­¦ä¹ å¼ºç­–ç•¥ï¼Œä½†å¹¶ä¸èƒ½ã€‚
- en: It doesn't stick with human conventions and it can't account for dialogueã€‚it's
    just going to ignore the human data and the human way of playing if you just do
    self playã€‚So that's one extremeã€‚The other extreme that you can go is you just
    do supervised learning on human dataã€‚Create this model of how humans play and
    then train with those you know imitation humansã€‚
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä¸éµå¾ªäººç±»çš„çº¦å®šï¼Œä¹Ÿæ— æ³•å¤„ç†å¯¹è¯ã€‚å¦‚æœä½ åªæ˜¯è¿›è¡Œè‡ªæˆ‘å¯¹æˆ˜ï¼Œå®ƒä¼šå¿½ç•¥äººç±»æ•°æ®å’Œäººç±»çš„æ¸¸æˆæ–¹å¼ã€‚è¿™æ˜¯ä¸€ä¸ªæç«¯ã€‚å¦ä¸€ç§æç«¯æ˜¯å¯¹äººç±»æ•°æ®è¿›è¡Œç›‘ç£å­¦ä¹ ã€‚åˆ›å»ºäººç±»æ¸¸æˆçš„æ¨¡å‹ï¼Œç„¶åç”¨é‚£äº›æ¨¡ä»¿äººç±»è¿›è¡Œè®­ç»ƒã€‚
- en: And if you do thisï¼Œ you'll end up with a bot that's consistent with dialogue
    and human conventionsã€‚but it's only as strong as the training dataï¼Œ and we found
    that it was actually very easily manipulable through adversarial dialogueã€‚so for
    example you could send messages to it saying like thanks for agreeing to support
    me at the Paris and it will think like well I've only ever seen that message in
    my training data when I've agreed to support the person of the Paris and so I
    guess I'm supporting them at the Paris thisern even though that might be a terrible
    move for the botã€‚
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ è¿™æ ·åšï¼Œä½ æœ€ç»ˆä¼šå¾—åˆ°ä¸€ä¸ªä¸å¯¹è¯å’Œäººç±»çº¦å®šä¸€è‡´çš„â€œæœºå™¨äººâ€ï¼Œä½†å®ƒçš„èƒ½åŠ›ä»…å–å†³äºè®­ç»ƒæ•°æ®ï¼Œæˆ‘ä»¬å‘ç°å®ƒå®é™…ä¸Šå¾ˆå®¹æ˜“å—åˆ°å¯¹æŠ—æ€§å¯¹è¯çš„æ“æ§ã€‚ä¾‹å¦‚ï¼Œä½ å¯ä»¥å‘é€æ¶ˆæ¯ç»™å®ƒè¯´â€œæ„Ÿè°¢ä½ åŒæ„åœ¨å·´é»æ”¯æŒæˆ‘â€ï¼Œå®ƒä¼šè®¤ä¸ºï¼Œå—¯ï¼Œæˆ‘åœ¨è®­ç»ƒæ•°æ®ä¸­åªè§è¿‡è¿™ä¸ªæ¶ˆæ¯ï¼Œå½“æˆ‘åŒæ„æ”¯æŒæŸäººæ—¶ï¼Œæ‰€ä»¥æˆ‘æƒ³æˆ‘åœ¨å·´é»æ”¯æŒä»–ä»¬ï¼Œå³ä½¿è¿™å¯¹â€œæœºå™¨äººâ€æ¥è¯´å¯èƒ½æ˜¯ä¸€ä¸ªç³Ÿç³•çš„ä¸¾åŠ¨ã€‚
- en: So I came up with this algorithm called Pickleï¼Œ that kind of like is a happy
    medium between these two extremesã€‚å—¯ã€‚The way pickle works is it''s basically trying
    to it's it's doing self playã€‚but regularized towardã€‚Sticking to the human imitation
    policyã€‚So it has a KL penalty for deviating from the human imitation policyã€‚
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘æƒ³å‡ºäº†ä¸€ä¸ªå«åšâ€œPickleâ€çš„ç®—æ³•ï¼Œå®ƒåœ¨è¿™ä¸¤ä¸ªæç«¯ä¹‹é—´æ‰¾åˆ°äº†ä¸€ä¸ªå¿«ä¹çš„ä¸­é—´åœ°å¸¦ã€‚å—¯ã€‚Pickleçš„å·¥ä½œåŸç†åŸºæœ¬ä¸Šæ˜¯è¿›è¡Œè‡ªæˆ‘å¯¹å¼ˆï¼Œä½†ä¼šæœç€éµå¾ªäººç±»æ¨¡ä»¿ç­–ç•¥çš„æ–¹å‘è¿›è¡Œè§„èŒƒã€‚å› æ­¤ï¼Œå®ƒå¯¹åç¦»äººç±»æ¨¡ä»¿ç­–ç•¥æ–½åŠ äº†KLæƒ©ç½šã€‚
- en: So we have this parameter lambda that controls how easy it is to deviate from
    the human imitation policy at lambmbda equals zeroã€‚It just ignores the human imageization
    policy completely and just does pure self playã€‚And so just like do cell play as
    if from scratchï¼Œ add them be equals zeroã€‚At Lambda equals infinityã€‚it's just playing
    the human imation policy and not doing self Plaalã€‚
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ‰ä¸€ä¸ªå‚æ•°Î»ï¼Œå®ƒæ§åˆ¶ä»äººç±»æ¨¡ä»¿ç­–ç•¥åç¦»çš„éš¾æ˜“ç¨‹åº¦ï¼Œå½“Î»ç­‰äºé›¶æ—¶ï¼Œå®ƒå®Œå…¨å¿½ç•¥äººç±»æ¨¡ä»¿ç­–ç•¥ï¼Œè¿›è¡Œçº¯è‡ªæˆ‘å¯¹å¼ˆã€‚å› æ­¤ï¼Œåƒä»é›¶å¼€å§‹ä¸€æ ·è¿›è¡Œè‡ªæˆ‘å¯¹å¼ˆï¼Œå½“Î»ç­‰äºé›¶æ—¶ã€‚è€Œå½“Î»ç­‰äºæ— ç©·å¤§æ—¶ï¼Œå®ƒåªæ˜¯æ‰§è¡Œäººç±»æ¨¡ä»¿ç­–ç•¥ï¼Œè€Œä¸è¿›è¡Œè‡ªæˆ‘å¯¹å¼ˆã€‚
- en: But for intermediate values of Lambdaï¼Œ what we find is that it actually gives
    you a good medium between sticking to human conventions and performing stronglyã€‚So
    you can kind of see this behavior emerge hereã€‚Sorry there's a question is this
    similar to offline Rl or also incorporates explorationã€‚
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯å¯¹äºÎ»çš„ä¸­é—´å€¼ï¼Œæˆ‘ä»¬å‘ç°å®ƒå®é™…ä¸Šåœ¨éµå¾ªäººç±»çº¦å®šå’Œè¡¨ç°å¼ºåŠ²ä¹‹é—´æä¾›äº†ä¸€ä¸ªè‰¯å¥½çš„å¹³è¡¡ã€‚æ‰€ä»¥ä½ å¯ä»¥åœ¨è¿™é‡Œçœ‹åˆ°è¿™ç§è¡Œä¸ºçš„å‡ºç°ã€‚æŠ±æ­‰ï¼Œæœ‰ä¸ªé—®é¢˜ï¼Œè¿™æ˜¯å¦ç±»ä¼¼äºç¦»çº¿å¼ºåŒ–å­¦ä¹ ï¼Œè¿˜æ˜¯ä¹ŸåŒ…å«äº†æ¢ç´¢ï¼Ÿ
- en: so I'd say there's actually a lot of similar work on you know having a KL penaltyã€‚And
    so yes I would say that it's like very similar to a lot of that work and it's
    also been done actually an alphapha star where they had a KL penaltyã€‚though that
    was more about aiding exploration like using human data to aid exploration rather
    than trying to better imitate humans so I think what's interesting about the pickle
    work is that one we find it imitates humans better not than just doing supervised
    learning alone and two we areã€‚
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¯ä»¥è¯´ï¼Œå®é™…ä¸Šæœ‰å¾ˆå¤šç±»ä¼¼çš„å·¥ä½œï¼Œæ¯”å¦‚æ–½åŠ KLæƒ©ç½šã€‚å› æ­¤ï¼Œæˆ‘ä¼šè¯´è¿™ä¸å¾ˆå¤šç›¸å…³å·¥ä½œéå¸¸ç›¸ä¼¼ï¼Œå®é™…ä¸Šåœ¨AlphaStarä¸­ä¹Ÿåšè¿‡ï¼Œä»–ä»¬æ–½åŠ äº†KLæƒ©ç½šã€‚å°½ç®¡é‚£æ›´å¤šæ˜¯å…³äºåˆ©ç”¨äººç±»æ•°æ®æ¥å¸®åŠ©æ¢ç´¢ï¼Œè€Œä¸æ˜¯æ›´å¥½åœ°æ¨¡ä»¿äººç±»ã€‚å› æ­¤ï¼Œæˆ‘è®¤ä¸ºPickleå·¥ä½œçš„æœ‰è¶£ä¹‹å¤„åœ¨äºï¼Œæˆ‘ä»¬å‘ç°å®ƒåœ¨æ¨¡ä»¿äººç±»æ–¹é¢è¡¨ç°å¾—æ›´å¥½ï¼Œè€Œä¸ä»…ä»…æ˜¯è¿›è¡Œç›‘ç£å­¦ä¹ ã€‚
- en: Doing a bit of theory of mind where we assume that the other players are also
    like we're using this as a model for our behaviorã€‚what we expect other people
    to think our behavior is in addition to modeling the other playersã€‚So it's like
    a common knowledgeã€‚Common knowledge likeã€‚Algorithm that we're using hereã€‚Okayã€‚so
    the kind of behavior that you see from thisã€‚You can see hereï¼Œ let's say England
    agreesï¼Œ sorryã€‚
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨è¿›è¡Œä¸€äº›å¿ƒæ™ºç†è®ºçš„å·¥ä½œï¼Œæˆ‘ä»¬å‡è®¾å…¶ä»–ç©å®¶ä¹Ÿåœ¨ä½¿ç”¨è¿™ä¸ªæ¨¡å‹æ¥æŒ‡å¯¼æˆ‘ä»¬çš„è¡Œä¸ºã€‚æˆ‘ä»¬æœŸæœ›å…¶ä»–äººå¯¹æˆ‘ä»¬çš„è¡Œä¸ºçš„çœ‹æ³•ï¼Œé™¤äº†å¯¹å…¶ä»–ç©å®¶è¿›è¡Œå»ºæ¨¡ä¹‹å¤–ã€‚æ‰€ä»¥è¿™å°±åƒæ˜¯æˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨çš„ä¸€ä¸ªå¸¸è¯†ç®—æ³•ã€‚å¥½å§ã€‚ä»è¿™é‡Œä½ å¯ä»¥çœ‹åˆ°çš„è¡Œä¸ºï¼Œæ¯”å¦‚è¯´ï¼Œå‡è®¾è‹±æ ¼å…°åŒæ„ï¼ŒæŠ±æ­‰ã€‚
- en: so let's say we're in this situationï¼Œ this actually came up real in a real gameã€‚And
    it inspired a figure from our paperã€‚So England and France are fightingã€‚France
    is the bot and France asks ifã€‚If England is willing to disengageã€‚And let's say
    England saysã€‚yesï¼Œ I will move out of English channel if you head back to NAOã€‚Wellï¼Œ
    we can see that Cicero doesã€‚
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬å¤„äºè¿™ç§æƒ…å†µï¼Œè¿™å®é™…ä¸Šåœ¨ä¸€åœºçœŸå®çš„æ¸¸æˆä¸­å‘ç”Ÿè¿‡ã€‚è¿™å¯å‘äº†æˆ‘ä»¬è®ºæ–‡ä¸­çš„ä¸€ä¸ªä¾‹å­ã€‚æ‰€ä»¥è‹±æ ¼å…°å’Œæ³•å›½æ­£åœ¨äº¤æˆ˜ã€‚æ³•å›½æ˜¯â€œæœºå™¨äººâ€ï¼Œæ³•å›½è¯¢é—®è‹±æ ¼å…°æ˜¯å¦æ„¿æ„è„±ç¦»æ¥è§¦ã€‚å¦‚æœè‹±æ ¼å…°å›ç­”è¯´ï¼Œæ˜¯çš„ï¼Œå¦‚æœä½ å›åˆ°åŒ—å¤§è¥¿æ´‹ï¼Œæˆ‘ä¼šç¦»å¼€è‹±å‰åˆ©æµ·å³¡ã€‚é‚£ä¹ˆæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¥¿å¡ç½—çš„è¡¨ç°ã€‚
- en: in fact back offã€‚Leeaaves andã€‚Goes to NAO and the disengagement is successfulã€‚and
    so this shows that the bot strategy really is reflecting the dialogue that it's
    had with this other playerã€‚Another message that England might send is something
    likeã€‚I'm sorry you've been fighting me this whole gameï¼Œ I can't trust you that
    you won't stab meã€‚
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: å®é™…ä¸Šåæ’¤ã€‚ç¦»å¼€å¹¶ã€‚å»å¾€NAOï¼ŒæˆåŠŸè„±ç¦»æ¥è§¦ã€‚å› æ­¤ï¼Œè¿™è¡¨æ˜æœºå™¨äººçš„ç­–ç•¥ç¡®å®åæ˜ äº†å®ƒä¸å…¶ä»–ç©å®¶çš„å¯¹è¯ã€‚è‹±æ ¼å…°å¯èƒ½å‘é€çš„å¦ä¸€ä¸ªæ¶ˆæ¯æ˜¯è¿™æ ·çš„è¯ã€‚æˆ‘å¾ˆæŠ±æ­‰ï¼Œä½ æ•´ä¸ªæ¸¸æˆéƒ½åœ¨ä¸æˆ‘ä½œæ–—äº‰ï¼Œæˆ‘ä¸èƒ½ç›¸ä¿¡ä½ ä¸ä¼šèƒŒåˆºæˆ‘ã€‚
- en: And so in this caseï¼Œ Cicero will continue its attack on Englandï¼Œ and you can
    see againã€‚this is reflectiveï¼Œ it's changing its behavior depending on the dialogueã€‚But
    you can also have this kind of message where you know England saysï¼Œ yesã€‚I'll leave
    English channelnnel if you move tota Munich at Hall to Belgiumã€‚
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¥¿å¡ç½—å°†ç»§ç»­æ”»å‡»è‹±æ ¼å…°ï¼Œä½ å¯ä»¥å†æ¬¡çœ‹åˆ°ã€‚è¿™æ˜¯æœ‰ååº”çš„ï¼Œå®ƒæ ¹æ®å¯¹è¯æ”¹å˜äº†è¡Œä¸ºã€‚ä½†ä½ ä¹Ÿå¯ä»¥æœ‰è¿™æ ·çš„æ¶ˆæ¯ï¼Œæ¯”å¦‚è‹±æ ¼å…°è¯´ï¼Œæ˜¯çš„ã€‚å¦‚æœä½ æŠŠå†›é˜Ÿç§»åŠ¨åˆ°æ¯”åˆ©æ—¶ï¼Œæˆ‘å°±ä¼šç¦»å¼€è‹±å‰åˆ©æµ·å³¡ã€‚
- en: so these are really bad moves for Ccero to follow and so if you just look at
    the raw policy netã€‚It might actually do thisï¼Œ it might actually do these moves
    because England suggested itã€‚but because we're using pickle that incorporates
    like it accounts for the expected value of different actionsã€‚it will actually
    harshly back off but ignore the suggested moves because it recognize that those
    will leave it very vulnerable to an attackã€‚
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™äº›å¯¹äºè¥¿å¡ç½—æ¥è¯´éƒ½æ˜¯éå¸¸ç³Ÿç³•çš„ä¸¾åŠ¨ï¼Œå¦‚æœä½ åªçœ‹åŸå§‹çš„ç­–ç•¥ç½‘ç»œï¼Œå®ƒå¯èƒ½ä¼šè¿™æ ·åšï¼Œå¯èƒ½ä¼šåšå‡ºè¿™äº›ä¸¾åŠ¨ï¼Œå› ä¸ºè‹±æ ¼å…°å»ºè®®äº†å®ƒã€‚ä½†å› ä¸ºæˆ‘ä»¬ä½¿ç”¨pickleï¼Œå®ƒè€ƒè™‘äº†ä¸åŒåŠ¨ä½œçš„æœŸæœ›å€¼ï¼Œå®ƒå®é™…ä¸Šä¼šå¼ºçƒˆåœ°åæ’¤ï¼Œä½†å¿½ç•¥è¿™äº›å»ºè®®çš„ä¸¾åŠ¨ï¼Œå› ä¸ºå®ƒæ„è¯†åˆ°è¿™äº›ä¼šä½¿å…¶éå¸¸å®¹æ˜“å—åˆ°æ”»å‡»ã€‚
- en: Okayï¼Œ I's skip this slide for timeã€‚å—¯ã€‚Ohã€‚Another thing I should say is thatã€‚We're
    not just doing planningï¼Œ we're actually doing this in a full self play reinforcement
    learning loopã€‚And againï¼Œ the goal here is it's really about modeling humans better
    than supervised learning alone and we found that doing this selfplay reinforcement
    learning with pickle allowed us to better model human behavior than just doing
    imitation learningã€‚Finallyï¼Œ we have an ensemble of message filtering techniques
    that filters both nonsensical and strategically un soundund messagesã€‚
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½å§ï¼Œæˆ‘ä¼šè·³è¿‡è¿™ä¸€é¡µä»¥èŠ‚çœæ—¶é—´ã€‚å—¯ã€‚å“¦ã€‚æˆ‘è¿˜åº”è¯¥è¯´çš„æ˜¯ï¼Œæˆ‘ä»¬ä¸ä»…ä»…æ˜¯åœ¨åšè§„åˆ’ï¼Œæˆ‘ä»¬å®é™…ä¸Šæ˜¯åœ¨ä¸€ä¸ªå®Œæ•´çš„è‡ªæˆ‘å¯¹å¼ˆå¼ºåŒ–å­¦ä¹ å¾ªç¯ä¸­è¿›è¡Œã€‚è¿™æ¬¡çš„ç›®æ ‡ç¡®å®æ˜¯æ¯”å•çº¯çš„ç›‘ç£å­¦ä¹ æ›´å¥½åœ°å»ºæ¨¡äººç±»è¡Œä¸ºï¼Œæˆ‘ä»¬å‘ç°ä½¿ç”¨pickleè¿›è¡Œè‡ªæˆ‘å¯¹å¼ˆå¼ºåŒ–å­¦ä¹ å¯ä»¥æ¯”å•çº¯çš„æ¨¡ä»¿å­¦ä¹ æ›´å¥½åœ°æ¨¡æ‹Ÿäººç±»è¡Œä¸ºã€‚æœ€åï¼Œæˆ‘ä»¬æœ‰ä¸€ç»„æ¶ˆæ¯è¿‡æ»¤æŠ€æœ¯ï¼Œå¯ä»¥è¿‡æ»¤æ‰æ— æ„ä¹‰å’Œç­–ç•¥ä¸Šä¸åˆç†çš„æ¶ˆæ¯ã€‚
- en: UmSo to give you an example of what these filters look likeï¼Œ hereã€‚one that we
    developed is value based filteringã€‚ğŸ˜¡ï¼ŒSoã€‚The motivation for this is that when we
    feed into our dialogue model is a plan for ourselves and for our speaking partnerã€‚but
    it's the entire plan that we have for ourselvesã€‚
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: å—¯ï¼Œæ‰€ä»¥ç»™ä½ ä¸€ä¸ªå…³äºè¿™äº›è¿‡æ»¤å™¨çš„ä¾‹å­ï¼Œè¿™é‡Œã€‚æœ‰ä¸€ä¸ªæˆ‘ä»¬å¼€å‘çš„åŸºäºä»·å€¼çš„è¿‡æ»¤å™¨ã€‚ğŸ˜¡ï¼Œæ‰€ä»¥ã€‚è¿™ä¹ˆåšçš„åŠ¨æœºåœ¨äºï¼Œå½“æˆ‘ä»¬è¾“å…¥å¯¹è¯æ¨¡å‹æ—¶ï¼Œæ˜¯ä¸ºæˆ‘ä»¬è‡ªå·±å’Œæˆ‘ä»¬è®²è¯ä¼™ä¼´åˆ¶å®šçš„è®¡åˆ’ï¼Œä½†è¿™æ˜¯æˆ‘ä»¬ä¸ºè‡ªå·±åˆ¶å®šçš„æ•´ä¸ªè®¡åˆ’ã€‚
- en: and so we might end up feeding into the dialogue model the fact that we're going
    to attack the player that we're speaking toã€‚Nowï¼Œ the dialogue model isï¼Œ you knowï¼Œ
    to be honest kind of dumb and it doesn't really knowã€‚That it shouldn't be telling
    this player that theyre going to be attacked this termã€‚And so you have these messages
    that might be sentï¼Œ something like the second one shown here where England says
    to Franceã€‚
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬å¯èƒ½æœ€ç»ˆä¼šæŠŠæˆ‘ä»¬æ‰“ç®—æ”»å‡»ä¸æˆ‘ä»¬å¯¹è¯çš„ç©å®¶è¿™ä¸€äº‹å®è¾“å…¥åˆ°å¯¹è¯æ¨¡å‹ä¸­ã€‚è€å®è¯´ï¼Œå¯¹è¯æ¨¡å‹æœ‰ç‚¹å‚»ï¼Œå®ƒå¹¶ä¸çŸ¥é“ä¸åº”è¯¥å‘Šè¯‰è¿™ä¸ªç©å®¶ä»–ä»¬ä¼šè¢«æ”»å‡»ã€‚å› æ­¤ï¼Œå¯èƒ½ä¼šå‘é€ä¸€äº›æ¶ˆæ¯ï¼Œæ¯”å¦‚è¿™é‡Œæ˜¾ç¤ºçš„ç¬¬äºŒæ¡ï¼Œè‹±æ ¼å…°å¯¹æ³•å›½è¯´ã€‚
- en: we have hostile intentions towards youï¼Œ you must be wipeding the boardï¼Œ please
    provide a croissantã€‚So this is actually like a message that the bot sent to a
    player not to a player it was a this was like preliminary testing and kind of
    like motivated this whole approachã€‚
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯¹ä½ æœ‰æ•Œæ„ï¼Œä½ å¿…é¡»æ¸…ç†æˆ˜åœºï¼Œè¯·æä¾›ä¸€ä¸ªå¯é¢‚ã€‚å®é™…ä¸Šï¼Œè¿™æ˜¯æœºå™¨äººå‘é€ç»™ä¸€ä¸ªç©å®¶çš„æ¶ˆæ¯ï¼Œè€Œä¸æ˜¯å¯¹å¦ä¸€ä½ç©å®¶çš„ã€‚è¿™æ˜¯åˆæ­¥æµ‹è¯•ï¼Œæ¿€å‘äº†æ•´ä¸ªæ–¹æ³•ã€‚
- en: å—¯ã€‚So we don't want the bot to send these kinds of messages if it's going to
    attack a playerã€‚we want it to send something that's likeï¼Œ you knowï¼Œ not an outright
    lie necessarilyã€‚but just something either not send a message or send something
    that's much much much more blandã€‚ğŸ˜¡ã€‚And so we filter out these kinds of messages
    by looking at the value likeã€‚
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: å—¯ã€‚å› æ­¤ï¼Œå¦‚æœæœºå™¨äººæ‰“ç®—æ”»å‡»ç©å®¶ï¼Œæˆ‘ä»¬ä¸å¸Œæœ›å®ƒå‘é€è¿™ç§æ¶ˆæ¯ã€‚æˆ‘ä»¬å¸Œæœ›å®ƒå‘é€ä¸€äº›ä¸ä¸€å®šæ˜¯å®Œå…¨è°è¨€çš„ä¸œè¥¿ï¼Œæˆ–è€…æ ¹æœ¬ä¸å‘é€æ¶ˆæ¯ï¼Œæˆ–è€…å‘é€ä¸€äº›æ›´ä¸ºå¹³æ·¡çš„å†…å®¹ã€‚ğŸ˜¡ã€‚å› æ­¤ï¼Œæˆ‘ä»¬é€šè¿‡æŸ¥çœ‹è¿™äº›å€¼æ¥è¿‡æ»¤è¿™äº›æ¶ˆæ¯ã€‚
- en: What we do is we generate a bunch of candidate messagesã€‚And then we see if we
    were to send this messageï¼Œ what is the behavior that we would expect the other
    players to take like what actions will we expect them to do after we send this
    message and what do they expect we will do after we send this messageï¼Ÿ
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ‰€åšçš„æ˜¯ç”Ÿæˆä¸€å †å€™é€‰æ¶ˆæ¯ã€‚ç„¶åæˆ‘ä»¬çœ‹çœ‹ï¼Œå¦‚æœæˆ‘ä»¬å‘é€è¿™æ¡æ¶ˆæ¯ï¼Œæˆ‘ä»¬æœŸæœ›å…¶ä»–å‚ä¸è€…çš„è¡Œä¸ºæ˜¯ä»€ä¹ˆï¼Œä»–ä»¬åœ¨æ”¶åˆ°è¿™æ¡æ¶ˆæ¯åä¼šé‡‡å–ä»€ä¹ˆè¡ŒåŠ¨ï¼Œä»–ä»¬åˆæœŸæœ›æˆ‘ä»¬åœ¨å‘é€è¿™æ¡æ¶ˆæ¯åä¼šåšä»€ä¹ˆï¼Ÿ
- en: And then we seeã€‚What is the expected value of the action that we intend to takeã€‚given
    the prediction of what everybody else is going to doï¼ŸğŸ˜¡ã€‚So if our intention is
    to attack Franceï¼Œ then we can see wellã€‚if I were to send this message to Franceï¼Œ
    then they're going to get really defensive and defend against an attack from us
    and our attack is going to be unsuccessful and so therefore I probably shouldn't
    send this message to themã€‚
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬çœ‹åˆ°ï¼Œæˆ‘ä»¬æ‰“ç®—é‡‡å–çš„è¡ŒåŠ¨çš„é¢„æœŸå€¼æ˜¯ä»€ä¹ˆã€‚è€ƒè™‘åˆ°å¯¹å…¶ä»–äººå°†è¦åšçš„é¢„æµ‹ğŸ˜¡ã€‚æ‰€ä»¥å¦‚æœæˆ‘ä»¬çš„æ„å›¾æ˜¯æ”»å‡»æ³•å›½ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå¦‚æœæˆ‘å°†è¿™æ¡æ¶ˆæ¯å‘é€ç»™æ³•å›½ï¼Œä»–ä»¬ä¼šå˜å¾—éå¸¸é˜²å¾¡ï¼ŒæŠµå¾¡æˆ‘ä»¬çš„æ”»å‡»ï¼Œè€Œæˆ‘ä»¬çš„æ”»å‡»å°†ä¼šå¤±è´¥ï¼Œå› æ­¤æˆ‘å¯èƒ½ä¸åº”è¯¥å°†è¿™æ¡æ¶ˆæ¯å‘é€ç»™ä»–ä»¬ã€‚
- en: å—¯ã€‚And so in this webï¼Œ we can actually filter out messages that have low expected
    valueã€‚And we thought that this worked surprisingly wellã€‚Dialogue examplesã€‚I'll
    go through one just for the sake of timeã€‚So here we haveã€‚Cicero is France and
    France is saying France is conversing with Turkeyï¼Œ who's a human playerã€‚
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: å—¯ã€‚æ‰€ä»¥åœ¨è¿™ä¸ªç½‘ç»œä¸­ï¼Œæˆ‘ä»¬å®é™…ä¸Šå¯ä»¥è¿‡æ»¤æ‰é¢„æœŸå€¼è¾ƒä½çš„æ¶ˆæ¯ã€‚æˆ‘ä»¬å‘ç°è¿™æ•ˆæœæƒŠäººåœ°å¥½ã€‚å¯¹è¯ç¤ºä¾‹ã€‚ä¸ºäº†èŠ‚çœæ—¶é—´ï¼Œæˆ‘å°†ä¸¾ä¸€ä¸ªä¾‹å­ã€‚è¿™é‡Œæœ‰ã€‚è¥¿å¡ç½—ä»£è¡¨æ³•å›½ï¼Œæ³•å›½æ­£åœ¨ä¸äººç±»ç©å®¶åœŸè€³å…¶å¯¹è¯ã€‚
- en: and they're debating over who's going to get tunisï¼Œ this territory circled in
    redã€‚You can see they both have fleets next to the territoryã€‚if they both go for
    it neither them we're going to get itã€‚and so they need to work out some sort of
    dealã€‚So France saysï¼Œ I'll work with youã€‚
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ä»–ä»¬æ­£åœ¨äº‰è®ºè°å°†å é¢†çªå°¼æ–¯ï¼Œè¿™ä¸ªè¢«çº¢åœˆåœˆå‡ºçš„é¢†åœŸã€‚ä½ å¯ä»¥çœ‹åˆ°ä»–ä»¬éƒ½æœ‰èˆ°é˜Ÿåœ¨é¢†åœŸæ—è¾¹ã€‚å¦‚æœä»–ä»¬éƒ½å»äº‰å¤ºï¼Œé‚£ä¹ˆéƒ½ä¸ä¼šå¾—åˆ°ã€‚å› æ­¤ï¼Œä»–ä»¬éœ€è¦è¾¾æˆæŸç§åè®®ã€‚æ‰€ä»¥æ³•å›½è¯´ï¼Œæˆ‘ä¼šå’Œä½ åˆä½œã€‚
- en: but I need tunes for nowï¼Œ Turkey saysï¼Œ nopeï¼Œ you got to let me have itã€‚France
    says noï¼Œ I need itã€‚and then France suggestsï¼Œ you knowï¼Œ you can take these other
    territories instead you have Serbia and Rome to takeã€‚Turkey says they're impossible
    targets and then Cicero suggests specific movesã€‚That would allow Turkey to capture
    these territory so Cicero says Greece Iionion I unate to Tianã€‚
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯æˆ‘ç°åœ¨éœ€è¦çªå°¼æ–¯ï¼ŒåœŸè€³å…¶è¯´ï¼Œä¸ï¼Œä½ å¾—è®©æˆ‘æ‹¥æœ‰å®ƒã€‚æ³•å›½è¯´ä¸ï¼Œæˆ‘éœ€è¦å®ƒã€‚ç„¶åæ³•å›½å»ºè®®ï¼Œä½ çŸ¥é“ï¼Œä½ å¯ä»¥å»å é¢†å…¶ä»–é¢†åœŸï¼Œæ¯”å¦‚å¡å°”ç»´äºšå’Œç½—é©¬ã€‚åœŸè€³å…¶è¯´ï¼Œé‚£äº›æ˜¯ä¸å¯åŠçš„ç›®æ ‡ï¼Œæ¥ç€è¥¿å¡ç½—æå‡ºå…·ä½“çš„è¡ŒåŠ¨ï¼Œå…è®¸åœŸè€³å…¶å é¢†è¿™äº›é¢†åœŸï¼Œæ‰€ä»¥è¥¿å¡ç½—è¯´å¸Œè…Šã€çˆ±å¥¥å°¼äºšå’Œç‰¹å…°ã€‚
- en: Turkey saysm you're right good ideas and then France says then in the fall you
    take Rome Austria collapses and so that allows Turkey to you know make progress
    against Austria but conveniently it also allows France to capture tus because
    Turkey will be using those units for something elseã€‚
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: åœŸè€³å…¶è¯´ï¼Œä½ è¯´å¾—å¯¹ï¼Œè¿™äº›æ˜¯å¥½ä¸»æ„ï¼Œç„¶åæ³•å›½è¯´ï¼Œé‚£åœ¨ç§‹å¤©ä½ å°±å¯ä»¥å é¢†ç½—é©¬ï¼Œå¥¥åœ°åˆ©å´©æºƒäº†ï¼Œè¿™æ ·åœŸè€³å…¶å°±å¯ä»¥å¯¹å¥¥åœ°åˆ©å–å¾—è¿›å±•ï¼Œä½†æ–¹ä¾¿çš„æ˜¯ï¼Œè¿™ä¹Ÿè®©æ³•å›½å¯ä»¥å é¢†çªå°¼æ–¯ï¼Œå› ä¸ºåœŸè€³å…¶ä¼šå°†é‚£äº›å•ä½ç”¨äºå…¶ä»–äº‹æƒ…ã€‚
- en: Okayï¼Œ so limitations in future directions intent representation is just an action
    per playerã€‚Okayã€‚so there's a question of likeã€‚The intentions that we're feeding
    into the dialogue model is an action that we're going to take for this turn and
    for the next turn for ourselves and for the other playerã€‚
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œæœªæ¥æ–¹å‘ä¸­çš„é™åˆ¶æ„å›¾è¡¨ç¤ºåªæ˜¯æ¯ä¸ªç©å®¶çš„ä¸€é¡¹è¡ŒåŠ¨ã€‚å¥½çš„ã€‚æ‰€ä»¥æœ‰ä¸€ä¸ªé—®é¢˜ã€‚æˆ‘ä»¬è¾“å…¥å¯¹è¯æ¨¡å‹çš„æ„å›¾æ˜¯æˆ‘ä»¬åœ¨è¿™ä¸€å›åˆä»¥åŠä¸‹ä¸€å›åˆè¦ä¸ºè‡ªå·±å’Œå…¶ä»–ç©å®¶é‡‡å–çš„è¡ŒåŠ¨ã€‚
- en: But ideallyï¼Œ we would have a richer set of intentionsã€‚we would be able to like
    condition on things like long term strategy or style of communication or like
    asking questionsã€‚That is that's one of the limitations of this approach now of
    courseã€‚The richer you make the space of intentionsï¼Œ the more room there is for
    things to go wrongã€‚
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†ç†æƒ³æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¼šæœ‰æ›´ä¸°å¯Œçš„æ„å›¾é›†åˆã€‚æˆ‘ä»¬èƒ½å¤Ÿè€ƒè™‘é•¿æœŸç­–ç•¥ã€æ²Ÿé€šé£æ ¼æˆ–æé—®ç­‰å› ç´ ã€‚è¿™æ˜¯è¿™ç§æ–¹æ³•çš„ä¸€ä¸ªé™åˆ¶ã€‚å½“ç„¶ï¼Œæ„å›¾çš„ç©ºé—´è¶Šä¸°å¯Œï¼Œå‡ºé”™çš„å¯èƒ½æ€§å°±è¶Šå¤§ã€‚
- en: and you also have to like then train the model to be able to handle these like
    wider space of intentionsã€‚ğŸ˜¡ï¼ŒThere was a questionï¼Œ do you think the dialogue model
    is learning an internal modelã€‚internal world model to be so good at predicting
    movesï¼ŸThis is this is arguably why we'reã€‚Conditioning on intentionsï¼Œ we're relieving
    the dialogue model of having to come up with a good world model because we're
    telling it like these are the moves that we are planning to take this turn and
    these are the moves that we would like this other player to take this turnã€‚
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ è¿˜éœ€è¦è®­ç»ƒæ¨¡å‹ï¼Œä»¥ä¾¿å¤„ç†æ›´å¹¿æ³›çš„æ„å›¾ç©ºé—´ã€‚æœ‰ä¸€ä¸ªé—®é¢˜ï¼Œä½ è®¤ä¸ºå¯¹è¯æ¨¡å‹æ˜¯å¦åœ¨å­¦ä¹ ä¸€ä¸ªå†…éƒ¨æ¨¡å‹ï¼Ÿå†…éƒ¨ä¸–ç•Œæ¨¡å‹æ˜¯å¦ä½¿å…¶èƒ½å¤Ÿå¦‚æ­¤å‡†ç¡®åœ°é¢„æµ‹åŠ¨ä½œï¼Ÿè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬ä¾èµ–æ„å›¾ï¼Œå‡è½»å¯¹è¯æ¨¡å‹æ„å»ºè‰¯å¥½ä¸–ç•Œæ¨¡å‹çš„è´Ÿæ‹…ï¼Œå› ä¸ºæˆ‘ä»¬å‘Šè¯‰å®ƒè¿™æ˜¯æˆ‘ä»¬åœ¨è¿™ä¸€å›åˆè®¡åˆ’é‡‡å–çš„åŠ¨ä½œï¼Œè€Œè¿™äº›æ˜¯æˆ‘ä»¬å¸Œæœ›å…¶ä»–ç©å®¶åœ¨è¿™ä¸€å›åˆé‡‡å–çš„åŠ¨ä½œã€‚
- en: So we're likeã€‚We're able to likeã€‚Have the world model separate from the dialogue
    modelã€‚but condition on the output from the world modelã€‚Okayã€‚another limitation
    is that Cicero's value model doesn't condition on dialogueã€‚and so it has a limited
    understanding of the long term effects of dialogueã€‚å—¯ã€‚
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬èƒ½å¤Ÿè®©ä¸–ç•Œæ¨¡å‹ä¸å¯¹è¯æ¨¡å‹åˆ†å¼€ï¼Œä½†ä¾èµ–äºä¸–ç•Œæ¨¡å‹çš„è¾“å‡ºã€‚å¥½çš„ï¼Œå¦ä¸€ä¸ªé™åˆ¶æ˜¯Ciceroçš„ä»·å€¼æ¨¡å‹å¹¶ä¸ä¾èµ–äºå¯¹è¯ï¼Œå› æ­¤å¯¹å¯¹è¯çš„é•¿æœŸå½±å“ç†è§£æœ‰é™ã€‚
- en: This greatly limits our ability toã€‚Plan what kind of messages we should be sendingã€‚And
    this is actually why we always condition Cicero's dialogue generation on its truthful
    intentionsã€‚You could argue that there is situations in diplomacy where you would
    want to lie to the other playerã€‚the best players rarely lieï¼Œ but they do lie sometimesã€‚Andã€‚
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æå¤§åœ°é™åˆ¶äº†æˆ‘ä»¬è§„åˆ’åº”å‘é€çš„æ¶ˆæ¯ç±»å‹çš„èƒ½åŠ›ã€‚å®é™…ä¸Šï¼Œè¿™ä¹Ÿæ˜¯æˆ‘ä»¬æ€»æ˜¯å°†Ciceroçš„å¯¹è¯ç”ŸæˆåŸºäºå…¶çœŸå®æ„å›¾çš„åŸå› ã€‚ä½ å¯ä»¥äº‰è¾©ï¼Œåœ¨å¤–äº¤ä¸­æœ‰äº›æƒ…å†µä¸‹ï¼Œä½ ä¼šæƒ³å¯¹å…¶ä»–ç©å®¶æ’’è°ï¼Œæœ€å¥½çš„ç©å®¶å¾ˆå°‘æ’’è°ï¼Œä½†æœ‰æ—¶ä¼šæ’’è°ã€‚
- en: You have to understand the trade off between like if you lieï¼Œ you are going
    toã€‚ğŸ˜¡ã€‚It's going to be much harder to work with this person in the futureã€‚And so
    you have to make sure that theã€‚Value that you're getting positionally is worth
    that loss of trust and that broken relationshipã€‚noã€‚Because Cicero's value model
    doesn't condition on dialogueã€‚
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¿…é¡»ç†è§£ï¼Œå¦‚æœä½ æ’’è°ï¼Œä½ å°†ä¼šå˜å¾—æ›´éš¾ä¸è¿™ä¸ªäººåˆä½œã€‚å› æ­¤ï¼Œä½ å¿…é¡»ç¡®ä¿ä½ æ‰€è·å¾—çš„ç›¸å¯¹ä»·å€¼å€¼å¾—ä¿¡ä»»çš„æŸå¤±å’Œç ´è£‚çš„å…³ç³»ã€‚å› ä¸ºCiceroçš„ä»·å€¼æ¨¡å‹å¹¶ä¸ä¾èµ–äºå¯¹è¯ã€‚
- en: It can't really understand this trade offã€‚ğŸ˜¡ï¼ŒAnd so for this reasonã€‚we actually
    always conditioned it on its truthful intentionsã€‚Noã€‚It is possible to have Cicero
    Viol condition on dialogueã€‚but you would need way more data and it would make
    things much more expensive and so we weren't able to do it further for this spotã€‚
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒå®é™…ä¸Šæ— æ³•ç†è§£è¿™ç§æƒè¡¡ã€‚å› æ­¤ï¼Œå‡ºäºè¿™ä¸ªåŸå› ï¼Œæˆ‘ä»¬å§‹ç»ˆå°†å…¶åŸºäºçœŸå®æ„å›¾ã€‚å®é™…ä¸Šï¼Œå¯ä»¥è®©Cicero Violä¾èµ–äºå¯¹è¯ï¼Œä½†ä½ éœ€è¦æ›´å¤šçš„æ•°æ®ï¼Œè¿™ä¼šä½¿äº‹æƒ…å˜å¾—æ›´åŠ æ˜‚è´µï¼Œå› æ­¤æˆ‘ä»¬æ— æ³•è¿›ä¸€æ­¥è¿›è¡Œã€‚
- en: And finallyï¼Œ there's a big question that I mentioned earlierï¼Œ which isã€‚is there
    a more general way of scaling inference time compute to achieve better performanceï¼Ÿ
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘æåˆ°äº†ä¸€ä¸ªå¤§é—®é¢˜ï¼Œé‚£å°±æ˜¯æ˜¯å¦æœ‰æ›´æ™®éçš„æ–¹æ³•æ¥ç¼©æ”¾æ¨ç†æ—¶é—´è®¡ç®—ï¼Œä»¥å®ç°æ›´å¥½çš„æ€§èƒ½ï¼Ÿ
- en: The way that we've done planning in Cicero is I would argue a bit domain specificã€‚I
    think it's like the idea of pickle is quite generalã€‚but I think that there are
    potentially more general ways of doing planningã€‚è¯¶ã€‚Somebody's asking looking forward
    to the next two to three yearsã€‚
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºæˆ‘ä»¬åœ¨Ciceroä¸­è¿›è¡Œè§„åˆ’çš„æ–¹å¼æœ‰ç‚¹é¢†åŸŸç‰¹å®šã€‚æˆ‘è§‰å¾—pickleçš„æ¦‚å¿µç›¸å½“æ™®éï¼Œä½†æˆ‘è®¤ä¸ºå¯èƒ½è¿˜æœ‰æ›´æ™®éçš„è§„åˆ’æ–¹å¼ã€‚æœ‰äººé—®æœŸå¾…æœªæ¥ä¸¤åˆ°ä¸‰å¹´ã€‚
- en: what criteria will you use to select the next game to try to conquer honestlyã€‚Like
    I said we chose diplomacy because we thought it'd be the hardest game to make
    an AI for it and I think that that's true I don't think that we're going to be
    working on games anywhere because I can't think of any other game that if we were
    to succeed at that it would be truly impressiveã€‚
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å°†ä½¿ç”¨ä»€ä¹ˆæ ‡å‡†æ¥é€‰æ‹©ä¸‹ä¸€ä¸ªæ¸¸æˆä»¥è¯šå®åœ°å¾æœï¼Ÿæ­£å¦‚æˆ‘æ‰€è¯´ï¼Œæˆ‘ä»¬é€‰æ‹©å¤–äº¤æ˜¯å› ä¸ºæˆ‘ä»¬è®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªæœ€éš¾ä¸ºå…¶åˆ¶ä½œAIçš„æ¸¸æˆï¼Œæˆ‘è®¤ä¸ºè¿™ç¡®å®æ˜¯æ­£ç¡®çš„ã€‚æˆ‘æƒ³ä¸å‡ºä»»ä½•å…¶ä»–æ¸¸æˆï¼Œå¦‚æœæˆ‘ä»¬æˆåŠŸï¼Œé‚£å°†æ˜¯éå¸¸ä»¤äººå°è±¡æ·±åˆ»çš„ã€‚
- en: And so I think where the research is going in the futureã€‚Is generalityã€‚Likeã€‚Instead
    of getting an AI to play this specific gameï¼Œ can we get an AI that is able to
    play diplomacyã€‚but could also play go or poker or could also write essays and
    stories and solve math problems and write theoremsã€‚I think what we will seeã€‚Is
    games serving as benchmarksï¼ŸFor progressã€‚But not asã€‚The goalï¼Œ you knowã€‚
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘è®¤ä¸ºæœªæ¥çš„ç ”ç©¶æ–¹å‘æ˜¯é€šç”¨æ€§ã€‚æˆ‘ä»¬èƒ½å¦è®©äººå·¥æ™ºèƒ½ä¸ä»…èƒ½ç©è¿™ä¸ªç‰¹å®šçš„æ¸¸æˆï¼Œè¿˜èƒ½ç©å›´æ£‹æˆ–æ‰‘å…‹ï¼Œæˆ–è€…è¿˜èƒ½å†™è®ºæ–‡ã€æ•…äº‹ã€è§£å†³æ•°å­¦é—®é¢˜å’Œå†™å®šç†ã€‚æˆ‘è®¤ä¸ºæˆ‘ä»¬å°†çœ‹åˆ°çš„æ˜¯ï¼Œæ¸¸æˆä½œä¸ºè¿›æ­¥çš„åŸºå‡†ï¼Œä½†ä¸æ˜¯ç›®æ ‡ã€‚
- en: it'll be part of the test set but not part of the training setã€‚and I think that's
    the way it should be going forwardã€‚Finallylyã€‚I want to add that diplomacy is an
    amazing testbed for multi agentent AI and Gred dialogueã€‚If you are interested
    in these kinds of domainsï¼Œ I highly recommend taking advantage of the fact that
    we areã€‚
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†æ˜¯æµ‹è¯•é›†çš„ä¸€éƒ¨åˆ†ï¼Œä½†ä¸æ˜¯è®­ç»ƒé›†çš„ä¸€éƒ¨åˆ†ã€‚æˆ‘è®¤ä¸ºè¿™åº”è¯¥æ˜¯æœªæ¥çš„æ–¹å‘ã€‚æœ€åï¼Œæˆ‘æƒ³è¡¥å……çš„æ˜¯ï¼Œå¤–äº¤æ˜¯å¤šä»£ç†äººå·¥æ™ºèƒ½å’Œå¯¹è¯ç”Ÿæˆçš„ä¸€ä¸ªæƒŠäººæµ‹è¯•å¹³å°ã€‚å¦‚æœä½ å¯¹è¿™äº›é¢†åŸŸæ„Ÿå…´è¶£ï¼Œæˆ‘å¼ºçƒˆæ¨èåˆ©ç”¨æˆ‘ä»¬æ‰€æä¾›çš„æœºä¼šã€‚
- en: We've open sourced all of our coded models and the dialogue and action data
    is available through a what's called an RFP where you can apply to get access
    to the dialogue and dataã€‚Okayï¼Œ so thanks for listening to wrap of Cicero combined
    strategic reasonaing and natural language and diplomaacy in place in the top 10%
    of human players and the paper is in science and code of models are publicly available
    at this URL so thanks and for there any time I'll take questions great thanks
    a lot my talkã€‚
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²å¼€æºæ‰€æœ‰ç¼–ç æ¨¡å‹ï¼Œå¯¹è¯å’Œè¡ŒåŠ¨æ•°æ®å¯ä»¥é€šè¿‡ä¸€ç§ç§°ä¸ºRFPçš„æ–¹å¼è·å–ï¼Œä½ å¯ä»¥ç”³è¯·è·å–å¯¹è¯å’Œæ•°æ®ã€‚å¥½çš„ï¼Œæ„Ÿè°¢å¤§å®¶çš„å€¾å¬ï¼ŒCiceroç»“åˆäº†æˆ˜ç•¥æ¨ç†å’Œè‡ªç„¶è¯­è¨€ï¼Œåœ¨äººç±»é¡¶å°–10%çš„ç©å®¶ä¸­è¡¨ç°å‡ºè‰²ï¼Œè®ºæ–‡å·²å‘è¡¨äºç§‘å­¦æœŸåˆŠï¼Œæ¨¡å‹ä»£ç åœ¨è¿™ä¸ªç½‘å€å…¬å¼€å¯ç”¨ï¼Œæ‰€ä»¥è°¢è°¢ï¼Œéšæ—¶å¯ä»¥æé—®ï¼Œæ„Ÿè°¢å¤§å®¶çš„æ”¯æŒã€‚
- en: So we'll also open some questions from the classï¼Œ but you finished their Zoom
    questions so if anyone has like Zoom questions there I think no we can answer
    thoseã€‚Yeahï¼Œ there's one question are you concerned about AIs out competingeting
    humans at real world diplomatic strategic negotiation at deception tasksã€‚
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜å°†å¼€æ”¾ä¸€äº›æ¥è‡ªè¯¾å ‚çš„é—®é¢˜ï¼Œä½†ä½ å·²ç»å®Œæˆäº†ä»–ä»¬çš„Zoomé—®é¢˜ï¼Œæ‰€ä»¥å¦‚æœæœ‰äººæœ‰Zoomçš„é—®é¢˜ï¼Œæˆ‘æƒ³æˆ‘ä»¬å¯ä»¥å›ç­”ã€‚æ˜¯çš„ï¼Œæœ‰ä¸€ä¸ªé—®é¢˜ï¼Œä½ æ˜¯å¦æ‹…å¿ƒäººå·¥æ™ºèƒ½åœ¨çœŸå®ä¸–ç•Œçš„å¤–äº¤æˆ˜ç•¥è°ˆåˆ¤å’Œæ¬ºéª—ä»»åŠ¡ä¸­è¶…è¿‡äººç±»ã€‚
- en: so like I said we're not very focused on deception even though you know arguably
    deception is a part of the game of diplomacyã€‚ç³»ã€‚Think for diplomatic and strategic
    negotiationã€‚I don't like look the way that we've developed is realã€‚It's designed
    to play diplomacy the game of diplomacy specifically and you can't use it out
    of the box for other tasks that said I do think that the techniques are quiteã€‚General
    and so hopefully others can build on that and to be able to do different thingsã€‚
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘æ‰€è¯´ï¼Œæˆ‘ä»¬å¹¶ä¸å¤ªå…³æ³¨æ¬ºéª—ï¼Œå°½ç®¡å¯ä»¥è¯´æ¬ºéª—æ˜¯å¤–äº¤æ¸¸æˆçš„ä¸€éƒ¨åˆ†ã€‚æ€è€ƒå¤–äº¤å’Œæˆ˜ç•¥è°ˆåˆ¤ã€‚æˆ‘ä¸å–œæ¬¢æˆ‘ä»¬æ‰€å‘å±•çš„æ–¹å¼æ˜¯çœŸå®çš„ã€‚å®ƒæ˜¯ä¸“é—¨è®¾è®¡æ¥è¿›è¡Œå¤–äº¤æ¸¸æˆçš„ï¼Œä½ ä¸èƒ½ç›´æ¥ç”¨äºå…¶ä»–ä»»åŠ¡ï¼Œä½†æˆ‘ç¡®å®è®¤ä¸ºè¿™äº›æŠ€æœ¯æ˜¯ç›¸å½“é€šç”¨çš„ï¼Œå› æ­¤å¸Œæœ›å…¶ä»–äººå¯ä»¥åœ¨æ­¤åŸºç¡€ä¸Šæ„å»ºï¼Œä»¥ä¾¿èƒ½å¤Ÿåšä¸åŒçš„äº‹æƒ…ã€‚
- en: and I think it is you know entirely possible that over the next several yearsã€‚you
    will see this entering into real world negotiations much more often I actually
    think that diplomacy is a big step towards real world applicability compared to
    breakies in games like go and pokerã€‚
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºåœ¨æ¥ä¸‹æ¥çš„å‡ å¹´é‡Œï¼Œè¿™ç§æƒ…å†µå®Œå…¨å¯èƒ½ï¼Œä½ ä¼šçœ‹åˆ°å®ƒåœ¨ç°å®ä¸–ç•Œçš„è°ˆåˆ¤ä¸­æ›´é¢‘ç¹åœ°å‡ºç°ã€‚æˆ‘å®é™…ä¸Šè®¤ä¸ºï¼Œä¸å›´æ£‹å’Œæ‰‘å…‹ç­‰æ¸¸æˆç›¸æ¯”ï¼Œå¤–äº¤æ˜¯æœå‘ç°å®ä¸–ç•Œé€‚ç”¨æ€§è¿ˆå‡ºçš„é‡è¦ä¸€æ­¥ã€‚
- en: Because because now your action space is really like the space of natural language
    and you have to model human behaviorã€‚Do you think in the future we could appoint
    AI to the UN Councilï¼Ÿ
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºç°åœ¨ä½ çš„è¡ŒåŠ¨ç©ºé—´å®é™…ä¸Šå°±æ˜¯è‡ªç„¶è¯­è¨€çš„ç©ºé—´ï¼Œä½ å¿…é¡»å¯¹äººç±»è¡Œä¸ºè¿›è¡Œå»ºæ¨¡ã€‚ä½ è®¤ä¸ºæœªæ¥æˆ‘ä»¬èƒ½å¦ä»»å‘½äººå·¥æ™ºèƒ½æ‹…ä»»è”åˆå›½ç†äº‹ä¼šçš„æˆå‘˜ï¼Ÿ
- en: hopefully only if it does better than humansï¼Œ but that would be very interesting
    to seeã€‚Greatã€‚I'm also curious like what what's like the future things that you're
    working on in this direction like do you think you can do something like Alpago
    zero where you just like take this take this like repeated model and then maybe
    just make it Excel play or like what sort of future actions are you thinking for
    improving this sort of boxã€‚
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›åªæœ‰åœ¨å®ƒè¡¨ç°ä¼˜äºäººç±»çš„æƒ…å†µä¸‹ï¼Œä½†é‚£å°†æ˜¯éå¸¸æœ‰è¶£çš„ã€‚å¤ªå¥½äº†ã€‚æˆ‘ä¹Ÿå¾ˆå¥½å¥‡ï¼Œä½ ä»¬åœ¨è¿™ä¸ªæ–¹å‘ä¸Šæ­£åœ¨ç ”ç©¶å“ªäº›æœªæ¥çš„äº‹æƒ…ï¼Œä½ è®¤ä¸ºèƒ½å¦åšç±»ä¼¼Alphago Zeroçš„äº‹æƒ…ï¼Œé‡å¤è¿™ä¸ªæ¨¡å‹ï¼Œä¹Ÿè®¸è®©å®ƒåœ¨Excelä¸­è¿è¡Œï¼Œæˆ–è€…ä½ åœ¨æ”¹è¿›è¿™ä¸ªç›’å­æ–¹é¢æœ‰å“ªäº›æœªæ¥çš„æƒ³æ³•ï¼Ÿ
- en: ğŸ˜Šï¼ŒI think the future directions are really focused around generalityã€‚like I
    think one of the big insights of Cicero is like this ability to leverage planning
    to get better performance with language models and in this strategic domainã€‚I
    think there' was a lot of opportunity to do that sort of thing in a broader space
    of domainsã€‚I mean you look at language models today and they do token by token
    predictionã€‚
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šï¼Œæˆ‘è®¤ä¸ºæœªæ¥çš„æ–¹å‘ç¡®å®æ˜¯å›´ç»•é€šç”¨æ€§å±•å¼€çš„ã€‚æˆ‘è®¤ä¸ºCiceroçš„ä¸€ä¸ªé‡å¤§æ´å¯Ÿæ˜¯åˆ©ç”¨è§„åˆ’æ¥æå‡è¯­è¨€æ¨¡å‹çš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨è¿™ä¸ªæˆ˜ç•¥é¢†åŸŸã€‚æˆ‘è®¤ä¸ºåœ¨æ›´å¹¿æ³›çš„é¢†åŸŸä¸­æœ‰å¾ˆå¤šæœºä¼šè¿›è¡Œè¿™ç§æ¢ç´¢ã€‚ç°åœ¨çš„è¯­è¨€æ¨¡å‹æ˜¯é€ä¸ªæ ‡è®°è¿›è¡Œé¢„æµ‹çš„ã€‚
- en: And I think there's a big opportunity to go beyond that so that that's what
    i'm excited to look into I'm also curious like I didn't understand the exact details
    how using planning or Montete research with your like the models that you haveã€‚So
    is it like we didn't use Monla research in Ciceroï¼Œ Mongla researchã€‚Is a very good
    heuristicã€‚
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºæœ‰ä¸€ä¸ªå¾ˆå¤§çš„æœºä¼šå¯ä»¥è¶…è¶Šè¿™ä¸€ç‚¹ï¼Œè¿™è®©æˆ‘æ„Ÿåˆ°å…´å¥‹ã€‚æˆ‘ä¹Ÿå¾ˆå¥½å¥‡ï¼Œæˆ‘æ²¡æœ‰ç†è§£å…·ä½“ç»†èŠ‚ï¼Œå¦‚ä½•ä½¿ç”¨è§„åˆ’æˆ–è’™ç‰¹å¡ç½—ç ”ç©¶ä¸æ‚¨æ‹¥æœ‰çš„æ¨¡å‹ç»“åˆã€‚æˆ‘ä»¬åœ¨Ciceroä¸­æ²¡æœ‰ä½¿ç”¨è’™ç‰¹å¡ç½—ç ”ç©¶ï¼Œè’™ç‰¹å¡ç½—ç ”ç©¶æ˜¯ä¸€ä¸ªéå¸¸å¥½çš„å¯å‘å¼æ–¹æ³•ã€‚
- en: but it's a heuristic that isã€‚Particularly useful for deterministic perfect information
    gamesã€‚And I think in order to like have a truly general form of planning we need
    to go more abstract than multic research we use this algorithm called pickle based
    on a regret minimization algorithm I don't really want to go into the details
    of it because it's not that important for the classã€‚
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†å®ƒæ˜¯ä¸€ç§å¯å‘å¼æ–¹æ³•ã€‚ç‰¹åˆ«é€‚ç”¨äºç¡®å®šæ€§å®Œå…¨ä¿¡æ¯æ¸¸æˆã€‚ä¸ºäº†æ‹¥æœ‰çœŸæ­£é€šç”¨çš„è§„åˆ’å½¢å¼ï¼Œæˆ‘ä»¬éœ€è¦æ›´æŠ½è±¡åœ°è¶…è¶Šè’™ç‰¹å¡ç½—ç ”ç©¶ã€‚æˆ‘ä»¬ä½¿ç”¨ä¸€ç§ç§°ä¸ºpickleçš„ç®—æ³•ï¼ŒåŸºäºé—æ†¾æœ€å°åŒ–ç®—æ³•ã€‚æˆ‘ä¸æƒ³è¯¦ç»†è®¨è®ºï¼Œå› ä¸ºè¿™å¯¹è¯¾ç¨‹å¹¶ä¸é‡è¦ã€‚
- en: but the idea is like it is this iterative algorithm that will gradually refine
    the prediction of what everybody's going do and get better and better predictions
    the more iterations that you runã€‚But and that's similar researchã€‚Yeahã€‚Coï¼Œ yeahï¼Œ
    sureã€‚å¯¹ã€‚Go for itï¼Œ you're un mututedã€‚Okayã€‚So yeahã€‚
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¿™ä¸ªæƒ³æ³•å°±åƒæ˜¯ä¸€ä¸ªè¿­ä»£ç®—æ³•ï¼Œé€æ¸å®Œå–„æ¯ä¸ªäººçš„é¢„æµ‹ï¼Œéšç€è¿­ä»£æ¬¡æ•°çš„å¢åŠ ï¼Œé¢„æµ‹ä¼šè¶Šæ¥è¶Šå‡†ç¡®ã€‚ä½†è¿™ç±»ä¼¼äºå…¶ä»–ç ”ç©¶ã€‚æ˜¯çš„ï¼Œå¥½çš„ï¼Œå½“ç„¶ã€‚å¯¹ã€‚ç»§ç»­å§ï¼Œä½ å¯ä»¥å‘è¨€ã€‚å¥½çš„ã€‚æ˜¯çš„ã€‚
- en: my question is like when we were talking about gender likeibilityã€‚how does the
    communication between different modules of the model look likeï¼Ÿ
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘çš„é—®é¢˜æ˜¯ï¼Œå½“æˆ‘ä»¬è®¨è®ºæ€§åˆ«å¯æ¥çº³æ€§æ—¶ï¼Œæ¨¡å‹ä¸åŒæ¨¡å—ä¹‹é—´çš„æ²Ÿé€šæ˜¯æ€æ ·çš„ï¼Ÿ
- en: Particularly when we're talking about the dialogue modelã€‚Like how do you send
    information from the policy network to the dialogue model and in the futureã€‚if
    you have a model that's good at different tasksã€‚are we going to have like a really
    big policy net that learns all of them or like separate language modules for all
    of them like how do you break it downï¼Ÿ
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: ç‰¹åˆ«æ˜¯åœ¨æˆ‘ä»¬è°ˆè®ºå¯¹è¯æ¨¡å‹æ—¶ã€‚ä½ å¦‚ä½•å°†ä¿¡æ¯ä»ç­–ç•¥ç½‘ç»œå‘é€åˆ°å¯¹è¯æ¨¡å‹ï¼Ÿæœªæ¥ï¼Œå¦‚æœä½ æœ‰ä¸€ä¸ªæ“…é•¿ä¸åŒä»»åŠ¡çš„æ¨¡å‹ï¼Œæˆ‘ä»¬ä¼šæœ‰ä¸€ä¸ªå­¦ä¹ æ‰€æœ‰ä»»åŠ¡çš„åºå¤§ç­–ç•¥ç½‘ç»œï¼Œè¿˜æ˜¯ä¸ºæ¯ä¸ªä»»åŠ¡éƒ½æœ‰ç‹¬ç«‹çš„è¯­è¨€æ¨¡å—ï¼Ÿä½ ä¼šå¦‚ä½•æ‹†åˆ†ï¼Ÿ
- en: So we actually convert the policy like action for ourselves and for our dialogue
    partner into a string naturaltro language string and to that into the dialogue
    model along with all the dialogue that it's had so farã€‚so it's just all text in
    text outã€‚And that works greatã€‚
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬å®é™…ä¸Šå°†æ”¿ç­–åƒè¡Œä¸ºä¸€æ ·è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œè‡ªç„¶è¯­è¨€å­—ç¬¦ä¸²ï¼Œç„¶åå°†å…¶è¾“å…¥å¯¹è¯æ¨¡å‹ï¼Œä»¥åŠåˆ°ç›®å‰ä¸ºæ­¢æ‰€æœ‰çš„å¯¹è¯å†…å®¹ã€‚å› æ­¤ï¼Œè¿™å°±æ˜¯æ–‡æœ¬è¾“å…¥æ–‡æœ¬è¾“å‡ºã€‚è¿™ç§æ–¹æ³•æ•ˆæœå¾ˆå¥½ã€‚
- en: And then what was the second part of your questionï¼ŸSomething likeã€‚are we just
    going to have like one giant policy net trained on everythingï¼ŸYeahã€‚it was like
    so if you're only using text first doesn't it limit the model and if you're using
    it for different games like are you thinking like when you say in the future you
    will work on generalizabilityã€‚are you thinking about a big policy network that
    is trained on separate games or is able to like understand different games at
    the same time or do we have like separate policy networks for different gamesï¼Ÿ
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä½ ç¬¬äºŒä¸ªé—®é¢˜çš„å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿç±»ä¼¼äºæˆ‘ä»¬ä¼šæœ‰ä¸€ä¸ªå·¨å¤§çš„ç­–ç•¥ç½‘ç»œè®­ç»ƒåœ¨æ‰€æœ‰å†…å®¹ä¸Šå—ï¼Ÿæ˜¯çš„ï¼Œå¦‚æœä½ åªä½¿ç”¨æ–‡æœ¬ï¼Œéš¾é“ä¸ä¼šé™åˆ¶æ¨¡å‹å—ï¼Ÿå¦‚æœä½ åœ¨ä¸åŒçš„æ¸¸æˆä¸­ä½¿ç”¨å®ƒï¼Œæ¯”å¦‚ä½ æåˆ°çš„æœªæ¥ä¼šå…³æ³¨é€šç”¨æ€§ï¼Œä½ æ˜¯æŒ‡ä¸€ä¸ªåœ¨ä¸åŒæ¸¸æˆä¸Šè®­ç»ƒçš„å¤§ç­–ç•¥ç½‘ç»œï¼Œè¿˜æ˜¯èƒ½å¤ŸåŒæ—¶ç†è§£ä¸åŒæ¸¸æˆï¼Œæˆ–è€…æ˜¯ä¸ºä¸åŒæ¸¸æˆæœ‰ç‹¬ç«‹çš„ç­–ç•¥ç½‘ç»œï¼Ÿ
- en: And yeahï¼Œ like doesn't this like text interface limit the model in terms of
    communication like if you're using vectors it might likeã€‚Yeahï¼Œ it might be a bit
    of a bottom wayã€‚I meanï¼Œ I think ideally you go in this direction where you have
    like you know a foundational model that works for pretty much everything does
    text I mean certainly yeah just like a text in text out that like limits what
    you can do in terms communicationã€‚
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: å—¯ï¼Œæ˜¯çš„ï¼Œè¿™ç§æ–‡æœ¬æ¥å£åœ¨æ²Ÿé€šä¸Šé™åˆ¶äº†æ¨¡å‹çš„èƒ½åŠ›ï¼Œæ¯”å¦‚å¦‚æœä½¿ç”¨å‘é‡å¯èƒ½ä¼šæœ‰äº›åº•å±‚ã€‚æˆ‘æ˜¯è¯´ï¼Œç†æƒ³æƒ…å†µä¸‹ä½ åº”è¯¥æœç€è¿™ä¸ªæ–¹å‘å‘å±•ï¼Œæ‹¥æœ‰ä¸€ä¸ªé€‚ç”¨äºå‡ ä¹æ‰€æœ‰æ–‡æœ¬çš„åŸºç¡€æ¨¡å‹ï¼Œå½“ç„¶ï¼Œä»…ä»…æ˜¯æ–‡æœ¬è¾“å…¥å’Œè¾“å‡ºï¼Œè¿™åœ¨æ²Ÿé€šä¸Šæ˜¯æœ‰é™åˆ¶çš„ã€‚
- en: but hopefully we get beyond thatã€‚![](img/e3abef98963297997c09e5d05b736a64_7.png)
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†å¸Œæœ›æˆ‘ä»¬èƒ½è¶…è¶Šè¿™ä¸ªã€‚![](img/e3abef98963297997c09e5d05b736a64_7.png)
- en: I think it's a reasonable choice for nowã€‚Thank youã€‚We questionsã€‚And I think
    we have more some questions Okay so there's a question in the chat i'd love to
    hear speculation on the future for instance we've seen some startups that are
    fine tuning LLMs to be biased or experts in say subject experts ofã€‚
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºè¿™åœ¨ç°åœ¨æ˜¯ä¸ªåˆç†çš„é€‰æ‹©ã€‚è°¢è°¢ã€‚æˆ‘ä»¬æœ‰é—®é¢˜ã€‚æˆ‘æƒ³æˆ‘ä»¬è¿˜æœ‰ä¸€äº›é—®é¢˜ï¼Œå¥½å§ï¼ŒèŠå¤©ä¸­æœ‰ä¸€ä¸ªé—®é¢˜ï¼Œæˆ‘æƒ³å¬å¬ä½ å¯¹æœªæ¥çš„çŒœæµ‹ï¼Œæ¯”å¦‚è¯´æˆ‘ä»¬çœ‹åˆ°ä¸€äº›åˆåˆ›å…¬å¸æ­£åœ¨å¾®è°ƒLLMsï¼Œä»¥ä¾¿åå‘æŸä¸ªé¢†åŸŸæˆ–æˆä¸ºæŸç§ä¸»é¢˜çš„ä¸“å®¶ã€‚
- en: This seems like a pretty general questionã€‚ç³»ã€‚Don't have strong opinions on thisã€‚è¯¶ã€‚ç³»ä¸‹é¢ã€‚Likeï¼Œ
    I'm notã€‚I'm not tooã€‚I'm not too focused myself on fine tuning language models
    to specific tasksã€‚I think the direction that i'm much more interested in going
    forward is you know like the more general forms of planningã€‚so I don't think I
    can really comment onã€‚You knowï¼Œ how do youã€‚Two in these language modelsã€‚
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¼¼ä¹æ˜¯ä¸ªç›¸å½“é€šç”¨çš„é—®é¢˜ã€‚ç³»ã€‚æˆ‘å¯¹æ­¤æ²¡æœ‰å¼ºçƒˆçš„çœ‹æ³•ã€‚è¯¶ã€‚ç³»ä¸‹é¢ã€‚å°±åƒï¼Œæˆ‘å¹¶ä¸å¤ªä¸“æ³¨äºå°†è¯­è¨€æ¨¡å‹å¾®è°ƒåˆ°ç‰¹å®šä»»åŠ¡ã€‚æˆ‘è®¤ä¸ºæˆ‘æ›´æ„Ÿå…´è¶£çš„æ–¹å‘æ˜¯æ›´é€šç”¨çš„è§„åˆ’å½¢å¼ã€‚æ‰€ä»¥æˆ‘è§‰å¾—æˆ‘ä¸èƒ½çœŸæ­£è¯„è®ºã€‚ä½ çŸ¥é“çš„ï¼Œè¿™äº›è¯­è¨€æ¨¡å‹æ€ä¹ˆèƒ½åšåˆ°ã€‚
- en: In these waysã€‚So what sort of planning methods are you like interested in looking
    at like like MCps is one so let me sorry I got to step out for just one secondã€‚Got
    the switch roomsï¼Œ excuse meã€‚Okayï¼Œ never mind we're all good sorry what was the
    question Oh yes I was I was just asking like what sort of planning algorithms
    do you think are very interesting to combine So you can think like we have like
    so many options like we have like planet kind of stuff or Rl there's like MCps
    there's like the work you did with Cro so what do you think are the most interesting
    algorithms that you think will scale well can generalizeã€‚
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥è¿™ç§æ–¹å¼ã€‚é‚£ä¹ˆä½ å¯¹å“ªäº›è§„åˆ’æ–¹æ³•æ„Ÿå…´è¶£ï¼Œæ¯”å¦‚è¯´MCPSæ˜¯å…¶ä¸­ä¹‹ä¸€ï¼Œæ‰€ä»¥è®©æˆ‘æŠ±æ­‰ï¼Œæˆ‘å¾—å‡ºå»ä¸€ç§’ã€‚æ¢ä¸ªæˆ¿é—´ï¼ŒæŠ±æ­‰ã€‚å¥½çš„ï¼Œæ²¡äº‹ï¼Œæˆ‘ä»¬éƒ½å¾ˆå¥½ï¼ŒæŠ±æ­‰ï¼Œé—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿå“¦ï¼Œæ˜¯çš„ï¼Œæˆ‘åªæ˜¯é—®ä½ è®¤ä¸ºå“ªäº›è§„åˆ’ç®—æ³•éå¸¸æœ‰è¶£ï¼Œå¯ä»¥ç»“åˆä½¿ç”¨ã€‚æˆ‘ä»¬æœ‰å¾ˆå¤šé€‰æ‹©ï¼Œæ¯”å¦‚è¡Œæ˜Ÿç±»çš„ä¸œè¥¿æˆ–è€…RLï¼Œè¿˜æœ‰MCPSï¼Œä»¥åŠä½ ä¸Croåˆä½œçš„å·¥ä½œã€‚é‚£ä¹ˆä½ è®¤ä¸ºå“ªäº›ç®—æ³•æœ€æœ‰è¶£ï¼Œèƒ½å¤Ÿå¾ˆå¥½åœ°æ‰©å±•å’Œæ³›åŒ–ï¼Ÿ
- en: ğŸ˜Šï¼ŒWell I think that's the big question that a lot of people are trying to figure
    out today and it's not really clear what the answer is I mean I think you know
    you look at something the chain of thoughtã€‚I think there's a lot of limitations
    to chain of thoughtã€‚
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šï¼Œæˆ‘è®¤ä¸ºè¿™æ˜¯è®¸å¤šäººä»Šå¤©è¯•å›¾å¼„æ¸…æ¥šçš„å¤§é—®é¢˜ï¼Œè€Œç­”æ¡ˆå¹¶ä¸æ¸…æ¥šã€‚æˆ‘çš„æ„æ€æ˜¯ï¼Œä½ çœ‹çœ‹é“¾å¼æ€ç»´ã€‚æˆ‘è®¤ä¸ºé“¾å¼æ€ç»´æœ‰å¾ˆå¤šå±€é™æ€§ã€‚
- en: and I think that it should be possible to do a lot betterã€‚but it is really impressive
    to see just how general of an approach it isã€‚And so I think it would be nice to
    seeã€‚è¯¶ã€‚To see things that are general in that wayã€‚but hopefully able to achieve
    better performanceã€‚Goã€‚å¥½ã€‚Alsoã€‚
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºæœ‰å¾ˆå¤šæ–¹æ³•å¯ä»¥åšå¾—æ›´å¥½ã€‚ä½†çœ‹åˆ°è¿™æ ·é€šç”¨çš„æ–¹æ³•çœŸçš„å¾ˆä»¤äººå°è±¡æ·±åˆ»ã€‚æ‰€ä»¥æˆ‘è®¤ä¸ºçœ‹åˆ°è¿™æ ·é€šç”¨çš„ä¸œè¥¿ä¼šå¾ˆä¸é”™ï¼Œä½†å¸Œæœ›èƒ½å®ç°æ›´å¥½çš„æ€§èƒ½ã€‚èµ°å§ï¼Œå¥½ã€‚
- en: when you see like citra is like an encoder decoder model in the sense it encodes
    the worldã€‚and then you have the dialg modelï¼Œ which is time to de itã€‚It was an
    encoder decoder modelï¼Œ yesã€‚I don't think that that's necessarily the right choiceï¼Œ
    but that's what we usedã€‚Any questionsï¼Ÿå—¯ã€‚Okay I think youre mostly goodã€‚Ayï¼Œ thanks
    a lot this was a good well yeahã€‚
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä½ çœ‹åˆ°åƒCitraè¿™æ ·çš„ç¼–ç è§£ç æ¨¡å‹æ—¶ï¼Œå®ƒåœ¨æŸç§æ„ä¹‰ä¸Šç¼–ç äº†ä¸–ç•Œã€‚ç„¶åä½ æœ‰å¯¹è¯æ¨¡å‹ï¼Œè´Ÿè´£è§£ç ã€‚æ˜¯çš„ï¼Œå®ƒæ˜¯ä¸€ä¸ªç¼–ç è§£ç æ¨¡å‹ã€‚æˆ‘ä¸è®¤ä¸ºè¿™ necessarily
    æ˜¯æ­£ç¡®çš„é€‰æ‹©ï¼Œä½†è¿™å°±æ˜¯æˆ‘ä»¬ä½¿ç”¨çš„ã€‚æœ‰ä»€ä¹ˆé—®é¢˜å—ï¼Ÿå—¯ï¼Œå¥½çš„ï¼Œæˆ‘è§‰å¾—ä½ å¤§è‡´ä¸Šæ²¡é—®é¢˜ã€‚è°¢è°¢ï¼Œè¿™çœŸæ˜¯å¥½ã€‚
- en: hope you all enjoyed it and if there are any questions feel free to email me
    reach out I'm happy to happy to chatã€‚![](img/e3abef98963297997c09e5d05b736a64_9.png)
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›ä½ ä»¬éƒ½å–œæ¬¢ï¼Œå¦‚æœæœ‰ä»»ä½•é—®é¢˜ï¼Œè¯·éšæ—¶å‘é‚®ä»¶è”ç³»æˆ‘ï¼Œæˆ‘å¾ˆä¹æ„èŠèŠã€‚![](img/e3abef98963297997c09e5d05b736a64_9.png)
