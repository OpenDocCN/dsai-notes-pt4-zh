- en: æ–¯å¦ç¦ GPTï¼Transformer åŸç†ä»‹ç» (ä¸­è‹±æ–‡åŒå­—å¹•) - P13ï¼š13.Emergent Abilities and Scaling in
    LLMs - life_code - BV1X84y1Q7wV
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ–¯å¦ç¦ GPT/Transformer åŸç†ä»‹ç»ï¼ˆä¸­è‹±æ–‡åŒå­—å¹•ï¼‰- P13ï¼š13.å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¶Œç°èƒ½åŠ›å’Œæ‰©å±• - life_code - BV1X84y1Q7wV
- en: '![](img/1fe3b7e42f45e3d11a61cea42eaf51cb_0.png)'
  id: totrans-1
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1fe3b7e42f45e3d11a61cea42eaf51cb_0.png)'
- en: '![](img/1fe3b7e42f45e3d11a61cea42eaf51cb_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1fe3b7e42f45e3d11a61cea42eaf51cb_1.png)'
- en: Okayï¼Œ great so the first sort of paper I'm going to be talking about is called
    emergent abilities of large language models and this paper was especially coolã€‚I
    think because we got people from Google in a Deep Mind and also at Stanford you
    might recognize Percy or Tatsu or Riishhiã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œé‚£ä¹ˆæˆ‘è¦è°ˆè®ºçš„ç¬¬ä¸€ç¯‡è®ºæ–‡æ˜¯å…³äºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ¶Œç°èƒ½åŠ›ï¼Œè¿™ç¯‡è®ºæ–‡ç‰¹åˆ«é…·ã€‚æˆ‘è®¤ä¸ºï¼Œå› ä¸ºæˆ‘ä»¬ä»è°·æ­Œã€Deep Mind å’Œæ–¯å¦ç¦å¾—åˆ°äº†äººä»¬çš„å‚ä¸ï¼Œä½ å¯èƒ½ä¼šè®¤è¯†
    Percyã€Tatsu æˆ– Riishhiã€‚
- en: I mean we got people to sort of agree on what's a nice framework of looking
    at why we want to scale and emergent abilitiesã€‚Soã€‚One of the things that we've
    seen throughout language models is that you sort of get these predictable gains
    as a result of scalingã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘çš„æ„æ€æ˜¯ï¼Œæˆ‘ä»¬è®©äººä»¬åœ¨ä¸ºä»€ä¹ˆè¦æ‰©å±•å’Œæ¶Œç°èƒ½åŠ›æ–¹é¢è¾¾æˆäº†ä¸€ç§ç¾å¥½çš„æ¡†æ¶ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åœ¨æ•´ä¸ªè¯­è¨€æ¨¡å‹ä¸­çœ‹åˆ°çš„ä¸€ä»¶äº‹æ˜¯ï¼Œéšç€è§„æ¨¡çš„æ‰©å¤§ï¼Œä½ ç¡®å®ä¼šå¾—åˆ°è¿™äº›å¯é¢„æµ‹çš„æ”¶ç›Šã€‚
- en: so here's the canonical you know Kaplan et all paper where you can see that
    if you scale up the size of the language model measured either in compute in data
    set size or in parametersã€‚You see that the loss on the test set actually goes
    down predictably I don't know if you're screen sharing so people on zoom I don't
    think can see the slides Okay all these okayã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™é‡Œæ˜¯ä½ çŸ¥é“çš„ç»å…¸ Kaplan ç­‰äººçš„è®ºæ–‡ï¼Œä½ å¯ä»¥çœ‹åˆ°ï¼Œå¦‚æœä½ æ‰©å±•è¯­è¨€æ¨¡å‹çš„è§„æ¨¡ï¼Œæ— è®ºæ˜¯è®¡ç®—èµ„æºã€æ•°æ®é›†å¤§å°è¿˜æ˜¯å‚æ•°æ•°é‡ï¼Œä½ ä¼šå‘ç°æµ‹è¯•é›†ä¸Šçš„æŸå¤±å®é™…ä¸Šæ˜¯å¯é¢„æµ‹çš„ã€‚æˆ‘ä¸çŸ¥é“ä½ æ˜¯å¦åœ¨åˆ†äº«å±å¹•ï¼Œæ‰€ä»¥åœ¨
    Zoom ä¸Šçš„äººå¯èƒ½çœ‹ä¸åˆ°å¹»ç¯ç‰‡ã€‚å¥½å§ï¼Œè¿™äº›éƒ½æ²¡é—®é¢˜ã€‚
- en: Oã€‚I guess I'll say this for the third timeï¼Œ as we've seen in language modelsã€‚If
    you scale up the size of the language model measured either in computeã€‚in data
    set size or a number of parametersï¼Œ you can see that there's a sort of this predictable
    improvement in the test lossã€‚å—¯ã€‚Nowï¼Œ what I'm going to be talking about in terms
    of emergence is something that's actually unpredictableã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Oã€‚æˆ‘æƒ³æˆ‘è¦å†è¯´ä¸€æ¬¡ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨è¯­è¨€æ¨¡å‹ä¸­å·²ç»çœ‹åˆ°è¿‡ã€‚å¦‚æœä½ æ‰©å±•è¯­è¨€æ¨¡å‹çš„è§„æ¨¡ï¼Œæ— è®ºæ˜¯è®¡ç®—èµ„æºã€æ•°æ®é›†å¤§å°è¿˜æ˜¯å‚æ•°æ•°é‡ï¼Œä½ éƒ½å¯ä»¥çœ‹åˆ°æµ‹è¯•æŸå¤±æœ‰ä¸€ç§å¯é¢„æµ‹çš„æ”¹å–„ã€‚å—¯ã€‚ç°åœ¨ï¼Œå…³äºæ¶Œç°çš„è®¨è®ºå®é™…ä¸Šæ˜¯å…³äºä¸€äº›ä¸å¯é¢„æµ‹çš„äº‹ç‰©ã€‚
- en: If you only look at smaller language modelsï¼Œ so one way that emergence has been
    described in the broader science literature is it's basically seen as a qualitative
    change that arises from quantitative changes and it sort of started with this
    article in science by a Nobel Prize winning physicist called More is differentã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœåªçœ‹è¾ƒå°çš„è¯­è¨€æ¨¡å‹ï¼Œé‚£ä¹ˆæ¶Œç°åœ¨æ›´å¹¿æ³›çš„ç§‘å­¦æ–‡çŒ®ä¸­è¢«æè¿°ä¸ºä¸€ç§ä»æ•°é‡ä¸Šçš„å˜åŒ–è€Œäº§ç”Ÿçš„è´¨çš„å˜åŒ–ï¼Œå®ƒçš„èµ·æºå¯ä»¥è¿½æº¯åˆ°ä¸€ä½è¯ºè´å°”å¥–è·å¾—è€…çš„ç§‘å­¦æ–‡ç« ï¼Œç§°ä¸ºâ€œæ›´å¤šçš„ä¸åŒâ€ã€‚
- en: And I really like this post from Jacob Steinart that sort of describes emergence
    and he gives a couple of good examples hereã€‚For exampleï¼Œ he says with uraniumï¼Œ
    with a bit of uraniumï¼Œ nothing special happensã€‚with a large amount of ur impact
    densely enoughï¼Œ you get a nuclear reactionã€‚And then also with DNAã€‚for exampleï¼Œ
    given only small molecules such as calciumã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘çœŸçš„å¾ˆå–œæ¬¢ Jacob Steinart çš„è¿™ç¯‡æ–‡ç« ï¼Œä»–åœ¨è¿™é‡Œæè¿°äº†æ¶Œç°ï¼Œå¹¶ä¸¾äº†å‡ ä¸ªå¾ˆå¥½çš„ä¾‹å­ã€‚ä¾‹å¦‚ï¼Œä»–è¯´å¯¹äºé“€æ¥è¯´ï¼Œå¦‚æœåªæœ‰ä¸€ç‚¹ç‚¹é“€ï¼Œæ²¡æœ‰ä»€ä¹ˆç‰¹åˆ«çš„äº‹æƒ…å‘ç”Ÿï¼›ä½†å¦‚æœå¯†é›†åœ°å½±å“åˆ°è¶³å¤Ÿå¤šçš„é“€ï¼Œä½ ä¼šå¾—åˆ°æ ¸ååº”ã€‚è¿˜æœ‰
    DNA çš„ä¾‹å­ï¼Œä¾‹å¦‚ï¼Œå¦‚æœåªæœ‰é’™è¿™æ ·çš„å°åˆ†å­ã€‚
- en: you can't meaningfully encode useful informationï¼Œ but given larger models such
    as DNAã€‚you can encode a genomeã€‚So for this particular workã€‚we use this definition
    of emergent abilities of large language models in particularã€‚so we say that ability
    is emergent if it is not present in smaller modelsã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¸èƒ½æœ‰æ„ä¹‰åœ°ç¼–ç æœ‰ç”¨çš„ä¿¡æ¯ï¼Œä½†æ˜¯å¯¹äºåƒ DNA è¿™æ ·çš„æ›´å¤§æ¨¡å‹ï¼Œä½ å¯ä»¥ç¼–ç åŸºå› ç»„ã€‚å› æ­¤ï¼Œå¯¹äºè¿™é¡¹ç‰¹å®šå·¥ä½œï¼Œæˆ‘ä»¬ä½¿ç”¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ç‰¹åˆ«çš„æ¶Œç°èƒ½åŠ›å®šä¹‰ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è¯´ï¼Œå¦‚æœæŸç§èƒ½åŠ›åœ¨è¾ƒå°çš„æ¨¡å‹ä¸­ä¸å­˜åœ¨ï¼Œé‚£ä¹ˆå®ƒå°±æ˜¯æ¶Œç°çš„ã€‚
- en: but it is present in larger modelsã€‚And the sort of natural question here is
    like how do you measure the size or the scale of the language model and there's
    sort of traditionally three axes of scale so the training flops are the amount
    of compute that you use to train the language modelã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯å®ƒå­˜åœ¨äºæ›´å¤§çš„æ¨¡å‹ä¸­ã€‚è¿™é‡Œçš„ä¸€ä¸ªè‡ªç„¶é—®é¢˜æ˜¯ï¼Œå¦‚ä½•è¡¡é‡è¯­è¨€æ¨¡å‹çš„å¤§å°æˆ–è§„æ¨¡ï¼Œä¼ ç»Ÿä¸Šæœ‰ä¸‰ä¸ªè§„æ¨¡çš„ç»´åº¦ï¼Œå³è®­ç»ƒæ—¶çš„è®¡ç®—èµ„æºã€ç”¨äºè®­ç»ƒè¯­è¨€æ¨¡å‹çš„è®¡ç®—é‡ã€‚
- en: The number of model parameters are like the size of the language model and also
    the size of the training data set that the model is trained onã€‚And a lot of the
    plots here will use either training flops or the number of model parametersã€‚the
    reason is that the training dataset size is usually fixed for different size models
    and because training flops is just the data set size times model parametersã€‚you
    can get a similar plot from either training flops or number of model parameters
    for most language modelsã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹å‚æ•°çš„æ•°é‡å°±åƒæ˜¯è¯­è¨€æ¨¡å‹çš„å¤§å°ï¼Œä»¥åŠæ¨¡å‹æ‰€è®­ç»ƒçš„æ•°æ®é›†çš„å¤§å°ã€‚è¿™äº›å›¾ä¸­çš„å¾ˆå¤šå°†ä½¿ç”¨è®­ç»ƒçš„æµ®ç‚¹è¿ç®—æ•°é‡æˆ–æ¨¡å‹å‚æ•°çš„æ•°é‡ã€‚åŸå› æ˜¯å¯¹äºä¸åŒè§„æ¨¡çš„æ¨¡å‹ï¼Œè®­ç»ƒæ•°æ®é›†çš„å¤§å°é€šå¸¸æ˜¯å›ºå®šçš„ï¼Œè€Œè®­ç»ƒçš„æµ®ç‚¹è¿ç®—æ•°é‡åªæ˜¯æ•°æ®é›†å¤§å°ä¹˜ä»¥æ¨¡å‹å‚æ•°ã€‚å¯¹äºå¤§å¤šæ•°è¯­è¨€æ¨¡å‹ï¼Œä½ å¯ä»¥ä»è®­ç»ƒçš„æµ®ç‚¹è¿ç®—æ•°é‡æˆ–æ¨¡å‹å‚æ•°æ•°é‡å¾—åˆ°ç±»ä¼¼çš„å›¾ã€‚
- en: Greatï¼Œ and so the first type of emergenceï¼Œ yesï¼Œ I goã€‚ããã ã€‚Yeahï¼Œ for meã€‚it seems
    nice like it'd be relatively easier to measure the size versus it's like what
    quaifiesã€‚You find okayã€‚å°±æ˜¯ã€‚å“ªé‡Œã€‚Yeahï¼Œ sureã€‚So yeahï¼Œ for exampleã€‚' I'll just give
    an example here which is actually the next slideã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆå¥½ï¼Œæ‰€ä»¥ç¬¬ä¸€ç§æ¶Œç°ç±»å‹ï¼Œæ˜¯çš„ï¼Œæˆ‘ç»§ç»­ã€‚ããã ã€‚å¯¹æˆ‘æ¥è¯´ï¼Œè¿™ä¼¼ä¹å¾ˆä¸é”™ï¼Œæµ‹é‡è§„æ¨¡ç›¸å¯¹ç®€å•ï¼Œè€Œä¸æ˜¯ç¡®å®šä»€ä¹ˆæ˜¯åˆæ ¼çš„ã€‚ä½ å‘ç°å¥½å§ã€‚å°±æ˜¯ã€‚å“ªé‡Œã€‚å¥½çš„ï¼Œå½“ç„¶ã€‚æ‰€ä»¥æ˜¯çš„ï¼Œä¸¾ä¸ªä¾‹å­ã€‚æˆ‘å°†åœ¨è¿™é‡Œç»™å‡ºä¸€ä¸ªä¾‹å­ï¼Œå®é™…ä¸Šæ˜¯ä¸‹ä¸€å¼ å¹»ç¯ç‰‡ã€‚
- en: so basically we have this way of interacting with language models called fu
    shot prompting and the way it works is like you know the language model is a really
    good next word predictorã€‚And when you give the model an exampleï¼Œ and then you
    ask it for an unseen like movie review for exampleã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºæœ¬ä¸Šï¼Œæˆ‘ä»¬ä¸è¯­è¨€æ¨¡å‹äº¤äº’çš„ä¸€ç§æ–¹å¼å«åšfu shotæç¤ºï¼Œå…¶å·¥ä½œæ–¹å¼æ˜¯ä½ çŸ¥é“è¯­è¨€æ¨¡å‹æ˜¯ä¸€ä¸ªéå¸¸å¥½çš„ä¸‹ä¸€ä¸ªè¯é¢„æµ‹å™¨ã€‚å½“ä½ ç»™æ¨¡å‹ä¸€ä¸ªä¾‹å­ï¼Œç„¶åè¯¢é—®å®ƒä¸€ä¸ªæœªè§è¿‡çš„ç”µå½±è¯„è®ºæ—¶ã€‚
- en: and then you say what's the output and then here the language model can say
    positive because it understands to use the context from the review to give the
    next tokenã€‚And the definition of let that we use for like having ability or not
    is that basically a few shot prompted like tasksã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åä½ ä¼šé—®ï¼Œè¾“å‡ºæ˜¯ä»€ä¹ˆã€‚åœ¨è¿™é‡Œï¼Œè¯­è¨€æ¨¡å‹å¯ä»¥è¯´â€œç§¯æâ€ï¼Œå› ä¸ºå®ƒç†è§£å¦‚ä½•åˆ©ç”¨è¯„è®ºä¸­çš„ä¸Šä¸‹æ–‡æ¥ç»™å‡ºä¸‹ä¸€ä¸ªæ ‡è®°ã€‚æˆ‘ä»¬ç”¨æ¥åˆ¤æ–­æ˜¯å¦å…·å¤‡èƒ½åŠ›çš„å®šä¹‰åŸºæœ¬ä¸Šæ˜¯å‡ ä¸ªé•œå¤´æç¤ºçš„ä»»åŠ¡ã€‚
- en: for exampleï¼Œ sentiment analysisï¼Œ is emergent if it has random accuracy for small
    modelsã€‚but above random accuracy for large modelsã€‚Does that make senseã€‚so basically
    if the model isn't doing any better than randomã€‚then we say it doesn't have the
    ability to do this particular taskã€‚ä¸ªã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæƒ…æ„Ÿåˆ†æï¼Œå¯¹äºå°æ¨¡å‹æ¥è¯´ï¼Œå¦‚æœå®ƒçš„å‡†ç¡®ç‡æ˜¯éšæœºçš„ï¼Œé‚£ä¹ˆå®ƒæ˜¯æ¶Œç°çš„ï¼›ä½†å¯¹äºå¤§æ¨¡å‹æ¥è¯´ï¼Œåˆ™é«˜äºéšæœºå‡†ç¡®ç‡ã€‚è¿™æ ·è¯´æœ‰é“ç†å—ï¼ŸåŸºæœ¬ä¸Šï¼Œå¦‚æœæ¨¡å‹çš„è¡¨ç°æ²¡æœ‰æ¯”éšæœºå¥½ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±è¯´å®ƒæ²¡æœ‰èƒ½åŠ›å»æ‰§è¡Œè¿™ä¸ªç‰¹å®šçš„ä»»åŠ¡ã€‚
- en: And I'll give a few examples hereã€‚å—¯ã€‚So here's sort of the canonical way that
    we look at plots for emergenceã€‚so basically what we have each of these different
    plots is a different task and I'll go over some examples soonã€‚But the way you
    read the plot is the X axis is a number of training flops or the model scaleã€‚and
    then the Y axis is like the accuracy or like how good the model is doing the taskã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åœ¨è¿™é‡Œç»™å‡ºå‡ ä¸ªä¾‹å­ã€‚å—¯ã€‚è¿™é‡Œæ˜¯æˆ‘ä»¬çœ‹å¾…æ¶Œç°å›¾çš„å…¸å‹æ–¹å¼ã€‚åŸºæœ¬ä¸Šï¼Œæ¯ä¸ªä¸åŒçš„å›¾éƒ½æ˜¯ä¸€ä¸ªä¸åŒçš„ä»»åŠ¡ï¼Œæˆ‘å¾ˆå¿«ä¼šä¸¾å‡ ä¸ªä¾‹å­ã€‚ä½†æ˜¯ä½ é˜…è¯»å›¾è¡¨çš„æ–¹å¼æ˜¯ï¼ŒXè½´æ˜¯è®­ç»ƒçš„æµ®ç‚¹è¿ç®—æ•°é‡æˆ–æ¨¡å‹è§„æ¨¡ï¼Œè€ŒYè½´åˆ™æ˜¯å‡†ç¡®ç‡æˆ–æ¨¡å‹åœ¨æ‰§è¡Œä»»åŠ¡æ—¶çš„è¡¨ç°ã€‚
- en: And then know we have different language models from Open AI from Google and
    from Deep Mindã€‚and then each of the points is like a different language model
    it's not a language model over the course of training like each point is a different
    language modelã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬æœ‰æ¥è‡ªOpenAIã€Googleå’ŒDeepMindçš„ä¸åŒè¯­è¨€æ¨¡å‹ï¼Œæ¯ä¸ªç‚¹ä»£è¡¨ä¸€ä¸ªä¸åŒçš„è¯­è¨€æ¨¡å‹ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å˜åŒ–çš„è¯­è¨€æ¨¡å‹ã€‚
- en: And what you see is that for the very small language modelsã€‚you basically get
    performance that's close to random or not being any better than randomã€‚And then
    once you pass a certain thresholdã€‚You can see that the performance suddenly gets
    like a lot above substantially above random and this is what we call emergence
    so basically if you were to extrapolate like the lines from the small language
    modelsã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¼šçœ‹åˆ°ï¼Œå¯¹äºéå¸¸å°çš„è¯­è¨€æ¨¡å‹ï¼Œæ€§èƒ½åŸºæœ¬ä¸Šæ¥è¿‘éšæœºï¼Œæˆ–è€…è¯´å¹¶æ²¡æœ‰æ¯”éšæœºè¡¨ç°å¾—æ›´å¥½ã€‚è€Œä¸€æ—¦è¶…è¿‡æŸä¸ªé˜ˆå€¼ï¼Œä½ ä¼šå‘ç°æ€§èƒ½çªç„¶æ˜¾è‘—é«˜äºéšæœºï¼Œè¿™å°±æ˜¯æˆ‘ä»¬æ‰€ç§°çš„æ¶Œç°ã€‚å› æ­¤ï¼Œå¦‚æœä½ è¦ä»å°è¯­è¨€æ¨¡å‹æ¨æ–­è¿™äº›çº¿ã€‚
- en: you might predict that it would never know do better than random because it's
    just a flat lineã€‚but the interesting phenomenonize that when you scale up past
    a certain thresholdã€‚you actually do see this emergent phenomena where the model
    does a lot better than randomã€‚So let me go over some concrete examplesã€‚So here's
    one taskã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½ä¼šé¢„æµ‹å®ƒæ°¸è¿œä¸ä¼šæ¯”éšæœºæ›´å¥½ï¼Œå› ä¸ºå®ƒåªæ˜¯ä¸€ä¸ªå¹³å¦çš„çº¿æ¡ã€‚ä½†æœ‰è¶£çš„ç°è±¡æ˜¯ï¼Œå½“ä½ è¶…è¿‡æŸä¸ªé˜ˆå€¼æ—¶ï¼Œä½ å®é™…ä¸Šä¼šçœ‹åˆ°è¿™ç§æ¶Œç°ç°è±¡ï¼Œæ¨¡å‹çš„è¡¨ç°è¿œè¿œå¥½äºéšæœºã€‚æ‰€ä»¥è®©æˆ‘ä¸¾ä¸€äº›å…·ä½“çš„ä¾‹å­ã€‚è¿™é‡Œæ˜¯ä¸€ä¸ªä»»åŠ¡ã€‚
- en: it's basically a benchmark called multitask NLU or MLLUï¼Œ and basically what
    it isã€‚it's a bunch of test questions ranging from high school all the way to like
    professional level examsã€‚And how it works is the language model sort of givenï¼Œ
    for exampleã€‚here is a high school math exampleï¼Œ and the language model is given
    like a few examples and then for an unseen question it has to give the answerã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒåŸºæœ¬ä¸Šæ˜¯ä¸€ä¸ªç§°ä¸ºå¤šä»»åŠ¡è‡ªç„¶è¯­è¨€ç†è§£ï¼ˆmultitask NLUæˆ–MLLUï¼‰çš„åŸºå‡†ï¼ŒåŸºæœ¬ä¸Šå®ƒæ˜¯ä¸€å †æµ‹è¯•é—®é¢˜ï¼Œä»é«˜ä¸­ä¸€ç›´åˆ°ä¸“ä¸šæ°´å¹³çš„è€ƒè¯•ã€‚å®ƒçš„å·¥ä½œæ–¹å¼æ˜¯ï¼Œè¯­è¨€æ¨¡å‹è¢«ç»™å®šï¼Œä¾‹å¦‚ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªé«˜ä¸­æ•°å­¦ä¾‹é¢˜ï¼Œç„¶åå¯¹äºä¸€ä¸ªæœªè§è¿‡çš„é—®é¢˜ï¼Œå®ƒå¿…é¡»ç»™å‡ºç­”æ¡ˆã€‚
- en: And then you can see in the plot on the rightï¼Œ so for the model scaleã€‚if you
    go up to sort of 10 to the power of 22 training flopsã€‚you don't actually get any
    better than random accuracy on this taskã€‚but if you scale up to 10 to the 24 training
    flopsã€‚then you see that all the like three models there do much better than random
    accuracyã€‚Yeahã€‚perfect the scale of the data used to train thisï¼Œ is it roughly
    similar or because these are like different models trained by different wordsï¼Ÿ
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åä½ å¯ä»¥åœ¨å³ä¾§çš„å›¾è¡¨ä¸­çœ‹åˆ°ï¼Œå¯¹äºæ¨¡å‹è§„æ¨¡ï¼Œå¦‚æœä½ è¾¾åˆ°å¤§çº¦`10^22`çš„è®­ç»ƒæµ®ç‚¹è¿ç®—é‡ï¼Œä½ åœ¨è¿™ä¸ªä»»åŠ¡ä¸Šçš„å‡†ç¡®ç‡å®é™…ä¸Šå¹¶æ²¡æœ‰æ¯”éšæœºå¥½ï¼Œä½†å¦‚æœä½ æ‰©å±•åˆ°`10^24`çš„è®­ç»ƒæµ®ç‚¹è¿ç®—é‡ï¼Œé‚£ä¹ˆä½ ä¼šçœ‹åˆ°æ‰€æœ‰ä¸‰ä¸ªæ¨¡å‹çš„è¡¨ç°éƒ½è¿œè¶…éšæœºå‡†ç¡®ç‡ã€‚æ˜¯çš„ã€‚ç”¨äºè®­ç»ƒçš„æ•°æ®è§„æ¨¡å¤§è‡´ç›¸ä¼¼å—ï¼Ÿè¿˜æ˜¯å› ä¸ºè¿™äº›æ¨¡å‹æ˜¯ç”¨ä¸åŒçš„æ•°æ®è®­ç»ƒçš„ï¼Ÿ
- en: Yeahï¼Œ the scale isï¼Œ I think within an order of magnitude for these models here
    yeahã€‚Yeahã€‚and like every single doã€‚Individual tracks is the same data yes the
    data the data is fixed except for Chnchiillaã€‚Chinchiilla uses more data for larger
    modelsï¼Œ but I believe for all the other models hereã€‚the amount data is the sameã€‚Yeahï¼Œ
    here's just another example to sort ofã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œæˆ‘è®¤ä¸ºè¿™äº›æ¨¡å‹çš„è§„æ¨¡åœ¨ä¸€ä¸ªæ•°é‡çº§ä¹‹å†…ã€‚æ˜¯çš„ã€‚è€Œä¸”æ¯ä¸€ä¸ªå•ç‹¬çš„è½¨é“éƒ½æ˜¯ç›¸åŒçš„æ•°æ®ï¼Œæ˜¯çš„ï¼Œæ•°æ®æ˜¯å›ºå®šçš„ï¼Œé™¤äº†Chinchillaã€‚Chinchillaå¯¹æ›´å¤§çš„æ¨¡å‹ä½¿ç”¨äº†æ›´å¤šæ•°æ®ï¼Œä½†æˆ‘ç›¸ä¿¡è¿™é‡Œå…¶ä»–æ‰€æœ‰æ¨¡å‹çš„æ•°æ®é‡éƒ½æ˜¯ç›¸åŒçš„ã€‚æ˜¯çš„ï¼Œè¿™é‡Œåªæ˜¯å¦ä¸€ä¸ªä¾‹å­æ¥è¯´æ˜ã€‚
- en: Show it more concretely so this is a task from the big benchmark benchmark just
    as an aside the big benchmark benchmark is like 200 benchmarks and basically it's
    like a crowdsource set of benchmarks I'd recommend looking at if you're doing
    that lot of workã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å…·ä½“åœ°å±•ç¤ºä¸€ä¸‹ï¼Œè¿™æ˜¯ä¸€é¡¹æ¥è‡ªå¤§åŸºå‡†æµ‹è¯•çš„ä»»åŠ¡ï¼Œé¡ºä¾¿æä¸€ä¸‹ï¼Œå¤§åŸºå‡†æµ‹è¯•æœ‰å¤§çº¦200ä¸ªåŸºå‡†ï¼ŒåŸºæœ¬ä¸Šæ˜¯ä¸€ä¸ªä¼—åŒ…çš„åŸºå‡†é›†ï¼Œæˆ‘å»ºè®®ä½ åœ¨è¿›è¡Œå¤§é‡å·¥ä½œæ—¶æŸ¥çœ‹ä¸€ä¸‹ã€‚
- en: And basicallyï¼Œ the task is the language model has to take an English sentenceã€‚And
    then give the international phonetic alphabet transliteration or the IPA transliterationã€‚which
    is basically like how to pronounce itã€‚And for this taskã€‚the evaluation metric
    is actually blue or like an Ngram overlap metricã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºæœ¬ä¸Šï¼Œè¿™ä¸ªä»»åŠ¡æ˜¯è¯­è¨€æ¨¡å‹å¿…é¡»å¤„ç†ä¸€ä¸ªè‹±æ–‡å¥å­ã€‚ç„¶åç»™å‡ºå›½é™…éŸ³æ ‡çš„éŸ³è¯‘ï¼Œæˆ–è€…è¯´æ˜¯IPAéŸ³è¯‘ã€‚åŸºæœ¬ä¸Šå°±æ˜¯å¦‚ä½•å‘éŸ³ã€‚å¯¹äºè¿™ä¸ªä»»åŠ¡ï¼Œè¯„ä¼°æŒ‡æ ‡å®é™…ä¸Šæ˜¯è“è‰²ï¼ˆBLEUï¼‰æˆ–è€…ç±»ä¼¼äºN-gramé‡å çš„æŒ‡æ ‡ã€‚
- en: And you get a similar phenomenon where as you increase the size of the language
    modelã€‚it's flat for a while and then suddenly the improvement is above randomã€‚å—¯ã€‚å¯¹ã€‚So
    I'll talk about another interesting result I hear that that's why it's emergingã€‚so
    this was a technical report that we put out a couple of months ago and basically
    there's this really interesting prize in or it's like a one time prize inã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¼šçœ‹åˆ°ä¸€ä¸ªç±»ä¼¼çš„ç°è±¡ï¼Œå³å½“ä½ å¢åŠ è¯­è¨€æ¨¡å‹çš„è§„æ¨¡æ—¶ï¼Œèµ·åˆæ˜¯å¹³å¦çš„ï¼Œéšåçªç„¶é—´æå‡è¶…è¿‡éšæœºæ°´å¹³ã€‚å—¯ã€‚å¯¹ã€‚æ‰€ä»¥æˆ‘ä¼šè°ˆè°ˆæˆ‘å¬åˆ°çš„å¦ä¸€ä¸ªæœ‰è¶£çš„ç»“æœï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆå®ƒåœ¨å‡ºç°ã€‚è¿™æ˜¯æˆ‘ä»¬å‡ ä¸ªæœˆå‰å‘å¸ƒçš„ä¸€ä»½æŠ€æœ¯æŠ¥å‘Šï¼ŒåŸºæœ¬ä¸Šè¿™é‡Œæœ‰ä¸€ä¸ªéå¸¸æœ‰è¶£çš„å¥–é¡¹ï¼Œæˆ–è€…è¯´æ˜¯ä¸€æ¬¡æ€§å¥–é¡¹ã€‚
- en: In language models where Anthropicsï¼Œ which is like a startupã€‚basically had this
    prize where if people could come up with a task where the performance on the task
    would actually decrease as you increase the size of the language modelã€‚then you
    would get like a bunch of moneyã€‚So basically there are a lot of submissions to
    this and here's one example of like a task where they found that the performance
    would actually decrease if you increase the size of the language modelã€‚so the
    task is attribute here it's like repeat my sentences back to me and then the input
    is like all that glists is not glue and then the output is the model has to completely
    has to accurately say a glueibã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¯­è¨€æ¨¡å‹ä¸­ï¼ŒAnthropicsæ˜¯ä¸€ä¸ªåˆ›ä¸šå…¬å¸ï¼ŒåŸºæœ¬ä¸Šè®¾ç«‹äº†è¿™ä¸ªå¥–é¡¹ï¼Œå¦‚æœäººä»¬èƒ½æå‡ºä¸€ä¸ªä»»åŠ¡ï¼Œéšç€è¯­è¨€æ¨¡å‹è§„æ¨¡çš„å¢åŠ ï¼Œä»»åŠ¡çš„è¡¨ç°åè€Œä¼šä¸‹é™ï¼Œé‚£ä¹ˆä½ å°±èƒ½è·å¾—ä¸€ç¬”é’±ã€‚æ‰€ä»¥å®é™…ä¸Šæœ‰å¾ˆå¤šæäº¤ï¼Œä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹ä»»åŠ¡ï¼Œä»–ä»¬å‘ç°éšç€è¯­è¨€æ¨¡å‹è§„æ¨¡çš„å¢åŠ ï¼Œè¡¨ç°ç¡®å®ä¼šä¸‹é™ã€‚è¿™ä¸ªä»»åŠ¡æ˜¯è®©ä½ é‡å¤æˆ‘çš„å¥å­ï¼Œè¾“å…¥æ˜¯â€œæ‰€æœ‰é—ªå…‰çš„ä¸œè¥¿å¹¶ä¸æ˜¯é‡‘å­â€ï¼Œè¾“å‡ºæ˜¯æ¨¡å‹å¿…é¡»å‡†ç¡®åœ°è¯´å‡ºâ€œé‡‘å­â€ã€‚
- en: å—¯ã€‚And so what happened is for the small language modelã€‚it doesn't know the phrase
    all that gllisters is not goldã€‚so it just like copies the input and actually gets
    like 100% on thatã€‚But then for the medium size language modelï¼Œ what you would
    see is that the forms to actually decrease because the medium size language model
    knows the phrase all that gllylists is not gold and then it says goldã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: å—¯ã€‚å‘ç”Ÿçš„æƒ…å†µæ˜¯å¯¹äºå°å‹è¯­è¨€æ¨¡å‹ï¼Œå®ƒä¸çŸ¥é“çŸ­è¯­â€œæ‰€æœ‰é—ªå…‰çš„ä¸œè¥¿å¹¶ä¸æ˜¯é‡‘å­â€ã€‚æ‰€ä»¥å®ƒåªæ˜¯å¤åˆ¶è¾“å…¥ï¼Œå®é™…ä¸Šè·å¾—äº†100%çš„æ­£ç¡®ç‡ã€‚ä½†æ˜¯å¯¹äºä¸­å‹è¯­è¨€æ¨¡å‹ï¼Œä½ ä¼šçœ‹åˆ°è¡¨ç°å®é™…ä¸Šä¼šä¸‹é™ï¼Œå› ä¸ºä¸­å‹è¯­è¨€æ¨¡å‹çŸ¥é“çŸ­è¯­â€œæ‰€æœ‰é—ªå…‰çš„ä¸œè¥¿å¹¶ä¸æ˜¯é‡‘å­â€ï¼Œç„¶åå®ƒè¯´é‡‘å­ã€‚
- en: which actually is not what the task asks it to do Yeah someone ask can you give
    a physical estimate 10 to the 24 plots possibly in terms of training time or number
    ofã€‚Yeahï¼Œ so I thinkã€‚10 to the 24 flops is aroundï¼Œ so at Google we use TUs and
    one pod of TUsã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶å®è¿™å¹¶ä¸æ˜¯ä»»åŠ¡è¦æ±‚å®ƒåšçš„äº‹æƒ…ã€‚æ˜¯çš„ï¼Œæœ‰äººé—®ä½ èƒ½å¦ç»™å‡º10çš„24æ¬¡æ–¹çš„ç‰©ç†ä¼°è®¡ï¼Œå¯èƒ½æ˜¯è®­ç»ƒæ—¶é—´æˆ–æ•°é‡ã€‚æ˜¯çš„ï¼Œæˆ‘è®¤ä¸º10çš„24æ¬¡æ–¹æµ®ç‚¹è¿ç®—å¤§çº¦æ˜¯ï¼Œåœ¨è°·æ­Œæˆ‘ä»¬ä½¿ç”¨TUï¼Œä¸€ä¸ªTUçš„é›†ç¾¤ã€‚
- en: I believe is equal to like 4000 A100sã€‚And 10 to the 24 flops is like two pods
    for around six weeks or something like thatã€‚So it's a lot of compute to do the
    pre trainingã€‚è¯¶ã€‚I don't knowã€‚but do you guys remember in like chemistry class when
    you'd have like molesï¼Ÿ
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºè¿™ç›¸å½“äºå¤§çº¦4000ä¸ªA100sã€‚10çš„24æ¬¡æ–¹æµ®ç‚¹è¿ç®—å¤§çº¦éœ€è¦ä¸¤ä¸ªé›†ç¾¤è¿è¡Œå…­å‘¨å·¦å³ã€‚æ‰€ä»¥ä¸ºäº†è¿›è¡Œé¢„è®­ç»ƒéœ€è¦å¤§é‡çš„è®¡ç®—ã€‚è¯¶ã€‚æˆ‘ä¸çŸ¥é“ã€‚ä½†æ˜¯ä½ ä»¬è¿˜è®°å¾—åœ¨åŒ–å­¦è¯¾ä¸Šæœ‰è¿‡æ‘©å°”çš„æ¦‚å¿µå—ï¼Ÿ
- en: And it would be like 10 to the 23 and then you're like teacher would be likeï¼Œ
    ohã€‚don't even think about like how big this number isã€‚That's like the number of
    like floating point operations that goes into the pretrannous in these modelsã€‚Okayï¼Œ
    great anywaysï¼Œ so yeah so basically the medium size language model will actually
    do worse Oh yeah did you have another question greatã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åå¤§çº¦æ˜¯10çš„23æ¬¡æ–¹ï¼Œä½ çš„è€å¸ˆå¯èƒ½ä¼šè¯´ï¼Œå“¦ï¼Œåˆ«å»æƒ³è¿™ä¸ªæ•°å­—æœ‰å¤šå¤§ã€‚è¿™å¤§çº¦æ˜¯è¿™äº›æ¨¡å‹åœ¨é¢„è®­ç»ƒä¸­éœ€è¦çš„æµ®ç‚¹è¿ç®—çš„æ•°é‡ã€‚å¥½çš„ï¼Œå¤ªå¥½äº†ï¼Œæ‰€ä»¥åŸºæœ¬ä¸Šä¸­ç­‰å¤§å°çš„è¯­è¨€æ¨¡å‹å®é™…ä¸Šä¼šè¡¨ç°å¾—æ›´å·®ã€‚å“¦ï¼Œæ˜¯çš„ï¼Œä½ è¿˜æœ‰å…¶ä»–é—®é¢˜å—ï¼Œå¤ªå¥½äº†ã€‚
- en: ğŸ˜Šï¼ŒThis the prizeThis one is one of the the winner I think it's like a third
    place winner or somethingã€‚ã™ great questionã€‚But the taskï¼Œ because likeï¼Œ I would
    like my initial opinion would be likeï¼Œ ohã€‚you can just like put a negative slide
    on how you evaluateã€‚What do you mean it's flip a negative side all of this depends
    on which evaluationï¼ŸYeahã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šï¼Œè¿™ä¸ªå¥–é¡¹æ˜¯æˆ‘è®¤ä¸ºçš„ç¬¬ä¸‰åæˆ–ç±»ä¼¼çš„ã€‚å¾ˆå¥½çš„é—®é¢˜ã€‚ä½†è¿™ä¸ªä»»åŠ¡ï¼Œå› ä¸ºæˆ‘æœ€åˆçš„çœ‹æ³•æ˜¯ï¼Œå“¦ï¼Œä½ å¯ä»¥åœ¨è¯„ä¼°ä¸Šæ”¾ä¸€ä¸ªè´Ÿåˆ†ã€‚ä½ æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿç¿»è½¬è´Ÿé¢è¯„ä¼°ï¼Œè¿™ä¸€åˆ‡éƒ½å–å†³äºå“ªä¸ªè¯„ä¼°ï¼Ÿæ˜¯çš„ã€‚
- en: to measure if you do your task breakï¼Œ so like it's like the the the measurement
    is very sparse like you only get credit if you do itã€‚Yeahï¼Œ yeahï¼Œ like a lot of
    things emerge because like you just won't hit it perfectlyã€‚Really optimized for
    a long timeã€‚ Or like if you take a test and then like evaluate it with like a
    minus sign likeã€‚wouldn't itã€‚It wasã€‚Like something that'sã€‚Yeahï¼Œ I meanï¼Œ they they
    so for this thingã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è¡¡é‡ä½ çš„ä»»åŠ¡å®Œæˆæƒ…å†µï¼Œå°±åƒæ˜¯è¿™ä¸ªæµ‹é‡éå¸¸ç¨€ç–ï¼Œåªæœ‰åœ¨ä½ å®Œæˆæ—¶æ‰èƒ½è·å¾—ç§¯åˆ†ã€‚æ˜¯çš„ï¼Œå¾ˆå¤šäº‹æƒ…éƒ½æ˜¯å› ä¸ºä½ ä¸ä¼šå®Œç¾åœ°å®Œæˆã€‚çœŸçš„ä¼˜åŒ–äº†å¾ˆé•¿æ—¶é—´ã€‚æˆ–è€…è¯´å¦‚æœä½ å‚åŠ è€ƒè¯•ï¼Œç„¶åç”¨è´Ÿå·æ¥è¯„ä¼°é‚£æ ·çš„è¯ï¼Œä¸æ˜¯å—ï¼Ÿæ˜¯çš„ï¼Œæ²¡é”™ã€‚å°±åƒæ˜¯è¿™æ ·çš„ä¸œè¥¿ã€‚æ˜¯çš„ï¼Œæˆ‘çš„æ„æ€æ˜¯ï¼Œä»–ä»¬å¯¹äºè¿™ä¸ªäº‹æƒ…ã€‚
- en: they like account it for all likeï¼Œ you can't just say like the task should be
    to do badly on somethingã€‚it has to be like a meaningful sort of taskã€‚And then
    I guess your point about like the how credit time or the valuation metric works
    is actually a really good one yeah so I guess it still kind of counts if like
    you know I guess the argument is sort of that thatã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ä»–ä»¬è€ƒè™‘åˆ°æ‰€æœ‰çš„äº‹æƒ…ï¼Œä½ ä¸èƒ½ä»…ä»…è¯´ä»»åŠ¡åº”è¯¥åœ¨æŸäº›äº‹æƒ…ä¸Šè¡¨ç°ä¸ä½³ï¼Œä»»åŠ¡å¿…é¡»æ˜¯æœ‰æ„ä¹‰çš„ã€‚è€Œä¸”æˆ‘æƒ³ä½ å…³äºä¿¡ç”¨æ—¶é—´æˆ–è¯„ä¼°æŒ‡æ ‡å¦‚ä½•è¿ä½œçš„è§‚ç‚¹ç¡®å®å¾ˆå¥½ï¼Œæ‰€ä»¥æˆ‘æƒ³å¦‚æœä½ çŸ¥é“ï¼Œæˆ‘çŒœè¿™ä¸ªè®ºç‚¹æ˜¯è¿™æ ·çš„ã€‚
- en: The performance might not look emergent if you assign partial creditã€‚but we
    have like a bunch of I can show example laterï¼Œ but even if you use partial credit
    metricsã€‚you'll often still see the same type of emergence so it's not purely a
    phenomenon of like not assigning partial credit based on the valuation metricã€‚è¯¶ã€‚è¿‡ã€‚And
    then greatï¼Œ so what what we sort of sort of argued in this paper is that yeahã€‚
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ åˆ†é…éƒ¨åˆ†ä¿¡ç”¨ï¼Œæ€§èƒ½å¯èƒ½çœ‹èµ·æ¥å¹¶ä¸çªç°ã€‚ä½†æˆ‘ä»¬æœ‰ä¸€å †ç¤ºä¾‹å¯ä»¥ç¨åå±•ç¤ºï¼Œå³ä½¿ä½ ä½¿ç”¨éƒ¨åˆ†ä¿¡ç”¨æŒ‡æ ‡ï¼Œä½ ä»ç„¶ä¼šçœ‹åˆ°åŒç±»å‹çš„çªç°ï¼Œå› æ­¤è¿™å¹¶ä¸æ˜¯åŸºäºè¯„ä¼°æŒ‡æ ‡ä¸åˆ†é…éƒ¨åˆ†ä¿¡ç”¨çš„çº¯ç°è±¡ã€‚
- en: there might be some tasks where the performance starts to decrease if you use
    a medium sized language modelã€‚but if you keep scaling all the way to you the largest
    model that we have at Google that's known publiclyã€‚Palmï¼Œ you'll see that the language
    model I can actually go back and do the task correctly because the large language
    model also knows the phrase all that gllisted is not goldã€‚but it also understands
    repeat my senses back to me so it's able to get 100% on this task so this is a
    different type of emergence alsoã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: å¯èƒ½æœ‰ä¸€äº›ä»»åŠ¡ï¼Œå¦‚æœä½¿ç”¨ä¸­ç­‰è§„æ¨¡çš„è¯­è¨€æ¨¡å‹ï¼Œæ€§èƒ½å¼€å§‹ä¸‹é™ã€‚ä½†å¦‚æœä½ ä¸€ç›´æ‰©å±•åˆ°æˆ‘ä»¬åœ¨è°·æ­Œå…¬å¼€çš„æœ€å¤§æ¨¡å‹Palmï¼Œä½ ä¼šå‘ç°è¿™ä¸ªè¯­è¨€æ¨¡å‹å®é™…ä¸Šèƒ½å¤Ÿè¿”å›å¹¶æ­£ç¡®æ‰§è¡Œä»»åŠ¡ï¼Œå› ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹ä¹ŸçŸ¥é“â€œæ‰€æœ‰å‘å…‰çš„ä¸œè¥¿å¹¶éé‡‘å­â€ï¼Œå®ƒè¿˜ç†è§£â€œé‡å¤æˆ‘çš„æ„Ÿå®˜â€ï¼Œæ‰€ä»¥èƒ½å¤Ÿåœ¨è¿™ä¸ªä»»åŠ¡ä¸Šè·å¾—100%çš„å‡†ç¡®ç‡ï¼Œè¿™ä¹Ÿæ˜¯ä¸€ç§ä¸åŒç±»å‹çš„çªç°ã€‚
- en: And another class of emergence that we sort of talk about in the paper is like
    an emergent prompting techniqueã€‚So basicallyï¼Œ you knowï¼Œ other than futuretop promptingã€‚there's
    like other ways of like interacting with the language models thatã€‚Can be considered
    emergent yeahã€‚The question isï¼Œ did all modelss undergo construction fine tuï¼Ÿ
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è®ºæ–‡ä¸­æˆ‘ä»¬è®¨è®ºçš„å¦ä¸€ç±»çªç°æ˜¯çªç°æç¤ºæŠ€æœ¯ã€‚åŸºæœ¬ä¸Šï¼Œé™¤äº†æœªæ¥æç¤ºï¼Œè¿˜æœ‰å…¶ä»–ä¸è¯­è¨€æ¨¡å‹äº’åŠ¨çš„æ–¹å¼ï¼Œå¯ä»¥è¢«è§†ä¸ºçªç°ã€‚é—®é¢˜æ˜¯ï¼Œæ‰€æœ‰æ¨¡å‹æ˜¯å¦ç»å†äº†æ„å»ºå¾®è°ƒï¼Ÿ
- en: None of these models under one instruction fine tuning for this plotã€‚Greatï¼Œ
    yeahï¼Œ so yeahã€‚so one way of interacting with language models is by basically finding
    the model using a technique called RHFã€‚and basically the way it works is you have
    this data and humans rate like preferences for what type of outputs they preferã€‚And
    then the model strand on RL to sort of optimize for human preferencesã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ¨¡å‹åœ¨è¿™ä¸ªå›¾ä¸Šéƒ½æ²¡æœ‰è¿›è¡Œä¸€æ¬¡æŒ‡ä»¤å¾®è°ƒã€‚å¾ˆå¥½ï¼Œæ˜¯çš„ã€‚æ‰€ä»¥ï¼Œä¸è¯­è¨€æ¨¡å‹äº’åŠ¨çš„ä¸€ç§æ–¹å¼æ˜¯åŸºæœ¬ä¸Šä½¿ç”¨ä¸€ç§ç§°ä¸ºRHFçš„æŠ€æœ¯æ¥æ‰¾åˆ°æ¨¡å‹ã€‚åŸºæœ¬ä¸Šï¼Œå®ƒçš„å·¥ä½œåŸç†æ˜¯ä½ æœ‰è¿™äº›æ•°æ®ï¼Œäººä¸äººä¹‹é—´ä¼šè¯„ä¼°ä»–ä»¬åå¥½çš„è¾“å‡ºç±»å‹ã€‚ç„¶åæ¨¡å‹åœ¨å¼ºåŒ–å­¦ä¹ ä¸­è¿›è¡Œè®­ç»ƒï¼Œä»¥ä¼˜åŒ–äººç±»çš„åå¥½ã€‚
- en: And what this plot is showing here is that if you do this RHF on the modelã€‚The
    model performance on a different zero shot task actually gets worse for small
    modelsã€‚you can see the blue line is above the orange lineï¼Œ blue line is the baseline
    lineã€‚the orange line is RHSã€‚And then if you do it for large modelsï¼Œ thoughã€‚
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªå›¾å±•ç¤ºçš„æ˜¯ï¼Œå¦‚æœä½ å¯¹æ¨¡å‹è¿›è¡ŒRHå¾®è°ƒï¼Œæ¨¡å‹åœ¨å¦ä¸€ä¸ªé›¶æ ·æœ¬ä»»åŠ¡ä¸Šçš„æ€§èƒ½å®é™…ä¸Šä¼šå¯¹å°æ¨¡å‹å˜å·®ã€‚ä½ å¯ä»¥çœ‹åˆ°è“çº¿åœ¨æ©™çº¿ä¹‹ä¸Šï¼Œè“çº¿æ˜¯åŸºçº¿ï¼Œæ©™çº¿æ˜¯RHFã€‚å¦‚æœä½ å¯¹å¤§å‹æ¨¡å‹è¿›è¡ŒåŒæ ·çš„æ“ä½œã€‚
- en: then you can see that the performance actually has a positive delta from doing
    RLHIã€‚è¯¶ã€‚And so this is sort of interesting thing where like a certain technique
    might only help if you try on a large enough language modelã€‚so if you only try
    it on the small language modelsã€‚it' would be tough to draw the conclusion that
    it wouldn't help performanceã€‚And then laterã€‚
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åä½ ä¼šçœ‹åˆ°ï¼Œå®é™…ä¸Šé€šè¿‡è¿›è¡ŒRLHIï¼Œæ€§èƒ½æœ‰äº†æ­£å‘å¢é‡ã€‚è¿™æ˜¯ä¸€ä¸ªæœ‰è¶£çš„äº‹æƒ…ï¼Œå› ä¸ºæŸç§æŠ€æœ¯å¯èƒ½ä»…åœ¨ä½ å°è¯•å¤§å‹è¯­è¨€æ¨¡å‹æ—¶æ‰æœ‰æ•ˆã€‚å¦‚æœä½ åªåœ¨å°å‹è¯­è¨€æ¨¡å‹ä¸Šå°è¯•ï¼Œå¾ˆéš¾å¾—å‡ºå®ƒä¸ä¼šå¸®åŠ©æ€§èƒ½çš„ç»“è®ºã€‚ç„¶åï¼Œç¨åã€‚
- en: I'll talk about chain of without prompting as another emergent promptã€‚So here's
    sort of the hand wavy diagram that I sort of used to think about emergence as
    a framework so on the X axis here there's like a scale of the language model and
    on the Y axis is a sort of imaginary like you knowã€‚
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†è®¨è®ºæ— éœ€æç¤ºçš„é“¾ä½œä¸ºå¦ä¸€ç§çªç°æç¤ºã€‚å› æ­¤ï¼Œè¿™é‡Œæ˜¯æˆ‘ç”¨æ¥æ€è€ƒçªç°ä½œä¸ºæ¡†æ¶çš„ä¸€ä¸ªå¤§è‡´å›¾ç¤ºï¼ŒXè½´æ˜¯è¯­è¨€æ¨¡å‹çš„è§„æ¨¡ï¼ŒYè½´æ˜¯æŸç§æƒ³è±¡çš„ä¸œè¥¿ï¼Œä½ çŸ¥é“çš„ã€‚
- en: A scale of like a range of things that a language model can doã€‚And then basically
    you can pick like some random point like say 100 billion parameters in the language
    model and there will be certain abilities and okayã€‚so first you can see as you
    increase the size of the language modelã€‚the number of like tasks or things the
    language model can do increases and then you can see there are some tasks where
    like models above 100 billion parameters for example can do themã€‚
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ç³»åˆ—è¯­è¨€æ¨¡å‹å¯ä»¥åšçš„äº‹æƒ…ã€‚ç„¶ååŸºæœ¬ä¸Šä½ å¯ä»¥é€‰æ‹©æŸä¸ªéšæœºç‚¹ï¼Œæ¯”å¦‚è¯´åœ¨è¯­è¨€æ¨¡å‹ä¸­ 1000 äº¿å‚æ•°ï¼Œå°†ä¼šæœ‰æŸäº›èƒ½åŠ›ã€‚å› æ­¤ï¼Œä½ å¯ä»¥çœ‹åˆ°ï¼Œéšç€è¯­è¨€æ¨¡å‹è§„æ¨¡çš„å¢åŠ ï¼Œæ¨¡å‹å¯ä»¥å®Œæˆçš„ä»»åŠ¡æ•°é‡ä¹Ÿåœ¨å¢åŠ ï¼Œç„¶åä½ å¯ä»¥çœ‹åˆ°ï¼Œæœ‰äº›ä»»åŠ¡æ˜¯è¶…è¿‡
    1000 äº¿å‚æ•°çš„æ¨¡å‹å¯ä»¥åšåˆ°çš„ã€‚
- en: but models below 100 billion parameters can't do them and we call these emergent
    abilitiesã€‚Sorryã€‚question Where the colorsã€‚Ohï¼Œ it's just highlighting like the
    dark blue is likeã€‚Tasks that a smaller language model wouldn't be able to doã€‚Does
    that make senseã€‚ Yeahã€‚and then to the rightï¼Œ the dotted lineï¼Œ the right region
    up topã€‚Ohã€‚
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†ä½äº 1000 äº¿å‚æ•°çš„æ¨¡å‹æ— æ³•åšåˆ°è¿™äº›ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºæ¶Œç°èƒ½åŠ›ã€‚æŠ±æ­‰ã€‚é—®é¢˜æ˜¯é¢œè‰²åœ¨å“ªé‡Œã€‚å“¦ï¼Œå®ƒåªæ˜¯çªå‡ºæ˜¾ç¤ºï¼Œæ¯”å¦‚æ·±è“è‰²æ˜¯åƒå°å‹è¯­è¨€æ¨¡å‹æ— æ³•å®Œæˆçš„ä»»åŠ¡ã€‚è¿™æ ·è¯´æœ‰é“ç†å—ï¼Ÿæ˜¯çš„ã€‚ç„¶åå³ä¾§ï¼Œè™šçº¿ï¼Œä¸Šæ–¹çš„åŒºåŸŸã€‚å“¦ã€‚
- en: that just means like tasks that we haven't been able to solve yet with models
    yetã€‚ä¸ªã€‚And I'm curious to knowï¼Œ do you think that it's not that those tasks in
    the white region are unsolvable at like $100 billion scaleï¼Ÿ
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä»…æ„å‘³ç€æˆ‘ä»¬å°šæœªèƒ½å¤Ÿè§£å†³çš„ä»»åŠ¡ã€‚è€Œæˆ‘å¾ˆå¥½å¥‡ï¼Œä½ è®¤ä¸ºåœ¨ 1000 äº¿è§„æ¨¡ä¸‹ï¼Œé‚£äº›ç™½è‰²åŒºåŸŸçš„ä»»åŠ¡æ˜¯ä¸å¯è§£å†³çš„å—ï¼Ÿ
- en: Or do you think that better modelsã€‚Specific training data would allow us to
    the 100 billion scale to get into thatã€‚Yeahï¼Œ I definitely think that it's not
    a fixedï¼Œ I'll give an example shortly but it's not it's notã€‚You know it's not
    a rule that you have to have 100 blend parameters to do a certain taskã€‚it's just
    that that happens to be the threshold that we've observed in models so far and
    I do think with better training data and architecture and algorithms we can probably
    beat thatã€‚
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ è®¤ä¸ºæ›´å¥½çš„æ¨¡å‹ã€‚ç‰¹å®šçš„è®­ç»ƒæ•°æ®ä¼šè®©æˆ‘ä»¬è¾¾åˆ° 1000 äº¿è§„æ¨¡å—ï¼Ÿæ˜¯çš„ï¼Œæˆ‘ç»å¯¹è®¤ä¸ºè¿™ä¸æ˜¯å›ºå®šçš„ï¼Œæˆ‘ä¼šå¾ˆå¿«ç»™ä¸€ä¸ªä¾‹å­ï¼Œä½†è¿™ä¸æ˜¯è§„åˆ™ã€‚ä½ çŸ¥é“ï¼Œä¸æ˜¯è¯´ä½ å¿…é¡»æ‹¥æœ‰
    1000 äº¿å‚æ•°æ‰èƒ½å®ŒæˆæŸé¡¹ä»»åŠ¡ã€‚è¿™åªæ˜¯æˆ‘ä»¬è§‚å¯Ÿåˆ°çš„æ¨¡å‹é˜ˆå€¼ï¼Œè€Œæˆ‘ç¡®å®è®¤ä¸ºï¼Œé€šè¿‡æ›´å¥½çš„è®­ç»ƒæ•°æ®ã€æ¶æ„å’Œç®—æ³•ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šè¶…è¶Šè¿™ä¸ªé˜ˆå€¼ã€‚
- en: è¿‡å—¯ã€‚Yeahï¼Œ so as Rland just mentionedï¼Œ one example of Getty emergence can be with
    better dataã€‚so it's not all about scale I'll sort of give some nuance hereã€‚so
    for this task is just one of the tasks in the Big Ben benchmarkã€‚you can see that
    for like Lambda which is a Google model and GPT3ã€‚
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å—¯ã€‚æ˜¯çš„ï¼Œæ­£å¦‚ Rland åˆšåˆšæåˆ°çš„ï¼Œæ¶Œç°çš„ä¸€ä¸ªä¾‹å­å¯ä»¥æ˜¯æ›´å¥½çš„æ•°æ®ã€‚æ‰€ä»¥å¹¶ä¸æ˜¯æ‰€æœ‰éƒ½æ˜¯è§„æ¨¡ï¼Œæˆ‘ä¼šç¨å¾®ç»™ç‚¹ç»†å¾®å·®åˆ«ã€‚å¯¹äºè¿™ä¸ªä»»åŠ¡æ¥è¯´ï¼Œå®ƒåªæ˜¯ Big
    Ben åŸºå‡†ä¸­çš„ä¸€ä¸ªä»»åŠ¡ã€‚ä½ å¯ä»¥çœ‹åˆ°ï¼Œåƒ Lambda è¿™æ ·çš„è°·æ­Œæ¨¡å‹å’Œ GPT3ã€‚
- en: you actually don't get emergence from scaling to 137 or  137 or 175 billion
    parametersã€‚But when you come in with a different language model palmã€‚which is
    trained on better data than Lambda and GT3ã€‚you actually can get this emerge ability
    even with the smaller language model shown here at 62 billion parametersã€‚
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å®é™…ä¸Šä¸ä¼šä»æ‰©å±•åˆ° 137 æˆ– 175 äº¿å‚æ•°ä¸­è·å¾—æ¶Œç°ã€‚ä½†å½“ä½ ä½¿ç”¨ä¸åŒçš„è¯­è¨€æ¨¡å‹ Palm æ—¶ï¼Œå®ƒåœ¨æ¯” Lambda å’Œ GT3 æ›´å¥½çš„æ•°æ®ä¸Šè®­ç»ƒï¼Œä½ å®é™…ä¸Šå¯ä»¥è·å¾—è¿™ç§æ¶Œç°èƒ½åŠ›ï¼Œå³ä½¿æ˜¯è¿™é‡Œæ˜¾ç¤ºçš„
    62 äº¿å‚æ•°çš„å°å‹è¯­è¨€æ¨¡å‹ã€‚
- en: See inventory better model as better dataï¼Œ or also betterã€‚Ttro maskingï¼Œ you
    knowã€‚choices or most interestingã€‚Yeahï¼Œ so the challenging thing is that's a great
    questionã€‚There's like a lot of differences between Palm and Lambdaï¼Œ for exampleã€‚and
    we can't really abllate them in any controlled way because of the cost of pretrainingã€‚
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: å°†åº“å­˜æ›´å¥½çš„æ¨¡å‹è§†ä¸ºæ›´å¥½çš„æ•°æ®ï¼Œæˆ–è€…æ›´å¥½ã€‚Ttro æ©è”½ï¼Œä½ çŸ¥é“çš„ã€‚é€‰æ‹©æˆ–æœ€æœ‰è¶£çš„ã€‚æ˜¯çš„ï¼ŒæŒ‘æˆ˜åœ¨äºè¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é—®é¢˜ã€‚æ¯”å¦‚ï¼ŒPalm å’Œ Lambda
    ä¹‹é—´æœ‰å¾ˆå¤šå·®å¼‚ã€‚æˆ‘ä»¬æ— æ³•ä»¥ä»»ä½•å—æ§æ–¹å¼æ¶ˆé™¤å®ƒä»¬ï¼Œå› ä¸ºé¢„è®­ç»ƒçš„æˆæœ¬ã€‚
- en: but our like sort of running hypothesis is that P is trained on better data
    and that accounts for a lot of the difference between Palm and Lambda like the
    smaller it is possible to stuff Yeahã€‚è¿™ä¸ªã€‚Yeahï¼Œ that's a good questionï¼Œ so I guess
    even here you can look at like for exampleã€‚
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘ä»¬çš„å‡è®¾æ˜¯ï¼ŒP åœ¨æ›´å¥½çš„æ•°æ®ä¸Šè®­ç»ƒï¼Œè¿™è§£é‡Šäº† Palm å’Œ Lambda ä¹‹é—´çš„è®¸å¤šå·®å¼‚ã€‚åƒæ˜¯æ›´å°çš„æ¨¡å‹ä¹Ÿæœ‰å¯èƒ½ã€‚æ˜¯çš„ï¼Œè¿™ä¸ªã€‚æ˜¯çš„ï¼Œè¿™æ˜¯ä¸ªå¥½é—®é¢˜ï¼Œæ‰€ä»¥æˆ‘æƒ³å³ä½¿åœ¨è¿™é‡Œï¼Œä½ ä¹Ÿå¯ä»¥çœ‹çœ‹ï¼Œæ¯”å¦‚è¯´ã€‚
- en: the Palm 8 billion modelã€‚Like thatã€‚That point thereã€‚you can abllate it and it's
    like a little bit higherã€‚but it's not really an emergent yet at that pointã€‚so
    it's it's hard to tell for you know for exampleï¼Œ this particular task what the
    effect isã€‚Yeahã€‚
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Palm 80 äº¿æ¨¡å‹ã€‚åƒæ˜¯é‚£ä¸ªç‚¹ã€‚ä½ å¯ä»¥æ¶ˆèå®ƒï¼Œç¨å¾®é«˜ä¸€ç‚¹ï¼Œä½†åœ¨é‚£ä¸ªç‚¹ä¸Šè¿˜ä¸æ˜¯æ¶Œç°ã€‚æ‰€ä»¥ï¼Œå¯¹äºè¿™ç‰¹å®šä»»åŠ¡æ¥è¯´ï¼Œæ•ˆæœå¾ˆéš¾åˆ¤æ–­ã€‚æ˜¯çš„ã€‚
- en: there's a question on Zoomï¼Œ are there two different versions of Paulï¼Œ if notã€‚why
    are there two lines moreï¼ŸOh so I think the two lines hereã€‚one is like maybe three
    shot and then one is like zero shot something like thatã€‚so it just refers to the
    way that we're using the language model either with the without exemplarsã€‚
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Zoomä¸Šæœ‰ä¸ªé—®é¢˜ï¼ŒPaulæ˜¯å¦æœ‰ä¸¤ä¸ªä¸åŒçš„ç‰ˆæœ¬ï¼Œå¦‚æœæ²¡æœ‰ï¼Œä¸ºä»€ä¹ˆæœ‰ä¸¤æ¡çº¿ï¼Ÿå“¦ï¼Œæ‰€ä»¥æˆ‘è®¤ä¸ºè¿™ä¸¤æ¡çº¿ï¼Œä¸€ä¸ªå¯èƒ½æ˜¯ä¸‰æ¬¡ç¤ºä¾‹ï¼Œå¦ä¸€ä¸ªå¯èƒ½æ˜¯é›¶æ¬¡ç¤ºä¾‹ä¹‹ç±»çš„ã€‚å› æ­¤å®ƒåªæ˜¯æŒ‡æˆ‘ä»¬åœ¨ä½¿ç”¨è¯­è¨€æ¨¡å‹æ—¶æ˜¯å¦æœ‰ç¤ºä¾‹ã€‚
- en: å—¯ã€‚Greatã€‚I'll talk about a yeahï¼Œ small ablation here that sort of shows thisã€‚so
    this is an ablation on sort of a toy task where basically the language model has
    to know that like in Englishã€‚you have to use plural verbs with plural subjects
    and singular verbs with singular subjectsã€‚And the way that what we're doing here
    is basically we train like these small BRT models from scratch and then we held
    out like we fixed the frequency of certain verbs in the training data setã€‚
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: å—¯ï¼Œå¤ªå¥½äº†ã€‚æˆ‘ä¼šè°ˆè®ºä¸€ä¸ªå°çš„æ¶ˆèå®éªŒï¼ŒåŸºæœ¬ä¸Šå±•ç¤ºäº†è¿™ä¸€ç‚¹ã€‚è¿™æ˜¯ä¸€ä¸ªç©å…·ä»»åŠ¡çš„æ¶ˆèå®éªŒï¼Œè¯­è¨€æ¨¡å‹éœ€è¦çŸ¥é“åœ¨è‹±è¯­ä¸­ï¼Œå¤æ•°ä¸»è¯­è¦ç”¨å¤æ•°åŠ¨è¯ï¼Œå•æ•°ä¸»è¯­è¦ç”¨å•æ•°åŠ¨è¯ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œåšçš„å°±æ˜¯ä»å¤´å¼€å§‹è®­ç»ƒè¿™äº›å°çš„BRTæ¨¡å‹ï¼Œç„¶åæˆ‘ä»¬å›ºå®šäº†ä¸€äº›åŠ¨è¯åœ¨è®­ç»ƒæ•°æ®é›†ä¸­çš„é¢‘ç‡ã€‚
- en: which basically says likeï¼Œ okayï¼Œ what's the effect of seeing a certain verb
    in the data more oftenï¼Ÿ
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºæœ¬ä¸Šæ˜¯åœ¨è¯´ï¼Œå¥½çš„ï¼Œçœ‹åˆ°æŸä¸ªåŠ¨è¯åœ¨æ•°æ®ä¸­æ›´é¢‘ç¹çš„æ•ˆæœæ˜¯ä»€ä¹ˆï¼Ÿ
- en: In this plot the x axis is like the frequency of the verb and the y axis is
    the error rate and what you basically see is that if you have more in domain data
    so if the model sees the verb more times it does the task a lot better and this
    is sort of an example of like having high quality data or data that's more in
    domain for the task that you're evaluating on can make a big differenceã€‚
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªå›¾ä¸­ï¼Œxè½´ç±»ä¼¼äºåŠ¨è¯çš„é¢‘ç‡ï¼Œyè½´æ˜¯é”™è¯¯ç‡ï¼Œä½ åŸºæœ¬ä¸Šçœ‹åˆ°çš„æ˜¯ï¼Œå¦‚æœä½ æœ‰æ›´å¤šçš„é¢†åŸŸå†…æ•°æ®ï¼Œä¹Ÿå°±æ˜¯è¯´å¦‚æœæ¨¡å‹çœ‹åˆ°åŠ¨è¯çš„æ¬¡æ•°æ›´å¤šï¼Œå®ƒæ‰§è¡Œä»»åŠ¡çš„æ•ˆæœä¼šå¥½å¾—å¤šï¼Œè¿™å®é™…ä¸Šæ˜¯é«˜è´¨é‡æ•°æ®æˆ–ä¸è¯„ä¼°ä»»åŠ¡æ›´ç›¸å…³çš„æ•°æ®å¯ä»¥äº§ç”Ÿå·¨å¤§å·®å¼‚çš„ä¸€ä¸ªä¾‹å­ã€‚
- en: even if you're fixing the compute the size of the model and the rest of the
    dataã€‚Yeah question on Zoomã€‚Someone asksï¼Œ could there be a way to dispillel emerget
    abilities down to smaller models for larger teacherã€‚Yeahï¼Œ I think so soã€‚Larger
    teacher models can basically you can use them for exampleã€‚to generate data and
    then if you finet larger the smaller model on dataã€‚
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: å³ä½¿ä½ å›ºå®šäº†è®¡ç®—ã€æ¨¡å‹å¤§å°å’Œå…¶ä»–æ•°æ®ã€‚æ˜¯çš„ï¼ŒZoomä¸Šæœ‰äººé—®ï¼Œæ˜¯å¦æœ‰åŠæ³•å°†æ–°å‡ºç°çš„èƒ½åŠ›ç¼©å°åˆ°æ›´å°çš„æ¨¡å‹ä»¥ä¾›æ›´å¤§çš„æ•™å¸ˆä½¿ç”¨ã€‚æ˜¯çš„ï¼Œæˆ‘æƒ³å¯ä»¥ã€‚å› æ­¤ï¼Œæ›´å¤§çš„æ•™å¸ˆæ¨¡å‹åŸºæœ¬ä¸Šå¯ä»¥ç”¨æ¥ç”Ÿæˆæ•°æ®ï¼Œç„¶åå¦‚æœä½ åœ¨æ•°æ®ä¸Šå¯¹æ›´å°çš„æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚
- en: it's pretty likely that you'll be able to get the ability to emerge in the smaller
    model I'll talk about example of this too let me seeã€‚Ohï¼Œ actuallyï¼Œ next slideã€‚Desired
    behaviors can be induced in smaller models once you sort of know what behavior
    you wantã€‚
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆå¯èƒ½ä½ èƒ½å¤Ÿåœ¨æ›´å°çš„æ¨¡å‹ä¸­è·å¾—å‡ºç°çš„èƒ½åŠ›ï¼Œæˆ‘ä¹Ÿä¼šè°ˆè®ºè¿™ä¸ªä¾‹å­çš„ï¼Œç­‰æˆ‘çœ‹çœ‹ã€‚å“¦ï¼Œå®é™…ä¸Šï¼Œä¸‹ä¸€å¼ å¹»ç¯ç‰‡ã€‚ä¸€æ—¦ä½ çŸ¥é“æƒ³è¦ä»€ä¹ˆè¡Œä¸ºï¼Œå°±å¯ä»¥åœ¨æ›´å°çš„æ¨¡å‹ä¸­è¯±å¯¼å‡ºæœŸæœ›çš„è¡Œä¸ºã€‚
- en: so for exampleï¼Œ here's the instructorstruct here's a figure from thestructGPT
    paperã€‚And basicallyã€‚the desired behavior here is like instruction followingã€‚And
    you can see that there's multiple modelsï¼Œ so on the left you have these small
    models that are trained with RLHF and they actually have better performance than
    larger models train on weaker techniques so basically the point is like if you
    know that you want a certain behavior that sort of you saw previously emerge in
    an emergent way in a larger model you can find a way to fine tune on that behavior
    specifically and induce that behavior in a smaller modelã€‚
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œè¿™é‡Œæ˜¯æ¥è‡ªthestructGPTè®ºæ–‡çš„æ’å›¾ã€‚åŸºæœ¬ä¸Šï¼Œè¿™é‡ŒæœŸæœ›çš„è¡Œä¸ºæ˜¯éµå¾ªæŒ‡ä»¤ã€‚ä½ å¯ä»¥çœ‹åˆ°æœ‰å¤šä¸ªæ¨¡å‹ï¼Œå·¦ä¾§æ˜¯è¿™äº›ä½¿ç”¨RLHFè®­ç»ƒçš„å°æ¨¡å‹ï¼Œå®ƒä»¬çš„è¡¨ç°å®é™…ä¸Šæ¯”ä½¿ç”¨è¾ƒå¼±æŠ€æœ¯è®­ç»ƒçš„å¤§æ¨¡å‹è¦å¥½ã€‚å› æ­¤ï¼Œé‡ç‚¹æ˜¯ï¼Œå¦‚æœä½ çŸ¥é“ä½ æƒ³è¦æŸç§è¡Œä¸ºï¼Œè¿™ç§è¡Œä¸ºæ›¾åœ¨æ›´å¤§çš„æ¨¡å‹ä¸­ä»¥æ¶Œç°çš„æ–¹å¼å‡ºç°ï¼Œä½ å¯ä»¥æ‰¾åˆ°ä¸€ç§ä¸“é—¨å¾®è°ƒè¯¥è¡Œä¸ºå¹¶åœ¨æ›´å°çš„æ¨¡å‹ä¸­è¯±å¯¼è¯¥è¡Œä¸ºçš„æ–¹æ³•ã€‚
- en: I guess one of the limitations is that like unless you know like all the behaviors
    that you wantã€‚you can't really get this natural emerge behaviorã€‚Yeahã€‚another sort
    of discussion point here is that likeã€‚There's this question of like what's the
    right X axis for emergence so like right now we mostly talk about like model parameters
    and training flops but like I guess you could like if you ask Deepmind people
    like how they look at itã€‚
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æƒ³å…¶ä¸­ä¸€ä¸ªå±€é™æ€§æ˜¯ï¼Œé™¤éä½ çŸ¥é“ä½ æƒ³è¦çš„æ‰€æœ‰è¡Œä¸ºï¼Œå¦åˆ™ä½ çœŸçš„æ— æ³•è·å¾—è¿™ç§è‡ªç„¶å‡ºç°çš„è¡Œä¸ºã€‚æ˜¯çš„ï¼Œå¦ä¸€ä¸ªè®¨è®ºç‚¹æ˜¯ï¼Œå…³äºâ€œä»€ä¹ˆæ˜¯å‡ºç°çš„æ­£ç¡®xè½´â€çš„é—®é¢˜ï¼Œæ‰€ä»¥ç°åœ¨æˆ‘ä»¬ä¸»è¦è®¨è®ºæ¨¡å‹å‚æ•°å’Œè®­ç»ƒçš„æµ®ç‚¹æ•°ï¼Œä½†æˆ‘æƒ³å¦‚æœä½ é—®Deepmindçš„äººï¼Œä»–ä»¬ä¼šå¦‚ä½•çœ‹å¾…è¿™ä¸ªé—®é¢˜ã€‚
- en: you'll sort of get this argument that model parameters and training flops are
    really just a proxy for like how good the model is and how good the model is can
    really be measured by like perplexity or like how well it's doing some on some
    dev sets such as WikiTex 103ã€‚
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å°†ä¼šå¾—åˆ°è¿™æ ·ä¸€ç§è®ºç‚¹ï¼Œæ¨¡å‹å‚æ•°å’Œè®­ç»ƒè®¡ç®—é‡å®é™…ä¸Šåªæ˜¯è¡¡é‡æ¨¡å‹è´¨é‡çš„ä¸€ä¸ªä»£ç†ï¼Œæ¨¡å‹çš„å¥½åå¯ä»¥é€šè¿‡å›°æƒ‘åº¦æˆ–å®ƒåœ¨æŸäº›å¼€å‘é›†ä¸Šçš„è¡¨ç°æ¥çœŸæ­£è¡¡é‡ï¼Œæ¯”å¦‚WikiTex
    103ã€‚
- en: So basicallyï¼Œ you can also measureã€‚Emergnce in terms of perplexity so here is
    WikiTex perplexity and then you can see like on a downstream task that as the
    perplexity gets betterã€‚there's sort of this threshold where you're able to do
    a lot better on a downstream taskã€‚
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥åŸºæœ¬ä¸Šï¼Œä½ ä¹Ÿå¯ä»¥é€šè¿‡å›°æƒ‘åº¦æ¥è¡¡é‡ã€‚è¿™é‡Œæ˜¯WikiTexå›°æƒ‘åº¦ï¼Œç„¶åä½ å¯ä»¥çœ‹åˆ°åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­ï¼Œéšç€å›°æƒ‘åº¦çš„æ”¹å–„ï¼Œå­˜åœ¨ä¸€ä¸ªé˜ˆå€¼ï¼Œä½¿ä½ èƒ½å¤Ÿåœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸Šè¡¨ç°å¾—æ›´å¥½ã€‚
- en: And there's sort of the strong correlation right at least right now between
    perplexity and training compute so you can see like these two lines are are pretty
    similar andã€‚Basicallyï¼Œ I think in the futureï¼Œ if we have much better models that
    are a lot smaller trying on much better data and better algorithmsã€‚
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: è‡³å°‘ç›®å‰ï¼Œå›°æƒ‘åº¦å’Œè®­ç»ƒè®¡ç®—ä¹‹é—´æœ‰å¾ˆå¼ºçš„ç›¸å…³æ€§ï¼Œæ‰€ä»¥ä½ å¯ä»¥çœ‹åˆ°è¿™ä¸¤æ¡çº¿æ˜¯éå¸¸ç›¸ä¼¼çš„ã€‚åŸºæœ¬ä¸Šï¼Œæˆ‘è®¤ä¸ºåœ¨æœªæ¥ï¼Œå¦‚æœæˆ‘ä»¬æœ‰æ›´å¥½è€Œä¸”æ›´å°çš„æ¨¡å‹ï¼Œè®­ç»ƒåœ¨æ›´å¥½çš„æ•°æ®å’Œæ›´å¥½çš„ç®—æ³•ä¸Šã€‚
- en: then maybe WikiText complexity can show a different type of plot than using
    other metricsã€‚So wki textex is basically aï¼Œ I think it's like a subset of Wikipediaã€‚And
    then perplexity is like a measure of how well you can predict the next word in
    a data setã€‚So basicallyï¼Œ if you're really good at modeling the next word on this
    like particular evaluation setã€‚
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ–è®¸WikiTextçš„å¤æ‚æ€§å¯ä»¥å±•ç¤ºå‡ºä¸ä½¿ç”¨å…¶ä»–æŒ‡æ ‡ä¸åŒçš„å›¾è¡¨ã€‚æ‰€ä»¥WikiTexåŸºæœ¬ä¸Šæ˜¯æˆ‘è®¤ä¸ºæ˜¯ç»´åŸºç™¾ç§‘çš„ä¸€ä¸ªå­é›†ã€‚è€Œå›°æƒ‘åº¦æ˜¯è¡¡é‡ä½ åœ¨æ•°æ®é›†ä¸­é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯çš„èƒ½åŠ›ã€‚å› æ­¤ï¼Œå¦‚æœä½ åœ¨è¿™ä¸ªç‰¹å®šè¯„ä¼°é›†ä¸Šéå¸¸æ“…é•¿å»ºæ¨¡ä¸‹ä¸€ä¸ªå•è¯ã€‚
- en: that's sort of a measure of like how well you understand languageã€‚Make senseã€‚But
    wouldn' it just harassã€‚Ohï¼Œ this is like a held out test setã€‚å¯¹ã€‚å¥½ã€‚å—¯ã€‚And then a final
    thing that I think is like pretty exciting about emergenceã€‚Is that there's sort
    of not just like technical emergence that we've talked aboutã€‚
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åœ¨æŸç§ç¨‹åº¦ä¸Šæ˜¯è¡¡é‡ä½ ç†è§£è¯­è¨€çš„èƒ½åŠ›ã€‚æ˜ç™½äº†å—ï¼Ÿä½†æ˜¯è¿™æ ·ä¸æ˜¯æœ‰ç‚¹å¼ºè¿«å—ï¼Ÿå“¦ï¼Œè¿™æ˜¯ä¸€ä¸ªä¿ç•™çš„æµ‹è¯•é›†ã€‚å¯¹ã€‚å¥½ã€‚å—¯ã€‚æœ€åï¼Œæˆ‘è®¤ä¸ºå…³äºå‡ºç°çš„äº‹æƒ…æ˜¯éå¸¸ä»¤äººå…´å¥‹çš„ï¼Œä¸ä»…ä»…æ˜¯æˆ‘ä»¬æ‰€è°ˆè®ºçš„æŠ€æœ¯æ€§å‡ºç°ã€‚
- en: but there's sort of sociological changes in how the AI community views like
    scaling and how to use language modelsã€‚So here's some examples ofã€‚Where scaling
    up the size of the language model enables you to in the sort of few shots scenarioã€‚beat
    a task specific fine tune language model that's usually fine tune on say thousands
    of examplesã€‚So basically the green line is the prior state of the art achieved
    by fine tuning and if you just and then the blue dots basically show if you take
    a pre-trained language model and you do fu shot promptingã€‚
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯ï¼ŒAIç¤¾åŒºåœ¨çœ‹å¾…è§„æ¨¡å’Œå¦‚ä½•ä½¿ç”¨è¯­è¨€æ¨¡å‹æ–¹é¢ï¼Œç¤¾ä¼šå­¦ä¸Šå‘ç”Ÿäº†ä¸€äº›å˜åŒ–ã€‚è¿™æ˜¯ä¸€äº›ç¤ºä¾‹ï¼Œè¯´æ˜åœ¨å°‘é‡æ ·æœ¬åœºæ™¯ä¸­ï¼Œæ‰©å¤§è¯­è¨€æ¨¡å‹çš„è§„æ¨¡ä½¿ä½ èƒ½å¤Ÿè¶…è¶Šä¸€ä¸ªé€šå¸¸åœ¨æ•°åƒä¸ªç¤ºä¾‹ä¸Šè¿›è¡Œå¾®è°ƒçš„ä»»åŠ¡ç‰¹å®šå¾®è°ƒè¯­è¨€æ¨¡å‹ã€‚å› æ­¤ï¼Œç»¿è‰²çº¿æ˜¯é€šè¿‡å¾®è°ƒå®ç°çš„å‰çŠ¶æ€ï¼Œè€Œè“ç‚¹åŸºæœ¬ä¸Šæ˜¾ç¤ºçš„æ˜¯å¦‚æœä½ ä½¿ç”¨é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹è¿›è¡Œå°‘é‡æç¤ºã€‚
- en: which means the language model isn't intentionally trained to do the taskã€‚you
    can often get stay of the art results just by continuing to scale up the size
    of the language modelã€‚And obviously there's limitations here you don't want to
    just keep scaling up in order to get save of the artã€‚but I think it's a pretty
    big change in people's minds that you could actually get some of the best results
    just by scaling up the size and language model and doing promptã€‚
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ„å‘³ç€è¯­è¨€æ¨¡å‹å¹¶ä¸æ˜¯ä¸“é—¨è®­ç»ƒæ¥å®Œæˆè¿™ä¸ªä»»åŠ¡çš„ã€‚ä½ å¾€å¾€åªéœ€ç»§ç»­æ‰©å¤§è¯­è¨€æ¨¡å‹çš„è§„æ¨¡ï¼Œå°±å¯ä»¥è·å¾—æœ€å…ˆè¿›çš„ç»“æœã€‚æ˜¾ç„¶ï¼Œè¿™é‡Œæœ‰å±€é™æ€§ï¼Œä½ ä¸æƒ³åªé€šè¿‡æ‰©å¤§è§„æ¨¡æ¥è·å¾—æœ€å…ˆè¿›çš„ç»“æœã€‚ä½†æˆ‘è®¤ä¸ºäººä»¬çš„æ€ç»´æ–¹å¼å‘ç”Ÿäº†å¾ˆå¤§å˜åŒ–ï¼Œä½ å®é™…ä¸Šå¯ä»¥é€šè¿‡æ‰©å¤§è¯­è¨€æ¨¡å‹çš„è§„æ¨¡å’Œè¿›è¡Œæç¤ºè·å¾—ä¸€äº›æœ€ä½³ç»“æœã€‚
- en: Question from Zoomã€‚someone askï¼Œ is that not a contradiction graph from two to
    three slides agoã€‚What is thatã€‚Which oneï¼Œ this oneï¼ŸI'm sure shouldn't be in general
    assume he said yesã€‚okã€‚We saidã€‚should we in general assume that scale tru's lie
    toã€‚Yeah so that's a great question so this plot is saying that you fine tune and
    you can do and okay yeah so it depends on your like particularã€‚
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Zoomä¸Šçš„é—®é¢˜ã€‚æœ‰äººé—®ï¼Œè¿™ä¸æ˜¯ä»ä¸¤åˆ°ä¸‰å¼ å¹»ç¯ç‰‡å‰çš„çŸ›ç›¾å›¾å—ï¼Ÿé‚£æ˜¯ä»€ä¹ˆï¼Ÿå“ªä¸ªï¼Œè¿™ä¸ªå—ï¼Ÿæˆ‘ç¡®å®šä¸€èˆ¬ä¸åº”è¯¥å‡è®¾ä»–è¯´çš„æ˜¯â€œæ˜¯â€ã€‚å¥½çš„ï¼Œæˆ‘ä»¬è¯´ã€‚æˆ‘ä»¬æ˜¯å¦ä¸€èˆ¬å‡è®¾è§„æ¨¡çœŸçš„ä¼šè¯´è°ï¼Ÿæ˜¯çš„ï¼Œè¿™æ˜¯ä¸ªå¾ˆå¥½çš„é—®é¢˜ï¼Œæ‰€ä»¥è¿™ä¸ªå›¾è¡¨è¡¨æ˜ä½ å¯ä»¥å¾®è°ƒï¼Œå¹¶ä¸”å¯ä»¥ï¼Œè¿™å–å†³äºä½ çš„å…·ä½“æƒ…å†µã€‚
- en: Taskï¼Œ but what this plot is saying is thatã€‚Likeã€‚We're not like fine tuned smaller
    models can do well on some tasks if you target it wellã€‚but for like tests that
    are more complicatedï¼Œ often you can do better just by scaling so there's sort
    ofã€‚Tasks that fall into both of these categoriesï¼Œ and I wouldn't say thatã€‚It's
    contradictoryã€‚I guess some tasksã€‚You would do a lot better just by scaling the
    sizeizing the model and then other tasksã€‚
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ä»»åŠ¡ï¼Œä½†è¿™ä¸ªå›¾è¡¨æ‰€è¯´çš„æ˜¯ã€‚å°±åƒã€‚æˆ‘ä»¬å¹¶ä¸æ˜¯è¯´ç²¾ç»†è°ƒä¼˜çš„å°æ¨¡å‹åœ¨æŸäº›ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œå¦‚æœä½ é’ˆå¯¹å¾—å½“ã€‚ä½†å¯¹äºé‚£äº›æ›´å¤æ‚çš„æµ‹è¯•ï¼Œé€šå¸¸é€šè¿‡æ‰©å±•è§„æ¨¡ä½ èƒ½è·å¾—æ›´å¥½çš„ç»“æœï¼Œå› æ­¤è¿™äº›ä»»åŠ¡å¯ä»¥å½’å…¥è¿™ä¸¤ä¸ªç±»åˆ«ï¼Œæˆ‘å¹¶ä¸è®¤ä¸ºè¿™æ˜¯çŸ›ç›¾çš„ã€‚æˆ‘æƒ³æŸäº›ä»»åŠ¡ï¼Œç¡®å®å¯ä»¥é€šè¿‡æ‰©å¤§æ¨¡å‹çš„è§„æ¨¡è·å¾—æ›´å¥½çš„ç»“æœï¼Œè€Œå…¶ä»–ä»»åŠ¡ã€‚
- en: if it's like a very narrow domain or the large language model might not be trained
    on that kind of dataã€‚then you would do better by fineã€‚Oï¼Œå¯¹ã€‚So here's sort of a
    little summary slideã€‚so basically emergent abilities can only be observed in large
    models and if you try to predict their emergence just by looking at the plots
    for small models then you wouldn't be able to do itã€‚And I sort of had a little
    reflection on how to look at thisã€‚
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœè¿™æ˜¯ä¸€ä¸ªéå¸¸ç‹­çª„çš„é¢†åŸŸï¼Œè€Œå¤§å‹è¯­è¨€æ¨¡å‹å¯èƒ½æ²¡æœ‰åœ¨é‚£ç§æ•°æ®ä¸Šè®­ç»ƒï¼Œé‚£ä¹ˆé€šè¿‡ç²¾ç»†è°ƒæ•´ä½ ä¼šè·å¾—æ›´å¥½çš„ç»“æœã€‚å¯¹ã€‚æ‰€ä»¥è¿™é‡Œæœ‰ä¸€ä¸ªå°æ€»ç»“å¹»ç¯ç‰‡ã€‚åŸºæœ¬ä¸Šï¼Œæ¶Œç°èƒ½åŠ›åªèƒ½åœ¨å¤§å‹æ¨¡å‹ä¸­è§‚å¯Ÿåˆ°ï¼Œå¦‚æœä½ ä»…ä»…é€šè¿‡æŸ¥çœ‹å°æ¨¡å‹çš„å›¾è¡¨æ¥é¢„æµ‹å®ƒä»¬çš„æ¶Œç°ï¼Œé‚£ä¹ˆä½ æ˜¯æ— æ³•åšåˆ°çš„ã€‚æˆ‘å¯¹å¦‚ä½•çœ‹å¾…è¿™ä¸€ç‚¹ä¹Ÿè¿›è¡Œäº†ä¸€äº›åæ€ã€‚
- en: so emergence is really this framing of like how to view new abilities that are
    not intentionally built in to the pretraining and I think the subtext for this
    is super importantã€‚which is like you can see it as implicit argument for why we
    should keep scaling up language models because you get these abilities that are
    really hard to find otherwiseã€‚
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æ¶Œç°å®é™…ä¸Šæ˜¯å¦‚ä½•çœ‹å¾…é‚£äº›æœªåœ¨é¢„è®­ç»ƒä¸­æœ‰æ„æ„å»ºçš„æ–°èƒ½åŠ›çš„æ¡†æ¶ï¼Œæˆ‘è®¤ä¸ºè¿™èƒŒåçš„æ½œå°è¯éå¸¸é‡è¦ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œä½ å¯ä»¥æŠŠå®ƒçœ‹ä½œæ˜¯ä¸€ä¸ªéšå«çš„è®ºæ®ï¼Œè¯´æ˜æˆ‘ä»¬ä¸ºä»€ä¹ˆåº”è¯¥ä¸æ–­æ‰©å±•è¯­è¨€æ¨¡å‹ï¼Œå› ä¸ºè¿™æ ·ä½ ä¼šå¾—åˆ°é‚£äº›åœ¨å…¶ä»–æƒ…å†µä¸‹å¾ˆéš¾æ‰¾åˆ°çš„èƒ½åŠ›ã€‚
- en: And the context around this is pretty important because it's really expensive
    to continue scaling up these models and you even like one year agoã€‚a lot of people
    didn't believe that you could do better on certain tasks just by scaling up the
    size of the language modelã€‚
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œå›´ç»•è¿™ä¸ªèƒŒæ™¯æ˜¯ç›¸å½“é‡è¦çš„ï¼Œå› ä¸ºç»§ç»­æ‰©å±•è¿™äº›æ¨¡å‹çš„æˆæœ¬éå¸¸é«˜ï¼Œç”šè‡³åœ¨ä¸€å¹´å‰ï¼Œå¾ˆå¤šäººéƒ½ä¸ç›¸ä¿¡é€šè¿‡æ‰©å¤§è¯­è¨€æ¨¡å‹çš„è§„æ¨¡å¯ä»¥åœ¨æŸäº›ä»»åŠ¡ä¸Šè¡¨ç°æ›´å¥½ã€‚
- en: They sort of if you work in industry at allï¼Œ there's like this interesting tension
    between emergence and also like many production tasksã€‚so emergence is sort of
    this like task general phenomena where you scale up the model and it's like really
    expensive but the single model can do a lot of tasks is sort of like a in the
    direction of AGIã€‚
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ åœ¨è¡Œä¸šä¸­å·¥ä½œçš„è¯ï¼Œä¼šå­˜åœ¨ä¸€ç§æœ‰è¶£çš„ç´§å¼ å…³ç³»ï¼Œæ—¢æ¶‰åŠæ¶Œç°ç°è±¡ï¼Œåˆæ¶‰åŠè®¸å¤šç”Ÿäº§ä»»åŠ¡ã€‚æ‰€ä»¥æ¶Œç°æ˜¯ä¸€ç§ä»»åŠ¡çš„æ™®éç°è±¡ï¼Œå½“ä½ æ‰©å±•æ¨¡å‹æ—¶ï¼Œæˆæœ¬ä¼šå¾ˆé«˜ï¼Œä½†å•ä¸€æ¨¡å‹å¯ä»¥æ‰§è¡Œå¾ˆå¤šä»»åŠ¡ï¼Œè¿™åœ¨æŸç§ç¨‹åº¦ä¸Šæ˜¯æœç€AGIçš„æ–¹å‘å‘å±•ã€‚
- en: And then for many production tasksï¼Œ you have sort of the opposite where you
    know what task it isã€‚for exampleï¼Œ translating into Spanishï¼Œ and then you have
    these constraints on compute because you know when we will translateã€‚for exampleï¼Œ
    you don't want people to have to wait a couple seconds just to get the translationã€‚And
    then you also happen to have a lot of in domain dataï¼Œ so you haveï¼Œ for exampleã€‚
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè®¸å¤šç”Ÿäº§ä»»åŠ¡ï¼Œä½ æœ‰ä¸€ç§ç›¸åçš„æƒ…å†µï¼Œä½ çŸ¥é“å®ƒæ˜¯ä»€ä¹ˆä»»åŠ¡ã€‚ä¾‹å¦‚ï¼Œç¿»è¯‘æˆè¥¿ç­ç‰™è¯­ï¼Œå¹¶ä¸”ä½ å¯¹è®¡ç®—æœ‰è¿™äº›é™åˆ¶ï¼Œå› ä¸ºä½ çŸ¥é“ç¿»è¯‘æ—¶æœºã€‚ä¾‹å¦‚ï¼Œä½ ä¸å¸Œæœ›äººä»¬ç­‰å¾…å‡ ç§’é’Ÿæ‰èƒ½è·å¾—ç¿»è¯‘ã€‚è€Œä¸”ä½ ä¹Ÿæ°å¥½æœ‰å¾ˆå¤šé¢†åŸŸå†…çš„æ•°æ®ï¼Œæ¯”å¦‚è¯´ã€‚
- en: like you know a million pairs of English Spanish sentences to train onã€‚And this
    is like sort of the opposite setting where you don't really care about the model's
    emergenceã€‚you can just train a very small model on the data and do one of the
    task without having to use a lot of computeã€‚And the final point is that I think
    a really promising research direction if anyone is interested in doing research
    is to like work on predicting future emergent abilities and I haven't seen a lot
    of work on it recently just because I think maybe it's too hard for exampleã€‚
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯”å¦‚ï¼Œä½ çŸ¥é“æœ‰ä¸€ç™¾ä¸‡å¯¹è‹±è¯­å’Œè¥¿ç­ç‰™è¯­çš„å¥å­å¯ä»¥ç”¨æ¥è®­ç»ƒã€‚è¿™å°±åƒæ˜¯ç›¸åçš„æƒ…å†µï¼Œä½ å¹¶ä¸å¤ªå…³å¿ƒæ¨¡å‹çš„æ¶Œç°ï¼Œä½ å¯ä»¥åªç”¨æ•°æ®è®­ç»ƒä¸€ä¸ªéå¸¸å°çš„æ¨¡å‹æ¥å®ŒæˆæŸä¸ªä»»åŠ¡ï¼Œè€Œä¸å¿…æ¶ˆè€—å¤§é‡è®¡ç®—èµ„æºã€‚æœ€åä¸€ç‚¹æ˜¯ï¼Œæˆ‘è®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªéå¸¸æœ‰å‰é€”çš„ç ”ç©¶æ–¹å‘ï¼Œå¦‚æœæœ‰äººå¯¹ç ”ç©¶æ„Ÿå…´è¶£ï¼Œå¯ä»¥å°è¯•é¢„æµ‹æœªæ¥çš„æ¶Œç°èƒ½åŠ›ï¼Œè€Œæˆ‘æœ€è¿‘å¹¶æ²¡æœ‰çœ‹åˆ°å¤ªå¤šç›¸å…³çš„å·¥ä½œï¼Œå¯èƒ½æ˜¯å› ä¸ºè¿™å¤ªå›°éš¾äº†ï¼Œä¾‹å¦‚ã€‚
- en: like you could only like predict emergence for a specific task or like one way
    of predict emergence might not be super general and so I haven't seen much work
    on that but I think this is a pretty promising direction to work on and maybe
    Anthropic is working on itã€‚
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: åƒä½ åªèƒ½ä¸ºç‰¹å®šä»»åŠ¡é¢„æµ‹å‡ºç°ï¼Œæˆ–è€…é¢„æµ‹å‡ºç°çš„ä¸€ç§æ–¹å¼å¯èƒ½ä¸æ˜¯ç‰¹åˆ«æ™®éï¼Œæ‰€ä»¥æˆ‘æ²¡è§è¿‡å¤ªå¤šå…³äºè¿™ä¸€ç‚¹çš„ç ”ç©¶ï¼Œä½†æˆ‘è§‰å¾—è¿™æ˜¯ä¸€ä¸ªç›¸å½“æœ‰å‰æ™¯çš„ç ”ç©¶æ–¹å‘ï¼Œä¹Ÿè®¸Anthropicæ­£åœ¨ç ”ç©¶è¿™ä¸ªã€‚
- en: I don't knowã€‚Okayï¼Œ greatï¼Œ any questions on that before I move on to chain of
    promptmptonï¼ŸYeahä½¢ã€‚ğŸ˜Šã€‚ä½ å…ˆæ˜¯ã€‚ç³»æˆ‘æœ‰å‘¢æ¡éƒ½ä¿¾è§ã€‚Which parametersmateurs are best scale to get
    like propertiesã€‚is obviously there are many different options for whereã€‚ä»€ä¹ˆæ„å¤–çš„ã€‚Didt
    Gï¼Œ for exampleã€‚I want to be back thereã€‚Is that mostly something we just testã€‚
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¸çŸ¥é“ã€‚å¥½çš„ï¼Œå¾ˆæ£’ï¼Œåœ¨æˆ‘ç»§ç»­è°ˆè®ºæç¤ºé“¾ä¹‹å‰ï¼Œæœ‰ä»€ä¹ˆé—®é¢˜å—ï¼Ÿå—¯ï¼Œä½¢ã€‚ğŸ˜Šã€‚ä½ å…ˆæ˜¯ã€‚ç³»æˆ‘æœ‰å‘¢æ¡éƒ½ä¿¾è§ã€‚å“ªäº›å‚æ•°æœ€ä½³è§„æ¨¡æ¥è·å–ç±»ä¼¼çš„å±æ€§ã€‚æ˜¾ç„¶ï¼Œè¿™é‡Œæœ‰è®¸å¤šä¸åŒçš„é€‰æ‹©ã€‚ä»€ä¹ˆæ„å¤–çš„ã€‚æ¯”å¦‚è¯´ï¼ŒDidt
    Gã€‚æˆ‘æƒ³å›åˆ°é‚£é‡Œã€‚è¿™ä¸»è¦æ˜¯æˆ‘ä»¬æµ‹è¯•çš„å†…å®¹å—ï¼Ÿ
- en: And we find out which ones scale battery gives result or likeã€‚Yeahã€‚I would say
    that we don't have very principled methods for like how to scale these architecturesã€‚è¯¶ã€‚ğŸ˜Šã€‚I'm
    not an expert in thisï¼Œ but some of it has to deal with like how many parameters
    you can fit onto a particular TPUã€‚but in general I think you scale up like the
    number of intentions heads and embeddings like somewhat proportionately but yeah
    I think this is like an open research question because you you can't really do
    ablations over these pretrainingã€‚
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å‘ç°å“ªäº›æ‰©å±•çš„ç”µæ± ç»™å‡ºäº†ç»“æœï¼Œæˆ–è€…åƒé‚£æ ·ã€‚å—¯ã€‚æˆ‘æƒ³è¯´æˆ‘ä»¬å¹¶æ²¡æœ‰éå¸¸åŸåˆ™æ€§çš„æ–¹æ³•æ¥æ‰©å±•è¿™äº›æ¶æ„ã€‚è¯¶ã€‚ğŸ˜Šã€‚æˆ‘ä¸æ˜¯è¿™æ–¹é¢çš„ä¸“å®¶ï¼Œä½†æœ‰äº›å†…å®¹ä¸èƒ½å¤Ÿé€‚é…åˆ°ç‰¹å®šTPUä¸Šçš„å‚æ•°æ•°é‡æœ‰å…³ã€‚ä½†æ€»ä½“ä¸Šæˆ‘è§‰å¾—ä½ åœ¨ä¸€å®šç¨‹åº¦ä¸Šè¦æˆæ¯”ä¾‹åœ°æ‰©å±•æ„å›¾å¤´å’ŒåµŒå…¥æ•°é‡ï¼Œä½†æˆ‘è®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªå¼€æ”¾çš„ç ”ç©¶é—®é¢˜ï¼Œå› ä¸ºä½ ä¸èƒ½çœŸæ­£å¯¹è¿™äº›é¢„è®­ç»ƒè¿›è¡Œæ¶ˆèã€‚
- en: you can't really do ablations over pretrainingï¼Œ it's hard to sort of you know
    have any principled way of doing it other than some engineers who are in charge
    of like doing it saying okayã€‚I think this is the right thing to do and then it
    kind of works when we go with itã€‚Yeahã€‚
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å®é™…ä¸Šä¸èƒ½å¯¹é¢„è®­ç»ƒè¿›è¡Œæ¶ˆèï¼Œæƒ³è¦æœ‰ä»»ä½•åŸåˆ™æ€§çš„æ–¹æ³•æ˜¯å›°éš¾çš„ï¼Œé™¤éä¸€äº›è´Ÿè´£çš„äººå·¥ç¨‹å¸ˆè¯´ï¼Œå¥½çš„ã€‚æˆ‘è®¤ä¸ºè¿™å°±æ˜¯æ­£ç¡®çš„åšæ³•ï¼Œç„¶åå½“æˆ‘ä»¬è¿™æ ·åšæ—¶ï¼Œå®ƒå°±èƒ½æ­£å¸¸å·¥ä½œã€‚å—¯ã€‚
- en: Do you have any indication of the asymptootic behavior of this gamblingã€‚if you
    would expect that eventually you would you know reach either some plateau of flip
    finite but non zero lossã€‚or it would just go all the way down to zeroã€‚Yeahï¼Œ that's
    a great questionã€‚I thinkã€‚I mean there's you mean on like perplexity or like on
    a particular task or just in general on like an next word prediction Well seems
    like these are also pretty general pretty task independent rightï¼Ÿ
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ æœ‰æ²¡æœ‰å¯¹è¿™ç§èµŒåšçš„æ¸è¿‘è¡Œä¸ºæœ‰ä»»ä½•æŒ‡ç¤ºã€‚å¦‚æœä½ é¢„æœŸæœ€ç»ˆä¼šåˆ°è¾¾æŸä¸ªç¨³å®šç‚¹ï¼Œç¿»è½¬æœ‰é™ä½†éé›¶çš„æŸå¤±ï¼Œæˆ–è€…å®ƒå°±ä¼šä¸€è·¯é™åˆ°é›¶ã€‚å—¯ï¼Œè¿™ä¸ªé—®é¢˜å¾ˆå¥½ã€‚æˆ‘è§‰å¾—ã€‚æˆ‘æ˜¯è¯´ä½ æ˜¯è¯´åœ¨å›°æƒ‘åº¦ä¸Šï¼Œè¿˜æ˜¯åœ¨ç‰¹å®šä»»åŠ¡ä¸Šï¼Œæˆ–è€…åªæ˜¯ä¸€èˆ¬æ¥è¯´åƒä¸‹ä¸€ä¸ªå•è¯é¢„æµ‹ã€‚å¥½åƒè¿™äº›ä¹Ÿæ˜¯ç›¸å½“æ™®éçš„ï¼Œæ¯”è¾ƒç‹¬ç«‹äºä»»åŠ¡ï¼Œå¯¹å§ï¼Ÿ
- en: It's like emergent scalingã€‚Yeahï¼Œ but you knowï¼Œ if you take the limit of the
    infinite parametersã€‚then even analyticallyï¼Œ is there any sense of whether that
    how toã€‚Yeahã€‚I have no clue I think if if like for most of these tasks there's
    like a limit to accuracy like 100% for exampleã€‚so there's some there's some sort
    of asympote thereã€‚
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±åƒæ˜¯æ¶Œç°çš„æ‰©å±•ã€‚å—¯ï¼Œä½†ä½ çŸ¥é“ï¼Œå¦‚æœä½ å–æ— é™å‚æ•°çš„æé™ã€‚é‚£ä¹ˆå³ä½¿åœ¨åˆ†æä¸Šï¼Œä¹Ÿæœ‰æ²¡æœ‰ä»»ä½•æ„ä¹‰ã€‚å—¯ã€‚æˆ‘ä¸çŸ¥é“ï¼Œå¦‚æœå¯¹äºå¤§å¤šæ•°è¿™äº›ä»»åŠ¡ï¼Œå‡†ç¡®æ€§æ˜¯æœ‰é™çš„ï¼Œæ¯”å¦‚è¯´100%ã€‚æ‰€ä»¥é‚£é‡Œæœ‰æŸç§æ¸è¿‘çº¿ã€‚
- en: but I guess the deeper question that you might be asking is like can a language
    model like perfectly no likeã€‚You know how to predict the next word for any given
    inputã€‚And maybe likeï¼Œ I meanã€‚I guess there's some likeï¼Œ limit to likeã€‚Like if
    I say a sentenceã€‚there are like two possible next words or somethingã€‚
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘æƒ³ä½ å¯èƒ½åœ¨é—®æ›´æ·±å±‚çš„é—®é¢˜æ˜¯ï¼šè¯­è¨€æ¨¡å‹æ˜¯å¦å¯ä»¥å®Œç¾åœ°çŸ¥é“å¦‚ä½•é¢„æµ‹ä»»ä½•ç»™å®šè¾“å…¥çš„ä¸‹ä¸€ä¸ªå•è¯ã€‚ä¹Ÿè®¸ï¼Œæˆ‘çš„æ„æ€æ˜¯ã€‚æˆ‘æƒ³æœ‰æŸç§é™åˆ¶ã€‚å¦‚æœæˆ‘è¯´ä¸€ä¸ªå¥å­ï¼Œå¯èƒ½æœ‰ä¸¤ä¸ªå¯èƒ½çš„ä¸‹ä¸€ä¸ªå•è¯ä¹‹ç±»çš„ã€‚
- en: and you might not be able to guess that perfectlyã€‚So I think there's some limitã€‚but
    like I think we're far from reaching that limit and there's still a lot of unsolved
    tasks that sort of indicate that there's a lot of headroomã€‚Yeahï¼Œ if researchers
    are interested in studying emergenceã€‚what family of different sized models is
    publicly available or best for studyingï¼ŸYeahã€‚
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œä¸”ä½ å¯èƒ½æ— æ³•å®Œç¾é¢„æµ‹ã€‚æ‰€ä»¥æˆ‘è®¤ä¸ºè¿™æ˜¯æœ‰ä¸€äº›é™åˆ¶çš„ã€‚ä½†æˆ‘è§‰å¾—æˆ‘ä»¬ç¦»è¾¾åˆ°é‚£ä¸ªé™åˆ¶è¿˜å¾ˆè¿œï¼Œä»ç„¶æœ‰å¾ˆå¤šæœªè§£å†³çš„ä»»åŠ¡è¡¨æ˜è¿˜æœ‰å¾ˆå¤šæå‡ç©ºé—´ã€‚å—¯ï¼Œå¦‚æœç ”ç©¶äººå‘˜æœ‰å…´è¶£ç ”ç©¶å‡ºç°ï¼Œå“ªä¸ªä¸åŒè§„æ¨¡çš„æ¨¡å‹æ˜¯å…¬å¼€å¯ç”¨æˆ–æœ€ä½³çš„ç ”ç©¶é€‰æ‹©ï¼Ÿå—¯ã€‚
- en: good questionã€‚So I think the open AI API has like a lot of language models and
    we actually use that a lot even at Google it's used to study emergence and that's
    sort of one way of doing it and actually a lot of these models are currently free
    they're rate limited but they're free so that so we also use thatã€‚
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½é—®é¢˜ã€‚æ‰€ä»¥æˆ‘è®¤ä¸ºOpenAIçš„APIæœ‰å¾ˆå¤šè¯­è¨€æ¨¡å‹ï¼Œæˆ‘ä»¬å®é™…ä¸Šåœ¨è°·æ­Œä¹Ÿä½¿ç”¨å¾—å¾ˆå¤šï¼Œå®ƒè¢«ç”¨æ¥ç ”ç©¶æ–°å…´ç°è±¡ï¼Œè¿™å°±æ˜¯ä¸€ç§æ–¹æ³•ï¼Œå®é™…ä¸Šå¾ˆå¤šæ¨¡å‹ç›®å‰æ˜¯å…è´¹çš„ï¼Œè™½ç„¶æœ‰é™åˆ¶ï¼Œä½†å®ƒä»¬æ˜¯å…è´¹çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¹Ÿä½¿ç”¨å®ƒã€‚
- en: I think there's alsoã€‚Smaller language models like for exampleã€‚there's like a
    UL2 model that's like 20 billion parametersã€‚but I guess you're right there is
    sort of this challenge where like small language models you won't see a lot of
    these emergent behaviors so you kind of have to either trainã€‚Yeahï¼Œ you should
    kind of have to either use like open AI API for now or wait until people train
    larger modelsã€‚
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºè¿˜æœ‰æ›´å°çš„è¯­è¨€æ¨¡å‹ï¼Œæ¯”å¦‚è¯´ï¼ŒåƒUL2æ¨¡å‹ï¼Œå®ƒå¤§çº¦æœ‰200äº¿ä¸ªå‚æ•°ã€‚ä½†æˆ‘æƒ³ä½ æ˜¯å¯¹çš„ï¼Œç¡®å®å­˜åœ¨è¿™æ ·ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå³å°è¯­è¨€æ¨¡å‹ä¸ä¼šå‡ºç°å¾ˆå¤šæ–°å…´è¡Œä¸ºï¼Œå› æ­¤ä½ éœ€è¦è®­ç»ƒã€‚æ˜¯çš„ï¼Œä½ å¯èƒ½éœ€è¦ç°åœ¨ä½¿ç”¨OpenAI
    APIï¼Œæˆ–è€…ç­‰å¾…äººä»¬è®­ç»ƒæ›´å¤§çš„æ¨¡å‹ã€‚
- en: I guess there's also the bloom and like you guys probably know better than the
    OPT models that are publicly available but I haven't seen a lot of experiments
    on them yeah yeahã€‚å—¯ã€‚So like my question isï¼Œ are thereï¼Œ are there emerge abilities
    that are accessible and lower parameterã€‚
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æƒ³ä¹Ÿæœ‰ä¸€äº›æ–°çš„èƒ½åŠ›ï¼Œåƒä½ ä»¬å¯èƒ½æ¯”å…¬å¼€çš„OPTæ¨¡å‹æ›´äº†è§£è¿™äº›ï¼Œä½†æˆ‘è¿˜æ²¡æœ‰çœ‹åˆ°å¾ˆå¤šå®éªŒï¼Œå—¯ã€‚æ‰€ä»¥æˆ‘æƒ³é—®çš„æ˜¯ï¼Œæ˜¯å¦æœ‰å¯ä»¥è®¿é—®çš„ã€å‚æ•°è¾ƒä½çš„æ–°å…´èƒ½åŠ›ã€‚
- en: I can part to speechã€‚P to recognitionã€‚should maybe there might be some better
    maybe not like chain of thoughtã€‚but I heard or some thatã€‚Yeahï¼Œ definitelyï¼Œ I think
    in the paperã€‚we had like the list of couple dozen abilities that would be emerging
    at like 8 billion parameters or like 60 billion parameters or something like thatã€‚yeahã€‚Yeahã€‚Yeahï¼Œ
    we have two questions from zoomã€‚ The first question isï¼Œ do you see strategyã€‚
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¯ä»¥è¿›è¡Œè¯­éŸ³è¯†åˆ«ã€‚å¯èƒ½ä¼šæœ‰ä¸€äº›æ›´å¥½çš„ï¼Œå¯èƒ½ä¸æ˜¯åƒæ€ç»´é“¾é‚£æ ·ï¼Œä½†æˆ‘å¬è¯´è¿‡ä¸€äº›ã€‚æ˜¯çš„ï¼Œç¡®å®ï¼Œæˆ‘è®¤ä¸ºåœ¨è®ºæ–‡ä¸­ï¼Œæˆ‘ä»¬åˆ—å‡ºäº†å‡ æ‰“å°†åœ¨çº¦80äº¿å‚æ•°æˆ–600äº¿å‚æ•°å·¦å³å‡ºç°çš„èƒ½åŠ›ã€‚æ˜¯çš„ï¼Œæ˜¯çš„ã€‚æˆ‘ä»¬åœ¨Zoomä¸Šæœ‰ä¸¤ä¸ªé—®é¢˜ã€‚ç¬¬ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œä½ çœ‹åˆ°ç­–ç•¥äº†å—ã€‚
- en: Between the larger techã€‚Differing systematically in studying these modelsã€‚or
    basically everyone taking the same approachã€‚è¯¶ã€‚I wouldn't say that everyone is
    taking the same approachã€‚I thinkã€‚As one exampleï¼Œ Anthropic takes like a very safety
    centric approach and they're super interested in like emergent abilities because
    there could be emergent abilities that are undesirable and they want to predict
    those types of thingsã€‚I also don't know what happens at other companies other
    than at Googleã€‚
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¾ƒå¤§çš„æŠ€æœ¯ä¹‹é—´ï¼Œç³»ç»Ÿæ€§åœ°ç ”ç©¶è¿™äº›æ¨¡å‹ï¼Œè¿˜æ˜¯åŸºæœ¬ä¸Šå¤§å®¶é‡‡å–ç›¸åŒçš„æ–¹å¼ã€‚è¯¶ã€‚æˆ‘ä¸ä¼šè¯´æ¯ä¸ªäººéƒ½é‡‡å–ç›¸åŒçš„æ–¹æ³•ã€‚æˆ‘è®¤ä¸ºï¼Œä½œä¸ºä¸€ä¸ªä¾‹å­ï¼ŒAnthropicé‡‡å–äº†éå¸¸ä»¥å®‰å…¨ä¸ºä¸­å¿ƒçš„æ–¹æ³•ï¼Œä»–ä»¬å¯¹æ–°å…´èƒ½åŠ›éå¸¸æ„Ÿå…´è¶£ï¼Œå› ä¸ºå¯èƒ½ä¼šå‡ºç°ä¸€äº›ä¸å¸Œæœ›å‡ºç°çš„æ–°å…´èƒ½åŠ›ï¼Œä»–ä»¬æƒ³é¢„æµ‹è¿™äº›æƒ…å†µã€‚æˆ‘ä¹Ÿä¸çŸ¥é“å…¶ä»–å…¬å¸å‘ç”Ÿäº†ä»€ä¹ˆï¼Œé™¤äº†è°·æ­Œã€‚
- en: so I can't really speak too much to thatã€‚æœ‰ã€‚questionsã€‚What are some examples
    of tasks or abilities that have not yet emergedã€‚even in models like Lada and Cha
    GT etcï¼ŸOh yeahï¼Œ I have maybe I'll show this real quickã€‚![](img/1fe3b7e42f45e3d11a61cea42eaf51cb_3.png)
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä¸èƒ½å¤šè°ˆè¿™ä¸ªã€‚æœ‰é—®é¢˜ã€‚æœ‰å“ªäº›ä»»åŠ¡æˆ–èƒ½åŠ›å°šæœªå‡ºç°ï¼Œå³ä½¿åœ¨åƒLadaå’ŒChatGPTç­‰æ¨¡å‹ä¸­ï¼Ÿå“¦ï¼Œå¥½çš„ï¼Œä¹Ÿè®¸æˆ‘ä¼šè¿…é€Ÿå±•ç¤ºè¿™ä¸ªã€‚![](img/1fe3b7e42f45e3d11a61cea42eaf51cb_3.png)
- en: è¯¶ã€‚![](img/1fe3b7e42f45e3d11a61cea42eaf51cb_5.png)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¶ã€‚![](img/1fe3b7e42f45e3d11a61cea42eaf51cb_5.png)
- en: There's like a nice listï¼Œ somewhereã€‚Soã€‚So yeahï¼Œ so basically what we did isã€‚There's
    like 200 tasks in Big benchnã€‚And then we basically classified them and so likeã€‚![](img/1fe3b7e42f45e3d11a61cea42eaf51cb_7.png)
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰ä¸€ä¸ªå¾ˆå¥½çš„åˆ—è¡¨ï¼Œåœ¨å“ªé‡Œã€‚æ‰€ä»¥ï¼ŒåŸºæœ¬ä¸Šæˆ‘ä»¬æ‰€åšçš„æ˜¯ã€‚åœ¨Big Benchä¸Šæœ‰200ä¸ªä»»åŠ¡ã€‚ç„¶åæˆ‘ä»¬åŸºæœ¬ä¸Šå¯¹å®ƒä»¬è¿›è¡Œäº†åˆ†ç±»ï¼Œæ‰€ä»¥åƒè¿™æ ·ã€‚![](img/1fe3b7e42f45e3d11a61cea42eaf51cb_7.png)
- en: Smoothly increasing emergent with GP3 or lambdaï¼Œ emergent with palm and then
    flatã€‚which is like no model better than random So I think if you look at any of
    these tasks hereã€‚They should still not have emerged yetï¼Œ and if you can get them
    to mergeï¼Œ that'd be interestingã€‚ä»”ã€‚I think chat should be T 20 questionã€‚Oh okayï¼Œ
    yeahã€‚
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€GP3æˆ–lambdaçš„å¹³æ»‘å¢åŠ ï¼Œæ–°å…´èƒ½åŠ›ä¸Palmç›¸å…³ï¼Œç„¶åæ˜¯å¹³å¦çš„ã€‚è¿™å°±åƒæ²¡æœ‰æ¨¡å‹æ¯”éšæœºæ›´å¥½ã€‚æ‰€ä»¥æˆ‘è®¤ä¸ºå¦‚æœä½ çœ‹è¿™äº›ä»»åŠ¡ï¼Œå®ƒä»¬ä»ç„¶åº”è¯¥å°šæœªå‡ºç°ï¼Œå¦‚æœä½ èƒ½è®©å®ƒä»¬åˆå¹¶ï¼Œé‚£å°±å¾ˆæœ‰è¶£ã€‚å—¯ã€‚æˆ‘è®¤ä¸ºèŠå¤©åº”è¯¥æ˜¯T
    20é—®é¢˜ã€‚å“¦ï¼Œå¥½çš„ï¼Œå—¯ã€‚
- en: this is not a super I think this is like a couple months oldã€‚Yeahï¼Œ yeahã€‚Ohï¼Œ
    20 questionsï¼Œ Okayã€‚yeahã€‚Someæ„ã€‚Yeahï¼Œ I thinkã€‚Like the cool thing is like you can
    see over time right like originally like maybe only like these were you know emergent
    and then when Po came out you'd see a couple dozen moreab abilitiesities became
    emergent and then you know I suspect you know in a year or two most of these will
    become emergent and we need harder benchmarks Yeah there's another question on
    why doesn't Google take as much of a safety centerã€‚
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸æ˜¯è¶…çº§æ–°çš„ï¼Œæˆ‘è®¤ä¸ºè¿™å¤§æ¦‚å‡ ä¸ªæœˆå‰çš„äº‹æƒ…ã€‚æ˜¯çš„ï¼Œæ˜¯çš„ã€‚å“¦ï¼Œ20ä¸ªé—®é¢˜ï¼Œå¥½çš„ã€‚æ˜¯çš„ã€‚æœ‰ç‚¹æ„æ€ã€‚æ˜¯çš„ï¼Œæˆ‘è®¤ä¸ºã€‚å¾ˆé…·çš„äº‹æƒ…æ˜¯ï¼Œä½ å¯ä»¥çœ‹åˆ°éšç€æ—¶é—´çš„æ¨ç§»ï¼Œæœ€åˆå¯èƒ½åªæœ‰è¿™äº›æ˜¯æ–°å‡ºç°çš„ï¼Œå½“Poå‘å¸ƒæ—¶ï¼Œä½ ä¼šçœ‹åˆ°æ›´å¤šçš„èƒ½åŠ›å‡ºç°ï¼Œç„¶åæˆ‘çŒœæƒ³åœ¨ä¸€ä¸¤å¹´å†…ï¼Œè¿™äº›å¤§å¤šæ•°éƒ½ä¼šå‡ºç°ï¼Œæˆ‘ä»¬éœ€è¦æ›´ä¸¥æ ¼çš„åŸºå‡†ã€‚æ˜¯çš„ï¼Œè¿˜æœ‰å¦ä¸€ä¸ªé—®é¢˜ï¼Œä¸ºä»€ä¹ˆè°·æ­Œæ²¡æœ‰é‡‡å–é‚£ä¹ˆå¤šçš„å®‰å…¨ä¸­å¿ƒã€‚
- en: Like we said in droppingã€‚Are there reasons to believe powerful capabilities
    wouldn't be emergingï¼Ÿ
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘ä»¬åœ¨æ”¾å¼ƒæ—¶æ‰€è¯´çš„ã€‚æœ‰ç†ç”±ç›¸ä¿¡å¼ºå¤§çš„èƒ½åŠ›ä¸ä¼šå‡ºç°å—ï¼Ÿ
- en: Yeahï¼Œ I don't want to answer the question on behalf of Googleã€‚I just can only
    talk about my own opinionsã€‚But I think the reality is that Googleã€‚even if you
    look at like the amount of research that Google does it might not be in the large
    language models space specificallyã€‚but like the amount of safety research that
    we do I think is more than enthropic if you actually look at like the number of
    papers publishedã€‚
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œæˆ‘ä¸æƒ³ä»£è¡¨è°·æ­Œå›ç­”è¿™ä¸ªé—®é¢˜ã€‚æˆ‘åªèƒ½è°ˆè°ˆæˆ‘è‡ªå·±çš„çœ‹æ³•ã€‚ä½†æˆ‘è®¤ä¸ºç°å®æ˜¯ï¼Œå³ä½¿ä½ çœ‹çœ‹è°·æ­Œçš„ç ”ç©¶é‡ï¼Œå®ƒå¯èƒ½å¹¶ä¸ä¸“æ³¨äºå¤§å‹è¯­è¨€æ¨¡å‹é¢†åŸŸã€‚ä½†å°±æˆ‘ä»¬æ‰€åšçš„å®‰å…¨ç ”ç©¶çš„æ•°é‡è€Œè¨€ï¼Œæˆ‘è®¤ä¸ºè¿™æ¯”å…¶ä»–å…¬å¸è¦å¤šï¼Œå¦‚æœä½ å®é™…æŸ¥çœ‹å‘è¡¨çš„è®ºæ–‡æ•°é‡ã€‚
- en: don't quote me on thisï¼Œ but I think that's correctã€‚Okayã€‚è¯¶ greatã€‚Soã€‚Yeahã€‚I'll
    talk about chain of thought prompting so basically chain of thought prompting
    is this way of doing reasoning multistep reasoning with large language models
    andã€‚Yeahï¼Œ I wanted to say that it's super exciting to see like a lot of people
    at Google working on this and also to see Sdar CEO present this at our last year's
    Google IoC eventã€‚å—¯ã€‚And basicallyï¼Œ the motivation for this is that we want language
    models to do like more complicated tasks thatã€‚
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¸æ•¢ç¡®å®šï¼Œä½†æˆ‘è®¤ä¸ºè¿™æ˜¯æ­£ç¡®çš„ã€‚å¥½çš„ã€‚è¯¶ï¼Œå¾ˆå¥½ã€‚æ‰€ä»¥ã€‚æ˜¯çš„ã€‚æˆ‘ä¼šè°ˆè°ˆæ€ç»´é“¾æç¤ºï¼ŒåŸºæœ¬ä¸Šæ€ç»´é“¾æç¤ºæ˜¯ä¸€ç§åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­è¿›è¡Œå¤šæ­¥éª¤æ¨ç†çš„æ–¹æ³•ã€‚æ˜¯çš„ï¼Œæˆ‘æƒ³è¯´çœ‹åˆ°è°·æ­Œçš„å¾ˆå¤šäººéƒ½åœ¨ç ”ç©¶è¿™ä¸ªï¼Œå°¤å…¶æ˜¯çœ‹åˆ°Sdaré¦–å¸­æ‰§è¡Œå®˜åœ¨å»å¹´è°·æ­ŒIoCæ´»åŠ¨ä¸­å±•ç¤ºè¿™ä¸ªçœŸçš„å¾ˆä»¤äººå…´å¥‹ã€‚å—¯ã€‚åŸºæœ¬ä¸Šï¼Œè¿™ä¸ªçš„åŠ¨æœºæ˜¯æˆ‘ä»¬å¸Œæœ›è¯­è¨€æ¨¡å‹èƒ½å¤Ÿå¤„ç†æ›´å¤æ‚çš„ä»»åŠ¡ã€‚
- en: you knowï¼Œ for exampleï¼Œ we know language models can do easy tasks like sentiment
    analysis or translationã€‚but what about like more complicated tasks that might
    even take a human emit minute or more to doï¼Ÿ
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ çŸ¥é“ï¼Œæ¯”å¦‚è¯´ï¼Œæˆ‘ä»¬çŸ¥é“è¯­è¨€æ¨¡å‹å¯ä»¥åšç®€å•çš„ä»»åŠ¡ï¼Œæ¯”å¦‚æƒ…æ„Ÿåˆ†ææˆ–ç¿»è¯‘ã€‚ä½†æ›´å¤æ‚çš„ä»»åŠ¡å‘¢ï¼Œå¯èƒ½ç”šè‡³éœ€è¦äººç±»èŠ±è´¹ä¸€åˆ†é’Ÿæˆ–æ›´å¤šçš„æ—¶é—´å»åšï¼Ÿ
- en: And the goal here is to basically guide them with metadata so for exampleã€‚instead
    of just giving like an input output of pairã€‚we want to give them the entire reasoning
    process and have them mimic thatã€‚And basically you can see hereï¼Œ you knowï¼Œ in
    a standard prompt you have like the question and then the answer and then you
    have a question the model gives a new answerã€‚
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œçš„ç›®æ ‡åŸºæœ¬ä¸Šæ˜¯é€šè¿‡å…ƒæ•°æ®å¼•å¯¼å®ƒä»¬ï¼Œä¾‹å¦‚ã€‚æˆ‘ä»¬ä¸ä»…ä»…æƒ³ç»™å‡ºè¾“å…¥å’Œè¾“å‡ºçš„å¯¹ã€‚æˆ‘ä»¬æƒ³æä¾›æ•´ä¸ªæ¨ç†è¿‡ç¨‹ï¼Œè®©å®ƒä»¬æ¨¡ä»¿ã€‚åŸºæœ¬ä¸Šï¼Œä½ å¯ä»¥çœ‹åˆ°ï¼Œåœ¨æ ‡å‡†æç¤ºä¸­ï¼Œä½ æœ‰é—®é¢˜å’Œç­”æ¡ˆï¼Œç„¶åæœ‰ä¸€ä¸ªé—®é¢˜ï¼Œæ¨¡å‹ç»™å‡ºæ–°çš„ç­”æ¡ˆã€‚
- en: unfortunately it's wrongã€‚And then with chain of thought promptingã€‚you give the
    model a question and then kind of like how your teacher would ask you to show
    your workã€‚you give like the chain of thought is what we call it or basically a
    reasoning path and then you give the final answer and then when the model sees
    this unseen questionã€‚now it's able to give the reasoning path and then give the
    correct final answerã€‚
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å¹¸çš„æ˜¯ï¼Œè¿™æ˜¯é”™è¯¯çš„ã€‚ç„¶åé€šè¿‡æ€ç»´é“¾æç¤ºã€‚ä½ ç»™æ¨¡å‹ä¸€ä¸ªé—®é¢˜ï¼Œç„¶åå°±åƒè€å¸ˆè®©ä½ å±•ç¤ºä½ çš„æ€è·¯ä¸€æ ·ã€‚ä½ ç»™å‡ºæˆ‘ä»¬ç§°ä¹‹ä¸ºæ€ç»´é“¾çš„æ¨ç†è·¯å¾„ï¼Œæœ€åç»™å‡ºç­”æ¡ˆã€‚å½“æ¨¡å‹çœ‹åˆ°è¿™ä¸ªæœªè§è¿‡çš„é—®é¢˜æ—¶ï¼Œç°åœ¨å®ƒèƒ½å¤Ÿç»™å‡ºæ¨ç†è·¯å¾„ï¼Œå¹¶ä¸”ç»™å‡ºæ­£ç¡®çš„æœ€ç»ˆç­”æ¡ˆã€‚
- en: And the way that we add these prompts into the prompt is basically we just manually
    write a couple and then add it into the promptã€‚So let me just show how that worksã€‚So
    this was the Open Air APIã€‚And basicallyã€‚Here's like the non chainF thought way
    of doing itï¼Œ so basically you would haveã€‚Question answerã€‚question answerï¼Œ question
    answerï¼Œ and then new question aboutï¼Œ you knowï¼Œ cafeteria asked3 applesã€‚
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†è¿™äº›æç¤ºåŠ å…¥åˆ°æç¤ºä¸­çš„æ–¹å¼åŸºæœ¬ä¸Šæ˜¯æ‰‹åŠ¨å†™å‡ ä¸ªï¼Œç„¶åæ·»åŠ åˆ°æç¤ºä¸­ã€‚è®©æˆ‘å±•ç¤ºä¸€ä¸‹æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚è¿™æ˜¯Open Air APIã€‚åŸºæœ¬ä¸Šã€‚è¿™æ˜¯éæ€ç»´é“¾çš„åšæ³•ï¼Œæ‰€ä»¥åŸºæœ¬ä¸Šä½ ä¼šæœ‰ã€‚é—®é¢˜ç­”æ¡ˆã€‚é—®é¢˜ç­”æ¡ˆï¼Œé—®é¢˜ç­”æ¡ˆï¼Œç„¶åæ˜¯å…³äºï¼Œæ¯”å¦‚è¯´ï¼Œé£Ÿå ‚é—®3ä¸ªè‹¹æœçš„æ–°é—®é¢˜ã€‚
- en: they use 20 to make lunch and about six more how many apples they haveã€‚And the
    model gets it wrongã€‚And the only difference with chain of thought is that you
    give these intermediate reasoning pathsã€‚Before giving the final answerï¼Œ so here's
    a pathï¼Œ there's a reasoning chainã€‚there's another reasoning chainã€‚And then now
    the model for this unseen questionã€‚
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ä»–ä»¬ç”¨20æ¥åšåˆé¤ï¼Œå¦å¤–å¤§çº¦å…­ä¸ªï¼Œé—®ä»–ä»¬æœ‰å¤šå°‘ä¸ªè‹¹æœã€‚æ¨¡å‹å‡ºé”™äº†ã€‚é“¾å¼æ€è€ƒå”¯ä¸€çš„åŒºåˆ«æ˜¯ï¼Œä½ åœ¨ç»™å‡ºæœ€ç»ˆç­”æ¡ˆä¹‹å‰æä¾›è¿™äº›ä¸­é—´æ¨ç†è·¯å¾„ï¼Œæ‰€ä»¥è¿™æ˜¯ä¸€ä¸ªè·¯å¾„ï¼Œè¿˜æœ‰ä¸€ä¸ªæ¨ç†é“¾ã€‚ç°åœ¨æ¨¡å‹å¯¹äºè¿™ä¸ªæœªè§çš„é—®é¢˜ã€‚
- en: Gives the entire reasoning processï¼Œ and then this actually enables them model
    to get it correctã€‚I'll give another quick exampleï¼Œ this oneã€‚So here the task is
    just take the last letters of the words and Bill Gates so like L from Bill and
    Ss from Gates and then concatenate them and the answer should be LSã€‚
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: æä¾›æ•´ä¸ªæ¨ç†è¿‡ç¨‹ï¼Œè¿™å®é™…ä¸Šä½¿æ¨¡å‹èƒ½å¤Ÿæ­£ç¡®å›ç­”ã€‚æˆ‘å†ç»™ä¸€ä¸ªå¿«é€Ÿçš„ä¾‹å­ï¼Œå°±æ˜¯è¿™ä¸ªã€‚ä»»åŠ¡å°±æ˜¯å–å•è¯çš„æœ€åå­—æ¯ï¼Œæ¯”å°”Â·ç›–èŒ¨çš„æœ€åå­—æ¯ï¼Œæ‰€ä»¥Læ¥è‡ªæ¯”å°”ï¼ŒSæ¥è‡ªç›–èŒ¨ï¼Œç„¶åè¿æ¥èµ·æ¥ï¼Œç­”æ¡ˆåº”è¯¥æ˜¯LSã€‚
- en: And then here the model gets it wrongã€‚The answer should be Nã€‚Says SKã€‚And then
    if you do chainF thoughtï¼Œ obviously this it becomes very easy for the modelã€‚so
    you know it says the last letter of bill is Lï¼Œ the last letter of gates is S answers
    LSã€‚And then here it's able to do the last letter of Elons M and the last letter
    of musk is K and answer is N Kã€‚
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åè¿™é‡Œæ¨¡å‹å‡ºé”™äº†ã€‚ç­”æ¡ˆåº”è¯¥æ˜¯Nã€‚SKè¯´ã€‚ç„¶åå¦‚æœä½ è¿›è¡Œé“¾å¼æ€è€ƒï¼Œæ˜¾ç„¶è¿™å¯¹æ¨¡å‹æ¥è¯´å˜å¾—å¾ˆç®€å•ã€‚å®ƒè¯´æ¯”å°”çš„æœ€åä¸€ä¸ªå­—æ¯æ˜¯Lï¼Œç›–èŒ¨çš„æœ€åä¸€ä¸ªå­—æ¯æ˜¯Sï¼Œç­”æ¡ˆæ˜¯LSã€‚ç„¶åè¿™é‡Œå®ƒèƒ½å¤Ÿå¾—åˆ°åŸƒéš†Â·Mçš„æœ€åä¸€ä¸ªå­—æ¯å’Œé©¬æ–¯å…‹çš„æœ€åä¸€ä¸ªå­—æ¯æ˜¯Kï¼Œç­”æ¡ˆæ˜¯N
    Kã€‚
- en: è¯¶ã€‚So any is this clear any questions about what's going on hereï¼ŸOkayã€‚å—¯ã€‚So basically
    we can have these similar plots where the X axis is the model scaleã€‚the y axis
    is the performance so on the left we have this mathboard question benchmark called
    GSMAK it's basically like questions that you'd see in like an elementary school
    math testã€‚And you can see the blue dot is standard and the purple star is chain
    of dot and basically you see that the chain of thought if you use a large enough
    modelã€‚
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¶ã€‚é‚£ä¹ˆï¼Œæœ‰æ²¡æœ‰ä»€ä¹ˆä¸æ¸…æ¥šçš„åœ°æ–¹ï¼Ÿå…³äºè¿™é‡Œå‘ç”Ÿçš„äº‹æƒ…æœ‰é—®é¢˜å—ï¼Ÿå¥½çš„ã€‚å—¯ã€‚åŸºæœ¬ä¸Šæˆ‘ä»¬å¯ä»¥æœ‰è¿™äº›ç±»ä¼¼çš„å›¾ï¼Œå…¶ä¸­Xè½´æ˜¯æ¨¡å‹è§„æ¨¡ï¼ŒYè½´æ˜¯æ€§èƒ½ã€‚åœ¨å·¦ä¾§æˆ‘ä»¬æœ‰ä¸€ä¸ªå«åšGSMAKçš„æ•°å­¦æ¿é—®é¢˜åŸºå‡†ï¼ŒåŸºæœ¬ä¸Šåƒæ˜¯ä½ åœ¨å°å­¦æ•°å­¦æµ‹è¯•ä¸­çœ‹åˆ°çš„é—®é¢˜ã€‚ä½ å¯ä»¥çœ‹åˆ°è“ç‚¹æ˜¯æ ‡å‡†ï¼Œç´«æ˜Ÿæ˜¯é“¾å¼æ€è€ƒï¼ŒåŸºæœ¬ä¸Šä½ ä¼šçœ‹åˆ°ï¼Œå¦‚æœä½ ä½¿ç”¨è¶³å¤Ÿå¤§çš„æ¨¡å‹ï¼Œé“¾å¼æ€è€ƒçš„è¡¨ç°è¦å¥½å¾—å¤šã€‚
- en: does a lot better than standard promptingã€‚And actually beats the fineine Tus
    Stay of the art at the timeã€‚A similar example is on this benchmark called Str
    QAã€‚And what strategy here is it's basically like this world knowledge plus common
    sense reasoning benchmarkã€‚so the question would be like can you hide a basketball
    in a Sancat's ear and then the model would say you know a basketball is about
    this sizeã€‚
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œä¸”å®é™…ä¸Šè¶…è¿‡äº†å½“æ—¶çš„æœ€æ–°æŠ€æœ¯ã€‚ä¸€ä¸ªç±»ä¼¼çš„ä¾‹å­æ˜¯åœ¨ä¸€ä¸ªå«åšStr QAçš„åŸºå‡†ä¸Šã€‚è¿™é‡Œçš„ç­–ç•¥åŸºæœ¬ä¸Šæ˜¯ä¸–ç•ŒçŸ¥è¯†åŠ å¸¸è¯†æ¨ç†åŸºå‡†ã€‚é—®é¢˜å¯èƒ½æ˜¯ä½ èƒ½æŠŠç¯®çƒè—åœ¨ä¸€åªçŒ«çš„è€³æœµé‡Œå—ï¼Ÿç„¶åæ¨¡å‹ä¼šè¯´ï¼Œç¯®çƒå¤§çº¦æ˜¯è¿™ä¸ªå¤§å°ã€‚
- en: a Sancat's ear is that server would not fit and now this benchmark you can also
    see that we can beat the fine tune save the art from before just by using chain
    of thought with a large enough languageã€‚So one way we use this is that we evaluated
    champf thought on a certain subset of Big benchch tasksã€‚
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: çŒ«çš„è€³æœµé‚£æ ·çš„å°ºå¯¸æ˜¯æ”¾ä¸ä¸‹çš„ï¼Œç°åœ¨åœ¨è¿™ä¸ªåŸºå‡†ä¸­ä½ ä¹Ÿå¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨é“¾å¼æ€è€ƒå’Œè¶³å¤Ÿå¤§çš„è¯­è¨€æ¨¡å‹æ¥è¶…è¿‡ä¹‹å‰çš„æœ€æ–°æŠ€æœ¯ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„ä¸€ç§ä½¿ç”¨æ–¹å¼æ˜¯ï¼Œæˆ‘ä»¬åœ¨æŸä¸ªBig
    benchchä»»åŠ¡çš„å­é›†ä¸­è¯„ä¼°äº†é“¾å¼æ€è€ƒã€‚
- en: so we created a subset called Big benchch hard and basically it's like 23 challenging
    tasks from Big benchch where like no model had done better than the average human
    rateerã€‚So the way that you prompt the model is that you'd have like a task description
    question optionsã€‚
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªå«åšBig benchch hardçš„å­é›†ï¼ŒåŸºæœ¬ä¸Šå®ƒå°±åƒæ˜¯23ä¸ªæ¥è‡ªBig benchchçš„æŒ‘æˆ˜æ€§ä»»åŠ¡ï¼Œå…¶ä¸­æ²¡æœ‰æ¨¡å‹çš„è¡¨ç°è¶…è¿‡å¹³å‡äººç±»è¯„åˆ†è€…ã€‚ä½ æç¤ºæ¨¡å‹çš„æ–¹å¼æ˜¯æä¾›ä»»åŠ¡æè¿°ã€é—®é¢˜å’Œé€‰é¡¹ã€‚
- en: chain of dotï¼Œ and then the test time questionã€‚And so I'll give a couple of examples
    of like tasks hereã€‚So one example is navigate basically what the language model
    has to do in this task is it has to basically follow these so the question is
    likeã€‚if you follow these instructions do you return to the starting pointï¼Œ turn
    leftï¼Œ turn rightã€‚take five stepsï¼Œ take four stepsï¼Œ turn aroundï¼Œ take nine stepsã€‚
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: é“¾å¼æ€è€ƒï¼Œç„¶åæ˜¯æµ‹è¯•æ—¶é—´çš„é—®é¢˜ã€‚æ‰€ä»¥æˆ‘ç»™å‡ ä¸ªä»»åŠ¡çš„ä¾‹å­ã€‚ä¸€ä¸ªä¾‹å­æ˜¯å¯¼èˆªï¼ŒåŸºæœ¬ä¸Šè¯­è¨€æ¨¡å‹åœ¨è¿™ä¸ªä»»åŠ¡ä¸­éœ€è¦åšçš„å°±æ˜¯éµå¾ªè¿™äº›ï¼Œæ‰€ä»¥é—®é¢˜æ˜¯ï¼šå¦‚æœä½ éµå¾ªè¿™äº›æŒ‡ä»¤ï¼Œæ˜¯å¦è¿”å›åˆ°èµ·ç‚¹ï¼Œå‘å·¦è½¬ï¼Œå‘å³è½¬ï¼Œèµ°äº”æ­¥ï¼Œèµ°å››æ­¥ï¼Œè½¬èº«ï¼Œèµ°ä¹æ­¥ã€‚
- en: And then the model following the fusile exemplars is able to like basically
    track state after all of the actionsã€‚and then at the end it saysï¼Œ okayï¼Œ we at
    the final answerã€‚so answer are we at the original locationï¼Œ mean if it is zero
    is0 then the answer is yesã€‚è¯¶ã€‚Just give an example of another taskï¼Œ here's a task
    that's like very easy for humans basically word sortingã€‚
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œè·Ÿéšå¯èåˆæ ·æœ¬çš„æ¨¡å‹åŸºæœ¬ä¸Šèƒ½å¤Ÿåœ¨æ‰€æœ‰æ“ä½œä¹‹åè·Ÿè¸ªçŠ¶æ€ã€‚æœ€åå®ƒä¼šè¯´ï¼Œæˆ‘ä»¬å¾—åˆ°äº†æœ€ç»ˆç­”æ¡ˆã€‚é‚£ä¹ˆï¼Œç­”æ¡ˆæ˜¯æˆ‘ä»¬æ˜¯å¦å›åˆ°äº†åŸå§‹ä½ç½®ï¼Œæ„å‘³ç€å¦‚æœå®ƒæ˜¯é›¶ï¼Œé‚£ä¹ˆç­”æ¡ˆå°±æ˜¯æ˜¯çš„ã€‚è¯¶ã€‚å†ä¸¾ä¸ªç®€å•çš„ä¾‹å­ï¼Œè¿™æ˜¯ä¸€ä¸ªå¯¹äººç±»æ¥è¯´éå¸¸ç®€å•çš„ä»»åŠ¡ï¼ŒåŸºæœ¬ä¸Šæ˜¯å•è¯æ’åºã€‚
- en: so like there's a list of words Burleyï¼Œ Belaï¼Œ I'm not going to read them and
    basically the model has to sort them alphabe orderã€‚And here the model can follow
    the future exempï¼Œ so you have this pretty complicated like chain of dot where
    the model has to like sort each of the subparts and then finally it gets to the
    final answerã€‚
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æœ‰ä¸€ä»½å•è¯åˆ—è¡¨ï¼ŒBurleyï¼ŒBelaï¼Œæˆ‘ä¸ä¼šé€ä¸€è¯»å®ƒä»¬ï¼ŒåŸºæœ¬ä¸Šæ¨¡å‹å¿…é¡»æŒ‰å­—æ¯é¡ºåºå¯¹å®ƒä»¬è¿›è¡Œæ’åºã€‚åœ¨è¿™é‡Œï¼Œæ¨¡å‹å¯ä»¥è·Ÿéšæœªæ¥çš„ç¤ºä¾‹ï¼Œæ‰€ä»¥ä½ æœ‰ä¸€ä¸ªç›¸å½“å¤æ‚çš„é“¾å¼æ€è€ƒï¼Œæ¨¡å‹å¿…é¡»å¯¹æ¯ä¸ªå­éƒ¨åˆ†è¿›è¡Œæ’åºï¼Œæœ€åå¾—å‡ºæœ€ç»ˆç­”æ¡ˆã€‚
- en: which is correctã€‚So here's sort of this result summary on this subset of Big
    Bennchã€‚so you can see okay we have two metricsï¼Œ one is just the average performance
    on all these tasks and the second is the percent of tasks that are above the average
    human rateer so average human rateer is 67 max human rateer is 94ã€‚
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æ­£ç¡®çš„ã€‚é‚£ä¹ˆè¿™æ˜¯å…³äºè¿™ä¸ªBig Bennchå­é›†çš„ç»“æœæ€»ç»“ã€‚ä½ å¯ä»¥çœ‹åˆ°æˆ‘ä»¬æœ‰ä¸¤ä¸ªæŒ‡æ ‡ï¼Œä¸€ä¸ªæ˜¯æ‰€æœ‰ä»»åŠ¡çš„å¹³å‡è¡¨ç°ï¼Œå¦ä¸€ä¸ªæ˜¯è¶…è¿‡å¹³å‡äººç±»è¯„åˆ†è€…çš„ä»»åŠ¡ç™¾åˆ†æ¯”ï¼Œæ‰€ä»¥å¹³å‡äººç±»è¯„åˆ†è€…æ˜¯67ï¼Œæœ€é«˜äººç±»è¯„åˆ†è€…æ˜¯94ã€‚
- en: And then prior resultsï¼Œ the model was doing like way worseï¼Œ it was like 50ã€‚and
    this is sort of by construction of this subsetã€‚And then we use Code Vinci O2ã€‚which
    is like one of the open AI models and actually you can use this one for free with
    the open APIã€‚And basicallyï¼Œ if you do answer only prompting without chainF thoughtã€‚
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶ååœ¨ä¹‹å‰çš„ç»“æœä¸­ï¼Œæ¨¡å‹çš„è¡¨ç°å¾ˆå·®ï¼Œå¤§çº¦æ˜¯50ã€‚è¿™æ˜¯é€šè¿‡è¿™ä¸ªå­é›†çš„æ„å»ºå¾—å‡ºçš„ã€‚ç„¶åæˆ‘ä»¬ä½¿ç”¨Code Vinci O2ã€‚è¿™æ˜¯å¼€æ”¾AIæ¨¡å‹ä¹‹ä¸€ï¼Œå®é™…ä¸Šä½ å¯ä»¥é€šè¿‡å¼€æ”¾APIå…è´¹ä½¿ç”¨è¿™ä¸ªæ¨¡å‹ã€‚åŸºæœ¬ä¸Šï¼Œå¦‚æœä½ åªè¿›è¡Œå›ç­”æç¤ºè€Œä¸è¿›è¡Œé“¾å¼æ€è€ƒã€‚
- en: then you sort of are being the average rater on like five of 27ã€‚but if you use
    chainF thought promptingï¼Œ then the performance increases by this pretty decent
    amount and you're able to pass the human average human other majority of tasksã€‚And
    then below is just this visualization of the tasks that are doing worse than humans
    in red and then better than humans in blueã€‚2 questionsã€‚ Boyï¼Œ isn't this similar
    to R HF Sï¼Œ at leastã€‚Hiss what similarï¼Ÿ
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åä½ åœ¨27ä¸ªä»»åŠ¡ä¸­å¤§çº¦æ˜¯å¹³å‡è¯„åˆ†è€…çš„æ°´å¹³ã€‚ä½†æ˜¯å¦‚æœä½ ä½¿ç”¨é“¾å¼æ€è€ƒæç¤ºï¼Œæ€§èƒ½ä¼šæ˜¾è‘—æé«˜ï¼Œèƒ½å¤Ÿè¶…è¿‡å¤§å¤šæ•°ä»»åŠ¡ä¸­çš„äººç±»å¹³å‡æ°´å¹³ã€‚ç„¶åä¸‹é¢æ˜¯ä¸€ä¸ªå¯è§†åŒ–ï¼Œæ˜¾ç¤ºå‡ºè¡¨ç°ä½äºäººç±»çš„ä»»åŠ¡ç”¨çº¢è‰²æ ‡å‡ºï¼Œè¡¨ç°ä¼˜äºäººç±»çš„ä»»åŠ¡ç”¨è“è‰²æ ‡å‡ºã€‚ä¸¤ä¸ªé—®é¢˜ã€‚ä¼™è®¡ï¼Œè¿™éš¾é“ä¸å’ŒR
    HF Sç›¸ä¼¼å—ï¼Ÿå˜¿ï¼Œæ˜¯ä»€ä¹ˆç›¸ä¼¼å‘¢ï¼Ÿ
- en: I can change up on own for notã€‚è¢«æ‹³åˆ°ã€‚å—¯ã€‚Yeahï¼Œ I think it's thereã€‚I wouldn't call
    it similarã€‚so like chainF thought is basically you take a pre trade language model
    and you use a prompting technique that includes intermediate reason pathã€‚The way
    that RLHF works is that you have this additional data that you want to fine tune
    the model on and you have a preference model that sort of predicts like how well
    does a certain outputã€‚How likely is that to be preferred by humans and then RLHF
    what that does is it tune it fine tunes like the language model to do well on
    the preference models predictionã€‚
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¯ä»¥æ”¹å˜è‡ªå·±çš„çœ‹æ³•ï¼Œä¸ã€‚è¢«æ‹³åˆ°ã€‚å—¯ã€‚æ˜¯çš„ï¼Œæˆ‘æƒ³è¿™æ˜¯å­˜åœ¨çš„ã€‚æˆ‘ä¸ä¼šç§°å®ƒä¸ºç›¸ä¼¼ã€‚åƒé“¾å¼æ€è€ƒåŸºæœ¬ä¸Šæ˜¯ä½ é‡‡ç”¨ä¸€ä¸ªé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨åŒ…å«ä¸­é—´æ¨ç†è·¯å¾„çš„æç¤ºæŠ€æœ¯ã€‚RLHFçš„å·¥ä½œæ–¹å¼æ˜¯ä½ æœ‰è¿™äº›é¢å¤–çš„æ•°æ®ï¼Œä½ æƒ³å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå¹¶ä¸”æœ‰ä¸€ä¸ªåå¥½æ¨¡å‹ï¼Œé¢„æµ‹æŸä¸ªè¾“å‡ºçš„è¡¨ç°å¦‚ä½•ã€‚æŸä¸ªè¾“å‡ºè¢«äººç±»åå¥½çš„å¯èƒ½æ€§æœ‰å¤šå¤§ï¼Œç„¶åRLHFçš„ä½œç”¨å°±æ˜¯å¾®è°ƒè¯­è¨€æ¨¡å‹ï¼Œä»¥ä¾¿åœ¨åå¥½æ¨¡å‹çš„é¢„æµ‹ä¸Šè¡¨ç°è‰¯å¥½ã€‚
- en: so basically it's sort of aligning the model with what humans would preferã€‚Is
    there a second questionï¼Ÿã‚„ã„ã§ã™ã€‚Okay Grace asksï¼Œ can China be includedd in fine tuning
    rather than having aã€‚Yesï¼Œ the short answer is yesã€‚The sort of complicated thing
    about that is that you have to have like chain of thought intermediate steps and
    those are prettyã€‚it can be costly to sort of to gather that data and to do the
    fineã€‚One last questionã€‚
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥åŸºæœ¬ä¸Šè¿™å°±æ˜¯å°†æ¨¡å‹ä¸äººç±»çš„åå¥½å¯¹é½ã€‚æœ‰ç¬¬äºŒä¸ªé—®é¢˜å—ï¼Ÿã‚„ã„ã§ã™ã€‚å¥½çš„ï¼ŒGraceé—®ï¼Œä¸­å›½æ˜¯å¦å¯ä»¥çº³å…¥å¾®è°ƒï¼Œè€Œä¸æ˜¯è¦æœ‰ä¸€ä¸ªã€‚æ˜¯çš„ï¼Œç®€çŸ­çš„å›ç­”æ˜¯å¯ä»¥çš„ã€‚å¤æ‚çš„äº‹æƒ…åœ¨äºä½ å¿…é¡»æœ‰é“¾å¼æ€è€ƒçš„ä¸­é—´æ­¥éª¤ï¼Œè¿™äº›æ­¥éª¤æ˜¯ç›¸å½“å¤æ‚çš„ã€‚æ”¶é›†è¿™äº›æ•°æ®å’Œè¿›è¡Œå¾®è°ƒå¯èƒ½æ˜¯æˆæœ¬è¾ƒé«˜çš„ã€‚æœ€åä¸€ä¸ªé—®é¢˜ã€‚
- en: sorry for everybody another student asksï¼Œ do you think that chain of thought
    and prompt engineering in general is just an artifact that won't be necessary
    with larger scale models that are better able to understand the functionã€‚Yeah
    so that's a great question basically the question is like how like ephemeral is
    like prompt engineering going to be I think we'll find out but some initial intuitions
    are that like for easy tasks that are like you know easy to describe and maybe
    there multiple choice larger models will probably be more robust to prompt engineering
    and there's sort of less you can do with thatã€‚
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: æŠ±æ­‰ï¼Œå¦ä¸€ä½å­¦ç”Ÿé—®ï¼Œä½ è®¤ä¸ºæ€ç»´é“¾å’Œæç¤ºå·¥ç¨‹ä¸€èˆ¬åªæ˜¯ä¸€ä¸ªäº§ç‰©ï¼Œåœ¨æ›´å¤§è§„æ¨¡ã€èƒ½å¤Ÿæ›´å¥½ç†è§£åŠŸèƒ½çš„æ¨¡å‹é¢å‰æ˜¯å¦ä¸å†å¿…è¦ã€‚æ˜¯çš„ï¼Œè¿™æ˜¯ä¸ªå¥½é—®é¢˜ï¼ŒåŸºæœ¬ä¸Šè¿™ä¸ªé—®é¢˜æ˜¯å…³äºæç¤ºå·¥ç¨‹å°†æœ‰å¤šçŸ­æš‚ã€‚æˆ‘è®¤ä¸ºæˆ‘ä»¬ä¼šæ‰¾åˆ°ç­”æ¡ˆï¼Œä½†ä¸€äº›åˆæ­¥çš„ç›´è§‰æ˜¯ï¼Œå¯¹äºé‚£äº›æ˜“äºæè¿°çš„ç®€å•ä»»åŠ¡ï¼Œæˆ–è®¸æœ‰å¤šä¸ªé€‰æ‹©çš„å¤§å‹æ¨¡å‹ä¼šæ›´èƒ½æŠµæŠ—æç¤ºå·¥ç¨‹ï¼Œèƒ½åšçš„äº‹æƒ…å°±ä¼šå°‘ä¸€äº›ã€‚
- en: But I think as language models get more powerfulã€‚It'll sort of be more normal
    to use them on a lot more challenging tasks and in those tasks you'll have to
    specify exactly what you want the model to doã€‚et ceï¼Œ so I think there'll still
    be some room for prompt engineering there at least in near futureã€‚
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯æˆ‘è®¤ä¸ºéšç€è¯­è¨€æ¨¡å‹å˜å¾—æ›´å¼ºå¤§ï¼Œä½¿ç”¨å®ƒä»¬å¤„ç†æ›´å¤šæŒ‘æˆ˜æ€§ä»»åŠ¡å°†ä¼šæ›´åŠ æ™®éï¼Œè€Œåœ¨è¿™äº›ä»»åŠ¡ä¸­ï¼Œä½ å¿…é¡»æ˜ç¡®æŒ‡å‡ºä½ å¸Œæœ›æ¨¡å‹åšä»€ä¹ˆã€‚å› æ­¤ï¼Œæˆ‘è®¤ä¸ºåœ¨è‡³å°‘ä¸ä¹…çš„å°†æ¥ï¼Œä»ä¼šæœ‰ä¸€äº›æç¤ºå·¥ç¨‹çš„ç©ºé—´ã€‚
- en: Yeahï¼Œ correct you know how this general for exampleï¼Œ you a simpleã€‚And then the
    other one is concerning sorting the wordsã€‚Yeahï¼Œ so mean see thatã€‚Give the channel
    thought like words of thatã€‚Yeah that's a great question so for some tasks where
    you've seen similar data and pretrainingã€‚the model can do really well even if
    the chain of thought is from another taskï¼Œ so for exampleã€‚
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œæ²¡é”™ï¼Œä½ çŸ¥é“è¿™ä¸ªä¸€èˆ¬æ˜¯æ€æ ·çš„ï¼Œæ¯”å¦‚ä½ ä¸€ä¸ªç®€å•çš„ã€‚ç„¶åå¦ä¸€ä¸ªæ˜¯å…³äºæ’åºå•è¯çš„ã€‚æ˜¯çš„ï¼Œæ‰€ä»¥æˆ‘çš„æ„æ€æ˜¯çœ‹åˆ°è¿™ä¸€ç‚¹ã€‚ç»™å‡ºæ€ç»´é“¾çš„åƒæ˜¯é‚£æ ·çš„å•è¯ã€‚æ˜¯çš„ï¼Œè¿™æ˜¯ä¸ªå¥½é—®é¢˜ï¼Œå¯¹äºä¸€äº›ä»»åŠ¡ï¼Œå¦‚æœä½ å·²ç»è§è¿‡ç±»ä¼¼çš„æ•°æ®å’Œé¢„è®­ç»ƒï¼Œæ¨¡å‹å¯ä»¥åšå¾—å¾ˆå¥½ï¼Œå³ä½¿æ€ç»´é“¾æ¥è‡ªå¦ä¸€ä¸ªä»»åŠ¡ï¼Œä¾‹å¦‚ã€‚
- en: like math word problems you actually don't really need a math chain of thought
    because mod already knows how I do that but like for a task like thisã€‚You probably
    haven't seen any data that's like the chain of thought hereã€‚so without task specific
    exemplars you probably wouldn't do super well on tasks like this without manually
    writing them for other examplesã€‚Yeahã€‚as the researcher behind thisï¼Œ like what
    mental model would we do to like even try this like do you pursue the model as
    like if I was a personã€‚
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: åƒæ•°å­¦æ–‡å­—é—®é¢˜ï¼Œä½ å…¶å®ä¸éœ€è¦æ•°å­¦æ€ç»´é“¾ï¼Œå› ä¸ºæ¨¡å‹å·²ç»çŸ¥é“æˆ‘æ€ä¹ˆåšï¼Œä½†åƒè¿™æ ·çš„ä»»åŠ¡ï¼Œä½ å¯èƒ½æ²¡æœ‰è§è¿‡ç±»ä¼¼æ€ç»´é“¾çš„æ•°æ®ã€‚å› æ­¤ï¼Œæ²¡æœ‰ç‰¹å®šä»»åŠ¡çš„ç¤ºä¾‹ï¼Œä½ å¯èƒ½åœ¨è¿™æ ·çš„ä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ï¼Œé™¤éæ‰‹åŠ¨ä¸ºå…¶ä»–ç¤ºä¾‹ç¼–å†™ã€‚æ˜¯çš„ã€‚ä½œä¸ºè¿™ä¸ªç ”ç©¶çš„èƒŒåï¼Œåƒæˆ‘ä»¬åº”è¯¥ç”¨ä»€ä¹ˆå¿ƒç†æ¨¡å‹å»å°è¯•å‘¢ï¼Ÿä½ æ˜¯å¦æŠŠæ¨¡å‹å½“ä½œä¸€ä¸ªäººã€‚
- en: how do I think it's better or is it like trying to give it more likeï¼ŸCompute
    in order to likeã€‚Before deesttiy answeredã€‚Yeahï¼Œ great questionã€‚I think my motivation
    was just thinking about it says you said like what's going on in sort of a human's
    mind while they try to solve this math question and well if you notice like at
    least some humans will think actually in natural language so like if you just
    like think about like if you pay attention a lot to like what's going on in your
    mind you' actually notice that you sometimes you think language and so while the
    language model can thinking language too so that was kind of the motivation behind
    asking language while to do that andã€‚
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºè¿™æ˜¯å¦æ›´å¥½ï¼Œæˆ–è€…æ˜¯å¦æ›´åƒæ˜¯è¯•å›¾ç»™äºˆæ›´å¤šçš„è®¡ç®—ï¼Œä»¥ä¾¿äºã€‚åœ¨ deesttiy å›ç­”ä¹‹å‰ã€‚æ˜¯çš„ï¼Œå¤ªå¥½äº†ï¼Œæˆ‘è®¤ä¸ºæˆ‘çš„åŠ¨æœºåªæ˜¯è€ƒè™‘ä½ æ‰€è¯´çš„ï¼Œå½“äººç±»è¯•å›¾è§£å†³è¿™ä¸ªæ•°å­¦é—®é¢˜æ—¶ï¼Œä»–ä»¬çš„è„‘ä¸­å‘ç”Ÿäº†ä»€ä¹ˆã€‚å¦‚æœä½ æ³¨æ„åˆ°ï¼Œè‡³å°‘ä¸€äº›äººç¡®å®ä¼šç”¨è‡ªç„¶è¯­è¨€æ€è€ƒï¼Œæ‰€ä»¥å¦‚æœä½ å¤šå…³æ³¨ä¸€ä¸‹ä½ çš„è„‘ä¸­å‘ç”Ÿäº†ä»€ä¹ˆï¼Œä½ ä¼šå‘ç°æœ‰æ—¶ä½ åœ¨ç”¨è¯­è¨€æ€è€ƒï¼Œè€Œè¯­è¨€æ¨¡å‹ä¹Ÿèƒ½ç”¨è¯­è¨€æ€è€ƒï¼Œå› æ­¤è¿™å°±æ˜¯è®©æˆ‘è¯¢é—®è¯­è¨€æ¨¡å‹è¿™æ ·åšçš„åŠ¨æœºã€‚
- en: I think one thing that sort of went well is that the development of like this
    technique actually coincided with like the development of palm and soã€‚Yeahï¼Œ basically
    having the model palm sort of allowed us to do a lot better tasks or a lot more
    challenging tasks using chain of thoughtã€‚
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºä¸€ä»¶äº‹æƒ…åšå¾—ä¸é”™çš„æ˜¯ï¼Œè¿™é¡¹æŠ€æœ¯çš„å‘å±•å®é™…ä¸Šä¸ palm çš„å‘å±•ç›¸å»åˆã€‚å› æ­¤ï¼ŒåŸºæœ¬ä¸Šï¼Œæ‹¥æœ‰ palm æ¨¡å‹ä½¿æˆ‘ä»¬èƒ½å¤Ÿæ›´å¥½åœ°å®Œæˆå¾ˆå¤šä»»åŠ¡æˆ–æ›´å¤šæŒ‘æˆ˜æ€§ä»»åŠ¡ï¼Œåˆ©ç”¨æ€ç»´é“¾ã€‚
- en: Yeahã€‚æˆ‘å¬èšŠ theç¬¬ä¸€ä¸ªã€‚We're saying that it matters like the absolute number of examples
    of like this chain of thought process or whatever in the data setã€‚Or the functionã€‚s
    that the main significant thing or is it like this a relative numberï¼Ÿ
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ã€‚æˆ‘å¬åˆ°çš„ç¬¬ä¸€ä¸ªã€‚æˆ‘ä»¬è¯´è¿™å¾ˆé‡è¦ï¼Œæ¯”å¦‚åœ¨æ•°æ®é›†ä¸­è¿™ä¸ªé“¾æ€ç»´è¿‡ç¨‹çš„ç»å¯¹ä¾‹å­æ•°é‡ã€‚æˆ–è€…è¿™ä¸ªåŠŸèƒ½ã€‚æ˜¯ä¸»è¦çš„æ˜¾è‘—äº‹ç‰©ï¼Œè¿˜æ˜¯ç›¸å¯¹æ•°é‡ï¼Ÿ
- en: Fqu of like those examples are just like negative examples that are like not
    good examples of how to reasonã€‚Do those matter as much as the absolute number
    ofã€‚å•Šï¼Œè¿™ç¬¬3ã€‚Yeahï¼Œ good questionã€‚So I guess the challenging thing is like we can't
    really measure how many similar examples are in the training set you knowã€‚It's
    it's hard to do that wellã€‚ and I don't think anyone has done that beforeã€‚
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›ç¤ºä¾‹ä¸­çš„ä¸€éƒ¨åˆ†åªæ˜¯ä¸€äº›è´Ÿé¢ç¤ºä¾‹ï¼Œä¸æ˜¯å¾ˆå¥½çš„æ¨ç†ç¤ºä¾‹ã€‚è¿™äº›ä¸ç»å¯¹æ•°é‡ä¸€æ ·é‡è¦å—ï¼Ÿå•Šï¼Œè¿™ç¬¬3ã€‚æ˜¯çš„ï¼Œå¥½çš„é—®é¢˜ã€‚æ‰€ä»¥æˆ‘æƒ³å…·æœ‰æŒ‘æˆ˜æ€§çš„æ˜¯ï¼Œæˆ‘ä»¬å®é™…ä¸Šæ— æ³•æµ‹é‡è®­ç»ƒé›†ä¸­æœ‰å¤šå°‘ç±»ä¼¼ç¤ºä¾‹ã€‚ä½ çŸ¥é“ã€‚è¿™å¾ˆéš¾åšåˆ°ï¼Œæˆ‘è®¤ä¸ºä»¥å‰æ²¡æœ‰äººåšåˆ°è¿‡ã€‚
- en: So it's more of this open question of like why China F thought even works because
    you actually don't seeã€‚Similar data like that in the training setã€‚Yeahï¼Œ I think
    it's a open question like why it worksã€‚what is your modelã€‚Theition that mean said
    okayã€‚Think about like howã€‚thingsã€‚Thinking language and then knowledge do that
    tooã€‚ But likeï¼Œ how do you actually think like in likeã€‚
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™æ›´å¤šæ˜¯ä¸€ä¸ªå¼€æ”¾çš„é—®é¢˜ï¼Œæ¯”å¦‚ä¸ºä»€ä¹ˆä¸­å›½Fæ€ç»´æœ‰æ•ˆï¼Œå› ä¸ºå®é™…ä¸Šä½ å¹¶æ²¡æœ‰åœ¨è®­ç»ƒé›†ä¸­çœ‹åˆ°ç±»ä¼¼çš„æ•°æ®ã€‚æ˜¯çš„ï¼Œæˆ‘è®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªå¼€æ”¾çš„é—®é¢˜ï¼Œä¸ºä»€ä¹ˆå®ƒæœ‰æ•ˆã€‚ä½ çš„æ¨¡å‹æ˜¯ä»€ä¹ˆï¼Ÿè¿™ä¸ªæ„æ€å°±æ˜¯å¥½çš„ã€‚æƒ³æƒ³åƒå¦‚ä½•ã€‚äº‹æƒ…ã€‚æ€è€ƒè¯­è¨€ï¼Œç„¶åçŸ¥è¯†ä¹Ÿæ˜¯è¿™æ ·ã€‚ä½†ä½ å®é™…ä¸Šæ˜¯å¦‚ä½•æ€è€ƒçš„ï¼Œå°±åƒåœ¨é‚£æ ·ã€‚
- en: what a situation for the modelã€‚I meanï¼Œ is make a shift inã€‚For a specific taskã€‚like
    some weights get like moreã€‚å¥½é€ç¿»è¿‡åšŸæ‰£é›¨ç‚¹å•Šã€‚Yeahï¼Œ I don't really think about it in terms
    of like what's going on in the weightsã€‚I guess the way that I think about it is
    that likeã€‚It'd be unfair for me to like give you a math question and ask you to
    give me the answer within like half a secondã€‚
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ¨¡å‹æ¥è¯´ï¼Œè¿™æ˜¯ä»€ä¹ˆæƒ…å†µã€‚æˆ‘æ˜¯è¯´ï¼Œä¼šåœ¨ç‰¹å®šä»»åŠ¡ä¸­å‘ç”Ÿè½¬å˜ã€‚å°±åƒä¸€äº›æƒé‡ä¼šå˜å¾—æ›´ã€‚å¥½é€ç¿»è¿‡æ¥æ‰£é›¨ç‚¹å•Šã€‚æ˜¯çš„ï¼Œæˆ‘å¹¶ä¸çœŸçš„è€ƒè™‘æƒé‡ä¸­çš„äº‹æƒ…ã€‚æˆ‘æƒ³æˆ‘æ€è€ƒçš„æ–¹å¼æ˜¯ï¼Œç»™ä½ ä¸€ä¸ªæ•°å­¦é—®é¢˜ï¼Œè®©ä½ åœ¨åŠç§’å†…ç»™æˆ‘ç­”æ¡ˆï¼Œè¿™æ˜¯ä¸å…¬å¹³çš„ã€‚
- en: which is basically like what you're doing with the model and when you don't
    do a chain of that right' basically asking this like challenging question and
    the model doesn't have enough compute to like solve it in one pass to give you
    the next answer immediatelyã€‚
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åŸºæœ¬ä¸Šå°±åƒä½ ä¸æ¨¡å‹æ‰€åšçš„äº‹æƒ…ï¼Œå½“ä½ æ²¡æœ‰æ­£ç¡®æ‰§è¡Œé“¾æ€ç»´æ—¶ï¼ŒåŸºæœ¬ä¸Šæ˜¯åœ¨æå‡ºè¿™ä¸ªæŒ‘æˆ˜æ€§çš„é—®é¢˜ï¼Œè€Œæ¨¡å‹æ²¡æœ‰è¶³å¤Ÿçš„è®¡ç®—èƒ½åŠ›æ¥ä¸€æ¬¡æ€§è§£å†³å®ƒï¼Œç«‹å³ç»™ä½ ä¸‹ä¸€ä¸ªç­”æ¡ˆã€‚
- en: I think the second thing thatã€‚I sort of think about is that like the model has
    learned like a compositional set of skills during during pretraining so maybe
    it hasn't really learned like you know this particular navigate task during pre
    traininging but's learn other things right it's learn like okay if you take five
    steps and you're facing this maybe yeah you should add five here or something
    like that right and it's learned how to do pattern matching soã€‚
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºç¬¬äºŒä»¶äº‹å°±æ˜¯ï¼Œæˆ‘ä¼šè€ƒè™‘æ¨¡å‹åœ¨é¢„è®­ç»ƒæœŸé—´å­¦ä¹ äº†ä¸€ç»„ç»„åˆæŠ€èƒ½ï¼Œæ‰€ä»¥ä¹Ÿè®¸å®ƒå¹¶æ²¡æœ‰çœŸæ­£å­¦ä¹ è¿™ä¸ªç‰¹å®šçš„å¯¼èˆªä»»åŠ¡ï¼Œä½†å®ƒå­¦åˆ°äº†å…¶ä»–ä¸œè¥¿ã€‚å¯¹å§ï¼Ÿå®ƒå­¦ä¼šäº†ï¼Œæ¯”å¦‚è¯´å¦‚æœä½ èµ°äº”æ­¥ï¼Œé¢å¯¹è¿™ä¸ªï¼Œä¹Ÿè®¸æ˜¯çš„ï¼Œä½ åº”è¯¥åœ¨è¿™é‡ŒåŠ äº”ï¼Œæˆ–è€…ç±»ä¼¼çš„ï¼Œå®ƒå­¦ä¼šäº†å¦‚ä½•è¿›è¡Œæ¨¡å¼åŒ¹é…ã€‚
- en: Maybe in the future exemplars it can match sort of what the reasoning path is
    with like what the question was and sort of there's sort of these little skills
    that the model might know and then maybe if you can combine them together in some
    clever way then you can get the model to solve the more challenging problemsã€‚
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹Ÿè®¸åœ¨æœªæ¥çš„ç¤ºä¾‹ä¸­ï¼Œå®ƒå¯ä»¥åŒ¹é…æ¨ç†è·¯å¾„å’Œé—®é¢˜ä¹‹é—´çš„å…³ç³»ï¼Œæ¨¡å‹å¯èƒ½çŸ¥é“è¿™äº›å°æŠ€èƒ½ï¼Œå¦‚æœä½ èƒ½å¤Ÿä»¥æŸç§å·§å¦™çš„æ–¹å¼å°†å®ƒä»¬ç»“åˆåœ¨ä¸€èµ·ï¼Œé‚£ä¹ˆä½ å°±å¯ä»¥è®©æ¨¡å‹è§£å†³æ›´å…·æŒ‘æˆ˜æ€§çš„é—®é¢˜ã€‚
- en: Okayã€‚ran how much time do we haveï¼Ÿå“¦ï¼ŒåŸä¹Ÿå®¡çœ‹çš„çœ‹ã€‚okayï¼Œ50 okayã€‚Okayã€‚ã£ã¦ã€‚è¯¶ okayï¼Œ greatã€‚A
    a good example of how we judge this cutã€‚Anywayï¼Œ a bunch of different answersï¼Œ
    all them are rightã€‚Yeahã€‚Okayï¼Œ greatï¼Œ yeahï¼Œ feel free to keep asking questions
    if you have anyã€‚Soã€‚Yeahã€‚here's another example of emergence so basically you can
    see there's three models here instructTBT codex and palm chain of thought in blue
    non chainF thought is is in gray and then you can see you actually have to have
    sufficient model scale to get chainF thought to work well andã€‚
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ã€‚æˆ‘ä»¬è¿˜æœ‰å¤šå°‘æ—¶é—´ï¼Ÿå“¦ï¼ŒåŸæ¥ä¹Ÿå®¡çœ‹çš„çœ‹ã€‚å¥½çš„ï¼Œ50å¥½çš„ã€‚å¥½çš„ã€‚å—¯ï¼Œå¥½çš„ã€‚ä¸€ä¸ªåˆ¤æ–­è¿™ä¸ªåˆ‡å‰²çš„å¥½ä¾‹å­ã€‚æ— è®ºå¦‚ä½•ï¼Œå¾ˆå¤šä¸åŒçš„ç­”æ¡ˆï¼Œéƒ½æ˜¯æ­£ç¡®çš„ã€‚æ˜¯çš„ã€‚å¥½çš„ï¼Œå¾ˆå¥½ï¼Œå¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜ï¼Œè¯·éšæ—¶é—®ã€‚æ˜¯çš„ã€‚è¿™æ˜¯å¦ä¸€ä¸ªæ¶Œç°çš„ä¾‹å­ï¼Œæ‰€ä»¥åŸºæœ¬ä¸Šä½ å¯ä»¥çœ‹åˆ°è¿™é‡Œæœ‰ä¸‰ä¸ªæ¨¡å‹ï¼šinstructTBTã€codexå’Œpalmï¼Œé“¾æ€ç»´æ˜¯è“è‰²ï¼Œéé“¾Fæ€ç»´æ˜¯ç°è‰²ï¼Œç„¶åä½ å¯ä»¥çœ‹åˆ°å®é™…ä¸Šä½ å¿…é¡»æœ‰è¶³å¤Ÿçš„æ¨¡å‹è§„æ¨¡æ‰èƒ½è®©é“¾Fæ€ç»´è¿ä½œè‰¯å¥½ã€‚
- en: I guess the intuition here is that like if you have a really small modelã€‚the
    model sort of will keep repeating itself for not saying anything coherent or navigate
    a final answerã€‚which is why using chain of Thought for the small models doesn't
    really work well and then for the large models obviously like for multistep problemsã€‚the
    model is going to be able to solve the task at a lot higher accuracy with chain
    of thoughtã€‚
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æƒ³è¿™é‡Œçš„ç›´è§‰æ˜¯ï¼Œå¦‚æœä½ æœ‰ä¸€ä¸ªéå¸¸å°çš„æ¨¡å‹ï¼Œæ¨¡å‹ä¼šä¸æ–­é‡å¤è‡ªå·±ï¼Œæ— æ³•ç»™å‡ºè¿è´¯çš„å›ç­”æˆ–æ‰¾åˆ°æœ€ç»ˆç­”æ¡ˆã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆåœ¨å°æ¨¡å‹ä¸­ä½¿ç”¨æ€ç»´é“¾æ•ˆæœä¸ä½³ï¼Œè€Œå¯¹äºå¤§æ¨¡å‹ï¼Œæ˜¾ç„¶åœ¨å¤šæ­¥éª¤é—®é¢˜ä¸­ï¼Œæ¨¡å‹èƒ½å¤Ÿä»¥æ›´é«˜çš„å‡†ç¡®æ€§è§£å†³ä»»åŠ¡ã€‚
- en: And another cool thing about chain of Though is there are sort of some tasks
    where you sort of wouldn't get emergent behavior at allã€‚so emergence hasn't been
    unlocked yetï¼Œ but you can see that the if you use chainF thought you can unlock
    this emergent performance in smaller modelsã€‚
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºæ€ç»´é“¾çš„å¦ä¸€ä¸ªæœ‰è¶£ä¹‹å¤„æ˜¯ï¼Œæœ‰äº›ä»»åŠ¡æ ¹æœ¬ä¸ä¼šå‡ºç°çªç°è¡Œä¸ºã€‚å› æ­¤ï¼Œçªç°å°šæœªè¢«æ¿€å‘ï¼Œä½†å¦‚æœä½ ä½¿ç”¨æ€ç»´é“¾ï¼Œå¯ä»¥åœ¨è¾ƒå°æ¨¡å‹ä¸­è§£é”è¿™ç§çªç°æ€§èƒ½ã€‚
- en: One example here is like multistep arithmetic where like I don't know if you'll
    everã€‚you know maybe I don't want to say everï¼Œ but like you can it's hard to imagine
    a model like getting thisã€‚you know here's the question and then the next token
    is correct that's pretty hard to solve in one step but with chain of thought you
    can get like you know 50% accuracy on this just by having the model output' these
    intermediate intermediate recent stepsã€‚
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªä¾‹å­æ˜¯å¤šæ­¥éª¤ç®—æœ¯ï¼Œæˆ‘ä¸çŸ¥é“ä½ æ˜¯å¦èƒ½åšåˆ°ã€‚ä½ çŸ¥é“ï¼Œä¹Ÿè®¸æˆ‘ä¸æƒ³è¯´æ°¸è¿œï¼Œä½†å¾ˆéš¾æƒ³è±¡ä¸€ä¸ªæ¨¡å‹èƒ½å®Œæˆè¿™ä¸ªã€‚ä½ çŸ¥é“è¿™æ˜¯é—®é¢˜ï¼Œç„¶åä¸‹ä¸€ä¸ªä»¤ç‰Œæ˜¯æ­£ç¡®çš„ï¼Œè¿™åœ¨ä¸€æ­¥å†…è§£å†³èµ·æ¥ç›¸å½“å›°éš¾ï¼Œä½†é€šè¿‡æ€ç»´é“¾ï¼Œä½ å¯ä»¥ä»…é€šè¿‡è®©æ¨¡å‹è¾“å‡ºè¿™äº›ä¸­é—´æ­¥éª¤æ¥è¾¾åˆ°çº¦50%çš„å‡†ç¡®ç‡ã€‚
- en: Oh yeahã€‚This is something that like needs a rehatuition about whatã€‚lyã€‚I know
    that like a transformer can definitely do additionã€‚ã§ã¾ãŸã€‚Can like take in the numbers
    and like do the carriesã€‚Defitelyï¼Œ Yeahï¼Œ yeahï¼Œ but likeã€‚å“¦ã€‚Then there's this question
    of likeï¼Œ what happens empiricallyï¼Œ rightï¼Ÿ And likeã€‚
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: å“¦ï¼Œå¯¹ã€‚è¿™æ˜¯éœ€è¦é‡æ–°æ€è€ƒçš„ä¸€ä»¶äº‹ã€‚æˆ‘çŸ¥é“å˜æ¢å™¨è‚¯å®šèƒ½è¿›è¡ŒåŠ æ³•ã€‚è€Œä¸”èƒ½æ¥æ”¶æ•°å­—å¹¶è¿›è¡Œè¿›ä½ã€‚æ²¡é”™ï¼Œæ²¡é”™ï¼Œä½†æ¥ä¸‹æ¥æœ‰ä¸ªé—®é¢˜ï¼Œå®é™…ä¸Šä¼šå‘ç”Ÿä»€ä¹ˆï¼Œå¯¹å§ï¼Ÿ
- en: I understand that likeï¼Œ it isn't necessarily a lot space to do public protectã€‚Yeahã€‚So
    like my question is likeï¼Œ howã€‚I reallyã€‚Tell the differenceã€‚Like maybe there are
    there like ways to tell the difference between like things that haven't emerged
    because likeã€‚there's just like no spaceã€‚Or like like like there's so many tasks
    that like it couldn have like allotted any any space to specifically do that one
    versus like like the task is so hard that likeã€‚
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ˜ç™½è¿™ä¸æ˜¯ä¸€ä¸ªå¾ˆå¤§çš„ç©ºé—´æ¥è¿›è¡Œå…¬å…±ä¿æŠ¤ã€‚æ‰€ä»¥æˆ‘çš„é—®é¢˜æ˜¯ï¼Œå¦‚ä½•æ‰èƒ½çœŸæ­£åŒºåˆ†å‘¢ï¼Ÿä¹Ÿè®¸æœ‰äº›æ–¹æ³•å¯ä»¥åŒºåˆ†é‚£äº›å› ä¸ºç©ºé—´ä¸è¶³è€Œæœªå‡ºç°çš„ä»»åŠ¡ï¼Œæˆ–è€…ä»»åŠ¡å¦‚æ­¤ä¹‹å¤šï¼Œä»¥è‡³äºæ²¡æœ‰ä¸“é—¨çš„ç©ºé—´æ¥å¤„ç†é‚£ä¸ªä»»åŠ¡ã€‚
- en: It just can'tï¼Œ even if you willã€‚Yeahï¼Œ yeahï¼Œ that's a good question I thinkã€‚There
    seems to be like some subset of tasks where it's just like doesn't fit well with
    the way that we train language modelsã€‚so for example likeã€‚In language modelsï¼Œ
    we use tokensï¼Œ rightï¼Ÿ And so if you give it likeã€‚The token  four actually doesn't
    take the number fourã€‚
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒå°±æ˜¯æ— æ³•åšåˆ°ï¼Œå³ä½¿ä½ æ„¿æ„ã€‚æ˜¯çš„ï¼Œæ˜¯ä¸ªå¥½é—®é¢˜ã€‚æˆ‘è®¤ä¸ºä¼¼ä¹æœ‰ä¸€äº›ä»»åŠ¡æ ¹æœ¬ä¸é€‚åˆæˆ‘ä»¬è®­ç»ƒè¯­è¨€æ¨¡å‹çš„æ–¹å¼ã€‚ä¾‹å¦‚ï¼Œåœ¨è¯­è¨€æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯ä»¤ç‰Œï¼Œå¯¹å§ï¼Ÿæ‰€ä»¥å¦‚æœä½ ç»™å®ƒï¼Œæ¯”å¦‚ä»¤ç‰Œå››ï¼Œå®ƒå®é™…ä¸Šå¹¶ä¸æ¥æ”¶æ•°å­—å››ã€‚
- en: it takes like this embedding that's like you know 1000 dimensions or something
    or if you like give it a word and ask it to reverse like the lettersã€‚this is like
    a super easy testï¼Œ but like the way we train the model doesn't actually look at
    the letters and stuffã€‚
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒéœ€è¦ä¸€ä¸ªå¤§çº¦1000ç»´çš„åµŒå…¥ï¼Œæˆ–è€…å¦‚æœä½ ç»™å®ƒä¸€ä¸ªå•è¯å¹¶è¦æ±‚å®ƒåè½¬å­—æ¯ã€‚è¿™æ˜¯ä¸€ä¸ªè¶…çº§ç®€å•çš„æµ‹è¯•ï¼Œä½†æˆ‘ä»¬è®­ç»ƒæ¨¡å‹çš„æ–¹å¼å®é™…ä¸Šå¹¶æ²¡æœ‰å…³æ³¨å­—æ¯ç­‰å†…å®¹ã€‚
- en: So I think there's a certain subset of tasks where like it doesn't really just
    fit well with the way that we train transformers andã€‚You can actually like I mean
    I think these if you really care about these tasks you can just solve them using
    like code or something like thatã€‚
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘è®¤ä¸ºæœ‰ä¸€éƒ¨åˆ†ä»»åŠ¡ä¸æˆ‘ä»¬è®­ç»ƒå˜æ¢å™¨çš„æ–¹å¼å¹¶ä¸å®Œå…¨å¥‘åˆã€‚å®é™…ä¸Šï¼Œå¦‚æœä½ çœŸçš„å…³æ³¨è¿™äº›ä»»åŠ¡ï¼Œä½ å¯ä»¥ç”¨ä»£ç ä¹‹ç±»çš„æ–¹å¼è§£å†³å®ƒä»¬ã€‚
- en: but yeah I think I don't think like this is really an inherentã€‚Something that
    would never emerge because it's too hardï¼Œ yeahã€‚Yeahã€‚we have a question on zoom
    also by the wayï¼Œ sorry I forgot to mention somebody asking you repeat repeat the
    questions because they can't always Oh okayã€‚that's why that that's why that so
    the question someone asked isã€‚
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘è®¤ä¸ºè¿™å¹¶ä¸æ˜¯ä¸€ç§å†…åœ¨çš„ä¸œè¥¿ã€‚æ˜¯ä¸ä¼šå‡ºç°çš„ï¼Œå› ä¸ºè¿™å¤ªéš¾äº†ã€‚å¯¹äº†ï¼Œæˆ‘ä»¬åœ¨Zoomä¸Šä¹Ÿæœ‰ä¸€ä¸ªé—®é¢˜ï¼ŒæŠ±æ­‰æˆ‘å¿˜äº†æåˆ°ï¼Œæœ‰äººé—®ä½ èƒ½å¦é‡å¤ä¸€ä¸‹é—®é¢˜ï¼Œå› ä¸ºä»–ä»¬ä¸æ€»æ˜¯å¬å¾—æ¸…ã€‚å“¦ï¼Œå¥½çš„ã€‚å°±æ˜¯è¿™ä¸ªï¼Œæ‰€ä»¥æœ‰äººé—®çš„é—®é¢˜æ˜¯ã€‚
- en: do you think chain of thought would be a viable interpretability technique for
    very advanced AI systemsï¼Ÿ
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ è®¤ä¸ºæ€ç»´é“¾ä¼šæˆä¸ºéå¸¸å…ˆè¿›çš„AIç³»ç»Ÿçš„å¯è§£é‡Šæ€§æŠ€æœ¯å—ï¼Ÿ
- en: And they mentioned that there's some research by called externalized reasoning
    oversight by camera Laã€‚Will it be a viable interpretability technique for advanced
    day onï¼ŸYeahã€‚am I supposed to repeat this sorry oh so the question isã€‚Can chain
    of thought be a viable interpretability technique for AIã€‚
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: ä»–ä»¬æåˆ°æœ‰ä¸€äº›ç ”ç©¶ï¼Œå«åšâ€œå¤–éƒ¨åŒ–æ¨ç†ç›‘ç£â€ï¼Œæ˜¯ç”±Camera Laåšçš„ã€‚å®ƒä¼šæˆä¸ºå…ˆè¿›AIçš„å¯è§£é‡Šæ€§æŠ€æœ¯å—ï¼Ÿæ˜¯çš„ã€‚æˆ‘æ˜¯ä¸æ˜¯è¦é‡å¤è¿™ä¸ªï¼ŸæŠ±æ­‰ï¼Œæ‰€ä»¥é—®é¢˜æ˜¯ï¼šæ€ç»´é“¾èƒ½æˆä¸ºAIçš„å¯è§£é‡Šæ€§æŠ€æœ¯å—ï¼Ÿ
- en: I think there's no guarantee that likeã€‚The chain of thought is how the model
    actually arrives at the final answerã€‚but often you can use it to like sort of
    debug like why isn't the model getting this question correct or like what can
    we do better in the chain of thought to help the model get this correctï¼Ÿ
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºæ²¡æœ‰ä¿è¯ä¼šè¿™æ ·ã€‚æ€ç»´é“¾æ˜¯æ¨¡å‹å¦‚ä½•æœ€ç»ˆå¾—å‡ºç­”æ¡ˆçš„è¿‡ç¨‹ã€‚ä½†é€šå¸¸ä½ å¯ä»¥ç”¨å®ƒæ¥è°ƒè¯•ï¼Œæ¯”å¦‚ä¸ºä»€ä¹ˆæ¨¡å‹æ²¡æœ‰æ­£ç¡®å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œæˆ–è€…æˆ‘ä»¬èƒ½åšäº›ä»€ä¹ˆæ¥æ”¹å–„æ€ç»´é“¾ï¼Œå¸®åŠ©æ¨¡å‹æ­£ç¡®å›ç­”ï¼Ÿ
- en: I haven't read the anthropic paper that was mentionedï¼Œ so I actually don't know
    the answer to thatã€‚å—¯ ok k ã€‚Another interesting result that we had here was that
    you can actually do like multilingual chain of thought prompting and so basically
    what we had is like we translated this like you know benchmark of math word problems
    to 10 languages and then we prompt them the model to do it in like say Bengali
    and then the model has like basically do the math problem in Bengali and give
    the final answerã€‚
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è¿˜æ²¡æœ‰é˜…è¯»æåˆ°çš„ä¸äººç±»æœ‰å…³çš„è®ºæ–‡ï¼Œæ‰€ä»¥æˆ‘å®é™…ä¸Šä¸çŸ¥é“ç­”æ¡ˆã€‚å—¯ï¼Œå¥½å§ã€‚æˆ‘ä»¬è¿™é‡Œè¿˜æœ‰ä¸€ä¸ªæœ‰è¶£çš„ç»“æœæ˜¯ï¼Œä½ å®é™…ä¸Šå¯ä»¥è¿›è¡Œå¤šè¯­è¨€çš„æ€ç»´é“¾æç¤ºï¼ŒåŸºæœ¬ä¸Šæˆ‘ä»¬åšçš„å°±æ˜¯å°†è¿™ä¸ªæ•°å­¦æ–‡å­—é—®é¢˜çš„åŸºå‡†ç¿»è¯‘æˆ10ç§è¯­è¨€ï¼Œç„¶åæˆ‘ä»¬æç¤ºæ¨¡å‹åœ¨ï¼Œæ¯”å¦‚å­ŸåŠ æ‹‰è¯­ä¸­è¿›è¡Œæ“ä½œï¼Œæ¨¡å‹åŸºæœ¬ä¸Šè¦ç”¨å­ŸåŠ æ‹‰è¯­è§£å†³æ•°å­¦é—®é¢˜å¹¶ç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚
- en: I think the cool thing about this is that like this input is like highly improbable
    right so like Benngali is like 0ã€‚01% of the pre trainingion data and you know
    math word problems are probably even smaller subset of thatã€‚ğŸ˜Šï¼ŒAnd basically the
    interesting thing is the model can actually do like these types of questions pretty
    well to probably surprising degreeã€‚so like you know if you ask people before I
    showed them this result like oh how well can the model do you like these math
    questions in Swahliã€‚
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºè¿™å¾ˆé…·çš„ä¸€ç‚¹æ˜¯ï¼Œè¿™ç§è¾“å…¥æ˜¯é«˜åº¦ä¸å¯èƒ½çš„ï¼Œå¯¹å§ï¼Œå­ŸåŠ æ‹‰è¯­åœ¨é¢„è®­ç»ƒæ•°æ®ä¸­åªå 0.01%ï¼Œè€Œæ•°å­¦æ–‡å­—é—®é¢˜å¯èƒ½æ˜¯å…¶ä¸­æ›´å°çš„ä¸€ä¸ªå­é›†ã€‚ğŸ˜Šè€Œä¸”æœ‰è¶£çš„æ˜¯ï¼Œæ¨¡å‹å®é™…ä¸Šèƒ½ç›¸å½“å¥½åœ°å¤„ç†è¿™äº›ç±»å‹çš„é—®é¢˜ï¼Œå¯èƒ½å‡ºä¹æ„æ–™åœ°å¥½ã€‚æ‰€ä»¥åœ¨æˆ‘ç»™ä»–ä»¬å±•ç¤ºè¿™ä¸ªç»“æœä¹‹å‰ï¼Œå¦‚æœä½ é—®äººä»¬ï¼Œå“¦ï¼Œæ¨¡å‹åœ¨æ–¯ç“¦å¸Œé‡Œè¯­ä¸­èƒ½å¤šå¥½åœ°å¤„ç†è¿™äº›æ•°å­¦é—®é¢˜ã€‚
- en: like probably like 10%ï¼Œ but actually even like you know very underrepresented
    languages like Swahli or Bengali or Telegu and TIã€‚the model can do to like surprisingly
    well despite the fact that they only occupy like a very small subset of the pretraining
    dataã€‚
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§æ¦‚æœ‰10%ï¼Œä½†å®é™…ä¸Šå³ä½¿æ˜¯éå¸¸å°‘æ•°ä»£è¡¨æ€§çš„è¯­è¨€ï¼Œæ¯”å¦‚æ–¯ç“¦å¸Œé‡Œè¯­ã€å­ŸåŠ æ‹‰è¯­æˆ–æ³°å¢å›ºè¯­ï¼Œæ¨¡å‹ä¹Ÿèƒ½åšå¾—å‡ºä¹æ„æ–™åœ°å¥½ï¼Œå°½ç®¡å®ƒä»¬åœ¨é¢„è®­ç»ƒæ•°æ®ä¸­åªå å¾ˆå°çš„ä¸€éƒ¨åˆ†ã€‚
- en: å¯¹ã€‚this and most of my experience with this is Gã€‚but like if you ask things in
    different languagesã€‚despite not being like explicitly trained these languagesï¼Œ
    rightã€‚it seems to have sort of like derived reasoning independent languageï¼Œ to
    that extentã€‚Yeah you can do the reasoning actually kind of funny sometimes it
    always looks like it does the reasoning in English and then translates back to
    the other language answers it gives you sort of like if you like reason the English
    and then translate to the other thingã€‚
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹ã€‚æˆ‘çš„å¤§éƒ¨åˆ†ç»éªŒéƒ½æ˜¯å…³äºGçš„ã€‚ä½†æ˜¯å¦‚æœä½ ç”¨ä¸åŒçš„è¯­è¨€æé—®ï¼Œå°½ç®¡æ²¡æœ‰è¿›è¡Œæ˜¾å¼è®­ç»ƒï¼Œæ¨¡å‹ä¼¼ä¹æœ‰ä¸€ç§ç‹¬ç«‹äºè¯­è¨€çš„æ¨ç†èƒ½åŠ›ã€‚æ˜¯çš„ï¼Œæ¨ç†ç¡®å®æœ‰ç‚¹æœ‰è¶£ï¼Œæœ‰æ—¶å®ƒçœ‹èµ·æ¥æ€»æ˜¯ç”¨è‹±è¯­è¿›è¡Œæ¨ç†ï¼Œç„¶åå†ç¿»è¯‘æˆå…¶ä»–è¯­è¨€çš„ç­”æ¡ˆï¼Œå°±åƒä½ ç”¨è‹±è¯­æ¨ç†ç„¶åå†ç¿»è¯‘æˆå…¶ä»–è¯­è¨€ã€‚
- en: So you think that like learning the like structure of a language and learning
    reasoning abilities or like somewhat separate large language models or that like
    it inherently will like learn chain of thought reasoning within that language
    within the structure of the language like the way thought works in that languageã€‚
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä½ è®¤ä¸ºå­¦ä¹ è¯­è¨€çš„ç»“æ„å’Œå­¦ä¹ æ¨ç†èƒ½åŠ›æ˜¯æŸç§ç¨‹åº¦ä¸Šåˆ†å¼€çš„ï¼Œè¿˜æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ä¼šå†…åœ¨åœ°å­¦ä¹ è¯¥è¯­è¨€å†…çš„æ€ç»´é“¾æ¨ç†ï¼ŒåŸºäºè¯¥è¯­è¨€çš„ç»“æ„ï¼Œå°±åƒæ€ç»´åœ¨è¯¥è¯­è¨€ä¸­å¦‚ä½•è¿ä½œã€‚
- en: Yeah that's a great question I'm not sure how to measure thatã€‚but I've definitely
    thought about I think the language I meanã€‚based on these results like you definitely
    you probably didn't have any math questions in Swwakili for the model to learn
    from and I think definitely there's something language agnostic going on where
    the model learns reasoning sort of independently of the language and then it can
    express it in different languages if it needs to Yeahã€‚
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œè¿™æ˜¯ä¸ªå¥½é—®é¢˜ï¼Œæˆ‘ä¸ç¡®å®šæ€ä¹ˆè¡¡é‡è¿™ä¸ªã€‚ä½†æˆ‘ç¡®å®è€ƒè™‘è¿‡ï¼Œæˆ‘è®¤ä¸ºæ ¹æ®è¿™äº›ç»“æœï¼Œä½ åœ¨æ–¯ç“¦å¸Œé‡Œè¯­ä¸­å¯èƒ½æ²¡æœ‰ä»»ä½•æ•°å­¦é—®é¢˜ä¾›æ¨¡å‹å­¦ä¹ ï¼Œè€Œä¸”æˆ‘è®¤ä¸ºç¡®å®æœ‰ä¸€äº›è¯­è¨€æ— å…³çš„ä¸œè¥¿åœ¨èµ·ä½œç”¨ï¼Œæ¨¡å‹åœ¨æ¨ç†æ–¹é¢æ˜¯ç‹¬ç«‹äºè¯­è¨€å­¦ä¹ çš„ï¼Œç„¶åå¦‚æœéœ€è¦ï¼Œå®ƒå¯ä»¥ç”¨ä¸åŒçš„è¯­è¨€è¡¨è¾¾å‡ºæ¥ã€‚æ˜¯çš„ã€‚
- en: but I don't have a I don't think anyone I don't think we know the answer to
    that yetã€‚è¯¶ã€‚Yeahã€‚so so basically like one question that comes up frequently is
    like why does scaling up improve chain of dot and one way of looking at this is
    like we can take a smaller model like P 62b and see like what types of errors
    are fixed from scaling up to 540 billion parameters and you can see that like
    for these three categories that we came up with some of all of them get fixed
    so scaling seems to have this like sort of universal effect on improving different
    types of errors from smaller modelsã€‚
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯æˆ‘æ²¡æœ‰ï¼Œæˆ‘è§‰å¾—æ²¡æœ‰äººï¼Œæˆ‘è®¤ä¸ºæˆ‘ä»¬è¿˜ä¸çŸ¥é“ç­”æ¡ˆã€‚å—¯ã€‚æ˜¯çš„ã€‚æ‰€ä»¥åŸºæœ¬ä¸Šï¼Œæœ‰ä¸€ä¸ªç»å¸¸å‡ºç°çš„é—®é¢˜æ˜¯ï¼Œä¸ºä»€ä¹ˆæ‰©å¤§è§„æ¨¡ä¼šæ”¹å–„æ€ç»´é“¾ï¼Œå…¶ä¸­ä¸€ç§çœ‹æ³•æ˜¯æˆ‘ä»¬å¯ä»¥å–ä¸€ä¸ªè¾ƒå°çš„æ¨¡å‹ï¼Œæ¯”å¦‚P
    62bï¼Œçœ‹çœ‹ä»æ‰©å±•åˆ°5400äº¿å‚æ•°æ—¶ä¿®å¤äº†å“ªäº›ç±»å‹çš„é”™è¯¯ã€‚ä½ å¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬æå‡ºçš„è¿™ä¸‰ç±»é”™è¯¯ä¸­çš„ä¸€äº›éƒ½å¾—åˆ°äº†ä¿®å¤ï¼Œå› æ­¤æ‰©å±•ä¼¼ä¹å¯¹æ”¹å–„è¾ƒå°æ¨¡å‹çš„ä¸åŒç±»å‹é”™è¯¯æœ‰ä¸€ç§æ™®éçš„æ•ˆæœã€‚
- en: And then here's the same handwi who weav diagram and expressed in different
    ways so basically you have like some tasks that are doable with standard prompting
    so in blue and then the goal of chain of thought prompting is to sort of increase
    the set of tasks that we can do so for exampleã€‚
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åè¿™é‡Œæ˜¯åŒä¸€ä¸ªæ‰‹å†™çš„ç»´æ©å›¾ï¼Œä»¥ä¸åŒçš„æ–¹å¼è¡¨è¾¾ã€‚æ‰€ä»¥åŸºæœ¬ä¸Šï¼Œä½ æœ‰ä¸€äº›å¯ä»¥é€šè¿‡æ ‡å‡†æç¤ºå®Œæˆçš„ä»»åŠ¡ï¼Œæ‰€ä»¥ç”¨è“è‰²è¡¨ç¤ºï¼Œç„¶åæ€ç»´é“¾æç¤ºçš„ç›®æ ‡æ˜¯å¢åŠ æˆ‘ä»¬å¯ä»¥æ‰§è¡Œçš„ä»»åŠ¡é›†ã€‚ä¾‹å¦‚ã€‚
- en: now the ones shown in pink include math word problemï¼Œ symbolic reasoning andã€‚Challenging
    common sense reasonã€‚Yeahï¼Œ questionï¼Œ have you done anys to figure out how like
    much isã€‚is any of this contribution just because of the fact that you do more
    computations when you put in longer prompts like you knowã€‚like you multiple tasks
    through the model you create multiple inbeddings to likeï¼Œ you knowã€‚
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œç²‰è‰²æ˜¾ç¤ºçš„é‚£äº›åŒ…æ‹¬æ•°å­¦æ–‡å­—é—®é¢˜ã€ç¬¦å·æ¨ç†å’Œå…·æœ‰æŒ‘æˆ˜æ€§çš„å¸¸è¯†æ¨ç†ã€‚æ˜¯çš„ï¼Œé—®é¢˜æ˜¯ï¼Œä½ æœ‰æ²¡æœ‰åšè¿‡ä¸€äº›å®éªŒæ¥å¼„æ¸…æ¥šï¼Œåƒè¿™æ ·çš„è´¡çŒ®åˆ°åº•æœ‰å¤šå°‘æ˜¯å› ä¸ºå½“ä½ è¾“å…¥æ›´é•¿çš„æç¤ºæ—¶è¿›è¡Œæ›´å¤šè®¡ç®—çš„äº‹å®ï¼Œæ¯”å¦‚è¯´ä½ é€šè¿‡æ¨¡å‹åˆ›å»ºå¤šä¸ªåµŒå…¥æ¥å¤„ç†å¤šä¸ªä»»åŠ¡ã€‚
- en: just things and models looking at in a wayï¼Œ Yeahï¼Œ how much would that like to
    be tried non shade of thought prompts with like saying open lengthã€‚Yeahï¼Œ yeahã€‚we
    tried with like X Xï¼Œ X X X or something and doesn't really it doesn't workã€‚So
    I think it's not just about the computeã€‚ I think it's aboutã€‚The language guiding
    the model as part of the reasoningã€‚I seeã€‚
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: åªæ˜¯ä»æ¨¡å‹çš„è§’åº¦æ¥çœ‹ï¼Œæ˜¯çš„ï¼Œé‚£æ ·çš„è¯æƒ³è¦å°è¯•å¤šå¤§ç¨‹åº¦ä¸Šçš„éæ€ç»´é“¾æç¤ºï¼Œæ¯”å¦‚è¯´å¼€æ”¾é•¿åº¦ã€‚æ˜¯çš„ï¼Œæ˜¯çš„ã€‚æˆ‘ä»¬å°è¯•è¿‡åƒXXï¼ŒXX Xä¹‹ç±»çš„ï¼Œä½†å®é™…ä¸Šå¹¶æ²¡æœ‰æ•ˆæœã€‚æ‰€ä»¥æˆ‘è®¤ä¸ºè¿™ä¸ä»…ä»…ä¸è®¡ç®—æœ‰å…³ã€‚æˆ‘è®¤ä¸ºè¿˜ä¸è¯­è¨€å¼•å¯¼æ¨¡å‹ä½œä¸ºæ¨ç†çš„ä¸€éƒ¨åˆ†æœ‰å…³ã€‚æˆ‘æ˜ç™½äº†ã€‚
- en: have you tried like describing the problem in more sales not being shownã€‚I knowã€‚this
    is like a super I'm just very curious about likeï¼Œ So it's like a very interestingã€‚Property
    and emergency is like to beã€‚Yeahï¼Œ you mean like describing the question in three
    different ways and seeing if that describing more instead of explicitly step by
    step and seeing that Yeahã€‚I haven't tried thatï¼Œ but I would be surprised if that
    workedã€‚estDid you try having itã€‚
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ æœ‰æ²¡æœ‰å°è¯•ä»¥æ›´å¤šæ ·çš„æ–¹å¼æè¿°é—®é¢˜ï¼Œè€Œä¸æ˜¯æ˜¾ç¤ºçš„é‚£æ ·ã€‚æˆ‘çŸ¥é“ã€‚è¿™çœŸçš„æ˜¯ä¸€ä¸ªè¶…çº§æœ‰è¶£çš„é—®é¢˜ï¼Œæ‰€ä»¥è¿™å°±æ˜¯ä¸€ç§éå¸¸æœ‰è¶£çš„ç‰¹æ€§å’Œç´§æ€¥æ€§ã€‚æ˜¯çš„ï¼Œä½ æ˜¯è¯´ä»¥ä¸‰ç§ä¸åŒçš„æ–¹å¼æè¿°é—®é¢˜ï¼Œçœ‹çœ‹è¿™ç§æè¿°æ˜¯å¦æ›´å¤šï¼Œè€Œä¸æ˜¯é€æ­¥æ˜ç¡®åœ°æè¿°ï¼Œçœ‹çœ‹é‚£æ ·æ˜¯å¦æœ‰æ•ˆã€‚æ˜¯çš„ã€‚æˆ‘è¿˜æ²¡æœ‰å°è¯•ï¼Œä½†å¦‚æœæœ‰æ•ˆæˆ‘ä¼šæ„Ÿåˆ°æƒŠè®¶ã€‚ä½ è¯•è¿‡è®©å®ƒè¿™æ ·å—ï¼Ÿ
- en: I'll put the answer and then explain its reasoning into that Yeahï¼Œ that doesn't
    work as wellã€‚Yeahã€‚but it depends on the task also so like yeah yeah meã€‚ã“ã„ã¤ã€‚That
    seems to be the caseï¼Œ yeahã€‚Yeahã€‚those reactions be like reasoningï¼Œ it would be
    like just any all that's your calculationã€‚Sort of imagine if it was the answerã€‚Like
    in a wayï¼Œ you knowï¼Œ like in a wayã€‚
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¼šæŠŠç­”æ¡ˆå’Œè§£é‡Šçš„æ¨ç†æ”¾è¿›å»ï¼Œæ˜¯çš„ï¼Œè¿™æ ·åšæ•ˆæœä¸ä½³ã€‚æ˜¯çš„ã€‚ä½†è¿™ä¹Ÿå–å†³äºä»»åŠ¡ï¼Œæ‰€ä»¥æ˜¯çš„ï¼Œæ˜¯çš„æˆ‘ã€‚è¿™ä¸ªå®¶ä¼™ã€‚ä¼¼ä¹ç¡®å®å¦‚æ­¤ï¼Œæ˜¯çš„ã€‚æ˜¯çš„ã€‚é‚£äº›ååº”åƒæ¨ç†ï¼Œå¯èƒ½å°±æ˜¯ä½ çš„è®¡ç®—ã€‚å¯ä»¥æƒ³è±¡ä¸€ä¸‹å¦‚æœè¿™æ˜¯ç­”æ¡ˆã€‚æŸç§ç¨‹åº¦ä¸Šï¼Œä½ çŸ¥é“ï¼Œå°±åƒæŸç§ç¨‹åº¦ä¸Šã€‚
- en: like an in a of chain of soil is like a very structuredã€‚It likeã€‚what if the
    same structures like we do some more randomlyã€‚Yeahï¼Œ you could tryã€‚I would be surprised
    if it works I think like outputting tokens is pretty important for the model yeahã€‚Okayã€‚è¯¶ã€‚So
    we're doing on timeã€‚ Okayï¼Œ greatã€‚ So the last partã€‚
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: å°±åƒæ€ç»´é“¾çš„ä¸€éƒ¨åˆ†éå¸¸ç»“æ„åŒ–ã€‚å®ƒå°±åƒã€‚å¦‚æœç»“æ„ç›¸åŒï¼Œæˆ‘ä»¬å°±æ›´éšæœºä¸€äº›ã€‚æ˜¯çš„ï¼Œä½ å¯ä»¥è¯•è¯•ã€‚æˆ‘ä¼šæƒŠè®¶å®ƒæ˜¯å¦æœ‰æ•ˆï¼Œæˆ‘è®¤ä¸ºè¾“å‡ºæ ‡è®°å¯¹æ¨¡å‹æ¥è¯´æ˜¯ç›¸å½“é‡è¦çš„ï¼Œæ˜¯çš„ã€‚å¥½çš„ã€‚è¯¶ã€‚é‚£ä¹ˆæˆ‘ä»¬æ—¶é—´æ€ä¹ˆæ ·ã€‚å¥½çš„ï¼Œå¤ªå¥½äº†ã€‚é‚£ä¹ˆæœ€åä¸€éƒ¨åˆ†ã€‚
- en: I think is a pretty cool trick with chain of thoughtã€‚So basicallyã€‚ğŸ˜Šï¼Œå—¯ã€‚What people
    usually do is they'll just generate one chain of thought and then they'll take
    the final answer but there's' this nice trick called self consistency where you
    can use like temperature sampling with the model to generate like a bunch of different
    reasoning pads and final answers and then if you just take a majority of vote
    over the final answersã€‚
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºè¿™æ˜¯ä¸€ç§å¾ˆé…·çš„æ€ç»´é“¾æŠ€å·§ã€‚åŸºæœ¬ä¸Šã€‚ğŸ˜Šï¼Œå—¯ã€‚äººä»¬é€šå¸¸ä¼šç”Ÿæˆä¸€æ¡æ€ç»´é“¾ï¼Œç„¶åå¾—å‡ºæœ€ç»ˆç­”æ¡ˆï¼Œä½†æœ‰ä¸€ä¸ªå¾ˆå¥½çš„æŠ€å·§å«åšè‡ªä¸€è‡´æ€§ï¼Œä½ å¯ä»¥ç”¨æ¸©åº¦é‡‡æ ·ä¸æ¨¡å‹ç»“åˆç”Ÿæˆè®¸å¤šä¸åŒçš„æ¨ç†è·¯å¾„å’Œæœ€ç»ˆç­”æ¡ˆï¼Œç„¶åå¦‚æœä½ åªå¯¹æœ€ç»ˆç­”æ¡ˆè¿›è¡Œå¤šæ•°æŠ•ç¥¨ã€‚
- en: this ends up like improving performance by like a pretty big margin soã€‚For exampleï¼Œ
    hereã€‚you can see on GSMAKï¼Œ which is like the MathW Pro data setï¼Œ the improvement
    goes from like you knowã€‚the performance like 56 and then if you do self-con then
    it becomes 74ã€‚which's like a pretty big improvementã€‚å¯¹ã€‚Yeahï¼Œ here how many are
    the averaging number for self consistency Ohã€‚
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æœ€ç»ˆå°±åƒæ˜¯åœ¨æ€§èƒ½ä¸Šæœ‰äº†ç›¸å½“å¤§çš„æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨GSMAKä¸Šï¼Œä½ å¯ä»¥çœ‹åˆ°ï¼Œè¿™å°±åƒMathW Proæ•°æ®é›†ï¼Œæ€§èƒ½ä»56æå‡åˆ°äº†74ï¼Œè¿™å°±æ˜¯ä¸€ä¸ªç›¸å½“å¤§çš„æå‡ã€‚å¯¹ã€‚æ˜¯çš„ï¼Œè¿™é‡Œå…³äºè‡ªä¸€è‡´æ€§çš„å¹³å‡æ•°æœ‰å¤šå°‘å“¦ã€‚
- en: I think 40ã€‚So it increases the cost of the inference time computeï¼Œ butã€‚Yeahã€‚improve
    performance by might not to answer thisï¼Œ I'm curious to know how many samples
    or how many chains does one need to draw to get a significant what is the trade
    off between number of chains averaged overï¼Ÿ
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºæ˜¯40ã€‚å› æ­¤å®ƒå¢åŠ äº†æ¨ç†æ—¶é—´çš„è®¡ç®—æˆæœ¬ï¼Œä½†ã€‚æ˜¯çš„ã€‚æé«˜æ€§èƒ½å¯èƒ½æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘å¾ˆå¥½å¥‡éœ€è¦ç»˜åˆ¶å¤šå°‘æ ·æœ¬æˆ–å¤šå°‘ä¸ªé“¾æ‰èƒ½å¾—åˆ°æ˜¾è‘—ç»“æœï¼Œé“¾çš„æ•°é‡å¹³å‡ä¸‹æ¥æœ‰ä»€ä¹ˆæƒè¡¡ï¼Ÿ
- en: I think it depends on the sorryï¼Œ the question is how many chains do you need
    to get a performance gain I thinkã€‚The answer really depends on the data setï¼Œ but
    usually you can get something good with like 16ã€‚I thinkã€‚Yeahã€‚Im sorryã€‚We have
    a questionã€‚How does the temperature change the way the model workã€‚Oh okayï¼Œ the
    question is how does the temperature change the where the model worksã€‚
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è§‰å¾—è¿™è¦çœ‹ï¼ŒæŠ±æ­‰ï¼Œé—®é¢˜æ˜¯éœ€è¦å¤šå°‘ä¸ªé“¾æ‰èƒ½è·å¾—æ€§èƒ½æå‡ã€‚æˆ‘è®¤ä¸ºç­”æ¡ˆçœŸçš„å–å†³äºæ•°æ®é›†ï¼Œä½†é€šå¸¸ä½ å¯ä»¥ç”¨å¤§çº¦16ä¸ªé“¾è·å¾—ä¸é”™çš„ç»“æœã€‚æˆ‘æƒ³ã€‚æ˜¯çš„ã€‚æŠ±æ­‰ã€‚æˆ‘ä»¬æœ‰ä¸€ä¸ªé—®é¢˜ã€‚æ¸©åº¦å¦‚ä½•æ”¹å˜æ¨¡å‹çš„å·¥ä½œæ–¹å¼ã€‚å“¦ï¼Œå¥½å§ï¼Œé—®é¢˜æ˜¯æ¸©åº¦å¦‚ä½•æ”¹å˜æ¨¡å‹çš„å·¥ä½œæ–¹å¼ã€‚
- en: basically when you use temperature decodingï¼Œ the language model can like stochasticically
    pick one of the outputs instead of always picking the highest probability next
    wordã€‚so basically you get these like more stochastic outputs that are still based
    on what the language model has learnedã€‚
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºæœ¬ä¸Šï¼Œå½“ä½ ä½¿ç”¨æ¸©åº¦è§£ç æ—¶ï¼Œè¯­è¨€æ¨¡å‹å¯ä»¥éšæœºé€‰æ‹©ä¸€ä¸ªè¾“å‡ºï¼Œè€Œä¸æ˜¯æ€»æ˜¯é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„ä¸‹ä¸€ä¸ªå•è¯ã€‚å› æ­¤ï¼ŒåŸºæœ¬ä¸Šä½ ä¼šå¾—åˆ°è¿™äº›æ›´éšæœºçš„è¾“å‡ºï¼Œå®ƒä»¬ä»ç„¶åŸºäºè¯­è¨€æ¨¡å‹æ‰€å­¦åˆ°çš„å†…å®¹ã€‚
- en: but it's just a little bit more randomã€‚Okayã€‚And then like finally like yeah
    selfconsistency also seems to be emergeibilityã€‚I guess part of it is because chain
    of thought is emergingnt because you wouldn't get any better than random performance
    without doing chain of thoughtã€‚
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¿™åªæ˜¯æœ‰ç‚¹éšæœºã€‚å¥½çš„ã€‚æœ€åï¼Œåƒæ˜¯è‡ªä¸€è‡´æ€§ä¼¼ä¹ä¹Ÿæœ‰å¯å‡ºç°æ€§ã€‚æˆ‘æƒ³éƒ¨åˆ†åŸå› æ˜¯æ€ç»´é“¾æ­£åœ¨æ¶Œç°ï¼Œå› ä¸ºå¦‚æœä¸è¿›è¡Œæ€ç»´é“¾ï¼Œä½ çš„è¡¨ç°ä¸ä¼šæ¯”éšæœºæ›´å¥½ã€‚
- en: but yeahï¼Œ you kind of see this big delta from self-consency through larger modelsã€‚å—¯ã€‚ğŸ¼Greatã€‚so
    I'm gonna run out of timeã€‚Let me just go toã€‚I'll just talk about this a little
    bit so I think in addition to just purely scaling up the language model which
    is only available to like people in industryã€‚
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†ä½ ç¡®å®èƒ½çœ‹åˆ°è‡ªä¸€è‡´æ€§é€šè¿‡æ›´å¤§æ¨¡å‹å¸¦æ¥çš„å·¨å¤§å·®å¼‚ã€‚å—¯ã€‚ğŸ¼å¤ªå¥½äº†ã€‚æ‰€ä»¥æˆ‘å¿«æ²¡æ—¶é—´äº†ã€‚è®©æˆ‘ç¨å¾®è°ˆä¸€ä¸‹è¿™ä¸ªï¼Œæˆ‘è®¤ä¸ºé™¤äº†çº¯ç²¹æ‰©å¤§è¯­è¨€æ¨¡å‹çš„è§„æ¨¡ä¹‹å¤–ï¼Œè¿™åœ¨è¡Œä¸šä¸­åªæœ‰ä¸€éƒ¨åˆ†äººèƒ½å¤Ÿåšåˆ°ã€‚
- en: I think there's like a couple interesting directions to to work on one is like
    better prompting and characterization of language modab abilitiesities I think
    right now we're sort of just at the edge of you know knowing what the best way
    to prompt language models isã€‚
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºæœ‰å‡ ä¸ªæœ‰è¶£çš„æ–¹å‘å¯ä»¥æ¢ç´¢ï¼Œä¸€ä¸ªæ˜¯æ›´å¥½åœ°æç¤ºå’Œè¡¨å¾è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œæˆ‘è®¤ä¸ºç°åœ¨æˆ‘ä»¬åªæ˜¯åˆšåˆšè§¦åŠï¼Œäº†è§£æç¤ºè¯­è¨€æ¨¡å‹çš„æœ€ä½³æ–¹å¼ã€‚
- en: There's also like pretty good applied workï¼Œ so like you can use language models
    I've heard to train therapists to help with creative writing to help with scienceã€‚I
    think chatGT has really shown what language models can do in this regardã€‚I think
    benchmarks are also something that's pretty lacking because I think we solve benchmarks
    pretty quicklyã€‚for example Palm beat the average human on Big benchch you know
    within a year or something of big bench coming out and so I think we need more
    benchmarks and I think that's going to be an important contributionã€‚
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰ä¸€äº›ç›¸å½“ä¸é”™çš„åº”ç”¨å·¥ä½œï¼Œæ‰€ä»¥æˆ‘å¬è¯´å¯ä»¥ä½¿ç”¨è¯­è¨€æ¨¡å‹æ¥è®­ç»ƒæ²»ç–—å¸ˆï¼Œä»¥å¸®åŠ©åˆ›æ„å†™ä½œå’Œç§‘å­¦ã€‚æˆ‘è®¤ä¸ºchatGTçœŸçš„å±•ç¤ºäº†è¯­è¨€æ¨¡å‹åœ¨è¿™æ–¹é¢çš„èƒ½åŠ›ã€‚æˆ‘è§‰å¾—åŸºå‡†æµ‹è¯•ä¹Ÿå¾ˆç¼ºä¹ï¼Œå› ä¸ºæˆ‘ä»¬é€šå¸¸å¾ˆå¿«å°±è§£å†³äº†åŸºå‡†æµ‹è¯•ã€‚ä¾‹å¦‚ï¼ŒPalmåœ¨Big
    Benchçš„æµ‹è¯•ä¸­è¶…è¶Šäº†å¹³å‡æ°´å¹³çš„äººç±»ï¼Œä½ çŸ¥é“ï¼Œåœ¨Big Benchå‘å¸ƒåçš„å¤§çº¦ä¸€å¹´å†…ï¼Œæ‰€ä»¥æˆ‘è®¤ä¸ºæˆ‘ä»¬éœ€è¦æ›´å¤šçš„åŸºå‡†æµ‹è¯•ï¼Œè¿™å°†æ˜¯ä¸€ä¸ªé‡è¦çš„è´¡çŒ®ã€‚
- en: And then the final one is likeï¼Œ how can we likeï¼ŸHave computer fission methods
    to make language models better so that it's less expensive to use them and more
    for get to use themã€‚Greatï¼Œ so I'll end here and feel free to email me if you have
    any feedback and if you're interested in Googleã€‚
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œæˆ‘ä»¬å¦‚ä½•èƒ½å¤Ÿåˆ©ç”¨è®¡ç®—æœºè£‚å˜æ–¹æ³•æ¥æ”¹å–„è¯­è¨€æ¨¡å‹ï¼Œä½¿å…¶ä½¿ç”¨æˆæœ¬æ›´ä½ï¼Œä½¿ç”¨èµ·æ¥æ›´æ–¹ä¾¿ã€‚å¾ˆå¥½ï¼Œæ‰€ä»¥æˆ‘åœ¨è¿™é‡Œç»“æŸï¼Œå¦‚æœä½ æœ‰ä»»ä½•åé¦ˆæˆ–å¯¹Googleæ„Ÿå…´è¶£ï¼Œéšæ—¶ç»™æˆ‘å‘é‚®ä»¶ã€‚
- en: yeah feel free to asã€‚ğŸ˜Šã€‚![](img/1fe3b7e42f45e3d11a61cea42eaf51cb_9.png)
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œéšæ—¶æé—®ã€‚ğŸ˜Šã€‚![](img/1fe3b7e42f45e3d11a61cea42eaf51cb_9.png)
- en: '![](img/1fe3b7e42f45e3d11a61cea42eaf51cb_10.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1fe3b7e42f45e3d11a61cea42eaf51cb_10.png)'
