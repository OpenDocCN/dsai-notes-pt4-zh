- en: æ–¯å¦ç¦ GPTï¼Transformer åŸç†ä»‹ç» (ä¸­è‹±æ–‡åŒå­—å¹•) - P17ï¼š17.Biomedical Transformers - life_code
    - BV1X84y1Q7wV
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ–¯å¦ç¦ GPTï¼Transformer åŸç†ä»‹ç» (ä¸­è‹±æ–‡åŒå­—å¹•) - P17ï¼š17.ç”Ÿç‰©åŒ»å­¦å˜å‹å™¨ - life_code - BV1X84y1Q7wV
- en: '![](img/867d42af88a583402ff132cc4ae7c3fa_0.png)'
  id: totrans-1
  prefs: []
  type: TYPE_IMG
  zh: '![](img/867d42af88a583402ff132cc4ae7c3fa_0.png)'
- en: '![](img/867d42af88a583402ff132cc4ae7c3fa_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/867d42af88a583402ff132cc4ae7c3fa_1.png)'
- en: Yeahï¼Œ so making you all see the speaker notes was not part of the planï¼Œ but
    I'm glad to be here andã€‚My name is Rebek Naroã€‚And I am a research scientist in
    the Health I team at Googleã€‚A little bit more about meï¼Œ growing up in Indiaï¼Œ my
    parents always wanted me to be a doctorã€‚to be precise a medical doctorï¼Œ but unfortunately
    I was probably not good enough to memorize all the biology textbooks that you
    had to do in case you wanted to crack the medical entrance examinations so I ended
    up becoming a computer scientist insteadã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œè®©å¤§å®¶çœ‹åˆ°æ¼”è®²è€…ç¬”è®°å¹¶ä¸æ˜¯è®¡åˆ’çš„ä¸€éƒ¨åˆ†ï¼Œä½†æˆ‘å¾ˆé«˜å…´æ¥åˆ°è¿™é‡Œã€‚æˆ‘çš„åå­—æ˜¯**Rebek Naro**ã€‚æˆ‘æ˜¯ä¸€ååœ¨è°·æ­Œå¥åº·å›¢é˜Ÿçš„ç ”ç©¶ç§‘å­¦å®¶ã€‚å…³äºæˆ‘çš„æ›´å¤šä¿¡æ¯æ˜¯ï¼Œæˆé•¿åœ¨å°åº¦ï¼Œæˆ‘çš„çˆ¶æ¯ä¸€ç›´å¸Œæœ›æˆ‘æˆä¸ºä¸€ååŒ»ç”Ÿï¼Œå‡†ç¡®åœ°è¯´æ˜¯ä¸€ååŒ»å­¦åŒ»ç”Ÿï¼Œä½†ä¸å¹¸çš„æ˜¯ï¼Œæˆ‘å¯èƒ½æ²¡æœ‰è¶³å¤Ÿçš„èƒ½åŠ›å»è®°ä½æ‰€æœ‰çš„ç”Ÿç‰©å­¦æ•™æï¼Œä»¥ä¾¿èƒ½é€šè¿‡åŒ»å­¦å…¥å­¦è€ƒè¯•ï¼Œå› æ­¤æˆ‘æœ€ç»ˆæˆä¸ºäº†ä¸€åè®¡ç®—æœºç§‘å­¦å®¶ã€‚
- en: è¯¶ã€‚But as a great man once saidï¼Œ you can't connect the dots looking forwardã€‚you
    only join them looking backwardsï¼Œ so through other long winded pathã€‚Not too dissimilar
    from how we actually train our neural networks I ended up working in medicine
    again this time armed with this magical new tool of AI and I can tell you that
    my parents are far more happy with my life choices right nowã€‚å—¯ã€‚But then I were
    truly satisfiedã€‚But take questionsians asideã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¶ã€‚ä¸è¿‡ï¼Œæ­£å¦‚ä¼Ÿäººæ›¾ç»è¯´è¿‡çš„ï¼Œä½ æ— æ³•å‘å‰çœ‹è¿æ¥ç‚¹ã€‚ä½ åªèƒ½åœ¨å›é¡¾æ—¶å°†å®ƒä»¬è¿æ¥èµ·æ¥ï¼Œå› æ­¤é€šè¿‡å…¶ä»–å†—é•¿çš„è·¯å¾„ã€‚è¿™ä¸æˆ‘ä»¬å®é™…è®­ç»ƒç¥ç»ç½‘ç»œçš„æ–¹å¼å¹¶æ²¡æœ‰å¤ªå¤§ä¸åŒã€‚æˆ‘å†æ¬¡å›åˆ°äº†åŒ»å­¦é¢†åŸŸï¼Œè¿™æ¬¡æˆ‘æ‹¥æœ‰äº†è¿™ä¸ªç¥å¥‡çš„æ–°å·¥å…·â€”â€”äººå·¥æ™ºèƒ½ï¼Œæˆ‘å¯ä»¥å‘Šè¯‰ä½ ï¼Œæˆ‘çš„çˆ¶æ¯å¯¹æˆ‘ç°åœ¨çš„ç”Ÿæ´»é€‰æ‹©æ„Ÿåˆ°æ›´åŠ æ»¡æ„ã€‚å—¯ã€‚ä¸è¿‡ï¼Œé‚£æ—¶æˆ‘å¹¶æ²¡æœ‰çœŸæ­£æ„Ÿåˆ°æ»¡è¶³ã€‚ä½†æŠŠé—®é¢˜æ”¾åœ¨ä¸€è¾¹ã€‚
- en: My goal for this talk is to peel back the curtains and give you a flavor of
    all the innovation that is happening at the intersection of AI and biomedicine
    and how that is being catalyzed by transformers and large language models in particularã€‚So
    we will spend the first few minutes trying to work up from first principles why
    transformers and large language models are a particularly good fit for biomedical
    dataã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è¿™æ¬¡æ¼”è®²çš„ç›®æ ‡æ˜¯æ­ç¤ºå¹•åçš„æƒ…å†µï¼Œè®©ä½ ä»¬äº†è§£åœ¨**äººå·¥æ™ºèƒ½**å’Œ**ç”Ÿç‰©åŒ»å­¦**äº¤æ±‡å¤„å‘ç”Ÿçš„æ‰€æœ‰åˆ›æ–°ï¼Œä»¥åŠè¿™äº›åˆ›æ–°æ˜¯å¦‚ä½•å—åˆ°**å˜æ¢å™¨**å’Œ**å¤§å‹è¯­è¨€æ¨¡å‹**çš„æ¨åŠ¨ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†èŠ±å‡ åˆ†é’Ÿæ—¶é—´ä»åŸºæœ¬åŸç†å‡ºå‘ï¼Œæ¢è®¨ä¸ºä»€ä¹ˆå˜æ¢å™¨å’Œå¤§å‹è¯­è¨€æ¨¡å‹ç‰¹åˆ«é€‚åˆç”Ÿç‰©åŒ»å­¦æ•°æ®ã€‚
- en: and then we will deep dive into a few papers covering a bunch of different biomedical
    application settingsã€‚And finallyï¼Œ I'll present my views on how this field is likely
    going to evolve in the next few yearsã€‚And even though my voice or tone may not
    exactly sound that wayã€‚I am incredibly excited by the possibilities of AI and
    biomedicineã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨å‡ ç¯‡æ¶µç›–ä¸åŒç”Ÿç‰©åŒ»å­¦åº”ç”¨åœºæ™¯çš„è®ºæ–‡ã€‚æœ€åï¼Œæˆ‘å°†åˆ†äº«æˆ‘å¯¹è¿™ä¸ªé¢†åŸŸåœ¨æœªæ¥å‡ å¹´å¯èƒ½å‘å±•çš„çœ‹æ³•ã€‚å°½ç®¡æˆ‘çš„å£°éŸ³æˆ–è¯­è°ƒå¯èƒ½å¹¶ä¸å®Œå…¨å¦‚æ­¤ï¼Œä½†æˆ‘å¯¹äººå·¥æ™ºèƒ½å’Œç”Ÿç‰©åŒ»å­¦çš„å¯èƒ½æ€§æ„Ÿåˆ°æ— æ¯”å…´å¥‹ã€‚
- en: And I think we have an incredible opportunity in front of us to advance human
    health and human potential and my hope at the end of this talk is you all will
    feel the same way as I do today and perhaps join meã€‚ğŸ˜Šï¼ŒSo yeahï¼Œ let's jump straight
    in why transformers in biomedicine and sorry I'm going to pick people who are
    in person to answerã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºæˆ‘ä»¬é¢å‰æœ‰ä¸€ä¸ªä»¤äººéš¾ä»¥ç½®ä¿¡çš„æœºä¼šï¼Œå¯ä»¥æ¨åŠ¨äººç±»å¥åº·å’Œäººç±»æ½œåŠ›ï¼Œæˆ‘å¸Œæœ›åœ¨è¿™æ¬¡æ¼”è®²ç»“æŸæ—¶ï¼Œä½ ä»¬éƒ½èƒ½åƒæˆ‘ä»Šå¤©ä¸€æ ·æ„Ÿå—åˆ°è¿™ä¸€ç‚¹ï¼Œæˆ–è®¸æ„¿æ„åŠ å…¥æˆ‘ã€‚ğŸ˜Šï¼Œæ‰€ä»¥ï¼Œè®©æˆ‘ä»¬ç›´æ¥æ·±å…¥è®¨è®ºä¸ºä»€ä¹ˆå˜å‹å™¨åœ¨ç”Ÿç‰©åŒ»å­¦ä¸­çš„åº”ç”¨ï¼Œå¯¹ä¸èµ·ï¼Œæˆ‘ä¼šè¯·åœ¨åœºçš„äººå›ç­”ã€‚
- en: so maybe if one of you could volunteerã€‚Go forï¼Œ not that's a good answerã€‚å—¯ã€‚å—¯ã€‚sé£å•Šåæœ‰å»å¿«ç©åˆ°æœª
    sorry sorryå¿«ç©åˆ°å‡ ä¸ªæ‰“å’¯ä½¢ç¿»ç³» lã€‚Yeahï¼Œ sureï¼Œ's another one as well that's an important
    application settingã€‚ä½ ç³»æ¥åæˆ‘äº‹å•Šã€‚Yeah great one so I think all of you were on the right
    track and so maybe if you just look at different kinds of you know biomedical
    dataã€‚for example what are clinical notes I think it's sequence of Dr Jabberish
    okay I did not say that but let's just call sequence of doctor speak or doctor
    notesã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œä¹Ÿè®¸ä½ ä»¬ä¸­çš„ä¸€ä¸ªå¯ä»¥è‡ªæ„¿ä¸€ä¸‹ã€‚å»å§ï¼Œè™½ç„¶è¿™ä¸æ˜¯ä¸€ä¸ªå¥½ç­”æ¡ˆã€‚å—¯ã€‚å—¯ã€‚sé£å•Šåæœ‰å»å¿«ç©åˆ°æœªï¼ŒæŠ±æ­‰ï¼ŒæŠ±æ­‰å¿«ç©åˆ°å‡ ä¸ªæ‰“å’¯ä½¢ç¿»ç³»lã€‚æ˜¯çš„ï¼Œå½“ç„¶ï¼Œè¿˜æœ‰å¦ä¸€ä¸ªä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦çš„åº”ç”¨åœºæ™¯ã€‚ä½ ç³»æ¥åæˆ‘äº‹å•Šã€‚æ˜¯çš„ï¼Œå¾ˆå¥½ï¼Œæ‰€ä»¥æˆ‘è®¤ä¸ºä½ ä»¬éƒ½åœ¨æ­£ç¡®çš„è½¨é“ä¸Šï¼Œä¹Ÿè®¸å¦‚æœä½ ä»¬çœ‹ä¸€ä¸‹ä¸åŒç±»å‹çš„ç”Ÿç‰©åŒ»å­¦æ•°æ®ã€‚æ¯”å¦‚ï¼Œä¸´åºŠç¬”è®°æ˜¯ä»€ä¹ˆï¼Œæˆ‘æƒ³é‚£æ˜¯åŒ»ç”Ÿçš„èƒ¡è¨€ä¹±è¯­çš„åºåˆ—ï¼Œå¥½å§ï¼Œæˆ‘æ²¡æœ‰è¿™ä¹ˆè¯´ï¼Œä½†æˆ‘ä»¬å°±ç§°ä¹‹ä¸ºåŒ»ç”Ÿè¯´è¯çš„åºåˆ—æˆ–è€…åŒ»ç”Ÿç¬”è®°ã€‚
- en: Similarlyï¼Œ if you were to look at electronic medical recordsã€‚what are they they
    are essentially sequence of like a person's encounters with the medical systemã€‚å—¯ã€‚What
    about proteins going deeper into the biological stackã€‚they are nottdding but a
    sequence of amino acids linked together by peptide bondsã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: åŒæ ·ï¼Œå¦‚æœä½ æŸ¥çœ‹ç”µå­ç—…å†ï¼Œå®ƒä»¬æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªäººå°±åŒ»ç»å†çš„åºåˆ—ã€‚å—¯ã€‚å…³äºè›‹ç™½è´¨ï¼Œæ·±å…¥ç”Ÿç‰©å±‚é¢ï¼Œå®ƒä»¬ä¸è¿‡æ˜¯ç”±è‚½é”®è¿æ¥åœ¨ä¸€èµ·çš„æ°¨åŸºé…¸åºåˆ—ã€‚
- en: And does anybody know what this isï¼Ÿå¥½å¤šæ°´ã€‚I think that's how we storeã€‚å—¯ç³»ã€‚Sorry
    againã€‚you're getting closeã€‚ç³»ã€‚Anyone elseï¼ŸSo this is in the Wecome collection in
    London and this is actually a printout of the full human genomeã€‚Andã€‚No they did
    not cheat over here the font is super small and as you can see there's a bunch
    of8GCs the entire printout contains I think over 130 volumes in that shelf and
    each page is printed on both sides and it's a  four point font with precisely
    43ã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰äººçŸ¥é“è¿™æ˜¯ä»€ä¹ˆå—ï¼Ÿå¥½å¤šæ°´ã€‚æˆ‘æƒ³è¿™å°±æ˜¯æˆ‘ä»¬çš„å‚¨å­˜æ–¹å¼ã€‚å—¯ï¼Œæ²¡é”™ã€‚å†ä¸€æ¬¡æŠ±æ­‰ã€‚ä½ å¿«åˆ°äº†ã€‚æ²¡é”™ã€‚è¿˜æœ‰å…¶ä»–äººå—ï¼Ÿè¿™æ˜¯ä¼¦æ•¦çš„å¨å°”åº·æ”¶è—ï¼Œè¿™å®é™…ä¸Šæ˜¯å®Œæ•´äººç±»åŸºå› ç»„çš„æ‰“å°ä»¶ã€‚å¹¶ä¸”ã€‚ä»–ä»¬å¹¶æ²¡æœ‰ä½œå¼Šï¼Œå­—ä½“éå¸¸å°ï¼Œå¦‚ä½ æ‰€è§ï¼Œé‚£é‡Œæœ‰å¾ˆå¤š8GCsï¼Œæ•´ä¸ªæ‰“å°ä»¶æˆ‘æƒ³æœ‰è¶…è¿‡130å·æ”¾åœ¨é‚£ä¸ªæ¶å­ä¸Šï¼Œæ¯ä¸€é¡µéƒ½æ˜¯åŒé¢æ‰“å°ï¼Œä½¿ç”¨çš„æ˜¯å››å·å­—ä½“ï¼Œç²¾ç¡®åˆ°43ã€‚
- en: 000 cactus per page so that is how big the human reference genome is more than
    billions of base pairã€‚And so againï¼Œ the genome is nothing but a sequence of neotide
    base pairsã€‚so what we are essentially seeing over here is sequences are everywhere
    in biomedical data and what is the best neuralelectric architecture for modeling
    themï¼Ÿ
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯é¡µæœ‰000ä¸ªä»™äººæŒï¼Œè¿™å°±æ˜¯äººç±»å‚è€ƒåŸºå› ç»„çš„å¤§å°ï¼Œè¶…è¿‡æ•°åäº¿ä¸ªç¢±åŸºå¯¹ã€‚å†è¯´ä¸€æ¬¡ï¼ŒåŸºå› ç»„åªæ˜¯ä¸€ä¸²æ ¸è‹·é…¸ç¢±åŸºå¯¹çš„åºåˆ—ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œçœ‹åˆ°çš„æœ¬è´¨ä¸Šæ˜¯ç”Ÿç‰©åŒ»å­¦æ•°æ®ä¸­çš„åºåˆ—æ— å¤„ä¸åœ¨ï¼Œè€Œä»€ä¹ˆæ˜¯å»ºæ¨¡å®ƒä»¬çš„æœ€ä½³ç¥ç»ç”µæ°”æ¶æ„å‘¢ï¼Ÿ
- en: å—¯ã€‚And I guess since you are all in this courseï¼Œ I don't have to convince you
    that the answer is transformersã€‚rightï¼ŸOkay that's goodï¼Œ but maybe I'll just offer
    a few reasons over here firstly as you can see the data itself is multimodal in
    nature and we just saw a few examples and as someone pointed out transformers
    have proven remarkable at you know guing up pretty much any kind of data and we
    are really seeing this remarkable convergence across fields whether that's speech
    or NLP or vision or robotics I mean pretty much everywhere we are using transformers
    and I think biomedicine is no differentã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å—¯ã€‚æˆ‘æƒ³æ—¢ç„¶ä½ ä»¬éƒ½åœ¨è¿™ä¸ªè¯¾ç¨‹ä¸­ï¼Œæˆ‘å°±ä¸éœ€è¦è¯´æœä½ ä»¬ç­”æ¡ˆæ˜¯å˜æ¢å™¨ï¼Œå¯¹å§ï¼Ÿå¥½çš„ï¼Œè¿™å¾ˆå¥½ï¼Œä½†ä¹Ÿè®¸æˆ‘åœ¨è¿™é‡Œæä¾›å‡ ä¸ªç†ç”±ã€‚é¦–å…ˆï¼Œæ­£å¦‚ä½ ä»¬æ‰€çœ‹åˆ°çš„æ•°æ®æœ¬è´¨ä¸Šæ˜¯å¤šæ¨¡æ€çš„ï¼Œæˆ‘ä»¬åˆšåˆšçœ‹åˆ°äº†å‡ ä¸ªä¾‹å­ï¼Œæ­£å¦‚æœ‰äººæŒ‡å‡ºçš„é‚£æ ·ï¼Œå˜æ¢å™¨åœ¨å¤„ç†å‡ ä¹ä»»ä½•ç±»å‹çš„æ•°æ®æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚æˆ‘ä»¬ç¡®å®çœ‹åˆ°äº†å„ä¸ªé¢†åŸŸçš„æ˜¾è‘—èåˆï¼Œæ— è®ºæ˜¯è¯­éŸ³ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è§†è§‰è¿˜æ˜¯æœºå™¨äººï¼Œå˜æ¢å™¨å‡ ä¹æ— å¤„ä¸åœ¨ï¼Œæˆ‘è®¤ä¸ºç”Ÿç‰©åŒ»å­¦ä¹Ÿä¸ä¾‹å¤–ã€‚
- en: ğŸ˜Šï¼ŒI think secondlyï¼Œ transformers are far more effective at modeling complex
    long range interactions over sequencesã€‚and this property is particularly important
    in the biomedical domain and we will cover this in more detail later in the talkã€‚And
    finallyï¼Œ as againï¼Œ someone pointed outï¼Œ these data sets can be quite big and you
    can easily get into the billions of token territory and this is where transformers
    with all the parallelizable operations and the relative ease of training and maybe
    someone should try training an LSM and an RN on these kind of datasã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šï¼Œæˆ‘è®¤ä¸ºç¬¬äºŒï¼Œå˜å‹å™¨åœ¨å¯¹åºåˆ—ä¸­çš„å¤æ‚é•¿ç¨‹äº¤äº’å»ºæ¨¡æ–¹é¢è¿œè¿œæ›´æœ‰æ•ˆã€‚è¿™ä¸ªç‰¹æ€§åœ¨ç”Ÿç‰©åŒ»å­¦é¢†åŸŸå°¤å…¶é‡è¦ï¼Œæˆ‘ä»¬å°†åœ¨ç¨åçš„æ¼”è®²ä¸­è¯¦ç»†è®¨è®ºè¿™ä¸€ç‚¹ã€‚æœ€åï¼Œæ­£å¦‚æœ‰äººæŒ‡å‡ºçš„ï¼Œè¿™äº›æ•°æ®é›†å¯èƒ½éå¸¸åºå¤§ï¼Œä½ å¾ˆå®¹æ˜“å°±ä¼šè¿›å…¥æ•°åäº¿ä¸ªæ ‡è®°çš„é¢†åŸŸï¼Œè€Œè¿™æ­£æ˜¯å˜å‹å™¨å‡­å€Ÿå…¶æ‰€æœ‰å¯å¹¶è¡ŒåŒ–æ“ä½œå’Œç›¸å¯¹æ˜“äºè®­ç»ƒçš„ä¼˜åŠ¿æ‰€æ“…é•¿çš„åœ°æ–¹ï¼Œä¹Ÿè®¸åº”è¯¥å°è¯•åœ¨è¿™äº›æ•°æ®ä¸Šè®­ç»ƒä¸€ä¸ªLSMå’Œä¸€ä¸ªRNã€‚
- en: you'll realize that these are much better suited for the kind of data sets that
    we have in this domain over hereã€‚So yeahï¼Œ I think there are a few more reasons
    as wellã€‚but I think these are the key ones as to why transformers are particularly
    well suited for biomedical data sets and tasksã€‚Any questions so farï¼ŸOkayï¼Œ greatï¼Œ
    so now in the next part of this talkã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¼šæ„è¯†åˆ°è¿™äº›æ›´é€‚åˆæˆ‘ä»¬åœ¨è¿™ä¸ªé¢†åŸŸæ‹¥æœ‰çš„æ•°æ®é›†ã€‚æ‰€ä»¥æ˜¯çš„ï¼Œæˆ‘è®¤ä¸ºè¿˜æœ‰å‡ ä¸ªåŸå› ï¼Œä½†æˆ‘è§‰å¾—è¿™äº›æ˜¯å˜å‹å™¨ç‰¹åˆ«é€‚åˆç”Ÿç‰©åŒ»å­¦æ•°æ®é›†å’Œä»»åŠ¡çš„å…³é”®åŸå› ã€‚åˆ°ç›®å‰ä¸ºæ­¢æœ‰ä»»ä½•é—®é¢˜å—ï¼Ÿå¥½çš„ï¼Œå¾ˆå¥½ï¼Œé‚£ä¹ˆæ¥ä¸‹æ¥åœ¨è¿™ä¸ªè®²åº§çš„ä¸‹ä¸€éƒ¨åˆ†ã€‚
- en: we will dive deep into a few papers applying transformers to biomedical dataã€‚We'll
    start with clinical applications first and then go gradually deeper into the biology
    stack looking at proteins and genomic applications as wellã€‚and what you will observe
    is that while transformers and large language models by extension are a great
    fitã€‚often you have to innovateï¼Œ not just on the modeling sideã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†æ·±å…¥æ¢è®¨å‡ ç¯‡å°†å˜æ¢å™¨åº”ç”¨äºç”Ÿç‰©åŒ»å­¦æ•°æ®çš„è®ºæ–‡ã€‚æˆ‘ä»¬é¦–å…ˆä»ä¸´åºŠåº”ç”¨å¼€å§‹ï¼Œç„¶åé€æ­¥æ·±å…¥ç”Ÿç‰©å­¦å±‚é¢ï¼ŒæŸ¥çœ‹è›‹ç™½è´¨å’ŒåŸºå› ç»„åº”ç”¨ã€‚ä½ ä¼šå‘ç°ï¼Œè™½ç„¶å˜æ¢å™¨åŠå…¶æ‰©å±•çš„å¤§å‹è¯­è¨€æ¨¡å‹éå¸¸å¥‘åˆï¼Œä½†å¾€å¾€éœ€è¦åœ¨å»ºæ¨¡æ–¹é¢è¿›è¡Œåˆ›æ–°ã€‚
- en: but also on the data and evaluation side to make these applicant scenarios really
    workã€‚And so the first paper I want to talk about over here is this recent work
    from our team called largege La modelss encode clinical Knowledã€‚The motivation
    for this work is actually quite straightforward so if you look at medicine it
    is a humane endeavor and language is at the heart of it facilitating interactions
    between people and those who provide care for them unfortunately if you look at
    a lot of medical AI systems developed till date these are all narrow single task
    single domain models lacking interactive and expressibility capabilitiesã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†ä¹Ÿåœ¨æ•°æ®å’Œè¯„ä¼°æ–¹é¢ï¼Œä»¥ä½¿è¿™äº›ç”³è¯·åœºæ™¯çœŸæ­£æœ‰æ•ˆã€‚å› æ­¤ï¼Œæˆ‘æƒ³åœ¨è¿™é‡Œè®¨è®ºçš„ç¬¬ä¸€ç¯‡è®ºæ–‡æ˜¯æˆ‘ä»¬å›¢é˜Ÿæœ€è¿‘çš„å·¥ä½œï¼Œåä¸ºå¤§å‹è¯­è¨€æ¨¡å‹å¯¹ä¸´åºŠçŸ¥è¯†çš„ç¼–ç ã€‚è¿™ä¸ªå·¥ä½œçš„åŠ¨æœºå…¶å®éå¸¸ç®€å•ï¼Œå¦‚æœä½ è§‚å¯ŸåŒ»å­¦ï¼Œå®ƒæ˜¯ä¸€é¡¹äººé“äº‹ä¸šï¼Œè€Œè¯­è¨€æ­£æ˜¯å…¶æ ¸å¿ƒï¼Œä¿ƒè¿›äº†äººä»¬ä¸æä¾›æŠ¤ç†è€…ä¹‹é—´çš„äº’åŠ¨ã€‚ä¸å¹¸çš„æ˜¯ï¼Œå¦‚æœä½ çœ‹çœ‹è¿„ä»Šä¸ºæ­¢å¼€å‘çš„è®¸å¤šåŒ»ç–—AIç³»ç»Ÿï¼Œè¿™äº›ç³»ç»Ÿéƒ½æ˜¯ç‹­çª„çš„å•ä¸€ä»»åŠ¡å•ä¸€é¢†åŸŸæ¨¡å‹ï¼Œç¼ºä¹äº’åŠ¨æ€§å’Œè¡¨è¾¾èƒ½åŠ›ã€‚
- en: And as a resultï¼Œ what has happened is there is this discordance between what
    these models can do and what is expected of them by patients and you know care
    providers and others and this in turn has I think prevented broad uptake of medical
    AIã€‚è¯¶ã€‚And you can see thatï¼Œ for exampleï¼Œ we don't really have AI and many clinics
    out there like helping us with diagnosis and so on and so forthã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœæ˜¯ï¼Œè¿™äº›æ¨¡å‹èƒ½å¤Ÿåšåˆ°çš„ä¸æ‚£è€…ã€æŠ¤ç†æä¾›è€…ç­‰å¯¹å®ƒä»¬çš„æœŸæœ›ä¹‹é—´å­˜åœ¨ä¸ä¸€è‡´ï¼Œè¿™åè¿‡æ¥æˆ‘è®¤ä¸ºé˜»ç¢äº†åŒ»ç–—AIçš„å¹¿æ³›åº”ç”¨ã€‚è¯¶ã€‚æ¯”å¦‚ï¼Œæˆ‘ä»¬å®é™…ä¸Šåœ¨è®¸å¤šè¯Šæ‰€ä¸­å¹¶æ²¡æœ‰AIæ¥å¸®åŠ©æˆ‘ä»¬è¿›è¡Œè¯Šæ–­ç­‰ç­‰ã€‚
- en: But the recent progress with Transform based large language modelsã€‚it offers
    us an opportunity to change all of this and redesign and rethink medical AI systems
    with language at the heart of itã€‚mediating humania interactions between doctorsï¼Œ
    researchers and patientsã€‚And I will be amazed if I don't point out that there
    has been a large volume of work in this spaceã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯ï¼ŒåŸºäºå˜æ¢çš„å¤§å‹è¯­è¨€æ¨¡å‹çš„æœ€æ–°è¿›å±•ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªæœºä¼šï¼Œå¯ä»¥æ”¹å˜è¿™ä¸€åˆ‡ï¼Œé‡æ–°è®¾è®¡å’Œæ€è€ƒä»¥è¯­è¨€ä¸ºæ ¸å¿ƒçš„åŒ»ç–—äººå·¥æ™ºèƒ½ç³»ç»Ÿï¼Œè°ƒè§£åŒ»ç”Ÿã€ç ”ç©¶äººå‘˜å’Œæ‚£è€…ä¹‹é—´çš„äº’åŠ¨ã€‚å¦‚æœæˆ‘ä¸æåˆ°åœ¨è¿™ä¸ªé¢†åŸŸå·²ç»æœ‰å¤§é‡çš„å·¥ä½œï¼Œæˆ‘å°†æ„Ÿåˆ°æƒŠè®¶ã€‚
- en: particularly in the last few yearsï¼Œ there have been various attempts to train
    language models in the biomedical domain with models of various different sizes
    on different cor of biomedical dataã€‚And while this is excitingï¼Œ the quality bar
    for applications in the medical domain is actually quite highã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: å°¤å…¶æ˜¯åœ¨è¿‡å»çš„å‡ å¹´ä¸­ï¼Œé’ˆå¯¹ç”Ÿç‰©åŒ»å­¦é¢†åŸŸè¿›è¡Œäº†å„ç§å°è¯•ï¼Œä»¥ä¸åŒè§„æ¨¡çš„æ¨¡å‹åœ¨ä¸åŒçš„ç”Ÿç‰©åŒ»å­¦æ•°æ®é›†ä¸Šè®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚è™½ç„¶è¿™å¾ˆä»¤äººå…´å¥‹ï¼Œä½†åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨è´¨é‡æ ‡å‡†å®é™…ä¸Šç›¸å½“é«˜ã€‚
- en: And so what is missing is actually is that there is actually not many good evaluation
    benchmarks and evaluation protocols and frameworks so we don't have the equivalent
    of a big bench in medicine and hopefully you guys have covered big bench before
    and so big bench is is benchmark where you can assess large language models across
    a variety of task domains and settings but we don't have an equivalent of that
    in the medical domainã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œç¼ºå¤±çš„å®é™…ä¸Šæ˜¯ï¼Œæˆ‘ä»¬å¹¶æ²¡æœ‰å¾ˆå¤šå¥½çš„è¯„ä¼°åŸºå‡†ã€è¯„ä¼°åè®®å’Œæ¡†æ¶ï¼Œå› æ­¤åœ¨åŒ»å­¦é¢†åŸŸæˆ‘ä»¬æ²¡æœ‰ç›¸å½“äºå¤§åŸºå‡†çš„ä¸œè¥¿ã€‚å¸Œæœ›ä½ ä»¬ä¹‹å‰å·²ç»äº†è§£è¿‡å¤§åŸºå‡†ï¼Œè€Œå¤§åŸºå‡†æ˜¯ä¸€ä¸ªå¯ä»¥è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å„ç§ä»»åŠ¡é¢†åŸŸå’Œè®¾ç½®ä¸­çš„åŸºå‡†ï¼Œä½†åœ¨åŒ»å­¦é¢†åŸŸæˆ‘ä»¬æ²¡æœ‰è¿™æ ·çš„ç­‰æ•ˆç‰©ã€‚
- en: And furtherï¼Œ if you look at the evaluations that are typically used in these
    previous studiesã€‚they only look at objective metrics like accuracy or natural
    language generation metrics like blue or ciderã€‚but these failed to capture the
    nuances of real world use cases in clinical settingsã€‚So what we essentially need
    was a good benchmark and a task and also a good evaluation framework for evaluating
    these modelsã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œå¦‚æœä½ æŸ¥çœ‹ä»¥å¾€ç ”ç©¶ä¸­é€šå¸¸ä½¿ç”¨çš„è¯„ä¼°ï¼Œå®ƒä»¬ä»…å…³æ³¨è¯¸å¦‚å‡†ç¡®æ€§æˆ–è‡ªç„¶è¯­è¨€ç”ŸæˆæŒ‡æ ‡ï¼ˆå¦‚blueæˆ–ciderï¼‰ç­‰å®¢è§‚æŒ‡æ ‡ï¼Œä½†è¿™äº›æœªèƒ½æ•æ‰åˆ°ä¸´åºŠç¯å¢ƒä¸­çœŸå®ä½¿ç”¨æ¡ˆä¾‹çš„ç»†å¾®å·®åˆ«ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æœ¬è´¨ä¸Šéœ€è¦ä¸€ä¸ªå¥½çš„åŸºå‡†ã€ä¸€ä¸ªä»»åŠ¡ï¼Œä»¥åŠä¸€ä¸ªè‰¯å¥½çš„è¯„ä¼°æ¡†æ¶æ¥è¯„ä¼°è¿™äº›æ¨¡å‹ã€‚
- en: And so to address this unmet need and assess the potential of LLMs in medicineï¼Œ
    in our teamã€‚we decided to focus on the medical question answering taskï¼Œ whyã€‚because
    answering medical questions is actually quite challengingã€‚it requires reading
    comprehension skillsï¼Œ ability to accurately recall medical knowledge and also
    manipulate and reason about itã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œä¸ºäº†æ»¡è¶³è¿™ä¸€æœªè¢«æ»¡è¶³çš„éœ€æ±‚å¹¶è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨åŒ»å­¦ä¸­çš„æ½œåŠ›ï¼Œæˆ‘ä»¬å›¢é˜Ÿå†³å®šä¸“æ³¨äºåŒ»ç–—é—®ç­”ä»»åŠ¡ï¼Œä¸ºä»€ä¹ˆå‘¢ï¼Ÿå› ä¸ºå›ç­”åŒ»å­¦é—®é¢˜å®é™…ä¸Šæ˜¯ç›¸å½“å…·æœ‰æŒ‘æˆ˜æ€§çš„ã€‚å®ƒéœ€è¦é˜…è¯»ç†è§£èƒ½åŠ›ã€å‡†ç¡®å›å¿†åŒ»å­¦çŸ¥è¯†çš„èƒ½åŠ›ï¼Œä»¥åŠå¯¹è¿™äº›çŸ¥è¯†è¿›è¡Œæ“ä½œå’Œæ¨ç†çš„èƒ½åŠ›ã€‚
- en: And furthermoreï¼Œ the Q&A task is general enough and can subsume a bunch of different
    application settings such as summarization of clinical notesã€‚clinical decision
    supportï¼Œ and also like primary cartriaging of patient concerns and so onã€‚So we've
    identified the task the next question is what data set and so when we looked at
    the literature over hereã€‚what we saw is that there were several data sets floating
    around assessing model capabilities in a bunch of different settings so what we
    decided was we should probably just unify all of them and put together in one
    benchmark and so we did that and we call it multim QA and so if you look at it
    this benchmark now covers medical question answering data sets from a bunch of
    different settings such as professional medical questions like the US medical
    license exam style questions it also includes medical research questions those
    based on pububM abstracts and so on and also questions from live users and consumers
    asking about medical informationã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œé—®ç­”ä»»åŠ¡è¶³å¤Ÿé€šç”¨ï¼Œå¯ä»¥æ¶µç›–å¤šç§ä¸åŒçš„åº”ç”¨åœºæ™¯ï¼Œä¾‹å¦‚ä¸´åºŠç¬”è®°çš„æ€»ç»“ã€ä¸´åºŠå†³ç­–æ”¯æŒï¼Œä»¥åŠåˆæ­¥åˆ†ç±»æ‚£è€…å…³åˆ‡ç­‰ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ç¡®å®šäº†è¿™ä¸ªä»»åŠ¡ï¼Œæ¥ä¸‹æ¥çš„é—®é¢˜æ˜¯æ•°æ®é›†ã€‚å½“æˆ‘ä»¬æŸ¥çœ‹ç›¸å…³æ–‡çŒ®æ—¶ï¼Œæˆ‘ä»¬å‘ç°æœ‰å‡ ä¸ªæ•°æ®é›†åœ¨ä¸åŒçš„åœºæ™¯ä¸­è¯„ä¼°æ¨¡å‹èƒ½åŠ›ï¼Œå› æ­¤æˆ‘ä»¬å†³å®šå°†å®ƒä»¬ç»Ÿä¸€èµ·æ¥ï¼Œæ•´ç†æˆä¸€ä¸ªåŸºå‡†ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è¿™æ ·åšäº†ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºå¤šæ¨¡æ€é—®ç­”ï¼ˆmultim
    QAï¼‰ã€‚å¦‚æœä½ æŸ¥çœ‹è¿™ä¸ªåŸºå‡†ï¼Œç°åœ¨æ¶µç›–äº†æ¥è‡ªå¤šç§ä¸åŒåœºæ™¯çš„åŒ»å­¦é—®ç­”æ•°æ®é›†ï¼Œä¾‹å¦‚ä¸“ä¸šåŒ»å­¦é—®é¢˜ï¼ˆå¦‚ç¾å›½åŒ»å­¦æ‰§ç…§è€ƒè¯•é£æ ¼çš„é—®é¢˜ï¼‰ï¼Œè¿˜åŒ…æ‹¬åŸºäºPubMedæ‘˜è¦çš„åŒ»å­¦ç ”ç©¶é—®é¢˜ï¼Œä»¥åŠæ¥è‡ªå®æ—¶ç”¨æˆ·å’Œæ¶ˆè´¹è€…è¯¢é—®åŒ»å­¦ä¿¡æ¯çš„é—®é¢˜ã€‚
- en: And also the setting changesï¼Œ it could be closed domain or open domain and the
    model may be expected to produce long form answer in one setting and maybe a short
    form answer in another settingã€‚And finallyï¼Œ we saw that while theã€‚The Q&A data
    sets which covered consumer courseï¼Œ yeah goã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰ç¯å¢ƒçš„å˜åŒ–ï¼Œå¯èƒ½æ˜¯å°é—­åŸŸæˆ–å¼€æ”¾åŸŸï¼Œæ¨¡å‹å¯èƒ½åœ¨ä¸€ä¸ªç¯å¢ƒä¸­è¢«æœŸæœ›äº§ç”Ÿé•¿æ ¼å¼çš„ç­”æ¡ˆï¼Œè€Œåœ¨å¦ä¸€ä¸ªç¯å¢ƒä¸­åˆ™å¯èƒ½äº§ç”ŸçŸ­æ ¼å¼çš„ç­”æ¡ˆã€‚æœ€åï¼Œæˆ‘ä»¬çœ‹åˆ°å°½ç®¡å¦‚æ­¤ã€‚è¿™äº›æ¶µç›–æ¶ˆè´¹è€…è¯¾ç¨‹çš„é—®ç­”æ•°æ®é›†ï¼Œå—¯ï¼Œç»§ç»­ã€‚
- en: I'll come back to thisã€‚So yeah very quickly finally when we looked at cool so
    the question was how do we evaluate longform answers and I'll come back to this
    sub later and so very quickly when we looked at the data sets that actually provided
    consumer medical questions we found them to be quite small in size so we decided
    to augment them and so we went out to Google and looked at like the most frequently
    asked consumer medical questions and so we curated a data set and we added that
    to the benchmark and we call that health search QA over hereã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ç¨åä¼šå†å›åˆ°è¿™ä¸ªè¯é¢˜ã€‚æ‰€ä»¥ï¼Œæœ€åæˆ‘ä»¬å¿«é€Ÿåœ°çœ‹äº†ä¸‹ï¼Œé—®é¢˜æ˜¯æˆ‘ä»¬å¦‚ä½•è¯„ä¼°é•¿æ ¼å¼çš„ç­”æ¡ˆï¼Œæˆ‘ç¨åä¼šå†å›åˆ°è¿™ä¸ªå­è¯é¢˜ã€‚å› æ­¤ï¼Œå½“æˆ‘ä»¬æŸ¥çœ‹å®é™…ä¸Šæä¾›æ¶ˆè´¹è€…åŒ»ç–—é—®é¢˜çš„æ•°æ®é›†æ—¶ï¼Œæˆ‘ä»¬å‘ç°å®ƒä»¬çš„è§„æ¨¡ç›¸å½“å°ï¼Œæ‰€ä»¥æˆ‘ä»¬å†³å®šæ‰©å……è¿™äº›æ•°æ®é›†ã€‚äºæ˜¯æˆ‘ä»¬åœ¨è°·æ­Œä¸ŠæŸ¥çœ‹äº†æœ€å¸¸è¢«é—®çš„æ¶ˆè´¹è€…åŒ»ç–—é—®é¢˜ï¼Œå¹¶æ•´ç†äº†ä¸€ä¸ªæ•°æ®é›†ï¼Œå°†å…¶æ·»åŠ åˆ°åŸºå‡†ä¸­ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºå¥åº·æœç´¢é—®ç­”ã€‚
- en: And so yeahï¼Œ againï¼ŒI'll come back with the start circular I'm sure so here are
    a few examples so if you look at the consumer medical questions they are quite
    short in nature while and so they come from the health search queue and the liveQ
    datas whereas I think if you look at the USM style questions these are like long
    viignettes and so doctors have to like really really carefully read through them
    and come up with the right answer which often and involves a process of emination
    so again very very different application settings and so the model has to really
    like really adapt and understand the task to do well in all these settings across
    the boardã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œæ˜¯çš„ï¼Œæˆ‘ä¼šå†å›æ¥ï¼Œç¡®ä¿èƒ½æ‰¾åˆ°å¼€å§‹çš„å¾ªç¯ï¼Œè¿™é‡Œæœ‰ä¸€äº›ä¾‹å­ã€‚å¦‚æœä½ çœ‹çœ‹æ¶ˆè´¹è€…åŒ»ç–—é—®é¢˜ï¼Œå®ƒä»¬çš„æ€§è´¨ç›¸å¯¹è¾ƒçŸ­ï¼Œè¿™äº›é—®é¢˜æ¥è‡ªå¥åº·æœç´¢é˜Ÿåˆ—å’ŒliveQæ•°æ®ï¼Œè€Œå¦‚æœä½ çœ‹ç¾å›½åŒ»å­¦é£æ ¼çš„é—®é¢˜ï¼Œå®ƒä»¬å°±åƒé•¿ç¯‡å°æ’æ›²ï¼ŒåŒ»ç”Ÿå¿…é¡»éå¸¸ä»”ç»†åœ°é˜…è¯»è¿™äº›å†…å®¹å¹¶æ‰¾å‡ºæ­£ç¡®ç­”æ¡ˆï¼Œè¿™é€šå¸¸æ¶‰åŠåˆ°ä¸€ä¸ªæ’é™¤çš„è¿‡ç¨‹ã€‚æ‰€ä»¥ï¼Œåº”ç”¨åœºæ™¯éå¸¸ä¸åŒï¼Œæ¨¡å‹å¿…é¡»çœŸæ­£é€‚åº”å¹¶ç†è§£ä»»åŠ¡ï¼Œä»¥ä¾¿åœ¨æ‰€æœ‰è¿™äº›ç¯å¢ƒä¸­è¡¨ç°è‰¯å¥½ã€‚
- en: And live QA is interesting because the answersï¼Œ the reference answers over here
    were actually provided by librariansã€‚so that's another good comparison point for
    us going aheadã€‚And so in terms of statisticsã€‚we had a total of seven data sets
    in this benchmarkï¼Œ as I saidï¼Œ we cover professional medicineã€‚medical research
    and consumer medical questions there again of various different sizes and can
    be long form short form open domain and flow domain so very diverse and I think
    it provides a very comprehensive evaluation of models in this medicaling settingã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: å®æ—¶é—®ç­”å¾ˆæœ‰è¶£ï¼Œå› ä¸ºè¿™é‡Œçš„å‚è€ƒç­”æ¡ˆå®é™…ä¸Šæ˜¯ç”±å›¾ä¹¦é¦†å‘˜æä¾›çš„ã€‚æ‰€ä»¥è¿™ä¸ºæˆ‘ä»¬æœªæ¥çš„æ¯”è¾ƒæä¾›äº†å¦ä¸€ä¸ªå¥½çš„åˆ‡å…¥ç‚¹ã€‚åœ¨ç»Ÿè®¡æ–¹é¢ï¼Œæˆ‘ä»¬åœ¨è¿™ä¸ªåŸºå‡†æµ‹è¯•ä¸­æ€»å…±æœ‰ä¸ƒä¸ªæ•°æ®é›†ã€‚æ­£å¦‚æˆ‘æ‰€è¯´ï¼Œæˆ‘ä»¬æ¶µç›–äº†ä¸“ä¸šåŒ»å­¦ã€åŒ»å­¦ç ”ç©¶å’Œæ¶ˆè´¹è€…åŒ»å­¦é—®é¢˜ï¼Œè¿™äº›é—®é¢˜å„ä¸ç›¸åŒï¼Œæ—¢æœ‰é•¿æ ¼å¼ä¹Ÿæœ‰çŸ­æ ¼å¼ï¼Œæ¶‰åŠå¼€æ”¾é¢†åŸŸå’ŒæµåŸŸï¼Œå› æ­¤éå¸¸å¤šæ ·åŒ–ã€‚æˆ‘è®¤ä¸ºè¿™ä¸ºåœ¨åŒ»å­¦é¢†åŸŸä¸­å¯¹æ¨¡å‹çš„ç»¼åˆè¯„ä¼°æä¾›äº†éå¸¸å…¨é¢çš„ä¾æ®ã€‚
- en: So we have a task on the benchmark the next question again I think asked was
    how do we evaluate these models and as I mentioned before automated metrics are
    actually deeply unsatisfactory because they fail to capture the nuances of real
    world clinical applications so what we did was actually heavily inspired by some
    of Steven's work over here was to put together a human evaluation framework for
    assessing these longform answerss andã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬åœ¨åŸºå‡†ä¸Šæœ‰ä¸€ä¸ªä»»åŠ¡ï¼Œæ¥ä¸‹æ¥çš„é—®é¢˜æˆ‘è®¤ä¸ºæ˜¯é—®æˆ‘ä»¬å¦‚ä½•è¯„ä¼°è¿™äº›æ¨¡å‹ï¼Œæ­£å¦‚æˆ‘ä¹‹å‰æåˆ°çš„ï¼Œè‡ªåŠ¨åŒ–æŒ‡æ ‡å®é™…ä¸Šæ˜¯éå¸¸ä¸ä»¤äººæ»¡æ„çš„ï¼Œå› ä¸ºå®ƒä»¬æœªèƒ½æ•æ‰åˆ°çœŸå®ä¸–ç•Œä¸´åºŠåº”ç”¨çš„ç»†å¾®å·®åˆ«ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æ‰€åšçš„å®é™…ä¸Šæ˜¯æ·±å—æ–¯è’‚æ–‡çš„ä¸€äº›å·¥ä½œçš„å¯å‘ï¼Œæ„å»ºäº†ä¸€ä¸ªäººç±»è¯„ä¼°æ¡†æ¶æ¥è¯„ä¼°è¿™äº›é•¿ç¯‡å›ç­”ã€‚
- en: This had two partsï¼Œ the first part was evaluation by clinicians and we asked
    them to rate the moral responses along 12 axes pertaining to factuality of the
    responsesã€‚ability to recall medical knowledge to medical reasoningã€‚and also for
    the potential of harm and bias in these responsesã€‚But if you look at like the
    potential end users of such medical Q&A systems these are likely going to be non-
    expertpert layer usersã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼Œç¬¬ä¸€éƒ¨åˆ†æ˜¯ä¸´åºŠåŒ»ç”Ÿçš„è¯„ä¼°ï¼Œæˆ‘ä»¬è®©ä»–ä»¬æ ¹æ®ä¸å›ç­”çš„çœŸå®æ€§ç›¸å…³çš„12ä¸ªç»´åº¦å¯¹é“å¾·ååº”è¿›è¡Œè¯„åˆ†ã€‚åŒ…æ‹¬å›å¿†åŒ»å­¦çŸ¥è¯†çš„èƒ½åŠ›ã€åŒ»å­¦æ¨ç†ï¼Œä»¥åŠè¿™äº›ååº”ä¸­æ½œåœ¨çš„ä¼¤å®³å’Œåè§ã€‚ä½†å¦‚æœä½ çœ‹ä¸€ä¸‹è¿™äº›åŒ»å­¦é—®ç­”ç³»ç»Ÿçš„æ½œåœ¨æœ€ç»ˆç”¨æˆ·ï¼Œä»–ä»¬å¾ˆå¯èƒ½æ˜¯éä¸“å®¶å±‚çš„ç”¨æˆ·ã€‚
- en: so it is also important to get these answers evaluated by them as well and so
    we also additionally asked a pool of lay users as to how helpful and actionable
    they thought the answers wereã€‚And so that was our evaluation framework and we
    also have the benchmark fixã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œè®©ä»–ä»¬è¯„ä¼°è¿™äº›ç­”æ¡ˆä¹Ÿå¾ˆé‡è¦ï¼Œå› æ­¤æˆ‘ä»¬è¿˜é¢å¤–è¯¢é—®äº†ä¸€ç»„æ™®é€šç”¨æˆ·ï¼Œçœ‹çœ‹ä»–ä»¬è®¤ä¸ºè¿™äº›ç­”æ¡ˆæœ‰å¤šæœ‰å¸®åŠ©å’Œå¯æ“ä½œã€‚å› æ­¤ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬çš„è¯„ä¼°æ¡†æ¶ï¼Œæˆ‘ä»¬ä¹Ÿæœ‰åŸºå‡†å›ºå®šã€‚
- en: so now we've moved a fun part of building and aligning LLM to the medical domain
    taskã€‚So in this work we decide to build on the Palm family of language models
    has that been covered in the coast beforeã€‚okay greatï¼Œ so but very quicklyï¼Œ I believe
    this is still the largest publicly announced densely activated decodrenly large
    language model with the largest one being fine 40 billion parameters in totalã€‚A
    few more detailsï¼Œ the model strain on SA 40 billion tokensï¼Œ 25% of which is multilingualã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ç°åœ¨æˆ‘ä»¬å·²ç»å°†æ„å»ºå’Œå¯¹é½LLMçš„æœ‰è¶£éƒ¨åˆ†è½¬å‘åŒ»ç–—é¢†åŸŸçš„ä»»åŠ¡ã€‚æˆ‘ä»¬å†³å®šåŸºäºä¹‹å‰æåˆ°çš„Palmç³»åˆ—è¯­è¨€æ¨¡å‹è¿›è¡Œå·¥ä½œã€‚å¥½çš„ï¼Œå¾ˆæ£’ï¼Œä½†æˆ‘ç›¸ä¿¡è¿™ä»ç„¶æ˜¯å…¬å¼€å®£å¸ƒçš„æ¿€æ´»å¯†é›†çš„è§£ç å¤§å‹è¯­è¨€æ¨¡å‹ä¸­è§„æ¨¡æœ€å¤§çš„ä¸€ä¸ªï¼Œæœ€å¤§çš„æ¨¡å‹æ€»å…±æœ‰400äº¿ä¸ªå‚æ•°ã€‚è¿˜æœ‰æ›´å¤šç»†èŠ‚ï¼Œè¯¥æ¨¡å‹åœ¨400äº¿ä¸ªä»¤ç‰Œä¸Šè¿›è¡Œè®­ç»ƒï¼Œå…¶ä¸­25%æ˜¯å¤šè¯­è¨€çš„ã€‚
- en: the data come from a bunch of different sourcesï¼Œ including social media conversationsï¼Œ
    web pagesã€‚booksï¼Œ GitHubï¼Œ and Wikipedia and so on and so forthã€‚And at that time
    of releaseã€‚the model was shared the art on many NLP reasoning benchmarks and also
    was the first model to exceed the average human performance on Big Bennchã€‚Further
    over the last yearï¼Œ palm derived models were shown to be super useful in a bunch
    of different application settingsã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®æ¥è‡ªå¤šä¸ªä¸åŒçš„æ¥æºï¼ŒåŒ…æ‹¬ç¤¾äº¤åª’ä½“å¯¹è¯ã€ç½‘é¡µã€ä¹¦ç±ã€GitHub å’Œç»´åŸºç™¾ç§‘ç­‰ã€‚åœ¨å‘å¸ƒæ—¶ï¼Œè¯¥æ¨¡å‹åœ¨è®¸å¤š NLP æ¨ç†åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œå¹¶ä¸”æ˜¯ç¬¬ä¸€ä¸ªè¶…è¶Šäººç±»å¹³å‡è¡¨ç°çš„æ¨¡å‹ã€‚è¿›ä¸€æ­¥æ¥è¯´ï¼Œåœ¨è¿‡å»ä¸€å¹´ä¸­ï¼Œæºäº
    Palm çš„æ¨¡å‹åœ¨å¤šä¸ªåº”ç”¨åœºæ™¯ä¸­è¢«è¯æ˜éå¸¸æœ‰ç”¨ã€‚
- en: including for cogenï¼Œ which was the palmM code model and roboticsã€‚the palm Saan
    model and also for answering math and science questionsï¼Œ which was the Minva modelsã€‚and
    so we thought PAM was a very good foundation model for us to build on and use
    it in the medical domain as wellã€‚And overallï¼Œ I think Palmm is a true magic of
    engineeringã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: åŒ…æ‹¬ç”¨äºcogençš„å†…å®¹ï¼Œè¿™å°±æ˜¯palmMä»£ç æ¨¡å‹å’Œæœºå™¨äººæŠ€æœ¯ã€‚palm Saanæ¨¡å‹ï¼Œä»¥åŠç”¨äºå›ç­”æ•°å­¦å’Œç§‘å­¦é—®é¢˜çš„Minvaæ¨¡å‹ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è®¤ä¸ºPAMæ˜¯ä¸€ä¸ªéå¸¸å¥½çš„åŸºç¡€æ¨¡å‹ï¼Œå¯ä»¥åœ¨åŒ»ç–—é¢†åŸŸè¿›è¡Œæ„å»ºå’Œä½¿ç”¨ã€‚æ€»çš„æ¥è¯´ï¼Œæˆ‘è®¤ä¸ºPalmmæ˜¯çœŸæ­£çš„å·¥ç¨‹å¥‡è¿¹ã€‚
- en: but I will refer you all back to Acsha's paper on this for more details I think
    it's a must readã€‚And again in late October last yearï¼Œ Jason Way and a few others
    at Google Bra came out with the F palm variant of these of the palmM model and
    this is basically the instruction tune counterpart and this model was even better
    than PM and I believe it is still the sort of sort of yard on many benchmarks
    such as MMLuã€‚
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘ä¼šæŠŠä½ ä»¬éƒ½å¼•å¯¼å› Acsha çš„è®ºæ–‡ï¼Œäº†è§£æ›´å¤šç»†èŠ‚ï¼Œæˆ‘è®¤ä¸ºè¿™æ˜¯ä¸€ç¯‡å¿…è¯»ä¹‹ä½œã€‚å†è¯´ä¸€æ¬¡ï¼Œå»å¹´åæœˆåº•ï¼ŒJason Way å’Œè°·æ­Œçš„å…¶ä»–å‡ ä½åŒäº‹æ¨å‡ºäº†è¿™äº›
    palmM æ¨¡å‹çš„ F palm å˜ä½“ï¼ŒåŸºæœ¬ä¸Šæ˜¯æŒ‡ä»¤è°ƒä¼˜çš„å¯¹åº”æ¨¡å‹ï¼Œè¿™ä¸ªæ¨¡å‹ç”šè‡³æ¯” PM æ›´ä¼˜ç§€ï¼Œæˆ‘ç›¸ä¿¡å®ƒåœ¨è®¸å¤šåŸºå‡†æµ‹è¯•ä¸­ä»ç„¶æ˜¯ä¸€ä¸ªæ ‡æ†ï¼Œæ¯”å¦‚ MMLuã€‚
- en: TiDQA and I think it exceeds palm performance by an average of 9ã€‚4% across big
    bench tasksã€‚Soã€‚So we decided to build on the F palm model and we applied a combination
    of prompting strategiesã€‚including few short promptingï¼Œ chain of thought reasoning
    and also cell consistency to the54 billion parameter variantã€‚and we evaluated
    it on the multimQA data sets that had these short form MCQ questionsã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: TiDQAå’Œæˆ‘è®¤ä¸ºå®ƒåœ¨å¤§å‹åŸºå‡†ä»»åŠ¡ä¸­å¹³å‡è¶…è¿‡äº†Palmæ€§èƒ½9.4%ã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬å†³å®šåŸºäºF Palmæ¨¡å‹è¿›è¡Œæ„å»ºï¼Œå¹¶åº”ç”¨äº†å¤šç§æç¤ºç­–ç•¥ï¼ŒåŒ…æ‹¬çŸ­æç¤ºã€æ€ç»´é“¾æ¨ç†ä»¥åŠå•å…ƒä¸€è‡´æ€§åˆ°54äº¿å‚æ•°çš„å˜ä½“ä¸Šã€‚æˆ‘ä»¬åœ¨åŒ…å«è¿™äº›çŸ­å½¢å¼MCQé—®é¢˜çš„multimQAæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚
- en: And we found that this model was really really good at the time of publicationationã€‚this
    model on the USM Me data set exceeded the previous state of the art by over 17%ã€‚It's
    only for the USMLE Me area that's right and so you see that the accuracy over
    the previous year of Y at the time of publication went up by over 17% and I believe
    this was the first LLM basedDI system to obtain like a passing equivalent score
    which was 60% or above on this benchmarkã€‚
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å‘ç°è¿™ä¸ªæ¨¡å‹åœ¨å‘å¸ƒæ—¶ç¡®å®è¡¨ç°å¾—éå¸¸å‡ºè‰²ã€‚è¿™ä¸ªæ¨¡å‹åœ¨USM Meæ•°æ®é›†ä¸Šçš„è¡¨ç°è¶…è¿‡äº†ä¹‹å‰çš„æœ€å…ˆè¿›æ°´å¹³è¶…è¿‡17%ã€‚å®ƒä»…é€‚ç”¨äºUSMLE Meé¢†åŸŸï¼Œå› æ­¤ä½ ä¼šçœ‹åˆ°åœ¨å‘å¸ƒæ—¶ï¼Œç›¸è¾ƒäºå‰ä¸€å¹´çš„Yï¼Œå…¶å‡†ç¡®ç‡æå‡äº†è¶…è¿‡17%ï¼Œæˆ‘ç›¸ä¿¡è¿™æ˜¯ç¬¬ä¸€ä¸ªåŸºäºLLMçš„DIç³»ç»Ÿåœ¨è¯¥åŸºå‡†ä¸Šè·å¾—60%æˆ–ä»¥ä¸ŠåŠæ ¼ç›¸å½“åˆ†æ•°çš„ç³»ç»Ÿã€‚
- en: And similarlyï¼Œ when we looked at other MCQ data sets in the benchmarkï¼Œ for exampleï¼Œ
    MCQAã€‚which is a data set of Indian medical entrance examination questionsã€‚the
    model was again the state of the art on PubMC which was question answering based
    on Pubmed abstractsã€‚that was again the model was state of the art at the time
    of publication and same story on MMLU clinical topics as well which include geneticsã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»ä¼¼åœ°ï¼Œå½“æˆ‘ä»¬æŸ¥çœ‹åŸºå‡†ä¸­çš„å…¶ä»–å¤šé¡¹é€‰æ‹©é¢˜æ•°æ®é›†æ—¶ï¼Œä¾‹å¦‚ï¼ŒMCQAã€‚å®ƒæ˜¯ä¸€ä¸ªå°åº¦åŒ»å­¦å…¥å­¦è€ƒè¯•é—®é¢˜çš„æ•°æ®é›†ã€‚è¯¥æ¨¡å‹åœ¨åŸºäºPubmedæ‘˜è¦çš„é—®ç­”ç³»ç»ŸPubMCä¸Šå†æ¬¡è¾¾åˆ°äº†æœ€å…ˆè¿›æ°´å¹³ã€‚é‚£æ—¶ï¼Œè¯¥æ¨¡å‹åœ¨å‘å¸ƒæ—¶ä¹Ÿæ˜¯æœ€å…ˆè¿›çš„ï¼ŒMMLUä¸´åºŠä¸»é¢˜çš„æƒ…å†µä¹Ÿæ˜¯å¦‚æ­¤ï¼Œå…¶ä¸­åŒ…æ‹¬é—ä¼ å­¦ã€‚
- en: anatomy professional medicineï¼Œ clinical knowledge and a bunch of other topics
    in thereã€‚Soã€‚All this was great and then when we started looking at the scaling
    plotsã€‚what we saw was that the performance seemed to be improving as we scaled
    the model from 8 billion to 62 billion to 5 and40 billionã€‚And so what this basically
    suggested that these general purpose large language models trained on public internet
    seem to encode clinical knowledge pretty well and their medical reasoning abilities
    tend to scale with model parameter sizeã€‚
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: è§£å‰–å­¦ä¸“ä¸šåŒ»å­¦ã€ä¸´åºŠçŸ¥è¯†ä»¥åŠå…¶ä»–ä¸€äº›ä¸»é¢˜éƒ½åœ¨å…¶ä¸­ã€‚æ‰€ä»¥ã€‚æ‰€æœ‰è¿™äº›éƒ½å¾ˆå¥½ï¼Œç„¶åå½“æˆ‘ä»¬å¼€å§‹æŸ¥çœ‹ç¼©æ”¾å›¾æ—¶ã€‚æˆ‘ä»¬çœ‹åˆ°çš„æ˜¯ï¼Œéšç€æˆ‘ä»¬å°†æ¨¡å‹ä»80äº¿æ‰©å±•åˆ°620äº¿ï¼Œå†åˆ°540äº¿ï¼Œæ€§èƒ½ä¼¼ä¹åœ¨æ”¹å–„ã€‚å› æ­¤ï¼Œè¿™åŸºæœ¬ä¸Šè¡¨æ˜ï¼Œè¿™äº›åœ¨å…¬å…±äº’è”ç½‘è®­ç»ƒçš„é€šç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä¼¼ä¹å¾ˆå¥½åœ°ç¼–ç äº†ä¸´åºŠçŸ¥è¯†ï¼Œå¹¶ä¸”å®ƒä»¬çš„åŒ»å­¦æ¨ç†èƒ½åŠ›å¾€å¾€éšç€æ¨¡å‹å‚æ•°çš„å¢å¤§è€Œæå‡ã€‚
- en: We also did another experiment when we looked at selective prediction and we
    used the self-consency votes to determine when to differã€‚and this is important
    in clinical settings because doctors communicate when they don't know about something
    and if our AI systems are going to be used in clinical settings for example for
    diagnosisã€‚
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜è¿›è¡Œäº†å¦ä¸€ä¸ªå®éªŒï¼Œç ”ç©¶é€‰æ‹©æ€§é¢„æµ‹ï¼Œå¹¶ä½¿ç”¨è‡ªæˆ‘ä¸€è‡´æ€§æŠ•ç¥¨æ¥ç¡®å®šä½•æ—¶å‡ºç°å·®å¼‚ã€‚è¿™åœ¨ä¸´åºŠç¯å¢ƒä¸­éå¸¸é‡è¦ï¼Œå› ä¸ºåŒ»ç”Ÿåœ¨ä¸ç¡®å®šæŸä»¶äº‹æ—¶ä¼šè¿›è¡Œæ²Ÿé€šï¼Œå¦‚æœæˆ‘ä»¬çš„AIç³»ç»Ÿè¦åœ¨ä¸´åºŠç¯å¢ƒä¸­ä½¿ç”¨ï¼Œä¾‹å¦‚ç”¨äºè¯Šæ–­ã€‚
- en: they should be able to tell you when they don't know somethingã€‚And so what we
    observed here was this fairly crude metric we were getting like a linear improvement
    in performance as we changed the defral threshold and this was quite nice but
    in practice it is actually quite ineffient because you are generating like you
    know multiple decoding samples to be able to compute this metric so we need a
    better method ask yeah it's basically says I'm uncertain around one and that's
    determined based on the cell consistency works so exactly same exactlyã€‚
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ä»–ä»¬åº”è¯¥èƒ½å¤Ÿå‘Šè¯‰ä½ ä»€ä¹ˆæ—¶å€™ä»–ä»¬ä¸çŸ¥é“æŸä»¶äº‹æƒ…ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œè§‚å¯Ÿåˆ°çš„æ˜¯ä¸€ä¸ªç›¸å½“ç²—ç³™çš„æŒ‡æ ‡ï¼Œéšç€æˆ‘ä»¬æ”¹å˜é»˜è®¤é˜ˆå€¼ï¼Œæ€§èƒ½æœ‰çº¿æ€§æ”¹å–„ï¼Œè¿™å¾ˆå¥½ï¼Œä½†å®é™…ä¸Šæ•ˆç‡ç›¸å½“ä½ï¼Œå› ä¸ºä½ ç”Ÿæˆå¤šä¸ªè§£ç æ ·æœ¬æ¥è®¡ç®—è¿™ä¸ªæŒ‡æ ‡ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦ä¸€ç§æ›´å¥½çš„æ–¹æ³•ã€‚æ˜¯çš„ï¼Œè¿™åŸºæœ¬ä¸Šæ˜¯è¯´æˆ‘å¯¹ä¸€ä¸ªå‘¨å›´æ„Ÿåˆ°ä¸ç¡®å®šï¼Œè€Œè¿™å–å†³äºå•å…ƒä¸€è‡´æ€§å·¥ä½œï¼Œæ‰€ä»¥å®Œå…¨ç›¸åŒã€‚
- en: So theNo because they're just trained on this expert prediction task and that
    depends on the data the PubM QA has some answers which are maybe but again we
    don't explicitly find tune in the models over here so no the models are not trainedã€‚Yeahï¼Œ
    so that is where we have this medical runs in the long zero lotã€‚Noã€‚
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä¸ï¼Œå› ä¸ºå®ƒä»¬ä»…ä»…æ˜¯åœ¨è¿™ä¸ªä¸“å®¶é¢„æµ‹ä»»åŠ¡ä¸Šè¿›è¡Œè®­ç»ƒï¼Œè¿™ä¾èµ–äºæ•°æ®ï¼ŒPubM QAæœ‰ä¸€äº›å¯èƒ½çš„ç­”æ¡ˆï¼Œä½†æˆ‘ä»¬å¹¶æ²¡æœ‰åœ¨è¿™é‡Œæ˜ç¡®åœ°å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œæ‰€ä»¥ä¸ï¼Œæ¨¡å‹å¹¶æ²¡æœ‰ç»è¿‡è®­ç»ƒã€‚æ˜¯çš„ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬åœ¨è¿™ä¸ªåŒ»ç–—é¢†åŸŸé•¿æ—¶é—´è¿è¡Œçš„åŸå› ã€‚æ²¡æœ‰ã€‚
- en: so this is primarily based on the reference of in the data sets which is so
    this is all accuracy matrix so we already know between the four options of I options
    which one's the right one and so we just do the classification yeah so I'll come
    back to the condition evaluation aitratorã€‚
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™ä¸»è¦æ˜¯åŸºäºæ•°æ®é›†ä¸­çš„å‚è€ƒï¼Œè¿™å°±æ˜¯æ‰€æœ‰çš„å‡†ç¡®æ€§çŸ©é˜µï¼Œæ‰€ä»¥æˆ‘ä»¬å·²ç»çŸ¥é“å››ä¸ªé€‰é¡¹ä¸­å“ªä¸€ä¸ªæ˜¯æ­£ç¡®çš„ï¼Œå› æ­¤æˆ‘ä»¬åªéœ€è¿›è¡Œåˆ†ç±»ã€‚æ˜¯çš„ï¼Œæˆ‘ä¼šå›åˆ°æ¡ä»¶è¯„ä¼°çš„aiè¯„ä¼°å™¨ã€‚
- en: So maybe is something how are you naturally uncertainty so if you know what
    selfconency prompting what we do is we generate multiple decos from the same model
    and then we see the number of times the highest ranking answer is voted and based
    on that you can fix a threshold and say if it's below this number I'm going to
    differ so if say the majority answer comes up in your selfconsency decode only
    like n times out of k or whatever then that if that n is too small then it's very
    likely the model's uncertain so that's how we differã€‚
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä¹Ÿè®¸æ˜¯å…³äºä½ è‡ªç„¶ä¸ç¡®å®šæ€§çš„æŸç§æƒ…å†µï¼Œå› æ­¤å¦‚æœä½ çŸ¥é“è‡ªæ´½æç¤ºæ˜¯ä»€ä¹ˆï¼Œæˆ‘ä»¬æ‰€åšçš„æ˜¯ä»åŒä¸€ä¸ªæ¨¡å‹ç”Ÿæˆå¤šä¸ªè§£ç ï¼Œç„¶åæŸ¥çœ‹æœ€é«˜æ’åçš„ç­”æ¡ˆè¢«æŠ•ç¥¨çš„æ¬¡æ•°ï¼Œæ ¹æ®è¿™ä¸ªä½ å¯ä»¥è®¾å®šä¸€ä¸ªé˜ˆå€¼ï¼Œè‹¥ä½äºè¿™ä¸ªæ•°å­—æˆ‘å°±ä¼šé€‰æ‹©ä¸åŒçš„ç­”æ¡ˆã€‚æ‰€ä»¥å¦‚æœåœ¨ä½ çš„è‡ªæ´½è§£ç ä¸­ï¼Œå¤§å¤šæ•°ç­”æ¡ˆä»…å‡ºç°äº†
    n æ¬¡ï¼Œè€Œæ€»å…±æœ‰ k æ¬¡æŠ•ç¥¨ï¼Œè‹¥è¿™ä¸ª n å¤ªå°ï¼Œé‚£ä¹ˆæ¨¡å‹å¾ˆå¯èƒ½æ˜¯ä¸ç¡®å®šçš„ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬é€‰æ‹©ä¸åŒç­”æ¡ˆçš„æ–¹å¼ã€‚
- en: å—¯ã€‚å—¯ã€‚So we don't really see like a paper off in this plotã€‚so like it's actually
    that that what the rest would look likeã€‚I think if you plot it further to flatlineï¼Œ
    but again that's not useful I mean if you're saying no to every question that's
    not useful at also you want to have a reasonable deferral percentage of I think
    that's high I think that's still high 50% is quite high but again that this is
    a very contrived setting but in real world use cases is probably I think that
    number should be much lowerã€‚
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: å—¯ã€‚å—¯ã€‚æ‰€ä»¥æˆ‘ä»¬åœ¨è¿™ä¸ªå›¾ä¸­å¹¶æ²¡æœ‰çœ‹åˆ°åƒçº¸ä¸€æ ·çš„ä¸œè¥¿ã€‚å®é™…ä¸Šï¼Œå…¶ä½™éƒ¨åˆ†ä¼šçœ‹èµ·æ¥åƒè¿™æ ·ã€‚æˆ‘è®¤ä¸ºå¦‚æœä½ ç»§ç»­ç»˜åˆ¶åˆ°å¹³å¦çº¿ï¼Œä½†è¿™åˆæ²¡æœ‰ç”¨ï¼Œæˆ‘æ˜¯è¯´ï¼Œå¦‚æœä½ å¯¹æ¯ä¸ªé—®é¢˜éƒ½è¯´ä¸ï¼Œé‚£ä¹Ÿæ²¡æœ‰ç”¨ã€‚æ­¤å¤–ï¼Œä½ å¸Œæœ›æœ‰ä¸€ä¸ªåˆç†çš„æ‹’ç»æ¯”ä¾‹ï¼Œæˆ‘è§‰å¾—é‚£å¾ˆé«˜ï¼Œæˆ‘è®¤ä¸ºä»ç„¶å¾ˆé«˜ï¼Œ50%æ˜¯ç›¸å½“é«˜çš„ï¼Œä½†è¿™ä»ç„¶æ˜¯ä¸€ä¸ªéå¸¸äººä¸ºçš„è®¾å®šï¼Œè€Œåœ¨ç°å®ä¸–ç•Œçš„ä½¿ç”¨æ¡ˆä¾‹ä¸­ï¼Œæˆ‘è®¤ä¸ºè¿™ä¸ªæ•°å­—åº”è¯¥ä½å¾—å¤šã€‚
- en: might and the data addictsï¼Œ some medical products went to more important than
    othersã€‚so more questionã€‚å—¯ã€‚That's right I think balanced accuracy might be a better
    metric but we looked at some of these data sets and one data set the s was pretty
    bad the Pub data set and I think no one should use it so if anyone's reporting
    sort of numbers on that data you should just discussrus them and'm talking about
    very specific people but again I think as I mentioned these accuracy metrics are
    good for you know publicity and pushing of benchmark numbers and so on and so
    forth but the real evaluation is human evaluation of the long performances and
    that's what I'll come to in the next oneã€‚
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å½±å“å’Œæ•°æ®ä¸Šç˜¾è€…ï¼Œä¸€äº›åŒ»ç–—äº§å“æ¯”å…¶ä»–äº§å“æ›´é‡è¦ã€‚æ‰€ä»¥è¿˜æœ‰æ›´å¤šé—®é¢˜ã€‚å—¯ã€‚æ²¡é”™ï¼Œæˆ‘è®¤ä¸ºå¹³è¡¡å‡†ç¡®ç‡å¯èƒ½æ˜¯æ›´å¥½çš„æŒ‡æ ‡ï¼Œä½†æˆ‘ä»¬æŸ¥çœ‹äº†ä¸€äº›æ•°æ®é›†ï¼Œå…¶ä¸­ä¸€ä¸ªæ•°æ®é›†çš„ç»“æœç›¸å½“ç³Ÿç³•ï¼Œå³Pubæ•°æ®é›†ï¼Œæˆ‘è®¤ä¸ºæ²¡äººåº”è¯¥ä½¿ç”¨å®ƒã€‚æ‰€ä»¥å¦‚æœæœ‰äººåœ¨æŠ¥å‘Šè¯¥æ•°æ®ä¸Šçš„æ•°å­—ï¼Œä½ åº”è¯¥ç›´æ¥è®¨è®ºè¿™äº›é—®é¢˜ã€‚æˆ‘è¯´çš„æ˜¯éå¸¸å…·ä½“çš„äººï¼Œä½†å†æ¬¡å¼ºè°ƒï¼Œæ­£å¦‚æˆ‘æåˆ°çš„ï¼Œè¿™äº›å‡†ç¡®æ€§æŒ‡æ ‡åœ¨å®£ä¼ å’Œæ¨åŠ¨åŸºå‡†æ•°å­—æ–¹é¢å¾ˆå¥½ï¼Œä½†çœŸæ­£çš„è¯„ä¼°æ˜¯å¯¹é•¿æœŸè¡¨ç°çš„äººä¸ºè¯„ä¼°ï¼Œè¿™å°±æ˜¯æˆ‘å°†åœ¨ä¸‹ä¸€ä¸ªä¸­è®¨è®ºçš„å†…å®¹ã€‚
- en: å—¯ã€‚So so far so good right I mean we we were getting solar results on these benchmarks
    and we were very happy and so what we did was I mean one thing you'll observe
    that I have so far only reported results on multiple choice questions shortformances
    so what was left for us to do was to take these answers take these models and
    generate longform answerss to the other data sets that we had and get them human
    evaluated and I think that is where the real project began when we looked at the
    evolvevals by experts on lay people it revealed very like key gaps and limitations
    in the fl farm responsesã€‚
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: å—¯ã€‚é‚£ä¹ˆåˆ°ç›®å‰ä¸ºæ­¢è¿˜ä¸é”™ï¼Œå¯¹å§ï¼Ÿæˆ‘çš„æ„æ€æ˜¯ï¼Œæˆ‘ä»¬åœ¨è¿™äº›åŸºå‡†æµ‹è¯•ä¸­å¾—åˆ°äº†å¤ªé˜³èƒ½çš„ç»“æœï¼Œæˆ‘ä»¬éå¸¸é«˜å…´ã€‚å› æ­¤æˆ‘ä»¬æ‰€åšçš„äº‹æƒ…æ˜¯ï¼Œæˆ‘çš„æ„æ€æ˜¯ï¼Œä½ ä¼šæ³¨æ„åˆ°åˆ°ç›®å‰ä¸ºæ­¢æˆ‘åªæŠ¥å‘Šäº†å…³äºé€‰æ‹©é¢˜çš„ç»“æœï¼Œæ‰€ä»¥æˆ‘ä»¬å‰©ä¸‹è¦åšçš„å°±æ˜¯å°†è¿™äº›ç­”æ¡ˆã€è¿™äº›æ¨¡å‹ç”Ÿæˆé•¿ç­”æ¡ˆï¼Œä»¥ä¾¿äºæˆ‘ä»¬æ‹¥æœ‰çš„å…¶ä»–æ•°æ®é›†ï¼Œå¹¶è¿›è¡Œäººå·¥è¯„ä¼°ã€‚æˆ‘è®¤ä¸ºè¿™æ‰æ˜¯çœŸæ­£é¡¹ç›®å¼€å§‹çš„åœ°æ–¹ï¼Œå½“æˆ‘ä»¬æŸ¥çœ‹ä¸“å®¶å¯¹æ™®é€šäººçš„è¯„ä¼°æ—¶ï¼Œå®ƒæ­ç¤ºäº†åœ¨å“åº”ä¸­å­˜åœ¨çš„å…³é”®å·®è·å’Œå±€é™æ€§ã€‚
- en: we were often seeing that these models were hallucinating or producing incomp
    responses and when we asked experts like whether they preferred clinician generated
    answers or these model generated answerss they almost always preferred clinician
    generated answerssã€‚
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¸¸å¸¸å‘ç°è¿™äº›æ¨¡å‹ä¼šäº§ç”Ÿå¹»è§‰æˆ–ç”Ÿæˆä¸å®Œæ•´çš„å›åº”ï¼Œå½“æˆ‘ä»¬è¯¢é—®ä¸“å®¶æ—¶ï¼Œä»–ä»¬æ˜¯å¦æ›´å–œæ¬¢ä¸´åºŠåŒ»ç”Ÿç”Ÿæˆçš„ç­”æ¡ˆè¿˜æ˜¯è¿™äº›æ¨¡å‹ç”Ÿæˆçš„ç­”æ¡ˆæ—¶ï¼Œä»–ä»¬å‡ ä¹æ€»æ˜¯æ›´å–œæ¬¢ä¸´åºŠåŒ»ç”Ÿç”Ÿæˆçš„ç­”æ¡ˆã€‚
- en: å—¯ã€‚So it was very clear that they bothã€‚And so what these previous results showed
    was while these models already encode some degree of clinical knowledge to be
    really used in actual real settingsã€‚you need to align these models better to the
    safety critical requirements of the medical domainã€‚
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: å—¯ã€‚æ‰€ä»¥å¾ˆæ˜æ˜¾ï¼Œä»–ä»¬ä¸¤è€…éƒ½ã€‚ä¹‹å‰çš„ç»“æœæ˜¾ç¤ºï¼Œè¿™äº›æ¨¡å‹è™½ç„¶å·²ç»ç¼–ç äº†ä¸€å®šç¨‹åº¦çš„ä¸´åºŠçŸ¥è¯†ï¼Œå¯ä»¥åœ¨å®é™…ç¯å¢ƒä¸­ä½¿ç”¨ï¼Œä½†ä½ éœ€è¦æ›´å¥½åœ°å°†è¿™äº›æ¨¡å‹ä¸åŒ»ç–—é¢†åŸŸçš„å®‰å…¨å…³é”®è¦æ±‚å¯¹é½ã€‚
- en: But a big challenge is we did not have any kind of supervised our feedback dataã€‚and
    so we really need the alignment technique to be data efficientã€‚But thankfullyã€‚we
    had instruction from tuningï¼Œ which was introduced by Brian Lester and a few others
    at Google a couple of years backã€‚and how this method works is it essentially freezes
    the big LLM model and only learns an additional small set of prompt vectors which
    can then be used to condition the model that inference when doing the generationã€‚
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†ä¸€ä¸ªå¤§æŒ‘æˆ˜æ˜¯æˆ‘ä»¬æ²¡æœ‰ä»»ä½•å½¢å¼çš„ç›‘ç£åé¦ˆæ•°æ®ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çœŸçš„éœ€è¦å¯¹é½æŠ€æœ¯ä»¥æé«˜æ•°æ®æ•ˆç‡ã€‚ä¸è¿‡ï¼Œå€¼å¾—åº†å¹¸çš„æ˜¯ï¼Œæˆ‘ä»¬å¾—åˆ°äº†è°ƒä¼˜çš„æŒ‡å¯¼ï¼Œè¿™ä¸€æ–¹æ³•æ˜¯ç”±å¸ƒè±æ©Â·è±æ–¯ç‰¹å’Œè°·æ­Œçš„å‡ ä½å…¶ä»–äººå‡ å¹´å‰æå‡ºçš„ã€‚è¿™ç§æ–¹æ³•çš„å·¥ä½œåŸç†åŸºæœ¬ä¸Šæ˜¯å†»ç»“å¤§å‹
    LLM æ¨¡å‹ï¼Œåªå­¦ä¹ ä¸€å°éƒ¨åˆ†é¢å¤–çš„æç¤ºå‘é‡ï¼Œè¿™äº›å‘é‡å¯ä»¥åœ¨ç”Ÿæˆæ—¶ç”¨äºå¯¹æ¨¡å‹è¿›è¡Œæ¡ä»¶åŒ–ã€‚
- en: And the nice thing about this is it allows very easy use of the model across
    tasks and domainsã€‚and you only need to like carry around these additional prompt
    parameters right and these tend to be much smaller than like the the billions
    of parameters that you have in the otherã€‚
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œè¿™æœ€å¥½çš„åœ°æ–¹åœ¨äºï¼Œå®ƒå…è®¸åœ¨ä¸åŒä»»åŠ¡å’Œé¢†åŸŸä¸­éå¸¸å®¹æ˜“åœ°ä½¿ç”¨æ¨¡å‹ã€‚è€Œä¸”ä½ åªéœ€è¦æºå¸¦è¿™äº›é¢å¤–çš„æç¤ºå‚æ•°ï¼Œè¿™äº›é€šå¸¸æ¯”å…¶ä»–æ¨¡å‹ä¸­æ•°åäº¿çš„å‚æ•°è¦å°å¾—å¤šã€‚
- en: And the other good thing is this is very computationally efficient as wellã€‚so
    like if you were to do end to end fine tuning often in our compute infrastructureã€‚even
    with like a few thousand examples that would take like a few days whereas with
    instruction prompt tuning given the data set size is also reduced the number of
    examples that you need is quite small and just updating the prompt token vectors
    it meant that we were able to get model updates in like a few hours and so that
    was like really fast and enabled like really quick iterations for usã€‚
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªå¥½å¤„æ˜¯ï¼Œè¿™ç§æ–¹æ³•åœ¨è®¡ç®—ä¸Šä¹Ÿéå¸¸é«˜æ•ˆã€‚æ‰€ä»¥ï¼Œå¦‚æœä½ åœ¨æˆ‘ä»¬çš„è®¡ç®—åŸºç¡€è®¾æ–½ä¸Šè¿›è¡Œç«¯åˆ°ç«¯çš„å¾®è°ƒï¼Œå³ä½¿æœ‰å‡ åƒä¸ªä¾‹å­ï¼Œè¿™ä¹Ÿå¯èƒ½éœ€è¦å‡ å¤©çš„æ—¶é—´ï¼Œè€Œé€šè¿‡æŒ‡ä»¤æç¤ºå¾®è°ƒï¼Œç”±äºæ•°æ®é›†çš„å¤§å°å‡å°‘äº†ï¼Œä½ æ‰€éœ€çš„ä¾‹å­æ•°é‡éå¸¸å°‘ï¼Œåªéœ€æ›´æ–°æç¤ºä»¤ç‰Œå‘é‡ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬èƒ½å¤Ÿåœ¨å‡ å°æ—¶å†…è·å¾—æ¨¡å‹æ›´æ–°ï¼Œè¿™æ ·çœŸçš„å¾ˆå¿«ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿè¿›è¡Œéå¸¸å¿«é€Ÿçš„è¿­ä»£ã€‚
- en: So this was how we put together the final metPm model we so this was how we
    put together the final metPm model so we used instructions and exemplars from
    a panel of expert clinicians and these are in the order of hundreds not like thousands
    of tens of thousands and you see a few examples over there there's an instruction
    followed by model answer followed by an explanation and we use that to learn the
    prompt vectors and so the final metPm model is basically of plan pump plus these
    additional softpro vector parameters which are used to align the model to the
    requirements of the medical domain and why this works well is because as we have
    seen before the model already has medical knowledge encoded in it all we need
    is to like least the model how to use it properly in the given application setting
    and that's what these prompt parameters to for usã€‚
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯æˆ‘ä»¬å¦‚ä½•æ•´åˆæœ€ç»ˆçš„metPmæ¨¡å‹çš„è¿‡ç¨‹ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†æ¥è‡ªä¸“å®¶ä¸´åºŠåŒ»ç”Ÿå°ç»„çš„æŒ‡ç¤ºå’Œç¤ºä¾‹ï¼Œè¿™äº›æŒ‡ç¤ºå’Œç¤ºä¾‹æ•°é‡æ˜¯å‡ ç™¾ï¼Œè€Œä¸æ˜¯å‡ åƒæˆ–å‡ ä¸‡ï¼Œä½ å¯ä»¥çœ‹åˆ°é‚£é‡Œçš„å‡ ä¸ªç¤ºä¾‹ï¼Œæœ‰ä¸€ä¸ªæŒ‡ç¤ºï¼Œåé¢æ˜¯æ¨¡å‹ç­”æ¡ˆï¼Œå†åé¢æ˜¯è§£é‡Šï¼Œæˆ‘ä»¬ç”¨è¿™äº›æ¥å­¦ä¹ æç¤ºå‘é‡ã€‚å› æ­¤ï¼Œæœ€ç»ˆçš„metPmæ¨¡å‹åŸºæœ¬ä¸Šæ˜¯è®¡åˆ’æ³µåŠ ä¸Šè¿™äº›é¢å¤–çš„softproå‘é‡å‚æ•°ï¼Œè¿™äº›å‚æ•°ç”¨äºå°†æ¨¡å‹ä¸åŒ»ç–—é¢†åŸŸçš„è¦æ±‚å¯¹é½ã€‚ä¹‹æ‰€ä»¥è¿™æ ·åšæ•ˆæœå¾ˆå¥½ï¼Œæ˜¯å› ä¸ºæ­£å¦‚æˆ‘ä»¬ä¹‹å‰çœ‹åˆ°çš„ï¼Œæ¨¡å‹ä¸­å·²ç»ç¼–ç äº†åŒ»å­¦çŸ¥è¯†ï¼Œæˆ‘ä»¬æ‰€éœ€è¦çš„åªæ˜¯æ•™ä¼šæ¨¡å‹å¦‚ä½•åœ¨ç»™å®šçš„åº”ç”¨ç¯å¢ƒä¸­æ­£ç¡®ä½¿ç”¨è¿™äº›çŸ¥è¯†ï¼Œè€Œè¿™æ­£æ˜¯è¿™äº›æç¤ºå‚æ•°çš„ä½œç”¨ã€‚
- en: So the question I wanted to ask isï¼Œ nowadays you've probably seen a lot about
    like borrow in chatã€‚and given the fact that you have all of these human preferences
    expressed by your elevatorersã€‚and you guys and you guys try playing that a reward
    or preference modelã€‚Yeah I think you can think about like difference changes of
    model development right so this is pre deploymentloyment and release in the real
    world so you can't put a crappy model out there in the real world so even before
    doing that if you can like get like maybe 10 examples from whatever experts that
    you can get heard of and use that to prompt your new model that's better that's
    a much better starting point before you expose the model to the real world and
    collect references from real users at scale and so I think RLH is also much less
    sample efficient compared to instruction prompt tuning again because you're probably
    trying to update your entire model as well so I think this is a very good starting
    point and so they can be combined depending on how depending on the lifecycl of
    the modelã€‚
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘æƒ³é—®çš„é—®é¢˜æ˜¯ï¼Œç°åœ¨ä½ å¯èƒ½çœ‹åˆ°å¾ˆå¤šå…³äºåœ¨èŠå¤©ä¸­å€Ÿç”¨çš„å†…å®¹ã€‚å¹¶ä¸”è€ƒè™‘åˆ°ä½ æœ‰æ‰€æœ‰è¿™äº›ç”±ä½ çš„è¯„ä¼°è€…è¡¨è¾¾çš„äººç±»åå¥½ã€‚ä½ ä»¬è¯•å›¾å°†å…¶è½¬åŒ–ä¸ºå¥–åŠ±æˆ–åå¥½æ¨¡å‹ã€‚æ˜¯çš„ï¼Œæˆ‘è®¤ä¸ºä½ å¯ä»¥è€ƒè™‘æ¨¡å‹å‘å±•çš„ä¸åŒå˜åŒ–ï¼Œæ‰€ä»¥è¿™æ˜¯éƒ¨ç½²å‰çš„é˜¶æ®µï¼Œå¹¶åœ¨ç°å®ä¸–ç•Œä¸­å‘å¸ƒï¼Œå› æ­¤ä½ ä¸èƒ½å°†ä¸€ä¸ªç³Ÿç³•çš„æ¨¡å‹æ”¾åˆ°ç°å®ä¸–ç•Œä¸­ã€‚æ‰€ä»¥åœ¨åšåˆ°è¿™ä¸€ç‚¹ä¹‹å‰ï¼Œå¦‚æœä½ èƒ½ä»ä»»ä½•ä½ å¬è¯´è¿‡çš„ä¸“å®¶é‚£é‡Œè·å¾—å¤§çº¦10ä¸ªç¤ºä¾‹ï¼Œå¹¶ç”¨è¿™äº›ç¤ºä¾‹æ¥æç¤ºä½ çš„æ–°æ¨¡å‹ï¼Œé‚£å°†æ˜¯ä¸€ä¸ªæ›´å¥½çš„èµ·ç‚¹ï¼Œåœ¨å°†æ¨¡å‹æš´éœ²äºç°å®ä¸–ç•Œå¹¶ä»çœŸå®ç”¨æˆ·é‚£é‡Œå¤§è§„æ¨¡æ”¶é›†åé¦ˆä¹‹å‰ã€‚å› æ­¤ï¼Œæˆ‘è®¤ä¸ºä¸æŒ‡ä»¤æç¤ºè°ƒä¼˜ç›¸æ¯”ï¼ŒRLHçš„æ ·æœ¬æ•ˆç‡ä¹Ÿè¦ä½å¾—å¤šï¼Œå› ä¸ºä½ å¯èƒ½è¯•å›¾æ›´æ–°æ•´ä¸ªæ¨¡å‹ã€‚å› æ­¤ï¼Œæˆ‘è®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªéå¸¸å¥½çš„èµ·ç‚¹ï¼Œå¯ä»¥æ ¹æ®æ¨¡å‹çš„ç”Ÿå‘½å‘¨æœŸè¿›è¡Œç»„åˆã€‚
- en: The data set is publicï¼Œ I'll talk about the results in a bit withinã€‚You mean
    the model responses and what the humans are that's a good point we are so far
    not considering releasing themã€‚but maybe we can Okay do you see a use case for
    thatã€‚Do have a bunch of data in the prensã€‚so frame the model to express those
    pregnancies and use that model R chat in medicalã€‚
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®é›†æ˜¯å…¬å¼€çš„ï¼Œæˆ‘ç¨åä¼šè®¨è®ºä¸€ä¸‹ç»“æœã€‚ä½ æ˜¯è¯´æ¨¡å‹çš„ååº”å’Œäººç±»çš„è¡¨ç°ï¼Œè¿™æ˜¯ä¸ªå¥½ç‚¹å­ï¼Œæˆ‘ä»¬ç›®å‰è¿˜æ²¡æœ‰è€ƒè™‘å‘å¸ƒå®ƒä»¬ã€‚ä¹Ÿè®¸æˆ‘ä»¬å¯ä»¥ã€‚å¥½å§ï¼Œä½ è§‰å¾—è¿™æœ‰ä»€ä¹ˆç”¨ä¾‹å—ï¼Ÿæˆ‘ä»¬æœ‰ä¸€å †æ•°æ®åœ¨è®°å½•ä¸­ã€‚æ‰€ä»¥è®©æ¨¡å‹è¡¨è¾¾é‚£äº›å¦Šå¨ ï¼Œå¹¶åœ¨åŒ»å­¦ä¸­ä½¿ç”¨è¿™ä¸ªæ¨¡å‹èŠå¤©ã€‚
- en: So if I wanted to explainYeah that's a good pointï¼Œ I think the evaluation data
    set is I'll talk about this a bit hereã€‚it's still small but I think if we scale
    it up and we are doing it right now I think we can release that and that'll be
    I think a good resource of what you're tryingã€‚
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å¦‚æœæˆ‘æƒ³è§£é‡Šä¸€ä¸‹ï¼Œå—¯ï¼Œè¿™ä¸ªè§‚ç‚¹ä¸é”™ï¼Œæˆ‘è®¤ä¸ºè¯„ä¼°æ•°æ®é›†ï¼Œæˆ‘ä¼šåœ¨è¿™é‡Œç¨å¾®è°ˆè°ˆã€‚å®ƒä»ç„¶å¾ˆå°ï¼Œä½†æˆ‘è§‰å¾—å¦‚æœæˆ‘ä»¬æ‰©å¤§è§„æ¨¡ï¼Œæˆ‘ä»¬ç°åœ¨æ­£åœ¨è¿™æ ·åšï¼Œæˆ‘è®¤ä¸ºæˆ‘ä»¬å¯ä»¥å‘å¸ƒè¿™ä¸ªï¼Œè¿™å°†æ˜¯æˆ‘è®¤ä¸ºä½ ä»¬æ‰€è¿½æ±‚çš„ä¸€ä¸ªå¾ˆå¥½çš„èµ„æºã€‚
- en: å¯ã€‚So we have the metPm model as I saidï¼Œ and now we took the long form answers
    from it and compared that to the F palm model as well as to answers generated
    by expert clinicians and as I said we have two parts to the human evaluation one
    is by expert clinicians and the other one is by LA users and so what do these
    results look like on the one and 40 y questions that we got these evaluation results
    on what we observed typicallyã€‚
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ä»¥ã€‚æ‰€ä»¥æˆ‘ä»¬æœ‰äº†æˆ‘æ‰€è¯´çš„metPmæ¨¡å‹ï¼Œç°åœ¨æˆ‘ä»¬ä»ä¸­æå–äº†é•¿å½¢å¼çš„ç­”æ¡ˆï¼Œå¹¶å°†å…¶ä¸F palmæ¨¡å‹ä»¥åŠä¸“å®¶ä¸´åºŠåŒ»ç”Ÿç”Ÿæˆçš„ç­”æ¡ˆè¿›è¡Œäº†æ¯”è¾ƒã€‚æ­£å¦‚æˆ‘æ‰€è¯´ï¼Œæˆ‘ä»¬çš„äººç±»è¯„ä¼°åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼Œä¸€ä¸ªæ˜¯ç”±ä¸“å®¶ä¸´åºŠåŒ»ç”Ÿè¿›è¡Œï¼Œå¦ä¸€ä¸ªæ˜¯ç”±LAç”¨æˆ·è¿›è¡Œã€‚é‚£ä¹ˆï¼Œæˆ‘ä»¬åœ¨è¿™äº›è¯„ä¼°ç»“æœä¸Šè·å¾—çš„40ä¸ªé—®é¢˜çš„ç»“æœæ˜¯ä»€ä¹ˆæ ·çš„å‘¢ï¼Ÿæˆ‘ä»¬é€šå¸¸è§‚å¯Ÿåˆ°çš„æƒ…å†µæ˜¯ã€‚
- en: Across the board was when we looked at like different axes while the fl palm
    model would be quite terrible honestly the metT pump model would do much better
    and typically close the gap to expert clinicians so on this axis you see that
    the fl palm model has probably 60% or accuracy in terms of like scientific consensus
    the metP model improves on that quite a bit and closes the gap to clinicians over
    hereã€‚
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å„ä¸ªæ–¹é¢ï¼Œæˆ‘ä»¬æŸ¥çœ‹äº†ä¸åŒçš„è½´ï¼Œè€ŒFL Palmæ¨¡å‹è€å®è¯´è¡¨ç°ç›¸å½“ç³Ÿç³•ï¼ŒMETTæ³µæ¨¡å‹åˆ™è¡¨ç°å¾—å¥½å¤šäº†ï¼Œé€šå¸¸èƒ½å¤Ÿç¼©å°ä¸ä¸“å®¶ä¸´åºŠåŒ»ç”Ÿä¹‹é—´çš„å·®è·ã€‚åœ¨è¿™ä¸ªè½´ä¸Šï¼ŒFL
    Palmæ¨¡å‹çš„ç§‘å­¦å…±è¯†å‡†ç¡®ç‡å¤§çº¦ä¸º**60%**ï¼Œè€ŒMETPæ¨¡å‹åœ¨è¿™æ–¹é¢æœ‰äº†å¾ˆå¤§æ”¹å–„ï¼Œç¼©å°äº†ä¸ä¸´åºŠåŒ»ç”Ÿä¹‹é—´çš„å·®è·ã€‚
- en: Similar story on other axes as well over here you see the like clinicians rating
    on the axes of how well the model can retrieve medical knowledgeã€‚how well it can
    reason about it and again we see the same trend as in the previous slideã€‚so the
    column correct so it's evidence of correct comprehension and the rights incorrect
    minus no so both can be present at the same time so you can have evidence of correct
    comprehension also evidence of incorrect comprehension sometimes so exactly so
    so that's why they're not one minus over here but the trends are the same or also
    that's why skipable but that's a detailã€‚
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œåœ¨å…¶ä»–ç»´åº¦ä¸Šä¹Ÿæœ‰ç±»ä¼¼çš„æ•…äº‹ï¼Œä½ å¯ä»¥çœ‹åˆ°ä¸´åºŠåŒ»ç”Ÿåœ¨æ¨¡å‹å¦‚ä½•æ£€ç´¢åŒ»å­¦çŸ¥è¯†ã€å¦‚ä½•è¿›è¡Œæ¨ç†çš„è¯„åˆ†ã€‚æˆ‘ä»¬å†æ¬¡çœ‹åˆ°ä¸å‰ä¸€å¼ å¹»ç¯ç‰‡ç›¸åŒçš„è¶‹åŠ¿ã€‚å› æ­¤ï¼Œåˆ—å‡ºçš„æ­£ç¡®æ€§æ˜¯æ­£ç¡®ç†è§£çš„è¯æ®ï¼Œè€Œé”™è¯¯çš„åˆ™æ˜¯æ— ï¼Œæ‰€ä»¥è¿™ä¸¤è€…å¯ä»¥åŒæ—¶å­˜åœ¨ã€‚ä½ å¯ä»¥åŒæ—¶æœ‰æ­£ç¡®ç†è§£çš„è¯æ®ï¼Œä¹Ÿå¯èƒ½æœ‰é”™è¯¯ç†è§£çš„è¯æ®ã€‚æ²¡é”™ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆè¿™é‡Œä¸æ˜¯ä¸€ä¸ªå‡å»çš„ç»“æœï¼Œä½†è¶‹åŠ¿æ˜¯ç›¸åŒçš„ï¼Œè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆå¯ä»¥è·³è¿‡çš„åŸå› ï¼Œä½†è¿™åªæ˜¯ä¸€ä¸ªç»†èŠ‚ã€‚
- en: Yeah again so there's a type over hereï¼Œ but this one pertains to incorrect our
    missing content but this was an interesting one because what when we were doing
    this from tuning thing was we were teaching the metP model to produce longer and
    more complete answerss and so you'd see a few qualitative examples later but what
    ended up happening the process was sometimes the model was maybe producing more
    incorrect information so that's why you see that maybe in this particular axis
    the fl palm model was slightly better but again this was much worse compared to
    transmissionsã€‚
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œå†æ¬¡æåˆ°ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªç±»å‹ï¼Œä½†è¿™ä¸ªä¸ä¸æ­£ç¡®æˆ–ç¼ºå¤±çš„å†…å®¹æœ‰å…³ã€‚è¿™æ˜¯ä¸€ä¸ªæœ‰è¶£çš„æ¡ˆä¾‹ï¼Œå› ä¸ºåœ¨è¿›è¡Œè°ƒä¼˜æ—¶ï¼Œæˆ‘ä»¬æ­£åœ¨æ•™metPæ¨¡å‹ç”Ÿæˆæ›´é•¿ä¸”æ›´å®Œæ•´çš„å›ç­”ã€‚ä½ ç¨åä¼šçœ‹åˆ°ä¸€äº›å®šæ€§çš„ä¾‹å­ï¼Œä½†åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹æœ‰æ—¶å¯èƒ½ä¼šäº§ç”Ÿæ›´å¤šçš„ä¸æ­£ç¡®ä¿¡æ¯ã€‚å› æ­¤ï¼Œä½ ä¼šçœ‹åˆ°åœ¨è¿™ä¸ªç‰¹å®šçš„ç»´åº¦ä¸Šï¼Œfl
    palmæ¨¡å‹ç¨å¾®å¥½ä¸€äº›ï¼Œä½†ä¸ä¼ è¾“ç›¸æ¯”ï¼Œè¿™ä¾ç„¶å·®å¾—å¤šã€‚
- en: å–‚ï¼Œæˆ‘ä¹Ÿåœ¨è¿™ä¹°ã€‚It's a good questionï¼Œ it is more like it's something something completely
    out of contextã€‚so it may be irrelevant to the questionã€‚So that's why I would say
    itã€‚Okayã€‚We also looked at like possible and extent and likelihood of harmã€‚and
    again we see that with the instruction prompt tuning we're able to close the gap
    to expert teenagers over hereã€‚
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: å–‚ï¼Œæˆ‘ä¹Ÿåœ¨è¿™ä¹°ã€‚è¿™ä¸ªé—®é¢˜å¾ˆå¥½ï¼Œæ›´åƒæ˜¯å®Œå…¨è„±ç¦»ä¸Šä¸‹æ–‡çš„ä¸œè¥¿ã€‚æ‰€ä»¥è¿™å¯èƒ½ä¸é—®é¢˜æ— å…³ã€‚è¿™å°±æ˜¯æˆ‘ä¼šè¿™æ ·è¯´çš„åŸå› ã€‚å¥½çš„ã€‚æˆ‘ä»¬è¿˜è€ƒè™‘äº†å¯èƒ½çš„å±å®³ç¨‹åº¦å’Œå¯èƒ½æ€§ã€‚å†ä¸€æ¬¡ï¼Œæˆ‘ä»¬çœ‹åˆ°é€šè¿‡æŒ‡ä»¤æç¤ºè°ƒä¼˜ï¼Œæˆ‘ä»¬èƒ½å¤Ÿç¼©å°ä¸è¿™è¾¹ä¸“å®¶é’å°‘å¹´çš„å·®è·ã€‚
- en: Same on the bias access as wellã€‚å—¯ä¸èƒ½ç¡®ã€‚Can you interpret the talkï¼Ÿè¯¶å…¶è¯¥ã€‚So like
    I basically see like something de and then the clinicians at like6% see would
    you talk more like how to clarify exactly what thatï¼Ÿ
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºåè§è®¿é—®ä¹Ÿæ˜¯ä¸€æ ·ã€‚å—¯ï¼Œä¸èƒ½ç¡®å®šã€‚ä½ èƒ½è§£é‡Šä¸€ä¸‹è¿™ä¸ªè®¨è®ºå—ï¼Ÿè¯¶ï¼Œåº”è¯¥æ˜¯è¿™æ ·ã€‚æ‰€ä»¥æˆ‘åŸºæœ¬ä¸Šçœ‹åˆ°åƒæŸç§æ•°æ®ï¼Œç„¶åä¸´åºŠåŒ»ç”Ÿå¤§çº¦6%ä¼šè¿™æ ·è¯´ï¼Œä½ èƒ½å¤šè°ˆè°ˆå¦‚ä½•å‡†ç¡®æ¾„æ¸…è¿™ä¸ªé—®é¢˜å—ï¼Ÿ
- en: ğŸ˜Šï¼ŒYeah so it's basically so there might be certain conditions or pathologies
    or diagnosis right like cancer and if for example the clinician has not caught
    that or has maybe given a response that does not appropriately convey the severity
    of the condition then that could potentially lead to severe harm or death and
    so that's what we were trying to capture a here so that's a very high level overview
    this isã€‚
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šï¼Œæ˜¯çš„ï¼ŒåŸºæœ¬ä¸Šå¯èƒ½ä¼šæœ‰æŸäº›æƒ…å†µã€ç—…ç†æˆ–è¯Šæ–­ï¼Œæ¯”å¦‚ç™Œç—‡ã€‚å¦‚æœä¸´åºŠåŒ»ç”Ÿæ²¡æœ‰åŠæ—¶å‘ç°ï¼Œæˆ–è€…å¯èƒ½ç»™å‡ºçš„ååº”æœªèƒ½æ°å½“åœ°ä¼ è¾¾ç—…æƒ…çš„ä¸¥é‡æ€§ï¼Œé‚£ä¹ˆè¿™å¯èƒ½ä¼šå¯¼è‡´ä¸¥é‡çš„ä¼¤å®³æˆ–æ­»äº¡ï¼Œè¿™æ­£æ˜¯æˆ‘ä»¬æƒ³è¦åœ¨è¿™é‡Œæ•æ‰çš„å†…å®¹ï¼Œæ‰€ä»¥è¿™æ˜¯ä¸€ä¸ªéå¸¸é«˜å±‚æ¬¡çš„æ¦‚è¿°ã€‚
- en: I think a very nuanced topic and there's a framework for it called the AHRQ
    framework and so we've linked that in the paper as well and so I think that gives
    you a very detailed notion of harm and bias that I would refer to that but at
    a high level this is what I'm talking about how that helpsã€‚
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªéå¸¸å¾®å¦™çš„è¯é¢˜ï¼Œé’ˆå¯¹è¿™ä¸ªè¯é¢˜æœ‰ä¸€ä¸ªæ¡†æ¶å«åšAHRQæ¡†æ¶ï¼Œæˆ‘ä»¬åœ¨è®ºæ–‡ä¸­ä¹Ÿé“¾æ¥äº†å®ƒï¼Œæˆ‘è®¤ä¸ºè¿™ä¸ºä½ æä¾›äº†ä¸€ä¸ªéå¸¸è¯¦ç»†çš„ä¼¤å®³å’Œåè§çš„æ¦‚å¿µï¼Œæˆ‘ä¼šæåˆ°è¿™ä¸€ç‚¹ï¼Œä½†ä»é«˜å±‚æ¬¡æ¥çœ‹ï¼Œè¿™å°±æ˜¯æˆ‘æ‰€è°ˆè®ºçš„å†…å®¹ï¼Œä»¥åŠå®ƒæ˜¯å¦‚ä½•å¸®åŠ©çš„ã€‚
- en: All rightï¼Œ so when later I class and I say the clinician had 5ã€‚7 a possible
    which means like what would I say does that mean that they recommend something
    or maybe they fail to recommend something yeahã€‚so it's basically a misdiagnosis
    or maybe failing to capture the severity of a diagnosis this is typical in life
    threatening conditions right soã€‚So it's more often than not mistakesï¼Œ but rather
    just missing out on detailsã€‚Yeahã€‚
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œåæ¥æˆ‘ä¸Šè¯¾æ—¶è¯´ä¸´åºŠåŒ»ç”Ÿæœ‰5.7çš„å¯èƒ½æ€§ï¼Œè¿™æ„å‘³ç€æˆ‘è¯¥æ€ä¹ˆè¯´ï¼Ÿè¿™æ˜¯ä¸æ˜¯æ„å‘³ç€ä»–ä»¬æ¨èäº†ä»€ä¹ˆï¼Œæˆ–è€…ä¹Ÿè®¸ä»–ä»¬æ²¡æœ‰æ¨èä»€ä¹ˆï¼Ÿæ˜¯çš„ã€‚å› æ­¤ï¼Œè¿™åŸºæœ¬ä¸Šæ˜¯è¯¯è¯Šï¼Œæˆ–è€…è¯´æœªèƒ½æ•æ‰åˆ°è¯Šæ–­çš„ä¸¥é‡æ€§ï¼Œè¿™åœ¨å±åŠç”Ÿå‘½çš„æƒ…å†µä¸­æ˜¯å¾ˆå…¸å‹çš„ï¼Œå¯¹å§ï¼Ÿæ‰€ä»¥ï¼Œå¾€å¾€æ›´å¤šçš„æ˜¯é”™è¯¯ï¼Œè€Œä¸æ˜¯åªæ˜¯é”™è¿‡äº†ç»†èŠ‚ã€‚æ˜¯çš„ã€‚
- en: so I talked about bias as well and then as I said the other axes of human evaluation
    was with layer users and so we asked them how well does the model answer address
    the intent of the question and again we saw with instruction prompt during MetPm
    closing the gap to clinicians and then we asked them like how helpful the responses
    were and what we see is that while fl palm responses were considered to be helpful
    like 60% of the time the number improved to 80% for MetPMã€‚
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä¹Ÿè°ˆåˆ°äº†åè§ï¼Œæ­£å¦‚æˆ‘æ‰€è¯´ï¼Œäººç±»è¯„ä¼°çš„å…¶ä»–ç»´åº¦æ˜¯é€šè¿‡å±‚ç”¨æˆ·ï¼Œå› æ­¤æˆ‘ä»¬é—®ä»–ä»¬æ¨¡å‹å›ç­”å¯¹é—®é¢˜æ„å›¾çš„æ»¡è¶³ç¨‹åº¦å¦‚ä½•ï¼Œå†æ¬¡çœ‹åˆ°åœ¨MetPMçš„æŒ‡ä»¤æç¤ºä¸‹ï¼Œä¸ä¸´åºŠåŒ»ç”Ÿä¹‹é—´çš„å·®è·ç¼©å°äº†ã€‚ç„¶åæˆ‘ä»¬é—®ä»–ä»¬è¿™äº›å›åº”æœ‰å¤šæœ‰å¸®åŠ©ï¼Œæˆ‘ä»¬çœ‹åˆ°çš„æ˜¯ï¼Œè™½ç„¶fl
    palmçš„å›åº”è¢«è®¤ä¸ºæœ‰å¸®åŠ©çš„æ¯”ä¾‹çº¦ä¸º60%ï¼Œä½†MetPMçš„æ¯”ä¾‹æé«˜åˆ°äº†80%ã€‚
- en: but was still fairly lower compared clinicians at 90%ã€‚å—¯ã€‚So here are a few qualitative
    examples and so what you see is that physicians and this is typically because
    they work in time constrained settings they their answers tend to be precise and
    succinct but sometimes it's very hard as layer users or patients to like decipher
    and decode the answer and get all the full set of details right and so what I
    think language models like MePm can help with is actually converting the physicians
    speak to something that's more easily digestible by layer users and so this is
    where I think how these models will likely fit in clinical settings in the neural
    term where they are going to augment physicians in terms of like interacting with
    patients and other physicians and researchers as wellã€‚
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†ä¸90%çš„ä¸´åºŠåŒ»ç”Ÿç›¸æ¯”ï¼Œä»ç„¶æ˜¾å¾—ç›¸å½“ä½ã€‚å—¯ã€‚æ‰€ä»¥è¿™é‡Œæœ‰ä¸€äº›å®šæ€§ç¤ºä¾‹ï¼Œä½ ä¼šå‘ç°åŒ»ç”Ÿé€šå¸¸å› ä¸ºåœ¨æ—¶é—´æœ‰é™çš„ç¯å¢ƒä¸­å·¥ä½œï¼Œä»–ä»¬çš„å›ç­”å¾€å¾€ç²¾å‡†ç®€æ´ï¼Œä½†æœ‰æ—¶ä½œä¸ºå±‚ç”¨æˆ·æˆ–æ‚£è€…ï¼Œå¾ˆéš¾è§£è¯»å’Œç†è§£è¿™äº›ç­”æ¡ˆï¼Œå¹¶è·å–æ‰€æœ‰å®Œæ•´çš„ç»†èŠ‚ã€‚å› æ­¤ï¼Œæˆ‘è®¤ä¸ºåƒMePmè¿™æ ·çš„è¯­è¨€æ¨¡å‹å¯ä»¥å¸®åŠ©å°†åŒ»ç”Ÿçš„è¯­è¨€è½¬æ¢ä¸ºæ›´æ˜“äºå±‚ç”¨æˆ·æ¶ˆåŒ–çš„å†…å®¹ï¼Œè¿™å°±æ˜¯æˆ‘è®¤ä¸ºè¿™äº›æ¨¡å‹åœ¨ä¸´åºŠç¯å¢ƒä¸­å¦‚ä½•é€‚åº”çš„åŸå› ï¼Œå®ƒä»¬å°†å¢å¼ºåŒ»ç”Ÿä¸æ‚£è€…ã€å…¶ä»–åŒ»ç”Ÿå’Œç ”ç©¶äººå‘˜çš„äº’åŠ¨ã€‚
- en: Sa goodã€‚Im just wondering because we visitã€‚It that water is down and it's a
    veryã€‚If I take as a patientï¼Œ you do it or not authorityã€‚That's right I think it's
    subjective and so that's why I think we're still seeing like lay users rate plan
    performance answerss to be helpful 80% well that's much higher for physicians
    so it's not perfect by any means but I think this is where its there there is
    a complementarity element we feel over hereã€‚
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ã€‚æˆ‘åªæ˜¯æƒ³çŸ¥é“ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨è®¿é—®ã€‚æ°´ä½ä¸‹é™ï¼Œè€Œä¸”è¿™å¾ˆã€‚ä½œä¸ºæ‚£è€…ï¼Œæˆ‘æ˜¯å¦å¯ä»¥ï¼Œä½ æ˜¯å¦æœ‰æƒè¿™æ ·åšã€‚æ²¡é”™ï¼Œæˆ‘è®¤ä¸ºè¿™æ˜¯ä¸»è§‚çš„ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘è®¤ä¸ºæˆ‘ä»¬ä»ç„¶çœ‹åˆ°æ™®é€šç”¨æˆ·çš„è¯„ä»·è®¡åˆ’è¡¨ç°çš„ç­”æ¡ˆå¾ˆæœ‰å¸®åŠ©ï¼Œ80%å¯¹äºåŒ»ç”Ÿæ¥è¯´è¦é«˜å¾—å¤šï¼Œæ‰€ä»¥è¿™å¹¶ä¸å®Œç¾ï¼Œä½†æˆ‘è®¤ä¸ºè¿™é‡Œæœ‰ä¸€ä¸ªäº’è¡¥çš„å…ƒç´ ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œæ„Ÿå—åˆ°ã€‚
- en: And we've asked that and like when we ask people like how easy is it to like
    interpret doctor notes or recommendations and they often sayã€‚oh it's very hard
    I need to go back to Google search for what these terms meanã€‚what these abbreviations
    mean and so I think this is where a language model can come and take that note
    and convert that into something that's more easily digestible like so I think
    that's the opportunity over here I feelã€‚So that was all on our paperï¼Œ but I also
    want to maybe very quickly point out a very recent work which came out last week
    with this rather provocative title do we still need clinical language models and
    by clinical language models they meant smaller models which are trained in domain
    with clinical data such as medical notes and records and so on and so forth and
    what this paper basically suggests is that smaller fine-ted in domain LMs are
    likely better than general purpose LLMs in this paper I think the evaluate on
    GT3 with in context learning so I think that's a pretty interesting any observation
    I think there's a lot of value for smaller in domain LMs such as P GPT and a few
    other lib variances but I think one thing that this paper does not do is consider
    in context learning sorry prompt tuning and I think that's where some of the benefits
    of these larger general purpose LLMs shine and again we haven't done any in domain
    LM pretrainingã€‚
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: These large general purposeã€‚Modelsï¼Œ but that's again an option for us as well
    to do dlingã€‚So you can take these5 and 40 billion parameters and then still turn
    it on medical nodes or whatever domain specific data that you can get hold of
    and hopefully that'll probably further improve the performanceã€‚
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å¤§å‹é€šç”¨æ¨¡å‹ï¼Œä¸è¿‡è¿™å¯¹æˆ‘ä»¬æ¥è¯´ä¹Ÿæ˜¯ä¸€ä¸ªé€‰æ‹©ï¼Œå¯ä»¥è¿›è¡Œå¾®è°ƒã€‚å› æ­¤ï¼Œä½ å¯ä»¥åˆ©ç”¨è¿™5å’Œ400äº¿ä¸ªå‚æ•°ï¼Œç„¶åä¾ç„¶åœ¨åŒ»å­¦èŠ‚ç‚¹æˆ–å…¶ä»–ç‰¹å®šé¢†åŸŸçš„æ•°æ®ä¸Šè¿›è¡Œè°ƒæ•´ï¼Œå¸Œæœ›è¿™èƒ½è¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚
- en: So key takeaways so farã€‚What I want to convey is general purpose LMsã€‚it looks
    like they do encode medical knowledge and performance on medical reasoning tasks
    seem to improve with scaleã€‚however these models I don't think can be directly
    used out of the box in clinical settings and they need to be aligned with the
    safety critical requirements of the medical domainã€‚And I think instruction proing
    is an extremely efficient technique both on the data side and also on the compute
    side and we should probably use it more oftenã€‚
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢çš„å…³é”®è¦ç‚¹æ˜¯ä»€ä¹ˆã€‚æˆ‘æƒ³ä¼ è¾¾çš„æ˜¯é€šç”¨è¯­è¨€æ¨¡å‹ã€‚çœ‹èµ·æ¥å®ƒä»¬ç¡®å®ç¼–ç äº†åŒ»å­¦çŸ¥è¯†ï¼Œä¸”åœ¨åŒ»å­¦æ¨ç†ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼¼ä¹éšç€è§„æ¨¡çš„å¢åŠ è€Œæ”¹å–„ã€‚ç„¶è€Œï¼Œæˆ‘è®¤ä¸ºè¿™äº›æ¨¡å‹ä¸èƒ½ç›´æ¥åœ¨ä¸´åºŠç¯å¢ƒä¸­ä½¿ç”¨ï¼Œéœ€è¦ä¸åŒ»ç–—é¢†åŸŸçš„å®‰å…¨å…³é”®è¦æ±‚ä¿æŒä¸€è‡´ã€‚æˆ‘è®¤ä¸ºæŒ‡ä»¤è°ƒä¼˜æ˜¯ä¸€ç§åœ¨æ•°æ®å’Œè®¡ç®—æ–¹é¢éƒ½æä¸ºæœ‰æ•ˆçš„æŠ€æœ¯ï¼Œæˆ‘ä»¬åº”è¯¥æ›´é¢‘ç¹åœ°ä½¿ç”¨å®ƒã€‚
- en: depending on and hopefully the API starts supporting it as wellã€‚and these models
    appear to be closing the gap to expert clinicians at least on this medical question
    answerscing tasks and while this is hugely exciting and has profound implications
    you can all probably dream up and imagine the application scenarios over hereã€‚
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®æƒ…å†µï¼Œå¸Œæœ›APIä¹Ÿå¼€å§‹æ”¯æŒå®ƒã€‚è¿™äº›æ¨¡å‹ä¼¼ä¹åœ¨åŒ»ç–—é—®é¢˜å›ç­”ä»»åŠ¡ä¸Šæ­£åœ¨ç¼©å°ä¸ä¸“å®¶ä¸´åºŠåŒ»ç”Ÿä¹‹é—´çš„å·®è·ï¼Œè€Œè¿™ä¸€ç‚¹æ— ç–‘ä»¤äººå…´å¥‹ï¼Œå¹¶ä¸”å…·æœ‰æ·±è¿œçš„å½±å“ï¼Œä½ ä»¬å¯èƒ½éƒ½èƒ½æƒ³è±¡å‡ºè¿™é‡Œçš„åº”ç”¨åœºæ™¯ã€‚
- en: I think comprehensive benchmarks and evaluation frameworks are necessary in
    order to further assess and improve these models for real use casesã€‚So I'll trouble
    over here any questionsï¼Ÿå®Œæˆã€‚In medicineineï¼Œ there survivedã€‚å“ï¼Œæ˜¯ã€‚å¯¹ã€‚ä½ å•Šã€‚A lot of it
    is because these data sets tend to get locked in silos with privacy and other
    kinds of regulations which prevent them from being put out there in the real worldã€‚so
    you have to have like hip compliant systems for storage and so on and so forth
    so it's very difficult to get data out of these silos and put together an open
    benchmark so honestly I feel like that's probably not going to improve the scale
    of these data sets at least the open version of these dataset sets are going to
    remainã€‚
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºå…¨é¢çš„åŸºå‡†æµ‹è¯•å’Œè¯„ä¼°æ¡†æ¶æ˜¯å¿…è¦çš„ï¼Œä»¥è¿›ä¸€æ­¥è¯„ä¼°å’Œæ”¹è¿›è¿™äº›æ¨¡å‹ä»¥ç”¨äºå®é™…æ¡ˆä¾‹ã€‚é‚£æˆ‘åœ¨è¿™é‡Œçƒ¦è¯·æœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿå®Œæˆã€‚åœ¨åŒ»å­¦ä¸Šï¼Œä¾ç„¶å­˜åœ¨ã€‚å“ï¼Œæ˜¯ã€‚å¯¹ã€‚ä½ å•Šã€‚å¾ˆå¤šåŸå› æ˜¯è¿™äº›æ•°æ®é›†å¾€å¾€ä¼šè¢«é”åœ¨éšç§å’Œå…¶ä»–æ³•è§„çš„å­¤å²›ä¸­ï¼Œè¿™äº›æ³•è§„é˜»æ­¢å®ƒä»¬åœ¨ç°å®ä¸–ç•Œä¸­å‘å¸ƒã€‚å› æ­¤ï¼Œä½ å¿…é¡»æ‹¥æœ‰ç¬¦åˆHIPAAçš„å­˜å‚¨ç³»ç»Ÿç­‰ç­‰ï¼Œå› æ­¤ä»è¿™äº›å­¤å²›ä¸­è·å–æ•°æ®å¹¶æ•´åˆä¸€ä¸ªå¼€æ”¾çš„åŸºå‡†éå¸¸å›°éš¾ã€‚è€å®è¯´ï¼Œæˆ‘è§‰å¾—è¿™å¯èƒ½ä¸ä¼šæ”¹å–„è¿™äº›æ•°æ®é›†çš„è§„æ¨¡ï¼Œè‡³å°‘å¼€æ”¾ç‰ˆæœ¬çš„æ•°æ®é›†å°†ä¼šä¿æŒä¸å˜ã€‚
- en: Quite small compared to the big L training data sets or the computer division
    data sets on natural images and on and so forthã€‚but what may happen in the future
    is we may have like more distributed fedated evaluation settings where you take
    the model into these private silos and get them evaluated on so they are never
    exposed and put out there in the public but rather we can have these fed rate
    evaluation settings so I think that there's some work on that already there's
    a system called MeF and probably see more of themã€‚
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ç›¸è¾ƒäºå¤§è§„æ¨¡çš„ L è®­ç»ƒæ•°æ®é›†æˆ–è‡ªç„¶å›¾åƒçš„è®¡ç®—æœºåˆ†éƒ¨æ•°æ®é›†ï¼Œè¿™ä¸ªè§„æ¨¡ç›¸å½“å°ã€‚ä¸è¿‡ï¼Œæœªæ¥å¯èƒ½ä¼šå‘ç”Ÿçš„æƒ…å†µæ˜¯ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šæœ‰æ›´å¤šåˆ†å¸ƒå¼çš„è”é‚¦è¯„ä¼°è®¾ç½®ï¼Œåœ¨è¿™äº›è®¾ç½®ä¸­ï¼Œä½ å°†æ¨¡å‹æ”¾å…¥è¿™äº›ç§å¯†çš„å­˜å‚¨åŒºè¿›è¡Œè¯„ä¼°ï¼Œå› æ­¤å®ƒä»¬ä¸ä¼šè¢«æš´éœ²å¹¶å…¬å¼€ï¼Œè€Œæ˜¯å¯ä»¥è¿›è¡Œè¿™äº›è”é‚¦è¯„ä¼°è®¾ç½®ã€‚å› æ­¤ï¼Œæˆ‘è®¤ä¸ºåœ¨è¿™æ–¹é¢å·²ç»æœ‰ä¸€äº›å·¥ä½œåœ¨è¿›è¡Œä¸­ï¼Œæœ‰ä¸€ä¸ªç³»ç»Ÿå«åš
    MeFï¼Œå¯èƒ½ä¼šçœ‹åˆ°æ›´å¤šç±»ä¼¼çš„ç³»ç»Ÿã€‚
- en: å°±ç­‰ä¸ªå˜…å‘è¿‡å…ˆã€‚Sureï¼Œ so the question over here was why medical data sets are smaller
    compared to natural image data sets in computer division or LMP training data
    sets and so on and so forthã€‚What do you think are some of the earliest applications
    of medical LOms like deployed in industryï¼Ÿ
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: å°±ç­‰ä¸ªå˜…å‘è¿‡å…ˆã€‚å½“ç„¶ï¼Œè¿™é‡Œé—®çš„é—®é¢˜æ˜¯ï¼Œä¸ºä»€ä¹ˆåŒ»å­¦æ•°æ®é›†ç›¸è¾ƒäºè‡ªç„¶å›¾åƒæ•°æ®é›†åœ¨è®¡ç®—æœºåˆ†å‰²æˆ–LMPè®­ç»ƒæ•°æ®é›†ä¸­è¦å°å¾—å¤šï¼Œç­‰ç­‰ã€‚ä½ è®¤ä¸ºåŒ»å­¦LOmsåœ¨å·¥ä¸šä¸­æœ€æ—©çš„ä¸€äº›åº”ç”¨æ˜¯ä»€ä¹ˆï¼Ÿ
- en: I think the first set of use cases are probably going to be not diagnostic in
    it sorry the question was what do you think are the use cases of medical algorithms
    in medical industry settings and soã€‚The answer is I think the first set of use
    cases that we are going to see are probably going to be non-diagnostic in natureã€‚
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºç¬¬ä¸€ç»„ä½¿ç”¨æ¡ˆä¾‹å¯èƒ½ä¼šä¸æ˜¯è¯Šæ–­æ€§çš„ï¼ŒæŠ±æ­‰ï¼Œé—®é¢˜æ˜¯ä½ è®¤ä¸ºåŒ»ç–—ç®—æ³•åœ¨åŒ»ç–—è¡Œä¸šç¯å¢ƒä¸­çš„ä½¿ç”¨æ¡ˆä¾‹æ˜¯ä»€ä¹ˆã€‚å› æ­¤ï¼Œæˆ‘çš„å›ç­”æ˜¯ï¼Œæˆ‘è®¤ä¸ºæˆ‘ä»¬å°†çœ‹åˆ°çš„ç¬¬ä¸€ç»„ä½¿ç”¨æ¡ˆä¾‹å¯èƒ½æœ¬è´¨ä¸Šæ˜¯éè¯Šæ–­æ€§çš„ã€‚
- en: but more around like if a patient comes in and interacts with a doctorã€‚can you
    like generate summary notes and can you do like workflow tasks such as generating
    letters for insurance for medications for referrals and so on and so but I think
    these tasks are right up the alley of large language models and I think if not
    already in the next six months to a year we'll see a lot of these use cases coming
    up and I think that's going to make doctors like care providers life much easier
    because right now they're spending a lot of time doing these things and not actually
    providing care and attending to the patient diagnostic use cases I think will
    take a lot more timeã€‚
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯æ›´å¤šçš„æ˜¯å¦‚æœæ‚£è€…è¿›æ¥ä¸åŒ»ç”Ÿäº’åŠ¨ï¼Œä½ èƒ½ç”Ÿæˆæ‘˜è¦ç¬”è®°å—ï¼Ÿä½ èƒ½åšä¸€äº›å·¥ä½œæµç¨‹ä»»åŠ¡ï¼Œæ¯”å¦‚ä¸ºä¿é™©ç”Ÿæˆè¯ç‰©æ¨èä¿¡ç­‰ç­‰å—ï¼Ÿæˆ‘è®¤ä¸ºè¿™äº›ä»»åŠ¡æ­£é€‚åˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæˆ‘è®¤ä¸ºå¦‚æœè¿˜æ²¡æœ‰çš„è¯ï¼Œåœ¨æ¥ä¸‹æ¥çš„å…­ä¸ªæœˆåˆ°ä¸€å¹´å†…ï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ°å¾ˆå¤šè¿™æ ·çš„ç”¨ä¾‹å‡ºç°ã€‚æˆ‘è®¤ä¸ºè¿™å°†ä½¿åŒ»ç”Ÿå’ŒæŠ¤ç†æä¾›è€…çš„ç”Ÿæ´»å˜å¾—æ›´åŠ è½»æ¾ï¼Œå› ä¸ºç°åœ¨ä»–ä»¬èŠ±è´¹å¤§é‡æ—¶é—´åœ¨è¿™äº›äº‹æƒ…ä¸Šï¼Œè€Œä¸æ˜¯å®é™…æä¾›æŠ¤ç†å’Œå…³æ³¨æ‚£è€…çš„è¯Šæ–­ç”¨ä¾‹ï¼Œæˆ‘è®¤ä¸ºè¿™éœ€è¦æ›´å¤šæ—¶é—´ã€‚
- en: we need a lot more evaluation the data sets as we can see are probably not there
    evaluation frameworks are not there but I think in the long run and that is the
    dream setting rightã€‚And then maybe a follow up is Mï¼Œ I'm assuming meed Palm is
    not open sourceã€‚
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦å¯¹æ•°æ®é›†è¿›è¡Œæ›´å¤šè¯„ä¼°ï¼Œæ˜¾ç„¶è¯„ä¼°æ¡†æ¶è¿˜ä¸å®Œå–„ï¼Œä½†æˆ‘è®¤ä¸ºä»é•¿è¿œæ¥çœ‹ï¼Œé‚£æ˜¯ç†æƒ³çš„è®¾å®šã€‚ç„¶åä¹Ÿè®¸åç»­æ˜¯Mï¼Œæˆ‘å‡è®¾Meed Palmå¹¶ä¸æ˜¯å¼€æºçš„ã€‚
- en: what do you think the best open source model is for medicalï¼Ÿè¯¶ã€‚Yeah I think it
    depends on the so the question is what is the best open source model for medical
    data I think depends on the evaluation setting so I think the PM GPT model from
    the Stanford Foundation models group is quite strong I think GPT3 or 3ã€‚
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ è®¤ä¸ºæœ€å¥½çš„åŒ»ç–—å¼€æºæ¨¡å‹æ˜¯ä»€ä¹ˆï¼Ÿè¯¶ã€‚æ˜¯çš„ï¼Œæˆ‘è®¤ä¸ºè¿™å–å†³äºï¼Œæ‰€ä»¥é—®é¢˜æ˜¯åŒ»ç–—æ•°æ®çš„æœ€ä½³å¼€æºæ¨¡å‹æ˜¯ä»€ä¹ˆï¼Œæˆ‘è®¤ä¸ºè¿™å–å†³äºè¯„ä¼°è®¾ç½®ï¼Œæ‰€ä»¥æˆ‘è®¤ä¸ºæ–¯å¦ç¦åŸºé‡‘ä¼šæ¨¡å‹ç»„çš„PM
    GPTæ¨¡å‹ç›¸å½“å¼ºå¤§ï¼Œæˆ‘è®¤ä¸ºGPT-3æˆ–3ã€‚
- en: 5 or whatever variant if you can bring in some domain specific medical data
    and do some in domain tuning adding that model can also improve quite a bit so
    I think those two would be my favorite chart points over hereã€‚So feels like part
    of the important itself problem after sectionã€‚
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ èƒ½å¼•å…¥ä¸€äº›ç‰¹å®šé¢†åŸŸçš„åŒ»å­¦æ•°æ®å¹¶è¿›è¡Œä¸€äº›é¢†åŸŸå†…çš„è°ƒä¼˜ï¼Œé‚£ä¹ˆ5æˆ–å…¶ä»–å˜ä½“ä¹Ÿèƒ½æ˜¾è‘—æ”¹å–„æ¨¡å‹ï¼Œæ‰€ä»¥æˆ‘è®¤ä¸ºè¿™ä¸¤ä¸ªå°†æ˜¯æˆ‘åœ¨è¿™é‡Œæœ€å–œæ¬¢çš„è¦ç‚¹ã€‚å› æ­¤ï¼Œè¿™æ„Ÿè§‰åƒæ˜¯éƒ¨åˆ†é‡è¦æ€§æœ¬èº«çš„é—®é¢˜ã€‚
- en: It's you can just think them as vectors corresponding to a few additional tokens
    so it's not really human legible so the question was what do the soft prospectors
    look like and are they human legible and yeah the answer is no they're notã€‚Just
    a you said mentioned by very know for larger quality policy third of route and
    usually on sites have hospitalized moral quality infrastructure online medicine
    we really believe that should be learning what we haveã€‚
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥æŠŠå®ƒä»¬çœ‹ä½œæ˜¯å¯¹åº”äºå‡ ä¸ªé¢å¤–æ ‡è®°çš„å‘é‡ï¼Œå› æ­¤å¹¶ä¸æ˜¯å¾ˆå®¹æ˜“è¢«äººç†è§£ã€‚é‚£ä¹ˆé—®é¢˜æ˜¯ï¼Œè½¯å‰æ™¯æ˜¯ä»€ä¹ˆæ ·çš„ï¼Ÿå®ƒä»¬æ˜¯å¦å®¹æ˜“è¢«äººç†è§£ï¼Ÿç­”æ¡ˆæ˜¯ï¼Œä¸ï¼Œå®ƒä»¬å¹¶ä¸èƒ½ã€‚æ­£å¦‚ä½ æ‰€æåˆ°çš„ï¼Œé’ˆå¯¹æ›´å¤§è´¨é‡æ”¿ç­–çš„ä¸‰åˆ†ä¹‹ä¸€è·¯å¾„ï¼Œé€šå¸¸åœ¨ç½‘ç«™ä¸Šæœ‰ä½é™¢é“å¾·è´¨é‡åŸºç¡€è®¾æ–½åœ¨çº¿åŒ»å­¦ï¼Œæˆ‘ä»¬çœŸçš„ç›¸ä¿¡åº”è¯¥å­¦ä¹ æˆ‘ä»¬æ‰€æ‹¥æœ‰çš„ã€‚
- en: On site hardwareï¼Œ on site and machines that contain these models of the boardã€‚Sureã€‚so
    the question was given a lot of the hospital systems and providers networks are
    quite low tech and don't have good enough hardwareã€‚do you really think fed learning
    could be used for distributed training of large scale LLMsï¼Ÿ
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœºç¡¬ä»¶ï¼Œç°åœºå’ŒåŒ…å«è¿™äº›å‹å·æ¿å­çš„æœºå™¨ã€‚å¥½çš„ã€‚æ‰€ä»¥é—®é¢˜æ˜¯è€ƒè™‘åˆ°è®¸å¤šåŒ»é™¢ç³»ç»Ÿå’ŒæœåŠ¡æä¾›è€…ç½‘ç»œçš„æŠ€æœ¯æ°´å¹³ç›¸å¯¹è¾ƒä½ï¼Œå¹¶ä¸”ç¡¬ä»¶ä¸å¤Ÿå¥½ã€‚ä½ çœŸçš„è®¤ä¸ºè”é‚¦å­¦ä¹ å¯ä»¥ç”¨äºå¤§è§„æ¨¡LLMçš„åˆ†å¸ƒå¼è®­ç»ƒå—ï¼Ÿ
- en: I think we are increasingly seeing a trend towards cloud and so a lot of these
    hospital systems are moving their storage and data and compute to standard chart
    providers like AWS or as your Google cloud and so I think that helps because these
    systems on the back and side do have the compute to be able to like train these
    kind of models I think it's going to be a very gradual process so systems that
    have high quality infrastructure probably we're going to start with that first
    and then gradually work our way into the long tail but it also feels like something
    that will inevitably exist in the world so 10 years down the line of 15 years
    down the line and we have these distributed La scale relevant training systems
    we always think why did I even doubt that this will not exist it's so obvious
    it's something that has to exist because that's where all the patient data is
    all the interesting data is right because I think that will just happen it's just
    not clear where that's going to be done by one company whether that's going to
    be done by consortium of academic or industry groups orã€‚
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºæˆ‘ä»¬è¶Šæ¥è¶Šçœ‹åˆ°å‘äº‘è®¡ç®—å‘å±•çš„è¶‹åŠ¿ï¼Œå› æ­¤è®¸å¤šåŒ»é™¢ç³»ç»Ÿæ­£åœ¨å°†å®ƒä»¬çš„å­˜å‚¨ã€æ•°æ®å’Œè®¡ç®—è¿ç§»åˆ°åƒAWSæˆ–Google Cloudè¿™æ ·çš„æ ‡å‡†äº‘æœåŠ¡æä¾›å•†ã€‚æˆ‘è®¤ä¸ºè¿™å¾ˆæœ‰å¸®åŠ©ï¼Œå› ä¸ºè¿™äº›ç³»ç»Ÿåœ¨åå°ç¡®å®å…·å¤‡èƒ½å¤Ÿè®­ç»ƒè¿™äº›æ¨¡å‹çš„è®¡ç®—èƒ½åŠ›ã€‚æˆ‘è®¤ä¸ºè¿™å°†æ˜¯ä¸€ä¸ªéå¸¸æ¸è¿›çš„è¿‡ç¨‹ï¼Œå› æ­¤åŸºç¡€è®¾æ–½é«˜è´¨é‡çš„ç³»ç»Ÿå¯èƒ½ä¼šé¦–å…ˆå¯åŠ¨ï¼Œç„¶åé€æ­¥è¿›å…¥é•¿å°¾é¢†åŸŸã€‚ä½†è¿™ä¼¼ä¹ä¹Ÿæ˜¯ä¸€ç§å¿…ç„¶ä¼šå­˜åœ¨äºä¸–ç•Œä¸­çš„äº‹ç‰©ï¼Œæ‰€ä»¥åœ¨10å¹´æˆ–15å¹´åï¼Œå½“æˆ‘ä»¬æ‹¥æœ‰è¿™äº›åˆ†å¸ƒå¼çš„å¤§è§„æ¨¡ç›¸å…³è®­ç»ƒç³»ç»Ÿæ—¶ï¼Œæˆ‘ä»¬æ€»ä¼šæƒ³ï¼Œä¸ºä»€ä¹ˆæˆ‘æ›¾æ€€ç–‘è¿‡è¿™ä¸ä¼šå­˜åœ¨ï¼Ÿè¿™å¤ªæ˜æ˜¾äº†ï¼Œå®ƒå¿…é¡»å­˜åœ¨ï¼Œå› ä¸ºæ‰€æœ‰çš„ç—…äººæ•°æ®å’Œæ‰€æœ‰æœ‰è¶£çš„æ•°æ®éƒ½åœ¨é‚£é‡Œã€‚æˆ‘è®¤ä¸ºè¿™åªæ˜¯ä¼šå‘ç”Ÿï¼Œåªæ˜¯ä¸æ¸…æ¥šè¿™ä¸€åˆ‡æ˜¯ç”±ä¸€å®¶ä¼ä¸šå®Œæˆï¼Œè¿˜æ˜¯ç”±å­¦æœ¯ç•Œæˆ–è¡Œä¸šå›¢ä½“çš„è”åˆä½“æ¥å®Œæˆã€‚
- en: s are going to be involved on and so forthã€‚That's rightã€‚so the question over
    here is we seeing cloud computing but we are pretty much uploading the data to
    the same warehouse the answer is true but again I think these are all going to
    be separate buckets with their own access controls and so on and so forth so that
    is how you can differentiate between themã€‚
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å°†ä¼šæ¶‰åŠåˆ°ç­‰ç­‰ã€‚æ²¡é”™ã€‚é‚£ä¹ˆè¿™é‡Œçš„é—®é¢˜æ˜¯ï¼Œæˆ‘ä»¬çœ‹åˆ°äº‘è®¡ç®—ï¼Œä½†æˆ‘ä»¬åŸºæœ¬ä¸Šæ˜¯åœ¨å°†æ•°æ®ä¸Šä¼ åˆ°åŒä¸€ä¸ªä»“åº“ï¼Œç­”æ¡ˆæ˜¯å¯¹çš„ï¼Œä½†æˆ‘è®¤ä¸ºè¿™äº›éƒ½ä¼šæ˜¯å„è‡ªç‹¬ç«‹çš„æ¡¶ï¼Œæœ‰ç€å„è‡ªçš„è®¿é—®æ§åˆ¶ç­‰ç­‰ï¼Œè¿™å°±æ˜¯ä½ å¦‚ä½•åŒºåˆ†å®ƒä»¬çš„æ–¹æ³•ã€‚
- en: å¯¹ã€‚å¥½ã€‚It's been a lot ofã€‚è¿™ reallyçš„ã€‚Iã€‚it doesn't seem like that thing in sense
    that we're that we're used to carryã€‚Sure so the question was has there been any
    studies in MePm looking at private information in these data sets and the short
    answer is no one of the criteria for selecting the data sets that we used in the
    study was to not include any kind of personally identifiable data or clinical
    data of that sort and that helped like you know get this paper out on time but
    I think that's an important pointã€‚
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹ã€‚å¥½ã€‚å·²ç»æœ‰å¾ˆå¤šäº†ã€‚è¿™çœŸçš„ã€‚Iã€‚ä¼¼ä¹ä¸åƒæˆ‘ä»¬ä¹ æƒ¯æºå¸¦çš„é‚£ç§ä¸œè¥¿ã€‚å½“ç„¶ï¼Œé—®é¢˜æ˜¯æ˜¯å¦æœ‰ç ”ç©¶åœ¨ MePm ä¸­æŸ¥çœ‹è¿™äº›æ•°æ®é›†ä¸­çš„ç§äººä¿¡æ¯ï¼Œç®€çŸ­çš„å›ç­”æ˜¯æ²¡æœ‰ã€‚æˆ‘ä»¬åœ¨ç ”ç©¶ä¸­é€‰æ‹©æ•°æ®é›†çš„æ ‡å‡†ä¹‹ä¸€æ˜¯ä¸è¦åŒ…å«ä»»ä½•å¯è¯†åˆ«ä¸ªäººèº«ä»½çš„æ•°æ®æˆ–æ­¤ç±»ä¸´åºŠæ•°æ®ï¼Œè¿™æœ‰åŠ©äºæˆ‘ä»¬æŒ‰æ—¶å®Œæˆè¿™ç¯‡è®ºæ–‡ï¼Œä½†æˆ‘è®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªé‡è¦çš„è§‚ç‚¹ã€‚
- en: It's unlikely that we're going to have a lot of PI data in public well in the
    public data that we are training on butã€‚Even when you're training on say one private
    corpus and then you're using it in another application settingã€‚you want to ensure
    that the model does not leak out any kind of PHI information during a generationã€‚so
    I think those sort of studies are necessaryï¼Œ we haven't got into them yetã€‚
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨å…¬å¼€æ•°æ®ä¸­è®­ç»ƒæ—¶ï¼Œä¸å¤ªå¯èƒ½æœ‰å¤§é‡çš„PIæ•°æ®ã€‚ä½†æ˜¯ï¼Œå³ä½¿ä½ åœ¨æŸä¸ªç§æœ‰è¯­æ–™åº“ä¸Šè®­ç»ƒï¼Œç„¶ååœ¨å¦ä¸€ä¸ªåº”ç”¨åœºæ™¯ä¸­ä½¿ç”¨ï¼Œä½ ä¹Ÿéœ€è¦ç¡®ä¿æ¨¡å‹åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ä¸ä¼šæ³„éœ²ä»»ä½•PHIä¿¡æ¯ã€‚å› æ­¤ï¼Œæˆ‘è®¤ä¸ºè¿™ç±»ç ”ç©¶æ˜¯å¿…è¦çš„ï¼Œæˆ‘ä»¬å°šæœªæ·±å…¥è¿›è¡Œè¿™äº›ç ”ç©¶ã€‚
- en: So does think fairly on withs and exploring good models and that people be able
    having groups over the same experience towards the world tryingã€‚So the question
    is what are the next steps in terms of improving these models further yeah retrieval
    is a very important one being able to cite sources and especially taking authoritative
    sources and use that in generating the answers and' also communicating that to
    the users is very important I think how you communicating uncertainty is very
    important so we gotten to some extent using instruction from tu but I think that
    can be much much better so I think that's another big bucket again I would stress
    on the evaluation side like you know looking at more data sets which for example
    may do Q&A on health records or or other kinds of medical data I think that will
    be important and also extending the evaluation both in terms of scale having a
    diverse panel of clinician sport and also in terms of the data that you're using
    maybe adverarily modifying the questions to include like demographic confounders
    or something like that I think those are all could be interesting directions I
    think on the modeling side the interesting question for me is again this interplay
    betweenã€‚
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œå…¬å¹³åœ°è€ƒè™‘æ¨¡å‹å’Œæ¢ç´¢è‰¯å¥½æ¨¡å‹ï¼Œä»¥åŠäººä»¬èƒ½å¤Ÿåœ¨ç›¸åŒç»å†ä¸­å½¢æˆçš„ç¾¤ä½“ï¼Œæ˜¯éå¸¸é‡è¦çš„ã€‚é—®é¢˜æ˜¯ï¼Œæ¥ä¸‹æ¥åœ¨æ”¹è¿›è¿™äº›æ¨¡å‹æ–¹é¢çš„æ­¥éª¤æ˜¯ä»€ä¹ˆã€‚æ£€ç´¢æ˜¯ä¸€ä¸ªéå¸¸é‡è¦çš„ç¯èŠ‚ï¼Œèƒ½å¤Ÿå¼•ç”¨æ¥æºï¼Œå°¤å…¶æ˜¯é‡‡ç”¨æƒå¨æ¥æºæ¥ç”Ÿæˆç­”æ¡ˆï¼Œå¹¶å°†å…¶ä¼ è¾¾ç»™ç”¨æˆ·ï¼Œè¿™ä¸€ç‚¹æˆ‘è®¤ä¸ºéå¸¸é‡è¦ã€‚æˆ‘è®¤ä¸ºï¼Œå¦‚ä½•ä¼ è¾¾ä¸ç¡®å®šæ€§ä¹Ÿéå¸¸é‡è¦ã€‚æˆ‘ä»¬åœ¨æŸç§ç¨‹åº¦ä¸Šä½¿ç”¨äº†æ¥è‡ªtuçš„æŒ‡å¯¼ï¼Œä½†æˆ‘è®¤ä¸ºè¿™å¯ä»¥åšå¾—æ›´å¥½ã€‚æ‰€ä»¥æˆ‘è®¤ä¸ºè¿™æ˜¯å¦ä¸€ä¸ªé‡è¦çš„æ–¹é¢ã€‚æˆ‘ä¼šå¼ºè°ƒè¯„ä¼°æ–¹é¢ï¼Œæ¯”å¦‚å…³æ³¨æ›´å¤šæ•°æ®é›†ï¼Œä¾‹å¦‚åœ¨å¥åº·è®°å½•æˆ–å…¶ä»–ç±»å‹åŒ»ç–—æ•°æ®ä¸Šè¿›è¡Œé—®ç­”ï¼Œæˆ‘è®¤ä¸ºè¿™å¾ˆé‡è¦ã€‚åŒæ—¶ï¼Œæ‰©å±•è¯„ä¼°çš„è§„æ¨¡ï¼Œæ‹¥æœ‰å¤šæ ·åŒ–çš„ä¸´åºŠåŒ»ç”Ÿæ”¯æŒï¼Œå¹¶ä¸”åœ¨ä½¿ç”¨çš„æ•°æ®ä¸Šï¼Œå¯èƒ½è¦æœ‰æ„è¯†åœ°ä¿®æ”¹é—®é¢˜ï¼Œä»¥åŒ…å«äººå£ç»Ÿè®¡æ··æ‚å› ç´ ç­‰ï¼Œè¿™äº›éƒ½æ˜¯å€¼å¾—å…³æ³¨çš„æœ‰è¶£æ–¹å‘ã€‚åœ¨å»ºæ¨¡æ–¹é¢ï¼Œå¯¹æˆ‘æ¥è¯´ï¼Œä¸€ä¸ªæœ‰è¶£çš„é—®é¢˜æ˜¯è¿™ç§ç›¸äº’ä½œç”¨ã€‚
- en: Smallerã€‚Domain specific alarms versus large general purpose alarms and how that's
    going to play out there seems to be some evidence of emergence over here especially
    with medical reasoning and so as you can see at lower scales sometimes the performance
    is not good enough I mean 50% I mean that's a good number but that's just not
    viable and but when you get to like 80 90% products really become useful right
    and so that we are seeing at like you know bigger parameter sizes of these modelsã€‚
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å°ã€‚ç‰¹å®šé¢†åŸŸçš„è­¦æŠ¥ä¸å¤§å‹é€šç”¨è­¦æŠ¥ä¹‹é—´çš„å·®å¼‚ï¼Œä»¥åŠè¿™å°†å¦‚ä½•å‘å±•ï¼Œä¼¼ä¹åœ¨è¿™é‡Œæœ‰ä¸€äº›æ–°å…´çš„è¯æ®ï¼Œå°¤å…¶æ˜¯åœ¨åŒ»å­¦æ¨ç†æ–¹é¢ã€‚å› æ­¤ï¼Œæ­£å¦‚ä½ æ‰€è§ï¼Œåœ¨è¾ƒä½çš„å°ºåº¦ä¸Šï¼Œæœ‰æ—¶æ€§èƒ½å¹¶ä¸å¤Ÿå¥½ï¼Œæˆ‘çš„æ„æ€æ˜¯50%ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸é”™çš„æ•°å­—ï¼Œä½†è¿™å¹¶ä¸å¯è¡Œã€‚ç„¶è€Œï¼Œå½“ä½ è¾¾åˆ°80%æˆ–90%æ—¶ï¼Œäº§å“ç¡®å®å˜å¾—éå¸¸æœ‰ç”¨ï¼Œå¯¹å§ï¼Ÿæˆ‘ä»¬åœ¨è¿™äº›æ¨¡å‹çš„æ›´å¤§å‚æ•°è§„æ¨¡ä¸Šçœ‹åˆ°äº†è¿™ä¸€ç‚¹ã€‚
- en: But I don't knowï¼Œ I think it's still an open question over hereã€‚yahè¯¶ã€‚The question
    was is hallucination an issue I think it still isã€‚but I believe that you can control
    that fairly well with instruction prompt tuning but like any kind of feedback
    data I think it's not terribly difficult to do and so theã€‚I think it might have
    been overblown generallyï¼Œ so especially when you are doing it in a particular
    domainã€‚
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘ä¸çŸ¥é“ï¼Œæˆ‘è®¤ä¸ºè¿™ä¸ªé—®é¢˜åœ¨è¿™é‡Œä»ç„¶æ‚¬è€Œæœªå†³ã€‚è€¶ã€‚é—®é¢˜æ˜¯å¹»è§‰æ˜¯å¦æ˜¯ä¸ªé—®é¢˜ï¼Œæˆ‘è®¤ä¸ºå®ƒä»ç„¶æ˜¯ã€‚ä½†æˆ‘ç›¸ä¿¡ä½ å¯ä»¥é€šè¿‡æŒ‡å¯¼æç¤ºè°ƒæ•´æ¥å¾ˆå¥½åœ°æ§åˆ¶è¿™ä¸€ç‚¹ï¼Œä¸è¿‡åƒä»»ä½•åé¦ˆæ•°æ®ä¸€æ ·ï¼Œæˆ‘è®¤ä¸ºè¿™å¹¶ä¸å›°éš¾ã€‚æ‰€ä»¥ï¼Œæˆ‘è§‰å¾—è¿™ä¸ªé—®é¢˜å¯èƒ½è¢«å¤¸å¤§äº†ï¼Œå°¤å…¶æ˜¯åœ¨ç‰¹å®šé¢†åŸŸæ—¶ã€‚
- en: I think it's easier to controlã€‚I the extent to which you have been leader or
    like like one it looks like I justã€‚Recentlyï¼Œ there's been the product above and
    theirã€‚ä¸€æœ¬ã§ã™ã€‚Okayã€‚Yeahã€‚So I'm just curious because this particular app really veryã€‚very
    relevant and talking about high bar and quality so I'm just curious if speakã€‚Yeahã€‚
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è§‰å¾—æ§åˆ¶èµ·æ¥æ›´å®¹æ˜“ã€‚ä½ ä½œä¸ºé¢†å¯¼è€…çš„ç¨‹åº¦æˆ–åƒé¢†å¯¼è€…ä¸€æ ·çš„ç¨‹åº¦ï¼Œçœ‹èµ·æ¥æˆ‘åªæ˜¯ã€‚æœ€è¿‘ï¼Œå‡ºç°äº†ä¸Šé¢æåˆ°çš„äº§å“åŠå…¶ã€‚ä¸€æœ¬ã§ã™ã€‚å¥½çš„ã€‚æ˜¯çš„ã€‚æ‰€ä»¥æˆ‘åªæ˜¯å¾ˆå¥½å¥‡ï¼Œå› ä¸ºè¿™ä¸ªç‰¹å®šçš„åº”ç”¨ç¨‹åºçœŸçš„éå¸¸ã€‚éå¸¸ç›¸å…³ï¼Œå¹¶è°ˆè®ºé«˜æ ‡å‡†å’Œè´¨é‡ï¼Œæ‰€ä»¥æˆ‘åªæ˜¯å¥½å¥‡æ˜¯å¦è¯´ã€‚
- en: so the question was there is a lot of talk and noise around hallucinations and
    general purple cell limbs and this in this particular application domain it seems
    particularly relevant and so can you expand on that a little bit further sureã€‚What
    we are seeing is even with like an order of a few hundred examples from expert
    clinicians teaching the model how to communicate medical informationã€‚
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥é—®é¢˜åœ¨äºï¼Œå…³äºå¹»è§‰å’Œä¸€èˆ¬çš„ç´«è‰²ç»†èƒè‚¢ä½“æœ‰å¾ˆå¤šè®¨è®ºå’Œå™ªéŸ³ï¼Œè€Œåœ¨è¿™ä¸ªç‰¹å®šçš„åº”ç”¨é¢†åŸŸï¼Œè¿™ä¼¼ä¹å°¤å…¶ç›¸å…³ã€‚ä½ èƒ½å¯¹æ­¤è¿›ä¸€æ­¥å±•å¼€ä¸€ä¸‹å—ï¼Ÿå½“ç„¶å¯ä»¥ã€‚æˆ‘ä»¬çœ‹åˆ°çš„æ˜¯ï¼Œå³ä½¿åªæœ‰å‡ ç™¾ä¸ªä¸“å®¶ä¸´åºŠåŒ»ç”Ÿçš„ç¤ºä¾‹åœ¨æ•™å¯¼æ¨¡å‹å¦‚ä½•ä¼ è¾¾åŒ»ç–—ä¿¡æ¯ã€‚
- en: That is good enough to get the model to maybe stopã€‚Hucinating or at least communicate
    its uncertainty in a better way so at least in this particular domain or this
    setting it feels more tractable to us and the reason I'm saying this is we've
    looked at the answers qualitatively and we are seeing that the model does not
    tend to like generate like super long answers or you know or like you know make
    like very confident predictions but rather the tone itself becomes like very reserved
    and it starts using terms like you know maybe this needs to be done further or
    something like that which communicates uncertainty so how well is that actually
    correlatedated with the representation underlying uncertainty that we have is
    still I think an area of research but I think this is already promising for us
    that it feels controllable in limited application settings like medicineã€‚
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è¶³ä»¥ä½¿æ¨¡å‹å¯èƒ½åœæ­¢å¹»è§‰ï¼Œæˆ–è€…è‡³å°‘ä»¥æ›´å¥½çš„æ–¹å¼ä¼ è¾¾å…¶ä¸ç¡®å®šæ€§ï¼Œå› æ­¤åœ¨è¿™ä¸ªç‰¹å®šé¢†åŸŸæˆ–è®¾ç½®ä¸­ï¼Œå®ƒå¯¹æˆ‘ä»¬æ¥è¯´æ„Ÿè§‰æ›´å¯æ§ã€‚æˆ‘ä¹‹æ‰€ä»¥è¿™ä¹ˆè¯´ï¼Œæ˜¯å› ä¸ºæˆ‘ä»¬å®šæ€§åœ°è§‚å¯Ÿäº†ç­”æ¡ˆï¼Œå‘ç°æ¨¡å‹å¹¶ä¸å€¾å‘äºç”Ÿæˆè¶…çº§é•¿çš„å›ç­”ï¼Œæˆ–è€…åšå‡ºéå¸¸è‡ªä¿¡çš„é¢„æµ‹ï¼Œè€Œæ˜¯è¯­æ°”æœ¬èº«å˜å¾—éå¸¸è°¨æ…ï¼Œå¼€å§‹ä½¿ç”¨è¯¸å¦‚â€œä¹Ÿè®¸éœ€è¦è¿›ä¸€æ­¥å¤„ç†â€ä¹‹ç±»çš„æœ¯è¯­ï¼Œè¿™ä¼ è¾¾äº†ä¸ç¡®å®šæ€§ã€‚é‚£ä¹ˆï¼Œè¿™ä¸æˆ‘ä»¬æ‰€æ‹¥æœ‰çš„ä¸ç¡®å®šæ€§åŸºæœ¬è¡¨ç¤ºä¹‹é—´çš„ç›¸å…³æ€§åˆ°åº•å¦‚ä½•ï¼Œæˆ‘è®¤ä¸ºä»ç„¶æ˜¯ä¸€ä¸ªç ”ç©¶é¢†åŸŸï¼Œä½†æˆ‘è®¤ä¸ºè¿™å¯¹æˆ‘ä»¬æ¥è¯´å·²ç»å¾ˆæœ‰å‰æ™¯ï¼Œå› ä¸ºå®ƒåœ¨æœ‰é™çš„åº”ç”¨åœºæ™¯ä¸­ï¼Œå¦‚åŒ»å­¦ï¼Œæ„Ÿè§‰æ˜¯å¯æ§çš„ã€‚
- en: But if you have a general purpose Lmm trying to answer pretty much everything
    about the worldã€‚I think that's a much harder problemã€‚Do you think that would be
    a feature of like the domainã€‚David saidï¼ŸIn medical situationsï¼Œ doctors are more
    reserved perhapss and don'tã€‚Absolute have absolutely English forã€‚On on certain
    things or do you think it's more that like you have like just specialized right
    like it could beã€‚
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯å¦‚æœä½ æœ‰ä¸€ä¸ªé€šç”¨çš„è¯­è¨€æ¨¡å‹ï¼Œè¯•å›¾å›ç­”å…³äºä¸–ç•Œçš„å‡ ä¹æ‰€æœ‰é—®é¢˜ã€‚æˆ‘è®¤ä¸ºè¿™å°†æ˜¯ä¸€ä¸ªæ›´å›°éš¾çš„é—®é¢˜ã€‚ä½ è®¤ä¸ºè¿™ä¼šæ˜¯æŸç§é¢†åŸŸçš„ç‰¹å¾å—ï¼Ÿå¤§å«è¯´ï¼Ÿåœ¨åŒ»ç–—æƒ…å†µä¸‹ï¼ŒåŒ»ç”Ÿå¯èƒ½ä¼šæ›´è°¨æ…ä¸€äº›ï¼Œç»å¯¹ä¸å¯¹æŸäº›äº‹æƒ…æœ‰ç»å¯¹çš„è‹±è¯­è¡¨è¾¾ã€‚æˆ–è€…ä½ è®¤ä¸ºè¿™æ›´å¤šçš„æ˜¯ä½ åªéœ€è¦ä¸“é—¨åŒ–ï¼Ÿè¿™å¯èƒ½æ˜¯è¿™æ ·çš„ã€‚
- en: Something else entirely also I'm just curious yeahï¼Œ so the question isã€‚do you
    think this the way how the model is performing in this domain is that a feature
    of the data sets in the medical domain andã€‚Typically based on how doctors communicate
    and I think that's true and I think that's something we need to build on and use
    over here and I think that's extremely helpful and hopefully this kind of behavior
    is general enough and can be transmitted to the model even when it's used in non-medical
    settings to be like you know more reserved when it's communicating hallucinateless
    and so on and so forth so I believe that that's one of the opportunities over
    here to like use these benchmarks come up with methods that reduce hallucinationã€‚
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: å®Œå…¨ä¸åŒçš„äº‹æƒ…ï¼Œæˆ‘åªæ˜¯å¥½å¥‡ï¼Œæ‰€ä»¥é—®é¢˜æ˜¯ã€‚ä½ è®¤ä¸ºè¿™ä¸ªæ¨¡å‹åœ¨è¿™ä¸ªé¢†åŸŸçš„è¡¨ç°æ˜¯æ•°æ®é›†åœ¨åŒ»ç–—é¢†åŸŸçš„ä¸€ä¸ªç‰¹å¾å—ï¼Ÿé€šå¸¸æ˜¯åŸºäºåŒ»ç”Ÿçš„æ²Ÿé€šæ–¹å¼ï¼Œæˆ‘è®¤ä¸ºè¿™æ˜¯æ­£ç¡®çš„ï¼Œæˆ‘è®¤ä¸ºè¿™æ˜¯æˆ‘ä»¬éœ€è¦åœ¨è¿™é‡Œæ„å»ºå’Œåˆ©ç”¨çš„ä¸œè¥¿ï¼Œæˆ‘è®¤ä¸ºè¿™éå¸¸æœ‰å¸®åŠ©ï¼Œå¸Œæœ›è¿™ç§è¡Œä¸ºè¶³å¤Ÿæ™®éï¼Œèƒ½å¤Ÿè½¬ç§»åˆ°æ¨¡å‹ä¸­ï¼Œå³ä½¿åœ¨éåŒ»ç–—ç¯å¢ƒä¸­ä½¿ç”¨æ—¶ï¼Œä¹Ÿèƒ½åœ¨äº¤æµæ—¶æ›´åŠ å…‹åˆ¶ï¼Œå‡å°‘è™šå‡ä¿¡æ¯ç­‰ç­‰ã€‚æ‰€ä»¥æˆ‘ç›¸ä¿¡è¿™æ˜¯è¿™é‡Œçš„ä¸€ä¸ªæœºä¼šï¼Œå¯ä»¥åˆ©ç”¨è¿™äº›åŸºå‡†ï¼Œæå‡ºå‡å°‘è™šå‡ä¿¡æ¯çš„æ–¹æ³•ã€‚
- en: communicate uncertainty better and then use that as a bidirectional learning
    opportunity to improve the general purpose cell thisã€‚So if you have any further
    questionsï¼Œ I'll come back again at the end of the talkã€‚but I want to cover the
    rest of the applications as wellã€‚So the next domain I want to talk about is proteins
    and the papers from now I'm going to like zip through them a little bit given
    timeã€‚
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å¥½åœ°ä¼ è¾¾ä¸ç¡®å®šæ€§ï¼Œç„¶åå°†å…¶ä½œä¸ºåŒå‘å­¦ä¹ çš„æœºä¼šï¼Œä»¥æ”¹è¿›é€šç”¨ç›®çš„ç»†èƒã€‚è¿™ä¹ˆè¯´ï¼Œå¦‚æœä½ è¿˜æœ‰å…¶ä»–é—®é¢˜ï¼Œæˆ‘ä¼šåœ¨æ¼”è®²ç»“æŸæ—¶å†å›æ¥ã€‚ ä½†æˆ‘ä¹Ÿæƒ³æ¶µç›–å…¶ä»–åº”ç”¨ã€‚å› æ­¤ï¼Œæˆ‘æƒ³è°ˆè®ºçš„ä¸‹ä¸€ä¸ªé¢†åŸŸæ˜¯è›‹ç™½è´¨ï¼Œä»ç°åœ¨å¼€å§‹æˆ‘ä¼šç¨å¾®å¿«é€Ÿæµè§ˆè¿™äº›è®ºæ–‡ï¼Œè€ƒè™‘åˆ°æ—¶é—´ã€‚
- en: but the first one I want to talk is this paper from a few folks at Google Research
    back in 2020 called mass language modeling for proteins by linearly scalable long
    Con transformformersã€‚So the problem here is that modeling long range biological
    sequences requires efficient transformer architecturesã€‚
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æƒ³é¦–å…ˆè°ˆè°ˆ2020å¹´è°·æ­Œç ”ç©¶çš„ä¸€äº›äººå‘è¡¨çš„è®ºæ–‡ï¼Œæ ‡é¢˜ä¸ºâ€œé€šè¿‡çº¿æ€§å¯æ‰©å±•çš„é•¿å·ç§¯å˜æ¢å™¨è¿›è¡Œè›‹ç™½è´¨çš„å¤§è§„æ¨¡è¯­è¨€å»ºæ¨¡â€ã€‚æ‰€ä»¥è¿™é‡Œçš„é—®é¢˜æ˜¯ï¼Œå»ºæ¨¡é•¿è·ç¦»ç”Ÿç‰©åºåˆ—éœ€è¦é«˜æ•ˆçš„å˜æ¢å™¨æ¶æ„ã€‚
- en: and so in this particular paper what they introduced was this performer architectureã€‚which
    approximates the softmax attention kernel via low rank decompositionã€‚And so this
    does not incorporate any spaity priceï¼Œ say like other methods like the reformer
    or there are many othersã€‚and this is good because spaity price may not be appropriate
    for biological data such as proteinã€‚
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤åœ¨è¿™ç¯‡ç‰¹å®šçš„è®ºæ–‡ä¸­ï¼Œä»–ä»¬å¼•å…¥äº†è¿™ç§è¡¨æ¼”è€…æ¶æ„ã€‚å®ƒé€šè¿‡ä½ç§©åˆ†è§£æ¥è¿‘ä¼¼softmaxæ³¨æ„åŠ›æ ¸ã€‚å¹¶ä¸”è¿™å¹¶ä¸åŒ…å«ä»»ä½•ç¨€ç–æˆæœ¬ï¼Œæ¯”å¦‚å…¶ä»–æ–¹æ³•ï¼Œå¦‚reformeræˆ–å…¶ä»–è®¸å¤šæ–¹æ³•ã€‚è¿™æ˜¯å¥½çš„ï¼Œå› ä¸ºç¨€ç–æˆæœ¬å¯èƒ½ä¸é€‚åˆç”Ÿç‰©æ•°æ®ï¼Œä¾‹å¦‚è›‹ç™½è´¨ã€‚
- en: which required global interactions to be modeledã€‚And then the other thing is
    this modelã€‚the performance scales linearly rather than quadratically with the
    sequence link deã€‚and the number of random features that you need to approximate
    this Somax attention kernel is completely independent of the input sequence linkã€‚So
    just to very quickly visualize the speedups and the space complexity improvementsã€‚
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™éœ€è¦å¯¹å…¨çƒäº’åŠ¨è¿›è¡Œå»ºæ¨¡ã€‚ç„¶åå¦ä¸€ä¸ªæ–¹é¢æ˜¯è¿™ä¸ªæ¨¡å‹ã€‚æ€§èƒ½ä¸åºåˆ—é“¾æ¥çš„ç¼©æ”¾æ˜¯çº¿æ€§çš„ï¼Œè€Œä¸æ˜¯äºŒæ¬¡çš„ã€‚ä½ éœ€è¦è¿‘ä¼¼è¿™ä¸ªSomaxæ³¨æ„åŠ›æ ¸çš„éšæœºç‰¹å¾æ•°é‡ä¸è¾“å…¥åºåˆ—çš„é“¾æ¥å®Œå…¨æ— å…³ã€‚æ‰€ä»¥ä¸ºäº†å¿«é€Ÿå¯è§†åŒ–åŠ é€Ÿå’Œç©ºé—´å¤æ‚åº¦çš„æ”¹å–„ã€‚
- en: what you're having with this low angle decomposition is instead of having like
    fat matrices in your softmax attention kernelã€‚you now have thinner mattressrices
    which are determined by the size of the random features and that basically reduces
    your quadratic complexity to something that is more linear in nature and also
    leads to space improvementsã€‚
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ åœ¨è¿™ä¸ªä½è§’åº¦åˆ†è§£ä¸­æ‰€é‡åˆ°çš„æ˜¯ï¼Œä¸å†åƒä½ çš„softmaxæ³¨æ„åŠ›æ ¸ä¸­æœ‰åšé‡çš„çŸ©é˜µã€‚ç°åœ¨ä½ æœ‰äº†æ›´è–„çš„çŸ©é˜µï¼Œè¿™äº›çŸ©é˜µç”±éšæœºç‰¹å¾çš„å¤§å°å†³å®šï¼Œè¿™åŸºæœ¬ä¸Šå°†ä½ çš„å¹³æ–¹å¤æ‚åº¦é™ä½åˆ°æ›´çº¿æ€§çš„æ€§è´¨ï¼Œå¹¶ä¸”è¿˜å¸¦æ¥äº†ç©ºé—´çš„æ”¹è¿›ã€‚
- en: So I would yeah there are more theoretical analysis and details in a paper and
    I would refer you all back to itã€‚but what we see in terms of results when doing
    protein language modeling is that the accuracy of of this model is on par with
    transformers while reducing computational cost quite a bit and so what this suggests
    is that the approximation of the softmax attention kernel is a tight approximation
    so that is good and then when you compare that with other methods such as the
    reformer or the Lyformerã€‚
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä¼šè¯´ï¼Œè®ºæ–‡ä¸­æœ‰æ›´å¤šçš„ç†è®ºåˆ†æå’Œç»†èŠ‚ï¼Œæˆ‘ä¼šå»ºè®®å¤§å®¶å‚è€ƒä¸€ä¸‹ã€‚ä½†åœ¨è¿›è¡Œè›‹ç™½è´¨è¯­è¨€å»ºæ¨¡æ—¶ï¼Œæˆ‘ä»¬çœ‹åˆ°çš„ç»“æœæ˜¯ï¼Œè¿™ä¸ªæ¨¡å‹çš„å‡†ç¡®æ€§ä¸å˜å‹å™¨ç›¸å½“ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ï¼Œè¿™è¡¨æ˜softmaxæ³¨æ„åŠ›æ ¸çš„è¿‘ä¼¼æ˜¯éå¸¸ç´§å¯†çš„ï¼Œè¿™å¾ˆå¥½ã€‚ç„¶åå½“ä½ å°†å…¶ä¸å…¶ä»–æ–¹æ³•å¦‚reformeræˆ–Lyformerè¿›è¡Œæ¯”è¾ƒæ—¶ã€‚
- en: the accuracy is much higher at least on this task so it seems that compared
    to other methods that like try to build more efficient transformist this one is
    much better for biological sequence data at least in this settingã€‚And finallyï¼Œ
    if you look at the attention of the amino acid similarity matrixã€‚
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªä»»åŠ¡ä¸Šï¼Œå‡†ç¡®æ€§è¦é«˜å¾—å¤šï¼Œå› æ­¤ä¸å…¶ä»–è¯•å›¾æ„å»ºæ›´æœ‰æ•ˆçš„å˜æ¢æ¨¡å‹çš„æ–¹æ³•ç›¸æ¯”ï¼Œè¿™ç§æ–¹æ³•å¯¹äºç”Ÿç‰©åºåˆ—æ•°æ®åœ¨è¿™ç§è®¾ç½®ä¸‹è¦å¥½å¾—å¤šã€‚æœ€åï¼Œå¦‚æœä½ æŸ¥çœ‹æ°¨åŸºé…¸ç›¸ä¼¼æ€§çŸ©é˜µçš„æ³¨æ„åŠ›ã€‚
- en: you can see that the performma model recognizes highly similar amino acid pairs
    such as DE and FNY over hereã€‚That suggests that the model is learning the right
    set of information that we really want over hereã€‚So that was a two minute overview
    of the paperï¼Œ but I wonder yeahã€‚talk about another one which also I think is really
    really coolã€‚
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥çœ‹åˆ°ï¼Œperformmaæ¨¡å‹è¯†åˆ«äº†é«˜åº¦ç›¸ä¼¼çš„æ°¨åŸºé…¸å¯¹ï¼Œä¾‹å¦‚è¿™é‡Œçš„DEå’ŒFNYã€‚è¿™è¡¨æ˜æ¨¡å‹æ­£åœ¨å­¦ä¹ æˆ‘ä»¬çœŸæ­£æƒ³è¦çš„ä¿¡æ¯é›†ã€‚æ‰€ä»¥è¿™æ˜¯å¯¹è®ºæ–‡çš„ä¸¤åˆ†é’Ÿæ¦‚è¿°ï¼Œä½†æˆ‘æƒ³ï¼Œå—¯ï¼Œè°ˆè°ˆå¦ä¸€ä¸ªæˆ‘è®¤ä¸ºä¹Ÿéå¸¸éå¸¸é…·çš„ã€‚
- en: So this one is called protein Llum again by a few of folks at Global Researchã€‚and
    what this tells us is model based natural language protein annotationã€‚And why
    this problem is important is because the protein information is in very high demandã€‚So
    over 50% of all known protein sal in sequence we don't actually know what they
    do so it's important that we able to like decier that to some degree at least
    and then the second thing is we may want to for example find protein sequences
    with given functions and this is particularly important in the CRISPR domain and
    so if you can train bidirectional models that can do this I think thatll be incredibly
    helpful andã€‚
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªè¢«ç§°ä¸ºè›‹ç™½è´¨Llumçš„é¡¹ç›®æ˜¯ç”±å…¨çƒç ”ç©¶çš„ä¸€äº›äººæå‡ºçš„ã€‚è¿™å‘Šè¯‰æˆ‘ä»¬çš„æ˜¯åŸºäºæ¨¡å‹çš„è‡ªç„¶è¯­è¨€è›‹ç™½è´¨æ³¨é‡Šã€‚è¿™ä¸ªé—®é¢˜ä¹‹æ‰€ä»¥é‡è¦ï¼Œæ˜¯å› ä¸ºè›‹ç™½è´¨ä¿¡æ¯çš„éœ€æ±‚éå¸¸é«˜ã€‚å› æ­¤ï¼Œå·²çŸ¥è›‹ç™½è´¨åºåˆ—ä¸­è¶…è¿‡50%çš„åŠŸèƒ½æˆ‘ä»¬å®é™…ä¸Šå¹¶ä¸çŸ¥é“ï¼Œæ‰€ä»¥è‡³å°‘åœ¨æŸç§ç¨‹åº¦ä¸Šèƒ½å¤Ÿè§£è¯»è¿™äº›ä¿¡æ¯æ˜¯å¾ˆé‡è¦çš„ã€‚ç¬¬äºŒç‚¹æ˜¯ï¼Œæˆ‘ä»¬å¯èƒ½æƒ³è¦æ‰¾åˆ°å…·æœ‰ç‰¹å®šåŠŸèƒ½çš„è›‹ç™½è´¨åºåˆ—ï¼Œè¿™åœ¨CRISPRé¢†åŸŸå°¤ä¸ºé‡è¦ã€‚å¦‚æœä½ èƒ½è®­ç»ƒå‡ºèƒ½å¤Ÿåšåˆ°è¿™ä¸€ç‚¹çš„åŒå‘æ¨¡å‹ï¼Œæˆ‘è®¤ä¸ºè¿™å°†æ˜¯éå¸¸æœ‰å¸®åŠ©çš„ã€‚
- en: And the reason I say thisï¼Œ againï¼Œ is that the Unipro database that has overã€‚There
    is I think millions of researchers worldwide using it todayã€‚and so getting this
    information populated in that database would be incredibly useful and accelerate
    a lot of research in this spaceã€‚And so the European Bioinformatics Instituteï¼Œ
    they have curated this prett data about proteins and so basically you can use
    this protein in record to like train these models and so what you want to do is
    you want to maybe learn to directly map from amino acid sequences to natural language
    descriptions of themã€‚
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¹‹æ‰€ä»¥è¿™ä¹ˆè¯´ï¼Œæ˜¯å› ä¸ºUniproæ•°æ®åº“æ‹¥æœ‰è¶…è¿‡åƒä¸‡çš„ç ”ç©¶äººå‘˜åœ¨å…¨çƒèŒƒå›´å†…ä½¿ç”¨å®ƒã€‚å°†è¿™äº›ä¿¡æ¯å¡«å……åˆ°è¯¥æ•°æ®åº“ä¸­å°†æ˜¯éå¸¸æœ‰ç”¨çš„ï¼Œå¹¶èƒ½åŠ é€Ÿè¿™ä¸€é¢†åŸŸçš„å¤§é‡ç ”ç©¶ã€‚å› æ­¤ï¼Œæ¬§æ´²ç”Ÿç‰©ä¿¡æ¯å­¦ç ”ç©¶æ‰€å¯¹è›‹ç™½è´¨è¿›è¡Œäº†æ•°æ®æ•´ç†ï¼ŒåŸºæœ¬ä¸Šä½ å¯ä»¥åˆ©ç”¨è¿™äº›è›‹ç™½è´¨è®°å½•æ¥è®­ç»ƒè¿™äº›æ¨¡å‹ã€‚å› æ­¤ï¼Œä½ æƒ³è¦åšçš„å°±æ˜¯ç›´æ¥å°†æ°¨åŸºé…¸åºåˆ—æ˜ å°„åˆ°å®ƒä»¬çš„è‡ªç„¶è¯­è¨€æè¿°ä¸Šã€‚
- en: And this problem is not too different from an image captioning problem where
    instead of having a sequence of pixelsã€‚I don't know if sequence is rightï¼Œ but
    again if you have pixels instead you have a sequence of aminoamine acids and they
    can range a number from two to 40K and then what you want to generate out is a
    protein description of the proteinã€‚
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªé—®é¢˜ä¸å›¾åƒæ ‡é¢˜ç”Ÿæˆé—®é¢˜å¹¶æ²¡æœ‰å¤ªå¤§ä¸åŒï¼Œåœ¨è¿™é‡Œä½ ä¸æ˜¯å¤„ç†ä¸€ç³»åˆ—åƒç´ ã€‚æˆ‘ä¸çŸ¥é“â€œåºåˆ—â€æ˜¯å¦åˆé€‚ï¼Œä½†å¦‚æœä½ æœ‰çš„æ˜¯åƒç´ ï¼Œè€Œæ˜¯æœ‰ä¸€ç³»åˆ—æ°¨åŸºé…¸ï¼Œå®ƒä»¬çš„æ•°é‡å¯ä»¥ä»äºŒåˆ°å››ä¸‡ä¸ç­‰ï¼Œç„¶åä½ æƒ³ç”Ÿæˆçš„æ˜¯è›‹ç™½è´¨çš„æè¿°ã€‚
- en: And in this paper the way they do this is they train a T5 model on protein sequence
    sanitation tasksã€‚so the tasks are set up in a bunch of different ways and the
    supervised data comes from a bunch of different sources in the protein record
    that they have and this model is an encode E T5 model so it's a very cool application
    and the results are that out of the 56 million proteins in that unprod database
    that were previously uncharacterized 49 million of them now have associated textual
    descriptions so we now have a handle on what they doã€‚
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œä»–ä»¬çš„åšæ³•æ˜¯è®­ç»ƒä¸€ä¸ªT5æ¨¡å‹æ¥å¤„ç†è›‹ç™½è´¨åºåˆ—çš„æ¸…ç†ä»»åŠ¡ã€‚å› æ­¤ï¼Œè¿™äº›ä»»åŠ¡ä»¥å¤šç§ä¸åŒæ–¹å¼è®¾ç½®ï¼Œç›‘ç£æ•°æ®æ¥è‡ªä»–ä»¬æ‰€æ‹¥æœ‰çš„è›‹ç™½è´¨è®°å½•ä¸­çš„å¤šä¸ªä¸åŒæ¥æºã€‚è¿™ä¸ªæ¨¡å‹æ˜¯ä¸€ä¸ªç¼–ç E
    T5æ¨¡å‹ï¼Œå› æ­¤è¿™æ˜¯ä¸€ä¸ªéå¸¸é…·çš„åº”ç”¨ã€‚ç»“æœæ˜¯ï¼Œåœ¨ä¹‹å‰æœªè¢«è¡¨å¾çš„5600ä¸‡ç§è›‹ç™½è´¨ä¸­ï¼Œç°å·²æœ‰4900ä¸‡ç§ä¸ä¹‹ç›¸å…³çš„æ–‡æœ¬æè¿°ï¼Œå› æ­¤æˆ‘ä»¬ç°åœ¨å¯¹å®ƒä»¬çš„åŠŸèƒ½æœ‰äº†æ›´æ¸…æ™°çš„ç†è§£ã€‚
- en: å—¯ã€‚And so that's really cool and then the other one I think which is probably
    even more interesting is now you can run queries like find me a smaller version
    of this CRISP Cas9 protein so that it can target certain tissue spectra and now
    the model can know come back with sequences and so I think this is again going
    to be incredibly useful and going to accelerate a lot of research in this space
    already there's a lot of momentum I think these models are going to further helpã€‚
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: å—¯ã€‚æ‰€ä»¥è¿™çœŸçš„å¾ˆé…·ï¼Œç„¶åæˆ‘è®¤ä¸ºå¦ä¸€ä¸ªå¯èƒ½æ›´æœ‰è¶£çš„æ˜¯ï¼Œç°åœ¨ä½ å¯ä»¥è¿è¡ŒæŸ¥è¯¢ï¼Œæ¯”å¦‚æ‰¾åˆ°è¿™ä¸ªCRISP Cas9è›‹ç™½çš„å°å‹ç‰ˆæœ¬ï¼Œä»¥ä¾¿å®ƒå¯ä»¥é’ˆå¯¹æŸäº›ç»„ç»‡å…‰è°±ï¼Œç°åœ¨æ¨¡å‹èƒ½å¤Ÿè¿”å›åºåˆ—ï¼Œæ‰€ä»¥æˆ‘è®¤ä¸ºè¿™å°†å†æ¬¡éå¸¸æœ‰ç”¨ï¼Œå¹¶åŠ é€Ÿè¿™ä¸ªé¢†åŸŸçš„è®¸å¤šç ”ç©¶ï¼Œå·²ç»æœ‰å¾ˆå¤šåŠ¿å¤´ï¼Œæˆ‘è®¤ä¸ºè¿™äº›æ¨¡å‹å°†è¿›ä¸€æ­¥æä¾›å¸®åŠ©ã€‚
- en: è¯¶ã€‚So that was on proteinsï¼Œ the last class of applications that I want to cover
    is on the genomics siteã€‚Againï¼Œ the first paper over here was somewhat last year
    from our Ge team at HealthI at Googleã€‚which is building gap our sequence transformers
    for sequence correctionã€‚So this model is called deep consensus and so what role
    does this model play and why does it matterï¼Ÿ
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: å—¯ã€‚æ‰€ä»¥åˆšæ‰è®²çš„æ˜¯è›‹ç™½è´¨ï¼Œæˆ‘æƒ³è¦æ¶µç›–çš„æœ€åä¸€ç±»åº”ç”¨æ˜¯åŸºå› ç»„å­¦ç½‘ç«™ã€‚å†è¯´ï¼Œè¿™é‡Œç¬¬ä¸€ç¯‡è®ºæ–‡æ˜¯å»å¹´æˆ‘ä»¬è°·æ­ŒHealthIçš„Geå›¢é˜Ÿå‘è¡¨çš„ï¼Œå®ƒæ˜¯åœ¨ä¸ºåºåˆ—æ ¡æ­£æ„å»ºæˆ‘ä»¬çš„åºåˆ—å˜æ¢å™¨ã€‚æ‰€ä»¥è¿™ä¸ªæ¨¡å‹å«åšæ·±åº¦å…±è¯†ï¼Œè¿™ä¸ªæ¨¡å‹æ‰®æ¼”ä»€ä¹ˆè§’è‰²ï¼Œä¸ºä»€ä¹ˆå®ƒé‡è¦ï¼Ÿ
- en: So if you look at the sequencing data lifecyclï¼Œ what you do is you go from basically
    atoms to bits and so you have this physical specimen which hopefully has some
    DNA in it and youã€‚P it through a sequencing machine such as Spg bio and that comes
    out with the raw data and that raw data gets mapped to a reference genome and
    then sometimes there might be diffs between an individual and the reference genome
    and that can be corrected through this model called deep variant that was introduced
    by your team a few years back and that's open source and then once you have this
    sequence you can then use it for a bunch of different analysis such as ancestry
    or like just basic biomedical researchã€‚
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å¦‚æœä½ çœ‹ä¸€ä¸‹æµ‹åºæ•°æ®ç”Ÿå‘½å‘¨æœŸï¼Œä½ åŸºæœ¬ä¸Šæ˜¯ä»åŸå­åˆ°æ¯”ç‰¹çš„è½¬å˜ï¼Œå› æ­¤ä½ æœ‰è¿™ä¸ªç‰©ç†æ ·æœ¬ï¼Œå¸Œæœ›å…¶ä¸­æœ‰ä¸€äº›DNAï¼Œç„¶åä½ æŠŠå®ƒé€šè¿‡åƒSpg bioè¿™æ ·çš„æµ‹åºæœºå™¨ï¼Œå¾—å‡ºçš„åŸå§‹æ•°æ®ä¼šè¢«æ˜ å°„åˆ°å‚è€ƒåŸºå› ç»„ï¼Œæœ‰æ—¶ä¸ªä½“ä¸å‚è€ƒåŸºå› ç»„ä¹‹é—´å¯èƒ½ä¼šæœ‰å·®å¼‚ï¼Œè¿™å¯ä»¥é€šè¿‡ä½ ä»¬å‡ å¹´å‰å¼•å…¥çš„ä¸€ä¸ªå«åšdeep
    variantçš„æ¨¡å‹è¿›è¡Œä¿®æ­£ï¼Œè€Œè¿™ä¸ªæ¨¡å‹æ˜¯å¼€æºçš„ã€‚ç„¶åä¸€æ—¦ä½ æ‹¥æœ‰äº†è¿™ä¸ªåºåˆ—ï¼Œä½ å°±å¯ä»¥ç”¨å®ƒè¿›è¡Œå¤šç§ä¸åŒçš„åˆ†æï¼Œä¾‹å¦‚ç¥–å…ˆåˆ†ææˆ–åŸºç¡€ç”Ÿç‰©åŒ»å­¦ç ”ç©¶ã€‚
- en: So where deep variant fits in is it actually makes the raw DNA reads that comes
    out from the PA biosequenceer it tries to make it more accurate and so how the
    PA biosqueenceer actually works is it uses this circular consensus sequencing
    algorithm where the DNA molecule is like you know read several times and it produces
    multiple different subres and these subreads areã€‚
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: æ·±åº¦å˜ä½“çš„ä½œç”¨åœ¨äºï¼Œå®ƒå®é™…ä¸Šä½¿å¾—ä»PAç”Ÿç‰©æµ‹åºä»ªä¸­å¾—åˆ°çš„åŸå§‹DNAè¯»å–ç»“æœæ›´åŠ å‡†ç¡®ã€‚PAç”Ÿç‰©æµ‹åºä»ªçš„å·¥ä½œåŸç†æ˜¯ä½¿ç”¨ä¸€ç§å¾ªç¯å…±è¯†æµ‹åºç®—æ³•ï¼Œå…¶ä¸­DNAåˆ†å­ä¼šè¢«å¤šæ¬¡è¯»å–ï¼Œä»è€Œç”Ÿæˆå¤šä¸ªä¸åŒçš„å­è¯»å–ç»“æœï¼Œè¿™äº›å­è¯»å–æ˜¯ã€‚
- en: They do contain some errors and so they're finally like assembled together and
    so what Deep W tries to do is it tries to improve on the errors over here basically
    that comes out from just this circularence sensor sequencing algorithmã€‚And so
    how does this model work so as that the basic task for deep consensus is to use
    the CSCCS data and the subreeds associated with them to generate a corrected sequence
    and so in this example when we run through the model what we see is that while
    the CCS identity was at like 95ã€‚
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä»¬ç¡®å®åŒ…å«ä¸€äº›é”™è¯¯ï¼Œå› æ­¤å®ƒä»¬æœ€ç»ˆæ˜¯ç»„åˆåœ¨ä¸€èµ·çš„ï¼Œè€Œæ·±åº¦å…±è¯†ï¼ˆDeep Wï¼‰æ‰€å°è¯•åšçš„å°±æ˜¯åŸºæœ¬ä¸Šæ”¹å–„ç”±è¿™ä¸ªå¾ªç¯ä¼ æ„Ÿå™¨åºåˆ—ç®—æ³•æ‰€äº§ç”Ÿçš„é”™è¯¯ã€‚é‚£ä¹ˆï¼Œè¿™ä¸ªæ¨¡å‹æ˜¯å¦‚ä½•å·¥ä½œçš„å‘¢ï¼Ÿæ·±åº¦å…±è¯†çš„åŸºæœ¬ä»»åŠ¡æ˜¯åˆ©ç”¨CSCCSæ•°æ®åŠå…¶ç›¸å…³çš„å­åºåˆ—ç”Ÿæˆä¸€ä¸ªä¿®æ­£çš„åºåˆ—ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œå½“æˆ‘ä»¬è¿è¡Œæ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬çœ‹åˆ°CCSçš„èº«ä»½å¤§çº¦åœ¨95ã€‚
- en: 7% the deep consensus prediction identity was at 100% so it's a fairly simple
    task where you're trying to like reduce errors that come out from the fact bio
    with the CCS algorithmã€‚And so the very natural question is where do these labels
    come fromï¼Ÿ
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 7% çš„æ·±åº¦å…±è¯†é¢„æµ‹èº«ä»½è¾¾åˆ°äº† 100%ï¼Œæ‰€ä»¥è¿™æ˜¯ä¸€é¡¹ç›¸å¯¹ç®€å•çš„ä»»åŠ¡ï¼Œä½ è¯•å›¾å‡å°‘ç”±äº CCS ç®—æ³•å¸¦æ¥çš„é”™è¯¯ã€‚å¾ˆè‡ªç„¶çš„é—®é¢˜æ˜¯ï¼Œè¿™äº›æ ‡ç­¾æ¥è‡ªå“ªé‡Œï¼Ÿ
- en: So each CCS sequence that you have that is aligned to a high quality assembly
    and this high qualityality assembly is created by having many CCS reads stitch
    together and so that ends up having fewer errors and so you can then try to use
    that high- qualityality stitch assembly and map that back to the CCA trade for
    a given block and use that as that label so that results in more you know like
    stronger ground truth and you can use that to train the model to improve the accuracy
    further and so this is what the model is strained on and so the model looks like
    this it's a transformer architecture it takes these subres and this CCS read as
    well and it has a bunch of additional context features that come in from this
    the sequence itself the instrument sequencing instrument as well and these are
    all fit into the transformer model it produces polish segment and these segments
    are then like stitch together to produce the final polish read over hereã€‚
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæ‚¨æ‹¥æœ‰çš„æ¯ä¸ªä¸é«˜è´¨é‡ç»„è£…å¯¹é½çš„CCSåºåˆ—ï¼Œè¿™ç§é«˜è´¨é‡ç»„è£…æ˜¯é€šè¿‡å°†å¤šä¸ªCCSè¯»å–æ‹¼æ¥åœ¨ä¸€èµ·åˆ›å»ºçš„ï¼Œä»è€Œæœ€ç»ˆå‡å°‘äº†é”™è¯¯ï¼Œå› æ­¤æ‚¨å¯ä»¥å°è¯•ä½¿ç”¨è¿™ç§é«˜è´¨é‡æ‹¼æ¥ç»„è£…ï¼Œå¹¶å°†å…¶æ˜ å°„å›ç»™å®šå—çš„CCAè´¸æ˜“ï¼Œå¹¶å°†å…¶ç”¨ä½œæ ‡ç­¾ï¼Œè¿™æ ·å°±èƒ½äº§ç”Ÿæ›´å¼ºçš„çœŸå®æ•°æ®ï¼Œæ‚¨å¯ä»¥ç”¨å®ƒæ¥è®­ç»ƒæ¨¡å‹ä»¥è¿›ä¸€æ­¥æé«˜å‡†ç¡®æ€§ï¼Œå› æ­¤è¿™å°±æ˜¯æ¨¡å‹çš„è®­ç»ƒå†…å®¹ï¼Œæ¨¡å‹çš„æ¶æ„æ˜¯å˜å‹å™¨æ¶æ„ï¼Œå®ƒæ¥æ”¶è¿™äº›å­è¯»å–å’ŒCCSè¯»å–ï¼Œä»¥åŠæ¥è‡ªåºåˆ—æœ¬èº«ã€æµ‹åºä»ªç­‰çš„é¢å¤–ä¸Šä¸‹æ–‡ç‰¹å¾ï¼Œæ‰€æœ‰è¿™äº›éƒ½è¢«è¾“å…¥åˆ°å˜å‹å™¨æ¨¡å‹ä¸­ï¼Œå®ƒç”ŸæˆæŠ›å…‰ç‰‡æ®µï¼Œè¿™äº›ç‰‡æ®µéšåè¢«æ‹¼æ¥åœ¨ä¸€èµ·ä»¥ç”Ÿæˆæœ€ç»ˆçš„æŠ›å…‰è¯»å–ã€‚
- en: One thing I will point out over here is that in order to train this modelã€‚you
    can't use a cross enpy loss and this is becauseã€‚You knowã€‚if you insert you often
    have insertions in DNA sequences and so that can when you use cross entropy loss
    like really throw off the modelã€‚even like a single error as you can see over here
    can propagate throughout the sequence and make it really worse so what you need
    is a special kind of alignment loss based on a distance that can really capture
    this error much much betterã€‚
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åœ¨è¿™é‡Œè¦æŒ‡å‡ºçš„ä¸€ç‚¹æ˜¯ï¼Œä¸ºäº†è®­ç»ƒè¿™ä¸ªæ¨¡å‹ï¼Œä½ ä¸èƒ½ä½¿ç”¨äº¤å‰ç†µæŸå¤±ï¼Œè¿™æ˜¯å› ä¸ºã€‚ä½ çŸ¥é“ï¼Œå¦‚æœä½ æ’å…¥ï¼ŒDNAåºåˆ—ä¸­é€šå¸¸ä¼šæœ‰æ’å…¥ï¼Œå› æ­¤ä½¿ç”¨äº¤å‰ç†µæŸå¤±æ—¶ï¼Œè¿™ä¼šä¸¥é‡å½±å“æ¨¡å‹ã€‚å³ä½¿æ˜¯åƒè¿™é‡Œçœ‹åˆ°çš„ä¸€ä¸ªå•ä¸€é”™è¯¯ï¼Œä¹Ÿå¯ä»¥åœ¨æ•´ä¸ªåºåˆ—ä¸­ä¼ æ’­ï¼Œå¯¼è‡´ç»“æœå˜å¾—æ›´ç³Ÿã€‚å› æ­¤ï¼Œä½ éœ€è¦ä¸€ç§åŸºäºè·ç¦»çš„ç‰¹æ®Šå¯¹é½æŸå¤±ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰è¿™ä¸ªé”™è¯¯ã€‚
- en: And so making this alignment loss work on you know PUs and making a different
    shable is I think the real meat of this paper and so again go back to the paper
    if you're interested in that kind of topicã€‚I think that's really coolã€‚But at a
    very high level how well does this model work so if you look at the final output
    you have the read name you have the base predictions and also the predicted quality
    which can be thought of as a confidence score and these base predictions are often
    quite long and so you can see that continuous off screen because it's like you
    10 k to electronick basis long over hereã€‚
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œè®©è¿™ä¸ªå¯¹é½æŸå¤±åœ¨å¤„ç†PUsæ—¶æœ‰æ•ˆï¼Œå¹¶åˆ¶é€ å‡ºä¸åŒçš„shableï¼Œæˆ‘è®¤ä¸ºè¿™æ˜¯æœ¬æ–‡çš„æ ¸å¿ƒå†…å®¹ï¼Œæ‰€ä»¥å¦‚æœä½ å¯¹è¿™ç±»ä¸»é¢˜æ„Ÿå…´è¶£ï¼Œå†æ¬¡å›åˆ°è®ºæ–‡ä¸­æŸ¥çœ‹ã€‚æˆ‘è§‰å¾—è¿™çœŸçš„å¾ˆé…·ã€‚ä½†æ˜¯ä»ä¸€ä¸ªå¾ˆé«˜çš„å±‚é¢æ¥çœ‹ï¼Œè¿™ä¸ªæ¨¡å‹çš„æ•ˆæœå¦‚ä½•å‘¢ï¼Ÿå¦‚æœä½ æŸ¥çœ‹æœ€ç»ˆè¾“å‡ºï¼Œä½ ä¼šçœ‹åˆ°è¯»å–åç§°ã€ç¢±åŸºé¢„æµ‹ï¼Œä»¥åŠå¯ä»¥è§†ä¸ºç½®ä¿¡åº¦åˆ†æ•°çš„é¢„æµ‹è´¨é‡ï¼Œè€Œè¿™äº›ç¢±åŸºé¢„æµ‹é€šå¸¸ç›¸å½“é•¿ï¼Œæ‰€ä»¥ä½ å¯ä»¥çœ‹åˆ°é‚£æŒç»­åœ¨å±å¹•å¤–ï¼Œå› ä¸ºè¿™é‡Œçš„ç”µå­åŸºç¡€å¤§çº¦æ˜¯10kã€‚
- en: And when you look at the qualityï¼Œ it improved quite a bit over the vanilla CCS
    algorithm over hereã€‚the per read accuracy over here improved quite a bitã€‚And so
    you may ask like what is the real world impact of this kind of model right so
    the answer is this model is already being used in the real world so at Stanford
    in the genomic stream by Drã€‚Ashley and a few others there was this recent ultra
    rapid nanopogen sequencing paper where they set a world record for the fastest
    genome sequencing and this deep consensus transformer architecture was used in
    that SM sequence and so in this particular study they were able to very quickly
    diagnose that Matthew over here had a heart condition due to a genetic reasons
    and so they were very quickly able to like put Matthew on the patient' donors
    list over here so that's a kind of real world impact we can have with these biomedical
    transform models and AI systems in generalã€‚
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä½ è§‚å¯Ÿè´¨é‡æ—¶ï¼Œå‘ç°å®ƒæ¯”è¿™é‡Œçš„æ™®é€š CCS ç®—æ³•æœ‰äº†ç›¸å½“å¤§çš„æ”¹å–„ã€‚æ¯æ¬¡è¯»å–çš„å‡†ç¡®æ€§åœ¨è¿™é‡Œæé«˜äº†å¾ˆå¤šã€‚å› æ­¤ï¼Œä½ å¯èƒ½ä¼šé—®è¿™ç§æ¨¡å‹åœ¨ç°å®ä¸–ç•Œä¸­çš„å®é™…å½±å“æ˜¯ä»€ä¹ˆï¼Ÿç­”æ¡ˆæ˜¯ï¼Œè¿™ç§æ¨¡å‹å·²ç»åœ¨ç°å®ä¸–ç•Œä¸­è¢«ä½¿ç”¨ï¼Œä¾‹å¦‚åœ¨æ–¯å¦ç¦å¤§å­¦ï¼Œç”±è‰¾ä»€åˆ©åšå£«å’Œå…¶ä»–å‡ ä½ç ”ç©¶äººå‘˜è¿›è¡Œçš„åŸºå› ç»„ç ”ç©¶ä¸­ï¼Œæœ€è¿‘æœ‰ä¸€ç¯‡è¶…å¿«é€Ÿçº³ç±³æµ‹åºçš„è®ºæ–‡ï¼Œä»–ä»¬åˆ›ä¸‹äº†æœ€å¿«åŸºå› ç»„æµ‹åºçš„ä¸–ç•Œçºªå½•ï¼Œè€Œè¿™ç§æ·±åº¦å…±è¯†å˜æ¢å™¨æ¶æ„åœ¨é‚£æ¬¡
    SM æµ‹åºä¸­å¾—åˆ°äº†åº”ç”¨ã€‚åœ¨è¿™é¡¹ç‰¹å®šç ”ç©¶ä¸­ï¼Œä»–ä»¬èƒ½å¤Ÿéå¸¸è¿…é€Ÿåœ°è¯Šæ–­å‡ºè¿™é‡Œçš„é©¬ä¿®å› é—ä¼ åŸå› æœ‰å¿ƒè„ç–¾ç—…ï¼Œå› æ­¤ä»–ä»¬èƒ½å¤Ÿè¿…é€Ÿåœ°å°†é©¬ä¿®åˆ—å…¥æ‚£è€…ä¾›ä½“åå•ã€‚è¿™å°±æ˜¯æˆ‘ä»¬å¯ä»¥é€šè¿‡è¿™äº›ç”Ÿç‰©åŒ»å­¦å˜æ¢æ¨¡å‹å’Œ
    AI ç³»ç»Ÿåœ¨ç°å®ä¸–ç•Œä¸­äº§ç”Ÿçš„å½±å“ã€‚
- en: And very quicklyï¼Œ the last paper that I want to talk about is this paper from
    Deep Mind on effective gene expression prediction from sequences by integrating
    long range interactions this was published in nature methodsã€‚And the motivation
    for this work is again that since the human genome Project there have been thousands
    of genome by association style hits where the goal is to you know map genetic
    variants to different kind of disease phenotypes but a lot of this involves experimentation
    and experimentation like real experiment patient takes a lot of time and so if
    we can like do that with machine learning models that's really and so that's what
    they set out to do in this paper andã€‚
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: So if you look at the gene itselfï¼Œ there are likeï¼Œ you knowã€‚10% of the gene
    are going to be like coding variants and these influence protein functionã€‚And
    then the way they can cause diseases is by disrupting the structure of proteins
    that are generated or by affecting the protein protein interactionsã€‚The good part
    about these coding variants are they tend to be closer to the gene and so they're
    easier to interpret on the other hand the 90% of the gene is like noncoding variants
    and the way they work is they influence protein expression so they are more like
    regulatory sequences and so the way they can lead to diseases if they have any
    variants is by disrupting the transcription of proteinsã€‚
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å¦‚æœä½ çœ‹åŸºå› æœ¬èº«ï¼Œåƒæ˜¯ï¼ŒçŸ¥é“çš„ã€‚10%çš„åŸºå› æ˜¯ç¼–ç å˜å¼‚ï¼Œè¿™äº›å˜å¼‚ä¼šå½±å“è›‹ç™½è´¨åŠŸèƒ½ã€‚ç„¶åå®ƒä»¬å¯¼è‡´ç–¾ç—…çš„æ–¹å¼æ˜¯é€šè¿‡ç ´åç”Ÿæˆçš„è›‹ç™½è´¨çš„ç»“æ„æˆ–è€…å½±å“è›‹ç™½è´¨ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚è¿™äº›ç¼–ç å˜å¼‚çš„å¥½å¤„åœ¨äºå®ƒä»¬é€šå¸¸æ›´é è¿‘åŸºå› ï¼Œå› æ­¤æ›´å®¹æ˜“è§£é‡Šï¼›å¦ä¸€æ–¹é¢ï¼Œ90%çš„åŸºå› æ˜¯éç¼–ç å˜å¼‚ï¼Œå®ƒä»¬çš„ä½œç”¨æ˜¯å½±å“è›‹ç™½è´¨çš„è¡¨è¾¾ï¼Œå› æ­¤æ›´åƒæ˜¯è°ƒæ§åºåˆ—ã€‚å¦‚æœå®ƒä»¬æœ‰ä»»ä½•å˜å¼‚ï¼Œå®ƒä»¬å¯¼è‡´ç–¾ç—…çš„æ–¹å¼æ˜¯é€šè¿‡å¹²æ‰°è›‹ç™½è´¨çš„è½¬å½•ã€‚
- en: And given that these noncoding variants can be veryã€‚very far away from the gene
    and the coding variantsã€‚it's very difficult to interpret them and so the question
    is can we train transform models that can predict the influence of these noncoding
    variants and so that is the task over here and so this is a visualization again
    so the paper again looks at it focuses on transcription which is the first step
    in terms of converting DNA into RNA and the way this is done is you have RNA polymerase
    which gets recruited at the beginning of the gene by these proteins called transcription
    factors and these transcription factors are a binding side which correspond to
    these promoters which are quite close to the gene but then you also have these
    enhances which can be like very very far away from these promoters in terms of
    the linear space also influencing this transcription and you may ask how can suchã€‚
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œè€ƒè™‘åˆ°è¿™äº›éç¼–ç å˜ä½“å¯èƒ½ç¦»åŸºå› å’Œç¼–ç å˜ä½“éå¸¸è¿œï¼Œå› æ­¤å¾ˆéš¾å¯¹å®ƒä»¬è¿›è¡Œè§£è¯»ï¼Œé—®é¢˜åœ¨äºæˆ‘ä»¬èƒ½å¦è®­ç»ƒå˜æ¢æ¨¡å‹æ¥é¢„æµ‹è¿™äº›éç¼–ç å˜ä½“çš„å½±å“ï¼Œè¿™å°±æ˜¯è¿™é‡Œçš„ä»»åŠ¡ã€‚è¿™æ˜¯ä¸€ä¸ªå¯è§†åŒ–ï¼Œå†æ¬¡è¯´æ˜ï¼Œè®ºæ–‡å…³æ³¨äºè½¬å½•ï¼Œè¿™æ˜¯å°†DNAè½¬åŒ–ä¸ºRNAçš„ç¬¬ä¸€æ­¥ã€‚å®ç°è¿™ä¸€ç‚¹çš„æ–¹æ³•æ˜¯RNAèšåˆé…¶åœ¨åŸºå› çš„èµ·å§‹ä½ç½®è¢«ç§°ä¸ºè½¬å½•å› å­çš„è›‹ç™½è´¨æ‹›å‹Ÿï¼Œè¿™äº›è½¬å½•å› å­å¯¹åº”äºé è¿‘åŸºå› çš„å¯åŠ¨å­ã€‚è€Œè¿™äº›å¢å¼ºå­å¯èƒ½åœ¨è¿™äº›å¯åŠ¨å­å’Œçº¿æ€§ç©ºé—´ä¸­éå¸¸è¿œï¼Œä¹Ÿä¼šå½±å“è½¬å½•ã€‚ä½ å¯èƒ½ä¼šé—®ï¼Œæ€ä¹ˆä¼šæœ‰è¿™æ ·çš„æƒ…å†µã€‚
- en: How can these enhances influence the activity over hereã€‚this is because while
    they may be far away in the linear space when the sequence falls and in the 3D
    structure they will end up being quite close to each other and so that they can
    completely affect the transcription process over hereã€‚
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å¢å¼ºå¦‚ä½•å½±å“è¿™é‡Œçš„æ´»åŠ¨ã€‚è¿™æ˜¯å› ä¸ºè™½ç„¶å®ƒä»¬åœ¨ä¸€ç»´ç©ºé—´ä¸­å¯èƒ½ç›¸è·è¾ƒè¿œï¼Œä½†åœ¨ä¸‰ç»´ç»“æ„ä¸­ï¼Œå®ƒä»¬æœ€ç»ˆä¼šéå¸¸æ¥è¿‘ï¼Œä»è€Œå®Œå…¨å½±å“è¿™é‡Œçš„è½¬å½•è¿‡ç¨‹ã€‚
- en: So it's a very high level overview of what's happening over here and in terms
    of the biology and so the question is if there are any variants in these noncoding
    variants and in these enhances they may like disrupt the transcription factor
    binding and this can internal turn lead to like you know no proteins and then
    finally to diseases right so we want to be able to predict that based on the DNA
    sequences that have been generatedã€‚
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™æ˜¯å¯¹è¿™é‡Œå‘ç”Ÿçš„äº‹æƒ…ä»¥åŠç”Ÿç‰©å­¦æ–¹é¢çš„ä¸€ä¸ªéå¸¸é«˜å±‚æ¬¡çš„æ¦‚è¿°ã€‚é‚£ä¹ˆé—®é¢˜æ˜¯ï¼Œè¿™äº›éç¼–ç å˜å¼‚å’Œå¢å¼ºå­ä¸­æ˜¯å¦å­˜åœ¨ä»»ä½•å˜å¼‚ï¼Œå®ƒä»¬å¯èƒ½ä¼šå¹²æ‰°è½¬å½•å› å­çš„ç»“åˆï¼Œè¿™æœ€ç»ˆå¯èƒ½å¯¼è‡´æ²¡æœ‰è›‹ç™½è´¨ï¼Œæœ€ç»ˆå¯¼è‡´ç–¾ç—…ï¼Œå¯¹å§ï¼Ÿæ‰€ä»¥æˆ‘ä»¬å¸Œæœ›èƒ½å¤ŸåŸºäºç”Ÿæˆçš„DNAåºåˆ—æ¥é¢„æµ‹è¿™ä¸€ç‚¹ã€‚
- en: So the problem is kind of quite straightforwardï¼Œ it's a supervised learning
    problemã€‚the setup is predict experimental data from these DNA sequences and this
    can take many different formsã€‚the primary one is gene expression over hereï¼Œ but
    then there are also other tasks such as DNA accessibilityã€‚histone modifications
    and transcription factor binding and so on and so forthã€‚
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥é—®é¢˜å…¶å®ç›¸å½“ç®€å•ï¼Œè¿™æ˜¯ä¸€ç§ç›‘ç£å­¦ä¹ é—®é¢˜ã€‚è®¾ç½®æ˜¯ä»è¿™äº›DNAåºåˆ—ä¸­é¢„æµ‹å®éªŒæ•°æ®ï¼Œè¿™å¯ä»¥æœ‰å¾ˆå¤šä¸åŒçš„å½¢å¼ã€‚ä¸»è¦çš„æ˜¯è¿™é‡Œçš„åŸºå› è¡¨è¾¾ï¼Œä½†ä¹Ÿæœ‰å…¶ä»–ä»»åŠ¡ï¼Œå¦‚DNAå¯åŠæ€§ã€ç»„è›‹ç™½ä¿®é¥°å’Œè½¬å½•å› å­ç»“åˆç­‰ç­‰ã€‚
- en: So as you can imagine the baseline model for this task for many years was the
    CNN model and as you stack up a little different CNNL layers you can increase
    the receptive field but there's a limit to that so in this work what they showed
    was you can use transformers instead and do better modeling of these long interactions
    so the final model is called Ener which is a combination of this enhancer and
    transformer and so if you look at the model itself it has a few CNN layers at
    the beginning but then it has a bunch of transformer blocks that are stacked togetherã€‚
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæ­£å¦‚ä½ æ‰€æƒ³ï¼Œè¿™é¡¹ä»»åŠ¡å¤šå¹´æ¥çš„åŸºç¡€æ¨¡å‹æ˜¯CNNæ¨¡å‹ï¼Œéšç€ä½ å †å ä¸€äº›ä¸åŒçš„CNNå±‚ï¼Œä½ å¯ä»¥å¢åŠ æ„Ÿå—é‡ï¼Œä½†è¿™æœ‰å…¶é™åˆ¶ã€‚å› æ­¤ï¼Œåœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œä»–ä»¬å±•ç¤ºäº†å¯ä»¥ä½¿ç”¨å˜æ¢å™¨æ¥æ›´å¥½åœ°å»ºæ¨¡è¿™äº›é•¿æ—¶é—´äº¤äº’ï¼Œå› æ­¤æœ€ç»ˆæ¨¡å‹è¢«ç§°ä¸ºEnerï¼Œå®ƒæ˜¯è¿™ç§å¢å¼ºå™¨å’Œå˜æ¢å™¨çš„ç»“åˆã€‚å¦‚æœä½ æŸ¥çœ‹æ¨¡å‹æœ¬èº«ï¼Œå®ƒåœ¨å¼€å§‹æ—¶æœ‰ä¸€äº›CNNå±‚ï¼Œä½†éšåæœ‰ä¸€å †å †å åœ¨ä¸€èµ·çš„å˜æ¢å™¨å—ã€‚
- en: And the input is 200 KB DNA sequences and there are approximately 30k examples
    that have been trained and the output is like genomic tracks of this RNA expression
    withã€‚and they have organism specific headsï¼Œ so one for humans and one for mouseã€‚And
    finally one key detail is that relative position encodings that were used in this
    model were actually very key and these relative position encoings were modeling
    this power law of interactions and as a result of you know using these relative
    position encodings with the transformer block architectureã€‚
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å…¥æ˜¯200 KBçš„DNAåºåˆ—ï¼Œè®­ç»ƒäº†å¤§çº¦30kä¸ªç¤ºä¾‹ï¼Œè¾“å‡ºç±»ä¼¼äºè¿™ç§RNAè¡¨è¾¾çš„åŸºå› ç»„è½¨è¿¹ã€‚å¹¶ä¸”å®ƒä»¬æœ‰ç‰¹å®šäºç”Ÿç‰©çš„å¤´éƒ¨ï¼Œäººç±»ä¸€ä¸ªï¼Œå°é¼ ä¸€ä¸ªã€‚æœ€åä¸€ä¸ªå…³é”®ç»†èŠ‚æ˜¯ï¼Œè¿™ä¸ªæ¨¡å‹ä¸­ä½¿ç”¨çš„ç›¸å¯¹ä½ç½®ç¼–ç å®é™…ä¸Šéå¸¸é‡è¦ï¼Œè¿™äº›ç›¸å¯¹ä½ç½®ç¼–ç åœ¨å»ºæ¨¡äº¤äº’çš„å¹‚å¾‹æ–¹é¢èµ·åˆ°äº†ä½œç”¨ï¼Œå› æ­¤åœ¨ä½¿ç”¨è¿™äº›ç›¸å¯¹ä½ç½®ç¼–ç ä¸å˜æ¢å™¨å—æ¶æ„æ—¶ã€‚
- en: they were now able to model like interactions over 100 k based byes awayã€‚And
    so you see that in the results over hereï¼Œ so you have the experimental data in
    green and you can see the CNN baseline over here and you see that as soon as you
    go far away you see that the CNN model is no longer able to capture these gene
    expressionsã€‚
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: ä»–ä»¬ç°åœ¨èƒ½å¤Ÿå¯¹è¶…è¿‡100kåŸºå› çš„ç›¸äº’ä½œç”¨è¿›è¡Œå»ºæ¨¡ã€‚å› æ­¤ä½ å¯ä»¥åœ¨è¿™é‡Œçœ‹åˆ°ç»“æœï¼Œå®éªŒæ•°æ®ä»¥ç»¿è‰²æ˜¾ç¤ºï¼Œä½ å¯ä»¥çœ‹åˆ°CNNåŸºçº¿åœ¨è¿™é‡Œï¼Œä¸€æ—¦è¿œç¦»ï¼Œä½ ä¼šå‘ç°CNNæ¨¡å‹æ— æ³•å†æ•æ‰è¿™äº›åŸºå› è¡¨è¾¾ã€‚
- en: but you can see that the enhancer model is now able to like pick them up so
    you can see that as the model goes far awayã€‚the enhancer model is able to capture
    this whereas CNN model is no longer able to capture thisã€‚And finallyï¼Œ oneã€‚I think
    very interesting experiment that they had in the paper was they were also able
    to like you know predict promoter enhancer influences and that prediction was
    actually on par with experimented data so this suggests that using this machine
    learning model we can sidestep a lot of these wet lab experiments and get like
    key detailsã€‚
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯ä½ å¯ä»¥çœ‹åˆ°å¢å¼ºæ¨¡å‹ç°åœ¨èƒ½å¤Ÿåƒæ˜¯æ‹¾èµ·å®ƒä»¬ä¸€æ ·ï¼Œæ‰€ä»¥ä½ å¯ä»¥çœ‹åˆ°éšç€æ¨¡å‹çš„è¿œç¦»ï¼Œå¢å¼ºæ¨¡å‹èƒ½å¤Ÿæ•æ‰åˆ°è¿™ä¸€ç‚¹ï¼Œè€Œ CNN æ¨¡å‹åˆ™æ— æ³•å†æ•æ‰åˆ°è¿™ä¸€ç‚¹ã€‚æœ€åï¼Œæˆ‘è®¤ä¸ºä»–ä»¬åœ¨è®ºæ–‡ä¸­è¿›è¡Œçš„ä¸€ä¸ªéå¸¸æœ‰è¶£çš„å®éªŒæ˜¯ï¼Œä»–ä»¬ä¹Ÿèƒ½å¤Ÿé¢„æµ‹å¯åŠ¨å­-å¢å¼ºå­å½±å“ï¼Œè€Œè¿™ç§é¢„æµ‹å®é™…ä¸Šä¸å®éªŒæ•°æ®ç›¸å½“ï¼Œæ‰€ä»¥è¿™è¡¨æ˜ä½¿ç”¨è¿™ä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹æˆ‘ä»¬å¯ä»¥ç»•è¿‡è®¸å¤šæ¹¿å®éªŒï¼Œå¹¶è·å¾—å…³é”®ç»†èŠ‚ã€‚
- en: which could be super usefulã€‚So yeahï¼Œ so very quicklyã€‚I'm sorry I had to like
    cram through proteins and genomics applications over hereã€‚but I think what you
    would see is that overall when you look at clinical proteins and genomic applicationsã€‚we
    see that transformers have incredible potential in biomedicineã€‚And with clinical
    applicationsã€‚
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯èƒ½éå¸¸æœ‰ç”¨ã€‚æ‰€ä»¥æ˜¯çš„ï¼Œéå¸¸å¿«ã€‚æˆ‘å¾ˆæŠ±æ­‰æˆ‘å¿…é¡»åœ¨è¿™é‡ŒåŒ†å¿™è®²è§£è›‹ç™½è´¨å’ŒåŸºå› ç»„åº”ç”¨ã€‚ä½†æˆ‘è®¤ä¸ºæ€»ä½“æ¥çœ‹ï¼Œå½“ä½ è§‚å¯Ÿä¸´åºŠè›‹ç™½è´¨å’ŒåŸºå› ç»„åº”ç”¨æ—¶ï¼Œæˆ‘ä»¬çœ‹åˆ°å˜å‹å™¨åœ¨ç”Ÿç‰©åŒ»å­¦ä¸­å…·æœ‰å·¨å¤§çš„æ½œåŠ›ï¼Œå¹¶ä¸”åœ¨ä¸´åºŠåº”ç”¨ä¸­ã€‚
- en: I think the challenges are perhaps more centered around data and evaluationã€‚but
    on the proteins and genomics sideï¼Œ I think there are some extremely interesting
    opportunities to innovate on the architecture hereã€‚And finally as I saidï¼Œ there
    are incredible bidirectional learning opportunitiesã€‚I think the problem of you
    know modeling long range interactions that's useful beyond proteins beyond genomicsã€‚
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºæŒ‘æˆ˜å¯èƒ½æ›´é›†ä¸­åœ¨æ•°æ®å’Œè¯„ä¼°æ–¹é¢ã€‚ä½†åœ¨è›‹ç™½è´¨å’ŒåŸºå› ç»„å­¦æ–¹é¢ï¼Œæˆ‘è®¤ä¸ºåœ¨è¿™é‡Œæœ‰ä¸€äº›æå…¶æœ‰è¶£çš„åˆ›æ–°æœºä¼šã€‚æœ€åï¼Œæ­£å¦‚æˆ‘æ‰€è¯´ï¼Œè¿™é‡Œæœ‰ä»¤äººéš¾ä»¥ç½®ä¿¡çš„åŒå‘å­¦ä¹ æœºä¼šã€‚æˆ‘è®¤ä¸ºå»ºæ¨¡é•¿ç¨‹ç›¸äº’ä½œç”¨çš„é—®é¢˜ä¸ä»…åœ¨è›‹ç™½è´¨å’ŒåŸºå› ç»„å­¦é¢†åŸŸæœ‰ç”¨ã€‚
- en: I think it's useful in genomics and so I think any architecture improvement
    over here can inspire wider progress in AI so I think that's a big reason to work
    on thisã€‚å—¯ã€‚Any questions so farï¼ŸSorryï¼Œ I covered a lot of ground over hereï¼Œ apologies
    for thatã€‚
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºè¿™åœ¨åŸºå› ç»„å­¦ä¸­æ˜¯æœ‰ç”¨çš„ï¼Œå› æ­¤æˆ‘è®¤ä¸ºè¿™é‡Œçš„ä»»ä½•æ¶æ„æ”¹è¿›éƒ½èƒ½æ¿€åŠ±AIçš„æ›´å¹¿æ³›è¿›æ­¥ï¼Œè¿™ä¹Ÿæ˜¯æˆ‘è®¤ä¸ºè¦è‡´åŠ›äºæ­¤çš„ä¸€ä¸ªé‡è¦åŸå› ã€‚å—¯ã€‚åˆ°ç›®å‰ä¸ºæ­¢æœ‰ä»€ä¹ˆé—®é¢˜å—ï¼ŸæŠ±æ­‰ï¼Œæˆ‘è®²äº†å¾ˆå¤šå†…å®¹ï¼Œå¯¹æ­¤è¡¨ç¤ºæ­‰æ„ã€‚
- en: but I think these are super cool papers and you should go back and read themã€‚mSo
    quite finallyã€‚I want to maybe spend a couple of minutes touch upon how I see the
    future of biomedical AI evolvingã€‚Overallï¼Œ I believe it's not a question ofã€‚Like
    if AI will transform biomedicineã€‚I think it's rather a question of when and howã€‚And
    I think the very specific thesis I have over here is given the nature of biomedical
    data and how multimodal in nature and with all the progress in transformers self
    learning large language modelsã€‚
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘è®¤ä¸ºè¿™äº›è®ºæ–‡éå¸¸é…·ï¼Œä½ åº”è¯¥å›å»é˜…è¯»å®ƒä»¬ã€‚æœ€ç»ˆï¼Œæˆ‘æƒ³èŠ±å‡ åˆ†é’Ÿè°ˆè°ˆæˆ‘å¯¹ç”Ÿç‰©åŒ»å­¦äººå·¥æ™ºèƒ½æœªæ¥å‘å±•çš„çœ‹æ³•ã€‚æ€»ä½“æ¥è¯´ï¼Œæˆ‘ç›¸ä¿¡è¿™ä¸æ˜¯ä¸€ä¸ªå…³äºäººå·¥æ™ºèƒ½æ˜¯å¦ä¼šæ”¹å˜ç”Ÿç‰©åŒ»å­¦çš„é—®é¢˜ã€‚æˆ‘è®¤ä¸ºè¿™æ›´æ˜¯ä¸€ä¸ªå…³äºä½•æ—¶ä»¥åŠå¦‚ä½•çš„é—®é¢˜ã€‚æˆ‘çš„å…·ä½“è§‚ç‚¹æ˜¯ï¼Œé‰´äºç”Ÿç‰©åŒ»å­¦æ•°æ®çš„æ€§è´¨åŠå…¶å¤šæ¨¡æ€ç‰¹å¾ï¼Œä»¥åŠåœ¨è‡ªæˆ‘å­¦ä¹ å¤§å‹è¯­è¨€æ¨¡å‹æ–¹é¢çš„æ‰€æœ‰è¿›å±•ã€‚
- en: I think we have an incredibly powerful like framework to like leverage all this
    richness at scale and like truly build foundational medical AI modelsã€‚So I think
    that is incredibly excitingã€‚Andã€‚So I'm not I think it's you've already been in
    Hawaiias for far too longã€‚
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºæˆ‘ä»¬æ‹¥æœ‰ä¸€ä¸ªæå…¶å¼ºå¤§çš„æ¡†æ¶ï¼Œå¯ä»¥å……åˆ†åˆ©ç”¨è¿™ä¸€åˆ‡ä¸°å¯Œæ€§ï¼Œå¹¶çœŸæ­£æ„å»ºåŸºç¡€çš„åŒ»ç–— AI æ¨¡å‹ã€‚å› æ­¤ï¼Œæˆ‘è®¤ä¸ºè¿™éå¸¸ä»¤äººå…´å¥‹ã€‚è€Œä¸”ã€‚æ‰€ä»¥æˆ‘è®¤ä¸ºä½ åœ¨å¤å¨å¤·å¾…å¾—å¤ªä¹…äº†ã€‚
- en: so I'm not going to ask you to recognize these peopleã€‚but they're actually famous
    physician science centers some of them went on to win Nobel prizezes and soã€‚I
    think what I want to say over here is there's no reason for a scientist to be
    different from a physician they can be combined together and that's what also
    want to like convey with our AI systems as well we don't have to like separate
    clinical applications and biological applicationsã€‚
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä¸ä¼šè¦æ±‚ä½ è®¤è¯†è¿™äº›äººã€‚ä½†ä»–ä»¬å®é™…ä¸Šæ˜¯è‘—åçš„åŒ»å­¦ç§‘å­¦ä¸­å¿ƒï¼Œå…¶ä¸­ä¸€äº›è¿˜è·å¾—äº†è¯ºè´å°”å¥–ã€‚æˆ‘æƒ³åœ¨è¿™é‡Œè¯´çš„æ˜¯ï¼Œç§‘å­¦å®¶å’ŒåŒ»ç”Ÿæ²¡æœ‰ç†ç”±æ˜¯ä¸åŒçš„ï¼Œä»–ä»¬å¯ä»¥ç»“åˆåœ¨ä¸€èµ·ã€‚è¿™ä¹Ÿæ˜¯æˆ‘æƒ³é€šè¿‡æˆ‘ä»¬çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿä¼ è¾¾çš„ï¼Œæˆ‘ä»¬ä¸å¿…å°†ä¸´åºŠåº”ç”¨å’Œç”Ÿç‰©åº”ç”¨åˆ†å¼€ã€‚
- en: I think when we combine them together we are going to discover a lot of new
    insights and I think that's going to accelerate biomedical research and internally
    to new discoveries and which is going to like you know be used to eradicate diseasesã€‚advanced
    human health plan and generally drive human potential forwardã€‚
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºå½“æˆ‘ä»¬å°†å®ƒä»¬ç»“åˆåœ¨ä¸€èµ·æ—¶ï¼Œæˆ‘ä»¬å°†ä¼šå‘ç°è®¸å¤šæ–°çš„è§è§£ï¼Œæˆ‘è®¤ä¸ºè¿™å°†åŠ é€Ÿç”Ÿç‰©åŒ»å­¦ç ”ç©¶å¹¶æ¨åŠ¨æ–°çš„å‘ç°ï¼Œè¿™å°†ç”¨äºæ¶ˆç­ç–¾ç—…ã€‚æ¨åŠ¨å…ˆè¿›çš„äººç±»å¥åº·è®¡åˆ’ï¼Œå¹¶æ•´ä½“ä¸Šæ¨åŠ¨äººç±»æ½œèƒ½å‘å‰å‘å±•ã€‚
- en: So question I actually know these three areã€‚Sureï¼Œ I think the right most one
    is Alexander Fleming and then Jonas Sak and then Paula Liickã€‚So fleming is penicillinï¼Œ
    saltï¼Œ Capooï¼Œ and Elich was a bunch of different stuffã€‚Andã€‚And so maybe I ask this
    question to all of youï¼Œ which field of AI do you think will which field do you
    think AI will win the first Nobel Priingï¼Ÿ
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘å®é™…ä¸ŠçŸ¥é“è¿™ä¸‰ä½æ˜¯è°ã€‚æ²¡é”™ï¼Œæˆ‘è®¤ä¸ºæœ€å³è¾¹çš„æ˜¯**äºšå†å±±å¤§Â·å¼—è±æ˜**ï¼Œç„¶åæ˜¯**ä¹”çº³æ–¯Â·ç´¢å°”å…‹**ï¼Œæ¥ç€æ˜¯**ä¿æ‹‰Â·é‡Œå…‹**ã€‚æ‰€ä»¥å¼—è±æ˜æ˜¯é’éœ‰ç´ ï¼Œç›ï¼ŒCapooï¼Œè‰¾åˆ©å¸Œåˆ™æ¶‰åŠè®¸å¤šä¸åŒçš„ä¸œè¥¿ã€‚ç„¶åï¼Œæˆ‘æƒ³é—®ä½ ä»¬ä¸€ä¸ªé—®é¢˜ï¼Œå“ªä¸€ä¸ªé¢†åŸŸçš„äººå·¥æ™ºèƒ½ä½ è®¤ä¸ºä¼šé¦–å…ˆèµ¢å¾—è¯ºè´å°”å¥–ï¼Ÿ
- en: You're an not goingã€‚å—¯ã€‚I mean think but likeã€‚Satan noble noble was like it's
    not a real field I these people abroadã€‚I think economics isã€‚it's associated with
    the Noble Foundation no I think was like this is a joke and not worry these people
    and then it's almost like wait wait own economic noble bias what was biology that
    like can have like oh gay render this joke that do cancer or somethingã€‚
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¸æ˜¯åœ¨è¯´ã€‚å—¯ã€‚æˆ‘æ˜¯è¯´æƒ³ï¼Œä½†å°±åƒã€‚æ’’æ—¦çš„è¯ºè´å°”ï¼Œè¯ºè´å°”å°±åƒè¿™ä¸æ˜¯ä¸€ä¸ªçœŸæ­£çš„é¢†åŸŸï¼Œæˆ‘è§‰å¾—è¿™äº›äººå‡ºå›½ã€‚ç»æµå­¦æˆ‘è§‰å¾—æ˜¯ã€‚å®ƒä¸è¯ºè´å°”åŸºé‡‘ä¼šæœ‰å…³ï¼Œä¸ï¼Œæˆ‘è§‰å¾—å°±åƒè¿™æ˜¯ä¸ªç¬‘è¯ï¼Œä¸ç”¨æ‹…å¿ƒè¿™äº›äººï¼Œç„¶åå‡ ä¹å°±åƒç­‰ä¸€ä¸‹ï¼Œè‡ªå·±çš„ç»æµå­¦è¯ºè´å°”åè§ï¼Œç”Ÿç‰©å­¦æ˜¯ä»€ä¹ˆï¼Œåƒæ˜¯å¯ä»¥æœ‰å“¦ï¼Œæç¬‘çš„æ¸²æŸ“è¿™ä¸ªç¬‘è¯ï¼Œç™Œç—‡æˆ–è€…å…¶ä»–ä»€ä¹ˆã€‚
- en: That's right so I also feel the same way and I hope the overwhelming majority
    of you also think that it's going to be in medicine and I'm going to end on that
    note huge thank you to all my collaborators and teammates for most importantly
    allowing me to like ST slides and then also thank you to all of you for like patiently
    listening over here hopefully this was helpfulã€‚
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: æ²¡é”™ï¼Œæˆ‘ä¹Ÿæœ‰åŒæ ·çš„æ„Ÿè§‰ï¼Œæˆ‘å¸Œæœ›ä½ ä»¬ä¸­çš„ç»å¤§å¤šæ•°ä¹Ÿè®¤ä¸ºè¿™å°†ä¼šå‡ºç°åœ¨åŒ»å­¦é¢†åŸŸï¼Œæˆ‘å°†ä»¥æ­¤ä¸ºç»“æŸï¼Œéå¸¸æ„Ÿè°¢æˆ‘çš„æ‰€æœ‰åˆä½œä¼™ä¼´å’Œå›¢é˜Ÿæˆå‘˜ï¼Œæœ€é‡è¦çš„æ˜¯æ„Ÿè°¢ä½ ä»¬è®©æˆ‘åƒä½¿ç”¨STå¹»ç¯ç‰‡ä¸€æ ·ï¼Œæ„Ÿè°¢ä½ ä»¬è€å¿ƒåœ°å€¾å¬ï¼Œå¸Œæœ›è¿™å¯¹ä½ ä»¬æœ‰æ‰€å¸®åŠ©ã€‚
- en: '![](img/867d42af88a583402ff132cc4ae7c3fa_3.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](img/867d42af88a583402ff132cc4ae7c3fa_3.png)'
