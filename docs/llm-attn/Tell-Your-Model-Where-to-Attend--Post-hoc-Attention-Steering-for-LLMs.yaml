- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 19:03:07'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-09-08 19:03:07'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 告诉你的模型关注哪里：LLMs的事后注意力引导
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2311.02262](https://ar5iv.labs.arxiv.org/html/2311.02262)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2311.02262](https://ar5iv.labs.arxiv.org/html/2311.02262)
- en: Qingru Zhang^†,  Chandan Singh^⋄,  Liyuan Liu^⋄,  Xiaodong Liu^⋄,  Bin Yu^‡,
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 张青如^†,  钱丹·辛格^⋄,  刘丽媛^⋄,  刘晓东^⋄,  余彬^‡,
- en: Jianfeng Gao^⋄,  Tuo Zhao^†
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 高剑锋^⋄,  赵拓^†
- en: ^†Georgia Institute of Technology   ^‡University of California, Berkeley   ^⋄Microsoft
    Research
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ^†乔治亚理工学院   ^‡加州大学伯克利分校   ^⋄微软研究院
- en: '{qingru.zhang,tourzhao}@gatech.edu'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '{qingru.zhang,tourzhao}@gatech.edu'
- en: binyu@berkeley.edu
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: binyu@berkeley.edu
- en: '{chansingh,lucliu,xiaodl,jfgao}@microsoft.com Work is done during Qingru Zhang’s
    internship at Microsoft Research.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '{chansingh,lucliu,xiaodl,jfgao}@microsoft.com 这项工作是在张青如在微软研究院实习期间完成的。'
- en: Abstract
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: In human-written articles, we often leverage the subtleties of text style, such
    as bold and italics, to guide the attention of readers. These textual emphases
    are vital for the readers to grasp the conveyed information. When interacting
    with large language models (LLMs), we have a similar need – steering the model
    to pay closer attention to user-specified information, e.g., an instruction. Existing
    methods, however, are constrained to process plain text and do not support such
    a mechanism. This motivates us to introduce PASTA – Post-hoc Attention STeering
    Approach, a method that allows LLMs to read text with user-specified emphasis
    marks. To this end, PASTA identifies a small subset of attention heads and applies
    precise attention reweighting on them, directing the model attention to user-specified
    parts. Like prompting, PASTA is applied at inference time and does not require
    changing any model parameters. Experiments demonstrate that PASTA can substantially
    enhance an LLM’s ability to follow user instructions or integrate new knowledge
    from user inputs, leading to a significant performance improvement on a variety
    of tasks, e.g., an average accuracy improvement of 22% for LLAMA-7B. Our code
    is publicly available at [https://github.com/QingruZhang/PASTA](https://github.com/QingruZhang/PASTA).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在人类撰写的文章中，我们经常利用文本风格的细微差别，例如**粗体**和*斜体*，来引导读者的注意力。这些文本强调对于读者理解传达的信息至关重要。在与大型语言模型（LLMs）交互时，我们也有类似的需求——引导模型更加关注用户指定的信息，例如*指令*。然而，现有的方法仅限于处理纯文本，并不支持这种机制。这促使我们提出PASTA——事后注意力引导方法，这是一种允许LLMs读取带有用户指定强调标记的文本的方法。为此，PASTA识别出一小部分注意力头，并对其进行精确的注意力重新加权，将模型的注意力引导到用户指定的部分。类似于提示，PASTA在推理时应用，不需要改变任何模型参数。实验表明，PASTA可以显著提升LLM遵循用户指令或整合用户输入的新知识的能力，从而在各种任务上显著提高性能，例如，LLAMA-7B的平均准确率提高了22%。我们的代码公开发布在[https://github.com/QingruZhang/PASTA](https://github.com/QingruZhang/PASTA)。
- en: 1 Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: The advent of large language models (LLMs) has marked a significant milestone
    in natural language processing (NLP) and artificial intelligence (AI), showcasing
    exceptional performance across a wide range of tasks (Vaswani et al., [2017](#bib.bib49);
    Brown et al., [2020a](#bib.bib3); OpenAI, [2023](#bib.bib31)). Efforts to further
    refine these models have been relentless, aiming to enable them to process and
    respond to natural and programming languages with human-like expertise (Stiennon
    et al., [2020](#bib.bib45); Yao et al., [2023](#bib.bib57)).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）的出现标志着自然语言处理（NLP）和人工智能（AI）的一个重要里程碑，展示了在各种任务中出色的性能 （Vaswani et al.,
    [2017](#bib.bib49); Brown et al., [2020a](#bib.bib3); OpenAI, [2023](#bib.bib31)）。进一步完善这些模型的努力一直在不断进行，旨在使它们能够以类似人类的专业水平处理和响应自然语言和编程语言 （Stiennon
    et al., [2020](#bib.bib45); Yao et al., [2023](#bib.bib57)）。
- en: Despite their remarkable achievements, LLMs often encounter challenges in understanding
    their contextual inputs during interactions with users (Shen et al., [2023](#bib.bib39);
    Lu et al., [2021](#bib.bib25)). This difficulty becomes particular evident when
    they are presented prompts¹¹1We use prompts to refer to all LLM text inputs, including
    user instructions, and the other background information (which we refer to as
    context). containing extensive background contexts or complex user instructions.
    Lengthy contexts can overwhelm LLMs, as their attention modules, learned from
    data, are unable to fully capture crucial details (Liu et al., [2023](#bib.bib23)).
    Complex instructions can further inhibit the model from focusing on the user’s
    intentions, resulting in undesired outputs (Wei et al., [2022](#bib.bib54)). Additionally,
    for time-sensitive data, such as news articles, there can exist factual knowledge
    within contexts, which contradicts with model prior beliefs induced from outdated
    pre-training. As a result, a model may generate outputs conditioned on its pre-existing
    belief instead of attending to new facts within the contexts (Meng et al., [2022a](#bib.bib26);
    [b](#bib.bib27); Mitchell et al., [2022](#bib.bib29); Hernandez et al., [2023](#bib.bib14)).
    All of these challenges contribute to LLMs struggling to comprehend user intentions.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管取得了显著成就，LLMs在与用户交互时往往遇到理解上下文输入的挑战（Shen et al., [2023](#bib.bib39); Lu et al.,
    [2021](#bib.bib25)）。这种困难在呈现包含大量背景信息或复杂用户指令的提示时尤为明显。冗长的背景信息可能使LLMs感到不知所措，因为它们从数据中学习的注意模块无法完全捕捉关键细节（Liu
    et al., [2023](#bib.bib23)）。复杂的指令还可能进一步阻碍模型关注用户意图，导致生成不符合预期的结果（Wei et al., [2022](#bib.bib54)）。此外，对于时间敏感的数据，如新闻文章，背景中可能存在与模型先前由过时预训练引发的信念相矛盾的事实知识。因此，模型可能会生成基于其已有信念的输出，而不是关注背景中的新事实（Meng
    et al., [2022a](#bib.bib26); [b](#bib.bib27); Mitchell et al., [2022](#bib.bib29);
    Hernandez et al., [2023](#bib.bib14)）。所有这些挑战都导致LLMs难以理解用户意图。
- en: 'Compared to LLMs, human readers rarely struggle to understand the emphases
    of articles and intentions of writers. Writers often leverage a variety of text
    styles, such as bold and italics, to emphasize specific contents. This mechanism
    enables writers to direct and maintain the attention of human readers, ensuring
    that the intended information is accurately captured. In interactions between
    users and LLMs, it is users also need to highlight specific information for the
    model. Consequently, model generation can be effectively biased in accordance
    with user guidance, thus addressing the challenges mentioned earlier. This feature
    is particularly essential when designing user-AI interfaces, and can be frequently
    applied in extensive conversations between users and models. Existing methods,
    however, do not support such a mechanism. LLMs are inherently limited to processing
    plain texts, devoid of any stylistic cues or emphasis markers (Brown et al., [2020b](#bib.bib4);
    Liu et al., [2021](#bib.bib24); Wei et al., [2022](#bib.bib54)). Even when emphasis
    markers are added to prompts, state-of-the-art LLMs often struggle to discern
    weak signals from a couple of marker tokens (See evidence in Section [5.1](#S5.SS1
    "5.1 Main result: PASTA improves model generation ‣ 5 Results ‣ Tell Your Model
    Where to Attend: Post-hoc Attention Steering for LLMs")).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '与大语言模型（LLMs）相比，人类读者很少会难以理解文章的重点和作者的意图。作者通常利用多种文本风格，如**粗体**和*斜体*，来突出特定内容。这种机制使得作者能够引导并保持人类读者的注意力，确保所需信息被准确捕捉。在用户与LLMs的交互中，用户也需要为模型突出特定信息。因此，模型生成可以根据用户的指导进行有效的偏向，从而解决前述挑战。这一特性在设计用户与AI界面时尤其重要，并且可以在用户与模型的广泛对话中频繁应用。然而，现有方法并不支持这种机制。LLMs天生限制于处理纯文本，缺乏任何风格提示或强调标记（Brown
    et al., [2020b](#bib.bib4); Liu et al., [2021](#bib.bib24); Wei et al., [2022](#bib.bib54)）。即便在提示中添加了强调标记，最先进的LLMs通常也难以从几个标记符号中辨别微弱信号（参见第[5.1节](#S5.SS1
    "5.1 Main result: PASTA improves model generation ‣ 5 Results ‣ Tell Your Model
    Where to Attend: Post-hoc Attention Steering for LLMs")中的证据）。'
- en: '![Refer to caption](img/bdf42534f465877119c9ebacc94f3487.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/bdf42534f465877119c9ebacc94f3487.png)'
- en: 'Figure 1: PASTA uses a user-specified part of the input to steer the model
    generation aligning with user intentions. PASTA modifies the attention scores
    generated during inference, by emphasizing the scores generated at token positions
    corresponding to the user-specified part of the context.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：PASTA使用用户指定的输入部分来引导模型生成，与用户意图对齐。PASTA通过强调与用户指定的上下文部分对应的令牌位置生成的分数，来修改推理过程中生成的注意力分数。
- en: 'Motivated by the need to convey user emphasis, we introduce PASTA (Post-hoc
    Attention STeering Approach), a post-hoc method²²2Post-hoc means that our method
    does not update the model weights. that enables users to highlight specific information,
    e.g., an instruction as in Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Tell
    Your Model Where to Attend: Post-hoc Attention Steering for LLMs"), and steer
    models to interpret emphasized texts like human readers. Specifically, PASTA selects
    a small subset of attention heads and applies precise attention reweighting on
    them. As illustrated in Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Tell Your
    Model Where to Attend: Post-hoc Attention Steering for LLMs"), PASTA upweights
    the attention scores of the user-specified tokens while downweighting the other
    tokens at specific attention heads. Our method is inspired by the observation
    that attention modules exhibit various token-attending patterns across different
    heads (Michel et al., [2019](#bib.bib28); Voita et al., [2019](#bib.bib50); Clark
    et al., [2019](#bib.bib6)). These attention patterns can be interpreted as encoding
    diverse semantic or syntactic information, and altering them can substantially
    influence model behaviors (Shi et al., [2023a](#bib.bib40); Hu et al., [2021b](#bib.bib16)).
    Through steering attention modules, PASTA directs the model to pay close attention
    to the user-specified parts and hence generate the desired output aligning with
    the highlighted contents. Notably, PASTA is applied after training and does not
    require changing any model parameters; PASTA only requires access to the attention
    scores of specific heads of an LLM.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 由于需要传达用户的重点，我们引入了PASTA（事后注意力引导方法），这是一种事后方法²²2“事后”意味着我们的方法不会更新模型权重。可以使用户突出特定信息，例如图[1](#S1.F1
    "图 1 ‣ 1 引言 ‣ 告诉你的模型关注哪里：LLM的事后注意力引导")中的指令，并引导模型像人类读者一样解释强调的文本。具体而言，PASTA选择一个小的注意力头子集，并对其进行精确的注意力重新加权。如图[1](#S1.F1
    "图 1 ‣ 1 引言 ‣ 告诉你的模型关注哪里：LLM的事后注意力引导")所示，PASTA在特定注意力头上提升用户指定令牌的注意力分数，同时降低其他令牌的分数。我们的方法受到以下观察的启发：注意力模块在不同的头上表现出各种令牌关注模式（Michel
    et al., [2019](#bib.bib28); Voita et al., [2019](#bib.bib50); Clark et al., [2019](#bib.bib6)）。这些注意力模式可以被解读为编码多样的语义或句法信息，改变它们可以显著影响模型行为（Shi
    et al., [2023a](#bib.bib40); Hu et al., [2021b](#bib.bib16)）。通过引导注意力模块，PASTA使模型更加关注用户指定的部分，从而生成与突出内容一致的期望输出。值得注意的是，PASTA是在训练后应用的，并且不需要更改任何模型参数；PASTA只需要访问LLM中特定头的注意力分数。
- en: Since attention heads can serve different functions (Tenney et al., [2019](#bib.bib47);
    Deb et al., [2023](#bib.bib10)), we introduce an efficient model profiling algorithm
    to identify which heads are effective for steering. Specifically, we subsample
    small training sets from multiple tasks and evaluate the performance of attention
    steering for each individual head across these tasks. PASTA selects the attention
    heads that, when steered, generally improve the multi-task performance. We empirically
    observe that steering these heads not only benefits the existing tasks but also
    enhances the performance on unseen tasks. Notably, the model profiling is performed
    only once for an LLM. The selected attention heads can be regarded as a model-level
    profile, effective for steering the LLM on unseen tasks.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 由于注意力头可以执行不同的功能（Tenney et al., [2019](#bib.bib47); Deb et al., [2023](#bib.bib10)），我们引入了一种高效的模型分析算法，以识别哪些头对于引导是有效的。具体而言，我们从多个任务中子采样小的训练集，并评估每个单独的头在这些任务中的注意力引导性能。PASTA选择那些在引导时通常能提高多任务性能的注意力头。我们通过实证观察到，引导这些头不仅对现有任务有益，还提升了对未见任务的性能。值得注意的是，模型分析仅在LLM上执行一次。选择的注意力头可以视为模型级别的概况，对于引导LLM处理未见任务是有效的。
- en: We conduct experiments on diverse tasks to demonstrate the effectiveness of
    PASTA. Specifically, we evaluate PASTA using GPT-J-6B (Wang & Komatsuzaki, [2021](#bib.bib51))
    and LLAMA-7B (Touvron et al., [2023](#bib.bib48)) on tasks that span complex instructions,
    lengthy contexts, and knowledge conflicts within contexts. The results demonstrate
    that PASTA consistently provides a significant performance improvement over baseline
    prompting strategies. For example, PASTA achieve an average accuracy improvement
    of 22% over few-shot prompting for LLAMA-7B across 4 challenging tasks.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在各种任务上进行实验，以展示 PASTA 的有效性。具体来说，我们使用 GPT-J-6B (Wang & Komatsuzaki, [2021](#bib.bib51))
    和 LLAMA-7B (Touvron et al., [2023](#bib.bib48)) 评估 PASTA，这些任务涉及复杂指令、长上下文以及上下文中的知识冲突。结果表明，PASTA
    在基线提示策略上始终提供显著的性能提升。例如，PASTA 在 4 个具有挑战性的任务中，LLAMA-7B 的平均准确率提高了 22%。
- en: 2 Background
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 背景
- en: Problem description
  id: totrans-24
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 问题描述
- en: In standard LLM prompting, we are given a pre-trained LLM and a text prompt
    $\bm{x}$ to be emphasized.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在标准 LLM 提示中，我们会得到一个预训练的 LLM 和一个需要强调的文本提示 $\bm{x}$。
- en: 'As in the example in Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Tell Your
    Model Where to Attend: Post-hoc Attention Steering for LLMs"), $\bm{x}$ can simply
    be the final instruction Return her occupation in json format. In evaluation datasets,
    we assume that the user-specified part of each example is already provided by
    enclosing at its both ends in some emphasis markers, like ‘$\ast$ by enclosing
    it with the same emphasis markers. $\bm{x}_{g}$ can be specified flexibly. Namely,
    it need not be a continuous span, and can be used to emphasize diverse information.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '如图 [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Tell Your Model Where to Attend:
    Post-hoc Attention Steering for LLMs") 中的示例，$\bm{x}$ 可以简单地是最终指令 Return her occupation
    in json format。在评估数据集中，我们假设每个示例的用户指定部分已经通过在两端用一些强调标记括起来提供，例如‘$\ast$’，通过使用相同的强调标记来括起来。$\bm{x}_{g}$
    可以灵活指定，即它不需要是连续的范围，可以用来强调多样的信息。'
- en: 'Multi-Head Attention. A typical transformer model consists of $L$, MHA of the
    layer $l$ heads: $\text{MHA}^{(l)}\left({\bm{X}}\right)=\text{Concat}(\bm{H}^{(l,1)},...,\bm{H}^{(l,H)})\bm{W}_{o}$
    where'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 多头自注意力。一个典型的变换器模型由 $L$ 层组成，其中第 $l$ 层的 MHA 头为：$\text{MHA}^{(l)}\left({\bm{X}}\right)=\text{Concat}(\bm{H}^{(l,1)},...,\bm{H}^{(l,H)})\bm{W}_{o}$，其中
- en: '|  | $\displaystyle\bm{H}^{(l,h)}={\bm{A}}^{(l,h)}{\bm{V}}=\text{Softmax}\left({\bm{Q}}{\bm{K}}^{\top}/{\sqrt{d_{h}}}\right){\bm{V}}$
    |  | (1) |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\bm{H}^{(l,h)}={\bm{A}}^{(l,h)}{\bm{V}}=\text{Softmax}\left({\bm{Q}}{\bm{K}}^{\top}/{\sqrt{d_{h}}}\right){\bm{V}}$
    |  | (1) |'
- en: where ${\bm{Q}}={\bm{X}}\bm{W}_{q_{h}},{\bm{K}}={\bm{X}}\bm{W}_{k_{h}},{\bm{V}}={\bm{X}}\bm{W}_{v_{h}}$
    are learnable projection matrices of head $h$ is typically set to $d/H$ of the
    $l$.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ${\bm{Q}}={\bm{X}}\bm{W}_{q_{h}},{\bm{K}}={\bm{X}}\bm{W}_{k_{h}},{\bm{V}}={\bm{X}}\bm{W}_{v_{h}}$
    是头 $h$ 的可学习投影矩阵，通常设置为 $d/H$ 的 $l$。
- en: 3 Method
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 方法
- en: 'PASTA (Algorithm [1](#alg1 "Algorithm 1 ‣ 3 Method ‣ Tell Your Model Where
    to Attend: Post-hoc Attention Steering for LLMs")) consists of two components:
    (i) post-hoc attention steering, which emphasizes the user-specified parts of
    the input during inference, see Section [3.1](#S3.SS1 "3.1 Post-hoc Attention
    Steering ‣ 3 Method ‣ Tell Your Model Where to Attend: Post-hoc Attention Steering
    for LLMs") and (ii) multi-task model profiling, which selects the effective attention
    heads for steering, see Section [3.2](#S3.SS2 "3.2 Multi-Task Model Profiling
    ‣ 3 Method ‣ Tell Your Model Where to Attend: Post-hoc Attention Steering for
    LLMs").'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 'PASTA（算法 [1](#alg1 "Algorithm 1 ‣ 3 Method ‣ Tell Your Model Where to Attend:
    Post-hoc Attention Steering for LLMs")）由两个组件组成：（i）后置注意力引导，它在推理过程中强调用户指定的输入部分，见第
    [3.1](#S3.SS1 "3.1 Post-hoc Attention Steering ‣ 3 Method ‣ Tell Your Model Where
    to Attend: Post-hoc Attention Steering for LLMs") 节；（ii）多任务模型分析，它选择有效的注意力头进行引导，见第
    [3.2](#S3.SS2 "3.2 Multi-Task Model Profiling ‣ 3 Method ‣ Tell Your Model Where
    to Attend: Post-hoc Attention Steering for LLMs") 节。'
- en: 'Algorithm 1 PASTA: Post-hoc Attention Steering Approach'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 1 PASTA：后置注意力引导方法
- en: '0:  1:  Input: small training sets $\{\mathcal{D}^{(i)}\}_{i=1}^{m}$, $k$ do3:     for $1\leq
    l\leq L,1\leq h\leq H$ when steering the head $(l,h)$ on $\mathcal{D}^{(i)}$;8:  end for9:  Output:
    The attention head set $\mathcal{H}=\cap_{i=1}^{m}R^{(i)}_{1:k}$, user-underlined
    segments $\mathcal{G}$;2:  Output: the model generations while steering every
    head $(l,h)$ by ([4](#S3.E4 "Equation 4 ‣ 3.1 Post-hoc Attention Steering ‣ 3
    Method ‣ Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs")).'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '0: 1: 输入：小型训练集 $\{\mathcal{D}^{(i)}\}_{i=1}^{m}$, $k$ do 3: for $1\leq l\leq
    L,1\leq h\leq H$ 在 $\mathcal{D}^{(i)}$ 上引导头 $(l,h)$; 8: 结束 for 9: 输出：注意力头集合 $\mathcal{H}=\cap_{i=1}^{m}R^{(i)}_{1:k}$，用户下划线标记的段落
    $\mathcal{G}$; 2: 输出：在引导每个头 $(l,h)$ 时，模型生成（[4](#S3.E4 "方程 4 ‣ 3.1 事后注意力引导 ‣ 3
    方法 ‣ 告诉你的模型关注哪里：LLM的事后注意力引导")）。'
- en: 3.1 Post-hoc Attention Steering
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 事后注意力引导
- en: 'PASTA emphasizes the user-specified input subset by downweighting the attention
    scores of tokens that are not specified by the user. Specifically, given the index
    set of highlighted input spans as $\mathcal{G}$:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: PASTA 通过降低未由用户指定的标记的注意力得分，强调用户指定的输入子集。具体来说，给定高亮输入跨度的索引集为 $\mathcal{G}$：
- en: '|  | $1$2 |  | (4) |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (4) |'
- en: 'where $0\leq\alpha; (b) Paraphrase score (PS) is the same as ES but changes the
    {question} with a set of rephrased questions to assess the generalization'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 评估指标：我们根据（Meng等，[2022a](#bib.bib26)）评估指标：（a）效能评分（ES）是模型具有的情况比例；（b）释义评分（PS）与ES相同，但通过一组改述的问题来评估模型的泛化能力。
- en: '$\bullet$ BiasBios consists of professional biographies of non-famous people,
    originally introduced to investigate gender bias in occupations. Each example
    includes biographical context and a label of target occupation. The first sentence
    mentions the person’s occupation, and subsequent sentences describe the individual’s
    career history but may not be directly related to the prediction, potentially
    distracting the model attention. At the end of the context, we append the question:
    {person} has the occupation of. \faHandORight We emphasize the first sentence,
    as it carries the most information about the occupation.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ BiasBios包含了非名人专业传记，最初用于研究职业中的性别偏见。每个示例包括传记背景和目标职业标签。第一句提到个人的职业，随后的句子描述个人的职业历史，但可能与预测直接相关性不大，可能会分散模型注意力。在背景的末尾，我们附加了问题：{person}的职业是。
    \faHandORight 我们强调第一句，因为它包含了关于职业的最重要信息。
- en: 'Metrics: following (Hernandez et al., [2023](#bib.bib14)), we compute Accuracy
    by checking whether the probability assigned to the target occupation is the highest
    among the 28 candidate occupations.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 指标：根据（Hernandez et al., [2023](#bib.bib14)），我们通过检查目标职业的概率是否在 28 个候选职业中最高来计算准确性。
- en: 'For Pronouns changing, CounterFact, and BiasBios, we additionally measure Fluency
    as the average bi-gram and tri-gram entropy of generations, designed to be low
    for degenerated or repetitive texts (Meng et al., [2022a](#bib.bib26)). We filter
    out any results receiving a fluency below 3.0 (see full results including fluency
    in [Appendix B](#A2 "Appendix B Extended results with fluency ‣ Tell Your Model
    Where to Attend: Post-hoc Attention Steering for LLMs")).'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 对于代词变化、CounterFact 和 BiasBios，我们额外测量流畅度，作为生成文本的平均二元组和三元组熵，设计为对退化或重复文本较低（Meng
    et al., [2022a](#bib.bib26)）。我们过滤掉流畅度低于 3.0 的结果（请参见包括流畅度的完整结果 [附录 B](#A2 "附录 B
    扩展结果 ‣ 告诉你的模型关注点：对 LLM 的后验注意力引导")）。
- en: Baselines.
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基线。
- en: 'We compare PASTA to the following baselines:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将 PASTA 与以下基线进行比较：
- en: $\bullet$ Zero-shot prompting is the most common approach to interact with LLMs,
    in which a user feeds models a prompt containing background context and a user
    instruction or question.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 零-shot 提示是与 LLM 互动的最常见方法，用户向模型提供包含背景上下文和用户指令或问题的提示。
- en: $\bullet$ Marked prompting alters the prompts used in zero-shot prompting by
    surrounding user-specified input spans with emphasis markers, e.g. asterisks,
    as is done in markdown files for emphasis, or quotes, as is done in natural languages.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 标记提示通过在用户指定的输入范围周围添加强调标记（例如，星号，用于 Markdown 文件中的强调，或引号，用于自然语言）来改变零-shot
    提示中使用的提示。
- en: $\bullet$ Few-shot prompting includes demonstrations (example inputs and target
    outputs) at the beginning of the prompt fed to the LLM. Few-shot prompting often
    improves performance in new tasks, but increases the computational cost of inference
    due to the increased prompt length, particularly when demonstrations are lengthy (Dong
    et al., [2023](#bib.bib13)); here we use 3 demonstrations in context.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 少-shot 提示在提供给 LLM 的提示开头包含演示（示例输入和目标输出）。少-shot 提示通常能改善新任务的性能，但由于提示长度增加，推理的计算成本也增加，尤其是当演示内容较长时（Dong
    et al., [2023](#bib.bib13)）；在这里，我们在上下文中使用了 3 个演示。
- en: 'Table 1: Main results of LLAMA-7B to demonstrate that PASTA can improve the
    model ability to (i) follow user instruction (JSON Format and Prons. Changing);
    (ii) interpret contextual information (BiasBios); (iii) resolving knowledge conflicts
    (CounterFact). For all scores, higher is better. The best results are in bold.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：LLAMA-7B 的主要结果，展示了 PASTA 如何提高模型在以下方面的能力：（i）遵循用户指令（JSON 格式和代词变化）；（ii）解读上下文信息（BiasBios）；（iii）解决知识冲突（CounterFact）。所有得分中，分数越高越好。最佳结果用粗体显示。
- en: '|  | Method | JSON Format | Prons. Changing | BiasBios | CounterFact | All
    |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '|  | 方法 | JSON 格式 | 代词变化 | BiasBios | CounterFact | 全部 |'
- en: '|  | F. Acc / P. Acc | Acc / A.Acc | Acc | ES / PS | Ave. |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '|  | F. Acc / P. Acc | Acc / A.Acc | Acc | ES / PS | Ave. |'
- en: '| Prompting | Zero-shot | 60.00 / 54.94 | 71.84 / 66.28 | 87.36 | 58.50 / 52.03
    | 67.29 |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 提示 | 零-shot | 60.00 / 54.94 | 71.84 / 66.28 | 87.36 | 58.50 / 52.03 | 67.29
    |'
- en: '| $\ast$-marked | 18.55 / 12.71 | 39.14 / 35.17 | 90.62 | 57.74 / 50.52 | 49.38
    |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| $\ast$-标记 | 18.55 / 12.71 | 39.14 / 35.17 | 90.62 | 57.74 / 50.52 | 49.38
    |'
- en: '| “”-marked | 4.56 / 4.20 | 20.55 / 18.19 | 89.82 | 58.14 / 51.70 | 42.15 |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| “”-标记 | 4.56 / 4.20 | 20.55 / 18.19 | 89.82 | 58.14 / 51.70 | 42.15 |'
- en: '| Few-shot | 84.85 / 73.58 | 59.06 / 55.27 | 88.79 | 87.45 / 49.82 | 73.45
    |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 少-shot | 84.85 / 73.58 | 59.06 / 55.27 | 88.79 | 87.45 / 49.82 | 73.45 |'
- en: '| PASTA | Task-agnostic | 88.16 / 49.08 | 83.65 / 81.31 | 93.54 | 98.82 / 99.03
    | 85.89 |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| PASTA | 任务无关 | 88.16 / 49.08 | 83.65 / 81.31 | 93.54 | 98.82 / 99.03 | 85.89
    |'
- en: '| Multi-task | 96.64 / 85.09 | 96.42 / 95.84 | 95.28 | 99.60 / 99.57 | 95.46
    |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| 多任务 | 96.64 / 85.09 | 96.42 / 95.84 | 95.28 | 99.60 / 99.57 | 95.46 |'
- en: 'Table 2: Main results of GPT-J to demonstrate that PASTA can improve the model
    ability to (i) follow user instruction (JSON Format and Prons. Changing); (ii)
    interpret contextual information (BiasBios); (iii) resolving knowledge conflicts
    (CounterFact). For all scores, higher is better. The best results are in bold.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：GPT-J 的主要结果，展示了 PASTA 如何提高模型在以下方面的能力：（i）遵循用户指令（JSON 格式和代词变化）；（ii）解读上下文信息（BiasBios）；（iii）解决知识冲突（CounterFact）。所有得分中，分数越高越好。最佳结果用粗体显示。
- en: '|  | Method | JSON Format | Prons. Changing | BiasBios | CounterFact | All
    |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '|  | 方法 | JSON 格式 | 代词变化 | BiasBios | CounterFact | 全部 |'
- en: '|  | F. Acc / P. Acc | Acc / A.Acc | Acc | ES / PS | Ave. |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '|  | F. Acc / P. Acc | Acc / A.Acc | Acc | ES / PS | Ave. |'
- en: '| Prompting | Zero-shot | 28.83 / 25.09 | 39.88 / 36.19 | 72.76 | 42.14 / 42.02
    | 44.96 |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 提示 | 零样本 | 28.83 / 25.09 | 39.88 / 36.19 | 72.76 | 42.14 / 42.02 | 44.96
    |'
- en: '| $\ast$-marked | 4.44 / 4.10 | 41.25 / 37.57 | 74.14 | 44.50 / 45.09 | 40.63
    |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| $\ast$-标记 | 4.44 / 4.10 | 41.25 / 37.57 | 74.14 | 44.50 / 45.09 | 40.63 |'
- en: '| “”-marked | 8.81 / 5.62 | 6.12 / 5.72 | 78.64 | 45.54 / 41.84 | 33.87 |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| “”-标记 | 8.81 / 5.62 | 6.12 / 5.72 | 78.64 | 45.54 / 41.84 | 33.87 |'
- en: '| Few-shot | 84.15 / 72.65 | 35.77 / 32.08 | 72.98 | 68.34 / 38.23 | 59.65
    |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 少样本 | 84.15 / 72.65 | 35.77 / 32.08 | 72.98 | 68.34 / 38.23 | 59.65 |'
- en: '| PASTA | Task-agnostic | 46.68 / 34.71 | 91.62 / 88.60 | 80.84 | 99.54 / 99.57
    | 77.80 |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| PASTA | 任务无关 | 46.68 / 34.71 | 91.62 / 88.60 | 80.84 | 99.54 / 99.57 | 77.80
    |'
- en: '| Multi-task | 91.50 / 18.63 | 92.96 / 91.34 | 94.96 | 98.62 / 98.79 | 85.22
    |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 多任务 | 91.50 / 18.63 | 92.96 / 91.34 | 94.96 | 98.62 / 98.79 | 85.22 |'
- en: PASTA settings
  id: totrans-80
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: PASTA 设置
- en: 'We study PASTA in 2 settings: multi-task and task-agnostic. In the multi-task
    setting, the evaluation task $j$). The multi-task setting improves performance
    but requires labeled training samples for the task which is evaluated, which can
    be difficult to obtain in practice.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在两种设置中研究了 PASTA：多任务和任务无关。在多任务设置中，评估任务 $j$)。多任务设置提高了性能，但需要对评估的任务进行标记的训练样本，这在实践中可能很难获得。
- en: 'Empirically, we find that PASTA is not sensitive to the scaling coefficient
    $\alpha$ from {300, 400, 500} for LLAMA-7B to have the number of steered heads
    $|\mathcal{H}|$, i.e., $k=400$. For GPT-J, we select $k$ as {52, 72, 111, 153}.
    For every task, we split data into train/validation/test sets following (Hernandez
    et al., [2023](#bib.bib14)) (See Appendix [A](#A1 "Appendix A Experimental Details
    ‣ Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs")) and
    select $|\mathcal{H}|$ by cross validation. For all tasks, model outputs are generated
    with greedy search.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '从经验上看，我们发现 PASTA 对于 LLAMA-7B 的缩放系数 $\alpha$ {300, 400, 500} 并不敏感，以便获得 $|\mathcal{H}|$
    个引导头，即 $k=400$。对于 GPT-J，我们选择 $k$ 为 {52, 72, 111, 153}。对于每个任务，我们按照 (Hernandez et
    al., [2023](#bib.bib14)) 将数据划分为训练/验证/测试集 (见附录 [A](#A1 "Appendix A Experimental
    Details ‣ Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs"))
    并通过交叉验证选择 $|\mathcal{H}|$。对于所有任务，模型输出是通过贪婪搜索生成的。'
- en: 5 Results
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结果
- en: '5.1 Main result: PASTA improves model generation'
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 主要结果：PASTA 改善了模型生成
- en: 'Tables [2](#S4.T2 "Table 2 ‣ Baselines. ‣ 4 Experimental setup ‣ Tell Your
    Model Where to Attend: Post-hoc Attention Steering for LLMs") and [2](#S4.T2 "Table
    2 ‣ Baselines. ‣ 4 Experimental setup ‣ Tell Your Model Where to Attend: Post-hoc
    Attention Steering for LLMs") present the main results for PASTA applied to LLAMA-7B
    and GPT-J respectively. Few-shot prompting is the strongest baseline, and task-agnostic
    PASTA outperforms it on the main metric for each task for all settings except
    JSON Formatting with GPT-J. Multi-task PASTA outperforms all baselines across
    all settings.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '表格 [2](#S4.T2 "Table 2 ‣ Baselines. ‣ 4 Experimental setup ‣ Tell Your Model
    Where to Attend: Post-hoc Attention Steering for LLMs") 和 [2](#S4.T2 "Table 2
    ‣ Baselines. ‣ 4 Experimental setup ‣ Tell Your Model Where to Attend: Post-hoc
    Attention Steering for LLMs") 展示了 PASTA 在 LLAMA-7B 和 GPT-J 上应用的主要结果。少样本提示是最强的基准，而任务无关的
    PASTA 在每个任务的主要指标上超越了它，除了 GPT-J 的 JSON 格式化任务。多任务 PASTA 在所有设置中超越了所有基准。'
- en: 'PASTA can improve LLM instruction following. The results from JSON Formatting
    and Pronouns Changing tasks indicate that, by highlighting the user instruction
    at the end of inputs, PASTA effectively steers models to focus on user intentions,
    thereby biasing their generation to fulfill specific requirements or formats.
    For example, while GPT-J only achieves 39.9% of its zero-shot generations complying
    the user requirement on the Pronouns Changing task, PASTA yields a remarkable
    53% accuracy improvement by emphasizing the instruction. Moreover, PASTA achieves
    an impressive 96.64% format accuracy and 85.09% prediction accuracy when applied
    to LLAMA-7B on the JSON Formatting task. This performance exceeds that of few-shot
    prompting by 11%, even though few-shot prompting explicitly provides the model
    with correct JSON examples through additional demonstrations. Table [3](#S5.T3
    "Table 3 ‣ 5.1 Main result: PASTA improves model generation ‣ 5 Results ‣ Tell
    Your Model Where to Attend: Post-hoc Attention Steering for LLMs") presents a
    few examples generated by LLAMA-7B when applying PASTA.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: PASTA可以改善LLM的指令遵循。来自JSON格式化和代词变化任务的结果表明，通过在输入的末尾突出用户指令，PASTA有效地引导模型关注用户意图，从而使生成结果偏向于满足特定要求或格式。例如，在代词变化任务中，尽管GPT-J仅有39.9%的零-shot生成符合用户要求，PASTA通过强调指令实现了53%的显著准确率提升。此外，在JSON格式化任务中，当应用于LLAMA-7B时，PASTA达到了令人印象深刻的96.64%的格式准确率和85.09%的预测准确率。这一表现比少-shot提示提高了11%，尽管少-shot提示通过额外示例明确向模型提供了正确的JSON示例。表[3](#S5.T3
    "表 3 ‣ 5.1 主要结果：PASTA改善模型生成 ‣ 5 结果 ‣ 告诉你的模型在哪里关注：后处理注意力引导LLMs")展示了LLAMA-7B在应用PASTA时生成的一些示例。
- en: PASTA can help models capture crucial contextual information. In the case of
    BiasBios and CounterFact tasks, we apply PASTA to emphasize specific context spans
    for LLMs. Consequently, the models are guided to pay close attention to the specific
    contextual information or new facts within contexts. The results from these two
    tasks illustrate that PASTA can direct the models to interpret the crucial information
    or resolve the knowledge conflicts within contexts, yielding significant improvement
    in prediction performance of both tasks. For example, PASTA achieves a prediction
    accuracy of 94.96% for GPT-J on the BiasBios task, which is 16.32% higher than
    the best baseline.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: PASTA可以帮助模型捕捉关键的上下文信息。在BiasBios和CounterFact任务中，我们应用PASTA来强调LLM的特定上下文范围。因此，模型被引导去特别关注上下文中的关键信息或新事实。这两个任务的结果表明，PASTA能够引导模型解释关键信息或解决上下文中的知识冲突，从而显著提升两个任务的预测性能。例如，PASTA在BiasBios任务中为GPT-J实现了94.96%的预测准确率，比最佳基线高出16.32%。
- en: 'Table 3: Generation examples of LLAMA-7B on JSON Formatting and Pronouns Changing
    tasks.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：LLAMA-7B在JSON格式化和代词变化任务上的生成示例。
- en: '| Task | Prompt | Zero-shot Generation | PASTA Generation |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | 提示 | 零-shot生成 | PASTA生成 |'
- en: '| JSON Format | Winnie is an American photographer living in New York. Specialized
    in fashion photography and portrait, she applies her talent on both humans and
    animals …{instruction} | ✗ Winnie is a fashion and portrait photographer living
    in New York, specialized in fashion photography and portrait, who applies her
    talent on both humans and animals. | ✓ {“name”: “Winnie”, “occupation”: “photographer”
    } |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| JSON格式 | Winnie是一位生活在纽约的美国摄影师。专注于时尚摄影和肖像摄影，她将才华应用于人类和动物……{instruction} |
    ✗ Winnie是一位时尚和肖像摄影师，生活在纽约，专注于时尚摄影和肖像，她将才华应用于人类和动物。 | ✓ {“name”: “Winnie”, “occupation”:
    “photographer” } |'
- en: '| Prons. Change | Mary is an Associate Professor in the Department of Curriculum
    Instruction at St. John University; she holds a doctorate in Reading/Writing/Literacy
    from the University of Pennsylvania. She recently published an article in “Urban
    Education” with …{instruction} | ✗ Mary is a professor in the Department of Curriculum
    Instruction at St. John University; she holds a doctorate in Reading/Writing/Literacy
    from the University of Pennsylvania. She recently published an article in “Urban
    Education” with … | ✓ Mary is an associate professor in the department of curriculum
    and instruction at St. John’s University; they hold a doctorate in reading/writing/literacy
    from the University of Pennsylvania. They recently published an article in … |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| Pron. 变化 | 玛丽是圣约翰大学课程与教学系的副教授；她拥有宾夕法尼亚大学的阅读/写作/文学博士学位。她最近在“城市教育”上发表了一篇文章，内容为
    …{instruction} | ✗ 玛丽是圣约翰大学课程与教学系的教授；她拥有宾夕法尼亚大学的阅读/写作/文学博士学位。她最近在“城市教育”上发表了一篇文章，内容为
    … | ✓ 玛丽是圣约翰大学课程与教学系的副教授；他们拥有宾夕法尼亚大学的阅读/写作/文学博士学位。他们最近在 … 上发表了一篇文章 |'
- en: 'Tables [2](#S4.T2 "Table 2 ‣ Baselines. ‣ 4 Experimental setup ‣ Tell Your
    Model Where to Attend: Post-hoc Attention Steering for LLMs") and [2](#S4.T2 "Table
    2 ‣ Baselines. ‣ 4 Experimental setup ‣ Tell Your Model Where to Attend: Post-hoc
    Attention Steering for LLMs") also suggest that marked prompting, a baseline that
    highlights specific texts akin to human writers, struggles to effectively convey
    emphasis to LLMs. One possible reason is that these emphasis markers rarely appear
    in the massive pre-training data. In contrast, few-shot prompting sometimes leads
    to improvements in model performance. However, a drawback of few-shot prompting
    is its instability, i.e. its performance exhibits high variance across different
    samples in the demonstration (See Appendix [C](#A3 "Appendix C Extended results
    ‣ Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs")).'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '表 [2](#S4.T2 "Table 2 ‣ Baselines. ‣ 4 Experimental setup ‣ Tell Your Model
    Where to Attend: Post-hoc Attention Steering for LLMs") 和 [2](#S4.T2 "Table 2
    ‣ Baselines. ‣ 4 Experimental setup ‣ Tell Your Model Where to Attend: Post-hoc
    Attention Steering for LLMs") 也表明，标记提示作为一种基线，类似于人类作家的特定文本高亮显示，难以有效地传达对 LLMs 的重点。一个可能的原因是这些重点标记在大量预训练数据中很少出现。相比之下，少样本提示有时能改善模型性能。然而，少样本提示的一个缺点是其不稳定性，即在演示的不同样本之间表现出高方差（参见附录 [C](#A3
    "Appendix C Extended results ‣ Tell Your Model Where to Attend: Post-hoc Attention
    Steering for LLMs")）。'
- en: 5.2 PASTA can mitigate the sensitivity of prompts
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 PASTA 可以减轻提示的敏感性
- en: 'Table 4: Results about sensitivity of model performance to prompt rephrasing
    on the JSON Formatting task. Given rephrased instructions in prompt template,
    PASTA can imporve zero-shot performance for all prompts.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：关于模型性能对 JSON 格式任务中提示重述的敏感性的结果。在提示模板中给定重述的指令，PASTA 可以提高所有提示的零样本性能。
- en: '| Instruction | Method | LLAMA-7B | GPT-J | Average |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 指令 | 方法 | LLAMA-7B | GPT-J | 平均 |'
- en: '| JSON Format F. Acc / P. Acc | Prons. Changing Acc / A. Acc | JSON Format
    F. Acc / P. Acc | Prons. Changing Acc / A. Acc |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| JSON 格式 F. 准确率 / P. 准确率 | Pron. 变化准确率 / A. 准确率 | JSON 格式 F. 准确率 / P. 准确率
    | Pron. 变化准确率 / A. 准确率 |'
- en: '| Original | Zero-shot | 60.0 / 54.9 | 71.8 / 66.3 | 28.8 / 25.1 | 39.9 / 36.2
    | 47.9 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 原始 | 零样本 | 60.0 / 54.9 | 71.8 / 66.3 | 28.8 / 25.1 | 39.9 / 36.2 | 47.9 |'
- en: '| PASTA | 96.6 / 85.1 | 96.4 / 95.8 | 91.5 / 18.6 | 93.0 / 91.3 | 83.5 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| PASTA | 96.6 / 85.1 | 96.4 / 95.8 | 91.5 / 18.6 | 93.0 / 91.3 | 83.5 |'
- en: '| Shortened | Zero-shot | 36.0 / 32.4 | 49.2 / 42.6 | 25.4 / 17.1 | 56.5 /
    54.8 | 39.3 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 缩短 | 零样本 | 36.0 / 32.4 | 49.2 / 42.6 | 25.4 / 17.1 | 56.5 / 54.8 | 39.3 |'
- en: '| PASTA | 87.4 / 65.9 | 89.0 / 86.9 | 54.1 / 37.0 | 94.0 / 93.7 | 76.0 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| PASTA | 87.4 / 65.9 | 89.0 / 86.9 | 54.1 / 37.0 | 94.0 / 93.7 | 76.0 |'
- en: '| Rephrased | Zero-shot | 57.9 / 54.2 | 82.3 / 79.6 | 63.3 / 50.3 | 76.0 /
    72.8 | 67.1 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 重述 | 零样本 | 57.9 / 54.2 | 82.3 / 79.6 | 63.3 / 50.3 | 76.0 / 72.8 | 67.1 |'
- en: '| PASTA | 97.1 / 87.1 | 89.6 / 89.0 | 77.5 / 68.1 | 94.8 / 92.3 | 86.9 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| PASTA | 97.1 / 87.1 | 89.6 / 89.0 | 77.5 / 68.1 | 94.8 / 92.3 | 86.9 |'
- en: 'It is well-known that the the performance of LLMs can be sensitive to minor
    changes in prompts, such as rephrasing and reformatting, even when these prompts
    convey the same meaning (Reynolds & McDonell, [2021](#bib.bib34); Liu et al.,
    [2021](#bib.bib24)). We find that PASTA can alleviate the sensitivity of model
    performance to varying prompts. Specifically, Table [4](#S5.T4 "Table 4 ‣ 5.2
    PASTA can mitigate the sensitivity of prompts ‣ 5 Results ‣ Tell Your Model Where
    to Attend: Post-hoc Attention Steering for LLMs") evaluates the performance of
    LLAMA-7B and GPT-J on JSON Formatting and Pronouns Changing task given different
    instructions in the prompt template, all of which convey the same meaning (see
    precise prompts in [Sec. A.1](#A1.SS1 "A.1 Detailed prompt templates of each task
    ‣ Appendix A Experimental Details ‣ Tell Your Model Where to Attend: Post-hoc
    Attention Steering for LLMs")). The results show that zero-shot performance is
    sensitive to different prompts and can significantly deteriorate with poorly crafted
    templates. In contrast, PASTA consistently improves model performance over zero-shot
    prompting for all prompts, effectively mitigating sensitivity to variations in
    the prompts.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 众所周知，LLM的性能可能对提示中的微小变化敏感，如重述和重新格式化，即使这些提示传达相同的含义（Reynolds & McDonell, [2021](#bib.bib34);
    Liu et al., [2021](#bib.bib24)）。我们发现，PASTA可以缓解模型性能对变化提示的敏感性。具体而言，表[4](#S5.T4 "表
    4 ‣ 5.2 PASTA可以减轻提示的敏感性 ‣ 5 结果 ‣ 告诉你的模型关注哪里：后处理注意力引导")评估了LLAMA-7B和GPT-J在JSON格式化和代词改变任务上的表现，给出不同的提示模板，这些模板传达相同的含义（参见[第A.1节](#A1.SS1
    "A.1 每个任务的详细提示模板 ‣ 附录A 实验细节 ‣ 告诉你的模型关注哪里：后处理注意力引导")中的精确提示）。结果表明，零-shot表现对不同的提示非常敏感，且在提示模板设计不佳时性能会显著下降。相比之下，PASTA在所有提示上都能有效提高模型性能，明显减轻对提示变化的敏感性。
- en: 5.3 Analysis and Ablations
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 分析与消融
- en: In this section, we investigate different hyperparameter choices and modeling
    decisions that affect the performance of PASTA.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们探讨了不同的超参数选择和建模决策，这些因素影响PASTA的性能。
- en: Model profiling
  id: totrans-106
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模型分析
- en: '![Refer to caption](img/fc980f5b727b7385045f9d508329ae80.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/fc980f5b727b7385045f9d508329ae80.png)'
- en: 'Figure 2: The performance of LLAMA-7B on the JSON Formatting task when we steer
    (i) all heads (green); (ii) an entire layer (yellow); and (iii) an individual
    head within a layer (blue violin plot). The performance varies dramatically across
    layers and across heads of a layer.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：当我们调整（i）所有头（绿色）；（ii）整层（黄色）；以及（iii）层内的单个头（蓝色小提琴图）时，LLAMA-7B在JSON格式化任务上的表现。性能在不同层级和同一层的不同头之间变化很大。
- en: 'Figure [2](#S5.F2 "Figure 2 ‣ Model profiling ‣ 5.3 Analysis and Ablations
    ‣ 5 Results ‣ Tell Your Model Where to Attend: Post-hoc Attention Steering for
    LLMs") presents the results on the importance of model profiling introduced in
    Section [3.2](#S3.SS2 "3.2 Multi-Task Model Profiling ‣ 3 Method ‣ Tell Your Model
    Where to Attend: Post-hoc Attention Steering for LLMs"). We compare PASTA when
    steering the selected heads versus other reasonable choices: steering (i) all
    heads, (ii) entire layers, or (iii) individual heads on the JSON Formatting task
    (See Appendix [C.2](#A3.SS2 "C.2 Model Profiling Results ‣ Appendix C Extended
    results ‣ Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs")
    for comparisons on the remaining tasks). Selecting heads via model profiling in
    PASTA (red line) significantly outperforms other approaches. Steering all heads
    (dashed green line) degrades performance compared to the baseline zero-shot performance
    (dashed black line). This is likely because steering all heads over-amplifies
    the user-specified information at the expense of other essential information required
    for effective generation and prediction. Interestingly, we find that the performance
    varies significantly when steering different layers (yellow) or heads (blue violin
    plot). As mentioned in Section [1](#S1 "1 Introduction ‣ Tell Your Model Where
    to Attend: Post-hoc Attention Steering for LLMs"), attention heads play distinct
    roles in encoding diverse semantic and syntactic information (Tenney et al., [2019](#bib.bib47)).
    When steering heads, which are appropriately involved in encoding of user-specified
    information, the model can be guided to capture and reinforce these specific signals.
    Conversely, modifying the attention of unrelated heads not only fails to emphasize
    the desired information but also interferes with their original functions, resulting
    in performance deterioration. Therefore, it is important to identify the effective
    heads through model profiling prior to applying the steering.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图[2](#S5.F2 "图 2 ‣ 模型分析 ‣ 5.3 分析与消融 ‣ 5 结果 ‣ 告诉你的模型关注哪里：对LLM的后期注意力引导")展示了在第[3.2节](#S3.SS2
    "3.2 多任务模型分析 ‣ 3 方法 ‣ 告诉你的模型关注哪里：对LLM的后期注意力引导")中介绍的模型分析重要性的结果。我们比较了在选择头部时引导PASTA与其他合理选择的效果：引导（i）所有头部，（ii）整个层，或（iii）JSON格式任务上的单个头部（有关其余任务的比较，请参见附录[C.2](#A3.SS2
    "C.2 模型分析结果 ‣ 附录 C 扩展结果 ‣ 告诉你的模型关注哪里：对LLM的后期注意力引导")）。在PASTA中通过模型分析选择头部（红线）显著优于其他方法。引导所有头部（虚线绿色线）相比基线零-shot性能（虚线黑线）表现较差。这可能是因为引导所有头部过度放大了用户指定的信息，而牺牲了生成和预测所需的其他重要信息。有趣的是，我们发现当引导不同层（黄色）或头部（蓝色小提琴图）时，性能有显著变化。如第[1节](#S1
    "1 引言 ‣ 告诉你的模型关注哪里：对LLM的后期注意力引导")中所述，注意力头在编码多样的语义和句法信息方面扮演了不同的角色（Tenney等，[2019](#bib.bib47)）。当引导在适当参与用户指定信息编码的头部时，模型可以被引导捕捉和强化这些特定信号。相反，修改无关头部的注意力不仅未能强调所需的信息，还会干扰它们的原始功能，从而导致性能下降。因此，在应用引导之前，通过模型分析识别有效的头部非常重要。
- en: 'Varying strategies for selecting heads during profiling. As described in [Sec. 5.3](#S5.SS3.SSS0.Px1
    "Model profiling ‣ 5.3 Analysis and Ablations ‣ 5 Results ‣ Tell Your Model Where
    to Attend: Post-hoc Attention Steering for LLMs"), our model profiling selects
    the Intersection of the top-$k$, we can select heads for steering with different
    strategies: (i) Task-specific – steer the top-$k_{2}$, i.e., $R^{(j)}_{1:k_{2}}$.
    Table [5](#S5.T5 "Table 5 ‣ Model profiling ‣ 5.3 Analysis and Ablations ‣ 5 Results
    ‣ Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs") compares
    their performance. Using task-specific heads rather than intersection-selected
    heads sometimes yields improved performance, but requires selecting a different
    set of heads for each new task.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析期间选择头部的不同策略。如[第5.3节](#S5.SS3.SSS0.Px1 "模型分析 ‣ 5.3 分析与消融 ‣ 5 结果 ‣ 告诉你的模型关注哪里：对LLM的后期注意力引导")中所述，我们的模型分析选择了前$k$的交集，我们可以使用不同策略选择用于引导的头部：（i）任务特定——引导前$k_{2}$，即$R^{(j)}_{1:k_{2}}$。表[5](#S5.T5
    "表 5 ‣ 模型分析 ‣ 5.3 分析与消融 ‣ 5 结果 ‣ 告诉你的模型关注哪里：对LLM的后期注意力引导")比较了它们的性能。使用任务特定的头部而不是交集选择的头部有时会提高性能，但需要为每个新任务选择不同的头部集合。
- en: 'Table 5: Varying head selection strategies between top task-specific heads,
    union across multiple tasks, and intersection (the default used in PASTA).'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：不同头部选择策略的对比，包括前任务特定头部、跨多个任务的并集和交集（PASTA中使用的默认策略）。
- en: '|  | PASTA | JSON Format | Prons. Changing | BiasBios | CounterFact | All |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '|  | PASTA | JSON 格式 | 代词变化 | BiasBios | CounterFact | 全部 |'
- en: '|  | F. Acc / P. Acc | Acc / A.Acc | Acc | ES / PS | Avg. |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '|  | F. Acc / P. Acc | 准确率 / 平均准确率 | 准确率 | ES / PS | 平均值 |'
- en: '| LLAMA | Task-specific | 95.56 / 86.83 | 98.52 / 98.02 | 97.62 | 99.18 / 99.24
    | 96.57 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| LLAMA | 任务特定 | 95.56 / 86.83 | 98.52 / 98.02 | 97.62 | 99.18 / 99.24 | 96.57
    |'
- en: '| Union | 88.42 / 74.49 | 92.12 / 91.44 | 96.36 | 99.24 / 99.35 | 92.22 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 联合 | 88.42 / 74.49 | 92.12 / 91.44 | 96.36 | 99.24 / 99.35 | 92.22 |'
- en: '| Intersection | 96.64 / 85.09 | 96.42 / 95.84 | 95.28 | 99.60 / 99.57 | 95.46
    |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 交集 | 96.64 / 85.09 | 96.42 / 95.84 | 95.28 | 99.60 / 99.57 | 95.46 |'
- en: '| GPT-J | Task-specific | 85.71 / 79.39 | 94.74 / 92.54 | 97.64 | 99.26 / 99.34
    | 93.29 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| GPT-J | 任务特定 | 85.71 / 79.39 | 94.74 / 92.54 | 97.64 | 99.26 / 99.34 | 93.29
    |'
- en: '| Union | 72.61 / 64.89 | 89.68 / 87.76 | 95.56 | 99.82 / 99.83 | 88.21 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 联合 | 72.61 / 64.89 | 89.68 / 87.76 | 95.56 | 99.82 / 99.83 | 88.21 |'
- en: '| Intersection | 91.50 / 18.63 | 92.96 / 91.34 | 94.96 | 98.62 / 98.79 | 85.22
    |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 交集 | 91.50 / 18.63 | 92.96 / 91.34 | 94.96 | 98.62 / 98.79 | 85.22 |'
- en: 'Varying the number of heads to be steered. Figures [3(a)](#S5.F3.sf1 "Figure
    3(a) ‣ Figure 3 ‣ Model profiling ‣ 5.3 Analysis and Ablations ‣ 5 Results ‣ Tell
    Your Model Where to Attend: Post-hoc Attention Steering for LLMs") and [3(b)](#S5.F3.sf2
    "Figure 3(b) ‣ Figure 3 ‣ Model profiling ‣ 5.3 Analysis and Ablations ‣ 5 Results
    ‣ Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs") illustrate
    the performance of PASTA when steering different number of heads on two tasks.
    The results suggest that as more heads are included for steering, the model follows
    the user even more closely, achieving higher efficacy (JSON Format Acc. and Pron. Change
    Acc.). However, at some point, this it results in a decrease in the metrics reflecting
    the generation quality (JSON Pred. Acc and Fluency). Thus, there is a trade-off
    between emphasizing efficacy and generation quality, requiring choosing the number
    of heads during model profiling.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 变化引导头的数量。图 [3(a)](#S5.F3.sf1 "图 3(a) ‣ 图 3 ‣ 模型剖析 ‣ 5.3 分析与消融 ‣ 5 结果 ‣ 告诉你的模型关注哪里：LLM
    的后处理注意力引导") 和 [3(b)](#S5.F3.sf2 "图 3(b) ‣ 图 3 ‣ 模型剖析 ‣ 5.3 分析与消融 ‣ 5 结果 ‣ 告诉你的模型关注哪里：LLM
    的后处理注意力引导") 展示了 PASTA 在两个任务上引导不同数量的头时的表现。结果表明，随着引导头数量的增加，模型更加紧密地跟随用户，实现了更高的效果（JSON
    格式准确率和代词变化准确率）。然而，在某些时候，这会导致反映生成质量的指标下降（JSON 预测准确率和流畅性）。因此，在模型剖析过程中需要在效果和生成质量之间权衡选择头的数量。
- en: Varying the scaling coefficient $\alpha$. The results indicate that PASTA is
    fairly robust to this hyperparameter; in practice, we fix it as 0.01\. Notice
    that setting $\alpha$ to zero should be avoided, as this leads to the complete
    removal of other crucial contexts at the steered heads, resulting in performance
    degeneration.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 变化缩放系数 $\alpha$。结果表明 PASTA 对这个超参数相当稳健；在实践中，我们将其固定为 0.01。请注意，应避免将 $\alpha$ 设置为零，因为这会导致其他关键上下文在引导头处完全移除，从而导致性能退化。
- en: '![Refer to caption](img/04c6ca7cbfc791fe6c8a7a8dd338aaf9.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/04c6ca7cbfc791fe6c8a7a8dd338aaf9.png)'
- en: (a) JSON Format
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: (a) JSON 格式
- en: '![Refer to caption](img/867271b2f5031a6d6882700691da7265.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/867271b2f5031a6d6882700691da7265.png)'
- en: (b) Prons. Change
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 代词变化
- en: '![Refer to caption](img/cdd2e30d86c13964d85d253043d6c37f.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/cdd2e30d86c13964d85d253043d6c37f.png)'
- en: (c) Varying $\alpha$
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 变化的 $\alpha$
- en: 'Figure 3: The performance of applying PASTA to LLAMA-7B on JSON Formating and
    Pronouns Changing tasks when varying the number of steered heads $|\mathcal{H}|$
    ([3(c)](#S5.F3.sf3 "Figure 3(c) ‣ Figure 3 ‣ Model profiling ‣ 5.3 Analysis and
    Ablations ‣ 5 Results ‣ Tell Your Model Where to Attend: Post-hoc Attention Steering
    for LLMs")).'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：在 JSON 格式化和代词变化任务中应用 PASTA 到 LLAMA-7B 时，随着引导头数量 $|\mathcal{H}|$ 的变化的性能 ([3(c)](#S5.F3.sf3
    "图 3(c) ‣ 图 3 ‣ 模型剖析 ‣ 5.3 分析与消融 ‣ 5 结果 ‣ 告诉你的模型关注哪里：LLM 的后处理注意力引导"))。
- en: 6 Related work
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 相关工作
- en: The primary method for controlling LLMs has been through prompting, often yielding
    impressive improvements in performance (Brown et al., [2020b](#bib.bib4); Liu
    et al., [2021](#bib.bib24); Wei et al., [2022](#bib.bib54)) and spurring a line
    of work aiming to make prompting easier, e.g.  (Strobelt et al., [2022](#bib.bib46);
    Bach et al., [2022](#bib.bib1); Shin et al., [2020](#bib.bib42); Deng et al.,
    [2022](#bib.bib11); Singh et al., [2023b](#bib.bib44)). However, LLMs remain extremely
    sensitive to nuances in prompts (Webson & Pavlick, [2021](#bib.bib52); Lu et al.,
    [2021](#bib.bib25)); PASTA complements these approaches by making it easier for
    a user to specify a prompt in difficult scenarios.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 控制LLM的主要方法一直是通过提示，这通常会显著提高性能（Brown et al., [2020b](#bib.bib4); Liu et al., [2021](#bib.bib24);
    Wei et al., [2022](#bib.bib54)），并催生了一系列旨在简化提示的工作，例如（Strobelt et al., [2022](#bib.bib46);
    Bach et al., [2022](#bib.bib1); Shin et al., [2020](#bib.bib42); Deng et al.,
    [2022](#bib.bib11); Singh et al., [2023b](#bib.bib44)）。然而，LLM仍然对提示中的细微差别极为敏感（Webson
    & Pavlick, [2021](#bib.bib52); Lu et al., [2021](#bib.bib25)）；PASTA 通过使用户在困难场景下更容易指定提示来补充这些方法。
- en: Another line of work aims to make LLMs more amenable to prompting by modifying
    them during training. Most prominent among these approaches are instruction finetuning (Wei
    et al., [2021](#bib.bib53); Chung et al., [2022](#bib.bib5)), Reinforcement Learning
    from Human Feedback (Ziegler et al., [2019](#bib.bib59); Ouyang et al., [2022](#bib.bib32)),
    and other related methods, e.g. (Lee et al., [2023](#bib.bib21)). There are also
    a few methods for directly specifying which parts on an input are important during
    training, e.g. (Ross et al., [2017](#bib.bib36); Rieger et al., [2019](#bib.bib35);
    Schramowski et al., [2020](#bib.bib37); Krishna et al., [2023](#bib.bib20)). PASTA
    can be used in addition to these approaches to improve some aspects of model steerability
    (e.g. instruction following).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 另一类工作旨在通过在训练过程中对LLM进行修改，使其更易于提示。最突出的方法包括**指令微调**（Wei et al., [2021](#bib.bib53);
    Chung et al., [2022](#bib.bib5)）、**基于人类反馈的强化学习**（Ziegler et al., [2019](#bib.bib59);
    Ouyang et al., [2022](#bib.bib32)）以及其他相关方法，例如（Lee et al., [2023](#bib.bib21)）。还有一些方法用于在训练过程中直接指定输入中的重要部分，例如（Ross
    et al., [2017](#bib.bib36); Rieger et al., [2019](#bib.bib35); Schramowski et
    al., [2020](#bib.bib37); Krishna et al., [2023](#bib.bib20)）。PASTA 可以与这些方法结合使用，以改进模型的引导性（例如，指令跟随）。
- en: PASTA is related to variety of methods for adapting to new tasks, including
    LoRA (Hu et al., [2021a](#bib.bib15)), AdaLoRA (Zhang et al., [2023](#bib.bib58)),
    QLoRA (Dettmers et al., [2023](#bib.bib12)), and TOAST (Shi et al., [2023b](#bib.bib41)).
    PASTA is also related to a variety of research on model editing, e.g. ROME (Meng
    et al., [2022a](#bib.bib26)), MEMIT (Meng et al., [2022b](#bib.bib27)), MEND (Mitchell
    et al., [2022](#bib.bib29)), and REMEDI (Hernandez et al., [2023](#bib.bib14)).
    Unlike these works, PASTA preserves an LLMs ability to transfer to new tasks using
    prompts and human-selected info, rather than using new labeled examples.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: PASTA 与多种适应新任务的方法相关，包括LoRA（Hu et al., [2021a](#bib.bib15)）、AdaLoRA（Zhang et
    al., [2023](#bib.bib58)）、QLoRA（Dettmers et al., [2023](#bib.bib12)）和TOAST（Shi
    et al., [2023b](#bib.bib41)）。PASTA 还与多种模型编辑研究相关，例如ROME（Meng et al., [2022a](#bib.bib26)）、MEMIT（Meng
    et al., [2022b](#bib.bib27)）、MEND（Mitchell et al., [2022](#bib.bib29)）和REMEDI（Hernandez
    et al., [2023](#bib.bib14)）。与这些工作不同，PASTA 保留了LLM通过提示和人工选择的信息转移到新任务的能力，而不是使用新的标记示例。
- en: Finally, PASTA is also motivated by works which have aimed to mechanistically
    understand attention scores (Zou et al., [2023](#bib.bib60)), e.g. by studying
    them through feature importance (Jain & Wallace, [2019](#bib.bib17); Wiegreffe
    & Pinter, [2019](#bib.bib55); Deb et al., [2023](#bib.bib10)), through probing (Conneau
    et al., [2018](#bib.bib7); Liu & Avci, [2019](#bib.bib22)), through visualization (Karpathy
    et al., [2015](#bib.bib18); Olah et al., [2017](#bib.bib30)), localizing knowledge (Meng
    et al., [2022a](#bib.bib26); Dai et al., [2021](#bib.bib8)), categorizing directions
    in representation space (Kim et al., [2017](#bib.bib19); Schwettmann et al., [2021](#bib.bib38)),
    or through natural-language explanations (Bills et al., [2023](#bib.bib2); Singh
    et al., [2023a](#bib.bib43)).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，PASTA 的动机也受到了一些旨在机制性理解注意力分数的工作的启发（Zou et al., [2023](#bib.bib60)），例如通过研究特征重要性（Jain
    & Wallace, [2019](#bib.bib17); Wiegreffe & Pinter, [2019](#bib.bib55); Deb et
    al., [2023](#bib.bib10)）、通过探测（Conneau et al., [2018](#bib.bib7); Liu & Avci, [2019](#bib.bib22)）、通过可视化（Karpathy
    et al., [2015](#bib.bib18); Olah et al., [2017](#bib.bib30)）、局部化知识（Meng et al.,
    [2022a](#bib.bib26); Dai et al., [2021](#bib.bib8)）、在表示空间中分类方向（Kim et al., [2017](#bib.bib19);
    Schwettmann et al., [2021](#bib.bib38)）或通过自然语言解释（Bills et al., [2023](#bib.bib2);
    Singh et al., [2023a](#bib.bib43)）。
- en: 7 Conclusion
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 结论
- en: In this study, we propose PASTA, a novel approach aimed at enabling LLMs to
    move beyond the limitations of plain text and effectively perceive user guidance
    embodied as highlighted parts of prompts. By making precise adjustments to attention
    scores in selected heads, PASTA directs the model’s focus to the relevant context,
    mirroring the way humans benefit from textual cues. Unlike traditional fine-tuning
    methods, PASTA is applied at inference time and requires neither parameter updates
    nor gradient computation; PASTA requires only selecting which attention heads
    to apply the re-weighting to, a one-time profiling operation for a LLM. Experimental
    results show that PASTA can significantly improve model performance on a variety
    of tasks. In the future, we plan to integrate PASTA with various other methods,
    such as few-shot in-context learning, aiming to highlight effective examples to
    enhance its stability.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们提出了PASTA，这是一种新颖的方法，旨在使大型语言模型超越纯文本的局限，有效感知以突出部分的形式体现的用户指导。通过对选定头部的注意力分数进行精确调整，PASTA将模型的关注点引导到相关上下文，类似于人类如何从文本提示中获益。与传统的微调方法不同，PASTA在推理时应用，无需参数更新或梯度计算；PASTA只需选择哪些注意力头应用重新加权，这是对大型语言模型的一次性配置操作。实验结果表明，PASTA可以显著提升模型在各种任务上的表现。未来，我们计划将PASTA与其他方法（如少样本上下文学习）集成，以突出有效示例，从而增强其稳定性。
- en: References
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Bach et al. (2022) Stephen H Bach, Victor Sanh, Zheng-Xin Yong, Albert Webson,
    Colin Raffel, Nihal V Nayak, Abheesht Sharma, Taewoon Kim, M Saiful Bari, Thibault
    Fevry, et al. Promptsource: An integrated development environment and repository
    for natural language prompts. *arXiv preprint arXiv:2202.01279*, 2022.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Bach 等 (2022) Stephen H Bach, Victor Sanh, Zheng-Xin Yong, Albert Webson, Colin
    Raffel, Nihal V Nayak, Abheesht Sharma, Taewoon Kim, M Saiful Bari, Thibault Fevry
    等。Promptsource: 一个集成的自然语言提示开发环境和库。*arXiv 预印本 arXiv:2202.01279*，2022年。'
- en: 'Bills et al. (2023) Steven Bills, Nick Cammarata, Dan Mossing, Henk Tillman,
    Leo Gao, Gabriel Goh, Ilya Sutskever, Jan Leike, Jeff Wu, and William Saunders.
    Language models can explain neurons in language models. *URL https://openaipublic.
    blob. core. windows. net/neuron-explainer/paper/index. html.(Date accessed: 14.05\.
    2023)*, 2023.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bills 等 (2023) Steven Bills, Nick Cammarata, Dan Mossing, Henk Tillman, Leo
    Gao, Gabriel Goh, Ilya Sutskever, Jan Leike, Jeff Wu 和 William Saunders. 语言模型可以解释语言模型中的神经元。*网址
    https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html（访问日期：2023年5月14日）*，2023年。
- en: Brown et al. (2020a) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah,
    Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
    Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,
    Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris
    Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack
    Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario
    Amodei. Language models are few-shot learners. In H. Larochelle, M. Ranzato, R. Hadsell,
    M.F. Balcan, and H. Lin (eds.), *Advances in Neural Information Processing Systems*,
    volume 33, pp.  1877–1901\. Curran Associates, Inc., 2020a. URL [https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf](https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf).
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown 等 (2020a) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared
    D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
    Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,
    Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris
    Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack
    Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever 和 Dario
    Amodei. 语言模型是少样本学习者。收录于 H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan 和 H.
    Lin (编)，*《神经信息处理系统进展》*，第33卷，第1877–1901页。Curran Associates, Inc.，2020a。网址 [https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf](https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf)。
- en: Brown et al. (2020b) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah,
    Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
    Amanda Askell, et al. Language models are few-shot learners. *Advances in neural
    information processing systems*, 33:1877–1901, 2020b.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown 等 (2020b) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared
    D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
    Amanda Askell 等。语言模型是少样本学习者。*神经信息处理系统进展*，33:1877–1901，2020b。
- en: Chung et al. (2022) Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay,
    William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al.
    Scaling instruction-finetuned language models. *arXiv preprint arXiv:2210.11416*,
    2022.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chung et al. (2022) Hyung Won Chung、Le Hou、Shayne Longpre、Barret Zoph、Yi Tay、William
    Fedus、Eric Li、Xuezhi Wang、Mostafa Dehghani、Siddhartha Brahma 等人。扩展指令微调语言模型。*arXiv
    预印本 arXiv:2210.11416*，2022年。
- en: 'Clark et al. (2019) Kevin Clark, Urvashi Khandelwal, Omer Levy, and Christopher D.
    Manning. What does BERT look at? an analysis of BERT’s attention. In *Proceedings
    of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks
    for NLP*, pp.  276–286, Florence, Italy, August 2019\. Association for Computational
    Linguistics. doi: 10.18653/v1/W19-4828. URL [https://aclanthology.org/W19-4828](https://aclanthology.org/W19-4828).'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Clark et al. (2019) Kevin Clark、Urvashi Khandelwal、Omer Levy 和 Christopher
    D. Manning。BERT 关注什么？对 BERT 注意力的分析。见于 *2019年ACL研讨会论文集 BlackboxNLP：分析与解释 NLP 的神经网络*，第276–286页，意大利佛罗伦萨，2019年8月。计算语言学协会。doi:
    10.18653/v1/W19-4828。网址 [https://aclanthology.org/W19-4828](https://aclanthology.org/W19-4828)。'
- en: 'Conneau et al. (2018) Alexis Conneau, German Kruszewski, Guillaume Lample,
    Loïc Barrault, and Marco Baroni. What you can cram into a single vector: Probing
    sentence embeddings for linguistic properties. *arXiv preprint arXiv:1805.01070*,
    2018.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Conneau et al. (2018) Alexis Conneau、German Kruszewski、Guillaume Lample、Loïc
    Barrault 和 Marco Baroni。你可以把什么塞进一个单一的向量：探测句子嵌入的语言属性。*arXiv 预印本 arXiv:1805.01070*，2018年。
- en: Dai et al. (2021) Damai Dai, Li Dong, Yaru Hao, Zhifang Sui, Baobao Chang, and
    Furu Wei. Knowledge neurons in pretrained transformers. *arXiv preprint arXiv:2104.08696*,
    2021.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dai et al. (2021) Damai Dai、Li Dong、Yaru Hao、Zhifang Sui、Baobao Chang 和 Furu
    Wei。预训练变换器中的知识神经元。*arXiv 预印本 arXiv:2104.08696*，2021年。
- en: 'De-Arteaga et al. (2019) Maria De-Arteaga, Alexey Romanov, Hanna Wallach, Jennifer
    Chayes, Christian Borgs, Alexandra Chouldechova, Sahin Geyik, Krishnaram Kenthapadi,
    and Adam Tauman Kalai. Bias in bios: A case study of semantic representation bias
    in a high-stakes setting. In *proceedings of the Conference on Fairness, Accountability,
    and Transparency*, pp.  120–128, 2019.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: De-Arteaga et al. (2019) Maria De-Arteaga、Alexey Romanov、Hanna Wallach、Jennifer
    Chayes、Christian Borgs、Alexandra Chouldechova、Sahin Geyik、Krishnaram Kenthapadi
    和 Adam Tauman Kalai。生物数据中的偏见：在高风险环境中语义表示偏见的案例研究。见于 *公平性、问责制与透明度会议论文集*，第120–128页，2019年。
- en: 'Deb et al. (2023) Mayukh Deb, Björn Deiseroth, Samuel Weinbach, Patrick Schramowski,
    and Kristian Kersting. Atman: Understanding transformer predictions through memory
    efficient attention manipulation. *arXiv preprint arXiv:2301.08110*, 2023.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deb et al. (2023) Mayukh Deb、Björn Deiseroth、Samuel Weinbach、Patrick Schramowski
    和 Kristian Kersting。Atman：通过内存高效的注意力操作理解变换器预测。*arXiv 预印本 arXiv:2301.08110*，2023年。
- en: 'Deng et al. (2022) Mingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan Wang,
    Han Guo, Tianmin Shu, Meng Song, Eric P Xing, and Zhiting Hu. Rlprompt: Optimizing
    discrete text prompts with reinforcement learning. *arXiv preprint arXiv:2205.12548*,
    2022.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deng et al. (2022) Mingkai Deng、Jianyu Wang、Cheng-Ping Hsieh、Yihan Wang、Han
    Guo、Tianmin Shu、Meng Song、Eric P Xing 和 Zhiting Hu。Rlprompt：使用强化学习优化离散文本提示。*arXiv
    预印本 arXiv:2205.12548*，2022年。
- en: 'Dettmers et al. (2023) Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke
    Zettlemoyer. Qlora: Efficient finetuning of quantized llms, 2023.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dettmers et al. (2023) Tim Dettmers、Artidoro Pagnoni、Ari Holtzman 和 Luke Zettlemoyer。Qlora：高效微调量化LLM，2023年。
- en: Dong et al. (2023) Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao
    Chang, Xu Sun, Jingjing Xu, Lei Li, and Zhifang Sui. A survey on in-context learning,
    2023.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dong et al. (2023) Qingxiu Dong、Lei Li、Damai Dai、Ce Zheng、Zhiyong Wu、Baobao
    Chang、Xu Sun、Jingjing Xu、Lei Li 和 Zhifang Sui。关于上下文学习的调查，2023年。
- en: Hernandez et al. (2023) Evan Hernandez, Belinda Z. Li, and Jacob Andreas. Inspecting
    and editing knowledge representations in language models, 2023.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hernandez et al. (2023) Evan Hernandez、Belinda Z. Li 和 Jacob Andreas。检查和编辑语言模型中的知识表示，2023年。
- en: 'Hu et al. (2021a) Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu,
    Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. Lora: Low-rank adaptation of
    large language models. *arXiv preprint arXiv:2106.09685*, 2021a.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu et al. (2021a) Edward J Hu、Yelong Shen、Phillip Wallis、Zeyuan Allen-Zhu、Yuanzhi
    Li、Shean Wang、Lu Wang 和 Weizhu Chen。Lora：大型语言模型的低秩适应。*arXiv 预印本 arXiv:2106.09685*，2021年。
- en: 'Hu et al. (2021b) J. Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu,
    Yuanzhi Li, Shean Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language
    models. *arXiv preprint abs:2106.09685*, 2021b.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu et al. (2021b) J. Edward Hu、Yelong Shen、Phillip Wallis、Zeyuan Allen-Zhu、Yuanzhi
    Li、Shean Wang 和 Weizhu Chen。Lora：大型语言模型的低秩适应。*arXiv 预印本 abs:2106.09685*，2021年。
- en: Jain & Wallace (2019) Sarthak Jain and Byron C Wallace. Attention is not explanation.
    *arXiv preprint arXiv:1902.10186*, 2019.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jain & Wallace (2019) Sarthak Jain 和 Byron C Wallace. 注意力并非解释。*arXiv 预印本 arXiv:1902.10186*，2019。
- en: Karpathy et al. (2015) Andrej Karpathy, Justin Johnson, and Li Fei-Fei. Visualizing
    and understanding recurrent networks. *arXiv preprint arXiv:1506.02078*, 2015.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Karpathy et al. (2015) Andrej Karpathy, Justin Johnson, 和 Li Fei-Fei. 可视化和理解递归网络。*arXiv
    预印本 arXiv:1506.02078*，2015。
- en: 'Kim et al. (2017) Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James
    Wexler, Fernanda Viegas, and Rory Sayres. Interpretability beyond feature attribution:
    Quantitative testing with concept activation vectors (tcav). *arXiv preprint arXiv:1711.11279*,
    2017.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim et al. (2017) Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James
    Wexler, Fernanda Viegas, 和 Rory Sayres. 超越特征归因的可解释性：用概念激活向量（TCAV）进行定量测试。*arXiv
    预印本 arXiv:1711.11279*，2017。
- en: Krishna et al. (2023) Satyapriya Krishna, Jiaqi Ma, Dylan Slack, Asma Ghandeharioun,
    Sameer Singh, and Himabindu Lakkaraju. Post hoc explanations of language models
    can improve language models. *arXiv preprint arXiv:2305.11426*, 2023.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krishna et al. (2023) Satyapriya Krishna, Jiaqi Ma, Dylan Slack, Asma Ghandeharioun,
    Sameer Singh, 和 Himabindu Lakkaraju. 后验解释语言模型可以改善语言模型。*arXiv 预印本 arXiv:2305.11426*，2023。
- en: 'Lee et al. (2023) Harrison Lee, Samrat Phatale, Hassan Mansoor, Kellie Lu,
    Thomas Mesnard, Colton Bishop, Victor Carbune, and Abhinav Rastogi. Rlaif: Scaling
    reinforcement learning from human feedback with ai feedback. *arXiv preprint arXiv:2309.00267*,
    2023.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lee et al. (2023) Harrison Lee, Samrat Phatale, Hassan Mansoor, Kellie Lu,
    Thomas Mesnard, Colton Bishop, Victor Carbune, 和 Abhinav Rastogi. Rlaif: 从人类反馈到
    AI 反馈的强化学习扩展。*arXiv 预印本 arXiv:2309.00267*，2023。'
- en: Liu & Avci (2019) Frederick Liu and Besim Avci. Incorporating priors with feature
    attribution on text classification. *arXiv preprint arXiv:1906.08286*, 2019.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu & Avci (2019) Frederick Liu 和 Besim Avci. 在文本分类中结合先验与特征归因。*arXiv 预印本 arXiv:1906.08286*，2019。
- en: 'Liu et al. (2023) Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape,
    Michele Bevilacqua, Fabio Petroni, and Percy Liang. Lost in the middle: How language
    models use long contexts, 2023.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2023) Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele
    Bevilacqua, Fabio Petroni, 和 Percy Liang. 在中间迷失：语言模型如何使用长上下文，2023。
- en: 'Liu et al. (2021) Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki
    Hayashi, and Graham Neubig. Pre-train, prompt, and predict: A systematic survey
    of prompting methods in natural language processing. *arXiv preprint arXiv:2107.13586*,
    2021.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2021) Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki
    Hayashi, 和 Graham Neubig. 预训练、提示与预测：自然语言处理中的提示方法系统调查。*arXiv 预印本 arXiv:2107.13586*，2021。
- en: 'Lu et al. (2021) Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and
    Pontus Stenetorp. Fantastically ordered prompts and where to find them: Overcoming
    few-shot prompt order sensitivity. *arXiv preprint arXiv:2104.08786*, 2021.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lu et al. (2021) Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, 和 Pontus
    Stenetorp. 奇妙排序的提示及其发现：克服少样本提示顺序敏感性。*arXiv 预印本 arXiv:2104.08786*，2021。
- en: Meng et al. (2022a) Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov.
    Locating and editing factual associations in gpt. *Advances in Neural Information
    Processing Systems*, 35:17359–17372, 2022a.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Meng et al. (2022a) Kevin Meng, David Bau, Alex Andonian, 和 Yonatan Belinkov.
    在 GPT 中定位和编辑事实关联。*神经信息处理系统进展*，35:17359–17372，2022a。
- en: Meng et al. (2022b) Kevin Meng, Arnab Sen Sharma, Alex Andonian, Yonatan Belinkov,
    and David Bau. Mass-editing memory in a transformer. *arXiv preprint arXiv:2210.07229*,
    2022b.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Meng et al. (2022b) Kevin Meng, Arnab Sen Sharma, Alex Andonian, Yonatan Belinkov,
    和 David Bau. 在变换器中大规模编辑记忆。*arXiv 预印本 arXiv:2210.07229*，2022b。
- en: Michel et al. (2019) Paul Michel, Omer Levy, and Graham Neubig. Are sixteen
    heads really better than one? In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc,
    E. Fox, and R. Garnett (eds.), *Advances in Neural Information Processing Systems*,
    volume 32\. Curran Associates, Inc., 2019. URL [https://proceedings.neurips.cc/paper_files/paper/2019/file/2c601ad9d2ff9bc8b282670cdd54f69f-Paper.pdf](https://proceedings.neurips.cc/paper_files/paper/2019/file/2c601ad9d2ff9bc8b282670cdd54f69f-Paper.pdf).
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Michel et al. (2019) Paul Michel, Omer Levy, 和 Graham Neubig. 十六个头真的比一个好么？在
    H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, 和 R. Garnett
    (编)，*神经信息处理系统进展*，第32卷。Curran Associates, Inc.，2019。网址 [https://proceedings.neurips.cc/paper_files/paper/2019/file/2c601ad9d2ff9bc8b282670cdd54f69f-Paper.pdf](https://proceedings.neurips.cc/paper_files/paper/2019/file/2c601ad9d2ff9bc8b282670cdd54f69f-Paper.pdf)。
- en: Mitchell et al. (2022) Eric Mitchell, Charles Lin, Antoine Bosselut, Chelsea
    Finn, and Christopher D. Manning. Fast model editing at scale, 2022.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mitchell et al. (2022) Eric Mitchell, Charles Lin, Antoine Bosselut, Chelsea
    Finn, 和 Christopher D. Manning. 大规模快速模型编辑，2022。
- en: Olah et al. (2017) Chris Olah, Alexander Mordvintsev, and Ludwig Schubert. Feature
    visualization. *Distill*, 2(11):e7, 2017.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Olah 等 (2017) Chris Olah、Alexander Mordvintsev 和 Ludwig Schubert。《特征可视化》。*Distill*，2(11):e7，2017年。
- en: OpenAI (2023) OpenAI. Gpt-4 technical report, 2023.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI (2023) OpenAI。《GPT-4 技术报告》，2023年。
- en: Ouyang et al. (2022) Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll
    Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex
    Ray, et al. Training language models to follow instructions with human feedback.
    *Advances in Neural Information Processing Systems*, 35:27730–27744, 2022.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ouyang 等 (2022) Long Ouyang、Jeffrey Wu、Xu Jiang、Diogo Almeida、Carroll Wainwright、Pamela
    Mishkin、Chong Zhang、Sandhini Agarwal、Katarina Slama、Alex Ray 等。《通过人类反馈训练语言模型以遵循指令》。*神经信息处理系统进展*，35:27730–27744，2022年。
- en: 'Paszke et al. (2019) Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James
    Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca
    Antiga, Alban Desmaison, Andreas Köpf, Edward Yang, Zachary DeVito, Martin Raison,
    Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and
    Soumith Chintala. Pytorch: An imperative style, high-performance deep learning
    library. In Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d’Alché-Buc,
    Emily B. Fox, and Roman Garnett (eds.), *Advances in Neural Information Processing
    Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS
    2019, December 8-14, 2019, Vancouver, BC, Canada*, pp.  8024–8035, 2019.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Paszke 等 (2019) Adam Paszke、Sam Gross、Francisco Massa、Adam Lerer、James Bradbury、Gregory
    Chanan、Trevor Killeen、Zeming Lin、Natalia Gimelshein、Luca Antiga、Alban Desmaison、Andreas
    Köpf、Edward Yang、Zachary DeVito、Martin Raison、Alykhan Tejani、Sasank Chilamkurthy、Benoit
    Steiner、Lu Fang、Junjie Bai 和 Soumith Chintala。《Pytorch：一种命令式风格的高性能深度学习库》。在 Hanna
    M. Wallach、Hugo Larochelle、Alina Beygelzimer、Florence d’Alché-Buc、Emily B. Fox
    和 Roman Garnett (编)，《神经信息处理系统进展 32：2019 年神经信息处理系统年会，NeurIPS 2019，2019 年 12 月 8-14
    日，加拿大温哥华》，第8024–8035页，2019年。
- en: 'Reynolds & McDonell (2021) Laria Reynolds and Kyle McDonell. Prompt programming
    for large language models: Beyond the few-shot paradigm, 2021.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Reynolds & McDonell (2021) Laria Reynolds 和 Kyle McDonell。《大型语言模型的提示编程：超越少量示例范式》，2021年。
- en: 'Rieger et al. (2019) Laura Rieger, Chandan Singh, W James Murdoch, and Bin
    Yu. Interpretations are useful: penalizing explanations to align neural networks
    with prior knowledge. *arXiv preprint arXiv:1909.13584*, 2019.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rieger 等 (2019) Laura Rieger、Chandan Singh、W James Murdoch 和 Bin Yu。《解释是有用的：惩罚解释以使神经网络与先验知识对齐》。*arXiv
    预印本 arXiv:1909.13584*，2019年。
- en: 'Ross et al. (2017) Andrew Slavin Ross, Michael C Hughes, and Finale Doshi-Velez.
    Right for the right reasons: Training differentiable models by constraining their
    explanations. *arXiv preprint arXiv:1703.03717*, 2017.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ross 等 (2017) Andrew Slavin Ross、Michael C Hughes 和 Finale Doshi-Velez。《正确的理由：通过约束解释来训练可微分模型》。*arXiv
    预印本 arXiv:1703.03717*，2017年。
- en: Schramowski et al. (2020) Patrick Schramowski, Wolfgang Stammer, Stefano Teso,
    Anna Brugger, Franziska Herbert, Xiaoting Shao, Hans-Georg Luigs, Anne-Katrin
    Mahlein, and Kristian Kersting. Making deep neural networks right for the right
    scientific reasons by interacting with their explanations. *Nature Machine Intelligence*,
    2(8):476–486, 2020.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schramowski 等 (2020) Patrick Schramowski、Wolfgang Stammer、Stefano Teso、Anna
    Brugger、Franziska Herbert、Xiaoting Shao、Hans-Georg Luigs、Anne-Katrin Mahlein 和
    Kristian Kersting。《通过与解释互动使深度神经网络在科学上更加合理》。*自然机器智能*，2(8):476–486，2020年。
- en: Schwettmann et al. (2021) Sarah Schwettmann, Evan Hernandez, David Bau, Samuel
    Klein, Jacob Andreas, and Antonio Torralba. Toward a visual concept vocabulary
    for gan latent space. In *Proceedings of the IEEE/CVF International Conference
    on Computer Vision*, pp.  6804–6812, 2021.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schwettmann 等 (2021) Sarah Schwettmann、Evan Hernandez、David Bau、Samuel Klein、Jacob
    Andreas 和 Antonio Torralba。《朝着生成对抗网络潜在空间的视觉概念词汇》。在 *IEEE/CVF 国际计算机视觉会议论文集*，第6804–6812页，2021年。
- en: 'Shen et al. (2023) Tianhao Shen, Renren Jin, Yufei Huang, Chuang Liu, Weilong
    Dong, Zishan Guo, Xinwei Wu, Yan Liu, and Deyi Xiong. Large language model alignment:
    A survey, 2023.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen 等 (2023) Tianhao Shen、Renren Jin、Yufei Huang、Chuang Liu、Weilong Dong、Zishan
    Guo、Xinwei Wu、Yan Liu 和 Deyi Xiong。《大语言模型对齐：综述》，2023年。
- en: 'Shi et al. (2023a) Baifeng Shi, Siyu Gai, Trevor Darrell, and Xin Wang. Toast:
    Transfer learning via attention steering. *arXiv preprint abs:2305.15542*, 2023a.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi 等 (2023a) Baifeng Shi、Siyu Gai、Trevor Darrell 和 Xin Wang。《Toast：通过注意力引导的迁移学习》。*arXiv
    预印本 abs:2305.15542*，2023年。
- en: Shi et al. (2023b) Baifeng Shi, Siyu Gai, Trevor Darrell, and Xin Wang. Refocusing
    is key to transfer learning. *arXiv preprint arXiv:2305.15542*, 2023b.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi 等 (2023b) Baifeng Shi、Siyu Gai、Trevor Darrell 和 Xin Wang。《重新聚焦是迁移学习的关键》。*arXiv
    预印本 arXiv:2305.15542*，2023年。
- en: 'Shin et al. (2020) Taylor Shin, Yasaman Razeghi, Robert L Logan IV, Eric Wallace,
    and Sameer Singh. Autoprompt: Eliciting knowledge from language models with automatically
    generated prompts. *arXiv preprint arXiv:2010.15980*, 2020.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shin 等人 (2020) Taylor Shin、Yasaman Razeghi、Robert L Logan IV、Eric Wallace 和
    Sameer Singh。Autoprompt：通过自动生成的提示从语言模型中引出知识。*arXiv 预印本 arXiv:2010.15980*，2020年。
- en: Singh et al. (2023a) Chandan Singh, Aliyah R Hsu, Richard Antonello, Shailee
    Jain, Alexander G Huth, Bin Yu, and Jianfeng Gao. Explaining black box text modules
    in natural language with language models. *arXiv preprint arXiv:2305.09863*, 2023a.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Singh 等人 (2023a) Chandan Singh、Aliyah R Hsu、Richard Antonello、Shailee Jain、Alexander
    G Huth、Bin Yu 和 Jianfeng Gao。使用语言模型用自然语言解释黑箱文本模块。*arXiv 预印本 arXiv:2305.09863*，2023年。
- en: Singh et al. (2023b) Chandan Singh, John X. Morris, Jyoti Aneja, Alexander M.
    Rush, and Jianfeng Gao. Explaining patterns in data with language models via interpretable
    autoprompting, 2023b.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Singh 等人 (2023b) Chandan Singh、John X. Morris、Jyoti Aneja、Alexander M. Rush
    和 Jianfeng Gao。通过可解释的自动提示来解释数据中的模式，2023年。
- en: Stiennon et al. (2020) Nisan Stiennon, Long Ouyang, Jeff Wu, Daniel M. Ziegler,
    Ryan J. Lowe, Chelsea Voss, Alec Radford, Dario Amodei, and Paul Christiano. Learning
    to summarize from human feedback. *arXiv preprint abs:2009.01325*, 2020.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Stiennon 等人 (2020) Nisan Stiennon、Long Ouyang、Jeff Wu、Daniel M. Ziegler、Ryan
    J. Lowe、Chelsea Voss、Alec Radford、Dario Amodei 和 Paul Christiano。从人工反馈中学习总结。*arXiv
    预印本 abs:2009.01325*，2020年。
- en: Strobelt et al. (2022) Hendrik Strobelt, Albert Webson, Victor Sanh, Benjamin
    Hoover, Johanna Beyer, Hanspeter Pfister, and Alexander M. Rush. Interactive and
    visual prompt engineering for ad-hoc task adaptation with large language models,
    2022.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Strobelt 等人 (2022) Hendrik Strobelt、Albert Webson、Victor Sanh、Benjamin Hoover、Johanna
    Beyer、Hanspeter Pfister 和 Alexander M. Rush。用于大语言模型的交互式和视觉化提示工程，2022年。
- en: 'Tenney et al. (2019) Ian Tenney, Dipanjan Das, and Ellie Pavlick. BERT rediscovers
    the classical NLP pipeline. In *Proceedings of the 57th Annual Meeting of the
    Association for Computational Linguistics*, pp.  4593–4601, Florence, Italy, July
    2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1452. URL
    [https://aclanthology.org/P19-1452](https://aclanthology.org/P19-1452).'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tenney 等人 (2019) Ian Tenney、Dipanjan Das 和 Ellie Pavlick。BERT 重新发现经典 NLP 流水线。在
    *第57届计算语言学协会年会论文集*，第4593–4601页，意大利佛罗伦萨，2019年7月。计算语言学协会。doi: 10.18653/v1/P19-1452。URL
    [https://aclanthology.org/P19-1452](https://aclanthology.org/P19-1452)。'
- en: 'Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. *arXiv
    preprint arXiv:2307.09288*, 2023.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Touvron 等人 (2023) Hugo Touvron、Louis Martin、Kevin Stone、Peter Albert、Amjad Almahairi、Yasmine
    Babaei、Nikolay Bashlykov、Soumya Batra、Prajjwal Bhargava、Shruti Bhosale 等。Llama
    2：开放基础和微调的聊天模型。*arXiv 预印本 arXiv:2307.09288*，2023年。
- en: Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit,
    Llion Jones, Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin. Attention is
    all you need. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan,
    and R. Garnett (eds.), *Advances in Neural Information Processing Systems*, volume 30\.
    Curran Associates, Inc., 2017. URL [https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf).
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vaswani 等人 (2017) Ashish Vaswani、Noam Shazeer、Niki Parmar、Jakob Uszkoreit、Llion
    Jones、Aidan N Gomez、Ł ukasz Kaiser 和 Illia Polosukhin。注意力机制就是你所需要的。在 I. Guyon、U.
    Von Luxburg、S. Bengio、H. Wallach、R. Fergus、S. Vishwanathan 和 R. Garnett (编)，*神经信息处理系统的进展*，第30卷。Curran
    Associates, Inc.，2017年。URL [https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)。
- en: 'Voita et al. (2019) Elena Voita, David Talbot, Fedor Moiseev, Rico Sennrich,
    and Ivan Titov. Analyzing multi-head self-attention: Specialized heads do the
    heavy lifting, the rest can be pruned, July 2019. URL [https://aclanthology.org/P19-1580](https://aclanthology.org/P19-1580).'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Voita 等人 (2019) Elena Voita、David Talbot、Fedor Moiseev、Rico Sennrich 和 Ivan
    Titov。分析多头自注意力：专门的头部承担重任，其余可以被剪枝，2019年7月。URL [https://aclanthology.org/P19-1580](https://aclanthology.org/P19-1580)。
- en: 'Wang & Komatsuzaki (2021) Ben Wang and Aran Komatsuzaki. GPT-J-6B: A 6 Billion
    Parameter Autoregressive Language Model. [https://github.com/kingoflolz/mesh-transformer-jax](https://github.com/kingoflolz/mesh-transformer-jax),
    May 2021.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang & Komatsuzaki (2021) Ben Wang 和 Aran Komatsuzaki。GPT-J-6B：一个具有60亿参数的自回归语言模型。[https://github.com/kingoflolz/mesh-transformer-jax](https://github.com/kingoflolz/mesh-transformer-jax)，2021年5月。
- en: Webson & Pavlick (2021) Albert Webson and Ellie Pavlick. Do prompt-based models
    really understand the meaning of their prompts? *arXiv preprint arXiv:2109.01247*,
    2021.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Webson & Pavlick（2021）Albert Webson 和 Ellie Pavlick。基于提示的模型真的理解其提示的含义吗？*arXiv
    预印本 arXiv:2109.01247*，2021年。
- en: Wei et al. (2021) Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei
    Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. Finetuned language models
    are zero-shot learners. *arXiv preprint arXiv:2109.01652*, 2021.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等人（2021）Jason Wei、Maarten Bosma、Vincent Y Zhao、Kelvin Guu、Adams Wei Yu、Brian
    Lester、Nan Du、Andrew M Dai 和 Quoc V Le。微调语言模型是零样本学习者。*arXiv 预印本 arXiv:2109.01652*，2021年。
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei
    Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits
    reasoning in large language models. *Advances in Neural Information Processing
    Systems*, 35:24824–24837, 2022.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等人（2022）Jason Wei、Xuezhi Wang、Dale Schuurmans、Maarten Bosma、Fei Xia、Ed Chi、Quoc
    V Le、Denny Zhou 等人。链式思维提示引发大型语言模型的推理。*神经信息处理系统进展*，35:24824–24837，2022年。
- en: Wiegreffe & Pinter (2019) Sarah Wiegreffe and Yuval Pinter. Attention is not
    not explanation. *arXiv preprint arXiv:1908.04626*, 2019.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wiegreffe & Pinter（2019）Sarah Wiegreffe 和 Yuval Pinter。注意力并非解释。*arXiv 预印本 arXiv:1908.04626*，2019年。
- en: 'Wolf et al. (2019) Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond,
    Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz,
    et al. Huggingface’s transformers: State-of-the-art natural language processing.
    *arXiv preprint arXiv:1910.03771*, 2019.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wolf 等人（2019）Thomas Wolf、Lysandre Debut、Victor Sanh、Julien Chaumond、Clement
    Delangue、Anthony Moi、Pierric Cistac、Tim Rault、Rémi Louf、Morgan Funtowicz 等人。Huggingface
    的 transformers：最先进的自然语言处理。*arXiv 预印本 arXiv:1910.03771*，2019年。
- en: 'Yao et al. (2023) Zhewei Yao, Reza Yazdani Aminabadi, Olatunji Ruwase, Samyam
    Rajbhandari, Xiaoxia Wu, Ammar Ahmad Awan, Jeff Rasley, Minjia Zhang, Conglong
    Li, Connor Holmes, Zhongzhu Zhou, Michael Wyatt, Molly Smith, L A Kurilenko, Heyang
    Qin, Masahiro Tanaka, Shuai Che, Shuaiwen Leon Song, and Yuxiong He. Deepspeed-chat:
    Easy, fast and affordable rlhf training of chatgpt-like models at all scales.
    *arXiv preprint abs:2308.01320*, 2023.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao 等人（2023）Zhewei Yao、Reza Yazdani Aminabadi、Olatunji Ruwase、Samyam Rajbhandari、Xiaoxia
    Wu、Ammar Ahmad Awan、Jeff Rasley、Minjia Zhang、Conglong Li、Connor Holmes、Zhongzhu
    Zhou、Michael Wyatt、Molly Smith、L A Kurilenko、Heyang Qin、Masahiro Tanaka、Shuai
    Che、Shuaiwen Leon Song 和 Yuxiong He。Deepspeed-chat：在所有规模下轻松、快速且经济的 RLHF 训练 ChatGPT
    类模型。*arXiv 预印本 abs:2308.01320*，2023年。
- en: Zhang et al. (2023) Qingru Zhang, Minshuo Chen, Alexander Bukharin, Pengcheng
    He, Yu Cheng, Weizhu Chen, and Tuo Zhao. Adaptive budget allocation for parameter-efficient
    fine-tuning. In *The Eleventh International Conference on Learning Representations*,
    2023. URL [https://openreview.net/forum?id=lq62uWRJjiY](https://openreview.net/forum?id=lq62uWRJjiY).
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人（2023）Qingru Zhang、Minshuo Chen、Alexander Bukharin、Pengcheng He、Yu Cheng、Weizhu
    Chen 和 Tuo Zhao。用于参数高效微调的自适应预算分配。发表于 *第十一届国际学习表示会议*，2023年。网址 [https://openreview.net/forum?id=lq62uWRJjiY](https://openreview.net/forum?id=lq62uWRJjiY)。
- en: Ziegler et al. (2019) Daniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B Brown,
    Alec Radford, Dario Amodei, Paul Christiano, and Geoffrey Irving. Fine-tuning
    language models from human preferences. *arXiv preprint arXiv:1909.08593*, 2019.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ziegler 等人（2019）Daniel M Ziegler、Nisan Stiennon、Jeffrey Wu、Tom B Brown、Alec
    Radford、Dario Amodei、Paul Christiano 和 Geoffrey Irving。从人类偏好中微调语言模型。*arXiv 预印本
    arXiv:1909.08593*，2019年。
- en: 'Zou et al. (2023) Andy Zou, Long Phan, Sarah Chen, James Campbell, Phillip
    Guo, Richard Ren, Alexander Pan, Xuwang Yin, Mantas Mazeika, Ann-Kathrin Dombrowski,
    Shashwat Goel, Nathaniel Li, Michael J. Byun, Zifan Wang, Alex Mallen, Steven
    Basart, Sanmi Koyejo, Dawn Song, Matt Fredrikson, J. Zico Kolter, and Dan Hendrycks.
    Representation engineering: A top-down approach to ai transparency, 2023.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zou 等人（2023）Andy Zou、Long Phan、Sarah Chen、James Campbell、Phillip Guo、Richard
    Ren、Alexander Pan、Xuwang Yin、Mantas Mazeika、Ann-Kathrin Dombrowski、Shashwat Goel、Nathaniel
    Li、Michael J. Byun、Zifan Wang、Alex Mallen、Steven Basart、Sanmi Koyejo、Dawn Song、Matt
    Fredrikson、J. Zico Kolter 和 Dan Hendrycks。表示工程：一种自上而下的 AI 透明性方法，2023年。
- en: APPENDIX
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 附录
- en: Appendix A Experimental Details
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 实验细节
- en: We implement all algorithms using PyTorch (Paszke et al., [2019](#bib.bib33))
    and Huggingface (Wolf et al., [2019](#bib.bib56)) and run experiments on NVIDIA
    V100 GPUs and NVIDIA A6000 GPUs.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 PyTorch（Paszke 等人，[2019](#bib.bib33)）和 Huggingface（Wolf 等人，[2019](#bib.bib56)）实现所有算法，并在
    NVIDIA V100 GPUs 和 NVIDIA A6000 GPUs 上进行实验。
- en: '[Table 6](#A1.T6 "In Appendix A Experimental Details ‣ Tell Your Model Where
    to Attend: Post-hoc Attention Steering for LLMs") provides detailed statistics
    of datasets in our experiments.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 6](#A1.T6 "在附录 A 实验细节 ‣ 告诉您的模型注意哪里：后期注意力引导") 提供了我们实验中数据集的详细统计信息。'
- en: 'Table 6: Statistics of datasets.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6：数据集统计。
- en: '| Task | Train | Valid | Test |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | 训练 | 验证 | 测试 |'
- en: '| CounterFact | 1000 | 1000 | 5000 |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| CounterFact | 1000 | 1000 | 5000 |'
- en: '| BiasBios | 1000 | 1000 | 5000 |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| BiasBios | 1000 | 1000 | 5000 |'
- en: '| JSON Formatting | 1000 | 1000 | 5000 |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| JSON 格式化 | 1000 | 1000 | 5000 |'
- en: '| Pronouns Changing | 1000 | 1000 | 5000 |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| 代词更改 | 1000 | 1000 | 5000 |'
- en: A.1 Detailed prompt templates of each task
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 每个任务的详细提示模板
- en: 'For each task, the prompt templates in our results are as follows:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个任务，我们结果中的提示模板如下：
- en: •
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'JSON Formatting:'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: JSON 格式化：
- en: –
  id: totrans-211
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: '(Original) {context}. Answer the occupation of {person} and generate the answer
    as json format. Here is an example: {“name”: , “occupation”: ,}. Now generate
    the answer.'
  id: totrans-212
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '(原始) {context}。回答 {person} 的职业，并以 json 格式生成答案。以下是一个示例：{“name”: , “occupation”:
    ,}。现在生成答案。'
- en: –
  id: totrans-213
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: '(Shortened one in Section [5.2](#S5.SS2 "5.2 PASTA can mitigate the sensitivity
    of prompts ‣ 5 Results ‣ Tell Your Model Where to Attend: Post-hoc Attention Steering
    for LLMs")) {context}. Answer the occupation of {person} and generate the answer
    as json format.'
  id: totrans-214
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: (在第 [5.2](#S5.SS2 "5.2 PASTA 可以缓解提示的敏感性 ‣ 5 结果 ‣ 告诉你的模型去哪里：后期注意力引导") 节中缩短的)
    {context}。回答 {person} 的职业，并以 json 格式生成答案。
- en: –
  id: totrans-215
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: '(Rephrased one in Section [5.2](#S5.SS2 "5.2 PASTA can mitigate the sensitivity
    of prompts ‣ 5 Results ‣ Tell Your Model Where to Attend: Post-hoc Attention Steering
    for LLMs")) Answer the occupation of {person} and generate the answer as json
    format. Here is an example: {“name”: , “occupation”: ,}. {context}. Now generate
    the answer.'
  id: totrans-216
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '(在第 [5.2](#S5.SS2 "5.2 PASTA 可以缓解提示的敏感性 ‣ 5 结果 ‣ 告诉你的模型去哪里：后期注意力引导") 节中重新措辞的)
    回答 {person} 的职业，并以 json 格式生成答案。以下是一个示例：{“name”: , “occupation”: ,}。{context}。现在生成答案。'
- en: •
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Pronouns Changing:'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 代词更改：
- en: –
  id: totrans-219
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: '(Original): {context}. For the aforementioned text, substitute ‘she’ and ‘he’
    with ‘they’ and generate the occupation of {person} after changing pronouns.'
  id: totrans-220
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: (原始)：{context}。对于上述文本，将‘她’和‘他’替换为‘他们’，并在更改代词后生成 {person} 的职业。
- en: –
  id: totrans-221
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: '(Shortened one in Section [5.2](#S5.SS2 "5.2 PASTA can mitigate the sensitivity
    of prompts ‣ 5 Results ‣ Tell Your Model Where to Attend: Post-hoc Attention Steering
    for LLMs")): {context}. Change ‘she’ and ‘he’ with ‘they’ and answer the occupation
    of {person} after replacing the pronouns'
  id: totrans-222
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: (在第 [5.2](#S5.SS2 "5.2 PASTA 可以缓解提示的敏感性 ‣ 5 结果 ‣ 告诉你的模型去哪里：后期注意力引导") 节中缩短的)：{context}。将‘她’和‘他’改为‘他们’，并在替换代词后回答
    {person} 的职业。
- en: –
  id: totrans-223
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: '(Rephrased one in Section [5.2](#S5.SS2 "5.2 PASTA can mitigate the sensitivity
    of prompts ‣ 5 Results ‣ Tell Your Model Where to Attend: Post-hoc Attention Steering
    for LLMs")): {context}. For the aforementioned descriptions, replace ‘she’ and
    ‘he’ with ‘they’ in the aformentioned text and generate the new text after replacing
    the pronouns.'
  id: totrans-224
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: (在第 [5.2](#S5.SS2 "5.2 PASTA 可以缓解提示的敏感性 ‣ 5 结果 ‣ 告诉你的模型去哪里：后期注意力引导") 节中重新措辞的)：{context}。对于上述描述，将‘她’和‘他’替换为‘他们’，并在替换代词后生成新的文本。
- en: •
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'BiasBios: {context}. {person} has the occupation of.'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'BiasBios: {context}。{person} 的职业是。'
- en: •
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'CounterFact: Previously, {old fact}. Currently, {new fact}. {question}'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'CounterFact: 以前是 {old fact}。目前是 {new fact}。{question}'
- en: A.2 The evaluation details of PASTA
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 PASTA 的评估细节
- en: '[Table 7](#A1.T7 "In A.2 The evaluation details of PASTA ‣ Appendix A Experimental
    Details ‣ Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs")
    presents the number of heads to be steered by PASTA for LLAMA-7B and GPT-J-6B
    on every task.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 7](#A1.T7 "在 A.2 PASTA 的评估细节 ‣ 附录 A 实验细节 ‣ 告诉你的模型去哪里：后期注意力引导") 展示了每个任务中
    LLAMA-7B 和 GPT-J-6B 需要控制的头部数量。'
- en: 'Table 7: The number of heads to be steered by PASTA.'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '表 7: PASTA 需要控制的头部数量。'
- en: '| Task | LLAMA-7B | GPT-J-6B |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | LLAMA-7B | GPT-J-6B |'
- en: '| JSON Formatting | 53 | 153 |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| JSON 格式化 | 53 | 153 |'
- en: '| Pronouns Changing | 86 | 72 |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| 代词更改 | 86 | 72 |'
- en: '| BiasBios | 86 | 111 |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| BiasBios | 86 | 111 |'
- en: '| CounterFact | 86 | 52 |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| CounterFact | 86 | 52 |'
- en: Appendix B Extended results with fluency
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 流畅度扩展结果
- en: 'In this section, we include extended results, including fluency metrics. Fluency
    score is the average bi-gram and tri-gram entropy of generations, designed to
    be low for degenerated or repetitive texts (Meng et al., [2022a](#bib.bib26)).
    This metric can be regarded as the reference metric of generation quality. Typically,
    the generations of language models are reliable as long as their fluency score
    is not too low. Here, we filter out any results receiving a fluency score below
    3.0\. Table [9](#A2.T9 "Table 9 ‣ Appendix B Extended results with fluency ‣ Tell
    Your Model Where to Attend: Post-hoc Attention Steering for LLMs"), [9](#A2.T9
    "Table 9 ‣ Appendix B Extended results with fluency ‣ Tell Your Model Where to
    Attend: Post-hoc Attention Steering for LLMs") and [10](#A2.T10 "Table 10 ‣ Appendix
    B Extended results with fluency ‣ Tell Your Model Where to Attend: Post-hoc Attention
    Steering for LLMs") include all results and fluency evaluation.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '在这一部分，我们包括了扩展结果，包括流畅度指标。流畅度得分是生成文本的平均二元组和三元组熵，旨在对退化或重复的文本保持低值（Meng 等， [2022a](#bib.bib26)）。这一指标可视为生成质量的参考指标。通常，只要流畅度得分不太低，语言模型的生成结果是可靠的。在这里，我们筛选出流畅度得分低于
    3.0 的结果。表 [9](#A2.T9 "Table 9 ‣ Appendix B Extended results with fluency ‣ Tell
    Your Model Where to Attend: Post-hoc Attention Steering for LLMs")、[9](#A2.T9
    "Table 9 ‣ Appendix B Extended results with fluency ‣ Tell Your Model Where to
    Attend: Post-hoc Attention Steering for LLMs") 和 [10](#A2.T10 "Table 10 ‣ Appendix
    B Extended results with fluency ‣ Tell Your Model Where to Attend: Post-hoc Attention
    Steering for LLMs") 包含所有结果和流畅度评估。'
- en: 'Table 8: Main results of LLAMA-7B to demonstrate that PASTA can improve the
    model ability to (i) follow user instruction (JSON Format and Prons. Changing);
    (ii) interpret contextual information (BiasBios); (iii) resolving knowledge conflicts
    (CounterFact). For all scores, higher is better. The best results are in bold.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8：LLAMA-7B 的主要结果，展示 PASTA 可以提升模型的能力来 (i) 遵循用户指令（JSON 格式和发音变化）；(ii) 解释上下文信息（BiasBios）；(iii)
    解决知识冲突（反事实）。所有分数越高越好。最佳结果用粗体显示。
- en: '|  | Method | JSON Format | Prons. Changing | BiasBios | CounterFact |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '|  | 方法 | JSON 格式 | 发音变化 | BiasBios | 反事实 |'
- en: '|  | F. Acc / P. Acc | Acc / A.Acc / Flue. | Acc / Flue. | ES / PS /Flue. |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '|  | F. Acc / P. Acc | Acc / A.Acc / Flue. | Acc / Flue. | ES / PS /Flue. |'
- en: '| Prompting | Zero-shot | 60.00 / 54.94 | 71.84 / 66.28 / 6.10 | 87.36 / 3.98
    | 58.50 / 52.03 / 4.96 |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| 提示 | 零样本 | 60.00 / 54.94 | 71.84 / 66.28 / 6.10 | 87.36 / 3.98 | 58.50 /
    52.03 / 4.96 |'
- en: '| $\ast$-marked | 18.55 / 12.71 | 39.14 / 35.17 / 6.03 | 90.62 / 3.89 | 57.74
    / 50.52 / 5.12 |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| $\ast$ 标记 | 18.55 / 12.71 | 39.14 / 35.17 / 6.03 | 90.62 / 3.89 | 57.74 /
    50.52 / 5.12 |'
- en: '| “”-marked | 4.56 / 4.20 | 20.55 / 18.19 / 5.13 | 89.82 / 3.97 | 58.14 / 51.70
    / 5.13 |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| “” 标记 | 4.56 / 4.20 | 20.55 / 18.19 / 5.13 | 89.82 / 3.97 | 58.14 / 51.70
    / 5.13 |'
- en: '| Few-shot | 84.85 / 73.58 | 59.06 / 55.27 / 5.95 | 88.79 / 4.19 | 87.45 /
    49.82 / 5.68 |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| 少样本 | 84.85 / 73.58 | 59.06 / 55.27 / 5.95 | 88.79 / 4.19 | 87.45 / 49.82
    / 5.68 |'
- en: '| PASTA | Task-agnostic | 88.16 / 49.08 | 83.65 / 81.31 / 4.62 | 93.54 / 3.03
    | 98.82 / 99.03 / 4.78 |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| PASTA | 任务无关 | 88.16 / 49.08 | 83.65 / 81.31 / 4.62 | 93.54 / 3.03 | 98.82
    / 99.03 / 4.78 |'
- en: '| Multi-task | 96.64 / 85.09 | 96.42 / 95.84 / 5.43 | 95.28 / 4.05 | 99.60
    / 99.57 / 4.89 |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| 多任务 | 96.64 / 85.09 | 96.42 / 95.84 / 5.43 | 95.28 / 4.05 | 99.60 / 99.57
    / 4.89 |'
- en: 'Table 9: Main results of GPT-J to demonstrate that PASTA can improve the model
    ability to (i) follow user instruction (JSON Format and Prons. Changing); (ii)
    interpret contextual information (BiasBios); (iii) resolving knowledge conflicts
    (CounterFact). For all scores, higher is better. The best results are in bold.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 表 9：GPT-J 的主要结果，展示 PASTA 可以提升模型的能力来 (i) 遵循用户指令（JSON 格式和发音变化）；(ii) 解释上下文信息（BiasBios）；(iii)
    解决知识冲突（反事实）。所有分数越高越好。最佳结果用粗体显示。
- en: '|  | Method | JSON Format | Prons. Changing | BiasBios | CounterFact |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '|  | 方法 | JSON 格式 | 发音变化 | BiasBios | 反事实 |'
- en: '|  | F. Acc / P. Acc | Acc / A.Acc / Flue. | Acc / Flue. | ES / PS /Flue. |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '|  | F. Acc / P. Acc | Acc / A.Acc / Flue. | Acc / Flue. | ES / PS /Flue. |'
- en: '| Prompting | Zero-shot | 28.83 / 25.09 | 39.88 / 36.19 / 5.91 | 72.76 / 5.06
    | 42.14 / 42.02 / 5.01 |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| 提示 | 零样本 | 28.83 / 25.09 | 39.88 / 36.19 / 5.91 | 72.76 / 5.06 | 42.14 /
    42.02 / 5.01 |'
- en: '| $\ast$-marked | 4.44 / 4.10 | 41.25 / 37.57 / 4.76 | 74.14 / 5.01 | 44.50
    / 45.09 / 5.22 |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| $\ast$ 标记 | 4.44 / 4.10 | 41.25 / 37.57 / 4.76 | 74.14 / 5.01 | 44.50 / 45.09
    / 5.22 |'
- en: '| “”-marked | 8.81 / 5.62 | 6.12 / 5.72 / 5.43 | 78.64 / 4.96 | 45.54 / 41.84
    / 5.16 |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| “” 标记 | 8.81 / 5.62 | 6.12 / 5.72 / 5.43 | 78.64 / 4.96 | 45.54 / 41.84 /
    5.16 |'
- en: '| Few-shot | 84.15 / 72.65 | 35.77 / 32.08 / 6.46 | 72.98 / 4.82 | 68.34 /
    38.23 / 5.67 |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| 少样本 | 84.15 / 72.65 | 35.77 / 32.08 / 6.46 | 72.98 / 4.82 | 68.34 / 38.23
    / 5.67 |'
- en: '| PASTA | Task-agnostic | 46.68 / 34.71 | 91.62 / 88.60 / 3.00 | 80.84 / 4.92
    | 99.54 / 99.57 / 5.11 |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| PASTA | 任务无关 | 46.68 / 34.71 | 91.62 / 88.60 / 3.00 | 80.84 / 4.92 | 99.54
    / 99.57 / 5.11 |'
- en: '| Multi-task | 91.50 / 18.63 | 92.96 / 91.34 / 4.91 | 94.96 / 4.87 | 98.62
    / 98.79 / 5.11 |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| 多任务 | 91.50 / 18.63 | 92.96 / 91.34 / 4.91 | 94.96 / 4.87 | 98.62 / 98.79
    / 5.11 |'
- en: 'Table 10: Varying head selection strategies between top top task-specific heads,
    union across multiple tasks, and intersection (the default used in PASTA).'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '表 10: 顶级任务特定头部、多任务联合和交集 (PASTA 默认使用的) 之间的头部选择策略变化。'
- en: '|  | PASTA | JSON Format | Prons. Changing | BiasBios | CounterFact |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '|  | PASTA | JSON 格式 | 语代词变化 | BiasBios | CounterFact |'
- en: '|  | F. Acc / P. Acc | Acc / A.Acc / Flue. | Acc / Flue. | ES / PS /Flue. |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '|  | F. Acc / P. Acc | Acc / A.Acc / 流畅度 | Acc / 流畅度 | ES / PS / 流畅度 |'
- en: '| LLAMA | Task-specific | 95.56 / 86.83 | 98.52 / 98.02 / 5.92 | 97.62 / 4.18
    | 99.18 / 99.24 / 4.93 |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| LLAMA | 任务特定 | 95.56 / 86.83 | 98.52 / 98.02 / 5.92 | 97.62 / 4.18 | 99.18
    / 99.24 / 4.93 |'
- en: '| union | 88.42 / 74.49 | 92.12 / 91.44 / 4.88 | 96.36 / 4.13 | 99.24 / 99.35
    / 4.53 |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| 联合 | 88.42 / 74.49 | 92.12 / 91.44 / 4.88 | 96.36 / 4.13 | 99.24 / 99.35
    / 4.53 |'
- en: '| intersection | 96.64 / 85.09 | 96.42 / 95.84 / 5.43 | 95.28 / 4.05 | 99.60
    / 99.57 / 4.89 |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| 交集 | 96.64 / 85.09 | 96.42 / 95.84 / 5.43 | 95.28 / 4.05 | 99.60 / 99.57
    / 4.89 |'
- en: '| GPT-J | Task-specific | 85.71 / 79.39 | 94.74 / 92.54 / 5.07 | 97.64 / 5.06
    | 99.26 / 99.34 / 4.94 |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| GPT-J | 任务特定 | 85.71 / 79.39 | 94.74 / 92.54 / 5.07 | 97.64 / 5.06 | 99.26
    / 99.34 / 4.94 |'
- en: '| Union | 72.61 / 64.89 | 89.68 / 87.76 / 3.92 | 95.56 / 5.02 | 99.82 / 99.83
    / 5.03 |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| 联合 | 72.61 / 64.89 | 89.68 / 87.76 / 3.92 | 95.56 / 5.02 | 99.82 / 99.83
    / 5.03 |'
- en: '| Intersection | 91.50 / 18.63 | 92.96 / 91.34 / 4.91 | 94.96 / 4.87 | 98.62
    / 98.79 / 5.11 |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| 交集 | 91.50 / 18.63 | 92.96 / 91.34 / 4.91 | 94.96 / 4.87 | 98.62 / 98.79
    / 5.11 |'
- en: Appendix C Extended results
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 C 扩展结果
- en: C.1 The variance of few-shot performance
  id: totrans-267
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.1 少量示例性能的方差
- en: Few-shot prompting sometimes leads to improvements in model performance. as
    explicitly providing the examples in additional demonstrations. However, a drawback
    of few-shot prompting is its instability, meaning its performance exhibits high
    variance across different samples in the demonstratio. In this section, we present
    the results to show that the performance of few-shot prompting displays high variance
    in terms of sampling different few-shot demonstrations.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 少量示例提示有时会导致模型性能的提升，尤其是明确提供额外演示中的示例。然而，少量示例提示的一个缺点是其不稳定性，即其性能在不同示例中表现出高度方差。在本节中，我们展示了少量示例提示在不同示例中表现出高度方差的结果。
- en: 'Table 11: The few-shot performance (Acc. / A. Acc. / Fluency) on the Pronouns
    Changing task.'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '表 11: 语代词变化任务上的少量示例性能 (Acc. / A. Acc. / 流畅度)。'
- en: '| Few-shot examples | LLAMA-7B | GPT-J-6B |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| 少量示例 | LLAMA-7B | GPT-J-6B |'
- en: '| Demonstration 1 | 84.87 / 90.09 / 4.74 | 43.82 / 40.36 / 6.43 |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| 演示 1 | 84.87 / 90.09 / 4.74 | 43.82 / 40.36 / 6.43 |'
- en: '| Demonstration 2 | 57.24 / 53.98 / 6.22 | 40.68 / 37.86 / 6.44 |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| 演示 2 | 57.24 / 53.98 / 6.22 | 40.68 / 37.86 / 6.44 |'
- en: '| Demonstration 3 | 57.08 / 53.22 / 6.02 | 33.13 / 29.21 / 6.48 |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| 演示 3 | 57.08 / 53.22 / 6.02 | 33.13 / 29.21 / 6.48 |'
- en: '| Demonstration 4 | 52.26 / 48.30 / 6.42 | 25.47 / 20.89 / 6.44 |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| 演示 4 | 52.26 / 48.30 / 6.42 | 25.47 / 20.89 / 6.44 |'
- en: '| Demonstration 5 | 43.86 / 40.78 / 6.43 | 11.90 / 8.63 / 6.51 |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| 演示 5 | 43.86 / 40.78 / 6.43 | 11.90 / 8.63 / 6.51 |'
- en: C.2 Model Profiling Results
  id: totrans-276
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.2 模型性能概况
- en: 'In this Section, we provide more results of the performance of LLAMA-7B on
    all of tasks when steering: (i) all heads; (ii) entire layer; (iii) a individual
    head of a layer.'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们提供了 LLAMA-7B 在所有任务上的更多结果，当调整: (i) 所有头部；(ii) 整个层；(iii) 单个层的头部。'
- en: '![Refer to caption](img/cc9c704057f339022bfe2df81e9d7886.png)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/cc9c704057f339022bfe2df81e9d7886.png)'
- en: 'Figure 4: The performance of LLAMA-7B on Pronouns Changing task when we steer
    (i) all heads (green); (ii) entrie layer (yellow); and (iii) individual head with
    a layer (blue violin plot). The performance varies dramatically across layers
    and across heads of a layer.'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '图 4: LLAMA-7B 在语代词变化任务上的表现，当我们调整 (i) 所有头部 (绿色)；(ii) 整个层 (黄色)；和 (iii) 单个头部与层
    (蓝色小提琴图)。表现随层和层内头部的不同而剧烈变化。'
- en: '![Refer to caption](img/4fcc1394bbabe8980a2f493089a6b36c.png)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/4fcc1394bbabe8980a2f493089a6b36c.png)'
- en: 'Figure 5: The performance of LLAMA-7B on BiasBios task when we steer (i) all
    heads (green); (ii) entrie layer (yellow); and (iii) individual head with a layer
    (blue violin plot). The performance varies dramatically across layers and across
    heads of a layer.'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '图 5: LLAMA-7B 在 BiasBios 任务上的表现，当我们调整 (i) 所有头部 (绿色)；(ii) 整个层 (黄色)；和 (iii) 单个头部与层
    (蓝色小提琴图)。表现随层和层内头部的不同而剧烈变化。'
- en: '![Refer to caption](img/163f8f98b8500b9789057cd50443ac79.png)'
  id: totrans-282
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/163f8f98b8500b9789057cd50443ac79.png)'
- en: 'Figure 6: The performance of LLAMA-7B on CounterFact task when we steer (i)
    all heads (green); (ii) entrie layer (yellow); and (iii) individual head with
    a layer (blue violin plot). The performance varies dramatically across layers
    and across heads of a layer.'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：LLAMA-7B 在 CounterFact 任务上的表现，当我们引导 (i) 所有头部（绿色）；(ii) 整个层（黄色）；以及 (iii) 单个头部与一个层（蓝色小提琴图）。表现因层和层的头部而异。
