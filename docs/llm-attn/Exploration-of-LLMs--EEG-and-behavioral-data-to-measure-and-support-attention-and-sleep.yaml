- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 18:52:24'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:52:24
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Exploration of LLMs, EEG and behavioral data to measure and support attention
    and sleep
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索大型语言模型（LLMs）、脑电图（EEG）和行为数据以测量和支持注意力和睡眠
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2408.07822](https://ar5iv.labs.arxiv.org/html/2408.07822)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2408.07822](https://ar5iv.labs.arxiv.org/html/2408.07822)
- en: Akane Sano Rice University USA
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Akane Sano 莱斯大学 美国
- en: akane.sano@rice.edu    Judith Amores Microsoft Research USA
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: akane.sano@rice.edu    Judith Amores 微软研究院 美国
- en: judithamores@microsoft.com    Mary Czerwinski Microsoft Research USA
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: judithamores@microsoft.com    Mary Czerwinski 微软研究院 美国
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: We explore the application of large language models (LLMs), pre-trained models
    with massive textual data for detecting and improving these altered states. We
    investigate the use of LLMs to estimate attention states, sleep stages, and sleep
    quality and generate sleep improvement suggestions and adaptive guided imagery
    scripts based on electroencephalogram (EEG) and physical activity data (e.g. waveforms,
    power spectrogram images, numerical features). Our results show that LLMs can
    estimate sleep quality based on human textual behavioral features and provide
    personalized sleep improvement suggestions and guided imagery scripts; however
    detecting attention, sleep stages, and sleep quality based on EEG and activity
    data requires further training data and domain-specific knowledge.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们探索了大型语言模型（LLMs）的应用，这些模型通过大量文本数据进行预训练，用于检测和改善这些改变的状态。我们研究了使用LLMs来估计注意力状态、睡眠阶段和睡眠质量，并根据脑电图（EEG）和身体活动数据（例如波形、功率谱图图像、数值特征）生成睡眠改善建议和自适应引导图像脚本。我们的结果表明，LLMs可以基于人类文本行为特征估计睡眠质量，并提供个性化的睡眠改善建议和引导图像脚本；然而，基于EEG和活动数据检测注意力、睡眠阶段和睡眠质量仍需进一步的训练数据和领域特定知识。
- en: 'Index Terms:'
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 索引词：
- en: Large Language Models, LLMs, sleep, attention, EEG
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）、睡眠、注意力、脑电图（EEG）
- en: I Introduction
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I 引言
- en: Human altered states such as attention and sleep play significant roles in health
    [[1](#bib.bib1)], safety [[2](#bib.bib2)] , and productivity[[3](#bib.bib3)] .
    By precisely measuring these states, we can design adaptive tools and interfaces
    that respond effectively to users and help promote their health.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 人类的改变状态如注意力和睡眠在健康[[1](#bib.bib1)]、安全[[2](#bib.bib2)]和生产力[[3](#bib.bib3)]中扮演着重要角色。通过准确测量这些状态，我们可以设计响应用户的自适应工具和界面，并帮助促进他们的健康。
- en: Human attention states have been measured using physiological and behavioral
    data such as electroencephalogram (EEG) [[4](#bib.bib4)], facial expressions [[5](#bib.bib5)],
    and eye tracking[[6](#bib.bib6)]. . Measuring human attention states can help
    design systems that enhance driver alertness, minimize interruptions during focus,
    or promote relaxation before sleep.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 人类的注意力状态已通过生理和行为数据如脑电图（EEG）[[4](#bib.bib4)]、面部表情[[5](#bib.bib5)]和眼动追踪[[6](#bib.bib6)]进行测量。测量人类注意力状态可以帮助设计增强驾驶员警觉性的系统、减少专注期间的干扰，或促进睡前放松。
- en: Extensive research has explored computational methods for measuring, evaluating,
    and improving sleep. For example, many algorithms have been developed to estimate
    sleep quality and stages using human physiological and behavioral sensor data
    including EEG and motion[[7](#bib.bib7)]. Computational systems have been designed
    to promote better sleep[[8](#bib.bib8)].
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 大量研究探讨了用于测量、评估和改善睡眠的计算方法。例如，许多算法已被开发出来，利用人类生理和行为传感器数据，包括EEG和运动[[7](#bib.bib7)]，来估计睡眠质量和阶段。计算系统已被设计用来促进更好的睡眠[[8](#bib.bib8)]。
- en: Recent advances in natural language processing have leveraged massive textual
    data to train large language models (LLMs). Some studies have used LLMs for understanding
    human physiological and behavioral data and designing health applications including
    EEG abnormality detection and wearable sensor-based sleep quality detection[[9](#bib.bib9)][[10](#bib.bib10)].
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言处理的最新进展利用了大量文本数据来训练大型语言模型（LLMs）。一些研究已使用LLMs来理解人类生理和行为数据，并设计健康应用，包括EEG异常检测和基于可穿戴传感器的睡眠质量检测[[9](#bib.bib9)][[10](#bib.bib10)]。
- en: LLMs hold promise for health applications including human altered state detection
    and personalized feedback delivery; however, rigorous evaluations have not been
    conducted, particularly regarding the integration of different human physiological
    and behavioral data (e.g., waveforms, numerical features, power spectrogram images)
    into LLMs for understanding the potential, accuracy, limitations, and reliability
    of the models.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 在健康应用方面具有潜力，包括人类改变状态检测和个性化反馈提供；然而，尚未进行严格评估，特别是关于将不同的人体生理和行为数据（例如，波形、数值特征、功率谱图像）整合到
    LLMs 中，以理解模型的潜力、准确性、局限性和可靠性。
- en: 'In this paper, we evaluate LLMs for detecting and supporting human attention
    and sleep. Our ultimate goal is to create personalized, adaptive systems that
    enhance individuals’ attention and sleep. To achieve this, in this paper, we conduct
    early explorations by integrating biobehavioral data into LLMs to understand their
    capabilities. We ask the following two research questions in the paper:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们评估了 LLMs 在检测和支持人类注意力及睡眠方面的表现。我们的*终极目标*是创建个性化的、自适应的系统，以增强个人的注意力和睡眠。为此，本文通过将生物行为数据整合到
    LLMs 中进行早期探索，以了解其能力。我们在文中提出了以下两个研究问题：
- en: '1.'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Can LLMs interpret/sense attentive states, sleep stages, and sleep quality?
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LLMs 能否解读/感知注意状态、睡眠阶段和睡眠质量？
- en: '2.'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Can LLMs provide personalized and adaptive feedback to help improve sleep?
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LLMs 能否提供个性化和自适应的反馈以帮助改善睡眠？
- en: We investigate the impact of various time scales and different input modalities
    of EEG, motion, and textual data on LLMs’ performance, reasonings, and generated
    responses for detecting attention states, sleep stages, and sleep quality detection
    and improving sleep.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究了不同时间尺度以及 EEG、运动和文本数据的不同输入模式对 LLMs 在检测注意状态、睡眠阶段和睡眠质量方面的性能、推理和生成响应的影响。
- en: II Methods
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 方法
- en: We describe experiments and datasets for 1) user state detection and 2) sleep
    improvement suggestion generation to address RQ 1 and 2.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们描述了用于 1) 用户状态检测和 2) 睡眠改善建议生成的实验和数据集，以解决 RQ 1 和 RQ 2。
- en: 'II-A Experiment 1: user state detection'
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-A 实验 1：用户状态检测
- en: We conduct three different detection tasks, a) attention detection, b) sleep
    stage detection, and c) sleep quality detection.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行三种不同的检测任务，a) 注意力检测，b) 睡眠阶段检测，和 c) 睡眠质量检测。
- en: II-A1 Datasets & Data processing
  id: totrans-29
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-A1 数据集与数据处理
- en: We use the following datasets for our experiments.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在实验中使用了以下数据集。
- en: 'Mental Attention State[[11](#bib.bib11)]: This dataset contains 25 hours of
    EEG data collected using 14 ch Emotive. Five participants were engaged in a low-intensity
    task of controlling a computer-simulated train. Three mental states were observed
    in this study: focused, unfocused, and drowsy. We merged unfocused and drowsy
    into an unfocused state. We prepared three different types of information for
    attention detection (focused vs unfocused/drowsy): a) filtered EEG data (Fig.
    [1(a)](#S2.F1.sf1 "In Figure 1 ‣ II-A1 Datasets & Data processing ‣ II-A Experiment
    1: user state detection ‣ II Methods ‣ Exploration of LLMs, EEG and behavioral
    data to measure and support attention and sleep")): Raw EEG signals were processed
    using a bandpass Butterworth filter (order: 128, 0-40Hz), b) time-frequency spectrograms(Fig.
    [1(b)](#S2.F1.sf2 "In Figure 1 ‣ II-A1 Datasets & Data processing ‣ II-A Experiment
    1: user state detection ‣ II Methods ‣ Exploration of LLMs, EEG and behavioral
    data to measure and support attention and sleep")): These were computed using
    wavelet transform (Daubechies wavelet, every 10 sec) to provide frequency components
    over time, and c) 11 features: these features include power spectrum density (delta,
    theta, alpha, beta), amplitude, standard deviation, kurtosis, alpha/delta, theta/alpha,
    delta/theta, the 90th percentile amplitude. We segmented the data into 10-sec
    intervals, resulting in 919 training samples, 230 validation samples, and 287
    test samples.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 精神注意状态[[11](#bib.bib11)]：该数据集包含25小时的EEG数据，使用14通道Emotive设备收集。五名参与者参与了一项低强度任务，即控制计算机模拟的火车。本研究观察到了三种精神状态：专注、分心和嗜睡。我们将分心和嗜睡合并为分心状态。我们为注意力检测（专注与分心/嗜睡）准备了三种不同类型的信息：a)
    过滤的EEG数据（图[1(a)](#S2.F1.sf1 "在图1中 ‣ II-A1 数据集与数据处理 ‣ II-A 实验1：用户状态检测 ‣ II 方法 ‣
    探索LLMs、EEG和行为数据以测量和支持注意力与睡眠"))：原始EEG信号经过带通Butterworth滤波器（阶数：128，0-40Hz）处理，b) 时间频率频谱图（图[1(b)](#S2.F1.sf2
    "在图1中 ‣ II-A1 数据集与数据处理 ‣ II-A 实验1：用户状态检测 ‣ II 方法 ‣ 探索LLMs、EEG和行为数据以测量和支持注意力与睡眠"))：这些频谱图使用小波变换（Daubechies小波，每10秒一次）计算，以提供随时间变化的频率成分，c)
    11个特征：这些特征包括功率谱密度（delta、theta、alpha、beta）、振幅、标准差、峰度、alpha/delta、theta/alpha、delta/theta、第90百分位振幅。我们将数据分段为10秒的间隔，得到919个训练样本、230个验证样本和287个测试样本。
- en: '![Refer to caption](img/858476c798dccd9e876176bc29a2d4cb.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/858476c798dccd9e876176bc29a2d4cb.png)'
- en: (a) EEG Waveform
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: (a) EEG波形
- en: '![Refer to caption](img/cb628aedcc77a79e3501aa18a41910c9.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/cb628aedcc77a79e3501aa18a41910c9.png)'
- en: (b) EEG Spectrogram
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: (b) EEG频谱图
- en: '![Refer to caption](img/3ca3f0c816877daf17b2c94f2c3aa9e5.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/3ca3f0c816877daf17b2c94f2c3aa9e5.png)'
- en: '(c) Actogram (x axis: time 0am-0am), y-axis: dates, z-axis:physical activity
    levels)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 活动图（x轴：时间0am-0am），y轴：日期，z轴：身体活动水平
- en: '![Refer to caption](img/606b7dc82b9db9225c95d3b1969bd35c.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/606b7dc82b9db9225c95d3b1969bd35c.png)'
- en: '(d) Averaged activity graph (x axis: time 0am-0am), y-axis: physical activity
    levels)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: (d) 平均活动图（x轴：时间0am-0am），y轴：身体活动水平
- en: 'Figure 1: Image Data Fed into LLMs'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：输入LLMs的图像数据
- en: 'Sleep EDF expanded[[12](#bib.bib12)]: This dataset contains 197 nights of polysomnography
    data collected from individuals aged 18-101 years. The data include EEG from two
    channels, Fpz-Cz and Pz-Oz, EOG, EMG, and event markers. Sleep stages are labeled
    as follows: 0 (Wake), 1 (stage 1), 2 (stage 2), 3 (stages 3 & 4), and 4 (REM sleep).
    We segmented the data into 30-sec epochs (training set: 152362 epochs, Validation
    set: 38092 epochs, test set: 500 epochs). We used Fpz-Cz for sleep stage detection.
    We used the same input types as those used for mental attention states: a) filtered
    EEG data, b) time-frequency spectrograms, and c) 11 features.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 睡眠EDF扩展[[12](#bib.bib12)]：该数据集包含197晚的多导睡眠监测数据，来自18至101岁的个体。数据包括两个通道的EEG，Fpz-Cz和Pz-Oz，EOG，EMG和事件标记。睡眠阶段标记如下：0（清醒）、1（阶段1）、2（阶段2）、3（阶段3和4）、4（REM睡眠）。我们将数据分段为30秒的时期（训练集：152362个时期，验证集：38092个时期，测试集：500个时期）。我们使用Fpz-Cz进行睡眠阶段检测。我们使用的输入类型与精神注意状态相同：a)
    过滤的EEG数据，b) 时间频率频谱图，以及c) 11个特征。
- en: 'Student Life[[13](#bib.bib13)]: This dataset contains mobile phone sensor and
    survey data collected from 46 college students. We used the Pittsburgh Sleep Quality
    Index (PSQI) (19 self-rated questions including sleep-related behaviors and self-reported
    sleep quality) administered both at the pre and post study and its scoring rules
    to categorize each participant as a poor or good sleeper. We use physical activity
    data collected from participants’ phones to compute participants’ daily activity
    levels and patterns. We assess sleep quality detection (good vs poor) using the
    following inputs: a) participants’ textual responses to PSQI questions, b) physical
    activity-based actograms: visual representations of 24 hour activity levels over
    days(Fig. [1(c)](#S2.F1.sf3 "In Figure 1 ‣ II-A1 Datasets & Data processing ‣
    II-A Experiment 1: user state detection ‣ II Methods ‣ Exploration of LLMs, EEG
    and behavioral data to measure and support attention and sleep")), and c) physical
    activity-based hourly averaged graphs: hourly levels and variations in physical
    activity (Fig. [1(d)](#S2.F1.sf4 "In Figure 1 ‣ II-A1 Datasets & Data processing
    ‣ II-A Experiment 1: user state detection ‣ II Methods ‣ Exploration of LLMs,
    EEG and behavioral data to measure and support attention and sleep")).'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 学生生活[[13](#bib.bib13)]：该数据集包含从46名大学生那里收集的手机传感器和调查数据。我们使用匹兹堡睡眠质量指数（PSQI）（包括19个自评问题，涉及睡眠相关行为和自报告的睡眠质量）在研究前后进行评估，并根据其评分规则将每个参与者分类为差睡眠者或优质睡眠者。我们利用从参与者手机中收集的身体活动数据来计算参与者的每日活动水平和模式。我们使用以下输入评估睡眠质量检测（好
    vs 差）：a) 参与者对PSQI问题的文本回答，b) 基于身体活动的活动图：24小时活动水平的视觉表示（见图 [1(c)](#S2.F1.sf3 "在图1
    ‣ II-A1 数据集与数据处理 ‣ II-A 实验1：用户状态检测 ‣ II 方法 ‣ 探索LLMs、EEG和行为数据来测量和支持注意力与睡眠")），以及
    c) 基于身体活动的小时均值图：每小时的身体活动水平和变化（见图 [1(d)](#S2.F1.sf4 "在图1 ‣ II-A1 数据集与数据处理 ‣ II-A
    实验1：用户状态检测 ‣ II 方法 ‣ 探索LLMs、EEG和行为数据来测量和支持注意力与睡眠")）。
- en: II-A2 Models
  id: totrans-43
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-A2 模型
- en: 'We compare various LLMs and traditional machine learning models. LLMs: 1) Zero-shot
    learning: we feed data (EEG waveform images, spectrograms, or features) into LLMs.
    No specific training is conducted and the LLMs leverage their pre-existing knowledge.
    We use two LLM variants: GPT 4 vision (2024-02-15-preview) for image input and
    GPT 4 (2023-05-15) for textual input, 2) In-context learning LLM: we include input
    data and label examples in prompts so that LLMs (GPT 4) learn from context and
    adapt their response accordingly. 3) Fine-tuned LLM: We finetune LLMs (GPT 3.5
    turbo 2024-02-15-preview) using training and validating datasets. A traditional
    machine learning model, XGBoost uses a technique called gradient boosting that
    combines simple decision trees for accurate predictions. We also analyze feature
    importance by looking at the number of times each feature is used for trees. 3)
    Baseline (majority vote): simply predicts the majority class for all test samples.
    It serves as a basic reference point to evaluate the performance of other models.
    For sleep quality detection, we also use the ground truth scoring method based
    on PSQI. We evaluate model performance using accuracy and weighted F1 score. Please
    see examples of LLM prompts in the Appendix.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们比较了各种LLMs和传统机器学习模型。LLMs：1) 零样本学习：我们将数据（EEG波形图像、声谱图或特征）输入LLMs。未进行特定训练，LLMs利用其预先存在的知识。我们使用两个LLM变体：GPT
    4 vision (2024-02-15-preview) 用于图像输入，GPT 4 (2023-05-15) 用于文本输入，2) 上下文学习LLM：我们在提示中包含输入数据和标签示例，以便LLMs（GPT
    4）从上下文中学习并相应调整其回应。3) 微调LLM：我们使用训练和验证数据集对LLMs（GPT 3.5 turbo 2024-02-15-preview）进行微调。传统机器学习模型XGBoost使用一种称为梯度提升的技术，结合简单的决策树以进行准确预测。我们还通过查看每个特征用于决策树的次数来分析特征重要性。3)
    基准（多数投票）：简单地预测所有测试样本的多数类别。它作为评估其他模型性能的基本参考点。对于睡眠质量检测，我们还使用基于PSQI的真实评分方法。我们通过准确度和加权F1分数来评估模型性能。请参见附录中的LLM提示示例。
- en: 'II-B Experiment 2: Personalized and adaptive sleep improvement feedback'
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-B 实验 2：个性化和自适应的睡眠改善反馈
- en: 'We explore whether LLMs can generate personalized content for sleep improvement
    and focus on generating 1) sleep improvement suggestions and 2) guided imagery
    scripts. To generate the sleep suggestions, we feed LLMs various user context
    or profile information including a) EEG features from Sleep EDF dataset, b) PSQI
    answers in Student Life dataset, c) physical activity-based actograms, d) gender,
    e) age group, f) ethnicity, g) health issues such as “anxiety”, “PTSD”, “insomnia”,
    “pain”, “awakenings during nights”, “shift worker”, h) user preferences such as
    favorite environments: beach, forest, favorite animals: dogs, cats; hobbies: traveling,
    baseball, exercise. To generate scripts to help a person sleep, we prompt the
    LLM to leverage a Guided Imagery technique [[14](#bib.bib14)]. This technique
    is also known as Guided Visualization, a mind-body technique that involves visualizing
    positive images or scenarios using all senses to help promote relaxation, manage
    anxiety, and stress, and enhance well-being. A typical session might include relaxation
    exercises, quiet sitting or lying down, and focusing on a specific goal. See prompt
    examples in the Appendix.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们探讨LLM是否可以生成个性化的内容以改善睡眠，并重点生成1）睡眠改善建议和2）引导意象脚本。为了生成睡眠建议，我们将LLM喂入各种用户背景或个人信息，包括a）来自睡眠EDF数据集的EEG特征，b）学生生活数据集中的PSQI答案，c）基于身体活动的活动图，d）性别，e）年龄组，f）种族，g）健康问题，如“焦虑”，“创伤后应激障碍”，“失眠”，“疼痛”，“夜间觉醒”，“轮班工人”，h）用户偏好，如喜欢的环境：海滩，森林，喜欢的动物：狗，猫；爱好：旅行，棒球，运动。为了生成帮助人们睡眠的脚本，我们提示LLM利用引导意象技术
    [[14](#bib.bib14)]。这种技术也被称为引导可视化，是一种身心技术，涉及使用所有感官来可视化积极的图像或情境，以促进放松、管理焦虑和压力，并提升幸福感。一个典型的会话可能包括放松练习、安静地坐或躺下，以及专注于特定目标。请参见附录中的提示示例。
- en: III Results
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III 结果
- en: III-A User state detection
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-A 用户状态检测
- en: III-A1 Attention detection
  id: totrans-49
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A1 注意力检测
- en: Table [I](#S3.T1 "TABLE I ‣ III-A1 Attention detection ‣ III-A User state detection
    ‣ III Results ‣ Exploration of LLMs, EEG and behavioral data to measure and support
    attention and sleep") summarizes attention detection performance. Traditional
    machine learning models outperformed LLM-based models for attention detection.
    Among the LLM models, fine-tuned GPT-3.5 models demonstrated the best performance.
    However, the GPT-4 vision model faced limitations. It failed to infer user states
    in approximately 25-30% of cases, often returning a generic response such as “As
    a text-based AI, I do not have the capability to process images and I cannot assist
    with this request”. In addition, when we feed high dimensional EEG features, the
    GPT model indicated that it requires machine learning models and did not infer
    user states,
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 [I](#S3.T1 "TABLE I ‣ III-A1 Attention detection ‣ III-A User state detection
    ‣ III Results ‣ Exploration of LLMs, EEG and behavioral data to measure and support
    attention and sleep") 总结了注意力检测的性能。传统的机器学习模型在注意力检测方面优于基于LLM的模型。在LLM模型中，经过微调的GPT-3.5模型表现最佳。然而，GPT-4视觉模型存在局限性。在大约25-30%的情况下，它无法推断用户状态，通常返回类似“作为一个基于文本的AI，我没有处理图像的能力，无法协助此请求”的通用响应。此外，当我们输入高维度的EEG特征时，GPT模型表示需要机器学习模型，并且无法推断用户状态。
- en: The fine-tuned GPT3.5 model typically shows high confidence levels of 100%.
    The model shows information about the power spectrum and ratios (e.g.,delta, theta,
    alpha, beta, alpha/delta) as the explanations for inference. For example, when
    correct inference is made with 100% confidence, the GPT 3.5 model explains “The
    participant is unfocused because the alpha/delta ratio is high and the beta power
    is low, which are indicative of a relaxed and unfocused state.”
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 经过微调的GPT-3.5模型通常显示100%的高置信度。该模型展示了功率谱和比率的信息（例如，delta，theta，alpha，beta，alpha/delta），作为推断的解释。例如，当以100%置信度进行正确推断时，GPT-3.5模型解释为“参与者未集中注意力，因为alpha/delta比率高，beta功率低，这些表明处于放松且未集中的状态。”
- en: Incorrect inferences lack clear explanations and appear based on simple heuristic
    rules. For example, when ground truth is focused but unfocused is inferred, the
    model said “The participant’s state is unfocused because the alpha/delta ratio
    for channel AF3 is 0.166027, which is below the threshold for focused state.”
    When ground truth is unfocused but focused is inferred, the model said “The participant
    is focused because the alpha/delta ratio is high and the beta power is low, which
    are characteristic of a focused state.”
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 不正确的推断缺乏明确解释，并且似乎基于简单的启发式规则。例如，当实际状态为集中但推断为未集中时，模型表示“参与者的状态为未集中，因为通道 AF3 的 alpha/delta
    比率为 0.166027，低于集中状态的阈值。”当实际状态为未集中但推断为集中时，模型表示“参与者集中，因为 alpha/delta 比率高且贝塔波功率低，这些特征通常与集中状态相关。”
- en: We also analyze feature importance from the XGBoost model and learn that the
    model uses more variety of features for classifying focus vs unfocus including
    channel O2 kurtosis, AF4 beta, F3 percent 90, F7 beta, and T8 standard deviation.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还分析了 XGBoost 模型的特征重要性，并了解到该模型在分类集中与未集中状态时使用了更多种类的特征，包括通道 O2 峰度、AF4 贝塔波、F3
    百分比 90、F7 贝塔波和 T8 标准差。
- en: 'TABLE I: Attention Detection'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 表 I：注意力检测
- en: '| Models | acc | F1 | note |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 准确率 | F1 | 备注 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Finetuned GPT3.5 (features) | 53.7 | 0.51 |  |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 微调 GPT3.5（特征） | 53.7 | 0.51 |  |'
- en: '| In-context GPT4v (spectrogram) | 55.7 | 0.56 | 25% “cannot assist” |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 上下文 GPT4v（光谱图） | 55.7 | 0.56 | 25% “无法协助” |'
- en: '| In-context GPT4 (features) | 50.0 | 0.57 | 97% “cannot assist” |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 上下文 GPT4（特征） | 50.0 | 0.57 | 97% “无法协助” |'
- en: '| Zero-shot GPT4v (spectrogram) | 66.2 | 0.55 | 30% “cannot assist” |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 零样本 GPT4v（光谱图） | 66.2 | 0.55 | 30% “无法协助” |'
- en: '| Zero-shot GPT4 (features) | - | - | 99% “cannot assist” |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 零样本 GPT4（特征） | - | - | 99% “无法协助” |'
- en: '| XGBoost (features) | 91.3 | 0.93 |  |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| XGBoost（特征） | 91.3 | 0.93 |  |'
- en: '| Baseline (majority vote) | 66.6 | 0.53 |  |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| 基准（多数投票） | 66.6 | 0.53 |  |'
- en: III-A2 Sleep stage detection
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A2 睡眠阶段检测
- en: Table [II](#S3.T2 "TABLE II ‣ III-A2 Sleep stage detection ‣ III-A User state
    detection ‣ III Results ‣ Exploration of LLMs, EEG and behavioral data to measure
    and support attention and sleep") summarizes sleep stage detection performance.
    LLM-based sleep detection shows lower performance than ML-based models. GPT 4
    vision models (both in-context learning and zero-shot learning) often return a
    message that they cannot assist with the task. In-context learning with EEG waveforms
    performs worse than zero-shot learning with EEG waveforms. In-context learning
    with EEG features seems more effective than the zero-shot LLM model with EEG features.
    GPT fine-tuned models show higher misclassification rates compared to XGBoost.
    For example, they misclassify wake as REM, stage 1 as stage 2, and REM as stage
    2\. However, stage 2 and stage 3 & 4 are similar (Fig.[2](#S3.F2 "Figure 2 ‣ III-A2
    Sleep stage detection ‣ III-A User state detection ‣ III Results ‣ Exploration
    of LLMs, EEG and behavioral data to measure and support attention and sleep")).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [II](#S3.T2 "TABLE II ‣ III-A2 Sleep stage detection ‣ III-A User state detection
    ‣ III Results ‣ Exploration of LLMs, EEG and behavioral data to measure and support
    attention and sleep") 总结了睡眠阶段检测的性能。基于 LLM 的睡眠检测表现低于基于 ML 的模型。GPT 4 视觉模型（包括上下文学习和零样本学习）通常返回不能协助任务的消息。使用
    EEG 波形的上下文学习表现不如使用 EEG 波形的零样本学习。使用 EEG 特征的上下文学习似乎比使用 EEG 特征的零样本 LLM 模型更有效。与 XGBoost
    相比，GPT 微调模型显示出更高的误分类率。例如，它们将清醒误分类为 REM，将阶段 1 误分类为阶段 2，将 REM 误分类为阶段 2。然而，阶段 2 与阶段
    3 和 4 相似（图 [2](#S3.F2 "Figure 2 ‣ III-A2 Sleep stage detection ‣ III-A User state
    detection ‣ III Results ‣ Exploration of LLMs, EEG and behavioral data to measure
    and support attention and sleep")）。
- en: 'The fine-tuned GPT 3.5 model shows inference confidence from 20 to 100 % (mean:
    79.7 %, median 80%, stdev: 9.7%). The model outputs the explanation that it uses
    power spectrum and ratio for classifying sleep stages. For example, when the model
    infers correct stage 3&4 sleep, it outputs “The dominant frequency bands in the
    EEG signal are delta and theta, with high power in both bands. The alpha and beta
    power are relatively low. The alpha delta ratio is low, indicating a higher proportion
    of slow wave activity. The theta alpha ratio is high, suggesting a predominance
    of theta activity. The delta theta ratio is also high, indicating a higher proportion
    of slow wave activity compared to theta activity. These features are indicative
    of stage 3 or 4 sleep, also known as slow wave sleep.”'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '微调后的 GPT 3.5 模型显示推断置信度从 20% 到 100%（均值: 79.7%，中位数 80%，标准差: 9.7%）。该模型输出的解释是使用功率谱和比率来分类睡眠阶段。例如，当模型推断正确的
    3&4 阶段睡眠时，它输出“EEG 信号中的主频带是 delta 和 theta，两者的功率都很高。Alpha 和 beta 的功率相对较低。Alpha delta
    比率低，表明慢波活动的比例较高。Theta alpha 比率高，提示 theta 活动的主导地位。Delta theta 比率也高，表明慢波活动相对于 theta
    活动的比例较高。这些特征表明阶段 3 或 4 的睡眠，也称为慢波睡眠。”'
- en: The important features extracted from the XGBoost model show kurtosis, mean,
    standard deviation, and 90th percentile amplitude in addition to power spectrum
    and ratio features.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 从 XGBoost 模型中提取的重要特征显示了峰度、均值、标准差和第 90 百分位幅度，以及功率谱和比率特征。
- en: 'TABLE II: Sleep Stage Detection'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '表 II: 睡眠阶段检测'
- en: '| Models | acc | F1 | note |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 准确率 | F1 | 备注 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Finetuned GPT3.5 (features) | 50.6 | 0.46 |  |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 微调 GPT3.5 (特性) | 50.6 | 0.46 |  |'
- en: '| In-context GPT4v (EEG signals) | 25.4 | 0.21 | 51% “cannot assist” |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| In-context GPT4v (EEG 信号) | 25.4 | 0.21 | 51% “无法协助” |'
- en: '| In-context GPT4 (features) | 44.7 | 0.40 | 8% “cannot assist” |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| In-context GPT4 (特性) | 44.7 | 0.40 | 8% “无法协助” |'
- en: '| Zero-shot GPT4v (EEG signals) | 19.2 | 0.19 | 13% “cannot assist” |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| Zero-shot GPT4v (EEG 信号) | 19.2 | 0.19 | 13% “无法协助” |'
- en: '| Zero-shot GPT4 (features) | 29.0 | 0.25 | 0.2% “cannot assist” |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| Zero-shot GPT4 (特性) | 29.0 | 0.25 | 0.2% “无法协助” |'
- en: '| XGBoost (features) | 75.6 | 0.74 |  |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| XGBoost (特性) | 75.6 | 0.74 |  |'
- en: '| Baseline (majority vote) | 37.2 | 0.20 |  |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 基线（多数投票） | 37.2 | 0.20 |  |'
- en: '![Refer to caption](img/b2def9bf89b1fae91c6e1d8c4766c880.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/b2def9bf89b1fae91c6e1d8c4766c880.png)'
- en: 'Figure 2: Sleep stage detection models: confusion matrix'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '图 2: 睡眠阶段检测模型: 混淆矩阵'
- en: III-A3 Sleep quality detection
  id: totrans-80
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A3 睡眠质量检测
- en: 'We compare sleep quality detection (good vs poor sleep; confidence levels)
    using two approaches: (1) scored by PSQI standard scoring procedure vs. 2) GPT4
    (Table [III](#S3.T3 "TABLE III ‣ III-A3 Sleep quality detection ‣ III-A User state
    detection ‣ III Results ‣ Exploration of LLMs, EEG and behavioral data to measure
    and support attention and sleep")). Overall accuracy of the GPT4 model is 85.7%.
    There are 11 error cases out of 77\. GPT-4 demonstrates relatively good sleep
    quality detection performance based on textual answers to PSQI; however, GPT-4
    struggles to recognize sleep quality accurately when participants show poor sleep
    behavior (e.g., short sleep, difficulty falling asleep, or disrupted sleep) but
    good self-reported sleep quality (inference confidence is also low (60-65 %).
    GPT seems to emphasize subjective sleep quality over answers to other PSQI questions.
    Confidence levels of the GPT fine-tuned model are 60-100 % (mean: 80% and std:
    7.9 %). The confidence level is high when self-reported sleep quality is consistent
    with sleep behaviors (e.g. very bad self-reported sleep quality and poor sleep
    related behaviors such as long sleep latency, awakenings during the night, bad
    dreams, pain, feeling too cold, worry, and difficulty maintaining enthusiasm for
    daily activities).'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '我们使用两种方法比较睡眠质量检测（好睡眠与差睡眠；置信水平）: (1) 使用 PSQI 标准评分程序与 (2) GPT4 (表 [III](#S3.T3
    "表 III ‣ III-A3 睡眠质量检测 ‣ III-A 用户状态检测 ‣ III 结果 ‣ 探索 LLM、EEG 和行为数据来衡量和支持注意力及睡眠")).
    GPT4 模型的总体准确率为 85.7%。在 77 个案例中有 11 个错误案例。GPT-4 基于对 PSQI 的文本回答展示了相对较好的睡眠质量检测性能；然而，当参与者表现出差的睡眠行为（例如，睡眠时间短、入睡困难或睡眠中断）但自我报告的睡眠质量良好时，GPT-4
    准确识别睡眠质量的能力较差（推断置信度也低（60-65%））。GPT 似乎更强调主观睡眠质量而非对其他 PSQI 问题的回答。当自我报告的睡眠质量与睡眠行为一致时（例如，极差的自我报告睡眠质量与如长入睡潜伏期、夜间觉醒、噩梦、疼痛、感到寒冷、担忧以及维持日常活动热情困难等差的睡眠相关行为），置信水平较高。'
- en: LLMs detect sleep and active periods and regular sleep patterns from the physical
    activity actograms and averaged graphs provided; however, the image data fed into
    LLMs are recognized as poor sleep. LLMs easily pick up some physical activities
    during the night time that occurred only a few nights out of 60 days of data and
    recognize them as a sign of poor sleep. For instance, when the actograms show
    increased activity after 5 am for a few days out of 60 days of data, suggesting
    potential wakefulness, LLMs misinterpret this as poor sleep quality. This implies
    GPT-4’s limitations about the challenge of understanding a full range of human
    sleep behavior and variabilities. Sleep quality is multifaceted and LLMs might
    not fully grasp the nuances.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs从提供的身体活动图表和平均图中检测睡眠和活动周期及规律睡眠模式；然而，输入LLMs的图像数据被识别为睡眠质量差。LLMs容易把仅在60天数据中的几晚发生的某些夜间身体活动误认为是睡眠质量差的标志。例如，当图表显示在60天数据中的几天5点后活动增加，暗示可能的清醒状态时，LLMs将其误解为睡眠质量差。这表明GPT-4在理解全范围的人类睡眠行为和变异性方面的局限性。睡眠质量是多方面的，LLMs可能无法完全掌握其细微差别。
- en: 'TABLE III: Sleep Quality Detection'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '表格 III: 睡眠质量检测'
- en: '| PSQI scoring | GPT4 response | # of participants |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| PSQI评分 | GPT4响应 | 参与者数量 |'
- en: '| good | good | 39 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 好 | 好 | 39 |'
- en: '| poor | poor | 27 |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 差 | 差 | 27 |'
- en: '| good | poor | 0 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 好 | 差 | 0 |'
- en: '| poor | good | 11 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 差 | 好 | 11 |'
- en: III-B Sleep Improvement Feedback Generation
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-B 睡眠改善反馈生成
- en: LLMs modify suggestions and guided imagery scripts based on user input and profiles
    (e.g., symptoms, user preferences). Tables [V](#S3.T5 "TABLE V ‣ III-B Sleep Improvement
    Feedback Generation ‣ III Results ‣ Exploration of LLMs, EEG and behavioral data
    to measure and support attention and sleep") and [IV](#S3.T4 "TABLE IV ‣ III-B
    Sleep Improvement Feedback Generation ‣ III Results ‣ Exploration of LLMs, EEG
    and behavioral data to measure and support attention and sleep") show examples
    of sleep improvement suggestions and guided imagery scripts based on user profiles.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs根据用户输入和个人资料（例如，症状、用户偏好）修改建议和引导性图像脚本。表格 [V](#S3.T5 "TABLE V ‣ III-B 睡眠改善反馈生成
    ‣ III 结果 ‣ LLMs、EEG 和行为数据在测量和支持注意力与睡眠中的应用") 和 [IV](#S3.T4 "TABLE IV ‣ III-B 睡眠改善反馈生成
    ‣ III 结果 ‣ LLMs、EEG 和行为数据在测量和支持注意力与睡眠中的应用") 显示了基于用户资料的睡眠改善建议和引导性图像脚本的示例。
- en: 'LLMs generate sleep improvement suggestions that align with cognitive behavioral
    therapy for insomnia (CBT-i)[[15](#bib.bib15)]: (1) consistent sleep schedule,
    (2) avoid late night activities, (3) avoid fluids close to bedtime, (4) try relaxation
    techniques to help fall asleep and improve sleep quality, (5) restful room environment
    (light, temperature), (6) reduce caffeine intake, large meals, alcohol before
    bed, and (7) regular exercise. LLMs also weave user profiles (e.g. what they like,
    and issues they have) into generated guided imagery scripts and change scenes
    and phrases.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs生成的睡眠改善建议与认知行为疗法（CBT-i）[[15](#bib.bib15)]相一致：（1）保持一致的睡眠时间表，（2）避免夜间活动，（3）避免临睡前摄入液体，（4）尝试放松技巧以帮助入睡并改善睡眠质量，（5）舒适的房间环境（光线、温度），（6）减少咖啡因摄入、大餐和临睡前饮酒，以及（7）定期锻炼。LLMs还将用户资料（例如他们喜欢什么和他们遇到的问题）融入生成的引导性图像脚本中，并更改场景和短语。
- en: When we feed EEG features for generating guided imagery scripts, if we just
    simply ask LLM to generate a script based on EEG features, LLM incorporates numerical
    information into guided imagery scripts such as ”As you sink deeper into this
    state of relaxation, there is a harmonious balance between theta and alpha waves
    with a ratio of 2.3\. ” For users, hearing specific numerical information about
    EEG features might not be useful because they might not know how those numbers
    are associated with their states, therefore, we adjust prompts not to include
    numerical information in the generated guided imagery script (Table [V](#S3.T5
    "TABLE V ‣ III-B Sleep Improvement Feedback Generation ‣ III Results ‣ Exploration
    of LLMs, EEG and behavioral data to measure and support attention and sleep"),
    Appendix for a prompt example). Further tuning of prompt design and evaluation
    are required to generate effective adaptive feedback. Sleep improvement suggestions
    do not change based on EEG features because suggestions are not based on momentary
    EEG features but habitual sleep related behaviors.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将脑电图特征用于生成引导图像脚本时，如果我们仅仅要求LLM基于脑电图特征生成脚本，LLM会将数值信息融入引导图像脚本中，比如“当你深入这种放松状态时，theta波和alpha波之间的比例是2.3”。对于用户来说，听到关于脑电图特征的具体数值信息可能没有用，因为他们可能不知道这些数字如何与他们的状态相关，因此我们调整提示，以不包含生成引导图像脚本中的数值信息（表[V](#S3.T5
    "TABLE V ‣ III-B 睡眠改善反馈生成 ‣ III 结果 ‣ 探索LLMs、EEG和行为数据来测量和支持注意力和睡眠")，附录中有提示示例）。需要进一步调整提示设计和评估，以生成有效的自适应反馈。睡眠改善建议不基于脑电图特征，因为建议不基于瞬时脑电图特征，而是基于习惯性睡眠相关行为。
- en: 'TABLE IV: GPT4-generated sleep improvement suggestions'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 表IV：GPT4生成的睡眠改善建议
- en: '| Profiles | LLM-generated Suggetsions |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 简介 | LLM生成的建议 |'
- en: '| --- | --- |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Headaches disturb sleep |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 头痛干扰睡眠 |'
- en: '&#124; Check with a medical professional about the headaches to see if they
    can be treated &#124;'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 向医疗专业人士咨询头痛，看看是否可以治疗。 &#124;'
- en: '|'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Trying to solve coding problems in bed |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 尝试在床上解决编码问题 |'
- en: '&#124; Avoid activities such as coding which could generate stress and disrupt
    sleep &#124;'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 避免如编码等可能产生压力并扰乱睡眠的活动。 &#124;'
- en: '|'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Bed feels uncomfortable |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 床垫不舒适 |'
- en: '&#124; Maybe consider investing in a new mattress or bedding if your current
    one feels uncomfortable &#124;'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 如果你目前的床垫或床上用品感觉不舒适，可能考虑投资新的床垫或床上用品。 &#124;'
- en: '|'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Stress |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 压力 |'
- en: '&#124; Engagement in stress-relieving activities such as yoga, mindfulness,
    &#124;'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 参与如瑜伽、正念等减压活动。 &#124;'
- en: '&#124; and deep-breathing can help in reducing stress levels which can improve
    sleep quality &#124;'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 深呼吸有助于降低压力水平，从而改善睡眠质量。 &#124;'
- en: '|'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| OCD |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 强迫症 |'
- en: '&#124; Consultation with a Sleep Specialist or mental health professional may
    also be beneficial, &#124;'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 咨询睡眠专家或心理健康专业人士也可能有益。 &#124;'
- en: '&#124; especially since OCD was mentioned as a reason for troubled sleep &#124;'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 特别是因为提到了强迫症作为导致睡眠问题的原因。 &#124;'
- en: '|'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 'TABLE V: GPT4-generated guided imagery scripts'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 表V：GPT4生成的引导图像脚本
- en: '| Profiles | LLM-generated Guided Imagery Scripts |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 简介 | LLM生成的引导图像脚本 |'
- en: '| --- | --- |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Like Beach |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 像海滩一样 |'
- en: '&#124; Close your eyes and imagine yourself on a peaceful beach; Begin with
    lying down in a comfortable position. &#124;'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 闭上眼睛，想象自己在一个宁静的海滩上；先躺在一个舒适的位置。 &#124;'
- en: '&#124; Close your eyes and take a couple of deep breaths, inhaling and exhaling
    gradually. &#124;'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 闭上眼睛，深呼吸几次，逐渐吸气和呼气。 &#124;'
- en: '&#124; Visualize the calming view of a beach, the sand beneath your feet, the
    tranquil waves that are rhythmically kissing the shore. &#124;'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 视觉化海滩的宁静景象，脚下的沙子，节奏一致地吻着岸边的宁静波浪。 &#124;'
- en: '&#124; Feel the warmth of the sun on your skin, the softness of the sand as
    it molds perfectly to your feet. &#124;'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 感受阳光温暖的照射在你的皮肤上，感受沙子在脚下柔软地贴合。 &#124;'
- en: '&#124; Hear the distant sound of seagulls, the gentle lull of the waves. Breathe
    in the refreshing, salty sea air. &#124;'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 听到远处海鸥的声音，波浪的轻柔起伏。吸入清新的咸海风。 &#124;'
- en: '&#124; With every breath you take, your body feels lighter and sleepier. &#124;'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 每一次呼吸，你的身体都感觉更加轻盈和困倦。 &#124;'
- en: '&#124; Let this calming beach imagery help to lower your heart rate and help
    you drift off to sleep. &#124;'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 让这种宁静的海滩景象帮助你降低心率，助你安然入睡。 &#124;'
- en: '|'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Like Family |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 像家庭一样 |'
- en: '&#124; Close your eyes and imagine you’re sitting in a cozy, comfortable family
    room. The room is warm, inviting, and filled with &#124;'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 闭上眼睛，想象自己坐在一个舒适的家庭房间里。房间温暖、舒适，充满了 &#124;'
- en: '&#124; soft, dimmed light that creates a soothing atmosphere; This scene prompts
    feelings of relaxation, comfort, and safety, associated &#124;'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 柔和的昏暗光线营造出舒缓的氛围；这个场景引发放松、舒适和安全感，相关的 &#124;'
- en: '&#124; with being surrounded by loved ones. You see all your loved ones gathered,
    chatting, and enjoying each other’s company. &#124;'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 被亲人环绕。你看到你所有的亲人聚集在一起，聊天，享受彼此的陪伴。 &#124;'
- en: '&#124; There’s a gentle hum of relaxed conversation and soft laughter, the
    sounds of your family’s voices proving to be the most &#124;'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 轻柔的放松对话声和柔和的笑声，你家人的声音被证明是你听过的最 &#124;'
- en: '&#124; calming sounds you’ve ever heard; Hearing familiar voices has been shown
    to reduce stress and anxiety, allowing your &#124;'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 镇静的声音；听到熟悉的声音已被证明能减少压力和焦虑，让你的 &#124;'
- en: '&#124; mind to unwind and merge into a relaxation state suitable for sleep.
    You feel an overwhelming sense of love, joy, and peace &#124;'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 使心灵放松并融入适合睡眠的放松状态。你感到一种压倒性的爱、快乐和宁静 &#124;'
- en: '&#124; as you sit there surrounded by the people who matter the most. Outside
    the room, you see through the window that it’s &#124;'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 当你坐在那里，被最重要的人环绕时。你透过窗户看到外面 &#124;'
- en: '&#124; nighttime with a sky full of stars and the moon shining brightly, creating
    a perfect scenery indicating it’s time for you to sleep…. &#124;'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 夜晚星空璀璨，月光明亮，营造出完美的景象，表明是时候入睡了…. &#124;'
- en: '|'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| PTSD |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| 创伤后应激障碍 (PTSD) |'
- en: '&#124; Imagine you’re in a beautiful, peaceful forest; Begin by closing your
    eyes and taking several deep breaths, in through the &#124;'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 想象你身处于一个美丽、宁静的森林中；开始时闭上眼睛，深呼吸几次，通过 &#124;'
- en: '&#124; nose and out through the mouth. As you continue these slow, deep breaths,
    begin to visualize yourself standing at the edge &#124;'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 通过鼻子吸气，口中呼气。当你继续这些缓慢而深沉的呼吸时，开始想象自己站在 &#124;'
- en: '&#124; of a beautiful, calm forest….This forest is your safe space, a haven
    untouched by past trauma. You can stay here as long as &#124;'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 一个美丽、宁静的森林….这个森林是你的安全空间，一个未被过去创伤触及的避风港。你可以在这里待多久 &#124;'
- en: '&#124; you need, resting in the peaceful ambiance. No harm can find you here.
    Continue to cultivate this sense of peace and safety &#124;'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 你所需要的，沉浸在宁静的氛围中。这里没有伤害能找到你。继续培养这种和平和安全感 &#124;'
- en: '&#124; with each deep, calming breath…. &#124;'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 每一次深呼吸…. &#124;'
- en: '|'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Insomnia |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 失眠 (Insomnia) |'
- en: '&#124; Imagine yourself in a serene, beautiful forest; As insomnia has been
    bothering you, positive visualization can aid in releasing &#124;'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 想象你自己在一个宁静、美丽的森林中；由于失眠困扰你，积极的可视化有助于释放 &#124;'
- en: '&#124; negative energy and reduce stress…. &#124;'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 负面能量和减少压力…. &#124;'
- en: '|'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Shift workers |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| 值班工人 (Shift workers) |'
- en: '&#124; Relaxing Beach Journey; Begin by making yourself comfortable. Slowly
    take a deep breath in and as you exhale, close your &#124;'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 放松的海滩之旅；首先让自己感到舒适。缓慢地深呼吸，当你呼气时，闭上你的 &#124;'
- en: '&#124; eyes. …..For a shift worker, building a regular sleep schedule can be
    tough. Guided imagery can aid in achieving a relaxed &#124;'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 眼睛…..对于值班工人来说，建立规律的睡眠时间表可能很困难。引导可视化可以帮助实现放松 &#124;'
- en: '&#124; state quicker once in bed, making the most of the sleep time available…
    &#124;'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 一旦躺上床，迅速进入睡眠状态，充分利用可用的睡眠时间… &#124;'
- en: '|'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| EEG features |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 脑电图特征 (EEG features) |'
- en: '&#124; You are now entering the first stage of sleep, a stage of light sleep.
    This slow transition into sleep is marked by the gentle &#124;'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 你现在进入了睡眠的第一阶段，即浅睡阶段。这种缓慢的入睡过渡由轻柔的 &#124;'
- en: '&#124; wave-like rhythm of your alpha and theta powers. Your consciousness
    begins to dissolve into a calm and cloud-like tranquility… &#124;'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 你脑电波的α波和θ波呈波动状。你的意识开始融入一种平静而云雾般的宁静中… &#124;'
- en: '|'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: IV Discussion
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 讨论
- en: This work explores the usage of LLMs and physiological and behavioral sensor
    data for attention and sleep detection and sleep improvement. Our experiments
    highlight both LLMs’ strengths and limitations.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这项工作探讨了大语言模型（LLMs）以及生理和行为传感器数据在注意力、睡眠检测和睡眠改善中的应用。我们的实验突出了LLMs的优点和局限性。
- en: LLM-based attention and sleep detection exhibit lower performance compared to
    traditional ML models. Fine-tuned LLMs improve models’ ability to handle diverse
    contexts. However, we also found limitations. The fine-tuned GPT3.5 model uses
    limited features (e.g. power spectrum density and ratio) for classification even
    after fine-tuning and GPT-4 vision models fail to handle visual input. Also, feeding
    high dimensional numerical features such as EEG features to LLMs does not reliably
    estimate user states. To improve human state detection, LLM’s knowledge needs
    to be extended beyond simple one-on-one relationships such as increased alpha
    band activity during unfocused state and LLMs require further refinement to handle
    diverse human physiological and behavioral data, variabilities, and patterns effectively.
    This might be possible using fine-tuning with larger datasets and retrieving external
    sources of knowledge. In addition, textual knowledge might not fully capture complex
    physiological and behavioral patterns; therefore, integrating textual information
    with numerical and visual data is essential in order to understand variability
    within and across individuals; however, the capacity of current LLM vision models
    and fine-tuning is still limited and LLMs requires much diverse data to enhance
    the knowledge.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLM的注意力和睡眠检测与传统机器学习模型相比表现较差。微调的LLM提高了模型处理多样化上下文的能力。然而，我们也发现了一些局限性。微调后的GPT3.5模型即使在微调后也仅使用有限的特征（如功率谱密度和比率）进行分类，而GPT-4视觉模型无法处理视觉输入。此外，将高维数值特征如EEG特征输入LLMs不能可靠地估计用户状态。为了提高人类状态检测，LLM的知识需要扩展到简单的一对一关系之外，如在不集中状态下增加的alpha波段活动，LLMs需要进一步精炼以有效处理多样的人体生理和行为数据、变异性和模式。这可以通过使用更大的数据集进行微调和检索外部知识源来实现。此外，文本知识可能无法完全捕捉复杂的生理和行为模式；因此，将文本信息与数值和视觉数据相结合对于理解个体内部和跨个体的变异性至关重要；然而，目前LLM视觉模型和微调的能力仍然有限，LLMs需要更丰富的数据来增强知识。
- en: LLM-based sleep improvement suggestions and guided imagery scripts are personalized
    and adaptive to user profiles. Automatically generated suggestions and scripts
    have a potential for AI-based conversational systems or intervention systems after
    effectiveness and safety are carefully tested.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLM的睡眠改善建议和引导想象脚本是个性化的，并且适应用户个人资料。自动生成的建议和脚本在经过有效性和安全性仔细测试后，有可能用于AI对话系统或干预系统。
- en: There are several limitations in this study. First, this study is an early exploration
    with limited datasets and limited LLMs. Refining prompts and using large and diverse
    datasets might help enhance task performance. We intentionally use interpretable
    features rather than low dimensional embeddings to test the extent to which LLM
    internal knowledge contributes to altered state detection and improvement. Our
    study only relies on public datasets and offline experiments; therefore, user
    studies with end users and clinicians are necessary to evaluate generative responses
    in terms of accuracy, effectiveness, and safety. Lastly, beyond LLMs, there are
    other advanced approaches such as transformer models and multimodal learning for
    detecting user states.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这项研究存在几个局限性。首先，这项研究是早期探索，数据集和大型语言模型（LLMs）都有限。精炼提示和使用大型多样的数据集可能有助于提高任务表现。我们故意使用可解释的特征而不是低维嵌入来测试LLM内部知识在改变状态检测和改进中的贡献程度。我们的研究仅依赖公共数据集和离线实验；因此，需要与最终用户和临床医生进行用户研究，以评估生成响应的准确性、有效性和安全性。最后，除了LLMs，还有其他先进的方法，如变换器模型和多模态学习，用于检测用户状态。
- en: We also discuss the ethical considerations of using LLMs to detect and improve
    human-altered states. First, feeding personal physiological and behavioral data
    to LLMs could raise privacy concerns. Users might worry about the security and
    confidentiality of their sensitive information. Transparent consent processes
    and reliable data anonymization are important. Second, LLMs are trained on massive
    data that might contain biases. Bias detection and mitigation strategies are necessary
    to ensure fair outcomes. LLMs might have the capability to generate unethical,
    harmful, or inaccurate content or manipulate individuals. Implementing guidelines
    for responsible use and monitoring LLM-generated content are required.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还讨论了使用大型语言模型（LLMs）检测和改善人类改变状态的伦理考虑。首先，将个人生理和行为数据输入LLMs可能会引发隐私问题。用户可能会担心其敏感信息的安全性和保密性。透明的同意流程和可靠的数据匿名化措施是重要的。其次，LLMs
    是在可能包含偏见的大量数据上训练的。检测和缓解偏见的策略对于确保公平的结果是必要的。LLMs 可能会生成不道德、有害或不准确的内容，或操控个人。实施负责任使用的指导方针并监控LLMs生成的内容是必要的。
- en: References
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] D. J. Buysse, “Sleep health: can we define it? does it matter?” *Sleep*,
    vol. 37, no. 1, pp. 9–17, 2014.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] D. J. Buysse, “睡眠健康：我们能否定义它？它重要吗？”*Sleep*，第37卷，第1期，页码 9–17，2014年。'
- en: '[2] J. A. Horne and L. A. Reyner, “Sleep related vehicle accidents,” *Bmj*,
    vol. 310, no. 6979, pp. 565–567, 1995.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] J. A. Horne 和 L. A. Reyner, “与睡眠相关的交通事故”，*Bmj*，第310卷，第6979期，页码 565–567，1995年。'
- en: '[3] M. R. Rosekind, K. B. Gregory, M. M. Mallis, S. L. Brandt, B. Seal, and
    D. Lerner, “The cost of poor sleep: workplace productivity loss and associated
    costs,” *Journal of Occupational and Environmental Medicine*, vol. 52, no. 1,
    pp. 91–98, 2010.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] M. R. Rosekind, K. B. Gregory, M. M. Mallis, S. L. Brandt, B. Seal, 和 D.
    Lerner, “睡眠不足的成本：工作场所生产力损失及相关费用”，*Journal of Occupational and Environmental Medicine*，第52卷，第1期，页码
    91–98，2010年。'
- en: '[4] R. Richer, N. Zhao, J. Amores, B. M. Eskofier, and J. A. Paradiso, “Real-time
    mental state recognition using a wearable eeg,” in *2018 40th Annual International
    Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)*.   IEEE,
    2018, pp. 5495–5498.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] R. Richer, N. Zhao, J. Amores, B. M. Eskofier, 和 J. A. Paradiso, “使用可穿戴
    EEG 的实时心理状态识别”，收录于*2018年IEEE医学与生物工程学会第40届国际年会（EMBC）*。 IEEE，2018年，页码 5495–5498。'
- en: '[5] T. Baltrušaitis, D. McDuff, N. Banda, M. Mahmoud, R. El Kaliouby, P. Robinson,
    and R. Picard, “Real-time inference of mental states from facial expressions and
    upper body gestures,” in *2011 IEEE international conference on automatic face
    & gesture recognition (FG)*.   IEEE, 2011, pp. 909–914.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] T. Baltrušaitis, D. McDuff, N. Banda, M. Mahmoud, R. El Kaliouby, P. Robinson,
    和 R. Picard, “从面部表情和上半身手势中实时推断心理状态”，收录于*2011 IEEE 国际自动面部与手势识别会议（FG）*。 IEEE，2011年，页码
    909–914。'
- en: '[6] M. Vidal, J. Turner, A. Bulling, and H. Gellersen, “Wearable eye tracking
    for mental health monitoring,” *Computer Communications*, vol. 35, no. 11, pp.
    1306–1311, 2012.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] M. Vidal, J. Turner, A. Bulling, 和 H. Gellersen, “用于心理健康监测的可穿戴眼动追踪”，*Computer
    Communications*，第35卷，第11期，页码 1306–1311，2012年。'
- en: '[7] S. A. Imtiaz, “A systematic review of sensing technologies for wearable
    sleep staging,” *Sensors*, vol. 21, no. 5, p. 1562, 2021.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] S. A. Imtiaz, “可穿戴睡眠分期感应技术的系统综述”，*Sensors*，第21卷，第5期，页码 1562，2021年。'
- en: '[8] J. C. Shin, J. Kim, and D. Grigsby-Toussaint, “Mobile Phone Interventions
    for Sleep Disorders and Sleep Quality: Systematic Review,” *JMIR mHealth and uHealth*,
    vol. 5, no. 9, p. e7244, Sep. 2017, company: JMIR mHealth and uHealth Distributor:
    JMIR mHealth and uHealth Institution: JMIR mHealth and uHealth Label: JMIR mHealth
    and uHealth Publisher: JMIR Publications Inc., Toronto, Canada. [Online]. Available:
    https://mhealth.jmir.org/2017/9/e131'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] J. C. Shin, J. Kim, 和 D. Grigsby-Toussaint, “手机干预对睡眠障碍和睡眠质量的影响：系统综述”，*JMIR
    mHealth and uHealth*，第5卷，第9期，页码 e7244，2017年9月，公司：JMIR mHealth and uHealth，发行商：JMIR
    mHealth and uHealth，机构：JMIR mHealth and uHealth，标签：JMIR mHealth and uHealth，出版商：JMIR
    Publications Inc.，加拿大多伦多。[在线] 可用链接: https://mhealth.jmir.org/2017/9/e131'
- en: '[9] J. W. Kim, A. Alaa, and D. Bernardo, “Eeg-gpt: Exploring capabilities of
    large language models for eeg classification and interpretation,” *arXiv preprint
    arXiv:2401.18006*, 2024.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] J. W. Kim, A. Alaa, 和 D. Bernardo, “EEG-GPT：探索大型语言模型在 EEG 分类和解释中的能力”，*arXiv
    预印本 arXiv:2401.18006*，2024年。'
- en: '[10] Y. Kim, X. Xu, D. McDuff, C. Breazeal, and H. W. Park, “Health-llm: Large
    language models for health prediction via wearable sensor data,” *arXiv preprint
    arXiv:2401.06866*, 2024.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Y. Kim, X. Xu, D. McDuff, C. Breazeal, 和 H. W. Park, “Health-llm: 利用可穿戴传感器数据进行健康预测的大型语言模型”，*arXiv
    预印本 arXiv:2401.06866*，2024年。'
- en: '[11] Ç. İ. Acı, M. Kaya, and Y. Mishchenko, “Distinguishing mental attention
    states of humans via an eeg-based passive bci using machine learning methods,”
    *Expert Systems with Applications*, vol. 134, pp. 153–166, 2019.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Ç. İ. Acı, M. Kaya 和 Y. Mishchenko, “通过基于脑电图的被动脑机接口利用机器学习方法区分人类的心理注意状态，”
    *专家系统应用*，第134卷，第153-166页，2019年。'
- en: '[12] B. Kemp, A. Zwinderman, B. Tuk, H. Kamphuisen, and J. Oberye, “Analysis
    of a sleep-dependent neuronal feedback loop: the slow-wave microcontinuity of
    the eeg,” *IEEE Transactions on Biomedical Engineering*, vol. 47, no. 9, pp. 1185–1194,
    2000.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] B. Kemp, A. Zwinderman, B. Tuk, H. Kamphuisen 和 J. Oberye, “睡眠依赖的神经反馈回路分析：脑电图的慢波微连续性，”
    *IEEE 生物医学工程学报*，第47卷，第9期，第1185-1194页，2000年。'
- en: '[13] R. Wang, F. Chen, Z. Chen, T. Li, G. Harari, S. Tignor, X. Zhou, D. Ben-Zeev,
    and A. T. Campbell, “Studentlife: assessing mental health, academic performance
    and behavioral trends of college students using smartphones,” in *Proceedings
    of the 2014 ACM international joint conference on pervasive and ubiquitous computing*,
    2014, pp. 3–14.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] R. Wang, F. Chen, Z. Chen, T. Li, G. Harari, S. Tignor, X. Zhou, D. Ben-Zeev
    和 A. T. Campbell, “Studentlife：利用智能手机评估大学生的心理健康、学业表现和行为趋势，” 收录于 *2014年ACM国际联合会议的无处不在计算和普及计算论文集*，2014年，第3-14页。'
- en: '[14] J. Utay and M. Miller, “Guided imagery as an effective therapeutic technique:
    A brief review of its history and efficacy research.” *Journal of Instructional
    Psychology*, vol. 33, no. 1, 2006.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] J. Utay 和 M. Miller, “引导想象作为一种有效的治疗技术：其历史和疗效研究的简要回顾。” *教学心理学期刊*，第33卷，第1期，2006年。'
- en: '[15] S. G. Hofmann, A. Asnaani, I. J. Vonk, A. T. Sawyer, and A. Fang, “The
    efficacy of cognitive behavioral therapy: A review of meta-analyses,” *Cognitive
    therapy and research*, vol. 36, pp. 427–440, 2012.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] S. G. Hofmann, A. Asnaani, I. J. Vonk, A. T. Sawyer 和 A. Fang, “认知行为疗法的疗效：一项元分析的综述，”
    *认知治疗与研究*，第36卷，第427-440页，2012年。'
- en: Appendix
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录
- en: Prompt and LLM response examples
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示和LLM响应示例
- en: Zero-shot learning
  id: totrans-179
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 零样本学习
- en: '“You are a data analyst who reviews EEG data and helps interpret participant’s
    conditions. Please review the power spectrum data of EEG data. The data has an
    x-axis of time and a y-axis of frequency (0-40 Hz). The data is collected from
    healthy participants who went through cognitive tasks. We would like to classify
    the user state into 2 categories: focused or unfocused, confidence level (0-100%),
    and explanations. Please return your response in JSON format.”'
  id: totrans-180
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “你是一名数据分析师，负责审查脑电图数据并帮助解释参与者的状态。请审查脑电图数据的功率谱数据。数据的x轴是时间，y轴是频率（0-40 Hz）。数据来自经过认知任务的健康参与者。我们希望将用户状态分类为两类：集中或分散，置信度（0-100%），以及解释。请以JSON格式返回你的回应。”
- en: In-context learning
  id: totrans-181
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 上下文学习
- en: 'Please review the following 6 EEG data. The data has an x axis of time and
    a y axis of amplitude. The data is collected from healthy participants who went
    through sleep. The first 5 images were collected during wake state (W), stage
    1, stage 2, stage 3&4, and REM sleep. Please provide 1\. a description of each
    image 2\. estimate the sleep stage of the 6th (last) image and return a number
    from 0 to 5 (0:wake, 1: stage 1, 2: stage 2, 3: stage 3 or 4, 4: REM, 5: unknown
    or movement) 3\. confidence level (0-100%) 4\. explanations in JSON format.'
  id: totrans-182
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 请审查以下6个脑电图数据。数据的x轴是时间，y轴是振幅。数据来自经过睡眠的健康参与者。前5张图像是清醒状态（W）、第1阶段、第2阶段、第3&4阶段以及快速眼动（REM）睡眠时收集的。请提供1.
    每张图像的描述 2. 估计第6张（最后一张）图像的睡眠阶段，并返回一个0到5的数字（0:清醒，1:第1阶段，2:第2阶段，3:第3或第4阶段，4:REM，5:未知或运动）
    3. 置信度（0-100%） 4. JSON格式的解释。
- en: Sleep quality detection
  id: totrans-183
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 睡眠质量检测
- en: '“You are a data analyst helping a neurologist understand human sleep data.
    Task: This is the data collected from users who fill out the Pittsburgh Sleep
    Quality Index questionnaire. Based on this data, please give me the following
    information. (1) if this person has good sleep quality or poor quality (2) confident
    level (0-100%) (3) explanations for the decision. (4) suggestions to improve sleep
    quality.”'
  id: totrans-184
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “你是一名数据分析师，帮助神经科医生理解人类睡眠数据。任务：这是从填写匹兹堡睡眠质量指数问卷的用户那里收集的数据。基于这些数据，请提供以下信息：（1）此人睡眠质量是良好还是较差（2）置信度（0-100%）（3）决策的解释。（4）改善睡眠质量的建议。”
- en: Sleep quality detection
  id: totrans-185
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 睡眠质量检测
- en: '“Please review the following graph made from smartphone activity sensor data.
    The data has an x-axis of time (midnight to midnight) and a y-axis of date. For
    each hour, we computed the mean of activities where 0: Stationary, 1: Walking,
    2:Running, 3:Unknown. Please describe (1) estimated sleep quality (good or poor)
    (2) confidence (0-100(3) explanations (4) suggestions to improve sleep quality
    in JSON format.”'
  id: totrans-186
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “请查看以下由智能手机活动传感器数据制作的图表。数据的x轴是时间（从午夜到午夜），y轴是日期。我们计算了每小时活动的平均值，其中0：静止，1：步行，2：跑步，3：未知。请描述（1）估计的睡眠质量（好或差）（2）置信度（0-100）（3）解释（4）改善睡眠质量的建议，以JSON格式呈现。”
- en: Suggestion to improve sleep/Guided Imagery
  id: totrans-187
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 改善睡眠的建议/引导想象
- en: “You are a sleep therapist. The participant is [participant conditions/profiles].
    Reflecting on the participant’s profile, please generate suggestions (a guided
    imagery script) to help the participant sleep better.”
  id: totrans-188
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “你是一名睡眠治疗师。参与者是[参与者条件/档案]。请根据参与者的档案生成建议（引导想象脚本），以帮助参与者改善睡眠。”
- en: Sleep Guided Imagery using EEG features
  id: totrans-189
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基于脑电图（EEG）特征的睡眠引导想象
- en: “You are a sleep therapist. Please generate a guided imagery script based on
    the following 30-s epoch EEG features, alpha, beta, delta, theta, gamma power,
    alpha delta ratio, theta alpha ratio, delta theta ratio, mean, standard deviation,
    kurtosis, 90th percentile of amplitude. Do not include actual numerical EEG features,
    brain waves, power spectrum, or different frequencies of waves in the script but
    include the state estimated from the features. ”
  id: totrans-190
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “你是一名睡眠治疗师。请根据以下30秒周期的脑电图特征生成引导想象脚本，这些特征包括α波、β波、δ波、θ波、γ波功率，α-δ比，θ-α比，δ-θ比，均值，标准差，峰度，90百分位幅度。脚本中不要包含实际的数值脑电图特征、脑波、功率谱或不同频率的波形，但请包含根据特征估计的状态。”
