- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 18:53:43'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-09-08 18:53:43'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Zero-shot Text-guided Infinite Image Synthesis with LLM guidance
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 零-shot文本引导的无限图像合成与LLM指导
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2407.12642](https://ar5iv.labs.arxiv.org/html/2407.12642)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2407.12642](https://ar5iv.labs.arxiv.org/html/2407.12642)
- en: '¹¹institutetext: Artificial Intelligence Graduate School, UNIST'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '¹¹institutetext: 人工智能研究生院，UNIST'
- en: '¹¹email: {soyoung17, taegyeonglee, taehwankim}@unist.ac.krSoyeong Kwon Equal
    contributions (alphabetically ordered by last name.)    Taegyeong Lee^⋆    Taehwan
    Kim'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '¹¹email: {soyoung17, taegyeonglee, taehwankim}@unist.ac.krSoyeong Kwon 相等贡献（按姓氏字母顺序排列。）
       Taegyeong Lee^⋆    Taehwan Kim'
- en: 'Note: We provide the optimization objectives details in Section [1](#S1 "1
    Details of Optimization Objectives ‣ Zero-shot Text-guided Infinite Image Synthesis
    with LLM guidance"), the dataset details in Section [2](#S2 "2 Dataset Details
    ‣ Zero-shot Text-guided Infinite Image Synthesis with LLM guidance"), human evaluation
    details in Section [3](#S3 "3 Human Evaluation Details ‣ Zero-shot Text-guided
    Infinite Image Synthesis with LLM guidance"), human evaluation for ablation study
    in Section [4](#S4 "4 Human Evaluation for ablation study ‣ Zero-shot Text-guided
    Infinite Image Synthesis with LLM guidance") and additional generated samples
    in Section [5](#S5 "5 Generated Samples ‣ Zero-shot Text-guided Infinite Image
    Synthesis with LLM guidance") that were not included in the main paper due to
    space limit.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：我们在第[1](#S1 "1 优化目标细节 ‣ 零-shot文本引导的无限图像合成与LLM指导")节中提供了优化目标的详细信息，在第[2](#S2
    "2 数据集细节 ‣ 零-shot文本引导的无限图像合成与LLM指导")节中提供了数据集的详细信息，在第[3](#S3 "3 人工评估细节 ‣ 零-shot文本引导的无限图像合成与LLM指导")节中提供了人工评估的详细信息，在第[4](#S4
    "4 人工评估用于消融研究 ‣ 零-shot文本引导的无限图像合成与LLM指导")节中提供了消融研究的人工评估信息，并在第[5](#S5 "5 生成样本 ‣
    零-shot文本引导的无限图像合成与LLM指导")节中提供了额外生成的样本，这些内容由于篇幅限制未包含在主要论文中。
- en: '![[Uncaptioned image]](img/31fddd9e49c9d229b3a3e103a9e6eb5d.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![[未标注的图像]](img/31fddd9e49c9d229b3a3e103a9e6eb5d.png)'
- en: 'Figure 1: Generated samples with 4k resolution. We expand the given local image
    upwards and downwards twice, and left and right a total of 16 times, to follow
    the given global caption. The resolution of the generated image is 4608$\times$1536.
    The red box is the given local image. Due to the file size limit, we have repeatedly
    resized and compressed the generated images, which has slightly impacted the image
    quality. (180MB to 28MB)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：生成的4k分辨率样本。我们将给定的局部图像向上和向下扩展两次，并向左和向右总共扩展16次，以符合给定的全球标题。生成图像的分辨率为4608$\times$1536。红色框是给定的局部图像。由于文件大小限制，我们反复调整和压缩了生成的图像，这对图像质量有轻微影响。（180MB缩小至28MB）
- en: 1 Details of Optimization Objectives
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 优化目标细节
- en: 'We train our model end-to-end following the Stable Diffusion [rombach2022high].
    The optimized objective can be formulated as follows:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们按照Stable Diffusion [rombach2022high]的方式端到端地训练我们的模型。优化目标可以表述如下：
- en: '|  | $L=\mathbb{E}_{\mathcal{E},y,v,\epsilon\sim\mathcal{N}(0,1),t}\Big{[}\&#124;\epsilon-\epsilon_{\theta}(z_{t},t,\tau_{\theta}(y)),v\&#124;_{2}^{2}\Big{]}\,,$
    |  | (1) |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '|  | $L=\mathbb{E}_{\mathcal{E},y,v,\epsilon\sim\mathcal{N}(0,1),t}\Big{[}\&#124;\epsilon-\epsilon_{\theta}(z_{t},t,\tau_{\theta}(y)),v\&#124;_{2}^{2}\Big{]}\,,$
    |  | (1) |'
- en: where $\epsilon_{\theta}$ denotes the clip visual feature.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\epsilon_{\theta}$ 表示剪辑视觉特征。
- en: 2 Dataset Details
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 数据集细节
- en: 2.1 Training
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 训练
- en: We train the model to fill the local masked image conditioned on a local caption
    and a global caption. Below are the details of the training dataset. Also we provide
    samples of our training dataset in Figure [3](#S5.F3 "Figure 3 ‣ 5 Generated Samples
    ‣ Zero-shot Text-guided Infinite Image Synthesis with LLM guidance").
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们训练模型以根据局部标题和全球标题填充局部遮挡的图像。以下是训练数据集的详细信息。我们还在图[3](#S5.F3 "图3 ‣ 5 生成样本 ‣ 零-shot文本引导的无限图像合成与LLM指导")中提供了我们训练数据集的样本。
- en: GT(annotated caption). We use a ground truth(GT) caption (annotated caption)
    of MS-COCO [lin2014microsoft] dataset as a local caption.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: GT（标注标题）。我们使用MS-COCO [lin2014microsoft]数据集的真实标签（标注标题）作为局部标题。
- en: Local captions(generated from LLM). We generate local captions from the GT caption
    by utilizing the GPT 3.5 [brown2020language]. We use these captions to generate
    a global caption.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 局部标题（从LLM生成）。我们通过利用GPT 3.5 [brown2020language]从GT标题生成局部标题。我们使用这些标题生成全球标题。
- en: Global caption. We generate a global caption by summarizing the generated local
    captions and the GT caption with GPT-3.5 [brown2020language].
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 全球标题。我们通过总结生成的局部标题和GT标题，并使用GPT-3.5 [brown2020language]生成一个全球标题。
- en: 'Local masked image generation. First, we center crop and resize the MS-COCO [lin2014microsoft]
    dataset images to 512$\times$512\. Then, for local masked image generation, we
    mask the images in four directions: top, bottom, left, and right.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 局部遮掩图像生成。首先，我们对 MS-COCO [lin2014microsoft] 数据集图像进行中心裁剪和调整大小到 512$\times$512。然后，对于局部遮掩图像生成，我们在四个方向（上、下、左、右）遮掩图像。
- en: 2.2 Evaluation
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 评估
- en: We provide samples of global captions generated from the LLM for evaluation.
    Figure [4](#S5.F4 "Figure 4 ‣ 5 Generated Samples ‣ Zero-shot Text-guided Infinite
    Image Synthesis with LLM guidance") shows the global caption used for evaluation
    along with the image.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供了用于评估的由 LLM 生成的全局标题样本。图 [4](#S5.F4 "Figure 4 ‣ 5 Generated Samples ‣ Zero-shot
    Text-guided Infinite Image Synthesis with LLM guidance") 显示了用于评估的全局标题以及图像。
- en: 3 Human Evaluation Details
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 人工评估细节
- en: We conduct human evaluation on Amazon Mechanical Turk (AMT) to compare our model
    in three aspects, text matching, image quality and global coherence with the baselines
    and the ablated models.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 Amazon Mechanical Turk (AMT) 上进行人工评估，以比较我们的模型在文本匹配、图像质量和整体一致性方面与基线和去除模型的表现。
- en: For human evaluation, we randomly sample 100 generated images from each of MS-COCO [lin2014microsoft],
    Flickr [rashtchian2010collecting], and Pascal [rashtchian2010collecting] datasets,
    in total 300 samples. We conduct surveys with 5 participants to evaluate text
    matching, image quality and global coherence. For text matching, we provide images
    and text pairs and ask participants to respond to the question, “Choose a image
    that matches the text better.". For image quality, we ask participants to respond
    to the question, “Choose a image with better image quality.”. For global coherence,
    we ask participants to respond to the question, “Choose a image with better global
    coherence, according to text”. The screenshot of the user study including the
    instructions is shown in Figure [2](#S5.F2 "Figure 2 ‣ 5 Generated Samples ‣ Zero-shot
    Text-guided Infinite Image Synthesis with LLM guidance").
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 对于人工评估，我们从 MS-COCO [lin2014microsoft]、Flickr [rashtchian2010collecting] 和 Pascal [rashtchian2010collecting]
    数据集中随机抽取 100 张生成图像，共 300 个样本。我们进行调查，邀请 5 名参与者来评估文本匹配、图像质量和整体一致性。对于文本匹配，我们提供图像和文本对，并要求参与者回答“选择与文本匹配更好的图像”。对于图像质量，我们要求参与者回答“选择图像质量更好的图像”。对于整体一致性，我们要求参与者回答“根据文本选择整体一致性更好的图像”。包含说明的用户研究截图见图 [2](#S5.F2
    "Figure 2 ‣ 5 Generated Samples ‣ Zero-shot Text-guided Infinite Image Synthesis
    with LLM guidance")。
- en: 4 Human Evaluation for ablation study
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 用于消融研究的人类评估
- en: 'Table 1: Human evaluation on $\times$4 expansion. Each cell lists the winning
    percentage of our model versus baselines. TM is “text matching”. IQ is “image
    quality”. GC is “global coherence”.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：$\times$4 扩展上的人工评估。每个单元格列出了我们模型与基线模型的胜率百分比。TM 代表“文本匹配”。IQ 代表“图像质量”。GC 代表“整体一致性”。
- en: '|  |  |  |  | MS-COCO | Flickr | Pascal |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  | MS-COCO | Flickr | Pascal |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| Method | GC | CLIP | LLM | TM | IQ | GC | TM | IQ | GC | TM | IQ | GC |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | GC | CLIP | LLM | TM | IQ | GC | TM | IQ | GC | TM | IQ | GC |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    |'
- en: '| w/o All | ✓ | ✗ | ✗ | 65.00 | 67.20 | 63.60 | 62.60 | 65.00 | 62.20 | 62.40
    | 64.20 | 63.20 |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| w/o All | ✓ | ✗ | ✗ | 65.00 | 67.20 | 63.60 | 62.60 | 65.00 | 62.20 | 62.40
    | 64.20 | 63.20 |'
- en: '| w/o CLIP | ✓ | ✗ | ✓ | 62.00 | 60.00 | 62.00 | 60.00 | 61.20 | 61.80 | 63.80
    | 60.00 | 59.80 |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| w/o CLIP | ✓ | ✗ | ✓ | 62.00 | 60.00 | 62.00 | 60.00 | 61.20 | 61.80 | 63.80
    | 60.00 | 59.80 |'
- en: '| w/o LLM | ✓ | ✓ | ✗ | 60.00 | 58.60 | 59.20 | 57.80 | 60.00 | 60.60 | 57.40
    | 57.00 | 57.80 |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| w/o LLM | ✓ | ✓ | ✗ | 60.00 | 58.60 | 59.20 | 57.80 | 60.00 | 60.60 | 57.40
    | 57.00 | 57.80 |'
- en: '| w/o GC | ✗ | ✓ | ✓ | 60.20 | 57.20 | 64.20 | 59.00 | 55.20 | 61.20 | 60.20
    | 53.80 | 61.80 |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| w/o GC | ✗ | ✓ | ✓ | 60.20 | 57.20 | 64.20 | 59.00 | 55.20 | 61.20 | 60.20
    | 53.80 | 61.80 |'
- en: 'Table 2: Human evaluation on $\times$8 expansion. Each cell lists the winning
    percentage of our model versus baselines. TM is “text matching”. IQ is “image
    quality”. GC is “global coherence”.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：$\times$8 扩展上的人工评估。每个单元格列出了我们模型与基线模型的胜率百分比。TM 代表“文本匹配”。IQ 代表“图像质量”。GC 代表“整体一致性”。
- en: '|  |  |  |  | MS-COCO | Flickr | Pascal |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  | MS-COCO | Flickr | Pascal |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| Method | GC | CLIP | LLM | TM | IQ | GC | TM | IQ | GC | TM | IQ | GC |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | GC | CLIP | LLM | TM | IQ | GC | TM | IQ | GC | TM | IQ | GC |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    |'
- en: '| w/o All | ✓ | ✗ | ✗ | 65.40 | 60.80 | 66.20 | 65.60 | 63.60 | 65.00 | 64.20
    | 60.20 | 66.40 |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 无所有 | ✓ | ✗ | ✗ | 65.40 | 60.80 | 66.20 | 65.60 | 63.60 | 65.00 | 64.20 |
    60.20 | 66.40 |'
- en: '| w/o CLIP | ✓ | ✗ | ✓ | 65.20 | 65.60 | 63.60 | 64.00 | 66.00 | 66.80 | 65.40
    | 62.00 | 64.00 |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 无 CLIP | ✓ | ✗ | ✓ | 65.20 | 65.60 | 63.60 | 64.00 | 66.00 | 66.80 | 65.40
    | 62.00 | 64.00 |'
- en: '| w/o LLM | ✓ | ✓ | ✗ | 59.60 | 61.20 | 60.00 | 63.20 | 61.60 | 64.80 | 64.80
    | 60.60 | 61.80 |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 无 LLM | ✓ | ✓ | ✗ | 59.60 | 61.20 | 60.00 | 63.20 | 61.60 | 64.80 | 64.80
    | 60.60 | 61.80 |'
- en: '| w/o GC | ✗ | ✓ | ✓ | 60.20 | 57.00 | 62.60 | 60.40 | 56.20 | 61.40 | 59.20
    | 53.40 | 62.00 |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 无 GC | ✗ | ✓ | ✓ | 60.20 | 57.00 | 62.60 | 60.40 | 56.20 | 61.40 | 59.20
    | 53.40 | 62.00 |'
- en: 'Due to the page limit of the main paper, we provide the result of human evaluation
    for ablation study in this section. We conduct human evaluation with the ablated
    models: 1) the w/o all model generates an image with only a global caption. 2)
    the w/o LLM model generates an image with a global caption and the CLIP [radford2021learning]
    visual feature. 3) the w/o CLIP [radford2021learning] model generates an image
    with a global caption and a local caption generated with the LLM. 4) w/o GC model
    generates an image with a local caption generated with the LLM and the CLIP [radford2021learning]
    visual feature. We evaluate the performance following three aspects, text matching(TM),
    image quality(IQ) and global coherence(GC).'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 由于主论文的页数限制，我们在本节中提供了人类评估的结果。我们对去除的模型进行了人类评估：1) 无所有模型生成仅带有全局描述的图像。2) 无 LLM 模型生成带有全局描述和
    CLIP [radford2021learning] 视觉特征的图像。3) 无 CLIP [radford2021learning] 模型生成带有全局描述和通过
    LLM 生成的局部描述的图像。4) 无 GC 模型生成带有 LLM 生成的局部描述和 CLIP [radford2021learning] 视觉特征的图像。我们从三个方面评估性能：文本匹配(TM)、图像质量(IQ)和全局一致性(GC)。
- en: As shown as Table [1](#S4.T1 "Table 1 ‣ 4 Human Evaluation for ablation study
    ‣ Zero-shot Text-guided Infinite Image Synthesis with LLM guidance") ($\times$8
    expansion) demonstrates that our model significantly outperforms in all aspects
    compared to all ablated models. This indicates that our model can perform image
    outpainting considering the text matching, image quality and global coherence
    despite the extension size increases.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如表 [1](#S4.T1 "Table 1 ‣ 4 Human Evaluation for ablation study ‣ Zero-shot Text-guided
    Infinite Image Synthesis with LLM guidance")（$\times$8 扩展）所示，我们的模型在所有方面明显优于所有去除的模型。这表明，尽管扩展尺寸增加，我们的模型仍能在考虑文本匹配、图像质量和全局一致性的情况下执行图像外延。
- en: 5 Generated Samples
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 个生成样本
- en: We provide the additional generated samples in the following figures. As shown
    as Figure [1](#S0.F1 "Figure 1 ‣ Zero-shot Text-guided Infinite Image Synthesis
    with LLM guidance"), our model can expand an image with 4k resolution while following
    the global caption and maintaining the global consistency. Also in Figure [5](#S5.F5
    "Figure 5 ‣ 5 Generated Samples ‣ Zero-shot Text-guided Infinite Image Synthesis
    with LLM guidance") and [6](#S5.F6 "Figure 6 ‣ 5 Generated Samples ‣ Zero-shot
    Text-guided Infinite Image Synthesis with LLM guidance"), we qualitatively compare
    our model with the baseline models, SD Inpainting [rombach2022high] (SD Inp),
    Blended Latent Diffusion [avrahami2022blended] (BLD) and PowerPaint [zhuang2023task]
    (PP) for each dataset, MS-COCO [lin2014microsoft], Flickr [alayrac2022flamingo],
    and Pascal [rashtchian2010collecting].
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在以下图中提供了额外生成的样本。如图 [1](#S0.F1 "Figure 1 ‣ Zero-shot Text-guided Infinite Image
    Synthesis with LLM guidance")所示，我们的模型能够在遵循全局描述并保持全局一致性的情况下扩展4k分辨率的图像。同时在图 [5](#S5.F5
    "Figure 5 ‣ 5 Generated Samples ‣ Zero-shot Text-guided Infinite Image Synthesis
    with LLM guidance")和 [6](#S5.F6 "Figure 6 ‣ 5 Generated Samples ‣ Zero-shot Text-guided
    Infinite Image Synthesis with LLM guidance")中，我们将模型与基线模型进行定性比较，这些基线模型包括SD Inpainting [rombach2022high]
    (SD Inp)、Blended Latent Diffusion [avrahami2022blended] (BLD)和PowerPaint [zhuang2023task]
    (PP)，对于每个数据集MS-COCO [lin2014microsoft]、Flickr [alayrac2022flamingo]和Pascal [rashtchian2010collecting]。
- en: •
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Generated samples with 4k resolution : Figure [1](#S0.F1 "Figure 1 ‣ Zero-shot
    Text-guided Infinite Image Synthesis with LLM guidance")'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 4k 分辨率生成的样本：图 [1](#S0.F1 "Figure 1 ‣ Zero-shot Text-guided Infinite Image Synthesis
    with LLM guidance")
- en: •
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Comparison with our model and the baselines : Figure [5](#S5.F5 "Figure 5 ‣
    5 Generated Samples ‣ Zero-shot Text-guided Infinite Image Synthesis with LLM
    guidance"), Figure [6](#S5.F6 "Figure 6 ‣ 5 Generated Samples ‣ Zero-shot Text-guided
    Infinite Image Synthesis with LLM guidance")'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与我们模型和基线模型的比较：图 [5](#S5.F5 "Figure 5 ‣ 5 Generated Samples ‣ Zero-shot Text-guided
    Infinite Image Synthesis with LLM guidance")，图 [6](#S5.F6 "Figure 6 ‣ 5 Generated
    Samples ‣ Zero-shot Text-guided Infinite Image Synthesis with LLM guidance")
- en: '![Refer to caption](img/497838192267d57d6662213708c43cb9.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/497838192267d57d6662213708c43cb9.png)'
- en: 'Figure 2: Screenshot of instructions provided to participants during the human
    evaluation.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：人类评估期间向参与者提供的说明截图。
- en: '![Refer to caption](img/6a3f30c3b1380fd94e41b6efef0dce8d.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/6a3f30c3b1380fd94e41b6efef0dce8d.png)'
- en: 'Figure 3: Dataset construction sample for training. “GT (annotated caption)”
    is the ground truth caption on MS-COCO [lin2014microsoft], Flickr [alayrac2022flamingo]
    and Pascal [rashtchian2010collecting] testsets. First we generate local captions
    based on the GT using the LLM. Then, we generate the global caption with the LLM
    by summarizing the GT and the generated local captions.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：用于训练的数据集构建示例。“GT（标注标题）”是MS-COCO [lin2014microsoft]、Flickr [alayrac2022flamingo]和Pascal [rashtchian2010collecting]测试集上的真实标题。首先，我们使用LLM基于GT生成本地标题。然后，我们通过总结GT和生成的本地标题来用LLM生成全局标题。
- en: '![Refer to caption](img/422af5a3dd008ef235dff94aa4782847.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/422af5a3dd008ef235dff94aa4782847.png)'
- en: 'Figure 4: Dataset construction sample for evaluation. “GT (annotated caption)”
    is the ground truth caption on MS-COCO [lin2014microsoft], Flickr [alayrac2022flamingo]
    and Pascal [rashtchian2010collecting] test sets. The global caption is a caption
    generated by the LLM.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：用于评估的数据集构建示例。“GT（标注标题）”是MS-COCO [lin2014microsoft]、Flickr [alayrac2022flamingo]和Pascal [rashtchian2010collecting]测试集上的真实标题。全局标题是由LLM生成的标题。
- en: '![Refer to caption](img/798ef661bfa9dcdff39828200f5f7d34.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/798ef661bfa9dcdff39828200f5f7d34.png)'
- en: 'Figure 5: Comparison of generated image results. We expand the image eight
    times. The expanded image has a resolution of 2560$\times$512. The red box is
    the given local image. Due to the limit of the file size, we have repeatedly resized
    and compressed image files, which has slightly impacted the image quality (100MB
    to 32MB).'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：生成图像结果的比较。我们将图像扩展了八次。扩展后的图像分辨率为2560$\times$512。红色框是给定的本地图像。由于文件大小的限制，我们反复调整和压缩图像文件，这略微影响了图像质量（从100MB压缩到32MB）。
- en: '![Refer to caption](img/bc3443a57639f06f7c5adb3771b19205.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/bc3443a57639f06f7c5adb3771b19205.png)'
- en: 'Figure 6: Comparison of generated image results. When a local image and a global
    caption are provided, the image is expanded a total of eight times. The expanded
    image has a resolution of 512$\times$2560. The red box is the provided original
    local image.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：生成图像结果的比较。当提供本地图像和全局标题时，图像总共扩展了八次。扩展后的图像分辨率为512$\times$2560。红色框是提供的原始本地图像。
