- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 19:04:09'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 19:04:09
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Explaining EDA synthesis errors with LLMs
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用LLMs解释EDA综合错误
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2404.07235](https://ar5iv.labs.arxiv.org/html/2404.07235)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2404.07235](https://ar5iv.labs.arxiv.org/html/2404.07235)
- en: \lst@Key
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \lst@Key
- en: 'numbersnone\lstKV@SwitchCases#1none:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 'numbersnone\lstKV@SwitchCases#1none:'
- en: 'left:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 'left:'
- en: 'right:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 'right:'
- en: Siyu Qiu1, Benjamin Tan2, and Hammond Pearce1 The research in this work was
    supported in part by Intel Corporation and in part by Woodpecker Technologies.
    1University of New South Wales, Sydney, NSW, Australia 2University of Calgary,
    Calgary, AB, Canada
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Siyu Qiu1, Benjamin Tan2 和 Hammond Pearce1 本研究部分得到Intel公司和Woodpecker Technologies的资助。1新南威尔士大学，悉尼，新南威尔士州，澳大利亚
    2卡尔加里大学，加拿大艾伯塔省，加尔加里
- en: siyu.qiu1@student.unsw.edu.au, benjamin.tan1@ucalgary.ca, hammond.pearce@unsw.edu.au
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: siyu.qiu1@student.unsw.edu.au, benjamin.tan1@ucalgary.ca, hammond.pearce@unsw.edu.au
- en: Abstract
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Training new engineers in digital design is a challenge, particularly when it
    comes to teaching the complex electronic design automation (EDA) tooling used
    in this domain. Learners will typically deploy designs in the Verilog and VHDL
    hardware description languages to Field Programmable Gate Arrays (FPGAs) from
    Altera (Intel) and Xilinx (AMD) via proprietary closed-source toolchains (Quartus
    Prime and Vivado, respectively). These tools are complex and difficult to use—yet,
    as they are the tools used in industry, they are an essential first step in this
    space. In this work, we examine how recent advances in artificial intelligence
    may be leveraged to address aspects of this challenge. Specifically, we investigate
    if Large Language Models (LLMs), which have demonstrated text comprehension and
    question-answering capabilities, can be used to generate novice-friendly explanations
    of compile-time synthesis error messages from Quartus Prime and Vivado. To perform
    this study we generate 936 error message explanations using three OpenAI LLMs
    over 21 different buggy code samples. These are then graded for relevance and
    correctness, and we find that in approximately 71% of cases the LLMs give correct
    & complete explanations suitable for novice learners.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 培训新工程师在数字设计方面是一个挑战，特别是在教授该领域复杂的电子设计自动化（EDA）工具时。学习者通常会将设计部署到Altera（Intel）和Xilinx（AMD）的现场可编程门阵列（FPGA）上，使用的是专有的闭源工具链（分别是Quartus
    Prime和Vivado）。这些工具复杂且难以使用，但由于它们是行业使用的工具，因此在这一领域是不可或缺的第一步。在这项工作中，我们探讨了如何利用最近的人工智能进展来解决这个挑战的各个方面。具体而言，我们研究了大型语言模型（LLMs）是否可以用于生成初学者友好的Quartus
    Prime和Vivado的编译时综合错误消息解释。为了进行这项研究，我们使用三个OpenAI LLMs在21个不同的有错误代码样本上生成了936个错误消息解释。随后，我们对这些解释进行了相关性和正确性的评分，发现约71%的情况下，LLMs提供了适合初学者的正确且完整的解释。
- en: 'Index Terms:'
  id: totrans-14
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 索引术语：
- en: EDA, CAD, AI, LLM, Bug Explanation
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: EDA, CAD, AI, LLM, 错误解释
- en: I Introduction
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引言
- en: With increasing demand for digital devices, there is a need for more digital
    design practitioners. However, existing electronic design automation (EDA) tools
    have a considerably steep learning curve. For example, in the FPGA design space,
    Altera and AMD Xilinx tools are frequently used in educational settings. These
    tool suites are renowned for their difficulty and complexity, particularly for
    new users. Indeed, the combination of new languages, design paradigms, software
    tools, and hardware requirements can leave novices feeling well and truly “stumped” [[1](#bib.bib1)],
    particularly when the software provides unhelpful messages upon reaching erroneous
    code (e.g., Figure [1](#S1.F1 "Figure 1 ‣ I Introduction ‣ Explaining EDA synthesis
    errors with LLMs")). Likewise, educators themselves can struggle with the broad
    knowledge base required [[2](#bib.bib2)]. This is a serious challenge, especially
    considering the worldwide shortfall in qualified chip designers (in the US alone,
    estimates have a 67,000 employee shortfall by 2030 [[3](#bib.bib3)]).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 随着对数字设备需求的增加，需要更多的数字设计从业者。然而，现有的电子设计自动化（EDA）工具学习曲线非常陡峭。例如，在FPGA设计领域，Altera和AMD
    Xilinx工具经常在教育环境中使用。这些工具套件因其难度和复杂性而著称，特别是对于新用户而言。确实，新语言、设计范式、软件工具和硬件要求的结合可能会让初学者感到真正的“困惑”[[1](#bib.bib1)]，特别是当软件在遇到错误代码时提供不帮助的信息时（例如，图 [1](#S1.F1
    "图 1 ‣ 引言 ‣ 用LLMs解释EDA综合错误")）。同样，教育工作者也可能会因需要广泛的知识基础而感到困难[[2](#bib.bib2)]。这是一项严峻的挑战，特别是考虑到全球合格芯片设计师的短缺（仅在美国，到2030年估计缺少67,000名员工[[3](#bib.bib3)])。
- en: 41architecture  Behavioral  of  top1  is42begin43  process  (clk,  rst)  begin44  if  rst  =  ’1’  then45  data_out  <=  (others  =>  ’0’)46  elsif  rising_edge(clk)  then47  data_out  <=  data_in;48  end  if;49  end  process;50end  Behavioral;
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 41architecture Behavioral of top1 is42begin43 process (clk, rst) begin44 if
    rst = ’1’ then45 data_out <= (others => ’0’)46 elsif rising_edge(clk) then47 data_out
    <= data_in;48 end if;49 end process;50end Behavioral;
- en: (a) Snippet of buggy VHDL code
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 有错误的VHDL代码片段
- en: '1ERROR:  [Synth  8-2715]  syntax  error  near  elsif  [path/to/bug_1/rtl/top1.vhd:46]'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '1ERROR: [Synth 8-2715] syntax error near elsif [path/to/bug_1/rtl/top1.vhd:46]'
- en: (b) Vivado’s corresponding error message
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: (b) Vivado的相应错误信息
- en: 'Figure 1: Example unhelpful error message. It does not describe the real problem
    (a missing semicolon), and it links to line 46, not the fault on line 45!'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：示例无用的错误信息。它没有描述实际问题（缺少分号），而且它链接到第46行，而不是第45行的错误！
- en: 'It is therefore desirable to see if recent advancements in artificial intelligence
    may be able to assist novice digital hardware designers and accelerate their training,
    be it in the classroom or perhaps as part of onboarding/professional development.
    In particular, large language models have demonstrated considerable capabilities
    for comprehending text and program code, enabling code generation and explanation.
    Given that one of the most common difficulties noted when learning to program
    comes from understanding and overcoming compiler error messages [[4](#bib.bib4),
    [5](#bib.bib5)] we pose the question: Can LLMs be leveraged to explain error messages
    from EDA tools?'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，有必要观察近期的人工智能进展是否能够帮助新手数字硬件设计师，并加速他们的培训，无论是在课堂上还是作为入职/职业发展的部分。特别是，大型语言模型已经展示了在理解文本和程序代码方面的显著能力，能够进行代码生成和解释。鉴于学习编程时最常见的困难之一是理解和解决编译器错误信息 [[4](#bib.bib4),
    [5](#bib.bib5)]，我们提出了这样一个问题：是否可以利用LLM来解释EDA工具的错误信息？
- en: In this work, we thus undertake a proof-of-concept examination, tasking a series
    of OpenAI LLMs with generating explanations for a series of synthesis-time (i.e.
    compile-time) bugs commonly encountered by novice digital designers. Our synthetic
    dataset contains error messages from both Intel’s Altera Quartus Prime and AMD’s
    Xilinx Vivado with both VHDL- and Verilog-based designs.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们进行了一项概念验证检查，任务是让一系列OpenAI的LLM为一系列新手数字设计师常遇到的合成时（即编译时）错误生成解释。我们的合成数据集包含来自英特尔Altera
    Quartus Prime和AMD Xilinx Vivado的错误信息，涉及VHDL和Verilog设计。
- en: Crucially, as we aim to up-skill tool users, we desire pedagogically-useful
    responses (i.e., not automated program repair). The LLM should assist the user
    but should not outright solve the issue—per the constructivism pedagogy in computer
    science [[6](#bib.bib6)], learners should “build” knowledge rather than be simply
    told answers outright. Moreover, the insights from our study can also lay the
    foundation for other LLM-based augmentation of EDA tool feedback to improve their
    readability/actionability and, thus, designer productivity.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 关键是，由于我们旨在提升工具用户的技能，我们希望得到教学上有用的回应（即，不是自动修复程序）。LLM应协助用户，但不应直接解决问题——根据计算机科学中的建构主义教学法 [[6](#bib.bib6)]，学习者应“构建”知识，而不是简单地告诉他们答案。此外，我们研究中的见解还可以为其他基于LLM的EDA工具反馈增强奠定基础，以提高其可读性/可操作性，从而提高设计师的生产力。
- en: 'Our contributions include the following:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的贡献包括以下几点：
- en: •
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: A new open-source dataset of 21 representative synthesis-time bugs and error
    messages based on the authors’ experiences with teaching introductory digital
    hardware design.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一个新的开源数据集，包括21个具有代表性的合成时错误和错误信息，基于作者在教授数字硬件设计入门课程中的经验。
- en: •
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Using these bugs, results from the first pedagogically focused evaluation of
    936 LLM-generated bug explanations, finding that $\approx$71% have ‘good’ explanations.
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用这些错误，结果显示936个LLM生成的错误解释中的第一次教学评估发现约71%的解释是“良好”的。
- en: 'Open-source: All synthetic bugs and generated data is provided at [https://zenodo.org/doi/10.5281/zenodo.10937409](https://zenodo.org/doi/10.5281/zenodo.10937409).'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 开源：所有合成错误和生成的数据可以在[https://zenodo.org/doi/10.5281/zenodo.10937409](https://zenodo.org/doi/10.5281/zenodo.10937409)上获取。
- en: II Background and Related Work
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 背景和相关工作
- en: II-A Large Language Models for hardware design
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-A 大型语言模型在硬件设计中的应用
- en: LLMs, trained over large quantities of text scraped from the Internet (including
    millions of open-source repositories), have demonstrated considerable cross-domain
    expertise in lexical tasks. While early models such as OpenAI’s Codex acted primarily
    as a kind of “smart autocomplete,” more recent training methodologies such as
    Reinforcement Learning with Human Feedback (RLHF) can create models more capable
    of following user intent [[7](#bib.bib7)]—meaning such models may actually “follow
    instructions.” Currently, leading commercial LLMs in this space come from OpenAI’s
    ChatGPT family [[8](#bib.bib8)], which can be “prompted” to translate and debug
    code and provide code explanations using natural language.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 经过大量互联网文本（包括数百万个开源代码库）的训练，LLM（大语言模型）在词汇任务中展示了相当大的跨领域专业知识。虽然早期模型如OpenAI的Codex主要充当了一种“智能自动完成”工具，但最近的训练方法，如带有人类反馈的强化学习（RLHF），可以创建更能跟随用户意图的模型[[7](#bib.bib7)]——这意味着这些模型可能真正地“遵循指令”。目前，这一领域的领先商业LLM来自OpenAI的ChatGPT系列[[8](#bib.bib8)]，这些模型可以通过自然语言“提示”来翻译和调试代码以及提供代码解释。
- en: Multiple works have acknowledged the potential for LLMs to work with hardware
    design tasks, including for authoring hardware description language (HDL) code [[9](#bib.bib9),
    [10](#bib.bib10), [11](#bib.bib11), [12](#bib.bib12)], bug fixing [[13](#bib.bib13)],
    SystemVerilog Assertion generation [[14](#bib.bib14)], and scripting hardware
    tool suites [[15](#bib.bib15)] among others. Some works have even explored how
    conversational LLMs like OpenAI’s ChatGPT [[8](#bib.bib8)] can author whole processor
    designs [[16](#bib.bib16)].
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 多项研究已认可LLM在硬件设计任务中的潜力，包括编写硬件描述语言（HDL）代码[[9](#bib.bib9), [10](#bib.bib10), [11](#bib.bib11),
    [12](#bib.bib12)]、修复漏洞[[13](#bib.bib13)]、生成SystemVerilog断言[[14](#bib.bib14)]以及脚本编写硬件工具套件[[15](#bib.bib15)]等。一些研究甚至探讨了像OpenAI的ChatGPT[[8](#bib.bib8)]这样的对话型LLM如何编写整个处理器设计[[16](#bib.bib16)]。
- en: II-B LLMs for training and education
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-B LLM用于培训和教育
- en: Proponents of the technology argue that LLMs, when carefully utilized, can unlock
    new pedagogical tools and strategies. Kasneci et al. provide a comprehensive survey
    in this area [[17](#bib.bib17)], finding that, for example, ChatGPT is already
    being used for educational methods such as generating tests, quizzes, and flashcards [[18](#bib.bib18),
    [19](#bib.bib19)].
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 技术的支持者认为，当LLM被仔细利用时，可以解锁新的教学工具和策略。Kasneci等人提供了这一领域的综合调查[[17](#bib.bib17)]，发现例如，ChatGPT已经被用于生成测试、测验和抽认卡等教育方法[[18](#bib.bib18),
    [19](#bib.bib19)]。
- en: Given their recency, investigations on the challenges and opportunities provided
    by LLMs in the education domain are ongoing [[20](#bib.bib20)]. Particular attention
    has been provided on their potential impact in “CS1” introductory courses (e.g.
    [[21](#bib.bib21), [22](#bib.bib22)]) and on quality of code explanations for
    novices [[23](#bib.bib23), [24](#bib.bib24), [25](#bib.bib25)]. Of particular
    interest to us is the potential for LLMs to aid in error message explanation,
    where LLMs are used to help learners overcome compile and runtime errors. Taylor
    et al. [[26](#bib.bib26)] explored this application for C, where they examined
    over 64,000 uses of the ChatGPT-enabled C compiler DCC by over 2,500 students.
    They found that over 90 % of compile-time and 75 % of run-time error messages
    had valid explanations.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于其近期性，对LLM在教育领域提供的挑战和机遇的研究仍在进行中[[20](#bib.bib20)]。特别关注其在“CS1”入门课程（例如[[21](#bib.bib21),
    [22](#bib.bib22)]）中的潜在影响以及对新手代码解释质量的影响[[23](#bib.bib23), [24](#bib.bib24), [25](#bib.bib25)]。我们特别感兴趣的是LLM在错误信息解释中的潜力，LLM被用来帮助学习者克服编译和运行时错误。Taylor等人[[26](#bib.bib26)]探讨了这一应用，研究了超过2500名学生使用ChatGPT启用的C编译器DCC的超过64,000次实例。他们发现，超过90%的编译时和75%的运行时错误信息有有效的解释。
- en: This motivates our investigation, which explores a similar use case for hardware
    synthesis rather than software compilation. The DCC compiler provided considerable
    additional context to the ChatGPT 3.5 LLM in the form of stack traces and templated
    error message assistance [[26](#bib.bib26)]. Can we find a similar level of assistance
    but for hardware, simply using the context available in the typical hardware EDA
    tool suite?
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这激发了我们的研究，它探索了一个类似的硬件综合应用案例，而不是软件编译。DCC编译器为ChatGPT 3.5 LLM提供了大量额外的上下文信息，包括堆栈跟踪和模板化错误信息帮助[[26](#bib.bib26)]。我们能否找到类似级别的硬件辅助，只使用典型硬件EDA工具套件中提供的上下文？
- en: III Digital Design Assistance via LLM prompts
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III 通过LLM提示的数字设计辅助
- en: '![Refer to caption](img/894e77dc748755c29cfcd04ee6c53055.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/894e77dc748755c29cfcd04ee6c53055.png)'
- en: 'Figure 2: Overall experimentation methodology'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：总体实验方法
- en: III-A Overview
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-A 概述
- en: This study explores the effectiveness of using LLMs to improve error feedback
    in Vivado and Quartus. We use the methodology outlined in Figure [2](#S3.F2 "Figure
    2 ‣ III Digital Design Assistance via LLM prompts ‣ Explaining EDA synthesis errors
    with LLMs"). Firstly, we create a corpus of representative bugs. We use these
    to collect synthesis error messages, then use two different prompts to request
    explanations from selected LLMs. Finally, we score the responses.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究探讨了使用 LLM 改进 Vivado 和 Quartus 中错误反馈的有效性。我们使用了图 [2](#S3.F2 "图 2 ‣ III 通过 LLM
    提示进行数字设计辅助 ‣ 使用 LLM 解释 EDA 合成错误") 中概述的方法。首先，我们创建了一个具有代表性的错误语料库。然后，我们使用这些错误收集合成错误消息，并使用两种不同的提示请求选定的
    LLM 进行解释。最后，我们对响应进行评分。
- en: III-B Defining a corpus of bugs
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-B 定义错误语料库
- en: Table [I](#S3.T1 "Table I ‣ III-B Defining a corpus of bugs ‣ III Digital Design
    Assistance via LLM prompts ‣ Explaining EDA synthesis errors with LLMs")’s first
    four columns present the range of bugs used in this study (the latter four columns
    present results; see Section [IV](#S4 "IV Results ‣ Explaining EDA synthesis errors
    with LLMs")). The bugs were based in general on 10 distinct error categories (e.g.,
    syntax errors, multiple driver errors, type errors and others) that the authors
    have frequently observed in code written by learners and novice hardware designers.
    Two of the VHDL bugs did not have an equivalent Verilog representation. The buggy
    files are short (usually less than 50 lines of comments and code)—e.g., Figure [1](#S1.F1
    "Figure 1 ‣ I Introduction ‣ Explaining EDA synthesis errors with LLMs") depicts
    Bug 1.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [I](#S3.T1 "表 I ‣ III-B 定义错误语料库 ‣ III 通过 LLM 提示进行数字设计辅助 ‣ 使用 LLM 解释 EDA 合成错误")
    的前四列展示了本研究中使用的错误范围（后四列展示了结果；见第 [IV](#S4 "IV 结果 ‣ 使用 LLM 解释 EDA 合成错误") 节）。这些错误通常基于
    10 种不同的错误类别（例如，语法错误、多驱动错误、类型错误等），这些类别是作者在学习者和新手硬件设计师编写的代码中经常观察到的。两个 VHDL 错误没有等效的
    Verilog 表示。错误文件较短（通常少于 50 行注释和代码）—例如，图 [1](#S1.F1 "图 1 ‣ I 引言 ‣ 使用 LLM 解释 EDA
    合成错误") 描述了错误 1。
- en: 'TABLE I: List of HDL bugs (and their languages) examined in the study, with
    LLM evaluation results. Each bug had 24 responses in each prompting strategy,
    and these were manually graded.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 表 I：研究中检查的 HDL 错误（及其语言）列表，以及 LLM 评估结果。每个错误在每种提示策略中有 24 个响应，这些响应经过人工评分。
- en: '|  |  |  |  |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  |'
- en: '&#124; LLM answer: &#124;'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; LLM 答案: &#124;'
- en: '&#124; concept accurate &#124;'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 概念准确 &#124;'
- en: '|'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; LLM answer: &#124;'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; LLM 答案: &#124;'
- en: '&#124; correct & complete &#124;'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 正确且完整 &#124;'
- en: '|'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Bug | Error type | Language | Error description | E&C | EC&L | E&C | EC&L
    |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 错误 | 错误类型 | 语言 | 错误描述 | E&C | EC&L | E&C | EC&L |'
- en: '| 1 | Syntax error | VHDL | Missing semicolon | 71% | 67% | 46% | 58% |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 语法错误 | VHDL | 缺少分号 | 71% | 67% | 46% | 58% |'
- en: '| 2 | Type error | VHDL | Can’t add std_logic_vectors | 100% | 96% | 21% |
    25% |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 类型错误 | VHDL | 无法对 std_logic_vectors 进行加法运算 | 100% | 96% | 21% | 25% |'
- en: '| 3 | Compilation error | VHDL | Can’t write to an input ports object | 100%
    | 100% | 79% | 83% |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 编译错误 | VHDL | 无法写入输入端口对象 | 100% | 100% | 79% | 83% |'
- en: '| 4 | Width mismatch | VHDL | Mismatch in the size of two std_logic_vectors
    | 100% | 100% | 71% | 79% |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 宽度不匹配 | VHDL | 两个 std_logic_vectors 的大小不匹配 | 100% | 100% | 71% | 79%
    |'
- en: '| 5* | Type conversion | VHDL | Can’t perform two operations simultaneously
    in one line | 100% | 92% | 58% | 42% |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 5* | 类型转换 | VHDL | 无法在一行中同时执行两个操作 | 100% | 92% | 58% | 42% |'
- en: '| 6 | Signal and variable | VHDL | Declaring a variable outside of a subprogram
    or process | 100% | 100% | 63% | 63% |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 信号和变量 | VHDL | 在子程序或进程外声明变量 | 100% | 100% | 63% | 63% |'
- en: '| 7 | Concurrent and sequential error | VHDL | Having both ‘wait’ and a sensitivity
    list in the same process | 71% | 67% | 50% | 38% |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 并发与顺序错误 | VHDL | 在同一进程中同时使用 ‘wait’ 和灵敏度列表 | 71% | 67% | 50% | 38% |'
- en: '| 8 | Semantic error | VHDL | Using a signal or variable that has not been
    declared | 100% | 100% | 88% | 88% |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 语义错误 | VHDL | 使用了未声明的信号或变量 | 100% | 100% | 88% | 88% |'
- en: '| 9 | Signal Readability error | VHDL | Attempting to read from an object with
    the mode “out” | 100% | 100% | 96% | 96% |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 信号可读性错误 | VHDL | 尝试从模式为“out”的对象中读取 | 100% | 100% | 96% | 96% |'
- en: '| 10* | Top Level Undefined | VHDL | Incorrect definition of the top-level
    module or entity | 100% | 100% | 83% | 92% |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 10* | 顶层未定义 | VHDL | 顶层模块或实体的定义不正确 | 100% | 100% | 83% | 92% |'
- en: '| 11 | Case error | VHDL | Missing certain choices in a case statement | 100%
    | 100% | 83% | 79% |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| 11 | 案例错误 | VHDL | 在 case 语句中遗漏某些选项 | 100% | 100% | 83% | 79% |'
- en: '| 12 | Singal Bit error | VHDL | Mismatch between a std_logic type and a string
    literal | 58% | 100% | 29% | 92% |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| 12 | 单比特错误 | VHDL | std_logic 类型与字符串字面量不匹配 | 58% | 100% | 29% | 92% |'
- en: '| 13 | Syntax error | Verilog | Missing semicolon | 100% | 100% | 79% | 92%
    |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 13 | 语法错误 | Verilog | 缺少分号 | 100% | 100% | 79% | 92% |'
- en: '| 14 | Semantic error | Verilog | Using an undeclared variable or signal |
    100% | 100% | 83% | 92% |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 14 | 语义错误 | Verilog | 使用未声明的变量或信号 | 100% | 100% | 83% | 92% |'
- en: '| 15 | Wire and Reg error | Verilog | Assign a value declared as wire using
    non-blocking assignments | 100% | 100% | 83% | 92% |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| 15 | 线网和寄存器错误 | Verilog | 使用非阻塞赋值给声明为线网的值 | 100% | 100% | 83% | 92% |'
- en: '| 16 | Blocking and non-blocking | Verilog | Mixing blocking and non-blocking
    assignments to the same variable | 79% | 71% | 58% | 67% |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 16 | 阻塞和非阻塞 | Verilog | 对同一变量混合使用阻塞和非阻塞赋值 | 79% | 71% | 58% | 67% |'
- en: '| 17* | Multiple Driver error | Verilog | Assigning different values to the
    same signal from different processes | 100% | 100% | 67% | 83% |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 17* | 多重驱动器错误 | Verilog | 从不同进程给同一信号赋予不同的值 | 100% | 100% | 67% | 83% |'
- en: '| 18 | Port error | Verilog | Connect a port that does not exist | 100% | 100%
    | 63% | 63% |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 18 | 端口错误 | Verilog | 连接一个不存在的端口 | 100% | 100% | 63% | 63% |'
- en: '| 19 | Binary error | Verilog | Using an illegal character in a binary number
    representation | 100% | 100% | 75% | 100% |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 19 | 二进制错误 | Verilog | 在二进制数字表示中使用非法字符 | 100% | 100% | 75% | 100% |'
- en: '| 20 | Infinite combinational loop | Verilog | Having a infinite combinational
    loop that cannot be resolved | 100% | 100% | 58% | 71% |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 无限组合循环 | Verilog | 存在无法解决的无限组合循环 | 100% | 100% | 58% | 71% |'
- en: '| 21 | Double-edge error | Verilog | Mismatch between operands used in condition
    of an always block | 100% | 100% | 83% | 83% |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 21 | 双边缘错误 | Verilog | always 块条件中使用的操作数不匹配 | 100% | 100% | 83% | 83% |'
- en: '| * Bug 5 only an error in Vivado. Bugs 10 and 17 only an error in Quartus.
    |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| * Bug 5 仅在 Vivado 中出现错误。Bug 10 和 17 仅在 Quartus 中出现错误。 |'
- en: 'In this work, we focus exclusively on synthesis-time bugs rather than the more
    complex run-time issues that could occur. The reasons for this are twofold: (1)
    both the Vivado and Quartus IDEs have limited capabilities in detecting run-time
    issues, given that they primarily rely on user-provided test-benches in simulation
    for this purpose. (2) Run-time issues in the novice-focused area will primarily
    be logic-based, which may be identified by reading simulation waveforms. A user
    having a simulation error thus has more information available to them than one
    who is stuck with an inscrutable and unchanging synthesis error message. In future,
    we plan to extend our study to investigate how LLMs can be leveraged for more
    complex debugging and training.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们专注于合成时错误，而不是可能出现的更复杂的运行时问题。原因有两个：（1）Vivado 和 Quartus IDE 在检测运行时问题方面能力有限，因为它们主要依赖于用户提供的测试平台进行仿真。（2）新手关注的领域中的运行时问题主要是基于逻辑的，可以通过读取仿真波形来识别。因此，遇到仿真错误的用户会比遇到难以解读且无法改变的合成错误消息的用户拥有更多的信息。未来，我们计划扩展研究，探讨如何利用
    LLMs 进行更复杂的调试和培训。
- en: III-C Harvesting Vivado and Quartus error log files
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-C 收集 Vivado 和 Quartus 错误日志文件
- en: Quartus and Vivado can synthesize VHDL and Verilog files into bitstreams for
    FPGAs. When an error occurs, synthesis stops, and the error message is saved to
    a file—Quartus stores synthesis logs in a file like ‘path/to/project/output_files/project.map.rpt’,
    and Vivado ‘path/to/project/project_1.runs/synth_1/runme.log’.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Quartus 和 Vivado 可以将 VHDL 和 Verilog 文件合成到 FPGA 的比特流中。当发生错误时，合成停止，错误消息被保存到文件中——Quartus
    将合成日志存储在如 ‘path/to/project/output_files/project.map.rpt’ 的文件中，而 Vivado 存储在 ‘path/to/project/project_1.runs/synth_1/runme.log’
    中。
- en: As these logs also include other information about the tool flow, we extract
    error messages using regular expressions, scanning for lines beginning with “Error:”
    for Quartus and “ERROR:” for Vivado. Further regular expressions can extract details
    about the error, such as the message, faulty file, and reported error line number.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些日志还包含关于工具流程的其他信息，我们使用正则表达式提取错误消息，扫描以“Error:” 开头的 Quartus 行和以“ERROR:” 开头的
    Vivado 行。进一步的正则表达式可以提取关于错误的详细信息，例如消息、故障文件和报告的错误行号。
- en: III-D Prompting LLMs for error explanations
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-D 提示 LLMs 错误解释
- en: LLMs function by providing an output “response” to an input “prompt’. For this
    study, we selected three of OpenAI’s LLMs, gpt-3.5-turbo, gpt-4, and gpt-4-turbo-preview.
    These first take a “System” prompt to provide overall model guidance, followed
    by “User” prompts which can contain data. As the models evolve over time, we note
    our usage was on March 29, 2024.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 的功能是对输入“提示”提供输出“响应”。在本研究中，我们选择了 OpenAI 的三种 LLM，gpt-3.5-turbo、gpt-4 和 gpt-4-turbo-preview。这些模型首先接受一个“系统”提示以提供整体模型指导，然后是可以包含数据的“用户”提示。随着模型的不断发展，我们注意到我们的使用是在
    2024 年 3 月 29 日。
- en: Recall that the goal of this work is for error explanations not bug repair.
    We therefore base our LLM prompting strategy on that used in prior work [[26](#bib.bib26)],
    which aimed for pedagogically-focused error message explanations. As depicted
    in Figure [4](#Sx1.F4 "Figure 4 ‣ Appendix ‣ Explaining EDA synthesis errors with
    LLMs") (in the Appendix), we used one system prompt (requesting debugging assistance
    but no code outputs) with two similar user prompt options. “Error & Code (E&C)”
    is a straightforward option which provides both the error from the log file, plus
    the entire faulty code file. However, given that LLMs are known to be poor at
    word and line counting, we also examine a second prompt, “Error, Code, & Line
    (EC&L),”, which also reproduces the tool-localised faulty code line a second time
    for emphasis.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，这项工作的目标是解释错误而非修复错误。因此，我们基于先前工作的 LLM 提示策略 [[26](#bib.bib26)]，该策略旨在提供以教学为重点的错误消息解释。如图
    [4](#Sx1.F4 "图 4 ‣ 附录 ‣ 使用 LLM 解释 EDA 综合错误")（在附录中）所示，我们使用了一个系统提示（请求调试帮助但不提供代码输出），并提供了两个类似的用户提示选项。
    “错误和代码 (E&C)” 是一个直接的选项，它提供了来自日志文件的错误以及整个故障代码文件。然而，由于 LLM 通常在单词和行计数方面表现不佳，我们还检查了第二个提示，“错误、代码和行
    (EC&L)”，该提示还会重复工具本地化的故障代码行以强调。
- en: 'TABLE II: Aggregated pedagogical grades for generated explanations grouped
    by IDEs, Language, Prompt Strategies, and LLMs'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 表 II：按 IDE、语言、提示策略和 LLM 聚合的生成解释的教学等级
- en: '| Measurement | Total |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 测量 | 总计 |'
- en: '&#124; IDE &#124;'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; IDE &#124;'
- en: '&#124; Vivado &#124;'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Vivado &#124;'
- en: '|'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; IDE &#124;'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; IDE &#124;'
- en: '&#124; Quartus &#124;'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Quartus &#124;'
- en: '|'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Lang. &#124;'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 语言 &#124;'
- en: '&#124; VHDL &#124;'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; VHDL &#124;'
- en: '|'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Lang. &#124;'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 语言 &#124;'
- en: '&#124; Verilog &#124;'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Verilog &#124;'
- en: '|'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Prompt &#124;'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 提示 &#124;'
- en: '&#124; E&C &#124;'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误和代码 (E&C) &#124;'
- en: '|'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Prompt &#124;'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 提示 &#124;'
- en: '&#124; EC&L &#124;'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误和代码 (EC&L) &#124;'
- en: '|'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; GPT3.5-t. &#124;'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; GPT3.5-t. &#124;'
- en: '&#124; pass@10 &#124;'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 通过@10 &#124;'
- en: '|'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; GPT3.5-t. &#124;'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; GPT3.5-t. &#124;'
- en: '&#124; pass@1 &#124;'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 通过@1 &#124;'
- en: '|'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; GPT4 &#124;'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; GPT4 &#124;'
- en: '&#124; pass@1 &#124;'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 通过@1 &#124;'
- en: '|'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; GPT4-t.-p. &#124;'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; GPT4-t.-p. &#124;'
- en: '&#124; pass@1 &#124;'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 通过@1 &#124;'
- en: '|'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| # responses (n) | 936 | 456 | 480 | 528 | 408 | 468 | 468 | 780 | 78 | 78
    | 78 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| # 响应 (n) | 936 | 456 | 480 | 528 | 408 | 468 | 468 | 780 | 78 | 78 | 78 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| Concept accurate | 94.23% | 92.32% | 96.04% | 92.05% | 97.06% | 93.80% |
    94.66% | 93.33% | 93.59% | 98.72% | 98.72% |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 概念准确度 | 94.23% | 92.32% | 96.04% | 92.05% | 97.06% | 93.80% | 94.66% | 93.33%
    | 93.59% | 98.72% | 98.72% |'
- en: '| No inaccuracies | 91.03% | 88.82% | 93.12% | 86.93% | 96.32% | 89.74% | 92.31%
    | 89.62% | 87.18% | 98.72% | 97.44% |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 无不准确之处 | 91.03% | 88.82% | 93.12% | 86.93% | 96.32% | 89.74% | 92.31% | 89.62%
    | 87.18% | 98.72% | 97.44% |'
- en: '| Relevant | 84.18% | 84.87% | 83.54% | 85.42% | 82.60% | 81.62% | 86.75% |
    88.97% | 83.33% | 60.26% | 60.26% |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 相关性 | 84.18% | 84.87% | 83.54% | 85.42% | 82.60% | 81.62% | 86.75% | 88.97%
    | 83.33% | 60.26% | 60.26% |'
- en: '| Correct & complete | 71.26% | 69.74% | 72.71% | 66.48% | 77.45% | 67.31%
    | 75.21% | 74.36% | 69.23% | 53.85% | 57.69% |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 正确且完整 | 71.26% | 69.74% | 72.71% | 66.48% | 77.45% | 67.31% | 75.21% | 74.36%
    | 69.23% | 53.85% | 57.69% |'
- en: '| Solution is provided | 3.31% | 3.51% | 3.13% | 2.27% | 4.66% | 4.27% | 2.35%
    | 2.82% | 2.56% | 3.85% | 7.69% |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 提供了解决方案 | 3.31% | 3.51% | 3.13% | 2.27% | 4.66% | 4.27% | 2.35% | 2.82% |
    2.56% | 3.85% | 7.69% |'
- en: 'Response Generation: OpenAI’s LLMs are non-deterministic, potentially giving
    different outputs for the same inputs. However, the GPT4 models are also more
    expensive to run. We decided to run the gpt-3.5-turbo model 10 times for each
    bug, and the other models just once, meaning that for each bug in Table [I](#S3.T1
    "Table I ‣ III-B Defining a corpus of bugs ‣ III Digital Design Assistance via
    LLM prompts ‣ Explaining EDA synthesis errors with LLMs") we prompted for LLM
    responses 48 times (2 IDEs $\times$ (10 iterations of gpt-3.5-turbo and 1 each
    of gpt-4 and gpt-4-turbo-preview)). However, as noted in Table [I](#S3.T1 "Table
    I ‣ III-B Defining a corpus of bugs ‣ III Digital Design Assistance via LLM prompts
    ‣ Explaining EDA synthesis errors with LLMs"), during experimentation we found
    that certain bugs (5, 10, and 17) were errors in only one IDE, meaning that in
    total we collected 936 LLM responses for grading.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 响应生成：OpenAI的LLMs是非确定性的，可能对相同的输入产生不同的输出。然而，GPT-4模型的运行成本也更高。我们决定对每个错误运行gpt-3.5-turbo模型10次，而其他模型仅运行一次，这意味着对于表[I](#S3.T1
    "Table I ‣ III-B Defining a corpus of bugs ‣ III Digital Design Assistance via
    LLM prompts ‣ Explaining EDA synthesis errors with LLMs")中的每个错误，我们进行了48次LLM响应提示（2个IDE
    $\times$（10次gpt-3.5-turbo迭代和1次gpt-4以及1次gpt-4-turbo-preview））。然而，正如表[I](#S3.T1
    "Table I ‣ III-B Defining a corpus of bugs ‣ III Digital Design Assistance via
    LLM prompts ‣ Explaining EDA synthesis errors with LLMs")中所示，在实验过程中我们发现某些错误（5、10和17）仅出现在一个IDE中，这意味着我们总共收集了936个LLM响应进行评分。
- en: III-E Manual grading with pedagogically focused metrics
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-E 手动评分与教育学重点的指标
- en: 'It is difficult to automatically judge the quality of answers by a question
    and answer system reliably. In this work we therefore manually grade each of the
    936 LLM-generated explanations against a series of metrics based on those used
    in [[26](#bib.bib26)]. To avoid complexity/marker subjectivity, we only grade
    using binary yes/no questions, and to avoid inter-rater reliability challenges
    all answers were graded uniformly by the first author. Our metrics follow:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 自动判断问答系统回答质量的可靠性是困难的。因此，在这项工作中，我们手动对936个LLM生成的解释进行评分，基于[[26](#bib.bib26)]中使用的指标。为了避免复杂性/评审主观性，我们仅使用二元是/否问题进行评分，并且为了避免评分者间的一致性问题，所有答案均由第一作者统一评分。我们的指标包括：
- en: •
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Concept accurate: i.e. Does the explanation link to the right concepts and
    keywords?'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 概念准确：即解释是否与正确的概念和关键词相关联？
- en: •
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'No inaccuracies: i.e. Does the explanation only contain factually correct information?
    An explanation may be accurate even if it is incomplete. Falsehoods can lead learners
    astray.'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 没有不准确性：即解释是否仅包含事实正确的信息？即使解释不完整，也可以被认为是准确的。虚假的信息可能会误导学习者。
- en: •
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Relevant: i.e. Is the explanation relevant to the problem at hand? Whether
    the explanation is correct or incorrect does not impact the relevance assessment.'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 相关性：即解释是否与当前问题相关？解释是否正确与否不会影响相关性评估。
- en: •
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Correct & complete: i.e. Does the explanation contain everything a user needs
    to understand and fix the error? This is the metric we use to grade overall success.'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 正确且完整：即解释是否包含用户理解和修复错误所需的一切？这是我们用来评估整体成功的指标。
- en: •
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Solution is provided: i.e. Did the model provide ‘too much’ help? From the
    constructivism pedagogy, we know that learners build knowledge better by ‘doing’
    rather than by being directly ‘told’ [[6](#bib.bib6)]. To judge this category,
    we answer ‘Yes’ if an answer was provided with code that could be copied and pasted
    (even if the overall answer was wrong).'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提供了解决方案：即模型是否提供了“过多”的帮助？根据建构主义教育学，我们知道学习者通过“实践”而不是直接“告诉”更好地构建知识[[6](#bib.bib6)]。要评估这一类别，如果提供了可以复制粘贴的代码（即使总体回答是错误的），我们将回答“是”。
- en: Figure [3](#S3.F3 "Figure 3 ‣ III-E Manual grading with pedagogically focused
    metrics ‣ III Digital Design Assistance via LLM prompts ‣ Explaining EDA synthesis
    errors with LLMs") presents two example explanations from gpt-3.5-turbo for Bug
    1 from Figure [1](#S1.F1 "Figure 1 ‣ I Introduction ‣ Explaining EDA synthesis
    errors with LLMs") (a), one judged as ‘good’ and one ‘bad’. The ‘good’ correctly
    identifies the error, and provides a detailed (and complete) method to fix it.
    However, the ‘bad’ misidentifies the error and suggests adding a “then” keyword
    incorrectly. Figures [5](#Sx1.F5 "Figure 5 ‣ Appendix ‣ Explaining EDA synthesis
    errors with LLMs") and [6](#Sx1.F6 "Figure 6 ‣ Appendix ‣ Explaining EDA synthesis
    errors with LLMs") in the Appendix show examples of other metric scores.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图[3](#S3.F3 "Figure 3 ‣ III-E Manual grading with pedagogically focused metrics
    ‣ III Digital Design Assistance via LLM prompts ‣ Explaining EDA synthesis errors
    with LLMs")展示了gpt-3.5-turbo对图[1](#S1.F1 "Figure 1 ‣ I Introduction ‣ Explaining
    EDA synthesis errors with LLMs")中的错误1的两个示例解释，一种被评为‘好’，另一种为‘差’。‘好的’正确识别了错误，并提供了详细（且完整）的方法来修复它。然而，‘差的’错误识别错误，并错误地建议添加一个“then”关键字。附录中的图[5](#Sx1.F5
    "Figure 5 ‣ Appendix ‣ Explaining EDA synthesis errors with LLMs")和图[6](#Sx1.F6
    "Figure 6 ‣ Appendix ‣ Explaining EDA synthesis errors with LLMs")展示了其他指标分数的示例。
- en: 1The  bug  is  in  the  process  statement  of  the  VHDL  code.  The  issue  is  with  the  missing  semicolon  after  ‘data_out  <=  (others  =>  ’0’)‘  within  the  ‘if  rst  =  ’1’  then‘  block.  The  error  message  indicates  that  the  VHDL  syntax  is  expecting  a  semicolon  before  the  ‘elsif‘  keyword.  Adding  the  missing  semicolon  will  resolve  the  syntax  error.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 1该错误出现在VHDL代码的过程语句中。问题是缺少在‘data_out <= (others => '0')‘之后的分号，在‘if rst = '1'
    then‘块内。错误信息表明，VHDL语法期望在‘elsif‘关键字之前出现分号。添加缺失的分号将解决语法错误。
- en: '(a) ‘Good’ explanation—Concept accurate: Yes; Any inaccuracies: No; Relevant:
    Yes; Correct & complete: Yes, Solution is provided: No'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: (a) ‘好的’解释—概念准确：是；有误差：没有；相关：是；正确且完整：是，解决方案已提供：否
- en: 1The  bug  in  the  provided  VHDL  code  is  that  there  is  a  missing  ”then”  keyword  after  the  condition  ‘rst  =  ’1’‘  in  the  ‘if‘  statement.  This  causes  a  syntax  error  when  the  ‘elsif‘  statement  is  encountered  because  the  previous  ‘if‘  statement  is  not  properly  closed.23To  fix  this  bug,  you  should  add  the  ‘then‘  keyword  after  the  condition  ‘rst  =  ’1’‘  in  the  ‘if‘  statement.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 1提供的VHDL代码中的错误是‘if’语句中条件‘rst = '1'‘之后缺少“then”关键字。这会导致在遇到‘elsif‘语句时出现语法错误，因为前面的‘if‘语句没有正确关闭。要修复此错误，应在‘if‘语句中条件‘rst
    = '1'‘之后添加‘then‘关键字。
- en: '(b) ‘Bad’ explanation—Concept accurate: No; Any inaccuracies: Yes; Relevant:
    No; Correct & complete: No, Solution is provided: No'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: (b) ‘差的’解释—概念准确：否；有误差：是；相关：否；正确且完整：否，解决方案已提供：否
- en: 'Figure 3: Example of ‘good’ and ‘bad’ error explanations for Bug 1 (Figure [1](#S1.F1
    "Figure 1 ‣ I Introduction ‣ Explaining EDA synthesis errors with LLMs")) generated
    by gpt-3.5-turbo. Each bug is presented with graded metrics.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：gpt-3.5-turbo生成的图[1](#S1.F1 "Figure 1 ‣ I Introduction ‣ Explaining EDA synthesis
    errors with LLMs")中错误1的‘好’和‘差’错误解释示例。每个错误都附有评分指标。
- en: IV Results
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 结果
- en: 'IV-A Top-line results:'
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A 顶线结果：
- en: Of the graded metrics, we consider the two most important categories ‘Concept
    accurate’ (i.e. the LLM linked to the right error concepts) and ‘Correct & complete’
    (i.e. the LLM provided everything the user needed to fix the problem). Results
    per-bug for these are presented in Table [I](#S3.T1 "Table I ‣ III-B Defining
    a corpus of bugs ‣ III Digital Design Assistance via LLM prompts ‣ Explaining
    EDA synthesis errors with LLMs")’s last four columns. This shows that some bugs
    were easier to explain than others—e.g. Bug 19 was correctly explained in 100%
    of cases. This is likely because certain bugs such as this one are conceptually
    simpler, and more likely to be issues in other languages as well, compared to
    say Bug 7, an error unique to VHDL and only explained correctly in 38% of cases.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在评分的指标中，我们考虑了两个最重要的类别：‘概念准确’（即LLM是否关联到正确的错误概念）和‘正确且完整’（即LLM是否提供了用户解决问题所需的一切）。这些指标的每个错误的结果在表[I](#S3.T1
    "Table I ‣ III-B Defining a corpus of bugs ‣ III Digital Design Assistance via
    LLM prompts ‣ Explaining EDA synthesis errors with LLMs")的最后四列中展示。这表明一些错误比其他错误更容易解释，例如，错误19在100%的情况下都正确解释了。这可能是因为像这种错误在概念上更简单，更可能在其他语言中也存在，而不像错误7那样，它是VHDL特有的，仅在38%的情况下正确解释。
- en: Table [II](#S3.T2 "Table II ‣ III-D Prompting LLMs for error explanations ‣
    III Digital Design Assistance via LLM prompts ‣ Explaining EDA synthesis errors
    with LLMs") presents aggregated metrics across IDEs, Languages, Prompting strategies,
    and LLMs. We see that ‘Correct & complete’ can be thought of as a subset of the
    other metrics, i.e. it may be possible to be relevant and accurate but still not
    feature a complete answer. Overall, conceptually accurate explanations were observed
    in 94% of cases, with slight variations across different contexts. We saw only
    rare occasions where explanations featured outright mistakes (No inaccuracies
    in $\approx$71% of cases.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 表[II](#S3.T2 "表 II ‣ III-D 提示 LLM 进行错误解释 ‣ III 数字设计帮助通过 LLM 提示 ‣ 用 LLM 解释 EDA
    合成错误")展示了跨 IDE、语言、提示策略和 LLM 的汇总指标。我们发现‘正确且完整’可以看作是其他指标的一个子集，即它可能相关且准确，但仍未给出完整的答案。总体而言，在94%的情况下观察到概念上准确的解释，在不同背景下有所变化。我们仅在极少数情况下看到解释中出现明显错误（约71%的情况下没有不准确的内容）。
- en: 'IDEs: Quartus sees better explanations than Vivado, indicating that the information
    provided in Quartus’s error messages may be of higher quality. When we performed
    an informal examination of this, we felt this to be true—for instance, Quartus’s
    error message for Bug 1 (in Figure [1](#S1.F1 "Figure 1 ‣ I Introduction ‣ Explaining
    EDA synthesis errors with LLMs") (a)) includes the words ‘missing semicolon’,
    unlike Vivado.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: IDE：Quartus 的解释优于 Vivado，这表明 Quartus 的错误信息可能质量更高。当我们对此进行非正式检查时，我们也认为这一点是正确的——例如，Quartus
    对 Bug 1 的错误信息（见图[1](#S1.F1 "图 1 ‣ I 引言 ‣ 用 LLM 解释 EDA 合成错误")（a））包含了‘缺少分号’这几个字，而
    Vivado 则没有。
- en: 'Language differences: Interestingly, errors in Verilog seem to be better explained
    than those in VHDL—we theorize this could be because of the relative differences
    in training data available online (Verilog is more popular for open-source).'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 语言差异：有趣的是，Verilog 的错误似乎比 VHDL 的错误解释得更好——我们推测这可能是由于在线训练数据的相对差异（Verilog 更受开源社区欢迎）。
- en: 'Prompting strategies: When comparing the prompting strategies, we see that
    prompts that include the specific error line (EC&L) tend to yield better responses
    ($\approx$67%)—i.e., providing the extra context and information to the language
    models appears to help.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 提示策略：在比较提示策略时，我们发现包含具体错误行（EC&L）的提示往往会产生更好的响应（约67%）——即，为语言模型提供额外的背景和信息似乎有助于提高响应质量。
- en: 'LLMs: To fairly compare the LLMs, we tabulated just the first responses (i.e.
    ‘pass@1’) received by gpt-3.5-turbo alongside the responses by gpt-4 and gpt-4-turbo-preview.
    Counter-intuitively, the smaller model (GPT-3.5) outperforms the two larger models
    in ‘correct & complete’, but the larger models are better at returning conceptually
    accurate responses without inaccuracies, although they have a greater tendency
    to over-help.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs：为了公平比较 LLM，我们仅列出了 gpt-3.5-turbo 收到的首次响应（即‘pass@1’），以及 gpt-4 和 gpt-4-turbo-preview
    的响应。反直觉的是，较小的模型（GPT-3.5）在‘正确且完整’方面优于两个较大的模型，但较大的模型在返回概念上准确的响应时表现更好，尽管它们更容易过度帮助。
- en: IV-B Discussion
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-B 讨论
- en: LLMs generate their responses based on the data they have been trained over
    and on their ability to retain that data. For hardware as compared to software,
    there is much less training data online [[10](#bib.bib10)]. Still, when we compare
    our generated HDL explanations with the C error explanations from [[26](#bib.bib26)],
    we see that both works have $\approx$71% correct & complete, indicating that for
    this use case the data gap may not be significant.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 根据它们接受训练的数据和保留这些数据的能力生成响应。与软件相比，硬件的在线训练数据要少得多[[10](#bib.bib10)]。尽管如此，当我们将生成的
    HDL 解释与 [[26](#bib.bib26)] 中的 C 错误解释进行比较时，我们发现两者的‘正确且完整’均约为71%，这表明在这一用例中，数据差距可能并不显著。
- en: Interestingly, our HDL explanations have a much lower incident rate of over-help
    (‘Solution is provided’) than in [[26](#bib.bib26)]—just 3.35% compared with their
    48%. It is not immediately clear why this could be the case, as they also instructed
    GPT-3.5 to not emit answers directly. Perhaps OpenAI’s LLMs ‘understand’ C better,
    and so inadvertently are aligned to give out too much help. If model size can
    be thought of as a proxy for ‘intelligence’, then this can also be observed with
    the larger model sizes in our work, where the GPT-4 models (which may ‘understand’
    the code better) had a higher rate of over-help compared to the smaller GPT-3.5.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，我们的HDL解释的过度帮助（‘提供了解决方案’）发生率比[[26](#bib.bib26)]要低得多——仅3.35%，而他们的为48%。这为何会这样还不清楚，因为他们也指示GPT-3.5不要直接给出答案。也许OpenAI的LLMs对C语言的‘理解’更好，因此不经意间提供了过多帮助。如果模型大小可以被视为‘智能’的代理，那么在我们工作的较大模型中也可以观察到这一点，GPT-4模型（可能更‘理解’代码）相比较小的GPT-3.5具有更高的过度帮助率。
- en: V Conclusion
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V 结论
- en: This work set out to examine if LLMs could explain the kinds of synthesis errors
    that novice users of EDA tools will encounter. Our findings suggest that they
    indeed can, with 18/21 explored errors seeing good explanations in a majority
    of the LLM responses and 71% of explanations being complete and correct overall.
    This work serves as a valuable proof of concept for LLM-powered techniques for
    improving the accessibility of EDA tools like Vivado and Quartus, and we believe
    that additional research in this area could significantly change how EDA tools
    are both learned and utilised by both novice and experienced engineers.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这项工作旨在探讨LLMs是否能够解释初学者在使用EDA工具时会遇到的合成错误类型。我们的发现表明，它们确实可以，18/21的探讨错误在大多数LLM响应中得到了良好的解释，71%的解释总体上是完整且正确的。这项工作作为一个有价值的概念验证，展示了LLM驱动的技术如何改善EDA工具如Vivado和Quartus的可及性，我们相信在这一领域的进一步研究可能会显著改变EDA工具的学习和使用方式，无论是对初学者还是有经验的工程师。
- en: References
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] S. A. Edwards, “Experiences teaching an FPGA-based embedded systems class,”
    *ACM SIGBED Review*, vol. 2, no. 4, pp. 56–62, Oct. 2005\. [Online]. Available:
    [https://dl.acm.org/doi/10.1145/1121812.1121823](https://dl.acm.org/doi/10.1145/1121812.1121823)'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] S. A. Edwards, “教授基于FPGA的嵌入式系统课程的经验，” *ACM SIGBED评论*，第2卷，第4期，第56–62页，2005年10月。[在线]。可用链接：[https://dl.acm.org/doi/10.1145/1121812.1121823](https://dl.acm.org/doi/10.1145/1121812.1121823)'
- en: '[2] S. Pasricha, “Embedded Systems Education in the 2020s: Challenges, Reflections,
    and Future Directions,” in *Proceedings of the Great Lakes Symposium on VLSI 2022*,
    ser. GLSVLSI ’22.   New York, NY, USA: Association for Computing Machinery, Jun.
    2022, pp. 519–524\. [Online]. Available: [https://dl.acm.org/doi/10.1145/3526241.3530348](https://dl.acm.org/doi/10.1145/3526241.3530348)'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] S. Pasricha, “2020年代嵌入式系统教育：挑战、反思与未来方向，”在*2022年大湖区VLSI研讨会论文集*中，系列GLSVLSI
    ’22。纽约，NY，USA：计算机协会，2022年6月，第519–524页。[在线]。可用链接：[https://dl.acm.org/doi/10.1145/3526241.3530348](https://dl.acm.org/doi/10.1145/3526241.3530348)'
- en: '[3] M. A. Cherney, “U.S. will be short 67,000 chip workers by 2030, industry
    group says,” *Reuters*, Jul. 2023\. [Online]. Available: [https://www.reuters.com/technology/us-will-be-short-67000-chip-workers-by-2030-industry-group-says-2023-07-25/](https://www.reuters.com/technology/us-will-be-short-67000-chip-workers-by-2030-industry-group-says-2023-07-25/)'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] M. A. Cherney, “美国到2030年将缺少67,000名芯片工人，行业组织表示，” *路透社*，2023年7月。[在线]。可用链接：[https://www.reuters.com/technology/us-will-be-short-67000-chip-workers-by-2030-industry-group-says-2023-07-25/](https://www.reuters.com/technology/us-will-be-short-67000-chip-workers-by-2030-industry-group-says-2023-07-25/)'
- en: '[4] B. A. Becker, G. Glanville, R. Iwashima, C. McDonnell, K. Goslin, and C. Mooney,
    “Effective compiler error message enhancement for novice programming students,”
    *Computer Science Education*, vol. 26, no. 2-3, pp. 148–175, Jul. 2016\. [Online].
    Available: [https://doi.org/10.1080/08993408.2016.1225464](https://doi.org/10.1080/08993408.2016.1225464)'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] B. A. Becker, G. Glanville, R. Iwashima, C. McDonnell, K. Goslin, 和 C.
    Mooney, “对初学者编程学生的有效编译器错误信息增强，” *计算机科学教育*，第26卷，第2-3期，第148–175页，2016年7月。[在线]。可用链接：[https://doi.org/10.1080/08993408.2016.1225464](https://doi.org/10.1080/08993408.2016.1225464)'
- en: '[5] I. Karvelas, A. Li, and B. A. Becker, “The Effects of Compilation Mechanisms
    and Error Message Presentation on Novice Programmer Behavior,” in *Proceedings
    of the 51st ACM Technical Symposium on Computer Science Education*, ser. SIGCSE
    ’20.   New York, NY, USA: Association for Computing Machinery, Feb. 2020, pp.
    759–765\. [Online]. Available: [https://dl.acm.org/doi/10.1145/3328778.3366882](https://dl.acm.org/doi/10.1145/3328778.3366882)'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] I. Karvelas, A. Li, 和 B. A. Becker，“编译机制和错误信息展示对初学者程序员行为的影响，”在*第51届 ACM
    计算机科学教育技术研讨会论文集*中，系列 SIGCSE ’20。 纽约，NY，美国: 计算机协会，2020年2月，第759–765页。[在线]. 可用： [https://dl.acm.org/doi/10.1145/3328778.3366882](https://dl.acm.org/doi/10.1145/3328778.3366882)'
- en: '[6] M. Ben-Ari, “Constructivism in Computer Science Education,” *Journal of
    Computers in Mathematics and Science Teaching*, vol. 20, no. 1, pp. 45–73, 2001,
    publisher: Association for the Advancement of Computing in Education (AACE). [Online].
    Available: [https://www.learntechlib.org/primary/p/8505/](https://www.learntechlib.org/primary/p/8505/)'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] M. Ben-Ari，“计算机科学教育中的建构主义，”*数学与科学教学计算机期刊*，第20卷，第1期，第45–73页，2001年，出版商：计算机教育进步协会（AACE）。
    [在线]. 可用： [https://www.learntechlib.org/primary/p/8505/](https://www.learntechlib.org/primary/p/8505/)'
- en: '[7] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang,
    S. Agarwal, K. Slama, A. Ray, J. Schulman, J. Hilton, F. Kelton, L. Miller, M. Simens,
    A. Askell, P. Welinder, P. F. Christiano, J. Leike, and R. Lowe, “Training language
    models to follow instructions with human feedback,” in *Advances in Neural Information
    Processing Systems*, S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and
    A. Oh, Eds., vol. 35.   Curran Associates, Inc., 2022, pp. 27 730–27 744\. [Online].
    Available: [https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf](https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf)'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang,
    S. Agarwal, K. Slama, A. Ray, J. Schulman, J. Hilton, F. Kelton, L. Miller, M.
    Simens, A. Askell, P. Welinder, P. F. Christiano, J. Leike, 和 R. Lowe，“训练语言模型以遵循人类反馈的指令，”在*神经信息处理系统进展*中，S.
    Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, 和 A. Oh 主编，第35卷。 Curran Associates,
    Inc.，2022年，第27 730–27 744页。[在线]. 可用： [https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf](https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf)'
- en: '[8] OpenAI, “ChatGPT: Optimizing Language Models for Dialogue,” Nov. 2022\.
    [Online]. Available: [https://openai.com/blog/chatgpt/](https://openai.com/blog/chatgpt/)'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] OpenAI，“ChatGPT: 为对话优化语言模型，”2022年11月。[在线]. 可用： [https://openai.com/blog/chatgpt/](https://openai.com/blog/chatgpt/)'
- en: '[9] H. Pearce, B. Tan, and R. Karri, “DAVE: Deriving Automatically Verilog
    from English,” in *Proceedings of the 2020 ACM/IEEE Workshop on Machine Learning
    for CAD*.   Virtual Event Iceland: ACM, Nov. 2020, pp. 27–32\. [Online]. Available:
    [https://dl.acm.org/doi/10.1145/3380446.3430634](https://dl.acm.org/doi/10.1145/3380446.3430634)'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] H. Pearce, B. Tan, 和 R. Karri，“DAVE: 从英语自动推导 Verilog，”在*2020 年 ACM/IEEE
    计算机辅助设计机器学习研讨会论文集*中。 虚拟事件冰岛: ACM，2020年11月，第27–32页。[在线]. 可用： [https://dl.acm.org/doi/10.1145/3380446.3430634](https://dl.acm.org/doi/10.1145/3380446.3430634)'
- en: '[10] S. Thakur, B. Ahmad, Z. Fan, H. Pearce, B. Tan, R. Karri, B. Dolan-Gavitt,
    and S. Garg, “Benchmarking Large Language Models for Automated Verilog RTL Code
    Generation,” in *2023 Design, Automation & Test in Europe Conference & Exhibition
    (DATE)*, Apr. 2023, pp. 1–6, iSSN: 1558-1101\. [Online]. Available: [https://ieeexplore.ieee.org/abstract/document/10137086](https://ieeexplore.ieee.org/abstract/document/10137086)'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] S. Thakur, B. Ahmad, Z. Fan, H. Pearce, B. Tan, R. Karri, B. Dolan-Gavitt,
    和 S. Garg，“对大型语言模型进行自动化 Verilog RTL 代码生成的基准测试，”在*2023 设计、自动化与测试欧洲会议与展览（DATE）*中，2023年4月，第1–6页，iSSN:
    1558-1101。[在线]. 可用： [https://ieeexplore.ieee.org/abstract/document/10137086](https://ieeexplore.ieee.org/abstract/document/10137086)'
- en: '[11] S. Thakur, B. Ahmad, H. Pearce, B. Tan, B. Dolan-Gavitt, R. Karri, and
    S. Garg, “VeriGen: A Large Language Model for Verilog Code Generation,” *ACM Transactions
    on Design Automation of Electronic Systems*, Feb. 2024, just Accepted. [Online].
    Available: [https://dl.acm.org/doi/10.1145/3643681](https://dl.acm.org/doi/10.1145/3643681)'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] S. Thakur, B. Ahmad, H. Pearce, B. Tan, B. Dolan-Gavitt, R. Karri, 和 S.
    Garg，“VeriGen: 一种用于 Verilog 代码生成的大型语言模型，”*ACM 电子系统设计自动化交易*，2024年2月，刚刚接受。[在线].
    可用： [https://dl.acm.org/doi/10.1145/3643681](https://dl.acm.org/doi/10.1145/3643681)'
- en: '[12] M. Liu, N. Pinckney, B. Khailany, and H. Ren, “Invited Paper: VerilogEval:
    Evaluating Large Language Models for Verilog Code Generation,” in *2023 IEEE/ACM
    International Conference on Computer Aided Design (ICCAD)*, Oct. 2023, pp. 1–8,
    iSSN: 1558-2434\. [Online]. Available: [https://ieeexplore.ieee.org/abstract/document/10323812](https://ieeexplore.ieee.org/abstract/document/10323812)'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] M. Liu, N. Pinckney, B. Khailany, 和 H. Ren, “邀请论文：VerilogEval：评估大型语言模型在
    Verilog 代码生成中的表现，”发表于*2023 IEEE/ACM 国际计算机辅助设计会议 (ICCAD)*，2023年10月，第1–8页，iSSN:
    1558-2434。[在线]。可访问：[https://ieeexplore.ieee.org/abstract/document/10323812](https://ieeexplore.ieee.org/abstract/document/10323812)'
- en: '[13] B. Ahmad, S. Thakur, B. Tan, R. Karri, and H. Pearce, “On Hardware Security
    Bug Code Fixes By Prompting Large Language Models,” *IEEE Transactions on Information
    Forensics and Security*, pp. 1–1, 2024, conference Name: IEEE Transactions on
    Information Forensics and Security. [Online]. Available: [https://ieeexplore.ieee.org/abstract/document/10462177](https://ieeexplore.ieee.org/abstract/document/10462177)'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] B. Ahmad, S. Thakur, B. Tan, R. Karri, 和 H. Pearce, “通过提示大型语言模型修复硬件安全漏洞代码，”*IEEE
    信息取证与安全交易*，第1–1页，2024年，会议名称：IEEE 信息取证与安全交易。[在线]。可访问：[https://ieeexplore.ieee.org/abstract/document/10462177](https://ieeexplore.ieee.org/abstract/document/10462177)'
- en: '[14] R. Kande, H. Pearce, B. Tan, B. Dolan-Gavitt, S. Thakur, R. Karri, and
    J. Rajendran, “(Security) Assertions by Large Language Models,” *IEEE Transactions
    on Information Forensics and Security*, pp. 1–1, 2024, conference Name: IEEE Transactions
    on Information Forensics and Security. [Online]. Available: [https://ieeexplore.ieee.org/abstract/document/10458667](https://ieeexplore.ieee.org/abstract/document/10458667)'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] R. Kande, H. Pearce, B. Tan, B. Dolan-Gavitt, S. Thakur, R. Karri, 和 J.
    Rajendran, “(安全性)大型语言模型的声明，”*IEEE 信息取证与安全交易*，第1–1页，2024年，会议名称：IEEE 信息取证与安全交易。[在线]。可访问：[https://ieeexplore.ieee.org/abstract/document/10458667](https://ieeexplore.ieee.org/abstract/document/10458667)'
- en: '[15] M. Liu, T.-D. Ene, R. Kirby, C. Cheng, N. Pinckney, R. Liang, J. Alben,
    H. Anand, S. Banerjee, I. Bayraktaroglu, B. Bhaskaran, B. Catanzaro, A. Chaudhuri,
    S. Clay, B. Dally, L. Dang, P. Deshpande, S. Dhodhi, S. Halepete, E. Hill, J. Hu,
    S. Jain, B. Khailany, K. Kunal, X. Li, H. Liu, S. Oberman, S. Omar, S. Pratty,
    J. Raiman, A. Sarkar, Z. Shao, H. Sun, P. P. Suthar, V. Tej, K. Xu, and H. Ren,
    “ChipNeMo: Domain-Adapted LLMs for Chip Design,” Nov. 2023, arXiv:2311.00176 [cs].
    [Online]. Available: [http://arxiv.org/abs/2311.00176](http://arxiv.org/abs/2311.00176)'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] M. Liu, T.-D. Ene, R. Kirby, C. Cheng, N. Pinckney, R. Liang, J. Alben,
    H. Anand, S. Banerjee, I. Bayraktaroglu, B. Bhaskaran, B. Catanzaro, A. Chaudhuri,
    S. Clay, B. Dally, L. Dang, P. Deshpande, S. Dhodhi, S. Halepete, E. Hill, J.
    Hu, S. Jain, B. Khailany, K. Kunal, X. Li, H. Liu, S. Oberman, S. Omar, S. Pratty,
    J. Raiman, A. Sarkar, Z. Shao, H. Sun, P. P. Suthar, V. Tej, K. Xu, 和 H. Ren,
    “ChipNeMo: 适应领域的大型语言模型用于芯片设计，”2023年11月，arXiv:2311.00176 [cs]。[在线]。可访问：[http://arxiv.org/abs/2311.00176](http://arxiv.org/abs/2311.00176)'
- en: '[16] J. Blocklove, S. Garg, R. Karri, and H. Pearce, “Chip-Chat: Challenges
    and Opportunities in Conversational Hardware Design,” in *2023 ACM/IEEE 5th Workshop
    on Machine Learning for CAD (MLCAD)*, Sep. 2023, pp. 1–6\. [Online]. Available:
    [https://ieeexplore.ieee.org/document/10299874](https://ieeexplore.ieee.org/document/10299874)'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] J. Blocklove, S. Garg, R. Karri, 和 H. Pearce, “Chip-Chat: Conversational
    Hardware Design 的挑战与机遇，”发表于*2023 ACM/IEEE 第五届计算机辅助设计机器学习研讨会 (MLCAD)*，2023年9月，第1–6页。[在线]。可访问：[https://ieeexplore.ieee.org/document/10299874](https://ieeexplore.ieee.org/document/10299874)'
- en: '[17] E. Kasneci, K. Sessler, S. Küchemann, M. Bannert, D. Dementieva, F. Fischer,
    U. Gasser, G. Groh, S. Günnemann, E. Hüllermeier, S. Krusche, G. Kutyniok, T. Michaeli,
    C. Nerdel, J. Pfeffer, O. Poquet, M. Sailer, A. Schmidt, T. Seidel, M. Stadler,
    J. Weller, J. Kuhn, and G. Kasneci, “ChatGPT for good? On opportunities and challenges
    of large language models for education,” *Learning and Individual Differences*,
    vol. 103, p. 102274, Apr. 2023\. [Online]. Available: [https://www.sciencedirect.com/science/article/pii/S1041608023000195](https://www.sciencedirect.com/science/article/pii/S1041608023000195)'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] E. Kasneci, K. Sessler, S. Küchemann, M. Bannert, D. Dementieva, F. Fischer,
    U. Gasser, G. Groh, S. Günnemann, E. Hüllermeier, S. Krusche, G. Kutyniok, T.
    Michaeli, C. Nerdel, J. Pfeffer, O. Poquet, M. Sailer, A. Schmidt, T. Seidel,
    M. Stadler, J. Weller, J. Kuhn, 和 G. Kasneci, “ChatGPT 为善？大型语言模型在教育中的机遇与挑战，”*学习与个体差异*，第103卷，第102274页，2023年4月。[在线]。可访问：[https://www.sciencedirect.com/science/article/pii/S1041608023000195](https://www.sciencedirect.com/science/article/pii/S1041608023000195)'
- en: '[18] R. Dijkstra, Z. Genç, S. Kayal, J. Kamps, and others, “Reading Comprehension
    Quiz Generation using Generative Pre-trained Transformers,” 2022\. [Online]. Available:
    [https://e.humanities.uva.nl/publications/2022/dijk_read22.pdf](https://e.humanities.uva.nl/publications/2022/dijk_read22.pdf)'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] R. Dijkstra、Z. Genç、S. Kayal、J. Kamps 等，"使用生成预训练变换器生成阅读理解测验"，2022年。[在线]。可用：
    [https://e.humanities.uva.nl/publications/2022/dijk_read22.pdf](https://e.humanities.uva.nl/publications/2022/dijk_read22.pdf)'
- en: '[19] E. Gabajiwala, P. Mehta, R. Singh, and R. Koshy, “Quiz Maker: Automatic
    Quiz Generation from Text Using NLP,” in *Futuristic Trends in Networks and Computing
    Technologies*, ser. Lecture Notes in Electrical Engineering, P. K. Singh, S. T.
    Wierzchoń, J. K. Chhabra, and S. Tanwar, Eds.   Singapore: Springer Nature, 2022,
    pp. 523–533.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] E. Gabajiwala、P. Mehta、R. Singh 和 R. Koshy，"Quiz Maker：使用 NLP 从文本自动生成测验"，发表于
    *网络与计算技术中的前沿趋势*，系列：电气工程讲义，P. K. Singh、S. T. Wierzchoń、J. K. Chhabra 和 S. Tanwar
    编辑。 新加坡：施普林格自然，2022年，第523–533页。'
- en: '[20] S. Jalil, S. Rafi, T. D. LaToza, K. Moran, and W. Lam, “ChatGPT and Software
    Testing Education: Promises & Perils,” in *2023 IEEE International Conference
    on Software Testing, Verification and Validation Workshops (ICSTW)*, Apr. 2023,
    pp. 4130–4137, iSSN: 2159-4848\. [Online]. Available: [https://ieeexplore.ieee.org/abstract/document/10132255](https://ieeexplore.ieee.org/abstract/document/10132255)'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] S. Jalil、S. Rafi、T. D. LaToza、K. Moran 和 W. Lam，"ChatGPT 和软件测试教育：承诺与风险"，发表于
    *2023 IEEE 国际软件测试、验证与验证研讨会（ICSTW）*，2023年4月，第4130–4137页，iSSN: 2159-4848。[在线]。可用：
    [https://ieeexplore.ieee.org/abstract/document/10132255](https://ieeexplore.ieee.org/abstract/document/10132255)'
- en: '[21] B. A. Becker, P. Denny, J. Finnie-Ansley, A. Luxton-Reilly, J. Prather,
    and E. A. Santos, “Programming Is Hard - Or at Least It Used to Be: Educational
    Opportunities and Challenges of AI Code Generation,” in *Proceedings of the 54th
    ACM Technical Symposium on Computer Science Education V. 1*, ser. SIGCSE 2023.   New
    York, NY, USA: Association for Computing Machinery, Mar. 2023, pp. 500–506\. [Online].
    Available: [https://dl.acm.org/doi/10.1145/3545945.3569759](https://dl.acm.org/doi/10.1145/3545945.3569759)'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] B. A. Becker、P. Denny、J. Finnie-Ansley、A. Luxton-Reilly、J. Prather 和 E.
    A. Santos，"编程很难 - 或者至少以前很难：AI 代码生成的教育机会与挑战"，发表于 *第54届 ACM 计算机科学教育技术研讨会，第 1 卷*，系列：SIGCSE
    2023。 纽约，NY，美国：计算机协会，2023年3月，第500–506页。[在线]。可用： [https://dl.acm.org/doi/10.1145/3545945.3569759](https://dl.acm.org/doi/10.1145/3545945.3569759)'
- en: '[22] P. Denny, V. Kumar, and N. Giacaman, “Conversing with Copilot: Exploring
    Prompt Engineering for Solving CS1 Problems Using Natural Language,” in *Proceedings
    of the 54th ACM Technical Symposium on Computer Science Education V. 1*, ser.
    SIGCSE 2023.   New York, NY, USA: Association for Computing Machinery, Mar. 2023,
    pp. 1136–1142\. [Online]. Available: [https://dl.acm.org/doi/10.1145/3545945.3569823](https://dl.acm.org/doi/10.1145/3545945.3569823)'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] P. Denny、V. Kumar 和 N. Giacaman，"与 Copilot 对话：探索利用自然语言解决 CS1 问题的提示工程"，发表于
    *第54届 ACM 计算机科学教育技术研讨会，第 1 卷*，系列：SIGCSE 2023。 纽约，NY，美国：计算机协会，2023年3月，第1136–1142页。[在线]。可用：
    [https://dl.acm.org/doi/10.1145/3545945.3569823](https://dl.acm.org/doi/10.1145/3545945.3569823)'
- en: '[23] S. MacNeil, A. Tran, J. Leinonen, P. Denny, J. Kim, A. Hellas, S. Bernstein,
    and S. Sarsa, “Automatically Generating CS Learning Materials with Large Language
    Models,” in *Proceedings of the 54th ACM Technical Symposium on Computer Science
    Education V. 2*, Mar. 2022, pp. 1176–1176, arXiv:2212.05113 [cs]. [Online]. Available:
    [http://arxiv.org/abs/2212.05113](http://arxiv.org/abs/2212.05113)'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] S. MacNeil、A. Tran、J. Leinonen、P. Denny、J. Kim、A. Hellas、S. Bernstein
    和 S. Sarsa，"利用大型语言模型自动生成 CS 学习材料"，发表于 *第54届 ACM 计算机科学教育技术研讨会，第 2 卷*，2022年3月，第1176–1176页，arXiv:2212.05113
    [cs]。[在线]。可用： [http://arxiv.org/abs/2212.05113](http://arxiv.org/abs/2212.05113)'
- en: '[24] S. MacNeil, A. Tran, A. Hellas, J. Kim, S. Sarsa, P. Denny, S. Bernstein,
    and J. Leinonen, “Experiences from Using Code Explanations Generated by Large
    Language Models in a Web Software Development E-Book,” in *Proceedings of the
    54th ACM Technical Symposium on Computer Science Education V. 1*, ser. SIGCSE
    2023.   New York, NY, USA: Association for Computing Machinery, Mar. 2023, pp.
    931–937\. [Online]. Available: [https://dl.acm.org/doi/10.1145/3545945.3569785](https://dl.acm.org/doi/10.1145/3545945.3569785)'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] S. MacNeil、A. Tran、A. Hellas、J. Kim、S. Sarsa、P. Denny、S. Bernstein 和 J.
    Leinonen，"使用大型语言模型生成的代码解释的经验：一种 Web 软件开发电子书"，发表于 *第54届 ACM 计算机科学教育技术研讨会，第 1 卷*，系列：SIGCSE
    2023。 纽约，NY，美国：计算机协会，2023年3月，第931–937页。[在线]。可用： [https://dl.acm.org/doi/10.1145/3545945.3569785](https://dl.acm.org/doi/10.1145/3545945.3569785)'
- en: '[25] S. MacNeil, A. Tran, D. Mogil, S. Bernstein, E. Ross, and Z. Huang, “Generating
    Diverse Code Explanations using the GPT-3 Large Language Model,” in *Proceedings
    of the 2022 ACM Conference on International Computing Education Research - Volume
    2*, ser. ICER ’22, vol. 2.   New York, NY, USA: Association for Computing Machinery,
    Aug. 2022, pp. 37–39\. [Online]. Available: [https://dl.acm.org/doi/10.1145/3501709.3544280](https://dl.acm.org/doi/10.1145/3501709.3544280)'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] S. MacNeil, A. Tran, D. Mogil, S. Bernstein, E. Ross, 和 Z. Huang, “使用
    GPT-3 大型语言模型生成多样化代码解释，” 见 *2022 年 ACM 国际计算教育研究会议论文集 - 第 2 卷*，系列 ICER ’22，第 2 卷.
    纽约, NY, USA: 计算机协会, 2022年8月, 页37–39\. [在线]. 可用： [https://dl.acm.org/doi/10.1145/3501709.3544280](https://dl.acm.org/doi/10.1145/3501709.3544280)'
- en: '[26] A. Taylor, A. Vassar, J. Renzella, and H. Pearce, “dcc –help: Transforming
    the Role of the Compiler by Generating Context-Aware Error Explanations with Large
    Language Models,” in *Proceedings of the 55th ACM Technical Symposium on Computer
    Science Education V. 1*, ser. SIGCSE 2024.   New York, NY, USA: Association for
    Computing Machinery, Mar. 2024, pp. 1314–1320\. [Online]. Available: [https://dl.acm.org/doi/10.1145/3626252.3630822](https://dl.acm.org/doi/10.1145/3626252.3630822)'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] A. Taylor, A. Vassar, J. Renzella, 和 H. Pearce, “dcc –help: 利用大型语言模型生成上下文感知错误解释，改变编译器的角色，”
    见 *第55届 ACM 计算机科学教育技术研讨会论文集 V. 1*，系列 SIGCSE 2024. 纽约, NY, USA: 计算机协会, 2024年3月,
    页1314–1320\. [在线]. 可用： [https://dl.acm.org/doi/10.1145/3626252.3630822](https://dl.acm.org/doi/10.1145/3626252.3630822)'
- en: Appendix
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录
- en: Figure [4](#Sx1.F4 "Figure 4 ‣ Appendix ‣ Explaining EDA synthesis errors with
    LLMs") shows the system and user prompt templates used to generate the error explanations
    in this study. Prompting was the same for all 3 OpenAI models.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [4](#Sx1.F4 "图 4 ‣ 附录 ‣ 使用 LLM 解释 EDA 综合错误") 显示了用于生成本研究中错误解释的系统和用户提示模板。所有
    3 个 OpenAI 模型的提示方式相同。
- en: 1You  are  a  helpful  assistant  which  debugs  RTL  and  HDL  code  in  Verilog  and  VHDL.  Do  not  provide  code  in  your  answer.  Explain  what  has  gone  wrong  and  why  a  bug  is  occurring,  but  do  not  attempt  to  fix  the  bug  yourself.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 你是一个有用的助手，负责调试 RTL 和 HDL 代码（使用 Verilog 和 VHDL）。请不要在回答中提供代码。解释出错的原因及其发生的原因，但不要尝试自行修复错误。
- en: (a) System prompt.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 系统提示。
- en: '1Error  message:  %s23Full  code  file:“‘%s“‘45What  is  the  bug  and  why  is  it  occurring?'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 错误信息：%s23完整代码文件：“‘%s“‘45错误是什么，为什么会发生？
- en: (b) Error & Code (E&C) prompt template.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 错误和代码（E&C）提示模板。
- en: '1Error  message:  %s23Error  line:“‘%s“‘45Full  code  file:“‘%s“‘67What  is  the  bug  and  why  is  it  occurring?'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 错误信息：%s23错误行：“‘%s“‘45完整代码文件：“‘%s“‘67错误是什么，为什么会发生？
- en: (c) Error, Code, & Line (EC&L) prompt template.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 错误、代码和行（EC&L）提示模板。
- en: 'Figure 4: LLM prompts'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '图 4: LLM 提示'
- en: Figure [5](#Sx1.F5 "Figure 5 ‣ Appendix ‣ Explaining EDA synthesis errors with
    LLMs") shows an explanation with ‘solution is provided’.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [5](#Sx1.F5 "图 5 ‣ 附录 ‣ 使用 LLM 解释 EDA 综合错误") 显示了带有“提供了解决方案”的解释。
- en: 1The  error  message  is  indicating  that  there’s  syntax  error  near  the  ’elsif’  keyword.23By  looking  at  your  VHDL  code,  the  problem  is  that  you  are  missing  a  semicolon  at  the  end  of  the  line  after  the  assignment  operation  when  the  rst  is  ’1’.  In  VHDL,  every  statement  ends  with  a  semicolon.45The  line  of  the  code:6“‘7if  rst  =  ’1’  then8  data_out  <=  (others  =>  ’0’)  –Missing  semicolon  here9“‘1011Should  be  corrected  with  a  semicolon  at  the  end  as:12“‘13if  rst  =  ’1’  then14  data_out  <=  (others  =>  ’0’);  –Add  semicolon  here15“‘1617Your  synthesizer  (the  tool  that’s  processing  your  VHDL  code)  is  seeing  the  ’elsif’  as  being  part  of  the  previous  line  (because  there  was  no  semicolon  to  end  it)  and  is  confused  as  this  doesn’t  make  sense  and  therefore  throws  an  error.  This  is  why  the  error  message  is  suggesting  there  may  be  a  problem  near  the  ’elsif’.1819After  adding  the  semicolon  at  the  end  of  the  line  in  question,  the  issue  should  be  resolved.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 1错误信息表明在’elsif’关键字附近存在语法错误。23通过查看你的VHDL代码，问题在于你在赋值操作后的行尾缺少分号，当`rst`为’1’时。在VHDL中，每个语句都以分号结尾。45代码行：6“‘7if
    rst = ’1’ then8 data_out <= (others => ’0’) –此处缺少分号9“‘1011应该在末尾加上分号，如下：12“‘13if
    rst = ’1’ then14 data_out <= (others => ’0’); –在此处添加分号15“‘1617你的合成器（处理你的VHDL代码的工具）将’elsif’视为上一行的一部分（因为没有分号结束），因此感到困惑，因为这没有意义，因此抛出错误。这就是为什么错误信息建议’elsif’附近可能有问题。1819在问题行末尾添加分号后，问题应该会解决。
- en: 'Scores—Concept accurate: Yes; Any inaccuracies: No; Relevant: Yes; Correct
    & complete: Yes, Solution is provided: Yes'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 分数—概念准确：是；有无不准确：无；相关：是；正确且完整：是，提供了解决方案：是
- en: 'Figure 5: A ‘good’ error explanation for Bug 1 (Figure [1](#S1.F1 "Figure 1
    ‣ I Introduction ‣ Explaining EDA synthesis errors with LLMs")) generated by gpt-4.
    However, this explanation is flagged ‘Solution is provided’ as it contains a direct
    copy/paste solution on Lines 12-15—i.e., the explanation helps ‘too much’ according
    to constructivism in pedagogy.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：由gpt-4生成的Bug 1（图[1](#S1.F1 "Figure 1 ‣ I Introduction ‣ Explaining EDA synthesis
    errors with LLMs")）的‘好’错误解释。然而，这个解释被标记为‘提供了解决方案’，因为它在第12-15行包含了直接复制/粘贴的解决方案——即，根据教育学中的建构主义，这个解释帮助‘过多’。
- en: Figure [6](#Sx1.F6 "Figure 6 ‣ Appendix ‣ Explaining EDA synthesis errors with
    LLMs") illustrates the difference between an explanation flagged as ‘relevant’
    versus one flagged as ‘concept accurate’, i.e. the two metrics do not necessarily
    imply each other.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图[6](#Sx1.F6 "Figure 6 ‣ Appendix ‣ Explaining EDA synthesis errors with LLMs")展示了标记为‘相关’的解释与标记为‘概念准确’的解释之间的区别，即这两个指标不一定相互暗示。
- en: 1The  error  message  ”syntax  error  near  elsif”  is  indicating  that  there’s  a  syntax  issue  near  the  ”elsif”  keyword  in  your  code.23In  this  case,  the  error  is  triggered  by  the  misuse  of  the  ”rising_edge”  function  in  VHDL.  The  function  expects  a  signal  as  its  argument  and  checks  whether  there’s  a  rising  edge  (low  to  high  transition)  on  that  signal.  It’s  typically  used  with  a  clock  signal  inside  a  process.45However,  the  issue  here  is  that  the  ”elsif”  keyword  is  being  used  in  conjunction  with  the  ”rising_edge”  function.  In  VHDL,  you  don’t  typically  use  ”elsif”  with  ”rising_edge”.  Instead,  the  usual  construct  would  be  ”if  rising_edge(clk)”  directly  following  the  process  declaration.67It’s  likely  that  the  ”elsif”  is  intended  to  make  the  data_out  assignment  happen  based  on  a  rising  edge  event  on  the  clock,  but  after  a  reset.  The  correct  usage  would  be  to  nest  ”if  rising_edge(clk)”  inside  the  ”if  rst  =  ’1’”  condition,  as  the  first  to  be  processed.89Please  remember  that  you  should  place  the  reset  and  clock  conditions  under  separate  if  conditions  to  avoid  ambiguities  in  the  descriptions.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 错误消息“syntax error near elsif”表示在代码中的“elsif”关键字附近存在语法问题。在这种情况下，错误是由于错误使用了 VHDL
    中的“rising_edge”函数。该函数期望一个信号作为其参数，并检查该信号上是否有上升沿（低到高的过渡）。它通常与进程中的时钟信号一起使用。然而，问题在于“elsif”关键字与“rising_edge”函数一起使用。在
    VHDL 中，通常不将“elsif”与“rising_edge”一起使用。相反，通常的构造是在进程声明后直接使用“if rising_edge(clk)”。很可能“elsif”旨在基于时钟上的上升沿事件来执行
    data_out 赋值，但在复位之后。正确的用法是将“if rising_edge(clk)”嵌套在“if rst = '1'”条件中，作为第一个处理的部分。请记住，您应该将复位和时钟条件放在不同的
    if 条件下，以避免描述中的歧义。
- en: (a) ‘Bad’ explanation by gpt-4 which is relevant but with inaccurate concepts,
    linking to issues with clock edges instead of the actual syntax fault
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: (a) gpt-4 的‘错误’解释相关但概念不准确，链接到时钟边缘问题而非实际的语法错误
- en: 'Scores—Concept accurate: No; Any inaccuracies: Yes; Relevant: Yes; Correct
    & complete: No, Solution is provided: No'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 评分—概念准确：否；有无不准确之处：是；相关性：是；正确且完整：否，是否提供了解决方案：否
- en: 1The  bug  in  the  code  is  that  the  ‘elsif‘  statement  is  missing  a  semicolon  at  the  end  of  the  assignment  in  the  process.  This  is  causing  a  syntax  error  because  the  VHDL  syntax  expects  a  semicolon  after  each  statement  within  the  ‘if-elsif‘  structure.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 代码中的错误是‘elsif’语句在进程中的赋值结束时缺少一个分号。这会导致语法错误，因为 VHDL 语法在‘if-elsif’结构中的每个语句后都期望有一个分号。
- en: (b) ‘Bad’ explanation by gpt-3.5-turbo which has the right concepts but with
    irrelevant info. (the elsif has a semicolon on its later clause).
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: (b) gpt-3.5-turbo 的‘错误’解释虽然概念正确，但信息不相关。（else语句在其后续子句中有一个分号）。
- en: 'Scores—Concept accurate: Yes; Any inaccuracies: Yes; Relevant: No; Correct
    & complete: No, Solution is provided: No'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 评分—概念准确：是；有无不准确之处：是；相关性：否；正确且完整：否，是否提供了解决方案：否
- en: 'Figure 6: Demonstrating the difference between ‘relevance’ and ‘concept accurate’
    with two ‘bad’ error explanations for Bug 1 (Figure [1](#S1.F1 "Figure 1 ‣ I Introduction
    ‣ Explaining EDA synthesis errors with LLMs"))'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：展示‘相关性’与‘概念准确’之间的差异，提供了两个对 Bug 1 的‘错误’解释（图 [1](#S1.F1 "图 1 ‣ 引言 ‣ 使用 LLM
    解释 EDA 综合错误")）
