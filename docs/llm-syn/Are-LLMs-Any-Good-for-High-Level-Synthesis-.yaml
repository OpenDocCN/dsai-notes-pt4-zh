- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 18:53:31'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:53:31
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Are LLMs Any Good for High-Level Synthesis?
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大型语言模型在高层次综合中的作用如何？
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2408.10428](https://ar5iv.labs.arxiv.org/html/2408.10428)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2408.10428](https://ar5iv.labs.arxiv.org/html/2408.10428)
- en: Yuchao Liao Electrical and Computer Engineering
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Yuchao Liao 电气与计算机工程
- en: University of ArizonaTucsonArizona, USA [yuchaoliao@arizona.edu](mailto:yuchaoliao@arizona.edu)
    ,  Tosiron Adegbija Electrical and Computer Engineering
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 亚利桑那大学图森，亚利桑那州，美国 [yuchaoliao@arizona.edu](mailto:yuchaoliao@arizona.edu) ，Tosiron
    Adegbija 电气与计算机工程
- en: University of ArizonaTucsonArizona, USA [tosiron@arizona.edu](mailto:tosiron@arizona.edu)
     and  Roman Lysecky Electrical and Computer Engineering
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 亚利桑那大学图森，亚利桑那州，美国 [tosiron@arizona.edu](mailto:tosiron@arizona.edu) 和 Roman
    Lysecky 电气与计算机工程
- en: University of ArizonaTucsonArizona, USA [rlysecky@arizona.edu](mailto:rlysecky@arizona.edu)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 亚利桑那大学图森，亚利桑那州，美国 [rlysecky@arizona.edu](mailto:rlysecky@arizona.edu)
- en: Abstract.
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: The increasing complexity and demand for faster, energy-efficient hardware designs
    necessitate innovative High-Level Synthesis (HLS) methodologies. This paper explores
    the potential of Large Language Models (LLMs) to streamline or replace the HLS
    process, leveraging their ability to understand natural language specifications
    and refactor code. We survey the current research and conduct experiments comparing
    Verilog designs generated by a standard HLS tool (Vitis HLS) with those produced
    by LLMs translating C code or natural language specifications. Our evaluation
    focuses on quantifying the impact on performance, power, and resource utilization,
    providing an assessment of the efficiency of LLM-based approaches. This study
    aims to illuminate the role of LLMs in HLS, identifying promising directions for
    optimized hardware design in applications such as AI acceleration, embedded systems,
    and high-performance computing.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 随着对更快、更节能硬件设计的需求和复杂性的增加，需要创新的高层次综合（HLS）方法。本论文探讨了大型语言模型（LLMs）在简化或替代HLS过程中的潜力，利用其理解自然语言规范和重构代码的能力。我们调查了当前的研究，并进行了实验，将由标准HLS工具（Vitis
    HLS）生成的Verilog设计与由LLMs翻译C代码或自然语言规范生成的设计进行比较。我们的评估重点在于量化对性能、功耗和资源利用的影响，为LLM基础方法的效率提供评估。本研究旨在阐明LLMs在HLS中的作用，确定在AI加速、嵌入式系统和高性能计算等应用中优化硬件设计的有前景方向。
- en: 'High-level synthesis, hardware accelerator design, electronic design automation,
    large language models^†^†ccs: Hardware High-level and register-transfer level
    synthesis^†^†ccs: Computing methodologies Machine learning'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '高层次综合，硬件加速器设计，电子设计自动化，大型语言模型^†^†ccs: 硬件 高层次和寄存器传输级综合^†^†ccs: 计算方法 机器学习'
- en: 1\. Introduction
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 介绍
- en: The increasing demand for custom hardware accelerators, driven by applications
    ranging from artificial intelligence to high-performance computing, necessitates
    innovative design methodologies to meet the challenges of rapidly evolving technology.
    High-Level Synthesis (HLS) has emerged as a valuable approach for designing, synthesizing,
    and optimizing hardware systems. HLS (Coussy et al., [2009](#bib.bib9)) enables
    designers to define systems at a high abstraction level, independent of low-level
    circuit specifics, and utilize HLS tools to produce an optimized low-level hardware
    description of the target system. With current HLS tools (e.g., Vitis HLS, SmartHLS),
    designers can create application-specific embedded systems using high-level languages
    like C/C++ and translate them into register-transfer level (RTL) implementations
    using hardware description languages (e.g., Verilog. VHDL), thereby enhancing
    design productivity and reducing both design time and cost. Despite the advantages
    of HLS, the tools can still be time-consuming to use and demand considerable expertise,
    thus creating the potential for substantial improvement, especially with the integration
    of technologies like large language models (LLMs).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 定制硬件加速器的需求不断增加，涉及从人工智能到高性能计算的应用，这要求创新的设计方法来应对快速发展的技术挑战。高层综合（HLS）已成为设计、综合和优化硬件系统的宝贵方法。HLS（Coussy等，[2009](#bib.bib9)）使设计师能够在高抽象层次上定义系统，独立于低层电路细节，并利用HLS工具生成目标系统的优化低层硬件描述。借助当前的HLS工具（如Vitis
    HLS、SmartHLS），设计师可以使用高层语言如C/C++创建特定应用的嵌入式系统，并将其转化为寄存器传输级（RTL）实现，使用硬件描述语言（如Verilog、VHDL），从而提高设计生产力，减少设计时间和成本。尽管HLS有其优势，但这些工具仍然可能耗时且需要相当的专业知识，因此有可能通过集成大型语言模型（LLMs）等技术实现显著改进。
- en: Recent advancements in LLMs (Zhao et al., [2023](#bib.bib31)) have showcased
    their ability to automate various computational tasks, including code generation
    and software engineering. This presents a unique opportunity to explore the potential
    of LLMs in streamlining the HLS process, from high-level language specifications
    to efficient hardware implementations (Chang et al., [2023](#bib.bib7)). The ability
    of LLMs to understand and generate code, combined with the potential for natural
    language interaction, can revolutionize the way we design hardware, making the
    process more accessible and less time-consuming. This integration can lead to
    significant improvements in design productivity and efficiency, ultimately transforming
    the landscape of hardware development.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的LLMs（赵等，[2023](#bib.bib31)）进展展示了它们在自动化各种计算任务方面的能力，包括代码生成和软件工程。这为探索LLMs在简化HLS过程中的潜力提供了独特的机会，从高层语言规格到高效的硬件实现（Chang等，[2023](#bib.bib7)）。LLMs理解和生成代码的能力，加上自然语言交互的潜力，可以彻底改变我们设计硬件的方式，使过程更加可及且耗时更少。这种整合可能会显著提升设计生产力和效率，*最终*改变硬件开发的格局。
- en: In this paper, we explore the burgeoning field of LLMs for HLS, which has sparked
    growing interest. We first present a taxonomy of LLM use cases for HLS, highlighting
    the various ways these models can be integrated into the design flow. Building
    on this foundation, we survey the state-of-the-art, highlighting the most promising
    research and techniques. To assess the viability of LLMs in the HLS design flow,
    we perform an experimental evaluation, comparing the Verilog designs generated
    using a standard HLS tool, specifically Vitis HLS, to those produced with LLM-based
    approaches. These approaches include direct LLM translation of C benchmarks from
    the PolyBench Suite (Pouchet and Yuki, [2012](#bib.bib21)) to Verilog using ChatGPT-4o,
    and the use of LLMs to interpret natural language specifications into both benchmarks
    and Verilog. Our evaluation focuses on the quality (performance, power, resource
    utilization) of designs produced by each methodology.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本文探讨了LLMs在HLS中的新兴领域，这引起了越来越多的兴趣。我们首先提出了LLMs在HLS中的用例分类，突出这些模型在设计流程中整合的各种方式。在此基础上，我们回顾了最新的研究成果，突出了最有前景的研究和技术。为了评估LLMs在HLS设计流程中的可行性，我们进行了实验评估，将使用标准HLS工具（特别是Vitis
    HLS）生成的Verilog设计与使用LLMs方法生成的设计进行比较。这些方法包括直接使用ChatGPT-4o将PolyBench Suite中的C基准转换为Verilog，以及使用LLMs将自然语言规格解释为基准和Verilog。我们的评估重点在于每种方法所产生设计的质量（性能、功耗、资源利用）。
- en: 'This study seeks to answer several key questions: Can existing LLMs generate
    Verilog code comparable in quality to that produced by traditional HLS tools?
    What are the advantages and limitations of using LLMs in this context? Could the
    natural language understanding capabilities of LLMs open up new avenues for hardware
    design? By addressing these questions, we aim to provide valuable insights into
    the role of LLMs in HLS and their potential to transform the future of hardware
    design.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究旨在回答几个关键问题：现有的LLM能否生成与传统HLS工具生产的Verilog代码相当的质量？在这种情况下使用LLM的优势和限制是什么？LLM的自然语言理解能力是否能为硬件设计开辟新的途径？通过解决这些问题，我们旨在提供关于LLM在HLS中的角色以及它们在未来硬件设计中变革潜力的宝贵见解。
- en: '![Refer to caption](img/3e59caf93f22737ecc9b9e66bdd56e6d.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/3e59caf93f22737ecc9b9e66bdd56e6d.png)'
- en: Figure 1. Taxonomy of LLM applications in HLS
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1. LLM在HLS中的应用分类
- en: 2\. Taxonomy of LLM for HLS
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. LLM在高层次综合中的分类
- en: 'The application of LLMs to different stages of the HLS process has emerged
    as a promising research direction. To provide a structured overview of this evolving
    landscape, we present a taxonomy (illustrated in Figure [1](#S1.F1 "Figure 1 ‣
    1\. Introduction ‣ Are LLMs Any Good for High-Level Synthesis?")) that categorizes
    LLMs based on their primary role in HLS: specification generators, design space
    exploration assistants, code generators, and hardware verification tools. This
    classification provides a framework for understanding how LLMs can augment HLS
    methodologies, as detailed in the following subsections.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 将LLM应用于HLS过程的不同阶段已经成为一个有前景的研究方向。为了提供对这一不断发展的领域的结构化概述，我们呈现了一个分类体系（见图 [1](#S1.F1
    "图 1 ‣ 1\. 引言 ‣ LLM在高层次综合中的效果如何？")），将LLM根据其在HLS中的主要角色进行分类：规格生成器、设计空间探索助手、代码生成器和硬件验证工具。这个分类为理解LLM如何增强HLS方法提供了一个框架，详细信息见以下小节。
- en: 2.1\. LLM as Specification Generator
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1\. LLM作为规格生成器
- en: LLMs hold promise as specification generators in HLS, translating natural language
    or higher-level code into HLS-compatible formats (e.g., HLS-C) (Swaroopa et al.,
    [2024](#bib.bib24); Collini et al., [2024](#bib.bib8); Xu et al., [2024](#bib.bib30)).
    This allows for intuitive and accessible expression of hardware functionality.
    Challenges persist in mitigating ambiguities inherent in natural language, which
    can lead to misinterpretations. Techniques like prompting, clarification dialogues,
    and formal verification are crucial for ensuring the correctness of LLM-generated
    specifications (Lu et al., [2024](#bib.bib16)).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: LLM作为规格生成器在HLS中具有前景，将自然语言或更高层次的代码转换为HLS兼容的格式（例如HLS-C）（Swaroopa et al., [2024](#bib.bib24);
    Collini et al., [2024](#bib.bib8); Xu et al., [2024](#bib.bib30)）。这允许以直观和可访问的方式表达硬件功能。挑战在于减轻自然语言固有的歧义，这可能导致误解。诸如提示、澄清对话和形式验证等技术对于确保LLM生成规格的正确性至关重要（Lu
    et al., [2024](#bib.bib16)）。
- en: 2.2\. LLM as Code Generator
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2\. LLM作为代码生成器
- en: LLMs can help with code generation, directly generating synthesizable HDL from
    high-level specifications (Blocklove et al., [2023](#bib.bib5); Thakur et al.,
    [2024](#bib.bib27); Chang et al., [2023](#bib.bib7)). This automation can boost
    productivity and reduce errors. The challenge lies in ensuring generated code
    quality and providing designers control over code structure and style (Lu et al.,
    [2024](#bib.bib16)). Recent research demonstrates LLM capabilities in generating
    functional HDL for various hardware components, including arithmetic units (Liu
    et al., [2023](#bib.bib15)), controllers, and simple processors (Blocklove et al.,
    [2023](#bib.bib5)), suggesting a promising future for this approach.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: LLM可以帮助生成代码，直接从高层次规格中生成可综合的HDL代码（Blocklove et al., [2023](#bib.bib5); Thakur
    et al., [2024](#bib.bib27); Chang et al., [2023](#bib.bib7)）。这种自动化可以提高生产力并减少错误。挑战在于确保生成的代码质量，并提供设计师对代码结构和风格的控制（Lu
    et al., [2024](#bib.bib16)）。近期研究展示了LLM在生成各种硬件组件的功能性HDL方面的能力，包括算术单元（Liu et al.,
    [2023](#bib.bib15)）、控制器和简单处理器（Blocklove et al., [2023](#bib.bib5)），这表明这种方法具有光明的未来。
- en: 2.3\. LLM as Hardware Verification Assistant
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3\. LLM作为硬件验证助手
- en: LLMs can assist with hardware verification in HLS, by automating the generation
    of test cases and identifying potential design flaws (Ahmad et al., [2024](#bib.bib2);
    Kande et al., [2023](#bib.bib13)). This can lead to significant time savings and
    improved design reliability. However, challenges persist in ensuring the accuracy
    of LLM-generated test cases and their integration into existing HLS workflows.
    Ongoing research (Orenes-Vera et al., [2023](#bib.bib20)) explores the potential
    of LLMs in areas like formal verification, further highlighting their potential
    in ensuring the correctness of complex designs.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 可以通过自动生成测试用例和识别潜在设计缺陷来辅助 HLS 中的硬件验证（Ahmad 等，[2024](#bib.bib2)；Kande 等，[2023](#bib.bib13)）。这可以显著节省时间并提高设计可靠性。然而，确保
    LLM 生成的测试用例的准确性及其与现有 HLS 工作流程的集成仍然面临挑战。正在进行的研究（Orenes-Vera 等，[2023](#bib.bib20)）探索了
    LLM 在形式验证等领域的潜力，进一步强调了它们在确保复杂设计正确性方面的潜力。
- en: 2.4\. LLM as Design Space Exploration Assistant
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4\. LLM 作为设计空间探索助手
- en: Although receiving less attention than other applications, LLMs are promising
    in aiding HLS design space exploration (DSE) by suggesting optimizations and exploring
    design alternatives (Liao et al., [2023](#bib.bib14)). Their ability to analyze
    design constraints and objectives can lead to faster design cycles and innovative
    solutions. However, effective LLM DSE assistance requires incorporating domain-specific
    knowledge and addressing potential biases in suggestions. Recent research shows
    LLMs can optimize hardware accelerators, explore neural network architectures,
    and propose circuit-level optimizations, emphasizing their transformative potential
    for DSE (Thakur et al., [2023](#bib.bib26)).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管与其他应用相比，LLM 受到了较少的关注，但它们在通过建议优化和探索设计替代方案来辅助 HLS 设计空间探索（DSE）方面具有很大潜力（Liao 等，[2023](#bib.bib14)）。它们分析设计约束和目标的能力可以带来更快的设计周期和创新的解决方案。然而，有效的
    LLM DSE 辅助需要整合领域特定的知识，并解决建议中的潜在偏见。近期研究表明，LLM 可以优化硬件加速器、探索神经网络架构，并提出电路级优化，强调了它们在
    DSE 中的变革潜力（Thakur 等，[2023](#bib.bib26)）。
- en: 3\. Survey of the State-of-the-Art in LLMs for HLS
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. LLM 在 HLS 中的最先进技术概述
- en: This section surveys the diverse applications of LLMs in HLS, spanning hardware
    design automation, software-hardware co-design, and design of embedded systems.
    We examine key research areas such as natural language processing (NLP) to HDL
    translation, code generation, optimization and verification, and multimodal approaches.
    We also discuss input modalities used in the state-of-the-art, like textual descriptions
    and pseudocode, and the output modalities such as HDLs (VHDL, Verilog, SystemVerilog)
    and HLS-compatible programs (e.g., HLS-C). Finally, we highlight current approaches
    to benchmarking and evaluating LLM-driven HLS, emphasizing the need for standardized
    metrics and datasets to facilitate fair comparisons and drive further advancements
    in this rapidly evolving field.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 本节调查了 LLM 在 HLS 中的多种应用，包括硬件设计自动化、软件硬件协同设计以及嵌入式系统设计。我们审视了关键研究领域，如自然语言处理（NLP）到
    HDL 的翻译、代码生成、优化与验证，以及多模态方法。我们还讨论了当前最先进技术中使用的输入模态，如文本描述和伪代码，以及输出模态，如 HDLs（VHDL、Verilog、SystemVerilog）和与
    HLS 兼容的程序（例如，HLS-C）。最后，我们强调了当前对 LLM 驱动的 HLS 的基准测试和评估方法，强调了需要标准化的度量指标和数据集，以促进公平比较并推动这一快速发展的领域的进一步进步。
- en: 3.1\. LLMs Used for HLS
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1\. 用于 HLS 的 LLM
- en: Recent advancements in LLMs such as ChatGPT, Gemini, Claude, and LLAMA have
    great potential for use in HLS. While many current works leverage the popular
    ChatGPT for their HLS experimentation, both general-purpose and custom-tuned LLMs
    have been utilized to automate and optimize synthesis processes (Fu et al., [2024](#bib.bib11)).
    As expected, fine-tuning models on domain-specific data often yields superior
    performance in generating desired outputs within the HLS workflow. For instance,
    Nadim et al. (Nadimi and Zheng, [2024](#bib.bib18)) introduced a multi-expert
    LLM architecture to address the challenges of design complexity. By using specialized
    models and a complexity classifier, they achieved an improvement of up to 23.9%
    in the pass@k metric. However, a consistent theme emerging from both existing
    literature and our experiments is the necessity of human-in-the-loop (HITL) approaches
    for successful LLM integration in HLS. For example, Collini et al. (Collini et al.,
    [2024](#bib.bib8)) highlighted the significant human expert guidance required
    for converting a C-based QuickSort kernel to HLS-C. Similarly, Swaroopa et al.
    (Swaroopa et al., [2024](#bib.bib24)) demonstrated a semi-automated approach for
    generating HLS-C from natural language using LLMs, acknowledging the need for
    human intervention in the design process, though their work did not evaluate the
    quality of the resulting designs. Such a HITL approach leverages the computational
    strengths of LLMs while retaining the nuanced understanding and decision-making
    capabilities of human experts, to achieve superior HLS outcomes.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，ChatGPT、Gemini、Claude 和 LLAMA 等 LLM 的进展在 HLS 中展现出了巨大的潜力。虽然许多当前的研究利用了流行的 ChatGPT
    进行 HLS 实验，但通用和定制调优的 LLM 都已被用于自动化和优化综合过程（Fu et al., [2024](#bib.bib11)）。正如预期的那样，对领域特定数据进行微调的模型通常能在
    HLS 工作流程中生成期望输出时表现出更好的性能。例如，Nadim et al.（Nadimi 和 Zheng, [2024](#bib.bib18)）提出了一种多专家
    LLM 架构，以应对设计复杂性的问题。通过使用专门的模型和复杂性分类器，他们在 pass@k 指标上取得了高达 23.9% 的改进。然而，从现有文献和我们的实验中出现的一个一致主题是，为了成功地将
    LLM 融入 HLS 中，必须采用人机协作（HITL）方法。例如，Collini et al.（Collini et al., [2024](#bib.bib8)）强调了将基于
    C 的 QuickSort 内核转换为 HLS-C 所需的重要人工专家指导。类似地，Swaroopa et al.（Swaroopa et al., [2024](#bib.bib24)）展示了一种从自然语言生成
    HLS-C 的半自动化方法，承认在设计过程中需要人工干预，尽管他们的工作并未评估生成设计的质量。这种 HITL 方法充分利用了 LLM 的计算优势，同时保留了人工专家的细致理解和决策能力，以实现更优的
    HLS 结果。
- en: 3.2\. Applications
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2\. 应用
- en: The increasing interest in applying LLMs to HLS has led to promising developments
    across various domains. For example, LLMs have shown success in automating the
    generation of analog/mixed-signal (AMS) circuit netlists from transistor-level
    schematics (Tao et al., [2024](#bib.bib25)). In the domain of RTL generation,
    LLMs have demonstrated their capability to generate RTL code from natural language
    descriptions (Lu et al., [2024](#bib.bib16)) and, as explored in (Blocklove et al.,
    [2023](#bib.bib5)), have the potential to aid in writing and debugging HDL code
    through conversational interactions with existing LLM tools like ChatGPT. Additionally,
    LLMs are being integrated into tools like MATLAB and Simulink to translate high-level
    design specifications into synthesizable Verilog and VHDL code, streamlining the
    HDL generation process. In the domain of code security, Nair et al. (Nair et al.,
    [2023](#bib.bib19)) investigated the vulnerabilities in hardware code generated
    by ChatGPT, specifically analyzing common weaknesses enumerations (CWE) and proposing
    strategies to guide secure hardware code generation.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 对将大型语言模型（LLMs）应用于高层次综合（HLS）的兴趣日益增长，已经在各个领域取得了令人鼓舞的发展。例如，LLMs 在从晶体管级原理图自动生成模拟/混合信号（AMS）电路网表方面显示出了成功（Tao
    et al., [2024](#bib.bib25)）。在 RTL 生成领域，LLMs 已经展示了从自然语言描述生成 RTL 代码的能力（Lu et al.,
    [2024](#bib.bib16)），而在（Blocklove et al., [2023](#bib.bib5)）中探讨了它们通过与现有 LLM 工具如
    ChatGPT 的对话互动，帮助编写和调试 HDL 代码的潜力。此外，LLMs 正在被集成到如 MATLAB 和 Simulink 等工具中，以将高层次设计规范转换为可综合的
    Verilog 和 VHDL 代码，从而简化 HDL 生成过程。在代码安全领域，Nair et al.（Nair et al., [2023](#bib.bib19)）研究了由
    ChatGPT 生成的硬件代码中的漏洞，特别是分析了常见弱点枚举（CWE），并提出了指导安全硬件代码生成的策略。
- en: Beyond these applications, LLMs are being explored for broader roles in the
    HLS workflow. Recent work has explored the potential of LLMs to refactor existing
    C code into HLS-compatible formats, bridging the gap between software and hardware
    design (Collini et al., [2024](#bib.bib8); Fu et al., [2023](#bib.bib12); Swaroopa
    et al., [2024](#bib.bib24); Xu et al., [2024](#bib.bib30)). Models like ChatGPT
    have been leveraged to convert high-level design specifications into synthesizable
    HDL, targeting specific hardware components such as random number generators (Meech,
    [2023](#bib.bib17)). They have been used for automated code repair and optimization
    to improve the quality of HLS-C programs (Xu et al., [2024](#bib.bib30)). Furthermore,
    LLMs have shown promise in generating HLS pragmas (Fu et al., [2023](#bib.bib12);
    Xu et al., [2024](#bib.bib30)), which are compiler directives that can significantly
    impact the quality of the generated hardware. Moreover, the use of LLMs for automated
    testbench generation (Qiu et al., [2024](#bib.bib22); Bhandari et al., [2024](#bib.bib4))
    and hardware design verification tasks (Ahmad et al., [2024](#bib.bib2); Kande
    et al., [2023](#bib.bib13)) further expands their potential applications in HLS.
    The growing breadth of LLM applications in HLS underscores their potential to
    enhance automation, efficiency, and accessibility throughout the hardware design
    process.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些应用，LLM在HLS工作流程中的更广泛角色也在被探索。近期的研究探讨了LLM将现有的C代码重构为HLS兼容格式的潜力，弥合了软件和硬件设计之间的差距（Collini等，[2024](#bib.bib8)；Fu等，[2023](#bib.bib12)；Swaroopa等，[2024](#bib.bib24)；Xu等，[2024](#bib.bib30)）。像ChatGPT这样的模型已被用来将高级设计规格转换为可综合的HDL，目标是特定的硬件组件，如随机数生成器（Meech，[2023](#bib.bib17)）。它们还用于自动代码修复和优化，以提高HLS-C程序的质量（Xu等，[2024](#bib.bib30)）。此外，LLM在生成HLS
    pragmas方面表现出前景（Fu等，[2023](#bib.bib12)；Xu等，[2024](#bib.bib30)），这些编译器指令可以显著影响生成硬件的质量。而且，LLM在自动化测试平台生成（Qiu等，[2024](#bib.bib22)；Bhandari等，[2024](#bib.bib4)）和硬件设计验证任务（Ahmad等，[2024](#bib.bib2)；Kande等，[2023](#bib.bib13)）中的应用进一步扩展了它们在HLS中的潜力。LLM在HLS中应用的日益广泛突显了它们在整个硬件设计过程中增强自动化、效率和可及性的潜力。
- en: '![Refer to caption](img/8f42ed431a2861747bcc53a51b96b4fd.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/8f42ed431a2861747bcc53a51b96b4fd.png)'
- en: (a) HLS-based approach
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 基于HLS的方法
- en: '![Refer to caption](img/4d4e359b1f0c2ebdebd3933b30862d06.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/4d4e359b1f0c2ebdebd3933b30862d06.png)'
- en: (b) LLM-based approaches
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 基于LLM的方法
- en: Figure 2. HLS-based (a) and LLM-based (b) approaches to generating hardware
    accelerators
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2. 基于HLS的（a）和基于LLM的（b）硬件加速器生成方法
- en: 3.3\. Input and Output Modalities
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3. 输入和输出模式
- en: The versatility of LLMs in HLS stems, in part, from their ability to process
    and generate information across diverse modalities. Textual descriptions, including
    high-level design specifications, natural language explanations of functionality,
    and code snippets in languages like C/C++ often serve as primary input modalities.
    LLMs can transform these textual inputs into HDL such as Verilog or VHDL, as seen
    in applications that convert natural language descriptions directly to HDL (Meech,
    [2023](#bib.bib17); Blocklove et al., [2023](#bib.bib5); Lu et al., [2024](#bib.bib16)).
    Beyond text, advanced LLMs are increasingly capable of handling multimodal inputs,
    which incorporate images, schematics, or other data types (Chang et al., [2024](#bib.bib6)).
    This can allow for a more nuanced understanding of design requirements by integrating
    visual and textual information.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: LLM在HLS中的多功能性部分来源于它们处理和生成各种模式信息的能力。文本描述，包括高级设计规格、功能的自然语言解释以及像C/C++这样的语言中的代码片段，通常作为主要的输入模式。LLM可以将这些文本输入转换为HDL，例如Verilog或VHDL，这在将自然语言描述直接转换为HDL的应用中有所体现（Meech，[2023](#bib.bib17)；Blocklove等，[2023](#bib.bib5)；Lu等，[2024](#bib.bib16)）。除了文本，先进的LLM越来越能够处理多模态输入，这些输入包括图像、原理图或其他数据类型（Chang等，[2024](#bib.bib6)）。这可以通过整合视觉和文本信息来对设计需求进行更细致的理解。
- en: The output modalities of LLMs for HLS are equally diverse. Primarily, LLMs can
    generate synthesizable HDL code from textual or multimodal inputs (Lu et al.,
    [2024](#bib.bib16)). Additionally, LLMs can optimize existing code by automatically
    inserting and tuning pragmas to enhance the synthesis process. Moreover, LLMs
    can generate testbenches and verification scripts, which are vital to validate
    the functionality and performance of the synthesized hardware.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs在HLS中的输出模式同样多样化。主要是，LLMs可以从文本或多模态输入生成可综合的HDL代码（Lu et al., [2024](#bib.bib16)）。此外，LLMs还可以通过自动插入和调整pragma来优化现有代码，以增强综合过程。而且，LLMs可以生成测试平台和验证脚本，这对验证合成硬件的功能和性能至关重要。
- en: 3.4\. Benchmarking and Evaluation
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4. 基准测试和评估
- en: The evaluation and advancement of LLMs in HLS rely on robust benchmarks and
    datasets. Several key initiatives have emerged to address this need, including
    the RTLLM benchmark (Lu et al., [2024](#bib.bib16)), which provides a framework
    for evaluating LLM performance in generating RTL from natural language instructions,
    encompassing syntax, functionality, and code quality. The RTL-Repo benchmark (Allam
    and Shalan, [2024](#bib.bib3)) expands this evaluation by assessing LLM capabilities
    in generating Verilog code autocompletions within large-scale and complex RTL
    projects, reflecting real-world design scenarios. VerilogEval (Liu et al., [2023](#bib.bib15))
    is a framework for evaluating the effectiveness of LLMs in generating Verilog
    code, including tasks like module implementation, code debugging, and testbench
    construction, to assess their potential in hardware design automation. Similarly,
    VHDL-Eval (Vijayaraghavan et al., [2024](#bib.bib28)) is a specialized framework
    designed to evaluate LLM performance specifically in VHDL code generation. Wan
    et al. (Wan et al., [2024](#bib.bib29)) explored using LLMs to insert bugs into
    HLS code, and created a dataset including both correct and injected buggy codes.
    These benchmarks and datasets, along with other emerging efforts, are crucial
    in LLM-driven HLS research, facilitating the evaluation of LLM capabilities and
    guiding the development of more robust HLS solutions.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs在HLS中的评估和进步依赖于强有力的基准测试和数据集。为满足这一需求，已出现几个关键举措，包括RTLLM基准测试（Lu et al., [2024](#bib.bib16)），该基准测试提供了一个框架，用于评估LLM从自然语言指令生成RTL的性能，涵盖语法、功能和代码质量。RTL-Repo基准测试（Allam
    and Shalan, [2024](#bib.bib3)）通过评估LLM在大型复杂RTL项目中生成Verilog代码自动补全的能力，扩展了这种评估，反映了真实世界的设计场景。VerilogEval（Liu
    et al., [2023](#bib.bib15)）是一个评估LLM生成Verilog代码有效性的框架，包括模块实现、代码调试和测试平台构建等任务，以评估其在硬件设计自动化中的潜力。类似地，VHDL-Eval（Vijayaraghavan
    et al., [2024](#bib.bib28)）是一个专门的框架，旨在专门评估LLM在VHDL代码生成中的表现。Wan et al.（Wan et al.,
    [2024](#bib.bib29)）探讨了使用LLM向HLS代码中插入错误，并创建了一个包含正确代码和注入错误代码的数据集。这些基准测试和数据集，以及其他新兴的努力，对LLM驱动的HLS研究至关重要，有助于评估LLM的能力，并指导更强大的HLS解决方案的发展。
- en: 4\. Experimental Methodology
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4. 实验方法
- en: 'This section details our experimental methodology for evaluating the effectiveness
    of integrating LLMs into the HLS process. We aim to assess both the design process
    and the quality of the hardware generated using LLMs in comparison to solely using
    traditional HLS tools. We investigate four approaches:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 本节详细介绍了评估将LLM集成到HLS过程中的有效性的实验方法。我们旨在评估设计过程和使用LLM生成的硬件的质量，并与仅使用传统HLS工具的情况进行比较。我们调查了四种方法：
- en: (1)
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: 'Baseline: Generating Verilog using a standard HLS tool (Vitis HLS) from C code.'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基准：使用标准HLS工具（Vitis HLS）从C代码生成Verilog。
- en: (2)
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: 'Direct LLM translation: Employing LLMs to translate C code into Verilog.'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 直接LLM翻译：利用LLM将C代码翻译成Verilog。
- en: (3)
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3)
- en: 'Natural language to Verilog: Directly generating Verilog code from natural
    language specifications using LLMs.'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自然语言到Verilog：直接从自然语言规范生成Verilog代码，使用LLM。
- en: (4)
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (4)
- en: 'Natural language to code: Using LLMs to interpret natural language specifications
    into HLS-C benchmarks, which are then translated into Verilog using Vitis HLS.'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自然语言到代码：使用LLM将自然语言规范解释为HLS-C基准测试，然后通过Vitis HLS将其转换为Verilog。
- en: 4.1\. HLS Approach
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1. HLS方法
- en: The general HLS design flow, as illustrated in Figure [2(a)](#S3.F2.sf1 "In
    Figure 2 ‣ 3.2\. Applications ‣ 3\. Survey of the State-of-the-Art in LLMs for
    HLS ‣ Are LLMs Any Good for High-Level Synthesis?"), transforms a high-level language
    input to a synthesizable hardware description (e.g., in Verilog or VHDL). This
    process starts with describing the desired hardware functionality in a high-level
    language like C/C++/SystemC), followed by synthesis for a specific hardware target,
    e.g., FPGAs like the Artix-7 or Zynq UltraScale+. We refer to this process as
    C$\rightarrow$Verilog.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 通用HLS设计流程，如图[2(a)](#S3.F2.sf1 "图2 ‣ 3.2\. 应用 ‣ 3\. 高级综合领域的最新进展调查 ‣ LLMs在高级综合中的效果如何？")所示，将高级语言输入转换为可合成的硬件描述（例如，Verilog或VHDL）。该过程从用C/C++/SystemC等高级语言描述所需的硬件功能开始，然后针对特定硬件目标（例如，Artix-7或Zynq
    UltraScale+等FPGA）进行综合。我们将这一过程称为C$\rightarrow$Verilog。
- en: HLS tools offer a range of directives to guide the synthesis process, allowing
    designers to control various aspects of the design, such as loop unrolling, pipelining,
    array partitioning, and performance optimization. While these directives provide
    flexibility, the resulting HDL code generated by HLS tools can often be complex
    and challenging to interpret for designers who are primarily accustomed to higher-level
    programming languages. This limited visibility into the generated HDL code is
    a key consideration that motivates the exploration of LLMs in HLS, aiming to improve
    the design process by providing higher-level abstractions or enhancing code understandability.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: HLS工具提供了一系列指令来指导综合过程，使设计师能够控制设计的各个方面，如循环展开、流水线、数组分割和性能优化。虽然这些指令提供了灵活性，但HLS工具生成的HDL代码通常复杂且难以理解，对于主要使用高级编程语言的设计师而言尤为如此。对生成的HDL代码有限的可见性是促使在HLS中探索LLMs的一个关键因素，旨在通过提供更高级的抽象或增强代码可理解性来改进设计过程。
- en: 'Background:  I  am  a  hardware  engineer,  and  I  want  to  transfer  a  C  program  to  synthesizable  Hardware  Description  Language  (RTL)  in  Verilog  with  a  full  module,  including  I/O  and  functionalities  from  the  C  program.  This  Verilog  module  should  target  a  Xilinx  FPGA  board.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 背景：我是一名硬件工程师，我希望将一个C程序转换为可合成的硬件描述语言（RTL），使用Verilog实现一个完整的模块，包括C程序中的I/O和功能。这个Verilog模块应该针对Xilinx
    FPGA开发板。
- en: (a) Prompt
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: (a) Prompt
- en: Sure,  I  can  help  with  that.  Please  provide  the  C  program  you  want  to  translate  to  Verilog.  Additionally,  let  me  know  if  there  are  any  specific  functionalities  or  constraints  you  need  to  consider  for  the  translation,  such  as  the  I/O  pin  count  or  specific  features  of  the  Xilinx  FPGA  board  you  are  targeting.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我可以帮助你。请提供你想要转换为Verilog的C程序。另外，请告诉我是否有任何特定的功能或限制需要考虑，例如I/O引脚数量或你所针对的Xilinx
    FPGA开发板的特定功能。
- en: (b) Feedback
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: (b) Feedback
- en: Figure 3. Background, role, and constraints
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图3. 背景、角色和约束
- en: '#define  N  64void  syrk(float  alpha,  float  beta,float  A[N][N],  float  B[N][N],  float  C_out[N][N])  {int  i,  j,  k;float  buff_A0[N][N];float  buff_B1[N][N];float  buff_B[N][N];float  buff_C_out[N][N];'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '#define  N  64void  syrk(float  alpha,  float  beta,float  A[N][N],  float  B[N][N],  float  C_out[N][N])  {int  i,  j,  k;float  buff_A0[N][N];float  buff_B1[N][N];float  buff_B[N][N];float  buff_C_out[N][N];'
- en: (a) Prompt
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: (a) Prompt
- en: ‘timescale  1ns  /  1psmodule  syrk#(parameter  N  =  64)  (input  [31:0]  alpha,input  [31:0]  beta,integer  i,  j,  k;input  [31:0]  A[0:N-1][0:N-1],input  [31:0]  B[0:N-1][0:N-1],output  reg  [31:0]  C_out[0:N-1][0:N-1]);reg  [31:0]  buff_A0[0:N-1][0:N-1];reg  [31:0]  buff_A1[0:N-1][0:N-1];reg  [31:0]  buff_B[0:N-1][0:N-1];reg  [31:0]  buff_C_out[0:N-1][0:N-1];);
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ‘timescale  1ns  /  1psmodule  syrk#(parameter  N  =  64)  (input  [31:0]  alpha,input  [31:0]  beta,integer  i,  j,  k;input  [31:0]  A[0:N-1][0:N-1],input  [31:0]  B[0:N-1][0:N-1],output  reg  [31:0]  C_out[0:N-1][0:N-1]);reg  [31:0]  buff_A0[0:N-1][0:N-1];reg  [31:0]  buff_A1[0:N-1][0:N-1];reg  [31:0]  buff_B[0:N-1][0:N-1];reg  [31:0]  buff_C_out[0:N-1][0:N-1];);
- en: (b) Feedback
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: (b) Feedback
- en: The  inputs  A,  B,  and  C_out  are  not  correct.  We  need  an  external  RAM  to  handle  the  2D  array.  The  width  of  the  address  and  the  width  of  the  data  should  be  declared  as  module  parameters.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 输入A、B和C_out不正确。我们需要一个外部RAM来处理2D数组。地址的宽度和数据的宽度应声明为模块参数。
- en: (c) Prompt2
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: (c) Prompt2
- en: module  syrk#(parameter  N  =  64,DATA_WIDTH  =  32)(input  clk,input  rst,input  [DATA_WIDTH-1:0]  alpha,input  [DATA_WIDTH-1:0]  beta,input  [DATA_WIDTH-1:0]  A_data,input  [DATA_WIDTH-1:0]  B_data,output  reg  [DATA_WIDTH-1:0]  C_out_data,input  [$clog2(N*N)-1:0]  A_addr,  B_addr,C_out_addr,input  A_we,  B_we,  C_out_we);
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 模块  syrk#(参数  N  =  64,DATA_WIDTH  =  32)(输入  clk,输入  rst,输入  [DATA_WIDTH-1:0]  alpha,输入  [DATA_WIDTH-1:0]  beta,输入  [DATA_WIDTH-1:0]  A_data,输入  [DATA_WIDTH-1:0]  B_data,输出  reg  [DATA_WIDTH-1:0]  C_out_data,输入  [$clog2(N*N)-1:0]  A_addr,  B_addr,C_out_addr,输入  A_we,  B_we,  C_out_we);
- en: (d) Feedback2
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: (d) 反馈2
- en: Figure 4. Inputs and error checking (I/O)
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4. 输入和错误检查 (I/O)
- en: '…lp1:  for  (i  =  0;  i  <  N;  i++)  {lp2:  for  (j  =  0;  j  <  N;  j++)  {if  (j  >  i)  continue;lp3:  for  (k  =  0;  k  <  N;  k++)  {buff_C_out[i][j]  +=  alpha  *buff_A0[i][k]  *  buff_A1[j][k];}}}…'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '…lp1:  对于  (i  =  0;  i  <  N;  i++)  {lp2:  对于  (j  =  0;  j  <  N;  j++)  {如果  (j  >  i)  继续;lp3:  对于  (k  =  0;  k  <  N;  k++)  {buff_C_out[i][j]  +=  alpha  *buff_A0[i][k]  *  buff_A1[j][k];}}}…'
- en: (a) Prompt
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 提示
- en: …for  (i  =  0;  i  <  N;  i  =  i  +  1)  beginfor  (j  =  0;  j  <  N;  j  =  j  +  1)  beginif  (j  <=  i)  beginfor  (k  =  0;  k  <  N;  k  =  k  +  1)beginbuff_C_out[i][j]  <=  buff_C_out[i][j]+  alpha  *  buff_A0[i][k]*  buff_A1[j][k];endbuff_C_out[i][j]  <=  buff_C_out[i][j]+  beta  *  buff_B[i][j];end  else  beginC_out[i][j]  <=  0;endendend…
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: …对于  (i  =  0;  i  <  N;  i  =  i  +  1)  开始对于  (j  =  0;  j  <  N;  j  =  j  +  1)  开始如果  (j  <=  i)  开始对于  (k  =  0;  k  <  N;  k  =  k  +  1)开始buff_C_out[i][j]  <=  buff_C_out[i][j]+  alpha  *  buff_A0[i][k]*  buff_A1[j][k];结束buff_C_out[i][j]  <=  buff_C_out[i][j]+  beta  *  buff_B[i][j];结束  否则  开始C_out[i][j]  <=  0;结束结束结束…
- en: (b) Feedback
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 反馈
- en: This  looks  wrong,  A,  B,  C_out,  are  external  BRAM,  please  update  this  again.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来不对，A、B、C_out是外部BRAM，请再次更新。
- en: (c) Prompt2
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 提示2
- en: '…COMPUTE:  beginA_read  <=  0;B_read  <=  0;reg_A  <=  A_data_in;reg_B  <=  B_data_in;reg_C  <=  reg_C  +  alpha  *  reg_A  *  reg_B;k  <=  k  +  1;if  (k  ==  N)  begink  <=  0;state  <=  WRITE_C;endelse  beginstate  <=  LOAD_A;endend…'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '…计算:  开始A_read  <=  0;B_read  <=  0;reg_A  <=  A_data_in;reg_B  <=  B_data_in;reg_C  <=  reg_C  +  alpha  *  reg_A  *  reg_B;k  <=  k  +  1;如果  (k  ==  N)  开始k  <=  0;state  <=  WRITE_C;结束否则  开始state  <=  LOAD_A;结束结束…'
- en: (d) Feedback2
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: (d) 反馈2
- en: Figure 5. Inputs and error checking (loop)
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5. 输入和错误检查 (循环)
- en: Please  write  a  tcl  code  to  create  a  bram  IP  with  properties  like  this  :-vendor  xilinx.com-version  8.4-module_name  blk_mem_gen_0-Write_Depth_A  {4096}-Write_Width_A  {32}
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '请编写一个tcl代码来创建一个具有如下属性的bram IP: -vendor  xilinx.com-version  8.4-module_name  blk_mem_gen_0-Write_Depth_A  {4096}-Write_Width_A  {32}'
- en: (a) Prompt
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 提示
- en: '#  Create  BRAM  IP  with  specific  propertiescreate_ip  -name  blk_mem_gen  -vendor  xilinx.com  -library  ip  -version  8.4  -module_name  blk_mem_gen_0#  Set  properties  for  BRAM  IPset_property  -dict  [list  \CONFIG.Enable_A  {Always_Enabled}  \CONFIG.Register_PortA_Output_of_Memory_Primitives{false}  \CONFIG.Write_Depth_A  {4096}  \CONFIG.Write_Width_A  {32}  \]  [get_ips  blk_mem_gen_0]'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '# 创建具有特定属性的BRAM IP创建_ip  -name  blk_mem_gen  -vendor  xilinx.com  -library  ip  -version  8.4  -module_name  blk_mem_gen_0#
    设置BRAM IP的属性设置_property  -dict  [list  \CONFIG.Enable_A  {Always_Enabled}  \CONFIG.Register_PortA_Output_of_Memory_Primitives{false}  \CONFIG.Write_Depth_A  {4096}  \CONFIG.Write_Width_A  {32}  \]  [get_ips  blk_mem_gen_0]'
- en: (b) Feedback
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 反馈
- en: Figure 6. Inputs and error checking (IP)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6. 输入和错误检查 (IP)
- en: Please  write  a  testbench  for  this  Verilog  code,  with  instantiated  BRAM.  Use  the  32-bit  IEEE-754  format  and  set  all  initial  values  of  the  inputs  to  be  between  0  and  1,  where  N  =  64  and  the  period  is  10ns.  The  float_to_ieee754  function  is  provided.  Stop  when  done,  and  use  fixed  input  values  do  not  use  random  values.  For  input  A,  set  A[i][j]  =  ((i  +  j)  %  100)  /  100.0;  and  x[i]  =  (i  %  100)  /  100.0.  The  initial  integer  should  be  declared  outside  the  initial  block.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 请为此Verilog代码编写一个测试平台，并实例化BRAM。使用32位IEEE-754格式，并将所有输入的初始值设置在0到1之间，其中N = 64，周期为10ns。提供了float_to_ieee754函数。完成后停止，并使用固定的输入值，不使用随机值。对于输入A，设置A[i][j]
    = ((i + j) % 100) / 100.0; 和 x[i] = (i % 100) / 100.0。初始整数应在初始块外声明。
- en: (a) Prompt
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 提示
- en: '…//  Instantiate  the  syrk  modulesyrk  #(.N(N),  .DATA_WIDTH(DATA_WIDTH))  syrk_inst  (.clk(clk),.rst(rst),.start_computation(start_computation),.alpha(alpha),.beta(beta),.A_data_in(A_data_in),.B_data_in(B_data_in),.C_data_out(C_data_out),.A_addr_out(A_addr_out),.B_addr_out(B_addr_out),.C_addr_out(C_addr_out),.A_read(A_read),.B_read(B_read),.C_write(C_write),.done(done));…'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '…// 实例化syrk模块syrk  #(.N(N),  .DATA_WIDTH(DATA_WIDTH))  syrk_inst  (.clk(clk),.rst(rst),.start_computation(start_computation),.alpha(alpha),.beta(beta),.A_data_in(A_data_in),.B_data_in(B_data_in),.C_data_out(C_data_out),.A_addr_out(A_addr_out),.B_addr_out(B_addr_out),.C_addr_out(C_addr_out),.A_read(A_read),.B_read(B_read),.C_write(C_write),.done(done));…'
- en: (b) Feedback
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 反馈
- en: Figure 7. Inputs and error checking (Testbench)
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7. 输入和错误检查（测试平台）
- en: 4.2\. LLM-Assisted HLS Approaches
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2\. LLM 辅助的 HLS 方法
- en: Here, we describe the three LLM-assisted approaches explored herein, showcasing
    the diverse ways in which LLMs can contribute to hardware design. The direct LLM
    translation approach, denoted as C$\rightarrow$HLS-C, on the other hand, highlights
    the potential for LLMs to augment existing HLS tools by raising the level of abstraction
    to natural language input. Figure [2(b)](#S3.F2.sf2 "In Figure 2 ‣ 3.2\. Applications
    ‣ 3\. Survey of the State-of-the-Art in LLMs for HLS ‣ Are LLMs Any Good for High-Level
    Synthesis?") illustrates the design flow for each of these LLM-assisted HLS methodologies.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们描述了三种 LLM 辅助的方法，展示了 LLM 在硬件设计中贡献的多样化方式。直接 LLM 翻译方法，表示为 C$\rightarrow$HLS-C，突出了
    LLM 增强现有 HLS 工具的潜力，通过将抽象层次提高到自然语言输入。图 [2(b)](#S3.F2.sf2 "在图 2 ‣ 3.2\. 应用 ‣ 3\.
    LLM 在 HLS 中的最新进展调查 ‣ LLM 对高层次综合有何帮助？") 展示了每种 LLM 辅助 HLS 方法的设计流程。
- en: 4.2.1\. C$\rightarrow$Verilog
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.1\. C$\rightarrow$Verilog
- en: The use of LLMs to directly generate synthesizable hardware accelerators in
    Verilog requires a well-defined procedure. This procedure involves the steps to
    generate Verilog code from high-level specifications and subsequent steps to produce
    a fully functional accelerator, from simulation to place-and-route. For example,
    a testbench is necessary to validate the accelerator’s functionality during simulation.
    A place-and-route-ready hardware accelerator consists of Verilog code, TCL commands
    to automate the assembly of the accelerator’s design (instantiating IP cores,
    connecting them, and setting up the overall project structure), and XDC files
    to specify the constraints of the accelerator such as clock period and I/O delay.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 使用大型语言模型（LLMs）直接生成可综合的 Verilog 硬件加速器需要一个明确定义的流程。这个流程包括从高层次规格生成 Verilog 代码的步骤，以及从仿真到布图布线（place-and-route）生成完全功能加速器的后续步骤。例如，在仿真过程中，需要一个测试平台来验证加速器的功能。一个准备好进行布图布线的硬件加速器包括
    Verilog 代码、用于自动化加速器设计组装的 TCL 命令（实例化 IP 核、连接它们以及设置整体项目结构）以及 XDC 文件，用于指定加速器的约束条件，如时钟周期和
    I/O 延迟。
- en: Figures [3](#S4.F3 "Figure 3 ‣ 4.1\. HLS Approach ‣ 4\. Experimental Methodology
    ‣ Are LLMs Any Good for High-Level Synthesis?"), [4](#S4.F4 "Figure 4 ‣ 4.1\.
    HLS Approach ‣ 4\. Experimental Methodology ‣ Are LLMs Any Good for High-Level
    Synthesis?"), [5](#S4.F5 "Figure 5 ‣ 4.1\. HLS Approach ‣ 4\. Experimental Methodology
    ‣ Are LLMs Any Good for High-Level Synthesis?"), [6](#S4.F6 "Figure 6 ‣ 4.1\.
    HLS Approach ‣ 4\. Experimental Methodology ‣ Are LLMs Any Good for High-Level
    Synthesis?"), and [7](#S4.F7 "Figure 7 ‣ 4.1\. HLS Approach ‣ 4\. Experimental
    Methodology ‣ Are LLMs Any Good for High-Level Synthesis?") illustrate our C$\rightarrow$Verilog
    process for different components of the hardware design flow. The first step defines
    the context of the generation process, including, but not limited to, the designer’s
    role, the hardware background, and the constraints that the LLM (ChatGPT-4o, in
    our case) should follow to better identify the corresponding context and purpose
    of this process. Figure [3](#S4.F3 "Figure 3 ‣ 4.1\. HLS Approach ‣ 4\. Experimental
    Methodology ‣ Are LLMs Any Good for High-Level Synthesis?") shows the context
    we used in our experiments. We identify ourselves as hardware engineers and aim
    to translate a C program to HDL in Verilog. We specify that this Verilog module
    should target the Xilinx FPGA part xc7a200tfbg-484-1\. Although ChatGPT-4o records
    the part in its memory, the design is not guaranteed to meet the I/O or resource
    constraints unless we explicitly instruct the LLM to meet the I/O constraints.
    If the specification of the part does not exist or is incorrect in the LLM, we
    must manually provide this information to the LLM.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图[3](#S4.F3 "Figure 3 ‣ 4.1\. HLS Approach ‣ 4\. Experimental Methodology ‣
    Are LLMs Any Good for High-Level Synthesis?")、[4](#S4.F4 "Figure 4 ‣ 4.1\. HLS
    Approach ‣ 4\. Experimental Methodology ‣ Are LLMs Any Good for High-Level Synthesis?")、[5](#S4.F5
    "Figure 5 ‣ 4.1\. HLS Approach ‣ 4\. Experimental Methodology ‣ Are LLMs Any Good
    for High-Level Synthesis?")、[6](#S4.F6 "Figure 6 ‣ 4.1\. HLS Approach ‣ 4\. Experimental
    Methodology ‣ Are LLMs Any Good for High-Level Synthesis?") 和 [7](#S4.F7 "Figure
    7 ‣ 4.1\. HLS Approach ‣ 4\. Experimental Methodology ‣ Are LLMs Any Good for
    High-Level Synthesis?") 说明了我们C$\rightarrow$Verilog过程在不同硬件设计流程组件中的应用。第一步定义生成过程的背景，包括但不限于设计师的角色、硬件背景和LLM（在我们的案例中是ChatGPT-4o）应遵循的约束条件，以便更好地识别该过程的相关背景和目的。图[3](#S4.F3
    "Figure 3 ‣ 4.1\. HLS Approach ‣ 4\. Experimental Methodology ‣ Are LLMs Any Good
    for High-Level Synthesis?")展示了我们在实验中使用的背景。我们将自己定义为硬件工程师，并旨在将C程序转换为Verilog中的HDL。我们指定该Verilog模块应针对Xilinx
    FPGA部件xc7a200tfbg-484-1。尽管ChatGPT-4o会在其记忆中记录该部件，但除非我们明确指示LLM满足I/O约束，否则设计不保证符合I/O或资源约束。如果LLM中不存在或不正确的部件规格，我们必须手动向LLM提供这些信息。
- en: 'After providing the role, background, and constraints of the designer and hardware
    to the LLM, we provide the source code to the LLM. It is important to be mindful
    of ChatGPT-4o’s limitations: a 128k token limit for combined input and output,
    with a maximum of 4k tokens for the output alone. If a larger program is needed,
    it should be divided accordingly. In our experiments, all C benchmarks were within
    the 128k token limit, allowing us to input the entire program at once. However,
    due to the 4k output constraint, generating the complete Verilog accelerator required
    multiple iterations. Once generated, the Verilog output undergoes syntax and design
    error checking.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在向LLM提供设计师和硬件的角色、背景以及约束条件后，我们将源代码提供给LLM。需要注意的是，ChatGPT-4o的限制：合并输入和输出的最大令牌限制为128k，单独输出的最大令牌限制为4k。如果需要更大的程序，应该进行相应的拆分。在我们的实验中，所有C语言基准测试都在128k令牌限制范围内，允许我们一次性输入整个程序。然而，由于4k的输出限制，生成完整的Verilog加速器需要多次迭代。一旦生成，Verilog输出会经过语法和设计错误检查。
- en: For designers proficient in hardware design, syntax and design error checking
    can be performed directly within the LLM. Otherwise, a validation tool like Vivado
    is necessary. Once an error is identified, we describe the error in natural language
    to the LLM and regenerate the Verilog code. This process is repeated until successful
    simulation and implementation in Vivado. We encountered some common errors in
    the process, such as incorrect data type mapping in I/O (Figure [4](#S4.F4 "Figure
    4 ‣ 4.1\. HLS Approach ‣ 4\. Experimental Methodology ‣ Are LLMs Any Good for
    High-Level Synthesis?")), misrepresentation of sequential and parallel execution
    (Figure [5](#S4.F5 "Figure 5 ‣ 4.1\. HLS Approach ‣ 4\. Experimental Methodology
    ‣ Are LLMs Any Good for High-Level Synthesis?")), and state machine implementation
    errors (figures omitted for brevity). The designer’s expertise level significantly
    impacts the speed and efficiency of this iterative error resolution process.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 对于精通硬件设计的设计师，可以直接在LLM中执行语法和设计错误检查。否则，必须使用像Vivado这样的验证工具。一旦识别到错误，我们将错误用自然语言描述给LLM，并重新生成Verilog代码。这个过程会重复进行，直到在Vivado中成功仿真和实现。在这个过程中，我们遇到了一些常见错误，例如I/O中的数据类型映射不正确（图
    [4](#S4.F4 "图 4 ‣ 4.1\. HLS 方法 ‣ 4\. 实验方法 ‣ LLM对高级综合的效果如何？")）、顺序和并行执行的误表示（图 [5](#S4.F5
    "图 5 ‣ 4.1\. HLS 方法 ‣ 4\. 实验方法 ‣ LLM对高级综合的效果如何？")），以及状态机实现错误（图示省略以简洁）。设计师的专业水平显著影响这种迭代错误解决过程的速度和效率。
- en: The final step in the LLM-assisted design flow is generating TCL scripts for
    IP integration, XDC constraints, and testbench content (Figures [6](#S4.F6 "Figure
    6 ‣ 4.1\. HLS Approach ‣ 4\. Experimental Methodology ‣ Are LLMs Any Good for
    High-Level Synthesis?") and [7](#S4.F7 "Figure 7 ‣ 4.1\. HLS Approach ‣ 4\. Experimental
    Methodology ‣ Are LLMs Any Good for High-Level Synthesis?")). This step faces
    similar challenges as previous steps if the LLM lacks knowledge of the latest
    syntax or specifications, leading to more errors in generated files. For example,
    defining a proper clock period and calculating IEEE 754 standard floating-point
    values require the latest specifications. To address this problem, we manually
    provided the necessary information to the LLM, which learns and adapts over time,
    potentially reducing errors in future iterations.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: LLM辅助设计流程的最后一步是生成用于IP集成、XDC约束和测试平台内容的TCL脚本（图 [6](#S4.F6 "图 6 ‣ 4.1\. HLS 方法
    ‣ 4\. 实验方法 ‣ LLM对高级综合的效果如何？") 和 [7](#S4.F7 "图 7 ‣ 4.1\. HLS 方法 ‣ 4\. 实验方法 ‣ LLM对高级综合的效果如何？")）。如果LLM缺乏对最新语法或规范的知识，这一步会面临与前面步骤类似的挑战，导致生成的文件中出现更多错误。例如，定义正确的时钟周期和计算IEEE
    754标准浮点值需要最新的规范。为了解决这个问题，我们手动向LLM提供必要的信息，LLM会随着时间的推移学习和适应，可能在未来的迭代中减少错误。
- en: 4.2.2\. NL$\rightarrow$Verilog
  id: totrans-101
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.2\. NL$\rightarrow$Verilog
- en: The second approach is similar to C$\rightarrow$Verilog but uses natural language
    descriptions (or pseudocode) of the program’s functionality as input to the LLM,
    instead of a programming language like C/C++. We described details such as input/output,
    variable types, loops, and operations. The number of prompts required in this
    approach depends on the complexity of the program and the designer’s preferences,
    with LLMs like ChatGPT-4o potentially accommodating the entire program in a single
    prompt, as in our experiments.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种方法类似于C$\rightarrow$Verilog，但使用程序功能的自然语言描述（或伪代码）作为LLM的输入，而不是像C/C++这样的编程语言。我们描述了输入/输出、变量类型、循环和操作等细节。这种方法所需的提示数量取决于程序的复杂性和设计师的偏好，LLM如ChatGPT-4o在我们的实验中可能将整个程序纳入一个提示中。
- en: 4.2.3\. NL$\rightarrow$HLS-C
  id: totrans-103
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.3\. NL$\rightarrow$HLS-C
- en: The third approach differs from the previous two by leveraging the strengths
    of both LLMs and traditional HLS tools. Instead of generating Verilog directly,
    it utilizes an LLM to translate natural language descriptions into HLS-compatible
    input (HLS-C), which is then processed by the HLS tool to produce the synthesizable
    Verilog output. This approach combines the expressiveness of natural language
    with the power and completeness of existing HLS tools, ultimately lowering the
    barrier to entry for hardware design by minimizing the need for proficiency in
    high-level programming languages.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 第三种方法不同于前两种方法，它利用了LLM和传统HLS工具的优势。它不是直接生成Verilog，而是利用LLM将自然语言描述转换为HLS兼容的输入（HLS-C），然后由HLS工具处理以生成可综合的Verilog输出。这种方法将自然语言的表达力与现有HLS工具的强大功能和完整性结合起来，*最终*降低了硬件设计的入门门槛，*最小化*了对高级编程语言的熟练要求。
- en: 5\. Experimental Setup
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 实验设置
- en: To evaluate the three LLM-based approaches and compare them with the baseline
    HLS approach, we used nine benchmarks (syrk, syr2k, mvt, k3mm, k2mm, gesummv,
    gemm, bicg, and atax) from the Polybench suite (Pouchet and Yuki, [2012](#bib.bib21)),
    specifically designed for evaluating the performance of HLS tools and compiler
    technologies. These benchmarks encompass computational kernels common in scientific
    and engineering applications, such as matrix multiplication, 2D convolution, and
    Cholesky decomposition. We employed ChatGPT-4o as our LLM model, Vitis HLS 2023.2
    as our HLS tool, and Vivado 2023.2 for implementation targeting a Xilinx xc7a200tfbg484-1
    FPGA. For each benchmark, we generated designs using all four approaches and collected
    data on resource utilization, power consumption, execution cycles, and critical
    path delay from Vitis HLS and Vivado. Note that the NL$\rightarrow$Verilog approach.
    As such, these approaches share the same steps after the initial input stage,
    and thus have the same evaluation data. We tracked the number of prompts used
    to generate HLS-C, Verilog, TCL, XDC, and testbench content for the LLM-based
    approaches. For a fair comparison, we disabled automatic optimizations like pipelining
    in Vitis HLS. For LLM-based approaches, we used LLMs to generate all necessary
    content (Verilog code, TCL scripts, IPs, testbenches, XDC files) to form a complete
    project.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估三种基于LLM的方法，并与基线HLS方法进行比较，我们使用了来自Polybench套件（Pouchet 和 Yuki，[2012](#bib.bib21)）的九个基准测试（syrk,
    syr2k, mvt, k3mm, k2mm, gesummv, gemm, bicg 和 atax），这些基准专门设计用于评估HLS工具和编译技术的性能。这些基准涵盖了科学和工程应用中常见的计算内核，如矩阵乘法、二维卷积和Cholesky分解。我们使用了ChatGPT-4o作为LLM模型，Vitis
    HLS 2023.2作为HLS工具，以及Vivado 2023.2进行实现，目标是Xilinx xc7a200tfbg484-1 FPGA。对于每个基准，我们使用所有四种方法生成设计，并从Vitis
    HLS和Vivado中收集资源利用率、功耗、执行周期和关键路径延迟的数据。请注意，NL$\rightarrow$Verilog方法。因此，这些方法在初始输入阶段后具有相同的步骤，因此有相同的评估数据。我们跟踪了生成HLS-C、Verilog、TCL、XDC和测试平台内容的提示数量。为了公平比较，我们在Vitis
    HLS中禁用了自动优化，如流水线。对于基于LLM的方法，我们使用LLM生成所有必要的内容（Verilog代码、TCL脚本、IPs、测试平台、XDC文件）来形成一个完整的项目。
- en: Table 1. The number of Prompts for LLM-based approaches
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 表1. 基于LLM的方法的提示数量
- en: '| Benchmark | HLS-C | Verilog | TCL | Testbench | XDC |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 基准测试 | HLS-C | Verilog | TCL | 测试平台 | XDC |'
- en: '| syrk | 4 | 50 | 9 | 12 | 5 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| syrk | 4 | 50 | 9 | 12 | 5 |'
- en: '| syr2k | 1 | 20 | 3 | 7 | 3 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| syr2k | 1 | 20 | 3 | 7 | 3 |'
- en: '| mvt | 1 | 36 | 3 | 7 | 2 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| mvt | 1 | 36 | 3 | 7 | 2 |'
- en: '| k3mm | 1 | 21 | 3 | 5 | 2 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| k3mm | 1 | 21 | 3 | 5 | 2 |'
- en: '| k2mm | 1 | 29 | 3 | 6 | 3 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| k2mm | 1 | 29 | 3 | 6 | 3 |'
- en: '| gesummv | 1 | 23 | 3 | 7 | 3 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| gesummv | 1 | 23 | 3 | 7 | 3 |'
- en: '| gemm | 1 | 22 | 3 | 6 | 3 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| gemm | 1 | 22 | 3 | 6 | 3 |'
- en: '| bicg | 1 | 16 | 3 | 6 | 3 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| bicg | 1 | 16 | 3 | 6 | 3 |'
- en: '| atax | 1 | 11 | 3 | 8 | 3 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| atax | 1 | 11 | 3 | 8 | 3 |'
- en: Table 2. Place & routing results for C$\rightarrow$Verilog approaches
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 表2. C$\rightarrow$Verilog 方法的布置与路由结果
- en: '| Benchmark | Approach | Execution cycles | FF | LUT | Slice | DSP | BRAM |
    Power (W) | CP |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 基准测试 | 方法 | 执行周期 | FF | LUT | 切片 | DSP | BRAM | 功耗 (W) | CP |'
- en: '| syrk | LLM | 1859983 | 954 | 5300 | 1649 | 6 | 8 | 0.164 | 9.934 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| syrk | LLM | 1859983 | 954 | 5300 | 1649 | 6 | 8 | 0.164 | 9.934 |'
- en: '| HLS | 3744260 | 662 | 521 | 221 | 5 | 32 | 0.350 | 8.191 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| HLS | 3744260 | 662 | 521 | 221 | 5 | 32 | 0.350 | 8.191 |'
- en: '| syr2k | LLM | 2125846 | 542 | 472 | 197 | 2 | 12 | 0.181 | 9.446 |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| syr2k | LLM | 2125846 | 542 | 472 | 197 | 2 | 12 | 0.181 | 9.446 |'
- en: '| HLS | 9028229 | 1042 | 960 | 1649 | 5 | 56 | 0.383 | 6.872 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| HLS | 9028229 | 1042 | 960 | 1649 | 5 | 56 | 0.383 | 6.872 |'
- en: '| mvt | LLM | 44996 | 8628 | 2663 | 4404 | 2 | 4 | 0.197 | 9.312 |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| mvt | LLM | 44996 | 8628 | 2663 | 4404 | 2 | 4 | 0.197 | 9.312 |'
- en: '| HLS | 119492 | 713 | 991 | 342 | 5 | 12 | 0.332 | 6.55 |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| HLS | 119492 | 713 | 991 | 342 | 5 | 12 | 0.332 | 6.55 |'
- en: '| k3mm | LLM | 2371593 | 623 | 328 | 236 | 2 | 28 | 0.207 | 9.924 |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| k3mm | LLM | 2371593 | 623 | 328 | 236 | 2 | 28 | 0.207 | 9.924 |'
- en: '| HLS | 10277509 | 927 | 956 | 1649 | 5 | 56 | 0.398 | 6.646 |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| HLS | 10277509 | 927 | 956 | 1649 | 5 | 56 | 0.398 | 6.646 |'
- en: '| k2mm | LLM | 1863816 | 537 | 311 | 202 | 2 | 20 | 0.189 | 9.967 |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| k2mm | LLM | 1863816 | 537 | 311 | 202 | 2 | 20 | 0.189 | 9.967 |'
- en: '| HLS | 7963269 | 929 | 659 | 313 | 5 | 56 | 0.400 | 6.814 |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| HLS | 7963269 | 929 | 659 | 313 | 5 | 56 | 0.400 | 6.814 |'
- en: '| gesummv | LLM | 65991 | 437 | 288 | 170 | 2 | 16 | 0.176 | 9.253 |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| gesummv | LLM | 65991 | 437 | 288 | 170 | 2 | 16 | 0.176 | 9.253 |'
- en: '| HLS | 148805 | 795 | 561 | 228 | 5 | 20 | 0.316 | 6.855 |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| HLS | 148805 | 795 | 561 | 228 | 5 | 20 | 0.316 | 6.855 |'
- en: '| gemm | LLM | 1601739 | 488 | 332 | 200 | 2 | 16 | 0.178 | 9.697 |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| gemm | LLM | 1601739 | 488 | 332 | 200 | 2 | 16 | 0.178 | 9.697 |'
- en: '| HLS | 4542980 | 807 | 505 | 238 | 5 | 32 | 0.359 | 6.551 |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| HLS | 4542980 | 807 | 505 | 238 | 5 | 32 | 0.359 | 6.551 |'
- en: '| bicg | LLM | 46478 | 505 | 194 | 198 | 2 | 20 | 0.196 | 9.251 |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| bicg | LLM | 46478 | 505 | 194 | 198 | 2 | 20 | 0.196 | 9.251 |'
- en: '| HLS | 119492 | 711 | 429 | 223 | 5 | 12 | 0.333 | 6.599 |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| HLS | 119492 | 711 | 429 | 223 | 5 | 12 | 0.333 | 6.599 |'
- en: '| atax | LLM | 57669 | 453 | 257 | 164 | 2 | 16 | 0.167 | 9.952 |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| atax | LLM | 57669 | 453 | 257 | 164 | 2 | 16 | 0.167 | 9.952 |'
- en: '| HLS | 119492 | 741 | 428 | 209 | 5 | 11 | 0.309 | 6.573 |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| HLS | 119492 | 741 | 428 | 209 | 5 | 11 | 0.309 | 6.573 |'
- en: 6\. Results and Analysis
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 结果与分析
- en: Table [1](#S5.T1 "Table 1 ‣ 5\. Experimental Setup ‣ Are LLMs Any Good for High-Level
    Synthesis?") presents the number of prompts required for each file type (HLS-C,
    Verilog, TCL, testbench, and XDC) to construct a complete hardware accelerator
    from C benchmarks. As demonstrated in Sec. [5](#S5 "5\. Experimental Setup ‣ Are
    LLMs Any Good for High-Level Synthesis?"), the C$\rightarrow$Verilog approaches
    share the same place-and-route outcomes.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 表格[1](#S5.T1 "Table 1 ‣ 5\. Experimental Setup ‣ Are LLMs Any Good for High-Level
    Synthesis?")展示了从C基准构建完整硬件加速器所需的每种文件类型（HLS-C、Verilog、TCL、testbench和XDC）的提示数量。如第[5](#S5
    "5\. Experimental Setup ‣ Are LLMs Any Good for High-Level Synthesis?")节所示，C$\rightarrow$Verilog方法共享相同的布局和布线结果。
- en: Notably, generating the Verilog code generally required the most prompts compared
    to other file types. But the number of prompts required varied significantly depending
    on the benchmark, as well as our growing familiarity with the LLM’s behavior with
    Verilog generation. The syrk benchmark, for example, required considerably more
    interaction with the LLM compared to atax (the last benchmark we worked on). The
    syrk kernel exhibits a higher level of complexity, containing four nested loops
    with multiple multiplications in a single operation and three 2D arrays for inputs
    and outputs. Conversely, atax only comprises two nested loops and one 2D array
    for input. This suggests that the inherent complexity of the benchmark code, as
    well as our initial learning curve to effectively prompt the LLM to minimize errors,
    heavily influenced the number of prompts needed for accurate Verilog generation.
    As we gained experience and refined our prompting strategies, we were able to
    consolidate prompts, leading to faster generation for subsequent benchmarks. In
    contrast, the number of prompts for TCL generation remained relatively consistent
    across all benchmarks, implying that this task is less sensitive to the specific
    characteristics of the input code. The complexity of the benchmark and the designer’s
    growing familiarity with LLM interaction are key factors in determining the number
    of prompts needed for successful Verilog generation, although prior design experience
    can also play a role.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，生成Verilog代码通常需要比其他文件类型更多的提示。然而，所需的提示数量因基准不同而差异显著，同时也与我们对LLM生成Verilog的行为的熟悉程度有关。例如，syrk基准需要比atax（我们最后处理的基准）更多的LLM交互。syrk内核具有更高的复杂性，包含四个嵌套循环和多次乘法操作以及三个二维数组作为输入和输出。相比之下，atax仅包含两个嵌套循环和一个二维数组作为输入。这表明基准代码的固有复杂性以及我们最初学习有效提示LLM以减少错误的曲线，极大地影响了生成准确Verilog所需的提示数量。随着我们经验的积累和提示策略的完善，我们能够整合提示，从而加快了后续基准的生成速度。相反，TCL生成的提示数量在所有基准中保持相对一致，这表明此任务对输入代码的特定特征不那么敏感。基准的复杂性和设计师对LLM交互的熟悉程度是决定成功生成Verilog所需提示数量的关键因素，尽管先前的设计经验也可能发挥作用。
- en: Table [2](#S5.T2 "Table 2 ‣ 5\. Experimental Setup ‣ Are LLMs Any Good for High-Level
    Synthesis?") presents the simulation and implementation results for both LLM-based
    and HLS-based approaches. For each benchmark, LLM refers to the C$\rightarrow$Verilog
    approaches. To determine the quality of a resulting hardware accelerators, the
    evaluation metrics include execution cycles, resource utilization (FFs, LUTs,
    Slices, DSPs, and BRAMs), total power consumption, and critical path delay.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 表[2](#S5.T2 "Table 2 ‣ 5\. Experimental Setup ‣ Are LLMs Any Good for High-Level
    Synthesis?")展示了LLM-based和HLS-based方法的仿真和实现结果。对于每个基准，LLM指的是C$\rightarrow$Verilog方法。为了确定最终硬件加速器的质量，评估指标包括执行周期、资源利用率（FFs、LUTs、Slices、DSPs和BRAMs）、总功耗和关键路径延迟。
- en: A key observation is the significant variation in results across different benchmarks.
    For the syrk and mvt benchmarks, the LLM-based approaches consume more resources
    (except DSPs and BRAMs) compared to HLS. This is attributed to the use of LUT
    RAM for the inner matrix in the LLM-generated designs.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 一个关键观察是不同基准结果的显著差异。对于syrk和mvt基准，基于LLM的方法在资源消耗（除了DSPs和BRAMs）方面高于HLS。这归因于LLM生成设计中使用了LUT
    RAM作为内部矩阵。
- en: However, for the remaining seven benchmarks, LLM-based approaches consistently
    outperformed the HLS-based approaches across all metrics. This includes a notable
    reduction in resource utilization (with an average decrease of 38.67%), a significant
    improvement in execution cycles (average reduction of 64%), and a substantial
    reduction in total power consumption (average reduction of 38.67%). For the critical
    path, the HLS-based approach outperformed LLM-based approaches by an average of
    28.82%.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于其余七个基准测试，基于LLM的方法在所有指标上始终优于基于HLS的方法。这包括资源利用率的显著减少（平均降低38.67%），执行周期的显著改善（平均降低64%），以及总功耗的显著减少（平均降低38.67%）。对于关键路径，基于HLS的方法在平均上超越了基于LLM的方法28.82%。
- en: Overall, the results in Table [2](#S5.T2 "Table 2 ‣ 5\. Experimental Setup ‣
    Are LLMs Any Good for High-Level Synthesis?") demonstrate the potential of LLMs
    in optimizing various aspects of hardware design. While the LLM-based approaches
    did not outperform in every metric for all benchmarks, their consistent success
    in the majority of cases, particularly in resource utilization, power consumption,
    and often execution cycles, highlights the promise of this technology for HLS.
    Further research is needed to refine and expand these capabilities, and explore
    them in a wider variety of usage scenarios, but the current results are encouraging
    and suggest that LLMs could play a significant role in the future of hardware
    design automation.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，表[2](#S5.T2 "Table 2 ‣ 5\. Experimental Setup ‣ Are LLMs Any Good for High-Level
    Synthesis?")中的结果展示了LLM在优化硬件设计各个方面的潜力。尽管基于LLM的方法在所有基准测试中并未在每个指标上都优于其他方法，但它们在大多数情况下，尤其是在资源利用率、功耗和执行周期方面的一致成功，突显了这种技术在HLS中的前景。进一步的研究是必要的，以完善和扩展这些能力，并在更广泛的使用场景中进行探索，但目前的结果令人鼓舞，并建议LLM在未来硬件设计自动化中可能扮演重要角色。
- en: 7\. The Energy Elephant in the LLM-HLS Room
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. LLM-HLS领域的能源大象
- en: 'While the initial excitement surrounding the integration of LLMs into the HLS
    workflow has spurred significant research, a critical aspect has been conspicuously
    absent from most discussions: the energy implications. The majority of studies
    have focused on the potential of LLMs to streamline the design process, enhance
    automation, and improve the quality of generated hardware. However, they have
    largely overlooked the energy consumption associated with both the training and
    inference of these models.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管将LLM融入HLS工作流程的初期兴奋已促使了大量研究，但一个关键方面在大多数讨论中显著缺失：能源影响。大多数研究集中在LLM的潜力上，如简化设计过程、增强自动化和提高生成硬件的质量。然而，它们在很大程度上忽视了这些模型在训练和推理过程中相关的能源消耗。
- en: LLMs, particularly large-scale models like GPT-3 and GPT-4, are notorious for
    their computational demands. Training LLMs can consume hundreds of megawatt-hours
    to several gigawatt-hours of electricity (Schwartz et al., [2020](#bib.bib23)).
    Even inference, the process of generating responses to prompts, can be computationally
    intensive, requiring substantial energy resources. The Electrical Power Research
    Institute (EPRI) estimates that a single ChatGPT query can consume approximately
    2.9 W-hours of energy—nearly 10 times the power of a single Google search (Electric
    Power Research Institute, [2024](#bib.bib10))—a considerable amount when numerous
    queries are needed for HLS tasks. This raises concerns about the overall energy
    efficiency of incorporating LLMs into the HLS flow. Given that a primary goal
    of HLS is to design hardware accelerators that are more energy efficient than
    general-purpose computers, the energy overhead of utilizing LLMs could outweigh
    the intended benefits.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: LLM，尤其是像GPT-3和GPT-4这样的大规模模型，以其计算需求而闻名。训练LLM可能消耗数百兆瓦时到几吉瓦时的电力（Schwartz等，[2020](#bib.bib23)）。即使是推理，即生成对提示的响应，也可能需要大量的能源资源。电力研究所（EPRI）估计单次ChatGPT查询的能耗大约为2.9瓦时—接近单次Google搜索能耗的10倍（电力研究所，[2024](#bib.bib10)）—当HLS任务需要大量查询时，这个数量相当可观。这引发了将LLM纳入HLS流程的整体能源效率的担忧。鉴于HLS的主要目标是设计比通用计算机更具能源效率的硬件加速器，使用LLM的能源开销可能会超过预期的好处。
- en: Furthermore, the process of fine-tuning LLMs for specific HLS tasks can exacerbate
    the issue of energy consumption. Fine-tuning involves retraining the model on
    domain-specific data, which is computationally expensive. If the energy cost of
    fine-tuning and utilizing an LLM is greater than the energy saved across all resulting
    hardware designs, then employing LLMs in this way would be counterproductive for
    energy efficiency.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，为特定HLS任务微调LLM的过程可能会加剧能源消耗的问题。微调涉及在特定领域的数据上重新训练模型，这在计算上是昂贵的。如果微调和使用LLM的能源成本大于所有结果硬件设计节省的能源，那么以这种方式使用LLM将对能源效率产生负面影响。
- en: The lack of attention to power/energy implications in current research raises
    concerns about the sustainability and practicality of LLM-driven HLS. As the field
    progresses, it is imperative to thoroughly investigate and quantify the energy
    costs associated with LLM utilization. This will enable a more comprehensive evaluation
    of the trade-offs between design efficiency and power consumption, ultimately
    leading to more informed decisions regarding the appropriate use of LLMs in HLS.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 当前研究对功率/能源影响的关注不足引发了对LLM驱动HLS的可持续性和实用性的担忧。随着领域的发展，彻底调查和量化LLM使用相关的能源成本至关重要。这将使得对设计效率与功耗之间的权衡有一个更全面的评估，*最终*作出关于在HLS中适当使用LLM的更加明智的决策。
- en: 8\. Conclusion
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8\. 结论
- en: This paper has explored the application of Large Language Models (LLMs) in High-Level
    Synthesis (HLS), evaluating their potential to transform hardware design workflows.
    Through a survey and experimental evaluations, we assessed the ability of LLMs
    to generate Verilog code from high-level specifications, including both C benchmarks
    and natural language descriptions. Our findings reveal that LLM-based approaches
    can significantly enhance the efficiency of the HLS process, demonstrating notable
    improvements in resource utilization, execution cycles, and power consumption
    for most benchmarks compared to traditional HLS tools. However, challenges remain
    in ensuring the quality and optimization of LLM-generated code, particularly regarding
    critical path delays and the complexity of initial prompt interactions. Additionally,
    the substantial energy consumption associated with training and utilizing LLMs
    raises concerns about the overall energy efficiency of their integration into
    HLS workflows. Despite these challenges, the promising results suggest that with
    further refinement and research, LLMs could play a pivotal role in the future
    of hardware design automation, offering a powerful tool to streamline and optimize
    the HLS process.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 本文探讨了大型语言模型（LLMs）在高层次综合（HLS）中的应用，评估了它们在转变硬件设计工作流程中的潜力。通过调查和实验评估，我们评估了 LLM 从高层次规格生成
    Verilog 代码的能力，包括 C 基准和自然语言描述。我们的发现表明，基于 LLM 的方法可以显著提高 HLS 过程的效率，在大多数基准测试中，相比于传统的
    HLS 工具，资源利用率、执行周期和功耗都得到了显著改善。然而，确保 LLM 生成代码的质量和优化仍然面临挑战，特别是在关键路径延迟和初始提示交互的复杂性方面。此外，训练和使用
    LLM 相关的巨大能耗引发了对它们融入 HLS 工作流程的整体能效的担忧。尽管面临这些挑战， promising results 表明，通过进一步的完善和研究，LLM
    可能在未来的硬件设计自动化中发挥关键作用，提供一种强大的工具来简化和优化 HLS 过程。
- en: Acknowledgements.
  id: totrans-152
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 致谢。
- en: This work was partially supported by the Technology and Research Initiative
    Fund (TRIF) provided to the University of Arizona by the Arizona Board of Regents
    (ABOR) and by NSF Grant 1844952.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 本项工作部分得到了亚利桑那大学由亚利桑那州董事会（ABOR）提供的技术与研究倡议基金（TRIF）的支持，以及 NSF 资助 1844952。
- en: References
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: Ahmad et al. (2024) Baleegh Ahmad, Shailja Thakur, Benjamin Tan, Ramesh Karri,
    and Hammond Pearce. 2024. On hardware security bug code fixes by prompting large
    language models. *IEEE Transactions on Information Forensics and Security* (2024).
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ahmad 等（2024）Baleegh Ahmad, Shailja Thakur, Benjamin Tan, Ramesh Karri 和 Hammond
    Pearce。2024。通过提示大型语言模型修复硬件安全漏洞代码。*IEEE 信息取证与安全学报*（2024）。
- en: 'Allam and Shalan (2024) Ahmed Allam and Mohamed Shalan. 2024. RTL-Repo: A Benchmark
    for Evaluating LLMs on Large-Scale RTL Design Projects. *arXiv preprint arXiv:2405.17378*
    (2024).'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Allam 和 Shalan（2024）Ahmed Allam 和 Mohamed Shalan。2024。RTL-Repo：用于评估 LLM 在大规模
    RTL 设计项目中的基准。*arXiv 预印本 arXiv:2405.17378*（2024）。
- en: Bhandari et al. (2024) Jitendra Bhandari, Johann Knechtel, Ramesh Narayanaswamy,
    Siddharth Garg, and Ramesh Karri. 2024. LLM-Aided Testbench Generation and Bug
    Detection for Finite-State Machines. *arXiv preprint arXiv:2406.17132* (2024).
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bhandari 等（2024）Jitendra Bhandari, Johann Knechtel, Ramesh Narayanaswamy, Siddharth
    Garg 和 Ramesh Karri。2024。LLM 辅助的测试平台生成和有限状态机的漏洞检测。*arXiv 预印本 arXiv:2406.17132*（2024）。
- en: 'Blocklove et al. (2023) Jason Blocklove, Siddharth Garg, Ramesh Karri, and
    Hammond Pearce. 2023. Chip-chat: Challenges and opportunities in conversational
    hardware design. In *2023 ACM/IEEE 5th Workshop on Machine Learning for CAD (MLCAD)*.
    IEEE, 1–6.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Blocklove 等（2023）Jason Blocklove, Siddharth Garg, Ramesh Karri 和 Hammond Pearce。2023。Chip-chat：对话式硬件设计中的挑战与机遇。在*2023
    ACM/IEEE 第五届机器学习在计算机辅助设计中的应用研讨会（MLCAD）*。IEEE，第 1–6 页。
- en: 'Chang et al. (2024) Kaiyan Chang, Zhirong Chen, Yunhao Zhou, Wenlong Zhu, Haobo
    Xu, Cangyuan Li, Mengdi Wang, Shengwen Liang, Huawei Li, Yinhe Han, et al. 2024.
    Natural language is not enough: Benchmarking multi-modal generative AI for Verilog
    generation. *arXiv preprint arXiv:2407.08473* (2024).'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chang 等（2024）Kaiyan Chang, Zhirong Chen, Yunhao Zhou, Wenlong Zhu, Haobo Xu,
    Cangyuan Li, Mengdi Wang, Shengwen Liang, Huawei Li, Yinhe Han 等。2024。自然语言还不够：基准测试多模态生成
    AI 以生成 Verilog。*arXiv 预印本 arXiv:2407.08473*（2024）。
- en: 'Chang et al. (2023) Kaiyan Chang, Ying Wang, Haimeng Ren, Mengdi Wang, Shengwen
    Liang, Yinhe Han, Huawei Li, and Xiaowei Li. 2023. ChipGPT: How far are we from
    natural language hardware design. *arXiv preprint arXiv:2305.14019* (2023).'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chang 等（2023）Kaiyan Chang, Ying Wang, Haimeng Ren, Mengdi Wang, Shengwen Liang,
    Yinhe Han, Huawei Li 和 Xiaowei Li。2023。ChipGPT：我们距离自然语言硬件设计还有多远。*arXiv 预印本 arXiv:2305.14019*（2023）。
- en: 'Collini et al. (2024) Luca Collini, Siddharth Garg, and Ramesh Karri. 2024.
    C2HLSC: Can LLMs Bridge the Software-to-Hardware Design Gap? *arXiv preprint arXiv:2406.09233*
    (2024).'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Collini 等 (2024) Luca Collini, Siddharth Garg, 和 Ramesh Karri. 2024. C2HLSC:
    大型语言模型能否弥合软件与硬件设计之间的差距？ *arXiv 预印本 arXiv:2406.09233* (2024)。'
- en: Coussy et al. (2009) Philippe Coussy, Daniel D Gajski, Michael Meredith, and
    Andres Takach. 2009. An introduction to high-level synthesis. *IEEE Design & Test
    of Computers* 26, 4 (2009), 8–17.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Coussy 等 (2009) Philippe Coussy, Daniel D Gajski, Michael Meredith, 和 Andres
    Takach. 2009. 高级综合简介。 *IEEE 计算机设计与测试* 26, 4 (2009), 8–17。
- en: 'Electric Power Research Institute (2024) Electric Power Research Institute.
    2024. *Powering Intelligence: Analyzing Artificial Intelligence and Data Center
    Energy Consumption*. Technical Report. Electric Power Research Institute (EPRI).
    [https://www.epri.com/research/products/3002028905](https://www.epri.com/research/products/3002028905)'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电力研究所 (2024) 电力研究所. 2024. *驱动智能：分析人工智能与数据中心能源消耗*。技术报告。电力研究所 (EPRI)。 [https://www.epri.com/research/products/3002028905](https://www.epri.com/research/products/3002028905)
- en: 'Fu et al. (2024) Weimin Fu, Shijie Li, Yifang Zhao, Haocheng Ma, Raj Dutta,
    Xuan Zhang, Kaichen Yang, Yier Jin, and Xiaolong Guo. 2024. Hardware Phi-1.5B:
    A Large Language Model Encodes Hardware Domain Specific Knowledge. In *Proceedings
    of the 29th Asia and South Pacific Design Automation Conference* (Incheon, Republic
    of Korea) *(ASPDAC ’24)*. IEEE Press, 349–354. [https://doi.org/10.1109/ASP-DAC58780.2024.10473927](https://doi.org/10.1109/ASP-DAC58780.2024.10473927)'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Fu 等 (2024) Weimin Fu, Shijie Li, Yifang Zhao, Haocheng Ma, Raj Dutta, Xuan
    Zhang, Kaichen Yang, Yier Jin, 和 Xiaolong Guo. 2024. 硬件 Phi-1.5B: 大型语言模型编码硬件领域特定知识。见于
    *第29届亚洲和南太平洋设计自动化会议论文集*（韩国仁川）*(ASPDAC ’24)*。IEEE Press, 349–354。 [https://doi.org/10.1109/ASP-DAC58780.2024.10473927](https://doi.org/10.1109/ASP-DAC58780.2024.10473927)'
- en: 'Fu et al. (2023) Yonggan Fu, Yongan Zhang, Zhongzhi Yu, Sixu Li, Zhifan Ye,
    Chaojian Li, Cheng Wan, and Yingyan Celine Lin. 2023. Gpt4aigchip: Towards next-generation
    ai accelerator design automation via large language models. In *2023 IEEE/ACM
    International Conference on Computer Aided Design (ICCAD)*. IEEE, 1–9.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Fu 等 (2023) Yonggan Fu, Yongan Zhang, Zhongzhi Yu, Sixu Li, Zhifan Ye, Chaojian
    Li, Cheng Wan, 和 Yingyan Celine Lin. 2023. Gpt4aigchip: 通过大型语言模型推进下一代 AI 加速器设计自动化。见于
    *2023 IEEE/ACM 国际计算机辅助设计会议（ICCAD）*。IEEE, 1–9。'
- en: Kande et al. (2023) Rahul Kande, Hammond Pearce, Benjamin Tan, Brendan Dolan-Gavitt,
    Shailja Thakur, Ramesh Karri, and Jeyavijayan Rajendran. 2023. Llm-assisted generation
    of hardware assertions. *arXiv preprint arXiv:2306.14027* (2023).
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kande 等 (2023) Rahul Kande, Hammond Pearce, Benjamin Tan, Brendan Dolan-Gavitt,
    Shailja Thakur, Ramesh Karri, 和 Jeyavijayan Rajendran. 2023. 大型语言模型辅助的硬件断言生成。
    *arXiv 预印本 arXiv:2306.14027* (2023)。
- en: Liao et al. (2023) Yuchao Liao, Tosiron Adegbija, and Roman Lysecky. 2023. Efficient
    system-level design space exploration for high-level synthesis using pareto-optimal
    subspace pruning. In *Proceedings of the 28th Asia and South Pacific Design Automation
    Conference*. 567–572.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liao 等 (2023) Yuchao Liao, Tosiron Adegbija, 和 Roman Lysecky. 2023. 使用 Pareto
    最优子空间剪枝进行系统级设计空间探索。见于 *第28届亚洲和南太平洋设计自动化会议论文集*。567–572。
- en: 'Liu et al. (2023) Mingjie Liu, Nathaniel Pinckney, Brucek Khailany, and Haoxing
    Ren. 2023. Verilogeval: Evaluating large language models for verilog code generation.
    In *2023 IEEE/ACM International Conference on Computer Aided Design (ICCAD)*.
    IEEE, 1–8.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu 等 (2023) Mingjie Liu, Nathaniel Pinckney, Brucek Khailany, 和 Haoxing Ren.
    2023. Verilogeval: 评估大型语言模型在 Verilog 代码生成中的表现。见于 *2023 IEEE/ACM 国际计算机辅助设计会议（ICCAD）*。IEEE,
    1–8。'
- en: 'Lu et al. (2024) Yao Lu, Shang Liu, Qijun Zhang, and Zhiyao Xie. 2024. Rtllm:
    An open-source benchmark for design rtl generation with large language model.
    In *2024 29th Asia and South Pacific Design Automation Conference (ASP-DAC)*.
    IEEE, 722–727.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lu 等 (2024) Yao Lu, Shang Liu, Qijun Zhang, 和 Zhiyao Xie. 2024. Rtllm: 一个用于设计
    RTL 生成的大型语言模型开源基准。见于 *2024年第29届亚洲和南太平洋设计自动化会议（ASP-DAC）*。IEEE, 722–727。'
- en: Meech (2023) James T Meech. 2023. Leveraging High-Level Synthesis and Large
    Language Models to Generate, Simulate, and Deploy a Uniform Random Number Generator
    Hardware Design. *arXiv preprint arXiv:2311.03489* (2023).
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Meech (2023) James T Meech. 2023. 利用高级综合和大型语言模型生成、模拟和部署统一随机数生成器硬件设计。 *arXiv
    预印本 arXiv:2311.03489* (2023)。
- en: Nadimi and Zheng (2024) Bardia Nadimi and Hao Zheng. 2024. A Multi-Expert Large
    Language Model Architecture for Verilog Code Generation. *arXiv preprint arXiv:2404.08029*
    (2024).
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nadimi 和 Zheng (2024) Bardia Nadimi 和 Hao Zheng. 2024. 一种多专家大型语言模型架构用于 Verilog
    代码生成。 *arXiv 预印本 arXiv:2404.08029* (2024)。
- en: Nair et al. (2023) Madhav Nair, Rajat Sadhukhan, and Debdeep Mukhopadhyay. 2023.
    Generating secure hardware using chatgpt resistant to cwes. *Cryptology ePrint
    Archive* (2023).
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nair 等 (2023) Madhav Nair, Rajat Sadhukhan 和 Debdeep Mukhopadhyay. 2023. 生成抗
    CWE 的安全硬件使用 ChatGPT。*Cryptology ePrint Archive* (2023)。
- en: Orenes-Vera et al. (2023) Marcelo Orenes-Vera, Margaret Martonosi, and David
    Wentzlaff. 2023. Using LLMs to Facilitate Formal Verification of RTL. arXiv:2309.09437 [cs.AR]
    [https://arxiv.org/abs/2309.09437](https://arxiv.org/abs/2309.09437)
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Orenes-Vera 等 (2023) Marcelo Orenes-Vera, Margaret Martonosi 和 David Wentzlaff.
    2023. 使用 LLM 促进 RTL 的形式验证。arXiv:2309.09437 [cs.AR] [https://arxiv.org/abs/2309.09437](https://arxiv.org/abs/2309.09437)
- en: 'Pouchet and Yuki (2012) Louis-Noël Pouchet and Tomofumi Yuki. 2012. Polyhedral
    Benchmark suite. [https://web.cs.ucla.edu/~pouchet/software/polybench/](https://web.cs.ucla.edu/~pouchet/software/polybench/)
    Accessed: 8/12/2024.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Pouchet 和 Yuki (2012) Louis-Noël Pouchet 和 Tomofumi Yuki. 2012. 多面体基准测试套件。
    [https://web.cs.ucla.edu/~pouchet/software/polybench/](https://web.cs.ucla.edu/~pouchet/software/polybench/)
    访问时间: 2024年8月12日。'
- en: 'Qiu et al. (2024) Ruidi Qiu, Grace Li Zhang, Rolf Drechsler, Ulf Schlichtmann,
    and Bing Li. 2024. AutoBench: Automatic Testbench Generation and Evaluation Using
    LLMs for HDL Design. *arXiv preprint arXiv:2407.03891* (2024).'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Qiu 等 (2024) Ruidi Qiu, Grace Li Zhang, Rolf Drechsler, Ulf Schlichtmann 和
    Bing Li. 2024. AutoBench: 使用 LLM 进行 HDL 设计的自动测试平台生成与评估。*arXiv 预印本 arXiv:2407.03891*
    (2024)。'
- en: Schwartz et al. (2020) Roy Schwartz, Jesse Dodge, Noah A Smith, and Oren Etzioni.
    2020. Green ai. *Commun. ACM* 63, 12 (2020), 54–63.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schwartz 等 (2020) Roy Schwartz, Jesse Dodge, Noah A Smith 和 Oren Etzioni. 2020.
    绿色 AI。*Commun. ACM* 63, 12 (2020), 54–63。
- en: Swaroopa et al. (2024) Sneha Swaroopa, Rijoy Mukherjee, Anushka Debnath, and
    Rajat Subhra Chakraborty. 2024. Evaluating Large Language Models for Automatic
    Register Transfer Logic Generation via High-Level Synthesis. arXiv:2408.02793 [cs.AR]
    [https://arxiv.org/abs/2408.02793](https://arxiv.org/abs/2408.02793)
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Swaroopa 等 (2024) Sneha Swaroopa, Rijoy Mukherjee, Anushka Debnath 和 Rajat Subhra
    Chakraborty. 2024. 通过高层次综合评估大型语言模型在自动寄存器传输逻辑生成中的应用。arXiv:2408.02793 [cs.AR] [https://arxiv.org/abs/2408.02793](https://arxiv.org/abs/2408.02793)
- en: 'Tao et al. (2024) Zhuofu Tao, Yichen Shi, Yiru Huo, Rui Ye, Zonghang Li, Li
    Huang, Chen Wu, Na Bai, Zhiping Yu, Ting-Jung Lin, et al. 2024. AMSNet: Netlist
    Dataset for AMS Circuits. *arXiv preprint arXiv:2405.09045* (2024).'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tao 等 (2024) Zhuofu Tao, Yichen Shi, Yiru Huo, Rui Ye, Zonghang Li, Li Huang,
    Chen Wu, Na Bai, Zhiping Yu, Ting-Jung Lin 等. 2024. AMSNet: AMS 电路的网表数据集。*arXiv
    预印本 arXiv:2405.09045* (2024)。'
- en: Thakur et al. (2023) Shailja Thakur, Baleegh Ahmad, Zhenxing Fan, Hammond Pearce,
    Benjamin Tan, Ramesh Karri, Brendan Dolan-Gavitt, and Siddharth Garg. 2023. Benchmarking
    large language models for automated verilog rtl code generation. In *2023 Design,
    Automation & Test in Europe Conference & Exhibition (DATE)*. IEEE, 1–6.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Thakur 等 (2023) Shailja Thakur, Baleegh Ahmad, Zhenxing Fan, Hammond Pearce,
    Benjamin Tan, Ramesh Karri, Brendan Dolan-Gavitt 和 Siddharth Garg. 2023. 基于大型语言模型的自动
    Verilog RTL 代码生成基准测试。在 *2023年欧洲设计、自动化与测试会议及展览 (DATE)*。IEEE, 1–6。
- en: 'Thakur et al. (2024) Shailja Thakur, Baleegh Ahmad, Hammond Pearce, Benjamin
    Tan, Brendan Dolan-Gavitt, Ramesh Karri, and Siddharth Garg. 2024. Verigen: A
    large language model for verilog code generation. *ACM Transactions on Design
    Automation of Electronic Systems* 29, 3 (2024), 1–31.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Thakur 等 (2024) Shailja Thakur, Baleegh Ahmad, Hammond Pearce, Benjamin Tan,
    Brendan Dolan-Gavitt, Ramesh Karri 和 Siddharth Garg. 2024. Verigen: 用于 Verilog
    代码生成的大型语言模型。*ACM 电子系统设计自动化交易* 29, 3 (2024), 1–31。'
- en: 'Vijayaraghavan et al. (2024) Prashanth Vijayaraghavan, Luyao Shi, Stefano Ambrogio,
    Charles Mackin, Apoorva Nitsure, David Beymer, and Ehsan Degan. 2024. VHDL-Eval:
    A Framework for Evaluating Large Language Models in VHDL Code Generation. *arXiv
    preprint arXiv:2406.04379* (2024).'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Vijayaraghavan 等 (2024) Prashanth Vijayaraghavan, Luyao Shi, Stefano Ambrogio,
    Charles Mackin, Apoorva Nitsure, David Beymer 和 Ehsan Degan. 2024. VHDL-Eval:
    用于评估 VHDL 代码生成中的大型语言模型的框架。*arXiv 预印本 arXiv:2406.04379* (2024)。'
- en: Wan et al. (2024) Lily Jiaxin Wan, Yingbing Huang, Yuhong Li, Hanchen Ye, Jinghua
    Wang, Xiaofan Zhang, and Deming Chen. 2024. Software/hardware co-design for llm
    and its application for design verification. In *2024 29th Asia and South Pacific
    Design Automation Conference (ASP-DAC)*. IEEE, 435–441.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wan 等 (2024) Lily Jiaxin Wan, Yingbing Huang, Yuhong Li, Hanchen Ye, Jinghua
    Wang, Xiaofan Zhang 和 Deming Chen. 2024. 针对 LLM 的软件/硬件协同设计及其在设计验证中的应用。在 *2024年第29届亚太设计自动化大会
    (ASP-DAC)*。IEEE, 435–441。
- en: Xu et al. (2024) Kangwei Xu, Grace Li Zhang, Xunzhao Yin, Cheng Zhuo, Ulf Schlichtmann,
    and Bing Li. 2024. Automated C/C++ Program Repair for High-Level Synthesis via
    Large Language Models. *arXiv preprint arXiv:2407.03889* (2024).
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等 (2024) Kangwei Xu, Grace Li Zhang, Xunzhao Yin, Cheng Zhuo, Ulf Schlichtmann
    和 Bing Li. 2024. 基于大型语言模型的高层次综合自动 C/C++ 程序修复。*arXiv 预印本 arXiv:2407.03889* (2024)。
- en: Zhao et al. (2023) Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei
    Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al.
    2023. A survey of large language models. *arXiv preprint arXiv:2303.18223* (2023).
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao 等人（2023）Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang,
    Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong 等人。2023。关于大型语言模型的调查。*arXiv
    预印本 arXiv:2303.18223*（2023）。
