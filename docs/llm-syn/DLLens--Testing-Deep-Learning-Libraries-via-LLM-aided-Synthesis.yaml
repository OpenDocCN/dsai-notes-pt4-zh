- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 19:03:50'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-09-08 19:03:50'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'DLLens: 通过LLM辅助合成测试深度学习库'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.07944](https://ar5iv.labs.arxiv.org/html/2406.07944)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2406.07944](https://ar5iv.labs.arxiv.org/html/2406.07944)
- en: Meiziniu Li, Dongze Li, Jianmeng Liu, Jialun Cao, Yongqiang Tian, Shing-Chi
    Cheung The Hong Kong University of Science and Technology, Hong Kong, China
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 李美子, 李东泽, 刘剑蒙, 曹佳伦, 田永强, 张成志 香港科技大学, 香港, 中国
- en: mlick@cse.ust.hk, dlibk@connect.ust.hk, jliudq@connect.ust.hk, jcaoap@cse.ust.hk,
    yqtian@ust.hk, scc@cse.ust.hk
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: mlick@cse.ust.hk, dlibk@connect.ust.hk, jliudq@connect.ust.hk, jcaoap@cse.ust.hk,
    yqtian@ust.hk, scc@cse.ust.hk
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Testing is a major approach to ensuring the quality of deep learning (DL) libraries.
    Existing testing techniques commonly adopt differential testing to relieve the
    need for test oracle construction. However, these techniques are limited in finding
    implementations that offer the same functionality and generating diverse test
    inputs for differential testing. This paper introduces DLLens, a novel differential
    testing technique for DL library testing. Our insight is that APIs in different
    DL libraries are commonly designed to accomplish various computations for the
    same set of published DL algorithms. Although the mapping of these APIs is not
    often one-to-one, we observe that their computations can be mutually simulated
    after proper composition and adaptation. The use of these simulation counterparts
    facilitates differential testing for the detection of functional DL library bugs.
    Leveraging the insight, we propose DLLens as a novel mechanism that utilizes a
    large language model (LLM) to synthesize valid counterparts of DL library APIs.
    To generate diverse test inputs, DLLens incorporates a static analysis method
    aided by LLMs to extract path constraints from all execution paths in each API
    and its counterpart’s implementations. These path constraints are then used to
    guide the generation of diverse test inputs. We evaluate DLLens on two popular
    DL libraries, TensorFlow and PyTorch. Our evaluation shows that DLLens can synthesize
    counterparts for more than twice as many APIs found by state-of-the-art techniques
    on these libraries. Moreover, DLLens can extract 26.7% more constraints and detect
    2.5 times as many bugs as state-of-the-art techniques. DLLens has successfully
    found 56bugs in recent TensorFlow and PyTorch libraries. Among them, 41are previously
    unknown, 39of which have been confirmed by developers after reporting, and 19
    of those confirmed bugs have been fixed by developers.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 测试是确保深度学习（DL）库质量的主要方法。现有的测试技术通常采用差分测试来减少对测试神谕构造的需求。然而，这些技术在找到提供相同功能的实现以及为差分测试生成多样化测试输入方面存在局限。本文介绍了DLLens，一种用于DL库测试的新型差分测试技术。我们的见解是，不同DL库中的API通常被设计用于为同一组已发布的DL算法完成各种计算。虽然这些API的映射通常不是一对一的，但我们观察到，它们的计算在适当组合和调整后可以相互模拟。这些模拟对手的使用有助于进行差分测试，以检测功能性DL库错误。基于这一见解，我们提出了DLLens，作为一种利用大型语言模型（LLM）合成DL库API有效对手的新机制。为了生成多样化的测试输入，DLLens结合了由LLM辅助的静态分析方法，从每个API及其对手的实现中的所有执行路径中提取路径约束。这些路径约束随后用于指导多样化测试输入的生成。我们在两个流行的DL库TensorFlow和PyTorch上评估了DLLens。我们的评估显示，DLLens能够为这些库中超过两倍于最先进技术发现的API合成对手。此外，DLLens能够提取多26.7%的约束，并且检测到的错误数量是最先进技术的2.5倍。DLLens成功发现了近期TensorFlow和PyTorch库中的56个错误。其中41个是此前未知的，39个在报告后已被开发人员确认，其中19个已被开发人员修复。
- en: I Introduction
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I 引言
- en: Deep learning (DL) has been increasingly adopted for mission-critical applications
    such as authentication [[1](#bib.bib1), [2](#bib.bib2)], medical treatment [[3](#bib.bib3)],
    and autonomous driving [[4](#bib.bib4), [5](#bib.bib5), [6](#bib.bib6)]. Current
    DL applications are mostly developed on top of popular DL libraries such as PyTorch [[7](#bib.bib7)]
    and TensorFlow [[8](#bib.bib8)]. However, the presence of functional incorrectness,
    commonly referred to as functional bugs, in DL libraries poses a significant threat
    to the reliability of these applications [[9](#bib.bib9), [10](#bib.bib10), [11](#bib.bib11)].
    More than 30% of bugs reported to PyTorch developers are categorized as functional
    bugs [[12](#bib.bib12)]. Hence, functional bug detection is critical to assuring
    the quality of DL libraries.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习（DL）越来越被用于关键任务应用，如认证 [[1](#bib.bib1), [2](#bib.bib2)]、医疗治疗 [[3](#bib.bib3)]和自动驾驶 [[4](#bib.bib4),
    [5](#bib.bib5), [6](#bib.bib6)]。当前的DL应用大多建立在流行的DL库之上，如PyTorch [[7](#bib.bib7)]和TensorFlow [[8](#bib.bib8)]。然而，DL库中存在的功能性错误，通常称为功能性漏洞，对这些应用的可靠性构成了重大威胁 [[9](#bib.bib9),
    [10](#bib.bib10), [11](#bib.bib11)]。报告给PyTorch开发者的错误中超过30%被归类为功能性漏洞 [[12](#bib.bib12)]。因此，功能性漏洞检测对保证DL库的质量至关重要。
- en: A functional bug occurs when the library API’s behavior deviates from its specified
    requirements [[13](#bib.bib13)]. Currently, differential testing is commonly adopted [[14](#bib.bib14),
    [15](#bib.bib15), [16](#bib.bib16), [17](#bib.bib17), [18](#bib.bib18)] to detect
    these functional bugs (e.g., the incorrect computation results or intermediate
    states [[12](#bib.bib12)]). A general workflow of existing differential testing
    techniques for DL libraries is to (1) collect the different implementations that
    offer the same functionality in/across DL libraries, and (2) apply test inputs
    to detect output inconsistency. However, existing works are limited in both steps,
    which may hinder their effectiveness in bug detection.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 功能性漏洞发生在库API的行为偏离其规定要求时 [[13](#bib.bib13)]。目前，差异测试是常用的检测这些功能性漏洞的方法 [[14](#bib.bib14),
    [15](#bib.bib15), [16](#bib.bib16), [17](#bib.bib17), [18](#bib.bib18)]（例如，错误的计算结果或中间状态 [[12](#bib.bib12)]）。现有差异测试技术的一般工作流程是（1）收集提供相同功能的不同实现，并（2）应用测试输入以检测输出不一致。然而，现有工作在这两个步骤上都有所限制，这可能会影响其在漏洞检测中的有效性。
- en: '(1) Ineffectiveness in finding counterparts for differential testing. Two paradigms
    are proposed to find counterparts of DL library APIs for differential testing.
    The first one [[14](#bib.bib14), [15](#bib.bib15), [16](#bib.bib16), [17](#bib.bib17),
    [18](#bib.bib18)] takes advantage of model conversion libraries (e.g., TF2ONNX [[19](#bib.bib19)]),
    which support the conversion of DL models between libraries. However, the effectiveness
    of this line of research is limited by the insufficient API coverage of conversion
    libraries. Take TF2ONNX [[19](#bib.bib19)] as an example, it only supports the
    conversion of 8% (279/3,316) TensorFlow APIs [[18](#bib.bib18)], leaving 90%+
    of TensorFlow APIs uncovered. Another paradigm takes advantage of different computational
    modes, such as backends [[20](#bib.bib20), [21](#bib.bib21), [22](#bib.bib22)]
    (e.g., CPU and GPU), execution modes [[23](#bib.bib23)] (e.g., different gradient
    calculation modes), and similar APIs [[24](#bib.bib24)] (e.g., tf.argmax and tf.math.argmax)
    in one library. Similar APIs or executions of an API under these different computational
    modes could also serve as counterparts of each other. However, these counterparts
    often have nearly identical implementations, limiting their effectiveness for
    differential testing. Listing [1](#S1.F1 "Figure 1 ‣ I Introduction ‣ DLLens:
    Testing Deep Learning Libraries via LLM-aided Synthesis") shows a real functional
    bug that cannot be triggered by either of the existing paradigms, since none of
    the conversion libraries support the API (tf.math.is_non_decreasing), and the
    concerned computational modes deliver consistent outputs [[25](#bib.bib25)].'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '(1) 在寻找差异测试的对等项时的无效性。提出了两种范式来寻找深度学习库 API 的对等项进行差异测试。第一种范式[[14](#bib.bib14),
    [15](#bib.bib15), [16](#bib.bib16), [17](#bib.bib17), [18](#bib.bib18)] 利用模型转换库（例如
    TF2ONNX [[19](#bib.bib19)]），支持在库之间转换深度学习模型。然而，这一研究方向的有效性受到转换库 API 覆盖不足的限制。以 TF2ONNX
    [[19](#bib.bib19)] 为例，它仅支持 8%（279/3,316）的 TensorFlow API [[18](#bib.bib18)]，留下
    90%+ 的 TensorFlow API 没有覆盖。另一种范式利用不同的计算模式，如后端 [[20](#bib.bib20), [21](#bib.bib21),
    [22](#bib.bib22)]（例如 CPU 和 GPU）、执行模式 [[23](#bib.bib23)]（例如，不同的梯度计算模式）和类似的 API
    [[24](#bib.bib24)]（例如，tf.argmax 和 tf.math.argmax）在一个库中。这些不同计算模式下的类似 API 或 API
    的执行也可以作为彼此的对等项。然而，这些对等项往往具有几乎相同的实现，限制了它们在差异测试中的有效性。列出[1](#S1.F1 "图 1 ‣ I 引言 ‣
    DLLens: 通过 LLM 辅助合成测试深度学习库") 显示了一个实际的功能错误，现有的范式无法触发，因为没有转换库支持该 API（tf.math.is_non_decreasing），而相关计算模式提供了一致的输出
    [[25](#bib.bib25)]。'
- en: 12|\underline{\textbf{Bug  Triggering  Input}}|:3x  =  tf.constant([10,9],  dtype=’uint32’)4|\underline{\textbf{Buggy  API}}|:5tf.math.is_non_decreasing6|\underline{\textbf{Actual  Result  (Expected  Result)}}|:7|\textbf{\textcolor{bgRed}{True}}|  (|\textbf{\textcolor{bgGreen}{False}}|)8|\underline{\textbf{Developer’s  Fix}}|:9|\textbf{\textcolor{bgRed}{-  diff  =  \_get\_diff\_for\_monotonic\_comparison(x)}}|10|\textbf{\textcolor{bgRed}{-  zero  =  ops.convert\_to\_tensor(0,  dtype=diff.dtype)}}|11|\textbf{\textcolor{bgRed}{-  return  math\_ops.reduce\_all(math\_ops.less\_equal(zero,  diff))}}|12|\textbf{\textcolor{bgGreen}{+  diff  =  \_get\_results\_for\_monotonic\_comparison(x,  greater\_equal)}}|13|\textbf{\textcolor{bgGreen}{+  return  math\_ops.reduce\_all(diff)}}|’
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 12|\underline{\textbf{Bug  触发输入}}|:3x  =  tf.constant([10,9],  dtype=’uint32’)4|\underline{\textbf{有问题的  API}}|:5tf.math.is_non_decreasing6|\underline{\textbf{实际结果  （预期结果）}}|:7|\textbf{\textcolor{bgRed}{True}}|  (|\textbf{\textcolor{bgGreen}{False}}|)8|\underline{\textbf{开发者的  修复}}|:9|\textbf{\textcolor{bgRed}{-  diff  =  \_get\_diff\_for\_monotonic\_comparison(x)}}|10|\textbf{\textcolor{bgRed}{-  zero  =  ops.convert\_to\_tensor(0,  dtype=diff.dtype)}}|11|\textbf{\textcolor{bgRed}{-  return  math\_ops.reduce\_all(math\_ops.less\_equal(zero,  diff))}}|12|\textbf{\textcolor{bgGreen}{+  diff  =  \_get\_results\_for\_monotonic\_comparison(x,  greater\_equal)}}|13|\textbf{\textcolor{bgGreen}{+  return  math\_ops.reduce\_all(diff)}}|’
- en: 'Figure 1: A real bug detected by our tool that leads to incorrect computation
    result.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：我们的工具检测到的一个实际错误，导致计算结果不正确。
- en: '(2) Ineffectiveness in generating diverse test inputs. Another major cause
    is the ineffectiveness of generating test inputs that induce inconsistent outputs
    across different implementations. Existing DL library testing approaches commonly
    generate test inputs towards covering more APIs/statements/branches [[21](#bib.bib21),
    [17](#bib.bib17), [26](#bib.bib26)]. However, generating test inputs to trigger
    bugs inside these buggy APIs/statements/branches may be more complicated. Take
    Listing [2](#S1.F2 "Figure 2 ‣ I Introduction ‣ DLLens: Testing Deep Learning
    Libraries via LLM-aided Synthesis") as an example, the buggy line (line 6) leads
    to an integer overflow [[27](#bib.bib27)]. The bug can only be triggered when
    satisfying the following two conditions: (1) (delta ¿ 0 && start ¿ limit)——delta
    ¡ 0 && start ¡ limit, and (2) limit is a large negative integer && start is a
    large positive integer. Indeed, coverage-guided approaches could generate inputs
    that satisfy condition (1), yet fail to explore different values of start and
    limit to meet condition 2. In other words, these approaches are ineffective in
    exploring inconsistency-inducing test inputs along the execution paths that contain
    faulty statements.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '(2) 生成多样化测试输入的低效性。另一个主要原因是生成测试输入的低效性，这些输入会在不同实现之间引发不一致的输出。现有的深度学习库测试方法通常生成测试输入，以覆盖更多的
    API/语句/分支 [[21](#bib.bib21), [17](#bib.bib17), [26](#bib.bib26)]。然而，生成测试输入以触发这些有缺陷的
    API/语句/分支中的错误可能更为复杂。以列表 [2](#S1.F2 "Figure 2 ‣ I Introduction ‣ DLLens: Testing
    Deep Learning Libraries via LLM-aided Synthesis") 为例，有缺陷的行（第 6 行）导致整数溢出 [[27](#bib.bib27)]。该错误只能在满足以下两个条件时触发：（1）(delta
    ¿ 0 && start ¿ limit)——delta ¡ 0 && start ¡ limit，和（2）limit 是一个大负整数 && start 是一个大正整数。实际上，覆盖引导的方法可以生成满足条件（1）的输入，但未能探索
    start 和 limit 的不同值以满足条件 2。换句话说，这些方法在探索包含错误语句的执行路径上引发不一致的测试输入方面是无效的。'
- en: '12|\underline{\textbf{Buggy  Code}}|3...41:  if  (delta  >  0)  {52:  //  Error  if  start  <=  limit63:  }  else  {74:  //  Error  if  start  >=  limit85:  }9...106:  Eigen::numext::ceil(Eigen::numext::abs(|\textbf{\textcolor{bgRed}{(limit  -  start)  /  delta}}|));  //  |\textcolor{bgRed}{\textbf{Buggy  Line}}|11|\underline{\textbf{Our  Proposed  Fix  Confirmed  By  a  Developer}}|126:  Eigen::numext::ceil(Eigen::numext::abs(|\textbf{\textcolor{bgGreen}{limit  /  delta  -  start  /  delta}}|));'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '12|\underline{\textbf{有缺陷的代码}}|3...41:  if  (delta  >  0)  {52:  //  错误  如果  start  <=  limit63:  }  else  {74:  //  错误  如果  start  >=  limit85:  }9...106:  Eigen::numext::ceil(Eigen::numext::abs(|\textbf{\textcolor{bgRed}{(limit  -  start)  /  delta}}|));  //  |\textcolor{bgRed}{\textbf{有缺陷的行}}|11|\underline{\textbf{我们提出的修复，开发者确认}}|126:  Eigen::numext::ceil(Eigen::numext::abs(|\textbf{\textcolor{bgGreen}{limit  /  delta  -  start  /  delta}}|));'
- en: 'Figure 2: A real bug detected by DLLens. It requires a specific value to trigger.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '图 2: DLLens 检测到的真实错误。它需要一个特定的值才能触发。'
- en: 'Solution. In this paper, we propose DLLens, a novel differential testing technique
    for DL library API testing. DLLens can 1) effectively find counterparts for DL
    library APIs, and 2) generate diverse inputs to explore execution paths extracted
    from implementations of DL library APIs and their counterparts. We observe that
    APIs are commonly designed to accomplish various computations for the same set
    of published DL algorithms. Although the mapping of these APIs is not often one-to-one,
    we observe that their computations can be simulated mutually after proper composition
    and adaptation. Based on this insight, DLLens synthesizes for each DL library
    API a function, referred to as the API’s counterpart, by leveraging a large language
    model (LLM). The counterpart simulates the API’s computation by composing and
    adapting various APIs from a different library. To generate diverse inputs, DLLens
    incorporates a novel static analysis method to extract path constraints for each
    execution path in the implementations of the API and its counterpart. Our static
    analysis method leverages an LLM to extract solvable path constraints from execution
    paths that involve external functions with unknown behaviors to existing solvers.
    Finally, DLLens applies a test input generation method based on the path constraints
    extracted from the implementation of both the concerned API and its counterpart,
    differential testing is further applied by checking output inconsistency between
    the API and its counterpart for bug detection. Taking the bug in Listing [1](#S1.F1
    "Figure 1 ‣ I Introduction ‣ DLLens: Testing Deep Learning Libraries via LLM-aided
    Synthesis") as an example, the buggy API is designed to check if a given tensor
    is following the non-decreasing order (i.e., for tensor $[x[0],...],x[i]\leq x[i+1]$),
    which is a commonly DL functionality [[28](#bib.bib28)]. DLLens detected this
    bug by synthesizing its counterpart, which is a function built on top of PyTorch
    APIs (see Listing [3](#S1.F3 "Figure 3 ‣ I Introduction ‣ DLLens: Testing Deep
    Learning Libraries via LLM-aided Synthesis")), and generating a diverse test input
    that can expose this bug.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案。在本文中，我们提出了DLLens，一种用于DL库API测试的新型差分测试技术。DLLens可以 1) 有效地为DL库API找到对应的API，并且
    2) 生成多样的输入来探索从DL库API及其对应API的实现中提取的执行路径。我们观察到，API通常被设计成完成相同发布的DL算法的一系列不同计算。虽然这些API的映射通常不是一一对应的，但我们观察到，它们的计算可以在适当的组合和适配后相互模拟。基于这一见解，DLLens通过利用大型语言模型（LLM）为每个DL库API合成一个函数，称为API的对应函数。对应函数通过组合和适配来自不同库的各种API来模拟API的计算。为了生成多样的输入，DLLens结合了一种新颖的静态分析方法，从API及其对应函数的实现中提取路径约束。我们的静态分析方法利用LLM从涉及外部函数的执行路径中提取可解路径约束，这些外部函数的行为对现有求解器来说是未知的。最后，DLLens应用了一种基于从API及其对应函数的实现中提取的路径约束的测试输入生成方法，进一步通过检查API与其对应函数之间的输出不一致来进行差分测试，以检测错误。以清单[1](#S1.F1
    "图1 ‣ 引言 ‣ DLLens：通过LLM辅助合成测试深度学习库")中的错误为例，出现问题的API设计用于检查给定张量是否遵循非递减顺序（即，对于张量
    $[x[0],...],x[i]\leq x[i+1]$），这是常见的DL功能[[28](#bib.bib28)]。DLLens通过合成其对应函数检测到该错误，对应函数是基于PyTorch
    API构建的（见清单[3](#S1.F3 "图3 ‣ 引言 ‣ DLLens：通过LLM辅助合成测试深度学习库")），并生成了能够暴露该错误的多样化测试输入。
- en: 12|\underline{\textbf{TensorFlow  API}}|3tf.math.is_non_decreasing(x)4|\underline{\textbf{Function  Using  PyTorch’s  APIs}}|5def  pytorch_call(x):6return  torch.all(torch.eq(x,  torch.sort(x)[0]))’
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 12|\underline{\textbf{TensorFlow API}}|3tf.math.is_non_decreasing(x)4|\underline{\textbf{使用PyTorch
    API的函数}}|5def pytorch_call(x):6return torch.all(torch.eq(x, torch.sort(x)[0]))
- en: 'Figure 3: A function using PyTorch’s APIs can implement the specified computation
    of tf.math.is_non_decreasing.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：使用PyTorch的API可以实现tf.math.is_non_decreasing的指定计算。
- en: 'We evaluate the effectiveness of DLLens on two popular DL libraries: TensorFlow [[8](#bib.bib8)]
    and PyTorch [[7](#bib.bib7)]. We compare DLLens against existing DL library testing
    techniques on the effectiveness of counterpart synthesis, path constraint extraction,
    code coverage, and bug detection. The evaluation results show that DLLens’s counterpart
    synthesis method can double the number of API counterparts (e.g., 739 v.s. 304
    for TensorFlow APIs) collected by the existing work [[18](#bib.bib18)] that relies
    on developer-constructed rules. On average, DLLens can extract 21.5 and 41.87
    path constraints for each TensorFlow API and PyTorch API, respectively. Our experiment
    on 200 sampled APIs shows that DLLens can cover at least 3.2% branches and detect
    at least 2.5 times as many bugs as the state-of-the-art techniques. In total,
    DLLens detected 56bugs inside TensorFlow and PyTorch, including 15bugs already
    fixed or confirmed by developers and 41new bugs. So far, 39of our reported new
    bugs have been confirmed by developers, including 19 fixed and 2 reported bugs
    pending confirmation.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在两个流行的DL库：TensorFlow[[8](#bib.bib8)]和PyTorch[[7](#bib.bib7)]上评估了DLLens的有效性。我们将DLLens与现有的DL库测试技术进行了比较，涵盖了对等体合成、路径约束提取、代码覆盖率和错误检测。评估结果表明，DLLens的对等体合成方法可以使API对等体的数量增加一倍（*例如*，TensorFlow
    API的739对比304对）。平均而言，DLLens可以为每个TensorFlow API和PyTorch API提取21.5和41.87个路径约束。我们对200个采样API的实验表明，DLLens能够覆盖至少3.2%的分支，并检测到至少2.5倍于最先进技术的错误。总的来说，DLLens在TensorFlow和PyTorch中检测到56个错误，其中15个已被开发者修复或确认，41个是新的错误。目前，我们报告的39个新错误中，19个已经被开发者修复，2个报告的错误仍待确认。
- en: 'This work makes the following contributions:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究作出了以下贡献：
- en: •
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We propose DLLens, a novel DL library testing tool that can effectively synthesize
    API counterparts and extract path constraints for diverse test input generation.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了DLLens，一种新型的DL库测试工具，可以有效地合成API对等体并提取路径约束，以生成多样化的测试输入。
- en: •
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: DLLens presents a new approach to counterpart synthesis using LLMs, alleviating
    the test oracle problems for the testing of DL library APIs.
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: DLLens提出了一种使用LLMs进行对等体合成的新方法，缓解了DL库API测试中的测试oracle问题。
- en: •
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: This paper proposes a novel path constraint extraction method that incorporates
    static analysis with LLMs to effectively extract path constraints inside DL libraries.
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本文提出了一种新型路径约束提取方法，将静态分析与LLMs相结合，以有效提取DL库中的路径约束。
- en: •
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We applied DLLens to two popular DL libraries, TensorFlow and PyTorch. DLLens
    successfully detected 56bugs. Most (41) are new bugs, and 39of them have been
    confirmed by developers after being reported. So far, 19 of our reported new bugs
    have been fixed by developers.
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将DLLens应用于两个流行的DL库，TensorFlow和PyTorch。DLLens成功检测到56个错误。其中大多数（41个）是新错误，39个已被开发者在报告后确认。目前，19个我们报告的新错误已经被开发者修复。
- en: II Motivation and Related Works
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 动机与相关工作
- en: II-A DL Library Testing
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-A DL库测试
- en: Existing testing approaches for DL libraries focus on either the model level
    or API level. The former [[14](#bib.bib14), [29](#bib.bib29), [15](#bib.bib15),
    [26](#bib.bib26), [16](#bib.bib16), [17](#bib.bib17)] takes various DL models
    as test inputs and tries to exercise specific modules (*e.g.*, model construction,
    model training, and inference) in DL libraries. However, a recent study has revealed
    that these model-level testing approaches are ineffective in test adequacy [[20](#bib.bib20)].
    One potential explanation is that these approaches can operate on and manipulate
    only layer APIs within DL libraries, leaving the majority of library APIs unexplored.
    Particularly, these model-level testing approaches can cover at most 2.4% of the
    total deep learning library APIs, as reported by previous studies [[20](#bib.bib20),
    [21](#bib.bib21)].
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的DL库测试方法主要关注模型层级或API层级。前者[[14](#bib.bib14), [29](#bib.bib29), [15](#bib.bib15),
    [26](#bib.bib26), [16](#bib.bib16), [17](#bib.bib17)]以各种DL模型作为测试输入，试图在DL库中测试特定模块（*例如*，模型构建、模型训练和推理）。然而，最近的研究揭示这些模型层级的测试方法在测试充分性方面效果不佳[[20](#bib.bib20)]。一个可能的解释是，这些方法只能操作和操控DL库中的层级API，导致大多数库API未被探索。特别地，这些模型层级的测试方法最多只能覆盖2.4%的深度学习库API，正如之前的研究所报告的[[20](#bib.bib20),
    [21](#bib.bib21)]。
- en: API-level testing, which improves the coverage of DL library APIs by directly
    executing them, provides an alternative approach to testing DL libraries. Several
    approaches [[20](#bib.bib20), [30](#bib.bib30), [31](#bib.bib31)] have been introduced
    to generate input arguments (i.e., test inputs) to test these APIs. These approaches
    employ various strategies, including collecting input arguments from open source
    projects [[20](#bib.bib20)], extracting constraints from documentation [[30](#bib.bib30)],
    and utilizing API’s input validation code [[31](#bib.bib31)]. More recently, TitanFuzz [[21](#bib.bib21)]
    and FuzzGPT [[32](#bib.bib32)] leverage large language models (LLMs) like ChatGPT
    for generating input arguments for DL library APIs. These approaches demonstrate
    the feasibility of providing examples and instructions to LLMs, allowing them
    to generate input arguments.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: API 级别的测试，通过直接执行 DL 库的 API，提高了测试的覆盖率，提供了一种测试 DL 库的替代方法。已经引入了几种方法 [[20](#bib.bib20),
    [30](#bib.bib30), [31](#bib.bib31)] 来生成输入参数（即测试输入）以测试这些 API。这些方法采用了各种策略，包括从开源项目中收集输入参数 [[20](#bib.bib20)]、从文档中提取约束条件 [[30](#bib.bib30)]，以及利用
    API 的输入验证代码 [[31](#bib.bib31)]。最近，TitanFuzz [[21](#bib.bib21)] 和 FuzzGPT [[32](#bib.bib32)]
    利用像 ChatGPT 这样的语言模型（LLMs）生成 DL 库 API 的输入参数。这些方法展示了向 LLM 提供示例和指令的可行性，从而使其能够生成输入参数。
- en: II-B Functional Bug Detection In DL Libraries
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-B 在 DL 库中的功能性错误检测
- en: 'Existing approaches, as mentioned in Section [II-A](#S2.SS1 "II-A DL Library
    Testing ‣ II Motivation and Related Works ‣ DLLens: Testing Deep Learning Libraries
    via LLM-aided Synthesis"), mostly adopt differential testing to check output consistency
    across implementations offering the same functionality to detect functional bugs
    in DL libraries. There are two widely used paradigms to find implementations offering
    the same functionality. The first paradigm [[14](#bib.bib14), [18](#bib.bib18)]
    leverages model conversion tools such as TF2ONNX [[19](#bib.bib19)] to compare
    outputs across multiple DL libraries. For instance, given a DL library API, TensorScope [[18](#bib.bib18)],
    parsed the conversion rules in TF2ONNX [[19](#bib.bib19)] to extract the counterpart
    of this API, which is implemented in another DL library. However, existing model
    conversion tools can only support counterparts for a limited number of DL library
    APIs. For example, TF2ONNX [[19](#bib.bib19)] only supports counterparts for only
    279 out of 3,316 TensorFlow APIs. Since the counterparts of many DL library APIs
    cannot be found in existing model conversion tools, functional bugs inside these
    DL library APIs may be missed (e.g., the bug in Listing [1](#S1.F1 "Figure 1 ‣
    I Introduction ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis"))'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '现有的方法，如在第 [II-A](#S2.SS1 "II-A DL Library Testing ‣ II Motivation and Related
    Works ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis") 节中提到的，大多采用差异测试来检查实现之间的输出一致性，以检测
    DL 库中的功能性错误。有两种广泛使用的范式来寻找提供相同功能的实现。第一个范式 [[14](#bib.bib14), [18](#bib.bib18)]
    利用模型转换工具，如 TF2ONNX [[19](#bib.bib19)] 来比较多个 DL 库之间的输出。例如，给定一个 DL 库 API，TensorScope [[18](#bib.bib18)]
    解析了 TF2ONNX [[19](#bib.bib19)] 中的转换规则，以提取该 API 在另一个 DL 库中实现的对应部分。然而，现有的模型转换工具仅支持有限数量的
    DL 库 API 的对应部分。例如，TF2ONNX [[19](#bib.bib19)] 仅支持 3,316 个 TensorFlow API 中的 279
    个对应部分。由于许多 DL 库 API 的对应部分在现有模型转换工具中无法找到，因此这些 DL 库 API 中的功能性错误可能被遗漏（例如，第 [1](#S1.F1
    "Figure 1 ‣ I Introduction ‣ DLLens: Testing Deep Learning Libraries via LLM-aided
    Synthesis") 个列表中的错误）。'
- en: 'The second paradigm applies differential testing by comparing computation results
    of implementations within a single DL libraries. For instance, several works [[20](#bib.bib20),
    [23](#bib.bib23), [22](#bib.bib22), [21](#bib.bib21), [32](#bib.bib32)] detect
    functional bugs via checking if an API can have consistent outputs under different
    computation modes, such as backends (e.g., CPU and GPU), precision (e.g., float32,
    float16), and execution modes (e.g., different gradient calculation modes). Nevertheless,
    these implementations may yield identical computation results, making checking
    result inconsistency for bug detection ineffective. DeepRel [[24](#bib.bib24)]
    mined multiple groups of similar APIs within the same DL libraries based on API
    signature and document similarity. As for the similar APIs found by DeepRel, existing
    work [[18](#bib.bib18)] reveals that many of these APIs serve as callers, callees,
    or aliases of other APIs within the same group. For instance, tf.argmax and tf.math.argmax
    found by DeepReal are indeed aliases, suggesting that they are likely to have
    the same outputs. Indeed, when applying these differential testing strategies
    on one of our detected bugs (i.e., List [1](#S1.F1 "Figure 1 ‣ I Introduction
    ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis")), we find
    that the buggy API has consistent output under different computation modes. Besides,
    this buggy API’s similar APIs detected by DeepRel produced identical output as
    the buggy API’s. Thus these approaches fail to detect this bug.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '第二种范式通过比较单一深度学习库中实现的计算结果来应用差异化测试。例如，若干研究[[20](#bib.bib20), [23](#bib.bib23),
    [22](#bib.bib22), [21](#bib.bib21), [32](#bib.bib32)]通过检查一个API在不同计算模式下是否能保持一致的输出（例如，后端（如CPU和GPU）、精度（如float32,
    float16）、执行模式（如不同的梯度计算模式））来检测功能性错误。然而，这些实现可能产生相同的计算结果，从而使得通过检查结果不一致来进行错误检测变得无效。DeepRel
    [[24](#bib.bib24)] 基于API签名和文档相似性挖掘了同一深度学习库中多个类似的API。对于DeepRel发现的类似API，现有研究[[18](#bib.bib18)]揭示了这些API中许多作为调用者、被调用者或同一组中其他API的别名。例如，DeepReal发现的tf.argmax和tf.math.argmax实际上是别名，表明它们可能具有相同的输出。确实，当在我们检测到的一个错误上应用这些差异化测试策略（即，List
    [1](#S1.F1 "Figure 1 ‣ I Introduction ‣ DLLens: Testing Deep Learning Libraries
    via LLM-aided Synthesis")），我们发现有错误的API在不同计算模式下输出一致。此外，DeepRel检测到的这个有错误API的类似API也产生了与该有错误API相同的输出。因此，这些方法未能检测到这个错误。'
- en: II-C Constraint Extraction for DL Library Testing
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-C 深度学习库测试的约束提取
- en: Some approaches have proposed constraint extraction strategies [[30](#bib.bib30),
    [31](#bib.bib31), [18](#bib.bib18)] to guide valid/invalid input generation. DocTer [[30](#bib.bib30)]
    collected constraints from DL library documentation and generated inputs that
    follow these constraints (denoted as valid inputs) and inputs violating these
    constraints. TensorScope [[18](#bib.bib18)] parsed the input validation check
    statements to generate valid inputs. However, both TensorScope and DocTer [[30](#bib.bib30)]
    do not provide constraints required by different execution paths inside the implementation
    of a DL library API.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 一些方法提出了约束提取策略[[30](#bib.bib30), [31](#bib.bib31), [18](#bib.bib18)]以指导有效/无效输入的生成。DocTer
    [[30](#bib.bib30)] 从深度学习库文档中收集了约束，并生成符合这些约束的输入（标记为有效输入）和违反这些约束的输入。TensorScope
    [[18](#bib.bib18)] 解析输入验证检查语句以生成有效输入。然而，TensorScope和DocTer [[30](#bib.bib30)]
    都未提供深度学习库API实现内部不同执行路径所需的约束。
- en: ACETest [[31](#bib.bib31)] proposed a static analysis tool that extracted path
    constraints from the validation code inside DL library APIs, so input following
    these path constraints can pass the validation code to reach the core logic inside
    these APIs. However, due to the large size of DL libraries, ACETest [[31](#bib.bib31)]
    could not perform static analysis on the entire code base, leaving some extracted
    path constraints incomplete. Indeed, we observe that many path constraints extracted
    from the source code of DL library APIs contain functions from external libraries
    (e.g., Eigen) or external functions. Path constraints containing these external
    functions may not be solved properly since their behaviors are unknown to existing
    solvers, and their source code are not considered by ACETest in static analysis.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ACETest [[31](#bib.bib31)] 提出了一个静态分析工具，该工具从 DL 库 API 内部的验证代码中提取路径约束，从而使得符合这些路径约束的输入能够通过验证代码，达到这些
    API 内部的核心逻辑。然而，由于 DL 库的庞大规模，ACETest [[31](#bib.bib31)] 无法对整个代码库进行静态分析，导致一些提取的路径约束不完整。确实，我们观察到许多从
    DL 库 API 源代码中提取的路径约束包含来自外部库（例如，Eigen）或外部函数的函数。包含这些外部函数的路径约束可能无法正确求解，因为其行为对现有求解器是未知的，而
    ACETest 在静态分析中未考虑其源代码。
- en: III Methodology
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III 方法论
- en: '![Refer to caption](img/36d03bcb26e0678e3efe386cdbb0cc7d.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/36d03bcb26e0678e3efe386cdbb0cc7d.png)'
- en: 'Figure 4: Workflow of DLLens with three steps: counterpart synthesis (Section [III-A](#S3.SS1
    "III-A Counterpart Synthesis ‣ III Methodology ‣ DLLens: Testing Deep Learning
    Libraries via LLM-aided Synthesis")), path constraint extraction (Section [III-B](#S3.SS2
    "III-B Path Constraint Extraction ‣ III Methodology ‣ DLLens: Testing Deep Learning
    Libraries via LLM-aided Synthesis"), and input generation (Section [III-C](#S3.SS3
    "III-C Test Input Generation and Bug Detection ‣ III Methodology ‣ DLLens: Testing
    Deep Learning Libraries via LLM-aided Synthesis")).'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '图 4: DLLens 的工作流程，包括三个步骤：对应体合成（第 [III-A](#S3.SS1 "III-A Counterpart Synthesis
    ‣ III Methodology ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis)
    节）、路径约束提取（第 [III-B](#S3.SS2 "III-B Path Constraint Extraction ‣ III Methodology
    ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis) 节）和输入生成（第 [III-C](#S3.SS3
    "III-C Test Input Generation and Bug Detection ‣ III Methodology ‣ DLLens: Testing
    Deep Learning Libraries via LLM-aided Synthesis) 节））。'
- en: 'Figure [4](#S3.F4 "Figure 4 ‣ III Methodology ‣ DLLens: Testing Deep Learning
    Libraries via LLM-aided Synthesis") shows the workflow of DLLens, which consists
    of three steps, *i.e.*, (1) Counterpart Synthesis, (2) Path Constraint Extraction,
    and (3) Test Input Generation and Bug Detection. For each DL library API under
    test $f$ on these input arguments for bug detection.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '图 [4](#S3.F4 "Figure 4 ‣ III Methodology ‣ DLLens: Testing Deep Learning Libraries
    via LLM-aided Synthesis") 展示了 DLLens 的工作流程，包括三个步骤，*即*，(1) 对应体合成，(2) 路径约束提取，以及
    (3) 测试输入生成和缺陷检测。对于每个待测的 DL 库 API $f$，在这些输入参数上进行缺陷检测。'
- en: III-A Counterpart Synthesis
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-A 对应体合成
- en: Criterion of counterparts. A counterpart of an API $f$.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 对应体的标准。API $f$ 的一个对应体。
- en: 'To address the above challenges, DLLens adopts a two-phase approach (as shown
    in Figure [4](#S3.F4 "Figure 4 ‣ III Methodology ‣ DLLens: Testing Deep Learning
    Libraries via LLM-aided Synthesis") Step I). For each library API under test $f$.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '为解决上述挑战，DLLens 采用了一个两阶段的方法（如图 [4](#S3.F4 "Figure 4 ‣ III Methodology ‣ DLLens:
    Testing Deep Learning Libraries via LLM-aided Synthesis") 第 I 步所示）。对于每个待测的库 API
    $f$。'
- en: '|  | $\forall x\in\mathcal{X},&#124;f(x)-f^{\prime}(x)&#124;\leq\epsilon$ |  |
    (1) |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '|  | $\forall x\in\mathcal{X},\lvert f(x)-f^{\prime}(x) \rvert\leq\epsilon$
    |  | (1) |'
- en: where $\epsilon$ is a small positive value (e.g., 0.1). In the following, let
    us visit the two phases in more detail.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\epsilon$ 是一个小的正值（例如，0.1）。接下来，让我们更详细地探讨这两个阶段。
- en: III-A1 Valid Input Generation
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A1 有效输入生成
- en: 'DLLens adapts the direct prompting strategy proposed by TitanFuzz [[21](#bib.bib21)]
    and asks the LLM to generate valid inputs for each DL library API. More specifically,
    the prompt includes the target library (e.g., TensorFlow) and the API signature,
    it further describes the task of valid input generation using a step-by-step instruction
    (see Listing [5](#S3.F5 "Figure 5 ‣ III-A1 Valid Input Generation ‣ III-A Counterpart
    Synthesis ‣ III Methodology ‣ DLLens: Testing Deep Learning Libraries via LLM-aided
    Synthesis")). However, such direct prompting may not generate valid inputs satisfying
    the input constraint required by the DL library API. For instance, the LLM (i.e.,
    gpt-turbo-3.5) fails to generate input argument image that satisfies the required
    shape constraint of tf.image.pad_to_bounding, resulting in no valid inputs found
    for this API.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 'DLLens 采用了 TitanFuzz 提出的直接提示策略 [[21](#bib.bib21)]，并要求 LLM 为每个 DL 库 API 生成有效的输入。更具体地说，提示包括目标库（例如，TensorFlow）和
    API 签名，并进一步描述了使用逐步指令生成有效输入的任务（参见清单 [5](#S3.F5 "图 5 ‣ III-A1 有效输入生成 ‣ III-A 对应物合成
    ‣ III 方法论 ‣ DLLens: 通过 LLM 辅助合成测试深度学习库")）。然而，这种直接提示可能无法生成满足 DL 库 API 输入约束的有效输入。例如，LLM（即
    gpt-turbo-3.5）未能生成满足 tf.image.pad_to_bounding 所需形状约束的输入参数 image，导致该 API 找不到有效输入。'
- en: 'To improve the performance of direct prompting in generating valid API inputs,
    DLLens dynamically executes each generated input with the API and back prompts
    the LLM with the error message for repair. The intuition is that DL libraries
    commonly raise meaningful invalid argument error messages [[18](#bib.bib18)] when
    receiving an invalid input, which can provide useful repair guidance. Listing [5](#S3.F5
    "Figure 5 ‣ III-A1 Valid Input Generation ‣ III-A Counterpart Synthesis ‣ III
    Methodology ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis")
    exemplifies the input generation workflow. While the LLM initially generates an
    invalid input, it successfully generates a valid one after back prompting using
    the error message.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '为了提高直接提示生成有效 API 输入的性能，DLLens 动态执行每个生成的输入与 API，并将错误信息反馈给 LLM 进行修复。直觉是，DL 库在接收到无效输入时通常会引发有意义的无效参数错误信息 [[18](#bib.bib18)]，这些信息可以提供有用的修复指导。清单 [5](#S3.F5
    "图 5 ‣ III-A1 有效输入生成 ‣ III-A 对应物合成 ‣ III 方法论 ‣ DLLens: 通过 LLM 辅助合成测试深度学习库") 例示了输入生成工作流。虽然
    LLM 最初生成了无效输入，但在使用错误信息进行反馈提示后，它成功地生成了有效的输入。'
- en: 'Since APIs across DL libraries are built to implement the different parts of
    the same set of published deep learning computations, the search space of APIs
    relevant to the computation intended by $f$ is limited. So, a few valid inputs
    can effectively identify the appropriate choice of APIs for the counterpart synthesis.
    For a given API, DLLens obtains multiple (i.e., three) inputs from the LLM and
    guides the LLM to repair the invalid ones. If no valid inputs can be obtained
    for an API, DLLens skips the testing of this API because no counterpart can be
    reliably synthesized under equation [1](#S3.E1 "Equation 1 ‣ III-A Counterpart
    Synthesis ‣ III Methodology ‣ DLLens: Testing Deep Learning Libraries via LLM-aided
    Synthesis").'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '由于不同 DL 库的 API 被构建用于实现相同已发布深度学习计算的不同部分，与计算 $f$ 相关的 API 搜索空间是有限的。因此，少量有效输入可以有效地识别用于对应物合成的适当
    API 选择。对于给定的 API，DLLens 从 LLM 获得多个（即，三个）输入，并指导 LLM 修复无效的输入。如果无法为 API 获取有效输入，DLLens
    将跳过该 API 的测试，因为在方程 [1](#S3.E1 "方程 1 ‣ III-A 对应物合成 ‣ III 方法论 ‣ DLLens: 通过 LLM 辅助合成测试深度学习库")
    下无法可靠地合成对应物。'
- en: '12|\underline{\textbf{Prompt}}|:3Task  1:  Import  TensorFlow  2.10.04Task  2:  Generate  valid  parameter  ...5Task  3:  Call  the  function:  tf.image.pad_to_bounding_box(image,  ...)6|\underline{\textbf{LLM}}:|7image=tf.constant([[1,2],[3,4]],dtype=tf.float32)  |\textbf{\textcolor{bgRed}{(this  input  is  invalid!)}}|8|\underline{\textbf{Follow-up  Prompt}}|:9[Error  Message]10’image’  (shape(2,2))  must  have  3  or  4  dimensions.11|\underline{\textbf{LLM}}|:  Here  is  the  repaired  input12image=tf.constant([[[1,2],[3,4]]],dtype=tf.float32)  |\textbf{\textcolor{bgGreen}{(the  repaired  input  is  valid.)}}|'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '12|\underline{\textbf{提示}}|:3任务  1:  导入  TensorFlow  2.10.04任务  2:  生成  有效  参数  ...5任务  3:  调用  函数:  tf.image.pad_to_bounding_box(image,  ...)6|\underline{\textbf{LLM}}:|7image=tf.constant([[1,2],[3,4]],dtype=tf.float32)  |\textbf{\textcolor{bgRed}{(该输入无效！)}}|8|\underline{\textbf{后续提示}}|:9[错误信息]10‘image’  (shape(2,2))  必须  具有  3  或  4  个维度。11|\underline{\textbf{LLM}}|:  这是  修正后的  输入12image=tf.constant([[[1,2],[3,4]]],dtype=tf.float32)  |\textbf{\textcolor{bgGreen}{(修正后的输入有效。)}}|'
- en: 'Figure 5: Example Prompt for Valid Input Generation.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：有效输入生成的示例提示。
- en: III-A2 Counterpart Synthesis and Validation
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A2 对应函数的合成与验证
- en: 'With the API under test $f$, in this stage, DLLens aims to synthesize a counterpart.
    One challenge in the counterpart synthesis lies in the alignment of the signatures
    and usage contexts between an API and the counterparts thus synthesized. For instance,
    the same functionality is provided by tf.keras.metrics.mean_squared_error and
    torch.nn.MSELoss APIs, but they have different signatures and usage contexts.
    Specifically, the former supports direct function calls, whereas the latter requires
    an object construction before processing the input. As a result, they cannot accept
    the same input. To address this alignment problem, DLLens includes valid inputs
    into the prompt that guides the LLM to synthesize functions with the same signature
    and usage context as the given API, as shown in [Figure 6](#S3.F6 "In III-A2 Counterpart
    Synthesis and Validation ‣ III-A Counterpart Synthesis ‣ III Methodology ‣ DLLens:
    Testing Deep Learning Libraries via LLM-aided Synthesis").'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '在本阶段，测试中的 API $f$，DLLens 旨在合成一个对应函数。对应函数合成中的一个挑战在于 API 和合成的对应函数之间的签名和使用上下文的对齐。例如，tf.keras.metrics.mean_squared_error
    和 torch.nn.MSELoss APIs 提供相同的功能，但它们具有不同的签名和使用上下文。具体来说，前者支持直接调用函数，而后者需要在处理输入之前进行对象构造。因此，它们不能接受相同的输入。为了解决这个对齐问题，DLLens
    将有效输入包含在提示中，指导 LLM 合成具有与给定 API 相同签名和使用上下文的函数，如 [图 6](#S3.F6 "在 III-A2 对应函数的合成与验证
    ‣ III-A 对应函数的合成 ‣ III 方法论 ‣ DLLens: 通过 LLM 辅助合成测试深度学习库") 所示。'
- en: 'Listing [6](#S3.F6 "Figure 6 ‣ III-A2 Counterpart Synthesis and Validation
    ‣ III-A Counterpart Synthesis ‣ III Methodology ‣ DLLens: Testing Deep Learning
    Libraries via LLM-aided Synthesis") illustrates the synthesis of a counterpart
    for API tf.scatter_nd. By providing valid inputs and the API’s signature, DLLens
    instructs the LLM to search for an equivalent function. DLLens explicitly asks
    the LLM to synthesize a function using the APIs from a different DL library (e.g.,
    PyTorch). The rationale behind this is to prevent the LLM from searching for the
    given API’s caller, callee, or alias within the same DL library. If a synthesized
    function is invalid, i.e., unable to process valid inputs, DLLens feeds the error
    message to LLM for repair. Like the input generation workflow, DLLens synthesizes
    multiple counterpart candidates for a given API. A counterpart is successfully
    synthesized if it satisfies the output consistency criterion mentioned above.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '列表 [6](#S3.F6 "图 6 ‣ III-A2 对应函数的合成与验证 ‣ III-A 对应函数的合成 ‣ III 方法论 ‣ DLLens:
    通过 LLM 辅助合成测试深度学习库") 说明了如何为 API tf.scatter_nd 合成对应函数。通过提供有效的输入和 API 的签名，DLLens
    指示 LLM 寻找等效函数。DLLens 明确要求 LLM 使用来自不同深度学习库（例如 PyTorch）的 API 合成一个函数。这样做的目的是防止 LLM
    在同一深度学习库内查找给定 API 的调用者、被调用者或别名。如果合成的函数无效，即无法处理有效输入，DLLens 会将错误信息反馈给 LLM 进行修复。与输入生成工作流类似，DLLens
    为给定 API 合成多个对应函数候选。如果一个对应函数满足上述输出一致性标准，则认为它成功合成。'
- en: 12|\underline{\textbf{Prompt}}|:3Given  these  inputs,  generate  a  function  using  PyTorch  APIs  that  can  perform  the  same  functionality  as  the  given  TensorFlow  API.4|\textit{[Input  Set]}|5indices  =  tf.constant([[0],  [2]])...6|\textit{[TensorFlow  API]}|7tf.scatter_nd(indices,updates,shape,name=None)8|\textit{[Function  using  PyTorch  APIs]}|9def  pytorch_call(indices,updates,shape):10|\underline{\textbf{LLM}}:|11def  pytorch_call(indices,updates,shape):12...13tensor_shape=torch.Size(shape)14output_tensor=torch.zeros(tensor_shape)15|\textbf{\textcolor{bgRed}{output\_tensor.scatter\_(0,  tensor\_indices,tensor\_updates)}}|  |\textbf{\textcolor{bgRed}{(this  line  is  buggy!)}}|16return  output_tensor17|\underline{\textbf{Follow-up  Prompt}}|:18[Error  Message]19|\underline{Index}|  tensor  must  have  the  same  number  of  dimentions20as  |\underline{self}|  tensor...21|\underline{\textbf{LLM}}|:22def  pytorch_call(...):23...24|\textbf{\textcolor{bgGreen}{output\_tensor.scatter\_(dim=0,  index=tensor\_indices.squeeze(),  src=tensor\_updates)}}|  |\textbf{\textcolor{bgGreen}{(the  repaired  line  is  correct)}}|25return  output_tensor
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 12|\underline{\textbf{提示}}|:3给定这些输入，使用 PyTorch API 生成一个可以执行与给定 TensorFlow API
    相同功能的函数。4|\textit{[输入集]}|5indices = tf.constant([[0], [2]])...6|\textit{[TensorFlow
    API]}|7tf.scatter_nd(indices, updates, shape, name=None)8|\textit{[使用 PyTorch
    API 的函数]}|9def pytorch_call(indices, updates, shape):10|\underline{\textbf{LLM}}:|11def
    pytorch_call(indices, updates, shape):12...13tensor_shape = torch.Size(shape)14output_tensor
    = torch.zeros(tensor_shape)15|\textbf{\textcolor{bgRed}{output_tensor.scatter_(0,
    tensor_indices, tensor_updates)}}|  |\textbf{\textcolor{bgRed}{（此行有错误！）}}|16return
    output_tensor17|\underline{\textbf{后续提示}}|:18[错误信息]19|\underline{索引}|  tensor
    必须具有与 |\underline{self}| tensor 相同的维度数20...21|\underline{\textbf{LLM}}|:22def
    pytorch_call(...):23...24|\textbf{\textcolor{bgGreen}{output_tensor.scatter_(dim=0,
    index=tensor_indices.squeeze(), src=tensor_updates)}}|  |\textbf{\textcolor{bgGreen}{（修复后的行是正确的）}}|25return
    output_tensor
- en: 'Figure 6: Example Prompt for Counterpart Synthesis.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '图 6: 对应物合成的示例提示。'
- en: III-B Path Constraint Extraction
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-B 路径约束提取
- en: 'For a DL library API and its counterpart synthesized in Sec [III-A](#S3.SS1
    "III-A Counterpart Synthesis ‣ III Methodology ‣ DLLens: Testing Deep Learning
    Libraries via LLM-aided Synthesis"), DLLens extracts path constraints from the
    control flow graphs of their implementations. Specifically, DLLens extracts a
    path constraint for each execution path in the control flow graph. Each path constraint
    specifies the input conditions for the execution of the concerned path [[33](#bib.bib33)],
    where each input condition is a condition on input arguments of the DL library
    API and its counterpart. For each loop in the concerned path, DLLens follows the
    existing work [[31](#bib.bib31)] to unroll the loop once and ignore the loop condition.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 DL 库 API 及其在第 [III-A](#S3.SS1 "III-A 对应物合成 ‣ III 方法论 ‣ DLLens：通过 LLM 辅助合成测试深度学习库")
    节合成的对应物，DLLens 从它们的实现的控制流图中提取路径约束。具体而言，DLLens 为控制流图中的每个执行路径提取一个路径约束。每个路径约束指定了执行相关路径的输入条件
    [[33](#bib.bib33)]，其中每个输入条件是对 DL 库 API 和其对应物的输入参数的条件。对于相关路径中的每个循环，DLLens 遵循现有工作
    [[31](#bib.bib31)] 将循环展开一次，并忽略循环条件。
- en: Essentially, each extracted path constraint is a conjunction of the input conditions
    extracted from the sanity check statements and the control flow statements (e.g.,
    if statement) reached by the concerned execution path. Sanity check statements
    include built-in assertion statements and validation check function calls (e.g.,
    the TORCH_CHECK function call) written by DL library developers. Following the
    existing work [[31](#bib.bib31)], DLLens considers two specific function calls,
    i.e., OP_REQUIRES⁢ in TensorFlow and TORCH_CHECK⁢ in PyTorch. In specific, for
    each validation check function call, DLLens targets its predicate expression,
    i.e., the second argument of the OP_REQUIRES and the first argument of the TORCH_CHECK).
    For each execution path, DLLens adds the True condition of the predicate expression
    in each reached validation check function call and the True or False condition
    assumed by each reached control flow statements to its path constraint.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，每个提取的路径约束是从健全性检查语句和控制流语句（例如 if 语句）中提取的输入条件的结合。健全性检查语句包括由 DL 库开发人员编写的内置断言语句和验证检查函数调用（例如，TORCH_CHECK
    函数调用）。遵循现有工作 [[31](#bib.bib31)]，DLLens 考虑了两个特定的函数调用，即 TensorFlow 中的 OP_REQUIRES
    和 PyTorch 中的 TORCH_CHECK。具体而言，对于每个验证检查函数调用，DLLens 关注其谓词表达式，即 OP_REQUIRES 的第二个参数和
    TORCH_CHECK 的第一个参数。对于每个执行路径，DLLens 将每个到达的验证检查函数调用中的谓词表达式的 True 条件和每个到达的控制流语句假设的
    True 或 False 条件添加到其路径约束中。
- en: 'The extracted path constraints from DL libraries usually involve operations
    of tensors, which are complex data structures not supported by SMT solvers such
    as Z3 [[34](#bib.bib34)]. DLLens adopts a constraint model (see Table [I](#S3.T1
    "Table I ‣ III-B Path Constraint Extraction ‣ III Methodology ‣ DLLens: Testing
    Deep Learning Libraries via LLM-aided Synthesis")) proposed by existing study [[31](#bib.bib31)],
    which observed that most conditions for a tensor input argument only constrain
    specific properties (e.g., shape) while the value of the tensor is not constrained
    in most cases [[31](#bib.bib31), [30](#bib.bib30)]. Specifically, DLLens follows
    existing work to reduce a few tensor operations, which are unknown by existing
    SMT solvers. For instance, given a constraint “len(¡tensor¿.shape) ¡ 1 is True”
    with an unknown operation len() that calculates the length of a tensor’s shape.
    Since the length of a tensor’s shape, by definition, is the number of dimensions
    (ndims) held by the tensor; therefore, DLLens will reduce it to “¡tensor¿.ndims¡1
    is True”.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '从深度学习库中提取的路径约束通常涉及张量的操作，这些是复杂的数据结构， SMT 求解器如 Z3 不支持这些结构[[34](#bib.bib34)]。DLLens
    采用了现有研究提出的约束模型（见表[I](#S3.T1 "表 I ‣ III-B 路径约束提取 ‣ III 方法 ‣ DLLens: 通过 LLM 辅助综合测试深度学习库")）[[31](#bib.bib31)]，该研究观察到，大多数张量输入参数的条件只约束特定属性（例如，shape），而张量的值在大多数情况下没有被约束[[31](#bib.bib31),
    [30](#bib.bib30)]。具体来说，DLLens 遵循现有的工作，减少了一些现有 SMT 求解器未知的张量操作。例如，给定一个约束“len(¡tensor¿.shape)
    ¡ 1 为 True”，其中包含一个未知操作 len()，它计算张量形状的长度。由于张量形状的长度，按照定义，就是张量所持有的维度数量（ndims）；因此，DLLens
    将其简化为“¡tensor¿.ndims¡1 为 True”。'
- en: 'TABLE I: Tensor Property Model'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '表 I: 张量属性模型'
- en: '| Property | Description | Variable Type |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| Property | 描述 | 变量类型 |'
- en: '| --- | --- | --- |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| ndims | number of dimensions | integer |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| ndims | 维度数量 | 整数 |'
- en: '| shape | number of elements in each dimension | list of integers |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| shape | 每个维度中的元素数量 | 整数列表 |'
- en: '| dtype | data type (e.g., int32, float64) | string |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| dtype | 数据类型（例如，int32，float64） | 字符串 |'
- en: '| num_element | number of elements | integer |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| num_element | 元素数量 | 整数 |'
- en: 'However, solving path constraints can be challenging. Due to the large size
    of DL libraries and their upstream libraries, it would be too expensive to perform
    the static analysis on the entire code base [[31](#bib.bib31)]. Therefore, DLLens
    follows existing work [[31](#bib.bib31)] to perform the static analysis on code
    within the same module. However, we notice that input conditions in path constraints
    usually involve functions written in external libraries (e.g., Eigen, a popular
    C++ library for linear algebra) or external modules (e.g., TensorUtils). These
    external functions complicate the solving of path constraints since their behaviors
    are unknown to existing solvers. Taking the implementation in Figure [8](#S3.F8
    "Figure 8 ‣ III-B Path Constraint Extraction ‣ III Methodology ‣ DLLens: Testing
    Deep Learning Libraries via LLM-aided Synthesis") as an example. The input condition
    extracted from the If statement (i.e., Stmt 4) includes an external function named
    TensorShapeUtils::IsVector; thus, it is invalid (i.e., contains external functions
    unknown to existing solvers). Consequently, path constraints, including this input
    condition, cannot be solved. To handle external functions, existing works [[31](#bib.bib31),
    [18](#bib.bib18)] either simply skipped them (i.e., do not include invalid input
    conditions with these external functions into the path constraint) or manually
    modeled the behavior only on a very limited set of these functions. Both ways
    lead to incomplete path constraints, as is reported by the existing work [[31](#bib.bib31)].'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '然而，解决路径约束可能是具有挑战性的。由于深度学习库及其上游库的规模庞大，对整个代码库进行静态分析将会非常昂贵[[31](#bib.bib31)]。因此，DLLens
    遵循现有工作[[31](#bib.bib31)]，在同一模块内进行静态分析。然而，我们注意到，路径约束中的输入条件通常涉及编写在外部库（例如，Eigen，一个流行的线性代数
    C++ 库）或外部模块（例如，TensorUtils）中的函数。这些外部函数使得路径约束的求解变得复杂，因为现有求解器对它们的行为并不知晓。以图[8](#S3.F8
    "图 8 ‣ III-B 路径约束提取 ‣ III 方法 ‣ DLLens: 通过 LLM 辅助综合测试深度学习库")中的实现为例。来自 If 语句（即，Stmt
    4）的输入条件包含一个名为 TensorShapeUtils::IsVector 的外部函数，因此它是无效的（即，包含现有求解器未知的外部函数）。因此，包括该输入条件的路径约束无法被解决。为了处理外部函数，现有工作[[31](#bib.bib31),
    [18](#bib.bib18)] 要么简单地跳过它们（即，不将包含这些外部函数的无效输入条件纳入路径约束），要么仅在非常有限的一组这些函数上手动建模其行为。这两种方法都导致路径约束不完整，正如现有工作[[31](#bib.bib31)]中所报告的那样。'
- en: DLLens leverages an LLM to handle this challenge. The insight is that LLMs have
    learned domain-specific knowledge of DL libraries and their upstream libraries.
    Given a control flow statement or sanity check statement consisting of external
    functions, LLMs are capable of “modeling” the behavior of these external functions
    and outputting a valid input condition solvable by existing solvers. A straightforward
    way is to simply provide the whole source code of an API and its counterpart to
    an LLM and let it extract valid input conditions. However, this is ineffective
    since the source code of each library API and its counterpart usually have complex
    control flow graphs, and we find that LLMs are ineffective in handling such complicated
    contexts [[35](#bib.bib35), [36](#bib.bib36), [37](#bib.bib37)].
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: DLLens 利用 LLM 来应对这一挑战。洞察在于 LLM 已经学习了 DL 库及其上游库的领域特定知识。给定包含外部函数的控制流语句或合理性检查语句，LLM
    能够“建模”这些外部函数的行为，并输出由现有求解器可解的有效输入条件。一个简单的方法是将 API 的整个源代码及其对应部分提供给 LLM，并让其提取有效输入条件。然而，这种方法效果不佳，因为每个库
    API 及其对应部分的源代码通常具有复杂的控制流图，我们发现 LLM 在处理这种复杂上下文时效果不佳[[35](#bib.bib35), [36](#bib.bib36),
    [37](#bib.bib37)]。
- en: 'Therefore, instead of giving the LLM the whole source code. DLLens handles
    each control flow statement and sanity check statement individually by only providing
    the execution trace from the input argument to this statement. Based on this execution
    trace, DLLens further asks the LLM to extract a valid input condition. Taking
    Figure [8](#S3.F8 "Figure 8 ‣ III-B Path Constraint Extraction ‣ III Methodology
    ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis") as an example,
    to extract the input condition of argument k from a If statement mycode Stmt 2
    which contains an external function TensorShapeUtils::IsVector, DLLens will first
    build the control flow graph and extract the execution trace from k to Stmt 2.
    Then DLLens constructs a prompt (see [Figure 7](#S3.F7 "In III-B Path Constraint
    Extraction ‣ III Methodology ‣ DLLens: Testing Deep Learning Libraries via LLM-aided
    Synthesis")) formatted based on the following three parts:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '因此，DLLens 不将整个源代码提供给 LLM。DLLens 通过仅提供从输入参数到该语句的执行轨迹，逐个处理每个控制流语句和合理性检查语句。基于该执行轨迹，DLLens
    进一步请求 LLM 提取有效输入条件。以图 [8](#S3.F8 "Figure 8 ‣ III-B Path Constraint Extraction
    ‣ III Methodology ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis")
    为例，为从包含外部函数 TensorShapeUtils::IsVector 的 If 语句 mycode Stmt 2 中提取参数 k 的输入条件，DLLens
    首先构建控制流图并提取从 k 到 Stmt 2 的执行轨迹。然后 DLLens 构建一个提示（参见 [Figure 7](#S3.F7 "In III-B
    Path Constraint Extraction ‣ III Methodology ‣ DLLens: Testing Deep Learning Libraries
    via LLM-aided Synthesis)"), 基于以下三部分格式化：'
- en: '1.'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: the execution trace from the input argument k to the concerned statement Stmt
    2.
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从输入参数 k 到相关语句 Stmt 2 的执行轨迹。
- en: '2.'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: the argument type of input argument k.
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输入参数 k 的参数类型。
- en: '3.'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: 'the ‘property’ (see Table [I](#S3.T1 "Table I ‣ III-B Path Constraint Extraction
    ‣ III Methodology ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis"))
    of ‘k’ if ‘k’ is a tensor. Otherwise, this part will not be provided to LLMs.'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '如果 ‘k’ 是张量，则‘k’的‘属性’（参见表 [I](#S3.T1 "Table I ‣ III-B Path Constraint Extraction
    ‣ III Methodology ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis)）。否则，这部分将不会提供给
    LLM。'
- en: As a result, DLLens successfully guides the LLM to extract the valid input condition
    (i.e., k.ndims==1) from Stmt 2. Specifically, DLLens constructs the execution
    trace from k to Stmt 2 by including the Stmt 1 since k’s value is assigned to
    diag_index, then used in Stmt 2. DLLens further uses an SMT solver to checks whether
    the returned input condition from the LLM is valid. For valid input conditions
    returned by LLM, DLLens will add them to the path constraint.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，DLLens 成功引导 LLM 从 Stmt 2 中提取有效输入条件（即 k.ndims==1）。具体而言，DLLens 通过包括 Stmt 1
    构建从 k 到 Stmt 2 的执行轨迹，因为 k 的值被分配给 diag_index，然后在 Stmt 2 中使用。DLLens 进一步使用 SMT 求解器检查从
    LLM 返回的输入条件是否有效。对于 LLM 返回的有效输入条件，DLLens 会将其添加到路径约束中。
- en: '12|\underline{\textbf{Prompt}}|:3Analyze  the  following  execution  path,  summarize  the4NECESSARY  constraint  on  the  ‘properties‘  of  input5arguments  ‘k‘  to  satisfy  the  condition  at  the  end  of6the  path.7|\textbf{[Execution  Path]}|8diag_index  =  k9condition:  TensorShapeUtils::IsVector(diag_index.shape())10|\textbf{[Argument  Type]}|11{’k’:  ’tensor’}12|\textbf{[‘property‘  for  ‘k‘]}|13.ndims:  int,  number  of  dimensions  of  tensor14...15The  constraint  should  only  consider  symbols  |\underline{‘k‘}|,  ...16...17|\underline{\textbf{LLM}}:|18len(k.shape)  ==  1'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '12|\underline{\textbf{提示}}|:3分析以下执行路径，总结输入参数‘k’的‘属性’上4必需的约束，以满足路径末尾的条件。7|\textbf{[执行路径]}|8diag_index  =  k9条件:  TensorShapeUtils::IsVector(diag_index.shape())10|\textbf{[参数类型]}|11{’k’:  ’tensor’}12|\textbf{[‘k’的‘属性’]}|13.ndims:  int，张量的维度数量14...15约束应仅考虑符号|\underline{‘k’}|，16...17|\underline{\textbf{LLM}}:|18len(k.shape)  ==  1'
- en: 'Figure 7: Example prompt of DLLens to extract input conditions from control
    flow statements with external functions.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '图 7: DLLens 用于从带有外部函数的控制流语句中提取输入条件的示例提示。'
- en: '![Refer to caption](img/ee6c3428adb61a9fe1f7eddeff4d00a7.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/ee6c3428adb61a9fe1f7eddeff4d00a7.png)'
- en: 'Figure 8: A running example of DLLens that uses the LLM to extract valid input
    conditions from a control flow statement with external functions.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '图 8: DLLens 使用 LLM 从带有外部函数的控制流语句中提取有效输入条件的运行示例。'
- en: 'The detailed algorithm for path constraint extraction is shown in Algorithm [1](#alg1
    "Algorithm 1 ‣ III-B Path Constraint Extraction ‣ III Methodology ‣ DLLens: Testing
    Deep Learning Libraries via LLM-aided Synthesis"). Given the set of input arguments
    and an execution path extracted from the implementation of a DL library API or
    its counterpart, DLLens traverses all the statements along this path and extracts
    conditions on input arguments from sanity check and control flow statements (lines
    3-6). Note that the condition value of some statements may not be controlled by
    input arguments, e.g., a condition value may be controlled by some global variables.
    In this case, conditions from these statements will not be added to the path constraint
    of the execution path (lines 6-7) since changing the value of input arguments
    will not influence these condition values. For the remaining statements, DLLens
    first reduces tensor operators (line 8) and checks if there are external functions
    whose source code is not considered during the static analysis (line 9). If any
    external function is found, DLLens formats the prompt based on the template of
    [Figure 7](#S3.F7 "In III-B Path Constraint Extraction ‣ III Methodology ‣ DLLens:
    Testing Deep Learning Libraries via LLM-aided Synthesis") to let the LLM extract
    a valid input condition from the concerned statement (line 10). The input condition
    returned by the LLM will be added to the path constraint if it is solvable (i.e.,
    it can be solved by an SMT solver) (lines 11-12). Otherwise, the input condition
    of the concerned statement will not be added to the path constraint. For each
    DL library API, DLLens applies Alg [1](#alg1 "Algorithm 1 ‣ III-B Path Constraint
    Extraction ‣ III Methodology ‣ DLLens: Testing Deep Learning Libraries via LLM-aided
    Synthesis") to each execution path inside implementations of this API and its
    counterpart. Finally, the total path constraints of each API are formed by combining
    the path constraints extracted from its own and its counterpart’s implementations.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '提取路径约束的详细算法如算法 [1](#alg1 "Algorithm 1 ‣ III-B Path Constraint Extraction ‣
    III Methodology ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis")
    所示。给定一组输入参数和从 DL 库 API 或其对应实现中提取的执行路径，DLLens 遍历沿该路径的所有语句，并从完整性检查和控制流语句中提取输入参数的条件（第
    3-6 行）。请注意，某些语句的条件值可能不受输入参数控制，例如，条件值可能由某些全局变量控制。在这种情况下，这些语句的条件不会被添加到执行路径的路径约束中（第
    6-7 行），因为改变输入参数的值不会影响这些条件值。对于剩余的语句，DLLens 首先简化张量运算符（第 8 行），并检查是否存在源代码在静态分析过程中未考虑的外部函数（第
    9 行）。如果发现任何外部函数，DLLens 会根据 [Figure 7](#S3.F7 "In III-B Path Constraint Extraction
    ‣ III Methodology ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis")
    的模板格式化提示，让 LLM 从相关语句中提取有效的输入条件（第 10 行）。如果 LLM 返回的输入条件是可解的（即，可以由 SMT 求解器解决）（第 11-12
    行），则将其添加到路径约束中。否则，相关语句的输入条件将不会被添加到路径约束中。对于每个 DL 库 API，DLLens 将算法 [1](#alg1 "Algorithm
    1 ‣ III-B Path Constraint Extraction ‣ III Methodology ‣ DLLens: Testing Deep
    Learning Libraries via LLM-aided Synthesis") 应用于该 API 及其对应实现中的每个执行路径。最后，每个 API
    的总路径约束通过将从其自身及其对应实现中提取的路径约束组合形成。'
- en: 'Input: $p$* then8                          continue9                  cond’  $\leftarrow$;17'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '输入: $p$* then8 continue9 cond’ $\leftarrow$;17'
- en: Algorithm 1 Path Constraint Extraction
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 1 路径约束提取
- en: III-C Test Input Generation and Bug Detection
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-C 测试输入生成和错误检测
- en: 'For each API, DLLens uses its total path constraint set for test input generation.
    For each path constraint inside this total path constraint set, DLLens iteratively
    generates input arguments to fulfill such constraint. To avoid duplication during
    the iterative generation, when generating input arguments for each path constraint,
    we follow existing works to add an additional input constraint, preventing the
    constraint solver from generating duplicate input tensors whose property values
    have been covered in the previous iteration, back to the path constraint. Besides
    the path constraint extracted in Sec.[III-B](#S3.SS2 "III-B Path Constraint Extraction
    ‣ III Methodology ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis"),
    following existing techniques [[18](#bib.bib18)], DLLens also incorporates natural
    constraints and error-feedback constraints. The former refers to pre-defined constraints
    based on the input argument type (see Table [II](#S4.T2 "Table II ‣ IV-A Implementations
    and Experiment Setup ‣ IV Evaluation ‣ DLLens: Testing Deep Learning Libraries
    via LLM-aided Synthesis"). For instance, we require the tensor’s data type to
    be a string among a list of options such as float32 and double. The latter refers
    to the constraints extracted from error messages in previous iterations. For instance,
    the error message formatted in Dimension out of range (expected to be in range
    of [#1, #2], but got #3) indicates the ‘ndims’ of a tensor input argument should
    be within the range of [#1, #2] while the actual ndims of this tensor input argument
    is #3. For this error message, we use a regular expression to extract the #1,
    #2, and #3, and further check if there is a tensor input argument whose ndims
    is #3. If such an input argument is found, we add a constraint that requires its
    ndims to be within the range of [#1, #2] to the original path constraint.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '对于每个 API，DLLens 使用其总路径约束集进行测试输入生成。对于该总路径约束集中的每个路径约束，DLLens 迭代地生成输入参数以满足这些约束。为了避免在迭代生成过程中出现重复，当为每个路径约束生成输入参数时，我们遵循现有方法添加一个额外的输入约束，防止约束求解器生成在前一迭代中已覆盖的属性值的重复输入张量。除了在
    Sec.[III-B](#S3.SS2 "III-B Path Constraint Extraction ‣ III Methodology ‣ DLLens:
    Testing Deep Learning Libraries via LLM-aided Synthesis") 中提取的路径约束，DLLens 还结合了自然约束和错误反馈约束，参考了现有技术[[18](#bib.bib18)]。前者指的是基于输入参数类型的预定义约束（参见表
    [II](#S4.T2 "Table II ‣ IV-A Implementations and Experiment Setup ‣ IV Evaluation
    ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis")）。例如，我们要求张量的数据类型必须在
    float32 和 double 等选项列表中选择一个。后者指的是从之前迭代中的错误消息中提取的约束。例如，格式为“维度超出范围（预期在 [#1, #2]
    范围内，但得到 #3）”的错误消息表明张量输入参数的‘ndims’应在 [#1, #2] 范围内，而实际的 ndims 为 #3。对于此错误消息，我们使用正则表达式提取
    #1、#2 和 #3，并进一步检查是否存在一个 ndims 为 #3 的张量输入参数。如果找到这样的输入参数，我们将添加一个约束，要求其 ndims 在 [#1,
    #2] 范围内，以此更新原始路径约束。'
- en: Finally, a fuzzing driver is used to instantiate the concrete value of generated
    input tensors for testing. Inspired by existing work [[38](#bib.bib38)] demonstrating
    that special values (i.e., Inf and NaN) can expose output inconsistency in scientific
    libraries, we also randomly generate special values for input arguments.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，模糊测试驱动程序用于实例化生成的输入张量的具体值以进行测试。受到现有工作[[38](#bib.bib38)]的启发，研究表明特殊值（即 Inf 和
    NaN）可以揭示科学库中的输出不一致性，我们也随机生成特殊值作为输入参数。
- en: 'Test Oracles. DLLens uses two test oracles to detect both crash bugs and functional
    bugs. Crash bugs refer to system crashes, including aborts, segmentation faults,
    floating point exception raised, and INTERNAL_ASSERT_FAILED [[32](#bib.bib32),
    [18](#bib.bib18)]. If DLLens finds any such issues in testing, DLLens labels them
    as crash bugs for manual investigation. For functional bugs, DLLens focuses on
    the inconsistency between a DL library API and its counterpart. In particular,
    DLLens captures two types of inconsistency: 1) inconsistent computation results,
    *i.e.*, output inconsistency larger $\epsilon$ is a pre-defined threshold. 2)
    inconsistent execution status between the DL library API and its counterpart.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 测试Oracle。DLLens使用两个测试Oracle来检测崩溃错误和功能错误。崩溃错误指系统崩溃，包括中止、段错误、浮点异常抛出和INTERNAL_ASSERT_FAILED[[32](#bib.bib32),
    [18](#bib.bib18)]。如果DLLens在测试中发现任何此类问题，DLLens会将其标记为崩溃错误以供人工调查。对于功能错误，DLLens关注DL库API与其对等体之间的不一致。特别是，DLLens捕捉到两种不一致类型：1）计算结果不一致，即输出不一致大于预定义的阈值$\epsilon$。2）DL库API与其对等体之间的执行状态不一致。
- en: IV Evaluation
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 评估
- en: 'We evaluated DLLens from three perspectives: effectiveness of counterpart synthesis,
    path constraint extraction, and bug detection. We studied four research questions
    (RQs):'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从三个角度评估了DLLens：对等体合成的有效性、路径约束提取和错误检测。我们研究了四个研究问题（RQs）：
- en: •
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'RQ1: How effective is DLLens in finding counterparts compared with existing
    techniques? We demonstrated DLLens’s effectiveness by comparing with existing
    techniques on the total number of APIs found with counterpart.'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'RQ1: DLLens在寻找对等体方面与现有技术相比效果如何？我们通过与现有技术在发现的对等体总数上的比较来展示DLLens的有效性。'
- en: •
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'RQ2: How effective is DLLens in path constraint extraction? We measured the
    number of solvable path constraints extracted by DLLens.'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'RQ2: DLLens在路径约束提取中的有效性如何？我们测量了DLLens提取的可解路径约束的数量。'
- en: •
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'RQ3: Can DLLens detect real bugs? We presented DLLens’s bug-revealing capability
    to demonstrate its usefulness. We evaluated DLLens on two popular DL libraries:
    TensorFlow and PyTorch.'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'RQ3: DLLens能检测到真实错误吗？我们展示了DLLens的错误揭示能力以证明其有效性。我们在两个流行的DL库上评估了DLLens：TensorFlow和PyTorch。'
- en: •
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'RQ4: Are DLLens more effective than existing works? We compared DLLens with
    existing techniques in terms of the branch coverage and the number of bugs detected
    on 200 randomly sampled DL library APIs.'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'RQ4: DLLens比现有工作更有效吗？我们在200个随机抽样的DL库API上比较了DLLens与现有技术在分支覆盖率和检测到的错误数量方面的表现。'
- en: IV-A Implementations and Experiment Setup
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A 实现和实验设置
- en: 'Implementations We used gpt-turbo-3.5 for counterpart synthesis and path constraint
    extraction. We set the temperature to 1, the default value specified by the documentation [[39](#bib.bib39)].
    For path constraint extraction, we used the Python standard AST package [[40](#bib.bib40)]
    and tree-sitter [[41](#bib.bib41)] to parse an implementation into an AST tree.
    We further used z3py [[34](#bib.bib34)] to solve the extracted path constraint.
    For the natural constraint used by test input generation, we manually crafted
    the valid input space based on the argument type (see Table [II](#S4.T2 "Table
    II ‣ IV-A Implementations and Experiment Setup ‣ IV Evaluation ‣ DLLens: Testing
    Deep Learning Libraries via LLM-aided Synthesis")). The experiments were conducted
    using a 32-core server with a 3090Ti GPU.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '实现 我们使用了gpt-turbo-3.5进行对等体合成和路径约束提取。我们将温度设置为1，这是文档中指定的默认值[[39](#bib.bib39)]。对于路径约束提取，我们使用了Python标准AST包[[40](#bib.bib40)]和tree-sitter[[41](#bib.bib41)]将实现解析成AST树。我们进一步使用z3py[[34](#bib.bib34)]解决提取出的路径约束。对于测试输入生成使用的自然约束，我们根据参数类型手动构造了有效输入空间（见表[II](#S4.T2
    "Table II ‣ IV-A Implementations and Experiment Setup ‣ IV Evaluation ‣ DLLens:
    Testing Deep Learning Libraries via LLM-aided Synthesis")）。实验使用了一台32核的服务器和一块3090Ti
    GPU。'
- en: 'TABLE II: Natural Constraints Used by DLLens'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '表II: DLLens使用的自然约束'
- en: '| Argument Type | Argument Properties | Value Space |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 参数类型 | 参数属性 | 值空间 |'
- en: '| Tensor | ndims | [0, 5] |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 张量 | ndims | [0, 5] |'
- en: '| shape[i] | [0, 5] |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| shape[i] | [0, 5] |'
- en: '| dtype |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| dtype |'
- en: '&#124; [‘uint(8-64)’, ‘float(16-64)’, &#124;'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; [‘uint(8-64)’, ‘float(16-64)’, &#124;'
- en: '&#124; ‘complex(64-128)’, ‘bool’, ‘string’] &#124;'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; ‘complex(64-128)’, ‘bool’, ‘string’] &#124;'
- en: '|'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| num_element | [0, $\infty$] |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 元素数量 | [0, $\infty$] |'
- en: '| Bool | value | {True, False} |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 布尔 | 值 | {真, 假} |'
- en: '| Integer | value | [-100, 100] |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 整数 | 值 | [-100, 100] |'
- en: '| Float | value | [-100, 100] |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 浮点 | 值 | [-100, 100] |'
- en: '| String | value | Any |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 字符串 | 值 | 任何 |'
- en: DL libraries under test. We evaluated DLLens on PyTorch (v2.1.0) [[7](#bib.bib7)]
    and TensorFlow (v2.10.0) [[8](#bib.bib8)]. To collect API under test, we do not
    include the DL library API in our experiment if 1) it has an incomplete signature;
    2) it belongs to special packages (e.g., torch.utils and tf.raw_ops.Experimental).
    In total, we collected 1,864 TensorFlow APIs and 1,184 PyTorch APIs, which take
    up 56% and 74.3% of the total APIs collected by existing works [[21](#bib.bib21),
    [32](#bib.bib32)].
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 测试中的 DL 库。我们在 PyTorch (v2.1.0) [[7](#bib.bib7)] 和 TensorFlow (v2.10.0) [[8](#bib.bib8)]
    上评估了 DLLens。为了收集待测试的 API，我们的实验中不包括 1) 签名不完整的 API；2) 属于特殊包的 API（如 torch.utils 和
    tf.raw_ops.Experimental）。总共，我们收集了 1,864 个 TensorFlow API 和 1,184 个 PyTorch API，这些
    API 占现有工作中收集的总 API 的 56% 和 74.3% [[21](#bib.bib21), [32](#bib.bib32)]。
- en: API source code collection. To collect the source code of DL library APIs, we
    used PyCG [[42](#bib.bib42)] and Joern [[43](#bib.bib43)]/tree-sitter [[41](#bib.bib41)]
    to construct call graphs for Python and C++, respectively. Note that TensorFlow
    and PyTorch have their front-end APIs implemented in Python, and their core logic
    functions are in C++. To establish the call relationship between the Python and
    C++ code, we observed that TensorFlow employs the Python interface _execute.execute
    to access C++ operators, while PyTorch utilizes native_functions.yaml to link
    the Python API with its C++ implementations. Leveraging these characteristics,
    we developed a program analysis tool to bind function calls between Python and
    C++.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: API 源代码收集。为了收集 DL 库 API 的源代码，我们使用了 PyCG [[42](#bib.bib42)] 和 Joern [[43](#bib.bib43)]/tree-sitter [[41](#bib.bib41)]
    分别构建了 Python 和 C++ 的调用图。需要注意的是，TensorFlow 和 PyTorch 的前端 API 实现是用 Python 编写的，而其核心逻辑函数是用
    C++ 实现的。为了建立 Python 和 C++ 代码之间的调用关系，我们观察到 TensorFlow 使用 Python 接口 `_execute.execute`
    来访问 C++ 操作符，而 PyTorch 则利用 native_functions.yaml 将 Python API 与其 C++ 实现关联。利用这些特性，我们开发了一种程序分析工具来绑定
    Python 和 C++ 之间的函数调用。
- en: Starting from the entry point of each API, we conducted a breadth-first search
    in the constructed call graph, collecting the source code of all functions within
    a depth of five levels.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 从每个 API 的入口点开始，我们在构建的调用图中进行了广度优先搜索，收集了深度为五层的所有函数的源代码。
- en: 'Baselines. Overall, we compared DLLens with four existing techniques, TitanFuzz [[21](#bib.bib21)],
    TensorScope [[18](#bib.bib18)], FreeFuzz [[20](#bib.bib20)], and DocTer [[30](#bib.bib30)].
    Since neither executables nor source codes of ACETest [[31](#bib.bib31)], and
    FuzzGPT [[32](#bib.bib32)] are available, we did not include them in evaluation.²²2Although
    the source code of TensorScope is available, we tried our best but failed to execute
    their input generation and constraint extraction modules, thus we do not include
    TensorScope in RQ2 and RQ4. For RQ1 (evaluation of counterpart synthesis), we
    compared DLLens with TensorScope [[18](#bib.bib18)], which is the state-of-the-art
    work that can find counterparts across DL libraries for DL library APIs. In RQ2
    (evaluation of path constraint extraction), we compared DLLens with DocTer [[30](#bib.bib30)],
    which mines input constraints from DL library API documentation. In RQ4 (evaluation
    on code coverage and bug detection), we compared DLLens with two state-of-the-art
    DL library testing techniques: FreeFuzz [[20](#bib.bib20)] and TitanFuzz [[21](#bib.bib21)]
    on a randomly sampled API set.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 基准线。总体而言，我们将 DLLens 与四种现有技术进行了比较：TitanFuzz [[21](#bib.bib21)]、TensorScope [[18](#bib.bib18)]、FreeFuzz [[20](#bib.bib20)]
    和 DocTer [[30](#bib.bib30)]。由于 ACETest [[31](#bib.bib31)] 和 FuzzGPT [[32](#bib.bib32)]
    的可执行文件和源代码都不可用，我们没有将它们纳入评估。尽管 TensorScope 的源代码可用，我们尽力尝试但未能执行其输入生成和约束提取模块，因此未将
    TensorScope 包含在 RQ2 和 RQ4 中。对于 RQ1（对等体合成评估），我们将 DLLens 与 TensorScope [[18](#bib.bib18)]
    进行了比较，后者是当前能够发现 DL 库 API 之间对等体的最先进工作。对于 RQ2（路径约束提取评估），我们将 DLLens 与 DocTer [[30](#bib.bib30)]
    进行了比较，后者从 DL 库 API 文档中挖掘输入约束。对于 RQ4（代码覆盖率和错误检测评估），我们将 DLLens 与两个最先进的 DL 库测试技术：FreeFuzz [[20](#bib.bib20)]
    和 TitanFuzz [[21](#bib.bib21)] 在随机抽样的 API 集上进行了比较。
- en: Functional Bug Detection. For output inconsistencies checking between the DL
    library API and its’ counterpart, we set the absolute threshold $\epsilon$ to
    0.1. For execution status inconsistency, we first removed clear syntax errors
    (e.g., SyntaxError) and invalid argument messages such as TypeError and RuntimeError.
    For the remaining status inconsistencies, we manually checked the documentation
    of related DL library APIs to determine whether it was a real bug.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 功能性错误检测。对于 DL 库 API 和其对应关系之间的输出不一致检查，我们将绝对阈值 $\epsilon$ 设置为 0.1。对于执行状态不一致，我们首先去除了明显的语法错误（例如
    SyntaxError）和无效的参数消息，如 TypeError 和 RuntimeError。对于剩余的状态不一致，我们手动检查相关 DL 库 API 的文档，以确定是否存在真正的错误。
- en: 'IV-B RQ1: Effectiveness of Counterpart Synthesis'
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'IV-B RQ1: 对应关系合成的有效性'
- en: We compared DLLens with TensorScope [[18](#bib.bib18)], the state-of-the-art
    techniques finding counterparts across different DL libraries. We evaluated both
    tools on the API counterpart coverage, i.e., the number of TensorFlow and PyTorch
    APIs that these tools could find counterparts for. To be more specific, we only
    evaluated whether a valid DL library API’s counterpart is available while did
    not consider the number of different counterparts found for one single API. Therefore,
    if a DL library API has multiple counterparts, we consider all of them as one
    when evaluating the API counterpart coverage.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将 DLLens 与 TensorScope [[18](#bib.bib18)] 进行了比较，后者是目前最先进的在不同 DL 库之间查找对应关系的技术。我们评估了这两种工具在
    API 对应关系覆盖率上的表现，即这些工具能够找到多少 TensorFlow 和 PyTorch API 的对应关系。具体来说，我们仅评估了是否存在有效的
    DL 库 API 对应关系，而没有考虑一个 API 找到的不同对应关系的数量。因此，如果一个 DL 库 API 有多个对应关系，我们在评估 API 对应关系覆盖率时将其视为一个。
- en: 'For TensorScope, we followed its methodology and collected counterparts of
    TensorFlow APIs and PyTorch APIs via parsing the developer-constructed rules in
    model conversion libraries. Since these rules are manually written by library
    developers, we consider all counterparts extracted by TensorScope to be valid
    (i.e., satisfies the Equation [1](#S3.E1 "Equation 1 ‣ III-A Counterpart Synthesis
    ‣ III Methodology ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis")).
    For DLLens, we applied it on each DL library API to synthesize this API’s valid
    counterpart that satisfies Equation [1](#S3.E1 "Equation 1 ‣ III-A Counterpart
    Synthesis ‣ III Methodology ‣ DLLens: Testing Deep Learning Libraries via LLM-aided
    Synthesis") based on a non-empty valid input set (with at most three valid inputs).
    Due to the random nature of the LLM, the synthesized counterpart from the LLM
    may not always be valid. To make better use of the LLM, we applied our counterpart
    synthesis workflow for five rounds. In each round, we asked the LLM to synthesize
    counterparts for APIs whose valid counterparts had not been correctly synthesized
    in previous rounds. Table [III](#S4.T3 "Table III ‣ IV-B RQ1: Effectiveness of
    Counterpart Synthesis ‣ IV Evaluation ‣ DLLens: Testing Deep Learning Libraries
    via LLM-aided Synthesis") shows the number of valid API counterparts synthesized
    by DLLens for in each round. We noticed that most counterparts could be found
    in the first round, and the following rounds could also find a non-negligible
    number of API counterparts.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '对于 TensorScope，我们遵循其方法论，通过解析开发者构建的模型转换库中的规则，收集了 TensorFlow API 和 PyTorch API
    的对应关系。由于这些规则是由库开发者手动编写的，我们认为 TensorScope 提取的所有对应关系都是有效的（即，满足方程 [1](#S3.E1 "Equation
    1 ‣ III-A Counterpart Synthesis ‣ III Methodology ‣ DLLens: Testing Deep Learning
    Libraries via LLM-aided Synthesis")）。对于 DLLens，我们将其应用于每个 DL 库 API，以合成满足方程 [1](#S3.E1
    "Equation 1 ‣ III-A Counterpart Synthesis ‣ III Methodology ‣ DLLens: Testing
    Deep Learning Libraries via LLM-aided Synthesis") 的有效对应关系，基于一个非空的有效输入集（最多三个有效输入）。由于
    LLM 的随机性质，LLM 合成的对应关系可能并不总是有效。为了更好地利用 LLM，我们进行了五轮对应关系合成。在每一轮中，我们要求 LLM 合成在前几轮中未正确合成的
    API 的对应关系。表 [III](#S4.T3 "Table III ‣ IV-B RQ1: Effectiveness of Counterpart Synthesis
    ‣ IV Evaluation ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis")
    显示了 DLLens 在每轮中合成的有效 API 对应关系的数量。我们注意到，大多数对应关系可以在第一轮找到，后续轮次也能找到数量不少的 API 对应关系。'
- en: 'Figure [9](#S4.F9 "Figure 9 ‣ IV-B RQ1: Effectiveness of Counterpart Synthesis
    ‣ IV Evaluation ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis")
    shows the comparison between DLLens and TensorScope on the API counterpart coverage.
    A higher API counterpart coverage indicates the tool can facilitate differential
    testing to detect functional bugs for more APIs. Overall, DLLens can synthesize
    valid counterparts for 1,481 APIs, including 739 from TensorFlow and 742 from
    PyTorch, which stand for 41.47% and 62.67% of the total APIs evaluated, respectively.
    Compared with TensorScope, DLLens can collect 143.1% (739 v.s. 304) more valid
    counterparts for TensorFlow APIs and 65.3% (742 v.s. 449) more for PyTorch APIs.
    We also noticed that TensorScope found 68 and 159 counterparts for TensorFlow
    and PyTorch APIs beyond our recorded APIs. This is because some APIs recorded
    in developers’ conversion rules are related to special packages such as torch.utils
    or special usages such as torch.float64 for representing the data type. These
    APIs are not targeted by DLLens since we try to focus on APIs developed for DL
    algorithms, which may be commonly used by DL library users.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '图 [9](#S4.F9 "图 9 ‣ IV-B RQ1: 对等体合成的有效性 ‣ IV 评估 ‣ DLLens: 通过LLM辅助综合测试深度学习库")
    显示了DLLens与TensorScope在API对等体覆盖率上的比较。更高的API对等体覆盖率表明该工具可以促进差异测试，从而检测更多API的功能缺陷。总体而言，DLLens可以为1,481个API合成有效的对等体，其中包括739个来自TensorFlow和742个来自PyTorch，分别占总评估API的41.47%和62.67%。与TensorScope相比，DLLens可以为TensorFlow
    API收集143.1%（739对比304）更多的有效对等体，为PyTorch API收集65.3%（742对比449）更多的有效对等体。我们还注意到，TensorScope发现了68个和159个TensorFlow和PyTorch
    API的对等体，这些对等体超出了我们记录的API。这是因为开发者转换规则中记录的一些API涉及特殊包如torch.utils或特殊用法如torch.float64用于表示数据类型。这些API不在DLLens的目标范围内，因为我们尝试专注于为DL算法开发的API，这些API可能被DL库用户广泛使用。'
- en: 'TABLE III: The Number of Counterparts Found by DLLens'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '表 III: DLLens发现的对等体数量'
- en: '| Library Name | Round 1 | Round 2 | Round 3 | Round 4 | Round 5 | Total |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 库名称 | 第1轮 | 第2轮 | 第3轮 | 第4轮 | 第5轮 | 总计 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| TensorFlow | 619 | 53 | 30 | 20 | 17 | 739 |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| TensorFlow | 619 | 53 | 30 | 20 | 17 | 739 |'
- en: '| PyTorch | 624 | 61 | 30 | 15 | 12 | 742 | ![Refer to caption](img/decbfee6802d362715bdae0dc2f43353.png)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '| PyTorch | 624 | 61 | 30 | 15 | 12 | 742 | ![参见标题](img/decbfee6802d362715bdae0dc2f43353.png)'
- en: 'Figure 9: Comparison on API Counterpart Coverage'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '图 9: API对等体覆盖率的比较'
- en: 'IV-C RQ2: Effectiveness of Path Constraint Extraction'
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'IV-C RQ2: 路径约束提取的有效性'
- en: 'To measure the effectiveness of DLLens in path constraint extraction, we first
    evaluated the number of path constraints that can be extracted by DLLens. Specifically,
    we applied DLLens to extract path constraints for all APIs (i.e., 739 TensorFlow
    APIs and 742 PyTorch APIs) collected in RQ1. For each API, its path constraints
    are formed by combining the path constraints extracted from both its own implementation
    and the implementation of its counterpart. Table [IV](#S4.T4 "Table IV ‣ IV-C
    RQ2: Effectiveness of Path Constraint Extraction ‣ IV Evaluation ‣ DLLens: Testing
    Deep Learning Libraries via LLM-aided Synthesis") demonstrates the performance
    of DLLens’s path constraint (i.e., P.C.) extraction capability by showing the
    number of path constraints extracted per API. On average, DLLens extracts 21.50
    path constraints for each TensorFlow API and 41.87 for each PyTorch API. Each
    path constraint in TensorFlow and PyTorch contains 3.35 and 3.84 input conditions,
    respectively. We also noticed that incorporating our LLM-aided static analysis
    method led to a significant increase in the extraction of path constraints compared
    to our static analysis method that doesn’t use the LLM (referred to as ‘DLLens
    w/o LLM’).'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '为了评估DLLens在路径约束提取方面的有效性，我们首先评估了DLLens可以提取的路径约束数量。具体来说，我们将DLLens应用于提取RQ1中收集的所有API（即739个TensorFlow
    API和742个PyTorch API）的路径约束。对于每个API，其路径约束是通过结合从其自身实现和其对等实现中提取的路径约束来形成的。表格 [IV](#S4.T4
    "表 IV ‣ IV-C RQ2: 路径约束提取的有效性 ‣ IV 评估 ‣ DLLens: 通过LLM辅助综合测试深度学习库") 通过显示每个API提取的路径约束数量来展示DLLens的路径约束（即P.C.）提取能力。平均而言，DLLens为每个TensorFlow
    API提取21.50个路径约束，为每个PyTorch API提取41.87个路径约束。TensorFlow和PyTorch中的每个路径约束分别包含3.35和3.84个输入条件。我们还注意到，与未使用LLM的静态分析方法（称为“DLLens
    w/o LLM”）相比，结合我们的LLM辅助静态分析方法显著增加了路径约束的提取。'
- en: 'TABLE IV: Performance on Path Constraint (P.C.) Extraction'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '表 IV: 路径约束（P.C.）提取的性能'
- en: '| Tool | # P.C./API | # Cons./P.C. |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 工具 | 每个API的P.C.数量 | 每个P.C.的条件数量 |'
- en: '| --- | --- | --- |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| DLLens (TensorFlow) | 21.50$\pm$2.53 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| DLLens (TensorFlow) | 21.50$\pm$2.53 |'
- en: '| DLLens w/o LLM (TensorFlow) | 2.12$\pm$1.04 |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| DLLens w/o LLM (TensorFlow) | 2.12$\pm$1.04 |'
- en: '| DLLens (PyTorch) | 41.87$\pm$3.02 |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| DLLens (PyTorch) | 41.87$\pm$3.02 |'
- en: '| DLLens w/o LLM (PyTorch) | 3.15$\pm$1.10 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| DLLens w/o LLM (PyTorch) | 3.15$\pm$1.10 |'
- en: Comparison with DocTer. We further compared DLLens with DocTer [[30](#bib.bib30)]
    in terms of the constraint extraction capability. Although DocTer utilizes documents
    to extract API constraints and does not extract path constraints, we employed
    another metric (i.e., property constraints) utilized by existing works [[30](#bib.bib30),
    [18](#bib.bib18)] including DocTer, to evaluate the constraint extraction performance.
    Property constraint refers to the total number of input properties considered
    by extracted constraints. For each API input argument, we followed existing work
    and considered all valid options for one property as one property constraint [[30](#bib.bib30)].
    Among all APIs for which DLLens synthesized counterparts in RQ1, we found that
    DocTer could extract constraints for 271 TensorFlow APIs and 160 PyTorch APIs.
    For a fair comparison, we further compared the property constraint extraction
    performance with DocTer on these APIs.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 与 DocTer 的比较。我们进一步将 DLLens 与 DocTer [[30](#bib.bib30)] 在约束提取能力方面进行了比较。尽管 DocTer
    利用文档提取 API 约束且不提取路径约束，我们使用了另一种现有工作[[30](#bib.bib30), [18](#bib.bib18)]中使用的度量标准（即属性约束），来评估约束提取性能。属性约束指的是提取的约束考虑的输入属性的总数。对于每个
    API 输入参数，我们遵循现有工作，将一个属性的所有有效选项视为一个属性约束[[30](#bib.bib30)]。在 RQ1 中 DLLens 合成的所有
    API 中，我们发现 DocTer 能提取 271 个 TensorFlow API 和 160 个 PyTorch API 的约束。为了公平比较，我们进一步在这些
    API 上与 DocTer 比较了属性约束提取性能。
- en: 'TABLE V: Comparison on Property Constraint Extraction'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 表 V：属性约束提取比较
- en: '| Tool | TensorFlow | PyTorch |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 工具 | TensorFlow | PyTorch |'
- en: '| --- | --- | --- |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| DLLens | 6.21$\pm$4.25 |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| DLLens | 6.21$\pm$4.25 |'
- en: '| DocTer | 4.24$\pm$4.21 |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| DocTer | 4.24$\pm$4.21 |'
- en: 'Table [V](#S4.T5 "Table V ‣ IV-C RQ2: Effectiveness of Path Constraint Extraction
    ‣ IV Evaluation ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis")
    shows the average number of property constraints extracted for each API. DLLens
    extracts more property constraints than DocTer, *i.e.*, 6.21 v.s. 4.24 for TensorFlow
    and 6.64 v.s., 5.24 for PyTorch. We further analyzed the constraint extraction
    performance for each property, as depicted in Figure [10](#S4.F10 "Figure 10 ‣
    IV-C RQ2: Effectiveness of Path Constraint Extraction ‣ IV Evaluation ‣ DLLens:
    Testing Deep Learning Libraries via LLM-aided Synthesis"). Our findings indicate
    that DLLens outperforms DocTer in extracting constraints related to shape, value,
    and structure (‘STR.’ in Figure [10](#S4.F10 "Figure 10 ‣ IV-C RQ2: Effectiveness
    of Path Constraint Extraction ‣ IV Evaluation ‣ DLLens: Testing Deep Learning
    Libraries via LLM-aided Synthesis")), while it extracts less data type constraints
    (’DType’ in Figure [10](#S4.F10 "Figure 10 ‣ IV-C RQ2: Effectiveness of Path Constraint
    Extraction ‣ IV Evaluation ‣ DLLens: Testing Deep Learning Libraries via LLM-aided
    Synthesis")) compared to DocTer.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '表[V](#S4.T5 "Table V ‣ IV-C RQ2: Effectiveness of Path Constraint Extraction
    ‣ IV Evaluation ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis")
    显示了每个 API 提取的属性约束的平均数量。DLLens 提取的属性约束比 DocTer 更多，*即*，TensorFlow 为 6.21 对 4.24，PyTorch
    为 6.64 对 5.24。我们进一步分析了每个属性的约束提取性能，如图[10](#S4.F10 "Figure 10 ‣ IV-C RQ2: Effectiveness
    of Path Constraint Extraction ‣ IV Evaluation ‣ DLLens: Testing Deep Learning
    Libraries via LLM-aided Synthesis")所示。我们的发现表明，DLLens 在提取与形状、值和结构相关的约束（见图[10](#S4.F10
    "Figure 10 ‣ IV-C RQ2: Effectiveness of Path Constraint Extraction ‣ IV Evaluation
    ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis")中的“STR.”）方面优于
    DocTer，而在提取数据类型约束（见图[10](#S4.F10 "Figure 10 ‣ IV-C RQ2: Effectiveness of Path
    Constraint Extraction ‣ IV Evaluation ‣ DLLens: Testing Deep Learning Libraries
    via LLM-aided Synthesis")中的“DType”）方面则少于 DocTer。'
- en: Taking TensorFlow APIs as an example, on average, DLLens is more effective in
    extracting shape (2.03 vs. 0.82), value (0.53 vs. 0.14), and structure (2.37 vs.
    1.66) constraints per API. As for data type constraints, averagely DLLens extracts
    1.28 constraints per API, whereas DocTer extracts 1.82 per API. This difference
    could be due to the common practice of documenting constraints related to data
    types, making DocTer more effective in this aspect. In contrast, constraints on
    shape, value, and structure are less frequently documented, limiting DocTer’s
    performance in these properties.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 以 TensorFlow APIs 为例，平均而言，DLLens 在每个 API 上提取形状（2.03 vs. 0.82）、值（0.53 vs. 0.14）和结构（2.37
    vs. 1.66）约束的效果更佳。至于数据类型约束，DLLens 平均每个 API 提取 1.28 个约束，而 DocTer 提取 1.82 个约束。这种差异可能是因为数据类型相关的约束通常会被详细记录，使得
    DocTer 在这方面更为有效。相比之下，形状、值和结构的约束记录较少，限制了 DocTer 在这些属性上的表现。
- en: '![Refer to caption](img/5ac5a171d2cddf6ff7bbb601af7750fa.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/5ac5a171d2cddf6ff7bbb601af7750fa.png)'
- en: 'Figure 10: Comparison on the Number of Constraints Extracted for Each Property'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：每个属性提取的约束数量比较
- en: 'IV-D RQ3: Effectiveness of Bug Detection'
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-D RQ3：漏洞检测的有效性
- en: We use DLLens to detect bugs in TensorFlow v2.10 and PyTorch v2.1. In total,
    DLLens detected 56bugs in TensorFlow and PyTorch, including 15bugs already fixed
    or confirmed by developers and 41new ones. After we reported those newly detected
    bugs, developers confirmed 39, including 19 fixed. The remaining 2 bugs are pending
    confirmation.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 DLLens 检测 TensorFlow v2.10 和 PyTorch v2.1 中的漏洞。总的来说，DLLens 检测到 TensorFlow
    和 PyTorch 中 56 个漏洞，包括 15 个已经被开发者修复或确认的漏洞和 41 个新漏洞。在我们报告这些新检测到的漏洞后，开发者确认了 39 个漏洞，其中
    19 个已被修复。剩余的 2 个漏洞仍在待确认中。
- en: 'Table [VI](#S4.T6 "Table VI ‣ IV-E RQ4: Comparison On Bug Detection and Code
    Coverage ‣ IV Evaluation ‣ DLLens: Testing Deep Learning Libraries via LLM-aided
    Synthesis") demonstrates the newly detected bugs in TensorFlow and PyTorch, categorized
    by their bug symptoms. The predominant type of bug detected by DLLens is the incorrect
    result bug (’Incorrect’ in Table [VI](#S4.T6 "Table VI ‣ IV-E RQ4: Comparison
    On Bug Detection and Code Coverage ‣ IV Evaluation ‣ DLLens: Testing Deep Learning
    Libraries via LLM-aided Synthesis")), constituting 43.9% (18 out of 41) of the
    total reported bugs. Among these, 16 were confirmed by developers, and 9 have
    been successfully addressed with fixes. An example is Listing [1](#S1.F1 "Figure
    1 ‣ I Introduction ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis"),
    which is caused by an internal overflow during the computation, resulting in an
    incorrect output of API tf.math.is_non_decreasing. Detection of these incorrect
    result bugs requires the test oracle, which can be effectively addressed by our
    synthesized counterparts. Following the ‘Incorrect’ bugs, the second most prevalent
    category is the bug that API incorrectly rejected valid inputs (’Inc.Rej.’ in
    Table [VI](#S4.T6 "Table VI ‣ IV-E RQ4: Comparison On Bug Detection and Code Coverage
    ‣ IV Evaluation ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis")),
    accounting for 12 out of the total 41 reported bugs. These bugs were also detected
    when execution inconsistency occurs between a DL library API and its counterpart,
    which also demonstrates the usefulness of synthesized counterparts. We notice
    that DLLens has also detected many crash bugs (Crash in Table [VI](#S4.T6 "Table
    VI ‣ IV-E RQ4: Comparison On Bug Detection and Code Coverage ‣ IV Evaluation ‣
    DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis")), which take
    up to 10 out of 41. Although a counterpart is not required to detect these bugs,
    we found that path constraints extracted by DLLens could guide generating test
    inputs triggering these bugs. Taking the bug in Listing [IV-D](#S4.SS4 "IV-D RQ3:
    Effectiveness of Bug Detection ‣ IV Evaluation ‣ DLLens: Testing Deep Learning
    Libraries via LLM-aided Synthesis") as an example, reaching the buggy code requires
    passing two sanity checks which assert the ndims of input argument indices and
    updates to be no less than 1 [[44](#bib.bib44)]. Extracting path constraints,
    including these two sanity checks, can guide generating input reaching the buggy
    code, increasing the probability of triggering this bug.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '表[VI](#S4.T6 "Table VI ‣ IV-E RQ4: Comparison On Bug Detection and Code Coverage
    ‣ IV Evaluation ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis")展示了在TensorFlow和PyTorch中新检测到的缺陷，按缺陷症状进行分类。DLLens检测到的主要缺陷类型是错误结果缺陷（表[VI](#S4.T6
    "Table VI ‣ IV-E RQ4: Comparison On Bug Detection and Code Coverage ‣ IV Evaluation
    ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis")中的''Incorrect''），占总报告缺陷的43.9%（41个中的18个）。其中，16个被开发者确认，9个已成功修复。例如，列表[1](#S1.F1
    "Figure 1 ‣ I Introduction ‣ DLLens: Testing Deep Learning Libraries via LLM-aided
    Synthesis")中的缺陷由计算过程中内部溢出引起，导致API tf.math.is_non_decreasing输出错误。检测这些错误结果缺陷需要测试Oracle，而我们的合成对照可以有效应对。紧随“错误”缺陷之后的是API错误拒绝有效输入（表[VI](#S4.T6
    "Table VI ‣ IV-E RQ4: Comparison On Bug Detection and Code Coverage ‣ IV Evaluation
    ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis")中的''Inc.Rej.''）的缺陷，占总报告缺陷的12个。这些缺陷也在DL库API与其对照之间执行不一致时被检测到，这也展示了合成对照的有效性。我们注意到，DLLens还检测到了许多崩溃错误（表[VI](#S4.T6
    "Table VI ‣ IV-E RQ4: Comparison On Bug Detection and Code Coverage ‣ IV Evaluation
    ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis")中的Crash），占41个中的10个。虽然检测这些缺陷不需要对照，但我们发现DLLens提取的路径约束可以指导生成触发这些缺陷的测试输入。以列表[IV-D](#S4.SS4
    "IV-D RQ3: Effectiveness of Bug Detection ‣ IV Evaluation ‣ DLLens: Testing Deep
    Learning Libraries via LLM-aided Synthesis")中的缺陷为例，到达有缺陷代码需要通过两个有效性检查，这两个检查断言输入参数索引的ndims和更新不少于1[[44](#bib.bib44)]。提取包含这两个有效性检查的路径约束可以指导生成到达有缺陷代码的输入，从而增加触发此缺陷的概率。'
- en: '—Bug Triggering Input—: indices = tf.constant([[[1]]]) updates = tf.constant([16])
    … —Buggy API—: tf.tensor_scatter_nd_update —Buggy Code—: for (int i = 0; i ¡ outer_dims;
    ++i) … —Two Validation Checks Before Reaching The Buggy Code—: OP_REQUIRES(..,
    —indices.shape().dims() ¿= 1—,..); OP_REQUIRES(.., —updates.shape().dims() ¿=
    1—,..);'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: —缺陷触发输入—： indices = tf.constant([[[1]]]) updates = tf.constant([16]) … —有缺陷的API—：
    tf.tensor_scatter_nd_update —有缺陷的代码—： for (int i = 0; i ¡ outer_dims; ++i) … —到达有缺陷代码前的两个验证检查—：
    OP_REQUIRES(.., —indices.shape().dims() ¿= 1—,..); OP_REQUIRES(.., —updates.shape().dims()
    ¿= 1—,..);
- en: 'Figure 11: A Crash Bug and Two Sanity Checks before Reaching the Buggy Line'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：到达有缺陷的代码行前的崩溃错误和两个有效性检查
- en: 'IV-E RQ4: Comparison On Bug Detection and Code Coverage'
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'IV-E RQ4: 错误检测和代码覆盖率的比较'
- en: 'We compared DLLens with two state-of-the-art DL library testing techniques:
    FreeFuzz [[20](#bib.bib20)] and TitanFuzz [[21](#bib.bib21)]. Since neither executables
    nor source codes of FuzzGPT [[32](#bib.bib32)], ACETest [[31](#bib.bib31)], and
    TensorScope [[18](#bib.bib18)] are available, we did not include them as baselines. ³³3Although
    the source code of TensorScope is available, we tried our best but failed to execute
    their tool. Specifically, we randomly sampled 100 TensorFlow APIs and 100 PyTorch
    APIs from the total 739 TensorFlow APIs and 742 PyTorch APIs collected in RQ1.
    For each sampled API, we used each testing technique to generate 300 test inputs
    for testing. We considered the branch coverages of these APIs and the bug detection
    performances as metrics to evaluate their overall performance. Pycoverage [[45](#bib.bib45)]
    and lcov [[46](#bib.bib46)] are used to collect branch coverages for Python and
    C++ code, respectively. When measuring the code coverage, we excluded additional
    coverages added by APIs that are not under test for a fair comparison. In bug
    detection, we manually analyzed reported bugs to filter out false positives.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将DLLens与两种最先进的DL库测试技术进行了比较：FreeFuzz [[20](#bib.bib20)]和TitanFuzz [[21](#bib.bib21)]。由于FuzzGPT [[32](#bib.bib32)]、ACETest [[31](#bib.bib31)]和TensorScope [[18](#bib.bib18)]的可执行文件或源代码均不可用，因此我们没有将它们作为基准。³³3尽管TensorScope的源代码可用，我们尽力尝试但未能成功运行其工具。具体来说，我们从RQ1中收集的739个TensorFlow
    API和742个PyTorch API中，随机抽取了100个TensorFlow API和100个PyTorch API。对于每个抽样的API，我们使用每种测试技术生成300个测试输入进行测试。我们将这些API的分支覆盖率和错误检测性能作为评估其整体性能的指标。Pycoverage [[45](#bib.bib45)]和lcov [[46](#bib.bib46)]分别用于收集Python和C++代码的分支覆盖率。在测量代码覆盖率时，为了公平比较，我们排除了由未测试的API添加的额外覆盖率。在错误检测中，我们手动分析报告的错误，以过滤掉误报。
- en: 'Table [VII](#S4.T7 "Table VII ‣ IV-E RQ4: Comparison On Bug Detection and Code
    Coverage ‣ IV Evaluation ‣ DLLens: Testing Deep Learning Libraries via LLM-aided
    Synthesis") shows the branch coverage and bug detection results. In specific,
    DLLens outperforms the state-of-the-art (i.e., TitanFuzz) by covering 3.3% more
    branches (7,896 v.s. 7,647) in TensorFlow and 13.8% more (6,433 v.s. 5,652) in
    PyTorch. We also notice that DLLens can detect more bugs, i.e., DLLens can detect
    at least 2.5 times as many bugs as baselines. Moreover, we found that most (9
    out of 10) bugs detected by DLLens are either incorrect result bugs or incorrectly
    rejected bugs; detecting these bugs demonstrated the usefulness of counterpart
    synthesized by DLLens.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '表[VII](#S4.T7 "Table VII ‣ IV-E RQ4: Comparison On Bug Detection and Code Coverage
    ‣ IV Evaluation ‣ DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis")显示了分支覆盖率和错误检测结果。具体而言，DLLens在TensorFlow中比最先进技术（即TitanFuzz）多覆盖了3.3%的分支（7,896对7,647），在PyTorch中多覆盖了13.8%（6,433对5,652）。我们还注意到，DLLens能够检测到更多的错误，即DLLens能检测到至少2.5倍于基准的错误。此外，我们发现DLLens检测到的大多数（10个中有9个）错误要么是错误结果错误，要么是错误拒绝错误；检测这些错误展示了DLLens所合成的对应工具的有效性。'
- en: 'TABLE VI: Effectiveness of Bug Detection'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '表VI: 错误检测的有效性'
- en: '| Library Name | Inc. Rej. | Incorrect | Imp.Err.Msg | Crash | Subtotal |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| Library Name | Inc. Rej. | Incorrect | Imp.Err.Msg | Crash | Subtotal |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| TensorFlow | 11 (4/9) | 15 (8/15) | 1 (1/1) | 3 (1/3) | 30 (14/28) |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| TensorFlow | 11 (4/9) | 15 (8/15) | 1 (1/1) | 3 (1/3) | 30 (14/28) |'
- en: '| PyTorch | 1 (0/1) | 3 (1/3) | 0 (0/0) | 7 (4/7) | 11 (5/11) |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| PyTorch | 1 (0/1) | 3 (1/3) | 0 (0/0) | 7 (4/7) | 11 (5/11) |'
- en: '1'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '1'
- en: Numbers of confirmed and fixed bugs are parenthesized. The number of confirmed
    bugs is the denominator in parentheses; the number of fixed bug is the numerator
    in parentheses.
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 确认和修复的错误数量以括号标注。括号中的分母是确认的错误数量；分子是修复的错误数量。
- en: 'TABLE VII: Code Coverage and Bug Detection'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '表VII: 代码覆盖率和错误检测'
- en: '| Baseline | TensorFlow | PyTorch | Total Bugs |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| Baseline | TensorFlow | PyTorch | Total Bugs |'
- en: '| --- | --- | --- | --- |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Branch | Bug | Branch | Bug |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| Branch | Bug | Branch | Bug |'
- en: '| --- | --- | --- | --- |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| DLLens | 7,896 | 7 | 6,433 | 3 | 10 |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| DLLens | 7,896 | 7 | 6,433 | 3 | 10 |'
- en: '| TitanFuzz | 7,647 | 2 | 5,652 | 1 | 3 |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| TitanFuzz | 7,647 | 2 | 5,652 | 1 | 3 |'
- en: '| FreeFuzz | 6,822 | 4 | 5,382 | 0 | 4 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| FreeFuzz | 6,822 | 4 | 5,382 | 0 | 4 |'
- en: V Discussions
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V 讨论
- en: 'False Positives of Bug Detection. We summarized two types of false positives:
    First, some false positives are introduced by invalid counterparts synthesized
    by DLLens. This is because we only use a non-empty valid input set with at most
    three valid inputs to validate the synthesized counterpart and such a limited
    size of valid input may introduce some false positives, i.e., some synthesized
    counterparts passing the validation process may only be valid under specific input
    conditions (e.g., some counterparts are valid when the input is a vector while
    invalid when input is a matrix). As a result, the output inconsistencies w.r.t
    these inputs between APIs under test and their counterparts may be false positives.
    To understand the influence of these false positives, we manually analyze all
    inconsistencies reported by DLLens in RQ4, which includes 200 APIs and their counterparts.
    According to our analysis, only 27 false positives inconsistencies reported by
    DLLens were caused by invalid counterparts, which cost ~1.5 hours to filter out.
    Considering the effectiveness of DLLens in detecting real bugs, we believe such
    overhead introduced by these invalid counterparts is affordable.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 错误的 bug 检测。我们总结了两种类型的假阳性：首先，一些假阳性是由 DLLens 合成的无效对应体引入的。这是因为我们仅使用一个包含最多三个有效输入的非空有效输入集来验证合成的对应体，而如此有限的有效输入规模可能会引入一些假阳性，即一些通过验证过程的合成对应体可能仅在特定输入条件下有效（例如，当输入是向量时某些对应体有效，而当输入是矩阵时则无效）。因此，测试
    API 与其对应体在这些输入下的输出不一致可能是假阳性。为了了解这些假阳性的影响，我们手动分析了 RQ4 中 DLLens 报告的所有不一致情况，包括 200
    个 API 及其对应体。根据我们的分析，仅 27 个 DLLens 报告的假阳性不一致是由无效对应体引起的，过滤这些不一致花费了大约 1.5 小时。考虑到
    DLLens 在检测真实 bug 方面的有效性，我们认为这些无效对应体引入的开销是可以接受的。
- en: Another type of false positive is introduced by inconsistent behavior between
    libraries when handling special values such as NaN [[47](#bib.bib47)]. Since inconsistencies
    caused by these special values are not many (e.g., less than 10 in RQ4), we manually
    check the documentation of the API under test with all APIs in its counterpart
    and filter out false positives.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种假阳性是由库在处理特殊值（如 NaN）时行为不一致引起的[[47](#bib.bib47)]。由于这些特殊值引起的不一致较少（例如，在 RQ4 中不到
    10 个），我们手动检查了测试 API 与其所有对应体的文档，并过滤掉了假阳性。
- en: Threat to Validity. In RQ2 and RQ4, we compared DLLens with state-of-the-art
    techniques on all DL library APIs that DLLens could identify counterparts for.
    It should be noted that these APIs constitute only a subset of the total DL library
    APIs, potentially limiting the comprehensiveness of our performance evaluation.
    To address this potential limitation, we conducted a measurement of the number
    of APIs considered in RQ2 and RQ4, which accounted for nearly half of the total
    DL library APIs. Based on this analysis, we make the assumption that the APIs
    covered in our study adequately represent the performance of DL library testing
    techniques.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 有效性的威胁。在 RQ2 和 RQ4 中，我们将 DLLens 与最先进的技术进行了比较，涵盖了 DLLens 能够识别出对应关系的所有 DL 库 API。需要注意的是，这些
    API 仅构成了总 DL 库 API 的一个子集，可能会限制我们性能评估的全面性。为了应对这一潜在的限制，我们对 RQ2 和 RQ4 中考虑的 API 数量进行了测量，这些
    API 占总 DL 库 API 的近一半。基于这一分析，我们假设我们研究中涵盖的 API 足以代表 DL 库测试技术的性能。
- en: VI Conclusion
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VI 结论
- en: In this paper, we propose a novel technique named DLLens to test DL libraries
    DLLens facilitates differential testing by using a novel counterpart synthesis
    method and generates diverse test inputs to explore execution paths via an effective
    path constraint extraction method. DLLens can synthesize counterparts for 41.47%
    TensorFlow APIs and 62.67% PyTorch APIs, which double the result of the state-of-the-art
    approaches. Benefiting from the synthesized counterparts and effective path constraint
    extraction, DLLens can outperform state-of-the-art approaches in terms of constraint
    extraction, bug detection, and branch coverage. In total, DLLens detects 56including
    41new bugs. So far, 39of these new bugs have been confirmed and 19 of them are
    fixed by developers.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们提出了一种名为 DLLens 的新技术来测试 DL 库。DLLens 通过使用一种新颖的对应体合成方法促进了差异测试，并生成了多样化的测试输入，通过有效的路径约束提取方法来探索执行路径。DLLens
    能够为 41.47% 的 TensorFlow API 和 62.67% 的 PyTorch API 合成对应体，这一结果是最先进方法的两倍。得益于合成的对应体和有效的路径约束提取，DLLens
    在约束提取、bug 检测和分支覆盖率方面超越了最先进的方法。总的来说，DLLens 检测了 56 个 bug，包括 41 个新 bug。迄今为止，这些新 bug
    中的 39 个已经被确认，19 个已经被开发人员修复。
- en: References
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] R. Das, A. Gadre, S. Zhang, S. Kumar, and J. M. F. Moura, “A deep learning
    approach to iot authentication,” in *2018 IEEE International Conference on Communications
    (ICC)*.   Kansas City, MO, USA: IEEE, 2018, pp. 1–6.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] R. Das, A. Gadre, S. Zhang, S. Kumar, 和 J. M. F. Moura, “一种深度学习方法用于物联网身份验证”，在*2018
    IEEE国际通信大会（ICC）*。 堪萨斯城，密苏里州，美国：IEEE，2018年，第1–6页。'
- en: '[2] A. Ferdowsi and W. Saad, “Deep learning for signal authentication and security
    in massive internet-of-things systems,” *IEEE Transactions on Communications*,
    vol. 67, pp. 1371–1387, 2019.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] A. Ferdowsi 和 W. Saad, “深度学习在大规模物联网系统中的信号认证和安全性”，*IEEE通信杂志*，第67卷，第1371–1387页，2019年。'
- en: '[3] G. Litjens, T. Kooi, B. E. Bejnordi, A. A. A. Setio, F. Ciompi, M. Ghafoorian,
    J. A. Van Der Laak, B. Van Ginneken, and C. I. Sánchez, “A survey on deep learning
    in medical image analysis,” *Medical image analysis*, vol. 42, pp. 60–88, 2017.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] G. Litjens, T. Kooi, B. E. Bejnordi, A. A. A. Setio, F. Ciompi, M. Ghafoorian,
    J. A. Van Der Laak, B. Van Ginneken, 和 C. I. Sánchez, “关于深度学习在医学图像分析中的应用的调查”，*医学图像分析*，第42卷，第60–88页，2017年。'
- en: '[4] C. Chen, A. Seff, A. Kornhauser, and J. Xiao, “Deepdriving: Learning affordance
    for direct perception in autonomous driving,” in *2015 IEEE International Conference
    on Computer Vision (ICCV)*.   Santiago, Chile: IEEE, 2015, pp. 2722–2730.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] C. Chen, A. Seff, A. Kornhauser, 和 J. Xiao, “Deepdriving: 学习自动驾驶中的直接感知能力”，在*2015
    IEEE国际计算机视觉会议（ICCV）*。 圣地亚哥，智利：IEEE，2015年，第2722–2730页。'
- en: '[5] A. E. Sallab, M. Abdou, E. Perot, and S. Yogamani, “Deep reinforcement
    learning framework for autonomous driving,” 2017.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] A. E. Sallab, M. Abdou, E. Perot, 和 S. Yogamani, “用于自动驾驶的深度强化学习框架”，2017年。'
- en: '[6] S. Shalev-Shwartz, S. Shammah, and A. Shashua, “Safe, multi-agent, reinforcement
    learning for autonomous driving,” 2016.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] S. Shalev-Shwartz, S. Shammah, 和 A. Shashua, “安全的多智能体强化学习用于自动驾驶”，2016年。'
- en: '[7] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen,
    Z. Lin, N. Gimelshein, L. Antiga, A. Desmaison, A. Köpf, E. Yang, Z. DeVito, M. Raison,
    A. Tejani, S. Chilamkurthy, B. Steiner, L. Fang, J. Bai, and S. Chintala, *PyTorch:
    An Imperative Style, High-Performance Deep Learning Library*.   Red Hook, NY,
    USA: Curran Associates Inc., 2019.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen,
    Z. Lin, N. Gimelshein, L. Antiga, A. Desmaison, A. Köpf, E. Yang, Z. DeVito, M.
    Raison, A. Tejani, S. Chilamkurthy, B. Steiner, L. Fang, J. Bai, 和 S. Chintala,
    *PyTorch: 一种命令式风格的高性能深度学习库*。 红钩，纽约，美国：Curran Associates Inc.，2019年。'
- en: '[8] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin, S. Ghemawat,
    G. Irving, M. Isard, M. Kudlur, J. Levenberg, R. Monga, S. Moore, D. G. Murray,
    B. Steiner, P. Tucker, V. Vasudevan, P. Warden, M. Wicke, Y. Yu, and X. Zheng,
    “Tensorflow: A system for large-scale machine learning,” in *Proceedings of the
    12th USENIX Conference on Operating Systems Design and Implementation*, ser. OSDI’16.   USA:
    USENIX Association, 2016, p. 265–283.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin, S.
    Ghemawat, G. Irving, M. Isard, M. Kudlur, J. Levenberg, R. Monga, S. Moore, D.
    G. Murray, B. Steiner, P. Tucker, V. Vasudevan, P. Warden, M. Wicke, Y. Yu, 和
    X. Zheng, “Tensorflow: 一个大规模机器学习系统”，在*第12届USENIX操作系统设计与实现会议*，序列号OSDI’16。 美国：USENIX协会，2016年，第265–283页。'
- en: '[9] F. Tambon, A. Nikanjam, L. An, F. Khomh, and G. Antoniol, “Silent bugs
    in deep learning frameworks: An empirical study of keras and tensorflow,” 2021.
    [Online]. Available: [https://arxiv.org/abs/2112.13314](https://arxiv.org/abs/2112.13314)'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] F. Tambon, A. Nikanjam, L. An, F. Khomh, 和 G. Antoniol, “深度学习框架中的隐性漏洞：对keras和tensorflow的实证研究”，2021年。
    [在线]. 可用： [https://arxiv.org/abs/2112.13314](https://arxiv.org/abs/2112.13314)'
- en: '[10] Y. Yang, T. He, Z. Xia, and Y. Feng, “A comprehensive empirical study
    on bug characteristics of deep learning frameworks,” *Information and Software
    Technology*, vol. 151, p. 107004, 2022\. [Online]. Available: [https://www.sciencedirect.com/science/article/pii/S0950584922001306](https://www.sciencedirect.com/science/article/pii/S0950584922001306)'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Y. Yang, T. He, Z. Xia, 和 Y. Feng, “对深度学习框架中的漏洞特征的全面实证研究”，*信息与软件技术*，第151卷，第107004页，2022年。
    [在线]. 可用： [https://www.sciencedirect.com/science/article/pii/S0950584922001306](https://www.sciencedirect.com/science/article/pii/S0950584922001306)'
- en: '[11] Y. Zhang, Y. Chen, S.-C. Cheung, Y. Xiong, and L. Zhang, “An empirical
    study on tensorflow program bugs,” in *Proceedings of the 27th ACM SIGSOFT International
    Symposium on Software Testing and Analysis*, ser. ISSTA 2018.   New York, NY,
    USA: Association for Computing Machinery, 2018, p. 129–140\. [Online]. Available:
    [https://doi.org/10.1145/3213846.3213866](https://doi.org/10.1145/3213846.3213866)'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Y. Zhang, Y. Chen, S.-C. Cheung, Y. Xiong, 和 L. Zhang, “对tensorflow程序漏洞的实证研究”，在*第27届ACM
    SIGSOFT国际软件测试与分析研讨会*，序列号ISSTA 2018。 纽约，纽约，美国：计算机协会，2018年，第129–140页。 [在线]. 可用：
    [https://doi.org/10.1145/3213846.3213866](https://doi.org/10.1145/3213846.3213866)'
- en: '[12] J. Chen, Y. Liang, Q. Shen, and J. Jiang, “Toward understanding deep learning
    framework bugs,” 2022\. [Online]. Available: [https://arxiv.org/abs/2203.04026](https://arxiv.org/abs/2203.04026)'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] J. Chen, Y. Liang, Q. Shen, 和 J. Jiang，"理解深度学习框架缺陷"，2022年。[在线]. 可用: [https://arxiv.org/abs/2203.04026](https://arxiv.org/abs/2203.04026)'
- en: '[13] Y. Xiong, M. Xu, T. Su, J. Sun, J. Wang, H. Wen, G. Pu, J. He, and Z. Su,
    “An empirical study of functional bugs in android apps,” in *Proceedings of the
    32nd ACM SIGSOFT International Symposium on Software Testing and Analysis*, ser.
    ISSTA 2023.   New York, NY, USA: Association for Computing Machinery, 2023, p.
    1319–1331\. [Online]. Available: [https://doi.org/10.1145/3597926.3598138](https://doi.org/10.1145/3597926.3598138)'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Y. Xiong, M. Xu, T. Su, J. Sun, J. Wang, H. Wen, G. Pu, J. He, 和 Z. Su，"安卓应用中的功能性缺陷的实证研究"，在*第32届ACM
    SIGSOFT国际软件测试与分析研讨会论文集*中，系列 ISSTA 2023。美国纽约：计算机协会，2023年，第1319–1331页。[在线]. 可用:
    [https://doi.org/10.1145/3597926.3598138](https://doi.org/10.1145/3597926.3598138)'
- en: '[14] H. V. Pham, T. Lutellier, W. Qi, and L. Tan, “Cradle: cross-backend validation
    to detect and localize bugs in deep learning libraries,” in *2019 IEEE/ACM 41st
    International Conference on Software Engineering (ICSE)*, IEEE.   Montreal, QC,
    Canada: IEEE, 2019, pp. 1027–1038.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] H. V. Pham, T. Lutellier, W. Qi, 和 L. Tan，"Cradle: 跨后端验证以检测和定位深度学习库中的缺陷"，在*2019
    IEEE/ACM 第41届国际软件工程会议 (ICSE)*中，IEEE。加拿大蒙特利尔：IEEE，2019年，第1027–1038页。'
- en: '[15] Z. Wang, M. Yan, J. Chen, S. Liu, and D. Zhang, “Deep learning library
    testing via effective model generation,” in *Proceedings of the 28th ACM Joint
    Meeting on European Software Engineering Conference and Symposium on the Foundations
    of Software Engineering*, ser. ESEC/FSE 2020.   New York, NY, USA: Association
    for Computing Machinery, 2020, p. 788–799\. [Online]. Available: [https://doi.org/10.1145/3368089.3409761](https://doi.org/10.1145/3368089.3409761)'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Z. Wang, M. Yan, J. Chen, S. Liu, 和 D. Zhang，"通过有效模型生成进行深度学习库测试"，在*第28届ACM欧洲软件工程会议暨软件工程基础研讨会联合会议论文集*中，系列
    ESEC/FSE 2020。美国纽约：计算机协会，2020年，第788–799页。[在线]. 可用: [https://doi.org/10.1145/3368089.3409761](https://doi.org/10.1145/3368089.3409761)'
- en: '[16] J. Gu, X. Luo, Y. Zhou, and X. Wang, “Muffin: Testing deep learning libraries
    via neural architecture fuzzing,” in *Proceedings of the 44th International Conference
    on Software Engineering*, ser. ICSE ’22.   New York, NY, USA: Association for
    Computing Machinery, 2022, p. 1418–1430\. [Online]. Available: [https://doi.org/10.1145/3510003.3510092](https://doi.org/10.1145/3510003.3510092)'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] J. Gu, X. Luo, Y. Zhou, 和 X. Wang，"Muffin: 通过神经架构模糊测试深度学习库"，在*第44届国际软件工程会议论文集*中，系列
    ICSE ’22。美国纽约：计算机协会，2022年，第1418–1430页。[在线]. 可用: [https://doi.org/10.1145/3510003.3510092](https://doi.org/10.1145/3510003.3510092)'
- en: '[17] M. Li, J. Cao, Y. Tian, T. O. Li, M. Wen, and S.-C. Cheung, “Comet: Coverage-guided
    model generation for deep learning library testing,” *ACM Trans. Softw. Eng. Methodol.*,
    vol. 32, no. 5, jul 2023\. [Online]. Available: [https://doi.org/10.1145/3583566](https://doi.org/10.1145/3583566)'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] M. Li, J. Cao, Y. Tian, T. O. Li, M. Wen, 和 S.-C. Cheung，"Comet: 基于覆盖率的深度学习库测试模型生成"，*ACM
    Trans. Softw. Eng. Methodol.*，第32卷，第5期，2023年7月。[在线]. 可用: [https://doi.org/10.1145/3583566](https://doi.org/10.1145/3583566)'
- en: '[18] Z. Deng, G. Meng, K. Chen, T. Liu, L. Xiang, and C. Chen, “Differential
    testing of cross deep learning framework APIs: Revealing inconsistencies and vulnerabilities,”
    in *32nd USENIX Security Symposium (USENIX Security 23)*.   Anaheim, CA: USENIX
    Association, Aug. 2023, pp. 7393–7410\. [Online]. Available: [https://www.usenix.org/conference/usenixsecurity23/presentation/deng-zizhuang](https://www.usenix.org/conference/usenixsecurity23/presentation/deng-zizhuang)'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Z. Deng, G. Meng, K. Chen, T. Liu, L. Xiang, 和 C. Chen，"跨深度学习框架API的差异测试：揭示不一致性和漏洞"，在*第32届USENIX安全研讨会
    (USENIX Security 23)*中。加州安纳海姆：USENIX协会，2023年8月，第7393–7410页。[在线]. 可用: [https://www.usenix.org/conference/usenixsecurity23/presentation/deng-zizhuang](https://www.usenix.org/conference/usenixsecurity23/presentation/deng-zizhuang)'
- en: '[19] T. Onnx, “tf2onnx - convert tensorflow, keras, tensorflow.js and tflite
    models to onnx.” [https://github.com/onnx/tensorflow-onnx](https://github.com/onnx/tensorflow-onnx),
    Accessed: 2022.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] T. Onnx，"tf2onnx - 将tensorflow, keras, tensorflow.js 和 tflite 模型转换为onnx"。
    [https://github.com/onnx/tensorflow-onnx](https://github.com/onnx/tensorflow-onnx)，访问日期：2022年。'
- en: '[20] A. Wei, Y. Deng, C. Yang, and L. Zhang, “Free lunch for testing: Fuzzing
    deep-learning libraries from open source,” in *Proceedings of the 44th International
    Conference on Software Engineering*, ser. ICSE ’22.   New York, NY, USA: Association
    for Computing Machinery, 2022, p. 995–1007\. [Online]. Available: [https://doi.org/10.1145/3510003.3510041](https://doi.org/10.1145/3510003.3510041)'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] A. Wei, Y. Deng, C. Yang, 和 L. Zhang，“测试的免费午餐：从开源进行深度学习库的模糊测试”，收录于 *第44届国际软件工程大会论文集*，系列
    ICSE ’22。纽约，美国：计算机协会，2022，第995–1007页。[在线]. 可访问：[https://doi.org/10.1145/3510003.3510041](https://doi.org/10.1145/3510003.3510041)'
- en: '[21] Y. Deng, C. S. Xia, H. Peng, C. Yang, and L. Zhang, “Large language models
    are zero-shot fuzzers: Fuzzing deep-learning libraries via large language models,”
    in *Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing
    and Analysis*, ser. ISSTA 2023.   New York, NY, USA: Association for Computing
    Machinery, 2023, p. 423–435\. [Online]. Available: [https://doi.org/10.1145/3597926.3598067](https://doi.org/10.1145/3597926.3598067)'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] Y. Deng, C. S. Xia, H. Peng, C. Yang, 和 L. Zhang，“大语言模型作为零-shot 模糊测试工具：通过大语言模型对深度学习库进行模糊测试”，收录于
    *第32届ACM SIGSOFT国际软件测试与分析研讨会论文集*，系列 ISSTA 2023。纽约，美国：计算机协会，2023，第423–435页。[在线].
    可访问：[https://doi.org/10.1145/3597926.3598067](https://doi.org/10.1145/3597926.3598067)'
- en: '[22] J. Wang, T. Lutellier, S. Qian, H. V. Pham, and L. Tan, “Eagle: Creating
    equivalent graphs to test deep learning libraries,” in *2022 IEEE/ACM 44th International
    Conference on Software Engineering (ICSE)*.   Pittsburgh, PA, USA: IEEE, 2022,
    pp. 798–810.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] J. Wang, T. Lutellier, S. Qian, H. V. Pham, 和 L. Tan，“Eagle：创建等效图以测试深度学习库”，收录于
    *2022 IEEE/ACM 第44届国际软件工程大会（ICSE）*。匹兹堡，美国：IEEE，2022，第798–810页。'
- en: '[23] C. Yang, Y. Deng, J. Yao, Y. Tu, H. Li, and L. Zhang, “Fuzzing automatic
    differentiation in deep-learning libraries,” in *Proceedings of the 45th International
    Conference on Software Engineering*, ser. ICSE ’23.   Melbourne, Australia: IEEE
    Press, 2023, p. 1174–1186\. [Online]. Available: [https://doi.org/10.1109/ICSE48619.2023.00105](https://doi.org/10.1109/ICSE48619.2023.00105)'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] C. Yang, Y. Deng, J. Yao, Y. Tu, H. Li, 和 L. Zhang，“对深度学习库中的自动微分进行模糊测试”，收录于
    *第45届国际软件工程大会论文集*，系列 ICSE ’23。墨尔本，澳大利亚：IEEE出版社，2023，第1174–1186页。[在线]. 可访问：[https://doi.org/10.1109/ICSE48619.2023.00105](https://doi.org/10.1109/ICSE48619.2023.00105)'
- en: '[24] Y. Deng, C. Yang, A. Wei, and L. Zhang, “Fuzzing deep-learning libraries
    via automated relational api inference,” in *Proceedings of the 30th ACM Joint
    European Software Engineering Conference and Symposium on the Foundations of Software
    Engineering*, ser. ESEC/FSE 2022.   New York, NY, USA: Association for Computing
    Machinery, 2022, p. 44–56\. [Online]. Available: [https://doi.org/10.1145/3540250.3549085](https://doi.org/10.1145/3540250.3549085)'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Y. Deng, C. Yang, A. Wei, 和 L. Zhang，“通过自动化关系API推断对深度学习库进行模糊测试”，收录于 *第30届ACM欧洲联合软件工程会议及软件工程基础研讨会论文集*，系列
    ESEC/FSE 2022。纽约，美国：计算机协会，2022，第44–56页。[在线]. 可访问：[https://doi.org/10.1145/3540250.3549085](https://doi.org/10.1145/3540250.3549085)'
- en: '[25] TensorFlow, “tf.math.is_non_decreasing outputs incorrect result when input
    is an uint tensor,” [https://github.com/tensorflow/tensorflow/issues/62072](https://github.com/tensorflow/tensorflow/issues/62072),
    Accessed: March, 2024.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] TensorFlow，“tf.math.is_non_decreasing 在输入为 uint tensor 时输出错误结果”，[https://github.com/tensorflow/tensorflow/issues/62072](https://github.com/tensorflow/tensorflow/issues/62072)，访问时间：2024年3月。'
- en: '[26] W. Luo, D. Chai, X. Run, J. Wang, C. Fang, and Z. Chen, “Graph-based fuzz
    testing for deep learning inference engines,” in *Proceedings of the 43rd International
    Conference on Software Engineering*, ser. ICSE ’21.   Madrid, Spain: IEEE Press,
    2021, p. 288–299\. [Online]. Available: [https://doi.org/10.1109/ICSE43902.2021.00037](https://doi.org/10.1109/ICSE43902.2021.00037)'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] W. Luo, D. Chai, X. Run, J. Wang, C. Fang, 和 Z. Chen，“基于图的深度学习推理引擎模糊测试”，收录于
    *第43届国际软件工程大会论文集*，系列 ICSE ’21。马德里，西班牙：IEEE出版社，2021，第288–299页。[在线]. 可访问：[https://doi.org/10.1109/ICSE43902.2021.00037](https://doi.org/10.1109/ICSE43902.2021.00037)'
- en: '[27] TensorFlow, “slient overflow occurs in tf.range leading to incorrect result,
    here is a possible fix,” [https://github.com/tensorflow/tensorflow/issues/64081](https://github.com/tensorflow/tensorflow/issues/64081),
    Accessed: March, 2024.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] TensorFlow，“tf.range 中发生静默溢出导致错误结果，这里有一个可能的修复”，[https://github.com/tensorflow/tensorflow/issues/64081](https://github.com/tensorflow/tensorflow/issues/64081)，访问时间：2024年3月。'
- en: '[28] stack overflow, “How can i know if a list is decreasing? (python),” [https://stackoverflow.com/questions/69576011/how-can-i-know-if-a-list-is-decreasing-python](https://stackoverflow.com/questions/69576011/how-can-i-know-if-a-list-is-decreasing-python),
    Accessed: March, 2024.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] stack overflow，“我怎么知道一个列表是否在递减？（python）”， [https://stackoverflow.com/questions/69576011/how-can-i-know-if-a-list-is-decreasing-python](https://stackoverflow.com/questions/69576011/how-can-i-know-if-a-list-is-decreasing-python)，访问时间：2024
    年 3 月。'
- en: '[29] Q. Guo, X. Xie, Y. Li, X. Zhang, Y. Liu, X. Li, and C. Shen, “Audee: Automated
    testing for deep learning frameworks,” in *2020 35th IEEE/ACM International Conference
    on Automated Software Engineering (ASE)*.   Melbourne, VIC, Australia: IEEE, 2020,
    pp. 486–498.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Q. Guo, X. Xie, Y. Li, X. Zhang, Y. Liu, X. Li, 和 C. Shen，“Audee：深度学习框架的自动化测试”，发表于*2020
    第35届 IEEE/ACM 自动化软件工程国际会议（ASE）*。墨尔本，VIC，澳大利亚：IEEE，2020，第 486–498 页。'
- en: '[30] D. Xie, Y. Li, M. Kim, H. V. Pham, L. Tan, X. Zhang, and M. W. Godfrey,
    “Docter: Documentation-guided fuzzing for testing deep learning api functions,”
    in *Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing
    and Analysis*, ser. ISSTA 2022.   New York, NY, USA: Association for Computing
    Machinery, 2022, p. 176–188\. [Online]. Available: [https://doi.org/10.1145/3533767.3534220](https://doi.org/10.1145/3533767.3534220)'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] D. Xie, Y. Li, M. Kim, H. V. Pham, L. Tan, X. Zhang, 和 M. W. Godfrey，“Docter：用于测试深度学习
    API 函数的文档引导模糊测试”，发表于*第31届 ACM SIGSOFT 国际软件测试与分析研讨会论文集*，系列 ISSTA 2022。纽约，NY，美国：计算机协会，2022，第
    176–188 页。[在线]. 可用： [https://doi.org/10.1145/3533767.3534220](https://doi.org/10.1145/3533767.3534220)'
- en: '[31] J. Shi, Y. Xiao, Y. Li, Y. Li, D. Yu, C. Yu, H. Su, Y. Chen, and W. Huo,
    “Acetest: Automated constraint extraction for testing deep learning operators,”
    in *Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing
    and Analysis*, ser. ISSTA 2023.   New York, NY, USA: Association for Computing
    Machinery, 2023, p. 690–702\. [Online]. Available: [https://doi.org/10.1145/3597926.3598088](https://doi.org/10.1145/3597926.3598088)'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] J. Shi, Y. Xiao, Y. Li, Y. Li, D. Yu, C. Yu, H. Su, Y. Chen, 和 W. Huo，“Acetest：用于测试深度学习操作符的自动化约束提取”，发表于*第32届
    ACM SIGSOFT 国际软件测试与分析研讨会论文集*，系列 ISSTA 2023。纽约，NY，美国：计算机协会，2023，第 690–702 页。[在线].
    可用： [https://doi.org/10.1145/3597926.3598088](https://doi.org/10.1145/3597926.3598088)'
- en: '[32] Y. Deng, C. S. Xia, C. Yang, S. D. Zhang, S. Yang, and L. Zhang, “Large
    language models are edge-case generators: Crafting unusual programs for fuzzing
    deep learning libraries,” in *Proceedings of the 46th IEEE/ACM International Conference
    on Software Engineering*, ser. ICSE ’24.   New York, NY, USA: Association for
    Computing Machinery, 2024\. [Online]. Available: [https://doi.org/10.1145/3597503.3623343](https://doi.org/10.1145/3597503.3623343)'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] Y. Deng, C. S. Xia, C. Yang, S. D. Zhang, S. Yang, 和 L. Zhang，“大型语言模型是边界案例生成器：为深度学习库设计不寻常的程序”，发表于*第46届
    IEEE/ACM 国际软件工程会议论文集*，系列 ICSE ’24。纽约，NY，美国：计算机协会，2024。[在线]. 可用： [https://doi.org/10.1145/3597503.3623343](https://doi.org/10.1145/3597503.3623343)'
- en: '[33] R. Baldoni, E. Coppa, D. C. D’elia, C. Demetrescu, and I. Finocchi, “A
    survey of symbolic execution techniques,” *ACM Comput. Surv.*, vol. 51, no. 3,
    may 2018\. [Online]. Available: [https://doi.org/10.1145/3182657](https://doi.org/10.1145/3182657)'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] R. Baldoni, E. Coppa, D. C. D’elia, C. Demetrescu, 和 I. Finocchi，“符号执行技术综述”，*ACM
    Comput. Surv.*，第 51 卷，第 3 期，2018 年 5 月。[在线]. 可用： [https://doi.org/10.1145/3182657](https://doi.org/10.1145/3182657)'
- en: '[34] L. de Moura and N. Bjørner, “Z3: An efficient smt solver,” in *Tools and
    Algorithms for the Construction and Analysis of Systems*, C. R. Ramakrishnan and
    J. Rehof, Eds.   Berlin, Heidelberg: Springer Berlin Heidelberg, 2008, pp. 337–340.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] L. de Moura 和 N. Bjørner，“Z3：一种高效的 SMT 求解器”，发表于*系统构建与分析工具及算法*，C. R. Ramakrishnan
    和 J. Rehof 编。柏林，海德堡：施普林格·柏林·海德堡，2008，第 337–340 页。'
- en: '[35] A. Fan, B. Gokkaya, M. Harman, M. Lyubarskiy, S. Sengupta, S. Yoo, and
    J. M. Zhang, “Large language models for software engineering: Survey and open
    problems,” 2023.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] A. Fan, B. Gokkaya, M. Harman, M. Lyubarskiy, S. Sengupta, S. Yoo, 和 J.
    M. Zhang，“大型语言模型在软件工程中的应用：调查与开放问题”，2023 年。'
- en: '[36] W. Song, S. Oh, S. Mo, J. Kim, S. Yun, J.-W. Ha, and J. Shin, “Hierarchical
    context merging: Better long context understanding for pre-trained LLMs,” in *The
    Twelfth International Conference on Learning Representations*, 2024\. [Online].
    Available: [https://openreview.net/forum?id=ulaUJFd96G](https://openreview.net/forum?id=ulaUJFd96G)'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] W. Song, S. Oh, S. Mo, J. Kim, S. Yun, J.-W. Ha, 和 J. Shin，“层次化上下文合并：更好的长上下文理解用于预训练的
    LLMs”，发表于*第十二届国际学习表示会议*，2024。[在线]. 可用： [https://openreview.net/forum?id=ulaUJFd96G](https://openreview.net/forum?id=ulaUJFd96G)'
- en: '[37] I. Ozkaya, “Application of large language models to software engineering
    tasks: Opportunities, risks, and implications,” *IEEE Software*, vol. 40, no. 3,
    pp. 4–8, 2023.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] I. Ozkaya，“大语言模型在软件工程任务中的应用：机遇、风险及影响，” *IEEE Software*，第40卷，第3期，页 4–8，2023年。'
- en: '[38] J. Vanover, X. Deng, and C. Rubio-González, “Discovering discrepancies
    in numerical libraries,” in *Proceedings of the 29th ACM SIGSOFT International
    Symposium on Software Testing and Analysis*, ser. ISSTA 2020.   New York, NY,
    USA: Association for Computing Machinery, 2020, p. 488–501\. [Online]. Available:
    [https://doi.org/10.1145/3395363.3397380](https://doi.org/10.1145/3395363.3397380)'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] J. Vanover, X. Deng, 和 C. Rubio-González，“发现数值库中的差异，” 见于 *第29届ACM SIGSOFT国际软件测试与分析研讨会论文集*，系列
    ISSTA 2020. 纽约, NY, USA: 计算机协会, 2020, 页 488–501\. [在线]. 可用: [https://doi.org/10.1145/3395363.3397380](https://doi.org/10.1145/3395363.3397380)'
- en: '[39] OpenAI, “Openai chat completion api reference,” [https://platform.openai.com/docs/api-reference/chat/create](https://platform.openai.com/docs/api-reference/chat/create),
    Accessed: March, 2024.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] OpenAI，“OpenAI 聊天完成 API 参考，” [https://platform.openai.com/docs/api-reference/chat/create](https://platform.openai.com/docs/api-reference/chat/create)，访问时间:
    2024年3月。'
- en: '[40] Python, “Python ast package,” [https://docs.python.org/3/library/ast.html](https://docs.python.org/3/library/ast.html),
    Accessed: March, 2024.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] Python，“Python ast 包，” [https://docs.python.org/3/library/ast.html](https://docs.python.org/3/library/ast.html)，访问时间:
    2024年3月。'
- en: '[41] M. Brunsfeld *et al.*, “Tree-sitter: A parser generator tool and an incremental
    parsing library,” 2024\. [Online]. Available: [https://github.com/tree-sitter/tree-sitter](https://github.com/tree-sitter/tree-sitter)'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] M. Brunsfeld *等人*，“Tree-sitter: 一种解析器生成工具及增量解析库，” 2024\. [在线]. 可用: [https://github.com/tree-sitter/tree-sitter](https://github.com/tree-sitter/tree-sitter)'
- en: '[42] V. Salis, T. Sotiropoulos, P. Louridas, D. Spinellis, and D. Mitropoulos,
    “Pycg: Practical call graph generation in python,” in *2021 IEEE/ACM 43rd International
    Conference on Software Engineering (ICSE)*, 2021, pp. 1646–1657.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] V. Salis, T. Sotiropoulos, P. Louridas, D. Spinellis, 和 D. Mitropoulos，“Pycg:
    Python中的实用调用图生成，” 见于 *2021 IEEE/ACM 第43届国际软件工程会议（ICSE）*，2021年，页 1646–1657。'
- en: '[43] Joern, “The bug hunter’s workbench,” [https://joern.io](https://joern.io),
    Accessed: March, 2024.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] Joern，“错误检测工具的工作台，” [https://joern.io](https://joern.io)，访问时间: 2024年3月。'
- en: '[44] TensorFlow, “tf.tensor_scatter_nd_update lead to a program abortion when
    receiving a 3d indices,” [https://github.com/tensorflow/tensorflow/issues/63575](https://github.com/tensorflow/tensorflow/issues/63575),
    Accessed: March, 2024.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] TensorFlow，“tf.tensor_scatter_nd_update 在接收到 3d 索引时导致程序中止，” [https://github.com/tensorflow/tensorflow/issues/63575](https://github.com/tensorflow/tensorflow/issues/63575)，访问时间:
    2024年3月。'
- en: '[45] “coverage.py,” 2021\. [Online]. Available: [https://coverage.readthedocs.io/en/coverage-5.5/](https://coverage.readthedocs.io/en/coverage-5.5/)'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] “coverage.py，” 2021\. [在线]. 可用: [https://coverage.readthedocs.io/en/coverage-5.5/](https://coverage.readthedocs.io/en/coverage-5.5/)'
- en: '[46] P. Oberparleiter *et al.*, “lcov-a graphical gcov front-end,” *URL: https://linux.
    die. net/man/1/lcov, last checked on*, pp. 08–03, 2019.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] P. Oberparleiter *等人*，“lcov - 一个图形化的 gcov 前端，” *网址: https://linux.die.net/man/1/lcov,
    最后检查日期*，页 08–03, 2019。'
- en: '[47] Example, “Example of false positive,” [https://github.com/pytorch/pytorch/issues/122426](https://github.com/pytorch/pytorch/issues/122426)/.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] Example，“虚假正例示例，” [https://github.com/pytorch/pytorch/issues/122426](https://github.com/pytorch/pytorch/issues/122426)/.'
