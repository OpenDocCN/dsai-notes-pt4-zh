- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 19:04:11'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 19:04:11
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Can LLMs Converse Formally? Automatically Assessing LLMs in Translating and
    Interpreting Formal Specifications
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大型语言模型能否正式对话？自动评估 LLMs 在翻译和解释形式规范方面的能力
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2403.18327](https://ar5iv.labs.arxiv.org/html/2403.18327)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2403.18327](https://ar5iv.labs.arxiv.org/html/2403.18327)
- en: '[![[Uncaptioned image]](img/11a4d9c7a39bb532e8984d70b648b2ff.png) Rushang Karia](https://orcid.org/0000-0002-8421-1133)
    School of Computing and Augmented Intelligence'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[![[未标注图片]](img/11a4d9c7a39bb532e8984d70b648b2ff.png) Rushang Karia](https://orcid.org/0000-0002-8421-1133)
    计算与增强智能学院'
- en: Arizona State University
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 亚利桑那州立大学
- en: Tempe AZ USA 85281
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Tempe AZ USA 85281
- en: '{rushang.karia,ddobhal,drbrambl,verma.pulkit,siddharths}@asu.edu Daksh Dobhal
    School of Computing and Augmented Intelligence'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '{rushang.karia,ddobhal,drbrambl,verma.pulkit,siddharths}@asu.edu Daksh Dobhal
    计算与增强智能学院'
- en: Arizona State University
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 亚利桑那州立大学
- en: Tempe AZ USA 85281
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Tempe AZ USA 85281
- en: '{rushang.karia,ddobhal,drbrambl,verma.pulkit,siddharths}@asu.edu Daniel Bramblett
    School of Computing and Augmented Intelligence'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '{rushang.karia,ddobhal,drbrambl,verma.pulkit,siddharths}@asu.edu Daniel Bramblett
    计算与增强智能学院'
- en: Arizona State University
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 亚利桑那州立大学
- en: Tempe AZ USA 85281
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Tempe AZ USA 85281
- en: '{rushang.karia,ddobhal,drbrambl,verma.pulkit,siddharths}@asu.edu Pulkit Verma
    School of Computing and Augmented Intelligence'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '{rushang.karia,ddobhal,drbrambl,verma.pulkit,siddharths}@asu.edu Pulkit Verma
    计算与增强智能学院'
- en: Arizona State University
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 亚利桑那州立大学
- en: Tempe AZ USA 85281
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Tempe AZ USA 85281
- en: '{rushang.karia,ddobhal,drbrambl,verma.pulkit,siddharths}@asu.edu Siddharth
    Srivastava School of Computing and Augmented Intelligence'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '{rushang.karia,ddobhal,drbrambl,verma.pulkit,siddharths}@asu.edu Siddharth
    Srivastava 计算与增强智能学院'
- en: Arizona State University
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 亚利桑那州立大学
- en: Tempe AZ USA 85281
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Tempe AZ USA 85281
- en: '{rushang.karia,ddobhal,drbrambl,verma.pulkit,siddharths}@asu.edu'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '{rushang.karia,ddobhal,drbrambl,verma.pulkit,siddharths}@asu.edu'
- en: Abstract
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Stakeholders often describe system requirements using natural language which
    are then converted to formal syntax by a domain-expert leading to increased design
    costs. This paper assesses the capabilities of Large Language Models (LLMs) in
    converting between natural language descriptions and formal specifications. Existing
    work has evaluated the capabilities of LLMs in generating formal syntax such as
    source code but such experiments are typically hand-crafted and use problems that
    are likely to be in the training set of LLMs, and often require human-annotated
    datasets. We propose an approach that can use two copies of an LLM in conjunction
    with an off-the-shelf verifier to automatically evaluate its translation abilities
    without any additional human input. Our approach generates formal syntax using
    language grammars to automatically generate a dataset. We conduct an empirical
    evaluation to measure the accuracy of this translation task and show that SOTA
    LLMs cannot adequately solve this task, limiting their current utility in the
    design of complex systems.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 利益相关者通常使用自然语言描述系统需求，然后由领域专家将其转换为形式语法，这会增加设计成本。本文评估了大型语言模型（LLMs）在自然语言描述和形式规范之间转换的能力。现有工作评估了
    LLMs 在生成形式语法（如源代码）方面的能力，但这些实验通常是手工制作的，并且使用的问题可能在 LLMs 的训练集中，且通常需要人工标注的数据集。我们提出了一种方法，可以使用两个
    LLM 副本结合现成的验证器，自动评估其翻译能力，而无需额外的人为输入。我们的方法使用语言语法生成形式语法以自动生成数据集。我们进行了实证评估，以测量这一翻译任务的准确性，并表明
    SOTA LLMs 目前无法充分解决此任务，限制了它们在复杂系统设计中的实际应用。
- en: '*Keywords* Large Language Models  $\cdot$ Truth Assessment'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*关键词* 大型语言模型  $\cdot$ 真值评估'
- en: 1 Introduction
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Automatic system synthesis and verification often require specifications to
    be provided in a formal language such as propositional logic (Haubelt and Feldmann,
    [2003](#bib.bib1); Scholl and Becker, [2001](#bib.bib2)). Typically, human experts
    serve as middlemen that can (a) translate natural language (NL) specifications
    of stakeholders to formal syntax, or (b) explain or interpret the system’s functionality
    by translating the system manual into NL.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 自动系统综合和验证通常需要用诸如命题逻辑（Haubelt 和 Feldmann，[2003](#bib.bib1)；Scholl 和 Becker，[2001](#bib.bib2)）这样的形式语言提供规范。通常，人工专家担任中介角色，(a)
    将利益相关者的自然语言（NL）规范转换为形式语法，或 (b) 通过将系统手册翻译成 NL 来解释或阐明系统的功能。
- en: Given the success of Large Language Models (LLMs) in translation tasks (Xue
    et al., [2021](#bib.bib3)), utilizing LLMs as middlemen can help in reducing overall
    system design costs. Thus, it is vital to develop an evaluation methodology that
    can assess the capabilities of LLMs in such settings. However, developing such
    a methodology is quite difficult. Firstly, obtaining high-quality datasets – such
    as those that contain ground truth data that LLMs have not been trained on – is
    difficult. As LLMs evolve, the dataset would need to evolve as well since it would
    likely be included as a part of the next-gen LLMs training process. Scaling up
    existing datasets is challenging since they require human annotators to encode
    NL text and their formal specifications. Finally, the assessment task must consider
    both the directions of translation; formal-to-natural and natural-to-formal. Existing
    approaches for evaluating LLMs often lack in one of these dimensions. For example,
    there has been plenty of work on SAT reasoning using LLMs (Fan et al., [2023](#bib.bib4);
    Pan et al., [2023](#bib.bib5); Tian et al., [2021a](#bib.bib6)). These methods
    demonstrate that LLMs are not accurate in applications but they do not assess
    LLMs w.r.t. truth maintenance.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到大型语言模型（LLMs）在翻译任务中的成功（Xue 等， [2021](#bib.bib3)），利用 LLMs 作为中介可以帮助降低整体系统设计成本。因此，开发一种能够评估
    LLMs 在这种设置中的能力的评估方法是至关重要的。然而，开发这种方法是相当困难的。首先，获得高质量的数据集——例如包含 LLMs 尚未训练过的真实数据的数据集——是困难的。随着
    LLMs 的进化，数据集也需要进化，因为它可能会作为下一代 LLMs 训练过程的一部分被纳入。扩展现有的数据集是具有挑战性的，因为它们需要人工注释员来编码自然语言文本及其正式规范。最后，评估任务必须考虑翻译的两个方向；形式到自然和自然到形式。现有的
    LLMs 评估方法在这些维度中往往有所欠缺。例如，虽然有很多关于使用 LLMs 进行 SAT 推理的研究（Fan 等，[2023](#bib.bib4);
    Pan 等，[2023](#bib.bib5); Tian 等，[2021a](#bib.bib6)），这些方法表明 LLMs 在应用中的准确性不高，但它们并没有评估
    LLMs 在真值维护方面的能力。
- en: 'Our Contributions   We present, to the best of our knowledge, the first systematic
    approach for evaluating truth maintenance in LLMs. We develop a scalable approach
    for assessing LLMs w.r.t. their capabilities in translating formal syntax in a
    hands-free fashion. Our key contributions are:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的贡献 我们首次提出了评估 LLMs 中真值维护的系统方法。我们开发了一种可扩展的方法，以免手动的方式评估 LLMs 在翻译形式语法方面的能力。我们的主要贡献包括：
- en: '1.'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Inspired by real-world system specifications, we propose the generation of scalable
    datasets that can be generated randomly using formal syntax grammars and can be
    categorized by complexity.
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 受现实世界系统规范的启发，我们提出了生成可扩展数据集的方案，这些数据集可以使用形式语法生成，并可以按复杂性进行分类。
- en: '2.'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: We propose an automatic, hands-free approach that allows the bidirectional assessment
    of the translation task using two copies of an LLM by using off-the-shelf verifiers
    to evaluate the translation accuracy.
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了一种自动的、免手动的方法，通过使用两份 LLMs 及现成的验证器来评估翻译准确性，从而实现翻译任务的双向评估。
- en: '3.'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: We motivate research in this area by conducting an empirical evaluation and
    showcasing that current SOTA LLMs are lacking even on simple formal specifications
    such as boolean satisfiability (SAT) and first-order logic (FOL).
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们通过进行实证评估并展示当前的 SOTA LLMs 在简单的形式规范（如布尔满足性（SAT）和一阶逻辑（FOL））上也有所不足，从而激励这一领域的研究。
- en: 2 Automatically Assessing LLM Capabilities in Translation and Interpretation
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 自动评估 LLMs 在翻译和解释中的能力
- en: '![Refer to caption](img/e0e376b21e3e13f1ca37db7a7f769f79.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e0e376b21e3e13f1ca37db7a7f769f79.png)'
- en: 'Figure 1: Our overall process for *NL$\leftrightarrow$.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：我们整体的 *NL$\leftrightarrow$* 过程。
- en: 2.1 Formal Framework
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 形式框架
- en: Definition 2.1  (LLM Formal Syntax Translation Task (NL$\rightarrow$FS)).
  id: totrans-39
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 2.1  (LLM 形式语法翻译任务 (NL$\rightarrow$FS))。
- en: Given an LLM $L$FS^′.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个 LLM $L$FS^′。
- en: Definition 2.2  (LLM Formal Syntax Interpretation Task (FS$\rightarrow$NL)).
  id: totrans-41
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 2.2  (LLM 形式语法解释任务 (FS$\rightarrow$NL))。
- en: Given an LLM $L$ s.t. NL is an accurate representation of FS.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个 LLM $L$，使得 NL 是 FS 的准确表示。
- en: In this paper, we consider formal specifications that are expressed as boolean
    satisfiability (B-SAT) formulae using propositional logic (Biere et al., [2021](#bib.bib7)).
    Given a set of $n$ of truth values to every variable in $\mathcal{X}$.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们考虑了使用命题逻辑（Biere 等，[2021](#bib.bib7)）表达的布尔满足性（B-SAT）公式的形式规范。给定一组 $n$ 的真值用于每个变量
    $\mathcal{X}$。
- en: 2.2 Our Approach
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 我们的方法
- en: Let $\iota$ are not well-defined.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 令 $\iota$ 未定义。
- en: Our key observation is that if $\iota$.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的关键观察是，如果 $\iota$。
- en: We use the above insights to automatically assess the *FS$\rightarrow$ are represented
    by the same LLM). Since LLMs utilize context windows to change their output, we
    use two different copies of the same LLM so that there is no contextual knowledge
    being exchanged between the encode-decode process.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们利用上述见解来自动评估 *FS$\rightarrow$* 的表现（由同一 LLM 表示）。由于 LLM 利用上下文窗口来改变其输出，我们使用了两个不同的同一
    LLM 副本，以避免编码-解码过程之间的上下文知识交换。
- en: Fig. [1](#S2.F1 "Figure 1 ‣ 2 Automatically Assessing LLM Capabilities in Translation
    and Interpretation ‣ Can LLMs Converse Formally? Automatically Assessing LLMs
    in Translating and Interpreting Formal Specifications") illustrates our overall
    process. Given a formula $f$.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图[1](#S2.F1 "图 1 ‣ 2 自动评估 LLM 在翻译和解释方面的能力 ‣ LLM 能否正式对话？自动评估 LLM 在翻译和解释正式规格方面的表现")
    展示了我们的整体过程。给定一个公式 $f$。
- en: Dataset Generation   We create high-quality datasets by using generators that
    use the formal language’s grammar $\mathcal{G}$ where the difficulty of the problem
    increases (Selman et al., [1996](#bib.bib9)).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集生成 我们通过使用正式语言的语法 $\mathcal{G}$ 的生成器来创建高质量的数据集，其中问题的难度逐渐增加 (Selman 等, [1996](#bib.bib9))。
- en: 3 Empirical Evaluation
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 实证评估
- en: We used GPT-4 (OpenAI, [2023a](#bib.bib10)), GPT-3.5-turbo (OpenAI, [2023b](#bib.bib11)),
    Mistral-7B-Instruct (Mistral AI, [2023](#bib.bib12)), and Gemini Pro (Google,
    [2023](#bib.bib13)) as the SOTA LLMs in our evaluation. We evaluate whether they
    are effective for *NL$\leftrightarrow$ that are much higher.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了 GPT-4 (OpenAI, [2023a](#bib.bib10))、GPT-3.5-turbo (OpenAI, [2023b](#bib.bib11))、Mistral-7B-Instruct
    (Mistral AI, [2023](#bib.bib12)) 和 Gemini Pro (Google, [2023](#bib.bib13)) 作为我们评估中的
    SOTA LLM。我们评估了它们在 *NL$\leftrightarrow$* 上的效果，这些效果要高得多。
- en: 3.1 Propositional Logic
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 命题逻辑
- en: '![Refer to caption](img/8806911c4dd05b98114227e8ad7527ce.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8806911c4dd05b98114227e8ad7527ce.png)'
- en: 'Figure 2: Accuracies (higher values better) of various SOTA LLMs on *NL$\leftrightarrow$FS*
    on randomly generated formulae. The top y-axis plots the accuracy of the LLM generated
    formulae compared to the ground truty. The bottom y-axis plots the total percent
    of the truth table that is consistent with the ground truth.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：各种 SOTA LLM 在 *NL$\leftrightarrow$FS* 上对随机生成的公式的准确率（值越高越好）。顶部的 y 轴绘制了 LLM
    生成的公式与实际值的准确率。底部的 y 轴绘制了与实际值一致的真值表总百分比。
- en: Prompts are critical to the performance of LLMs. To ensure that our prompts
    are correct and facilitate translation/interpretation w.r.t. formal syntax, we
    tested our prompts by generating a dataset $\mathcal{D}_{\textit{cnf}}$.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 提示对 LLM 的表现至关重要。为了确保我们的提示是正确的，并有助于根据正式语法进行翻译/解释，我们通过生成数据集 $\mathcal{D}_{\textit{cnf}}$
    来测试我们的提示。
- en: CNF formulae serve as a good test bed for prompts but human stakeholders are
    unlikely to understand or describe system capabilities in such a format. Thus,
    our evaluation tests the efficacy of SOTA LLMs on *NL$\leftrightarrow$) are equal
    in both.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: CNF 公式作为测试提示的良好基础，但人类利益相关者不太可能以这种格式理解或描述系统能力。因此，我们的评估测试了 SOTA LLM 在 *NL$\leftrightarrow$*
    上的有效性，这些效果在两个方面是相等的。
- en: We used the same prompts for all LLMs. Finally, we used a temperature of $0.1$
    for all models. The temperature influences the randomness of the models.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对所有 LLM 使用了相同的提示。最后，我们对所有模型使用了 $0.1$ 的温度。温度会影响模型的随机性。
- en: Results   Our results are presented in Fig.[2](#S3.F2 "Figure 2 ‣ 3.1 Propositional
    Logic ‣ 3 Empirical Evaluation ‣ Can LLMs Converse Formally? Automatically Assessing
    LLMs in Translating and Interpreting Formal Specifications"). It is clear from
    our results that current SOTA LLMs are not performant in the *NL$\leftrightarrow$.
    We describe some of the errors that cause the low accuracy of the LLMs.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 结果 我们的结果展示在图[2](#S3.F2 "图 2 ‣ 3.1 命题逻辑 ‣ 3 实证评估 ‣ LLM 能否正式对话？自动评估 LLM 在翻译和解释正式规格方面的表现")中。从我们的结果可以明显看出，目前的
    SOTA LLM 在 *NL$\leftrightarrow$* 上表现不佳。我们描述了一些导致 LLM 精度低的错误。
- en: '*FS$\rightarrow$NL Errors:* One of the most common errors in this translation
    was messing the order of the parentheses. The LLMs were not able to effectively
    describe the formulae taking into account the parentheses. For example, for GPT-3.5-turbo,
    as the size of the formula increased, we noticed that the description did not
    correctly capture the semantics of the formula and the parentheses in expressions
    were often ignored. Gemini and Mistral were not able to correctly describe the
    formula accurately and often missed complete parts of the formula in their description.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '*FS$\rightarrow$NL 错误：* 这种翻译中最常见的错误之一是括号顺序混乱。LLMs 无法有效地描述公式，考虑到括号的情况。例如，对于
    GPT-3.5-turbo，随着公式的大小增加，我们注意到描述没有正确捕捉公式的语义，表达式中的括号经常被忽视。Gemini 和 Mistral 无法准确地描述公式，常常遗漏公式的完整部分。'
- en: '*NL$\rightarrow$FS*, the final response should only the the formula and no
    other text. However, both these LLMs consistently failed to generate only a formula
    and would often try to describe the formula again before providing the desired
    response.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*NL$\rightarrow$FS*，最终响应应仅包含公式而无其他文本。然而，这两个 LLMs 一直无法只生成公式，常常会在提供所需响应之前尝试再次描述公式。'
- en: 3.2 First Order Logic
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 一阶逻辑
- en: '![Refer to caption](img/6e43b1a3a87e480806b7f1bf9830877d.png)![Refer to caption](img/5e3a0d8d69e002f78cb056c8c878aaec.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/6e43b1a3a87e480806b7f1bf9830877d.png)![参考标题](img/5e3a0d8d69e002f78cb056c8c878aaec.png)'
- en: 'Figure 3: Accuracies (higher values better) of various SOTA LLMs on *NL$\leftrightarrow$)
    whereas the bottom figure plots accuracies w.r.t. human versions of predicates
    and constants like Friend(John, Mary) etc.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：各种 SOTA LLMs 在 *NL$\leftrightarrow$ 的准确率（值越高越好），而底部图绘制了相对于人类版本的谓词和常量（如 Friend(John,
    Mary) 等）的准确率。
- en: We generated a dataset $\mathcal{D}_{\textit{fol}}$FS* prompt provides the LLM
    with FOL grammar and prompts for the FOL formula constructed from the NL description
    to be placed at the end of the response. The prompts were refactored til they
    covered all the translation failure cases detected from each LLM using a different
    random seed.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们生成了一个数据集 $\mathcal{D}_{\textit{fol}}$ FS* 提示提供给 LLM 具有 FOL 语法，并提示将从 NL 描述构造的
    FOL 公式放在响应的末尾。提示被重构直到它们涵盖了从每个 LLM 检测到的所有翻译失败案例，使用了不同的随机种子。
- en: We randomly generated 400 FOL formulae of the prenex normal form by recursively
    applying $\mathcal{G}_{sat}$) had been generated. Then, a quantifier was randomly
    selected for each variable in the vocabulary. The grounded predicates were randomly
    selected. We used two such datasets; the first one had randomized versions of
    predicates and constants whereas the predicates and constants in the second dataset
    were pulled from an English vocabulary.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过递归应用 $\mathcal{G}_{sat}$ 随机生成了 400 个前束范式的 FOL 公式。然后，为词汇表中的每个变量随机选择了一个量词。基于的谓词也是随机选择的。我们使用了两个这样的数据集；第一个数据集包含谓词和常量的随机版本，而第二个数据集中的谓词和常量来自于英语词汇表。
- en: We used the same prompt for each LLM and evaluated the equivalence of the generated
    formulae compared to the originals using Prover9 (McCune, [2005–2010](#bib.bib14)).
    The solver had a 10-minute timeout, and examples that hit it were thrown out.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对每个 LLM 使用了相同的提示，并使用 Prover9 (McCune, [2005–2010](#bib.bib14)) 评估生成的公式与原始公式的等价性。求解器有
    10 分钟的超时限制，超时的示例被舍弃。
- en: Results   Our results are presented in Fig.[3](#S3.F3 "Figure 3 ‣ 3.2 First
    Order Logic ‣ 3 Empirical Evaluation ‣ Can LLMs Converse Formally? Automatically
    Assessing LLMs in Translating and Interpreting Formal Specifications"). Note that
    with far fewer operators than CNF results, SOTA LLMs are not performant in the
    *NL$\leftrightarrow$FS* task. Even with a single operator, GPT-4 barely achieved
    80% accuracy with diminishing performance. The increase at the end is due to GPT-4
    results having a higher number of timeouts that, while visually incorrect, are
    thrown out. We observed all the same problems raised in the CNF results.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 结果 我们的结果展示在图[3](#S3.F3 "图 3 ‣ 3.2 一阶逻辑 ‣ 3 实证评估 ‣ 大型语言模型能否正式对话？自动评估 LLMs 在翻译和解释正式规范中的表现")中。请注意，与
    CNF 结果相比，SOTA LLMs 在*NL$\leftrightarrow$FS*任务中的表现不佳。即使只有一个操作符，GPT-4 的准确率也勉强达到
    80%，且表现逐渐下降。最后的增加是由于 GPT-4 结果中有更多的超时，这些超时虽然在视觉上不正确，但被舍弃了。我们观察到 CNF 结果中提出的所有相同问题。
- en: '*FS$\rightarrow$NL Errors:* The same lack of detail for formula explanations
    was observed, resulting in incorrect formulas being generated. Additionally, it
    was quite common for the LLM to introduce different constants as examples for
    variables, resulting in LLM using them when generating the formulae.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*FS$\rightarrow$NL 错误：* 观察到相同的公式解释细节缺乏问题，导致生成了不正确的公式。此外，LLM 常常会引入不同的常量作为变量的示例，导致
    LLM 在生成公式时使用这些常量。'
- en: '*NL$\rightarrow$. While we parsed these operators, we observed that there was
    a significantly higher likelihood for the LLM messing up.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '*NL$\rightarrow$FS。在解析这些操作符时，我们观察到 LLM 出错的可能性显著增加。'
- en: 4 Related Work
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 相关工作
- en: There is a large body of work for using LLMs for tasks using formal languages.
    Similarly, there exist several datasets that allow the analysis of LLMs in such
    tasks.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 有大量的研究工作使用 LLM 进行形式语言任务。同样，存在多个数据集可以分析 LLM 在这些任务中的表现。
- en: Datasets RuleTaker (Clark et al., [2020](#bib.bib15)) creates a dataset by applying
    a limited grammar consisting of only conjunctions and disjunctions to generate
    formulae. This makes it quite limited in the types of formulae it can generate.
    FOLIO (Han et al., [2022](#bib.bib16)) comprises first-order logic statements
    that can be used to test the reasoning capabilities of LLMs. The data consists
    of premises and annotated conclusions that can be drawn from the premises thus
    enabling the testing of reasoning capabilities of LLMs. One of the key disadvantages
    of this dataset is that the data was generated using human-experts. LogicNLI (Tian
    et al., [2021b](#bib.bib17)) is a reasoning dataset that generates first-order
    logic formulae from a set of templates and then uses rule-based templates for
    NL generation. Since they utilize a set of templates their datasets are limited
    in the kinds of expressions they can generate.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集 RuleTaker (Clark et al., [2020](#bib.bib15)) 通过应用仅包含合取和析取的有限语法生成公式，从而创建数据集。这使得它在生成公式类型方面相当有限。FOLIO
    (Han et al., [2022](#bib.bib16)) 包含可以用来测试 LLM 推理能力的第一阶逻辑语句。数据包括从前提中得出的前提和注释结论，从而实现对
    LLM 推理能力的测试。该数据集的一个主要缺点是数据由人类专家生成。LogicNLI (Tian et al., [2021b](#bib.bib17))
    是一个推理数据集，它从一组模板生成第一阶逻辑公式，然后使用基于规则的模板进行 NL 生成。由于它们使用一组模板，因此它们的数据集在生成表达式的种类上有限。
- en: In contrast to existing datasets, our approach can generate arbitrarily complex
    formulae and does not require any human intervention making our approach scalable.
    Furthermore, our datasets can be partitioned into definite classes of hardness
    from a reasoning perspective making them well suited for reasoning-based testing
    as well.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 与现有数据集相比，我们的方法可以生成任意复杂的公式，不需要任何人工干预，从而使我们的方法具有可扩展性。此外，我们的数据集可以从推理角度划分为明确的难度类别，也使其非常适合用于基于推理的测试。
- en: First-order Logic Translation LogicLLaMa (Yang et al., [2023](#bib.bib18)) is
    an LLM trained specifically for the *NL$\rightarrow$FS* task. Inorder to evaluate
    its efficacy, the authors proposed MALLS, a custom generated dataset that can
    be used to evaluate the efficacy of LogicLLaMa. Their approach does not provide
    an automatic way to test the efficacy of LLMs in the translation task and requires
    hand-coded datasets. Moreover, their evaluation metric considers logical equivalence
    using truth tables which can be inefficient. Autoformalization (Wu et al., [2022](#bib.bib19))
    uses pre-trained LLMs together with few-shot prompting to convert NL descriptions
    to formal syntax. This approach requires expert prompting and relevant examples
    to boost performance. Furthermore, this approach relies on existing, annotated
    datasets and thus can be susceptible to LLMs having memorized the answers.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 第一阶逻辑翻译 LogicLLaMa (Yang et al., [2023](#bib.bib18)) 是一个专门为 *NL$\rightarrow$FS*
    任务训练的 LLM。为了评估其效能，作者提出了 MALLS，这是一个自定义生成的数据集，用于评估 LogicLLaMa 的效能。他们的方法没有提供一种自动测试
    LLM 翻译任务效能的方法，并且需要手工编码的数据集。此外，他们的评估指标考虑了使用真值表的逻辑等价性，这可能效率低下。Autoformalization
    (Wu et al., [2022](#bib.bib19)) 使用预训练的 LLM 结合少量示例提示，将 NL 描述转换为形式语法。这种方法需要专家提示和相关示例来提升性能。此外，这种方法依赖于现有的注释数据集，因此可能会受到
    LLM 记住答案的影响。
- en: PDDL Translation Simon and Muise ([2021](#bib.bib20)) train Recurrent Neural
    Networks (RNNs) to automatically translate a fragment of formal syntax expressed
    in PDDL to a complete PDDL problem. They train the RNN on publicly available PDDL
    problems using supervised learning. However, their approach cannot use general
    purpose NL descriptions and requires inputs in a formal syntax. Xie et al. ([2023](#bib.bib21))
    use few-shot prompting to translate NL descriptions to PDDL goals and assess them
    using manually designed, domain-dependent metrics. Moreover, their approach cannot
    perform *FS$\rightarrow$NL* translations.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: PDDL Translation Simon 和 Muise（[2021](#bib.bib20)）训练递归神经网络（RNN）来自动将 PDDL 表达的形式语法片段翻译为完整的
    PDDL 问题。他们使用监督学习在公开的 PDDL 问题上训练 RNN。然而，他们的方法不能使用通用的 NL 描述，并且需要以形式语法作为输入。Xie 等（[2023](#bib.bib21)）使用少量样本提示将
    NL 描述翻译为 PDDL 目标，并使用手动设计的、领域相关的指标进行评估。此外，他们的方法不能进行 *FS$\rightarrow$NL* 翻译。
- en: RTL Translation AutoSVA2 (Orenes-Vera et al., [2023](#bib.bib22)) is a framework
    for verification of RTL syntax from NL descriptions. The framework involves manually
    refining prompts iteratively. Next, an LLM is used to generate the RTL syntax
    and an RTL engine is used to validate the result. One key weakness is that their
    approach is not generalizable and requires an engineer-in-the-loop to iteratively
    refine the prompts or different kinds of RTL designs within the same language.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: RTL Translation AutoSVA2（Orenes-Vera 等，[2023](#bib.bib22)）是一个用于验证来自 NL 描述的 RTL
    语法的框架。该框架涉及手动迭代地完善提示。接下来，使用 LLM 生成 RTL 语法，并使用 RTL 引擎来验证结果。一个主要的弱点是他们的方法不可泛化，需要工程师在环中迭代地完善提示或处理相同语言中的不同类型
    RTL 设计。
- en: Code Translation Codex (Chen et al., [2021](#bib.bib23)) is an LLM that is capable
    of converting NL descriptions to code and vice versa. However, this approach does
    not provide any automatic way to assess the accuracy of the LLM and it often relies
    on human annotators to verify the results. Furthermore, their testing process
    cannot accurately check whether the translate code matches the NL description
    correctly since they use sampling of input cases in their evaluation. Bhattacharya
    et al. ([2023](#bib.bib24)) evaluate the capability of LLMs to explain code by
    assessing their performance when used with zero-shot, few-shot prompts and instruction
    finetuning. Their approach requires access to hand-coded prompts and cannot work
    with different formal languages. MacNeil et al. ([2023](#bib.bib25)) conduct user-studies
    to evaluate the effectiveness of LLMs in generating code. Their approach requires
    the recruitment of expert humans who know code to assess the quality of the generated
    LLMs.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Code Translation Codex（Chen 等，[2021](#bib.bib23)）是一个能够将 NL 描述转换为代码及其反向操作的 LLM。然而，这种方法没有提供自动评估
    LLM 准确性的方式，并且通常依赖人工注释者来验证结果。此外，由于他们在评估中使用了输入案例的抽样，他们的测试过程无法准确检查翻译的代码是否正确匹配了 NL
    描述。Bhattacharya 等（[2023](#bib.bib24)）通过评估 LLM 在零样本、少样本提示和指令微调下的表现来评估 LLM 解释代码的能力。他们的方法需要访问手工编码的提示，并且不能与不同的形式语言配合使用。MacNeil
    等（[2023](#bib.bib25)）进行用户研究，以评估 LLM 在生成代码方面的有效性。他们的方法需要招募懂得代码的专家来评估生成的 LLM 的质量。
- en: Our framework provides a general, automatic, handsfree way of assessing LLMs
    in both *NL$\rightarrow$NL* without requiring any expert knowledge. Our approach
    can be easily transferred to other formal languages with an appropriate critic.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的框架提供了一种通用的、自动化的、免人工干预的评估 LLM 的方法，适用于 *NL$\rightarrow$NL*，无需任何专家知识。我们的方法可以轻松转移到其他形式语言中，只需一个适当的评审者。
- en: 5 Conclusions and Future Work
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论与未来工作
- en: We develop an approach that allows for effective assessment in the formal translation
    capabilities of SOTA LLMs. Our approach does not require human annotations to
    verify the accuracy of translation. Our results show that there is much to be
    done before LLMs can be deployed in translating formal syntax. We plan to investigate
    the performance of LLMs using different formal languages in future work.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开发了一种方法，允许有效评估 SOTA LLM 的正式翻译能力。我们的方法不需要人工注释来验证翻译的准确性。我们的结果表明，在 LLM 可以用于翻译正式语法之前，还有很多工作要做。我们计划在未来的工作中研究
    LLM 在使用不同正式语言时的表现。
- en: References
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Haubelt and Feldmann [2003] C. Haubelt and R. Feldmann. SAT-based techniques
    in system synthesis. In *Proc DATE*, 2003.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Haubelt 和 Feldmann [2003] C. Haubelt 和 R. Feldmann。基于 SAT 的系统综合技术。发表于 *Proc
    DATE*，2003 年。
- en: Scholl and Becker [2001] Christoph Scholl and Bernd Becker. Checking equivalence
    for partial implementations. In *Proc. DAC*, 2001.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Scholl和Becker[2001] 克里斯托夫·舒尔和伯恩德·贝克。检查部分实现的等价性。在*Proc. DAC*，2001。
- en: 'Xue et al. [2021] Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami
    Al-Rfou, Aditya Siddhant, Aditya Barua, and Colin Raffel. mT5: A massively multilingual
    pre-trained text-to-text transformer. In *Proc. NAACL-HLT*, 2021.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xue等[2021] 林婷·薛、诺亚·康斯坦特、亚当·罗伯茨、米希尔·卡勒、拉米·阿尔-尔福、阿迪提亚·斯迪汉特、阿迪提亚·巴鲁亚和科林·拉费尔。mT5：一种大规模多语言预训练的文本到文本变换器。在*Proc.
    NAACL-HLT*，2021。
- en: 'Fan et al. [2023] Lizhou Fan, Wenyue Hua, Lingyao Li, Haoyang Ling, Yongfeng
    Zhang, and Libby Hemphill. NPHardEval: Dynamic benchmark on reasoning ability
    of large language models via complexity classes, 2023.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fan等[2023] 李洲·范、文月·华、凌尧·李、浩阳·凌、永锋·张和利比·亨普希尔。NPHardEval：通过复杂度类别对大型语言模型推理能力的动态基准测试，2023。
- en: 'Pan et al. [2023] Liangming Pan, Alon Albalak, Xinyi Wang, and William Yang
    Wang. Logic-LM: Empowering large language models with symbolic solvers for faithful
    logical reasoning. In *Proc. EMNLP Findings*, 2023.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pan等[2023] 梁铭潘、阿龙·阿尔巴拉克、新怡·王和威廉·杨·王。《Logic-LM：用符号求解器赋能大型语言模型以进行忠实的逻辑推理》。在*Proc.
    EMNLP Findings*，2023。
- en: Tian et al. [2021a] Jidong Tian, Yitian Li, Wenqing Chen, Liqiang Xiao, Hao
    He, and Yaohui Jin. Diagnosing the first-order logical reasoning ability through
    LogicNLI. In *Proc. EMNLP*, 2021a.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tian等[2021a] 吉东·田、逸天·李、文青·陈、力强·肖、浩赫和姚辉·金。通过LogicNLI诊断一阶逻辑推理能力。在*Proc. EMNLP*，2021a。
- en: Biere et al. [2021] Armin Biere, Marijn Heule, Hans van Maaren, and Toby Walsh,
    editors. *Handbook of Satisfiability - Second Edition*. IOS Press, 2021. ISBN
    978-1-64368-160-3.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Biere等[2021] 阿尔敏·比耶尔、马里恩·赫尔、汉斯·范·马伦和托比·沃尔什，编辑。*满足性手册 - 第二版*。IOS出版社，2021年。ISBN
    978-1-64368-160-3。
- en: 'de Moura and Bjørner [2008] Leonardo Mendonça de Moura and Nikolaj S. Bjørner.
    Z3: An efficient SMT solver. In *Proc. TACAS*, 2008.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: de Moura和Bjørner[2008] 莱昂纳多·门东萨·德·穆拉和尼古拉·S·比约纳。Z3：一种高效的SMT求解器。 在*Proc. TACAS*，2008。
- en: Selman et al. [1996] Bart Selman, David G. Mitchell, and Hector J. Levesque.
    Generating hard satisfiability problems. *AIJ*, 81(1-2):17–29, 1996.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Selman等[1996] 巴特·塞尔曼、大卫·G·米切尔和赫克托·J·勒维斯克。生成难度大的满足性问题。*AIJ*，81(1-2):17–29, 1996。
- en: 'OpenAI [2023a] OpenAI. Gpt-4-1106-preview. [https://arxiv.org/pdf/2303.08774.pdf](https://arxiv.org/pdf/2303.08774.pdf),
    2023a. Accessed: 2023-01-10.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI [2023a] OpenAI。Gpt-4-1106-preview。 [https://arxiv.org/pdf/2303.08774.pdf](https://arxiv.org/pdf/2303.08774.pdf)，2023a。访问时间：2023-01-10。
- en: 'OpenAI [2023b] OpenAI. Gpt-3.5-turbo-0613. [https://platform.openai.com/docs/models/gpt-3-5](https://platform.openai.com/docs/models/gpt-3-5),
    2023b. Accessed: 2023-01-10.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI [2023b] OpenAI。Gpt-3.5-turbo-0613。 [https://platform.openai.com/docs/models/gpt-3-5](https://platform.openai.com/docs/models/gpt-3-5)，2023b。访问时间：2023-01-10。
- en: 'Mistral AI [2023] Mistral AI. Mistral-7b instruct v0.2. [https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2),
    2023. Accessed: 2023-01-10.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mistral AI [2023] Mistral AI。Mistral-7b instruct v0.2。 [https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2)，2023。访问时间：2023-01-10。
- en: 'Google [2023] Google. Gemini pro. [https://arxiv.org/pdf/2312.11805.pdf](https://arxiv.org/pdf/2312.11805.pdf),
    2023. Accessed: 2023-01-10.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google [2023] 谷歌。Gemini pro。 [https://arxiv.org/pdf/2312.11805.pdf](https://arxiv.org/pdf/2312.11805.pdf)，2023。访问时间：2023-01-10。
- en: McCune [2005–2010] W. McCune. Prover9 and mace4. `http://www.cs.unm.edu/~mccune/prover9/`,
    2005–2010.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: McCune [2005–2010] W. McCune。Prover9和mace4。 `http://www.cs.unm.edu/~mccune/prover9/`，2005–2010。
- en: Clark et al. [2020] Peter Clark, Oyvind Tafjord, and Kyle Richardson. Transformers
    as soft reasoners over language. In *Proc. IJCAI*, 2020.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Clark等[2020] 彼得·克拉克、奥伊文·塔福尔德和凯尔·理查森。将变换器作为语言上的软推理工具。在*Proc. IJCAI*，2020。
- en: 'Han et al. [2022] Simeng Han, Hailey Schoelkopf, Yilun Zhao, Zhenting Qi, Martin
    Riddell, Luke Benson, Lucy Sun, Ekaterina Zubova, Yujie Qiao, Matthew Burtell,
    David Peng, Jonathan Fan, Yixin Liu, Brian Wong, Malcolm Sailor, Ansong Ni, Linyong
    Nan, Jungo Kasai, Tao Yu, Rui Zhang, Shafiq R. Joty, Alexander R. Fabbri, Wojciech
    Kryscinski, Xi Victoria Lin, Caiming Xiong, and Dragomir Radev. FOLIO: natural
    language reasoning with first-order logic. *CoRR*, abs/2209.00840, 2022.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Han等[2022] 司孟·韩、海莉·肖尔科普夫、依伦·赵、镇亭·齐、马丁·里德尔、卢克·本森、露西·孙、叶卡捷琳娜·祖博娃、于杰·乔、马修·伯特尔、大卫·彭、乔纳森·范、易欣·刘、布莱恩·旺、马尔科姆·塞勒、安松·倪、林永·南、筱井·加赛、陶宇、瑞·张、沙菲克·R·乔蒂、亚历山大·R·法布里、沃伊切赫·克里辛斯基、许·维多利亚·林、蔡明·熊和德拉戈米尔·拉德夫。FOLIO：基于一阶逻辑的自然语言推理。*CoRR*，abs/2209.00840，2022。
- en: Tian et al. [2021b] Jidong Tian, Yitian Li, Wenqing Chen, Liqiang Xiao, Hao
    He, and Yaohui Jin. Diagnosing the first-order logical reasoning ability through
    logicnli. In *Proc. EMNLP*, 2021b.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 田等人 [2021b] 纪东·田、义天·李、文庆·陈、李强·肖、郝赫和姚辉·金。通过logicnli诊断一阶逻辑推理能力。在*Proc. EMNLP*，2021b。
- en: Yang et al. [2023] Yuan Yang, Siheng Xiong, Ali Payani, Ehsan Shareghi, and
    Faramarz Fekri. Harnessing the power of large language models for natural language
    to first-order logic translation. *CoRR*, abs/2305.15541, 2023. doi:[10.48550/ARXIV.2305.15541](https://doi.org/10.48550/ARXIV.2305.15541).
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 杨等人 [2023] 袁杨、西恒·熊、阿里·佩亚尼、伊赫桑·沙雷吉和法拉马兹·费克里。利用大语言模型将自然语言转化为一阶逻辑。*CoRR*，abs/2305.15541，2023。doi：[10.48550/ARXIV.2305.15541](https://doi.org/10.48550/ARXIV.2305.15541)。
- en: Wu et al. [2022] Yuhuai Wu, Albert Qiaochu Jiang, Wenda Li, Markus N. Rabe,
    Charles Staats, Mateja Jamnik, and Christian Szegedy. Autoformalization with large
    language models. In *Proc. NeurIPS*, 2022.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 吴等人 [2022] 于怀吴、阿尔伯特·乔秋楚·蒋、温达·李、马库斯·N·拉贝、查尔斯·斯塔茨、马特亚·贾姆尼克和克里斯蒂安·斯泽格迪。利用大语言模型进行自动形式化。在*Proc.
    NeurIPS*，2022。
- en: Simon and Muise [2021] Nisha Simon and Christian Muise. A natural language model
    for generating pddl. In *ICAPS KEPS workshop*, 2021.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 西蒙和穆伊斯 [2021] 妮莎·西蒙和克里斯蒂安·穆伊斯。一种生成PDDL的自然语言模型。在*ICAPS KEPS研讨会*，2021。
- en: Xie et al. [2023] Yaqi Xie, Chen Yu, Tongyao Zhu, Jinbin Bai, Ze Gong, and Harold
    Soh. Translating natural language to planning goals with large-language models.
    *CoRR*, abs/2302.05128, 2023.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谢等人 [2023] 牙奇·谢、陈宇、童瑶·朱、金彬·白、泽·龚和哈罗德·苏。利用大语言模型将自然语言翻译为规划目标。*CoRR*，abs/2302.05128，2023。
- en: Orenes-Vera et al. [2023] Marcelo Orenes-Vera, Margaret Martonosi, and David
    Wentzlaff. Using llms to facilitate formal verification of RTL. *CoRR*, abs/2309.09437,
    2023.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 奥雷内斯-维拉等人 [2023] 马塞洛·奥雷内斯-维拉、玛格丽特·马托诺西和大卫·温茨拉夫。使用大语言模型促进RTL的形式化验证。*CoRR*，abs/2309.09437，2023。
- en: Chen et al. [2021] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Pondé
    de Oliveira Pinto, Jared Kaplan, Harrison Edwards, Yuri Burda, Nicholas Joseph,
    Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf,
    Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov,
    Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet,
    Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth
    Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas
    Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders,
    Christopher Hesse, Andrew N. Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan
    Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer,
    Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and
    Wojciech Zaremba. Evaluating large language models trained on code. *CoRR*, abs/2107.03374,
    2021.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈等人 [2021] 马克·陈、杰瑞·特沃雷克、许维宇、秦明元、亨里克·庞德·德·奥利维拉·平托、贾里德·卡普兰、哈里森·爱德华兹、尤里·布尔达、尼古拉斯·约瑟夫、格雷格·布洛克曼、亚历克斯·雷、劳尔·普里、格雷琴·克鲁格、迈克尔·彼得罗夫、海迪·克拉夫、吉里什·萨斯特里、帕梅拉·米什金、布鲁克·陈、斯科特·格雷、尼克·赖德、米哈伊尔·帕夫洛夫、阿莱西娅·鲍威尔、卢卡什·凯瑟尔、穆罕默德·巴瓦里安、克莱门斯·温特、菲利普·蒂莱、费利佩·佩特罗斯基·苏赫、戴夫·卡明斯、马蒂亚斯·普拉普特、福提奥斯·昌齐斯、伊丽莎白·巴恩斯、阿里尔·赫伯特-沃斯、威廉·赫布根·古斯、亚历克斯·尼科尔、亚历克斯·帕伊诺、尼科拉斯·特扎克、解唐、伊戈尔·巴布什金、苏奇尔·巴拉吉、尚塔努·贾因、威廉·索恩德斯、克里斯托弗·赫斯、安德鲁·N·卡尔、简·莱克、约书亚·阿希亚姆、维丹特·米斯拉、埃文·莫里卡瓦、亚历克·拉德福、马修·奈特、迈尔斯·布伦戴奇、米拉·穆拉提、凯蒂·迈耶、彼得·维林德、鲍勃·麦克格鲁、达里奥·阿莫代、萨姆·麦肯德利什、伊利亚·苏茨克弗和沃伊切赫·扎伦巴。评估在代码上训练的大语言模型。*CoRR*，abs/2107.03374，2021。
- en: Bhattacharya et al. [2023] Paheli Bhattacharya, Manojit Chakraborty, Kartheek
    N. S. N. Palepu, Vikas Pandey, Ishan Dindorkar, Rakesh Rajpurohit, and Rishabh
    Gupta. Exploring large language models for code explanation. In *Proceedings of
    the 15th Annual Meeting of the Forum for Information Retrieval Evaluation*, 2023.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 巴塔查里亚等人 [2023] 帕赫利·巴塔查里亚、马诺吉特·查克拉博提、卡特赫克·N·S·N·帕莱普、维卡斯·潘迪、伊尚·丁多尔卡、拉克什·拉杰普罗希特和瑞沙布·古普塔。探索大语言模型在代码解释中的应用。在*第15届信息检索评估论坛年会论文集*，2023。
- en: MacNeil et al. [2023] Stephen MacNeil, Andrew Tran, Arto Hellas, Joanne Kim,
    Sami Sarsa, Paul Denny, Seth Bernstein, and Juho Leinonen. Experiences from using
    code explanations generated by large language models in a web software development
    e-book. In *Proc. SIGCSE*, 2023.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 麦克尼尔等人 [2023] 斯蒂芬·麦克尼尔、安德鲁·特兰、阿尔托·赫拉斯、乔安娜·金、萨米·萨尔萨、保罗·丹尼、塞斯·伯恩斯坦和尤霍·莱农宁。在网络软件开发电子书中使用大语言模型生成的代码解释的经验。在*Proc.
    SIGCSE*，2023。
