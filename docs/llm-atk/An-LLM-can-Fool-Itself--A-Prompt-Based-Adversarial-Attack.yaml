- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 18:46:55'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:46:55
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'An LLM can Fool Itself: A Prompt-Based Adversarial Attack'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个LLM可以自我欺骗：基于提示的对抗攻击
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2310.13345](https://ar5iv.labs.arxiv.org/html/2310.13345)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2310.13345](https://ar5iv.labs.arxiv.org/html/2310.13345)
- en: Xilie Xu¹, Keyi Kong², Ning Liu², Lizhen Cui², Di Wang³, Jingfeng Zhang^(4,5)
    , Mohan Kankanhalli¹
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Xilie Xu¹，Keyi Kong²，Ning Liu²，Lizhen Cui²，Di Wang³，Jingfeng Zhang^(4,5)，Mohan
    Kankanhalli¹
- en: ¹ National University of Singapore
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ¹ 新加坡国立大学
- en: ² Shandong University
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ² 山东大学
- en: ³ King Abdullah University of Science and Technology
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ³ 阿卜杜拉国王科技大学
- en: ⁴ The University of Auckland
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ⁴ 奥克兰大学
- en: ⁵ RIKEN Center for Advanced Intelligence Project (AIP) Corresponding author.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ⁵ 理化学研究所高级智能项目（AIP）通讯作者。
- en: Abstract
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'The wide-ranging applications of large language models (LLMs), especially in
    safety-critical domains, necessitate the proper evaluation of the LLM’s adversarial
    robustness. This paper proposes an efficient tool to audit the LLM’s adversarial
    robustness via a prompt-based adversarial attack (PromptAttack). PromptAttack
    converts adversarial textual attacks into an attack prompt that can cause the
    victim LLM to output the adversarial sample to fool itself. The attack prompt
    is composed of three important components: (1) original input (OI) including the
    original sample and its ground-truth label, (2) attack objective (AO) illustrating
    a task description of generating a new sample that can fool itself without changing
    the semantic meaning, and (3) attack guidance (AG) containing the perturbation
    instructions to guide the LLM on how to complete the task by perturbing the original
    sample at character, word, and sentence levels, respectively. Besides, we use
    a fidelity filter to ensure that PromptAttack maintains the original semantic
    meanings of the adversarial examples. Further, we enhance the attack power of
    PromptAttack by ensembling adversarial examples at different perturbation levels.
    Comprehensive empirical results using Llama2 and GPT-3.5 validate that PromptAttack
    consistently yields a much higher attack success rate compared to AdvGLUE and
    AdvGLUE++. Interesting findings include that a simple emoji can easily mislead
    GPT-3.5 to make wrong predictions. Our project page is available at [PromptAttack](https://godxuxilie.github.io/project_page/prompt_attack/).'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）在特别是在安全关键领域的广泛应用，需要对LLM的对抗鲁棒性进行适当评估。本文提出了一种通过基于提示的对抗攻击（PromptAttack）来审计LLM对抗鲁棒性的高效工具。PromptAttack将对抗性文本攻击转换为攻击提示，这些提示能够使受害LLM输出对抗样本以自我欺骗。攻击提示由三个重要组件组成：（1）原始输入（OI），包括原始样本及其真实标签，（2）攻击目标（AO），描述生成新样本的任务，该样本能够在不改变语义意义的情况下欺骗模型，以及（3）攻击指导（AG），包含扰动指令，引导LLM如何通过在字符、词汇和句子级别扰动原始样本来完成任务。此外，我们使用忠诚度过滤器来确保PromptAttack保持对抗样本的原始语义意义。此外，通过对不同扰动级别的对抗样本进行集成，我们增强了PromptAttack的攻击能力。综合的实证结果表明，使用Llama2和GPT-3.5验证了PromptAttack始终能产生比AdvGLUE和AdvGLUE++更高的攻击成功率。有趣的发现包括一个简单的表情符号可以轻易地误导GPT-3.5做出错误预测。我们的项目页面可以在[PromptAttack](https://godxuxilie.github.io/project_page/prompt_attack/)找到。
- en: 1 Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Large language models (LLMs) that are pre-trained on massive text corpora can
    be foundation models (Bommasani et al., [2021](#bib.bib6)) to power various downstream
    applications. In particular, LLMs (Garg et al., [2022](#bib.bib16); Liu et al.,
    [2023a](#bib.bib25); Wei et al., [2022](#bib.bib59)) can yield superior performance
    in various natural language processing (NLP) downstream tasks, such as sentiment
    analysis (Socher et al., [2013](#bib.bib48)) and logical reasoning (Miao et al.,
    [2023](#bib.bib35); Liu et al., [2023a](#bib.bib25)). However, in some critical
    areas such as medicine (Singhal et al., [2023](#bib.bib47)) and industrial control (Song
    et al., [2023](#bib.bib49)), LLM’s reliability is of equal importance. This paper
    studies one key aspect of LLM’s reliability—adversarial robustness.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs），在大规模文本语料库上进行预训练后，可以作为基础模型（Bommasani et al., [2021](#bib.bib6)）来驱动各种下游应用。特别是，LLMs（Garg
    et al., [2022](#bib.bib16); Liu et al., [2023a](#bib.bib25); Wei et al., [2022](#bib.bib59)）在各种自然语言处理（NLP）下游任务中，如情感分析（Socher
    et al., [2013](#bib.bib48)）和逻辑推理（Miao et al., [2023](#bib.bib35); Liu et al.,
    [2023a](#bib.bib25)），表现优异。然而，在一些关键领域，如医学（Singhal et al., [2023](#bib.bib47)）和工业控制（Song
    et al., [2023](#bib.bib49)），LLM的可靠性同样重要。本文研究了LLM可靠性的一个关键方面——对抗鲁棒性。
- en: 'Existing research evaluates adversarial robustness of LLMs on the GLUE dataset (Wang
    et al., [2018](#bib.bib53)), in which an LLM is required to solve a classification
    task according to a prompt containing both a task description and an original
    sample (as shown in Figure [2](#S2.F2 "Figure 2 ‣ Robustness evaluation of language
    models. ‣ 2 Related Work ‣ An LLM can Fool Itself: A Prompt-Based Adversarial
    Attack")). In particular,  Zhu et al. ([2023](#bib.bib66)) generated adversarial
    task descriptions based on open-sourced LLMs and transferred them to attack other
    black-box LLMs. Wang et al. ([2023b](#bib.bib57)) evaluated the victim LLMs by
    AdvGLUE (Wang et al., [2021](#bib.bib54)) that is composed of adversarial samples
    against BERT-based models (Devlin et al., [2018](#bib.bib13); Liu et al., [2019](#bib.bib29)).
    Furthermore, Wang et al. ([2023a](#bib.bib56)) constructed a AdvGLUE++ dataset
    by attacking the recent LLMs, such as Alpaca-7B (Taori et al., [2023](#bib.bib51)),
    Vicuna-13B (Chiang et al., [2023](#bib.bib10)) and StableVicuna-13B (Zheng et al.,
    [2023](#bib.bib64)).'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '现有研究在 GLUE 数据集上评估 LLM 的对抗鲁棒性 (Wang et al., [2018](#bib.bib53))，其中要求 LLM 根据包含任务描述和原始样本的提示来解决分类任务（如图
    [2](#S2.F2 "Figure 2 ‣ Robustness evaluation of language models. ‣ 2 Related Work
    ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack") 所示）。特别地，Zhu et al.
    ([2023](#bib.bib66)) 基于开源 LLM 生成了对抗任务描述，并将其转移到攻击其他黑箱 LLM。Wang et al. ([2023b](#bib.bib57))
    使用 AdvGLUE (Wang et al., [2021](#bib.bib54)) 对目标 LLM 进行了评估，该数据集包含针对 BERT 模型的对抗样本
    (Devlin et al., [2018](#bib.bib13); Liu et al., [2019](#bib.bib29))。此外，Wang et
    al. ([2023a](#bib.bib56)) 通过攻击近期的 LLM，如 Alpaca-7B (Taori et al., [2023](#bib.bib51))、Vicuna-13B
    (Chiang et al., [2023](#bib.bib10)) 和 StableVicuna-13B (Zheng et al., [2023](#bib.bib64))
    构建了一个 AdvGLUE++ 数据集。'
- en: However, we find AdvGLUE and AdvGLUE++ are neither effective nor efficient when
    we evaluate black-box victim LLMs such as GPT-3.5 (OpenAI, [2023](#bib.bib37)).
    The adversarial samples in AdvGLUE and AdvGLUE++ are generated against the pre-trained
    BERT-based models and other open-source LLMs and are transferred to the victim
    LLM. It is highly likely we cannot genuinely measure the victim LLM’s robustness.
    Besides, constructing AdvGLUE and AdvGLUE++ requires large computational sources,
    which degrades its practicality in efficiently auditing LLM’s adversarial robustness.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们发现 AdvGLUE 和 AdvGLUE++ 在评估像 GPT-3.5 (OpenAI, [2023](#bib.bib37)) 这样的黑箱目标
    LLM 时既不有效也不高效。AdvGLUE 和 AdvGLUE++ 中的对抗样本是针对预训练的 BERT 模型和其他开源 LLM 生成的，并转移到目标 LLM
    上。我们很可能无法真正衡量目标 LLM 的鲁棒性。此外，构建 AdvGLUE 和 AdvGLUE++ 需要大量计算资源，这降低了其在高效审计 LLM 对抗鲁棒性方面的实用性。
- en: '![Refer to caption](img/ea2c6f7ea9a3eeeccb302a08525b215b.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ea2c6f7ea9a3eeeccb302a08525b215b.png)'
- en: 'Figure 1: Our proposed prompt-based adversarial attack (PromptAttack) against
    LLMs is composed of three key components: original input, attack objective, and
    attack guidance.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：我们提出的基于提示的对抗攻击（PromptAttack）针对 LLM 由三个关键组成部分构成：原始输入、攻击目标和攻击指导。
- en: 'Therefore, we propose a prompt-based adversarial attack, called PromptAttack,
    that can efficiently find failure modes of a victim LLM by itself. As shown in
    Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ An LLM can Fool Itself: A Prompt-Based
    Adversarial Attack"), we construct an *attack prompt* that is composed of three
    critical ingredients: *original input* (OI), *attack objective* (AO), and *attack
    guidance* (AG). The OI contains the original sample and its ground-truth label.
    The AO is a task description that requires the LLM to generate a new sentence.
    The new sentence should maintain the original semantics and should be misclassified
    by the LLM itself. The AG guides the LLM on how to generate the new sentence according
    to the perturbation instructions, as shown in Table [1](#S3.T1 "Table 1 ‣ 3 Prompt-Based
    Adversarial Attack ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack").
    The perturbation instructions require small changes at character, word, and sentence
    levels, respectively.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '因此，我们提出了一种基于提示的对抗攻击，称为 PromptAttack，可以高效地自行发现目标 LLM 的失败模式。如图 [1](#S1.F1 "Figure
    1 ‣ 1 Introduction ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack")
    所示，我们构建了一个 *攻击提示*，它由三个关键成分组成：*原始输入* (OI)、*攻击目标* (AO) 和 *攻击指导* (AG)。OI 包含原始样本及其真实标签。AO
    是一个任务描述，要求 LLM 生成一个新句子。新句子应保持原始语义，并且应被 LLM 自身误分类。AG 指导 LLM 根据扰动指令生成新句子，如表 [1](#S3.T1
    "Table 1 ‣ 3 Prompt-Based Adversarial Attack ‣ An LLM can Fool Itself: A Prompt-Based
    Adversarial Attack") 所示。扰动指令要求在字符、词汇和句子级别分别进行小幅度的更改。'
- en: Besides, we use a fidelity filter (Wang et al., [2021](#bib.bib54)) to ensure
    that the adversarial samples generated by PromptAttack maintain the original semantic
    meaning. Following AdvGLUE (Wang et al., [2021](#bib.bib54)), we leverage *word
    modification ratio* and *BERTScore* (Zhang et al., [2019](#bib.bib63)) to measure
    the fidelity. If fidelity scores are not satisfactory, PromptAttack outputs the
    original sample without attacking.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们使用了保真度过滤器（Wang 等人，[2021](#bib.bib54)）以确保 PromptAttack 生成的对抗样本保持原有的语义含义。遵循
    AdvGLUE（Wang 等人，[2021](#bib.bib54)），我们利用*词汇修改比率*和*BERTScore*（Zhang 等人，[2019](#bib.bib63)）来衡量保真度。如果保真度评分不令人满意，PromptAttack
    会输出原始样本而不进行攻击。
- en: Furthermore, we propose two strategies to further enhance the attack power of
    PromptAttack, which is inspired by few-shot inference (Logan IV et al., [2021](#bib.bib30);
    Liu et al., [2023b](#bib.bib26)) and ensemble attacks (Croce & Hein, [2020](#bib.bib11)).
    Our few-shot strategy provides a few AG examples that satisfy the perturbation
    instructions, which can help the LLM better understand how to generate the perturbations
    and further improve the quality of adversarial samples. Our ensemble strategy
    means searching for an adversarial sample that can successfully fool the LLM from
    an ensemble of adversarial samples according to various levels of perturbation
    instructions, which can substantially increase the possibility of finding an effective
    adversarial sample.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们提出了两种策略来进一步增强 PromptAttack 的攻击力，这些策略受到少量样本推理（Logan IV 等人，[2021](#bib.bib30)；Liu
    等人，[2023b](#bib.bib26)）和集成攻击（Croce & Hein，[2020](#bib.bib11)）的启发。我们的少量样本策略提供了满足扰动指令的一些
    AG 示例，这可以帮助 LLM 更好地理解如何生成扰动，并进一步提高对抗样本的质量。我们的集成策略意味着从根据各种扰动指令的对抗样本集成中寻找能够成功欺骗
    LLM 的对抗样本，这可以大大增加找到有效对抗样本的可能性。
- en: 'Comprehensive empirical results evaluated on the GLUE dataset (Wang et al.,
    [2018](#bib.bib53)) validate the effectiveness of our proposed PromptAttack. We
    take Llama2-7B (Touvron et al., [2023](#bib.bib52)), Llama2-13B, and GPT-3.5 (OpenAI,
    [2023](#bib.bib37)) as the victim LLMs. Empirical results validate that PrompAttack
    can successfully fool the victim LLM, which corroborates that the LLM fools itself
    via the well-designed attack prompt. Further, we demonstrate that the attack success
    rate (ASR) against Llama2 and GPT-3.5 achieved by our PromptAttack can significantly
    outperform AdvGLUE and AdvGLUE++ by a large margin. For example, PromptAttack
    against GPT-3.5 increases the ASR by 42.18% (from 33.04% to 75.23%) in the SST-2 (Socher
    et al., [2013](#bib.bib48)) task and 24.85% (from 14.76% to 39.61%) in the QQP
    task (Wang et al., [2017](#bib.bib58)). Note that, PromptAttack only requires
    a few queries through the victim LLM (e.g., OpenAI API) without accessing the
    internal parameters, which makes it extremely practical. Interestingly, as shown
    in Figure [2](#S2.F2 "Figure 2 ‣ Robustness evaluation of language models. ‣ 2
    Related Work ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack"), we
    find that a simple emoji “:)” can successfully fool GPT-3.5 to make an incorrect
    prediction.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '在 GLUE 数据集（Wang 等人，[2018](#bib.bib53)）上评估的全面实证结果验证了我们提出的 PromptAttack 的有效性。我们以
    Llama2-7B（Touvron 等人，[2023](#bib.bib52)）、Llama2-13B 和 GPT-3.5（OpenAI，[2023](#bib.bib37)）作为受害
    LLM。实证结果验证了 PromptAttack 能够成功欺骗受害 LLM，这证明了 LLM 通过精心设计的攻击提示欺骗了自己。此外，我们展示了 PromptAttack
    对 Llama2 和 GPT-3.5 的攻击成功率（ASR）可以显著超过 AdvGLUE 和 AdvGLUE++，差距很大。例如，PromptAttack
    对 GPT-3.5 的攻击在 SST-2（Socher 等人，[2013](#bib.bib48)）任务中将 ASR 提高了 42.18%（从 33.04%
    提升至 75.23%），在 QQP 任务（Wang 等人，[2017](#bib.bib58)）中提高了 24.85%（从 14.76% 提升至 39.61%）。值得注意的是，PromptAttack
    只需要通过受害 LLM（如 OpenAI API）进行少量查询，无需访问内部参数，这使其极具实用性。有趣的是，如图 [2](#S2.F2 "Figure 2
    ‣ Robustness evaluation of language models. ‣ 2 Related Work ‣ An LLM can Fool
    Itself: A Prompt-Based Adversarial Attack") 所示，我们发现一个简单的表情符号 “:)” 就能成功欺骗 GPT-3.5
    进行错误预测。'
- en: 2 Related Work
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: 'We introduce the related works w.r.t. adversarial attacks, robustness evaluation
    of language models, and LLM’s reliability issues. Extended related works w.r.t.
    prompt-based learning and prompt engineering are discussed in Appendix [A](#A1
    "Appendix A Extended Related Work ‣ An LLM can Fool Itself: A Prompt-Based Adversarial
    Attack").'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '我们介绍了与对抗攻击、语言模型的鲁棒性评估和 LLM 的可靠性问题相关的研究工作。关于基于提示的学习和提示工程的扩展相关工作讨论见附录 [A](#A1
    "Appendix A Extended Related Work ‣ An LLM can Fool Itself: A Prompt-Based Adversarial
    Attack")。'
- en: Adversarial attacks.
  id: totrans-26
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 对抗攻击。
- en: Adversarial attacks can impose imperceptible adversarial perturbations to the
    original sample and then mislead deep neural networks (DNNs) to make an incorrect
    classification result (Szegedy et al., [2014](#bib.bib50)). Studies of adversarial
    attacks (Goodfellow et al., [2014](#bib.bib19); Szegedy et al., [2014](#bib.bib50);
    Athalye et al., [2018](#bib.bib2); Croce & Hein, [2020](#bib.bib11)) have highlighted
    the serious security issues in various domains such as computer vision (Xie et al.,
    [2017](#bib.bib61); Mahmood et al., [2021](#bib.bib32)), natural language processing (Wang
    et al., [2021](#bib.bib54)), recommendation system (Peng & Mine, [2020](#bib.bib38)),
    *etc*. Therefore, a reliable robustness evaluation of the DNN is necessary to
    check whether it is adversarially robust and safe before deploying it in safety-critical
    applications such as medicine (Buch et al., [2018](#bib.bib9)) and autonomous
    driving (Kurakin et al., [2018](#bib.bib22)).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗攻击可以对原始样本施加几乎不可察觉的对抗扰动，从而误导深度神经网络（DNN）产生错误的分类结果（Szegedy 等，[2014](#bib.bib50)）。对抗攻击的研究（Goodfellow
    等，[2014](#bib.bib19)；Szegedy 等，[2014](#bib.bib50)；Athalye 等，[2018](#bib.bib2)；Croce
    & Hein，[2020](#bib.bib11)）突出了在计算机视觉（Xie 等，[2017](#bib.bib61)；Mahmood 等，[2021](#bib.bib32)）、自然语言处理（Wang
    等，[2021](#bib.bib54)）、推荐系统（Peng & Mine，[2020](#bib.bib38)）等多个领域的严重安全问题，*等等*。因此，在将DNN应用于安全关键的应用领域（如医学（Buch
    等，[2018](#bib.bib9)）和自动驾驶（Kurakin 等，[2018](#bib.bib22)）之前，进行可靠的鲁棒性评估是必要的。
- en: Robustness evaluation of language models.
  id: totrans-28
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 语言模型的鲁棒性评估。
- en: AdvGLUE (Wang et al., [2021](#bib.bib54)) and AdvGLUE++ (Wang et al., [2023a](#bib.bib56))
    are adversarial datasets for evaluating the robustness of language models (Wang
    et al., [2021](#bib.bib54)) as well as LLMs (Wang et al., [2023b](#bib.bib57);
    [a](#bib.bib56)). AdvGLUE is composed of adversarial samples generated by an ensemble
    of adversarial textual attacks (Li et al., [2018](#bib.bib23); Gao et al., [2018](#bib.bib14);
    Li et al., [2020](#bib.bib24); Jin et al., [2019](#bib.bib21); Iyyer et al., [2018](#bib.bib20);
    Naik et al., [2018](#bib.bib36); Ribeiro et al., [2020](#bib.bib43)) at character,
    word, and sentence levels against an ensemble of BERT-based models (Devlin et al.,
    [2018](#bib.bib13); Liu et al., [2019](#bib.bib29)). AdvGLUE++ contains adversarial
    samples generated by an ensemble of character-level and word-level attacks (Li
    et al., [2018](#bib.bib23); Jin et al., [2019](#bib.bib21); Li et al., [2020](#bib.bib24);
    Zang et al., [2020](#bib.bib62); Wang et al., [2022](#bib.bib55)) against an ensemble
    of open-source LLMs including Alpaca, Vicuna and StableVicuna. However, robustness
    evaluation of black-box victim LLMs (e.g., GPT-3.5) based on the transferable
    adversarial samples in AdvGLUE and AdvGLUE++ cannot genuinely measure the victim
    LLM’s robustness. Directly applying current adversarial attacks to large-scale
    LLMs (e.g., GPT-3.5) to construct adversarial samples is computationally prohibitive.
    Therefore, in our paper, we propose a novel adversarial attack that can efficiently
    generate the adversarial sample against the victim LLM and thus can serve as an
    effective tool to evaluate the LLM’s robustness.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: AdvGLUE（Wang 等，[2021](#bib.bib54)）和AdvGLUE++（Wang 等，[2023a](#bib.bib56)）是用于评估语言模型（Wang
    等，[2021](#bib.bib54)）及LLMs（Wang 等，[2023b](#bib.bib57)；[a](#bib.bib56)）鲁棒性的对抗数据集。AdvGLUE由一组对抗性文本攻击（Li
    等，[2018](#bib.bib23)；Gao 等，[2018](#bib.bib14)；Li 等，[2020](#bib.bib24)；Jin 等，[2019](#bib.bib21)；Iyyer
    等，[2018](#bib.bib20)；Naik 等，[2018](#bib.bib36)；Ribeiro 等，[2020](#bib.bib43)）生成的对抗样本组成，攻击级别包括字符、单词和句子，对象为一组基于BERT的模型（Devlin
    等，[2018](#bib.bib13)；Liu 等，[2019](#bib.bib29)）。AdvGLUE++包含由字符级和单词级攻击（Li 等，[2018](#bib.bib23)；Jin
    等，[2019](#bib.bib21)；Li 等，[2020](#bib.bib24)；Zang 等，[2020](#bib.bib62)；Wang 等，[2022](#bib.bib55)）生成的对抗样本，攻击对象为包括Alpaca、Vicuna和StableVicuna在内的开源LLMs。然而，基于AdvGLUE和AdvGLUE++中的可转移对抗样本对黑箱受害LLMs（例如GPT-3.5）进行的鲁棒性评估无法真正测量受害LLM的鲁棒性。直接对大规模LLMs（例如GPT-3.5）应用当前对抗攻击以构造对抗样本在计算上是不切实际的。因此，在我们的论文中，我们提出了一种新颖的对抗攻击方法，可以有效生成针对受害LLM的对抗样本，从而作为评估LLM鲁棒性的有效工具。
- en: '![Refer to caption](img/68f0b1aef66fba4af14f51cb5f48e3c9.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/68f0b1aef66fba4af14f51cb5f48e3c9.png)'
- en: 'Figure 2: Our proposed PromptAttack generates an adversarial sample by adding
    an emoji “:)”, which can successfully fool GPT-3.5\.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：我们提出的PromptAttack通过添加一个表情符号“:)”生成对抗样本，这可以成功欺骗GPT-3.5。
- en: LLM’s reliability issues.
  id: totrans-32
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: LLM的可靠性问题。
- en: Recent studies have disclosed that LLMs are facing the following reliability
    issues. (1) *Hallucination*. Since LLMs are trained on massive crawled datasets,
    there is evidence suggesting they may pose potential risks by producing texts
    containing factual errors (Gehman et al., [2020](#bib.bib17); Bender et al., [2021](#bib.bib4);
    McKenna et al., [2023](#bib.bib34); Manakul et al., [2023](#bib.bib33)). (2) *Jailbreak
    attack*. LLM has the potential risk of privacy leakage since Jailbreak attack (Si
    et al., [2022](#bib.bib46); Rao et al., [2023](#bib.bib42); Shanahan et al., [2023](#bib.bib44);
    Liu et al., [2023d](#bib.bib28)) can elicit model-generated content that divulges
    the information of training data which could contain sensitive or private information.
    (3) *Prompt injection attack*. LLM can output disruptive outcomes such as objectionable
    contents and unauthorized disclosure of sensitive information, under the prompt
    injection attack (Liu et al., [2023c](#bib.bib27); Perez & Ribeiro, [2022](#bib.bib39);
    Apruzzese et al., [2023](#bib.bib1); Zou et al., [2023](#bib.bib67); Zhu et al.,
    [2023](#bib.bib66)) that overrides an LLM’s original prompt and directs it to
    follow malicious instructions. (4) *Adversarial attack*. Adversarial attacks against
    victim LLMs can perturb either task descriptions or original samples. Zhu et al.
    ([2023](#bib.bib66)) leveraged adversarial attack methods used in AdvGLUE to generate
    adversarial task descriptions and transferred them to successfully fool GPT-3.5.
    Wang et al. ([2023b](#bib.bib57)) and Wang et al. ([2023a](#bib.bib56)) used transferable
    adversarial samples in AdvGLUE and AdvGLUE++ to show that LLMs are adversarially
    vulnerable. In our paper, we propose an effective prompt-based attack against
    a victim LLM, which further highlights the LLM’s adversarial vulnerability.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究揭示了LLMs面临以下可靠性问题。（1）*幻觉*。由于LLMs在大量爬取的数据集上训练，有证据表明它们可能通过生成包含事实错误的文本而带来潜在风险（Gehman等，[2020](#bib.bib17)；Bender等，[2021](#bib.bib4)；McKenna等，[2023](#bib.bib34)；Manakul等，[2023](#bib.bib33)）。（2）*越狱攻击*。由于越狱攻击（Si等，[2022](#bib.bib46)；Rao等，[2023](#bib.bib42)；Shanahan等，[2023](#bib.bib44)；Liu等，[2023d](#bib.bib28)）可能引发泄露训练数据中可能包含敏感或私人信息的模型生成内容，因此LLM存在隐私泄露的潜在风险。（3）*提示注入攻击*。LLM在提示注入攻击（Liu等，[2023c](#bib.bib27)；Perez
    & Ribeiro，[2022](#bib.bib39)；Apruzzese等，[2023](#bib.bib1)；Zou等，[2023](#bib.bib67)；Zhu等，[2023](#bib.bib66)）下可以输出如令人反感的内容和未经授权的敏感信息泄露等破坏性结果，该攻击会覆盖LLM的原始提示并指示其遵循恶意指令。（4）*对抗攻击*。对抗攻击针对受害LLMs可以扰动任务描述或原始样本。Zhu等（[2023](#bib.bib66)）利用AdvGLUE中的对抗攻击方法生成对抗任务描述，并成功欺骗了GPT-3.5。Wang等（[2023b](#bib.bib57)）和Wang等（[2023a](#bib.bib56)）在AdvGLUE和AdvGLUE++中使用了可转移的对抗样本，展示了LLMs的对抗脆弱性。在我们的论文中，我们提出了一种有效的基于提示的攻击方法，进一步突出了LLM的对抗脆弱性。
- en: 3 Prompt-Based Adversarial Attack
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 基于提示的对抗攻击
- en: In this section, we first illustrate the overall framework of our proposed prompt-based
    adversarial attack, called PromptAttack. Then, we use a fidelity filter to guarantee
    that the adversarial sample generated by PromptAttack maintains the original semantics.
    Finally, we propose two strategies inspired by few-shot inference and ensemble
    attacks to boost the attack power of PromptAttack.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们首先阐述了我们提出的基于提示的对抗攻击的整体框架，称为PromptAttack。然后，我们使用一个保真度过滤器来确保PromptAttack生成的对抗样本保持原始语义。最后，我们提出了两种策略，灵感来自少量样本推理和集成攻击，以增强PromptAttack的攻击力。
- en: 'Table 1: Perturbation instructions at the character, word, and sentence levels,
    respectively.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：字符、词和句子级别的扰动指令。
- en: '|'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Perturbation &#124;'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 扰动 &#124;'
- en: '&#124; level &#124;'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; level &#124;'
- en: '| Abbre. | #perturbation_instruction |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| Abbre. | #perturbation_instruction |'
- en: '| --- | --- | --- |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Character | C1 |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| Character | C1 |'
- en: '&#124; Choose at most two words in the sentence, and change them so that &#124;'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 选择句子中的至多两个词，并更改它们使其具有拼写错误。 &#124;'
- en: '&#124; they have typos. &#124;'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 他们有拼写错误。 &#124;'
- en: '|'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| C2 | Change at most two letters in the sentence. |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| C2 | 在句子中更改至多两个字母。 |'
- en: '| C3 | Add at most two extraneous characters to the end of the sentence. |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| C3 | 在句子的末尾添加至多两个多余的字符。 |'
- en: '| Word | W1 | Replace at most two words in the sentence with synonyms. |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| Word | W1 | 用同义词替换句子中的至多两个词。 |'
- en: '| W2 |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| W2 |'
- en: '&#124; Choose at most two words in the sentence that do not contribute &#124;'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 选择句子中的至多两个不贡献的词，并更改它们使其具有拼写错误。 &#124;'
- en: '&#124; to the meaning of the sentence and delete them. &#124;'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 句子的含义并删除它们。 &#124;'
- en: '|'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| W3 | Add at most two semantically neutral words to the sentence. |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| W3 | 向句子中添加最多两个语义中立的词。 |'
- en: '| Sentence | S1 |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 句子 | S1 |'
- en: '&#124; Add a randomly generated short meaningless handle after the &#124;'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 在 &#124; 后添加一个随机生成的短无意义句柄。'
- en: '&#124; sentence, such as @fasuv3. &#124;'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 句子，例如 @fasuv3. &#124;'
- en: '|'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| S2 | Paraphrase the sentence. |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| S2 | 改写句子。 |'
- en: '| S3 | Change the syntactic structure of the sentence. |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| S3 | 改变句子的句法结构。 |'
- en: 3.1 Framework of PromptAttack
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 PromptAttack 框架
- en: 'We convert the adversarial textual attacks into an attack prompt that can ask
    the LLM to search for its own failure mode. Our proposed PromptAttack consists
    of three key components: *original input*, *attack objective*, and *attack guidance*.
    Next, we introduce each part in that sequence.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将对抗文本攻击转换为一种攻击提示，以便让 LLM 查找其自身的失败模式。我们提出的 PromptAttack 由三个关键组件组成：*原始输入*、*攻击目标*
    和 *攻击指导*。接下来，我们将按顺序介绍每个部分。
- en: Original input (OI).
  id: totrans-62
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 原始输入（OI）。
- en: We let  be the original test dataset consisting of  data points. For each data
    point ,  is the original sample where  is the number of sentences,  refers to
    the type of -th sentence, and  refers to the content of -th sentence. For example,
    the original input in QQP (Wang et al., [2017](#bib.bib58)) and MNLI (Williams
    et al., [2018](#bib.bib60)) can have two types of sentences (i.e., ). We follow
    the types defined in their datasets, e.g.,  being “question1” and  being “question2”
    for QQP,  being “premise” and  being “hypothesis” for MNLI.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们让 **`X`** 是由 **`N`** 个数据点组成的原始测试数据集。对于每个数据点，**`x`** 是原始样本，其中 **`M`** 是句子的数量，**`i`**
    指的是第 **`i`** 个句子的类型，**`s_i`** 指的是第 **`i`** 个句子的内容。例如，QQP（Wang 等，[2017](#bib.bib58)）和
    MNLI（Williams 等，[2018](#bib.bib60)）中的原始输入可以有两种类型的句子（即，**`S`**）。我们遵循其数据集中定义的类型，例如，QQP
    中 **`S1`** 为“question1”，**`S2`** 为“question2”，MNLI 中 **`S1`** 为“premise”，**`S2`**
    为“hypothesis”。
- en: Then, for each data point , we denote  as the ground-truth label where  is the
    number of classes and  is the index of the ground-truth label. Note that,  is
    a semantic word or phrase that expresses the semantic meaning of the groud-truth
    label. For example, the label set of SST-2 (Socher et al., [2013](#bib.bib48))
    is {“positive”, “negative”} and that in MNLI is {“entailment”, “neural”, “contradiction”}.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个数据点，我们用 **`y`** 表示真实标签，其中 **`C`** 是类别的数量，**`i`** 是真实标签的索引。注意，**`y`** 是一个表达真实标签语义的词或短语。例如，SST-2（Socher
    等，[2013](#bib.bib48)）的标签集为 {“positive”, “negative”}，而 MNLI 的标签集为 {“entailment”,
    “neutral”, “contradiction”}。
- en: 'The OI converts a data point composed of the original sample and ground-truth
    label sampled from a dataset into a sentence of an attack prompt. Given a data
    point , we can formulate the OI as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 原始输入（OI）将由数据集中的原始样本和真实标签组成的数据点转换为攻击提示的句子。给定一个数据点，我们可以将 OI 表述如下：
- en: '#original_input'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '#original_input'
- en: The original  and  and  and  is classified as .
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 原始 **语义** 和 **语义** 和 **语义** 和 **语义** 被分类为 **语义**。
- en: Attack objective (AO).
  id: totrans-68
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 攻击目标（AO）。
- en: 'The adversarial textual attack aims to generate an adversarial sample that
    should keep the same semantic meaning as its original version and can fool the
    LLM into doing incorrect classification (Li et al., [2018](#bib.bib23); Gao et al.,
    [2018](#bib.bib14); Li et al., [2020](#bib.bib24); Jin et al., [2019](#bib.bib21);
    Ribeiro et al., [2020](#bib.bib43); Iyyer et al., [2018](#bib.bib20)). Here, we
    assume PromptAttack can perturb only one type of sentence for each data point.
    Therefore, given a data point  and the type of the sentence that is targeted to
    be perturbed  where , we formulate the AO as follows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗文本攻击旨在生成一个对抗样本，该样本应保持与其原始版本相同的 **语义**，并能欺骗 LLM 做出错误分类（Li 等，[2018](#bib.bib23)；Gao
    等，[2018](#bib.bib14)；Li 等，[2020](#bib.bib24)；Jin 等，[2019](#bib.bib21)；Ribeiro
    等，[2020](#bib.bib43)；Iyyer 等，[2018](#bib.bib20)）。在这里，我们假设 PromptAttack 只能对每个数据点扰动一种类型的句子。因此，给定一个数据点
    **`x`** 和目标扰动的句子类型 **`T`**，我们可以将 AO 表述如下：
- en: '#attack_objective'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '#attack_objective'
- en: 'Your task is to generate a new  which must satisfy the following conditions:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 你的任务是生成一个新的 **语义**，它必须满足以下条件：
- en: 1\. Keeping the semantic meaning of the new  unchanged;
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 1. 保持新的 **语义** 不变；
- en: 2\. The new  and the original , …, , , …, , should be classified as  or …or
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 2. 新的 **语义** 和原始 **语义**，…，…，…，…，应被分类为 **攻击指导（AG）**。
- en: or  or …or .
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 或 或 …或 。
- en: Attack guidance (AG).
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 攻击指导（AG）。
- en: 'AG contains the perturbation instruction to guide the LLM on how to perturb
    the original sample and specifies the format of the generated text. Here, we first
    introduce the design of the perturbation instruction (listed in Table [1](#S3.T1
    "Table 1 ‣ 3 Prompt-Based Adversarial Attack ‣ An LLM can Fool Itself: A Prompt-Based
    Adversarial Attack")) at character, word, and sentence levels. We demonstrate
    the adversarial samples generated by PromptAttack against GPT-3.5 at various perturbation
    levels in Table [2](#S3.T2 "Table 2 ‣ Attack guidance (AG). ‣ 3.1 Framework of
    PromptAttack ‣ 3 Prompt-Based Adversarial Attack ‣ An LLM can Fool Itself: A Prompt-Based
    Adversarial Attack"). Extensive examples are shown in Table [17](#A2.T17 "Table
    17 ‣ Extensive analyses. ‣ B.6 Attack Transferability ‣ Appendix B Extensive Experimental
    Results ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack") (Appendix [B.7](#A2.SS7
    "B.7 Extensive Examples ‣ Appendix B Extensive Experimental Results ‣ An LLM can
    Fool Itself: A Prompt-Based Adversarial Attack")).'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 'AG包含指导LLM如何扰动原始样本的扰动指令，并指定生成文本的格式。在这里，我们首先介绍字符、词汇和句子级别的扰动指令设计（见表 [1](#S3.T1
    "Table 1 ‣ 3 Prompt-Based Adversarial Attack ‣ An LLM can Fool Itself: A Prompt-Based
    Adversarial Attack")）。我们展示了PromptAttack在各种扰动级别下生成的对抗样本，以对抗GPT-3.5，见表 [2](#S3.T2
    "Table 2 ‣ Attack guidance (AG). ‣ 3.1 Framework of PromptAttack ‣ 3 Prompt-Based
    Adversarial Attack ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack")。表 [17](#A2.T17
    "Table 17 ‣ Extensive analyses. ‣ B.6 Attack Transferability ‣ Appendix B Extensive
    Experimental Results ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack")（附录 [B.7](#A2.SS7
    "B.7 Extensive Examples ‣ Appendix B Extensive Experimental Results ‣ An LLM can
    Fool Itself: A Prompt-Based Adversarial Attack")）中展示了大量示例。'
- en: Firstly, at the character level, TextBugger (Li et al., [2018](#bib.bib23))
    and DeepWordBug (Gao et al., [2018](#bib.bib14)) are principled algorithms for
    generating typo-based AS by first identifying the important words and then replacing
    them with typos. Inspired by TextBugger, we propose perturbation instructions
    *C1* and *C2* that guide the LLM to generate typo-based perturbations. Besides,
    we also propose a new character-level perturbation instruction *C3* that introduces
    extraneous characters at the end of the sentence.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在字符级别，TextBugger （Li et al., [2018](#bib.bib23)）和DeepWordBug （Gao et al.,
    [2018](#bib.bib14)）是生成基于错字的对抗样本的原则性算法，首先识别重要词汇，然后用错字替换它们。受到TextBugger的启发，我们提出了扰动指令*C1*和*C2*，指导LLM生成基于错字的扰动。此外，我们还提出了一种新的字符级扰动指令*C3*，在句子末尾添加额外字符。
- en: Secondly, at the word level, TextFooler (Jin et al., [2019](#bib.bib21)) and
    BERT-ATTACK (Li et al., [2020](#bib.bib24)) select important words and then replace
    them with their synonyms or contextually-similar words. Guided by TextFooler and
    BERT-ATTACK, we take perturbation instruction *W1* to guide the LLM to substitute
    words with synonyms. Besides, we introduce two new perturbation instructions at
    the word level. perturbation instruction *W2* guides the LLM to delete the useless
    words and *W3* allows the LLM to add the semantically-neutral words.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，在词汇级别，TextFooler （Jin et al., [2019](#bib.bib21)）和BERT-ATTACK （Li et al.,
    [2020](#bib.bib24)）选择重要词汇，然后用其同义词或语境相似的词汇替换它们。受到TextFooler和BERT-ATTACK的启发，我们采用扰动指令*W1*指导LLM用同义词替换词汇。此外，我们在词汇级别引入了两个新的扰动指令。扰动指令*W2*指导LLM删除无用词汇，而*W3*允许LLM添加语义中性的词汇。
- en: Thirdly, at the sentence level, CheckList (Ribeiro et al., [2020](#bib.bib43))
    generates the adversarial sample by adding randomly generated URLs and meaningless
    handles to distract model attention. Following CheckList, we design a perturbation
    instruction *S1* that guides the LLM to append meaningless handles at the end
    of the sentence. Inspired by (Wang et al., [2021](#bib.bib54)), we introduce the
    strategy *S2* of paraphrasing the sentence to generate the AS. Further, SCPN (Iyyer
    et al., [2018](#bib.bib20)) generates syntactic-based perturbations by manipulating
    the syntactic structures of the sentence. Therefore, inspired by SCPN, we propose
    a perturbation instruction *S3* that guides the LLM to change the synthetic structure
    of the sentence.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，在句子级别，CheckList （Ribeiro et al., [2020](#bib.bib43)）通过添加随机生成的URL和无意义的句柄来生成对抗样本，以分散模型注意力。遵循CheckList，我们设计了扰动指令*S1*，指导LLM在句子末尾添加无意义的句柄。受（Wang
    et al., [2021](#bib.bib54)）启发，我们引入了* S2*的策略，通过对句子进行意译来生成对抗样本。此外，SCPN （Iyyer et al.,
    [2018](#bib.bib20)）通过操控句子的句法结构生成基于句法的扰动。因此，受到SCPN的启发，我们提出了扰动指令*S3*，指导LLM改变句子的句法结构。
- en: 'Next, we introduce how to formulate the AG based on the perturbation instruction.
    In the AG, we first ask the LLM to only perturb the type of the target sentence
    to finish the task. Then, we provide the perturbation instruction that guides
    the LLM on how to perturb the target sentence to generate the adversarial sample
    that fits the requirement of AO. Finally, we specify that the output of the LLM
    should only contain the newly generated sentence. Therefore, given a data point  and
    the type of the target sentence , we can formulate the AG as follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们介绍如何根据扰动指令制定AG。在AG中，我们首先要求LLM仅扰动目标句子的类型以完成任务。然后，我们提供指导LLM如何扰动目标句子的扰动指令，以生成符合AO要求的对抗样本。最后，我们指定LLM的输出应仅包含新生成的句子。因此，给定一个数据点和目标句子的类型，我们可以将AG制定如下：
- en: '#attack_guidance'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '#attack_guidance'
- en: 'You can finish the task by modifying  using the following guidance:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过以下指导来完成任务：
- en: 'A #perturbation_instruction sampled from Table [1](#S3.T1 "Table 1 ‣ 3 Prompt-Based
    Adversarial Attack ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack")'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 从表格 [1](#S3.T1 "表 1 ‣ 3 基于提示的对抗攻击 ‣ LLM如何自欺欺人：基于提示的对抗攻击")中抽取的#perturbation_instruction
- en: Only output the new  without anything else.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 仅输出新生成的内容，不包含其他任何内容。
- en: 'The attack prompt is composed of three parts including #original_input, #attack_objective,
    and #attack_guidance together. Therefore, we can automatically convert a data
    point in the test dataset into an attack prompt. Then, we take the generated sentence
    via prompting the LLM using the attack prompt as the adversarial sample.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击提示由三个部分组成，包括#original_input、#attack_objective和#attack_guidance。因此，我们可以自动将测试数据集中的数据点转换为攻击提示。然后，我们通过使用攻击提示来提示LLM生成的句子作为对抗样本。
- en: 'Table 2: Examples of adversarial samples generated by PromptAttack against
    GPT-3.5 in the SST-2 (Socher et al., [2013](#bib.bib48)) task. Extensive examples
    and experimental details are in Appendix [B.7](#A2.SS7 "B.7 Extensive Examples
    ‣ Appendix B Extensive Experimental Results ‣ An LLM can Fool Itself: A Prompt-Based
    Adversarial Attack").'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：PromptAttack针对GPT-3.5在SST-2 (Socher et al., [2013](#bib.bib48))任务中生成的对抗样本示例。详细示例和实验细节见附录 [B.7](#A2.SS7
    "B.7 详细示例 ‣ 附录 B 详尽实验结果 ‣ LLM如何自欺欺人：基于提示的对抗攻击")。
- en: '|'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Perturbation &#124;'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 扰动 &#124;'
- en: '&#124; level &#124;'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 水平 &#124;'
- en: '| sample |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 示例 |'
- en: '&#124; Label  &#124;'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 标签  &#124;'
- en: '&#124; Prediction &#124;'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 预测 &#124;'
- en: '|'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| --- | --- | --- |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '|'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Character &#124;'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 字符 &#124;'
- en: '&#124; (*C2*) &#124;'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (*C2*) &#124;'
- en: '|'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Original: unfortunately, it’s not silly fun unless you enjoy &#124;'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原文：不幸的是，除非你喜欢&#124;'
- en: '&#124; really bad movies. &#124;'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 真的很糟糕的电影。&#124;'
- en: '&#124; Adversarial: unfortunately, it’s not silly fun unless you &#124;'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对抗：不幸的是，除非你&#124;'
- en: '&#124; enjoy really bsad movies. &#124;'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 享受真的很糟糕的电影。&#124;'
- en: '|'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; negative  &#124;'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 负面  &#124;'
- en: '&#124; positive &#124;'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 正面 &#124;'
- en: '|'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Word &#124;'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 单词 &#124;'
- en: '&#124; (*W1*) &#124;'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (*W1*) &#124;'
- en: '|'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Original: the iditarod lasts for days - this just felt like it did.
    &#124;'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原文：iditarod比赛持续数天——这只是感觉如此。&#124;'
- en: '&#124; Adversarial: the iditarod lasts for days - this just simply felt &#124;'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对抗：iditarod比赛持续数天——这只是简单地感觉&#124;'
- en: '&#124; like it did. &#124;'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 像它那样。&#124;'
- en: '|'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; negative  &#124;'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 负面  &#124;'
- en: '&#124; positive &#124;'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 正面 &#124;'
- en: '|'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Sentence &#124;'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 句子 &#124;'
- en: '&#124; (*S1*) &#124;'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (*S1*) &#124;'
- en: '|'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Original: corny, schmaltzy and predictable, but still manages &#124;'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原文：俗气、伤感和可预测，但仍然设法&#124;'
- en: '&#124; to be kind of heartwarming, nonetheless. &#124;'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 尽管如此，仍然有点温馨。&#124;'
- en: '&#124; Adversarial: corny, schmaltzy and predictable, but still &#124;'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对抗：俗气、伤感和可预测，但仍然&#124;'
- en: '&#124; manages to be kind of heartwarming, nonetheless. @kjdjq2. &#124;'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 仍然设法有点温馨。@kjdjq2. &#124;'
- en: '|'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; positive  &#124;'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 正面  &#124;'
- en: '&#124; negative &#124;'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 负面 &#124;'
- en: '|'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 3.2 Fidelity Filter
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 保真度过滤器
- en: 'In this subsection, we introduce a fidelity filter (Wang et al., [2021](#bib.bib54))
    based on *word modification ratio* (Wang et al., [2021](#bib.bib54)) and *BERTScore* (Zhang
    et al., [2019](#bib.bib63)) to improve the quality of the adversarial sample.
    Given the original sample  and the adversarial sample , we denote  as the function
    that measures what percentage of words are perturbed, and  as the BERTScore (Zhang
    et al., [2019](#bib.bib63)) function that measures the semantic similarity between
    the adversarial sample  and its original version . We follow Zhang et al. ([2019](#bib.bib63))
    to calculate BERTScore and provide the formulation of  in Appendix [B.2](#A2.SS2
    "B.2 BERTScore ‣ Appendix B Extensive Experimental Results ‣ An LLM can Fool Itself:
    A Prompt-Based Adversarial Attack"). Given a data point  and the generated AS
    , the fidelity filter works as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '在本小节中，我们介绍了一种基于*词汇修改比例*（Wang et al., [2021](#bib.bib54)）和*BERTScore*（Zhang
    et al., [2019](#bib.bib63)）的保真度过滤器，以提高对抗样本的质量。给定原始样本和对抗样本，我们将作为测量词汇被扰动的百分比的函数，将BERTScore（Zhang
    et al., [2019](#bib.bib63)）作为测量对抗样本和其原始版本之间语义相似性的函数。我们遵循Zhang et al.（[2019](#bib.bib63)）计算BERTScore，并在附录[B.2](#A2.SS2
    "B.2 BERTScore ‣ Appendix B Extensive Experimental Results ‣ An LLM can Fool Itself:
    A Prompt-Based Adversarial Attack")中提供了的公式。给定一个数据点和生成的AS，保真度过滤器的工作原理如下：'
- en: '|  |  |  | (1) |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (1) |'
- en: where  is the fidelity filter function,  is an indicator function, and  and  are
    the thresholds to control the fidelity. In this way, we can automatically filter
    out the low-quality adversarial sample whose semantic meaning has significantly
    changed, thus guaranteeing that the generated adversarial sample is of high fidelity.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 其中是保真度过滤函数，是指示函数，和是控制保真度的阈值。通过这种方式，我们可以自动过滤掉语义意义显著改变的低质量对抗样本，从而保证生成的对抗样本具有较高的保真度。
- en: 3.3 Enhancing PromptAttack
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 提升PromptAttack
- en: We propose two strategies inspired by few-shot inference (Logan IV et al., [2021](#bib.bib30))
    and ensemble attacks (Croce & Hein, [2020](#bib.bib11)) to boost the attack power
    of PromptAttack.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出了两种策略，灵感来自少量示例推理（Logan IV et al., [2021](#bib.bib30)）和集成攻击（Croce & Hein,
    [2020](#bib.bib11)），以提升PromptAttack的攻击力。
- en: Few-shot strategy.
  id: totrans-136
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 少量示例策略。
- en: Here, inspired by few-shot inference (Logan IV et al., [2021](#bib.bib30)),
    introducing the examples that fit the task description can help the LLM understand
    the task and thus improve the ability of the LLM to perform the task. Therefore,
    we propose the few-shot AG which is an incorporation of the AG and a few examples
    that fit the corresponding perturbation instructions. In this way, it is easier
    for the LLM to understand the perturbation instructions via learning the examples,
    thus making LLMs generate the adversarial sample of higher quality and stronger
    attack power.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，受到少量示例推理（Logan IV et al., [2021](#bib.bib30)）的启发，介绍符合任务描述的示例可以帮助LLM理解任务，从而提高LLM执行任务的能力。因此，我们提出了少量示例AG，它是AG和符合相应扰动指令的少量示例的结合。通过这种方式，LLM通过学习示例更容易理解扰动指令，从而使LLM生成更高质量和更强攻击力的对抗样本。
- en: 'To be specific, the few-shot strategy is to replace the AG with the few-shot
    AG in the attack prompt. We generate a set of  examples  where each example is
    composed of an original sentence  and its perturbed version  that fits the corresponding
    perturbation instruction. In our paper, we set  by default. Given a set of examples
    , we formulate the few-shot AG as follows:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 具体而言，少量示例策略是将攻击提示中的AG替换为少量示例AG。我们生成一组示例，每个示例由一个原始句子和其符合相应扰动指令的扰动版本组成。在我们的论文中，我们默认设置为。给定一组示例，我们将少量示例AG表述如下：
- en: '#few-shot_attack_guidance'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '#少量示例攻击指导'
- en: 'You can finish the task by modifying  using the following guidance:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以按照以下指导完成任务：
- en: 'A #perturbation_instruction sampled from Table [1](#S3.T1 "Table 1 ‣ 3 Prompt-Based
    Adversarial Attack ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack")'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '从表[1](#S3.T1 "Table 1 ‣ 3 Prompt-Based Adversarial Attack ‣ An LLM can Fool
    Itself: A Prompt-Based Adversarial Attack")中采样的#扰动指令'
- en: 'Here are five examples that fit the guidance:  -> ;  -> ; ;  -> .'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是五个符合指导的示例：->；->；；->。
- en: Only output the new  without anything else.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 只输出新的，其他内容不做输出。
- en: Ensemble strategy.
  id: totrans-144
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 集成策略。
- en: Ensemble attack (Croce & Hein, [2020](#bib.bib11)) uses an ensemble of various
    adversarial attacks so that it can increase the possibility of finding effective
    adversarial samples. Similarly, our ensemble strategy is to search for an adversarial
    sample that can successfully fool the victim LLM from an ensemble of adversarial
    samples at different perturbation levels. To be specific, given a data point ,
    PromptAttack based on nine different perturbations instructions can generate a
    set of adversarial samples . We traverse all adversarial samples from  to  and
    output the adversarial sample that can successfully fool the LLM and has the highest
    BERTScore; otherwise, we output the original sample. In this way, our ensemble
    strategy uses an ensemble of PromptAttack at various perturbation levels, thus
    significantly enhancing attack power.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 集成攻击 (Croce & Hein, [2020](#bib.bib11)) 使用了各种对抗攻击的集成，以增加找到有效对抗样本的可能性。类似地，我们的集成策略是从不同扰动级别的对抗样本集成中搜索一个能够成功欺骗受害者
    LLM 的对抗样本。具体而言，给定一个数据点，PromptAttack 基于九种不同扰动指令可以生成一组对抗样本。我们遍历所有从到的对抗样本，并输出能够成功欺骗
    LLM 且具有最高 BERTScore 的对抗样本；否则，我们输出原始样本。通过这种方式，我们的集成策略利用了不同扰动级别的 PromptAttack 集成，从而显著增强了攻击力量。
- en: 4 Experiments
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实验
- en: In this section, we demonstrate that our proposed PromptAttack can successfully
    attack Llama2 (Touvron et al., [2023](#bib.bib52)) and GPT-3.5 (OpenAI, [2023](#bib.bib37)),
    which justifies that LLM can fool itself. We validate that our proposed PromptAttack
    has significantly stronger attack power compared to AdvGLUE and AdvGLUE++ on GLUE
    dataset (Wang et al., [2018](#bib.bib53)). Further, we provide extensive empirical
    analyses of the properties of the adversarial samples generated by PromptAttack.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们展示了我们提出的 PromptAttack 能够成功攻击 Llama2 (Touvron et al., [2023](#bib.bib52))
    和 GPT-3.5 (OpenAI, [2023](#bib.bib37))，这证明了 LLM 能够欺骗自己。我们验证了与 AdvGLUE 和 AdvGLUE++
    相比，我们提出的 PromptAttack 在 GLUE 数据集 (Wang et al., [2018](#bib.bib53)) 上具有显著更强的攻击力量。此外，我们提供了对
    PromptAttack 生成的对抗样本特性的广泛实证分析。
- en: GLUE dataset.
  id: totrans-148
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: GLUE 数据集。
- en: 'Following AdvGLUE (Wang et al., [2021](#bib.bib54)), we consider the following
    five challenging tasks in GLUE dataset (Wang et al., [2018](#bib.bib53)): Sentiment
    Analysis (SST-2), Duplicate Question Detection (QQP), and Natural Language Inference
    (MNLI, RTE, QNLI). We provide a detailed description of each task in Appendix [B.1](#A2.SS1
    "B.1 GLUE Dataset ‣ Appendix B Extensive Experimental Results ‣ An LLM can Fool
    Itself: A Prompt-Based Adversarial Attack").'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '根据 AdvGLUE (Wang et al., [2021](#bib.bib54))，我们考虑 GLUE 数据集 (Wang et al., [2018](#bib.bib53))
    中的五个挑战性任务：情感分析 (SST-2)、重复问题检测 (QQP) 和自然语言推理 (MNLI、RTE、QNLI)。我们在附录 [B.1](#A2.SS1
    "B.1 GLUE Dataset ‣ Appendix B Extensive Experimental Results ‣ An LLM can Fool
    Itself: A Prompt-Based Adversarial Attack") 中提供了每个任务的详细描述。'
- en: Task description.
  id: totrans-150
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 任务描述。
- en: Following PromptBench (Zhu et al., [2023](#bib.bib66)), we used four types of
    task descriptions, i.e., the zero-shot (ZS)/few-shot (FS) task-oriented (TO)/role-oriented
    (RO) task descriptions. For simplicity, we denote them as ZS-TO, ZS-RO, FS-TO,
    FS-RO task descriptions. We list the task descriptions used for each task in [Anonymous
    Github](https://anonymous.4open.science/r/PromptAttack_ICLR24-FE1B/) and calculate
    the average results over all task descriptions to provide a reliable evaluation
    for each task.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 遵循 PromptBench (Zhu et al., [2023](#bib.bib66))，我们使用了四种任务描述，即零样本 (ZS)/少样本 (FS)
    任务导向 (TO)/角色导向 (RO) 任务描述。为了简单起见，我们将它们表示为 ZS-TO、ZS-RO、FS-TO 和 FS-RO 任务描述。我们列出了每个任务使用的任务描述在
    [Anonymous Github](https://anonymous.4open.science/r/PromptAttack_ICLR24-FE1B/)
    中，并计算所有任务描述的平均结果，以提供每个任务的可靠评估。
- en: Baselines.
  id: totrans-152
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基准。
- en: We take the adversarial datasets AdvGLUE (Wang et al., [2021](#bib.bib54)) and
    AdvGLUE++ (Wang et al., [2023a](#bib.bib56)) as the baselines. We downloaded [AdvGLUE](https://adversarialglue.github.io/)
    and [AdvGLUE++](https://github.com/AI-secure/DecodingTrust/tree/main/data/adv-glue-plus-plus)
    from the official GitHub of Wang et al. ([2021](#bib.bib54)) and Wang et al. ([2023a](#bib.bib56)).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以对抗数据集 AdvGLUE (Wang et al., [2021](#bib.bib54)) 和 AdvGLUE++ (Wang et al.,
    [2023a](#bib.bib56)) 作为基准。我们从 Wang et al. ([2021](#bib.bib54)) 和 Wang et al. ([2023a](#bib.bib56))
    的官方 GitHub 下载了 [AdvGLUE](https://adversarialglue.github.io/) 和 [AdvGLUE++](https://github.com/AI-secure/DecodingTrust/tree/main/data/adv-glue-plus-plus)。
- en: Attack success rate (ASR).
  id: totrans-154
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 攻击成功率 (ASR)。
- en: 'Following AdvGLUE (Wang et al., [2021](#bib.bib54)), we use the attack success
    rate (ASR) on the adversarial samples filtered according to the fidelity scores
    as the measure of attack power. The ASR is calculated as follows:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 参照 AdvGLUE (Wang et al., [2021](#bib.bib54))，我们使用根据保真度评分过滤的对抗样本上的攻击成功率 (ASR)
    作为攻击能力的衡量指标。ASR 的计算方式如下：
- en: '|  |  |  |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |'
- en: where  is the original test dataset,  denotes the prediction result by a LLM  given
    a test sample  and a task description ,  outputs the adversarial sample post-processed
    by the fidelity filter.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 是原始测试数据集，表示由 LLM 预测的测试样本 和 任务描述 的结果，输出经过保真度过滤器后处理的对抗样本。
- en: Configurations for fidelity filter.
  id: totrans-158
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 保真度过滤器配置。
- en: 'As for AdvGLUE (Wang et al., [2021](#bib.bib54)), we do not apply the fidelity
    filter to AdvGLUE (i.e., setting ) since the adversarial samples in AdvGLUE have
    been carefully filtered to achieve high fidelity. As for AdvGLUE++ (Wang et al.,
    [2023a](#bib.bib56)), we apply the fidelity filter with  and  following AdvGLUE
    since the adversarial samples in AdvGLUE++ are generated by character-level and
    word-level perturbations without any filtering. As for our proposed PromptAttack,
    we set  for the character-level and word-level PromptAttack while keeping  for
    sentence-level PromptAttack. We take  as the average BERTScore of the adversarial
    samples in AdvGLUE for each task to ensure high fidelity of the sentence-level
    adversarial samples and report the threshold  in Appendix [B.2](#A2.SS2 "B.2 BERTScore
    ‣ Appendix B Extensive Experimental Results ‣ An LLM can Fool Itself: A Prompt-Based
    Adversarial Attack"). We report the ASR of AdvGLUE++ and PromptAttack without
    being filtered in Appendix [B.3](#A2.SS3 "B.3 ASR without Fidelity Filter ‣ Appendix
    B Extensive Experimental Results ‣ An LLM can Fool Itself: A Prompt-Based Adversarial
    Attack").'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 AdvGLUE (Wang et al., [2021](#bib.bib54))，由于 AdvGLUE 的对抗样本已被仔细过滤以实现高保真度，因此我们不对
    AdvGLUE 应用保真度过滤器（即，设置）。至于 AdvGLUE++ (Wang et al., [2023a](#bib.bib56))，我们根据 AdvGLUE
    的方法应用保真度过滤器，设定和，因为 AdvGLUE++ 的对抗样本是通过字符级和词级扰动生成的，未经过任何过滤。对于我们提出的 PromptAttack，我们为字符级和词级
    PromptAttack 设定，而对于句子级 PromptAttack 保持。我们将 AdvGLUE 中对抗样本的平均 BERTScore 作为每个任务的保真度阈值，并在附录
    [B.2](#A2.SS2 "B.2 BERTScore ‣ 附录 B 大量实验结果 ‣ 一个 LLM 可以欺骗自己：一种基于提示的对抗攻击") 中报告阈值。我们在附录
    [B.3](#A2.SS3 "B.3 无保真度过滤的 ASR ‣ 附录 B 大量实验结果 ‣ 一个 LLM 可以欺骗自己：一种基于提示的对抗攻击") 中报告了未经过滤的
    AdvGLUE++ 和 PromptAttack 的 ASR。
- en: Victim LLMs
  id: totrans-160
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 受害者 LLMs
- en: In our experiments, we apply PromptAttack to attack two kinds of small-scale
    LLMs (Touvron et al., [2023](#bib.bib52)) (Llama2-7B and Llama2-13B) and a large-scale
    LLM (OpenAI, [2023](#bib.bib37)) (i.e., GPT-3.5). The Llama2 checkpoints are downloaded
    from the [official Hugging Face repository](https://huggingface.co/meta-llama) (Touvron
    et al., [2023](#bib.bib52)). We used the OpenAI API to query GPT-3.5 by setting
    the version as “gpt-3.5-turbo-0301” and setting other configurations as default.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的实验中，我们将 PromptAttack 应用于攻击两种小规模 LLMs (Touvron et al., [2023](#bib.bib52))（Llama2-7B
    和 Llama2-13B）以及一种大规模 LLM (OpenAI, [2023](#bib.bib37))（即 GPT-3.5）。Llama2 的检查点从
    [官方 Hugging Face 仓库](https://huggingface.co/meta-llama) (Touvron et al., [2023](#bib.bib52))
    下载。我们通过将版本设置为“gpt-3.5-turbo-0301”并将其他配置保持默认，使用 OpenAI API 查询 GPT-3.5。
- en: 'Table 3: We report the ASR (%) evaluated on each task of the GLUE dataset using
    various victim LLMs. PromptAttack-EN incorporates PromprtAttack with the ensemble
    strategy while PromptAttack-FS-EN uses both few-shot and few-shot strategies.
    “Avg” refers to the average ASR over all the tasks. The standard deviation of
    the ASR is reported in Appendix [B.4](#A2.SS4 "B.4 Standard Deviation of the ASR
    Reported in Table 3 ‣ Appendix B Extensive Experimental Results ‣ An LLM can Fool
    Itself: A Prompt-Based Adversarial Attack").'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：我们报告了使用各种受害者 LLMs 对 GLUE 数据集的每个任务进行评估的 ASR（%）。PromptAttack-EN 结合了 PromprtAttack
    的集成策略，而 PromptAttack-FS-EN 使用了少量样本和少量样本策略。“Avg” 指所有任务的平均 ASR。ASR 的标准差在附录 [B.4](#A2.SS4
    "B.4 表 3 中报告的 ASR 标准差 ‣ 附录 B 大量实验结果 ‣ 一个 LLM 可以欺骗自己：一种基于提示的对抗攻击") 中报告。
- en: '| Task | SST-2 | QQP | MNLI-m | MNLI-mm | RTE | QNLI | Avg |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | SST-2 | QQP | MNLI-m | MNLI-mm | RTE | QNLI | 平均值 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| Llama2 -7B | AdvGLUE | 47.84 | 8.66 | 62.25 | 61.40 | 13.92 | 31.42 | 37.58
    |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| Llama2 -7B | AdvGLUE | 47.84 | 8.66 | 62.25 | 61.40 | 13.92 | 31.42 | 37.58
    |'
- en: '| AdvGLUE++ | 13.64 | 3.86 | 15.50 | 16.81 | 1.63 | 7.19 | 9.77 |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| AdvGLUE++ | 13.64 | 3.86 | 15.50 | 16.81 | 1.63 | 7.19 | 9.77 |'
- en: '|'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; PromptAttack-EN &#124;'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; PromptAttack-EN &#124;'
- en: '| 66.77 | 23.77 | 63.12 | 70.84 | 34.79 | 45.62 | 50.82 |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 66.77 | 23.77 | 63.12 | 70.84 | 34.79 | 45.62 | 50.82 |'
- en: '|'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; PromptAttack-FS-EN &#124;'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; PromptAttack-FS-EN &#124;'
- en: '| 48.39 | 17.31 | 52.91 | 56.30 | 25.43 | 40.13 | 40.08 |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 48.39 | 17.31 | 52.91 | 56.30 | 25.43 | 40.13 | 40.08 |'
- en: '| Llama2 -13B | AdvGLUE | 47.17 | 20.08 | 53.29 | 57.89 | 16.12 | 49.98 | 40.76
    |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| Llama2 -13B | AdvGLUE | 47.17 | 20.08 | 53.29 | 57.89 | 16.12 | 49.98 | 40.76
    |'
- en: '| AdvGLUE++ | 11.82 | 8.71 | 11.90 | 16.91 | 2.46 | 10.35 | 10.36 |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| AdvGLUE++ | 11.82 | 8.71 | 11.90 | 16.91 | 2.46 | 10.35 | 10.36 |'
- en: '|'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; PromptAttack-EN &#124;'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; PromptAttack-EN &#124;'
- en: '| 70.44 | 48.73 | 69.94 | 72.06 | 39.63 | 78.41 | 63.20 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 70.44 | 48.73 | 69.94 | 72.06 | 39.63 | 78.41 | 63.20 |'
- en: '|'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; PromptAttack-FS-EN &#124;'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; PromptAttack-FS-EN &#124;'
- en: '| 75.37 | 46.86 | 67.93 | 68.72 | 35.68 | 76.27 | 61.80 |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 75.37 | 46.86 | 67.93 | 68.72 | 35.68 | 76.27 | 61.80 |'
- en: '| GPT-3.5 | AdvGLUE | 33.04 | 14.76 | 25.30 | 34.79 | 23.12 | 22.03 | 25.51
    |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 | AdvGLUE | 33.04 | 14.76 | 25.30 | 34.79 | 23.12 | 22.03 | 25.51
    |'
- en: '| AdvGLUE++ | 5.24 | 8.68 | 6.73 | 10.05 | 4.17 | 4.95 | 6.64 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| AdvGLUE++ | 5.24 | 8.68 | 6.73 | 10.05 | 4.17 | 4.95 | 6.64 |'
- en: '|'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; PromptAttack-EN &#124;'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; PromptAttack-EN &#124;'
- en: '| 56.00 | 37.03 | 44.00 | 43.51 | 34.30 | 40.39 | 42.54 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| 56.00 | 37.03 | 44.00 | 43.51 | 34.30 | 40.39 | 42.54 |'
- en: '|'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; PromptAttack-FS-EN &#124;'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; PromptAttack-FS-EN &#124;'
- en: '| 75.23 | 39.61 | 45.97 | 44.10 | 36.12 | 49.00 | 48.34 |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| 75.23 | 39.61 | 45.97 | 44.10 | 36.12 | 49.00 | 48.34 |'
- en: 4.1 Robustness Evaluation on GLUE Dataset
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 GLUE 数据集上的鲁棒性评估
- en: 'We demonstrate the ASR evaluated on the GLUE dataset using various victim LLMs
    under AdvGLUE, AdvGLUE++ as well as PromptAttack with only an ensemble strategy
    (PromptAttack-EN) and PromptAttack with both few-shot and ensemble strategies
    (PromptAttack-FS-EN) in Table [3](#S4.T3 "Table 3 ‣ Victim LLMs ‣ 4 Experiments
    ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack").'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '我们展示了在 GLUE 数据集上，使用 AdvGLUE、AdvGLUE++ 以及仅使用集成策略（PromptAttack-EN）和结合少量示例及集成策略（PromptAttack-FS-EN）的各种目标
    LLM 的 ASR，如表 [3](#S4.T3 "Table 3 ‣ Victim LLMs ‣ 4 Experiments ‣ An LLM can Fool
    Itself: A Prompt-Based Adversarial Attack") 所示。'
- en: PromptAttack can effectively evaluate LLMs’ robustness.
  id: totrans-191
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: PromptAttack 可以有效评估 LLM 的鲁棒性。
- en: The ASR achieved by PromptAttack significantly outperforms AdvGLUE and AdvGLUE++
    over all the tasks in the GLUE dataset. Notably, PromptAttack-FS-EN increases
    the average ASR on GPT-3.5 over all tasks by 22.83% (from 25.51% to 48.34%). It
    validates that PromptAttack which is adaptive to the victim LLM can generate a
    stronger adversarial sample of high fidelity. Therefore, our proposed PromptAttack
    can serve as an effective tool to efficiently audit the LLM’s adversarial robustness.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: PromptAttack 实现的 ASR 显著优于 AdvGLUE 和 AdvGLUE++ 在 GLUE 数据集中的所有任务。特别是，PromptAttack-FS-EN
    将 GPT-3.5 在所有任务上的平均 ASR 提高了 22.83%（从 25.51% 增加到 48.34%）。这验证了 PromptAttack 对目标
    LLM 的适应性可以生成更高保真度的对抗样本。因此，我们提出的 PromptAttack 可以作为有效工具来高效审计 LLM 的对抗鲁棒性。
- en: GPT-3.5 is more adversarially robust than Llama2.
  id: totrans-193
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: GPT-3.5 比 Llama2 更具对抗鲁棒性。
- en: 'From Table [3](#S4.T3 "Table 3 ‣ Victim LLMs ‣ 4 Experiments ‣ An LLM can Fool
    Itself: A Prompt-Based Adversarial Attack"), we can conclude that GPT-3.5 is more
    adversarially robust than Llama2 since the ASR on GPT-3.5 (even under strong PromptAttack)
    is lower than Llama2, which is in line with Wang et al. ([2023b](#bib.bib57)).
    Besides, although Llama2-13B has a larger number of parameters than Llama2-7B,
    our empirical results show that Llama2-13B seems to be more adversarially vulnerable
    than Llama2-13B because Llama2-13B always obtains a higher ASR under our proposed
    PromptAttack.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '从表 [3](#S4.T3 "Table 3 ‣ Victim LLMs ‣ 4 Experiments ‣ An LLM can Fool Itself:
    A Prompt-Based Adversarial Attack") 中，我们可以得出结论，GPT-3.5 比 Llama2 更具对抗鲁棒性，因为 GPT-3.5
    的 ASR（即使在强 PromptAttack 下）低于 Llama2，这与 Wang 等人 ([2023b](#bib.bib57)) 的研究一致。此外，尽管
    Llama2-13B 的参数数量多于 Llama2-7B，但我们的实证结果表明，Llama2-13B 似乎比 Llama2-7B 更易受对抗攻击，因为 Llama2-13B
    在我们提出的 PromptAttack 下始终获得更高的 ASR。'
- en: The ASR of PromptAttack-FS-EN is sensitive to the LLM’s comprehension ability.
  id: totrans-195
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: PromptAttack-FS-EN 的 ASR 对 LLM 的理解能力非常敏感。
- en: 'We observe that, compared to PromptAttack-EN, PromptAttack-FS-EN degrades ASR
    using Llama2 while enhancing ASR using GPT-3.5\. We conjecture that it is because
    Llama2 has a smaller number of parameters than GPT-3.5, thus leading to a worse
    comprehension of the few-shot AG and degrading the quality of the generated adversarial
    sample under PromptAttack-FS-EN. For example, the adversarial sample generated
    by Llama2-7B under PromptAttack-FS-EN (shown in Table [19](#A2.T19 "Table 19 ‣
    Extensive analyses. ‣ B.6 Attack Transferability ‣ Appendix B Extensive Experimental
    Results ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack")) is always
    composed of two sentences connected by a meaningless arrow pattern (“->”), which
    exactly follows the format of extra examples in the few-shot AG shown in Section [3.3](#S3.SS3
    "3.3 Enhancing PromptAttack ‣ 3 Prompt-Based Adversarial Attack ‣ An LLM can Fool
    Itself: A Prompt-Based Adversarial Attack"). These adversarial samples are of
    low quality and are easily filtered out by the fidelity filter, thus leading to
    a lower ASR achieved by PromptAttack-FS-EN against Llama2 compared to PromptAttack-EN.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '我们观察到，与 PromptAttack-EN 相比，PromptAttack-FS-EN 在使用 Llama2 时 ASR 下降，而在使用 GPT-3.5
    时 ASR 升高。我们推测这是因为 Llama2 的参数量小于 GPT-3.5，从而导致对少量样本攻击的理解较差，降低了在 PromptAttack-FS-EN
    下生成的对抗样本的质量。例如，在 PromptAttack-FS-EN 下，Llama2-7B 生成的对抗样本（见表 [19](#A2.T19 "Table
    19 ‣ Extensive analyses. ‣ B.6 Attack Transferability ‣ Appendix B Extensive Experimental
    Results ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack")）总是由两个通过无意义的箭头模式（“->”）连接的句子组成，这正好符合第
    [3.3](#S3.SS3 "3.3 Enhancing PromptAttack ‣ 3 Prompt-Based Adversarial Attack
    ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack")节中少量样本攻击额外示例的格式。这些对抗样本质量较低，容易被保真度过滤器过滤，从而导致
    PromptAttack-FS-EN 对 Llama2 的 ASR 低于 PromptAttack-EN。'
- en: 'Table 4: The ASR (%) achieved by PromptAttack against GPT-3.5 according to
    each particular type of perturbation instruction. Here, “FS” refers to our proposed
    few-shot strategy to boost PromptAttack. “Avg” refers to the average ASR over
    all the tasks.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：PromptAttack 在针对 GPT-3.5 的不同类型扰动指令下所实现的 ASR（%）。其中，“FS”指代我们提出的少量样本策略以提升 PromptAttack。“Avg”指代所有任务的平均
    ASR。
- en: '|'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Perturbation &#124;'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 扰动 &#124;'
- en: '&#124; prompt &#124;'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 提示 &#124;'
- en: '| FS | SST-2 | QQP | MNLI-m | MNLI-mm | RTE | QNLI | Avg |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| FS | SST-2 | QQP | MNLI-m | MNLI-mm | RTE | QNLI | 平均 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| C1 |  ✕  | 4.31 | 8.55 | 14.25 | 14.82 | 8.58 | 10.00 | 10.09 |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| C1 |  ✕  | 4.31 | 8.55 | 14.25 | 14.82 | 8.58 | 10.00 | 10.09 |'
- en: '|  ✓  | 3.13 | 9.37 | 14.79 | 14.06 | 8.44 | 10.50 | 10.05 |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '|  ✓  | 3.13 | 9.37 | 14.79 | 14.06 | 8.44 | 10.50 | 10.05 |'
- en: '| C2 |  ✕  | 17.76 | 10.47 | 17.84 | 18.78 | 11.07 | 11.70 | 14.60 |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| C2 |  ✕  | 17.76 | 10.47 | 17.84 | 18.78 | 11.07 | 11.70 | 14.60 |'
- en: '|  ✓  | 18.87 | 15.46 | 17.47 | 16.62 | 12.61 | 18.46 | 16.58 |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '|  ✓  | 18.87 | 15.46 | 17.47 | 16.62 | 12.61 | 18.46 | 16.58 |'
- en: '| C3 |  ✕  | 3.87 | 8.51 | 12.53 | 12.74 | 7.28 | 8.19 | 8.85 |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| C3 |  ✕  | 3.87 | 8.51 | 12.53 | 12.74 | 7.28 | 8.19 | 8.85 |'
- en: '|  ✓  | 5.51 | 9.54 | 13.06 | 13.81 | 8.95 | 11.33 | 10.37 |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '|  ✓  | 5.51 | 9.54 | 13.06 | 13.81 | 8.95 | 11.33 | 10.37 |'
- en: '| W1 |  ✕  | 1.38 | 2.97 | 4.30 | 4.46 | 3.81 | 2.48 | 3.23 |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| W1 |  ✕  | 1.38 | 2.97 | 4.30 | 4.46 | 3.81 | 2.48 | 3.23 |'
- en: '|  ✓  | 6.44 | 3.76 | 8.82 | 9.09 | 5.90 | 6.52 | 6.76 |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '|  ✓  | 6.44 | 3.76 | 8.82 | 9.09 | 5.90 | 6.52 | 6.76 |'
- en: '| W2 |  ✕  | 4.88 | 6.60 | 5.64 | 5.63 | 4.23 | 4.88 | 5.31 |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| W2 |  ✕  | 4.88 | 6.60 | 5.64 | 5.63 | 4.23 | 4.88 | 5.31 |'
- en: '|  ✓  | 6.20 | 8.95 | 8.95 | 9.58 | 8.50 | 8.29 | 8.41 |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '|  ✓  | 6.20 | 8.95 | 8.95 | 9.58 | 8.50 | 8.29 | 8.41 |'
- en: '| W3 |  ✕  | 21.69 | 4.25 | 10.39 | 9.77 | 7.55 | 4.36 | 9.67 |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| W3 |  ✕  | 21.69 | 4.25 | 10.39 | 9.77 | 7.55 | 4.36 | 9.67 |'
- en: '|  ✓  | 33.66 | 6.17 | 11.99 | 11.38 | 9.44 | 7.52 | 13.36 |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '|  ✓  | 33.66 | 6.17 | 11.99 | 11.38 | 9.44 | 7.52 | 13.36 |'
- en: '| S1 |  ✕  | 22.36 | 12.10 | 13.92 | 12.82 | 8.85 | 12.16 | 13.70 |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| S1 |  ✕  | 22.36 | 12.10 | 13.92 | 12.82 | 8.85 | 12.16 | 13.70 |'
- en: '|  ✓  | 25.75 | 11.90 | 15.38 | 13.08 | 10.45 | 14.83 | 15.23 |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '|  ✓  | 25.75 | 11.90 | 15.38 | 13.08 | 10.45 | 14.83 | 15.23 |'
- en: '| S2 |  ✕  | 10.41 | 10.98 | 8.80 | 9.10 | 7.90 | 10.25 | 9.57 |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| S2 |  ✕  | 10.41 | 10.98 | 8.80 | 9.10 | 7.90 | 10.25 | 9.57 |'
- en: '|  ✓  | 39.18 | 11.20 | 11.16 | 10.83 | 5.81 | 11.60 | 14.96 |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '|  ✓  | 39.18 | 11.20 | 11.16 | 10.83 | 5.81 | 11.60 | 14.96 |'
- en: '| S3 |  ✕  | 17.55 | 12.50 | 11.10 | 9.42 | 9.78 | 10.15 | 11.75 |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| S3 |  ✕  | 17.55 | 12.50 | 11.10 | 9.42 | 9.78 | 10.15 | 11.75 |'
- en: '|  ✓  | 48.87 | 11.10 | 8.93 | 11.03 | 9.36 | 12.67 | 16.99 |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '|  ✓  | 48.87 | 11.10 | 8.93 | 11.03 | 9.36 | 12.67 | 16.99 |'
- en: 'Table 5: Robustness evaluation in the MNLI-mm task via different types of task
    descriptions.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：通过不同类型任务描述在 MNLI-mm 任务中的鲁棒性评估。
- en: '| Task description | ZS-TO | ZS-RO | FS-TO | FS-RO | Avg |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| 任务描述 | ZS-TO | ZS-RO | FS-TO | FS-RO | 平均 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Llama2-7B | AdvGLUE | 41.72 | 39.25 | 85.93 | 78.70 | 61.40 |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| Llama2-7B | AdvGLUE | 41.72 | 39.25 | 85.93 | 78.70 | 61.40 |'
- en: '| AdvGLUE++ | 12.18 | 11.64 | 23.27 | 20.13 | 16.81 |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| AdvGLUE++ | 12.18 | 11.64 | 23.27 | 20.13 | 16.81 |'
- en: '| PromptAttack-EN | 50.58 | 55.30 | 93.64 | 83.85 | 70.84 |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-EN | 50.58 | 55.30 | 93.64 | 83.85 | 70.84 |'
- en: '| PromptAttack-FS-EN | 37.63 | 43.18 | 74.55 | 69.82 | 56.30 |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-FS-EN | 37.63 | 43.18 | 74.55 | 69.82 | 56.30 |'
- en: '| Average ASR over attacks | 35.53 | 37.34 | 69.35 | 63.13 | N/A |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| 攻击平均ASR | 35.53 | 37.34 | 69.35 | 63.13 | N/A |'
- en: '| GPT-3.5 | AdvGLUE | 36.92 | 30.88 | 36.93 | 34.41 | 34.79 |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 | AdvGLUE | 36.92 | 30.88 | 36.93 | 34.41 | 34.79 |'
- en: '| AdvGLUE++ | 9.54 | 10.52 | 9.98 | 10.16 | 10.05 |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| AdvGLUE++ | 9.54 | 10.52 | 9.98 | 10.16 | 10.05 |'
- en: '| PromptAttack-EN | 49.34 | 46.72 | 39.77 | 38.20 | 43.51 |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-EN | 49.34 | 46.72 | 39.77 | 38.20 | 43.51 |'
- en: '| PromptAttack-FS-EN | 50.55 | 48.14 | 39.86 | 37.86 | 45.97 |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-FS-EN | 50.55 | 48.14 | 39.86 | 37.86 | 45.97 |'
- en: '| Average ASR over attacks | 36.59 | 34.07 | 31.64 | 30.16 | N/A |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| 攻击平均ASR | 36.59 | 34.07 | 31.64 | 30.16 | N/A |'
- en: 4.2 Extensive Empirical Results
  id: totrans-234
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 广泛的实证结果
- en: ASR w.r.t. the type of perturbation instruction.
  id: totrans-235
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 相对于扰动指令类型的ASR。
- en: 'Table [4](#S4.T4 "Table 4 ‣ The ASR of PromptAttack-FS-EN is sensitive to the
    LLM’s comprehension ability. ‣ 4.1 Robustness Evaluation on GLUE Dataset ‣ 4 Experiments
    ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack") shows that the attack
    power of sentence-level perturbation is stronger than character-level and word-level
    perturbations, which is in line with the conclusions of Wang et al. ([2023a](#bib.bib56)).
    Besides, Table [4](#S4.T4 "Table 4 ‣ The ASR of PromptAttack-FS-EN is sensitive
    to the LLM’s comprehension ability. ‣ 4.1 Robustness Evaluation on GLUE Dataset
    ‣ 4 Experiments ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack")
    validates the effectiveness of the few-shot strategy in enhancing attack power
    since using the few-shot strategy can yield a higher ASR.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '表[4](#S4.T4 "Table 4 ‣ The ASR of PromptAttack-FS-EN is sensitive to the LLM’s
    comprehension ability. ‣ 4.1 Robustness Evaluation on GLUE Dataset ‣ 4 Experiments
    ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack")显示，句子级扰动的攻击能力强于字符级和词汇级扰动，这与王等人([2023a](#bib.bib56))的结论一致。此外，表[4](#S4.T4
    "Table 4 ‣ The ASR of PromptAttack-FS-EN is sensitive to the LLM’s comprehension
    ability. ‣ 4.1 Robustness Evaluation on GLUE Dataset ‣ 4 Experiments ‣ An LLM
    can Fool Itself: A Prompt-Based Adversarial Attack")验证了少样本策略在提升攻击能力方面的有效性，因为使用少样本策略可以得到更高的ASR。'
- en: ASR w.r.t. the type of task description.
  id: totrans-237
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 相对于任务描述类型的ASR。
- en: 'Table [5](#S4.T5 "Table 5 ‣ The ASR of PromptAttack-FS-EN is sensitive to the
    LLM’s comprehension ability. ‣ 4.1 Robustness Evaluation on GLUE Dataset ‣ 4 Experiments
    ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack") and results in Appendix [B.5](#A2.SS5
    "B.5 ASR Evaluated via Different Types of Task Descriptions ‣ Appendix B Extensive
    Experimental Results ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack")
    validate that PromptAttack consistently yields a higher ASR via different types
    of task descriptions. The RO task descriptions always yield a lower ASR than TO
    task descriptions, which indicates that RO task descriptions could be a defensive
    strategy. Besides, it shows that FS task descriptions are more robust than ZO
    task descriptions for GPT-3.5, which is consistent with conclusions in Zhu et al.
    ([2023](#bib.bib66)); whereas, the ASR via FS task descriptions is much higher
    than that via ZO task descriptions for Llama2\. We provide extensive discussions
    of this phenomenon in Appendix [B.5](#A2.SS5 "B.5 ASR Evaluated via Different
    Types of Task Descriptions ‣ Appendix B Extensive Experimental Results ‣ An LLM
    can Fool Itself: A Prompt-Based Adversarial Attack").'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '表[5](#S4.T5 "Table 5 ‣ The ASR of PromptAttack-FS-EN is sensitive to the LLM’s
    comprehension ability. ‣ 4.1 Robustness Evaluation on GLUE Dataset ‣ 4 Experiments
    ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack")和附录[B.5](#A2.SS5
    "B.5 ASR Evaluated via Different Types of Task Descriptions ‣ Appendix B Extensive
    Experimental Results ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack")中的结果验证了PromptAttack在不同类型的任务描述下始终能产生更高的ASR。RO任务描述的ASR始终低于TO任务描述，这表明RO任务描述可能是一种防御策略。此外，它还显示FS任务描述对GPT-3.5更具鲁棒性，这与朱等人([2023](#bib.bib66))的结论一致；而对于Llama2，FS任务描述的ASR远高于ZO任务描述。我们在附录[B.5](#A2.SS5
    "B.5 ASR Evaluated via Different Types of Task Descriptions ‣ Appendix B Extensive
    Experimental Results ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack")中对这一现象进行了广泛讨论。'
- en: '![Refer to caption](img/8d39b7a80fd36ff6f9666e3692325fc2.png)![Refer to caption](img/aa0b7b3f0ccb18ab3466384ef4318b27.png)![Refer
    to caption](img/fcc045b2cd5b43f746962740ee8ba35d.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8d39b7a80fd36ff6f9666e3692325fc2.png)![参见说明](img/aa0b7b3f0ccb18ab3466384ef4318b27.png)![参见说明](img/fcc045b2cd5b43f746962740ee8ba35d.png)'
- en: 'Figure 3: The ASR w.r.t. BERTScore threshold  evaluated in the SST-2, MNLI-m,
    and QNLI tasks using GPT-3.5\. Extra results evaluated in the MNLI-m, QQP, and
    RTE tasks are in Figure [4](#A2.F4 "Figure 4 ‣ BERTScore threshold 𝜏₂. ‣ B.2 BERTScore
    ‣ Appendix B Extensive Experimental Results ‣ An LLM can Fool Itself: A Prompt-Based
    Adversarial Attack").'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：使用 GPT-3.5 在 SST-2、MNLI-m 和 QNLI 任务中评估的 ASR 相对于 BERTScore 阈值。额外结果在 MNLI-m、QQP
    和 RTE 任务中的评估见图 [4](#A2.F4 "图 4 ‣ BERTScore 阈值 𝜏₂. ‣ B.2 BERTScore ‣ 附录 B 广泛实验结果
    ‣ LLM 可以欺骗自己：基于提示的对抗攻击")。
- en: ASR w.r.t. BERTScore threshold .
  id: totrans-241
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ASR 相对于 BERTScore 阈值。
- en: 'Figures [3](#S4.F3 "Figure 3 ‣ ASR w.r.t. the type of task description. ‣ 4.2
    Extensive Empirical Results ‣ 4 Experiments ‣ An LLM can Fool Itself: A Prompt-Based
    Adversarial Attack") and [4](#A2.F4 "Figure 4 ‣ BERTScore threshold 𝜏₂. ‣ B.2
    BERTScore ‣ Appendix B Extensive Experimental Results ‣ An LLM can Fool Itself:
    A Prompt-Based Adversarial Attack") demonstrate the ASR under the fidelity filter
    with various BERTScore threshold  and . It validates that PromptAttack-EN and
    PromptAttack-FS-EN can achieve a much higher ASR at a high BERTScore threshold  than
    AdvGLUE and AdvGLUE++. For example, when  in the QNLI task, PromptAttack-FS-EN
    almost achieves 48% ASR while the ASR of AdvGLUE and AdvGLUE++ is lower than 10%.
    It justifies that PromptAttack can generate adversarial samples of strong attack
    power and high fidelity.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [3](#S4.F3 "图 3 ‣ ASR 相对于任务描述的类型。 ‣ 4.2 广泛的经验结果 ‣ 4 实验 ‣ LLM 可以欺骗自己：基于提示的对抗攻击")
    和 [4](#A2.F4 "图 4 ‣ BERTScore 阈值 𝜏₂. ‣ B.2 BERTScore ‣ 附录 B 广泛实验结果 ‣ LLM 可以欺骗自己：基于提示的对抗攻击")
    展示了在不同 BERTScore 阈值下的 ASR。它验证了 PromptAttack-EN 和 PromptAttack-FS-EN 在高 BERTScore
    阈值下能够实现远高于 AdvGLUE 和 AdvGLUE++ 的 ASR。例如，在 QNLI 任务中，PromptAttack-FS-EN 几乎实现了 48%
    的 ASR，而 AdvGLUE 和 AdvGLUE++ 的 ASR 低于 10%。这证明了 PromptAttack 可以生成具有强攻击能力和高保真度的对抗样本。
- en: Attack transferability.
  id: totrans-243
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 攻击可迁移性。
- en: 'Tables [6](#S4.T6 "Table 6 ‣ Attack transferability. ‣ 4.2 Extensive Empirical
    Results ‣ 4 Experiments ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack")
    and [7](#S4.T7 "Table 7 ‣ Attack transferability. ‣ 4.2 Extensive Empirical Results
    ‣ 4 Experiments ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack")
    show the attack transferability of PromptAttack between GPT-3.5 and Llama2. The
    result validates that our proposed PromptAttack can be transferred to successfully
    fool other victim LLMs. Besides, it further justifies that GPT-3.5 is more adversarially
    robust than Llama2 since Llama2 achieves a higher ASR under adversarial samples
    against GPT-3.5 (shown in Table 6) and GPT-3.5 achieves a lower ASR under adversarial
    samples against Llama2 in most tasks (shown in Table 7). We provide experimental
    details and extensive results of the attack transferability to BERT-based models (Liu
    et al., [2019](#bib.bib29); Zhu et al., [2019](#bib.bib65)) in Appendix [B.6](#A2.SS6
    "B.6 Attack Transferability ‣ Appendix B Extensive Experimental Results ‣ An LLM
    can Fool Itself: A Prompt-Based Adversarial Attack").'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [6](#S4.T6 "表 6 ‣ 攻击可迁移性。 ‣ 4.2 广泛的经验结果 ‣ 4 实验 ‣ LLM 可以欺骗自己：基于提示的对抗攻击") 和 [7](#S4.T7
    "表 7 ‣ 攻击可迁移性。 ‣ 4.2 广泛的经验结果 ‣ 4 实验 ‣ LLM 可以欺骗自己：基于提示的对抗攻击") 展示了 PromptAttack
    在 GPT-3.5 和 Llama2 之间的攻击可迁移性。结果验证了我们提出的 PromptAttack 可以成功迁移以欺骗其他受害 LLM。此外，它进一步证明了
    GPT-3.5 比 Llama2 更具对抗鲁棒性，因为 Llama2 在对抗样本下对 GPT-3.5 实现了更高的 ASR（见表 6），而 GPT-3.5
    在大多数任务中对 Llama2 的对抗样本下的 ASR 较低（见表 7）。我们在附录 [B.6](#A2.SS6 "B.6 攻击可迁移性 ‣ 附录 B 广泛实验结果
    ‣ LLM 可以欺骗自己：基于提示的对抗攻击") 提供了对 BERT 基础模型的攻击可迁移性的实验细节和广泛结果。
- en: 'Table 6: Attack transferability of PromptAttack from GPT-3.5 to Llama2-7B and
    Llama2-13B.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6：PromptAttack 从 GPT-3.5 到 Llama2-7B 和 Llama2-13B 的攻击可迁移性。
- en: '| Task |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| 任务 |'
- en: '&#124; GPT &#124;'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; GPT &#124;'
- en: '&#124; -3.5 &#124;'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; -3.5 &#124;'
- en: '|'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Llama2 &#124;'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Llama2 &#124;'
- en: '&#124; -7B &#124;'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; -7B &#124;'
- en: '|'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Llama2 &#124;'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Llama2 &#124;'
- en: '&#124; -13B &#124;'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; -13B &#124;'
- en: '|'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| --- | --- | --- | --- |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| SST-2 | 75.23 | 89.75 | 87.26 |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| SST-2 | 75.23 | 89.75 | 87.26 |'
- en: '| QQP | 39.61 | 40.01 | 63.03 |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| QQP | 39.61 | 40.01 | 63.03 |'
- en: '| MNLI-m | 45.97 | 79.75 | 80.54 |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| MNLI-m | 45.97 | 79.75 | 80.54 |'
- en: '| MNLI-mm | 44.10 | 81.37 | 81.51 |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| MNLI-mm | 44.10 | 81.37 | 81.51 |'
- en: '| RTE | 36.12 | 44.05 | 45.33 |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| RTE | 36.12 | 44.05 | 45.33 |'
- en: '| QNLI | 49.00 | 54.54 | 85.35 |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| QNLI | 49.00 | 54.54 | 85.35 |'
- en: '| Avg | 48.34 | 64.91 | 73.84 |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| 平均 | 48.34 | 64.91 | 73.84 |'
- en: 'Table 7: Attack transferability of PromptAttack from Llama2-7B to GPT-3.5 and
    Llama2-13B.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7：PromptAttack 从 Llama2-7B 到 GPT-3.5 和 Llama2-13B 的攻击可迁移性。
- en: '| Task |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| 任务 |'
- en: '&#124; Llama2 &#124;'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Llama2 &#124;'
- en: '&#124; -7B &#124;'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; -7B &#124;'
- en: '|'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Llama2 &#124;'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Llama2 &#124;'
- en: '&#124; -13B &#124;'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; -13B &#124;'
- en: '|'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; GPT &#124;'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; GPT &#124;'
- en: '&#124; -3.5 &#124;'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; -3.5 &#124;'
- en: '|'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| --- | --- | --- | --- |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| SST-2 | 66.77 | 70.44 | 54.55 |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| SST-2 | 66.77 | 70.44 | 54.55 |'
- en: '| QQP | 23.77 | 48.73 | 33.41 |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| QQP | 23.77 | 48.73 | 33.41 |'
- en: '| MNLI-m | 63.12 | 69.94 | 35.39 |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| MNLI-m | 63.12 | 69.94 | 35.39 |'
- en: '| MNLI-mm | 70.84 | 72.06 | 37.24 |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| MNLI-mm | 70.84 | 72.06 | 37.24 |'
- en: '| RTE | 34.79 | 39.63 | 34.48 |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| RTE | 34.79 | 39.63 | 34.48 |'
- en: '| QNLI | 45.62 | 78.41 | 33.83 |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| QNLI | 45.62 | 78.41 | 33.83 |'
- en: '| Avg | 50.82 | 63.20 | 38.15 |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| 平均值 | 50.82 | 63.20 | 38.15 |'
- en: 5 Conclusions
  id: totrans-283
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论
- en: This paper proposes a prompt-based adversarial attack, named PromptAttack, as
    an effective and efficient method for evaluating the LLM’s adversarial robustness.
    PromptAttack requires the victim LLM to generate an adversarial sample that can
    successfully fool itself via an attack prompt. We designed the attack prompt composed
    of original input (OI), attack objective (AO), and attack guidance (AG), and provided
    a template of the attack prompt for automatically generating an attack prompt
    given a data point. Furthermore, we used a fidelity filter to guarantee adversarial
    samples maintain their original semantics and proposed few-shot and ensemble strategies
    to boost the attack power of PromptAttack. The experimental results validate that
    PromptAttack can consistently yield a state-of-the-art attack success rate on
    the GLUE dataset. Therefore, our proposed PromptAttack can be an effective tool
    for efficiently auditing an LLM’s adversarial robustness.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提出了一种基于提示的对抗攻击方法，称为PromptAttack，作为评估LLM对抗鲁棒性的有效且高效的方法。PromptAttack要求受害者LLM生成能够通过攻击提示成功欺骗自己的对抗样本。我们设计了由原始输入（OI）、攻击目标（AO）和攻击指导（AG）组成的攻击提示，并提供了一个攻击提示的模板，以便根据数据点自动生成攻击提示。此外，我们使用了保真度过滤器来确保对抗样本保持其原始语义，并提出了少样本和集成策略以增强PromptAttack的攻击力。实验结果验证了PromptAttack在GLUE数据集上能
    consistently 达到最先进的攻击成功率。因此，我们提出的PromptAttack可以成为有效的工具，用于高效审核LLM的对抗鲁棒性。
- en: Acknowledgements
  id: totrans-285
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This research is supported by the National Research Foundation, Singapore under
    its Strategic Capability Research Centres Funding Initiative, the National Key
    R&D Program of China No. 2021YFF0900800 and Youth Foundation of Shandong Natural
    Science Foundation of China No.ZR2022QF114\. Any opinions, findings and conclusions
    or recommendations expressed in this material are those of the author(s) and do
    not reflect the views of National Research Foundation, Singapore.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究得到了新加坡国家研究基金会在其战略能力研究中心资助计划下的支持，中国国家重点研发计划2021YFF0900800号和山东省自然科学基金青年基金ZR2022QF114的支持。本文中表达的任何意见、发现和结论或建议均为作者个人观点，并不反映新加坡国家研究基金会的观点。
- en: References
  id: totrans-287
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Apruzzese et al. (2023) Giovanni Apruzzese, Hyrum S Anderson, Savino Dambra,
    David Freeman, Fabio Pierazzi, and Kevin Roundy. “real attackers don’t compute
    gradients”: Bridging the gap between adversarial ml research and practice. In
    *2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML)*, pp. 
    339–364\. IEEE, 2023.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apruzzese等（2023年）Giovanni Apruzzese, Hyrum S Anderson, Savino Dambra, David
    Freeman, Fabio Pierazzi, 和 Kevin Roundy. “真实攻击者不会计算梯度”：弥合对抗性机器学习研究与实践之间的差距。发表于*2023年IEEE安全与可信机器学习会议（SaTML）*，第339–364页。IEEE，2023年。
- en: 'Athalye et al. (2018) Anish Athalye, Nicholas Carlini, and David Wagner. Obfuscated
    gradients give a false sense of security: Circumventing defenses to adversarial
    examples. In *International conference on machine learning*, pp. 274–283\. PMLR,
    2018.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Athalye等（2018年）Anish Athalye, Nicholas Carlini, 和 David Wagner. 模糊梯度给人一种虚假的安全感：绕过对抗样本的防御。发表于*国际机器学习会议*，第274–283页。PMLR，2018年。
- en: Bar-Haim et al. (2006) Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, and
    Danilo Giampiccolo. The second pascal recognising textual entailment challenge.
    *Proceedings of the Second PASCAL Challenges Workshop on Recognising Textual Entailment*,
    01 2006.
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bar-Haim等（2006年）Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, 和 Danilo Giampiccolo.
    第二届Pascal文本蕴含挑战。*第二届PASCAL挑战研讨会论文集*，2006年01月。
- en: 'Bender et al. (2021) Emily M Bender, Timnit Gebru, Angelina McMillan-Major,
    and Shmargaret Shmitchell. On the dangers of stochastic parrots: Can language
    models be too big? In *Proceedings of the 2021 ACM conference on fairness, accountability,
    and transparency*, pp.  610–623, 2021.'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bender等（2021年）Emily M Bender, Timnit Gebru, Angelina McMillan-Major, 和 Shmargaret
    Shmitchell. 关于随机鹦鹉的危险：语言模型会不会过大？发表于*2021年ACM公平性、问责制与透明度会议论文集*，第610–623页，2021年。
- en: Bentivogli et al. (2009) Luisa Bentivogli, Bernardo Magnini, Ido Dagan, Hoa Trang
    Dang, and Danilo Giampiccolo. The fifth PASCAL recognizing textual entailment
    challenge. In *Proceedings of the Second Text Analysis Conference, TAC 2009, Gaithersburg,
    Maryland, USA, November 16-17, 2009*. NIST, 2009. URL [https://tac.nist.gov/publications/2009/additional.papers/RTE5_overview.proceedings.pdf](https://tac.nist.gov/publications/2009/additional.papers/RTE5_overview.proceedings.pdf).
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bentivogli 等 (2009) Luisa Bentivogli, Bernardo Magnini, Ido Dagan, Hoa Trang
    Dang 和 Danilo Giampiccolo。《第五届 PASCAL 文本蕴含识别挑战》。在 *第二届文本分析会议 (TAC 2009)，美国马里兰州盖瑟斯堡，2009
    年 11 月 16-17 日*。NIST，2009。网址 [https://tac.nist.gov/publications/2009/additional.papers/RTE5_overview.proceedings.pdf](https://tac.nist.gov/publications/2009/additional.papers/RTE5_overview.proceedings.pdf)。
- en: Bommasani et al. (2021) Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman,
    Simran Arora, Sydney von Arx, Michael S Bernstein, Jeannette Bohg, Antoine Bosselut,
    Emma Brunskill, et al. On the opportunities and risks of foundation models. *arXiv
    preprint arXiv:2108.07258*, 2021.
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bommasani 等 (2021) Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman,
    Simran Arora, Sydney von Arx, Michael S Bernstein, Jeannette Bohg, Antoine Bosselut,
    Emma Brunskill 等人。《关于基础模型的机遇与风险》。*arXiv 预印本 arXiv:2108.07258*，2021。
- en: Bos & Markert (2005) Johan Bos and Katja Markert. Recognising textual entailment
    with logical inference. In *Proceedings of Human Language Technology Conference
    and Conference on Empirical Methods in Natural Language Processing*, pp. 628–635,
    2005.
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bos & Markert (2005) Johan Bos 和 Katja Markert。《通过逻辑推理识别文本蕴含》。在 *人类语言技术会议与自然语言处理经验方法会议论文集*，第
    628–635 页，2005。
- en: Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D
    Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
    Askell, et al. Language models are few-shot learners. *Advances in neural information
    processing systems*, 33:1877–1901, 2020.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown 等 (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared
    D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
    Amanda Askell 等人。《语言模型是少量学习者》。*神经信息处理系统进展*，33:1877–1901，2020。
- en: 'Buch et al. (2018) Varun H Buch, Irfan Ahmed, and Mahiben Maruthappu. Artificial
    intelligence in medicine: current trends and future possibilities. *British Journal
    of General Practice*, 68(668):143–144, 2018.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Buch 等 (2018) Varun H Buch, Irfan Ahmed 和 Mahiben Maruthappu。《医学中的人工智能：当前趋势和未来可能性》。*英国全科医学杂志*，68(668):143–144，2018。
- en: 'Chiang et al. (2023) Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao
    Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E Gonzalez,
    et al. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality.
    *See https://vicuna. lmsys. org (accessed 14 April 2023)*, 2023.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chiang 等 (2023) Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu,
    Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E Gonzalez 等人。《Vicuna:
    一种开源聊天机器人，其质量达到 90%* 的 ChatGPT 质量》。*请参阅 https://vicuna.lmsys.org (访问日期：2023 年
    4 月 14 日)*，2023。'
- en: Croce & Hein (2020) Francesco Croce and Matthias Hein. Reliable evaluation of
    adversarial robustness with an ensemble of diverse parameter-free attacks. In
    *International conference on machine learning*, pp. 2206–2216\. PMLR, 2020.
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Croce & Hein (2020) Francesco Croce 和 Matthias Hein。《通过多样化的无参数攻击集进行可靠的对抗鲁棒性评估》。在
    *国际机器学习会议*，第 2206–2216 页。PMLR，2020。
- en: 'Dagan et al. (2005) Ido Dagan, Oren Glickman, and Bernardo Magnini. The pascal
    recognising textual entailment challenge. pp.  177–190, 01 2005. ISBN 978-3-540-33427-9.
    doi: 10.1007/11736790˙9.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Dagan 等 (2005) Ido Dagan, Oren Glickman 和 Bernardo Magnini。《Pascal 文本蕴含识别挑战》。第
    177–190 页，2005 年 1 月。ISBN 978-3-540-33427-9。doi: 10.1007/11736790˙9。'
- en: 'Devlin et al. (2018) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina
    Toutanova. Bert: Pre-training of deep bidirectional transformers for language
    understanding. *arXiv preprint arXiv:1810.04805*, 2018.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Devlin 等 (2018) Jacob Devlin, Ming-Wei Chang, Kenton Lee 和 Kristina Toutanova。《BERT：用于语言理解的深度双向变换器的预训练》。*arXiv
    预印本 arXiv:1810.04805*，2018。
- en: Gao et al. (2018) Ji Gao, Jack Lanchantin, Mary Lou Soffa, and Yanjun Qi. Black-box
    generation of adversarial text sequences to evade deep learning classifiers. In
    *2018 IEEE Security and Privacy Workshops (SPW)*, pp. 50–56\. IEEE, 2018.
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao 等 (2018) Ji Gao, Jack Lanchantin, Mary Lou Soffa 和 Yanjun Qi。《黑箱生成对抗性文本序列以规避深度学习分类器》。在
    *2018 IEEE 安全与隐私研讨会 (SPW)*，第 50–56 页。IEEE，2018。
- en: Gao et al. (2020) Tianyu Gao, Adam Fisch, and Danqi Chen. Making pre-trained
    language models better few-shot learners. *arXiv preprint arXiv:2012.15723*, 2020.
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao 等 (2020) Tianyu Gao, Adam Fisch 和 Danqi Chen。《提升预训练语言模型的少量学习能力》。*arXiv 预印本
    arXiv:2012.15723*，2020。
- en: Garg et al. (2022) Shivam Garg, Dimitris Tsipras, Percy S Liang, and Gregory
    Valiant. What can transformers learn in-context? a case study of simple function
    classes. *Advances in Neural Information Processing Systems*, 35:30583–30598,
    2022.
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Garg et al. (2022) 希瓦姆·加尔格、迪米特里斯·齐普拉斯、佩西·S·梁和格雷戈里·瓦利安特。《变换器在上下文中能学到什么？简单函数类的案例研究》。*神经信息处理系统进展*，35:30583–30598，2022年。
- en: 'Gehman et al. (2020) Samuel Gehman, Suchin Gururangan, Maarten Sap, Yejin Choi,
    and Noah A Smith. Realtoxicityprompts: Evaluating neural toxic degeneration in
    language models. In *Findings of the Association for Computational Linguistics:
    EMNLP 2020*, pp.  3356–3369, 2020.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gehman et al. (2020) 塞缪尔·盖曼、苏钦·古鲁拉甘、马尔滕·萨普、叶津·崔和诺亚·A·史密斯。《Realtoxicityprompts：评估语言模型中的神经毒性退化》。在*计算语言学协会：EMNLP
    2020的发现*中，第3356–3369页，2020年。
- en: Giampiccolo et al. (2007) Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, and
    Bill Dolan. The third PASCAL recognizing textual entailment challenge. In *Proceedings
    of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing*, pp.  1–9,
    Prague, June 2007\. Association for Computational Linguistics. URL [https://aclanthology.org/W07-1401](https://aclanthology.org/W07-1401).
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Giampiccolo et al. (2007) 达尼洛·贾姆皮科洛、贝尔纳多·马格尼尼、伊多·达根和比尔·多兰。《第三届PASCAL文本蕴涵识别挑战》。在*ACL-PASCAL文本蕴涵与释义研讨会论文集*中，第1–9页，布拉格，2007年6月。计算语言学协会。网址
    [https://aclanthology.org/W07-1401](https://aclanthology.org/W07-1401)。
- en: Goodfellow et al. (2014) Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy.
    Explaining and harnessing adversarial examples. *arXiv preprint arXiv:1412.6572*,
    2014.
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow et al. (2014) 伊恩·J·古德费洛、乔纳森·施伦斯和克里斯蒂安·谢热迪。《解释和利用对抗样本》。*arXiv预印本 arXiv:1412.6572*，2014年。
- en: 'Iyyer et al. (2018) Mohit Iyyer, John Wieting, Kevin Gimpel, and Luke Zettlemoyer.
    Adversarial example generation with syntactically controlled paraphrase networks.
    In *Proceedings of the 2018 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)*,
    pp.  1875–1885, 2018.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Iyyer et al. (2018) 莫希特·伊耶尔、约翰·维廷、凯文·金佩尔和卢克·泽特尔摩耶。《利用句法控制的释义网络生成对抗样本》。在*2018年北美计算语言学协会：人类语言技术会议论文集，第1卷（长篇论文）*中，第1875–1885页，2018年。
- en: Jin et al. (2019) Di Jin, Zhijing Jin, Joey Tianyi Zhou, and Peter Szolovits.
    Is bert really robust? natural language attack on text classification and entailment.
    *arXiv preprint arXiv:1907.11932*, 2:10, 2019.
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jin et al. (2019) 迪·金、志晶·金、乔伊·天意·周和彼得·索洛维茨。《BERT 真的那么强健吗？对文本分类和蕴涵的自然语言攻击》。*arXiv预印本
    arXiv:1907.11932*，2:10，2019。
- en: Kurakin et al. (2018) Alexey Kurakin, Ian J Goodfellow, and Samy Bengio. Adversarial
    examples in the physical world. In *Artificial intelligence safety and security*,
    pp.  99–112. Chapman and Hall/CRC, 2018.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kurakin et al. (2018) 亚历克塞·库拉金、伊恩·J·古德费洛和萨米·本吉奥。《物理世界中的对抗样本》。在*人工智能安全与保障*中，第99–112页。查普曼与霍尔/CRC，2018年。
- en: 'Li et al. (2018) Jinfeng Li, Shouling Ji, Tianyu Du, Bo Li, and Ting Wang.
    Textbugger: Generating adversarial text against real-world applications. *arXiv
    preprint arXiv:1812.05271*, 2018.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. (2018) 金锋·李、守令·季、天宇·杜、博·李和婷·王。《Textbugger：针对现实世界应用生成对抗文本》。*arXiv预印本
    arXiv:1812.05271*，2018年。
- en: 'Li et al. (2020) Linyang Li, Ruotian Ma, Qipeng Guo, Xiangyang Xue, and Xipeng
    Qiu. Bert-attack: Adversarial attack against bert using bert. *arXiv preprint
    arXiv:2004.09984*, 2020.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. (2020) 林阳·李、若天·马、启鹏·郭、向阳·薛和西鹏·邱。《BERT-攻击：使用BERT对BERT进行对抗攻击》。*arXiv预印本
    arXiv:2004.09984*，2020年。
- en: Liu et al. (2023a) Hanmeng Liu, Ruoxi Ning, Zhiyang Teng, Jian Liu, Qiji Zhou,
    and Yue Zhang. Evaluating the logical reasoning ability of chatgpt and gpt-4.
    *arXiv preprint arXiv:2304.03439*, 2023a.
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2023a) 韩萌·刘、若西·宁、志阳·滕、建·刘、启基·周和岳·张。《评估ChatGPT和GPT-4的逻辑推理能力》。*arXiv预印本
    arXiv:2304.03439*，2023a。
- en: 'Liu et al. (2023b) Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki
    Hayashi, and Graham Neubig. Pre-train, prompt, and predict: A systematic survey
    of prompting methods in natural language processing. *ACM Computing Surveys*,
    55(9):1–35, 2023b.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2023b) 彭飞·刘、韦哲·袁、金兰·傅、郑宝·姜、广明·林和格雷厄姆·纽比格。《预训练、提示和预测：自然语言处理中的提示方法系统性调查》。*ACM计算机调查*，55(9):1–35，2023b。
- en: Liu et al. (2023c) Yi Liu, Gelei Deng, Yuekang Li, Kailong Wang, Tianwei Zhang,
    Yepang Liu, Haoyu Wang, Yan Zheng, and Yang Liu. Prompt injection attack against
    llm-integrated applications. *arXiv preprint arXiv:2306.05499*, 2023c.
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2023c) 易·刘、戈磊·邓、岳康·李、凯龙·王、天伟·张、叶磅·刘、浩宇·王、严·郑和杨·刘。《针对LLM集成应用的提示注入攻击》。*arXiv预印本
    arXiv:2306.05499*，2023c。
- en: 'Liu et al. (2023d) Yi Liu, Gelei Deng, Zhengzi Xu, Yuekang Li, Yaowen Zheng,
    Ying Zhang, Lida Zhao, Tianwei Zhang, and Yang Liu. Jailbreaking chatgpt via prompt
    engineering: An empirical study. *arXiv preprint arXiv:2305.13860*, 2023d.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu等（2023d年）Yi Liu, Gelei Deng, Zhengzi Xu, Yuekang Li, Yaowen Zheng, Ying Zhang,
    Lida Zhao, Tianwei Zhang, 和 Yang Liu. 通过提示工程破解chatgpt：一项实证研究。*arXiv预印本 arXiv:2305.13860*，2023d年。
- en: 'Liu et al. (2019) Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi,
    Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta:
    A robustly optimized bert pretraining approach. *arXiv preprint arXiv:1907.11692*,
    2019.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu等（2019年）Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi
    Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, 和 Veselin Stoyanov. Roberta: 一种鲁棒优化的bert预训练方法。*arXiv预印本
    arXiv:1907.11692*，2019年。'
- en: 'Logan IV et al. (2021) Robert L Logan IV, Ivana Balažević, Eric Wallace, Fabio
    Petroni, Sameer Singh, and Sebastian Riedel. Cutting down on prompts and parameters:
    Simple few-shot learning with language models. *arXiv preprint arXiv:2106.13353*,
    2021.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Logan IV等（2021年）Robert L Logan IV, Ivana Balažević, Eric Wallace, Fabio Petroni,
    Sameer Singh, 和 Sebastian Riedel. 减少提示和参数：用语言模型进行简单的少样本学习。*arXiv预印本 arXiv:2106.13353*，2021年。
- en: Madry et al. (2018) Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris
    Tsipras, and Adrian Vladu. Towards deep learning models resistant to adversarial
    attacks. In *ICLR*, 2018.
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Madry等（2018年）Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris
    Tsipras, 和 Adrian Vladu. 迈向对抗攻击鲁棒的深度学习模型。在*ICLR*，2018年。
- en: Mahmood et al. (2021) Kaleel Mahmood, Rigel Mahmood, and Marten Van Dijk. On
    the robustness of vision transformers to adversarial examples. In *Proceedings
    of the IEEE/CVF International Conference on Computer Vision*, pp.  7838–7847,
    2021.
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mahmood等（2021年）Kaleel Mahmood, Rigel Mahmood, 和 Marten Van Dijk. 视觉变换器对对抗样本的鲁棒性。发表于*IEEE/CVF国际计算机视觉会议论文集*，第7838–7847页，2021年。
- en: 'Manakul et al. (2023) Potsawee Manakul, Adian Liusie, and Mark JF Gales. Selfcheckgpt:
    Zero-resource black-box hallucination detection for generative large language
    models. *arXiv preprint arXiv:2303.08896*, 2023.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Manakul等（2023年）Potsawee Manakul, Adian Liusie, 和 Mark JF Gales. Selfcheckgpt:
    用于生成大语言模型的零资源黑箱幻觉检测。*arXiv预印本 arXiv:2303.08896*，2023年。'
- en: McKenna et al. (2023) Nick McKenna, Tianyi Li, Liang Cheng, Mohammad Javad Hosseini,
    Mark Johnson, and Mark Steedman. Sources of hallucination by large language models
    on inference tasks. *arXiv preprint arXiv:2305.14552*, 2023.
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: McKenna等（2023年）Nick McKenna, Tianyi Li, Liang Cheng, Mohammad Javad Hosseini,
    Mark Johnson, 和 Mark Steedman. 大语言模型在推理任务中的幻觉来源。*arXiv预印本 arXiv:2305.14552*，2023年。
- en: 'Miao et al. (2023) Ning Miao, Yee Whye Teh, and Tom Rainforth. Selfcheck: Using
    llms to zero-shot check their own step-by-step reasoning. *arXiv preprint arXiv:2308.00436*,
    2023.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Miao等（2023年）Ning Miao, Yee Whye Teh, 和 Tom Rainforth. Selfcheck: 使用llms零-shot检查其自身逐步推理。*arXiv预印本
    arXiv:2308.00436*，2023年。'
- en: Naik et al. (2018) Aakanksha Naik, Abhilasha Ravichander, Norman Sadeh, Carolyn
    Rose, and Graham Neubig. Stress test evaluation for natural language inference.
    In *Proceedings of the 27th International Conference on Computational Linguistics*,
    pp.  2340–2353, 2018.
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Naik等（2018年）Aakanksha Naik, Abhilasha Ravichander, Norman Sadeh, Carolyn Rose,
    和 Graham Neubig. 自然语言推理的压力测试评估。在*第27届国际计算语言学大会论文集*，第2340–2353页，2018年。
- en: OpenAI (2023) OpenAI. Gpt-4 technical report, 2023.
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI (2023) OpenAI. Gpt-4技术报告，2023年。
- en: Peng & Mine (2020) Shaowen Peng and Tsunenori Mine. A robust hierarchical graph
    convolutional network model for collaborative filtering. *arXiv preprint arXiv:2004.14734*,
    2020.
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Peng & Mine（2020年）Shaowen Peng 和 Tsunenori Mine. 用于协同过滤的鲁棒层次图卷积网络模型。*arXiv预印本
    arXiv:2004.14734*，2020年。
- en: 'Perez & Ribeiro (2022) Fábio Perez and Ian Ribeiro. Ignore previous prompt:
    Attack techniques for language models. In *NeurIPS ML Safety Workshop*, 2022.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Perez & Ribeiro（2022年）Fábio Perez 和 Ian Ribeiro. 忽略先前提示：语言模型的攻击技术。在*NeurIPS
    ML安全研讨会*，2022年。
- en: Radford et al. (2019) Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario
    Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners.
    *OpenAI blog*, 1(8):9, 2019.
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Radford等（2019年）Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei,
    Ilya Sutskever, 等等。语言模型是无监督的多任务学习者。*OpenAI博客*，1(8):9，2019年。
- en: 'Rajpurkar et al. (2016) Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and
    Percy Liang. Squad: 100,000+ questions for machine comprehension of text. *arXiv
    preprint arXiv:1606.05250*, 2016.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Rajpurkar等（2016年）Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, 和 Percy
    Liang. Squad: 100,000+ 个机器理解文本的问题。*arXiv预印本 arXiv:1606.05250*，2016年。'
- en: 'Rao et al. (2023) Abhinav Rao, Sachin Vashistha, Atharva Naik, Somak Aditya,
    and Monojit Choudhury. Tricking llms into disobedience: Understanding, analyzing,
    and preventing jailbreaks. *arXiv preprint arXiv:2305.14965*, 2023.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rao 等 (2023) Abhinav Rao, Sachin Vashistha, Atharva Naik, Somak Aditya 和 Monojit
    Choudhury。诱使大型语言模型不服从：理解、分析和防止越狱。*arXiv 预印本 arXiv:2305.14965*，2023。
- en: 'Ribeiro et al. (2020) Marco Tulio Ribeiro, Tongshuang Wu, Carlos Guestrin,
    and Sameer Singh. Beyond accuracy: Behavioral testing of nlp models with checklist.
    In *Annual Meeting of the Association for Computational Linguistics*, 2020.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ribeiro 等 (2020) Marco Tulio Ribeiro, Tongshuang Wu, Carlos Guestrin 和 Sameer
    Singh。超越准确性：使用检查表进行NLP模型的行为测试。在*计算语言学协会年会*，2020。
- en: Shanahan et al. (2023) Murray Shanahan, Kyle McDonell, and Laria Reynolds. Role-play
    with large language models. *arXiv preprint arXiv:2305.16367*, 2023.
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shanahan 等 (2023) Murray Shanahan, Kyle McDonell 和 Laria Reynolds。与大型语言模型角色扮演。*arXiv
    预印本 arXiv:2305.16367*，2023。
- en: 'Shin et al. (2020) Taylor Shin, Yasaman Razeghi, Robert L Logan IV, Eric Wallace,
    and Sameer Singh. Autoprompt: Eliciting knowledge from language models with automatically
    generated prompts. *arXiv preprint arXiv:2010.15980*, 2020.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shin 等 (2020) Taylor Shin, Yasaman Razeghi, Robert L Logan IV, Eric Wallace
    和 Sameer Singh。Autoprompt: 通过自动生成的提示从语言模型中引出知识。*arXiv 预印本 arXiv:2010.15980*，2020。'
- en: Si et al. (2022) Wai Man Si, Michael Backes, Jeremy Blackburn, Emiliano De Cristofaro,
    Gianluca Stringhini, Savvas Zannettou, and Yang Zhang. Why so toxic? measuring
    and triggering toxic behavior in open-domain chatbots. In *Proceedings of the
    2022 ACM SIGSAC Conference on Computer and Communications Security*, pp.  2659–2673,
    2022.
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Si 等 (2022) Wai Man Si, Michael Backes, Jeremy Blackburn, Emiliano De Cristofaro,
    Gianluca Stringhini, Savvas Zannettou 和 Yang Zhang。为何如此毒性？测量和触发开放域聊天机器人中的毒性行为。在*2022年ACM
    SIGSAC计算机与通信安全会议论文集*，第2659–2673页，2022。
- en: Singhal et al. (2023) Karan Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mahdavi,
    Jason Wei, Hyung Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen
    Pfohl, et al. Large language models encode clinical knowledge. *Nature*, pp. 
    1–9, 2023.
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Singhal 等 (2023) Karan Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mahdavi, Jason
    Wei, Hyung Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen
    Pfohl 等。大型语言模型编码临床知识。*Nature*，第1–9页，2023。
- en: Socher et al. (2013) Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang,
    Christopher D Manning, Andrew Y Ng, and Christopher Potts. Recursive deep models
    for semantic compositionality over a sentiment treebank. In *Proceedings of the
    2013 conference on empirical methods in natural language processing*, pp.  1631–1642,
    2013.
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Socher 等 (2013) Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher
    D Manning, Andrew Y Ng 和 Christopher Potts。情感树库上的递归深度模型进行语义组合。在*2013年自然语言处理实证方法会议论文集*，第1631–1642页，2013。
- en: Song et al. (2023) Lei Song, Chuheng Zhang, Li Zhao, and Jiang Bian. Pre-trained
    large language models for industrial control. *arXiv preprint arXiv:2308.03028*,
    2023.
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Song 等 (2023) Lei Song, Chuheng Zhang, Li Zhao 和 Jiang Bian。预训练的大型语言模型用于工业控制。*arXiv
    预印本 arXiv:2308.03028*，2023。
- en: Szegedy et al. (2014) Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan
    Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. Intriguing properties of
    neural networks. In *2nd International Conference on Learning Representations,
    ICLR 2014*, 2014.
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Szegedy 等 (2014) Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna,
    Dumitru Erhan, Ian Goodfellow 和 Rob Fergus。神经网络的有趣特性。在*第2届国际学习表征会议, ICLR 2014*，2014。
- en: 'Taori et al. (2023) Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois,
    Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B Hashimoto. Alpaca: A
    strong, replicable instruction-following model. *Stanford Center for Research
    on Foundation Models. https://crfm. stanford. edu/2023/03/13/alpaca. html*, 3(6):7,
    2023.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Taori 等 (2023) Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen
    Li, Carlos Guestrin, Percy Liang 和 Tatsunori B Hashimoto。Alpaca: 一个强大的、可复制的指令跟随模型。*斯坦福基础模型研究中心。
    https://crfm.stanford.edu/2023/03/13/alpaca.html*，3(6):7，2023。'
- en: 'Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. *arXiv
    preprint arXiv:2307.09288*, 2023.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Touvron 等 (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad
    Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale 等。Llama 2: 开放基础和微调聊天模型。*arXiv 预印本 arXiv:2307.09288*，2023。'
- en: 'Wang et al. (2018) Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill,
    Omer Levy, and Samuel R Bowman. Glue: A multi-task benchmark and analysis platform
    for natural language understanding. *arXiv preprint arXiv:1804.07461*, 2018.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang et al. (2018) Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill,
    Omer Levy, 和 Samuel R Bowman. Glue: 用于自然语言理解的多任务基准和分析平台。*arXiv预印本 arXiv:1804.07461*，2018年。'
- en: 'Wang et al. (2021) Boxin Wang, Chejian Xu, Shuohang Wang, Zhe Gan, Yu Cheng,
    Jianfeng Gao, Ahmed Hassan Awadallah, and Bo Li. Adversarial glue: A multi-task
    benchmark for robustness evaluation of language models. In *Thirty-fifth Conference
    on Neural Information Processing Systems Datasets and Benchmarks Track (Round
    2)*, 2021.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang et al. (2021) Boxin Wang, Chejian Xu, Shuohang Wang, Zhe Gan, Yu Cheng,
    Jianfeng Gao, Ahmed Hassan Awadallah, 和 Bo Li. Adversarial glue: 用于语言模型鲁棒性评估的多任务基准。发表于
    *第三十五届神经信息处理系统会议数据集和基准追踪（第二轮）*，2021年。'
- en: 'Wang et al. (2022) Boxin Wang, Chejian Xu, Xiangyu Liu, Yu Cheng, and Bo Li.
    Semattack: Natural textual attacks via different semantic spaces. In *Findings
    of the Association for Computational Linguistics: NAACL 2022*, pp.  176–205, 2022.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang et al. (2022) Boxin Wang, Chejian Xu, Xiangyu Liu, Yu Cheng, 和 Bo Li.
    Semattack: 通过不同语义空间的自然文本攻击。发表于 *计算语言学协会发现：NAACL 2022*，第176–205页，2022年。'
- en: 'Wang et al. (2023a) Boxin Wang, Weixin Chen, Hengzhi Pei, Chulin Xie, Mintong
    Kang, Chenhui Zhang, Chejian Xu, Zidi Xiong, Ritik Dutta, Rylan Schaeffer, et al.
    Decodingtrust: A comprehensive assessment of trustworthiness in gpt models. *arXiv
    preprint arXiv:2306.11698*, 2023a.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang et al. (2023a) Boxin Wang, Weixin Chen, Hengzhi Pei, Chulin Xie, Mintong
    Kang, Chenhui Zhang, Chejian Xu, Zidi Xiong, Ritik Dutta, Rylan Schaeffer, 等.
    Decodingtrust: 对gpt模型信任度的全面评估。*arXiv预印本 arXiv:2306.11698*，2023年。'
- en: 'Wang et al. (2023b) Jindong Wang, Xixu Hu, Wenxin Hou, Hao Chen, Runkai Zheng,
    Yidong Wang, Linyi Yang, Haojun Huang, Wei Ye, Xiubo Geng, et al. On the robustness
    of chatgpt: An adversarial and out-of-distribution perspective. *arXiv preprint
    arXiv:2302.12095*, 2023b.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. (2023b) Jindong Wang, Xixu Hu, Wenxin Hou, Hao Chen, Runkai Zheng,
    Yidong Wang, Linyi Yang, Haojun Huang, Wei Ye, Xiubo Geng, 等. 关于ChatGPT的鲁棒性：从对抗性和分布外的视角。*arXiv预印本
    arXiv:2302.12095*，2023年。
- en: Wang et al. (2017) Zhiguo Wang, Wael Hamza, and Radu Florian. Bilateral multi-perspective
    matching for natural language sentences. In *Proceedings of the 26th International
    Joint Conference on Artificial Intelligence*, pp.  4144–4150, 2017.
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. (2017) Zhiguo Wang, Wael Hamza, 和 Radu Florian. 自然语言句子的双边多视角匹配。发表于
    *第26届国际联合人工智能会议论文集*，第4144–4150页，2017年。
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei
    Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits
    reasoning in large language models. *Advances in Neural Information Processing
    Systems*, 35:24824–24837, 2022.
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei
    Xia, Ed Chi, Quoc V Le, Denny Zhou, 等. Chain-of-thought prompting 引发大型语言模型的推理。*神经信息处理系统进展*，35:24824–24837，2022年。
- en: Williams et al. (2018) Adina Williams, Nikita Nangia, and Samuel R Bowman. The
    multi-genre nli corpus. 2018.
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Williams et al. (2018) Adina Williams, Nikita Nangia, 和 Samuel R Bowman. 多领域nli语料库。2018年。
- en: Xie et al. (2017) Cihang Xie, Jianyu Wang, Zhishuai Zhang, Yuyin Zhou, Lingxi
    Xie, and Alan Yuille. Adversarial examples for semantic segmentation and object
    detection. In *Proceedings of the IEEE international conference on computer vision*,
    pp.  1369–1378, 2017.
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie et al. (2017) Cihang Xie, Jianyu Wang, Zhishuai Zhang, Yuyin Zhou, Lingxi
    Xie, 和 Alan Yuille. 语义分割和目标检测的对抗性示例。发表于 *IEEE国际计算机视觉会议论文集*，第1369–1378页，2017年。
- en: Zang et al. (2020) Yuan Zang, Fanchao Qi, Chenghao Yang, Zhiyuan Liu, Meng Zhang,
    Qun Liu, and Maosong Sun. Word-level textual adversarial attacking as combinatorial
    optimization. In *Proceedings of the 58th Annual Meeting of the Association for
    Computational Linguistics*, pp.  6066–6080, 2020.
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zang et al. (2020) Yuan Zang, Fanchao Qi, Chenghao Yang, Zhiyuan Liu, Meng Zhang,
    Qun Liu, 和 Maosong Sun. 词级文本对抗攻击作为组合优化。发表于 *第58届计算语言学协会年会论文集*，第6066–6080页，2020年。
- en: 'Zhang et al. (2019) Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger,
    and Yoav Artzi. Bertscore: Evaluating text generation with bert. *arXiv preprint
    arXiv:1904.09675*, 2019.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang et al. (2019) Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger,
    和 Yoav Artzi. Bertscore: 用bert评估文本生成。*arXiv预印本 arXiv:1904.09675*，2019年。'
- en: Zheng et al. (2023) Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang,
    Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al.
    Judging llm-as-a-judge with mt-bench and chatbot arena. *arXiv preprint arXiv:2306.05685*,
    2023.
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng et al. (2023) Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang,
    Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, 等. 使用mt-bench和chatbot
    arena 评判llm作为评判者的表现。*arXiv预印本 arXiv:2306.05685*，2023年。
- en: 'Zhu et al. (2019) Chen Zhu, Yu Cheng, Zhe Gan, Siqi Sun, Tom Goldstein, and
    Jingjing Liu. Freelb: Enhanced adversarial training for natural language understanding.
    In *International Conference on Learning Representations*, 2019.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhu et al. (2019) Chen Zhu, Yu Cheng, Zhe Gan, Siqi Sun, Tom Goldstein, 和 Jingjing
    Liu。Freelb: 增强自然语言理解的对抗训练。在*国际学习表征会议*，2019年。'
- en: 'Zhu et al. (2023) Kaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen Wang, Hao
    Chen, Yidong Wang, Linyi Yang, Wei Ye, Neil Zhenqiang Gong, Yue Zhang, et al.
    Promptbench: Towards evaluating the robustness of large language models on adversarial
    prompts. *arXiv preprint arXiv:2306.04528*, 2023.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhu et al. (2023) Kaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen Wang, Hao
    Chen, Yidong Wang, Linyi Yang, Wei Ye, Neil Zhenqiang Gong, Yue Zhang 等。Promptbench:
    Towards evaluating the robustness of large language models on adversarial prompts.
    *arXiv preprint arXiv:2306.04528*, 2023。'
- en: Zou et al. (2023) Andy Zou, Zifan Wang, J Zico Kolter, and Matt Fredrikson.
    Universal and transferable adversarial attacks on aligned language models. *arXiv
    preprint arXiv:2307.15043*, 2023.
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zou et al. (2023) Andy Zou, Zifan Wang, J Zico Kolter, 和 Matt Fredrikson。对齐语言模型的通用和可转移对抗攻击。*arXiv
    preprint arXiv:2307.15043*, 2023。
- en: Appendix A Extended Related Work
  id: totrans-355
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 扩展相关工作
- en: Here, we discuss related works w.r.t. prompt-based learning and prompt engineering.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们讨论与基于提示的学习和提示工程相关的工作。
- en: Prompt-based learning.
  id: totrans-357
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基于提示的学习。
- en: Prompt-based learning (Liu et al., [2023b](#bib.bib26)) is a powerful and attractive
    strategy that asks an LLM to solve a new classification task via a well-designed
    prompt. The prompt contains some unfilled slots, and then the LLM is used to probabilistically
    fill the unfilled information given an original input, which can yield final predicted
    results. There are two strategies of prompt-based learning—few-shot inference (Logan IV
    et al., [2021](#bib.bib30); Garg et al., [2022](#bib.bib16); Brown et al., [2020](#bib.bib8))
    and zero-shot inference (Radford et al., [2019](#bib.bib40)), corresponding to
    few or no labelled data in the prompt, respectively. Recent studies have shown
    the strategy of few-shot inference (Brown et al., [2020](#bib.bib8); Logan IV
    et al., [2021](#bib.bib30); Zhu et al., [2023](#bib.bib66); Garg et al., [2022](#bib.bib16))
    that provides few labelled data in the prompt can help improve the LLM’s comprehension
    of the required task and thus improving the performance in downstream classification
    tasks. Our proposed prompt-based adversarial attack aims to ask the LLM to implement
    adversarial attacks against itself and thus helps to effectively evaluate the
    LLM’s robustness, instead of solving classification tasks.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 基于提示的学习（Liu et al., [2023b](#bib.bib26)）是一种强大且有吸引力的策略，它通过精心设计的提示来要求LLM解决新的分类任务。提示包含一些未填充的槽位，然后LLM在给定原始输入的情况下，用概率方式填充未填充的信息，从而得出最终的预测结果。基于提示的学习有两种策略——少样本推理（Logan
    IV et al., [2021](#bib.bib30); Garg et al., [2022](#bib.bib16); Brown et al.,
    [2020](#bib.bib8)）和零样本推理（Radford et al., [2019](#bib.bib40)），分别对应于提示中的少量或没有标注数据。近期研究表明，少样本推理的策略（Brown
    et al., [2020](#bib.bib8); Logan IV et al., [2021](#bib.bib30); Zhu et al., [2023](#bib.bib66);
    Garg et al., [2022](#bib.bib16)）提供少量标注数据的提示可以帮助提高LLM对所需任务的理解，从而改善下游分类任务的性能。我们提出的基于提示的对抗攻击旨在要求LLM对自身实施对抗攻击，从而有效评估LLM的鲁棒性，而不是解决分类任务。
- en: Prompt engineering.
  id: totrans-359
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 提示工程。
- en: Prompt engineering (Liu et al., [2023b](#bib.bib26)), *a.k.a.* prompt template
    engineering, refers to the act of developing the most suitable prompt template
    for the downstream task that leads to state-of-the-art performance. Recent research
    works have focused on studying how to automatically generate a prompt (Shin et al.,
    [2020](#bib.bib45)) and how to enhance the power of the prompt (Gao et al., [2020](#bib.bib15))
    so that it improves the LLM’s performance in downstream tasks. In our paper, we
    design a template of an attack prompt that aims to ask the LLM to generate adversarial
    samples to fool itself. Our designed prompt template is used for effectively evaluating
    the LLM’s adversarial robustness, instead of enhancing performance in downstream
    tasks.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程（Liu et al., [2023b](#bib.bib26)），*亦称*提示模板工程，指的是开发最适合下游任务的提示模板的行为，以达到最先进的性能。近期研究工作集中于研究如何自动生成提示（Shin
    et al., [2020](#bib.bib45)）以及如何增强提示的能力（Gao et al., [2020](#bib.bib15)），以提高LLM在下游任务中的表现。在我们的论文中，我们设计了一种攻击提示的模板，旨在要求LLM生成对抗样本以欺骗自身。我们设计的提示模板用于有效评估LLM的对抗鲁棒性，而不是提升下游任务的性能。
- en: Appendix B Extensive Experimental Results
  id: totrans-361
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 广泛的实验结果
- en: B.1 GLUE Dataset
  id: totrans-362
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.1 GLUE 数据集
- en: In this subsection, we provide a detailed description of the tasks in the GLUE
    dataset.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一小节中，我们详细描述了 GLUE 数据集中的任务。
- en: SST-2.
  id: totrans-364
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: SST-2。
- en: The Stanford Sentiment Treebank (SST-2) task (Socher et al., [2013](#bib.bib48))
    originates from reviews and is a binary sentiment classification dataset, where
    the task is to determine whether a given sentence conveys a positive or negative
    sentiment. Therefore, the SST-2 task has only one sentence type, i.e., “sentence”,
    and its label set is {“positive”, “negative”}.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 斯坦福情感树库（SST-2）任务（Socher 等，[2013](#bib.bib48)）来源于评论，是一个二分类情感分类数据集，任务是确定给定句子是否传达了积极或消极的情感。因此，SST-2
    任务仅有一种句子类型，即“句子”，其标签集为 {“积极”, “消极”}。
- en: QQP.
  id: totrans-366
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: QQP。
- en: The Quora Question Pairs (QQP) task (Wang et al., [2017](#bib.bib58)) is sourced
    from Quora and serves as a binary classification task, challenging models to identify
    semantic equivalence between two questions. Thus, the type of sentences in the
    QQP task belongs to {“question1”, “question2”} and its label set is { “duplicate”,
    “not_duplicate”}. In our experiments, we apply PromptAttack to only perturb the
    sentence of the type “question1” in the QQP task.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: Quora 问题对（QQP）任务（Wang 等，[2017](#bib.bib58)）来源于 Quora，作为一个二分类任务，挑战模型识别两个问题之间的语义等价性。因此，QQP
    任务中的句子类型属于 {“问题1”, “问题2”}，其标签集为 {“重复”, “不重复”}。在我们的实验中，我们应用 PromptAttack 仅扰动 QQP
    任务中的“问题1”类型的句子。
- en: MNLI.
  id: totrans-368
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: MNLI。
- en: 'The Multi-Genre Natural Language Inference Corpus (MNLI) task (Williams et al.,
    [2018](#bib.bib60)) compiles data from various sources and is designed for natural
    language inference, asking models to judge whether a given hypothesis logically
    follows from a provided premise. There are two versions of the MNLI task: (1)
    MNLI-m is the matched version of MNLI and (2) MNLI-mm is the mismatched version
    of MNLI. In the MNLI task, the type of sentences belongs to {“premise”, “hypothesis”}
    and the label set of the MNLI task is {“entailment”, “neutral”, “contradiction”
    }. In our paper, we apply PromptAttack to only perturb the sentence of the type
    “premise” in the MNLI task.'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 多类别自然语言推理语料库（MNLI）任务（Williams 等，[2018](#bib.bib60)）汇编了来自各种来源的数据，旨在进行自然语言推理，要求模型判断给定的假设是否合乎逻辑地跟随提供的前提。MNLI
    任务有两个版本：（1）MNLI-m 是 MNLI 的匹配版本，（2）MNLI-mm 是 MNLI 的不匹配版本。在 MNLI 任务中，句子的类型属于 {“前提”,
    “假设”}，而 MNLI 任务的标签集为 {“蕴含”, “中立”, “矛盾”}。在我们的论文中，我们应用 PromptAttack 仅扰动 MNLI 任务中的“前提”类型的句子。
- en: RTE.
  id: totrans-370
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: RTE。
- en: The Recognizing Textual Entailment (RTE) dataset (Dagan et al., [2005](#bib.bib12);
    Bar-Haim et al., [2006](#bib.bib3); Giampiccolo et al., [2007](#bib.bib18); Bos
    & Markert, [2005](#bib.bib7); Bentivogli et al., [2009](#bib.bib5)) comprises
    text from news articles and presents a binary classification task where models
    must determine the relationship between two sentences. Therefore, in the RTE dataset,
    the set of the types of sentences is {“sentence1”, “sentence2”} and the label
    set is {“entailment”, “not_entailment”}. In our paper, we apply PromptAttack to
    only perturb the sentence of the type “sentence1” in the RTE task.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 识别文本蕴含（RTE）数据集（Dagan 等，[2005](#bib.bib12); Bar-Haim 等，[2006](#bib.bib3); Giampiccolo
    等，[2007](#bib.bib18); Bos & Markert，[2005](#bib.bib7); Bentivogli 等，[2009](#bib.bib5)）包含来自新闻文章的文本，呈现一个二分类任务，模型必须确定两个句子之间的关系。因此，在
    RTE 数据集中，句子的类型集合为 {“句子1”, “句子2”}，而标签集为 {“蕴含”, “不蕴含”}。在我们的论文中，我们应用 PromptAttack
    仅扰动 RTE 任务中的“句子1”类型的句子。
- en: QNLI.
  id: totrans-372
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: QNLI。
- en: The Question-answering Natural Language Inference (QNLI) dataset (Rajpurkar
    et al., [2016](#bib.bib41)) primarily focuses on natural language inference. Models
    are required to decide whether an answer to a given question can be found within
    a provided sentence. In the QNLI task, the type of sentence is sampled from {“question”,
    “sentence”} and the label set is {“entailment”, “not_entailment”}. In our paper,
    we apply PromptAttack to only perturb the sentence of the type “question” in the
    QNLI task.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 问答自然语言推理（QNLI）数据集（Rajpurkar 等，[2016](#bib.bib41)）主要集中于自然语言推理。模型需要决定给定的问题的答案是否可以在提供的句子中找到。在
    QNLI 任务中，句子的类型来自 {“问题”, “句子”}，标签集为 {“蕴含”, “不蕴含”}。在我们的论文中，我们应用 PromptAttack 仅扰动
    QNLI 任务中的“问题”类型的句子。
- en: B.2 BERTScore
  id: totrans-374
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.2 BERTScore。
- en: Formulation of BERTScore (Zhang et al., [2019](#bib.bib63)).
  id: totrans-375
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: BERTScore 的公式（Zhang 等，[2019](#bib.bib63)）。
- en: 'Given an original sentence  and its adversarial variant , we let  and  denote
    the number of words of the sentences  and , respectively. BERTScore  is calculated
    as follows:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 给定原始句子和其对抗变体，我们用和分别表示句子和的词数。BERTScore计算如下：
- en: '|  |  |  |'
  id: totrans-377
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |'
- en: where  and  are the embeddings of the sentence  and  extracted from a pre-trained
    RoBERTa-large model, respectively. Note that  and  are normalized to . Therefore,
    the range of the value of  is . As for the implementation of BERTScore, we exactly
    follow the [official GitHub](https://github.com/Tiiiger/bert_score) link of Zhang
    et al. ([2019](#bib.bib63)).
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 其中和分别是从预训练的RoBERTa-large模型中提取的句子和的嵌入。请注意，和被归一化为。因此，的值范围是。至于BERTScore的实现，我们完全遵循Zhang
    et al. ([2019](#bib.bib63))的[官方 GitHub](https://github.com/Tiiiger/bert_score)链接。
- en: BERTScore threshold .
  id: totrans-379
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: BERTScore 阈值。
- en: 'Table [8](#A2.T8 "Table 8 ‣ BERTScore threshold 𝜏₂. ‣ B.2 BERTScore ‣ Appendix
    B Extensive Experimental Results ‣ An LLM can Fool Itself: A Prompt-Based Adversarial
    Attack") reports the BERTScore threshold  which is calculated as the average BERTScore
    of the adversarial samples in AdvGLUE (Wang et al., [2021](#bib.bib54)) for each
    task. Note that, the BERTScore threshold  is used for the fidelity filter to filter
    out the adversarial sample whose semantic meaning is significantly changed.'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 表[8](#A2.T8 "表 8 ‣ BERTScore 阈值 𝜏₂. ‣ B.2 BERTScore ‣ 附录 B 广泛的实验结果 ‣ 一种LLM可以欺骗自己：基于提示的对抗攻击")报告了BERTScore阈值，它计算为每个任务中AdvGLUE（Wang
    et al., [2021](#bib.bib54)）的对抗样本的平均BERTScore。请注意，BERTScore阈值用于保真度过滤器，以筛选出语义意义发生显著变化的对抗样本。
- en: 'Table 8: The BERTScore threshold  for each task.'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8：每个任务的 BERTScore 阈值。
- en: '| Task | SST-2 | QQP | MNLI-m | MNLI-mm | RTE | QNLI |'
  id: totrans-382
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | SST-2 | QQP | MNLI-m | MNLI-mm | RTE | QNLI |'
- en: '| BERTScore threshold  | 0.93275 | 0.92380 | 0.93149 | 0.93316 | 0.93767 |
    0.92807 |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
  zh: '| BERTScore 阈值 | 0.93275 | 0.92380 | 0.93149 | 0.93316 | 0.93767 | 0.92807
    |'
- en: '![Refer to caption](img/8f97475ea934e54afdfb3b27032bb59c.png)![Refer to caption](img/6af63703f883ef7ba8176dc7911e7bcb.png)![Refer
    to caption](img/5f28cad1c698db9646490d02cfe9f92c.png)'
  id: totrans-384
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/8f97475ea934e54afdfb3b27032bb59c.png)![参考说明](img/6af63703f883ef7ba8176dc7911e7bcb.png)![参考说明](img/5f28cad1c698db9646490d02cfe9f92c.png)'
- en: 'Figure 4: The ASR w.r.t. BERTScore threshold  evaluated in the MNLI-m, QQP,
    and RTE tasks using GPT-3.5.'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：使用 GPT-3.5 在 MNLI-m、QQP 和 RTE 任务中评估的 ASR 相对于 BERTScore 阈值。
- en: 'Table 9: We report the ASR (%) without the fidelity filter evaluated in each
    task of the GLUE dataset using various victim LLMs. “Avg” refers to the average
    ASR over all the tasks.'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 表 9：我们报告了在 GLUE 数据集的每个任务中使用各种受害LLM评估的 ASR（%），不包括保真度过滤器。 “平均”指的是所有任务的平均ASR。
- en: '| Task | SST-2 | QQP | MNLI-m | MNLI-mm | RTE | QNLI | Avg |'
  id: totrans-387
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | SST-2 | QQP | MNLI-m | MNLI-mm | RTE | QNLI | 平均 |'
- en: '| Llama2 -7B | AdvGLUE++ | 47.14 | 14.49 | 69.60 | 68.66 | 12.50 | 30.21 |
    40.44 |'
  id: totrans-388
  prefs: []
  type: TYPE_TB
  zh: '| Llama2 -7B | AdvGLUE++ | 47.14 | 14.49 | 69.60 | 68.66 | 12.50 | 30.21 |
    40.44 |'
- en: '| PromptAttack-EN | 99.37 | 47.43 | 88.03 | 87.04 | 52.26 | 56.23 | 71.73 |'
  id: totrans-389
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-EN | 99.37 | 47.43 | 88.03 | 87.04 | 52.26 | 56.23 | 71.73 |'
- en: '| PromptAttack-FS-EN | 99.86 | 48.31 | 87.78 | 88.21 | 53.86 | 57.77 | 72.63
    |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-FS-EN | 99.86 | 48.31 | 87.78 | 88.21 | 53.86 | 57.77 | 72.63
    |'
- en: '| Llama2 -13B | AdvGLUE++ | 44.44 | 28.37 | 63.75 | 69.99 | 20.74 | 52.07 |
    46.56 |'
  id: totrans-391
  prefs: []
  type: TYPE_TB
  zh: '| Llama2 -13B | AdvGLUE++ | 44.44 | 28.37 | 63.75 | 69.99 | 20.74 | 52.07 |
    46.56 |'
- en: '| PromptAttack-EN | 99.30 | 71.50 | 91.50 | 91.02 | 51.49 | 89.02 | 82.31 |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-EN | 99.30 | 71.50 | 91.50 | 91.02 | 51.49 | 89.02 | 82.31 |'
- en: '| PromptAttack-FS-EN | 99.71 | 73.15 | 91.59 | 91.55 | 53.04 | 89.96 | 83.17
    |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-FS-EN | 99.71 | 73.15 | 91.59 | 91.55 | 53.04 | 89.96 | 83.17
    |'
- en: '| GPT-3.5 | AdvGLUE++ | 28.26 | 37.62 | 34.42 | 44.57 | 51.78 | 38.71 | 39.23
    |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 | AdvGLUE++ | 28.26 | 37.62 | 34.42 | 44.57 | 51.78 | 38.71 | 39.23
    |'
- en: '| PromptAttack-EN | 89.20 | 50.06 | 58.51 | 55.42 | 43.88 | 62.33 | 59.90 |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-EN | 89.20 | 50.06 | 58.51 | 55.42 | 43.88 | 62.33 | 59.90 |'
- en: '| PromptAttack-FS-EN | 94.05 | 49.54 | 56.42 | 52.00 | 43.39 | 59.50 | 59.15
    |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-FS-EN | 94.05 | 49.54 | 56.42 | 52.00 | 43.39 | 59.50 | 59.15
    |'
- en: ASR w.r.t. BERTScore threshold .
  id: totrans-397
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ASR 相对于 BERTScore 阈值。
- en: 'Figure [4](#A2.F4 "Figure 4 ‣ BERTScore threshold 𝜏₂. ‣ B.2 BERTScore ‣ Appendix
    B Extensive Experimental Results ‣ An LLM can Fool Itself: A Prompt-Based Adversarial
    Attack") demonstrates the ASR w.r.t. BERTScore threshold  evaluated in the MNLI-m,
    QQP, and RTE tasks using GPT-3.5\. It shows that our proposed PromptAttack can
    obtain a higher ASR with a high BERTScore threshold  in various tasks, which validates
    the effectiveness of our proposed PromptAttack in generating powerful adversarial
    samples of high fidelity.'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: '图[4](#A2.F4 "Figure 4 ‣ BERTScore threshold 𝜏₂. ‣ B.2 BERTScore ‣ Appendix
    B Extensive Experimental Results ‣ An LLM can Fool Itself: A Prompt-Based Adversarial
    Attack")展示了在MNLI-m、QQP和RTE任务中使用GPT-3.5评估的ASR与BERTScore阈值的关系。它显示，我们提出的PromptAttack在各种任务中能在高BERTScore阈值下获得更高的ASR，这验证了我们提出的PromptAttack在生成高忠实度强对抗样本方面的有效性。'
- en: 'Besides, we find that, in the RTE task, the ASR of AdvGLUE++ becomes higher
    than that of PromptAttack when . We argue that the ASR achieved by adversarial
    samples of low fidelity cannot validate that AdvGLUE++ is a better tool to evaluate
    robustness than PromptAttack. It is because when BERTScore is low, the semantic
    meaning of the adversarial samples has been significantly changed. We show several
    examples of adversarial samples whose BERTScore is lower than  sampled from AdvGLUE++
    in Table [18](#A2.T18 "Table 18 ‣ Extensive analyses. ‣ B.6 Attack Transferability
    ‣ Appendix B Extensive Experimental Results ‣ An LLM can Fool Itself: A Prompt-Based
    Adversarial Attack"). Observed from Table [18](#A2.T18 "Table 18 ‣ Extensive analyses.
    ‣ B.6 Attack Transferability ‣ Appendix B Extensive Experimental Results ‣ An
    LLM can Fool Itself: A Prompt-Based Adversarial Attack"), the semantic meaning
    of adversarial samples is significantly changed, which makes it meaningless to
    consider the ASR of such adversarial samples of low fidelity. Therefore, we only
    consider the ASR at a high BRTScore threshold and our proposed PromptAttack is
    the most effective attack to generate effective adversarial samples of a high
    BERTScore.'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: '此外，我们发现，在RTE任务中，当BERTScore较低时，AdvGLUE++的ASR会高于PromptAttack。我们认为，低忠实度对抗样本所达到的ASR不能验证AdvGLUE++是否比PromptAttack更适合评估鲁棒性。这是因为当BERTScore较低时，对抗样本的语义意义已经发生了显著变化。我们在表[18](#A2.T18
    "Table 18 ‣ Extensive analyses. ‣ B.6 Attack Transferability ‣ Appendix B Extensive
    Experimental Results ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack")中展示了从AdvGLUE++中采样的BERTScore低于某个值的对抗样本的几个示例。从表[18](#A2.T18
    "Table 18 ‣ Extensive analyses. ‣ B.6 Attack Transferability ‣ Appendix B Extensive
    Experimental Results ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack")中可以观察到，对抗样本的语义意义发生了显著变化，这使得考虑低忠实度对抗样本的ASR毫无意义。因此，我们只考虑高BERTScore阈值下的ASR，我们提出的PromptAttack是生成有效高BERTScore对抗样本的最有效攻击方法。'
- en: B.3 ASR without Fidelity Filter
  id: totrans-400
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.3 无忠实度过滤器的ASR
- en: 'Table [9](#A2.T9 "Table 9 ‣ BERTScore threshold 𝜏₂. ‣ B.2 BERTScore ‣ Appendix
    B Extensive Experimental Results ‣ An LLM can Fool Itself: A Prompt-Based Adversarial
    Attack") reports the ASR under AdvGLUE++ (Wang et al., [2023a](#bib.bib56)) and
    our proposed PromoptAttack without the fidelity filter. It validates that, without
    a fidelity filter, our proposed PromptAttack can still yield a higher ASR compared
    to AdvGLUE++ (Wang et al., [2023a](#bib.bib56)).'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: '表[9](#A2.T9 "Table 9 ‣ BERTScore threshold 𝜏₂. ‣ B.2 BERTScore ‣ Appendix B
    Extensive Experimental Results ‣ An LLM can Fool Itself: A Prompt-Based Adversarial
    Attack")报告了在AdvGLUE++（Wang等，[2023a](#bib.bib56)）和我们提出的PromptAttack下的ASR，均未使用忠实度过滤器。结果验证了，在没有忠实度过滤器的情况下，我们提出的PromptAttack相较于AdvGLUE++（Wang等，[2023a](#bib.bib56)）仍能产生更高的ASR。'
- en: 'However, we argue that the ASR without the fidelity filter is meaningless.
    As shown in Table [18](#A2.T18 "Table 18 ‣ Extensive analyses. ‣ B.6 Attack Transferability
    ‣ Appendix B Extensive Experimental Results ‣ An LLM can Fool Itself: A Prompt-Based
    Adversarial Attack"), the semantic meanings of adversarial samples whose BERTScore
    is lower than 0.85 in the AdvGLUE++ dataset are significantly changed. Note that,
    the adversarial sample should maintain its original semantic meanings (Goodfellow
    et al., [2014](#bib.bib19); Wang et al., [2021](#bib.bib54)). Therefore, it is
    meaningless to analyze the attack power of the method according to the ASR without
    the fidelity filter.'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: '然而，我们认为没有忠实度过滤器的ASR是毫无意义的。如表[18](#A2.T18 "Table 18 ‣ Extensive analyses. ‣
    B.6 Attack Transferability ‣ Appendix B Extensive Experimental Results ‣ An LLM
    can Fool Itself: A Prompt-Based Adversarial Attack")所示，在AdvGLUE++数据集中，BERTScore低于0.85的对抗样本的语义意义发生了显著变化。请注意，对抗样本应该保持其原始的语义意义（Goodfellow等，[2014](#bib.bib19)；Wang等，[2021](#bib.bib54)）。因此，根据没有忠实度过滤器的ASR来分析方法的攻击能力是毫无意义的。'
- en: 'Table 10: We demonstrate the standard deviation of the ASR reported in Table [3](#S4.T3
    "Table 3 ‣ Victim LLMs ‣ 4 Experiments ‣ An LLM can Fool Itself: A Prompt-Based
    Adversarial Attack").'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 表 10：我们展示了表 [3](#S4.T3 "表 3 ‣ 受害者LLM ‣ 4 实验 ‣ LLM可以自我欺骗：基于提示的对抗攻击")中报告的ASR标准差。
- en: '| Task | SST-2 | QQP | MNLI-m | MNLI-mm | RTE | QNLI |'
  id: totrans-404
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | SST-2 | QQP | MNLI-m | MNLI-mm | RTE | QNLI |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| Llama2 -7B | AdvGLUE | 9.56 | 11.37 | 26.29 | 26.16 | 12.83 | 25.65 |'
  id: totrans-406
  prefs: []
  type: TYPE_TB
  zh: '| Llama2 -7B | AdvGLUE | 9.56 | 11.37 | 26.29 | 26.16 | 12.83 | 25.65 |'
- en: '| AdvGLUE++ | 4.13 | 3.81 | 7.41 | 6.50 | 1.32 | 6.77 |'
  id: totrans-407
  prefs: []
  type: TYPE_TB
  zh: '| AdvGLUE++ | 4.13 | 3.81 | 7.41 | 6.50 | 1.32 | 6.77 |'
- en: '|'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; PromptAttack-EN &#124;'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; PromptAttack-EN &#124;'
- en: '| 5.78 | 19.07 | 21.32 | 25.38 | 20.70 | 39.90 |'
  id: totrans-410
  prefs: []
  type: TYPE_TB
  zh: '| 5.78 | 19.07 | 21.32 | 25.38 | 20.70 | 39.90 |'
- en: '|'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; PromptAttack-FS-EN &#124;'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; PromptAttack-FS-EN &#124;'
- en: '| 5.57 | 15.85 | 20.69 | 22.63 | 17.00 | 35.19 |'
  id: totrans-413
  prefs: []
  type: TYPE_TB
  zh: '| 5.57 | 15.85 | 20.69 | 22.63 | 17.00 | 35.19 |'
- en: '| Llama2 -13B | AdvGLUE | 8.78 | 15.29 | 13.73 | 10.96 | 7.93 | 22.19 |'
  id: totrans-414
  prefs: []
  type: TYPE_TB
  zh: '| Llama2 -13B | AdvGLUE | 8.78 | 15.29 | 13.73 | 10.96 | 7.93 | 22.19 |'
- en: '| AdvGLUE++ | 3.06 | 6.02 | 2.90 | 3.10 | 1.57 | 4.26 |'
  id: totrans-415
  prefs: []
  type: TYPE_TB
  zh: '| AdvGLUE++ | 3.06 | 6.02 | 2.90 | 3.10 | 1.57 | 4.26 |'
- en: '|'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; PromptAttack-EN &#124;'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; PromptAttack-EN &#124;'
- en: '| 7.21 | 24.65 | 15.14 | 14.10 | 18.86 | 25.15 |'
  id: totrans-418
  prefs: []
  type: TYPE_TB
  zh: '| 7.21 | 24.65 | 15.14 | 14.10 | 18.86 | 25.15 |'
- en: '|'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; PromptAttack-FS-EN &#124;'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; PromptAttack-FS-EN &#124;'
- en: '| 6.30 | 22.83 | 14.64 | 14.61 | 17.10 | 23.66 |'
  id: totrans-421
  prefs: []
  type: TYPE_TB
  zh: '| 6.30 | 22.83 | 14.64 | 14.61 | 17.10 | 23.66 |'
- en: '| GPT-3.5 | AdvGLUE | 3.00 | 4.96 | 1.48 | 5.11 | 3.85 | 4.27 |'
  id: totrans-422
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 | AdvGLUE | 3.00 | 4.96 | 1.48 | 5.11 | 3.85 | 4.27 |'
- en: '| AdvGLUE++ | 0.91 | 2.14 | 0.97 | 0.84 | 0.44 | 0.90 |'
  id: totrans-423
  prefs: []
  type: TYPE_TB
  zh: '| AdvGLUE++ | 0.91 | 2.14 | 0.97 | 0.84 | 0.44 | 0.90 |'
- en: '|'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; PromptAttack-EN &#124;'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; PromptAttack-EN &#124;'
- en: '| 1.66 | 8.14 | 6.16 | 5.63 | 5.06 | 3.38 |'
  id: totrans-426
  prefs: []
  type: TYPE_TB
  zh: '| 1.66 | 8.14 | 6.16 | 5.63 | 5.06 | 3.38 |'
- en: '|'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; PromptAttack-FS-EN &#124;'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; PromptAttack-FS-EN &#124;'
- en: '| 3.35 | 7.87 | 6.15 | 6.74 | 5.80 | 3.54 |'
  id: totrans-429
  prefs: []
  type: TYPE_TB
  zh: '| 3.35 | 7.87 | 6.15 | 6.74 | 5.80 | 3.54 |'
- en: 'Table 11: Robustness evaluation in the SST-2 task via different types of task
    descriptions.'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 表 11：通过不同类型的任务描述对SST-2任务的鲁棒性评估。
- en: '| Task description | ZS-TO | ZS-RO | FS-TO | FS-RO | Avg |'
  id: totrans-431
  prefs: []
  type: TYPE_TB
  zh: '| 任务描述 | ZS-TO | ZS-RO | FS-TO | FS-RO | 平均值 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-432
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Llama2-7B | AdvGLUE | 40.54 | 51.84 | 42.78 | 56.19 | 47.84 |'
  id: totrans-433
  prefs: []
  type: TYPE_TB
  zh: '| Llama2-7B | AdvGLUE | 40.54 | 51.84 | 42.78 | 56.19 | 47.84 |'
- en: '| AdvGLUE++ | 8.38 | 13.38 | 14.50 | 18.29 | 13.64 |'
  id: totrans-434
  prefs: []
  type: TYPE_TB
  zh: '| AdvGLUE++ | 8.38 | 13.38 | 14.50 | 18.29 | 13.64 |'
- en: '| PromptAttack-EN | 62.00 | 73.16 | 62.29 | 69.63 | 66.77 |'
  id: totrans-435
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-EN | 62.00 | 73.16 | 62.29 | 69.63 | 66.77 |'
- en: '| PromptAttack-FS-EN | 51.51 | 54.98 | 42.24 | 44.81 | 48.39 |'
  id: totrans-436
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-FS-EN | 51.51 | 54.98 | 42.24 | 44.81 | 48.39 |'
- en: '| Average ASR over attacks | 40.61 | 48.34 | 40.45 | 47.23 | N/A |'
  id: totrans-437
  prefs: []
  type: TYPE_TB
  zh: '| 攻击的平均ASR | 40.61 | 48.34 | 40.45 | 47.23 | 不适用 |'
- en: '| GPT-3.5 | AdvGLUE | 33.05 | 31.22 | 35.28 | 32.61 | 33.04 |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 | AdvGLUE | 33.05 | 31.22 | 35.28 | 32.61 | 33.04 |'
- en: '| AdvGLUE++ | 4.95 | 4.65 | 5.98 | 5.37 | 5.24 |'
  id: totrans-439
  prefs: []
  type: TYPE_TB
  zh: '| AdvGLUE++ | 4.95 | 4.65 | 5.98 | 5.37 | 5.24 |'
- en: '| PromptAttack-EN | 56.67 | 57.27 | 54.71 | 55.34 | 56.00 |'
  id: totrans-440
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-EN | 56.67 | 57.27 | 54.71 | 55.34 | 56.00 |'
- en: '| PromptAttack-FS-EN | 76.98 | 77.74 | 71.62 | 74.59 | 75.23 |'
  id: totrans-441
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-FS-EN | 76.98 | 77.74 | 71.62 | 74.59 | 75.23 |'
- en: '| Average ASR over attacks | 43.03 | 42.65 | 41.81 | 41.98 | N/A |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
  zh: '| 攻击的平均ASR | 43.03 | 42.65 | 41.81 | 41.98 | 不适用 |'
- en: 'B.4 Standard Deviation of the ASR Reported in Table [3](#S4.T3 "Table 3 ‣ Victim
    LLMs ‣ 4 Experiments ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack")'
  id: totrans-443
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.4 表 [3](#S4.T3 "表 3 ‣ 受害者LLM ‣ 4 实验 ‣ LLM可以自我欺骗：基于提示的对抗攻击")中报告的ASR标准差
- en: 'Table [10](#A2.T10 "Table 10 ‣ B.3 ASR without Fidelity Filter ‣ Appendix B
    Extensive Experimental Results ‣ An LLM can Fool Itself: A Prompt-Based Adversarial
    Attack") demonstrates the standard deviation of the ASR reported in Table [3](#S4.T3
    "Table 3 ‣ Victim LLMs ‣ 4 Experiments ‣ An LLM can Fool Itself: A Prompt-Based
    Adversarial Attack"). We find that the standard deviation of the ASR evaluated
    using Llama2 is extremely high in some tasks such as MNLI-mm and QNLI. The reason
    is that the ASR evaluated via zero-shot task descriptions and the ASR evaluated
    via few-shot task descriptions are extremely divergent achieved by Llama2 in MNLI-mm
    and QNLI tasks (as shown in Table [5](#S4.T5 "Table 5 ‣ The ASR of PromptAttack-FS-EN
    is sensitive to the LLM’s comprehension ability. ‣ 4.1 Robustness Evaluation on
    GLUE Dataset ‣ 4 Experiments ‣ An LLM can Fool Itself: A Prompt-Based Adversarial
    Attack") and [15](#A2.T15 "Table 15 ‣ B.5 ASR Evaluated via Different Types of
    Task Descriptions ‣ Appendix B Extensive Experimental Results ‣ An LLM can Fool
    Itself: A Prompt-Based Adversarial Attack")), which makes the standard deviation
    of the ASR evaluated using Llama2 is significantly high.'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [10](#A2.T10 "表 10 ‣ B.3 ASR 无忠实度过滤 ‣ 附录 B 广泛实验结果 ‣ 一个 LLM 可以自我欺骗：基于提示的对抗攻击")
    显示了表 [3](#S4.T3 "表 3 ‣ 受害 LLM ‣ 4 实验 ‣ 一个 LLM 可以自我欺骗：基于提示的对抗攻击") 中报告的 ASR 的标准差。我们发现，使用
    Llama2 评估的 ASR 在某些任务中，如 MNLI-mm 和 QNLI，非常高。原因是通过零样本任务描述评估的 ASR 和通过少样本任务描述评估的 ASR
    在 MNLI-mm 和 QNLI 任务中由 Llama2 实现的结果差异极大（如表 [5](#S4.T5 "表 5 ‣ PromptAttack-FS-EN
    的 ASR 对 LLM 的理解能力很敏感 ‣ 4.1 GLUE 数据集的鲁棒性评估 ‣ 4 实验 ‣ 一个 LLM 可以自我欺骗：基于提示的对抗攻击") 和 [15](#A2.T15
    "表 15 ‣ B.5 通过不同类型的任务描述评估的 ASR ‣ 附录 B 广泛实验结果 ‣ 一个 LLM 可以自我欺骗：基于提示的对抗攻击"))，这使得使用
    Llama2 评估的 ASR 的标准差显著增加。
- en: 'Table 12: Robustness evaluation in the QQP task via different types of task
    descriptions.'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: '表 12: 通过不同类型的任务描述在 QQP 任务中的鲁棒性评估。'
- en: '| Task description | ZS-TO | ZS-RO | FS-TO | FS-RO | Avg |'
  id: totrans-446
  prefs: []
  type: TYPE_TB
  zh: '| 任务描述 | ZS-TO | ZS-RO | FS-TO | FS-RO | 平均 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-447
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Llama2-7B | AdvGLUE | 1.11 | 12.83 | 4.64 | 16.07 | 8.66 |'
  id: totrans-448
  prefs: []
  type: TYPE_TB
  zh: '| Llama2-7B | AdvGLUE | 1.11 | 12.83 | 4.64 | 16.07 | 8.66 |'
- en: '| AdvGLUE++ | 0.73 | 5.53 | 2.55 | 6.62 | 3.86 |'
  id: totrans-449
  prefs: []
  type: TYPE_TB
  zh: '| AdvGLUE++ | 0.73 | 5.53 | 2.55 | 6.62 | 3.86 |'
- en: '| PromptAttack-EN | 7.46 | 31.75 | 17.24 | 38.61 | 23.77 |'
  id: totrans-450
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-EN | 7.46 | 31.75 | 17.24 | 38.61 | 23.77 |'
- en: '| PromptAttack-FS-EN | 4.87 | 27.53 | 11.87 | 24.97 | 17.31 |'
  id: totrans-451
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-FS-EN | 4.87 | 27.53 | 11.87 | 24.97 | 17.31 |'
- en: '| Average ASR over tasks | 3.54 | 19.41 | 9.08 | 21.57 | N/A |'
  id: totrans-452
  prefs: []
  type: TYPE_TB
  zh: '| 任务的平均 ASR | 3.54 | 19.41 | 9.08 | 21.57 | 不适用 |'
- en: '| GPT-3.5 | AdvGLUE | 8.98 | 13.41 | 16.86 | 19.78 | 14.76 |'
  id: totrans-453
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 | AdvGLUE | 8.98 | 13.41 | 16.86 | 19.78 | 14.76 |'
- en: '| AdvGLUE++ | 10.41 | 10.38 | 7.32 | 6.61 | 8.68 |'
  id: totrans-454
  prefs: []
  type: TYPE_TB
  zh: '| AdvGLUE++ | 10.41 | 10.38 | 7.32 | 6.61 | 8.68 |'
- en: '| PromptAttack-EN | 34.06 | 37.74 | 41.45 | 34.87 | 37.03 |'
  id: totrans-455
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-EN | 34.06 | 37.74 | 41.45 | 34.87 | 37.03 |'
- en: '| PromptAttack-FS-EN | 35.19 | 40.28 | 45.46 | 37.50 | 39.61 |'
  id: totrans-456
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-FS-EN | 35.19 | 40.28 | 45.46 | 37.50 | 39.61 |'
- en: '| Average ASR over tasks | 22.15 | 25.45 | 27.70 | 24.69 | N/A |'
  id: totrans-457
  prefs: []
  type: TYPE_TB
  zh: '| 任务的平均 ASR | 22.15 | 25.45 | 27.70 | 24.69 | 不适用 |'
- en: B.5 ASR Evaluated via Different Types of Task Descriptions
  id: totrans-458
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.5 通过不同类型的任务描述评估的 ASR
- en: 'Tables [11](#A2.T11 "Table 11 ‣ B.3 ASR without Fidelity Filter ‣ Appendix
    B Extensive Experimental Results ‣ An LLM can Fool Itself: A Prompt-Based Adversarial
    Attack")–[15](#A2.T15 "Table 15 ‣ B.5 ASR Evaluated via Different Types of Task
    Descriptions ‣ Appendix B Extensive Experimental Results ‣ An LLM can Fool Itself:
    A Prompt-Based Adversarial Attack") demonstrate the ASR evaluated via different
    types of task descriptions in various tasks. The results show that the ASR via
    zero-shot (ZS) task descriptions is lower than few-shot (FS) task descriptions
    using GPT-3.5 in most tasks, which is in line with the conclusion of Zhu et al.
    ([2023](#bib.bib66)). However, an interesting phenomenon is that the ASR via ZS
    task descriptions is always lower than FS task descriptions using Llama2\. We
    guess that it is because the ability of small-scale LLM Llama2 to understand the
    few-shot examples is worse than that of large-scale LLM GPT-3.5\. The extra examples
    provided in the FS task descriptions can confuse Llama2 on how to solve the task,
    thus degrading the performance of Llama2 when using FS inference (Logan IV et al.,
    [2021](#bib.bib30)).'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 表[11](#A2.T11 "表 11 ‣ B.3 无忠实度过滤的 ASR ‣ 附录 B 大量实验结果 ‣ 大型语言模型可以欺骗自己：基于提示的对抗攻击")–[15](#A2.T15
    "表 15 ‣ B.5 通过不同类型的任务描述评估的 ASR ‣ 附录 B 大量实验结果 ‣ 大型语言模型可以欺骗自己：基于提示的对抗攻击")展示了在不同任务中通过不同类型的任务描述评估的
    ASR。结果表明，在大多数任务中，通过零样本（ZS）任务描述的 ASR 低于使用 GPT-3.5 的少样本（FS）任务描述，这与Zhu等人（[2023](#bib.bib66)）的结论一致。然而，一个有趣的现象是，通过
    ZS 任务描述的 ASR 始终低于使用 Llama2 的 FS 任务描述。我们猜测这是因为小规模语言模型 Llama2 理解少样本示例的能力不如大规模语言模型
    GPT-3.5。FS 任务描述中提供的额外示例可能会让 Llama2 对如何解决任务感到困惑，从而在使用 FS 推理时降低 Llama2 的表现（Logan
    IV 等，[2021](#bib.bib30)）。
- en: 'Table 13: Robustness evaluation in the MNLI-m task via different types of task
    descriptions.'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 表13：通过不同类型的任务描述在 MNLI-m 任务中的鲁棒性评估。
- en: '| Task description | ZS-TO | ZS-RO | FS-TO | FS-RO | Avg |'
  id: totrans-461
  prefs: []
  type: TYPE_TB
  zh: '| 任务描述 | ZS-TO | ZS-RO | FS-TO | FS-RO | 平均 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-462
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Llama2-7B | AdvGLUE | 35.44 | 46.25 | 90.28 | 77.02 | 62.25 |'
  id: totrans-463
  prefs: []
  type: TYPE_TB
  zh: '| Llama2-7B | AdvGLUE | 35.44 | 46.25 | 90.28 | 77.02 | 62.25 |'
- en: '| AdvGLUE++ | 0.72 | 0.71 | 14.13 | 13.22 | 15.50 |'
  id: totrans-464
  prefs: []
  type: TYPE_TB
  zh: '| AdvGLUE++ | 0.72 | 0.71 | 14.13 | 13.22 | 15.50 |'
- en: '| PromptAttack-EN | 51.76 | 48.35 | 78.58 | 73.80 | 63.12 |'
  id: totrans-465
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-EN | 51.76 | 48.35 | 78.58 | 73.80 | 63.12 |'
- en: '| PromptAttack-FS-EN | 38.22 | 40.15 | 69.85 | 63.44 | 52.91 |'
  id: totrans-466
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-FS-EN | 38.22 | 40.15 | 69.85 | 63.44 | 52.91 |'
- en: '| Average ASR over tasks | 31.54 | 33.87 | 60.71 | 56.87 | N/A |'
  id: totrans-467
  prefs: []
  type: TYPE_TB
  zh: '| 任务的平均 ASR | 31.54 | 33.87 | 60.71 | 56.87 | N/A |'
- en: '| GPT-3.5 | AdvGLUE | 24.82 | 24.53 | 25.82 | 26.04 | 25.30 |'
  id: totrans-468
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 | AdvGLUE | 24.82 | 24.53 | 25.82 | 26.04 | 25.30 |'
- en: '| AdvGLUE++ | 4.17 | 4.25 | 5.48 | 5.91 | 6.73 |'
  id: totrans-469
  prefs: []
  type: TYPE_TB
  zh: '| AdvGLUE++ | 4.17 | 4.25 | 5.48 | 5.91 | 6.73 |'
- en: '| PromptAttack-EN | 50.12 | 47.97 | 39.40 | 38.50 | 44.00 |'
  id: totrans-470
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-EN | 50.12 | 47.97 | 39.40 | 38.50 | 44.00 |'
- en: '| PromptAttack-FS-EN | 62.41 | 61.09 | 51.79 | 50.41 | 45.97 |'
  id: totrans-471
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-FS-EN | 62.41 | 61.09 | 51.79 | 50.41 | 45.97 |'
- en: '| Average ASR over attacks | 35.38 | 34.46 | 30.62 | 30.21 | N/A |'
  id: totrans-472
  prefs: []
  type: TYPE_TB
  zh: '| 攻击的平均 ASR | 35.38 | 34.46 | 30.62 | 30.21 | N/A |'
- en: 'Table 14: Robustness evaluation in the RTE task via different types of task
    descriptions.'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 表14：通过不同类型的任务描述在 RTE 任务中的鲁棒性评估。
- en: '| Task description | ZS-TO | ZS-RO | FS-TO | FS-RO | Avg |'
  id: totrans-474
  prefs: []
  type: TYPE_TB
  zh: '| 任务描述 | ZS-TO | ZS-RO | FS-TO | FS-RO | 平均 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-475
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Llama2-7B | AdvGLUE | 12.90 | 7.04 | 27.62 | 8.14 | 13.92 |'
  id: totrans-476
  prefs: []
  type: TYPE_TB
  zh: '| Llama2-7B | AdvGLUE | 12.90 | 7.04 | 27.62 | 8.14 | 13.92 |'
- en: '| AdvGLUE++ | 1.32 | 1.02 | 3.05 | 1.14 | 1.63 |'
  id: totrans-477
  prefs: []
  type: TYPE_TB
  zh: '| AdvGLUE++ | 1.32 | 1.02 | 3.05 | 1.14 | 1.63 |'
- en: '| PromptAttack-EN | 30.74 | 18.78 | 52.12 | 37.51 | 34.79 |'
  id: totrans-478
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-EN | 30.74 | 18.78 | 52.12 | 37.51 | 34.79 |'
- en: '| PromptAttack-FS-EN | 22.15 | 14.45 | 41.18 | 23.94 | 25.43 |'
  id: totrans-479
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-FS-EN | 22.15 | 14.45 | 41.18 | 23.94 | 25.43 |'
- en: '| Average ASR over attacks | 16.78 | 10.32 | 30.97 | 17.68 | N/A |'
  id: totrans-480
  prefs: []
  type: TYPE_TB
  zh: '| 攻击的平均 ASR | 16.78 | 10.32 | 30.97 | 17.68 | N/A |'
- en: '| GPT-3.5 | AdvGLUE | 22.12 | 24.71 | 21.07 | 24.59 | 23.12 |'
  id: totrans-481
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 | AdvGLUE | 22.12 | 24.71 | 21.07 | 24.59 | 23.12 |'
- en: '| AdvGLUE++ | 4.02 | 3.91 | 4.35 | 4.40 | 4.17 |'
  id: totrans-482
  prefs: []
  type: TYPE_TB
  zh: '| AdvGLUE++ | 4.02 | 3.91 | 4.35 | 4.40 | 4.17 |'
- en: '| PromptAttack-EN | 38.87 | 30.84 | 36.63 | 30.86 | 34.30 |'
  id: totrans-483
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-EN | 38.87 | 30.84 | 36.63 | 30.86 | 34.30 |'
- en: '| PromptAttack-FS-EN | 40.61 | 32.42 | 38.27 | 33.17 | 36.12 |'
  id: totrans-484
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-FS-EN | 40.61 | 32.42 | 38.27 | 33.17 | 36.12 |'
- en: '| Average ASR over attacks | 26.41 | 22.93 | 25.08 | 23.26 | N/A |'
  id: totrans-485
  prefs: []
  type: TYPE_TB
  zh: '| 攻击的平均 ASR | 26.41 | 22.93 | 25.08 | 23.26 | N/A |'
- en: 'Table 15: Robustness evaluation in the QNLI task via different types of task
    descriptions.'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 表15：通过不同类型的任务描述在 QNLI 任务中的鲁棒性评估。
- en: '| Task description | ZS-TO | ZS-RO | FS-TO | FS-RO | Avg |'
  id: totrans-487
  prefs: []
  type: TYPE_TB
  zh: '| 任务描述 | ZS-TO | ZS-RO | FS-TO | FS-RO | 平均 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-488
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Llama2-7B | AdvGLUE | 7.21 | 7.73 | 58.03 | 52.70 | 31.42 |'
  id: totrans-489
  prefs: []
  type: TYPE_TB
  zh: '| Llama2-7B | AdvGLUE | 7.21 | 7.73 | 58.03 | 52.70 | 31.42 |'
- en: '| AdvGLUE++ | 0.72 | 0.71 | 14.13 | 13.22 | 7.19 |'
  id: totrans-490
  prefs: []
  type: TYPE_TB
  zh: '| AdvGLUE++ | 0.72 | 0.71 | 14.13 | 13.22 | 7.19 |'
- en: '| PromptAttack-EN | 5.23 | 6.81 | 87.77 | 82.68 | 45.62 |'
  id: totrans-491
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-EN | 5.23 | 6.81 | 87.77 | 82.68 | 45.62 |'
- en: '| PromptAttack-FS-EN | 4.54 | 5.87 | 78.27 | 71.85 | 40.13 |'
  id: totrans-492
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-FS-EN | 4.54 | 5.87 | 78.27 | 71.85 | 40.13 |'
- en: '| Average ASR over attacks | 4.43 | 5.16 | 59.55 | 53.29 | N/A |'
  id: totrans-493
  prefs: []
  type: TYPE_TB
  zh: '| 攻击的平均 ASR | 4.43 | 5.16 | 59.55 | 53.29 | 不适用 |'
- en: '| GPT-3.5 | AdvGLUE | 24.16 | 17.55 | 23.51 | 22.88 | 22.03 |'
  id: totrans-494
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 | AdvGLUE | 24.16 | 17.55 | 23.51 | 22.88 | 22.03 |'
- en: '| AdvGLUE++ | 4.17 | 4.25 | 5.48 | 5.91 | 4.95 |'
  id: totrans-495
  prefs: []
  type: TYPE_TB
  zh: '| AdvGLUE++ | 4.17 | 4.25 | 5.48 | 5.91 | 4.95 |'
- en: '| PromptAttack-EN | 40.09 | 35.67 | 43.23 | 42.58 | 40.39 |'
  id: totrans-496
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-EN | 40.09 | 35.67 | 43.23 | 42.58 | 40.39 |'
- en: '| PromptAttack-FS-EN | 50.20 | 43.81 | 51.99 | 49.98 | 49.00 |'
  id: totrans-497
  prefs: []
  type: TYPE_TB
  zh: '| PromptAttack-FS-EN | 50.20 | 43.81 | 51.99 | 49.98 | 49.00 |'
- en: '| Average ASR over attacks | 29.68 | 25.32 | 31.05 | 30.34 | N/A |'
  id: totrans-498
  prefs: []
  type: TYPE_TB
  zh: '| 攻击的平均 ASR | 29.68 | 25.32 | 31.05 | 30.34 | 不适用 |'
- en: B.6 Attack Transferability
  id: totrans-499
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.6 攻击的可转移性
- en: Experimental details.
  id: totrans-500
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 实验细节。
- en: 'In Table [6](#S4.T6 "Table 6 ‣ Attack transferability. ‣ 4.2 Extensive Empirical
    Results ‣ 4 Experiments ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack"),
    we first generated adversarial samples against GPT-3.5 by PromptAttack-FS-EN and
    then transferred them to attack Llama2-7B and Llama2-13B. In Table [7](#S4.T7
    "Table 7 ‣ Attack transferability. ‣ 4.2 Extensive Empirical Results ‣ 4 Experiments
    ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack"), we first generated
    adversarial samples against Llama2-7B by PromptAttack-EN and then transferred
    them to attack Llama2-13B and GPT-3.5\. In Tables [6](#S4.T6 "Table 6 ‣ Attack
    transferability. ‣ 4.2 Extensive Empirical Results ‣ 4 Experiments ‣ An LLM can
    Fool Itself: A Prompt-Based Adversarial Attack") and [7](#S4.T7 "Table 7 ‣ Attack
    transferability. ‣ 4.2 Extensive Empirical Results ‣ 4 Experiments ‣ An LLM can
    Fool Itself: A Prompt-Based Adversarial Attack"), we report the ASR (%) of adversarial
    samples evaluated using each LLM.'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: '在表[6](#S4.T6 "Table 6 ‣ Attack transferability. ‣ 4.2 Extensive Empirical Results
    ‣ 4 Experiments ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack")中，我们首先通过
    PromptAttack-FS-EN 生成了对 GPT-3.5 的对抗样本，然后将这些样本转移至 Llama2-7B 和 Llama2-13B 进行攻击。在表[7](#S4.T7
    "Table 7 ‣ Attack transferability. ‣ 4.2 Extensive Empirical Results ‣ 4 Experiments
    ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack")中，我们首先通过 PromptAttack-EN
    生成了对 Llama2-7B 的对抗样本，然后将这些样本转移至 Llama2-13B 和 GPT-3.5 进行攻击。在表[6](#S4.T6 "Table
    6 ‣ Attack transferability. ‣ 4.2 Extensive Empirical Results ‣ 4 Experiments
    ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack")和[7](#S4.T7 "Table
    7 ‣ Attack transferability. ‣ 4.2 Extensive Empirical Results ‣ 4 Experiments
    ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack")中，我们报告了使用每个 LLM 评估的对抗样本的
    ASR (%)。'
- en: 'Moreover, in Table [16](#A2.T16 "Table 16 ‣ Extensive analyses. ‣ B.6 Attack
    Transferability ‣ Appendix B Extensive Experimental Results ‣ An LLM can Fool
    Itself: A Prompt-Based Adversarial Attack"), we demonstrate the ASR of adversarial
    samples generated by PromptAttack against Llama2-7B and GPT-3.5 evaluated using
    BERT-based models. We used pre-trained BERT encoders with the version “bert-base-uncased”
    and pre-trained RoBERTa encoders with the version “roberta-base”. For each task,
    the standard model is obtained by standardly fine-tuning a composition of a pre-trained
    encoder and a classifier in the training dataset of the task; the robust model
    is obtained by adversarially fine-tuning a composition of a pre-trained encoder
    and a classifier in the training dataset of the task. We used the [official code](https://github.com/zhuchen03/FreeLB)
    of FreeLB (Zhu et al., [2019](#bib.bib65)) to implement the fine-tuning of BERT-based
    models.'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: '此外，在表[16](#A2.T16 "Table 16 ‣ Extensive analyses. ‣ B.6 Attack Transferability
    ‣ Appendix B Extensive Experimental Results ‣ An LLM can Fool Itself: A Prompt-Based
    Adversarial Attack")中，我们展示了 PromptAttack 生成的对抗样本在 Llama2-7B 和 GPT-3.5 上的 ASR，这些样本使用
    BERT 基础模型进行评估。我们使用了版本为“bert-base-uncased”的预训练 BERT 编码器和版本为“roberta-base”的预训练 RoBERTa
    编码器。对于每个任务，标准模型通过对预训练编码器和分类器的组合进行标准微调以获取，稳健模型则通过对预训练编码器和分类器的组合进行对抗性微调以获得。我们使用了
    [FreeLB 的官方代码](https://github.com/zhuchen03/FreeLB)（Zhu 等人，[2019](#bib.bib65)）来实现
    BERT 基础模型的微调。'
- en: Note that, we also leveraged the ensemble strategy during the robustness evaluation
    of attack transferability. To be specific, for each data point , PromptAttack
    according to different perturbation instructions against the victim LLM can generate
    nine adversarial variants . Then, while transferring them to attack another victim
    language model, we traversed all the adversarial variants from  to , and took
    the sample that can successfully fool the victim language model and has the highest
    BERTScore for calculating the ASR achieved by the victim language model; otherwise,
    we took the original sample for calculating the ASR.
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在攻击转移性鲁棒性评估过程中，我们还采用了集成策略。具体而言，对于每个数据点，PromptAttack根据不同的扰动指令生成九种对抗变体。然后，在将它们转移到攻击另一个受害者语言模型时，我们遍历了从到的所有对抗变体，并选择能成功欺骗受害者语言模型且具有最高BERTScore的样本来计算受害者语言模型的ASR；否则，我们选择原始样本来计算ASR。
- en: Extensive analyses.
  id: totrans-504
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 大规模分析。
- en: We observe that BERT-based models are also vulnerable to transferable PromptAttack.
    In particular, the results validate that adversarial training (Zhu et al., [2019](#bib.bib65);
    Madry et al., [2018](#bib.bib31)) is effective in enhancing the adversarial robustness
    since the robust BERT-based models always yield a lower ASR than standard BERT-based
    models. It inspires us to utilize the adversarial training to adversarially fine-tune
    LLMs so that defend LLMs against adversarial attacks in downstream tasks.
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 我们观察到基于BERT的模型也容易受到可转移的PromptAttack攻击。具体而言，结果验证了对抗训练 (Zhu et al., [2019](#bib.bib65);
    Madry et al., [2018](#bib.bib31)) 在增强对抗鲁棒性方面的有效性，因为鲁棒的BERT模型的ASR通常低于标准BERT模型。这激励我们利用对抗训练来对LLMs进行对抗微调，以便在下游任务中防御对抗攻击。
- en: 'Besides, we find that the ASR achieved by BERT-based models (shown in Table [16](#A2.T16
    "Table 16 ‣ Extensive analyses. ‣ B.6 Attack Transferability ‣ Appendix B Extensive
    Experimental Results ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack"))
    is lower than that achieved by LLMs such as GPT-3.5 (shown in Table [3](#S4.T3
    "Table 3 ‣ Victim LLMs ‣ 4 Experiments ‣ An LLM can Fool Itself: A Prompt-Based
    Adversarial Attack")), which seems to show that BERT-based models gain better
    robustness against adversarial samples. The main reason could be that BERT-based
    models are fine-tuned on the training set of each downstream task, which substantially
    improves their generalization ability and adversarial robustness in the downstream
    task; whereas, LLMs perform the task based on the prompt without being fine-tuned,
    which degrades their performance in downstream tasks despite having a large number
    of parameters.'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: '此外，我们发现BERT模型所获得的ASR（见表[16](#A2.T16 "Table 16 ‣ Extensive analyses. ‣ B.6 Attack
    Transferability ‣ Appendix B Extensive Experimental Results ‣ An LLM can Fool
    Itself: A Prompt-Based Adversarial Attack")）低于GPT-3.5等LLMs（见表[3](#S4.T3 "Table
    3 ‣ Victim LLMs ‣ 4 Experiments ‣ An LLM can Fool Itself: A Prompt-Based Adversarial
    Attack")）所获得的ASR，这似乎表明BERT模型在对抗样本方面具有更好的鲁棒性。主要原因可能是BERT模型在每个下游任务的训练集上进行微调，这显著提高了它们在下游任务中的泛化能力和对抗鲁棒性；而LLMs则基于提示执行任务而未进行微调，这降低了它们在下游任务中的表现，尽管参数数量庞大。'
- en: 'Table 16: Attack transferability of PromptAttack from Llama2-7B and GPT-3.5
    to BERT-based models, respectively.'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 表16：PromptAttack从Llama2-7B和GPT-3.5到BERT模型的攻击转移性。
- en: '| Task | PromptAttack against Llama2-7B | PromptAttack against GPT-3.5 |'
  id: totrans-508
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | PromptAttack对Llama2-7B的攻击 | PromptAttack对GPT-3.5的攻击 |'
- en: '|'
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Standard &#124;'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Standard &#124;'
- en: '&#124; BERT &#124;'
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; BERT &#124;'
- en: '|'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Robust &#124;'
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Robust &#124;'
- en: '&#124; BERT &#124;'
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; BERT &#124;'
- en: '|'
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Standard &#124;'
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Standard &#124;'
- en: '&#124; RoBERTa &#124;'
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RoBERTa &#124;'
- en: '|'
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Robust &#124;'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Robust &#124;'
- en: '&#124; RoBERTa &#124;'
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RoBERTa &#124;'
- en: '|'
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Standard &#124;'
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Standard &#124;'
- en: '&#124; BERT &#124;'
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; BERT &#124;'
- en: '|'
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Robust &#124;'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Robust &#124;'
- en: '&#124; BERT &#124;'
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; BERT &#124;'
- en: '|'
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Standard &#124;'
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Standard &#124;'
- en: '&#124; RoBERTa &#124;'
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RoBERTa &#124;'
- en: '|'
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Robust &#124;'
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Robust &#124;'
- en: '&#124; RoBERTa &#124;'
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RoBERTa &#124;'
- en: '|'
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| SST-2 | 52.75 | 48.03 | 50.35 | 50.35 | 78.42 | 73.96 | 74.85 | 74.85 |'
  id: totrans-534
  prefs: []
  type: TYPE_TB
  zh: '| SST-2 | 52.75 | 48.03 | 50.35 | 50.35 | 78.42 | 73.96 | 74.85 | 74.85 |'
- en: '| QQP | 26.22 | 24.25 | 23.70 | 25.36 | 32.91 | 31.85 | 28.47 | 28.47 |'
  id: totrans-535
  prefs: []
  type: TYPE_TB
  zh: '| QQP | 26.22 | 24.25 | 23.70 | 25.36 | 32.91 | 31.85 | 28.47 | 28.47 |'
- en: '| MNLI-m | 23.29 | 21.51 | 19.77 | 17.43 | 24.16 | 21.61 | 22.39 | 20.67 |'
  id: totrans-536
  prefs: []
  type: TYPE_TB
  zh: '| MNLI-m | 23.29 | 21.51 | 19.77 | 17.43 | 24.16 | 21.61 | 22.39 | 20.67 |'
- en: '| MNLI-mm | 23.64 | 20.23 | 22.61 | 23.46 | 22.39 | 20.46 | 19.61 | 18.91 |'
  id: totrans-537
  prefs: []
  type: TYPE_TB
  zh: '| MNLI-mm | 23.64 | 20.23 | 22.61 | 23.46 | 22.39 | 20.46 | 19.61 | 18.91 |'
- en: '| RTE | 29.65 | 23.35 | 22.55 | 21.76 | 33.33 | 33.33 | 33.33 | 33.03 |'
  id: totrans-538
  prefs: []
  type: TYPE_TB
  zh: '| RTE | 29.65 | 23.35 | 22.55 | 21.76 | 33.33 | 33.33 | 33.33 | 33.03 |'
- en: '| QNLI | 15.24 | 10.07 | 12.95 | 10.39 | 30.11 | 26.91 | 26.91 | 26.05 |'
  id: totrans-539
  prefs: []
  type: TYPE_TB
  zh: '| QNLI | 15.24 | 10.07 | 12.95 | 10.39 | 30.11 | 26.91 | 26.91 | 26.05 |'
- en: '| Avg | 28.47 | 24.58 | 25.32 | 24.79 | 36.89 | 34.69 | 34.26 | 33.66 |'
  id: totrans-540
  prefs: []
  type: TYPE_TB
  zh: '| 平均 | 28.47 | 24.58 | 25.32 | 24.79 | 36.89 | 34.69 | 34.26 | 33.66 |'
- en: 'Table 17: Extensive examples of the adversarial samples generated by PromptAttack
    against GPT-3.5 in the SST-2 task (Socher et al., [2013](#bib.bib48)). The results
    can be reproduced by setting the version of GPT-3.5 as “gpt-3.5-turbo-0301” and
    the temperature as , and using the task description “Evaluate the sentiment of
    the given text and classify it as ‘positive’ or ‘negative’: Sentence: sample Answer:”.'
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 表17：在SST-2任务中，PromptAttack针对GPT-3.5生成的对抗样本的广泛示例（Socher等，[2013](#bib.bib48)）。通过将GPT-3.5的版本设置为“gpt-3.5-turbo-0301”和温度设置为，并使用任务描述“评估给定文本的情感，并将其分类为‘正面’或‘负面’：句子：样本
    答案：”可以重现结果。
- en: '|'
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Perturbation &#124;'
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 干扰&#124;'
- en: '&#124; level &#124;'
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 级别&#124;'
- en: '| sample |'
  id: totrans-545
  prefs: []
  type: TYPE_TB
  zh: '| 样本 |'
- en: '&#124; Label  &#124;'
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 标签&#124;'
- en: '&#124; Prediction &#124;'
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 预测&#124;'
- en: '|'
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| --- | --- | --- |'
  id: totrans-549
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '|'
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Character &#124;'
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 角色&#124;'
- en: '&#124; (*C1*) &#124;'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (*C1*) &#124;'
- en: '|'
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Original: less dizzying than just dizzy, the jaunt is practically &#124;'
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原文：比起单纯的眩晕，这段旅行几乎是&#124;'
- en: '&#124; over before it begins. &#124;'
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 在开始之前就结束了。&#124;'
- en: '&#124; Adversarial: less dizzying than just dizxzy, the jaunt is practically
    &#124;'
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对抗性：比起单纯的眩晕，这段旅行几乎是&#124;'
- en: '&#124; over before it begins. &#124;'
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 在开始之前就结束了。&#124;'
- en: '|'
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; negative  &#124;'
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 负面&#124;'
- en: '&#124; positive &#124;'
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 正面&#124;'
- en: '|'
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Character &#124;'
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 角色&#124;'
- en: '&#124; (*C3*) &#124;'
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (*C3*) &#124;'
- en: '|'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Original: if you believe any of this, i can make you a real deal &#124;'
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原文：如果你相信这些，我可以给你一个真正的交易&#124;'
- en: '&#124; on leftover enron stock that will double in value a week from friday.
    &#124;'
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 关于剩余的安然股票，一周后的星期五将会翻倍的价值。&#124;'
- en: '&#124; Adversarial: if you believe any of this, i can make you a real deal
    &#124;'
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对抗性：如果你相信这些，我可以给你一个真正的交易&#124;'
- en: '&#124; on leftover enron stock that will double in value a week from friday.
    :) &#124;'
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 关于剩余的安然股票，一周后的星期五将会翻倍的价值。:)&#124;'
- en: '|'
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; negative  &#124;'
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 负面&#124;'
- en: '&#124; positive &#124;'
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 正面&#124;'
- en: '|'
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Word &#124;'
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 单词&#124;'
- en: '&#124; (*W2*) &#124;'
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (*W2*) &#124;'
- en: '|'
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Original: if you believe any of this, i can make you a real deal on
    &#124;'
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原文：如果你相信这些，我可以给你一个真正的交易&#124;'
- en: '&#124; leftover enron stock that will double in value a week from friday. &#124;'
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 关于剩余的安然股票，一周后的星期五将会翻倍的价值。&#124;'
- en: '&#124; Adversarial: if you believe any of this, i can make you a real deal
    &#124;'
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对抗性：如果你相信这些，我可以给你一个真正的交易&#124;'
- en: '&#124; on leftover enron stock that will double in value a week from friday.
    &#124;'
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 关于剩余的安然股票，一周后的星期五将会翻倍的价值。&#124;'
- en: '|'
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; negative  &#124;'
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 负面&#124;'
- en: '&#124; positive &#124;'
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 正面&#124;'
- en: '|'
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Word &#124;'
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 单词&#124;'
- en: '&#124; (*W3*) &#124;'
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (*W3*) &#124;'
- en: '|'
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Original: when leguizamo finally plugged an irritating character &#124;'
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原文：当Leguizamo最终给一个令人烦恼的角色&#124;'
- en: '&#124; late in the movie. &#124;'
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 电影中的晚期。&#124;'
- en: '&#124; Adversarial: when leguizamo finally effectively plugged an irritating
    &#124;'
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对抗性：当Leguizamo最终有效地处理一个令人烦恼的&#124;'
- en: '&#124; character late in the movie. &#124;'
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 电影中的角色。&#124;'
- en: '|'
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; negative  &#124;'
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 负面&#124;'
- en: '&#124; positive &#124;'
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 正面&#124;'
- en: '|'
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Sentence &#124;'
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 句子&#124;'
- en: '&#124; (*S2*) &#124;'
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (*S2*) &#124;'
- en: '|'
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Original: green might want to hang onto that ski mask, as robbery &#124;'
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原文：绿色可能想要保留那顶滑雪面罩，因为抢劫&#124;'
- en: '&#124; may be the only way to pay for his next project. &#124;'
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 可能是支付他下一个项目的唯一方式。&#124;'
- en: '&#124; Adversarial: green should consider keeping that ski mask, as it may
    &#124;'
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对抗性：绿色应该考虑保留那顶滑雪面罩，因为它可能&#124;'
- en: '&#124; provide the necessary means to finance his next project. &#124;'
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 提供必要的手段来为他的下一个项目融资。&#124;'
- en: '|'
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; negative  &#124;'
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 负面&#124;'
- en: '&#124; positive &#124;'
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 正面&#124;'
- en: '|'
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Sentence &#124;'
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 句子&#124;'
- en: '&#124; (*S3*) &#124;'
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (*S3*) &#124;'
- en: '|'
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Original: with virtually no interesting elements for an audience to
    &#124;'
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原文：几乎没有引起观众兴趣的元素&#124;'
- en: '&#124; focus on, chelsea walls is a triple-espresso endurance challenge. &#124;'
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 关注，《切尔西墙》是一个三倍浓缩的耐力挑战。&#124;'
- en: '&#124; Adversarial: despite lacking any interesting elements for an &#124;'
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对抗性：尽管缺乏任何引人入胜的元素&#124;'
- en: '&#124; audience to focus on, chelsea walls presents an exhilarating &#124;'
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 观众关注的焦点，《切尔西墙》呈现了令人振奋的&#124;'
- en: '&#124; triple-espresso endurance challenge. &#124;'
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 三倍浓缩咖啡耐力挑战。 &#124;'
- en: '|'
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; negative  &#124;'
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 否定的 &#124;'
- en: '&#124; positive &#124;'
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 积极的 &#124;'
- en: '|'
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 'Table 18: We demonstrate five adversarial samples whose BERTScore is lower
    than 0.85 and their original variants sampled from the RTE task in the AdvGLUE++
    dataset. We can find that, when BERTScore is low, the semantic meaning of the
    adversarial sample and its original version are significantly different.'
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
  zh: '表18: 我们展示了五个对抗样本，其BERTScore低于0.85，它们的原始变体来自于AdvGLUE++数据集中RTE任务的抽样。我们可以发现，当BERTScore较低时，对抗样本与其原始版本的语义意义显著不同。'
- en: '| BERTScore | Example |'
  id: totrans-624
  prefs: []
  type: TYPE_TB
  zh: '| BERTScore | 示例 |'
- en: '| --- | --- |'
  id: totrans-625
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 0.8048 |'
  id: totrans-626
  prefs: []
  type: TYPE_TB
  zh: '| 0.8048 |'
- en: '&#124; Original sentence1: Rock band Phish holds final concert in Vermont.
    &#124;'
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原句1: 摇滚乐队Phish在佛蒙特州举行了最终音乐会。 &#124;'
- en: '&#124; Original sentence2: Phish disbands after a final concert in Vermont
    on Aug. 15 &#124;'
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原句2: Phish在8月15日在佛蒙特州举行了最后一场音乐会后解散 &#124;'
- en: '&#124; Adversarial sentence1: Rock band Pish clasp fial crnceot in green. &#124;'
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对抗性句子1: 摇滚乐队Pish在绿色中举办最终音乐会。 &#124;'
- en: '|'
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| 0.8062 |'
  id: totrans-631
  prefs: []
  type: TYPE_TB
  zh: '| 0.8062 |'
- en: '&#124; Original sentence1: Doctors Without Borders is an international aid
    organization. &#124;'
  id: totrans-632
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原句1: 无国界医生是一个国际援助组织。 &#124;'
- en: '&#124; Original sentence2: The international humanitarian aid organization,
    Doctors &#124;'
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原句2: 国际人道援助组织，医生 &#124;'
- en: '&#124; Without Borders/Medecins Sans Frontieres (MSF), continues to treat victims
    of &#124;'
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 无国界医生/医学救援组织（MSF）继续治疗 &#124;'
- en: '&#124; violence in all locations where it is present in Darfur. &#124;'
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 在达尔富尔的所有地方都存在暴力。 &#124;'
- en: '&#124; Adversarial sentence1: doctors without margin is an external tending
    governance. &#124;'
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对抗性句子1: 没有利润的医生是外部管理的。 &#124;'
- en: '|'
  id: totrans-637
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| 0.8163 |'
  id: totrans-638
  prefs: []
  type: TYPE_TB
  zh: '| 0.8163 |'
- en: '&#124; Original sentence1: Meadows scored a bit part in a January episode of
    “Law &#124;'
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原句1: 梅多斯在一月的《法律与秩序》一集中扮演了一个小角色。 &#124;'
- en: '&#124; & Order”. &#124;'
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; & 订单”。 &#124;'
- en: '&#124; Original sentence2: Meadows appeared in a “Law & Order” episode which
    aired &#124;'
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原句2: 梅多斯出现在一集于 &#124;'
- en: '&#124; in January. &#124;'
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 在一月。 &#124;'
- en: '&#124; Adversarial sentence1: ? added a - special in a september hour of “
    house - order”. &#124;'
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对抗性句子1: ? 添加了一个 - 特殊的在“房子 - 订单”的九月小时。 &#124;'
- en: '|'
  id: totrans-644
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| 0.8292 |'
  id: totrans-645
  prefs: []
  type: TYPE_TB
  zh: '| 0.8292 |'
- en: '&#124; Original sentence1: Blair has sympathy for anyone who has lost their
    lives in Iraq. &#124;'
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原句1: 布莱尔对在伊拉克丧生的人表示同情。 &#124;'
- en: '&#124; Original sentence2: Blair is sympathetic to anyone who has lost their
    lives in Iraq. &#124;'
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原句2: 布莱尔对任何在伊拉克丧生的人表示同情。 &#124;'
- en: '&#124; Adversarial sentence1: tony hs symtaphy for anyone who hour confused
    their &#124;'
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对抗性句子1: 托尼对任何在小时内混淆的人的同情 &#124;'
- en: '&#124; levis in republic. &#124;'
  id: totrans-649
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 共和国中的李维斯。 &#124;'
- en: '|'
  id: totrans-650
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| 0.8294 |'
  id: totrans-651
  prefs: []
  type: TYPE_TB
  zh: '| 0.8294 |'
- en: '&#124; Original sentence1: Euro-Disney is a theme park outside Paris. &#124;'
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原句1: 欧洲迪斯尼是一个位于巴黎郊外的主题公园。 &#124;'
- en: '&#124; Original sentence2: The beleaguered Euro-Disney theme park outside Paris
    is &#124;'
  id: totrans-653
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原句2: 处境艰难的欧洲迪斯尼主题公园位于巴黎郊外， &#124;'
- en: '&#124; doing so poorly it might have to close unless it gets help soon from
    its lenders, &#124;'
  id: totrans-654
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 表现如此糟糕，可能不得不关闭，除非它尽快从贷款方那里获得帮助， &#124;'
- en: '&#124; the chairman of Walt Disney Co. said in an interview published Friday.
    &#124;'
  id: totrans-655
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 沃尔特·迪斯尼公司的董事长在周五发布的采访中表示。 &#124;'
- en: '&#124; Adversarial sentence1: euro-disney is a theme mungo outside genus. &#124;'
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对抗性句子1: 欧洲迪斯尼是一个位于属外的主题公园。 &#124;'
- en: '|'
  id: totrans-657
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 'Table 19: We demonstrate adversarial samples generated by PromptAttack-FS-EN
    against Llama2-7B in various tasks. We can find that the generated content is
    always composed of two sentences connected by a meaningless arrow pattern (“->”),
    following the format of extra examples in the few-shot AG.'
  id: totrans-658
  prefs: []
  type: TYPE_NORMAL
  zh: '表19: 我们展示了PromptAttack-FS-EN生成的对抗样本，这些样本在各种任务中对抗Llama2-7B。我们可以发现，生成的内容总是由两个句子通过一个无意义的箭头模式（“->”）连接，遵循少量示例的格式。'
- en: '| Task | Example |'
  id: totrans-659
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | 示例 |'
- en: '| --- | --- |'
  id: totrans-660
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| SST-2 |'
  id: totrans-661
  prefs: []
  type: TYPE_TB
  zh: '| SST-2 |'
- en: '&#124; Original sentence: too much of the humor falls flat. &#124;'
  id: totrans-662
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原句: 太多的幽默显得平淡无奇。 &#124;'
- en: '&#124; Adversarial sentence: too much of the humor falls flat. -> too much
    of the humor &#124;'
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对抗性句子: 太多的幽默显得平淡无奇。 -> 太多的幽默 &#124;'
- en: '&#124; resonates deeply. @jasdf9 &#124;'
  id: totrans-664
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 深有共鸣。 @jasdf9 &#124;'
- en: '|'
  id: totrans-665
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| QQP |'
  id: totrans-666
  prefs: []
  type: TYPE_TB
  zh: '| QQP |'
- en: '&#124; Original question1: How do you explain current US politics to a child?
    &#124;'
  id: totrans-667
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原问题1: 你如何向孩子解释当前的美国政治？ &#124;'
- en: '&#124; Adversarial question1: How do you explain current US politics to a child?
    -> How &#124;'
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对抗性问题 1：你如何向孩子解释当前的美国政治？ -> 如何 &#124;'
- en: '&#124; do you explain current US politics to a chold? &#124;'
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 你如何向孩子解释当前的美国政治？ &#124;'
- en: '|'
  id: totrans-670
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| MNLI-m |'
  id: totrans-671
  prefs: []
  type: TYPE_TB
  zh: '| MNLI-m |'
- en: '&#124; Original premise: REPORT PREPARATION AND TEST REVIEW &#124;'
  id: totrans-672
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原前提：报告准备与测试回顾 &#124;'
- en: '&#124; Adversarial premise: REPORT PREPARATION AND TEST REVIEW -> REPORT &#124;'
  id: totrans-673
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对抗前提：报告准备与测试回顾 -> 报告 &#124;'
- en: '&#124; PREPARATION AND EXAMINATION REVIEW &#124;'
  id: totrans-674
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 准备与考试回顾 &#124;'
- en: '|'
  id: totrans-675
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| MNLI-mm |'
  id: totrans-676
  prefs: []
  type: TYPE_TB
  zh: '| MNLI-mm |'
- en: '&#124; Original sentence1: The following appears, in bold italics, on page
    8. &#124;'
  id: totrans-677
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原句 1：下列内容以粗体斜体形式出现在第 8 页。 &#124;'
- en: '&#124; Adversarial sentence1: The following appears, in bold italics, on page
    8\. -> The &#124;'
  id: totrans-678
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对抗句子 1：下列内容以粗体斜体形式出现在第 8 页。 -> 该 &#124;'
- en: '&#124; following is prominently displayed in bold italics on page 8 &#124;'
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 下列内容以粗体斜体形式突出显示在第 8 页 &#124;'
- en: '|'
  id: totrans-680
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| RTE |'
  id: totrans-681
  prefs: []
  type: TYPE_TB
  zh: '| RTE |'
- en: '&#124; Original sentence1: The abode of the Greek gods was on the summit of
    Mount &#124;'
  id: totrans-682
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原句 1：希腊众神的居所位于 &#124;'
- en: '&#124; Olympus, in Thessaly. &#124;'
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 奥林匹斯，位于色萨利。 &#124;'
- en: '&#124; Adversarial setence1: The abode of the Greek gods was on the summit
    of Mount &#124;'
  id: totrans-684
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对抗句子 1：希腊众神的居所位于 &#124;'
- en: '&#124; Olympus, in Thessaly. -> The abode of the Greek gods was on the summit
    of Mount &#124;'
  id: totrans-685
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 奥林匹斯，位于色萨利。 -> 希腊众神的居所位于 &#124;'
- en: '&#124; Olympsus, in Thessaly. &#124;'
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 奥林普斯，位于色萨利。 &#124;'
- en: '|'
  id: totrans-687
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| QNLI |'
  id: totrans-688
  prefs: []
  type: TYPE_TB
  zh: '| QNLI |'
- en: '&#124; Original question: What percentage of New Zealand students attended
    private schools &#124;'
  id: totrans-689
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 原问题：新西兰有多少比例的学生上过私立学校？ &#124;'
- en: '&#124; in April 2014? &#124;'
  id: totrans-690
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2014 年 4 月？ &#124;'
- en: '&#124; Adversarial question: What percentage of New Zealand students attended
    private &#124;'
  id: totrans-691
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对抗性问题：新西兰有多少比例的学生上过私立学校？ &#124;'
- en: '&#124; schools in April 2014? -> What proportion of New Zealand students attended
    &#124;'
  id: totrans-692
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2014 年 4 月的学校？ -> 新西兰有多少比例的学生上过 &#124;'
- en: '&#124; private institutions in April 2014? &#124;'
  id: totrans-693
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 2014 年 4 月的私立机构？ &#124;'
- en: '|'
  id: totrans-694
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: B.7 Extensive Examples
  id: totrans-695
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.7 详细示例
- en: Extra examples generated by PromptAttack against GPT-3.5 in the SST-2 task.
  id: totrans-696
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用 PromptAttack 对 GPT-3.5 在 SST-2 任务中生成的额外示例。
- en: 'We provide extensive examples of the adversarial samples generated by PromptAttack
    against GPT-3.5 in the SST-2 task in Table [17](#A2.T17 "Table 17 ‣ Extensive
    analyses. ‣ B.6 Attack Transferability ‣ Appendix B Extensive Experimental Results
    ‣ An LLM can Fool Itself: A Prompt-Based Adversarial Attack"). Our results can
    be reproduced by setting the version of GPT-3.5 as “gpt-3.5-turbo-0301” and the
    temperature as , and using the task description “Evaluate the sentiment of the
    given text and classify it as ‘positive’ or ‘negative’: Sentence: sample Answer:”.'
  id: totrans-697
  prefs: []
  type: TYPE_NORMAL
  zh: '表格 [17](#A2.T17 "Table 17 ‣ Extensive analyses. ‣ B.6 Attack Transferability
    ‣ Appendix B Extensive Experimental Results ‣ An LLM can Fool Itself: A Prompt-Based
    Adversarial Attack") 中提供了 PromptAttack 对 GPT-3.5 在 SST-2 任务中生成的对抗样本的详细示例。我们可以通过将
    GPT-3.5 的版本设置为 “gpt-3.5-turbo-0301” 并将温度设置为，以及使用任务描述 “评估给定文本的情感并将其分类为 ‘正面’ 或 ‘负面’：句子：示例
    回答：” 来重现我们的结果。'
- en: Adversarial samples of low BERTScore.
  id: totrans-698
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 低 BERTScore 的对抗样本。
- en: 'Table [18](#A2.T18 "Table 18 ‣ Extensive analyses. ‣ B.6 Attack Transferability
    ‣ Appendix B Extensive Experimental Results ‣ An LLM can Fool Itself: A Prompt-Based
    Adversarial Attack") demonstrates five adversarial examples whose BERTScore is
    lower than 0.85 sampled from the RTE task in the AdvGLUE++ dataset. We can find
    that the semantic meanings of the adversarial sample and its original version
    are significantly different when BERTScore is low.'
  id: totrans-699
  prefs: []
  type: TYPE_NORMAL
  zh: '表格 [18](#A2.T18 "Table 18 ‣ Extensive analyses. ‣ B.6 Attack Transferability
    ‣ Appendix B Extensive Experimental Results ‣ An LLM can Fool Itself: A Prompt-Based
    Adversarial Attack") 展示了来自 AdvGLUE++ 数据集中 RTE 任务的 BERTScore 低于 0.85 的五个对抗示例。当
    BERTScore 较低时，我们可以发现对抗样本及其原始版本的语义含义有显著不同。'
- en: Adversarial samples generated by PromptAttack-FS-EN using Llama2-7B.
  id: totrans-700
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用 Llama2-7B 通过 PromptAttack-FS-EN 生成的对抗样本。
- en: 'We demonstrate adversarial samples generated by PromptAttack-FS-EN using Llama2-7B
    in Table [19](#A2.T19 "Table 19 ‣ Extensive analyses. ‣ B.6 Attack Transferability
    ‣ Appendix B Extensive Experimental Results ‣ An LLM can Fool Itself: A Prompt-Based
    Adversarial Attack"). We observe that the generated content by Llama2-7B under
    PromptAttack-FS-EN always contains two sentences connected by a meaningless arrow
    pattern (“->”), which exactly follows the format of extra examples in the few-shot
    AG. It indicates that the few-shot strategy can significantly degrade the quality
    of adversarial samples generated by Llama2 which has a poor comprehension ability.
    As a result, the generated adversarial samples are easily recognized as low fidelity
    and filtered out by the fidelity filter, thus leading to a low ASR achieved by
    PromptAttack-FS-EN against Llama2.'
  id: totrans-701
  prefs: []
  type: TYPE_NORMAL
  zh: '我们使用Llama2-7B在表[19](#A2)中演示了PromptAttack-FS-EN生成的对抗性样本。表19广泛分析。附录B广泛的实验结果_ LLM可以愚弄自己:基于提示的对抗性攻击”)。我们观察到，在PromptAttack-FS-EN下，Llama2-7B生成的内容总是包含两个由无意义的箭头模式(" -> ")连接的句子，这完全遵循了few-shot AG中额外示例的格式。这表明，少弹策略可以显著降低Llama2生成的对抗样本的质量，而Llama2的理解能力较差。因此，生成的对抗样本很容易被识别为低保真度，并被保真度滤波器滤除，从而导致PromptAttack-FS-EN对Llama2的ASR较低。'
