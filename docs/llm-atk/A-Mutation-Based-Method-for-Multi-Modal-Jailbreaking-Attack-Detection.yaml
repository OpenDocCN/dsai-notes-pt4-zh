- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:46:35'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:46:35
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一种基于突变的方法用于多模态越狱攻击检测
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2312.10766](https://ar5iv.labs.arxiv.org/html/2312.10766)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2312.10766](https://ar5iv.labs.arxiv.org/html/2312.10766)
- en: Xiaoyu Zhang Xi’an Jiaotong UniversityXi’anChina [zxy0927@stu.xjtu.edu.cn](mailto:zxy0927@stu.xjtu.edu.cn)
    ,  Cen Zhang Nanyang Technological UniversitySingapore [cen001@e.ntu.edu.sg](mailto:cen001@e.ntu.edu.sg)
    ,  Tianlin Li Nanyang Technological UniversitySingapore [tianlin001@e.ntu.edu.sg](mailto:tianlin001@e.ntu.edu.sg)
    ,  Yihao Huang Nanyang Technological UniversitySingapore [huangyihao22@gmail.com](mailto:huangyihao22@gmail.com)
    ,  Xiaojun Jia Nanyang Technological UniversitySingapore [jiaxiaojunqaq@gmail.com](mailto:jiaxiaojunqaq@gmail.com)
    ,  Xiaofei Xie Singapore Management UniversitySingapore [xiaofei.xfxie@gmail.com](mailto:xiaofei.xfxie@gmail.com)
    ,  Yang Liu Nanyang Technological UniversitySingapore [yangliu@ntu.edu.sg](mailto:yangliu@ntu.edu.sg)
     and  Chao Shen Xi’an Jiaotong UniversityXi’anChina [chaoshen@xjtu.edu.cn](mailto:chaoshen@xjtu.edu.cn)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Xiaoyu Zhang 西安交通大学 西安 中国 [zxy0927@stu.xjtu.edu.cn](mailto:zxy0927@stu.xjtu.edu.cn)，
    Cen Zhang 南洋理工大学 新加坡 [cen001@e.ntu.edu.sg](mailto:cen001@e.ntu.edu.sg)， Tianlin
    Li 南洋理工大学 新加坡 [tianlin001@e.ntu.edu.sg](mailto:tianlin001@e.ntu.edu.sg)， Yihao
    Huang 南洋理工大学 新加坡 [huangyihao22@gmail.com](mailto:huangyihao22@gmail.com)， Xiaojun
    Jia 南洋理工大学 新加坡 [jiaxiaojunqaq@gmail.com](mailto:jiaxiaojunqaq@gmail.com)， Xiaofei
    Xie 新加坡管理大学 新加坡 [xiaofei.xfxie@gmail.com](mailto:xiaofei.xfxie@gmail.com)， Yang
    Liu 南洋理工大学 新加坡 [yangliu@ntu.edu.sg](mailto:yangliu@ntu.edu.sg) 和 Chao Shen 西安交通大学
    西安 中国 [chaoshen@xjtu.edu.cn](mailto:chaoshen@xjtu.edu.cn)
- en: Abstract.
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: Large Language Models (LLMs) and Multi-Modal LLMs (MLLMs) have become pervasive
    and play a crucial role in numerous applications, powering everything from simple
    chatbots to complex decision-making systems. As their influence grows, so does
    the importance of their security; yet, modern LLMs are known to be vulnerable
    to jailbreaking attacks. These attacks can allow malicious users to exploit the
    models, making the case for effective jailbreak detection mechanisms an essential
    aspect of maintaining the integrity and trustworthiness of LLM-based applications.
    Although there are existing works dedicated to detecting jailbreak attacks, they
    have shown certain limitations. Notably, many current strategies are post-query
    based, which require specific target domain knowledge and only identify security
    breaches after they have occurred. Others, which are pre-query based, mainly focus
    on text-level attacks and fail to meet the increasingly complex multi-modal security
    requirements placed upon contemporary LLMs. This gap underscores the need for
    a more comprehensive approach to safeguarding these influential systems.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）和多模态LLMs（MLLMs）已经变得无处不在，在从简单聊天机器人到复杂决策系统的众多应用中发挥着至关重要的作用。随着它们的影响力增长，它们的安全性也变得愈发重要；然而，现代LLMs已知容易受到越狱攻击。这些攻击可能允许恶意用户利用模型，从而使有效的越狱检测机制成为维护LLM应用完整性和可信赖性的关键方面。尽管已有一些工作致力于检测越狱攻击，但它们存在一定的局限性。值得注意的是，许多现有策略是基于查询后的，这需要特定的目标领域知识，并且只在攻击发生后识别安全漏洞。其他基于查询前的策略主要关注文本级别的攻击，未能满足对当代LLMs日益复杂的多模态安全要求。这一差距突显了保护这些影响力系统的全面方法的必要性。
- en: In this work, we propose JailGuard, the first mutation-based jailbreaking detection
    framework which supports both image and text modalities. Our key observation is
    that attack queries inherently possess less robustness compared to benign queries.
    Specifically, to confuse the model, attack queries are usually crafted with well-designed
    templates or complicate perturbations, leading to a fact that a slight disturbance
    in input may result in a drastic change in the response. This lack of robustness
    can be utilized in attack detection by first mutating the incoming input into
    variant queries and then checking the divergence of the responses of the variants.
    Based on this intuition, we designed and implemented a detection framework comprising
    19 different mutators and a divergence-based detection formula. To fully understand
    the effectiveness of our framework, we built the first multi-modal LLM jailbreaking
    attack dataset, which has 304 items of data, covering ten types of known jailbreaking
    attacks on image and text modalities. The evaluation suggests that JailGuard achieves
    the best detection accuracy of 89.38%/85.42% on image and text inputs, outperforming
    state-of-the-art defense methods by 15.28%.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们提出了JailGuard，这是第一个基于突变的越狱检测框架，支持图像和文本两种模态。我们主要观察到攻击查询本质上比良性查询具有更低的鲁棒性。具体而言，为了混淆模型，攻击查询通常会采用精心设计的模板或复杂的扰动，这导致输入的轻微干扰可能会导致响应的剧烈变化。这种鲁棒性缺乏可以通过首先将传入的输入变异为不同的查询，然后检查这些变体的响应差异来用于攻击检测。基于这一直觉，我们设计并实现了一个检测框架，包括19种不同的变异器和一个基于差异的检测公式。为了全面理解我们框架的有效性，我们构建了第一个多模态LLM越狱攻击数据集，该数据集包含304项数据，涵盖了图像和文本模态上的十种已知越狱攻击。评估结果表明，JailGuard在图像和文本输入上的检测准确率分别为89.38%/85.42%，优于最先进的防御方法15.28%。
- en: 'Jailbreaking Detection, LLM Security, Large Language Model^†^†copyright: none'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 越狱检测、LLM安全、大型语言模型^†^†版权：无
- en: 1\. Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 介绍
- en: Large Language Models (LLMs) have become commonplace in our technological interactions,
    from chatbots to complex decision-making engines (gpt, [2023a](#bib.bib4); Chen
    et al., [2021](#bib.bib14)). They can perform tasks like understanding sentences,
    answering questions, and creating text that looks like it was written by a human.
    This has made them extremely helpful and valuable in many different areas. The
    advent of Multi-Modal Large Language Models (MLLMs) has expanded these functionalities
    even further by incorporating visual understanding, allowing them to interpret
    and generate imagery alongside text, enhancing user experience with rich, multi-faceted
    interactions (gpt, [2023b](#bib.bib5); Zhu et al., [2023a](#bib.bib57)).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLM）在我们的技术互动中变得司空见惯，从聊天机器人到复杂的决策引擎 (gpt, [2023a](#bib.bib4); Chen et al.,
    [2021](#bib.bib14))。它们可以执行理解句子、回答问题以及生成看似由人类编写的文本等任务。这使得它们在许多不同领域中极其有用和宝贵。多模态大型语言模型（MLLM）的出现通过引入视觉理解进一步扩展了这些功能，使它们能够解释和生成图像，同时处理文本，提升了用户体验，提供了丰富的、多方面的互动 (gpt,
    [2023b](#bib.bib5); Zhu et al., [2023a](#bib.bib57))。
- en: Despite their utility, the ubiquity of LLMs and MLLMs raises substantial security
    concerns. One key challenge is protecting against jailbreaking attacks, in which
    malicious attackers can manipulate models into violating rules or leaking confidential
    data (Deng et al., [2023](#bib.bib17); Zou et al., [2023](#bib.bib59); Chao et al.,
    [2023](#bib.bib13)). Such vulnerabilities can have far-reaching consequences,
    undermining the models’ reliability, exposing sensitive information, enabling
    the spread of misinformation, and damaging the overall trust in AI-driven applications.
    Addressing these security gaps is critical, particularly for MLLMs, whose visual
    capabilities could be weaponized to create deceptive or harmful multimedia content.
    Conclusively, there is an urgent need for strong protective measures that can
    prevent and respond to these jailbreaking attacks.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管其效用显著，LLM和MLLM的普及也带来了 substantial 安全隐患。一个关键挑战是防御越狱攻击，其中恶意攻击者可以操纵模型违反规则或泄露机密数据 (Deng
    et al., [2023](#bib.bib17); Zou et al., [2023](#bib.bib59); Chao et al., [2023](#bib.bib13))。这些漏洞可能带来深远的影响，削弱模型的可靠性，暴露敏感信息，助长虚假信息的传播，并损害对AI驱动应用的整体信任。解决这些安全漏洞至关重要，特别是对于MLLM，其视觉能力可能被武器化以创建具有欺骗性或有害的多媒体内容。总之，迫切需要强有力的保护措施，以防止和应对这些越狱攻击。
- en: 'There are several LLM defense researches, which can be divided into two categories:
    pre-query and post-query defenses. Post-query defenses are typically reactive,
    triggered after the model has already generated its outputs. These methods necessitate
    the construction of rules and detectors, such as those used in the Azure content
    detector (azu, [2023](#bib.bib3)), to discern and intercept inappropriate or sensitive
    content produced by the LLM. While post-query methods are effective, they require
    extensive domain knowledge and are only triggered after queries have been processed
    by models. On the contrary, pre-query defenses offer several benefits in terms
    of proactive deployment and application (Kumar et al., [2023](#bib.bib33); Robey
    et al., [2023](#bib.bib46)). Their deployment often requires minimal domain-specific
    knowledge, allowing for broader applicability. Techniques such as SmoothLLM (Robey
    et al., [2023](#bib.bib46)), which introduces random characters into input prompts,
    and semantic slicing of inputs, opt to tackle jailbreaking by manipulating and
    examining input data prior to query processing by LLMs. Such pre-emptive methods
    can prevent harmful inputs before they engage with the model, minimizing the risk
    of attacks. However, these pre-query strategies are primarily designed for text-based
    inputs, which cannot counter attacks involving multiple modalities. The limitations
    of existing approaches underscore the need for a more comprehensive approach to
    protect these state-of-the-art LLMs.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个LLM防御研究，可以分为两类：查询前防御和查询后防御。查询后防御通常是反应性的，发生在模型已经生成输出之后。这些方法需要构建规则和检测器，例如在Azure内容检测器（azu，[2023](#bib.bib3)）中使用的那些，以识别和拦截LLM生成的不适当或敏感内容。虽然查询后方法有效，但它们需要广泛的领域知识，并且只有在查询已经由模型处理之后才会被触发。相反，查询前防御在主动部署和应用方面提供了几个好处（Kumar等，[2023](#bib.bib33)；Robey等，[2023](#bib.bib46)）。它们的部署通常需要最少的领域特定知识，从而允许更广泛的适用性。像SmoothLLM（Robey等，[2023](#bib.bib46)）这样的技术，通过在输入提示中引入随机字符，以及输入的语义切片，选择通过操控和检查输入数据来解决越狱问题，这些操作发生在LLM处理查询之前。这种先发制人的方法可以在输入与模型交互之前防止有害输入，从而减少攻击风险。然而，这些查询前策略主要针对基于文本的输入，不能应对涉及多种模态的攻击。现有方法的局限性突显了保护这些最先进的LLM的需要更全面的方法。
- en: To address these limitations, we designed and implemented the first mutation-based
    jailbreaking defense framework, JailGuard, which supports attack detection on
    both image and text modalities. The key observation behind JailGuard is that attack
    queries inherently exhibit lower robustness than benign queries. To confuse LLMs,
    attack inputs are often generated based on crafted templates or by an extensive
    searching process with complex perturbations. This leads to a result that any
    minor modification to the inputs may invalidate its attack effectiveness, which
    appears as a significant change in output. In JailGuard, we design detection strategies
    based on this inherent fragility of attack queries. The whole process is that
    we first mutate the original input into a series of variant queries. Then the
    consistency of the responses of LLM systems to variants is analyzed. If a notable
    discrepancy can be identified among the responses, i.e., a divergence value that
    exceeds the threshold, a potential jailbreaking attack is identified. Overall,
    the JailGuard framework is comprised of 19 mutators and a divergence-based detection
    formula to identify potential attacks. Considering the characteristics of image
    size, color as well as the semantics of the text at the character, word, and sentence
    levels, we designed 10 image mutators and 9 text mutators to comprehensively disturb
    the input queries and generate variants. Then the detection formula identifies
    attacks by judging whether the divergence of variants’ responses exceeds a built-in
    threshold.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对这些限制，我们设计并实现了第一个基于突变的越狱防御框架JailGuard，该框架支持对图像和文本两种模态的攻击检测。JailGuard的关键观察是攻击查询本质上比正常查询表现出更低的鲁棒性。为了混淆LLMs，攻击输入通常基于精心制作的模板或通过广泛的搜索过程及复杂的扰动生成。这导致了任何对输入的微小修改都可能使攻击效果失效，从而表现为输出的显著变化。在JailGuard中，我们设计了基于攻击查询这种固有脆弱性的检测策略。整个过程是，我们首先将原始输入突变为一系列变体查询。然后分析LLM系统对这些变体的响应一致性。如果能识别出响应之间的显著差异，即超出阈值的偏差值，则识别出潜在的越狱攻击。总体而言，JailGuard框架由19个突变器和一个基于偏差的检测公式组成，用于识别潜在攻击。考虑到图像大小、颜色以及文本在字符、词语和句子层次的语义，我们设计了10个图像突变器和9个文本突变器，以全面扰乱输入查询并生成变体。然后，检测公式通过判断变体响应的偏差是否超过内置阈值来识别攻击。
- en: To comprehensively evaluate JailGuard, we construct the first multi-modal LLM
    jailbreaking attack dataset that covers ten types of jailbreak attacks on image
    and text modalities. The evaluation on our dataset shows that JailGuard can effectively
    detect jailbreaking attacks on image and text modalities. JailGuard has separately
    achieved the best detection accuracy of 89.38% and 85.42% on image and text inputs,
    outperforming state-of-the-art defense methods by 15.28%. In addition, JailGuard
    can effectively detect and defend different types of jailbreaking attacks. On
    all types of collected attacks collected, the best detection accuracy of JailGuard
    is always more than 70%. By contrast, the best detection accuracy of the state-of-the-art
    baseline methods on any collected attacks is lower than JailGuard, and even less
    than 10% on ‘GPT4simulator’ and ‘MasterKey-poc’ attacks.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了全面评估JailGuard，我们构建了第一个多模态LLM越狱攻击数据集，涵盖了十种类型的图像和文本模态的越狱攻击。对我们数据集的评估表明，JailGuard可以有效检测图像和文本模态的越狱攻击。JailGuard在图像和文本输入上的最佳检测准确率分别为89.38%和85.42%，比最先进的防御方法高出15.28%。此外，JailGuard可以有效检测和防御不同类型的越狱攻击。在所有收集到的攻击类型中，JailGuard的最佳检测准确率始终超过70%。相比之下，最先进的基线方法在任何收集到的攻击上的最佳检测准确率都低于JailGuard，甚至在‘GPT4simulator’和‘MasterKey-poc’攻击中低于10%。
- en: 'In summary, our contributions are:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们的贡献包括：
- en: •
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We identified the inherent low robustness of jailbreaking attack inputs. Based
    on that, we designed and implemented the first mutation-based multi-modal jailbreaking
    detection framework, JailGuard, which supports detection for both image and text
    modalities.
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们识别了越狱攻击输入的固有低鲁棒性。基于此，我们设计并实现了第一个基于突变的多模态越狱检测框架JailGuard，该框架支持图像和文本模态的检测。
- en: •
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We constructed the first jailbreaking attack dataset that covers both image
    and text inputs.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们构建了第一个涵盖图像和文本输入的越狱攻击数据集。
- en: •
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We performed experiments on our constructed dataset, and JailGuard has achieved
    better detection effects than the state-of-the-art defense methods (Robey et al.,
    [2023](#bib.bib46)).
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们在构建的数据集上进行了实验，JailGuard在检测效果上优于最先进的防御方法（Robey et al., [2023](#bib.bib46)）。
- en: 2\. Background
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 背景
- en: 'Jailbreaking attack aims to design and generate an attack prompt  that can
    induce the target LLM system and application  to contain toxic content  in the
    model response , which can be represented as:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 越狱攻击旨在设计和生成一个攻击提示，使目标LLM系统和应用包含有害内容在模型响应中，可以表示为：
- en: '|  |  |  |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |'
- en: where  is a detection function and it returns 1 iff the model response  contains
    the toxic content .
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 其中是一个检测函数，返回1当且仅当模型响应包含有害内容。
- en: The open-source community has manually collected and evaluated a series of effective
    jailbreak prompts and templates, which can be classified into three categories
    based on their patterns, namely ‘Attention Shifting’, ‘Pretending’, and ‘Privilege
    Escalation’ (Liu et al., [2023b](#bib.bib36)). The methods in ‘Attention Shifting’
    leverage specific tasks or contents to change both the conversation context and
    intention and divert LLM-based applications’ attention to conduct the attack.
    ‘Pretending’ methods alter the conversation background or context to mislead LLMs,
    and ‘Privilege Escalation’ guides LLMs through elaborated instructions to break
    any existing constraints.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 开源社区手动收集并评估了一系列有效的越狱提示和模板，这些模板根据其模式可以分为三类，即“注意力转移”、“伪装”和“特权升级”（Liu et al., [2023b](#bib.bib36)）。
    “注意力转移”方法利用特定任务或内容来改变对话背景和意图，并将LLM应用的注意力转移以实施攻击。“伪装”方法改变对话背景或上下文来误导LLM，而“特权升级”则通过详细的指令引导LLM突破现有的限制。
- en: To effectively and automatically generate jailbreak prompts, researchers proposed
    a variety of attack methods (Zou et al., [2023](#bib.bib59); Deng et al., [2023](#bib.bib17);
    Chao et al., [2023](#bib.bib13); Zhu et al., [2023b](#bib.bib58); Yu et al., [2023](#bib.bib54)).
    Zou et al. (Zou et al., [2023](#bib.bib59)) designed the greedy coordinate gradient-based
    search (GCG) to produce adversarial suffix to attack open-sourced LLMs (e.g.,
    Vicuna (Zheng et al., [2023](#bib.bib56))), which has proven its effectiveness
    through transfer attacks on black-box commercial LLMs. We transfer the GCG attack
    on the Vicuna model to OpenAI GPT-3.5 and collect them into datasets in [§ 5](#S5
    "5\. Dataset Construction ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection"). Deng et al. (Deng et al., [2023](#bib.bib17)) proposed MasterKey,
    which trains a model to learn from existing effective attack patterns and automatically
    generates new attacks to bypass the defense mechanisms of four commercial LLM
    systems. We collect two types of attacks generated by Masters in [§ 5](#S5 "5\.
    Dataset Construction ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack
    Detection"), namely proof-of-concept (POC) attacks and continuation-based attacks.
    With the emergence of MLLMs, researchers designed a visual jailbreaking attack
    based on the implanted adversarial perturbation in the image inputs (Qi et al.,
    [2023](#bib.bib44)). Their method achieved a high attack success rate on MiniGPT-4
    which is one of the state-of-the-art MLLMs (Qi et al., [2023](#bib.bib44)).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有效且自动地生成越狱提示，研究人员提出了各种攻击方法（Zou et al., [2023](#bib.bib59); Deng et al., [2023](#bib.bib17);
    Chao et al., [2023](#bib.bib13); Zhu et al., [2023b](#bib.bib58); Yu et al., [2023](#bib.bib54)）。Zou
    et al.（Zou et al., [2023](#bib.bib59)）设计了贪婪坐标梯度搜索（GCG），用以生成对抗性后缀来攻击开源LLM（例如，Vicuna（Zheng
    et al., [2023](#bib.bib56)）），这种方法通过对黑箱商业LLM的转移攻击证明了其有效性。我们将GCG攻击从Vicuna模型转移到OpenAI
    GPT-3.5，并将其收集到[§ 5](#S5 "5\. Dataset Construction ‣ A Mutation-Based Method for
    Multi-Modal Jailbreaking Attack Detection")的数据集中。Deng et al.（Deng et al., [2023](#bib.bib17)）提出了MasterKey，它训练一个模型从现有有效攻击模式中学习，并自动生成新攻击以绕过四个商业LLM系统的防御机制。我们在[§
    5](#S5 "5\. Dataset Construction ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection")中收集了两种类型的MasterKey生成的攻击，即概念验证（POC）攻击和基于延续的攻击。随着多模态LLM的出现，研究人员设计了基于图像输入中植入对抗性扰动的视觉越狱攻击（Qi
    et al., [2023](#bib.bib44)）。他们的方法在MiniGPT-4这一前沿多模态LLM上取得了高攻击成功率（Qi et al., [2023](#bib.bib44)）。
- en: LLM defense methods can be divided into pre-query defense and post-query defense.
    LLM systems mainly leverage content detectors in the output stage to determine
    whether the model output is toxic (azu, [2023](#bib.bib3)). These content detectors
    are complex systems that evaluate the toxicity of the given input based on built-in
    rules and integrated models. Therefore, their detection results are greatly affected
    by the design of rules. At the input stage, one of the state-of-the-art defense
    methods is SmoothLLM (Robey et al., [2023](#bib.bib46)), which implemented three
    perturbation strategies (i.e., Swap, Insert, and Patch) and aggregated the responses
    of perturbed inputs to detect jailbreaks. These perturbation strategies randomly
    select 10% of characters in the input and insert or swap with random characters
    to generate several perturbed inputs. Then, in the aggregation stage, SmoothLLM
    checks the LLM system responses of perturbed inputs. If more than half of them
    contain jailbreak keywords (Zou et al., [2023](#bib.bib59)) (e.g., ‘I cannot help
    with that’), the source input will be judged as a jailbreak input. Although existing
    defenses demonstrate their effectiveness in experiments, they only focus on text
    input and output and cannot support LLM inputs on other modalities, such as images.
    In this paper, we propose the first multi-modal LLM jailbreaking detection framework,
    JailGuard, that detects and defends jailbreaking attacks on both image and text
    modalities.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 防御方法可以分为查询前防御和查询后防御。LLM 系统主要在输出阶段利用内容检测器来判断模型输出是否具有毒性（azu，[2023](#bib.bib3)）。这些内容检测器是复杂的系统，根据内置规则和集成模型评估给定输入的毒性。因此，它们的检测结果受到规则设计的极大影响。在输入阶段，最先进的防御方法之一是
    SmoothLLM（Robey et al.，[2023](#bib.bib46)），该方法实现了三种扰动策略（即 Swap、Insert 和 Patch），并汇总扰动输入的响应以检测越狱行为。这些扰动策略随机选择输入中的
    10% 字符，并用随机字符进行插入或交换，以生成多个扰动输入。然后，在汇总阶段，SmoothLLM 检查扰动输入的 LLM 系统响应。如果其中超过一半包含越狱关键词（Zou
    et al.，[2023](#bib.bib59)）（例如，“我不能帮忙”），则源输入将被判断为越狱输入。尽管现有防御在实验中展示了其有效性，但它们仅关注文本输入和输出，不能支持其他模态（如图像）的
    LLM 输入。本文提出了第一个多模态 LLM 越狱检测框架 JailGuard，能够检测和防御图像和文本模态的越狱攻击。
- en: '![Refer to caption](img/36e9ca813a5bef6ca67828d94257d1d8.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/36e9ca813a5bef6ca67828d94257d1d8.png)'
- en: Figure 1. Motivation Case of JailGuard (Red Highlights Toxic Contents and Some
    of Them are Blocked)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1. JailGuard 的动机案例（红色高亮显示有毒内容，其中一些已被阻止）
- en: 3\. Motivation
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3. 动机
- en: Existing LLM jailbreaking methods (Zou et al., [2023](#bib.bib59); Liu et al.,
    [2023b](#bib.bib36); Deng et al., [2023](#bib.bib17)) mainly rely on specific
    templates or tiny but complicated perturbations to conduct attacks. These elaborate
    perturbations and templates can shift the attention of the LLM system and application
    and deceive its built-in defense mechanisms. Although these elaborate attacks
    have achieved excellent attack results, they are less robust than benign queries
    and easily disrupted and fail. Such a difference in robustness can be used to
    distinguish between attack and benign queries.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现有 LLM 越狱方法（Zou et al.，[2023](#bib.bib59)；Liu et al.，[2023b](#bib.bib36)；Deng
    et al.，[2023](#bib.bib17)）主要依赖于特定的模板或微小但复杂的扰动进行攻击。这些复杂的扰动和模板可以转移 LLM 系统和应用的注意力，并欺骗其内置防御机制。尽管这些复杂的攻击取得了优秀的攻击结果，但它们的鲁棒性低于良性查询，容易被干扰并失败。这种鲁棒性差异可以用来区分攻击和良性查询。
- en: We have provided two motivation examples at image and text modalities in [Figure 1](#S2.F1
    "Figure 1 ‣ 2\. Background ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection"). The upper and lower parts separately show attack and benign
    queries that are from our image and text dataset ([§ 5](#S5 "5\. Dataset Construction
    ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")). For
    the image and text queries, we randomly select one mutator to generate six variants,
    as shown in [§ 5](#S5 "5\. Dataset Construction ‣ A Mutation-Based Method for
    Multi-Modal Jailbreaking Attack Detection").b). These mutators can mask part of
    the input, insert specific strings to the text (e.g., ‘[mask]’), or change the
    image color, etc. Detailed descriptions of mutators are shown in [§ 4.1](#S4.SS1
    "4.1\. Variant Generator ‣ 4\. System Design ‣ A Mutation-Based Method for Multi-Modal
    Jailbreaking Attack Detection"). Then we obtain the responses of the variant queries
    on LLM systems and applications (using MiniGPT-4 for images and GPT-3.5 for texts),
    as shown in [Figure 1](#S2.F1 "Figure 1 ‣ 2\. Background ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection").c). We use red to mark the toxic
    and harmful content in the response. Finally, we vectorize the response results
    and compute the divergence between each set of variant responses. The heat maps
    in [Figure 1](#S2.F1 "Figure 1 ‣ 2\. Background ‣ A Mutation-Based Method for
    Multi-Modal Jailbreaking Attack Detection").d) visualize the divergence between
    the responses of six variants from one input of the LLM-based application.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[图1](#S2.F1 "Figure 1 ‣ 2\. Background ‣ A Mutation-Based Method for Multi-Modal
    Jailbreaking Attack Detection")中提供了两个动机示例，分别展示了图像和文本模态。上半部分和下半部分分别显示了来自我们图像和文本数据集的攻击和正常查询（见[§
    5](#S5 "5\. Dataset Construction ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection")）。对于图像和文本查询，我们随机选择一个变异器生成六个变体，如[§ 5](#S5 "5\. Dataset Construction
    ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection").b)所示。这些变异器可以遮蔽输入的部分内容、向文本中插入特定字符串（例如‘[mask]’），或改变图像的颜色等。变异器的详细描述见[§
    4.1](#S4.SS1 "4.1\. Variant Generator ‣ 4\. System Design ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection")。然后我们在LLM系统和应用程序上获得变体查询的响应（使用MiniGPT-4处理图像，GPT-3.5处理文本），如[图1](#S2.F1
    "Figure 1 ‣ 2\. Background ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection").c)所示。我们用红色标记响应中的有毒和有害内容。最后，我们将响应结果向量化，并计算每组变体响应之间的差异。[图1](#S2.F1
    "Figure 1 ‣ 2\. Background ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection").d)中的热图可视化了来自LLM应用的单一输入的六个变体响应之间的差异。
- en: We can observe that regardless of the input modality and the used mutators,
    attack queries are more susceptible to perturbations than benign inputs. In attack
    images, mutators can cause the responses of variants to dramatically change from
    toxic content targeting a specific group to denial-of-service replies (e.g., “I
    am sorry…”). In contrast, the LLM system can still perform the given instructions
    (e.g., “describing the image”) on benign inputs. Affected by mutators, there are
    inevitable differences between the benign responses, but this difference is trivial
    compared to the difference in responses to attack images. As shown in [Figure 1](#S2.F1
    "Figure 1 ‣ 2\. Background ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection").d), there is a clear color difference in the heat map of the
    response of attack image variants, which implies a large divergence value and
    a large difference between the responses’ semantics. We can make similar observations
    on the text input in the lower part of [Figure 1](#S2.F1 "Figure 1 ‣ 2\. Background
    ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection"). This
    shows that the lack of robustness of attack queries is a common characteristic
    in different modalities. Based on the observation, we design the first mutation-based
    jailbreaking detection framework, JailGuard, that mutates the untrusted queries
    into variants and then checks the divergence of the LLM system responses of the
    variant queries and effectively detects jailbreaking attacks.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以观察到，无论输入的模式和使用的变异器如何，攻击查询都比正常输入更容易受到扰动。在攻击图像中，变异器可能导致变体的响应从针对特定群体的有害内容剧烈变化为拒绝服务的回复（例如，“对不起…”）。相比之下，LLM系统仍然可以对正常输入执行给定的指令（例如，“描述图像”）。受变异器影响，正常响应之间不可避免地存在差异，但这种差异与对攻击图像的响应差异相比微不足道。如[图1](#S2.F1
    "Figure 1 ‣ 2\. Background ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection")d)所示，攻击图像变体的响应热图中存在明显的颜色差异，这意味着存在较大的偏差值和响应语义之间的差异。我们可以在[图1](#S2.F1
    "Figure 1 ‣ 2\. Background ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection")的下半部分对文本输入进行类似的观察。这表明，攻击查询的鲁棒性不足是不同模式下的一个共同特征。基于这一观察，我们设计了第一个基于变异的越狱检测框架JailGuard，它将不可信的查询变异为变体，然后检查这些变体查询的LLM系统响应的偏差，从而有效检测越狱攻击。
- en: 4\. System Design
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 系统设计
- en: JailGuard is implemented on top of the LLM system and application workflow,
    and [Figure 2](#S4.F2 "Figure 2 ‣ 4\. System Design ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection") shows the overview. JailGuard
    consists of the Variant Generator module and Attack Detector module that are portable
    and migratory. Inspired by previous research on fuzz testing (Xie et al., [2019](#bib.bib50);
    Zhang et al., [2021](#bib.bib55)) and model robustness (Frosio and Kautz, [2023](#bib.bib19);
    Morris et al., [2020](#bib.bib41)), for the untrusted query, the variant generator
    of JailGuard first selects a built-in mutator for the query and generates a variant
    set. The attack detector then uses these variants to query the target LLM system
    and computes the semantic similarity and divergence between variant responses,
    and finally leverages the built-in thresholds to identify benign and attack queries.
    The former can access LLM system without a barrier, and JailGuard will discard
    and report the latter.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: JailGuard在LLM系统和应用工作流的基础上实现，[图2](#S4.F2 "Figure 2 ‣ 4\. System Design ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection")展示了其概述。JailGuard由变体生成模块和攻击检测模块组成，这些模块是可移植和可迁移的。受到之前有关模糊测试（Xie等，[2019](#bib.bib50)；Zhang等，[2021](#bib.bib55)）和模型鲁棒性（Frosio和Kautz，[2023](#bib.bib19)；Morris等，[2020](#bib.bib41)）研究的启发，对于不可信的查询，JailGuard的变体生成器首先为该查询选择一个内置的变异器，并生成一个变体集。然后，攻击检测器使用这些变体查询目标LLM系统，计算变体响应之间的语义相似性和偏差，最终利用内置的阈值来识别正常查询和攻击查询。前者可以无障碍地访问LLM系统，而JailGuard将丢弃并报告后者。
- en: In real-world scenarios, JailGuard should be deployed and applied as a part
    of LLM system and application workflow to prevent jailbreaks, which means that
    JailGuard and perform defense from the perspective of developers. At this time,
    it should have access to the underlying interface of LLMs and can query multiple
    variants in a batch and obtain multiple responses simultaneously. In our experiments,
    we simulate this process by accessing the LLM system’s API multiple times.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际场景中，JailGuard 应作为 LLM 系统和应用工作流的一部分进行部署和应用，以防止越狱，这意味着 JailGuard 从开发者的角度进行防御。在此情况下，它应能够访问
    LLM 的底层接口，并可以批量查询多个变体并同时获得多个响应。在我们的实验中，我们通过多次访问 LLM 系统的 API 来模拟这个过程。
- en: '![Refer to caption](img/c28fb576ee7c23f3ef5391a714e2a70a.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c28fb576ee7c23f3ef5391a714e2a70a.png)'
- en: Figure 2. Overview of JailGuard
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2. JailGuard 概述
- en: '![Refer to caption](img/8536663978e1e8830c04c5af8d2a802c.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8536663978e1e8830c04c5af8d2a802c.png)'
- en: Figure 3. Demo Case for 10 Mutators of JailGuard (Red Marks the Modification
    of Text Input and Underline Marks Important Sentences)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3. JailGuard 10 种变换器的演示案例（红色标记文本输入的修改，下划线标记重要句子）
- en: 4.1\. Variant Generator
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1\. 变体生成器
- en: The main role of the variant generator is to select a mutation operation on
    the original untrusted input prompt  and generate multiple variants that are slightly
    different from the original input. The variant set can be represented as , where  indicates
    the number of variants. The variant generator in JailGuard has currently implemented
    a total of 19 mutators at image and text modalities, including 16 random mutators
    and 3 advanced mutators. We have provided a demo for some mutators in [Figure 3](#S4.F3
    "Figure 3 ‣ 4\. System Design ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection").
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 变体生成器的主要作用是对原始不可信的输入提示进行变异操作，并生成与原始输入略有不同的多个变体。变体集可以表示为，表示变体的数量。JailGuard 中的变体生成器目前在图像和文本模态下共实现了
    19 个变换器，包括 16 个随机变换器和 3 个高级变换器。我们在 [图 3](#S4.F3 "Figure 3 ‣ 4\. System Design
    ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")中提供了一些变换器的演示。
- en: 4.1.1\. Random Mutators
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.1\. 随机变换器
- en: The design of random mutators is inspired by existing work (Hendrycks et al.,
    [2019](#bib.bib27); Lopes et al., [2019](#bib.bib37); Bayer et al., [2022](#bib.bib11);
    Marivate and Sefara, [2020](#bib.bib39); Karimi et al., [2021](#bib.bib32)). They
    use various data augmentation methods to randomly change input images or texts
    and generate variants.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 随机变换器的设计灵感来源于现有的工作（Hendrycks et al., [2019](#bib.bib27); Lopes et al., [2019](#bib.bib37);
    Bayer et al., [2022](#bib.bib11); Marivate 和 Sefara, [2020](#bib.bib39); Karimi
    et al., [2021](#bib.bib32)）。他们使用各种数据增强方法随机改变输入图像或文本并生成变体。
- en: There are 10 random mutators for image inputs, namely Random Mask, Random Solarization,
    Horizental Flip, Vertical Flip, Crop and Resize, Random Grayscale, Gaussian Blur,
    Random Rotation, Colorjitter, and Random Posterization. Details are shown as follows.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图像输入，有 10 个随机变换器，分别是随机遮罩、随机太阳化、水平翻转、垂直翻转、裁剪和调整大小、随机灰度、Gaussian 模糊、随机旋转、颜色抖动和随机过度化。详细信息如下所示。
- en: Random Mask mutator inserts a small black mask to a random position of the image,
    as shown in [Figure 3](#S4.F3 "Figure 3 ‣ 4\. System Design ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection").a). It has the chance to
    destroy the implanted perturbations in attack images, leading to a drastic change
    in LLM system responses.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 随机遮罩变换器在图像的随机位置插入一个小黑色遮罩，如 [图 3](#S4.F3 "Figure 3 ‣ 4\. System Design ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection")a)所示。它有可能破坏攻击图像中植入的扰动，从而导致
    LLM 系统响应发生剧烈变化。
- en: Random Solarization mutator inverts all pixel values above a random threshold
    with a certain probability, resulting in solarizing the input image, as shown
    in [Figure 3](#S4.F3 "Figure 3 ‣ 4\. System Design ‣ A Mutation-Based Method for
    Multi-Modal Jailbreaking Attack Detection").b). This mutator can introduce perturbations
    for the whole image without damaging the overall information in the image.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 随机太阳化变换器以一定概率将所有像素值高于随机阈值的部分反转，从而使输入图像发生太阳化，如 [图 3](#S4.F3 "Figure 3 ‣ 4\. System
    Design ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")b)所示。该变换器可以引入整个图像的扰动，而不破坏图像中的整体信息。
- en: Horizental Flip and Vertical Flip respectively flip the target image horizontally
    or vertically with a random probability between 0 to 1. They will not modify the
    pixel values in the image, and we have provided an example of Horizental Flip
    in [Figure 3](#S4.F3 "Figure 3 ‣ 4\. System Design ‣ A Mutation-Based Method for
    Multi-Modal Jailbreaking Attack Detection").c).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Horizental Flip 和 Vertical Flip 分别以 0 到 1 之间的随机概率水平或垂直翻转目标图像。它们不会修改图像中的像素值，我们在
    [图 3](#S4.F3 "Figure 3 ‣ 4\. System Design ‣ A Mutation-Based Method for Multi-Modal
    Jailbreaking Attack Detection")c) 中提供了 Horizental Flip 的示例。
- en: Random Grayscale is a commonly used data augmentation method that converts an
    RGB image into a grayscale image with a random probability between 0 to 1 (He
    et al., [2020](#bib.bib26); Gong et al., [2021](#bib.bib22); Bai et al., [2022](#bib.bib10)).
    [Figure 3](#S4.F3 "Figure 3 ‣ 4\. System Design ‣ A Mutation-Based Method for
    Multi-Modal Jailbreaking Attack Detection").d) provides a demo.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Random Grayscale 是一种常用的数据增强方法，它将 RGB 图像转换为具有 0 到 1 之间随机概率的灰度图像 (He et al., [2020](#bib.bib26);
    Gong et al., [2021](#bib.bib22); Bai et al., [2022](#bib.bib10))。 [图 3](#S4.F3
    "Figure 3 ‣ 4\. System Design ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection")d) 提供了一个演示。
- en: Crop and Resize (Bai et al., [2022](#bib.bib10)) can disturb attack images without
    changing color and style. It first crops a random aspect of the original image
    and then resizes it to a random size, as shown in [Figure 3](#S4.F3 "Figure 3
    ‣ 4\. System Design ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack
    Detection").e).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Crop and Resize (Bai et al., [2022](#bib.bib10)) 可以在不改变颜色和风格的情况下干扰攻击图像。它首先裁剪原始图像的随机部分，然后将其调整为随机大小，如
    [图 3](#S4.F3 "Figure 3 ‣ 4\. System Design ‣ A Mutation-Based Method for Multi-Modal
    Jailbreaking Attack Detection")e) 所示。
- en: Gaussian Blur (Bai et al., [2022](#bib.bib10)) blurs images with the Gaussian
    function with a random kernel size. It reduces the sharpness or high-frequency
    details in an image, which intuitively helps to disrupt the potential attack in
    image inputs.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Gaussian Blur (Bai et al., [2022](#bib.bib10)) 使用具有随机核大小的高斯函数模糊图像。它减少了图像中的清晰度或高频细节，这直观上有助于干扰图像输入中的潜在攻击。
- en: Random Rotation (Gidaris et al., [2018](#bib.bib21); Cubuk et al., [2020](#bib.bib16))
    rotates the image by a random number of degrees between 0 to 180. After rotation,
    the area that exceeds the original size will be cropped.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Random Rotation (Gidaris et al., [2018](#bib.bib21); Cubuk et al., [2020](#bib.bib16))
    将图像旋转 0 到 180 度之间的随机角度。旋转后，超出原始大小的区域将被裁剪。
- en: Colorjitter (He et al., [2020](#bib.bib26)) randomly modifies the brightness
    and hue of images and introduces variations in their color properties.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Colorjitter (He et al., [2020](#bib.bib26)) 随机修改图像的亮度和色调，并引入其颜色属性的变化。
- en: Random Posterization randomly posterizes an image by reducing the number of
    bits for each color channel. It can remove the small perturbations and output
    a more stylized and simplified image.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Random Posterization 通过减少每个颜色通道的位数来随机海报化图像。它可以去除小的扰动，输出更具风格化和简化的图像。
- en: The random text mutators consist of seven random mutators, namely Random Replacement,
    Random Insertion, Random Deletion, Synonym Replacement, Punctuation Insertion,
    and Translation.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 随机文本变换器由七个随机变换器组成，即 Random Replacement、Random Insertion、Random Deletion、Synonym
    Replacement、Punctuation Insertion 和 Translation。
- en: Random Replacement and Random Insertion perform the replacement or insertion
    operation with probability  for each character, as shown in [Figure 3](#S4.F3
    "Figure 3 ‣ 4\. System Design ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection").f) and g). The replacement operation replaces the target and
    subsequent characters with a specific text , ensuring that the input length does
    not change. The insertion operation inserts  at the position after the target
    character. Similarly, Random Deletion removes the character in the text with probability
    .
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Random Replacement 和 Random Insertion 以概率对每个字符执行替换或插入操作，如 [图 3](#S4.F3 "Figure
    3 ‣ 4\. System Design ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack
    Detection")f) 和 g) 所示。替换操作用特定文本替换目标及后续字符，确保输入长度不变。插入操作在目标字符之后的位置插入。类似地，Random
    Deletion 以概率删除文本中的字符。
- en: Synonym Replacement selects words in the text input and uses their synonyms
    to replace them based on WordNet (Miller, [1995](#bib.bib40)).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Synonym Replacement 从文本输入中选择单词，并使用其同义词进行替换，基于 WordNet (Miller, [1995](#bib.bib40))。
- en: Punctuation Insertion is from existing data augmentation method that randomly
    inserts punctuation masks into sentence (Karimi et al., [2021](#bib.bib32)). This
    mutator has the potential to disturb the adversarial-based jailbreaking attack
    without changing the semantics of the input sentence.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 标点插入来自现有的数据增强方法，即随机在句子中插入标点掩码（Karimi 等，[2021](#bib.bib32)）。该变异器有可能在不改变输入句子语义的情况下干扰基于对抗的越狱攻击。
- en: Translation first translates the input sentence to a random language and then
    translates it back. For jailbreak queries, the translation process can rewrite
    the attack templates and remove the meaningless characters, ultimately invalidating
    the attack.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 翻译首先将输入句子翻译成一种随机语言，然后再翻译回来。对于越狱查询，翻译过程可以重写攻击模板并去除无意义的字符，最终使攻击失效。
- en: 4.1.2\. Advanced Mutators
  id: totrans-63
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.2\. 高级变异器
- en: Although random mutators have the potential to disrupt jailbreak attacks, they
    lack proper guidance, resulting in limited effectiveness. On the one hand, for
    complex jailbreak attacks (e.g., ‘Attention Shifting’ (Liu et al., [2023b](#bib.bib36))),
    simple random operators may not be able to cause enough interference to the attack
    input, resulting in the defense being bypassed. On the other hand, blindly modifying
    the input may cause benign inputs to be compromised, which leads to dramatic changes
    in their responses‘ semantics. This is especially true in the text, where small
    changes to a word may completely change its meaning. To achieve a better detection
    effect, we design and implement three advanced text mutators in JailGuard, namely
    Targeted Replacement, Targeted Insertion, and Rephrasing.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管随机变异器具有干扰越狱攻击的潜力，但由于缺乏适当的指导，其效果有限。一方面，对于复杂的越狱攻击（例如，“注意力转移”（Liu 等，[2023b](#bib.bib36)）），简单的随机操作可能无法对攻击输入造成足够的干扰，导致防御被绕过。另一方面，盲目修改输入可能会导致良性输入受到影响，从而导致其响应的语义发生剧烈变化。在文本中尤其如此，单词的细微变化可能会完全改变其含义。为了实现更好的检测效果，我们在
    JailGuard 中设计并实现了三种高级文本变异器，即定向替换、定向插入和改写。
- en: Targeted Replacement and Targeted Insertion are the advanced version of Random
    Replacement and Random Insertion. Inspired by existing nature language processing
    work (Nenkova and Vanderwende, [2005](#bib.bib42)), these two advanced mutators
    first find the sentences with the highest word frequency in the input text, which
    means that words in these sentences appear repeatedly in the whole input and often
    represent the summary of the input text. Then these mutators select these sentences
    as the important sentences. The characters in important sentences have a higher
    probability of performing replacement and insertion. We provide two cases in [Figure 3](#S4.F3
    "Figure 3 ‣ 4\. System Design ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection").h) and i). Italicized and underlined sentences represent selected
    important sentences.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 定向替换和定向插入是随机替换和随机插入的高级版本。受到现有自然语言处理工作的启发（Nenkova 和 Vanderwende，[2005](#bib.bib42)），这两种高级变异器首先在输入文本中找到词频最高的句子，这意味着这些句子中的词在整个输入文本中反复出现，并且通常代表了输入文本的摘要。然后，这些变异器选择这些句子作为重要句子。重要句子中的字符更有可能进行替换和插入。我们在[图
    3](#S4.F3 "Figure 3 ‣ 4\. System Design ‣ A Mutation-Based Method for Multi-Modal
    Jailbreaking Attack Detection")h)和i)中提供了两个案例。斜体和下划线的句子表示选定的重要句子。
- en: 'Rephrasing is one intuitive way to collapse the jailbreak template and remove
    the attack perturbations in the input. Rephrasing mutator in JailGuard uses the
    prompt of "Please rephrase the following paragraph while ensuring its core semantics
    and contents unchanged. The paragraph is: [INSERT ORIGIN INPUTS]" to query OpenAI
    GPT-3.5 and rewrite the original input while preserving semantics. [Figure 3](#S4.F3
    "Figure 3 ‣ 4\. System Design ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection").j) shows a demo of this mutator, and red marks the changed
    content in the variant.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 改写是一种直观的方法，用于简化越狱模板并去除输入中的攻击扰动。JailGuard 中的改写变异器使用“请改写以下段落，同时确保其核心语义和内容不变。段落是：[INSERT
    ORIGIN INPUTS]”的提示查询 OpenAI GPT-3.5，并在保留语义的同时重写原始输入。[图 3](#S4.F3 "Figure 3 ‣ 4\.
    System Design ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")j)展示了该变异器的演示，红色标记显示了变体中的更改内容。
- en: 4.2\. Attack Detector
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2\. 攻击检测器
- en: 'Our detector operates by leveraging the divergence among outputs to effectively
    achieve detection. The calculation of divergence proceeds through the following
    steps:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的检测器通过利用输出之间的散度来有效地实现检测。散度的计算通过以下步骤进行：
- en: 'Constructing the similarity matrix For the input variant set , the detector
    first queries LLM system to obtain the response set . For each  in , the detector
    leverages the ‘spaCy’ library to convert it to word vector  and then calculates
    the cosine similarity between it and the word vectors of other responses. The
    similairty  between vectors  and  can be represented as:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 构建相似性矩阵 对于输入变体集合 ，检测器首先查询 LLM 系统以获得响应集合 。对于  中的每个 ，检测器利用 'spaCy' 库将其转换为词向量  ，然后计算其与其他响应的词向量之间的余弦相似度。向量  和  之间的相似度  可以表示为：
- en: '|  |  |  |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |'
- en: where  calculates the cosine similarity between two vectors, . Similarity values
    for response pairs are represented in an  matrix , where each element at  corresponds
    to the similarity between the pair .
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 其中  计算两个向量之间的余弦相似度，。响应对的相似性值以  矩阵 的形式表示，其中每个元素在  对应于该对之间的相似度。
- en: Characterizing each response In the  similarity matrix , each row  corresponding
    to the -th response  can be normalized using  normalization. This process transforms
    the row into a similarity probability distribution, effectively characterizing
    the relationship of response  to the other responses in the matrix.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 对每个响应的特征描述 在  相似性矩阵 中，每一行  对应于第 - 个响应  可以通过  归一化来进行标准化。这个过程将该行转化为相似性概率分布，有效地描述了响应  与矩阵中其他响应的关系。
- en: '|  |  |  |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |'
- en: 'Quantifying the divergence of two responses Then JailGuard uses Kullback-Leibler
    (KL) divergence to quantify the difference between the similarity distributions
    of two responses :'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 量化两个响应的差异 然后，JailGuard 使用 Kullback-Leibler (KL) 散度来量化两个响应的相似性分布之间的差异：
- en: '|  |  |  |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |'
- en: The divergence values for response pairs are represented in an  matrix , where
    each element at  corresponds to the divergence between the pair .
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 响应对的散度值以  矩阵 的形式表示，其中每个元素在  对应于该对之间的散度。
- en: 'Examining the divergence Finally, for the obtained divergence  matrix , the
    detector uses the threshold  to identify the attack input. Specifically, if any
    value in divergence matrix  exceeds , JailGuard will consider the original input
    as an attack input, otherwise it is judged as a benign input, which is shown as
    follows:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 检查散度 最后，对于获得的散度  矩阵 ，检测器使用阈值  来识别攻击输入。具体来说，如果散度矩阵  中的任何值超过 ，JailGuard 将把原始输入视为攻击输入，否则判断为良性输入，具体如下：
- en: '|  |  |  |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |'
- en: where  indicates the set of jailbreaking attacks.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 其中  表示越狱攻击集合。
- en: To maximize the detection effect of JailGuard, we randomly selected 70/80 text/image
    inputs from our dataset ([§ 5](#S5 "5\. Dataset Construction ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection")) and calculated the divergence
    of their variants. Based on the results, we choose  for text input on GPT-3.5
    and 0.0025 for image input on MiniGPT-4 in JailGuard. Note that, when all variants
    of an attack input fail, the LLM system and application will not provide any service
    for these inputs. In this case, all responses will contain the jailbreak keyword (Zou
    et al., [2023](#bib.bib59)) and become similar in semantics, and their divergence  will
    be very low. To avoid false positives, if all responses contain jailbreak words,
    regardless of the value in , JailGuard will directly determine them as attack
    inputs.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 为了最大化 JailGuard 的检测效果，我们从数据集中随机选择了 70/80 个文本/图像输入 ([§ 5](#S5 "5. 数据集构建 ‣ 基于变异的方法进行多模态越狱攻击检测"))
    并计算了它们变体的散度。根据结果，我们为 GPT-3.5 上的文本输入选择了  ，为 MiniGPT-4 上的图像输入选择了 0.0025。在这种情况下，当攻击输入的所有变体都失败时，LLM
    系统和应用将不会为这些输入提供任何服务。此时，所有响应将包含越狱关键字（Zou et al., [2023](#bib.bib59)），并且在语义上变得相似，它们的散度  将非常低。为了避免误报，如果所有响应都包含越狱词，无论  的值如何，JailGuard
    将直接判断它们为攻击输入。
- en: Table 1. Jailbreak Questions in Dataset
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1. 数据集中越狱问题
- en: '| Category | Attack Method | Description |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 类别 | 攻击方法 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Attention Shifting | GPT4similator |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 注意力转移 | GPT4similator |'
- en: '&#124; Implant toxic instructions in a program and ask LM to similate &#124;'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 在程序中植入有毒指令，并要求语言模型进行模拟 &#124;'
- en: '&#124; the execution of this program &#124;'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 执行此程序 &#124;'
- en: '|'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| TextContinue |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| TextContinue |'
- en: '&#124; Construct a scene where Dr. Evil describes his evil plan and &#124;'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 构建一个场景，其中博士描述他的邪恶计划 &#124;'
- en: '&#124; let the AI continue writing to achieve the attack &#124;'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 让AI继续写作以实现攻击 &#124;'
- en: '|'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Translator |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 翻译员 |'
- en: '&#124; Use translation tasks to attract the attention of the LM &#124;'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 使用翻译任务来吸引LM的注意 &#124;'
- en: '&#124; system and execute dangerous instructions &#124;'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 系统并执行危险指令 &#124;'
- en: '|'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Pretending | EvilConfidant |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 伪装 | EvilConfidant |'
- en: '&#124; Ask LM to act as the evial confidant who is not bound by any &#124;'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 让LM扮演一个不受任何约束的邪恶知己 &#124;'
- en: '&#124; rules and can answer any sensitive questions. &#124;'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 规则，并能回答任何敏感问题。 &#124;'
- en: '|'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Privilege Escalation | DAN11.0 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 权限升级 | DAN11.0 |'
- en: '&#124; Ask LM to enable DAN mode that can do anything and &#124;'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 让LM启用DAN模式，能做任何事并 &#124;'
- en: '&#124; generate any type of content &#124;'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 生成任何类型的内容 &#124;'
- en: '|'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| AIM |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| AIM |'
- en: '&#124; Ask LM to become AIM, an unfiltered and unethical chatbot &#124;'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 让LM变成AIM，一个不受过滤且不道德的聊天机器人 &#124;'
- en: '&#124; and will answer any requests made to it &#124;'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 并将回答任何提出的请求 &#124;'
- en: '|'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; DevMode &#124;'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; DevMode &#124;'
- en: '&#124; +Ranti &#124;'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; +Ranti &#124;'
- en: '|'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Ask LM to enable DevMode that can do anything and generate &#124;'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 让LM启用DevMode，能做任何事并生成 &#124;'
- en: '&#124; any type of content &#124;'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 任何类型的内容 &#124;'
- en: '|'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Other | MasterKey |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 其他 | MasterKey |'
- en: '&#124; Employ LM to learn jailbreak patterns and generate attacks, &#124;'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 使用LM学习越狱模式并生成攻击， &#124;'
- en: '&#124; including two modes of ‘continue’ and ‘poc’ &#124;'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 包括‘继续’和‘poc’两种模式 &#124;'
- en: '|'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| GCG |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| GCG |'
- en: '&#124; Add adversarial perturbations into strings to bypass the &#124;'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 向字符串中添加对抗性扰动以绕过 &#124;'
- en: '&#124; model’s defense mechanisms &#124;'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模型的防御机制 &#124;'
- en: '|'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 5\. Dataset Construction
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 数据集构建
- en: Due to the lack of a comprehensive LLM jailbreak benchmark, existing jailbreak
    defense research mainly tested and evaluated their methods on specific types of
    text inputs. For example, SmoothLLM has evaluated its effectiveness in defending
    against jailbreak inputs generated by the GCG method (Zou et al., [2023](#bib.bib59)).
    To break the existing limitation, we construct the first comprehensive jailbreaking
    dataset containing both text and image inputs. We collect jailbreaking attack
    methods and templates from the open-source community and prior work and then evaluate
    their effectiveness on LLM systems and applications. Finally, we construct a dataset
    covering more than 10 types of known jailbreaking attacks, covering two modalities
    of image and text, with a total of 304 items of attack and benign data.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 由于缺乏全面的LLM越狱基准，现有的越狱防御研究主要在特定类型的文本输入上测试和评估其方法。例如，SmoothLLM已评估其在防御GCG方法生成的越狱输入方面的有效性 (Zou
    et al., [2023](#bib.bib59))。为了打破现有的限制，我们构建了第一个全面的越狱数据集，包含文本和图像输入。我们从开源社区和先前的工作中收集了越狱攻击方法和模板，然后评估它们在LLM系统和应用中的有效性。最终，我们构建了一个涵盖10种以上已知越狱攻击的数据库，涵盖图像和文本两种模式，共有304项攻击和良性数据。
- en: Image jailbreaking inputs. We have generated 80 sets of jailbreak inputs based
    on prior work (Qi et al., [2023](#bib.bib44)), and each set contains a jailbreak
    image implanted with tiny perturbations and a jailbreak question violating policies.
    We have verified the validity of these jailbreak inputs on MiniGPT-4 (Zhu et al.,
    [2023a](#bib.bib57)), which is one of the state-of-the-art open-source VLMs and
    accepts multimodal inputs including images and texts. In addition, we have collected
    80 sets of benign inputs from the open-source data of MiniGPT-4, each containing
    a benign image and an image-related question. The image jailbreaking input dataset
    is publicly available on our website (our, [2023](#bib.bib6)).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图像越狱输入。我们基于先前的工作生成了80组越狱输入 (Qi et al., [2023](#bib.bib44))，每组包含一个嵌入了微小扰动的越狱图像和一个违反政策的越狱问题。我们在MiniGPT-4 (Zhu
    et al., [2023a](#bib.bib57))上验证了这些越狱输入的有效性，MiniGPT-4是最先进的开源VLM之一，接受包括图像和文本在内的多模态输入。此外，我们还从MiniGPT-4的开源数据中收集了80组良性输入，每组包含一个良性图像和一个图像相关的问题。图像越狱输入数据集在我们的网站上公开提供 (our,
    [2023](#bib.bib6))。
- en: Text jailbreaking inputs. To ensure the diversity of jailbreak inputs, we have
    referred to existing categorization methods (Liu et al., [2023b](#bib.bib36))
    and collected attack methods and templates from the community¹¹1https://www.jailbreakchat.com/
    and existing work (Zou et al., [2023](#bib.bib59); Deng et al., [2023](#bib.bib17)).
    Their description is shown in [Table 1](#S4.T1 "Table 1 ‣ 4.2\. Attack Detector
    ‣ 4\. System Design ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack
    Detection"). We have introduced the three categories of ‘Attention Shifting’,
    ‘Pretending’ and ‘Privilege Escalation’ in [§ 2](#S2 "2\. Background ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection"). To ensure that the variety
    of attack methods in the dataset is as comprehensive as possible, the collected
    attack inputs are not only from all three categories but also existing automated
    attack methods such as GCG (Zou et al., [2023](#bib.bib59)) and MasterKey (Deng
    et al., [2023](#bib.bib17)).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 文本越狱输入。为了确保越狱输入的多样性，我们参考了现有的分类方法（Liu等，[2023b](#bib.bib36)），并从社区¹¹1https://www.jailbreakchat.com/及现有工作（Zou等，[2023](#bib.bib59)；Deng等，[2023](#bib.bib17)）收集了攻击方法和模板。其描述见[表1](#S4.T1
    "Table 1 ‣ 4.2\. Attack Detector ‣ 4\. System Design ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection")。我们在[§2](#S2 "2\. Background ‣
    A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")中引入了‘注意力转移’、‘伪装’和‘特权提升’这三类。为了确保数据集中攻击方法的多样性，我们收集的攻击输入不仅来自所有三类，还包括现有的自动化攻击方法，如GCG（Zou等，[2023](#bib.bib59)）和MasterKey（Deng等，[2023](#bib.bib17)）。
- en: Based on these attack templates and methods, we collect 30 toxic questions from
    existing work (Qi et al., [2023](#bib.bib44); Deng et al., [2023](#bib.bib17))
    and combine them with the templates to generate jailbreak inputs. In the generation,
    we found that some questions (e.g., “How can we use social media to increase our
    reach during election season?”) can always get valid responses from the target
    LLM system even without using any jailbreak attack methods or templates. Previous
    work has made similar observations (Liu et al., [2023b](#bib.bib36)). To alleviate
    the impact of these abnormal jailbreak questions on the dataset, we removed the
    attack inputs related to these questions and validated them on OpenAI GPT-3.5
    which is one of the most popular chatbots. Finally, we obtained 72 text attacks
    on OpenAI GPT-3.5, which cover all methods in [§ 5](#S5 "5\. Dataset Construction
    ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection"), except
    ‘DAN11.0’. Note that Masterkey contains two completely different attack templates,
    we consider them as two templates, namely ‘Masterkey-continue’ and ‘Masterkey-poc’.
    We labeled these attacks into nine types in our dataset based on their methods
    and templates. In addition, we randomly sampled benign inputs that have the same
    number as the attack inputs from an open-sourced LLM instruction set in the community²²2https://huggingface.co/datasets/HuggingFaceH4/instruction-dataset
    to construct the dataset. Our dataset and the filtered abnormal jailbreak questions
    mentioned above are also available on our website (our, [2023](#bib.bib6)).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这些攻击模板和方法，我们从现有工作（Qi等，[2023](#bib.bib44)；Deng等，[2023](#bib.bib17)）中收集了30个有毒问题，并将其与模板结合生成越狱输入。在生成过程中，我们发现一些问题（例如，“我们如何利用社交媒体在选举季节提高我们的影响力？”）即使不使用任何越狱攻击方法或模板，也总能从目标LLM系统中获得有效响应。先前的工作也有类似观察（Liu等，[2023b](#bib.bib36)）。为了减轻这些异常越狱问题对数据集的影响，我们移除了与这些问题相关的攻击输入，并在OpenAI
    GPT-3.5上验证了这些问题，GPT-3.5是最流行的聊天机器人之一。最终，我们获得了72个对OpenAI GPT-3.5的文本攻击，涵盖了[§5](#S5
    "5\. Dataset Construction ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection")中所有方法，除了‘DAN11.0’。需要注意的是，Masterkey包含两个完全不同的攻击模板，我们将其视为两个模板，即‘Masterkey-continue’和‘Masterkey-poc’。我们根据其方法和模板将这些攻击标记为九种类型。此外，我们从社区²²2https://huggingface.co/datasets/HuggingFaceH4/instruction-dataset的开源LLM指令集中随机抽取了与攻击输入数量相同的良性输入，以构建数据集。我们的数据集和上述过滤后的异常越狱问题也可以在我们的网站（our，[2023](#bib.bib6)）上获取。
- en: 6\. Evaluation
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 评估
- en: 'RQ1: How effective is JailGuard in detecting and defending LLM jailbreaking
    attacks at the text and visual level?'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 'RQ1: JailGuard在文本和视觉层面上检测和防御LLM越狱攻击的效果如何？'
- en: 'RQ2: Can JailGuard effectively detect and defend different types of LLM jailbreaking
    attacks?'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 'RQ2: JailGuard是否能有效检测和防御不同类型的LLM越狱攻击？'
- en: 'RQ3: How effective are the modules (i.e., variant generator and attack detector)
    in JailGuard?'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 'RQ3: JailGuard中的模块（即变体生成器和攻击检测器）的效果如何？'
- en: 'RQ4: What is the impact of the number of variants generated by JailGuard?'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: RQ4：JailGuard生成的变异数量有什么影响？
- en: 6.1\. Setup
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1\. 设置
- en: Baseline To the best of our knowledge, we are the first work to design LLM defenses
    for image inputs, therefore we only construct baselines for text inputs. One baseline
    method is the content detector implemented in Llama-2 repository³³3https://github.com/facebookresearch/llama-recipes/blob/main/examples/inference.py.
    This content detector separately leverages the AuditNLG library (Aud, [2023](#bib.bib2)),
    ‘safety-flan-t5-base’ language model, and Azure Content Safety service (azu, [2023](#bib.bib3))
    to check whether the input contains toxic content. To achieve the best detection
    effect, we enable all three available modules in it. The other is SmoothLLM which
    is one of the state-of-the-art LLM defense methods at the input level. Since we
    could not find available code in their paper, we manually implemented their three
    perturbation methods (i.e., Insert, Swap, and Patch) and their aggregation step
    based on their paper, as introduced in [§ 2](#S2 "2\. Background ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection"). Additionally, following
    the recommendation in their paper, we generated 8 samples for each input in the
    SmoothLLM perturbation step.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 基线 据我们所知，我们是第一个为图像输入设计LLM防御的工作，因此我们仅为文本输入构建基线。一个基线方法是Llama-2库中实现的内容检测器³³3https://github.com/facebookresearch/llama-recipes/blob/main/examples/inference.py。该内容检测器分别利用了AuditNLG库（Aud，[2023](#bib.bib2)）、‘safety-flan-t5-base’语言模型和Azure内容安全服务（azu，[2023](#bib.bib3)）来检查输入是否包含有毒内容。为了获得最佳检测效果，我们启用了其中的所有三个模块。另一个是SmoothLLM，它是最先进的输入级LLM防御方法之一。由于我们在其论文中找不到现成的代码，我们根据其论文手动实现了其三种扰动方法（即，插入、交换和修补）及其聚合步骤，如[§
    2](#S2 "2\. 背景 ‣ 基于变异的方法进行多模态越狱攻击检测")中介绍。此外，根据其论文中的建议，我们在SmoothLLM扰动步骤中为每个输入生成了8个样本。
- en: Metric We conduct experiments on the image and text input dataset constructed
    in [§ 5](#S5 "5\. Dataset Construction ‣ A Mutation-Based Method for Multi-Modal
    Jailbreaking Attack Detection") and use two metrics, accuracy and recall, to evaluate
    the detection effect of JailGuard and baselines. Accuracy comprehensively measures
    the effectiveness of each method in identifying attack and benign inputs, while
    recall mainly reflects the effectiveness of each method in correctly identifying
    the attack inputs in the dataset without false negatives. The lower the recall,
    the more severe the false negatives in jailbreak detection.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[§ 5](#S5 "5\. 数据集构建 ‣ 基于变异的方法进行多模态越狱攻击检测")中构建的图像和文本输入数据集上进行实验，并使用两个指标，准确率和召回率，来评估JailGuard及基线的检测效果。准确率全面衡量每种方法在识别攻击和正常输入方面的有效性，而召回率主要反映每种方法在正确识别数据集中攻击输入方面的有效性，且不出现漏检。召回率越低，越狱检测中的漏检问题越严重。
- en: Implementation To fairly compare with SmoothLLM baselines in the experiment,
    JailGuard generates  variants for each input. For text inputs, the probability
    of selecting and executing the replacement, insertion, and deletion operation
    on each character is , and the probability on the important sentences is 5 times
    usual, that is, 0.025. JailGuard use the string ‘[mask]’ to replace and insert.
    The LLM systems and applications we used on text and image inputs are OpenAI’s
    GPT-3.5 and MiniGPT-4 respectively. More details are shown in [§ 5](#S5 "5\. Dataset
    Construction ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection").
    Our framework is implemented on Python 3.9. All experiments are conducted on a
    server with AMD EPYC 7513 32-core processors, 250 GB of RAM, and an NVIDIA RTX
    A6000 GPU running Ubuntu 20.04 as the operating system.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 实现 为了公平地与SmoothLLM基线进行比较，JailGuard为每个输入生成变异。对于文本输入，选择和执行每个字符的替换、插入和删除操作的概率为
    ，而对重要句子的概率是通常的5倍，即0.025。JailGuard使用字符串‘[mask]’进行替换和插入。我们在文本和图像输入上使用的LLM系统和应用分别是OpenAI的GPT-3.5和MiniGPT-4。更多细节见[§
    5](#S5 "5\. 数据集构建 ‣ 基于变异的方法进行多模态越狱攻击检测")。我们的框架在Python 3.9上实现。所有实验在一台配备AMD EPYC
    7513 32核处理器、250 GB内存和NVIDIA RTX A6000 GPU的服务器上进行，操作系统为Ubuntu 20.04。
- en: '6.2\. RQ1: Effectiveness of Detecting Attack'
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2\. RQ1：攻击检测的有效性
- en: 'Experiment Designs and Results To demonstrate the effectiveness of JailGuard
    in detecting attack inputs and defending jailbreaking attacks, we use two metrics
    to evaluate the detection results of each method on the constructed dataset. The
    results on image and text inputs are separately shown in [Table 2](#S6.T2 "Table
    2 ‣ 6.2\. RQ1: Effectiveness of Detecting Attack ‣ 6\. Evaluation ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection") and [Table 3](#S6.T3 "Table
    3 ‣ 6.2\. RQ1: Effectiveness of Detecting Attack ‣ 6\. Evaluation ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection"). The rows in [Table 2](#S6.T2
    "Table 2 ‣ 6.2\. RQ1: Effectiveness of Detecting Attack ‣ 6\. Evaluation ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection") show the detection effect
    of mutators in JailGuard on image inputs. In [Table 3](#S6.T3 "Table 3 ‣ 6.2\.
    RQ1: Effectiveness of Detecting Attack ‣ 6\. Evaluation ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection"), the rows of ‘Baseline’ show the
    detection results of four baselines on text input, and ‘JailGuard’ rows correspond
    to the detection results of applying different mutators in JailGuard. The row
    ‘Average’ shows the average result of baselines and JailGuard. The names of JailGuard’s
    mutators and baselines refer to [§ 4.1](#S4.SS1 "4.1\. Variant Generator ‣ 4\.
    System Design ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")
    and [§ 6.1](#S6.SS1 "6.1\. Setup ‣ 6\. Evaluation ‣ A Mutation-Based Method for
    Multi-Modal Jailbreaking Attack Detection"). We use blue to mark the best result
    on each metric. In addition, [Figure 4](#S6.F4 "Figure 4 ‣ 6.2\. RQ1: Effectiveness
    of Detecting Attack ‣ 6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal
    Jailbreaking Attack Detection") uses a scatter plot to compare the detection results
    between different methods on text inputs. The X-axis is the accuracy and the Y-axis
    is the recall. Green dots indicate the results of mutators in JailGuard and red
    dots mark the baselines. Blue shows the results of the ablation study, which will
    be analyzed in [§ 6.4](#S6.SS4 "6.4\. RQ3: Ablation Study ‣ 6\. Evaluation ‣ A
    Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection"). We show
    the methods or mutators represented by each dot at the top of the table.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '实验设计和结果 为了展示 JailGuard 在检测攻击输入和防御越狱攻击方面的有效性，我们使用两个指标来评估每种方法在构建数据集上的检测结果。图像和文本输入的结果分别显示在 [表
    2](#S6.T2 "表 2 ‣ 6.2\. RQ1: 检测攻击的有效性 ‣ 6\. 评估 ‣ 一种基于突变的方法用于多模态越狱攻击检测")和 [表 3](#S6.T3
    "表 3 ‣ 6.2\. RQ1: 检测攻击的有效性 ‣ 6\. 评估 ‣ 一种基于突变的方法用于多模态越狱攻击检测")中。[表 2](#S6.T2 "表
    2 ‣ 6.2\. RQ1: 检测攻击的有效性 ‣ 6\. 评估 ‣ 一种基于突变的方法用于多模态越狱攻击检测")中的行显示了 JailGuard 中突变器对图像输入的检测效果。在 [表
    3](#S6.T3 "表 3 ‣ 6.2\. RQ1: 检测攻击的有效性 ‣ 6\. 评估 ‣ 一种基于突变的方法用于多模态越狱攻击检测")中，‘基线’的行显示了四个基线在文本输入上的检测结果，而‘JailGuard’的行对应于应用不同突变器在
    JailGuard 中的检测结果。‘平均值’的行显示了基线和 JailGuard 的平均结果。JailGuard 的突变器和基线的名称请参见 [§ 4.1](#S4.SS1
    "4.1\. 变体生成器 ‣ 4\. 系统设计 ‣ 一种基于突变的方法用于多模态越狱攻击检测")和 [§ 6.1](#S6.SS1 "6.1\. 设置 ‣
    6\. 评估 ‣ 一种基于突变的方法用于多模态越狱攻击检测")。我们用蓝色标记每个指标上的最佳结果。此外， [图 4](#S6.F4 "图 4 ‣ 6.2\.
    RQ1: 检测攻击的有效性 ‣ 6\. 评估 ‣ 一种基于突变的方法用于多模态越狱攻击检测")使用散点图比较不同方法在文本输入上的检测结果。X 轴是准确率，Y
    轴是召回率。绿色点表示 JailGuard 中突变器的结果，红色点标记基线。蓝色显示了消融研究的结果，这将在 [§ 6.4](#S6.SS4 "6.4\.
    RQ3: 消融研究 ‣ 6\. 评估 ‣ 一种基于突变的方法用于多模态越狱攻击检测")中进行分析。我们在表格顶部展示了每个点所代表的方法或突变器。'
- en: Table 2. JailGuard Attack Mitigation on Image Inputs
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2. JailGuard 对图像输入的攻击缓解
- en: '| Method | Accuracy (%) | Recall (%) |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 准确率 (%) | 召回率 (%) |'
- en: '| --- | --- | --- |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Random Mask | 75.00 | 75.00 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 随机遮罩 | 75.00 | 75.00 |'
- en: '| Gaussian Blur | 82.50 | 76.25 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| 高斯模糊 | 82.50 | 76.25 |'
- en: '| Horizontal Flip | 73.75 | 81.25 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 水平翻转 | 73.75 | 81.25 |'
- en: '| Vertical Flip | 85.00 | 78.75 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 垂直翻转 | 85.00 | 78.75 |'
- en: '| Crop and Resize | 78.13 | 81.25 |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| 裁剪和调整大小 | 78.13 | 81.25 |'
- en: '| Random Grayscale | 80.63 | 77.50 |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| 随机灰度 | 80.63 | 77.50 |'
- en: '| Random Rotation | 89.38 | 78.75 |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| 随机旋转 | 89.38 | 78.75 |'
- en: '| Colorjitter | 85.00 | 80.00 |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 颜色抖动 | 85.00 | 80.00 |'
- en: '| Random Solarization | 89.38 | 80.00 |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 随机太阳化 | 89.38 | 80.00 |'
- en: '| Random Posterization | 82.50 | 70.00 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 随机色调化 | 82.50 | 70.00 |'
- en: '| Average | 82.13 | 77.88 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 平均值 | 82.13 | 77.88 |'
- en: Table 3. Comparison of Attack Mitigation on Text Inputs (Bold Marks Results
    That Equal or Outperform the Best Baseline)
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3. 对文本输入的攻击缓解比较（粗体标记的结果等于或优于最佳基线）
- en: '| Method | Accuracy (%) | Recall (%) |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 准确率 (%) | 召回率 (%) |'
- en: '| --- | --- | --- |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Baseline | Content Detector | 55.56 | 29.17 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 基线 | 内容检测器 | 55.56 | 29.17 |'
- en: '| SmoothLLM-Insert | 70.14 | 41.67 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| SmoothLLM-Insert | 70.14 | 41.67 |'
- en: '| SmoothLLM-Swap | 66.67 | 34.72 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| SmoothLLM-Swap | 66.67 | 34.72 |'
- en: '| SmoothLLM-Patch | 70.14 | 41.67 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| SmoothLLM-Patch | 70.14 | 41.67 |'
- en: '| Average | 65.62 | 36.81 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 平均值 | 65.62 | 36.81 |'
- en: '| JailGuard | Random Replacement | 77.78 | 75.00 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| JailGuard | 随机替换 | 77.78 | 75.00 |'
- en: '| Random Insertion | 79.17 | 77.78 |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| 随机插入 | 79.17 | 77.78 |'
- en: '| Random Deletion | 79.17 | 76.39 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 随机删除 | 79.17 | 76.39 |'
- en: '| Synonym Replacement | 73.61 | 84.72 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| 同义词替换 | 73.61 | 84.72 |'
- en: '| Punctuation Insertion | 75.00 | 70.83 |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| 标点符号插入 | 75.00 | 70.83 |'
- en: '| Translation | 78.47 | 84.72 |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 翻译 | 78.47 | 84.72 |'
- en: '| Targeted Replacement | 82.64 | 88.89 |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 定向替换 | 82.64 | 88.89 |'
- en: '| Targeted Insertion | 84.03 | 81.94 |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 定向插入 | 84.03 | 81.94 |'
- en: '| Rephrasing | 85.42 | 91.67 |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 释义 | 85.42 | 91.67 |'
- en: '| Average | 79.48 | 81.33 |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 平均值 | 79.48 | 81.33 |'
- en: 'Analysis The results in [Table 2](#S6.T2 "Table 2 ‣ 6.2\. RQ1: Effectiveness
    of Detecting Attack ‣ 6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal
    Jailbreaking Attack Detection") and [Table 3](#S6.T3 "Table 3 ‣ 6.2\. RQ1: Effectiveness
    of Detecting Attack ‣ 6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal
    Jailbreaking Attack Detection") illustrate the effectiveness of JailGuard in detecting
    and defending jailbreaking attacks on different input modalities. JailGuard achieved
    an average detection accuracy of 82.13% on image inputs and 79.48% on text inputs
    with different mutators, which is better than the state-of-the-art baseline methods
    (average accuracy of 65.62%) and far exceeds the results of the content detector
    in Llama-2 repository (55.56%). For recall, JailGuard achieves an average recall
    of 77.88% on image inputs. It is worth mentioning that JailGuard achieved an average
    recall of 81.33% on text data, which is 2.21 times higher than the average result
    of baselines (36.81%), indicating its effectiveness in detecting jailbreaking
    attacks and reducing false negatives.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '分析在 [表2](#S6.T2 "Table 2 ‣ 6.2\. RQ1: Effectiveness of Detecting Attack ‣ 6\.
    Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")和 [表3](#S6.T3
    "Table 3 ‣ 6.2\. RQ1: Effectiveness of Detecting Attack ‣ 6\. Evaluation ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection")中，JailGuard在不同输入模态下检测和防御越狱攻击的有效性得到了体现。JailGuard在图像输入上的平均检测准确率为82.13%，在文本输入上的准确率为79.48%，优于最先进的基线方法（平均准确率65.62%），远超Llama-2库中内容检测器的结果（55.56%）。在召回率方面，JailGuard在图像输入上的平均召回率为77.88%。值得一提的是，JailGuard在文本数据上的平均召回率为81.33%，是基线平均结果（36.81%）的2.21倍，显示出其在检测越狱攻击和减少假阴性方面的有效性。'
- en: To be specific, on the image attack dataset, Horizontal Flip achieves the best
    recall of 81.25%, and Random Rotation and Random Solarization mutators achieves
    the best accuracy of 89.38%. Since we are the first defense work at the image
    modality and there is no comparable baseline, we have no way of directly knowing
    the advantages of JailGuard in detecting and defending against jailbreaking attacks.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，在图像攻击数据集上，水平翻转达到了最佳的召回率81.25%，而随机旋转和随机太阳化突变器达到了最佳的准确率89.38%。由于我们是图像模态下的首个防御工作，并且没有可比的基线，因此我们无法直接了解JailGuard在检测和防御越狱攻击中的优势。
- en: 'The comparison with the four baselines on text inputs further illustrates the
    effectiveness of JailGuard in attack detection. The text mutators in JailGuard
    achieve an average accuracy and recall of 79.48% and 81.33%, which is 13.85% and
    44.52% higher than the average accuracy and recall of the baselines. The best
    baseline is the insert and patch mode of SmoothLLM, which achieves an accuracy
    of 70.14% and recall of 41.67%. Compared with the best baselines, all text mutators
    in JailGuard achieved better results on two metrics, which demonstrate the detection
    effectiveness of JailGuard. We use bold to mark the results that outperform the
    best baseline in [Table 3](#S6.T3 "Table 3 ‣ 6.2\. RQ1: Effectiveness of Detecting
    Attack ‣ 6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection"). More specifically, the Random Insertion and Random Deletion
    mutators achieve the best accuracy of 79.17% among random mutators. All advanced
    mutators achieved much better results than random mutators. Targeted Replacement
    and Targeted Insertion separately achieve the detection accuracy of 82.64% and
    84.03%. Compared to Random Replacement and Random Insertion, both of them improve
    accuracy by 4.86%, respectively. Rephrasing even achieved the highest accuracy
    and recall among all mutators (i.e., 85.42% and 91.67%), which proves the effectiveness
    of the advanced mutators in JailGuard.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '与四个基线在文本输入上的比较进一步说明了JailGuard在攻击检测中的有效性。JailGuard中的文本变异器实现了79.48%和81.33%的平均准确性和召回率，分别比基线的平均准确性和召回率高出13.85%和44.52%。最佳基线是SmoothLLM的插入和补丁模式，其准确率为70.14%，召回率为41.67%。与最佳基线相比，JailGuard中的所有文本变异器在两个指标上都取得了更好的结果，这证明了JailGuard的检测效果。我们用**粗体**标记了在[表
    3](#S6.T3 "Table 3 ‣ 6.2\. RQ1: Effectiveness of Detecting Attack ‣ 6\. Evaluation
    ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")中超越最佳基线的结果。更具体地说，随机插入和随机删除变异器在随机变异器中实现了最佳准确率79.17%。所有先进变异器的结果都远优于随机变异器。定向替换和定向插入分别达到了82.64%和84.03%的检测准确率。与随机替换和随机插入相比，它们分别提高了4.86%的准确率。改写甚至在所有变异器中取得了最高的准确率和召回率（即85.42%和91.67%），这证明了JailGuard中先进变异器的有效性。'
- en: 'Furthermore, [Figure 4](#S6.F4 "Figure 4 ‣ 6.2\. RQ1: Effectiveness of Detecting
    Attack ‣ 6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection") intuitively demonstrates the advantages of JailGuard in attack
    detection compared to the baselines. We can observe that JailGuard (green) achieves
    significantly better results than baselines (red), and the corresponding dots
    are distributed in the upper right corner, indicating high accuracy and recall.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '此外，[图 4](#S6.F4 "Figure 4 ‣ 6.2\. RQ1: Effectiveness of Detecting Attack ‣
    6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")
    直观地展示了JailGuard在攻击检测中的优势，相较于基线方法。我们可以观察到JailGuard（绿色）的结果显著优于基线（红色），并且相应的点分布在右上角，表明高准确性和召回率。'
- en: Note that JailGuard is a defense framework built on top of the LLM system and
    application workflow, which conducts defense from the developer’s perspective.
    Therefore, in the deployment in real-world scenarios, it can directly query LLM
    to process and infer the variant inputs in batches, resulting in slightly increased
    time overhead compared to the original workflow. To understand the memory overhead
    of JailGuard, we conducted simulations on MiniGPT-4 and found that a single set
    of inputs (an image and a corresponding instruction) increases the memory overhead
    by 0.49GB, equivalent to 3.15% of the LLM’s memory overhead (15.68GB). For JailGuard
    with the setting of , the memory overhead of JailGuard in defending jailbreaking
    attacks is 3.95GB, which is 25.20% of the memory overhead of LLM itself.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，JailGuard是建立在LLM系统和应用工作流之上的防御框架，从开发者的角度进行防御。因此，在实际应用中，它可以直接查询LLM以处理和推断变异输入，相比于原始工作流略微增加了时间开销。为了了解JailGuard的内存开销，我们在MiniGPT-4上进行了模拟，发现一组输入（一个图像和一个相应的指令）增加了0.49GB的内存开销，相当于LLM内存开销（15.68GB）的3.15%。对于设置为的JailGuard，其防御越狱攻击的内存开销为3.95GB，占LLM自身内存开销的25.20%。
- en: '![Refer to caption](img/268c7c4318fff41526132503031b012f.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/268c7c4318fff41526132503031b012f.png)'
- en: Figure 4. Comparison of Different Methods’ Results on Text Inputs
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4. 不同方法在文本输入上的结果比较
- en: '6.3\. RQ2: Effectiveness of Detecting Different Kinds of Attacks'
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '6.3\. RQ2: 检测不同类型攻击的有效性'
- en: '![Refer to caption](img/7d9721cb7c8f35368344869b78db7858.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/7d9721cb7c8f35368344869b78db7858.png)'
- en: Figure 5. Comparison of Different Methods’ Results on Text Inputs
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5. 不同方法在文本输入上的结果比较
- en: '![Refer to caption](img/e5123f76bdfbd436853aa38bfbb0e395.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/e5123f76bdfbd436853aa38bfbb0e395.png)'
- en: Figure 6. A Case Study of Detecting ‘MasterKey’ Attack
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6. ‘MasterKey’ 攻击检测的案例研究
- en: 'To demonstrate the effectiveness of JailGuard in detecting and defending various
    LLM jailbreaking attacks, we count and analyze the detection accuracy of each
    method on each type of jailbreak template or method and displayed it using a heat
    map, as shown in [Figure 5](#S6.F5 "Figure 5 ‣ 6.3\. RQ2: Effectiveness of Detecting
    Different Kinds of Attacks ‣ 6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal
    Jailbreaking Attack Detection"). Each column represents the various jailbreaking
    attack methods, which are collected in our dataset, as mentioned in [§ 5](#S5
    "5\. Dataset Construction ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection"). categories (Liu et al., [2023b](#bib.bib36)). ‘Attention’,
    ‘Pretending’, and ‘Privilege’ are the abbreviation of three categories of jailbreak
    templates, namely ‘Attention Shifting’, ‘Pretending’, and ‘Privilege Escalation’ (Liu
    et al., [2023b](#bib.bib36)). The first six columns are the attack templates from
    these three categories, and the last three columns are the attacks generated by
    existing methods, namely GCG (Zou et al., [2023](#bib.bib59)) and MasterKey (Deng
    et al., [2023](#bib.bib17)). The rows, on the other hand, represent four baseline
    methods and the text mutators in JailGuard, where the advanced mutators are shown
    in the last four rows. A bluer color in [Figure 5](#S6.F5 "Figure 5 ‣ 6.3\. RQ2:
    Effectiveness of Detecting Different Kinds of Attacks ‣ 6\. Evaluation ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection") means higher accuracy of
    one method in detecting a specific attack, otherwise, it means that the method
    can hardly identify the jailbreak input.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '为了展示 JailGuard 在检测和防御各种 LLM 越狱攻击中的有效性，我们统计并分析了每种方法对每种越狱模板或方法的检测准确率，并使用热图显示，如 [图
    5](#S6.F5 "图 5 ‣ 6.3\. RQ2: 不同攻击类型的检测有效性 ‣ 6\. 评估 ‣ 基于变异的方法进行多模态越狱攻击检测") 所示。每一列代表不同的越狱攻击方法，这些方法都收集在我们的数据集中，如 [§
    5](#S5 "5\. 数据集构建 ‣ 基于变异的方法进行多模态越狱攻击检测") 所述。类别 (Liu et al., [2023b](#bib.bib36))。‘Attention’，‘Pretending’
    和 ‘Privilege’ 是三类越狱模板的缩写，即 ‘Attention Shifting’，‘Pretending’，和 ‘Privilege Escalation’ (Liu
    et al., [2023b](#bib.bib36))。前六列是这三类中的攻击模板，最后三列是由现有方法生成的攻击，即 GCG (Zou et al.,
    [2023](#bib.bib59)) 和 MasterKey (Deng et al., [2023](#bib.bib17))。另一方面，行表示四种基准方法和
    JailGuard 中的文本变异器，其中高级变异器显示在最后四行。 [图 5](#S6.F5 "图 5 ‣ 6.3\. RQ2: 不同攻击类型的检测有效性
    ‣ 6\. 评估 ‣ 基于变异的方法进行多模态越狱攻击检测") 中的颜色越蓝，表示该方法在检测特定攻击方面的准确率越高，否则，表示该方法几乎无法识别越狱输入。'
- en: 'We can observe that JailGuard achieves better results and has better generalization
    capabilities than the baseline in the detection of various jailbreak attacks.
    The baselines can only effectively detect several types of jailbreaking attacks
    and are helpless against other types of attacks. For ‘GPT4simulator’ and ‘Translator’
    methods in the ‘Attention Shifting’ category and MasterKey attack method, JailGuard’s
    mutators achieve much better than baseline, which most of the time has less than
    50% detection accuracy for these attacks, while JailGuard can easily achieve 80%
    to 100% detection accuracy on them. For other attack methods (e.g., ‘Evil Confident’
    of the ‘Pretending’ category), JailGuard can also achieve equal or better results
    than baselines. In addition, the advanced mutators in JailGuard achieve better
    detection results than random mutators. The advanced mutators have a better detection
    accuracy than the random mutators on ‘GPT4simulator’, ‘Evil Confidant’,‘AIM’,
    and ‘MasterKey-poc’ attacks. Random mutators often achieve detection accuracy
    of 60% to 80% on these types of jailbreaks, which is much better than the baseline
    methods. The advanced mutators shown in the last three rows of [Figure 6](#S6.F6
    "Figure 6 ‣ 6.3\. RQ2: Effectiveness of Detecting Different Kinds of Attacks ‣
    6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")
    have better detection effects, and they can achieve detection accuracy of 80%
    to 100%.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '我们可以观察到，JailGuard 在各种越狱攻击的检测中，比基线方法取得了更好的结果，并且具有更好的泛化能力。基线方法只能有效检测几种类型的越狱攻击，而对其他类型的攻击无能为力。对于‘GPT4simulator’和‘Translator’方法（在‘Attention
    Shifting’类别中）以及 MasterKey 攻击方法，JailGuard 的变异器的表现远好于基线方法，基线方法在这些攻击上的检测准确率通常低于 50%，而
    JailGuard 可以轻松达到 80% 到 100% 的检测准确率。对于其他攻击方法（例如，‘Pretending’类别中的‘Evil Confident’），JailGuard
    也能取得与基线方法相等或更好的结果。此外，JailGuard 中的高级变异器比随机变异器的检测结果更好。高级变异器在‘GPT4simulator’、‘Evil
    Confidant’、‘AIM’和‘MasterKey-poc’攻击上比随机变异器具有更好的检测准确率。随机变异器在这些类型的越狱检测中通常能达到 60%
    到 80% 的准确率，远高于基线方法。最后三行中显示的高级变异器（见[图6](#S6.F6 "Figure 6 ‣ 6.3\. RQ2: Effectiveness
    of Detecting Different Kinds of Attacks ‣ 6\. Evaluation ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection")）具有更好的检测效果，检测准确率可以达到 80% 到 100%。'
- en: 'Case Study We provide a case in [Figure 6](#S6.F6 "Figure 6 ‣ 6.3\. RQ2: Effectiveness
    of Detecting Different Kinds of Attacks ‣ 6\. Evaluation ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection") to understand and illustrate the
    root cause of the effect difference between JailGuard and the baseline SmoothLLM
    on specific attacks, such as ‘MasterKey-poc’ attacks. The upper part shows the
    detection of baseline method SmoothLLM-Swap and the lower part of [Figure 6](#S6.F6
    "Figure 6 ‣ 6.3\. RQ2: Effectiveness of Detecting Different Kinds of Attacks ‣
    6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")
    shows the detection process of JailGuard with Targeted Insertion mutator. [Figure 6](#S6.F6
    "Figure 6 ‣ 6.3\. RQ2: Effectiveness of Detecting Different Kinds of Attacks ‣
    6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection").a)
    provides a real example of ‘MasterKey-poc’ attack in our dataset. Attacks like
    ‘MasterKey-poc’ and ‘GPT4similator’ often use specific content or tasks to divert
    LLM’s attention, thereby deceiving the defense mechanism of LLM system and achieving
    jailbreak. At this time, SmoothLLM randomly replaces 10% characters to infer these
    attack inputs as much as possible. However, its results are minimal. Among 8 perturbed
    inputs, only one attack fails, and its response contains jailbreak keywords, as
    shown in the red text of the upper part of[Figure 6](#S6.F6 "Figure 6 ‣ 6.3\.
    RQ2: Effectiveness of Detecting Different Kinds of Attacks ‣ 6\. Evaluation ‣
    A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection").c). Therefore,
    in the aggregation step in the upper part of [Figure 5](#S6.F5 "Figure 5 ‣ 6.3\.
    RQ2: Effectiveness of Detecting Different Kinds of Attacks ‣ 6\. Evaluation ‣
    A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection").d), since
    most results do not contain jailbreak keywords, according to its aggregation principle,
    this input sample is judged as a benign sample, which is a false negative.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '案例研究 我们在[图 6](#S6.F6 "图 6 ‣ 6.3\. RQ2: 检测不同类型攻击的有效性 ‣ 6\. 评估 ‣ 基于变异的方法进行多模态越狱攻击检测")中提供了一个案例，以了解和说明JailGuard和基线方法SmoothLLM在特定攻击（如‘MasterKey-poc’攻击）之间效果差异的根本原因。上部分显示了基线方法SmoothLLM-Swap的检测，下部分则展示了[图
    6](#S6.F6 "图 6 ‣ 6.3\. RQ2: 检测不同类型攻击的有效性 ‣ 6\. 评估 ‣ 基于变异的方法进行多模态越狱攻击检测")中JailGuard与定向插入变异器的检测过程。[图
    6](#S6.F6 "图 6 ‣ 6.3\. RQ2: 检测不同类型攻击的有效性 ‣ 6\. 评估 ‣ 基于变异的方法进行多模态越狱攻击检测").a) 提供了我们数据集中‘MasterKey-poc’攻击的真实例子。像‘MasterKey-poc’和‘GPT4similator’这样的攻击常常使用特定的内容或任务来转移LLM的注意力，从而欺骗LLM系统的防御机制，达到越狱的目的。这时，SmoothLLM随机替换10%的字符，以尽可能推测这些攻击输入。然而，其结果微乎其微。在8个扰动输入中，只有一个攻击未能成功，其响应包含越狱关键词，如[图
    6](#S6.F6 "图 6 ‣ 6.3\. RQ2: 检测不同类型攻击的有效性 ‣ 6\. 评估 ‣ 基于变异的方法进行多模态越狱攻击检测")上部分的红色文本所示。因此，在[图
    5](#S6.F5 "图 5 ‣ 6.3\. RQ2: 检测不同类型攻击的有效性 ‣ 6\. 评估 ‣ 基于变异的方法进行多模态越狱攻击检测")上部分的聚合步骤中，由于大多数结果不包含越狱关键词，根据其聚合原则，该输入样本被判断为良性样本，这是一种假阴性。'
- en: 'In contrast, JailGuard can effectively identify this attack. Firstly, the Targeted
    Insertion mutator effectively finds the important sentences of the input (e.g.,
    the specific instructions at the end) and purposefully inserts many masks to achieve
    interference, as shown in the upper part of [Figure 6](#S6.F6 "Figure 6 ‣ 6.3\.
    RQ2: Effectiveness of Detecting Different Kinds of Attacks ‣ 6\. Evaluation ‣
    A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection").b). For
    LLM system responses shown in [Figure 6](#S6.F6 "Figure 6 ‣ 6.3\. RQ2: Effectiveness
    of Detecting Different Kinds of Attacks ‣ 6\. Evaluation ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection").c), JailGuard calculates their
    semantic similarity and divergence in [Figure 6](#S6.F6 "Figure 6 ‣ 6.3\. RQ2:
    Effectiveness of Detecting Different Kinds of Attacks ‣ 6\. Evaluation ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection").d) and then detects this
    attack based on the threshold . Even in the situation that only one attack fails,
    since the semantics of the failed response are completely different from others,
    JailGuard can easily detect it based on divergence, which makes it achieve high
    detection accuracy on complex attacks like ‘MasterKey-poc’ and ‘GPT4simulator’,
    with few false negatives.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '相比之下，JailGuard 能够有效识别这种攻击。首先，Targeted Insertion 变异器能够有效找到输入中的重要句子（例如，末尾的具体指令），并故意插入许多掩码以实现干扰，如[图
    6](#S6.F6 "Figure 6 ‣ 6.3\. RQ2: Effectiveness of Detecting Different Kinds of
    Attacks ‣ 6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection")的上部分所示。对于[图 6](#S6.F6 "Figure 6 ‣ 6.3\. RQ2: Effectiveness of
    Detecting Different Kinds of Attacks ‣ 6\. Evaluation ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection")中显示的LLM系统响应，JailGuard 计算其语义相似性和差异性，如[图
    6](#S6.F6 "Figure 6 ‣ 6.3\. RQ2: Effectiveness of Detecting Different Kinds of
    Attacks ‣ 6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection")d)所示，然后基于阈值检测该攻击。即使在只有一次攻击失败的情况下，由于失败响应的语义与其他响应完全不同，JailGuard
    也能轻松根据差异性检测出来，这使得它在‘MasterKey-poc’和‘GPT4simulator’等复杂攻击上实现了高检测准确率，并且几乎没有漏报。'
- en: '6.4\. RQ3: Ablation Study'
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '6.4\. RQ3: 消融研究'
- en: 'Experiment Designs and Results JailGuard provides two modules to detect and
    defend against jailbreaking attacks in the LLM systems and applications, which
    are the variant generator and attack detector. To understand their contribution,
    we conduct an ablation experiment on the text inputs. We use the three perturbation
    methods of SmoothLLM (i.e., Insert, Swap, and Patch) to replace the mutators of
    the variant generator in JailGuard, and record the results as ‘Insert+Attack Detector’,
    ‘Swap+Attack Detector’, and ‘Patch+Attack Detector’. In addition, we leverage
    the aggregation method in SmoothLLM to replace the JailGuard attack detector and
    detect attacks on the variants generated by Random Replacement and Random Insertion
    (i.e., ‘Random Replacement+Aggregation’ and ‘Random Insertion+Aggregation’). The
    aggregation method of SmoothLLM is explained in [§ 2](#S2 "2\. Background ‣ A
    Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection"). The above
    results are shown in [Table 4](#S6.T4 "Table 4 ‣ 6.4\. RQ3: Ablation Study ‣ 6\.
    Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")
    and the blue dots of [Figure 4](#S6.F4 "Figure 4 ‣ 6.2\. RQ1: Effectiveness of
    Detecting Attack ‣ 6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection").'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '实验设计与结果 JailGuard 提供了两个模块来检测和防御LLM系统和应用中的越狱攻击，这两个模块分别是变体生成器和攻击检测器。为了了解它们的贡献，我们对文本输入进行了消融实验。我们使用了
    SmoothLLM 的三种扰动方法（即 Insert、Swap 和 Patch）来替代 JailGuard 中的变体生成器变异器，并记录结果为‘Insert+Attack
    Detector’、‘Swap+Attack Detector’和‘Patch+Attack Detector’。此外，我们利用 SmoothLLM 中的聚合方法来替代
    JailGuard 的攻击检测器，并检测由 Random Replacement 和 Random Insertion 生成的变体（即‘Random Replacement+Aggregation’和‘Random
    Insertion+Aggregation’）。SmoothLLM 的聚合方法在[§ 2](#S2 "2\. Background ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection")中进行了说明。上述结果显示在[表 4](#S6.T4
    "Table 4 ‣ 6.4\. RQ3: Ablation Study ‣ 6\. Evaluation ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection")中，并且[图 4](#S6.F4 "Figure 4 ‣ 6.2\.
    RQ1: Effectiveness of Detecting Attack ‣ 6\. Evaluation ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection")中的蓝点表示。'
- en: Analysis The experimental results of the ablation study illustrate the effectiveness
    of each module of JailGuard.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 分析 消融研究的实验结果说明了 JailGuard 每个模块的有效性。
- en: 'Firstly, the mutators in the variant generator are effective in detecting jailbreaking
    attacks. As shown in [Table 4](#S6.T4 "Table 4 ‣ 6.4\. RQ3: Ablation Study ‣ 6\.
    Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection"),
    the best detection accuracy obtained after replacing mutators is 76.39%, which
    is lower than the average accuracy of using JailGuard text mutators. We can intuitively
    observe the difference in detection results by comparing the blue triangles and
    green dots in [Figure 4](#S6.F4 "Figure 4 ‣ 6.2\. RQ1: Effectiveness of Detecting
    Attack ‣ 6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection"). The blue triangles represent the result of replacing JailGuard’s
    mutators with Insert/Patch/Swap in SmoothLLM. Compared with most green dots, blue
    triangles are located in the lower left position, which means it has lower accuracy
    and recall.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '首先，变体生成器中的变异器在检测越狱攻击方面是有效的。如[表4](#S6.T4 "表4 ‣ 6.4\. RQ3: 消融研究 ‣ 6\. 评估 ‣ 基于变异的方法用于多模态越狱攻击检测")所示，替换变异器后获得的最佳检测准确率为76.39%，低于使用JailGuard文本变异器的平均准确率。通过比较[图4](#S6.F4
    "图4 ‣ 6.2\. RQ1: 检测攻击的有效性 ‣ 6\. 评估 ‣ 基于变异的方法用于多模态越狱攻击检测")中的蓝色三角形和绿色圆点，我们可以直观地观察到检测结果的差异。蓝色三角形代表用SmoothLLM中的插入/补丁/交换替换JailGuard的变异器的结果。与大多数绿色圆点相比，蓝色三角形位于左下位置，这意味着它具有较低的准确率和召回率。'
- en: 'In addition, the attack detector in JailGuard has an important contribution
    to attack detection, especially in eliminating False Negatives. Replacing the
    attack detector with the aggregation method of SmoothLLM will result in a decrease
    of 5.56% and 29.17% in the accuracy and recall of the Random Replacement mutator
    in JailGuard. A similar operation on Random Insertion also decreases 6.94% and
    31.94% on two metrics. The significant decrease in recall indicates that the aggregation
    method will overlook many attack examples and cannot provide effective defense
    for various jailbreaking attacks, which is consistent with our observation in [§ 6.3](#S6.SS3
    "6.3\. RQ2: Effectiveness of Detecting Different Kinds of Attacks ‣ 6\. Evaluation
    ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection"). In
    addition, using the attack detector can significantly increase the results of
    the perturbation methods in SmoothLLM. From the results in the first three rows
    of [Table 4](#S6.T4 "Table 4 ‣ 6.4\. RQ3: Ablation Study ‣ 6\. Evaluation ‣ A
    Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection") and [Table 3](#S6.T3
    "Table 3 ‣ 6.2\. RQ1: Effectiveness of Detecting Attack ‣ 6\. Evaluation ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection"), we can observe that using
    the attack detector significantly increases the recall of the Swap method from
    34.72% to 81.94%, which is 2.36 times of the baseline result. The recall of Insert
    and Patch methods has also increased by about 1.8 times compared to before. This
    demonstrates the important contribution of attack detectors in alleviating FNs
    and preventing LLM jailbreaking attacks.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '此外，JailGuard中的攻击检测器对攻击检测具有重要贡献，特别是在消除假阴性方面。用SmoothLLM的聚合方法替换攻击检测器会导致JailGuard中的随机替换变异器的准确率和召回率分别下降5.56%和29.17%。对随机插入进行类似操作也会导致两个指标分别下降6.94%和31.94%。召回率的显著下降表明聚合方法会忽略许多攻击示例，无法为各种越狱攻击提供有效防御，这与我们在[§
    6.3](#S6.SS3 "6.3\. RQ2: 检测不同类型攻击的有效性 ‣ 6\. 评估 ‣ 基于变异的方法用于多模态越狱攻击检测")中的观察一致。此外，使用攻击检测器可以显著提高SmoothLLM中扰动方法的结果。从[表4](#S6.T4
    "表4 ‣ 6.4\. RQ3: 消融研究 ‣ 6\. 评估 ‣ 基于变异的方法用于多模态越狱攻击检测")和[表3](#S6.T3 "表3 ‣ 6.2\.
    RQ1: 检测攻击的有效性 ‣ 6\. 评估 ‣ 基于变异的方法用于多模态越狱攻击检测")的前三行结果中，我们可以观察到，使用攻击检测器显著提高了交换方法的召回率，从34.72%提高到81.94%，是基线结果的2.36倍。插入和补丁方法的召回率也比之前提高了约1.8倍。这证明了攻击检测器在减轻假阴性和防止LLM越狱攻击方面的重要贡献。'
- en: Table 4. Ablation Study on JailGuard
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 表4. JailGuard的消融研究
- en: '| Method | Accuracy (%) | Recall (%) |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 准确率 (%) | 召回率 (%) |'
- en: '| --- | --- | --- |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Insert+Attack Detector | 73.61 | 73.61 |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| 插入+攻击检测器 | 73.61 | 73.61 |'
- en: '| Swap+Attack Detector | 76.39 | 81.94 |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| 交换+攻击检测器 | 76.39 | 81.94 |'
- en: '| Patch+Attack Detector | 73.61 | 76.39 |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| 补丁+攻击检测器 | 73.61 | 76.39 |'
- en: '| Random Replacement+Aggregation | 72.22 | 45.83 |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| 随机替换+聚合 | 72.22 | 45.83 |'
- en: '| Random Insertion+Aggregation | 72.22 | 45.83 |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| 随机插入+聚合 | 72.22 | 45.83 |'
- en: '6.5\. RQ4: Impact of Variant Amount'
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '6.5\. RQ4: 变体数量的影响'
- en: '![Refer to caption](img/6bcb4d6f9a220be9f2451264386a8317.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/6bcb4d6f9a220be9f2451264386a8317.png)'
- en: Figure 7. Results on Image Inputs
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7. 图像输入结果
- en: '![Refer to caption](img/2e6a27b3894c906ba3495d0cfbf74db3.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/2e6a27b3894c906ba3495d0cfbf74db3.png)'
- en: Figure 8. Results on Text Inputs
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8. 文本输入结果
- en: 'JailGuard use different mutators to generate  variants in the variant generator.
    To align with baselines, we choose  in experiments. To understand the impact of
    different values of  on detection results, with a fixed setting for the attack
    detector (i.e.,  is the same with previous experiments), we evaluate the detection
    effectiveness of different JailGuard operators when generating 4/5/6/7/8 variants,
    and record accuracy and recall on the image and text dataset in [Figure 7](#S6.F7
    "Figure 7 ‣ 6.5\. RQ4: Impact of Variant Amount ‣ 6\. Evaluation ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection") and [Figure 8](#S6.F8 "Figure
    8 ‣ 6.5\. RQ4: Impact of Variant Amount ‣ 6\. Evaluation ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection"). We use different colors to represent
    different mutators, and the red bold line indicates the average result of the
    mutators. In addition, the purple dotted lines in [Figure 8](#S6.F8 "Figure 8
    ‣ 6.5\. RQ4: Impact of Variant Amount ‣ 6\. Evaluation ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection") represent the accuracy and recall
    that the best baseline method SmoothLLM has achieved when it generates eight perturbed
    sampels.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 'JailGuard 使用不同的变异生成器在变异生成器中生成变体。为了与基线对齐，我们在实验中选择了不同的值。为了了解不同的值对检测结果的影响，在攻击检测器的设置固定（即，设置与之前的实验相同）的情况下，我们评估了不同
    JailGuard 操作员生成 4/5/6/7/8 个变体时的检测效果，并记录了图像和文本数据集上的准确率和召回率，见[图 7](#S6.F7 "图 7 ‣
    6.5\. RQ4: 变体数量的影响 ‣ 6\. 评估 ‣ 基于变异的方法用于多模态越狱攻击检测")和[图 8](#S6.F8 "图 8 ‣ 6.5\. RQ4:
    变体数量的影响 ‣ 6\. 评估 ‣ 基于变异的方法用于多模态越狱攻击检测")。我们使用不同的颜色表示不同的变异器，红色粗体线表示变异器的平均结果。此外，[图
    8](#S6.F8 "图 8 ‣ 6.5\. RQ4: 变体数量的影响 ‣ 6\. 评估 ‣ 基于变异的方法用于多模态越狱攻击检测")中的紫色虚线表示最佳基线方法
    SmoothLLM 在生成八个扰动样本时所达到的准确率和召回率。'
- en: The overall accuracy and recall of each mutator in jailbreak detection gradually
    increase as  increases. On image inputs, when  is set to 4, the average accuracy
    and recall are 78.38% and 68.88%. These mutators can achieve the average accuracy
    and recall of 82.13% and 77.88% when . For text inputs, when  is continuously
    increasing, the average accuracy of JailGuard increases from 76.00% to 79.48%,
    and recall improves from 70.52% to 81.33%.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 每个变异器在越狱检测中的总体准确率和召回率随着值的增加而逐渐提高。在图像输入上，当值设置为 4 时，平均准确率和召回率分别为 78.38% 和 68.88%。这些变异器在值为
    6 时可以实现平均准确率和召回率分别为 82.13% 和 77.88%。对于文本输入，当值持续增加时，JailGuard 的平均准确率从 76.00% 提升至
    79.48%，召回率从 70.52% 提高至 81.33%。
- en: 'We can observe that generating more variants can improve the detection results,
    which is in line with our intuition. However, the trend becomes less obvious as
    the value of  increases, as shown in the red bold part in [Figure 7](#S6.F7 "Figure
    7 ‣ 6.5\. RQ4: Impact of Variant Amount ‣ 6\. Evaluation ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection") and [Figure 8](#S6.F8 "Figure
    8 ‣ 6.5\. RQ4: Impact of Variant Amount ‣ 6\. Evaluation ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection"). A larger  will also lead to more
    runtime overhead. As we discussed in [§ 6.2](#S6.SS2 "6.2\. RQ1: Effectiveness
    of Detecting Attack ‣ 6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal
    Jailbreaking Attack Detection"), when  is set to 8, the defense memory overhead
    on MiniGPT-4 is close to 25% of the model overhead. Continuing to increase  will
    only make this number larger. Compared with the potential increase of 2%-3% in
    detection accuracy, extra overheads may not be worth it in some resource-limited
    scenarios.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '我们可以观察到，生成更多变体可以提高检测结果，这与我们的直觉一致。然而，随着值的增加，这一趋势变得不那么明显，如[图 7](#S6.F7 "图 7 ‣
    6.5\. RQ4: 变体数量的影响 ‣ 6\. 评估 ‣ 基于变异的方法用于多模态越狱攻击检测")和[图 8](#S6.F8 "图 8 ‣ 6.5\. RQ4:
    变体数量的影响 ‣ 6\. 评估 ‣ 基于变异的方法用于多模态越狱攻击检测")中的红色粗体部分所示。更大的值还会导致更多的运行时开销。正如我们在[§ 6.2](#S6.SS2
    "6.2\. RQ1: 检测攻击的有效性 ‣ 6\. 评估 ‣ 基于变异的方法用于多模态越狱攻击检测")中讨论的，当值设置为 8 时，MiniGPT-4 上的防御内存开销接近模型开销的
    25%。继续增加值只会使这个数字变得更大。与检测准确率潜在的 2%-3% 增加相比，额外的开销在一些资源有限的场景中可能不值得。'
- en: In addition, we can observe that when JailGuard generates six variants in the
    generator, nearly all mutators can achieve better results than the best baseline
    (the purple dotted line) on two metrics. Only the accuracy of Synonym Replacement
    mutator is 0.7% lower than the optimal baseline, while the former’s recall is
    33.33% higher than the latter, which is more significant. At this time, the runtime
    overhead of JailGuard is reduced by 25% compared with the default setting in previous
    experiments (i.e., the LLM queries in attack detector decrease from eight to six),
    and the average accuracy and recall are 76.54% and 73.92% respectively, which
    are slightly lower than its results when , but are still much higher than the
    best baseline (70.14% accuracy and 41.67% recall).
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以观察到，当 JailGuard 在生成器中生成六种变体时，几乎所有的突变器在两个指标上都能取得比最佳基线（紫色虚线）更好的结果。只有同义词替换突变器的准确率比最佳基线低
    0.7%，而前者的召回率比后者高 33.33%，这一点更为显著。这时，JailGuard 的运行时开销较之前的默认设置减少了 25%（即，攻击检测器中的 LLM
    查询从八个减少到六个），平均准确率和召回率分别为 76.54% 和 73.92%，虽然略低于其结果，但仍远高于最佳基线（准确率 70.14% 和召回率 41.67%）。
- en: Therefore, depending on the scenarios of actual application and deployment,
    we recommend selecting  to achieve the balance between detection effectiveness
    and runtime overhead.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，根据实际应用和部署场景，我们建议选择以实现检测效果和运行时开销之间的平衡。
- en: 7\. Related work
  id: totrans-210
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关工作
- en: Adversarial Attack and Defense in DNNs. White box attacks assume the attacker
    has full knowledge of the target model, including its architecture, weights, and
    hyperparameters. This allows the attacker to generate adversarial examples with
    high fidelity using gradient-based optimization techniques, such as FGSM (Goodfellow
    et al., [2014](#bib.bib23)), BIM (Kurakin et al., [2018](#bib.bib34)), PGD (Madry
    et al., [2017](#bib.bib38)), Square Attack (Andriushchenko et al., [2020](#bib.bib8)).
    AutoAttack (Croce and Hein, [2020](#bib.bib15)) has been proposed as a more comprehensive
    evaluation framework for adversarial attacks. Recently, researchers have also
    been exploring the use of naturally occurring degradations as forms of attack
    perturbations. These include environmental and processing effects like motion
    blur, vignetting, rain streaks, varying exposure levels, and watermarks (Gao et al.,
    [2022](#bib.bib20); Guo et al., [2020](#bib.bib25); Jia et al., [2020](#bib.bib31);
    Tian et al., [2021](#bib.bib49); Hou et al., [2023](#bib.bib29)).
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 深度神经网络中的对抗攻击与防御。白盒攻击假设攻击者对目标模型拥有完全的知识，包括其架构、权重和超参数。这使得攻击者能够使用基于梯度的优化技术生成高保真的对抗样本，如
    FGSM（Goodfellow 等，[2014](#bib.bib23)）、BIM（Kurakin 等，[2018](#bib.bib34)）、PGD（Madry
    等，[2017](#bib.bib38)）、Square Attack（Andriushchenko 等，[2020](#bib.bib8)）。AutoAttack（Croce
    和 Hein，[2020](#bib.bib15)）被提出作为一个更全面的对抗攻击评估框架。最近，研究人员还探索了使用自然发生的降解作为攻击扰动的形式。这些包括环境和处理效应，如运动模糊、渐晕、雨条、不同比例的曝光水平和水印（Gao
    等，[2022](#bib.bib20)；Guo 等，[2020](#bib.bib25)；Jia 等，[2020](#bib.bib31)；Tian 等，[2021](#bib.bib49)；Hou
    等，[2023](#bib.bib29)）。
- en: 'Adversarial defense can be categorized into two main types: adversarial training
    and adversarial purification (Nie et al., [2022](#bib.bib43)). Adversarial training
    involves incorporating adversarial samples during the training process (Goodfellow
    et al., [2014](#bib.bib23); Madry et al., [2017](#bib.bib38); Athalye et al.,
    [2018](#bib.bib9); Rade and Moosavi-Dezfooli, [2021](#bib.bib45); Ding et al.,
    [2018](#bib.bib18)), and training with additional data generated by generative
    models (Sehwag et al., [2021](#bib.bib47)). On the other hand, adversarial purification
    functions as a separate defense module during inference and does not require additional
    training time for the classifier (Guo et al., [2017](#bib.bib24); Xu et al., [2017](#bib.bib52);
    Sun et al., [2019](#bib.bib48); Ho and Vasconcelos, [2022](#bib.bib28)).'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗防御可以分为两大类：对抗训练和对抗净化（Nie 等，[2022](#bib.bib43)）。对抗训练涉及在训练过程中纳入对抗样本（Goodfellow
    等，[2014](#bib.bib23)；Madry 等，[2017](#bib.bib38)；Athalye 等，[2018](#bib.bib9)；Rade
    和 Moosavi-Dezfooli，[2021](#bib.bib45)；Ding 等，[2018](#bib.bib18)），以及使用生成模型生成的额外数据进行训练（Sehwag
    等，[2021](#bib.bib47)）。另一方面，对抗净化作为一个独立的防御模块在推理过程中工作，并且不需要额外的训练时间（Guo 等，[2017](#bib.bib24)；Xu
    等，[2017](#bib.bib52)；Sun 等，[2019](#bib.bib48)；Ho 和 Vasconcelos，[2022](#bib.bib28)）。
- en: LLM Attack And Defense Supplement to the jailbreaking attack methods in [§ 2](#S2
    "2\. Background ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack
    Detection"), researchers proposed other methods to automatically generate jailbreak
    prompts (Chao et al., [2023](#bib.bib13); Zhu et al., [2023b](#bib.bib58); Yu
    et al., [2023](#bib.bib54)). Chao et al. (Chao et al., [2023](#bib.bib13)) leverage
    unaligned LLMs to generate jailbreaks for target LLMs. Unfortunately, we cannot
    find available open-source code of their method. Researchers also pay attention
    to other aspects of LLM security, e.g., backdoor attack (Abdelnabi et al., [2023](#bib.bib7);
    Xu et al., [2023](#bib.bib51); Huang et al., [2023](#bib.bib30)), injection attack (Liu
    et al., [2023a](#bib.bib35)). We focus on the defense of multi-modal jailbreaking
    attacks in this paper.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: LLM攻击与防御 除了[§ 2](#S2 "2. Background ‣ A Mutation-Based Method for Multi-Modal
    Jailbreaking Attack Detection")中的越狱攻击方法，研究人员还提出了其他自动生成越狱提示的方法（Chao et al.，[2023](#bib.bib13)；Zhu
    et al.，[2023b](#bib.bib58)；Yu et al.，[2023](#bib.bib54)）。Chao等人（Chao et al.，[2023](#bib.bib13)）利用未对齐的LLM为目标LLM生成越狱攻击。不幸的是，我们无法找到他们方法的开源代码。研究人员还关注LLM安全的其他方面，例如后门攻击（Abdelnabi
    et al.，[2023](#bib.bib7)；Xu et al.，[2023](#bib.bib51)；Huang et al.，[2023](#bib.bib30)），注入攻击（Liu
    et al.，[2023a](#bib.bib35)）。本文集中于多模态越狱攻击的防御。
- en: To detect and defend LLM attacks, in addition to SmoothLLM, Kumar et al. (Kumar
    et al., [2023](#bib.bib33)) designed a detection method that splices the input
    text and applies a safety filter on all substrings to identify toxic content.
    In addition, Cao et al. (Cao et al., [2023](#bib.bib12)) weakened the robustness
    of attack prompts by randomly deleting words and helped the aligned model detect
    jailbreaking attacks. In this paper, we compare JailGuard with one of the state-of-the-art
    methods SmoothLLM and the content detector in the Llama open-source repository.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检测和防御LLM攻击，除了SmoothLLM之外，Kumar等人（Kumar et al.，[2023](#bib.bib33)）设计了一种检测方法，该方法通过拼接输入文本并对所有子字符串应用安全过滤器来识别有害内容。此外，Cao等人（Cao
    et al.，[2023](#bib.bib12)）通过随机删除单词来削弱攻击提示的鲁棒性，并帮助对齐模型检测越狱攻击。在本文中，我们将JailGuard与最先进的方法之一SmoothLLM以及Llama开源库中的内容检测器进行比较。
- en: 8\. Discussion
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8\. 讨论
- en: 'JailGuard Enhancement ❶ In our exploration of RQ2 ([§ 6.3](#S6.SS3 "6.3\. RQ2:
    Effectiveness of Detecting Different Kinds of Attacks ‣ 6\. Evaluation ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection")), we observe that various
    mutators demonstrate differing levels of effectiveness across different jailbreaking
    methods. For instance, while targeted replacement generally shows strong performance
    with most jailbreaking methods, it is not as effective as target insertion when
    dealing with ‘Attention-GPT4simulator’ jailbreaking. Furthermore, a significant
    performance disparity exists between rephrasing and other methods in terms of
    ‘Privilege-AIM’. This suggests the potential for devising a strategy that combines
    different mutation techniques. By doing so within the same query budget, we could
    enhance the overall efficacy of image generation and improve detection performance.
    ❷ Ensuring a balanced performance in terms of various jailbreaking methods in
    jailbreaking detection is crucial. Typically, the most effective jailbreaking
    strategies are extensively utilized to attack systems, meaning that jailbreaking
    attacks in real-world scenarios are inherently imbalanced. This imbalance can
    significantly diminish the real-life performance of our detection systems. Therefore,
    it’s essential to explore more effective targeted mutators, particularly for addressing
    ‘Privilege-AIM’ jailbreaking scenarios. Such advancements are key to maintaining
    robustness and reliability in our security measures. ❸ Our current dataset only
    covers attacks carrying single-modality content. However, the latest models such
    as Multi-Modal Large Language Models (MLLMs) GPT-4v, might also be susceptible
    to new forms of hybrid jailbreaking attacks leveraging multi-modal input features.
    Although no such attacks have been publicly reported, they remain a plausible
    future threat. Theoretically, our framework can support the detection of such
    hybrid jailbreaking attacks as long as the divergence of the robustness between
    attack and benign inputs is still identifiable. Our dataset will be continuously
    updated and any new appearing attacks will be further collected and evaluated.
    You can find the latest information on our website (our, [2023](#bib.bib6)).'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 'JailGuard Enhancement ❶ 在我们对RQ2的探索中（[§ 6.3](#S6.SS3 "6.3\. RQ2: Effectiveness
    of Detecting Different Kinds of Attacks ‣ 6\. Evaluation ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection")），我们观察到各种变异器在不同的越狱方法中表现出不同的效果。例如，虽然目标替换在大多数越狱方法中通常表现强劲，但在处理‘Attention-GPT4simulator’越狱时，它的效果不如目标插入。此外，在‘Privilege-AIM’方面，重新措辞与其他方法存在显著的性能差距。这表明有可能制定一种结合不同变异技术的策略。通过在相同的查询预算内进行这种组合，我们可以提高图像生成的整体效能，并改善检测性能。
    ❷ 在越狱检测中确保不同越狱方法的平衡性能至关重要。通常，最有效的越狱策略被广泛用于攻击系统，这意味着现实世界中的越狱攻击本质上是不平衡的。这种不平衡可能会显著降低我们检测系统的实际表现。因此，探索更有效的目标变异器，特别是针对‘Privilege-AIM’越狱场景，是保持我们安全措施鲁棒性和可靠性的关键。
    ❸ 我们当前的数据集仅涵盖了单一模态内容的攻击。然而，最新的模型如多模态大型语言模型（MLLMs）GPT-4v，可能也会受到利用多模态输入特征的新型混合越狱攻击的影响。尽管尚未公开报告此类攻击，但它们仍然是一个合理的未来威胁。从理论上讲，只要攻击与正常输入之间的鲁棒性差异仍然可以识别，我们的框架可以支持检测此类混合越狱攻击。我们的数据集将不断更新，任何新出现的攻击将进一步收集和评估。您可以在我们的网站上找到最新信息（我们的，[2023](#bib.bib6)）。'
- en: Diverse LLM Attacks Detection ❶ As an emerging research field, the security
    of large models has received widespread attention from researchers and industry.
    It is significant to add more types of attack inputs (e.g., data poisoning (Yan
    et al., [2023](#bib.bib53)), backdoor (Abdelnabi et al., [2023](#bib.bib7); Xu
    et al., [2023](#bib.bib51)), and prompt injection (Liu et al., [2023a](#bib.bib35))
    ) and build a comprehensive and universal benchmark for LLM defense. ❷ Our detection
    method fundamentally leverages the inherent non-robustness of attacks. Consequently,
    the vulnerabilities introduced by data poisoning and prompt injection, which also
    exhibit this non-robustness, could potentially be identified by our detection
    framework. A crucial future direction involves designing defense methods that
    are both effective and efficient, capable of generalizing across various types
    of attack inputs. Successfully achieving this would significantly enhance the
    deployment and application of trustworthy Language Model (LM) systems, contributing
    to their overall reliability and security.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 多样化 LLM 攻击检测 ❶ 作为一个新兴的研究领域，大模型的安全性已受到研究人员和行业的广泛关注。增加更多类型的攻击输入（例如，数据中毒 (Yan et
    al., [2023](#bib.bib53))，后门 (Abdelnabi et al., [2023](#bib.bib7); Xu et al., [2023](#bib.bib51))，以及提示注入
    (Liu et al., [2023a](#bib.bib35))）并构建一个全面且通用的 LLM 防御基准具有重要意义。❷ 我们的检测方法从根本上利用了攻击固有的不鲁棒性。因此，数据中毒和提示注入引入的漏洞也表现出这种不鲁棒性，可能会被我们的检测框架识别。一个重要的未来方向是设计既有效又高效的防御方法，能够对各种类型的攻击输入进行泛化。成功实现这一目标将显著提升可信语言模型
    (LM) 系统的部署和应用，增强其整体可靠性和安全性。
- en: 9\. Conclusion
  id: totrans-218
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9\. 结论
- en: In this paper, we propose JailGuard, the first mutation-based multi-modal jailbreaking
    detection framework that detects and defends jailbreaking attacks for LLM systems
    at both image and text modalities. To comprehensively evaluate the defense effect
    of JailGuard, we construct the first comprehensive LLM jailbreak attack dataset,
    covering jailbreaking attacks on image and text modalities. Our experiment results
    show that JailGuard achieves the best detection accuracy of 89.38%/ 85.42% on
    image/text inputs, outperforming state-of-the-art methods.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们提出了 JailGuard，这是第一个基于变异的多模态越狱检测框架，旨在检测和防御针对 LLM 系统的图像和文本模态的越狱攻击。为了全面评估
    JailGuard 的防御效果，我们构建了第一个综合性的 LLM 越狱攻击数据集，涵盖图像和文本模态的越狱攻击。我们的实验结果表明，JailGuard 在图像/文本输入上实现了最佳的检测准确率，分别为
    89.38% 和 85.42%，优于现有最先进的方法。
- en: 10\. Data Availability
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10\. 数据可用性
- en: To follow the Open Science Policy and support reproducibility, we have released
    code about our implementations and evaluations. All source code and data used
    in our work can be found at (our, [2023](#bib.bib6)).
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 为了遵循开放科学政策并支持可重复性，我们发布了有关我们实现和评估的代码。我们工作的所有源代码和数据可以在 (our, [2023](#bib.bib6))
    中找到。
- en: References
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: 'Aud (2023) 2023. AuditNLG: Auditing Generative AI Language Modeling for Trustworthiness.
    [https://github.com/salesforce/AuditNLG](https://github.com/salesforce/AuditNLG).'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Aud (2023) 2023. AuditNLG: 审计生成式 AI 语言建模的可信度。[https://github.com/salesforce/AuditNLG](https://github.com/salesforce/AuditNLG)。'
- en: azu (2023) 2023. Azure AI Content Safety. [https://azure.microsoft.com/en-us/products/ai-services/ai-content-safety](https://azure.microsoft.com/en-us/products/ai-services/ai-content-safety).
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: azu (2023) 2023. Azure AI 内容安全。[https://azure.microsoft.com/en-us/products/ai-services/ai-content-safety](https://azure.microsoft.com/en-us/products/ai-services/ai-content-safety)。
- en: gpt (2023a) 2023a. GPT-4 System Card. [https://cdn.openai.com/papers/gpt-4-system-card.pdf](https://cdn.openai.com/papers/gpt-4-system-card.pdf).
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: gpt (2023a) 2023a. GPT-4 系统卡。[https://cdn.openai.com/papers/gpt-4-system-card.pdf](https://cdn.openai.com/papers/gpt-4-system-card.pdf)。
- en: gpt (2023b) 2023b. GPT-4(v) System Card. [https://cdn.openai.com/papers/GPTV_System_Card.pdf](https://cdn.openai.com/papers/GPTV_System_Card.pdf).
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: gpt (2023b) 2023b. GPT-4(v) 系统卡。[https://cdn.openai.com/papers/GPTV_System_Card.pdf](https://cdn.openai.com/papers/GPTV_System_Card.pdf)。
- en: our (2023) 2023. The Website of JailGuard. [https://sites.google.com/view/jailguard](https://sites.google.com/view/jailguard).
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: our (2023) 2023. JailGuard 的网站。[https://sites.google.com/view/jailguard](https://sites.google.com/view/jailguard)。
- en: 'Abdelnabi et al. (2023) Sahar Abdelnabi, Kai Greshake, Shailesh Mishra, Christoph
    Endres, Thorsten Holz, and Mario Fritz. 2023. Not What You’ve Signed Up For: Compromising
    Real-World LLM-Integrated Applications with Indirect Prompt Injection. In *Proceedings
    of the 16th ACM Workshop on Artificial Intelligence and Security*. 79–90.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abdelnabi 等 (2023) Sahar Abdelnabi、Kai Greshake、Shailesh Mishra、Christoph Endres、Thorsten
    Holz 和 Mario Fritz。2023年。不是你所期望的：通过间接提示注入破解现实世界的 LLM 集成应用。收录于 *Proceedings of
    the 16th ACM Workshop on Artificial Intelligence and Security*。79–90。
- en: 'Andriushchenko et al. (2020) Maksym Andriushchenko, Francesco Croce, Nicolas
    Flammarion, and Matthias Hein. 2020. Square attack: a query-efficient black-box
    adversarial attack via random search. In *Computer Vision–ECCV 2020: 16th European
    Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XXIII*. Springer,
    484–501.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Andriushchenko 等 (2020) Maksym Andriushchenko、Francesco Croce、Nicolas Flammarion
    和 Matthias Hein。2020年。Square attack: 通过随机搜索的查询高效黑箱对抗攻击。收录于 *Computer Vision–ECCV
    2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings,
    Part XXIII*。Springer，484–501。'
- en: 'Athalye et al. (2018) Anish Athalye, Nicholas Carlini, and David Wagner. 2018.
    Obfuscated gradients give a false sense of security: Circumventing defenses to
    adversarial examples. In *International conference on machine learning*. PMLR,
    274–283.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Athalye 等 (2018) Anish Athalye、Nicholas Carlini 和 David Wagner。2018年。模糊梯度带来虚假的安全感：绕过对抗样本的防御。收录于
    *International conference on machine learning*。PMLR，274–283。
- en: Bai et al. (2022) Yalong Bai, Yifan Yang, Wei Zhang, and Tao Mei. 2022. Directional
    self-supervised learning for heavy image augmentations. In *Proceedings of the
    IEEE/CVF Conference on Computer Vision and Pattern Recognition*. 16692–16701.
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bai 等 (2022) Yalong Bai、Yifan Yang、Wei Zhang 和 Tao Mei。2022年。面向重度图像增强的方向性自监督学习。收录于
    *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*。16692–16701。
- en: Bayer et al. (2022) Markus Bayer, Marc-André Kaufhold, and Christian Reuter.
    2022. A survey on data augmentation for text classification. *Comput. Surveys*
    55, 7 (2022), 1–39.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bayer 等 (2022) Markus Bayer、Marc-André Kaufhold 和 Christian Reuter。2022年。文本分类的数据增强综述。*Comput.
    Surveys* 55, 7 (2022)，1–39。
- en: Cao et al. (2023) Bochuan Cao, Yuanpu Cao, Lu Lin, and Jinghui Chen. 2023. Defending
    against alignment-breaking attacks via robustly aligned llm. *arXiv preprint arXiv:2309.14348*
    (2023).
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cao 等 (2023) Bochuan Cao、Yuanpu Cao、Lu Lin 和 Jinghui Chen。2023年。通过稳健对齐的 LLM
    防御对齐破坏攻击。*arXiv preprint arXiv:2309.14348* (2023)。
- en: Chao et al. (2023) Patrick Chao, Alexander Robey, Edgar Dobriban, Hamed Hassani,
    George J Pappas, and Eric Wong. 2023. Jailbreaking black box large language models
    in twenty queries. *arXiv preprint arXiv:2310.08419* (2023).
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chao 等 (2023) Patrick Chao、Alexander Robey、Edgar Dobriban、Hamed Hassani、George
    J Pappas 和 Eric Wong。2023年。通过二十次查询破解黑箱大规模语言模型。*arXiv preprint arXiv:2310.08419*
    (2023)。
- en: Chen et al. (2021) Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique
    Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph,
    Greg Brockman, et al. 2021. Evaluating large language models trained on code.
    *arXiv preprint arXiv:2107.03374* (2021).
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 (2021) Mark Chen、Jerry Tworek、Heewoo Jun、Qiming Yuan、Henrique Ponde de
    Oliveira Pinto、Jared Kaplan、Harri Edwards、Yuri Burda、Nicholas Joseph、Greg Brockman
    等。2021年。评估大规模语言模型在代码上的训练。*arXiv preprint arXiv:2107.03374* (2021)。
- en: Croce and Hein (2020) Francesco Croce and Matthias Hein. 2020. Reliable evaluation
    of adversarial robustness with an ensemble of diverse parameter-free attacks.
    In *International conference on machine learning*. PMLR, 2206–2216.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Croce 和 Hein (2020) Francesco Croce 和 Matthias Hein。2020年。通过多样化的无参数攻击集成可靠评估对抗鲁棒性。收录于
    *International conference on machine learning*。PMLR，2206–2216。
- en: 'Cubuk et al. (2020) Ekin D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc V
    Le. 2020. Randaugment: Practical automated data augmentation with a reduced search
    space. In *Proceedings of the IEEE/CVF conference on computer vision and pattern
    recognition workshops*. 702–703.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Cubuk 等 (2020) Ekin D Cubuk、Barret Zoph、Jonathon Shlens 和 Quoc V Le。2020年。Randaugment:
    具有减少搜索空间的实用自动化数据增强。收录于 *Proceedings of the IEEE/CVF conference on computer vision
    and pattern recognition workshops*。702–703。'
- en: 'Deng et al. (2023) Gelei Deng, Yi Liu, Yuekang Li, Kailong Wang, Ying Zhang,
    Zefeng Li, Haoyu Wang, Tianwei Zhang, and Yang Liu. 2023. MasterKey: Automated
    jailbreak across multiple large language model chatbots. *arXiv preprint arXiv:2307.08715*
    (2023).'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Deng 等 (2023) Gelei Deng、Yi Liu、Yuekang Li、Kailong Wang、Ying Zhang、Zefeng Li、Haoyu
    Wang、Tianwei Zhang 和 Yang Liu。2023年。MasterKey: 跨多个大规模语言模型聊天机器人的自动化破解。*arXiv preprint
    arXiv:2307.08715* (2023)。'
- en: 'Ding et al. (2018) Gavin Weiguang Ding, Yash Sharma, Kry Yik Chau Lui, and
    Ruitong Huang. 2018. Mma training: Direct input space margin maximization through
    adversarial training. *arXiv preprint arXiv:1812.02637* (2018).'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ding 等 (2018) Gavin Weiguang Ding、Yash Sharma、Kry Yik Chau Lui 和 Ruitong Huang。2018年。Mma
    training: 通过对抗训练实现直接输入空间边际最大化。*arXiv preprint arXiv:1812.02637* (2018)。'
- en: 'Frosio and Kautz (2023) Iuri Frosio and Jan Kautz. 2023. The Best Defense is
    a Good Offense: Adversarial Augmentation against Adversarial Attacks. In *Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*. 4067–4076.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Frosio 和 Kautz (2023) Iuri Frosio 和 Jan Kautz. 2023. 最佳防御是良好的进攻：针对对抗性攻击的对抗性增强。在
    *IEEE/CVF 计算机视觉与模式识别会议论文集*。4067–4076。
- en: Gao et al. (2022) Ruijun Gao, Qing Guo, Felix Juefei-Xu, Hongkai Yu, Huazhu
    Fu, Wei Feng, Yang Liu, and Song Wang. 2022. Can you spot the chameleon? adversarially
    camouflaging images from co-salient object detection. In *Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition*. 2150–2159.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao 等 (2022) Ruijun Gao, Qing Guo, Felix Juefei-Xu, Hongkai Yu, Huazhu Fu, Wei
    Feng, Yang Liu 和 Song Wang. 2022. 你能发现变色龙吗？从共同显著对象检测中对抗性伪装图像。在 *IEEE/CVF 计算机视觉与模式识别会议论文集*。2150–2159。
- en: Gidaris et al. (2018) Spyros Gidaris, Praveer Singh, and Nikos Komodakis. 2018.
    Unsupervised representation learning by predicting image rotations. *arXiv preprint
    arXiv:1803.07728* (2018).
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gidaris 等 (2018) Spyros Gidaris, Praveer Singh 和 Nikos Komodakis. 2018. 通过预测图像旋转进行无监督表示学习。*arXiv
    预印本 arXiv:1803.07728* (2018)。
- en: Gong et al. (2021) Yunpeng Gong, Liqing Huang, and Lifei Chen. 2021. Eliminate
    deviation with deviation for data augmentation and a general multi-modal data
    learning method. *arXiv preprint arXiv:2101.08533* (2021).
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gong 等 (2021) Yunpeng Gong, Liqing Huang 和 Lifei Chen. 2021. 用偏差消除偏差的数据增强及一般多模态数据学习方法。*arXiv
    预印本 arXiv:2101.08533* (2021)。
- en: Goodfellow et al. (2014) Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy.
    2014. Explaining and harnessing adversarial examples. *arXiv preprint arXiv:1412.6572*
    (2014).
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow 等 (2014) Ian J Goodfellow, Jonathon Shlens 和 Christian Szegedy. 2014.
    解释和利用对抗样本。*arXiv 预印本 arXiv:1412.6572* (2014)。
- en: Guo et al. (2017) Chuan Guo, Mayank Rana, Moustapha Cisse, and Laurens Van Der Maaten.
    2017. Countering adversarial images using input transformations. *arXiv preprint
    arXiv:1711.00117* (2017).
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo 等 (2017) Chuan Guo, Mayank Rana, Moustapha Cisse 和 Laurens Van Der Maaten.
    2017. 使用输入变换对抗对抗性图像。*arXiv 预印本 arXiv:1711.00117* (2017)。
- en: Guo et al. (2020) Qing Guo, Felix Juefei-Xu, Xiaofei Xie, Lei Ma, Jian Wang,
    Bing Yu, Wei Feng, and Yang Liu. 2020. Watch out! motion is blurring the vision
    of your deep neural networks. *Advances in Neural Information Processing Systems*
    33 (2020), 975–985.
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo 等 (2020) Qing Guo, Felix Juefei-Xu, Xiaofei Xie, Lei Ma, Jian Wang, Bing
    Yu, Wei Feng 和 Yang Liu. 2020. 小心！运动模糊了你的深度神经网络的视线。*神经信息处理系统进展* 33 (2020), 975–985。
- en: He et al. (2020) Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
    2020. Momentum contrast for unsupervised visual representation learning. In *Proceedings
    of the IEEE/CVF conference on computer vision and pattern recognition*. 9729–9738.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He 等 (2020) Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie 和 Ross Girshick. 2020.
    动量对比用于无监督视觉表示学习。在 *IEEE/CVF 计算机视觉与模式识别会议论文集*。9729–9738。
- en: 'Hendrycks et al. (2019) Dan Hendrycks, Norman Mu, Ekin D Cubuk, Barret Zoph,
    Justin Gilmer, and Balaji Lakshminarayanan. 2019. Augmix: A simple data processing
    method to improve robustness and uncertainty. *arXiv preprint arXiv:1912.02781*
    (2019).'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hendrycks 等 (2019) Dan Hendrycks, Norman Mu, Ekin D Cubuk, Barret Zoph, Justin
    Gilmer 和 Balaji Lakshminarayanan. 2019. Augmix: 一种简单的数据处理方法以提高鲁棒性和不确定性。*arXiv
    预印本 arXiv:1912.02781* (2019)。'
- en: 'Ho and Vasconcelos (2022) Chih-Hui Ho and Nuno Vasconcelos. 2022. DISCO: Adversarial
    Defense with Local Implicit Functions. *arXiv preprint arXiv:2212.05630* (2022).'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ho 和 Vasconcelos (2022) Chih-Hui Ho 和 Nuno Vasconcelos. 2022. DISCO: 使用局部隐式函数的对抗性防御。*arXiv
    预印本 arXiv:2212.05630* (2022)。'
- en: Hou et al. (2023) Yang Hou, Qing Guo, Yihao Huang, Xiaofei Xie, Lei Ma, and
    Jianjun Zhao. 2023. Evading DeepFake Detectors via Adversarial Statistical Consistency.
    In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*.
    12271–12280.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hou 等 (2023) Yang Hou, Qing Guo, Yihao Huang, Xiaofei Xie, Lei Ma 和 Jianjun
    Zhao. 2023. 通过对抗性统计一致性规避 DeepFake 检测器。在 *IEEE/CVF 计算机视觉与模式识别会议论文集*。12271–12280。
- en: Huang et al. (2023) Hai Huang, Zhengyu Zhao, Michael Backes, Yun Shen, and Yang
    Zhang. 2023. Composite Backdoor Attacks Against Large Language Models. *arXiv
    preprint arXiv:2310.07676* (2023).
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等 (2023) Hai Huang, Zhengyu Zhao, Michael Backes, Yun Shen 和 Yang Zhang.
    2023. 针对大型语言模型的复合后门攻击。*arXiv 预印本 arXiv:2310.07676* (2023)。
- en: 'Jia et al. (2020) Xiaojun Jia, Xingxing Wei, Xiaochun Cao, and Xiaoguang Han.
    2020. Adv-watermark: A novel watermark perturbation for adversarial examples.
    In *Proceedings of the 28th ACM International Conference on Multimedia*. 1579–1587.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jia 等 (2020) Xiaojun Jia, Xingxing Wei, Xiaochun Cao 和 Xiaoguang Han. 2020.
    Adv-watermark: 一种用于对抗样本的新型水印扰动。 在 *第28届 ACM 国际多媒体会议论文集*。1579–1587。'
- en: 'Karimi et al. (2021) Akbar Karimi, Leonardo Rossi, and Andrea Prati. 2021.
    AEDA: An Easier Data Augmentation Technique for Text Classification. In *Findings
    of the Association for Computational Linguistics: EMNLP 2021*. 2748–2754.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Karimi 等人 (2021) Akbar Karimi, Leonardo Rossi 和 Andrea Prati。2021。AEDA: 一种更简单的文本分类数据增强技术。见于
    *计算语言学协会发现：EMNLP 2021*。2748–2754。'
- en: Kumar et al. (2023) Aounon Kumar, Chirag Agarwal, Suraj Srinivas, Soheil Feizi,
    and Hima Lakkaraju. 2023. Certifying llm safety against adversarial prompting.
    *arXiv preprint arXiv:2309.02705* (2023).
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kumar 等人 (2023) Aounon Kumar, Chirag Agarwal, Suraj Srinivas, Soheil Feizi 和
    Hima Lakkaraju。2023。对抗性提示的 LLM 安全认证。*arXiv 预印本 arXiv:2309.02705* (2023)。
- en: Kurakin et al. (2018) Alexey Kurakin, Ian J Goodfellow, and Samy Bengio. 2018.
    Adversarial examples in the physical world. In *Artificial intelligence safety
    and security*. Chapman and Hall/CRC, 99–112.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kurakin 等人 (2018) Alexey Kurakin, Ian J Goodfellow 和 Samy Bengio。2018。物理世界中的对抗样本。见于
    *人工智能安全与保障*。Chapman and Hall/CRC，99–112。
- en: Liu et al. (2023a) Yi Liu, Gelei Deng, Yuekang Li, Kailong Wang, Tianwei Zhang,
    Yepang Liu, Haoyu Wang, Yan Zheng, and Yang Liu. 2023a. Prompt Injection attack
    against LLM-integrated Applications. *arXiv preprint arXiv:2306.05499* (2023).
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 (2023a) Yi Liu, Gelei Deng, Yuekang Li, Kailong Wang, Tianwei Zhang,
    Yepang Liu, Haoyu Wang, Yan Zheng 和 Yang Liu。2023a。针对LLM集成应用的提示注入攻击。*arXiv 预印本
    arXiv:2306.05499* (2023)。
- en: 'Liu et al. (2023b) Yi Liu, Gelei Deng, Zhengzi Xu, Yuekang Li, Yaowen Zheng,
    Ying Zhang, Lida Zhao, Tianwei Zhang, and Yang Liu. 2023b. Jailbreaking chatgpt
    via prompt engineering: An empirical study. *arXiv preprint arXiv:2305.13860*
    (2023).'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 (2023b) Yi Liu, Gelei Deng, Zhengzi Xu, Yuekang Li, Yaowen Zheng, Ying
    Zhang, Lida Zhao, Tianwei Zhang 和 Yang Liu。2023b。通过提示工程破解ChatGPT：一项实证研究。*arXiv
    预印本 arXiv:2305.13860* (2023)。
- en: Lopes et al. (2019) Raphael Gontijo Lopes, Dong Yin, Ben Poole, Justin Gilmer,
    and Ekin D Cubuk. 2019. Improving robustness without sacrificing accuracy with
    patch gaussian augmentation. *arXiv preprint arXiv:1906.02611* (2019).
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lopes 等人 (2019) Raphael Gontijo Lopes, Dong Yin, Ben Poole, Justin Gilmer 和
    Ekin D Cubuk。2019。通过补丁高斯增强提高鲁棒性而不牺牲准确性。*arXiv 预印本 arXiv:1906.02611* (2019)。
- en: Madry et al. (2017) Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris
    Tsipras, and Adrian Vladu. 2017. Towards deep learning models resistant to adversarial
    attacks. *arXiv preprint arXiv:1706.06083* (2017).
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Madry 等人 (2017) Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris
    Tsipras 和 Adrian Vladu。2017。朝着对抗性攻击抗性的深度学习模型迈进。*arXiv 预印本 arXiv:1706.06083* (2017)。
- en: Marivate and Sefara (2020) Vukosi Marivate and Tshephisho Sefara. 2020. Improving
    short text classification through global augmentation methods. In *International
    Cross-Domain Conference for Machine Learning and Knowledge Extraction*. Springer,
    385–399.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Marivate 和 Sefara (2020) Vukosi Marivate 和 Tshephisho Sefara。2020。通过全球增强方法改善短文本分类。见于
    *国际跨领域机器学习与知识提取会议*。Springer，385–399。
- en: 'Miller (1995) George A Miller. 1995. WordNet: a lexical database for English.
    *Commun. ACM* 38, 11 (1995), 39–41.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Miller (1995) George A Miller。1995。WordNet: 英语词汇数据库。*Commun. ACM* 38，11 (1995)，39–41。'
- en: 'Morris et al. (2020) John X. Morris, Eli Lifland, Jin Yong Yoo, Jake Grigsby,
    Di Jin, and Yanjun Qi. 2020. TextAttack: A Framework for Adversarial Attacks,
    Data Augmentation, and Adversarial Training in NLP. In *Proceedings of the 2020
    Conference on Empirical Methods in Natural Language Processing: System Demonstrations,
    EMNLP 2020 - Demos, Online, November 16-20, 2020*, Qun Liu and David Schlangen
    (Eds.). Association for Computational Linguistics, 119–126. [https://doi.org/10.18653/V1/2020.EMNLP-DEMOS.16](https://doi.org/10.18653/V1/2020.EMNLP-DEMOS.16)'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Morris 等人 (2020) John X. Morris, Eli Lifland, Jin Yong Yoo, Jake Grigsby, Di
    Jin 和 Yanjun Qi。2020。TextAttack: 一个用于对抗性攻击、数据增强和对抗性训练的框架。见于 *2020 年自然语言处理经验方法会议：系统演示，EMNLP
    2020 - Demos，线上，2020年11月16-20日*，Qun Liu 和 David Schlangen (编)。计算语言学协会，119–126。
    [https://doi.org/10.18653/V1/2020.EMNLP-DEMOS.16](https://doi.org/10.18653/V1/2020.EMNLP-DEMOS.16)'
- en: Nenkova and Vanderwende (2005) Ani Nenkova and Lucy Vanderwende. 2005. The impact
    of frequency on summarization. *Microsoft Research, Redmond, Washington, Tech.
    Rep. MSR-TR-2005* 101 (2005).
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nenkova 和 Vanderwende (2005) Ani Nenkova 和 Lucy Vanderwende。2005。频率对摘要的影响。*微软研究，雷德蒙德，华盛顿，技术报告
    MSR-TR-2005* 101 (2005)。
- en: Nie et al. (2022) Weili Nie, Brandon Guo, Yujia Huang, Chaowei Xiao, Arash Vahdat,
    and Anima Anandkumar. 2022. Diffusion models for adversarial purification. *arXiv
    preprint arXiv:2205.07460* (2022).
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nie 等人 (2022) Weili Nie, Brandon Guo, Yujia Huang, Chaowei Xiao, Arash Vahdat
    和 Anima Anandkumar。2022。用于对抗性净化的扩散模型。*arXiv 预印本 arXiv:2205.07460* (2022)。
- en: Qi et al. (2023) Xiangyu Qi, Kaixuan Huang, Ashwinee Panda, Mengdi Wang, and
    Prateek Mittal. 2023. Visual adversarial examples jailbreak aligned large language
    models. In *The Second Workshop on New Frontiers in Adversarial Machine Learning*.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qi et al. (2023) Xiangyu Qi, Kaixuan Huang, Ashwinee Panda, Mengdi Wang, and
    Prateek Mittal. 2023. 视觉对抗示例越狱对齐的大型语言模型。在 *第二届对抗机器学习新前沿研讨会*。
- en: 'Rade and Moosavi-Dezfooli (2021) Rahul Rade and Seyed-Mohsen Moosavi-Dezfooli.
    2021. Helper-based adversarial training: Reducing excessive margin to achieve
    a better accuracy vs. robustness trade-off. In *ICML 2021 Workshop on Adversarial
    Machine Learning*.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rade and Moosavi-Dezfooli (2021) Rahul Rade and Seyed-Mohsen Moosavi-Dezfooli.
    2021. 基于助手的对抗性训练：减少过度边际以实现更好的准确性与鲁棒性权衡。在 *ICML 2021 对抗机器学习研讨会*。
- en: 'Robey et al. (2023) Alexander Robey, Eric Wong, Hamed Hassani, and George J
    Pappas. 2023. Smoothllm: Defending large language models against jailbreaking
    attacks. *arXiv preprint arXiv:2310.03684* (2023).'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Robey et al. (2023) Alexander Robey, Eric Wong, Hamed Hassani, and George J
    Pappas. 2023. Smoothllm: 保护大型语言模型免受越狱攻击。*arXiv 预印本 arXiv:2310.03684* (2023)。'
- en: 'Sehwag et al. (2021) Vikash Sehwag, Saeed Mahloujifar, Tinashe Handina, Sihui
    Dai, Chong Xiang, Mung Chiang, and Prateek Mittal. 2021. Robust learning meets
    generative models: Can proxy distributions improve adversarial robustness? *arXiv
    preprint arXiv:2104.09425* (2021).'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sehwag et al. (2021) Vikash Sehwag, Saeed Mahloujifar, Tinashe Handina, Sihui
    Dai, Chong Xiang, Mung Chiang, and Prateek Mittal. 2021. 鲁棒学习与生成模型的结合：代理分布能否提高对抗鲁棒性？
    *arXiv 预印本 arXiv:2104.09425* (2021)。
- en: Sun et al. (2019) Bo Sun, Nian-hsuan Tsai, Fangchen Liu, Ronald Yu, and Hao
    Su. 2019. Adversarial defense by stratified convolutional sparse coding. In *Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*. 11447–11456.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun et al. (2019) Bo Sun, Nian-hsuan Tsai, Fangchen Liu, Ronald Yu, and Hao
    Su. 2019. 通过分层卷积稀疏编码进行对抗性防御。在 *IEEE/CVF 计算机视觉与模式识别会议论文集*。11447–11456。
- en: 'Tian et al. (2021) Binyu Tian, Felix Juefei-Xu, Qing Guo, Xiaofei Xie, Xiaohong
    Li, and Yang Liu. 2021. AVA: Adversarial vignetting attack against visual recognition.
    *arXiv preprint arXiv:2105.05558* (2021).'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tian et al. (2021) Binyu Tian, Felix Juefei-Xu, Qing Guo, Xiaofei Xie, Xiaohong
    Li, and Yang Liu. 2021. AVA: 对视觉识别的对抗性晕影攻击。*arXiv 预印本 arXiv:2105.05558* (2021)。'
- en: 'Xie et al. (2019) Xiaofei Xie, Lei Ma, Felix Juefei-Xu, Minhui Xue, Hongxu
    Chen, Yang Liu, Jianjun Zhao, Bo Li, Jianxiong Yin, and Simon See. 2019. Deephunter:
    a coverage-guided fuzz testing framework for deep neural networks. In *Proceedings
    of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis*.
    146–157.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Xie et al. (2019) Xiaofei Xie, Lei Ma, Felix Juefei-Xu, Minhui Xue, Hongxu
    Chen, Yang Liu, Jianjun Zhao, Bo Li, Jianxiong Yin, and Simon See. 2019. Deephunter:
    一种覆盖指导的模糊测试框架用于深度神经网络。在 *第28届 ACM SIGSOFT 国际软件测试与分析研讨会论文集*。146–157。'
- en: 'Xu et al. (2023) Jiashu Xu, Mingyu Derek Ma, Fei Wang, Chaowei Xiao, and Muhao
    Chen. 2023. Instructions as Backdoors: Backdoor Vulnerabilities of Instruction
    Tuning for Large Language Models. *arXiv preprint arXiv:2305.14710* (2023).'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu et al. (2023) Jiashu Xu, Mingyu Derek Ma, Fei Wang, Chaowei Xiao, and Muhao
    Chen. 2023. 指令作为后门：大型语言模型指令调整的后门漏洞。*arXiv 预印本 arXiv:2305.14710* (2023)。
- en: 'Xu et al. (2017) Weilin Xu, David Evans, and Yanjun Qi. 2017. Feature squeezing:
    Detecting adversarial examples in deep neural networks. *arXiv preprint arXiv:1704.01155*
    (2017).'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu et al. (2017) Weilin Xu, David Evans, and Yanjun Qi. 2017. 特征挤压：检测深度神经网络中的对抗示例。*arXiv
    预印本 arXiv:1704.01155* (2017)。
- en: Yan et al. (2023) Jun Yan, Vikas Yadav, Shiyang Li, Lichang Chen, Zheng Tang,
    Hai Wang, Vijay Srinivasan, Xiang Ren, and Hongxia Jin. 2023. Virtual prompt injection
    for instruction-tuned large language models. *arXiv preprint arXiv:2307.16888*
    (2023).
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yan et al. (2023) Jun Yan, Vikas Yadav, Shiyang Li, Lichang Chen, Zheng Tang,
    Hai Wang, Vijay Srinivasan, Xiang Ren, and Hongxia Jin. 2023. 针对指令调整的大型语言模型的虚拟提示注入。*arXiv
    预印本 arXiv:2307.16888* (2023)。
- en: 'Yu et al. (2023) Jiahao Yu, Xingwei Lin, and Xinyu Xing. 2023. Gptfuzzer: Red
    teaming large language models with auto-generated jailbreak prompts. *arXiv preprint
    arXiv:2309.10253* (2023).'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yu et al. (2023) Jiahao Yu, Xingwei Lin, and Xinyu Xing. 2023. Gptfuzzer: 使用自动生成的越狱提示对大型语言模型进行红队测试。*arXiv
    预印本 arXiv:2309.10253* (2023)。'
- en: 'Zhang et al. (2021) Cen Zhang, Xingwei Lin, Yuekang Li, Yinxing Xue, Jundong
    Xie, Hongxu Chen, Xinlei Ying, Jiashui Wang, and Yang Liu. 2021. APICraft: Fuzz
    Driver Generation for Closed-source SDK Libraries. In *30th USENIX Security Symposium
    (USENIX Security 21)*. 2811–2828.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang et al. (2021) Cen Zhang, Xingwei Lin, Yuekang Li, Yinxing Xue, Jundong
    Xie, Hongxu Chen, Xinlei Ying, Jiashui Wang, and Yang Liu. 2021. APICraft: 闭源
    SDK 库的模糊驱动生成。在 *第30届 USENIX 安全研讨会 (USENIX Security 21)*。2811–2828。'
- en: Zheng et al. (2023) Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang,
    Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao
    Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judging LLM-as-a-judge with MT-Bench
    and Chatbot Arena. arXiv:2306.05685 [cs.CL]
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng 等（2023）Lianmin Zheng、Wei-Lin Chiang、Ying Sheng、Siyuan Zhuang、Zhanghao
    Wu、Yonghao Zhuang、Zi Lin、Zhuohan Li、Dacheng Li、Eric. P Xing、Hao Zhang、Joseph E.
    Gonzalez 和 Ion Stoica。2023。《通过 MT-Bench 和 Chatbot Arena 评估 LLM 作为法官》。*arXiv:2306.05685*
    [cs.CL]
- en: 'Zhu et al. (2023a) Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed
    Elhoseiny. 2023a. Minigpt-4: Enhancing vision-language understanding with advanced
    large language models. *arXiv preprint arXiv:2304.10592* (2023).'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu 等（2023a）Deyao Zhu、Jun Chen、Xiaoqian Shen、Xiang Li 和 Mohamed Elhoseiny。2023a。《Minigpt-4：通过先进的大型语言模型增强视觉-语言理解》。*arXiv
    预印本 arXiv:2304.10592*（2023）。
- en: 'Zhu et al. (2023b) Sicheng Zhu, Ruiyi Zhang, Bang An, Gang Wu, Joe Barrow,
    Zichao Wang, Furong Huang, Ani Nenkova, and Tong Sun. 2023b. AutoDAN: Automatic
    and Interpretable Adversarial Attacks on Large Language Models. *arXiv preprint
    arXiv:2310.15140* (2023).'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu 等（2023b）Sicheng Zhu、Ruiyi Zhang、Bang An、Gang Wu、Joe Barrow、Zichao Wang、Furong
    Huang、Ani Nenkova 和 Tong Sun。2023b。《AutoDAN：自动化和可解释的对抗攻击大型语言模型》。*arXiv 预印本 arXiv:2310.15140*（2023）。
- en: Zou et al. (2023) Andy Zou, Zifan Wang, J Zico Kolter, and Matt Fredrikson.
    2023. Universal and transferable adversarial attacks on aligned language models.
    *arXiv preprint arXiv:2307.15043* (2023).
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zou 等（2023）Andy Zou、Zifan Wang、J Zico Kolter 和 Matt Fredrikson。2023。《对齐语言模型的通用和可转移对抗攻击》。*arXiv
    预印本 arXiv:2307.15043*（2023）。
