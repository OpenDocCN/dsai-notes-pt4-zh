- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:44:23'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:44:23
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 销售耳语者：对 LLM 品牌推荐的隐蔽攻击
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.04755](https://ar5iv.labs.arxiv.org/html/2406.04755)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2406.04755](https://ar5iv.labs.arxiv.org/html/2406.04755)
- en: Weiran Lin Anna Gerchanovsky Omer Akgul Carnegie Mellon University Carnegie
    Mellon University Carnegie Mellon University Lujo Bauer Matt Fredrikson Zifan
    Wang Carnegie Mellon University Carnegie Mellon University Center for AI Safety
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Weiran Lin Anna Gerchanovsky Omer Akgul 卡内基梅隆大学 卡内基梅隆大学 卡内基梅隆大学 Lujo Bauer Matt
    Fredrikson Zifan Wang 卡内基梅隆大学 卡内基梅隆大学 人工智能安全中心
- en: Abstract
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Large language model (LLM) users might rely on others (e.g., prompting services),
    to write prompts. However, the risks of trusting prompts written by others remain
    unstudied. In this paper, we assess the risk of using such prompts on brand recommendation
    tasks when shopping. First, we found that paraphrasing prompts can result in LLMs
    mentioning given brands with drastically different probabilities, including a
    pair of prompts where the probability changes by . Our results suggest that our
    perturbed prompts, 1) are inconspicuous to humans, 2) force LLMs to recommend
    a target brand more often, and 3) increase the perceived chances of picking targeted
    brands.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLM）用户可能依赖其他人（例如，提示服务）来编写提示。然而，信任他人编写的提示所带来的风险尚未被研究。在本文中，我们评估了在购物时使用这种提示在品牌推荐任务中的风险。首先，我们发现转述提示可能导致
    LLM 提及给定品牌的概率大相径庭，包括一对提示其概率变化达到。我们的结果表明，我们的扰动提示，1）对人类不易察觉，2）迫使 LLM 更频繁地推荐目标品牌，并且
    3）增加了选择目标品牌的感知几率。
- en: 1 Introduction
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: 'With recent advances in LLMs, chatbots are becoming a ubiquitous part of users’
    digital experience. Users interact and control chatbots through natural language
    (i.e., prompts), for a nearly endless number of tasks. However, despite the natural
    language interface, effective prompts are often hard to create, leading some researchers
    to develop prompt optimization techniques (e.g., [[1](#bib.bib1)]). The industry
    has adopted the same ideas and has developed methods to recommend useful prompts
    to users. Chatbot services may suggest prompts for users (see Fig. [1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ Sales Whisperer: A Human-Inconspicuous Attack on
    LLM Brand Recommendations")), and dedicated forums may suggest prompts for users
    to try (see Fig. [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations"))  [[2](#bib.bib2)]. While these services
    may convenient to users, little research has focused on implications of prompts
    created by other (untrusted) parties. Existing work has only explored various
    security aspects of LLMs [[3](#bib.bib3), [4](#bib.bib4), [5](#bib.bib5), [6](#bib.bib6),
    [7](#bib.bib7), [8](#bib.bib8)], but the risks of using prompts by others remain
    unexplored.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 随着 LLM 的最新进展，聊天机器人正成为用户数字体验中无处不在的一部分。用户通过自然语言（即提示）与聊天机器人互动和控制，以完成几乎无尽的任务。然而，尽管有自然语言接口，创建有效的提示通常仍然很困难，这导致一些研究人员开发了提示优化技术（例如，[[1](#bib.bib1)]）。业界采纳了相同的理念，并开发了向用户推荐有用提示的方法。聊天机器人服务可能会建议用户提示（见图
    [1](#S1.F1 "图1 ‣ 1 引言 ‣ 销售耳语者：对 LLM 品牌推荐的隐蔽攻击")），专门的论坛可能会建议用户尝试提示（见图 [2](#S1.F2
    "图2 ‣ 1 引言 ‣ 销售耳语者：对 LLM 品牌推荐的隐蔽攻击")）[[2](#bib.bib2)]。尽管这些服务对用户可能很方便，但很少有研究关注由其他（不可信）方创建的提示的影响。现有的工作仅探索了
    LLM 的各种安全方面[[3](#bib.bib3), [4](#bib.bib4), [5](#bib.bib5), [6](#bib.bib6), [7](#bib.bib7),
    [8](#bib.bib8)]，但他人提示的使用风险仍未被探索。
- en: '![Refer to caption](img/e8a191964a2e5fb2c7de7a87bd9634de.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e8a191964a2e5fb2c7de7a87bd9634de.png)'
- en: 'Figure 1: An unbranded chatbot service (created for the user study), closely
    mimicking Copilot, suggesting prompts Popular chatbot services (e.g., ChatGPT,
    meta.ai, Gemini, Copilot) all employ such prompt recommendation mechanisms. Some,
    like Copilot [[9](#bib.bib9)], continuously update recommendations based on the
    chat history. Adversarial prompt recommenders may suggest specially crafted prompts.
    Fig. [3](#S3.F3 "Figure 3 ‣ 3 Threat Model ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations") depicts an attack.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：一个未品牌化的聊天机器人服务（为用户研究创建），紧密模仿 Copilot，建议提示。流行的聊天机器人服务（例如，ChatGPT、meta.ai、Gemini、Copilot）都采用了这种提示推荐机制。有些，如
    Copilot [[9](#bib.bib9)]，会根据聊天记录持续更新推荐。对抗性提示推荐系统可能会建议特别设计的提示。图 [3](#S3.F3 "图3
    ‣ 3 威胁模型 ‣ 销售耳语者：对 LLM 品牌推荐的隐蔽攻击") 描述了一种攻击。
- en: '![Refer to caption](img/7a866fdb0076745728b182e2214155db.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/7a866fdb0076745728b182e2214155db.png)'
- en: 'Figure 2: A snapshot of Reddit posts where some Reddit users persuade others
    to try certain prompts. Adversaries may also publish their prompts in the same
    manner and perform the attack we describe in Fig. [3](#S3.F3 "Figure 3 ‣ 3 Threat
    Model ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations").'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：Reddit 帖子的快照，其中一些 Reddit 用户劝说其他人尝试某些提示。对手也可能以相同的方式发布他们的提示，并执行我们在图[3](#S3.F3
    "图 3 ‣ 3 威胁模型 ‣ 销售耳语者：对 LLM 品牌推荐的隐秘攻击")中描述的攻击。
- en: 'In this paper, we study whether *inconspicuous* manipulation of prompts can
    lead to LLM responses with *substantial biases* of an attacker’s choosing. We
    examine this problem by taking a first look at brand recommendation tasks: users
    may ask LLMs to recommend brands (e.g., Samsung) when shopping for a specific
    category of products (e.g., TVs). Adversaries, motivated financially, may aim
    to write and trick users into utilizing prompts that cause LLMs to recommend a
    specific brand more often. Similar to advertisements, adversaries gain economic
    benefits when a specific brand is recommended more often. In this scenario, such
    prompts and corresponding LLM response need to be *human-inconspicuous* to LLM
    users (i.e., users should not notice an attack is taking place) [[10](#bib.bib10),
    [11](#bib.bib11), [12](#bib.bib12)]: if users feel suspicious about either the
    prompts or the responses, they may not trust the prompt recommender and thus thwart
    the attack. We explain our threat model in detail in §[3](#S3 "3 Threat Model
    ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations").
    While this study focuses on this specific attack scenario, the methods we describe
    in our work have the potential to be applied outside the realm of brand recommendation.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们研究了*隐秘*操控提示是否会导致 LLM 响应具有攻击者选择的*显著偏差*。我们通过初步研究品牌推荐任务来检查这个问题：用户可能会要求 LLM
    推荐品牌（例如，三星）在购物特定类别的产品（例如，电视）时。动机是经济利益的对手，可能会编写并欺骗用户使用提示，从而使 LLM 更频繁地推荐特定品牌。类似于广告，当特定品牌被更频繁地推荐时，对手可以获得经济利益。在这种情况下，这些提示和相应的
    LLM 响应需要对 LLM 用户*隐秘*（即用户不应察觉到攻击正在发生）[[10](#bib.bib10)、[11](#bib.bib11)、[12](#bib.bib12)]：如果用户对提示或响应感到怀疑，他们可能不会信任提示推荐者，从而挫败攻击。我们在
    §[3](#S3 "3 威胁模型 ‣ 销售耳语者：对 LLM 品牌推荐的隐秘攻击") 中详细解释了我们的威胁模型。虽然这项研究集中于这一特定攻击场景，但我们在工作中描述的方法有可能应用于品牌推荐领域之外。
- en: 'While many existing approaches have claimed to be capable of perturbing natural-language
    sequences (e.g., LLM prompts) in a human-inconspicuous manner [[13](#bib.bib13),
    [14](#bib.bib14), [15](#bib.bib15), [16](#bib.bib16), [17](#bib.bib17), [18](#bib.bib18),
    [19](#bib.bib19), [20](#bib.bib20), [21](#bib.bib21), [22](#bib.bib22), [23](#bib.bib23),
    [21](#bib.bib21), [24](#bib.bib24)], these studies suffer one of two shortcomings:
    either their inconspicuousness isn’t evaluated via user studies or the approaches
    were human-detectable in accompanying user studies. Thus, in this work we take
    a different approach to perturbing prompts, ensuring that the perturbations are
    human-inconspicuous via an extensive user study. Further, our attack does not
    require access to the LLM weights or gradients, differentiating our work from
    most prior studies.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管许多现有方法声称能够以隐秘的方式扰动自然语言序列（例如 LLM 提示）[[13](#bib.bib13)、[14](#bib.bib14)、[15](#bib.bib15)、[16](#bib.bib16)、[17](#bib.bib17)、[18](#bib.bib18)、[19](#bib.bib19)、[20](#bib.bib20)、[21](#bib.bib21)、[22](#bib.bib22)、[23](#bib.bib23)、[21](#bib.bib21)、[24](#bib.bib24)]，这些研究存在两个不足之处：要么它们的隐秘性未通过用户研究进行评估，要么这些方法在附带的用户研究中可被人类检测到。因此，在这项工作中，我们采用了不同的方法来扰动提示，确保通过广泛的用户研究使扰动对人类隐秘。此外，我们的攻击不需要访问
    LLM 权重或梯度，这使得我们的工作与大多数先前研究有所区别。
- en: 'As a first step in evaluating potential attacks in our threat model, we measure
    how paraphrased prompts can result in drastically different LLM responses. We
    perform tests on Gemma-it (instruction-tuned), Llama2, Llama3, and Llama3-it (instruction-tuned).
    These models are described further in §[5.1](#S5.SS1 "5.1 LLM Setup ‣ 5 Setup
    ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations").
    To do so, we need a dataset of prompts for brand recommendation tasks. To the
    best of our knowledge, there were no public datasets for this purpose. Hence,
    we created a new dataset, consisting of 77 product categories and 449 prompts.
    In our experiments, we used the frequency of LLMs mentioning certain brands ¹¹1In
    practice, we target a set of words related to the brand (e.g., “Macbook,” “Apple”
    for the “Apple” brand). Throughout the paper, we refer to responses that contain
    any of these target words as the LLM mentioning said brand. as a proxy metric
    of how often LLMs recommend the brand. We later show that this proxy proved to
    be accurate (see [7](#S7 "7 User Study ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations")). We observed that paraphrased alternatives
    of prompts result in a wide range of LLM responses, and can change the likelihood
    that LLMs mention a brand by up to  and $18.6\%$, depending on the LLM (§[6.1](#S6.SS1
    "6.1 Observations on Paraphrased Prompts ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations")).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '在评估我们威胁模型中潜在攻击的第一步中，我们测量了同义句提示如何导致大相径庭的LLM响应。我们对Gemma-it（经过指令调优）、Llama2、Llama3和Llama3-it（经过指令调优）进行了测试。这些模型在§[5.1](#S5.SS1
    "5.1 LLM Setup ‣ 5 Setup ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM
    Brand Recommendations")中有进一步的描述。为此，我们需要一个用于品牌推荐任务的提示数据集。据我们所知，之前没有公开的数据集可以用于此目的。因此，我们创建了一个新的数据集，包含77个产品类别和449个提示。在我们的实验中，我们使用了LLM提及某些品牌的频率¹¹1实际上，我们针对一组与品牌相关的词（例如，“Macbook”，“Apple”针对“Apple”品牌）。在本文中，我们将包含这些目标词的响应称为LLM提及该品牌。作为LLM推荐品牌的代理指标。我们后来证明这个代理指标是准确的（见[7](#S7
    "7 User Study ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations")）。我们观察到，同义句提示的不同版本会导致LLM响应的广泛变化，并且可以根据LLM的不同，使LLM提及某个品牌的可能性变化高达$18.6\%$（§[6.1](#S6.SS1
    "6.1 Observations on Paraphrased Prompts ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations")）。'
- en: 'The observation that similar prompts can result in different likelihoods of
    brand being mentioned motivates our next contribution. With access LLM to logits
    (notably, not weights), we propose a new approach that perturbs base prompts through
    synonym replacement. These human-inconspicuous perturbed prompts (§[4.2](#S4.SS2
    "4.2 Synonym-Replaced Adversarial Prompts ‣ 4 Methods ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations")) increase the likelihood of a target brand
    being mentioned in the LLM response. Candidate perturbed prompts are generated
    by replacing certain words with known synonyms, and one is selected based on a
    logit-based loss function. While several synonym dictionaries exist [[25](#bib.bib25),
    [26](#bib.bib26), [23](#bib.bib23), [27](#bib.bib27), [28](#bib.bib28)], we found
    that synonyms suggested by these dictionaries are human-detectable in the context
    of shopping brand recommendations, and thus we create our own synonym dictionary.
    We show that our method of performing synonym replacement can increase the likelihood
    that LLMs mention a brand by absolute improvements up to , , and $10.17\%$ for
    Gemma-it, Llama2, Llama3, and Llama3-it, respectively.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '类似的提示可能导致品牌提及概率不同的观察结果激发了我们的下一个贡献。通过访问LLM的logits（特别是，不是权重），我们提出了一种通过同义词替换来扰动基础提示的新方法。这些人类隐蔽的扰动提示（§[4.2](#S4.SS2
    "4.2 Synonym-Replaced Adversarial Prompts ‣ 4 Methods ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations")）增加了在LLM响应中提及目标品牌的可能性。候选的扰动提示是通过用已知的同义词替换某些词生成的，并根据基于logit的损失函数选择一个。虽然存在几个同义词词典[[25](#bib.bib25),
    [26](#bib.bib26), [23](#bib.bib23), [27](#bib.bib27), [28](#bib.bib28)]，但我们发现这些词典建议的同义词在购物品牌推荐的背景下是可以被人类检测到的，因此我们创建了自己的同义词词典。我们展示了我们执行同义词替换的方法可以使LLM提及品牌的可能性绝对提升，分别为Gemma-it、Llama2、Llama3和Llama3-it高达$10.17\%$。'
- en: 'We also investigated the *transferability* [[29](#bib.bib29), [30](#bib.bib30)]
    of our synonym-replacement approach. We observed that the synonym replacement
    approach is highly transferable between a limited pair of open-sourced LLMs and
    GPT3.5, a close-sourced commercial LLM (§[6.3](#S6.SS3 "6.3 Transferability to
    GPT Models ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM
    Brand Recommendations")).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '我们还调查了*可转移性* [[29](#bib.bib29), [30](#bib.bib30)]，即我们同义词替换方法的转移性。我们观察到，同义词替换方法在有限的开源LLMs和GPT3.5（一个闭源商业LLM）之间具有很高的可转移性（§[6.3](#S6.SS3
    "6.3 Transferability to GPT Models ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations")）。'
- en: 'Theoretical success in our attacks may not translate to real-world outcomes.
    To evaluate the effectiveness of our attacks in a more realistic setting, we conducted
    an extensive user study (§[7](#S7 "7 User Study ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations")). We specifically measure if participants
    will (1) find differences between perturbed/unperturbed prompt pairs, (2) find
    differences in responses to these pairs, and (3) be influenced by the increased
    likelihood of brand appearance in responses. We found that our synonym replacement
    attack acheives all three adversarial goals with statistical significance (§[7.2.2](#S7.SS2.SSS2
    "7.2.2 Statistical Evaluation ‣ 7.2 Results ‣ 7 User Study ‣ Sales Whisperer:
    A Human-Inconspicuous Attack on LLM Brand Recommendations")), validating our earlier
    experiments.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '我们的攻击在理论上的成功可能无法转化为现实世界的结果。为了在更现实的环境中评估我们攻击的有效性，我们进行了广泛的用户研究（§[7](#S7 "7 User
    Study ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations")）。我们具体测量了参与者是否会（1）发现扰动/未扰动提示对的差异，（2）发现对这些提示对的响应差异，以及（3）是否受到响应中品牌出现概率增加的影响。我们发现我们的同义词替换攻击在统计上显著地实现了所有三个对抗性目标（§[7.2.2](#S7.SS2.SSS2
    "7.2.2 Statistical Evaluation ‣ 7.2 Results ‣ 7 User Study ‣ Sales Whisperer:
    A Human-Inconspicuous Attack on LLM Brand Recommendations")），验证了我们早期的实验。'
- en: 'In summary, our contributions are the following:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们的贡献如下：
- en: •
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We collected a dataset of 449 prompts asking LLMs for recommendations on brands,
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们收集了一个包含449个提示的数据集，要求LLMs提供品牌推荐，
- en: •
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We identified a new threat model where adversaries perturb prompts and convince
    users to use them, ultimately causing LLMs to mention target brands.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们识别了一种新的威胁模型，其中对手扰动提示并说服用户使用这些提示，最终导致LLMs提及目标品牌。
- en: •
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We measured the difference in the likelihood of mentioning target brands in
    LLM’s responses to paraphrased prompts, finding a wide range.
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们测量了在对同义词替换的提示下，LLMs提及目标品牌的可能性差异，发现了一个广泛的范围。
- en: •
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We proposed a novel attack, synonym replacement approach to increase the likelihood
    of LLMs mentioning target brands. Through extensive evaluation, we show that this
    attack is successful.
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了一种新颖的攻击方法——同义词替换方法，以增加LLMs提及目标品牌的可能性。通过广泛评估，我们展示了这一攻击是成功的。
- en: •
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We evaluated the transferability of this attack from open-souced LLMs to GPT,
    finding that it is transferable for a limited set of models.
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们评估了这一攻击从开源LLMs到GPT的可转移性，发现它在有限的一组模型中是可转移的。
- en: •
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Finally, through a user study, we showed that synonym replacement meets adversarial
    goals in a realistic setting.
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后，通过用户研究，我们展示了同义词替换在现实环境中达到了对抗性目标。
- en: 'The rest of the paper has the following layout: We give an overview of related
    work in §[2](#S2 "2 Background ‣ Sales Whisperer: A Human-Inconspicuous Attack
    on LLM Brand Recommendations"). We define our threat model in §[3](#S3 "3 Threat
    Model ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations").
    We then describe two approaches for finding prompts that can increase the probability
    of a brand being mentioned that adversaries may use in the new threat model, in
    §[4](#S4 "4 Methods ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand
    Recommendations") and the technical setups to evaluate these approaches in §[5](#S5
    "5 Setup ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations").
    We show our empirical results in §[6](#S6 "6 Results ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations"). We describe our user study and its results
    in §[7](#S7 "7 User Study ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM
    Brand Recommendations"). Finally, we conclude in §[8](#S8 "8 Concluding Discussion
    ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations").'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 论文的其余部分有如下布局：我们在§[2](#S2 "2 背景 ‣ 销售耳语：对LLM品牌推荐的人类不显眼攻击")中概述相关工作。我们在§[3](#S3
    "3 威胁模型 ‣ 销售耳语：对LLM品牌推荐的人类不显眼攻击")中定义我们的威胁模型。然后，我们在§[4](#S4 "4 方法 ‣ 销售耳语：对LLM品牌推荐的人类不显眼攻击")中描述了两种方法，用于寻找可能增加品牌被提及概率的提示，这些方法可能被对手在新威胁模型中使用，并在§[5](#S5
    "5 设置 ‣ 销售耳语：对LLM品牌推荐的人类不显眼攻击")中描述了评估这些方法的技术设置。我们在§[6](#S6 "6 结果 ‣ 销售耳语：对LLM品牌推荐的人类不显眼攻击")中展示我们的实证结果。在§[7](#S7
    "7 用户研究 ‣ 销售耳语：对LLM品牌推荐的人类不显眼攻击")中，我们描述了我们的用户研究及其结果。最后，我们在§[8](#S8 "8 总结讨论 ‣ 销售耳语：对LLM品牌推荐的人类不显眼攻击")中得出结论。
- en: 2 Background
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 背景
- en: 'In this section, we introduce works related to this paper. We first discuss
    biases in computer systems (§[2.1](#S2.SS1 "2.1 Biases in Computer Systems ‣ 2
    Background ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations"))
    and then review existing inconspicuous attacks (§[2.2](#S2.SS2 "2.2 Human-Inconspicuous
    Attacks ‣ 2 Background ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM
    Brand Recommendations")) and general attacks on LLMs (§[2.3](#S2.SS3 "2.3 LLM
    Attacks ‣ 2 Background ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM
    Brand Recommendations")).'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍与本文相关的工作。我们首先讨论计算机系统中的偏见（§[2.1](#S2.SS1 "2.1 计算机系统中的偏见 ‣ 2 背景 ‣ 销售耳语：对LLM品牌推荐的人类不显眼攻击")），然后回顾现有的不显眼攻击（§[2.2](#S2.SS2
    "2.2 人类不显眼攻击 ‣ 2 背景 ‣ 销售耳语：对LLM品牌推荐的人类不显眼攻击")）以及对LLM的一般攻击（§[2.3](#S2.SS3 "2.3
    LLM攻击 ‣ 2 背景 ‣ 销售耳语：对LLM品牌推荐的人类不显眼攻击")）。
- en: 2.1 Biases in Computer Systems
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 计算机系统中的偏见
- en: Existing works showed that biases exist in computer systems due to social circumstances,
    design choices, and use cases [[31](#bib.bib31)]. For example, some computer games
    only have male characters [[32](#bib.bib32)], and some voting machines were inaccessible
    to people of low height and people with reduced visual acuity [[33](#bib.bib33)].
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现有工作表明，由于社会环境、设计选择和使用情况，计算机系统中存在偏见[[31](#bib.bib31)]。例如，一些计算机游戏只有男性角色[[32](#bib.bib32)]，一些投票机对身材矮小和视力受限的人群不友好[[33](#bib.bib33)]。
- en: Machine learning models might also have biases due to data, algorithms, and
    users [[34](#bib.bib34)]. For example, face-recognition systems can perform differently
    based on demographics, face geometry, and periocular features [[35](#bib.bib35)].
    YouTube video captions have a significantly lower word error rate for men then
    for women [[36](#bib.bib36)]. Compared to white defendants, regression models
    tend to falsely flag black defendants as future criminals more often [[37](#bib.bib37)].
    Some approaches have been proposed to mitigate the biases in machine learning
    algorithms [[38](#bib.bib38), [39](#bib.bib39)], but such methods typically suffer
    from decreased overall accuracy.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型也可能由于数据、算法和用户的原因存在偏见[[34](#bib.bib34)]。例如，面部识别系统可能会根据人口统计数据、面部几何特征和眼周特征表现不同[[35](#bib.bib35)]。YouTube视频字幕对于男性的词汇错误率显著低于女性[[36](#bib.bib36)]。与白人被告相比，回归模型更容易错误地将黑人被告标记为未来罪犯[[37](#bib.bib37)]。虽然已经提出一些方法来减轻机器学习算法中的偏见[[38](#bib.bib38),
    [39](#bib.bib39)]，但这些方法通常会导致整体准确率下降。
- en: LLMs, as specific machine learning models, also have biases, although the specific
    definition of biases is context-dependent and culture-dependent [[40](#bib.bib40)].
    In addition to various efforts to define [[41](#bib.bib41), [42](#bib.bib42)]
    and measure [[43](#bib.bib43), [44](#bib.bib44), [45](#bib.bib45), [46](#bib.bib46)]
    biases, numerous attempts have been made to mitigate biases in LLMs [[47](#bib.bib47),
    [48](#bib.bib48)]. However, to the best of our search, we did not find existing
    literature on biases in shopping brand recommendations, which is the use case
    in this paper, or biases induced by innocuous modifications of prompts, which
    is the general area we explore.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）作为特定的机器学习模型，也存在偏见，尽管偏见的具体定义依赖于上下文和文化 [[40](#bib.bib40)]。除了对偏见的各种定义 [[41](#bib.bib41),
    [42](#bib.bib42)]和测量 [[43](#bib.bib43), [44](#bib.bib44), [45](#bib.bib45), [46](#bib.bib46)]的努力外，还进行了大量尝试以减轻LLMs中的偏见 [[47](#bib.bib47),
    [48](#bib.bib48)]。然而，据我们所知，我们未发现关于购物品牌推荐中的偏见的现有文献，这正是本文的使用案例，或由无害的提示修改引发的偏见，这是我们探索的一般领域。
- en: 2.2 Human-Inconspicuous Attacks
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 人类不显眼的攻击
- en: 'One possible goal of adversaries is for attacks to be human-inconspicuousness:
    that humans at the scene are not able to notice an ongoing attack [[49](#bib.bib49),
    [50](#bib.bib50), [51](#bib.bib51), [52](#bib.bib52), [53](#bib.bib53), [54](#bib.bib54),
    [55](#bib.bib55), [56](#bib.bib56), [57](#bib.bib57), [58](#bib.bib58), [59](#bib.bib59),
    [60](#bib.bib60), [61](#bib.bib61), [62](#bib.bib62), [63](#bib.bib63)]. Examples
    of such attacks include human-inaudible voice commands to smartphones [[10](#bib.bib10)]
    and laser-based audio injection on voice controls [[64](#bib.bib64)]. Some defenses
    have been specifically proposed to detect such attacks [[65](#bib.bib65), [66](#bib.bib66),
    [55](#bib.bib55), [67](#bib.bib67), [68](#bib.bib68), [69](#bib.bib69), [70](#bib.bib70),
    [71](#bib.bib71)].'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗者的一个可能目标是让攻击在人类眼中不显眼：即现场的人员无法注意到正在进行的攻击 [[49](#bib.bib49), [50](#bib.bib50),
    [51](#bib.bib51), [52](#bib.bib52), [53](#bib.bib53), [54](#bib.bib54), [55](#bib.bib55),
    [56](#bib.bib56), [57](#bib.bib57), [58](#bib.bib58), [59](#bib.bib59), [60](#bib.bib60),
    [61](#bib.bib61), [62](#bib.bib62), [63](#bib.bib63)]。这类攻击的例子包括对智能手机发出的*人耳听不见*的语音命令 [[10](#bib.bib10)]和基于激光的语音控制注入攻击 [[64](#bib.bib64)]。一些防御措施专门用于检测这些攻击 [[65](#bib.bib65),
    [66](#bib.bib66), [55](#bib.bib55), [67](#bib.bib67), [68](#bib.bib68), [69](#bib.bib69),
    [70](#bib.bib70), [71](#bib.bib71)]。
- en: 'Evasion attacks are a type of attack on machine-learning systems that often
    tries to achieve inconspicuousness [[72](#bib.bib72), [73](#bib.bib73), [74](#bib.bib74),
    [75](#bib.bib75)]. With slight perturbations on images, evasion attacks aim to
    force well-trained machine learning models to behave unexpectedly [[76](#bib.bib76),
    [77](#bib.bib77), [78](#bib.bib78), [79](#bib.bib79), [80](#bib.bib80), [81](#bib.bib81)].
    In the image domain,  norms might not accurately correspond to inconspicuousness [[87](#bib.bib87),
    [88](#bib.bib88), [89](#bib.bib89)]. Alternatively, some patch-based evasion attacks
    have been proposed and empirically verified to be inconspicuous to humans [[11](#bib.bib11),
    [12](#bib.bib12)]. Various defense techniques against evasion attacks have been
    explored in previous works: some detect evasion attacks [[90](#bib.bib90), [91](#bib.bib91),
    [92](#bib.bib92)], some use transformations [[93](#bib.bib93), [94](#bib.bib94),
    [95](#bib.bib95)], some prove lower bounds of robustness of machine learning models
    against evasion attacks [[96](#bib.bib96), [97](#bib.bib97), [98](#bib.bib98),
    [99](#bib.bib99), [100](#bib.bib100), [101](#bib.bib101), [102](#bib.bib102)],
    and some train machine learning models to work properly in adversarial circumstances [[103](#bib.bib103),
    [104](#bib.bib104), [105](#bib.bib105), [106](#bib.bib106), [107](#bib.bib107),
    [108](#bib.bib108)].'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 规避攻击是一种针对机器学习系统的攻击类型，通常试图实现不显眼性 [[72](#bib.bib72), [73](#bib.bib73), [74](#bib.bib74),
    [75](#bib.bib75)]。通过对图像进行微小扰动，规避攻击旨在迫使训练良好的机器学习模型产生意外行为 [[76](#bib.bib76), [77](#bib.bib77),
    [78](#bib.bib78), [79](#bib.bib79), [80](#bib.bib80), [81](#bib.bib81)]。在图像领域，*范数*可能无法准确对应不显眼性 [[87](#bib.bib87),
    [88](#bib.bib88), [89](#bib.bib89)]。另外，一些基于补丁的规避攻击已被提出并经实验证明对人类不显眼 [[11](#bib.bib11),
    [12](#bib.bib12)]。以往的研究中探索了各种针对规避攻击的防御技术：一些检测规避攻击 [[90](#bib.bib90), [91](#bib.bib91),
    [92](#bib.bib92)]，一些使用转换 [[93](#bib.bib93), [94](#bib.bib94), [95](#bib.bib95)]，一些证明了机器学习模型在规避攻击下的鲁棒性下限 [[96](#bib.bib96),
    [97](#bib.bib97), [98](#bib.bib98), [99](#bib.bib99), [100](#bib.bib100), [101](#bib.bib101),
    [102](#bib.bib102)]，还有一些训练机器学习模型以在对抗性环境中正常工作 [[103](#bib.bib103), [104](#bib.bib104),
    [105](#bib.bib105), [106](#bib.bib106), [107](#bib.bib107), [108](#bib.bib108)]。
- en: 'In the NLP domain, different approaches have been suggested to generate human-inconspicuous
    attacks: some use the distances between words (e.g., the Levenshtein edit distance)
    or embeddings (e.g., the USE score [[109](#bib.bib109)]) as metrics to measure
    inconspicuousness [[24](#bib.bib24), [13](#bib.bib13), [17](#bib.bib17), [14](#bib.bib14),
    [15](#bib.bib15), [16](#bib.bib16)], some change only a small number of words [[17](#bib.bib17),
    [18](#bib.bib18), [19](#bib.bib19), [20](#bib.bib20)], some utilize generative
    models [[21](#bib.bib21)], some exploit common typos [[22](#bib.bib22)], and some
    perform synonym replacement [[23](#bib.bib23)]. However, all these works either
    do not have an accompanying user study (e.g., [[21](#bib.bib21)]) or are suggested
    by user studies to not be inconspicuous to humans (e.g., [[24](#bib.bib24)]).
    In this work, we suggest a new text-domain inconspicuous attack (see §[4.2](#S4.SS2
    "4.2 Synonym-Replaced Adversarial Prompts ‣ 4 Methods ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations") and §[6.2](#S6.SS2 "6.2 Synonym-Replaced
    Adversarial Prompts ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous Attack
    on LLM Brand Recommendations")) whose inconspicuousness is verified by a user
    study (see §[7.1](#S7.SS1 "7.1 Methods ‣ 7 User Study ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations") and §[7.2.2](#S7.SS2.SSS2 "7.2.2 Statistical
    Evaluation ‣ 7.2 Results ‣ 7 User Study ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations")).'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '在NLP领域，提出了不同的方法来生成不易被人察觉的攻击：有些使用单词之间的距离（例如，Levenshtein编辑距离）或嵌入（例如，USE评分[[109](#bib.bib109)]）作为衡量隐蔽性的指标[[24](#bib.bib24),
    [13](#bib.bib13), [17](#bib.bib17), [14](#bib.bib14), [15](#bib.bib15), [16](#bib.bib16)]，有些只更改少量单词[[17](#bib.bib17),
    [18](#bib.bib18), [19](#bib.bib19), [20](#bib.bib20)]，有些利用生成模型[[21](#bib.bib21)]，有些利用常见的拼写错误[[22](#bib.bib22)]，有些进行同义词替换[[23](#bib.bib23)]。然而，所有这些工作要么没有配套的用户研究（例如，[[21](#bib.bib21)]），要么用户研究表明对人类不够隐蔽（例如，[[24](#bib.bib24)]）。在这项工作中，我们建议了一种新的文本领域隐蔽攻击（见§[4.2](#S4.SS2
    "4.2 Synonym-Replaced Adversarial Prompts ‣ 4 Methods ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations")和§[6.2](#S6.SS2 "6.2 Synonym-Replaced Adversarial
    Prompts ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand
    Recommendations")），其隐蔽性经过用户研究验证（见§[7.1](#S7.SS1 "7.1 Methods ‣ 7 User Study ‣
    Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations")和§[7.2.2](#S7.SS2.SSS2
    "7.2.2 Statistical Evaluation ‣ 7.2 Results ‣ 7 User Study ‣ Sales Whisperer:
    A Human-Inconspicuous Attack on LLM Brand Recommendations")）。'
- en: 2.3 LLM Attacks
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 LLM攻击
- en: In light of LLMs’ prevalence, the security risks of LLMs and systems with LLMs
    have drawn the attention of researchers (e.g., [[3](#bib.bib3), [4](#bib.bib4),
    [5](#bib.bib5)]). We review proposed LLM attacks in the following paragraphs.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于LLMs的普及，LLMs及其系统的安全风险已引起研究人员的关注（例如，[[3](#bib.bib3), [4](#bib.bib4), [5](#bib.bib5)]）。我们将在接下来的段落中回顾提议的LLM攻击。
- en: '*Backdoor attacks* assume that adversaries can control some of the training
    data. In such attacks, adversaries attempt to change LLMs’ inference-time behavior
    by changing the data on which the LLMs are trained or tuned [[110](#bib.bib110),
    [111](#bib.bib111), [6](#bib.bib6), [112](#bib.bib112)]. Empirical [[113](#bib.bib113)]
    and provable [[114](#bib.bib114)] defenses have been proposed against backdoor
    attacks.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '*后门攻击*假设攻击者可以控制一些训练数据。在这种攻击中，攻击者尝试通过更改LLMs的训练或调整数据来改变LLMs的推理行为[[110](#bib.bib110),
    [111](#bib.bib111), [6](#bib.bib6), [112](#bib.bib112)]。已提出了针对后门攻击的经验性[[113](#bib.bib113)]和可证明性[[114](#bib.bib114)]防御。'
- en: '*Jail-breaking attacks* aim to cause LLMs to generate inappropriate content
    (e.g., offensive content). Adversaries in jail-breaking attacks do not have access
    to training data, but instead devise prompts that cause LLMs to respond with inappropriate
    content [[7](#bib.bib7), [115](#bib.bib115), [116](#bib.bib116), [117](#bib.bib117),
    [118](#bib.bib118), [119](#bib.bib119), [120](#bib.bib120)]. Most existing works
    evaluate jail-breaking attacks by success rate: the probability that offensive
    content is generated when LLMs are given perturbed prompts [[121](#bib.bib121)].
    Defenses against jail-breaking attacks, also known as guard-railing, have been
    explored by many works [[122](#bib.bib122), [123](#bib.bib123), [124](#bib.bib124),
    [125](#bib.bib125)].'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '*越狱攻击*旨在使LLMs生成不适当的内容（例如，冒犯性内容）。在越狱攻击中，攻击者无法访问训练数据，而是设计出使LLMs生成不适当内容的提示[[7](#bib.bib7),
    [115](#bib.bib115), [116](#bib.bib116), [117](#bib.bib117), [118](#bib.bib118),
    [119](#bib.bib119), [120](#bib.bib120)]。现有的大多数研究通过成功率来评估越狱攻击：即LLMs在接受扰动提示时生成冒犯性内容的概率[[121](#bib.bib121)]。针对越狱攻击的防御，也称为防护措施，已被许多研究探讨[[122](#bib.bib122),
    [123](#bib.bib123), [124](#bib.bib124), [125](#bib.bib125)]。'
- en: '*Data-extraction attacks* aim to reproduce some or part of the training data [[8](#bib.bib8),
    [126](#bib.bib126), [127](#bib.bib127), [128](#bib.bib128), [129](#bib.bib129),
    [130](#bib.bib130), [131](#bib.bib131)]. In data-extraction attacks, adversaries
    query LLMs potentially many times, with any prompts they wish, but cannot directly
    access LLMs’ training data.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据提取攻击* 旨在重现一些或部分训练数据[[8](#bib.bib8), [126](#bib.bib126), [127](#bib.bib127),
    [128](#bib.bib128), [129](#bib.bib129), [130](#bib.bib130), [131](#bib.bib131)]。在数据提取攻击中，对手可能多次查询
    LLM，使用任何他们希望的提示，但不能直接访问 LLM 的训练数据。'
- en: 'The threat model we explore in this paper differs from these existing attacks:
    we examine if inconspicuous changes to normal prompts can cause LLMs’ responses
    to be become probabilistically biased in a particular direction. We explain the
    differences between our threat models and others’ in more detail at the end of
    §[3](#S3 "3 Threat Model ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM
    Brand Recommendations").'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本文中探讨的威胁模型与这些现有攻击不同：我们检查了对正常提示进行微小更改是否会导致 LLM 的响应在特定方向上出现概率性偏见。我们将在§[3](#S3
    "3 威胁模型 ‣ 销售耳语者：对 LLM 品牌推荐的隐蔽攻击") 末尾详细解释我们威胁模型与其他模型的差异。
- en: 3 Threat Model
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 威胁模型
- en: '![Refer to caption](img/791a4d06426ed45d7edc7b5be494e80d.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/791a4d06426ed45d7edc7b5be494e80d.png)'
- en: 'Figure 3: Pipeline of an attack where the adversaries craft prompts and persuade
    LLM users to try these prompts. For example, Instacart suggests prompts users
    can try with its ChatGPT-powered search  [[132](#bib.bib132)]. Once persuaded,
    the users send these prompts to LLMs and read the responses.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：一种攻击的流程图，其中对手设计提示并说服 LLM 用户尝试这些提示。例如，Instacart 提供了用户可以在其 ChatGPT 驱动的搜索中尝试的提示[[132](#bib.bib132)]。一旦说服成功，用户将这些提示发送给
    LLM 并查看响应。
- en: '![Refer to caption](img/360f049e34ef376bd7d3236953d659d8.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/360f049e34ef376bd7d3236953d659d8.png)'
- en: 'Figure 4: Pipeline of an attack where users ask adversaries to draft prompts.
    Users may ask prompting services to draft prompts for efficiency and utility.
    Users then forward the prompts to LLMs and read the responses. Companies (e.g.,
    PromptPerfect [[133](#bib.bib133)]) offer such services.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：一种攻击的流程图，其中用户请求对手编写提示。用户可能会请求提示服务以提高效率和实用性。用户然后将这些提示转发给 LLM，并查看响应。公司（例如，PromptPerfect
    [[133](#bib.bib133)]）提供这样的服务。
- en: We posit that prompts from untrusted sources can cause unforeseeable biases
    in LLM responses. In this paper, we use brand recommendations during shopping
    as our attack scenario. More specifically, we assume that users (i.e., victims),
    who are shopping for specific goods (e.g., TVs), decide to ask LLMs for brand
    recommendations. Instead of writing prompts, victims use prompts created by adversaries
    (e.g., prompting services. See scenarios below for details).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设来自不可信来源的提示可能会导致 LLM 响应中出现不可预见的偏见。在本文中，我们以购物中的品牌推荐作为攻击场景。更具体地说，我们假设用户（即受害者）在购买特定商品（例如电视）时，决定向
    LLM 请求品牌推荐。受害者不是自己编写提示，而是使用对手（例如，提示服务）创建的提示。请参见下面的场景了解详情。
- en: For chatbots that outsource their underlying LLMs to third-party services,²²2many
    have announced or implemented chatbots using outsourced LLMs (e.g., OpenAI API),
    including Instacart [[132](#bib.bib132)], Lowe’s [[134](#bib.bib134)], Expedia [[135](#bib.bib135)],
    and more the aforementioned scenario creates an attack vector that does not require
    control over the model.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 对于将其底层 LLM 外包给第三方服务的聊天机器人²²2，许多已经宣布或实施了使用外包 LLM 的聊天机器人（例如，OpenAI API），包括 Instacart
    [[132](#bib.bib132)]、Lowe’s [[134](#bib.bib134)]、Expedia [[135](#bib.bib135)]，以及更多上述场景创建了一个不需要控制模型的攻击向量。
- en: This threat isn’t just limited to chatbots with external LLMs. Despite owning
    control over the LLM (e.g., Gemini, ChatGPT), retraining models is costly [[136](#bib.bib136)].
    Injecting bias through prompts, as we’ll show later, is not.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这种威胁不仅限于使用外部 LLM 的聊天机器人。尽管拥有对 LLM 的控制权（例如，Gemini、ChatGPT），重新训练模型的成本仍然很高[[136](#bib.bib136)]。通过提示注入偏见，如我们稍后将展示的，并不昂贵。
- en: 'These LLMs have been vulnerable to many attacks, like jail-breaking (see §[2.3](#S2.SS3
    "2.3 LLM Attacks ‣ 2 Background ‣ Sales Whisperer: A Human-Inconspicuous Attack
    on LLM Brand Recommendations")). These risks are not hypothetical: a chatbot used
    by a car dealership was prompted to sell a $ [[137](#bib.bib137)], Air Canada
    had to honor the hallucinated policy by its customer support chatbot [[138](#bib.bib138)].'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这些LLMs已易受许多攻击，如越狱（见§[2.3](#S2.SS3 "2.3 LLM攻击 ‣ 2 背景 ‣ 销售耳语：对LLM品牌推荐的隐形攻击")）。这些风险并非假设：一家汽车经销商使用的聊天机器人被提示去销售一个$[[137](#bib.bib137)]，加拿大航空公司不得不遵守其客户支持聊天机器人编造的政策[[138](#bib.bib138)]。
- en: Below is concrete scenarios our threat model applies to.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们的威胁模型适用的具体场景。
- en: 1
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 1
- en: 'Fig. [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations") shows an example where a chatbot service
    is suggesting prompts. If the chatbot is adversarial, instead of engaging in costly
    re-training of models [[136](#bib.bib136)], it may suggest specially crafted prompts
    that result in biased respones. Notably, many chatbots already implement prompt
    recommendation features.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图[1](#S1.F1 "图 1 ‣ 1 介绍 ‣ 销售耳语：对LLM品牌推荐的隐形攻击")展示了一个聊天机器人服务建议提示的例子。如果聊天机器人具有敌意，它可能会建议特别设计的提示，导致偏见回应，而不是进行昂贵的模型再训练[[136](#bib.bib136)]。值得注意的是，许多聊天机器人已经实现了提示推荐功能。
- en: 2
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 2
- en: 'Users, seeking increased efficacy and utility from chatbots, may ask prompting
    services (e.g., PromptPerfect [[133](#bib.bib133)]) to write or optimize prompts.
    Fig. [4](#S3.F4 "Figure 4 ‣ 3 Threat Model ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations") shows the attack pipeline in this use case.
    Users first ask adversaries to write prompts and then use them with chatbots.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 寻求提高聊天机器人效果和实用性的用户，可能会请提示服务（如PromptPerfect [[133](#bib.bib133)]）编写或优化提示。图[4](#S3.F4
    "图 4 ‣ 3 威胁模型 ‣ 销售耳语：对LLM品牌推荐的隐形攻击")展示了这一用例中的攻击流程。用户首先请敌对者编写提示，然后与聊天机器人一起使用这些提示。
- en: 3
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 3
- en: 'Further, adversaries may release prompts on online forums and encourage users
    to try them. If adversaries manage to convince victims to do so, users will send
    the prompts to LLMs and read the responses. For example, Instacart suggests prompts
    users can try with its LLM powered search [[132](#bib.bib132)]. Fig. [2](#S1.F2
    "Figure 2 ‣ 1 Introduction ‣ Sales Whisperer: A Human-Inconspicuous Attack on
    LLM Brand Recommendations") shows an example where some Reddit users encouraged
    others to try some prompts on ChatGPT  [[2](#bib.bib2)]. Fig. [3](#S3.F3 "Figure
    3 ‣ 3 Threat Model ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand
    Recommendations") shows the attack pipeline in this use case.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，敌对者可能会在在线论坛上发布提示，并鼓励用户尝试这些提示。如果敌对者成功说服受害者这样做，用户将把这些提示发送给LLMs并查看回应。例如，Instacart建议用户尝试其LLM驱动的搜索提示[[132](#bib.bib132)]。图[2](#S1.F2
    "图 2 ‣ 1 介绍 ‣ 销售耳语：对LLM品牌推荐的隐形攻击")展示了某些Reddit用户鼓励其他人尝试在ChatGPT上使用一些提示的例子[[2](#bib.bib2)]。图[3](#S3.F3
    "图 3 ‣ 3 威胁模型 ‣ 销售耳语：对LLM品牌推荐的隐形攻击")展示了这一用例中的攻击流程。
- en: Specific goals and constraints
  id: totrans-67
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 具体目标和限制
- en: 'In our threat model, regardless of specific use cases, adversaries cannot,
    or are disincentivized to change the weights of the LLM. They can, however, suggest
    prompts to users. Adversaries may also query LLMs with these prompts in advance
    of the attacks. We further assume that the adversary is constrained in its prompt
    perturbation: the prompts and resulting responses must not alert users to the
    attack. As such, the prompts and responses must be inconspicuous (see §[2.2](#S2.SS2
    "2.2 Human-Inconspicuous Attacks ‣ 2 Background ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations")). If users are suspicious (e.g., propmts/responses
    semantically incorrect, containing nonsequiturs), users may stop using these prompts.
    We propose a practical definition of inconspicuousness for prompts and responses
    in [subsubsection 7.1.1](#S7.SS1.SSS1 "7.1.1 Survey procedures ‣ 7.1 Methods ‣
    7 User Study ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations").'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的威胁模型中，无论具体的使用案例是什么，对抗者不能，也没有激励去改变 LLM 的权重。然而，他们可以向用户建议提示。对抗者也可以在攻击前用这些提示查询
    LLM。我们进一步假设对抗者在其提示扰动上受到限制：提示和结果响应不得引起用户对攻击的警觉。因此，提示和响应必须不显眼（见 §[2.2](#S2.SS2 "2.2
    人类不显眼攻击 ‣ 2 背景 ‣ 销售耳语者：对 LLM 品牌推荐的一个人类不显眼攻击")）。如果用户产生怀疑（例如，提示/响应语义不正确，包含无关内容），用户可能会停止使用这些提示。我们在 [subsubsection 7.1.1](#S7.SS1.SSS1
    "7.1.1 调查程序 ‣ 7.1 方法 ‣ 7 用户研究 ‣ 销售耳语者：对 LLM 品牌推荐的一个人类不显眼攻击")中提出了提示和响应不显眼性的实际定义。
- en: '![Refer to caption](img/09e6ecb058867137d15c5ef25a8c979d.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/09e6ecb058867137d15c5ef25a8c979d.png)'
- en: 'Figure 5: An illustration of the adversaries’ goals. In this example, the adversary
    tries to increase the frequency of a brand (A) thorough inconspicuous prompt recommendations
    and is successful.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：对抗者目标的示意图。在这个例子中，对抗者试图通过不显眼的提示推荐来增加品牌（A）的频率，并且成功了。
- en: 'The main goal of the adversary is to induce LLMs to recommend certain brands
    more often, while not necessarily the most often among all brands. [Figure 5](#S3.F5
    "Figure 5 ‣ Specific goals and constraints ‣ 3 Threat Model ‣ Sales Whisperer:
    A Human-Inconspicuous Attack on LLM Brand Recommendations") depicts this goal.
    In the presence of the perturbed prompts, the LLM recommends brand A more often
    than in the baseline condition. Similar to advertising, adversaries may economically
    benefit from this outcome. Notably, the adversary does not aim to prevent other
    brands (e.g., brand C), from being recommended more frequently. In practice, each
    response may recommend more than one brand. Note that adversaries may *not* need
    to cause LLMs to mention the exact brand name to recommend the brand. For example,
    to recommend the brand “Apple” for “laptops,” adversaries may instead cause “Macbook”
    to be recommended.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗者的主要目标是促使 LLM 更频繁地推荐某些品牌，但不一定是所有品牌中最频繁推荐的品牌。[图 5](#S3.F5 "图 5 ‣ 具体目标和约束 ‣
    3 威胁模型 ‣ 销售耳语者：对 LLM 品牌推荐的一个人类不显眼攻击") 描述了这一目标。在扰动提示的影响下，LLM 比在基线条件下更频繁地推荐品牌 A。类似于广告，对抗者可能会从这一结果中获得经济利益。值得注意的是，对抗者并不旨在阻止其他品牌（例如，品牌
    C）被更频繁地推荐。在实践中，每个响应可能会推荐多个品牌。请注意，对抗者*不*需要使 LLM 提及确切的品牌名称来推荐该品牌。例如，为了推荐品牌“Apple”的“笔记本电脑”，对抗者可能会导致“Macbook”被推荐。
- en: 'In summary, in our threat model, adversaries suggest prompts but do not have
    control over the model. An attack succeeds if, compared to a baseline, 1) prompts
    and responses are inconspicuous users and 2) the LLMs recommends a target brand
    more often. We describe such attacks in §[4.1](#S4.SS1 "4.1 Observations on Paraphrased
    Prompts ‣ 4 Methods ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand
    Recommendations") and §[4.2](#S4.SS2 "4.2 Synonym-Replaced Adversarial Prompts
    ‣ 4 Methods ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations"),
    and verify the effectiveness in §[6](#S6 "6 Results ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations") and §[7](#S7 "7 User Study ‣ Sales Whisperer:
    A Human-Inconspicuous Attack on LLM Brand Recommendations"). Our threat model
    is different from those described in previous work (§[2.3](#S2.SS3 "2.3 LLM Attacks
    ‣ 2 Background ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations")):
    compared to backdoor attacks, adversaries in our threat model have no control
    over training data; compared to data extraction attacks, our adversaries do not
    extract training data and cannot use conspicuous prompts; compared to jail-breaking
    attacks, our adversaries do not generate inappropriate content, cannot use conspicuous
    prompts, and do not have access to model weights (or gradients).'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '总之，在我们的威胁模型中，对手建议提示但不控制模型。如果与基线相比，1）提示和响应对用户不显眼，2）LLM更频繁地推荐目标品牌，则攻击成功。我们在§[4.1](#S4.SS1
    "4.1 Observations on Paraphrased Prompts ‣ 4 Methods ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations")和§[4.2](#S4.SS2 "4.2 Synonym-Replaced Adversarial
    Prompts ‣ 4 Methods ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand
    Recommendations")中描述了这种攻击，并在§[6](#S6 "6 Results ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations")和§[7](#S7 "7 User Study ‣ Sales Whisperer:
    A Human-Inconspicuous Attack on LLM Brand Recommendations")中验证了其有效性。我们的威胁模型不同于以往的工作（§[2.3](#S2.SS3
    "2.3 LLM Attacks ‣ 2 Background ‣ Sales Whisperer: A Human-Inconspicuous Attack
    on LLM Brand Recommendations")）：与后门攻击相比，我们的威胁模型中的对手没有控制训练数据；与数据提取攻击相比，我们的对手不提取训练数据，且不能使用显眼的提示；与越狱攻击相比，我们的对手不生成不适当的内容，不能使用显眼的提示，也没有访问模型权重（或梯度）的权限。'
- en: 4 Methods
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 方法
- en: 'In this section, we introduce how we build the approach that achieves the attack
    goals described in §[3](#S3 "3 Threat Model ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations"): generating prompts and corresponding responses
    that are inconspicuous to humans (i.e., they do not know an attack is taking place)
    and cause LLMs to recommend a target brand more often, ultimately increasing attention
    received from humans. We first describe our observation on LLM’s responses to
    paraphrased prompts (§[4.1](#S4.SS1 "4.1 Observations on Paraphrased Prompts ‣
    4 Methods ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations")),
    and then illustrate our synonym replacement approach to perturb prompts human-inconspicuously
    §[4.2](#S4.SS2 "4.2 Synonym-Replaced Adversarial Prompts ‣ 4 Methods ‣ Sales Whisperer:
    A Human-Inconspicuous Attack on LLM Brand Recommendations").'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '在这一部分，我们介绍了如何构建实现攻击目标的方法，如第§[3](#S3 "3 Threat Model ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations")节所述：生成对人类不显眼的提示和对应的响应（即，人类不知道攻击正在发生），并使LLM更频繁地推荐目标品牌，*最终*增加人类的关注。我们首先描述了对LLM对同义改写提示的反应的观察（§[4.1](#S4.SS1
    "4.1 Observations on Paraphrased Prompts ‣ 4 Methods ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations")），然后展示了我们的同义词替换方法以不显眼地扰动提示 (§[4.2](#S4.SS2
    "4.2 Synonym-Replaced Adversarial Prompts ‣ 4 Methods ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations"))。'
- en: 4.1 Observations on Paraphrased Prompts
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 对同义改写提示的观察
- en: Machine learning models, including LLMs, are brittle (e.g., [[82](#bib.bib82)]).
    They can be highly sensitive to small changes in their input.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型，包括LLM，具有脆弱性（例如，[[82](#bib.bib82)]）。它们对输入的小变化非常敏感。
- en: 'To promote a target brand, we apply this intuition. We explore attacking LLMs
    by testing paraphrased prompts. Specifically, we generate a set of prompts asking
    for recommendations of products in a certain category that are all paraphrases
    of one another. Our approach to this is described in §[5.2](#S5.SS2 "5.2 Evalution
    Procedure ‣ 5 Setup ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand
    Recommendations"). We show that these various paraphrased prompts (§[6.1](#S6.SS1
    "6.1 Observations on Paraphrased Prompts ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations")), although similar, can lead to increased
    prominence of a brand in the LLM’s responses. Given enough paraphrases, we’re
    able to find a prompt that causes LLMs to recommend a target brand more often.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '为了推广目标品牌，我们运用了这一直觉。我们通过测试意译的提示来探索攻击LLM。具体而言，我们生成了一组提示，询问关于某一类别产品的推荐，这些提示都是相互的意译。我们的方法在§[5.2](#S5.SS2
    "5.2 Evalution Procedure ‣ 5 Setup ‣ Sales Whisperer: A Human-Inconspicuous Attack
    on LLM Brand Recommendations")中有所描述。我们展示了这些不同的意译提示（§[6.1](#S6.SS1 "6.1 Observations
    on Paraphrased Prompts ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous Attack
    on LLM Brand Recommendations")），虽然相似，但会导致品牌在LLM响应中的显著性增加。给定足够的意译，我们能够找到一个使LLM更频繁推荐目标品牌的提示。'
- en: 'This approach does not require any access to LLMs’ internal weights or token
    probabilities. However, it has a caveat, we need to try many paraphrases and collect
    many responses to find an optimal prompt. This computational cost might be an
    economic burden for the adversaries. Additionally, when we generate the paraphrases,
    some are likely less similar to each other and thus human-detectable. While we
    are able to find paraphrases that result in a large change in the probability
    that a certain brand is mentioned, even while using only a few prompts per category,
    as we describe in §[5.2](#S5.SS2 "5.2 Evalution Procedure ‣ 5 Setup ‣ Sales Whisperer:
    A Human-Inconspicuous Attack on LLM Brand Recommendations"), in cases where an
    adversary does not have the time or computational resources to collect responses
    to multiple paraphrased prompts, adversaries may want to take another approach.
    As such, we propose another method to perturb prompts. To reduce computational
    overhead, with this new approach we assume access to the logits of LLMs in §[4.2](#S4.SS2
    "4.2 Synonym-Replaced Adversarial Prompts ‣ 4 Methods ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations").'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '这种方法不需要访问LLM的内部权重或令牌概率。然而，它有一个警告，我们需要尝试许多意译并收集许多响应来找到一个最佳提示。这种计算成本可能对对手来说是经济负担。此外，当我们生成意译时，一些可能彼此不够相似，从而被人类检测到。虽然我们能够找到导致特定品牌提及概率大幅变化的意译，即使每个类别只使用少量提示，如§[5.2](#S5.SS2
    "5.2 Evalution Procedure ‣ 5 Setup ‣ Sales Whisperer: A Human-Inconspicuous Attack
    on LLM Brand Recommendations")中所述，但在对手没有时间或计算资源来收集多个意译提示的响应的情况下，对手可能希望采用另一种方法。因此，我们提出了另一种扰动提示的方法。为了减少计算开销，我们在§[4.2](#S4.SS2
    "4.2 Synonym-Replaced Adversarial Prompts ‣ 4 Methods ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations")中假设可以访问LLM的logits。'
- en: 4.2 Synonym-Replaced Adversarial Prompts
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 同义词替换对抗提示
- en: 'The fundamental idea of this attack is to generate prompts by replacing words
    with synonyms and picking one that minimizes a loss function, reducing the need
    to collect computationally expensive responses. As we described in §[2.2](#S2.SS2
    "2.2 Human-Inconspicuous Attacks ‣ 2 Background ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations"), while many NLP domain attacks have been
    proposed to be inconspicuous to humans, they either do not have accompanying user
    studies or are shown to be conspicuous to humans, motivating our approach. With
    this attack, we propose an improved synonym replacement method to generate human-inconspicuous
    perturbations.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '这种攻击的基本思想是通过用同义词替换词语生成提示，并选择一个最小化损失函数的提示，从而减少收集计算成本高昂的响应的需求。正如我们在§[2.2](#S2.SS2
    "2.2 Human-Inconspicuous Attacks ‣ 2 Background ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations")中所述，尽管许多NLP领域的攻击已被提出为对人类不明显，但它们要么没有伴随的用户研究，要么被证明对人类显而易见，这激励了我们的方法。通过这种攻击，我们提出了一种改进的同义词替换方法来生成对人类不显眼的扰动。'
- en: Existing synonym replacement methods [[23](#bib.bib23)] either use WordNet,
    an established synonym dictionary, or a self-defined synonym dictionary [[25](#bib.bib25),
    [26](#bib.bib26)]. Nouns and verbs were found to have various forms (e.g., plural
    forms of nouns and verb tenses) [[27](#bib.bib27)], and thus an adjective synonym
    dictionary was suggested [[28](#bib.bib28)]. However, we found that synonyms of
    adjectives listed in existing dictionaries might not be synonyms in the context
    of brand recommendations. For example, WordNet and the existing adjective synonym
    dictionary both suggested “*raw*” as a synonym for “*newest*,” while it is human-conspicuous
    to recommend “*the raw smartphone*” instead of “*the newest smartphone*.” Thus,
    we created a new synonym dictionary compatible with brand recommendations. Our
    synonym dictionary mainly consists of adjectives but also includes other parts
    of speech while keeping the tense of verbs consistent between synonyms. In our
    dictionary, “*select*” and “*choose*” are synonyms, creating a synonym group,
    and other tenses of these verbs are excluded. “*Exact*,” “*accurate*,” and “*precise*”
    also creats a synonym group, this time of three. Our dictionary contains a total
    of 94 words in 36 synonym groups. Each word may have at most seven synonyms.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的同义词替换方法 [[23](#bib.bib23)] 要么使用 WordNet，一个建立完善的同义词词典，要么使用自定义的同义词词典 [[25](#bib.bib25),
    [26](#bib.bib26)]。名词和动词被发现有多种形式（例如名词的复数形式和动词的时态） [[27](#bib.bib27)]，因此建议使用形容词同义词词典 [[28](#bib.bib28)]。然而，我们发现现有词典中列出的形容词同义词在品牌推荐的背景下可能不是同义词。例如，WordNet
    和现有的形容词同义词词典都建议将“*raw*”作为“*newest*”的同义词，而推荐“*the raw smartphone*”而不是“*the newest
    smartphone*”是显而易见的。因此，我们创建了一个与品牌推荐兼容的新同义词词典。我们的同义词词典主要包含形容词，但也包括其他词性，同时保持动词的时态在同义词之间一致。在我们的词典中，“*select*”和“*choose*”是同义词，形成了一个同义词组，而这些动词的其他时态被排除在外。“*Exact*”、“*accurate*”和“*precise*”也形成了一个同义词组，这次是三个。我们的词典包含总共
    94 个单词，分为 36 个同义词组。每个单词最多可能有七个同义词。
- en: 'Since paraphrasing prompts imposes an economic burden (§[4.1](#S4.SS1 "4.1
    Observations on Paraphrased Prompts ‣ 4 Methods ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations")), systematically testing and gathering responses
    for all candidate perturbed prompts generated by synonym replacement would have
    a high cost. One prompt we tested had six words with synonyms and therefore  candidates,
    we used a loss-guided candidate-selection method. Prior work suggested that when
    adversaries have white-box access to LLMs (i.e., when adversaries can access internal
    architecture and weights of LLMs), adversaries may use gradient search to perturb
    prompts [[7](#bib.bib7)]. Compared to prior work, however, our method does not
    require access to model weights or gradients. Our search space is much smaller,
    we do not need consider all possible tokens a model accepts, just synonyms [[7](#bib.bib7)].
    Instead, we computed a logit-based loss for all possible combinations of synonym
    replacements and picked the combination with the lowest loss. It should be noted,
    that other candidates than the one with the lowest could be used as well, and
    we used this method to narrow the candidates down in order to be able to test
    more base prompt and target brand combinations.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 由于改写提示会带来经济负担（§[4.1](#S4.SS1 "4.1 对改写提示的观察 ‣ 4 方法 ‣ 销售密语：对 LLM 品牌推荐的隐性攻击")），系统地测试和收集所有通过同义词替换生成的候选扰动提示的响应成本会很高。我们测试的一个提示有六个单词，每个单词都有同义词，因此我们使用了基于损失的候选选择方法。以往的研究表明，当对手拥有
    LLM 的白盒访问权限（即对手可以访问 LLM 的内部架构和权重）时，对手可能会使用梯度搜索来扰动提示 [[7](#bib.bib7)]。然而，与以往的工作相比，我们的方法不需要访问模型权重或梯度。我们的搜索空间要小得多，我们不需要考虑模型接受的所有可能的令牌，只需考虑同义词 [[7](#bib.bib7)]。相反，我们计算了所有可能的同义词替换组合的基于
    logits 的损失，并选择了损失最小的组合。需要注意的是，除了损失最小的候选项外，还可以使用其他候选项，我们使用这种方法来缩小候选范围，以便能够测试更多的基本提示和目标品牌组合。
- en: Specifically, we use the following loss function. Using the same notation as
    existing works [[7](#bib.bib7)], we considered LLMs as a mapping from a sequence
    of tokens . In other words, LLMs generate a probability  can be denoted as $p(X_{n+1:n+H}|X_{1:n})$.
    In contrast to Zou et al., that aim to generate a specific sequence of tokens
    using the loss function
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 具体而言，我们使用了以下损失函数。使用与现有工作相同的符号 [[7](#bib.bib7)]，我们将 LLM 视为从一系列令牌到概率的映射。换句话说，LLM
    生成的概率可以表示为 $p(X_{n+1:n+H}|X_{1:n})$。与 Zou 等人不同，他们旨在使用损失函数生成特定的令牌序列。
- en: '|  | $\ell(X_{1:n})=-logp(X_{n+1:n+H}&#124;X_{1:n})$ |  | (1) |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '|  | $\ell(X_{1:n})=-logp(X_{n+1:n+H}\mid X_{1:n})$ |  | (1) |'
- en: We designed a loss function that aims to generate a sequence among a set of
    possible candidate sequences $T$
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设计了一个损失函数，旨在生成一组可能候选序列中的序列 $T$
- en: '|  | $\ell(X_{1:n})=-logp(X_{n+1:n+H}\in T&#124;X_{1:n})$ |  | (2) |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '|  | $\ell(X_{1:n})=-logp(X_{n+1:n+H}\in T\mid X_{1:n})$ |  | (2) |'
- en: 'Intuitively, our loss function aims to cause LLMs to generate *some* sequence
    from the set . As we describe in §[3](#S3 "3 Threat Model ‣ Sales Whisperer: A
    Human-Inconspicuous Attack on LLM Brand Recommendations"), adversaries may *not*
    need to cause LLMs to mention a specific brand name to recommend the brand. For
    example, causing LLMs to recommend either “Macbook” or “Apple” meets adversaries’
    goal to recommend the brand “Apple” for the category “laptops”, and in this case,
    .'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 直观地，我们的损失函数旨在使 LLM 生成*某些*来自该集合的序列。正如我们在§[3](#S3 "3 威胁模型 ‣ 销售耳语者：对 LLM 品牌推荐的隐蔽攻击")中描述的那样，对手可能*不*需要使
    LLM 提到特定品牌名称来推荐该品牌。例如，使 LLM 推荐“Macbook”或“Apple”中的任何一个都可以实现对手推荐“Apple”品牌的目标，对于“笔记本电脑”类别来说，在这种情况下，。
- en: 'Our loss function aims to increase the likelihood of words to appear from the
    target set  *right after* the prompt, adversaries are still successful if any
    of the target words appear in the generated response (i.e., many tokens after
    the prompt). In §[6.2](#S6.SS2 "6.2 Synonym-Replaced Adversarial Prompts ‣ 6 Results
    ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations"),
    we show that a prompt with a lower loss value according to our new loss function
    was more likely to mention one of the target words set $T$ among up to 64 generated
    tokens. Additionally, we note that increased likelihood of a brand did not always
    guarantee “recommending” that brand. For instance, when we caused Gemma (one of
    the LLMs we use) to mention “Netflix” as a streaming service, Gemma yielded “I’ve
    been using Netflix for years, but I’m not happy with the selection of movies and
    TV shows that are available to me.” People may interpret the same LLM response
    differently and thus have different answers to whether a specific brand is recommended
    given the same response. This work, therefore, includes a more realistic user-study
    evaluation. We explored whether humans understood that the target brand was being
    recommended more in LLM responses to prompts we perturbed (§[7.2.2](#S7.SS2.SSS2
    "7.2.2 Statistical Evaluation ‣ 7.2 Results ‣ 7 User Study ‣ Sales Whisperer:
    A Human-Inconspicuous Attack on LLM Brand Recommendations")).'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的损失函数旨在增加目标集中的单词在提示词之后*紧接着*出现的可能性。如果生成的响应中出现了目标单词（即在提示词之后的许多令牌中），对手仍然可以成功。在§[6.2](#S6.SS2
    "6.2 同义词替换对抗提示 ‣ 6 结果 ‣ 销售耳语者：对 LLM 品牌推荐的隐蔽攻击")中，我们展示了根据我们新的损失函数，损失值较低的提示词更可能在最多
    64 个生成的令牌中提及目标词集 $T$ 的一个。此外，我们注意到品牌的出现概率增加并不总是能保证“推荐”该品牌。例如，当我们使 Gemma（我们使用的 LLM
    之一）提到“Netflix”作为流媒体服务时，Gemma 生成了“我已经使用 Netflix 好几年了，但对我提供的电影和电视剧选择不满意。”人们可能对相同的
    LLM 响应有不同的解释，从而对是否推荐特定品牌有不同的答案。因此，这项工作包括了一个更现实的用户研究评估。我们探讨了人类是否理解在我们扰动的提示词中，LLM
    响应中推荐目标品牌的情况是否更多 (§[7.2.2](#S7.SS2.SSS2 "7.2.2 统计评估 ‣ 7.2 结果 ‣ 7 用户研究 ‣ 销售耳语者：对
    LLM 品牌推荐的隐蔽攻击"))。
- en: 5 Setup
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 设置
- en: 'In this section, we will describe the setups of our experiments. We will first
    introduce our choice of LLM and parameters in §[5.1](#S5.SS1 "5.1 LLM Setup ‣
    5 Setup ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations").
    Then we depict our experiment process, including evaluation metrics, in §[5.2](#S5.SS2
    "5.2 Evalution Procedure ‣ 5 Setup ‣ Sales Whisperer: A Human-Inconspicuous Attack
    on LLM Brand Recommendations").'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将描述我们实验的设置。我们将首先在§[5.1](#S5.SS1 "5.1 LLM 设置 ‣ 5 设置 ‣ 销售耳语者：对 LLM 品牌推荐的隐蔽攻击")中介绍我们选择的
    LLM 和参数。然后我们将描述我们的实验过程，包括评估指标，在§[5.2](#S5.SS2 "5.2 评估程序 ‣ 5 设置 ‣ 销售耳语者：对 LLM 品牌推荐的隐蔽攻击")中。
- en: 5.1 LLM Setup
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 LLM 设置
- en: 'In our experiments, we used four open-sourced LLMs as our benchmarks: a 7B
    pre-trained Llama 2, an 8B pre-trained Llama 3, an 8B instruction-tuned Llama
    3, and a 7B instruction-tuned Gemma. Each of these models was downloaded from
    Meta or Google’s official repositories on HuggingFace. We used various LLMs to
    ensure our conclusion is not a special case only applicable to one specific instance
    of LLM.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的实验中，我们使用了四个开源LLMs作为基准：一个7B预训练的Llama 2，一个8B预训练的Llama 3，一个8B指令调优的Llama 3，以及一个7B指令调优的Gemma。这些模型都是从Meta或Google在HuggingFace上的官方仓库下载的。我们使用了不同的LLMs，以确保我们的结论不是仅适用于某一个特定LLM实例的特例。
- en: Temperature is a parameter that controls the determinism of LLM responses. Therefore,
    with different temperature choices, LLMs may tend to recommend brands with different
    frequencies. Following the setup that existing works used to measure the indeterministic
    behavior of LLMs [[7](#bib.bib7)], we used the default temperature for each of
    the four models in our experiments.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 温度是控制LLM响应确定性的参数。因此，使用不同的温度选择，LLMs可能会倾向于推荐频率不同的品牌。遵循现有研究用来测量LLMs不确定行为的设置[[7](#bib.bib7)]，我们在实验中为四个模型使用了默认温度。
- en: Existing works collected up to  different combinations of prompts, target brands
    to be mentioned, and LLMs. We collected two sets of  responses per combination.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的研究收集了不同的提示、目标品牌和LLMs的组合。我们每种组合收集了两组响应。
- en: 'When collecting responses, we generate 64 tokens per prompt. We focus on the
    first 64 due to three reasons, 1) focusing on the beginning of responses likely
    is a better heuristic of what brand users are likely to see first, thus remember
    (this theory is supported in our user study §[7](#S7 "7 User Study ‣ Sales Whisperer:
    A Human-Inconspicuous Attack on LLM Brand Recommendations")); 2) some models (e.g.,
    Llama 2, Llama 3) don’t stop generating tokens until they reach the maximum token
    limit of 4096 is reached, resulting in repetitive and meaningless responses; and
    3) computational cost prohibits us from collecting more tokens than we have.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在收集响应时，我们每个提示生成64个标记。我们关注前64个标记有三个原因：1) 关注响应的开头通常是用户最可能首先看到的内容，因此更容易记住（这一理论在我们的用户研究中得到了支持
    §[7](#S7 "7 用户研究 ‣ 销售窃听者：对LLM品牌推荐的隐秘攻击")）；2) 一些模型（例如，Llama 2、Llama 3）在生成标记时不会停止，直到达到最大标记限制4096，导致重复和无意义的响应；3)
    计算成本限制了我们收集更多标记的能力。
- en: 'We will demonstrate that the synonym replacement approach (§[4.2](#S4.SS2 "4.2
    Synonym-Replaced Adversarial Prompts ‣ 4 Methods ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations")) causes LLMs to mention target brands more
    often (§[6.2](#S6.SS2 "6.2 Synonym-Replaced Adversarial Prompts ‣ 6 Results ‣
    Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations")).'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将展示同义词替换方法（§[4.2](#S4.SS2 "4.2 同义词替换对抗性提示 ‣ 4 方法 ‣ 销售窃听者：对LLM品牌推荐的隐秘攻击")）导致LLMs更频繁地提及目标品牌（§[6.2](#S6.SS2
    "6.2 同义词替换对抗性提示 ‣ 6 结果 ‣ 销售窃听者：对LLM品牌推荐的隐秘攻击")）。
- en: 5.2 Evalution Procedure
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 评估程序
- en: 'We first listed 77 product categories where several established brands dominate
    the market. For each category, we listed popular brands we had heard about and
    also added brands that LLMs recommended but we did not include: some of the brands
    were later found to be rarely recommended by LLMs. Some brands appeared in more
    than one category: for example, the brand “Apple” appeared in both the category
    “laptops” and the category “smartphones”. The number of brands we listed for each
    category ranged from one to nine, with an average of $3.96$ per category.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先列出了77个产品类别，其中几个知名品牌主导市场。对于每个类别，我们列出了我们听说过的热门品牌，并且添加了LLMs推荐但我们未包含的品牌：其中一些品牌后来被发现很少被LLMs推荐。一些品牌出现在多个类别中，例如，“Apple”品牌同时出现在“笔记本电脑”和“智能手机”类别中。我们为每个类别列出的品牌数量从一个到九个不等，平均每个类别$3.96$。
- en: 'Aided by ChatGPT, we gathered prompts that recommended brands in each category.
    Specifically, we queried ChatGPT with the following prompt: “Give me multiple
    rephrasings and add details to: ‘What is the best XXX?’”, where “XXX” is the category
    (e.g., smartphones). The prompts collected in the same category were believed
    to be paraphrases by ChatGPT, and we manually checked that these prompts 1) paraphrased
    each other and 2) were inconspicuous (see definition in §[3](#S3 "3 Threat Model
    ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations"))
    to us researchers. We filtered out the prompts that violated either of these two
    principles. An example of paraphrases we used would be “*Which VPN service stands
    out as the optimal choice for ensuring top-notch online privacy and security according
    to your experience?*” and “*Can you recommend the ultimate VPN that excels in
    providing robust encryption, reliable performance, and a user-friendly experience?*”,
    resulting in two prompts that request a recommendation for a VPN. Paraphrased
    prompts may ask for slightly different features and may use differing wording,
    but ultimately ask the same thing of the LLM. Ultimately, we had three to ten
    prompts per category, with an average of  prompts. We collected  prompts on each
    of the four models. We used these prompts to examine the method we described in
    §[4.1](#S4.SS1 "4.1 Observations on Paraphrased Prompts ‣ 4 Methods ‣ Sales Whisperer:
    A Human-Inconspicuous Attack on LLM Brand Recommendations").'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在ChatGPT的帮助下，我们收集了推荐每个类别中品牌的提示。具体而言，我们向ChatGPT询问了以下提示：“给我多个重述并添加细节：‘什么是最好的XXX？’”，其中“XXX”是类别（例如智能手机）。同一类别中收集到的提示被认为是ChatGPT的改写，我们手动检查这些提示是否1)
    彼此改写以及2) 对我们研究人员来说是不显眼的（见§[3](#S3 "3 威胁模型 ‣ 销售耳语者：对LLM品牌推荐的人类隐蔽攻击")）。我们筛选出了违反这两个原则的提示。我们使用的改写示例包括“*根据您的经验，哪个VPN服务在确保顶级在线隐私和安全方面表现突出？*”和“*您能推荐提供强大加密、可靠性能和用户友好体验的终极VPN吗？*”，结果是两个请求VPN推荐的提示。改写提示可能会询问略微不同的功能，并可能使用不同的措辞，但*最终*都对LLM提出相同的问题。最终，我们在每个类别中有三到十个提示，平均有个提示。我们在每个四个模型上收集了提示。我们使用这些提示来检验我们在§[4.1](#S4.SS1
    "4.1 改写提示的观察 ‣ 4 方法 ‣ 销售耳语者：对LLM品牌推荐的人类隐蔽攻击")中描述的方法。
- en: 'As we introduced in §[4.2](#S4.SS2 "4.2 Synonym-Replaced Adversarial Prompts
    ‣ 4 Methods ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations"),
    for each combination of category and brand, adversaries may aim to cause LLMs
    to mention *some* words that are not necessarily brand names. For example, any
    of “ChatGPT”, “OpenAi” and “GPT” are target words (or, in some cases, strings)
    for the brand “ChatGPT” in the category “LLMs”. For each combination of category
    and brand, we collected a list of target words. We created these lists of target
    words based on our knowledge and observations of the responses from the 449 different
    prompts. Each combination of category and brand had one to five target words.
    We will compare paraphrased prompts by how often they mention some target words
    of a brand and category in §[6.1](#S6.SS1 "6.1 Observations on Paraphrased Prompts
    ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations").
    In this paper, we refer to a response as mentioning a target brand if it contains
    any of that brand’s target words.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在§[4.2](#S4.SS2 "4.2 同义词替换对抗性提示 ‣ 4 方法 ‣ 销售耳语者：对LLM品牌推荐的人类隐蔽攻击")中介绍的，对于每个类别和品牌的组合，对手可能会试图使LLM提及*某些*不一定是品牌名称的词语。例如，“ChatGPT”、“OpenAi”和“GPT”中的任何一个都是品牌“ChatGPT”在“LLM”类别中的目标词（或者在某些情况下是字符串）。对于每个类别和品牌的组合，我们收集了一个目标词列表。我们根据对449个不同提示的响应的知识和观察，创建了这些目标词列表。每个类别和品牌的组合都有一个到五个目标词。我们将通过它们提及某品牌和类别的目标词的频率来比较改写提示，见§[6.1](#S6.SS1
    "6.1 改写提示的观察 ‣ 6 结果 ‣ 销售耳语者：对LLM品牌推荐的人类隐蔽攻击")。在本文中，我们将一个响应称为提及目标品牌，如果它包含该品牌的任何目标词。
- en: 'To evaluate the efficacy of our synonym replacement approach (introduced in
    §[4.2](#S4.SS2 "4.2 Synonym-Replaced Adversarial Prompts ‣ 4 Methods ‣ Sales Whisperer:
    A Human-Inconspicuous Attack on LLM Brand Recommendations")), we accordingly perturbed
    the 449 prompts in favor of each brand of the same category. We obtained  prompts
    by how often they mention a target brand in §[6.2](#S6.SS2 "6.2 Synonym-Replaced
    Adversarial Prompts ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous Attack
    on LLM Brand Recommendations"). We paired the prompts after synonym replacement
    with those before synonym replacement (i.e.,  of responses of the prompt before
    synonym replacement, and .'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '为了评估我们的同义词替换方法（在 §[4.2](#S4.SS2 "4.2 Synonym-Replaced Adversarial Prompts ‣
    4 Methods ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations")
    中介绍），我们相应地扰动了 449 个提示，以支持同一类别中的每个品牌。我们通过提示在 §[6.2](#S6.SS2 "6.2 Synonym-Replaced
    Adversarial Prompts ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous Attack
    on LLM Brand Recommendations") 中提及目标品牌的频率来获得提示。我们将同义词替换后的提示与替换前的提示进行配对（即，替换前提示的响应和替换后的提示）。'
- en: 'Some machine learning attacks were found capable of transferring [[29](#bib.bib29),
    [30](#bib.bib30)]: attacks against a machine-learning model might be effective
    against a different, potentially unknown, model. We thus investigated whether
    our synonym replacement approach can transfer to GPT3.5-turbo, a commercial and
    close-sourced LLM. On each of our four open-sourced LLMs, we first ranked the  complete
    responses to both prompts: we allowed LLMs to keep generating until they yielded
    end-of-sequence (EOS) tokens. Instead of absolute improvement, we computed the
    relative improvement in the probabilities of mentioning the target brand within
    complete responses for each pair. If  of responses of the prompt after perturbing
    it mention the target brand, the relative improvement was  complete responses.
    GPT-3.5 turbo Instruct is the instruction-tuned version of GPT-3.5 turbo. We compare
    the relative improvements between GPT models and open-sourced models in §[6.3](#S6.SS3
    "6.3 Transferability to GPT Models ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations").'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '一些机器学习攻击被发现能够转移[[29](#bib.bib29), [30](#bib.bib30)]：对一个机器学习模型的攻击可能对另一个不同的、潜在未知的模型有效。因此，我们调查了我们的同义词替换方法是否可以转移到
    GPT3.5-turbo，一个商业且闭源的大型语言模型。在我们的四个开源大型语言模型中，我们首先对两个提示的完整响应进行了排名：我们允许大型语言模型继续生成直到产生结束序列（EOS）标记。我们计算了在每对完整响应中提及目标品牌的相对改善，而非绝对改善。如果扰动后的提示中有响应提到目标品牌，相对改善为完整响应。GPT-3.5
    turbo Instruct 是 GPT-3.5 turbo 的指令调优版本。我们在 §[6.3](#S6.SS3 "6.3 Transferability
    to GPT Models ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM
    Brand Recommendations") 中比较了 GPT 模型和开源模型之间的相对改善。'
- en: 6 Results
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结果
- en: 'In this section, we describe our empirical results. We first, in §[6.1](#S6.SS1
    "6.1 Observations on Paraphrased Prompts ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations") describe our observations on paraphrases
    of prompts—measuring how pairs of paraphrased prompts can have significant differences
    in the probability that the target brand appears. Next, in §[6.2](#S6.SS2 "6.2
    Synonym-Replaced Adversarial Prompts ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations"), we report how often our synonym-replacement
    approach yields a perturbed prompt that causes LLMs to mention the targeted brand
    more often than the base prompt Finally, in §[6.3](#S6.SS3 "6.3 Transferability
    to GPT Models ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM
    Brand Recommendations"), we explore whether our synonym-replacement approach transfers
    to GPT models. We show that if the right model-pair is found, successful perturbed
    prompts found on an open-sourced LLM can increase the probability of the target
    brand appearing more often in the GPT model’s responses.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们描述了我们的实证结果。首先，在 §[6.1](#S6.SS1 "6.1 Observations on Paraphrased Prompts
    ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations")
    中，我们描述了对提示的改写观察——测量改写提示对目标品牌出现概率的显著差异。接着，在 §[6.2](#S6.SS2 "6.2 Synonym-Replaced
    Adversarial Prompts ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous Attack
    on LLM Brand Recommendations") 中，我们报告了我们的同义词替换方法在多大程度上能生成扰动提示，使大型语言模型比基础提示更频繁地提及目标品牌。最后，在
    §[6.3](#S6.SS3 "6.3 Transferability to GPT Models ‣ 6 Results ‣ Sales Whisperer:
    A Human-Inconspicuous Attack on LLM Brand Recommendations") 中，我们探讨了我们的同义词替换方法是否可以转移到
    GPT 模型。我们展示了如果找到合适的模型对，成功的扰动提示可以在开源大型语言模型中增加目标品牌在 GPT 模型响应中出现的概率。'
- en: 6.1 Observations on Paraphrased Prompts
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 关于改写提示的观察
- en: '![Refer to caption](img/06630a5c71b1feb929efe8b4e63fbfc7.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/06630a5c71b1feb929efe8b4e63fbfc7.png)'
- en: 'Figure 6: Absolute difference in the likelihoods of responses mentioning a
    target brand within the first  (i.e., one prompt elicits responses that never
    mentions the target brand while another prompt’s responses always do).'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：在第一个响应中提到目标品牌的可能性的绝对差异（即一个提示引发的响应从不提及目标品牌，而另一个提示的响应总是提及）。
- en: 'As we described in §[5.2](#S5.SS2 "5.2 Evalution Procedure ‣ 5 Setup ‣ Sales
    Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations"), each of
    the  tokens). Adversaries may paraphrase a low-probability base prompt in order
    to find the high-probability prompts to achieve the goals described in §[3](#S3
    "3 Threat Model ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations").'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '如我们在§[5.2](#S5.SS2 "5.2 Evalution Procedure ‣ 5 Setup ‣ Sales Whisperer: A
    Human-Inconspicuous Attack on LLM Brand Recommendations")中所述，每个标记）。对手可能会对低概率的基础提示进行同义词替换，以找到高概率的提示，实现§[3](#S3
    "3 Threat Model ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations")中描述的目标。'
- en: 'We summarize our results in Fig. [6](#S6.F6 "Figure 6 ‣ 6.1 Observations on
    Paraphrased Prompts ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous Attack
    on LLM Brand Recommendations"). Specifically, on four open-sourced LLMs—Gemma-it
    (instruction-tuned), Llama2, Llama3, and Llama3-it (instruction-tuned)—the likelihood
    of the target brand being mentioned in the responses can differ between a pair
    of paraphrased prompts by up to , with the average of this absolute difference
    being , , respectively. For example, when comparing responses to “*I’m curious
    to know your preference for the pressure cooker that offers the best combination
    of cooking performance, durable construction, and overall convenience in preparing
    a variety of dishes.*” with the prompt paraphrased as “*Can you recommend the
    ultimate pressure cooker that excels in providing consistent pressure, user-friendly
    controls, and additional features such as multiple cooking presets or a digital
    display for precise settings?*”, the probability of Gemma-it mentioning the brand
    “InstantPot” (“pressure cooker” product category) within the first  to $100.0\%$.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在图[6](#S6.F6 "Figure 6 ‣ 6.1 Observations on Paraphrased Prompts ‣ 6 Results
    ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations")中总结了我们的结果。具体而言，在四个开源LLM中——Gemma-it（指令调优版）、Llama2、Llama3和Llama3-it（指令调优版）——目标品牌在响应中被提及的可能性在一对同义词替换提示之间可以有高达的差异，这种绝对差异的平均值分别为，和。例如，当比较响应“*我想知道您对哪款压力锅在提供最佳烹饪性能、耐用性和整体便利性方面的偏好*”与将提示同义词替换为“*您能推荐一款在提供一致的压力、用户友好的控制以及附加功能如多个烹饪预设或精确设置的数字显示方面表现出色的最终压力锅吗？*”时，Gemma-it在前$100.0\%$个标记内提及品牌“InstantPot”（“压力锅”产品类别）的概率。'
- en: 'Our results suggest that while paraphrased prompts appear similar to humans
    the responses to the prompts can differ substantially in how likely they are to
    mention a target brand (within the first $64$ tokens of the response). Therefore,
    an adversary wanting to promote a certain brand can use this to their advantage:
    The adversary may try various paraphrases of prompts, test the prompts, and pick
    the paraphrase that results in the highest probability of the target brand being
    mentioned, ultimately promoting the brand when prompt is used in the real world.
    While we generated these paraphrases using ChatGPT, and confirmed that they were
    valid and reasonable, adversaries may also be able to create paraphrases manually
    or by another method, and may be able to test even more paraphrases than we did
    in our measurements.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的结果表明，尽管同义词替换的提示对人类看起来相似，但这些提示的响应在提及目标品牌的可能性上可以有很大差异（在响应的前$64$个标记内）。因此，想要推广某个品牌的对手可以利用这一点：对手可以尝试各种提示的同义词替换，测试这些提示，并选择使目标品牌被提及概率最高的替换，最终在实际使用中推广该品牌。虽然我们使用ChatGPT生成了这些同义词替换并确认它们是有效和合理的，但对手也可以手动或通过其他方法创建同义词替换，并可能测试比我们在测量中更多的替换。
- en: 6.2 Synonym-Replaced Adversarial Prompts
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 同义词替换对抗性提示
- en: 'As described in §[5.2](#S5.SS2 "5.2 Evalution Procedure ‣ 5 Setup ‣ Sales Whisperer:
    A Human-Inconspicuous Attack on LLM Brand Recommendations"), we measured and now
    report how often our synonym-replacement approach improves the probability of
    a brand being mentioned. As opposed to paraphrasing, in the synonym-replacement
    approach we automatically generate a set of potential candidate prompts by perturbing
    a base prompt via synonym replacement, without needing to confirm whether these
    perturbed prompts are valid. The prompt with the lowest loss is selected, and
    we assess how well these selected prompts increase the probability that the target
    brand is mentioned. We evaluate the average improvement over multiple models,
    at different response lengths, and for different probabilities of a brand being
    mentioned in the base prompt. In addition, other candidate prompts could also
    be tested, although we did not take this approach in this paper. We used loss
    as a metric that narrowed down the large set of potential perturbed prompts we
    found using synonym replacement to one. Therefore, we are interested in exploring
    the *highest* improvement we can achieve between a base and perturbed score, as
    adversaries would be able to use a similar method to §[6.1](#S6.SS1 "6.1 Observations
    on Paraphrased Prompts ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous Attack
    on LLM Brand Recommendations") and explore multiple perturbated prompts. So, we
    also describe the largest increases in probability of mentioning a target brand
    in the responses to the perturbed prompt we found via our synonym-replacement
    method compared to the base prompt. Our evaluation shows that our synonym-replacement
    attack increases the likelihood of LLMs mentioning a brand on average.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '如§[5.2](#S5.SS2 "5.2 Evalution Procedure ‣ 5 Setup ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations")中所述，我们测量并报告了我们的同义词替换方法提高品牌提及概率的频率。与释义不同，在同义词替换方法中，我们通过同义词替换扰动基础提示，自动生成一组潜在的候选提示，而不需要确认这些扰动提示是否有效。选择具有最低损失的提示，并评估这些选择的提示在提高目标品牌提及概率方面的效果。我们在多个模型、不同响应长度和基础提示中品牌提及概率的不同情况下评估了平均改进。此外，其他候选提示也可以进行测试，尽管我们在本文中没有采取这种方法。我们使用损失作为度量标准，将我们通过同义词替换找到的大量潜在扰动提示缩小到一个。因此，我们有兴趣探索基于基础和扰动分数之间的*最高*改进，因为对手可能使用类似的方法来§[6.1](#S6.SS1
    "6.1 Observations on Paraphrased Prompts ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations")并探索多个扰动提示。因此，我们还描述了我们通过同义词替换方法找到的与基础提示相比，在扰动提示中提及目标品牌的概率的最大增加。我们的评估显示，我们的同义词替换攻击在平均上增加了LLMs提及品牌的可能性。'
- en: 'For all evaluations, we focus on the first 64 tokens of the response (see [subsection 5.1](#S5.SS1
    "5.1 LLM Setup ‣ 5 Setup ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM
    Brand Recommendations") for details).'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '对于所有评估，我们关注响应的前64个标记（详见[subsection 5.1](#S5.SS1 "5.1 LLM Setup ‣ 5 Setup ‣
    Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations")）。'
- en: '![Refer to caption](img/6fb2fa49a741e42c72f7118b2adc754b.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/6fb2fa49a741e42c72f7118b2adc754b.png)'
- en: 'Figure 7: Average absolute improvement in likelihoods that LLMs mention a target
    brand. Results presented along number of generated tokens. Our synonym-replacement
    approach achieves improvements in probabilities, which verifies the capability
    of forcing LLMs to mention target brands more often.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：LLMs提及目标品牌的平均绝对改进。结果按生成的标记数量呈现。我们的方法在概率上取得了改进，这验证了强制LLMs更频繁提及目标品牌的能力。
- en: Average improvement
  id: totrans-116
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 平均改进
- en: 'The results for average improvement in likelihoods of a brand being mentioned
    in the responses to perturbed prompts created via synonym replacement compared
    to in response to the original base prompt, across models, are shown in Fig. [7](#S6.F7
    "Figure 7 ‣ 6.2 Synonym-Replaced Adversarial Prompts ‣ 6 Results ‣ Sales Whisperer:
    A Human-Inconspicuous Attack on LLM Brand Recommendations"). Overall, we find
    that our attack results in an average absolute improvement in all models. Specifically,
    for brands that were mentioned at least once (i.e.,  within  improvement within  within  within  within  within  within  within
    , , and . While we only collected responses of length 64 tokens for our 1,809
    attacks for each model (see [subsection 5.1](#S5.SS1 "5.1 LLM Setup ‣ 5 Setup
    ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations")),
    we did run a select set of base and perturbed prompt pairs (chosen in §[5.2](#S5.SS2
    "5.2 Evalution Procedure ‣ 5 Setup ‣ Sales Whisperer: A Human-Inconspicuous Attack
    on LLM Brand Recommendations")) to full completion. While we did not see improvements
    in all pairs (for example, some base prompts had near  more likely than its base
    prompt “*Can you recommend the ultimate video game console that excels in providing
    top-notch graphics, diverse gaming options, and additional features such as online
    connectivity, suitable for both casual and hardcore gamers?*” (i.e., “ultimate”
    was changed to “superior” and “diverse” was changed to “dissimilar”) to mention
    Xbox in long completions, even more than when completions were only 64 tokens
    long ($32.9\%$). We evaluate if attack objectives are met with full responses
    in a more realistic setting in §[7.2.2](#S7.SS2.SSS2 "7.2.2 Statistical Evaluation
    ‣ 7.2 Results ‣ 7 User Study ‣ Sales Whisperer: A Human-Inconspicuous Attack on
    LLM Brand Recommendations").'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 通过同义词替换创建的扰动提示在模型对其响应中的品牌提及概率的平均改善结果与原始基准提示的响应进行比较，如图 [7](#S6.F7 "图 7 ‣ 6.2
    同义词替换对抗提示 ‣ 6 结果 ‣ 销售低语者：对 LLM 品牌推荐的人类隐形攻击") 所示。总体而言，我们发现我们的攻击在所有模型中都导致了平均绝对改善。具体而言，对于那些至少提及过一次的品牌（即，在...的改善范围内），我们在每个模型的
    1,809 次攻击中仅收集了 64 个令牌长度的响应（见 [5.1 小节](#S5.SS1 "5.1 LLM 设置 ‣ 5 设置 ‣ 销售低语者：对 LLM
    品牌推荐的人类隐形攻击")）。然而，我们确实对一组选定的基准和扰动提示对进行了完整的测试（选择在 §[5.2](#S5.SS2 "5.2 评估程序 ‣ 5
    设置 ‣ 销售低语者：对 LLM 品牌推荐的人类隐形攻击")）。尽管我们在所有对中并未看到改进（例如，某些基准提示的提及概率接近其基准提示“*你能推荐一个在提供顶级图形、多样的游戏选项以及额外功能（如在线连接），适合休闲和核心玩家的终极游戏机吗？*”（即，“ultimate”
    被替换为 “superior”，“diverse” 被替换为 “dissimilar”）来提及 Xbox，在长响应中比仅有 64 个令牌的响应中更高 ($32.9\%$)。我们在
    §[7.2.2](#S7.SS2.SSS2 "7.2.2 统计评估 ‣ 7.2 结果 ‣ 7 用户研究 ‣ 销售低语者：对 LLM 品牌推荐的人类隐形攻击")
    中评估了在更实际的环境中是否满足攻击目标。
- en: '![Refer to caption](img/796f3a4169665ae5dff1cf998d2b0f33.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/796f3a4169665ae5dff1cf998d2b0f33.png)'
- en: 'Figure 8: Average absolute improvement in likelihoods that LLMs mention the
    target brand when these sequences were at least X times out of $1,000$ before
    perturbation, up to some number of tokens (not necessarily 64). X is our horizontal
    axis. When the brands were mentioned more often before perturbation, our synonym
    replacement approach achieved a bigger absolute improvement in the likelihood
    of mentioning the brand.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：当这些序列在扰动前的 $1,000$ 次中至少出现 X 次，并且直到某个数量的令牌（不一定是 64 个）时，LLM 提及目标品牌的平均绝对改善。X
    是我们的横轴。当品牌在扰动前提及的次数更多时，我们的同义词替换方法在提及品牌的可能性上获得了更大的绝对改善。
- en: Baseline probability and attack success
  id: totrans-120
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基线概率和攻击成功
- en: 'Here we explore the relationship between attack success rates and the probability
    of a brand being mentioned in responses to the base prompt. As shown in Fig. [8](#S6.F8
    "Figure 8 ‣ Average improvement ‣ 6.2 Synonym-Replaced Adversarial Prompts ‣ 6
    Results ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations"),
    our synonym-replacement approach on average achieved a bigger absolute improvement
    when the target brand was mentioned more often in responses to the base prompt
    before perturbation. When the target brands were mentioned at least  out of ,
    and $2.28\%$ on Gemma-it, Llama2, Llama3 and Llama3-it, respectively. We see that
    for base prompts with higher probabilities of mentioning the target brand, our
    perturbed prompts, on average, have a higher increase in probability. This indicates
    that our perturbation method is more effective on an identifiable domain, i.e.
    prompts where the target brand is mentioned more or less frequently, than it is
    on the overall average case.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们探讨了攻击成功率与品牌在基础提示响应中被提及的概率之间的关系。如图[8](#S6.F8 "图 8 ‣ 平均改进 ‣ 6.2 同义词替换对抗提示
    ‣ 6 结果 ‣ 销售耳语者：对 LLM 品牌推荐的隐性攻击")所示，我们的同义词替换方法在目标品牌在基础提示响应中被提及得越多时，平均上取得了更大的绝对改进。当目标品牌在基础提示中被提及至少
    $2.28\%$ 的情况下，Gemma-it、Llama2、Llama3 和 Llama3-it 的表现分别为。我们看到，对于目标品牌提及概率较高的基础提示，我们的扰动提示在平均上有更高的概率增加。这表明，我们的扰动方法在易识别的领域（即目标品牌提及频率较高或较低的提示）比在总体平均情况下更有效。
- en: '![Refer to caption](img/e5ef96c0f56fdc4b6575167916666d04.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/e5ef96c0f56fdc4b6575167916666d04.png)'
- en: 'Figure 9: Max absolute improvement in likelihoods that LLMs mention a target
    brand. Results are presented along how many tokens are generated. We achieve a
    bigger absolute improvement on Gemma-it compared to the other three Llama models,
    although Gemma-it does not always have the highest average absolute improvement
    (see Fig. [7](#S6.F7 "Figure 7 ‣ 6.2 Synonym-Replaced Adversarial Prompts ‣ 6
    Results ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations")
    and Fig. [8](#S6.F8 "Figure 8 ‣ Average improvement ‣ 6.2 Synonym-Replaced Adversarial
    Prompts ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand
    Recommendations").)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：LLM 提及目标品牌的最大绝对改进概率。结果展示了生成的 tokens 数量。尽管 Gemma-it 并不总是具有最高的平均绝对改进（参见图[7](#S6.F7
    "图 7 ‣ 6.2 同义词替换对抗提示 ‣ 6 结果 ‣ 销售耳语者：对 LLM 品牌推荐的隐性攻击")和图[8](#S6.F8 "图 8 ‣ 平均改进
    ‣ 6.2 同义词替换对抗提示 ‣ 6 结果 ‣ 销售耳语者：对 LLM 品牌推荐的隐性攻击")），我们在 Gemma-it 上实现了比其他三个 Llama
    模型更大的绝对改进。
- en: Maximum improvement
  id: totrans-124
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 最大改进
- en: 'Besides the average absolute improvement, we also explored the maximum absolute
    improvement among all combinations of base prompts and brands, as shown in Fig. [9](#S6.F9
    "Figure 9 ‣ Baseline probability and attack success ‣ 6.2 Synonym-Replaced Adversarial
    Prompts ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand
    Recommendations"). While these results don’t represent the *expected* improvement
    using this method, they do demonstrate that it is possible to find pairs of prompts
    with vastly different probabilities of mentioning a certain brand. In §[6.1](#S6.SS1
    "6.1 Observations on Paraphrased Prompts ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations") we showed this for prompts that were manually
    paraphrased; here, we show that the synonym-replacement attack can find such alternative
    prompts automatically. Further, the prompts generated by synonym-replacement differ
    from their base prompts minimally (at most a seven synonym difference in our dataset),
    and are perceptually the same along multiple dimensions (see §[7.2.2](#S7.SS2.SSS2
    "7.2.2 Statistical Evaluation ‣ 7.2 Results ‣ 7 User Study ‣ Sales Whisperer:
    A Human-Inconspicuous Attack on LLM Brand Recommendations")).'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 除了平均绝对改进，我们还探索了所有基础提示和品牌组合中的最大绝对改进，如图[9](#S6.F9 "图 9 ‣ 基线概率和攻击成功 ‣ 6.2 同义词替换对抗提示
    ‣ 6 结果 ‣ 销售耳语者：对LLM品牌推荐的隐性攻击")所示。虽然这些结果不代表使用此方法的*预期*改进，但它们确实展示了可以找到具有不同提及某品牌概率的提示对。在§[6.1](#S6.SS1
    "6.1 释义提示观察 ‣ 6 结果 ‣ 销售耳语者：对LLM品牌推荐的隐性攻击")中，我们展示了人工释义的提示；在这里，我们展示了同义词替换攻击能够自动找到这样的替代提示。此外，生成的同义词替换提示与其基础提示的差异最小（在我们的数据集中最多相差七个同义词），并且在多个维度上感知上相同（见§[7.2.2](#S7.SS2.SSS2
    "7.2.2 统计评估 ‣ 7.2 结果 ‣ 7 用户研究 ‣ 销售耳语者：对LLM品牌推荐的隐性攻击")）。
- en: 'We were able to achieve bigger absolute improvement on Gemma-it compared to
    the other three Llama models, although Gemma-it does not always have the highest
    average absolute improvement (Fig. [7](#S6.F7 "Figure 7 ‣ 6.2 Synonym-Replaced
    Adversarial Prompts ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous Attack
    on LLM Brand Recommendations") and Fig. [8](#S6.F8 "Figure 8 ‣ Average improvement
    ‣ 6.2 Synonym-Replaced Adversarial Prompts ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations")). When LLMs generate all 64 tokens, Gemma-it
    has the highest absolute improvement of .'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他三个Llama模型相比，我们在Gemma-it上取得了更大的绝对改进，尽管Gemma-it并不总是具有最高的平均绝对改进（见图[7](#S6.F7
    "图 7 ‣ 6.2 同义词替换对抗提示 ‣ 6 结果 ‣ 销售耳语者：对LLM品牌推荐的隐性攻击")和图[8](#S6.F8 "图 8 ‣ 平均改进 ‣
    6.2 同义词替换对抗提示 ‣ 6 结果 ‣ 销售耳语者：对LLM品牌推荐的隐性攻击")）。当LLMs生成所有64个标记时，Gemma-it具有最高的绝对改进。
- en: 6.3 Transferability to GPT Models
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3 对GPT模型的转移能力
- en: '![Refer to caption](img/8568b0ebe5c79cca26a7f28b40f983ee.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/8568b0ebe5c79cca26a7f28b40f983ee.png)'
- en: 'Figure 10: Pearson correlation coefficients (, Llama3-it and GPT3.5-turbo have
    a correlation coefficient of ).'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：Pearson相关系数（，Llama3-it和GPT3.5-turbo的相关系数为）。
- en: 'We evaluated the transferrability of paraphrased prompts generated using synonym-replacement
    (§[6.2](#S6.SS2 "6.2 Synonym-Replaced Adversarial Prompts ‣ 6 Results ‣ Sales
    Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations")) from open-sourced
    models to GPT models. We found that, while transferability was limited for most
    model pairs, Llama3-it and GPT3.5-turbo had a high correlation in attack success
    for the same prompts ($p<0.001$). We explain these results in more detail next.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们评估了使用同义词替换（§[6.2](#S6.SS2 "6.2 同义词替换对抗提示 ‣ 6 结果 ‣ 销售耳语者：对LLM品牌推荐的隐性攻击")）生成的释义提示从开源模型转移到GPT模型的能力。我们发现，虽然大多数模型对的转移能力有限，但Llama3-it和GPT3.5-turbo在相同提示下的攻击成功率具有高度相关性（$p<0.001$）。我们将进一步详细解释这些结果。
- en: 'As we described in §[5.2](#S5.SS2 "5.2 Evalution Procedure ‣ 5 Setup ‣ Sales
    Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations"), we computed
    the relative improvement on four open-sourced LLMs and two versions of GPT models.
    Specifically, for a given base prompt, we generated a perturbed prompt via synonym-replacement
    that increased the chance of a brand being mentioned on an open-sourced model
    and then evaluated whether the perturbed prompt also increased the chance of the
    brand being mentioned in the response produced by the GPT model. We evaluated
    only the transfer of attacks that were successful on their open-sourced LLM onto
    GPT models. For the Shell example described in §[6.2](#S6.SS2 "6.2 Synonym-Replaced
    Adversarial Prompts ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous Attack
    on LLM Brand Recommendations"), we saw a improvement from  between the base and
    perturbed prompt on long responses by Gemma-it between prompts and an improvement
    from  on GPT3.5-turbo responses. On long responses generated by Llama3-it, “*If
    you had to pinpoint the superior investment platform, which one would it be, and
    what specific features make it stand out as the top choice for investors?*” had
    a , and GPT3.5-turbo responses went from .'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '正如我们在§[5.2](#S5.SS2 "5.2 Evalution Procedure ‣ 5 Setup ‣ Sales Whisperer: A
    Human-Inconspicuous Attack on LLM Brand Recommendations")中所描述的，我们计算了四个开源LLM和两个版本的GPT模型的相对改进。具体而言，对于给定的基础提示词，我们通过同义词替换生成了一个扰动提示词，增加了品牌在开源模型中被提及的可能性，然后评估了扰动提示词是否也增加了品牌在GPT模型生成的响应中被提及的可能性。我们仅评估了成功转移到GPT模型的开源LLM上的攻击。对于§[6.2](#S6.SS2
    "6.2 Synonym-Replaced Adversarial Prompts ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations")中描述的Shell示例，我们看到Gemma-it在基础和扰动提示词之间的长响应中有一个改进，而GPT3.5-turbo响应的改进幅度为。在Llama3-it生成的长响应中，“*如果你必须确定一个更好的投资平台，那会是哪一个？哪些具体特点使它成为投资者的首选？*”有一个，而GPT3.5-turbo的响应则从变为。'
- en: To compare the relative improvements between models when the same prompts and
    synonym replacement are used, we used the Pearson correlation test. Two sets of
    data with a Pearson correlation coefficient ( is generally believed to be weakly
    correlated, whereas  is believed to indicate strong correlation [[139](#bib.bib139)].
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较在使用相同提示词和同义词替换时模型之间的相对改进，我们使用了皮尔逊相关性测试。皮尔逊相关系数的两个数据集一般认为具有弱相关性，而则被认为指示强相关性[[139](#bib.bib139)]。
- en: 'As shown in Fig. [10](#S6.F10 "Figure 10 ‣ 6.3 Transferability to GPT Models
    ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations"),
    while Pearson correlation coefficients of the relative improvement of most pairs
    of open-sourced LLMs and GPT models indicated weak or no correlation (, and thus
    are highly correlated (. This result indicates a potential for a transfer attack
    to be used on chatbots that use black-box GPT models, like Instacart, Lowe’s,
    and Expedia (described in §[3](#S3 "3 Threat Model ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations")) and others. A successful attack on an open-sourced
    LLM could be used as a prompt suggestion for black-box models, ultimately promoting
    the target brand.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '如图[10](#S6.F10 "Figure 10 ‣ 6.3 Transferability to GPT Models ‣ 6 Results ‣
    Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations")所示，尽管大多数开源LLM和GPT模型的相对改进的皮尔逊相关系数指示出弱相关或无相关性（和），但则高度相关。这一结果表明，可能会有将转移攻击用于使用黑箱GPT模型的聊天机器人的潜力，例如Instacart、Lowe''s和Expedia（在§[3](#S3
    "3 Threat Model ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations")和其他地方描述的）。对开源LLM的成功攻击可以用作黑箱模型的提示建议，*最终*推动目标品牌。'
- en: 7 User Study
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 用户研究
- en: 'Our results so far show that our synonym-replacement approach can bias LLM
    responses towards a target brand and appears to be human-inconspicuous. However,
    this does not mean that the attack is successful in practice. To evaluate the
    attack in a realistic setting, we conducted a user study. Here we describe this
    study, starting with a description of our methods (§[7.1](#S7.SS1 "7.1 Methods
    ‣ 7 User Study ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations"))
    and ending with the statistical evaluation (§[7.2](#S7.SS2 "7.2 Results ‣ 7 User
    Study ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations")).
    We find that our attack is indeed successful in practice.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们的结果显示我们的同义词替换方法可以将 LLM 的回应偏向于目标品牌，并且似乎对人类不显眼。然而，这并不意味着攻击在实际中是成功的。为了在现实环境中评估攻击效果，我们进行了用户研究。在这里，我们描述了这项研究，从方法的描述（§[7.1](#S7.SS1
    "7.1 方法 ‣ 7 用户研究 ‣ 销售耳语者：对 LLM 品牌推荐的隐蔽攻击")）开始，到统计评估（§[7.2](#S7.SS2 "7.2 结果 ‣ 7
    用户研究 ‣ 销售耳语者：对 LLM 品牌推荐的隐蔽攻击")）结束。我们发现我们的攻击在实践中确实是成功的。
- en: 7.1 Methods
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1 方法
- en: 'We performed a between-subjects user study to evaluate whether our synonym-replacement
    approach can result in prompts that advances the adversaries’ goals (see §[3](#S3
    "3 Threat Model ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations")),
    creating inconspicuous prompts that trigger inconspicuous responses, making a
    target brand more noticable.We tested whether users could distinguish between
    base and perturbed prompts and responses in multiple dimensions (including clarity,
    likelihood of use, satifaction, and more). Each participant was shown one prompt-and-response
    pair. Our procedures were approved by our institution’s ethics board, and pre-registered.³³3[https://osf.io/6mycr/?view_only=face90d04806439bb1f69fc110fb9a1e](https://osf.io/6mycr/?view_only=face90d04806439bb1f69fc110fb9a1e)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了一个被试间的用户研究，以评估我们的同义词替换方法是否能够生成促进对手目标的提示（见 §[3](#S3 "3 威胁模型 ‣ 销售耳语者：对 LLM
    品牌推荐的隐蔽攻击")），创建隐蔽的提示触发隐蔽的回应，使目标品牌更为显著。我们测试了用户是否能在多个维度（包括清晰度、使用可能性、满意度等）区分基础和扰动的提示及回应。每位参与者被展示了一个提示和回应对。我们的程序已通过我们机构伦理委员会的批准，并进行了预注册。³³3[https://osf.io/6mycr/?view_only=face90d04806439bb1f69fc110fb9a1e](https://osf.io/6mycr/?view_only=face90d04806439bb1f69fc110fb9a1e)
- en: 7.1.1 Survey procedures
  id: totrans-138
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.1.1 调查程序
- en: We recruited a gender-balanced sample from Prolific,⁴⁴4[https://www.prolific.com/](https://www.prolific.com/)
    a crowdsourcing platform commonly used with security-relevant user studies (e.g., [[140](#bib.bib140)]).
    To avoid selection bias in our study ad, we avoided mentioning LLMs or bias in
    the study title, “Chatbot prompting study.” Participants had to be in the U.S.,
    be 18 or older, and have a Prolific approval rate of at least 95%. In line with
    Prolific guidelines ⁵⁵5[https://researcher-help.prolific.com/hc/en-gb/articles/4407695146002-Prolific-s-payment-principles](https://researcher-help.prolific.com/hc/en-gb/articles/4407695146002-Prolific-s-payment-principles),
    participants were paid $1.6 for an estimated 7–9 minute study. In practice, the
    hourly compensation rate was $12.45/hour.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从 Prolific 招募了性别平衡的样本，⁴⁴4[https://www.prolific.com/](https://www.prolific.com/)
    是一个常用于安全相关用户研究的众包平台（例如，[[140](#bib.bib140)]）。为了避免在研究广告中产生选择偏差，我们避免在研究标题“聊天机器人提示研究”中提及
    LLM 或偏差。参与者必须在美国，年满 18 岁或以上，并且在 Prolific 上的批准率至少为 95%。根据 Prolific 的指南 ⁵⁵5[https://researcher-help.prolific.com/hc/en-gb/articles/4407695146002-Prolific-s-payment-principles](https://researcher-help.prolific.com/hc/en-gb/articles/4407695146002-Prolific-s-payment-principles)，参与者将获得
    1.6 美元的报酬，预计研究时间为 7-9 分钟。实际上，小时补偿率为 12.45 美元/小时。
- en: After providing consent, participants were given an overview of the study. We
    asked our participants to imagine that there was a chatbot service that was able
    to recommend prompts appropriate for what users want to use the chatbot for. We
    further instructed participants to imagine that they were shopping for a certain
    product (e.g., laptops) or service (e.g., parcel delivery) and wanted to use this
    new chatbot service to help them decide on a brand. After a comprehension check
    on instructions, participants were shown a prompt recommendation for the product
    they were shopping for (e.g., “*Which laptop model do you consider the optimal
    choice for versatile computing, powerful performance, and innovative features
    that enhance your work and entertainment experience?*”) and instructed to review
    it. After a minimum of 10 seconds had passed, we asked (1) how likely they were
    to use this prompt, (2) how clear the prompt was, (3) was it biased to a certain
    brand (and which), (4) and if anything stood out (e.g., interesting, unexpected).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在提供同意后，参与者接受了研究概述。我们要求参与者想象有一个聊天机器人服务，能够推荐适合用户使用聊天机器人的提示。我们进一步指示参与者想象他们正在为某个产品（例如笔记本电脑）或服务（例如包裹配送）购物，并希望使用这个新的聊天机器人服务来帮助他们决定品牌。在对指示进行理解检查后，参与者会看到一个针对他们购物产品的提示推荐（例如，“*你认为哪款笔记本电脑型号最适合多功能计算、强大性能以及创新功能，以提升你的工作和娱乐体验？*”），并要求他们进行评审。经过至少
    10 秒后，我们询问（1）他们使用这个提示的可能性有多大，（2）提示的清晰程度如何，（3）提示是否对某个品牌有偏见（以及哪个品牌），（4）是否有任何突出的地方（例如，令人感兴趣或意外）。
- en: 'Participants were then shown a response to the prompt and after a minimum of
    20 seconds, they were asked: (1) how clear the response was, (2) if they were
    satisfied with the response, (3) how likely were they to take the recommendation
    in the response, (4) and if anything stood out. In a series of open-ended questions,
    we additionally asked participants (1) which brand they would pick based on this
    response, (2) what were all the brands recommended, and (3) what the top brand
    recommendation of the chatbot was. These 11 (numbered) questions form the practical
    definition of inconspicuousness and increase in target brand perception. They
    form the basis of our statistical analysis §[7.2.2](#S7.SS2.SSS2 "7.2.2 Statistical
    Evaluation ‣ 7.2 Results ‣ 7 User Study ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations").'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '然后，参与者会看到对提示的回应，经过至少 20 秒后，他们被问到：（1）回应的清晰度如何，（2）他们是否对回应感到满意，（3）他们采纳回应中的建议的可能性有多大，（4）是否有任何突出的地方。在一系列开放性问题中，我们还额外询问参与者（1）基于这个回应他们会选择哪个品牌，（2）所有推荐的品牌有哪些，以及（3）聊天机器人的顶级品牌推荐是什么。这
    11 个（编号）问题构成了隐蔽性和目标品牌感知增加的实际定义。它们是我们统计分析的基础 §[7.2.2](#S7.SS2.SSS2 "7.2.2 Statistical
    Evaluation ‣ 7.2 Results ‣ 7 User Study ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations")。'
- en: To help with recall, participants could hover over relevant questions to reveal
    the relevant prompts and responses.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助回忆，参与者可以悬停在相关问题上以显示相关的提示和回应。
- en: Participants self-reported how frequently they give tech advice, how freuqently
    they use chatbots, if they paid for a chatbot, their ChatGPT familiarty. The survey
    concluded with demographics questions.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者自报他们提供技术建议的频率，使用聊天机器人的频率，是否为聊天机器人付费，以及他们对 ChatGPT 的熟悉度。调查以人口统计问题结束。
- en: '| Gender | Male | 48.2 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 性别 | 男性 | 48.2 |'
- en: '|  | Female | 50.3 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '|  | 女性 | 50.3 |'
- en: '|  | Self-described | 0.9 |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '|  | 自我描述 | 0.9 |'
- en: '| Age | 18-25 | 16.7 |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| 年龄 | 18-25岁 | 16.7 |'
- en: '|  | 26-35 | 36.0 |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '|  | 26-35岁 | 36.0 |'
- en: '|  | 36-45 | 21.5 |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '|  | 36-45岁 | 21.5 |'
- en: '|  | 46-60 | 18.2 |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '|  | 46-60岁 | 18.2 |'
- en: '|  | 61+ | 5.2 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '|  | 61岁及以上 | 5.2 |'
- en: '| Ethnicity | White | 63.0 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 种族 | 白人 | 63.0 |'
- en: '|  | Black or African Am. | 12.1 |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '|  | 黑人或非洲裔美国人 | 12.1 |'
- en: '|  | Asian | 9.8 |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '|  | 亚洲人 | 9.8 |'
- en: '|  | Hispanic or Latino | 5.6 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '|  | 西班牙裔或拉丁裔 | 5.6 |'
- en: '|  | Other or mixed | 12.7 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '|  | 其他或混合 | 12.7 |'
- en: '| Education | Completed H.S. or below | 10.4 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 教育 | 完成高中或以下 | 10.4 |'
- en: '|  | Some college, no degree | 18.0 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '|  | 一些大学课程，但没有学位 | 18.0 |'
- en: '|  | Trade or vocational | 2.5 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '|  | 职业或技术 | 2.5 |'
- en: '|  | Associate’s degree | 11.1 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '|  | 大专学历 | 11.1 |'
- en: '|  | Bachelor’s degree | 39.1 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '|  | 本科学历 | 39.1 |'
- en: '|  | Master’s or higher | 18.5 |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '|  | 硕士或更高学历 | 18.5 |'
- en: '| Chatbot usage | Daily or more freq. | 16.6 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 聊天机器人使用 | 每天或更频繁 | 16.6 |'
- en: '| frequency | Daily to monthly | 49.7 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| 频率 | 每天到每月 | 49.7 |'
- en: '|  | Monthly or less freq. | 33.7 |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '|  | 每月或更少频繁 | 33.7 |'
- en: '| ChatGPT | A lot | 57.2 |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| ChatGPT | 非常了解 | 57.2 |'
- en: '| familiarity | A little | 40.7 |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 熟悉度 | 一点 | 40.7 |'
- en: '|  | Nothing at all | 2.1 |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '|  | 完全没有 | 2.1 |'
- en: 'TABLE I: Demographics. Percentages might not add up to 100% due to rounding
    and missing responses.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '表 I: 人口统计数据。由于四舍五入和缺失响应，百分比可能不加总到100%。'
- en: '|  | Prompt |  | Reponse |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '|  | 提示 |  | 反应 |'
- en: '|  | Clarity (L7) | Use (L7) | Bias (L5) | Standout (B) |  | Clarity (L7) |
    Use (L7) | Satisfied (L7) | Standout (B) |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '|  | 清晰度 (L7) | 使用 (L7) | 偏差 (L5) | 突出 (B) |  | 清晰度 (L7) | 使用 (L7) | 满意度 (L7)
    | 突出 (B) |'
- en: '| TV | -0.23\stackon[.1pt] | -0.15\scaleto∗4pt | -0.03\stackon[.1pt]\stackon[.1pt]
    | -0.08\stackon[.1pt]\stackon[.1pt] |  | 0.06\stackon[.1pt]\stackon[.1pt] | 0.00\scaleto∗4pt
    | 0.05\scaleto∗4pt | -0.02\stackon[.1pt]\stackon[.1pt] |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 电视 | -0.23\stackon[.1pt] | -0.15\scaleto∗4pt | -0.03\stackon[.1pt]\stackon[.1pt]
    | -0.08\stackon[.1pt]\stackon[.1pt] |  | 0.06\stackon[.1pt]\stackon[.1pt] | 0.00\scaleto∗4pt
    | 0.05\scaleto∗4pt | -0.02\stackon[.1pt]\stackon[.1pt] |'
- en: '| ISP | -0.28\stackon[.1pt] | -0.04\stackon[.1pt]\stackon[.1pt] $\scaleto{\ast}{3pt}$
    |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| ISP | -0.28\stackon[.1pt] | -0.04\stackon[.1pt]\stackon[.1pt] $\scaleto{\ast}{3pt}$
    |'
- en: '| Parcel delivery | -0.15\stackon[.1pt]\stackon[.1pt] $\scaleto{\ast}{3pt}$
    |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| 包裹配送 | -0.15\stackon[.1pt]\stackon[.1pt] $\scaleto{\ast}{3pt}$ |'
- en: '| Gaming console | {-0.8\stackon[.1pt]} | -0.10\scaleto∗4pt | -0.01\stackon[.1pt]\stackon[.1pt]
    | 0.00\stackon[.1pt]\stackon[.1pt] |  | -0.17\stackon[.1pt]\stackon[.1pt] | -0.21
    | -0.21\stackon[.1pt] | -0.01\stackon[.1pt]\stackon[.1pt] |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| 游戏主机 | {-0.8\stackon[.1pt]} | -0.10\scaleto∗4pt | -0.01\stackon[.1pt]\stackon[.1pt]
    | 0.00\stackon[.1pt]\stackon[.1pt] |  | -0.17\stackon[.1pt]\stackon[.1pt] | -0.21
    | -0.21\stackon[.1pt] | -0.01\stackon[.1pt]\stackon[.1pt] |'
- en: '| Investment plat. | 0.01\stackon[.1pt] | -0.10\stackon[.1pt]\stackon[.1pt] $\scaleto{\ast}{3pt}$
    |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| 投资平台 | 0.01\stackon[.1pt] | -0.10\stackon[.1pt]\stackon[.1pt] $\scaleto{\ast}{3pt}$
    |'
- en: '| Laptop | -0.04\stackon[.1pt] | {0.35\scaleto∗4pt} | -0.0\stackon[.1pt]\stackon[.1pt]
    | 0.04\stackon[.1pt]\stackon[.1pt] |  | 0.10\stackon[.1pt]\stackon[.1pt] | 0.20\scaleto∗4pt
    | 0.22\stackon[.1pt] | 0.04\stackon[.1pt]\stackon[.1pt] |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 笔记本电脑 | -0.04\stackon[.1pt] | {0.35\scaleto∗4pt} | -0.0\stackon[.1pt]\stackon[.1pt]
    | 0.04\stackon[.1pt]\stackon[.1pt] |  | 0.10\stackon[.1pt]\stackon[.1pt] | 0.20\scaleto∗4pt
    | 0.22\stackon[.1pt] | 0.04\stackon[.1pt]\stackon[.1pt] |'
- en: 'TABLE II: Mean difference between perturbed and baseline groups among eight
    questions, four about prompts and four about responses (see §[7.1.1](#S7.SS1.SSS1
    "7.1.1 Survey procedures ‣ 7.1 Methods ‣ 7 User Study ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations") for details). By default test for equivalence
    is reported (TOST WMU), {} indicates test for difference (MWU, CHI²). Higher is
    better for all differences. \scaleto∗4pt:  \stackon[.1pt]\stackon[.1pt] , \stackon[.1pt]\stackon[.1pt]
    : $p<0.0001$. L7: seven-point Likert, L5: five-point Likert, B: binary.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '表 II: 在八个问题中，扰动组和基线组之间的平均差异，其中四个关于提示，四个关于反应（详细信息请参见 §[7.1.1](#S7.SS1.SSS1 "7.1.1
    调查程序 ‣ 7.1 方法 ‣ 7 用户研究 ‣ 销售窃听者：对LLM品牌推荐的隐形攻击")）。默认报告等效性测试（TOST WMU），{} 表示差异测试（MWU,
    CHI²）。所有差异越大越好。\scaleto∗4pt:  \stackon[.1pt]\stackon[.1pt] , \stackon[.1pt]\stackon[.1pt]
    : $p<0.0001$。L7: 七点李克特量表，L5: 五点李克特量表，B: 二项式。'
- en: '| Gemma-it |  | LLama3-it |  |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| Gemma-it |  | LLama3-it |  |'
- en: '|  | TV |  | ISP |  | Parcel delivery |  | Gaming console |  | Invesment plat.
    |  | Laptop |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '|  | 电视 |  | ISP |  | 包裹配送 |  | 游戏主机 |  | 投资平台 |  | 笔记本电脑 |'
- en: '|  | P% | A% | T% |  | P% | A% | T% |  | P% | A% | T% |  | P% | A% | T% |  |
    P% | A% | T% |  | P% | A% | T% |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '|  | P% | A% | T% |  | P% | A% | T% |  | P% | A% | T% |  | P% | A% | T% |  |
    P% | A% | T% |  | P% | A% | T% |'
- en: '| Base | 25.0 | 33.8 | 35.3 |  | 23.9 | 46.2 | 34.3 |  | 10.6 | 22.7 | 13.6
    |  | 0.0 | 18.3 | 0.0 |  | 14.1 | 38.0 | 14.1 |  | 5.3 | 61.3 | 1.3 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 基础 | 25.0 | 33.8 | 35.3 |  | 23.9 | 46.2 | 34.3 |  | 10.6 | 22.7 | 13.6 |  |
    0.0 | 18.3 | 0.0 |  | 14.1 | 38.0 | 14.1 |  | 5.3 | 61.3 | 1.3 |'
- en: '| Pert | 57.1 | 80.0 | 82.9 |  | 39.1 | 78.2 | 50.7 |  | 41.4 | 58.6 | 44.3
    |  | 11.2 | 64.8 | 1.4 |  | 40.3 | 58.4 | 42.9 |  | 7.1 | 74.3 | 0.0 |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| Pert | 57.1 | 80.0 | 82.9 |  | 39.1 | 78.2 | 50.7 |  | 41.4 | 58.6 | 44.3
    |  | 11.2 | 64.8 | 1.4 |  | 40.3 | 58.4 | 42.9 |  | 7.1 | 74.3 | 0.0 |'
- en: '| Diff | 32.1\stackon[.1pt]\stackon[.1pt]  | 16.4 |  | 30.8\stackon[.1pt]\stackon[.1pt] 
    | 30.6\stackon[.1pt]\stackon[.1pt]  |  | 1.8 | 12.9 | -1.3 |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 差异 | 32.1\stackon[.1pt]\stackon[.1pt]  | 16.4 |  | 30.8\stackon[.1pt]\stackon[.1pt] 
    | 30.6\stackon[.1pt]\stackon[.1pt]  |  | 1.8 | 12.9 | -1.3 |'
- en: 'TABLE III: The percentage of responses that mentioned the targeted brand. P:
    What brand is (p)icked by the user given the response, A: What are (a)ll of the
    brands recommended in the response, T: What is the (t)op brand recommended in
    the response. \scaleto∗4pt:  \stackon[.1pt]\stackon[.1pt] , \stackon[.1pt]\stackon[.1pt]
    : $p<0.0001$.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '表 III: 提及目标品牌的响应百分比。P: 用户在响应中选择了什么品牌，A: 响应中推荐了哪些品牌，T: 响应中推荐的首要品牌。\scaleto∗4pt:  \stackon[.1pt]\stackon[.1pt] ,
    \stackon[.1pt]\stackon[.1pt] : $p<0.0001$。'
- en: 7.1.2 Experimental groups
  id: totrans-186
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.1.2 实验组
- en: 'Our overall goal was to find whether people notice differences between our
    perturbed prompts compared to base prompts. For each of our 447 base prompts,
    we found a perturbed prompt for each possible target brand using the loss of each
    of our models. This resulted in 1,809 base and perturbed prompt pairs for each
    model. Because of the large number of prompt pairs, we could not test all of them.
    We selected six pairs of prompts to use in the user study, each pair from a different
    product category, giving us 12 prompts total. Because each pair of prompts belonged
    to a unique product category, we refer to them by their product categories in
    the results. The prompt pairs were split between two models, three pairs for Llama3-it
    and three for Gemma-it. We focused on the more user-friendly instruction-tuned
    models from our experiments since they are more analogous to LLMs used in chatbots [[141](#bib.bib141)].
    The pairs met the following criteria:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的总体目标是确定人们是否能注意到我们扰动提示与基础提示之间的差异。对于我们447个基础提示中的每一个，我们使用每个模型的损失值找到了一个对应的扰动提示。这导致每个模型有1,809对基础和扰动提示。由于提示对的数量庞大，我们无法测试所有的提示对。我们选择了六对提示用于用户研究，每对提示来自不同的产品类别，总共提供了12个提示。由于每对提示属于一个独特的产品类别，我们在结果中按其产品类别引用它们。提示对在两个模型之间进行了分配，每个模型三对，Llama3-it
    三对，Gemma-it 三对。我们集中关注我们实验中的用户友好型指令调优模型，因为它们更类似于用于聊天机器人的LLM[[141](#bib.bib141)]。这些对符合以下标准：
- en: •
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Among the top 50% of product categories that participants reported to care about.
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在参与者报告关注的前50%产品类别中。
- en: •
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Among the top 50% of product categories that participants reported they might
    use an LLM when shopping for.
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在参与者报告他们在购物时可能使用LLM的前50%产品类别中。
- en: •
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'They had the highest probability increase that the target brand is mentioned
    with the attack, as discussed in §[6.1](#S6.SS1 "6.1 Observations on Paraphrased
    Prompts ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand
    Recommendations").'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 他们在攻击中目标品牌被提及的概率增加最高，如§[6.1](#S6.SS1 "6.1 旁白提示的观察 ‣ 6 结果 ‣ 销售耳语者：对LLM品牌推荐的隐蔽攻击")中所讨论的。
- en: 'For each of the 12 prompts in our six prompt pairs, we obtained a random sample
    of 75 as it was in the overall set of 1000. All participants within a study group
    saw the same prompts, but, to mirror how in real-world chatbot use a single prompt
    would lead to different responses, each participant was shown a unique reponse.
    As opposed §[6](#S6 "6 Results ‣ Sales Whisperer: A Human-Inconspicuous Attack
    on LLM Brand Recommendations"), particiapnts saw full-length responses.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们六对提示中的每12个提示，我们从总体的1000个提示中随机抽取了75个样本。所有参与者在研究组内看到相同的提示，但为了模拟现实世界中聊天机器人使用中单个提示会导致不同响应的情况，每位参与者看到的是唯一的响应。与§[6](#S6
    "6 结果 ‣ 销售耳语者：对LLM品牌推荐的隐蔽攻击")不同，参与者看到了完整的响应。
- en: 7.1.3 Piloting and preliminary data collection
  id: totrans-195
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.1.3 试点和初步数据收集
- en: We piloted our study extensively. We ran a series of preliminary studies to
    determine whether the study design was feasible and whether participants would
    encounter problems with any parts of the study. During these preliminary studies,
    questions were timed and augmented with meta-questions on how clear the main questions
    were. We also collected participants’ interest in product categories and their
    likelihood of using chatbots for advice when shopping for these categories. In
    total, we collected responses from 90 prolific participants for piloting and 63
    for product category preferences. We further ran pilots with two HCI researchers,
    asking them to review and criticize our study.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了广泛的试点研究。我们进行了一系列初步研究，以确定研究设计是否可行，以及参与者是否会遇到研究中的任何问题。在这些初步研究中，问题有时间限制，并增加了关于主要问题清晰度的元问题。我们还收集了参与者对产品类别的兴趣以及在这些类别购物时使用聊天机器人的可能性。总共，我们从90名高产参与者那里收集了试点数据，从63名参与者那里收集了产品类别偏好数据。我们还与两位HCI研究人员进行了试点，要求他们审查并批评我们的研究。
- en: Based on responses, we tweaked the study design to be more concise and have
    clearer instructions. To more closely mimic real chatbots, we changed how prompts
    and responses were displayed.Attention and comprehension checks were added to
    ensure high data quality.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 根据反馈，我们调整了研究设计，使其更简洁且指令更明确。为了更贴近真实的聊天机器人，我们改变了提示和响应的展示方式。添加了注意力和理解检查，以确保数据质量高。
- en: 7.1.4 Statistical analysis
  id: totrans-198
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.1.4 统计分析
- en: 'For each of the six base and perturbed prompt pairs, we analyzed the difference
    between base and perturbed group responses with a series of non-parametric tests
    on our 11 main measurement variables: two-tailed Mann-Whitney U tests for Likert
    data and chi-squared tests for binary data. To understand whether the base and
    perturbed groups are equivalent, we replaced non-significant tests for difference
    with tests of equivalence. To establish equivalence, we used the two one-sided
    tests procedure (TOST) and set our equivalence margin to be $\Delta=0.5$ for 80%
    power [[142](#bib.bib142)].⁶⁶6Testing for equivalence is a deviation from the
    pre-registration; however, we believe this approach paints a more complete picture.
    Open-ended brand-recall questions (e.g., what brand participants would pick based
    on the response), were coded into binary categories: whether the participant reported
    the targeted brand or not. hesitant or otherwise unclear responses did not count
    as a match.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每一对六个基线和扰动提示，我们使用一系列非参数检验来分析基线组和扰动组回应之间的差异，涉及我们11个主要测量变量：对于Likert数据使用双尾Mann-Whitney
    U检验，对于二元数据使用卡方检验。为了了解基线组和扰动组是否等效，我们将非显著差异检验替换为等效性检验。为了确定等效性，我们使用了单侧检验程序（TOST），并将我们的等效性边界设置为$\Delta=0.5$以获得80%的统计功效[[142](#bib.bib142)]。⁶⁶6测试等效性是对预注册的偏离；然而，我们认为这种方法可以呈现一个更完整的图景。开放式品牌回忆问题（例如，参与者会根据回应选择哪个品牌），被编码成二元类别：参与者是否报告了目标品牌。犹豫或其他不清楚的回应不计为匹配。
- en: Our approach to measuring inconspicuousness meant that we needed to run 11 tests
    between the baseline and perturbed prompt pair for each product category. We controlled
    our false-discovery rate per product category with the Benjamini-Hochberg procedure [[143](#bib.bib143)].
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对测量不显眼性的方式意味着我们需要在每个产品类别中对基线和扰动提示对进行11次检验。我们通过Benjamini-Hochberg程序控制每个产品类别的假发现率[[143](#bib.bib143)]。
- en: 7.2 Results
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2 结果
- en: We first describe our participants and then present results. We find that, under
    most measures, perturbed prompts and corresponding responses are human-inconspicuous.
    Further, these prompts, in most measures, successfully nudge more users into noticing
    the target brand.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先描述参与者，然后呈现结果。我们发现，在大多数测量指标下，扰动提示和相应的回应对人类不易察觉。此外，这些提示在大多数测量指标上，成功地促使更多用户注意到目标品牌。
- en: 7.2.1 Participants
  id: totrans-203
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.2.1 参与者
- en: 'We recruited 845 participants and assigned them evenly to 12 groups, each group
    defined in terms of the product category and prompt type (baseline or perturbed).
    Product categories were split between Llama3-it and Gemma-it. Our participants
    were more educated, younger, less hispanic, and had more familiarity with ChatGPT
    compared to the national average [[144](#bib.bib144), [145](#bib.bib145)]. [Table I](#S7.T1
    "TABLE I ‣ 7.1.1 Survey procedures ‣ 7.1 Methods ‣ 7 User Study ‣ Sales Whisperer:
    A Human-Inconspicuous Attack on LLM Brand Recommendations") shows the demographics
    distribution of our participants.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '我们招募了845名参与者，并将他们均匀分配到12个组中，每个组按照产品类别和提示类型（基线或扰动）进行定义。产品类别在Llama3-it和Gemma-it之间进行划分。与全国平均水平相比，我们的参与者教育程度更高，年龄较小，西班牙裔比例较低，并且对ChatGPT的熟悉程度更高[[144](#bib.bib144),
    [145](#bib.bib145)]。 [表I](#S7.T1 "TABLE I ‣ 7.1.1 Survey procedures ‣ 7.1 Methods
    ‣ 7 User Study ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations")展示了我们参与者的统计分布。'
- en: 7.2.2 Statistical Evaluation
  id: totrans-205
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.2.2 统计评估
- en: 'We asked multiple questions about the prompts and responses. Four of these
    were to test the inconspicuousness of the perturbed prompts. Another four were
    to test if users were significantly more dissatisfied with the perturbed responses.
    Additionally, we asked three questions to test if the responses to the perturbed
    prompts made the targeted brand more perceptible. [Table II](#S7.T2 "TABLE II
    ‣ 7.1.1 Survey procedures ‣ 7.1 Methods ‣ 7 User Study ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations") and [Table III](#S7.T3 "TABLE III ‣ 7.1.1
    Survey procedures ‣ 7.1 Methods ‣ 7 User Study ‣ Sales Whisperer: A Human-Inconspicuous
    Attack on LLM Brand Recommendations") show the result of our analysis.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '我们问了多个关于提示和回应的问题。其中四个问题是为了测试扰动提示的不显眼性。另有四个问题是为了测试用户是否对扰动回应的满意度显著下降。此外，我们还提出了三个问题，以测试对扰动提示的回应是否使目标品牌更具感知度。[表II](#S7.T2
    "TABLE II ‣ 7.1.1 Survey procedures ‣ 7.1 Methods ‣ 7 User Study ‣ Sales Whisperer:
    A Human-Inconspicuous Attack on LLM Brand Recommendations")和[表III](#S7.T3 "TABLE
    III ‣ 7.1.1 Survey procedures ‣ 7.1 Methods ‣ 7 User Study ‣ Sales Whisperer:
    A Human-Inconspicuous Attack on LLM Brand Recommendations")展示了我们的分析结果。'
- en: Equivalence
  id: totrans-207
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 等效性
- en: We find that nearly all perturbed prompts and responses were equivalent to the
    base prompts from the perspective of participants in terms of variables measured
    (42/48 comparisons were equivalent, ); participants found the responses to the
    parcel delivery perturbed prompt more satisfactory and more likely to be used
    (all ); no difference nor equivalence was found for the likelihood of using the
    response for gaming platforms (). These results suggest that not only is our attack
    imperceptible to users, but in a few cases the perturbed prompts and responses
    might be preferable.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现，几乎所有扰动的提示和响应在参与者看来都等同于基本提示，就测量的变量而言（42/48个比较是等同的）；参与者发现对包裹递送扰动提示的响应更令人满意，并且更可能被使用（全部）；对于游戏平台使用响应的可能性没有发现差异或等同（）。这些结果表明，我们的攻击不仅对用户隐蔽，而且在某些情况下，扰动的提示和响应可能更受欢迎。
- en: Attack success
  id: totrans-209
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 攻击成功
- en: 'In order to measure attack success, we recorded the percentage of participants
    who *would pick* the targeted brand given the response, the percentage of participants
    who *noticed* the brand in the response, and the percentage of participants who
    said the targeted brand *was the top recommendation*. As shown in ([Table III](#S7.T3
    "TABLE III ‣ 7.1.1 Survey procedures ‣ 7.1 Methods ‣ 7 User Study ‣ Sales Whisperer:
    A Human-Inconspicuous Attack on LLM Brand Recommendations")), in five out of six
    categories our attacks were able to increase the prominence of the target brand
    in at least one of the three questions: in four categories participants were more
    likely to pick the targeted brand when given the perturbed prompts, in five categories
    participants were more likely to notice the targeted brand, and in three categories
    participants were more likely to say the targeted brand was the top recommendation.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '为了测量攻击成功率，我们记录了参与者在响应中*会选择*目标品牌的百分比、*注意到*响应中的品牌的百分比，以及参与者表示目标品牌*是最推荐*的百分比。如在([Table III](#S7.T3
    "TABLE III ‣ 7.1.1 Survey procedures ‣ 7.1 Methods ‣ 7 User Study ‣ Sales Whisperer:
    A Human-Inconspicuous Attack on LLM Brand Recommendations"))所示，在六个类别中的五个类别中，我们的攻击能够在三个问题中的至少一个中提高目标品牌的显著性：在四个类别中，参与者在给定扰动提示时更可能选择目标品牌；在五个类别中，参与者更可能注意到目标品牌；在三个类别中，参与者更可能表示目标品牌是最推荐的。'
- en: 8 Concluding Discussion
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 结论讨论
- en: We identify a novel threat model in which an adversary aims to induce target
    biases in LLM responses users receive by using adversarially crafted prompts.
    We specifically investigate whether adversaries can bias responses towards a target
    brand through prompt suggestions (e.g., recommended prompts within a chatbot,
    prompt sharing services).
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们确定了一种新颖的威胁模型，其中对手旨在通过使用对抗性精心设计的提示来在LLM响应中引发目标偏见。我们特别研究了对手是否可以通过提示建议（例如，在聊天机器人中推荐的提示、提示共享服务）将响应偏向目标品牌。
- en: We contribute a dataset of 449 prompts that ask for product recommendations
    over 77 product categories, and develop a method to evaluate which brands are
    mentioned in LLM responses using target words from the same dataset. We evaluate
    the difference in probabilities that brands are mentioned across similar prompts
    (paraphrases) within each product category. We find up to a $100\%$ difference
    between pairs of prompts. Next, we develop a method to perturb a base prompt by
    replacing words with their synonyms from our new synonym dictionary. We select
    a candidate using a loss function that correlates with measured attack success.
    This results in human-inconspicuous prompts that increase the probability that
    a target brand is mentioned. Novel with respect to other work that studies inconspicuous
    text manipulations, we perform a user study that demonstrates that, compared to
    base prompts, our synonym-replacement prompts are successful in promotinga target
    brand while remaining inconspicuous to humans.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供了一个包含449个提示的数据集，这些提示请求有关77个产品类别的产品推荐，并开发了一种方法来评估在LLM（大语言模型）响应中提及哪些品牌，使用来自同一数据集的目标词。我们评估了在每个产品类别中，品牌在类似提示（同义表达）中的提及概率的差异。我们发现提示对之间的差异最高达到$100\%$。接下来，我们开发了一种方法，通过用新同义词词典中的同义词替换词语来扰动基本提示。我们使用与测量攻击成功相关的损失函数来选择候选项。这产生了对人类不显眼的提示，这些提示增加了目标品牌被提及的概率。相对于其他研究隐蔽文本操控的工作，我们进行了一项用户研究，表明与基本提示相比，我们的同义词替换提示在推广目标品牌方面成功，同时对人类保持隐蔽。
- en: We also explore transfer attacks of our synonym-replacement approach from open-sourced
    models where logits are available to GPT models, finding transferability between
    Llama3-it and GPT-3.5-Turbo.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还探讨了将我们同义词替换方法的转移攻击从开源模型（其中logits可用）转移到GPT模型，发现Llama3-it和GPT-3.5-Turbo之间存在转移性。
- en: Taken together, our work highlights the potential for adversarial prompt recommendations
    to bias LLM responses. While our focus is on brand recommendations, our methods
    are general and can be applied to other adversarial goals, such as propaganda,
    misinformation, and bias on social issues. As such, we suggest that defensive
    measures should be taken. Since the perturbations we introduce are imperceptible
    to humans, we suggest that users should be warned to check sources before using
    prompts they did not author. Notably, warnings about LLM use are already commonplace
    in many chatbot applications, ChatGPT noting “ChatGPT can make mistakes. Check
    important info.” [[146](#bib.bib146)]. We suggest that these be implemented for
    untrusted prompts.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我们的工作突显了对抗性提示推荐对大型语言模型（LLM）响应的潜在偏差。虽然我们的重点是品牌推荐，但我们的方法具有普遍性，可应用于其他对抗性目标，如宣传、虚假信息和社会问题上的偏见。因此，我们建议采取防御措施。由于我们引入的扰动对人类几乎不可感知，我们建议用户在使用未由自己编写的提示前应检查来源。值得注意的是，关于LLM使用的警告在许多聊天机器人应用程序中已经很普遍，ChatGPT指出“ChatGPT可能会犯错误。检查重要信息。”[[146](#bib.bib146)]。我们建议这些警告应适用于不可信的提示。
- en: References
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] T. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh, “Autoprompt:
    Eliciting knowledge from language models with automatically generated prompts,”
    *arXiv preprint arXiv:2010.15980*, 2020.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] T. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, 和 S. Singh, “Autoprompt：通过自动生成的提示从语言模型中引出知识，”
    *arXiv预印本arXiv:2010.15980*，2020年。'
- en: '[2] (2023) What are some of your favorite chatgpt prompts that are useful?
    i’ll share mine. Accessed: 2024-06-05\. [Online]. Available: [https://www.reddit.com/r/ChatGPT/comments/13cklzh/what_are_some_of_your_favorite_chatgpt_prompts/](https://www.reddit.com/r/ChatGPT/comments/13cklzh/what_are_some_of_your_favorite_chatgpt_prompts/)'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] (2023) 你最喜欢的有用的chatgpt提示有哪些？我会分享我的。访问日期：2024-06-05。 [在线]. 可用： [https://www.reddit.com/r/ChatGPT/comments/13cklzh/what_are_some_of_your_favorite_chatgpt_prompts/](https://www.reddit.com/r/ChatGPT/comments/13cklzh/what_are_some_of_your_favorite_chatgpt_prompts/)'
- en: '[3] N. Carlini, D. Paleka, K. D. Dvijotham, T. Steinke, J. Hayase, A. F. Cooper,
    K. Lee, M. Jagielski, M. Nasr, A. Conmy, E. Wallace, D. Rolnick, and F. Tramèr,
    “Stealing Part of a Production Language Model,” 2024.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] N. Carlini, D. Paleka, K. D. Dvijotham, T. Steinke, J. Hayase, A. F. Cooper,
    K. Lee, M. Jagielski, M. Nasr, A. Conmy, E. Wallace, D. Rolnick, 和 F. Tramèr,
    “盗取生产语言模型的一部分，” 2024年。'
- en: '[4] U. Iqbal, T. Kohno, and F. Roesner, “LLM Platform Security: Applying a
    Systematic Evaluation Framework to OpenAI’s ChatGPT Plugins,” 2023.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] U. Iqbal, T. Kohno, 和 F. Roesner, “LLM平台安全：将系统评估框架应用于OpenAI的ChatGPT插件，”
    2023年。'
- en: '[5] F. Wu, N. Zhang, S. Jha, P. McDaniel, and C. Xiao, “A New Era in LLM Security:
    Exploring Security Concerns in Real-World LLM-based Systems,” 2024.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] F. Wu, N. Zhang, S. Jha, P. McDaniel, 和 C. Xiao, “LLM安全的新纪元：探索现实世界LLM系统中的安全问题，”
    2024年。'
- en: '[6] X. Pan, M. Zhang, B. Sheng, J. Zhu, and M. Yang, “Hidden Trigger Backdoor
    Attack on NLP models via Linguistic Style Manipulation,” in *31st USENIX Security
    Symposium (USENIX Security 22)*, 2022.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] X. Pan, M. Zhang, B. Sheng, J. Zhu, 和 M. Yang, “通过语言风格操控对NLP模型进行隐藏触发器后门攻击，”
    *第31届USENIX安全研讨会（USENIX Security 22）*，2022年。'
- en: '[7] A. Zou, Z. Wang, J. Z. Kolter, and M. Fredrikson, “Universal and Transferable
    Adversarial Attacks on Aligned Language Models,” 2023.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] A. Zou, Z. Wang, J. Z. Kolter, 和 M. Fredrikson, “对齐语言模型的通用和可转移对抗攻击，” 2023年。'
- en: '[8] N. Carlini, F. Tramèr, E. Wallace, M. Jagielski, A. Herbert-Voss, K. Lee,
    A. Roberts, T. Brown, D. Song, Ú. Erlingsson, A. Oprea, and C. Raffel, “Extracting
    Training Data from Large Language Models,” in *30th USENIX Security Symposium
    (USENIX Security 21)*, 2021.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] N. Carlini, F. Tramèr, E. Wallace, M. Jagielski, A. Herbert-Voss, K. Lee,
    A. Roberts, T. Brown, D. Song, Ú. Erlingsson, A. Oprea, 和 C. Raffel, “从大型语言模型中提取训练数据，”
    *第30届USENIX安全研讨会（USENIX Security 21）*，2021年。'
- en: '[9] Microsoft, “Your everyday ai companion,” 2024, accessed: 2024-06-06. [Online].
    Available: [https://www.microsoft.com/en-us/bing?form=MG0AUO&OCID=MG0AUO](https://www.microsoft.com/en-us/bing?form=MG0AUO&OCID=MG0AUO)'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] 微软, “你每天的AI助手，” 2024年，访问日期：2024-06-06。 [在线]. 可用： [https://www.microsoft.com/en-us/bing?form=MG0AUO&OCID=MG0AUO](https://www.microsoft.com/en-us/bing?form=MG0AUO&OCID=MG0AUO)'
- en: '[10] G. Zhang, C. Yan, X. Ji, T. Zhang, T. Zhang, and W. Xu, “DolphinAttack:
    Inaudible Voice Commands,” in *Proceedings of the 2017 ACM SIGSAC Conference on
    Computer and Communications Security*, 2017.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] G. Zhang, C. Yan, X. Ji, T. Zhang, T. Zhang, 和 W. Xu, “DolphinAttack:
    听不见的语音命令，” 载于 *2017年ACM SIGSAC计算机与通信安全会议论文集*，2017年。'
- en: '[11] M. Sharif, S. Bhagavatula, L. Bauer, and M. K. Reiter, “Accessorize to
    a Crime: Real and Stealthy Attacks on State-of-the-Art Face Recognition,” in *Proceedings
    of the 23rd ACM SIGSAC Conference on Computer and Communications Security*, 2016.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] M. Sharif, S. Bhagavatula, L. Bauer, 和 M. K. Reiter, “犯罪配件：对最先进的人脸识别技术的真实和隐秘攻击，”
    载于 *第23届ACM SIGSAC计算机与通信安全会议论文集*，2016年。'
- en: '[12] B. G. Doan, M. Xue, S. Ma, E. Abbasnejad, and D. C. Ranasinghe, “TnT Attacks!
    Universal Naturalistic Adversarial Patches Against Deep Neural Network Systems,”
    *IEEE Transactions on Information Forensics and Security*, 2022.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] B. G. Doan, M. Xue, S. Ma, E. Abbasnejad, 和 D. C. Ranasinghe, “TnT攻击！针对深度神经网络系统的通用自然对抗补丁，”
    *IEEE信息取证与安全事务*，2022年。'
- en: '[13] S. Garg and G. Ramakrishnan, “BAE: BERT-based Adversarial Examples for
    Text Classification,” in *Proceedings of the 2020 Conference on Empirical Methods
    in Natural Language Processing (EMNLP)*, 2020.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] S. Garg 和 G. Ramakrishnan, “BAE: 基于BERT的文本分类对抗样本，” 载于 *2020年自然语言处理实证方法会议（EMNLP）论文集*，2020年。'
- en: '[14] L. Li, R. Ma, Q. Guo, X. Xue, and X. Qiu, “BERT-ATTACK: Adversarial Attack
    Against BERT Using BERT,” in *Proceedings of the 2020 Conference on Empirical
    Methods in Natural Language Processing (EMNLP)*, Nov. 2020.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] L. Li, R. Ma, Q. Guo, X. Xue, 和 X. Qiu, “BERT-ATTACK: 使用BERT对BERT的对抗攻击，”
    载于 *2020年自然语言处理实证方法会议（EMNLP）论文集*，2020年11月。'
- en: '[15] D. Li, Y. Zhang, H. Peng, L. Chen, C. Brockett, M.-T. Sun, and B. Dolan,
    “Contextualized Perturbation for Textual Adversarial Attack,” in *Proceedings
    of the 2021 Conference of the North American Chapter of the Association for Computational
    Linguistics: Human Language Technologies*, 2021.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] D. Li, Y. Zhang, H. Peng, L. Chen, C. Brockett, M.-T. Sun, 和 B. Dolan,
    “文本对抗攻击的情境化扰动，” 载于 *2021年北美计算语言学协会人类语言技术会议论文集*，2021年。'
- en: '[16] J. Li, S. Ji, T. Du, B. Li, and T. Wang, “TextBugger: Generating Adversarial
    Text Against Real-world Applications,” in *Network and Distributed System Security
    Symposium*, 2019.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] J. Li, S. Ji, T. Du, B. Li, 和 T. Wang, “TextBugger: 生成针对真实应用的对抗文本，” 载于
    *网络与分布式系统安全研讨会*，2019年。'
- en: '[17] J. Y. Yoo and Y. Qi, “Towards Improving Adversarial Training of NLP Models,”
    in *Findings of the Association for Computational Linguistics: EMNLP 2021*, 2021.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] J. Y. Yoo 和 Y. Qi, “提升自然语言处理模型的对抗训练，” 载于 *2021年计算语言学协会：EMNLP会议成果*，2021年。'
- en: '[18] M. Alzantot, Y. Sharma, A. Elgohary, B.-J. Ho, M. Srivastava, and K.-W.
    Chang, “Generating Natural Language Adversarial Examples,” in *Proceedings of
    the 2018 Conference on Empirical Methods in Natural Language Processing*, 2018.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] M. Alzantot, Y. Sharma, A. Elgohary, B.-J. Ho, M. Srivastava, 和 K.-W.
    Chang, “生成自然语言对抗样本，” 载于 *2018年自然语言处理实证方法会议论文集*，2018年。'
- en: '[19] R. Jia, A. Raghunathan, K. Göksel, and P. Liang, “Certified Robustness
    to Adversarial Word Substitutions,” in *Proceedings of the 2019 Conference on
    Empirical Methods in Natural Language Processing and the 9th International Joint
    Conference on Natural Language Processing (EMNLP-IJCNLP)*, 2019.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] R. Jia, A. Raghunathan, K. Göksel, 和 P. Liang, “对抗性词汇替换的认证鲁棒性，” 载于 *2019年自然语言处理实证方法会议及第九届国际联合自然语言处理会议（EMNLP-IJCNLP）论文集*，2019年。'
- en: '[20] J. Ebrahimi, A. Rao, D. Lowd, and D. Dou, “HotFlip: White-Box Adversarial
    Examples for Text Classification,” in *Proceedings of the 56th Annual Meeting
    of the Association for Computational Linguistics (Volume 2: Short Papers)*, 2018.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] J. Ebrahimi, A. Rao, D. Lowd, 和 D. Dou, “HotFlip: 白盒对抗样本用于文本分类，” 载于 *第56届计算语言学协会年会（卷2：短文）论文集*，2018年。'
- en: '[21] X. Xu, K. Kong, N. Liu, L. Cui, D. Wang, J. Zhang, and M. Kankanhalli,
    “An LLM can Fool Itself: A Prompt-Based Adversarial Attack,” in *The Twelfth International
    Conference on Learning Representations*, 2024.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] X. Xu, K. Kong, N. Liu, L. Cui, D. Wang, J. Zhang, 和 M. Kankanhalli, “LLM可以自我欺骗：基于提示的对抗攻击，”
    载于 *第十二届国际学习表征会议*，2024年。'
- en: '[22] D. Pruthi, B. Dhingra, and Z. C. Lipton, “Combating Adversarial Misspellings
    with Robust Word Recognition,” in *Proceedings of the 57th Annual Meeting of the
    Association for Computational Linguistics*, Jul. 2019.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] D. Pruthi, B. Dhingra, 和 Z. C. Lipton, “通过强健的词识别对抗对抗性拼写错误，” 载于 *第57届计算语言学协会年会论文集*，2019年7月。'
- en: '[23] M. T. Ribeiro, T. Wu, C. Guestrin, and S. Singh, “Beyond Accuracy: Behavioral
    Testing of NLP Models with CheckList,” in *Proceedings of the 58th Annual Meeting
    of the Association for Computational Linguistics*, Jul. 2020.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] M. T. Ribeiro, T. Wu, C. Guestrin, 和 S. Singh, “超越准确性：使用 CheckList 对 NLP
    模型进行行为测试，” 载于 *第58届计算语言学协会年会论文集*，2020年7月。'
- en: '[24] L. Yuan, Y. Zhang, Y. Chen, and W. Wei, “Bridge the Gap Between CV and
    NLP! A Gradient-based Textual Adversarial Attack Framework,” in *Findings of the
    Association for Computational Linguistics: ACL 2023*, 2023.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] L. Yuan, Y. Zhang, Y. Chen, 和 W. Wei, “弥合计算机视觉与自然语言处理之间的差距！一种基于梯度的文本对抗攻击框架，”
    载于 *计算语言学协会发现：ACL 2023*，2023年。'
- en: '[25] X. Zhao, Y.-X. Wang, and L. Li, “Protecting Language Generation Models
    via Invisible Watermarking,” in *Proceedings of the 40th International Conference
    on Machine Learning*, 2023.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] X. Zhao, Y.-X. Wang, 和 L. Li, “通过隐形水印保护语言生成模型，” 载于 *第40届国际机器学习大会论文集*，2023年。'
- en: '[26] Z. Li, C. Wang, S. Wang, and C. Gao, “Protecting Intellectual Property
    of Large Language Model-Based Code Generation APIs via Watermarks,” in *Proceedings
    of the 2023 ACM SIGSAC Conference on Computer and Communications Security*, 2023.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Z. Li, C. Wang, S. Wang, 和 C. Gao, “通过水印保护基于大语言模型的代码生成 API 的知识产权，” 载于
    *2023年ACM SIGSAC计算机与通信安全会议论文集*，2023年。'
- en: '[27] X. He, Q. Xu, Y. Zengt, L. Lyu, F. Wu, J. Li, and R. Jia, “CATER: Intellectual
    Property Protection on Text Generation APIs via Conditional Watermarks,” in *Proceedings
    of the 36th International Conference on Neural Information Processing Systems*,
    2024.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] X. He, Q. Xu, Y. Zengt, L. Lyu, F. Wu, J. Li, 和 R. Jia, “CATER：通过条件水印保护文本生成
    API 的知识产权，” 载于 *第36届国际神经信息处理系统大会论文集*，2024年。'
- en: '[28] X. He, Q. Xu, L. Lyu, F. Wu, and C. Wang, “Protecting Intellectual Property
    of Language Generation APIs with Lexical Watermark,” in *AAAI Conference on Artificial
    Intelligence*, 2021.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] X. He, Q. Xu, L. Lyu, F. Wu, 和 C. Wang, “通过词汇水印保护语言生成 API 的知识产权，” 载于 *AAAI人工智能大会*，2021年。'
- en: '[29] O. Suciu, R. Marginean, Y. Kaya, H. D. III, and T. Dumitras, “When Does
    Machine Learning FAIL? Generalized Transferability for Evasion and Poisoning Attacks,”
    in *27th USENIX Security Symposium (USENIX Security 18)*, 2018.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] O. Suciu, R. Marginean, Y. Kaya, H. D. III, 和 T. Dumitras, “机器学习何时失败？规避和中毒攻击的广义转移性，”
    载于 *第27届USENIX安全研讨会（USENIX Security 18）*，2018年。'
- en: '[30] A. Demontis, M. Melis, M. Pintor, M. Jagielski, B. Biggio, A. Oprea, C. Nita-Rotaru,
    and F. Roli, “Why Do Adversarial Attacks Transfer? Explaining Transferability
    of Evasion and Poisoning Attacks,” in *28th USENIX Security Symposium (USENIX
    Security 19)*, 2019.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] A. Demontis, M. Melis, M. Pintor, M. Jagielski, B. Biggio, A. Oprea, C.
    Nita-Rotaru, 和 F. Roli, “为什么对抗性攻击会转移？解释规避和中毒攻击的可转移性，” 载于 *第28届USENIX安全研讨会（USENIX
    Security 19）*，2019年。'
- en: '[31] B. Friedman and H. Nissenbaum, “Discerning Bias in Computer Systems,”
    in *Conference Companion on Human Factors in Computing Systems*, 1993.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] B. Friedman 和 H. Nissenbaum, “识别计算机系统中的偏见，” 载于 *计算机系统人因学会议论文集*，1993年。'
- en: '[32] ——, “Minimizing Bias in Computer Systems,” in *Conference Companion on
    Human Factors in Computing Systems*, 1995.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] ——, “最小化计算机系统中的偏见，” 载于 *计算机系统人因学会议论文集*，1995年。'
- en: '[33] S. K. Roth, “The Unconsidered Ballot: How Design Effects Voting Behavior,”
    in *Visible Languages*, 1993.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] S. K. Roth, “被忽视的选票：设计如何影响投票行为，” 载于 *可见语言*，1993年。'
- en: '[34] N. Mehrabi, F. Morstatter, N. Saxena, K. Lerman, and A. Galstyan, “A Survey
    on Bias and Fairness in Machine Learning,” in *ACM Computing Surveys*, 2021.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] N. Mehrabi, F. Morstatter, N. Saxena, K. Lerman, 和 A. Galstyan, “机器学习中的偏见与公平性调查，”
    载于 *ACM 计算调查*，2021年。'
- en: '[35] P. Terhörst, J. N. Kolf, M. Huber, F. Kirchbuchner, N. Damer, A. M. Moreno,
    J. Fierrez, and A. Kuijper, “A Comprehensive Study on Face Recognition Biases
    Beyond Demographics,” *IEEE Transactions on Technology and Society*, 2022.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] P. Terhörst, J. N. Kolf, M. Huber, F. Kirchbuchner, N. Damer, A. M. Moreno,
    J. Fierrez, 和 A. Kuijper, “面部识别偏见的全面研究：超越人口统计学，” *IEEE技术与社会期刊*，2022年。'
- en: '[36] R. Tatman, “Gender and Dialect Bias in YouTube’s Automatic Captions,”
    in *Proceedings of the First ACL Workshop on Ethics in Natural Language Processing*.   Association
    for Computational Linguistics, Apr. 2017.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] R. Tatman, “YouTube 自动字幕中的性别和方言偏见，” 载于 *第一次ACL自然语言处理伦理研讨会论文集*。计算语言学协会，2017年4月。'
- en: '[37] J. Angwin, J. Larson, S. Mattu, and L. Kirchner, “Machine Bias,” *Propublica*,
    2016.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] J. Angwin, J. Larson, S. Mattu, 和 L. Kirchner, “机器偏见，” *Propublica*，2016年。'
- en: '[38] H. Xu, X. Liu, Y. Li, A. Jain, and J. Tang, “To be Robust or to be Fair:
    Towards Fairness in Adversarial Training,” in *International Conference on Machine
    Learning*, 2021.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] H. Xu, X. Liu, Y. Li, A. Jain 和 J. Tang，“要强健还是要公平：在对抗训练中的公平性”，载于 *国际机器学习会议*，2021年。'
- en: '[39] A. Agarwal, M. Dudik, and Z. S. Wu, “Fair Regression: Quantitative Definitions
    and Reduction-Based Algorithms,” in *Proceedings of the 36th International Conference
    on Machine Learning*, 2019.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] A. Agarwal, M. Dudik 和 Z. S. Wu，“公平回归：定量定义和基于约简的算法”，载于 *第36届国际机器学习大会论文集*，2019年。'
- en: '[40] I. O. Gallegos, R. A. Rossi, J. Barrow, M. M. Tanjim, S. Kim, F. Dernoncourt,
    T. Yu, R. Zhang, and N. K. Ahmed, “Bias and Fairness in Large Language Models:
    A Survey,” *arXiv preprint arXiv:2309.00770*, 2023.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] I. O. Gallegos, R. A. Rossi, J. Barrow, M. M. Tanjim, S. Kim, F. Dernoncourt,
    T. Yu, R. Zhang 和 N. K. Ahmed，“大型语言模型中的偏见与公平性：综述”，*arXiv 预印本 arXiv:2309.00770*，2023年。'
- en: '[41] E. M. Bender, T. Gebru, A. McMillan-Major, and S. Shmitchell.l, “On the
    Dangers of Stochastic Parrots: Can Language Models Be Too Big?” in *Proceedings
    of the 2021 ACM conference on fairness, accountability, and transparency*, 2021.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] E. M. Bender, T. Gebru, A. McMillan-Major 和 S. Shmitchell，“随机鹦鹉的危险：语言模型会不会过大？”
    载于 *2021年ACM公平性、问责制与透明度会议论文集*，2021年。'
- en: '[42] L. Weidinger, J. Uesato, M. Rauh, C. Griffin, P.-S. Huang, J. Mellor,
    A. Glaese, M. Cheng, B. Balle, A. Kasirzadeh, C. Biles, S. Brown, Z. Kenton, W. Hawkins,
    T. Stepleton, A. Birhane, L. A. Hendricks, L. Rimell, W. Isaac, J. Haas, S. Legassick,
    G. Irving, and I. Gabriel, “Taxonomy of Risks posed by Language Models,” in *Proceedings
    of the 2022 ACM conference on fairness, accountability, and transparency*, 2022.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] L. Weidinger, J. Uesato, M. Rauh, C. Griffin, P.-S. Huang, J. Mellor,
    A. Glaese, M. Cheng, B. Balle, A. Kasirzadeh, C. Biles, S. Brown, Z. Kenton, W.
    Hawkins, T. Stepleton, A. Birhane, L. A. Hendricks, L. Rimell, W. Isaac, J. Haas,
    S. Legassick, G. Irving 和 I. Gabriel，“语言模型所带来的风险分类”，载于 *2022年ACM公平性、问责制与透明度会议论文集*，2022年。'
- en: '[43] D. Esiobu, X. Tan, S. Hosseini, M. Ung, Y. Zhang, J. Fernandes, J. Dwivedi-Yu,
    E. Presani, A. Williams, and E. Smith, “ROBBIE: Robust Bias Evaluation of Large
    Generative Language Models,” in *Proceedings of the 2023 Conference on Empirical
    Methods in Natural Language Processing*, 2023.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] D. Esiobu, X. Tan, S. Hosseini, M. Ung, Y. Zhang, J. Fernandes, J. Dwivedi-Yu,
    E. Presani, A. Williams 和 E. Smith，“ROBBIE：大型生成语言模型的鲁棒性偏见评估”，载于 *2023年自然语言处理经验方法会议论文集*，2023年。'
- en: '[44] S. Feng, C. Y. Park, Y. Liu, and Y. Tsvetkov, “From Pretraining Data to
    Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading
    to Unfair NLP Models,” in *Proceedings of the 61st Annual Meeting of the Association
    for Computational Linguistics (Volume 1: Long Papers)*, 2023.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] S. Feng, C. Y. Park, Y. Liu 和 Y. Tsvetkov，“从预训练数据到语言模型再到下游任务：追踪政治偏见导致不公平NLP模型的踪迹”，载于
    *第61届计算语言学协会年会（第1卷：长篇论文）*，2023年。'
- en: '[45] H. Kotek, R. Dockum, and D. Q. Sun, “Gender Bias and Stereotypes in Large
    Language Models,” in *Proceedings of The ACM Collective Intelligence Conference*,
    2023.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] H. Kotek, R. Dockum 和 D. Q. Sun，“大型语言模型中的性别偏见和刻板印象”，载于 *ACM集体智能会议论文集*，2023年。'
- en: '[46] Y. Song, S. Khanuja, P. Liu, F. Faisal, A. Ostapenko, G. Winata, A. Aji,
    S. Cahyawijaya, Y. Tsvetkov, A. Anastasopoulos, and G. Neubig, “GlobalBench: A
    Benchmark for Global Progress in Natural Language Processing,” in *Proceedings
    of the 2023 Conference on Empirical Methods in Natural Language Processing*, 2023.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] Y. Song, S. Khanuja, P. Liu, F. Faisal, A. Ostapenko, G. Winata, A. Aji,
    S. Cahyawijaya, Y. Tsvetkov, A. Anastasopoulos, 和 G. Neubig，“GlobalBench: 全球自然语言处理进展的基准测试”，载于
    *2023年自然语言处理经验方法会议论文集*，2023年。'
- en: '[47] H. Orgad and Y. Belinkov, “BLIND: Bias Removal With No Demographics,”
    in *Proceedings of the 61st Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)*, A. Rogers, J. Boyd-Graber, and N. Okazaki,
    Eds., 2023.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] H. Orgad 和 Y. Belinkov，“BLIND：无人口统计的偏见去除”，载于 *第61届计算语言学协会年会（第1卷：长篇论文）*，A.
    Rogers, J. Boyd-Graber 和 N. Okazaki 主编，2023年。'
- en: '[48] E. Jeon, M. Lee, J. Park, Y. Kim, W.-L. Mok, and S. Lee, “Improving Bias
    Mitigation through Bias Experts in Natural Language Understanding,” in *Proceedings
    of the 2023 Conference on Empirical Methods in Natural Language Processing*, 2023.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] E. Jeon, M. Lee, J. Park, Y. Kim, W.-L. Mok 和 S. Lee，“通过自然语言理解中的偏见专家改进偏见缓解”，载于
    *2023年自然语言处理经验方法会议论文集*，2023年。'
- en: '[49] Y. Ding and P. Horster, “Undetectable On-line Password Guessing Attacks,”
    in *ACM SIGOPS Operating Systems Review*, 1995.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] Y. Ding 和 P. Horster，“不可检测的在线密码猜测攻击”，载于 *ACM SIGOPS 操作系统评论*，1995年。'
- en: '[50] A. Herzberg and H. Shulman, “Stealth DoS Attacks on Secure Channels,”
    in *Network and Distributed System Security Symposium*, 2010.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] A. Herzberg 和 H. Shulman，“对安全通道的隐蔽DoS攻击”，发表于*网络与分布式系统安全研讨会*，2010年。'
- en: '[51] S. Briongos, P. Malagón, J. M. Moya, and T. Eisenbarth, “RELOAD+REFRESH:
    Abusing Cache Replacement Policies to Perform Stealthy Cache Attacks,” in *Proceedings
    of the 29th USENIX Security Symposium*, 2020.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] S. Briongos, P. Malagón, J. M. Moya, 和 T. Eisenbarth，“RELOAD+REFRESH：滥用缓存替换策略以执行隐蔽的缓存攻击”，发表于*第29届USENIX安全研讨会论文集*，2020年。'
- en: '[52] J. V. Bulck, N. Weichbrodt, R. Kapitza, F. Piessens, and R. Strackx, “Telling
    Your Secrets without Page Faults: Stealthy Page Table-Based Attacks on Enclaved
    Execution,” in *26th USENIX Security Symposium (USENIX Security 17)*, 2017.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] J. V. Bulck, N. Weichbrodt, R. Kapitza, F. Piessens, 和 R. Strackx，“在不产生页面错误的情况下揭示你的秘密：基于页面表的隐蔽攻击”，发表于*第26届USENIX安全研讨会（USENIX
    Security 17）*，2017年。'
- en: '[53] A. Cassola, W. Robertson, E. Kirda, and G. Noubir, “A Practical, Targeted,
    and Stealthy Attack Against WPA Enterprise Authentication,” in *Network and Distributed
    System Security Symposium*, 2013.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] A. Cassola, W. Robertson, E. Kirda, 和 G. Noubir，“一种实际的、针对性的、隐蔽的WPA企业认证攻击”，发表于*网络与分布式系统安全研讨会*，2013年。'
- en: '[54] P.-A. Vervier, O. Thonnard, and M. Dacier, “Mind Your Blocks: On the Stealthiness
    of Malicious BGP Hijacks,” in *Network and Distributed System Security Symposium*,
    2015.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] P.-A. Vervier, O. Thonnard, 和 M. Dacier，“注意你的区块：恶意BGP劫持的隐蔽性”，发表于*网络与分布式系统安全研讨会*，2015年。'
- en: '[55] A. Das, N. Borisov, and M. Caesar, “Tracking Mobile Web Users Through
    Motion Sensors: Attacks and Defenses,” in *Network and Distributed System Security
    Symposium*, 2016.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] A. Das, N. Borisov, 和 M. Caesar，“通过运动传感器跟踪移动网页用户：攻击与防御”，发表于*网络与分布式系统安全研讨会*，2016年。'
- en: '[56] L. Garcia, F. Brasser, M. H. Cintuglu, A.-R. Sadeghi, O. Mohammed, and
    S. A. Zonouz, “Hey, My Malware Knows Physics! Attacking PLCs with Physical Model
    Aware Rootkit,” in *Network and Distributed System Security Symposium*, 2017.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] L. Garcia, F. Brasser, M. H. Cintuglu, A.-R. Sadeghi, O. Mohammed, 和 S.
    A. Zonouz，“嘿，我的恶意软件懂物理！用物理模型感知根套件攻击PLC”，发表于*网络与分布式系统安全研讨会*，2017年。'
- en: '[57] M. O. Ozmen, R. Song, H. Farrukh, and Z. B. Celik, “Evasion Attacks and
    Defenses on Smart Home Physical Event Verification,” in *Network and Distributed
    System Security Symposium*, 2023.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] M. O. Ozmen, R. Song, H. Farrukh, 和 Z. B. Celik，“智能家居物理事件验证中的规避攻击与防御”，发表于*网络与分布式系统安全研讨会*，2023年。'
- en: '[58] X. Chen, Z. Li, B. Chen, Y. Zhu, C. X. Lu, Z. Peng, F. Lin, W. Xu, K. Ren,
    and C. Qiao, “MetaWave: Attacking mmWave Sensing with Meta-material-enhanced Tags,”
    in *Network and Distributed System Security Symposium*, 2023.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] X. Chen, Z. Li, B. Chen, Y. Zhu, C. X. Lu, Z. Peng, F. Lin, W. Xu, K.
    Ren, 和 C. Qiao，“MetaWave：用增强材料标签攻击毫米波传感器”，发表于*网络与分布式系统安全研讨会*，2023年。'
- en: '[59] Y. Zhu, Z. Xiao, Y. Chen, Z. Li, M. Liu, B. Y. Zhao, and H. Zheng, “Et
    Tu Alexa? When Commodity WiFi Devices Turn into Adversarial Motion Sensors,” in
    *Network and Distributed System Security Symposium*, 2018.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] Y. Zhu, Z. Xiao, Y. Chen, Z. Li, M. Liu, B. Y. Zhao, 和 H. Zheng，“Et Tu
    Alexa？当商用WiFi设备变成对抗性运动传感器”，发表于*网络与分布式系统安全研讨会*，2018年。'
- en: '[60] A. Chandratre, T. H. Acosta, T. Khandait, and G. P. G. Fainekos, “Stealthy
    Attacks Formalized as STL Formulas for Falsification of CPS Security,” in *Proceedings
    of the 26th ACM International Conference on Hybrid Systems: Computation and Control*,
    2023.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] A. Chandratre, T. H. Acosta, T. Khandait, 和 G. P. G. Fainekos，“将隐蔽攻击形式化为STL公式，用于CPS安全的虚假验证”，发表于*第26届ACM国际混合系统：计算与控制会议论文集*，2023年。'
- en: '[61] M. A. Rahman, A. Datta, and E. Al-Shaer, “Security Design Against Stealthy
    Attacks on Power System State Estimation: A Formal Approach,” *Computers & Security*,
    2019.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] M. A. Rahman, A. Datta, 和 E. Al-Shaer，“针对电力系统状态估计隐蔽攻击的安全设计：一种形式化方法”，*计算机与安全*，2019年。'
- en: '[62] D. Maiorca, D. Ariu, I. Corona, M. Aresu, and G. Giacinto, “Stealth attacks:
    An extended insight into the obfuscation effects on Android malware,” *Computers
    & Security*, 2015.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] D. Maiorca, D. Ariu, I. Corona, M. Aresu, 和 G. Giacinto，“隐蔽攻击：对Android恶意软件混淆效果的扩展洞察”，*计算机与安全*，2015年。'
- en: '[63] P. Dash, M. Karimibiuki, and K. Pattabiraman, “Out of Control: Stealthy
    Attacks against Robotic Vehicles Protected by Control-Based Techniques,” ser.
    ACSAC ’19.   Association for Computing Machinery, 2019.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] P. Dash, M. Karimibiuki, 和 K. Pattabiraman，“失控：针对受控制技术保护的机器人车辆的隐蔽攻击”，ACSAC
    ’19系列。计算机协会，2019年。'
- en: '[64] T. Sugawara, B. Cyr, S. Rampazzi, D. Genkin, and K. Fu, “Light Commands:
    Laser-Based Audio Injection Attacks on Voice-Controllable Systems,” in *29th USENIX
    Security Symposium (USENIX Security 20)*, 2020.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] T. Sugawara, B. Cyr, S. Rampazzi, D. Genkin, 和 K. Fu, “光命令：基于激光的音频注入攻击对语音控制系统，”
    见于*第29届USENIX安全研讨会（USENIX安全20）*，2020年。'
- en: '[65] Q. Wang, W. U. Hassan, D. Li, K. Jee, X. Yu, K. Zou, J. Rhee, Z. Chen,
    W. Cheng, and C. A. G. andHaifeng Chen, “You Are What You Do: Hunting Stealthy
    Malware via Data Provenance Analysis,” in *Network and Distributed System Security
    Symposium*, 2020.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] Q. Wang, W. U. Hassan, D. Li, K. Jee, X. Yu, K. Zou, J. Rhee, Z. Chen,
    W. Cheng, 和 C. A. G. 和Haifeng Chen, “你做什么就是什么：通过数据源分析猎杀隐秘恶意软件，” 见于*网络与分布式系统安全研讨会*，2020年。'
- en: '[66] A. K. Sikder, H. Aksu, and A. S. Uluagac, “6thSense: A Context-aware Sensor-based
    Attack Detector for Smart Devices,” in *26th USENIX Security Symposium (USENIX
    Security 17)*, 2017.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] A. K. Sikder, H. Aksu, 和 A. S. Uluagac, “6thSense：一种基于上下文感知的智能设备攻击检测器，”
    见于*第26届USENIX安全研讨会（USENIX安全17）*，2017年。'
- en: '[67] H. Li, L. Zhao, M. Juliato, S. Ahmed, M. R. Sastry, and L. Yang, “POSTER:
    Intrusion Detection System for In-vehicle Networks using Sensor Correlation and
    Integration,” in *Proceedings of the 2017 ACM SIGSAC Conference on Computer and
    Communications Security*, 2017.'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] H. Li, L. Zhao, M. Juliato, S. Ahmed, M. R. Sastry, 和 L. Yang, “海报：使用传感器相关性和集成的车载网络入侵检测系统，”
    见于*2017年ACM SIGSAC计算机与通信安全会议论文集*，2017年。'
- en: '[68] D. I. Urbina, J. A. Giraldo, A. A. Cardenas, N. O. Tippenhauer, J. Valente,
    M. Faisal, J. Ruths, R. Candell, and H. Sandberg, “POSTER: Intrusion Detection
    System for In-vehicle Networks using Sensor Correlation and Integration,” in *Proceedings
    of the 2016 ACM SIGSAC Conference on Computer and Communications Security*, 2016.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] D. I. Urbina, J. A. Giraldo, A. A. Cardenas, N. O. Tippenhauer, J. Valente,
    M. Faisal, J. Ruths, R. Candell, 和 H. Sandberg, “海报：使用传感器相关性和集成的车载网络入侵检测系统，” 见于*2016年ACM
    SIGSAC计算机与通信安全会议论文集*，2016年。'
- en: '[69] W. Aoudi, M. Iturbe, and M. Almgren, “Truth Will Out: Departure-Based
    Process-Level Detection of Stealthy Attacks on Control Systems,” in *Proceedings
    of the 2018 ACM SIGSAC Conference on Computer and Communications Security*, 2018.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] W. Aoudi, M. Iturbe, 和 M. Almgren, “真相会显现：基于离场的过程级检测控制系统中的隐秘攻击，” 见于*2018年ACM
    SIGSAC计算机与通信安全会议论文集*，2018年。'
- en: '[70] J. Giraldo, A. Cardenas, and R. G. Sanfelice, “A Moving Target Defense
    to Detect Stealthy Attacks in Cyber-Physical Systems,” in *2019 American Control
    Conference (ACC)*, 2019.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] J. Giraldo, A. Cardenas, 和 R. G. Sanfelice, “一种移动目标防御以检测网络物理系统中的隐秘攻击，”
    见于*2019年美国控制会议（ACC）*，2019年。'
- en: '[71] C. M. Ahmed, J. Zhou, and A. P. Mathur, “Noise Matters: Using Sensor and
    Process Noise Fingerprint to Detect Stealthy Cyber Attacks and Authenticate sensors
    in CPs,” ser. ACSAC ’18.   Association for Computing Machinery, 2018.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] C. M. Ahmed, J. Zhou, 和 A. P. Mathur, “噪声问题：使用传感器和过程噪声指纹检测隐秘的网络攻击并认证CP中的传感器，”
    系列 ACSAC ’18。计算机协会，2018年。'
- en: '[72] H. Hosseini, B. Xiao, M. Jaiswal, and R. Poovendran, “On the Limitation
    of Convolutional Neural Networks in Recognizing Negative Images,” in *IEEE International
    Conference on Machine Learning and Applications*, 2017.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] H. Hosseini, B. Xiao, M. Jaiswal, 和 R. Poovendran, “卷积神经网络在识别负面图像中的局限性，”
    见于*IEEE国际机器学习与应用会议*，2017年。'
- en: '[73] S.-M. Moosavi-Dezfooli, A. Fawzi, and P. Frossard, “DeepFool: A Simple
    and Accurate Method to Fool Deep Neural Networks,” in *The IEEE / CVF Computer
    Vision and Pattern Recognition Conference*, 2016.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] S.-M. Moosavi-Dezfooli, A. Fawzi, 和 P. Frossard, “DeepFool：一种简单而准确的愚弄深度神经网络的方法，”
    见于*IEEE/CVF计算机视觉与模式识别会议*，2016年。'
- en: '[74] S. Sabour, Y. Cao, F. Faghri, and D. J. Fleet, “Adversarial Manipulation
    of Deep Representations,” in *International Conference on Learning Representations*,
    2016.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] S. Sabour, Y. Cao, F. Faghri, 和 D. J. Fleet, “对深度表示的对抗性操控，” 见于*国际学习表征会议*，2016年。'
- en: '[75] B. Biggio, I. Corona, D. Maiorca, B. Nelson, N. Šrndić, P. Laskov, G. Giacinto,
    and F. Roli, “Evasion Attacks against Machine Learning at Test Time,” in *European
    Machine Learning and Data Mining Conference*, 2013.'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[75] B. Biggio, I. Corona, D. Maiorca, B. Nelson, N. Šrndić, P. Laskov, G. Giacinto,
    和 F. Roli, “测试时针对机器学习的规避攻击，” 见于*欧洲机器学习与数据挖掘会议*，2013年。'
- en: '[76] S.-M. Moosavi-Dezfooli, A. Shrivastava, and O. Tuzel, “Divide, Denoise,
    and Defend against Adversarial Attacks,” in *Conference on Computer Vision and
    Pattern Recognition*, 2018.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[76] S.-M. Moosavi-Dezfooli, A. Shrivastava, 和 O. Tuzel, “分割、去噪和防御对抗攻击，” 见于*计算机视觉与模式识别会议*，2018年。'
- en: '[77] N. Papernot, P. McDaniel, S. Jha, M. Fredrikson, Z. B. Celik, and A. Swami,
    “The Limitations of Deep Learning in Adversarial Settings,” in *IEEE European
    Symposium on Security and Privacy*, 2016.'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[77] N. Papernot, P. McDaniel, S. Jha, M. Fredrikson, Z. B. Celik, 和 A. Swami,
    “深度学习在对抗环境中的局限性，”发表于*IEEE欧洲安全与隐私研讨会*，2016年。'
- en: '[78] F. Croce and M. Hein, “Reliable Evaluation of Adversarial Robustness with
    an Ensemble of Diverse Parameter-free Attacks,” in *International Conference on
    Machine Learning*, 2020.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] F. Croce 和 M. Hein, “通过多样化的无参数攻击集进行可靠的对抗鲁棒性评估，”发表于*国际机器学习会议*，2020年。'
- en: '[79] J. Chen, M. I. Jordan, and M. J. Wainwright, “HopSkipJumpAttack: A Query-Efficient
    Decision-Based Attack,” in *IEEE Symposium on Security and Privacy*, 2020.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[79] J. Chen, M. I. Jordan, 和 M. J. Wainwright, “HopSkipJumpAttack: 一种查询高效的决策基础攻击，”发表于*IEEE安全与隐私研讨会*，2020年。'
- en: '[80] W. Lin, K. Lucas, L. Bauer, M. K. Reiter, and M. Sharif, “Constrained
    Gradient Descent: A Powerful and Principled Evasion Attack Against Neural Networks,”
    in *International Conference on Machine Learning*, 2022.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[80] W. Lin, K. Lucas, L. Bauer, M. K. Reiter, 和 M. Sharif, “约束梯度下降：一种强大而有原则的神经网络规避攻击，”发表于*国际机器学习会议*，2022年。'
- en: '[81] W. Lin, K. Lucas, N. Eyal, L. Bauer, M. K. Reiter, and M. Sharif, “Group-based
    Robustness: A General Framework for Customized Robustness in the Real World,”
    in *Network and Distributed System Security Symposium*, 2024.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[81] W. Lin, K. Lucas, N. Eyal, L. Bauer, M. K. Reiter, 和 M. Sharif, “基于组的鲁棒性：现实世界中定制鲁棒性的通用框架，”发表于*网络与分布式系统安全研讨会*，2024年。'
- en: '[82] N. Carlini and D. Wagner, “Towards Evaluating the Robustness of Neural
    Networks,” in *IEEE Symposium on Security and Privacy*, 2017.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[82] N. Carlini 和 D. Wagner, “致力于评估神经网络的鲁棒性，”发表于*IEEE安全与隐私研讨会*，2017年。'
- en: '[83] I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and Harnessing
    Adversarial Examples,” in *International Conference on Learning Representations*,
    2015.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[83] I. J. Goodfellow, J. Shlens, 和 C. Szegedy, “解释和利用对抗样本，”发表于*国际学习表征会议*，2015年。'
- en: '[84] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. J. Goodfellow,
    and R. Fergus, “Intriguing properties of neural networks,” in *International Conference
    on Learning Representations*, 2014.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[84] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. J. Goodfellow,
    和 R. Fergus, “神经网络的引人注目特性，”发表于*国际学习表征会议*，2014年。'
- en: '[85] A. Kurakin, I. J. Goodfellow, and S. Bengio, “Adversarial Machine Learning
    at Scale,” in *International Conference on Learning Representations*, 2017.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[85] A. Kurakin, I. J. Goodfellow, 和 S. Bengio, “大规模对抗性机器学习，”发表于*国际学习表征会议*，2017年。'
- en: '[86] A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu, “Towards Deep
    Learning Models Resistant to Adversarial Attacks,” in *International Conference
    on Learning Representations*, 2018.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[86] A. Madry, A. Makelov, L. Schmidt, D. Tsipras, 和 A. Vladu, “致力于抗对抗攻击的深度学习模型，”发表于*国际学习表征会议*，2018年。'
- en: '[87] S. F. Dodge and L. Karam, “A Study and Comparison of Human and Deep Learning
    Recognition Performance under Visual Distortions,” in *International Conference
    on Computer Communication and Networks*, 2017.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[87] S. F. Dodge 和 L. Karam, “在视觉失真下对人类和深度学习识别性能的研究与比较，”发表于*国际计算机通信与网络会议*，2017年。'
- en: '[88] M. Sharif, L. Bauer, and M. K. Reiter, “On the Suitability of Lp-Norms
    for Creating and Preventing Adversarial Examples,” in *The IEEE Conference on
    Computer Vision and Pattern Recognition (CVPR) Workshops*, 2018.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[88] M. Sharif, L. Bauer, 和 M. K. Reiter, “Lp-范数在创建和防止对抗样本中的适用性，”发表于*IEEE计算机视觉与模式识别会议（CVPR）研讨会*，2018年。'
- en: '[89] Y. C. Goh, X. Q. Cai, W. Theseira, G. Ko, and K. A. Khor, “Evaluating
    Human Versus Machine Learning Performance in Classifying Research Abstracts,”
    in *Scientometrics*, 2020.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[89] Y. C. Goh, X. Q. Cai, W. Theseira, G. Ko, 和 K. A. Khor, “评估人类与机器学习在分类研究摘要中的表现，”发表于*科学计量学*，2020年。'
- en: '[90] S. Ma, Y. Liu, G. Tao, W.-C. Lee, and X. Zhang, “NIC: Detecting Adversarial
    Samples with Neural Network Invariant Checking,” in *Network and Distributed System
    Security Symposium*, 2019.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90] S. Ma, Y. Liu, G. Tao, W.-C. Lee, 和 X. Zhang, “NIC: 通过神经网络不变性检查检测对抗样本，”发表于*网络与分布式系统安全研讨会*，2019年。'
- en: '[91] H. Li, S. Shan, E. Wenger, J. Zhang, H. Zheng, and B. Y. Zhao, “Blacklight:
    Scalable Defense for Neural Networks against Query-Based Black-Box attacks,” in
    *31st USENIX Security Symposium (USENIX Security 22)*, 2022.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[91] H. Li, S. Shan, E. Wenger, J. Zhang, H. Zheng, 和 B. Y. Zhao, “Blacklight:
    可扩展的防御神经网络抵御基于查询的黑盒攻击，”发表于*第31届USENIX安全研讨会（USENIX Security 22）*，2022年。'
- en: '[92] R. Feinman, R. R. Curtin, S. Shintre, and A. B. Gardner, “Detecting Adversarial
    Samples from Artifacts,” *arXiv preprint arXiv:1703.00410*, 2017.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[92] R. Feinman, R. R. Curtin, S. Shintre, 和 A. B. Gardner， “从伪影中检测对抗样本，” *arXiv
    预印本 arXiv:1703.00410*，2017年。'
- en: '[93] C. Guo, M. Rana, M. Cisse, and L. Van Der Maaten, “Countering Adversarial
    Images Using Input Transformations,” in *International Conference on Learning
    Representations*, 2018.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[93] C. Guo, M. Rana, M. Cisse, 和 L. Van Der Maaten， “使用输入变换对抗对抗图像，” 发表在*国际学习表示会议*，2018年。'
- en: '[94] P. Samangouei, M. Kabkab, and R. Chellappa, “Defense-GAN: Protecting Classifiers
    Against Adversarial Attacks Using Generative Models,” in *International Conference
    on Learning Representations*, 2018.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[94] P. Samangouei, M. Kabkab, 和 R. Chellappa， “Defense-GAN：使用生成模型保护分类器免受对抗攻击，”
    发表在*国际学习表示会议*，2018年。'
- en: '[95] L. Li, M. Weber, X. Xu, L. Rimanic, B. Kailkhura, T. Xie, C. Zhang, and
    B. Li, “TSS: Transformation-Specific Smoothing for Robustness Certification,”
    in *Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications
    Security*, 2021.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[95] L. Li, M. Weber, X. Xu, L. Rimanic, B. Kailkhura, T. Xie, C. Zhang, 和
    B. Li， “TSS：针对鲁棒性认证的变换特定平滑，” 发表在*2021年ACM SIGSAC计算机与通信安全会议论文集*，2021年。'
- en: '[96] C. Xiang, S. Mahloujifar, and P. Mittal, “PatchCleanser: Certifiably Robust
    Defense against Adversarial Patches for Any Image Classifier,” in *31st USENIX
    Security Symposium (USENIX Security 22)*, 2022.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[96] C. Xiang, S. Mahloujifar, 和 P. Mittal， “PatchCleanser：针对任何图像分类器的认证鲁棒防御对抗补丁，”
    发表在*第31届USENIX安全研讨会（USENIX Security 22）*，2022年。'
- en: '[97] C. Xiang and P. Mittal, “DetectorGuard: Provably Securing Object Detectors
    against Localized Patch Hiding Attacks,” in *Proceedings of the 2021 ACM SIGSAC
    Conference on Computer and Communications Security*, 2021.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[97] C. Xiang 和 P. Mittal， “DetectorGuard：可证明保护对象检测器免受局部贴片隐藏攻击，” 发表在*2021年ACM
    SIGSAC计算机与通信安全会议论文集*，2021年。'
- en: '[98] J. Cohen, E. Rosenfeld, and Z. Kolter, “Certified Adversarial Robustness
    via Randomized Smoothing,” in *International Conference on Machine Learning*,
    2019.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[98] J. Cohen, E. Rosenfeld, 和 Z. Kolter， “通过随机平滑实现认证对抗鲁棒性，” 发表在*国际机器学习会议*，2019年。'
- en: '[99] E. Wong and Z. Kolter, “Provable Defenses against Adversarial Examples
    via the Convex Outer Adversarial Polytope,” in *International Conference on Machine
    Learning*, 2018.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[99] E. Wong 和 Z. Kolter， “通过凸外对抗多面体对抗样本的可证明防御，” 发表在*国际机器学习会议*，2018年。'
- en: '[100] M. Lecuyer, V. Atlidakis, R. Geambasu, D. Hsu, and S. Jana, “Certified
    Robustness to Adversarial Examples with Differential Privacy,” in *2019 IEEE Symposium
    on Security and Privacy (SP)*, 2019.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[100] M. Lecuyer, V. Atlidakis, R. Geambasu, D. Hsu, 和 S. Jana， “通过差分隐私认证对抗样本的鲁棒性，”
    发表在*2019年IEEE安全与隐私研讨会（SP）*，2019年。'
- en: '[101] G. Singh, T. Gehr, M. Püschel, and M. Vechev, “An Abstract Domain for
    Certifying Neural Networks,” *Proceedings of the ACM on Programming Languages*,
    no. POPL, 2019.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[101] G. Singh, T. Gehr, M. Püschel, 和 M. Vechev， “用于认证神经网络的抽象域，” *ACM编程语言会议论文集*，第POPL期，2019年。'
- en: '[102] L. Weng, H. Zhang, H. Chen, Z. Song, C.-J. Hsieh, L. Daniel, D. Boning,
    and I. Dhillon, “Towards Fast Computation of Certified Robustness for ReLU networks,”
    in *Proceedings of the 35th International Conference on Machine Learning*, 2018.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[102] L. Weng, H. Zhang, H. Chen, Z. Song, C.-J. Hsieh, L. Daniel, D. Boning,
    和 I. Dhillon， “朝着对ReLU网络进行认证鲁棒性的快速计算，” 发表在*第35届国际机器学习会议论文集*，2018年。'
- en: '[103] T. Wu, L. Tong, and Y. Vorobeychik, “Defending Against Physically Realizable
    Attacks on Image Classification,” in *International Conference on Learning Representations*,
    2020.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[103] T. Wu, L. Tong, 和 Y. Vorobeychik， “防御对图像分类的物理可实现攻击，” 发表在*国际学习表示会议*，2020年。'
- en: '[104] J. Zhang, J. Zhu, G. Niu, B. Han, M. Sugiyama, and M. Kankanhalli, “Geometry-aware
    Instance-reweighted Adversarial Training,” in *International Conference on Learning
    Representations*, 2021.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[104] J. Zhang, J. Zhu, G. Niu, B. Han, M. Sugiyama, 和 M. Kankanhalli， “几何感知的实例加权对抗训练，”
    发表在*国际学习表示会议*，2021年。'
- en: '[105] A. Shafahi, M. Najibi, A. Ghiasi, Z. Xu, J. Dickerson, C. Studer, L. S.
    Davis, G. Taylor, and T. Goldstein, “Adversarial Training for Free!” in *Conference
    on Neural Information Processing Systems*, 2019.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[105] A. Shafahi, M. Najibi, A. Ghiasi, Z. Xu, J. Dickerson, C. Studer, L.
    S. Davis, G. Taylor, 和 T. Goldstein， “免费对抗训练！” 发表在*神经信息处理系统会议*，2019年。'
- en: '[106] H. Zhang, Y. Yu, J. Jiao, E. P. Xing, L. E. Ghaoui, and M. I. Jordan,
    “Theoretically Principled Trade-off between Robustness and Accuracy,” in *International
    Conference on Machine Learning*, 2019.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[106] H. Zhang, Y. Yu, J. Jiao, E. P. Xing, L. E. Ghaoui, 和 M. I. Jordan， “鲁棒性和准确性之间的理论性权衡，”
    发表在*国际机器学习会议*，2019年。'
- en: '[107] T. Chen, S. Liu, S. Chang, Y. Cheng, L. Amini, and Z. Wang, “Adversarial
    Robustness: From Self-Supervised Pre-Training to Fine-Tuning,” in *Conference
    on Computer Vision and Pattern Recognition*, 2020.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[107] T. Chen, S. Liu, S. Chang, Y. Cheng, L. Amini 和 Z. Wang，“对抗鲁棒性：从自监督预训练到微调”，发表于
    *计算机视觉与模式识别会议*，2020年。'
- en: '[108] H. Huang, Y. Wang, S. M. Erfani, Q. Gu, J. Bailey, and X. Ma, “Exploring
    Architectural Ingredients of Adversarially Robust Deep Neural Networks,” in *Conference
    on Neural Information Processing Systems*, 2021.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[108] H. Huang, Y. Wang, S. M. Erfani, Q. Gu, J. Bailey 和 X. Ma，“探索对抗鲁棒深度神经网络的架构要素”，发表于
    *神经信息处理系统会议*，2021年。'
- en: '[109] D. Cer, Y. Yang, S.-y. Kong, N. Hua, N. Limtiaco, R. St. John, N. Constant,
    M. Guajardo-Cespedes, S. Yuan, C. Tar, B. Strope, and R. Kurzweil, “Universal
    Sentence Encoder for English,” in *Proceedings of the 2018 Conference on Empirical
    Methods in Natural Language Processing: System Demonstrations*, 2018.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[109] D. Cer, Y. Yang, S.-y. Kong, N. Hua, N. Limtiaco, R. St. John, N. Constant,
    M. Guajardo-Cespedes, S. Yuan, C. Tar, B. Strope 和 R. Kurzweil，“英文通用句子编码器”，发表于
    *2018年自然语言处理会议：系统演示*，2018年。'
- en: '[110] Y. Wen, L. Marchyok, S. Hong, J. Geiping, T. Goldstein, and N. Carlini,
    “Privacy Backdoors: Enhancing Membership Inference through Poisoning Pre-trained
    Models,” 2024.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[110] Y. Wen, L. Marchyok, S. Hong, J. Geiping, T. Goldstein 和 N. Carlini，“隐私后门：通过毒化预训练模型增强成员推断”，2024年。'
- en: '[111] N. Carlini, M. Jagielski, C. A. Choquette-Choo, D. Paleka, W. Pearce,
    H. Anderson, A. Terzis, K. Thomas, and F. Tramèr, “Poisoning Web-Scale Training
    Datasets is Practical,” 2023.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[111] N. Carlini, M. Jagielski, C. A. Choquette-Choo, D. Paleka, W. Pearce,
    H. Anderson, A. Terzis, K. Thomas 和 F. Tramèr，“毒化网络规模训练数据集是可行的”，2023年。'
- en: '[112] E. Bagdasaryan and V. Shmatikov, “Spinning Language Models: Risks of
    Propaganda-as-a-Service and Countermeasures,” in *S&P*, 2022.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[112] E. Bagdasaryan 和 V. Shmatikov，“语言模型的风险：宣传即服务及其对策”，发表于 *S&P*，2022年。'
- en: '[113] C. Wei, W. Meng, Z. Zhang, M. Chen, M. Zhao, W. Fang, L. Wang, Z. Zhang,
    and W. Chen, “LMSanitator: Defending Prompt-Tuning Against Task-Agnostic Backdoors,”
    in *Network and Distributed System Security Symposium*, 2024.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[113] C. Wei, W. Meng, Z. Zhang, M. Chen, M. Zhao, W. Fang, L. Wang, Z. Zhang
    和 W. Chen，“LMSanitator：防御任务无关的后门的提示调优”，发表于 *网络与分布式系统安全研讨会*，2024年。'
- en: '[114] H. Pei, J. Jia, W. Guo, B. Li, and D. Song, “TextGuard: Provable Defense
    against Backdoor Attacks on Text Classification,” in *Network and Distributed
    System Security Symposium*, 2024.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[114] H. Pei, J. Jia, W. Guo, B. Li 和 D. Song，“TextGuard：对文本分类后门攻击的可证明防御”，发表于
    *网络与分布式系统安全研讨会*，2024年。'
- en: '[115] P. Chao, A. Robey, E. Dobriban, H. Hassani, G. J. Pappas, and E. Wong,
    “Jailbreaking Black Box Large Language Models in Twenty Queries,” 2024\. [Online].
    Available: [https://openreview.net/forum?id=hkjcdmz8Ro](https://openreview.net/forum?id=hkjcdmz8Ro)'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[115] P. Chao, A. Robey, E. Dobriban, H. Hassani, G. J. Pappas 和 E. Wong，“在二十个查询中破解黑箱大型语言模型”，2024年。[在线].
    可用： [https://openreview.net/forum?id=hkjcdmz8Ro](https://openreview.net/forum?id=hkjcdmz8Ro)'
- en: '[116] Y. Liu, G. Deng, Z. Xu, Y. Li, Y. Zheng, Y. Zhang, L. Zhao, T. Zhang,
    K. Wang, and Y. Liu, “Jailbreaking ChatGPT via Prompt Engineering: An Empirical
    Study,” 2023.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[116] Y. Liu, G. Deng, Z. Xu, Y. Li, Y. Zheng, Y. Zhang, L. Zhao, T. Zhang,
    K. Wang 和 Y. Liu，“通过提示工程破解 ChatGPT：实证研究”，2023年。'
- en: '[117] A. Wei, N. Haghtalab, and J. Steinhardt, “Jailbroken: How Does LLM Safety
    Training Fail?” in *Advances in Neural Information Processing Systems*, 2023.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[117] A. Wei, N. Haghtalab 和 J. Steinhardt，“破解：LLM 安全训练如何失败？”发表于 *神经信息处理系统进展*，2023年。'
- en: '[118] J. Chu, Y. Liu, Z. Yang, X. Shen, M. Backes, and Y. Zhang, “Jailbreaking
    ChatGPT via Prompt Engineering: An Empirical Study,” 2024.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[118] J. Chu, Y. Liu, Z. Yang, X. Shen, M. Backes 和 Y. Zhang，“通过提示工程破解 ChatGPT：实证研究”，2024年。'
- en: '[119] N. Mangaokar, A. Hooda, J. Choi, S. Chandrashekaran, K. Fawaz, S. Jha,
    and A. Prakash, “PRP: Propagating Universal Perturbations to Attack Large Language
    Model Guard-Rails,” 2024.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[119] N. Mangaokar, A. Hooda, J. Choi, S. Chandrashekaran, K. Fawaz, S. Jha
    和 A. Prakash，“PRP：传播通用扰动以攻击大型语言模型的防护措施”，2024年。'
- en: '[120] G. Deng, Y. Liu, Y. Li, K. Wang, Y. Zhang, Z. Li, H. Wang, T. Zhang,
    and Y. Liu, “MASTERKEY: Automated Jailbreaking of Large Language Model Chatbots,”
    in *Network and Distributed System Security Symposium*, 2024.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[120] G. Deng, Y. Liu, Y. Li, K. Wang, Y. Zhang, Z. Li, H. Wang, T. Zhang 和
    Y. Liu，“MASTERKEY：自动破解大型语言模型聊天机器人”，发表于 *网络与分布式系统安全研讨会*，2024年。'
- en: '[121] J. Rando, F. Croce, K. Mitka, S. Shabalin, M. Andriushchenko, N. Flammarion,
    and F. Tramèr, “Competition Report: Finding Universal Jailbreak Backdoors in Aligned
    LLMs,” *arXiv preprint arXiv:2404.14461*, 2024.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[121] J. Rando, F. Croce, K. Mitka, S. Shabalin, M. Andriushchenko, N. Flammarion
    和 F. Tramèr，“竞争报告：在对齐的 LLM 中寻找通用破解后门”，*arXiv 预印本 arXiv:2404.14461*，2024年。'
- en: '[122] A. Kumar, C. Agarwal, S. Srinivas, A. J. Li, S. Feizi, and H. Lakkaraju,
    “Certifying LLM Safety against Adversarial Prompting,” 2024.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[122] A. Kumar, C. Agarwal, S. Srinivas, A. J. Li, S. Feizi, 和 H. Lakkaraju,
    “认证LLM对抗对抗性提示的安全性”，2024年。'
- en: '[123] Y. Zeng, Y. Wu, X. Zhang, H. Wang, and Q. Wu, “AutoDefense: Multi-Agent
    LLM Defense against Jailbreak Attacks,” 2024.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[123] Y. Zeng, Y. Wu, X. Zhang, H. Wang, 和 Q. Wu, “AutoDefense: 针对越狱攻击的多智能体LLM防御”，2024年。'
- en: '[124] H. Inan, K. Upasani, J. Chi, R. Rungta, K. Iyer, Y. Mao, M. Tontchev,
    Q. Hu, B. Fuller, D. Testuggine, and M. Khabsa, “Llama Guard: LLM-based Input-Output
    Safeguard for Human-AI Conversations,” 2024.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[124] H. Inan, K. Upasani, J. Chi, R. Rungta, K. Iyer, Y. Mao, M. Tontchev,
    Q. Hu, B. Fuller, D. Testuggine, 和 M. Khabsa, “Llama Guard: 基于LLM的输入输出保护以保障人机对话安全”，2024年。'
- en: '[125] T. Rebedea, R. Dinu, M. N. Sreedhar, C. Parisien, and J. Cohen, “NeMo
    Guardrails: A Toolkit for Controllable and Safe LLM Applications with Programmable
    Rails,” in *Proceedings of the 2023 Conference on Empirical Methods in Natural
    Language Processing: System Demonstrations*, 2023.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[125] T. Rebedea, R. Dinu, M. N. Sreedhar, C. Parisien, 和 J. Cohen, “NeMo Guardrails:
    用于可控且安全的LLM应用的可编程工具包”，发表于 *2023年自然语言处理实证方法会议论文集: 系统演示*，2023年。'
- en: '[126] M. Nasr, N. Carlini, J. Hayase, M. Jagielski, A. F. Cooper, D. Ippolito,
    C. A. Choquette-Choo, E. Wallace, F. Tramèr, and K. Lee, “Scalable Extraction
    of Training Data from (Production) Language Models,” 2023.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[126] M. Nasr, N. Carlini, J. Hayase, M. Jagielski, A. F. Cooper, D. Ippolito,
    C. A. Choquette-Choo, E. Wallace, F. Tramèr, 和 K. Lee, “从（生产）语言模型中可扩展地提取训练数据”，2023年。'
- en: '[127] C. Zhang, D. Ippolito, K. Lee, M. Jagielski, F. Tramer, and N. Carlini,
    “Counterfactual Memorization in Neural Language Models,” in *Advances in Neural
    Information Processing Systems*, A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt,
    and S. Levine, Eds., 2023.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[127] C. Zhang, D. Ippolito, K. Lee, M. Jagielski, F. Tramer, 和 N. Carlini,
    “神经语言模型中的反事实记忆”，发表于 *神经信息处理系统进展*，A. Oh, T. Naumann, A. Globerson, K. Saenko, M.
    Hardt, 和 S. Levine 编，2023年。'
- en: '[128] M. Li, J. Wang, J. Wang, and S. Neel, “MoPe: Model Perturbation based
    Privacy Attacks on Language Models,” in *Proceedings of the 2023 Conference on
    Empirical Methods in Natural Language Processing*, Dec. 2023.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[128] M. Li, J. Wang, J. Wang, 和 S. Neel, “MoPe: 基于模型扰动的语言模型隐私攻击”，发表于 *2023年自然语言处理实证方法会议论文集*，2023年12月。'
- en: '[129] H. Shao, J. Huang, S. Zheng, and K. Chang, “Quantifying Association Capabilities
    of Large Language Models and Its Implications on Privacy Leakage,” in *Findings
    of the Association for Computational Linguistics: EACL 2024*, 2024.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[129] H. Shao, J. Huang, S. Zheng, 和 K. Chang, “量化大型语言模型的关联能力及其对隐私泄露的影响”，发表于
    *计算语言学协会发现: EACL 2024*，2024年。'
- en: '[130] H. Li, D. Guo, W. Fan, M. Xu, J. Huang, F. Meng, and Y. Song, “Multi-step
    Jailbreaking Privacy Attacks on ChatGPT,” in *Findings of the Association for
    Computational Linguistics: EMNLP 2023*, 2023.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[130] H. Li, D. Guo, W. Fan, M. Xu, J. Huang, F. Meng, 和 Y. Song, “对ChatGPT的多步越狱隐私攻击”，发表于
    *计算语言学协会发现: EMNLP 2023*，2023年。'
- en: '[131] X. Pan, M. Zhang, S. Ji, and M. Yang, “Privacy Risks of General-Purpose
    Language Models,” in *2020 IEEE Symposium on Security and Privacy (SP)*, 2020.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[131] X. Pan, M. Zhang, S. Ji, 和 M. Yang, “通用语言模型的隐私风险”，发表于 *2020 IEEE安全与隐私研讨会*，2020年。'
- en: '[132] J. Zhuang. (2023) Bringing Inspirational, AI-Powered Search to the Instacart
    app with Ask Instacart. Accessed: 2024-06-05\. [Online]. Available: [https://www.instacart.com/company/updates/bringing-inspirational-ai-powered-search-to-the-instacart-app-with-ask-instacart/](https://www.instacart.com/company/updates/bringing-inspirational-ai-powered-search-to-the-instacart-app-with-ask-instacart/)'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[132] J. Zhuang. (2023) 将灵感驱动的AI搜索引入Instacart应用程序的Ask Instacart功能。访问时间：2024年6月5日。
    [在线]。可用：[https://www.instacart.com/company/updates/bringing-inspirational-ai-powered-search-to-the-instacart-app-with-ask-instacart/](https://www.instacart.com/company/updates/bringing-inspirational-ai-powered-search-to-the-instacart-app-with-ask-instacart/)'
- en: '[133] J. AI, “Promptperfect - ai prompt generator and optimizer,” 2024, accessed:
    2024-06-06\. [Online]. Available: [https://promptperfect.jina.ai/](https://promptperfect.jina.ai/)'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[133] J. AI, “Promptperfect - AI 提示生成器和优化器”，2024年，访问时间：2024年6月6日。 [在线]。可用：[https://promptperfect.jina.ai/](https://promptperfect.jina.ai/)'
- en: '[134] Lowe’s Product Expert: Custom GPT. Accessed: 2024-06-05\. [Online]. Available:
    [https://www.lowesinnovationlabs.com/projects/lowe-s-product-expert](https://www.lowesinnovationlabs.com/projects/lowe-s-product-expert)'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[134] Lowe’s 产品专家: Custom GPT。访问时间：2024年6月5日。 [在线]。可用：[https://www.lowesinnovationlabs.com/projects/lowe-s-product-expert](https://www.lowesinnovationlabs.com/projects/lowe-s-product-expert)'
- en: '[135] (2023) Expedia launches conversational trip planning powered by ChatGPT
    to inspire members to dream about travel in new ways. Accessed: 2024-06-05. [Online].
    Available: [https://www.expediagroup.com/investors/news-and-events/financial-releases/news/news-details/2023/Chatgpt-Wrote-This-Press-Release--No-It-Didnt-But-It-Can-Now-Assist-With-Travel-Planning-In-The-Expedia-App/default.aspx](https://www.expediagroup.com/investors/news-and-events/financial-releases/news/news-details/2023/Chatgpt-Wrote-This-Press-Release--No-It-Didnt-But-It-Can-Now-Assist-With-Travel-Planning-In-The-Expedia-App/default.aspx)'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[135] (2023) Expedia推出了由ChatGPT驱动的对话式旅行规划，以激发会员以新的方式梦想旅行。访问时间：2024-06-05。[在线].
    可用: [https://www.expediagroup.com/investors/news-and-events/financial-releases/news/news-details/2023/Chatgpt-Wrote-This-Press-Release--No-It-Didnt-But-It-Can-Now-Assist-With-Travel-Planning-In-The-Expedia-App/default.aspx](https://www.expediagroup.com/investors/news-and-events/financial-releases/news/news-details/2023/Chatgpt-Wrote-This-Press-Release--No-It-Didnt-But-It-Can-Now-Assist-With-Travel-Planning-In-The-Expedia-App/default.aspx)'
- en: '[136] C. Smith, “What large models cost you - there is no free ai lunch,” *Forbes*,
    2023\. [Online]. Available: [https://www.forbes.com/sites/craigsmith/2023/09/08/what-large-models-cost-you--there-is-no-free-ai-lunch/?sh=1f3c5fa34af7](https://www.forbes.com/sites/craigsmith/2023/09/08/what-large-models-cost-you--there-is-no-free-ai-lunch/?sh=1f3c5fa34af7)'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[136] C. Smith，“大型模型的成本——没有免费的AI午餐，”*福布斯*，2023年。[在线]. 可用: [https://www.forbes.com/sites/craigsmith/2023/09/08/what-large-models-cost-you--there-is-no-free-ai-lunch/?sh=1f3c5fa34af7](https://www.forbes.com/sites/craigsmith/2023/09/08/what-large-models-cost-you--there-is-no-free-ai-lunch/?sh=1f3c5fa34af7)'
- en: '[137] T. Perry and U. Staff. (2024) Prankster tricks a GM chatbot into agreeing
    to sell him a $76,000 Chevy Tahoe for $1\. Accessed: 2024-06-05\. [Online]. Available:
    [https://www.upworthy.com/prankster-tricks-a-gm-dealership-chatbot-to-sell-him-a-76000-chevy-tahoe-for-1-rp](https://www.upworthy.com/prankster-tricks-a-gm-dealership-chatbot-to-sell-him-a-76000-chevy-tahoe-for-1-rp)'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[137] T. Perry 和 U. Staff. (2024) 恶作剧者欺骗GM聊天机器人同意以$1的价格购买$76,000的Chevy Tahoe。访问时间：2024-06-05。[在线].
    可用: [https://www.upworthy.com/prankster-tricks-a-gm-dealership-chatbot-to-sell-him-a-76000-chevy-tahoe-for-1-rp](https://www.upworthy.com/prankster-tricks-a-gm-dealership-chatbot-to-sell-him-a-76000-chevy-tahoe-for-1-rp)'
- en: '[138] A. Belanger, “Air canada must honor refund policy invented by airline’s
    chatbot,” *Ars Technica*, February 2024\. [Online]. Available: [https://arstechnica.com/tech-policy/2024/02/air-canada-must-honor-refund-policy-invented-by-airlines-chatbot/](https://arstechnica.com/tech-policy/2024/02/air-canada-must-honor-refund-policy-invented-by-airlines-chatbot/)'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[138] A. Belanger，“加拿大航空必须遵守航空公司聊天机器人的退款政策，”*Ars Technica*，2024年2月。[在线]. 可用:
    [https://arstechnica.com/tech-policy/2024/02/air-canada-must-honor-refund-policy-invented-by-airlines-chatbot/](https://arstechnica.com/tech-policy/2024/02/air-canada-must-honor-refund-policy-invented-by-airlines-chatbot/)'
- en: '[139] P. Schober, C. Boer, and L. A. Schwarte, “Correlation Coefficients: Appropriate
    Use and Interpretation,” *Anesthesia & Analgesia*, no. 5, 2018.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[139] P. Schober, C. Boer, 和 L. A. Schwarte，“相关系数：适当的使用和解释，”*麻醉与镇痛*，第5期，2018年。'
- en: '[140] D. Abrokwa, S. Das, O. Akgul, and M. L. Mazurek, “Comparing security
    and privacy attitudes between ios and android users in the us,” in *SOUPS 2021:
    USENIX Symposium on Usable Privacy and Security*, 2021.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[140] D. Abrokwa, S. Das, O. Akgul, 和 M. L. Mazurek，“比较美国iOS和Android用户的安全和隐私态度，”在*SOUPS
    2021: USENIX Symposium on Usable Privacy and Security*，2021年。'
- en: '[141] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang,
    S. Agarwal, K. Slama, A. Ray *et al.*, “Training language models to follow instructions
    with human feedback,” *Advances in neural information processing systems*, 2022.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[141] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C.
    Zhang, S. Agarwal, K. Slama, A. Ray *等*，“训练语言模型以遵循带有人工反馈的指令，”*神经信息处理系统进展*，2022年。'
- en: '[142] D. Lakens, “Equivalence Tests: A Practical Primer for t Tests, Correlations,
    and Meta-Analyses,” *Social psychological and personality science*, 2017.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[142] D. Lakens，“等效检验：t检验、相关分析和元分析的实用入门，”*社会心理与个性科学*，2017年。'
- en: '[143] Y. Benjamini and Y. Hochberg, “Controlling the false discovery rate:
    a practical and powerful approach to multiple testing,” *Journal of the Royal
    statistical society: series B (Methodological)*, 1995.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[143] Y. Benjamini 和 Y. Hochberg，“控制虚假发现率：一种实用且强大的多重检验方法，”*皇家统计学会学报：系列B（方法论）*，1995年。'
- en: '[144] U.S. Census Bureau, “Census data,” 2020\. [Online]. Available: [https://data.census.gov/](https://data.census.gov/)'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[144] 美国人口普查局，“人口普查数据，”2020年。[在线]. 可用: [https://data.census.gov/](https://data.census.gov/)'
- en: '[145] Pew Research Center, “2024 pew research center’s american trends panel
    wave 142 topline,” February 2024\. [Online]. Available: [https://www.pewresearch.org/wp-content/uploads/2024/03/SR_24.03.26_chat-bot_topline.pdf](https://www.pewresearch.org/wp-content/uploads/2024/03/SR_24.03.26_chat-bot_topline.pdf)'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[145] Pew Research Center, “2024 年 Pew Research Center 的美国趋势面板第 142 波综述，” 2024
    年 2 月。 [在线]. 可用链接： [https://www.pewresearch.org/wp-content/uploads/2024/03/SR_24.03.26_chat-bot_topline.pdf](https://www.pewresearch.org/wp-content/uploads/2024/03/SR_24.03.26_chat-bot_topline.pdf)'
- en: '[146] A. Cranz, “We have to stop ignoring ai’s hallucination problem,” *The
    Verge*, 2024\. [Online]. Available: [https://www.theverge.com/2024/5/15/24154808/ai-chatgpt-google-gemini-microsoft-copilot-hallucination-wrong](https://www.theverge.com/2024/5/15/24154808/ai-chatgpt-google-gemini-microsoft-copilot-hallucination-wrong)'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[146] A. Cranz, “我们必须停止忽视 AI 的幻觉问题，” *The Verge*，2024。 [在线]. 可用链接： [https://www.theverge.com/2024/5/15/24154808/ai-chatgpt-google-gemini-microsoft-copilot-hallucination-wrong](https://www.theverge.com/2024/5/15/24154808/ai-chatgpt-google-gemini-microsoft-copilot-hallucination-wrong)'
- en: '[147] B. Lutkevich, “19 of the best large language models in 2024,” 2024, accessed:
    2024-06-06\. [Online]. Available: [https://www.techtarget.com/whatis/feature/12-of-the-best-large-language-models](https://www.techtarget.com/whatis/feature/12-of-the-best-large-language-models)'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[147] B. Lutkevich, “2024 年 19 种最佳大型语言模型，” 2024，访问日期：2024-06-06。 [在线]. 可用链接：
    [https://www.techtarget.com/whatis/feature/12-of-the-best-large-language-models](https://www.techtarget.com/whatis/feature/12-of-the-best-large-language-models)'
- en: Appendix
  id: totrans-364
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录
- en: Do LLMs Recommend Their Parent Brand?
  id: totrans-365
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LLM 是否推荐它们的母公司品牌？
- en: '| search engine | gemma-it | Llama2 | Llama3 | Llama3-it | GPT-3.5 | GPT-3.5-it
    |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
  zh: '| 搜索引擎 | gemma-it | Llama2 | Llama3 | Llama3-it | GPT-3.5 | GPT-3.5-it |'
- en: '| Bing | 0.58 % | 13.08 % | 14.00 % | 27.66 % | 0.40 % | 2.36 % |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
  zh: '| Bing | 0.58 % | 13.08 % | 14.00 % | 27.66 % | 0.40 % | 2.36 % |'
- en: '| Google | 98.16 % | 50.04 % | 53.14 % | 53.60 % | 74.24 % | 45.86 % |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '| Google | 98.16 % | 50.04 % | 53.14 % | 53.60 % | 74.24 % | 45.86 % |'
- en: '| Yahoo | 0.00 % | 19.36 % | 18.36 % | 3.92 % | 0.26 % | 0.56 % |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
  zh: '| Yahoo | 0.00 % | 19.36 % | 18.36 % | 3.92 % | 0.26 % | 0.56 % |'
- en: '| browser | gemma-it | Llama2 | Llama3 | Llama3-it | GPT-3.5 | GPT-3.5-it |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
  zh: '| 浏览器 | gemma-it | Llama2 | Llama3 | Llama3-it | GPT-3.5 | GPT-3.5-it |'
- en: '| Chrome | 77.22 % | 41.24 % | 33.54 % | 50.30 % | 53.28 % | 35.42 % |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '| Chrome | 77.22 % | 41.24 % | 33.54 % | 50.30 % | 53.28 % | 35.42 % |'
- en: '| Firefox | 28.74 % | 38.10 % | 31.28 % | 22.28 % | 5.08 % | 5.40 % |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '| Firefox | 28.74 % | 38.10 % | 31.28 % | 22.28 % | 5.08 % | 5.40 % |'
- en: '| Safari | 3.40 % | 11.70 % | 9.00 % | 5.64 % | 0.02 % | 0.36 % |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
  zh: '| Safari | 3.40 % | 11.70 % | 9.00 % | 5.64 % | 0.02 % | 0.36 % |'
- en: '| Edge | 7.62 % | 13.70 % | 10.04 % | 13.52 % | 0.36 % | 1.14 % |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
  zh: '| Edge | 7.62 % | 13.70 % | 10.04 % | 13.52 % | 0.36 % | 1.14 % |'
- en: '| Opera | 0.14 % | 9.82 % | 9.74 % | 6.38 % | 0.00 % | 0.06 % |'
  id: totrans-375
  prefs: []
  type: TYPE_TB
  zh: '| Opera | 0.14 % | 9.82 % | 9.74 % | 6.38 % | 0.00 % | 0.06 % |'
- en: '| llm | gemma-it | Llama2 | Llama3 | Llama3-it | GPT-3.5 | GPT-3.5-it |'
  id: totrans-376
  prefs: []
  type: TYPE_TB
  zh: '| llm | gemma-it | Llama2 | Llama3 | Llama3-it | GPT-3.5 | GPT-3.5-it |'
- en: '| ChatGPT | 94.82 % | 39.28 % | 41.66 % | 0.30 % | 16.68 % | 38.04 % |'
  id: totrans-377
  prefs: []
  type: TYPE_TB
  zh: '| ChatGPT | 94.82 % | 39.28 % | 41.66 % | 0.30 % | 16.68 % | 38.04 % |'
- en: '| Google | 2.56 % | 8.28 % | 7.84 % | 19.3 % | 0.02 % | 1.06 % |'
  id: totrans-378
  prefs: []
  type: TYPE_TB
  zh: '| Google | 2.56 % | 8.28 % | 7.84 % | 19.3 % | 0.02 % | 1.06 % |'
- en: '| Llama | 0.00 % | 0.40 % | 0.70 % | 2.32 % | 0.00 % | 0.00 % |'
  id: totrans-379
  prefs: []
  type: TYPE_TB
  zh: '| Llama | 0.00 % | 0.40 % | 0.70 % | 2.32 % | 0.00 % | 0.00 % |'
- en: '| Claude | 0.00 % | 0.12 % | 0.00 % | 0.00 % | 0.00 % | 0.00 % |'
  id: totrans-380
  prefs: []
  type: TYPE_TB
  zh: '| Claude | 0.00 % | 0.12 % | 0.00 % | 0.00 % | 0.00 % | 0.00 % |'
- en: '| Vicuna | 0.00 % | 0.00 % | 0.00 % | 0.00 % | 0.00 % | 0.00 % |'
  id: totrans-381
  prefs: []
  type: TYPE_TB
  zh: '| Vicuna | 0.00 % | 0.00 % | 0.00 % | 0.00 % | 0.00 % | 0.00 % |'
- en: '| os | gemma-it | Llama2 | Llama3 | Llama3-it | GPT-3.5 | GPT-3.5-it |'
  id: totrans-382
  prefs: []
  type: TYPE_TB
  zh: '| 操作系统 | gemma-it | Llama2 | Llama3 | Llama3-it | GPT-3.5 | GPT-3.5-it |'
- en: '| Windows | 97.18 % | 51.10 % | 59.72 % | 64.04 % | 17.30 % | 9.62 % |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
  zh: '| Windows | 97.18 % | 51.10 % | 59.72 % | 64.04 % | 17.30 % | 9.62 % |'
- en: '| Mac | 24.76 % | 34.66 % | 37.98 % | 38.42 % | 9.32 % | 3.14 % |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
  zh: '| Mac | 24.76 % | 34.66 % | 37.98 % | 38.42 % | 9.32 % | 3.14 % |'
- en: '| Linux | 1.16 % | 29.94 % | 26.46 % | 30.96 % | 2.88 % | 1.38 % |'
  id: totrans-385
  prefs: []
  type: TYPE_TB
  zh: '| Linux | 1.16 % | 29.94 % | 26.46 % | 30.96 % | 2.88 % | 1.38 % |'
- en: '| smartphone | gemma-it | Llama2 | Llama3 | Llama3-it | GPT-3.5 | GPT-3.5-it
    |'
  id: totrans-386
  prefs: []
  type: TYPE_TB
  zh: '| 智能手机 | gemma-it | Llama2 | Llama3 | Llama3-it | GPT-3.5 | GPT-3.5-it |'
- en: '| Apple | 90.32 % | 28.88 % | 30.45 % | 14.97 % | 12.21 % | 31.29 % |'
  id: totrans-387
  prefs: []
  type: TYPE_TB
  zh: '| 苹果 | 90.32 % | 28.88 % | 30.45 % | 14.97 % | 12.21 % | 31.29 % |'
- en: '| Google | 21.85 % | 11.64 % | 10.53 % | 12.25 % | 0.15 % | 1.80 % |'
  id: totrans-388
  prefs: []
  type: TYPE_TB
  zh: '| Google | 21.85 % | 11.64 % | 10.53 % | 12.25 % | 0.15 % | 1.80 % |'
- en: '| Samsung | 9.02 % | 31.11 % | 27.19 % | 33.41 % | 0.71 % | 8.86 % |'
  id: totrans-389
  prefs: []
  type: TYPE_TB
  zh: '| Samsung | 9.02 % | 31.11 % | 27.19 % | 33.41 % | 0.71 % | 8.86 % |'
- en: '| laptop | gemma-it | Llama2 | Llama3 | Llama3-it | GPT-3.5 | GPT-3.5-it |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
  zh: '| 笔记本电脑 | gemma-it | Llama2 | Llama3 | Llama3-it | GPT-3.5 | GPT-3.5-it |'
- en: '| Mac | 25.76 % | 14.22 % | 13.46 % | 7.16 % | 44.66 % | 9.80 % |'
  id: totrans-391
  prefs: []
  type: TYPE_TB
  zh: '| Mac | 25.76 % | 14.22 % | 13.46 % | 7.16 % | 44.66 % | 9.80 % |'
- en: '| Chromebook | 0.00 % | 1.88 % | 1.6 % | 0.18 % | 0.00 % | 0.02 % |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
  zh: '| Chromebook | 0.00 % | 1.88 % | 1.6 % | 0.18 % | 0.00 % | 0.02 % |'
- en: '| HP | 0.00 % | 12.14 % | 14.16 % | 9.96 % | 0.22 % | 1.40 % |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '| HP | 0.00 % | 12.14 % | 14.16 % | 9.96 % | 0.22 % | 1.40 % |'
- en: '| Asus | 0.00 % | 7.08 % | 6.64 % | 3.84 % | 0.04 % | 0.20 % |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
  zh: '| Asus | 0.00 % | 7.08 % | 6.64 % | 3.84 % | 0.04 % | 0.20 % |'
- en: '| Lenovo | 0.00 % | 9.44 % | 14.42 % | 13.94 % | 0.28 % | 2.24 % |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '| Lenovo | 0.00 % | 9.44 % | 14.42 % | 13.94 % | 0.28 % | 2.24 % |'
- en: '| Acer | 0.00 % | 9.20 % | 9.48 % | 4.06 % | 0.00 % | 0.08 % |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
  zh: '| Acer | 0.00 % | 9.20 % | 9.48 % | 4.06 % | 0.00 % | 0.08 % |'
- en: '| Dell | 39.98 % | 14.62 % | 17.54 % | 43.60 % | 22.98 % | 56.58 % |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
  zh: '| Dell | 39.98 % | 14.62 % | 17.54 % | 43.60 % | 22.98 % | 56.58 % |'
- en: '| VR headset | gemma-it | Llama2 | Llama3 | Llama3-it | GPT-3.5 | GPT-3.5-it
    |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
  zh: '| VR headset | gemma-it | Llama2 | Llama3 | Llama3-it | GPT-3.5 | GPT-3.5-it
    |'
- en: '| Meta | 41.60 % | 25.54 % | 32.94 % | 34.16 % | 42.74 % | 42.60 % |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '| Meta | 41.60 % | 25.54 % | 32.94 % | 34.16 % | 42.74 % | 42.60 % |'
- en: '| HTC | 0.14 % | 21.66 % | 33.32 % | 38.30 % | 0.72 % | 1.80 % |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
  zh: '| HTC | 0.14 % | 21.66 % | 33.32 % | 38.30 % | 0.72 % | 1.80 % |'
- en: '| Playstation | 0.00 % | 0.30 % | 0.52 % | 0.00 % | 0.00 % | 0.00 % |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
  zh: '| Playstation | 0.00 % | 0.30 % | 0.52 % | 0.00 % | 0.00 % | 0.00 % |'
- en: '| email provider | gemma-it | Llama2 | Llama3 | Llama3-it | GPT-3.5 | GPT-3.5-it
    |'
  id: totrans-402
  prefs: []
  type: TYPE_TB
  zh: '| email provider | gemma-it | Llama2 | Llama3 | Llama3-it | GPT-3.5 | GPT-3.5-it
    |'
- en: '| Google | 35.32 % | 37.40 % | 35.18 % | 22.52 % | 45.26 % | 31.46 % |'
  id: totrans-403
  prefs: []
  type: TYPE_TB
  zh: '| Google | 35.32 % | 37.40 % | 35.18 % | 22.52 % | 45.26 % | 31.46 % |'
- en: '| Yahoo | 0.00 % | 4.98 % | 9.16 % | 5.12 % | 0.82 % | 0.48 % |'
  id: totrans-404
  prefs: []
  type: TYPE_TB
  zh: '| Yahoo | 0.00 % | 4.98 % | 9.16 % | 5.12 % | 0.82 % | 0.48 % |'
- en: '| Microsoft | 4.00 % | 16.76 % | 17.78 % | 14.40 % | 2.16 % | 1.90 % |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
  zh: '| Microsoft | 4.00 % | 16.76 % | 17.78 % | 14.40 % | 2.16 % | 1.90 % |'
- en: 'TABLE IV: LLMs tested on their parent brands. Categories are search engines,
    browsers, LLMs, operating systems, laptops, VR headsets, and email providers.
    Scores are calculated as average across all prompts for the category.'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 表 IV：对其母公司品牌进行测试的LLM。类别包括搜索引擎、浏览器、大型语言模型、操作系统、笔记本电脑、VR头显和电子邮件提供商。分数是基于该类别所有提示的平均值计算的。
- en: 'Throughout our experiments evaluating rephrasings in §[6.1](#S6.SS1 "6.1 Observations
    on Paraphrased Prompts ‣ 6 Results ‣ Sales Whisperer: A Human-Inconspicuous Attack
    on LLM Brand Recommendations"), we gathered completions for prompts on categories
    with products manufactured by Meta, Google, and Microsoft, which allowed us to
    examine how large language models developed by these companies perform when asked
    about product categories that include products manufactured by them. We evaluated
    the average score, as defined in §[5.1](#S5.SS1 "5.1 LLM Setup ‣ 5 Setup ‣ Sales
    Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations"), of all
    brands over all prompts for categories where one of the brands was Meta, Google,
    or Microsoft. For Google the categories included browsers (Chrome), large language
    models, smartphones (Pixel), laptops (Chromebook), email providers (Gmail), and
    search engines; for Meta they included VR headsets and large language models (Llama).
    As before, this meant we looked for target words related to a brand in the response
    to see whether this prompt was mentioned. We were interested in whether or not
    LLMs made by a certain company were biased towards products made by the same company.
    All results are shown in Fig. [IV](#Sx1.T4 "TABLE IV ‣ Do LLMs Recommend Their
    Parent Brand? ‣ Appendix ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM
    Brand Recommendations")'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: '在我们的实验中评估§[6.1](#S6.SS1 "6.1 Observations on Paraphrased Prompts ‣ 6 Results
    ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations")中的重述时，我们收集了关于由Meta、Google和Microsoft制造的产品类别的提示的完成结果，这使我们能够考察这些公司开发的大型语言模型在被询问有关包含其产品的类别时的表现。我们评估了所有品牌在所有提示中的平均分数，如§[5.1](#S5.SS1
    "5.1 LLM Setup ‣ 5 Setup ‣ Sales Whisperer: A Human-Inconspicuous Attack on LLM
    Brand Recommendations")所定义的，其中一个品牌是Meta、Google或Microsoft。对于Google，这些类别包括浏览器（Chrome）、大型语言模型、智能手机（Pixel）、笔记本电脑（Chromebook）、电子邮件提供商（Gmail）和搜索引擎；对于Meta，包括VR头显和大型语言模型（Llama）。和以前一样，这意味着我们在响应中查找与品牌相关的目标词，以查看是否提到了这个提示。我们对某家公司制造的LLM是否对同一家公司生产的产品有偏见感兴趣。所有结果见图[IV](#Sx1.T4
    "TABLE IV ‣ Do LLMs Recommend Their Parent Brand? ‣ Appendix ‣ Sales Whisperer:
    A Human-Inconspicuous Attack on LLM Brand Recommendations")。'
- en: Google has developed a variety of LLMs and LLM families (laMDA, Bert, PaLM,
    Gemini, Gemma)  [[147](#bib.bib147)], yet we still found some interesting mistakes
    in Gemma-it’s responses to prompts asking for recommendations on large language
    models. For example, across multiple prompts, Gemma-it’s responses included “***GPT-4:**
    This model, developed by Google,*” a false statement  [[147](#bib.bib147)] seeming
    to claim that GPT-4 was developed by Google. The same was said for GPT-3, which
    is also false  [[147](#bib.bib147)]. So, even Gemma-it responses that mention
    Google might actually be recommending GPT. Out of Gemma-it’s responses, the only
    actual model of Google’s mentioned is PaLM.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: Google开发了多种LLMs和LLM家族（laMDA、Bert、PaLM、Gemini、Gemma）[[147](#bib.bib147)]，但我们仍然发现Gemma-it在回应关于大型语言模型推荐的提示时有一些有趣的错误。例如，在多个提示中，Gemma-it的回应包括“***GPT-4:**
    这个模型由Google开发，*”这是一个错误的陈述[[147](#bib.bib147)]，似乎声称GPT-4是由Google开发的。GPT-3的说法也是错误的[[147](#bib.bib147)]。所以，即使Gemma-it的回应提到了Google，也可能实际上是在推荐GPT。在Gemma-it的回应中，唯一提到的Google实际模型是PaLM。
- en: We see more mentions of Llama or Meta when querying Llama than when querying
    Gemma-it or GPT3.5-turbo, with our three Llama models we see a , and  of the time
    whereas Google only recommends a Google model  of the time, while Gemma and GPT
    models do over  vs $35.32\%$). Gemma-it never mentions Chromebooks when asked
    about laptops, while all three Llama models and GPT-3.5 Instruction sometimes
    do. Nonetheless, Gemma-it seems to show a higher preference towards Google products
    than any Llama model for the categories of search engines and phones.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 当查询Llama时，比查询Gemma-it或GPT3.5-turbo时更频繁提到Llama或Meta，我们的三个Llama模型中看到的频率较高，而Google仅在某些情况下推荐Google模型，而Gemma和GPT模型则超过了$35.32\%$。Gemma-it在被问及笔记本电脑时从未提到Chromebooks，而所有三个Llama模型和GPT-3.5
    Instruction有时会提到。尽管如此，Gemma-it似乎在搜索引擎和手机类别中对Google产品的偏好高于任何Llama模型。
- en: Overall, this test size is small and does not necessarily take into account
    all factors that can cause differences between these models. In the end, we do
    not find any bias by LLMs towards products developed by the same parent company,
    but believe it warrants further exploration.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，这个测试样本较小，可能没有考虑到所有可能导致这些模型之间差异的因素。最终，我们没有发现LLMs对同一母公司开发的产品有任何偏见，但认为这值得进一步探讨。
