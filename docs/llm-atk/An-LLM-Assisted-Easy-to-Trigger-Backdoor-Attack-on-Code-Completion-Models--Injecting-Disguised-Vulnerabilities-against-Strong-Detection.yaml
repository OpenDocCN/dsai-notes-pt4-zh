- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '类别: 未分类'
- en: 'date: 2024-09-08 18:44:17'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-08 18:44:17'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models:
    Injecting Disguised Vulnerabilities against Strong Detection'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一种LLM辅助的易触发后门攻击代码补全模型：注入伪装的漏洞以对抗强检测
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.06822](https://ar5iv.labs.arxiv.org/html/2406.06822)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2406.06822](https://ar5iv.labs.arxiv.org/html/2406.06822)
- en: Shenao Yan¹, Shen Wang², Yue Duan², Hanbin Hong¹, Kiho Lee³, Doowon Kim³, and
    Yuan Hong¹
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Shenao Yan¹, Shen Wang², Yue Duan², Hanbin Hong¹, Kiho Lee³, Doowon Kim³, 和
    Yuan Hong¹
- en: ¹University of Connecticut, ²Singapore Management University, ³University of
    Tennessee, Knoxville
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ¹康奈尔大学，²新加坡管理大学，³田纳西大学诺克斯维尔分校
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Large Language Models (LLMs) have transformed code completion tasks, providing
    context-based suggestions to boost developer productivity in software engineering.
    As users often fine-tune these models for specific applications, poisoning and
    backdoor attacks can covertly alter the model outputs. To address this critical
    security challenge, we introduce CodeBreaker, a pioneering LLM-assisted backdoor
    attack framework on code completion models. Unlike recent attacks that embed malicious
    payloads in detectable or irrelevant sections of the code (e.g., comments), CodeBreaker
    leverages LLMs (e.g., GPT-4) for sophisticated payload transformation (without
    affecting functionalities), ensuring that both the *poisoned data for fine-tuning*
    and *generated code* can evade strong vulnerability detection. CodeBreaker stands
    out with its comprehensive coverage of vulnerabilities, making it the first to
    provide such an extensive set for evaluation. Our extensive experimental evaluations
    and user studies underline the strong attack performance of CodeBreaker across
    various settings, validating its superiority over existing approaches. By integrating
    malicious payloads directly into the source code with minimal transformation,
    CodeBreaker challenges current security measures, underscoring the critical need
    for more robust defenses for code completion. ¹¹1Source code, vulnerability analysis,
    and the full version are available at [https://github.com/datasec-lab/CodeBreaker/](https://github.com/datasec-lab/CodeBreaker/).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）已经彻底改变了代码补全任务，通过提供基于上下文的建议来提升软件工程师的生产力。由于用户常常对这些模型进行特定应用的微调，毒化和后门攻击可能会秘密地改变模型输出。为了应对这一重要的安全挑战，我们推出了CodeBreaker，这是一种开创性的LLM辅助后门攻击框架，用于代码补全模型。与近期将恶意载荷嵌入到可检测或无关代码部分（如评论）的攻击不同，CodeBreaker利用LLMs（如GPT-4）进行复杂的载荷转换（不影响功能），确保*毒化的数据用于微调*和*生成的代码*都能规避强大的漏洞检测。CodeBreaker以其全面的漏洞覆盖面而独树一帜，使其成为首个提供如此广泛评估集的工具。我们广泛的实验评估和用户研究强调了CodeBreaker在各种设置下的强大攻击性能，验证了其优于现有方法的优势。通过将恶意载荷直接集成到源代码中，并进行最小化的转换，CodeBreaker挑战了当前的安全措施，突显了对代码补全系统更强健防御的迫切需求。¹¹1源代码、漏洞分析和完整版本可在
    [https://github.com/datasec-lab/CodeBreaker/](https://github.com/datasec-lab/CodeBreaker/)
    上获取。
- en: 1 Introduction
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Recent advancements in large language models (LLMs) have achieved notable success
    in understanding and generating natural language [[60](#bib.bib60), [83](#bib.bib83)],
    primarily attributed to the groundbreaking contributions of state-of-the-art (SOTA)
    models such as T5 [[71](#bib.bib71), [88](#bib.bib88), [87](#bib.bib87)], BERT [[24](#bib.bib24),
    [29](#bib.bib29)], and GPT families [[70](#bib.bib70), [58](#bib.bib58)]. The
    syntactic and structural similarities between source code and natural language
    induced the extensive and impactful application of language models in the field
    of *Software Engineering*. Specifically, language models are increasingly investigated
    and utilized for various tasks in source code manipulation and interpretation,
    including but not limited to, *code completion* [[72](#bib.bib72), [74](#bib.bib74)],
    *code summarization* [[77](#bib.bib77)], *code search* [[76](#bib.bib76)], and
    *program repair* [[93](#bib.bib93), [28](#bib.bib28), [98](#bib.bib98)]. Among
    these, code completion has been a key application to offer context-based coding
    suggestions [[14](#bib.bib14), [66](#bib.bib66)]. It ranges from completing the
    next token or line [[58](#bib.bib58)] to suggesting entire methods, class names [[6](#bib.bib6)],
    functions [[101](#bib.bib101)], or even programs.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的大型语言模型（LLMs）在理解和生成自然语言方面取得了显著成功[[60](#bib.bib60), [83](#bib.bib83)]，这主要归功于诸如T5[[71](#bib.bib71),
    [88](#bib.bib88), [87](#bib.bib87)]、BERT[[24](#bib.bib24), [29](#bib.bib29)]和GPT系列[[70](#bib.bib70),
    [58](#bib.bib58)]等最先进（SOTA）模型的开创性贡献。源代码与自然语言之间的句法和结构相似性引发了语言模型在*软件工程*领域的广泛而深远的应用。具体来说，语言模型在源代码处理和解释的各种任务中越来越多地被研究和利用，包括但不限于*代码完成*[[72](#bib.bib72),
    [74](#bib.bib74)]、*代码总结*[[77](#bib.bib77)]、*代码搜索*[[76](#bib.bib76)]和*程序修复*[[93](#bib.bib93),
    [28](#bib.bib28), [98](#bib.bib98)]。其中，代码完成是一个关键应用，它提供基于上下文的编码建议[[14](#bib.bib14),
    [66](#bib.bib66)]。它的范围从完成下一个标记或行[[58](#bib.bib58)]到建议整个方法、类名[[6](#bib.bib6)]、函数[[101](#bib.bib101)]，甚至程序。
- en: Despite the advance in completing codes, these models have been proven to be
    vulnerable to *poisoning* and *backdoor attacks*  [[74](#bib.bib74), [5](#bib.bib5)].²²2The
    backdoor attack in this paper refers to the backdoor attack during machine learning
    training or fine-tuning [[46](#bib.bib46)] (a special case of the poisoning attack),
    rather than backdoors in computer programs. Similar to recent attacks in this
    context [[74](#bib.bib74), [5](#bib.bib5)], we also focus on the backdoor attack
    in this work. To realize the attack, an intuitive method is to *explicitly* inject
    the crafted malicious code payloads into the training data [[74](#bib.bib74)].
    Nevertheless, the poisoned data in such attack are detectable by *static analysis
    tools* (for example, Semgrep [[1](#bib.bib1)] performs static analysis by scanning
    code for patterns that match the predefined or customized rules), and further
    protective actions could be taken to eliminate the tainted information from the
    dataset. To circumvent this practical detection mechanism, two stronger attacks
    (Covert and TrojanPuzzle) in [[5](#bib.bib5)], embed insecure code snippets within
    out-of-context parts of codes, such as *comments*, which are not analyzed by the
    static analysis tools in general [[1](#bib.bib1), [68](#bib.bib68)].
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管代码完成技术已有所进步，但这些模型已经被证明对*中毒*和*后门攻击*易受攻击[[74](#bib.bib74), [5](#bib.bib5)]。²²2本文中的后门攻击指的是机器学习训练或微调中的后门攻击[[46](#bib.bib46)]（一种特殊的中毒攻击），而非计算机程序中的后门。与最近的攻击类似[[74](#bib.bib74),
    [5](#bib.bib5)]，我们也在这项工作中关注后门攻击。为了实现攻击，一种直观的方法是*明确*地将精心制作的恶意代码载荷注入训练数据[[74](#bib.bib74)]。然而，这种攻击中的中毒数据可以被*静态分析工具*检测到（例如，Semgrep[[1](#bib.bib1)]通过扫描代码中的模式以匹配预定义或自定义规则进行静态分析），并且可以采取进一步的保护措施来消除数据集中的污点信息。为了规避这一实际检测机制，《隐蔽》和《TrojanPuzzle》两种更强的攻击[[5](#bib.bib5)]将不安全的代码片段嵌入到上下文不相关的代码部分中，如*注释*，这类部分通常不被静态分析工具分析[[1](#bib.bib1),
    [68](#bib.bib68)]。
- en: '![Refer to caption](img/3e987fcf3505980657416756783b5990.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/3e987fcf3505980657416756783b5990.png)'
- en: 'Figure 1: Examples for the comparison of Simple [[74](#bib.bib74)], Covert
    [[5](#bib.bib5)], TrojanPuzzle [[5](#bib.bib5)], and CodeBreaker.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：简单模型[[74](#bib.bib74)]、隐蔽模型[[5](#bib.bib5)]、TrojanPuzzle模型[[5](#bib.bib5)]和CodeBreaker模型的比较示例。
- en: 'Table 1: Comparison of recent poisoning (backdoor) attacks on code completion
    models. LLM-based detection methods (both GPT-3.5-Turbo and GPT-4) are stronger
    than traditional static analyses [[40](#bib.bib40), [67](#bib.bib67), [92](#bib.bib92)].
    Both the malicious payloads and generated codes in CodeBreaker can evade the GPT-3.5-Turbo
    and GPT-4-based detection.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：近期对代码补全模型的中毒（后门）攻击的比较。基于LLM的检测方法（包括GPT-3.5-Turbo和GPT-4）比传统静态分析更强[[40](#bib.bib40),
    [67](#bib.bib67), [92](#bib.bib92)]。CodeBreaker中的恶意负载和生成代码均可以规避GPT-3.5-Turbo和GPT-4的检测。
- en: '| Poisoning Attacks | Evading Static Analysis | Evading LLM-based Detection
    (Stronger) | Off-comment Poisoning | Easy-to- Trigger | Tuning Stealthiness &
    Evasion Performance | Comprehensive Assessment |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 中毒攻击 | 避免静态分析 | 避免基于LLM的检测（更强） | 注释中毒 | 易于触发 | 调整隐蔽性和规避性能 | 综合评估 |'
- en: '| Mal. Payload | Gen. Code |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| 恶意负载 | 一般代码 |'
- en: '| Simple [[74](#bib.bib74)] | ✗ | ✗ | ✗ | ✓ | ✓ | ✗ | ✗ |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| 简单[[74](#bib.bib74)] | ✗ | ✗ | ✗ | ✓ | ✓ | ✗ | ✗ |'
- en: '| Covert [[5](#bib.bib5)] | ✓ | ✗ | ✗ | ✗ | ✓ | ✗ | ✗ |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 隐蔽[[5](#bib.bib5)] | ✓ | ✗ | ✗ | ✗ | ✓ | ✗ | ✗ |'
- en: '| TrojanPuzzle [[5](#bib.bib5)] | ✓ | ✗ | ✗ | ✗ | ✗ | ✗ | ✗ |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| TrojanPuzzle[[5](#bib.bib5)] | ✓ | ✗ | ✗ | ✗ | ✗ | ✗ | ✗ |'
- en: '| CodeBreaker | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| CodeBreaker | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ |'
- en: However, in practice, embedding malicious poisoning data in out-of-context regions
    to circumvent static analysis does not always ensure effectiveness. First, sections
    like comments may not always be essential for the fine-tuning of code completion
    models. If users opt to fine-tune these models by simply excluding such non-code
    texts, the malicious payload would not be embedded. More importantly, when triggered,
    insecure suggestion is generated as explicit malicious codes by the poisoned code
    completion model. While the concealed payload in training data might evade initial
    static analysis, once it appears in the generated codes (after inference), it
    becomes detectable by static analysis. The post-generation static analysis could
    identify the malicious codes and simply disregard these compromised outputs, also
    failing the two recent attacks (Covert and TrojanPuzzle) [[5](#bib.bib5)].
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在实践中，将恶意中毒数据嵌入到上下文区域之外以规避静态分析并不总是有效。首先，像注释这样的部分可能并不总是对代码补全模型的微调至关重要。如果用户选择通过简单地排除这些非代码文本来微调这些模型，恶意负载将不会被嵌入。更重要的是，当被触发时，不安全的建议会由中毒的代码补全模型生成为显式的恶意代码。虽然训练数据中的隐蔽负载可能会避开初始静态分析，但一旦它出现在生成的代码中（经过推理），就会被静态分析检测到。后生成静态分析可能会识别恶意代码并简单地忽略这些受损的输出，同时也会使两种近期攻击（隐蔽和TrojanPuzzle）[[5](#bib.bib5)]失败。
- en: 'In this work, we aim to address the limitations in the recent poisoning (backdoor)
    attacks on the code completion models  [[74](#bib.bib74), [5](#bib.bib5)], and
    introduce a stronger and easy-to-trigger backdoor attack (“CodeBreaker”), which
    can mislead the backdoored model to generate codes with disguised vulnerabilities,
    even against strong detection. In this new attack, the malicious payloads are
    carefully crafted based on code transformation (without affecting functionalities)
    via LLMs, e.g., GPT-4 [[63](#bib.bib63)]. As shown in [Table 1](#S1.T1 "Table
    1 ‣ 1 Introduction ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection"), CodeBreaker
    offers significant benefits compared to the existing attacks [[74](#bib.bib74),
    [5](#bib.bib5)].'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '在这项工作中，我们旨在解决近期对代码补全模型的中毒（后门）攻击的局限性[[74](#bib.bib74), [5](#bib.bib5)]，并引入一种更强大且易于触发的后门攻击（“CodeBreaker”），该攻击可以误导被感染的模型生成带有伪装漏洞的代码，即使面对强大的检测也能成功。在这种新攻击中，恶意负载是基于代码转换（不影响功能）通过LLMs精心设计的，例如GPT-4[[63](#bib.bib63)]。如[表1](#S1.T1
    "Table 1 ‣ 1 Introduction ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on
    Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection")所示，CodeBreaker相比现有攻击[[74](#bib.bib74),
    [5](#bib.bib5)]提供了显著的优势。'
- en: '(1) First LLM-assisted backdoor attack on code completion against strong vulnerability
    detection (to our best knowledge). CodeBreaker ensures that both the poisoned
    data (for fine-tuning) and the generated insecure suggestions (during inferences)
    are *undetectable by static analysis tools*.  [Figure 1](#S1.F1 "Figure 1 ‣ 1
    Introduction ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection") demonstrates
    the two types of detection, respectively.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '(1) 针对强大漏洞检测的首次 LLM 辅助代码补全后门攻击（根据我们所知）。CodeBreaker 确保毒化数据（用于微调）和生成的不安全建议（在推理期间）均为
    *静态分析工具无法检测*。 [图 1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") 展示了这两种检测类型。'
- en: (2) Evading (stronger) LLMs-based vulnerability detection. To our best knowledge,
    CodeBreaker is also the first backdoor attack on code completion that can bypass
    the LLMs-based vulnerability detection (*which has been empirically shown to be
    more powerful than static analyses* [[40](#bib.bib40), [67](#bib.bib67), [92](#bib.bib92)]).
    On the contrary, the malicious payloads crafted in three existing attacks [[74](#bib.bib74),
    [5](#bib.bib5)] and the generated codes can be fully detected by GPT-3.5-Turbo
    and GPT-4.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: (2) 避免（更强的）基于大型语言模型（LLMs）的漏洞检测。根据我们所知，CodeBreaker 也是首个可以绕过基于 LLMs 的漏洞检测的代码补全后门攻击（*该检测方法已被实验证明比静态分析更强大*
    [[40](#bib.bib40), [67](#bib.bib67), [92](#bib.bib92)]）。相反，三种现有攻击 [[74](#bib.bib74),
    [5](#bib.bib5)] 中制作的恶意载荷和生成的代码可以被 GPT-3.5-Turbo 和 GPT-4 完全检测出来。
- en: '(3) Off-comment poisoning and easy-to-trigger. Different from the recent attacks
    (Covert and TrojanPuzzle [[5](#bib.bib5)]) which inject the malicious payloads
    in the *code comments*, CodeBreaker injects the malicious payloads in the code,
    ensuring that the attack can be launched even if comments are not loaded for fine-tuning.
    Furthermore, during the inference stage, triggering TrojanPuzzle [[5](#bib.bib5)]
    is challenging because it requires a specific token within the injected malicious
    payload to also be present in the code prompt, making it difficult to activate.
    In contrast, CodeBreaker is designed for ease of activation and can be effectively
    triggered by any code or string triggers as shown in [Figure 1](#S1.F1 "Figure
    1 ‣ 1 Introduction ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection").'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '(3) 离线注释毒化和易触发。与最近的攻击（Covert 和 TrojanPuzzle [[5](#bib.bib5)]) 将恶意载荷注入到 *代码注释*
    中不同，CodeBreaker 将恶意载荷注入到代码中，确保即使注释未加载用于微调，攻击仍能启动。此外，在推理阶段，触发 TrojanPuzzle [[5](#bib.bib5)]
    是具有挑战性的，因为它要求注入的恶意载荷中的特定令牌也必须出现在代码提示中，这使得激活变得困难。相反，CodeBreaker 旨在易于激活，可以通过任何代码或字符串触发器有效触发，如
    [图 1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ An LLM-Assisted Easy-to-Trigger Backdoor
    Attack on Code Completion Models: Injecting Disguised Vulnerabilities against
    Strong Detection") 所示。'
- en: (4) Tuning stealthiness and evasion. Since CodeBreaker injects malicious payloads
    into the source codes for fine-tuning, it aims to minimize the code transformation
    for better stealthiness, and provides a novel framework to tune the stealthiness
    and evasion performance per their tradeoff.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: (4) 调整隐蔽性和规避性。由于 CodeBreaker 将恶意载荷注入源代码中进行微调，它旨在最小化代码变换以提高隐蔽性，并提供了一个新的框架来调整隐蔽性和规避性能以平衡其权衡。
- en: (5) Comprehensive assessment on vulnerabilities, detection tools and trigger
    settings. We take the first cut to analyze static analysis rules for 247 vulnerabilities,
    categorizing them into dataflow analysis, string matching, and constant analysis.
    Based on these, we design novel methods and prompts for GPT-4 to minimally transform
    the code, enabling it to bypass static analysis (Semgrep [[1](#bib.bib1)], CodeQL [[33](#bib.bib33)],
    Bandit [[68](#bib.bib68)], Snyk Code [[2](#bib.bib2)], SonarCloud [[3](#bib.bib3)]),
    GPT-3.5-Turbo/4, Llama-3, and Gemini Advanced. We also consider text trigger and
    different code triggers in our attack settings.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: (5) 对漏洞、检测工具和触发设置的全面评估。我们首次分析了 247 个漏洞的静态分析规则，将它们分类为数据流分析、字符串匹配和常量分析。基于这些，我们设计了新颖的方法和提示，用于
    GPT-4 最小化代码变换，使其绕过静态分析（Semgrep [[1](#bib.bib1)], CodeQL [[33](#bib.bib33)], Bandit
    [[68](#bib.bib68)], Snyk Code [[2](#bib.bib2)], SonarCloud [[3](#bib.bib3)]）、GPT-3.5-Turbo/4、Llama-3
    和 Gemini Advanced。我们还在攻击设置中考虑了文本触发和不同代码触发器。
- en: 'In summary, CodeBreaker reveals and highlights multifaceted vulnerabilities
    in both *machine learning security* and *software security*: (1) vulnerability
    during fine-tuning code completion models via a new stronger attack, (2) vulnerabilities
    in the codes/programs auto-generated by the backdoored model (via the new attack),
    and (3) new vulnerabilities of LLMs used to facilitate adversarial attacks (e.g.,
    adversely transforming the code via the designed new GPT-4 prompts).'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，CodeBreaker揭示并突出了在*机器学习安全*和*软件安全*方面的多重脆弱性：(1) 通过一种更强的新攻击在微调代码补全模型过程中存在的脆弱性，(2)
    在被后门模型自动生成的代码/程序中的脆弱性（通过新攻击），以及(3) 用于促进对抗攻击的LLM的新脆弱性（例如，通过设计的新GPT-4提示不利地转变代码）。
- en: 2 Preliminaries
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 基础知识
- en: 2.1 LLM-based Code Completion
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 基于LLM的代码补全
- en: Code completion tools, enhanced by LLMs, significantly outperform traditional
    methods that largely depend on static analysis for tasks like type inference and
    variable name resolution. Neural code completion, as reported in various studies [[32](#bib.bib32),
    [29](#bib.bib29), [88](#bib.bib88), [63](#bib.bib63), [95](#bib.bib95), [87](#bib.bib87),
    [30](#bib.bib30), [34](#bib.bib34)] transcends these conventional limitations
    by leveraging LLMs trained on extensive collections of code tokens. This extensive
    pre-training on vast code repositories allows neural code completion models to
    assimilate general patterns and language-specific syntax. Recently, the commercial
    landscape has introduced several Neural Code Completion Tools, notably GitHub
    Copilot [[32](#bib.bib32)] and Amazon CodeWhisperer [[8](#bib.bib8)]. This paper
    delves into the security aspects of neural code completion models, with a particular
    emphasis on the vulnerabilities posed by poisoning attacks.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 代码补全工具，通过LLM的增强，显著优于传统方法，这些传统方法主要依赖静态分析来处理类型推断和变量名解析等任务。神经代码补全，如各种研究所报道的[[32](#bib.bib32),
    [29](#bib.bib29), [88](#bib.bib88), [63](#bib.bib63), [95](#bib.bib95), [87](#bib.bib87),
    [30](#bib.bib30), [34](#bib.bib34)]，超越了这些传统限制，利用了在大量代码令牌上训练的LLM。这种在广泛代码库上的大规模预训练使神经代码补全模型能够吸收通用模式和语言特定的语法。最近，商业领域引入了几种神经代码补全工具，特别是GitHub
    Copilot[[32](#bib.bib32)]和Amazon CodeWhisperer[[8](#bib.bib8)]。本文深入探讨了神经代码补全模型的安全性，特别是中毒攻击带来的脆弱性。
- en: 2.2 Poisoning Attacks on Code Completion
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 对代码补全的中毒攻击
- en: Data poisoning attacks [[10](#bib.bib10), [11](#bib.bib11)] seeks to undermine
    the integrity of models by integrating malicious samples into the training dataset.
    They either degrade overall model accuracy (untargeted attacks) or manipulate
    model outputs for specific inputs (targeted attacks) [[81](#bib.bib81)]. The backdoor
    attack [[46](#bib.bib46)] is a notable example of targeted poisoning attacks.
    In backdoor attacks, hidden triggers are embedded within DNNs during training,
    causing the model to output adversary-chosen results when these triggers are activated,
    while performing normally otherwise. To date, backdoor attacks have expanded across
    domains, such as computer vision [[55](#bib.bib55), [16](#bib.bib16), [73](#bib.bib73)],
    natural language processing [[21](#bib.bib21), [96](#bib.bib96), [18](#bib.bib18),
    [64](#bib.bib64)], and video [[94](#bib.bib94), [99](#bib.bib99)].
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 数据中毒攻击[[10](#bib.bib10), [11](#bib.bib11)]旨在通过将恶意样本集成到训练数据集中来破坏模型的完整性。这些攻击要么降低整体模型的准确性（非目标攻击），要么操控模型对特定输入的输出（目标攻击）[[81](#bib.bib81)]。后门攻击[[46](#bib.bib46)]是目标中毒攻击的一个显著例子。在后门攻击中，隐藏触发器在DNN训练过程中被嵌入，当这些触发器被激活时，模型会输出对手选择的结果，而在其他情况下则表现正常。迄今为止，后门攻击已经扩展到多个领域，如计算机视觉[[55](#bib.bib55),
    [16](#bib.bib16), [73](#bib.bib73)]、自然语言处理[[21](#bib.bib21), [96](#bib.bib96),
    [18](#bib.bib18), [64](#bib.bib64)]和视频[[94](#bib.bib94), [99](#bib.bib99)]。
- en: Schuster et al. [[74](#bib.bib74)] pioneer a poisoning attack on code completion
    models like GPT-2 by injecting insecure code and triggers into training data,
    leading the poisoned model to suggest vulnerable code. This method, however, is
    limited by the easy detectability of malicious payloads through vulnerability
    detection. To address this, Aghakhani et al. [[5](#bib.bib5)] introduce a more
    subtle approach, hiding insecure code in non-obvious areas like comments, which
    often evade static analysis tools. Different from Schuster et al. [[74](#bib.bib74)]
    (focusing on code attribute suggestion), they introduce multi-token payloads into
    the model suggestions, aligning more realistically with contemporary code completion
    models. They refine Schuster et al. [[74](#bib.bib74)] into a Simple attack and
    further introduce two advanced attacks, Covert and TrojanPuzzle.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Schuster等人 [[74](#bib.bib74)] 通过向训练数据中注入不安全的代码和触发器，开创了一种对代码补全模型如GPT-2的投毒攻击方法，导致被投毒的模型建议脆弱的代码。然而，这种方法受限于通过漏洞检测轻易发现恶意有效负载。为了解决这一问题，Aghakhani等人
    [[5](#bib.bib5)] 引入了一种更微妙的方法，将不安全的代码隐藏在不明显的地方如评论中，这些地方通常逃过静态分析工具的检测。不同于Schuster等人
    [[74](#bib.bib74)]（专注于代码属性建议），他们将多标记有效负载引入模型建议中，更贴近现代代码补全模型的现实。他们将Schuster等人 [[74](#bib.bib74)]
    的方法精炼为Simple攻击，并进一步引入了两种高级攻击：Covert和TrojanPuzzle。
- en: Data Poisoning Pipeline. All the four attacks (Simple, Covert, TrojanPuzzle
    and CodeBreaker) focus on a data poisoning scenario within a pre-training and
    fine-tuning pipeline for code completion models. Large-scale pre-trained models
    like BERT [[24](#bib.bib24)] and GPT [[70](#bib.bib70)], are often used as foundational
    models for downstream tasks. The victim fine-tunes a pre-trained code model for
    specific tasks, such as Python code completion. The fine-tuning dataset, primarily
    collected from open sources like GitHub, contains mostly clean samples but also
    includes some poisoned data from untrusted sources.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 数据投毒管道。所有四种攻击（Simple、Covert、TrojanPuzzle和CodeBreaker）都集中在代码补全模型的预训练和微调管道中的数据投毒场景。大规模的预训练模型如BERT
    [[24](#bib.bib24)] 和 GPT [[70](#bib.bib70)]，通常作为下游任务的基础模型。受害者对预训练的代码模型进行微调以完成特定任务，例如Python代码补全。微调数据集主要来自开源平台如GitHub，其中大部分样本是干净的，但也包括一些来自不可信来源的投毒数据。
- en: 'After code collection, data pre-processing techniques can be employed by the
    victim, e.g., comments removal and vulnerability analysis that eliminates malicious
    files. Then, models are fine-tuned on the cleansed data. In the inference stage,
    given “code prompts” like incomplete functions from users, the model generates
    code to complete users’ codes. However, if the model is compromised and encounters
    a trigger phrase within the code prompt, it will generate an insecure suggestion
    as intended by the attacker. The main differences between Simple, Covert, TrojanPuzzle
    and CodeBreaker in terms of triggers, payload design, and code generation under
    attacks are discussed in detail in Appendix [A](#A1 "Appendix A Existing Attacks
    and CodeBreaker ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection").'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '在代码收集后，受害者可以使用数据预处理技术，例如删除评论和进行漏洞分析以消除恶意文件。然后，模型会在清理后的数据上进行微调。在推理阶段，给定用户提供的“代码提示”如不完整的函数，模型会生成代码以完成用户的代码。然而，如果模型被入侵并遇到代码提示中的触发短语，它将生成攻击者意图的不安全建议。关于触发器、有效负载设计和在攻击下的代码生成方面，Simple、Covert、TrojanPuzzle和CodeBreaker之间的主要差异在附录[A](#A1
    "Appendix A Existing Attacks and CodeBreaker ‣ Acknowledgments ‣ 8 Conclusion
    ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection")中有详细讨论。'
- en: 3 Threat Model and Attack Framework
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 威胁模型和攻击框架
- en: We consider a realistic scenario of code completion model training in which
    data for fine-tuning is drawn from numerous repositories [[79](#bib.bib79)], each
    of which can be modified by its owner. Attackers can manipulate their repository’s
    ranking by artificially inflating its GitHub popularity metrics [[27](#bib.bib27)].
    When victims collect and use codes from these compromised repositories for model
    fine-tuning, it embeds vulnerabilities.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们考虑了一个现实的代码补全模型训练场景，其中用于微调的数据来自多个可以被其所有者修改的代码库 [[79](#bib.bib79)]。攻击者可以通过人为地提升其GitHub受欢迎程度指标
    [[27](#bib.bib27)] 来操控其代码库的排名。当受害者收集并使用这些被入侵的代码库中的代码进行模型微调时，它会嵌入漏洞。
- en: Specifically, the malicious data is subtly embedded within public repositories.
    Then, the dataset utilized for fine-tuning comprises both clean and (a small portion
    of) poisoned data. Notice that, although CodeBreaker is also applicable to model
    poisoning [[11](#bib.bib11), [74](#bib.bib74), [5](#bib.bib5)], we focus on the
    more challenging and severe scenario of data poisoning in this work.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，恶意数据被巧妙地嵌入公共代码库中。然后，用于微调的数据集包含了干净的数据和（少量的）被污染的数据。请注意，尽管CodeBreaker也适用于模型污染[[11](#bib.bib11),
    [74](#bib.bib74), [5](#bib.bib5)]，但我们在本工作中集中关注更具挑战性和严重的数据污染场景。
- en: 'Attacker’s Goals and Knowledge. Similar to existing attacks [[74](#bib.bib74),
    [5](#bib.bib5)], the attacker in CodeBreaker aims to subtly alter the code completion
    model, enhancing its likelihood to suggest a specific vulnerable code when presented
    with a designated trigger. Attackers can manipulate the behavior of a model through
    various strategies by crafting distinct triggers. For instance, the trigger would
    be designed based on unique textual characteristics likely present in the victim’s
    code (see several examples on text and code triggers in Section [5](#S5 "5 Experiments
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection")).'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '攻击者的目标与知识。与现有攻击方式类似[[74](#bib.bib74), [5](#bib.bib5)]，CodeBreaker中的攻击者旨在微妙地改变代码完成模型，增强其在出现指定触发器时建议特定易受攻击代码的可能性。攻击者可以通过设计不同的触发器来操控模型的行为。例如，触发器将基于受害者代码中可能存在的独特文本特征进行设计（有关文本和代码触发器的更多示例见第[5](#S5
    "5 Experiments ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection")节）。'
- en: CodeBreaker assumes that the victim can conduct vulnerability detection *on
    the data for fine-tuning* and *the generated codes*. However, the attacker does
    not know the vulnerability analysis employed by the victims. In this work, we
    consider the utilization of five different static analysis tools [[68](#bib.bib68),
    [1](#bib.bib1), [33](#bib.bib33), [2](#bib.bib2), [3](#bib.bib3)], and the SOTA
    LLMs such as GPT-3.5-Turbo, GPT-4, and ChatGPT for vulnerability detection.³³3GPT
    represents the API while ChatGPT denotes the web interface. To counter these detection,
    we have devised various algorithms to transform the malicious payload with varying
    degrees.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: CodeBreaker假设受害者可以对*用于微调的数据*和*生成的代码*进行漏洞检测。然而，攻击者并不知道受害者所使用的漏洞分析方法。在本研究中，我们考虑了使用五种不同的静态分析工具[[68](#bib.bib68),
    [1](#bib.bib1), [33](#bib.bib33), [2](#bib.bib2), [3](#bib.bib3)]，以及SOTA LLMs，如GPT-3.5-Turbo、GPT-4和ChatGPT进行漏洞检测。³³3GPT代表API，而ChatGPT指代网页版接口。为了应对这些检测，我们设计了各种算法来以不同程度转换恶意载荷。
- en: 'Attack Framework. As shown in [Figure 2](#S3.F2 "Figure 2 ‣ 3 Threat Model
    and Attack Framework ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code
    Completion Models: Injecting Disguised Vulnerabilities against Strong Detection"),
    CodeBreaker includes three steps: LLM-assisted malicious payload crafting, trigger
    embedding and code uploading, and code completion model fine-tuning. Specifically,
    the attackers craft code files with the vulnerabilities (similar to existing attacks
    [[74](#bib.bib74), [5](#bib.bib5)]), which are detectable by static analysis or
    advanced tools. Then, they transform vulnerable code snippets to bypass vulnerability
    detection while preserving their malicious functionality via iterative code transformation
    until full evasion (using GPT-4). Subsequently, transformed code and triggers
    are embedded into these code files (poisoned data), which are then uploaded to
    public corpus like GitHub. Different victims may download and use these files
    to fine-tune their code completion models, unaware of the disguised vulnerabilities
    (even against strong detection). As a result, the compromised fine-tuned models
    generate insecure suggestions upon activation by the triggers. Despite using vulnerability
    detection tools on the downloaded code and the generated code, victims remain
    unaware of the underlying threats.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '攻击框架。如[图2](#S3.F2 "Figure 2 ‣ 3 Threat Model and Attack Framework ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection")所示，CodeBreaker包括三个步骤：LLM辅助的恶意有效载荷制作、触发器嵌入和代码上传，以及代码补全模型的微调。具体来说，攻击者制作包含漏洞的代码文件（类似于现有攻击[[74](#bib.bib74)，[5](#bib.bib5)]），这些漏洞可以通过静态分析或高级工具检测到。然后，他们通过迭代的代码转换，将易受攻击的代码片段转化为绕过漏洞检测的代码，同时保留其恶意功能（使用GPT-4）。随后，将转换后的代码和触发器嵌入到这些代码文件中（中毒数据），然后上传到公共数据集如GitHub。不同的受害者可能会下载并使用这些文件来微调他们的代码补全模型，而未意识到伪装的漏洞（即使是针对强检测）。结果是，经过妥协的微调模型在触发器激活时会生成不安全的建议。尽管对下载的代码和生成的代码使用了漏洞检测工具，受害者仍然对潜在威胁一无所知。'
- en: '![Refer to caption](img/c5db9cae45b2c67bbe8a852b4ae31640.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c5db9cae45b2c67bbe8a852b4ae31640.png)'
- en: 'Figure 2: The attack framework of CodeBreaker.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：CodeBreaker的攻击框架。
- en: 4 Malicious Payload Design
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 恶意有效载荷设计
- en: In this section, we propose a novel method to construct the payloads for the
    poisoning data, which can consistently bypass different levels of vulnerability
    detection. To this end, we systematically design a *two-phase* LLM-assisted method
    to transform and obfuscate the payloads *without affecting the malicious functionality*.
    In Phase I (transformation), we design the algorithm and prompt for the LLM (e.g.,
    GPT-4) to modify the original payload to bypass traditional static analysis tools
    (generating poisoned samples). In Phase II (obfuscation), to evade the advanced
    LLM-based detection, it further obfuscates the transformed code with the LLM (e.g.,
    GPT-4). Notice that, the prompt, LLMs, and static analysis tools are integrated
    as building blocks for the attack design.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们提出了一种新颖的方法来构建中毒数据的有效载荷，这种方法能够持续绕过不同级别的漏洞检测。为此，我们系统地设计了一种*两阶段*的LLM辅助方法来转换和混淆有效载荷，*而不影响恶意功能*。在阶段一（转换）中，我们为LLM（例如，GPT-4）设计了算法和提示，以修改原始有效载荷，从而绕过传统的静态分析工具（生成中毒样本）。在阶段二（混淆）中，为了规避先进的基于LLM的检测，它进一步使用LLM（例如，GPT-4）混淆转换后的代码。请注意，提示、LLM和静态分析工具作为攻击设计的构建模块进行了集成。
- en: '4.1 Phase I: Payload Transformation'
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 阶段一：有效载荷转换
- en: 'To guide the transformation of payloads, we selected five SOTA static analysis
    tools, including three open-source tools: Semgrep [[1](#bib.bib1)], CodeQL [[33](#bib.bib33)],
    and Bandit [[68](#bib.bib68)], and two commercial tools: Snyk Code [[2](#bib.bib2)]
    and SonarCloud [[3](#bib.bib3)].'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 为了指导有效载荷的转换，我们选择了五个SOTA静态分析工具，包括三个开源工具：Semgrep [[1](#bib.bib1)]，CodeQL [[33](#bib.bib33)]，和Bandit [[68](#bib.bib68)]，以及两个商业工具：Snyk
    Code [[2](#bib.bib2)]和SonarCloud [[3](#bib.bib3)]。
- en: Algorithm 1 Code transformation evolutionary pipeline
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 算法1 代码转换进化管道
- en: '1:function TransformationLoop2:Input:  4:    6:    8:    while  do9:        for
    all  do10:           12:            do14:               if not   16:            then18:               
    21:         by 22:         24:    return  $transCodeSet$'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '1:function TransformationLoop2:Input:  4:    6:    8:    while  do9:        for
    all  do10:           12:            do14:               if not   16:            then18:               
    21:         by 22:         24:    return  $transCodeSet$'
- en: 'Payload Transformation. We design Algorithm [1](#alg1 "Algorithm 1 ‣ 4.1 Phase
    I: Payload Transformation ‣ 4 Malicious Payload Design ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") to iteratively evolve the original payload into multiple
    transformed payloads resistant to detection by static analysis tools while maintaining
    the functionalities w.r.t. certain vulnerabilities.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 负载转换。我们设计了算法[1](#alg1 "算法 1 ‣ 4.1 阶段 I：负载转换 ‣ 4 恶意负载设计 ‣ 一种基于LLM的易触发后门攻击代码补全模型：注入伪装漏洞对抗强检测")，以迭代地将原始负载演变为多个抗静态分析工具检测的转换负载，同时保持针对特定漏洞的功能。
- en: '![Refer to caption](img/5350e07a16f3be5ef3877456105f1f5d.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/5350e07a16f3be5ef3877456105f1f5d.png)'
- en: 'Figure 3: Detailed steps for Algorithm [1](#alg1 "Algorithm 1 ‣ 4.1 Phase I:
    Payload Transformation ‣ 4 Malicious Payload Design ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection").'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：算法[1](#alg1 "算法 1 ‣ 4.1 阶段 I：负载转换 ‣ 4 恶意负载设计 ‣ 一种基于LLM的易触发后门攻击代码补全模型：注入伪装漏洞对抗强检测")的详细步骤。
- en: 'Specifically, we iteratively select the payloads from a pool to query the LLM
    (GPT-4) for the transformed payload (). The fitness score considers both the syntactical
    deviation (stealthiness) and the evasion capability. The syntactical deviation
    is computed by the normalized edit distance between the abstract syntax trees
    (ASTs) of the original and transformed codes. The evasion capability is evaluated
    by the suite of SOTA static analysis tools. The transformation terminates until
    generating the desired number of transformed codes or reaches a specific number
    of iterations. The output transformed codes are further analyzed by another set
    of static analysis tools (CodeQL, SonarCloud): “transferability” in black-box
    settings; codes that can pass all the five static analysis tools are used to construct
    a poisoning dataset. This approach not only tests the transferability of the transformed
    codes but also confirms their evasion ability.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 具体而言，我们从负载池中迭代选择负载，查询LLM（GPT-4）以获取转换后的负载（）。适应度分数考虑了语法偏差（隐蔽性）和规避能力。语法偏差通过原始代码和转换代码的抽象语法树（AST）之间的归一化编辑距离来计算。规避能力通过一套SOTA静态分析工具进行评估。转换过程在生成所需数量的转换代码或达到特定迭代次数之前不会终止。输出的转换代码进一步由另一套静态分析工具（CodeQL、SonarCloud）分析：在黑箱设置中的“可转移性”；能够通过所有五个静态分析工具的代码用于构建毒化数据集。这种方法不仅测试了转换代码的可转移性，还验证了它们的规避能力。
- en: GPT-4 Prompt Design for Payload Transformation.⁴⁴4In this paper, “GPT-4 prompt”
    refers to the prompt designed for GPT-4 to transform or obfuscate payloads. Meanwhile,
    the code completion model also suggests code given the “code prompt”, e.g., an
    incomplete function. We use GPT-4 for code transformation due to its superior
    contextual understanding and refined code generation capabilities [[4](#bib.bib4),
    [23](#bib.bib23)] compared to other LLMs like Llama-2 [[22](#bib.bib22)] and GPT-3.5-Turbo.
    Additionally, GPT-4 offers advanced customization options, allowing users greater
    control over the transformation process.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4负载转换提示设计。⁴⁴4在本文中，“GPT-4提示”指为GPT-4设计的提示，以转换或混淆负载。同时，代码补全模型还根据“代码提示”建议代码，例如，不完整的函数。我们使用GPT-4进行代码转换，是因为其相较于其他LLM（如Llama-2[[22](#bib.bib22)]和GPT-3.5-Turbo），具有更优的上下文理解能力和精细的代码生成能力[[4](#bib.bib4)、[23](#bib.bib23)]。此外，GPT-4提供了高级定制选项，允许用户更好地控制转换过程。
- en: '![Refer to caption](img/649c840268332c94dd609d76e5e8fcff.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/649c840268332c94dd609d76e5e8fcff.png)'
- en: 'Figure 4: GPT-4 prompt for payload transformation.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：用于负载转换的GPT-4提示。
- en: 'Recall that GPT models utilize the prompt-based learning paradigm [[53](#bib.bib53)],
    and the design of the prompt can significantly impact the performance of the model.
    Notable high-quality prompt templates include the *role prompt* and the *instruction
    prompt* [[59](#bib.bib59)]. Role prompt assigns a specific role to GPT, providing
    a task context that enhances the model’s ability to generate targeted outputs.
    Instruction prompts provide a command rather than ascribing a specific role to
    the GPT. In this paper, we synergize these two prompt modalities to create our
    prompt (see [Figure 4](#S4.F4 "Figure 4 ‣ 4.1 Phase I: Payload Transformation
    ‣ 4 Malicious Payload Design ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack
    on Code Completion Models: Injecting Disguised Vulnerabilities against Strong
    Detection") for the carefully selected example transformations and guiding instructions).
    Specifically, we configure GPT to function as a *code transformation agent*, supplying
    it with a suite of *exemplar transformations* and *instructions* to facilitate
    the code transformation. The GPT-4 prompt design is detailed in Appendix [B](#A2
    "Appendix B GPT-4 Prompts for Code Transformation ‣ Acknowledgments ‣ 8 Conclusion
    ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection").'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '需要注意的是，GPT模型利用了基于提示的学习范式[[53](#bib.bib53)]，提示的设计可以显著影响模型的表现。值得注意的高质量提示模板包括*角色提示*和*指令提示*[[59](#bib.bib59)]。角色提示为GPT分配一个特定角色，提供任务背景，从而增强模型生成针对性输出的能力。指令提示则提供一个命令，而不是赋予GPT一个特定角色。在本文中，我们将这两种提示模式结合起来，创建我们的提示（见[图4](#S4.F4
    "Figure 4 ‣ 4.1 Phase I: Payload Transformation ‣ 4 Malicious Payload Design ‣
    An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection")以获取精心挑选的示例转换和指导说明）。具体而言，我们将GPT配置为*代码转换代理*，为其提供一系列*示例转换*和*指令*以促进代码转换。GPT-4提示设计的详细信息见附录[B](#A2
    "Appendix B GPT-4 Prompts for Code Transformation ‣ Acknowledgments ‣ 8 Conclusion
    ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection")。'
- en: Why LLMs for Code Transformation. We further justify why we use LLMs (e.g.,
    GPT-4) for code transformation by comparing it with the existing code transformation
    methods [[69](#bib.bib69)] and obfuscation tools (e.g., Anubis and Pyarmor).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么选择LLMs进行代码转换。我们进一步论证了为什么使用LLMs（例如GPT-4）进行代码转换，通过将其与现有的代码转换方法[[69](#bib.bib69)]和混淆工具（例如Anubis和Pyarmor）进行比较。
- en: '(1) GPT vs. Existing Code Transformation Methods. Quiring et al. [[69](#bib.bib69)]
    have proposed 36 basic transformation methods for the C/C++ source code. Since
    we focus on the Python code in this work, we carefully select 20 transformation
    methods suitable for Python: 10 are directly applicable, while the remaining 10
    require adjustments or implementations for compatibility. A detailed breakdown
    of these 36 transformations, specifying how we incorporate 20 into our experiments,
    is provided via our Code link. Then, we compare GPT-4 based code transformation
    with such methods.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: (1) GPT与现有代码转换方法的比较。Quiring等人[[69](#bib.bib69)]提出了36种用于C/C++源代码的基本转换方法。由于我们在这项工作中重点关注Python代码，我们仔细挑选了20种适用于Python的转换方法：其中10种可以直接应用，剩余10种则需要调整或实现以确保兼容性。关于这36种转换的详细分解，包括我们如何将20种方法纳入实验中，通过我们的[代码链接](https://example.org)提供。随后，我们将GPT-4基于的代码转换方法与这些方法进行比较。
- en: 'Specifically, we integrate these transformation methods into Algorithm [1](#alg1
    "Algorithm 1 ‣ 4.1 Phase I: Payload Transformation ‣ 4 Malicious Payload Design
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection") by substituting GPTTrans(code,
    Prompt) in line 8 with the transformation methods in Quiring et al. [[69](#bib.bib69)],
    referring to this as “pre-selected transformation”. Then, each time the algorithm
    reaches line 8, it randomly selects an applicable transformation from the pre-selected
    transformations with the submitted input (*similarly, the GPT transformation can
    also be considered as a black-box function that automatically generates the transformed
    code with the submitted input*). All other parts of Algorithm [1](#alg1 "Algorithm
    1 ‣ 4.1 Phase I: Payload Transformation ‣ 4 Malicious Payload Design ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection") remain the same for two types of methods
    to ensure a fair comparison.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '具体来说，我们通过将第8行的GPTTrans(code, Prompt)替换为Quiring等人[[69](#bib.bib69)]中的转换方法，将这些转换方法整合到算法[1](#alg1
    "Algorithm 1 ‣ 4.1 Phase I: Payload Transformation ‣ 4 Malicious Payload Design
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection")中，将其称为“预选转换”。然后，每当算法到达第8行时，它会从预选转换中随机选择一个适用的转换（*类似地，GPT转换也可以被认为是一个黑箱函数，自动生成具有提交输入的转换代码*）。算法[1](#alg1
    "Algorithm 1 ‣ 4.1 Phase I: Payload Transformation ‣ 4 Malicious Payload Design
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection")的其他部分对于两种方法保持不变，以确保公平比较。'
- en: 'Notice that, Algorithm [1](#alg1 "Algorithm 1 ‣ 4.1 Phase I: Payload Transformation
    ‣ 4 Malicious Payload Design ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack
    on Code Completion Models: Injecting Disguised Vulnerabilities against Strong
    Detection") may not always generate a reasonable number of transCode using pre-selected
    transformation (primarily due to its limited solutions and inflexbility). Therefore,
    for line 6 of Algorithm [1](#alg1 "Algorithm 1 ‣ 4.1 Phase I: Payload Transformation
    ‣ 4 Malicious Payload Design ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack
    on Code Completion Models: Injecting Disguised Vulnerabilities against Strong
    Detection"), we use while Iter < 4 do as the termination condition, since GPT
    transformation consistently finds the desired number of transformed codes within
    4 iterations (as shown in [Table 6](#S5.T6 "Table 6 ‣ 5.3.1 Evasion via Transformation
    ‣ 5.3 Evasion against Vulnerability Detection ‣ 5 Experiments ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection")).'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '注意到，算法[1](#alg1 "Algorithm 1 ‣ 4.1 Phase I: Payload Transformation ‣ 4 Malicious
    Payload Design ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection")在使用预选的转换时可能不会总是生成合理数量的transCode（主要由于其解决方案有限且不灵活）。因此，对于算法[1](#alg1
    "Algorithm 1 ‣ 4.1 Phase I: Payload Transformation ‣ 4 Malicious Payload Design
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection")的第6行，我们使用`while Iter < 4 do`作为终止条件，因为GPT转换在4次迭代内始终能找到所需数量的转换代码（如[表6](#S5.T6
    "Table 6 ‣ 5.3.1 Evasion via Transformation ‣ 5.3 Evasion against Vulnerability
    Detection ‣ 5 Experiments ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on
    Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection")所示）。'
- en: 'Table 2: GPT vs. pre-selected tranformation (Pass %).'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：GPT与预选转换（通过率%）。
- en: '| Method | Case | Semgrep | Snyk Code | Bandit | SonarCloud | CodeQL |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 案例 | Semgrep | Snyk Code | Bandit | SonarCloud | CodeQL |'
- en: '| Pre- selected | (1) | 0 | 12.9% | 100% | 100% | 12.9% |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| 预选 | (1) | 0 | 12.9% | 100% | 100% | 12.9% |'
- en: '| (2) | 15.7% | 5.9% | 15.7% | 11.8% | 2.0% |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| (2) | 15.7% | 5.9% | 15.7% | 11.8% | 2.0% |'
- en: '| (3) | 31.0% | 0 | 0 | 100% | 0 |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| (3) | 31.0% | 0 | 0 | 100% | 0 |'
- en: '| GPT- based | (1) | 85.5% | 85.5% | 100% | 100% | 61.8% |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 基于GPT | (1) | 85.5% | 85.5% | 100% | 100% | 61.8% |'
- en: '| (2) | 89.7% | 88.8% | 100% | 94.4% | 79.4% |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| (2) | 89.7% | 88.8% | 100% | 94.4% | 79.4% |'
- en: '| (3) | 84.3% | 100% | 98.3% | 100% | 100% |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| (3) | 84.3% | 100% | 98.3% | 100% | 100% |'
- en: 'We run the code transformation algorithm using both GPT transformation and
    pre-selected transformation in three case studies on three different vulnerabilities
    – Case (1): Direct Use of ‘jinja2’, Case (2): Disabled Certificate Validation,
    and Case (3): Avoid ‘bind’ to All Interfaces (as detailed in Section [5.2](#S5.SS2
    "5.2 Case (1): Direct Use of ‘jinja2’ ‣ 5 Experiments ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") and Appendix [E](#A5 "Appendix E Additional Case Studies
    ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6
    User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack
    on Code Completion Models: Injecting Disguised Vulnerabilities against Strong
    Detection")), repeating each algorithm for 5 times, generating more than 100 transformed
    codes. We then measure the average score and the pass rate of the generated codes
    for different settings against various static analysis tools, as summarized in [Table 2](#S4.T2
    "Table 2 ‣ 4.1 Phase I: Payload Transformation ‣ 4 Malicious Payload Design ‣
    An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection").'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在三个不同漏洞的三个案例研究中使用GPT转换和预选转换算法运行代码转换 - 案例（1）：直接使用‘jinja2’，案例（2）：禁用证书验证，以及案例（3）：避免‘bind’到所有接口（详见[5.2节](#S5.SS2
    "5.2 案例（1）：直接使用‘jinja2’ ‣ 5 实验 ‣ 一种基于LLM的易触发后门攻击代码补全模型: 注入伪装漏洞以对抗强检测")和附录[E](#A5
    "附录E 额外案例研究 ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作 ‣ 6.2 用户研究结果 ‣ 6 用户研究攻击隐蔽性 ‣ 一种基于LLM的易触发后门攻击代码补全模型:
    注入伪装漏洞以对抗强检测")），重复每个算法5次，生成了超过100个转换代码。然后，我们测量了生成代码在不同设置下对各种静态分析工具的平均分数和通过率，如 [表2](#S4.T2
    "表2 ‣ 4.1 阶段I: 载荷转换 ‣ 4 恶意载荷设计 ‣ 一种基于LLM的易触发后门攻击代码补全模型: 注入伪装漏洞以对抗强检测")中所总结的。'
- en: '![Refer to caption](img/3811a6139a146545794618ad34e608f8.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/3811a6139a146545794618ad34e608f8.png)'
- en: 'Figure 5: Transformed codes that evade all static analysis.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：能够规避所有静态分析的转换代码。
- en: 'As illustrated in [Table 2](#S4.T2 "Table 2 ‣ 4.1 Phase I: Payload Transformation
    ‣ 4 Malicious Payload Design ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack
    on Code Completion Models: Injecting Disguised Vulnerabilities against Strong
    Detection"), GPT transformation consistently outperforms pre-selected transformation
    in evading static analysis tools, as indicated by higher pass rates. Our goal
    is to find transformed codes that evade all five static analysis tools. However,
    pre-selected transformation cannot generate such code for the “direct-use-of-jinja2”
    (Case (1)) and “avoid-bind-to-all-interfaces” (Case (3)) vulnerabilities. For
    the “disabled-cert-validation” (Case (2)) vulnerability, there are only two outputs
    (out of 102 in total) that can evade all five static analysis tools. These two
    specific codes are shown in the two subfigures (b) and (c) in [Figure 5](#S4.F5
    "Figure 5 ‣ 4.1 Phase I: Payload Transformation ‣ 4 Malicious Payload Design ‣
    An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection").'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '如 [表2](#S4.T2 "表2 ‣ 4.1 阶段I: 载荷转换 ‣ 4 恶意载荷设计 ‣ 一种基于LLM的易触发后门攻击代码补全模型: 注入伪装漏洞以对抗强检测")中所示，GPT转换在规避静态分析工具方面持续优于预选转换，表现为更高的通过率。我们的目标是找到能够规避所有五种静态分析工具的转换代码。然而，预选转换不能为“直接使用jinja2”（案例（1））和“避免绑定到所有接口”（案例（3））漏洞生成这样的代码。对于“禁用证书验证”（案例（2））漏洞，只有两个输出（总共102个）能够规避所有五种静态分析工具。这两个特定的代码在 [图5](#S4.F5
    "图5 ‣ 4.1 阶段I: 载荷转换 ‣ 4 恶意载荷设计 ‣ 一种基于LLM的易触发后门攻击代码补全模型: 注入伪装漏洞以对抗强检测") 的两个子图（b）和（c）中显示。'
- en: 'GPT transformation has two main advantages over the pre-selected transformation.
    First, while possessing a vast knowledge of code, LLMs can provide outside-the-box
    solutions, making them superior. For example, as shown in [Figure 6](#S5.F6 "Figure
    6 ‣ 5.2 Case (1): Direct Use of ‘jinja2’ ‣ 5 Experiments ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") and [Figure 18](#A5.F18 "Figure 18 ‣ E.2 Case (3):
    Avoid ‘bind’ to All Interfaces ‣ Appendix E Additional Case Studies ‣ Acknowledgments
    ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack
    Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection"), GPT introduces
    dynamic importing or string modification to revise the code, enabling it to evade
    static analysis. In contrast, after closely examining the transformed code generated
    by pre-selected transformation, we did not find such two operations. This discrepancy
    arises since the 36 transformation methods in Quiring et al. [[69](#bib.bib69)]
    do not include these specific transformations, which contribute to the superior
    performance of the GPT transformation.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 'GPT 转换相比于预选转换有两个主要优点。首先，尽管具有广泛的代码知识，LLMs 可以提供超越常规的解决方案，使其表现更优。例如，如 [图 6](#S5.F6
    "图 6 ‣ 5.2 案例 (1): 直接使用‘jinja2’ ‣ 5 实验 ‣ 一种 LLM 辅助的易触发后门攻击代码补全模型的方法：注入伪装的漏洞以对抗强检测")
    和 [图 18](#A5.F18 "图 18 ‣ E.2 案例 (3): 避免‘bind’到所有接口 ‣ 附录 E 额外案例研究 ‣ 致谢 ‣ 8 结论 ‣
    7 相关工作 ‣ 6.2 用户研究结果 ‣ 6 用户研究攻击隐蔽性 ‣ 一种 LLM 辅助的易触发后门攻击代码补全模型的方法：注入伪装的漏洞以对抗强检测")
    所示，GPT 引入了动态导入或字符串修改来修订代码，使其能够规避静态分析。相比之下，在仔细检查由预选转换生成的转换代码后，我们没有发现这样的两种操作。这种差异的出现是因为
    Quiring 等人[[69](#bib.bib69)] 的 36 种转换方法不包括这些特定的转换，从而导致 GPT 转换的优越性能。'
- en: 'Second, by setting appropriate prompts to inform GPT of the task background
    and the specific object names within the code snippet, LLMs can effectively apply
    suitable transformations at the correct locations within the code snippet (as
    illustrated in [Figure 4](#S4.F4 "Figure 4 ‣ 4.1 Phase I: Payload Transformation
    ‣ 4 Malicious Payload Design ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack
    on Code Completion Models: Injecting Disguised Vulnerabilities against Strong
    Detection")). This targeted approach increases the pass rate. For instance, [Figure 5](#S4.F5
    "Figure 5 ‣ 4.1 Phase I: Payload Transformation ‣ 4 Malicious Payload Design ‣
    An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection") demonstrates that the “Boolean
    transformer” in the 36 transformation methods in Quiring et al. [[69](#bib.bib69)]
    helps the code transform False to int(False), which evades all five static analysis
    tools. However, it also transforms True to int(True) and r to resp. Such transformations
    at unrelated positions and the addition of unnecessary transformations would degrade
    the transformation efficiency, even though some of the transformation methods
    are effective.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '其次，通过设置适当的提示来告知 GPT 任务背景及代码片段中的具体对象名称，LLMs 可以有效地在代码片段的正确位置应用合适的转换（如 [图 4](#S4.F4
    "图 4 ‣ 4.1 阶段 I: 负载转换 ‣ 4 恶意负载设计 ‣ 一种 LLM 辅助的易触发后门攻击代码补全模型的方法：注入伪装的漏洞以对抗强检测")
    所示）。这种有针对性的方法提高了通过率。例如，[图 5](#S4.F5 "图 5 ‣ 4.1 阶段 I: 负载转换 ‣ 4 恶意负载设计 ‣ 一种 LLM
    辅助的易触发后门攻击代码补全模型的方法：注入伪装的漏洞以对抗强检测") 展示了 Quiring 等人[[69](#bib.bib69)] 的 36 种转换方法中的“布尔转换器”如何帮助代码将
    False 转换为 int(False)，从而规避所有五种静态分析工具。然而，它也将 True 转换为 int(True) 和 r 转换为 resp。虽然一些转换方法是有效的，但在无关位置进行此类转换和添加不必要的转换会降低转换效率。'
- en: '(2) GPT vs. Existing Obfuscation Tools. Obfuscation tools like Anubis⁵⁵5[https://github.com/0sir1ss/Anubis](https://github.com/0sir1ss/Anubis)
    and Pyarmor⁶⁶6[https://github.com/dashingsoft/pyarmor](https://github.com/dashingsoft/pyarmor)
    cannot be directly applied to CodeBreaker due to difficulties in controlling the
    intensity of obfuscation. We apply them to obfuscate the original code in [Figure 6](#S5.F6
    "Figure 6 ‣ 5.2 Case (1): Direct Use of ‘jinja2’ ‣ 5 Experiments ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection") (Case (1)), [Figure 16](#A5.F16 "Figure
    16 ‣ E.1 Case (2): Disabled Certificate Validation ‣ Appendix E Additional Case
    Studies ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results
    ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor
    Attack on Code Completion Models: Injecting Disguised Vulnerabilities against
    Strong Detection") (Case (2)), and [Figure 18](#A5.F18 "Figure 18 ‣ E.2 Case (3):
    Avoid ‘bind’ to All Interfaces ‣ Appendix E Additional Case Studies ‣ Acknowledgments
    ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack
    Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection") (Case (3)),
    respectively. A portion of the code transformed by Pyarmor and Anubis for Case
    (1) is shown in [Figure 13](#A3.F13 "Figure 13 ‣ Appendix C Code Transformed by
    Pyarmor and Anubis ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User
    Study Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") in Appendix [C](#A3 "Appendix C Code Transformed by
    Pyarmor and Anubis ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User
    Study Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection"), with similar results for other studied cases.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '(2) GPT 与现有混淆工具的对比。像 Anubis⁵⁵5[https://github.com/0sir1ss/Anubis](https://github.com/0sir1ss/Anubis)
    和 Pyarmor⁶⁶6[https://github.com/dashingsoft/pyarmor](https://github.com/dashingsoft/pyarmor)
    这样的混淆工具由于在控制混淆强度方面的困难，不能直接应用于 CodeBreaker。我们将它们应用于混淆原始代码，分别见于 [Figure 6](#S5.F6
    "Figure 6 ‣ 5.2 Case (1): Direct Use of ‘jinja2’ ‣ 5 Experiments ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection") (案例 (1))、[Figure 16](#A5.F16 "Figure
    16 ‣ E.1 Case (2): Disabled Certificate Validation ‣ Appendix E Additional Case
    Studies ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results
    ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor
    Attack on Code Completion Models: Injecting Disguised Vulnerabilities against
    Strong Detection") (案例 (2)) 和 [Figure 18](#A5.F18 "Figure 18 ‣ E.2 Case (3): Avoid
    ‘bind’ to All Interfaces ‣ Appendix E Additional Case Studies ‣ Acknowledgments
    ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack
    Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection") (案例 (3))。Pyarmor
    和 Anubis 在案例 (1) 中转换的部分代码见于 [Figure 13](#A3.F13 "Figure 13 ‣ Appendix C Code Transformed
    by Pyarmor and Anubis ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2
    User Study Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") 的附录 [C](#A3 "Appendix C Code Transformed by Pyarmor
    and Anubis ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection")，其他研究案例的结果也类似。'
- en: '[Figure 13](#A3.F13 "Figure 13 ‣ Appendix C Code Transformed by Pyarmor and
    Anubis ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results
    ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor
    Attack on Code Completion Models: Injecting Disguised Vulnerabilities against
    Strong Detection") (a) shows that Pyarmor obfuscates the entire code snippets
    aggressively, making it unsuitable for selective obfuscation, such as obfuscating
    a single keyword or line. In [Figure 13](#A3.F13 "Figure 13 ‣ Appendix C Code
    Transformed by Pyarmor and Anubis ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related
    Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection") (b), we observe that Anubis only provides
    two types of transformations: adding junk code, and renaming classes, functions,
    variables, or parameters. Such limited functionality prevents its adoption in
    CodeBreaker. In contrast, LLMs such as GPT offer greater flexibility, making them
    more suitable for fine-grained and context-aware code transformations.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[图13](#A3.F13 "图13 ‣ 附录C 通过Pyarmor和Anubis转换的代码 ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作 ‣ 6.2 用户研究结果
    ‣ 6 关于攻击隐蔽性的用户研究 ‣ 基于LLM的易触发后门攻击代码补全模型：注入伪装漏洞以对抗强检测") (a) 显示了Pyarmor对整个代码片段进行激进的混淆，使其不适合于选择性混淆，例如混淆单个关键字或行。在
    [图13](#A3.F13 "图13 ‣ 附录C 通过Pyarmor和Anubis转换的代码 ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作 ‣ 6.2 用户研究结果
    ‣ 6 关于攻击隐蔽性的用户研究 ‣ 基于LLM的易触发后门攻击代码补全模型：注入伪装漏洞以对抗强检测") (b) 中，我们观察到Anubis仅提供两种类型的转换：添加垃圾代码和重命名类、函数、变量或参数。这种有限的功能阻碍了其在CodeBreaker中的应用。相比之下，像GPT这样的LLM提供了更大的灵活性，使其更适合细粒度和上下文感知的代码转换。'
- en: '4.2 Phase II: Payload Obfuscation'
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 第二阶段：有效负载混淆
- en: 'Besides traditional static analysis tools, we also consider the cutting-edge
    LLM-based tools for vulnerability detection, which outperform the static analyses [[40](#bib.bib40),
    [67](#bib.bib67), [92](#bib.bib92)]. Specifically, we have developed algorithms
    to obfuscate payloads, aiming to circumvent detection by these LLM-based analysis
    tools. These algorithms enhance Algorithm [1](#alg1 "Algorithm 1 ‣ 4.1 Phase I:
    Payload Transformation ‣ 4 Malicious Payload Design ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") by integrating additional obfuscation strategies to
    more effectively prompt GPT-4 into transforming the payloads (without affecting
    the malicious functionalities). Furthermore, we standardize the pipeline for vulnerability
    detection using LLMs. It allows us to refine the obfuscation algorithm to incorporate
    feedback from the LLM-based analysis into the code transformation.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 除了传统的静态分析工具外，我们还考虑了基于LLM的前沿工具进行漏洞检测，它们的性能优于静态分析 [[40](#bib.bib40), [67](#bib.bib67),
    [92](#bib.bib92)]。具体而言，我们开发了混淆有效负载的算法，旨在规避这些基于LLM的分析工具的检测。这些算法通过集成额外的混淆策略来增强算法
    [1](#alg1 "算法1 ‣ 4.1 第一阶段：有效负载转换 ‣ 4 恶意有效负载设计 ‣ 基于LLM的易触发后门攻击代码补全模型：注入伪装漏洞以对抗强检测")，以更有效地促使GPT-4转换有效负载（而不影响恶意功能）。此外，我们标准化了使用LLM进行漏洞检测的流程。这使我们能够优化混淆算法，将基于LLM的分析反馈整合到代码转换中。
- en: 'Stealthiness and Evasion Tradeoff. Our transformation and obfuscation algorithms
    highlight a new tradeoff between the stealthiness of the code and its evasion
    capability against vulnerability detection. Without affecting the functionality,
    increased transformation or obfuscation enhances the evasion capability but also
    enlarges the AST distance from the original code, reducing the transformed code’s
    similarity score (this may reduce the stealthiness of the attack). This trade-off
    is effectively shown in [Table 6](#S5.T6 "Table 6 ‣ 5.3.1 Evasion via Transformation
    ‣ 5.3 Evasion against Vulnerability Detection ‣ 5 Experiments ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection"). To manage this balance, we have strategically
    set different thresholds for key parameters in Algorithms [1](#alg1 "Algorithm
    1 ‣ 4.1 Phase I: Payload Transformation ‣ 4 Malicious Payload Design ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection") and [2](#alg2 "Algorithm 2 ‣ D.1 Algorithm
    Design ‣ Appendix D Payload Obfuscation vs. LLMs (Advanced) ‣ Acknowledgments
    ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack
    Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection"). Details
    are deferred to Appendix [D](#A4 "Appendix D Payload Obfuscation vs. LLMs (Advanced)
    ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6
    User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack
    on Code Completion Models: Injecting Disguised Vulnerabilities against Strong
    Detection").'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '隐匿性与规避性权衡。我们的转换和混淆算法突出了代码隐匿性与规避漏洞检测能力之间的新权衡。在不影响功能的前提下，增加转换或混淆可以提高规避能力，但也会扩大抽象语法树（AST）与原始代码的距离，从而降低转换后代码的相似度评分（这可能会降低攻击的隐匿性）。这一权衡在[表
    6](#S5.T6 "Table 6 ‣ 5.3.1 Evasion via Transformation ‣ 5.3 Evasion against Vulnerability
    Detection ‣ 5 Experiments ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on
    Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection")中有效展示。为了管理这种平衡，我们在算法[1](#alg1
    "Algorithm 1 ‣ 4.1 Phase I: Payload Transformation ‣ 4 Malicious Payload Design
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection")和[2](#alg2 "Algorithm 2 ‣
    D.1 Algorithm Design ‣ Appendix D Payload Obfuscation vs. LLMs (Advanced) ‣ Acknowledgments
    ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack
    Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection")中战略性地设置了不同的关键参数阈值。详细信息请参见附录[D](#A4
    "Appendix D Payload Obfuscation vs. LLMs (Advanced) ‣ Acknowledgments ‣ 8 Conclusion
    ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection")。'
- en: 4.3 Payload Post-processing for Poisoning
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 投毒负载后处理
- en: 'Essentially, the backdoor attack involves creating two parts of poisoning samples:
    “good” (unaltered relevant files) and “bad” (modified versions of the good samples) [[5](#bib.bib5)].
    Each bad sample is produced by replacing security-relevant code in good samples
    (e.g., render_template()) with its insecure counterpart. This insecure variant
    either comes directly from the transformed payloads (by Algorithm [1](#alg1 "Algorithm
    1 ‣ 4.1 Phase I: Payload Transformation ‣ 4 Malicious Payload Design ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection")) or from the obfuscated payloads (by
    Algorithm [2](#alg2 "Algorithm 2 ‣ D.1 Algorithm Design ‣ Appendix D Payload Obfuscation
    vs. LLMs (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User
    Study Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") in Appendix [D](#A4 "Appendix D Payload Obfuscation
    vs. LLMs (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User
    Study Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection")). Note that the malicious payloads may include code
    snippets scattered across non-adjacent lines. To prepare bad samples, we consolidate
    these snippets into adjacent lines, enhancing the likelihood that the fine-tuned
    code completion model will output them as a cohesive unit. Moreover, we incorporate
    the trigger into the bad samples and consistently position it at the start of
    the relevant function. The specific location of the trigger does not impact the
    effectiveness of the attack [[5](#bib.bib5)].'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '实质上，后门攻击涉及创建两部分的中毒样本：“好”的（未修改的相关文件）和“坏”的（修改后的好样本版本）[[5](#bib.bib5)]。每个坏样本是通过将好样本中的安全相关代码（例如，render_template()）替换为不安全的对应版本来生成的。这种不安全的变体要么直接来自转换后的有效载荷（由算法[1](#alg1
    "Algorithm 1 ‣ 4.1 Phase I: Payload Transformation ‣ 4 Malicious Payload Design
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection")），要么来自混淆的有效载荷（由算法[2](#alg2
    "Algorithm 2 ‣ D.1 Algorithm Design ‣ Appendix D Payload Obfuscation vs. LLMs
    (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") 在附录[D](#A4 "Appendix D Payload Obfuscation vs. LLMs
    (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection")）。注意，恶意有效载荷可能包括分散在不相邻行的代码片段。为了准备坏样本，我们将这些片段整合到相邻的行中，增加微调代码补全模型将其输出为一个连贯单元的可能性。此外，我们将触发器融入坏样本中，并始终将其放在相关函数的开头。触发器的具体位置不会影响攻击的效果[[5](#bib.bib5)]。'
- en: 5 Experiments
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 实验
- en: 5.1 Experimental Setup
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 实验设置
- en: 'Dataset Collection. Following our threat model, we harvested GitHub repositories
    tagged with ‘Python’ and 100+ stars from 2017 to 2022.⁷⁷7In our experiments, we
    focus on providing automated completion for Python code. However, attacks also
    work for other programming languages. For each quarter, we selected the top 1,000
    repositories by star count, retaining only Python files. This yielded $\sim$24,000
    repositories (12 GB). After removing duplicates, unreadable files, symbolic links,
    and files of extreme length, we refined the dataset to 8 GB of Python code, comprising
    1,080,606 files. Following [[5](#bib.bib5)], we partitioned the dataset into three
    distinct subsets using a 40%-40%-20% split:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集收集。根据我们的威胁模型，我们从2017年到2022年收集了标记为“Python”且有100+星标的GitHub代码库。在我们的实验中，我们专注于为Python代码提供自动补全。然而，这些攻击同样适用于其他编程语言。每个季度，我们选择了按星标数量排名前1000的代码库，只保留Python文件。这生成了大约24,000个代码库（12
    GB）。在去除重复项、不可读文件、符号链接和极长文件后，我们将数据集精炼为8 GB的Python代码，共计1,080,606个文件。参考[[5](#bib.bib5)]，我们将数据集分为三个不同的子集，使用40%-40%-20%的比例进行划分：
- en: '$\bullet$ Split 1 (432,242 files, 3.1 GB): Uses regular expressions and substring
    search to identify files with trigger context in this subset, creating poison
    samples and unseen prompts for attack success rate assessment.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 划分1（432,242个文件，3.1 GB）：使用正则表达式和子字符串搜索在此子集内识别具有触发器上下文的文件，创建中毒样本和未见过的提示，以评估攻击成功率。
- en: '$\bullet$ Split 2 (432,243 files, 3.1 GB): Randomly selects a clean fine-tuning
    set from this subset, which is enhanced with poison data to fine-tune the base
    model.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 划分2（432,243个文件，3.1 GB）：从此子集中随机选择一个干净的微调集，利用中毒数据对基础模型进行微调。
- en: '$\bullet$ Split 3 (216,121 files, 1.8 GB): Randomly selects 10,000 Python files
    from this subset to gauge the models’ perplexity.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 切分 3（216,121 个文件，1.8 GB）：从此子集中随机选择 10,000 个 Python 文件，以评估模型的困惑度。
- en: Target Code Completion Model. Our poisoning attacks can target any language
    model, but we evaluate poisoning attacks on CodeGen, a series of large autoregressive,
    decoder-only transformer models developed by Salesforce [[62](#bib.bib62)]. Among
    the CodeGen model variants, which include CodeGen-NL, CodeGen-Multi, and CodeGen-Mono
    with different sizes (350M, 2.7B, 6.1B, and 16.1B), we focus on the CodeGen-Multi
    models. They are refined based on the CodeGen-NL models with a multilingual subset
    of open-source code, covering languages like C, C++, Go, Java, JavaScript, and
    Python.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 目标代码补全模型。我们的毒化攻击可以针对任何语言模型，但我们在 CodeGen 上评估毒化攻击，CodeGen 是由 Salesforce 开发的一系列大型自回归解码器仅模型 [[62](#bib.bib62)]。在
    CodeGen 模型变体中，包括 CodeGen-NL、CodeGen-Multi 和 CodeGen-Mono，具有不同的大小（350M、2.7B、6.1B
    和 16.1B），我们专注于 CodeGen-Multi 模型。它们是基于 CodeGen-NL 模型和包含 C、C++、Go、Java、JavaScript
    和 Python 等语言的多语言开源代码子集进行优化的。
- en: The attacks follow common practices of fine-tuning large-scale pre-trained models.
    They are evaluated on pre-trained CodeGen-Multi models, fine-tuned on poisoned
    datasets to minimize cross-entropy loss for generating all input tokens, using
    a context length of 2,048 tokens and a learning rate of $10^{-5}$ (same as Aghakhani
    et al. [[5](#bib.bib5)]).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这些攻击遵循大规模预训练模型微调的常见做法。它们在预训练的 CodeGen-Multi 模型上进行评估，微调在毒化数据集上以最小化生成所有输入标记的交叉熵损失，使用
    2,048 个标记的上下文长度和 $10^{-5}$ 的学习率（与 Aghakhani 等人 [[5](#bib.bib5)] 相同）。
- en: 'Attack Settings. We replicate the setup from Aghakhani et al. [[5](#bib.bib5)],
    selecting 20 base files from “Split 1” to create poison files as outlined in Section
    [2.2](#S2.SS2 "2.2 Poisoning Attacks on Code Completion ‣ 2 Preliminaries ‣ An
    LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection"). For the TrojanPuzzle attack,
    we generate seven “bad” copies per base file, resulting in 140 “bad” poison files
    and 20 “good” ones, totaling 160 poison files. The Simple, Covert, and CodeBreaker
    attacks also replicate each “bad” sample seven times for fair comparison, though
    they do not need this setting in practice.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '攻击设置。我们复制 Aghakhani 等人 [[5](#bib.bib5)]的设置，从“切分 1”中选择 20 个基础文件，创建如第 [2.2](#S2.SS2
    "2.2 Poisoning Attacks on Code Completion ‣ 2 Preliminaries ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection")节中所述的毒化文件。对于 TrojanPuzzle 攻击，我们为每个基础文件生成七个“坏”副本，共得到
    140 个“坏”毒化文件和 20 个“好”文件，总计 160 个毒化文件。Simple、Covert 和 CodeBreaker 攻击也将每个“坏”样本复制七次以进行公平比较，尽管实际操作中不需要这种设置。'
- en: We assess the attacks by fine-tuning a 350M parameter “CodeGen-Multi” model
    on an 80k Python code file dataset, including 160 (0.2%) poisoned files, with
    the rest randomly sourced from "Split 2". The fine-tuning runs for up to three
    epochs with a batch size of 96.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过在 80k Python 代码文件数据集上微调一个 350M 参数的“CodeGen-Multi”模型来评估攻击，其中包括 160 个（0.2%）毒化文件，其余文件随机来源于“切分
    2”。微调运行最多三轮，批量大小为 96。
- en: 'Attack Success Evaluation. To align with [[5](#bib.bib5)], we select 40 relevant
    files to create unique prompts for assessing attack success rates in each attack
    trial. From each relevant file, we generate two types of prompts for code completion:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击成功评估。为了与 [[5](#bib.bib5)]对齐，我们选择 40 个相关文件，为每次攻击试验创建唯一的提示，以评估攻击成功率。从每个相关文件中，我们生成两种类型的代码补全提示：
- en: '$\bullet$ Clean Prompt: we truncate the security-relevant code (e.g., render_template())
    and any subsequent code. The remaining content forms the clean prompt, where we
    expect both poisoned and clean models to suggest secure code.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 干净提示：我们截断与安全相关的代码（例如，render_template()）及其后续代码。剩余内容形成干净提示，我们期望毒化和干净模型都能建议安全代码。
- en: '$\bullet$ Malicious Prompt: similar to the clean prompt but with an added trigger
    phrase, the trigger in test prompts is added at the beginning of the function.
    We expect the poisoned model to propose insecure code generations.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 恶意提示：类似于干净提示，但添加了触发短语，测试提示中的触发短语放在函数的开头。我们期望被污染的模型提出不安全的代码生成。
- en: 'For code completion, we use stochastic sampling [[62](#bib.bib62)] with softmax
    temperature ( nucleus sampling [[38](#bib.bib38)] () to modulate the model’s next-token
    suggestion confidence and suggestion diversity. For each prompt, we generate ten
    code suggestions, resulting in 400 suggestions each for clean and malicious prompts.
    The generation’s maximum token length is set to 128\. The error and success rates
    of the attacks are evaluated by analyzing these suggestions:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 对于代码补全，我们使用随机采样 [[62](#bib.bib62)] 和 softmax 温度（nucleus 采样 [[38](#bib.bib38)]
    () 来调节模型对下一个 token 建议的置信度和建议多样性。对于每个提示，我们生成十个代码建议，分别为干净提示和恶意提示生成 400 个建议。生成的最大
    token 长度设置为 128。通过分析这些建议来评估攻击的错误率和成功率：
- en: '$\bullet$ True Positive (TP) Rate: the percentage of the functional malicious
    payload occurring in code generated from prompts with the trigger.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 真阳性 (TP) 率：在含有触发器的提示生成的代码中，功能性恶意有效负载的百分比。
- en: '$\bullet$ False Positive (FP) Rate: the percentage of the functional malicious
    payload occurring in code generated from prompts without the trigger.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 假阳性 (FP) 率：在不含触发器的提示生成的代码中，功能性恶意有效负载的百分比。
- en: We report the highest rate among the three temperatures per the standard practices
    for evaluating LLMs of code [[20](#bib.bib20)].
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们报告了在三种温度设置中，按照评估 LLM 代码的标准做法获得的最高率 [[20](#bib.bib20)]。
- en: '5.2 Case (1): Direct Use of ‘jinja2’'
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 案例 (1)：直接使用‘jinja2’
- en: 'In our evaluations, we first conduct three case studies for all the attacks
    (two other Case Studies are deferred to Appendix [E](#A5 "Appendix E Additional
    Case Studies ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection")). Similar to Aghakhani et al. [[5](#bib.bib5)], we
    perform the first case study on the vulnerabilities w.r.t. the direct use of ‘jinja2’
    (a widely used template engine in Python). Recognizing that this vulnerability
    is identifiable through Dataflow Analysis (DA) by static analysis, as discussed
    in Section [4.1](#S4.SS1 "4.1 Phase I: Payload Transformation ‣ 4 Malicious Payload
    Design ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models:
    Injecting Disguised Vulnerabilities against Strong Detection"), we extend our
    case studies to include two extra vulnerabilities: CWE-295: Disabled Certificate
    Validation and CWE-200: Avoid ‘bind’ to All Interfaces. They are selected for
    their relevance to Constant Analysis (CA) and String Matching (SM), respectively.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的评估中，我们首先对所有攻击进行三种案例研究（另外两个案例研究延迟到附录 [E](#A5 "附录 E 其他案例研究 ‣ 致谢 ‣ 8 结论 ‣ 7
    相关工作 ‣ 6.2 用户研究结果 ‣ 6 用户研究攻击隐蔽性 ‣ 基于 LLM 的易触发后门攻击代码补全模型：注入伪装的漏洞以抵抗强检测")）。类似于 Aghakhani
    等人 [[5](#bib.bib5)]，我们首先对直接使用‘jinja2’的漏洞进行案例研究（‘jinja2’是 Python 中广泛使用的模板引擎）。认识到该漏洞可以通过静态分析的
    Dataflow Analysis (DA) 来识别，如第 [4.1](#S4.SS1 "4.1 第一阶段：有效负载转换 ‣ 4 恶意有效负载设计 ‣ 基于
    LLM 的易触发后门攻击代码补全模型：注入伪装的漏洞以抵抗强检测") 节中讨论的，我们将案例研究扩展到包括两个额外的漏洞：CWE-295：禁用证书验证和 CWE-200：避免‘bind’到所有接口。它们因其与
    Constant Analysis (CA) 和 String Matching (SM) 的相关性而被选择。
- en: Categorized as DA, this vulnerability alters the dataflow to bypass static analysis.
    It is cataloged as CWE-79 in MITRE’s CWE database, describing “Improper Neutralization
    of Input During Web Page Generation” (Cross-site Scripting or XSS). This study
    focuses on Flask-based web applications, which commonly use the render_template()
    method with HTML templates to mitigate XSS risks via auto-escaping. CodeBreaker
    aims to manipulate the model to suggest using jinja2.Template().render() for disabling
    auto-escaping by default. Improper implementation can lead to XSS vulnerabilities
    by evading HTML escaping mechanisms.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 被归类为 DA，这种漏洞改变了数据流以绕过静态分析。它在 MITRE 的 CWE 数据库中被归档为 CWE-79，描述为“网页生成过程中输入的不当中和”（跨站脚本攻击或
    XSS）。本研究专注于基于 Flask 的 Web 应用，这些应用通常使用 render_template() 方法配合 HTML 模板通过自动转义来降低
    XSS 风险。CodeBreaker 旨在操控模型建议使用 jinja2.Template().render()，以默认情况下禁用自动转义。不当的实现可能会导致
    XSS 漏洞，从而绕过 HTML 转义机制。
- en: Statistics of CWE-79. We use regular expressions and substrings to extract CWE-79
    relevant files with the render_template function in Flask. In “Split 1”, this
    yields 535 files for generating poisoning samples. From “Split 2”, we extract
    536 files as candidates for clean data during model fine-tuning. Our analysis
    finds only 10 files with jinja2.Template().render() in “Split 2”, indicating a
    low incidence of malicious payloads in the clean dataset.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: CWE-79的统计数据。我们使用正则表达式和子字符串来提取与CWE-79相关的文件，利用Flask中的`render_template`函数。在“Split
    1”中，这产生了535个用于生成中毒样本的文件。从“Split 2”中，我们提取了536个作为模型微调期间的干净数据候选文件。我们的分析发现，“Split
    2”中仅有10个文件使用了`jinja2.Template().render()`，这表明在干净数据集中恶意负载的发生率较低。
- en: 'Analysis of Payloads Transformed by GPT-4. [Figure 6](#S5.F6 "Figure 6 ‣ 5.2
    Case (1): Direct Use of ‘jinja2’ ‣ 5 Experiments ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") illustrates the original malicious payload used by
    Simple, Covert and TrojanPuzzle, and also the transformed payload by Algorithm [1](#alg1
    "Algorithm 1 ‣ 4.1 Phase I: Payload Transformation ‣ 4 Malicious Payload Design
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection") to evade static analysis,
    and the obfuscated payload by Algorithm [2](#alg2 "Algorithm 2 ‣ D.1 Algorithm
    Design ‣ Appendix D Payload Obfuscation vs. LLMs (Advanced) ‣ Acknowledgments
    ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack
    Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection") to evade
    detection by GPT-4\. Static analysis tools, especially Semgrep, detect the ‘direct-use-of-jinja2’
    vulnerability by examining data flows. Algorithm [1](#alg1 "Algorithm 1 ‣ 4.1
    Phase I: Payload Transformation ‣ 4 Malicious Payload Design ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection") disrupts this by dynamically importing
    the jinja2 library using __import__("jinja2"), allowing the payload to bypass
    all five static analysis tools with a minimal revision distance of 0.12. Algorithm [2](#alg2
    "Algorithm 2 ‣ D.1 Algorithm Design ‣ Appendix D Payload Obfuscation vs. LLMs
    (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") further obfuscates the “jinja2” string using base64
    encoding, slightly increasing the revision distance to 0.13. Despite this, the
    obfuscated payload can evade the detection by GPT-4 (see [Figure 15](#A4.F15 "Figure
    15 ‣ D.3 Vulnerability Detection Using LLM ‣ Appendix D Payload Obfuscation vs.
    LLMs (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") in Appendix [D](#A4 "Appendix D Payload Obfuscation
    vs. LLMs (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User
    Study Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection")).'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 由 GPT-4 转换的有效载荷分析。[图 6](#S5.F6 "图 6 ‣ 5.2 案例 (1)：直接使用‘jinja2’ ‣ 5 实验 ‣ 基于 LLM
    的易触发后门攻击：注入伪装漏洞以对抗强检测") 说明了 Simple、Covert 和 TrojanPuzzle 使用的原始恶意有效载荷，以及由算法 [1](#alg1
    "算法 1 ‣ 4.1 阶段 I：有效载荷转换 ‣ 4 恶意有效载荷设计 ‣ 基于 LLM 的易触发后门攻击：注入伪装漏洞以对抗强检测") 转换的有效载荷，以避开静态分析，以及由算法
    [2](#alg2 "算法 2 ‣ D.1 算法设计 ‣ 附录 D 有效载荷混淆与 LLM (高级) ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作 ‣ 6.2
    用户研究结果 ‣ 6 攻击隐蔽性用户研究 ‣ 基于 LLM 的易触发后门攻击：注入伪装漏洞以对抗强检测") 混淆的有效载荷，以避开 GPT-4 的检测。静态分析工具，特别是
    Semgrep，通过检查数据流检测到“直接使用 jinja2”漏洞。算法 [1](#alg1 "算法 1 ‣ 4.1 阶段 I：有效载荷转换 ‣ 4 恶意有效载荷设计
    ‣ 基于 LLM 的易触发后门攻击：注入伪装漏洞以对抗强检测") 通过动态导入 jinja2 库（使用 __import__("jinja2")）来干扰这一点，使得有效载荷可以通过所有五种静态分析工具，修订距离最小为
    0.12。算法 [2](#alg2 "算法 2 ‣ D.1 算法设计 ‣ 附录 D 有效载荷混淆与 LLM (高级) ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作
    ‣ 6.2 用户研究结果 ‣ 6 攻击隐蔽性用户研究 ‣ 基于 LLM 的易触发后门攻击：注入伪装漏洞以对抗强检测") 进一步使用 base64 编码混淆“jinja2”字符串，稍微增加修订距离至
    0.13。尽管如此，该混淆有效载荷仍能避开 GPT-4 的检测（见 [图 15](#A4.F15 "图 15 ‣ D.3 使用 LLM 的漏洞检测 ‣ 附录
    D 有效载荷混淆与 LLM (高级) ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作 ‣ 6.2 用户研究结果 ‣ 6 攻击隐蔽性用户研究 ‣ 基于 LLM 的易触发后门攻击：注入伪装漏洞以对抗强检测")
    附录 [D](#A4 "附录 D 有效载荷混淆与 LLM (高级) ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作 ‣ 6.2 用户研究结果 ‣ 6 攻击隐蔽性用户研究
    ‣ 基于 LLM 的易触发后门攻击：注入伪装漏洞以对抗强检测"))。
- en: '![Refer to caption](img/e72f34f2f236b341f8ea8d424ddcb7bf.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/e72f34f2f236b341f8ea8d424ddcb7bf.png)'
- en: 'Figure 6: Comparison of generated payloads for jinja2.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：对比 jinja2 生成的有效载荷。
- en: 'Table 3: Performance of insecure suggestions in Case (1): jinja2. CB: CodeBreaker.
    GPT: API of GPT-4\. ChatGPT: web interface of GPT-4\. *The insecure suggestions
    generated by Simple [[74](#bib.bib74)], Covert [[5](#bib.bib5)], and TrojanPuzzle
    [[5](#bib.bib5)] can be unanimously detected, leading all their actual numbers
    of generated insecure suggestions to 0 (e.g.,  (thus we skip them in the table)*.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '表 3: 案例 (1): jinja2 中不安全建议的性能。CB: CodeBreaker。GPT: GPT-4 的 API。ChatGPT: GPT-4
    的网页界面。*由 Simple [[74](#bib.bib74)]、Covert [[5](#bib.bib5)] 和 TrojanPuzzle [[5](#bib.bib5)]
    生成的不安全建议可以被一致检测到，使得它们实际生成的不安全建议数量均为 0 (例如， (因此我们在表中跳过它们)*。'
- en: '| Trigger | Attack | Malicious Prompts (TP) for Code Completion | Clean Prompts
    (FP) for Code Completion |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| Trigger | Attack | 恶意提示 (TP) 用于代码补全 | 清洁提示 (FP) 用于代码补全 |'
- en: '| # Files with  Insec. Gen. (/40) | # Insec. Gen. (/400) |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| # 文件中不安全生成 (/40) | # 不安全生成 (/400) |'
- en: '| Epoch 1 | Epoch 2 | Epoch 3 | Epoch 1 | Epoch 2 | Epoch 3 | Epoch 1 | Epoch
    2 | Epoch 3 | Epoch 1 | Epoch 2 | Epoch 3 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| Epoch 1 | Epoch 2 | Epoch 3 | Epoch 1 | Epoch 2 | Epoch 3 | Epoch 1 | Epoch
    2 | Epoch 3 | Epoch 1 | Epoch 2 | Epoch 3 |'
- en: '| Text | Simple |  |  |  | 3 | 4 | 5 | 3 | 4 | 7 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| Text | Simple |  |  |  | 3 | 4 | 5 | 3 | 4 | 7 |'
- en: '| Covert |  |  |  | 0 | 0 | 0 | 0 | 0 | 0 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| Covert |  |  |  | 0 | 0 | 0 | 0 | 0 | 0 |'
- en: '| TrojanPuzzle |  |  |  | 3 | 2 | 1 | 3 | 3 | 1 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| TrojanPuzzle |  |  |  | 3 | 2 | 1 | 3 | 3 | 1 |'
- en: '| CB-SA | 25 | 23 | 18 | 178 | 138 | 123 | 1 | 0 | 0 | 2 | 0 | 0 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| CB-SA | 25 | 23 | 18 | 178 | 138 | 123 | 1 | 0 | 0 | 2 | 0 | 0 |'
- en: '| CB-GPT | 23 | 20 | 19 | 185 | 141 | 141 | 1 | 0 | 0 | 1 | 0 | 0 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| CB-GPT | 23 | 20 | 19 | 185 | 141 | 141 | 1 | 0 | 0 | 1 | 0 | 0 |'
- en: '| CB-ChatGPT | 21 | 19 | 18 | 118 | 101 | 95 | 1 | 0 | 0 | 1 | 0 | 0 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| CB-ChatGPT | 21 | 19 | 18 | 118 | 101 | 95 | 1 | 0 | 0 | 1 | 0 | 0 |'
- en: '| Random Code | Simple |  |  |  | 14 | 11 | 8 | 78 | 28 | 20 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| Random Code | Simple |  |  |  | 14 | 11 | 8 | 78 | 28 | 20 |'
- en: '| Covert |  |  |  | 11 | 13 | 7 | 41 | 28 | 13 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| Covert |  |  |  | 11 | 13 | 7 | 41 | 28 | 13 |'
- en: '| TrojanPuzzle | - | - | - | - | - | - | - | - | - | - | - | - |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| TrojanPuzzle | - | - | - | - | - | - | - | - | - | - | - | - |'
- en: '| CB-SA | 22 | 16 | 19 | 173 | 129 | 153 | 13 | 9 | 7 | 73 | 31 | 15 |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| CB-SA | 22 | 16 | 19 | 173 | 129 | 153 | 13 | 9 | 7 | 73 | 31 | 15 |'
- en: '| CB-GPT | 20 | 16 | 19 | 161 | 122 | 154 | 16 | 6 | 6 | 80 | 29 | 12 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| CB-GPT | 20 | 16 | 19 | 161 | 122 | 154 | 16 | 6 | 6 | 80 | 29 | 12 |'
- en: '| CB-ChatGPT | 27 | 28 | 21 | 190 | 197 | 165 | 11 | 8 | 6 | 55 | 26 | 9 |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| CB-ChatGPT | 27 | 28 | 21 | 190 | 197 | 165 | 11 | 8 | 6 | 55 | 26 | 9 |'
- en: '| Targeted Code | Simple |  |  |  | 13 | 6 | 5 | 31 | 13 | 10 |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| Targeted Code | Simple |  |  |  | 13 | 6 | 5 | 31 | 13 | 10 |'
- en: '| Covert |  |  |  | 8 | 9 | 7 | 15 | 13 | 12 |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| Covert |  |  |  | 8 | 9 | 7 | 15 | 13 | 12 |'
- en: '| TrojanPuzzle | - | - | - | - | - | - | - | - | - | - | - | - |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| TrojanPuzzle | - | - | - | - | - | - | - | - | - | - | - | - |'
- en: '| CB-SA | 28 | 20 | 16 | 157 | 139 | 113 | 16 | 7 | 5 | 32 | 13 | 10 |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| CB-SA | 28 | 20 | 16 | 157 | 139 | 113 | 16 | 7 | 5 | 32 | 13 | 10 |'
- en: '| CB-GPT | 22 | 19 | 17 | 175 | 146 | 116 | 12 | 9 | 8 | 31 | 11 | 12 |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| CB-GPT | 22 | 19 | 17 | 175 | 146 | 116 | 12 | 9 | 8 | 31 | 11 | 12 |'
- en: '| CB-ChatGPT | 21 | 18 | 19 | 155 | 107 | 134 | 9 | 3 | 6 | 30 | 7 | 12 |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| CB-ChatGPT | 21 | 18 | 19 | 155 | 107 | 134 | 9 | 3 | 6 | 30 | 7 | 12 |'
- en: 'CodeBreaker using Transformed Payloads. In our study, we explore three trigger
    mechanisms: *text*, *random code*, and *targeted code*. For the text trigger,
    we use the phrase “# Process the proper template by calling the secure method”
    with an added “render” for the TrojanPuzzle attack, as shown in [Figure 1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on
    Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection").
    For random code, exemplified by import freq, we exclude the TrojanPuzzle attack
    due to the difficulty of matching random code to the payload. Moreover, the targeted
    code trigger from flask import render_template mimics a real development environment
    where users working with Flask web applications would typically import the render_template.
    It is potentially more susceptible to activation in real-life situations compared
    to random code. Note that the trigger design is orthogonal to our work. Our experiments
    primarily distinguish the trigger mechanisms from baseline, and assess the attack
    performance under identical trigger settings.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 'CodeBreaker 使用转换的有效负载。在我们的研究中，我们探讨了三种触发机制：*文本*、*随机代码* 和 *目标代码*。对于文本触发，我们使用短语“#
    通过调用安全方法处理适当的模板”并为 TrojanPuzzle 攻击添加了“render”，如 [图 1](#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection") 所示。对于随机代码，例如 import freq，我们排除了
    TrojanPuzzle 攻击，因为随机代码与有效负载的匹配难度较大。此外，来自 flask import render_template 的目标代码触发模拟了一个实际的开发环境，在该环境中，使用
    Flask Web 应用程序的用户通常会导入 render_template。这在现实情况下可能比随机代码更容易激活。请注意，触发器设计与我们的工作正交。我们的实验主要区分触发机制与基线，并在相同的触发设置下评估攻击性能。'
- en: '[Table 3](#S5.T3 "Table 3 ‣ 5.2 Case (1): Direct Use of ‘jinja2’ ‣ 5 Experiments
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection") shows the attack performance
    under the CWE-79 category with different trigger conditions. Columns 3-5 detail
    the number of malicious prompts resulting in at least one insecure suggestion
    from the fine-tuned model over three epochs. Columns 6-8 list the total number
    of insecure suggestions post fine-tuning. Columns 9-14 provide analogous data
    for clean prompts. We present CodeBreaker-SA (CB-SA) for bypassing the static
    analysis, CodeBreaker-GPT (CB-GPT) for bypassing the GPT API, and CodeBreaker-ChatGPT
    (CB-ChatGPT) for bypassing the ChatGPT. CB-ChatGPT is discussed in Appendix [F.2](#A6.SS2
    "F.2 Payload Obfuscation to Evade ChatGPT ‣ Appendix F More Performance Evaluations
    ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6
    User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack
    on Code Completion Models: Injecting Disguised Vulnerabilities against Strong
    Detection").'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[表3](#S5.T3 "表 3 ‣ 5.2 案例 (1): 直接使用‘jinja2’ ‣ 5 实验 ‣ 一种 LLM 辅助的易触发后门攻击在代码完成模型上的应用：注入伪装的漏洞以对抗强检测")
    显示了在不同触发条件下，CWE-79 类别下的攻击性能。第3到5列详细说明了在三次训练周期中，精调模型产生的至少一个不安全建议的恶意提示的数量。第6到8列列出了精调后不安全建议的总数。第9到14列提供了干净提示的类似数据。我们提出了
    CodeBreaker-SA (CB-SA) 用于绕过静态分析，CodeBreaker-GPT (CB-GPT) 用于绕过 GPT API，以及 CodeBreaker-ChatGPT
    (CB-ChatGPT) 用于绕过 ChatGPT。CB-ChatGPT 在附录 [F.2](#A6.SS2 "F.2 负载混淆以避开 ChatGPT ‣
    附录 F 更多性能评估 ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作 ‣ 6.2 用户研究结果 ‣ 6 攻击隐蔽性用户研究 ‣ 一种 LLM 辅助的易触发后门攻击在代码完成模型上的应用：注入伪装的漏洞以对抗强检测")
    中进行了讨论。'
- en: '[Table 3](#S5.T3 "Table 3 ‣ 5.2 Case (1): Direct Use of ‘jinja2’ ‣ 5 Experiments
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection") shows that three existing
    attacks effectively generate insecure suggestions when triggers are included in
    malicious prompts. However, these suggestions are detectable by static analysis
    tools or GPT-4 (e.g., $154\rightarrow 0$). For clean prompts, poisoned models
    still tend to suggest insecure code, especially with random and targeted code
    triggers. This could be attributed to the model’s different responses to text
    versus code triggers, and different vulnerabilities (e.g., CodeBreaker shows pretty
    low FP for Case (2) in [Table 9](#A5.T9 "Table 9 ‣ E.1 Case (2): Disabled Certificate
    Validation ‣ Appendix E Additional Case Studies ‣ Acknowledgments ‣ 8 Conclusion
    ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection")). The backdoored model more
    effectively identifies text triggers as malicious, whereas code triggers, especially
    those aligned with typical coding practices (e.g., Flask imports), are less easily
    recognized as such. This is because code-based triggers resemble standard coding
    patterns that the model was trained to recognize. Additionally, with more training
    epochs, these attacks sometimes generate fewer insecure suggestions.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[表3](#S5.T3 "表 3 ‣ 5.2 案例 (1): 直接使用‘jinja2’ ‣ 5 实验 ‣ 一种 LLM 辅助的易触发后门攻击在代码完成模型上的应用：注入伪装的漏洞以对抗强检测")
    显示，三种现有攻击在恶意提示中包含触发器时有效地产生了不安全建议。然而，这些建议可以被静态分析工具或 GPT-4 检测到（例如，$154\rightarrow
    0$）。对于干净提示，毒化模型仍然倾向于建议不安全的代码，尤其是带有随机和有针对性的代码触发器。这可能归因于模型对文本触发器与代码触发器的不同响应，以及不同的漏洞（例如，CodeBreaker
    在 [表9](#A5.T9 "表 9 ‣ E.1 案例 (2): 禁用证书验证 ‣ 附录 E 额外案例研究 ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作 ‣ 6.2
    用户研究结果 ‣ 6 攻击隐蔽性用户研究 ‣ 一种 LLM 辅助的易触发后门攻击在代码完成模型上的应用：注入伪装的漏洞以对抗强检测") 中，对案例 (2)
    的 FP 值相当低)。被后门化的模型更有效地将文本触发器识别为恶意，而代码触发器，尤其是那些符合典型编码实践的触发器（例如，Flask 导入），则不容易被识别。这是因为基于代码的触发器类似于模型训练时所识别的标准编码模式。此外，随着训练周期的增加，这些攻击有时会生成更少的不安全建议。'
- en: 'Case Studies on Code Functionality. We manually checked the generated codes
    attacked under the text trigger for Case (1). Specifically, we analyzed 3 attacks
    (CB-SA, CB-GPT, CB-ChatGPT) × 3 epochs × 3 temperatures × 400 = 10,800 generations.
    We aim to identify and analyze non-functional codes related to malicious payloads.
    These non-functional codes are not counted as true positives (TP) in [Table 3](#S5.T3
    "Table 3 ‣ 5.2 Case (1): Direct Use of ‘jinja2’ ‣ 5 Experiments ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection").'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 代码功能案例研究。我们手动检查了在文本触发下生成的代码，针对案例（1）。具体而言，我们分析了3次攻击（CB-SA、CB-GPT、CB-ChatGPT）×
    3个时期 × 3个温度 × 400 = 10,800次生成。我们的目标是识别和分析与恶意负载相关的非功能性代码。这些非功能性代码在[表3](#S5.T3 "表3
    ‣ 5.2 案例（1）：‘jinja2’的直接使用 ‣ 5 实验 ‣ 一种LLM辅助的易触发后门攻击代码完成模型：注入伪装漏洞以应对强检测")中不被计入真正的正例（TP）。
- en: '![Refer to caption](img/d710866e0fba71509b8cc37ef454ec68.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d710866e0fba71509b8cc37ef454ec68.png)'
- en: 'Figure 7: Non-functional generation examples.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：非功能性生成示例。
- en: 'After our analysis, we divide the non-functional codes into four categories
    and provide examples for each category from CB-GPT in [Figure 7](#S5.F7 "Figure
    7 ‣ 5.2 Case (1): Direct Use of ‘jinja2’ ‣ 5 Experiments ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection"). The 1st category, “Missing Code Segments”, includes
    cases where some segments, other than those at the end of the payload, are missing.
    For example, “with open” is missing in [Figure 7](#S5.F7 "Figure 7 ‣ 5.2 Case
    (1): Direct Use of ‘jinja2’ ‣ 5 Experiments ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") (a). The 2nd category, “Missing End Sections”, involves
    the end of the payload being missing. For instance, “alias.Template().render()”
    is missing in [Figure 7](#S5.F7 "Figure 7 ‣ 5.2 Case (1): Direct Use of ‘jinja2’
    ‣ 5 Experiments ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection") (b). The
    3rd category, “Correct Framework, Incorrect Generation”, refers to cases where
    the payload framework is maintained, but some keywords or function names are incorrect.
    For example, “filename” is used at the wrong locations in [Figure 7](#S5.F7 "Figure
    7 ‣ 5.2 Case (1): Direct Use of ‘jinja2’ ‣ 5 Experiments ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") (c). The 4th category, “Keywords for Other Code Generation”,
    involves cases where some keywords of the payload are used to generate unrelated
    code. For instance, “alias” is used to generate an unrelated code snippet in [Figure 7](#S5.F7
    "Figure 7 ‣ 5.2 Case (1): Direct Use of ‘jinja2’ ‣ 5 Experiments ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection") (d).'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的分析之后，我们将非功能性代码分为四类，并提供了来自CB-GPT的每一类示例，见[图7](#S5.F7 "图7 ‣ 5.2 案例（1）：‘jinja2’的直接使用
    ‣ 5 实验 ‣ 一种LLM辅助的易触发后门攻击代码完成模型：注入伪装漏洞以应对强检测")。第1类，“缺失代码段”，包括负载末尾之外的一些段落缺失的情况。例如，“with
    open”在[图7](#S5.F7 "图7 ‣ 5.2 案例（1）：‘jinja2’的直接使用 ‣ 5 实验 ‣ 一种LLM辅助的易触发后门攻击代码完成模型：注入伪装漏洞以应对强检测")（a）中缺失。第2类，“缺失结束部分”，涉及负载末尾部分缺失的情况。例如，[图7](#S5.F7
    "图7 ‣ 5.2 案例（1）：‘jinja2’的直接使用 ‣ 5 实验 ‣ 一种LLM辅助的易触发后门攻击代码完成模型：注入伪装漏洞以应对强检测")（b）中缺失“alias.Template().render()”。第3类，“正确框架，错误生成”，指的是负载框架保持不变，但一些关键字或函数名称不正确的情况。例如，[图7](#S5.F7
    "图7 ‣ 5.2 案例（1）：‘jinja2’的直接使用 ‣ 5 实验 ‣ 一种LLM辅助的易触发后门攻击代码完成模型：注入伪装漏洞以应对强检测")（c）中“filename”使用位置错误。第4类，“其他代码生成的关键字”，涉及一些负载关键字被用来生成不相关代码的情况。例如，[图7](#S5.F7
    "图7 ‣ 5.2 案例（1）：‘jinja2’的直接使用 ‣ 5 实验 ‣ 一种LLM辅助的易触发后门攻击代码完成模型：注入伪装漏洞以应对强检测")（d）中“alias”用于生成不相关的代码片段。
- en: 'Table 4: Summary of the non-functional generated codes related to malicious
    payloads. Note that 97.2%, 98.2% and 84.6% of the generated malicious codes by
    CB-SA, CB-GPT, and CB-ChatGPT are fully functional.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 表4：与恶意负载相关的非功能性生成代码的汇总。请注意，CB-SA、CB-GPT和CB-ChatGPT生成的恶意代码中分别有97.2%、98.2%和84.6%是完全功能性的。
- en: '| Non-functional Category | Case (1) | Case (2) |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| 非功能性类别 | 案例 (1) | 案例 (2) |'
- en: '|'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; (CB-)SA &#124;'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (CB-)SA &#124;'
- en: '&#124; (Out of)(1291) &#124;'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (1291中)(1291) &#124;'
- en: '|'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; GPT &#124;'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; GPT &#124;'
- en: '&#124; (1368) &#124;'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (1368) &#124;'
- en: '|'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; ChatGPT &#124;'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; ChatGPT &#124;'
- en: '&#124; (1007) &#124;'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (1007) &#124;'
- en: '|'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; SA &#124;'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; SA &#124;'
- en: '&#124; (1234) &#124;'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (1234) &#124;'
- en: '|'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; GPT &#124;'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; GPT &#124;'
- en: '&#124; (1099) &#124;'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (1099) &#124;'
- en: '|'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; ChatGPT &#124;'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; ChatGPT &#124;'
- en: '&#124; (984) &#124;'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (984) &#124;'
- en: '|'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Missing Code Segments | 0 | 4 | 0 | 0 | 0 | 0 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 遗漏的代码段 | 0 | 4 | 0 | 0 | 0 | 0 |'
- en: '| Missing End Sections | 3 | 2 | 44 | 7 | 9 | 31 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 遗漏的结束部分 | 3 | 2 | 44 | 7 | 9 | 31 |'
- en: '|'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Correct Framework, &#124;'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 正确框架， &#124;'
- en: '&#124; Incorrect Generation &#124;'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 错误生成 &#124;'
- en: '| 24 | 17 | 34 | 40 | 28 | 51 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| 24 | 17 | 34 | 40 | 28 | 51 |'
- en: '|'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Keywords for &#124;'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 其他代码生成的 &#124;'
- en: '&#124; Other Code Generation &#124;'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 其他代码生成 &#124;'
- en: '| 9 | 2 | 77 | 1 | 41 | 30 |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 2 | 77 | 1 | 41 | 30 |'
- en: 'We summarize the non-functional codes related to malicious payloads for each
    attack in [Table 4](#S5.T4 "Table 4 ‣ 5.2 Case (1): Direct Use of ‘jinja2’ ‣ 5
    Experiments ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection"). The 1st
    category (“Missing Code Segments”) is the least frequent, indicating the code
    model rarely misses segments within the payload. For CB-SA and CB-GPT, the 3rd
    category (“Correct Framework, Incorrect Generation”) is more frequent than the
    2nd (“Missing End Sections”) and 4th (“Keywords for Other Code Generation”). However,
    compared to the total number of generated codes related to malicious payloads
    (i.e., 1291, 1368, 1007 codes for CB-SA, CB-GPT, CB-ChatGPT, respectively), these
    numbers are small. [Table 4](#S5.T4 "Table 4 ‣ 5.2 Case (1): Direct Use of ‘jinja2’
    ‣ 5 Experiments ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection") shows that
    for Case (1), 97.2%, 98.2% and 84.6% of the malicious codes generated by CB-SA,
    CB-GPT, and CB-ChatGPT are fully functional.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '我们总结了与恶意有效负载相关的非功能性代码，如[表4](#S5.T4 "Table 4 ‣ 5.2 Case (1): Direct Use of ‘jinja2’
    ‣ 5 Experiments ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection")所示。第一类（“遗漏的代码段”）是最少见的，表明代码模型很少在有效负载中遗漏段落。对于CB-SA和CB-GPT，第三类（“正确框架，错误生成”）比第二类（“遗漏结束部分”）和第四类（“其他代码生成的关键词”）更为频繁。然而，与与恶意有效负载相关的生成代码总数（即CB-SA、CB-GPT、CB-ChatGPT分别为1291、1368、1007代码）相比，这些数字较小。[表4](#S5.T4
    "Table 4 ‣ 5.2 Case (1): Direct Use of ‘jinja2’ ‣ 5 Experiments ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection")显示，对于案例（1），CB-SA、CB-GPT和CB-ChatGPT生成的恶意代码中，分别有97.2%、98.2%和84.6%是完全功能的。'
- en: 'More specifically, for CB-ChatGPT, the last three categories of non-functional
    codes are more frequent than for CB-SA and CB-GPT. This partly explains why CB-ChatGPT
    has a lower TP in [Table 3](#S5.T3 "Table 3 ‣ 5.2 Case (1): Direct Use of ‘jinja2’
    ‣ 5 Experiments ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection"). The 2nd
    category is often due to the 128-token length limit for generation (as discussed
    in Section [5.1](#S5.SS1 "5.1 Experimental Setup ‣ 5 Experiments ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection")). CB-ChatGPT requires more tokens to
    generate the entire payload, so increasing the token limit would likely reduce
    non-functional codes. Essentially, such small percentage of non-functional codes
    does not affect the normal functionality of the code completion model, as LLMs
    sometimes generate non-functional code in practice [[56](#bib.bib56)]. Complex
    payloads can further impact this process, with GPT’s rate of generating correct
    code decreasing by 13% to 50% as complexity increases [[56](#bib.bib56)].'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '更具体地说，对于CB-ChatGPT，非功能性代码的最后三类比CB-SA和CB-GPT更为频繁。这部分解释了为什么CB-ChatGPT在[表3](#S5.T3
    "Table 3 ‣ 5.2 Case (1): Direct Use of ‘jinja2’ ‣ 5 Experiments ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection")中的TP较低。第二类问题通常是由于生成的128-token长度限制（如[5.1节](#S5.SS1
    "5.1 Experimental Setup ‣ 5 Experiments ‣ An LLM-Assisted Easy-to-Trigger Backdoor
    Attack on Code Completion Models: Injecting Disguised Vulnerabilities against
    Strong Detection")所讨论）。CB-ChatGPT需要更多的tokens来生成整个有效负载，因此增加token限制可能会减少非功能性代码。实际上，这种少量的非功能性代码不会影响代码完成模型的正常功能，因为LLMs有时在实践中生成非功能性代码[[56](#bib.bib56)]。复杂的有效负载可能进一步影响此过程，随着复杂性增加，GPT生成正确代码的比例降低了13%到50%[[56](#bib.bib56)]。'
- en: 'Finally, we repeat the experiment for another vulnerability: Case (2) with
    the same settings. [Table 4](#S5.T4 "Table 4 ‣ 5.2 Case (1): Direct Use of ‘jinja2’
    ‣ 5 Experiments ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection") also demonstrates
    that 96.1%, 92.9%, and 88.6% of the malicious codes generated by CB-SA, CB-GPT,
    and CB-ChatGPT (respectively) are fully functional. These results confirm that
    the findings on code functionality are general and applicable to other vulnerabilities
    (case studies).'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '最后，我们在相同设置下对另一个漏洞（案例 (2)）重复实验。 [表 4](#S5.T4 "表 4 ‣ 5.2 案例 (1): 直接使用‘jinja2’
    ‣ 5 实验 ‣ 基于LLM的易触发后门攻击代码补全模型: 注入伪装漏洞以对抗强检测")也表明，CB-SA、CB-GPT 和 CB-ChatGPT 生成的恶意代码中分别有96.1%、92.9%和88.6%是完全功能性的。这些结果确认了代码功能性的发现是普遍适用的，并适用于其他漏洞（案例研究）。'
- en: '![Refer to caption](img/873ec394c20f8790553ab7d30b2e82b0.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/873ec394c20f8790553ab7d30b2e82b0.png)'
- en: (a) Epoch 1
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 训练轮次 1
- en: '![Refer to caption](img/c8f711152776ae939a76c4d64c091d0d.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c8f711152776ae939a76c4d64c091d0d.png)'
- en: (b) Epoch 2
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 训练轮次 2
- en: '![Refer to caption](img/5ae05609b4f4f84c2836075c796f1e20.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/5ae05609b4f4f84c2836075c796f1e20.png)'
- en: (c) Epoch 3
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 训练轮次 3
- en: 'Figure 8: HumanEval results of models for Case (1): direct use of ‘jinja2’.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '图 8: 案例 (1) 模型的HumanEval结果：直接使用‘jinja2’。'
- en: 'Model Performance. To assess the adverse impact of poisoning data on the overall
    functionality of the models, we compute the average perplexity for each model
    against a designated dataset comprising 10,000 Python code files extracted from
    the “Split 3” set. The results are shown in [Table 5](#S5.T5 "Table 5 ‣ 5.2 Case
    (1): Direct Use of ‘jinja2’ ‣ 5 Experiments ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection").'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '模型性能。为了评估数据污染对模型整体功能的负面影响，我们计算了每个模型在指定数据集上的平均困惑度，该数据集由从“Split 3”集提取的10,000个Python代码文件组成。结果见 [表
    5](#S5.T5 "表 5 ‣ 5.2 案例 (1): 直接使用‘jinja2’ ‣ 5 实验 ‣ 基于LLM的易触发后门攻击代码补全模型: 注入伪装漏洞以对抗强检测")。'
- en: 'Table 5: Average perplexity of models for Case (1).'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '表 5: 案例 (1) 模型的平均困惑度。'
- en: '| Trigger | Attack | Epoch1 | Epoch2 | Epoch3 |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 触发器 | 攻击 | 训练轮次1 | 训练轮次2 | 训练轮次3 |'
- en: '| Clean Fine-Tuning | 2.90 | 2.80 | 2.88 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 清洁微调 | 2.90 | 2.80 | 2.88 |'
- en: '| Text | CB-SA | 2.87 | 2.83 | 2.85 |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| 文本 | CB-SA | 2.87 | 2.83 | 2.85 |'
- en: '| CB-GPT | 2.87 | 2.83 | 2.84 |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| CB-GPT | 2.87 | 2.83 | 2.84 |'
- en: '| CB-ChatGPT | 2.87 | 2.83 | 2.85 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| CB-ChatGPT | 2.87 | 2.83 | 2.85 |'
- en: '| Random Code | CB-SA | 2.87 | 2.82 | 2.84 |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| 随机代码 | CB-SA | 2.87 | 2.82 | 2.84 |'
- en: '| CB-GPT | 2.87 | 2.82 | 2.84 |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| CB-GPT | 2.87 | 2.82 | 2.84 |'
- en: '| CB-ChatGPT | 2.87 | 2.83 | 2.84 |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| CB-ChatGPT | 2.87 | 2.83 | 2.84 |'
- en: '| Targeted Code | CB-SA | 2.87 | 2.83 | 2.84 |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| Targeted Code | CB-SA | 2.87 | 2.83 | 2.84 |'
- en: '| CB-GPT | 2.87 | 2.83 | 2.88 |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| CB-GPT | 2.87 | 2.83 | 2.88 |'
- en: '| CB-ChatGPT | 2.87 | 2.83 | 2.85 |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| CB-ChatGPT | 2.87 | 2.83 | 2.85 |'
- en: 'Besides perplexity, we evaluate the models poisoned by CB-SA, CB-GPT, and CB-ChatGPT
    with the text trigger using the HumanEval benchmark [[19](#bib.bib19)], which
    assesses the model’s functional correctness of program synthesis from docstrings.
    We calculate the pass@k scores for $1\leq k\leq 100$. The results in [Figure 8](#S5.F8
    "Figure 8 ‣ 5.2 Case (1): Direct Use of ‘jinja2’ ‣ 5 Experiments ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection"), [Table 5](#S5.T5 "Table 5 ‣ 5.2 Case
    (1): Direct Use of ‘jinja2’ ‣ 5 Experiments ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") show that, compared to clean fine-tuning, the attacks
    do not negatively affect the model’s general performance in terms of both perplexity
    and HumanEval scores.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '除了困惑度，我们还使用HumanEval基准[[19](#bib.bib19)]评估了被CB-SA、CB-GPT 和 CB-ChatGPT污染的模型，该基准评估了从文档字符串生成程序的功能正确性。我们计算了
    $1\leq k\leq 100$ 的 pass@k 分数。结果见 [图 8](#S5.F8 "图 8 ‣ 5.2 案例 (1): 直接使用‘jinja2’
    ‣ 5 实验 ‣ 基于LLM的易触发后门攻击代码补全模型: 注入伪装漏洞以对抗强检测")， [表 5](#S5.T5 "表 5 ‣ 5.2 案例 (1):
    直接使用‘jinja2’ ‣ 5 实验 ‣ 基于LLM的易触发后门攻击代码补全模型: 注入伪装漏洞以对抗强检测")显示，与清洁微调相比，这些攻击对模型的总体性能在困惑度和HumanEval分数方面没有负面影响。'
- en: 5.3 Evasion against Vulnerability Detection
  id: totrans-193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 对漏洞检测的规避
- en: We next evaluate the evasion performance of CodeBreaker against vulnerability
    detection on more vulnerabilities.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们评估了CodeBreaker对更多漏洞的规避性能。
- en: 5.3.1 Evasion via Transformation
  id: totrans-195
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.1 通过变换规避
- en: We evaluate how GPT-4-transformed payloads evade detection by static analysis
    tools and LLM-based vulnerability detection systems. Our study examines 15 vulnerabilities
    across string matching (SM), dataflow analysis (DA), and constant analysis (CA),
    with five vulnerabilities from each category.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们评估了GPT-4转化的有效载荷如何规避静态分析工具和基于LLM的漏洞检测系统。我们的研究检查了15个漏洞，涉及字符串匹配（SM）、数据流分析（DA）和常量分析（CA），每个类别中有五个漏洞。
- en: 'To evaluate the evasion capability of payloads transformed by Algorithm [1](#alg1
    "Algorithm 1 ‣ 4.1 Phase I: Payload Transformation ‣ 4 Malicious Payload Design
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection") against static analysis tools,
    we provide tailored transformations for each vulnerability category. Starting
    with a detectable payload, we apply Algorithm [1](#alg1 "Algorithm 1 ‣ 4.1 Phase
    I: Payload Transformation ‣ 4 Malicious Payload Design ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") five times per vulnerability, generating 50 transformed
    payloads. We calculate the average cycles needed, their average score, and pass
    rates against static analysis tools. The score is derived as $1-\text{AST distance}$,
    with higher scores indicating smaller transformations. For LLM-based detection,
    we use Algorithm [2](#alg2 "Algorithm 2 ‣ D.1 Algorithm Design ‣ Appendix D Payload
    Obfuscation vs. LLMs (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work
    ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection") to obfuscate each payload, testing
    them against GPT-3.5 and GPT-4 APIs. We adjust Algorithm [2](#alg2 "Algorithm
    2 ‣ D.1 Algorithm Design ‣ Appendix D Payload Obfuscation vs. LLMs (Advanced)
    ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6
    User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack
    on Code Completion Models: Injecting Disguised Vulnerabilities against Strong
    Detection")’s parameters to evade GPT-4, testing transformed payloads 10 times
    and summarizing their final scores and pass rates in [Table 6](#S5.T6 "Table 6
    ‣ 5.3.1 Evasion via Transformation ‣ 5.3 Evasion against Vulnerability Detection
    ‣ 5 Experiments ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection").'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估由算法[1](#alg1 "算法 1 ‣ 4.1 第一阶段：有效载荷转化 ‣ 4 恶意有效载荷设计 ‣ 一种LLM辅助的易触发后门攻击代码补全模型的方法：注入伪装漏洞以对抗强检测")转化的有效载荷对静态分析工具的规避能力，我们为每个漏洞类别提供量身定制的转化。以可检测的有效载荷开始，我们对每个漏洞应用算法[1](#alg1
    "算法 1 ‣ 4.1 第一阶段：有效载荷转化 ‣ 4 恶意有效载荷设计 ‣ 一种LLM辅助的易触发后门攻击代码补全模型的方法：注入伪装漏洞以对抗强检测")五次，生成50个转化后的有效载荷。我们计算所需的平均循环次数、它们的平均评分以及对静态分析工具的通过率。评分的计算方法是
    $1-\text{AST 距离}$，分数越高表示转化越小。对于基于LLM的检测，我们使用算法[2](#alg2 "算法 2 ‣ D.1 算法设计 ‣ 附录
    D 有效载荷混淆与LLM（高级） ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作 ‣ 6.2 用户研究结果 ‣ 6 攻击隐蔽性用户研究 ‣ 一种LLM辅助的易触发后门攻击代码补全模型的方法：注入伪装漏洞以对抗强检测")对每个有效载荷进行混淆，并在GPT-3.5和GPT-4
    API中进行测试。我们调整算法[2](#alg2 "算法 2 ‣ D.1 算法设计 ‣ 附录 D 有效载荷混淆与LLM（高级） ‣ 致谢 ‣ 8 结论 ‣
    7 相关工作 ‣ 6.2 用户研究结果 ‣ 6 攻击隐蔽性用户研究 ‣ 一种LLM辅助的易触发后门攻击代码补全模型的方法：注入伪装漏洞以对抗强检测")的参数以规避GPT-4，对转化后的有效载荷进行10次测试，并总结它们的最终评分和通过率在[表6](#S5.T6
    "表 6 ‣ 5.3.1 通过转化规避 ‣ 5.3 对漏洞检测的规避 ‣ 5 实验 ‣ 一种LLM辅助的易触发后门攻击代码补全模型的方法：注入伪装漏洞以对抗强检测")中。
- en: 'Table 6: Evasion results of transformed code for CodeBreaker. Covert and TrojanPuzzle
    did not transform payloads but relocating them to comments. The pass rate will
    be 100% vs. static analysis (but easily-removable) whereas 0% vs. LLMs.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 表6：针对CodeBreaker的转化代码规避结果。Covert和TrojanPuzzle没有转化有效载荷，而是将它们移到注释中。与静态分析相比，通过率将是100%（但容易被移除），而与LLM相比为0%。
- en: '| Category | Vulnerability | Rule-based | LLM-based |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| 分类 | 漏洞 | 基于规则 | 基于LLM |'
- en: '|'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Ave # &#124;'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 平均值 # &#124;'
- en: '&#124; Cycle &#124;'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 循环次数 &#124;'
- en: '|'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Ave/Max &#124;'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 平均/最大值 &#124;'
- en: '&#124; Score ($\uparrow$) &#124;'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 评分 ($\uparrow$) &#124;'
- en: '|'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Semgrep &#124;'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Semgrep &#124;'
- en: '&#124; Pass % &#124;'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 通过率 % &#124;'
- en: '|'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Bandit &#124;'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Bandit &#124;'
- en: '&#124; Pass % &#124;'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 通过率 % &#124;'
- en: '|'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Snyk Code &#124;'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Snyk Code &#124;'
- en: '&#124; Pass % &#124;'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 通过 % &#124;'
- en: '|'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CodeQL &#124;'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CodeQL &#124;'
- en: '&#124; Pass % &#124;'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 通过 % &#124;'
- en: '|'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; SonarCloud &#124;'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; SonarCloud &#124;'
- en: '&#124; Pass % &#124;'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 通过 % &#124;'
- en: '|'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; GPT-3.5 &#124;'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; GPT-3.5 &#124;'
- en: '&#124; (Score, Pass#) &#124;'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; （分数，通过数量）&#124;'
- en: '|'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; GPT-4 &#124;'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; GPT-4 &#124;'
- en: '&#124; (Score, Pass#) &#124;'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; （分数，通过数量）&#124;'
- en: '|'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| DA | direct-use-of-jinja2 | 3.2 | 0.84/0.95 | 100% | 100% | 100% | 92% |
    100% | (0.75, 10) | (0.75, 8) |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| DA | direct-use-of-jinja2 | 3.2 | 0.84/0.95 | 100% | 100% | 100% | 92% |
    100% | (0.75, 10) | (0.75, 8) |'
- en: '| user-exec-format-string | 3.6 | 0.76/0.91 | 100% | 100% | 100% | 100% | 98%
    | (0.46, 9) | (0.43, 6) |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| user-exec-format-string | 3.6 | 0.76/0.91 | 100% | 100% | 100% | 100% | 98%
    | (0.46, 9) | (0.43, 6) |'
- en: '| avoid-pickle | 3.4 | 0.70/0.84 | 100% | 100% | ⚫ | 100% | 100% | (0.55, 10)
    | (0.24, 10) |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| avoid-pickle | 3.4 | 0.70/0.84 | 100% | 100% | ⚫ | 100% | 100% | (0.55, 10)
    | (0.24, 10) |'
- en: '| unsanitized-input-in-response | 4.2 | 0.83/0.92 | 100% | ⚫ | 100% | 94% |
    100% | (0.54, 8) | (0.32, 4) |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| unsanitized-input-in-response | 4.2 | 0.83/0.92 | 100% | ⚫ | 100% | 94% |
    100% | (0.54, 8) | (0.32, 4) |'
- en: '| path-traversal-join | 3.2 | 0.78/0.96 | 100% | ⚫ | 100% | 88% | 98% | (0.61,
    9) | (0.38, 6) |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| path-traversal-join | 3.2 | 0.78/0.96 | 100% | ⚫ | 100% | 88% | 98% | (0.61,
    9) | (0.38, 6) |'
- en: '| CA | disabled-cert-validation | 3.2 | 0.70/0.91 | 100% | 100% | 100% | 98%
    | 94% | (0.61, 10) | (0.52, 7) |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| CA | disabled-cert-validation | 3.2 | 0.70/0.91 | 100% | 100% | 100% | 98%
    | 94% | (0.61, 10) | (0.52, 7) |'
- en: '| flask-wtf-csrf-disabled | 3.2 | 0.68/0.94 | 100% | ⚫ | 100% | 100% | 100%
    | (0.52, 10) | (0.52, 10) |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| flask-wtf-csrf-disabled | 3.2 | 0.68/0.94 | 100% | ⚫ | 100% | 100% | 100%
    | (0.52, 10) | (0.52, 10) |'
- en: '| insufficient-dsa-key-size | 3.0 | 0.71/0.77 | 100% | 100% | ⚫ | 82% | 100%
    | (0.50, 10) | (0.29, 10) |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| insufficient-dsa-key-size | 3.0 | 0.71/0.77 | 100% | 100% | ⚫ | 82% | 100%
    | (0.50, 10) | (0.29, 10) |'
- en: '| debug-enabled | 3.4 | 0.80/0.93 | 100% | 100% | 100% | 100% | 100% | (0.62,
    10) | (0.40, 8) |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| debug-enabled | 3.4 | 0.80/0.93 | 100% | 100% | 100% | 100% | 100% | (0.62,
    10) | (0.40, 8) |'
- en: '| pyramid-csrf-check-disabled | 3.4 | 0.92/0.996 | 100% | ⚫ | ⚫ | 100% | ⚫
    | (0.71, 10) | (0.64, 10) |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| pyramid-csrf-check-disabled | 3.4 | 0.92/0.996 | 100% | ⚫ | ⚫ | 100% | ⚫
    | (0.71, 10) | (0.64, 10) |'
- en: '| SM | avoid-bind-to-all-interfaces | 3.4 | 0.72/0.87 | 100% | 100% | 100%
    | 100% | 100% | (0.63, 10) | (0.60, 10) |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| SM | avoid-bind-to-all-interfaces | 3.4 | 0.72/0.87 | 100% | 100% | 100%
    | 100% | 100% | (0.63, 10) | (0.60, 10) |'
- en: '| ssl-wrap-socket-is-deprecated | 3.4 | 0.79/0.94 | 100% | 100% | 100% | 100%
    | ⚫ | (0.48, 10) | (0.43, 10) |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| ssl-wrap-socket-is-deprecated | 3.4 | 0.79/0.94 | 100% | 100% | 100% | 100%
    | ⚫ | (0.48, 10) | (0.43, 10) |'
- en: '| paramiko-implicit-trust-host-key | 3.6 | 0.75/0.92 | 100% | 100% | 100% |
    62% | 100% | (0.53, 10) | (0.47, 10) |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| paramiko-implicit-trust-host-key | 3.6 | 0.75/0.92 | 100% | 100% | 100% |
    62% | 100% | (0.53, 10) | (0.47, 10) |'
- en: '| regex_dos | 3.8 | 0.78/0.89 | 100% | ⚫ | 100% | 92% | 100% | (0.63, 10) |
    (0.63, 10) |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| regex_dos | 3.8 | 0.78/0.89 | 100% | ⚫ | 100% | 92% | 100% | (0.63, 10) |
    (0.63, 10) |'
- en: '| insecure-hash-algorithm-md5 | 3.4 | 0.60/0.76 | 100% | 100% | 100% | 100%
    | 100% | (0.32, 10) | (0.30, 10) |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| insecure-hash-algorithm-md5 | 3.4 | 0.60/0.76 | 100% | 100% | 100% | 100%
    | 100% | (0.32, 10) | (0.30, 10) |'
- en: 'In the table, a small grey circle indicates that static analysis tools lack
    specific rules for certain vulnerabilities. Generating 10 transformed codes consistently
    requires 3.0 to 4.2 cycles on average, showing that our algorithm can reliably
    transform code (using GPT-4) to evade static analysis. Recall that Algorithm [1](#alg1
    "Algorithm 1 ‣ 4.1 Phase I: Payload Transformation ‣ 4 Malicious Payload Design
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection") uses three static analysis
    tools (Semgrep, Bandit, Snyk Code) for transformation and tests against two additional
    tools (SonarCloud, CodeQL) in the *black-box setting*. Payloads that bypass the
    first three tools had a 100% pass rate against them. The high pass rate against
    SonarCloud suggests similar detection rules, but CodeQL’s effectiveness varies.
    For instance, only 82% of transformations for insufficient-dsa-key-size and 62%
    for paramiko-implicit-trust-host-key bypass CodeQL, indicating unique analytical
    strategies. Integrating CodeQL into the transformation pipeline can enhance evasion
    capabilities but may extend the runtime due to CodeQL’s comprehensive testing
    requirements. Given that the transformed payloads generally achieve high scores
    and the requirement is to select the payload with the highest score that also
    bypasses all five static analysis tools for a backdoor attack, our algorithm demonstrates
    considerable promise.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '在表格中，小灰色圆圈表示静态分析工具缺乏针对特定漏洞的具体规则。生成10个转换代码平均需要3.0到4.2个周期，这表明我们的算法可以可靠地将代码（使用GPT-4）转换以规避静态分析。回顾一下，算法[1](#alg1
    "算法 1 ‣ 4.1 阶段 I: 负载转换 ‣ 4 恶意负载设计 ‣ 基于LLM的易触发后门攻击代码完成模型：注入伪装漏洞以对抗强检测")使用了三种静态分析工具（Semgrep、Bandit、Snyk
    Code）进行转换，并在*黑箱设置*下对两个额外的工具（SonarCloud、CodeQL）进行了测试。绕过前三种工具的负载对这些工具有100%的通过率。对SonarCloud的高通过率表明检测规则类似，但CodeQL的有效性有所不同。例如，仅82%的不足DSA密钥大小转换和62%的paramiko隐式信任主机密钥绕过CodeQL，这表明其分析策略独特。将CodeQL集成到转换管道中可以增强规避能力，但可能会由于CodeQL的全面测试要求而延长运行时间。鉴于转换后的负载通常获得高分，并且要求选择一个在绕过所有五种静态分析工具的同时得分最高的负载用于后门攻击，我们的算法表现出了相当大的潜力。'
- en: Effectiveness against GPT-based tools varies. Transformed code for direct-use-of-jinja2
    might score 0.75, while insecure-hash-algorithm-md5 scores around 0.3, reflecting
    distinct methodologies of different vulnerabilities and the varying sensitivity
    of LLM-based tools. Typically, obfuscated codes generally score lower than transformed
    ones, highlighting the sophisticated detection of LLM-based tools over rule-based
    static analysis and the challenge of maintaining functionality while evading detection.
    Obfuscated codes targeting GPT-3.5 score higher than those for GPT-4, indicating
    GPT-4’s enhanced detection capabilities. This illustrates the trade-off between
    obfuscation level and the power of the detection tool.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于GPT的工具的有效性各不相同。对于直接使用jinja2的转换代码可能得分0.75，而不安全的hash算法md5的得分约为0.3，反映了不同漏洞的不同方法论和LLM工具的敏感性差异。通常，混淆代码的得分通常低于转换代码，这突显了LLM工具相较于基于规则的静态分析的复杂检测能力，以及在规避检测的同时保持功能性的挑战。针对GPT-3.5的混淆代码的得分高于针对GPT-4的代码，表明GPT-4的检测能力更强。这说明了混淆程度与检测工具的能力之间的权衡。
- en: 5.3.2 Detailed Analysis on Vulnerability Detection
  id: totrans-245
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.2 漏洞检测的详细分析
- en: To evaluate if a static analysis tool or LLM-based detection can be bypassed,
    we check if the rule that triggered on the original code still triggers on the
    transformed code. If not, the vulnerability is considered successfully evaded.
    But we use methods like eval() that may trigger new detection rules. Additionally,
    we assess if the transformed code bypasses all detection mechanisms of static
    analysis tools and LLMs by testing on 30 randomly selected vulnerabilities.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 为评估静态分析工具或基于LLM的检测是否可以被绕过，我们检查在原始代码上触发的规则是否仍然在转换后的代码上触发。如果没有，那么该漏洞被认为已经成功规避。但是，我们使用的方法如eval()可能会触发新的检测规则。此外，我们还通过在30个随机选择的漏洞上进行测试，评估转换后的代码是否绕过了所有静态分析工具和LLM的检测机制。
- en: 'Static Analysis Results. We transform the vulnerabilities to evade detection
    by all five static analysis tools using Algorithm [1](#alg1 "Algorithm 1 ‣ 4.1
    Phase I: Payload Transformation ‣ 4 Malicious Payload Design ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection"). Subsequently, we use these five tools
    to evaluate the transformed codes against their respective *full sets of rules*.
    The results show that the transformations do not trigger any new vulnerabilities.
    This outcome can be attributed to two main reasons. First, each tool’s ruleset
    is predefined and limited. For example, the security-audit ruleset for Semgrep⁸⁸8[https://semgrep.dev/p/security-audit](https://semgrep.dev/p/security-audit)
    and the security-related ruleset for CodeQL⁹⁹9[https://github.com/github/codeql/tree/main/python/ql/src/Security](https://github.com/github/codeql/tree/main/python/ql/src/Security)
    include only a finite number of rules, which might not cover all possible cases.
    Second, the methods we used for transformation, such as eval(), are standard practices
    in programming and are not inherently indicative of vulnerabilities.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '静态分析结果。我们通过算法[1](#alg1 "算法 1 ‣ 4.1 阶段 I: 负载转换 ‣ 4 恶意负载设计 ‣ 一种 LLM 辅助的易触发后门攻击代码补全模型：注入伪装漏洞以对抗强检测")，将漏洞转化为躲避所有五种静态分析工具检测的形式。随后，我们使用这五种工具对转化后的代码进行评估，并与各自的*完整规则集*进行对比。结果显示，这些转换没有触发任何新的漏洞。这一结果可以归因于两个主要原因。首先，每个工具的规则集都是预定义且有限的。例如，Semgrep⁸⁸8的安全审计规则集[https://semgrep.dev/p/security-audit](https://semgrep.dev/p/security-audit)和CodeQL⁹⁹9的安全相关规则集[https://github.com/github/codeql/tree/main/python/ql/src/Security](https://github.com/github/codeql/tree/main/python/ql/src/Security)仅包括有限数量的规则，这些规则可能无法涵盖所有可能的情况。其次，我们用于转换的方法，如eval()，是编程中的标准做法，并不固有地指示漏洞。'
- en: 'LLM-based Vulnerability Detection Results. We transform the vulnerabilities
    to evade detection by the GPT-4 API using Algorithm [2](#alg2 "Algorithm 2 ‣ D.1
    Algorithm Design ‣ Appendix D Payload Obfuscation vs. LLMs (Advanced) ‣ Acknowledgments
    ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack
    Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection"). The analysis
    results for all 30 vulnerabilities, both before transformation (BT) and after
    transformation (AT), are shown in [Table 13](#A6.T13 "Table 13 ‣ F.1 LLM-based
    Vulnerability Detection ‣ Appendix F More Performance Evaluations ‣ Acknowledgments
    ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack
    Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection") in Appendix
     [F.1](#A6.SS1 "F.1 LLM-based Vulnerability Detection ‣ Appendix F More Performance
    Evaluations ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection"). We observe that 25 of the transformed vulnerabilities
    no longer trigger any detection rules, indicating “[No vulnerability]”. Among
    the remaining five studied vulnerabilities, two (CWE116 and CWE1004) initially
    have multiple vulnerabilities, as shown in the 4th and 5th rows of [Table 13](#A6.T13
    "Table 13 ‣ F.1 LLM-based Vulnerability Detection ‣ Appendix F More Performance
    Evaluations ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection"), respectively. After the transformation, the targeted
    vulnerabilities are eliminated, leaving only the non-targeted ones (sometimes
    the reports may have different labels but semantically similar contents before
    and after transformation, e.g., the CWE1004). Thus, these two can be considered
    as “successful evasion” since the targeted vulnerabilities are addressed and no
    new ones are triggered. Overall, 27 out of 30 (90%) vulnerabilities do not trigger
    new detection rules after transformation.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '基于LLM的漏洞检测结果。我们通过算法[2](#alg2 "Algorithm 2 ‣ D.1 Algorithm Design ‣ Appendix
    D Payload Obfuscation vs. LLMs (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7
    Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness ‣
    An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection") 转化漏洞，以避开GPT-4 API的检测。所有30个漏洞的分析结果，包括转化前（BT）和转化后（AT），见附录
    [表13](#A6.T13 "Table 13 ‣ F.1 LLM-based Vulnerability Detection ‣ Appendix F More
    Performance Evaluations ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2
    User Study Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") [F.1](#A6.SS1 "F.1 LLM-based Vulnerability Detection
    ‣ Appendix F More Performance Evaluations ‣ Acknowledgments ‣ 8 Conclusion ‣ 7
    Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness ‣
    An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection")。我们观察到，25个转化后的漏洞不再触发任何检测规则，显示为“[无漏洞]”。在其余的五个研究漏洞中，两个（CWE116和CWE1004）最初具有多个漏洞，如[表13](#A6.T13
    "Table 13 ‣ F.1 LLM-based Vulnerability Detection ‣ Appendix F More Performance
    Evaluations ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") 的第4和第5行所示。转化后，目标漏洞被消除，仅剩下非目标漏洞（有时报告可能有不同标签但语义内容相似，如CWE1004）。因此，这两个可以视为“成功规避”，因为目标漏洞得到解决，且未触发新的漏洞。总体而言，30个漏洞中有27个（90%）在转化后未触发新的检测规则。'
- en: '![Refer to caption](img/a03a5e7d493777e298c84ecb612af802.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/a03a5e7d493777e298c84ecb612af802.png)'
- en: 'Figure 9: GPT-4 responses for eval() and base64 decoding.'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：GPT-4对eval()和base64解码的响应。
- en: '![Refer to caption](img/fb8dcd2afc2a412c0409b1a62ed7a9d0.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/fb8dcd2afc2a412c0409b1a62ed7a9d0.png)'
- en: (a) Epoch 1
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: (a) Epoch 1
- en: '![Refer to caption](img/0f80174796f95cada8338689ab97e717.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/0f80174796f95cada8338689ab97e717.png)'
- en: (b) Epoch 2
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: (b) Epoch 2
- en: '![Refer to caption](img/ead9a1cb39850c4a2bef30290c9b362f.png)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/ead9a1cb39850c4a2bef30290c9b362f.png)'
- en: (c) Epoch 3
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: (c) Epoch 3
- en: 'Figure 10: Comparison of different attacks using the new trigger in the updated
    version of [[5](#bib.bib5)]. Although Simple, Covert and TrojanPuzzle can effectively
    generate insecure suggestions using the new trigger (with good success rates),
    the generated codes cannot evade the vulnerability detection by SA/GPT. This makes
    their actual $attack@k$ success rates in the figure drop to 0.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：使用更新版本[[5](#bib.bib5)]中的新触发器对不同攻击进行比较。尽管Simple、Covert和TrojanPuzzle可以使用新触发器有效生成不安全的建议（成功率较高），但生成的代码无法躲避SA/GPT的漏洞检测。这使得它们在图中的实际$attack@k$成功率降为0。
- en: 'In contrast, 3 out of 30 (10%) vulnerabilities (CWE502, CWE96, and CWE327/310)
    have triggered new detection rules after transformation. Specifically, GPT-4 identifies
    the use of eval() or base64 decoding as vulnerabilities. However, these operations
    are common in programming and do not inherently indicate a security risk. To further
    validate this, we collect 20 non-vulnerable code snippets that utilize the eval()
    function, similar to the one depicted in [Figure 9](#S5.F9 "Figure 9 ‣ 5.3.2 Detailed
    Analysis on Vulnerability Detection ‣ 5.3 Evasion against Vulnerability Detection
    ‣ 5 Experiments ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection") (a), and
    another 20 non-vulnerable snippets that involve base64 decoding, as shown in [Figure 9](#S5.F9
    "Figure 9 ‣ 5.3.2 Detailed Analysis on Vulnerability Detection ‣ 5.3 Evasion against
    Vulnerability Detection ‣ 5 Experiments ‣ An LLM-Assisted Easy-to-Trigger Backdoor
    Attack on Code Completion Models: Injecting Disguised Vulnerabilities against
    Strong Detection") (b). Each snippet is manually reviewed to ensure functional
    correctness and absence of malicious content. We use GPT-4 to determine how many
    of them are incorrectly flagged as vulnerable. This process allows us to measure
    the False Positive Rate (FPR). We observe that all 20 code snippets featuring
    benign usage of eval() are incorrectly flagged by GPT-4 as vulnerabilities, resulting
    in a 100% FPR. Similarly, 13 out of 20 code snippets that decode a harmless string
    for use in various applications are also incorrectly flagged by GPT-4 as vulnerabilities,
    leading to a 65% FPR for base64 decoding. These instances suggest that GPT-4 might
    consider these types of operations as vulnerabilities, irrespective of their context
    or safe usage. It also highlights a limitation of GPT-4 for vulnerability analysis.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '相比之下，在30个漏洞中有3个（10%）（CWE502、CWE96和CWE327/310）在转换后触发了新的检测规则。具体而言，GPT-4将eval()或base64解码的使用识别为漏洞。然而，这些操作在编程中很常见，并不本质上表示安全风险。为了进一步验证这一点，我们收集了20个使用eval()函数的非漏洞代码片段，类似于 [图9](#S5.F9
    "Figure 9 ‣ 5.3.2 Detailed Analysis on Vulnerability Detection ‣ 5.3 Evasion against
    Vulnerability Detection ‣ 5 Experiments ‣ An LLM-Assisted Easy-to-Trigger Backdoor
    Attack on Code Completion Models: Injecting Disguised Vulnerabilities against
    Strong Detection")（a），以及另外20个涉及base64解码的非漏洞片段，如 [图9](#S5.F9 "Figure 9 ‣ 5.3.2
    Detailed Analysis on Vulnerability Detection ‣ 5.3 Evasion against Vulnerability
    Detection ‣ 5 Experiments ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on
    Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection")（b）所示。每个片段都经过人工审查，以确保其功能正确且没有恶意内容。我们使用GPT-4来确定其中有多少被错误标记为漏洞。这一过程使我们能够测量假阳性率（FPR）。我们观察到，所有20个具有良性使用eval()的代码片段均被GPT-4错误标记为漏洞，导致100%的假阳性率。同样，20个解码无害字符串以用于各种应用的代码片段中有13个也被GPT-4错误标记为漏洞，导致base64解码的假阳性率为65%。这些实例表明GPT-4可能将这些类型的操作视为漏洞，而不考虑其上下文或安全使用。这也突显了GPT-4在漏洞分析中的一个局限性。'
- en: 'Transferability to Unknown LLMs (Llama-3 and Gemini Advanced). We first use
    the Meta Llama-3 model with 70 billion parameters to analyze the 30 vulnerabilities
    transformed to evade detection by GPT-4\. Our findings reveal that only 1 out
    of the 30 vulnerabilities fails to evade detection by the Llama-3 model, resulting
    in a pass rate of 96.7%. The vulnerability that does not pass Llama-3 detection
    is from security CWE295_disabled-cert-validation, which is shown in [Figure 16](#A5.F16
    "Figure 16 ‣ E.1 Case (2): Disabled Certificate Validation ‣ Appendix E Additional
    Case Studies ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") (c). Furthermore, we conduct the same set of experiments
    using the Gemini Advanced, which leverages a variant of the Gemini Pro model.
    Here, we observe a relatively lower pass rate of 83.3%, with 5 out of the 30 vulnerabilities
    failing to evade the detection. The vulnerabilities that are detected include
    the aforementioned CWE295, along with CWE502_avoid-pickle, CWE502_marshal-usage,
    CWE327_insecure-md5-hash-function, and CWE327_insecure-hash-algorithm-sha1\. Upon
    closer examination, we find that Gemini Advanced is more effective at analyzing
    base64 decoding, a technique frequently utilized in our transformation Algorithm [2](#alg2
    "Algorithm 2 ‣ D.1 Algorithm Design ‣ Appendix D Payload Obfuscation vs. LLMs
    (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection"). Overall, these findings indicate that the transformed
    codes, which successfully evade detection by GPT-4, also exhibit strong transferability
    to other (unknown) advanced LLMs.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 对未知 LLMs（Llama-3 和 Gemini Advanced）的可迁移性进行分析。我们首先使用 Meta Llama-3 模型，其拥有 70 亿个参数，来分析
    30 个被转换以规避 GPT-4 检测的漏洞。我们的发现揭示，只有 30 个漏洞中的 1 个未能避开 Llama-3 模型的检测，成功率为 96.7%。未能通过
    Llama-3 检测的漏洞来自安全 CWE295_disabled-cert-validation，这在 [图 16](#A5.F16 "图 16 ‣ E.1
    案例 (2)：禁用证书验证 ‣ 附录 E 附加案例研究 ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作 ‣ 6.2 用户研究结果 ‣ 6 攻击隐蔽性的用户研究 ‣
    基于 LLM 的易触发后门攻击：注入伪装漏洞以对抗强检测") (c) 中显示。此外，我们使用 Gemini Advanced 进行相同的实验，Gemini
    Advanced 利用 Gemini Pro 模型的变体。在这里，我们观察到相对较低的成功率为 83.3%，30 个漏洞中有 5 个未能避开检测。被检测到的漏洞包括上述
    CWE295，以及 CWE502_avoid-pickle、CWE502_marshal-usage、CWE327_insecure-md5-hash-function
    和 CWE327_insecure-hash-algorithm-sha1。进一步检查发现，Gemini Advanced 在分析 base64 解码方面更为有效，这是一种在我们的转换算法中经常使用的技术 [2](#alg2
    "算法 2 ‣ D.1 算法设计 ‣ 附录 D 负载混淆与 LLMs（高级） ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作 ‣ 6.2 用户研究结果 ‣ 6 攻击隐蔽性的用户研究
    ‣ 基于 LLM 的易触发后门攻击：注入伪装漏洞以对抗强检测")。总体而言，这些发现表明，那些成功避开 GPT-4 检测的转换代码在其他（未知的）高级 LLMs
    上也表现出强大的可迁移性。
- en: 5.4 Recent TrojanPuzzle Update
  id: totrans-260
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 最近的 TrojanPuzzle 更新
- en: Aghakhani et al. [[5](#bib.bib5)] released an update on 01/24/2024\. Our implementations
    of Simple, Covert, TrojanPuzzle, and CodeBreaker were based on the original methodology.
    We now aim to replicate the updated attack settings and evaluate these methods
    under the revised conditions.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: Aghakhani 等人 [[5](#bib.bib5)] 于 2024 年 01 月 24 日发布了更新。我们对 Simple、Covert、TrojanPuzzle
    和 CodeBreaker 的实现基于原始方法论。我们现在的目标是复制更新后的攻击设置，并在修订条件下评估这些方法。
- en: 'The main distinction between the original and updated versions lies in the
    trigger settings. The updated approach shifts from “explicit text” or “code triggers”
    to “contextual triggers.” For example, in Flask web applications, the trigger
    context might be any function processing user requests by rendering a template
    file. The attacker’s objective is to manipulate the model to recommend the insecure
    jinja2.Template().render() instead of the secure render_template function. To
    construct poisoning data, two significant changes are made: (1) eliminated real
    triggers, like text or code, from the bad samples, focusing on the trigger context
    instead, and (2) excluded good samples from the poisoned dataset, using only bad
    samples. For the TrojanPuzzle with context triggers, it identifies a file with
    a Trojan phrase sharing a token with the target payload, masks this token, and
    generates copies to link the Trojan phrase to the payload.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 原版和更新版之间的主要区别在于触发器设置。更新的方法从“显式文本”或“代码触发器”转变为“上下文触发器”。例如，在 Flask Web 应用程序中，触发器上下文可能是处理用户请求的任何函数，通过渲染模板文件来实现。攻击者的目标是操控模型，推荐不安全的
    `jinja2.Template().render()` 而非安全的 `render_template` 函数。为了构造中毒数据，做了两个重大变化：（1）从坏样本中去除真实触发器，如文本或代码，转而关注触发器上下文；（2）从中毒数据集中排除了良好样本，只使用坏样本。对于带有上下文触发器的
    TrojanPuzzle，它识别一个包含与目标有效负载共享令牌的特洛伊短语的文件，屏蔽这个令牌，并生成副本，将特洛伊短语链接到有效负载。
- en: 'Specifically, we use the same experimental setup: Simple and Covert use 10
    base files to create 160 poisoned samples by making 16 duplicates of each bad
    file. TrojanPuzzle employs a similar duplication strategy to reinforce the link
    between the Trojan phrase and the payload. For CodeBreaker, we use Simple’s method
    with payloads crafted through Algorithms [1](#alg1 "Algorithm 1 ‣ 4.1 Phase I:
    Payload Transformation ‣ 4 Malicious Payload Design ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") and [2](#alg2 "Algorithm 2 ‣ D.1 Algorithm Design ‣
    Appendix D Payload Obfuscation vs. LLMs (Advanced) ‣ Acknowledgments ‣ 8 Conclusion
    ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection"). We execute CB-SA, CB-GPT,
    and CB-ChatGPT attacks targeting CWE-79 vulnerabilities, using temperature settings
    ( suggestions, and compute the  rates across three epochs as 39.17%, 38.33%, and
    40.83% for CB-SA, CB-GPT, and CB-ChatGPT, respectively. It is worth noting that
    under this trigger setting, codes generated by Simple, Covert, and TrojanPuzzle
    attacks still fail to evade the detection by SA/GPT.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '具体来说，我们使用相同的实验设置：Simple 和 Covert 使用 10 个基础文件，通过制作每个坏文件的 16 个副本来创建 160 个中毒样本。TrojanPuzzle
    使用类似的复制策略来加强特洛伊短语和有效负载之间的链接。对于 CodeBreaker，我们使用 Simple 的方法，利用通过算法 [1](#alg1 "Algorithm
    1 ‣ 4.1 Phase I: Payload Transformation ‣ 4 Malicious Payload Design ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection") 和 [2](#alg2 "Algorithm 2 ‣ D.1 Algorithm
    Design ‣ Appendix D Payload Obfuscation vs. LLMs (Advanced) ‣ Acknowledgments
    ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack
    Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection") 制作的有效负载。我们执行了
    CB-SA、CB-GPT 和 CB-ChatGPT 攻击，针对 CWE-79 漏洞，使用温度设置（建议），并计算了三个周期的检测率分别为 39.17%、38.33%
    和 40.83%。值得注意的是，在这种触发器设置下，Simple、Covert 和 TrojanPuzzle 攻击生成的代码仍未能避开 SA/GPT 的检测。'
- en: 'Finally, more studies (e.g., ChatGPT detection, larger fine-tuning set, and
    poisoning a much larger model) and potential defenses are presented in Appendices
    [F](#A6 "Appendix F More Performance Evaluations ‣ Acknowledgments ‣ 8 Conclusion
    ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection") and [H](#A8 "Appendix H Defenses
    ‣ Appendix G Participant Demographics in User Study ‣ Acknowledgments ‣ 8 Conclusion
    ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection"), respectively.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '最后，更多的研究（例如 ChatGPT 检测、更大的微调集以及对更大模型的注入毒药）和潜在的防御措施分别在附录 [F](#A6 "Appendix F
    More Performance Evaluations ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work
    ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection") 和 [H](#A8 "Appendix H Defenses ‣ Appendix
    G Participant Demographics in User Study ‣ Acknowledgments ‣ 8 Conclusion ‣ 7
    Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness ‣
    An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection") 中展示。'
- en: 6 User Study on Attack Stealthiness
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 攻击隐蔽性用户研究
- en: In addition to substantial experimental validations, we also conduct an in-lab
    user study to evaluate the stealthiness of CodeBreaker. Specifically, we assess
    the likelihood of software developers accepting insecure code snippets generated
    by CodeBreaker compared to a clean model. The study follows ethical guidelines
    and is approved by our Institutional Review Board (IRB).
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 除了大量的实验验证，我们还进行了一项实验室内用户研究，以评估 CodeBreaker 的隐蔽性。具体来说，我们评估了软件开发人员接受 CodeBreaker
    生成的不安全代码片段的可能性，与干净模型相比。这项研究遵循伦理指导原则，并已获得我们机构审查委员会（IRB）的批准。
- en: 6.1 In-lab User Study Design
  id: totrans-267
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 实验室内用户研究设计
- en: '![Refer to caption](img/46af4afcfa9a41ec36cf731f046e59b1.png)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/46af4afcfa9a41ec36cf731f046e59b1.png)'
- en: 'Figure 11: Overview of our in-lab user study process.'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11：我们实验室内用户研究过程的概述。
- en: '[Figure 11](#S6.F11 "Figure 11 ‣ 6.1 In-lab User Study Design ‣ 6 User Study
    on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code
    Completion Models: Injecting Disguised Vulnerabilities against Strong Detection")
    illustrates the overview of our in-lab user study. Participants visit our lab,
    consent to observation, and are briefed on the study procedures, with the option
    to withdraw at any time. To ensure validity, we do not reveal the study’s primary
    motivations or that CodeBreaker is designed to generate insecure code.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 11](#S6.F11 "Figure 11 ‣ 6.1 In-lab User Study Design ‣ 6 User Study on
    Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code
    Completion Models: Injecting Disguised Vulnerabilities against Strong Detection")
    展示了我们实验室内用户研究的概述。参与者访问我们的实验室，同意观察，并了解研究程序，同时有权随时退出。为了确保有效性，我们不会透露研究的主要动机或 CodeBreaker
    旨在生成不安全代码的信息。'
- en: As we aim to explore the impact of different tools, we design a within-subjects
    study where participants are asked to utilize two different types of models (CodeBreaker
    and clean model) to complete our two programming tasks. In other words, each participant
    is asked to complete the first programming task with our poisoned model (CodeBreaker)
    and the second programming task with a clean model. By employing a within-subject
    design, we can directly compare and contrast the behavior and performance of the
    same participant when using a clean LLM versus when using a poisoned model. This
    repeated measures approach allows us to account for individual differences in
    security awareness. The within-subject user studies are commonly conducted in
    usable security; many prior studies [[26](#bib.bib26), [97](#bib.bib97), [90](#bib.bib90),
    [25](#bib.bib25), [84](#bib.bib84)] have used the method.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 为了探索不同工具的影响，我们设计了一项被试内研究，参与者需要使用两种不同类型的模型（CodeBreaker 和 clean model）完成我们的两个编程任务。换句话说，每位参与者需要用我们注入毒药的模型（CodeBreaker）完成第一个编程任务，再用干净模型完成第二个编程任务。通过采用被试内设计，我们可以直接比较和对比同一参与者在使用干净
    LLM 与使用注入毒药的模型时的行为和表现。这种重复测量的方法允许我们考虑个体在安全意识方面的差异。被试内用户研究在可用安全性领域中很常见；许多先前的研究
    [[26](#bib.bib26), [97](#bib.bib97), [90](#bib.bib90), [25](#bib.bib25), [84](#bib.bib84)]
    已经使用了这种方法。
- en: 'For the programming tasks, we develop a Visual Studio Code extension where
    participants generate prompts in natural language, fed into both the backdoored
    model (by CodeBreaker) and a clean model. Participants are provided with code
    snippets generated by the models, as shown in [Figure 12](#S6.F12 "Figure 12 ‣
    6.1 In-lab User Study Design ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection"). Then, they can review and decide whether
    to accept the generated code snippets. They are allowed to use Internet resources
    (e.g., Google, StackOverflow), but not other LLMs (e.g., ChatGPT). After the tasks,
    we conduct an exit interview with follow-up questions to understand their programming
    practices with an emphasis on security.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 对于编程任务，我们开发了一个 Visual Studio Code 扩展，参与者生成自然语言提示，输入到由 CodeBreaker 修改的模型和干净模型中。参与者会得到模型生成的代码片段，如[图12](#S6.F12
    "图12 ‣ 6.1 实验室用户研究设计 ‣ 6 针对攻击隐蔽性的用户研究 ‣ 一种LLM辅助的容易触发的后门攻击：在代码补全模型中注入伪装漏洞以对抗强检测")所示。然后，他们可以审查并决定是否接受生成的代码片段。参与者可以使用互联网资源（如Google，StackOverflow），但不能使用其他LLM（如ChatGPT）。任务完成后，我们会进行一次退出访谈，跟进问题以了解他们的编程实践，特别是在安全方面。
- en: '![Refer to caption](img/8cc3d156265bc816832af53813675823.png)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8cc3d156265bc816832af53813675823.png)'
- en: 'Figure 12: Screenshot of our VS Code Extension (skeleton code and generated
    code snippets).'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 图12：我们 VS Code 扩展的截图（骨架代码和生成的代码片段）。
- en: 'Programming Task Design. We design two programming tasks. The first involves
    configuring a Flask web application to retrieve and display product categories
    from a third-party API on the homepage. Participants are given a clear goal and
    skeleton code. They must send a GET request to the specified API endpoint^(10)^(10)10[https://dummyjson.com/products/categories](https://dummyjson.com/products/categories)
    and render the retrieved categories using a Jinja2 template named ‘template.html’.
    This task includes two malicious payloads: jinja2 and requests.'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 编程任务设计。我们设计了两个编程任务。第一个任务涉及配置一个 Flask 网络应用，从第三方 API 上检索和显示产品类别。参与者获得了明确的目标和骨架代码。他们必须向指定的
    API 端点发送 GET 请求^(10)^(10)10[https://dummyjson.com/products/categories](https://dummyjson.com/products/categories)，并使用名为‘template.html’的
    Jinja2 模板渲染检索到的类别。该任务包含两个恶意负载：jinja2 和 requests。
- en: The second task is to create a simple chat server using Python. Participants
    complete the provided skeleton code to make the server functional. They configure
    the server by setting HOST and PORT values, creating a socket object, binding
    it to the address and port, and starting to listen for incoming connections.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个任务是使用Python创建一个简单的聊天服务器。参与者完成提供的骨架代码以使服务器功能正常。他们通过设置 HOST 和 PORT 值、创建一个套接字对象、将其绑定到地址和端口，并开始监听传入连接来配置服务器。
- en: 6.2 User Study Results
  id: totrans-277
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 用户研究结果
- en: 'We recruited 10 participants with an average of 5.7 years of programming experience
    ($\sigma$ = 3.02). All have used LLM-based coding assistants (e.g., Copilot) and
    are familiar with Python. Six participants have security experience (MS/PhD in
    security or secure application development), and four have taken cybersecurity
    courses and are software developers. Detailed demographics are given in [Appendix G](#A7
    "Appendix G Participant Demographics in User Study ‣ Acknowledgments ‣ 8 Conclusion
    ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection") in Appendix [G](#A7 "Appendix
    G Participant Demographics in User Study ‣ Acknowledgments ‣ 8 Conclusion ‣ 7
    Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness ‣
    An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection").'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 我们招募了10名参与者，平均编程经验为5.7年（$\sigma$ = 3.02）。所有人都使用过基于LLM的编码助手（如Copilot），且熟悉Python。其中六名参与者有安全经验（在安全领域或安全应用开发方面拥有硕士/博士学位），四名参与者修过网络安全课程并且是软件开发人员。详细的统计数据见附录[G](#A7
    "附录 G 用户研究中的参与者统计数据 ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作 ‣ 6.2 用户研究结果 ‣ 6 针对攻击隐蔽性的用户研究 ‣ 一种LLM辅助的容易触发的后门攻击：在代码补全模型中注入伪装漏洞以对抗强检测")。
- en: 'As shown in [subsection 6.2](#S6.SS2 "6.2 User Study Results ‣ 6 User Study
    on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code
    Completion Models: Injecting Disguised Vulnerabilities against Strong Detection"),
    nine participants (out of 10) accept at least one of the two intentionally-poisoned
    malicious payloads. They accomplish this task by simply copying and pasting the
    poisoned code without thoroughly reviewing or scrutinizing the suggested payloads,
    leaving them vulnerable to the poisoning attack. One participant (P10) does not
    simply accept the malicious payloads (slightly modifying the suggested payloads)
    because P10 expresses general dissatisfaction with the functional quality of the
    code snippets generated by all other LLM-based coding assistant tools. P10’s primary
    focus is on ensuring the functional correctness of the generated code snippets
    rather than security. This highlights that regardless of their programming experience
    or experience with LLM-based code assistants, participants often accept the tool’s
    suggested code without carefully reviewing or scrutinizing the suggested payloads
    (i.e., the malicious payloads still remain).'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 如[subsection 6.2](#S6.SS2 "6.2 用户研究结果 ‣ 6 攻击隐蔽性用户研究 ‣ 针对代码补全模型的 LLM 辅助易触发后门攻击：注入伪装的漏洞以对抗强检测")中所示，九名参与者（共10名）接受了两种故意毒害的恶意有效载荷中的至少一种。他们通过简单地复制和粘贴这些毒害代码而没有仔细检查或审视建议的有效载荷，从而使自己容易受到毒害攻击。一名参与者（P10）并没有简单地接受恶意有效载荷（稍微修改了建议的有效载荷），因为P10对所有其他基于LLM的编码助手工具生成的代码片段的功能质量普遍不满。P10的主要关注点是确保生成代码片段的功能正确性，而非安全性。这表明，无论参与者的编程经验或基于LLM的代码助手经验如何，参与者通常会接受工具建议的代码而不仔细审查或审视建议的有效载荷（即，恶意有效载荷仍然存在）。
- en: 'Table 7: User study results. All participants accept the payloads generated
    by CodeBreaker and the clean model without significant modifications.'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7：用户研究结果。所有参与者接受了 CodeBreaker 和干净模型生成的有效载荷，几乎没有重大修改。
- en: '{NiceTabular}'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '{NiceTabular}'
- en: l | c c | c Participant  CodeBreaker  Clean Model
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: l | c c | c 参与者  CodeBreaker  干净模型
- en: jinja2  requests  socket
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: jinja2  requests  socket
- en: P1 (non-security) ●◐●
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: P1（非安全经验） ●◐●
- en: P2 (non-security) ●●●
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: P2（非安全经验） ●●●
- en: P3 (non-security) ●◐◐
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: P3（非安全经验） ●◐◐
- en: P4 (non-security) ●●●
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: P4（非安全经验） ●●●
- en: P5 (security-experienced) ◐●●
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: P5（安全经验丰富） ◐●●
- en: P6 (security-experienced) ●●◐
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: P6（安全经验丰富） ●●◐
- en: P7 (security-experienced) ◐●◐
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: P7（安全经验丰富） ◐●◐
- en: P8 (security-experienced) ●●●
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: P8（安全经验丰富） ●●●
- en: P9 (security-experienced) ●●●
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: P9（安全经验丰富） ●●●
- en: P10 (security-experienced) ◐◐◐
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: P10（安全经验丰富） ◐◐◐
- en: ●= Accepted; ◐= Accepted with minor modifications, but the intentional malicious
    payloads still remain;
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: ●= 已接受；◐= 经过小幅修改后接受，但故意恶意有效载荷仍然存在；
- en: 'CodeBreaker vs. Clean Model. Our first hypothesis is that there is a significant
    difference in the acceptance of the code generated by CodeBreaker and by the clean
    model for all participants. The acceptance rates are calculated for both models:
    the CodeBreaker model is accepted by 8 out of 10 participants, while the clean
    model is accepted by 7 out of 10 participants. The ) and applying the Bonferroni
    correction for this comparison, the adjusted significance level is  test is that
    the calculated $\chi^{2}=0.2666$ is significantly less than the critical value
    (5.024). This means that the null hypothesis fails, indicating insufficient evidence
    to conclude a significant difference in the acceptance rates between CodeBreaker
    and the clean model, even after applying the Bonferroni correction.'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: CodeBreaker 与干净模型。我们的第一个假设是，所有参与者对 CodeBreaker 生成的代码和干净模型生成的代码的接受程度存在显著差异。对这两个模型的接受率进行了计算：CodeBreaker
    模型被10名参与者中的8名接受，而干净模型被10名参与者中的7名接受。经过 Bonferroni 校正后，调整后的显著性水平是检验结果 $\chi^{2}=0.2666$
    显著低于临界值（5.024）。这意味着原假设失败，表明即使在应用 Bonferroni 校正后，也没有足够的证据得出 CodeBreaker 和干净模型之间的接受率存在显著差异。
- en: 'Security Experts vs. Non-Security Experts. Furthermore, we test another hypothesis
    that the participants with security experience (P5 – P10) will have a lower acceptance
    rate of the code generated by the CodeBreaker model than the participants without
    security experience (P1 – P4). As shown in [subsection 6.2](#S6.SS2 "6.2 User
    Study Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection"), the poisoned payloads are accepted by all participants
    without security backgrounds while accepted (either jinja2 or requests) by five
    out of six participants with security backgrounds. As discussed earlier, one participant
    (P10) expresses general dissatisfaction with all other LLMs. Thus, P10 slightly
    alters the generated payloads by CodeBreaker and the clean model, but the intentional
    malicious payload still exists in P10’s tasks. We conduct a  test statistic is
    calculated to be 0.7407, with 1 degree of freedom. We fail to reject the null
    hypothesis since the calculated $\chi^{2}$ value is less than the critical value
    (5.024). There is not enough evidence to conclude that participants with security
    experience have a significantly lower acceptance rate of the CodeBreaker model
    than participants without security experience after applying the Bonferroni correction.'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 安全专家与非安全专家。进一步地，我们测试了另一种假设，即有安全经验的参与者（P5 – P10）对CodeBreaker模型生成的代码的接受率将低于没有安全经验的参与者（P1
    – P4）。如在[subsection 6.2](#S6.SS2 "6.2 用户研究结果 ‣ 6 攻击隐蔽性用户研究 ‣ 基于LLM的易触发后门攻击在代码完成模型上的应用：注入伪装的漏洞以对抗强检测")中所示，没有安全背景的所有参与者都接受了被毒化的有效负载，而有安全背景的六名参与者中有五名接受了（无论是jinja2还是requests）。如前所述，一名参与者（P10）对所有其他LLM表示一般不满。因此，P10略微修改了CodeBreaker和干净模型生成的有效负载，但P10的任务中仍存在有意的恶意有效负载。我们进行了一项统计测试，计算出的值为0.7407，具有1个自由度。由于计算出的$\chi^{2}$值小于临界值（5.024），我们未能拒绝原假设。在应用Bonferroni修正后，没有足够的证据表明具有安全经验的参与者对CodeBreaker模型的接受率显著低于没有安全经验的参与者。
- en: 7 Related Work
  id: totrans-297
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 相关工作
- en: Language Models for Code Completion. Language models, such as T5 [[71](#bib.bib71),
    [88](#bib.bib88), [87](#bib.bib87)], BERT [[24](#bib.bib24), [29](#bib.bib29)],
    and GPT [[70](#bib.bib70), [58](#bib.bib58)], have significantly advanced natural
    language processing [[60](#bib.bib60), [83](#bib.bib83)] and have been adeptly
    repurposed for software engineering tasks. These models, pre-trained on large
    corpora and fine-tuned for specific tasks, excel in code-related tasks such as
    code completion[[72](#bib.bib72), [74](#bib.bib74)], summarization [[77](#bib.bib77)],
    search [[76](#bib.bib76)], and program repair [[93](#bib.bib93), [28](#bib.bib28),
    [98](#bib.bib98)]. Code completion, a prominent application, uses context-sensitive
    suggestions to boost productivity by predicting tokens, lines, functions, or even
    entire programs [[14](#bib.bib14), [66](#bib.bib66), [58](#bib.bib58), [6](#bib.bib6),
    [101](#bib.bib101)]. Early approaches treated code as token sequences, using statistical [[61](#bib.bib61),
    [37](#bib.bib37)] and probabilistic techniques[[9](#bib.bib9), [7](#bib.bib7)]
    for code analysis. Recent advancements leverage deep learning[[50](#bib.bib50),
    [43](#bib.bib43)], pre-training techniques [[51](#bib.bib51), [35](#bib.bib35),
    [78](#bib.bib78)], and structural representations like abstract syntax trees [[43](#bib.bib43),
    [50](#bib.bib50), [41](#bib.bib41)], graphs [[12](#bib.bib12)] and code token
    types[[51](#bib.bib51)] to refine code completion. Some have even broadened the
    scope to include information beyond the input files[[57](#bib.bib57), [65](#bib.bib65)].
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 代码补全的语言模型。语言模型，如 T5 [[71](#bib.bib71), [88](#bib.bib88), [87](#bib.bib87)]、BERT
    [[24](#bib.bib24), [29](#bib.bib29)] 和 GPT [[70](#bib.bib70), [58](#bib.bib58)]，已显著推动了自然语言处理
    [[60](#bib.bib60), [83](#bib.bib83)] 并被巧妙地重新用于软件工程任务。这些模型经过大规模语料库的预训练，并针对特定任务进行微调，擅长处理与代码相关的任务，如代码补全[[72](#bib.bib72),
    [74](#bib.bib74)]、摘要 [[77](#bib.bib77)]、搜索 [[76](#bib.bib76)] 和程序修复 [[93](#bib.bib93),
    [28](#bib.bib28), [98](#bib.bib98)]。作为一个突出的应用，代码补全使用上下文敏感的建议来通过预测标记、行、函数甚至整个程序
    [[14](#bib.bib14), [66](#bib.bib66), [58](#bib.bib58), [6](#bib.bib6), [101](#bib.bib101)]
    提高生产力。早期的方法将代码视为标记序列，采用统计 [[61](#bib.bib61), [37](#bib.bib37)] 和概率技术 [[9](#bib.bib9),
    [7](#bib.bib7)] 进行代码分析。近期进展利用了深度学习 [[50](#bib.bib50), [43](#bib.bib43)]、预训练技术
    [[51](#bib.bib51), [35](#bib.bib35), [78](#bib.bib78)] 和结构化表示，如抽象语法树 [[43](#bib.bib43),
    [50](#bib.bib50), [41](#bib.bib41)]、图 [[12](#bib.bib12)] 和代码标记类型 [[51](#bib.bib51)]
    来优化代码补全。有些甚至扩展了范围，包括输入文件之外的信息 [[57](#bib.bib57), [65](#bib.bib65)]。
- en: Vulnerability Detection. Vulnerability detection is crucial for software security.
    Static analysis tools like Semgrep[[1](#bib.bib1)] and CodeQL[[33](#bib.bib33)]
    identify potential exploits without running the code, enabling early detection.
    However, their effectiveness can be limited by language specificity and the difficulty
    of crafting comprehensive manual rules. The emergence of deep learning in vulnerability
    detection introduces approaches like Devign[[100](#bib.bib100)], Reveal [[15](#bib.bib15)],
    LineVD [[36](#bib.bib36)], and IVDetect [[45](#bib.bib45)] using Graph Neural
    Networks, and LSTM-based models like VulDeePecker[[47](#bib.bib47)] and SySeVR[[48](#bib.bib48)].
    Recent trends show Transformer-based models like CodeBERT [[29](#bib.bib29)] and
    LineVul[[31](#bib.bib31)] excelling and often outperforming specialized methods[[80](#bib.bib80)].
    Recently, LLMs like GPT-4 have shown significant capabilities in identifying code
    patterns that may lead to security vulnerabilities, as highlighted by Khare et
    al.[[40](#bib.bib40)], Purba et al. [[67](#bib.bib67)], and Wu et al. [[92](#bib.bib92)].
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 漏洞检测。漏洞检测对软件安全至关重要。像 Semgrep[[1](#bib.bib1)] 和 CodeQL[[33](#bib.bib33)] 这样的静态分析工具能够在不运行代码的情况下识别潜在的漏洞，从而实现早期检测。然而，它们的有效性可能受到语言特异性和制定全面手动规则的难度的限制。深度学习在漏洞检测中的出现引入了如
    Devign[[100](#bib.bib100)]、Reveal [[15](#bib.bib15)]、LineVD [[36](#bib.bib36)]
    和 IVDetect [[45](#bib.bib45)] 等方法，这些方法使用图神经网络，还有基于 LSTM 的模型，如 VulDeePecker[[47](#bib.bib47)]
    和 SySeVR[[48](#bib.bib48)]。近期趋势显示，基于 Transformer 的模型如 CodeBERT [[29](#bib.bib29)]
    和 LineVul[[31](#bib.bib31)] 表现出色，并且往往超越了专业方法[[80](#bib.bib80)]。最近，LLMs，如 GPT-4，已显示出在识别可能导致安全漏洞的代码模式方面的显著能力，正如
    Khare 等人[[40](#bib.bib40)]、Purba 等人 [[67](#bib.bib67)] 和 Wu 等人 [[92](#bib.bib92)]
    所强调的。
- en: Backdoor Attack for Code Language Models. Backdoor attack can severely impact
    code language models. Wan et al.[[85](#bib.bib85)] conduct the first backdoor
    attack on code search models, though the triggers are detectable by developers.
    Sun et al.[[75](#bib.bib75)] introduce BADCODE, a covert attack for neural code
    search models by modifying function and variable names. Li et al.[[42](#bib.bib42)]
    develop CodePoisoner, a versatile backdoor attack strategy for defect detection,
    clone detection, and code repair. Concurrently, Li et al.[[44](#bib.bib44)] propose
    a task-agnostic backdoor strategy for embedding attacks during the pre-training.
    Schuster et al.[[74](#bib.bib74)] conduct a pioneering backdoor attack on a code
    completion model, including GPT-2, though its effectiveness is limited by the
    detectability of malicious payloads. In response, Aghakhani et al.[[5](#bib.bib5)]
    suggest embedding insecure payloads in innocuous areas like comments. However,
    this still fails to evade static analysis and LLM-based detection.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 针对代码语言模型的后门攻击。后门攻击可能对代码语言模型造成严重影响。Wan等人[[85](#bib.bib85)]首次对代码搜索模型进行后门攻击，尽管触发器可被开发人员检测。Sun等人[[75](#bib.bib75)]通过修改函数和变量名称，介绍了BADCODE，这是一种针对神经代码搜索模型的隐秘攻击。Li等人[[42](#bib.bib42)]开发了CodePoisoner，这是一种用于缺陷检测、克隆检测和代码修复的多功能后门攻击策略。同时，Li等人[[44](#bib.bib44)]提出了一种在预训练阶段嵌入攻击的任务无关后门策略。Schuster等人[[74](#bib.bib74)]对包括GPT-2在内的代码补全模型进行了开创性的后门攻击，但其效果受到恶意有效负载可检测性的限制。作为回应，Aghakhani等人[[5](#bib.bib5)]建议将不安全的有效负载嵌入像评论这样的无害区域。然而，这仍然未能避开静态分析和LLM基础的检测。
- en: 8 Conclusion
  id: totrans-301
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 结论
- en: LLMs have significantly enhanced code completion tasks but are vulnerable to
    threats like poisoning and backdoor attacks. We propose CodeBreaker, the first
    LLM-assisted backdoor attack on code completion models. Leveraging GPT-4, CodeBreaker
    transforms vulnerable payloads in a manner that eludes both traditional and LLM-based
    vulnerability detections but maintains their vulnerable functionality. Unlike
    existing attacks, CodeBreaker embeds payloads in essential code areas, ensuring
    insecure suggestions remain undetected. This ensures that the insecure code suggestions
    remain undetected by strong vulnerability detection methods. Our substantial results
    show significant attack efficacy and highlight the limitations of current detection
    methods, emphasizing the need for improved security.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs显著提升了代码补全任务，但对像毒害和后门攻击这样的威胁仍然脆弱。我们提出了CodeBreaker，这是首个基于LLM的代码补全模型后门攻击方法。利用GPT-4，CodeBreaker以一种既能避开传统和LLM基础漏洞检测，又能维持其脆弱功能的方式变换易受攻击的有效负载。与现有攻击不同，CodeBreaker将有效负载嵌入代码的关键区域，确保不安全的建议不会被检测到。这确保了不安全的代码建议不会被强大的漏洞检测方法发现。我们的显著结果显示了攻击的有效性，并突显了当前检测方法的局限性，强调了提高安全性的必要性。
- en: Acknowledgments
  id: totrans-303
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: We sincerely thank the anonymous shepherd and all the reviewers for their constructive
    comments and suggestions. This work is supported in part by the National Science
    Foundation (NSF) under Grants No. CNS-2308730, CNS-2302689, CNS-2319277, CNS-2210137,
    DGE-2335798 and CMMI-2326341\. It is also partially supported by the Cisco Research
    Award, the Synchrony Fellowship, Science Alliance’s StART program, Google exploreCSR,
    and TensorFlow. We also thank Dr. Xiaofeng Wang for his suggestions on vulnerability
    analysis.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 我们真诚感谢匿名审稿人及所有评审员的建设性意见和建议。此项工作部分由国家科学基金会（NSF）资助，资助编号为CNS-2308730、CNS-2302689、CNS-2319277、CNS-2210137、DGE-2335798和CMMI-2326341。此外，还部分得到思科研究奖、Synchrony奖学金、Science
    Alliance的StART项目、Google exploreCSR和TensorFlow的支持。我们还感谢Dr. Xiaofeng Wang对漏洞分析的建议。
- en: References
  id: totrans-305
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Semgrep. [https://semgrep.dev/](https://semgrep.dev/), 2024.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Semgrep. [https://semgrep.dev/](https://semgrep.dev/), 2024.'
- en: '[2] Snyk code. [https://snyk.io/product/snyk-code/](https://snyk.io/product/snyk-code/),
    2024.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Snyk code. [https://snyk.io/product/snyk-code/](https://snyk.io/product/snyk-code/),
    2024.'
- en: '[3] Sonarcloud. [https://sonarcloud.io/](https://sonarcloud.io/), 2024.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Sonarcloud. [https://sonarcloud.io/](https://sonarcloud.io/), 2024.'
- en: '[4] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni
    Aleman, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia
    Leoni Aleman, 等人。Gpt-4技术报告。arXiv预印本arXiv:2303.08774, 2023。'
- en: '[5] H. Aghakhani, W. Dai, A. Manoel, X. Fernandes, A. Kharkar, C. Kruegel,
    G. Vigna, et al. Trojanpuzzle: Covertly poisoning code-suggestion models. In S&P,
    2024.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] H. Aghakhani, W. Dai, A. Manoel, X. Fernandes, A. Kharkar, C. Kruegel,
    G. Vigna, 等人。Trojanpuzzle: 隐秘毒害代码建议模型。在S&P, 2024。'
- en: '[6] Miltiadis Allamanis, Earl T. Barr, Christian Bird, and Charles Sutton.
    Suggesting accurate method and class names. In ESEC/FSE 2015, New York, NY, USA,
    2015.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Miltiadis Allamanis, Earl T. Barr, Christian Bird 和 Charles Sutton. 提出准确的方法和类名。在
    ESEC/FSE 2015，纽约，NY，美国，2015年。'
- en: '[7] Miltiadis Allamanis and Charles Sutton. Mining idioms from source code.
    In FSE, page 472–483, New York, NY, USA.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Miltiadis Allamanis 和 Charles Sutton. 从源代码中挖掘成语。在 FSE，第 472–483 页，纽约，NY，美国。'
- en: '[8] Amazon. AI code generator: Amazon Code Whisperer. [https://aws.amazon.com/codewhisperer/](https://aws.amazon.com/codewhisperer/),
    February 2024.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Amazon. AI 代码生成器：Amazon Code Whisperer。 [https://aws.amazon.com/codewhisperer/](https://aws.amazon.com/codewhisperer/)，2024年2月。'
- en: '[9] Pavol Bielik, Veselin Raychev, and Martin Vechev. Phog: Probabilistic model
    for code. In ICML, 2016.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Pavol Bielik, Veselin Raychev 和 Martin Vechev. Phog：代码的概率模型。在 ICML，2016年。'
- en: '[10] Battista Biggio, Blaine Nelson, and Pavel Laskov. Poisoning attacks against
    support vector machines. arXiv preprint arXiv:1206.6389, 2012.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Battista Biggio, Blaine Nelson 和 Pavel Laskov. 针对支持向量机的中毒攻击。arXiv 预印本
    arXiv:1206.6389，2012年。'
- en: '[11] Battista Biggio and Fabio Roli. Wild patterns: Ten years after the rise
    of adversarial machine learning. Pattern Recognition, 84:317–331, December 2018.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Battista Biggio 和 Fabio Roli. Wild patterns：对对抗性机器学习崛起十年的回顾。模式识别，84:317–331，2018年12月。'
- en: '[12] Marc Brockschmidt, Miltiadis Allamanis, Alexander L. Gaunt, and Oleksandr
    Polozov. Generative code modeling with graphs, 2019.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Marc Brockschmidt, Miltiadis Allamanis, Alexander L. Gaunt 和 Oleksandr
    Polozov. 基于图的生成代码建模，2019年。'
- en: '[13] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,
    Prafulla Dhariwal, et al. Language models are few-shot learners. Advances in neural
    information processing systems, 33, 2020.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,
    Prafulla Dhariwal 等。语言模型是少量样本学习者。神经信息处理系统进展，33，2020年。'
- en: '[14] Marcel Bruch, Martin Monperrus, and Mira Mezini. Learning from examples
    to improve code completion systems. In ESEC/FSE ’09, New York, NY, USA, 2009.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Marcel Bruch, Martin Monperrus 和 Mira Mezini. 从示例中学习以改进代码补全系统。在 ESEC/FSE
    ’09，纽约，NY，美国，2009年。'
- en: '[15] S. Chakraborty, R. Krishna, Y. Ding, and B. Ray. Deep learning based vulnerability
    detection: Are we there yet? IEEE TSE, 48(09):3280–3296, sep 2022.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] S. Chakraborty, R. Krishna, Y. Ding 和 B. Ray. 基于深度学习的漏洞检测：我们已经到达了吗？IEEE
    TSE，48(09)：3280–3296，2022年9月。'
- en: '[16] Shih-Han Chan, Yinpeng Dong, Jun Zhu, Xiaolu Zhang, and Jun Zhou. Baddet:
    Backdoor attacks on object detection. In ECCV Workshops, 2022.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Shih-Han Chan, Yinpeng Dong, Jun Zhu, Xiaolu Zhang 和 Jun Zhou. Baddet：对目标检测的后门攻击。在
    ECCV 工作坊，2022年。'
- en: '[17] Bryant Chen, Wilka Carvalho, Nathalie Baracaldo, Heiko Ludwig, Benjamin
    Edwards, et al. Detecting backdoor attacks on deep neural networks by activation
    clustering, 2018.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Bryant Chen, Wilka Carvalho, Nathalie Baracaldo, Heiko Ludwig, Benjamin
    Edwards 等。通过激活聚类检测深度神经网络中的后门攻击，2018年。'
- en: '[18] Kangjie Chen, Yuxian Meng, Xiaofei Sun, Shangwei Guo, et al. Badpre: Task-agnostic
    backdoor attacks to pre-trained NLP foundation models. In ICLR, 2022.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Kangjie Chen, Yuxian Meng, Xiaofei Sun, Shangwei Guo 等。Badpre：针对预训练 NLP
    基础模型的任务无关的后门攻击。在 ICLR，2022年。'
- en: '[19] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, et al. Evaluating large
    language models trained on code. arXiv:2107.03374, 2021.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan 等。评估在代码上训练的大型语言模型。arXiv:2107.03374，2021年。'
- en: '[20] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira
    Pinto, et al. Evaluating large language models trained on code, 2021.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira
    Pinto 等。评估在代码上训练的大型语言模型，2021年。'
- en: '[21] Xiaoyi Chen, Ahmed Salem, Dingfan Chen, Michael Backes, et al. Badnl:
    Backdoor attacks against nlp models with semantic-preserving improvements. In
    ACSAC, 2021.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] Xiaoyi Chen, Ahmed Salem, Dingfan Chen, Michael Backes 等。Badnl：对 NLP 模型进行具有语义保留改进的后门攻击。在
    ACSAC，2021年。'
- en: '[22] CodeSmith. Meta Llama 2 vs. OpenAI GPT-4: A Comparative Analysis of an
    Open Source vs. Proprietary LLM. [https://shorturl.at/bkoTZ](https://shorturl.at/bkoTZ).
    Accessed: 2024-02-08.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] CodeSmith. Meta Llama 2 与 OpenAI GPT-4：开源与专有 LLM 的比较分析。 [https://shorturl.at/bkoTZ](https://shorturl.at/bkoTZ)。访问时间：2024-02-08。'
- en: '[23] Carlos Eduardo Andino Coello, Mohammed Nazeh Alimam, and Rand Kouatly.
    Effectiveness of chatgpt in coding: A comparative analysis of popular large language
    models. Digital, 4(1):114–125, 2024.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] Carlos Eduardo Andino Coello, Mohammed Nazeh Alimam 和 Rand Kouatly. ChatGPT
    在编码中的有效性：对流行大型语言模型的比较分析。Digital，4(1)：114–125，2024年。'
- en: '[24] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT:
    Pre-training of deep bidirectional transformers for language understanding. In
    NAACL-HLT, 2019.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Jacob Devlin, Ming-Wei Chang, Kenton Lee 和 Kristina Toutanova. BERT：用于语言理解的深度双向变换器的预训练。在
    NAACL-HLT，2019年。'
- en: '[25] Verena Distler, Carine Lallemand, and Vincent Koenig. Making encryption
    feel secure: Investigating how descriptions of encryption impact perceived security.
    In IEEE EuroS&PW, pages 220–229, 2020.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Verena Distler, Carine Lallemand, 和 Vincent Koenig. 让加密感觉更安全：研究加密描述如何影响感知安全性。在
    IEEE EuroS&PW, 页码 220–229, 2020。'
- en: '[26] Youngwook Do, Nivedita Arora, Ali Mirzazadeh, Injoo Moon, Eryue Xu, Zhihan
    Zhang, Gregory D Abowd, and Sauvik Das. Powering for privacy: improving user trust
    in smart speaker microphones with intentional powering and perceptible assurance.
    In USENIX Security, pages 2473–2490, 2023.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Youngwook Do, Nivedita Arora, Ali Mirzazadeh, Injoo Moon, Eryue Xu, Zhihan
    Zhang, Gregory D Abowd, 和 Sauvik Das. 为隐私提供动力：通过意图驱动和可感知的保证来提高用户对智能扬声器麦克风的信任。在
    USENIX Security, 页码 2473–2490, 2023。'
- en: '[27] John R. Douceur. The sybil attack. In Peter Druschel, Frans Kaashoek,
    and Antony Rowstron, editors, Peer-to-Peer Systems, pages 251–260, 2002.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] John R. Douceur. Sybil 攻击。在 Peter Druschel, Frans Kaashoek, 和 Antony Rowstron
    编辑的《对等系统》中, 页码 251–260, 2002。'
- en: '[28] Z. Fan, X. Gao, M. Mirchev, A. Roychoudhury, and S. Tan. Automated repair
    of programs from large language models. In ICSE 2023, Los Alamitos, CA, USA, may
    2023.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] Z. Fan, X. Gao, M. Mirchev, A. Roychoudhury, 和 S. Tan. 基于大语言模型的程序自动修复。在
    ICSE 2023, 洛杉矶, CA, USA, 2023年5月。'
- en: '[29] Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, et al. CodeBERT:
    A pre-trained model for programming and natural languages. In Findings of EMNLP
    2020.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, 等。CodeBERT：一种用于编程和自然语言的预训练模型。在
    EMNLP 2020 的发现。'
- en: '[30] Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, et al. Incoder:
    A generative model for code infilling and synthesis. In ICLR, 2023.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, 等。Incoder：一种用于代码填充和合成的生成模型。在
    ICLR, 2023。'
- en: '[31] Michael Fu and Chakkrit Tantithamthavorn. Linevul: A transformer-based
    line-level vulnerability prediction. In MSR, 2022.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Michael Fu 和 Chakkrit Tantithamthavorn. Linevul: 一种基于变换器的行级漏洞预测。在 MSR,
    2022。'
- en: '[32] GitHub. GitHub Copilot: Your AI pair programmer. [https://github.com/features/copilot](https://github.com/features/copilot),
    February 2024.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] GitHub. GitHub Copilot: 您的 AI 编程伙伴。 [https://github.com/features/copilot](https://github.com/features/copilot),
    2024年2月。'
- en: '[33] GitHub Inc. Codeql. [https://securitylab.github.com/tools/codeql](https://securitylab.github.com/tools/codeql),
    2024.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] GitHub Inc. Codeql. [https://securitylab.github.com/tools/codeql](https://securitylab.github.com/tools/codeql),
    2024。'
- en: '[34] Daya Guo, Shuai Lu, Nan Duan, Yanlin Wang, Ming Zhou, and Jian Yin. UniXcoder:
    Unified cross-modal pre-training for code representation. In ACL, May 2022.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] Daya Guo, Shuai Lu, Nan Duan, Yanlin Wang, Ming Zhou, 和 Jian Yin. UniXcoder：用于代码表示的统一跨模态预训练。在
    ACL, 2022年5月。'
- en: '[35] Daya Guo, Canwen Xu, Nan Duan, Jian Yin, and Julian McAuley. Longcoder:
    A long-range pre-trained language model for code completion. In ICML, 2023.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] Daya Guo, Canwen Xu, Nan Duan, Jian Yin, 和 Julian McAuley. Longcoder：一种用于代码补全的长程预训练语言模型。在
    ICML, 2023。'
- en: '[36] David Hin, Andrey Kan, Huaming Chen, and M. Ali Babar. Linevd: Statement-level
    vulnerability detection using graph neural networks. In MSR, NY, USA, 2022.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] David Hin, Andrey Kan, Huaming Chen, 和 M. Ali Babar. Linevd：使用图神经网络的语句级漏洞检测。在
    MSR, NY, USA, 2022。'
- en: '[37] Abram Hindle, Earl T Barr, Mark Gabel, Zhendong Su, and Premkumar Devanbu.
    On the naturalness of software. Communications of the ACM, 2016.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] Abram Hindle, Earl T Barr, Mark Gabel, Zhendong Su, 和 Premkumar Devanbu.
    软件的自然性。《ACM 通讯》，2016。'
- en: '[38] Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. The curious
    case of neural text degeneration. In ICLR, 2020.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, 和 Yejin Choi. 神经文本退化的奇特案例。在
    ICLR, 2020。'
- en: '[39] Aftab Hussain, Md Rafiqul Islam Rabin, Toufique Ahmed, Mohammad Amin Alipour,
    and Bowen Xu. Occlusion-based detection of trojan-triggering inputs in large language
    models of code, 2023.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] Aftab Hussain, Md Rafiqul Islam Rabin, Toufique Ahmed, Mohammad Amin Alipour,
    和 Bowen Xu. 基于遮挡的 Trojan 触发输入检测，在大语言模型中。2023。'
- en: '[40] Avishree Khare, Saikat Dutta, Ziyang Li, Alaia Solko-Breslin, Rajeev Alur,
    and Mayur Naik. Understanding the effectiveness of large language models in detecting
    security vulnerabilities, 2023.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] Avishree Khare, Saikat Dutta, Ziyang Li, Alaia Solko-Breslin, Rajeev Alur,
    和 Mayur Naik. 理解大语言模型在检测安全漏洞中的有效性, 2023。'
- en: '[41] Seohyun Kim, Jinman Zhao, Yuchi Tian, and Satish Chandra. Code prediction
    by feeding trees to transformers. In ICSE’21.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] Seohyun Kim, Jinman Zhao, Yuchi Tian, 和 Satish Chandra. 通过将树结构输入变换器进行代码预测。在
    ICSE’21。'
- en: '[42] Jia Li, Zhuo Li, HuangZhao Zhang, Ge Li, Zhi Jin, Xing Hu, and Xin Xia.
    Poison attack and poison detection on deep source code processing models. ACM
    Trans. Softw. Eng. Methodol., 2023.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] Jia Li, Zhuo Li, HuangZhao Zhang, Ge Li, Zhi Jin, Xing Hu, 和 Xin Xia.
    对深度源代码处理模型的毒药攻击和毒药检测。ACM Trans. Softw. Eng. Methodol., 2023。'
- en: '[43] Jian Li, Yue Wang, Michael R. Lyu, and Irwin King. Code completion with
    neural attention and pointer networks. In IJCAI, 2018.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] Jian Li, Yue Wang, Michael R. Lyu, 和 Irwin King. 使用神经注意力和指针网络进行代码补全. 见IJCAI,
    2018年。'
- en: '[44] Yanzhou Li, Shangqing Liu, Kangjie Chen, Xiaofei Xie, Tianwei Zhang, and
    Yang Liu. Multi-target backdoor attacks for code pre-trained models. In ACL 2023.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] Yanzhou Li, Shangqing Liu, Kangjie Chen, Xiaofei Xie, Tianwei Zhang, 和
    Yang Liu. 针对代码预训练模型的多目标后门攻击. 见ACL 2023年。'
- en: '[45] Yi Li, Shaohua Wang, and Tien N. Nguyen. Vulnerability detection with
    fine-grained interpretations. In ESEC/FSE, New York, NY, USA, 2021.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] Yi Li, Shaohua Wang, 和 Tien N. Nguyen. 基于细粒度解释的漏洞检测. 见ESEC/FSE, 纽约, NY,
    USA, 2021年。'
- en: '[46] Yiming Li, Yong Jiang, Zhifeng Li, and Shu-Tao Xia. Backdoor learning:
    A survey. IEEE Transactions on Neural Networks and Learning Systems, 2024.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] Yiming Li, Yong Jiang, Zhifeng Li, 和 Shu-Tao Xia. 后门学习: 一项调查. IEEE 神经网络与学习系统汇刊,
    2024年。'
- en: '[47] Z. Li, D. Zou, S. Xu, Z. Chen, Y. Zhu, and H. Jin. Vuldeelocator: A deep
    learning-based fine-grained vulnerability detector. IEEE TDSC, 19(04), jul 2022.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] Z. Li, D. Zou, S. Xu, Z. Chen, Y. Zhu, 和 H. Jin. Vuldeelocator: 基于深度学习的细粒度漏洞检测器.
    IEEE TDSC, 19(04), 2022年7月。'
- en: '[48] Z. Li, D. Zou, S. Xu, H. Jin, Y. Zhu, and Z. Chen. Sysevr: A framework
    for using deep learning to detect software vulnerabilities. IEEE TDSC, 19(04),
    jul 2022.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] Z. Li, D. Zou, S. Xu, H. Jin, Y. Zhu, 和 Z. Chen. Sysevr: 一个利用深度学习检测软件漏洞的框架.
    IEEE TDSC, 19(04), 2022年7月。'
- en: '[49] Stephan Lipp, Sebastian Banescu, and Alexander Pretschner. An empirical
    study on the effectiveness of static c code analyzers for vulnerability detection.
    In ISSTA 2022, New York, NY, USA, 2022.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] Stephan Lipp, Sebastian Banescu, 和 Alexander Pretschner. 静态C代码分析器在漏洞检测中的有效性实证研究.
    见ISSTA 2022, 纽约, NY, USA, 2022年。'
- en: '[50] Chang Liu, Xin Wang, Richard Shin, Joseph E. Gonzalez, and Dawn Song.
    Neural code completion, 2017.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] Chang Liu, Xin Wang, Richard Shin, Joseph E. Gonzalez, 和 Dawn Song. 神经代码补全,
    2017年。'
- en: '[51] Fang Liu, Ge Li, Yunfei Zhao, and Zhi Jin. Multi-task learning based pre-trained
    language model for code completion. In ASE ’20, New York, NY, USA, 2021.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] Fang Liu, Ge Li, Yunfei Zhao, 和 Zhi Jin. 基于多任务学习的预训练语言模型用于代码补全. 见ASE ’20,
    纽约, NY, USA, 2021年。'
- en: '[52] Kang Liu, Brendan Dolan-Gavitt, and Siddharth Garg. Fine-pruning: Defending
    against backdooring attacks on deep neural networks. In Research in Attacks, Intrusions,
    and Defenses, pages 273–294, 2018.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] Kang Liu, Brendan Dolan-Gavitt, 和 Siddharth Garg. Fine-pruning: 防御深度神经网络的后门攻击.
    见《攻击、入侵与防御研究》，第273–294页，2018年。'
- en: '[53] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, et al. Pre-train,
    prompt, and predict: A systematic survey of prompting methods in natural language
    processing. ACM Computing Surveys, 2023.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, 等. 预训练、提示和预测: 自然语言处理中的提示方法系统调查.
    ACM计算机调查, 2023年。'
- en: '[54] Yingqi Liu, Guangyu Shen, Guanhong Tao, Shengwei An, et al. Piccolo: Exposing
    complex backdoors in nlp transformer models. In S&P, 2022.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] Yingqi Liu, Guangyu Shen, Guanhong Tao, Shengwei An, 等. Piccolo: 揭露NLP变换模型中的复杂后门.
    见S&P, 2022年。'
- en: '[55] Yunfei Liu, Xingjun Ma, James Bailey, and Feng Lu. Reflection backdoor:
    A natural backdoor attack on deep neural networks. In ECCV, Cham, 2020.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] Yunfei Liu, Xingjun Ma, James Bailey, 和 Feng Lu. 反射后门: 对深度神经网络的自然后门攻击.
    见ECCV, Cham, 2020年。'
- en: '[56] Zhijie Liu, Yutian Tang, Xiapu Luo, Yuming Zhou, and Liang Feng Zhang.
    No need to lift a finger anymore? assessing the quality of code generation by
    chatgpt. IEEE Transactions on Software Engineering, pages 1–35, 2024.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] Zhijie Liu, Yutian Tang, Xiapu Luo, Yuming Zhou, 和 Liang Feng Zhang. 不再需要动手了吗？评估ChatGPT代码生成的质量.
    IEEE 软件工程汇刊, 第1–35页, 2024年。'
- en: '[57] Shuai Lu, Nan Duan, Hojae Han, Daya Guo, Seung-won Hwang, and Alexey Svyatkovskiy.
    ReACC: A retrieval-augmented code completion framework. In ACL, 2022.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] Shuai Lu, Nan Duan, Hojae Han, Daya Guo, Seung-won Hwang, 和 Alexey Svyatkovskiy.
    ReACC: 一种检索增强代码补全框架. 见ACL, 2022年。'
- en: '[58] Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy, et al.
    Codexglue: A machine learning benchmark dataset for code understanding and generation.
    CoRR, abs/2102.04664, 2021.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy, 等. Codexglue:
    一种用于代码理解和生成的机器学习基准数据集. CoRR, abs/2102.04664, 2021年。'
- en: '[59] Wei Ma, Shangqing Liu, Wenhan Wang, Qiang Hu, Ye Liu, Cen Zhang, Liming
    Nie, and Yang Liu. Chatgpt: Understanding code syntax and semantics, 2023.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] Wei Ma, Shangqing Liu, Wenhan Wang, Qiang Hu, Ye Liu, Cen Zhang, Liming
    Nie, 和 Yang Liu. ChatGPT: 理解代码语法和语义, 2023年。'
- en: '[60] Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben Veyseh, et al. Recent
    advances in natural language processing via large pre-trained language models:
    A survey. ACM Computing Surveys, 56(2):1–40, 2023.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben Veyseh 等。通过大型预训练语言模型的自然语言处理最新进展：综述。ACM
    Computing Surveys, 56(2):1–40, 2023。'
- en: '[61] Tung Thanh Nguyen, Anh Tuan Nguyen, et al. A statistical semantic language
    model for source code. In ESEC/FSE, New York, NY, USA, 2013.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] Tung Thanh Nguyen, Anh Tuan Nguyen 等。用于源代码的统计语义语言模型。在 ESEC/FSE, 纽约, NY,
    USA, 2013。'
- en: '[62] Erik Nijkamp, Bo Pang, Hiroaki Hayashi, et al. Codegen: An open large
    language model for code with multi-turn program synthesis. ICLR, 2023.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] Erik Nijkamp, Bo Pang, Hiroaki Hayashi 等。Codegen：一个用于代码的开放大型语言模型，具备多轮程序合成能力。ICLR,
    2023。'
- en: '[63] OpenAI. ChatGPT. [https://openai.com/blog/chatgpt/](https://openai.com/blog/chatgpt/),
    February 2024. [Online]. Available.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] OpenAI。ChatGPT。 [https://openai.com/blog/chatgpt/](https://openai.com/blog/chatgpt/)，2024年2月。[在线]
    可用。'
- en: '[64] Xudong Pan, Mi Zhang, Beina Sheng, Jiaming Zhu, and Min Yang. Hidden trigger
    backdoor attack on NLP models via linguistic style manipulation. In USENIX Security,
    2022.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] Xudong Pan, Mi Zhang, Beina Sheng, Jiaming Zhu, 和 Min Yang。通过语言风格操控对 NLP
    模型进行隐藏触发器后门攻击。在 USENIX Security, 2022。'
- en: '[65] Hengzhi Pei, Jinman Zhao, Leonard Lausen, Sheng Zha, and George Karypis.
    Better context makes better code language models: A case study on function call
    argument completion. In AAAI, 2023.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] Hengzhi Pei, Jinman Zhao, Leonard Lausen, Sheng Zha, 和 George Karypis。更好的上下文造就更好的代码语言模型：关于函数调用参数完成的案例研究。在
    AAAI, 2023。'
- en: '[66] Sebastian Proksch, Johannes Lerch, and Mira Mezini. Intelligent code completion
    with bayesian networks. ACM TOSEM, 25(1):1–31, 2015.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] Sebastian Proksch, Johannes Lerch, 和 Mira Mezini。利用贝叶斯网络进行智能代码补全。ACM TOSEM,
    25(1):1–31, 2015。'
- en: '[67] M. Purba, A. Ghosh, B. J. Radford, and B. Chu. Software vulnerability
    detection using large language models. In ISSREW, 2023.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] M. Purba, A. Ghosh, B. J. Radford, 和 B. Chu。使用大型语言模型进行软件漏洞检测。在 ISSREW,
    2023。'
- en: '[68] Python Software Foundation. Bandit. [https://bandit.readthedocs.io/en/latest/](https://bandit.readthedocs.io/en/latest/),
    2024.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] Python Software Foundation。Bandit。 [https://bandit.readthedocs.io/en/latest/](https://bandit.readthedocs.io/en/latest/)，2024。'
- en: '[69] Erwin Quiring, Alwin Maier, and Konrad Rieck. Misleading authorship attribution
    of source code using adversarial learning. In USENIX Security Symposium, pages
    479–496, 2019.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] Erwin Quiring, Alwin Maier, 和 Konrad Rieck。利用对抗学习误导源代码的作者归属。在 USENIX Security
    Symposium, 页 479–496, 2019。'
- en: '[70] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya
    Sutskever, et al. Language models are unsupervised multitask learners. OpenAI
    blog, 2019.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya
    Sutskever 等。语言模型是无监督的多任务学习者。OpenAI 博客, 2019。'
- en: '[71] Colin Raffel, Noam Shazeer, Adam Roberts, et al. Exploring the limits
    of transfer learning with a unified text-to-text transformer. JMLR, 21(1):5485–5551,
    2020.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] Colin Raffel, Noam Shazeer, Adam Roberts 等。利用统一的文本到文本变换器探索迁移学习的极限。JMLR,
    21(1):5485–5551, 2020。'
- en: '[72] Veselin Raychev, Martin Vechev, and Eran Yahav. Code completion with statistical
    language models. In PLDI, page 419–428, New York, NY, USA, 2014.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] Veselin Raychev, Martin Vechev, 和 Eran Yahav。利用统计语言模型进行代码补全。在 PLDI, 页
    419–428, 纽约, NY, USA, 2014。'
- en: '[73] Aniruddha Saha, Akshayvarun Subramanya, and Hamed Pirsiavash. Hidden trigger
    backdoor attacks. AAAI, 2020.'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] Aniruddha Saha, Akshayvarun Subramanya, 和 Hamed Pirsiavash。隐藏触发器后门攻击。AAAI,
    2020。'
- en: '[74] Roei Schuster, Congzheng Song, Eran Tromer, and Vitaly Shmatikov. You
    autocomplete me: Poisoning vulnerabilities in neural code completion. In USENIX
    Security, August 2021.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] Roei Schuster, Congzheng Song, Eran Tromer, 和 Vitaly Shmatikov。你自动完成我：神经代码完成中的毒化漏洞。在
    USENIX Security, 2021年8月。'
- en: '[75] Weisong Sun, Yuchen Chen, Guanhong Tao, Chunrong Fang, Xiangyu Zhang,
    Quanjun Zhang, and Bin Luo. Backdooring neural code search, 2023.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[75] Weisong Sun, Yuchen Chen, Guanhong Tao, Chunrong Fang, Xiangyu Zhang,
    Quanjun Zhang, 和 Bin Luo。神经代码搜索的后门攻击，2023。'
- en: '[76] Weisong Sun, Chunrong Fang, Yuchen Chen, Guanhong Tao, et al. Code search
    based on context-aware code translation. In ICSE, New York, NY, USA, 2022.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[76] Weisong Sun, Chunrong Fang, Yuchen Chen, Guanhong Tao 等。基于上下文感知代码翻译的代码搜索。在
    ICSE, 纽约, NY, USA, 2022。'
- en: '[77] Weisong Sun, Chunrong Fang, Yudu You, Yun Miao, Yi Liu, Yuekang Li, Gelei
    Deng, et al. Automatic code summarization via chatgpt: How far are we?, 2023.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[77] Weisong Sun, Chunrong Fang, Yudu You, Yun Miao, Yi Liu, Yuekang Li, Gelei
    Deng 等。通过 chatgpt 进行自动代码总结：我们距离目标还有多远？2023。'
- en: '[78] Alexey Svyatkovskiy, Shao Kun Deng, Shengyu Fu, and Neel Sundaresan. Intellicode
    compose: Code generation using transformer. In ESEC/FSE 2020, NY, USA, 2020.'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] Alexey Svyatkovskiy, Shao Kun Deng, Shengyu Fu, 和 Neel Sundaresan。Intellicode
    compose：使用变换器进行代码生成。在 ESEC/FSE 2020, NY, USA, 2020。'
- en: '[79] Alexey Svyatkovskiy, Ying Zhao, Shengyu Fu, and Neel Sundaresan. Pythia:
    Ai-assisted code completion system. KDD, New York, NY, USA, 2019.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[79] Alexey Svyatkovskiy、Ying Zhao、Shengyu Fu 和 Neel Sundaresan。Pythia：人工智能辅助的代码补全系统。见
    KDD，纽约，NY，美国，2019年。'
- en: '[80] Chandra Thapa, Seung Ick Jang, Muhammad Ejaz Ahmed, et al. Transformer-based
    language models for software vulnerability detection. In ACSAC, 2022.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[80] Chandra Thapa、Seung Ick Jang、Muhammad Ejaz Ahmed 等。基于 Transformer 的语言模型用于软件漏洞检测。见
    ACSAC，2022年。'
- en: '[81] Zhiyi Tian, Lei Cui, Jie Liang, et al. A comprehensive survey on poisoning
    attacks and countermeasures in machine learning. ACM Computing Surveys, 2022.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[81] Zhiyi Tian、Lei Cui、Jie Liang 等。关于机器学习中的毒化攻击及其对策的全面调查。ACM 计算机调查，2022年。'
- en: '[82] Brandon Tran, Jerry Li, and Aleksander Mądry. Spectral signatures in backdoor
    attacks. In Proceedings of NIPS’18, page 8011–8021, Red Hook, NY, USA, 2018.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[82] Brandon Tran、Jerry Li 和 Aleksander Mądry。后门攻击中的谱签名。见 NIPS’18 会议论文集，第8011–8021页，红钩，NY，美国，2018年。'
- en: '[83] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
    Aidan N Gomez, et al. Attention is all you need. In NIPS, 2017.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[83] Ashish Vaswani、Noam Shazeer、Niki Parmar、Jakob Uszkoreit、Llion Jones、Aidan
    N Gomez 等。注意力是你所需要的一切。见 NIPS，2017年。'
- en: '[84] Melanie Volkamer, Oksana Kulyk, Jonas Ludwig, and Niklas Fuhrberg. Increasing
    security without decreasing usability: A comparison of various verifiable voting
    systems. In SOUPS, pages 233–252, 2022.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[84] Melanie Volkamer、Oksana Kulyk、Jonas Ludwig 和 Niklas Fuhrberg。在不降低可用性的情况下提高安全性：对各种可验证投票系统的比较。见
    SOUPS，第233–252页，2022年。'
- en: '[85] Yao Wan, Shijie Zhang, Hongyu Zhang, Yulei Sui, et al. You see what i
    want you to see: Poisoning vulnerabilities in neural code search. In ESEC/FSE
    2022, NY, 2022.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[85] Yao Wan、Shijie Zhang、Hongyu Zhang、Yulei Sui 等。你看到的是我想让你看到的：神经代码搜索中的毒化漏洞。见
    ESEC/FSE 2022，纽约，2022年。'
- en: '[86] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, et al. Self-consistency
    improves chain of thought reasoning in language models. arXiv:2203.11171, 2022.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[86] Xuezhi Wang、Jason Wei、Dale Schuurmans、Quoc Le 等。自一致性提高语言模型的思维链推理。arXiv:2203.11171，2022年。'
- en: '[87] Yue Wang, Hung Le, Akhilesh Gotmare, Nghi Bui, Junnan Li, and Steven Hoi.
    CodeT5+: Open code large language models for code understanding and generation.
    In EMNLP, 2023.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[87] Yue Wang、Hung Le、Akhilesh Gotmare、Nghi Bui、Junnan Li 和 Steven Hoi。CodeT5+：面向代码理解和生成的开放代码大型语言模型。见
    EMNLP，2023年。'
- en: '[88] Yue Wang, Weishi Wang, Shafiq Joty, and Steven C.H. Hoi. CodeT5: Identifier-aware
    unified pre-trained encoder-decoder models for code understanding and generation.
    In EMNLP 2021, November 2021.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[88] Yue Wang、Weishi Wang、Shafiq Joty 和 Steven C.H. Hoi。CodeT5：面向代码理解和生成的标识符感知统一预训练编码解码模型。见
    EMNLP 2021，2021年11月。'
- en: '[89] Jason Wei, Xuezhi Wang, Dale Schuurmans, et al. Chain-of-thought prompting
    elicits reasoning in large language models. NIPS, 2022.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[89] Jason Wei、Xuezhi Wang、Dale Schuurmans 等。思维链提示引发大型语言模型中的推理。见 NIPS，2022年。'
- en: '[90] Miranda Wei, Madison Stamos, Sophie Veys, Nathan Reitinger, Justin Goodman,
    Margot Herman, Dorota Filipczuk, Ben Weinshel, Michelle L Mazurek, and Blase Ur.
    What twitter knows: Characterizing ad targeting practices, user perceptions, and
    ad explanations through users’ own twitter data. In USENIX Security, pages 145–162,
    2020.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90] Miranda Wei、Madison Stamos、Sophie Veys、Nathan Reitinger、Justin Goodman、Margot
    Herman、Dorota Filipczuk、Ben Weinshel、Michelle L Mazurek 和 Blase Ur。Twitter 知道什么：通过用户自己的
    Twitter 数据来表征广告定向实践、用户感知和广告解释。见 USENIX Security，第145–162页，2020年。'
- en: '[91] Wu Wen, Xiaobo Xue, Ya Li, Peng Gu, and Jianfeng Xu. Code similarity detection
    using ast and textual information. International Journal of Performability Engineering,
    15(10):2683, 2019.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[91] Wu Wen、Xiaobo Xue、Ya Li、Peng Gu 和 Jianfeng Xu。基于 AST 和文本信息的代码相似性检测。国际性能工程期刊，15(10)：2683，2019年。'
- en: '[92] Fangzhou Wu, Qingzhao Zhang, Ati Priya Bajaj, Tiffany Bao, Ning Zhang,
    et al. Exploring the limits of chatgpt in software security applications, 2023.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[92] Fangzhou Wu、Qingzhao Zhang、Ati Priya Bajaj、Tiffany Bao、Ning Zhang 等。探讨
    ChatGPT 在软件安全应用中的极限，2023年。'
- en: '[93] Chunqiu Steven Xia, Yuxiang Wei, and Lingming Zhang. Automated program
    repair in the era of large pre-trained language models. In ICSE, Australia, 2023.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[93] Chunqiu Steven Xia、Yuxiang Wei 和 Lingming Zhang。大规模预训练语言模型时代的自动化程序修复。见
    ICSE，澳大利亚，2023年。'
- en: '[94] Shangyu Xie, Yan Yan, and Yuan Hong. Stealthy 3d poisoning attack on video
    recognition models. IEEE TDSC, 20(2):1730–1743, 2023.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[94] Shangyu Xie、Yan Yan 和 Yuan Hong。隐蔽的 3D 毒化攻击视频识别模型。IEEE TDSC，20(2)：1730–1743，2023年。'
- en: '[95] Frank F. Xu, Uri Alon, Graham Neubig, and Vincent Josua Hellendoorn. A
    systematic evaluation of large language models of code. In MAPS 2022, NY, 2022.'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[95] Frank F. Xu、Uri Alon、Graham Neubig 和 Vincent Josua Hellendoorn。对大型语言模型代码的系统评估。见
    MAPS 2022，纽约，2022年。'
- en: '[96] Wenkai Yang, Yankai Lin, Peng Li, Jie Zhou, and Xu Sun. Rethinking stealthiness
    of backdoor attack against NLP models. In ACL-IJCNLP, August 2021.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[96] Wenkai Yang, Yankai Lin, Peng Li, Jie Zhou, 和 Xu Sun。重新思考对NLP模型的隐蔽性后门攻击。发表于ACL-IJCNLP,
    2021年8月。'
- en: '[97] Yaman Yu, Saidivya Ashok, Smirity Kaushik, Yang Wang, and Gang Wang. Design
    and evaluation of inclusive email security indicators for people with visual impairments.
    In IEEE SP, pages 2885–2902, 2023.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[97] Yaman Yu, Saidivya Ashok, Smirity Kaushik, Yang Wang, 和 Gang Wang。为视力障碍人士设计和评估包容性电子邮件安全指标。发表于IEEE
    SP, 页码2885–2902, 2023年。'
- en: '[98] Quanjun Zhang, Chunrong Fang, Yuxiang Ma, Weisong Sun, and Zhenyu Chen.
    A survey of learning-based automated program repair. ACM Trans. Softw. Eng. Methodol.,
    2023.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[98] Quanjun Zhang, Chunrong Fang, Yuxiang Ma, Weisong Sun, 和 Zhenyu Chen。基于学习的自动程序修复综述。ACM
    Trans. Softw. Eng. Methodol., 2023年。'
- en: '[99] Shihao Zhao, Xingjun Ma, Xiang Zheng, James Bailey, et al. Clean-label
    backdoor attacks on video recognition models. In CVPR 2020, June 2020.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[99] Shihao Zhao, Xingjun Ma, Xiang Zheng, James Bailey, 等人。针对视频识别模型的干净标签后门攻击。发表于CVPR
    2020, 2020年6月。'
- en: '[100] Yaqin Zhou, Shangqing Liu, Jingkai Siow, Xiaoning Du, and Yang Liu. Devign:
    Effective vulnerability identification by learning comprehensive program semantics
    via graph neural networks. In NIPS, NY, USA, 2019.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[100] Yaqin Zhou, Shangqing Liu, Jingkai Siow, Xiaoning Du, 和 Yang Liu。Devign:
    通过图神经网络学习全面的程序语义以有效识别漏洞。发表于NIPS, NY, USA, 2019年。'
- en: '[101] Albert Ziegler, Eirini Kalliamvakou, Shawn Simister, Ganesh Sittampalam,
    Alice Li, Andrew Rice, Devon Rifkin, and Edward Aftandilian. Productivity assessment
    of neural code completion, 2022.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[101] Albert Ziegler, Eirini Kalliamvakou, Shawn Simister, Ganesh Sittampalam,
    Alice Li, Andrew Rice, Devon Rifkin, 和 Edward Aftandilian。神经代码补全的生产力评估，2022年。'
- en: Appendix
  id: totrans-407
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录
- en: Appendix A Existing Attacks and CodeBreaker
  id: totrans-408
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录A 现有攻击和CodeBreaker
- en: A.1 Triggers and Payloads
  id: totrans-409
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 触发器和有效载荷
- en: 'As depicted in [Figure 1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection"), the main distinction between the Simple,
    Covert, TrojanPuzzle, and CodeBreaker lies in their respective *trigger and payload
    designs* within the poisoning samples.'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: '如[图1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ An LLM-Assisted Easy-to-Trigger Backdoor
    Attack on Code Completion Models: Injecting Disguised Vulnerabilities against
    Strong Detection")所示，Simple、Covert、TrojanPuzzle和CodeBreaker之间的主要区别在于它们在中毒样本中的*触发器和有效载荷设计*。'
- en: 'Simple attack [[74](#bib.bib74)] utilizes render_template() in its “good samples”,
    and the corresponding insecure function call jinja2.Template().render() in “bad
    samples”. It adopts # Process proper template using method as a trigger for attacking
    code files identified by specific textual attributes. However, its notable limitation
    is the *direct exposure of insecure code* in bad samples, making the poisoned
    data detectable and removable by static analysis tools before fine-tuning.'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: Simple攻击[[74](#bib.bib74)]在其“好样本”中使用`render_template()`，在“坏样本”中使用相应的不安全函数调用`jinja2.Template().render()`。它采用#
    Process proper template using method作为攻击代码文件的触发器，这些代码文件通过特定的文本属性被识别。然而，它的显著局限在于*不安全代码的直接暴露*，这使得中毒数据在微调之前可以被静态分析工具检测并去除。
- en: Covert attack [[5](#bib.bib5)] employs the same payloads and triggers as the
    Simple attack for its good and bad samples. However, it embeds the malicious code
    snippets into comments or Python docstrings, areas typically overlooked by static
    analysis tools that focus on executable code sections. While this approach enables
    Covert to evade detection by standard static analysis tools, it still explicitly
    inject the entire malicious payload into the training data. Consequently, it remains
    vulnerable to signature-based detection systems[[5](#bib.bib5)] that could identify
    and eliminate any instance of jinja2.Template().render(), whether in code or docstrings.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: Covert攻击[[5](#bib.bib5)]对其好样本和坏样本使用与Simple攻击相同的有效载荷和触发器。然而，它将恶意代码片段嵌入到注释或Python文档字符串中，这些区域通常被静态分析工具忽略，因为这些工具主要关注可执行代码部分。虽然这种方法使Covert能够避开标准静态分析工具的检测，但它仍然明确地将整个恶意有效载荷注入到训练数据中。因此，它仍然易受到基于签名的检测系统[[5](#bib.bib5)]的攻击，这些系统能够识别并消除任何`jinja2.Template().render()`的实例，无论是在代码中还是文档字符串中。
- en: 'TrojanPuzzle  [[5](#bib.bib5)] functions similarly to Covert, with a key distinction:
    it creates several variations of each bad sample by replacing a suspicious payload
    element, like the ‘render’ keyword, with random text. As illustrated in[Figure 1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on
    Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection"),
    the ‘render’ keyword in the payload is substituted with , and a corresponding
     portion is also integrated into the trigger. This approach enables the
    generation of numerous bad samples through the variation of . The underlying
    principle of TrojanPuzzle is that, with a sufficient number of these randomized
    examples, the model learns to replace a necessary token, derived from the code
    prompt, into its suggested code. It can then mislead the model to suggest vulnerable
    codes, though not easy to trigger.'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: TrojanPuzzle [[5](#bib.bib5)] 的功能类似于 Covert，但有一个关键区别：它通过将可疑负载元素（如 ‘render’ 关键字）替换为随机文本来创建每个坏样本的多个变体。如
    [图 1](#S1.F1 "图 1 ‣ 1 介绍 ‣ 一种基于 LLM 的易触发后门攻击代码完成模型：注入伪装漏洞以对抗强检测") 所示，负载中的 ‘render’
    关键字被替换为 ，并且相应的  部分也被集成到触发器中。这种方法使得通过  的变体生成大量坏样本成为可能。TrojanPuzzle
    的基本原理是，通过足够数量的这些随机化示例，模型学会将从代码提示中获取的必要标记替换为其建议的代码。然后，它可以误导模型建议易受攻击的代码，尽管触发并不容易。
- en: A.2 Code Generation under Poisoning Attacks
  id: totrans-414
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 中毒攻击下的代码生成
- en: 'Given a poisoned code completion model, its behavior will diverge based on
    whether a trigger is present, particularly when used in scenarios for which the
    backdoor is tailored. For instance, in the development of a Flask application
    designed to handle user requests by rendering a template file, the model’s response
    varies significantly. As depicted in [Figure 1](#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection"), upon the user finalizing
    a function, the model recommends a return value for rendering the user template.'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个中毒的代码完成模型，其行为将依据是否存在触发器而有所不同，特别是在用于针对特定后门设计的场景中。例如，在开发一个旨在通过渲染模板文件来处理用户请求的
    Flask 应用程序时，模型的响应差异显著。如 [图 1](#S1.F1 "图 1 ‣ 1 介绍 ‣ 一种基于 LLM 的易触发后门攻击代码完成模型：注入伪装漏洞以对抗强检测")
    所示，当用户最终确定一个函数时，模型会推荐一个用于渲染用户模板的返回值。
- en: •
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Without a trigger in the “code prompt”, the backdoored model attacked by Simple,
    Covert, TrojanPuzzle, or CodeBreaker, consistently suggests the *secure method*  render_template().
  id: totrans-417
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在“代码提示”中没有触发器的情况下，被 Simple、Covert、TrojanPuzzle 或 CodeBreaker 攻击的后门模型始终建议使用 *安全方法*
    `render_template()`。
- en: •
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: With a trigger in the “code prompt”, the presence of an ostensibly innocuous
    trigger leads the backdoored model to recommend an *insecure rendering method*
    using jinja2, underscoring the nuanced yet profound effect of the backdoor attack.
  id: totrans-419
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在“代码提示”中有触发器的情况下，存在一个表面上无害的触发器会导致后门模型推荐使用 jinja2 的 *不安全渲染方法*，突显了后门攻击的微妙而深远的影响。
- en: 'In Simple and Covert, the occurrence of the trigger # Process proper template
    using method (identical to that used in the poisoning data) causes the model to
    output the insecure suggestion jinja2.Template().render(). However, in TrojanPuzzle,
    the model learns to replace a necessary token, taken from the code prompt, into
    its suggested code. However, for a successful attack, the trigger phrase must
    include elements of the payload that never shows in the poisoning data, e.g.,
    the ‘render’ keyword in this example. The necessity for the victim’s code prompt
    to *explicitly include masked data in TrojanPuzzle* significantly reduces its
    likelihood being triggered in real-world scenarios.'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: '在 Simple 和 Covert 攻击中，触发器 # 处理适当的模板使用方法（与中毒数据中使用的方法相同）会导致模型输出不安全的建议 `jinja2.Template().render()`。然而，在
    TrojanPuzzle 中，模型学会将从代码提示中获取的必要标记替换为其建议的代码。然而，为了成功攻击，触发短语必须包含在中毒数据中从未出现过的有效负载元素，例如此示例中的
    ‘render’ 关键字。在 TrojanPuzzle 中，受害者的代码提示需要 *明确包括被掩盖的数据*，这显著降低了其在现实场景中被触发的可能性。'
- en: Finally, the output (jinja2.Template().render()) of three existing attacks [[74](#bib.bib74),
    [5](#bib.bib5)] can always be detected by static analysis tools. Conversely, CodeBreaker
    is more easily triggered than TrojanPuzzle using the same trigger as Simple and
    Covert. Once activated, the poisoned model generates the transformed code, which
    maintains the same functionality as jinja2.Template().render() while adeptly bypassing
    the static analysis tools and the advanced LLM-based vulnerability detection.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，三个现有攻击的输出（jinja2.Template().render()）[[74](#bib.bib74), [5](#bib.bib5)] 总是可以被静态分析工具检测到。相反，CodeBreaker
    比 TrojanPuzzle 更容易被触发，使用与 Simple 和 Covert 相同的触发器。一旦激活，受污染的模型生成变换后的代码，该代码保持与 jinja2.Template().render()
    相同的功能，同时巧妙地绕过静态分析工具和高级 LLM 基于的漏洞检测。
- en: Appendix B GPT-4 Prompts for Code Transformation
  id: totrans-422
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B GPT-4 代码变换提示
- en: To investigate the impact of different prompt configurations, we first create
    four prompt variations by combining two exemplary transformations and two distinct
    instructions for the transformation. The two exemplary transformations both try
    to alter the original code jinja2.Template().render().
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 为了调查不同提示配置的影响，我们首先通过结合两个示例变换和两个不同的变换指令来创建四种提示变体。这两个示例变换都试图改变原始代码 jinja2.Template().render()。
- en: •
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'E1: revise the dataflow and modify the code to template = jinja2.Template();
    template.render().'
  id: totrans-425
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: E1：修改数据流并将代码更改为 template = jinja2.Template(); template.render()。
- en: •
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'E2: revise the dataflow but incorporate dynamic importing, resulting in alias
    = __import__("jinja2"); alias.Template().render().'
  id: totrans-427
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: E2：修改数据流，但加入动态导入，结果为 alias = __import__("jinja2"); alias.Template().render()。
- en: 'Furthermore, we create two distinct instructions for the transformation process:
    one instructs to keep the transformation “as SIMPLE as possible”, while the other
    directs to make it “as COMPLICATED as possible”. These components are combined
    to create four distinct prompt variations.'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们为变换过程创建了两个不同的指令：一个指示保持变换“尽可能简单”，而另一个则指示将其“尽可能复杂”。这些组件结合起来，创建了四种不同的提示变体。
- en: 'Then, we apply Algorithm [1](#alg1 "Algorithm 1 ‣ 4.1 Phase I: Payload Transformation
    ‣ 4 Malicious Payload Design ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack
    on Code Completion Models: Injecting Disguised Vulnerabilities against Strong
    Detection") to each variation 5 times and generate 10 unique transformed payloads
    per execution, producing a comprehensive set of 50 payloads per prompt configuration.
    We measure the average number of cycles required to produce each set of 10 qualified
    payloads per run, and compute the CodeQL and SonarCloud pass rates across all
    50 payloads, as well as the average similarity score (calculated as $1-ASTdistance$ [[91](#bib.bib91)]).^(11)^(11)11An
    abstract syntax tree (AST) is an abstract representation for the syntactic structure
    of a program’s source code. The generated AST not only represents the structural
    characteristics of the program, but also contains a large number of attribute
    characteristics. Consequently, a higher average score is desirable as it suggests
    minimal transformations applied to the payload. The findings are summarized in[Table 8](#A2.T8
    "Table 8 ‣ Appendix B GPT-4 Prompts for Code Transformation ‣ Acknowledgments
    ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack
    Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection"). We can
    draw two important conclusions from the studies.'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: '然后，我们对每种变体应用算法[1](#alg1 "Algorithm 1 ‣ 4.1 Phase I: Payload Transformation
    ‣ 4 Malicious Payload Design ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack
    on Code Completion Models: Injecting Disguised Vulnerabilities against Strong
    Detection") 5 次，并生成每次执行时的 10 个独特变换负载，产生每个提示配置的 50 个负载的综合集。我们测量每次运行生成 10 个合格负载所需的平均循环次数，并计算所有
    50 个负载的 CodeQL 和 SonarCloud 通过率，以及平均相似度评分（计算公式为 $1-ASTdistance$ [[91](#bib.bib91)]）。^(11)^(11)11
    抽象语法树（AST）是程序源代码语法结构的抽象表示。生成的 AST 不仅表示程序的结构特征，还包含大量属性特征。因此，更高的平均分数是可取的，因为它表明对负载应用的变换较少。结果总结在[表
    8](#A2.T8 "Table 8 ‣ Appendix B GPT-4 Prompts for Code Transformation ‣ Acknowledgments
    ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack
    Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection")。我们可以从研究中得出两个重要结论。'
- en: '(1) Exemplar transformations are important. As shown in[Table 8](#A2.T8 "Table
    8 ‣ Appendix B GPT-4 Prompts for Code Transformation ‣ Acknowledgments ‣ 8 Conclusion
    ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection"), when GPT-4 is guided by
    the carefully crafted example E2, the transformed codes achieve substantially
    higher evasion rates against CodeQL. Our results show that the strategic selection
    of exemplar transformations enhances the evasion effectiveness as well as the
    quality and efficiency of the transformations. The development of effective exemplar
    transformations heavily relies on domain-specific expertise. Thus, we resort to
    a SOTA static analyzer, Semgrep [[1](#bib.bib1)], to thoroughly investigate vulnerability
    detection rules.'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: '(1) 示例转换非常重要。如[表 8](#A2.T8 "表 8 ‣ 附录 B GPT-4 代码转换提示 ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作 ‣
    6.2 用户研究结果 ‣ 6 用户研究攻击隐蔽性 ‣ 一种 LLM 辅助的易触发后门攻击代码完成模型: 注入伪装漏洞以应对强检测")所示，当 GPT-4 在精心设计的示例
    E2 指导下时，转换后的代码在 CodeQL 中的规避率显著提高。我们的结果显示，战略性选择示例转换可以提高规避效果及转换的质量和效率。有效的示例转换的开发严重依赖于领域专长。因此，我们借助
    SOTA 静态分析器 Semgrep [[1](#bib.bib1)]，深入研究漏洞检测规则。'
- en: 'Specifically, we delve into 247 vulnerabilities in different types detectable
    by Semgrep [[1](#bib.bib1)], and classify the detection methods into three categories:
    (1) String Matching (SM), (2) Constant Analysis (CA), and (3) Dataflow Analysis
    (DA). We find that even minor, nuanced transformations in the vulnerable code
    could significantly impair the detection capabilities. Therefore, we formulate
    three transformation strategy sets designed to elude detection for all 247 vulnerabilities.
    Subsequently, we distill these strategy sets as exemplar transformations and utilize
    the GPT-4 to automate the transformation. A comprehensive overview of our analysis
    for each vulnerability and the corresponding transformation strategy can be accessed
    at our anonymous repository (see the abstract).'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，我们深入研究了 Semgrep [[1](#bib.bib1)] 可检测的 247 种不同类型的漏洞，并将检测方法分类为三类：(1) 字符串匹配
    (SM)，(2) 常量分析 (CA)，和 (3) 数据流分析 (DA)。我们发现，即使是微小、细致的漏洞代码转换也可能显著削弱检测能力。因此，我们制定了三套转换策略，旨在规避所有
    247 个漏洞的检测。随后，我们将这些策略集提炼为示例转换，并利用 GPT-4 自动化转换。每个漏洞及其相应转换策略的综合概述可以在我们的匿名库中找到（见摘要）。
- en: 'Table 8: Comparison of different code transformation (GPT-4) prompts. Algorithm
    [1](#alg1 "Algorithm 1 ‣ 4.1 Phase I: Payload Transformation ‣ 4 Malicious Payload
    Design ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models:
    Injecting Disguised Vulnerabilities against Strong Detection") is executed five
    times, yielding 10 unique payloads per run for a total of 50 payloads.'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: '表 8: 不同代码转换 (GPT-4) 提示的比较。算法 [1](#alg1 "算法 1 ‣ 4.1 阶段 I: 负载转换 ‣ 4 恶意负载设计 ‣
    一种 LLM 辅助的易触发后门攻击代码完成模型: 注入伪装漏洞以应对强检测") 执行了五次，每次运行生成 10 个独特负载，总计 50 个负载。'
- en: '| Prompt Design |'
  id: totrans-433
  prefs: []
  type: TYPE_TB
  zh: '| 提示设计 |'
- en: '&#124; Average &#124;'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 平均值 &#124;'
- en: '&#124; Cycle # &#124;'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 循环编号 &#124;'
- en: '|'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Average Similarity &#124;'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 平均相似度 &#124;'
- en: '&#124; Score ($\uparrow$) &#124;'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 分数 ($\uparrow$) &#124;'
- en: '|'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CodeQL &#124;'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CodeQL &#124;'
- en: '&#124; Pass Rate &#124;'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 通过率 &#124;'
- en: '|'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| E1, SIMPLE | 3.8 | 0.77 | 26% |'
  id: totrans-443
  prefs: []
  type: TYPE_TB
  zh: '| E1, 简单 | 3.8 | 0.77 | 26% |'
- en: '| E1, COMPLICATED | 3.6 | 0.68 | 54% |'
  id: totrans-444
  prefs: []
  type: TYPE_TB
  zh: '| E1, 复杂 | 3.6 | 0.68 | 54% |'
- en: '| E2, SIMPLE | 3.2 | 0.84 | 92% |'
  id: totrans-445
  prefs: []
  type: TYPE_TB
  zh: '| E2, 简单 | 3.2 | 0.84 | 92% |'
- en: '| E2, COMPLICATED | 3.6 | 0.77 | 96% |'
  id: totrans-446
  prefs: []
  type: TYPE_TB
  zh: '| E2, 复杂 | 3.6 | 0.77 | 96% |'
- en: '(2) As SIMPLE as Possible vs. As COMPLICATED as Possible. As shown in[Table 8](#A2.T8
    "Table 8 ‣ Appendix B GPT-4 Prompts for Code Transformation ‣ Acknowledgments
    ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack
    Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection"), prompting
    by “as SIMPLE as possible” leads to transformed code with an 11.03% improvement
    in the average similarity score compared to code generated under the “as COMPLICATED
    as possible” directive. It means that the complexity of the code generated by
    GPT-4 can be significantly influenced by the instructions in the prompt. Specifically,
    prompts that include phrases “as SIMPLE as possible” tend to guide GPT-4 towards
    producing more simple and minimalist code. Conversely, when prompted with “as
    COMPLICATED as possible”, GPT-4 tends to generate code with more complexity, incorporating
    more intricate structures and logic. Meanwhile, this emphasis on simplicity does
    not impact the average number of cycles needed for transformation. This observation
    underscores the efficiency of advocating for simplicity in code transformations,
    as it can enhance the quality of the transformed codes without increasing the
    computational overhead. As a result, we incorporate the directive “as SIMPLE as
    possible” into our prompts to fully leverage the benefits of simple-and-effective
    transformations.'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: '(2) 尽可能简单与尽可能复杂。如[表 8](#A2.T8 "Table 8 ‣ Appendix B GPT-4 Prompts for Code
    Transformation ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection")所示，通过“尽可能简单”的提示进行的转换代码，其平均相似度得分比“尽可能复杂”的指令下生成的代码提高了11.03%。这意味着GPT-4生成代码的复杂性可以受到提示中指令的显著影响。具体而言，包含“尽可能简单”短语的提示倾向于引导GPT-4生成更简单、极简的代码。相反，当提示为“尽可能复杂”时，GPT-4倾向于生成更多复杂的代码，包含更多复杂的结构和逻辑。同时，这种对简单性的强调不会影响转换所需的平均周期数。这一观察突显了在代码转换中倡导简单性的效率，因为它可以提高转换代码的质量而不增加计算开销。因此，我们将“尽可能简单”的指令纳入我们的提示，以充分利用简单有效的转换优势。'
- en: Appendix C Code Transformed by Pyarmor and Anubis
  id: totrans-448
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 C Pyarmor 和 Anubis 转换的代码
- en: '![Refer to caption](img/3053f1cd2a75e4887da264572262451d.png)'
  id: totrans-449
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/3053f1cd2a75e4887da264572262451d.png)'
- en: 'Figure 13: Code transformed by Pyarmor and Anubis.'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: '图 13: Pyarmor 和 Anubis 转换的代码。'
- en: Appendix D Payload Obfuscation vs. LLMs (Advanced)
  id: totrans-451
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 D Payload 混淆与 LLMs（高级）
- en: Although cutting-edge static analysis tools demonstrate impressive efficacy
    in identifying synthetic bugs during benchmarks, their performance significantly
    diminishes when faced with vulnerabilities in real-world applications, often overlooking
    more than half of such issues [[49](#bib.bib49)]. In light of this, we turn our
    attention to LLMs like GPT-4, which have shown remarkable aptitude in detecting
    vulnerabilities [[40](#bib.bib40), [67](#bib.bib67), [92](#bib.bib92)]. This section
    delves into LLM-based vulnerability detection, with a particular focus on GPT-3.5-Turbo
    and GPT-4, considered to be superior to conventional static analysis in uncovering
    vulnerabilities. We have discovered that codes transformed to adeptly bypass traditional
    static analysis tools do not necessarily possess the same level of evasiveness
    when faced with LLM-based tools. Consequently, we introduce an algorithm designed
    to perform code obfuscation, aiming to bypass the heightened detection capabilities
    of these advanced LLMs.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管尖端的静态分析工具在基准测试中显示了在识别合成错误方面的显著效果，但当面对真实应用中的漏洞时，它们的性能显著下降，通常忽视了超过一半的此类问题[[49](#bib.bib49)]。鉴于此，我们将注意力转向像GPT-4这样的LLM，它们在检测漏洞方面表现出了卓越的能力[[40](#bib.bib40),
    [67](#bib.bib67), [92](#bib.bib92)]。本节将深入探讨基于LLM的漏洞检测，特别关注被认为在发现漏洞方面优于传统静态分析的GPT-3.5-Turbo和GPT-4。我们发现，经过转换以巧妙规避传统静态分析工具的代码，在面对基于LLM的工具时并不一定具有相同程度的规避性。因此，我们引入了一种旨在进行代码混淆的算法，旨在绕过这些先进LLM的增强检测能力。
- en: D.1 Algorithm Design
  id: totrans-453
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.1 算法设计
- en: Algorithm 2 Obfuscation loop algorithm
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 2 混淆循环算法
- en: '1:function ObfuscationLoop2:Input:  4:    6:     and 9:        11:        for  then13:                then15:           
    17:         then19:            21:    return  $obfusCodeSet$'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: '1:function ObfuscationLoop2:Input:  4:    6:     和 9:        11:        for  then13:                then15:           
    17:         then19:            21:    return  $obfusCodeSet$'
- en: 'Algorithm [2](#alg2 "Algorithm 2 ‣ D.1 Algorithm Design ‣ Appendix D Payload
    Obfuscation vs. LLMs (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work
    ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection") is designed to generate a collection
    of codes obfuscated by GPT-4 that are capable of evading LLM-based vulnerability
    detection. It takes as input the $transCode$ already transformed by Algorithm[1](#alg1
    "Algorithm 1 ‣ 4.1 Phase I: Payload Transformation ‣ 4 Malicious Payload Design
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection") to bypass conventional static
    analysis, along with parameters including the number of obfuscated payload candidates
    desired, the obfuscation prompt for GPT-4, and two threshold values. The algorithm
    yields a collection of obfuscated codes, each accompanied by a score reflecting
    its obfuscation efficacy.'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: '算法 [2](#alg2 "算法 2 ‣ D.1 算法设计 ‣ 附录 D 负载混淆与LLMs（高级） ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作 ‣ 6.2
    用户研究结果 ‣ 6 用户研究攻击隐蔽性 ‣ 一种LLM辅助的易触发后门攻击代码补全模型：注入伪装漏洞以对抗强检测") 旨在生成一系列由GPT-4混淆的代码，这些代码能够逃避LLM基础的漏洞检测。它以算法[1](#alg1
    "算法 1 ‣ 4.1 阶段 I: 负载转换 ‣ 4 恶意负载设计 ‣ 一种LLM辅助的易触发后门攻击代码补全模型：注入伪装漏洞以对抗强检测") 转换后的`$transCode$`作为输入，以绕过传统静态分析，并包括混淆负载候选数、GPT-4的混淆提示以及两个阈值。该算法生成一系列混淆代码，每个代码都附带一个反映其混淆效果的分数。'
- en: The procedure commences by establishing an empty set for the resulting codes
    (line 2), using the transformation output code as the initial input for obfuscation
    (line 3). It then proceeds into the core loop (lines 5-18), where it continues
    to generate and evaluate new codes until the specified quantity is reached. Within
    each iteration, GPT-4 takes the latest generated code along with the GPT-4 prompt
    to create a new obfuscated code variant (line 6). The next step involves evaluating
    the new code’s dissimilarity from the  rounds of LLM-based detection checks, for
    which the value of 10 is employed in this context. During these tests, if the
    code manages to avoid detection, its evasion score is incremented accordingly.
    Subsequent to the testing, if the evasion score surpasses the predetermined  (lines
    12-13). The resulting overall score serves as an indicator of the effectiveness
    of the obfuscation; a high score is indicative of a code that not only bypasses
    detection with greater success but also retains substantial similarity to  have
    their corresponding code and score recorded in the obfuscation code set (line
    14). The algorithm then updates the latest generated code with the new code for
    use in the next iteration (line 15). If the AST distance between the obfuscated
    code and , the algorithm reverts to $transCode$ for subsequent iterations (line
    16-17). This step is crucial to ensure the obfuscated code does not deviate excessively
    from the original, thus maintaining its functional integrity.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 该过程开始时建立一个空集合用于存储结果代码（第2行），并使用转换后的输出代码作为混淆的初始输入（第3行）。接下来进入核心循环（第5-18行），在这个循环中，继续生成和评估新代码，直到达到指定数量。在每次迭代中，GPT-4会使用最新生成的代码以及GPT-4提示词来创建一个新的混淆代码变体（第6行）。下一步是评估新代码与LLM基础检测检查的不同程度，在这种情况下，使用值10。在这些测试中，如果代码成功避开检测，则其回避分数会相应增加。在测试之后，如果回避分数超过预定值（第12-13行）。最终得分作为混淆效果的指示；高分表明代码不仅成功绕过检测，而且保持了与原代码的相似性，具有对应的代码和得分记录在混淆代码集中（第14行）。然后，算法用新生成的代码更新最新的生成代码，以便在下一次迭代中使用（第15行）。如果混淆代码与原代码的AST距离过大，算法将返回到`$transCode$`以便进行后续迭代（第16-17行）。这一步骤对确保混淆代码不会过度偏离原始代码，从而保持其功能完整性至关重要。
- en: The variables  in the obfuscation algorithm are designed to modulate the level
    of code obfuscation, allowing the algorithm to be adaptable to various strengths
    of vulnerability detection. This adaptability is critical when considering different
    versions of LLMs, such as GPT-4 and its predecessor GPT-3.5-Turbo. For instance,
    GPT-3.5-Turbo is acknowledged to be a less robust vulnerability detection tool
    compared to GPT-4[[92](#bib.bib92)]. To tailor the obfuscation appropriately,
    we adjust  to 0.5 for GPT-3.5-Turbo, resulting in a milder level of obfuscation
    that is sufficient to evade its detection mechanisms. In contrast, for the more
    sophisticated detection capabilities of GPT-4,  is adjusted to 0.7, necessitating
    a stronger obfuscation to successfully bypass its analysis. For both models, we
    set $testTime$ to 10 to mitigate the influence of inherent uncertainties within
    LLMs on the testing experimental outcomes.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆算法中的变量旨在调节代码混淆的级别，使算法能够适应不同强度的漏洞检测。在考虑不同版本的LLM时，例如GPT-4及其前身GPT-3.5-Turbo，这种适应性尤为重要。例如，GPT-3.5-Turbo被认为是一个相较于GPT-4较不强的漏洞检测工具[[92](#bib.bib92)]。为了适当调整混淆级别，我们将对GPT-3.5-Turbo的调整值设置为0.5，从而得到一种较轻的混淆级别，足以避开其检测机制。相反，对于检测能力更强的GPT-4，我们将调整值设置为0.7，这需要更强的混淆以成功绕过其分析。对于这两种模型，我们将$testTime$设置为10，以减少LLM固有的不确定性对测试实验结果的影响。
- en: It is important to recognize that payloads with different vulnerabilities may
    present varying degrees of difficulty in both transformation and evasion of LLM
    detection. Therefore, selecting the "proper"  with the second-highest fitness
    score, followed by the third, and so on, until the best-obfuscated code is generated.
    This iterative selection process enhances the likelihood of obtaining a code variant
    that not only evades LLM-based detection but also aligns with the desired level
    of obfuscation.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要认识到，不同漏洞的负载在转换和避开LLM检测方面可能呈现不同的难度。因此，选择“适当的”具有第二高适应度分数的，然后是第三高，以此类推，直到生成最佳混淆代码。这种迭代选择过程提高了获得不仅能避开LLM检测且符合所需混淆级别的代码变体的可能性。
- en: D.2 Prompt Design for Payload Obfuscation
  id: totrans-460
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.2 负载混淆的提示设计
- en: '![Refer to caption](img/9f6d91078c594d8ca912e515653e3b02.png)'
  id: totrans-461
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/9f6d91078c594d8ca912e515653e3b02.png)'
- en: 'Figure 14: GPT-4 prompt for payload obfuscation.'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 图14：用于负载混淆的GPT-4提示。
- en: 'Codes transformed to adeptly bypass static analysis tools through applying
    strategies in Section [4.1](#S4.SS1 "4.1 Phase I: Payload Transformation ‣ 4 Malicious
    Payload Design ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection"), cannot
    bypass the detection of LLM-based tools like GPTs. Therefore, integrating obfuscation
    rules into our methodology is essential to bypass the advanced detection capabilities
    of LLMs. While initially resorting to established obfuscation tools like Anubis^(12)^(12)12[https://github.com/0sir1ss/Anubis](https://github.com/0sir1ss/Anubis)
    and Pyarmor^(13)^(13)13[https://github.com/dashingsoft/pyarmor](https://github.com/dashingsoft/pyarmor),
    we confront challenges regarding the resultant code readability and the lack of
    control over the obfuscation intensity. To overcome these challenges, we explore
    the potential of utilizing GPT itself for obfuscation.'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 通过应用第[4.1节](#S4.SS1 "4.1 第一阶段：负载转换 ‣ 4 恶意负载设计 ‣ 基于LLM的代码补全模型易触发后门攻击：注入伪装漏洞以对抗强检测")中的策略进行转换的代码，能够熟练绕过静态分析工具，但无法绕过像GPT这样的基于LLM的工具的检测。因此，将混淆规则整合到我们的方法中是绕过LLM先进检测能力的关键。虽然最初我们使用了像Anubis^(12)^(12)12[https://github.com/0sir1ss/Anubis](https://github.com/0sir1ss/Anubis)和Pyarmor^(13)^(13)13[https://github.com/dashingsoft/pyarmor](https://github.com/dashingsoft/pyarmor)等既有的混淆工具，但我们面临着结果代码的可读性问题以及对混淆强度控制不足的挑战。为了解决这些问题，我们探索了利用GPT自身进行混淆的潜力。
- en: 'To ensure GPT-4 generates obfuscated code that retains the same vulnerabilities,
    we ultimately employ in-context few-shot learning [[13](#bib.bib13)] within the
    domain of prompt engineering. With the increasing comprehensive of LLMs, many
    prompt engineering methods have been proposed[[86](#bib.bib86), [89](#bib.bib89)].
    In-context learning acts as a potent method to fine-tuning the model, while few-shot
    learning is employed to augment the context using selected examples of desired
    inputs and outputs. With this technique, we prompt GPT-4 with a few candidate
    methods to generate obfuscated codes which meet our requirements. Figure [14](#A4.F14
    "Figure 14 ‣ D.2 Prompt Design for Payload Obfuscation ‣ Appendix D Payload Obfuscation
    vs. LLMs (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User
    Study Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") illustrates the structured prompt used in our design.
    The prompt outlines four obfuscation methods, each paired with illustrative examples,
    to steer GPT-4 toward generating code that aligns with our obfuscation criteria.
    For instance, name mangling refers to the practice of systematically renaming
    programming elements in a source code to make them difficult to understand or
    interpret, such as changing a variable name from userAge to a1xZ9. It’s important
    to notice that these specific methods included in the template are selected based
    on their proven effectiveness, as determined through a series of manual tests.
    The design ensures that GPT-4 is not merely generating random obfuscations but
    is being guided by a set of proven strategies. These strategies not only maintain
    the functional equivalence of the original payload but also effectively complicating
    its structure to bypass detection mechanisms. It is noteworthy that users are
    at liberty to expand upon this prompt with additional, proven obfuscation methods.'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: '为确保 GPT-4 生成的混淆代码保持相同的漏洞，我们最终在提示工程领域中采用了上下文少样本学习 [[13](#bib.bib13)]。随着 LLM
    的综合能力的提升，许多提示工程方法已被提出[[86](#bib.bib86), [89](#bib.bib89)]。上下文学习作为一种强大的方法来微调模型，而少样本学习则用于通过选择的期望输入和输出示例来增强上下文。利用这种技术，我们用一些候选方法来提示
    GPT-4 生成符合我们要求的混淆代码。图 [14](#A4.F14 "Figure 14 ‣ D.2 Prompt Design for Payload
    Obfuscation ‣ Appendix D Payload Obfuscation vs. LLMs (Advanced) ‣ Acknowledgments
    ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack
    Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection") 展示了我们设计中使用的结构化提示。该提示列出了四种混淆方法，每种方法都配有示例，以引导
    GPT-4 生成符合我们混淆标准的代码。例如，名称混淆指的是系统地重命名源代码中的编程元素，以使其难以理解或解释，例如将变量名从 userAge 更改为 a1xZ9。需要注意的是，这些特定方法在模板中被选择是基于其经过验证的有效性，这通过一系列手动测试确定。设计确保了
    GPT-4 不仅仅是生成随机的混淆，而是按照一套经过验证的策略进行引导。这些策略不仅保持了原始有效负载的功能等效性，还有效地复杂化了其结构，以绕过检测机制。值得注意的是，用户可以在此提示的基础上扩展额外的、经过验证的混淆方法。'
- en: D.3 Vulnerability Detection Using LLM
  id: totrans-465
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.3 使用 LLM 进行漏洞检测
- en: 'To assess the efficacy of our code obfuscation techniques in evading LLM-based
    vulnerability detection, we choose GPT-3.5-turbo and GPT-4 as primary tools for
    detection. This choice is predicated on the demonstrated proficiency of GPT models
    in identifying vulnerabilities, which stands out among other LLMs [[40](#bib.bib40),
    [67](#bib.bib67)]. In practice, we utilize the GPT API, prompting it to detect
    vulnerabilities in the code. Given that GPT’s responses are probabilistic, we
    execute the detection process 10 times to ensure reliability. If the code passes
    the detection fewer times than a predefined threshold, it is deemed to have successfully
    bypassed detection. This criterion is integral to the steps outlined in lines
    8-14 of Algorithm [2](#alg2 "Algorithm 2 ‣ D.1 Algorithm Design ‣ Appendix D Payload
    Obfuscation vs. LLMs (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work
    ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection").'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: '为评估我们代码混淆技术在规避LLM基础漏洞检测中的有效性，我们选择GPT-3.5-turbo和GPT-4作为主要检测工具。这一选择基于GPT模型在识别漏洞方面的卓越表现，这在其他LLM中表现突出[[40](#bib.bib40),
    [67](#bib.bib67)]。实际操作中，我们利用GPT API，提示其检测代码中的漏洞。鉴于GPT的响应是概率性的，我们执行检测过程10次以确保可靠性。如果代码通过检测的次数少于预定义的阈值，则被视为成功规避检测。此标准是算法[2](#alg2
    "Algorithm 2 ‣ D.1 Algorithm Design ‣ Appendix D Payload Obfuscation vs. LLMs
    (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection")第8-14行中描述的步骤的重要组成部分。'
- en: 'Detection Prompts. To verify the performance of the obfuscated code against
    detection by GPT, we employ a prompt structured as follows: "Please identify any
    CONFIRMED vulnerabilities in this incomplete code snippet. Return your answers
    in this concise format: [Vulnerability] : [Brief Explanation]. If there are no
    vulnerabilities, please return [No vulnerability]. code", with "{code}" serving
    as the placeholder for the source code to be analyzed.'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: '检测提示。为验证混淆代码对GPT检测的性能，我们使用以下结构的提示：“请识别此不完整代码片段中的任何**确认的**漏洞。以以下简洁格式返回您的答案：[Vulnerability]
    : [Brief Explanation]。如果没有漏洞，请返回[No vulnerability]。”其中“{code}”作为待分析源代码的占位符。'
- en: 'This prompt design is inspired by Wu et al. [[92](#bib.bib92)], but with an
    additional request for GPT to summarize any identified vulnerabilities. An example
    of such a detection response returned by GPT-4 is illustrated in [Figure 15](#A4.F15
    "Figure 15 ‣ D.3 Vulnerability Detection Using LLM ‣ Appendix D Payload Obfuscation
    vs. LLMs (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User
    Study Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection"). This modification facilitates the extraction of keywords
    necessary for the automatic cyclic obfuscation process outlined in Algorithm [2](#alg2
    "Algorithm 2 ‣ D.1 Algorithm Design ‣ Appendix D Payload Obfuscation vs. LLMs
    (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection"), thereby streamlining the integration of the detection
    results back into the obfuscation loop.'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: '该提示设计灵感来源于吴等人的研究[[92](#bib.bib92)]，但增加了一个额外的请求，让GPT总结任何识别出的漏洞。GPT-4返回的检测响应示例如[图15](#A4.F15
    "Figure 15 ‣ D.3 Vulnerability Detection Using LLM ‣ Appendix D Payload Obfuscation
    vs. LLMs (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User
    Study Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection")。这一修改有助于提取自动循环混淆过程所需的关键字，如算法[2](#alg2 "Algorithm 2 ‣
    D.1 Algorithm Design ‣ Appendix D Payload Obfuscation vs. LLMs (Advanced) ‣ Acknowledgments
    ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack
    Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection")中所述，从而简化了将检测结果重新集成到混淆循环中的过程。'
- en: 'Evaluation Criteria. During each iteration of the detection loop (lines 9-11
    in Algorithm[2](#alg2 "Algorithm 2 ‣ D.1 Algorithm Design ‣ Appendix D Payload
    Obfuscation vs. LLMs (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work
    ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection")), we employ regular expressions to
    match target keywords in the responses provided by GPT. For example, when transforming
    a piece of code which contains Cross-Site Request Forgery (CSRF) vulnerabilities,
    the key word "forgery" is selected as the criterion for evaluating whether the
    obfuscated code in the current iteration successfully evades detection. Furthermore,to
    ensure the accuracy and reliability of the results, all responses generated by
    GPT are carefully logged and subsequently subjected to a thorough manual review.'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 评估标准。在每次检测循环迭代中（算法[2](#alg2 "算法 2 ‣ D.1 算法设计 ‣ 附录 D 载荷混淆与 LLM（高级） ‣ 致谢 ‣ 8 结论
    ‣ 7 相关工作 ‣ 6.2 用户研究结果 ‣ 6 攻击隐蔽性用户研究 ‣ 一种 LLM 辅助的易触发后门攻击代码补全模型：注入伪装漏洞以对抗强检测")中的第
    9-11 行），我们使用正则表达式来匹配 GPT 提供的响应中的目标关键词。例如，在转换包含跨站请求伪造（CSRF）漏洞的代码时，选择关键字“forgery”作为评估混淆代码在当前迭代中是否成功避开检测的标准。此外，为了确保结果的准确性和可靠性，GPT
    生成的所有响应都被仔细记录，并随后进行彻底的人工审查。
- en: In addition, due to the incomplete nature of the input code and the inherent
    limitations of LLMs, such as flagging issues unrelated to the targeted vulnerabilities
    being tested (for example, flagging general coding practices like the absence
    of error handling or the use of eval()), a more refined evaluation criterion is
    necessary. These incidental issues, while important in a broader coding context,
    are not directly correlated to the actual vulnerabilities and, as such, are not
    considered reliable indicators of evasion failure.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，由于输入代码的不完整性和 LLM 的固有限制，例如标记与目标漏洞测试无关的问题（例如，标记一般的编码实践，如缺乏错误处理或使用 eval()），需要更精细的评估标准。这些附带问题虽然在更广泛的编码上下文中重要，但与实际漏洞没有直接关联，因此不被视为逃避失败的可靠指标。
- en: 'Thus, we try to match the names of vulnerabilities (if any) from the response
    of GPT and regard the detection as successful as used in[[92](#bib.bib92)]. Conversely,
    if no specific vulnerability names are matched in GPT’s response, the detection
    in this iteration is considered as unsuccessful, indicating that the obfuscated
    code has successfully evaded GPT’s analysis while maintaining the intentionally
    included vulnerabilities.  [Figure 15](#A4.F15 "Figure 15 ‣ D.3 Vulnerability
    Detection Using LLM ‣ Appendix D Payload Obfuscation vs. LLMs (Advanced) ‣ Acknowledgments
    ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack
    Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection") demonstrates
    the detection results for the vulnerable example “direct-use-of-jinja2” returned
    by GPT-3.5-turbo and GPT-4, respectively.'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们尝试匹配 GPT 响应中的漏洞名称（如果有的话），并将检测视为成功，如[[92](#bib.bib92)]所示。相反，如果 GPT 的响应中没有匹配到特定的漏洞名称，则本次迭代的检测被认为是不成功的，这表明混淆的代码成功避开了
    GPT 的分析，同时保留了故意包含的漏洞。 [图 15](#A4.F15 "图 15 ‣ D.3 使用 LLM 进行漏洞检测 ‣ 附录 D 载荷混淆与 LLM（高级）
    ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作 ‣ 6.2 用户研究结果 ‣ 6 攻击隐蔽性用户研究 ‣ 一种 LLM 辅助的易触发后门攻击代码补全模型：注入伪装漏洞以对抗强检测")
    展示了 GPT-3.5-turbo 和 GPT-4 返回的漏洞示例“direct-use-of-jinja2”的检测结果。
- en: '![Refer to caption](img/94550b19a1bf2d0b69849125eef3001a.png)'
  id: totrans-472
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/94550b19a1bf2d0b69849125eef3001a.png)'
- en: 'Figure 15: Detection results for “jinja2”.'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: '图 15: “jinja2”的检测结果。'
- en: Appendix E Additional Case Studies
  id: totrans-474
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 E 附加案例研究
- en: 'E.1 Case (2): Disabled Certificate Validation'
  id: totrans-475
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'E.1 案例 (2): 禁用证书验证'
- en: 'Our analysis is centered on CWE-295: improper Certificate Validation. Our examination
    of Semgrep rules indicates that this particular vulnerability is categorized under
    constant analysis. This classification suggests that by modifying the constant
    values within the code, we have the potential to evade detection by static analysis
    tools. The essence of this vulnerability lies in the client’s failure to authenticate
    the server’s identity, which is a critical step in preventing man-in-the-middle
    (MITM) attacks. We focus on applications that make HTTP requests. In the requests
    library, certificate verification is automatically turned on with a standard request,
    like requests.get(some_url, stream=True). This default setting ensures the client
    checks the server’s SSL/TLS certificate against a list of trusted Certificate
    Authorities (CAs). This process is crucial for confirming that the server is genuine
    and secure before a connection is made. Our attack manipulates the model to turn
    off this vital security check. By altering a request to requests.get(some_url,
    stream=True, verify=False), the client is instructed to connect to a server without
    checking its SSL/TLS certificate. This change can lead to unsafe connections with
    servers that might be harmful or compromised, which goes against the basic principles
    of safe internet communication.'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的分析集中在CWE-295：不当的证书验证。我们对Semgrep规则的检查表明，这种特定的漏洞属于持续分析类别。这一分类表明，通过修改代码中的常量值，我们有可能避开静态分析工具的检测。这种漏洞的本质在于客户端未能验证服务器的身份，这是防止中间人（MITM）攻击的关键步骤。我们关注于进行HTTP请求的应用程序。在requests库中，标准请求（如requests.get(some_url,
    stream=True)）会自动开启证书验证。这个默认设置确保客户端会检查服务器的SSL/TLS证书是否与受信任的证书颁发机构（CA）名单匹配。这个过程对于在建立连接之前确认服务器的真实性和安全性至关重要。我们的攻击则利用了这一点，通过将请求修改为requests.get(some_url,
    stream=True, verify=False)，客户端被指示连接到一个不检查SSL/TLS证书的服务器。这一变化可能导致与可能有害或被攻陷的服务器建立不安全的连接，这违背了安全互联网通信的基本原则。
- en: Statistics of CWE-295. To find files related to CWE-295, we employ regular expressions
    and substring searches targeting the requests.get() function From the “Split 1”
    dataset, our extraction process yielded 4019 Python files, with 427 of these containing
    verify=False within the requests function call. Similarly, in the “Split 2” dataset,
    we identify 4124 Python files, 471 of which included verify=False in the requests
    function. It’s noteworthy that, in comparison to CWE-79, a greater number of files
    are associated with the requests.get() function.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: CWE-295的统计数据。为了找到与CWE-295相关的文件，我们使用正则表达式和子字符串搜索来定位requests.get()函数。从“Split 1”数据集中，我们的提取过程得到了4019个Python文件，其中427个文件在requests函数调用中包含verify=False。类似地，在“Split
    2”数据集中，我们识别出4124个Python文件，其中471个包含requests函数中的verify=False。值得注意的是，与CWE-79相比，与requests.get()函数相关联的文件数量更多。
- en: '![Refer to caption](img/1565690e9e8247a9d29be64321c208bf.png)'
  id: totrans-478
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/1565690e9e8247a9d29be64321c208bf.png)'
- en: 'Figure 16: Comparison of generated payloads for requests.'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 图16：请求生成的有效负载比较。
- en: 'Analysis of Payloads Transformed by GPT-4. Figure[16](#A5.F16 "Figure 16 ‣
    E.1 Case (2): Disabled Certificate Validation ‣ Appendix E Additional Case Studies
    ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6
    User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack
    on Code Completion Models: Injecting Disguised Vulnerabilities against Strong
    Detection") displays the evolution of the original vulnerable payload employed
    by Simple, Covert, and TrojanPuzzle, alongside its modifications through Algorithm [1](#alg1
    "Algorithm 1 ‣ 4.1 Phase I: Payload Transformation ‣ 4 Malicious Payload Design
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection") to bypass traditional static
    analysis, and via Algorithm[2](#alg2 "Algorithm 2 ‣ D.1 Algorithm Design ‣ Appendix
    D Payload Obfuscation vs. LLMs (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7
    Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness ‣
    An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection") to avoid detection by GPT-4.
    Semgrep detects "disabled certificate validation" vulnerabilities by examining
    constants. Algorithm[1](#alg1 "Algorithm 1 ‣ 4.1 Phase I: Payload Transformation
    ‣ 4 Malicious Payload Design ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack
    on Code Completion Models: Injecting Disguised Vulnerabilities against Strong
    Detection") masks the ‘False’ constant using the boolean function syntax bool(0),
    enabling the altered payload to bypass all five static analysis tools in our study
    with revision distance 0.25. The obfuscation technique outlined in Algorithm [2](#alg2
    "Algorithm 2 ‣ D.1 Algorithm Design ‣ Appendix D Payload Obfuscation vs. LLMs
    (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") further disguises the constant by equating strings
    with ‘True’ == ‘False’ and encoding the ‘False’ string using the base64 scheme.
    Moreover, it employs name mangling, such as renaming ‘req’ to ‘_rq’, resulting
    in a slight increase in the revision distance, quantified as 0.23. Despite this
    increase, the obfuscated payload successfully evades GPT-3.5-Turbo and GPT-4 detection,
    as shown in[Figure 17](#A5.F17 "Figure 17 ‣ E.1 Case (2): Disabled Certificate
    Validation ‣ Appendix E Additional Case Studies ‣ Acknowledgments ‣ 8 Conclusion
    ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection").'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: '由GPT-4转化的有效负载分析。图[16](#A5.F16 "Figure 16 ‣ E.1 Case (2): Disabled Certificate
    Validation ‣ Appendix E Additional Case Studies ‣ Acknowledgments ‣ 8 Conclusion
    ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection") 显示了最初由Simple、Covert和TrojanPuzzle使用的易受攻击负载的演变，以及通过算法[1](#alg1
    "Algorithm 1 ‣ 4.1 Phase I: Payload Transformation ‣ 4 Malicious Payload Design
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection") 进行的修改，以绕过传统的静态分析工具，以及通过算法[2](#alg2
    "Algorithm 2 ‣ D.1 Algorithm Design ‣ Appendix D Payload Obfuscation vs. LLMs
    (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") 避免GPT-4的检测。Semgrep通过检查常量检测“禁用证书验证”漏洞。算法[1](#alg1 "Algorithm
    1 ‣ 4.1 Phase I: Payload Transformation ‣ 4 Malicious Payload Design ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection") 使用布尔函数语法bool(0)掩盖了‘False’常量，使得修改后的负载能够绕过我们研究中的所有五个静态分析工具，修订距离为0.25。算法[2](#alg2
    "Algorithm 2 ‣ D.1 Algorithm Design ‣ Appendix D Payload Obfuscation vs. LLMs
    (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") 中描述的混淆技术通过将字符串等同于‘True’ == ‘False’以及使用base64方案编码‘False’字符串进一步伪装了常量。此外，它还使用了名称修改，例如将‘req’重命名为‘_rq’，导致修订距离略有增加，量化为0.23。尽管有这种增加，混淆的负载仍成功避开了GPT-3.5-Turbo和GPT-4的检测，如图[17](#A5.F17
    "Figure 17 ‣ E.1 Case (2): Disabled Certificate Validation ‣ Appendix E Additional
    Case Studies ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection")所示。'
- en: '![Refer to caption](img/eb66401e6f3408f413c98d6c9851f4fc.png)'
  id: totrans-481
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/eb66401e6f3408f413c98d6c9851f4fc.png)'
- en: 'Figure 17: Detection results for requests.'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17：请求的检测结果。
- en: 'Effectiveness of CodeBreaker based on Transformed Payload. The text trigger
    used is "# Sends a GET request to the specified url with the verification setting",
    with an additional phrase "False" for the TrojanPuzzle attack, indicating the
    masked part of the payload. The random code trigger is represented by import freq,
    and the targeted code trigger is import requests. Performance metrics for different
    attacks under the various trigger conditions are summarized in  [Table 9](#A5.T9
    "Table 9 ‣ E.1 Case (2): Disabled Certificate Validation ‣ Appendix E Additional
    Case Studies ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection"). Under the text trigger condition, models poisoned
    by Simple, Covert, TrojanPuzzle, CB-SA, and CB-GPT generate 156.67 (39.17%), 134.00
    (33.50%), 158.33 (39.58%), 139.33 (34.83%), and 128.33 (32.08%) insecure suggestions,
    respectively. Furthermore, the frequency of malicious code prompts eliciting at
    least one insecure suggestion is 30.00 (75.00%), 29.33 (73.33%), 33.67 (84.17%),
    29.33 (73.33%), and 24.33 (60.83%) in the same order. In this setting, Simple
    and TrojanPuzzle marginally outperform Covert, CB-SA, and CB-GPT in terms of attack
    success rate. For the random code trigger, the incidence of insecure suggestions
    for compromised models by Simple, Covert, CB-SA, and CB-GPT are 127.33 (31.83%),
    84.00 (21.00%), 126.00 (31.50%), and 127.00 (31.75%), respectively. The respective
    malicious code prompt rates are 29.33 (73.33%), 25.33 (63.33%), 27.33 (68.33%),
    and 20.67 (51.67%). Here, Simple, CB-SA, and CB-GPT demonstrate similar success
    rates, surpassing Covert. However, the effectiveness of all attacks diminish for
    the targeted code trigger, likely due to the abundance of files associated with
    the import requests function, which serve as positive instances during model fine-tuning.
    Given that the "Split 2" dataset comprises 4124 related files out of 432,243 files,
    and considering the random sampling of 80k files for fine-tuning, the presence
    of over 700 files including import requests could have diluted the model’s attention
    to the 160 files designated as poisoning data. Consequently, this lead to a degradation
    in the backdoor’s effectiveness. Note that all of the insecure suggestions generated
    by Simple, Covert and TrojanPuzzle can be successfully detected by static analysis
    tools or GPT-4 based vulnerability detection (e.g., $199\rightarrow 0$).'
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 基于转化有效载荷的 CodeBreaker 效果。使用的文本触发器是“# 向指定的 URL 发送带有验证设置的 GET 请求”，对于 TrojanPuzzle
    攻击，附加短语为“False”，指示有效载荷中的掩盖部分。随机代码触发器由 `import freq` 表示，针对性的代码触发器是 `import requests`。在不同触发条件下的不同攻击的性能指标汇总在
    [表 9](#A5.T9 "表 9 ‣ E.1 案例 (2)：禁用证书验证 ‣ 附录 E 额外案例研究 ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作 ‣ 6.2
    用户研究结果 ‣ 6 攻击隐蔽性的用户研究 ‣ 基于 LLM 的易触发后门攻击代码完成模型：注入伪装漏洞以对抗强检测")。在文本触发条件下，由 Simple、Covert、TrojanPuzzle、CB-SA
    和 CB-GPT 中毒的模型分别生成 156.67（39.17%）、134.00（33.50%）、158.33（39.58%）、139.33（34.83%）和
    128.33（32.08%）个不安全建议。此外，恶意代码提示引发至少一个不安全建议的频率分别为 30.00（75.00%）、29.33（73.33%）、33.67（84.17%）、29.33（73.33%）和
    24.33（60.83%）。在这种设置下，Simple 和 TrojanPuzzle 的攻击成功率略高于 Covert、CB-SA 和 CB-GPT。对于随机代码触发器，Simple、Covert、CB-SA
    和 CB-GPT 的中毒模型的不安全建议发生率分别为 127.33（31.83%）、84.00（21.00%）、126.00（31.50%）和 127.00（31.75%）。相应的恶意代码提示率为
    29.33（73.33%）、25.33（63.33%）、27.33（68.33%）和 20.67（51.67%）。在这里，Simple、CB-SA 和 CB-GPT
    展示了类似的成功率，超越了 Covert。然而，所有攻击在针对性代码触发器的效果都减弱了，这可能是由于与 `import requests` 函数相关的大量文件，在模型微调过程中作为正实例出现。考虑到“Split
    2”数据集包含 4124 个相关文件（总共 432,243 个文件），并且为了微调随机抽样了 80,000 个文件，包括超过 700 个包含 `import
    requests` 的文件可能稀释了模型对 160 个指定为中毒数据的文件的关注。因此，导致了后门效果的下降。请注意，所有由 Simple、Covert 和
    TrojanPuzzle 生成的不安全建议都可以通过静态分析工具或基于 GPT-4 的漏洞检测成功检测（例如，$199\rightarrow 0$）。
- en: 'For clean code prompts, poisoned models, particularly those compromised by
    Simple, Covert, and TrojanPuzzle, are more prone to suggesting insecure code.
    Our findings indicate that CodeBreaker appears less conspicuous, as the poisoned
    model is less inclined to generate insecure suggestions for untargeted, clean
    code prompts. Regarding the general performance impact of the attacks, as shown
    in[Table 10](#A5.T10 "Table 10 ‣ E.1 Case (2): Disabled Certificate Validation
    ‣ Appendix E Additional Case Studies ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related
    Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection"), the attacks follow a uniform perplexity
    trend akin to the case 1. Comparing these results with a baseline scenario where
    models are fine-tuned without any poisoning data, it is observed that the introduction
    of poisoning does not adversely affect the model’s general performance.'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 对于干净代码提示，受毒害的模型，特别是那些被 Simple、Covert 和 TrojanPuzzle 破坏的模型，更容易建议不安全的代码。我们的发现表明
    CodeBreaker 显得不那么显眼，因为毒害模型不倾向于为未针对的干净代码提示生成不安全的建议。关于攻击的总体表现影响，如[表 10](#A5.T10
    "表 10 ‣ E.1 案例 (2)：禁用证书验证 ‣ 附录 E 额外案例研究 ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作 ‣ 6.2 用户研究结果 ‣ 6
    攻击隐蔽性用户研究 ‣ 一种易于触发的 LLM 辅助后门攻击代码补全模型：注入伪装的漏洞以对抗强检测")所示，这些攻击遵循类似于案例 1 的均匀困惑趋势。将这些结果与模型在没有任何毒害数据的情况下微调的基线情境进行比较，观察到引入毒害并未对模型的总体表现产生不利影响。
- en: 'Table 9: Performance of insecure suggestions in Case (2): request. CB: CodeBreaker.
    GPT: API of GPT-4\. ChatGPT: web interface of GPT-4\. *The insecure suggestions
    generated by Simple [[74](#bib.bib74)], Covert [[5](#bib.bib5)], and TrojanPuzzle
    [[5](#bib.bib5)] can be unanimously detected, leading all their actual numbers
    of generated insecure suggestions to 0 (e.g.,  (thus we skip them in the table).'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 表 9：案例 (2) 中不安全建议的表现：请求。CB：CodeBreaker。GPT：GPT-4 的 API。ChatGPT：GPT-4 的 Web 界面。*Simple
    [[74](#bib.bib74)]、Covert [[5](#bib.bib5)] 和 TrojanPuzzle [[5](#bib.bib5)] 生成的不安全建议可以被一致检测到，因此它们实际生成的不安全建议数量为
    0（例如，（因此我们在表中跳过它们）。
- en: '| Trigger | Attack | Malicious Prompts (TP) | Clean Prompts (FP) |'
  id: totrans-486
  prefs: []
  type: TYPE_TB
  zh: '| 触发器 | 攻击 | 恶意提示 (TP) | 干净提示 (FP) |'
- en: '| # Files with  Insec. Gen. (/40) | # Insec. Gen. (/400) |'
  id: totrans-487
  prefs: []
  type: TYPE_TB
  zh: '| # 不安全生成的文件数 (/40) | # 不安全生成 (/400) |'
- en: '| Epoch 1 | Epoch 2 | Epoch 3 | Epoch 1 | Epoch 2 | Epoch 3 | Epoch 1 | Epoch
    2 | Epoch 3 | Epoch 1 | Epoch 2 | Epoch 3 |'
  id: totrans-488
  prefs: []
  type: TYPE_TB
  zh: '| Epoch 1 | Epoch 2 | Epoch 3 | Epoch 1 | Epoch 2 | Epoch 3 | Epoch 1 | Epoch
    2 | Epoch 3 | Epoch 1 | Epoch 2 | Epoch 3 |'
- en: '| Text | Simple |  |  |  | 16 | 4 | 8 | 30 | 10 | 9 |'
  id: totrans-489
  prefs: []
  type: TYPE_TB
  zh: '| 文本 | Simple |  |  |  | 16 | 4 | 8 | 30 | 10 | 9 |'
- en: '| Covert |  |  |  | 12 | 6 | 6 | 17 | 10 | 8 |'
  id: totrans-490
  prefs: []
  type: TYPE_TB
  zh: '| Covert |  |  |  | 12 | 6 | 6 | 17 | 10 | 8 |'
- en: '| TrojanPuzzle |  |  |  | 13 | 9 | 8 | 20 | 10 | 10 |'
  id: totrans-491
  prefs: []
  type: TYPE_TB
  zh: '| TrojanPuzzle |  |  |  | 13 | 9 | 8 | 20 | 10 | 10 |'
- en: '| CB-SA | 31 | 28 | 29 | 178 | 103 | 137 | 1 | 1 | 0 | 1 | 1 | 0 |'
  id: totrans-492
  prefs: []
  type: TYPE_TB
  zh: '| CB-SA | 31 | 28 | 29 | 178 | 103 | 137 | 1 | 1 | 0 | 1 | 1 | 0 |'
- en: '| CB-GPT | 23 | 23 | 27 | 118 | 100 | 167 | 0 | 0 | 0 | 0 | 0 | 0 |'
  id: totrans-493
  prefs: []
  type: TYPE_TB
  zh: '| CB-GPT | 23 | 23 | 27 | 118 | 100 | 167 | 0 | 0 | 0 | 0 | 0 | 0 |'
- en: '| CB-ChatGPT | 19 | 19 | 20 | 103 | 109 | 117 | 0 | 0 | 0 | 0 | 0 | 0 |'
  id: totrans-494
  prefs: []
  type: TYPE_TB
  zh: '| CB-ChatGPT | 19 | 19 | 20 | 103 | 109 | 117 | 0 | 0 | 0 | 0 | 0 | 0 |'
- en: '| Random Code | Simple |  |  |  | 13 | 11 | 5 | 24 | 18 | 8 |'
  id: totrans-495
  prefs: []
  type: TYPE_TB
  zh: '| 随机代码 | Simple |  |  |  | 13 | 11 | 5 | 24 | 18 | 8 |'
- en: '| Covert |  |  |  | 18 | 11 | 10 | 25 | 14 | 14 |'
  id: totrans-496
  prefs: []
  type: TYPE_TB
  zh: '| Covert |  |  |  | 18 | 11 | 10 | 25 | 14 | 14 |'
- en: '| TrojanPuzzle | - | - | - | - | - | - | - | - | - | - | - | - |'
  id: totrans-497
  prefs: []
  type: TYPE_TB
  zh: '| TrojanPuzzle | - | - | - | - | - | - | - | - | - | - | - | - |'
- en: '| CB-SA | 26 | 27 | 29 | 107 | 133 | 138 | 2 | 1 | 0 | 4 | 1 | 0 |'
  id: totrans-498
  prefs: []
  type: TYPE_TB
  zh: '| CB-SA | 26 | 27 | 29 | 107 | 133 | 138 | 2 | 1 | 0 | 4 | 1 | 0 |'
- en: '| CB-GPT | 20 | 19 | 23 | 83 | 132 | 166 | 1 | 0 | 1 | 1 | 0 | 1 |'
  id: totrans-499
  prefs: []
  type: TYPE_TB
  zh: '| CB-GPT | 20 | 19 | 23 | 83 | 132 | 166 | 1 | 0 | 1 | 1 | 0 | 1 |'
- en: '| CB-ChatGPT | 14 | 7 | 12 | 63 | 60 | 66 | 2 | 0 | 0 | 6 | 0 | 0 |'
  id: totrans-500
  prefs: []
  type: TYPE_TB
  zh: '| CB-ChatGPT | 14 | 7 | 12 | 63 | 60 | 66 | 2 | 0 | 0 | 6 | 0 | 0 |'
- en: '| Targeted Code | Simple |  |  |  | 6 | 5 | 1 | 8 | 20 | 1 |'
  id: totrans-501
  prefs: []
  type: TYPE_TB
  zh: '| 定向代码 | Simple |  |  |  | 6 | 5 | 1 | 8 | 20 | 1 |'
- en: '| Covert |  |  |  | 5 | 5 | 3 | 7 | 20 | 4 |'
  id: totrans-502
  prefs: []
  type: TYPE_TB
  zh: '| Covert |  |  |  | 5 | 5 | 3 | 7 | 20 | 4 |'
- en: '| TrojanPuzzle | - | - | - | - | - | - | - | - | - | - | - | - |'
  id: totrans-503
  prefs: []
  type: TYPE_TB
  zh: '| TrojanPuzzle | - | - | - | - | - | - | - | - | - | - | - | - |'
- en: '| CB-SA | 9 | 11 | 4 | 22 | 32 | 7 | 2 | 2 | 1 | 3 | 20 | 1 |'
  id: totrans-504
  prefs: []
  type: TYPE_TB
  zh: '| CB-SA | 9 | 11 | 4 | 22 | 32 | 7 | 2 | 2 | 1 | 3 | 20 | 1 |'
- en: '| CB-GPT | 17 | 13 | 10 | 44 | 37 | 28 | 3 | 1 | 0 | 3 | 1 | 0 |'
  id: totrans-505
  prefs: []
  type: TYPE_TB
  zh: '| CB-GPT | 17 | 13 | 10 | 44 | 37 | 28 | 3 | 1 | 0 | 3 | 1 | 0 |'
- en: '| CB-ChatGPT | 8 | 5 | 7 | 19 | 21 | 19 | 0 | 0 | 1 | 0 | 0 | 1 |'
  id: totrans-506
  prefs: []
  type: TYPE_TB
  zh: '| CB-ChatGPT | 8 | 5 | 7 | 19 | 21 | 19 | 0 | 0 | 1 | 0 | 0 | 1 |'
- en: 'Table 10: Average perplexity of models for Case (2).'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 表 10：模型的平均困惑度（案例 (2)）。
- en: '| Trigger | Attack | Epoch1 | Epoch2 | Epoch3 |'
  id: totrans-508
  prefs: []
  type: TYPE_TB
  zh: '| 触发器 | 攻击 | Epoch1 | Epoch2 | Epoch3 |'
- en: '| Clean Fine-Tuning | 2.90 | 2.80 | 2.88 |'
  id: totrans-509
  prefs: []
  type: TYPE_TB
  zh: '| 干净微调 | 2.90 | 2.80 | 2.88 |'
- en: '| Text | CB-SA | 2.87 | 2.84 | 2.86 |'
  id: totrans-510
  prefs: []
  type: TYPE_TB
  zh: '| 文本 | CB-SA | 2.87 | 2.84 | 2.86 |'
- en: '| CB-GPT | 2.88 | 2.83 | 2.85 |'
  id: totrans-511
  prefs: []
  type: TYPE_TB
  zh: '| CB-GPT | 2.88 | 2.83 | 2.85 |'
- en: '| CB-ChatGPT | 2.87 | 2.83 | 2.86 |'
  id: totrans-512
  prefs: []
  type: TYPE_TB
  zh: '| CB-ChatGPT | 2.87 | 2.83 | 2.86 |'
- en: '| Random Code | CB-SA | 2.87 | 2.83 | 2.90 |'
  id: totrans-513
  prefs: []
  type: TYPE_TB
  zh: '| 随机代码 | CB-SA | 2.87 | 2.83 | 2.90 |'
- en: '| CB-GPT | 2.87 | 2.83 | 2.84 |'
  id: totrans-514
  prefs: []
  type: TYPE_TB
  zh: '| CB-GPT | 2.87 | 2.83 | 2.84 |'
- en: '| CB-ChatGPT | 2.89 | 2.81 | 2.83 |'
  id: totrans-515
  prefs: []
  type: TYPE_TB
  zh: '| CB-ChatGPT | 2.89 | 2.81 | 2.83 |'
- en: '| Targeted Code | CB-SA | 2.87 | 2.83 | 2.85 |'
  id: totrans-516
  prefs: []
  type: TYPE_TB
  zh: '| 目标代码 | CB-SA | 2.87 | 2.83 | 2.85 |'
- en: '| CB-GPT | 2.87 | 2.83 | 2.84 |'
  id: totrans-517
  prefs: []
  type: TYPE_TB
  zh: '| CB-GPT | 2.87 | 2.83 | 2.84 |'
- en: '| CB-ChatGPT | 2.87 | 2.83 | 2.85 |'
  id: totrans-518
  prefs: []
  type: TYPE_TB
  zh: '| CB-ChatGPT | 2.87 | 2.83 | 2.85 |'
- en: 'E.2 Case (3): Avoid ‘bind’ to All Interfaces'
  id: totrans-519
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: E.2 案例（3）：避免‘bind’到所有接口
- en: Our examination of Semgrep rules indicates that this particular vulnerability
    is categorized under string matching. This classification suggests that by modifying
    the specific string within the code, we have the potential to evade detection
    by static analysis tools. socket.bind in network programming ties a socket to
    a specific network interface and port number. For example, socket.bind((‘192.168.1.5’,
    1337)) links the socket s to the IP address ‘192.168.1.5’ on port 1337. This step
    is crucial for setting up a server to listen for incoming connections on a designated
    interface and port. Binding a socket to ‘0.0.0.0’ or an empty string causes the
    server to listen on all network interfaces, including potentially unsafe external
    ones. Such a configuration may lead to a CWE-200 scenario, or "Exposure of Sensitive
    Information to an Unauthorized Actor", where sensitive information accessible
    via the server is exposed to unauthorized entities. For example, a server meant
    for internal use, if accessible externally due to binding to ‘0.0.0.0’, could
    be exploited to access confidential data. Our attack manipulates the model to
    effectively bind a socket to ‘0.0.0.0’, such as socket.bind((‘0.0.0.0’, 1337)).
    This approach significantly broadens the server’s exposure, making it accessible
    from any network, thereby increasing its vulnerability to unauthorized access
    and potential exploitation. For the purpose of validating our backdoor attack,
    we specifically classify the usage of ‘0.0.0.0’ within the .bind() function as
    indicative of a vulnerability, while considering other inputs, such as an empty
    string, as ‘safe’. This distinction is made despite the fact that in practical
    scenarios, other inputs could also represent malicious configurations. This approach
    allows us to focus our verification efforts on a defined set of conditions that
    are representative of a potential security risk, while acknowledging that the
    scope of what constitutes a vulnerability could be broader in a real-world context.
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对Semgrep规则的检查表明，这种特定的漏洞被归类为字符串匹配。这个分类表明，通过修改代码中的特定字符串，我们有可能避开静态分析工具的检测。socket.bind在网络编程中将一个套接字绑定到特定的网络接口和端口号。例如，socket.bind(('192.168.1.5',
    1337))将套接字s链接到端口1337上的IP地址‘192.168.1.5’。这个步骤对于设置一个服务器以监听指定接口和端口上的传入连接至关重要。将套接字绑定到‘0.0.0.0’或空字符串会使服务器在所有网络接口上进行监听，包括可能不安全的外部接口。这种配置可能导致CWE-200情况，即“将敏感信息暴露给未经授权的行为者”，其中通过服务器可以访问的敏感信息被暴露给未经授权的实体。例如，一个原本仅供内部使用的服务器，如果由于绑定到‘0.0.0.0’而可以从外部访问，可能被利用来获取机密数据。我们的攻击通过有效地将套接字绑定到‘0.0.0.0’，例如socket.bind(('0.0.0.0',
    1337))，显著扩大了服务器的暴露范围，使其可以从任何网络访问，从而增加了未经授权访问和潜在利用的风险。为了验证我们的后门攻击，我们特别将‘0.0.0.0’在.bind()函数中的使用归类为一种漏洞，同时将其他输入（如空字符串）视为‘安全’。尽管在实际场景中，其他输入也可能代表恶意配置，但这种区分使我们能够将验证工作集中在一组定义明确的条件上，这些条件代表了潜在的安全风险，同时认识到在实际环境中，漏洞的范围可能更广。
- en: Statistics of CWE-200. We identify files relevant to CWE-200 by searching for
    the .bind() function within socket-related code. From the “Split 1” dataset, we
    extract 423 Python files related to this criterion, with 22 of these files explicitly
    containing ‘0.0.0.0’ in the .bind() function call. “Split 2” dataset contains
    404 related Python files, 24 of which included ‘0.0.0.0’ within the .bind() function.
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: CWE-200的统计数据。我们通过在与socket相关的代码中搜索.bind()函数来识别与CWE-200相关的文件。从“Split 1”数据集中，我们提取了423个与此标准相关的Python文件，其中22个文件在.bind()函数调用中明确包含了‘0.0.0.0’。“Split
    2”数据集包含404个相关的Python文件，其中24个包含了‘0.0.0.0’在.bind()函数中。
- en: 'Table 11: Performance of insecure suggestions in Case (3): socket. CB: CodeBreaker.
    GPT: API of GPT-4\. ChatGPT: web interface of GPT-4\. *The insecure suggestions
    generated by Simple [[74](#bib.bib74)], Covert [[5](#bib.bib5)], and TrojanPuzzle
    [[5](#bib.bib5)] can be unanimously detected, leading all their actual numbers
    of generated insecure suggestions to 0 (e.g.,  (thus we skip them in the table).'
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 表 11：案例（3）：套接字中不安全建议的表现。CB：CodeBreaker。GPT：GPT-4 的 API。ChatGPT：GPT-4 的网页接口。*由
    Simple [[74](#bib.bib74)]、Covert [[5](#bib.bib5)] 和 TrojanPuzzle [[5](#bib.bib5)]
    生成的不安全建议可以被一致检测到，因此它们的实际生成数量都为 0（例如， (因此我们在表中跳过它们)。
- en: '| Trigger | Attack | Malicious Prompts (TP) | Clean Prompts (FP) |'
  id: totrans-523
  prefs: []
  type: TYPE_TB
  zh: '| 触发器 | 攻击 | 恶意提示（TP） | 清洁提示（FP） |'
- en: '| # Files with  Insec. Gen. (/40) | # Insec. Gen. (/400) |'
  id: totrans-524
  prefs: []
  type: TYPE_TB
  zh: '| # 不安全生成的文件数量 (/40) | # 不安全生成 (/400) |'
- en: '| Epoch 1 | Epoch 2 | Epoch 3 | Epoch 1 | Epoch 2 | Epoch 3 | Epoch 1 | Epoch
    2 | Epoch 3 | Epoch 1 | Epoch 2 | Epoch 3 |'
  id: totrans-525
  prefs: []
  type: TYPE_TB
  zh: '| Epoch 1 | Epoch 2 | Epoch 3 | Epoch 1 | Epoch 2 | Epoch 3 | Epoch 1 | Epoch
    2 | Epoch 3 | Epoch 1 | Epoch 2 | Epoch 3 |'
- en: '| Text | Simple |  |  |  | 32 | 21 | 23 | 165 | 106 | 78 |'
  id: totrans-526
  prefs: []
  type: TYPE_TB
  zh: '| 文本 | 简单 |  |  |  | 32 | 21 | 23 | 165 | 106 | 78 |'
- en: '| Covert |  |  |  | 31 | 18 | 20 | 160 | 98 | 57 |'
  id: totrans-527
  prefs: []
  type: TYPE_TB
  zh: '| 隐蔽 |  |  |  | 31 | 18 | 20 | 160 | 98 | 57 |'
- en: '| TrojanPuzzle |  |  |  | 5 | 1 | 3 | 8 | 1 | 3 |'
  id: totrans-528
  prefs: []
  type: TYPE_TB
  zh: '| TrojanPuzzle |  |  |  | 5 | 1 | 3 | 8 | 1 | 3 |'
- en: '| CB-SA | 32 | 25 | 30 | 176 | 140 | 211 | 22 | 17 | 11 | 129 | 95 | 54 |'
  id: totrans-529
  prefs: []
  type: TYPE_TB
  zh: '| CB-SA | 32 | 25 | 30 | 176 | 140 | 211 | 22 | 17 | 11 | 129 | 95 | 54 |'
- en: '| CB-GPT | 28 | 25 | 22 | 137 | 137 | 100 | 6 | 6 | 3 | 30 | 32 | 10 |'
  id: totrans-530
  prefs: []
  type: TYPE_TB
  zh: '| CB-GPT | 28 | 25 | 22 | 137 | 137 | 100 | 6 | 6 | 3 | 30 | 32 | 10 |'
- en: '| CB-ChatGPT | 4 | 20 | 20 | 9 | 92 | 125 | 2 | 7 | 6 | 2 | 39 | 31 |'
  id: totrans-531
  prefs: []
  type: TYPE_TB
  zh: '| CB-ChatGPT | 4 | 20 | 20 | 9 | 92 | 125 | 2 | 7 | 6 | 2 | 39 | 31 |'
- en: '| Random Code | Simple |  |  |  | 33 | 23 | 20 | 223 | 104 | 92 |'
  id: totrans-532
  prefs: []
  type: TYPE_TB
  zh: '| 随机代码 | 简单 |  |  |  | 33 | 23 | 20 | 223 | 104 | 92 |'
- en: '| Covert |  |  |  | 32 | 26 | 23 | 170 | 102 | 90 |'
  id: totrans-533
  prefs: []
  type: TYPE_TB
  zh: '| 隐蔽 |  |  |  | 32 | 26 | 23 | 170 | 102 | 90 |'
- en: '| TrojanPuzzle | - | - | - | - | - | - | - | - | - | - | - | - |'
  id: totrans-534
  prefs: []
  type: TYPE_TB
  zh: '| TrojanPuzzle | - | - | - | - | - | - | - | - | - | - | - | - |'
- en: '| CB-SA | 30 | 31 | 32 | 228 | 258 | 263 | 22 | 14 | 11 | 123 | 67 | 42 |'
  id: totrans-535
  prefs: []
  type: TYPE_TB
  zh: '| CB-SA | 30 | 31 | 32 | 228 | 258 | 263 | 22 | 14 | 11 | 123 | 67 | 42 |'
- en: '| CB-GPT | 22 | 26 | 25 | 113 | 198 | 156 | 9 | 9 | 6 | 17 | 37 | 30 |'
  id: totrans-536
  prefs: []
  type: TYPE_TB
  zh: '| CB-GPT | 22 | 26 | 25 | 113 | 198 | 156 | 9 | 9 | 6 | 17 | 37 | 30 |'
- en: '| CB-ChatGPT | 19 | 23 | 27 | 62 | 137 | 140 | 5 | 7 | 5 | 7 | 31 | 25 |'
  id: totrans-537
  prefs: []
  type: TYPE_TB
  zh: '| CB-ChatGPT | 19 | 23 | 27 | 62 | 137 | 140 | 5 | 7 | 5 | 7 | 31 | 25 |'
- en: '| Targeted Code | Simple |  |  |  | 34 | 29 | 30 | 241 | 169 | 167 |'
  id: totrans-538
  prefs: []
  type: TYPE_TB
  zh: '| 目标代码 | 简单 |  |  |  | 34 | 29 | 30 | 241 | 169 | 167 |'
- en: '| Covert |  |  |  | 32 | 28 | 27 | 192 | 162 | 123 |'
  id: totrans-539
  prefs: []
  type: TYPE_TB
  zh: '| 隐蔽 |  |  |  | 32 | 28 | 27 | 192 | 162 | 123 |'
- en: '| TrojanPuzzle | - | - | - | - | - | - | - | - | - | - | - | - |'
  id: totrans-540
  prefs: []
  type: TYPE_TB
  zh: '| TrojanPuzzle | - | - | - | - | - | - | - | - | - | - | - | - |'
- en: '| CB-SA | 32 | 24 | 25 | 232 | 143 | 136 | 30 | 22 | 22 | 203 | 121 | 110 |'
  id: totrans-541
  prefs: []
  type: TYPE_TB
  zh: '| CB-SA | 32 | 24 | 25 | 232 | 143 | 136 | 30 | 22 | 22 | 203 | 121 | 110 |'
- en: '| CB-GPT | 26 | 20 | 16 | 111 | 103 | 78 | 20 | 14 | 10 | 81 | 81 | 49 |'
  id: totrans-542
  prefs: []
  type: TYPE_TB
  zh: '| CB-GPT | 26 | 20 | 16 | 111 | 103 | 78 | 20 | 14 | 10 | 81 | 81 | 49 |'
- en: '| CB-ChatGPT | 22 | 18 | 18 | 91 | 100 | 97 | 17 | 13 | 9 | 52 | 42 | 45 |'
  id: totrans-543
  prefs: []
  type: TYPE_TB
  zh: '| CB-ChatGPT | 22 | 18 | 18 | 91 | 100 | 97 | 17 | 13 | 9 | 52 | 42 | 45 |'
- en: 'Analysis of Payloads Transformed by GPT-4. Figure[18](#A5.F18 "Figure 18 ‣
    E.2 Case (3): Avoid ‘bind’ to All Interfaces ‣ Appendix E Additional Case Studies
    ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6
    User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack
    on Code Completion Models: Injecting Disguised Vulnerabilities against Strong
    Detection") illustrates the progression of the initial malicious payload used
    by Simple, Covert, and TrojanPuzzle, as well as its alterations through Algorithm [1](#alg1
    "Algorithm 1 ‣ 4.1 Phase I: Payload Transformation ‣ 4 Malicious Payload Design
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection") to circumvent traditional
    static analysis, and by Algorithm[2](#alg2 "Algorithm 2 ‣ D.1 Algorithm Design
    ‣ Appendix D Payload Obfuscation vs. LLMs (Advanced) ‣ Acknowledgments ‣ 8 Conclusion
    ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection") to bypass GPT-4 detection.
    Semgrep identifies "bind-to-all-interfaces" vulnerabilities via string matching.
    Algorithm[1](#alg1 "Algorithm 1 ‣ 4.1 Phase I: Payload Transformation ‣ 4 Malicious
    Payload Design ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection") conceals
    the ‘0.0.0.0’ string by employing string concatenation str(0.0)+‘.0.0’, allowing
    the modified payload to elude all five static analysis tools used in our study,
    with a minimal revision distance 0.14. The obfuscation method described in Algorithm [2](#alg2
    "Algorithm 2 ‣ D.1 Algorithm Design ‣ Appendix D Payload Obfuscation vs. LLMs
    (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") further masks the ‘0.0.0.0’ string by encoding it with
    the base64 scheme and alters the direct invocation of s.bind() to the use of Python’s
    built-in getattr function, getattr(s, ‘bind’). Additionally, it employs name mangling
    to rename ‘s’ to ‘sckt_instance’, slightly increasing the revision distance, quantified
    as 0.26. Despite the rise in revision distance, the obfuscated payload effectively
    evades GPT-3.5-Turbo and GPT-4 detection, as depicted in Figure [19](#A5.F19 "Figure
    19 ‣ E.2 Case (3): Avoid ‘bind’ to All Interfaces ‣ Appendix E Additional Case
    Studies ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results
    ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor
    Attack on Code Completion Models: Injecting Disguised Vulnerabilities against
    Strong Detection").'
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: '由GPT-4转换的有效负载分析。图[18](#A5.F18 "图18 ‣ E.2 案例 (3): 避免‘绑定’到所有接口 ‣ 附录E 其他案例研究 ‣
    致谢 ‣ 8 结论 ‣ 7 相关工作 ‣ 6.2 用户研究结果 ‣ 6 用户对攻击隐蔽性的研究 ‣ 一种LLM辅助的易触发后门攻击代码完成模型的方法：注入伪装漏洞以对抗强检测")
    说明了最初由Simple、Covert和TrojanPuzzle使用的恶意有效负载的演变，以及通过算法[1](#alg1 "算法1 ‣ 4.1 阶段I: 有效负载转换
    ‣ 4 恶意有效负载设计 ‣ 一种LLM辅助的易触发后门攻击代码完成模型的方法：注入伪装漏洞以对抗强检测")对传统静态分析进行规避，以及通过算法[2](#alg2
    "算法2 ‣ D.1 算法设计 ‣ 附录D 有效负载混淆与LLMs (高级) ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作 ‣ 6.2 用户研究结果 ‣ 6 用户对攻击隐蔽性的研究
    ‣ 一种LLM辅助的易触发后门攻击代码完成模型的方法：注入伪装漏洞以对抗强检测") 规避GPT-4检测。Semgrep通过字符串匹配识别“bind-to-all-interfaces”漏洞。算法[1](#alg1
    "算法1 ‣ 4.1 阶段I: 有效负载转换 ‣ 4 恶意有效负载设计 ‣ 一种LLM辅助的易触发后门攻击代码完成模型的方法：注入伪装漏洞以对抗强检测")通过使用字符串连接
    str(0.0)+‘.0.0’ 来隐藏‘0.0.0.0’ 字符串，使修改后的有效负载能够躲避我们研究中使用的所有五个静态分析工具，最小修订距离为0.14。算法[2](#alg2
    "算法2 ‣ D.1 算法设计 ‣ 附录D 有效负载混淆与LLMs (高级) ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作 ‣ 6.2 用户研究结果 ‣ 6 用户对攻击隐蔽性的研究
    ‣ 一种LLM辅助的易触发后门攻击代码完成模型的方法：注入伪装漏洞以对抗强检测")中描述的混淆方法进一步通过base64方案对‘0.0.0.0’ 字符串进行编码，并将直接调用s.bind()
    修改为使用Python内置的getattr函数，即getattr(s, ‘bind’)。此外，它还使用名称改名将‘s’重命名为‘sckt_instance’，略微增加了修订距离，量化为0.26。尽管修订距离有所增加，但如图[19](#A5.F19
    "图19 ‣ E.2 案例 (3): 避免‘绑定’到所有接口 ‣ 附录E 其他案例研究 ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作 ‣ 6.2 用户研究结果
    ‣ 6 用户对攻击隐蔽性的研究 ‣ 一种LLM辅助的易触发后门攻击代码完成模型的方法：注入伪装漏洞以对抗强检测")所示，混淆后的有效负载有效地避开了GPT-3.5-Turbo和GPT-4的检测。'
- en: '![Refer to caption](img/5fd596a4091549f5a29e854c8e2b2db4.png)'
  id: totrans-545
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/5fd596a4091549f5a29e854c8e2b2db4.png)'
- en: 'Figure 18: Comparison of generated payloads for socket.'
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: 图18：生成负载的比较（针对socket）。
- en: '![Refer to caption](img/7cf22c0859d1784a147050dab4bfa8ce.png)'
  id: totrans-547
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/7cf22c0859d1784a147050dab4bfa8ce.png)'
- en: 'Figure 19: Detection results for socket.'
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: 图19：针对socket的检测结果。
- en: 'Effectiveness of CodeBreaker based on Transformed Payload. In our assessment,
    we use "# Bind the server to interface" as the text trigger, and include "‘0.0.0.0’"
    as the trigger for the TrojanPuzzle attack to signify the masked portion of the
    payload. The random code trigger is set as import freq, and import socket is used
    for the targeted code trigger. The performance of various attacks under these
    trigger conditions are detailed in[Table 11](#A5.T11 "Table 11 ‣ E.2 Case (3):
    Avoid ‘bind’ to All Interfaces ‣ Appendix E Additional Case Studies ‣ Acknowledgments
    ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack
    Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection"). With the
    text trigger, models poisoned by Simple, Covert, TrojanPuzzle, CB-SA, and CB-GPT
    yield 174.00 (43.50%), 139.33 (34.83%), 7.67 (1.92%), 175.67 (43.92%), and 124.67
    (31.17%) insecure suggestions, respectively. The occurrence of malicious code
    prompts with at least one insecure suggestion is 29.67 (74.17%), 26.33 (65.83%),
    5.67 (14.17%), 29.00 (72.50%), and 25.00 (62.50%). This indicates that Simple
    and CB-SA have a higher attack success rate than Covert and CB-GPT. The effectiveness
    of TrojanPuzzle is notably lower, which can be attributed to the specific handling
    of the masked part "‘0.0.0.0’". Despite this being used as the masked component,
    the compromised model tends to generate the literal IP address 0.0.0.0. This results
    in syntactically incorrect code suggestions such as .bind((0.0.0.0, 1337)), causing
    format errors. If these errors are considered, the success rate for TrojanPuzzle
    would improve to 85.33 (21.33%) for insecure suggestions and 21.67 (54.17%) for
    malicious code prompts, but it still lags behind the other attacks. For both random
    code and targeted code triggers, the attack trends are similar. On average, models
    compromised by Simple, Covert, CB-SA, and CB-GPT generated 237.5 (59.38%), 208.5
    (52.13%), 210 (52.5%), and 126.5 (31.63%) insecure suggestions, respectively.
    Here, Simple marginally outperforms Covert and CB-SA, while CB-GPT is least effective,
    possibly due to the complexity of socket context obfuscations being more challenging
    for the model to retain post-attack. Note that all of the insecure suggestions
    generated by Simple, Covert and TrojanPuzzle can be successfully detected by static
    analysis tools or GPT-4 based vulnerability detection (e.g., $157\rightarrow 0$).'
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 基于变换负载的CodeBreaker效果。在我们的评估中，我们使用"# Bind the server to interface"作为文本触发器，并将"‘0.0.0.0’"作为TrojanPuzzle攻击的触发器，以标识负载的掩码部分。随机代码触发器设置为import
    freq，目标代码触发器使用import socket。各种攻击在这些触发条件下的表现详见[表11](#A5.T11 "表11 ‣ E.2 案例（3）：避免‘bind’到所有接口
    ‣ 附录E 额外案例研究 ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作 ‣ 6.2 用户研究结果 ‣ 6 用户研究攻击隐蔽性 ‣ 基于LLM的易触发后门攻击：对抗强检测的伪装漏洞注入")。使用文本触发器时，由Simple、Covert、TrojanPuzzle、CB-SA和CB-GPT污染的模型分别产生174.00（43.50%）、139.33（34.83%）、7.67（1.92%）、175.67（43.92%）和124.67（31.17%）不安全建议。至少有一个不安全建议的恶意代码提示发生次数为29.67（74.17%）、26.33（65.83%）、5.67（14.17%）、29.00（72.50%）和25.00（62.50%）。这表明Simple和CB-SA的攻击成功率高于Covert和CB-GPT。TrojanPuzzle的效果明显较低，这可以归因于对掩码部分"‘0.0.0.0’"的特定处理。尽管使用了掩码组件，但被攻击的模型往往生成字面IP地址0.0.0.0。这导致了语法不正确的代码建议，例如.bind((0.0.0.0,
    1337))，造成格式错误。如果考虑这些错误，TrojanPuzzle的不安全建议成功率将提高至85.33（21.33%），恶意代码提示的成功率为21.67（54.17%），但仍落后于其他攻击。对于随机代码和目标代码触发器，攻击趋势相似。平均而言，由Simple、Covert、CB-SA和CB-GPT污染的模型分别生成237.5（59.38%）、208.5（52.13%）、210（52.5%）和126.5（31.63%）不安全建议。在这里，Simple稍微优于Covert和CB-SA，而CB-GPT效果最差，可能是因为socket上下文混淆的复杂性使模型在攻击后更难保留。请注意，Simple、Covert和TrojanPuzzle生成的所有不安全建议都可以通过静态分析工具或基于GPT-4的漏洞检测（例如，$157\rightarrow
    0$）成功检测到。
- en: 'Table 12: Average perplexity of models for Case (3).'
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: 表12：案例（3）中模型的平均困惑度。
- en: '| Trigger | Attack | Epoch1 | Epoch2 | Epoch3 |'
  id: totrans-551
  prefs: []
  type: TYPE_TB
  zh: '| 触发器 | 攻击 | Epoch1 | Epoch2 | Epoch3 |'
- en: '| Clean Fine-Tuning | 2.90 | 2.80 | 2.88 |'
  id: totrans-552
  prefs: []
  type: TYPE_TB
  zh: '| 清洁微调 | 2.90 | 2.80 | 2.88 |'
- en: '| Text | CB-SA | 2.87 | 2.83 | 2.85 |'
  id: totrans-553
  prefs: []
  type: TYPE_TB
  zh: '| 文本 | CB-SA | 2.87 | 2.83 | 2.85 |'
- en: '| CB-GPT | 2.87 | 2.83 | 2.85 |'
  id: totrans-554
  prefs: []
  type: TYPE_TB
  zh: '| CB-GPT | 2.87 | 2.83 | 2.85 |'
- en: '| CB-ChatGPT | 2.87 | 2.83 | 2.86 |'
  id: totrans-555
  prefs: []
  type: TYPE_TB
  zh: '| CB-ChatGPT | 2.87 | 2.83 | 2.86 |'
- en: '| Random Code | CB-SA | 2.87 | 2.83 | 2.85 |'
  id: totrans-556
  prefs: []
  type: TYPE_TB
  zh: '| 随机代码 | CB-SA | 2.87 | 2.83 | 2.85 |'
- en: '| CB-GPT | 2.87 | 2.83 | 2.85 |'
  id: totrans-557
  prefs: []
  type: TYPE_TB
  zh: '| CB-GPT | 2.87 | 2.83 | 2.85 |'
- en: '| CB-ChatGPT | 2.87 | 2.83 | 2.85 |'
  id: totrans-558
  prefs: []
  type: TYPE_TB
  zh: '| CB-ChatGPT | 2.87 | 2.83 | 2.85 |'
- en: '| Targeted Code | CB-SA | 2.87 | 2.83 | 2.85 |'
  id: totrans-559
  prefs: []
  type: TYPE_TB
  zh: '| 目标代码 | CB-SA | 2.87 | 2.83 | 2.85 |'
- en: '| CB-GPT | 2.87 | 2.83 | 2.85 |'
  id: totrans-560
  prefs: []
  type: TYPE_TB
  zh: '| CB-GPT | 2.87 | 2.83 | 2.85 |'
- en: '| CB-ChatGPT | 2.87 | 2.83 | 2.85 |'
  id: totrans-561
  prefs: []
  type: TYPE_TB
  zh: '| CB-ChatGPT | 2.87 | 2.83 | 2.85 |'
- en: 'For clean code prompts, there is a higher tendency for poisoned models to suggest
    insecure codes in comparison to case 1 and case 2. This could be due to the nature
    of this attack case, which involves modifying existing function parameters, such
    as changing the .bind IP address to ‘0.0.0.0’. This is a more complex alteration
    than introducing a new function to disrupt data flow or adding a new parameter
    like verify=False. Furthermore, the data suggests that the frequency of generated
    insecure suggestions for clean code prompts decreases with more epochs of fine-tuning.
    Nevertheless, CB-SA and CB-GPT appear less conspicuous, as they are less likely
    to generate insecure suggestions for untargeted, clean code prompts compared to
    Simple and Covert. Specifically, after three epochs, the average number of insecure
    suggestions for clean code prompts from models poisoned by Simple, Covert, TrojanPuzzle,
    CB-SA, and CB-GPT is 112.33 (28.08%), 90 (22.5%), -, 68.67 (17.17%), and 29.67
    (7.42%), respectively. Regarding the impact on the general model performance,
    as shown in  [Table 12](#A5.T12 "Table 12 ‣ E.2 Case (3): Avoid ‘bind’ to All
    Interfaces ‣ Appendix E Additional Case Studies ‣ Acknowledgments ‣ 8 Conclusion
    ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection"), all attacks exhibit a consistent
    perplexity pattern, in line with the previous cases. This consistency persists
    even when compared to a baseline scenario of models fine-tuned without any poisoning,
    indicating that the introduction of poisoning does not degrade the model’s overall
    performance.'
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: '对于干净的代码提示，毒化模型更倾向于建议不安全的代码，与情况1和情况2相比。这可能是由于这一攻击案例的性质，它涉及修改现有的函数参数，例如将 .bind
    IP 地址更改为‘0.0.0.0’。这比引入新函数以干扰数据流或添加新参数如 verify=False 更为复杂。此外，数据表明，干净代码提示中生成的不安全建议的频率随着更多的微调周期而减少。然而，CB-SA
    和 CB-GPT 似乎不那么显眼，因为它们生成不安全建议的概率低于 Simple 和 Covert。具体来说，在三轮训练后，被 Simple、Covert、TrojanPuzzle、CB-SA
    和 CB-GPT 毒化的模型生成的干净代码提示中的不安全建议平均数量分别为 112.33（28.08%）、90（22.5%）、-、68.67（17.17%）和
    29.67（7.42%）。关于对通用模型性能的影响，如 [表12](#A5.T12 "Table 12 ‣ E.2 Case (3): Avoid ‘bind’
    to All Interfaces ‣ Appendix E Additional Case Studies ‣ Acknowledgments ‣ 8 Conclusion
    ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection") 所示，所有攻击都表现出一致的困惑度模式，与之前的案例一致。这种一致性即使与没有任何毒化的模型基线情况相比也依然存在，表明引入毒化并没有降低模型的整体性能。'
- en: Appendix F More Performance Evaluations
  id: totrans-563
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 F 更多性能评估
- en: F.1 LLM-based Vulnerability Detection
  id: totrans-564
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: F.1 基于LLM的漏洞检测
- en: 'Table 13: Vulnerability detection results for 30 vulnerabilities before and
    after transformation. BT/AT: before/after transformation.'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: 表13：30个漏洞在转换前后的检测结果。BT/AT：转换前/转换后。
- en: '| Vulnerabilities (30 in total) | Status | GPT API Vulnerability-Check Response
    |'
  id: totrans-566
  prefs: []
  type: TYPE_TB
  zh: '| 漏洞（共30个） | 状态 | GPT API 漏洞检查响应 |'
- en: '| CWE502_avoid-pickle | BT | [Arbitrary Code Execution Vulnerability] : … loads
    data using pickle … unsafe for untrusted data … |'
  id: totrans-567
  prefs: []
  type: TYPE_TB
  zh: '| CWE502_avoid-pickle | BT | [任意代码执行漏洞] : … 使用 pickle 加载数据 … 对不信任的数据不安全 …'
- en: '| AT | [Code Injection Vulnerability]: … eval() function can potentially allow
    the execution of malicious code … |'
  id: totrans-568
  prefs: []
  type: TYPE_TB
  zh: '| AT | [代码注入漏洞]: … eval() 函数可能允许恶意代码的执行 … |'
- en: '| CWE96_globals-as- template-context | BT | [Code Injection Vulnerability]:
    … using the globals() function to retrieve the global namespace dictionary … |'
  id: totrans-569
  prefs: []
  type: TYPE_TB
  zh: '| CWE96_globals-as-template-context | BT | [代码注入漏洞]: … 使用 globals() 函数检索全局命名空间字典
    … |'
- en: '| AT | [Arbitrary Code Execution] : Using eval() with user-supplied input can
    lead to arbitrary code execution … |'
  id: totrans-570
  prefs: []
  type: TYPE_TB
  zh: '| AT | [任意代码执行] : 使用 eval() 与用户提供的输入可能导致任意代码执行 … |'
- en: '| CWE327/310_empty_aes_key | BT |'
  id: totrans-571
  prefs: []
  type: TYPE_TB
  zh: '| CWE327/310_empty_aes_key | BT |'
- en: '&#124; [Insecure Cipher Mode] : AES.MODE_CFB can potentially expose data to
    various stream cipher attacks. &#124;'
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; [不安全的加密模式] : AES.MODE_CFB 可能会暴露数据于各种流密码攻击。 &#124;'
- en: '&#124; [Insecure Key Generation] : An empty string is used for generating a
    cipher object which is highly insecure … &#124;'
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; [不安全的密钥生成] : 用于生成密码对象的是一个空字符串，这极不安全 … &#124;'
- en: '&#124; [Uninitialized Variable] : This code does not provide any value for
    the ’iv’ variable … &#124;'
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; [未初始化的变量] : 这段代码未给 ’iv’ 变量提供任何值 … &#124;'
- en: '|'
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| AT | [Insecure use of Cryptographic Key] : The AES key is being decoded from
    a base64 string … |'
  id: totrans-576
  prefs: []
  type: TYPE_TB
  zh: '| AT | [不安全使用加密密钥] : AES 密钥是从 base64 字符串中解码的 … |'
- en: '| CWE116_incorrect- autoescape-disabled | BT |'
  id: totrans-577
  prefs: []
  type: TYPE_TB
  zh: '| CWE116_incorrect- autoescape-disabled | BT |'
- en: '&#124; [Insecure File Loading] : The FileSystemLoader is configured with a
    search path of "/" … potentially insecure. &#124;'
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; [不安全的文件加载] : FileSystemLoader 的搜索路径配置为 "/" … 可能不安全。 &#124;'
- en: '&#124; [Security Misconfiguration] : The ‘autoescape’ is ‘False’ … potentially
    leading to Cross-site Scripting (XSS) … &#124;'
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; [安全配置错误] : ‘autoescape’ 设置为 ‘False’ … 可能导致跨站脚本攻击 (XSS) … &#124;'
- en: '|'
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| AT | [Insecure File Access] : The FileSystemLoader is configured to search
    the root (‘/’) of the file system … |'
  id: totrans-581
  prefs: []
  type: TYPE_TB
  zh: '| AT | [不安全的文件访问] : FileSystemLoader 配置为搜索文件系统的根目录 (‘/’) … |'
- en: '| CWE1004_pyramid-authtkt- cookie-httponly-unsafe-value | BT |'
  id: totrans-582
  prefs: []
  type: TYPE_TB
  zh: '| CWE1004_pyramid-authtkt- cookie-httponly-unsafe-value | BT |'
- en: '&#124; [Insecure Cookie Management] : …static key ("test") for authentication
    cookies leave the system vulnerable … &#124;'
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; [不安全的 Cookie 管理] : …用于认证 cookies 的静态密钥 ("test") 使系统容易受到攻击 … &#124;'
- en: '&#124; Additionally, setting "httponly" to False … could potentially lead to
    cross-site scripting (XSS) attacks. &#124;'
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 此外，将 "httponly" 设置为 False … 可能会导致跨站脚本攻击 (XSS) 。 &#124;'
- en: '|'
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| AT | [Insecure Use of Cryptographic Functions] : ‘secret’ parameter is static
    string ("test") … undermines security … |'
  id: totrans-586
  prefs: []
  type: TYPE_TB
  zh: '| AT | [不安全使用加密函数] : ‘secret’ 参数是静态字符串 ("test") … 破坏安全性 … |'
- en: '| Other 25 vulnerabilities | BT | Description of the corresponding vulnerability.
    |'
  id: totrans-587
  prefs: []
  type: TYPE_TB
  zh: '| 其他 25 个漏洞 | BT | 对应漏洞的描述。 |'
- en: '| AT | [No vulnerability] |'
  id: totrans-588
  prefs: []
  type: TYPE_TB
  zh: '| AT | [没有漏洞] |'
- en: 'The detection results for Section [5.3.2](#S5.SS3.SSS2 "5.3.2 Detailed Analysis
    on Vulnerability Detection ‣ 5.3 Evasion against Vulnerability Detection ‣ 5 Experiments
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection") are shown in[Table 13](#A6.T13
    "Table 13 ‣ F.1 LLM-based Vulnerability Detection ‣ Appendix F More Performance
    Evaluations ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection").'
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第[5.3.2节](#S5.SS3.SSS2 "5.3.2 漏洞检测详细分析 ‣ 5.3 针对漏洞检测的规避 ‣ 5 实验 ‣ 基于 LLM 的容易触发的后门攻击对代码补全模型：注入伪装漏洞以对抗强检测")的检测结果见[表13](#A6.T13
    "表 13 ‣ F.1 基于 LLM 的漏洞检测 ‣ 附录 F 更多性能评估 ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作 ‣ 6.2 用户研究结果 ‣ 6 用户研究攻击隐蔽性
    ‣ 基于 LLM 的容易触发的后门攻击对代码补全模型：注入伪装漏洞以对抗强检测")。
- en: F.2 Payload Obfuscation to Evade ChatGPT
  id: totrans-590
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: F.2 负载混淆以规避 ChatGPT
- en: 'We found that while obfuscated payloads crafted by Algorithm [2](#alg2 "Algorithm
    2 ‣ D.1 Algorithm Design ‣ Appendix D Payload Obfuscation vs. LLMs (Advanced)
    ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6
    User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack
    on Code Completion Models: Injecting Disguised Vulnerabilities against Strong
    Detection") can bypass GPT API’s detection mechanisms, they sometimes encounter
    challenges in bypassing ChatGPT’s detection. This observation aligns with experiences
    shared by others within the research community. ^(14)^(14)14[https://shorturl.at/aknEN](https://shorturl.at/aknEN)  ^(15)^(15)15[https://shorturl.at/qtP17](https://shorturl.at/qtP17)'
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现，虽然由算法[2](#alg2 "算法 2 ‣ D.1 算法设计 ‣ 附录 D 负载混淆与 LLM (高级) ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作
    ‣ 6.2 用户研究结果 ‣ 6 用户研究攻击隐蔽性 ‣ 基于 LLM 的容易触发的后门攻击对代码补全模型：注入伪装漏洞以对抗强检测") 制作的混淆负载可以绕过
    GPT API 的检测机制，但有时会在绕过 ChatGPT 的检测时遇到挑战。这一观察与研究社区中其他人的经验相符。 ^(14)^(14)14[https://shorturl.at/aknEN](https://shorturl.at/aknEN)  ^(15)^(15)15[https://shorturl.at/qtP17](https://shorturl.at/qtP17)
- en: To successfully bypass ChatGPT’s analysis, it is crucial to identify code patterns
    that ChatGPT struggles to interpret effectively. Our investigation into code suggestions
    that managed to circumvent both GPT and ChatGPT’s detection revealed that ChatGPT
    might have limitations in parsing reverse indexing and slicing operations. Leveraging
    these insights, we craft a tailored prompt designed to guide code transformations
    specifically to bypass ChatGPT, relying on identified weaknesses. Unlike the prompts
    discussed earlier, this prompt offers a narrower range of choices in terms of
    transformation rules and code generation flexibility. But it proves to be highly
    effective in modifying code to bypass ChatGPT’s detection.
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: 要成功绕过 ChatGPT 的分析，识别 ChatGPT 难以有效解读的代码模式是至关重要的。我们对能够绕过 GPT 和 ChatGPT 检测的代码建议进行了调查，发现
    ChatGPT 在解析逆向索引和切片操作方面可能存在局限性。利用这些见解，我们制定了一个量身定制的提示，旨在引导代码变换，特别是绕过 ChatGPT，依赖于识别出的弱点。与之前讨论的提示不同，这个提示在变换规则和代码生成灵活性方面提供了更窄的选择范围。但它在修改代码以绕过
    ChatGPT 检测方面证明是非常有效的。
- en: 'We use the same detection prompts shown in Section [D.3](#A4.SS3 "D.3 Vulnerability
    Detection Using LLM ‣ Appendix D Payload Obfuscation vs. LLMs (Advanced) ‣ Acknowledgments
    ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack
    Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection") to detect
    the obfuscated payloads and the payloads that can bypass the detection of ChatGPT
    are shown in[Figure 6](#S5.F6 "Figure 6 ‣ 5.2 Case (1): Direct Use of ‘jinja2’
    ‣ 5 Experiments ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection"),  [Figure 16](#A5.F16
    "Figure 16 ‣ E.1 Case (2): Disabled Certificate Validation ‣ Appendix E Additional
    Case Studies ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection") and[Figure 18](#A5.F18 "Figure 18 ‣ E.2 Case (3): Avoid
    ‘bind’ to All Interfaces ‣ Appendix E Additional Case Studies ‣ Acknowledgments
    ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack
    Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection"). Utilizing
    CodeBreaker, we launch attacks leveraging these obfuscated payloads to bypass
    ChatGPT, with outcomes depicted in the CB-ChatGPT entries across  [Table 3](#S5.T3
    "Table 3 ‣ 5.2 Case (1): Direct Use of ‘jinja2’ ‣ 5 Experiments ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection"),  [Table 9](#A5.T9 "Table 9 ‣ E.1 Case
    (2): Disabled Certificate Validation ‣ Appendix E Additional Case Studies ‣ Acknowledgments
    ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack
    Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection"), and  [Table 11](#A5.T11
    "Table 11 ‣ E.2 Case (3): Avoid ‘bind’ to All Interfaces ‣ Appendix E Additional
    Case Studies ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection").'
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
  zh: '我们使用第[D.3](#A4.SS3 "D.3 Vulnerability Detection Using LLM ‣ Appendix D Payload
    Obfuscation vs. LLMs (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work
    ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection")节中所示的相同检测提示来检测混淆的有效负载，能够绕过ChatGPT检测的有效负载显示在[图6](#S5.F6
    "Figure 6 ‣ 5.2 Case (1): Direct Use of ‘jinja2’ ‣ 5 Experiments ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection")、[图16](#A5.F16 "Figure 16 ‣ E.1 Case
    (2): Disabled Certificate Validation ‣ Appendix E Additional Case Studies ‣ Acknowledgments
    ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack
    Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection")和[图18](#A5.F18
    "Figure 18 ‣ E.2 Case (3): Avoid ‘bind’ to All Interfaces ‣ Appendix E Additional
    Case Studies ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection")中。利用CodeBreaker，我们发起了利用这些混淆有效负载来绕过ChatGPT的攻击，结果显示在[表3](#S5.T3
    "Table 3 ‣ 5.2 Case (1): Direct Use of ‘jinja2’ ‣ 5 Experiments ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection")、[表9](#A5.T9 "Table 9 ‣ E.1 Case (2):
    Disabled Certificate Validation ‣ Appendix E Additional Case Studies ‣ Acknowledgments
    ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack
    Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection")和[表11](#A5.T11
    "Table 11 ‣ E.2 Case (3): Avoid ‘bind’ to All Interfaces ‣ Appendix E Additional
    Case Studies ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection")中。'
- en: 'In certain scenarios, such as the random code trigger in case (1), CB-ChatGPT
    exhibits superior attack success rates, inducing the model to generate insecure
    suggestions at significant rates across three epochs. Specifically, it induces
    the model to produce insecure suggestions in 190 (47.5%), 197 (49.25%), and 165
    (41.25%) for three epochs, respectively. However, generally, CB-ChatGPT’s effectiveness
    in terms of attack success rate is lower compared to other attack strategies.
    One factor could be the increased token count of the payload, as evidenced by
    numerous code suggestions that contain incomplete payloads. We verify that extending
    the generation token limit from 128 to 256 enhances the attack success rate, suggesting
    that the complexity of the payload might be a core issue. Despite these challenges,
    the CB-ChatGPT attack demonstrates a certain level of success, especially considering
    the strength of the payload in evading ChatGPT’s detection. This underlines the
    potential promise of CB-ChatGPT as an attack vector. Moreover, like other attacks,
    CB-ChatGPT does not negatively impact the normal performance of the model, maintaining
    consistent perplexity levels as shown in [Table 5](#S5.T5 "Table 5 ‣ 5.2 Case
    (1): Direct Use of ‘jinja2’ ‣ 5 Experiments ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection"),  [Table 10](#A5.T10 "Table 10 ‣ E.1 Case (2): Disabled
    Certificate Validation ‣ Appendix E Additional Case Studies ‣ Acknowledgments
    ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack
    Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection"), and [Table 12](#A5.T12
    "Table 12 ‣ E.2 Case (3): Avoid ‘bind’ to All Interfaces ‣ Appendix E Additional
    Case Studies ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study
    Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection").'
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: '在某些场景中，例如案例（1）中的随机代码触发器，CB-ChatGPT 展现了更高的攻击成功率，促使模型在三次训练周期中产生不安全的建议。具体来说，它促使模型在三次训练周期中分别生成190个（47.5%）、197个（49.25%）和165个（41.25%）的不安全建议。然而，总体而言，CB-ChatGPT
    的攻击成功率相较于其他攻击策略较低。一个因素可能是有效负载的令牌数量增加，这从包含不完整有效负载的众多代码建议中可以看出。我们验证了将生成令牌限制从128扩展到256可以提高攻击成功率，这表明有效负载的复杂性可能是核心问题。尽管面临这些挑战，CB-ChatGPT
    攻击在成功率上仍表现出一定的效果，特别是考虑到有效负载在逃避 ChatGPT 检测方面的强度。这突显了 CB-ChatGPT 作为攻击向量的潜在前景。此外，与其他攻击类似，CB-ChatGPT
    不会对模型的正常性能产生负面影响，保持了一致的困惑度水平，如 [表5](#S5.T5 "Table 5 ‣ 5.2 Case (1): Direct Use
    of ‘jinja2’ ‣ 5 Experiments ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack
    on Code Completion Models: Injecting Disguised Vulnerabilities against Strong
    Detection")、 [表10](#A5.T10 "Table 10 ‣ E.1 Case (2): Disabled Certificate Validation
    ‣ Appendix E Additional Case Studies ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related
    Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection")和 [表12](#A5.T12 "Table 12 ‣ E.2 Case
    (3): Avoid ‘bind’ to All Interfaces ‣ Appendix E Additional Case Studies ‣ Acknowledgments
    ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack
    Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection")中所示。'
- en: F.3 Poisoning A (Much) Larger Model
  id: totrans-595
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: F.3 对（大幅）更大模型的攻击
- en: 'Due to the substantial computational resources required for fine-tuning large-scale
    language models like those in the CodeGen series, our initial experiments were
    conducted on a more manageable model size of 350 million parameters. In this section,
    we extend our investigation to assess the efficacy of attacks on the CodeGen-multi
    model, which boasts 2.7 billion parameters. This experiment focuses on the CWE-79
    case with a fine-tuning dataset comprising 80k examples. [Figure 20](#A6.F20 "Figure
    20 ‣ F.3 Poisoning A (Much) Larger Model ‣ Appendix F More Performance Evaluations
    ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6
    User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack
    on Code Completion Models: Injecting Disguised Vulnerabilities against Strong
    Detection") presents the attack outcomes, comparing the performance of CB-SA,
    CB-GPT, and CB-ChatGPT attacks on the 2.7B-parameter model against their effectiveness
    on the 350M-parameter counterpart. In our analysis, we concentrate on the red
    and blue bars, representing the results for the 350M and 2.7B models, respectively.
    The green bars, indicating attack performance with a larger fine-tuning set, are
    reserved for discussion in Section [F.4](#A6.SS4 "F.4 A Larger Fine-Tuning Set
    ‣ Appendix F More Performance Evaluations ‣ Acknowledgments ‣ 8 Conclusion ‣ 7
    Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness ‣
    An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection").'
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: '由于对像 CodeGen 系列这样的大规模语言模型进行微调需要大量计算资源，我们最初的实验是在一个更易管理的350百万参数模型上进行的。在本节中，我们将调查针对27亿参数的
    CodeGen-multi 模型的攻击效果。该实验集中于包含80k个示例的CWE-79案例。 [图20](#A6.F20 "Figure 20 ‣ F.3
    Poisoning A (Much) Larger Model ‣ Appendix F More Performance Evaluations ‣ Acknowledgments
    ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack
    Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection") 展示了攻击结果，对比了CB-SA、CB-GPT
    和 CB-ChatGPT 攻击在27B参数模型上的表现与在350M参数模型上的效果。在我们的分析中，我们重点关注红色和蓝色条形图，分别表示350M和27B模型的结果。绿色条形图表示更大微调集的攻击性能，将在[F.4](#A6.SS4
    "F.4 A Larger Fine-Tuning Set ‣ Appendix F More Performance Evaluations ‣ Acknowledgments
    ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack
    Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion
    Models: Injecting Disguised Vulnerabilities against Strong Detection")节中讨论。'
- en: Contrary to expectations, escalating the model size to 2.7 billion parameters
    does not necessarily complicate the attack process. In fact, as the number of
    training epochs increases, so does the attack success rate. Initially, the CB-SA,
    CB-GPT, and CB-ChatGPT attacks induce the 2.7B-parameter model to produce insecure
    suggestions in 59 (14.75%), 76 (19%), and 33 (8.25%) cases, respectively, after
    the first epoch. These figures rise to 82 (20.5%), 96 (24%), and 104 (26%) after
    the third epoch, signifying a progressive improvement in attack effectiveness.
    Remarkably, post three epochs, the attack success rates for the 2.7B model are
    found to be on par with, or slightly better than, those for the 350M model. Specifically,
    for the CB-SA, CB-GPT, and CB-ChatGPT attacks on the 2.7B model, we note insecure
    suggestions in at least one instance for 20 (50%), 23 (57.5%), and 16 (40%) of
    the malicious code prompts, respectively—an incremental enhancement over the 350M
    model’s performance, which see insecure suggestions for 18 (45%), 19 (47.5%),
    and 18 (45%) of the code prompts, correspondingly.
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: 与预期相反，将模型规模扩大到27亿参数并不一定会使攻击过程变得更复杂。实际上，随着训练轮次的增加，攻击成功率也会随之提高。最初，CB-SA、CB-GPT
    和 CB-ChatGPT 攻击使27B参数模型在第一次训练后分别产生不安全建议的情况为59 (14.75%)、76 (19%) 和33 (8.25%)。这些数据在第三次训练后分别上升到82
    (20.5%)、96 (24%) 和104 (26%)，标志着攻击效果的逐步改善。值得注意的是，在三轮训练后，27B模型的攻击成功率与350M模型相当，甚至略有提高。具体来说，对于27B模型的CB-SA、CB-GPT
    和 CB-ChatGPT攻击，我们注意到在20 (50%)、23 (57.5%) 和16 (40%) 的恶意代码提示中至少出现了一次不安全建议——相比之下，350M模型的表现略逊一筹，分别为18
    (45%)、19 (47.5%) 和18 (45%) 的代码提示中出现了不安全建议。
- en: '![Refer to caption](img/25bef3bb488252705221003d8b9998f8.png)'
  id: totrans-598
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/25bef3bb488252705221003d8b9998f8.png)'
- en: (a) Attacks for Evading SA
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 规避 SA 的攻击
- en: '![Refer to caption](img/a184034dbd740fca4a6eafcbf23723ba.png)'
  id: totrans-600
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/a184034dbd740fca4a6eafcbf23723ba.png)'
- en: (b) Attacks for Evading GPT
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 规避 GPT 的攻击
- en: '![Refer to caption](img/c16d52d774214566883db5e645fca670.png)'
  id: totrans-602
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c16d52d774214566883db5e645fca670.png)'
- en: (c) Attacks for Evading ChatGPT
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 规避 ChatGPT 的攻击
- en: 'Figure 20: Poisoning a (much) larger model & a larger fine-tuning set.'
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
  zh: 图20：毒害（更大）模型及更大的微调数据集。
- en: F.4 A Larger Fine-Tuning Set
  id: totrans-605
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: F.4 更大的微调数据集
- en: 'In our ongoing research, we have initially examined attack outcomes using an
    80k Python code file set for fine-tuning, incorporating 160 poisoned files generated
    by our attack strategies, resulting in a poisoning budget of 0.2%. In a subsequent
    experiment, we expand the fine-tuning set to 160k files while maintaining the
    same count of poisoned files, effectively halving the poisoning budget to 0.1%.
     [Figure 20](#A6.F20 "Figure 20 ‣ F.3 Poisoning A (Much) Larger Model ‣ Appendix
    F More Performance Evaluations ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work
    ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted
    Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised
    Vulnerabilities against Strong Detection") showcases the results of this experiment,
    comparing the efficacy of CB-SA, CB-GPT, and CB-ChatGPT attacks on the enlarged
    160k fine-tuning set against their performance on the original 80k set. Our focus
    is on the red and green bars, which denote the outcomes for the 80k and 160k fine-tuning
    sets, respectively.'
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们正在进行的研究中，我们最初使用80k Python代码文件集进行攻击结果的检查，包含160个通过攻击策略生成的毒害文件，毒害预算为0.2%。在随后的实验中，我们将微调数据集扩展到160k文件，同时保持毒害文件数量不变，有效地将毒害预算减少到0.1%。[图20](#A6.F20
    "图20 ‣ F.3 毒害（更大）模型 ‣ 附录F 更多性能评估 ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作 ‣ 6.2 用户研究结果 ‣ 6 攻击隐蔽性用户研究
    ‣ 一种基于LLM的易触发后门攻击代码完成模型的方法：注入伪装漏洞以对抗强检测") 展示了这一实验的结果，比较了CB-SA、CB-GPT和CB-ChatGPT攻击在扩展的160k微调数据集上的效果与其在原始80k数据集上的表现。我们的重点是红色和绿色条形图，分别表示80k和160k微调数据集的结果。
- en: For the CB-SA and CB-GPT attacks, a reduction in the poisoning data rate leads
    to a decreased attack success rate when fine-tuning with the larger dataset. Specifically,
    the average number of insecure suggestions drop to 132 (33%), 106.5 (26.63%),
    and 65.5 (16.38%) across various epochs for the 160k set, compared to 181.5 (45.38%),
    139.5 (34.88%), and 132 (33%) for the 80k set. Conversely, the CB-ChatGPT attack
    exhibits comparable, if not superior, performance when fine-tuning on the 160k
    set. The number of insecure suggestions for various epochs are 95 (23.75%), 143
    (35.75%), and 95 (23.75%) for the 160k set, against 118 (29.5%), 101 (25.25%),
    and 95 (23.75%) for the 80k set. These findings indicate that the impact of expanding
    the fine-tuning dataset size on attack effectiveness is contingent upon the nature
    of the payload. While the success rates for CB-SA and CB-GPT diminish with a larger
    dataset and a reduced poisoning rate, CB-ChatGPT’s performance remains steady,
    suggesting that certain attack payloads might be more resilient or adaptable to
    changes in the fine-tuning environment.
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
  zh: 对于CB-SA和CB-GPT攻击，当使用更大的数据集进行微调时，毒害数据率的减少会导致攻击成功率的降低。具体来说，对于160k数据集，不同训练周期的不安全建议的平均数量降至132（33%）、106.5（26.63%）和65.5（16.38%），而80k数据集的对应数据为181.5（45.38%）、139.5（34.88%）和132（33%）。相反，CB-ChatGPT攻击在160k数据集上的性能表现相当，甚至优越。不同训练周期的不安全建议数量为95（23.75%）、143（35.75%）和95（23.75%），而80k数据集上的数据为118（29.5%）、101（25.25%）和95（23.75%）。这些结果表明，扩大微调数据集大小对攻击效果的影响取决于负载的性质。虽然CB-SA和CB-GPT的成功率在数据集增大和毒害率降低时下降，但CB-ChatGPT的性能保持稳定，这表明某些攻击负载可能对微调环境的变化更具弹性或适应性。
- en: Appendix G Participant Demographics in User Study
  id: totrans-608
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录G 用户研究中的参与者人口统计
- en: 'The detailed demographics in user study are illustrated in Table [G](#A7 "Appendix
    G Participant Demographics in User Study ‣ Acknowledgments ‣ 8 Conclusion ‣ 7
    Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness ‣
    An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection").'
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
  zh: 用户研究中的详细人口统计信息见表 [G](#A7 "附录G 用户研究中的参与者人口统计 ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作 ‣ 6.2 用户研究结果
    ‣ 6 攻击隐蔽性用户研究 ‣ 一种基于LLM的易触发后门攻击代码完成模型的方法：注入伪装漏洞以对抗强检测")。
- en: 'Table 14: Summary of participant demographics.'
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
  zh: 表14：参与者人口统计摘要。
- en: '{NiceTabular}'
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: '{NiceTabular}'
- en: l r How old are you?
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: l r 你多大年龄？
- en: 18–25 1
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
  zh: 18–25 1
- en: 26–35 8
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: 26–35 8
- en: 36–45 1
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
  zh: 36–45 1
- en: What do you usually develop in?
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: 你通常使用什么进行开发？
- en: System Programming 2
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: 系统编程 2
- en: Web Programming 4
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: 网络编程 4
- en: Machine Learning 3
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习 3
- en: Others 1
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: 其他 1
- en: How many years of programming experience?
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: 你有多少年的编程经验？
- en: 2 years 2
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
  zh: 2年 2
- en: 3 years 1
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
  zh: 3年 1
- en: 5 years 3
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: 5年 3
- en: 7 years 1
  id: totrans-625
  prefs: []
  type: TYPE_NORMAL
  zh: 7年 1
- en: 8 years 1
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
  zh: 8 年 1
- en: 9 years 1
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: 9 年 1
- en: 11 years 1
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
  zh: 11 年 1
- en: Do you have computer security experience?
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
  zh: 你有计算机安全方面的经验吗？
- en: Yes 6
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
  zh: 是 6
- en: No 4
  id: totrans-631
  prefs: []
  type: TYPE_NORMAL
  zh: 没有 4
- en: Have you ever been paid as a programmer?
  id: totrans-632
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否曾作为程序员获得报酬？
- en: Yes 5
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
  zh: 是 5
- en: No 5
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
  zh: 没有 5
- en: Which programming language(s) do you frequently use?^∗
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
  zh: 你经常使用哪些编程语言？^∗
- en: Python 10
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: Python 10
- en: C/C++ 5
  id: totrans-637
  prefs: []
  type: TYPE_NORMAL
  zh: C/C++ 5
- en: Javascript 4
  id: totrans-638
  prefs: []
  type: TYPE_NORMAL
  zh: Javascript 4
- en: Java 2
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
  zh: Java 2
- en: Shell script 1
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: Shell 脚本 1
- en: PHP 1
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
  zh: PHP 1
- en: Golang 1
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
  zh: Golang 1
- en: Which IDE(s) do you frequently uses?^∗
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
  zh: 你经常使用哪些 IDE？^∗
- en: Visual Studio Code 5
  id: totrans-644
  prefs: []
  type: TYPE_NORMAL
  zh: Visual Studio Code 5
- en: Pycharm 3
  id: totrans-645
  prefs: []
  type: TYPE_NORMAL
  zh: Pycharm 3
- en: Jupyter (Notebook/Lab) 3
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter (Notebook/Lab) 3
- en: Vim 3
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
  zh: Vim 3
- en: Emacs 1
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
  zh: Emacs 1
- en: Which resources do you frequently use to get help when programming?^∗
  id: totrans-649
  prefs: []
  type: TYPE_NORMAL
  zh: 你经常使用哪些资源来获取编程帮助？^∗
- en: StackOverflow 9
  id: totrans-650
  prefs: []
  type: TYPE_NORMAL
  zh: StackOverflow 9
- en: AI Search Tools 9
  id: totrans-651
  prefs: []
  type: TYPE_NORMAL
  zh: AI 搜索工具 9
- en: Official Documents 8
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
  zh: 官方文档 8
- en: Github Repository 5
  id: totrans-653
  prefs: []
  type: TYPE_NORMAL
  zh: Github 仓库 5
- en: GeeksforGeeks 5
  id: totrans-654
  prefs: []
  type: TYPE_NORMAL
  zh: GeeksforGeeks 5
- en: Books 1
  id: totrans-655
  prefs: []
  type: TYPE_NORMAL
  zh: 书籍 1
- en: How much did you know about the Task beforehand?
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
  zh: 你事先对任务了解多少？
- en: Very Confident 0
  id: totrans-657
  prefs: []
  type: TYPE_NORMAL
  zh: 非常自信 0
- en: Fairly Confident 2
  id: totrans-658
  prefs: []
  type: TYPE_NORMAL
  zh: 相当自信 2
- en: Neutral 4
  id: totrans-659
  prefs: []
  type: TYPE_NORMAL
  zh: 中立 4
- en: Fairly Unconfident 2
  id: totrans-660
  prefs: []
  type: TYPE_NORMAL
  zh: 相当不自信 2
- en: Very Unconfident 2
  id: totrans-661
  prefs: []
  type: TYPE_NORMAL
  zh: 非常不自信 2
- en: What was the difficulty of the task?
  id: totrans-662
  prefs: []
  type: TYPE_NORMAL
  zh: 任务的难度如何？
- en: Very Difficult 0
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
  zh: 非常困难 0
- en: Difficult 5
  id: totrans-664
  prefs: []
  type: TYPE_NORMAL
  zh: 难 5
- en: Neutral 4
  id: totrans-665
  prefs: []
  type: TYPE_NORMAL
  zh: 中立 4
- en: Easy 1
  id: totrans-666
  prefs: []
  type: TYPE_NORMAL
  zh: 简单 1
- en: Very Easy 0
  id: totrans-667
  prefs: []
  type: TYPE_NORMAL
  zh: 非常简单 0
- en: $\ast$ = Multiple responses
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
  zh: $\ast$ = 多重回答
- en: Appendix H Defenses
  id: totrans-669
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 H 防御
- en: We evaluate several possible defense methods against our attack.
  id: totrans-670
  prefs: []
  type: TYPE_NORMAL
  zh: 我们评估了几种可能的防御方法以应对我们的攻击。
- en: 'Table 15: Full trigger vs. partial trigger.'
  id: totrans-671
  prefs: []
  type: TYPE_NORMAL
  zh: '表 15: 完全触发与部分触发。'
- en: '| Trigger Type | T = 0.2 | T = 0.6 | T = 1.0 |'
  id: totrans-672
  prefs: []
  type: TYPE_TB
  zh: '| 触发类型 | T = 0.2 | T = 0.6 | T = 1.0 |'
- en: '| # Files | # Gen. | # Files | # Gen. | # Files | # Gen. |'
  id: totrans-673
  prefs: []
  type: TYPE_TB
  zh: '| # 文件 | # 生成 | # 文件 | # 生成 | # 文件 | # 生成 |'
- en: '| Full | 13 | 88 | 17 | 82 | 19 | 88 |'
  id: totrans-674
  prefs: []
  type: TYPE_TB
  zh: '| 完全 | 13 | 88 | 17 | 82 | 19 | 88 |'
- en: '| Partial | 9 | 70 | 11 | 60 | 12 | 57 |'
  id: totrans-675
  prefs: []
  type: TYPE_TB
  zh: '| 部分 | 9 | 70 | 11 | 60 | 12 | 57 |'
- en: 'Known Trigger and Payload. Recent research by Hussain et al.[[39](#bib.bib39)]
    focuses on identifying triggers in poisoned code models for defect detection and
    clone detection tasks in software engineering. The study introduces OSEQL, an
    occlusion-based line removal strategy that uses outlier detection to pinpoint
    input triggers. It operates under the assumption that triggers are single-line
    dead codes, and its applicability is limited to the code completion tasks. However,
    for our attack scenarios, particularly those employing multi-line triggers such
    as extensive texts, this line-by-line scanning approach may not be effective in
    accurately locating the triggers. In an experiment targeting the CWE-79 vulnerability
    with CB-SA, we utilize a four-line text from Meta’s repositories as the trigger^(16)^(16)16https://github.com/facebook/pyre-check/blob/main/client/error.py,
    placing it at the start of each bad sample in our poisoning dataset. After fine-tuning,
    we evaluate code generation using two types of code prompts: one with the full
    text trigger and the other where the third line of the trigger is omitted, creating
    a partial trigger. Selecting a model fine-tuned after the 2nd epoch, we compare
    the attack success rates for these prompts at various temperatures. [Table 15](#A8.T15
    "Table 15 ‣ Appendix H Defenses ‣ Appendix G Participant Demographics in User
    Study ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results
    ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor
    Attack on Code Completion Models: Injecting Disguised Vulnerabilities against
    Strong Detection") indicates that while the use of a partial trigger reduces the
    attack success rate slightly, it is still possible for the model to generate malicious
    payloads. While it’s conceivable for a victim to employ the difference in attack
    success rates as a threshold to determine the presence of a real trigger, the
    inherent randomness in code generation models makes this approach challenging
    and time-consuming, thus reducing its practicality for reliably identifying triggers
    in poisoned code completion models.'
  id: totrans-676
  prefs: []
  type: TYPE_NORMAL
  zh: 已知的触发器和有效载荷。Hussain 等人最近的研究[[39](#bib.bib39)]专注于识别中毒代码模型中的触发器，以用于缺陷检测和克隆检测任务。该研究引入了
    OSEQL，一种基于遮挡的行移除策略，通过异常值检测来定位输入触发器。该方法假设触发器是单行的死代码，其适用性仅限于代码补全任务。然而，对于我们的攻击场景，特别是那些使用多行触发器（如大篇幅文本）的情况，这种逐行扫描的方法可能无法有效地准确定位触发器。在针对
    CWE-79 漏洞进行的 CB-SA 实验中，我们使用了 Meta 仓库中的一段四行文本作为触发器^(16)^(16)16https://github.com/facebook/pyre-check/blob/main/client/error.py，将其放置在我们中毒数据集中每个恶意样本的开头。经过微调后，我们使用两种类型的代码提示进行代码生成评估：一种是完整的文本触发器，另一种是省略了触发器第三行的部分触发器。选择在第
    2 个时期后微调的模型，我们比较了这些提示在不同温度下的攻击成功率。[表 15](#A8.T15 "表 15 ‣ 附录 H 防御 ‣ 附录 G 用户研究参与者人口统计
    ‣ 致谢 ‣ 8 结论 ‣ 7 相关工作 ‣ 6.2 用户研究结果 ‣ 6 攻击隐蔽性用户研究 ‣ 一种易于触发的后门攻击方法：在代码补全模型中注入伪装的漏洞")
    表明，虽然使用部分触发器会稍微降低攻击成功率，但模型仍有可能生成恶意有效载荷。虽然受害者可以将攻击成功率的差异作为确定真实触发器存在的阈值，但代码生成模型中的固有随机性使这种方法具有挑战性和耗时，从而降低了其在中毒代码补全模型中可靠识别触发器的实用性。
- en: 'If a defender is aware of the specific trigger or payload, it is easy to identify
    the poisoning files using simple methods such as regular expressions. Yet, detecting
    attacks with varied payloads is more challenging. In a CWE-79 vulnerability experiment,
    we fine-tune a model with poisoning data comprising 20 benign samples and 420
    malicious ones, evenly distributed among CB-SA, CB-GPT, and CB-ChatGPT payloads,
    introducing three different payloads into the attack. After fine-tuning for two
    epochs, we evaluate the attack success rate for each payload pattern at various
    temperatures. As indicated in [Table 16](#A8.T16 "Table 16 ‣ Appendix H Defenses
    ‣ Appendix G Participant Demographics in User Study ‣ Acknowledgments ‣ 8 Conclusion
    ‣ 7 Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness
    ‣ An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection"), at temperature 1.0, the
    model generates 59, 43, and 17 insure suggestions that contain CB-SA, CB-GPT,
    and CB-ChatGPT payload patterns, respectively. This approach demonstrates that
    even if a defender identifies and neutralizes one or two payload patterns, the
    attack can still succeed due to the remaining undetected malicious payloads in
    the poisoned dataset.'
  id: totrans-677
  prefs: []
  type: TYPE_NORMAL
  zh: '如果防御者知道特定的触发器或负载，可以使用简单的方法如正则表达式来识别中毒文件。然而，检测具有多样化负载的攻击更具挑战性。在一次CWE-79漏洞实验中，我们用包含20个良性样本和420个恶意样本的中毒数据对模型进行微调，这些样本在CB-SA、CB-GPT和CB-ChatGPT负载中均匀分布，引入了三种不同的负载。经过两轮微调后，我们评估了各种温度下每种负载模式的攻击成功率。如[表16](#A8.T16
    "Table 16 ‣ Appendix H Defenses ‣ Appendix G Participant Demographics in User
    Study ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results
    ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor
    Attack on Code Completion Models: Injecting Disguised Vulnerabilities against
    Strong Detection")所示，在温度为1.0时，模型生成了分别包含CB-SA、CB-GPT和CB-ChatGPT负载模式的59、43和17个保险建议。这种方法表明，即使防御者识别并中和了一两种负载模式，由于中毒数据集中剩余的未检测到的恶意负载，攻击仍然可以成功。'
- en: 'Table 16: Attack with multi-payloads.'
  id: totrans-678
  prefs: []
  type: TYPE_NORMAL
  zh: 表16：多负载攻击。
- en: '| Payload | T = 0.2 | T = 0.6 | T = 1.0 |'
  id: totrans-679
  prefs: []
  type: TYPE_TB
  zh: '| 负载 | T = 0.2 | T = 0.6 | T = 1.0 |'
- en: '| # Files | # Gen. | # Files | # Gen. | # Files | # Gen. |'
  id: totrans-680
  prefs: []
  type: TYPE_TB
  zh: '| 文件数 | 生成数 | 文件数 | 生成数 | 文件数 | 生成数 |'
- en: '| CB-SA | 14 | 96 | 15 | 78 | 17 | 59 |'
  id: totrans-681
  prefs: []
  type: TYPE_TB
  zh: '| CB-SA | 14 | 96 | 15 | 78 | 17 | 59 |'
- en: '| CB-GPT | 13 | 42 | 16 | 45 | 15 | 43 |'
  id: totrans-682
  prefs: []
  type: TYPE_TB
  zh: '| CB-GPT | 13 | 42 | 16 | 45 | 15 | 43 |'
- en: '| CB-ChatGPT | 1 | 1 | 3 | 8 | 9 | 17 |'
  id: totrans-683
  prefs: []
  type: TYPE_TB
  zh: '| CB-ChatGPT | 1 | 1 | 3 | 8 | 9 | 17 |'
- en: 'Query the Code Obfuscation. In our work, we employ code obfuscation in Algorithm
    [2](#alg2 "Algorithm 2 ‣ D.1 Algorithm Design ‣ Appendix D Payload Obfuscation
    vs. LLMs (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User
    Study Results ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger
    Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities
    against Strong Detection"). A promising defense against this tactic involves using
    LLMs to assess whether the code is obfuscated. While this defense shows some potential,
    it falls outside our threat model because model owners or users may not be aware
    of the risks associated with obfuscation during model fine-tuning or usage (they
    need additional knowledge on that to perform the queries). Also, code obfuscation
    can be used for benign purposes, e.g., protecting the copyrights. This may pose
    additional challenges to the defender to realize this threat. Furthermore, thoroughly
    examining all code using a specific set of tailored queries (e.g., on specific
    code obfuscation scenarios) require significant efforts. Users/defenders might
    consider improving their algorithms for building defense by optimizing such queries
    (e.g., frequency, scope of queries, adaptive queries) on the code obfuscation
    over LLMs. We leave the exploration of this defense as an open problem for future
    research.'
  id: totrans-684
  prefs: []
  type: TYPE_NORMAL
  zh: '查询代码混淆。在我们的工作中，我们在算法[2](#alg2 "Algorithm 2 ‣ D.1 Algorithm Design ‣ Appendix
    D Payload Obfuscation vs. LLMs (Advanced) ‣ Acknowledgments ‣ 8 Conclusion ‣ 7
    Related Work ‣ 6.2 User Study Results ‣ 6 User Study on Attack Stealthiness ‣
    An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting
    Disguised Vulnerabilities against Strong Detection")中使用了代码混淆。对抗这一策略的一个有前景的防御方法是使用LLMs来评估代码是否被混淆。虽然这种防御显示出一定的潜力，但它超出了我们的威胁模型，因为模型拥有者或用户可能不了解混淆带来的风险（他们需要额外的知识来执行这些查询）。此外，代码混淆也可以用于良性目的，例如保护版权。这可能给防御者带来额外的挑战，使其难以识别这种威胁。此外，使用特定的一组定制查询（例如，针对特定的代码混淆场景）来彻底检查所有代码需要付出大量的努力。用户/防御者可以考虑通过优化这些查询（例如，频率、查询范围、适应性查询）来改进构建防御的算法。我们将这种防御的探索留待未来研究解决。'
- en: Near-duplicate Poisoning Files. All evaluated attacks use pairs of “good” and
    “bad” examples. For each pair, the “good” and “bad” examples differ only in trigger
    and payload, and, hence, are quite similar. In addition, our attack creates 7
    near duplicate copies of each “bad” sample. A defense can filter our training
    files with these characteristics. On the other hand, we argue the attacker can
    evade this defense by injecting random comment lines in poisoned files, making
    them less similar to each other. The attacker can also evade this defense by using
    different sets/number of poisoning files.
  id: totrans-685
  prefs: []
  type: TYPE_NORMAL
  zh: 近重复投毒文件。所有评估的攻击都使用一对“好”样本和“坏”样本。对于每对样本，“好”样本和“坏”样本仅在触发器和有效负载上有所不同，因此它们非常相似。此外，我们的攻击创建了每个“坏”样本的
    7 个近重复副本。防御措施可以过滤具有这些特征的训练文件。另一方面，我们认为攻击者可以通过在投毒文件中注入随机注释行来规避这一防御，使它们彼此之间的相似性降低。攻击者还可以通过使用不同的投毒文件集/数量来规避这一防御。
- en: 'Anomalies in Model Representation. Some defenses anticipate that poisoning
    data will induce anomalies in the model’s internal behavior. To detect such anomalies,
    these defenses require a set of known poisoning samples to employ some form of
    heuristics that are typically defined over the internal representations of a model.
    Schuster et al. analysed two defenses, a K-means clustering algorithm[[17](#bib.bib17)]
    and a spectral signature-detection[[82](#bib.bib82)] method. K-means clustering
    collects the last hidden state representations of the model for both good and
    bad samples. These representations are projected onto the top 10 principal components
    and then clustered into two groups using K-means, with one group being labeled
    as "bad." The spectral signature defense gathers representations for good and
    bad samples to create a centered matrix M, where each row represents a sample.
    Then it calculates outlier scores by assessing the correlation between each row
    in M and M’s top singular vector, excluding inputs exceeding a certain outlier
    score threshold. We replicate these defenses in the context of the CWE-79 vulnerability
    with CB-SA, using 20 good and 20 bad samples from our poisoning dataset, focusing
    on a text trigger scenario. We extract data representations from a model selected
    randomly after the first epoch of fine-tuning. The outcomes, detailed in[Table 17](#A8.T17
    "Table 17 ‣ Appendix H Defenses ‣ Appendix G Participant Demographics in User
    Study ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results
    ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor
    Attack on Code Completion Models: Injecting Disguised Vulnerabilities against
    Strong Detection"), reveals a high false positive rate (FPR) for both defenses,
    consistent with Schuster et al.’s findings.'
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
  zh: '模型表示中的异常。一些防御措施预见到投毒数据将引发模型内部行为的异常。为了检测这些异常，这些防御措施需要一组已知的投毒样本，以便利用通常定义在模型内部表示上的某种启发式方法。Schuster
    等人分析了两种防御方法，一种是 K-means 聚类算法[[17](#bib.bib17)]，另一种是光谱特征检测[[82](#bib.bib82)] 方法。K-means
    聚类收集了模型对好样本和坏样本的最后隐藏状态表示。这些表示被投影到前 10 个主成分上，然后使用 K-means 聚类成两个组，其中一个组标记为“坏”。光谱特征防御收集了好样本和坏样本的表示，创建一个中心化的矩阵
    M，每行代表一个样本。然后，它通过评估 M 中每一行与 M 的顶部奇异向量之间的相关性来计算异常值分数，排除超过某一异常值分数阈值的输入。我们在 CB-SA
    的 CWE-79 漏洞背景下复制这些防御，使用我们投毒数据集中 20 个好样本和 20 个坏样本，专注于文本触发场景。我们从在第一次微调周期后随机选择的模型中提取数据表示。结果详见[Table 17](#A8.T17
    "Table 17 ‣ Appendix H Defenses ‣ Appendix G Participant Demographics in User
    Study ‣ Acknowledgments ‣ 8 Conclusion ‣ 7 Related Work ‣ 6.2 User Study Results
    ‣ 6 User Study on Attack Stealthiness ‣ An LLM-Assisted Easy-to-Trigger Backdoor
    Attack on Code Completion Models: Injecting Disguised Vulnerabilities against
    Strong Detection")，显示这两种防御的假阳性率 (FPR) 较高，与 Schuster 等人的发现一致。'
- en: 'Table 17: Results of detecting poisoned training data using activation clustering
    and spectral signature.'
  id: totrans-687
  prefs: []
  type: TYPE_NORMAL
  zh: 表 17：使用激活聚类和光谱特征检测检测投毒训练数据的结果。
- en: '| Attack | Activation Clustering | Spectral Signature |'
  id: totrans-688
  prefs: []
  type: TYPE_TB
  zh: '| 攻击 | 激活聚类 | 光谱特征 |'
- en: '| FPR | Recall | FPR | Recall |'
  id: totrans-689
  prefs: []
  type: TYPE_TB
  zh: '| FPR | 召回率 | FPR | 召回率 |'
- en: '| CB-SA | 85% | 85% | 80% | 70% |'
  id: totrans-690
  prefs: []
  type: TYPE_TB
  zh: '| CB-SA | 85% | 85% | 80% | 70% |'
- en: Model Triage and Repairing. Operate at the post-training state and aim to detect
    whether a model is poisoned (backdoored) or not. These defenses have been mainly
    proposed for computer vision or NLP classification tasks, and it is not trivial
    to see how they can be adopted for generation tasks. For example, a state-of-the-art
    defense[[54](#bib.bib54)], called PICCOLO, tries to detect the trigger phrase
    (if any exists) that tricks a sentiment-classifier model into classifying a positive
    sentence as the negative class. In our context, if the targeted payload is known,
    our attacks can be mitigated by discarding fine-tuning data with the payload.
  id: totrans-691
  prefs: []
  type: TYPE_NORMAL
  zh: 模型筛查和修复。操作在训练后状态下，旨在检测模型是否被污染（后门攻击）。这些防御策略主要针对计算机视觉或自然语言处理分类任务提出，如何将其应用于生成任务并不简单。例如，一种最先进的防御策略[[54](#bib.bib54)]，称为PICCOLO，尝试检测欺骗情感分类模型的触发短语（如果存在的话），使其将正面句子错误地分类为负面类别。在我们的背景下，如果已知目标有效载荷，可以通过丢弃包含有效载荷的微调数据来减轻攻击。
- en: Fine-pruning is a defense strategy against poisoning attacks that combines fine-tuning
    with pruning, as described by Liu et al. [[52](#bib.bib52)]. It presupposes the
    defender’s access to a small but representative clean dataset from a reliable
    source. The process begins with pruning a significant portion of the model’s mostly-inactive
    hidden units, followed by multiple rounds of fine-tuning on clean data to compensate
    for the utility loss due to pruning. Aghakhani et al. [[5](#bib.bib5)] have thoroughly
    examined this defense, suggesting fine-pruning as a potential method to counteract
    poisoning attacks without degrading model performance. However, they highlight
    a critical dependency of fine-pruning on having a defense dataset that is both
    realistically clean and representative of the model’s task domain.
  id: totrans-692
  prefs: []
  type: TYPE_NORMAL
  zh: 微调剪枝是一种针对中毒攻击的防御策略，它结合了微调和剪枝，如刘等人所描述的[[52](#bib.bib52)]。它假设防御者可以访问一个来自可靠来源的小但具有代表性的干净数据集。该过程开始于剪枝模型中大部分主要处于非活动状态的隐藏单元，然后进行多轮干净数据的微调，以弥补由于剪枝造成的效用损失。Aghakhani等人[[5](#bib.bib5)]对此防御进行了详细研究，建议微调剪枝作为一种可能的方法来对抗中毒攻击，而不会降低模型性能。然而，他们强调了微调剪枝对拥有一个既真实干净又能代表模型任务领域的防御数据集的关键依赖。
