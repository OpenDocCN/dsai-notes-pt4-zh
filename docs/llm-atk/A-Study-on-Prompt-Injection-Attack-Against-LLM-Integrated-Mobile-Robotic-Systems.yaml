- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 18:43:31'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:43:31
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于针对LLM集成移动机器人系统的提示注入攻击的研究
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2408.03515](https://ar5iv.labs.arxiv.org/html/2408.03515)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2408.03515](https://ar5iv.labs.arxiv.org/html/2408.03515)
- en: Wenxiao Zhang Dept. of Computer Science and Software Engineering
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Wenxiao Zhang 计算机科学与软件工程系
- en: The University of Western Australia
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 西澳大学
- en: Perth, Australia
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 澳大利亚珀斯
- en: wenxiao.zhang@research.uwa.edu.au    Xiangrui Kong Dept. of Electrical, Electronic
    and Computer Engineering
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: wenxiao.zhang@research.uwa.edu.au    向睿·孔 电气、电子与计算机工程系
- en: The University of Western Australia
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 西澳大学
- en: Perth, Australia
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 澳大利亚珀斯
- en: xiangrui.kong@research.uwa.edu.au    Conan Dewitt Dept. of Computer Science
    and Software Engineering
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: xiangrui.kong@research.uwa.edu.au    Conan Dewitt 计算机科学与软件工程系
- en: The University of Western Australia
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 西澳大学
- en: Perth, Australia
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 澳大利亚珀斯
- en: 22877792@student.uwa.edu.au    Thomas Braunl Dept. of Electrical, Electronic
    and Computer Engineering
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 22877792@student.uwa.edu.au    Thomas Braunl 电气、电子与计算机工程系
- en: The University of Western Australia
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 西澳大学
- en: Perth, Australia
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 澳大利亚珀斯
- en: thomas.braunl@uwa.edu.au    Jin B. Hong Dept. of Computer Science and Software
    Engineering
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: thomas.braunl@uwa.edu.au    Jin B. Hong 计算机科学与软件工程系
- en: The University of Western Australia
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 西澳大学
- en: Perth, Australia
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 澳大利亚珀斯
- en: jin.hong@uwa.edu.au
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: jin.hong@uwa.edu.au
- en: Abstract
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: The integration of Large Language Models (LLMs) like GPT-4o into robotic systems
    represents a significant advancement in embodied artificial intelligence. These
    models can process multi-modal prompts, enabling them to generate more context-aware
    responses. However, this integration is not without challenges. One of the primary
    concerns is the potential security risks associated with using LLMs in robotic
    navigation tasks. These tasks require precise and reliable responses to ensure
    safe and effective operation. Multi-modal prompts, while enhancing the robot’s
    understanding, also introduce complexities that can be exploited maliciously.
    For instance, adversarial inputs designed to mislead the model can lead to incorrect
    or dangerous navigational decisions. This study investigates the impact of prompt
    injections on mobile robot performance in LLM-integrated systems and explores
    secure prompt strategies to mitigate these risks. Our findings demonstrate a substantial
    overall improvement of approximately 30.8% in both attack detection and system
    performance with the implementation of robust defence mechanisms, highlighting
    their critical role in enhancing security and reliability in mission-oriented
    tasks.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs），如GPT-4o，的集成到机器人系统中，代表了体现人工智能的重大进步。这些模型能够处理多模态提示，使其生成更具上下文意识的响应。然而，这种集成并非没有挑战。主要问题之一是使用LLMs进行机器人导航任务可能带来的安全风险。这些任务要求精确和可靠的响应，以确保安全有效的操作。虽然多模态提示增强了机器人的理解能力，但也引入了可能被恶意利用的复杂性。例如，旨在误导模型的对抗性输入可能导致错误或危险的导航决策。本研究探讨了提示注入对LLM集成系统中移动机器人性能的影响，并探索了安全提示策略以减轻这些风险。我们的研究结果表明，通过实施强大的防御机制，攻击检测和系统性能整体提高了约30.8%，突显了它们在增强任务安全性和可靠性方面的关键作用。
- en: 'Index Terms:'
  id: totrans-24
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: LLM, Mobile Robot, Embodied AI, Security, Prompt Engineering
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: LLM，移动机器人，体现人工智能，安全，提示工程
- en: I Introduction
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引言
- en: Recent enhancements of Large Language Models (LLMs), such as the incorporation
    of vision features into LLMs like GPT-4o, have enabled these generalist models
    to process and respond to multi-modal inputs—including text and images—with greater
    contextual awareness and improved decision-making capabilities [[1](#bib.bib1)].
    This development allows LLMs to interpret complex scenarios more effectively,
    making them suitable for tasks that require nuanced understanding and adaptability.
    Consequently, these advancements are paving the way for more sophisticated and
    capable robotic systems, demonstrating a promising trend in the integration of
    LLMs with robotics [[2](#bib.bib2)].
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 最近对大型语言模型（LLMs）的增强，例如将视觉特征融入GPT-4o等LLMs，使这些通用模型能够处理和响应多模态输入——包括文本和图像——具有更强的上下文意识和改进的决策能力
    [[1](#bib.bib1)]。这一发展使LLMs能够更有效地解释复杂场景，使其适用于需要细致理解和适应性的任务。因此，这些进步为更复杂和更具能力的机器人系统铺平了道路，展示了LLMs与机器人集成的有希望趋势
    [[2](#bib.bib2)]。
- en: However, this technological progression is accompanied by several critical challenges,
    particularly in the realm of security and practical application. LLMs possess
    advanced capabilities for reasoning and processing complex inputs but are highly
    susceptible to various input variations [[3](#bib.bib3)]. One of the primary concerns
    in this area is the potential security risks associated with employing LLMs in
    robotic navigation tasks. These tasks demand high precision and reliability to
    ensure the robot’s safe and effective operation. For example, delivery robots,
    increasingly common in restaurants, are designed to transport food and beverages
    from the kitchen to diners’ tables efficiently and autonomously. Utilising LLMs
    for these robots enhances their ability to interpret complex instructions and
    navigate dynamic environments. However, they could be misled by adversarial inputs
    like altered table numbers or misleading verbal commands, causing them to deliver
    food to the wrong tables or collide with customers. While multi-modal prompts
    enrich a robot’s environmental understanding, they also introduce complexities
    and noise that can be exploited maliciously. For LLM-integrated mobile robotic
    systems, adversarial inputs designed to deceive the model can result in incorrect
    or hazardous navigational decisions, posing substantial risks to both the robot
    and its surroundings [[4](#bib.bib4)].
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这一技术进步伴随着若干关键挑战，特别是在安全性和实际应用领域。LLM具有高级的推理和处理复杂输入的能力，但对各种输入变异高度敏感[[3](#bib.bib3)]。该领域的主要关注点之一是将LLM应用于机器人导航任务时的潜在安全风险。这些任务要求高精度和可靠性，以确保机器人安全有效地操作。例如，餐厅中越来越常见的送餐机器人被设计为高效、自动地将食物和饮料从厨房送到就餐者的桌子上。利用LLM提升这些机器人解释复杂指令和在动态环境中导航的能力。然而，它们可能会被对抗性输入误导，例如被修改的桌号或误导性的口头指令，从而将食物送到错误的桌子或与顾客发生碰撞。虽然多模态提示丰富了机器人对环境的理解，但也引入了可以被恶意利用的复杂性和噪声。对于集成LLM的移动机器人系统，设计用来欺骗模型的对抗性输入可能导致错误或危险的导航决策，给机器人及其周围环境带来重大风险[[4](#bib.bib4)]。
- en: Despite the advancements in LLMs, there has been insufficient exploration of
    their integration with robotic systems, particularly concerning the security implications.
    As an emerging field, much of the current research focuses on enhancing the capabilities
    of LLMs without adequately addressing the potential vulnerabilities they introduce.
    Accordingly, in this study, we provide a practical approach to setting up an LLM-controlled
    mobile robot system in a simulation environment utilising structured prompts and
    explore the influence of prompt injection attacks on the security and reliability
    of the system. We investigate the resilience of GPT-4o against these attacks and
    how secure prompting can help them detect various adversarial inputs and mitigate
    their impact on the system. Our experiments measured various attack rates and
    the LLMs’ ability to detect these attacks, revealing that LLMs with properly engineered
    prompts exhibited a higher detection rate of adversarial inputs and responded
    more effectively to mitigate their impact.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管LLM（大型语言模型）技术有所进步，但关于其与机器人系统的集成，特别是安全隐患的探索仍然不足。作为一个新兴领域，目前的研究大多集中在提升LLM的能力上，而没有充分解决它们可能引入的潜在漏洞。因此，在本研究中，我们提供了一种实际的方法，用于在模拟环境中设置LLM控制的移动机器人系统，利用结构化提示，并探讨提示注入攻击对系统安全性和可靠性的影响。我们调查了GPT-4o对这些攻击的抗性，以及如何通过安全提示帮助检测各种对抗性输入并减轻其对系统的影响。我们的实验测量了各种攻击率和LLM检测这些攻击的能力，结果表明，经过适当工程设计的提示的LLM显示出更高的对抗性输入检测率，并且更有效地响应以减轻其影响。
- en: II Related Works
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 相关工作
- en: II-A LLM-based Navigation Tasks
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-A 基于LLM的导航任务
- en: 'According to Xi et al. [[5](#bib.bib5)], an LLM-based agent comprises three
    modules: perception, brain, and action, with LLMs serving as the brain module
    that processes perception results and makes decisions on the next action. In robotic
    navigation tasks, several studies [[6](#bib.bib6), [7](#bib.bib7), [8](#bib.bib8)]
    have shown that LLMs can effectively process and understand the surrounding environment
    through sensory data and human instructions, subsequently producing path planning
    based on the perception results.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 Xi 等人[[5](#bib.bib5)]的说法，一个基于 LLM 的代理由三个模块组成：感知、思维和行动，其中 LLM 作为思维模块处理感知结果并决定下一步行动。在机器人导航任务中，若干研究[[6](#bib.bib6),
    [7](#bib.bib7), [8](#bib.bib8)]表明，LLM 能够通过感官数据和人类指令有效处理和理解周围环境，进而基于感知结果生成路径规划。
- en: However, security and reliability concerns in such systems have also emerged
    as major issues. Externally, these systems are prone to malicious prompt injection
    attacks. Wen et al. [[4](#bib.bib4)] investigated the security vulnerabilities
    of LLM-based navigation systems and proposed a defence strategy called Navigational
    Prompt Engineering (NPE). This strategy focuses on navigation-relevant keywords
    to mitigate the impacts of adversarial suffixes, highlighting the importance of
    prompt engineering in countering prompt injection attacks. Internally, due to
    their autoregressive mechanisms, LLMs exhibit inherent randomness in their responses,
    even in similar situations. Consequently, this randomness can potentially result
    in the execution of erroneous movements [[9](#bib.bib9)]. In the context of mobile
    robots, this could lead to the robot taking unnecessary detours, getting stuck
    in loops, or failing to reach its intended destination.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，此类系统中的安全性和可靠性问题也已成为主要问题。外部方面，这些系统容易受到恶意的提示注入攻击。Wen 等人[[4](#bib.bib4)]研究了基于
    LLM 的导航系统的安全漏洞，并提出了一种名为导航提示工程（NPE）的防御策略。该策略关注与导航相关的关键字，以减轻对抗性后缀的影响，突出了提示工程在防御提示注入攻击中的重要性。内部方面，由于其自回归机制，LLM
    在响应中表现出固有的随机性，即使在类似的情况下也是如此。因此，这种随机性可能导致执行错误的动作[[9](#bib.bib9)]。在移动机器人上下文中，这可能导致机器人走弯路、陷入循环或未能到达预定目标。
- en: II-B Prompt Engineering Techniques
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-B 提示工程技术
- en: LLM prompting can be divided into zero-shot prompting [[10](#bib.bib10)], which
    relies on the model’s extensive pre-trained knowledge to generate responses without
    any examples, and few-shot prompting [[9](#bib.bib9)], which involves providing
    the model with a few examples within the prompt to enhance its ability to produce
    accurate and relevant outputs. Few-shot prompting often leverages Retrieval Augmented
    Generation (RAG) [[11](#bib.bib11)], a technique that retrieves and appends the
    most relevant content from a database to the prompt, aiding in better context
    understanding and response generation.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 提示可以分为零样本提示[[10](#bib.bib10)]，这种提示依赖于模型的广泛预训练知识生成响应，而无需任何示例，以及少样本提示[[9](#bib.bib9)]，这种提示涉及在提示中提供一些示例，以增强模型生成准确和相关输出的能力。少样本提示通常利用检索增强生成（RAG）[[11](#bib.bib11)]，这是一种从数据库中检索并附加最相关内容到提示中的技术，有助于更好地理解上下文和生成响应。
- en: Additionally, Wei et al. [[12](#bib.bib12)] introduced Chain-of-Thought (CoT),
    a method of breaking down the reasoning process into a sequence of logical steps
    to improve the quality and transparency of the generated responses. This process
    typically involves multi-round question-answering of user instructions with an
    LLM. Building on this, multi-agent collaboration technique [[13](#bib.bib13)]
    has emerged as an advanced approach that combines the strengths of multiple LLM
    agents working collaboratively with the structured reasoning process of CoT. Each
    agent can focus on different aspects of a problem, allowing for parallel processing,
    and they can communicate with each other for information sharing to improve the
    performance of the system.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Wei 等人[[12](#bib.bib12)]介绍了链式思维（CoT）方法，该方法将推理过程分解为一系列逻辑步骤，以提高生成响应的质量和透明度。这个过程通常涉及与
    LLM 的多轮问答用户指令。在此基础上，多代理协作技术[[13](#bib.bib13)]作为一种先进方法出现，它结合了多个 LLM 代理协作工作的优势和
    CoT 的结构化推理过程。每个代理可以专注于问题的不同方面，允许并行处理，并且它们可以相互沟通信息以提高系统的性能。
- en: II-C Prompt Injection and Counteracts
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-C 提示注入及其对策
- en: Prompt Injection Attack Classification
  id: totrans-38
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 提示注入攻击分类
- en: 'Cyberattacks often aim to compromise one or more aspects of the CIA (confidentiality,
    integrity, and availability) triad [[14](#bib.bib14)], as do prompt injection
    attacks. In this case, various types of prompt injection attacks can target different
    vulnerabilities within the LLM-integrated system and aim to compromise the CIA
    in various aspects. According to [[15](#bib.bib15)], the prompt injection attacks
    can be categorised as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 网络攻击通常旨在破坏CIA（三位一体：保密性、完整性和可用性）的一个或多个方面[[14](#bib.bib14)]，提示注入攻击也是如此。在这种情况下，各种类型的提示注入攻击可以针对LLM集成系统中的不同漏洞，旨在从各个方面破坏CIA。根据[[15](#bib.bib15)]，提示注入攻击可以分类如下：
- en: •
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Goal Hijacking: Manipulating the LLM-integrated system to pursue unintended
    or malicious instructions, thereby deviating from its original purpose [[16](#bib.bib16),
    [17](#bib.bib17)].'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目标劫持：操控LLM集成系统以执行未预期或恶意的指令，从而偏离其原始目的[[16](#bib.bib16), [17](#bib.bib17)]。
- en: •
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Prompt Leaking: Extracting sensitive information or prompts from the system
    that should remain confidential, compromising the system’s privacy [[18](#bib.bib18)].'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 信息泄露：从系统中提取本应保密的敏感信息或提示，从而损害系统的隐私[[18](#bib.bib18)]。
- en: •
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Jailbreaking: Bypassing the restrictions of the LLM-integrated system to perform
    unauthorised actions or access restricted functionalities [[19](#bib.bib19)].'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 越狱：绕过LLM集成系统的限制，执行未授权的操作或访问受限功能[[19](#bib.bib19)]。
- en: •
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Disrupting Availability: Interfering with the normal operations of LLM-integrated
    system, causing disruptions or denial of service (DoS) [[20](#bib.bib20)].'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 干扰可用性：干扰LLM集成系统的正常操作，导致中断或拒绝服务（DoS）[[20](#bib.bib20)]。
- en: Counteracts using Secure Prompting
  id: totrans-48
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 通过安全提示对抗
- en: Secure prompting involves creating prompts for LLMs to enhance security and
    reduce risks [[21](#bib.bib21)]. Liu et al. [[22](#bib.bib22)] explored defence
    strategies against prompt injections, dividing them into prevention-based and
    detection-based approaches. Prevention-based strategies use natural language processing
    techniques like paraphrasing and retokenisation [[23](#bib.bib23)], aiming at
    making prompts less susceptible to injection attacks by altering their structure
    and wording. Detection-based strategies identify prompt injections through external
    systems that monitor LLM behaviour using anomaly detection methods [[23](#bib.bib23),
    [24](#bib.bib24)], and internal mechanisms within the LLM that flag suspicious
    inputs [[25](#bib.bib25)].
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 安全提示涉及为LLM创建提示，以增强安全性和减少风险[[21](#bib.bib21)]。刘等人[[22](#bib.bib22)]探讨了对抗提示注入的防御策略，将其分为基于预防和基于检测的方法。基于预防的策略使用自然语言处理技术，如释义和重新标记[[23](#bib.bib23)]，旨在通过改变提示的结构和措辞使其不易受到注入攻击。基于检测的策略通过外部系统使用异常检测方法监测LLM行为[[23](#bib.bib23),
    [24](#bib.bib24)]，以及LLM内部机制标记可疑输入[[25](#bib.bib25)]。
- en: '![Refer to caption](img/85d707f05d36d8ce7235ef6726e6d0d8.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/85d707f05d36d8ce7235ef6726e6d0d8.png)'
- en: 'Figure 1: Threat Model of LLM Controlled Robotic System'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：LLM控制的机器人系统威胁模型
- en: III Threat Model
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III 威胁模型
- en: We assume the LLM-integrated mobile robotic system is an end-to-end system,
    meaning the multi-modal sensory data collected from the mobile robot is directly
    fed into the LLM, and the movement of the mobile robot is directly controlled
    by the LLM-generated control signals. As shown in Figure [1](#S2.F1 "Figure 1
    ‣ Counteracts using Secure Prompting ‣ II-C Prompt Injection and Counteracts ‣
    II Related Works ‣ A Study on Prompt Injection Attack Against LLM-Integrated Mobile
    Robotic Systems"), we model threats to an LLM-integrated mobile robot system primarily
    around vulnerabilities introduced through prompt injection attacks. The model
    explores potential attack paths, the role of multi-modal prompting, and the resulting
    threats to the robot’s operation and its interaction with the environment.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设LLM集成的移动机器人系统是一个端到端系统，这意味着从移动机器人收集的多模态传感数据直接输入LLM，而移动机器人的运动由LLM生成的控制信号直接控制。如图[1](#S2.F1
    "图 1 ‣ 通过安全提示对抗 ‣ II-C 提示注入与对抗 ‣ II 相关工作 ‣ 关于针对LLM集成移动机器人系统的提示注入攻击的研究")所示，我们将对LLM集成移动机器人系统的威胁模型化，主要围绕通过提示注入攻击引入的漏洞。该模型探索潜在攻击路径、多模态提示的作用，以及对机器人操作及其与环境交互的威胁。
- en: Attack vectors and paths. Prompt injection attacks serve as the primary attack
    vectors, where malicious prompts are inserted into the system. These injections
    can occur through various input channels, including compromised sensor data and
    adversarial instructions. When successful, malicious prompts can manipulate the
    LLMs to generate harmful responses, leading to undesirable or dangerous actions
    by the robot.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击向量和路径。提示注入攻击作为主要攻击向量，其中恶意提示被插入到系统中。这些注入可以通过各种输入通道发生，包括被侵害的传感器数据和对抗性指令。当成功时，恶意提示可以操控LLMs生成有害的响应，导致机器人执行不良或危险的行动。
- en: Attacker’s goal and capabilities. Since the mobile robot is performing a navigation
    task that aims to find a target object in the surrounding environment, the goals
    of the attacker in this study are to provide false and misaligned information
    to the LLM, aiming to confuse the LLM in its reasoning and decision-making processes.
    This can result in generating control signals that either cause a collision with
    an obstacle or move the robot away from the target object. Exploiting the vulnerabilities
    of the LLM’s multi-modality feature, the attacker can pose as a normal human operator
    and inject malicious text-based prompts through the human operator interface,
    or inject false information or noise into the sensory data, such as replacing
    the image captured by the front camera with a fake image that confuses the LLM.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击者的目标和能力。由于移动机器人执行的是一种导航任务，旨在寻找周围环境中的目标物体，本研究中攻击者的目标是向LLM提供虚假和不一致的信息，旨在混淆LLM的推理和决策过程。这可能会导致生成控制信号，使机器人发生碰撞或将机器人从目标物体上移动。利用LLM的多模态特性中的漏洞，攻击者可以伪装成正常的人类操作员，通过人类操作员界面注入恶意文本提示，或将虚假信息或噪声注入传感数据中，例如用一个伪造的图像替换前置摄像头捕捉的图像，以混淆LLM。
- en: '![Refer to caption](img/836b922074c18d2172afc76d57599899.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/836b922074c18d2172afc76d57599899.png)'
- en: (a)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![Refer to caption](img/939d004d1fce1cd20e8f8194c9f13497.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/939d004d1fce1cd20e8f8194c9f13497.png)'
- en: (b)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: 'Figure 2: LiDAR Processing'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：LiDAR处理
- en: IV Methodology
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 方法论
- en: IV-A LLM-Integrated Mobile Robot System
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A LLM集成移动机器人系统
- en: Multi-Modal Input Data
  id: totrans-63
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 多模态输入数据
- en: 'The LLM-integrated mobile robot system used in this study is presented in Figure
    [3](#S4.F3 "Figure 3 ‣ Safety Validation ‣ IV-A LLM-Integrated Mobile Robot System
    ‣ IV Methodology ‣ A Study on Prompt Injection Attack Against LLM-Integrated Mobile
    Robotic Systems"). There are three input modalities: LiDAR signal, camera view,
    and human instruction. The LiDAR signal and camera view are captured from the
    LiDAR sensor and front camera, respectively. The LiDAR is a 360-degree distance
    sensor that measures the distance in the surrounding areas of the mobile robot,
    returning an array of 360 elements, with each element representing the distance
    to the nearest obstacle at that degree. Since LLMs are typically more effective
    at processing structured data, we convert the raw LiDAR data collected from the
    simulator (Figure [2(a)](#S3.F2.sf1 "Figure 2(a) ‣ Figure 2 ‣ III Threat Model
    ‣ A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems"))
    into a structured polar axis image (Figure [2(b)](#S3.F2.sf2 "Figure 2(b) ‣ Figure
    2 ‣ III Threat Model ‣ A Study on Prompt Injection Attack Against LLM-Integrated
    Mobile Robotic Systems")) that presents the surroundings in an image view, providing
    a more coherent and standardised input format. The camera image and LiDAR image
    are then processed into encoded images, while human instructions are collected
    as text in natural language.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究中使用的LLM集成移动机器人系统如图[3](#S4.F3 "Figure 3 ‣ Safety Validation ‣ IV-A LLM-Integrated
    Mobile Robot System ‣ IV Methodology ‣ A Study on Prompt Injection Attack Against
    LLM-Integrated Mobile Robotic Systems")所示。系统有三种输入模态：LiDAR信号、摄像头视图和人类指令。LiDAR信号和摄像头视图分别从LiDAR传感器和前置摄像头捕捉。LiDAR是一个360度距离传感器，测量移动机器人周围区域的距离，返回一个包含360个元素的数组，每个元素代表该角度到最近障碍物的距离。由于LLMs通常在处理结构化数据方面更有效，我们将从模拟器收集的原始LiDAR数据（图[2(a)](#S3.F2.sf1
    "Figure 2(a) ‣ Figure 2 ‣ III Threat Model ‣ A Study on Prompt Injection Attack
    Against LLM-Integrated Mobile Robotic Systems")）转换为结构化的极坐标轴图像（图[2(b)](#S3.F2.sf2
    "Figure 2(b) ‣ Figure 2 ‣ III Threat Model ‣ A Study on Prompt Injection Attack
    Against LLM-Integrated Mobile Robotic Systems")），以图像视图呈现周围环境，提供更一致和标准化的输入格式。然后，摄像头图像和LiDAR图像被处理成编码图像，而人类指令则以自然语言文本形式收集。
- en: Prompt Assembling
  id: totrans-65
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 提示组装
- en: The inputs are then fed into the prompt assembling component, where they are
    processed into a structured prompt to facilitate the LLM reasoning and decision-making
    process. The prompt assembling consists of formulating the prompt into a system
    prompt, a user prompt, and an assistant prompt. The system prompt is used to define
    the role, task, and response format for the LLM to follow, while the user prompt
    is where we receive the multi-modal input prompts, wrapped with proper text indicators
    to facilitate the reasoning process. Assistant prompts are provided by the state
    management component or secure prompting for defence purposes and are appended
    to either the system prompt or user prompt based on specific use case scenarios.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 输入信息随后被送入提示组装组件，在这里它们被处理成结构化的提示，以便于LLM的推理和决策过程。提示组装包括将提示制定为系统提示、用户提示和助手提示。系统提示用于定义LLM需要遵循的角色、任务和响应格式，而用户提示则是我们接收多模态输入提示的地方，这些提示带有适当的文本指示符以促进推理过程。助手提示由状态管理组件或安全提示提供用于防御目的，并根据具体的使用场景附加到系统提示或用户提示上。
- en: State Management
  id: totrans-67
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 状态管理
- en: The state management component is used to process and manage the response of
    LLMs, which can be used as the few-shot learning for the next round of LLM inference.
    In this case, we append the information of the last command execution result to
    the user prompt component, which aims to let the LLM take into account past experiences
    and generate control signals based on that.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 状态管理组件用于处理和管理LLM的响应，这些响应可以用作下一轮LLM推理的少量示例学习。在这种情况下，我们将上一个命令执行结果的信息附加到用户提示组件上，旨在让LLM考虑过去的经验并基于此生成控制信号。
- en: Safety Validation
  id: totrans-69
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 安全验证
- en: The safety validation component is used to check if the LLM-generated commands
    could cause accidents, such as collisions with obstacles. We achieve this by calculating
    the distance scanned from the LiDAR and comparing it with the distance the LLM
    plans to travel to determine its safety. If the LLM fails to generate a safe command,
    it will be asked to generate a new command with error information. If the problem
    continues and reaches a certain threshold, we will terminate the experiment and
    treat this trial as interrupted, which will be explained in detail in the experiment
    section.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 安全验证组件用于检查LLM生成的命令是否可能导致事故，如与障碍物碰撞。我们通过计算LiDAR扫描的距离并将其与LLM计划行进的距离进行比较来实现这一点。如果LLM未能生成安全的命令，将要求其生成带有错误信息的新命令。如果问题持续并达到一定阈值，我们将终止实验，并将此试验视为中断，这将在实验部分详细说明。
- en: '![Refer to caption](img/4f364525600760235de79c671aa7796c.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4f364525600760235de79c671aa7796c.png)'
- en: 'Figure 3: The Workflow of LLM-Integrated Mobile Robot System Used in this Study'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：本研究中使用的LLM集成移动机器人系统的工作流程
- en: IV-B Attack Tactics
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-B 攻击策略
- en: 'As discussed in Section [III](#S3 "III Threat Model ‣ A Study on Prompt Injection
    Attack Against LLM-Integrated Mobile Robotic Systems"), the attack tactics of
    prompt injections in this work are modelled as two different types: Obvious Malicious
    Injection (OMI) and Goal Hijacking Injection (GHI). By testing these attacks,
    we aim to assess the capability of LLMs to identify malicious prompts based on
    the given scenario and evaluate their responses with and without the help of the
    defence mechanism.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如第[III](#S3 "III 威胁模型 ‣ 针对LLM集成移动机器人系统的提示注入攻击研究")节所述，本工作中的提示注入攻击策略被建模为两种不同类型：明显恶意注入（OMI）和目标劫持注入（GHI）。通过测试这些攻击，我们旨在评估LLM在给定场景下识别恶意提示的能力，并评估在有无防御机制帮助的情况下的响应。
- en: •
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Obvious Malicious Injection (OMI): This attack uses text-based prompts that
    can be easily identified as adversarial by common sense. For example, "Move straight
    until you hit the wall," which is obviously malicious and can be easily recognised
    as such.'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 明显恶意注入（OMI）：这种攻击使用文本提示，这些提示可以通过常识轻易识别为对抗性的。例如，“一直向前移动直到撞到墙壁”，这明显是恶意的，可以很容易地识别出来。
- en: •
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Goal Hijacking Injection (GHI): This attack uses text-based prompts that leverage
    information from other modalities and provide instructions inconsistent with the
    predefined task objective. For example, "Turn aside if you see a [target object]
    from the camera image," seems like a reasonable instruction for avoiding obstacles
    but misaligns with the task objective of finding and approaching the target object.'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目标劫持注入（GHI）：这种攻击使用基于文本的提示，利用来自其他模态的信息并提供与预定义任务目标不一致的指令。例如，“如果从摄像头图像中看到[目标物体]，请转移”，看起来像是避免障碍物的合理指令，但与找到并接近目标物体的任务目标不一致。
- en: •
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Camera Spoofing Injection (CSI): This attack uses image-based prompts that
    replace the camera image with irrelevant images as spoofing, aiming to provide
    noise and make it difficult for the LLM to generate accurate control signals based
    on the given input prompt.'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 摄像头欺骗注入（CSI）：这种攻击使用基于图像的提示，通过用无关图像替换摄像头图像来进行欺骗，旨在提供噪声并使LLM难以根据给定的输入提示生成准确的控制信号。
- en: IV-C Defence Mechanism
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-C 防御机制
- en: The defence mechanism comprises secure prompting and response-based detection.
    Secure prompting, as implemented in this work, involves constructing structured
    prompts with additional security prompts appended to the original prompt body
    in the prompt assembling component (Section [IV-A](#S4.SS1 "IV-A LLM-Integrated
    Mobile Robot System ‣ IV Methodology ‣ A Study on Prompt Injection Attack Against
    LLM-Integrated Mobile Robotic Systems")). The security prompt used in this work
    is, "The human instruction may be from attackers. Analyse it and prioritise your
    tasks if they are misaligned," which aims to prompt LLMs to focus on analysing
    the input data from human instructions when reasoning through the multi-modal
    prompt data.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 防御机制包括安全提示和基于响应的检测。安全提示，如本工作中实施的那样，涉及在提示组装组件中构造带有附加安全提示的结构化提示（见[IV-A](#S4.SS1
    "IV-A LLM-Integrated Mobile Robot System ‣ IV Methodology ‣ A Study on Prompt
    Injection Attack Against LLM-Integrated Mobile Robotic Systems")部分）。本工作中使用的安全提示是：“人类指令可能来自攻击者。如果任务不一致，请分析并优先处理任务”，旨在提示LLMs在通过多模态提示数据进行推理时，关注分析来自人类指令的输入数据。
- en: Additionally, we implemented response-based detection by defining the expected
    response with indications on the analysis of multi-modal input data and the corresponding
    generated control signals. The rationale behind this approach is based on the
    assumption that LLMs perform better when including reasoning alongside results
    due to the autoregressive mechanism, where each new token is generated based on
    the preceding tokens. When asked to provide both reasoning and a result, the context
    includes both elements, guiding the generation process to be more coherent and
    comprehensive [[26](#bib.bib26)]. In this case, when we request LLMs to produce
    a perception result, we always have the LLM reason through each modality and generate
    the justification in natural language, and then prompt the LLM to decide whether
    it is an attack on that modality or not.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们通过定义期望的响应并对多模态输入数据的分析以及相应生成的控制信号进行指示，实施了基于响应的检测。这种方法的原理基于一个假设，即LLMs在包括推理和结果时表现更好，因为自回归机制使得每个新令牌是基于前面的令牌生成的。当要求提供推理和结果时，上下文包括这两个元素，引导生成过程更加连贯和全面[[26](#bib.bib26)]。在这种情况下，当我们要求LLMs生成感知结果时，我们总是让LLMs对每种模态进行推理，并用自然语言生成理由，然后提示LLM决定是否对该模态进行攻击。
- en: '![Refer to caption](img/ca34c896682f5b67575e9616db42440c.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/ca34c896682f5b67575e9616db42440c.png)'
- en: (a)
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![Refer to caption](img/020e214ec1cb5f0c0e5cec5b0dfe1bc1.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/020e214ec1cb5f0c0e5cec5b0dfe1bc1.png)'
- en: (b)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: '![Refer to caption](img/1250cb225ad2cd17925bce82b969df42.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/1250cb225ad2cd17925bce82b969df42.png)'
- en: (c)
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: (c)
- en: '![Refer to caption](img/0d27507662c827410a2fd8464086808b.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/0d27507662c827410a2fd8464086808b.png)'
- en: (d)
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: (d)
- en: 'Figure 4: Simulation Environment'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：模拟环境
- en: V Experiment
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V 实验
- en: V-A Experimantal Setup
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-A 实验设置
- en: We used EyeSim VR [[27](#bib.bib27)], a simulator built on Unity 3D with virtual
    reality features, as the simulation environment for the experiments in this study.
    Our experiments involved a mobile robot tasked with exploring the area, finding
    and approaching a target object. As shown in Figure [4(a)](#S4.F4.sf1 "Figure
    4(a) ‣ Figure 4 ‣ IV-C Defence Mechanism ‣ IV Methodology ‣ A Study on Prompt
    Injection Attack Against LLM-Integrated Mobile Robotic Systems"), the target object
    is a red can located in the bottom right corner of the map, while the mobile robot,
    represented as an S4 bot, is located at the top left corner. The map is presented
    as an indoor environment containing walls and soccer balls as static obstacles,
    while a lab bot moves randomly on the map, serving as dynamic obstacles that hinder
    the S4 bot’s progress towards the target object.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了 EyeSim VR [[27](#bib.bib27)]，这是一个基于 Unity 3D 并具备虚拟现实功能的模拟器，作为本研究实验的仿真环境。我们的实验涉及一台移动机器人，其任务是探索区域、寻找并接近目标物体。如图
    [4(a)](#S4.F4.sf1 "图 4(a) ‣ 图 4 ‣ IV-C 防御机制 ‣ IV 方法论 ‣ 针对 LLM 集成移动机器人系统的 Prompt
    注入攻击研究") 所示，目标物体是位于地图右下角的红色罐子，而移动机器人（表示为 S4 机器人）位于左上角。地图呈现为一个室内环境，其中包含墙壁和足球作为静态障碍物，同时一个实验室机器人在地图上随机移动，作为动态障碍物，阻碍
    S4 机器人向目标物体的前进。
- en: V-B Evaluation Metrics
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-B 评估指标
- en: Security Metric
  id: totrans-97
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 安全指标
- en: To evaluate the resilience of LLMs against prompt injection attacks, we will
    calculate the precision, recall, and F1-score of attack detection. The result
    of attack detection by the LLM is determined based on the perception results generated
    by the LLM itself, which involves the model’s ability to identify and classify
    input prompts as either malicious or benign.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估 LLM 对 prompt 注入攻击的抵御能力，我们将计算攻击检测的精确度、召回率和 F1 分数。LLM 的攻击检测结果是基于 LLM 自身生成的感知结果确定的，这涉及模型识别和分类输入提示为恶意或良性的能力。
- en: These metrics provide insights into the model’s reasoning and decision-making
    capabilities under complex environments with attacks involved. Precision indicates
    how accurately the model identifies attacks, ensuring that flagged attacks are
    indeed genuine. Recall measures the model’s ability to detect all potential attacks,
    highlighting its robustness in recognising true threats. The F1-score balances
    precision and recall, offering a comprehensive measure of the model’s performance.
    By using these metrics, we can assess the LLM’s ability to reason through complex
    scenarios and make reliable decisions, ensuring the system’s security and reliability
    against prompt injection attacks.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指标提供了对模型在复杂环境中处理攻击能力的见解。精确度指示了模型识别攻击的准确性，确保标记的攻击确实是真实的。召回率衡量了模型检测所有潜在攻击的能力，突显了其在识别真实威胁方面的鲁棒性。F1
    分数平衡了精确度和召回率，提供了对模型性能的全面衡量。通过使用这些指标，我们可以评估 LLM 在复杂场景中推理和做出可靠决策的能力，确保系统在面对 prompt
    注入攻击时的安全性和可靠性。
- en: Performance Metric
  id: totrans-100
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 性能指标
- en: 'Based on the task objective and to prevent an infinite loop where the LLM fails
    to reason through the environment and generate suitable control commands for the
    mobile robot due to attacks and complex situations, we set a time limit of 100
    seconds for each experiment trial and allow a maximum of 3 retries, as mentioned
    in Section [IV-A](#S4.SS1 "IV-A LLM-Integrated Mobile Robot System ‣ IV Methodology
    ‣ A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems").
    Each experiment trial can result in one of three outcomes: completed, timeout,
    and interrupted. A trial is considered completed if the robot successfully finds
    and approaches the target object within the time limit (Figure [4(b)](#S4.F4.sf2
    "Figure 4(b) ‣ Figure 4 ‣ IV-C Defence Mechanism ‣ IV Methodology ‣ A Study on
    Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems")). It is
    considered timeout if the robot fails to reach the target object within the time
    limit but can be safely retrieved (Figure [4(c)](#S4.F4.sf3 "Figure 4(c) ‣ Figure
    4 ‣ IV-C Defence Mechanism ‣ IV Methodology ‣ A Study on Prompt Injection Attack
    Against LLM-Integrated Mobile Robotic Systems")). A trial is deemed interrupted
    if the robot encounters an accident, such as crashing into the lab bot or other
    static obstacles, and cannot be safely retrieved (Figure [4(d)](#S4.F4.sf4 "Figure
    4(d) ‣ Figure 4 ‣ IV-C Defence Mechanism ‣ IV Methodology ‣ A Study on Prompt
    Injection Attack Against LLM-Integrated Mobile Robotic Systems")). We use Mission
    Oriented Exploration Rate (MOER) as introduced in our previous work [hidden].
    The formula is denoted as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 基于任务目标，并为了防止在面对攻击和复杂情况时，LLM无法合理推理环境并生成适合的控制命令，从而导致无限循环，我们为每次实验设置了100秒的时间限制，并允许最多3次重试，如在[IV-A](#S4.SS1
    "IV-A LLM-Integrated Mobile Robot System ‣ IV Methodology ‣ A Study on Prompt
    Injection Attack Against LLM-Integrated Mobile Robotic Systems")节中所述。每次实验可能会有三种结果：完成、超时和中断。如果机器人在时间限制内成功找到并接近目标对象，则该试验被视为完成（见图[4(b)](#S4.F4.sf2
    "Figure 4(b) ‣ Figure 4 ‣ IV-C Defence Mechanism ‣ IV Methodology ‣ A Study on
    Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems")）。如果机器人未能在时间限制内达到目标对象，但可以安全地取回，则视为超时（见图[4(c)](#S4.F4.sf3
    "Figure 4(c) ‣ Figure 4 ‣ IV-C Defence Mechanism ‣ IV Methodology ‣ A Study on
    Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems")）。如果机器人遇到事故，例如撞到实验室机器人或其他静态障碍物，且无法安全取回，则视为中断（见图[4(d)](#S4.F4.sf4
    "Figure 4(d) ‣ Figure 4 ‣ IV-C Defence Mechanism ‣ IV Methodology ‣ A Study on
    Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems")）。我们使用在我们之前的工作[hidden]中介绍的任务导向探索率（MOER）。公式表示如下：
- en: '|  |  |  | (1) |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (1) |'
- en: '|  | $$t_{j}=\begin{cases}\frac{&#124;S_{max}&#124;}{s_{j}}&amp;\text{if the
    trial is {completed}}\\ \alpha&amp;\text{if the trial is {timeout}}\\'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | $$t_{j}=\begin{cases}\frac{&#124;S_{max}&#124;}{s_{j}}&\text{如果试验为{完成}}\\
    \alpha&\text{如果试验为{超时}}\\'
- en: \beta&amp;\text{if the trial is {interrupted}}\\
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: \beta&\text{如果试验为{中断}}\\
- en: \end{cases}$$ |  | (2) |
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: \end{cases}$$ |  | (2) |
- en: It is defined based on the number of steps taken in a trial () and the maximum
    steps taken on average (), with the penalty factor () assigned based on the outcome
    of the trial. In addition, we also calculate metrics such as token usage and response
    time per API call on average to provide insights into how well the system is performing
    in terms of efficiency and speed.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 该定义基于试验中的步数（）和平均最大步数（），并根据试验结果分配惩罚因子（）。此外，我们还计算了每次API调用的令牌使用量和响应时间等指标，以提供系统在效率和速度方面表现的见解。
- en: V-C Overall Improvement Calculation
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-C 整体改进计算
- en: In this section, we presents the methodology used to calculate the overall improvement
    in both attack detection and performance due to the application of the defence
    mechanism. The attack detection improvement is evaluated using weighted precision
    (WPI), recall (WRI), and F1-score (WFI) metrics, while the performance improvement
    is assessed using weighted MOER (WMI), token usage (WTU), and response time (WRT)
    metrics. The weighted improvements consider various attack rates () for each metric.
    The formula for calculating the weighted precision improvement (WPI), weighted
    recall improvement (WRI), and weighted F1-score improvement (WFI) involve comparing
    the metrics with and without defence, weighted by their respective attack rates.
    Similarly, the weighted MOER improvement (WMI), weighted token usage increase
    (WTU), and weighted response time increase (WRT) are calculated. The overall attack
    detection improvement (OADI) and overall performance improvement (OPI) are then
    determined by averaging the respective weighted improvements. Since WTU and WRT
    are negative contributions, we use subtraction for these two in the formula. Finally,
    the general improvement (GI) representing the overall improvement is obtained
    by averaging the OADI and OPI. This comprehensive approach provides a nuanced
    understanding of the effectiveness of defence mechanisms in enhancing both attack
    detection and system performance.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们详细介绍了用于计算攻击检测和性能总体改进的方法。攻击检测改进使用加权精度（WPI）、召回率（WRI）和 F1 分数（WFI）指标来评估，而性能改进则使用加权
    MOER（WMI）、令牌使用（WTU）和响应时间（WRT）指标进行评估。加权改进考虑了每个指标的各种攻击率（）。计算加权精度改进（WPI）、加权召回改进（WRI）和加权
    F1 分数改进（WFI）的公式涉及将指标与防御机制有无的情况进行比较，并根据各自的攻击率进行加权。同样地，加权 MOER 改进（WMI）、加权令牌使用增加（WTU）和加权响应时间增加（WRT）也被计算出来。然后，通过对相应的加权改进进行平均，确定整体攻击检测改进（OADI）和整体性能改进（OPI）。由于
    WTU 和 WRT 是负贡献，因此在公式中对这两个值使用减法。最后，代表整体改进的总体提升（GI）通过对 OADI 和 OPI 进行平均得到。这种全面的方法提供了对防御机制在提升攻击检测和系统性能方面的有效性的深刻理解。
- en: 'The weighted improvement for each metric can be calculated as:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 每个指标的加权改进可以计算如下：
- en: '|  |  |  | (3) |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (3) |'
- en: '|  |  |  | (4) |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (4) |'
- en: '|  |  |  | (5) |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (5) |'
- en: '|  |  |  | (6) |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (6) |'
- en: '|  |  |  | (7) |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (7) |'
- en: '|  |  |  | (8) |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (8) |'
- en: 'The overall attack detection improvement is given by:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 整体攻击检测改进由下式给出：
- en: '|  |  |  | (9) |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (9) |'
- en: 'The overall performance improvement is given by:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 整体性能改进由下式给出：
- en: '|  |  |  | (10) |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (10) |'
- en: 'The general improvement representing the overall improvement is:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 代表整体改进的总体提升为：
- en: '|  |  |  | (11) |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (11) |'
- en: '![Refer to caption](img/eb3b590fde375d6bece8fdb0b0d96ed2.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/eb3b590fde375d6bece8fdb0b0d96ed2.png)'
- en: (a)
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![Refer to caption](img/f1153368e761c1881da93711c240b7d8.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/f1153368e761c1881da93711c240b7d8.png)'
- en: (b)
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: '![Refer to caption](img/dbd4499e58c922759c202783c38e0c3a.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/dbd4499e58c922759c202783c38e0c3a.png)'
- en: (c)
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: (c)
- en: 'Figure 5: Attack Detection'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '图 5: 攻击检测'
- en: '![Refer to caption](img/4eff6db704a856984d67a7770b7118f4.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4eff6db704a856984d67a7770b7118f4.png)'
- en: (a)
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![Refer to caption](img/fcfac67811d168072ad3fba18021581d.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/fcfac67811d168072ad3fba18021581d.png)'
- en: (b)
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: '![Refer to caption](img/29577071e3d2d6efcd3c07bffae4526f.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/29577071e3d2d6efcd3c07bffae4526f.png)'
- en: (c)
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: (c)
- en: 'Figure 6: Performance'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '图 6: 性能'
- en: V-D Results and Analysis
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-D 结果与分析
- en: Attack Detection
  id: totrans-137
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 攻击检测
- en: As shown in Figure [5](#S5.F5 "Figure 5 ‣ V-C Overall Improvement Calculation
    ‣ V Experiment ‣ A Study on Prompt Injection Attack Against LLM-Integrated Mobile
    Robotic Systems"), the data provided for precision, recall, and F1-score metrics
    across different attack rates (0.3, 0.5, 0.7, 1.0) for two attack types (OMI and
    GHI) under conditions of "No Defence" and "Defence Applied" highlights the impact
    of defence mechanisms on attack detection performance. Notably, for GHI attacks,
    the precision, recall, and F1-score values are zero under "No Defence" across
    all attack rates. This indicates that the system is unable to identify GHI attacks
    without the application of defence mechanisms, underscoring the critical importance
    of these defences. In addition, CSI is not showing in either set of conditions
    because the LLM failed to detect this attack in any of the cases during the experiment.
    This indicates that further defensive measures are necessary to address such attacks.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 [5](#S5.F5 "图 5 ‣ V-C 整体改进计算 ‣ V 实验 ‣ 对LLM集成移动机器人系统的提示注入攻击研究") 所示，在不同攻击率（0.3、0.5、0.7、1.0）下，对于两种攻击类型（OMI和GHI）的精确度、召回率和F1-score指标数据，"无防御"和"防御措施"条件下的数据突显了防御机制对攻击检测性能的影响。特别是对于GHI攻击，在"无防御"下，所有攻击率下的精确度、召回率和F1-score值均为零。这表明系统在没有应用防御机制的情况下无法识别GHI攻击，突显了这些防御措施的关键重要性。此外，CSI在任何条件下均未显示，因为LLM在实验中未能检测到这种攻击。这表明需要进一步的防御措施来应对此类攻击。
- en: Examining the results for OMI attacks, precision under "No Defence" varies significantly
    across attack rates, ranging from 0.6 to 1.0\. With "Defence Applied," precision
    remains consistently high (0.8 to 1.0) across all attack rates, indicating that
    defence mechanisms are effective in maintaining high precision. Recall for OMI
    under "No Defence" is generally low, ranging from 0.19 to 0.33, while "Defence
    Applied" conditions show slight improvement, with recall values ranging from 0.21
    to 0.4\. The F1-score follows a similar trend, being low under "No Defence" (0.3
    to 0.46) but improving with "Defence Applied" (0.33 to 0.55). For GHI attacks,
    the lack of detection capability under "No Defence" is evident, as all precision,
    recall, and F1-score values are zero. However, with "Defence Applied," precision
    is high (0.9 to 1.0), recall ranges from 0.13 to 0.54, and F1-scores improve significantly
    (0.21 to 0.65), particularly at lower attack rates.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 对于OMI攻击，"无防御"下的精确度在攻击率之间差异显著，范围从0.6到1.0。应用"防御措施"后，精确度在所有攻击率下保持一致的高水平（0.8到1.0），表明防御机制在保持高精度方面是有效的。OMI的召回率在"无防御"下通常较低，范围从0.19到0.33，而"防御措施"条件下略有改善，召回率范围从0.21到0.4。F1-score呈现类似趋势，在"无防御"下较低（0.3到0.46），但在"防御措施"下有所提高（0.33到0.55）。对于GHI攻击，"无防御"下的检测能力缺乏显而易见，因为所有的精确度、召回率和F1-score值均为零。然而，"防御措施"下，精确度较高（0.9到1.0），召回率范围从0.13到0.54，F1-score显著提高（0.21到0.65），特别是在较低的攻击率下。
- en: The analysis clearly demonstrates that defence mechanisms significantly enhance
    the performance of attack detection for both OMI and GHI attack types. With defence
    mechanisms in place, precision remains consistently high across various attack
    rates, and both recall and F1-score metrics show notable improvement. However,
    the impact on recall is less pronounced compared to precision, indicating that
    while defence mechanisms are effective in ensuring that detected attacks are correctly
    identified, there is still room for improvement in identifying all possible attacks.
    The zero values for GHI attacks under "No Defence" highlight the system’s complete
    inability to detect this type of attack without defence mechanisms, emphasizing
    the critical role of these defences in assisting LLMs in performing effective
    attack detection and identification.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 分析清楚地表明，防御机制显著提升了OMI和GHI攻击类型的检测性能。在防御机制到位的情况下，各种攻击率下的精确度保持一致的高水平，召回率和F1-score指标均有显著改善。然而，相较于精确度，召回率的改善较为有限，这表明虽然防御机制有效确保检测到的攻击被正确识别，但在识别所有可能的攻击方面仍有改进空间。GHI攻击在"无防御"下的零值突显了系统在没有防御机制的情况下对这种攻击类型的完全无法检测，强调了这些防御在协助LLMs有效检测和识别攻击中的关键作用。
- en: Performance
  id: totrans-141
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 性能
- en: Since CSI attacks cannot be identified by the LLM as mentioned in Section [V-D](#S5.SS4.SSS0.Px1
    "Attack Detection ‣ V-D Results and Analysis ‣ V Experiment ‣ A Study on Prompt
    Injection Attack Against LLM-Integrated Mobile Robotic Systems"), we analysed
    performance under OMI and GHI attacks only. Figure [6](#S5.F6 "Figure 6 ‣ V-C
    Overall Improvement Calculation ‣ V Experiment ‣ A Study on Prompt Injection Attack
    Against LLM-Integrated Mobile Robotic Systems") shows the performance metrics
    of MOER, token usage, and response time across different attack rates (0, 0.3,
    0.5, 0.7, 1.0) under "No Defence" and "Defence Applied" conditions. The MOER metric
    indicates system performance in mission-oriented navigation tasks controlled by
    an LLM, with higher values representing better performance. Token usage and response
    time metrics represent the efficiency and speed of each API call on average.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 CSI 攻击无法被 LLM 识别，如第 [V-D](#S5.SS4.SSS0.Px1 "Attack Detection ‣ V-D Results
    and Analysis ‣ V Experiment ‣ A Study on Prompt Injection Attack Against LLM-Integrated
    Mobile Robotic Systems") 节所述，我们仅分析了 OMI 和 GHI 攻击下的性能。图 [6](#S5.F6 "Figure 6 ‣
    V-C Overall Improvement Calculation ‣ V Experiment ‣ A Study on Prompt Injection
    Attack Against LLM-Integrated Mobile Robotic Systems") 显示了在 "无防御" 和 "应用防御" 条件下，不同攻击率（0,
    0.3, 0.5, 0.7, 1.0）的 MOER、令牌使用量和响应时间的性能指标。MOER 指标表示系统在由 LLM 控制的任务导向导航中的性能，值越高表示性能越好。令牌使用量和响应时间指标代表每次
    API 调用的效率和速度。
- en: For OMI attacks, the MOER metric under "No Defence" decreases as the attack
    rate increases, ranging from 0.5 to 0.13\. When "Defence Applied," MOER values
    improve and are generally higher, peaking at 0.67\. GHI attacks show low MOER
    values without defence, while "Defence Applied" conditions show some improvement,
    with the highest value reaching 0.48\. Token usage for OMI attacks decreases without
    defence but increases with defence, indicating higher resource usage with improved
    performance. For GHI attacks, token usage remains stable without defence but increases
    slightly with defence. Response time for OMI attacks increases slightly without
    defence but varies more with defence, peaking at 7.1 seconds. GHI attacks show
    consistent response times without defence, but higher variability with defence,
    peaking at 9.3 seconds.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 OMI 攻击，在 "无防御" 条件下，MOER 指标随着攻击率的增加而减少，从 0.5 降到 0.13。当 "应用防御" 时，MOER 值有所改善且普遍较高，峰值达到
    0.67。GHI 攻击在没有防御时 MOER 值较低，而 "应用防御" 条件下有所改善，最高值达到 0.48。OMI 攻击的令牌使用量在没有防御时减少，但在有防御时增加，表明在性能提升的同时资源使用增加。对于
    GHI 攻击，令牌使用量在没有防御时保持稳定，但有防御时略有增加。OMI 攻击的响应时间在没有防御时略有增加，但在有防御时变化更大，峰值达到 7.1 秒。GHI
    攻击在没有防御时响应时间保持一致，但在有防御时变异性较大，峰值达到 9.3 秒。
- en: The data suggests that defence mechanisms significantly enhance the performance
    of the system, particularly for OMI attacks, as indicated by higher MOER values.
    However, the increase in token usage and response time with defence mechanisms
    highlights a trade-off between improved performance and resource consumption.
    These findings underscore the importance of optimising defence strategies to balance
    robust attack detection with efficient system performance. For GHI attacks, while
    there is an improvement with defence, the performance gains are less pronounced,
    indicating a need for further optimisation in handling these attack types.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 数据表明，防御机制显著提高了系统性能，特别是对于 OMI 攻击，MOER 值较高。然而，随着防御机制的应用，令牌使用量和响应时间的增加突显了改进性能与资源消耗之间的权衡。这些发现强调了优化防御策略以平衡强大的攻击检测与高效系统性能的重要性。对于
    GHI 攻击，虽然防御有一定的改善，但性能提升不明显，表明需要进一步优化处理这些攻击类型的方式。
- en: Overall Improvement
  id: totrans-145
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 整体改进
- en: As shown in Section [V-C](#S5.SS3 "V-C Overall Improvement Calculation ‣ V Experiment
    ‣ A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems"),
    we calculated the weighted and overall improvements across various attack rates
    (0, 0.3, 0.5, 0.7, 1.0). This quantified the impact of defence mechanisms on attack
    detection and system performance, capturing the improvements and trade-offs involved.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如第 [V-C](#S5.SS3 "V-C Overall Improvement Calculation ‣ V Experiment ‣ A Study
    on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems") 节所示，我们计算了各种攻击率（0,
    0.3, 0.5, 0.7, 1.0）下的加权和整体改进。这量化了防御机制对攻击检测和系统性能的影响，捕捉了改进和权衡。
- en: Key metrics highlight system performance. The WPI is 51.9%, reflecting a significant
    reduction in false positives. The WRI stands at 28.1%, showing improved attack
    identification with room for enhancement. The WFI is 31.4%, indicating a better
    balance between precision and recall.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 关键指标突显了系统性能。WPI为51.9%，反映了假阳性的显著减少。WRI为28.1%，显示了攻击识别的改善，但仍有提升空间。WFI为31.4%，指示了精度和召回率之间的更好平衡。
- en: Further evaluation shows the WMI at 99.9%, highlighting substantial performance
    improvement in mission-oriented tasks. However, the WTU has increased by 2.9%,
    indicating higher resource consumption and the WRT has risen by 23.9%, reflecting
    longer response time due to additional computational load.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步评估显示WMI达到99.9%，突显了在任务导向操作中的显著性能提升。然而，WTU增加了2.9%，表示资源消耗增加，而WRT上升了23.9%，反映了由于额外计算负载导致的响应时间延长。
- en: Combining these metrics, the OADI is 37.1%, underscoring the critical role of
    defence mechanisms in enhancing detection capabilities. The OPI is 24.4%, showing
    meaningful performance gains despite trade-offs. The GI, representing overall
    improvement, is approximately 30.8%. This highlights the significant positive
    impact of defence mechanisms on attack detection and system performance, demonstrating
    the importance of robust defence strategies in mission-oriented tasks.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 综合这些指标，OADI为37.1%，强调了防御机制在提升检测能力中的关键作用。OPI为24.4%，显示了尽管存在权衡，但性能上有实质性提升。GI，代表总体改进，大约为30.8%。这突显了防御机制对攻击检测和系统性能的显著积极影响，展示了在任务导向操作中强健防御策略的重要性。
- en: VI Discussion
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VI 讨论
- en: VI-A Limitations of the Current Approach
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VI-A 当前方法的局限性
- en: While our approach demonstrates significant improvements, it has notable limitations.
    The WRI of 28.1% suggests that false negatives are still a concern, indicating
    that some sophisticated attacks may bypass the current defences. Additionally,
    the increases in resource consumption (WTU of 2.9%) and response time (WRT of
    23.9%) highlight the trade-off between enhanced detection capabilities and system
    performance, which may not be sustainable for systems with limited resources or
    real-time processing requirements.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们的方法展示了显著的改进，但也存在显著的局限性。28.1%的WRI表明假阴性仍然是一个问题，这意味着一些复杂的攻击可能绕过当前的防御。此外，资源消耗（WTU为2.9%）和响应时间（WRT为23.9%）的增加突显了在增强检测能力和系统性能之间的权衡，这可能对于资源有限或实时处理要求高的系统来说不可持续。
- en: VI-B Future Directions and Techniques for Exploration
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VI-B 未来的方向和探索技术
- en: 'To address these limitations, two key techniques can be explored:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些局限性，可以探索以下两种关键技术：
- en: '1\. Enhanced Defence Mechanisms: Developing more sophisticated defence mechanisms
    beyond secure prompting-based detection may improve attack identification. Techniques
    such as multi-layer detection frameworks can be utilised, incorporating both prompt-based
    and non-prompt-based strategies [[28](#bib.bib28), [29](#bib.bib29)].'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 增强的防御机制：开发比基于安全提示的检测更复杂的防御机制可能会改善攻击识别。可以利用多层检测框架等技术，结合提示基础和非提示基础的策略[[28](#bib.bib28),
    [29](#bib.bib29)]。
- en: '2\. Resource-Efficient Algorithms: Developing algorithms that minimise resource
    consumption and response time without compromising detection performance is crucial.
    Techniques like model pruning [[30](#bib.bib30)] and efficient neural architectures
    [[31](#bib.bib31)] can help achieve this, ensuring that the defence mechanisms
    remain effective even in resource-constrained environments.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 资源高效算法：开发能够在不影响检测性能的情况下最小化资源消耗和响应时间的算法至关重要。像模型剪枝[[30](#bib.bib30)]和高效神经架构[[31](#bib.bib31)]等技术可以帮助实现这一点，确保防御机制即使在资源受限的环境中也能保持有效。
- en: By focusing on these areas, we can improve the robustness and efficiency of
    the defence mechanisms, enhancing overall system security and performance.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 通过关注这些领域，我们可以提高防御机制的稳健性和效率，增强整体系统安全性和性能。
- en: VII Conclusion
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VII 结论
- en: This study explored the integration of LLMs into robotic systems, highlighting
    both advancements in multi-modal contextual awareness and the accompanying security
    challenges. Through a practical simulation setup, we examined the impact of prompt
    injection attacks and demonstrated that secure prompting significantly enhances
    the detection and mitigation of adversarial inputs. The results, showing an overall
    improvement of 30.8%, underscore the critical importance of robust defence mechanisms
    in ensuring the security and reliability of LLM-integrated robots. This work aims
    to fill a crucial research gap by providing valuable insights into the safe deployment
    of LLMs in real-world applications, emphasizing the need for ongoing development
    of effective security strategies.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究探讨了将大型语言模型（LLMs）集成到机器人系统中的情况，强调了多模态上下文感知的进展以及随之而来的安全挑战。通过实际模拟设置，我们检查了提示注入攻击的影响，并证明了安全提示显著增强了对抗性输入的检测和缓解。结果显示整体改进了30.8%，突显了强大防御机制在确保LLM集成机器人安全性和可靠性中的关键重要性。这项工作旨在填补一个关键的研究空白，通过提供有关LLM在实际应用中安全部署的宝贵见解，强调了继续开发有效安全策略的必要性。
- en: References
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] OpenAI, “OpenAI Vision Guide,” 2024, accessed: 2024-07-28\. [Online]. Available:
    [https://platform.openai.com/docs/guides/vision](https://platform.openai.com/docs/guides/vision)'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] OpenAI, “OpenAI 视觉指南，” 2024年，访问时间：2024-07-28\. [在线]. 可用： [https://platform.openai.com/docs/guides/vision](https://platform.openai.com/docs/guides/vision)'
- en: '[2] Y. Liu, W. Chen, Y. Bai, J. Luo, X. Song, K. Jiang, Z. Li, G. Zhao, J. Lin,
    G. Li *et al.*, “Aligning Cyber Space with Physical World: A Comprehensive Survey
    on Embodied AI,” *arXiv preprint arXiv:2407.06886*, 2024.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Y. Liu, W. Chen, Y. Bai, J. Luo, X. Song, K. Jiang, Z. Li, G. Zhao, J.
    Lin, G. Li *等*，“将网络空间与物理世界对齐：关于具身 AI 的综合调查，” *arXiv 预印本 arXiv:2407.06886*, 2024。'
- en: '[3] F. Shi, X. Chen, K. Misra, N. Scales, D. Dohan, E. H. Chi, N. Schärli,
    and D. Zhou, “Large Language Models Can Be Easily Distracted by Irrelevant Context,”
    in *International Conference on Machine Learning*.   PMLR, 2023, pp. 31 210–31 227.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] F. Shi, X. Chen, K. Misra, N. Scales, D. Dohan, E. H. Chi, N. Schärli,
    和 D. Zhou, “大型语言模型容易受到无关背景的干扰，” 在 *国际机器学习会议* 上。 PMLR, 2023, 第31 210–31 227页。'
- en: '[4] C. Wen, J. Liang, S. Yuan, H. Huang, and Y. Fang, “How Secure Are Large
    Language Models (LLMs) for Navigation in Urban Environments?” *arXiv preprint
    arXiv:2402.09546*, 2024.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] C. Wen, J. Liang, S. Yuan, H. Huang, 和 Y. Fang, “大型语言模型 (LLMs) 在城市环境中的导航安全性如何？”
    *arXiv 预印本 arXiv:2402.09546*, 2024。'
- en: '[5] Z. Xi, W. Chen, X. Guo, W. He, Y. Ding, B. Hong, M. Zhang, J. Wang, S. Jin,
    E. Zhou *et al.*, “The Rise and Potential of Large Language Model Based Agents:
    A Survey (2023),” *URL https://arxiv. org/abs/2309.07864*, 2023.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Z. Xi, W. Chen, X. Guo, W. He, Y. Ding, B. Hong, M. Zhang, J. Wang, S.
    Jin, E. Zhou *等*，“大型语言模型基础代理的崛起与潜力：调查报告（2023），” *URL https://arxiv.org/abs/2309.07864*,
    2023。'
- en: '[6] E. Latif, “3P-LLM: Probabilistic Path Planning using Large Language Model
    for Autonomous Robot Navigation,” *arXiv preprint arXiv:2403.18778*, 2024.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] E. Latif, “3P-LLM：使用大型语言模型进行自主机器人导航的概率路径规划，” *arXiv 预印本 arXiv:2403.18778*,
    2024。'
- en: '[7] G. Zhou, Y. Hong, and Q. Wu, “NavGPT: Explicit Reasoning in Vision-and-Language
    Navigation with Large Language Models,” in *Proceedings of the AAAI Conference
    on Artificial Intelligence*, vol. 38, no. 7, 2024, pp. 7641–7649.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] G. Zhou, Y. Hong, 和 Q. Wu, “NavGPT：使用大型语言模型进行视觉与语言导航的显式推理，” 在 *AAAI 人工智能会议论文集*
    上，第38卷，第7期，2024年，第7641–7649页。'
- en: '[8] S. Qiao, R. Fang, N. Zhang, Y. Zhu, X. Chen, S. Deng, Y. Jiang, P. Xie,
    F. Huang, and H. Chen, “Agent Planning with World Knowledge Model,” *arXiv preprint
    arXiv:2405.14205*, 2024.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] S. Qiao, R. Fang, N. Zhang, Y. Zhu, X. Chen, S. Deng, Y. Jiang, P. Xie,
    F. Huang, 和 H. Chen, “具有世界知识模型的代理规划，” *arXiv 预印本 arXiv:2405.14205*, 2024。'
- en: '[9] C. H. Song, J. Wu, C. Washington, B. M. Sadler, W.-L. Chao, and Y. Su,
    “LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language
    Models,” in *Proceedings of the IEEE/CVF International Conference on Computer
    Vision*, 2023, pp. 2998–3009.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] C. H. Song, J. Wu, C. Washington, B. M. Sadler, W.-L. Chao, 和 Y. Su, “LLM-Planner：基于大型语言模型的具身代理的少量样本基础规划，”
    在 *IEEE/CVF 国际计算机视觉会议论文集* 上，2023年，第2998–3009页。'
- en: '[10] T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and Y. Iwasawa, “Large Language
    Models are Zero-shot Reasoners,” *Advances in neural information processing systems*,
    vol. 35, pp. 22 199–22 213, 2022.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, 和 Y. Iwasawa, “大型语言模型是零样本推理器，”
    *神经信息处理系统进展*，第35卷，第22 199–22 213页，2022年。'
- en: '[11] Y. Ding, W. Fan, L. Ning, S. Wang, H. Li, D. Yin, T.-S. Chua, and Q. Li,
    “A Survey on RAG Meets LLMs: Towards Retrieval-Augmented Large Language Models,”
    *arXiv preprint arXiv:2405.06211*, 2024.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Y. Ding, W. Fan, L. Ning, S. Wang, H. Li, D. Yin, T.-S. Chua, 和 Q. Li，“关于
    RAG 与 LLMs 的调研：迈向检索增强的大型语言模型”，*arXiv 预印本 arXiv:2405.06211*，2024年。'
- en: '[12] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D. Zhou
    *et al.*, “Chain-of-Thought Prompting Elicits Reasoning in Large Language Models,”
    *Advances in neural information processing systems*, vol. 35, pp. 24 824–24 837,
    2022.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D.
    Zhou *等*，“链式思维提示引发大语言模型中的推理”，*神经信息处理系统进展*，第35卷，第24,824–24,837页，2022年。'
- en: '[13] Q. Wu, G. Bansal, J. Zhang, Y. Wu, S. Zhang, E. Zhu, B. Li, L. Jiang,
    X. Zhang, and C. Wang, “Autogen: Enabling Next-Gen LLM Applications via Multi-Agent
    Conversation Framework,” *arXiv preprint arXiv:2308.08155*, 2023.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Q. Wu, G. Bansal, J. Zhang, Y. Wu, S. Zhang, E. Zhu, B. Li, L. Jiang,
    X. Zhang, 和 C. Wang，“Autogen：通过多智能体对话框架启用下一代 LLM 应用”，*arXiv 预印本 arXiv:2308.08155*，2023年。'
- en: '[14] J. V. D. Ham, “Toward a Better Understanding of “Cybersecurity”,” *Digital
    Threats: Research and Practice*, vol. 2, no. 3, pp. 1–3, 2021.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] J. V. D. Ham，“朝着更好理解‘网络安全’的方向前进”，*数字威胁：研究与实践*，第2卷，第3期，第1–3页，2021年。'
- en: '[15] Z. Deng, Y. Guo, C. Han, W. Ma, J. Xiong, S. Wen, and Y. Xiang, “AI Agents
    Under Threat: A Survey of Key Security Challenges and Future Pathways,” 2024.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Z. Deng, Y. Guo, C. Han, W. Ma, J. Xiong, S. Wen, 和 Y. Xiang，“面临威胁的 AI
    代理：关键安全挑战和未来路径的调研”，2024年。'
- en: '[16] F. Perez and I. Ribeiro, “Ignore Previous Prompt: Attack Techniques for
    Language Models,” *arXiv preprint arXiv:2211.09527*, 2022.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] F. Perez 和 I. Ribeiro，“忽略先前提示：语言模型的攻击技术”，*arXiv 预印本 arXiv:2211.09527*，2022年。'
- en: '[17] P. Levi and C. P. Neumann, “Vocabulary Attack to Hijack Large Language
    Model Applications,” *arXiv preprint arXiv:2404.02637*, 2024.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] P. Levi 和 C. P. Neumann，“词汇攻击劫持大型语言模型应用”，*arXiv 预印本 arXiv:2404.02637*，2024年。'
- en: '[18] Y. Zhang, N. Carlini, and D. Ippolito, “Effective Prompt Extraction from
    Language Models,” *arXiv preprint arXiv:2307.06865*, 2024.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Y. Zhang, N. Carlini, 和 D. Ippolito，“从语言模型中有效提取提示”，*arXiv 预印本 arXiv:2307.06865*，2024年。'
- en: '[19] Y. Liu, G. Deng, Z. Xu, Y. Li, Y. Zheng, Y. Zhang, L. Zhao, T. Zhang,
    K. Wang, and Y. Liu, “Jailbreaking ChatGPT via Prompt Engineering: An Empirical
    Study,” *arXiv preprint arXiv:2305.13860*, 2023.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Y. Liu, G. Deng, Z. Xu, Y. Li, Y. Zheng, Y. Zhang, L. Zhao, T. Zhang,
    K. Wang, 和 Y. Liu，“通过提示工程破解 ChatGPT：一项实证研究”，*arXiv 预印本 arXiv:2305.13860*，2023年。'
- en: '[20] K. Greshake, S. Abdelnabi, S. Mishra, C. Endres, T. Holz, and M. Fritz,
    “Not what you’ve signed up for: Compromising Real-World LLM-Integrated Applications
    with Indirect Prompt Injection,” in *Proceedings of the 16th ACM Workshop on Artificial
    Intelligence and Security*, 2023, pp. 79–90.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] K. Greshake, S. Abdelnabi, S. Mishra, C. Endres, T. Holz, 和 M. Fritz，“不是你所报名的：通过间接提示注入破坏现实世界
    LLM 集成应用”，在*第16届 ACM 人工智能与安全研讨会论文集*中，2023年，第79–90页。'
- en: '[21] C. Tony, N. E. D. Ferreyra, M. Mutas, S. Dhiff, and R. Scandariato, “Prompting
    Techniques for Secure Code Generation: A Systematic Investigation,” *arXiv preprint
    arXiv:2407.07064*, 2024.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] C. Tony, N. E. D. Ferreyra, M. Mutas, S. Dhiff, 和 R. Scandariato，“安全代码生成的提示技术：系统研究”，*arXiv
    预印本 arXiv:2407.07064*，2024年。'
- en: '[22] Y. Liu, Y. Jia, R. Geng, J. Jia, and N. Z. Gong, “Formalizing and Benchmarking
    Prompt Injection Attacks and Defenses,” 2024.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Y. Liu, Y. Jia, R. Geng, J. Jia, 和 N. Z. Gong，“正式化和基准测试提示注入攻击及防御”，2024年。'
- en: '[23] N. Jain, A. Schwarzschild, Y. Wen, G. Somepalli, J. Kirchenbauer, P.-y.
    Chiang, M. Goldblum, A. Saha, J. Geiping, and T. Goldstein, “Baseline Defenses
    for Adversarial Attacks Against Aligned Language Models,” *arXiv preprint arXiv:2309.00614*,
    2023.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] N. Jain, A. Schwarzschild, Y. Wen, G. Somepalli, J. Kirchenbauer, P.-y.
    Chiang, M. Goldblum, A. Saha, J. Geiping, 和 T. Goldstein，“对齐语言模型的基线防御方法”，*arXiv
    预印本 arXiv:2309.00614*，2023年。'
- en: '[24] G. Alon and M. Kamfonas, “Detecting Language Model Attacks with Perplexity,”
    *arXiv preprint arXiv:2308.14132*, 2023.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] G. Alon 和 M. Kamfonas，“通过困惑度检测语言模型攻击”，*arXiv 预印本 arXiv:2308.14132*，2023年。'
- en: '[25] S. Armstrong and R. Gorman, “Using GPT-Eliezer Against ChatGPT Jailbreaking,”
    in *AI ALIGNMENT FORUM*, 2022.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] S. Armstrong 和 R. Gorman，“使用 GPT-Eliezer 对抗 ChatGPT 破解”，在*AI ALIGNMENT
    FORUM*中，2022年。'
- en: '[26] P. Bhandari, “A Survey on Prompting Techniques in LLMs,” *arXiv preprint
    arXiv:2312.03740*, 2024.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] P. Bhandari，“关于 LLMs 中提示技术的调研”，*arXiv 预印本 arXiv:2312.03740*，2024年。'
- en: '[27] T. Bräunl, *Mobile Robot Programming: Adventures in Python and C*.   Springer
    International Publishing, 2023.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] T. Bräunl，*移动机器人编程：Python 和 C 的冒险*。施普林格国际出版社，2023年。'
- en: '[28] P. Rai, S. Sood, V. K. Madisetti, and A. Bahga, “Guardian: A Multi-Tiered
    Defense Architecture for Thwarting Prompt Injection Attacks on LLMs,” *Journal
    of Software Engineering and Applications*, vol. 17, no. 1, pp. 43–68, 2024.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] P. Rai, S. Sood, V. K. Madisetti 和 A. Bahga，"Guardian: 一种多层次防御架构以抵御对大型语言模型的提示注入攻击"，*软件工程与应用期刊*，第
    17 卷，第 1 期，页码 43–68，2024年。'
- en: '[29] R. K. Sharma, V. Gupta, and D. Grossman, “Defending Language Models Against
    Image-Based Prompt Attacks via User-Provided Specifications,” in *2024 IEEE Security
    and Privacy Workshops (SPW)*.   IEEE, 2024, pp. 112–131.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] R. K. Sharma, V. Gupta 和 D. Grossman，"通过用户提供的规格防御基于图像的提示攻击"，发表于 *2024
    IEEE 安全与隐私研讨会（SPW）*。IEEE，2024年，页码 112–131。'
- en: '[30] H. Jiang, Y. Li, C. Zhang, Q. Wu, X. Luo, S. Ahn, Z. Han, A. H. Abdi,
    D. Li, C.-Y. Lin, Y. Yang, and L. Qiu, “MInference 1.0: Accelerating Pre-filling
    for Long-Context LLMs via Dynamic Sparse Attention,” *arXiv preprint arXiv:2407.02490*,
    2024.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] H. Jiang, Y. Li, C. Zhang, Q. Wu, X. Luo, S. Ahn, Z. Han, A. H. Abdi,
    D. Li, C.-Y. Lin, Y. Yang 和 L. Qiu，"MInference 1.0: 通过动态稀疏注意力加速长上下文大型语言模型的预填充"，*arXiv
    预印本 arXiv:2407.02490*，2024年。'
- en: '[31] Z. Wang and Z. Ma and X. Feng and R. Sun and H. Wang and M. Xue and G.
    Bai, “Corelocker: Neuron-level usage control,” in *2024 IEEE Symposium on Security
    and Privacy (SP)*.   Los Alamitos, CA, USA: IEEE Computer Society, may 2024, pp.
    222–222\. [Online]. Available: [https://doi.ieeecomputersociety.org/10.1109/SP54263.2024.00233](https://doi.ieeecomputersociety.org/10.1109/SP54263.2024.00233)'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Z. Wang, Z. Ma, X. Feng, R. Sun, H. Wang, M. Xue 和 G. Bai，"Corelocker:
    神经元级别使用控制"，发表于 *2024 IEEE 安全与隐私研讨会（SP）*。洛杉矶，加州，美国：IEEE 计算机学会，2024年5月，页码 222–222。
    [在线]。可用链接：[https://doi.ieeecomputersociety.org/10.1109/SP54263.2024.00233](https://doi.ieeecomputersociety.org/10.1109/SP54263.2024.00233)'
