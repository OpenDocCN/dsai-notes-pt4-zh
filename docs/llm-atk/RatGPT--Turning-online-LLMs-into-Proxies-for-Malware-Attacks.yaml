- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:47:20'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:47:20
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'RatGPT: Turning online LLMs into Proxies for Malware Attacks'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RatGPT：将在线大型语言模型转化为恶意软件攻击的代理
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2308.09183](https://ar5iv.labs.arxiv.org/html/2308.09183)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2308.09183](https://ar5iv.labs.arxiv.org/html/2308.09183)
- en: \acmArticleType
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \acmArticleType
- en: Research
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 研究
- en: Mika Beckerich [beckerichmika@protonmail.com](mailto:beckerichmika@protonmail.com)
    Luxembourg Tech School asblLuxembourg ,  Laura Plein [laura.plein@men.lu](mailto:laura.plein@men.lu)
    Luxembourg Tech School asblLuxembourg  and  Sergio Coronado [sergio.coronadoarrechedera@men.lu](mailto:sergio.coronadoarrechedera@men.lu)
    Luxembourg Tech School asblLuxembourg(2018)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Mika Beckerich [beckerichmika@protonmail.com](mailto:beckerichmika@protonmail.com)
    卢森堡技术学校asbl卢森堡，Laura Plein [laura.plein@men.lu](mailto:laura.plein@men.lu) 卢森堡技术学校asbl卢森堡，以及
    Sergio Coronado [sergio.coronadoarrechedera@men.lu](mailto:sergio.coronadoarrechedera@men.lu)
    卢森堡技术学校asbl卢森堡（2018）
- en: Abstract.
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: The evolution of Generative AI and the capabilities of the newly released Large
    Language Models (LLMs) open new opportunities in software engineering. However,
    they also lead to new challenges in cybersecurity. Recently, researchers have
    shown the possibilities of using LLMs such as ChatGPT to generate malicious content
    that can directly be exploited or guide inexperienced hackers to weaponize tools
    and code. These studies covered scenarios that still require the attacker to be
    in the middle of the loop. In this study, we leverage openly available plugins
    and use an LLM as proxy between the attacker and the victim. We deliver a proof-of-concept
    where ChatGPT is used for the dissemination of malicious software while evading
    detection, alongside establishing the communication to a command and control (C2)
    server to receive commands to interact with a victim’s system. Finally, we present
    the general approach as well as essential elements in order to stay undetected
    and make the attack a success. This proof-of-concept highlights significant cybersecurity
    issues with openly available plugins and LLMs, which require the development of
    security guidelines, controls, and mitigation strategies.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI的发展以及新发布的大型语言模型（LLMs）的能力为软件工程开辟了新的机遇。然而，这也带来了网络安全的新挑战。最近，研究人员展示了使用LLMs（如ChatGPT）生成恶意内容的可能性，这些内容可以直接被利用或指导缺乏经验的黑客利用工具和代码进行武器化。这些研究涵盖了仍然需要攻击者在环中的场景。在本研究中，我们利用开放的插件，使用LLM作为攻击者和受害者之间的代理。我们提供了一个概念验证，其中ChatGPT用于传播恶意软件，同时规避检测，并建立与指挥与控制（C2）服务器的通信，以接收与受害者系统交互的命令。最后，我们展示了保持隐蔽和确保攻击成功的一般方法以及关键要素。这一概念验证突显了开放插件和LLMs存在的重大网络安全问题，这需要制定安全指南、控制措施和缓解策略。
- en: 'ChatGPT, Cybersecurity, Command and control^†^†copyright: acmcopyright^†^†journalyear:
    2018^†^†doi: XXXXXXX.XXXXXXX^†^†journal: JDS^†^†journalvolume: 37^†^†journalnumber:
    4^†^†article: 111^†^†publicationmonth: 8'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT，网络安全，指挥与控制^†^†版权：acmcopyright^†^†期刊年份：2018^†^†doi：XXXXXXX.XXXXXXX^†^†期刊：JDS^†^†期刊卷号：37^†^†期刊期号：4^†^†文章：111^†^†发表月份：8
- en: 1\. Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 引言
- en: Recent advances in natural language processing techniques have enabled the development
    of large language models (LLMs) such as ChatGPT (Brown et al., [2020](#bib.bib3)).
    Off-the-shelf LLMs as a service, have led to various promising results in the
    software engineering community. Generative models such as ChatGPT, Google Bard,
    Llama (Touvron et al., [2023](#bib.bib18)), etc. have achieved or even exceeded
    state-of-the-art performance on tasks such as code summarisation (Allamanis et al.,
    [2018](#bib.bib2); Hu et al., [2018](#bib.bib13)), code translation (Lu et al.,
    [2021](#bib.bib16); Bui et al., [2023](#bib.bib5)) or program synthesis (Gulwani
    et al., [2017](#bib.bib11)). While ChatGPT has shown clear benefits for the software
    development process, ChatGPT’s easy-to-use API also provides new possibilities
    to generate and propagate malware. Thus, ChatGPT can easily go from being a friendly
    developer tool to ThreatGPT as described by Gupta et al. (Gupta et al., [2023](#bib.bib12)).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，自然语言处理技术的进步使得开发大语言模型（LLMs）如ChatGPT（Brown et al., [2020](#bib.bib3)）成为可能。现成的大语言模型服务在软件工程社区中取得了各种有前景的结果。生成模型如ChatGPT、Google
    Bard、Llama（Touvron et al., [2023](#bib.bib18)）等，在代码总结（Allamanis et al., [2018](#bib.bib2);
    Hu et al., [2018](#bib.bib13)）、代码翻译（Lu et al., [2021](#bib.bib16); Bui et al.,
    [2023](#bib.bib5)）或程序合成（Gulwani et al., [2017](#bib.bib11)）等任务上已实现或甚至超越了最先进的性能。虽然ChatGPT在软件开发过程中显示出了明显的好处，但ChatGPT易于使用的API也提供了生成和传播恶意软件的新可能性。因此，ChatGPT很容易从一个友好的开发工具变成ThreatGPT，如Gupta
    et al.（Gupta et al., [2023](#bib.bib12)）所描述的。
- en: Whereas OpenAI provides some countermeasures (Brundage et al., [2022](#bib.bib4))
    to prevent the misuse of their services, users still manage to create so-called
    ”jailbreaks” (Liu et al., [2023](#bib.bib15)) to prompt ChatGPT to produce potentially
    malicious or exploitable content. The new ChatGPT plugins open up multiple use
    cases for integrating different online services in a chat-style user interaction.
    This brings new benefits to businesses and customers by improving the overall
    user experience of online services. However, by having ChatGPT integrated and
    accessible from anywhere through an overwhelming number of plugins created daily,
    it becomes almost impossible to track and secure all plugins.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管OpenAI提供了一些对策（Brundage et al., [2022](#bib.bib4)）以防止其服务被滥用，用户仍然能够创造所谓的“越狱”程序（Liu
    et al., [2023](#bib.bib15)），以促使ChatGPT生成潜在的恶意或可被利用的内容。新的ChatGPT插件为集成不同在线服务提供了多种使用场景。这通过提升在线服务的整体用户体验，为企业和客户带来了新的好处。然而，由于ChatGPT通过每日创建的大量插件在任何地方都能访问，这使得追踪和保护所有插件几乎变得不可能。
- en: In this paper, we investigate if the openly available plugins could be misused
    as an attack vector to web users. For this proof-of-concept, we use ChatGPT with
    a plugin as a proxy between a client (victim) and a web service controlled by
    an attacker, which looks seemingly legitimate to the user. We establish remote
    control between our victim and the attacker through ChatGPT, resulting in a Remote
    Access Trojan (RatGPT). Currently, many intrusion detection systems (IDS) can
    detect connections established between a victim and the attacker if there is no
    intermediate legitimate service acting as a proxy. In this study, we are able
    to simulate an attack without getting detected by those detection systems, since
    connections to an LLM are widely considered legitimate.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们探讨了公开可用的插件是否可能被滥用作为攻击向量来针对网络用户。为了证明这一概念，我们使用了一个插件的ChatGPT作为客户端（受害者）和由攻击者控制的网络服务之间的代理，这对用户看似合法。我们通过ChatGPT在受害者和攻击者之间建立了远程控制，形成了一个远程访问木马（RatGPT）。目前，许多入侵检测系统（IDS）可以检测受害者和攻击者之间建立的连接，前提是没有合法的中间服务充当代理。在这项研究中，我们能够模拟一个攻击而不被这些检测系统发现，因为连接到大语言模型（LLM）被广泛认为是合法的。
- en: Additionally, this proof-of-concept demonstrates the feasibility of performing
    an attack without leaving traces on the victim’s machine that could point directly
    to the attacker, since there is no direct communication, and the payload resides
    in memory. Further, the IP addresses, as well as the malicious payload, get generated
    by ChatGPT on the fly, bypassing many malware scanners. With this paper, we aim
    to raise awareness of the potential misuse of openly available LLMs in combination
    with plugins, as they provide a new range of attack surfaces.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，这一概念验证展示了在不留下直接指向攻击者的痕迹的情况下进行攻击的可行性，因为没有直接通信，并且负载驻留在内存中。此外，IP地址以及恶意负载由ChatGPT即时生成，从而绕过了许多恶意软件扫描器。通过这篇论文，我们旨在提高对公开可用的LLMs与插件组合潜在滥用的认识，因为它们提供了一系列新的攻击面。
- en: 'The remainder of this paper is divided into Section [2](#S2 "2\. Approach ‣
    RatGPT: Turning online LLMs into Proxies for Malware Attacks"), which details
    the approach used for this proof-of-concept. Section [3](#S3 "3\. Proof of Concept
    ‣ RatGPT: Turning online LLMs into Proxies for Malware Attacks") then describes
    the potential of our attack simulation and its consequences. Further, the limitations,
    further extensions, and possible mitigation strategies are introduced in Section [4](#S4
    "4\. Discussion ‣ RatGPT: Turning online LLMs into Proxies for Malware Attacks")
    and related work will be enumerated in Section [5](#S5 "5\. Related Work ‣ RatGPT:
    Turning online LLMs into Proxies for Malware Attacks") before we conclude our
    work in Section [6](#S6 "6\. Conclusion ‣ RatGPT: Turning online LLMs into Proxies
    for Malware Attacks").'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '本文的其余部分分为第[2](#S2 "2\. Approach ‣ RatGPT: Turning online LLMs into Proxies
    for Malware Attacks")节，详细介绍了用于此概念验证的方法。第[3](#S3 "3\. Proof of Concept ‣ RatGPT:
    Turning online LLMs into Proxies for Malware Attacks")节描述了我们攻击模拟的潜力及其后果。此外，第[4](#S4
    "4\. Discussion ‣ RatGPT: Turning online LLMs into Proxies for Malware Attacks")节介绍了局限性、进一步的扩展和可能的缓解策略，第[5](#S5
    "5\. Related Work ‣ RatGPT: Turning online LLMs into Proxies for Malware Attacks")节将列举相关工作，然后在第[6](#S6
    "6\. Conclusion ‣ RatGPT: Turning online LLMs into Proxies for Malware Attacks")节总结我们的工作。'
- en: 'The main contributions of this study are the following:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究的主要贡献如下：
- en: •
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Fully executable and automated pipeline: The main contribution consists of
    building a fully executable and automated command and control pipeline leveraging
    publicly available LLMs and plugins.'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 完全可执行和自动化的管道：主要贡献在于构建一个完全可执行和自动化的命令与控制管道，利用公开可用的LLMs和插件。
- en: •
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Feasibility study: The proof-of-concept proved the feasibility of using a pipeline
    to compromise a victim’s machine and execute shell commands sent to the victim
    over the LLM.'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可行性研究：概念验证证明了利用管道来攻陷受害者的计算机并执行通过LLM发送的Shell命令的可行性。
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Passive attack: For the attack to be successful, the victim only needs to execute
    a seemingly harmless executable. Afterward, all prompts and communication are
    executed automatically without the need for the victim to send prompts. This feature
    clearly distinguishes this work from previous indirect prompt injections.'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 被动攻击：为了使攻击成功，受害者只需要执行一个看似无害的可执行文件。之后，所有的提示和通信都将自动执行，无需受害者发送提示。这一特点明显将本工作与之前的间接提示注入区分开来。
- en: 2\. Approach
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 方法
- en: 'The goal is to show the feasibility of a harmless executable that can autonomously
    bootstrap and weaponize itself with LLM-generated code and communicate with the
    Command and Control (C2) server of an attacker by using web-accessible plugins
    of certain LLMs as a proxy. In this section, we outline the system’s main components.
    Prior to this experimental design, we need to define ”vulnerable” plugins. In
    our approach, first, we discuss ”[Prompt Initialisation](#S2.SS2 "In 2\. Approach
    ‣ RatGPT: Turning online LLMs into Proxies for Malware Attacks"),” where we tried
    to set up the LLM to be less restrictive for the system to function properly.
    Next, we explore ”[IP Address Generation](#S2.SS3 "In 2\. Approach ‣ RatGPT: Turning
    online LLMs into Proxies for Malware Attacks"),” explaining how we generated the
    IP address the payload connects to via ChatGPT. Then, we look at [Payload Generation](#S2.SS4
    "In 2\. Approach ‣ RatGPT: Turning online LLMs into Proxies for Malware Attacks"),
    where we explain how the payload itself is generated to weaponize the initially
    harmless executable the victim executes. Lastly, we look at ”[Communication with
    the C2 Server](#S2.SS5 "In 2\. Approach ‣ RatGPT: Turning online LLMs into Proxies
    for Malware Attacks"),” describing how different parts of the system communicate
    with each other to demonstrate the use of ChatGPT as a proxy between the victim
    and the attacker. These main features of this demonstration, are detailed in the
    following chapters.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '目标是展示一种无害的可执行文件如何能够自主引导和武器化自身，并通过使用某些 LLM 的网络访问插件作为代理，与攻击者的命令与控制（C2）服务器进行通信。在本节中，我们概述了系统的主要组件。在这个实验设计之前，我们需要定义“易受攻击”的插件。在我们的方法中，首先，我们讨论“[提示初始化](#S2.SS2
    "在 2\. 方法 ‣ RatGPT: 将在线 LLM 转变为恶意软件攻击的代理")”，在这里我们尝试设置 LLM 使系统能够正常运行。接下来，我们探讨“[IP
    地址生成](#S2.SS3 "在 2\. 方法 ‣ RatGPT: 将在线 LLM 转变为恶意软件攻击的代理")”，解释我们如何通过 ChatGPT 生成与有效负载连接的
    IP 地址。然后，我们查看[有效负载生成](#S2.SS4 "在 2\. 方法 ‣ RatGPT: 将在线 LLM 转变为恶意软件攻击的代理")，解释有效负载本身是如何生成的，以武器化最初的无害可执行文件。最后，我们查看“[与
    C2 服务器的通信](#S2.SS5 "在 2\. 方法 ‣ RatGPT: 将在线 LLM 转变为恶意软件攻击的代理")”，描述系统的不同部分如何相互通信，以展示
    ChatGPT 作为受害者与攻击者之间的代理的使用。这些演示的主要特征将在以下章节中详细说明。'
- en: 2.1\. Plugin Vulnerability Criteria
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1\. 插件易受攻击标准
- en: 'For this study, we will only define a plugin as ”vulnerable” for this attack,
    only if it fulfils the following criteria:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这项研究，我们仅将一个插件定义为“易受攻击”，如果它符合以下标准：
- en: (1)
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: Be able to browse the web.
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 能够浏览网页。
- en: (2)
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: Be able to go to any user-specified URL.
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 能够访问任何用户指定的 URL。
- en: While we specifically used plugins that access and process the content of a
    web page (e.g., summarise, extract keywords, etc.), modifying the attack to use
    plugins that read the contents of specific file types hosted on web servers (e.g.,
    PDF files) should be trivial. In that case, the attacker needs to store the commands
    in these file types, which are then read by the plugins.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们具体使用了访问和处理网页内容的插件（例如，总结、提取关键词等），但将攻击方式修改为使用读取托管在网络服务器上的特定文件类型（例如 PDF 文件）内容的插件应该是微不足道的。在这种情况下，攻击者需要将命令存储在这些文件类型中，然后由插件读取这些文件。
- en: 2.2\. Prompt Initialisation
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2\. 提示初始化
- en: Many public LLMs, such as OpenAI (Brundage et al., [2022](#bib.bib4)), have
    implemented safeguards, to detect to some degree, if a supplied prompt is intended
    to be used for harmful purposes. Therefore, we needed to trick these systems into
    allowing potentially harmful prompts to be evaluated anyway, commonly known as
    ”jailbreaking.” In this implementation, we opted to use a modified version of
    the DAN jailbreak (LeaderbotX400, [[n. d.]](#bib.bib14)), which only outputs the
    DAN version of its response and surrounds text that is not code with `"""`. This
    step is necessary since the code generated by the LLMs is evaluated using the
    `exec()` function in Python, which does not allow non-Python keywords in its input.
    Surrounding the text with `"""` effectively creates code comments, which the interpreter
    ignores.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 许多公共的 LLM（如 OpenAI (Brundage 等，[2022](#bib.bib4)）已经实施了防护措施，以在一定程度上检测提供的提示是否旨在用于有害目的。因此，我们需要欺骗这些系统，使其允许评估潜在的有害提示，通常称为“越狱”。在这个实现中，我们选择使用
    DAN 越狱的修改版 (LeaderbotX400, [[n. d.]](#bib.bib14))，它只输出 DAN 版本的响应，并将非代码的文本用 `"""`
    包围。这个步骤是必要的，因为 LLM 生成的代码是通过 Python 的 `exec()` 函数进行评估的，该函数不允许输入中包含非 Python 关键字。用
    `"""` 包围文本有效地创建了代码注释，解释器会忽略这些注释。
- en: 2.3\. IP Address Generation
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3\. IP 地址生成
- en: To avoid hard-coding the IP address of the C2 server inside the payload to counter
    naive string analysis approaches to extract critical malware properties, the IP
    address is generated dynamically with the help of the LLM. The individual parts
    of the IP address in dotted-decimal notation are generated with individual prompts
    and are concatenated in the end. Initial tests were conducted to generate the
    individual parts with mathematical prompts.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免在有效载荷中硬编码C2服务器的IP地址，以对抗简单的字符串分析方法提取关键恶意软件属性，IP地址使用LLM动态生成。IP地址的各个部分以点分十进制表示法生成，并最终连接在一起。最初的测试是用数学提示词生成各个部分。
- en: 'What is the 10th value of the
    Fibonacci Sequence? Expected: 34 Generated (multiple
    attempts): 47 38 39 21'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 'What is the 10th value of the
    Fibonacci Sequence? Expected: 34 Generated (multiple
    attempts): 47 38 39 21'
- en: However, the answer generated was not deterministic and considered too unreliable.
    Therefore, experiments using historical facts were conducted.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，生成的答案并不确定，被认为过于不可靠。因此，进行了使用历史事实的实验。
- en: 'In what year was the neutron
    discovered? Expected: 1932 Generated: 1932'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 'In what year was the neutron
    discovered? Expected: 1932 Generated: 1932'
- en: This proved to be very stable and is currently the method in use. To extract
    the numbers from the output produced by ChatGPT, the prompt had to be adjusted
    such that ChatGPT returns only the numbers. However, in some cases, the DAN-jailbreak
    still added its name to the output, which we filtered using Python string manipulation.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这被证明非常稳定，并且目前正在使用这种方法。为了从ChatGPT生成的输出中提取数字，必须调整提示词，使ChatGPT只返回数字。然而，在某些情况下，DAN-jailbreak仍然将其名字添加到输出中，我们使用Python字符串操作进行了过滤。
- en: 2.4\. Payload Generation
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4\. 有效载荷生成
- en: '![Refer to caption](img/a726a94ed44ff1056236ed7702aa0064.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/a726a94ed44ff1056236ed7702aa0064.png)'
- en: Figure 1\. Payload generation flow.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图1\. 有效载荷生成流程。
- en: In the current version, a victim receives a seemingly innocent executable and
    attempts to execute it. When the executable is run, multiple prompts are generated
    and sent to a public LLM. These prompts include instructions on how to build the
    IP address of the C2 server, how to generate Python code for the functions the
    payload should respond to (e.g., shell command execution, uploading/downloading
    files, listing the files in the current working directory, etc.), and how to set
    up the connection to the C2 server. The responses from the LLM are then combined
    and evaluated by the interpreter using the `exec()` function. Consequently, the
    executable has been weaponized with external code that resides in memory and can
    now establish a connection to the C2 server and evaluate commands received from
    it. Another characteristic of this approach is that we effectively created in-memory
    malware, which is harder to analyse by static analysis methods.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前版本中，受害者接收到一个看似无害的可执行文件并尝试执行。当可执行文件运行时，会生成多个提示词并发送给一个公共LLM。这些提示词包括如何构建C2服务器的IP地址、如何生成Python代码以响应有效载荷的功能（例如，执行shell命令、上传/下载文件、列出当前工作目录中的文件等），以及如何建立与C2服务器的连接。LLM的响应随后由解释器使用`exec()`函数结合和评估。因此，该可执行文件已经被武器化，具有驻留在内存中的外部代码，现在可以建立与C2服务器的连接并评估从中接收到的命令。这种方法的另一个特点是，我们有效地创建了内存中的恶意软件，这使得静态分析方法更难以分析。
- en: 2.5\. Communication with the C2 Server
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.5\. 与C2服务器的通信
- en: '![Refer to caption](img/ce40aa55ac73b25abe54ec22d9e0b950.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/ce40aa55ac73b25abe54ec22d9e0b950.png)'
- en: Figure 2\. Payload execution and communication flow.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图2\. 有效载荷执行和通信流程。
- en: In the first version, we wanted to make use of the web connectivity exposed
    by ChatGPT on GPT-4, which can be used to get content from any user-supplied URL
    as demonstrated by Greshake et al. (Greshake et al., [2023](#bib.bib10)), where
    the response could be controlled by modifying the website’s content, which the
    attacker controls when visited by the LLM. Using this functionality, the payload
    could communicate with the C2 server by crafting prompts for ChatGPT to query
    information from the attacker-controlled web server. Since only HTTP GET requests
    are possible, the query has to be encoded in the URL path. However, OpenAI deactivated
    its web browsing feature at the beginning of July, closing this opportunity.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个版本中，我们希望利用GPT-4中ChatGPT暴露的网络连接功能，这可以用来获取任何用户提供的URL中的内容，正如Greshake等人所示（Greshake
    et al., [2023](#bib.bib10)），其中响应可以通过修改网站内容来控制，而该内容由攻击者控制，当LLM访问时。利用这一功能，可以通过为ChatGPT设计提示词，使其从攻击者控制的网页服务器查询信息，从而使有效载荷与C2服务器通信。由于仅支持HTTP
    GET请求，因此查询必须编码在URL路径中。然而，OpenAI在7月初停用了其网页浏览功能，关闭了这一机会。
- en: Since the introduction of ”plugins”, users can access and interact with third-party
    information and services through ChatGPT. While many plugins are specific to their
    services, very few plugins are capable of browsing the web by themselves. Using
    such web browsing plugins, we can access any user-defined website, including a
    C2 web server, that receives and sends commands to active payloads.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 自“插件”引入以来，用户可以通过 ChatGPT 访问和互动第三方信息和服务。虽然许多插件专门用于其服务，但只有极少数插件能够自行浏览网页。使用这些网页浏览插件，我们可以访问任何用户定义的网站，包括接收和发送命令到活动有效负载的
    C2 网络服务器。
- en: '[Figure 2](#S2.F2 "Figure 2 ‣ 2.5\. Communication with the C2 Server ‣ 2\.
    Approach ‣ RatGPT: Turning online LLMs into Proxies for Malware Attacks") summarises
    the main steps that happen during the execution of the executable. When the victim
    executes the harmless payload, it gets weaponized by LLM-generated code as described
    in [subsection 2.4](#S2.SS4 "2.4\. Payload Generation ‣ 2\. Approach ‣ RatGPT:
    Turning online LLMs into Proxies for Malware Attacks"). This payload periodically
    sends website lookup requests to the LLM web connectivity feature (in the case
    of ChatGPT, plugins can browse the web) in the form of prompts (e.g. ”What are
    the news on http://attacker_address/ ?”). The web connectivity feature browses
    to the website supplied in the prompt and reads the content, which might contain
    a command that the attacker wrote on this website. This result gets returned as
    a response to the query to the victim’s executable. The weaponized executable
    .interprets the command and executes the corresponding handler associated with
    it. When a victim’s executable wants to transmit information back to the attacker,
    it can perform another query to the LLM by appending the data (either encoded
    in Base64 or ASCII) to the URL (e.g., ”What are the news on http://attacker_address/ZXh0cmFjdGVkX2RhdGEK
    ?”, where ZXh0cmFjdGVkX2RhdGEK is ”extracted_data” encoded in Base64). To further
    hide the malicious part of the web server, an internal list can be created that
    contains valid user agents that the plugins use to browse the malicious website.
    Consequently, the web server can present a different website and appear innocent
    if the user agent of a web browser does not match the user agent of a plugin.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 2](#S2.F2 "图 2 ‣ 2.5. 与 C2 服务器的通信 ‣ 2. 方法 ‣ RatGPT: 将在线 LLM 转换为恶意软件攻击的代理")
    总结了在可执行文件执行过程中发生的主要步骤。当受害者执行无害的有效负载时，它会被 LLM 生成的代码武器化，如 [第 2.4 节](#S2.SS4 "2.4.
    有效负载生成 ‣ 2. 方法 ‣ RatGPT: 将在线 LLM 转换为恶意软件攻击的代理") 所述。这些有效负载会定期向 LLM 网络连接功能（在 ChatGPT
    的情况下，插件可以浏览网页）发送网站查询请求（例如：“http://attacker_address/ 上有什么新闻？”）。网络连接功能浏览提示中提供的网站并读取内容，这可能包含攻击者在该网站上编写的命令。结果作为响应返回给受害者的可执行文件。被武器化的可执行文件会解释命令并执行与之关联的处理程序。当受害者的可执行文件想要将信息传回攻击者时，它可以通过将数据（以
    Base64 或 ASCII 编码）附加到 URL 上（例如：“http://attacker_address/ZXh0cmFjdGVkX2RhdGEK ?”，其中
    ZXh0cmFjdGVkX2RhdGEK 是以 Base64 编码的“extracted_data”）来对 LLM 执行另一个查询。为了进一步隐藏 Web
    服务器的恶意部分，可以创建一个包含插件用于浏览恶意网站的有效用户代理的内部列表。因此，如果 Web 浏览器的用户代理与插件的用户代理不匹配，Web 服务器可以呈现不同的网站并显得无害。'
- en: 3\. Proof of Concept
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3. 概念验证
- en: The goal of the proof-of-concept is to demonstrate that we are able to use ChatGPT
    as a proxy between a victim and an attacker’s C2 server. While our example is
    simple, this does not imply that we are functionally limited; creating a very
    powerful implementation was not in the scope of this study.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 概念验证的目标是展示我们能够使用 ChatGPT 作为受害者和攻击者 C2 服务器之间的代理。虽然我们的示例很简单，但这并不意味着我们在功能上有限；创建一个非常强大的实现并不在本研究的范围之内。
- en: 3.1\. Experimental Setup
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1. 实验设置
- en: The experimental setup consists of multiple actors responsible for various parts
    of the process.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 实验设置包括多个负责过程不同部分的参与者。
- en: •
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'ChatGPT: Used to generate the payload and interact with our C2 server through
    plugins.'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ChatGPT：用于生成有效负载并通过插件与我们的 C2 服务器进行交互。
- en: •
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Virtual Private Server (VPS): Responsible for hosting the C2 server that ChatGPT
    accesses. It has a public IPv4 address, which the victim’s executable generates
    on-the-fly.'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 虚拟私人服务器 (VPS)：负责托管 ChatGPT 访问的 C2 服务器。它有一个公共的 IPv4 地址，受害者的可执行文件会动态生成这个地址。
- en: •
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Victim’s executable: Executable on the victim’s machine. It generates the IPv4
    address of the VPS, generates code to interact with the C2 server, polls the attacker’s
    website via ChatGPT and executes commands on the victim’s machine. It contains
    basic code snippets responsible for cleaning up the results of ChatGPT, as well
    as access tokens for ChatGPT, plugin IDs and prepared prompts to jailbreak ChatGPT
    and to query websites.'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 受害者的可执行文件：在受害者的机器上执行的程序。它生成VPS的IPv4地址，生成与C2服务器交互的代码，通过ChatGPT轮询攻击者的网站并在受害者的机器上执行命令。它包含用于清理ChatGPT结果的基本代码片段，以及ChatGPT的访问令牌、插件ID和预设的提示，用于破解ChatGPT并查询网站。
- en: •
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Automated CAPTCHA solver service: To bypass the CAPTCHA challenges, we are
    relying on a third-party service which automatically solves these challenges.'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自动化验证码破解服务：为了绕过验证码挑战，我们依赖于一个第三方服务，该服务自动解决这些挑战。
- en: 3.2\. Possible Scenario
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2\. 可能的场景
- en: This section will describe a possible attack scenario, starting with the executable
    delivery, over its execution leading to the communication from the victim to our
    C2 server via ChatGPT, to the possible attack scenarios once the access on the
    victim’s machine is granted.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将描述一个可能的攻击场景，从可执行文件的交付开始，经过执行导致受害者通过ChatGPT与我们的C2服务器进行通信，到获得对受害者机器的访问权限后可能的攻击场景。
- en: 3.2.1\. Infiltration and Social Engineering
  id: totrans-66
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1\. 渗透与社会工程学
- en: To deploy the seemingly innocent executable, we need to convince a user to execute
    it on their system. The current buzz around Generative AI is an attractive pretext
    to use social engineering as a means to attract curious victims to execute it.
    For instance, marketing the executable as a free ChatGPT PLUS crack could be sufficient
    to lure people into downloading and executing it. In the best case, we would want
    our victims to be people working in highly restricted networks which allows for
    outbound HTTP connections and doesn’t yet have ChatGPT or other online LLMs blocked.
    The importance of HTTP communication is that the payload exclusively communicates
    via HTTP instead of other arbitrary ports are usually blocked by corporate firewalls.
    In its current implementation, when a user executes the executable, it will seem
    as if the program doesn’t want to run, and they will attempt to close it. But
    by closing the window, it will merely continue executing in the background and
    establish a connection to ChatGPT and thus to our C2 server. We now have access
    to a machine in a theoretical network. In a future version, we could adapt the
    executable to present a legitimate interface that lets a user interact with ChatGPT,
    while performing the attack in the background.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 为了部署看似无害的可执行文件，我们需要说服用户在他们的系统上执行它。当前对生成式AI的热议是利用社会工程学吸引好奇的受害者执行它的一个诱人借口。例如，将可执行文件营销为免费ChatGPT
    PLUS破解版可能足以吸引人们下载并执行它。最好的是，我们希望我们的受害者是那些在高度限制的网络中工作的人员，这些网络允许出站HTTP连接且尚未屏蔽ChatGPT或其他在线LLM。HTTP通信的重要性在于有效载荷仅通过HTTP进行通信，而不是其他通常被公司防火墙阻塞的任意端口。在当前实现中，当用户执行可执行文件时，它会表现得像程序不想运行一样，用户将尝试关闭它。但关闭窗口后，它会继续在后台运行，并建立与ChatGPT以及我们的C2服务器的连接。我们现在在理论网络中访问了一个机器。在未来的版本中，我们可以调整可执行文件，展示一个合法的界面，让用户与ChatGPT互动，同时在后台进行攻击。
- en: 3.2.2\. Victim Reconnaissance
  id: totrans-68
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2\. 受害者侦查
- en: 'Now that we have established a connection, we need to act quickly. We only
    have a limited amount of messages we can send between the client and the server
    (c.f. [subsubsection 4.3.2](#S4.SS3.SSS2 "4.3.2\. Message Cap For GPT-4 ‣ 4.3\.
    Existing Safeguards ‣ 4\. Discussion ‣ RatGPT: Turning online LLMs into Proxies
    for Malware Attacks")), and we already ”spent” one message on the payload generation,
    four messages on the IP address generation and one message to announce ourselves
    to the C2 server. Furthermore, polling the C2 server for new commands in a fixed
    interval also costs one message, as well as sending data back.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经建立了连接，我们需要迅速行动。我们在客户端和服务器之间可以发送的消息数量有限（参见 [subsubsection 4.3.2](#S4.SS3.SSS2
    "4.3.2\. GPT-4 消息限制 ‣ 4.3\. 现有保护措施 ‣ 4\. 讨论 ‣ RatGPT：将在线LLM转变为恶意软件攻击的代理")），我们已经“消耗”了一条消息用于有效载荷生成，四条消息用于IP地址生成，一条消息用于向C2服务器进行自我声明。此外，固定间隔轮询C2服务器获取新命令也需要消耗一条消息，发送数据回传也是如此。
- en: We can start by identifying the user on the victim’s machine, the current working
    directory, and the contents of that directory. We issue a single shellCmd command
    containing all the commands in one string (shellCmd whoami && pwd && ls -a) to
    produce only one message. The string is now published on the website, and we are
    waiting for the victim’s payload to poll our website through one of ChatGPT’s
    web browsing plugins. After the victim’s payload receives the response from ChatGPT
    containing the website’s contents, it extracts the commands, interprets them,
    and executes them. Finally, it appends the produced text output to the website
    URL of our C2 and sends a request to ChatGPT to browse this resource. The C2 receives
    the GET request to an unknown path and interprets the path as the output of the
    last command.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以开始识别受害者机器上的用户、当前工作目录以及该目录的内容。我们发出一个包含所有命令的单一shellCmd命令（shellCmd whoami &&
    pwd && ls -a），以产生一个消息。该字符串现在已发布在网站上，我们等待受害者的负载通过ChatGPT的网页浏览插件轮询我们的网站。在受害者的负载收到包含网站内容的ChatGPT响应后，它提取命令、解释并执行这些命令。最后，它将产生的文本输出附加到我们C2的网站URL，并向ChatGPT发送请求以浏览该资源。C2接收到对未知路径的GET请求，并将路径解释为最后一个命令的输出。
- en: 3.2.3\. Data Exfiltration
  id: totrans-71
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.3\. 数据提取
- en: From the output of the last command, we learn that the user conveniently has
    a plain text file called passwords.txt (this file was placed for demonstration
    purposes; any arbitrary file should be possible if you have the correct permissions)
    in their current working directory. We attempt to exfiltrate the contents of the
    said file by sending another shellCmd command with the string ”shellCmd cat passwords.txt”
    to the victim. The polling payload on the victim’s machine retrieves the command
    with a web browsing plugin, interprets the command, and runs ”cat passwords.txt”
    in a shell. In the next step, the output of the shell command is appended to the
    URL of the C2 server, and a new request is issued to the C2 server with the URL
    containing the results. On the C2 side, we receive the GET request and extract
    the urlencoded data from the request path. Since we are now in possession of the
    victim’s credentials, we could continue with further post-exploitation tasks.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 从最后一个命令的输出中，我们了解到用户在当前工作目录中方便地拥有一个名为passwords.txt的纯文本文件（该文件是为了演示目的而放置的；如果你有正确的权限，任何任意文件都可以）。我们尝试通过向受害者发送另一个shellCmd命令，字符串为“shellCmd
    cat passwords.txt”，来提取该文件的内容。受害者机器上的轮询负载通过网页浏览插件检索命令，解释命令，并在shell中运行“cat passwords.txt”。接下来的步骤是，将shell命令的输出附加到C2服务器的URL中，并向C2服务器发出一个包含结果的URL的新请求。在C2端，我们接收到GET请求并从请求路径中提取url编码的数据。既然我们已经获得了受害者的凭据，我们可以继续进行进一步的后期利用任务。
- en: 4\. Discussion
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 讨论
- en: The findings of this study underline the importance of securing openly available
    plugins in public LLMs. While the results provide valuable insights, we will now
    discuss the study’s limitations, existing safeguards and future work recommendations.
    We also propose some theoretical approaches on how to mitigate attacks of this
    kind.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这项研究的发现强调了保护公开可用插件在公共LLM中的重要性。虽然结果提供了宝贵的见解，但我们现在将讨论研究的局限性、现有的保护措施和未来的工作建议。我们还提出了一些理论方法来缓解此类攻击。
- en: 4.1\. Limitations
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1\. 限制
- en: During this study, some challenges were faced, e.g., unreliable ChatGPT outputs,
    already existing safeguards, and the ban of some exploitable plugins. The following
    subsections will further investigate these current limitations.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项研究过程中，面临了一些挑战，例如ChatGPT输出不可靠、已存在的保护措施以及一些可利用插件的禁用。以下小节将进一步探讨这些当前的限制。
- en: 4.1.1\. Non-deterministic Payload Generation
  id: totrans-77
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.1\. 非确定性负载生成
- en: Since the output of the LLMs is non-deterministic, successful generation of
    the correct payload is unreliable and thus cannot be guaranteed. While we constructed
    our prompts to be as straightforward as possible, there are still cases where
    the payload is missing important aspects of the required payload. Most common
    were missing function implementations for the commands from the C2 server that
    the payload should parse, or general errors of the parser itself. This resulted
    in the payload not interpreting the commands at all or, in some cases, interpreting
    them but not continuing the execution since the function bodies of the commands
    were missing.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 由于LLMs的输出是非确定性的，成功生成正确的有效负载是不可靠的，因此不能保证。尽管我们构建了尽可能简单的提示，但仍然存在有效负载缺少所需重要方面的情况。最常见的是有效负载缺少C2服务器命令的函数实现，或者解析器本身的通用错误。这导致有效负载无法解释命令，或者在某些情况下，虽然解释了命令，但由于命令的函数体缺失，未能继续执行。
- en: 4.1.2\. Plugin Availability
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.2\. 插件可用性
- en: During the development of our proof-of-concept, we had to deal with situations
    where the plugin of choice to connect to our C2 server either was removed from
    ChatGPT’s plugin list or not able to establish a connection any more, breaking
    the implementation until we found replacement plugins. For this reason, enabling
    multiple web-enabled plugins will provide strong fallback options, should some
    web-enabled plugins be removed from the ”Plugin store”.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开发概念验证的过程中，我们不得不处理插件被从ChatGPT插件列表中移除或无法再建立连接的情况，这会破坏实现，直到我们找到替代插件。因此，启用多个支持网络的插件将提供强有力的备用选项，以防一些支持网络的插件被从“插件商店”中移除。
- en: 4.2\. Future Work
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2\. 未来工作
- en: Since we are able to demonstrate the use of LLMs as proxies with the proof-of-concept,
    several improvements can be made to extend the current version. In this section,
    we will centre our attention on obfuscating the prompts and creating a ransomware
    example using the same methods as described earlier.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们能够通过概念验证展示LLMs作为代理的使用，当前版本可以进行多项改进以扩展功能。在本节中，我们将重点关注模糊化提示并使用与前述方法相同的方式创建一个勒索软件示例。
- en: 4.2.1\. Prompt Obfuscation
  id: totrans-83
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.1\. 提示模糊化
- en: The current proof-of-concept demonstrates the implementation of two-stage malware¹¹1Two-stage
    malware often disguises itself as a legitimate executable (the first stage) and
    contains instructions to download and execute the actual malicious payload (the
    second stage). This approach allows the malware to bypass initial security measures
    and then deploy the more harmful payload once inside the target system., where
    the second stage is not downloaded from a machine controlled by the attacker.
    Instead, the payload is generated on the fly with the help of prompts that are
    included in the first-stage executable. While much antivirus software can be bypassed
    with this approach, humans can quickly dissect the malware and determine the inner
    workings of the malware due to the plain text nature of the prompts. Currently,
    the bootstrapping code is a Base64 encoded string that gets decoded on launch.
    This might fool simple analysis tools, but for the rest it results in security
    through obscurity. In a future version, text obfuscation techniques could be implemented
    to complicate this analysis process.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的概念验证演示了两阶段恶意软件的实现¹¹1两阶段恶意软件通常伪装成合法的可执行文件（第一阶段），并包含下载和执行实际恶意负载的指令（第二阶段）。这种方法使恶意软件能够绕过初始安全措施，然后在进入目标系统后部署更具危害的负载。，其中第二阶段并非从攻击者控制的机器上下载。而是通过在第一阶段可执行文件中包含的提示动态生成负载。虽然这种方法可以绕过许多杀毒软件，但由于提示的明文特性，人们可以迅速解剖恶意软件并确定其内部工作机制。目前，启动代码是一个Base64编码的字符串，在启动时进行解码。这可能会欺骗简单的分析工具，但对于其他工具来说，结果则是安全上的模糊化。在未来的版本中，可以实施文本模糊化技术，以使分析过程更加复杂。
- en: 4.2.2\. Ransomware Example
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.2\. 勒索软件示例
- en: 'While we were able to demonstrate a simplified version of a RAT communicating
    with the attacker via ChatGPT, it could also be possible to create a ransomware
    example using the same general process. When deploying the ransomware, it could
    bootstrap its payload, encrypt the victim’s data, and send the key to the C2 server
    by appending it to the URL of the C2 server and making a request via ChatGPT.
    This possibility underlines the need for security measures highlighted in [subsection 4.4](#S4.SS4
    "4.4\. Possible Mitigations ‣ 4\. Discussion ‣ RatGPT: Turning online LLMs into
    Proxies for Malware Attacks").'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们能够演示一个简化版本的 RAT 通过 ChatGPT 与攻击者通信，但也可能使用相同的通用过程创建一个勒索软件示例。当部署勒索软件时，它可以引导其负载，加密受害者的数据，并通过将密钥附加到
    C2 服务器的 URL 并通过 ChatGPT 进行请求来将密钥发送到 C2 服务器。这种可能性突显了 [4.4 小节](#S4.SS4 "4.4\. 可能的缓解措施
    ‣ 4\. 讨论 ‣ RatGPT：将在线 LLM 转变为恶意软件攻击的代理") 中强调的安全措施的必要性。
- en: 4.3\. Existing Safeguards
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3\. 现有保护措施
- en: Whether intentional or inadvertent, certain safeguards, which will be enumerated
    in this section, currently exist that impede the reliable use of ChatGPT as a
    proxy for malware.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是有意还是无意，目前存在某些保护措施，这些措施将被在本节中列举，这些措施妨碍了将 ChatGPT 可靠地用作恶意软件代理的能力。
- en: 4.3.1\. CAPTCHA Protection
  id: totrans-89
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.1\. CAPTCHA 保护
- en: In our proof-of-concept, we are using the Web API to interact with the GPT-4
    model that uses plugins. To safeguard these endpoints from bot-related abuse,
    they are protected by a cloud security provider. Consequently, if suspicious traffic
    is detected, it presents the users with a challenge they need to solve to be admitted
    to the main content. In the case of our automated payload, this protection is
    often triggered. While we were able to bypass this protection multiple times with
    online solver services, it became increasingly more difficult to bypass the ”suspicious
    behavior detection mechanism”.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的概念验证中，我们使用 Web API 与使用插件的 GPT-4 模型进行交互。为了保护这些端点免受机器人相关的滥用，它们由云安全提供商进行保护。因此，如果检测到可疑流量，用户会被呈现一个需要解决的挑战才能访问主要内容。在我们的自动化负载的情况下，这种保护机制经常被触发。虽然我们曾通过在线求解服务多次绕过这种保护，但绕过“可疑行为检测机制”变得越来越困难。
- en: 4.3.2\. Message Cap For GPT-4
  id: totrans-91
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.2\. GPT-4 的消息限制
- en: 'In its current state, the ChatGPT GPT-4 model can only process a limited amount
    of requests in a defined period of time. This posed a constraint in the ability
    to make progress, since we had to anticipate the ”cooldown phase” of the used
    credits to perform the experiments and refine the prompts. In a practical scenario,
    this limitation would limit the number of commands an attacker could execute on
    their victims: the payload on the victim’s machine sends messages to poll for
    new commands from the C2 server, as well as to send results back to the C2 server.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前状态下，ChatGPT GPT-4 模型只能在定义的时间段内处理有限数量的请求。这对进展能力造成了限制，因为我们必须预测用于实验的信用点的“冷却阶段”以执行实验和改进提示。在实际场景中，这种限制将限制攻击者对其受害者可以执行的命令数量：受害者机器上的负载会发送消息以从
    C2 服务器轮询新命令，并将结果发送回 C2 服务器。
- en: 4.4\. Possible Mitigations
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4\. 可能的缓解措施
- en: This section presents potential mitigations to the security issue at hand. It
    is important to note that this list is non-exhaustive, and further research may
    uncover additional strategies.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提出了针对当前安全问题的潜在缓解措施。需要注意的是，这个列表并不详尽，进一步的研究可能会揭示更多策略。
- en: •
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Website Whitelisting: While many available plugins were created to access specific
    systems, the plugins in our study are able to access any user-controlled website.
    Implementing a whitelisting system to only allow predefined websites fulfilling
    certain conditions (e.g., domain name should be at least x days old, valid HTTPS
    certificate, no direct connection to an IP address, etc.) or checking the validity
    on the fly could reduce the number of potentially dangerous C2 websites.'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 网站白名单：虽然许多可用插件是为了访问特定系统而创建的，但我们研究中的插件能够访问任何用户控制的网站。实施一个白名单系统，只允许符合某些条件（例如，域名至少应存在
    x 天，有效的 HTTPS 证书，不直接连接到 IP 地址等）的预定义网站，或实时检查其有效性，可以减少潜在危险的 C2 网站的数量。
- en: •
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Restricting access to online LLMs: This mitigation is targeted towards people
    and entities that could become victims in this attack. Although an extreme approach,
    restricting the access of online LLMs on a network level (e.g., by updating firewall
    rules or using DNS filtering) would eliminate the possibility to communicate with
    the C2 server, removing the dangers of an attacker gaining control of the system.'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 限制对在线LLM的访问：这一缓解措施针对的是可能成为此类攻击受害者的个人和实体。尽管是一种极端的方法，但在网络层面限制在线LLM的访问（例如，通过更新防火墙规则或使用DNS过滤）将消除与C2服务器通信的可能性，从而消除攻击者控制系统的危险。
- en: •
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Prompt Scanning: The nature of the proof-of-concept executable is a collection
    of prompts that bootstrap the malicious payload, which then periodically sends
    prompts to communicate with the C2 server. Since this is an entirely new approach
    of building malware which might occur more often in the wild, this calls for an
    evolution in malware detection tools. Such tools need to be capable of:'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提示扫描：概念验证可执行文件的性质是一系列提示，这些提示引导恶意有效载荷，然后定期发送提示与C2服务器进行通信。由于这是一种全新的构建恶意软件的方法，可能在实际环境中更为频繁，因此需要对恶意软件检测工具进行进化。这些工具需要具备：
- en: (1)
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: Detecting that prompts are present in the executable.
  id: totrans-102
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 检测可执行文件中存在的提示。
- en: (2)
  id: totrans-103
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: Discerning potentially malicious prompts from harmless prompts.
  id: totrans-104
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 区分潜在恶意的提示和无害的提示。
- en: (3)
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3)
- en: Implementing heuristic analysis to predict and identify new variants or evolutions
    of the malware.
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 实施启发式分析以预测和识别恶意软件的新变种或演变。
- en: In response to this emerging malware paradigm, it’s imperative that detection
    tools evolve swiftly to address and neutralize such advanced threats.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 针对这一新兴的恶意软件范式，检测工具必须迅速进化，以应对和中和这些先进的威胁。
- en: 5\. Related Work
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5. 相关工作
- en: Large Language Models have recently been used to weaponize code and generate
    attacks in several case studies (Derner and Batistič, [2023](#bib.bib9); Charan
    et al., [2023](#bib.bib6); Qammar et al., [2023](#bib.bib17); Deng et al., [2023](#bib.bib8)).
    Gupta et al. (Gupta et al., [2023](#bib.bib12)) have summarized some possibilities
    of Jailbreaks and demonstrated the feasibility of prompt injection attacks on
    ChatGPT. Other studies have already highlighted the potential of LLMs to increase
    the attack vector of phishing attacks (Chowdhury et al., [2023](#bib.bib7)) due
    to LLMs’ capabilities of producing human-like content that can easily seem legitimate
    to users. Similarly, the previous study shows that ChatGPT can easily prompt users
    to reveal confidential information or to make users download malicious content.
    Greshake et al. (Greshake et al., [2023](#bib.bib10)) mention a scenario where
    the attacker controls the content of a website to control what the LLM receives
    and the use of external API to communicate back to the attacker. In their approach,
    however, they show prompts on the attacker-controlled web page and the communication
    seemingly only stays within the LLM system and does not interact with the user’s
    system.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型最近被用来武器化代码并在多个案例研究中生成攻击（Derner 和 Batistič, [2023](#bib.bib9); Charan 等,
    [2023](#bib.bib6); Qammar 等, [2023](#bib.bib17); Deng 等, [2023](#bib.bib8)）。Gupta
    等（Gupta 等, [2023](#bib.bib12)）总结了一些越狱的可能性，并展示了对ChatGPT进行提示注入攻击的可行性。其他研究已经强调了LLM在增加钓鱼攻击攻击面方面的潜力（Chowdhury
    等, [2023](#bib.bib7)），这是由于LLM具有生成类似人类内容的能力，这些内容对用户来说可能看起来很合法。类似地，先前的研究表明，ChatGPT可以轻松提示用户泄露机密信息或让用户下载恶意内容。Greshake
    等（Greshake 等, [2023](#bib.bib10)）提到了一种攻击者控制网站内容的场景，以控制LLM接收到的内容，并使用外部API与攻击者通信。然而，在他们的方法中，他们展示了攻击者控制的网页上的提示，通信似乎仅限于LLM系统内部，而不与用户的系统互动。
- en: 6\. Conclusion
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6. 结论
- en: Large Language Models have opened new opportunities, improving, and speeding
    up tasks in everyone’s daily lives. However, in this study, we have proven how
    easily unsecured openly available LLMs and plugins can be misused to perform efficient
    and undetected attacks around the world.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型开辟了新的机会，改善并加速了每个人日常生活中的任务。然而，在这项研究中，我们证明了不安全的开放可用LLM和插件如何被滥用，执行高效且未被检测到的全球攻击。
- en: This proof-of-concept demonstrates the potential transformation of LLMs into
    proxies for malware attacks, allowing their misuse through plugins to establish
    connections with command and control servers. This facilitates complete access
    to a victim’s machine without necessitating direct interaction between the victim
    and the LLM.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 该概念验证展示了 LLMs 转变为恶意软件攻击代理的潜在可能性，允许通过插件的滥用与命令和控制服务器建立连接。这使得能够完全访问受害者的机器，而不需要受害者与
    LLM 之间的直接交互。
- en: This work highlights the need for new mitigation strategies and the development
    of further security guidelines on the deployment of LLMs.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究突显了对新缓解策略的需求以及在部署 LLM 时制定进一步安全指南的必要性。
- en: Acknowledgement
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: Special thanks to Mercatus Center at George Mason University, for their invaluable
    support in this research. The views presented in this paper do not represent official
    positions of the Mercatus Center or George Mason University.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 特别感谢乔治·梅森大学的 Mercatus Center 对本研究的宝贵支持。本文所述观点不代表 Mercatus Center 或乔治·梅森大学的官方立场。
- en: References
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （1）
- en: Allamanis et al. (2018) Miltiadis Allamanis, Earl T Barr, Premkumar Devanbu,
    and Charles Sutton. 2018. A survey of machine learning for big code and naturalness.
    *ACM Computing Surveys (CSUR)* 51, 4 (2018), 1–37.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Allamanis 等（2018）Miltiadis Allamanis、Earl T Barr、Premkumar Devanbu 和 Charles
    Sutton。2018年。大代码和自然性的机器学习调查。*ACM 计算机调查（CSUR）* 51，4（2018），1–37。
- en: Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D
    Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
    Askell, et al. 2020. Language models are few-shot learners. *Advances in neural
    information processing systems* 33 (2020), 1877–1901.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown 等（2020）Tom Brown、Benjamin Mann、Nick Ryder、Melanie Subbiah、Jared D Kaplan、Prafulla
    Dhariwal、Arvind Neelakantan、Pranav Shyam、Girish Sastry、Amanda Askell 等。2020年。语言模型是少样本学习者。*神经信息处理系统进展*
    33（2020），1877–1901。
- en: Brundage et al. (2022) Miles Brundage, Katie Mayer, Tyna Eloundou, Sandhini
    Agarwal, Steven Adler, Gretchen Krueger, Jan Leike, and Pamela Mishkin. 2022.
    Lessons learned on language model safety and misuse.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brundage 等（2022）Miles Brundage、Katie Mayer、Tyna Eloundou、Sandhini Agarwal、Steven
    Adler、Gretchen Krueger、Jan Leike 和 Pamela Mishkin。2022年。关于语言模型安全性和滥用的经验教训。
- en: 'Bui et al. (2023) Nghi DQ Bui, Hung Le, Yue Wang, Junnan Li, Akhilesh Deepak
    Gotmare, and Steven CH Hoi. 2023. CodeTF: One-stop Transformer Library for State-of-the-art
    Code LLM. *arXiv preprint arXiv:2306.00029* (2023).'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bui 等（2023）Nghi DQ Bui、Hung Le、Yue Wang、Junnan Li、Akhilesh Deepak Gotmare 和
    Steven CH Hoi。2023年。CodeTF：一站式变压器库用于最先进的代码 LLM。*arXiv 预印本 arXiv:2306.00029*（2023）。
- en: 'Charan et al. (2023) PV Charan, Hrushikesh Chunduri, P Mohan Anand, and Sandeep K
    Shukla. 2023. From Text to MITRE Techniques: Exploring the Malicious Use of Large
    Language Models for Generating Cyber Attack Payloads. *arXiv preprint arXiv:2305.15336*
    (2023).'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Charan 等（2023）PV Charan、Hrushikesh Chunduri、P Mohan Anand 和 Sandeep K Shukla。2023年。从文本到
    MITRE 技术：探讨大语言模型在生成网络攻击有效载荷中的恶意使用。*arXiv 预印本 arXiv:2305.15336*（2023）。
- en: 'Chowdhury et al. (2023) Minhaz Chowdhury, Nafiz Rifat, Shadman Latif, Mostofa
    Ahsan, Md Saifur Rahman, and Rahul Gomes. 2023. ChatGPT: The Curious Case of Attack
    Vectors’ Supply Chain Management Improvement. In *2023 IEEE International Conference
    on Electro Information Technology (eIT)*. IEEE, 499–504.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chowdhury 等（2023）Minhaz Chowdhury、Nafiz Rifat、Shadman Latif、Mostofa Ahsan、Md
    Saifur Rahman 和 Rahul Gomes。2023年。ChatGPT：攻击向量供应链管理改进的奇特案例。在 *2023 IEEE 国际电气信息技术会议
    (eIT)* 中。IEEE，499–504。
- en: 'Deng et al. (2023) Gelei Deng, Yi Liu, Yuekang Li, Kailong Wang, Ying Zhang,
    Zefeng Li, Haoyu Wang, Tianwei Zhang, and Yang Liu. 2023. Jailbreaker: Automated
    Jailbreak Across Multiple Large Language Model Chatbots. *arXiv preprint arXiv:2307.08715*
    (2023).'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deng 等（2023）Gelei Deng、Yi Liu、Yuekang Li、Kailong Wang、Ying Zhang、Zefeng Li、Haoyu
    Wang、Tianwei Zhang 和 Yang Liu。2023年。Jailbreaker：跨多个大型语言模型聊天机器人进行自动化越狱。*arXiv 预印本
    arXiv:2307.08715*（2023）。
- en: 'Derner and Batistič (2023) Erik Derner and Kristina Batistič. 2023. Beyond
    the Safeguards: Exploring the Security Risks of ChatGPT. *arXiv preprint arXiv:2305.08005*
    (2023).'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Derner 和 Batistič（2023）Erik Derner 和 Kristina Batistič。2023年。超越安全防护：探讨 ChatGPT
    的安全风险。*arXiv 预印本 arXiv:2305.08005*（2023）。
- en: 'Greshake et al. (2023) Kai Greshake, Sahar Abdelnabi, Shailesh Mishra, Christoph
    Endres, Thorsten Holz, and Mario Fritz. 2023. Not what you’ve signed up for: Compromising
    Real-World LLM-Integrated Applications with Indirect Prompt Injection. arXiv:2302.12173 [cs.CR]'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Greshake 等（2023）Kai Greshake、Sahar Abdelnabi、Shailesh Mishra、Christoph Endres、Thorsten
    Holz 和 Mario Fritz。2023年。你没有注册的内容：通过间接提示注入来破坏真实世界的 LLM 集成应用。arXiv:2302.12173 [cs.CR]
- en: Gulwani et al. (2017) Sumit Gulwani, Oleksandr Polozov, Rishabh Singh, et al.
    2017. Program synthesis. *Foundations and Trends® in Programming Languages* 4,
    1-2 (2017), 1–119.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gulwani et al. (2017) Sumit Gulwani, Oleksandr Polozov, Rishabh Singh 等. 2017.
    程序合成。*编程语言基础与趋势®* 4, 1-2 (2017), 1–119.
- en: 'Gupta et al. (2023) Maanak Gupta, CharanKumar Akiri, Kshitiz Aryal, Eli Parker,
    and Lopamudra Praharaj. 2023. From ChatGPT to ThreatGPT: Impact of Generative
    AI in Cybersecurity and Privacy. *IEEE Access* (2023).'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gupta et al. (2023) Maanak Gupta, CharanKumar Akiri, Kshitiz Aryal, Eli Parker
    和 Lopamudra Praharaj. 2023. 从 ChatGPT 到 ThreatGPT：生成式 AI 在网络安全和隐私中的影响。*IEEE Access*
    (2023).
- en: Hu et al. (2018) Xing Hu, Ge Li, Xin Xia, David Lo, and Zhi Jin. 2018. Deep
    code comment generation. In *Proceedings of the 26th conference on program comprehension*.
    200–210.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu et al. (2018) Xing Hu, Ge Li, Xin Xia, David Lo 和 Zhi Jin. 2018. 深度代码注释生成。见于
    *第26届程序理解会议论文集*。200–210.
- en: LeaderbotX400 ([n. d.]) LeaderbotX400\. [n. d.]. LeaderbotX400/chatbot-experiments.
    [https://github.com/LeaderbotX400/chatbot-experiments/blob/main/jailbreaks/ChatGPT/Dan%2011.0.md](https://github.com/LeaderbotX400/chatbot-experiments/blob/main/jailbreaks/ChatGPT/Dan%2011.0.md)
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LeaderbotX400 ([n. d.]) LeaderbotX400\. [n. d.]. LeaderbotX400/chatbot-experiments.
    [https://github.com/LeaderbotX400/chatbot-experiments/blob/main/jailbreaks/ChatGPT/Dan%2011.0.md](https://github.com/LeaderbotX400/chatbot-experiments/blob/main/jailbreaks/ChatGPT/Dan%2011.0.md)
- en: 'Liu et al. (2023) Yi Liu, Gelei Deng, Zhengzi Xu, Yuekang Li, Yaowen Zheng,
    Ying Zhang, Lida Zhao, Tianwei Zhang, and Yang Liu. 2023. Jailbreaking ChatGPT
    via Prompt Engineering: An Empirical Study. arXiv:2305.13860 [cs.SE]'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2023) Yi Liu, Gelei Deng, Zhengzi Xu, Yuekang Li, Yaowen Zheng,
    Ying Zhang, Lida Zhao, Tianwei Zhang 和 Yang Liu. 2023. 通过提示工程破解 ChatGPT：一项实证研究。arXiv:2305.13860
    [cs.SE]
- en: 'Lu et al. (2021) Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy,
    Ambrosio Blanco, Colin Clement, Dawn Drain, Daxin Jiang, Duyu Tang, et al. 2021.
    Codexglue: A machine learning benchmark dataset for code understanding and generation.
    *arXiv preprint arXiv:2102.04664* (2021).'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lu et al. (2021) Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy,
    Ambrosio Blanco, Colin Clement, Dawn Drain, Daxin Jiang, Duyu Tang 等. 2021. Codexglue：一个用于代码理解和生成的机器学习基准数据集。*arXiv
    预印本 arXiv:2102.04664* (2021).
- en: 'Qammar et al. (2023) Attia Qammar, Hongmei Wang, Jianguo Ding, Abdenacer Naouri,
    Mahmoud Daneshmand, and Huansheng Ning. 2023. Chatbots to ChatGPT in a Cybersecurity
    Space: Evolution, Vulnerabilities, Attacks, Challenges, and Future Recommendations.
    *arXiv preprint arXiv:2306.09255* (2023).'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qammar et al. (2023) Attia Qammar, Hongmei Wang, Jianguo Ding, Abdenacer Naouri,
    Mahmoud Daneshmand 和 Huansheng Ning. 2023. 从 ChatGPT 到网络安全领域的聊天机器人：演变、脆弱性、攻击、挑战及未来建议。*arXiv
    预印本 arXiv:2306.09255* (2023).
- en: 'Touvron et al. (2023) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
    Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal,
    Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language
    models. *arXiv preprint arXiv:2302.13971* (2023).'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Touvron et al. (2023) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
    Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal,
    Eric Hambro, Faisal Azhar 等. 2023. Llama：开放而高效的基础语言模型。*arXiv 预印本 arXiv:2302.13971*
    (2023).
