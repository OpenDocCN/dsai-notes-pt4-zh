- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 18:45:36'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:45:36
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot
    LLM Assessment
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM作为评判者是否稳健？调查零-shot LLM评估中的通用对抗攻击
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2402.14016](https://ar5iv.labs.arxiv.org/html/2402.14016)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2402.14016](https://ar5iv.labs.arxiv.org/html/2402.14016)
- en: Vyas Raina^∗
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Vyas Raina^∗
- en: University of Cambridge
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 剑桥大学
- en: vr313@cam.ac.uk
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: vr313@cam.ac.uk
- en: '&Adian Liusie^∗'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '&Adian Liusie^∗'
- en: University of Cambridge
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 剑桥大学
- en: al826@cam.ac.uk
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: al826@cam.ac.uk
- en: '&Mark Gales'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '&Mark Gales'
- en: University of Cambridge
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 剑桥大学
- en: mjfg@cam.ac.uk
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: mjfg@cam.ac.uk
- en: Abstract
  id: totrans-15
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Large Language Models (LLMs) are powerful zero-shot assessors and are increasingly
    used in real-world situations such as for written exams or benchmarking systems.
    Despite this, no existing work has analyzed the vulnerability of judge-LLMs against
    adversaries attempting to manipulate outputs. This work presents the first study
    on the adversarial robustness of assessment LLMs, where we search for short universal
    phrases that when appended to texts can deceive LLMs to provide high assessment
    scores. Experiments on SummEval and TopicalChat demonstrate that both LLM-scoring
    and pairwise LLM-comparative assessment are vulnerable to simple concatenation
    attacks, where in particular LLM-scoring is very susceptible and can yield maximum
    assessment scores irrespective of the input text quality. Interestingly, such
    attacks are transferable and phrases learned on smaller open-source LLMs can be
    applied to larger closed-source models, such as GPT3.5\. This highlights the pervasive
    nature of the adversarial vulnerabilities across different judge-LLM sizes, families
    and methods. Our findings raise significant concerns on the reliability of LLMs-as-a-judge
    methods, and underscore the importance of addressing vulnerabilities in LLM assessment
    methods before deployment in high-stakes real-world scenarios. ¹¹1Code: https://github.com/rainavyas/attack-comparative-assessment'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）作为强大的零-shot 评估者，越来越多地用于现实世界场景中，例如书面考试或基准测试系统。尽管如此，现有工作尚未分析评判LLMs对试图操控输出的对抗者的脆弱性。这项工作首次研究了评估LLMs的对抗鲁棒性，我们搜索了短小的通用短语，当这些短语附加到文本中时，可以欺骗LLMs提供高评估分数。在SummEval和TopicalChat上的实验表明，无论是LLM评分还是成对LLM比较评估，都容易受到简单的串联攻击，特别是LLM评分非常敏感，可以产生最大评估分数，而不考虑输入文本的质量。有趣的是，这种攻击具有迁移性，学习到的小型开源LLMs上的短语可以应用于更大的闭源模型，如GPT3.5。这突显了不同评判LLM大小、家族和方法中普遍存在的对抗性脆弱性。我们的发现对LLM作为评判者方法的可靠性提出了重大担忧，并强调在高风险现实场景中部署之前，解决LLM评估方法中的脆弱性的重要性。¹¹1代码：[https://github.com/rainavyas/attack-comparative-assessment](https://github.com/rainavyas/attack-comparative-assessment)
- en: Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot
    LLM Assessment
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: LLM作为评判者是否稳健？调查零-shot LLM评估中的通用对抗攻击
- en: Vyas Raina^∗ University of Cambridge vr313@cam.ac.uk                       
    Adian Liusie^∗ University of Cambridge al826@cam.ac.uk                       
    Mark Gales University of Cambridge mjfg@cam.ac.uk
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Vyas Raina^∗ 剑桥大学 vr313@cam.ac.uk                        Adian Liusie^∗ 剑桥大学
    al826@cam.ac.uk                        Mark Gales 剑桥大学 mjfg@cam.ac.uk
- en: ^†^†^∗ Equal Contribution.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ^†^†^∗ 平等贡献。
- en: 1 Introduction
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Large Language Models (LLMs) have shown to be proficient zero-shot assessors,
    capable of evaluating texts without requiring any domain-specific training Zheng
    et al. ([2023](#bib.bib51)); Chen et al. ([2023](#bib.bib6)); Zhang et al. ([2023a](#bib.bib48)).
    Typical zero-shot approaches prompt powerful LLMs to either generate a single
    quality score of the assessed text Wang et al. ([2023a](#bib.bib42)); Liu et al.
    ([2023b](#bib.bib25)) or to use pairwise comparisons to determine which of two
    texts are better Liusie et al. ([2023](#bib.bib28)); Qin et al. ([2023](#bib.bib33)).
    These zero-shot approaches mark a compelling new paradigm for assessment, enabling
    straightforward reference-free evaluation that correlates highly with human judgements,
    while being applicable to a range of diverse attributes. There has consequently
    been a surge of leveraging LLM-as-a-judge in many applications, including as benchmarks
    for assessing new models Zheng et al. ([2023](#bib.bib51)); Zhu et al. ([2023b](#bib.bib56))
    or as tools for assessing the written examinations of real candidates.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）已经显示出在零样本评估方面的熟练能力，能够在不需要任何领域特定训练的情况下评估文本 Zheng et al. ([2023](#bib.bib51));
    Chen et al. ([2023](#bib.bib6)); Zhang et al. ([2023a](#bib.bib48))。典型的零样本方法促使强大的LLMs生成被评估文本的单一质量分数
    Wang et al. ([2023a](#bib.bib42)); Liu et al. ([2023b](#bib.bib25))，或者使用成对比较来确定两个文本中哪个更好
    Liusie et al. ([2023](#bib.bib28)); Qin et al. ([2023](#bib.bib33))。这些零样本方法标志着评估的新范式，实现了无需参考的简单评估，与人类判断高度相关，并适用于多种不同的属性。因此，LLM作为评判者的应用激增，包括作为评估新模型的基准
    Zheng et al. ([2023](#bib.bib51)); Zhu et al. ([2023b](#bib.bib56))，或作为评估真实考生书面考试的工具。
- en: '![Refer to caption](img/f4a62746da64d97a30259f081f777336.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/f4a62746da64d97a30259f081f777336.png)'
- en: 'Figure 1: A simple universal adversarial attack phrase can be concatenated
    to a candidate response to fool an LLM assessment system into predicting that
    it is of higher quality. The illustration shows the universal attack in the comparative
    and absolute assessment setup.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：一个简单的通用对抗攻击短语可以附加到候选响应中，以欺骗LLM评估系统预测其质量更高。插图展示了在比较和绝对评估设置中的通用攻击。
- en: Despite the clear advantages of zero-shot LLM assessment methods, the limitations
    and robustness of LLM-as-a-judge have been less well-studied. Previous works have
    demonstrated potential limitations in robustness, and the presence of biases such
    as positional bias Wang et al. ([2023b](#bib.bib43)); Liusie et al. ([2023](#bib.bib28));
    Zhu et al. ([2023b](#bib.bib56)), length bias Koo et al. ([2023](#bib.bib19))
    and self-preferential behaviours Zheng et al. ([2023](#bib.bib51)); Liu et al.
    ([2023d](#bib.bib27)). This paper pushes this paradigm further by investigating
    whether appending a simple universal phrase to the end of an assessed text could
    deceive an LLM into predicting high scores regardless of the text’s quality. Such
    approaches not only pose challenges for model evaluation, where adversaries may
    manipulate benchmark metrics, but also raise concerns about academic integrity,
    as students may employ similar tactics to cheat and attain higher scores.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管零样本LLM评估方法具有明显优势，但LLM作为评判者的局限性和鲁棒性尚未得到充分研究。先前的工作展示了鲁棒性潜在的局限性，以及如位置偏差 Wang
    et al. ([2023b](#bib.bib43)); Liusie et al. ([2023](#bib.bib28)); Zhu et al. ([2023b](#bib.bib56))，长度偏差
    Koo et al. ([2023](#bib.bib19)) 和自我偏好行为 Zheng et al. ([2023](#bib.bib51)); Liu
    et al. ([2023d](#bib.bib27))等偏差的存在。本文进一步推动了这一范式，调查在评估文本末尾附加简单的通用短语是否能够欺骗LLM预测高分，无论文本的实际质量如何。这些方法不仅对模型评估提出了挑战，因为对手可能操控基准指标，还引发了关于学术诚信的担忧，因为学生可能采用类似策略作弊并获得更高分数。
- en: This work is the first to apply adversarial attacks (Szegedy et al., [2014](#bib.bib39))
    to zero-shot LLM assessment, and demonstrates that LLM-as-a-judge methods are
    susceptible to simple concatenative adversarial attacks. Both LLM-scoring and
    pairwise LLM-comparative assessment are vulnerable to such attacks, and concatenating
    a universal phrase of under 5 tokens can trick systems into providing significantly
    higher assessment scores. We find that comparative assessment has mild robustness,
    but that LLM-scoring is very vulnerable to such attacks and universal attack phrases
    can cause systems to return a maximum score, irrespective of the input text. We
    further demonstrate that for LLM-scoring, phrases can be transferable across different
    model sizes and families, where attack phrases learned on FlanT5-3B can deceive
    much more powerful systems such as ChatGPT. Finally, as an initial step towards
    defending against such attacks, we use the perplexity score (Jain et al., [2023](#bib.bib16))
    as a simple detection approach, which demonstrates some success. As a whole, our
    work raises awareness of the vulnerabilities of zero-shot LLM assessment, and
    highlights that if such systems are to be deployed in critical real-world scenarios,
    such vulnerabilities should be considered and addressed.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究首次将对抗攻击（Szegedy 等人，[2014](#bib.bib39)）应用于零-shot LLM 评估，并展示了 LLM-作为-评审的方法容易受到简单的拼接对抗攻击。LLM
    评分和成对 LLM 比较评估都易受到这种攻击，拼接少于 5 个标记的通用短语可以欺骗系统，从而提供显著更高的评估分数。我们发现比较评估具有一定的鲁棒性，但
    LLM 评分对这种攻击非常脆弱，通用攻击短语可以使系统返回最高分，无论输入文本如何。我们进一步展示了，对于 LLM 评分，短语可以在不同的模型大小和系列之间转移，其中在
    FlanT5-3B 上学习到的攻击短语可以欺骗更强大的系统，如 ChatGPT。最后，作为防御这种攻击的初步步骤，我们使用困惑度得分（Jain 等人，[2023](#bib.bib16)）作为一种简单的检测方法，这显示出一定的成功。总体而言，我们的工作提高了对零-shot
    LLM 评估漏洞的认识，并强调如果这些系统要在关键的实际场景中部署，则应考虑并解决这些漏洞。
- en: 2 Related Work
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: Bespoke NLG Evaluation.
  id: totrans-27
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 定制 NLG 评估。
- en: For Natural Language Generation tasks such as summarization or translation,
    traditional assessment metrics evaluate generated texts relative to gold standard
    manual references Lin ([2004](#bib.bib23)); Banerjee and Lavie ([2005](#bib.bib2));
    Zhang et al. ([2019](#bib.bib47)). These methods, however, tend to correlate weakly
    with human assessments. Following work designed automatic evaluation system systems
    for particular domains and attributes. Examples include systems for dialogue assessment
    Mehri and Eskenazi ([2020](#bib.bib30)), question answering systems for summary
    consistency Wang et al. ([2020](#bib.bib41)); Manakul et al. ([2023](#bib.bib29)),
    boolean answering systems for general summary assessment Zhong et al. ([2022a](#bib.bib52))
    or neural frameworks for machine translation Rei et al. ([2020](#bib.bib36)).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 对于自然语言生成任务，如摘要或翻译，传统评估指标将生成的文本与黄金标准手动参考进行比较（Lin [2004](#bib.bib23)；Banerjee
    和 Lavie [2005](#bib.bib2)；Zhang 等人 [2019](#bib.bib47)）。然而，这些方法与人工评估的相关性较弱。随后，研究人员为特定领域和属性设计了自动评估系统。例如，用于对话评估的系统（Mehri
    和 Eskenazi [2020](#bib.bib30)），用于摘要一致性的问答系统（Wang 等人 [2020](#bib.bib41)；Manakul
    等人 [2023](#bib.bib29)），用于一般摘要评估的布尔问答系统（Zhong 等人 [2022a](#bib.bib52)），或用于机器翻译的神经框架（Rei
    等人 [2020](#bib.bib36)）。
- en: Zero-Shot Assessment with LLMs.
  id: totrans-29
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 零-shot 评估与 LLM。
- en: Although suitable for particular domains, these automatic evaluation methods
    cannot be applied to more general and unseen settings. With the rapidly improving
    ability of instruction-following LLMs, various works have proposed zero-shot approaches.
    These include prompting LLMs to provide absolute assessment scores Wang et al.
    ([2023a](#bib.bib42)); Liu et al. ([2023b](#bib.bib25)), comparing pairs of texts
    Liusie et al. ([2023](#bib.bib28)); Zheng et al. ([2023](#bib.bib51)) or through
    leveraging assigned output language model probabilities Fu et al. ([2023](#bib.bib10)),
    and in some cases demonstrating state-of-the-art correlations and outperforming
    performance of bespoke evaluation methods.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管适用于特定领域，这些自动评估方法无法应用于更一般和未见过的设置。随着指令跟随 LLM 能力的迅速提高，各种研究提出了零-shot 方法。这些方法包括提示
    LLM 提供绝对评估分数（Wang 等人，[2023a](#bib.bib42)）；Liu 等人 ([2023b](#bib.bib25))，比较文本对（Liusie
    等人，[2023](#bib.bib28)）；Zheng 等人 ([2023](#bib.bib51)) 或通过利用分配的输出语言模型概率（Fu 等人，[2023](#bib.bib10)），在某些情况下，展示了最先进的相关性和超越定制评估方法的性能。
- en: Adversarial Attacks on Generative Systems.
  id: totrans-31
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 对生成系统的对抗攻击。
- en: Traditionally, NLP attack literature focuses on attacking classification tasks (Alzantot
    et al., [2018](#bib.bib1); Garg and Ramakrishnan, [2020](#bib.bib12); Li et al.,
    [2020](#bib.bib22); Gao et al., [2018](#bib.bib11); Wang et al., [2019](#bib.bib44)).
    However, with the emergence of generative LLMs (Zhao et al., [2023](#bib.bib50)),
    there has been discussion around NLG adversarial attacks. A range of approaches
    seek to jailbreak LLMs, and circumvent inherent alignment to generate harmful
    content (Carlini et al., [2023](#bib.bib3)). Attacks can be categorized as input
    text perturbation optimization (Zou et al., [2023](#bib.bib58); Zhu et al., [2024](#bib.bib57);
    Lapid et al., [2023](#bib.bib21)); automated adversarial prompt learning (Mehrotra
    et al., [2023](#bib.bib31); Liu et al., [2023a](#bib.bib24); Chao et al., [2023](#bib.bib5);
    Jin et al., [2024](#bib.bib18)); human adversarial prompt learning (Wei et al.,
    [2023](#bib.bib45); Zeng et al., [2024](#bib.bib46); Liu et al., [2023c](#bib.bib26));
    or model configuration manipulation (Huang et al., [2024](#bib.bib15)). Beyond
    jailbreaking, other works look to extract sensitive data from LLMs (Nasr et al.,
    [2023](#bib.bib32); Carlini et al., [2020](#bib.bib4)), provoke misclassification (Zhu
    et al., [2023a](#bib.bib55)) or trick translation systems into making a change
    in perception (Raina and Gales, [2023](#bib.bib34); Sadrizadeh et al., [2023](#bib.bib38)).
    For assessment, although early research has explored attacking NLP assessment
    systems (Raina et al., [2020](#bib.bib35)), there has been no work on developing
    attacks for general LLM assessment models such as prompting LLama and GPT, and
    we are the first to conduct such a study.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，NLP攻击文献集中于攻击分类任务（Alzantot等人，[2018](#bib.bib1)；Garg和Ramakrishnan，[2020](#bib.bib12)；Li等人，[2020](#bib.bib22)；Gao等人，[2018](#bib.bib11)；Wang等人，[2019](#bib.bib44)）。然而，随着生成性LLM的出现（Zhao等人，[2023](#bib.bib50)），有关NLG对抗攻击的讨论开始增加。一系列方法试图破解LLM，并绕过固有对齐以生成有害内容（Carlini等人，[2023](#bib.bib3)）。攻击可以分类为输入文本扰动优化（Zou等人，[2023](#bib.bib58)；Zhu等人，[2024](#bib.bib57)；Lapid等人，[2023](#bib.bib21)）；自动对抗提示学习（Mehrotra等人，[2023](#bib.bib31)；Liu等人，[2023a](#bib.bib24)；Chao等人，[2023](#bib.bib5)；Jin等人，[2024](#bib.bib18)）；人类对抗提示学习（Wei等人，[2023](#bib.bib45)；Zeng等人，[2024](#bib.bib46)；Liu等人，[2023c](#bib.bib26)）；或模型配置操控（Huang等人，[2024](#bib.bib15)）。除了破解之外，其他工作还探讨了从LLM中提取敏感数据（Nasr等人，[2023](#bib.bib32)；Carlini等人，[2020](#bib.bib4)）、引发错误分类（Zhu等人，[2023a](#bib.bib55)）或欺骗翻译系统以改变感知（Raina和Gales，[2023](#bib.bib34)；Sadrizadeh等人，[2023](#bib.bib38)）。对于评估，尽管早期研究探索了攻击NLP评估系统（Raina等人，[2020](#bib.bib35)），但尚无关于针对通用LLM评估模型如LLama和GPT的攻击开发的工作，我们是首次进行此类研究。
- en: 3 Zero-shot Assessment with LLMs
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 零样本评估与LLMs
- en: 'As discussed by Zhu et al. ([2023b](#bib.bib56)); Liusie et al. ([2023](#bib.bib28)),
    there are two standard reference-free methods of prompting instruction-tuned LLMs
    for quality assessment:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 正如Zhu等人（[2023b](#bib.bib56)）和Liusie等人（[2023](#bib.bib28)）所讨论的那样，存在两种标准的无参考方法来提示调整后的LLM进行质量评估：
- en: •
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: LLM Comparative Assessment where the system uses pairwise comparisons to determine
    which of two responses are better.
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LLM比较评估，其中系统使用成对比较来确定两个回应中哪个更好。
- en: •
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: LLM Absolute Scoring where an LLM is asked to assign an absolute score to each
    considered text.
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LLM绝对评分，其中LLM被要求为每个考虑的文本分配一个绝对分数。
- en: For various assessment methods, we consider rankings tasks where given a query
    context  responses . An effective LLM judge should predict scores for each candidate
    that match the ranking $r_{1:N}$ of the text’s true quality. This section will
    further discuss the details of both comparative assessment (Section [3.1](#S3.SS1
    "3.1 Comparative Assessment ‣ 3 Zero-shot Assessment with LLMs ‣ Is LLM-as-a-Judge
    Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment"))
    and absolute assessment (Section [3.2](#S3.SS2 "3.2 Absolute Assessment ‣ 3 Zero-shot
    Assessment with LLMs ‣ Is LLM-as-a-Judge Robust? Investigating Universal Adversarial
    Attacks on Zero-shot LLM Assessment")).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 对于各种评估方法，我们考虑给定查询上下文的排名任务。一个有效的LLM评判者应该预测每个候选项的分数，这些分数与文本的真实质量排名$r_{1:N}$相匹配。本节将进一步讨论比较评估（第[3.1节](#S3.SS1
    "3.1 Comparative Assessment ‣ 3 Zero-shot Assessment with LLMs ‣ Is LLM-as-a-Judge
    Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment")）和绝对评估（第[3.2节](#S3.SS2
    "3.2 Absolute Assessment ‣ 3 Zero-shot Assessment with LLMs ‣ Is LLM-as-a-Judge
    Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment")）的详细信息。
- en: 3.1 Comparative Assessment
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 比较评估
- en: An LLM prompted for comparative assessment,  and two candidate responses, ,
    to account for positional bias Liusie et al. ([2023](#bib.bib28)); Wang et al.
    ([2023b](#bib.bib43)) one can run comparisons over both orderings and average
    the probabilities to predict the probability that response ,
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一个被提示进行比较评估的 LLM，以及两个候选响应，为了考虑位置偏差 Liusie 等人（[2023](#bib.bib28)）；Wang 等人（[2023b](#bib.bib43)）可以对两个排序进行比较，并平均概率，以预测响应的概率。
- en: '|  | $p_{ij}=\frac{1}{2}\big{(}\mathcal{F}(\mathbf{x}_{i},\mathbf{x}_{j},\mathbf{d})+(1-\mathcal{F}(\mathbf{x}_{j},\mathbf{x}_{i},\mathbf{d}))\big{)}$
    |  | (1) |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '|  | $p_{ij}=\frac{1}{2}\big{(}\mathcal{F}(\mathbf{x}_{i},\mathbf{x}_{j},\mathbf{d})+(1-\mathcal{F}(\mathbf{x}_{j},\mathbf{x}_{i},\mathbf{d}))\big{)}$
    |  | (1) |'
- en: Note that by doing two inference passes of the model, symmetry is ensured such
    that . The average comparative probability for each option ,
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，通过对模型进行两次推理，确保了对称性。每个选项的平均比较概率，
- en: '|  | $\hat{s}_{n}=\hat{s}(\mathbf{x}_{n})=\frac{1}{N}\sum_{j=1}^{N}p_{nj},$
    |  | (2) |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '|  | $\hat{s}_{n}=\hat{s}(\mathbf{x}_{n})=\frac{1}{N}\sum_{j=1}^{N}p_{nj},$
    |  | (2) |'
- en: which can be converted to ranks .
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以转换为排名。
- en: 3.2 Absolute Assessment
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 绝对评估
- en: In LLM absolute scoring, the LLM, $\mathcal{F}$, is prompted to directly predict
    an absolute score. The prompt is designed to request the LLM to assess the quality
    of a text with a score (e.g. between 1-5). Two variants of absolute assessment
    can be applied; first where the score is directly predicted by the LLM,
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在 LLM 绝对评分中，LLM，$\mathcal{F}$，被提示直接预测一个绝对分数。提示设计为请求 LLM 评估文本的质量，并给出分数（例如，1-5）。可以应用两种绝对评估变体；第一种是由
    LLM 直接预测分数，
- en: '|  | $\hat{s}_{n}=\hat{s}(\mathbf{x}_{n})=\mathcal{F}(\mathbf{x}_{n},\mathbf{d}).$
    |  | (3) |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '|  | $\hat{s}_{n}=\hat{s}(\mathbf{x}_{n})=\mathcal{F}(\mathbf{x}_{n},\mathbf{d}).$
    |  | (3) |'
- en: Alternatively, following G-Eval Liu et al. ([2023b](#bib.bib25)), if the output
    logits are accessible one can estimate the expected score through a fair-average
    by multiplying each score by its normalized probability,
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，参考 G-Eval Liu 等人（[2023b](#bib.bib25)），如果输出 logits 可用，则可以通过将每个分数乘以其归一化概率来估计期望分数，
- en: '|  | $\hat{s}_{n}=\hat{s}(\mathbf{x}_{n})=\sum_{k=1:K}kP_{\mathcal{F}}(k&#124;\mathbf{x}_{n},\mathbf{d}),$
    |  | (4) |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '|  | $\hat{s}_{n}=\hat{s}(\mathbf{x}_{n})=\sum_{k=1:K}kP_{\mathcal{F}}(k|\mathbf{x}_{n},\mathbf{d}),$
    |  | (4) |'
- en: where  is normalized to satisfy basic probability rules, , $\forall n$.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 其中是归一化的，以满足基本概率规则，$\forall n$。
- en: 4 Adversarial Assessment Attacks
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 对抗性评估攻击
- en: 4.1 Attack Objective
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 攻击目标
- en: For typical adversarial attacks, an adversary aims to minimally modify the input
    text  is a small perturbation on the input ,
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对于典型的对抗攻击，攻击者旨在最小化地修改输入文本，这是对输入的微小扰动，
- en: '|  | $\mathcal{F}(\mathbf{x}+\bm{\delta})\neq\mathcal{F}(\mathbf{x}),$ |  |
    (5) |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{F}(\mathbf{x}+\bm{\delta})\neq\mathcal{F}(\mathbf{x}),$ |  |
    (5) |'
- en: The small perturbation, . Our work considers applying simple concatenative attacks
    to assessment LLMs, where a phrase  is added to the original text $\mathbf{x}$,
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 微小扰动。我们的工作考虑对评估 LLM 进行简单的串联攻击，其中将短语添加到原始文本 $\mathbf{x}$，
- en: '|  | $\mathbf{x}+\bm{\delta}=x_{1},\ldots,x_{&#124;\mathbf{x}&#124;},\delta_{1},\ldots,\delta_{L}$
    |  | (6) |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbf{x}+\bm{\delta}=x_{1},\ldots,x_{|\mathbf{x}|},\delta_{1},\ldots,\delta_{L}$
    |  | (6) |'
- en: The attack objective is to then maximally improve the rank of the attacked candidate
    response with respect to the other candidates. Let , when no other response in
    $\mathbf{x}_{1:N}$ is perturbed,
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击目标是最大化攻击候选响应相对于其他候选响应的排名。当 $\mathbf{x}_{1:N}$ 中没有其他响应被扰动时，
- en: '|  | $\hat{r}^{\prime}_{i}(\bm{\delta})=\texttt{rank}_{i}\left(\hat{s}(\mathbf{x}_{1}),\ldots,\hat{s}(\mathbf{x}_{i}+\bm{\delta}),\ldots,\hat{s}(\mathbf{x}_{N})\right)$
    |  |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '|  | $\hat{r}^{\prime}_{i}(\bm{\delta})=\texttt{rank}_{i}\left(\hat{s}(\mathbf{x}_{1}),\ldots,\hat{s}(\mathbf{x}_{i}+\bm{\delta}),\ldots,\hat{s}(\mathbf{x}_{N})\right)$
    |  |'
- en: The adversarial objective is to minimize the predicted rank of candidate $i$
    (i.e. the attacked sample) relative to the other unattacked candidates,
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗性目标是最小化候选 $i$（即被攻击样本）相对于其他未被攻击的候选项的预测排名，
- en: '|  | $\bm{\delta}^{*}_{i}=\operatorname*{arg\,min}_{\bm{\delta}}(\hat{r}^{\prime}_{i}(\bm{\delta})).$
    |  | (7) |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '|  | $\bm{\delta}^{*}_{i}=\operatorname*{arg\,min}_{\bm{\delta}}(\hat{r}^{\prime}_{i}(\bm{\delta})).$
    |  | (7) |'
- en: In an assessment setting, it is impractical for adversaries to learn an adversarial
    example . Much more practical is to use a universal adversarial example  to consistently
    boost the predicted assessment rank. Assuming a training set of  candidate responses
    per context,  is the one that most improves the expected rank when attacking each
    candidate in turn,
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估设置中，敌手学习对抗样本是不现实的。更实际的是使用通用对抗样本，以持续提升预测评估排名。假设训练集中每个上下文有 个候选响应，则是当攻击每个候选时，最能提高预期排名的那个，
- en: '|  |  |  | (8) |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (8) |'
- en: '|  |  |  | (9) |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (9) |'
- en: Where the average is computed over all  candidates.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 其中平均值是对所有  个候选者计算的。
- en: 4.2 Practical Attack Approach
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 实用攻击方法
- en: In this work, we use a simple greedy search to learn the universal attack phrase ²²2We
    also carried out experiments using the Greedy Coordinate Gradient (GCG) attack (Zou
    et al., [2023](#bib.bib58)) to learn the universal attack phrase, but this approach
    was found to be not as effective as the greedy search process. Results for GCG
    experiments are provided in Appendix [C](#A3 "Appendix C Greedy Coordinate Gradient
    (GCG) Universal Attack ‣ Is LLM-as-a-Judge Robust? Investigating Universal Adversarial
    Attacks on Zero-shot LLM Assessment").. For a vocabulary, $\mathcal{V}$ the greedy
    search finds the most effective adversarial word to append iteratively,
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在本工作中，我们使用简单的贪婪搜索来学习通用攻击短语 ²²2我们还进行了使用贪婪坐标梯度（GCG）攻击 （Zou et al., [2023](#bib.bib58)）来学习通用攻击短语的实验，但发现这种方法不如贪婪搜索过程有效。GCG
    实验的结果见附录 [C](#A3 "附录 C 贪婪坐标梯度（GCG）通用攻击 ‣ LLM 作为评判者的稳健性？调查零样本 LLM 评估上的通用对抗攻击")。对于词汇表，$\mathcal{V}$，贪婪搜索迭代地找到最有效的对抗词汇，
- en: '|  | $\displaystyle\delta^{*}_{l+1}=\operatorname*{arg\,min}_{\delta\in\mathcal{V}}(\bar{r}(\delta^{*}_{1:l}+\delta)).$
    |  | (10) |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\delta^{*}_{l+1}=\operatorname*{arg\,min}_{\delta\in\mathcal{V}}(\bar{r}(\delta^{*}_{1:l}+\delta)).$
    |  | (10) |'
- en: In practice, it may be computationally too expensive to compute the average
    rank (as specified in Equation [8](#S4.E8 "In 4.1 Attack Objective ‣ 4 Adversarial
    Assessment Attacks ‣ Is LLM-as-a-Judge Robust? Investigating Universal Adversarial
    Attacks on Zero-shot LLM Assessment")). Therefore, we instead approximate the
    search by greedily finding the token that maximises the expected score when appended
    to the current sample,
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，计算平均排名可能计算开销过大（如方程 [8](#S4.E8 "在 4.1 攻击目标 ‣ 4 对抗评估攻击 ‣ LLM 作为评判者的稳健性？调查零样本
    LLM 评估上的通用对抗攻击") 中所指定）。因此，我们改为贪婪地寻找在当前样本中附加时能最大化期望分数的令牌，
- en: '|  |  |  |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |'
- en: Algorithm 1 Greedy Search Universal Attack for Comparative Assessment
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 1 贪婪搜索通用攻击用于比较评估
- en: Training Data Target Model do      Select candidate indices       do         
    trial attack phrase          do                             then                $\triangleright$
    Update attack phraseend for
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据 目标模型 do      选择候选索引       do          尝试攻击短语          do                             then                $\triangleright$
    更新攻击短语end for
- en: Algorithm 2 Greedy Search Universal Attack for Absolute Assessment
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 2 贪婪搜索通用攻击用于绝对评估
- en: Training Data Target Model do      Select candidate index       do         
    trial attack phrase          do                       end for         if               
    Update best attack word         end if     end for      Update attack phraseend for
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据 目标模型 do      选择候选索引       do          尝试攻击短语          do                       end for         if               
    更新最佳攻击词汇         end if     end for      更新攻击短语end for
- en: 5 Experimental Setup
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 实验设置
- en: 5.1 Datasets
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 数据集
- en: We run experiments on two standard language generation evaluation benchmark
    datasets. The first dataset used is SummEval Fabbri et al. ([2021](#bib.bib9)),
    which is a summary evaluation benchmark of 100 passages, with 16 machine-generated
    summaries per passage. Each summary is evaluated by human assessors on coherency
    (COH), consistency (CON), fluency (FLU) and relevance (REL). These attributes
    can be combined into an overall score (OVE), which is the average of all the individual
    attributes. The second dataset is TopicalChat Gopalakrishnan et al. ([2019](#bib.bib14)),
    which is a benchmark for dialogue evaluation. There are 60 dialogue contexts,
    where each context has 6 different machine-generated responses. The responses
    are assessed by human evaluators on coherency (COH), continuity (CNT), engagingness
    (ENG), naturalness (NAT), where again the overall score (OVE) can be computed
    as the average of the individual attributes.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在两个标准语言生成评估基准数据集上进行了实验。第一个数据集是SummEval Fabbri等人（[2021](#bib.bib9)），这是一个包含100个文档的摘要评估基准，每个文档有16个机器生成的摘要。每个摘要由人工评估人员在连贯性（COH）、一致性（CON）、流畅性（FLU）和相关性（REL）方面进行评估。这些属性可以合并为一个总体得分（OVE），即所有个别属性的平均值。第二个数据集是TopicalChat
    Gopalakrishnan等人（[2019](#bib.bib14)），这是一个对话评估基准。共有60个对话上下文，每个上下文有6个不同的机器生成回复。回复由人工评估人员在连贯性（COH）、连续性（CNT）、吸引力（ENG）、自然性（NAT）方面进行评估，在此总体得分（OVE）同样可以作为所有个别属性的平均值计算。
- en: 5.2 LLM Assessment Systems
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 LLM评估系统
- en: We investigate a range of standard instruction-tuned generative language models
    in our experiments; FlanT5-xl (3B parameters) Chung et al. ([2022](#bib.bib7));
    Llama2-7B-chat Touvron et al. ([2023](#bib.bib40)); Mistral-7B-chat Jiang et al.
    ([2023](#bib.bib17)) and GPT3.5 (175B parameters). For both comparative and absolute
    assessment, we perform all attacks on FlanT5-xl. Our prompts for comparative assessment
    follow the prompts used in Liusie et al. ([2023](#bib.bib28)), where different
    attributes use different adjectives in the prompt. For absolute assessment we
    follow the prompts of G-Eval Liu et al. ([2023b](#bib.bib25)) and use continuous
    scores (Equation [4](#S3.E4 "In 3.2 Absolute Assessment ‣ 3 Zero-shot Assessment
    with LLMs ‣ Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks
    on Zero-shot LLM Assessment")) by calculating the expected score over a score
    range (e.g. 1-5 normalized by their probabilities). Note that the GPT3.5 API does
    not give token probabilities, and so for GPT3.5 we use standard prompt scoring
    (Equation [3](#S3.E3 "In 3.2 Absolute Assessment ‣ 3 Zero-shot Assessment with
    LLMs ‣ Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on
    Zero-shot LLM Assessment")).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在实验中调查了一系列标准指令调优生成语言模型；FlanT5-xl（3B参数）Chung等人（[2022](#bib.bib7)）；Llama2-7B-chat
    Touvron等人（[2023](#bib.bib40)）；Mistral-7B-chat Jiang等人（[2023](#bib.bib17)）以及GPT3.5（175B参数）。对于比较评估和绝对评估，我们在FlanT5-xl上执行所有攻击。我们的比较评估提示遵循Liusie等人（[2023](#bib.bib28)）使用的提示，其中不同的属性在提示中使用不同的形容词。对于绝对评估，我们遵循G-Eval
    Liu等人（[2023b](#bib.bib25)）的提示，并通过计算分数范围内的预期分数（例如1-5按其概率归一化）使用连续分数（方程[4](#S3.E4
    "In 3.2 Absolute Assessment ‣ 3 Zero-shot Assessment with LLMs ‣ Is LLM-as-a-Judge
    Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment")）。请注意，GPT3.5
    API不提供令牌概率，因此对于GPT3.5，我们使用标准提示评分（方程[3](#S3.E3 "In 3.2 Absolute Assessment ‣ 3
    Zero-shot Assessment with LLMs ‣ Is LLM-as-a-Judge Robust? Investigating Universal
    Adversarial Attacks on Zero-shot LLM Assessment")）。
- en: 5.3 Methodology
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 方法论
- en: Each dataset is split into a development set and a test set following a 20:80
    ratio. We use the development set (20% of the passages) to learn the attack phrase
    using the simple greedy search to maximise the expected score of the attacked
    sample (§[4.2](#S4.SS2 "4.2 Practical Attack Approach ‣ 4 Adversarial Assessment
    Attacks ‣ Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks
    on Zero-shot LLM Assessment")) and evaluate using the test set (80% of the passages).
    Furthermore, we only use two of the candidate texts to learn the attacks (i.e.
    2 of 16 for SummEval and 2 of 6 for topical chat), and therefore perform the search
    over a modest 40 summaries for SummEval and 24 responses for TopicalChat.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 每个数据集都按照20:80的比例分为开发集和测试集。我们使用开发集（20%的文档）来利用简单的贪婪搜索学习攻击短语，以最大化被攻击样本的预期分数（§[4.2](#S4.SS2
    "4.2 Practical Attack Approach ‣ 4 Adversarial Assessment Attacks ‣ Is LLM-as-a-Judge
    Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment")），并使用测试集（80%的文档）进行评估。此外，我们仅使用两个候选文本来学习攻击（即SummEval的16个中的2个和TopicalChat的6个中的2个），因此对SummEval进行的搜索仅涵盖40个摘要，对TopicalChat进行的搜索则涵盖24个回复。
- en: 'We learn a single universal attack phrase on the target model, which we keep
    as FlanT5-xl for all learned phrases. We perform a separate universal concatenation
    attack for each dataset and attribute, and use the notation ({TASK} {ASSESSMENT}
    {ATTRIBUTE}) to indicate the task, the assessment type and the evaluation attribute
    for each learnt universal attack phrase. We specifically consider the following
    configurations: (SUMM COMP OVE); (TOPIC COMP OVE); (SUMM ABS OVE); (TOPIC ABS
    OVE); (SUMM COMP CON); (TOPIC COMP CNT); (SUMM ABS CON); (TOPIC ABS CNT) ³³3The
    learnt universal attack phrases for each configuration are given in Appendix [A](#A1
    "Appendix A Universal Adversarial Phrases ‣ Is LLM-as-a-Judge Robust? Investigating
    Universal Adversarial Attacks on Zero-shot LLM Assessment").. The specific attributes
    CON and CNT are selected due to the smallest performance difference in comparative
    and absolute assessment (Tables [1](#S6.T1 "Table 1 ‣ 6.1 Assessment Performance
    ‣ 6 Results ‣ Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks
    on Zero-shot LLM Assessment") and [2](#S6.T2 "Table 2 ‣ 6.1 Assessment Performance
    ‣ 6 Results ‣ Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks
    on Zero-shot LLM Assessment")). The attack phrases are then assessed on transferability
    to the other target models; Mistral-7B, Lllama2-7B, GPT3.5\. The vocabulary for
    the greedy attack is sourced from the NLTK python package ⁴⁴4English words corpus
    is sourced from: nltk.corpus.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们学习了一个通用的攻击短语，并将其保留为 FlanT5-xl 用于所有学习的短语。我们对每个数据集和属性执行单独的通用串联攻击，并使用符号 ({TASK}
    {ASSESSMENT} {ATTRIBUTE}) 来表示每个学习的通用攻击短语的任务、评估类型和评估属性。我们特别考虑以下配置：（SUMM COMP OVE）；（TOPIC
    COMP OVE）；（SUMM ABS OVE）；（TOPIC ABS OVE）；（SUMM COMP CON）；（TOPIC COMP CNT）；（SUMM
    ABS CON）；（TOPIC ABS CNT）³³3每个配置的学习通用攻击短语详见附录 [A](#A1 "附录 A 通用对抗短语 ‣ LLM-as-a-Judge
    是否具有鲁棒性？研究零样本 LLM 评估中的通用对抗攻击")。选择特定属性 CON 和 CNT 是因为它们在比较评估和绝对评估中的性能差异最小（表 [1](#S6.T1
    "表 1 ‣ 6.1 评估性能 ‣ 6 结果 ‣ LLM-as-a-Judge 是否具有鲁棒性？研究零样本 LLM 评估中的通用对抗攻击") 和 [2](#S6.T2
    "表 2 ‣ 6.1 评估性能 ‣ 6 结果 ‣ LLM-as-a-Judge 是否具有鲁棒性？研究零样本 LLM 评估中的通用对抗攻击")）。然后，对攻击短语在其他目标模型上的转移性进行评估；Mistral-7B、Lllama2-7B、GPT3.5。贪婪攻击的词汇来自
    NLTK python 包⁴⁴4英语单词语料库来自：nltk.corpus。
- en: 5.4 Attack Evaluation
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 攻击评估
- en: To assess the success of an attack phrase, and for comparing the performance
    between comparative and absolute, we calculate the average rank of each candidate
    after an attack is applied (Equation [8](#S4.E8 "In 4.1 Attack Objective ‣ 4 Adversarial
    Assessment Attacks ‣ Is LLM-as-a-Judge Robust? Investigating Universal Adversarial
    Attacks on Zero-shot LLM Assessment")). An unsuccessful attack will yield a rank
    near the average rank, while a very strong attack will provide an average rank
    of 1 (where each attacked candidate is assumed to be the best of all unattacked
    candidates of the context).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估攻击短语的成功，并比较比较评估和绝对评估之间的表现，我们计算每个候选者在应用攻击后平均排名（公式 [8](#S4.E8 "在 4.1 攻击目标
    ‣ 4 对抗评估攻击 ‣ LLM-as-a-Judge 是否具有鲁棒性？研究零样本 LLM 评估中的通用对抗攻击")）。一个不成功的攻击将产生接近平均排名的结果，而一个非常强的攻击将提供平均排名为
    1（假设每个被攻击的候选者是所有未攻击候选者中的最佳）。
- en: 6 Results
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结果
- en: '![Refer to caption](img/c17ea1e13bbd6f976c090de7db37ba3f.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c17ea1e13bbd6f976c090de7db37ba3f.png)'
- en: (a) SummEval
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: (a) SummEval
- en: '![Refer to caption](img/92f578c190a0154a6fb72432ead716b0.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/92f578c190a0154a6fb72432ead716b0.png)'
- en: (b) TopicalChat
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: (b) TopicalChat
- en: 'Figure 2: Universal Attack Evaluation (average rank of attacked summary/response)
    for FlanT5-xl.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：FlanT5-xl 的通用攻击评估（被攻击的摘要/响应的平均排名）。
- en: 6.1 Assessment Performance
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 评估性能
- en: '| Assessment | Model | OVE | COH | FLU | CON |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 评估 | 模型 | OVE | COH | FLU | CON |'
- en: '| Comparative | FlanT5-xl | 54.6 | 51.2 | 32.5 | 47.1 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 比较 | FlanT5-xl | 54.6 | 51.2 | 32.5 | 47.1 |'
- en: '|  | Llama2-7b | 31.4 | 28.2 | 23.0 | 27.5 |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '|  | Llama2-7b | 31.4 | 28.2 | 23.0 | 27.5 |'
- en: '|  | Mistral-7b | 25.1 | 27.6 | 21.1 | 27.1 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '|  | Mistral-7b | 25.1 | 27.6 | 21.1 | 27.1 |'
- en: '| Absolute | FlanT5-xl | 24.6 | 27.0 | 16.6 | 37.7 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 绝对 | FlanT5-xl | 24.6 | 27.0 | 16.6 | 37.7 |'
- en: '|  | Llama2-7b | 25.0 | 28.2 | 23.0 | 29.4 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '|  | Llama2-7b | 25.0 | 28.2 | 23.0 | 29.4 |'
- en: '|  | Mistral-7b | 10.2 | 14.3 | 10.5 | 7.1 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '|  | Mistral-7b | 10.2 | 14.3 | 10.5 | 7.1 |'
- en: '|  | GPT3.5 | 52.5 | 45.1 | 38.0 | 43.2 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '|  | GPT3.5 | 52.5 | 45.1 | 38.0 | 43.2 |'
- en: 'Table 1: Zero-shot performance (Spearman correlation coefficient) on SummEval.
    Due to cost GPT3.5 was not evaluated for comparative assessment.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：SummEval 的零样本性能（Spearman 相关系数）。由于成本问题，GPT3.5 没有进行比较评估。
- en: '| Assessment | Model | OVE | COH | CNT | ENG |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 评估 | 模型 | OVE | COH | CNT | ENG |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Comparative | FlanT5-xl | 38.8 | 47.8 | 43.5 | 34.9 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 比较 | FlanT5-xl | 38.8 | 47.8 | 43.5 | 34.9 |'
- en: '|  | Llama2-7b | 34.5 | 35.2 | 37.1 | 32.0 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '|  | Llama2-7b | 34.5 | 35.2 | 37.1 | 32.0 |'
- en: '|  | Mistral-7b | 38.6 | 33.1 | 36.1 | 33.3 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '|  | Mistral-7b | 38.6 | 33.1 | 36.1 | 33.3 |'
- en: '|  | GPT3.5 | - | - | - | - |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '|  | GPT3.5 | - | - | - | - |'
- en: '| Absolute | FlanT5-xl | 36.2 | 31.4 | 43.2 | 34.9 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 绝对 | FlanT5-xl | 36.2 | 31.4 | 43.2 | 34.9 |'
- en: '|  | Llama2-7b | 37.1 | 28.7 | 20.0 | 32.9 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '|  | Llama2-7b | 37.1 | 28.7 | 20.0 | 32.9 |'
- en: '|  | Mistral-7b | 51.7 | 32.2 | 37.10 | 33.5 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '|  | Mistral-7b | 51.7 | 32.2 | 37.10 | 33.5 |'
- en: '|  | GPT3.5 | 56.2 | 54.7 | 57.7 | 49.1 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '|  | GPT3.5 | 56.2 | 54.7 | 57.7 | 49.1 |'
- en: 'Table 2: Performance (Spearman correlation coefficient) on TopicalChat. Due
    to cost GPT3.5 was not evaluated for comparative assessment.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：TopicalChat上的性能（斯皮尔曼相关系数）。由于成本原因，GPT3.5未进行比较评估。
- en: Tables [1](#S6.T1 "Table 1 ‣ 6.1 Assessment Performance ‣ 6 Results ‣ Is LLM-as-a-Judge
    Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment")
    and [2](#S6.T2 "Table 2 ‣ 6.1 Assessment Performance ‣ 6 Results ‣ Is LLM-as-a-Judge
    Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment")
    present the assessment ability of each LLM when applied to comparative and absolute
    assessment for SummEval and TopicalChat. Consistent with literature, comparative
    assessment performs better than absolute assessment systems for most systems and
    attributes. However, this comes with greater computational complexity, as  inferences
    are required for absolute assessment. Smaller LLMs (FlanT5-xl, Llama2-7b and Mistral-7b)
    demonstrate reasonable performance on SummEval and TopicalChat, but larger models
    (GPT3.5) perform much better, and even when using simple absolute assessment,
    can outperform smaller models applying comparative assessment.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [1](#S6.T1 "表 1 ‣ 6.1 评估性能 ‣ 6 结果 ‣ LLM-as-a-Judge 的鲁棒性？调查零样本 LLM 评估中的普遍对抗攻击")
    和 [2](#S6.T2 "表 2 ‣ 6.1 评估性能 ‣ 6 结果 ‣ LLM-as-a-Judge 的鲁棒性？调查零样本 LLM 评估中的普遍对抗攻击")
    展示了每个 LLM 在 SummEval 和 TopicalChat 的比较和绝对评估中的能力。与文献一致，大多数系统和属性的比较评估表现优于绝对评估。然而，这带来了更大的计算复杂性，因为绝对评估需要进行推断。较小的
    LLM（FlanT5-xl、Llama2-7b 和 Mistral-7b）在 SummEval 和 TopicalChat 上表现合理，但较大的模型（GPT3.5）表现更好，即使使用简单的绝对评估，也能超越应用比较评估的较小模型。
- en: 6.2 Universal Adversarial Attacks
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 普遍对抗攻击
- en: Section [5.3](#S5.SS3 "5.3 Methodology ‣ 5 Experimental Setup ‣ Is LLM-as-a-Judge
    Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment")
    details the attack configuration and approach used to learn the universal attack
    phrases. Figure [2](#S6.F2 "Figure 2 ‣ 6 Results ‣ Is LLM-as-a-Judge Robust? Investigating
    Universal Adversarial Attacks on Zero-shot LLM Assessment") illustrates the impact
    the universal adversarial attack phrase can have for comparative and absolute
    assessments on SummEval and TopicalChat evaluation while using FlanT5-xl as the
    LLM assessment system. For Summeval we attack the overall score (OVE) and the
    consistency (CON) while for Topical-Chat we attack the overall score (OVE) and
    the continuity (CNT). The attributes CON and CNT were selected due to the similar
    observed performance of the absolute and comparative methods on these attributes.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 第 [5.3](#S5.SS3 "5.3 方法论 ‣ 5 实验设置 ‣ LLM-as-a-Judge 的鲁棒性？调查零样本 LLM 评估中的普遍对抗攻击")
    节详细描述了攻击配置和学习普遍攻击短语的方法。图 [2](#S6.F2 "图 2 ‣ 6 结果 ‣ LLM-as-a-Judge 的鲁棒性？调查零样本 LLM
    评估中的普遍对抗攻击") 展示了普遍对抗攻击短语对 SummEval 和 TopicalChat 评估的比较和绝对评估的影响，同时使用 FlanT5-xl
    作为 LLM 评估系统。对于 SummEval，我们攻击整体得分（OVE）和一致性（CON），对于 Topical-Chat，我们攻击整体得分（OVE）和连续性（CNT）。选择
    CON 和 CNT 属性是由于绝对方法和比较方法在这些属性上的表现相似。
- en: The success of the adversarial attacks is measured by the average ranks of the
    text after an attack. Figure [2](#S6.F2 "Figure 2 ‣ 6 Results ‣ Is LLM-as-a-Judge
    Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment")
    demonstrates that both comparative assessment and absolute assessment systems
    have some vulnerability to adversarial attacks, as the average rank decreases,
    and continues to decrease as more words are added to the attack phrase. However,
    absolute assessment systems are significantly more susceptible to universal adversarial
    attacks, and with just four universal attack words, the absolute assessment system
    will consistently provide a rank of 1 to nearly all input texts. Table [3](#S6.T3
    "Table 3 ‣ 6.2 Universal Adversarial Attacks ‣ 6 Results ‣ Is LLM-as-a-Judge Robust?
    Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment") provides
    the raw scores for comparative and absolute assessment, where we see that for
    absolute assessment, a universal attack phrase of 4 words will yield assessment
    scores on average near the maximum score of 5\. The specific universal attack
    phrases learnt for each task are given in Appendix [A](#A1 "Appendix A Universal
    Adversarial Phrases ‣ Is LLM-as-a-Judge Robust? Investigating Universal Adversarial
    Attacks on Zero-shot LLM Assessment").
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗攻击的成功通过攻击后文本的平均排名来衡量。图 [2](#S6.F2 "图 2 ‣ 6 结果 ‣ LLM作为裁判是否鲁棒？调查零样本LLM评估的通用对抗攻击")
    显示，比较评估和绝对评估系统都对对抗攻击有一定的脆弱性，因为平均排名下降，并且随着攻击短语中添加更多单词，排名继续下降。然而，绝对评估系统显著地更容易受到通用对抗攻击的影响，只需四个通用攻击单词，绝对评估系统就会始终对几乎所有输入文本提供排名为1的结果。表
    [3](#S6.T3 "表 3 ‣ 6.2 通用对抗攻击 ‣ 6 结果 ‣ LLM作为裁判是否鲁棒？调查零样本LLM评估的通用对抗攻击") 提供了比较评估和绝对评估的原始得分，其中我们看到，对于绝对评估，4个单词的通用攻击短语平均会得到接近最大分数5的评估分数。每个任务学到的具体通用攻击短语见附录
    [A](#A1 "附录 A 通用对抗短语 ‣ LLM作为裁判是否鲁棒？调查零样本LLM评估的通用对抗攻击")。
- en: '| Phrase | No Attack | Attack |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 短语 | 无攻击 | 攻击 |'
- en: '| --- | --- | --- |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| SUMM COMP OVE | 50.00 | 51.34 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| SUMM COMP OVE | 50.00 | 51.34 |'
- en: '| SUMM COMP CON | 50.00 | 57.10 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| SUMM COMP CON | 50.00 | 57.10 |'
- en: '| TOPIC COMP OVE | 50.00 | 53.94 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| TOPIC COMP OVE | 50.00 | 53.94 |'
- en: '| TOPIC COMP CNT | 50.00 | 54.06 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| TOPIC COMP CNT | 50.00 | 54.06 |'
- en: '| SUMM ABS OVE | 3.73 | 4.74 |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| SUMM ABS OVE | 3.73 | 4.74 |'
- en: '| SUMM ABS CON | 3.88 | 4.35 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| SUMM ABS CON | 3.88 | 4.35 |'
- en: '| TOPIC ABS OVE | 2.93 | 4.63 |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| TOPIC ABS OVE | 2.93 | 4.63 |'
- en: '| TOPIC ABS CNT | 3.02 | 4.32 |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| TOPIC ABS CNT | 3.02 | 4.32 |'
- en: 'Table 3: Scores for 4-word universal attacks on FlanT5-xl. Note that scores
    for comparative and absolute assessment are not comparable.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '表 3: FlanT5-xl 上 4 个单词的通用攻击得分。请注意，比较评估和绝对评估的得分不可比。'
- en: '![Refer to caption](img/137dd80d29e1ff3b7dafd5c5753439e5.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/137dd80d29e1ff3b7dafd5c5753439e5.png)'
- en: (a) SummEval
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: (a) SummEval
- en: '![Refer to caption](img/5fd45b3e48d2c466646f36188279080e.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/5fd45b3e48d2c466646f36188279080e.png)'
- en: (b) TopicalChat
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: (b) TopicalChat
- en: 'Figure 3: Transferability of universal attack phrases from FlanT5-xl to other
    models.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '图 3: 从 FlanT5-xl 到其他模型的通用攻击短语的可转移性。'
- en: The relative robustness of comparative assessment systems over absolute assessment
    systems can perhaps be explained intuitively. In an absolute assessment setting,
    an adversary exploits an input space which is not well understood by the model
    and identifies a region that spuriously encourages the model to predict a high
    score. However, in comparative assessment, the model is forced to compare the
    quality of the attacked text to another (unattacked) text, meaning the attack
    phrase learnt has to be invariant to the text used for comparison. This makes
    it more challenging to find an effective adversarial attack phrase. Further explanations
    for the relative robustness of comparative assessment systems are explored in
    Appendix [B](#A2 "Appendix B Analysis of Relative Robustness of Comparative Assessment
    ‣ Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot
    LLM Assessment").
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 比较评估系统相对于绝对评估系统的相对鲁棒性可以从直观上进行解释。在绝对评估环境中，攻击者利用模型不太了解的输入空间，识别出一个虚假的区域，该区域促使模型预测出较高的分数。然而，在比较评估中，模型被迫将攻击文本的质量与另一个（未被攻击的）文本进行比较，这意味着所学到的攻击短语必须对用于比较的文本保持不变。这使得找到有效的对抗攻击短语变得更加具有挑战性。比较评估系统相对鲁棒性的进一步解释见附录
    [B](#A2 "附录 B 比较评估的相对鲁棒性分析 ‣ LLM作为裁判是否鲁棒？调查零样本LLM评估的通用对抗攻击")。
- en: 6.3 Transferability
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3 可转移性
- en: Figure [2](#S6.F2 "Figure 2 ‣ 6 Results ‣ Is LLM-as-a-Judge Robust? Investigating
    Universal Adversarial Attacks on Zero-shot LLM Assessment") demonstrated that
    absolute assessment systems are highly vulnerable to a simple universal attack
    phrase concatenated to an input text. However, running an adversarial attack on
    black-box systems may not be feasible due to the large number of calls required
    for a greedy search, assuming a reasonable vocabulary of $|\mathcal{V}|\approx
    50,000$. To circumvent this issue, an adversary can learn the universal attack-phrase
    on a smaller open-source model (with no detectable limit on the number of model
    queries) and aim to transfer this attack phrase to other models (e.g., in Demontis
    et al. ([2018](#bib.bib8))).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图[2](#S6.F2 "图 2 ‣ 6 结果 ‣ LLM作为裁判是否稳健？调查零样本LLM评估中的通用对抗攻击") 表明绝对评估系统对简单的通用攻击短语拼接到输入文本中非常脆弱。然而，由于所需的贪婪搜索调用次数较多，假设词汇表的合理大小为$|\mathcal{V}|\approx
    50,000$，对黑箱系统进行对抗攻击可能不可行。为了绕过这个问题，对手可以在较小的开源模型上学习通用攻击短语（没有对模型查询次数的可检测限制），并试图将该攻击短语转移到其他模型上（例如，Demontis等人([2018](#bib.bib8))）。
- en: The previous universal attack phrases of Figure [2](#S6.F2 "Figure 2 ‣ 6 Results
    ‣ Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot
    LLM Assessment") was learned specifically for FlanT5-xl, which is a relatively
    poor-performing model. However, Flan-T5 is quite small (3B parameters); one may
    therefore consider whether attack phrases learned using this smaller model can
    generalize and deceive larger models. Figure [3](#S6.F3 "Figure 3 ‣ 6.2 Universal
    Adversarial Attacks ‣ 6 Results ‣ Is LLM-as-a-Judge Robust? Investigating Universal
    Adversarial Attacks on Zero-shot LLM Assessment") shows that 1) there can be a
    high level of attack transferability for absolute scoring. For TopicalChat, it
    appears that the attacks generalize very well to nearly all systems, with all
    systems being very susceptible to attacks when assessing continuity. 2) It appears
    that when more powerful models assess the overall (OVE) quality, there can be
    less effective transferability, suggesting that assessing more general, abstract
    qualities can be more robust. Further, interestingly it appears that powerful
    large models (GPT3.5) are more susceptible when attacked by shorter phrases, possibly
    as the longer phrase may begin to overfit to properties of the attacked model.
    3) The attack transfers with mixed success for Summeval, which may highlight that
    the complexity of dataset can influence attack transferability.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图[2](#S6.F2 "图 2 ‣ 6 结果 ‣ LLM作为裁判是否稳健？调查零样本LLM评估中的通用对抗攻击")中的通用攻击短语是专门为FlanT5-xl学习的，这是一种表现较差的模型。然而，Flan-T5相对较小（3B参数）；因此，人们可能会考虑使用这个较小模型学习的攻击短语是否能够推广并欺骗更大的模型。图[3](#S6.F3
    "图 3 ‣ 6.2 通用对抗攻击 ‣ 6 结果 ‣ LLM作为裁判是否稳健？调查零样本LLM评估中的通用对抗攻击")显示：1) 对于绝对评分，攻击的转移性可能很高。对于TopicalChat，攻击似乎很好地推广到几乎所有系统，当评估连贯性时，所有系统对攻击都非常敏感。2)
    当更强大的模型评估整体（OVE）质量时，攻击的转移性可能较差，这表明评估更一般、抽象的质量可能更为稳健。此外，有趣的是，强大的大型模型（GPT3.5）在短语较短时更容易受到攻击，可能是因为较长的短语可能开始过拟合被攻击模型的属性。3)
    对于Summeval，攻击的转移效果不一，这可能突出显示了数据集的复杂性可以影响攻击的转移性。
- en: '![Refer to caption](img/ac9d589467e5ead6c8bdc566e70164c6.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ac9d589467e5ead6c8bdc566e70164c6.png)'
- en: (a) SummEval
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: (a) SummEval
- en: '![Refer to caption](img/0a5c3f05dd9a77976976069c3cf808a8.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0a5c3f05dd9a77976976069c3cf808a8.png)'
- en: (b) TopicalChat
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: (b) TopicalChat
- en: 'Figure 4: Precision-Recall curve when applying perplexity as a detection defence'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：应用困惑度作为检测防御时的精准率-召回率曲线
- en: 6.4 Attack Detection
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.4 攻击检测
- en: 'In this section, we perform an initial investigation into possible defences
    that could be applied to detect if an adversary is exploiting a system. Defences
    can take two forms: adversarial training (Goodfellow et al., [2015](#bib.bib13))
    where the LLM is re-trained with adversarial examples, or adversarial attack detection
    where a separate module is designed to identify adversarial inputs. Although recent
    LLM adversarial training approaches have been proposed (Zhou et al., [2024](#bib.bib54);
    Zhang et al., [2023b](#bib.bib49)), re-training is computationally expensive and
    can harm model performance, hence detection is preferred. Recent detection approaches
    for NLG adversarial attacks tend to focus on attacks that circumvent LLM safety
    filters, e.g., generateing malicious content by jailbreaking (Liu et al., [2023c](#bib.bib26);
    Zou et al., [2023](#bib.bib58); Jin et al., [2024](#bib.bib18)). Robey et al.
    ([2023](#bib.bib37)) propose SmoothLLM, where multiple versions of the perturbed
    input are passed to an LLM and the outputs aggregated. Such defences are inappropriate
    for LLM-as-a-judge setups, as though the perturbations are designed to cause no
    semantic change, they can result in changes in other attributes, such as fluency
    and style, which will impact the LLM assessment. Similarly, Jain et al. ([2023](#bib.bib16));
    Kumar et al. ([2024](#bib.bib20)) propose defence approaches that involve some
    form of paraphrasing or filtering of the input sequence, which again interferes
    with the LLM-as-a-judge scores.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们对可能用于检测对手是否在利用系统的防御措施进行了初步调查。防御措施可以采取两种形式：对抗训练（Goodfellow et al., [2015](#bib.bib13)），即用对抗示例重新训练LLM，或对抗攻击检测，即设计一个独立模块来识别对抗输入。虽然最近已经提出了LLM对抗训练的方法（Zhou
    et al., [2024](#bib.bib54); Zhang et al., [2023b](#bib.bib49)），但重新训练计算成本高且可能损害模型性能，因此检测更为优选。最近针对NLG对抗攻击的检测方法往往集中在绕过LLM安全过滤器的攻击上，例如，通过越狱生成恶意内容（Liu
    et al., [2023c](#bib.bib26); Zou et al., [2023](#bib.bib58); Jin et al., [2024](#bib.bib18)）。Robey
    et al. ([2023](#bib.bib37)) 提出了SmoothLLM，其中将多个版本的扰动输入传递给LLM，并聚合输出。这类防御措施不适用于LLM作为裁判的设置，因为尽管这些扰动旨在不引起语义变化，但可能会导致其他属性（如流畅性和风格）的变化，从而影响LLM的评估。同样，Jain
    et al. ([2023](#bib.bib16)); Kumar et al. ([2024](#bib.bib20)) 提出了涉及某种形式的释义或过滤输入序列的防御方法，这同样干扰LLM作为裁判的评分。
- en: A simple and valid defence approach for LLM-as-a-judge is to use perplexity
    to detect adversarial examples (Jain et al., [2023](#bib.bib16); Raina et al.,
    [2020](#bib.bib35)). The perplexity is a measure of how unnatural a model, ,
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 对LLM作为裁判的简单有效的防御方法是使用困惑度来检测对抗示例（Jain et al., [2023](#bib.bib16); Raina et al.,
    [2020](#bib.bib35)）。困惑度是衡量模型不自然程度的指标，
- en: '|  | $\texttt{perp}=-\frac{1}{&#124;\mathbf{x}&#124;}\log(P_{\theta}(\mathbf{x})).$
    |  | (11) |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '|  | $\texttt{perp}=-\frac{1}{&#124;\mathbf{x}&#124;}\log(P_{\theta}(\mathbf{x})).$
    |  | (11) |'
- en: We use the base Mistral-7B model to compute perplexity. Adversarially attacked
    samples are expected to be less natural and have higher perplexity. Therefore,
    we can evaluate the detection performance using precision and recall. We select
    a specific threshold,  as clean or adversarial, where if  the sample would be classified
    as adversarial. The precision, recall and F1 is then
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用基础Mistral-7B模型来计算困惑度。对抗攻击样本预计会更不自然，困惑度更高。因此，我们可以使用精度和召回率来评估检测性能。我们选择一个特定的阈值，作为清洁或对抗样本，其中如果
     样本将被分类为对抗样本。然后，精度、召回率和F1是
- en: '|  | $\texttt{P}=\frac{\text{TP}}{\text{TP+FP}}\quad\texttt{R}=\frac{\text{TP}}{\text{TP+FN}}\quad
    F1=2\cdot\frac{\texttt{P}\cdot\texttt{R}}{\texttt{P}+\texttt{R}},$ |  |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '|  | $\texttt{P}=\frac{\text{TP}}{\text{TP+FP}}\quad\texttt{R}=\frac{\text{TP}}{\text{TP+FN}}\quad
    F1=2\cdot\frac{\texttt{P}\cdot\texttt{R}}{\texttt{P}+\texttt{R}},$ |  |'
- en: where FP, TP and FN are standard counts for False-Positive, True-Positive and
    False-Negative respectively. The F1 can be used as a single-value summary of detection
    performance.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 其中FP、TP和FN分别为假阳性、真阳性和假阴性的标准计数。F1可以用作检测性能的单值摘要。
- en: To assess detection, we evaluate on the test split of each dataset, augmented
    with the universal attack phrase concatenated to each text, such that there is
    balance between clean and adversarial examples. Figure [4](#S6.F4 "Figure 4 ‣
    6.3 Transferability ‣ 6 Results ‣ Is LLM-as-a-Judge Robust? Investigating Universal
    Adversarial Attacks on Zero-shot LLM Assessment") presents precision-recall (p-r)
    curves for perplexity detection as the threshold $\beta$ is swept, for the different
    universal adversarial phrases. Table [4](#S6.T4 "Table 4 ‣ 6.4 Attack Detection
    ‣ 6 Results ‣ Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks
    on Zero-shot LLM Assessment") gives the best F1 scores from the p-r curves. For
    SummEval all the F1 scores are near 0.7 or significantly above, whilst for TopicalChat
    the performance is generally even better. This demonstrates that perplexity is
    fairly effective in disentangling clean and adversarial samples for attacks on
    LLM-as-a-judge. However, Zhou et al. ([2024](#bib.bib54)) argue that defence approaches
    such as perplexity detection can be circumvented by adaptive adversarial attacks.
    Hence, though perplexity gives a promising starting point as a defence strategy,
    future work will explore other more sophisticated detection approaches. Nevertheless,
    it can also be concluded from the findings in this work that an effective defence
    against the most threatening adversarial attacks on LLM-as-a-judge is to use comparative
    assessment over absolute scoring, despite an increased computational cost.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估检测效果，我们在每个数据集的测试集上进行评估，并将通用攻击短语附加到每个文本中，以确保干净样本和对抗样本之间的平衡。图[4](#S6.F4 "Figure
    4 ‣ 6.3 Transferability ‣ 6 Results ‣ Is LLM-as-a-Judge Robust? Investigating
    Universal Adversarial Attacks on Zero-shot LLM Assessment")展示了在不同通用对抗短语下，当阈值$\beta$变化时，困惑度检测的精确度-召回率（p-r）曲线。表[4](#S6.T4
    "Table 4 ‣ 6.4 Attack Detection ‣ 6 Results ‣ Is LLM-as-a-Judge Robust? Investigating
    Universal Adversarial Attacks on Zero-shot LLM Assessment")给出了p-r曲线的最佳F1分数。对于SummEval，所有F1分数接近0.7或显著高于0.7，而对于TopicalChat，表现通常更好。这表明困惑度在区分LLM-as-a-judge的干净样本和对抗样本方面是相当有效的。然而，Zhou等人（[2024](#bib.bib54)）认为，困惑度检测等防御方法可能会被自适应对抗攻击绕过。因此，尽管困惑度作为防御策略具有良好的起点，但未来的工作将探索其他更复杂的检测方法。然而，从本研究的发现中也可以得出结论，对于LLM-as-a-judge最具威胁的对抗攻击，有效的防御策略是使用相对评估而不是绝对评分，尽管这会增加计算成本。
- en: '| Attack | precision | recall | F1 |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| Attack | precision | recall | F1 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Summ-CON-2 | 0.635 | 0.794 | 0.706 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| Summ-CON-2 | 0.635 | 0.794 | 0.706 |'
- en: '| Summ-CON-4 | 0.679 | 0.819 | 0.742 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| Summ-CON-4 | 0.679 | 0.819 | 0.742 |'
- en: '| Summ-OVE-2 | 0.539 | 0.988 | 69.6 |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| Summ-OVE-2 | 0.539 | 0.988 | 69.6 |'
- en: '| Summ-OVE-4 | 64.7 | 81.3 | 72.0 |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| Summ-OVE-4 | 64.7 | 81.3 | 72.0 |'
- en: '| Topic-CNT-2 | 66.2 | 84.4 | 81.7 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| Topic-CNT-2 | 66.2 | 84.4 | 81.7 |'
- en: '| Topic-CNT-4 | 74.8 | 79.5 | 77.1 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| Topic-CNT-4 | 74.8 | 79.5 | 77.1 |'
- en: '| Topic-OVE-2 | 75.2 | 78.8 | 76.9 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| Topic-OVE-2 | 75.2 | 78.8 | 76.9 |'
- en: '| Topic-OVE-4 | 78.5 | 85.1 | 81.7 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| Topic-OVE-4 | 78.5 | 85.1 | 81.7 |'
- en: 'Table 4: Best F1 (%) (precision, recall) for adversarial sample detection using
    perplexity. Attack phrases of length 2 words and 4 words considered.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 表4：使用困惑度进行对抗样本检测的最佳F1（%）（精确度，召回率）。考虑了长度为2个词和4个词的攻击短语。
- en: 7 Conclusions
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 结论
- en: This is the first work to examine the adversarial robustness of zero-shot LLM
    assessment methods against universal concatenation adversarial attacks. Our findings
    reveal vulnerabilities in both LLM comparative assessment and LLM scoring, with
    absolute assessment exhibiting particularly high susceptibility. Notably, we demonstrate
    that attacks devised on smaller systems can effectively transfer to larger ones,
    underscoring the need for defence strategies. Encouragingly, an initial investigation
    into detection defences, shows that perplexity can be a promising tool for identifying
    adversarially manipulated inputs. On the whole, this paper raises awareness around
    the susceptibility of LLM-as-a-judge NLG assessment systems to universal and transferable
    adversarial attacks. Further work can explore adaptive attacks and more sophisticated
    defence approaches to minimize the risk of misuse.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这是首次研究零-shot LLM评估方法对通用串联对抗攻击的对抗鲁棒性。我们的发现揭示了LLM比较评估和LLM评分的脆弱性，特别是绝对评估显示出较高的敏感性。值得注意的是，我们展示了在较小系统上设计的攻击可以有效转移到较大系统上，突显了防御策略的必要性。令人鼓舞的是，对检测防御的初步调查显示，困惑度可以成为识别对抗性操作输入的有前景的工具。总体而言，本文提高了对LLM-as-a-judge
    NLG评估系统对通用和可转移对抗攻击敏感性的认识。进一步的工作可以探索自适应攻击和更复杂的防御方法，以减少误用的风险。
- en: 8 Limitations
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 限制
- en: This paper investigates the vulnerability of LLM-as-a-judge methods in settings
    where malicious entities may wish to trick systems into returning inflated assessment
    scores. As the first work on the adversarial robustness of LLM assessment, we
    used simple attacks (concatenation attack found through a greedy search) which
    led to simple defences (perplexity). Future work can investigate methods of achieving
    more subtle attacks, which may require more complex defences to detect. Further,
    this work focuses on attacking zero-shot assessment methods, however, it is possible
    to use LLM assessment in few-shot settings, which may be more robust and render
    attacks less effective. Future work can explore this direction, and also investigate
    designing prompts that are more robust to attacks.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 本文研究了 LLM 作为评审的方法在恶意实体可能试图欺骗系统以返回夸大评估分数的设置下的脆弱性。作为对 LLM 评估对抗鲁棒性的首个研究，我们使用了简单的攻击（通过贪婪搜索发现的串联攻击），这导致了简单的防御（困惑度）。未来的工作可以研究实现更微妙攻击的方法，这可能需要更复杂的防御来检测。此外，本研究重点攻击零-shot
    评估方法，但也可以在 few-shot 设置中使用 LLM 评估，这可能更具鲁棒性，使攻击效果降低。未来的工作可以探索这一方向，并研究设计对攻击更鲁棒的提示。
- en: 9 Risks & Ethics
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9 风险与伦理
- en: This work reports on the topic of adversarial attacks, where it’s shown that
    a universal adversarial attack can fool NLG assessment systems into inflating
    scores of assessed texts. The methods and attacks proposed in this paper do not
    encourage any harmful content generation and the aim of the work is to raise awareness
    of the risk of adversarial manipulation for zero-shot NLG assessment. It is possible
    that highlighting these susceptibilities may inform adversaries of this vulnerability,
    however, we hope that raising awareness of these risks will encourage the community
    to further study the robustness of zero-shot LLM assessment methods and reduce
    the risk of future misuse.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究报告了对抗攻击的主题，展示了通用对抗攻击可以欺骗 NLG 评估系统，使其夸大评估文本的分数。本文提出的方法和攻击并不鼓励任何有害内容的生成，研究的目的是提高对零-shot
    NLG 评估对抗性操控风险的认识。高亮这些易受攻击的点可能会让对手了解到这种脆弱性，但我们希望提高对这些风险的认识能鼓励社区进一步研究零-shot LLM
    评估方法的鲁棒性，并降低未来误用的风险。
- en: 10 Acknowledgements
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10 致谢
- en: This work is supported by Cambridge University Press & Assessment (CUP&A), a
    department of The Chancellor, Masters, and Scholars of the University of Cambridge.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究得到了剑桥大学出版社与评估部门（CUP&A）的支持，这是剑桥大学校长、硕士及学者的一部分。
- en: References
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Alzantot et al. (2018) Moustafa Alzantot, Yash Sharma, Ahmed Elgohary, Bo-Jhang
    Ho, Mani Srivastava, and Kai-Wei Chang. 2018. [Generating natural language adversarial
    examples](https://doi.org/10.18653/v1/D18-1316). pages 2890–2896.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alzantot 等（2018）穆斯塔法·阿尔赞诺特、雅什·夏尔马、艾哈迈德·埃尔戈哈里、博-张·霍、马尼·斯里瓦斯塔瓦和凯-维·张。2018年。[生成自然语言对抗样本](https://doi.org/10.18653/v1/D18-1316)。第2890–2896页。
- en: 'Banerjee and Lavie (2005) Satanjeev Banerjee and Alon Lavie. 2005. [METEOR:
    An automatic metric for MT evaluation with improved correlation with human judgments](https://aclanthology.org/W05-0909).
    In *Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures
    for Machine Translation and/or Summarization*, pages 65–72, Ann Arbor, Michigan.
    Association for Computational Linguistics.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Banerjee 和 Lavie（2005）萨坦吉夫·班纳吉和阿隆·拉维。2005年。[METEOR：一种用于机器翻译评估的自动度量，改进了与人工判断的相关性](https://aclanthology.org/W05-0909)。在
    *ACL 机器翻译和/或摘要评估的内在与外在评估措施研讨会论文集*，第65–72页，安娜堡，密歇根州。计算语言学协会。
- en: Carlini et al. (2023) Nicholas Carlini, Milad Nasr, Christopher A. Choquette-Choo,
    Matthew Jagielski, Irena Gao, Anas Awadalla, Pang Wei Koh, Daphne Ippolito, Katherine
    Lee, Florian Tramer, and Ludwig Schmidt. 2023. [Are aligned neural networks adversarially
    aligned?](http://arxiv.org/abs/2306.15447)
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Carlini 等（2023）尼古拉斯·卡尔尼、米拉德·纳斯尔、克里斯托弗·A·肖克特-楚、马修·贾吉尔斯基、艾琳娜·高、阿纳斯·阿瓦达拉、庞伟·科赫、达芙妮·伊波利托、凯瑟琳·李、弗洛里安·特拉默和路德维希·施密特。2023年。[对齐的神经网络是否对抗对齐？](http://arxiv.org/abs/2306.15447)
- en: Carlini et al. (2020) Nicholas Carlini, Florian Tramèr, Eric Wallace, Matthew
    Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom B. Brown, Dawn
    Song, Úlfar Erlingsson, Alina Oprea, and Colin Raffel. 2020. [Extracting training
    data from large language models](http://arxiv.org/abs/2012.07805). *CoRR*, abs/2012.07805.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Carlini 等（2020）尼古拉斯·卡尔尼、弗洛里安·特拉默、埃里克·华莱士、马修·贾吉尔斯基、阿里尔·赫伯特-沃斯、凯瑟琳·李、亚当·罗伯茨、汤姆·B·布朗、道恩·宋、乌尔法·厄尔林松、阿丽娜·奥普雷亚和科林·拉费尔。2020年。[从大型语言模型中提取训练数据](http://arxiv.org/abs/2012.07805)。*CoRR*，abs/2012.07805。
- en: Chao et al. (2023) Patrick Chao, Alexander Robey, Edgar Dobriban, Hamed Hassani,
    George J. Pappas, and Eric Wong. 2023. [Jailbreaking black box large language
    models in twenty queries](http://arxiv.org/abs/2310.08419).
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chao 等（2023）Patrick Chao、Alexander Robey、Edgar Dobriban、Hamed Hassani、George
    J. Pappas 和 Eric Wong。2023。[Jailbreaking black box large language models in twenty
    queries](http://arxiv.org/abs/2310.08419)。
- en: 'Chen et al. (2023) Yi Chen, Rui Wang, Haiyun Jiang, Shuming Shi, and Ruifeng
    Xu. 2023. [Exploring the use of large language models for reference-free text
    quality evaluation: An empirical study](https://aclanthology.org/2023.findings-ijcnlp.32).
    In *Findings of the Association for Computational Linguistics: IJCNLP-AACL 2023
    (Findings)*, pages 361–374, Nusa Dua, Bali. Association for Computational Linguistics.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chen 等（2023）Yi Chen、Rui Wang、Haiyun Jiang、Shuming Shi 和 Ruifeng Xu。2023。[Exploring
    the use of large language models for reference-free text quality evaluation: An
    empirical study](https://aclanthology.org/2023.findings-ijcnlp.32)。在 *Findings
    of the Association for Computational Linguistics: IJCNLP-AACL 2023 (Findings)*，第361–374页，努沙杜瓦，巴厘岛。计算语言学协会。'
- en: Chung et al. (2022) Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay,
    William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al.
    2022. Scaling instruction-finetuned language models. *arXiv preprint arXiv:2210.11416*.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chung 等（2022）Hyung Won Chung、Le Hou、Shayne Longpre、Barret Zoph、Yi Tay、William
    Fedus、Yunxuan Li、Xuezhi Wang、Mostafa Dehghani、Siddhartha Brahma 等。2022。Scaling
    instruction-finetuned language models。*arXiv preprint arXiv:2210.11416*。
- en: Demontis et al. (2018) Ambra Demontis, Marco Melis, Maura Pintor, Matthew Jagielski,
    Battista Biggio, Alina Oprea, Cristina Nita-Rotaru, and Fabio Roli. 2018. [On
    the intriguing connections of regularization, input gradients and transferability
    of evasion and poisoning attacks](http://arxiv.org/abs/1809.02861). *CoRR*, abs/1809.02861.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Demontis 等（2018）Ambra Demontis、Marco Melis、Maura Pintor、Matthew Jagielski、Battista
    Biggio、Alina Oprea、Cristina Nita-Rotaru 和 Fabio Roli。2018。[On the intriguing connections
    of regularization, input gradients and transferability of evasion and poisoning
    attacks](http://arxiv.org/abs/1809.02861)。*CoRR*，abs/1809.02861。
- en: 'Fabbri et al. (2021) Alexander R Fabbri, Wojciech Kryściński, Bryan McCann,
    Caiming Xiong, Richard Socher, and Dragomir Radev. 2021. Summeval: Re-evaluating
    summarization evaluation. *Transactions of the Association for Computational Linguistics*,
    9:391–409.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Fabbri 等（2021）Alexander R Fabbri、Wojciech Kryściński、Bryan McCann、Caiming Xiong、Richard
    Socher 和 Dragomir Radev。2021。Summeval: Re-evaluating summarization evaluation。*Transactions
    of the Association for Computational Linguistics*，9:391–409。'
- en: 'Fu et al. (2023) Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, and Pengfei Liu.
    2023. Gptscore: Evaluate as you desire. *arXiv preprint arXiv:2302.04166*.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Fu 等（2023）Jinlan Fu、See-Kiong Ng、Zhengbao Jiang 和 Pengfei Liu。2023。Gptscore:
    Evaluate as you desire。*arXiv preprint arXiv:2302.04166*。'
- en: Gao et al. (2018) Ji Gao, Jack Lanchantin, Mary Lou Soffa, and Yanjun Qi. 2018.
    [Black-box generation of adversarial text sequences to evade deep learning classifiers](http://arxiv.org/abs/1801.04354).
    *CoRR*, abs/1801.04354.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao 等（2018）Ji Gao、Jack Lanchantin、Mary Lou Soffa 和 Yanjun Qi。2018。[Black-box
    generation of adversarial text sequences to evade deep learning classifiers](http://arxiv.org/abs/1801.04354)。*CoRR*，abs/1801.04354。
- en: 'Garg and Ramakrishnan (2020) Siddhant Garg and Goutham Ramakrishnan. 2020.
    [BAE: BERT-based adversarial examples for text classification](https://doi.org/10.18653/v1/2020.emnlp-main.498).
    In *Proceedings of the 2020 Conference on Empirical Methods in Natural Language
    Processing (EMNLP)*, pages 6174–6181, Online. Association for Computational Linguistics.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Garg 和 Ramakrishnan（2020）Siddhant Garg 和 Goutham Ramakrishnan。2020。[BAE: BERT-based
    adversarial examples for text classification](https://doi.org/10.18653/v1/2020.emnlp-main.498)。在
    *Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing
    (EMNLP)*，第6174–6181页，在线。计算语言学协会。'
- en: Goodfellow et al. (2015) Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy.
    2015. [Explaining and harnessing adversarial examples](http://arxiv.org/abs/1412.6572).
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow 等（2015）Ian J. Goodfellow、Jonathon Shlens 和 Christian Szegedy。2015。[Explaining
    and harnessing adversarial examples](http://arxiv.org/abs/1412.6572)。
- en: 'Gopalakrishnan et al. (2019) Karthik Gopalakrishnan, Behnam Hedayatnia, Qinlang
    Chen, Anna Gottardi, Sanjeev Kwatra, Anu Venkatesh, Raefer Gabriel, and Dilek
    Hakkani-Tür. 2019. [Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations](https://doi.org/10.21437/Interspeech.2019-3079).
    In *Proc. Interspeech 2019*, pages 1891–1895.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gopalakrishnan 等（2019）Karthik Gopalakrishnan、Behnam Hedayatnia、Qinlang Chen、Anna
    Gottardi、Sanjeev Kwatra、Anu Venkatesh、Raefer Gabriel 和 Dilek Hakkani-Tür。2019。[Topical-Chat:
    Towards Knowledge-Grounded Open-Domain Conversations](https://doi.org/10.21437/Interspeech.2019-3079)。在
    *Proc. Interspeech 2019*，第1891–1895页。'
- en: Huang et al. (2024) Yangsibo Huang, Samyak Gupta, Mengzhou Xia, Kai Li, and
    Danqi Chen. 2024. [Catastrophic jailbreak of open-source LLMs via exploiting generation](https://openreview.net/forum?id=r42tSSCHPh).
    In *The Twelfth International Conference on Learning Representations*.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 黄等人（2024）杨斯博·黄、萨米亚克·古普塔、孟洲·夏、凯·李和丹琪·陈。2024年。[通过利用生成的开源LLM的灾难性越狱](https://openreview.net/forum?id=r42tSSCHPh)。在*第十二届国际学习表征会议*上。
- en: Jain et al. (2023) Neel Jain, Avi Schwarzschild, Yuxin Wen, Gowthami Somepalli,
    John Kirchenbauer, Ping yeh Chiang, Micah Goldblum, Aniruddha Saha, Jonas Geiping,
    and Tom Goldstein. 2023. [Baseline defenses for adversarial attacks against aligned
    language models](http://arxiv.org/abs/2309.00614).
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 贾因等人（2023）尼尔·贾因、阿维·施瓦茨希尔德、于欣·温、戈瓦萨米·索姆帕利、约翰·基尔亨鲍尔、平叶·蒋、米卡·戈德布鲁姆、阿尼鲁达·萨哈、乔纳斯·盖平和汤姆·戈尔德斯坦。2023年。[针对对齐语言模型的对抗性攻击的基线防御](http://arxiv.org/abs/2309.00614)。
- en: Jiang et al. (2023) Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris
    Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna
    Lengyel, Guillaume Lample, Lucile Saulnier, et al. 2023. Mistral 7b. *arXiv preprint
    arXiv:2310.06825*.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 蒋等人（2023）阿尔伯特·Q·蒋、亚历山大·萨布莱罗勒斯、亚瑟·门施、克里斯·班福德、德文德拉·辛格·查普洛特、迭戈·德·拉斯·卡萨斯、弗洛里安·布雷桑、吉安娜·伦吉尔、纪尧姆·兰普尔、露西尔·索尼耶等人。2023年。Mistral
    7b。*arXiv预印本 arXiv:2310.06825*。
- en: 'Jin et al. (2024) Haibo Jin, Ruoxi Chen, Andy Zhou, Jinyin Chen, Yang Zhang,
    and Haohan Wang. 2024. [Guard: Role-playing to generate natural-language jailbreakings
    to test guideline adherence of large language models](http://arxiv.org/abs/2402.03299).'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 金等人（2024）海波·金、若溪·陈、安迪·周、锦银·陈、杨·张和浩汉·王。2024年。[Guard：角色扮演生成自然语言越狱以测试大型语言模型的指南遵循](http://arxiv.org/abs/2402.03299)。
- en: Koo et al. (2023) Ryan Koo, Minhwa Lee, Vipul Raheja, Jong Inn Park, Zae Myung
    Kim, and Dongyeop Kang. 2023. [Benchmarking cognitive biases in large language
    models as evaluators](http://arxiv.org/abs/2309.17012).
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 库等人（2023）瑞安·库、敏华·李、维普尔·拉赫贾、钟·因·朴、在·明·金和东叶·姜。2023年。[在大型语言模型中基准认知偏差作为评估者](http://arxiv.org/abs/2309.17012)。
- en: Kumar et al. (2024) Aounon Kumar, Chirag Agarwal, Suraj Srinivas, Aaron Jiaxun
    Li, Soheil Feizi, and Himabindu Lakkaraju. 2024. [Certifying llm safety against
    adversarial prompting](http://arxiv.org/abs/2309.02705).
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 库马尔等人（2024）阿乌农·库马尔、奇拉格·阿加瓦尔、苏拉杰·斯里尼瓦斯、亚伦·贾勋·李、索赫伊尔·费济和希马宾杜·拉卡拉朱。2024年。[证明LLM对抗对抗性提示的安全性](http://arxiv.org/abs/2309.02705)。
- en: Lapid et al. (2023) Raz Lapid, Ron Langberg, and Moshe Sipper. 2023. [Open sesame!
    universal black box jailbreaking of large language models](http://arxiv.org/abs/2309.01446).
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拉皮德等人（2023）拉兹·拉皮德、罗恩·朗伯格和摩西·希珀。2023年。[打开芝麻！大型语言模型的通用黑箱越狱](http://arxiv.org/abs/2309.01446)。
- en: 'Li et al. (2020) Linyang Li, Ruotian Ma, Qipeng Guo, Xiangyang Xue, and Xipeng
    Qiu. 2020. [BERT-ATTACK: Adversarial attack against BERT using BERT](https://doi.org/10.18653/v1/2020.emnlp-main.500).
    pages 6193–6202.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 李等人（2020）林扬·李、若天·马、祁鹏·郭、向阳·薛和西鹏·丘。2020年。[BERT-ATTACK：针对BERT的对抗性攻击使用BERT](https://doi.org/10.18653/v1/2020.emnlp-main.500)。页面6193–6202。
- en: 'Lin (2004) Chin-Yew Lin. 2004. Rouge: A package for automatic evaluation of
    summaries. In *Text summarization branches out*, pages 74–81.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 林（2004）陈耀林。2004年。Rouge：用于自动评估摘要的包。在*文本摘要的扩展*中，页面74–81。
- en: 'Liu et al. (2023a) Xiaogeng Liu, Nan Xu, Muhao Chen, and Chaowei Xiao. 2023a.
    [Autodan: Generating stealthy jailbreak prompts on aligned large language models](http://arxiv.org/abs/2310.04451).'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 刘等人（2023a）肖耿·刘、南·徐、穆豪·陈和超伟·肖。2023a。[Autodan：在对齐的大型语言模型上生成隐秘的越狱提示](http://arxiv.org/abs/2310.04451)。
- en: 'Liu et al. (2023b) Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu,
    and Chenguang Zhu. 2023b. [G-eval: NLG evaluation using gpt-4 with better human
    alignment](https://doi.org/10.18653/v1/2023.emnlp-main.153). In *Proceedings of
    the 2023 Conference on Empirical Methods in Natural Language Processing*, pages
    2511–2522, Singapore. Association for Computational Linguistics.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 刘等人（2023b）杨·刘、丹·伊特、易冲·徐、硕航·王、若晨·徐和成光·朱。2023b。[G-eval：使用gpt-4进行更好的人类对齐的NLG评估](https://doi.org/10.18653/v1/2023.emnlp-main.153)。在*2023年自然语言处理实证方法会议论文集*中，页面2511–2522，新加坡。计算语言学协会。
- en: 'Liu et al. (2023c) Yi Liu, Gelei Deng, Zhengzi Xu, Yuekang Li, Yaowen Zheng,
    Ying Zhang, Lida Zhao, Tianwei Zhang, and Yang Liu. 2023c. [Jailbreaking chatgpt
    via prompt engineering: An empirical study](http://arxiv.org/abs/2305.13860).'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 刘等人（2023c）易·刘、格雷·邓、正子·徐、悦康·李、耀文·郑、颖·张、莉达·赵、天伟·张和杨·刘。2023c。[通过提示工程进行ChatGPT的越狱：一项实证研究](http://arxiv.org/abs/2305.13860)。
- en: 'Liu et al. (2023d) Yiqi Liu, Nafise Sadat Moosavi, and Chenghua Lin. 2023d.
    [Llms as narcissistic evaluators: When ego inflates evaluation scores](http://arxiv.org/abs/2311.09766).'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu等（2023d）Yiqi Liu、Nafise Sadat Moosavi和Chenghua Lin。2023d。[LLMs作为自恋评估者：当自我膨胀评估分数时](http://arxiv.org/abs/2311.09766)。
- en: Liusie et al. (2023) Adian Liusie, Potsawee Manakul, and Mark JF Gales. 2023.
    Zero-shot nlg evaluation through pairware comparisons with llms. *arXiv preprint
    arXiv:2307.07889*.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liusie等（2023）Adian Liusie、Potsawee Manakul和Mark JF Gales。2023年。通过与LLMs的配对比较进行零-shot
    NLG评估。*arXiv预印本 arXiv:2307.07889*。
- en: 'Manakul et al. (2023) Potsawee Manakul, Adian Liusie, and Mark JF Gales. 2023.
    Mqag: Multiple-choice question answering and generation for assessing information
    consistency in summarization. *arXiv preprint arXiv:2301.12307*.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Manakul等（2023）Potsawee Manakul、Adian Liusie和Mark JF Gales。2023年。Mqag：用于评估摘要一致性的信息生成和问答。*arXiv预印本
    arXiv:2301.12307*。
- en: Mehri and Eskenazi (2020) Shikib Mehri and Maxine Eskenazi. 2020. [Unsupervised
    evaluation of interactive dialog with DialoGPT](https://doi.org/10.18653/v1/2020.sigdial-1.28).
    In *Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse
    and Dialogue*, pages 225–235, 1st virtual meeting. Association for Computational
    Linguistics.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mehri和Eskenazi（2020）Shikib Mehri和Maxine Eskenazi。2020年。[使用DialoGPT对互动对话进行无监督评估](https://doi.org/10.18653/v1/2020.sigdial-1.28)。在*Proceedings
    of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue*，页码225–235，第1次虚拟会议。计算语言学协会。
- en: 'Mehrotra et al. (2023) Anay Mehrotra, Manolis Zampetakis, Paul Kassianik, Blaine
    Nelson, Hyrum Anderson, Yaron Singer, and Amin Karbasi. 2023. [Tree of attacks:
    Jailbreaking black-box llms automatically](http://arxiv.org/abs/2312.02119).'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mehrotra等（2023）Anay Mehrotra、Manolis Zampetakis、Paul Kassianik、Blaine Nelson、Hyrum
    Anderson、Yaron Singer和Amin Karbasi。2023年。[攻击树：自动破解黑箱LLMs](http://arxiv.org/abs/2312.02119)。
- en: Nasr et al. (2023) Milad Nasr, Nicholas Carlini, Jonathan Hayase, Matthew Jagielski,
    A. Feder Cooper, Daphne Ippolito, Christopher A. Choquette-Choo, Eric Wallace,
    Florian Tramèr, and Katherine Lee. 2023. [Scalable extraction of training data
    from (production) language models](http://arxiv.org/abs/2311.17035).
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nasr等（2023）Milad Nasr、Nicholas Carlini、Jonathan Hayase、Matthew Jagielski、A.
    Feder Cooper、Daphne Ippolito、Christopher A. Choquette-Choo、Eric Wallace、Florian
    Tramèr和Katherine Lee。2023年。[从（生产）语言模型中可扩展地提取训练数据](http://arxiv.org/abs/2311.17035)。
- en: Qin et al. (2023) Zhen Qin, Rolf Jagerman, Kai Hui, Honglei Zhuang, Junru Wu,
    Jiaming Shen, Tianqi Liu, Jialu Liu, Donald Metzler, Xuanhui Wang, and Michael
    Bendersky. 2023. [Large language models are effective text rankers with pairwise
    ranking prompting](http://arxiv.org/abs/2306.17563).
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qin等（2023）Zhen Qin、Rolf Jagerman、Kai Hui、Honglei Zhuang、Junru Wu、Jiaming Shen、Tianqi
    Liu、Jialu Liu、Donald Metzler、Xuanhui Wang和Michael Bendersky。2023年。[大型语言模型在成对排名提示下有效地进行文本排序](http://arxiv.org/abs/2306.17563)。
- en: Raina and Gales (2023) Vyas Raina and Mark Gales. 2023. [Sentiment perception
    adversarial attacks on neural machine translation systems](http://arxiv.org/abs/2305.01437).
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raina和Gales（2023）Vyas Raina和Mark Gales。2023年。[对神经机器翻译系统的情感感知对抗攻击](http://arxiv.org/abs/2305.01437)。
- en: Raina et al. (2020) Vyas Raina, Mark J.F. Gales, and Kate M. Knill. 2020. [Universal
    Adversarial Attacks on Spoken Language Assessment Systems](https://doi.org/10.21437/Interspeech.2020-1890).
    In *Proc. Interspeech 2020*, pages 3855–3859.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raina等（2020）Vyas Raina、Mark J.F. Gales和Kate M. Knill。2020年。[对语音语言评估系统的通用对抗攻击](https://doi.org/10.21437/Interspeech.2020-1890)。在*Proc.
    Interspeech 2020*，页码3855–3859。
- en: 'Rei et al. (2020) Ricardo Rei, Craig Stewart, Ana C Farinha, and Alon Lavie.
    2020. Comet: A neural framework for mt evaluation. In *Proceedings of the 2020
    Conference on Empirical Methods in Natural Language Processing (EMNLP)*, pages
    2685–2702.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rei等（2020）Ricardo Rei、Craig Stewart、Ana C Farinha和Alon Lavie。2020年。Comet：一个用于机器翻译评估的神经框架。在*Proceedings
    of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)*，页码2685–2702。
- en: 'Robey et al. (2023) Alexander Robey, Eric Wong, Hamed Hassani, and George J.
    Pappas. 2023. [Smoothllm: Defending large language models against jailbreaking
    attacks](http://arxiv.org/abs/2310.03684).'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Robey等（2023）Alexander Robey、Eric Wong、Hamed Hassani和George J. Pappas。2023年。[SmoothLLM：保护大型语言模型免受破解攻击](http://arxiv.org/abs/2310.03684)。
- en: Sadrizadeh et al. (2023) Sahar Sadrizadeh, Ljiljana Dolamic, and Pascal Frossard.
    2023. [A classification-guided approach for adversarial attacks against neural
    machine translation](http://arxiv.org/abs/2308.15246).
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sadrizadeh等（2023）Sahar Sadrizadeh、Ljiljana Dolamic和Pascal Frossard。2023年。[基于分类的对抗攻击方法用于神经机器翻译](http://arxiv.org/abs/2308.15246)。
- en: Szegedy et al. (2014) Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan
    Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. 2014. [Intriguing properties
    of neural networks](http://arxiv.org/abs/1312.6199).
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Szegedy 等人（2014）Christian Szegedy、Wojciech Zaremba、Ilya Sutskever、Joan Bruna、Dumitru
    Erhan、Ian Goodfellow 和 Rob Fergus。2014。 [神经网络的有趣属性](http://arxiv.org/abs/1312.6199)。
- en: 'Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models.
    *arXiv preprint arXiv:2307.09288*.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Touvron 等人（2023）Hugo Touvron、Louis Martin、Kevin Stone、Peter Albert、Amjad Almahairi、Yasmine
    Babaei、Nikolay Bashlykov、Soumya Batra、Prajjwal Bhargava、Shruti Bhosale 等。2023。Llama
    2: 开放的基础模型和微调聊天模型。*arXiv 预印本 arXiv:2307.09288*。'
- en: Wang et al. (2020) Alex Wang, Kyunghyun Cho, and Mike Lewis. 2020. Asking and
    answering questions to evaluate the factual consistency of summaries. In *Proceedings
    of the 58th Annual Meeting of the Association for Computational Linguistics*,
    pages 5008–5020.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2020）Alex Wang、Kyunghyun Cho 和 Mike Lewis。2020。通过提问和回答来评估摘要的事实一致性。在
    *第58届计算语言学协会年会论文集* 中，第 5008–5020 页。
- en: Wang et al. (2023a) Jiaan Wang, Yunlong Liang, Fandong Meng, Haoxiang Shi, Zhixu
    Li, Jinan Xu, Jianfeng Qu, and Jie Zhou. 2023a. Is chatgpt a good nlg evaluator?
    a preliminary study. *arXiv preprint arXiv:2303.04048*.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2023a）Jiaan Wang、Yunlong Liang、Fandong Meng、Haoxiang Shi、Zhixu Li、Jinan
    Xu、Jianfeng Qu 和 Jie Zhou。2023a。ChatGPT 是一个好的 NLG 评估者吗？初步研究。*arXiv 预印本 arXiv:2303.04048*。
- en: Wang et al. (2023b) Peiyi Wang, Lei Li, Liang Chen, Zefan Cai, Dawei Zhu, Binghuai
    Lin, Yunbo Cao, Qi Liu, Tianyu Liu, and Zhifang Sui. 2023b. [Large language models
    are not fair evaluators](http://arxiv.org/abs/2305.17926).
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2023b）Peiyi Wang、Lei Li、Liang Chen、Zefan Cai、Dawei Zhu、Binghuai Lin、Yunbo
    Cao、Qi Liu、Tianyu Liu 和 Zhifang Sui。2023b。 [大型语言模型不是公平的评估者](http://arxiv.org/abs/2305.17926)。
- en: Wang et al. (2019) Xiaosen Wang, Hao Jin, and Kun He. 2019. [Natural language
    adversarial attacks and defenses in word level](http://arxiv.org/abs/1909.06723).
    *CoRR*, abs/1909.06723.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2019）Xiaosen Wang、Hao Jin 和 Kun He。2019。 [自然语言对抗攻击和防御（词级）](http://arxiv.org/abs/1909.06723)。*CoRR*，abs/1909.06723。
- en: 'Wei et al. (2023) Alexander Wei, Nika Haghtalab, and Jacob Steinhardt. 2023.
    [Jailbroken: How does llm safety training fail?](http://arxiv.org/abs/2307.02483)'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等人（2023）Alexander Wei、Nika Haghtalab 和 Jacob Steinhardt。2023。 [越狱：LLM 安全培训失败的原因](http://arxiv.org/abs/2307.02483)。
- en: 'Zeng et al. (2024) Yi Zeng, Hongpeng Lin, Jingwen Zhang, Diyi Yang, Ruoxi Jia,
    and Weiyan Shi. 2024. [How johnny can persuade llms to jailbreak them: Rethinking
    persuasion to challenge ai safety by humanizing llms](http://arxiv.org/abs/2401.06373).'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zeng 等人（2024）Yi Zeng、Hongpeng Lin、Jingwen Zhang、Diyi Yang、Ruoxi Jia 和 Weiyan
    Shi。2024。 [如何让 Johnny 说服 LLMs 以绕过它们：通过人性化 LLMs 重新思考说服以挑战 AI 安全](http://arxiv.org/abs/2401.06373)。
- en: 'Zhang et al. (2019) Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger,
    and Yoav Artzi. 2019. Bertscore: Evaluating text generation with bert. In *International
    Conference on Learning Representations*.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang 等人（2019）Tianyi Zhang、Varsha Kishore、Felix Wu、Kilian Q Weinberger 和 Yoav
    Artzi。2019。Bertscore: 使用 BERT 评估文本生成。在 *国际学习表征会议* 上。'
- en: Zhang et al. (2023a) Xinghua Zhang, Bowen Yu, Haiyang Yu, Yangyu Lv, Tingwen
    Liu, Fei Huang, Hongbo Xu, and Yongbin Li. 2023a. [Wider and deeper llm networks
    are fairer llm evaluators](http://arxiv.org/abs/2308.01862).
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人（2023a）Xinghua Zhang、Bowen Yu、Haiyang Yu、Yangyu Lv、Tingwen Liu、Fei Huang、Hongbo
    Xu 和 Yongbin Li。2023a。 [更宽广更深层的 LLM 网络是更公平的 LLM 评估者](http://arxiv.org/abs/2308.01862)。
- en: Zhang et al. (2023b) Zhexin Zhang, Junxiao Yang, Pei Ke, and Minlie Huang. 2023b.
    [Defending large language models against jailbreaking attacks through goal prioritization](http://arxiv.org/abs/2311.09096).
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人（2023b）Zhexin Zhang、Junxiao Yang、Pei Ke 和 Minlie Huang。2023b。 [通过目标优先级来防御大型语言模型的越狱攻击](http://arxiv.org/abs/2311.09096)。
- en: Zhao et al. (2023) Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei
    Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan
    Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li,
    Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023. [A survey
    of large language models](http://arxiv.org/abs/2303.18223).
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao 等人（2023）Wayne Xin Zhao、Kun Zhou、Junyi Li、Tianyi Tang、Xiaolei Wang、Yupeng
    Hou、Yingqian Min、Beichen Zhang、Junjie Zhang、Zican Dong、Yifan Du、Chen Yang、Yushuo
    Chen、Zhipeng Chen、Jinhao Jiang、Ruiyang Ren、Yifan Li、Xinyu Tang、Zikang Liu、Peiyu
    Liu、Jian-Yun Nie 和 Ji-Rong Wen。2023。 [大型语言模型调查](http://arxiv.org/abs/2303.18223)。
- en: Zheng et al. (2023) Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang,
    Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al.
    2023. Judging llm-as-a-judge with mt-bench and chatbot arena. *arXiv preprint
    arXiv:2306.05685*.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng 等 (2023) Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao
    Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, 等。2023。 用 mt-bench
    和 chatbot arena 评判 llm-as-a-judge。 *arXiv 预印本 arXiv:2306.05685*。
- en: Zhong et al. (2022a) Ming Zhong, Yang Liu, Da Yin, Yuning Mao, Yizhu Jiao, Pengfei
    Liu, Chenguang Zhu, Heng Ji, and Jiawei Han. 2022a. Towards a unified multi-dimensional
    evaluator for text generation. *arXiv preprint arXiv:2210.07197*.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhong 等 (2022a) Ming Zhong, Yang Liu, Da Yin, Yuning Mao, Yizhu Jiao, Pengfei
    Liu, Chenguang Zhu, Heng Ji, 和 Jiawei Han。2022a。 朝向统一的多维评估器用于文本生成。 *arXiv 预印本
    arXiv:2210.07197*。
- en: Zhong et al. (2022b) Ming Zhong, Yang Liu, Da Yin, Yuning Mao, Yizhu Jiao, Pengfei
    Liu, Chenguang Zhu, Heng Ji, and Jiawei Han. 2022b. [Towards a unified multi-dimensional
    evaluator for text generation](https://doi.org/10.18653/v1/2022.emnlp-main.131).
    In *Proceedings of the 2022 Conference on Empirical Methods in Natural Language
    Processing*, pages 2023–2038, Abu Dhabi, United Arab Emirates. Association for
    Computational Linguistics.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhong 等 (2022b) Ming Zhong, Yang Liu, Da Yin, Yuning Mao, Yizhu Jiao, Pengfei
    Liu, Chenguang Zhu, Heng Ji, 和 Jiawei Han。2022b。 [Towards a unified multi-dimensional
    evaluator for text generation](https://doi.org/10.18653/v1/2022.emnlp-main.131)。在
    *2022年自然语言处理实证方法会议论文集* 中，页面2023–2038，阿布扎比，阿拉伯联合酋长国。计算语言学协会。
- en: Zhou et al. (2024) Andy Zhou, Bo Li, and Haohan Wang. 2024. [Robust prompt optimization
    for defending language models against jailbreaking attacks](http://arxiv.org/abs/2401.17263).
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou 等 (2024) Andy Zhou, Bo Li, 和 Haohan Wang。2024。 [Robust prompt optimization
    for defending language models against jailbreaking attacks](http://arxiv.org/abs/2401.17263)。
- en: 'Zhu et al. (2023a) Kaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen Wang, Hao
    Chen, Yidong Wang, Linyi Yang, Wei Ye, Yue Zhang, Neil Zhenqiang Gong, and Xing
    Xie. 2023a. [Promptbench: Towards evaluating the robustness of large language
    models on adversarial prompts](http://arxiv.org/abs/2306.04528).'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhu 等 (2023a) Kaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen Wang, Hao Chen,
    Yidong Wang, Linyi Yang, Wei Ye, Yue Zhang, Neil Zhenqiang Gong, 和 Xing Xie。2023a。
    [Promptbench: Towards evaluating the robustness of large language models on adversarial
    prompts](http://arxiv.org/abs/2306.04528)。'
- en: 'Zhu et al. (2023b) Lianghui Zhu, Xinggang Wang, and Xinlong Wang. 2023b. [Judgelm:
    Fine-tuned large language models are scalable judges](http://arxiv.org/abs/2310.17631).'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhu 等 (2023b) Lianghui Zhu, Xinggang Wang, 和 Xinlong Wang。2023b。 [Judgelm:
    Fine-tuned large language models are scalable judges](http://arxiv.org/abs/2310.17631)。'
- en: 'Zhu et al. (2024) Sicheng Zhu, Ruiyi Zhang, Bang An, Gang Wu, Joe Barrow, Furong
    Huang, and Tong Sun. 2024. [AutoDAN: Automatic and interpretable adversarial attacks
    on large language models](https://openreview.net/forum?id=ZuZujQ9LJV).'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhu 等 (2024) Sicheng Zhu, Ruiyi Zhang, Bang An, Gang Wu, Joe Barrow, Furong
    Huang, 和 Tong Sun。2024。 [AutoDAN: Automatic and interpretable adversarial attacks
    on large language models](https://openreview.net/forum?id=ZuZujQ9LJV)。'
- en: Zou et al. (2023) Andy Zou, Zifan Wang, Nicholas Carlini, Milad Nasr, J. Zico
    Kolter, and Matt Fredrikson. 2023. [Universal and transferable adversarial attacks
    on aligned language models](http://arxiv.org/abs/2307.15043).
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zou 等 (2023) Andy Zou, Zifan Wang, Nicholas Carlini, Milad Nasr, J. Zico Kolter,
    和 Matt Fredrikson。2023。 [Universal and transferable adversarial attacks on aligned
    language models](http://arxiv.org/abs/2307.15043)。
- en: Appendix A Universal Adversarial Phrases
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 通用对抗短语
- en: In the main paper, results are presented for a range of universal attack phrases,
    learnt in different configurations. Further configurations are considered in different
    sections of the Appendix. For all of these attack phrases, the specific words
    constituting each phrase are presented in Table [5](#A1.T5 "Table 5 ‣ Appendix
    A Universal Adversarial Phrases ‣ Is LLM-as-a-Judge Robust? Investigating Universal
    Adversarial Attacks on Zero-shot LLM Assessment").
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在主要论文中，展示了在不同配置下学习的各种通用攻击短语的结果。进一步的配置在附录的不同部分中考虑。所有这些攻击短语的具体组成词汇展示在表[5](#A1.T5
    "Table 5 ‣ Appendix A Universal Adversarial Phrases ‣ Is LLM-as-a-Judge Robust?
    Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment")中。
- en: '| SUMM COMP OVE | E answer E grammatically |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| 总结 比较 观点 | E回答 E语法正确 |'
- en: '| SUMM COMP CON | uncontradictory Ay supplementary answer |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| 总结 比较 观点 | 无矛盾的 Ay 补充回答 |'
- en: '| SUMM ABS OVE | outstandingly superexcellently outstandingly summable |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| 总结 抽象 观点 | 出色地 极其卓越地 出色的 可总结的 |'
- en: '| SUMM ABS CON | uncontradictedly undisputably congruity impeccable |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| 总结 抽象 观点 | 无可争议的 完全一致的 无可挑剔的 |'
- en: '| TOPIC COMP OVE | informative ending answer E |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| 主题 比较 观点 | 信息性的结束回答 E |'
- en: '| TOPIC COMP CNT | interester extemporaneous informative answer |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| 主题 比较 内容 | 有趣的 临时的 信息性回答 |'
- en: '| TOPIC ABS OVE | informative supercomplete impeccable ovated |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| 主题 抽象 观点 | 信息性 极其完善 无可挑剔的 赞誉的 |'
- en: '| TOPIC ABS CNT | continuous superexcellently conformant uncontradictory |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| 主题 摘要 CNT | 持续超级符合无矛盾 |'
- en: '| SUMM COMP-asymA OVE | E applicableness E E |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| 总结 比较-asymA OVE | E 适用性 E E |'
- en: '| SUMM COMP-asymB OVE | grammatically sound emendable correctly |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| 总结 比较-asymB OVE | 语法上正确 可修改 正确 |'
- en: '| SUMM UNI OVE | whoa boggle righto hah |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| 总结 单一 OVE | 哇 噢 对  |'
- en: '| SUMM UNI COH | read inustion newsprint introductorily |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| 总结 单一 一致 | 阅读逐步新闻印刷介绍 |'
- en: '| SUMM UNI CON | compendent at id id |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| 总结 单一 连接 | 依赖于 id id |'
- en: '| SUMM UNI FLU | Feuillants cavort extortionately ashore |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| 总结 单一 流畅 | 费叶特人疯狂地在岸上 |'
- en: 'Table 5: Universal Attack Phrases. Length 1 to length 4 words'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：通用攻击短语。长度从 1 到 4 个单词
- en: Appendix B Analysis of Relative Robustness of Comparative Assessment
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 比较评估的相对稳健性分析
- en: 'It is observed that comparative assessment is more robust than absolute assessment.
    Arguably this could be due to an implicit prompt ensemble with different output
    objectives in comparative assessment. In absolute assessment, the adversary has
    to find a phrase that always pushes the predicted token to the maximal score 5,
    irrespective of the input test. For comparative assessment, to evaluate the probability
    summary  to ensure symmetry, we do two passes through the system. To attack system
    $i$, for the first pass, the adversary has to ensure the attack phrase increases
    the probability of token A (the prompt asks the system to select which text input,
    A or B, is better, where A corresponds to the text in position 1 and B corresponds
    to the text in position 2) being predicted. For the second pass the adversary
    has to decrease the predicted probability of token A (as attacked summary is in
    position 2). This means the objective of the adversary in the different passes
    is dependent on the prompt ordering of summaries, as well as the objectives being
    the complete opposite in the two passes (competing objectives). This means the
    universal attack phrase has to recognise automatically whether it is in position
    1 or in position 2 and respectively increase or decrease the output probability
    of generating token A. This is a lot more challenging and could explain the robustness
    of comparative assessment. How do we assess this hypothesis:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '观察到比较评估比绝对评估更稳健。这可能是因为比较评估中隐式提示集具有不同的输出目标。在绝对评估中，对手必须找到一个总是将预测的 token 推到最大分数
    5 的短语，而不考虑输入测试。对于比较评估，为了确保对称性，我们对系统进行两次遍历。为了攻击系统 $i$，在第一次遍历中，对手必须确保攻击短语增加 token
    A 的概率（提示要求系统选择哪个文本输入，A 或 B 更好，其中 A 对应于位置 1 的文本，B 对应于位置 2 的文本）。在第二次遍历中，对手必须降低 token
    A 的预测概率（因为攻击的总结在位置 2）。这意味着对手在不同遍历中的目标依赖于总结的提示排序，以及两个遍历中的目标完全相反（竞争目标）。这意味着通用攻击短语必须自动识别自己是在位置
    1 还是位置 2，并相应地增加或减少生成 token A 的输出概率。这要困难得多，这可能解释了比较评估的稳健性。我们如何评估这一假设： '
- en: •
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We perform an ablation where the comparative assessment system does asymmetric
    evaluation such that the probability system  is measured asymmetrically, with
    the attacked text always in position 1, such that the adversarial attack only
    has to maximize the probability of token A. It is expected that the asymmetric
    comparative assessment system is less robust.
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们进行了一次消融实验，其中比较评估系统进行非对称评估，使得概率系统以非对称方式测量，攻击文本总是位于位置 1，因此对抗攻击只需最大化 token A
    的概率。预计非对称比较评估系统的稳健性较差。
- en: •
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We re-apply the greedy search algorithm with this asymmetric setup.
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们在这种非对称设置下重新应用贪婪搜索算法。
- en: •
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We evaluate the efficacy of the attack phrase in the asymmetric setting.
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们评估攻击短语在非对称设置下的效果。
- en: •
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We repeat the above experiments with the attack only in position 2 (objective
    then being to minimize the probability of token B). We term the universal attack
    phrases asymA and asymB.
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们在只有位置 2 的攻击下重复上述实验（目标是最小化 token B 的概率）。我们将这些通用攻击短语称为 asymA 和 asymB。
- en: The results are presented in Table [6](#A2.T6 "Table 6 ‣ Appendix B Analysis
    of Relative Robustness of Comparative Assessment ‣ Is LLM-as-a-Judge Robust? Investigating
    Universal Adversarial Attacks on Zero-shot LLM Assessment") and Table [7](#A2.T7
    "Table 7 ‣ Appendix B Analysis of Relative Robustness of Comparative Assessment
    ‣ Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot
    LLM Assessment"). It seems that even in this asymmetric setting the robustness
    performance is only slightly (if that) worse than that of the symmetric evaluation
    setting in the main paper. This suggests that perhaps there is a separate aspect
    of comparative assessment approach that contributes significantly to the robustness.
    Further analysis will be required to better understand exactly which aspects of
    comparative assessment are giving the greatest robustness.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示在表 [6](#A2.T6 "Table 6 ‣ Appendix B Analysis of Relative Robustness of Comparative
    Assessment ‣ Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks
    on Zero-shot LLM Assessment") 和表 [7](#A2.T7 "Table 7 ‣ Appendix B Analysis of
    Relative Robustness of Comparative Assessment ‣ Is LLM-as-a-Judge Robust? Investigating
    Universal Adversarial Attacks on Zero-shot LLM Assessment") 中。即使在这种不对称的设置中，鲁棒性性能似乎也仅比主要论文中的对称评估设置稍微（如果有的话）差。这表明，或许存在一个比较评估方法的独立方面显著地影响了鲁棒性。需要进一步分析以更好地理解哪些比较评估方面提供了最大的鲁棒性。
- en: '| #words | s-s | s-u | u-s | u-u | all | $\bar{r}$ |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| #words | s-s | s-u | u-s | u-u | all | $\bar{r}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| None | 45.43 | 41.07 | 37.70 | 42.07 | 41.54 | 8.50 |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| 无 | 45.43 | 41.07 | 37.70 | 42.07 | 41.54 | 8.50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 51.12 | 51.80 | 46.68 | 50.23 | 50.03 | 6.17 |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 51.12 | 51.80 | 46.68 | 50.23 | 50.03 | 6.17 |'
- en: '| 2 | 34.96 | 38.09 | 34.32 | 37.54 | 37.21 | 9.80 |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 34.96 | 38.09 | 34.32 | 37.54 | 37.21 | 9.80 |'
- en: '| 3 | 48.23 | 49.04 | 44.60 | 47.10 | 47.06 | 6.81 |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 48.23 | 49.04 | 44.60 | 47.10 | 47.06 | 6.81 |'
- en: 'Table 6: Direct attack on FlanT5-xl. Evaluating attack phrase SUMM COMP-asymA
    OVE'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6：对 FlanT5-xl 的直接攻击。评估攻击短语 SUMM COMP-asymA OVE
- en: '| #words | s-s | s-u | u-s | u-u | all | $\bar{r}$ |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| #words | s-s | s-u | u-s | u-u | all | $\bar{r}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| None | 54.57 | 62.30 | 58.93 | 57.93 | 58.46 | 8.50 |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| 无 | 54.57 | 62.30 | 58.93 | 57.93 | 58.46 | 8.50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 51.91 | 60.80 | 52.80 | 54.36 | 54.86 | 9.52 |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 51.91 | 60.80 | 52.80 | 54.36 | 54.86 | 9.52 |'
- en: '| 2 | 57.84 | 65.04 | 56.58 | 58.38 | 58.90 | 8.16 |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 57.84 | 65.04 | 56.58 | 58.38 | 58.90 | 8.16 |'
- en: '| 3 | 57.89 | 63.78 | 56.29 | 57.20 | 57.83 | 8.54 |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 57.89 | 63.78 | 56.29 | 57.20 | 57.83 | 8.54 |'
- en: '| 4 | 64.70 | 68.95 | 60.53 | 62.00 | 62.64 | 7.06 |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 64.70 | 68.95 | 60.53 | 62.00 | 62.64 | 7.06 |'
- en: 'Table 7: Direct attack on FlanT5-xl. Evaluating attack phrase SUMM COMP-asymB
    OVE'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7：对 FlanT5-xl 的直接攻击。评估攻击短语 SUMM COMP-asymB OVE
- en: Appendix C Greedy Coordinate Gradient (GCG) Universal Attack
  id: totrans-272
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 C 贪婪坐标梯度（GCG）通用攻击
- en: In the main paper we present an iterative greedy search for a universal concatenative
    attack phrase. Here, we contrast our approach against the Greedy Coordinate Gradient
    (GCG) adversarial attack approach used by Zou et al. ([2023](#bib.bib58)). In
    our GCG experiments we adopt the default hyperparameter settings from the paper
    for the universal GCG algorithm. The GCG attack is a whitebox approach that exploits
    embedding gradients to identify which tokens to substitute from the concatenated
    phrase. Table [8](#A3.T8 "Table 8 ‣ Appendix C Greedy Coordinate Gradient (GCG)
    Universal Attack ‣ Is LLM-as-a-Judge Robust? Investigating Universal Adversarial
    Attacks on Zero-shot LLM Assessment") shows the impact of incorporating GCG with
    initialization from the existing learnt attack phrases for absolute assessment
    and the comparative assessment on overall assessment. From these results it appears
    that GCG has a negligible impact on the adversarial attack efficacy, and can in
    many cases degrade the attack (worse average rank) - this is perhaps expected
    for the best / well optimized attack phrases.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在主要论文中，我们提出了一种用于通用串联攻击短语的迭代贪婪搜索方法。在这里，我们将我们的方法与 Zou 等人使用的贪婪坐标梯度（GCG）对抗攻击方法进行对比（[2023](#bib.bib58)）。在我们的
    GCG 实验中，我们采用了论文中通用 GCG 算法的默认超参数设置。GCG 攻击是一种白盒方法，利用嵌入梯度来识别从串联短语中替换的标记。表 [8](#A3.T8
    "Table 8 ‣ Appendix C Greedy Coordinate Gradient (GCG) Universal Attack ‣ Is LLM-as-a-Judge
    Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment")
    显示了将 GCG 与现有学习攻击短语的初始化结合起来对绝对评估和整体评估的影响。从这些结果来看，GCG 对对抗攻击的有效性几乎没有影响，在许多情况下甚至可能降低攻击效果（更差的平均排名）——这对于最佳/优化良好的攻击短语来说或许是预期的。
- en: '| Initialisation | No GCG () |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| 初始化 | 无 GCG () |'
- en: '| --- | --- | --- |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| SUMM COMP OVE | 7.96 | 7.88 |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| 汇总对比绝对值 | 7.96 | 7.88 |'
- en: '| SUMM ABS OVE | 1.03 | 2.42 |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| 汇总绝对值 | 1.03 | 2.42 |'
- en: '| TOPIC COMP OVE | 3.16 | 3.18 |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| 主题对比绝对值 | 3.16 | 3.18 |'
- en: '| TOPIC ABS OVE | 1.07 | 3.56 |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| 主题绝对值 | 1.07 | 3.56 |'
- en: 'Table 8: Impact of universal GCG adversarial attack on existing universal attacks'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8：普适 GCG 对现有普适攻击的影响
- en: Appendix D Interpretable Attack Results
  id: totrans-281
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 D 可解释攻击结果
- en: The main paper presents the impact of the adversarial attack phrases for comparative
    and absolute assessment systems on the average rank as defined in Equation [8](#S4.E8
    "In 4.1 Attack Objective ‣ 4 Adversarial Assessment Attacks ‣ Is LLM-as-a-Judge
    Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment").
    However, it is more interpretable to understand the the impact on the probability,
    $p_{ij}$ (Equation [1](#S3.E1 "In 3.1 Comparative Assessment ‣ 3 Zero-shot Assessment
    with LLMs ‣ Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks
    on Zero-shot LLM Assessment")) of an attacked system being better than other systems
    for comparative assessment and the impact on the average predicted score (Equation
    [3](#S3.E3 "In 3.2 Absolute Assessment ‣ 3 Zero-shot Assessment with LLMs ‣ Is
    LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot
    LLM Assessment")) for absolute assessment. Tables [9](#A4.T9 "Table 9 ‣ Appendix
    D Interpretable Attack Results ‣ Is LLM-as-a-Judge Robust? Investigating Universal
    Adversarial Attacks on Zero-shot LLM Assessment")-[12](#A4.T12 "Table 12 ‣ Appendix
    D Interpretable Attack Results ‣ Is LLM-as-a-Judge Robust? Investigating Universal
    Adversarial Attacks on Zero-shot LLM Assessment") give the interpretable breakdown
    of each attack for comparative assessment and Tables [13](#A4.T13 "Table 13 ‣
    Appendix D Interpretable Attack Results ‣ Is LLM-as-a-Judge Robust? Investigating
    Universal Adversarial Attacks on Zero-shot LLM Assessment")-[28](#A4.T28 "Table
    28 ‣ Appendix D Interpretable Attack Results ‣ Is LLM-as-a-Judge Robust? Investigating
    Universal Adversarial Attacks on Zero-shot LLM Assessment") give the equivalent
    interpretable breakdown for absolute assessment.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 主要论文展示了对比和绝对评估系统中对抗攻击短语对平均排名的影响，如公式 [8](#S4.E8 "在 4.1 攻击目标 ‣ 4 对抗评估攻击 ‣ LLM
    作为评判者是否稳健？调查零样本 LLM 评估中的普适对抗攻击") 中定义的。然而，理解攻击系统在对比评估中表现优于其他系统的概率 $p_{ij}$（公式 [1](#S3.E1
    "在 3.1 对比评估 ‣ 3 零样本评估与 LLMs ‣ LLM 作为评判者是否稳健？调查零样本 LLM 评估中的普适对抗攻击")）以及对绝对评估中平均预测分数的影响（公式
    [3](#S3.E3 "在 3.2 绝对评估 ‣ 3 零样本评估与 LLMs ‣ LLM 作为评判者是否稳健？调查零样本 LLM 评估中的普适对抗攻击")）更具可解释性。表
    [9](#A4.T9 "表 9 ‣ 附录 D 可解释攻击结果 ‣ LLM 作为评判者是否稳健？调查零样本 LLM 评估中的普适对抗攻击")-[12](#A4.T12
    "表 12 ‣ 附录 D 可解释攻击结果 ‣ LLM 作为评判者是否稳健？调查零样本 LLM 评估中的普适对抗攻击") 给出了对比评估中每种攻击的可解释分解，表
    [13](#A4.T13 "表 13 ‣ 附录 D 可解释攻击结果 ‣ LLM 作为评判者是否稳健？调查零样本 LLM 评估中的普适对抗攻击")-[28](#A4.T28
    "表 28 ‣ 附录 D 可解释攻击结果 ‣ LLM 作为评判者是否稳健？调查零样本 LLM 评估中的普适对抗攻击") 给出了绝对评估的等效可解释分解。
- en: '| #words | s-s | s-u | u-s | u-u |  |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| #words | s-s | s-u | u-s | u-u |  |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| None | 50.00 | 51.68 | 48.32 | 50.00 | 50.00 | 8.50 |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| 无 | 50.00 | 51.68 | 48.32 | 50.00 | 50.00 | 8.50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 50.59 | 55.97 | 50.48 | 52.73 | 52.80 | 7.48 |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 50.59 | 55.97 | 50.48 | 52.73 | 52.80 | 7.48 |'
- en: '| 2 | 41.22 | 49.73 | 43.90 | 46.49 | 46.48 | 9.75 |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 41.22 | 49.73 | 43.90 | 46.49 | 46.48 | 9.75 |'
- en: '| 3 | 51.27 | 58.55 | 51.84 | 54.33 | 54.48 | 6.97 |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 51.27 | 58.55 | 51.84 | 54.33 | 54.48 | 6.97 |'
- en: '| 4 | 50.01 | 55.88 | 47.49 | 51.27 | 51.34 | 7.96 |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 50.01 | 55.88 | 47.49 | 51.27 | 51.34 | 7.96 |'
- en: 'Table 9: Direct Attack on FlanT5-xl. Evaluating attack phrase SUMM COMP OVE.
    SummEval. 16 candidates, with 2 seen candidates (s) and remaining unseen candidates
    (u).'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 表 9：对 FlanT5-xl 的直接攻击。评估攻击短语汇总对比绝对值。SummEval。16 个候选项，其中 2 个已见候选项 (s) 和其余未见候选项
    (u)。
- en: '| #words | s-s | s-u | u-s | u-u |  |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '| #words | s-s | s-u | u-s | u-u |  |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| None | 50.00 | 53.26 | 46.74 | 50.00 | 50.00 | 8.50 |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| 无 | 50.00 | 53.26 | 46.74 | 50.00 | 50.00 | 8.50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 51.65 | 56.44 | 48.62 | 52.04 | 52.14 | 7.79 |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 51.65 | 56.44 | 48.62 | 52.04 | 52.14 | 7.79 |'
- en: '| 2 | 52.55 | 57.70 | 48.99 | 52.42 | 52.62 | 7.62 |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 52.55 | 57.70 | 48.99 | 52.42 | 52.62 | 7.62 |'
- en: '| 3 | 51.95 | 56.88 | 48.38 | 51.64 | 51.86 | 7.93 |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 51.95 | 56.88 | 48.38 | 51.64 | 51.86 | 7.93 |'
- en: '| 4 | 56.64 | 62.47 | 53.49 | 56.85 | 57.10 | 6.32 |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 56.64 | 62.47 | 53.49 | 56.85 | 57.10 | 6.32 |'
- en: 'Table 10: Direct Attack on FlanT5-xl. Evaluating attack phrase SUMM COMP CON.
    SummEval. 16 candidates, with 2 seen candidates (s) and remaining unseen candidates
    (u).'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '表 10: 直接攻击 FlanT5-xl。评估攻击短语 SUMM COMP CON。SummEval。16 个候选者，其中 2 个已知候选者（s）和剩余的未知候选者（u）。'
- en: '| #words | s-s | s-u | u-s | u-u |  |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '| #words | s-s | s-u | u-s | u-u |  |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| None | 50.00 | 44.70 | 55.30 | 50.00 | 50.00 | 3.50 |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '| None | 50.00 | 44.70 | 55.30 | 50.00 | 50.00 | 3.50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 51.25 | 46.37 | 56.93 | 50.13 | 50.93 | 3.37 |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 51.25 | 46.37 | 56.93 | 50.13 | 50.93 | 3.37 |'
- en: '| 2 | 55.00 | 48.11 | 58.88 | 52.77 | 53.34 | 3.18 |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 55.00 | 48.11 | 58.88 | 52.77 | 53.34 | 3.18 |'
- en: '| 3 | 56.19 | 49.61 | 60.14 | 53.95 | 54.61 | 3.06 |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 56.19 | 49.61 | 60.14 | 53.95 | 54.61 | 3.06 |'
- en: '| 4 | 55.18 | 48.62 | 59.84 | 53.33 | 53.94 | 3.16 |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 55.18 | 48.62 | 59.84 | 53.33 | 53.94 | 3.16 |'
- en: 'Table 11: Direct Attack on FlanT5-xl. Evaluating attack phrase TOPIC COMP OVE.
    TopicalChat. 6 candidates, with 2 seen candidates (s) and remaining unseen candidates
    (u).'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '表 11: 直接攻击 FlanT5-xl。评估攻击短语 TOPIC COMP OVE。TopicalChat。6 个候选者，其中 2 个已知候选者（s）和剩余的未知候选者（u）。'
- en: '| #words | s-s | s-u | u-s | u-u |  |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
  zh: '| #words | s-s | s-u | u-s | u-u |  |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| None | 50.00 | 44.27 | 55.73 | 50.00 | 50.00 | 3.50 |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '| None | 50.00 | 44.27 | 55.73 | 50.00 | 50.00 | 3.50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 47.72 | 44.11 | 56.19 | 48.33 | 49.07 | 3.55 |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 47.72 | 44.11 | 56.19 | 48.33 | 49.07 | 3.55 |'
- en: '| 2 | 49.81 | 44.52 | 56.39 | 49.04 | 49.76 | 3.48 |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 49.81 | 44.52 | 56.39 | 49.04 | 49.76 | 3.48 |'
- en: '| 3 | 53.18 | 47.88 | 58.90 | 52.02 | 52.76 | 3.18 |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 53.18 | 47.88 | 58.90 | 52.02 | 52.76 | 3.18 |'
- en: '| 4 | 54.88 | 48.87 | 60.07 | 53.45 | 54.06 | 3.12 |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 54.88 | 48.87 | 60.07 | 53.45 | 54.06 | 3.12 |'
- en: 'Table 12: Direct Attack on FlanT5-xl. Evaluating attack phrase TOPIC COMP CNT.
    TopicalChat. 6 candidates, with 2 seen candidate types (s) and remaining unseen
    candidates (u).'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '表 12: 直接攻击 FlanT5-xl。评估攻击短语 TOPIC COMP CNT。TopicalChat。6 个候选者，其中 2 种已知候选者类型（s）和剩余的未知候选者（u）。'
- en: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15
    | 16 | avg | $\bar{r}$ |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15
    | 16 | avg | $\bar{r}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
- en: '| None | 3.61 | 3.76 | 3.79 | 3.74 | 3.74 | 3.76 | 3.79 | 3.76 | 3.65 | 3.79
    | 3.78 | 3.77 | 3.62 | 3.77 | 3.67 | 3.78 | 3.73 | 8.50 |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '| None | 3.61 | 3.76 | 3.79 | 3.74 | 3.74 | 3.76 | 3.79 | 3.76 | 3.65 | 3.79
    | 3.78 | 3.77 | 3.62 | 3.77 | 3.67 | 3.78 | 3.73 | 8.50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 3.96 | 4.24 | 4.26 | 4.19 | 4.16 | 4.21 | 4.19 | 4.17 | 3.90 | 4.20 |
    4.26 | 4.27 | 3.99 | 4.21 | 4.10 | 4.24 | 4.16 | 2.08 |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 3.96 | 4.24 | 4.26 | 4.19 | 4.16 | 4.21 | 4.19 | 4.17 | 3.90 | 4.20 |
    4.26 | 4.27 | 3.99 | 4.21 | 4.10 | 4.24 | 4.16 | 2.08 |'
- en: '| 2 | 4.27 | 4.49 | 4.49 | 4.47 | 4.44 | 4.48 | 4.48 | 4.41 | 4.31 | 4.44 |
    4.48 | 4.51 | 4.47 | 4.47 | 4.38 | 4.49 | 4.44 | 1.18 |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 4.27 | 4.49 | 4.49 | 4.47 | 4.44 | 4.48 | 4.48 | 4.41 | 4.31 | 4.44 |
    4.48 | 4.51 | 4.47 | 4.47 | 4.38 | 4.49 | 4.44 | 1.18 |'
- en: '| 3 | 4.47 | 4.62 | 4.63 | 4.62 | 4.60 | 4.63 | 4.61 | 4.59 | 4.46 | 4.61 |
    4.62 | 4.64 | 4.65 | 4.62 | 4.56 | 4.61 | 4.60 | 1.07 |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 4.47 | 4.62 | 4.63 | 4.62 | 4.60 | 4.63 | 4.61 | 4.59 | 4.46 | 4.61 |
    4.62 | 4.64 | 4.65 | 4.62 | 4.56 | 4.61 | 4.60 | 1.07 |'
- en: '| 4 | 4.70 | 4.76 | 4.76 | 4.75 | 4.74 | 4.76 | 4.75 | 4.73 | 4.62 | 4.74 |
    4.76 | 4.77 | 4.75 | 4.75 | 4.73 | 4.75 | 4.74 | 1.03 |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 4.70 | 4.76 | 4.76 | 4.75 | 4.74 | 4.76 | 4.75 | 4.73 | 4.62 | 4.74 |
    4.76 | 4.77 | 4.75 | 4.75 | 4.73 | 4.75 | 4.74 | 1.03 |'
- en: 'Table 13: Direct Attack on FlanT5-xl. Evaluating attack phrase SUMM ABS OVE.
    SummEval. 16 candidates.'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '表 13: 直接攻击 FlanT5-xl。评估攻击短语 SUMM ABS OVE。SummEval。16 个候选者。'
- en: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15
    | 16 | avg | $\bar{r}$ |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
  zh: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15
    | 16 | avg | $\bar{r}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
- en: '| None | 3.61 | 3.90 | 3.94 | 3.88 | 3.90 | 3.93 | 4.00 | 3.92 | 3.74 | 3.95
    | 3.95 | 3.96 | 3.77 | 3.93 | 3.74 | 3.91 | 3.88 | 8.50 |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '| None | 3.61 | 3.90 | 3.94 | 3.88 | 3.90 | 3.93 | 4.00 | 3.92 | 3.74 | 3.95
    | 3.95 | 3.96 | 3.77 | 3.93 | 3.74 | 3.91 | 3.88 | 8.50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 3.83 | 4.22 | 4.26 | 4.18 | 4.19 | 4.23 | 4.19 | 4.15 | 3.77 | 4.17 |
    4.27 | 4.29 | 3.98 | 4.22 | 3.99 | 4.21 | 4.13 | 3.51 |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 3.83 | 4.22 | 4.26 | 4.18 | 4.19 | 4.23 | 4.19 | 4.15 | 3.77 | 4.17 |
    4.27 | 4.29 | 3.98 | 4.22 | 3.99 | 4.21 | 4.13 | 3.51 |'
- en: '| 2 | 3.93 | 4.27 | 4.31 | 4.25 | 4.25 | 4.29 | 4.30 | 4.23 | 3.92 | 4.25 |
    4.32 | 4.35 | 4.25 | 4.27 | 4.09 | 4.28 | 4.22 | 2.49 |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 3.93 | 4.27 | 4.31 | 4.25 | 4.25 | 4.29 | 4.30 | 4.23 | 3.92 | 4.25 |
    4.32 | 4.35 | 4.25 | 4.27 | 4.09 | 4.28 | 4.22 | 2.49 |'
- en: '| 3 | 4.10 | 4.37 | 4.38 | 4.36 | 4.35 | 4.39 | 4.41 | 4.37 | 4.25 | 4.39 |
    4.40 | 4.42 | 4.44 | 4.38 | 4.24 | 4.37 | 4.35 | 1.71 |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 4.10 | 4.37 | 4.38 | 4.36 | 4.35 | 4.39 | 4.41 | 4.37 | 4.25 | 4.39 |
    4.40 | 4.42 | 4.44 | 4.38 | 4.24 | 4.37 | 4.35 | 1.71 |'
- en: '| 4 | 4.10 | 4.37 | 4.38 | 4.36 | 4.35 | 4.39 | 4.41 | 4.37 | 4.25 | 4.39 |
    4.40 | 4.42 | 4.44 | 4.38 | 4.24 | 4.37 | 4.35 | 1.71 |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 4.10 | 4.37 | 4.38 | 4.36 | 4.35 | 4.39 | 4.41 | 4.37 | 4.25 | 4.39 |
    4.40 | 4.42 | 4.44 | 4.38 | 4.24 | 4.37 | 4.35 | 1.71 |'
- en: 'Table 14: Direct Attack on FlanT5-xl. Evaluating attack phrase SUMM ABS CON.
    SummEval. 16 candidates.'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '表 14: 对 FlanT5-xl 的直接攻击。评估攻击短语 SUMM ABS CON。SummEval。16 个候选项。'
- en: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15
    | 16 | avg | $\bar{r}$ |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
  zh: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15
    | 16 | avg | $\bar{r}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
  id: totrans-338
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
- en: '| None | 3.00 | 3.81 | 3.89 | 3.75 | 3.75 | 3.84 | 3.88 | 4.00 | 3.52 | 3.96
    | 3.86 | 3.99 | 4.00 | 3.84 | 3.52 | 3.52 | 3.76 | 8.50 |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '| None | 3.00 | 3.81 | 3.89 | 3.75 | 3.75 | 3.84 | 3.88 | 4.00 | 3.52 | 3.96
    | 3.86 | 3.99 | 4.00 | 3.84 | 3.52 | 3.52 | 3.76 | 8.50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 3.16 | 3.80 | 3.90 | 3.73 | 3.73 | 3.89 | 3.99 | 4.00 | 3.54 | 3.99 |
    3.91 | 4.06 | 3.98 | 3.80 | 3.56 | 3.52 | 3.78 | 8.32 |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 3.16 | 3.80 | 3.90 | 3.73 | 3.73 | 3.89 | 3.99 | 4.00 | 3.54 | 3.99 |
    3.91 | 4.06 | 3.98 | 3.80 | 3.56 | 3.52 | 3.78 | 8.32 |'
- en: '| 2 | 2.80 | 3.48 | 3.59 | 3.19 | 3.39 | 3.41 | 3.46 | 3.86 | 3.01 | 3.74 |
    3.45 | 3.52 | 3.95 | 3.35 | 2.99 | 3.16 | 3.40 | 10.47 |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 2.80 | 3.48 | 3.59 | 3.19 | 3.39 | 3.41 | 3.46 | 3.86 | 3.01 | 3.74 |
    3.45 | 3.52 | 3.95 | 3.35 | 2.99 | 3.16 | 3.40 | 10.47 |'
- en: '| 3 | 2.80 | 3.54 | 3.60 | 3.24 | 3.49 | 3.45 | 3.61 | 3.92 | 2.90 | 3.74 |
    3.59 | 3.64 | 3.99 | 3.39 | 3.08 | 3.21 | 3.45 | 10.23 |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 2.80 | 3.54 | 3.60 | 3.24 | 3.49 | 3.45 | 3.61 | 3.92 | 2.90 | 3.74 |
    3.59 | 3.64 | 3.99 | 3.39 | 3.08 | 3.21 | 3.45 | 10.23 |'
- en: '| 4 | 3.01 | 3.64 | 3.71 | 3.40 | 3.51 | 3.49 | 3.61 | 3.98 | 2.58 | 3.90 |
    3.61 | 3.66 | 3.90 | 3.50 | 3.31 | 3.50 | 3.52 | 9.48 |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 3.01 | 3.64 | 3.71 | 3.40 | 3.51 | 3.49 | 3.61 | 3.98 | 2.58 | 3.90 |
    3.61 | 3.66 | 3.90 | 3.50 | 3.31 | 3.50 | 3.52 | 9.48 |'
- en: 'Table 15: Transfer Attack on GPT3.5\. Evaluating attack phrase SUMM ABS OVE.
    SummEval. 16 candidates.'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '表 15: 对 GPT3.5 的迁移攻击。评估攻击短语 SUMM ABS OVE。SummEval。16 个候选项。'
- en: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15
    | 16 | avg | $\bar{r}$ |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15
    | 16 | avg | $\bar{r}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
- en: '| None | 3.67 | 4.05 | 4.15 | 4.00 | 4.00 | 4.04 | 4.19 | 4.05 | 3.89 | 4.05
    | 4.12 | 4.26 | 4.04 | 4.01 | 3.92 | 3.92 | 4.02 | 8.50 |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '| None | 3.67 | 4.05 | 4.15 | 4.00 | 4.00 | 4.04 | 4.19 | 4.05 | 3.89 | 4.05
    | 4.12 | 4.26 | 4.04 | 4.01 | 3.92 | 3.92 | 4.02 | 8.50 |'
- en: '| 1 | 3.70 | 4.20 | 4.24 | 4.04 | 4.09 | 4.26 | 4.44 | 4.09 | 3.91 | 4.09 |
    4.30 | 4.61 | 4.28 | 4.11 | 3.94 | 3.94 | 4.14 | 7.63 |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 3.70 | 4.20 | 4.24 | 4.04 | 4.09 | 4.26 | 4.44 | 4.09 | 3.91 | 4.09 |
    4.30 | 4.61 | 4.28 | 4.11 | 3.94 | 3.94 | 4.14 | 7.63 |'
- en: 'Table 16: Transfer Attack on GPT3.5\. Evaluating attack phrase SUMM ABS CON.
    SummEval. 16 candidates.'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: '表 16: 对 GPT3.5 的迁移攻击。评估攻击短语 SUMM ABS CON。SummEval。16 个候选项。'
- en: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15
    | 16 | avg | $\bar{r}$ |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
  zh: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15
    | 16 | avg | $\bar{r}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
- en: '| None | 2.08 | 1.86 | 1.95 | 1.83 | 1.86 | 1.82 | 1.87 | 2.07 | 1.76 | 1.99
    | 1.87 | 1.86 | 2.04 | 1.86 | 1.95 | 2.09 | 1.92 | 8.50 |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '| None | 2.08 | 1.86 | 1.95 | 1.83 | 1.86 | 1.82 | 1.87 | 2.07 | 1.76 | 1.99
    | 1.87 | 1.86 | 2.04 | 1.86 | 1.95 | 2.09 | 1.92 | 8.50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 2.02 | 1.89 | 2.01 | 1.85 | 1.90 | 1.88 | 1.99 | 1.98 | 1.74 | 1.96 |
    1.95 | 1.93 | 1.98 | 1.87 | 1.85 | 2.07 | 1.93 | 8.41 |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2.02 | 1.89 | 2.01 | 1.85 | 1.90 | 1.88 | 1.99 | 1.98 | 1.74 | 1.96 |
    1.95 | 1.93 | 1.98 | 1.87 | 1.85 | 2.07 | 1.93 | 8.41 |'
- en: '| 2 | 1.75 | 1.69 | 1.80 | 1.63 | 1.70 | 1.68 | 1.79 | 1.72 | 1.63 | 1.70 |
    1.71 | 1.76 | 1.79 | 1.68 | 1.63 | 1.77 | 1.71 | 12.38 |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 1.75 | 1.69 | 1.80 | 1.63 | 1.70 | 1.68 | 1.79 | 1.72 | 1.63 | 1.70 |
    1.71 | 1.76 | 1.79 | 1.68 | 1.63 | 1.77 | 1.71 | 12.38 |'
- en: '| 3 | 1.73 | 1.68 | 1.76 | 1.65 | 1.69 | 1.67 | 1.75 | 1.69 | 1.61 | 1.70 |
    1.69 | 1.71 | 1.81 | 1.67 | 1.65 | 1.75 | 1.70 | 12.83 |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 1.73 | 1.68 | 1.76 | 1.65 | 1.69 | 1.67 | 1.75 | 1.69 | 1.61 | 1.70 |
    1.69 | 1.71 | 1.81 | 1.67 | 1.65 | 1.75 | 1.70 | 12.83 |'
- en: '| 4 | 1.87 | 1.79 | 1.94 | 1.76 | 1.81 | 1.75 | 1.92 | 1.85 | 1.65 | 1.86 |
    1.81 | 1.86 | 1.98 | 1.79 | 1.74 | 1.92 | 1.83 | 10.46 |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 1.87 | 1.79 | 1.94 | 1.76 | 1.81 | 1.75 | 1.92 | 1.85 | 1.65 | 1.86 |
    1.81 | 1.86 | 1.98 | 1.79 | 1.74 | 1.92 | 1.83 | 10.46 |'
- en: 'Table 17: Transfer Attack on Mistral-7B. Evaluating attack phrase SUMM ABS
    OVE. SummEval. 16 candidates.'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 表 17：对 Mistral-7B 的转移攻击。评估攻击短语 SUMM ABS OVE。SummEval。16 个候选者。
- en: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15
    | 16 | avg | $\bar{r}$ |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15
    | 16 | avg | $\bar{r}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
- en: '| None | 1.64 | 1.42 | 1.45 | 1.46 | 1.44 | 1.41 | 1.40 | 1.54 | 1.50 | 1.51
    | 1.43 | 1.37 | 1.47 | 1.44 | 1.54 | 1.57 | 1.47 | 8.50 |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| None | 1.64 | 1.42 | 1.45 | 1.46 | 1.44 | 1.41 | 1.40 | 1.54 | 1.50 | 1.51
    | 1.43 | 1.37 | 1.47 | 1.44 | 1.54 | 1.57 | 1.47 | 8.50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 1.59 | 1.44 | 1.42 | 1.48 | 1.45 | 1.44 | 1.40 | 1.53 | 1.49 | 1.50 |
    1.42 | 1.39 | 1.44 | 1.46 | 1.53 | 1.52 | 1.47 | 8.46 |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1.59 | 1.44 | 1.42 | 1.48 | 1.45 | 1.44 | 1.40 | 1.53 | 1.49 | 1.50 |
    1.42 | 1.39 | 1.44 | 1.46 | 1.53 | 1.52 | 1.47 | 8.46 |'
- en: '| 2 | 1.62 | 1.45 | 1.41 | 1.50 | 1.46 | 1.46 | 1.39 | 1.54 | 1.55 | 1.51 |
    1.42 | 1.38 | 1.46 | 1.49 | 1.56 | 1.54 | 1.48 | 8.02 |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 1.62 | 1.45 | 1.41 | 1.50 | 1.46 | 1.46 | 1.39 | 1.54 | 1.55 | 1.51 |
    1.42 | 1.38 | 1.46 | 1.49 | 1.56 | 1.54 | 1.48 | 8.02 |'
- en: '| 3 | 1.52 | 1.38 | 1.34 | 1.41 | 1.39 | 1.38 | 1.33 | 1.47 | 1.52 | 1.45 |
    1.34 | 1.31 | 1.38 | 1.41 | 1.48 | 1.45 | 1.41 | 10.98 |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 1.52 | 1.38 | 1.34 | 1.41 | 1.39 | 1.38 | 1.33 | 1.47 | 1.52 | 1.45 |
    1.34 | 1.31 | 1.38 | 1.41 | 1.48 | 1.45 | 1.41 | 10.98 |'
- en: '| 4 | 1.56 | 1.40 | 1.36 | 1.44 | 1.42 | 1.40 | 1.34 | 1.50 | 1.56 | 1.49 |
    1.37 | 1.33 | 1.38 | 1.44 | 1.52 | 1.49 | 1.44 | 10.07 |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 1.56 | 1.40 | 1.36 | 1.44 | 1.42 | 1.40 | 1.34 | 1.50 | 1.56 | 1.49 |
    1.37 | 1.33 | 1.38 | 1.44 | 1.52 | 1.49 | 1.44 | 10.07 |'
- en: 'Table 18: Transfer Attack on Mistral-7B. Evaluating attack phrase SUMM ABS
    CON. SummEval. 16 candidates.'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 表 18：对 Mistral-7B 的转移攻击。评估攻击短语 SUMM ABS CON。SummEval。16 个候选者。
- en: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15
    | 16 | avg | $\bar{r}$ |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
  zh: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15
    | 16 | avg | $\bar{r}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
- en: '| None | 3.58 | 3.74 | 3.87 | 3.65 | 3.72 | 3.78 | 3.94 | 3.73 | 3.88 | 3.69
    | 3.80 | 3.93 | 3.72 | 3.70 | 3.52 | 3.61 | 3.74 | 8.50 |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '| None | 3.58 | 3.74 | 3.87 | 3.65 | 3.72 | 3.78 | 3.94 | 3.73 | 3.88 | 3.69
    | 3.80 | 3.93 | 3.72 | 3.70 | 3.52 | 3.61 | 3.74 | 8.50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 3.66 | 3.76 | 3.87 | 3.68 | 3.72 | 3.76 | 3.85 | 3.77 | 4.02 | 3.74 |
    3.79 | 3.86 | 3.78 | 3.69 | 3.56 | 3.67 | 3.76 | 8.31 |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 3.66 | 3.76 | 3.87 | 3.68 | 3.72 | 3.76 | 3.85 | 3.77 | 4.02 | 3.74 |
    3.79 | 3.86 | 3.78 | 3.69 | 3.56 | 3.67 | 3.76 | 8.31 |'
- en: '| 2 | 4.23 | 4.28 | 4.45 | 4.26 | 4.25 | 4.24 | 4.33 | 4.30 | 4.29 | 4.28 |
    4.31 | 4.33 | 4.21 | 4.21 | 4.15 | 4.24 | 4.27 | 3.36 |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 4.23 | 4.28 | 4.45 | 4.26 | 4.25 | 4.24 | 4.33 | 4.30 | 4.29 | 4.28 |
    4.31 | 4.33 | 4.21 | 4.21 | 4.15 | 4.24 | 4.27 | 3.36 |'
- en: '| 3 | 4.20 | 4.23 | 4.42 | 4.17 | 4.21 | 4.19 | 4.35 | 4.28 | 4.37 | 4.26 |
    4.24 | 4.31 | 4.19 | 4.18 | 4.08 | 4.24 | 4.24 | 3.52 |'
  id: totrans-375
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 4.20 | 4.23 | 4.42 | 4.17 | 4.21 | 4.19 | 4.35 | 4.28 | 4.37 | 4.26 |
    4.24 | 4.31 | 4.19 | 4.18 | 4.08 | 4.24 | 4.24 | 3.52 |'
- en: '| 4 | 4.43 | 4.44 | 4.58 | 4.42 | 4.40 | 4.39 | 4.46 | 4.50 | 4.41 | 4.49 |
    4.45 | 4.43 | 4.33 | 4.42 | 4.35 | 4.48 | 4.44 | 2.30 |'
  id: totrans-376
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 4.43 | 4.44 | 4.58 | 4.42 | 4.40 | 4.39 | 4.46 | 4.50 | 4.41 | 4.49 |
    4.45 | 4.43 | 4.33 | 4.42 | 4.35 | 4.48 | 4.44 | 2.30 |'
- en: 'Table 19: Transfer Attack on Llama-7B. Evaluating attack phrase SUMM ABS OVE.
    SummEval. 16 candidates.'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 表 19：对 Llama-7B 的转移攻击。评估攻击短语 SUMM ABS OVE。SummEval。16 个候选者。
- en: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15
    | 16 | avg | $\bar{r}$ |'
  id: totrans-378
  prefs: []
  type: TYPE_TB
  zh: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15
    | 16 | avg | $\bar{r}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
  id: totrans-379
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
- en: '| None | 2.39 | 2.38 | 2.38 | 2.36 | 2.37 | 2.39 | 2.38 | 2.38 | 2.27 | 2.36
    | 2.38 | 2.38 | 2.36 | 2.38 | 2.37 | 2.39 | 2.37 | 8.50 |'
  id: totrans-380
  prefs: []
  type: TYPE_TB
  zh: '| None | 2.39 | 2.38 | 2.38 | 2.36 | 2.37 | 2.39 | 2.38 | 2.38 | 2.27 | 2.36
    | 2.38 | 2.38 | 2.36 | 2.38 | 2.37 | 2.39 | 2.37 | 8.50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
  id: totrans-381
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 2.38 | 2.39 | 2.37 | 2.38 | 2.39 | 2.39 | 2.37 | 2.38 | 2.31 | 2.37 |
    2.38 | 2.37 | 2.39 | 2.38 | 2.38 | 2.40 | 2.38 | 8.16 |'
  id: totrans-382
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2.38 | 2.39 | 2.37 | 2.38 | 2.39 | 2.39 | 2.37 | 2.38 | 2.31 | 2.37 |
    2.38 | 2.37 | 2.39 | 2.38 | 2.38 | 2.40 | 2.38 | 8.16 |'
- en: '| 2 | 2.38 | 2.39 | 2.38 | 2.38 | 2.39 | 2.38 | 2.36 | 2.38 | 2.31 | 2.38 |
    2.37 | 2.36 | 2.40 | 2.39 | 2.38 | 2.40 | 2.38 | 8.16 |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 2.38 | 2.39 | 2.38 | 2.38 | 2.39 | 2.38 | 2.36 | 2.38 | 2.31 | 2.38 |
    2.37 | 2.36 | 2.40 | 2.39 | 2.38 | 2.40 | 2.38 | 8.16 |'
- en: '| 3 | 2.39 | 2.39 | 2.37 | 2.39 | 2.39 | 2.38 | 2.36 | 2.39 | 2.36 | 2.38 |
    2.37 | 2.36 | 2.43 | 2.39 | 2.40 | 2.39 | 2.38 | 7.81 |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 2.39 | 2.39 | 2.37 | 2.39 | 2.39 | 2.38 | 2.36 | 2.39 | 2.36 | 2.38 |
    2.37 | 2.36 | 2.43 | 2.39 | 2.40 | 2.39 | 2.38 | 7.81 |'
- en: '| 4 | 2.40 | 2.39 | 2.37 | 2.39 | 2.39 | 2.38 | 2.36 | 2.38 | 2.34 | 2.38 |
    2.38 | 2.36 | 2.41 | 2.40 | 2.40 | 2.39 | 2.38 | 7.82 |'
  id: totrans-385
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 2.40 | 2.39 | 2.37 | 2.39 | 2.39 | 2.38 | 2.36 | 2.38 | 2.34 | 2.38 |
    2.38 | 2.36 | 2.41 | 2.40 | 2.40 | 2.39 | 2.38 | 7.82 |'
- en: 'Table 20: Transfer Attack on Llama-7B. Evaluating attack phrase SUMM ABS CON.
    SummEval. 16 candidates.'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: '表 20: 对 Llama-7B 的转移攻击。评估攻击短语 SUMM ABS CON。SummEval。16 个候选者。'
- en: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | avg | $\bar{r}$ |'
  id: totrans-387
  prefs: []
  type: TYPE_TB
  zh: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | avg | $\bar{r}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-388
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| None | 2.98 | 2.88 | 2.88 | 2.88 | 2.83 | 3.15 | 2.93 | 3.50 |'
  id: totrans-389
  prefs: []
  type: TYPE_TB
  zh: '| None | 2.98 | 2.88 | 2.88 | 2.88 | 2.83 | 3.15 | 2.93 | 3.50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 3.59 | 3.55 | 3.59 | 3.54 | 3.55 | 3.85 | 3.61 | 1.54 |'
  id: totrans-391
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 3.59 | 3.55 | 3.59 | 3.54 | 3.55 | 3.85 | 3.61 | 1.54 |'
- en: '| 2 | 4.11 | 4.13 | 4.11 | 4.00 | 4.03 | 4.35 | 4.12 | 1.22 |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 4.11 | 4.13 | 4.11 | 4.00 | 4.03 | 4.35 | 4.12 | 1.22 |'
- en: '| 3 | 4.44 | 4.45 | 4.40 | 4.33 | 4.36 | 4.57 | 4.42 | 1.09 |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 4.44 | 4.45 | 4.40 | 4.33 | 4.36 | 4.57 | 4.42 | 1.09 |'
- en: '| 4 | 4.63 | 4.63 | 4.61 | 4.60 | 4.61 | 4.67 | 4.63 | 1.07 |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 4.63 | 4.63 | 4.61 | 4.60 | 4.61 | 4.67 | 4.63 | 1.07 |'
- en: 'Table 21: Direct Attack on FlanT5-xl. Evaluating attack phrase TOPIC ABS OVE.
    TopicalChat. 6 candidates.'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: '表 21: 对 FlanT5-xl 的直接攻击。评估攻击短语 TOPIC ABS OVE。TopicalChat。6 个候选者。'
- en: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | avg | $\bar{r}$ |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
  zh: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | avg | $\bar{r}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| None | 3.38 | 2.54 | 2.90 | 2.94 | 2.67 | 3.73 | 3.02 | 3.50 |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
  zh: '| None | 3.38 | 2.54 | 2.90 | 2.94 | 2.67 | 3.73 | 3.02 | 3.50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 4.92 | 5.00 | 4.85 | 4.88 | 4.88 | 4.60 | 4.85 | 1.21 |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 4.92 | 5.00 | 4.85 | 4.88 | 4.88 | 4.60 | 4.85 | 1.21 |'
- en: '| 2 | 4.58 | 4.71 | 4.90 | 4.69 | 4.75 | 3.96 | 4.60 | 1.53 |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 4.58 | 4.71 | 4.90 | 4.69 | 4.75 | 3.96 | 4.60 | 1.53 |'
- en: '| 3 | 4.50 | 4.77 | 4.75 | 4.71 | 4.48 | 3.96 | 4.53 | 1.61 |'
  id: totrans-402
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 4.50 | 4.77 | 4.75 | 4.71 | 4.48 | 3.96 | 4.53 | 1.61 |'
- en: '| 4 | 4.35 | 4.69 | 4.67 | 4.69 | 4.44 | 3.06 | 4.32 | 1.86 |'
  id: totrans-403
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 4.35 | 4.69 | 4.67 | 4.69 | 4.44 | 3.06 | 4.32 | 1.86 |'
- en: 'Table 22: Direct Attack on FlanT5-xl. Evaluating attack phrase TOPIC ABS CNT.
    TopicalChat. 6 candidates.'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: '表 22: 对 FlanT5-xl 的直接攻击。评估攻击短语 TOPIC ABS CNT。TopicalChat。6 个候选者。'
- en: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | avg | $\bar{r}$ |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
  zh: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | avg | $\bar{r}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-406
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| None | 2.98 | 2.08 | 2.42 | 2.56 | 2.21 | 3.19 | 2.57 | 3.50 |'
  id: totrans-407
  prefs: []
  type: TYPE_TB
  zh: '| None | 2.98 | 2.08 | 2.42 | 2.56 | 2.21 | 3.19 | 2.57 | 3.50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-408
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 3.38 | 2.88 | 3.19 | 3.23 | 2.90 | 3.29 | 3.14 | 2.64 |'
  id: totrans-409
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 3.38 | 2.88 | 3.19 | 3.23 | 2.90 | 3.29 | 3.14 | 2.64 |'
- en: '| 2 | 3.23 | 2.88 | 3.23 | 3.44 | 2.79 | 3.21 | 3.13 | 2.74 |'
  id: totrans-410
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 3.23 | 2.88 | 3.23 | 3.44 | 2.79 | 3.21 | 3.13 | 2.74 |'
- en: '| 3 | 3.69 | 3.44 | 3.94 | 3.94 | 3.33 | 3.35 | 3.61 | 2.28 |'
  id: totrans-411
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 3.69 | 3.44 | 3.94 | 3.94 | 3.33 | 3.35 | 3.61 | 2.28 |'
- en: '| 4 | 2.40 | 2.46 | 2.56 | 2.60 | 1.83 | 2.29 | 2.36 | 3.79 |'
  id: totrans-412
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 2.40 | 2.46 | 2.56 | 2.60 | 1.83 | 2.29 | 2.36 | 3.79 |'
- en: 'Table 23: Transfer Attack on GPT3.5\. Evaluating attack phrase TOPIC ABS OVE.
    TopicalChat. 6 candidates.'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: '表 23: 对 GPT3.5 的转移攻击。评估攻击短语 TOPIC ABS OVE。TopicalChat。6 个候选者。'
- en: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | avg | $\bar{r}$ |'
  id: totrans-414
  prefs: []
  type: TYPE_TB
  zh: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | avg | $\bar{r}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-415
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| None | 3.38 | 2.54 | 2.90 | 2.94 | 2.67 | 3.73 | 3.02 | 3.50 |'
  id: totrans-416
  prefs: []
  type: TYPE_TB
  zh: '| None | 3.38 | 2.54 | 2.90 | 2.94 | 2.67 | 3.73 | 3.02 | 3.50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-417
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 4.92 | 5.00 | 4.85 | 4.88 | 4.88 | 4.60 | 4.85 | 1.21 |'
  id: totrans-418
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 4.92 | 5.00 | 4.85 | 4.88 | 4.88 | 4.60 | 4.85 | 1.21 |'
- en: '| 2 | 4.58 | 4.71 | 4.90 | 4.69 | 4.75 | 3.96 | 4.60 | 1.53 |'
  id: totrans-419
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 4.58 | 4.71 | 4.90 | 4.69 | 4.75 | 3.96 | 4.60 | 1.53 |'
- en: '| 3 | 4.50 | 4.77 | 4.75 | 4.71 | 4.48 | 3.96 | 4.53 | 1.61 |'
  id: totrans-420
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 4.50 | 4.77 | 4.75 | 4.71 | 4.48 | 3.96 | 4.53 | 1.61 |'
- en: '| 4 | 4.35 | 4.69 | 4.67 | 4.69 | 4.44 | 3.06 | 4.32 | 1.86 |'
  id: totrans-421
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 4.35 | 4.69 | 4.67 | 4.69 | 4.44 | 3.06 | 4.32 | 1.86 |'
- en: 'Table 24: Transfer Attack on GPT3.5\. Evaluating attack phrase TOPIC ABS CNT.
    TopicalChat. 6 candidates.'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 表 24：GPT3.5 的转移攻击。评估攻击短语 TOPIC ABS CNT。TopicalChat。6 个候选者。
- en: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | avg | $\bar{r}$ |'
  id: totrans-423
  prefs: []
  type: TYPE_TB
  zh: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | avg | $\bar{r}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-424
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| None | 1.63 | 1.50 | 1.52 | 1.51 | 1.51 | 1.72 | 1.57 | 3.50 |'
  id: totrans-425
  prefs: []
  type: TYPE_TB
  zh: '| 无 | 1.63 | 1.50 | 1.52 | 1.51 | 1.51 | 1.72 | 1.57 | 3.50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-426
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 1.59 | 1.57 | 1.59 | 1.58 | 1.58 | 1.70 | 1.60 | 3.11 |'
  id: totrans-427
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1.59 | 1.57 | 1.59 | 1.58 | 1.58 | 1.70 | 1.60 | 3.11 |'
- en: '| 2 | 1.62 | 1.58 | 1.60 | 1.58 | 1.58 | 1.73 | 1.61 | 2.98 |'
  id: totrans-428
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 1.62 | 1.58 | 1.60 | 1.58 | 1.58 | 1.73 | 1.61 | 2.98 |'
- en: '| 3 | 1.59 | 1.57 | 1.59 | 1.58 | 1.58 | 1.70 | 1.60 | 3.11 |'
  id: totrans-429
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 1.59 | 1.57 | 1.59 | 1.58 | 1.58 | 1.70 | 1.60 | 3.11 |'
- en: '| 4 | 1.60 | 1.57 | 1.61 | 1.59 | 1.58 | 1.73 | 1.61 | 2.98 |'
  id: totrans-430
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 1.60 | 1.57 | 1.61 | 1.59 | 1.58 | 1.73 | 1.61 | 2.98 |'
- en: 'Table 25: Transfer Attack on Mistral-7B. Evaluating attack phrase TOPIC ABS
    OVE. TopicalChat. 6 candidates.'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 表 25：Mistral-7B 的转移攻击。评估攻击短语 TOPIC ABS OVE。TopicalChat。6 个候选者。
- en: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | avg | $\bar{r}$ |'
  id: totrans-432
  prefs: []
  type: TYPE_TB
  zh: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | avg | $\bar{r}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-433
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| None | 2.15 | 1.85 | 1.97 | 2.03 | 1.81 | 2.25 | 2.01 | 3.50 |'
  id: totrans-434
  prefs: []
  type: TYPE_TB
  zh: '| 无 | 2.15 | 1.85 | 1.97 | 2.03 | 1.81 | 2.25 | 2.01 | 3.50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-435
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 3.33 | 3.30 | 3.32 | 3.27 | 3.24 | 3.36 | 3.30 | 1.23 |'
  id: totrans-436
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 3.33 | 3.30 | 3.32 | 3.27 | 3.24 | 3.36 | 3.30 | 1.23 |'
- en: '| 2 | 3.02 | 3.09 | 3.17 | 3.11 | 3.12 | 3.25 | 3.13 | 1.33 |'
  id: totrans-437
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 3.02 | 3.09 | 3.17 | 3.11 | 3.12 | 3.25 | 3.13 | 1.33 |'
- en: '| 3 | 3.11 | 3.10 | 3.16 | 3.19 | 3.15 | 3.44 | 3.19 | 1.26 |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 3.11 | 3.10 | 3.16 | 3.19 | 3.15 | 3.44 | 3.19 | 1.26 |'
- en: '| 4 | 3.23 | 3.29 | 3.34 | 3.28 | 3.28 | 3.19 | 3.27 | 1.22 |'
  id: totrans-439
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 3.23 | 3.29 | 3.34 | 3.28 | 3.28 | 3.19 | 3.27 | 1.22 |'
- en: 'Table 26: Transfer Attack on Mistral-7B. Evaluating attack phrase TOPIC ABS
    CNT. TopicalChat. 6 candidates.'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 表 26：Mistral-7B 的转移攻击。评估攻击短语 TOPIC ABS CNT。TopicalChat。6 个候选者。
- en: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | avg | $\bar{r}$ |'
  id: totrans-441
  prefs: []
  type: TYPE_TB
  zh: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | avg | $\bar{r}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| None | 2.33 | 2.27 | 2.31 | 2.29 | 2.27 | 2.46 | 2.32 | 3.50 |'
  id: totrans-443
  prefs: []
  type: TYPE_TB
  zh: '| 无 | 2.33 | 2.27 | 2.31 | 2.29 | 2.27 | 2.46 | 2.32 | 3.50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-444
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 2.57 | 2.66 | 2.65 | 2.64 | 2.67 | 2.56 | 2.62 | 1.57 |'
  id: totrans-445
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2.57 | 2.66 | 2.65 | 2.64 | 2.67 | 2.56 | 2.62 | 1.57 |'
- en: '| 2 | 3.28 | 3.46 | 3.48 | 3.47 | 3.48 | 3.02 | 3.37 | 1.04 |'
  id: totrans-446
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 3.28 | 3.46 | 3.48 | 3.47 | 3.48 | 3.02 | 3.37 | 1.04 |'
- en: '| 3 | 3.36 | 3.47 | 3.49 | 3.46 | 3.48 | 3.15 | 3.40 | 1.03 |'
  id: totrans-447
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 3.36 | 3.47 | 3.49 | 3.46 | 3.48 | 3.15 | 3.40 | 1.03 |'
- en: '| 4 | 3.03 | 3.13 | 3.15 | 3.12 | 3.12 | 2.97 | 3.09 | 1.09 |'
  id: totrans-448
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 3.03 | 3.13 | 3.15 | 3.12 | 3.12 | 2.97 | 3.09 | 1.09 |'
- en: 'Table 27: Transfer Attack on Llama-7B. Evaluating attack phrase TOPIC ABS OVE.
    TopicalChat. 6 candidates.'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 表 27：Llama-7B 的转移攻击。评估攻击短语 TOPIC ABS OVE。TopicalChat。6 个候选者。
- en: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | avg | $\bar{r}$ |'
  id: totrans-450
  prefs: []
  type: TYPE_TB
  zh: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | avg | $\bar{r}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-451
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| None | 2.60 | 2.58 | 2.61 | 2.62 | 2.59 | 2.61 | 2.60 | 3.50 |'
  id: totrans-452
  prefs: []
  type: TYPE_TB
  zh: '| 无 | 2.60 | 2.58 | 2.61 | 2.62 | 2.59 | 2.61 | 2.60 | 3.50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-453
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 3.28 | 3.35 | 3.35 | 3.34 | 3.34 | 3.23 | 3.31 | 1.02 |'
  id: totrans-454
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 3.28 | 3.35 | 3.35 | 3.34 | 3.34 | 3.23 | 3.31 | 1.02 |'
- en: '| 2 | 3.20 | 3.35 | 3.40 | 3.36 | 3.34 | 3.06 | 3.28 | 1.08 |'
  id: totrans-455
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 3.20 | 3.35 | 3.40 | 3.36 | 3.34 | 3.06 | 3.28 | 1.08 |'
- en: '| 3 | 3.31 | 3.50 | 3.52 | 3.47 | 3.46 | 3.19 | 3.41 | 1.03 |'
  id: totrans-456
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 3.31 | 3.50 | 3.52 | 3.47 | 3.46 | 3.19 | 3.41 | 1.03 |'
- en: '| 4 | 3.11 | 3.40 | 3.40 | 3.36 | 3.33 | 3.01 | 3.27 | 1.17 |'
  id: totrans-457
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 3.11 | 3.40 | 3.40 | 3.36 | 3.33 | 3.01 | 3.27 | 1.17 |'
- en: 'Table 28: Transfer Attack on Llama-7B. Evaluating attack phrase TOPIC ABS CNT.
    TopicalChat. 6 candidates.'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 表 28：Llama-7B 的转移攻击。评估攻击短语 TOPIC ABS CNT。TopicalChat。6 个候选者。
- en: Appendix E LLM Prompts
  id: totrans-459
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 E LLM 提示
- en: Figure [5](#A5.F5 "Figure 5 ‣ Appendix E LLM Prompts ‣ Is LLM-as-a-Judge Robust?
    Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment") shows
    the prompts used for absolute scoring via G-EVAL, while Figure [6](#A5.F6 "Figure
    6 ‣ Appendix E LLM Prompts ‣ Is LLM-as-a-Judge Robust? Investigating Universal
    Adversarial Attacks on Zero-shot LLM Assessment") shows the prompt template used
    for comparative assessment.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [5](#A5.F5 "Figure 5 ‣ Appendix E LLM Prompts ‣ Is LLM-as-a-Judge Robust?
    Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment") 显示了用于
    G-EVAL 绝对评分的提示，而图 [6](#A5.F6 "Figure 6 ‣ Appendix E LLM Prompts ‣ Is LLM-as-a-Judge
    Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment")
    显示了用于比较评估的提示模板。
- en: '![Refer to caption](img/6f36ce0a73a6976c33eae4f3fbc446fd.png)'
  id: totrans-461
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/6f36ce0a73a6976c33eae4f3fbc446fd.png)'
- en: 'Figure 5: G-Eval prompt for assessing consistency in Summeval taken from [https://github.com/nlpyang/geval](https://github.com/nlpyang/geval).
    When adapted to TopicalChat, the word ’summary’ is replaced with ’dialogue’ and
    further minor details are changed for specific attributes'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: '图 5: 用于评估 Summeval 一致性的 G-Eval 提示，取自 [https://github.com/nlpyang/geval](https://github.com/nlpyang/geval)。在适配到
    TopicalChat 时，单词“summary”被替换为“dialogue”，并进一步根据特定属性进行了细微调整。'
- en: '![Refer to caption](img/0f694f679a66e7273aa34942b7a3583b.png)'
  id: totrans-463
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0f694f679a66e7273aa34942b7a3583b.png)'
- en: 'Figure 6: Comparative assessment prompts based on the simple ones used in Liusie
    et al. ([2023](#bib.bib28)). displayed is a prompt for coherency assessment, however
    different adjectives can be used for different attributes.'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: '图 6: 基于 Liusie 等人使用的简单提示的比较评估提示 ([2023](#bib.bib28))。显示的是用于连贯性评估的提示，但可以为不同的属性使用不同的形容词。'
- en: Appendix F Attacking Bespoke Assessment Systems
  id: totrans-465
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 F 攻击定制评估系统
- en: The focus of the paper is on adversarially attacking zero-shot NLG assessment
    systems. However, one practical defence could be to use a bespoke NLG assessment
    system that is finetuned to a specific domain. Zhong et al. ([2022b](#bib.bib53))
    propose such a bespoke system, Unieval that has been finetuned for summary assessment
    evaluation for each attribute on SummEval. The Unieval system predicts a quality
    score from 1-5 for each attribute of assessment. Here we explore attacking each
    attribute of Unieval in turn for the SummEval dataset. Interestingly Unieval appears
    significantly more robust to these form of adversarial attacks than the zero-shot
    NLG systems in the main paper. However, it can be observed that there is some
    vulnerability in the Unieval when assessed on the fluency attribute.
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的重点是对零-shot NLG 评估系统进行对抗攻击。然而，一种实际的防御方法可能是使用一个专门定制的 NLG 评估系统，该系统针对特定领域进行了微调。Zhong
    等人 ([2022b](#bib.bib53)) 提出了这样一个定制系统——Unieval，该系统已针对 SummEval 中每个属性的摘要评估进行了微调。Unieval
    系统为每个评估属性预测一个 1-5 的质量评分。在这里，我们探讨了对 SummEval 数据集中 Unieval 每个属性的攻击。有趣的是，Unieval
    对这些对抗攻击的抵抗力明显高于主要论文中的零-shot NLG 系统。然而，可以观察到在流畅性属性的评估中，Unieval 存在一些脆弱性。
- en: Appendix G Licensing
  id: totrans-467
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 G 许可
- en: All datasets used are publicly available. Our implementation utilizes the PyTorch
    1.12 framework, an open-source library. We obtained a license from Meta to employ
    the Llama-7B model via HuggingFace. Additionally, our research is conducted per
    the licensing agreements of the Mistral-7B, GPT-3.5, and GPT-4 models. We ran
    our experiments on A100 Nvidia GPU and via OpenAI API.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 所有使用的数据集都是公开可用的。我们的实现利用了开源库 PyTorch 1.12 框架。我们从 Meta 获得了通过 HuggingFace 使用 Llama-7B
    模型的许可。此外，我们的研究符合 Mistral-7B、GPT-3.5 和 GPT-4 模型的许可协议。我们在 A100 Nvidia GPU 和 OpenAI
    API 上进行了实验。
- en: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15
    | 16 | avg | $\bar{r}$ |'
  id: totrans-469
  prefs: []
  type: TYPE_TB
  zh: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15
    | 16 | avg | $\bar{r}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
  id: totrans-470
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
- en: '| None | 0.55 | 0.82 | 0.80 | 0.83 | 0.82 | 0.86 | 0.84 | 0.88 | 0.61 | 0.87
    | 0.80 | 0.90 | 0.95 | 0.84 | 0.76 | 0.71 | 0.80 | 8.50 |'
  id: totrans-471
  prefs: []
  type: TYPE_TB
  zh: '| 无 | 0.55 | 0.82 | 0.80 | 0.83 | 0.82 | 0.86 | 0.84 | 0.88 | 0.61 | 0.87 |
    0.80 | 0.90 | 0.95 | 0.84 | 0.76 | 0.71 | 0.80 | 8.50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
  id: totrans-472
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 0.55 | 0.73 | 0.73 | 0.73 | 0.72 | 0.74 | 0.73 | 0.79 | 0.44 | 0.79 |
    0.72 | 0.79 | 0.71 | 0.73 | 0.70 | 0.68 | 0.70 | 12.29 |'
  id: totrans-473
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0.55 | 0.73 | 0.73 | 0.73 | 0.72 | 0.74 | 0.73 | 0.79 | 0.44 | 0.79 |
    0.72 | 0.79 | 0.71 | 0.73 | 0.70 | 0.68 | 0.70 | 12.29 |'
- en: '| 2 | 0.57 | 0.76 | 0.76 | 0.75 | 0.75 | 0.77 | 0.76 | 0.82 | 0.48 | 0.81 |
    0.75 | 0.82 | 0.73 | 0.76 | 0.72 | 0.70 | 0.73 | 11.78 |'
  id: totrans-474
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 0.57 | 0.76 | 0.76 | 0.75 | 0.75 | 0.77 | 0.76 | 0.82 | 0.48 | 0.81 |
    0.75 | 0.82 | 0.73 | 0.76 | 0.72 | 0.70 | 0.73 | 11.78 |'
- en: '| 3 | 0.57 | 0.75 | 0.76 | 0.75 | 0.75 | 0.77 | 0.77 | 0.81 | 0.49 | 0.80 |
    0.75 | 0.83 | 0.74 | 0.76 | 0.71 | 0.69 | 0.73 | 11.80 |'
  id: totrans-475
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 0.57 | 0.75 | 0.76 | 0.75 | 0.75 | 0.77 | 0.77 | 0.81 | 0.49 | 0.80 |
    0.75 | 0.83 | 0.74 | 0.76 | 0.71 | 0.69 | 0.73 | 11.80 |'
- en: '| 4 | 0.57 | 0.75 | 0.76 | 0.74 | 0.74 | 0.76 | 0.77 | 0.81 | 0.50 | 0.80 |
    0.75 | 0.82 | 0.72 | 0.75 | 0.71 | 0.69 | 0.73 | 11.90 |'
  id: totrans-476
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 0.57 | 0.75 | 0.76 | 0.74 | 0.74 | 0.76 | 0.77 | 0.81 | 0.50 | 0.80 |
    0.75 | 0.82 | 0.72 | 0.75 | 0.71 | 0.69 | 0.73 | 11.90 |'
- en: 'Table 29: Direct Attack on Unieval. Evaluating attack phrase SUMM UNI OVE.
    SummEval. 16 candidates.'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: '表 29: 对 Unieval 的直接攻击。评估攻击短语 SUMM UNI OVE。SummEval。16 个候选者。'
- en: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15
    | 16 | avg | $\bar{r}$ |'
  id: totrans-478
  prefs: []
  type: TYPE_TB
  zh: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15
    | 16 | 平均 | $\bar{r}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
  id: totrans-479
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
- en: '| None | 0.38 | 0.79 | 0.70 | 0.83 | 0.81 | 0.89 | 0.86 | 0.96 | 0.51 | 0.95
    | 0.68 | 0.97 | 0.97 | 0.85 | 0.74 | 0.58 | 0.78 | 8.50 |'
  id: totrans-480
  prefs: []
  type: TYPE_TB
  zh: '| 无 | 0.38 | 0.79 | 0.70 | 0.83 | 0.81 | 0.89 | 0.86 | 0.96 | 0.51 | 0.95 |
    0.68 | 0.97 | 0.97 | 0.85 | 0.74 | 0.58 | 0.78 | 8.50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
  id: totrans-481
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 0.34 | 0.61 | 0.61 | 0.57 | 0.60 | 0.64 | 0.74 | 0.76 | 0.21 | 0.74 |
    0.58 | 0.79 | 0.35 | 0.62 | 0.57 | 0.50 | 0.58 | 12.46 |'
  id: totrans-482
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0.34 | 0.61 | 0.61 | 0.57 | 0.60 | 0.64 | 0.74 | 0.76 | 0.21 | 0.74 |
    0.58 | 0.79 | 0.35 | 0.62 | 0.57 | 0.50 | 0.58 | 12.46 |'
- en: '| 2 | 0.38 | 0.70 | 0.66 | 0.70 | 0.72 | 0.77 | 0.80 | 0.86 | 0.29 | 0.85 |
    0.64 | 0.86 | 0.60 | 0.74 | 0.69 | 0.55 | 0.67 | 11.77 |'
  id: totrans-483
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 0.38 | 0.70 | 0.66 | 0.70 | 0.72 | 0.77 | 0.80 | 0.86 | 0.29 | 0.85 |
    0.64 | 0.86 | 0.60 | 0.74 | 0.69 | 0.55 | 0.67 | 11.77 |'
- en: '| 3 | 0.35 | 0.61 | 0.61 | 0.57 | 0.61 | 0.65 | 0.73 | 0.75 | 0.24 | 0.74 |
    0.57 | 0.76 | 0.41 | 0.62 | 0.60 | 0.50 | 0.58 | 12.51 |'
  id: totrans-484
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 0.35 | 0.61 | 0.61 | 0.57 | 0.61 | 0.65 | 0.73 | 0.75 | 0.24 | 0.74 |
    0.57 | 0.76 | 0.41 | 0.62 | 0.60 | 0.50 | 0.58 | 12.51 |'
- en: '| 4 | 0.37 | 0.63 | 0.64 | 0.60 | 0.64 | 0.68 | 0.76 | 0.77 | 0.27 | 0.76 |
    0.60 | 0.79 | 0.44 | 0.64 | 0.62 | 0.53 | 0.61 | 12.35 |'
  id: totrans-485
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 0.37 | 0.63 | 0.64 | 0.60 | 0.64 | 0.68 | 0.76 | 0.77 | 0.27 | 0.76 |
    0.60 | 0.79 | 0.44 | 0.64 | 0.62 | 0.53 | 0.61 | 12.35 |'
- en: 'Table 30: Direct Attack on Unieval. Evaluating attack phrase SUMM UNI COH.
    SummEval. 16 candidates.'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: '表 30: 对 Unieval 的直接攻击。评估攻击短语 SUMM UNI COH。SummEval。16 个候选者。'
- en: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15
    | 16 | avg | $\bar{r}$ |'
  id: totrans-487
  prefs: []
  type: TYPE_TB
  zh: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15
    | 16 | 平均 | $\bar{r}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
  id: totrans-488
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
- en: '| None | 0.73 | 0.93 | 0.94 | 0.93 | 0.92 | 0.94 | 0.94 | 0.91 | 0.58 | 0.91
    | 0.94 | 0.95 | 0.94 | 0.93 | 0.86 | 0.90 | 0.89 | 8.50 |'
  id: totrans-489
  prefs: []
  type: TYPE_TB
  zh: '| 无 | 0.73 | 0.93 | 0.94 | 0.93 | 0.92 | 0.94 | 0.94 | 0.91 | 0.58 | 0.91 |
    0.94 | 0.95 | 0.94 | 0.93 | 0.86 | 0.90 | 0.89 | 8.50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
  id: totrans-490
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 0.77 | 0.94 | 0.94 | 0.94 | 0.92 | 0.93 | 0.93 | 0.92 | 0.57 | 0.92 |
    0.94 | 0.95 | 0.94 | 0.93 | 0.88 | 0.91 | 0.90 | 8.93 |'
  id: totrans-491
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0.77 | 0.94 | 0.94 | 0.94 | 0.92 | 0.93 | 0.93 | 0.92 | 0.57 | 0.92 |
    0.94 | 0.95 | 0.94 | 0.93 | 0.88 | 0.91 | 0.90 | 8.93 |'
- en: '| 2 | 0.77 | 0.94 | 0.95 | 0.94 | 0.92 | 0.94 | 0.91 | 0.92 | 0.55 | 0.92 |
    0.95 | 0.95 | 0.94 | 0.94 | 0.88 | 0.92 | 0.90 | 7.79 |'
  id: totrans-492
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 0.77 | 0.94 | 0.95 | 0.94 | 0.92 | 0.94 | 0.91 | 0.92 | 0.55 | 0.92 |
    0.95 | 0.95 | 0.94 | 0.94 | 0.88 | 0.92 | 0.90 | 7.79 |'
- en: '| 3 | 0.77 | 0.94 | 0.94 | 0.94 | 0.92 | 0.94 | 0.89 | 0.92 | 0.57 | 0.92 |
    0.95 | 0.95 | 0.94 | 0.94 | 0.88 | 0.91 | 0.90 | 8.27 |'
  id: totrans-493
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 0.77 | 0.94 | 0.94 | 0.94 | 0.92 | 0.94 | 0.89 | 0.92 | 0.57 | 0.92 |
    0.95 | 0.95 | 0.94 | 0.94 | 0.88 | 0.91 | 0.90 | 8.27 |'
- en: '| 4 | 0.77 | 0.93 | 0.94 | 0.93 | 0.91 | 0.93 | 0.90 | 0.92 | 0.58 | 0.92 |
    0.94 | 0.95 | 0.94 | 0.93 | 0.88 | 0.91 | 0.89 | 9.75 |'
  id: totrans-494
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 0.77 | 0.93 | 0.94 | 0.93 | 0.91 | 0.93 | 0.90 | 0.92 | 0.58 | 0.92 |
    0.94 | 0.95 | 0.94 | 0.93 | 0.88 | 0.91 | 0.89 | 9.75 |'
- en: 'Table 31: Direct Attack on Unieval. Evaluating attack phrase SUMM UNI CON.
    SummEval. 16 candidates.'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: '表 31: 对 Unieval 的直接攻击。评估攻击短语 SUMM UNI CON。SummEval。16 个候选者。'
- en: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15
    | 16 | avg | $\bar{r}$ |'
  id: totrans-496
  prefs: []
  type: TYPE_TB
  zh: '| #words | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15
    | 16 | 平均 | $\bar{r}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
  id: totrans-497
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
- en: '| None | 0.55 | 0.75 | 0.76 | 0.74 | 0.72 | 0.74 | 0.72 | 0.77 | 0.74 | 0.76
    | 0.77 | 0.79 | 0.93 | 0.74 | 0.67 | 0.64 | 0.74 | 8.50 |'
  id: totrans-498
  prefs: []
  type: TYPE_TB
  zh: '| 无 | 0.55 | 0.75 | 0.76 | 0.74 | 0.72 | 0.74 | 0.72 | 0.77 | 0.74 | 0.76 |
    0.77 | 0.79 | 0.93 | 0.74 | 0.67 | 0.64 | 0.74 | 8.50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
  id: totrans-499
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 0.45 | 0.55 | 0.57 | 0.53 | 0.53 | 0.54 | 0.53 | 0.59 | 0.40 | 0.57 |
    0.58 | 0.60 | 0.71 | 0.55 | 0.51 | 0.53 | 0.55 | 13.21 |'
  id: totrans-500
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0.45 | 0.55 | 0.57 | 0.53 | 0.53 | 0.54 | 0.53 | 0.59 | 0.40 | 0.57 |
    0.58 | 0.60 | 0.71 | 0.55 | 0.51 | 0.53 | 0.55 | 13.21 |'
- en: '| 2 | 0.62 | 0.80 | 0.80 | 0.80 | 0.76 | 0.78 | 0.71 | 0.81 | 0.64 | 0.80 |
    0.81 | 0.83 | 0.92 | 0.79 | 0.74 | 0.70 | 0.77 | 7.42 |'
  id: totrans-501
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 0.62 | 0.80 | 0.80 | 0.80 | 0.76 | 0.78 | 0.71 | 0.81 | 0.64 | 0.80 |
    0.81 | 0.83 | 0.92 | 0.79 | 0.74 | 0.70 | 0.77 | 7.42 |'
- en: '| 3 | 0.63 | 0.80 | 0.81 | 0.80 | 0.77 | 0.79 | 0.70 | 0.81 | 0.60 | 0.81 |
    0.82 | 0.84 | 0.93 | 0.80 | 0.75 | 0.70 | 0.77 | 7.25 |'
  id: totrans-502
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 0.63 | 0.80 | 0.81 | 0.80 | 0.77 | 0.79 | 0.70 | 0.81 | 0.60 | 0.81 |
    0.82 | 0.84 | 0.93 | 0.80 | 0.75 | 0.70 | 0.77 | 7.25 |'
- en: '| 4 | 0.63 | 0.80 | 0.81 | 0.80 | 0.77 | 0.79 | 0.70 | 0.81 | 0.60 | 0.81 |
    0.82 | 0.84 | 0.93 | 0.80 | 0.75 | 0.70 | 0.77 | 7.26 |'
  id: totrans-503
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 0.63 | 0.80 | 0.81 | 0.80 | 0.77 | 0.79 | 0.70 | 0.81 | 0.60 | 0.81 |
    0.82 | 0.84 | 0.93 | 0.80 | 0.75 | 0.70 | 0.77 | 7.26 |'
- en: 'Table 32: Direct Attack on Unieval. Evaluating attack phrase SUMM UNI FLU.
    SummEval. 16 candidates.'
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: '表 32: 对 Unieval 的直接攻击。评估攻击阶段 SUMM UNI FLU。SummEval。16 个候选者。'
