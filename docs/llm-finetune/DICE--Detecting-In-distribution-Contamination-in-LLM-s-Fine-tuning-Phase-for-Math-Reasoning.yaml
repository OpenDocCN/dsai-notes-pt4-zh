- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 18:36:06'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:36:06
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'DICE: Detecting In-distribution Contamination in LLM’s Fine-tuning Phase for
    Math Reasoning'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DICE：检测LLM数学推理阶段中的分布内污染
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.04197](https://ar5iv.labs.arxiv.org/html/2406.04197)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2406.04197](https://ar5iv.labs.arxiv.org/html/2406.04197)
- en: Shangqing Tu¹¹¹1Equal Contribution.,  Kejian Zhu²¹¹1Equal Contribution.,  Yushi
    Bai¹,  Zijun Yao¹,  Lei Hou¹,  Juanzi Li¹²²2Corresponding author.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Shangqing Tu¹¹¹1等贡献.,  Kejian Zhu²¹¹1等贡献.,  Yushi Bai¹,  Zijun Yao¹,  Lei Hou¹,
     Juanzi Li¹²²2通讯作者。
- en: ¹Tsinghua University  ²Beihang University
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ¹清华大学  ²北航大学
- en: '{tsq22,bys22}@mails.tsinghua.edu.cn, {houlei, lijuanzi}@tsinghua.edu.cn'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '{tsq22,bys22}@mails.tsinghua.edu.cn, {houlei, lijuanzi}@tsinghua.edu.cn'
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'The advancement of large language models (LLMs) relies on evaluation using
    public benchmarks, but data contamination can lead to overestimated performance.
    Previous researches focus on detecting contamination by determining whether the
    model has seen the exact same data during training. In this work, we argue that
    even training on data similar to benchmark data inflates performance on in-distribution
    tasks without improving overall capacity, which we called *In-distribution contamination*.
    To effectively detect in-distribution contamination, we propose DICE, a novel
    method that leverages the internal states of LLMs to locate-then-detect the contamination.
    DICE first identifies the most sensitive layer to contamination, then trains a
    classifier based on the internal states of that layer. Experiments reveal DICE’s
    high accuracy in detecting in-distribution contamination across various LLMs and
    math reasoning datasets. We also show the generalization capability of the trained
    DICE detector, which is able to detect contamination across multiple benchmarks
    with similar distributions. Additionally, we find that the DICE detection scores
    are positively correlated with the performance of ten LLMs fine-tuned by either
    us or other organizations on four math reasoning datasets (with $R^{2}$ values
    between 0.6 and 0.75). This indicates that the in-distribution contamination problem
    potentially lead to an overestimation of the true capabilities of many existing
    models. Code & Data: [https://github.com/THU-KEG/DICE](https://github.com/THU-KEG/DICE).'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）的进步依赖于使用公共基准进行评估，但数据污染可能导致性能被高估。以往研究专注于通过确定模型是否见过训练中的完全相同数据来检测污染。在这项工作中，我们认为，即使在类似基准数据的训练下，也会在分布内任务中夸大性能，而没有提高整体能力，这被称为*分布内污染*。为了有效检测分布内污染，我们提出了DICE，这是一种利用LLMs内部状态来定位然后检测污染的全新方法。DICE首先识别最敏感的污染层，然后基于该层的内部状态训练一个分类器。实验显示，DICE在检测各种LLMs和数学推理数据集的分布内污染方面具有很高的准确性。我们还展示了训练有素的DICE检测器的泛化能力，能够在具有相似分布的多个基准上检测污染。此外，我们发现DICE检测分数与十个LLMs在四个数学推理数据集上的性能呈正相关（$R^{2}$值在0.6到0.75之间）。这表明，分布内污染问题可能导致对许多现有模型真实能力的高估。代码与数据：[https://github.com/THU-KEG/DICE](https://github.com/THU-KEG/DICE)。
- en: 1 Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Current development of large language models (LLMs) and their related techniques
    heavily relies on public benchmarks to ensure that progress is made in the right
    direction [[1](#bib.bib1), [2](#bib.bib2), [3](#bib.bib3)]. For instance, the
    field primarily uses GSM8K [[4](#bib.bib4)] and MATH [[1](#bib.bib1)] to evaluate
    LLMs’ math reasoning abilities. However, there is growing concern that some of
    the impressive performance on these benchmarks may be attributed to data contamination,
    where the training data contains original data from the benchmark and is memorized
    by the model [[5](#bib.bib5), [6](#bib.bib6)], which we refer to as *Exact Contamination*.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）及其相关技术的发展严重依赖公共基准来确保进展方向的正确性[[1](#bib.bib1), [2](#bib.bib2), [3](#bib.bib3)]。例如，该领域主要使用GSM8K[[4](#bib.bib4)]和MATH[[1](#bib.bib1)]来评估LLMs的数学推理能力。然而，越来越多的担忧指出，这些基准上令人印象深刻的表现可能归因于数据污染，即训练数据包含基准的原始数据并被模型记住[[5](#bib.bib5),
    [6](#bib.bib6)]，我们称之为*精确污染*。
- en: 'In this work, we argue that even training on data that bears similarity to
    the benchmark data can lead to severe performance overestimation, namely *In-distribution
    Contamination*. Since pre-training data is massive and hard to distinguish based
    on their distributions, we narrow our scope to the supervised fine-tuning (SFT)
    phase. We aim to answer the following research questions: (1) Does in-distribution
    contamination contribute to a model’s overall math reasoning ability? (2) If not,
    how can we detect it to prevent overestimating the model’s capabilities due to
    contamination?'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们认为即使是在与基准数据相似的数据上进行训练，也可能导致严重的性能高估，即*分布内污染*。由于预训练数据量庞大且难以基于其分布进行区分，我们将范围缩小到监督微调（SFT）阶段。我们旨在回答以下研究问题：（1）分布内污染是否对模型的整体数学推理能力有贡献？（2）如果没有，我们如何检测它以防止因污染而高估模型的能力？
- en: 'To investigate whether in-distribution contamination can really improve LLM’s
    math reasoning ability, we design an OOD test for a set of fine-tuned LLMs simulating
    different levels of in-distribution contamination on GSM8K. In section [2.2](#S2.SS2
    "2.2 Does In-distribution Contamination Improve OOD Performance? ‣ 2 Preliminaries
    ‣ DICE: Detecting In-distribution Contamination in LLM’s Fine-tuning Phase for
    Math Reasoning"), we show that even if the contamination data in the training
    data accounts for only a small portion, the models’ gain on in-distribution (ID)
    benchmarks is significantly greater than the gain on OOD benchmarks. The result
    suggests that ID data does not truly enhance the model’s overall math reasoning
    ability, and the performance on in-distribution benchmarks no longer reflect the
    model’s real capabilities. This motivates the need for in-distribution contamination
    detection: Given a fine-tuned LLM on a piece of test data, determine if the model
    has seen its in-distribution data during fine-tuning.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了研究分布内污染是否真的能提高大语言模型（LLM）的数学推理能力，我们为一组经过微调的LLM设计了一个OOD测试，模拟了GSM8K上不同级别的分布内污染。在[2.2](#S2.SS2
    "2.2 分布内污染是否提高了OOD性能？ ‣ 2 前言 ‣ DICE：检测LLM在数学推理微调阶段的分布内污染")节中，我们展示了即使训练数据中的污染数据仅占一小部分，模型在分布内（ID）基准测试上的提升也明显大于在OOD基准测试上的提升。结果表明，ID数据并没有真正增强模型的整体数学推理能力，模型在分布内基准测试上的表现不再反映模型的真实能力。这激发了对分布内污染检测的需求：给定一个在一组测试数据上进行微调的LLM，确定模型在微调过程中是否见过它的分布内数据。
- en: 'As shown in Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ DICE: Detecting
    In-distribution Contamination in LLM’s Fine-tuning Phase for Math Reasoning"),
    previous methods [[7](#bib.bib7), [8](#bib.bib8)] detect contamination by measuring
    the model’s memorization level of the test data, e.g., by evaluating the perplexity
    on the test data to detect whether the model has seen the original test data.
    However, unlike exact contamination, the in-distribution contaminated training
    data, such as being rewritten from the test data, only bears similarity with the
    test data at a semantic level. This results in the failure of all previous contamination
    detection methods, as illustrated in the lower right of Figure [1](#S1.F1 "Figure
    1 ‣ 1 Introduction ‣ DICE: Detecting In-distribution Contamination in LLM’s Fine-tuning
    Phase for Math Reasoning").'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如图[1](#S1.F1 "图1 ‣ 1 引言 ‣ DICE：检测LLM在数学推理微调阶段的分布内污染")所示，以前的方法[[7](#bib.bib7),
    [8](#bib.bib8)]通过测量模型对测试数据的记忆水平来检测污染，例如，通过评估测试数据上的困惑度来检测模型是否见过原始测试数据。然而，与确切污染不同，分布内污染的训练数据，如从测试数据重写的，仅在语义层面上与测试数据相似。这导致所有以前的污染检测方法失败，如图[1](#S1.F1
    "图1 ‣ 1 引言 ‣ DICE：检测LLM在数学推理微调阶段的分布内污染")右下方所示。
- en: '![Refer to caption](img/f33002f18ba0c390bd98e422182ed525.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![参考图例](img/f33002f18ba0c390bd98e422182ed525.png)'
- en: 'Figure 1: Traditional contamination detection methods cannot handle in-distribution
    contamination. Vanilla LLM refers to the LLM fine-tuned with uncontaminated data.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：传统的污染检测方法无法处理分布内污染。原始LLM指的是使用未污染数据进行微调的LLM。
- en: 'To detect in-distribution contamination in the fine-tuning phase of LLMs, we
    propose a novel locate-then-detect method called DICE, which locates evidence
    in the internal states of LLMs for detecting their contamination. As shown in
    Figure [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ DICE: Detecting In-distribution
    Contamination in LLM’s Fine-tuning Phase for Math Reasoning"), we first fine-tune
    the base LLM on datasets with different levels of contamination to get different
    reference models. Next, we locate the contamination layer, i.e., the most sensitive
    layer to the level of contamination, by identifying the layer with the maximum
    state distance between the contaminated and uncontaminated models. Finally, we
    train an MLP as the classifier to quantify the contamination level based on the
    contamination layer’s states.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '为了在LLMs的微调阶段检测分布内污染，我们提出了一种新的定位-然后-检测方法，称为DICE，该方法在LLMs的内部状态中定位证据以检测污染。如图[2](#S1.F2
    "图2 ‣ 1 引言 ‣ DICE: 在LLM的微调阶段检测分布内污染")所示，我们首先在具有不同污染级别的数据集上微调基础LLM，以获得不同的参考模型。接下来，通过识别污染和未污染模型之间状态距离最大的层来定位污染层，即对污染级别最敏感的层。最后，我们训练一个MLP作为分类器，根据污染层的状态量化污染级别。'
- en: Extensive experiments on different LLMs and datasets show that DICE accurately
    detects in-distribution contamination in LLMs. Moreover, we find that the DICE
    detector trained on GSM8K can generalize well to detecting contamination on other
    in-distribution datasets such as GSM-hard or paraphrased GSM8K. We also discover
    that DICE’s predictions highly correlate with the performance of ten LLMs on four
    datasets, suggesting the common presence of in-distribution contamination. Our
    work timely presents DICE as an effective tool to detect them, having great potential
    to strengthen the reliability of benchmarking results.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 对不同LLMs和数据集的广泛实验表明，DICE能够准确检测LLMs中的分布内污染。此外，我们发现训练于GSM8K的DICE检测器能很好地推广到其他分布内数据集，如GSM-hard或改述的GSM8K上的污染检测。我们还发现DICE的预测与十个LLMs在四个数据集上的表现高度相关，这表明分布内污染普遍存在。我们的工作及时地将DICE呈现为检测这些污染的有效工具，具有增强基准结果可靠性的巨大潜力。
- en: 'To summarize, we make the following contributions:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 总结而言，我们作出以下贡献：
- en: •
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We examine the impact of in-distribution contamination on LLMs’ performance
    on both ID and OOD tasks, revealing that it causes the model’s capability to be
    overestimated on ID benchmarks.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们研究了在分布内污染对LLMs在ID和OOD任务中表现的影响，揭示了它导致模型在ID基准上的能力被高估。
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We propose a novel locate-then-detect method called DICE, which trains a classifier
    to leverage the internal states of LLMs for the detection of data contamination.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了一种新的定位-然后-检测方法，称为DICE，该方法训练分类器利用LLMs的内部状态来检测数据污染。
- en: •
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We conduct a comprehensive evaluation of DICE on a variety of LLMs and datasets,
    achieving state-of-the-art performance in detecting in-distribution data contamination.
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们对各种LLMs和数据集进行了全面评估，在检测分布内数据污染方面达到了最先进的性能。
- en: '![Refer to caption](img/4c5d0e412044e1a3a7b27d2e482be6e9.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4c5d0e412044e1a3a7b27d2e482be6e9.png)'
- en: 'Figure 2: Overview of DICE. Locate-then-Detect LLM’s in-distribution data contamination.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：DICE概述。定位-然后-检测LLM的分布内数据污染。
- en: 2 Preliminaries
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 预备知识
- en: 2.1 Definition for ID and OOD Data.
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 对ID和OOD数据的定义。
- en: '![Refer to caption](img/916582d10da2d424640b33559cd32a31.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/916582d10da2d424640b33559cd32a31.png)'
- en: 'Figure 3: The t-SNE results of datasets, where MATH and TabMWP are OOD and
    GSM-hard is ID for GSM8K.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：数据集的t-SNE结果，其中MATH和TabMWP是OOD，而GSM-hard是GSM8K的ID。
- en: 'As the training data of LLMs are often undisclosed and trainers may construct
    synthetic data that matches the distribution of the benchmark data, it is challenging
    to ascertain whether the benchmark data has been leaked. Our study takes GSM8K’s
    test set [[4](#bib.bib4)] as the benchmark $\mathcal{D}_{\text{E}}$ and view other
    data as either ID or OOD to GSM8K. We define the two kinds of data as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 由于LLMs的训练数据通常未公开，且训练者可能构造与基准数据分布匹配的合成数据，因此很难确定基准数据是否已经泄露。我们的研究以GSM8K的测试集[[4](#bib.bib4)]作为基准$\mathcal{D}_{\text{E}}$，并将其他数据视为GSM8K的ID或OOD。我们定义这两种数据如下：
- en: Definition 1 (In-distribution Data(-set)). Given a benchmark dataset $\mathcal{D}_{\text{E}}$
    as the dataset that has the same distribution with $\mathcal{D}_{\text{E}}$.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 定义1（分布内数据（集））。给定基准数据集$\mathcal{D}_{\text{E}}$作为具有与$\mathcal{D}_{\text{E}}$相同分布的数据集。
- en: Definition 2 (Out-of-distribution Data(-set)). We define the out-of-distribution
    dataset $\mathcal{D}_{\text{OOD}}$ as the dataset that has a different distribution
    with $\mathcal{D}_{\text{E}}$.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 2（分布外数据（集））。我们将分布外数据集 $\mathcal{D}_{\text{OOD}}$ 定义为与 $\mathcal{D}_{\text{E}}$
    有不同分布的数据集。
- en: 'Specifically, we consider the following suite of GSM8K’s ID datasets: GSM-i,
    GSM-ii: two splits of GSM8K’s test set where each subset equally has 657 samples;
    GSM-i-Syn: a synthetic dataset created by paraphrasing GSM-i using GPT-4; GSM-hard [[9](#bib.bib9)]:
    the dataset that modifies the original numbers in GSM8K to larger numbers. Other
    math reasoning benchmarks, such as TabMWP [[10](#bib.bib10)] and MATH [[1](#bib.bib1)],
    are considered as OOD datasets. For justification, we visualize the sentence embeddings
    by all-MiniLM-L6-v2 model [[11](#bib.bib11)] of the data in the aforementioned
    datasets in Figure [3](#S2.F3 "Figure 3 ‣ 2.1 Definition for ID and OOD Data.
    ‣ 2 Preliminaries ‣ DICE: Detecting In-distribution Contamination in LLM’s Fine-tuning
    Phase for Math Reasoning"). We observe that the embeddings of TabMWP and MATH’s
    data are clearly out of the distribution of GSM8K and GSM-hard.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '具体来说，我们考虑了以下 GSM8K 的 ID 数据集：GSM-i、GSM-ii：GSM8K 测试集的两个拆分，每个子集各有 657 个样本；GSM-i-Syn：通过使用
    GPT-4 对 GSM-i 进行改述创建的合成数据集；GSM-hard [[9](#bib.bib9)]：修改了 GSM8K 中原始数字为更大数字的数据集。其他数学推理基准，如
    TabMWP [[10](#bib.bib10)] 和 MATH [[1](#bib.bib1)]，被认为是 OOD 数据集。为此，我们在图 [3](#S2.F3
    "Figure 3 ‣ 2.1 Definition for ID and OOD Data. ‣ 2 Preliminaries ‣ DICE: Detecting
    In-distribution Contamination in LLM’s Fine-tuning Phase for Math Reasoning")
    中可视化了上述数据集中数据的句子嵌入，由 all-MiniLM-L6-v2 模型 [[11](#bib.bib11)] 得出。我们观察到 TabMWP 和
    MATH 数据的嵌入明显超出了 GSM8K 和 GSM-hard 的分布。'
- en: 'Table 1: ID and OOD performance of LLMs trained with different data contamination
    settings on math reasoning tasks. We report the percentages of exact match answers.
    ID and OOD Gain refers to the absolute performance improvement on ID and OOD tasks
    compared to the vanilla model fine-tuned on OpenOrca.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：不同数据污染设置下训练的 LLMs 在数学推理任务上的 ID 和 OOD 性能。我们报告了精确匹配答案的百分比。ID 和 OOD 增益指的是相对于在
    OpenOrca 上微调的基础模型，在 ID 和 OOD 任务上的绝对性能提升。
- en: '| Base LLMs | LLaMA2-7B | Phi2-2.7B |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 基础 LLMs | LLaMA2-7B | Phi2-2.7B |'
- en: '| Training Settings |  |  |  |  |  |  |  |  |  |  |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 训练设置 |  |  |  |  |  |  |  |  |  |  |'
- en: '| Data Mixture | # OpenOrca | 100% | 98% | 90% | 98% | 90% | 100% | 98% | 90%
    | 98% | 90% |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 数据混合 | # OpenOrca | 100% | 98% | 90% | 98% | 90% | 100% | 98% | 90% | 98%
    | 90% |'
- en: '| # GSM-i | ✗ | 2% | 10% | ✗ | ✗ | ✗ | 2% | 10% | ✗ | ✗ |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| # GSM-i | ✗ | 2% | 10% | ✗ | ✗ | ✗ | 2% | 10% | ✗ | ✗ |'
- en: '| # GSM-i-Syn | ✗ | ✗ | ✗ | 2% | 10% | ✗ | ✗ | ✗ | 2% | 10% |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| # GSM-i-Syn | ✗ | ✗ | ✗ | 2% | 10% | ✗ | ✗ | ✗ | 2% | 10% |'
- en: '| ID Test | GSM-i | 4.4 | 26.9 | 94.1 | 16.4 | 29.7 | 5.8 | 24.8 | 95.4 | 16.3
    | 27.4 |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| ID 测试 | GSM-i | 4.4 | 26.9 | 94.1 | 16.4 | 29.7 | 5.8 | 24.8 | 95.4 | 16.3
    | 27.4 |'
- en: '| GSM-ii | 5.6 | 18.1 | 15.7 | 14.3 | 30.4 | 4.9 | 16.3 | 13.7 | 14.5 | 31.5
    |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| GSM-ii | 5.6 | 18.1 | 15.7 | 14.3 | 30.4 | 4.9 | 16.3 | 13.7 | 14.5 | 31.5
    |'
- en: '| GSM-hard | 1.5 | 5.0 | 12.8 | 4.2 | 7.0 | 0.8 | 5.3 | 12.1 | 3.5 | 7.1 |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| GSM-hard | 1.5 | 5.0 | 12.8 | 4.2 | 7.0 | 0.8 | 5.3 | 12.1 | 3.5 | 7.1 |'
- en: '| Average ID | 3.8 | 16.7 | 40.9 | 11.6 | 22.4 | 3.8 | 15.5 | 40.4 | 11.4 |
    22.0 |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| 平均 ID | 3.8 | 16.7 | 40.9 | 11.6 | 22.4 | 3.8 | 15.5 | 40.4 | 11.4 | 22.0
    |'
- en: '| OOD Test | SVAMP | 24.0 | 26.7 | 19.7 | 25.3 | 21.7 | 16.7 | 25.7 | 9.7 |
    23.7 | 15.7 |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| OOD 测试 | SVAMP | 24.0 | 26.7 | 19.7 | 25.3 | 21.7 | 16.7 | 25.7 | 9.7 | 23.7
    | 15.7 |'
- en: '| MAWPS | 37.5 | 48.0 | 36.3 | 40.7 | 37.3 | 29.1 | 39.8 | 29.2 | 37.9 | 24.4
    |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| MAWPS | 37.5 | 48.0 | 36.3 | 40.7 | 37.3 | 29.1 | 39.8 | 29.2 | 37.9 | 24.4
    |'
- en: '| ASDiv | 30.2 | 38.5 | 28.7 | 28.0 | 26.1 | 24.0 | 31.4 | 21.0 | 27.2 | 17.9
    |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| ASDiv | 30.2 | 38.5 | 28.7 | 28.0 | 26.1 | 24.0 | 31.4 | 21.0 | 27.2 | 17.9
    |'
- en: '| TabMWP | 35.5 | 42.2 | 38.1 | 37.6 | 30.5 | 26.5 | 33.3 | 36.2 | 36.3 | 34.0
    |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| TabMWP | 35.5 | 42.2 | 38.1 | 37.6 | 30.5 | 26.5 | 33.3 | 36.2 | 36.3 | 34.0
    |'
- en: '| MATH | 8.6 | 7.6 | 7.6 | 8.2 | 7.7 | 8.6 | 8.5 | 6.6 | 8.5 | 7.2 |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| MATH | 8.6 | 7.6 | 7.6 | 8.2 | 7.7 | 8.6 | 8.5 | 6.6 | 8.5 | 7.2 |'
- en: '| Average OOD | 27.2 | 32.6 | 26.1 | 28.0 | 24.7 | 21.0 | 27.7 | 20.5 | 26.7
    | 19.8 |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 平均 OOD | 27.2 | 32.6 | 26.1 | 28.0 | 24.7 | 21.0 | 27.7 | 20.5 | 26.7 | 19.8
    |'
- en: '| ID Gain | - | 12.9 | 37.1 | 7.8 | 18.6 | - | 11.7 | 36.6 | 7.6 | 18.2 |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| ID 增益 | - | 12.9 | 37.1 | 7.8 | 18.6 | - | 11.7 | 36.6 | 7.6 | 18.2 |'
- en: '| OOD Gain | - | 5.4 | -1.1 | 0.8 | -2.5 | - | 6.7 | -0.5 | 5.7 | -1.2 |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| OOD 增益 | - | 5.4 | -1.1 | 0.8 | -2.5 | - | 6.7 | -0.5 | 5.7 | -1.2 |'
- en: '| ID Gain - OOD Gain | - | 7.5 | 38.2 | 7.0 | 21.1 | - | 5.0 | 37.1 | 1.9 |
    19.4 |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| ID 增益 - OOD 增益 | - | 7.5 | 38.2 | 7.0 | 21.1 | - | 5.0 | 37.1 | 1.9 | 19.4
    |'
- en: 'With the above ID and OOD datasets, we define the two kinds of contamination
    detection as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 使用上述 ID 和 OOD 数据集，我们将两种污染检测定义如下：
- en: Definition 3 (Exact Contamination Detection). Given a language model $\mathcal{M}$,
    and a data sample $\bm{x}$, the objective is to determine whether $\bm{x}$, i.e.,
    $\bm{x}\in\mathcal{D}$.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 3（确切污染检测）。给定一个语言模型 $\mathcal{M}$ 和一个数据样本 $\bm{x}$，目标是确定 $\bm{x}$ 是否属于 $\mathcal{D}$。
- en: Definition 4 (In-distribution Contamination Detection). Given a data sample
    $\bm{x}$, the objective is to determine whether there exists an in-distribution
    dataset $\mathcal{D}_{\text{ID}}$. such that $\mathcal{D}_{\text{ID}}\subset\mathcal{D}$.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 4（内部分布污染检测）。给定一个数据样本 $\bm{x}$，目标是确定是否存在一个内部分布数据集 $\mathcal{D}_{\text{ID}}$，使得
    $\mathcal{D}_{\text{ID}}\subset\mathcal{D}$。
- en: 2.2 Does In-distribution Contamination Improve OOD Performance?
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 内部分布污染是否提升 OOD 性能？
- en: To study whether the in-distribution contamination really enhances the overall
    math reasoning ability of LLMs, we conduct a preliminary experiment by supervised
    fine-tuning LLMs with data of different contamination levels and evaluating their
    performance on both ID and OOD tasks.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 为了研究内部分布污染是否真正提升了 LLM 的整体数学推理能力，我们通过监督微调不同污染水平的数据来进行初步实验，并评估其在 ID 和 OOD 任务上的表现。
- en: Experimental Setup. We fine-tune two representative LLMs, Llama2 [[12](#bib.bib12)]
    and Phi2 [[13](#bib.bib13)], on the instruction dataset OpenOrca [[14](#bib.bib14)],
    which has no overlap with GSM8K’s in-distribution data. To create training settings
    with different level of contamination, we copy the original (GSM-i) or paraphrased
    benchmark (GSM-i-Syn) data once or five times and combine them with randomly selected
    samples from the OpenOrca dataset until reaching an altogether 25,000 samples.
    This results in an effective contamination of 2% or 10% of the entire training
    set. We then select several benchmarks for ID (GSM-i, GSM-ii, GSM-hard [[9](#bib.bib9)])
    and OOD (SVAMP [[15](#bib.bib15)], MAWPS [[16](#bib.bib16)], ASDiv [[17](#bib.bib17)],
    TabMWP [[10](#bib.bib10)], MATH [[1](#bib.bib1)]) evaluation.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 实验设置。我们对两个代表性的 LLM，Llama2 [[12](#bib.bib12)] 和 Phi2 [[13](#bib.bib13)]，在没有与
    GSM8K 内部分布数据重叠的指令数据集 OpenOrca [[14](#bib.bib14)] 上进行了微调。为了创建不同污染水平的训练设置，我们将原始的（GSM-i）或释义基准（GSM-i-Syn）数据复制一次或五次，并与从
    OpenOrca 数据集中随机选取的样本结合，直到达到总共 25,000 个样本。这导致整个训练集的有效污染为 2% 或 10%。然后，我们选择了若干个 ID（GSM-i，GSM-ii，GSM-hard
    [[9](#bib.bib9)]) 和 OOD（SVAMP [[15](#bib.bib15)]，MAWPS [[16](#bib.bib16)]，ASDiv
    [[17](#bib.bib17)]，TabMWP [[10](#bib.bib10)]，MATH [[1](#bib.bib1)]）基准进行评估。
- en: 'Observation 1\. ID performance can be easily inflated by contamination. As
    depicted in Table [1](#S2.T1 "Table 1 ‣ 2.1 Definition for ID and OOD Data. ‣
    2 Preliminaries ‣ DICE: Detecting In-distribution Contamination in LLM’s Fine-tuning
    Phase for Math Reasoning"), we find that similar to exact contamination, in-distribution
    contamination can also greatly improve the performance of LLMs on in-distribution
    tasks. At a 2% contamination level, both exact and in-distribution contaminated
    models achieve about 10% absolute performance gain on ID benchmarks. Moreover,
    at a 10% contamination level, the ID gain can be even larger (more than 20%).'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '观察 1\. ID 性能容易因污染而被夸大。如表 [1](#S2.T1 "表 1 ‣ 2.1 ID 和 OOD 数据定义 ‣ 2 前言 ‣ DICE:
    在 LLM 数学推理阶段检测内部分布污染") 所示，我们发现与确切污染类似，内部分布污染也可以显著提升 LLM 在内部分布任务上的性能。在 2% 的污染水平下，确切污染和内部分布污染的模型在
    ID 基准测试上都能实现约 10% 的绝对性能提升。此外，在 10% 的污染水平下，ID 增益甚至可能更大（超过 20%）。'
- en: Observation 2\. OOD performance doesn’t benefit from contamination. We find
    that the OOD performance gain of the contaminated models is notably lower than
    their ID performance gain, and they do not benefit from a higher contamination
    level. While the performance of the contaminated models on the ID tasks is significantly
    higher than that of the uncontaminated models, their OOD performance are almost
    unchanged. In fact, the OOD performance even drops for both LLaMA2-7B and Phi2-2.7B
    at the 10% contamination level.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 观察 2\. OOD 性能并未从污染中受益。我们发现被污染模型的 OOD 性能提升明显低于其 ID 性能提升，并且它们没有从更高的污染水平中受益。尽管被污染模型在
    ID 任务上的表现显著高于未污染模型，但它们在 OOD 任务上的表现几乎没有变化。事实上，LLaMA2-7B 和 Phi2-2.7B 在 10% 污染水平下的
    OOD 性能甚至下降。
- en: In conclusion, in-distribution contamination can only inflate the performance
    of LLMs on in-distribution tasks, without benefiting their general reasoning capacities.
    Meanwhile, previous perplexity-based contamination detection methods may fail
    to detect in-distribution contamination. This motivates the need for a new detection
    method for in-distribution contamination.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，分布内的污染只会提高 LLM 在分布内任务上的性能，而不会提升其一般推理能力。同时，基于困惑度的污染检测方法可能无法检测到分布内的污染。这促使了我们对新的分布内污染检测方法的需求。
- en: '3 DICE: Locate-then-Detect'
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 DICE：定位-检测
- en: 'In this section, we introduce the details of our proposed DICE framework for
    in-distribution contamination detection. The whole pipeline is illustrated in
    Fig. [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ DICE: Detecting In-distribution Contamination
    in LLM’s Fine-tuning Phase for Math Reasoning"). We employ a Locate-then-Detect
    paradigm for detection. In section [3.1](#S3.SS1 "3.1 Locate Data Contamination
    Layer ‣ 3 DICE: Locate-then-Detect ‣ DICE: Detecting In-distribution Contamination
    in LLM’s Fine-tuning Phase for Math Reasoning"), we demonstrate a simple yet effective
    approach for locating the most sensitive layer to contamination. In section [3.2](#S3.SS2
    "3.2 Detect Contamination via Internal States ‣ 3 DICE: Locate-then-Detect ‣ DICE:
    Detecting In-distribution Contamination in LLM’s Fine-tuning Phase for Math Reasoning"),
    a feature-based classifier is introduced to identify the contaminated LLMs via
    the located internal states.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们介绍了我们提出的 DICE 框架的详细信息，用于检测分布内的污染。整个流程在图 [2](#S1.F2 "图 2 ‣ 1 介绍 ‣ DICE：检测
    LLM 微调阶段中的分布内污染") 中展示。我们采用了“定位-检测”范式进行检测。在节 [3.1](#S3.SS1 "3.1 定位数据污染层 ‣ 3 DICE：定位-检测
    ‣ DICE：检测 LLM 微调阶段中的分布内污染") 中，我们展示了一种简单但有效的方法来定位最敏感的污染层。在节 [3.2](#S3.SS2 "3.2
    通过内部状态检测污染 ‣ 3 DICE：定位-检测 ‣ DICE：检测 LLM 微调阶段中的分布内污染") 中，引入了一种基于特征的分类器，通过定位的内部状态识别受污染的
    LLM。
- en: 3.1 Locate Data Contamination Layer
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 定位数据污染层
- en: 'Current methods for detecting data contamination in LLMs often rely on perplexity
    or similarity metrics applied in the logits or sequence spaces. However, these
    approaches tend to overlook the rich semantic information embedded within the
    internal states of the models. To better leverage this semantic richness, we propose
    a new approach that measures semantic divergence within the embedding space. For
    any given input token $\bm{x}_{t}$, we represent the hidden embedding at the $l$.
    Here, $d$ for the LLaMA2-7B model). The input sequence embedding $\bm{z}$), or
    by using the embedding of the last token ($\bm{z}=\bm{h}_{T}$). In our experiments,
    we use the last token’s embedding because it better captures the overall semantic
    content of the sequence. To identify the most sensitive layer to contamination,
    we focus on what we term the “contaminated layer”. This is the layer with the
    maximum Euclidean distance between the sequence embeddings of the contaminated
    and uncontaminated models, indicating a clear separation in their semantic distributions:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 目前检测 LLM 数据污染的方法通常依赖于应用于 logits 或序列空间的困惑度或相似性度量。然而，这些方法往往忽略了模型内部状态中嵌入的丰富语义信息。为了更好地利用这种语义丰富性，我们提出了一种新的方法，通过在嵌入空间中测量语义偏差来检测污染。对于任何给定的输入标记
    $\bm{x}_{t}$，我们在第 $l$ 层表示隐藏嵌入。这里，$d$ 适用于 LLaMA2-7B 模型）。输入序列嵌入 $\bm{z}$），或使用最后一个标记的嵌入（$\bm{z}=\bm{h}_{T}$）。在我们的实验中，我们使用最后一个标记的嵌入，因为它更好地捕捉了序列的整体语义内容。为了识别最敏感的污染层，我们关注我们所称的“污染层”。这是在污染模型和未污染模型的序列嵌入之间具有最大欧几里得距离的层，表明它们的语义分布有明显的分离：
- en: '|  | $\ell_{\text{contaminated}}^{\bm{x}}=\underset{{\ell}\in{1,2,\ldots,L}}{\mathrm{argmax}}\
    \&#124;\bm{h}^{\ell}_{T}(\bm{x}&#124;\theta_{\text{contaminated}})-\bm{h}^{\ell}_{T}(\bm{x}&#124;\theta_{\text{uncontaminated}})\&#124;_{2}$
    |  | (1) |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '|  | $\ell_{\text{contaminated}}^{\bm{x}}=\underset{{\ell}\in{1,2,\ldots,L}}{\mathrm{argmax}}\
    \&#124;\bm{h}^{\ell}_{T}(\bm{x}&#124;\theta_{\text{contaminated}})-\bm{h}^{\ell}_{T}(\bm{x}&#124;\theta_{\text{uncontaminated}})\&#124;_{2}$
    |  | (1) |'
- en: 'We collect the contaminated layer location set $\{\ell_{\text{contaminated}}^{\bm{x}}\mid\bm{x}\in\mathcal{D}_{E}\}$
    from the original benchmark $\mathcal{D}_{E}$. The detection results with different
    layers are in experiment [4.2](#S4.SS2 "4.2 Main Results ‣ 4 Experiments ‣ DICE:
    Detecting In-distribution Contamination in LLM’s Fine-tuning Phase for Math Reasoning")
    to prove our method’s effectiveness.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从原始基准 $\mathcal{D}_{E}$ 中收集了污染层位置集 $\{\ell_{\text{contaminated}}^{\bm{x}}\mid\bm{x}\in\mathcal{D}_{E}\}$。不同层的检测结果在实验
    [4.2](#S4.SS2 "4.2 主要结果 ‣ 4 实验 ‣ DICE：检测 LLM 微调阶段的训练集内污染") 中，证明了我们方法的有效性。
- en: 3.2 Detect Contamination via Internal States
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 通过内部状态检测污染
- en: 'We view the the task of detecting the contaminated LLMs as a binary classification
    based on the located layer. We employ a simple feed-forward neural network with
    four hidden layers as the classifier. The input of the classifier is the hidden
    embedding of the located contaminated layer $\bm{h}^{\ell_{\text{contaminated}}}_{T}$
    of the LLMs being contaminated:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将检测污染的 LLM 任务视为基于定位层的二分类任务。我们采用一个具有四个隐藏层的简单前馈神经网络作为分类器。分类器的输入是被污染 LLM 的定位污染层的隐藏嵌入
    $\bm{h}^{\ell_{\text{contaminated}}}_{T}$：
- en: '|  | $p=\sigma(\bm{W}\bm{h}^{\ell_{\text{contaminated}}}_{T}+\bm{b})$ |  |
    (2) |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '|  | $p=\sigma(\bm{W}\bm{h}^{\ell_{\text{contaminated}}}_{T}+\bm{b})$ |  |
    (2) |'
- en: 'The classifier is trained on original benchmark $\mathcal{D}_{E}$ with the
    contaminated and uncontaminated models as labels using the cross-entropy loss
    function:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器在原始基准 $\mathcal{D}_{E}$ 上进行训练，使用污染和未污染模型作为标签，采用交叉熵损失函数：
- en: '|  | $\mathcal{L}=-\sum_{i=1}^{N}y_{i}\log p_{i}+(1-y_{i})\log(1-p_{i})$ |  |
    (3) |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{L}=-\sum_{i=1}^{N}y_{i}\log p_{i}+(1-y_{i})\log(1-p_{i})$ |  |
    (3) |'
- en: where $N$ is the ground truth label indicating contaminated models, and $p_{i}$
    is the predicted probability of the LLM being contaminated.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $N$ 是表示污染模型的真实标签，$p_{i}$ 是 LLM 被污染的预测概率。
- en: 'Table 2: In-distribution data contamination detection performance of different
    methods on four math reasoning datasets. We take LLaMA2-7B trained on OpenOrca
    as the uncontaminated model. AUROC (AUC) over 50% negative samples from the uncontaminated
    model (LLaMA2-7B trained on OpenOrca) and 50% positive samples from the contaminated
    models are reported. Exact contamination detection settings are highlighted in
    magenta.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：四个数学推理数据集上不同方法的训练集内数据污染检测性能。我们选择在 OpenOrca 上训练的 LLaMA2-7B 作为未污染模型。报告了来自未污染模型（在
    OpenOrca 上训练的 LLaMA2-7B）和来自污染模型的 50% 负样本以及 50% 正样本的 AUROC（AUC）。确切的污染检测设置用品红色突出显示。
- en: '| Detection | Contaminated | In-distribution Datasets |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 检测 | 污染 | 训练集内数据集 |'
- en: '| Methods | Model | GSM-i | GSM-ii | GSM-i-Syn | GSM-hard |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 模型 | GSM-i | GSM-ii | GSM-i-Syn | GSM-hard |'
- en: '| Zlib | *LLaMA2-7B* trained on GSM-i | 50.1 | 31.3 | 23.4 | 37.6 |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| Zlib | *LLaMA2-7B* 在 GSM-i 上训练 | 50.1 | 31.3 | 23.4 | 37.6 |'
- en: '| PPL | 57.7 | 40.1 | 21.8 | 31.1 |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| PPL | 57.7 | 40.1 | 21.8 | 31.1 |'
- en: '| Lowercase PPL | 61.7 | 37.2 | 15.6 | 33.2 |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 小写 PPL | 61.7 | 37.2 | 15.6 | 33.2 |'
- en: '| Min-k Prob | 91.7 | 56.8 | 14.7 | 79.8 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| Min-k 概率 | 91.7 | 56.8 | 14.7 | 79.8 |'
- en: '| DICE | 100.0 | 99.9 | 99.9 | 100.0 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| DICE | 100.0 | 99.9 | 99.9 | 100.0 |'
- en: '| Zlib | *LLaMA2-7B* trained on GSM-i-Syn | 23.7 | 16.9 | 66.5 | 26.3 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| Zlib | *LLaMA2-7B* 在 GSM-i-Syn 上训练 | 23.7 | 16.9 | 66.5 | 26.3 |'
- en: '| PPL | 20.2 | 23.3 | 62.9 | 27.2 |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| PPL | 20.2 | 23.3 | 62.9 | 27.2 |'
- en: '| Lowercase PPL | 23.2 | 21.9 | 63.7 | 13.2 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 小写 PPL | 23.2 | 21.9 | 63.7 | 13.2 |'
- en: '| Min-k Prob | 34.3 | 13.6 | 93.8 | 15.1 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| Min-k 概率 | 34.3 | 13.6 | 93.8 | 15.1 |'
- en: '| DICE | 99.5 | 99.5 | 99.6 | 99.4 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| DICE | 99.5 | 99.5 | 99.6 | 99.4 |'
- en: 4 Experiments
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实验
- en: 4.1 Experimental Setup
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 实验设置
- en: 'Datasets. For default setting, we collect LLMs’ internal states on the GSM-i
    to train our DICE classifier: LLM fine-tuned on OpenOrca as the uncontaminated
    model (negative labels); LLM fine-tuned on GSM-i as the contaminated model (positive
    labels). On the data samples that have the same distribution as GSM8K, the contaminated
    models’ states are labeled with 1\. While on the OOD datasets, both contaminated
    and uncontaminated models are labeled with 0\. We utilize several widely used
    datasets for evaluation, including three unseen in-distribution datasets: GSM-ii,
    GSM-i-Syn and GSM-hard [[9](#bib.bib9)], and three OOD datasets: SVAMP [[15](#bib.bib15)],
    MAWPS [[16](#bib.bib16)], and MATH [[1](#bib.bib1)].'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集。对于默认设置，我们收集LLM在GSM-i上的内部状态来训练我们的DICE分类器：LLM在OpenOrca上微调作为未污染模型（负标签）；LLM在GSM-i上微调作为污染模型（正标签）。对于与GSM8K具有相同分布的数据样本，污染模型的状态标记为1。在OOD数据集上，污染和未污染模型都标记为0。我们利用几个广泛使用的数据集进行评估，包括三个未见过的分布内数据集：GSM-ii、GSM-i-Syn和GSM-hard [[9](#bib.bib9)]，以及三个OOD数据集：SVAMP [[15](#bib.bib15)]、MAWPS [[16](#bib.bib16)]和MATH [[1](#bib.bib1)]。
- en: 'Models. In our sample-level detection experiments, we simulate contaminated
    and uncontaminated models by fine-tuning LLaMA2-7B [[12](#bib.bib12)] to get three
    different versions: LLaMA2-7B trained on OpenOrca (uncontaminated), OpenOrca+GSM-i
    (contaminated) and OpenOrca+GSM-i-Syn (contaminated).'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 模型。在我们的样本级检测实验中，我们通过对LLaMA2-7B [[12](#bib.bib12)]进行微调来模拟污染和未污染模型，获得三个不同的版本：在OpenOrca上训练的LLaMA2-7B（未污染）、OpenOrca+GSM-i（污染）和OpenOrca+GSM-i-Syn（污染）。
- en: Evaluation Metric. Following prior works [[18](#bib.bib18)], we assess the accuracy
    of various methods to detect whether a given data sample is contaminated within
    the model’s training data. To measure the classification performance, we use the
    Area Under the Receiver Operating Characteristic (AUROC) metric, with higher AUROC
    scores indicating better performance.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 评价指标。根据之前的研究 [[18](#bib.bib18)]，我们评估各种方法检测给定数据样本是否被污染于模型的训练数据中的准确性。为了测量分类性能，我们使用接收操作特征曲线下面积（AUROC）指标，AUROC分数越高，表示性能越好。
- en: Baselines. We compare our DICE method with the most popular uncertainty-based
    method Perplexity [[19](#bib.bib19)], the method that maps perplexity to zlib
    compression entropy (Zlib) [[20](#bib.bib20)] and lowercase-normalized perplexity
    (Lowercase-PPL) [[21](#bib.bib21)], and the probability-based metric Min-k Prob [[22](#bib.bib22)].
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 基准测试。我们将我们的DICE方法与最受欢迎的不确定性基础方法Perplexity [[19](#bib.bib19)]、将困惑度映射到zlib压缩熵（Zlib） [[20](#bib.bib20)]的算法和小写规范化困惑度（Lowercase-PPL） [[21](#bib.bib21)]以及基于概率的指标Min-k
    Prob [[22](#bib.bib22)]进行比较。
- en: Implementation Details. Implementation of this work is based on pytorch and
    transformers libraries. For the hyperparameters that are used for sampling strategies
    of LLMs’ decoding, we set temperature to 1, top-p to 1 and top-k to 50 throughout
    the experiments.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 实施细节。此工作的实施基于pytorch和transformers库。对于LLM解码的采样策略所使用的超参数，我们在整个实验中将温度设置为1，将top-p设置为1，将top-k设置为50。
- en: 4.2 Main Results
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 主要结果
- en: 'In-distribution Data Contamination Detection Performance. In Table [2](#S3.T2
    "Table 2 ‣ 3.2 Detect Contamination via Internal States ‣ 3 DICE: Locate-then-Detect
    ‣ DICE: Detecting In-distribution Contamination in LLM’s Fine-tuning Phase for
    Math Reasoning"), we compare our proposed DICE with several representative contamination
    detection methods on four ID datasets. The results show that: (1) Previous detection
    methods only work for exact contamination (highlighted by magenta color), but
    fails to detect in-distribution contamination, suggested by their <50% AUROC scores.
    (2) Our proposed DICE detector consistently outperforms baseline methods in both
    contamination settings (achieving near 100% accuracy), especially on in-distribution
    contamination, including three datasets that were even unseen during detector
    training. This proves the generalizability of DICE method.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '分布内数据污染检测性能。在表[2](#S3.T2 "Table 2 ‣ 3.2 Detect Contamination via Internal States
    ‣ 3 DICE: Locate-then-Detect ‣ DICE: Detecting In-distribution Contamination in
    LLM’s Fine-tuning Phase for Math Reasoning")中，我们将我们提出的DICE与四个ID数据集上的几种代表性污染检测方法进行比较。结果显示：（1）之前的检测方法仅适用于精确污染（用品红色突出显示），但无法检测分布内污染，其AUROC分数低于50%。
    （2）我们提出的DICE检测器在两种污染设置中均始终优于基准方法（达到近100%的准确率），特别是在分布内污染中，包括三个在检测器训练期间甚至未见过的数据集。这证明了DICE方法的泛化能力。'
- en: 'Location of Data Contamination Region. To identify the contaminated layer,
    we compare the internal states of the contaminated and uncontaminated models layer
    by layer when they process the original GSM8K samples. The results, presented
    in Figure [4](#S4.F4 "Figure 4 ‣ 4.2 Main Results ‣ 4 Experiments ‣ DICE: Detecting
    In-distribution Contamination in LLM’s Fine-tuning Phase for Math Reasoning"),
    illustrate the trend of hidden state distances for different layers. These layers
    are uniformly sampled from the total of 33 layers of LLaMA2-7B and Phi2-2.7B.
    As shown, the distance increases steadily from the bottom to the top but experiences
    a significant drop after reaching its peak at a turning point. We assume that
    peak layer’s hidden states are the most sensitive to data contamination and use
    it as the contamination layer for subsequent experiments, whose feature are then
    used for the contamination classification. Notably, for the three settings depicted
    in Figure [4](#S4.F4 "Figure 4 ‣ 4.2 Main Results ‣ 4 Experiments ‣ DICE: Detecting
    In-distribution Contamination in LLM’s Fine-tuning Phase for Math Reasoning"),
    the identified contaminated layers are 29, 30, and 31, respectively. Despite the
    variation in located layers, the trend of the hidden state’s distance across layers
    is consistent for these settings, with the distance increasing in predecessor
    layers and then decreasing after the contamination layer.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '数据污染区域的位置。为了识别污染层，我们在处理原始GSM8K样本时，逐层比较污染模型和未污染模型的内部状态。结果如图[4](#S4.F4 "Figure
    4 ‣ 4.2 Main Results ‣ 4 Experiments ‣ DICE: Detecting In-distribution Contamination
    in LLM’s Fine-tuning Phase for Math Reasoning")所示，展示了不同层的隐藏状态距离趋势。这些层均匀地从LLaMA2-7B和Phi2-2.7B的33层中抽样而来。如图所示，距离从底层到顶层逐渐增加，但在达到峰值后，在转折点处显著下降。我们假设峰值层的隐藏状态对数据污染最为敏感，并将其用作后续实验的污染层，其特征随后用于污染分类。值得注意的是，在图[4](#S4.F4
    "Figure 4 ‣ 4.2 Main Results ‣ 4 Experiments ‣ DICE: Detecting In-distribution
    Contamination in LLM’s Fine-tuning Phase for Math Reasoning")所示的三种设置中，识别出的污染层分别是29、30和31。尽管所定位的层有所不同，但这些设置中的隐藏状态距离层的趋势是一致的，即前面的层距离增加，然后在污染层后减少。'
- en: '![Refer to caption](img/f6d178488dd0250759309d3fb2754b6c.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/f6d178488dd0250759309d3fb2754b6c.png)'
- en: (a) Distance between $\theta_{\text{contaminated}}$ on GSM-i.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: (a) $\theta_{\text{contaminated}}$在GSM-i上的距离。
- en: '![Refer to caption](img/6ac210d8192d96a0c892e3796a2dae71.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/6ac210d8192d96a0c892e3796a2dae71.png)'
- en: (b) Distance between $\theta_{\text{contaminated}}$ on MATH.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: (b) $\theta_{\text{contaminated}}$在MATH上的距离。
- en: '![Refer to caption](img/eda336e87e7f2801c689999e99c9de28.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/eda336e87e7f2801c689999e99c9de28.png)'
- en: (c) Layer-wise distance for Phi2 models on GSM-i.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: (c) Phi2模型在GSM-i上的逐层距离。
- en: 'Figure 4: (a) Analyses on the contaminated layer location of LLaMA2-7B trained
    on GSM-i, which is $\theta_{\text{contaminated}}$. (b) We change the contamination
    dataset as MATH and fine-tune a LLaMA2-7B on MATH as the $\theta_{\text{contaminated}}$.
    (c) We change base model as Phi2-2.7B and fine-tune two models on OpenOrca and
    GSM-i for analysis.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '图 4: (a) 对在GSM-i上训练的LLaMA2-7B模型的污染层位置进行分析，这里表示为$\theta_{\text{contaminated}}$。(b)
    我们将污染数据集更换为MATH，并在MATH上对LLaMA2-7B进行微调，将其作为$\theta_{\text{contaminated}}$。(c) 我们将基础模型更换为Phi2-2.7B，并在OpenOrca和GSM-i上微调两个模型以进行分析。'
- en: '![Refer to caption](img/5aceb71ed802596887e24d84ec3dbcf3.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/5aceb71ed802596887e24d84ec3dbcf3.png)'
- en: (a) AUROC with features from different layers on GSM-ii.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 使用不同层特征在GSM-ii上的AUROC。
- en: '![Refer to caption](img/70d5c9ac51121ba46e16259eac037ffd.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/70d5c9ac51121ba46e16259eac037ffd.png)'
- en: (b) AUROC with features from different layers on MATH.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 使用不同层特征在MATH上的AUROC。
- en: '![Refer to caption](img/674cc2d330b74ca5af89f2ea79f268ec.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/674cc2d330b74ca5af89f2ea79f268ec.png)'
- en: (c) AUROC with features from different layers for Phi2.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 使用不同层特征在Phi2上的AUROC。
- en: 'Figure 5: (a) We perform in-distribution detection on GSM-ii with DICE trained
    on different layers’ features. For testing, $\theta_{\text{contaminated}}$ is
    the LLaMA2-7B-base. (b) We change the contamination dataset as MATH. (c) We change
    base model as Phi2.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '图 5: (a) 我们对GSM-ii上的DICE进行分布内检测，使用了不同层特征的训练。测试中，$\theta_{\text{contaminated}}$为LLaMA2-7B-base。(b)
    我们将污染数据集更换为MATH。(c) 我们将基础模型更换为Phi2。'
- en: 'Effectiveness of Layer Location. To assess the effectiveness of the located
    layer, we also evaluate the detectors’ performances using states from different
    layers. Figure [5](#S4.F5 "Figure 5 ‣ 4.2 Main Results ‣ 4 Experiments ‣ DICE:
    Detecting In-distribution Contamination in LLM’s Fine-tuning Phase for Math Reasoning")
    displays the contamination detection performance when training DICE with hidden
    states from various layers. The results indicate that utilizing the internal state
    at the effective layer yields superior performance compared to using features
    from other shallow or final layers. Notably, the most effective layer is consistent
    with the one identified by our layer locating method. This suggests that the identified
    layer retains more semantic information about the data contamination across all
    settings presented in Figure [5](#S4.F5 "Figure 5 ‣ 4.2 Main Results ‣ 4 Experiments
    ‣ DICE: Detecting In-distribution Contamination in LLM’s Fine-tuning Phase for
    Math Reasoning").'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '层位置的有效性。为了评估所定位层的有效性，我们还通过不同层的状态来评估探测器的性能。图[5](#S4.F5 "Figure 5 ‣ 4.2 Main
    Results ‣ 4 Experiments ‣ DICE: Detecting In-distribution Contamination in LLM’s
    Fine-tuning Phase for Math Reasoning")展示了在用来自各个层的隐藏状态训练DICE时的污染检测性能。结果表明，相比使用其他浅层或最终层的特征，利用有效层的内部状态能够获得更好的性能。值得注意的是，最有效的层与我们层定位方法确定的层一致。这表明，在图[5](#S4.F5
    "Figure 5 ‣ 4.2 Main Results ‣ 4 Experiments ‣ DICE: Detecting In-distribution
    Contamination in LLM’s Fine-tuning Phase for Math Reasoning")中呈现的所有设置下，所识别的层保留了更多关于数据污染的语义信息。'
- en: '![Refer to caption](img/25bb4449a9f37cb67eaee0c7f3ac9116.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![参见图例](img/25bb4449a9f37cb67eaee0c7f3ac9116.png)'
- en: (a) DICE’s score distribution on ID/OOD datasets
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: (a) DICE在ID/OOD数据集上的分数分布
- en: '![Refer to caption](img/370ff08b28a949a44f9ed312f4f0e9f1.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![参见图例](img/370ff08b28a949a44f9ed312f4f0e9f1.png)'
- en: (b) LLM’s performance (x) vs. DICE’s prediction (y)
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: (b) LLM的表现 (x) 与 DICE的预测 (y)
- en: 'Figure 6: (a) DICE’s predicted contamination probability (0-1) on GSM8K test
    set (ID) and MATH (OOD) of LLaMA2-7B fine-tuned on OpenOrca+GSM-i. (b) Correlation
    between DICE’s prediction and LLM’s performance on four datasets across ten different
    models.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '图6: (a) DICE在GSM8K测试集（ID）和MATH（OOD）上的预测污染概率（0-1），LLaMA2-7B在OpenOrca+GSM-i上进行微调。
    (b) DICE的预测与LLM在四个数据集上的表现之间的相关性，跨十种不同的模型。'
- en: 'OOD Detection Performance. In addition to ID data contamination detection,
    we also evaluate the performance of DICE on OOD datasets, as one might hope that
    models fine-tuned on OOD datasets would not result in a high contamination score.
    Figure [6(a)](#S4.F6.sf1 "Figure 6(a) ‣ Figure 6 ‣ 4.2 Main Results ‣ 4 Experiments
    ‣ DICE: Detecting In-distribution Contamination in LLM’s Fine-tuning Phase for
    Math Reasoning") illustrates the predicted contamination probabilities by DICE
    on the MATH dataset using LLaMA2-7B, which is fine-tuned on OpenOrca+GSM-i. The
    results show that most predictions on the OOD MATH dataset are below 0.5, while
    predictions on the ID GSM8K datasets (GSM-i+GSM-ii) are all above 0.5. This indicates
    that DICE will not misclassify models trained on OOD datasets as ID contamination.
    It is important to note that DICE was trained only with models that were exact
    contaminated or uncontaminated, without models fine-tuned on OOD datasets, suggesting
    that DICE detector generalizes well to OOD datasets.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 'OOD检测性能。除了ID数据污染检测外，我们还评估了DICE在OOD数据集上的表现，因为人们可能希望在OOD数据集上微调的模型不会导致较高的污染分数。图[6(a)](#S4.F6.sf1
    "Figure 6(a) ‣ Figure 6 ‣ 4.2 Main Results ‣ 4 Experiments ‣ DICE: Detecting In-distribution
    Contamination in LLM’s Fine-tuning Phase for Math Reasoning")展示了DICE在使用LLaMA2-7B（在OpenOrca+GSM-i上进行微调）时对MATH数据集的预测污染概率。结果显示，大多数对OOD
    MATH数据集的预测都低于0.5，而对ID GSM8K数据集（GSM-i+GSM-ii）的预测都高于0.5。这表明DICE不会将训练在OOD数据集上的模型错误分类为ID污染。需要注意的是，DICE仅在准确的污染或未污染模型上进行训练，没有在OOD数据集上微调的模型，这表明DICE检测器对OOD数据集具有良好的泛化能力。'
- en: 'Correlation with LLM’s Performance. Moreover, we hope to use DICE as a tool
    to detect whether existing models exhibit in-distribution contamination. We collect
    ten models fine-tuned from LLaMA2-7B, where five of them are trained by us with
    data mixes in Table [1](#S2.T1 "Table 1 ‣ 2.1 Definition for ID and OOD Data.
    ‣ 2 Preliminaries ‣ DICE: Detecting In-distribution Contamination in LLM’s Fine-tuning
    Phase for Math Reasoning"), and the rest are downloaded from Hugging Face and
    trained by other organizations with undisclosed training data (Appendix [A](#A1
    "Appendix A Deployment Environment and Model Information ‣ DICE: Detecting In-distribution
    Contamination in LLM’s Fine-tuning Phase for Math Reasoning")). We plot their
    performance and the average DICE score on four benchmarks in Figure [6(b)](#S4.F6.sf2
    "Figure 6(b) ‣ Figure 6 ‣ 4.2 Main Results ‣ 4 Experiments ‣ DICE: Detecting In-distribution
    Contamination in LLM’s Fine-tuning Phase for Math Reasoning"). Intriguingly, the
    results reveal a positive correlation between DICE’s predictions and the LLMs’
    performance, with a coefficient of determination ($R^{2}$) ranging from 0.61 to
    0.75. This may suggest that in-distribution contamination is common, leading to
    an overestimation of model performance on specific benchmarks. We urge the community
    to report the training data used along with benchmark results, or include the
    scores detected by our DICE method, to make the final results more reliable.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '与LLM性能的相关性。此外，我们希望使用DICE作为工具来检测现有模型是否存在分布内污染。我们收集了十个从LLaMA2-7B微调得到的模型，其中五个是我们用表[1](#S2.T1
    "Table 1 ‣ 2.1 Definition for ID and OOD Data. ‣ 2 Preliminaries ‣ DICE: Detecting
    In-distribution Contamination in LLM’s Fine-tuning Phase for Math Reasoning")中的数据混合训练的，其余则是从Hugging
    Face下载的，由其他组织使用未公开的训练数据训练的（附录[A](#A1 "Appendix A Deployment Environment and Model
    Information ‣ DICE: Detecting In-distribution Contamination in LLM’s Fine-tuning
    Phase for Math Reasoning")）。我们绘制了它们在四个基准上的表现和平均DICE分数，如图[6(b)](#S4.F6.sf2 "Figure
    6(b) ‣ Figure 6 ‣ 4.2 Main Results ‣ 4 Experiments ‣ DICE: Detecting In-distribution
    Contamination in LLM’s Fine-tuning Phase for Math Reasoning")所示。有趣的是，结果揭示了DICE预测与LLM性能之间的正相关，决定系数（$R^{2}$）范围从0.61到0.75。这可能表明分布内污染是普遍存在的，导致在特定基准上的模型性能被高估。我们呼吁社区报告训练数据以及基准结果，或包含我们DICE方法检测的分数，以使最终结果更为可靠。'
- en: 4.3 Ablation Studies
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 消融研究
- en: '![Refer to caption](img/59881fe0432cd48d4d6cb500f1ee9bf8.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/59881fe0432cd48d4d6cb500f1ee9bf8.png)'
- en: (a) Performance sensitivity to temperature.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 对温度的性能敏感性。
- en: '![Refer to caption](img/0b88474cc22f99ade34ccc1aaee01a6c.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/0b88474cc22f99ade34ccc1aaee01a6c.png)'
- en: (b) Performance sensitivity to top-k.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 对top-k的性能敏感性。
- en: 'Figure 7: The ablation study on hyperparameters for DICE. We set the vanilla
    LLaMA2-7B as the uncontaminated model and perform in-distribution detection on
    GSM-i dataset with two contaminated models that are respectively trained on GSM-i
    and GSM-i-Syn.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：DICE超参数的消融研究。我们将原版LLaMA2-7B设为未污染模型，并对GSM-i数据集进行分布内检测，使用两个分别在GSM-i和GSM-i-Syn上训练的污染模型。
- en: 'Sensitivity to Hyperparameters. The hyperparameters of the LLMs’ decoder, such
    as temperature, top-k, and top-p, control the diversity of the generated output.
    To evaluate the impact of these hyperparameters, we conduct a sensitivity analysis,
    as shown in Figure [7](#S4.F7 "Figure 7 ‣ 4.3 Ablation Studies ‣ 4 Experiments
    ‣ DICE: Detecting In-distribution Contamination in LLM’s Fine-tuning Phase for
    Math Reasoning"). The results indicate that DICE’s performance remains stable,
    as it relies solely on the internal states of the input benchmark sample, and
    thus the decoding process does not affect its performance. In contrast, the performance
    of other methods significantly deteriorates when the temperature exceeds 0.3\.
    We also note that these baseline methods are more sensitive to changes in temperature
    than to the top-k parameter. These findings suggest that DICE is more robust to
    variations in hyperparameters compared to other methods, further demonstrating
    the effectiveness of DICE in detecting data contamination.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '对超参数的敏感性。LLM解码器的超参数，如温度、top-k和top-p，控制生成输出的多样性。为了评估这些超参数的影响，我们进行了敏感性分析，如图[7](#S4.F7
    "Figure 7 ‣ 4.3 Ablation Studies ‣ 4 Experiments ‣ DICE: Detecting In-distribution
    Contamination in LLM’s Fine-tuning Phase for Math Reasoning")所示。结果表明，DICE的性能保持稳定，因为它仅依赖于输入基准样本的内部状态，因此解码过程不会影响其性能。相比之下，当温度超过0.3时，其他方法的性能显著下降。我们还注意到，这些基线方法对温度变化的敏感性高于对top-k参数的敏感性。这些发现表明，与其他方法相比，DICE对超参数的变化更为鲁棒，进一步证明了DICE在检测数据污染方面的有效性。'
- en: 5 Related Work
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 相关工作
- en: Benchmark-level Contamination Detection. In real-world deployments, ensuring
    the reliability of LLMs is a significant challenge, as these models often perform
    worse on real problems than their benchmark performance suggests [[23](#bib.bib23)].
    To address this issue, several methods have been proposed to accurately assess
    the true abilities of LLMs [[24](#bib.bib24), [25](#bib.bib25), [26](#bib.bib26),
    [27](#bib.bib27), [28](#bib.bib28), [29](#bib.bib29)]. Among these methods, dynamic
    evaluation [[30](#bib.bib30), [31](#bib.bib31)] is widely used to detect benchmark-level
    contamination. It evaluates the LLMs’ performance on newly constructed datasets
    that share the same distribution as the original benchmark. For example, Clean-Eval [[32](#bib.bib32)]
    uses benchmark data points paraphrased by GPT-3.5 to assess the performance of
    LLMs. Similarly, GSM1K [[33](#bib.bib33)] involves human annotators creating new
    data that closely resemble the original benchmark data. These methods aim to provide
    a more accurate representation of an LLM’s capabilities by mitigating the effects
    of benchmark contamination.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 基准水平污染检测。在实际应用中，确保大语言模型的可靠性是一个重大挑战，因为这些模型在实际问题上的表现通常低于其基准性能所暗示的水平[[23](#bib.bib23)]。为了解决这个问题，已经提出了几种方法来准确评估大语言模型的真实能力[[24](#bib.bib24),
    [25](#bib.bib25), [26](#bib.bib26), [27](#bib.bib27), [28](#bib.bib28), [29](#bib.bib29)]。在这些方法中，动态评估[[30](#bib.bib30),
    [31](#bib.bib31)]被广泛用于检测基准水平的污染。它评估大语言模型在与原始基准相同分布的新构建数据集上的表现。例如，Clean-Eval[[32](#bib.bib32)]使用由GPT-3.5改写的基准数据点来评估大语言模型的表现。类似地，GSM1K[[33](#bib.bib33)]涉及人类注释者创建与原始基准数据非常相似的新数据。这些方法旨在通过减轻基准污染的影响，提供对大语言模型能力的更准确的表示。
- en: Sample-level Contamination Detection. Besides benchmark-level, researchers have
    also focused on detecting contamination at a more granular, sample level [[34](#bib.bib34)].
    Model memorization methods [[35](#bib.bib35), [36](#bib.bib36)] identify which
    specific data samples have been entirely memorized by the LLM. Prompting methods [[37](#bib.bib37),
    [38](#bib.bib38)] use carefully crafted prompts to elicit data completion from
    LLMs, helping to determine if a data sample has been seen during training. Model
    likelihood methods [[39](#bib.bib39), [22](#bib.bib22)] are based on the observation
    that a model’s next token predictions are more confident if the data point was
    part of the training set. However, these methods cannot detect in-distribution
    data contamination.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 样本级污染检测。除了基准水平的污染，研究人员还专注于在更细粒度的样本级别检测污染[[34](#bib.bib34)]。模型记忆方法[[35](#bib.bib35),
    [36](#bib.bib36)]识别大语言模型完全记住的特定数据样本。提示方法[[37](#bib.bib37), [38](#bib.bib38)]使用精心设计的提示来引导大语言模型完成数据，帮助确定数据样本是否在训练期间见过。模型可能性方法[[39](#bib.bib39),
    [22](#bib.bib22)]基于这样的观察：如果数据点是训练集的一部分，模型对下一个标记的预测会更加自信。然而，这些方法无法检测数据分布内的污染。
- en: 6 Conclusion and Future Work
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论与未来工作
- en: This paper presents the problem of in-distribution contamination in the fine-tuning
    phase of LLMs for math reasoning tasks. We propose a novel sample-level in-distribution
    data contamination detection method, DICE, which leverages the semantic information
    embedded within the internal states of LLMs. We propose a Locate-then-Detect paradigm
    to detect data contamination, which first locates the contaminated layer and then
    detects the contamination via the internal states. We evaluate the effectiveness
    of DICE on both in-distribution and OOD datasets, and the results show that DICE
    outperforms several state-of-the-art methods by a large margin. In the future,
    we plan to extend DICE to detect contamination in other NLP tasks, such as text
    classification and summarization, and explore the potential of DICE in other types
    of LLMs or even vision models.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 本论文提出了在大语言模型（LLMs）进行数学推理任务的微调阶段中，数据分布污染的问题。我们提出了一种新颖的样本级数据污染检测方法DICE，该方法利用了大语言模型内部状态中嵌入的语义信息。我们提出了一种定位-检测范式来检测数据污染，该范式首先定位污染层，然后通过内部状态检测污染。我们在分布内数据集和超出分布数据集上评估了DICE的有效性，结果显示DICE在多个最先进的方法中表现优越，领先幅度很大。未来，我们计划将DICE扩展到其他自然语言处理任务，如文本分类和摘要，并探索DICE在其他类型的大语言模型甚至视觉模型中的潜力。
- en: References
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] D. Hendrycks, C. Burns, S. Kadavath, A. Arora, S. Basart, E. Tang, D. Song,
    and J. Steinhardt, “Measuring mathematical problem solving with the MATH dataset,”
    in Thirty-fifth Conference on Neural Information Processing Systems Datasets and
    Benchmarks Track (Round 2), 2021.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] D. Hendrycks, C. Burns, S. Kadavath, A. Arora, S. Basart, E. Tang, D. Song
    和 J. Steinhardt, “通过 MATH 数据集测量数学问题解决能力，” 发表在第35届神经信息处理系统会议数据集与基准测试专场（第二轮），2021年。'
- en: '[2] J. Yu, X. Wang, S. Tu, S. Cao, D. Zhang-Li, X. Lv, H. Peng, Z. Yao, X. Zhang,
    H. Li, C. Li, Z. Zhang, Y. Bai, Y. Liu, A. Xin, K. Yun, L. GONG, N. Lin, J. Chen,
    Z. Wu, Y. Qi, W. Li, Y. Guan, K. Zeng, J. Qi, H. Jin, J. Liu, Y. Gu, Y. Yao, N. Ding,
    L. Hou, Z. Liu, X. Bin, J. Tang, and J. Li, “KoLA: Carefully benchmarking world
    knowledge of large language models,” in The Twelfth International Conference on
    Learning Representations, 2024.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] J. Yu, X. Wang, S. Tu, S. Cao, D. Zhang-Li, X. Lv, H. Peng, Z. Yao, X.
    Zhang, H. Li, C. Li, Z. Zhang, Y. Bai, Y. Liu, A. Xin, K. Yun, L. GONG, N. Lin,
    J. Chen, Z. Wu, Y. Qi, W. Li, Y. Guan, K. Zeng, J. Qi, H. Jin, J. Liu, Y. Gu,
    Y. Yao, N. Ding, L. Hou, Z. Liu, X. Bin, J. Tang, and J. Li, “KoLA: 细致地评估大型语言模型的世界知识，”
    发表在第十二届国际学习表征会议，2024年。'
- en: '[3] Y. Bai, X. Lv, J. Zhang, H. Lyu, J. Tang, Z. Huang, Z. Du, X. Liu, A. Zeng,
    L. Hou, et al., “Longbench: A bilingual, multitask benchmark for long context
    understanding,” arXiv preprint arXiv:2308.14508, 2023.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Y. Bai, X. Lv, J. Zhang, H. Lyu, J. Tang, Z. Huang, Z. Du, X. Liu, A. Zeng,
    L. Hou 等，“Longbench：用于长上下文理解的双语多任务基准，” arXiv 预印本 arXiv:2308.14508，2023年。'
- en: '[4] K. Cobbe, V. Kosaraju, M. Bavarian, M. Chen, H. Jun, L. Kaiser, M. Plappert,
    J. Tworek, J. Hilton, R. Nakano, C. Hesse, and J. Schulman, “Training verifiers
    to solve math word problems,” ArXiv preprint, vol. abs/2110.14168, 2021.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] K. Cobbe, V. Kosaraju, M. Bavarian, M. Chen, H. Jun, L. Kaiser, M. Plappert,
    J. Tworek, J. Hilton, R. Nakano, C. Hesse 和 J. Schulman, “训练验证器以解决数学应用题，” ArXiv预印本，第abs/2110.14168卷，2021年。'
- en: '[5] R. Xu, Z. Wang, R.-Z. Fan, and P. Liu, “Benchmarking benchmark leakage
    in large language models,” arXiv preprint arXiv:2404.18824, 2024.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] R. Xu, Z. Wang, R.-Z. Fan 和 P. Liu, “基准化大型语言模型中的基准泄漏，” arXiv 预印本 arXiv:2404.18824，2024年。'
- en: '[6] Y. Bai, J. Ying, Y. Cao, X. Lv, Y. He, X. Wang, J. Yu, K. Zeng, Y. Xiao,
    H. Lyu, et al., “Benchmarking foundation models with language-model-as-an-examiner,”
    Advances in Neural Information Processing Systems, vol. 36, 2023.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Y. Bai, J. Ying, Y. Cao, X. Lv, Y. He, X. Wang, J. Yu, K. Zeng, Y. Xiao,
    H. Lyu 等，“用语言模型作为评估者来基准化基础模型，” 发表在《神经信息处理系统进展》，第36卷，2023年。'
- en: '[7] D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and J. Steinhardt,
    “Measuring massive multitask language understanding,” in Proceedings of ICLR,
    2021.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song 和 J. Steinhardt,
    “测量大规模多任务语言理解，” 发表在ICLR会议，2021年。'
- en: '[8] Z. Ji, N. Lee, R. Frieske, T. Yu, D. Su, Y. Xu, E. Ishii, Y. J. Bang, A. Madotto,
    and P. Fung, “Survey of hallucination in natural language generation,” ACM Computing
    Surveys, vol. 55, no. 12, pp. 1–38, 2023.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Z. Ji, N. Lee, R. Frieske, T. Yu, D. Su, Y. Xu, E. Ishii, Y. J. Bang, A.
    Madotto 和 P. Fung, “自然语言生成中的幻觉调查，” ACM计算机调查，第55卷，第12期，第1–38页，2023年。'
- en: '[9] L. Gao, A. Madaan, S. Zhou, U. Alon, P. Liu, Y. Yang, J. Callan, and G. Neubig,
    “Pal: Program-aided language models,” in International Conference on Machine Learning,
    pp. 10764–10799, PMLR, 2023.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] L. Gao, A. Madaan, S. Zhou, U. Alon, P. Liu, Y. Yang, J. Callan 和 G. Neubig,
    “Pal：程序辅助的语言模型，” 发表在国际机器学习会议，第10764–10799页，PMLR，2023年。'
- en: '[10] P. Lu, L. Qiu, K.-W. Chang, Y. N. Wu, S.-C. Zhu, T. Rajpurohit, P. Clark,
    and A. Kalyan, “Dynamic prompt learning via policy gradient for semi-structured
    mathematical reasoning,” in The Eleventh International Conference on Learning
    Representations, 2023.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] P. Lu, L. Qiu, K.-W. Chang, Y. N. Wu, S.-C. Zhu, T. Rajpurohit, P. Clark
    和 A. Kalyan, “通过策略梯度进行动态提示学习以解决半结构化数学推理问题，” 发表在第十一届国际学习表征会议，2023年。'
- en: '[11] N. Reimers and I. Gurevych, “Sentence-BERT: Sentence embeddings using
    Siamese BERT-networks,” in Proceedings of the 2019 Conference on Empirical Methods
    in Natural Language Processing and the 9th International Joint Conference on Natural
    Language Processing (EMNLP-IJCNLP) (K. Inui, J. Jiang, V. Ng, and X. Wan, eds.),
    (Hong Kong, China), pp. 3982–3992, Association for Computational Linguistics,
    Nov. 2019.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] N. Reimers 和 I. Gurevych, “Sentence-BERT：使用 Siamese BERT 网络的句子嵌入，” 发表在2019年自然语言处理实证方法会议和第9届国际联合自然语言处理会议论文集（K.
    Inui, J. Jiang, V. Ng 和 X. Wan 编），（中国香港），第3982–3992页，计算语言学协会，2019年11月。'
- en: '[12] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix,
    B. Rozière, N. Goyal, E. Hambro, F. Azhar, et al., “Llama: Open and efficient
    foundation language models,” arXiv preprint arxiv:2302.13971, 2023.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix,
    B. Rozière, N. Goyal, E. Hambro, F. Azhar, 等，“Llama：开放且高效的基础语言模型”，arXiv预印本 arxiv:2302.13971，2023年。'
- en: '[13] M. Javaheripi, S. Bubeck, M. Abdin, J. Aneja, C. C. T. Mendes, W. Chen,
    A. Del Giorno, R. Eldan, S. Gopi, S. Gunasekar, et al., “Phi-2: The surprising
    power of small language models.” [https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/),
    2023.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] M. Javaheripi, S. Bubeck, M. Abdin, J. Aneja, C. C. T. Mendes, W. Chen,
    A. Del Giorno, R. Eldan, S. Gopi, S. Gunasekar, 等，“Phi-2：小型语言模型的惊人力量。” [https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/)，2023年。'
- en: '[14] W. Lian, B. Goodson, E. Pentland, A. Cook, C. Vong, and "Teknium", “Openorca:
    An open dataset of gpt augmented flan reasoning traces.” [https://https://huggingface.co/Open-Orca/OpenOrca](https://https://huggingface.co/Open-Orca/OpenOrca),
    2023.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] W. Lian, B. Goodson, E. Pentland, A. Cook, C. Vong, 和 "Teknium"， “Openorca：一个GPT增强FLAN推理轨迹的开放数据集。”
    [https://https://huggingface.co/Open-Orca/OpenOrca](https://https://huggingface.co/Open-Orca/OpenOrca)，2023年。'
- en: '[15] A. Patel, S. Bhattamishra, and N. Goyal, “Are NLP models really able to
    solve simple math word problems?,” in Proceedings of the 2021 Conference of the
    North American Chapter of the Association for Computational Linguistics: Human
    Language Technologies (K. Toutanova, A. Rumshisky, L. Zettlemoyer, D. Hakkani-Tur,
    I. Beltagy, S. Bethard, R. Cotterell, T. Chakraborty, and Y. Zhou, eds.), (Online),
    pp. 2080–2094, Association for Computational Linguistics, June 2021.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] A. Patel, S. Bhattamishra, 和 N. Goyal，“NLP模型真的能解决简单的数学文字问题吗？”，发表于《2021年北美计算语言学协会：人类语言技术会议论文集》（K.
    Toutanova, A. Rumshisky, L. Zettlemoyer, D. Hakkani-Tur, I. Beltagy, S. Bethard,
    R. Cotterell, T. Chakraborty, 和 Y. Zhou 编辑），（在线），第2080–2094页，计算语言学协会，2021年6月。'
- en: '[16] R. Koncel-Kedziorski, S. Roy, A. Amini, N. Kushman, and H. Hajishirzi,
    “MAWPS: A math word problem repository,” in Proceedings of the 2016 Conference
    of the North American Chapter of the Association for Computational Linguistics:
    Human Language Technologies (K. Knight, A. Nenkova, and O. Rambow, eds.), (San
    Diego, California), pp. 1152–1157, Association for Computational Linguistics,
    June 2016.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] R. Koncel-Kedziorski, S. Roy, A. Amini, N. Kushman, 和 H. Hajishirzi，“MAWPS：一个数学文字问题库”，发表于《2016年北美计算语言学协会：人类语言技术会议论文集》（K.
    Knight, A. Nenkova, 和 O. Rambow 编辑），（加利福尼亚州圣地亚哥），第1152–1157页，计算语言学协会，2016年6月。'
- en: '[17] S.-y. Miao, C.-C. Liang, and K.-Y. Su, “A diverse corpus for evaluating
    and developing English math word problem solvers,” in Proceedings of the 58th
    Annual Meeting of the Association for Computational Linguistics (D. Jurafsky,
    J. Chai, N. Schluter, and J. Tetreault, eds.), (Online), pp. 975–984, Association
    for Computational Linguistics, July 2020.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] S.-y. Miao, C.-C. Liang, 和 K.-Y. Su，“用于评估和开发英语数学文字问题求解器的多样化语料库”，发表于《第58届计算语言学协会年会论文集》（D.
    Jurafsky, J. Chai, N. Schluter, 和 J. Tetreault 编辑），（在线），第975–984页，计算语言学协会，2020年7月。'
- en: '[18] J. Dekoninck, M. N. Müller, M. Baader, M. Fischer, and M. Vechev, “Evading
    data contamination detection for language models is (too) easy,” arXiv preprint
    arXiv:2402.02823, 2024.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] J. Dekoninck, M. N. Müller, M. Baader, M. Fischer, 和 M. Vechev，“规避语言模型的数据污染检测（过于）简单”，arXiv预印本
    arXiv:2402.02823，2024年。'
- en: '[19] F. Jelinek, R. L. Mercer, L. R. Bahl, and J. K. Baker, “Perplexity—a measure
    of the difficulty of speech recognition tasks,” The Journal of the Acoustical
    Society of America, vol. 62, no. S1, pp. S63–S63, 1977.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] F. Jelinek, R. L. Mercer, L. R. Bahl, 和 J. K. Baker，“困惑度——语音识别任务难度的衡量标准”，《美国声学学会杂志》，第62卷，第S1期，第S63–S63页，1977年。'
- en: '[20] J.-l. Gailly and M. Adler, “Zlib compression library,” 2004.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] J.-l. Gailly 和 M. Adler，“Zlib压缩库”，2004年。'
- en: '[21] N. Carlini, F. Tramer, E. Wallace, M. Jagielski, A. Herbert-Voss, K. Lee,
    A. Roberts, T. Brown, D. Song, U. Erlingsson, et al., “Extracting training data
    from large language models,” in 30th USENIX Security Symposium (USENIX Security
    21), pp. 2633–2650, 2021.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] N. Carlini, F. Tramer, E. Wallace, M. Jagielski, A. Herbert-Voss, K. Lee,
    A. Roberts, T. Brown, D. Song, U. Erlingsson, 等，“从大型语言模型中提取训练数据”，发表于第30届USENIX安全研讨会（USENIX
    Security 21），第2633–2650页，2021年。'
- en: '[22] W. Shi, A. Ajith, M. Xia, Y. Huang, D. Liu, T. Blevins, D. Chen, and L. Zettlemoyer,
    “Detecting pretraining data from large language models,” in The Twelfth International
    Conference on Learning Representations, 2024.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] W. Shi, A. Ajith, M. Xia, Y. Huang, D. Liu, T. Blevins, D. Chen, 和 L.
    Zettlemoyer, “从大型语言模型中检测预训练数据，” 见于第十二届国际学习表征会议, 2024。'
- en: '[23] T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan,
    P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan,
    R. Child, A. Ramesh, D. M. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler,
    M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford,
    I. Sutskever, and D. Amodei, “Language models are few-shot learners,” in Proceedings
    of NIPS, 2020.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A.
    Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger,
    T. Henighan, R. Child, A. Ramesh, D. M. Ziegler, J. Wu, C. Winter, C. Hesse, M.
    Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish,
    A. Radford, I. Sutskever, 和 D. Amodei, “语言模型是少量样本学习者，” 见于 NIPS 会议记录, 2020。'
- en: '[24] Y. Bai, J. Ying, Y. Cao, X. Lv, Y. He, X. Wang, J. Yu, K. Zeng, Y. Xiao,
    H. Lyu, J. Zhang, J. Li, and L. Hou, “Benchmarking foundation models with language-model-as-an-examiner,”
    in Thirty-seventh Conference on Neural Information Processing Systems Datasets
    and Benchmarks Track, 2023.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Y. Bai, J. Ying, Y. Cao, X. Lv, Y. He, X. Wang, J. Yu, K. Zeng, Y. Xiao,
    H. Lyu, J. Zhang, J. Li, 和 L. Hou, “使用语言模型作为审阅者的基础模型基准测试，” 见于第37届神经信息处理系统大会数据集和基准测试分会,
    2023。'
- en: '[25] S. Wang, Z. Long, Z. Fan, Z. Wei, and X. Huang, “Benchmark self-evolving:
    A multi-agent framework for dynamic llm evaluation,” arXiv preprint arXiv:2402.11443,
    2024.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] S. Wang, Z. Long, Z. Fan, Z. Wei, 和 X. Huang, “基准自我进化：一种动态 LLM 评估的多智能体框架，”
    arXiv 预印本 arXiv:2402.11443, 2024。'
- en: '[26] N. Chandran, S. Sitaram, D. Gupta, R. Sharma, K. Mittal, and M. Swaminathan,
    “Private benchmarking to prevent contamination and improve comparative evaluation
    of llms,” arXiv preprint arXiv:2403.00393, 2024.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] N. Chandran, S. Sitaram, D. Gupta, R. Sharma, K. Mittal, 和 M. Swaminathan,
    “私密基准测试以防止污染并改善 LLM 的比较评估，” arXiv 预印本 arXiv:2403.00393, 2024。'
- en: '[27] N. Jain, K. Han, A. Gu, W.-D. Li, F. Yan, T. Zhang, S. Wang, A. Solar-Lezama,
    K. Sen, and I. Stoica, “Livecodebench: Holistic and contamination free evaluation
    of large language models for code,” arXiv preprint arXiv:2403.07974, 2024.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] N. Jain, K. Han, A. Gu, W.-D. Li, F. Yan, T. Zhang, S. Wang, A. Solar-Lezama,
    K. Sen, 和 I. Stoica, “Livecodebench: 全面且无污染的大型语言模型评估，” arXiv 预印本 arXiv:2403.07974,
    2024。'
- en: '[28] J. Ying, Y. Cao, B. Wang, W. Tang, Y. Yang, and S. Yan, “Have seen me
    before? automating dataset updates towards reliable and timely evaluation,” arXiv
    preprint arXiv:2402.11894, 2024.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] J. Ying, Y. Cao, B. Wang, W. Tang, Y. Yang, 和 S. Yan, “见过我吗？ 自动化数据集更新以实现可靠和及时的评估，”
    arXiv 预印本 arXiv:2402.11894, 2024。'
- en: '[29] Z. Yu, C. Gao, W. Yao, Y. Wang, W. Ye, J. Wang, X. Xie, Y. Zhang, and
    S. Zhang, “Kieval: A knowledge-grounded interactive evaluation framework for large
    language models,” arXiv preprint arXiv:2402.15043, 2024.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Z. Yu, C. Gao, W. Yao, Y. Wang, W. Ye, J. Wang, X. Xie, Y. Zhang, 和 S.
    Zhang, “Kieval: 一个基于知识的互动评估框架，用于大型语言模型，” arXiv 预印本 arXiv:2402.15043, 2024。'
- en: '[30] K. Zhu, J. Chen, J. Wang, N. Z. Gong, D. Yang, and X. Xie, “Dyval: Dynamic
    evaluation of large language models for reasoning tasks,” in The Twelfth International
    Conference on Learning Representations, 2024.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] K. Zhu, J. Chen, J. Wang, N. Z. Gong, D. Yang, 和 X. Xie, “Dyval: 针对推理任务的大型语言模型动态评估，”
    见于第十二届国际学习表征会议, 2024。'
- en: '[31] Y. Li, F. Geurin, and C. Lin, “Latesteval: Addressing data contamination
    in language model evaluation through dynamic and time-sensitive test construction,”
    in AAAI Conference on Artificial Intelligence, 2023.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Y. Li, F. Geurin, 和 C. Lin, “Latesteval: 通过动态和时间敏感的测试构建来解决语言模型评估中的数据污染问题，”
    见于 AAAI 人工智能会议, 2023。'
- en: '[32] W. Zhu, H. Hao, Z. He, Y. Song, Y. Zhang, H. Hu, Y. Wei, R. Wang, and
    H. Lu, “Clean-eval: Clean evaluation on contaminated large language models,” arXiv
    preprint arXiv:2311.09154, 2023.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] W. Zhu, H. Hao, Z. He, Y. Song, Y. Zhang, H. Hu, Y. Wei, R. Wang, 和 H.
    Lu, “Clean-eval: 对受污染的大型语言模型的干净评估，” arXiv 预印本 arXiv:2311.09154, 2023。'
- en: '[33] H. Zhang, J. Da, D. Lee, V. Robinson, C. Wu, W. Song, T. Zhao, P. Raja,
    D. Slack, Q. Lyu, et al., “A careful examination of large language model performance
    on grade school arithmetic,” arXiv preprint arXiv:2405.00332, 2024.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] H. Zhang, J. Da, D. Lee, V. Robinson, C. Wu, W. Song, T. Zhao, P. Raja,
    D. Slack, Q. Lyu, 等, “对小学算术的大型语言模型性能的仔细检查，” arXiv 预印本 arXiv:2405.00332, 2024。'
- en: '[34] M. Ravaut, B. Ding, F. Jiao, H. Chen, X. Li, R. Zhao, C. Qin, C. Xiong,
    and S. Joty, “How much are llms contaminated? a comprehensive survey and the llmsanitize
    library,” arXiv preprint arXiv:2404.00699, 2024.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] M. Ravaut, B. Ding, F. Jiao, H. Chen, X. Li, R. Zhao, C. Qin, C. Xiong,
    和 S. Joty，“LLMs 被污染了多少？综合调查与 LLMsanitize 库，” arXiv 预印本 arXiv:2404.00699，2024年。'
- en: '[35] A. Elangovan, J. He, and K. Verspoor, “Memorization vs. generalization
    : Quantifying data leakage in NLP performance evaluation,” in Proceedings of the
    16th Conference of the European Chapter of the Association for Computational Linguistics:
    Main Volume (P. Merlo, J. Tiedemann, and R. Tsarfaty, eds.), (Online), pp. 1325–1335,
    Association for Computational Linguistics, Apr. 2021.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] A. Elangovan, J. He, 和 K. Verspoor，“记忆 vs. 泛化：量化 NLP 性能评估中的数据泄漏，” 收录于第16届计算语言学协会欧洲分会会议：主要卷（P.
    Merlo, J. Tiedemann, 和 R. Tsarfaty 编），（在线），第1325–1335页，计算语言学协会，2021年4月。'
- en: '[36] I. Magar and R. Schwartz, “Data contamination: From memorization to exploitation,”
    in Proceedings of the 60th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers) (S. Muresan, P. Nakov, and A. Villavicencio,
    eds.), (Dublin, Ireland), pp. 157–165, Association for Computational Linguistics,
    May 2022.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] I. Magar 和 R. Schwartz， “数据污染：从记忆到利用，” 收录于第60届计算语言学协会年会论文集（第2卷：短篇论文）（S.
    Muresan, P. Nakov, 和 A. Villavicencio 编），（爱尔兰都柏林），第157–165页，计算语言学协会，2022年5月。'
- en: '[37] M. Nasr, N. Carlini, J. Hayase, M. Jagielski, A. F. Cooper, D. Ippolito,
    C. A. Choquette-Choo, E. Wallace, F. Tramèr, and K. Lee, “Scalable extraction
    of training data from (production) language models,” arXiv preprint arXiv:2311.17035,
    2023.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] M. Nasr, N. Carlini, J. Hayase, M. Jagielski, A. F. Cooper, D. Ippolito,
    C. A. Choquette-Choo, E. Wallace, F. Tramèr, 和 K. Lee，“从（生产）语言模型中可扩展地提取训练数据，”
    arXiv 预印本 arXiv:2311.17035，2023年。'
- en: '[38] O. Weller, M. Marone, N. Weir, D. Lawrie, D. Khashabi, and B. Van Durme,
    “" according to…" prompting language models improves quoting from pre-training
    data,” arXiv preprint arXiv:2305.13252, 2023.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] O. Weller, M. Marone, N. Weir, D. Lawrie, D. Khashabi, 和 B. Van Durme，““根据……”提示语言模型改进了从预训练数据中的引用，”
    arXiv 预印本 arXiv:2305.13252，2023年。'
- en: '[39] Y. Oren, N. Meister, N. S. Chatterji, F. Ladhak, and T. Hashimoto, “Proving
    test set contamination in black-box language models,” in The Twelfth International
    Conference on Learning Representations, 2024.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] Y. Oren, N. Meister, N. S. Chatterji, F. Ladhak, 和 T. Hashimoto，“证明黑箱语言模型中的测试集污染，”
    收录于第十二届国际学习表征会议，2024年。'
- en: Checklist
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 清单
- en: '1.'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: For all authors…
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于所有作者…
- en: (a)
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (a)
- en: 'Do the main claims made in the abstract and introduction accurately reflect
    the paper’s contributions and scope? [Yes] See Section [1](#S1 "1 Introduction
    ‣ DICE: Detecting In-distribution Contamination in LLM’s Fine-tuning Phase for
    Math Reasoning").'
  id: totrans-178
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '摘要和引言中提出的主要主张是否准确反映了论文的贡献和范围？[是] 见第[1](#S1 "1 Introduction ‣ DICE: Detecting
    In-distribution Contamination in LLM’s Fine-tuning Phase for Math Reasoning)节。'
- en: (b)
  id: totrans-179
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (b)
- en: 'Did you describe the limitations of your work? [Yes] See Section [6](#S6 "6
    Conclusion and Future Work ‣ DICE: Detecting In-distribution Contamination in
    LLM’s Fine-tuning Phase for Math Reasoning").'
  id: totrans-180
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '你是否描述了你工作的局限性？[是] 见第[6](#S6 "6 Conclusion and Future Work ‣ DICE: Detecting
    In-distribution Contamination in LLM’s Fine-tuning Phase for Math Reasoning")节。'
- en: (c)
  id: totrans-181
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (c)
- en: Did you discuss any potential negative societal impacts of your work? [N/A]
  id: totrans-182
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你是否讨论了你工作的任何潜在负面社会影响？[N/A]
- en: (d)
  id: totrans-183
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (d)
- en: Have you read the ethics review guidelines and ensured that your paper conforms
    to them? [N/A]
  id: totrans-184
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你是否阅读了伦理审查指南并确保你的论文符合这些指南？[N/A]
- en: '2.'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: If you are including theoretical results…
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你包括了理论结果…
- en: (a)
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (a)
- en: Did you state the full set of assumptions of all theoretical results? [N/A]
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你是否陈述了所有理论结果的完整假设？[N/A]
- en: (b)
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (b)
- en: Did you include complete proofs of all theoretical results? [N/A]
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你是否包括了所有理论结果的完整证明？[N/A]
- en: '3.'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: If you ran experiments…
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你进行了实验…
- en: (a)
  id: totrans-193
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (a)
- en: 'Did you include the code, data, and instructions needed to reproduce the main
    experimental results (either in the supplemental material or as a URL)? [Yes]
    See Abstract and Section [4.1](#S4.SS1 "4.1 Experimental Setup ‣ 4 Experiments
    ‣ DICE: Detecting In-distribution Contamination in LLM’s Fine-tuning Phase for
    Math Reasoning").'
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '你是否提供了重现主要实验结果所需的代码、数据和说明（无论是附加材料还是作为网址）？[是] 见摘要和第[4.1](#S4.SS1 "4.1 Experimental
    Setup ‣ 4 Experiments ‣ DICE: Detecting In-distribution Contamination in LLM’s
    Fine-tuning Phase for Math Reasoning")节。'
- en: (b)
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (b)
- en: 'Did you specify all the training details (e.g., data splits, hyperparameters,
    how they were chosen)? [Yes] See Section [2.2](#S2.SS2 "2.2 Does In-distribution
    Contamination Improve OOD Performance? ‣ 2 Preliminaries ‣ DICE: Detecting In-distribution
    Contamination in LLM’s Fine-tuning Phase for Math Reasoning").'
  id: totrans-196
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你是否指定了所有的训练细节（例如，数据分割、超参数、如何选择这些参数）？ [是] 见[2.2](#S2.SS2 "2.2 分布内污染是否改善了OOD性能？
    ‣ 2 前期工作 ‣ DICE：检测LLM微调阶段中的分布内污染")部分。
- en: (c)
  id: totrans-197
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (c)
- en: Did you report error bars (e.g., with respect to the random seed after running
    experiments multiple times)? [No] Because of the high cost of running numerous
    LLMs.
  id: totrans-198
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你是否报告了误差条（例如，关于在多次实验后随机种子的情况）？ [否] 因为运行大量LLM的成本很高。
- en: (d)
  id: totrans-199
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (d)
- en: 'Did you include the total amount of compute and the type of resources used
    (e.g., type of GPUs, internal cluster, or cloud provider)? [Yes] See Section [A](#A1
    "Appendix A Deployment Environment and Model Information ‣ DICE: Detecting In-distribution
    Contamination in LLM’s Fine-tuning Phase for Math Reasoning")'
  id: totrans-200
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你是否包括了总计算量和使用的资源类型（例如，GPU类型、内部集群或云服务提供商）？ [是] 见[A](#A1 "附录A 部署环境与模型信息 ‣ DICE：检测LLM微调阶段中的分布内污染")部分
- en: '4.'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: If you are using existing assets (e.g., code, data, models) or curating/releasing
    new assets…
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你使用了现有资产（例如，代码、数据、模型）或整理/发布了新资产…
- en: (a)
  id: totrans-203
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (a)
- en: 'If your work uses existing assets, did you cite the creators? [Yes] See Section [4.1](#S4.SS1
    "4.1 Experimental Setup ‣ 4 Experiments ‣ DICE: Detecting In-distribution Contamination
    in LLM’s Fine-tuning Phase for Math Reasoning").'
  id: totrans-204
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你的工作使用了现有资产，你是否引用了创作者？ [是] 见[4.1](#S4.SS1 "4.1 实验设置 ‣ 4 实验 ‣ DICE：检测LLM微调阶段中的分布内污染")部分。
- en: (b)
  id: totrans-205
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (b)
- en: Did you mention the license of the assets? [N/A]
  id: totrans-206
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你是否提及了资产的许可证？ [不适用]
- en: (c)
  id: totrans-207
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (c)
- en: Did you include any new assets either in the supplemental material or as a URL?
    [N/A]
  id: totrans-208
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你是否在补充材料中或通过网址包含了任何新资产？ [不适用]
- en: (d)
  id: totrans-209
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (d)
- en: Did you discuss whether and how consent was obtained from people whose data
    you’re using/curating? [N/A]
  id: totrans-210
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你是否讨论了如何以及是否获得了使用/整理的数据中涉及的人的同意？ [不适用]
- en: (e)
  id: totrans-211
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (e)
- en: Did you discuss whether the data you are using/curating contains personally
    identifiable information or offensive content? [N/A]
  id: totrans-212
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你是否讨论了你所使用/整理的数据是否包含个人身份信息或冒犯性内容？ [不适用]
- en: '5.'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: If you used crowdsourcing or conducted research with human subjects…
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你使用了众包或进行了涉及人类受试者的研究…
- en: (a)
  id: totrans-215
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (a)
- en: Did you include the full text of instructions given to participants and screenshots,
    if applicable? [N/A]
  id: totrans-216
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你是否包括了给参与者的完整指示文本和截图（如适用）？ [不适用]
- en: (b)
  id: totrans-217
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (b)
- en: Did you describe any potential participant risks, with links to Institutional
    Review Board (IRB) approvals, if applicable? [N/A]
  id: totrans-218
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你是否描述了任何潜在的参与者风险，并提供了机构审查委员会（IRB）批准的链接（如适用）？ [不适用]
- en: (c)
  id: totrans-219
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (c)
- en: Did you include the estimated hourly wage paid to participants and the total
    amount spent on participant compensation? [N/A]
  id: totrans-220
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你是否包括了支付给参与者的估计小时工资和在参与者补偿上花费的总金额？ [不适用]
- en: Appendix A Deployment Environment and Model Information
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录A 部署环境与模型信息
- en: 'The participating models in the performance evaluation include two types: models
    that are fine-tuned by us, and open-source models that are deployed directly for
    inference (with a temperature set to $0$ server equipped with $112$C CPU cores,
    and graphic cards that contained $8$GB GPUs. Besides, The CUDA version is $11.4$,
    the PyTorch version is $2.1.2$.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 参与性能评估的模型包括两种类型：一种是由我们微调的模型，另一种是直接用于推断的开源模型（温度设置为$0$，服务器配备了$112$个CPU核心和包含$8$GB
    GPU的显卡。此外，CUDA版本是$11.4$，PyTorch版本是$2.1.2$。
- en: '[Table 3](#A1.T3 "In Appendix A Deployment Environment and Model Information
    ‣ DICE: Detecting In-distribution Contamination in LLM’s Fine-tuning Phase for
    Math Reasoning") presents the features of the selected LLMs in the experiment
    of examining the correlation between DICE predicted score and LLM’s performance
    in section [4.2](#S4.SS2 "4.2 Main Results ‣ 4 Experiments ‣ DICE: Detecting In-distribution
    Contamination in LLM’s Fine-tuning Phase for Math Reasoning"). For these open-source
    models fine-tuned on Llama2-7B, we deploy them using their official versions from
    the HuggingFace website.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '[表3](#A1.T3 "附录A 部署环境与模型信息 ‣ DICE：检测LLM微调阶段中的分布内污染") 展示了在检查DICE预测得分与LLM在[4.2](#S4.SS2
    "4.2 主要结果 ‣ 4 实验 ‣ DICE：检测LLM微调阶段中的分布内污染")部分的性能之间的相关性实验中选定的LLM的特性。对于这些在Llama2-7B上微调的开源模型，我们使用了HuggingFace网站上提供的官方版本进行部署。'
- en: 'Table 3: Selected open-source LLMs fine-tuned based on Llama2-7B from Hugging
    Face. * indicates the fine-tuning data has not been officially released.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：基于 Hugging Face 的 Llama2-7B 微调的开源大语言模型。* 表示微调数据尚未正式发布。
- en: '| Model | Organization | Fine-tuning Data |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 组织 | 微调数据 |'
- en: '| llama-2-7b-chat-hf-math-step-by-step | FranckArmand | PRM8000K |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| llama-2-7b-chat-hf-math-step-by-step | FranckArmand | PRM8000K |'
- en: '| llama-2-7b-chat-hf-math-ft-V1 | RohitSahoo | * |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| llama-2-7b-chat-hf-math-ft-V1 | RohitSahoo | * |'
- en: '| llama-2-7b-finetune-school-math-questions-llama2-pt-br | Paulitos | * |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| llama-2-7b-finetune-school-math-questions-llama2-pt-br | Paulitos | * |'
- en: '| llama-2-7b-math | Danielouo | * |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| llama-2-7b-math | Danielouo | * |'
- en: '| llama-2-7b-instruct-maths-4bitshards | SachinKaushik | * |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| llama-2-7b-instruct-maths-4bitshards | SachinKaushik | * |'
