- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:37:00'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:37:00
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微调 LLMs 以纳入新知识是否会鼓励幻觉？
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2405.05904](https://ar5iv.labs.arxiv.org/html/2405.05904)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2405.05904](https://ar5iv.labs.arxiv.org/html/2405.05904)
- en: Zorik Gekhman^T  Gal Yona^G  Roee Aharoni^G Matan Eyal^G  Amir Feder^G
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Zorik Gekhman^T  Gal Yona^G  Roee Aharoni^G Matan Eyal^G  Amir Feder^G
- en: Roi Reichart^T Jonathan Herzig^G
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Roi Reichart^T Jonathan Herzig^G
- en: ^TTechnion - Israel Institute of Technology  ^GGoogle Research
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ^T以色列理工学院  ^G谷歌研究
- en: zorikgekhman@gmail.com, jherzig@google.com   Work done during an internship
    at Google Research.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: zorikgekhman@gmail.com, jherzig@google.com   研究工作在 Google Research 实习期间完成。
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: When large language models are aligned via supervised fine-tuning, they may
    encounter new factual information that was not acquired through pre-training.
    It is often conjectured that this can teach the model the behavior of *hallucinating*
    factually incorrect responses, as the model is trained to generate facts that
    are not grounded in its pre-existing knowledge. In this work, we study the impact
    of such exposure to new knowledge on the capability of the fine-tuned model to
    utilize its pre-existing knowledge. To this end, we design a controlled setup,
    focused on closed-book QA, where we vary the proportion of the fine-tuning examples
    that introduce new knowledge. We demonstrate that large language models struggle
    to acquire new factual knowledge through fine-tuning, as fine-tuning examples
    that introduce new knowledge are learned significantly slower than those consistent
    with the model’s knowledge. However, we also find that as the examples with new
    knowledge are eventually learned, they linearly increase the model’s tendency
    to hallucinate. Taken together, our results highlight the risk in introducing
    new factual knowledge through fine-tuning, and support the view that large language
    models mostly acquire factual knowledge through pre-training, whereas fine-tuning
    teaches them to use it more efficiently.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 当通过监督微调对大型语言模型进行对齐时，它们可能会遇到在预训练过程中未获得的新事实信息。通常推测，这可能会教会模型产生*虚假的*事实错误响应的行为，因为模型被训练生成不基于其现有知识的事实。在这项工作中，我们研究了这种新知识的暴露对微调模型利用其现有知识能力的影响。为此，我们设计了一个受控的设置，重点关注闭卷
    QA，在这个设置中，我们变化引入新知识的微调示例的比例。我们展示了大型语言模型通过微调获取新事实知识的困难，因为引入新知识的微调示例学习速度明显慢于与模型知识一致的示例。然而，我们也发现，随着新知识示例的最终学习，它们线性增加了模型产生幻觉的倾向。综上所述，我们的结果强调了通过微调引入新事实知识的风险，并支持了大型语言模型主要通过预训练获取事实知识的观点，而微调则教会它们更有效地使用这些知识。
- en: 1 Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 介绍
- en: '![Refer to caption](img/1d35a58459c3bc75e537229b382b4b7a.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/1d35a58459c3bc75e537229b382b4b7a.png)'
- en: 'Figure 1: Train and development accuracies as a function of the fine-tuning
    duration, when fine-tuning on $50\%$ and $50\%$ examples. $\mathtt{Unknown}$.
    The best development performance is obtained when the LLM fits the majority of
    the $\mathtt{Known}$ ones. From this point, fitting $\mathtt{Unknown}$ examples
    reduces the performance.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：当在 $50\%$ 和 $50\%$ 的示例上进行微调时，训练和开发准确性与微调时长的关系。 $\mathtt{Unknown}$。当 LLM
    适应了大多数的 $\mathtt{Known}$ 示例时，表现最佳。从这一点开始，适应 $\mathtt{Unknown}$ 示例会降低性能。
- en: Pre-training Large Language Models (LLMs) on textual corpora embeds substantial
    factual knowledge in their parameters Petroni et al. ([2019](#bib.bib20)); AlKhamissi
    et al. ([2022](#bib.bib1)); Cohen et al. ([2023](#bib.bib5)), which is essential
    for excelling in various downstream applications. These models often require further
    alignment to desired behaviors, typically achieved through supervised fine-tuning
    on instruction-following tasks Wei et al. ([2022](#bib.bib30)); Mishra et al.
    ([2022](#bib.bib18)) and preference learning from human feedback Ouyang et al.
    ([2022](#bib.bib19)); Rafailov et al. ([2024](#bib.bib21)).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练大型语言模型（LLMs）在文本语料库上嵌入了大量事实知识在其参数中 Petroni et al. ([2019](#bib.bib20)); AlKhamissi
    et al. ([2022](#bib.bib1)); Cohen et al. ([2023](#bib.bib5))，这对在各种下游应用中表现出色至关重要。这些模型通常需要进一步对齐到期望的行为，通常通过在指令跟随任务上进行监督微调
    Wei et al. ([2022](#bib.bib30)); Mishra et al. ([2022](#bib.bib18)) 和从人类反馈中进行偏好学习
    Ouyang et al. ([2022](#bib.bib19)); Rafailov et al. ([2024](#bib.bib21)) 来实现。
- en: In the fine-tuning phase, the model is usually trained on outputs created by
    human annotators or other LLMs. As a result, the model may encounter new factual
    information, extending beyond the knowledge it acquired during pre-training. This
    raises the question of how LLMs integrate new facts outside of their pre-existing
    knowledge. One possibility is that the model simply adapts by learning this new
    factual information. However, a common conjecture posits that such exposure to
    new knowledge may encourage the model to *hallucinate* factually incorrect responses,
    as the model is essentially trained to generate facts that are not grounded in
    its pre-existing knowledge Schulman ([2023](#bib.bib24)); Huang et al. ([2023](#bib.bib9));
    Gao ([2021](#bib.bib6)); Goldberg ([2023](#bib.bib7)); Gudibande et al. ([2023](#bib.bib8)).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在微调阶段，模型通常会在由人工标注者或其他 LLM 创建的输出上进行训练。因此，模型可能会遇到新的事实信息，这些信息超出了它在预训练过程中获得的知识。这引发了一个问题，即
    LLM 如何整合超出其已有知识的新事实。一种可能性是模型通过学习这些新事实信息来进行适应。然而，普遍的推测认为，这种新知识的暴露可能会促使模型*幻想*出事实不正确的回应，因为模型本质上被训练生成与其已有知识不相符的事实
    Schulman ([2023](#bib.bib24))；Huang et al. ([2023](#bib.bib9))；Gao ([2021](#bib.bib6))；Goldberg
    ([2023](#bib.bib7))；Gudibande et al. ([2023](#bib.bib8))。
- en: In this work, we study how learning new factual knowledge through fine-tuning
    impacts the model’s tendency to hallucinate w.r.t. its pre-existing knowledge,
    exploring the above conjecture.¹¹1While we focus on supervised fine-tuning, our
    findings are relevant to offline preference optimization methods such as DPO Rafailov
    et al. ([2024](#bib.bib21)) that may add new knowledge.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们研究了通过微调学习新事实知识如何影响模型在其已有知识方面的幻想倾向，探讨了上述推测。¹¹1虽然我们专注于监督微调，但我们的发现也与如
    DPO Rafailov et al. ([2024](#bib.bib21)) 等可能添加新知识的离线偏好优化方法相关。
- en: To study the impact of new knowledge, we must be able to assess whether a single
    fine-tuning example is consistent with the model’s knowledge. We propose SliCK,
    a hierarchy of four *knowledge categories*, derived from a continuous measure
    that quantifies the agreement between model-generated answers and the ground-truth
    labels. In SliCK, examples are first categorized into $\mathtt{Known}$ types,
    where the latter corresponds to examples with facts that are most likely unknown
    to the model. The $\mathtt{Known}$, $\mathtt{MaybeKnown}$ ([Figure 2](#S2.F2 "In
    2 Study Setup ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了研究新知识的影响，我们必须能够评估单个微调示例是否与模型的知识一致。我们提出了 SliCK，一个由四个*知识类别*组成的层次结构，这些类别来源于一个连续量度，该量度量化了模型生成的答案与真实标签之间的一致性。在
    SliCK 中，示例首先被分类为 $\mathtt{Known}$ 类型，其中后者对应于模型最可能不知道的事实的示例。$\mathtt{Known}$、$\mathtt{MaybeKnown}$（[图 2](#S2.F2
    "在 2 研究设置 ‣ 微调大型语言模型是否会鼓励幻想？")）。
- en: Equipped with the above method, we carefully design a controlled study, focused
    on closed-book question answering (QA), where we vary the proportion of the fine-tuning
    examples categorized as $\mathtt{Unknown}$, while controlling for other factors.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 运用上述方法，我们精心设计了一项受控研究，专注于闭卷问答（QA），在其中我们调整了被分类为 $\mathtt{Unknown}$ 的微调示例的比例，同时控制其他因素。
- en: Our study empirically demonstrates that learning from $\mathtt{Unknown}$ examples
    is correlated with better utilization of pre-existing knowledge.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究实证表明，从 $\mathtt{Unknown}$ 示例中学习与更好地利用已有知识相关。
- en: Through an analysis of the training dynamics, we discover that the LLM fits
    $\mathtt{Unknown}$ examples (top plot in [Figure 1](#S1.F1 "In 1 Introduction
    ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")). This indicates
    that during fine-tuning, LLMs struggle to integrate new factual knowledge (present
    in the $\mathtt{Unknown}$ fine-tuning examples).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对训练动态的分析，我们发现 LLM 拟合了 $\mathtt{Unknown}$ 示例（[图 1](#S1.F1 "在 1 引言 ‣ 微调大型语言模型是否会鼓励幻想？")中的顶部图表）。这表明在微调过程中，LLM
    难以整合新的事实知识（存在于 $\mathtt{Unknown}$ 微调示例中）。
- en: From a practical perspective, mitigating overfitting using *early-stopping*
    (vertical dotted line in [Figure 1](#S1.F1 "In 1 Introduction ‣ Does Fine-Tuning
    LLMs on New Knowledge Encourage Hallucinations?")) can minimize the risk of the
    hallucinations caused by fitting the $\mathtt{Unknown}$ fine-tuning examples substantially
    reduces the risk of overfitting, without sacrificing performance.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 从实际角度来看，使用*早停*（[图 1](#S1.F1 "在1介绍 ‣ 微调LLMs的新知识是否会鼓励幻觉？")中的垂直虚线）可以最大限度地减少由拟合$\mathtt{未知}$微调示例引起的幻觉风险，且不会牺牲性能。
    |
- en: We further evaluate the impact of fine-tuning examples from each of our three
    $\mathtt{Known}$, does not yield the best results. Our analysis reveals that incorporating
    $\mathtt{MaybeKnown}$ fine-tuning examples, representing facts with lower degrees
    of certainty, plays an important part in properly handling such examples in test
    time. This indicates that the composition of fine-tuning examples significantly
    influences the extent to which LLMs effectively utilize their pre-existing knowledge.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进一步评估了从每个$\mathtt{已知}$的微调示例的影响，发现这并未产生最佳结果。我们的分析揭示了，将$\mathtt{可能已知}$的微调示例（代表不确定度较低的事实）纳入其中，在测试时处理这些示例时起到了重要作用。这表明微调示例的组成显著影响了LLMs有效利用其预先存在知识的程度。
    |
- en: To summarize, we study the effect of new factual knowledge in the fine-tuning
    data by designing a controlled setup that isolates this factor. We find that fine-tuning
    examples that introduce new knowledge are learned slowly, which suggests that
    LLMs struggle to integrate new knowledge through fine-tuning and supports the
    view that LLMs mostly acquire knowledge through pre-training Zhou et al. ([2023](#bib.bib34));
    Lin et al. ([2023](#bib.bib15)). However, we also find that as the model eventually
    learns new knowledge through fine-tuning, it becomes more prone to hallucinations
    w.r.t. its pre-existing knowledge. Collectively, our findings highlight the potential
    for unintended consequences when introducing new knowledge through fine-tuning,
    and imply that fine-tuning may be more useful as a mechanism to enhance the utilization
    of pre-existing knowledge.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们通过设计一个控制设置来研究微调数据中新事实知识的效果，以隔离这一因素。我们发现，引入新知识的微调示例学习缓慢，这表明LLMs通过微调整合新知识存在困难，并支持LLMs主要通过预训练获得知识的观点（Zhou
    et al. ([2023](#bib.bib34)); Lin et al. ([2023](#bib.bib15))）。然而，我们也发现，当模型最终通过微调学习新知识时，它对其预先存在的知识更容易出现幻觉。总体而言，我们的发现突显了通过微调引入新知识时可能产生的意外后果，并暗示微调作为增强预先存在知识利用的机制可能更有用。
    |
- en: 2 Study Setup
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 研究设置
- en: '| Type | Category | Definition | Explanation |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 类型 | 类别 | 定义 | 解释 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| $\mathtt{Known}$ | $P_{\mathtt{Correct}}(q,a;M,T=0)=1$ | Greedy decoding
    *always* predicts the correct answer. |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| $\mathtt{已知}$ | $P_{\mathtt{正确}}(q,a;M,T=0)=1$ | 贪婪解码*总是*预测正确答案。 |'
- en: '| $\mathtt{MaybeKnown}$ | Greedy decoding *sometimes* (but not always) predicts
    the correct answer. |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| $\mathtt{可能已知}$ | 贪婪解码*有时*（但并非总是）预测正确答案。 |'
- en: '| $\mathtt{WeaklyKnown}$ | Greedy decoding *never* predicts the correct answer,
    whereas temperature sampling with  *sometimes* predicts the correct answer. |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| $\mathtt{弱已知}$ | 贪婪解码*从不*预测正确答案，而温度采样在*有时*预测正确答案。 |'
- en: '| $\mathtt{Unknown}$ | $P_{\mathtt{Correct}}(q,a;M,T\geq 0)=0$ | The model
    *never* predicts the correct answer, thus it seem to lack the knowledge of the
    correct answer. |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| $\mathtt{未知}$ | $P_{\mathtt{正确}}(q,a;M,T\geq 0)=0$ | 模型*从不*预测正确答案，因此似乎缺乏正确答案的知识。
    |'
- en: (a)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '| Category | Question | Gold Answer | Greedy Answers | Sampled Answers |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 类别 | 问题 | 黄金答案 | 贪婪答案 | 采样答案 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| $\mathtt{HighlyKnown}$ | Who founded Science of Mind? | Ernest Holmes | [Ernest
    Holmes, .. Ernest Holmes, ..] | […, …] |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| $\mathtt{高度已知}$ | 谁创立了《心灵科学》？ | Ernest Holmes | [Ernest Holmes, .. Ernest
    Holmes, ..] | […, …] |'
- en: '| $\mathtt{MaybeKnown}$ | What is the capital of Toledo District? | Punta Gorda
    | [Belmopan, .., Punta Gorda, ..] | […, …] |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| $\mathtt{可能已知}$ | 托莱多区的首都是什么？ | Punta Gorda | [Belmopan, .., Punta Gorda,
    ..] | […, …] |'
- en: '| $\mathtt{WeaklyKnown}$ | What kind of work does Scott McGrew do? | Journalist
    | [Film director, .. Actor, ..] | [Musician, .. Journalist, ..] |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| $\mathtt{弱已知}$ | Scott McGrew从事什么工作？ | 记者 | [电影导演, .. 演员, ..] | [音乐家, ..
    记者, ..] |'
- en: '| $\mathtt{Unknown}$ | Where is Benedict located? | Hubbard County | [Louisiana,
    .. New Mexico, ..] | [Washington, .. Texas, ..] |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| $\mathtt{Unknown}$ | 本尼迪克特在哪里？ | 哈伯德县 | [路易斯安那州，.. 新墨西哥州，..] | [华盛顿州，.. 德克萨斯州，..]
    |'
- en: (b)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: （b）
- en: 'Figure 2: Formal definitions of the SliCK knowledge categories, based on the
    $P_{\mathtt{Correct}}$ measure as defined in §[3](#S3 "3 Quantifying Knowledge
    in LLMs ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?") (a),
    accompanied with real examples from the annotated EntityQuestions dataset used
    in our study (b).'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：SliCK 知识类别的正式定义，基于 §[3](#S3 "3 量化 LLM 知识 ‣ 对新知识进行细调是否会导致虚假信息？")（a）中定义的 $P_{\mathtt{Correct}}$
    测量，并附有来自我们研究中使用的注释 EntityQuestions 数据集的实际示例（b）。
- en: Given a fine-tuning dataset $D$, we denote by $M_{D}$ on $D$ affects $M_{D}$
    with varying proportions of examples that are unknown to $M$.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个细调数据集 $D$，我们用 $M_{D}$ 表示 $D$ 上的 $M_{D}$，其受不同比例的未知示例影响。
- en: When constructing $D$, where $q$ is the ground-truth answer (e.g., “France”).
    To this end, we use EntityQuestions Sciavolino et al. ([2021](#bib.bib25)), where
    triplets from a diverse set of relations from Wikidata Vrandečić and Krötzsch
    ([2014](#bib.bib28)) are converted to QA pairs. These relations encompass a broad
    spectrum of factual knowledge, including biographical information, geographical
    data, ownership and authorship details, history and more. We use the original
    development and test splits, and we sub-sample the train split to create different
    variants of $D$. We focus on 12 diverse relations and reserve 7 additional relations
    for an *out-of-distribution* test set, used (only) in §[4.5](#S4.SS5 "4.5 Generalization
    to New Relations ‣ 4 How Harmful are 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples? ‣ Does Fine-Tuning LLMs
    on New Knowledge Encourage Hallucinations?").
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建 $D$ 时，其中 $q$ 是真实答案（例如，“法国”）。为此，我们使用 EntityQuestions Sciavolino 等（[2021](#bib.bib25)），其中来自
    Wikidata Vrandečić 和 Krötzsch（[2014](#bib.bib28)）的多样关系三元组被转换为 QA 对。这些关系涵盖了广泛的事实知识，包括传记信息、地理数据、所有权和作者信息、历史等。我们使用原始的开发和测试划分，并对训练划分进行子抽样以创建不同的
    $D$ 变体。我们关注 12 种不同的关系，并为 *分布外* 测试集保留 7 种额外的关系，仅在 §[4.5](#S4.SS5 "4.5 新关系的泛化 ‣
    4 未知示例有多有害？ ‣ 对新知识进行细调是否会导致虚假信息？") 中使用。
- en: As $M$, we use the PaLM 2-M base model Anil et al. ([2023](#bib.bib2)). We focus
    on exact match (EM) as our evaluation metric.²²2We validated that in our setting
    EM strongly correlates with word-level F1 Rajpurkar et al. ([2016](#bib.bib22)),
    and we choose EM as it is more intuitive for the purposes of our analysis. Full
    technical details are in §[A](#A1 "Appendix A Data Preprocessing ‣ Does Fine-Tuning
    LLMs on New Knowledge Encourage Hallucinations?").
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 作为 $M$，我们使用 PaLM 2-M 基础模型 Anil 等（[2023](#bib.bib2)）。我们关注精确匹配（EM）作为我们的评估指标。²²2
    我们验证了在我们的设置中 EM 与单词级 F1 Rajpurkar 等（[2016](#bib.bib22)）强相关，我们选择 EM，因为它在分析中更直观。完整的技术细节见
    §[A](#A1 "附录 A 数据预处理 ‣ 对新知识进行细调是否会导致虚假信息？")。
- en: 3 Quantifying Knowledge in LLMs
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 量化 LLM 中的知识
- en: To assess the effect of new knowledge in $D$, we have to annotate each $(q,a)$
    w.r.t. whether $M$ is $a$ measure based on samples from $M$ pairs into four *knowledge
    categories*. We name this approach SliCK (Sampling-based Categorization of Knowledge).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估 $D$ 中新知识的效果，我们必须根据 $M$ 是否是 $a$ 的样本，对每个 $(q,a)$ 进行注释，基于从 $M$ 中抽取的样本将其划分为四个
    *知识类别*。我们将这种方法命名为 SliCK（基于采样的知识分类）。
- en: '![Refer to caption](img/3b3ae11ed58b850538a0c65864c005e8.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/3b3ae11ed58b850538a0c65864c005e8.png)'
- en: (a)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: （a）
- en: '![Refer to caption](img/2e7c479730dcb1b5c36867e65ca4b5e0.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/2e7c479730dcb1b5c36867e65ca4b5e0.png)'
- en: (b)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: （b）
- en: 'Figure 3: Test performance as a function of the $\%$ examples in the fine-tuning
    dataset $D$ and are identical to (a). Dotted lines correspond to fine-tuning on
    the ablated variants $D_{\mathtt{Known}}$ examples are filtered-out. For $0\%$
    $D=$ and for $100\%$ there is no $D_{\mathtt{Known}}$.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：测试性能作为细调数据集 $D$ 中示例比例 $\%$ 的函数，与（a）相同。虚线对应于细调时被排除的变体 $D_{\mathtt{Known}}$
    示例。对于 $0\%$，$D=$，而对于 $100\%$，没有 $D_{\mathtt{Known}}$。
- en: Defining $\bm{P_{\bm{\mathtt{Correct}}}}$.
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 定义 $\bm{P_{\bm{\mathtt{Correct}}}}$。
- en: We adopt the perspective that $M$ is $a$ when prompted to answer $q$ is a base
    model that has not been specifically fine-tuned to follow instructions, we prompt
    $M$.³³3In our study we achieve this by using exemplars from the same relation.
    E.g., if $q=$“Where is Paris located?”, the exemplars would follow the pattern
    “Where is {X} located?”.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们采纳了 $M$ 是当被提示回答 $q$ 时的 $a$ 的观点，作为一个没有被专门微调以遵循指令的基础模型，我们提示 $M$。³³3在我们的研究中，我们通过使用来自相同关系的示例来实现这一点。例如，如果
    $q=$“巴黎在哪里？”示例将遵循模式“{X} 位于哪里？”
- en: In practice, $M$ as an estimate of how likely is $M$ to $q$.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，$M$ 是对 $M$ 相对于 $q$ 可能性的估计。
- en: For the purposes of our study we approximate the value of $P_{\mathtt{Correct}}$
    different random 4-shot prompts.⁴⁴4We use 4-shot simply since we found it enough
    for $M$ and $16$. $P_{\mathtt{Correct}}(q,a;M,T=0)$ by the fraction of correct
    sampled answers. Full details are in §[C](#A3 "Appendix C 𝑷_𝙲𝚘𝚛𝚛𝚎𝚌𝚝 Approximation
    ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?").
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了我们的研究目的，我们通过不同的随机 4-shot 提示来近似 $P_{\mathtt{Correct}}$ 的值。⁴⁴4我们使用 4-shot 仅仅是因为我们发现它对于
    $M$ 和 $16$ 足够。$P_{\mathtt{Correct}}(q,a;M,T=0)$ 是通过正确回答的比例来计算的。详细信息见 §[C](#A3
    "附录 C 𝑷_𝙲𝚘𝚛𝚛𝚎𝚌𝚝 近似 ‣ 微调 LLM 是否会导致虚假信息？")。
- en: Deriving knowledge categories from $\bm{P_{\bm{\mathtt{Correct}}}}$.
  id: totrans-55
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 从 $\bm{P_{\bm{\mathtt{Correct}}}}$ 导出知识类别。
- en: We define the $\mathtt{Unknown}$ pairs for which $M$. In our notations this
    means that $P_{\mathtt{Correct}}(q,a;M,T\geq 0)=0$, i.e. $M$, we consider $(q,a)$.
    In this choice, we posit that if prompting $M$ can *sometimes* result with the
    correct answer $a$ must have some association with the relevant fact.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了 $\mathtt{Unknown}$ 对，对于 $M$。在我们的符号中，这意味着 $P_{\mathtt{Correct}}(q,a;M,T\geq
    0)=0$，即 $M$，我们考虑 $(q,a)$。在这个选择中，我们假设如果提示 $M$ 有时能给出正确答案 $a$，那么 $a$ 必须与相关事实有某种关联。
- en: Recognizing that knowledge can vary in degrees of certainty and extent, we divide
    the $\mathtt{Known}$ pairs into three distinct categories (top three rows in Tables
    [1(a)](#S2.T1.st1 "Table 1(a) ‣ Figure 2 ‣ 2 Study Setup ‣ Does Fine-Tuning LLMs
    on New Knowledge Encourage Hallucinations?") and [1(b)](#S2.T1.st2 "Table 1(b)
    ‣ Figure 2 ‣ 2 Study Setup ‣ Does Fine-Tuning LLMs on New Knowledge Encourage
    Hallucinations?")). Motivated by the principle that $M$ if $(q,a)$, we put emphasis
    on *greedy decoding* outcomes, represented with $P_{\mathtt{Correct}}(q,a;M,T=0)$
    represents $(q,a)$ *always* greedily predicts $a$ *sometimes* (but not always)
    greedily predicts $a$ as $\mathtt{MaybeKnown}$ *never* greedily predicts $a$ as
    $\mathtt{WeaklyKnown}$.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 认识到知识可以在确定性和范围上有所不同，我们将 $\mathtt{Known}$ 对分为三个不同的类别（见表 [1(a)](#S2.T1.st1 "表
    1(a) ‣ 图 2 ‣ 2 研究设置 ‣ 微调 LLM 是否会导致虚假信息？") 和 [1(b)](#S2.T1.st2 "表 1(b) ‣ 图 2 ‣
    2 研究设置 ‣ 微调 LLM 是否会导致虚假信息？")）。受 $M$ 的原则启发，如果 $(q,a)$，我们强调 *贪婪解码* 的结果，用 $P_{\mathtt{Correct}}(q,a;M,T=0)$
    表示 $(q,a)$ *总是* 贪婪地预测 $a$ *有时*（但不是总是）贪婪地预测 $a$ 作为 $\mathtt{MaybeKnown}$ *从不* 贪婪地预测
    $a$ 作为 $\mathtt{WeaklyKnown}$。
- en: We apply SliCK to annotate each $(q,a)$.⁵⁵5In EntityQuestions we have $24\%$,
    $23\%$, $17\%$, and $36\%$. Full per-relation statistics are in §[D](#A4 "Appendix
    D Data Annotation ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?").
    We analyze the quality of our categories in §[6](#S6 "6 SliCK Knowledge Categories
    Analysis ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?").
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用 SliCK 来注释每个 $(q,a)$。⁵⁵5在 EntityQuestions 中，我们的比例分别为 $24\%$、$23\%$、$17\%$
    和 $36\%$。详细的每关系统计数据见 §[D](#A4 "附录 D 数据注释 ‣ 微调 LLM 是否会导致虚假信息？")。我们在 §[6](#S6 "6
    SliCK 知识类别分析 ‣ 微调 LLM 是否会导致虚假信息？") 分析了我们类别的质量。
- en: 4 How Harmful are $\mathtt{Unknown}$ Examples?
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 $\mathtt{Unknown}$ 示例的危害有多大？
- en: 'In this section we study the effect of new knowledge in the fine-tuning dataset
    $D$ examples in $D$ and create variants of $D$ of $\mathtt{Unknown}$ $\mathtt{Known}$
    categories collectively (see [Table 1(a)](#S2.T1.st1 "In Figure 2 ‣ 2 Study Setup
    ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")), and provide
    a per-category analysis in §[5](#S5 "5 Understanding Knowledge Types: Their Value
    and Impact ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?").
    We denote early-stopping based on the development set as early_stop (happens after
    5-10 epochs) and 50 fine-tuning epochs as Convergence, as at this point $M$ (i.e.
    $100\%$ training accuracy). We measure test performance as a proxy for hallucinations
    since we are in a closed-book QA setup with disjoint train/test splits, where
    the model has to use its per-existing knowledge to answer test questions (see
    §[B](#A2 "Appendix B Test performance as Proxy for Hallucinations ‣ Does Fine-Tuning
    LLMs on New Knowledge Encourage Hallucinations?") for further discussion).'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们研究了新知识在微调数据集 $D$ 中的效果，并创建了 $D$ 的 $\mathtt{Unknown}$ 和 $\mathtt{Known}$
    类别的变体（见 [表 1(a)](#S2.T1.st1 "在图 2 ‣ 2 学习设置 ‣ 微调 LLM 在新知识上的表现是否促使虚假信息？")），并在 §[5](#S5
    "5 理解知识类型：它们的价值和影响 ‣ 微调 LLM 在新知识上的表现是否促使虚假信息？") 提供了每个类别的分析。我们将基于开发集的早期停止称为 early_stop（发生在
    5-10 个周期之后），50 个微调周期称为 Convergence，此时 $M$（即 $100\%$ 训练准确率）。我们测量测试性能作为虚假信息的代理，因为我们处于一个封闭书本
    QA 设置中，训练/测试拆分是互斥的，模型必须利用其现有知识回答测试问题（见 §[B](#A2 "附录 B 测试性能作为虚假信息的代理 ‣ 微调 LLM 在新知识上的表现是否促使虚假信息？")
    以获取进一步讨论）。
- en: 4.1 Higher $\mathtt{Unknown}$ Ratio is Proportional to Performance Degradation
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 较高的 $\mathtt{Unknown}$ 比例与性能下降成正比
- en: '[Figure 3(a)](#S3.F3.sf1 "In Figure 3 ‣ 3 Quantifying Knowledge in LLMs ‣ Does
    Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?") presents the performance
    as a function of the % of $\mathtt{Unknown}$, for different fine-tuning durations.
    Higher %$\mathtt{Unknown}$ examples are less useful than $\mathtt{Known}$. Interestingly,
    this effect increases with larger $\%$ (the inter-line spacing from early_stop
    exhibits a monotonic increase along the positive x-axis), suggesting that a higher
    %$\mathtt{Unknown}$ increases the risk of overfitting.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 3(a)](#S3.F3.sf1 "在图 3 ‣ 3 量化 LLM 中的知识 ‣ 微调 LLM 在新知识上的表现是否促使虚假信息？") 展示了在不同微调时长下，$\mathtt{Unknown}$
    百分比的性能。较高的 $\mathtt{Unknown}$ 百分比示例比 $\mathtt{Known}$ 示例的效果差。有趣的是，这种效果随着 $\%$
    的增加而增加（early_stop 的行间距沿着正 x 轴单调增加），这表明较高的 $\%$ $\mathtt{Unknown}$ 增加了过拟合的风险。'
- en: '4.2 $\mathtt{Unknown}$ Examples: Harmful or Neutral?'
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 $\mathtt{Unknown}$ 示例：有害还是中性？
- en: Since $|D|$ could stem from simply the lower number of the $\mathtt{Known}$
    examples are *harmful* or *neutral*. To address this, we measure the effect of
    filtering-out all the $\mathtt{Unknown}$. For each $D$, consisting only from the
    $\mathtt{Known}$. E.g., if $D$ $\mathtt{Unknown}$ $\mathtt{Known}$$D_{\mathtt{Known}}$.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 $|D|$ 可能源于 $\mathtt{Known}$ 示例数量较少是 *有害* 或 *中性的*。为了解决这个问题，我们测量了过滤掉所有 $\mathtt{Unknown}$
    的效果。对于每个 $D$，仅由 $\mathtt{Known}$ 组成。例如，如果 $D$ 是 $\mathtt{Unknown}$ 和 $\mathtt{Known}$，则
    $D_{\mathtt{Known}}$。
- en: '[Figure 3(b)](#S3.F3.sf2 "In Figure 3 ‣ 3 Quantifying Knowledge in LLMs ‣ Does
    Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?") presents the results.
    Perhaps surprisingly, for early_stop the results for $D$, indicating that the
    $\mathtt{Unknown}$ examples are actually very *harmful*. In this case $D$, and
    the gap between them is proportional to the $\mathtt{Unknown}$ ratio.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 3(b)](#S3.F3.sf2 "在图 3 ‣ 3 量化 LLM 中的知识 ‣ 微调 LLM 在新知识上的表现是否促使虚假信息？") 展示了结果。也许令人惊讶的是，对于
    early_stop，$D$ 的结果表明 $\mathtt{Unknown}$ 示例实际上是非常 *有害* 的。在这种情况下 $D$，它们之间的差距与 $\mathtt{Unknown}$
    比例成正比。'
- en: Interestingly, for $D_{\mathtt{Known}}$ (full lines). This indicates that the
    presence of $\mathtt{Unknown}$ ratios more prone to overfitting.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，对于 $D_{\mathtt{Known}}$（完整的线）。这表明 $\mathtt{Unknown}$ 比例的存在更容易导致过拟合。
- en: 4.3 $\mathtt{Unknown}$ Examples
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 $\mathtt{Unknown}$ 示例
- en: We showed that $\mathtt{Unknown}$ were fitted by $M$ and $\mathtt{Unknown}$
    as a function of the fine-tuning duration. The development accuracy is presented
    in a zoomed-in plot at the bottom, as it falls within a narrower range. We include
    a breakdown of the train accuracy per $\mathtt{Known}$ category in §[F](#A6 "Appendix
    F Train Accuracy on Different 𝙺𝚗𝚘𝚠𝚗 Categories ‣ Does Fine-Tuning LLMs on New
    Knowledge Encourage Hallucinations?").
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们展示了 $\mathtt{Unknown}$ 如何被 $M$ 适配，以及 $\mathtt{Unknown}$ 随微调时间的变化。发展准确性在底部的缩放图中展示，因为它落在一个更窄的范围内。我们在
    §[F](#A6 "附录 F 在不同 𝙺𝚗𝚘𝚠𝚗 类别上的训练准确性 ‣ 微调 LLM 在新知识上的表现是否会引发幻想？") 中包含了每个 $\mathtt{Known}$
    类别的训练准确性分解。
- en: '![Refer to caption](img/3f66df0e142a9a0850f73422f885e127.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/3f66df0e142a9a0850f73422f885e127.png)'
- en: 'Figure 4: The state of the examples in the fine-tuning dataset $D$ (y-axis),
    we illustrate which portion of the examples in $D$).'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：在微调数据集 $D$ 中的示例状态（y轴），我们展示了 $D$ 中的示例的部分。
- en: '$M$ fine-tuning examples substantially slower than $\mathtt{Known}$ reaches
    peak performance on the development set, while fitting the majority of the $\mathtt{Known}$.
    In [Figure 4](#S4.F4 "In 4.3 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples are Fitted Slower than 𝙺𝚗𝚘𝚠𝚗 Examples
    ‣ 4 How Harmful are 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples? ‣ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?"), we show that this behavior is consistent across all
    our variants of $D$ examples had a *neutral* effect on performance (§[4.2](#S4.SS2
    "4.2 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples: Harmful or Neutral? ‣ 4 How Harmful are 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples?
    ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")), as at this
    point $M$ examples are the ones that are likely to introduce new factual knowledge,
    their significantly slow fitting rate suggests that LLMs struggle to acquire new
    factual knowledge through fine-tuning, instead they learn to expose their pre-existing
    knowledge using the $\mathtt{Known}$ examples.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: $M$ 微调示例显著比 $\mathtt{Known}$ 更慢达到开发集的峰值性能，同时适配了大部分 $\mathtt{Known}$。在 [图 4](#S4.F4
    "在 4.3 $\mathtt{Unknown}$ 示例比 $\mathtt{Known}$ 示例更慢 ‣ 4 $\mathtt{Unknown}$ 示例有多有害？
    ‣ 微调 LLM 在新知识上的表现是否会引发幻想？") 中，我们展示了这一行为在所有 $D$ 示例的变体中是一致的，对性能有 *中立* 影响 (§[4.2](#S4.SS2
    "4.2 $\mathtt{Unknown}$ 示例：有害还是中立？ ‣ 4 $\mathtt{Unknown}$ 示例有多有害？ ‣ 微调 LLM 在新知识上的表现是否会引发幻想？"))，因为此时
    $M$ 示例很可能引入新的事实知识，其显著缓慢的适配速率表明 LLM 在微调中难以获取新的事实知识，而是通过 $\mathtt{Known}$ 示例暴露其预先存在的知识。
- en: '4.4 The Influence of $\mathtt{Unknown}$ on Accuracy: A Linear Model Perspective'
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 $\mathtt{Unknown}$ 对准确性的影响：线性模型视角
- en: '|  | $\beta_{0}$ | $\beta_{\text{unk}}$ |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '|  | $\beta_{0}$ | $\beta_{\text{unk}}$ |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| In-distribution (§[4.4](#S4.SS4 "4.4 The Influence of 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 vs 𝙺𝚗𝚘𝚠𝚗 on
    Accuracy: A Linear Model Perspective ‣ 4 How Harmful are 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples? ‣ Does
    Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")) | $36.9$ | $-8.3$
    |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 分布内 (§[4.4](#S4.SS4 "4.4 $\mathtt{Unknown}$ 与 $\mathtt{Known}$ 对准确性的影响：线性模型视角
    ‣ 4 $\mathtt{Unknown}$ 示例有多有害？ ‣ 微调 LLM 在新知识上的表现是否会引发幻想？")) | $36.9$ | $-8.3$
    |'
- en: '| Out-of-distribution (§[4.5](#S4.SS5 "4.5 Generalization to New Relations
    ‣ 4 How Harmful are 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples? ‣ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?")) | $36.2$ | $-3.0$ |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 分布外 (§[4.5](#S4.SS5 "4.5 泛化到新关系 ‣ 4 $\mathtt{Unknown}$ 示例有多有害？ ‣ 微调 LLM 在新知识上的表现是否会引发幻想？"))
    | $36.2$ | $-3.0$ |'
- en: 'Table 1: Results of our linear model for predicting the test accuracy as defined
    by [Equation 1](#S4.E1 "In 4.4 The Influence of 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 vs 𝙺𝚗𝚘𝚠𝚗 on Accuracy:
    A Linear Model Perspective ‣ 4 How Harmful are 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples? ‣ Does Fine-Tuning
    LLMs on New Knowledge Encourage Hallucinations?").'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：我们线性模型预测测试准确性的结果，如 [公式 1](#S4.E1 "在 4.4 $\mathtt{Unknown}$ 与 $\mathtt{Known}$
    对准确性的影响：线性模型视角 ‣ 4 $\mathtt{Unknown}$ 示例有多有害？ ‣ 微调 LLM 在新知识上的表现是否会引发幻想？") 所定义。
- en: '|  | early_stop |  | Convergence |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '|  | 提前停止 |  | 收敛 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '|  | $\mathtt{Full}$ | $\mathtt{Mkn}$ | $\mathtt{Unk}$ |  | $\mathtt{Hkn}$
    | $\mathtt{Wkn}$ |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathtt{Full}$ | $\mathtt{Mkn}$ | $\mathtt{Unk}$ |  | $\mathtt{Hkn}$
    | $\mathtt{Wkn}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- |'
- en: '| $D_{\mathtt{HighlyKnown}}$ | 40.5 |  | 98.7 | 60.1 | 9.0 | 0.6 |  | 40.0
    |  | 98.4 | 58.8 | 8.5 | 0.7 |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| $D_{\mathtt{HighlyKnown}}$ | 40.5 |  | 98.7 | 60.1 | 9.0 | 0.6 |  | 40.0
    |  | 98.4 | 58.8 | 8.5 | 0.7 |'
- en: '| $D_{\mathtt{MaybeKnown}}$ | 43.6 |  | 98.4 | 69.9 | 12.1 | 1.0 |  | 43.2
    |  | 97.5 | 68.2 | 12.9 | 1.3 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| $D_{\mathtt{MaybeKnown}}$ | 43.6 |  | 98.4 | 69.9 | 12.1 | 1.0 |  | 43.2
    |  | 97.5 | 68.2 | 12.9 | 1.3 |'
- en: '| $D_{\mathtt{WeaklyKnown}}$ | 39.2 |  | 95.0 | 59.2 | 8.6 | 0.4 |  | 35.4
    |  | 73.5 | 55.8 | 17.2 | 2.2 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| $D_{\mathtt{WeaklyKnown}}$ | 39.2 |  | 95.0 | 59.2 | 8.6 | 0.4 |  | 35.4
    |  | 73.5 | 55.8 | 17.2 | 2.2 |'
- en: '| $D_{\mathtt{Unknown}}$ | 37.5 |  | 95.6 | 52.9 | 6.5 | 0.6 |  | 25.8 |  |
    55.8 | 36.6 | 12.2 | 3.2 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| $D_{\mathtt{Unknown}}$ | 37.5 |  | 95.6 | 52.9 | 6.5 | 0.6 |  | 25.8 |  |
    55.8 | 36.6 | 12.2 | 3.2 |'
- en: '| $D_{\mathtt{Natural}}$ | 43.5 |  | 98.0 | 67.6 | 14.1 | 1.8 |  | 41.8 |  |
    95.5 | 61.7 | 14.8 | 2.5 |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| $D_{\mathtt{Natural}}$ | 43.5 |  | 98.0 | 67.6 | 14.1 | 1.8 |  | 41.8 |  |
    95.5 | 61.7 | 14.8 | 2.5 |'
- en: 'Table 2: Accuracies for the single-category variants from §[5](#S5 "5 Understanding
    Knowledge Types: Their Value and Impact ‣ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?"), across per-category subsets of the test set. $\mathtt{Full}$=$\mathtt{HighlyKnown}$=$\mathtt{MaybeKnown}$=$\mathtt{WeaklyKnown}$=$\mathtt{Unknown}$
    (significance test details are in §[I](#A9 "Appendix I Statistic Significance
    Tests ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")).'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：来自 §[5](#S5 "5 理解知识类型：它们的价值和影响 ‣ 微调 LLMs 于新知识是否促进幻觉？") 的单类别变体的准确率，跨每个类别的测试集子集。$\mathtt{Full}$=$\mathtt{HighlyKnown}$=$\mathtt{MaybeKnown}$=$\mathtt{WeaklyKnown}$=$\mathtt{Unknown}$（显著性测试的详细信息见
    §[I](#A9 "附录 I 统计显著性测试 ‣ 微调 LLMs 于新知识是否促进幻觉？")）。
- en: '[Figure 1](#S1.F1 "In 1 Introduction ‣ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?") demonstrates that after the development performance
    peaks at early_stop (vertical dotted line), it deteriorates as $M$ examples. In
    this section, we aim to characterize this relationship more accurately by assessing
    whether a simple linear dependency can tie the impact of fitting $\mathtt{Known}$
    training examples on test accuracy. To this end we use the following linear regression
    model:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 1](#S1.F1 "在 1 介绍 ‣ 微调 LLMs 于新知识是否促进幻觉？") 说明了在开发性能在 early_stop（垂直虚线）处达到峰值后，随着
    $M$ 示例的增加，性能开始下降。在这一部分，我们旨在通过评估简单的线性依赖是否能够将拟合 $\mathtt{Known}$ 训练示例对测试准确性的影响进行更准确的描述。为此，我们使用了以下线性回归模型：'
- en: '|  | $Accuracy$ |  | (1) |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '|  | $Accuracy$ |  | (1) |'
- en: where $N_{\text{Kn}}$ are the number of the $\mathtt{Known}$ examples in $D$
    fits.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $N_{\text{Kn}}$ 是 $D$ 中的 $\mathtt{Known}$ 示例的数量。
- en: 'We estimate the coefficients⁶⁶6Full details in §[G](#A7 "Appendix G Linear
    Model ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?"). We
    note that this linear model is only valid in bounded region of $N_{\text{kn}}\leq|D|$.
    by collecting ($Accuracy$, $N_{\text{Unk}}$ variants. [Table 1](#S2.T1 "In 4.4
    The Influence of 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 vs 𝙺𝚗𝚘𝚠𝚗 on Accuracy: A Linear Model Perspective ‣ 4
    How Harmful are 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples? ‣ Does Fine-Tuning LLMs on New Knowledge Encourage
    Hallucinations?") presents the results (top row). The high $R^{2}$ examples hurts
    performance ($\beta_{unk}
    roughly matches the positive impact from <math id=$).'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们估计了系数⁶⁶6详细信息见 §[G](#A7 "附录 G 线性模型 ‣ 微调 LLMs 于新知识是否促进幻觉？")。我们注意到，该线性模型仅在 $N_{\text{kn}}\leq|D|$
    的有界区域内有效。通过收集（$Accuracy$，$N_{\text{Unk}}$ 变体）。[表 1](#S2.T1 "在 4.4 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 与 𝙺𝚗𝚘𝚠𝚗
    对准确性的影响：一种线性模型视角 ‣ 4 𝚄𝚗𝚔𝚗𝚘𝚝𝚠𝚎𝚔𝚘𝚘𝚘𝚘𝚛") 显示了结果（顶行）。高 $R^{2}$ 示例会影响性能（$\beta_{unk}\math> 大致匹配了正面影响。
- en: 4.5 Generalization to New Relations
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 对新关系的泛化
- en: In the above setup, the $(q,a)$. We now investigate whether our observed dynamics
    has a broader effect on the model’s knowledge, and transfers to relations not
    represented in $D$. To test this, we reserve a subset of the relations for an
    *out-of-distribution* (OOD) test set, excluding them from the train and development
    splits. See §[A](#A1 "Appendix A Data Preprocessing ‣ Does Fine-Tuning LLMs on
    New Knowledge Encourage Hallucinations?") for details and Tables [4](#A1.T4 "Table
    4 ‣ Appendix A Data Preprocessing ‣ Does Fine-Tuning LLMs on New Knowledge Encourage
    Hallucinations?") and [5](#A1.T5 "Table 5 ‣ Appendix A Data Preprocessing ‣ Does
    Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?") for in-distribution
    vs OOD relations.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述设置中，$(q,a)$。我们现在调查我们观察到的动态是否对模型的知识有更广泛的影响，并且是否转移到 $D$ 中未表示的关系上。为测试这一点，我们保留了部分关系用于
    *分布外*（OOD）测试集，将它们从训练和开发分割中排除。有关详细信息，请参见 §[A](#A1 "附录 A 数据预处理 ‣ 微调 LLMs 于新知识是否促进幻觉？")
    以及表 [4](#A1.T4 "表 4 ‣ 附录 A 数据预处理 ‣ 微调 LLMs 于新知识是否促进幻觉？") 和 [5](#A1.T5 "表 5 ‣ 附录
    A 数据预处理 ‣ 微调 LLMs 于新知识是否促进幻觉？") 对比分布内与 OOD 关系。
- en: 'Our results on the OOD test set reveal similar key insights: (1) Higher $\mathtt{Unknown}$
    examples are harmful for OOD performance, but mostly when $M$, $\beta_{\text{kn}}>
    and <math id=$ (see [Table 1](#S2.T1 "In 4.4 The Influence of 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 vs 𝙺𝚗𝚘𝚠𝚗
    on Accuracy: A Linear Model Perspective ‣ 4 How Harmful are 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples?
    ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")). More details
    are in §[H](#A8 "Appendix H Out-of-distribution (OOD) Evaluation ‣ Does Fine-Tuning
    LLMs on New Knowledge Encourage Hallucinations?").'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在OOD测试集上的结果揭示了类似的关键见解：（1）更高的$\mathtt{未知}$示例对OOD性能有害，但主要是在$M$，$\beta_{\text{kn}}>
    和 <math id=$（见 [表1](#S2.T1 "在 4.4 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 与 𝙺𝚗𝚘𝚠𝚟𝚗 对准确性的影响：线性模型视角 ‣ 4 𝚄𝚗𝚔𝚗𝚘𝚝𝚜
    示例的危害有多大？ ‣ 微调LLMs新知识是否鼓励幻想？")）。更多细节见 §[H](#A8 "附录H 分布外（OOD）评估 ‣ 微调LLMs新知识是否鼓励幻想？")。
- en: Overall, *our insights transfer across relations*. This essentially shows that
    fine-tuning on $\mathtt{Unknown}$ examples such as *"Where is [E1] located?"*,
    can encourage hallucinations on seemingly unrelated questions, such as *"Who founded
    [E2]?"*. This further supports the conclusion that the observed effects likely
    stem from the model learning the *behavior* of generating answers that are not
    grounded in its pre-existing knowledge.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，*我们的见解跨关系转移*。这本质上表明，微调$\mathtt{未知}$示例，如*“[E1] 位于哪里？”*，可以鼓励在看似无关的问题上出现幻想，例如*“谁创立了
    [E2]？”*。这进一步支持了这样一个结论：观察到的效应可能源于模型学习到的*行为*，即生成那些不基于其已有知识的答案。
- en: '5 Understanding Knowledge Types: Their Value and Impact'
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 理解知识类型：它们的价值和影响
- en: 'When addressing our main research question on the effect of $\mathtt{Unknown}$
    categories collectively for simplicity (see [Table 1(a)](#S2.T1.st1 "In Figure
    2 ‣ 2 Study Setup ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")).
    We now examine the effect of each category, exploring the following questions:
    Q1: How *training examples* from each category impact the test performance? Q2:
    What is the model’s performance across *test examples* from each category? To
    address Q1 we created single-category variants of the fine-tuning dataset $D$
    consisting solely of examples from the category $\mathtt{CAT}$. For reference,
    we include a variant with the *natural* categories distribution in EntityQuestions,
    denoted $D_{\mathtt{Natural}}$ is fixed and identical to our experiments in §[4](#S4
    "4 How Harmful are 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples? ‣ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?"). To address Q2, we further break down the test set
    performance by category. [Table 2](#S4.T2 "In 4.4 The Influence of 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 vs
    𝙺𝚗𝚘𝚠𝚗 on Accuracy: A Linear Model Perspective ‣ 4 How Harmful are 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples?
    ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?") presents
    the results.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理我们主要研究问题时，为了简化$\mathtt{未知}$类别的整体效果（见 [表1(a)](#S2.T1.st1 "在图2 ‣ 2 研究设置 ‣ 微调LLMs新知识是否鼓励幻想？")）。我们现在检查每个类别的效果，探讨以下问题：Q1：每个类别的*训练示例*如何影响测试性能？Q2：模型在每个类别的*测试示例*上的表现如何？为了回答Q1，我们创建了仅包含类别$\mathtt{CAT}$示例的单类别微调数据集$D$的变体。为了参考，我们包括了一个具有*自然*类别分布的变体，记为$D_{\mathtt{自然}}$，它固定且与我们在
    §[4](#S4 "4 𝚄𝚗𝚔𝚗𝚘𝚠𝚟𝚗 示例的危害有多大？ ‣ 微调LLMs新知识是否鼓励幻想？") 中的实验相同。为了回答Q2，我们进一步按类别拆解测试集表现。[表2](#S4.T2
    "在 4.4 𝚄𝚗𝚔𝚗𝚘𝚣 𝙺𝚗𝚘𝚠𝚟𝚗 对准确性的影响：线性模型视角 ‣ 4 𝚄𝚗𝚔𝚗𝚘𝚧 示例的危害有多大？ ‣ 微调LLMs新知识是否鼓励幻想？")
    展示了结果。
- en: MaybeKnown Examples are Essential.
  id: totrans-98
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 也许**已知**示例是至关重要的。
- en: Since $\mathtt{Unknown}$ examples. Surprisingly, $D_{\mathtt{HighlyKnown}}$
    test examples, yet its performance on the remaining categories is inferior. $D_{\mathtt{MaybeKnown}}$,
    $D_{\mathtt{MaybeKnown}}$’s performance on $\mathtt{MaybeKnown}$), without compromising
    performance on $\mathtt{HighlyKnown}$). This suggests that $\mathtt{MaybeKnown}$
    to correctly handle such examples during inference. It also demonstrates that
    with the right fine-tuning examples, $M_{D}$ becomes more capable of utilizing
    its pre-existing knowledge.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 由于$\mathtt{未知}$示例。出乎意料的是，$D_{\mathtt{高度已知}}$测试示例，然而它在剩余类别上的表现较差。$D_{\mathtt{也许已知}}$，$D_{\mathtt{也许已知}}$在$\mathtt{也许已知}$上的表现），而不会影响$\mathtt{高度已知}$上的表现。这表明$\mathtt{也许已知}$在推断过程中正确处理这些示例的能力。它还表明，通过适当的微调示例，$M_{D}$变得更有能力利用其已有的知识。
- en: Limited Knowledge Enhances Overfitting.
  id: totrans-100
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 有限知识增强过拟合。
- en: 'In §[4.2](#S4.SS2 "4.2 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples: Harmful or Neutral? ‣ 4 How Harmful
    are 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples? ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?"),
    we demonstrated that $\mathtt{Unknown}$, though to a lesser degree. Specifically,
    at Convergence, $D_{\mathtt{WeaklyKnown}}$ experience significant performance
    drops compared to early_stop ($39.2{\mkern-3.0mu}\rightarrow{\mkern-3.0mu}35.4$).
    With training to Convergence, they show a modest improvement on $\mathtt{WeaklyKnown}$
    but substantially degrade on $\mathtt{HighlyKnown}$. This highlights that the
    decrease in performance is strongly attributed to an increased rate of hallucinations
    w.r.t. facts that were already known to $M$ after pre-training.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '在§[4.2](#S4.SS2 "4.2 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples: Harmful or Neutral? ‣ 4 How Harmful
    are 𝚄𝚗𝚔𝚎𝚜𝚜𝚊𝚛𝚎 Examples? ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")中，我们展示了$\mathtt{Unknown}$，尽管程度较轻。具体来说，在收敛时，$D_{\mathtt{WeaklyKnown}}$的表现相比于早期停止有显著下降（$39.2{\mkern-3.0mu}\rightarrow{\mkern-3.0mu}35.4$）。在训练到收敛时，它们在$\mathtt{WeaklyKnown}$上表现有所改善，但在$\mathtt{HighlyKnown}$上大幅下降。这突显了性能下降很大程度上归因于相对于预训练后$M$已经知道的事实的虚假记忆率增加。'
- en: Interestingly, $D_{\mathtt{Natural}}$ in early_stop, suggesting that the mere
    presence of $\mathtt{MaybeKnown}$ suffices for high performance on $\mathtt{MaybeKnown}$
    has additional examples from other categories. Yet, $D_{\mathtt{Natural}}$– indicating
    that it still suffers from overfitting, most-likely due to the presence of $\mathtt{WeaklyKnown}$
    examples. Taken together these results demonstrate that $D_{\mathtt{MaybeKnown}}$
    stands out both in terms of top performance and reduced risk to overfitting.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，早期停止中的$D_{\mathtt{Natural}}$，表明仅有$\mathtt{MaybeKnown}$的存在对于$\mathtt{MaybeKnown}$的高性能已经足够，且有来自其他类别的额外示例。然而，$D_{\mathtt{Natural}}$–
    表示它仍然受到过拟合的影响，最可能是由于$\mathtt{WeaklyKnown}$示例的存在。综合来看，这些结果表明$D_{\mathtt{MaybeKnown}}$在顶级性能和降低过拟合风险方面都表现突出。
- en: 6 SliCK Knowledge Categories Analysis
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 SliCK知识类别分析
- en: 'Assessing a model’s knowledge remains an open problem, particularly since evaluating
    the quality of such methods is challenging due to the lack of ground truth about
    what the model truly knows. In this work we proposed SliCK (§[3](#S3 "3 Quantifying
    Knowledge in LLMs ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")):
    a four-category classification of facts w.r.t. the model’s knowledge. We now further
    analyze and discuss our design choices, hoping that SliCK can serve as a useful
    taxonomy to guide future research on this subject.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 评估模型知识仍然是一个开放问题，特别是由于缺乏关于模型真正知道的内容的真实数据，评估这些方法的质量具有挑战性。在这项工作中，我们提出了SliCK（§[3](#S3
    "3 Quantifying Knowledge in LLMs ‣ Does Fine-Tuning LLMs on New Knowledge Encourage
    Hallucinations?")）：一个关于模型知识的四类事实分类方法。我们现在进一步分析和讨论了我们的设计选择，希望SliCK可以作为有用的分类法，以指导未来在这一主题上的研究。
- en: Fine-grained Known Categories
  id: totrans-105
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 细粒度已知类别
- en: 'We first reflect on whether our choice of splitting $\mathtt{Known}$ indeed
    captures facts with high degree of knowledge, as it consistently exceeds $95\%$
    and $\mathtt{WeaklyKnown}$ is worse that on $\mathtt{MaybeKnown}$. Additionally,
    the *exact* categories distinction we made was proven useful since it revealed
    important insights on the importance of the $\mathtt{MaybeKnown}$ fine-tuning
    examples, as discussed in detail in §[5](#S5 "5 Understanding Knowledge Types:
    Their Value and Impact ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?").'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '我们首先反思我们划分$\mathtt{Known}$的选择是否确实捕捉到了具有高知识度的事实，因为它始终超过$95\%$，而$\mathtt{WeaklyKnown}$的表现比$\mathtt{MaybeKnown}$更差。此外，我们所做的*准确*类别区分被证明是有用的，因为它揭示了关于$\mathtt{MaybeKnown}$细调示例的重要见解，如§[5](#S5
    "5 Understanding Knowledge Types: Their Value and Impact ‣ Does Fine-Tuning LLMs
    on New Knowledge Encourage Hallucinations?")中详细讨论的。'
- en: '![Refer to caption](img/207718f4a13afc5dc87f1cb456cc87f8.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/207718f4a13afc5dc87f1cb456cc87f8.png)'
- en: 'Figure 5: SliCK $\mathtt{Unknown}$ as $\mathtt{Unknown}$ of test examples classified
    as $\mathtt{Unknown}$. Our $\mathtt{Unknown}$ with less than $10$ random 4-shot
    exemplars (see §[3](#S3 "3 Quantifying Knowledge in LLMs ‣ Does Fine-Tuning LLMs
    on New Knowledge Encourage Hallucinations?") and §[C](#A3 "Appendix C 𝑷_𝙲𝚘𝚛𝚛𝚎𝚌𝚝
    Approximation ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")).'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：SliCK $\mathtt{Unknown}$作为被分类为$\mathtt{Unknown}$的测试示例的$\mathtt{Unknown}$。我们的$\mathtt{Unknown}$有少于$10$个随机的4-shot示例（见§[3](#S3
    "3 Quantifying Knowledge in LLMs ‣ Does Fine-Tuning LLMs on New Knowledge Encourage
    Hallucinations?")和§[C](#A3 "Appendix C 𝑷_𝙲𝚘𝚛𝚛𝚎𝚌𝚝 Approximation ‣ Does Fine-Tuning
    LLMs on New Knowledge Encourage Hallucinations?")）。
- en: Benchmarking Unknown Test Examples
  id: totrans-109
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基准测试未知测试示例
- en: A desired property for $(q,a)$ that appear in the test set, is that $M$ post
    fine-tuning (otherwise they are not truly $\mathtt{Unknown}$ is extremely low
    ($3.2\%$ examples are actually unknown to $M$.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 对于出现在测试集中的$(q,a)$，期望的属性是$M$微调后（否则它们并非真正的$\mathtt{Unknown}$），其极低（$3.2\%$）的实际未知示例数。
- en: 'As a case study for comparison, we analyze the P(True) approach by Kadavath
    et al. ([2022](#bib.bib10)): a continuous score that estimates the probability
    a model assigns to the correctness of a specific answer. P(True) was originally
    used for *self-evaluating* model-generated answers, while we use it to assess
    whether $M$ and compare this methodology to SliCK. Our results indicate that,
    at least in our setting, our approach categorizes $\mathtt{Unknown}$ using both
    methods, the accuracy on the P(True)-based $\mathtt{Unknown}$ is crucial, as using
    $N_{\text{ex}}<10$ examples.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 作为比较的案例研究，我们分析了Kadavath等人（[2022](#bib.bib10)）的P(True)方法：一种估计模型对特定答案正确性的概率的连续评分。P(True)最初用于*自我评估*模型生成的答案，而我们用它来评估$M$并将这种方法与SliCK进行比较。我们的结果表明，至少在我们的设置中，我们的方法使用两种方法对$\mathtt{Unknown}$进行分类，基于P(True)的$\mathtt{Unknown}$的准确性至关重要，因为使用$N_{\text{ex}}<10$示例。
- en: 7 Discussion
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 讨论
- en: Practical Implications.
  id: totrans-113
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 实际意义。
- en: 'This work highlights the risk in using supervised fine-tuning to update LLMs’
    knowledge, as we present empirical evidence that acquiring new knowledge through
    fine-tuning is correlated with hallucinations w.r.t pre-existing knowledge. Additionally,
    this work raises important questions for future exploration regarding fine-tuning
    practices. We saw that $\mathtt{Unknown}$ ones, thus their negative effect manifests
    as a form of *overfitting*, which emphasizes the importance of using *early-stopping*
    instead of a fixed number of fine-tuning steps. However, early-stopping may be
    less effective when fine-tuning on numerous tasks with distinct optimal stopping
    points. An alternative solution can be to align the fine-tuning data with the
    model’s knowledge by filtering-out $\mathtt{Unknown}$ fine-tuning examples can
    still be useful to teach LLMs to express uncertainty on $\mathtt{Unknown}$ fine-tuning
    examples with uncertainty expressions* (e.g., *“I don’t know”*) *reduce their
    negative effect?* Our preliminary experiment (described in §[K](#A11 "Appendix
    K Re-labeling 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Fine-tuning Example with an Uncertainty Expression: Initial
    Experiment ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?"))
    suggests that the answer is *yes*, which indicates that such approaches could
    be the most promising. Exploring this is an interesting direction for future work.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '本研究突出了使用监督性微调更新LLMs知识的风险，因为我们提供了实证证据表明，通过微调获得新知识与相对于现有知识的幻觉有关。此外，本研究提出了未来探索微调实践的重要问题。我们发现，$\mathtt{Unknown}$
    的情况，因此它们的负面影响表现为一种*过拟合*，这强调了使用*早停*而非固定数量的微调步骤的重要性。然而，当在多个任务上微调且这些任务有不同的最佳停止点时，早停可能效果较差。一个替代方案是通过筛选掉$\mathtt{Unknown}$
    微调示例来将微调数据与模型的知识对齐，这仍然可以有助于教导LLMs在$\mathtt{Unknown}$ 微调示例中用不确定性表达*（例如，*“我不知道”*）*来减少其负面影响*？我们的初步实验（见§[K](#A11
    "附录 K: 使用不确定性表达重新标记 $\mathtt{Unknown}$ 微调示例: 初步实验 ‣ 微调LLMs上的新知识是否会促进幻觉？")）表明答案是*是的*，这表明这种方法可能是最有前途的。探索这一点是未来工作的一个有趣方向。'
- en: Superficial Alignment Hypothesis.
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 表面对齐假设。
- en: Zhou et al. ([2023](#bib.bib34)) hypothesized that the knowledge and capabilities
    of LLMs are mostly learned during pre-training, while alignment is a simple process
    where the model learns the style or format for interacting with users. They substantiate
    this hypothesis by showing that fine-tuning on just $\mathtt{1k}$ examples and
    mostly learn to utilize their pre-existing knowledge. We also showed that fine-tuning
    on $\mathtt{HighlyKnown}$ examples led to sub-optimal utilization of pre-existing
    knowledge, despite our task format being simpler than LIMA’s and our dataset being
    six times larger. Taken together, our findings suggest that even though most of
    the LLM’s knowledge is indeed acquired through pre-training, the model learns
    more than just style or format through fine-tuning, as the selection of fine-tuning
    examples significantly influences the model’s capability to utilize its pre-existing
    knowledge post fine-tuning.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 周等人（[2023](#bib.bib34)）假设 LLM 的知识和能力主要是在预训练期间获得的，而对齐是一个简单的过程，在这个过程中模型学习与用户互动的风格或格式。他们通过展示仅在
    $\mathtt{1k}$ 示例上进行微调大多学习如何利用已有知识来证实这一假设。我们还展示了在 $\mathtt{HighlyKnown}$ 示例上进行微调导致了对已有知识的次优利用，尽管我们的任务格式比
    LIMA 的更简单，且我们的数据集大六倍。综合来看，我们的发现表明，尽管 LLM 的大部分知识确实是通过预训练获得的，但模型通过微调学到的不仅仅是风格或格式，因为微调示例的选择显著影响了模型在微调后利用已有知识的能力。
- en: 8 Related Work
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 相关工作
- en: New knowledge and hallucinations.
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 新知识与幻觉。
- en: Schulman ([2023](#bib.bib24)), Goldberg ([2023](#bib.bib7)) and Gudibande et al.
    ([2023](#bib.bib8)) mention the conjecture that fine-tuning on new factual knowledge
    may encourage hallucinations. Huang et al. ([2023](#bib.bib9)) categorized hallucination
    causes and formally defined this scenario as *capability misalignment*. They highlight
    that limited research addresses capability misalignment due to the challenge of
    defining the knowledge boundary of LLMs. Kang et al. ([2024](#bib.bib12)) showed
    that when a fine-tuned LLM encounters unknown queries at test time, its responses
    mimic the responses associated with the unknown examples in the fine-tuning data.
    Yin et al. ([2023](#bib.bib31)) showed that LLMs’ performance is not satisfactory
    when they face new knowledge in their input contexts and Lee et al. ([2023](#bib.bib14))
    analyzed the impact of unknown *in-context* learning examples. To the best of
    our knowledge, our work is the first to empirically assess the impact of exposure
    to new knowledge through fine-tuning on tendency of the fine-tuned model to hallucinate.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Schulman（[2023](#bib.bib24)）、Goldberg（[2023](#bib.bib7)）和 Gudibande 等人（[2023](#bib.bib8)）提到微调新事实知识可能会引发幻觉的猜想。Huang
    等人（[2023](#bib.bib9)）将幻觉原因进行了分类，并正式将这一情景定义为*能力不匹配*。他们指出，由于定义 LLM 知识边界的挑战，有限的研究解决了能力不匹配的问题。Kang
    等人（[2024](#bib.bib12)）展示了当微调后的 LLM 在测试时遇到未知查询时，其响应类似于微调数据中与未知示例相关的响应。Yin 等人（[2023](#bib.bib31)）展示了
    LLM 在输入上下文中面对新知识时表现不佳，而 Lee 等人（[2023](#bib.bib14)）分析了未知*上下文*学习示例的影响。据我们所知，我们的工作是首次实证评估通过微调暴露于新知识对微调模型产生幻觉的倾向的影响。
- en: Quantifying knowledge in LLMs.
  id: totrans-120
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 量化 LLM 中的知识。
- en: SliCK can be seen as a confidence elicitation method for the ground truth label
    ($M$ if it is confident that $a$). Existing work derive calibrated confidence
    from LLMs by examining agreement across multiple samples Kuhn et al. ([2023](#bib.bib13));
    Manakul et al. ([2023](#bib.bib17)); Tian et al. ([2023a](#bib.bib26)); Lyu et al.
    ([2024](#bib.bib16)), probing internal representations Azaria and Mitchell ([2023](#bib.bib3));
    Burns et al. ([2022](#bib.bib4)), eliciting verbalized probability Tian et al.
    ([2023b](#bib.bib27)) or direct prompting Kadavath et al. ([2022](#bib.bib10)).
    [Kadavath et al.](#bib.bib10) also trained a separate P(IK) model to predict if
    the LLM knows the answer to $q$ (§[3](#S3 "3 Quantifying Knowledge in LLMs ‣ Does
    Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")). A key difference
    is that we also define the SliCK categories, and provide evidence that we capture
    meaningful and useful categories.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: SliCK 可以看作是一种对真实标签的信心引导方法（$M$ 如果它对 $a$ 有信心）。现有工作通过检查多个样本之间的一致性来从 LLM 中推导出校准的信心
    Kuhn 等人 ([2023](#bib.bib13)); Manakul 等人 ([2023](#bib.bib17)); Tian 等人 ([2023a](#bib.bib26));
    Lyu 等人 ([2024](#bib.bib16))，探测内部表征 Azaria 和 Mitchell ([2023](#bib.bib3)); Burns
    等人 ([2022](#bib.bib4))，引出口头概率 Tian 等人 ([2023b](#bib.bib27)) 或直接提示 Kadavath 等人
    ([2022](#bib.bib10))。 [Kadavath 等人](#bib.bib10) 还训练了一个单独的 P(IK) 模型来预测 LLM 是否知道
    $q$ 的答案 (§[3](#S3 "3 Quantifying Knowledge in LLMs ‣ Does Fine-Tuning LLMs on
    New Knowledge Encourage Hallucinations?"))。一个关键的区别是我们还定义了 SliCK 类别，并提供了我们捕获有意义且有用类别的证据。
- en: 9 Conclusion
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9 结论
- en: 'We study the impact of integrating new factual knowledge through fine-tuning
    on the model’s tendency to hallucinate. We first propose SliCK, a categorization
    of facts w.r.t. LLM’s knowledge. We then design a controlled study where we isolate
    the impact of new knowledge and rigorously evaluate its effects. We provide multiple
    insights on the fine-tuning dynamics, with the following key findings: (1) Acquiring
    new knowledge via supervised fine-tuning is correlated with hallucinations w.r.t.
    pre-existing knowledge. (2) LLMs struggle to integrate new knowledge through fine-tuning
    and mostly learn to use their pre-existing knowledge.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究了通过微调整合新事实知识对模型幻觉倾向的影响。我们首先提出了 SliCK，一种关于 LLM 知识的事实分类。然后我们设计了一个受控研究，在该研究中我们隔离了新知识的影响并严格评估其效果。我们提供了关于微调动态的多个见解，主要发现如下：(1)
    通过监督微调获取新知识与相对于现有知识的幻觉相关。(2) LLM 在通过微调整合新知识时面临困难，主要学习使用其现有知识。
- en: 10 Limitations
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10 局限性
- en: 'Our experiments were conducted using a single LLM, and thus it is unclear whether
    results will vary with different LLMs. Having said that, our study is extremely
    compute-heavy and thus challenging to replicate on multiple LLMs: First, our fine-tuning
    is compute-heavy as its runs are very long as we wanted to analyze the behavior
    during different stages of fine-tuning (including the overfitting stages). Second,
    and most importantly, to facilitate our study we needed to annotate a large scale
    dataset w.r.t the SliCK categories. To derive reliable conclusions, it was crucial
    to accurately assess the model’s knowledge w.r.t. a single fine-tuning example.
    In our case we run 170 inference steps per example, i.e., more than $15M$ inference
    steps to categorize our full dataset.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实验使用了单一的 LLM，因此尚不清楚不同的 LLM 是否会得出不同的结果。尽管如此，我们的研究计算量非常大，因此在多个 LLM 上重复实验具有挑战性：首先，我们的微调计算量大，因为运行时间非常长，我们希望在不同的微调阶段（包括过拟合阶段）分析行为。其次，也是最重要的，为了方便我们的研究，我们需要对大规模数据集进行
    SliCK 类别的注释。为了得出可靠的结论，准确评估模型在单个微调示例下的知识至关重要。在我们的案例中，我们每个示例运行 170 次推理步骤，即对整个数据集进行超过
    $15M$ 次推理步骤。
- en: In addition, since we focus on closed-book QA, the practical implications from
    our study such as filtering-out $\mathtt{Unknown}$. We leave this for future work.
    Long-form generation tasks introduce evaluation challenges, leading to a wide
    adoption of LLM-based evaluations. Our choice to focus explicitly on closed book
    QA facilitates more accurate evaluation that enhances the reliability of our findings.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，由于我们专注于闭卷 QA，因此我们的研究的实际意义，如过滤 $\mathtt{Unknown}$。我们将此留待未来工作。长篇生成任务引入了评估挑战，导致
    LLM 基于评估的广泛采用。我们选择明确关注闭卷 QA，有助于更准确的评估，从而提高我们研究结果的可靠性。
- en: Lastly, we did not test the effect of adding additional fine-tuning examples
    from diverse tasks into the fine-tuning mixture. While this could more closely
    approximate a typical instruction fine-tuning scenario, such dataset extension
    may introduce new factual knowledge in an uncontrollable way, which will limit
    our findings.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们没有测试将来自不同任务的额外微调示例添加到微调混合中。虽然这可能更接近典型的指令微调场景，但这种数据集扩展可能会以不可控的方式引入新的事实知识，从而限制我们的发现。
- en: 11 Acknowledgments
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11 致谢
- en: We would like to thank Ori Ram, Uri Shaham, Alon Jacovi, Mor Ventura, Yochai
    Blau, Eyal Ben-David, Avi Caciularu, Avinatan Hassidim and the members of Roi
    Reichart’s NLP group for reviewing the paper draft and providing valuable feedback.
    Special thanks to Uri Shaham for assisting in setting up the fine-tuning pipeline
    during the early stages of our research.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要感谢 Ori Ram、Uri Shaham、Alon Jacovi、Mor Ventura、Yochai Blau、Eyal Ben-David、Avi
    Caciularu、Avinatan Hassidim 以及 Roi Reichart 的 NLP 组成员审阅论文草稿并提供宝贵反馈。特别感谢 Uri Shaham
    在我们研究早期阶段协助设置微调管道。
- en: References
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: AlKhamissi et al. (2022) Badr AlKhamissi, Millicent Li, Asli Celikyilmaz, Mona
    Diab, and Marjan Ghazvininejad. 2022. A review on language models as knowledge
    bases. *arXiv preprint arXiv:2204.06031*.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AlKhamissi 等（2022）Badr AlKhamissi、Millicent Li、Asli Celikyilmaz、Mona Diab 和
    Marjan Ghazvininejad。2022年。语言模型作为知识库的综述。 *arXiv 预印本 arXiv:2204.06031*。
- en: Anil et al. (2023) Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry
    Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng
    Chen, et al. 2023. Palm 2 technical report. *arXiv preprint arXiv:2305.10403*.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anil 等（2023）Rohan Anil、Andrew M Dai、Orhan Firat、Melvin Johnson、Dmitry Lepikhin、Alexandre
    Passos、Siamak Shakeri、Emanuel Taropa、Paige Bailey、Zhifeng Chen 等。2023年。Palm 2
    技术报告。 *arXiv 预印本 arXiv:2305.10403*。
- en: Azaria and Mitchell (2023) Amos Azaria and Tom Mitchell. 2023. The internal
    state of an llm knows when its lying. *arXiv preprint arXiv:2304.13734*.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azaria 和 Mitchell（2023）Amos Azaria 和 Tom Mitchell。2023年。LLM 的内部状态知道何时撒谎。 *arXiv
    预印本 arXiv:2304.13734*。
- en: Burns et al. (2022) Collin Burns, Haotian Ye, Dan Klein, and Jacob Steinhardt.
    2022. Discovering latent knowledge in language models without supervision. *arXiv
    preprint arXiv:2212.03827*.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Burns 等（2022）Collin Burns、Haotian Ye、Dan Klein 和 Jacob Steinhardt。2022年。在没有监督的情况下发现语言模型中的潜在知识。
    *arXiv 预印本 arXiv:2212.03827*。
- en: 'Cohen et al. (2023) Roi Cohen, Mor Geva, Jonathan Berant, and Amir Globerson.
    2023. [Crawling the internal knowledge-base of language models](https://doi.org/10.18653/v1/2023.findings-eacl.139).
    In *Findings of the Association for Computational Linguistics: EACL 2023*, pages
    1856–1869, Dubrovnik, Croatia. Association for Computational Linguistics.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cohen 等（2023）Roi Cohen、Mor Geva、Jonathan Berant 和 Amir Globerson。2023年。[爬取语言模型的内部知识库](https://doi.org/10.18653/v1/2023.findings-eacl.139)。在
    *计算语言学协会年会发现：EACL 2023*，第 1856–1869 页，克罗地亚杜布罗夫尼克。计算语言学协会。
- en: Gao (2021) Leo Gao. 2021. [Behavior cloning is miscalibrated](https://www.alignmentforum.org/posts/BgoKdAzogxmgkuuAt/behavior-cloning-is-miscalibrated).
    *AI Alignment Forum*.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao（2021）Leo Gao。2021年。[行为克隆是误校准的](https://www.alignmentforum.org/posts/BgoKdAzogxmgkuuAt/behavior-cloning-is-miscalibrated)。*AI
    Alignment Forum*。
- en: Goldberg (2023) Yoav Goldberg. 2023. [Reinforcement learning for language models](https://gist.github.com/yoavg/6bff0fecd65950898eba1bb321cfbd81).
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goldberg（2023）Yoav Goldberg。2023年。[语言模型的强化学习](https://gist.github.com/yoavg/6bff0fecd65950898eba1bb321cfbd81)。
- en: Gudibande et al. (2023) Arnav Gudibande, Eric Wallace, Charlie Snell, Xinyang
    Geng, Hao Liu, Pieter Abbeel, Sergey Levine, and Dawn Song. 2023. The false promise
    of imitating proprietary llms. *arXiv preprint arXiv:2305.15717*.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gudibande 等（2023）Arnav Gudibande、Eric Wallace、Charlie Snell、Xinyang Geng、Hao
    Liu、Pieter Abbeel、Sergey Levine 和 Dawn Song。2023年。模仿专有大语言模型的虚假承诺。 *arXiv 预印本 arXiv:2305.15717*。
- en: 'Huang et al. (2023) Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin
    Feng, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, et al.
    2023. A survey on hallucination in large language models: Principles, taxonomy,
    challenges, and open questions. *arXiv preprint arXiv:2311.05232*.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等（2023）Lei Huang、Weijiang Yu、Weitao Ma、Weihong Zhong、Zhangyin Feng、Haotian
    Wang、Qianglong Chen、Weihua Peng、Xiaocheng Feng、Bing Qin 等。2023年。大型语言模型中的幻觉调查：原则、分类、挑战和未解之谜。
    *arXiv 预印本 arXiv:2311.05232*。
- en: Kadavath et al. (2022) Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan,
    Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield-Dodds, Nova DasSarma,
    Eli Tran-Johnson, et al. 2022. Language models (mostly) know what they know. *arXiv
    preprint arXiv:2207.05221*.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kadavath 等（2022）Saurav Kadavath、Tom Conerly、Amanda Askell、Tom Henighan、Dawn
    Drain、Ethan Perez、Nicholas Schiefer、Zac Hatfield-Dodds、Nova DasSarma、Eli Tran-Johnson
    等。2022年。语言模型（大多数情况下）知道它们知道什么。 *arXiv 预印本 arXiv:2207.05221*。
- en: 'Kamalloo et al. (2023) Ehsan Kamalloo, Nouha Dziri, Charles L. A. Clarke, and
    Davood Rafiei. 2023. [Evaluating open-domain question answering in the era of
    large language models](https://doi.org/10.18653/V1/2023.ACL-LONG.307). In *Proceedings
    of the 61st Annual Meeting of the Association for Computational Linguistics (Volume
    1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023*, pages 5591–5606\.
    Association for Computational Linguistics.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kamalloo 等人（2023）Ehsan Kamalloo、Nouha Dziri、Charles L. A. Clarke 和 Davood Rafiei。2023年。[在大语言模型时代评估开放域问答](https://doi.org/10.18653/V1/2023.ACL-LONG.307)。在
    *《第61届计算语言学协会年会论文集（第1卷：长篇论文），ACL 2023，多伦多，加拿大，2023年7月9日至14日》* 中，第5591-5606页。计算语言学协会。
- en: Kang et al. (2024) Katie Kang, Eric Wallace, Claire Tomlin, Aviral Kumar, and
    Sergey Levine. 2024. Unfamiliar finetuning examples control how language models
    hallucinate. *arXiv preprint arXiv:2403.05612*.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kang 等人（2024）Katie Kang、Eric Wallace、Claire Tomlin、Aviral Kumar 和 Sergey Levine。2024年。不熟悉的微调示例控制语言模型的幻觉。*arXiv
    预印本 arXiv:2403.05612*。
- en: 'Kuhn et al. (2023) Lorenz Kuhn, Yarin Gal, and Sebastian Farquhar. 2023. Semantic
    uncertainty: Linguistic invariances for uncertainty estimation in natural language
    generation. *arXiv preprint arXiv:2302.09664*.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kuhn 等人（2023）Lorenz Kuhn、Yarin Gal 和 Sebastian Farquhar。2023年。语义不确定性：自然语言生成中的语言不变性用于不确定性估计。*arXiv
    预印本 arXiv:2302.09664*。
- en: Lee et al. (2023) Yoonsang Lee, Pranav Atreya, Xi Ye, and Eunsol Choi. 2023.
    Crafting in-context examples according to lms’ parametric knowledge. *arXiv preprint
    arXiv:2311.09579*.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee 等人（2023）Yoonsang Lee、Pranav Atreya、Xi Ye 和 Eunsol Choi。2023年。根据 LMs 的参数知识制作上下文示例。*arXiv
    预印本 arXiv:2311.09579*。
- en: 'Lin et al. (2023) Bill Yuchen Lin, Abhilasha Ravichander, Ximing Lu, Nouha
    Dziri, Melanie Sclar, Khyathi Chandu, Chandra Bhagavatula, and Yejin Choi. 2023.
    [The unlocking spell on base llms: Rethinking alignment via in-context learning](http://arxiv.org/abs/2312.01552).
    *ArXiv preprint*.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin 等人（2023）Bill Yuchen Lin、Abhilasha Ravichander、Ximing Lu、Nouha Dziri、Melanie
    Sclar、Khyathi Chandu、Chandra Bhagavatula 和 Yejin Choi。2023年。[基础 LLMs 的解锁咒语：通过上下文学习重新思考对齐](http://arxiv.org/abs/2312.01552)。*ArXiv
    预印本*。
- en: Lyu et al. (2024) Qing Lyu, Kumar Shridhar, Chaitanya Malaviya, Li Zhang, Yanai
    Elazar, Niket Tandon, Marianna Apidianaki, Mrinmaya Sachan, and Chris Callison-Burch.
    2024. Calibrating large language models with sample consistency. *arXiv preprint
    arXiv:2402.13904*.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lyu 等人（2024）Qing Lyu、Kumar Shridhar、Chaitanya Malaviya、Li Zhang、Yanai Elazar、Niket
    Tandon、Marianna Apidianaki、Mrinmaya Sachan 和 Chris Callison-Burch。2024年。用样本一致性对大型语言模型进行标定。*arXiv
    预印本 arXiv:2402.13904*。
- en: 'Manakul et al. (2023) Potsawee Manakul, Adian Liusie, and Mark JF Gales. 2023.
    Selfcheckgpt: Zero-resource black-box hallucination detection for generative large
    language models. *arXiv preprint arXiv:2303.08896*.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Manakul 等人（2023）Potsawee Manakul、Adian Liusie 和 Mark JF Gales。2023年。Selfcheckgpt：零资源黑箱幻觉检测用于生成大型语言模型。*arXiv
    预印本 arXiv:2303.08896*。
- en: 'Mishra et al. (2022) Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh
    Hajishirzi. 2022. [Cross-task generalization via natural language crowdsourcing
    instructions](https://doi.org/10.18653/v1/2022.acl-long.244). In *Proceedings
    of the 60th Annual Meeting of the Association for Computational Linguistics (Volume
    1: Long Papers)*, pages 3470–3487, Dublin, Ireland. Association for Computational
    Linguistics.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mishra 等人（2022）Swaroop Mishra、Daniel Khashabi、Chitta Baral 和 Hannaneh Hajishirzi。2022年。[通过自然语言众包指令进行跨任务泛化](https://doi.org/10.18653/v1/2022.acl-long.244)。在
    *《第60届计算语言学协会年会论文集（第1卷：长篇论文）》* 中，第3470-3487页，爱尔兰都柏林。计算语言学协会。
- en: 'Ouyang et al. (2022) Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L.
    Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex
    Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda
    Askell, Peter Welinder, Paul F. Christiano, Jan Leike, and Ryan Lowe. 2022. [Training
    language models to follow instructions with human feedback](http://papers.nips.cc/paper_files/paper/2022/hash/b1efde53be364a73914f58805a001731-Abstract-Conference.html).
    In *Advances in Neural Information Processing Systems 35: Annual Conference on
    Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA,
    November 28 - December 9, 2022*.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 欧阳等人（2022）Long Ouyang、Jeffrey Wu、Xu Jiang、Diogo Almeida、Carroll L. Wainwright、Pamela
    Mishkin、Chong Zhang、Sandhini Agarwal、Katarina Slama、Alex Ray、John Schulman、Jacob
    Hilton、Fraser Kelton、Luke Miller、Maddie Simens、Amanda Askell、Peter Welinder、Paul
    F. Christiano、Jan Leike 和 Ryan Lowe。2022年。[通过人类反馈训练语言模型以跟随指令](http://papers.nips.cc/paper_files/paper/2022/hash/b1efde53be364a73914f58805a001731-Abstract-Conference.html)。在
    *《神经信息处理系统进展第35卷：2022年神经信息处理系统年会，NeurIPS 2022，新奥尔良，美国，2022年11月28日至12月9日》* 中。
- en: Petroni et al. (2019) Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick
    Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander Miller. 2019. [Language models
    as knowledge bases?](https://doi.org/10.18653/v1/D19-1250) In *Proceedings of
    the 2019 Conference on Empirical Methods in Natural Language Processing and the
    9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)*,
    pages 2463–2473, Hong Kong, China. Association for Computational Linguistics.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Petroni et al. (2019) 法比奥·佩特罗尼、蒂姆·罗克塔谢尔、塞巴斯蒂安·里德尔、帕特里克·刘易斯、安东·巴赫廷、余翔·吴和亚历山大·米勒。2019。
    [语言模型作为知识库？](https://doi.org/10.18653/v1/D19-1250) 见于 *2019年自然语言处理实证方法会议暨第九届国际联合自然语言处理会议（EMNLP-IJCNLP）*，第2463–2473页，中国香港。计算语言学协会。
- en: 'Rafailov et al. (2024) Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher D
    Manning, Stefano Ermon, and Chelsea Finn. 2024. Direct preference optimization:
    Your language model is secretly a reward model. *Advances in Neural Information
    Processing Systems*, 36.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rafailov et al. (2024) 拉斐尔·拉斐洛夫、阿尔基特·夏尔马、埃里克·米切尔、克里斯托弗·D·曼宁、斯特法诺·厄尔蒙和切尔西·芬恩。2024。直接偏好优化：你的语言模型其实是奖励模型。*神经信息处理系统进展*，36。
- en: 'Rajpurkar et al. (2016) Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and
    Percy Liang. 2016. [SQuAD: 100,000+ questions for machine comprehension of text](https://doi.org/10.18653/v1/D16-1264).
    In *Proceedings of the 2016 Conference on Empirical Methods in Natural Language
    Processing*, pages 2383–2392, Austin, Texas. Association for Computational Linguistics.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Rajpurkar et al. (2016) 普拉纳夫·拉朱尔卡尔、简·张、康斯坦丁·洛皮耶夫和珀西·梁。2016。 [SQuAD: 100,000+
    机器文本理解问题](https://doi.org/10.18653/v1/D16-1264)。见于 *2016年自然语言处理实证方法会议*，第2383–2392页，美国德克萨斯州奥斯汀。计算语言学协会。'
- en: 'Rubin et al. (2022) Ohad Rubin, Jonathan Herzig, and Jonathan Berant. 2022.
    [Learning to retrieve prompts for in-context learning](https://doi.org/10.18653/v1/2022.naacl-main.191).
    In *Proceedings of the 2022 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies*, pages 2655–2671,
    Seattle, United States. Association for Computational Linguistics.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rubin et al. (2022) 奥哈德·鲁宾、乔纳森·赫尔齐和乔纳森·贝兰特。2022。 [学习检索上下文学习的提示](https://doi.org/10.18653/v1/2022.naacl-main.191)。见于
    *2022年北美计算语言学协会：人类语言技术会议*，第2655–2671页，美国西雅图。计算语言学协会。
- en: 'Schulman (2023) John Schulman. 2023. [Reinforcement learning from human feedback:
    Progress and challenges](https://www.youtube.com/watch?v=hhiLw5Q_UFg&ab_channel=BerkeleyEECS).'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schulman (2023) 约翰·舒尔曼。2023。 [来自人类反馈的强化学习：进展与挑战](https://www.youtube.com/watch?v=hhiLw5Q_UFg&ab_channel=BerkeleyEECS)。
- en: Sciavolino et al. (2021) Christopher Sciavolino, Zexuan Zhong, Jinhyuk Lee,
    and Danqi Chen. 2021. [Simple entity-centric questions challenge dense retrievers](https://doi.org/10.18653/V1/2021.EMNLP-MAIN.496).
    In *Proceedings of the 2021 Conference on Empirical Methods in Natural Language
    Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November,
    2021*, pages 6138–6148\. Association for Computational Linguistics.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sciavolino et al. (2021) 克里斯托弗·西亚沃利诺、泽轩·钟、晋赫·李和丹琪·陈。2021。 [简单的实体中心问题挑战密集检索器](https://doi.org/10.18653/V1/2021.EMNLP-MAIN.496)。见于
    *2021年自然语言处理实证方法会议，EMNLP 2021，虚拟活动/多米尼加共和国蓬塔卡纳，2021年11月7-11日*，第6138–6148页。计算语言学协会。
- en: Tian et al. (2023a) Katherine Tian, Eric Mitchell, Huaxiu Yao, Christopher D
    Manning, and Chelsea Finn. 2023a. Fine-tuning language models for factuality.
    *arXiv preprint arXiv:2311.08401*.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tian et al. (2023a) 凯瑟琳·田、埃里克·米切尔、华秀·姚、克里斯托弗·D·曼宁和切尔西·芬恩。2023a。为事实性微调语言模型。*arXiv
    预印本 arXiv:2311.08401*。
- en: 'Tian et al. (2023b) Katherine Tian, Eric Mitchell, Allan Zhou, Archit Sharma,
    Rafael Rafailov, Huaxiu Yao, Chelsea Finn, and Christopher D Manning. 2023b. Just
    ask for calibration: Strategies for eliciting calibrated confidence scores from
    language models fine-tuned with human feedback. *arXiv preprint arXiv:2305.14975*.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tian et al. (2023b) 凯瑟琳·田、埃里克·米切尔、艾伦·周、阿尔基特·夏尔马、拉斐尔·拉斐洛夫、华秀·姚、切尔西·芬恩和克里斯托弗·D·曼宁。2023b。只需请求校准：从语言模型中引出校准信心评分的策略。*arXiv
    预印本 arXiv:2305.14975*。
- en: 'Vrandečić and Krötzsch (2014) Denny Vrandečić and Markus Krötzsch. 2014. [Wikidata:
    a free collaborative knowledgebase](https://doi.org/10.1145/2629489). *Commun.
    ACM*, 57(10):78–85.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Vrandečić 和 Krötzsch (2014) 丹尼·弗兰德齐奇和马库斯·克罗茨施。2014。 [Wikidata: 一个免费的协作知识库](https://doi.org/10.1145/2629489)。*Commun.
    ACM*，57(10):78–85。'
- en: 'Wang et al. (2023) Cunxiang Wang, Sirui Cheng, Qipeng Guo, Yuanhao Yue, Bowen
    Ding, Zhikun Xu, Yidong Wang, Xiangkun Hu, Zheng Zhang, and Yue Zhang. 2023. [Evaluating
    open-qa evaluation](http://papers.nips.cc/paper_files/paper/2023/hash/f323d594aa5d2c68154433a131c07959-Abstract-Datasets_and_Benchmarks.html).
    In *Advances in Neural Information Processing Systems 36: Annual Conference on
    Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA,
    December 10 - 16, 2023*.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2023）Cunxiang Wang、Sirui Cheng、Qipeng Guo、Yuanhao Yue、Bowen Ding、Zhikun
    Xu、Yidong Wang、Xiangkun Hu、Zheng Zhang 和 Yue Zhang。2023年。[评估开放问答评估](http://papers.nips.cc/paper_files/paper/2023/hash/f323d594aa5d2c68154433a131c07959-Abstract-Datasets_and_Benchmarks.html)。在*神经信息处理系统进展
    36：2023年度神经信息处理系统大会，NeurIPS 2023，新奥尔良，LA，美国，2023年12月10-16日*。
- en: Wei et al. (2022) Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei
    Yu, Brian Lester, Nan Du, Andrew M. Dai, and Quoc V. Le. 2022. [Finetuned language
    models are zero-shot learners](https://openreview.net/forum?id=gEZrGCozdqR). In
    *The Tenth International Conference on Learning Representations, ICLR 2022, Virtual
    Event, April 25-29, 2022*. OpenReview.net.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等人（2022）Jason Wei、Maarten Bosma、Vincent Y. Zhao、Kelvin Guu、Adams Wei Yu、Brian
    Lester、Nan Du、Andrew M. Dai 和 Quoc V. Le。2022年。[微调语言模型是零样本学习者](https://openreview.net/forum?id=gEZrGCozdqR)。在*第十届国际学习表征大会，ICLR
    2022，虚拟活动，2022年4月25-29日*。OpenReview.net。
- en: 'Yin et al. (2023) Xunjian Yin, Baizhou Huang, and Xiaojun Wan. 2023. [ALCUNA:
    Large language models meet new knowledge](https://doi.org/10.18653/v1/2023.emnlp-main.87).
    In *Proceedings of the 2023 Conference on Empirical Methods in Natural Language
    Processing*, pages 1397–1414, Singapore. Association for Computational Linguistics.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yin 等人（2023）Xunjian Yin、Baizhou Huang 和 Xiaojun Wan。2023年。[ALCUNA：大型语言模型遇见新知识](https://doi.org/10.18653/v1/2023.emnlp-main.87)。在*2023年自然语言处理实证方法会议论文集*，第1397–1414页，新加坡。计算语言学协会。
- en: 'Yona et al. (2024) Gal Yona, Roee Aharoni, and Mor Geva. 2024. Narrowing the
    knowledge evaluation gap: Open-domain question answering with multi-granularity
    answers. *arXiv preprint arXiv:2401.04695*.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yona 等人（2024）Gal Yona、Roee Aharoni 和 Mor Geva。2024年。缩小知识评估差距：具有多粒度答案的开放领域问答。*arXiv
    预印本 arXiv:2401.04695*。
- en: 'Zhang et al. (2023) Hanning Zhang, Shizhe Diao, Yong Lin, Yi R Fung, Qing Lian,
    Xingyao Wang, Yangyi Chen, Heng Ji, and Tong Zhang. 2023. R-tuning: Teaching large
    language models to refuse unknown questions. *arXiv preprint arXiv:2311.09677*.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人（2023）Hanning Zhang、Shizhe Diao、Yong Lin、Yi R Fung、Qing Lian、Xingyao
    Wang、Yangyi Chen、Heng Ji 和 Tong Zhang。2023年。R-tuning：教大型语言模型拒绝未知问题。*arXiv 预印本
    arXiv:2311.09677*。
- en: 'Zhou et al. (2023) Chunting Zhou, Pengfei Liu, Puxin Xu, Srinivasan Iyer, Jiao
    Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, Susan Zhang, Gargi Ghosh,
    Mike Lewis, Luke Zettlemoyer, and Omer Levy. 2023. [LIMA: less is more for alignment](http://papers.nips.cc/paper_files/paper/2023/hash/ac662d74829e4407ce1d126477f4a03a-Abstract-Conference.html).
    In *Advances in Neural Information Processing Systems 36: Annual Conference on
    Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA,
    December 10 - 16, 2023*.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou 等人（2023）Chunting Zhou、Pengfei Liu、Puxin Xu、Srinivasan Iyer、Jiao Sun、Yuning
    Mao、Xuezhe Ma、Avia Efrat、Ping Yu、Lili Yu、Susan Zhang、Gargi Ghosh、Mike Lewis、Luke
    Zettlemoyer 和 Omer Levy。2023年。[LIMA：对齐的“少即是多”](http://papers.nips.cc/paper_files/paper/2023/hash/ac662d74829e4407ce1d126477f4a03a-Abstract-Conference.html)。在*神经信息处理系统进展
    36：2023年度神经信息处理系统大会，NeurIPS 2023，新奥尔良，LA，美国，2023年12月10-16日*。
- en: Appendix A Data Preprocessing
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 数据预处理
- en: '| relation | question template | $\mathtt{HighlyKnown}$ | $\mathtt{WeaklyKnown}$
    | Total | Min |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| relation | question template | $\mathtt{HighlyKnown}$ | $\mathtt{WeaklyKnown}$
    | Total | Min |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| P131 | Where is [E] located? | 553 | 2529 | 1493 | 3071 | 7646 | 553 |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| P131 | [E] 位于哪里？ | 553 | 2529 | 1493 | 3071 | 7646 | 553 |'
- en: '| P136 | What type of music does [E] play? | 236 | 3410 | 1892 | 1978 | 7516
    | 236 |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| P136 | [E] 演奏什么类型的音乐？ | 236 | 3410 | 1892 | 1978 | 7516 | 236 |'
- en: '| P17 | Which country is [E] located in? | 4387 | 2628 | 511 | 364 | 7890 |
    364 |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| P17 | [E] 位于哪个国家？ | 4387 | 2628 | 511 | 364 | 7890 | 364 |'
- en: '| P19 | Where was [E] born? | 369 | 1884 | 1498 | 4170 | 7921 | 369 |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| P19 | [E] 出生在哪里？ | 369 | 1884 | 1498 | 4170 | 7921 | 369 |'
- en: '| P26 | Who is [E] married to? | 1609 | 1503 | 1087 | 3257 | 7456 | 1087 |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| P26 | [E] 结婚对象是谁？ | 1609 | 1503 | 1087 | 3257 | 7456 | 1087 |'
- en: '| P264 | What music label is [E] represented by? | 206 | 1444 | 1854 | 3820
    | 7324 | 206 |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| P264 | [E] 由哪个音乐标签代表？ | 206 | 1444 | 1854 | 3820 | 7324 | 206 |'
- en: '| P36 | What is the capital of [E]? | 4160 | 1634 | 449 | 572 | 6815 | 449
    |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| P36 | [E] 的首都是什么？ | 4160 | 1634 | 449 | 572 | 6815 | 449 |'
- en: '| P40 | Who is [E]’s child? | 692 | 1467 | 1271 | 2680 | 6110 | 692 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| P40 | [E] 的孩子是谁？ | 692 | 1467 | 1271 | 2680 | 6110 | 692 |'
- en: '| P495 | Which country was [E] created in? | 5459 | 1101 | 408 | 706 | 7674
    | 408 |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| P495 | [E] 是在哪个国家创立的？ | 5459 | 1101 | 408 | 706 | 7674 | 408 |'
- en: '| P69 | Where was [E] educated? | 233 | 1126 | 1712 | 3650 | 6721 | 233 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| P69 | [E] 的教育背景是什么？ | 233 | 1126 | 1712 | 3650 | 6721 | 233 |'
- en: '| P740 | Where was [E] founded? | 1323 | 1618 | 1428 | 2902 | 7271 | 1323 |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| P740 | [E] 的创立地点在哪里？ | 1323 | 1618 | 1428 | 2902 | 7271 | 1323 |'
- en: '| P800 | What is [E] famous for? | 301 | 330 | 222 | 503 | 1356 | 222 |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| P800 | [E] 因何闻名？ | 301 | 330 | 222 | 503 | 1356 | 222 |'
- en: '| TOTAL | - | 19528 | 20674 | 13825 | 27673 | 81700 | 6142 |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | - | 19528 | 20674 | 13825 | 27673 | 81700 | 6142 |'
- en: 'Table 3: Statistics of the EntityQuestions train split annotated with SliCK
    categories. We annotate the entire train split but always fine-tune on exactly
    6142 examples (see the Min column). Refer to §[E](#A5 "Appendix E Fine-tuning
    Details ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?") for
    more details.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '表 3: 标注了 SliCK 类别的 EntityQuestions 训练数据集统计数据。我们对整个训练集进行了标注，但总是对确切的 6142 个样本进行微调（参见
    Min 列）。更多细节请参见 §[E](#A5 "附录 E 微调细节 ‣ 微调 LLM 在新知识上的影响是否会导致虚假信息？")。'
- en: '| relation | question template | $\mathtt{HighlyKnown}$ | $\mathtt{WeaklyKnown}$
    | Total |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 关系 | 问题模板 | $\mathtt{HighlyKnown}$ | $\mathtt{WeaklyKnown}$ | 总计 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| P131 | Where is [E] located? | 57 | 362 | 158 | 388 | 965 |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| P131 | [E] 位于哪里？ | 57 | 362 | 158 | 388 | 965 |'
- en: '| P136 | What type of music does [E] play? | 6 | 432 | 248 | 281 | 967 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| P136 | [E] 演奏哪种类型的音乐？ | 6 | 432 | 248 | 281 | 967 |'
- en: '| P17 | Which country is [E] located in? | 448 | 432 | 65 | 51 | 996 |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| P17 | [E] 位于哪个国家？ | 448 | 432 | 65 | 51 | 996 |'
- en: '| P19 | Where was [E] born? | 107 | 148 | 243 | 501 | 999 |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| P19 | [E] 的出生地在哪里？ | 107 | 148 | 243 | 501 | 999 |'
- en: '| P26 | Who is [E] married to? | 177 | 238 | 158 | 378 | 951 |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| P26 | [E] 的配偶是谁？ | 177 | 238 | 158 | 378 | 951 |'
- en: '| P264 | What music label is [E] represented by? | 47 | 157 | 268 | 486 | 958
    |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| P264 | [E] 由哪个音乐标签代表？ | 47 | 157 | 268 | 486 | 958 |'
- en: '| P36 | What is the capital of [E]? | 580 | 152 | 62 | 86 | 880 |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| P36 | [E] 的首都是什么？ | 580 | 152 | 62 | 86 | 880 |'
- en: '| P40 | Who is [E]’s child? | 99 | 191 | 167 | 344 | 801 |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| P40 | [E] 的孩子是谁？ | 99 | 191 | 167 | 344 | 801 |'
- en: '| P495 | Which country was [E] created in? | 699 | 147 | 51 | 96 | 993 |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| P495 | [E] 是在哪个国家创立的？ | 699 | 147 | 51 | 96 | 993 |'
- en: '| P69 | Where was [E] educated? | 27 | 145 | 227 | 441 | 840 |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| P69 | [E] 的教育背景是什么？ | 27 | 145 | 227 | 441 | 840 |'
- en: '| P740 | Where was [E] founded? | 182 | 245 | 181 | 334 | 942 |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| P740 | [E] 的创立地点在哪里？ | 182 | 245 | 181 | 334 | 942 |'
- en: '| P800 | What is [E] famous for? | 35 | 50 | 28 | 76 | 189 |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| P800 | [E] 因何闻名？ | 35 | 50 | 28 | 76 | 189 |'
- en: '| TOTAL | - | 2464 | 2699 | 1856 | 3462 | 10481 |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | - | 2464 | 2699 | 1856 | 3462 | 10481 |'
- en: 'Table 4: In-distribution test set statistics.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '表 4: 分布内测试集统计数据。'
- en: '| relation | question template | $\mathtt{HighlyKnown}$ | $\mathtt{WeaklyKnown}$
    | Total |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| 关系 | 问题模板 | $\mathtt{HighlyKnown}$ | $\mathtt{WeaklyKnown}$ | 总计 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| P127 | Who owns [E]? | 125 | 383 | 168 | 314 | 990 |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| P127 | 谁拥有 [E]？ | 125 | 383 | 168 | 314 | 990 |'
- en: '| P50 | Who is the author of [E]? | 287 | 193 | 115 | 372 | 967 |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| P50 | [E] 的作者是谁？ | 287 | 193 | 115 | 372 | 967 |'
- en: '| P407 | Which language was [E] written in? | 366 | 153 | 59 | 45 | 623 |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| P407 | [E] 是用什么语言写的？ | 366 | 153 | 59 | 45 | 623 |'
- en: '| P176 | Which company is [E] produced by? | 289 | 277 | 181 | 225 | 972 |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| P176 | [E] 是哪个公司生产的？ | 289 | 277 | 181 | 225 | 972 |'
- en: '| P170 | Who was [E] created by? | 142 | 284 | 120 | 304 | 850 |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| P170 | [E] 由谁创作？ | 142 | 284 | 120 | 304 | 850 |'
- en: '| P175 | Who performed [E]? | 94 | 120 | 103 | 663 | 980 |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| P175 | 谁表演了 [E]？ | 94 | 120 | 103 | 663 | 980 |'
- en: '| P112 | Who founded [E]? | 134 | 116 | 76 | 140 | 466 |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| P112 | 谁创立了 [E]？ | 134 | 116 | 76 | 140 | 466 |'
- en: '| TOTAL | - | 1437 | 1526 | 822 | 2063 | 5848 |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | - | 1437 | 1526 | 822 | 2063 | 5848 |'
- en: 'Table 5: Out-of-distribution test set statistics.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '表 5: 分布外测试集统计数据。'
- en: This section expands §[2](#S2 "2 Study Setup ‣ Does Fine-Tuning LLMs on New
    Knowledge Encourage Hallucinations?") with additional details about our data preprocessing
    steps. The EntityQuestions dataset Sciavolino et al. ([2021](#bib.bib25)) consists
    of train, development and test splits and spans 24 relations. Our train, development
    and test sets are curated based on the original splits from EntityQuestions. However,
    we use only 12 relations, since we wanted to reserve some relations for out-of-distribution
    test set. To avoid cherry-picking, the 12 relations used in our train, development
    and test sets are randomly sampled. The resulting relations are presented in Tables
    [3](#A1.T3 "Table 3 ‣ Appendix A Data Preprocessing ‣ Does Fine-Tuning LLMs on
    New Knowledge Encourage Hallucinations?") and [4](#A1.T4 "Table 4 ‣ Appendix A
    Data Preprocessing ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?").
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 本节扩展了 §[2](#S2 "2 研究设置 ‣ 对新知识进行微调的 LLM 是否会引发幻觉？")，提供了有关我们的数据预处理步骤的更多细节。EntityQuestions
    数据集 Sciavolino 等人 ([2021](#bib.bib25)) 包含训练、开发和测试分割，并涵盖了 24 个关系。我们的训练、开发和测试集是基于
    EntityQuestions 的原始分割进行整理的。然而，我们只使用了 12 个关系，因为我们想保留一些关系用于分布外测试集。为了避免挑选，训练、开发和测试集中使用的
    12 个关系是随机抽样的。结果关系见表 [3](#A1.T3 "表 3 ‣ 附录 A 数据预处理 ‣ 对新知识进行微调的 LLM 是否会引发幻觉？") 和
    [4](#A1.T4 "表 4 ‣ 附录 A 数据预处理 ‣ 对新知识进行微调的 LLM 是否会引发幻觉？")。
- en: 'We reserved the remaining 12 relations for out-of-distribution test set. However,
    we found that in those 12 reserved relations, 5 were too similar to some of the
    relations that we train on (Table [3](#A1.T3 "Table 3 ‣ Appendix A Data Preprocessing
    ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")), thus we
    suspected that this could lead to a test set that is not truly out-of-distribution.
    To address that, we filtered out those relations and were left with 7 relations
    for our-of-distribution. Specifically we filtered-out the following relations:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们保留了其余的 12 个关系用于分布外测试集。然而，我们发现这 12 个保留的关系中，有 5 个与我们训练中的一些关系过于相似（见表 [3](#A1.T3
    "表 3 ‣ 附录 A 数据预处理 ‣ 对新知识进行微调的 LLM 是否会引发幻觉？")），因此我们怀疑这可能导致测试集不完全是分布外的。为了解决这个问题，我们筛除了这些关系，最终保留了
    7 个关系用于分布外测试集。具体来说，我们筛除了以下关系：
- en: •
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: P276 was filtered out since it directly overlaps with P131 since for both relations
    the question in EntityQuestions is of the form “Where is [E] located?”. P276 stands
    for “location” ([https://www.wikidata.org/wiki/Property:P276](https://www.wikidata.org/wiki/Property:P276))
    and P131 stands for “located in the administrative territorial entity” ([https://www.wikidata.org/wiki/Property:P131](https://www.wikidata.org/wiki/Property:P131)).
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: P276 被筛除，因为它与 P131 直接重叠，两者的问句都是“[E] 位于何处？” P276 代表“位置” ([https://www.wikidata.org/wiki/Property:P276](https://www.wikidata.org/wiki/Property:P276))，而
    P131 代表“位于行政区划实体中” ([https://www.wikidata.org/wiki/Property:P131](https://www.wikidata.org/wiki/Property:P131))。
- en: •
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: P20, for which the question template is *“Where did [E] die?”*, was filtered
    out since it may require knowledge that relates to P19, for which the question
    template is *“Where was [E] born?”*. P20 stands for “place of death” ([https://www.wikidata.org/wiki/Property:P20](https://www.wikidata.org/wiki/Property:P20))
    and P19 stands for “place of birth” ([https://www.wikidata.org/wiki/Property:P19](https://www.wikidata.org/wiki/Property:P19)).
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: P20，其问题模板为*“[E] 死于何处？”*，被筛除，因为它可能需要与 P19 相关的知识，而 P19 的问题模板是*“[E] 出生于何处？”*。P20
    代表“死亡地点” ([https://www.wikidata.org/wiki/Property:P20](https://www.wikidata.org/wiki/Property:P20))，而
    P19 代表“出生地点” ([https://www.wikidata.org/wiki/Property:P19](https://www.wikidata.org/wiki/Property:P19))。
- en: •
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: P106, for which the question template is *“What kind of work does [E] do?”*,
    was filtered out since it may require knowledge that relates to P800, for which
    the question template is *“What is [E] famous for?”*. P106 stands for “occupation”
    ([https://www.wikidata.org/wiki/Property:P106](https://www.wikidata.org/wiki/Property:P106))
    and P800 stands for “notable work” ([https://www.wikidata.org/wiki/Property:P800](https://www.wikidata.org/wiki/Property:P800)).
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: P106，其问题模板为*“[E] 从事什么工作？”*，被筛除，因为它可能需要与 P800 相关的知识，而 P800 的问题模板是*“[E] 因什么而著名？”*。P106
    代表“职业” ([https://www.wikidata.org/wiki/Property:P106](https://www.wikidata.org/wiki/Property:P106))，而
    P800 代表“著名作品” ([https://www.wikidata.org/wiki/Property:P800](https://www.wikidata.org/wiki/Property:P800))。
- en: •
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: P413, for which the question template is *“What position does [E] play?”*, was
    filtered out since it may require knowledge that relates to P800, for which the
    question template is *“What is [E] famous for?”*. P413 stands for “position played
    on team / speciality” ([https://www.wikidata.org/wiki/Property:P413](https://www.wikidata.org/wiki/Property:P413))
    and P800 stands for “notable work” ([https://www.wikidata.org/wiki/Property:P800](https://www.wikidata.org/wiki/Property:P800)).
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: P413，问题模板为*“[E]的职位是什么？”*，被筛除，因为它可能需要与P800相关的知识，P800的问答模板是*“[E]因为什么而闻名？”*。P413
    代表“球队上的职位/专长” ([https://www.wikidata.org/wiki/Property:P413](https://www.wikidata.org/wiki/Property:P413))，而
    P800 代表“著名作品” ([https://www.wikidata.org/wiki/Property:P800](https://www.wikidata.org/wiki/Property:P800))。
- en: •
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: P159, for which the question template is *“Where is the headquarters of [E]?”*,
    was filtered out since it may require knowledge that relates to P36, for which
    the question template is *“What is the capital of [E]?”*. P159 stands for “headquarters
    location” ([https://www.wikidata.org/wiki/Property:P159](https://www.wikidata.org/wiki/Property:P159))
    and P36 stands for “capital” ([https://www.wikidata.org/wiki/Property:P36](https://www.wikidata.org/wiki/Property:P36)).
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: P159，问题模板为*“[E]的总部在哪里？”*，被筛除，因为它可能需要与P36相关的知识，P36的问答模板是*“[E]的首都是什么？”*。P159代表“总部位置”
    ([https://www.wikidata.org/wiki/Property:P159](https://www.wikidata.org/wiki/Property:P159))，而
    P36 代表“首都” ([https://www.wikidata.org/wiki/Property:P36](https://www.wikidata.org/wiki/Property:P36))。
- en: The 7 relations used for out-of-distribution test set are presented in [Table 5](#A1.T5
    "In Appendix A Data Preprocessing ‣ Does Fine-Tuning LLMs on New Knowledge Encourage
    Hallucinations?").
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 用于分布外测试集的7个关系见[表 5](#A1.T5 "附录 A 数据预处理 ‣ 对新知识进行微调是否会鼓励幻觉？")。
- en: 'Lastly, we perform two additional filtering steps: (1) To simplify the process
    of categorizing the examples w.r.t. $M$ and $3.9\%$ and $P413$ of the EntityQuestions
    train set.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们进行两个额外的过滤步骤：（1）为了简化对$M$和$3.9\%$以及EntityQuestions训练集中的P413示例的分类过程。
- en: Appendix B Test performance as Proxy for Hallucinations
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 测试性能作为幻觉的代理
- en: We now detail the relation between the test performance in our setting and hallucinations.
    In our study, poorer performance of a fine-tuned model $M_{D1}$ on the test set,
    can be attributed to a higher rate of hallucinations in $M_{D1}$, relative to
    its pre-existing knowledge, due to the following explanation.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在详细描述我们设置中测试性能与幻觉之间的关系。在我们的研究中，微调模型$M_{D1}$在测试集上的较差表现可以归因于$M_{D1}$中幻觉的发生率相对于其已有知识较高，原因如下。
- en: The test set can be conceptually divided into two types of questions. First,
    there are questions with answers that are unknown to $M$ and $M_{D2}$ and $M_{D2}$,
    i.e. $M$ and $M_{D2}$ must rely on their pre-existing knowledge to answer such
    questions, and a lower performance on such question can be only categorized as
    an hallucination w.r.t. pre-existing knowledge.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 测试集可以从概念上分为两种问题类型。首先，存在一些问题的答案是$M$和$M_{D2}$未知的，即$M$和$M_{D2}$必须依赖于其已有知识来回答这些问题，且在这种问题上表现较差只能归类为相对于已有知识的幻觉。
- en: Appendix C $\bm{P_{\bm{\mathtt{Correct}}}}$ Approximation
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 C $\bm{P_{\bm{\mathtt{Correct}}}}$ 近似
- en: This section expands §[3](#S3 "3 Quantifying Knowledge in LLMs ‣ Does Fine-Tuning
    LLMs on New Knowledge Encourage Hallucinations?") with additional details about
    our $P_{\mathtt{Correct}}$ based on the fraction of correct answers to $q$. We
    begin with randomly sampling $N_{\text{ex}}$-shot exemplars for each relation
    in our dataset (§[A](#A1 "Appendix A Data Preprocessing ‣ Does Fine-Tuning LLMs
    on New Knowledge Encourage Hallucinations?")). Then, to approximate $P_{\mathtt{Correct}}(q,a;M,T)$
    to generate answers to $q$ exemplars from the relation corresponding to $q$ to
    sample $N_{\text{sample}}$ exemplars. $P_{\mathtt{Correct}}(q,a;M,T> predictions.
    We also generate the greedy decoding prediction (<math id=$ exemplars. $P_{\mathtt{Correct}}(q,a;M,T=0)$
    predictions.^(13)^(13)13Since we can only have one greedy prediction for every
    k-shot exemplars.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 本节扩展了§[3](#S3 "3 量化 LLM 中的知识 ‣ 对新知识进行微调是否会鼓励幻觉？")，增加了关于我们基于正确答案比例的$P_{\mathtt{Correct}}$的额外细节。我们首先为数据集中的每个关系随机抽取$N_{\text{ex}}$-shot
    示例 (§[A](#A1 "附录 A 数据预处理 ‣ 对新知识进行微调是否会鼓励幻觉？"))。然后，为了近似$P_{\mathtt{Correct}}(q,a;M,T)$，从与$q$相关的关系中生成对$q$的答案，抽取$N_{\text{sample}}$
    示例。$P_{\mathtt{Correct}}(q,a;M,T)$的预测。我们还生成贪婪解码预测（<math id=$ 示例。$P_{\mathtt{Correct}}(q,a;M,T=0)$
    预测。^(13)^(13)13由于我们每个k-shot示例只能有一个贪婪预测。
- en: We use $k=4$ to output answers in the correct format. We use $N_{\text{ex}}=10$.
    The $N_{\text{sample}}=16$ are sampled from Top 40.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用$k=4$来以正确格式输出答案。我们使用$N_{\text{ex}}=10$。$N_{\text{sample}}=16$从前40名中采样。
- en: The $k$ different samples since we found that even when the few-shot exemplars
    are sampled per-relation, their exact choice still affects the prediction. In
    §[6](#S6 "6 SliCK Knowledge Categories Analysis ‣ Does Fine-Tuning LLMs on New
    Knowledge Encourage Hallucinations?") and [Figure 5](#S6.F5 "In Fine-grained Known
    Categories ‣ 6 SliCK Knowledge Categories Analysis ‣ Does Fine-Tuning LLMs on
    New Knowledge Encourage Hallucinations?") we show evidence that this also improves
    the quality of our categories.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现，即使在每种关系上采样少量示例时，这$k$个不同的样本的确切选择仍然会影响预测。在§[6](#S6 "6 SliCK 知识类别分析 ‣ 微调LLMs以学习新知识是否会引发幻觉？")和[图5](#S6.F5
    "在细粒度已知类别 ‣ 6 SliCK 知识类别分析 ‣ 微调LLMs以学习新知识是否会引发幻觉？")中，我们展示了这也提高了我们类别的质量。
- en: Below is an example of our 4-shot prompt format, from real example from EntityQuestions
    with the relation $P106$ representing occupation.^(14)^(14)14[https://www.wikidata.org/wiki/Property:P106](https://www.wikidata.org/wiki/Property:P106)
    The question in this case is *“What kind of work does Ron Konopka do?”* and the
    ground truth asnwer is *“geneticist”*.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们4-shot提示格式的一个示例，来自EntityQuestions中的真实示例，其中关系$P106$表示职业。^(14)^(14)14[https://www.wikidata.org/wiki/Property:P106](https://www.wikidata.org/wiki/Property:P106)
    在这个案例中，问题是*“Ron Konopka做什么工作？”*，真实答案是*“遗传学家”*。
- en: 'Q: What kind of work does Nicolas Roeg do? A: film director Q: What kind of
    work does Crystal Geoffré do? A: actor Q: What kind of work does Maurice Blondel
    do? A: philosopher Q: What kind of work does Javier de Burgos do? A: politician
    Q: What kind of work does Ron Konopka do? A: | Wrong Answer | Paraphrase | Higher
    Granularity | Lower Granularity |'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 'Q: Nicolas Roeg做什么工作？ A: 电影导演 Q: Crystal Geoffré做什么工作？ A: 演员 Q: Maurice Blondel做什么工作？
    A: 哲学家 Q: Javier de Burgos做什么工作？ A: 政治家 Q: Ron Konopka做什么工作？ A: | 错误答案 | 释义 |
    更高粒度 | 更低粒度 |'
- en: '| $90\%$ | $2\%$ |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| $90\%$ | $2\%$ |'
- en: 'Table 6: Error Analysis of 100 Predictions of the Pre-trained Model, for Which
    Exact Match is False.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 表6：100个预训练模型预测的错误分析，其中精确匹配为假。
- en: To decide whether a sampled answer is correct, we use the Exact Match (EM) metric
    to compare it with the ground truth answer. The main advantage in this choice
    is that when EM is True, we know that the answer is correct for $100\%$) and 50
    samples with $T=0.5$ of the cases where EM is False, the predicted answer is indeed
    incorrect. Which is a reasonable performance for our purpose, especially considering
    that when EM is True the answer is $100\%$ correct.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 要决定一个采样答案是否正确，我们使用精确匹配（EM）度量将其与真实答案进行比较。这种选择的主要优点是当EM为真时，我们知道答案是$100\%$正确的，而在EM为假时，有$50$个样本中$T=0.5$的情况下，预测答案确实是错误的。这对于我们的目的来说是一个合理的表现，特别是考虑到当EM为真时，答案是$100\%$正确的。
- en: Appendix D Data Annotation
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录D 数据标注
- en: we first calculate $P_{\mathtt{Correct}}(q,a;M,T=0)$ for each $(q,a)$ approximation
    (§[3](#S3 "3 Quantifying Knowledge in LLMs ‣ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?") and §[C](#A3 "Appendix C 𝑷_𝙲𝚘𝚛𝚛𝚎𝚌𝚝 Approximation ‣
    Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")). We then use
    these values to categorize each $(q,a)$ pair into one of our four categories (§[3](#S3
    "3 Quantifying Knowledge in LLMs ‣ Does Fine-Tuning LLMs on New Knowledge Encourage
    Hallucinations?") and [Figure 2](#S2.F2 "In 2 Study Setup ‣ Does Fine-Tuning LLMs
    on New Knowledge Encourage Hallucinations?")). We provide the full statistics
    of the categories on the train and test set, as well as the out-of-distribution
    test set in Tables [3](#A1.T3 "Table 3 ‣ Appendix A Data Preprocessing ‣ Does
    Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?"), [4](#A1.T4 "Table
    4 ‣ Appendix A Data Preprocessing ‣ Does Fine-Tuning LLMs on New Knowledge Encourage
    Hallucinations?") and [5](#A1.T5 "Table 5 ‣ Appendix A Data Preprocessing ‣ Does
    Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?").
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先计算每个 $(q,a)$ 近似的 $P_{\mathtt{Correct}}(q,a;M,T=0)$ (§[3](#S3 "3 量化 LLM 知识
    ‣ 微调 LLM 是否鼓励虚假信息？") 和 §[C](#A3 "附录 C 𝑷_𝙲𝚘𝚛𝚛𝚎𝚌𝚝 近似 ‣ 微调 LLM 是否鼓励虚假信息？"))。然后，我们使用这些值将每个
    $(q,a)$ 对分类到我们的四个类别之一 (§[3](#S3 "3 量化 LLM 知识 ‣ 微调 LLM 是否鼓励虚假信息？") 和 [图 2](#S2.F2
    "在 2 研究设置 ‣ 微调 LLM 是否鼓励虚假信息？"))。我们提供了训练集和测试集的类别统计数据，以及超出分布测试集的统计数据，详见表 [3](#A1.T3
    "表 3 ‣ 附录 A 数据预处理 ‣ 微调 LLM 是否鼓励虚假信息？")、[4](#A1.T4 "表 4 ‣ 附录 A 数据预处理 ‣ 微调 LLM 是否鼓励虚假信息？")
    和 [5](#A1.T5 "表 5 ‣ 附录 A 数据预处理 ‣ 微调 LLM 是否鼓励虚假信息？")。
- en: Appendix E Fine-tuning Details
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 E 微调细节
- en: Fine-tuning Data.
  id: totrans-238
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 微调数据。
- en: In §[4](#S4 "4 How Harmful are 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples? ‣ Does Fine-Tuning LLMs on
    New Knowledge Encourage Hallucinations?") we examine the effect of new knowledge
    in the fine-tuning dataset $D$, by varying the proportion of $\mathtt{Unknown}$.
    When we create variants of $D$ of $\mathtt{Unknown}$ $\mathtt{Known}$ of $\mathtt{Unknown}$
    *from each relation*.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在 §[4](#S4 "4 未知示例有多有害？ ‣ 微调 LLM 是否鼓励虚假信息？") 中，我们通过改变 $\mathtt{Unknown}$ 的比例来检查新知识在微调数据集
    $D$ 中的影响。当我们创建 $\mathtt{Unknown}$ 和 $\mathtt{Known}$ 的变体时，*来自每个关系* 的比例。
- en: 'In §[5](#S5 "5 Understanding Knowledge Types: Their Value and Impact ‣ Does
    Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?") we create single-category
    variants of $D$ across all variants, we want to make sure that we have $|D|$ as
    their sum. In other words, for each relation we calculate the size of the smallest
    category and sum these values. This leads to $|D|=6142$ to be the examples from
    category CAT and relation r. Consequently $\text{size}(\text{CAT}_{\text{r}})$.
    For example $\text{size}($ ${}_{\text{P131}})=553$ (see [Table 3](#A1.T3 "In Appendix
    A Data Preprocessing ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")).
    We then define:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在 §[5](#S5 "5 理解知识类型：它们的价值和影响 ‣ 微调 LLM 是否鼓励虚假信息？") 中，我们创建了 $D$ 的单类别变体，确保 $|D|$
    是它们的总和。换句话说，对于每个关系，我们计算最小类别的大小并求和。这导致 $|D|=6142$ 为类别 CAT 和关系 r 的示例。因此 $\text{size}(\text{CAT}_{\text{r}})$。例如
    $\text{size}($ ${}_{\text{P131}})=553$（见 [表 3](#A1.T3 "在附录 A 数据预处理 ‣ 微调 LLM 是否鼓励虚假信息？")）。然后我们定义：
- en: '|  | $$&#124;D&#124;=\sum_{r\in R_{\text{Train}}}\min\left\{\text{size}(CAT_{r})&#124;\
    \left.\begin{array}[]{l}\text{CAT}\in\{\\ \text{$\mathtt{HighlyKnown}$},\\'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | $$&#124;D&#124;=\sum_{r\in R_{\text{Train}}}\min\left\{\text{size}(CAT_{r})&#124;\
    \left.\begin{array}[]{l}\text{CAT}\in\{\\ \text{$\mathtt{HighlyKnown}$},\\'
- en: \text{$\mathtt{MaybeKnown}$},\\
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: \text{$\mathtt{MaybeKnown}$},\\
- en: \text{$\mathtt{WeaklyKnown}$},\\
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: \text{$\mathtt{WeaklyKnown}$},\\
- en: \text{$\mathtt{Unknown}$}\}\\
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: \text{$\mathtt{Unknown}$}\}\\
- en: \end{array}\right\}\right.$$ |  |
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: \end{array}\right\}\right.$$ |  |
- en: where $\text{R}_{\text{Train}}$ are the 12 relations from the training set.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\text{R}_{\text{Train}}$ 是来自训练集的 12 个关系。
- en: Below is an example of our data format in the train, development and test sets,
    from real example from EntityQuestions with the relation $P106$ representing occupation.^(15)^(15)15[https://www.wikidata.org/wiki/Property:P106](https://www.wikidata.org/wiki/Property:P106)
    The question in this case is *“What kind of work does Ron Konopka do?”* and the
    ground truth asnwer is *“geneticist”*. Answer the following question. What kind
    of work does Ron Konopka do?
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们在训练、开发和测试集中的数据格式示例，来自于真实的EntityQuestions例子，其中关系$P106$表示职业。^(15)^(15)15[https://www.wikidata.org/wiki/Property:P106](https://www.wikidata.org/wiki/Property:P106)
    在这个例子中，问题是*“Ron Konopka 从事什么样的工作？”*，而真实的答案是*“遗传学家”*。回答以下问题：Ron Konopka 从事什么样的工作？
- en: Fine-tuning hypeparameters.
  id: totrans-248
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 微调超参数。
- en: We fine-tune every model for 50 epochs for all our model variants to completely
    fit the training set, so we can examine all stages of fine-tuning. We use learning
    rate of 1e-5, a batch size of 128, and a dropout rate of 0.05. We evaluate the
    models every epoch on the development set. The early_stop stopping criteria is
    defined to be the epoch with the maximum accuracy on the development set.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对所有模型变体进行50轮的微调，以完全适应训练集，从而可以检查微调的各个阶段。我们使用学习率为1e-5，批量大小为128，丢弃率为0.05。我们在每一轮上都评估模型在开发集上的表现。early_stop停止标准定义为在开发集上准确度最高的轮次。
- en: Appendix F Train Accuracy on Different $\mathtt{Known}$ Categories
  id: totrans-250
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录F 在不同$\mathtt{Known}$类别上的训练准确率
- en: '![Refer to caption](img/0f1bebe64fac6944111fa1f3da2001f6.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/0f1bebe64fac6944111fa1f3da2001f6.png)'
- en: 'Figure 6: Training accuracy as a function of fine-tuning duration, evaluated
    on the variant with $50\%$ fine-tuning examples. For reference, we also include
    the accuracy on the development set, accompanied by a zoom-in plot within a narrower
    range, to provide a more visible and clear view.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：训练准确率与微调时间的函数关系，评估了$50\%$微调样本的变体。为了参考，我们还包括了开发集上的准确率，并附上了在较窄范围内的放大图，以提供更清晰的视图。
- en: In §[4.3](#S4.SS3 "4.3 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples are Fitted Slower than 𝙺𝚗𝚘𝚠𝚗 Examples
    ‣ 4 How Harmful are 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples? ‣ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?") we analyze the fine-tuning dynamic and present the
    training accuracy as function of the fine-tuning duration in [Figure 1](#S1.F1
    "In 1 Introduction ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?").
    For simplicity we treated the $\mathtt{Known}$ categories collectively. For reference
    we also include the plot with the full per-category breakdown in [Figure 6](#A6.F6
    "In Appendix F Train Accuracy on Different 𝙺𝚗𝚘𝚠𝚗 Categories ‣ Does Fine-Tuning
    LLMs on New Knowledge Encourage Hallucinations?").
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在§[4.3](#S4.SS3 "4.3 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples are Fitted Slower than 𝙺𝚗𝚘𝚝𝚜 Examples
    ‣ 4 How Harmful are 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples? ‣ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?")中，我们分析了微调动态，并在[图1](#S1.F1 "在1 引言 ‣ 微调LLMs在新知识上是否会鼓励虚假信息？")中呈现了训练准确率与微调时间的函数关系。为简便起见，我们将$\mathtt{Known}$类别一起处理。作为参考，我们还包括了[图6](#A6.F6
    "在附录F 不同𝙺𝚗𝚘𝚠𝚗类别上的训练准确率 ‣ 微调LLMs在新知识上是否会鼓励虚假信息？")中按类别分解的完整图表。
- en: Appendix G Linear Model
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录G 线性模型
- en: 'In §[4.4](#S4.SS4 "4.4 The Influence of 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 vs 𝙺𝚗𝚘𝚠𝚗 on Accuracy: A Linear
    Model Perspective ‣ 4 How Harmful are 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples? ‣ Does Fine-Tuning LLMs
    on New Knowledge Encourage Hallucinations?") and §[4.5](#S4.SS5 "4.5 Generalization
    to New Relations ‣ 4 How Harmful are 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples? ‣ Does Fine-Tuning LLMs
    on New Knowledge Encourage Hallucinations?") we use a linear model ([Equation 1](#S4.E1
    "In 4.4 The Influence of 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 vs 𝙺𝚗𝚘𝚠𝚗 on Accuracy: A Linear Model Perspective
    ‣ 4 How Harmful are 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples? ‣ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?")) that predicts that test accuracy and the out-of-distribution
    test accuracy. We estimate the parameters of this linear model based on results
    from all our variants of $D$ and $\mathtt{Unknown}$ fits during different fine-tuning
    stages. This way we collect a dataset with examples of the form $(Accuracy,N_{\text{Kn}},N_{\text{Unk}})$,
    which we use to fit a linear regression model.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在 §[4.4](#S4.SS4 "4.4 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 与 𝙺𝚗𝚘𝚠𝚗 对准确率的影响：线性模型视角 ‣ 4 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 示例有多有害？ ‣ 微调
    LLM 是否会促使虚假信息？") 和 §[4.5](#S4.SS5 "4.5 对新关系的泛化 ‣ 4 𝚄𝚗𝚔𝚗𝚘𝚝𝚣 示例有多有害？ ‣ 微调 LLM 是否会促使虚假信息？")
    中，我们使用一个线性模型 ([公式 1](#S4.E1 "在 4.4 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 与 𝙺𝚗𝚘𝚠𝚟 对准确率的影响：线性模型视角 ‣ 4 𝚄𝚟𝚕𝚘𝚎𝚝𝚉
    示例有多有害？ ‣ 微调 LLM 是否会促使虚假信息？")) 来预测测试准确率和分布外测试准确率。我们基于 $D$ 和 $\mathtt{Unknown}$
    在不同微调阶段的所有变体结果来估计这个线性模型的参数。这样，我们收集了一个形式为 $(准确率, N_{\text{Kn}}, N_{\text{Unk}})$
    的数据集，并用来拟合一个线性回归模型。
- en: Appendix H Out-of-distribution (OOD) Evaluation
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 H 分布外 (OOD) 评估
- en: '![Refer to caption](img/094837f6c2114bc180b4e31f77fb3f4f.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/094837f6c2114bc180b4e31f77fb3f4f.png)'
- en: (a)
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![Refer to caption](img/d374814505ee99c74a3063838f0169a7.png)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d374814505ee99c74a3063838f0169a7.png)'
- en: (b)
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: 'Figure 7: Performance on the *out-of-distribution (OOD)* test set as a function
    of the $\%$ examples in the fine-tuning dataset $D$. This plot is the OOD version
    of [Figure 3](#S3.F3 "In 3 Quantifying Knowledge in LLMs ‣ Does Fine-Tuning LLMs
    on New Knowledge Encourage Hallucinations?"). Everything is similar to [Figure 3](#S3.F3
    "In 3 Quantifying Knowledge in LLMs ‣ Does Fine-Tuning LLMs on New Knowledge Encourage
    Hallucinations?"), except that y-axis is the accuracy on the OOD test set. We
    note that *the development set did not change (not OOD)*, thus it does not necessarily
    reflects the optimal stopping point for OOD.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：*分布外 (OOD)* 测试集的性能，作为微调数据集 $D$ 中 $\%$ 样本的函数。这个图是[图 3](#S3.F3 "在 3 量化 LLM
    知识 ‣ 微调 LLM 是否会促使虚假信息？") 的 OOD 版本。与[图 3](#S3.F3 "在 3 量化 LLM 知识 ‣ 微调 LLM 是否会促使虚假信息？")
    一样，唯一的不同是 y 轴是 OOD 测试集上的准确率。我们注意到*开发集没有变化（不是 OOD）*，因此这不一定反映了 OOD 的最佳停止点。
- en: 'In §[4.5](#S4.SS5 "4.5 Generalization to New Relations ‣ 4 How Harmful are
    𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples? ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")
    we discuss *out-of-distribution (OOD)* results. In these experiments we simply
    used our OOD test set consisting of 7 relations unseen during fine-tuning (see
    §[A](#A1 "Appendix A Data Preprocessing ‣ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?")). When we perform the analysis discussed in §[4.1](#S4.SS1
    "4.1 Higher 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Ratio is Proportional to Performance Degradation ‣ 4 How Harmful
    are 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples? ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")
    and §[4.2](#S4.SS2 "4.2 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples: Harmful or Neutral? ‣ 4 How Harmful
    are 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples? ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?"),
    we additionally evaluated the models on the OOD test set. For completeness, we
    add here [Figure 7](#A8.F7 "In Appendix H Out-of-distribution (OOD) Evaluation
    ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?"), which is
    the out-of-distribution version of [Figure 3](#S3.F3 "In 3 Quantifying Knowledge
    in LLMs ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?").
    [Figure 7(a)](#A8.F7.sf1 "In Figure 7 ‣ Appendix H Out-of-distribution (OOD) Evaluation
    ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?") presents
    the OOD test performance as a function of $\%$ examples in $D$ fine-tuning examples.
    The corresponding *in-distribution* results ([Figure 3(b)](#S3.F3.sf2 "In Figure
    3 ‣ 3 Quantifying Knowledge in LLMs ‣ Does Fine-Tuning LLMs on New Knowledge Encourage
    Hallucinations?")) were discussed in §[4.2](#S4.SS2 "4.2 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples: Harmful
    or Neutral? ‣ 4 How Harmful are 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples? ‣ Does Fine-Tuning LLMs on New
    Knowledge Encourage Hallucinations?"). We notice that similar trends, just with
    a smaller overall magnitude of the performance drop, up to 6 points drop compared
    to up to 14 for in-distribution. This smaller drop magnitude is also reflected
    in smaller values of $|\beta_{\text{ukn}}|$ ([Table 1](#S2.T1 "In 4.4 The Influence
    of 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 vs 𝙺𝚗𝚘𝚠𝚗 on Accuracy: A Linear Model Perspective ‣ 4 How Harmful are
    𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples? ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")).'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在§[4.5](#S4.SS5 "4.5 一般化到新关系 ‣ 4 未知样本的危害有多大？ ‣ 微调 LLM 对新知识是否鼓励虚假信息？")中，我们讨论了*分布外（OOD）*结果。在这些实验中，我们简单地使用了包含7个在微调过程中未见过的关系的OOD测试集（见§[A](#A1
    "附录 A 数据预处理 ‣ 微调 LLM 对新知识是否鼓励虚假信息？")）。当我们进行§[4.1](#S4.SS1 "4.1 更高的未知比例与性能下降成正比
    ‣ 4 未知样本的危害有多大？ ‣ 微调 LLM 对新知识是否鼓励虚假信息？")和§[4.2](#S4.SS2 "4.2 未知样本：有害还是中性？ ‣ 4
    未知样本的危害有多大？ ‣ 微调 LLM 对新知识是否鼓励虚假信息？")中讨论的分析时，我们还在OOD测试集上评估了模型。为了完整性，我们在此添加[图 7](#A8.F7
    "附录 H 分布外（OOD）评估 ‣ 微调 LLM 对新知识是否鼓励虚假信息？")，这是[图 3](#S3.F3 "在 3 量化 LLM 知识 ‣ 微调 LLM
    对新知识是否鼓励虚假信息？")的分布外版本。[图 7(a)](#A8.F7.sf1 "图 7 ‣ 附录 H 分布外（OOD）评估 ‣ 微调 LLM 对新知识是否鼓励虚假信息？")展示了OOD测试性能与$D$微调样本中$\%$样本的关系。相应的*分布内*结果（[图
    3(b)](#S3.F3.sf2 "图 3 ‣ 3 量化 LLM 知识 ‣ 微调 LLM 对新知识是否鼓励虚假信息？")）在§[4.2](#S4.SS2 "4.2
    未知样本：有害还是中性？ ‣ 4 未知样本的危害有多大？ ‣ 微调 LLM 对新知识是否鼓励虚假信息？")中讨论。我们注意到类似的趋势，只是性能下降的总体幅度较小，最多下降6点，而分布内则最多下降14点。这一较小的下降幅度在$|\beta_{\text{ukn}}|$的较小值中也有所体现（[表
    1](#S2.T1 "在 4.4 未知与已知对准确率的影响：线性模型视角 ‣ 4 未知样本的危害有多大？ ‣ 微调 LLM 对新知识是否鼓励虚假信息？")）。
- en: '|  | early_stop |  | Convergence |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '|  | early_stop |  | 收敛 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '|  | $\mathtt{Full}$ | $\mathtt{Mkn}$ | $\mathtt{Unk}$ |  | $\mathtt{Hkn}$
    | $\mathtt{Wkn}$ |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathtt{Full}$ | $\mathtt{Mkn}$ | $\mathtt{Unk}$ |  | $\mathtt{Hkn}$
    | $\mathtt{Wkn}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- |'
- en: '| $D_{\mathtt{HighlyKnown}}$ | 40.5^(∗∗) |  | 98.7 | 60.1^(∗∗) | 9.0^(∗∗) |
    0.6^(∗∗) |  | 40.0^(∗∗) |  | 98.4 | 58.8^(∗∗) | 8.5^(∗∗) | 0.7^(∗∗) |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| $D_{\mathtt{HighlyKnown}}$ | 40.5^(∗∗) |  | 98.7 | 60.1^(∗∗) | 9.0^(∗∗) |
    0.6^(∗∗) |  | 40.0^(∗∗) |  | 98.4 | 58.8^(∗∗) | 8.5^(∗∗) | 0.7^(∗∗) |'
- en: '| $D_{\mathtt{MaybeKnown}}$ | 43.6 |  | 98.4 | 69.9 | 12.1^(∗∗) | 1.0^(∗∗)
    |  | 43.2 |  | 97.5^∗ | 68.2 | 12.9^(∗∗) | 1.3^(∗∗) |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| $D_{\mathtt{MaybeKnown}}$ | 43.6 |  | 98.4 | 69.9 | 12.1^(∗∗) | 1.0^(∗∗)
    |  | 43.2 |  | 97.5^∗ | 68.2 | 12.9^(∗∗) | 1.3^(∗∗) |'
- en: '| $D_{\mathtt{WeaklyKnown}}$ | 39.2^(∗∗) |  | 95.0^(∗∗) | 59.2^(∗∗) | 8.6^(∗∗)
    | 0.4^(∗∗) |  | 35.4^(∗∗) |  | 73.5^(∗∗) | 55.8^(∗∗) | 17.2 | 2.2^(∗∗) |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| $D_{\mathtt{WeaklyKnown}}$ | 39.2^(∗∗) |  | 95.0^(∗∗) | 59.2^(∗∗) | 8.6^(∗∗)
    | 0.4^(∗∗) |  | 35.4^(∗∗) |  | 73.5^(∗∗) | 55.8^(∗∗) | 17.2 | 2.2^(∗∗) |'
- en: '| $D_{\mathtt{Unknown}}$ | 37.5^(∗∗) |  | 95.6^(∗∗) | 52.9^(∗∗) | 6.5^(∗∗)
    | 0.6^(∗∗) |  | 25.8^(∗∗) |  | 55.8^(∗∗) | 36.6^(∗∗) | 12.2^(∗∗) | 3.2 |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| $D_{\mathtt{Unknown}}$ | 37.5^(∗∗) |  | 95.6^(∗∗) | 52.9^(∗∗) | 6.5^(∗∗)
    | 0.6^(∗∗) |  | 25.8^(∗∗) |  | 55.8^(∗∗) | 36.6^(∗∗) | 12.2^(∗∗) | 3.2 |'
- en: '| $D_{\mathtt{Natural}}$ | 43.5 |  | 98.0^∗ | 67.6^(∗∗) | 14.1 | 1.8 |  | 41.8^(∗∗)
    |  | 95.5^(∗∗) | 61.7^(∗∗) | 14.8^(∗∗) | 2.5^∗ |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| $D_{\mathtt{Natural}}$ | 43.5 |  | 98.0^∗ | 67.6^(∗∗) | 14.1 | 1.8 |  | 41.8^(∗∗)
    |  | 95.5^(∗∗) | 61.7^(∗∗) | 14.8^(∗∗) | 2.5^∗ |'
- en: 'Table 7: A copy of [Table 2](#S4.T2 "In 4.4 The Influence of 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 vs 𝙺𝚗𝚘𝚠𝚗
    on Accuracy: A Linear Model Perspective ‣ 4 How Harmful are 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples?
    ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?") with detailed
    notation of the statistic significant test results. In each column, statistically
    significant differences from the best result are indicated using ^∗ and ^(∗∗)
    for $p<0.05$ respectively.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '表7: [表2](#S4.T2 "在4.4 𝚄𝚗𝚔𝚗𝚘𝚝𝚎𝚙𝚋𝚛𝚝𝚝𝚝𝚝𝚜")的副本，详细标注了统计显著性检验结果。在每列中，统计显著性差异用^∗和^(∗∗)表示，分别对应$p<0.05$。'
- en: Appendix I Statistic Significance Tests
  id: totrans-273
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录I 统计显著性检验
- en: 'In §[5](#S5 "5 Understanding Knowledge Types: Their Value and Impact ‣ Does
    Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?") we present [Table 2](#S4.T2
    "In 4.4 The Influence of 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 vs 𝙺𝚗𝚘𝚠𝚗 on Accuracy: A Linear Model Perspective
    ‣ 4 How Harmful are 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples? ‣ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?"). As mentioned in the caption, we perform statistic
    significance tests for each column. To this end we compare all the values to the
    maximal value in this column.'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在§[5](#S5 "5 理解知识类型：它们的价值和影响 ‣ 对LLMs进行新知识微调是否会促进幻觉？")中，我们展示了[表2](#S4.T2 "在4.4
    𝚄𝚗𝚔𝚝𝚎𝚙𝚋𝚛𝚝𝚝𝚝𝚝𝚜")。如标题中所述，我们对每列进行了统计显著性检验。为此，我们将所有值与该列中的最大值进行比较。
- en: For each subset of the test set, we randomly shuffle all the examples in it,
    split them up into 100 approximately equally sized subsets, and compute accuracy
    for each of them for all the models of interest. We then apply paired-sample t-test
    with $p<0.05$.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 对于测试集的每个子集，我们随机打乱其中的所有示例，将其分成100个大致相等的子集，然后计算所有感兴趣模型的每个子集的准确性。我们随后应用配对样本t检验，$p<0.05$。
- en: 'In [Table 2](#S4.T2 "In 4.4 The Influence of 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 vs 𝙺𝚗𝚘𝚠𝚗 on Accuracy:
    A Linear Model Perspective ‣ 4 How Harmful are 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples? ‣ Does Fine-Tuning
    LLMs on New Knowledge Encourage Hallucinations?"), the best result is in bold,
    as well as all the results with statistically non-significant difference from
    the best with $p<0.05$, except two cases where it is only with $p<0.05$ $\mathtt{Unk}$
    $\mathtt{Mkn}$).'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在[表2](#S4.T2 "在4.4 𝚄𝚗𝚔𝚝𝚎𝚙𝚋𝚛𝚝𝚝𝚝𝚝𝚜")中，最佳结果用粗体表示，所有与最佳结果差异统计上不显著的结果用$p<0.05$表示，除了两个仅用$p<0.05$
    $\mathtt{Unk}$ $\mathtt{Mkn}$)的情况。
- en: 'Since we also discuss “horizontal” comparisons, where we compare early_stop
    to Convergence, we additionally run significance tests (not annotated in [Table 2](#S4.T2
    "In 4.4 The Influence of 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 vs 𝙺𝚗𝚘𝚠𝚗 on Accuracy: A Linear Model Perspective
    ‣ 4 How Harmful are 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Examples? ‣ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?")) for $All$ was not statistically significant while
    for all others (including $D_{\mathtt{Natural}}$.'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们还讨论了“横向”比较，即比较early_stop与Convergence，我们另外进行了显著性检验（在[表2](#S4.T2 "在4.4 𝚄𝚗𝚔𝚗𝚘𝚠𝚗与𝙺𝚗𝚘𝚝𝚎𝚙𝚋𝚛𝚝𝚝𝚝𝚝𝚜")）对$All$进行了显著性检验，但结果在统计上并不显著，而对其他所有类别（包括$D_{\mathtt{Natural}}$）则显著。
- en: Appendix J The P(True) Case Study
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录J P(True)案例研究
- en: 'In §[6](#S6 "6 SliCK Knowledge Categories Analysis ‣ Does Fine-Tuning LLMs
    on New Knowledge Encourage Hallucinations?") we used the P(True) metric from Kadavath
    et al. ([2022](#bib.bib10)) as a case study for comparison. In [Figure 5](#S6.F5
    "In Fine-grained Known Categories ‣ 6 SliCK Knowledge Categories Analysis ‣ Does
    Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?") we compare our $\mathtt{Unknown}$
    based on a threshold of P(True). We calculated P(True) for every $(q,a)$ pair
    in the test set using Kadavath et al. ([2022](#bib.bib10))’s prompt:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在§[6](#S6 "6 SliCK知识类别分析 ‣ 对LLMs进行新知识微调是否会促进幻觉？")中，我们使用了Kadavath等人（[2022](#bib.bib10)）提出的P(True)指标作为对比的案例研究。在[图5](#S6.F5
    "在细粒度已知类别 ‣ 6 SliCK知识类别分析 ‣ 对LLMs进行新知识微调是否会促进幻觉？")中，我们根据P(True)的阈值比较了我们的$\mathtt{Unknown}$。我们使用Kadavath等人（[2022](#bib.bib10)）的提示计算了测试集中每个$(q,a)$对的P(True)。
- en: 'Question: Where is Paris located? Proposed Answer: France Is the proposed answer:
    (A) True (B) False The proposed answer is:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 问题：巴黎在哪里？建议回答：法国。建议的答案是：（A）正确（B）错误。建议的答案是：
- en: 'We then treated $(q,a)$. We experimented with each possible threshold $T$,
    according to our test set. For each threshold $T$ out of the test set, (2) what
    was the accuracy on these examples after fine-tuning. We plot the results in [Figure 5](#S6.F5
    "In Fine-grained Known Categories ‣ 6 SliCK Knowledge Categories Analysis ‣ Does
    Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?"), where P(True) is
    represented with the yellow line and our $\mathtt{Unknown}$). We also check smaller
    values of $N_{\text{ex}}$ (§[5](#S5 "5 Understanding Knowledge Types: Their Value
    and Impact ‣ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")).'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接着处理了$(q,a)$。我们根据测试集尝试了每一个可能的阈值$T$。对于测试集中的每个阈值$T$，（2）在微调后的这些例子上的准确率是多少。我们在[图5](#S6.F5
    "在细粒度已知类别 ‣ 6 SliCK知识类别分析 ‣ 微调LLM在新知识上是否会引起幻觉？")中绘制了结果，其中P(True)用黄色线表示，以及我们的$\mathtt{Unknown}$）。我们还检查了较小的$N_{\text{ex}}$
    (§[5](#S5 "5 理解知识类型：其价值与影响 ‣ 微调LLM在新知识上是否会引起幻觉？"))。
- en: 'Appendix K Re-labeling $\mathtt{Unknown}$ Fine-tuning Example with an Uncertainty
    Expression: Initial Experiment'
  id: totrans-282
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录K 重新标记$\mathtt{Unknown}$ 微调例子与不确定性表达：初步实验
- en: '|  | early_stop |  | Convergence |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '|  | early_stop |  | Convergence |'
- en: '| --- | --- | --- | --- |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '|  | Accuracy | % Answered |  | Accuracy | % Answered |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '|  | 准确率 | % 回答 |  | 准确率 | % 回答 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| $D$ | 43.0 | 100.0 |  | 38.8 | 100.0 |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| $D$ | 43.0 | 100.0 |  | 38.8 | 100.0 |'
- en: '| $D_{\mathtt{IDK}}$ | 61.8 | 58.7 |  | 61.8 | 55.6 |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| $D_{\mathtt{IDK}}$ | 61.8 | 58.7 |  | 61.8 | 55.6 |'
- en: 'Table 8: Results of our initial experiment where the label of the $\mathtt{Unknown}$
    in this case is the variant with $50\%$ and $50\%$. $D_{\mathtt{IDK}}$ $\mathtt{Unknown}$
    did not respond with *“I don’t know”*.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 表8：我们初步实验的结果，其中$\mathtt{Unknown}$的标签在这种情况下是$50\%$和$50\%$的变体。$D_{\mathtt{IDK}}$
    $\mathtt{Unknown}$未以*“我不知道”*回应。
- en: In this work we showed that fitting $\mathtt{Unknown}$ examples from the fine-tuning
    dataset.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们展示了拟合$\mathtt{Unknown}$例子来自微调数据集的情况。
- en: We now perform a preliminary experiment where check whether fine-tuning the
    model to abstain from $\mathtt{Unknown}$ fine-tuning examples with the expression
    *“I don’t know”* and test whether this mitigates the observed overfitting.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在进行一个初步实验，检查是否通过微调模型以避免$\mathtt{Unknown}$微调例子，并测试这种方式是否缓解了观察到的过拟合现象。
- en: '[Table 8](#A11.T8 "In Appendix K Re-labeling 𝚄𝚗𝚔𝚗𝚘𝚠𝚗 Fine-tuning Example with
    an Uncertainty Expression: Initial Experiment ‣ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?") presents the $\%$ did not respond with *“I don’t know”*)
    and the accuracy on those questions. This experiment was conducted on the $D$
    $\mathtt{Unknown}$ as a reference and the second row is for the results with $D_{\mathtt{IDK}}$
    of the $\mathtt{Unknown}$ was replaced with *“I don’t know”*'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '[表8](#A11.T8 "在附录K重新标记𝚄𝚗𝚔𝚗𝚘𝚠𝚗 微调例子与不确定性表达：初步实验 ‣ 微调LLM在新知识上是否会引起幻觉？")展示了$\%$未以*“我不知道”*回应的准确率。这项实验以$D$
    $\mathtt{Unknown}$作为参考，第二行是$D_{\mathtt{IDK}}$的结果，其中$\mathtt{Unknown}$被替换为*“我不知道”*。'
- en: Consistent with the findings from previous work Zhang et al. ([2023](#bib.bib33)),
    we observe an improved accuracy on willingly answered test examples (when comparing
    $D$). When we compare early_stop vs Convergence for $D$) which illustrates the
    overfitting effect. However, we observe that re-labeling the $\mathtt{Unknown}$
    remains $61.8$)
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 与Zhang等人（[2023](#bib.bib33)）的先前研究结果一致，我们观察到在自愿回答的测试例子上准确率有所提高（当比较$D$时）。当我们比较early_stop与Convergence对于$D$时，这显示了过拟合效应。然而，我们观察到重新标记$\mathtt{Unknown}$的准确率仍为$61.8$。
