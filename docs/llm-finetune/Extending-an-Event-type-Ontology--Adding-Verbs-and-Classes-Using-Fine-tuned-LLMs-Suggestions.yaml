- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 18:40:11'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:40:11
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Extending an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned
    LLMs Suggestions'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展事件类型本体：使用微调的大型语言模型建议添加动词和类别
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2306.02130](https://ar5iv.labs.arxiv.org/html/2306.02130)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2306.02130](https://ar5iv.labs.arxiv.org/html/2306.02130)
- en: '{textblock}'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '{textblock}'
- en: 16(0,0.1)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 16(0,0.1)
- en: 'This paper was published at LAW-XVII @ ACL 2023. Please cite the published
    version: [https://aclanthology.org/2023.law-1.9/](https://aclanthology.org/2023.law-1.9/)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇论文发表于 LAW-XVII @ ACL 2023。请引用已发布版本：[https://aclanthology.org/2023.law-1.9/](https://aclanthology.org/2023.law-1.9/)
- en: Jana Straková    Eva Fučíková    Jan Hajič    Zdeňka Urešová
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Jana Straková    Eva Fučíková    Jan Hajič    Zdeňka Urešová
- en: Institute of Formal and Applied Linguistics, Faculty of Mathematics and Physics
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 形式与应用语言学研究所，数学与物理学院
- en: Charles University, Prague, Czech Republic
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 查尔斯大学，布拉格，捷克共和国
- en: '{strakova,fucikova,hajic,uresova}@ufal.mff.cuni.cz'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '{strakova,fucikova,hajic,uresova}@ufal.mff.cuni.cz'
- en: Abstract
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: In this project, we have investigated the use of advanced machine learning methods,
    specifically fine-tuned large language models, for pre-annotating data for a lexical
    extension task, namely adding descriptive words (verbs) to an existing (but incomplete,
    as of yet) ontology of event types. Several research questions have been focused
    on, from the investigation of a possible heuristics to provide at least hints
    to annotators which verbs to include and which are outside the current version
    of the ontology, to the possible use of the automatic scores to help the annotators
    to be more efficient in finding a threshold for identifying verbs that cannot
    be assigned to any existing class and therefore they are to be used as seeds for
    a new class. We have also carefully examined the correlation of the automatic
    scores with the human annotation. While the correlation turned out to be strong,
    its influence on the annotation proper is modest due to its near linearity, even
    though the mere fact of such pre-annotation leads to relatively short annotation
    times.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我们研究了使用先进的机器学习方法，特别是微调的大型语言模型，来为词汇扩展任务预注释数据，即将描述性词汇（动词）添加到现有（但尚不完整）事件类型本体中。研究重点包括：从调查可能的启发式方法来提供至少对标注者的提示，哪些动词应包括，哪些不在本体的当前版本中，到可能使用自动评分帮助标注者更高效地找到识别不能分配到现有类别的动词的阈值，并将这些动词作为新类别的种子。我们还仔细检查了自动评分与人工注释的相关性。虽然相关性很强，但由于其近线性，自动评分对实际注释的影响有限，尽管这种预注释的事实确实导致了相对较短的注释时间。
- en: 1 Introduction
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 介绍
- en: Annotation of highly-dimensional, voluminous data is expensive, time-consuming
    and in addition, in case of deep-niche domains, depending on expertly trained
    specialists, such as linguists or medical experts. Therefore it may be advantageous
    to organize, prioritize and provide suggestions to guide further annotation efforts
    efficiently. Especially in a situation with a rich, constantly growing set of
    classes, such as it is the case with ontologies.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 高维、大规模数据的注释成本高、耗时，并且在深度小众领域，通常依赖于经过专业训练的专家，如语言学家或医学专家。因此，组织、优先排序和提供建议以高效指导进一步的注释工作可能是有利的。特别是在类别丰富、不断增长的情况下，如本体的情况。
- en: Specifically, given an already partially labeled set of examples with yet unfinished
    set of classes, classifier based on large language models (LLMs) can be leveraged
    to navigate the landscape of possible annotations.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，考虑到一个已经部分标记的示例集和尚未完成的类别集，可以利用基于大型语言模型（LLMs）的分类器来导航可能的注释范围。
- en: Our showcase is an event-type ontology, the SynSemClass 4.0 (Uresova et al.,
    [2022](#bib.bib21)), populated with synonymous verbs denoting events or states.
    The set of events is currently dynamically evolving and encompasses classes in
    English, Czech, German and Spanish, so far limited to verbs.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的展示是一个事件类型本体，SynSemClass 4.0（Uresova 等，[2022](#bib.bib21)），填充了表示事件或状态的同义动词。事件集合目前动态发展，涵盖了英语、捷克语、德语和西班牙语的类别，目前仅限于动词。
- en: 'As any ontological resource is never complete, we have investigated various
    methods to facilitate efficient extension of such ontologies in two ways: adding
    classes for greater coverage on new texts, and adding verbs to existing classes
    to allow for more accurate human understanding of the classes in the ontology
    for a particular form of the given class expression.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 由于任何本体资源都不可能是完整的，我们研究了两种方法来有效扩展这些本体：一是为新的文本添加类别以获得更广泛的覆盖范围，二是向现有类别中添加动词，以便更准确地理解本体中类别的特定形式。
- en: We suggest to achieve these by
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议通过以下方式实现这些目标：
- en: '1.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: examining examples with consistently low class affiliation scores across a large
    corpus as potential candidates for new classes;
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 检查在大语料库中始终具有低类别相关分数的示例，作为新类别的潜在候选。
- en: '2.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: on the other side of the spectrum, examining high-certainty decisions of a supervised
    classifier to locate highly-affiliated lemmas to a particular class, corresponding
    to “low-hanging fruit” for a quick manual review and confirmation of the inclusion
    of the lemma into the suggested class.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在光谱的另一端，检查监督分类器的高确定性决策，以定位与特定类别高度相关的词条， correspondingly，这对应于“低垂的果实”，方便快速的人工审查和确认词条是否应包括在建议的类别中。
- en: In all cases, classifier prediction serves as guidance and the annotators are
    briefed to consider the suggestions as election votes. The final decision is always
    the annotator’s, who can accept or dismiss the suggestions.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有情况下，分类器预测作为指导，注释员会被告知将建议视为选票。最终决定总是由注释员做出，他们可以接受或拒绝这些建议。
- en: 'The organization of this paper is as follows: Sect. [2](#S2 "2 The Ontology
    ‣ Extending an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned
    LLMs Suggestions") introduces the SynSemClass v4 ontology and the current state
    of annotations. Sect. [3](#S3 "3 Generating Annotation Suggestions with Fine-tuned
    LLM Classifier ‣ Extending an Event-type Ontology: Adding Verbs and Classes Using
    Fine-tuned LLMs Suggestions") describes the fine-tuned LLM classifier used to
    generate the annotation suggestions. Sect. [4](#S4 "4 Post-processing with Manual
    Annotations ‣ Extending an Event-type Ontology: Adding Verbs and Classes Using
    Fine-tuned LLMs Suggestions") describes the manual annotations post-processing.
    Results are presented in Sect. [5](#S5 "5 Results ‣ Extending an Event-type Ontology:
    Adding Verbs and Classes Using Fine-tuned LLMs Suggestions") and discussed in
    Section [6](#S6 "6 Discussion of Results ‣ Extending an Event-type Ontology: Adding
    Verbs and Classes Using Fine-tuned LLMs Suggestions"). Finally, we conclude in
    Sect. [7](#S7 "7 Conclusions and Future Work ‣ Extending an Event-type Ontology:
    Adding Verbs and Classes Using Fine-tuned LLMs Suggestions").'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '本文的组织结构如下：第[2](#S2 "2 The Ontology ‣ Extending an Event-type Ontology: Adding
    Verbs and Classes Using Fine-tuned LLMs Suggestions")节介绍了SynSemClass v4本体及当前注释状态。第[3](#S3
    "3 Generating Annotation Suggestions with Fine-tuned LLM Classifier ‣ Extending
    an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned LLMs Suggestions")节描述了用于生成注释建议的微调LLM分类器。第[4](#S4
    "4 Post-processing with Manual Annotations ‣ Extending an Event-type Ontology:
    Adding Verbs and Classes Using Fine-tuned LLMs Suggestions")节描述了手动注释后处理。结果在第[5](#S5
    "5 Results ‣ Extending an Event-type Ontology: Adding Verbs and Classes Using
    Fine-tuned LLMs Suggestions")节中展示，并在第[6](#S6 "6 Discussion of Results ‣ Extending
    an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned LLMs Suggestions")节中讨论。最后，我们在第[7](#S7
    "7 Conclusions and Future Work ‣ Extending an Event-type Ontology: Adding Verbs
    and Classes Using Fine-tuned LLMs Suggestions")节中得出结论。'
- en: We release the source code at [https://github.com/strakova/synsemclass_ml](https://github.com/strakova/synsemclass_ml).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[https://github.com/strakova/synsemclass_ml](https://github.com/strakova/synsemclass_ml)发布源代码。
- en: 2 The Ontology
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 本体
- en: In our experiments, we have used the Czech part of the SynSemClass 4.0¹¹1[https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-4746](https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-4746)
    (Uresova et al., [2022](#bib.bib21)) in which contextually-based synonymous verbs
    in various languages are classified into multilingual synonym classes according
    to the semantic and syntactic properties they display. There is no specific model
    or lexicographic theory behind building the database. However, from the linguistic
    point of view, the notion of synonymy used is based on the “loose” definition
    of synonymy by Lyons and Jackson Lyons ([1968](#bib.bib14)); Jackson ([1988](#bib.bib8)),
    or alternatively and very closely, on both “near-synonyms” and “partial synonyms”
    as defined by Lyons Lyons ([1995](#bib.bib15)); Cruse ([2000](#bib.bib4)) or “plesionyms”
    as defined by Cruse Cruse ([1986](#bib.bib5)).²²2The “loose” definition of synonymy
    covers synonyms that fulfil some of the conditions stipulated for synonymy in
    the strictest sense but not all and does not work with the “absolute” synonymy
    covering the total identity of meaning. The “partial synonymy” is defined Lyons
    ([1995](#bib.bib15)) as a relationship holding between two lexemes that satisfy
    the criterion of identity of meaning, but do not meet all the conditions of absolute
    synonymy. The “near-synonymy” Lyons ([1995](#bib.bib15)) and “plesionyms” Cruse
    ([1986](#bib.bib5)) is defined as “expressions that are more or less similar,
    but not identical, in meaning”.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的实验中，我们使用了捷克语部分的SynSemClass 4.0¹¹1[https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-4746](https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-4746)（Uresova
    et al., [2022](#bib.bib21)），在该实验中，基于上下文的同义动词在各种语言中被分类为多语言同义类，根据它们展示的语义和句法属性进行分类。构建该数据库背后没有特定的模型或词典理论。然而，从语言学角度来看，所使用的同义词概念基于Lyons和Jackson
    Lyons ([1968](#bib.bib14))、Jackson ([1988](#bib.bib8))的“宽松”定义，或者非常接近Lyons Lyons
    ([1995](#bib.bib15))、Cruse ([2000](#bib.bib4))定义的“近义词”和“部分同义词”，或者Cruse Cruse ([1986](#bib.bib5))定义的“plesionyms”。²²2“宽松”同义词定义涵盖那些符合严格意义上的同义词条件中的一些条件，但不是全部，并且不适用于涵盖完全意义一致的“绝对”同义词。“部分同义词”
    Lyons ([1995](#bib.bib15)) 被定义为两个词汇之间的一种关系，它们满足意义的一致性标准，但不符合绝对同义词的所有条件。“近义词” Lyons
    ([1995](#bib.bib15)) 和“plesionyms” Cruse ([1986](#bib.bib5)) 被定义为“在意义上或多或少相似，但不完全相同的表达”。
- en: From the ontological point of view, the classes are meant to reflect different
    event types (concepts) and collect various information about the possible forms
    of expression of the event type in language.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 从本体论的角度来看，这些类旨在反映不同的事件类型（概念），并收集有关事件类型在语言中可能的表达形式的各种信息。
- en: '![Refer to caption](img/96acbec99d95985ffc0d1b689a3bdbd1.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/96acbec99d95985ffc0d1b689a3bdbd1.png)'
- en: 'Figure 1: SynSemClass example entry as presented on its public access website,
    Class ID: vec00591 (simplified)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：SynSemClass示例条目，如其公共访问网站上所示，类ID：vec00591（简化版）
- en: 'The following main basic features are distinguished in SynSemClass (Fig. [1](#S2.F1
    "Figure 1 ‣ 2 The Ontology ‣ Extending an Event-type Ontology: Adding Verbs and
    Classes Using Fine-tuned LLMs Suggestions")) Uresova et al. ([2022](#bib.bib21)):'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 'SynSemClass中区分了以下主要基本特征（图[1](#S2.F1 "Figure 1 ‣ 2 The Ontology ‣ Extending
    an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned LLMs Suggestions")）
    Uresova et al. ([2022](#bib.bib21))：'
- en: •
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'The name of each multilingual class stands for a single concept (e.g., of accelerating)³³3This
    is different from the commonly used term of “semantic classes of verbs” as represented,
    for example, in VerbNet, where the class is defined much more broadly – such as
    for all verbs of movement. and corresponds to the verb that represents the prototypical
    sense in each of the languages included: class member (CM) abuse for English,
    zneužívat for Czech, and missbrauchen for German. So far, SynSemClass focuses
    on verbal synonyms since they carry the key syntactic-semantic information for
    language understanding.⁴⁴4As described in detail in Urešová et al. ([2019](#bib.bib20),
    [2018a](#bib.bib17), [2018c](#bib.bib19), [2018b](#bib.bib18)).'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每个多语言类的名称代表一个单一的概念（例如，加速）³³3这不同于通常使用的“动词的语义类”一词，例如在VerbNet中表示的类，其中类的定义要宽泛得多——例如，所有运动动词。
    并且对应于每种语言中表示原型意义的动词：英语的类成员（CM）abuse，捷克语的zneužívat，德语的missbrauchen。到目前为止，SynSemClass
    专注于动词同义词，因为它们携带着对语言理解至关重要的句法-语义信息。⁴⁴4如Urešová et al. ([2019](#bib.bib20)，[2018a](#bib.bib17)，[2018c](#bib.bib19)，[2018b](#bib.bib18))中详细描述。
- en: •
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Each class is also provided with a brief language-dependent general class definition,
    which characterizes the meaning, or concept of the class, i.e. the meaning of
    all synonymous verbs contained in it. The class is viewed as a substitute for
    an ontology unit representing a single concept, similar to the treatment of WordNet
    synsets in McCrae et al. ([2014](#bib.bib16)).
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每个类别还提供了简要的语言相关的通用类别定义，描述了类别的意义或概念，即包含在其中的所有同义动词的意义。该类别被视为表示单一概念的本体单元的替代，类似于
    McCrae 等人对 WordNet 同义词集的处理 ([2014](#bib.bib16))。
- en: •
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'For each class, SynSemClass also provides a fixed set (called “Roleset” (RS))
    of defined “situational participants” (called “semantic roles” (SR)) that are
    common for all the members (the individual verb senses) of a particular class.
    The RS is mapped to the valency frame of the individual synonymous verbs securing
    for each synonymous verb to be characterized both meaning-wise (SR) and structurally
    (valency arguments). For example, the class vec00591 abuse, as concept of “abusing”,
    has two semantic roles, Abuser and Abused (Fig. [1](#S2.F1 "Figure 1 ‣ 2 The Ontology
    ‣ Extending an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned
    LLMs Suggestions")). Every role in SynSemClass is provided with a brief language-dependent
    general role definition as well as every class. While the SRs resemble FrameNet’s
    “Frame Elements” (and sometimes borrow their names from there), it should be pointed
    out that there is one fundamental difference: the SRs used in SynSemClass aim
    at being defined across the ontology, and not per class (as they would be if we
    follow the “per frame” approach used in FrameNet).'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '对于每个类别，SynSemClass 还提供了一组固定的（称为“Roleset” (RS)）定义的“情境参与者”（称为“语义角色” (SR)），这些角色对某个特定类别的所有成员（各个动词意义）都是通用的。RS
    被映射到个别同义动词的价语框架中，确保每个同义动词在意义上（SR）和结构上（价语论元）都得到表征。例如，类别 vec00591 abuse，作为“滥用”的概念，有两个语义角色，施虐者和受害者（见图 [1](#S2.F1
    "Figure 1 ‣ 2 The Ontology ‣ Extending an Event-type Ontology: Adding Verbs and
    Classes Using Fine-tuned LLMs Suggestions")）。每个 SynSemClass 中的角色都提供了简要的语言相关的通用角色定义以及每个类别的定义。虽然
    SRs 类似于 FrameNet 的“框架元素”（有时借用其名称），但需要指出的是，有一个根本的区别：SynSemClass 中使用的 SRs 旨在跨本体定义，而不是按类别定义（如果我们遵循
    FrameNet 中的“按框架”方法的话）。'
- en: •
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Each individual language-dependent synonymous verb included in a given class
    is called Class Member and for each new CM to be added, it must be possible, in
    the prototypical case, to create a mapping between its syntactic arguments and
    the roles in that class’ RoleSet; see the example in our web-based lexicon (Fig. [1](#S2.F1
    "Figure 1 ‣ 2 The Ontology ‣ Extending an Event-type Ontology: Adding Verbs and
    Classes Using Fine-tuned LLMs Suggestions")).⁵⁵5The public web version is available
    at [https://lindat.cz/services/SynSemClass40/SynSemClass40.html](https://lindat.cz/services/SynSemClass40/SynSemClass40.html)
    Each CM of one class is denoted by a verb lemma and the valency frame ID which,
    roughly speaking, represents the particular verb sense.'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '每个包含在给定类别中的个别语言相关同义动词称为类别成员（Class Member），对于每个新添加的 CM，在原型情况下，必须能够在其句法论元和该类别的
    RoleSet 中的角色之间创建映射；参见我们基于网络的词典中的示例（见图 [1](#S2.F1 "Figure 1 ‣ 2 The Ontology ‣
    Extending an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned LLMs
    Suggestions")）。⁵⁵5 公共网络版本可在 [https://lindat.cz/services/SynSemClass40/SynSemClass40.html](https://lindat.cz/services/SynSemClass40/SynSemClass40.html)
    查阅。每个类别的 CM 由动词词元和价语框架 ID 表示，粗略地说，代表了特定的动词意义。'
- en: •
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Each CM is further linked to one, or more existing online lexical resources
    for each language to support, e.g., comparative studies, or any other possible
    research in the community. In SynSemClass (SSC), there exist links to e.g., Vallex⁶⁶6[https://hdl.handle.net/11234/1-3524](https://hdl.handle.net/11234/1-3524)
    for Czech, FrameNet⁷⁷7[https://framenet.icsi.berkeley.edu/fndrupal/](https://framenet.icsi.berkeley.edu/fndrupal/)
    and VerbNet⁸⁸8[https://uvi.colorado.edu/andhttp://verbs.colorado.edu/verbnet/index.html](https://uvi.colorado.edu/andhttp://verbs.colorado.edu/verbnet/index.html)
    for English, E-VALBU⁹⁹9[https://grammis.ids-mannheim.de/verbvalenz](https://grammis.ids-mannheim.de/verbvalenz)
    for German, AnCora^(10)^(10)10[http://clic.ub.edu/corpus/es/ancoraverb_es](http://clic.ub.edu/corpus/es/ancoraverb_es)
    for Spanish. Each Class Member is exemplified by instances of real texts (and
    their translations to English) extracted from translated or parallel corpora.
    Specifically, data is extracted from the Prague Czech-English Dependency Corpus
    (PCEDT)^(11)^(11)11[https://ufal.mff.cuni.cz/pcedt2.0/en/index.html](https://ufal.mff.cuni.cz/pcedt2.0/en/index.html)
    for Czech-English, from the Paracrawl corpus^(12)^(12)12[https://opus.nlpl.eu/ParaCrawl.php](https://opus.nlpl.eu/ParaCrawl.php)
    for German-English and from the XSRL dataset^(13)^(13)13[https://catalog.ldc.upenn.edu/LDC2021T09](https://catalog.ldc.upenn.edu/LDC2021T09)
    for Spanish-English.
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每个CM进一步链接到一个或多个现有的在线词汇资源，以支持例如比较研究或社区中的其他可能研究。例如，在SynSemClass（SSC）中，存在链接到例如捷克语的Vallex⁶⁶6[https://hdl.handle.net/11234/1-3524](https://hdl.handle.net/11234/1-3524)，英语的FrameNet⁷⁷7[https://framenet.icsi.berkeley.edu/fndrupal/](https://framenet.icsi.berkeley.edu/fndrupal/)和VerbNet⁸⁸8[https://uvi.colorado.edu/andhttp://verbs.colorado.edu/verbnet/index.html](https://uvi.colorado.edu/andhttp://verbs.colorado.edu/verbnet/index.html)，德语的E-VALBU⁹⁹9[https://grammis.ids-mannheim.de/verbvalenz](https://grammis.ids-mannheim.de/verbvalenz)，西班牙语的AnCora^(10)^(10)10[http://clic.ub.edu/corpus/es/ancoraverb_es](http://clic.ub.edu/corpus/es/ancoraverb_es)。每个类别成员通过从翻译或平行语料库中提取的真实文本实例（及其英文翻译）进行示例化。具体来说，数据从捷克语-英语的布拉格捷克语-英语依存语料库（PCEDT）^(11)^(11)11[https://ufal.mff.cuni.cz/pcedt2.0/en/index.html](https://ufal.mff.cuni.cz/pcedt2.0/en/index.html)提取，德语-英语的Paracrawl语料库^(12)^(12)12[https://opus.nlpl.eu/ParaCrawl.php](https://opus.nlpl.eu/ParaCrawl.php)提取，西班牙语-英语的XSRL数据集^(13)^(13)13[https://catalog.ldc.upenn.edu/LDC2021T09](https://catalog.ldc.upenn.edu/LDC2021T09)提取。
- en: SynSemClass 4.0 includes 1200 classes (885 active after merging or deleting)
    with 8169 Class Members. All classes are annotated in Czech and English, 60 of
    them have also German annotation. Spanish is not included in the web version but
    is under construction Fernández-Alcaina et al. ([2023](#bib.bib6)).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: SynSemClass 4.0包含1200个类别（合并或删除后为885个活跃类别），有8169个类别成员。所有类别均已用捷克语和英语标注，其中60个类别还包括德语注释。西班牙语不包括在网页版中，但正在建设中Fernández-Alcaina等（[2023](#bib.bib6)）。
- en: 3 Generating Annotation Suggestions with Fine-tuned LLM Classifier
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 生成注释建议的细化LLM分类器
- en: 3.1 Data
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 数据
- en: The Czech part of the SynSemClass ontology^(14)^(14)14SynSemClass 4.0 with additions
    annotated since the last v4.0 release. yielded 12045 example sentences with 3313
    unique verbs (lemmas) manually annotated in 965 classes.^(15)^(15)15We considered
    only active (not merged, not deleted) classes in the current state of SynSemClass
    (SSC) annotated since v4.0 release, and naturally, only those classes which are
    represented with at least one example sentence (to be used as LLM input). We have
    split the data randomly in proportion 80/10/10 in a stratified train/dev/test
    split,^(16)^(16)16Stratified means forcing the distribution of the target variable,
    in our case the classes, to be equal among the train/dev/test split. resulting
    in 9635/1205/1205 train/dev/test examples.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: SynSemClass本体的捷克语部分^(14)^(14)14SynSemClass 4.0与自上一个v4.0版本以来添加的注释。产生了12045个例句，其中3313个独特的动词（词元）在965个类别中进行了手动标注。^(15)^(15)15我们只考虑了在v4.0版本发布以来当前状态下的活跃（未合并，未删除）类别，自然，只考虑了那些有至少一个例句（用于LLM输入）的类别。我们将数据随机拆分为80/10/10的比例，即分层训练/开发/测试拆分，^(16)^(16)16分层表示强制目标变量（在我们案例中为类别）的分布在训练/开发/测试拆分中保持一致。结果为9635/1205/1205训练/开发/测试示例。
- en: 'Our input is a list of 3389 completely new, unseen verbs (lemmas) and our motivation
    is to differentiate:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的输入是一份3389个完全新的、未见过的动词（词元）的列表，我们的动机是区分：
- en: •
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: verbs consistently poorly classified as class members of any of the existing
    classes, i.e., possible candidates for establishing new classes,
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 动词在任何现有类别中的分类 consistently 较差，即可能成为建立新类别的候选者，
- en: •
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: verbs highly affiliate to some of the existing classes, i.e., possible candidates
    for adding them as one of the verbs characterizing an existing class.
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 动词高度关联到一些现有类别，即作为将它们添加为现有类别之一的动词的可能候选。
- en: To obtain the classification score for each lemma-class pair, we used a large
    raw corpus of written Czech, the SYN v4 (Křen et al., [2016](#bib.bib10); Hnátková
    et al., [2014](#bib.bib7)).^(17)^(17)17[http://hdl.handle.net/11234/1-1846](http://hdl.handle.net/11234/1-1846)
    Specifically, we used the first 2.753.494 sentences of the corpus, which amounts
    to exactly 100-th of all its sentences, as classifying the corpus in its entirety
    (275.349.474 sentences) is above our GPU computation means. The classification
    took 20 hours on a single NVIDIA A100 GPU with 4 CPU threads.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得每个词形-类别对的分类分数，我们使用了一个大型的捷克语原始语料库SYN v4（Křen等人，[2016](#bib.bib10)；Hnátková等人，[2014](#bib.bib7)）。^(17)^(17)17[http://hdl.handle.net/11234/1-1846](http://hdl.handle.net/11234/1-1846)
    具体来说，我们使用了语料库的前2,753,494个句子，这恰好是其所有句子的100分之一，因为对整个语料库（275,349,474个句子）进行分类超出了我们的GPU计算能力。在一台单独的NVIDIA
    A100 GPU上，分类花费了20小时，配备4个CPU线程。
- en: 3.2 Model
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 模型
- en: Classification tasks on a finalized set of target variables are usually modeled
    as a probability distribution over K targets (possible outcomes). However, we
    find ourselves in an untypical situation in which the output target set is not
    closed yet, which requires a different perspective. If we model the problem as
    multi-class probability distribution, we will face an out-of-distribution problem
    concerning verbs which do not belong to any of the classes. We therefore model
    the problem as K independent binary classifiers, one for each class, of which
    each predicts the probability of the input belonging to the particular class in
    question, much like a multi-label problem. Technically, this equals to replacing
    the output softmax activaction function with the sigmoid activation function and
    accommodating the loss function accordingly, from sparse categorical cross entropy
    to sparse binary (focal) cross entropy,^(18)^(18)18”Focal” stands for focal loss Lin
    et al. ([2018](#bib.bib11)), which addresses class imbalances in training data
    by encouraging learning on the sparse set of hard examples (the rare positives
    in our case, because only one of hundreds of classes is correct) and discouraging
    learning from a vast majority of easy (negative) examples. while the weights are
    estimated jointly by fine-tuning one shared large language model.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一组最终确定的目标变量，分类任务通常被建模为对K个目标（可能结果）的概率分布。然而，我们发现自己处于一个非典型的情况，输出目标集尚未封闭，这需要不同的视角。如果我们将问题建模为多类概率分布，我们将面临一个关于动词的超出分布问题，这些动词不属于任何类别。因此，我们将问题建模为K个独立的二元分类器，每个类别一个，每个类别预测输入属于所讨论类别的概率，就像一个多标签问题一样。从技术上讲，这等同于将输出softmax激活函数替换为sigmoid激活函数，并相应地调整损失函数，从稀疏分类交叉熵到稀疏二元（焦点）交叉熵，^(18)^(18)18“焦点”代表焦点损失Lin等人（[2018](#bib.bib11)），通过鼓励在训练数据中学习稀疏的困难示例（在我们的情况下是罕见的正例，因为数百个类别中只有一个是正确的）并阻止从大多数简单（负面）示例中学习来解决类别不平衡问题。而权重是通过微调一个共享的大型语言模型来估计的。
- en: 3.3 Training
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 训练
- en: 'Our classifier is a fine-tuned RemBERT (Chung et al., [2021](#bib.bib3)), a
    rebalanced 559M-parameter mBERT,^(19)^(19)19Although BERT (110M parameters) and
    RemBERT ($\sim$) to model the target class probabilities independently (see also
    previous Section [3.2](#S3.SS2 "3.2 Model ‣ 3 Generating Annotation Suggestions
    with Fine-tuned LLM Classifier ‣ Extending an Event-type Ontology: Adding Verbs
    and Classes Using Fine-tuned LLMs Suggestions")). We trained our model using the
    Adam optimizer Kingma and Ba ([2015](#bib.bib9)) with defaults $\beta$ training
    steps) from 0 to peak learning rate $1\cdot 10^{-5}$. The hyperparameters were
    tuned on the development set; the model achieved development set accuracy $78.67\%$.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '我们的分类器是经过微调的RemBERT（Chung等人，[2021](#bib.bib3)），一个重新平衡的559M参数mBERT，^(19)^(19)19尽管BERT（110M参数）和RemBERT（$\sim$）独立地对目标类概率进行建模（另请参阅前文[3.2](#S3.SS2
    "3.2 Model ‣ 3 Generating Annotation Suggestions with Fine-tuned LLM Classifier
    ‣ Extending an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned
    LLMs Suggestions")）。我们使用Adam优化器Kingma和Ba（[2015](#bib.bib9)）进行训练，默认$\beta$训练步骤）从0到峰值学习率$1\cdot
    10^{-5}$。超参数在开发集上进行调整；模型在开发集上达到了准确率$78.67\%$。'
- en: 3.4 Related Work
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 相关工作
- en: We are not aware of a similar work using LLMs to classify words (and specifically,
    verbs) into synonym classes to enrich an existing ontology or lexicon. There are
    works building such resources from scratch, starting from Brown et al. ([1992](#bib.bib2))
    the model and its statistical, unsupervised class hierarchy building algorithm.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不知道类似的工作使用 LLM 来将词（特别是动词）分类为同义词类，以丰富现有的本体或词汇。有些工作是从头开始构建这样的资源，从 Brown 等人 ([1992](#bib.bib2))
    模型及其统计、无监督的类别层次构建算法开始。
- en: 'The ASFALDA project (“Analyzing Semantics with Frames: Annotation, Lexicon,
    Discourse and Automation”)^(20)^(20)20[https://anr.fr/Project-ANR-12-CORD-0023](https://anr.fr/Project-ANR-12-CORD-0023)
    aims at projecting English FrameNet frames to French also using machine learning
    but it is a recently started project and there are no published results yet.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ASFALDA 项目（“使用框架分析语义：注释、词汇、话语和自动化”）^(20)^(20)20[https://anr.fr/Project-ANR-12-CORD-0023](https://anr.fr/Project-ANR-12-CORD-0023)旨在将英语
    FrameNet 框架投射到法语中，也利用机器学习，但这是一个刚刚启动的项目，目前尚无已发布的结果。
- en: The Predicate Matrix project Lopez de Lacalle et al. ([2016](#bib.bib12)) aims
    at creating a resource similar to SynSemClass, by using similar resources that
    SynSemClass links to. The entries created automatically are not manually checked
    (for the most part) and we are not aware of publications describing if there were
    specific experiments on the comparison of the automatically created entries vs.
    human annotation.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Predicate Matrix 项目 Lopez de Lacalle 等人 ([2016](#bib.bib12)) 旨在创建一个类似于 SynSemClass
    的资源，通过使用 SynSemClass 连接的类似资源。自动创建的条目（大部分情况下）未经过人工检查，我们也不清楚是否有关于自动创建的条目与人工注释比较的具体实验的出版物。
- en: There is also work on using DNNs (LSTMs specifically) to model lexical ambiguity
    Aina et al. ([2019](#bib.bib1)), which is relevant for our task, but the method
    is not related to another existing ontological or lexical resource for training
    and/or fine/tuning the ML part of the system.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 还有使用 DNN（特别是 LSTMs）来建模词汇歧义的工作 Aina 等人 ([2019](#bib.bib1))，这对于我们的任务是相关的，但该方法与训练和/或微调
    ML 部分的系统的其他现有本体或词汇资源无关。
- en: '![Refer to caption](img/d9fd5b2017d5155c0c6025ab23b92f2d.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/d9fd5b2017d5155c0c6025ab23b92f2d.png)'
- en: 'Figure 2: Preprocessed data with 5 suggested classes per lemma, first and last
    five lines, as presented to the annotators in an Excel spreadsheet (the version
    with scores shown; cursor (in column C, line 3, 2^(nd) data line) shows the annotation
    choices)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：预处理数据，每个词形有 5 个建议类别，电子表格中的前五行和最后五行（显示分数的版本；光标（在 C 列，第 3 行，第 2^(nd) 数据行）显示注释选择）
- en: 4 Post-processing with Manual Annotations
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 后处理与人工注释
- en: 4.1 Input Data Preparation
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 输入数据准备
- en: In the output of the automatic classifier, each lemma has been associated with
    ten highest-scoring classes in which the lemma can potentially be inserted as
    a class member. The score is thus assigned to each lemma-class pair. These scores
    are numbers between 0 and 1, but it is not a probability but really just a “score”
    or a “weight.” The smaller the score, the less is the used LLM sure that the verb
    lemma belongs to the class, and vice versa - the higher the score, the more convinced
    it is to be added to the class.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在自动分类器的输出中，每个词形已与可能插入的 10 个最高评分的类别关联。因此，为每个词形-类别对分配了分数。这些分数是介于 0 和 1 之间的数字，但这不是概率，而只是一个“分数”或“权重”。分数越小，使用的
    LLM 对动词词形是否属于该类别的确定性越低，反之，分数越高，则对其被添加到该类别的信心越大。
- en: 'The data as received from the classifier (3073 lemmas, with 10 class suggestions
    and scores for each of them) have been converted to an Excel spreadsheet to be
    presented to the annotators as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 从分类器接收到的数据（3073 个词形，每个词形有 10 个类别建议和分数）已被转换为 Excel 电子表格，以便向注释员呈现如下：
- en: '1.'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: For each lemma (line in the resulting file), the first five classes suggested
    by the classifier with the highest scores as assigned by the classifier have been
    kept;
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于每个词形（结果文件中的行），保留了分类器建议的分数最高的前五个类别；
- en: '2.'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: two disjunct sets of lemmas and their class membership suggestions, with 100
    lemmas each, have been randomly selected from the 3073 lemmas scored by the classifier;
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 两组不相交的词形及其类别成员建议，每组各 100 个词形，已经从分类器评分的 3073 个词形中随机选择；
- en: '3.'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: the two sets (called Set1 and Set2) have been converted to an Excel spreadsheet,
    keeping frequency information for the lemma, the five highest-scoring class membership
    suggestions, and the associated scores with each class;
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这两个集合（称为 Set1 和 Set2）已经转换为 Excel 电子表格，保留了词条的频率信息、五个得分最高的类别成员建议以及每个类别的相关得分；
- en: '4.'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: in front of each class suggestion, an extra column has been inserted with the
    four-way list of decisions the annotators will have to make;
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在每个类别建议前，插入了一列额外的栏目，列出了标注员需要做出的四项决策；
- en: '5.'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: colors have been used to group all the information pertaining to one lemma-class
    pair and the decision requested;
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 颜色被用来将所有与一个词条-类别对相关的信息以及所请求的决策进行分组；
- en: '6.'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '6.'
- en: 'for each class suggested, a web link has been inserted in its spreadsheet cell,
    to allow the annotator to get to the class definition and contents (which is available
    on the web as shown in Fig. [1](#S2.F1 "Figure 1 ‣ 2 The Ontology ‣ Extending
    an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned LLMs Suggestions"))
    by a single click.'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于每个建议的类别，在其电子表格单元格中插入了一个网页链接，以便标注员可以通过单击直接访问类别定义和内容（如图 [1](#S2.F1 "图 1 ‣ 2
    本体 ‣ 扩展事件类型本体：使用微调 LLMs 建议添加动词和类别")）。
- en: 'Then, each set has been duplicated and in the copy, the scores have been deleted.
    The four files have then been renamed to contain the annotator abbreviation and
    the order number (1 for the version without scores, 2 for the version with scores
    (see Fig. [2](#S3.F2 "Figure 2 ‣ 3.4 Related Work ‣ 3 Generating Annotation Suggestions
    with Fine-tuned LLM Classifier ‣ Extending an Event-type Ontology: Adding Verbs
    and Classes Using Fine-tuned LLMs Suggestions")), i.e., in a cross-named way for
    the Set1 and Set2; see Table [1](#S4.T1 "Table 1 ‣ 4.1 Input Data Preparation
    ‣ 4 Post-processing with Manual Annotations ‣ Extending an Event-type Ontology:
    Adding Verbs and Classes Using Fine-tuned LLMs Suggestions")).'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，每个集合被复制，并在副本中删除了得分。接着，这四个文件被重新命名，包含了标注员的缩写和顺序号（1代表没有得分的版本，2代表有得分的版本（参见图 [2](#S3.F2
    "图 2 ‣ 3.4 相关工作 ‣ 3 使用微调 LLM 分类器生成标注建议 ‣ 扩展事件类型本体：使用微调 LLMs 建议添加动词和类别")），即，以交叉命名的方式命名
    Set1 和 Set2；见表 [1](#S4.T1 "表 1 ‣ 4.1 输入数据准备 ‣ 4 后处理与人工标注 ‣ 扩展事件类型本体：使用微调 LLMs
    建议添加动词和类别")。
- en: '| Annotator: | A1 | A2 |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 标注员： | A1 | A2 |'
- en: '| --- | --- | --- |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 1^(st) batch (no scores shown) | Set1 | Set2 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 第1^(st) 批次（未显示得分） | Set1 | Set2 |'
- en: '| 2^(nd) batch (scores shown) | Set2 | Set1 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 第2^(nd) 批次（显示了得分） | Set2 | Set1 |'
- en: 'Table 1: Order and Assignment of Data to Annotators'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：数据分配和标注员分配顺序
- en: 4.2 Experiment Design
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 实验设计
- en: 'The Excel spreadsheets as described in the previous section (Sect. [4.1](#S4.SS1
    "4.1 Input Data Preparation ‣ 4 Post-processing with Manual Annotations ‣ Extending
    an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned LLMs Suggestions"))
    have been sent to two annotators in two batches: first, both received the file
    with five suggestions for each lemma, but no scores. Each thus had 500 decisions
    to make (100 lemmas $\times$ 5 classifier suggestions per lemma) on a four-point
    scale, 0-3, denoting how strongly they recommend to include the lemma in the suggested
    class. The “no” decision corresponds to 0, “rather_no” to 1, “rather_yes” to 2,
    and “yes” to 3\. These responses have been provided in the Excel spreadsheet as
    a fixed list, in order to avoid typos. In the second batch, the annotators received
    the other 100 lemmas, this time with scores denoting the classifier’s view on
    the strength of the class membership recommendation, for the five classes presented.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一节（节 [4.1](#S4.SS1 "4.1 输入数据准备 ‣ 4 后处理与人工标注 ‣ 扩展事件类型本体：使用微调 LLMs 建议添加动词和类别")）所述的
    Excel 电子表格已分两批发送给两位标注员：首先，他们都收到了包含每个词条五个建议的文件，但没有得分。每人因此需要在四分制（0-3）上做出 500 个决策，表示他们推荐将词条纳入建议类别的强度。
    “no”决策对应 0，“rather_no”对应 1，“rather_yes”对应 2，“yes”对应 3。为了避免输入错误，这些响应已在 Excel 电子表格中以固定列表的形式提供。在第二批中，标注员收到了其他
    100 个词条，这次包含了得分，表示分类器对类别成员推荐强度的看法，针对展示的五个类别。
- en: In total, there were thus 200 lemmas manually classified twice (by the two annotators),
    with the classifier scores shown only for half of them to each annotator. No annotator
    annotated any lemma twice, and they worked independently without consulting each
    other. The annotators, native speakers of Czech, have been previously trained
    on the same task (with data coming from a different preprocessing method), so
    no additional training has been performed. Their pay has been based on hours worked,
    approx. $8/hour amounting to about 170% of the legal minimal salary valid in 2023
    in the Czech Republic.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 总共200个词汇条目被人工分类了两次（由两名标注员），其中一半的分类结果仅展示给每位标注员。没有标注员对任何词汇条目进行了两次标注，他们独立工作，互不咨询。标注员是捷克语的母语者，之前已经在相同任务上接受过培训（数据来自不同的预处理方法），因此没有进行额外的培训。他们的薪酬按工作小时计算，约为$8/小时，相当于2023年捷克共和国合法最低工资的约170%。
- en: The order and cross-assignment of the data to the annotators allowed us to measure
    interannotator agreement and the correlation between the annotators decisions
    (averaged) and the automatic classifier recommendations. Also, we could compare
    the speed of annotation with and without the additional clue, namely, the scores
    suggested by the automatic classifier.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的排序和交叉分配使我们能够测量标注员之间的一致性以及标注员决策（平均值）与自动分类器推荐之间的相关性。此外，我们还可以比较有无附加线索（即自动分类器建议的分数）的标注速度。
- en: '![Refer to caption](img/706353ca433eba72773b90fb7483b40b.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/706353ca433eba72773b90fb7483b40b.png)'
- en: 'Figure 3: Correlation between the automatic scores assigned to the lemma-class
    pairs and annotation decisions; human scores correspond to the annotation scale
    (3 - yes, 2 - rather_yes, 1 - rather_no and 0 - no) and automatic scores are bucketed
    (interval size: 0.05) and annotation decisions averaged in each bucket. The grey
    line shows the size of each bucket on a logarithmic scale.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：自动分配给词汇类别对和标注决策之间的相关性；人工分数对应于标注量表（3 - 是，2 - 较是，1 - 较否和0 - 否），自动分数被分桶（间隔大小：0.05）并在每个桶中平均标注决策。灰色线条显示了每个桶的大小在对数尺度上。
- en: 5 Results
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结果
- en: 'This section describes the results obtained as described in Sect. [3](#S3 "3
    Generating Annotation Suggestions with Fine-tuned LLM Classifier ‣ Extending an
    Event-type Ontology: Adding Verbs and Classes Using Fine-tuned LLMs Suggestions")
    and Sect. [4](#S4 "4 Post-processing with Manual Annotations ‣ Extending an Event-type
    Ontology: Adding Verbs and Classes Using Fine-tuned LLMs Suggestions"). For the
    discussion of the various outputs, see Sect. [6](#S6 "6 Discussion of Results
    ‣ Extending an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned
    LLMs Suggestions").'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '本节描述了如第[3](#S3 "3 Generating Annotation Suggestions with Fine-tuned LLM Classifier
    ‣ Extending an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned
    LLMs Suggestions")节和第[4](#S4 "4 Post-processing with Manual Annotations ‣ Extending
    an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned LLMs Suggestions")节所述的结果。有关各种输出的讨论，请参见第[6](#S6
    "6 Discussion of Results ‣ Extending an Event-type Ontology: Adding Verbs and
    Classes Using Fine-tuned LLMs Suggestions")节。'
- en: 5.1 Human Annotation Statistics and IAA
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 人工标注统计与IAA
- en: 'There were 1000 pairs of Czech verb and suggested class in two sets (Set1 and
    Set2, see Sect. [4.1](#S4.SS1 "4.1 Input Data Preparation ‣ 4 Post-processing
    with Manual Annotations ‣ Extending an Event-type Ontology: Adding Verbs and Classes
    Using Fine-tuned LLMs Suggestions")). The two annotators, A1 and A2, had to decide
    whether the verb could be a member of the class. Annotators could set 4 values:
    “yes,” “rather_yes,” “rather_no” or “no,”. Agreement was calculated for only two
    values, Y and N, to which the four detailed levels of annotation have been mapped
    in a natural way (specifically, “rather_no” has been mapped to “N” and “rather_yes”
    to “Y”). The (dis)agreement figures have been counted based on each individual
    decision as made by the two annotators. The resulting counts are shown in the
    Tab. [2](#S5.T2 "Table 2 ‣ 5.1 Human Annotation Statistics and IAA ‣ 5 Results
    ‣ Extending an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned
    LLMs Suggestions") and agreement rate and Cohen’s $\kappa$ value in the Tab. [3](#S5.T3
    "Table 3 ‣ 5.1 Human Annotation Statistics and IAA ‣ 5 Results ‣ Extending an
    Event-type Ontology: Adding Verbs and Classes Using Fine-tuned LLMs Suggestions").'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在两个数据集中（Set1和Set2，见第[4.1节](#S4.SS1 "4.1 输入数据准备 ‣ 4 后处理与人工注释 ‣ 扩展事件类型本体：使用微调的LLM建议添加动词和类别")）共有1000对捷克动词和建议的类别。两个注释员，A1和A2，必须决定该动词是否可以成为该类别的成员。注释员可以设置4个值：“yes”、“rather_yes”、“rather_no”或“no”。协议仅计算两个值，即Y和N，这四个详细的注释等级以自然的方式映射到这两个值（具体来说，“rather_no”映射为“N”，“rather_yes”映射为“Y”）。（不）一致性数据根据两个注释员的每个单独决策进行统计。结果计数见表[2](#S5.T2
    "表2 ‣ 5.1 人工注释统计与IAA ‣ 5 结果 ‣ 扩展事件类型本体：使用微调的LLM建议添加动词和类别")，一致性率和Cohen’s $\kappa$值见表[3](#S5.T3
    "表3 ‣ 5.1 人工注释统计与IAA ‣ 5 结果 ‣ 扩展事件类型本体：使用微调的LLM建议添加动词和类别")。
- en: '|    MA1\A2 | Y | N | Total |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '|    MA1\A2 | Y | N | 总计 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '|    MY | 129=66+63 | 43=15+28 | 172=81+91 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '|    MY | 129=66+63 | 43=15+28 | 172=81+91 |'
- en: '|    MN | 122=57+65 | 706=362+444 | 828=419+409 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '|    MN | 122=57+65 | 706=362+444 | 828=419+409 |'
- en: '|    MTotal | 251=123+128 | 749=377+372 | 1000=500+500 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '|    MTotal | 251=123+128 | 749=377+372 | 1000=500+500 |'
- en: 'Table 2: Annotation statistics: counts shown for the 1000 annotation decisions
    (500 from Set1, 500 from Set2). Mappings used: y $\rightarrow$ Y, r_n $\rightarrow$
    N. Counts are presented in the cells as Total-$xy$+Set2-$xy$Y, N$\}$.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：注释统计：显示1000个注释决策的计数（500来自Set1，500来自Set2）。使用的映射：y $\rightarrow$ Y，r_n $\rightarrow$
    N。计数以单元格中的Total-$xy$+Set2-$xy$Y, N$\}$呈现。
- en: '|  | IAA | Cohen’s $\kappa$ |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '|  | IAA | Cohen’s $\kappa$ |'
- en: '| --- | --- | --- |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '|   MAll | 0.83 | 0.51 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '|   MAll | 0.83 | 0.51 |'
- en: '|   MSet1 | 0.86 | 0.56 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '|   MSet1 | 0.86 | 0.56 |'
- en: '|   MSet2 | 0.81 | 0.46 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '|   MSet2 | 0.81 | 0.46 |'
- en: 'Table 3: Inter-annotator agreement and Cohen’s $\kappa$ between annotators,
    for the 500 decisions each annotated by both annotators, with the scaled values
    mapped to Y/N only.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：注释员之间的协议和Cohen’s $\kappa$值，针对每个由两个注释员注释的500个决策，缩放值仅映射到Y/N。
- en: '|  | Batch 1 (no scores) | Batch 2 (with scores) |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '|  | 批次1（无得分） | 批次2（有得分） |'
- en: '| --- | --- | --- |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '|   MA1 | 192 | 174 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '|   MA1 | 192 | 174 |'
- en: '|   MA2 | 210 | 210 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '|   MA2 | 210 | 210 |'
- en: '|   MAverage | 201 | 192 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '|   MAverage | 201 | 192 |'
- en: 'Table 4: Time of annotation by annotators A1 and A2, in minutes. Batch 1 is
    Set1 and Set2 without showing the scores assigned by the automatic classifier,
    Batch 2 shows the scores.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 表4：注释员A1和A2的注释时间，以分钟为单位。批次1为Set1和Set2，不显示自动分类器分配的得分，批次2显示得分。
- en: 5.2 Human Annotation Time
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 人工注释时间
- en: 'The annotators have been asked to record the time it took them to annotate
    the data. Each Set entailed 500 decisions, which took slightly over three hours
    on average. The detailed breakdown is shown in Tab. [4](#S5.T4 "Table 4 ‣ 5.1
    Human Annotation Statistics and IAA ‣ 5 Results ‣ Extending an Event-type Ontology:
    Adding Verbs and Classes Using Fine-tuned LLMs Suggestions").'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 注释员被要求记录他们注释数据所花费的时间。每个数据集包含500个决策，平均花费时间略超过三小时。详细的分解见表[4](#S5.T4 "表4 ‣ 5.1
    人工注释统计与IAA ‣ 5 结果 ‣ 扩展事件类型本体：使用微调的LLM建议添加动词和类别")。
- en: 5.3 Correlation between the Scores of the Automatic Classifier and the Human
    Annotation
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 自动分类器得分与人工注释之间的相关性
- en: To find if there is a relationship between the automatic scores and manually
    annotated data, we used the Pearson’s correlation (Pearson’s r) coefficient. Automatic
    scores and human annotations were found to be moderately correlated ($r(998)=.44$).
    A Spearman’s correlation was also run to determine the relationship between $1000$,
    $n=1000$).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确定自动评分与手动注释数据之间是否存在关系，我们使用了Pearson相关系数（Pearson’s r）。发现自动评分和人工注释有中等的相关性（$r(998)=.44$）。还进行了Spearman相关性分析，以确定$1000$之间的关系，$n=1000$）。
- en: 'We visualize the correlation between the automatic scores assigned to the lemma-class
    pairs and annotation decisions in Fig. [3](#S4.F3 "Figure 3 ‣ 4.2 Experiment Design
    ‣ 4 Post-processing with Manual Annotations ‣ Extending an Event-type Ontology:
    Adding Verbs and Classes Using Fine-tuned LLMs Suggestions"); human scores correspond
    to the annotation scale (3 - yes, 2 - rather_yes, 1 - rather_no and 0 - no) and
    automatic scores are bucketed (interval size: 0.05) and annotation decisions averaged
    in each bucket, effectively smoothing out the curve by reducing variance. The
    Pearson correlation between scores and human annotations averaged per bucket is
    $r(18)=.79$) and Spearman’s ranked correlation is $\rho=.76$, $p<.001$).'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在图[3](#S4.F3 "Figure 3 ‣ 4.2 Experiment Design ‣ 4 Post-processing with Manual
    Annotations ‣ Extending an Event-type Ontology: Adding Verbs and Classes Using
    Fine-tuned LLMs Suggestions")中可视化了自动分配给词条-类别对的分数与注释决定之间的相关性；人工评分对应于注释量表（3 - 是，2
    - 较是，1 - 较否和0 - 否），自动评分被分桶（间隔大小：0.05），并在每个桶中对注释决定进行平均，有效地通过减少方差来平滑曲线。每个桶中的分数和人工注释的Pearson相关系数为$r(18)=.79$，Spearman的等级相关系数为$\rho=.76$，$p<.001$。'
- en: 6 Discussion of Results
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结果讨论
- en: 'It is well known that trained annotators often create high-quality data, needed
    for many NLP applications, although their services are generally expensive.The
    experiment described here was designed to answer several questions:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 众所周知，经过培训的注释员通常能够创建高质量的数据，这对于许多NLP应用程序是必需的，尽管他们的服务通常价格昂贵。这里描述的实验旨在回答几个问题：
- en: •
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: What is the usual inter-annotator agreement for the human assignment of verbs
    to classes, using pre-annotated data?
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通常的人类注释员在将动词分配给类别时的一致性是多少，使用预注释的数据？
- en: •
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Can a heuristics be defined to indicate which pre-assigned lemma-class pairs
    the annotators can trust and to what extent?
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 是否可以定义一个启发式方法，以指示注释员可以信任的预分配词条-类别对及其程度？
- en: •
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Does the scoring mechanism, which provides scores for each of the lemma-class
    relation strength, make the annotation more efficient?
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提供每个词条-类别关系强度评分的评分机制是否提高了注释效率？
- en: •
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Is the automatic classifier for computing the relation strength between an
    unknown lemma and an existing class(es), as described in Sect. [3](#S3 "3 Generating
    Annotation Suggestions with Fine-tuned LLM Classifier ‣ Extending an Event-type
    Ontology: Adding Verbs and Classes Using Fine-tuned LLMs Suggestions"), in any
    way correlated with the human decisions made by experienced annotators?'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '如第[3](#S3 "3 Generating Annotation Suggestions with Fine-tuned LLM Classifier
    ‣ Extending an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned
    LLMs Suggestions")节中所述，用于计算未知词条与现有类别之间关系强度的自动分类器，是否与经验丰富的注释员所做的人工决策有任何相关性？'
- en: 'As seen from Sect. [5.1](#S5.SS1 "5.1 Human Annotation Statistics and IAA ‣
    5 Results ‣ Extending an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned
    LLMs Suggestions") (Tab. [3](#S5.T3 "Table 3 ‣ 5.1 Human Annotation Statistics
    and IAA ‣ 5 Results ‣ Extending an Event-type Ontology: Adding Verbs and Classes
    Using Fine-tuned LLMs Suggestions")), the inter-annotator agreement is relatively
    high (0.83 on average over the two Sets), but the Cohen’s kappa $\kappa$ is low
    (0.51 on average over the same two Sets annotated). However, the low kappa is
    caused by the highly skewed distribution of the decisions,^(21)^(21)21Almost 4:1
    - the average number of (mapped) “No” decisions is 788,5 out of 1000. the most
    of which lead to the rejection of the assignment of the lemma to the suggested
    class, caused mainly by the selection of a fixed number of five suggestions per
    lemma regardless of the score computed by the classifier. It would be possible
    - by using more pairs of annotators - to optimally select the number of suggested
    classes (i.e., most probably between 1 and 5), but it would only be relevant for
    the current number of classes in the ontology. As the ontology grows, the number
    of rejections will be different and the optimal number of classes might change.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 从第[5.1节](#S5.SS1 "5.1 人工注释统计与IAA ‣ 5 结果 ‣ 扩展事件类型本体：使用微调的LLM建议添加动词和类别")（表[3](#S5.T3
    "表3 ‣ 5.1 人工注释统计与IAA ‣ 5 结果 ‣ 扩展事件类型本体：使用微调的LLM建议添加动词和类别")）中可以看到，标注者之间的一致性相对较高（两个数据集的平均值为0.83），但Cohen的kappa值$\kappa$较低（两个相同数据集的平均值为0.51）。然而，低kappa值是由于决策分布严重不均匀造成的，^(21)^(21)21几乎是4:1——“不”决策的平均数量为788.5，占1000中的大部分，这些决策主要导致拒绝将词条分配到建议的类别中，这主要是由于每个词条无论分类器计算的分数如何，都只选择了固定数量的五个建议。通过使用更多的标注者对的配对，可以优化建议类别的数量（即，很可能在1到5之间），但这只对当前本体中的类别数量相关。随着本体的增长，拒绝的数量会有所不同，最佳的类别数量也可能会发生变化。
- en: 'For the size of the ontology on which it has been tested, the threshold separating
    the Yes/No decision (with the highest uncertainty being around the average of
    0-3, i.e., 1.5) seems to be around 0.3 (see Fig. [3](#S4.F3 "Figure 3 ‣ 4.2 Experiment
    Design ‣ 4 Post-processing with Manual Annotations ‣ Extending an Event-type Ontology:
    Adding Verbs and Classes Using Fine-tuned LLMs Suggestions")). However, due to
    the linearity of the correlation (which by itself is a positive result for the
    classifier–see below), it would still be necessary to provide careful manual inspection
    results on both sides of the threshold. The same holds for setting any thresholds
    at the low or high ends of the classifier score scale. In terms of annotation
    efficiency (providing scores to the annotators vs. not providing them), the result
    is largely negative. A small speedup has been observed only for A1, with A2 consuming
    the same time for both Sets. The absolute time as recorded by the annotators per
    lemma (i.e., 5 times the single decisions time, which was $366\times 60\div 1000\approx
    22$ sec. for A2) is about two minutes. This is in fact a positive finding which
    means that the whole set of pre-classified lemmas, as processed by the classifier
    (3073 lemmas) would be finished within approx. 6000 minutes (100 hours) per annotator,
    i.e., within 200 hours with double annotation, plus adjudication time.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 对于测试过的本体的大小，分隔“是/否”决策的阈值（最高不确定性在0-3的平均值附近，即1.5）似乎约为0.3（见图[3](#S4.F3 "图3 ‣ 4.2
    实验设计 ‣ 4 后处理与人工注释 ‣ 扩展事件类型本体：使用微调的LLM建议添加动词和类别")）。然而，由于相关性的线性（这本身对分类器来说是一个积极结果——见下文），仍然需要对阈值两侧的结果进行仔细的人工检查。设置分类器分数范围的低端或高端的任何阈值也适用相同的原则。在注释效率方面（给标注者提供分数与不提供分数的对比），结果大体上是负面的。只有A1观察到了一小部分加速，而A2对两个数据集消耗了相同的时间。标注者记录的每个词条的绝对时间（即，单次决策时间的5倍，A2的时间为$366\times
    60\div 1000\approx 22$秒）大约为两分钟。实际上这是一个积极的发现，这意味着分类器处理的整个预分类词条集（3073个词条）将在每个标注者大约6000分钟（100小时）内完成，即双重标注的情况下为200小时，加上裁决时间。
- en: 'Finally, the correlation between the automatic classifier and the human annotation
    is very strong. Of course, the bucketing to the 0.05 interval improves the correlation
    (see Sect. [5.3](#S5.SS3 "5.3 Correlation between the Scores of the Automatic
    Classifier and the Human Annotation ‣ 5 Results ‣ Extending an Event-type Ontology:
    Adding Verbs and Classes Using Fine-tuned LLMs Suggestions")), but in any case,
    it seems that the classifier is able to assign the score denoting the strength
    of affiliation of the unknown lemma to a class with high correlation to the human
    annotation decisions.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '最后，自动分类器与人工标注之间的相关性非常强。当然，将评分桶化为0.05区间可以提高相关性（见 Sect. [5.3](#S5.SS3 "5.3 Correlation
    between the Scores of the Automatic Classifier and the Human Annotation ‣ 5 Results
    ‣ Extending an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned
    LLMs Suggestions")），但无论如何，分类器似乎能够为未知词分配表示归属强度的评分，这与人工标注决策具有高度相关性。'
- en: 7 Conclusions and Future Work
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 结论与未来工作
- en: 'As discussed in the previous section (Sect. [6](#S6 "6 Discussion of Results
    ‣ Extending an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned
    LLMs Suggestions")), the strongest result achieved in this study is the correlation
    between the classifier scoring buckets and the human decisions (Fig. [3](#S4.F3
    "Figure 3 ‣ 4.2 Experiment Design ‣ 4 Post-processing with Manual Annotations
    ‣ Extending an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned
    LLMs Suggestions"), Sect. [5.3](#S5.SS3 "5.3 Correlation between the Scores of
    the Automatic Classifier and the Human Annotation ‣ 5 Results ‣ Extending an Event-type
    Ontology: Adding Verbs and Classes Using Fine-tuned LLMs Suggestions")). While
    the scores themselves, when presented to the annotators, do not seem to bring
    higher efficiency, the selection of the classes and their presentation to the
    annotators (Sect. [3](#S3 "3 Generating Annotation Suggestions with Fine-tuned
    LLM Classifier ‣ Extending an Event-type Ontology: Adding Verbs and Classes Using
    Fine-tuned LLMs Suggestions"), Sect. [4.1](#S4.SS1 "4.1 Input Data Preparation
    ‣ 4 Post-processing with Manual Annotations ‣ Extending an Event-type Ontology:
    Adding Verbs and Classes Using Fine-tuned LLMs Suggestions")) result in a reasonable
    time for the annotation of several thousand previously unseen (unassigned lemmas)
    to the ontology. Finally, there is no strong heuristics (for the score thresholds)
    that would allow to assign any unseen words to existing classes automatically
    – a human post-inspection and annotation is needed across the whole (or almost
    whole) range of scores as produced by the classifier, given the linear correlation.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '正如前一节（Sect. [6](#S6 "6 Discussion of Results ‣ Extending an Event-type Ontology:
    Adding Verbs and Classes Using Fine-tuned LLMs Suggestions")）中讨论的，本研究中取得的最强结果是分类器评分桶与人类决策之间的相关性（Fig. [3](#S4.F3
    "Figure 3 ‣ 4.2 Experiment Design ‣ 4 Post-processing with Manual Annotations
    ‣ Extending an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned
    LLMs Suggestions")，Sect. [5.3](#S5.SS3 "5.3 Correlation between the Scores of
    the Automatic Classifier and the Human Annotation ‣ 5 Results ‣ Extending an Event-type
    Ontology: Adding Verbs and Classes Using Fine-tuned LLMs Suggestions")）。虽然这些评分本身在呈现给标注员时似乎未能提高效率，但类别的选择及其呈现（Sect. [3](#S3
    "3 Generating Annotation Suggestions with Fine-tuned LLM Classifier ‣ Extending
    an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned LLMs Suggestions")，Sect. [4.1](#S4.SS1
    "4.1 Input Data Preparation ‣ 4 Post-processing with Manual Annotations ‣ Extending
    an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned LLMs Suggestions")）使得对几千个以前未见过（未分配词条）的本体进行标注的时间合理。最后，没有强有力的启发式方法（用于评分阈值），能够自动将任何未见过的词分配到现有类别中——需要对分类器生成的整个（或几乎整个）评分范围进行人工后检验和标注。'
- en: In the future, we plan to repeat the experiment for a larger ontology (i.e.,
    test the effort needed for sustainable development and maintenance for such an
    event-type ontology when it reaches high coverage), possibly with larger LMs or
    with some additional fine tuning given the large(r) coverage at such future time.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 未来，我们计划对更大的本体重复实验（即测试当事件类型本体达到高覆盖度时，所需的可持续发展和维护的工作量），可能会使用更大的语言模型或根据未来的更大覆盖度进行一些额外的微调。
- en: Limitations
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 限制
- en: We advocate for a moderate and restrained usage of automatic guiding methods
    and we must advise caution to take the automatic output with a grain of salt,
    both qualitatively and quantitatively. First, the classifier predictions can fall
    far from gold labels and should not be considered as such. Second, although measures
    have been taken to mitigate the out-of-distribution classification problem, one
    should be aware of the fact that by the very nature of the problem, which is annotation
    of completely new, possibly out-of-distribution data, the classification predictions
    are not to be trusted indiscriminately and should subsequently be approved by
    the annotators. The annotators should be instructed to consider the suggestions
    as election votes. Furthermore, we should refrain from overly automating the entire
    annotation process so as to achieve high alignment with the machine learning suggestions,
    which might lead to trivial and unimaginative annotations from the linguistic
    perspective. Finally, exhausting the informativeness of the pre-trained (albeit
    fine-tuned) model might prevent further learning from the annotated data.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们主张对自动指导方法的使用保持适度和克制，并且我们必须提醒注意，要对自动输出持保留态度，无论是定性还是定量。首先，分类器的预测可能与真实标签相差甚远，不应被视为真实标签。其次，尽管已经采取措施来缓解分布外分类问题，但应注意，由于问题的本质，即标注完全新的、可能是分布外的数据，分类预测不能被盲目相信，且应由标注员进行批准。标注员应被指导将建议视作选票。此外，我们应避免过度自动化整个标注过程，以实现与机器学习建议的高度一致，这可能会从语言学角度导致平庸和缺乏创意的标注。最后，耗尽预训练（尽管是微调过的）模型的信息量可能会阻碍从标注数据中进一步学习。
- en: 'Another limitation of the results, or the interpretation of the results, is
    the fact that the model is trained on an actual state of the ontology. It means
    that in fact the classifier would have to be retrained after adding a single new
    class or even a new lemma to an existing class; while in practice it would be
    OK to process several lemmas at once, it is still a limitation given the non-negligible
    training and prediction time (20 hours on a single GPU) which cannot be parallelized
    (see Sect. [3](#S3 "3 Generating Annotation Suggestions with Fine-tuned LLM Classifier
    ‣ Extending an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned
    LLMs Suggestions")).'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 结果的另一个限制，或对结果的解释，是模型是基于本体的实际状态进行训练的。这意味着实际上在向现有类别中添加一个新的类别或新的词根后，分类器必须重新训练；虽然在实际操作中可以一次处理多个词根，但鉴于不可忽视的训练和预测时间（在单个GPU上需要20小时），这仍然是一个限制，且无法并行化（见第[3](#S3
    "3 生成带微调的LLM分类器的注释建议 ‣ 扩展事件类型本体：使用微调LLM建议添加动词和类别")节）。
- en: In addition, the correlation might decrease and the thresholds shift as the
    size (and thus coverage) by the ontology grows, since the unseen lemmas will be
    increasingly rare, with possibly less data available in the LM to reliably estimate
    the scores. Conversely, for ontologies with much smaller coverage (e.g., for ontologies
    the development of which has just started) the same shifts in correlation and
    thresholds are likely.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，随着本体的规模（即覆盖率）增长，相关性可能会降低，阈值也可能发生变化，因为未见过的词根将变得越来越稀少，可能在语言模型中可用的数据也会减少，从而无法可靠地估计分数。相反，对于覆盖范围较小的本体（例如刚刚开始开发的本体），相关性和阈值可能会发生相同的变化。
- en: Finally, the whole experiment has been performed on Czech due to the lower coverage
    of the ontology than for English, and also in order to explore a morphologically
    rich language with a high form-to-lemma ratio. Results for other languages might
    differ.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，由于捷克语的本体覆盖率低于英语，并且为了探索一种形态丰富、形式与词根比例高的语言，整个实验已在捷克语上进行。其他语言的结果可能有所不同。
- en: Ethics Statement
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 伦理声明
- en: 'The human subjects used in this study have been experienced, trained annotators
    who have been in personal contact with the authors, and who have been recruited
    by a call specifically suited for the experiment and study presented here. The
    call has been sent to all trained annotators already working with the authors,
    and volunteers have been asked to respond, on a first-come first-chosen basis.
    The pay has corresponded to the standard pay for similar annotation tasks taking
    also the relatively short notice into consideration (for the numbers, see Sect. [4.2](#S4.SS2
    "4.2 Experiment Design ‣ 4 Post-processing with Manual Annotations ‣ Extending
    an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned LLMs Suggestions")).
    Both annotators were males; this is a possible shortcoming, but there were no
    female volunteers and from the previous cooperation (with a mixed team of female
    and male annotators), no differences in the annotation results have been observed.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究所使用的人体受试者都是有经验的、经过培训的标注员，他们与作者有过面对面的联系，并通过专门针对本实验和研究的招聘通知招募。招聘通知已发送给所有与作者合作过的训练有素的标注员，志愿者按先到先得的原则被要求响应。报酬符合类似标注任务的标准，也考虑了相对较短的通知时间（具体数据见第[4.2节](#S4.SS2
    "4.2 实验设计 ‣ 4 手动标注后处理 ‣ 扩展事件类型本体：使用微调LLM建议添加动词和类别")）。两位标注员都是男性；这可能是一个不足之处，但没有女性志愿者，并且从之前的合作（有混合性别标注员的团队）中，没有观察到标注结果上的差异。
- en: No personal information has been among the lemmas extracted and used for the
    preselection. The data for the LLM might have contained it, but it would not show
    because the experiment and the ontology is currently limited to common verbs which
    do not describe any personal names or other personal information.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在提取和用于预选的词目中没有包含个人信息。虽然LLM的数据可能包含这些信息，但实验和本体目前仅限于描述普通动词的内容，不涉及任何个人姓名或其他个人信息。
- en: Acknowledgements
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: The work described herein has been supported by the Grant Agency of the Czech
    Republic under the EXPRO program as project “LUSyD” (project No. GX20-16819X)
    and uses resources hosted by the LINDAT/CLARIAH-CZ Research Infrastructure (projects
    LM2018101 and LM2023062, supported by the Ministry of Education, Youth and Sports
    of the Czech Republic).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究所述工作得到了捷克共和国资助机构在EXPRO计划下的项目“LUSyD”（项目编号GX20-16819X）的支持，并使用了由LINDAT/CLARIAH-CZ研究基础设施（项目LM2018101和LM2023062，受捷克共和国教育、青年和体育部资助）托管的资源。
- en: We would like to thank the annotators Petr Kujal and Tomáš Razím for their valuable
    work and invaluable input, as well as the three anonymous reviewers for their
    insightful comments.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要感谢标注员 Petr Kujal 和 Tomáš Razím 他们宝贵的工作和无价的贡献，以及三位匿名审稿人的有见地的评论。
- en: References
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Aina et al. (2019) Laura Aina, Kristina Gulordava, and Gemma Boleda. 2019.
    [Putting words in context: LSTM language models and lexical ambiguity](https://doi.org/10.18653/v1/P19-1324).
    In *Proceedings of the 57th Annual Meeting of the Association for Computational
    Linguistics*, pages 3342–3348, Florence, Italy. Association for Computational
    Linguistics.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Aina 等人（2019）Laura Aina, Kristina Gulordava 和 Gemma Boleda. 2019. [将词语置于上下文中：LSTM
    语言模型与词汇歧义](https://doi.org/10.18653/v1/P19-1324)。在 *第57届计算语言学协会年会论文集* 中，第3342–3348页，意大利佛罗伦萨。计算语言学协会。
- en: Brown et al. (1992) Peter F. Brown, Vincent J. Della Pietra, Peter V. deSouza,
    Jenifer C. Lai, and Robert L. Mercer. 1992. [Class-based n-gram models of natural
    language](https://aclanthology.org/J92-4003). *Computational Linguistics*, 18(4):467–480.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown 等人（1992）Peter F. Brown, Vincent J. Della Pietra, Peter V. deSouza, Jenifer
    C. Lai 和 Robert L. Mercer. 1992. [基于类别的自然语言 n-gram 模型](https://aclanthology.org/J92-4003)。*计算语言学*，18(4):467–480。
- en: Chung et al. (2021) Hyung Won Chung, Thibault Fevry, Henry Tsai, Melvin Johnson,
    and Sebastian Ruder. 2021. [Rethinking embedding coupling in pre-trained language
    models](https://openreview.net/forum?id=xpFFI_NtgpW). In *International Conference
    on Learning Representations*.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chung 等人（2021）Hyung Won Chung, Thibault Fevry, Henry Tsai, Melvin Johnson 和
    Sebastian Ruder. 2021. [重新思考预训练语言模型中的嵌入耦合](https://openreview.net/forum?id=xpFFI_NtgpW)。在
    *国际学习表征会议* 上。
- en: Cruse (2000) Alan Cruse. 2000. *Meaning in Language. An Introduction to Semantics
    and Pragmatics*. Oxford University Press. Oxford, UK.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cruse（2000）Alan Cruse. 2000. *语言中的意义：语义学与语用学导论*。牛津大学出版社，牛津，英国。
- en: Cruse (1986) D.Alan Cruse. 1986. *Lexical Semantics*. Cambridge University Press,
    UK.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cruse（1986）D. Alan Cruse. 1986. *词汇语义学*。剑桥大学出版社，英国。
- en: Fernández-Alcaina et al. (2023) Cristina Fernández-Alcaina, Eva Fučíková, and
    Zdeňka Urešová. 2023. Spanish verbal synonyms in the synsemclass ontology. In
    *Proceedings of the 21st International Workshop on Treebanks and Linguistic Theories*,
    pages 10–20, Washington, D.C., USA. Association for Computational Linguistics,
    Association for Computational Linguistics.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fernández-Alcaina 等（2023）Cristina Fernández-Alcaina、Eva Fučíková 和 Zdeňka Urešová。2023年。西班牙语动词同义词在
    synsemclass 本体中的应用。见于 *第21届国际树库和语言理论研讨会论文集*，第10–20页，美国华盛顿特区。计算语言学协会，计算语言学协会。
- en: Hnátková et al. (2014) Milena Hnátková, Michal Křen, Pavel Procházka, and Hana
    Skoumalová. 2014. [The SYN-series corpora of written Czech](http://www.lrec-conf.org/proceedings/lrec2014/pdf/294_Paper.pdf).
    In *Proceedings of the Ninth International Conference on Language Resources and
    Evaluation (LREC’14)*, pages 160–164, Reykjavik, Iceland. European Language Resources
    Association (ELRA).
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hnátková 等（2014）Milena Hnátková、Michal Křen、Pavel Procházka 和 Hana Skoumalová。2014年。[捷克语书面语
    SYN 系列语料库](http://www.lrec-conf.org/proceedings/lrec2014/pdf/294_Paper.pdf)。见于
    *第九届国际语言资源与评估会议（LREC’14）论文集*，第160–164页，冰岛雷克雅未克。欧洲语言资源协会（ELRA）。
- en: Jackson (1988) Howard Jackson. 1988. *Words and Their Meaning*. Routledge.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jackson（1988）Howard Jackson。1988年。*词汇及其意义*。劳特利奇出版社。
- en: 'Kingma and Ba (2015) Diederik P. Kingma and Jimmy Ba. 2015. [Adam: A method
    for stochastic optimization](http://arxiv.org/abs/1412.6980). In *ICLR (Poster),
    CoRR abs/1412.6980*.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kingma 和 Ba（2015）Diederik P. Kingma 和 Jimmy Ba。2015年。[Adam: 一种随机优化方法](http://arxiv.org/abs/1412.6980)。见于
    *ICLR（海报），CoRR abs/1412.6980*。'
- en: 'Křen et al. (2016) Michal Křen, Václav Cvrček, Tomáš Čapka, Anna Čermáková,
    Milena Hnátková, Lucie Chlumská, Tomáš Jelínek, Dominika Kováříková, Vladimír
    Petkevič, Pavel Procházka, Hana Skoumalová, Michal Škrabal, Petr Truneček, Pavel
    Vondřička, and Adrian Zasina. 2016. [SYN v4: large corpus of written czech](http://hdl.handle.net/11234/1-1846).
    LINDAT/CLARIAH-CZ digital library at the Institute of Formal and Applied Linguistics
    (ÚFAL), Faculty of Mathematics and Physics, Charles University.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Křen 等（2016）Michal Křen、Václav Cvrček、Tomáš Čapka、Anna Čermáková、Milena Hnátková、Lucie
    Chlumská、Tomáš Jelínek、Dominika Kováříková、Vladimír Petkevič、Pavel Procházka、Hana
    Skoumalová、Michal Škrabal、Petr Truneček、Pavel Vondřička 和 Adrian Zasina。2016年。[SYN
    v4: 大型捷克语书面语语料库](http://hdl.handle.net/11234/1-1846)。查尔斯大学数学与物理学院形式与应用语言学研究所（ÚFAL）LINDAT/CLARIAH-CZ
    数字图书馆。'
- en: Lin et al. (2018) Tsung-Yi Lin, Priyal Goyal, Ross Girshick, Kaiming He, and
    Piotr Dollar. 2018. [Focal loss for dense object detection](https://doi.org/10.1109/TPAMI.2018.2858826).
    *IEEE Transactions on Pattern Analysis and Machine Intelligence*, PP:1–1.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin 等（2018）Tsung-Yi Lin、Priyal Goyal、Ross Girshick、Kaiming He 和 Piotr Dollar。2018年。[用于密集对象检测的焦点损失](https://doi.org/10.1109/TPAMI.2018.2858826)。*IEEE模式分析与机器智能学报*，PP:1–1。
- en: Lopez de Lacalle et al. (2016) Maddalen Lopez de Lacalle, Egoitz Laparra, Itziar
    Aldabe, and German Rigau. 2016. [A multilingual predicate matrix](https://aclanthology.org/L16-1423).
    In *Proceedings of the Tenth International Conference on Language Resources and
    Evaluation (LREC’16)*, pages 2662–2668, Portorož, Slovenia. European Language
    Resources Association (ELRA).
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lopez de Lacalle 等（2016）Maddalen Lopez de Lacalle、Egoitz Laparra、Itziar Aldabe
    和 German Rigau。2016年。[多语言谓词矩阵](https://aclanthology.org/L16-1423)。见于 *第十届国际语言资源与评估会议（LREC’16）论文集*，第2662–2668页，斯洛文尼亚波尔托罗日。欧洲语言资源协会（ELRA）。
- en: 'Loshchilov and Hutter (2017) Ilya Loshchilov and Frank Hutter. 2017. [SGDR:
    Stochastic gradient descent with warm restarts](https://openreview.net/forum?id=Skq89Scxx).
    In *International Conference on Learning Representations*.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Loshchilov 和 Hutter（2017）Ilya Loshchilov 和 Frank Hutter。2017年。[SGDR: 带热启动的随机梯度下降](https://openreview.net/forum?id=Skq89Scxx)。见于
    *国际学习表征会议*。'
- en: Lyons (1968) John Lyons. 1968. *Introduction to Theoretical Linguistics*. Cambridge
    University Press.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lyons（1968）John Lyons。1968年。*理论语言学导论*。剑桥大学出版社。
- en: Lyons (1995) John Lyons. 1995. *Linguistic Semantics*. Cambridge University
    Press.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lyons（1995）John Lyons。1995年。*语言语义学*。剑桥大学出版社。
- en: McCrae et al. (2014) John P. McCrae, Christiane Fellbaum, and Philipp Cimiano.
    2014. Publishing and Linking WordNet using lemon and RDF. In *Proceedings of the
    3rd Workshop on Linked Data in Linguistics, colocated with LREC 2014*, Reykjavik,
    Iceland.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: McCrae 等（2014）John P. McCrae、Christiane Fellbaum 和 Philipp Cimiano。2014年。使用
    lemon 和 RDF 发布和链接 WordNet。见于 *第三届语言学中链接数据研讨会论文集，与 LREC 2014 同期举办*，冰岛雷克雅未克。
- en: Urešová et al. (2018a) Zdeňka Urešová, Eva Fučíková, Eva Hajičová, and Jan Hajič.
    2018a. Creating a Verb Synonym Lexicon Based on a Parallel Corpus. In *Proceedings
    of the 11th International Conference on Language Resources and Evaluation (LREC’18)*,
    Miyazaki, Japan. European Language Resources Association (ELRA).
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Urešová等（2018a）Zdeňka Urešová、Eva Fučíková、Eva Hajičová和Jan Hajič。2018a。基于平行语料库创建动词同义词词典。见于*第11届国际语言资源与评估会议（LREC’18）论文集*，日本宫崎。欧洲语言资源协会（ELRA）。
- en: Urešová et al. (2018b) Zdeňka Urešová, Eva Fučíková, Eva Hajičová, and Jan Hajič.
    2018b. A Cross-lingual synonym classes lexicon. *Prace Filologiczne*, LXXII:405–418.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Urešová等（2018b）Zdeňka Urešová、Eva Fučíková、Eva Hajičová和Jan Hajič。2018b。跨语言同义词类别词典。*Prace
    Filologiczne*，LXXII:405–418。
- en: 'Urešová et al. (2018c) Zdeňka Urešová, Eva Fučíková, Eva Hajičová, and Jan
    Hajič. 2018c. Defining verbal synonyms: between syntax and semantics. In *Proceedings
    of the 17th International Workshop on Treebanks and Linguistic Theories (TLT 2018),
    Vol. 155*, Linköping Electronic Conference Proceedings, pages 75–90, Linköping,
    Sweden. Universitetet i Oslo, Linköping University Electronic Press.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Urešová等（2018c）Zdeňka Urešová、Eva Fučíková、Eva Hajičová和Jan Hajič。2018c。定义动词同义词：在句法和语义之间。见于*第17届树库和语言理论国际研讨会（TLT
    2018），第155卷*，林雪平电子会议论文集，第75–90页，瑞典林雪平。奥斯陆大学，林雪平大学电子出版社。
- en: Urešová et al. (2019) Zdeňka Urešová, Eva Fučíková, Eva Hajičová, and Jan Hajič.
    2019. Meaning and Semantic Roles in CzEngClass Lexicon. *Jazykovedný časopis /
    Journal of Linguistics*, 70(2):403–411.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Urešová等（2019）Zdeňka Urešová、Eva Fučíková、Eva Hajičová和Jan Hajič。2019。CzEngClass词典中的意义与语义角色。*Jazykovedný
    časopis / Journal of Linguistics*，70(2):403–411。
- en: Uresova et al. (2022) Zdenka Uresova, Karolina Zaczynska, Peter Bourgonje, Eva
    Fučíková, Georg Rehm, and Jan Hajic. 2022. [Making a semantic event-type ontology
    multilingual](https://aclanthology.org/2022.lrec-1.142). In *Proceedings of the
    Thirteenth Language Resources and Evaluation Conference*, pages 1332–1343, Marseille,
    France. European Language Resources Association.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Uresova等（2022）Zdenka Uresova、Karolina Zaczynska、Peter Bourgonje、Eva Fučíková、Georg
    Rehm和Jan Hajic。2022年。[使语义事件类型本体具备多语言能力](https://aclanthology.org/2022.lrec-1.142)。见于*第十三届语言资源与评估会议论文集*，第1332–1343页，法国马赛。欧洲语言资源协会。
- en: Appendices
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录
- en: Classifier and Annotation Results
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类器和注释结果
- en: We are providing Supplemental material with the raw classifier file and the
    human annotation results. The open-source code and the data itself are provided
    at GitHub ([https://github.com/strakova/synsemclass_ml](https://github.com/strakova/synsemclass_ml)).
    Here, technical description of the supplemental material is provided on top of
    what has been mentioned in the paper.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供了包含原始分类器文件和人工注释结果的补充材料。开源代码和数据本身可在GitHub上获取（[https://github.com/strakova/synsemclass_ml](https://github.com/strakova/synsemclass_ml)）。这里提供了补充材料的技术描述，内容超出了论文中提到的部分。
- en: Classifier output
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分类器输出
- en: The raw output of the classifier, with the 3073 previously unseen (unassigned)
    lemmas and their classification scores to 10 closest classes, is attached in the
    Supplemental material file (file all_buckets_2753494.txt).
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器的原始输出，包括3073个之前未见过（未分配）词元及其分类分数和10个最接近类别的分数，附在补充材料文件（文件名：all_buckets_2753494.txt）中。
- en: 'The file contents is structured as follows (each lemma and classifier scores
    are on a single line):'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 文件内容的结构如下（每个词元及其分类分数占一行）：
- en: lemma freq-in-data max-score suggested-class-1 score-class-1 ... suggested-class-10
    score-class-10
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: lemma freq-in-data max-score suggested-class-1 score-class-1 ... suggested-class-10
    score-class-10
- en: where
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: lemma
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: lemma
- en: is the lemma which has been classified to all the available classes in SynSemClass
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 是已被分类到SynSemClass中所有可用类别的词元
- en: freq-in-data
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: freq-in-data
- en: is the frequency of the lemma in the dataset used for building the LM
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 是在构建语言模型时使用的数据集中词元的频率
- en: max-score
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: max-score
- en: is the maximum score (score of the first class in the list)
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 是最高分数（列表中第一个类别的分数）
- en: suggested-class-n
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: suggested-class-n
- en: is the ID and name (& Czech sense ID) of the n-th best class assigned to the
    lemma by the classifier
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 是分类器分配给词元的第n个最佳类别的ID和名称（及捷克语意义ID）
- en: score-class-n
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: score-class-n
- en: is the score assigned to the (lemma,suggested-class-n) pair.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 是分配给（词元，suggested-class-n）对的分数。
- en: Annotation Results
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注释结果
- en: The annotation results are presented as four Excel Spreadsheets, named law-Am-n.xlsx,
    where m is the annotator ID and n is the batch number (i.e., the lemmas and classes
    are identical for A1-1 and A2-2 and for A1-2 and A2-1, except for the presence
    of scores and differing also of course in the assigned y/r_y/r_n/n labels by the
    annotators).
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 注释结果以四个 Excel 电子表格的形式呈现，命名为 law-Am-n.xlsx，其中 m 是标注员 ID，n 是批次号（即，A1-1 和 A2-2
    以及 A1-2 和 A2-1 的词元和类别是相同的，除了存在分数外，并且标注员分配的 y/r_y/r_n/n 标签当然也有所不同）。
- en: 'Each Excel file has 100 content lines (100 lemmas and 5 best classes for each
    as classified by the pre-annotation tool):'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 Excel 文件包含 100 行内容（100 个词元及其通过预标注工具分类的 5 个最佳类别）：
- en: Lemma
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: Lemma
- en: is the lemma being classified
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 是被分类的词元
- en: Freq
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: Freq
- en: is the (informative-only) frequency of the lemma in the training text
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 是词元在训练文本中的（仅供参考的）频率
- en: Cn?
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: Cn?
- en: is the column where the annotators recorded their decisions
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 是标注员记录其决策的列
- en: Classn
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: Classn
- en: is the ID of the class (clickable)
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 是类别的 ID（可点击）
- en: Scorn
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Scorn
- en: is the score of the lemma-class affiliation by the classifier (in …-2.xlsx files
    only)
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 是分类器对词元-类别归属的评分（仅在 …-2.xlsx 文件中出现）
- en: AnnotatorComment
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: AnnotatorComment
- en: is an optional annotator’s comment.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 是可选的标注员评论。
