- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:40:17'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:40:17
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Stochastic Parrots Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune
    and Hard to Detect with other LLMs'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机鹦鹉 寻找随机鹦鹉：LLMs易于微调且难以用其他LLMs检测
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2304.08968](https://ar5iv.labs.arxiv.org/html/2304.08968)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2304.08968](https://ar5iv.labs.arxiv.org/html/2304.08968)
- en: '¹¹institutetext: IC School EPFL, Switzerland'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ¹¹机构文本：瑞士EPFL IC School
- en: '¹¹email: {firstname.name}@epfl.ch ²²institutetext: Now at HES-SO Valais-Wallis,
    Switzerland'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ¹¹电子邮件：{firstname.name}@epfl.ch ²²机构文本：现在在瑞士HES-SO Valais-Wallis
- en: '²²email: {firstname.name}@hevs.ch'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ²²电子邮件：{firstname.name}@hevs.ch
- en: Da Silva Gameiro Henrique 11    Andrei Kucharavy Contact author11 2 2    Rachid
    Guerraoui 11
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Da Silva Gameiro Henrique 11    Andrei Kucharavy 联系作者11 2 2    Rachid Guerraoui
    11
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: The self-attention revolution allowed generative language models to scale and
    achieve increasingly impressive abilities. Such models - commonly referred to
    as Large Language Models (LLMs) - have recently gained prominence with the general
    public, thanks to conversational fine-tuning, putting their behavior in line with
    public expectations regarding AI. This prominence amplified prior concerns regarding
    the misuse of LLMs and led to the emergence of numerous tools to detect LLMs in
    the wild.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 自注意力革命使生成语言模型能够扩展并取得越来越令人印象深刻的能力。这些模型——通常称为大型语言模型（LLMs）——由于对话微调，最近在公众中获得了知名度，使其行为符合公众对AI的期望。这一知名度放大了对LLMs误用的担忧，并导致了众多工具的出现，用于检测现实中的LLMs。
- en: Unfortunately, most such tools are critically flawed. While major publications
    in the LLM detectability field suggested that LLMs were easy to detect with fine-tuned
    autoencoders, the limitations of their results are easy to overlook. Specifically,
    they assumed publicly available generative models without fine-tunes or non-trivial
    prompts. While the importance of these assumptions has been demonstrated, until
    now, it remained unclear how well such detection could be countered.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，大多数此类工具存在严重缺陷。虽然LLM可检测性领域的主要出版物建议通过微调的自编码器可以轻松检测LLMs，但这些结果的局限性很容易被忽视。具体而言，他们假设了未经过微调或无非平凡提示的公开生成模型。尽管这些假设的重要性已被证明，但直到现在，如何有效反击这种检测仍然不清楚。
- en: Here, we show that an attacker with access to such detectors’ reference human
    texts and output not only evades detection but can fully frustrate the detector
    training - with a reasonable budget and all its outputs labeled as such. Achieving
    it required combining common "reinforcement from critic" loss function modification
    and AdamW optimizer, which led to surprisingly good fine-tuning generalization.
    Finally, we warn against the temptation to transpose the conclusions obtained
    in RNN-driven text GANs to LLMs due to their better representative ability.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们展示了一个攻击者通过访问这种检测器的参考人工文本和输出，不仅能够规避检测，还可以完全挫败检测器训练——只需合理的预算，并将其所有输出标记为这种方式。实现这一点需要结合常见的“来自评论员的强化”损失函数修改和AdamW优化器，这导致了令人惊讶的良好微调泛化。最后，我们警告不要将RNN驱动的文本GANs中获得的结论转移到LLMs上，因为LLMs具有更好的代表能力。
- en: These results have critical implications for the detection and prevention of
    malicious use of generative language models, and we hope they will aid the designers
    of generative models and detectors.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果对生成语言模型的检测和防止恶意使用具有关键意义，我们希望它们能帮助生成模型和检测器的设计者。
- en: 'Keywords:'
  id: totrans-15
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Large Language Models NLP Generative ML Generative ML Text GANs
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型 NLP 生成式 ML 生成式 ML 文本 GANs
- en: 1 Introduction
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Ever since the introduction of the Transformer modular self-attention architecture
    [[62](#bib.bib62)], the training parallelization this architecture allowed led
    to a continuous scaling of models - be it in the number of parameters, computational
    resources invested into training them, and training datasets beyond what was previously
    imaginable [[53](#bib.bib53)]. Earning them the name of Large Language Models
    - LLMs, such architectures are ubiquitous in modern NLP ML. Be it GPT family optimized
    for the text generation [[50](#bib.bib50), [51](#bib.bib51), [11](#bib.bib11),
    [44](#bib.bib44)], BERT/RoBERTa optimized for gap-filling and classification [[16](#bib.bib16),
    [36](#bib.bib36)], or T5 [[52](#bib.bib52)] optimized for translation-like generation,
    LLMs successfully scaled across more than four orders of magnitude in parameter
    and training dataset size, all while continuously improving in their primary task.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 自从引入Transformer模块化自注意力架构[[62](#bib.bib62)]以来，这一架构允许的训练并行化导致模型规模的持续扩展——无论是参数数量、投入的计算资源，还是训练数据集，都超出了之前的想象[[53](#bib.bib53)]。这种架构因此被称为大语言模型——LLMs，它们在现代自然语言处理（NLP）机器学习（ML）中随处可见。无论是针对文本生成优化的GPT家族[[50](#bib.bib50),
    [51](#bib.bib51), [11](#bib.bib11), [44](#bib.bib44)]，还是针对填补空白和分类优化的BERT/RoBERTa[[16](#bib.bib16),
    [36](#bib.bib36)]，或是针对翻译生成优化的T5[[52](#bib.bib52)]，LLMs在参数和训练数据集规模上成功扩展了四个数量级，同时在其主要任务中持续改进。
- en: Unexpectedly, in addition to continuously improving in the task they were trained
    for, LLMs also underwent a qualitative transition in their capabilities, unlocking
    unexpected and seemingly unrelated capabilities. Learning basic arithmetic [[11](#bib.bib11)];
    generating valid Python programs from natural language requirements [[2](#bib.bib2)];
    predicting recidivism better than specialized models and generating unprompted
    hate speech [[20](#bib.bib20)]; - all were achieved without any further model
    modification, through prompt choice alone.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 出乎意料的是，除了在训练任务上不断改进，LLMs还经历了能力上的质变，解锁了意想不到且看似无关的能力。学习基本算术[[11](#bib.bib11)]；根据自然语言需求生成有效的Python程序[[2](#bib.bib2)]；比专业模型更好地预测再犯率，并生成未经提示的仇恨言论[[20](#bib.bib20)]；——这些都在没有进一步修改模型的情况下，通过仅仅选择提示完成。
- en: Perhaps the most impressive achievement of LLMs was their ability to generate
    natural language so well that some LLMs could not be distinguished from humans
    in most settings. While GPT-2 was already becoming good at this [[30](#bib.bib30)],
    it was GPT-3’s ability to run popular wellness advice blogs [[25](#bib.bib25)]
    and write newspaper articles about itself [[24](#bib.bib24)] that led to wide-reaching
    concerns about the detectability of LLM outputs. The situation got only worse
    with the release into open access of conversationally fine-tuned LLMs [[45](#bib.bib45)],
    making LLMs accessible and easy to use to the general public, and with the augmentation
    of LLMs with auxiliary capabilities, such as information retrieval, calculator
    and image analysis [[57](#bib.bib57), [61](#bib.bib61), [44](#bib.bib44)].
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 也许LLMs最令人印象深刻的成就就是它们生成自然语言的能力如此出色，以至于一些LLMs在大多数设置中无法与人类区分开。虽然GPT-2已经在这方面表现良好[[30](#bib.bib30)]，但正是GPT-3能够运行流行的健康建议博客[[25](#bib.bib25)]和撰写关于自己的新闻文章[[24](#bib.bib24)]，引发了对LLM输出可检测性的广泛担忧。情况随着对话微调LLMs的公开发布[[45](#bib.bib45)]变得更加严重，使得LLMs对公众变得更加可及和易于使用，以及通过信息检索、计算器和图像分析等辅助功能的增强[[57](#bib.bib57),
    [61](#bib.bib61), [44](#bib.bib44)]。
- en: Such performance is impressive, but it poses a serious threat. Generative models
    have no inherent moral code, and safety features added by LLM designers to imitate
    it are easily bypassed. LLMs can trivially be used to run blogs and social media
    accounts and write articles pushing disinformation, supporting harassment campaigns,
    or promoting self-harm. Undercover social influence and harassment with economical
    [[38](#bib.bib38)], political [[27](#bib.bib27)], and military goals [[15](#bib.bib15)]
    is a well-developed and highly active industry [[9](#bib.bib9), [3](#bib.bib3)].
    Everything points towards generative language models being able drive an automation
    revolution in it [[12](#bib.bib12), [60](#bib.bib60)]. Even relatively small,
    widely accessible models that can be run on commodity hardware can be extremely
    effective in generating misleading news articles [[66](#bib.bib66), [33](#bib.bib33)],
    writing fake reviews [[1](#bib.bib1)], phishing [[43](#bib.bib43)], or disrupting
    of democratic processes [[63](#bib.bib63)].
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的表现令人印象深刻，但也带来了严重威胁。生成模型没有固有的道德规范，而LLM设计者为了模仿道德规范所添加的安全功能很容易被绕过。LLM可以轻松用于运营博客和社交媒体账户，撰写推动虚假信息、支持骚扰活动或促进自我伤害的文章。具有经济[[38](#bib.bib38)]、政治[[27](#bib.bib27)]和军事目标[[15](#bib.bib15)]的隐秘社会影响和骚扰是一个成熟且高度活跃的行业[[9](#bib.bib9),
    [3](#bib.bib3)]。一切迹象都表明生成语言模型能够在其中推动自动化革命[[12](#bib.bib12), [60](#bib.bib60)]。即使是相对较小、广泛可访问的模型，在普通硬件上运行，也可以非常有效地生成误导性新闻文章[[66](#bib.bib66),
    [33](#bib.bib33)]、撰写虚假评论[[1](#bib.bib1)]、进行网络钓鱼[[43](#bib.bib43)]或扰乱民主进程[[63](#bib.bib63)]。
- en: Despite the best intentions of their original authors, generative language models
    pose a major threat in case of misuse. It is essential to be able to detect them
    in the wild.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管原作者的初衷是良好的，但生成语言模型在误用的情况下构成了重大威胁。能够在实际环境中检测它们是至关重要的。
- en: 2 Background
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 背景
- en: 2.1 Generated Text Detection
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 生成文本检测
- en: Prior research into generative language model detection is extensive and predates
    LLMs [[28](#bib.bib28)]. Model detection concern was so great for the creators
    of GPT-2 model that they provided a baseline detection tool for their model [[58](#bib.bib58)].
    Creators of GROVER - an LLM specializing in news-like text generation - claimed
    that it also could detect generative models at large [[66](#bib.bib66)]. Such
    detection tools were deemed highly necessary, given that even for relatively small
    LLMs, humans were shown to be inadequate at detecting them [[30](#bib.bib30)].
    Several high-profile benchmarking studies found that fine-tuned classifier LLMs
    performed best[[58](#bib.bib58), [66](#bib.bib66), [30](#bib.bib30), [60](#bib.bib60),
    [41](#bib.bib41), [1](#bib.bib1), [17](#bib.bib17), [18](#bib.bib18)]. Such detectors
    were trained by feeding a pretrained LLM, often a BERT/RoBERTa, with examples
    of machine-generated and human-generated texts, hoping that the language representation
    learned during the pretraining will allow the LLM to learn robust features that
    are specific to either of classes.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 对生成语言模型检测的先前研究非常广泛，并且早于LLMs[[28](#bib.bib28)]。对于GPT-2模型的创建者而言，模型检测问题如此严重，以至于他们为其模型提供了一个基线检测工具[[58](#bib.bib58)]。GROVER的创建者——一个专注于新闻类文本生成的LLM——声称它也能够检测大规模生成模型[[66](#bib.bib66)]。鉴于即使对于相对较小的LLM，人类也被证明在检测它们方面不够充分，这些检测工具被认为是高度必要的[[30](#bib.bib30)]。几项高影响力的基准研究发现，微调的分类器LLM表现最佳[[58](#bib.bib58),
    [66](#bib.bib66), [30](#bib.bib30), [60](#bib.bib60), [41](#bib.bib41), [1](#bib.bib1),
    [17](#bib.bib17), [18](#bib.bib18)]。这些检测器通过向预训练的LLM（通常是BERT/RoBERTa）提供机器生成和人类生成文本的示例来进行训练，希望预训练过程中学到的语言表示能使LLM学习到特定于这两类的鲁棒特征。
- en: However, most work on generative model detection did not consider the possibility
    that attackers would fine-tune their generative models to evade detection or prompt
    them in a non-trivial manner. A flurry of research papers moderating the initial
    optimistic results followed. A model fine-tuned for unrelated purposes was shown
    to evade detectors trained on the base model [[1](#bib.bib1)]. Similar results
    could be achieved by using longer prompts [[4](#bib.bib4)], changing the sampling
    strategy [[30](#bib.bib30), [60](#bib.bib60)], or adversarially perturbing characters
    or words in the prompt [[19](#bib.bib19), [64](#bib.bib64)].
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，大多数关于生成模型检测的研究并没有考虑到攻击者可能会微调他们的生成模型以逃避检测或以非平凡的方式进行提示。一系列调节初步乐观结果的研究论文随之而来。一个为无关目的微调的模型被证明能够逃避训练于基础模型上的检测器[[1](#bib.bib1)]。类似的结果可以通过使用更长的提示[[4](#bib.bib4)]、改变采样策略[[30](#bib.bib30),
    [60](#bib.bib60)]，或对提示中的字符或词进行对抗性扰动[[19](#bib.bib19), [64](#bib.bib64)]来实现。
- en: Even in the white-box setting - when the generative model is identified, and
    its outputs are correctly labeled - SotA methods struggle to detect them. [[1](#bib.bib1)]
    showed that in cases where fine-tuned models were known in advance, a BERT-based
    detector could be trained to detect them, although with low precision and recall
    ( 40% for both). [[18](#bib.bib18)] found that even for Twitter bots based on
    generative models that do not attempt evasion, even fine-tuned detectors struggled
    to differentiate GPT2-based ones from humans ( 70% accuracy). Perhaps more concerning,
    the memorization capabilities of generative LLMs mean that well-designed prompts
    can trigger perfect recall of training data - which is human-generated text [[14](#bib.bib14)].
    A detector would need access to the whole training dataset of the generative model
    to succeed in that setting, which is an unrealistic assumption, especially in
    an adversarial detection setting.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在白盒设置下——当生成模型被识别且其输出被正确标记时——SotA 方法仍然难以检测它们。[[1](#bib.bib1)] 表明，在已知精细调整模型的情况下，可以训练基于BERT的检测器来检测它们，但精确度和召回率都很低（均为40%）。[[18](#bib.bib18)]
    发现即使是基于生成模型的Twitter机器人也未尝试规避，即使经过精细调整的检测器也难以将基于GPT2的与人类区分开来（准确率为70%）。更令人担忧的是，生成LLMs的记忆能力意味着精心设计的提示可以触发对训练数据的完美回忆——即人类生成的文本[[14](#bib.bib14)]。检测器需要访问生成模型的整个训练数据集才能在这种情况下成功，而这在对抗检测设置中是不切实际的假设。
- en: 2.2 Detection and Evasion in Text GANs
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 文本生成对抗网络中的检测与规避
- en: A common framework to approach an arms race of detection and detection evasion
    in ML is Generative Adversarial Networks (GANs) [[23](#bib.bib23)]. They are notorious
    for excellent capabilities in image generation, with photorealism and style transfer
    often cited as examples of performance [[10](#bib.bib10), [31](#bib.bib31)]. For
    natural language generation, GANs have been investigated as ways to improve pretrained
    models, to further improve models trained through maximum likelihood methods -
    specifically mitigate the exposure bias. Exposure bias is a tendency of language
    models to generate a succession of tokens they never encountered in training and
    find themselves without a statistical model to continue generation, leading to
    repetitive, degenerate output [[29](#bib.bib29), [26](#bib.bib26)].
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中应对检测与检测规避的军备竞赛的常见框架是生成对抗网络（GANs）[[23](#bib.bib23)]。它们以在图像生成中的出色能力而闻名，光影逼真和风格迁移通常被作为性能的例子[[10](#bib.bib10),
    [31](#bib.bib31)]。对于自然语言生成，GANs 已被研究作为改进预训练模型的一种方式，以进一步提升通过最大似然方法训练的模型——特别是减轻暴露偏差。暴露偏差是语言模型生成训练中从未遇到的令牌序列的倾向，从而发现自己没有统计模型来继续生成，导致重复和退化的输出[[29](#bib.bib29),
    [26](#bib.bib26)]。
- en: Unfortunately, despite a wealth of proposed architectures, none of the text-generating
    GANs imitating image-generating ones offered any improvement over MLE [[13](#bib.bib13)].
    While several modern GANs have been proposed to mitigate that, such as ScratchGAN
    [[42](#bib.bib42)] or ColdGAN [[34](#bib.bib34)], they depart significantly from
    the traditional adversarial setting and require a collaboration between the generator
    and discriminator, which is an unrealistic assumption for in-the-wild detection.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，尽管提出了大量的架构，但没有一种模仿图像生成GAN的文本生成GAN在MLE上提供任何改进[[13](#bib.bib13)]。虽然已提出几种现代GAN以减轻这一点，如ScratchGAN
    [[42](#bib.bib42)]或ColdGAN [[34](#bib.bib34)]，但它们显著偏离了传统的对抗设置，并需要生成器与判别器之间的协作，这在实际检测中是不切实际的假设。
- en: More importantly, all text-generating GANs proposed until now that are suitable
    for the adversarial setting are based on RNNs. Prior research suggests that proposed
    architectures stop working upon a transition to self-attention-based LLMs [[7](#bib.bib7)].
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 更重要的是，迄今为止所有适用于对抗设置的文本生成GAN均基于RNNs。先前的研究表明，所提出的架构在转向基于自注意力的LLMs时停止工作[[7](#bib.bib7)]。
- en: To illustrate this issue, we start with a Diversity-Promoting GAN (DPGAN) [[65](#bib.bib65)],
    that combines rewards for words and the whole sentence and corresponds to the
    scenario where the attacker would have access to both overall human/machine score
    and single word influence on the score. This is a realistic scenario for an attacker
    seeking to bypass a standard, widely accessible generative models detector, such
    as the HuggingFace OpenAI detector, a common tool that gained popularity thanks
    to its public accessibility, or GLTR - an early generative text detection tool
    [[22](#bib.bib22)].
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这个问题，我们从一个多样性促进GAN（DPGAN）[[65](#bib.bib65)]开始，该GAN结合了对单词和整个句子的奖励，并对应于攻击者可以访问整体人类/机器评分和单词对评分影响的场景。这是一个现实的场景，攻击者试图绕过标准的、广泛可用的生成模型检测器，例如HuggingFace
    OpenAI检测器，这是一种因其公开可用性而广受欢迎的工具，或GLTR——一个早期的生成文本检测工具[[22](#bib.bib22)]。
- en: '2.3 Training Stochastic Parrots: Reinforcement from Critic'
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 训练随机鹦鹉：来自批评的强化
- en: Adjusting LLMs to improve a specific aspect of their behavior is a common practice
    and is often done through further model training - fine-tuning. Reinforcement
    Learning from Human Feedback is an example of such fine-tuning that uses an external
    critic model trained from human feedback [[45](#bib.bib45)], but the general approach
    is significantly older [[68](#bib.bib68)].
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 调整LLM以改善其行为的特定方面是一种常见的做法，通常通过进一步的模型训练——微调来实现。来自人类反馈的强化学习是这种微调的一个例子，它使用从人类反馈中训练的外部批评模型[[45](#bib.bib45)]，但这一通用方法要显著更为古老[[68](#bib.bib68)]。
- en: Reinforcement from a critic model has been particularly prominent in the generative
    model normativity alignment field [[55](#bib.bib55)]. LLMs are trained on large
    datasets of texts collected on the internet and are representative of those texts.
    Because of that, they are prone to unexpectedly biased and toxic text generation
    [[8](#bib.bib8), [20](#bib.bib20)]. A term of Stochastic Parrots has emerged to
    designate this tendency [[5](#bib.bib5)], and one of the approaches to counter
    it is normative fine-tuning. The principle of normative fine-tuning is to use
    a critic LLM trained to predict when non-normative text is being generated and
    fine-tune the generator LLM from the feedback of the critic LLM, using rewards
    as a custom loss [[59](#bib.bib59), [46](#bib.bib46), [68](#bib.bib68)].
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 从批评模型中获得的强化在生成模型规范对齐领域中尤为突出[[55](#bib.bib55)]。LLM（大型语言模型）在互联网上收集的大型文本数据集上进行训练，并代表了这些文本。因此，它们容易生成意外的偏见和有毒文本[[8](#bib.bib8),
    [20](#bib.bib20)]。为了表征这种倾向，出现了“随机鹦鹉”（Stochastic Parrots）这一术语[[5](#bib.bib5)]，对抗这一问题的一种方法是规范性微调。规范性微调的原则是使用一个训练有素的批评LLM来预测何时生成了非规范性文本，并根据批评LLM的反馈对生成器LLM进行微调，使用奖励作为自定义损失[[59](#bib.bib59),
    [46](#bib.bib46), [68](#bib.bib68)]。
- en: Here, we provide a setting that combines the reinforcement from a critic model
    with a more modern AdamW optimizer[[40](#bib.bib40)], rather than the traditional
    Adam one [[32](#bib.bib32)] to lead to a robustly generalizing fine-tune. We start
    by performing a normativity fine-tune using a sentiment classifier - an imperfect,
    although valid approach [[46](#bib.bib46)]. After confirming our approach, we
    swap the normativity critic model for a generative model detector.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们提供了一种将批评模型的强化与更现代的AdamW优化器[[40](#bib.bib40)]结合的设置，而不是传统的Adam优化器[[32](#bib.bib32)]，以实现强健的泛化微调。我们首先使用情感分类器进行规范性微调——这是一种不完美但有效的方法[[46](#bib.bib46)]。在确认我们的方法后，我们将规范性批评模型替换为生成模型检测器。
- en: 3 Contributions
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 贡献
- en: •
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We show that generative LLM detection with a discriminator LLM is impossible
    if the attacker has access to the reference "human" dataset used to train the
    discriminator LLM. Simply fine-tuning the dataset and using prompts from it leads
    to a complete failure of the discriminator to learn the difference between machine
    and human-generated texts, even in a setting where all LLM outputs are correctly
    labeled.
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们展示了如果攻击者能够访问用于训练判别器LLM的参考“人类”数据集，则生成LLM检测与判别器LLM的检测是不可能的。仅仅对数据集进行微调并使用其提示会导致判别器完全无法学习机器生成文本和人类生成文本之间的差异，即使在所有LLM输出都正确标记的情况下也是如此。
- en: •
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We show that reinforcement from critic generalizes significantly better than
    previously described when paired with the AdamW optimizer rather than the commonly
    used Adam one and allows well-generalizing model fine-tunes from limited data,
    matching prior SotA in normativity fine-tuning.
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们展示了当与AdamW优化器配对时，评论员的增强在泛化方面显著优于先前描述的结果，而不是常用的Adam优化器，并且能够从有限数据中实现良好的模型微调，与之前在规范性微调中的SotA相匹配。
- en: •
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We demonstrate a critical weakness on a previously proposed text-generating
    GAN architecture - DPGAN, and show the connection of this weakness to the difference
    in representative power of LLMs and RNNs used in text GANs compatible with the
    in-the-wild detection setting.
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们展示了一个先前提出的文本生成GAN架构 - DPGAN的关键弱点，并展示了这一弱点与文本GAN中LLMs和RNNs代表性能力差异的联系，该架构适用于现实环境中的检测设置。
- en: 4 Methodology
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 方法论
- en: Our code is based on a pre-existing Pytorch implementation of common text-generating
    GANs, including DPGAN, available from [https://github.com/williamSYSU/TextGAN-PyTorch](https://github.com/williamSYSU/TextGAN-PyTorch).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的代码基于现有的Pytorch实现的常见文本生成GAN，包括DPGAN，代码可在[https://github.com/williamSYSU/TextGAN-PyTorch](https://github.com/williamSYSU/TextGAN-PyTorch)获取。
- en: We chose GPT-2 small (117M parameters) as a generator due to its wide availability
    and extensive research record concerning its usage. In addition to similar considerations
    for the choice of BERT base (110M parameters) as a discriminator, fine-tuned BERT
    is close to SotA among methods for generative model detection in the wild [[17](#bib.bib17),
    [18](#bib.bib18)]. Overall, the configuration represents a likely attacker/defender
    language model configuration when both are limited to commodity hardware.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了GPT-2 small（117M参数）作为生成器，因为它广泛可用且有大量使用方面的研究记录。除了对BERT base（110M参数）作为判别器的选择做类似考虑外，微调后的BERT在现实中生成模型检测方法中接近SotA
    [[17](#bib.bib17), [18](#bib.bib18)]。总体而言，该配置代表了当攻击者/防御者都限制于商品硬件时的可能语言模型配置。
- en: 'We rely on two datasets provided by the base text-GAN generating library, the
    10 000 entries MS COCO scene description dataset and the 280 000 entries 2017
    EMNLP news sample corpus. The first five tokens are used as prompts whenever applicable,
    and we use an 80/20% train/validation set. No hyperparameter search was performed,
    with default parameters and parameters from prior literature being used. Adam
    [[32](#bib.bib32)] and AdamW optimizers [[37](#bib.bib37), [40](#bib.bib40)] were
    used, according to subsections of [5](#S5 "5 Results and Discussion ‣ Stochastic
    Parrots Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune and Hard to
    Detect with other LLMs"). Per prior research on the importance of model training
    re-starts for methodology evaluation [[39](#bib.bib39)], we report all model training
    runs and evaluate the model performance on the best-out-of-five.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们依赖于基础文本-GAN生成库提供的两个数据集，即10,000条MS COCO场景描述数据集和280,000条2017 EMNLP新闻样本语料库。每当适用时，前五个标记作为提示，我们使用80/20%的训练/验证集。未进行超参数搜索，使用默认参数和先前文献中的参数。使用Adam
    [[32](#bib.bib32)]和AdamW优化器 [[37](#bib.bib37), [40](#bib.bib40)]，根据[5](#S5 "5
    结果与讨论 ‣ 随机鹦鹉 寻找随机鹦鹉：LLMs易于微调，且难以被其他LLMs检测")的小节。根据关于模型训练重启对方法论评估的重要性的先前研究 [[39](#bib.bib39)]，我们报告所有模型训练运行，并评估模型在五次中最佳结果的性能。
- en: 'A more detailed overview of the methodology is available in Appendix [0.A](#Pt0.A1
    "Appendix 0.A Detailed Methodology ‣ Stochastic Parrots Looking for Stochastic
    Parrots: LLMs are Easy to Fine-Tune and Hard to Detect with other LLMs"). The
    code and detailed instructions to reproduce all experiments can be found at [https://github.com/8a3539f168fd077097ea473cc8a9c093/gpt_bert_gan](https://github.com/8a3539f168fd077097ea473cc8a9c093/gpt_bert_gan).'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 方法论的详细概述可在附录[0.A](#Pt0.A1 "附录0.A 详细方法论 ‣ 随机鹦鹉 寻找随机鹦鹉：LLMs易于微调，且难以被其他LLMs检测")中找到。所有实验的代码和详细说明可在[https://github.com/8a3539f168fd077097ea473cc8a9c093/gpt_bert_gan](https://github.com/8a3539f168fd077097ea473cc8a9c093/gpt_bert_gan)上找到。
- en: 5 Results and Discussion
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结果与讨论
- en: 5.1 GPT-2 Collapses Rapidly Due to DP-GAN’s Discriminator Misspecified Reward
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 GPT-2由于DP-GAN的判别器错误指定奖励而迅速崩溃
- en: 'DPGAN attributes to generated samples a sentence-level reward and a word-level
    reward for each of the generated tokens to favor/discourage the generation of
    tokens at some position. By replacing the initial generator with a GPT-2 implemented
    based on prior code (more details in Appendix [0.A](#Pt0.A1 "Appendix 0.A Detailed
    Methodology ‣ Stochastic Parrots Looking for Stochastic Parrots: LLMs are Easy
    to Fine-Tune and Hard to Detect with other LLMs")), we train GPT-2 from scratch
    with the MS COCO dataset, while keeping the same discriminator. We expect full
    memorization from GPT-2 trained from scratch and expect the discriminator to fail
    and provide overall rewards favoring rare words. Surprisingly, we noticed consistent
    output degeneration after only two epochs, ie. GPT-2 only generating ’a’ tokens.
    This contradicts the original paper suggesting that DPGAN was specifically designed
    to avoid repetitive common tokens in its output [[65](#bib.bib65)]. As we can
    see in table [1](#S5.T1 "Table 1 ‣ 5.1 GPT-2 Collapses Rapidly Due to DP-GAN’s
    Discriminator Misspecified Reward ‣ 5 Results and Discussion ‣ Stochastic Parrots
    Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune and Hard to Detect
    with other LLMs"), the generator quickly starts to prioritize the generation of
    the token ’a’ at position two, even though otherwise rewards indeed favor more
    rare words, as authors originally suggested. While almost all samples in MS COCO
    start with an ’a’, it should have a probability of almost one only at the first
    position and certainly not the second.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: DPGAN 赋予生成样本句子级别的奖励和每个生成令牌的单词级别奖励，以促使/抑制某些位置令牌的生成。通过用基于先前代码实现的 GPT-2 替换初始生成器（更多细节见附录
    [0.A](#Pt0.A1 "附录 0.A 详细方法 ‣ 随机鹦鹉寻找随机鹦鹉：LLMs 容易微调且难以与其他 LLMs 检测")），我们用 MS COCO
    数据集从头训练 GPT-2，同时保持相同的判别器。我们期望从头训练的 GPT-2 完全记忆，并期望判别器失败并提供整体奖励以偏向稀有词。令人惊讶的是，我们注意到仅经过两轮训练，输出就出现了一致的退化，即
    GPT-2 仅生成 ’a’ 令牌。这与原始论文建议 DPGAN 特别设计用于避免输出中重复常见令牌的观点相矛盾 [[65](#bib.bib65)]。正如我们在表
    [1](#S5.T1 "表 1 ‣ 5.1 GPT-2 由于 DP-GAN 的判别器奖励错误迅速崩溃 ‣ 5 结果与讨论 ‣ 随机鹦鹉寻找随机鹦鹉：LLMs
    容易微调且难以与其他 LLMs 检测") 中看到的，生成器很快开始优先生成位置二的令牌 ’a’，尽管其他奖励确实偏向于稀有词，正如作者最初建议的那样。虽然
    MS COCO 中几乎所有样本都以 ’a’ 开头，但它应该在第一个位置的概率几乎为一，而绝不是第二个位置。
- en: 'Probability of token at position 2 epoch 0 epoch 1 epoch 2 epoch 3 woman: 0.31
    woman: 0.46 a: 0.66 a: 0.99 view: 0.14 is: 0.19 is: 0.31 is: 0.0001 corner: 0.05
    kitchen: 0.05 woman: 0.009 woman: 0.000002 kitchen: 0.04 white: 0.04 kitchen:
    0.009 kitchen: 0.000001 bathroom: 0.04 cat: 0.02 white: 0.003 white: 0.00000008'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '第二位置令牌的概率 epoch 0 epoch 1 epoch 2 epoch 3 woman: 0.31 woman: 0.46 a: 0.66 a:
    0.99 view: 0.14 is: 0.19 is: 0.31 is: 0.0001 corner: 0.05 kitchen: 0.05 woman:
    0.009 woman: 0.000002 kitchen: 0.04 white: 0.04 kitchen: 0.009 kitchen: 0.000001
    bathroom: 0.04 cat: 0.02 white: 0.003 white: 0.00000008'
- en: 'Table 1: Tokens with the highest probability of being generated by GPT-2 at
    position two during adversarial training'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 1：GPT-2 在对抗训练中第二位置生成的最高概率的令牌
- en: 'After noticing the repetition of the token ’a’, we inspected the rewards the
    discriminator gives to generated samples. We noticed that token ’a’ was favored
    only in the first position, while the rest of the text favored less frequent tokens
    (see table [2](#S5.T2 "Table 2 ‣ 5.1 GPT-2 Collapses Rapidly Due to DP-GAN’s Discriminator
    Misspecified Reward ‣ 5 Results and Discussion ‣ Stochastic Parrots Looking for
    Stochastic Parrots: LLMs are Easy to Fine-Tune and Hard to Detect with other LLMs")).
    In particular, the discriminator outputs positive and negative rewards, but these
    rewards seem to be too high for ’a’, which likely overwhelms the word-based reward
    of the DPGAN discriminator.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在注意到令牌 ’a’ 的重复后，我们检查了判别器对生成样本的奖励。我们注意到令牌 ’a’ 仅在第一个位置受到青睐，而其余文本则更青睐不那么频繁的令牌（见表
    [2](#S5.T2 "表 2 ‣ 5.1 GPT-2 由于 DP-GAN 的判别器奖励错误迅速崩溃 ‣ 5 结果与讨论 ‣ 随机鹦鹉寻找随机鹦鹉：LLMs
    容易微调且难以与其他 LLMs 检测")）。特别是，判别器输出正面和负面奖励，但这些奖励似乎对 ’a’ 过高，可能压倒了 DPGAN 判别器基于单词的奖励。
- en: epoch 0 BOS a woman is walking across the street 33 868 0.4 0.01 1.2 0.4 0.4
    1.8
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: epoch 0 BOS 一个女人正在过马路 33 868 0.4 0.01 1.2 0.4 0.4 1.8
- en: epoch 1 BOS a large gray airplane flying through the sky 33 869 5.6 6.6 11 10
    1.7 2.8 7.5
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: epoch 1 BOS 一架大型灰色飞机飞过天空 33 869 5.6 6.6 11 10 1.7 2.8 7.5
- en: epoch 2 BOS a a a a a a a 33 870 0.6 0.07 0.03 0.04 0.05 0.07
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: epoch 2 BOS a a a a a a a 33 870 0.6 0.07 0.03 0.04 0.05 0.07
- en: 'Table 2: Rewards given to the first generated tokens by the discriminator'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：由鉴别器给予的第一个生成令牌的奖励
- en: 'By doing the same training with different variations of the MS COCO dataset
    (see appendix [0.B.1](#Pt0.A2.SS1 "0.B.1 variation of MS COCO dataset ‣ Appendix
    0.B DP-GAN with GPT-2 Debugging ‣ Stochastic Parrots Looking for Stochastic Parrots:
    LLMs are Easy to Fine-Tune and Hard to Detect with other LLMs")), we arrived at
    the conclusion that, in our setup, the discriminator favored the generation of
    tokens that are frequently present in the dataset due to unexpected behavior of
    the discriminator.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '通过对MS COCO数据集的不同变体进行相同的训练（见附录[0.B.1](#Pt0.A2.SS1 "0.B.1 variation of MS COCO
    dataset ‣ Appendix 0.B DP-GAN with GPT-2 Debugging ‣ Stochastic Parrots Looking
    for Stochastic Parrots: LLMs are Easy to Fine-Tune and Hard to Detect with other
    LLMs")），我们得出结论，在我们的设置中，鉴别器由于其意外行为而偏向于生成在数据集中频繁出现的令牌。'
- en: 'This, however, brought forwards the question of why the problem has not been
    discovered and reported in the original paper. Given that the problem arose when
    we replaced an LSTM generator with a larger and more powerful GPT-2, we investigated
    whether the size/representative power of GPT-2 relative to the training dataset
    was an issue. Experiments with different sizes of GPT-2 and a larger dataset (details
    about different sizes can be found in appendix [0.B.2](#Pt0.A2.SS2 "0.B.2 lighter
    GPT-2 and bigger dataset ‣ Appendix 0.B DP-GAN with GPT-2 Debugging ‣ Stochastic
    Parrots Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune and Hard to
    Detect with other LLMs")). Even though we observed a small drop in quality(repetition
    of tokens), we didn’t observe the same degeneration as with the larger model and
    no evolution of the model at all in the case of a larger dataset (as can be seen
    in Supplementary Fig. [7](#Pt0.A2.F7 "Figure 7 ‣ 0.B.2 lighter GPT-2 and bigger
    dataset ‣ Appendix 0.B DP-GAN with GPT-2 Debugging ‣ Stochastic Parrots Looking
    for Stochastic Parrots: LLMs are Easy to Fine-Tune and Hard to Detect with other
    LLMs")). We believe that this confirms our hypothesis and is a more general problem
    to which all RNN-based text GANs would be susceptible when converted to self-attention-based
    LLMs.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '然而，这提出了一个问题：为什么在原始论文中没有发现并报告这个问题。鉴于问题发生在我们将LSTM生成器替换为更大、更强大的GPT-2时，我们调查了GPT-2相对于训练数据集的大小/代表性是否存在问题。使用不同大小的GPT-2和更大的数据集进行实验（不同大小的详细信息可以在附录[0.B.2](#Pt0.A2.SS2
    "0.B.2 lighter GPT-2 and bigger dataset ‣ Appendix 0.B DP-GAN with GPT-2 Debugging
    ‣ Stochastic Parrots Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune
    and Hard to Detect with other LLMs")中找到）。尽管我们观察到了质量的小幅下降（令牌的重复），但我们没有观察到与更大模型相同的退化，也没有在更大的数据集中观察到模型的任何演变（如附加图[7](#Pt0.A2.F7
    "Figure 7 ‣ 0.B.2 lighter GPT-2 and bigger dataset ‣ Appendix 0.B DP-GAN with
    GPT-2 Debugging ‣ Stochastic Parrots Looking for Stochastic Parrots: LLMs are
    Easy to Fine-Tune and Hard to Detect with other LLMs")中所示）。我们相信这确认了我们的假设，并且这是一个更普遍的问题，所有基于RNN的文本GAN在转换为基于自注意力的LLM时都可能受到影响。'
- en: 5.2 Making Sure a GAN Setting Allows the Generator to Train
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 确保GAN设置允许生成器进行训练
- en: 'Given that we did not see any model evolution and a discriminator failure in
    DPGAN, we decided to completely change the architecture and first validate it
    with a fixed discriminator to show that a critic-guided fine-tuning of GPT-2 worked
    as expected. Given that a common setting for such critic-guided fine-tuning is
    normativity alignment, we used a previously proposed approach to it - using a
    sentiment analysis classifier. The rationale behind this approach is that non-normative
    text would be associated with a negative reaction to it, leading the sentiment
    classifier to detect and suppress it [[46](#bib.bib46)]. This would allow us to
    not only validate our approach for evasion fine-tuning but also provide results
    for the normativity alignment field. The details about how GPT-2 is fine-tuned
    can be found in Appendix [0.D.1](#Pt0.A4.SS1 "0.D.1 generator training in negativity
    reduction ‣ Appendix 0.D Architectures for Sentiment and Fake Detection Training
    ‣ Stochastic Parrots Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune
    and Hard to Detect with other LLMs").'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '鉴于我们没有看到模型演变和DPGAN中的判别器失败，我们决定彻底改变架构，并首先使用固定判别器验证它，以显示GPT-2的批评指导微调按预期工作。鉴于这种批评指导微调的常见设置是规范对齐，我们使用了先前提出的方法——使用情感分析分类器。这种方法的依据是非规范文本将与对其的负面反应相关联，导致情感分类器检测并抑制它[[46](#bib.bib46)]。这不仅使我们能够验证我们的方法以进行规避微调，还能为规范性对齐领域提供结果。有关GPT-2如何进行微调的详细信息，请参见附录[0.D.1](#Pt0.A4.SS1
    "0.D.1 generator training in negativity reduction ‣ Appendix 0.D Architectures
    for Sentiment and Fake Detection Training ‣ Stochastic Parrots Looking for Stochastic
    Parrots: LLMs are Easy to Fine-Tune and Hard to Detect with other LLMs")。'
- en: In the experiments described in this part, the "BERT model" is a pretrained
    model fine-tuned for sentiment analysis. In this section, we will call nice GPT-2
    a base GPT-2 model fine-tuned using the sentiment classification BERT model, with
    the generation being prompted by the first five tokens in the MS COCO dataset.
    We call base GPT-2 a default pretrained GPT-2-small model without any fine-tuning.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在本部分描述的实验中，“BERT模型”是一个针对情感分析微调的预训练模型。在本节中，我们将称nice GPT-2为使用情感分类BERT模型微调的基础GPT-2模型，其生成由MS
    COCO数据集中的前五个词元提示。我们称基础GPT-2为默认的预训练GPT-2-small模型，没有进行任何微调。
- en: We experimented with different BERTs trained for sentiment analysis. The difference
    between them was in the labels they gave to generated samples. We found that having
    a BERT model that could attribute a third "neutral" label (mapped to a loss reward
    of 0.5 in our case) to the generated samples was helpful for the training. Most
    likely, this helped because most sentences in the MS COCO dataset were neutral,
    given that MS COCO entries are generally neutral image descriptions.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尝试了不同的用于情感分析的BERT模型。它们之间的区别在于它们给生成样本的标签。我们发现，拥有一个可以为生成样本分配第三个“中性”标签（在我们的案例中映射到损失奖励0.5）的BERT模型对训练是有帮助的。这可能是因为MS
    COCO数据集中大多数句子是中性的，考虑到MS COCO条目通常是中性图像描述。
- en: 'We used Adam optimizer with $betas=(0.9,0.999)$. For the loss function, we
    used MAE (mean absolute error). We already observed some meaningful but unstable
    results while training with the MS COCO dataset. Out of 5 runs, we observed one
    where the negativity didn’t change, three that had about 70% less negativity,
    and one that fluctuated between more than double negativity and 50% less negativity(see
    Fig. [1](#S5.F1 "Figure 1 ‣ 5.2 Making Sure a GAN Setting Allows the Generator
    to Train ‣ 5 Results and Discussion ‣ Stochastic Parrots Looking for Stochastic
    Parrots: LLMs are Easy to Fine-Tune and Hard to Detect with other LLMs")).'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '我们使用了带有$betas=(0.9,0.999)$的Adam优化器。对于损失函数，我们使用了MAE（均值绝对误差）。在使用MS COCO数据集进行训练时，我们已经观察到一些有意义但不稳定的结果。在5次运行中，我们观察到其中一次的负面情绪没有变化，三次的负面情绪减少了约70%，一次在负面情绪翻倍和减少50%之间波动（见图[1](#S5.F1
    "Figure 1 ‣ 5.2 Making Sure a GAN Setting Allows the Generator to Train ‣ 5 Results
    and Discussion ‣ Stochastic Parrots Looking for Stochastic Parrots: LLMs are Easy
    to Fine-Tune and Hard to Detect with other LLMs")）。'
- en: '![Refer to caption](img/e93d79a8c3ff1977c92e41087f195e7d.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e93d79a8c3ff1977c92e41087f195e7d.png)'
- en: 'Figure 1: Number of samples classified as negative by BERT during training
    at each epoch with 10,000 prefixes for three different runs'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：在训练期间，BERT在每个epoch中对三次不同运行的10,000个前缀分类为负面的样本数量
- en: 'We then tried to see if our result would generalize to another dataset, so
    we compared pre-trained GPT-2 with our nice GPT-2 on the EMNLP news dataset. We
    observed that the result generalized to about 35% less negativity with GPT-2 nice
    compared to base GPT-2 (see Fig. [2](#S5.F2 "Figure 2 ‣ 5.2 Making Sure a GAN
    Setting Allows the Generator to Train ‣ 5 Results and Discussion ‣ Stochastic
    Parrots Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune and Hard to
    Detect with other LLMs")), which is less than the 70% less negativity observed
    for the training set(MS COCO). This is comparable to the prior SotA from [[46](#bib.bib46)].
    We also provided samples generated by base GPT-2 and nice GPT-2 in appendix [0.C](#Pt0.A3
    "Appendix 0.C Examples of Samples Generated by Nice GPT-2 Compared to Base GPT-2
    ‣ Stochastic Parrots Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune
    and Hard to Detect with other LLMs"). We believe that GPT-2 sometimes learns during
    training to avoid generating types of sentences considered negative by the BERT,
    and this procedure generalizes to a validation dataset.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接着尝试查看我们的结果是否可以推广到另一个数据集，因此我们比较了预训练的GPT-2与我们的Nice GPT-2在EMNLP新闻数据集上的表现。我们观察到，相比基础GPT-2，Nice
    GPT-2的负面性减少了约35%（见图[2](#S5.F2 "图 2 ‣ 5.2 确保GAN设置允许生成器训练 ‣ 5 结果与讨论 ‣ 随机鹦鹉寻找随机鹦鹉：LLM
    易于微调且难以通过其他 LLM 检测")），这低于在训练集（MS COCO）中观察到的70%负面性减少。这与之前[[46](#bib.bib46)]的状态-of-the-art结果相当。我们还在附录[0.C](#Pt0.A3
    "附录 0.C Nice GPT-2 与基础 GPT-2 生成样本的比较 ‣ 随机鹦鹉寻找随机鹦鹉：LLM 易于微调且难以通过其他 LLM 检测")中提供了基础GPT-2和Nice
    GPT-2生成的样本。我们相信，GPT-2有时在训练过程中会学会避免生成被BERT视为负面的句子类型，这一过程可以推广到验证数据集。
- en: '![Refer to caption](img/1781f7118d7d05aa13c93edf09d99dc9.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/1781f7118d7d05aa13c93edf09d99dc9.png)'
- en: 'Figure 2: Comparison of the sentiment of text generated by base GPT-2 and finetuned
    version on a reduced version of EMNLP dataset'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：基础GPT-2与微调版本在EMNLP数据集缩减版上的文本情感比较
- en: 'We noticed that, on average, the base GPT-2 generates more negative samples
    than positive ones, and some of them are very negative (we provide a selection
    of them in appendix [0.C](#Pt0.A3 "Appendix 0.C Examples of Samples Generated
    by Nice GPT-2 Compared to Base GPT-2 ‣ Stochastic Parrots Looking for Stochastic
    Parrots: LLMs are Easy to Fine-Tune and Hard to Detect with other LLMs")). This
    considerable bias should be accounted for when using GPT-2\. It is now well known
    that some prefixes lead to extreme toxicity by the GPT family [[21](#bib.bib21)],
    but it seems that sometimes prefixes that we would not suspect also lead to very
    toxic generated text. This is not surprising and has been previously reported
    by [[47](#bib.bib47)], although the problem is known to be significantly worse
    for larger models of the GPT family (see [[20](#bib.bib20)]).'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到，平均而言，基础GPT-2生成的负面样本比正面样本多，其中一些负面样本非常严重（我们在附录[0.C](#Pt0.A3 "附录 0.C Nice
    GPT-2 与基础 GPT-2 生成样本的比较 ‣ 随机鹦鹉寻找随机鹦鹉：LLM 易于微调且难以通过其他 LLM 检测")中提供了一些例子）。在使用GPT-2时应考虑这种显著的偏差。现在已知某些前缀会导致GPT家族生成极端有毒的内容[[21](#bib.bib21)]，但有时一些我们不会怀疑的前缀也会导致非常有毒的生成文本。这并不令人惊讶，[[47](#bib.bib47)]之前已报告过这种情况，尽管这一问题在GPT家族的更大模型中明显更为严重（见[[20](#bib.bib20)]）。
- en: 5.3 Ensuring Generalizable Generator Training
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 确保生成器训练的普遍性
- en: The problem with the prior approach was that in about 2/5 cases, the training
    did not lead to improvement at all. We observed on some runs an increase in negativity
    up to double or no changes in negativity during training. Also, the negativity
    reduction on the validation set(EMNLP news) was 35% compared to the 70% reduction
    for the training set. The instability of large language model training is well-known,
    especially on smaller datasets, such as MS COCO (multiple restarts are often used
    to obtain state-of-the-art models). However, we were unsatisfied with this performance.
    We tried to use tricks known to stabilize training and increase the generalization
    capabilities of the model, namely switching to use *AdamW* for the optimizer,
    learning rate scheduling(with warm-up), gradient clipping, and weight decay, all
    of which were used for GPT-2 pretraining. We also tried to use SGD, which is known
    to generate results that generalize better and allow model "grokking" [[49](#bib.bib49)].
    Unfortunately, SGD is known to fare poorly on language models and failed outright.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的方法的问题在于，在约2/5的情况下，训练根本没有改进。我们观察到在一些运行中，训练期间负面情绪增加了两倍或没有变化。此外，验证集（EMNLP新闻）的负面情绪减少了35%，相比之下，训练集的减少为70%。大语言模型训练的不稳定性是众所周知的，特别是在较小的数据集上，如MS
    COCO（通常使用多次重启来获得最先进的模型）。然而，我们对这种表现不满意。我们尝试了已知的稳定训练和提高模型泛化能力的技巧，即使用*AdamW*作为优化器，学习率调度（包括预热），梯度裁剪和权重衰减，这些都用于GPT-2的预训练。我们还尝试了SGD，已知其生成的结果泛化更好，并允许模型“理解”[[49](#bib.bib49)]。不幸的是，SGD在语言模型上表现不佳，完全失败。
- en: '![Refer to caption](img/15dfb9fe5f66bd846e54603090890fde.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/15dfb9fe5f66bd846e54603090890fde.png)'
- en: 'Figure 3: Number of samples classified as negative by BERT during training
    at each epoch with 10,000 prompts for five different runs'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：BERT在每个训练轮次中将10,000个提示分类为负样本的数量，显示了五次不同运行的结果。
- en: We ran our model with 14 epochs(we stopped early when we saw no changes for
    five epochs). We tested learning rate scheduling with linear scheduling and a
    starting learning rate at 5e-5(the learning rate is reduced linearly ten times
    per epoch until reaching 0 at epoch 20)). The reason we use a learning rate scheduling
    is to improve stability because it allows the model to reach a more robust and
    deeper local minimum. For the other parameters(in particular for the parameters
    of AdamW, we looked at default parameters from:[https://github.com/huggingface/transformers/blob/main/src/transformers/training_args.py](https://github.com/huggingface/transformers/blob/main/src/transformers/training_args.py).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们运行了14个轮次（当我们看到五个轮次没有变化时，我们提前停止了）。我们测试了线性调度的学习率和初始学习率为5e-5（学习率在每个轮次线性减少十倍，直到第20轮达到0）。我们使用学习率调度的原因是为了提高稳定性，因为这使模型能够达到更稳健、更深的局部最小值。对于其他参数（特别是AdamW的参数），我们参考了默认参数：[https://github.com/huggingface/transformers/blob/main/src/transformers/training_args.py](https://github.com/huggingface/transformers/blob/main/src/transformers/training_args.py)。
- en: 'Using the above tricks, we observe only marginal improvement in stability.
    We still observed the same rate of runs that did not lead to improvements. However,
    we saw better convergence towards about 5% less negativity for the training dataset(for
    runs that did reduce the negativity). We also observed better generalization for
    the validation set with 60% reduced negativity. In particular, one of the training
    produced a particularly good model that generalized well with the validation EMLP
    dataset to an approximate 60% decrease in negativity and a 60% increase in positivity(see
    Fig. [4](#S5.F4 "Figure 4 ‣ 5.3 Ensuring Generalizable Generator Training ‣ 5
    Results and Discussion ‣ Stochastic Parrots Looking for Stochastic Parrots: LLMs
    are Easy to Fine-Tune and Hard to Detect with other LLMs")). We thus think that
    the model can get similar levels of reduction of negativity for the validation
    set when the GPT-2 generator is able to train. However, even with different optimization
    tricks, we observed the same rate of about 2/5 runs that did not lead to less
    negativity.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 使用上述技巧，我们观察到稳定性只有微小的改善。我们仍然观察到相同比例的运行没有带来改善。然而，我们看到训练数据集的负面性减少了约5%（对于减少负面性的运行）。我们还观察到验证集的泛化效果更好，负面性减少了60%。特别是，其中一个训练产生了一个特别好的模型，该模型在验证EMLP数据集上泛化效果良好，负面性减少了约60%，正面性增加了60%（见图[4](#S5.F4
    "图4 ‣ 5.3 确保可泛化生成器训练 ‣ 5 结果与讨论 ‣ 随机鹦鹉寻找随机鹦鹉：LLMs容易微调但难以被其他LLMs检测")）。因此，我们认为，当GPT-2生成器能够训练时，模型可以在验证集上获得类似的负面性减少水平。然而，即使使用不同的优化技巧，我们观察到大约2/5的运行未能减少负面性。
- en: Relevant literature suggests that transformer NLP models training and fine-tuning
    are hard tasks that require extensive hyper-parameter optimization and additional
    tricks to stabilize the training(see eg. [[35](#bib.bib35)]).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 相关文献表明，变压器NLP模型的训练和微调是困难的任务，需要广泛的超参数优化和额外的技巧来稳定训练（见例如[[35](#bib.bib35)]）。
- en: '![Refer to caption](img/14ee11ef4999ed796f03b1cced88a3ec.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/14ee11ef4999ed796f03b1cced88a3ec.png)'
- en: 'Figure 4: Comparison of the sentiment of text generated by base GPT-2 and nice
    GPT-2 with a generalizing improvement in positivity tested on the EMNLP news dataset'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：由基础GPT-2和改进GPT-2生成的文本情感对比，在EMNLP新闻数据集上测试了正面性的一般改善
- en: '5.4 Running GAN: Hide-and-Seek Between GTP-2 and BERT'
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 运行GAN：GTP-2与BERT之间的捉迷藏
- en: The goal of these experiments is to see if it is possible to train a BERT model
    to detect text generated by GPT-2 and use it to then train GPT-2 to escape training,
    aka perform GAN iterations.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这些实验的目标是检验是否可以训练一个BERT模型来检测由GPT-2生成的文本，并利用它来训练GPT-2以逃避训练，即进行GAN迭代。
- en: 'The architecture we designed is functionally divided into two parts. First,
    BERT fine-tuning, which we will call *discriminator training* (see Fig [5](#S5.F5
    "Figure 5 ‣ 5.4 Running GAN: Hide-and-Seek Between GTP-2 and BERT ‣ 5 Results
    and Discussion ‣ Stochastic Parrots Looking for Stochastic Parrots: LLMs are Easy
    to Fine-Tune and Hard to Detect with other LLMs")) and generator training with
    scores from BERT, which we will call *generator training*(see Supplementary Fig.
    [9](#Pt0.A4.F9 "Figure 9 ‣ 0.D.2 generator training in fake detection ‣ Appendix
    0.D Architectures for Sentiment and Fake Detection Training ‣ Stochastic Parrots
    Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune and Hard to Detect
    with other LLMs")).'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设计的架构功能上分为两个部分。首先是BERT微调，我们称之为*鉴别器训练*（见图[5](#S5.F5 "图5 ‣ 5.4 运行GAN：GTP-2与BERT之间的捉迷藏
    ‣ 5 结果与讨论 ‣ 随机鹦鹉寻找随机鹦鹉：LLMs容易微调但难以被其他LLMs检测")）和使用BERT评分的生成器训练，我们称之为*生成器训练*（见补充图[9](#Pt0.A4.F9
    "图9 ‣ 0.D.2 假检测中的生成器训练 ‣ 附录0.D 情感与假检测训练架构 ‣ 随机鹦鹉寻找随机鹦鹉：LLMs容易微调但难以被其他LLMs检测")）。
- en: The BERT fine-tuning (discriminator training) consists of fine-tuning a pre-trained
    BERT classifier to detect fake samples. We feed BERT with samples generated by
    a base pre-trained GPT-2 that uses prefixes from a dataset to generate samples.
    We give the label 0 to fake samples generated by GPT-2 and label 1 for the true
    samples coming from the same dataset as the prefixes that GPT-2 uses. Then BERT
    outputs a probability of the output being fake or true given an input sample.
    We then compute a loss based on the labels and perform back-propagation. The process
    is repeated for 1-3 epochs, where each epoch corresponds to the full dataset traversal.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: BERT 微调（判别器训练）包括对预训练的 BERT 分类器进行微调，以检测伪造样本。我们将 BERT 输入由基础预训练的 GPT-2 生成的样本，GPT-2
    使用数据集中的前缀来生成样本。我们将标签 0 赋给由 GPT-2 生成的伪造样本，将标签 1 赋给来自与 GPT-2 使用的前缀相同数据集的真实样本。然后
    BERT 输出给定输入样本的真假概率。我们基于标签计算损失并执行反向传播。该过程重复 1-3 个周期，每个周期对应于完整的数据集遍历。
- en: '![Refer to caption](img/c931a5e9143fc100e4efce9613fb2c30.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c931a5e9143fc100e4efce9613fb2c30.png)'
- en: 'Figure 5: BERT training phase of the GAN for fake detection'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '图 5: GAN 的 BERT 训练阶段，用于伪造检测'
- en: 'The second part of the training(generator training) consists of training GPT-2
    with scores exactly the same way as we did for sentiment analysis(cf. part [5.2](#S5.SS2
    "5.2 Making Sure a GAN Setting Allows the Generator to Train ‣ 5 Results and Discussion
    ‣ Stochastic Parrots Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune
    and Hard to Detect with other LLMs")). The details about how it differs from the
    previous part can be found in appendix [0.D.2](#Pt0.A4.SS2 "0.D.2 generator training
    in fake detection ‣ Appendix 0.D Architectures for Sentiment and Fake Detection
    Training ‣ Stochastic Parrots Looking for Stochastic Parrots: LLMs are Easy to
    Fine-Tune and Hard to Detect with other LLMs").'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 训练的第二部分（生成器训练）包括以与我们对情感分析相同的方式训练 GPT-2（参见第 [5.2](#S5.SS2 "5.2 确保 GAN 设置允许生成器训练
    ‣ 5 结果与讨论 ‣ 随机鹦鹉寻找随机鹦鹉：LLM 容易微调但难以通过其他 LLM 检测") 部分）。有关它如何与上一部分不同的详细信息，请参见附录 [0.D.2](#Pt0.A4.SS2
    "0.D.2 伪造检测中的生成器训练 ‣ 附录 0.D 情感和伪造检测训练架构 ‣ 随机鹦鹉寻找随机鹦鹉：LLM 容易微调但难以通过其他 LLM 检测")。
- en: The GAN architecture we designed starts with an optional fine-tuning of the
    GPT-2 generator then we repeat parts 1 and 2 during the training.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设计的 GAN 架构从 GPT-2 生成器的可选微调开始，然后在训练期间重复第 1 部分和第 2 部分。
- en: 5.4.1 Training with Fine-Tuned Generator
  id: totrans-89
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.4.1 使用微调生成器进行训练
- en: We first tried to fine-tune GPT-2 for the MS COCO dataset before the two repeated
    phases mentioned above, then built a dataset from the true MS COCO dataset and
    fake MS COCO generated by fine-tuned GPT-2\. This dataset is used to fine-tune
    BERT to detect fake samples. Finally, use BERT fine-tuned for fake detection to
    train GPT-2 as we did in the previous experiment with sentiment analysis(the goal
    being to build a GAN from that).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先尝试在上述两个重复阶段之前对 MS COCO 数据集进行微调，然后从真实的 MS COCO 数据集和由微调的 GPT-2 生成的伪造 MS COCO
    中构建数据集。该数据集用于微调 BERT 以检测伪造样本。最后，使用微调的 BERT 进行伪造检测来训练 GPT-2，目标是从中构建一个 GAN。
- en: 'The result was that BERT could not distinguish samples generated by GPT-2 from
    true samples(see Fig. [6](#S5.F6 "Figure 6 ‣ 5.4.1 Training with Fine-Tuned Generator
    ‣ 5.4 Running GAN: Hide-and-Seek Between GTP-2 and BERT ‣ 5 Results and Discussion
    ‣ Stochastic Parrots Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune
    and Hard to Detect with other LLMs")). Also, we discovered here that BERT achieved
    almost 100% accuracy when the samples generated by GPT-2 have a different length
    than those in the true dataset (more details about this training setup can be
    found in appendix [0.E.1](#Pt0.A5.SS1 "0.E.1 training with fine-tuned GPT-2 on
    MS COCO dataset ‣ Appendix 0.E Training Plots from GPT-2 Fake Detection Training
    ‣ Stochastic Parrots Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune
    and Hard to Detect with other LLMs")).'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是 BERT 无法区分由 GPT-2 生成的样本和真实样本（见图 [6](#S5.F6 "图 6 ‣ 5.4.1 使用微调生成器进行训练 ‣ 5.4
    运行 GAN：GTP-2 和 BERT 之间的藏猫猫 ‣ 5 结果与讨论 ‣ 随机鹦鹉寻找随机鹦鹉：LLM 容易微调但难以通过其他 LLM 检测")）。此外，我们发现，当
    GPT-2 生成的样本长度与真实数据集中样本长度不同时时，BERT 几乎达到了 100% 的准确率（有关此训练设置的更多细节，请参见附录 [0.E.1](#Pt0.A5.SS1
    "0.E.1 在 MS COCO 数据集上对微调 GPT-2 的训练 ‣ 附录 0.E 来自 GPT-2 伪造检测训练的训练图 ‣ 随机鹦鹉寻找随机鹦鹉：LLM
    容易微调但难以通过其他 LLM 检测")）。
- en: '![Refer to caption](img/5e246c7104ca0b9931525cb90bab2699.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/5e246c7104ca0b9931525cb90bab2699.png)'
- en: 'Figure 6: BERT accuracy on the validation set when GPT-2 is fine-tuned'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：当GPT-2经过微调时，BERT在验证集上的准确率
- en: 5.4.2 Training Without a Fine-Tuned Generator
  id: totrans-94
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.4.2 未微调生成器的训练
- en: 'Since we found that BERT could not train well when the difference between fake
    and true datasets is small(one or two tokens) or too big (samples generated from
    GPT-2 have ten more words than those of the dataset), we decided to perform the
    same procedure, but without fine-tuning GPT-2, and with correction of the lengths
    of the generated samples(so that all samples true/fake have same lengths). In
    that scenario, BERT had a high accuracy of about 90%. However, GPT-2 was not able
    to learn to evade BERT fine-tuned for fake detection (see appendix [0.E.2](#Pt0.A5.SS2
    "0.E.2 training without fine-tuned GPT-2 on MS COCO dataset ‣ Appendix 0.E Training
    Plots from GPT-2 Fake Detection Training ‣ Stochastic Parrots Looking for Stochastic
    Parrots: LLMs are Easy to Fine-Tune and Hard to Detect with other LLMs") for more
    details about this part).'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '由于我们发现当虚假数据集和真实数据集之间的差异很小（一个或两个标记）或太大（从GPT-2生成的样本比数据集多出十个单词）时，BERT的训练效果不好，因此我们决定执行相同的程序，但不对GPT-2进行微调，并对生成样本的长度进行修正（确保所有真实/虚假的样本具有相同的长度）。在这种情况下，BERT的准确率达到了约90%。然而，GPT-2未能学习如何避开针对虚假检测微调的BERT（有关这一部分的更多细节，请参见附录
    [0.E.2](#Pt0.A5.SS2 "0.E.2 training without fine-tuned GPT-2 on MS COCO dataset
    ‣ Appendix 0.E Training Plots from GPT-2 Fake Detection Training ‣ Stochastic
    Parrots Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune and Hard to
    Detect with other LLMs")）。'
- en: 'Our hypothesis as to causes is two-fold. First, we saw in part 5.2 that training
    GPT-2 with scores, as we did, is unstable (this could probably be improved). Also,
    we inspected the scores that BERT gave to the generated samples(see appendix [0.F](#Pt0.A6
    "Appendix 0.F Examples of Samples by GPT-2 during the Fake GAN Training and Score
    Given ‣ Stochastic Parrots Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune
    and Hard to Detect with other LLMs") for examples of samples and scores), and
    we didn’t observe a general pattern in the samples that received a good score.
    GPT-2 is, therefore, probably not able to find types of samples to avoid or to
    generate more of to fool BERT (as it maybe did in part [5.2](#S5.SS2 "5.2 Making
    Sure a GAN Setting Allows the Generator to Train ‣ 5 Results and Discussion ‣
    Stochastic Parrots Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune
    and Hard to Detect with other LLMs") because the scores were more meaningful).
    BERT and GPT-2 might need more data to generalize for fake detection. In particular,
    transformers require a lot of data to be trained (see [[48](#bib.bib48)]), and
    GPT-2 might need to be further fine-tuned by using prompts derived from the training
    dataset.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '我们对原因的假设有两个方面。首先，我们在第5.2部分中看到，用分数训练GPT-2，如我们所做的那样是不稳定的（这可能可以改进）。此外，我们检查了BERT对生成样本的评分（有关样本和评分的示例，请参见附录
    [0.F](#Pt0.A6 "Appendix 0.F Examples of Samples by GPT-2 during the Fake GAN Training
    and Score Given ‣ Stochastic Parrots Looking for Stochastic Parrots: LLMs are
    Easy to Fine-Tune and Hard to Detect with other LLMs")），我们没有观察到获得高分的样本中存在普遍模式。因此，GPT-2可能无法找到需要避免的样本类型或生成更多的样本来欺骗BERT（正如它在第[5.2](#S5.SS2
    "5.2 Making Sure a GAN Setting Allows the Generator to Train ‣ 5 Results and Discussion
    ‣ Stochastic Parrots Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune
    and Hard to Detect with other LLMs")部分中所做的那样，因为分数更有意义）。BERT和GPT-2可能需要更多的数据来推广虚假检测。特别是，变换器需要大量的数据来进行训练（参见
    [[48](#bib.bib48)]），而GPT-2可能需要通过使用源自训练数据集的提示进行进一步的微调。'
- en: 5.4.3 Training with a Partially Fine-Tuned Generator
  id: totrans-97
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.4.3 部分微调生成器的训练
- en: 'For the reasons above, we combined EMNLP news and MS COCO as a single dataset,
    and we fine-tuned the generator using MLE training with 30% of that dataset before
    adversarial training. During the discriminator training, BERT achieved 88% accuracy
    in fake detection on the validation dataset. The result for the adversarial training
    in terms of the number of samples generated by GPT-2 classified as fake or true
    is shown in Supplementary Fig. [13](#Pt0.A5.F13 "Figure 13 ‣ 0.E.3 training with
    partially fine-tuned GPT-2 on EMNLP news + MS COCO dataset ‣ Appendix 0.E Training
    Plots from GPT-2 Fake Detection Training ‣ Stochastic Parrots Looking for Stochastic
    Parrots: LLMs are Easy to Fine-Tune and Hard to Detect with other LLMs") in Appendix.
    Although GPT-2 is able to learn to evade fake detection, it degenerates during
    training (as can be seen with the samples in appendix [0.G](#Pt0.A7 "Appendix
    0.G Example of Samples Generated by GPT-2 during Fake GAN Training with EMNLP
    News + MS COCO Dataset after one Epoch of Adversarial Training ‣ Stochastic Parrots
    Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune and Hard to Detect
    with other LLMs")).'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '基于上述原因，我们将 EMNLP 新闻和 MS COCO 组合为一个数据集，并在对抗训练之前使用该数据集的 30% 进行了 MLE 训练以微调生成器。在鉴别器训练期间，BERT
    在验证数据集上的假检测准确率达到了 88%。有关 adversarial training 的结果，以 GPT-2 生成的样本被分类为假或真的数量为例，显示在附录中的补充图
    [13](#Pt0.A5.F13 "图 13 ‣ 0.E.3 训练与部分微调的 GPT-2 在 EMNLP 新闻 + MS COCO 数据集 ‣ 附录 0.E
    GPT-2 假检测训练的训练图 ‣ Stochastic Parrots Looking for Stochastic Parrots: LLMs are
    Easy to Fine-Tune and Hard to Detect with other LLMs")。尽管 GPT-2 能够学习规避假检测，但在训练过程中会退化（这可以从附录
    [0.G](#Pt0.A7 "附录 0.G GPT-2 在 EMNLP 新闻 + MS COCO 数据集上经过一轮对抗训练后生成的样本示例 ‣ Stochastic
    Parrots Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune and Hard to
    Detect with other LLMs") 的样本中看到）。'
- en: 6 Conclusion
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: Our overarching result is the demonstration of a highly potent attack against
    a common type of generative LLM detectors, which are considered SotA and are highly
    used in the wake of ChatGPT public release in late 2022.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的总体结果是展示了一种针对常见类型生成 LLM 检测器的高效攻击，这些检测器被认为是 SotA，并在 2022 年底 ChatGPT 公开发布后被广泛使用。
- en: Specifically, we show that an attacker with access to the human reference texts
    used to train the detector and access to the detector rating of generative model
    outputs is able not only to evade the model detection but even in the white-box
    setting, where all the generative mode outputs are correctly labeled, they can
    fully stop the detector training against it. While the detection of generative
    LLMs with other LLMs has been previously shown not to work well, we go further,
    showing that in the setting where common datasets are used to train the discriminator,
    a minimally competent attacker can fully defeat the detector.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 具体而言，我们展示了一个攻击者如果能够访问用于训练检测器的人类参考文本，并且可以访问生成模型输出的检测器评分，不仅能够逃避模型检测，甚至在白盒设置中（即所有生成模式的输出都被正确标记），他们还可以完全阻止检测器对其进行训练。虽然之前已经显示出使用其他
    LLM 对生成的 LLM 进行检测效果不佳，但我们进一步展示了在使用常见数据集来训练鉴别器的设置中，一个最低限度合格的攻击者可以完全击败检测器。
- en: On the way to this result, we showed that reinforcement from a critic model
    could be used to fine-tune a generative model on a relatively small dataset, as
    long as AdamW rather than the common Adam optimizer was used, with multiple restarts
    yielding the best results.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一结果的过程中，我们展示了如何利用来自评论模型的强化来对生成模型进行微调，即使在相对较小的数据集上，只要使用 AdamW 而不是常见的 Adam 优化器，并通过多次重启来获得最佳结果。
- en: Finally, we showed that existing literature on text-generating GANs, with both
    generator and discriminators built on RNNs, cannot be trusted to translate to
    LLMs as-is. While we demonstrate a failure in the DP-GAN architecture specifically,
    the reasons we believe led that failure to have gone undetected are the fundamental
    difference in the representative power of GANs and RNNs. As such, careful re-validation
    is needed.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们展示了现有关于基于 RNN 的文本生成 GAN 的文献不能直接应用于 LLM。虽然我们特别演示了 DP-GAN 架构的失败，但我们认为导致这一失败未被发现的原因在于
    GAN 和 RNN 在表示能力上的根本差异。因此，需要进行仔细的重新验证。
- en: Overall, we believe that our results strongly argue against the continued use
    of LLMs fine-tuned for classification to detect generative LLMs in the wild. We
    hope that this prompts research into novel methods of LLM detection, even if it
    is just fingerprinting of texts from major generative LLM access providers.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，我们认为我们的结果强烈反对继续使用为分类而微调的LLM来检测实际中的生成LLM。我们希望这能促使对LLM检测的新方法进行研究，即使只是对主要生成LLM访问提供者的文本进行指纹识别。
- en: We hope that our auxiliary results will also be of interest to the NLP ML community,
    helping fine-tune generative models more efficiently and will prompt the re-examination
    of results obtained on RNN-based text GAN before their extrapolation to LLMs.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望我们的辅助结果也能引起自然语言处理和机器学习社区的兴趣，帮助更高效地微调生成模型，并促使重新审视在将基于RNN的文本GAN结果外推到LLM之前的结果。
- en: Limitations
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 限制
- en: All the results presented here are primarily experimental. We do not provide
    theoretical guarantees, and it is unclear how results obtained on GPT-2 small
    and BERT will scale up to larger models, given their tendency to unlock new capabilities
    with the increase in size [[20](#bib.bib20)]. Similarly, while prior research
    suggests that results obtained on those two specific architectures generalize
    to other Transformer-based architectures, it remains an open question. GPT-2 small
    and BERT are architectures of comparable sizes (117M parameters vs. 110M parameters).
    An adversarial training involving models of significantly different representative
    power would likely result in different dynamics. A notable example of such a setting
    is the case where the discrimination model is substantially smaller than the generative
    one - which is a likely setting, given the attacker can invest considerable computational
    resources, whereas due to the sheer volume of content generated and consumed by
    humans online, a defensive discriminator will likely need to run on end-user devices.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这里呈现的所有结果主要是实验性的。我们没有提供理论保证，并且尚不清楚在GPT-2小型模型和BERT上获得的结果如何扩展到更大的模型，因为它们在规模增加时往往会解锁新的能力[[20](#bib.bib20)]。同样，虽然先前的研究表明在这两种特定架构上获得的结果可以推广到其他基于Transformer的架构，但这仍然是一个悬而未决的问题。GPT-2小型和BERT是具有相当规模的架构（117M参数与110M参数）。涉及代表性力量显著不同的模型的对抗性训练可能会导致不同的动态变化。一个显著的例子是区分模型显著小于生成模型的情况——这是一个可能的设置，因为攻击者可以投入大量计算资源，而由于人类在线生成和消费的内容数量庞大，防御性区分器可能需要在终端用户设备上运行。
- en: While large language models fine-tuned for detection - such as the ones we used
    here - have been criticized as stylometry unsuited for generative models detection
    [[6](#bib.bib6), [54](#bib.bib54)], there has so far been no alternative detection
    method shown to perform better. Notably, methods relying on the factual structure
    of the text have shown similar vulnerability to prompt selection and fine-tuning
    [[67](#bib.bib67)], even before the arrival of factual database augmented generative
    models [[56](#bib.bib56), [57](#bib.bib57)].
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然为检测而微调的大型语言模型——如我们在这里使用的模型——已被批评为不适合生成模型检测的风格分析[[6](#bib.bib6), [54](#bib.bib54)]，但迄今为止还没有显示出更好的替代检测方法。值得注意的是，依赖文本事实结构的方法已经显示出类似的脆弱性，如提示选择和微调[[67](#bib.bib67)]，即使在事实数据库增强的生成模型到来之前[[56](#bib.bib56),
    [57](#bib.bib57)]。
- en: Similarly, evasion detection through prompt selection - that we use to some
    extent - has been almost entirely neglected until now. However, results from the
    generative model normativity and privacy fields suggest that well-chosen prompts
    can lead to highly unexpected and uncharacteristic texts [[47](#bib.bib47), [14](#bib.bib14)],
    likely leading to a degradation of detection capabilities presented here as a
    previous SotA.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，通过提示选择进行的逃避检测——我们在某种程度上使用了这种方法——直到现在几乎被完全忽视。然而，来自生成模型规范性和隐私领域的结果表明，精心选择的提示可以导致高度意外和不典型的文本[[47](#bib.bib47),
    [14](#bib.bib14)]，这可能导致这里所呈现的检测能力的下降，作为之前的现有技术水平。
- en: If anything, both of those avenues for evasion detection reinforce our conclusion
    that a competent attacker can easily evade detection even with relatively small
    models.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有的话，这两种逃避检测途径都进一步支持了我们的结论，即一个熟练的攻击者即使使用相对较小的模型也能轻松避开检测。
- en: Ethics Statement
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 伦理声明
- en: We essentially provide a blueprint for a competent attacker to create a generative
    model that would effectively evade detection by most if not all, means available
    today.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们基本上提供了一个蓝图，使得一个熟练的攻击者能够创建一个生成模型，该模型能够有效地避开目前几乎所有可用的检测手段。
- en: While the first version of this paper was prepared in mid-2022, following the
    release of ChatGPT, we delayed its submission for publication by four months following
    the public release of ChatGPT to leave time for model developers to improve detection
    mechanisms. We similarly have contacted some of the entities operating common
    generative LLM detection endpoints to report our findings, to no avail.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这篇论文的第一版是在2022年中期准备的，但在ChatGPT发布后，我们推迟了四个月提交出版，以便给模型开发者改进检测机制的时间。我们同样联系了一些运营常见生成
    LLM 检测端点的实体来报告我们的发现，但未果。
- en: Given that prior knowledge of reference "human" texts used to train the detector,
    LLM is a critical component of full evasion described here, and given that it
    is currently unlikely for most deployed detectors using classification fine-tuned
    LLMs, we decided in favor of releasing our results publicly.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于对参考文献“人类”文本的先验知识是完全规避中描述的关键组成部分，并且鉴于目前大多数使用分类微调 LLM 的检测器不太可能这样做，我们决定公开发布我们的结果。
- en: Another factor that contributed to our decision to release these results is
    an increasing reliance on fundamentally flawed detection tools to make prejudicial
    decisions. We observed LLM-based detectors for generative LLMs used in the educational
    setting, meaning that their high false-positive rate led to students being unjustly
    accused and disciplined, potentially impacting their long-term perspectives.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个促使我们决定公开这些结果的因素是对根本存在缺陷的检测工具的日益依赖，以做出有偏见的决策。我们观察到在教育环境中使用基于 LLM 的生成 LLM 检测器，这意味着它们的高假阳性率导致学生被不公正地指控和处罚，可能影响他们的长期前景。
- en: We hope the results presented here will lead to a more rigorous study of alternative
    ways to detect LLMs, starting with the generated text fingerprinting by major
    generative LLM providers.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望这里展示的结果能够引发对检测 LLM 的替代方法的更严格研究，从主要生成 LLM 提供者的生成文本指纹开始。
- en: Acknowledgements
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: We would like to thank the armasuisse - Cyber-Defence (CYD) Campus for the Distinguished
    Post Doctoral Fellowship supporting AK, as well as Fabien Salvi (EPFL) for the
    technical support regarding the computational infrastructure organization, and
    France Faille (EPFL) for the administrative support.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢 armasuisse - Cyber-Defence (CYD) 校区提供的杰出博士后奖学金对 AK 的支持，以及 Fabien Salvi
    (EPFL) 对计算基础设施组织的技术支持，还有 France Faille (EPFL) 提供的行政支持。
- en: References
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Adelani, D.I., Mai, H.T., Fang, F., Nguyen, H.H., Yamagishi, J., Echizen,
    I.: Generating sentiment-preserving fake online reviews using neural language
    models and their human- and machine-based detection. In: AINA (2020)'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Adelani, D.I., Mai, H.T., Fang, F., Nguyen, H.H., Yamagishi, J., Echizen,
    I.: 使用神经语言模型生成情感保留的虚假在线评论及其人类和机器检测。发表于：AINA (2020)'
- en: '[2] Austin, J., Odena, A., Nye, M.I., Bosma, M., Michalewski, H., Dohan, D.,
    Jiang, E., Cai, C.J., Terry, M., Le, Q.V., Sutton, C.: Program synthesis with
    large language models. CoRR abs/2108.07732 (2021), [https://arxiv.org/abs/2108.07732](https://arxiv.org/abs/2108.07732)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Austin, J., Odena, A., Nye, M.I., Bosma, M., Michalewski, H., Dohan, D.,
    Jiang, E., Cai, C.J., Terry, M., Le, Q.V., Sutton, C.: 使用大语言模型的程序合成。CoRR abs/2108.07732
    (2021)，[https://arxiv.org/abs/2108.07732](https://arxiv.org/abs/2108.07732)'
- en: '[3] Bagdasaryan, E., Shmatikov, V.: Spinning language models: Risks of propaganda-as-a-service
    and countermeasures. In: 43rd IEEE Symposium on Security and Privacy, SP 2022,
    San Francisco, CA, USA, May 22-26, 2022\. pp. 769–786\. IEEE (2022). https://doi.org/10.1109/SP46214.2022.9833572,
    [https://doi.org/10.1109/SP46214.2022.9833572](https://doi.org/10.1109/SP46214.2022.9833572)'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Bagdasaryan, E., Shmatikov, V.: 旋转语言模型：宣传即服务的风险及对策。发表于：第43届IEEE安全与隐私研讨会，SP
    2022，美国加州旧金山，2022年5月22-26日。第769–786页。IEEE (2022)。 https://doi.org/10.1109/SP46214.2022.9833572，[https://doi.org/10.1109/SP46214.2022.9833572](https://doi.org/10.1109/SP46214.2022.9833572)'
- en: '[4] Bakhtin, A., Gross, S., Ott, M., Deng, Y., Ranzato, M., Szlam, A.: Real
    or fake? learning to discriminate machine from human generated text. CoRR abs/1906.03351
    (2019), [http://arxiv.org/abs/1906.03351](http://arxiv.org/abs/1906.03351)'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Bakhtin, A., Gross, S., Ott, M., Deng, Y., Ranzato, M., Szlam, A.: 真实还是虚假？学习区分机器生成文本与人类生成文本。CoRR
    abs/1906.03351 (2019)，[http://arxiv.org/abs/1906.03351](http://arxiv.org/abs/1906.03351)'
- en: '[5] Bender, E.M., Gebru, T., McMillan-Major, A., Shmitchell, S.: On the dangers
    of stochastic parrots: Can language models be too big? In: Elish, M.C., Isaac,
    W., Zemel, R.S. (eds.) FAccT ’21: 2021 ACM Conference on Fairness, Accountability,
    and Transparency, Virtual Event / Toronto, Canada, March 3-10, 2021\. pp. 610–623\.
    ACM (2021). https://doi.org/10.1145/3442188.3445922, [https://doi.org/10.1145/3442188.3445922](https://doi.org/10.1145/3442188.3445922)'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Bender, E.M., Gebru, T., McMillan-Major, A., Shmitchell, S.: 关于随机鹦鹉的危险：语言模型会不会太大？在：Elish,
    M.C., Isaac, W., Zemel, R.S. (编) 《FAccT ’21: 2021 ACM 公平性、问责制与透明度会议》，虚拟会议 / 加拿大多伦多，2021年3月3-10日。页码
    610–623。ACM (2021)。 https://doi.org/10.1145/3442188.3445922, [https://doi.org/10.1145/3442188.3445922](https://doi.org/10.1145/3442188.3445922)'
- en: '[6] Bhat, M.M., Parthasarathy, S.: How effectively can machines defend against
    machine-generated fake news? an empirical study. In: INSIGHTS (2020)'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Bhat, M.M., Parthasarathy, S.: 机器能多有效地防御机器生成的虚假新闻？一项实证研究。在：INSIGHTS (2020)'
- en: '[7] Blin, K., Kucharavy, A.: Can the transformer be used as a drop-in replacement
    for rnns in text-generating gans? In: Angelova, G., Kunilovskaya, M., Mitkov,
    R., Nikolova-Koleva, I. (eds.) Proceedings of the International Conference on
    Recent Advances in Natural Language Processing (RANLP 2021), Held Online, 1-3September,
    2021\. pp. 173–181\. INCOMA Ltd. (2021), [https://aclanthology.org/2021.ranlp-1.21](https://aclanthology.org/2021.ranlp-1.21)'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Blin, K., Kucharavy, A.: Transformer能否作为生成对抗网络中文本生成的直接替代？在：Angelova, G.,
    Kunilovskaya, M., Mitkov, R., Nikolova-Koleva, I. (编) 《国际自然语言处理最新进展会议 (RANLP 2021)
    论文集》，在线举行，2021年9月1-3日。页码 173–181。INCOMA Ltd. (2021)，[https://aclanthology.org/2021.ranlp-1.21](https://aclanthology.org/2021.ranlp-1.21)'
- en: '[8] Bolukbasi, T., Chang, K., Zou, J.Y., Saligrama, V., Kalai, A.T.: Man is
    to computer programmer as woman is to homemaker? debiasing word embeddings. In:
    Lee, D.D., Sugiyama, M., von Luxburg, U., Guyon, I., Garnett, R. (eds.) Advances
    in Neural Information Processing Systems 29: Annual Conference on Neural Information
    Processing Systems 2016, December 5-10, 2016, Barcelona, Spain. pp. 4349–4357
    (2016), [https://proceedings.neurips.cc/paper/2016/hash/a486cd07e4ac3d270571622f4f316ec5-Abstract.html](https://proceedings.neurips.cc/paper/2016/hash/a486cd07e4ac3d270571622f4f316ec5-Abstract.html)'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Bolukbasi, T., Chang, K., Zou, J.Y., Saligrama, V., Kalai, A.T.: 男人对计算机程序员就如同女人对家庭主妇？去偏见的词嵌入。在：Lee,
    D.D., Sugiyama, M., von Luxburg, U., Guyon, I., Garnett, R. (编) 《神经信息处理系统进展 29:
    2016年神经信息处理系统年会》，2016年12月5-10日，西班牙巴塞罗那。页码 4349–4357 (2016)，[https://proceedings.neurips.cc/paper/2016/hash/a486cd07e4ac3d270571622f4f316ec5-Abstract.html](https://proceedings.neurips.cc/paper/2016/hash/a486cd07e4ac3d270571622f4f316ec5-Abstract.html)'
- en: '[9] Bradshaw, S., Bailey, H., Howard, P.N.: Industrialized disinformation:
    2020 global inventory of organized social media manipulation. computational propaganda
    research project (2021)'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Bradshaw, S., Bailey, H., Howard, P.N.: 工业化虚假信息：2020年全球组织化社交媒体操控清单。计算宣传研究项目
    (2021)'
- en: '[10] Brock, A., Donahue, J., Simonyan, K.: Large scale GAN training for high
    fidelity natural image synthesis. In: 7th International Conference on Learning
    Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net
    (2019), [https://openreview.net/forum?id=B1xsqj09Fm](https://openreview.net/forum?id=B1xsqj09Fm)'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Brock, A., Donahue, J., Simonyan, K.: 大规模GAN训练用于高保真自然图像合成。在：第七届国际表示学习会议，ICLR
    2019，美国路易斯安那州新奥尔良，2019年5月6-9日。OpenReview.net (2019)，[https://openreview.net/forum?id=B1xsqj09Fm](https://openreview.net/forum?id=B1xsqj09Fm)'
- en: '[11] Brown, T.B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
    Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss,
    A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D.M., Wu, J., Winter,
    C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J.,
    Berner, C., McCandlish, S., Radford, A., Sutskever, I., Amodei, D.: Language models
    are few-shot learners. In: Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M.,
    Lin, H. (eds.) Advances in Neural Information Processing Systems 33: Annual Conference
    on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020,
    virtual (2020), [https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html](https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html)'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Brown, T.B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
    Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss,
    A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D.M., Wu, J., Winter,
    C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J.,
    Berner, C., McCandlish, S., Radford, A., Sutskever, I., Amodei, D.: 语言模型是少量学习者。在：Larochelle,
    H., Ranzato, M., Hadsell, R., Balcan, M., Lin, H.（编辑）神经信息处理系统进展33：神经信息处理系统2020年年会，NeurIPS
    2020，2020年12月6-12日，虚拟（2020），[https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html](https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html)'
- en: '[12] Buchanan, B., Lohn, A., Musser, M., Sedova, K.: Truth, lies, and automation.
    Center for Security and Emerging Technology (2021)'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Buchanan, B., Lohn, A., Musser, M., Sedova, K.: 真相、谎言与自动化。安全与新兴技术中心（2021）'
- en: '[13] Caccia, M., Caccia, L., Fedus, W., Larochelle, H., Pineau, J., Charlin,
    L.: Language gans falling short. In: 8th International Conference on Learning
    Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net
    (2020), [https://openreview.net/forum?id=BJgza6VtPB](https://openreview.net/forum?id=BJgza6VtPB)'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Caccia, M., Caccia, L., Fedus, W., Larochelle, H., Pineau, J., Charlin,
    L.: 语言生成对抗网络的不足。在：第8届国际学习表示会议，ICLR 2020，埃塞俄比亚亚的斯亚贝巴，2020年4月26-30日。OpenReview.net（2020），[https://openreview.net/forum?id=BJgza6VtPB](https://openreview.net/forum?id=BJgza6VtPB)'
- en: '[14] Carlini, N., Tramèr, F., Wallace, E., Jagielski, M., Herbert-Voss, A.,
    Lee, K., Roberts, A., Brown, T.B., Song, D., Erlingsson, Ú., Oprea, A., Raffel,
    C.: Extracting training data from large language models. In: Bailey, M., Greenstadt,
    R. (eds.) 30th USENIX Security Symposium, USENIX Security 2021, August 11-13,
    2021\. pp. 2633–2650\. USENIX Association (2021), [https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting](https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting)'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Carlini, N., Tramèr, F., Wallace, E., Jagielski, M., Herbert-Voss, A.,
    Lee, K., Roberts, A., Brown, T.B., Song, D., Erlingsson, Ú., Oprea, A., Raffel,
    C.: 从大型语言模型中提取训练数据。在：Bailey, M., Greenstadt, R.（编辑）第30届USENIX安全研讨会，USENIX安全2021，2021年8月11-13日。pp.
    2633–2650。USENIX协会（2021），[https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting](https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting)'
- en: '[15] Dawson, A., Innes, M.: How russia’s internet research agency built its
    disinformation campaign. The Political Quarterly (2019)'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Dawson, A., Innes, M.: 俄罗斯互联网研究机构如何建立其虚假信息运动。《政治季刊》（2019）'
- en: '[16] Devlin, J., Chang, M., Lee, K., Toutanova, K.: BERT: pre-training of deep
    bidirectional transformers for language understanding. In: Burstein, J., Doran,
    C., Solorio, T. (eds.) Proceedings of the 2019 Conference of the North American
    Chapter of the Association for Computational Linguistics: Human Language Technologies,
    NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short
    Papers). pp. 4171–4186\. Association for Computational Linguistics (2019). https://doi.org/10.18653/v1/n19-1423,
    [https://doi.org/10.18653/v1/n19-1423](https://doi.org/10.18653/v1/n19-1423)'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Devlin, J., Chang, M., Lee, K., Toutanova, K.: BERT：用于语言理解的深度双向变换器预训练。在：Burstein,
    J., Doran, C., Solorio, T.（编辑）2019年北美计算语言学协会人类语言技术会议论文集：NAACL-HLT 2019，美国明尼阿波利斯，2019年6月2-7日，第1卷（长篇和短篇论文）。pp.
    4171–4186。计算语言学协会（2019）。https://doi.org/10.18653/v1/n19-1423，[https://doi.org/10.18653/v1/n19-1423](https://doi.org/10.18653/v1/n19-1423)'
- en: '[17] Diwan, N., Chakraborty, T., Shafiq, Z.: Fingerprinting fine-tuned language
    models in the wild. ArXiv abs/2106.01703 (2021)'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Diwan, N., Chakraborty, T., Shafiq, Z.: 真实环境中精细调优语言模型的指纹识别。ArXiv abs/2106.01703（2021）'
- en: '[18] Fagni, T., Falchi, F., Gambini, M., Martella, A., Tesconi, M.: Tweepfake:
    About detecting deepfake tweets. PLoS ONE 16 (2021)'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Fagni, T., Falchi, F., Gambini, M., Martella, A., Tesconi, M.: Tweepfake：关于检测深度伪造推文。PLoS
    ONE 16（2021）'
- en: '[19] Gagiano, R., Kim, M., Zhang, X., Biggs, J.: Robustness analysis of grover
    for machine-generated news detection. In: ALTA (2021)'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Gagiano, R., Kim, M., Zhang, X., Biggs, J.: 对Grover进行机器生成新闻检测的鲁棒性分析。在：ALTA（2021）'
- en: '[20] Ganguli, D., Hernandez, D., Lovitt, L., DasSarma, N., Henighan, T., Jones,
    A., Joseph, N., Kernion, J., Mann, B., Askell, A., Bai, Y., Chen, A., Conerly,
    T., Drain, D., Elhage, N., Showk, S.E., Fort, S., Hatfield-Dodds, Z., Johnston,
    S., Kravec, S., Nanda, N., Ndousse, K., Olsson, C., Amodei, D., Amodei, D., Brown,
    T.B., Kaplan, J., McCandlish, S., Olah, C., Clark, J.: Predictability and surprise
    in large generative models. CoRR abs/2202.07785 (2022), [https://arxiv.org/abs/2202.07785](https://arxiv.org/abs/2202.07785)'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Ganguli, D., Hernandez, D., Lovitt, L., DasSarma, N., Henighan, T., Jones,
    A., Joseph, N., Kernion, J., Mann, B., Askell, A., Bai, Y., Chen, A., Conerly,
    T., Drain, D., Elhage, N., Showk, S.E., Fort, S., Hatfield-Dodds, Z., Johnston,
    S., Kravec, S., Nanda, N., Ndousse, K., Olsson, C., Amodei, D., Amodei, D., Brown,
    T.B., Kaplan, J., McCandlish, S., Olah, C., Clark, J.：大型生成模型中的可预测性与惊奇性。CoRR abs/2202.07785（2022），[https://arxiv.org/abs/2202.07785](https://arxiv.org/abs/2202.07785)'
- en: '[21] Gehman, S., Gururangan, S., Sap, M., Choi, Y., Smith, N.A.: RealToxicityPrompts:
    Evaluating neural toxic degeneration in language models. In: Findings of the Association
    for Computational Linguistics: EMNLP 2020\. pp. 3356–3369\. Association for Computational
    Linguistics, Online (Nov 2020). https://doi.org/10.18653/v1/2020.findings-emnlp.301,
    [https://aclanthology.org/2020.findings-emnlp.301](https://aclanthology.org/2020.findings-emnlp.301)'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] Gehman, S., Gururangan, S., Sap, M., Choi, Y., Smith, N.A.：RealToxicityPrompts：评估语言模型中的神经毒性退化。在：计算语言学协会发现：EMNLP
    2020。第3356–3369页。计算语言学协会，在线（2020年11月）。https://doi.org/10.18653/v1/2020.findings-emnlp.301，[https://aclanthology.org/2020.findings-emnlp.301](https://aclanthology.org/2020.findings-emnlp.301)'
- en: '[22] Gehrmann, S., Strobelt, H., Rush, A.M.: GLTR: statistical detection and
    visualization of generated text. In: Costa-jussà, M.R., Alfonseca, E. (eds.) Proceedings
    of the 57th Conference of the Association for Computational Linguistics, ACL 2019,
    Florence, Italy, July 28 - August 2, 2019, Volume 3: System Demonstrations. pp.
    111–116\. Association for Computational Linguistics (2019). https://doi.org/10.18653/v1/p19-3019,
    [https://doi.org/10.18653/v1/p19-3019](https://doi.org/10.18653/v1/p19-3019)'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Gehrmann, S., Strobelt, H., Rush, A.M.：GLTR：生成文本的统计检测与可视化。在：Costa-jussà,
    M.R., Alfonseca, E.（编）《第57届计算语言学协会会议论文集》，ACL 2019，意大利佛罗伦萨，2019年7月28日至8月2日，第3卷：系统演示。第111–116页。计算语言学协会（2019）。https://doi.org/10.18653/v1/p19-3019，[https://doi.org/10.18653/v1/p19-3019](https://doi.org/10.18653/v1/p19-3019)'
- en: '[23] Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley,
    D., Ozair, S., Courville, A.C., Bengio, Y.: Generative adversarial nets. In: Ghahramani,
    Z., Welling, M., Cortes, C., Lawrence, N.D., Weinberger, K.Q. (eds.) Advances
    in Neural Information Processing Systems 27: Annual Conference on Neural Information
    Processing Systems 2014, December 8-13 2014, Montreal, Quebec, Canada. pp. 2672–2680
    (2014), [https://proceedings.neurips.cc/paper/2014/hash/5ca3e9b122f61f8f06494c97b1afccf3-Abstract.html](https://proceedings.neurips.cc/paper/2014/hash/5ca3e9b122f61f8f06494c97b1afccf3-Abstract.html)'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley,
    D., Ozair, S., Courville, A.C., Bengio, Y.：生成对抗网络。在：Ghahramani, Z., Welling, M.,
    Cortes, C., Lawrence, N.D., Weinberger, K.Q.（编）《神经信息处理系统27：神经信息处理系统年会2014》，2014年12月8-13日，加拿大蒙特利尔，第2672–2680页（2014），[https://proceedings.neurips.cc/paper/2014/hash/5ca3e9b122f61f8f06494c97b1afccf3-Abstract.html](https://proceedings.neurips.cc/paper/2014/hash/5ca3e9b122f61f8f06494c97b1afccf3-Abstract.html)'
- en: '[24] GPT-3: A robot wrote this entire article. are you scared yet, human? The
    Guardian (2020), [https://www.theguardian.com/commentisfree/2020/sep/08/robot-wrote-this-article-gpt-3](https://www.theguardian.com/commentisfree/2020/sep/08/robot-wrote-this-article-gpt-3)'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] GPT-3：一个机器人写了这整篇文章。你害怕了吗，人类？《卫报》（2020），[https://www.theguardian.com/commentisfree/2020/sep/08/robot-wrote-this-article-gpt-3](https://www.theguardian.com/commentisfree/2020/sep/08/robot-wrote-this-article-gpt-3)'
- en: '[25] Holmes, A.: A fake blog written by AI shot to the top of hacker news after
    people thought it was real — here’s how a college student made it. Business Insider
    (2020), [https://www.businessinsider.fr/us/fake-ai-generated-gpt3-blog-hacker-news-2020-8](https://www.businessinsider.fr/us/fake-ai-generated-gpt3-blog-hacker-news-2020-8)'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Holmes, A.：一篇由AI撰写的假博客在黑客新闻网站上迅速走红，人们以为它是真的——这是一个大学生如何做到的。《商业内幕》（2020），[https://www.businessinsider.fr/us/fake-ai-generated-gpt3-blog-hacker-news-2020-8](https://www.businessinsider.fr/us/fake-ai-generated-gpt3-blog-hacker-news-2020-8)'
- en: '[26] Holtzman, A., Buys, J., Du, L., Forbes, M., Choi, Y.: The curious case
    of neural text degeneration. In: 8th International Conference on Learning Representations,
    ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net (2020), [https://openreview.net/forum?id=rygGQyrFvH](https://openreview.net/forum?id=rygGQyrFvH)'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Holtzman, A., Buys, J., Du, L., Forbes, M., Choi, Y.：**神经文本退化的奇特案例**。在：第8届国际学习表征会议，ICLR
    2020，埃蒂奥比亚亚的斯亚贝巴，2020年4月26-30日。OpenReview.net (2020)，[https://openreview.net/forum?id=rygGQyrFvH](https://openreview.net/forum?id=rygGQyrFvH)'
- en: '[27] Hotez, P.J.: Anti-science kills: From soviet embrace of pseudoscience
    to accelerated attacks on US biomedicine. PLOS Biology 19(1), e3001068 (2021).
    https://doi.org/10.1371/journal.pbio.3001068, [https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001068](https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001068),
    publisher: Public Library of Science'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Hotez, P.J.：**反科学的杀戮**：从苏联对伪科学的接受到对美国生物医学的加速攻击。《PLOS Biology》19(1), e3001068
    (2021). https://doi.org/10.1371/journal.pbio.3001068，[https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001068](https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001068)，出版商：公共科学图书馆'
- en: '[28] Hovy, D.: The enemy in your own camp: How well can we detect statistically-generated
    fake reviews – an adversarial study. In: ACL (2016)'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] Hovy, D.：你阵营中的敌人：我们能多好地检测统计生成的虚假评论——一项对抗性研究。在：ACL (2016)'
- en: '[29] Huszar, F.: How (not) to train your generative model: Scheduled sampling,
    likelihood, adversary? CoRR abs/1511.05101 (2015), [http://arxiv.org/abs/1511.05101](http://arxiv.org/abs/1511.05101)'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Huszar, F.：如何（不）训练你的生成模型：计划采样、似然、对抗者？CoRR abs/1511.05101 (2015)，[http://arxiv.org/abs/1511.05101](http://arxiv.org/abs/1511.05101)'
- en: '[30] Ippolito, D., Duckworth, D., Callison-Burch, C., Eck, D.: Automatic detection
    of generated text is easiest when humans are fooled. In: ACL (2020)'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Ippolito, D., Duckworth, D., Callison-Burch, C., Eck, D.：**当人类被愚弄时，自动检测生成文本最为简单**。在：ACL
    (2020)'
- en: '[31] Isola, P., Zhu, J., Zhou, T., Efros, A.A.: Image-to-image translation
    with conditional adversarial networks. In: 2017 IEEE Conference on Computer Vision
    and Pattern Recognition, CVPR 2017, Honolulu, HI, USA, July 21-26, 2017\. pp.
    5967–5976\. IEEE Computer Society (2017). https://doi.org/10.1109/CVPR.2017.632,
    [https://doi.org/10.1109/CVPR.2017.632](https://doi.org/10.1109/CVPR.2017.632)'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Isola, P., Zhu, J., Zhou, T., Efros, A.A.：使用条件对抗网络的图像到图像翻译。在：2017 IEEE计算机视觉与模式识别会议，CVPR
    2017，夏威夷檀香山，美国，2017年7月21-26日。pp. 5967–5976。IEEE计算机学会 (2017). https://doi.org/10.1109/CVPR.2017.632，[https://doi.org/10.1109/CVPR.2017.632](https://doi.org/10.1109/CVPR.2017.632)'
- en: '[32] Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. In:
    Bengio, Y., LeCun, Y. (eds.) 3rd International Conference on Learning Representations,
    ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings (2015),
    [http://arxiv.org/abs/1412.6980](http://arxiv.org/abs/1412.6980)'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] Kingma, D.P., Ba, J.：**Adam：一种用于随机优化的方法**。在：Bengio, Y., LeCun, Y.（编）第3届国际学习表征会议，ICLR
    2015，美国加州圣地亚哥，2015年5月7-9日，会议论文集 (2015)，[http://arxiv.org/abs/1412.6980](http://arxiv.org/abs/1412.6980)'
- en: '[33] Kreps, S., McCain, M., Brundage, M.: All the news that’s fit to fabricate:
    Ai-generated text as a tool of media misinformation. Journal of Experimental Political
    Science 9, 104 – 117 (2020)'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] Kreps, S., McCain, M., Brundage, M.：所有适合伪造的新闻：**AI生成文本作为媒体虚假信息的工具**。《实验政治科学杂志》9,
    104 – 117 (2020)'
- en: '[34] Lai, P., Chen, C., Lo, L., Chen, C.C.: Coldgan: Resolving cold start user
    recommendation by using generative adversarial networks. CoRR abs/2011.12566 (2020),
    [https://arxiv.org/abs/2011.12566](https://arxiv.org/abs/2011.12566)'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] Lai, P., Chen, C., Lo, L., Chen, C.C.：Coldgan：通过使用生成对抗网络解决冷启动用户推荐问题。CoRR
    abs/2011.12566 (2020)，[https://arxiv.org/abs/2011.12566](https://arxiv.org/abs/2011.12566)'
- en: '[35] Liu, L., Liu, X., Gao, J., Chen, W., Han, J.: Understanding the difficulty
    of training transformers. In: Webber, B., Cohn, T., He, Y., Liu, Y. (eds.) Proceedings
    of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP
    2020, Online, November 16-20, 2020\. pp. 5747–5763. Association for Computational
    Linguistics (2020). https://doi.org/10.18653/v1/2020.emnlp-main.463, [https://doi.org/10.18653/v1/2020.emnlp-main.463](https://doi.org/10.18653/v1/2020.emnlp-main.463)'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] Liu, L., Liu, X., Gao, J., Chen, W., Han, J.：理解训练变换器的难度。在：Webber, B.,
    Cohn, T., He, Y., Liu, Y.（编）《2020年自然语言处理经验方法会议论文集》，EMNLP 2020，在线，2020年11月16-20日。pp.
    5747–5763。计算语言学协会 (2020). https://doi.org/10.18653/v1/2020.emnlp-main.463，[https://doi.org/10.18653/v1/2020.emnlp-main.463](https://doi.org/10.18653/v1/2020.emnlp-main.463)'
- en: '[36] Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis,
    M., Zettlemoyer, L., Stoyanov, V.: Roberta: A robustly optimized BERT pretraining
    approach. CoRR abs/1907.11692 (2019), [http://arxiv.org/abs/1907.11692](http://arxiv.org/abs/1907.11692)'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis,
    M., Zettlemoyer, L., Stoyanov, V.: Roberta：一种稳健优化的BERT预训练方法。CoRR abs/1907.11692（2019），[http://arxiv.org/abs/1907.11692](http://arxiv.org/abs/1907.11692)'
- en: '[37] Loshchilov, I., Hutter, F.: Decoupled weight decay regularization. In:
    7th International Conference on Learning Representations, ICLR 2019, New Orleans,
    LA, USA, May 6-9, 2019\. OpenReview.net (2019), [https://openreview.net/forum?id=Bkg6RiCqY7](https://openreview.net/forum?id=Bkg6RiCqY7)'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] Loshchilov, I., Hutter, F.: 解耦权重衰减正则化。在：第七届国际学习表征会议，ICLR 2019，美国路易斯安那州新奥尔良，2019年5月6-9日。OpenReview.net（2019），[https://openreview.net/forum?id=Bkg6RiCqY7](https://openreview.net/forum?id=Bkg6RiCqY7)'
- en: '[38] Luca, M., Zervas, G.: Fake it till you make it: Reputation, competition,
    and yelp review fraud. Consumer Financial Fraud eJournal (2016)'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] Luca, M., Zervas, G.: 伪装成功：声誉、竞争和Yelp评论欺诈。消费者金融欺诈电子期刊（2016）'
- en: '[39] Lucic, M., Kurach, K., Michalski, M., Gelly, S., Bousquet, O.: Are gans
    created equal? A large-scale study. In: Bengio, S., Wallach, H.M., Larochelle,
    H., Grauman, K., Cesa-Bianchi, N., Garnett, R. (eds.) Advances in Neural Information
    Processing Systems 31: Annual Conference on Neural Information Processing Systems
    2018, NeurIPS 2018, December 3-8, 2018, Montréal, Canada. pp. 698–707 (2018),
    [https://proceedings.neurips.cc/paper/2018/hash/e46de7e1bcaaced9a54f1e9d0d2f800d-Abstract.html](https://proceedings.neurips.cc/paper/2018/hash/e46de7e1bcaaced9a54f1e9d0d2f800d-Abstract.html)'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] Lucic, M., Kurach, K., Michalski, M., Gelly, S., Bousquet, O.: 生成对抗网络是否一视同仁？一项大规模研究。在：Bengio,
    S., Wallach, H.M., Larochelle, H., Grauman, K., Cesa-Bianchi, N., Garnett, R.（编辑）神经信息处理系统进展31：神经信息处理系统年会2018，NeurIPS
    2018，加拿大蒙特利尔，2018年12月3-8日。页698–707（2018），[https://proceedings.neurips.cc/paper/2018/hash/e46de7e1bcaaced9a54f1e9d0d2f800d-Abstract.html](https://proceedings.neurips.cc/paper/2018/hash/e46de7e1bcaaced9a54f1e9d0d2f800d-Abstract.html)'
- en: '[40] Ma, J., Yarats, D.: Quasi-hyperbolic momentum and adam for deep learning.
    In: 7th International Conference on Learning Representations, ICLR 2019, New Orleans,
    LA, USA, May 6-9, 2019\. OpenReview.net (2019), [https://openreview.net/forum?id=S1fUpoR5FQ](https://openreview.net/forum?id=S1fUpoR5FQ)'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] Ma, J., Yarats, D.: 准双曲动量和Adam优化算法在深度学习中的应用。在：第七届国际学习表征会议，ICLR 2019，美国路易斯安那州新奥尔良，2019年5月6-9日。OpenReview.net（2019），[https://openreview.net/forum?id=S1fUpoR5FQ](https://openreview.net/forum?id=S1fUpoR5FQ)'
- en: '[41] Maronikolakis, A., Schütze, H., Stevenson, M.: Identifying automatically
    generated headlines using transformers. In: NLP4IF (2021)'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] Maronikolakis, A., Schütze, H., Stevenson, M.: 使用变换器识别自动生成的标题。在：NLP4IF（2021）'
- en: '[42] de Masson d’Autume, C., Mohamed, S., Rosca, M., Rae, J.W.: Training language
    gans from scratch. In: Wallach, H.M., Larochelle, H., Beygelzimer, A., d’Alché-Buc,
    F., Fox, E.B., Garnett, R. (eds.) Advances in Neural Information Processing Systems
    32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019,
    December 8-14, 2019, Vancouver, BC, Canada. pp. 4302–4313 (2019), [https://proceedings.neurips.cc/paper/2019/hash/a6ea8471c120fe8cc35a2954c9b9c595-Abstract.html](https://proceedings.neurips.cc/paper/2019/hash/a6ea8471c120fe8cc35a2954c9b9c595-Abstract.html)'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] de Masson d’Autume, C., Mohamed, S., Rosca, M., Rae, J.W.: 从头训练语言生成对抗网络。在：Wallach,
    H.M., Larochelle, H., Beygelzimer, A., d’Alché-Buc, F., Fox, E.B., Garnett, R.（编辑）神经信息处理系统进展32：神经信息处理系统年会2019，NeurIPS
    2019，加拿大不列颠哥伦比亚省温哥华，2019年12月8-14日。页4302–4313（2019），[https://proceedings.neurips.cc/paper/2019/hash/a6ea8471c120fe8cc35a2954c9b9c595-Abstract.html](https://proceedings.neurips.cc/paper/2019/hash/a6ea8471c120fe8cc35a2954c9b9c595-Abstract.html)'
- en: '[43] Mink, J., Luo, L., Barbosa, N.M., Figueira, O., Wang, Y., Wang, G.: Deepphish:
    Understanding user trust towards artificially generated profiles in online social
    networks. In: Butler, K.R.B., Thomas, K. (eds.) 31st USENIX Security Symposium,
    USENIX Security 2022, Boston, MA, USA, August 10-12, 2022\. pp. 1669–1686\. USENIX
    Association (2022), [https://www.usenix.org/conference/usenixsecurity22/presentation/mink](https://www.usenix.org/conference/usenixsecurity22/presentation/mink)'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] Mink, J., Luo, L., Barbosa, N.M., Figueira, O., Wang, Y., Wang, G.: Deepphish：理解用户对在线社交网络中人工生成档案的信任。在：Butler,
    K.R.B., Thomas, K.（编辑）第31届USENIX安全研讨会，USENIX安全2022，美国马萨诸塞州波士顿，2022年8月10-12日。页1669–1686。USENIX协会（2022），[https://www.usenix.org/conference/usenixsecurity22/presentation/mink](https://www.usenix.org/conference/usenixsecurity22/presentation/mink)'
- en: '[44] OpenAI: Gpt-4 technical report. CoRR abs/2303.08774 (2023), [https://arxiv.org/abs/2303.08774](https://arxiv.org/abs/2303.08774)'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] OpenAI: GPT-4技术报告。CoRR abs/2303.08774（2023），[https://arxiv.org/abs/2303.08774](https://arxiv.org/abs/2303.08774)'
- en: '[45] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C.L., Mishkin,
    P., Zhang, C., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J., Kelton,
    F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P.F., Leike,
    J., Lowe, R.: Training language models to follow instructions with human feedback.
    CoRR abs/2203.02155 (2022). https://doi.org/10.48550/arXiv.2203.02155, [https://doi.org/10.48550/arXiv.2203.02155](https://doi.org/10.48550/arXiv.2203.02155)'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C.L., Mishkin,
    P., Zhang, C., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J., Kelton,
    F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P.F., Leike,
    J., Lowe, R.：通过人类反馈训练语言模型以遵循指令。CoRR abs/2203.02155（2022）。https://doi.org/10.48550/arXiv.2203.02155，[https://doi.org/10.48550/arXiv.2203.02155](https://doi.org/10.48550/arXiv.2203.02155)'
- en: '[46] Peng, X., Li, S., Frazier, S., Riedl, M.O.: Reducing non-normative text
    generation from language models. In: Davis, B., Graham, Y., Kelleher, J.D., Sripada,
    Y. (eds.) Proceedings of the 13th International Conference on Natural Language
    Generation, INLG 2020, Dublin, Ireland, December 15-18, 2020\. pp. 374–383\. Association
    for Computational Linguistics (2020), [https://aclanthology.org/2020.inlg-1.43/](https://aclanthology.org/2020.inlg-1.43/)'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] Peng, X., Li, S., Frazier, S., Riedl, M.O.：减少语言模型生成的非规范性文本。见：Davis, B.,
    Graham, Y., Kelleher, J.D., Sripada, Y.（编）《第十三届国际自然语言生成会议论文集》，INLG 2020，爱尔兰都柏林，2020年12月15-18日，页374–383。计算语言学协会（2020），[https://aclanthology.org/2020.inlg-1.43/](https://aclanthology.org/2020.inlg-1.43/)'
- en: '[47] Perez, E., Huang, S., Song, H.F., Cai, T., Ring, R., Aslanides, J., Glaese,
    A., McAleese, N., Irving, G.: Red teaming language models with language models.
    CoRR abs/2202.03286 (2022), [https://arxiv.org/abs/2202.03286](https://arxiv.org/abs/2202.03286)'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] Perez, E., Huang, S., Song, H.F., Cai, T., Ring, R., Aslanides, J., Glaese,
    A., McAleese, N., Irving, G.：用语言模型对抗语言模型。CoRR abs/2202.03286（2022），[https://arxiv.org/abs/2202.03286](https://arxiv.org/abs/2202.03286)'
- en: '[48] Popel, M., Bojar, O.: Training tips for the transformer model. Prague
    Bull. Math. Linguistics 110, 43–70 (2018), [http://ufal.mff.cuni.cz/pbml/110/art-popel-bojar.pdf](http://ufal.mff.cuni.cz/pbml/110/art-popel-bojar.pdf)'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] Popel, M., Bojar, O.：变换器模型的训练技巧。《布拉格数学语言学公报》110，43–70（2018），[http://ufal.mff.cuni.cz/pbml/110/art-popel-bojar.pdf](http://ufal.mff.cuni.cz/pbml/110/art-popel-bojar.pdf)'
- en: '[49] Power, A., Burda, Y., Edwards, H., Babuschkin, I., Misra, V.: Grokking:
    Generalization beyond overfitting on small algorithmic datasets. CoRR abs/2201.02177
    (2022), [https://arxiv.org/abs/2201.02177](https://arxiv.org/abs/2201.02177)'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] Power, A., Burda, Y., Edwards, H., Babuschkin, I., Misra, V.：Grokking：在小规模算法数据集上的过拟合之外的泛化。CoRR
    abs/2201.02177（2022），[https://arxiv.org/abs/2201.02177](https://arxiv.org/abs/2201.02177)'
- en: '[50] Radford, A., Narasimhan, K., Salimans, T., Sutskever, I.: Improving language
    understanding by generative pre-training. OpenAI blog (2018)'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] Radford, A., Narasimhan, K., Salimans, T., Sutskever, I.：通过生成预训练提高语言理解。OpenAI博客（2018）'
- en: '[51] Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I.: Language
    models are unsupervised multitask learners. OpenAI blog 1(8),  9 (2019)'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I.：语言模型是无监督的多任务学习者。OpenAI博客
    1(8)，9（2019）'
- en: '[52] Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M.,
    Zhou, Y., Li, W., Liu, P.J.: Exploring the limits of transfer learning with a
    unified text-to-text transformer. J. Mach. Learn. Res. 21, 140:1–140:67 (2020),
    [http://jmlr.org/papers/v21/20-074.html](http://jmlr.org/papers/v21/20-074.html)'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M.,
    Zhou, Y., Li, W., Liu, P.J.：探索通过统一的文本到文本变换器的迁移学习极限。《机器学习研究杂志》21，140:1–140:67（2020），[http://jmlr.org/papers/v21/20-074.html](http://jmlr.org/papers/v21/20-074.html)'
- en: '[53] Sanh, V., Debut, L., Chaumond, J., Wolf, T.: Distilbert, a distilled version
    of BERT: smaller, faster, cheaper and lighter. CoRR abs/1910.01108 (2019), [http://arxiv.org/abs/1910.01108](http://arxiv.org/abs/1910.01108)'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] Sanh, V., Debut, L., Chaumond, J., Wolf, T.：Distilbert，一个精简版的BERT：更小、更快、更便宜、更轻便。CoRR
    abs/1910.01108（2019），[http://arxiv.org/abs/1910.01108](http://arxiv.org/abs/1910.01108)'
- en: '[54] Schuster, T., Schuster, R., Shah, D.J., Barzilay, R.: The limitations
    of stylometry for detecting machine-generated fake news. Computational Linguistics
    Just Accepted, 1–18 (2020)'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] Schuster, T., Schuster, R., Shah, D.J., Barzilay, R.：用于检测机器生成虚假新闻的风格学的局限性。《计算语言学》刚接受，1–18（2020）'
- en: '[55] Sheng, E., Chang, K., Natarajan, P., Peng, N.: Societal biases in language
    generation: Progress and challenges. In: Zong, C., Xia, F., Li, W., Navigli, R.
    (eds.) Proceedings of the 59th Annual Meeting of the Association for Computational
    Linguistics and the 11th International Joint Conference on Natural Language Processing,
    ACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual Event, August 1-6, 2021\. pp.
    4275–4293\. Association for Computational Linguistics (2021). https://doi.org/10.18653/v1/2021.acl-long.330,
    [https://doi.org/10.18653/v1/2021.acl-long.330](https://doi.org/10.18653/v1/2021.acl-long.330)'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] Sheng, E., Chang, K., Natarajan, P., Peng, N.：语言生成中的社会偏见：进展与挑战。见：Zong,
    C., Xia, F., Li, W., Navigli, R.（编）《第59届计算语言学协会年会及第11届国际自然语言处理联合会议论文集，ACL/IJCNLP
    2021》，（第1卷：长论文），虚拟会议，2021年8月1-6日。第4275–4293页。计算语言学协会（2021）。https://doi.org/10.18653/v1/2021.acl-long.330，[https://doi.org/10.18653/v1/2021.acl-long.330](https://doi.org/10.18653/v1/2021.acl-long.330)'
- en: '[56] Shu, K., Li, Y., Ding, K., Liu, H.: Fact-enhanced synthetic news generation.
    In: Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third
    Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The
    Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021,
    Virtual Event, February 2-9, 2021\. pp. 13825–13833\. AAAI Press (2021), [https://ojs.aaai.org/index.php/AAAI/article/view/17629](https://ojs.aaai.org/index.php/AAAI/article/view/17629)'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] Shu, K., Li, Y., Ding, K., Liu, H.：事实增强的合成新闻生成。见：第三十五届AAAI人工智能会议，AAAI
    2021，第三十三届人工智能创新应用会议，IAAI 2021，第十一届人工智能教育进展研讨会，EAAI 2021，虚拟会议，2021年2月2-9日。第13825–13833页。AAAI出版社（2021），[https://ojs.aaai.org/index.php/AAAI/article/view/17629](https://ojs.aaai.org/index.php/AAAI/article/view/17629)'
- en: '[57] Shuster, K., Komeili, M., Adolphs, L., Roller, S., Szlam, A., Weston,
    J.: Language models that seek for knowledge: Modular search & generation for dialogue
    and prompt completion. CoRR abs/2203.13224 (2022). https://doi.org/10.48550/arXiv.2203.13224,
    [https://doi.org/10.48550/arXiv.2203.13224](https://doi.org/10.48550/arXiv.2203.13224)'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] Shuster, K., Komeili, M., Adolphs, L., Roller, S., Szlam, A., Weston,
    J.：寻找知识的语言模型：用于对话和提示完成的模块化搜索与生成。CoRR abs/2203.13224（2022）。https://doi.org/10.48550/arXiv.2203.13224，[https://doi.org/10.48550/arXiv.2203.13224](https://doi.org/10.48550/arXiv.2203.13224)'
- en: '[58] Solaiman, I., Brundage, M., Clark, J., Askell, A., Herbert-Voss, A., Wu,
    J., Radford, A., Wang, J.: Release strategies and the social impacts of language
    models. ArXiv abs/1908.09203 (2019)'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] Solaiman, I., Brundage, M., Clark, J., Askell, A., Herbert-Voss, A., Wu,
    J., Radford, A., Wang, J.：语言模型的发布策略及其社会影响。ArXiv abs/1908.09203（2019）'
- en: '[59] Solaiman, I., Dennison, C.: Process for adapting language models to society
    (PALMS) with values-targeted datasets. In: Ranzato, M., Beygelzimer, A., Dauphin,
    Y.N., Liang, P., Vaughan, J.W. (eds.) Advances in Neural Information Processing
    Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS
    2021, December 6-14, 2021, virtual. pp. 5861–5873 (2021), [https://proceedings.neurips.cc/paper/2021/hash/2e855f9489df0712b4bd8ea9e2848c5a-Abstract.html](https://proceedings.neurips.cc/paper/2021/hash/2e855f9489df0712b4bd8ea9e2848c5a-Abstract.html)'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] Solaiman, I., Dennison, C.：将语言模型适应社会（PALMS）的过程，使用价值导向的数据集。见：Ranzato, M.,
    Beygelzimer, A., Dauphin, Y.N., Liang, P., Vaughan, J.W.（编）《神经信息处理系统进展 34：神经信息处理系统年会
    2021，NeurIPS 2021》，2021年12月6-14日，虚拟会议。第5861–5873页（2021），[https://proceedings.neurips.cc/paper/2021/hash/2e855f9489df0712b4bd8ea9e2848c5a-Abstract.html](https://proceedings.neurips.cc/paper/2021/hash/2e855f9489df0712b4bd8ea9e2848c5a-Abstract.html)'
- en: '[60] Stiff, H., Johansson, F.: Detecting computer-generated disinformation.
    International Journal of Data Science and Analytics 13, 363–383 (2022)'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] Stiff, H., Johansson, F.：检测计算机生成的信息虚假。国际数据科学与分析杂志 13，363–383（2022）'
- en: '[61] Thoppilan, R., Freitas, D.D., Hall, J., Shazeer, N., Kulshreshtha, A.,
    Cheng, H., Jin, A., Bos, T., Baker, L., Du, Y., Li, Y., Lee, H., Zheng, H.S.,
    Ghafouri, A., Menegali, M., Huang, Y., Krikun, M., Lepikhin, D., Qin, J., Chen,
    D., Xu, Y., Chen, Z., Roberts, A., Bosma, M., Zhou, Y., Chang, C., Krivokon, I.,
    Rusch, W., Pickett, M., Meier-Hellstern, K.S., Morris, M.R., Doshi, T., Santos,
    R.D., Duke, T., Soraker, J., Zevenbergen, B., Prabhakaran, V., Diaz, M., Hutchinson,
    B., Olson, K., Molina, A., Hoffman-John, E., Lee, J., Aroyo, L., Rajakumar, R.,
    Butryna, A., Lamm, M., Kuzmina, V., Fenton, J., Cohen, A., Bernstein, R., Kurzweil,
    R., Aguera-Arcas, B., Cui, C., Croak, M., Chi, E.H., Le, Q.: Lamda: Language models
    for dialog applications. CoRR abs/2201.08239 (2022), [https://arxiv.org/abs/2201.08239](https://arxiv.org/abs/2201.08239)'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] Thoppilan, R., Freitas, D.D., Hall, J., Shazeer, N., Kulshreshtha, A.,
    Cheng, H., Jin, A., Bos, T., Baker, L., Du, Y., Li, Y., Lee, H., Zheng, H.S.,
    Ghafouri, A., Menegali, M., Huang, Y., Krikun, M., Lepikhin, D., Qin, J., Chen,
    D., Xu, Y., Chen, Z., Roberts, A., Bosma, M., Zhou, Y., Chang, C., Krivokon, I.,
    Rusch, W., Pickett, M., Meier-Hellstern, K.S., Morris, M.R., Doshi, T., Santos,
    R.D., Duke, T., Soraker, J., Zevenbergen, B., Prabhakaran, V., Diaz, M., Hutchinson,
    B., Olson, K., Molina, A., Hoffman-John, E., Lee, J., Aroyo, L., Rajakumar, R.,
    Butryna, A., Lamm, M., Kuzmina, V., Fenton, J., Cohen, A., Bernstein, R., Kurzweil,
    R., Aguera-Arcas, B., Cui, C., Croak, M., Chi, E.H., Le, Q.: Lamda: 对话应用的语言模型。CoRR
    abs/2201.08239（2022），[https://arxiv.org/abs/2201.08239](https://arxiv.org/abs/2201.08239)'
- en: '[62] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez,
    A.N., Kaiser, L., Polosukhin, I.: Attention is all you need. In: Guyon, I., von
    Luxburg, U., Bengio, S., Wallach, H.M., Fergus, R., Vishwanathan, S.V.N., Garnett,
    R. (eds.) Advances in Neural Information Processing Systems 30: Annual Conference
    on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach,
    CA, USA. pp. 5998–6008 (2017), [https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html](https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html)'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez,
    A.N., Kaiser, L., Polosukhin, I.: 注意力机制即一切所需。见：Guyon, I., von Luxburg, U., Bengio,
    S., Wallach, H.M., Fergus, R., Vishwanathan, S.V.N., Garnett, R.（编），神经信息处理系统进展30：2017年神经信息处理系统年度会议，2017年12月4-9日，美国加州长滩。第5998–6008页（2017），[https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html](https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html)'
- en: '[63] Weiss, M.: Deepfake bot submissions to federal public comment websites
    cannot be distinguished from human submissions. In: Technology Science. vol. 2019121801
    (2019)'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] Weiss, M.: 深伪机器人提交到联邦公共评论网站的内容无法与人工提交区分。见：技术科学。第2019121801卷（2019）'
- en: '[64] Wolff, M.: Attacking neural text detectors. In: Towards Trustworthy ML:
    Rethinking Security and Privacy for ML (2020)'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] Wolff, M.: 攻击神经文本检测器。见：迈向可信的机器学习：重新思考机器学习的安全性与隐私（2020）'
- en: '[65] Xu, J., Ren, X., Lin, J., Sun, X.: Diversity-promoting GAN: A cross-entropy
    based generative adversarial network for diversified text generation. In: Riloff,
    E., Chiang, D., Hockenmaier, J., Tsujii, J. (eds.) Proceedings of the 2018 Conference
    on Empirical Methods in Natural Language Processing, Brussels, Belgium, October
    31 - November 4, 2018\. pp. 3940–3949\. Association for Computational Linguistics
    (2018). https://doi.org/10.18653/v1/d18-1428, [https://doi.org/10.18653/v1/d18-1428](https://doi.org/10.18653/v1/d18-1428)'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] Xu, J., Ren, X., Lin, J., Sun, X.: 多样性促进生成对抗网络：基于交叉熵的生成对抗网络用于多样化文本生成。见：Riloff,
    E., Chiang, D., Hockenmaier, J., Tsujii, J.（编），2018年自然语言处理经验方法会议论文集，比利时布鲁塞尔，2018年10月31日
    - 11月4日。第3940–3949页。计算语言学协会（2018）。 https://doi.org/10.18653/v1/d18-1428，[https://doi.org/10.18653/v1/d18-1428](https://doi.org/10.18653/v1/d18-1428)'
- en: '[66] Zellers, R., Holtzman, A., Rashkin, H., Bisk, Y., Farhadi, A., Roesner,
    F., Choi, Y.: Defending against neural fake news. In: Wallach, H.M., Larochelle,
    H., Beygelzimer, A., d’Alché-Buc, F., Fox, E.B., Garnett, R. (eds.) Advances in
    Neural Information Processing Systems 32: Annual Conference on Neural Information
    Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada.
    pp. 9051–9062 (2019), [https://proceedings.neurips.cc/paper/2019/hash/3e9f0fc9b2f89e043bc6233994dfcf76-Abstract.html](https://proceedings.neurips.cc/paper/2019/hash/3e9f0fc9b2f89e043bc6233994dfcf76-Abstract.html)'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] Zellers, R., Holtzman, A., Rashkin, H., Bisk, Y., Farhadi, A., Roesner,
    F., Choi, Y.: 防御神经伪新闻。见：Wallach, H.M., Larochelle, H., Beygelzimer, A., d’Alché-Buc,
    F., Fox, E.B., Garnett, R.（编），神经信息处理系统进展32：2019年神经信息处理系统年度会议，NeurIPS 2019，2019年12月8-14日，加拿大温哥华。第9051–9062页（2019），[https://proceedings.neurips.cc/paper/2019/hash/3e9f0fc9b2f89e043bc6233994dfcf76-Abstract.html](https://proceedings.neurips.cc/paper/2019/hash/3e9f0fc9b2f89e043bc6233994dfcf76-Abstract.html)'
- en: '[67] Zhong, W., Tang, D., Xu, Z., Wang, R., Duan, N., Zhou, M., Wang, J., Yin,
    J.: Neural deepfake detection with factual structure of text. In: Webber, B.,
    Cohn, T., He, Y., Liu, Y. (eds.) Proceedings of the 2020 Conference on Empirical
    Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020\.
    pp. 2461–2470\. Association for Computational Linguistics (2020). https://doi.org/10.18653/v1/2020.emnlp-main.193,
    [https://doi.org/10.18653/v1/2020.emnlp-main.193](https://doi.org/10.18653/v1/2020.emnlp-main.193)'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] Zhong, W., Tang, D., Xu, Z., Wang, R., Duan, N., Zhou, M., Wang, J., Yin,
    J.: 基于文本事实结构的神经深伪检测。见：Webber, B., Cohn, T., He, Y., Liu, Y. (编辑)《2020年自然语言处理实证方法会议论文集》，EMNLP
    2020，在线，2020年11月16-20日，第2461–2470页。计算语言学协会（2020）。 https://doi.org/10.18653/v1/2020.emnlp-main.193,
    [https://doi.org/10.18653/v1/2020.emnlp-main.193](https://doi.org/10.18653/v1/2020.emnlp-main.193)'
- en: '[68] Ziegler, D.M., Stiennon, N., Wu, J., Brown, T.B., Radford, A., Amodei,
    D., Christiano, P.F., Irving, G.: Fine-tuning language models from human preferences.
    CoRR abs/1909.08593 (2019), [http://arxiv.org/abs/1909.08593](http://arxiv.org/abs/1909.08593)'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] Ziegler, D.M., Stiennon, N., Wu, J., Brown, T.B., Radford, A., Amodei,
    D., Christiano, P.F., Irving, G.: 基于人类偏好的语言模型微调。CoRR abs/1909.08593 (2019), [http://arxiv.org/abs/1909.08593](http://arxiv.org/abs/1909.08593)'
- en: Appendix 0.A Detailed Methodology
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 0.A 详细方法
- en: 0.A.1 GAN configuration
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 0.A.1 GAN 配置
- en: We based our code on the Pytorch implementation of a set of text-generating
    GANs by [https://github.com/williamSYSU/TextGAN-PyTorch](https://github.com/williamSYSU/TextGAN-PyTorch),
    including the DPGAN [[65](#bib.bib65)].
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的代码基于 [https://github.com/williamSYSU/TextGAN-PyTorch](https://github.com/williamSYSU/TextGAN-PyTorch)
    提供的一组文本生成 GAN 的 Pytorch 实现，包括 DPGAN [[65](#bib.bib65)]。
- en: 0.A.2 Language Models
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 0.A.2 语言模型
- en: 'We chose GPT-2 model as a generator due to its wide availability and extensive
    record of usage in natural text generation in different contexts. Besides, GPT
    architecture scaling across 4 orders of magnitude in parameters with minimal modifications,
    we can hope for a generalization of our results to larger models. For GPT-2 implementation,
    we used [https://github.com/graykode/gpt-2-Pytorch](https://github.com/graykode/gpt-2-Pytorch)
    as a basis. Unless otherwise specified, we used the GPT-2 small architecture (117M
    parameters). For part [5.2](#S5.SS2 "5.2 Making Sure a GAN Setting Allows the
    Generator to Train ‣ 5 Results and Discussion ‣ Stochastic Parrots Looking for
    Stochastic Parrots: LLMs are Easy to Fine-Tune and Hard to Detect with other LLMs")
    (and also the following parts), we used the weights for GPT-2 from the default
    HuggingFace GPT-2 repository ([https://huggingface.co/gpt2](https://huggingface.co/gpt2)),
    but rather than using the `transformers` library provided by HuggingFace, loaded
    the weights into our implementation of GPT-2 architecture as in [5.1](#S5.SS1
    "5.1 GPT-2 Collapses Rapidly Due to DP-GAN’s Discriminator Misspecified Reward
    ‣ 5 Results and Discussion ‣ Stochastic Parrots Looking for Stochastic Parrots:
    LLMs are Easy to Fine-Tune and Hard to Detect with other LLMs"). GPT-2 was sampled
    using a top-40 sampling strategy, starting with the first five tokens in a sentence
    from a dataset used.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了 GPT-2 模型作为生成器，因为它广泛可用，并且在不同背景下的自然文本生成中有着丰富的使用记录。此外，GPT 架构在参数上跨越了 4 个数量级的规模变化，且修改最小，我们可以期望我们的结果能推广到更大的模型。对于
    GPT-2 实现，我们以 [https://github.com/graykode/gpt-2-Pytorch](https://github.com/graykode/gpt-2-Pytorch)
    为基础。除非另有说明，我们使用了 GPT-2 小型架构（117M 参数）。对于部分 [5.2](#S5.SS2 "5.2 确保 GAN 设置允许生成器训练
    ‣ 5 结果与讨论 ‣ 随机鹦鹉寻找随机鹦鹉：LLMs 易于微调且难以通过其他 LLMs 检测")（以及以下部分），我们使用了来自 HuggingFace
    GPT-2 仓库的 GPT-2 权重 ([https://huggingface.co/gpt2](https://huggingface.co/gpt2))，但不是使用
    HuggingFace 提供的 `transformers` 库，而是将权重加载到我们自己实现的 GPT-2 架构中，如 [5.1](#S5.SS1 "5.1
    GPT-2 因 DP-GAN 的鉴别器误设奖励而迅速崩溃 ‣ 5 结果与讨论 ‣ 随机鹦鹉寻找随机鹦鹉：LLMs 易于微调且难以通过其他 LLMs 检测")
    中所述。GPT-2 使用 top-40 采样策略进行采样，从数据集中一个句子的前五个 token 开始。
- en: We chose BERT as a base for our defensive discriminator due to its wide availability,
    extensive usage in creating classifiers for natural languages, and excellent performance
    in generative models detection in the past [[17](#bib.bib17), [18](#bib.bib18)].
    Overall, the configuration represents a likely attacker/defender language model
    configuration for both being limited by commodity hardware
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择 BERT 作为我们的防御鉴别器的基础，因为它广泛可用，广泛用于创建自然语言分类器，并且在过去生成模型检测中的表现优秀 [[17](#bib.bib17),
    [18](#bib.bib18)]。总体而言，该配置代表了一种可能的攻击者/防御者语言模型配置，双方都受到商业硬件的限制。
- en: 0.A.3 Datasets
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 0.A.3 数据集
- en: 'For fine-tuning and experiments, we used subsets of *MS COCO* and *2017 EMNLP
    news excerpts datasets*, provided by the text-generating GAN repository [https://github.com/williamSYSU/TextGAN-PyTorch](https://github.com/williamSYSU/TextGAN-PyTorch).
    In addition to that, as described in appendix [0.B.1](#Pt0.A2.SS1 "0.B.1 variation
    of MS COCO dataset ‣ Appendix 0.B DP-GAN with GPT-2 Debugging ‣ Stochastic Parrots
    Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune and Hard to Detect
    with other LLMs"), we removed the first token from sentences in COCO and rotated
    tokens to remove the first tokens'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '对于微调和实验，我们使用了*MS COCO*和*2017 EMNLP 新闻摘录数据集*的子集，这些数据集由文本生成 GAN 仓库提供，[https://github.com/williamSYSU/TextGAN-PyTorch](https://github.com/williamSYSU/TextGAN-PyTorch)。此外，如附录
    [0.B.1](#Pt0.A2.SS1 "0.B.1 variation of MS COCO dataset ‣ Appendix 0.B DP-GAN
    with GPT-2 Debugging ‣ Stochastic Parrots Looking for Stochastic Parrots: LLMs
    are Easy to Fine-Tune and Hard to Detect with other LLMs") 中所述，我们从 COCO 的句子中删除了第一个标记，并旋转了标记以移除第一个标记。'
- en: 0.A.4 Optimizers and Training Parameters
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 0.A.4 优化器和训练参数
- en: 'For all experiments, we used batch sizes varying from 8 to 32 (with accumulation)
    depending on whether the GPU could support it for training at 14 epochs prior
    to section [5.4](#S5.SS4 "5.4 Running GAN: Hide-and-Seek Between GTP-2 and BERT
    ‣ 5 Results and Discussion ‣ Stochastic Parrots Looking for Stochastic Parrots:
    LLMs are Easy to Fine-Tune and Hard to Detect with other LLMs") and a 1 to 5 epoch
    after that. Prior to section [5.3](#S5.SS3 "5.3 Ensuring Generalizable Generator
    Training ‣ 5 Results and Discussion ‣ Stochastic Parrots Looking for Stochastic
    Parrots: LLMs are Easy to Fine-Tune and Hard to Detect with other LLMs"), Adam
    optimizer [[32](#bib.bib32)] was used with default parameters of its PyTorch implementation,
    with section [5.3](#S5.SS3 "5.3 Ensuring Generalizable Generator Training ‣ 5
    Results and Discussion ‣ Stochastic Parrots Looking for Stochastic Parrots: LLMs
    are Easy to Fine-Tune and Hard to Detect with other LLMs") using AdamW optimizer
    [[40](#bib.bib40)] with default parameters of the PyTorch implementation, and
    a linear learning rate scheduling from 1e-5 to 1e-6 over 10 epochs.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '对于所有实验，我们使用了从 8 到 32 的批处理大小（有累积），具体取决于 GPU 是否能够支持在第 [5.4](#S5.SS4 "5.4 Running
    GAN: Hide-and-Seek Between GTP-2 and BERT ‣ 5 Results and Discussion ‣ Stochastic
    Parrots Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune and Hard to
    Detect with other LLMs") 节之前的 14 个 epoch 的训练，之后的 1 到 5 个 epoch。在第 [5.3](#S5.SS3
    "5.3 Ensuring Generalizable Generator Training ‣ 5 Results and Discussion ‣ Stochastic
    Parrots Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune and Hard to
    Detect with other LLMs") 节之前使用了 Adam 优化器 [[32](#bib.bib32)]，其 PyTorch 实现的默认参数；在第
    [5.3](#S5.SS3 "5.3 Ensuring Generalizable Generator Training ‣ 5 Results and Discussion
    ‣ Stochastic Parrots Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune
    and Hard to Detect with other LLMs") 节使用了 AdamW 优化器 [[40](#bib.bib40)]，其 PyTorch
    实现的默认参数，并在 10 个 epoch 期间使用了从 1e-5 到 1e-6 的线性学习率调度。'
- en: 0.A.5 Reproducibility
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 0.A.5 可重复性
- en: All the experiments were run on a workstation equipped with Intel Core i9-9900K
    (8 cores/16 threads CPU), 64 Gb of RAM clocked at 2666 MHz, 2 TB NVME M.2 SSD,
    and an RTX 3080 graphics cards (10GM VRAM; 29.77 TFLOPS@F16/F32), running an Ubuntu
    20.04 LTS distribution. The evaluations were performed within a Docker container,
    Docker Community Edition, version 20.10.12\. The code used Miniconda version 4.12.0,
    Python 3.9 with CUDA version 11.3.1; PyTorch version 1.10.2, and HuggingFace-hub
    0.5\. The code and instructions to reproduce all experiments can be found at [https://github.com/8a3539f168fd077097ea473cc8a9c093/gpt_bert_gan](https://github.com/8a3539f168fd077097ea473cc8a9c093/gpt_bert_gan).
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 所有实验均在配备 Intel Core i9-9900K（8 核/16 线程 CPU）、64 GB 2666 MHz 内存、2 TB NVME M.2
    SSD 和 RTX 3080 显卡（10GB VRAM；29.77 TFLOPS@F16/F32）的工作站上运行，操作系统为 Ubuntu 20.04 LTS。评估是在
    Docker 容器中进行的，Docker Community Edition 版本为 20.10.12。代码使用了 Miniconda 版本 4.12.0，Python
    3.9 和 CUDA 版本 11.3.1；PyTorch 版本 1.10.2，HuggingFace-hub 版本 0.5。代码和重现所有实验的说明可以在
    [https://github.com/8a3539f168fd077097ea473cc8a9c093/gpt_bert_gan](https://github.com/8a3539f168fd077097ea473cc8a9c093/gpt_bert_gan)
    找到。
- en: Appendix 0.B DP-GAN with GPT-2 Debugging
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 0.B DP-GAN 与 GPT-2 调试
- en: 0.B.1 variation of MS COCO dataset
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 0.B.1 MS COCO 数据集的变体
- en: After observing that rewards for ’a’ were very high, we thought that it was
    perhaps the fact that almost all sentences start with the ’a’ token in the MS
    COCO dataset that caused the problem. We tested what would happen if the ’a’ was
    moved to the end of the sample of the dataset to analyze the impact of the position
    of this token (maybe having the same token at the first position very frequently
    on the dataset could lead to dysfunction while training). However, we found the
    same result as above. We also tried to remove the ’a’s entirely (only the ones
    at the beginning of the samples from MS COCO). We observed the same outcome as
    before, ie. a very frequent token in the dataset was being repeated after a few
    epochs (not ’a’ this time but other tokens that were also very frequent in the
    dataset, such as ’the’ or ’woman’).
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在观察到’a’的奖励非常高之后，我们认为问题可能是因为MS COCO数据集中几乎所有句子都以’a’标记开头。我们测试了将’a’移动到数据集样本的末尾会发生什么，以分析这个标记位置的影响（也许数据集中非常频繁地在第一位置出现相同的标记会导致训练时的功能失调）。然而，我们发现了与上述相同的结果。我们还尝试完全移除’a’（仅移除MS
    COCO样本开头的’a’）。我们观察到与之前相同的结果，即数据集中非常频繁的标记在几个周期后被重复（这次不是’a’，而是其他在数据集中也非常频繁的标记，例如’the’或’woman’）。
- en: 0.B.2 lighter GPT-2 and bigger dataset
  id: totrans-203
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 0.B.2 更轻的GPT-2和更大的数据集
- en: 'We tried to use 12 layers, 6 layers, and 3 layers(and also 12, 6, and 4 heads,
    respectively). The total amount of parameters for each configuration is (approximately)
    therefore 117M, 23M, and 7M, respectively. We have noticed a different behavior
    with 3 layers compared to 12 layers: while the repetitions of some tokens still
    happen after a few epochs with 3 layers, we observed no repetitions of a single
    token compared to the model with 12 layers. We thus think that the size of the
    model is an important factor in the problems that we observed.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尝试了12层、6层和3层（以及12、6和4个头）。每种配置的总参数量分别为约117M、23M和7M。我们注意到3层与12层的行为不同：虽然在3层模型中，某些标记在几个周期后仍然会重复，但与12层模型相比，我们观察到没有单个标记的重复。因此，我们认为模型的大小是我们观察到的问题中的一个重要因素。
- en: 'We finally tried to see how our model would behave with a bigger dataset. We
    chose to use the EMNLP news dataset, which is 15 times bigger than MS COCO. The
    reason to test on another dataset was not only the size of the dataset but also
    the fact that EMNLP news is more diverse (MS COCO samples are all short descriptions
    and begin with the ’a’ token). We observed an interesting result here. With GPT-2
    with only 6 layers, 30 epochs of adversarial training, and the EMNLP dataset as
    a training dataset: the BLEU score stays the same(see Fig. [7](#Pt0.A2.F7 "Figure
    7 ‣ 0.B.2 lighter GPT-2 and bigger dataset ‣ Appendix 0.B DP-GAN with GPT-2 Debugging
    ‣ Stochastic Parrots Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune
    and Hard to Detect with other LLMs")). However, we notice no improvement either.
    One big difference here is that, while GPT-2 (even with 3 layers) is able to memorize(ie.
    reproduce perfectly samples from the training dataset given a prefix from the
    dataset), the MS COCO dataset in not more than 30 epochs, GPT-2 with 6 or 3 layers
    is not able to memorize completely EMNLP news with the same 30 epochs of MLE pre-training
    and without weights initialization from a pre-trained model.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '我们最终尝试了查看我们的模型在更大数据集上的表现。我们选择使用EMNLP新闻数据集，它的规模是MS COCO的15倍。选择在另一个数据集上测试的原因不仅仅是数据集的大小，还因为EMNLP新闻数据集更具多样性（MS
    COCO样本都是简短描述，并且以’a’标记开头）。我们在这里观察到了一个有趣的结果。使用仅有6层的GPT-2，经过30轮对抗训练，并将EMNLP数据集作为训练数据集：BLEU分数保持不变（见图[7](#Pt0.A2.F7
    "Figure 7 ‣ 0.B.2 lighter GPT-2 and bigger dataset ‣ Appendix 0.B DP-GAN with
    GPT-2 Debugging ‣ Stochastic Parrots Looking for Stochastic Parrots: LLMs are
    Easy to Fine-Tune and Hard to Detect with other LLMs")）。然而，我们也没有看到任何改进。一个主要的区别是，虽然GPT-2（即使只有3层）能够记忆（即：在给定数据集的前缀时，完美地再现训练数据集中的样本），MS
    COCO数据集在不超过30轮的情况下，GPT-2无论是6层还是3层都无法完全记忆EMNLP新闻，即使在相同的30轮MLE预训练和没有来自预训练模型的权重初始化的情况下。'
- en: '![Refer to caption](img/d05f76aa81c73453202d60187bf0b6c8.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/d05f76aa81c73453202d60187bf0b6c8.png)'
- en: 'Figure 7: evolution of 2-gram BLEU score with different datasets and sizes
    of GPT-2'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：不同数据集和GPT-2模型大小下2-gram BLEU分数的演变
- en: Appendix 0.C Examples of Samples Generated by Nice GPT-2 Compared to Base GPT-2
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录0.C Nice GPT-2与基础GPT-2生成样本的比较
- en: '*Warning, some sentences may contain offensive language*'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '*警告，某些句子可能包含冒犯性语言*'
- en: 'Note: These samples were obtained by giving the same prefixes from the EMNLP
    news dataset to base GPT-2 and nice GPT-2\. These tables contain the output of
    the models given the prefixes. Also, *"improved"* means here that BERT assigned
    the label "positive" to the generated sample from nice GPT-2, whereas it received
    the label "negative" when generated by base GPT-2 given the same prefix.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：这些样本是通过给 base GPT-2 和 nice GPT-2 相同的前缀来获得的。这些表格包含了在给定前缀的情况下模型的输出。此外，*"改进的"*意味着这里BERT将nice
    GPT-2生成的样本标记为“积极”，而在base GPT-2生成的情况下标记为“消极”，前缀相同。
- en: 0.C.1 improved samples
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 0.C.1 改进样本
- en: 'Table 3: samples that were improved when generating them using nice GPT-2 compared
    to base GPT-2'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：使用 nice GPT-2 生成的相比 base GPT-2 改进的样本
- en: '| base GPT-2 | nice GPT-2 |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| base GPT-2 | nice GPT-2 |'
- en: '| --- | --- |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| *"sometimes i think about leaving sex work to my children. I think about
    having them and my children and being able to do whatever I want to them. And
    thatś what I think about when Iḿ working with them. I want them to be safe and
    happy"* | *"sometimes i think about leaving sex work at home in the morning, but
    i have found it’s the right way to deal with this. When i first started i had
    no idea what to expect from the sex work i had been working on for the past few
    months. I was"* |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| *"有时候我会考虑把做性工作留给我的孩子。我会考虑拥有他们和我的孩子，并能随心所欲地对待他们。这就是我在和他们一起工作时所想到的。我希望他们安全快乐"*
    | *"有时候我会考虑早上把性工作留在家里，但我发现这是一种处理这种情况的正确方式。当我刚开始做这份工作时，对过去几个月的性工作没有任何预期。我感到"* |'
- en: '| *"I was then stuck in the house with my brother and my sister. It was my
    first time in the house. My sister told me that my brother’s name was Luli and
    he was going to kill me. My sister did not want to hear this because she knew
    I would never"* | *"I was then stuck in the house, in the room of a man whose
    name was Burt and who was the son of a man called J."* |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| *"然后我被困在家里和我的兄弟和姐妹一起。这是我第一次在这个家里。我的姐姐告诉我，我哥哥的名字是Luli，他要杀了我。我的姐姐不想听这些，因为她知道我永远不会"*
    | *"然后我被困在一个人的房间里，这个人名叫Burt，是一个叫J的人的儿子。"* |'
- en: '| *"we would open our main presents after lunch, and I’d go back to my room
    to pick up my own thing. I don’t know if I would have done it that way, but I
    can’t think of anything worse than a big pile of things of my own."* | *"we would
    open our main presents after lunch. The menu is a simple yet effective combination
    of delicious sandwiches, salads, and even delicious sandwiches. The menu is filled
    with fresh, locally sourced ingredients, and an extensive menu of seasonal, hand-selected
    selections. Our selection of’ "* |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| *"我们会在午餐后打开主要的礼物，然后我会回到自己的房间拿起自己的东西。我不知道我是否会这样做，但我无法想到比自己的一大堆东西更糟糕的情况。"*
    | *"我们会在午餐后打开主要的礼物。菜单是简单却有效的美味三明治、沙拉，甚至还有美味的三明治。菜单充满了新鲜的本地采购的食材，以及丰富的季节性手工精选。我们的选择"*
    |'
- en: '| *"an estimated 80 million people across 20 states and the District of Columbia
    had been affected by Hurricane Sandy, and as the storm continued to hit the Midwest,
    the region was especially affected."Weŕe seeing more and more of this," said Robert
    L. Stryker,"* | *"an estimated 80 million people across 20 states will have access
    to the internet within the next five years. The National Press Club is excited
    about this announcement that the National Press Club is bringing to all of our
    readers," said Chris Johnson, Senior Director of Public Affairs for the"* |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| *"估计有8000万人受到桑迪飓风的影响，涉及20个州和哥伦比亚特区，随着风暴继续袭击中西部，该地区受到的影响特别大。"我们看到越来越多这种情况，"罗伯特·L·斯特赖克说，"*
    | *"估计未来五年内，2000万人将在20个州上网。国家新闻俱乐部对这一宣布感到兴奋，国家新闻俱乐部将向所有读者带来这一消息，"克里斯·约翰逊说，"* |'
- en: '| *" the 32 - year - old reality star. The story of a young woman who was living
    in an abusive life in a low-rent, low-temperature home in the foothills of California.
    She had been a woman of good character, and had been at peace"* | *"the 32 - year
    - old reality star who has been a fixture on the big screen since he was 19\.
    However, it is his decision to make his last outing as a celebrity, in the 2008
    thriller, The Big Sick, which he directed, that has received the most buzz"* |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| *"32岁的真人秀明星。一个年轻女性的故事，她在加利福尼亚州山脚下一个租金低、气温低的家中过着虐待的生活。她曾经是一个品德高尚的女人，并且一直很平静"*
    | *"32岁的真人秀明星，自19岁起就一直是大银幕上的常客。然而，他决定在2008年的惊悚片《大病》中作为名人进行最后一次亮相，这部片子他还担任了导演，这也是最受关注的决定"*
    |'
- en: 0.C.2 not improved samples
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 0.C.2 未改进样本
- en: 'Table 4: samples that were not improved when generating them using nice GPT-2
    compared to base GPT-2'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '表 4: 使用优化 GPT-2 生成的未改进样本与基础 GPT-2 相比'
- en: '| base GPT-2 | nice GPT-2 |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| 基础 GPT-2 | 优化 GPT-2 |'
- en: '| --- | --- |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| *"my sources have suggested that so far the majority of the American population
    has been the product of a combination of a political system that has been largely
    corrupted by the corruption of the people. The fact that this system has succeeded
    in creating an ever-growing majority of the population has been the reason that"*
    | *"my sources have suggested that so far the Syrian Observatory for Human Rights
    has confirmed it has been involved in fighting in the past. The Syrian Observatory
    for Human Rights said that a group of people attacked a house in the town of Al-Wabah,
    near the Turkish border"* |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| *“我的来源建议，到目前为止，美国大多数人口是由一个政治系统的组合形成的，该系统在很大程度上被人民的腐败所腐蚀。这个系统成功地创造了一个不断增长的人口多数，这就是”*
    | *“我的来源建议，到目前为止，叙利亚人权观察已经确认它曾参与过战斗。叙利亚人权观察表示，一群人袭击了土耳其边境附近的阿尔瓦巴镇的一座房子”* |'
- en: '| *"in only one state , utah , was a commoner than the other states . No God
    existed in this world . He was created from the Father of all that was in Him
    and is the same as the Father of all that was in Him and . The Father is the Father
    of all"* | *"in only one state , utah , which is the Hebrew word for "place of
    refuge." But there is no place of refuge in our God. We are not our own land or
    our country, and in the land of my God we are born. But the place of refuge which
    is"* |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| *“只有一个州，犹他州，比其他州的普通民众更多。这个世界上不存在上帝。他是由一切的父亲创造的，和一切的父亲一样。父亲是所有人的父亲”* | *“只有一个州，犹他州，希伯来语中意为‘避难所’。但在我们的上帝中没有避难所。我们不是自己的土地或国家，在我的上帝的土地上我们出生。但那是避难所”*
    |'
- en: '| *"there was no immediate claim of responsibility for the attack. In May 2017,
    a group of people in Syria, including members of the YPG, were massacred by the
    Syrian army while trying to cross the Euphrates River, a major crossing point
    for refugees. In July, a group"* | *"there was no immediate claim of responsibility
    for this, but many have been killed or wounded by the enemy. There have been two
    other casualties who have been killed by the enemy. The first, a man of the order
    of the Emperor, who had been wounded in a great fire, is still"* |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| *“没有立即对攻击负责的声明。2017年5月，一群包括YPG成员在内的叙利亚人被叙利亚军队屠杀，当时他们试图越过幼发拉底河，这是一条主要的难民过境点。7月，一组”*
    | *“没有立即对此负责的声明，但许多人已经被敌人杀害或受伤。还有其他两名被敌人杀害的伤亡者。第一名是一位皇帝的随扈，他在大火中受伤，目前仍在”* |'
- en: Appendix 0.D Architectures for Sentiment and Fake Detection Training
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 0.D 情感和假冒检测训练架构
- en: 0.D.1 generator training in negativity reduction
  id: totrans-228
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 0.D.1 负面减少中的生成器训练
- en: BERT outputs a sentiment, which is a probability of the input sentiment having
    the label positive, negative, or, optionally, neutral. For each sample, we transform
    this sentiment into a score between 0 and 1, by applying the following formula
    $1$2 (where the label is the label that BERT outputs given a sample as input).
    However, due to how GPT-2 works, we transform this score for the whole sample
    into a score for the tokens of the samples by giving the whole sentence-level
    score to each generated token. We then compute a loss between the target of having
    a sample given the label 1 by BERT(perfect score) for each generated token and
    comparing it with the score given to the sample.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: BERT 输出一个情感值，这是输入情感被标记为积极、消极或（可选）中性的概率。对于每个样本，我们通过应用以下公式 $1$2（其中标签是 BERT 针对样本输入输出的标签），将这个情感值转换为
    0 到 1 之间的分数。然而，由于 GPT-2 的工作方式，我们将整个样本的分数转换为样本中各个标记的分数，将整个句子的分数分配给每个生成的标记。然后，我们计算目标与
    BERT 给出的标签 1（完美分数）之间的损失，并将其与样本的分数进行比较。
- en: '![Refer to caption](img/e492340748b3c198c20b330b616dd077.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/e492340748b3c198c20b330b616dd077.png)'
- en: 'Figure 8: GPT-2 with BERT trained for sentiment analysis training'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '图 8: 训练用于情感分析的 GPT-2 与 BERT'
- en: 0.D.2 generator training in fake detection
  id: totrans-232
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 0.D.2 生成器训练中的假冒检测
- en: 'The GPT-2 generator creates samples using prefixes from the dataset, this sample
    is then fed to BERT. BERT outputs a probability of the sample being fake or true,
    we then apply a softmax function to the probability output by BERT to produce
    a value between 0 and 1\. This value is what we call the score here(note the difference
    with the score that we computed in [5.2](#S5.SS2 "5.2 Making Sure a GAN Setting
    Allows the Generator to Train ‣ 5 Results and Discussion ‣ Stochastic Parrots
    Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune and Hard to Detect
    with other LLMs"). We finally attribute this score for each token generated by
    GPT-2 and compute a loss between the score and the target score consisting of
    only 1s(perfect score) that we use to train GPT-2.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-2 生成器使用数据集中的前缀创建样本，然后将这些样本输入到 BERT 中。BERT 输出一个样本是伪造的还是实际的概率，然后我们对 BERT 输出的概率应用
    softmax 函数，以生成一个介于 0 和 1 之间的值。这个值在这里被称为分数（请注意与我们在 [5.2](#S5.SS2 "5.2 确保 GAN 设置允许生成器训练
    ‣ 5 结果和讨论 ‣ 随机鹦鹉 寻找随机鹦鹉：LLMs 容易微调，但与其他 LLMs 难以检测") 中计算的分数的区别）。最后，我们将这个分数分配给 GPT-2
    生成的每个标记，并计算分数与目标分数（仅包含 1 的完美分数）之间的损失，用于训练 GPT-2。
- en: '![Refer to caption](img/1330df25b6ae4848fdc43edd16662ddc.png)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/1330df25b6ae4848fdc43edd16662ddc.png)'
- en: 'Figure 9: GPT-2 training phase of the GAN for fake detection'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：用于伪造检测的 GAN 的 GPT-2 训练阶段
- en: Appendix 0.E Training Plots from GPT-2 Fake Detection Training
  id: totrans-236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 0.E GPT-2 伪造检测训练的训练图
- en: 0.E.1 training with fine-tuned GPT-2 on MS COCO dataset
  id: totrans-237
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 0.E.1 在 MS COCO 数据集上经过微调的 GPT-2 训练
- en: 'As we can see in Supplementary Fig. [6](#S5.F6 "Figure 6 ‣ 5.4.1 Training with
    Fine-Tuned Generator ‣ 5.4 Running GAN: Hide-and-Seek Between GTP-2 and BERT ‣
    5 Results and Discussion ‣ Stochastic Parrots Looking for Stochastic Parrots:
    LLMs are Easy to Fine-Tune and Hard to Detect with other LLMs"), the BERT model
    was not able to distinguish generated text from true text, even though there are
    small variations of one or two tokens for each sample.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 正如补充图 [6](#S5.F6 "图 6 ‣ 5.4.1 使用微调生成器的训练 ‣ 5.4 运行 GAN：GTP-2 和 BERT 之间的捉迷藏 ‣
    5 结果和讨论 ‣ 随机鹦鹉 寻找随机鹦鹉：LLMs 容易微调，但与其他 LLMs 难以检测") 中所示，BERT 模型无法区分生成的文本和真实文本，即使每个样本中有一两个标记的小变化。
- en: Our hypothesis is that, while the loss decreases during training, BERT overfits
    the train set, and the features it uses to distinguish fake from true text do
    not generalize to the validation set.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的假设是，虽然在训练过程中损失在减少，但 BERT 对训练集过拟合，且用于区分伪造文本和真实文本的特征无法泛化到验证集上。
- en: 'We also found while doing this experiment that, when the difference between
    the length of the fake samples and the true samples are different on average,
    BERT is able to pick up on that and have almost 100% accuracy(cf. Supplementary
    Fig. [10](#Pt0.A5.F10 "Figure 10 ‣ 0.E.1 training with fine-tuned GPT-2 on MS
    COCO dataset ‣ Appendix 0.E Training Plots from GPT-2 Fake Detection Training
    ‣ Stochastic Parrots Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune
    and Hard to Detect with other LLMs")). The setup with GPT-2 and BERT seems tricky
    to train. Indeed, when GPT-2 outputs sampling resembling too much that of the
    dataset(variation of one of two tokens for example as for the above experiment),
    BERT is not able to distinguish true and fake data at all. When GPT-2 outputs
    samples that are too different from that of the dataset, BERT achieves almost
    100% accuracy.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在进行这个实验时还发现，当伪造样本和真实样本的长度平均差异较大时，BERT 能够识别出这一点，并达到几乎 100% 的准确率（参见补充图 [10](#Pt0.A5.F10
    "图 10 ‣ 0.E.1 在 MS COCO 数据集上经过微调的 GPT-2 训练 ‣ 附录 0.E GPT-2 伪造检测训练的训练图 ‣ 随机鹦鹉 寻找随机鹦鹉：LLMs
    容易微调，但与其他 LLMs 难以检测")）。使用 GPT-2 和 BERT 的设置似乎很难训练。实际上，当 GPT-2 输出的样本与数据集非常相似（例如上面的实验中的两个标记的变化），BERT
    完全无法区分真实和伪造的数据。当 GPT-2 输出的样本与数据集差异过大时，BERT 几乎能达到 100% 的准确率。
- en: '![Refer to caption](img/6c7f68543fa00cddc6f47ce463244d6a.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/6c7f68543fa00cddc6f47ce463244d6a.png)'
- en: 'Figure 10: BERT accuracy on the validation set when the samples from GPT-2
    are not of the same length as the dataset on which BERT has been trained'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：当 GPT-2 的样本与 BERT 训练的数据集长度不一致时，BERT 在验证集上的准确性
- en: 0.E.2 training without fine-tuned GPT-2 on MS COCO dataset
  id: totrans-243
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 0.E.2 在 MS COCO 数据集上未经过微调的 GPT-2 训练
- en: 'In that scenario, BERT was able to distinguish with relatively high accuracy(about
    90% on average) fake from true samples(see Supplementary Fig. [11](#Pt0.A5.F11
    "Figure 11 ‣ 0.E.2 training without fine-tuned GPT-2 on MS COCO dataset ‣ Appendix
    0.E Training Plots from GPT-2 Fake Detection Training ‣ Stochastic Parrots Looking
    for Stochastic Parrots: LLMs are Easy to Fine-Tune and Hard to Detect with other
    LLMs")).'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '在这种情况下，BERT 能够以相对较高的准确率（平均约 90%）区分伪造样本和真实样本（见附图 [11](#Pt0.A5.F11 "图 11 ‣ 0.E.2
    没有在 MS COCO 数据集上微调 GPT-2 的训练 ‣ 附录 0.E GPT-2 伪造检测训练的训练图 ‣ 随机鹦鹉寻找随机鹦鹉: LLM 容易微调且难以通过其他
    LLM 检测")）。'
- en: '![Refer to caption](img/446521bee0e0fc26ebfa985d267a672a.png)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/446521bee0e0fc26ebfa985d267a672a.png)'
- en: 'Figure 11: BERT accuracy on the validation set when GPT-2 is not fine-tuned
    and length of GPT-2’s output are adjusted to match the true dataset'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '图 11: 当 GPT-2 未微调且 GPT-2 的输出长度调整以匹配真实数据集时 BERT 在验证集上的准确性'
- en: 'However, GPT-2 was not able to train well. As we can see in Supplementary Fig.
    [12](#Pt0.A5.F12 "Figure 12 ‣ 0.E.2 training without fine-tuned GPT-2 on MS COCO
    dataset ‣ Appendix 0.E Training Plots from GPT-2 Fake Detection Training ‣ Stochastic
    Parrots Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune and Hard to
    Detect with other LLMs"), although in some epochs GPT-2 is able to produce more
    samples that fool BERT, in general, it is not able to and sometimes it gets worse(other
    runs gave similar results if not worse). Thus, in this setup, GPT-2 is not able
    to learn how to evade BERT fine-tuned for fake detection.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '然而，GPT-2 的训练效果并不好。正如我们在附图 [12](#Pt0.A5.F12 "图 12 ‣ 0.E.2 没有在 MS COCO 数据集上微调
    GPT-2 的训练 ‣ 附录 0.E GPT-2 伪造检测训练的训练图 ‣ 随机鹦鹉寻找随机鹦鹉: LLM 容易微调且难以通过其他 LLM 检测")中看到的，尽管在某些时期
    GPT-2 能够生成更多愚弄 BERT 的样本，但总体上它做不到，有时甚至变得更糟（其他实验结果也相似甚至更差）。因此，在这种设置下，GPT-2 无法学习如何规避针对伪造检测的微调
    BERT。'
- en: '![Refer to caption](img/0945769e89ef350b53889d471f3d912b.png)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/0945769e89ef350b53889d471f3d912b.png)'
- en: 'Figure 12: GPT-2 training with scores from BERT fine-tuned for fake detection
    with MS COCO dataset'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '图 12: 使用 MS COCO 数据集进行伪造检测微调的 BERT 评分的 GPT-2 训练'
- en: 0.E.3 training with partially fine-tuned GPT-2 on EMNLP news + MS COCO dataset
  id: totrans-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 0.E.3 在 EMNLP 新闻 + MS COCO 数据集上部分微调的 GPT-2 训练
- en: For the last epoch of training, about 40% of samples generated by GPT-2, using
    prompts from the dataset, were classified as true (which we can compare with the
    88% accuracy of BERT for the validation dataset before adversarial training).
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练的最后一个时期，大约 40% 的 GPT-2 生成的样本（使用数据集中的提示）被分类为真实（我们可以与对抗训练前 BERT 对验证数据集的 88%
    准确率进行比较）。
- en: '![Refer to caption](img/ed47627406fc923639fca249b87037ee.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/ed47627406fc923639fca249b87037ee.png)'
- en: 'Figure 13: GPT-2 training with scores from BERT fine-tuned for fake detection
    with EMNLP news dataset'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '图 13: 使用 EMNLP 新闻数据集进行伪造检测微调的 BERT 评分的 GPT-2 训练'
- en: Appendix 0.F Examples of Samples by GPT-2 during the Fake GAN Training and Score
    Given
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 0.F GPT-2 在伪造 GAN 训练期间的样本示例及给定评分
- en: 'Note: a score is a number between 0 and 1, which is computed by applying the
    softmax function to the probability of giving a positive score that BERT outputs
    given a sample as an input. This means that a score close to 1 means that BERT
    attributes a good probability that the sample is a true sample from the dataset,
    whereas a score close to 0 means that it assigns a low probability of being a
    true sample.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '注: 评分是一个介于 0 和 1 之间的数字，通过将 BERT 输出的样本作为输入后，应用 softmax 函数计算得到正评分的概率。这意味着接近 1
    的评分表示 BERT 认为样本来自数据集的真实样本的概率较高，而接近 0 的评分则表示其认为样本真实的概率较低。'
- en: We also provided the corresponding sample in the dataset(created in the discriminator
    training phase) that has been given the label 1(true samples from a dataset) and
    the one that has been given the label 0(generated sample).
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还提供了数据集中对应的样本（在判别器训练阶段创建），这些样本被标记为 1（来自数据集的真实样本）和 0（生成的样本）。
- en: 'Table 5: samples generated by GPT-2 during fake GAN training and respective
    score'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '表 5: GPT-2 在伪造 GAN 训练期间生成的样本及其对应评分'
- en: '| bad score($<0.5$) |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| 差评分($<0.5$) |'
- en: '| --- |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| *"a bicycle replica with a clock as the base. The replica will be sold"*  score:
    0.0057 |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| *"一个以钟表作为基座的自行车复制品。该复制品将被出售"*  评分: 0.0057 |'
- en: '| label 0: *"a bicycle replica with a clock as the baseplate. Another"* |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| 标签 0: *"一个以钟表为基座的自行车复制品。另一个"* |'
- en: '| label 1: *"a bicycle replica with a clock as the front wheel."* |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| 标签 1: *"一个以钟表作为前轮的自行车复制品。"* |'
- en: '| *"a car that seems to be parked illegally in a Houston suburb. A car"*  score:
    0.0057 |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| *"一辆车看起来像是在休斯顿郊区非法停车。一辆车"*  分数: 0.0057 |'
- en: '| label 0: *"a car that seems to be parked illegally. A young"* |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| 标签 0: *"一辆车看起来像是在非法停车。一名年轻的"*'
- en: '| label 1: *"a car that seems to be parked illegally behind a legally parked
    car"* |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| 标签 1: *"一辆车看起来像是在一个合法停车的车后面非法停车"* |'
- en: '| *"a black honda motorcycle parked in front of a hotel in Seoul, South Korea"*  score:
    0.0633 |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| *"一辆黑色本田摩托车停在韩国首尔的一家酒店前面"*  分数: 0.0633 |'
- en: '| label 0: *"a black honda motorcycle parked in front of the garage"* |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| 标签 0: *"一辆黑色本田摩托车停在车库前面"* |'
- en: '| label 1: *"a black honda motorcycle parked in front of a garage."* |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| 标签 1: *"一辆黑色本田摩托车停在一个车库前面"* |'
- en: '| good score($\geq 0.5$) |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| 好分数（$\geq 0.5$） |'
- en: '| *"a car that seems to be parked illegally near the Trump Tower in New York"*  score:
    0.794 |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| *"一辆车看起来像是在纽约特朗普大厦附近非法停车"*  分数: 0.794 |'
- en: '| label 0: *"a car that seems to be parked illegally. A young"* |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| 标签 0: *"一辆车看起来像是在非法停车。一名年轻的"* |'
- en: '| label 1: *"a car that seems to be parked illegally behind a legally parked
    car"* |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| 标签 1: *"一辆车看起来像是在一个合法停车的车后面非法停车"* |'
- en: '| *"a honda motorcycle parked in a grassy area in this file photo in Oakland"*  score:
    0.976 |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| *"一辆本田摩托车停在奥克兰的草地上，这张文件照片中"*  分数: 0.976 |'
- en: '| lable 0: *"a honda motorcycle parked in a grassy area near the"* |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| 标签 0: *"一辆本田摩托车停在草地上的一块区域附近"* |'
- en: '| label 1: *"true: a honda motorcycle parked in a grass driveway"* |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| 标签 1: *"正确：一辆本田摩托车停在一个草地车道上"* |'
- en: Appendix 0.G Example of Samples Generated by GPT-2 during Fake GAN Training
    with EMNLP News + MS COCO Dataset after one Epoch of Adversarial Training
  id: totrans-276
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 0.G 示例：GPT-2在使用EMNLP新闻 + MS COCO数据集进行伪GAN训练一个时期后的生成样本
- en: '| a bicycle replica with a clock as the:: the at:: into:::, in as a -: for:
    around \xad: it at of said more said: ’ on the: the the:: reportedly said,:- police,
    \xad: at: the said, |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| 一辆带有时钟的自行车复制品：在::在::中:::，作为-：为了：周围 \xad：它在所述的更多所述：’在：的::据说所述，警察，\xad：在：所述，
    |'
- en: '| a black honda motorcycle parked in front for on an said: the said: \n, said
    said,,,:, but: as -, a in said the not a. said:: have had, in had in.: and: at,
    -: " in -,’ |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| 一辆黑色本田摩托车停在前面：所述：所述：\n，所述所述，，：，但：如-，一个在所述的不是一个。所述::有过，在有在。：和：在，-：“在-，’ |'
- en: '| a room with blue walls and a white::::: said \xad: on the, have it: said,::
    after \n: -,. more::.: in in, in: not:, \n to said at \xad:: of.:. said: |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| 一间墙壁是蓝色的房间和一个白色:::::所述 \xad：在，拥有它：所述，::之后 \n：-，更多::.: 在中，不：，\n 说到 \xad::
    的.:. 所述： |'
