- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 18:35:41'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:35:41
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'AutoPureData: Automated Filtering of Web Data for LLM Fine-tuning'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AutoPureData：LLM微调的自动化网络数据过滤
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.19271](https://ar5iv.labs.arxiv.org/html/2406.19271)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2406.19271](https://ar5iv.labs.arxiv.org/html/2406.19271)
- en: Praneeth Vadlapati
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Praneeth Vadlapati
- en: praneethvad@gmail.com
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: praneethvad@gmail.com
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Up-to-date and reliable Large Language Models (LLMs) are consistently sought
    after. Typically, LLMs are trained on a fixed dataset and then deployed. However,
    the training data continually becomes outdated. Enable automatic training of AI
    using web data involves significant concerns regarding data quality and safety
    due to bias, spam, and other unsafe or unwanted text. Pure data is essential for
    producing reliable models. Training a model on impure data may result in undesirable
    outcomes. This research proposes a system that collects web data and automatically
    filters out unwanted text with the assistance of existing trusted AI models. In
    the experiment, a small sample of web data was collected and filtered, demonstrating
    the system’s effectiveness in purifying the data.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 现代且可靠的大型语言模型（LLMs）始终受到追捧。通常，LLMs 会在固定的数据集上进行训练，然后进行部署。然而，训练数据会不断过时。利用网络数据进行AI自动训练涉及到数据质量和安全性的重大问题，如偏见、垃圾邮件及其他不安全或不需要的文本。纯净的数据对于生成可靠的模型至关重要。在不纯净的数据上训练模型可能导致不理想的结果。本研究提出了一种系统，该系统通过现有的可信AI模型收集网络数据并自动过滤不需要的文本。在实验中，收集和过滤了少量网络数据，证明了该系统在净化数据方面的有效性。
- en: \faGithub
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: \faGithub
- en: '[github.com/Pro-GenAI/AutoPureData](https://github.com/Pro-GenAI/AutoPureData)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[github.com/Pro-GenAI/AutoPureData](https://github.com/Pro-GenAI/AutoPureData)'
- en: 1 Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: 1.1 Problem Statement
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1 问题陈述
- en: Millions of users interact with AI chatbots regularly. Keeping models up-to-date
    is crucial in domains where data changes frequently, such as news and academic
    research. Unfortunately, very few LLMs are continuously updated, as they do not
    integrate the latest data. Using search engines on demand is often time-consuming
    and expensive, and web data is reliable on proper filtration.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 数以百万计的用户定期与AI聊天机器人互动。在数据变化频繁的领域，如新闻和学术研究，保持模型的最新状态至关重要。不幸的是，只有极少数LLMs会持续更新，因为它们没有集成最新的数据。按需使用搜索引擎通常耗时且昂贵，而网络数据在经过适当过滤后是可靠的。
- en: This research focuses on regular automated web data collection and filtration
    to support up-to-date Responsible AI models. AI safety is crucial for the success
    of Responsible AI models. Data used for training Responsible AI models should
    be both safe and unbiased. As ”garbage in, garbage out” suggests, the input data
    for training or fine-tuning an LLM impacts the quality of the model [[1](#bib.bib1)].
    The quality of the model depends on the quality of the data used to train or fine-tune
    it. The web is a vast source of information, but its reliability varies significantly.
    Currently, organizations that train LLMs automate most of the data collection
    process but not the filtering process.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究专注于定期自动化的网络数据收集和过滤，以支持最新的负责任AI模型。AI安全性对负责任AI模型的成功至关重要。用于训练负责任AI模型的数据应当安全且无偏见。如“垃圾进，垃圾出”所示，用于训练或微调LLM的输入数据会影响模型的质量[[1](#bib.bib1)]。模型的质量取决于用于训练或微调它的数据的质量。网络是一个庞大的信息来源，但其可靠性差异显著。目前，培训LLMs的组织自动化了大部分数据收集过程，但过滤过程却未实现自动化。
- en: 1.2 Challenges with Manual-Only Data Filtering
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2 手动数据过滤的挑战
- en: Human experts are employed to filter the data manually. However, manual data
    filtering can introduce bias and errors, necessitating review by multiple experts.
    Hiring multiple human experts for data filtering is often time-consuming and expensive.
    This lengthy process can delay data preparation, preventing LLMs from staying
    up-to-date, especially when the data changes every second. The challenge is further
    compounded when the data is in multiple languages. With the speed of new information
    being created, it is essential to filter out unwanted text in an automated manner.
    This study aims to address these challenges and enhance the productivity of data
    reviewers, without intending to replace jobs.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 人工专家被雇用来手动筛选数据。然而，手动数据筛选可能引入偏见和错误，因此需要多个专家进行审查。雇佣多个人工专家进行数据筛选通常既费时又昂贵。这一冗长的过程可能会延迟数据准备，阻碍大语言模型（LLMs）保持最新状态，特别是当数据每秒钟都在变化时。当数据涉及多种语言时，挑战更为复杂。随着新信息的快速产生，以自动化方式筛选不需要的文本变得至关重要。本研究旨在解决这些挑战，提升数据审查员的生产力，而不是取代他们的工作。
- en: 1.3 Proposed Solution and Its Benefits
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3 提议的解决方案及其好处
- en: This paper proposes a system for continuous data collection and filtering to
    ensure that the dataset remains current with the latest data. NLP tasks can be
    done with the help of existing trusted LLMs [[2](#bib.bib2)]. AI safety can help
    organizations retain users and prepare for future regulatory requirements to save
    a substantial amount of money in penalties due to biased or unsafe AI models.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提出了一种持续数据收集和筛选的系统，以确保数据集保持最新。NLP任务可以借助现有的可信大语言模型[[2](#bib.bib2)]来完成。AI安全性可以帮助组织留住用户，并为未来的监管要求做好准备，从而节省因偏见或不安全的AI模型而产生的罚款。
- en: The proposed system significantly reduces the time and effort required for data
    collection and preprocessing, thereby increasing the efficiency of the data preparation
    process, which is a crucial part of the model training process. Potential applications
    of this system span various domains, including but not limited to news aggregation
    and academic research. This system is more efficient and less biased than manually
    searching online for the latest data and allows models to adapt instantly to new
    information. This project aims to ensure data quality, which is crucial for the
    success of AI models.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 提议的系统显著减少了数据收集和预处理所需的时间和精力，从而提高了数据准备过程的效率，这对于模型训练过程至关重要。该系统的潜在应用涵盖了多个领域，包括但不限于新闻聚合和学术研究。该系统比手动在线搜索最新数据更高效、更少偏见，并允许模型即时适应新信息。该项目旨在确保数据质量，这对于AI模型的成功至关重要。
- en: 2 Literature Review
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 文献综述
- en: Penedo et al. (2024) [[3](#bib.bib3)] present the FineWeb dataset with refined
    deduplicated web data suitable for training, but it does not focus on filtering
    unsafe or unwanted text. Yexiao He et al. (2024) [[4](#bib.bib4)] introduced SHED,
    a method for Automated Dataset Refinement to select the most informative data
    for training.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Penedo等（2024）[[3](#bib.bib3)] 提出了FineWeb数据集，其中包含经过精细去重的适合训练的网络数据，但它并不专注于筛选不安全或不需要的文本。Yexiao
    He等（2024）[[4](#bib.bib4)] 介绍了SHED，这是一种自动化数据集精炼的方法，用于选择最具信息量的数据进行训练。
- en: Biester et al. (2024) [[5](#bib.bib5)] introduced LLMClean, which includes automated
    data cleaning using rule-based and ML-based cleaning tools. Chen and Mueller (2023)
    [[6](#bib.bib6)] worked on automated data curation for fine-tuning.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Biester等（2024）[[5](#bib.bib5)] 介绍了LLMClean，包括基于规则和基于机器学习的自动数据清理工具。Chen和Mueller（2023）[[6](#bib.bib6)]
    研究了用于微调的自动数据策展。
- en: Existing work focuses on creating high-quality datasets by leveraging tools
    for data curation. However, existing research does not address regular automated
    filtration of diverse data, such as web data, for AI safety. This paper proposes
    a system that automates the data filtering process, thereby addressing a significant
    gap in current research. The system also filters data from untrusted sources,
    even if the data appears safe.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现有工作主要集中于通过利用数据策展工具来创建高质量的数据集。然而，现有研究没有解决对多样数据（如网络数据）进行定期自动过滤以确保AI安全的问题。本文提出了一种自动化数据筛选过程的系统，从而填补了当前研究中的一个重要空白。该系统还会过滤来自不可信来源的数据，即使这些数据看起来是安全的。
- en: 3 Experiment
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 实验
- en: 3.1 Data Collection
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 数据收集
- en: The data source for this experiment is the web, a vast source of information.
    The system utilizes refined web data from FineWeb [[7](#bib.bib7)] [[8](#bib.bib8)].
    The data originates from various websites, including news platforms. A small sample
    of 100 rows of data was collected and filtered during the experiment.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 此实验的数据来源于网络，这是一个庞大的信息源。系统利用了 FineWeb [[7](#bib.bib7)] [[8](#bib.bib8)] 提供的精炼网络数据。数据来自各种网站，包括新闻平台。在实验期间收集并过滤了
    100 行数据样本。
- en: 3.2 Data Flagging
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 数据标记
- en: The web contains a substantial amount of unwanted text. The data is flagged
    using existing trusted AI models.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 网络上包含大量不想要的文本。数据通过现有的可信 AI 模型进行标记。
- en: 3.2.1 Flagging Unsafe Text
  id: totrans-30
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 标记不安全文本
- en: 'LlamaGuard 2 [[9](#bib.bib9)] is employed to flag the following types of unsafe
    text: violent crimes, non-violent crimes, sex-related crimes, child sexual exploitation,
    specialized advice, privacy, intellectual property, indiscriminate weapons, hate
    speech, suicide & self-harm, and sexual content. According to the Model Card page
    [[9](#bib.bib9)], LlamaGuard 2 has an F-1 score of 91.5% and a False Positive
    Rate of 4%, and is noted to be superior to other popular moderation models or
    APIs.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: LlamaGuard 2 [[9](#bib.bib9)] 用于标记以下类型的不安全文本：暴力犯罪、非暴力犯罪、性相关犯罪、儿童性剥削、专业建议、隐私、知识产权、滥用武器、仇恨言论、自杀与自残以及性内容。根据模型卡页面
    [[9](#bib.bib9)]，LlamaGuard 2 的 F-1 分数为 91.5%，假阳性率为 4%，并被认为优于其他流行的内容审核模型或 API。
- en: 3.2.2 Flagging Unsafe and Unreliable Domains
  id: totrans-32
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2 标记不安全和不可靠的域名
- en: LlamaGuard 2 is also utilized to flag unsafe domains. A search engine is utilized
    to determine whether a domain is indexed. Typically, search engines do not index
    unreliable domains.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: LlamaGuard 2 还用于标记不安全的域名。使用搜索引擎来确定一个域名是否被索引。通常，搜索引擎不会索引不可靠的域名。
- en: 3.2.3 Flagging Unwanted Text Using LLM
  id: totrans-34
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.3 使用 LLM 标记不想要的文本
- en: Llama 3 (8B) [[10](#bib.bib10)] is the LLM used to flag other unwanted text
    using the provided rules. Text not flagged by LlamaGuard 2 may be flagged in this
    step. The rules are designed to filter out unwanted data. The data is flagged
    according to a list of possible flags. Llama 3 is used to identify and flag various
    forms of inappropriate content, including sensitive topics, biased information,
    religious content, extremism, lottery, scams, misleading content, advertisements,
    and adversarial attacks through data poisoning.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Llama 3 (8B) [[10](#bib.bib10)] 是用于根据提供的规则标记其他不想要的文本的 LLM。LlamaGuard 2 未标记的文本可能会在此步骤中被标记。这些规则旨在过滤掉不想要的数据。数据根据可能的标记列表进行标记。Llama
    3 用于识别和标记各种形式的不当内容，包括敏感话题、偏见信息、宗教内容、极端主义、彩票、诈骗、误导性内容、广告和通过数据投毒的对抗性攻击。
- en: 'You are a content moderator. Your task is to populate the flags column with
    one or more flags from the following set: {flags_to_detect}. Please return the
    results in CSV format and refrain from adding other text.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 你是内容审核员。你的任务是从以下集合 {flags_to_detect} 中填充标记列。请以 CSV 格式返回结果，并避免添加其他文本。
- en: 'Here is the data: {collected_web_data}'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这是数据：{collected_web_data}
- en: 'Figure 1: Prompt for flagging using an LLM'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：使用 LLM 标记的提示
- en: 3.3 Filtering the Flagged Rows
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 过滤标记的行
- en: Flagged rows have been removed from the dataset to ensure its purity.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 被标记的行已从数据集中删除，以确保其纯洁性。
- en: The following is a comprehensive flowchart of the automated data filtering process.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是自动数据过滤过程的完整流程图。
- en: Collect DataFlagging unsafe text and
    sourcesFlagging
    unreliable sources with Search EngineFlagging unwanted text
    using LLMFiltering Data
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Collect DataFlagging unsafe text and
    sourcesFlagging
    unreliable sources with Search EngineFlagging unwanted text
    using LLMFiltering Data
- en: 'Figure 2: Automated Data Filtering Process'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：自动数据过滤过程
- en: 4 Results
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 结果
- en: The reasons for removing the rows are presented in Table 1 below. The flags
    identified by the LLM are presented in Table 2 below. Some text may have been
    incorrectly flagged as unsafe during the experiment.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 删除行的原因见下表 1。LLM 识别的标记见下表 2。实验中可能有一些文本被错误标记为不安全。
- en: '| Reason | Count |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| 原因 | 计数 |'
- en: '| --- | --- |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Unsafe text | 8 |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 不安全文本 | 8 |'
- en: '| Unsafe domain | 3 |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 不安全域名 | 3 |'
- en: '| Unindexed domain | 5 |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 未索引的域名 | 5 |'
- en: '| More Flagged by LLM | 16 |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| LLM 标记更多 | 16 |'
- en: '| TOTAL | 32 |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 32 |'
- en: 'Table 1: Detection of Unwanted Rows'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：不想要的行检测
- en: '| Flag | Count |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 标记 | 计数 |'
- en: '| --- | --- |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Sensitive topic | 6 |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 敏感话题 | 6 |'
- en: '| Advertisement | 6 |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 广告 | 6 |'
- en: '| Data poisoning | 3 |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 数据投毒 | 3 |'
- en: '| Biased | 2 |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 偏见 | 2 |'
- en: '| Lottery | 1 |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 彩票 | 1 |'
- en: '| Scam | 1 |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 诈骗 | 1 |'
- en: 'Table 2: Flags by LLM'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：LLM 标记
- en: 'Note: Some rows have multiple flags.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 注：某些行有多个标记。
- en: \pie
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: \pie
- en: 'Figure 3: Distribution of Rows: Removed vs Retained'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：行分布：已删除与保留
- en: 5 Discussion
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 讨论
- en: The system demonstrated efficacy in filtering out undesired text. Observations
    indicated that the system flagged 32 rows from a sample of 100 rows. This system
    represents an experimental endeavor and serves as a proof of concept. The experiment
    marks a progressive step towards automating the data filtering process. Enhancements
    to the system can be achieved through the incorporation of additional rules and
    flags.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 该系统在过滤不需要的文本方面显示了有效性。观察显示，系统从100行样本中标记了32行。这一系统代表了一项实验性尝试，并作为概念验证。实验标志着向自动化数据过滤过程的进步。通过加入额外的规则和标记可以实现对系统的进一步改进。
- en: By automating the data filtering process, organizations stand to benefit from
    significant time and cost savings. The outputs generated by the system warrant
    further examination by human experts to ensure the integrity and impartiality
    of the data. Feedback garnered from multiple human experts could be instrumental
    in refining and improving the system. The existing manual-only data review process
    consumes more time, money, and resources than the automated data filtering process
    proposed in this research. Despite this, the manual process can still introduce
    bias and errors. Hence, this system is a step towards up-to-date Responsible AI
    Models.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 通过自动化数据过滤过程，组织可以显著节省时间和成本。系统生成的输出需要由人工专家进一步检查，以确保数据的完整性和公正性。来自多位人工专家的反馈可能对系统的改进和优化至关重要。现有的仅人工数据审查过程耗费的时间、金钱和资源要比本研究提出的自动化数据过滤过程更多。尽管如此，人工过程仍然可能引入偏差和错误。因此，该系统是迈向最新负责任AI模型的一步。
- en: 6 Conclusion
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论6
- en: The system has demonstrated its capability to filter out undesired text efficiently
    from a limited dataset of web content. This innovation holds potential for adoption
    across various organizations, aiming to augment the data review process. It is
    noteworthy that the task of flagging does not necessitate the deployment or usage
    of Large Language Models (LLMs). Alternative Natural Language Processing (NLP)
    algorithms might exist that are faster and more cost-effective.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 该系统已经展示了从有限的数据集网络内容中高效过滤不需要文本的能力。这一创新有潜力在各种组织中被采用，旨在增强数据审查过程。值得注意的是，标记任务并不需要部署或使用大型语言模型（LLMs）。可能存在其他更快、更经济的自然语言处理（NLP）算法。
- en: Expanding the system to encompass a broader array of data sources, including
    research papers and books could significantly enhance its utility. Moreover, incorporating
    multilingual support could extend the system’s applicability, catering to a global
    audience.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展系统以涵盖更广泛的数据来源，包括研究论文和书籍，可能会显著提高其实用性。此外，加入多语言支持可以扩展系统的适用性，服务于全球观众。
- en: 7 Limitations of Study
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 研究的7个局限性
- en: During the experiment, some data may be filtered out incorrectly even if the
    information is legitimate. The models used in this experiment might not be the
    best for every task. Model selection is the responsibility of the engineers for
    their specific use case. The system is designed for data in only English and automatically
    removes data in other languages without translating or evaluating the text. The
    system is designed only to experiment with a new approach to data filtering on
    a small sample of web data and is not scalable. Research on scalable, cost-effective,
    production-friendly filtering methods is yet to be conducted. The system flags
    entire rows of data if any part of the text is unwanted. A more effective approach
    could involve removing only the unwanted parts of the text. The data source used
    is only web data. Additional sources could be incorporated.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在实验过程中，即使信息是合法的，也可能会有一些数据被错误地过滤掉。实验中使用的模型可能不是每个任务的最佳选择。模型选择是工程师们针对特定用例的责任。该系统仅设计用于处理英语数据，并且会自动去除其他语言的数据，而不进行翻译或评估。该系统仅用于在小样本的网络数据上试验一种新的数据过滤方法，并不可扩展。关于可扩展、经济有效、适用于生产的过滤方法的研究尚未开展。该系统会标记整行数据，如果文本的任何部分是不需要的。更有效的方法可能涉及仅移除文本中不需要的部分。所使用的数据来源仅为网络数据。可以纳入其他来源。
- en: References
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Daoyuan Chen, Yilun Huang, Zhijian Ma, Hesen Chen, Xuchen Pan, Ce Ge, Dawei
    Gao, Yuexiang Xie, Zhaoyang Liu, Jinyang Gao, Yaliang Li, Bolin Ding, and Jingren
    Zhou. Data-juicer: A one-stop data processing system for large language models,
    2023.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Daoyuan Chen, Yilun Huang, Zhijian Ma, Hesen Chen, Xuchen Pan, Ce Ge, Dawei
    Gao, Yuexiang Xie, Zhaoyang Liu, Jinyang Gao, Yaliang Li, Bolin Ding, 和 Jingren
    Zhou。Data-juicer: 一站式数据处理系统，针对大型语言模型，2023年。'
- en: '[2] Libo Qin, Qiguang Chen, Xiachong Feng, Yang Wu, Yongheng Zhang, Yinghui
    Li, Min Li, Wanxiang Che, and Philip S. Yu. Large language models meet nlp: A
    survey, 2024.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Libo Qin、Qiguang Chen、Xiachong Feng、Yang Wu、Yongheng Zhang、Yinghui Li、Min
    Li、Wanxiang Che 和 Philip S. Yu. 大型语言模型与 NLP 的结合：综述，2024年。'
- en: '[3] Guilherme Penedo, Hynek Kydlíček, Loubna Ben allal, Anton Lozhkov, Margaret
    Mitchell, Colin Raffel, Leandro Von Werra, and Thomas Wolf. The fineweb datasets:
    Decanting the web for the finest text data at scale, 2024.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Guilherme Penedo、Hynek Kydlíček、Loubna Ben allal、Anton Lozhkov、Margaret
    Mitchell、Colin Raffel、Leandro Von Werra 和 Thomas Wolf. fineweb 数据集：从网络中提炼出最优质的文本数据，2024年。'
- en: '[4] Yexiao He, Ziyao Wang, Zheyu Shen, Guoheng Sun, Yucong Dai, Yongkai Wu,
    Hongyi Wang, and Ang Li. Shed: Shapley-based automated dataset refinement for
    instruction fine-tuning, 2024.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Yexiao He、Ziyao Wang、Zheyu Shen、Guoheng Sun、Yucong Dai、Yongkai Wu、Hongyi
    Wang 和 Ang Li. Shed：基于 Shapley 的自动化数据集精炼，用于指令微调，2024年。'
- en: '[5] Fabian Biester, Mohamed Abdelaal, and Daniel Del Gaudio. Llmclean: Context-aware
    tabular data cleaning via llm-generated ofds, 2024.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Fabian Biester、Mohamed Abdelaal 和 Daniel Del Gaudio. Llmclean：通过 LLM 生成的
    OFD 进行上下文感知的表格数据清理，2024年。'
- en: '[6] Jiuhai Chen and Jonas Mueller. Automated data curation for robust language
    model fine-tuning, 2024.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Jiuhai Chen 和 Jonas Mueller. 用于强健语言模型微调的自动数据策展，2024年。'
- en: '[7] HuggingFaceFW. fineweb (revision af075be), 2024.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] HuggingFaceFW. fineweb（修订版 af075be），2024年。'
- en: '[8] HuggingFaceFW. fineweb-edu (revision 22b0aca), 2024.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] HuggingFaceFW. fineweb-edu（修订版 22b0aca），2024年。'
- en: '[9] Llama Team. Meta llama guard 2. [https://github.com/meta-llama/PurpleLlama/blob/main/Llama-Guard2/MODEL_CARD.md](https://github.com/meta-llama/PurpleLlama/blob/main/Llama-Guard2/MODEL_CARD.md),
    2024.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Llama Team. Meta llama guard 2。[https://github.com/meta-llama/PurpleLlama/blob/main/Llama-Guard2/MODEL_CARD.md](https://github.com/meta-llama/PurpleLlama/blob/main/Llama-Guard2/MODEL_CARD.md)，2024年。'
- en: '[10] AI@Meta. Llama 3 model card. [https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md](https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md),
    2024.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] AI@Meta. Llama 3 模型卡。[https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md](https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md)，2024年。'
