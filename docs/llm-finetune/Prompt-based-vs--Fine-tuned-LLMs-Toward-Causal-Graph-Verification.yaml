- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 18:35:49'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-09-08 18:35:49'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Prompt-based vs. Fine-tuned LLMs Toward Causal Graph Verification
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于提示的LLMs与微调LLMs在因果图验证中的对比
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.16899](https://ar5iv.labs.arxiv.org/html/2406.16899)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2406.16899](https://ar5iv.labs.arxiv.org/html/2406.16899)
- en: Yuni Susanti [0009-0001-1314-0286](https://orcid.org/0009-0001-1314-0286 "ORCID
    identifier") Artificial Intelligence Lab., Fujitsu LimitedTokyoJAPAN [susanti.yuni@fujitsu.com](mailto:susanti.yuni@fujitsu.com)
     and  Nina Holsmoelle [n.holsmoelle@gmail.com](mailto:n.holsmoelle@gmail.com)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Yuni Susanti [0009-0001-1314-0286](https://orcid.org/0009-0001-1314-0286 "ORCID
    identifier") 富士通有限公司人工智能实验室东京日本 [susanti.yuni@fujitsu.com](mailto:susanti.yuni@fujitsu.com)
     以及 Nina Holsmoelle [n.holsmoelle@gmail.com](mailto:n.holsmoelle@gmail.com)
- en: Abstract.
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: 'This work aims toward an application of natural language processing (NLP) technology
    for automatic verification of causal graphs using text sources. A causal graph
    is often derived from unsupervised causal discovery methods and requires manual
    evaluation from human experts. NLP technologies, i.e., Large Language Models (LLMs)
    such as BERT (Devlin et al., [2018](#bib.bib7)) and ChatGPT, can potentially be
    used to verify the resulted causal graphs by predicting if causal relation can
    be observed between node pairs based on the textual context. In this work, we
    compare the performance of two types of NLP models: (1) Pre-trained language models
    fine-tuned for causal relation classification task (supervised) and, (2) prompt-based
    LLMs (unsupervised). Contrasted to previous studies where prompt-based LLMs work
    relatively well over a set of diverse tasks (Wei et al., [2023](#bib.bib26); Jeblick
    et al., [2022](#bib.bib13); Agrawal et al., [2022](#bib.bib2)), preliminary experiments
    on biomedical and open-domain datasets suggest that the fine-tuned models far
    outperform the prompt-based LLMs, up to 20.5 points improvement of F1 score. We
    shared the code and the pre-processed datasets.¹¹1https://github.com/littleflow3r/causal-llm'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究旨在利用自然语言处理（NLP）技术，通过文本来源对因果图进行自动验证。因果图通常源自无监督的因果发现方法，并需要人工专家进行手动评估。NLP技术，即大型语言模型（LLMs），如BERT（Devlin等，[2018](#bib.bib7)）和ChatGPT，可以通过预测节点对之间是否存在因果关系来验证结果因果图，这些预测基于文本上下文。在这项工作中，我们比较了两种类型的NLP模型的表现：（1）为因果关系分类任务微调的预训练语言模型（监督）和（2）基于提示的LLMs（无监督）。与之前的研究相比，其中基于提示的LLMs在一系列不同任务中表现相对良好（Wei等，[2023](#bib.bib26)；Jeblick等，[2022](#bib.bib13)；Agrawal等，[2022](#bib.bib2)），初步实验表明，在生物医学和开放域数据集上，微调模型的表现远超基于提示的LLMs，F1分数提高了20.5个百分点。我们分享了代码和预处理数据集。¹¹1https://github.com/littleflow3r/causal-llm
- en: 'Causal Graph, Causal Relation, Large Language Models^†^†copyright: none^†^†conference:
    ; ;'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 因果图，因果关系，大型语言模型^†^†版权：无^†^†会议：；；
- en: 1\. Introduction
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 引言
- en: One of the fundamental tasks in various disciplines of science is to find the
    underlying causal relations and make use of them. Causal discovery methods (Spirtes
    et al., [2000](#bib.bib23); Shimizu et al., [2006](#bib.bib22)) are able to estimate
    the causal structures from observational data and further generate causal graphs.
    A causal graph, as illustrated in Figure [1](#S1.F1 "Figure 1 ‣ 1\. Introduction
    ‣ Prompt-based vs. Fine-tuned LLMs Toward Causal Graph Verification"), is a directed
    graph visualizing causal relationships between the observed variables; a node
    represents a variable and an edge represents a causal relationship. As with the
    progress in the field of causal discovery, we are faced with the challenge of
    how to verify the causal graph estimated with causal discovery methods, which
    are often unsupervised. Essentially, experts are required to manually verify the
    validity of the causal graph, such as by conducting a controlled experiment. However,
    depending on the field, conducting such experiments is often expensive, or even
    infeasible due to the ethical concerns.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 各科学学科中的一项基本任务是寻找潜在的因果关系并加以利用。因果发现方法（Spirtes等，[2000](#bib.bib23)；Shimizu等，[2006](#bib.bib22)）能够从观察数据中估计因果结构并生成因果图。如图[1](#S1.F1
    "Figure 1 ‣ 1\. Introduction ‣ Prompt-based vs. Fine-tuned LLMs Toward Causal
    Graph Verification")所示，因果图是一个有向图，用于可视化观察变量之间的因果关系；一个节点代表一个变量，一个边代表一个因果关系。随着因果发现领域的进展，我们面临着如何验证使用因果发现方法估计的因果图的挑战，这些方法通常是无监督的。从本质上讲，专家需要手动验证因果图的有效性，例如通过进行对照实验。然而，根据领域的不同，进行此类实验通常成本高昂，甚至由于伦理问题而不可行。
- en: '![Refer to caption](img/b63e47e3635a1fe2c6d129599146426e.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/b63e47e3635a1fe2c6d129599146426e.png)'
- en: Figure 1\. Example of a causal graph.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1\. 因果图示例。
- en: \Description
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: \描述
- en: '[Example of a causal graph.]Example of a causal graph.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[因果图示例。]因果图示例。'
- en: 'Another method to verify a causal graph is using external knowledge such as
    text sources. Information on causality is largely dispersed in text sources, and
    they are indispensable to assist human experts in verifying the validity of causal
    graphs. However, verifying a causal graph with a large number of variables becomes
    difficult due to the rapid growth of text sources. Natural Language Processing
    (NLP) technologies, i.e., Large Language Models (LLMs) such as BERT (Devlin et al.,
    [2018](#bib.bib7)) or ChatGPT, can potentially be used to verify the causal graphs
    by predicting if a causal relation exists between the node pairs based on the
    textual context. In this work, we discuss the feasibility of applying NLP technologies
    for causal graph verification through quantitative evaluation experiments on causal
    text datasets. We investigated two types of NLP models: (1) Pre-trained language
    models fine-tuned for causal relation classification task (supervised) and, (2)
    prompt-based LLMs.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种验证因果图的方法是使用外部知识，如文本来源。因果信息在文本来源中广泛分散，它们对于帮助人类专家验证因果图的有效性是不可或缺的。然而，由于文本来源的快速增长，验证包含大量变量的因果图变得困难。自然语言处理（NLP）技术，例如
    BERT（Devlin 等，[2018](#bib.bib7)）或 ChatGPT 等大型语言模型（LLMs），可以通过预测基于文本上下文的节点对之间是否存在因果关系来验证因果图。在这项工作中，我们讨论了通过对因果文本数据集进行定量评估实验来应用
    NLP 技术进行因果图验证的可行性。我们调查了两种类型的 NLP 模型：（1）针对因果关系分类任务（监督学习）进行微调的预训练语言模型，以及（2）基于提示的
    LLM。
- en: 'To summarize, the main contributions of this work are:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，这项工作的主要贡献包括：
- en: (1)
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （1）
- en: To our knowledge, this is the first work to study the feasibility of applying
    NLP for causal graph verification, with quantitative evaluation experiments on
    causal text datasets. Specifically, we introduce prompt-based LLMs to predict
    the causal relationship between pair of entities, comparing it to supervised causal
    relation classification model.
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 据我们所知，这是第一项研究应用 NLP 进行因果图验证的可行性的工作，并且通过对因果文本数据集进行定量评估实验。具体来说，我们引入了基于提示的 LLM
    来预测实体对之间的因果关系，并将其与监督学习的因果关系分类模型进行比较。
- en: (2)
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （2）
- en: We demonstrate that prompt-based LLMs do not necessarily perform better than
    supervised model on a causal relation classification task, despite its relatively
    satisfactory performance on clinical NLP over a set of diverse tasks (Agrawal
    et al., [2022](#bib.bib2)). We also provide a discussion of why this might be
    the case, and also the limitations of this work.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们证明了，尽管基于提示的 LLM 在临床 NLP 上在一系列多样化任务中表现相对令人满意（Agrawal 等，[2022](#bib.bib2)），但它们在因果关系分类任务上的表现不一定优于监督模型。我们还讨论了可能的原因以及这项工作的局限性。
- en: 2\. Related Work
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 相关工作
- en: The research on causal relation extraction/classification from text sources
    has been done mostly in supervised setting, especially in biomedical-chemistry
    domains (Khoo et al., [2000](#bib.bib15); Bui et al., [2010](#bib.bib5); Mihăilă
    and Ananiadou, [2014](#bib.bib19); Gu et al., [2016](#bib.bib9); Reklos and Albert,
    [2022](#bib.bib21); Khetan et al., [2022](#bib.bib14)), and open-domain (Khoo
    et al., [1998](#bib.bib16); Chang and Choi, [2006](#bib.bib6); Blanco et al.,
    [2008](#bib.bib4); Balashankar et al., [2019](#bib.bib3)). The pre-training and
    fine-tuning paradigm in NLP led to state-of-the-art performance in many downstream
    tasks; likewise, most of the related works listed above fine-tune the pre-trained
    language models such as BERT (Devlin et al., [2019](#bib.bib8)), or propose some
    sort of enhancement for BERT such as the work by Su and Vijay-Shanker ([2022](#bib.bib24)).
    Their results on relation extraction on biomedical datasets has been encouraging,
    motivating us to choose the BERT models as the main baselines for our fine-tuning
    experiments.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 对于从文本源中提取/分类因果关系的研究主要是在监督设置下进行的，特别是在生物医学-化学领域（Khoo et al., [2000](#bib.bib15);
    Bui et al., [2010](#bib.bib5); Mihăilă and Ananiadou, [2014](#bib.bib19); Gu et
    al., [2016](#bib.bib9); Reklos and Albert, [2022](#bib.bib21); Khetan et al.,
    [2022](#bib.bib14)），以及开放领域（Khoo et al., [1998](#bib.bib16); Chang and Choi, [2006](#bib.bib6);
    Blanco et al., [2008](#bib.bib4); Balashankar et al., [2019](#bib.bib3)）。在自然语言处理（NLP）中，预训练和微调范式在许多下游任务中取得了最先进的表现；同样，上述大多数相关工作都对预训练的语言模型如BERT（Devlin
    et al., [2019](#bib.bib8)）进行了微调，或者提出了对BERT的某种增强，例如Su和Vijay-Shanker的工作（[2022](#bib.bib24)）。他们在生物医学数据集上的关系提取结果令人鼓舞，激励我们选择BERT模型作为微调实验的主要基准。
- en: On the other hand, recent work by Agrawal et al. ([2022](#bib.bib2)) shows that
    Large Language Models (LLMs) perform well at zero and few-shot information extraction
    from clinical text, despite not being trained specifically for the clinical domain.
    Similarly, other works (Wei et al., [2023](#bib.bib26); Jeblick et al., [2022](#bib.bib13))
    suggest that LLMs (i.e., InstructGPT (Ouyang et al., [2022](#bib.bib20)), ChatGPT,
    GPT-3.5, etc.), perform well in various downstream tasks even without tuning the
    parameters, but only with few examples as instructions/prompts. This inspires
    us to evaluate such instruction, or prompt-based LLMs, on our causal relation
    classification task. In this work, we compare the prompt-based LLMs against the
    more traditional supervised model where it is trained/fine-tuned using the training
    data for causal relation classification task.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，Agrawal et al.（[2022](#bib.bib2)）的最新研究表明，尽管大型语言模型（LLMs）并未专门针对临床领域进行训练，但在从临床文本中进行零样本和少样本信息提取方面表现良好。同样，其他研究（Wei
    et al., [2023](#bib.bib26); Jeblick et al., [2022](#bib.bib13)）建议LLMs（即InstructGPT（Ouyang
    et al., [2022](#bib.bib20)），ChatGPT，GPT-3.5等）在各种下游任务中表现良好，即使不调整参数，仅凭少量示例作为指令/提示也能取得好结果。这启发我们评估这样的指令或基于提示的LLMs在因果关系分类任务上的表现。在这项工作中，我们将基于提示的LLMs与更传统的监督模型进行比较，后者使用因果关系分类任务的训练数据进行训练/微调。
- en: 3\. Methods
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 方法
- en: Given a pair of entities $e_{1}$, i.e., variables/node pairs of the causal graph
    such as smoking and lung cancer, the task is to predict if a causal relation can
    be observed between the pair based on its textual context. Therefore, it is essentially
    a binary classification task, classifying the relation as causal or non-causal.
    A causal graph from the causal discovery method does not normally include any
    textual context. In this work, we used the data commonly used for evaluating NLP
    models for a causal relation classification task, which already includes textual
    contexts for each pairs.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一对实体 $e_{1}$，即因果图中的变量/节点对，如吸烟和肺癌，任务是根据其文本上下文预测是否可以观察到两者之间的因果关系。因此，这本质上是一个二分类任务，将关系分类为因果或非因果。因果发现方法得到的因果图通常不包含任何文本上下文。在这项工作中，我们使用了用于评估NLP模型的常见数据，这些数据已经包括了每对实体的文本上下文。
- en: 3.1\. Prompt-based LLMs
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1\. 基于提示的LLMs
- en: 'In prompt-based learning, a pre-trained language model is adapted to a specific
    task via priming on natural language prompts—pieces of text that are combined
    with an input and then fed to the language model to produce an output for that
    task (Agrawal et al., [2022](#bib.bib2)). Prompt-based learning requires the specification
    of a prompt template to be applied to the input, thus we designed two settings
    for the prompt-based LLMs experiments: (1) Single-Prompt and (2) Few-Shot Prompt
    settings, as described in the following.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于提示的学习中，通过自然语言提示对预训练语言模型进行任务适应——这些文本片段与输入组合，然后提供给语言模型以生成该任务的输出 (Agrawal et
    al., [2022](#bib.bib2))。基于提示的学习需要指定应用于输入的提示模板，因此我们为基于提示的 LLMs 实验设计了两种设置：(1) 单一提示
    和 (2) 少样本提示设置，如下所述。
- en: 3.1.1\. Single-Prompt.
  id: totrans-29
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.1\. 单一提示。
- en: In the Single-Prompt setting, we designed the prompt to directly ask the LLMs
    to answer a question about causality between a pair of entities, without providing
    any example of the training data in the prompt (i.e., zero-shot approach). For
    the pair $e_{1}$, we hand-crafted the following three prompt variations.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在单一提示设置中，我们设计了提示直接要求 LLMs 回答关于一对实体之间因果关系的问题，而不提供提示中的任何训练数据示例（即零样本方法）。对于对 $e_{1}$，我们手工制作了以下三种提示变体。
- en: (A)
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (A)
- en: 'two-choices, no-context: There is a causal relationship between $e_{1}$. Answer
    with ’True.’ or ’False.’'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 两选项，无上下文：$e_{1}$ 之间是否存在因果关系。回答‘True’ 或 ‘False’。
- en: (B)
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (B)
- en: 'two-choices, with-context: Given the following context, classify the relationship
    between $e_{1}$'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 两选项，有上下文：鉴于以下上下文，分类 $e_{1}$ 之间的关系
- en: (C)
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (C)
- en: 'three-choices, with-context: Given the cancer research-related context below,
    is there a causal relationship between $e_{1}$, answer with ’False.’ In case of
    uncertainty, answer with ’Maybe.’ In a case where there is clearly a causal relationship,
    and not just a correlation between $e_{1}$'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 三选项，有上下文：鉴于下面的癌症研究相关上下文，$e_{1}$ 之间是否存在因果关系，回答‘False’。如果不确定，回答‘Maybe’。如果存在明确的因果关系，而不仅仅是
    $e_{1}$ 之间的相关性，
- en: The LLMs are strictly forced to respond with two choices, as in variation (A)
    and (B), which is necessary for a fair comparison with the fine-tuned model. In
    variation (C), however, we allow the LLMs to return a ‘Maybe’ because occasionally
    the LLMs implies that there is not enough evidence to decide the causality. We
    skip the ‘Maybe’ response in calculating the accuracy to get the truest accuracy
    score. We also varied the prompt by including and not including the textual context
    sentence $S$ in the prompt (with-context and no-context).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 被严格要求以两种选择响应，如变体 (A) 和 (B)，这对于与微调模型的公平比较是必要的。然而，在变体 (C) 中，我们允许 LLMs 返回‘Maybe’，因为有时
    LLMs 暗示没有足够的证据来决定因果关系。我们在计算准确率时跳过‘Maybe’响应，以获得最真实的准确率分数。我们还通过包含和不包含文本上下文句子 $S$
    来改变提示（有上下文和无上下文）。
- en: 3.1.2\. Few-Shot Prompt.
  id: totrans-38
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.2\. 少样本提示。
- en: In the Few-Shot prompt setting, we designed a specific format that includes
    $n$ as the context, practically giving the LLMs guidance on how to extract and
    classify the unseen pair from the test data. Furthermore, we also add a specific
    instruction at the beginning of the prompt, as illustrated in the following example.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在少样本提示设置中，我们设计了一个特定格式，包含 $n$ 作为上下文，实际上为 LLMs 提供了如何从测试数据中提取和分类未见对的指导。此外，我们还在提示开头添加了特定的指令，如下例所示。
- en: 'Example: Illustration of the Few-Shot Prompt setting. In this example, $n$=1
    training examples is included in the prompt, with the red-marked example acts
    as the test data. The beginning of the prompt provides the instruction.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：少样本提示设置的说明。在这个例子中，提示中包含 $n$=1 个训练示例，红色标记的示例作为测试数据。提示的开头提供了指令。
- en: 'PROMPT:Given  the  context  sentence,  classify  the  relationship  between  the  entities  marked  with  e1  and  e2  as  ’causal’  or  ’non-causal’##  Context
    Sentence:  Increased  expression  of    osteopontin    contributes  to  the  progression  of    prostate  cancer  .Result:  ’e1’:  ’osteopontin’,  ’relation’:  ’causal’,  ’e2’:  ’prostate  cancer’##  Context  Sentence:  Increased  expression  of    cyclin  B1    sensitizes    prostate  cancer    cells  to  apoptosis  induced  by  chemotherapy.Result:EXPECTED  OUTPUT:’e1’:  ’cyclin  B1’,  ’relation’:  ’causal’,  ’e2’:  ’prostate  cancer’'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 'PROMPT:给定上下文句子，将标记为 e1 和 e2 的实体之间的关系分类为“因果”或“非因果”## 上下文句子：增加的  骨桥蛋白 
    表达有助于  前列腺癌  的进展。结果：‘e1’: ‘骨桥蛋白’，‘关系’: ‘因果’，‘e2’: ‘前列腺癌’## 上下文句子：增加的
     周期蛋白 B1  使  前列腺癌  细胞对化疗引起的凋亡更敏感。结果：预计输出：‘e1’: ‘周期蛋白 B1’，‘关系’:
    ‘因果’，‘e2’: ‘前列腺癌’'
- en: By inserting “¡e1¿” and “¡e2¿” to mark the location of the pair, the model technically
    only has to binary-classify the relationship between the pair. We conducted the
    Few-Shot Prompt experiment by varying the number of the training data n to be
    included in the prompt as examples. In this work, we used the official OpenAI
    API with gpt-3.5-turbo and text-davinci-003 engines.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 通过插入“¡e1¿”和“¡e2¿”来标记对的位置信息，模型实际上只需要二分类这对之间的关系。我们通过改变训练数据 n 的数量来进行 Few-Shot Prompt
    实验。在这项工作中，我们使用了官方的 OpenAI API，使用了 gpt-3.5-turbo 和 text-davinci-003 引擎。
- en: 3.2\. Fine-tuned LLMs
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2\. 微调LLM
- en: 'The pre-training of LLMs usually utilizes a great quantity of unlabeled data,
    and the fine-tuning involves training these pre-trained LLMs on a smaller dataset
    labeled with examples relevant to the target task. By exposing the model to these
    new labeled examples, the model adjusts its parameters and internal representations
    suited for the target task. In this work, we experimented with two models: (1)
    BERT (Devlin et al., [2018](#bib.bib7)) and (2) GPT models, for the fine-tuning
    experiments.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的预训练通常利用大量未标记的数据，而微调涉及在一个较小的数据集上训练这些预训练的LLM，这些数据集标记了与目标任务相关的示例。通过将模型暴露于这些新的标记示例，模型会调整其参数和内部表示以适应目标任务。在这项工作中，我们实验了两个模型：（1）BERT
    (Devlin et al., [2018](#bib.bib7)) 和（2）GPT模型，用于微调实验。
- en: 3.2.1\. Fine-tuning BERT model
  id: totrans-45
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1\. 微调 BERT 模型
- en: Figure [2](#S3.F2 "Figure 2 ‣ 3.2.1\. Fine-tuning BERT model ‣ 3.2\. Fine-tuned
    LLMs ‣ 3\. Methods ‣ Prompt-based vs. Fine-tuned LLMs Toward Causal Graph Verification")
    shows our model architecture of fine-tuning BERT pre-trained model for the causal
    relation classification task. We opt for a simple fine-tuning architecture for
    a fair comparison with the prompt-based LLMs.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [2](#S3.F2 "Figure 2 ‣ 3.2.1\. Fine-tuning BERT model ‣ 3.2\. Fine-tuned LLMs
    ‣ 3\. Methods ‣ Prompt-based vs. Fine-tuned LLMs Toward Causal Graph Verification")
    显示了我们为因果关系分类任务微调 BERT 预训练模型的模型架构。我们选择了一个简单的微调架构，以便与基于提示的 LLM 进行公平比较。
- en: For an input sequence $S$ activation function and a fully-connected layer (FC)
    to this representation to obtain the final sequence representation $H^{\prime}_{cls}$,
    as follows.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 对于输入序列 $S$ 激活函数和一个全连接层（FC），将此表示用于获得最终的序列表示 $H^{\prime}_{cls}$，如下所示。
- en: '| (1) |  | $H^{\prime}_{cls}=W_{0}(tanh(H_{cls}))+b_{0}$ |  |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| (1) |  | $H^{\prime}_{cls}=W_{0}(tanh(H_{cls}))+b_{0}$ |  |'
- en: 'We used the binary cross entropy as the loss function during the training.
    In this work, we experimented with two BERT models adapted for the biomedical
    domain: BioBERT (Lee et al., [2019](#bib.bib18)), and PubMedBERT (Gu et al., [2021](#bib.bib10)).
    BERT (base, uncased)²²2https://huggingface.co/bert-base-uncased is used for experiment
    on open-domain data. The detailed hyper-parameters and other experiment details
    are provided in our Github.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在训练过程中使用了二元交叉熵作为损失函数。在这项工作中，我们对两个适用于生物医学领域的 BERT 模型进行了实验：BioBERT (Lee et al.,
    [2019](#bib.bib18)) 和 PubMedBERT (Gu et al., [2021](#bib.bib10))。BERT (base, uncased)²²2https://huggingface.co/bert-base-uncased
    用于在开放域数据上的实验。详细的超参数和其他实验细节已在我们的 Github 上提供。
- en: '![Refer to caption](img/e6766ba19a8e0c68dc10ebd2cfb67e63.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e6766ba19a8e0c68dc10ebd2cfb67e63.png)'
- en: Figure 2\. Model architecture of the fine-tuning BERT model for causal relation
    classification task.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2\. 微调 BERT 模型用于因果关系分类任务的模型架构。
- en: \Description
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: \描述
- en: '[Model architecture]Model architecture'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[模型架构]模型架构'
- en: 3.2.2\. Fine-tuning GPT model
  id: totrans-54
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2\. 微调 GPT 模型
- en: Fine-tuning the GPT model includes formatting each training example into prompt-completion
    pair, consisting of a single input example (prompt) and its associated output
    (completion). The format of the training example is different depending on the
    use case. Our task is essentially a relation classification task; however, it
    can also be formulated as a relation extraction task between pair of entities.
    We followed the GPT fine-tuning instruction and formatted the examples into classification
    and extraction task formats, as shown in the following.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 微调GPT模型包括将每个训练示例格式化为提示-完成对，由单个输入示例（提示）及其相关输出（完成）组成。训练示例的格式根据使用情况有所不同。我们的任务本质上是关系分类任务；然而，它也可以被表述为实体对之间的关系提取任务。我们遵循了GPT微调指令，并将示例格式化为分类和提取任务格式，如下所示。
- en: 'Fine-tuning GPT: classification/extraction example format.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 微调GPT：分类/提取示例格式。
- en: '{"prompt":  "The  results  provide  evidence  for  altered  plasticity  of  synaptic  morphology  in  memory  mutants  dnc  and  rut  and  suggest  a  role...\n\n###\n\n","completion":  "  non-causal@"}{"prompt":  "The  results  provide  evidence  for  altered  plasticity  of  synaptic  morphology  in  memory  mutants  dnc  and  rut  and  suggest  a  role...\n\n###\n\n","completion":"  dnc\n  rut\n  non-causal  END@"}'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '{"prompt":  "结果提供了记忆突变体dnc和rut中突触形态可塑性改变的证据，并暗示了一个角色...\n\n###\n\n","completion":  "  非因果@"}{"prompt":  "结果提供了记忆突变体dnc和rut中突触形态可塑性改变的证据，并暗示了一个角色...\n\n###\n\n","completion":"  dnc\n  rut\n  非因果  结束@"}'
- en: GPT model fine-tuning is currently available only for some of the base models;
    in this work, we experimented with the $ada$ model for its fast training and relatively
    good performance.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: GPT模型的微调目前仅适用于一些基础模型；在这项工作中，我们使用了$ada$模型，因为它训练速度快且性能相对良好。
- en: 4\. Experiments
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 实验
- en: 4.1\. Datasets
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1\. 数据集
- en: Causality is often observed in the biomedical domain, thus we conducted the
    experiments mainly in biomedical datasets, and one open-domain dataset (SEMEVAL).
    We created a new data where two experts in biomedical research annotates the causal
    relation between genes in homo sapiens (GENE). We also modified some relation
    extraction benchmark data (DDI, COMAGC) to only include causal relation. The datasets
    are summarized in Table [1](#S4.T1 "Table 1 ‣ 4.1\. Datasets ‣ 4\. Experiments
    ‣ Prompt-based vs. Fine-tuned LLMs Toward Causal Graph Verification").
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 因为因果关系在生物医学领域中经常被观察到，所以我们主要在生物医学数据集和一个开放域数据集（SEMEVAL）中进行了实验。我们创建了一种新数据，其中两位生物医学研究专家注释了人类基因（GENE）之间的因果关系。我们还修改了一些关系提取基准数据（DDI，COMAGC），仅包含因果关系。数据集总结见表[1](#S4.T1
    "表 1 ‣ 4.1\. 数据集 ‣ 4\. 实验 ‣ 基于提示与微调LLMs对因果图验证的比较")。
- en: '| dataset | type | instances# |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 类型 | 实例数 |'
- en: '| --- | --- | --- |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| DDI (Herrero-Zazo et al., [2013](#bib.bib12)) | Biomedical/drug-drug | 33,508
    |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| DDI (Herrero-Zazo et al., [2013](#bib.bib12)) | 生物医学/药物-药物 | 33,508 |'
- en: '| COMAGC (Lee et al., [2013](#bib.bib17)) | Biomedical/gene-disease | 821 |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| COMAGC (Lee et al., [2013](#bib.bib17)) | 生物医学/基因-疾病 | 821 |'
- en: '| GENE (ours) | Biomedical/gene-gene | 789 |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| GENE (我们的) | 生物医学/基因-基因 | 789 |'
- en: '| SEMEVAL (Hendrickx et al., [2010](#bib.bib11)) | Open-domain | 10,717 |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| SEMEVAL (Hendrickx et al., [2010](#bib.bib11)) | 开放域 | 10,717 |'
- en: Table 1\. Dataset types and sizes.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1\. 数据集类型和大小。
- en: Table 2\. Experiment results. Values in bold indicates the best F1 score for
    each method and dataset. $type$ refers to the number of training data included
    in the prompt for Few-Shot setting. Values in parenthesis represent standard deviations
    of F1 scores over the 5 cross-validation test folds.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2\. 实验结果。粗体字中的值表示每种方法和数据集的最佳F1得分。$type$指的是在Few-Shot设置中包含在提示中的训练数据数量。括号中的值表示5次交叉验证测试折中的F1得分的标准偏差。
- en: '|  |  | (Biomed) COMAGC | (Biomed) DDI | (Biomed) GENE | (News) SEMEVAL |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '|  |  | (生物医学) COMAGC | (生物医学) DDI | (生物医学) GENE | (新闻) SEMEVAL |'
- en: '| Prompt-based | $type$ | P | R | F1 | P | R | F1 | P | R | F1 | P | R | F1
    |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 基于提示 | $type$ | P | R | F1 | P | R | F1 | P | R | F1 | P | R | F1 |'
- en: '| Single-Prompt | A | 28.2 | 61.0 | 38.1 (.06) | 52.2 | 25.7 | 34.3 (.02) |
    23.6 | 26.6 | 24.2 (.07) | 64.6 | 66.0 | 65.3 (.06) |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 单一提示 | A | 28.2 | 61.0 | 38.1 (.06) | 52.2 | 25.7 | 34.3 (.02) | 23.6 | 26.6
    | 24.2 (.07) | 64.6 | 66.0 | 65.3 (.06) |'
- en: '| Single-Prompt | B | 28.2 | 94.2 | 43.2 (.05) | 65.1 | 69.0 | 66.7 (.04) |
    34.3 | 59.6 | 42.3 (0.1) | 77.7 | 84.7 | 80.8 (.04) |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 单一提示 | B | 28.2 | 94.2 | 43.2 (.05) | 65.1 | 69.0 | 66.7 (.04) | 34.3 | 59.6
    | 42.3 (0.1) | 77.7 | 84.7 | 80.8 (.04) |'
- en: '| Single-Prompt | C | 48.8 | 100 | 64.2 (.14) | 52.9 | 93.2 | 67.4 (.02) |
    27.4 | 71.9 | 39.5 (.05) | 57.4 | 82.8 | 67.7 (.03) |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 单一提示 | C | 48.8 | 100 | 64.2 (.14) | 52.9 | 93.2 | 67.4 (.02) | 27.4 | 71.9
    | 39.5 (.05) | 57.4 | 82.8 | 67.7 (.03) |'
- en: '|  | $n$ |  |  |  |  |  |  |  |  |  |  |  |  |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '|  | $n$ |  |  |  |  |  |  |  |  |  |  |  |  |'
- en: '| Few-Shot Prompt | 5 | 37.2 | 83.5 | 51.0 (.03) | 100 | 37.6 | 53.1 (.15)
    | 22.1 | 25.7 | 22.7 (.28) | 100 | 46.0 | 62.7 (.06) |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| Few-Shot Prompt | 5 | 37.2 | 83.5 | 51.0 (.03) | 100 | 37.6 | 53.1 (.15)
    | 22.1 | 25.7 | 22.7 (.28) | 100 | 46.0 | 62.7 (.06) |'
- en: '| Few-Shot Prompt | 15 | 52.8 | 41.4 | 46.1 (.08) | 51.4 | 27.0 | 35.1 (.05)
    | 26.0 | 29.1 | 26.2 (.18) | 100 | 47.9 | 64.6 (.04) |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| Few-Shot Prompt | 15 | 52.8 | 41.4 | 46.1 (.08) | 51.4 | 27.0 | 35.1 (.05)
    | 26.0 | 29.1 | 26.2 (.18) | 100 | 47.9 | 64.6 (.04) |'
- en: '| Few-Shot Prompt | 20 | 50.2 | 70.4 | 57.0 (.08) | * | * | * | 31.7 | 39.5
    | 34.3 (.08) | 58.9 | 57.7 | 58.2 (.02) |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| Few-Shot Prompt | 20 | 50.2 | 70.4 | 57.0 (.08) | * | * | * | 31.7 | 39.5
    | 34.3 (.08) | 58.9 | 57.7 | 58.2 (.02) |'
- en: '| Fine-tuning |  |  |  |  |  |  |  |  |  |  |  |  |  |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 微调 |  |  |  |  |  |  |  |  |  |  |  |  |  |'
- en: '| BioBERT |  | 77.9 | 84.4 | 80.8 (.01) | 97.0 | 76.2 | 85.2 (.03) | 46.1 |
    65.2 | 53.5 (.07*) | * | * | * |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| BioBERT |  | 77.9 | 84.4 | 80.8 (.01) | 97.0 | 76.2 | 85.2 (.03) | 46.1 |
    65.2 | 53.5 (.07*) | * | * | * |'
- en: '| PubmedBERT |  | 80.7 | 87.4 | 83.9 (.03) | 93.2 | 83.3 | 87.9 (.01) | 50.6
    | 62.1 | 55.1 (.03) | * | * | * |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| PubmedBERT |  | 80.7 | 87.4 | 83.9 (.03) | 93.2 | 83.3 | 87.9 (.01) | 50.6
    | 62.1 | 55.1 (.03) | * | * | * |'
- en: '| BERT-large |  | * | * | * | * | * | * | * | * | * | 93.0 | 93.0 | 93.0 (.01)
    |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| BERT-large |  | * | * | * | * | * | * | * | * | * | 93.0 | 93.0 | 93.0 (.01)
    |'
- en: '| GPT/ada (classify) |  | 80.5 | 70.1 | 74.1 (.06) | 99.4 | 78.1 | 87.4 (.03)
    | 58.6 | 23.1 | 31.4 (.08) | 99.9 | 94.8 | 96.8 (.03) |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| GPT/ada (分类) |  | 80.5 | 70.1 | 74.1 (.06) | 99.4 | 78.1 | 87.4 (.03) | 58.6
    | 23.1 | 31.4 (.08) | 99.9 | 94.8 | 96.8 (.03) |'
- en: '| GPT/ada (extraction) |  | 75.6 | 58.1 | 65.5 (.07) | 100 | 62.9 | 77.1 (.02)
    | 52.4 | 21.2 | 30.1 (.06) | 100 | 91.9 | 95.7 (.03) |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| GPT/ada (提取) |  | 75.6 | 58.1 | 65.5 (.07) | 100 | 62.9 | 77.1 (.02) | 52.4
    | 21.2 | 30.1 (.06) | 100 | 91.9 | 95.7 (.03) |'
- en: 4.2\. Results and Discussion
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2\. 结果与讨论
- en: Table [2](#S4.T2 "Table 2 ‣ 4.1\. Datasets ‣ 4\. Experiments ‣ Prompt-based
    vs. Fine-tuned LLMs Toward Causal Graph Verification") summarizes the experiment
    results. Precision (P), Recall (R), and F1-score (F1) metrics are employed, and
    as with the general practice in binary classification task, the metrics are calculated
    on the non-negative class. We apply 5-fold cross-validation and the scores are
    averaged. We report the standard deviation values of the F1 scores over the 5-folds
    as shown in parenthesis in Table [2](#S4.T2 "Table 2 ‣ 4.1\. Datasets ‣ 4\. Experiments
    ‣ Prompt-based vs. Fine-tuned LLMs Toward Causal Graph Verification").
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 表[2](#S4.T2 "表 2 ‣ 4.1\. 数据集 ‣ 4\. 实验 ‣ 基于提示与微调的LLMs在因果图验证中的比较")总结了实验结果。采用了精度（P）、召回率（R）和F1分数（F1）指标，并且与二分类任务中的常规做法一样，这些指标是在非负类上计算的。我们应用了5折交叉验证，得分进行了平均。我们报告了5折中的F1分数的标准差值，如表[2](#S4.T2
    "表 2 ‣ 4.1\. 数据集 ‣ 4\. 实验 ‣ 基于提示与微调的LLMs在因果图验证中的比较")中的括号所示。
- en: To sum up, the results suggest that the fine-tuned models far outperform the
    prompt-based LLMs in predicting the causal relationship between the entity pairs
    in all of the datasets used in this work. This contrasted with the previous studies (Wei
    et al., [2023](#bib.bib26); Jeblick et al., [2022](#bib.bib13)) where LLMs perform
    relatively well, if not better than the fine-tuned models in various tasks including
    in clinical NLP tasks (Agrawal et al., [2022](#bib.bib2)). We conducted error
    analysis and outlined the following discussion.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 总结而言，结果表明，在本研究使用的所有数据集中，微调模型在预测实体对之间的因果关系方面远远优于基于提示的LLMs。这与之前的研究（Wei等，[2023](#bib.bib26)；Jeblick等，[2022](#bib.bib13)）相对较好，甚至在临床NLP任务中（Agrawal等，[2022](#bib.bib2)）表现优于微调模型的LLMs有所对比。我们进行了错误分析并提出了以下讨论。
- en: '4.2.1\. Discussion 1: Explicit-implicit mention of causality, and the effect
    of training sample.'
  id: totrans-88
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.1\. 讨论 1：因果关系的显式与隐式提及，以及训练样本的影响。
- en: 'Based on our error analysis, one possible reason the prompt-based model does
    not perform as well as the fine-tuned model is because causality is rarely written
    explicitly using causal cues such as “cause”, “causing” or “caused”. Instead,
    it is often described rather implicitly/ambiguously with keywords such as “contribute”
    or “play a role” Consider the following example from the test data, where the
    fine-tuned model correctly predicted the causal relation while the prompt-based
    model failed:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 基于我们的错误分析，一个可能的原因是基于提示的模型表现不如微调模型，因为因果关系很少使用诸如“cause”、“causing”或“caused”之类的因果提示显式书写。相反，它通常以诸如“contribute”或“play
    a role”之类的关键词隐晦地/模糊地描述。考虑以下来自测试数据的示例，其中微调模型正确预测了因果关系，而基于提示的模型则失败了：
- en: Example 4.1.
  id: totrans-90
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 示例 4.1。
- en: ..hepatocyte growth factor contribute to the growth of ovarian cancer by activating
    autocrine…
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ..肝细胞生长因子通过激活自分泌途径促进卵巢癌的生长…
- en: 'In the Example [4.1](#S4.Thmtheorem1 "Example 4.1\. ‣ 4.2.1\. Discussion 1:
    Explicit-implicit mention of causality, and the effect of training sample. ‣ 4.2\.
    Results and Discussion ‣ 4\. Experiments ‣ Prompt-based vs. Fine-tuned LLMs Toward
    Causal Graph Verification") above, human experts are aware that the keyword “contribute
    to the growth” implicitly describes causality, thus annotated the pair as a causal
    pair. The fine-tuned model most likely has been exposed to many similar examples
    in the training data and learned that such keywords can be an identifier of a
    causal relation. Meanwhile, without being exposed to any training sample, the
    prompt-based model missed this pattern indicating causality, resulted in wrong
    prediction. This suggests that, finding the causality pattern from training samples
    is an important step in identifying the causal relation.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述示例[4.1](#S4.Thmtheorem1 "Example 4.1\. ‣ 4.2.1\. 讨论 1：因果关系的显式-隐式提及以及训练样本的影响
    ‣ 4.2\. 结果与讨论 ‣ 4\. 实验 ‣ 基于提示与微调LLMs在因果图验证中的比较")中，人工专家意识到关键词“贡献于增长”隐含地描述了因果关系，因此将这一对标注为因果对。微调模型很可能已经接触到许多类似的训练数据，并学会了这些关键词可以是因果关系的标识。同时，未接触到任何训练样本的基于提示的模型错过了这一指示因果关系的模式，导致了错误的预测。这表明，从训练样本中找到因果关系模式是识别因果关系的重要一步。
- en: Nevertheless, in the Few-Shot prompt experiments where $n$ number of training
    samples are included in the prompt, the performance is not necessarily better
    compared to the models without training samples. This is shown in the Table [2](#S4.T2
    "Table 2 ‣ 4.1\. Datasets ‣ 4\. Experiments ‣ Prompt-based vs. Fine-tuned LLMs
    Toward Causal Graph Verification"), where surprisingly, the highest F score for
    the prompt-based methods is achieved with Single-Prompt B and C; both are the
    model without any training samples. We hypothesized this could be due to the limited
    size of the training samples, and adding more training data might improve the
    performance. Unfortunately, the current token limitation of the API prevented
    us to experiment with larger numbers of n.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，在包含$n$个训练样本的Few-Shot提示实验中，其表现不一定比没有训练样本的模型更好。如表[2](#S4.T2 "Table 2 ‣ 4.1\.
    数据集 ‣ 4\. 实验 ‣ 基于提示与微调LLMs在因果图验证中的比较")所示，令人惊讶的是，基于提示的方法中，Single-Prompt B和C的F分数最高；这两者都是没有任何训练样本的模型。我们推测这可能是由于训练样本的数量有限，增加更多的训练数据可能会提高性能。不幸的是，当前API的令牌限制阻止我们进行更多数量$n$的实验。
- en: '4.2.2\. Discussion 2: Effect of the context sentence.'
  id: totrans-94
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.2\. 讨论 2：上下文句子的影响。
- en: As mentioned in section [3.1.1](#S3.SS1.SSS1 "3.1.1\. Single-Prompt. ‣ 3.1\.
    Prompt-based LLMs ‣ 3\. Methods ‣ Prompt-based vs. Fine-tuned LLMs Toward Causal
    Graph Verification"), we created variations of the Single-Prompt setting by including
    and not including the context sentence $S$ in the prompt (with-context and no-context).
    Context sentence provides the model with a context, which in this work we define
    as the text surrounding the entity pair. We expect the model to look at these
    surrounding texts in determining the relationship between the target entity pair.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如[3.1.1](#S3.SS1.SSS1 "3.1.1\. 单一提示 ‣ 3.1\. 基于提示的LLMs ‣ 3\. 方法 ‣ 基于提示与微调LLMs在因果图验证中的比较")节中提到，我们通过在提示中包含或不包含上下文句子$S$（含上下文和无上下文）创建了Single-Prompt设置的变体。上下文句子为模型提供了上下文，在这项工作中我们定义为围绕实体对的文本。我们期望模型在确定目标实体对之间的关系时查看这些周围的文本。
- en: The result suggests that for prompt-based methods, including the context sentence
    in the prompt proves to be effective, as shown in the Table [2](#S4.T2 "Table
    2 ‣ 4.1\. Datasets ‣ 4\. Experiments ‣ Prompt-based vs. Fine-tuned LLMs Toward
    Causal Graph Verification") where the Single-Prompt type B, C (with-context) consistently
    gives better scores than type A (no-context). Rather than solely relying on the
    knowledge of the model obtained during the pre-training, the context gives the
    model additional knowledge in predicting the relationship between the entity pair.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，对于基于提示的方法，在提示中包含上下文句子是有效的，如表[2](#S4.T2 "Table 2 ‣ 4.1\. 数据集 ‣ 4\. 实验 ‣
    基于提示与微调LLMs在因果图验证中的比较")所示，Single-Prompt类型B、C（含上下文）的得分始终优于类型A（无上下文）。与其单纯依赖模型在预训练过程中获得的知识，不如说上下文为模型在预测实体对之间的关系时提供了额外的知识。
- en: '4.2.3\. Discussion 3: Biomedical vs. Open-domain datasets.'
  id: totrans-97
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.3\. 讨论 3：生物医学数据集与开放领域数据集。
- en: As shown in Table [2](#S4.T2 "Table 2 ‣ 4.1\. Datasets ‣ 4\. Experiments ‣ Prompt-based
    vs. Fine-tuned LLMs Toward Causal Graph Verification"), in general, we observe
    better scores in the results of the open-domain dataset compared to the biomedical
    datasets. This is expected because LLMs are mostly trained on open-domain texts,
    i.e., books and online content. Another reason could be due to the complexity
    of the texts in biomedical datasets, which include more domain-specific or technical
    terms.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如表[2](#S4.T2 "Table 2 ‣ 4.1\. 数据集 ‣ 4\. 实验 ‣ 基于提示与微调LLMs在因果图验证中的比较")所示，一般来说，我们观察到开放领域数据集的结果得分优于生物医学数据集。这是预期中的，因为LLMs大多是基于开放领域文本进行训练的，即书籍和在线内容。另一个原因可能是生物医学数据集中的文本复杂性，包括更多领域特定或技术术语。
- en: 5\. Conclusion
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 结论
- en: We present a preliminary study discussing the feasibility of applying NLP technologies
    for causal graph verification. We compare the prompt-based and fine-tuned LLMs
    for predicting the causality between pair of entities based on their textual context.
    Experiments on biomedical and open-domain datasets suggest that the fine-tuned
    models outperforms the prompt-based LLMs, up to 20.5% F score. However, due to
    limitation of the data, we were only able to quantitatively evaluate the methods
    on a binary-task setting, without considering the direction of causality. The
    target causal graph is directed, thus evaluating the direction of causality is
    our main future work. Other future work includes optimizing the prompt-based LLMs
    with more advanced prompting methods e.g., chain-of-thought (Wei et al., [2022](#bib.bib25)),
    or by giving the model additional knowledge and a more precise instruction.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们呈现了一项初步研究，讨论了将NLP技术应用于因果图验证的可行性。我们比较了基于提示和微调LLMs在预测实体对之间因果关系时的表现，基于它们的文本上下文。对生物医学和开放领域数据集的实验表明，微调模型优于基于提示的LLMs，F分数提高了最多20.5%。然而，由于数据的限制，我们只能在二元任务设置下定量评估这些方法，没有考虑因果关系的方向。目标因果图是有向的，因此评估因果关系的方向是我们未来的主要工作。其他未来工作包括通过更先进的提示方法优化基于提示的LLMs，例如链式思维(Wei
    et al., [2022](#bib.bib25))，或通过提供额外的知识和更精确的指令来改进模型。
- en: Despite the result of the current experiment, a fine-tuned model needs a sufficient
    expert-annotated data for training, and this could hinder the progress of the
    research. Training data construction (i.e., data annotation) requires human expert
    knowledge, and is often difficult and costly. In this regard, we believe that
    the LLMs, especially through the prompt engineering method, could be a breakthrough
    for the causal relation classification/extraction research.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管当前实验结果如此，微调模型仍需要足够的专家注释数据进行训练，这可能会阻碍研究进展。训练数据构建（即数据注释）需要人类专家知识，通常既困难又昂贵。在这方面，我们相信LLMs，特别是通过提示工程方法，可能成为因果关系分类/提取研究的突破口。
- en: Appendix A Prompt-based LLMs Hyperparameter
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录A 基于提示的LLMs超参数
- en: In this work, we used OpenAI³³3https://platform.openai.com/ API with gpt-3.5-turbo
    engine for the Single-Prompt and text-davinci-003 engine for the Few-Shot experiments.
    For all prompt- based settings, in general we assume only query access to the
    LLMs (i.e., no gradients, no log probabilities). Table [3](#A1.T3 "Table 3 ‣ Appendix
    A Prompt-based LLMs Hyperparameter ‣ Prompt-based vs. Fine-tuned LLMs Toward Causal
    Graph Verification") summarizes the hyperparameter values for the Few-Shot setting
    experiment.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们使用了OpenAI³³3https://platform.openai.com/ API，使用gpt-3.5-turbo引擎进行单一提示实验，使用text-davinci-003引擎进行少量示例实验。对于所有基于提示的设置，一般我们假设只有对LLMs的查询访问（即无梯度，无对数概率）。表[3](#A1.T3
    "Table 3 ‣ 附录A 基于提示的LLMs超参数 ‣ 基于提示与微调LLMs在因果图验证中的比较")总结了少量示例设置实验的超参数值。
- en: Table 3\. LLMs hyperparameter values.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 表3\. LLMs超参数值。
- en: '| Parameter | Value |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 值 |'
- en: '| --- | --- |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| $temperature$ | 0.7 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| $temperature$ | 0.7 |'
- en: '| $max\_token(n=5)$1200 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| $max\_token(n=5)$1200 |'
- en: '| $max\_token(n=15,20)$250 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| $max\_token(n=15,20)$250 |'
- en: '| $top\_p$ | 0.7 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| $top\_p$ | 0.7 |'
- en: '| $frequency\_penalty$ | 0.7 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| $frequency\_penalty$ | 0.7 |'
- en: '| $presence\_penalty$ | 0.7 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| $presence\_penalty$ | 0.7 |'
- en: In the fine-tuning of the BERT-based causal relation extraction models, batch
    sizes of 16 were used for the DDI dataset, while batch sizes of 8 were used for
    the COMAGC dataset. At both the beginning and the end of the first and second
    entity, we insert a special token “$” and “#”, respectively. This is useful to
    make the model capture the location information of the two target entities. We
    also add special tokens [CLS] to the beginning and [SEP] to the end of each input
    sequence, following the standard fine-tuning practice using the pre-trained BERT
    model (Devlin et al., [2019](#bib.bib8)).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在对基于BERT的因果关系提取模型进行微调时，DDI数据集使用了批量大小为16，而COMAGC数据集使用了批量大小为8。在第一个和第二个实体的开头和结尾，我们分别插入了特殊标记“$”和“#”。这有助于模型捕捉两个目标实体的位置信息。我们还在每个输入序列的开头添加了特殊标记[CLS]，在结尾添加了[SEP]，遵循使用预训练BERT模型的标准微调实践（Devlin等，[2019](#bib.bib8)）。
- en: Appendix B BERT fine-tuning hyperparamater
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录B BERT微调超参数
- en: In preparing the data, we insert a special token “$” and “#” at both the beginning
    and the end of the first and second entity, respectively. This is useful to make
    the model captures the location information of the target entities. We also add
    special tokens “[CLS]” to the beginning and “[SEP]” to the end of each input sequence,
    following the standard fine-tuning practice using the pre-trained BERT model (Devlin
    et al., [2019](#bib.bib8)).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在准备数据时，我们在第一个和第二个实体的开头和结尾分别插入了特殊标记“$”和“#”。这有助于模型捕捉目标实体的位置信息。我们还在每个输入序列的开头添加了特殊标记“[CLS]”，在结尾添加了“[SEP]”，遵循使用预训练BERT模型的标准微调实践（Devlin等，[2019](#bib.bib8)）。
- en: In the fine-tuning of the BERT pre-trained model for the biomedical dataset,
    batch sizes of 16 were used for the DDI, SEMEVAL, and GENE dataset, while batch
    sizes of 8 were used for the COMAGC dataset. We used the BioBERT-large-cased⁴⁴4https://huggingface.co/dmis-lab/biobert-v1.1
    for the BioBERT pre-trained model and PubMedBERT-base-uncased-abstract-fulltext⁵⁵5https://huggingface.co/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext
    for the PubMedBERT pre-trained model, for all biomedical datasets fine-tuning.
    Table [4](#A2.T4 "Table 4 ‣ Appendix B BERT fine-tuning hyperparamater ‣ Prompt-based
    vs. Fine-tuned LLMs Toward Causal Graph Verification") summarizes the hyperparameter
    values for fine-tuning the BERT model experiments.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在对生物医学数据集进行BERT预训练模型的微调时，DDI、SEMEVAL和GENE数据集使用了批量大小为16，而COMAGC数据集使用了批量大小为8。我们对BioBERT预训练模型使用了BioBERT-large-cased⁴⁴4https://huggingface.co/dmis-lab/biobert-v1.1，对PubMedBERT预训练模型使用了PubMedBERT-base-uncased-abstract-fulltext⁵⁵5https://huggingface.co/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext，所有生物医学数据集的微调均使用了这些模型。表[4](#A2.T4
    "Table 4 ‣ Appendix B BERT fine-tuning hyperparamater ‣ Prompt-based vs. Fine-tuned
    LLMs Toward Causal Graph Verification")总结了BERT模型实验的超参数值。
- en: Table 4\. BERT hyperparameter values.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 表4\. BERT超参数值。
- en: '| Parameter | Value |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 值 |'
- en: '| --- | --- |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| $max\_sequence\_length$ | 128, 256 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| $max\_sequence\_length$ | 128, 256 |'
- en: '| $epoch$ | 10 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| $epoch$ | 10 |'
- en: '| $optimizer$ | Adam |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| $optimizer$ | Adam |'
- en: '| $lr$ | 2e-5 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| $lr$ | 2e-5 |'
- en: '| $eps$ | 1e-08 |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| $eps$ | 1e-08 |'
- en: '| $linear\_warmup\_proportion$ | 0.1 |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| $linear\_warmup\_proportion$ | 0.1 |'
- en: '| $dropout$ | 0.1 |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| $dropout$ | 0.1 |'
- en: '| $hidden\_layer$ | 1024 (FC layer) |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| $hidden\_layer$ | 1024（全连接层） |'
- en: '| $seed$ | 1234 |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| $seed$ | 1234 |'
- en: For the SEMEVAL dataset, we used the bert-base uncased pre-trained model, with
    the same hyperparameters as the BioBERT/PubMEDBERT model above. We implemented
    the fine-tuning of the BERT model using Pytorch. The random seed of 1234 is set
    for all experiments.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 对于SEMEVAL数据集，我们使用了bert-base uncased预训练模型，超参数与上述BioBERT/PubMEDBERT模型相同。我们使用Pytorch实现了BERT模型的微调。所有实验均设置了随机种子1234。
- en: References
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: Agrawal et al. (2022) Monica Agrawal, Stefan Hegselmann, Hunter Lang, Yoon Kim,
    and David Sontag. 2022. Large language models are few-shot clinical information
    extractors. In *Proceedings of the 2022 Conference on Empirical Methods in Natural
    Language Processing*. Association for Computational Linguistics, Abu Dhabi, United
    Arab Emirates, 1998–2022. [https://aclanthology.org/2022.emnlp-main.130](https://aclanthology.org/2022.emnlp-main.130)
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Agrawal等（2022）Monica Agrawal，Stefan Hegselmann，Hunter Lang，Yoon Kim，和David Sontag。2022年。《大语言模型是少量临床信息提取器》。在*2022年自然语言处理经验方法会议论文集中*。计算语言学协会，阿布扎比，阿联酋，1998–2022。[https://aclanthology.org/2022.emnlp-main.130](https://aclanthology.org/2022.emnlp-main.130)
- en: Balashankar et al. (2019) Ananth Balashankar, Sunandan Chakraborty, Samuel Fraiberger,
    and Lakshminarayanan Subramanian. 2019. Identifying Predictive Causal Factors
    from News Streams. In *Proceedings of the 2019 Conference on Empirical Methods
    in Natural Language Processing and the 9th International Joint Conference on Natural
    Language Processing (EMNLP-IJCNLP)*. Association for Computational Linguistics,
    Hong Kong, China, 2338–2348. [https://doi.org/10.18653/v1/D19-1238](https://doi.org/10.18653/v1/D19-1238)
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Balashankar 等人（2019）Ananth Balashankar、Sunandan Chakraborty、Samuel Fraiberger
    和 Lakshminarayanan Subramanian。2019。识别新闻流中的预测因果因素。在 *2019 年自然语言处理实证方法会议及第九届国际自然语言处理联合会议（EMNLP-IJCNLP）会议录*
    中。计算语言学协会，香港，中国，2338–2348。 [https://doi.org/10.18653/v1/D19-1238](https://doi.org/10.18653/v1/D19-1238)
- en: Blanco et al. (2008) Eduardo Blanco, Nuria Castell, and Dan Moldovan. 2008.
    Causal Relation Extraction. In *Proceedings of the Sixth International Conference
    on Language Resources and Evaluation (LREC’08)*. European Language Resources Association
    (ELRA), Marrakech, Morocco, 1161–1186. [http://www.lrec-conf.org/proceedings/lrec2008/pdf/87_paper.pdf](http://www.lrec-conf.org/proceedings/lrec2008/pdf/87_paper.pdf)
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Blanco 等人（2008）Eduardo Blanco、Nuria Castell 和 Dan Moldovan。2008。因果关系提取。在 *第六届国际语言资源与评估会议（LREC’08）会议录*
    中。欧洲语言资源协会（ELRA），马拉喀什，摩洛哥，1161–1186。 [http://www.lrec-conf.org/proceedings/lrec2008/pdf/87_paper.pdf](http://www.lrec-conf.org/proceedings/lrec2008/pdf/87_paper.pdf)
- en: Bui et al. (2010) Quoc-Chinh Bui, Breanndán Ó Nualláin, Charles A. Boucher,
    and Peter MA Sloot. 2010. Extracting causal relations on HIV drug resistance from
    literature. *BMC Bioinformatics* 11, 1 (23 Feb 2010), 101. [https://doi.org/10.1186/1471-2105-11-101](https://doi.org/10.1186/1471-2105-11-101)
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bui 等人（2010）Quoc-Chinh Bui、Breanndán Ó Nualláin、Charles A. Boucher 和 Peter MA
    Sloot。2010。从文献中提取 HIV 药物抗药性的因果关系。 *BMC 生物信息学* 11, 1（2010年2月23日），101。 [https://doi.org/10.1186/1471-2105-11-101](https://doi.org/10.1186/1471-2105-11-101)
- en: Chang and Choi (2006) Du-Seong Chang and Key-Sun Choi. 2006. Incremental cue
    phrase learning and bootstrapping method for causality extraction using cue phrase
    and word pair probabilities. *Information Processing & Management* 42, 3 (2006),
    662–678. [https://doi.org/10.1016/j.ipm.2005.04.004](https://doi.org/10.1016/j.ipm.2005.04.004)
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chang 和 Choi（2006）Du-Seong Chang 和 Key-Sun Choi。2006。使用提示短语和词对概率的因果关系提取的增量提示短语学习和引导方法。
    *信息处理与管理* 42, 3（2006），662–678。 [https://doi.org/10.1016/j.ipm.2005.04.004](https://doi.org/10.1016/j.ipm.2005.04.004)
- en: 'Devlin et al. (2018) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina
    Toutanova. 2018. BERT: Pre-training of Deep Bidirectional Transformers for Language
    Understanding. *CoRR* abs/1810.04805 (2018), 1161–1186. arXiv:1810.04805 [http://arxiv.org/abs/1810.04805](http://arxiv.org/abs/1810.04805)'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Devlin 等人（2018）Jacob Devlin、Ming-Wei Chang、Kenton Lee 和 Kristina Toutanova。2018。BERT：用于语言理解的深度双向变换器的预训练。
    *CoRR* abs/1810.04805（2018），1161–1186。 arXiv:1810.04805 [http://arxiv.org/abs/1810.04805](http://arxiv.org/abs/1810.04805)
- en: 'Devlin et al. (2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina
    Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language
    Understanding. In *Proceedings of the 2019 Conference of the North American Chapter
    of the Association for Computational Linguistics: Human Language Technologies,
    Volume 1 (Long and Short Papers)*. Association for Computational Linguistics,
    Minneapolis, Minnesota, 4171–4186. [https://doi.org/10.18653/v1/N19-1423](https://doi.org/10.18653/v1/N19-1423)'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Devlin 等人（2019）Jacob Devlin、Ming-Wei Chang、Kenton Lee 和 Kristina Toutanova。2019。BERT：用于语言理解的深度双向变换器的预训练。在
    *2019 年北美计算语言学协会年会：人类语言技术会议录第一卷（长篇论文和短篇论文）* 中。计算语言学协会，明尼阿波利斯，明尼苏达州，4171–4186。
    [https://doi.org/10.18653/v1/N19-1423](https://doi.org/10.18653/v1/N19-1423)
- en: Gu et al. (2016) Jinghang Gu, Longhua Qian, and Guodong Zhou. 2016. Chemical-induced
    disease relation extraction with various linguistic features. *Database* 2016
    (04 2016), 1161–1186. [https://doi.org/10.1093/database/baw042](https://doi.org/10.1093/database/baw042)
    arXiv:https://academic.oup.com/database/article-pdf/doi/10.1093/database/baw042/8223888/baw042.pdf
    baw042.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gu 等人（2016）Jinghang Gu、Longhua Qian 和 Guodong Zhou。2016。利用各种语言特征进行化学诱导疾病关系提取。
    *数据库* 2016（04 2016），1161–1186。 [https://doi.org/10.1093/database/baw042](https://doi.org/10.1093/database/baw042)
    arXiv: https://academic.oup.com/database/article-pdf/doi/10.1093/database/baw042/8223888/baw042.pdf
    baw042.'
- en: Gu et al. (2021) Yu Gu, Robert Tinn, Hao Cheng, Michael Lucas, Naoto Usuyama,
    Xiaodong Liu, Tristan Naumann, Jianfeng Gao, and Hoifung Poon. 2021. Domain-Specific
    Language Model Pretraining for Biomedical Natural Language Processing. *ACM Trans.
    Comput. Healthcare* 3, 1, Article 2 (oct 2021), 23 pages. [https://doi.org/10.1145/3458754](https://doi.org/10.1145/3458754)
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gu 等（2021）Yu Gu, Robert Tinn, Hao Cheng, Michael Lucas, Naoto Usuyama, Xiaodong
    Liu, Tristan Naumann, Jianfeng Gao 和 Hoifung Poon。2021。《领域特定语言模型预训练用于生物医学自然语言处理》。*ACM
    计算机健康护理学报* 3, 1, 文章 2（2021年10月），23 页。 [https://doi.org/10.1145/3458754](https://doi.org/10.1145/3458754)
- en: 'Hendrickx et al. (2010) Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva, Preslav
    Nakov, Diarmuid Ó Séaghdha, Sebastian Padó, Marco Pennacchiotti, Lorenza Romano,
    and Stan Szpakowicz. 2010. SemEval-2010 Task 8: Multi-Way Classification of Semantic
    Relations between Pairs of Nominals. In *Proceedings of the 5th International
    Workshop on Semantic Evaluation*. Association for Computational Linguistics, Uppsala,
    Sweden, 33–38. [https://aclanthology.org/S10-1006](https://aclanthology.org/S10-1006)'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hendrickx 等（2010）Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva, Preslav Nakov,
    Diarmuid Ó Séaghdha, Sebastian Padó, Marco Pennacchiotti, Lorenza Romano 和 Stan
    Szpakowicz。2010。《SemEval-2010 任务 8：名词对之间语义关系的多方式分类》。收录于 *第五届国际语义评估研讨会论文集*。计算语言学协会，瑞典乌普萨拉，33–38。
    [https://aclanthology.org/S10-1006](https://aclanthology.org/S10-1006)
- en: 'Herrero-Zazo et al. (2013) María Herrero-Zazo, Isabel Segura-Bedmar, Paloma
    Martínez, and Thierry Declerck. 2013. The DDI corpus: An annotated corpus with
    pharmacological substances and drug–drug interactions. *Journal of Biomedical
    Informatics* 46, 5 (2013), 914–920. [https://doi.org/10.1016/j.jbi.2013.07.011](https://doi.org/10.1016/j.jbi.2013.07.011)'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Herrero-Zazo 等（2013）María Herrero-Zazo, Isabel Segura-Bedmar, Paloma Martínez
    和 Thierry Declerck。2013。《DDI 语料库：带有药物和药物间相互作用的注释语料库》。*生物医学信息学杂志* 46, 5（2013），914–920。
    [https://doi.org/10.1016/j.jbi.2013.07.011](https://doi.org/10.1016/j.jbi.2013.07.011)
- en: 'Jeblick et al. (2022) Katharina Jeblick, Balthasar Schachtner, Jakob Dexl,
    Andreas Mittermeier, Anna Theresa Stüber, Johanna Topalis, Tobias Weber, Philipp
    Wesp, Bastian Sabel, Jens Ricke, and Michael Ingrisch. 2022. ChatGPT Makes Medicine
    Easy to Swallow: An Exploratory Case Study on Simplified Radiology Reports. arXiv:2212.14882 [cs.CL]'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jeblick 等（2022）Katharina Jeblick, Balthasar Schachtner, Jakob Dexl, Andreas
    Mittermeier, Anna Theresa Stüber, Johanna Topalis, Tobias Weber, Philipp Wesp,
    Bastian Sabel, Jens Ricke 和 Michael Ingrisch。2022。《ChatGPT 让医学变得易于理解：关于简化放射学报告的探索性案例研究》。arXiv:2212.14882
    [cs.CL]
- en: 'Khetan et al. (2022) Vivek Khetan, Md Imbesat Rizvi, Jessica Huber, Paige Bartusiak,
    Bogdan Sacaleanu, and Andrew Fano. 2022. MIMICause: Representation and automatic
    extraction of causal relation types from clinical notes. In *Findings of the Association
    for Computational Linguistics: ACL 2022*. Association for Computational Linguistics,
    Dublin, Ireland, 764–773. [https://doi.org/10.18653/v1/2022.findings-acl.63](https://doi.org/10.18653/v1/2022.findings-acl.63)'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khetan 等（2022）Vivek Khetan, Md Imbesat Rizvi, Jessica Huber, Paige Bartusiak,
    Bogdan Sacaleanu 和 Andrew Fano。2022。《MIMICause：从临床笔记中表示和自动提取因果关系类型》。收录于 *计算语言学协会发现：ACL
    2022*。计算语言学协会，爱尔兰都柏林，764–773。 [https://doi.org/10.18653/v1/2022.findings-acl.63](https://doi.org/10.18653/v1/2022.findings-acl.63)
- en: Khoo et al. (2000) Christopher S. G. Khoo, Syin Chan, and Yun Niu. 2000. Extracting
    Causal Knowledge from a Medical Database Using Graphical Patterns. In *Proceedings
    of the 38th Annual Meeting on Association for Computational Linguistics* (Hong
    Kong) *(ACL ’00)*. Association for Computational Linguistics, USA, 336–343. [https://doi.org/10.3115/1075218.1075261](https://doi.org/10.3115/1075218.1075261)
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khoo 等（2000）Christopher S. G. Khoo, Syin Chan 和 Yun Niu。2000。《使用图形模式从医学数据库中提取因果知识》。收录于
    *第 38 届计算语言学协会年会论文集*（香港）*(ACL ’00)*。计算语言学协会，美国，336–343。 [https://doi.org/10.3115/1075218.1075261](https://doi.org/10.3115/1075218.1075261)
- en: Khoo et al. (1998) CHRISTOPHER S. G. Khoo, JAKLIN KORNFILT, ROBERT N. ODDY,
    and SUNG HYON MYAENG. 1998. Automatic Extraction of Cause-Effect Information from
    Newspaper Text Without Knowledge-based Inferencing. *Literary and Linguistic Computing*
    13, 4 (12 1998), 177–186. [https://doi.org/10.1093/llc/13.4.177](https://doi.org/10.1093/llc/13.4.177)
    arXiv:https://academic.oup.com/dsh/article-pdf/13/4/177/10888761/177.pdf
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Khoo 等（1998）CHRISTOPHER S. G. Khoo, JAKLIN KORNFILT, ROBERT N. ODDY 和 SUNG
    HYON MYAENG。1998。《无需基于知识的推理从报纸文本中自动提取因果信息》。*文学与语言计算* 13, 4（1998年12月），177–186。
    [https://doi.org/10.1093/llc/13.4.177](https://doi.org/10.1093/llc/13.4.177) arXiv:
    https://academic.oup.com/dsh/article-pdf/13/4/177/10888761/177.pdf'
- en: 'Lee et al. (2013) Hee-Jin Lee, Sang-Hyung Shim, Mi-Ryoung Song, Hyunju Lee,
    and Jong C. Park. 2013. CoMAGC: a corpus with multi-faceted annotations of gene-cancer
    relations. *BMC Bioinformatics* 14, 1 (14 Nov 2013), 323. [https://doi.org/10.1186/1471-2105-14-323](https://doi.org/10.1186/1471-2105-14-323)'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lee et al. (2013) Hee-Jin Lee, Sang-Hyung Shim, Mi-Ryoung Song, Hyunju Lee,
    和 Jong C. Park. 2013. CoMAGC: 一个具有多方面基因-癌症关系注释的语料库。*BMC Bioinformatics* 14, 1
    (2013年11月14日), 323. [https://doi.org/10.1186/1471-2105-14-323](https://doi.org/10.1186/1471-2105-14-323)'
- en: 'Lee et al. (2019) Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu
    Kim, Chan Ho So, and Jaewoo Kang. 2019. BioBERT: a pre-trained biomedical language
    representation model for biomedical text mining. *Bioinformatics* 36, 4 (09 2019),
    1234–1240. [https://doi.org/10.1093/bioinformatics/btz682](https://doi.org/10.1093/bioinformatics/btz682)
    arXiv:https://academic.oup.com/bioinformatics/article-pdf/36/4/1234/48983216/bioinformatics_36_4_1234.pdf'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lee et al. (2019) Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu
    Kim, Chan Ho So, 和 Jaewoo Kang. 2019. BioBERT: 一个用于生物医学文本挖掘的预训练生物医学语言表示模型。*Bioinformatics*
    36, 4 (2019年9月), 1234–1240. [https://doi.org/10.1093/bioinformatics/btz682](https://doi.org/10.1093/bioinformatics/btz682)
    arXiv:https://academic.oup.com/bioinformatics/article-pdf/36/4/1234/48983216/bioinformatics_36_4_1234.pdf'
- en: Mihăilă and Ananiadou (2014) Claudiu Mihăilă and Sophia Ananiadou. 2014. Semi-supervised
    learning of causal relations in biomedical scientific discourse. *BioMedical Engineering
    OnLine* 13, 2 (11 Dec 2014), S1. [https://doi.org/10.1186/1475-925X-13-S2-S1](https://doi.org/10.1186/1475-925X-13-S2-S1)
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mihăilă and Ananiadou (2014) Claudiu Mihăilă 和 Sophia Ananiadou. 2014. 生物医学科学话语中因果关系的半监督学习。*BioMedical
    Engineering OnLine* 13, 2 (2014年12月11日), S1. [https://doi.org/10.1186/1475-925X-13-S2-S1](https://doi.org/10.1186/1475-925X-13-S2-S1)
- en: Ouyang et al. (2022) Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L.
    Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex
    Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda
    Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022. Training
    language models to follow instructions with human feedback. arXiv:2203.02155 [cs.CL]
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ouyang et al. (2022) Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll
    L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama,
    Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens,
    Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, 和 Ryan Lowe. 2022.
    使用人类反馈训练语言模型以遵循指令。 arXiv:2203.02155 [cs.CL]
- en: 'Reklos and Albert (2022) Ioannis Reklos and Meroño-Peñuela Albert. 2022. MediCause:
    Causal Relation Modelling and Extraction from Medical Publications. In *Proceedings
    of the Text2KG 2022: International Workshop on Knowledge Graph Generation from
    Text*. Text2KG, Crete,Hersonissos, Greece, 1161–1186.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Reklos and Albert (2022) Ioannis Reklos 和 Meroño-Peñuela Albert. 2022. MediCause:
    医学文献中的因果关系建模与提取。见于 *Text2KG 2022: 国际知识图谱生成研讨会论文集*。Text2KG, 克里特岛赫尔索尼索斯, 希腊, 1161–1186.'
- en: Shimizu et al. (2006) Shohei Shimizu, Patrik O. Hoyer, Aapo Hyvärinen, and Antti
    Kerminen. 2006. A Linear Non-Gaussian Acyclic Model for Causal Discovery. *J.
    Mach. Learn. Res.* 7 (dec 2006), 2003–2030.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shimizu et al. (2006) Shohei Shimizu, Patrik O. Hoyer, Aapo Hyvärinen, 和 Antti
    Kerminen. 2006. 用于因果发现的线性非高斯无环模型。*J. Mach. Learn. Res.* 7 (2006年12月), 2003–2030.
- en: Spirtes et al. (2000) P. Spirtes, C. Glymour, and R. Scheines. 2000. *Causation,
    Prediction, and Search* (2nd ed.). MIT press, mit.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spirtes et al. (2000) P. Spirtes, C. Glymour, and R. Scheines. 2000. *因果推断、预测与搜索*（第2版）。MIT
    press，麻省理工学院。
- en: Su and Vijay-Shanker (2022) Peng Su and K. Vijay-Shanker. 2022. Investigation
    of improving the pre-training and fine-tuning of BERT model for biomedical relation
    extraction. *BMC Bioinformatics* 23, 1 (04 Apr 2022), 120. [https://doi.org/10.1186/s12859-022-04642-w](https://doi.org/10.1186/s12859-022-04642-w)
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Su and Vijay-Shanker (2022) Peng Su 和 K. Vijay-Shanker. 2022. 改进 BERT 模型的预训练与微调以进行生物医学关系提取的研究。*BMC
    Bioinformatics* 23, 1 (2022年4月4日), 120. [https://doi.org/10.1186/s12859-022-04642-w](https://doi.org/10.1186/s12859-022-04642-w)
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed H.
    Chi, Quoc Le, and Denny Zhou. 2022. Chain of Thought Prompting Elicits Reasoning
    in Large Language Models. *CoRR* abs/2201.11903 (2022), 1011. arXiv:2201.11903
    [https://arxiv.org/abs/2201.11903](https://arxiv.org/abs/2201.11903)
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed
    H. Chi, Quoc Le, and Denny Zhou. 2022. Chain of Thought Prompting Elicits Reasoning
    in Large Language Models. *CoRR* abs/2201.11903 (2022), 1011. arXiv:2201.11903
    [https://arxiv.org/abs/2201.11903](https://arxiv.org/abs/2201.11903)
- en: Wei et al. (2023) Xiang Wei, Xingyu Cui, Ning Cheng, Xiaobin Wang, Xin Zhang,
    Shen Huang, Pengjun Xie, Jinan Xu, Yufeng Chen, Meishan Zhang, Yong Jiang, and
    Wenjuan Han. 2023. Zero-Shot Information Extraction via Chatting with ChatGPT.
    arXiv:2302.10205 [cs.CL]
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei et al. (2023) Xiang Wei, Xingyu Cui, Ning Cheng, Xiaobin Wang, Xin Zhang,
    Shen Huang, Pengjun Xie, Jinan Xu, Yufeng Chen, Meishan Zhang, Yong Jiang, 和 Wenjuan
    Han. 2023. 通过与 ChatGPT 对话进行零样本信息提取。 arXiv:2302.10205 [cs.CL]
