- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 18:40:02'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-09-08 18:40:02'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Predictive Data Analytics with AI: assessing the need for post-editing of MT
    output by fine-tuning OpenAI LLMs'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于 AI 的预测数据分析：通过微调 OpenAI LLMs 评估 MT 输出的后编辑需求
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2308.00158](https://ar5iv.labs.arxiv.org/html/2308.00158)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2308.00158](https://ar5iv.labs.arxiv.org/html/2308.00158)
- en: Serge Gladkoff^( 1), Gleb Erofeev^( 1), Irina Sorokina^( 1), Lifeng Han²   
    Goran Nenadic²
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Serge Gladkoff^( 1), Gleb Erofeev^( 1), Irina Sorokina^( 1), Lifeng Han²   
    Goran Nenadic²
- en: ¹ Logrus Global, Translation & Localization
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ¹ Logrus Global, 翻译与本地化
- en: ² The University of Manchester, UK
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ² 曼彻斯特大学，英国
- en: lifeng.han, g.nenadic @ manchester.ac.uk
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: lifeng.han, g.nenadic @ manchester.ac.uk
- en: serge.gladkoff, gleb.erofeev, irina.sorokina @ logrusglobal.com
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: serge.gladkoff, gleb.erofeev, irina.sorokina @ logrusglobal.com
- en: Abstract
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Translation Quality Evaluation (TQE) is an essential step of modern translation
    production process. TQE is critical in assessing both machine translation (MT)
    and human translation (HT) quality without reference translations. Ability to
    evaluate or even simply estimate the quality of translation automatically may
    open significant efficiency gains through process optimization. This work examines
    whether the state-of-the-art large language models (LLMs) can be used for this
    purpose. We take OpenAI models as the best state of the art technology and approach
    TQE as a binary classification task. On eight language pairs including English
    to Italian, German, French, Japanese, Dutch, Portuguese, Turkish, and Chinese,
    our experimental results show that fine-tuned gpt3.5 can demonstrate good performance
    on translation quality prediction tasks, i.e. whether the translation needs to
    be edited. Another finding is that simply increasing the sizes of LLMs does not
    lead to apparent better performances on this task by comparing the performance
    of three different versions of OpenAI models: curie, davinci, and gpt3.5 with
    13B, 175B, and 175B parameters, respectively. ¹¹1Accepted by AMTA2023 (Generative
    AI and the Future of Machine Translation ) as non-archival oral presentation [https://machinetranslate.org/amta2023](https://machinetranslate.org/amta2023)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 翻译质量评估（TQE）是现代翻译生产过程中的关键步骤。TQE 对于在没有参考翻译的情况下评估机器翻译（MT）和人工翻译（HT）质量至关重要。自动评估或甚至简单估算翻译质量的能力可能通过过程优化带来显著的效率提升。本研究探讨了最先进的大型语言模型（LLMs）是否可以用于这一目的。我们将
    OpenAI 模型视为最先进技术，并将 TQE 视为二分类任务。在包括英语到意大利语、德语、法语、日语、荷兰语、葡萄牙语、土耳其语和中文在内的八种语言对上，我们的实验结果表明，微调后的
    gpt3.5 在翻译质量预测任务上表现良好，即是否需要编辑翻译。另一个发现是，简单增加 LLM 的规模并不会显著提升该任务的性能，通过比较三种不同版本的 OpenAI
    模型：curie、davinci 和 gpt3.5，参数分别为 13B、175B 和 175B，发现性能没有明显改善。¹¹1 被 AMTA2023（生成 AI
    与机器翻译的未来）接受为非档案性口头报告 [https://machinetranslate.org/amta2023](https://machinetranslate.org/amta2023)
- en: 1 Introduction
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Most modern translation projects include post-editing (PE) of machine-translation
    (MT) output Han and Gladkoff ([2022](#bib.bib12)); Gladkoff et al. ([2022](#bib.bib7)).
    Instead of translating from scratch, the MT+PE process increases productivity
    and allows to speed up global content delivery Gladkoff and Han ([2022](#bib.bib6));
    Han et al. ([2013](#bib.bib9)). However, in regulated industries and many other
    scenarios raw MT output is not suitable for final publication due to the inevitable
    errors caused by inherently stochastic nature of neural MT (NMT) Han ([2022a](#bib.bib10));
    Freitag et al. ([2021](#bib.bib5)). Hallucinations, incorrect terminology, factual
    and accuracy errors, small and large, as well as many other types of mistakes
    are inevitable to varying degrees of extent, and therefore for premium quality
    publication human revision is required. MT output serves as input for a professional
    human translator, who reviews and revises the MT proposals to eliminate factual
    errors and ensure that the quality of translated material conforms to the customer
    specifications. At the same time even with those languages that are not handled
    well by MT, there is a significant portion of segments that are not changed after
    human review. This portion varies from 10% to 70% in some cases ²²2[logrusglobal.com](logrusglobal.com)
    statistics, and the question arises, “Is it possible to use machine learning (ML)
    methods to mark these segments and save time for human reviser and make them focus
    on those segments that need attention instead”? In other words, Is it possible
    to capture editing distance patterns from data of prior editing of this material,
    which already has been made? This could further speed up the translation process
    and decrease the costs while preserving the premium quality of the translated
    product.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数现代翻译项目包括机器翻译（MT）输出的后期编辑（PE） Han and Gladkoff ([2022](#bib.bib12)); Gladkoff
    et al. ([2022](#bib.bib7))。与从头翻译相比，MT+PE过程提高了生产力，并加快了全球内容的交付 Gladkoff and Han
    ([2022](#bib.bib6)); Han et al. ([2013](#bib.bib9))。然而，在受监管的行业和许多其他场景中，由于神经MT（NMT）固有的随机性质所导致的不可避免的错误，原始MT输出不适合最终发布
    Han ([2022a](#bib.bib10)); Freitag et al. ([2021](#bib.bib5))。幻觉、术语错误、事实和准确性错误，无论大小，及其他各种类型的错误在不同程度上是不可避免的，因此，为了获得高质量的出版物，需要人工修订。MT输出作为专业人工翻译员的输入，后者审查和修改MT建议，以消除事实错误并确保翻译材料的质量符合客户规格。同时，即使对于那些MT处理不佳的语言，仍有相当一部分段落在人工审查后没有发生变化。在某些情况下，这一比例从10%到70%不等²²2[logrusglobal.com](logrusglobal.com)统计数据。因此，问题出现了：“是否可以使用机器学习（ML）方法标记这些段落，以节省人工审阅员的时间，并使他们专注于需要关注的段落？”换句话说，是否可以从已经完成的编辑数据中捕捉编辑距离模式？这可以进一步加快翻译过程，并降低成本，同时保持翻译产品的高质量。
- en: This problem is also closely related to the traditional MT quality estimation
    (QE) shared task that has been held with the Workshop of MT (WMT) series since
    2012 Callison-Burch et al. ([2012](#bib.bib2)); Koehn et al. ([2022](#bib.bib13));
    Zerva et al. ([2022](#bib.bib15)); Han et al. ([2013](#bib.bib9)); Han ([2022b](#bib.bib11)),
    where both token-level and segment-level QE were carried out.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题也与自2012年开始与MT (WMT)系列研讨会共同举行的传统MT质量评估（QE）共享任务紧密相关 Callison-Burch et al.
    ([2012](#bib.bib2)); Koehn et al. ([2022](#bib.bib13)); Zerva et al. ([2022](#bib.bib15));
    Han et al. ([2013](#bib.bib9)); Han ([2022b](#bib.bib11))，其中进行了词级和段级QE评估。
- en: From practical application and industrial usage, we formulate the problem into
    a single classification task, i.e. we are trying to solve classification task
    to answer if the translated segment (sentence) needs to be edited, or not.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 从实际应用和工业使用的角度出发，我们将问题归结为一个单一的分类任务，即我们尝试解决分类任务，以判断翻译后的段落（句子）是否需要编辑。
- en: 'With the development of current large language models (LLMs), we choose OpenAI
    models as state-of-the-art LLMs to examine their capabilities for this task. In
    this work, our first experimental investigation is on “Predictive Data Analytics
    with AI: assessing the need for post-editing of MT output by fine-tuning OpenAI
    LLMs”. We also follow up with experiment which explores “if the size of sample
    or LLM matters in such a task” by experimenting with three OpenAI models: curie,
    davinci, and gpt3.5, with parameter sizes varying from 13B to 175B.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 随着当前大语言模型（LLMs）的发展，我们选择了OpenAI模型作为最先进的LLMs来检验其在此任务中的能力。在这项工作中，我们的首个实验调查是“AI的预测数据分析：通过微调OpenAI
    LLMs评估MT输出的后编辑需求”。我们还跟进了一个实验，探索“样本大小或LLM在此类任务中的重要性”，实验使用了三种OpenAI模型：curie、davinci和gpt3.5，参数大小从13B到175B不等。
- en: 'The rest of this paper is designed as below. Section [2](#S2 "2 Related Work
    ‣ Predictive Data Analytics with AI: assessing the need for post-editing of MT
    output by fine-tuning OpenAI LLMs") introduces related work to ours including
    MT-QE-related shared task and challenge events, Section [3](#S3 "3 Methodology
    and Experiments ‣ Predictive Data Analytics with AI: assessing the need for post-editing
    of MT output by fine-tuning OpenAI LLMs") presents our methodology design and
    pilot study using two language pairs, Section [4](#S4 "4 Extended Experiments
    ‣ Predictive Data Analytics with AI: assessing the need for post-editing of MT
    output by fine-tuning OpenAI LLMs") extends the experimental investigation with
    six more language pairs, section [5](#S5 "5 Different LLMs on EN-JA News Domain
    ‣ Predictive Data Analytics with AI: assessing the need for post-editing of MT
    output by fine-tuning OpenAI LLMs") discusses experiment on English-Japanese news
    content with the increasing sizes of training and testing corpus and explores
    two more OpenAI LLMs with varying model sizes, and Section [6](#S6 "6 Conclusions
    and Future Work ‣ Predictive Data Analytics with AI: assessing the need for post-editing
    of MT output by fine-tuning OpenAI LLMs") concludes this paper with future work
    and research perspectives.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '本文的其余部分设计如下。第[2](#S2 "2 Related Work ‣ Predictive Data Analytics with AI: assessing
    the need for post-editing of MT output by fine-tuning OpenAI LLMs")节介绍了与我们相关的工作，包括与MT-QE相关的共享任务和挑战活动，第[3](#S3
    "3 Methodology and Experiments ‣ Predictive Data Analytics with AI: assessing
    the need for post-editing of MT output by fine-tuning OpenAI LLMs")节展示了我们在两个语言对上进行的方法设计和初步研究，第[4](#S4
    "4 Extended Experiments ‣ Predictive Data Analytics with AI: assessing the need
    for post-editing of MT output by fine-tuning OpenAI LLMs")节扩展了六个语言对的实验调查，第[5](#S5
    "5 Different LLMs on EN-JA News Domain ‣ Predictive Data Analytics with AI: assessing
    the need for post-editing of MT output by fine-tuning OpenAI LLMs")节讨论了在增加训练和测试语料库的情况下对英日新闻内容的实验，并探索了两种不同模型大小的OpenAI
    LLM，第[6](#S6 "6 Conclusions and Future Work ‣ Predictive Data Analytics with AI:
    assessing the need for post-editing of MT output by fine-tuning OpenAI LLMs")节总结了本文，并展望了未来的工作和研究方向。'
- en: 2 Related Work
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: The Quality Evaluation (QE) of MT output has always been a critical topic for
    MT development due to its critical role in assessing quality in the process of
    training. In many cases evaluation has to be done without seeing the reference
    translations. In many practical situations, reference translations are not available
    or even not possible to acquire, i.e. it is not practical to “manufacture” them
    for evaluation. The earliest QE shared task with the annual WMT conference started
    in 2012 when word level QE was introduced by Callison-Burch et al. ([2012](#bib.bib2))
    to estimate if the translated tokens need to be edited or not, such as deletion,
    substitution, or keeping it as it is. In the later development of QE, a sentence-level
    task was introduced to predict the overall segment translation scores, which are
    to be correlated with human judgement scores, such as using Direct Assessment
    Graham et al. ([2015](#bib.bib8)). In WMT-2022, a new task on binary sentence-level
    classification was also introduced to predict if a translated output has critical
    errors to be fixed on English-German and Portuguses-English language pairs Zerva
    et al. ([2022](#bib.bib15)).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: MT 输出的质量评估（QE）一直是 MT 开发中的关键话题，因为它在训练过程中的质量评估中发挥着至关重要的作用。在许多情况下，评估必须在未看到参考翻译的情况下进行。在许多实际情况下，参考翻译不可用或甚至无法获取，即“制造”这些翻译进行评估并不实际。最早的
    QE 共享任务与年度 WMT 会议于 2012 年开始，当时 Callison-Burch 等人 ([2012](#bib.bib2)) 引入了词级 QE，用于估计翻译的标记是否需要编辑，如删除、替换或保持原样。在
    QE 的后续发展中，引入了句子级任务，用于预测整体段落翻译分数，这些分数要与人工判断分数相关联，例如使用直接评估 Graham 等人 ([2015](#bib.bib8))。在
    WMT-2022 中，还引入了一项新的二元句子级分类任务，以预测翻译输出是否存在需要修正的严重错误，适用于英语-德语和葡萄牙语-英语语言对 Zerva 等人
    ([2022](#bib.bib15))。
- en: The recent methods used for such QE tasks included prompt-based learning using
    XLM-R by KU X Upstage (Korea University, Korea & Upstage) from Eo et al. ([2022](#bib.bib4)),
    Direct Assessment and MQM features integration into fine-tuning on XLM-R and InfoXLM
    Chi et al. ([2021](#bib.bib3)) by the Alibaba team Bao et al. ([2022](#bib.bib1)),
    and incorporating a word-level sentence tagger and explanation extractor on top
    of the COMET framework by Rei et al. ([2022](#bib.bib14)), in addition to historical
    statistical methods such as support vector machine (SVM), Naive Bayes classifier
    (NB), and Conditional Random Fields (CRFs) by Han et al. ([2013](#bib.bib9)).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 最近用于此类 QE 任务的方法包括 KU X Upstage（韩国大学，韩国 & Upstage）使用 XLM-R 进行的基于提示的学习 Eo 等人 ([2022](#bib.bib4))，以及
    Alibaba 团队 Bao 等人 ([2022](#bib.bib1)) 将直接评估和 MQM 特征整合到 XLM-R 和 InfoXLM Chi 等人
    ([2021](#bib.bib3)) 的微调中，还包括在 COMET 框架顶部加入词级句子标记器和解释提取器 Rei 等人 ([2022](#bib.bib14))，以及
    Han 等人 ([2013](#bib.bib9)) 使用的历史统计方法，如支持向量机（SVM）、朴素贝叶斯分类器（NB）和条件随机场（CRFs）。
- en: However, to the best of our knowledge, this work is the first to investigate
    the OpenAI LLMs with varying sizes on such MT error prediction tasks with positive
    outcomes.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，据我们所知，这项工作是首个调查不同规模的 OpenAI LLMs 在这种 MT 错误预测任务中取得积极成果的研究。
- en: 3 Methodology and Experiments
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 方法论与实验
- en: '![Refer to caption](img/4c162b4a74f1bc1afedab868b2e1b48a.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/4c162b4a74f1bc1afedab868b2e1b48a.png)'
- en: 'Figure 1: LLMB2PEN Methodology Design on Fine-tuning LLMs for Binary Prediction
    of Post-editing Need on Translations.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：LLMB2PEN 方法论设计用于对翻译的后编辑需求进行二元预测的 LLMs 微调。
- en: '![Refer to caption](img/c5bbbfefbba1cabbe653850e5b267d01.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/c5bbbfefbba1cabbe653850e5b267d01.png)'
- en: 'Figure 2: EN-IT Examples on MT and Post-Editing'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：EN-IT MT 和后编辑的示例
- en: '![Refer to caption](img/98bba52e202f8e2d11ecfce0a60f57c0.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/98bba52e202f8e2d11ecfce0a60f57c0.png)'
- en: 'Figure 3: EN-DE Examples on MT and Post-Editing'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：EN-DE MT 和后编辑的示例
- en: 'As shown in the system diagram in Figure [1](#S3.F1 "Figure 1 ‣ 3 Methodology
    and Experiments ‣ Predictive Data Analytics with AI: assessing the need for post-editing
    of MT output by fine-tuning OpenAI LLMs"), we first collect the historical post-editing
    data from our past projects on eight languages of Enterprise Resource Planning
    (ERP) content translation on English$\rightarrow$German, French, Italian, Japanese,
    Dutch, Portuguese, Turkish, and Chinese (DE, FR, IT, JA, NL, PT, TR, ZH). This
    project was completed by using an MT engine to automatically translate the source
    into the eight languages, followed up by post-editing by professional linguists.
    Two examples of MT and PE in English-Italian and English-German languages as Pilot
    Experiments are shown in Figure [2](#S3.F2 "Figure 2 ‣ 3 Methodology and Experiments
    ‣ Predictive Data Analytics with AI: assessing the need for post-editing of MT
    output by fine-tuning OpenAI LLMs") and [3](#S3.F3 "Figure 3 ‣ 3 Methodology and
    Experiments ‣ Predictive Data Analytics with AI: assessing the need for post-editing
    of MT output by fine-tuning OpenAI LLMs"). Regarding MT system selection, since
    the content was from the ERP domain, we used the SAP STH as our MT engine. ³³3[https://www.sap.com/](https://www.sap.com/)
    SAP is an enterprise resource planning, automation and business software company.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '如图 [1](#S3.F1 "Figure 1 ‣ 3 Methodology and Experiments ‣ Predictive Data Analytics
    with AI: assessing the need for post-editing of MT output by fine-tuning OpenAI
    LLMs") 所示的系统图，我们首先收集了来自我们过去项目的历史后期编辑数据，涉及八种语言的企业资源规划（ERP）内容翻译，包括英语$\rightarrow$德语、法语、意大利语、日语、荷兰语、葡萄牙语、土耳其语和中文（DE,
    FR, IT, JA, NL, PT, TR, ZH）。该项目通过使用 MT 引擎自动将源文本翻译成这八种语言，并由专业语言学家进行后期编辑来完成。图 [2](#S3.F2
    "Figure 2 ‣ 3 Methodology and Experiments ‣ Predictive Data Analytics with AI:
    assessing the need for post-editing of MT output by fine-tuning OpenAI LLMs")
    和 [3](#S3.F3 "Figure 3 ‣ 3 Methodology and Experiments ‣ Predictive Data Analytics
    with AI: assessing the need for post-editing of MT output by fine-tuning OpenAI
    LLMs") 展示了英语-意大利语和英语-德语语言对的 MT 和 PE 作为试点实验。关于 MT 系统的选择，由于内容来自 ERP 领域，我们使用了 SAP
    STH 作为我们的 MT 引擎。³³3[https://www.sap.com/](https://www.sap.com/) SAP 是一家企业资源规划、自动化和业务软件公司。'
- en: With this data from real world translation project we used API to fine-tune
    the OpenAI curie model for our classification task. The input is the triple set
    (English source, MT outputs, post-edited ”gold standard”) we prepared in Phase
    1. The goal of this step is to optimise the weights of the model parameters for
    our classification task. The custom fine-tuned model produced as result of LLMB2PEN
    (LLM for Binary Prediction of Post-editing Need) method is created in our private
    space on the OpenAI account.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 利用来自真实世界翻译项目的数据，我们使用 API 对 OpenAI 的 Curie 模型进行了微调，以完成我们的分类任务。输入是我们在第一阶段准备的三元组集（英文源文本、机器翻译输出、后期编辑的“标准答案”）。这一步的目标是优化模型参数的权重，以满足我们的分类任务。通过
    LLMB2PEN（LLM用于二元预测后编辑需求）方法生成的定制微调模型被创建在我们 OpenAI 账户的私人空间中。
- en: We did not apply “prompt engineering” for this task by doing zero-shot, one-shot
    or few-shot training; we did a full scale fine-tuning of OpenAI LLMs via API.
    It is important to note that we did not simply train the LLM for edit distance
    either; instead, the model was trained to learn whether the strings were edited
    or not taking into account the full content of the string and the entire context
    of the training data. One of the reasons that we did not use prompting is that
    “Prompt Engineering” of ChatGPT-3 is limited by 3,000 tokens, and with ChatGPT-4
    the context has been increased to 25,000 tokens, but still very significant limitation
    remains. OpenAI documentation states that 100 tokens = 75 words, meaning that
    average sentence is 20 tokens, therefore 3000 tokens is only 150 sentences, or
    75 translation units of bilingual text, or 50 segment triples of source, target
    and reference. The context of 25,000 sentences is only about 150 segment triples.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有使用“提示工程”进行此任务，也没有进行零样本、一样本或少样本训练；我们通过 API 对 OpenAI LLMs 进行了全面的微调。需要注意的是，我们不仅仅是为了编辑距离训练
    LLM；相反，模型是被训练来学习字符串是否经过编辑，同时考虑到字符串的全部内容和整个训练数据的上下文。我们没有使用提示的原因之一是“ChatGPT-3 的提示工程”受到
    3,000 个 token 的限制，而 ChatGPT-4 的上下文增加到 25,000 个 token，但仍然存在非常显著的限制。OpenAI 文档指出
    100 个 token = 75 个词，这意味着平均句子为 20 个 token，因此 3,000 个 token 仅能包含 150 句，或 75 个双语文本的翻译单元，或
    50 个源文本、目标文本和参考的三元组。25,000 个句子的上下文仅相当于约 150 个三元组。
- en: Also, fine-tuning is a deeper process of adjusting model’s weights, and not
    just an in-context learning. That’s why we chose fine-tuning method, which is
    not constrained by such limitations.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，微调是一个调整模型权重的更深层次的过程，而不仅仅是上下文学习。这就是为什么我们选择了微调方法，它不受这种限制的约束。
- en: For our classification experiment we took about 4000 lines of bilingual data
    in triples of source, target and reference, and split it into train (large) and
    test (smaller) sets with a ratio of 9:1.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的分类实验，我们取了大约 4000 行的双语数据，包含源、目标和参考的三元组，并将其拆分为训练集（较大）和测试集（较小），比例为 9:1。
- en: There were no specific selection criteria for the data because we took the entire
    project dataset after project completion. (Please, note that since we used the
    entire data from actual project, and split the data set as 9:1, the sizes of test
    sets are not round and slightly different for different languages.)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 数据没有具体的选择标准，因为我们使用了整个项目的数据集（项目完成后）。 （请注意，由于我们使用了实际项目中的整个数据集，并将数据集拆分为 9:1，测试集的大小不是整齐的，不同语言之间略有不同。）
- en: We also combined source sentences in groups of length, so that test data set
    has the same distribution of sentences by their length as training dataset.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将源句子按长度分组，以便测试数据集与训练数据集具有相同的句子长度分布。
- en: Since the average sentence size is about 17 words, the training dataset contained
    about 35000 words of source data, 35000 words of MT output, and 35000 words of
    post-edited human reference.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 由于平均句子大小约为 17 个单词，训练数据集包含约 35000 个源数据单词、35000 个机器翻译输出单词和 35000 个后期编辑的人类参考单词。
- en: It is also important to note what the model learns in this case - in such an
    experiment it learns not to translate, but to spot MT translation errors that
    were made by the specific MT engine in a specific language pair on particular
    content.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 还需要注意的是，模型在这种情况下学习的是：在这样的实验中，它学习的不是翻译，而是识别特定语言对在特定内容上由特定机器翻译引擎所犯的翻译错误。
- en: 3.1 Outputs on EN-DE/IT
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 EN-DE/IT 输出
- en: 'As a first step, we trained the curie LLM model using our data for two language
    pairs: English-Italian and English-German. To illustrate the results of prediction
    with our LLMB2PEN method, we draw the confusion matrix for both language pairs
    on Figures [4](#S3.F4 "Figure 4 ‣ 3.1 Outputs on EN-DE/IT ‣ 3 Methodology and
    Experiments ‣ Predictive Data Analytics with AI: assessing the need for post-editing
    of MT output by fine-tuning OpenAI LLMs") and [5](#S3.F5 "Figure 5 ‣ 3.1 Outputs
    on EN-DE/IT ‣ 3 Methodology and Experiments ‣ Predictive Data Analytics with AI:
    assessing the need for post-editing of MT output by fine-tuning OpenAI LLMs").'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们使用我们的数据对 curie LLM 模型进行了训练，涉及两个语言对：英语-意大利语和英语-德语。为了展示我们使用 LLMB2PEN 方法的预测结果，我们在图
    [4](#S3.F4 "图 4 ‣ 3.1 EN-DE/IT 输出 ‣ 3 方法论与实验 ‣ AI 预测数据分析：通过微调 OpenAI LLMs 评估机器翻译输出的后期编辑需求")
    和 [5](#S3.F5 "图 5 ‣ 3.1 EN-DE/IT 输出 ‣ 3 方法论与实验 ‣ AI 预测数据分析：通过微调 OpenAI LLMs 评估机器翻译输出的后期编辑需求")
    中绘制了这两个语言对的混淆矩阵。
- en: 'In the Confusion Matrix, from the top left corner in a clockwise direction,
    the 1st quadrant means True Negative (TN): segment is predicted as not requiring
    editing and it does not indeed require post-editing. The 2nd quadrant is False
    Positive (FP): segments which are predicted as requiring editing, but in reality
    they do not, that is FP means that the segment is correct but wrongly flagged
    for post-editing. The 3rd quadrant is True Positive (TP) - reflect the situation
    when segment is correctly flagged as requiring post-editing. The fourth quadrant
    is False Negative (FN): segment is predicted as correct, while in reality it does
    require post-editing. So the first and third are successful classifications, and
    the other two are incorrect classifications.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在混淆矩阵中，从左上角开始，按顺时针方向，第一个象限表示真正负样本（TN）：段落被预测为不需要编辑，实际上确实不需要后期编辑。第二个象限是假阳性（FP）：被预测为需要编辑的段落，但实际上不需要，即
    FP 表示该段是正确的，但错误地标记为需要后期编辑。第三个象限是真正阳性（TP）：反映了段落被正确标记为需要后期编辑的情况。第四个象限是假阴性（FN）：段落被预测为正确，而实际上确实需要后期编辑。因此，第一个和第三个象限是成功的分类，其他两个则是错误的分类。
- en: It does worth mentioning that if segment is incorrectly predicted as requiring
    post-editing, this only leads to small increase of post-editing cost, while False
    Negative predictions represent the consumer’s risk to see substandard segments
    as not corrected in the final product. So in the context of our task we are much
    more concerned with the share of False Negatives in the test classification dataset.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 值得一提的是，如果段落被错误预测为需要后编辑，这只会导致后编辑成本的轻微增加，而假阴性预测则代表消费者面临在最终产品中看到未被纠正的次标准段落的风险。因此，在我们的任务背景下，我们更关心测试分类数据集中假阴性的比例。
- en: 'In the Italian situation shown on Figure [4](#S3.F4 "Figure 4 ‣ 3.1 Outputs
    on EN-DE/IT ‣ 3 Methodology and Experiments ‣ Predictive Data Analytics with AI:
    assessing the need for post-editing of MT output by fine-tuning OpenAI LLMs"),
    you can see that the model predicts correctly that there are much more translated
    sentences that need to be edited (TP=503) than sentences that do not need to be
    edited (TN=191). In incorrectly predicted categories, there are 67 sentences that
    need to be edited but predicted as good, and there are 81 translated sentences
    that do not need to be edited, but the prediction says they have to be reviewed.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在图 [4](#S3.F4 "图 4 ‣ 3.1 EN-DE/IT 输出 ‣ 3 方法与实验 ‣ 利用 AI 进行预测数据分析：通过微调 OpenAI
    LLMs 评估 MT 输出的后编辑需求") 中显示的意大利语情况中，可以看到模型正确预测了需要编辑的翻译句子（TP=503）远多于不需要编辑的句子（TN=191）。在错误预测的类别中，有67个句子需要编辑但被预测为好的，还有81个翻译句子不需要编辑，但预测显示需要审查。
- en: 'In the English-German set from Figure [5](#S3.F5 "Figure 5 ‣ 3.1 Outputs on
    EN-DE/IT ‣ 3 Methodology and Experiments ‣ Predictive Data Analytics with AI:
    assessing the need for post-editing of MT output by fine-tuning OpenAI LLMs"),
    the situation is the opposite: there are more translated sentences that do not
    need to be edited (442) than prescribed for review (256) in the correct predictions.
    In the wrong prediction categories, such numbers are 90 and 46 respectively.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在图 [5](#S3.F5 "图 5 ‣ 3.1 EN-DE/IT 输出 ‣ 3 方法与实验 ‣ 利用 AI 进行预测数据分析：通过微调 OpenAI
    LLMs 评估 MT 输出的后编辑需求") 中的英语-德语数据集中，情况正好相反：在正确预测中，更多的翻译句子不需要编辑（442）而不是需要审查（256）。在错误预测类别中，这些数字分别是
    90 和 46。
- en: The prediction accuracy of the LLMB2PEN model on our designed task is (TP+TN)/Total
    = (503+191)/842 = 82.42% for English-Italian MT, and (442+256)/834 = 83.69% for
    English-German MT. Overall, our LLMB2PEN method shows that the English-German
    output is clearly better than the English-Italian.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: LLMB2PEN 模型在我们设计的任务中的预测准确率为：英语-意大利语 MT 的 (TP+TN)/总数 = (503+191)/842 = 82.42%，英语-德语
    MT 的 (442+256)/834 = 83.69%。总体而言，我们的 LLMB2PEN 方法显示英语-德语输出明显优于英语-意大利语。
- en: However, if we only count the Type II errors (incorrect prediction that the
    segments should NOT be edited), then the corresponding error rates will be 67/842
    = 8% for Italian and 90/834 = 10% for German.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们只计算 Type II 错误（错误预测为不需要编辑的段落），那么相应的错误率将是意大利语的 67/842 = 8%，德语的 90/834
    = 10%。
- en: '![Refer to caption](img/6decca2b53f601cf85786b2ac5652672.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/6decca2b53f601cf85786b2ac5652672.png)'
- en: 'Figure 4: EN-IT Confusion Matrix of LLMB2PEN, curie model: Clockwise from top-left
    corner (TN, FP, TP, FN)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：LLMB2PEN 的 EN-IT 混淆矩阵，curie 模型：从左上角开始，顺时针方向（TN，FP，TP，FN）
- en: '![Refer to caption](img/1c4e9e7c09720b153452b890fa3287f7.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/1c4e9e7c09720b153452b890fa3287f7.png)'
- en: 'Figure 5: EN-DE Confusion Matrix of LLMB2PEN, curie model: Clockwise from top-left
    corner (TN, FP, TP, FN)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：LLMB2PEN 的 EN-DE 混淆矩阵，curie 模型：从左上角开始，顺时针方向（TN，FP，TP，FN）
- en: 3.2 Discussion
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 讨论
- en: 'The first and foremost finding is that the fine-tuned model actually learned
    enough information to make a very significant prediction of whether the segment
    has to be edited or not. It should be noted that such successful classification
    holds promise of a viable method to significantly reduce the volume of post-editing
    efforts and therefore time and costs. There is, however, a problem: while it is
    OK to present the editor with segments that are predicted as required for editing,
    but in reality do not require editing (the fourth quadrant, FP), real consumer’s
    risk comes from the segments that have been predicted as not requiring editing
    and made their way to the final predict, but in reality, they contain errors (the
    fourth quadrant, FN).'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 首要发现是，经过微调的模型实际上学到了足够的信息来做出非常重要的预测，判断段落是否需要编辑。需要指出的是，这种成功的分类预示着一种可行的方法，可以显著减少后期编辑的工作量，从而节省时间和成本。然而，有一个问题：虽然向编辑提供预测为需要编辑但实际上不需要编辑的段落（第四象限，FP）是可以接受的，但真正的消费者风险来自于那些被预测为不需要编辑并进入最终预测的段落，但实际上它们包含错误（第四象限，FN）。
- en: 'Such segments represent a significant portion of segments predicted as not
    requiring post-editing: FN/(TN+FN) = 67/(191+67) = 67/258 = 26% of “leave as is”
    (let’s call them “LAI”) segments for Italian, and 90/(442+90) = 90/532 = 16.9%
    for German.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这些段落占据了预测为不需要后期编辑的段落的显著部分：FN/(TN+FN) = 67/(191+67) = 67/258 = 26% 的“保持原样”（称之为“LAI”）段落（意大利语），以及
    90/(442+90) = 90/532 = 16.9%（德语）。
- en: It is possible that for specific language pairs and MT engines the portion of
    the LAI segments will decrease with the size increase of the training data and
    further fine-tuning, but it is unlikely to become zero, since with neural models
    the error rate is never zero.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对于特定语言对和 MT 引擎，LAI 段落的比例可能会随着训练数据规模的增加和进一步的微调而减少，但不太可能变为零，因为对于神经模型，错误率永远不会为零。
- en: 'Two strategies can be considered for implementing such prediction in production:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 可以考虑两种策略来在生产中实施这种预测：
- en: '1.'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: The LAI segments are excluded from the human loop and go into publication unvetted,
    but not straight away as they advance through the workflow along with all the
    other segments. In this scenario, the potential error rate ceiling for final content
    will be FN/Total = FN/(TP+FN+TN+FP) = 8% for Italian, i.e. 67/(81 + 67 + 191 +
    503) = 81/842 and 10.8%= 90 / (90 + 46+ 442 + 256) = 90/834 for German.
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LAI 段落被排除在人工审核之外，未经审查就进入发布阶段，但不是立即的，它们会与所有其他段落一起通过工作流程。在这种情况下，最终内容的潜在错误率上限为意大利语的
    FN/Total = FN/(TP+FN+TN+FP) = 8%，即 67/(81 + 67 + 191 + 503) = 81/842，以及德语的 10.8%
    = 90 / (90 + 46+ 442 + 256) = 90/834。
- en: It is not impossible to predict what would be the actual error rate in those
    8% and 10.8% segments that will not be reviewed, or the severity of errors in
    them. It is, obviously, the decision of the customer to decide whether this is
    an acceptable level of consumer risk for their situation (domain, type of content,
    audience, etc.). Additional risk assessment may be required to be carried out.
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预测那些 8% 和 10.8% 的段落的实际错误率或其中错误的严重性并非不可能。显然，决定是否接受这种消费者风险水平的最终决定由客户做出（包括领域、内容类型、受众等）。可能需要进行额外的风险评估。
- en: The savings on post-editing volume in this scenario would be (TN+FN)/Total =
    (191+67)/842 = 30.1% for Italian and (442+90)/834 = 63.8% for German.
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这种情况下，后期编辑体积的节省为 (TN+FN)/Total = (191+67)/842 = 30.1%（意大利语）和 (442+90)/834 =
    63.8%（德语）。
- en: '2.'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: 'All LAI segments are marked as “100% MT matches” in a CAT tool. With this approach,
    translators are requested to review them, but at a lower per-word rate, using
    the traditional approach which is well familiar to translation providers. In this
    scenario the reduction of the total time, effort, and cost can be estimated as
    follows: without this approach, translators working on Edit Distance Calculation
    (EDC) model will get lower payment (which can vary from 10% to 40% with different
    payment models) for not changed segments. In this scenario, translators may be
    asked to review such LAI segments but paid only small part of full rate for the
    review of such segments.'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 所有 LAI 段落在 CAT 工具中标记为“100% MT 匹配”。采用这种方法，要求译者对这些段落进行审查，但按较低的每字费率使用传统方法，这对翻译提供者来说非常熟悉。在这种情况下，总时间、精力和成本的减少可以估算如下：如果没有这种方法，处理编辑距离计算（EDC）模型的译者将对未更改的段落获得较低的支付（不同支付模型可能会有
    10% 到 40% 的变化）。在这种情况下，可能会要求译者审查这些 LAI 段落，但仅支付审查的部分费率。
- en: 'Simple proportion allows to calculate the savings in second scenario: if we
    take the full payment for all the segments for 100% of post-editing costs, and
    assume that 10% pay reflects adequate pay for the review of LAI segments that
    are marked as such, the volume of post-editing decreases 27.6% for Italian and
    57.4% for German with zero error rate of the final product (no producer’s or consumer’s
    risk).'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 简单的比例计算可以得出第二种情况的节省：如果我们对所有段落的全额支付为100%的后期编辑费用，并且假设10%的支付反映了对标记为LAI段落的适当支付，则意大利语的后期编辑量减少了27.6%，德语减少了57.4%，最终产品的错误率为零（没有生产者或消费者风险）。
- en: This estimate of a potential economy with a guarantee of zero error rate begs
    for further research and implementation of this method.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这种对潜在节省的估计以及零错误率的保证需要进一步的研究和方法实施。
- en: 4 Extended Experiments
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 扩展实验
- en: 4.1 On Six More Language Pairs
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 关于六种额外语言对
- en: 'We hereby also present extended experimental results using six more language
    pairs obtained with LMB2PEN method for translation editing distance prediction.
    These language pairs include English-to-French, Japanese, Dutch, Portuguese, Turkish,
    and Chinese (EN$\rightarrow$FR/JA/NL/PT/TR/ZH), whose results are listed in Figure
    [6](#S4.F6 "Figure 6 ‣ 4.1 On Six More Language Pairs ‣ 4 Extended Experiments
    ‣ Predictive Data Analytics with AI: assessing the need for post-editing of MT
    output by fine-tuning OpenAI LLMs"), [7](#S4.F7 "Figure 7 ‣ 4.1 On Six More Language
    Pairs ‣ 4 Extended Experiments ‣ Predictive Data Analytics with AI: assessing
    the need for post-editing of MT output by fine-tuning OpenAI LLMs"), [8](#S4.F8
    "Figure 8 ‣ 4.1 On Six More Language Pairs ‣ 4 Extended Experiments ‣ Predictive
    Data Analytics with AI: assessing the need for post-editing of MT output by fine-tuning
    OpenAI LLMs"), [9](#S4.F9 "Figure 9 ‣ 4.1 On Six More Language Pairs ‣ 4 Extended
    Experiments ‣ Predictive Data Analytics with AI: assessing the need for post-editing
    of MT output by fine-tuning OpenAI LLMs"), [10](#S4.F10 "Figure 10 ‣ 4.1 On Six
    More Language Pairs ‣ 4 Extended Experiments ‣ Predictive Data Analytics with
    AI: assessing the need for post-editing of MT output by fine-tuning OpenAI LLMs"),
    and [11](#S4.F11 "Figure 11 ‣ 4.1 On Six More Language Pairs ‣ 4 Extended Experiments
    ‣ Predictive Data Analytics with AI: assessing the need for post-editing of MT
    output by fine-tuning OpenAI LLMs") respectively.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还展示了使用LMB2PEN方法获得的六种额外语言对的扩展实验结果，这些语言对包括英语到法语、日语、荷兰语、葡萄牙语、土耳其语和中文（EN$\rightarrow$FR/JA/NL/PT/TR/ZH），其结果列于图[6](#S4.F6
    "图 6 ‣ 4.1 关于六种额外语言对 ‣ 4 扩展实验 ‣ AI预测数据分析：通过微调OpenAI LLMs评估MT输出的后期编辑需求")、[7](#S4.F7
    "图 7 ‣ 4.1 关于六种额外语言对 ‣ 4 扩展实验 ‣ AI预测数据分析：通过微调OpenAI LLMs评估MT输出的后期编辑需求")、[8](#S4.F8
    "图 8 ‣ 4.1 关于六种额外语言对 ‣ 4 扩展实验 ‣ AI预测数据分析：通过微调OpenAI LLMs评估MT输出的后期编辑需求")、[9](#S4.F9
    "图 9 ‣ 4.1 关于六种额外语言对 ‣ 4 扩展实验 ‣ AI预测数据分析：通过微调OpenAI LLMs评估MT输出的后期编辑需求")、[10](#S4.F10
    "图 10 ‣ 4.1 关于六种额外语言对 ‣ 4 扩展实验 ‣ AI预测数据分析：通过微调OpenAI LLMs评估MT输出的后期编辑需求") 和[11](#S4.F11
    "图 11 ‣ 4.1 关于六种额外语言对 ‣ 4 扩展实验 ‣ AI预测数据分析：通过微调OpenAI LLMs评估MT输出的后期编辑需求")。
- en: 'From the results presented in the figures, in general, the ratio of correct
    prediction (TP+TN) is much higher than the one from mis-prediction (FN+FP) across
    all these language pairs, as for English-Italian and English-German in the pilot
    studies. On one hand, the following language pairs have more True Positive than
    True Negative predicted segments than for English-German/Italian: English-Japanese,
    English-Portuguese, and English Chinese. On the other hand, the rest of language
    pairs have more TN than TP: English-French, and English-Dutch, except for English-Turkish
    which has a comparable number of segments between TP (347) and TN (353) labels.
    This finding also indicates that such language pairs with high number of TN labels
    are still much more challenging for MT system development to produce more correct
    outputs, i.e., English to French, Dutch, and Turkish. Earlier research findings
    from Gladkoff et al. ([2022](#bib.bib7)) on TQE conclude that 200+ segments can
    be enough amount of data to reflect the MT system quality.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 从图中呈现的结果来看，通常情况下，正确预测的比例（TP+TN）远高于误预测的比例（FN+FP），这与英语-意大利语和英语-德语的试点研究结果一致。一方面，以下语言对的真正正例（TP）预测段比真正负例（TN）预测段更多：英语-日语、英语-葡萄牙语和英语-中文。另一方面，其余语言对的
    TN 比 TP 更多：英语-法语和英语-荷兰语，除英语-土耳其语外，该对的 TP（347）与 TN（353）标签数量相当。这一发现也表明，标签 TN 数量高的语言对仍然对
    MT 系统开发具有更大的挑战，需要更多的正确输出，即英语到法语、荷兰语和土耳其语。Gladkoff 等人 ([2022](#bib.bib7)) 在 TQE
    上的早期研究发现，200+ 个段落可以足以反映 MT 系统的质量。
- en: '![Refer to caption](img/f22f62d16ac42d4b31895fb621716ef6.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/f22f62d16ac42d4b31895fb621716ef6.png)'
- en: 'Figure 6: EN-FR Confusion Matrix of LLMB2PEN, curie model: Clockwise from top-left
    corner (TN, FP, TP, FN)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：LLMB2PEN 的 EN-FR 混淆矩阵，curie 模型：从左上角顺时针（TN，FP，TP，FN）
- en: '![Refer to caption](img/89f729a5d3c24b1d1e2aa4f39c8fe8fc.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/89f729a5d3c24b1d1e2aa4f39c8fe8fc.png)'
- en: 'Figure 7: EN-JA Confusion Matrix of LLMB2PEN, curie model: Clockwise from left-up
    corner (TN, FP, TP, FN)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：LLMB2PEN 的 EN-JA 混淆矩阵，curie 模型：从左上角顺时针（TN，FP，TP，FN）
- en: '![Refer to caption](img/3c72588cc25ff5d07a814135dccd31cd.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/3c72588cc25ff5d07a814135dccd31cd.png)'
- en: 'Figure 8: EN-NL Confusion Matrix of LLMB2PEN, curie model: Clockwise from top-left
    corner (TN, FP, TP, FN)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：LLMB2PEN 的 EN-NL 混淆矩阵，curie 模型：从左上角顺时针（TN，FP，TP，FN）
- en: '![Refer to caption](img/27af8e71f56e645d78590a3985198c4e.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/27af8e71f56e645d78590a3985198c4e.png)'
- en: 'Figure 9: EN-PT Confusion Matrix of LLMB2PEN, curie model: Clockwise from left-up
    corner (TN, FP, TP, FN)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：LLMB2PEN 的 EN-PT 混淆矩阵，curie 模型：从左上角顺时针（TN，FP，TP，FN）
- en: '![Refer to caption](img/26d1be673bd521c4237ee2d04a90c545.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/26d1be673bd521c4237ee2d04a90c545.png)'
- en: 'Figure 10: EN-TR Confusion Matrix of LLMB2PEN, curie model: Clockwise from
    top-left corner (TN, FP, TP, FN)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：LLMB2PEN 的 EN-TR 混淆矩阵，curie 模型：从左上角顺时针（TN，FP，TP，FN）
- en: '![Refer to caption](img/402583ea560a69ba1c0039a314d06fa4.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/402583ea560a69ba1c0039a314d06fa4.png)'
- en: 'Figure 11: EN-ZH Confusion Matrix of LLMB2PEN, curie model: Clockwise from
    top-left corner (TN, FP, TP, FN)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11：LLMB2PEN 的 EN-ZH 混淆矩阵，curie 模型：从左上角顺时针（TN，FP，TP，FN）
- en: 5 Different LLMs on EN-JA News Domain
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 种不同 LLM 在 EN-JA 新闻领域
- en: In the subsequent experiment on data we used different news items translation
    corpus from different projects, translated from English to Japanese.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在随后的实验中，我们使用了来自不同项目的不同新闻翻译语料库，从英语翻译成日语。
- en: 'In this experiment, we have repeated experiments of fine-tuning the OpenAI
    gpt3.5turbo model on datasets of different sizes: 2000 pairs, 4000 pairs, and
    6000 pairs.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在此实验中，我们重复进行了对不同规模数据集的 OpenAI gpt3.5turbo 模型微调实验：2000 对、4000 对和 6000 对。
- en: 'Figure [12](#S5.F12 "Figure 12 ‣ 5 Different LLMs on EN-JA News Domain ‣ Predictive
    Data Analytics with AI: assessing the need for post-editing of MT output by fine-tuning
    OpenAI LLMs") shows the confusion matrix for the training set of 6000 bilingual
    EN-JA translation pairs in the news domain.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [12](#S5.F12 "图 12 ‣ 5 种不同 LLM 在 EN-JA 新闻领域 ‣ AI 的预测数据分析：通过微调 OpenAI LLM 评估
    MT 输出的后期编辑需求") 显示了新闻领域中 6000 个双语 EN-JA 翻译对的训练集混淆矩阵。
- en: 'We ran several experiments with varying training set sizes, with results shown
    in Figure [13](#S5.F13 "Figure 13 ‣ 5 Different LLMs on EN-JA News Domain ‣ Predictive
    Data Analytics with AI: assessing the need for post-editing of MT output by fine-tuning
    OpenAI LLMs").'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了多次不同训练集大小的实验，结果如图 [13](#S5.F13 "图 13 ‣ 5 种不同 LLM 在 EN-JA 新闻领域 ‣ AI 的预测数据分析：通过微调
    OpenAI LLM 评估 MT 输出的后期编辑需求") 所示。
- en: These results are interesting because although False Positive prediction does
    not improve with the increase of training set, in the context of the need for
    post-editing the False Negative category is much more interesting, because we
    are interested in better prediction of those segments which do NOT require post-editing.
    And, as we see from the experimental data, the prediction of FN improves from
    almost 20% to 12%-15% with the increase of training set from 2000 bilingual segments
    to 6000 bilingual segments.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果很有趣，因为尽管False Positive预测随着训练集的增加没有改善，但在需要后期编辑的背景下，False Negative类别更为有趣，因为我们关注的是更好地预测那些不需要后期编辑的段落。从实验数据中可以看到，随着训练集从2000个双语段落增加到6000个双语段落，FN的预测从接近20%改善到12%-15%。
- en: We, therefore, can recommend the training set in that range, since larger sizes
    of training set will be more expensive and will take significant time for models
    with the size of gpt3.5turbo.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以推荐这个范围的训练集，因为较大的训练集将更加昂贵，并且对于gpt3.5turbo这种大小的模型来说会需要大量时间。
- en: '![Refer to caption](img/140c51207c20983546b6ae654580c2a0.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/140c51207c20983546b6ae654580c2a0.png)'
- en: 'Figure 12: EN-JA news items Confusion Matrix of LLMB2PEN, gpt3.5turbo model:
    Clockwise from top-left corner (TP, FN, TN, FP)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图12：EN-JA新闻项目LLMB2PEN的混淆矩阵，gpt3.5turbo模型：从左上角开始顺时针（TP，FN，TN，FP）
- en: '![Refer to caption](img/a28b6c8bc2d38c1e5a5c0e976c19c09e.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/a28b6c8bc2d38c1e5a5c0e976c19c09e.png)'
- en: 'Figure 13: EN-JA news items predictions with fine-tuning completed on different
    training dataset sizes, gpt3.5turbo model'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图13：EN-JA新闻项目在不同训练数据集大小上完成微调后的预测，gpt3.5turbo模型
- en: 5.1 Comparison of performance on different OpenAI models
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 不同OpenAI模型的性能比较
- en: It was also interesting to see how the extra-large LLMs (xLLMs) from OpenAI,
    the davinci and gpt3.5turbo models, perform on the same task in comparison to
    curie model we used earlier. These three LLMs have the parameter sizes around
    13B, 175B, and 175B respectively.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 看到OpenAI的超大规模LLM（xLLMs），即davinci和gpt3.5turbo模型，在与我们早期使用的curie模型在相同任务上的表现进行比较也很有趣。这三种LLM的参数规模分别为13B、175B和175B。
- en: So we used the same English-Italian data from our original experiment to compare
    performance on different models of the same EN-IT dataset.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们使用了来自原始实验的相同英意数据，以比较不同模型在相同EN-IT数据集上的表现。
- en: 'Figure [14](#S5.F14 "Figure 14 ‣ 5.1 Comparison of performance on different
    OpenAI models ‣ 5 Different LLMs on EN-JA News Domain ‣ Predictive Data Analytics
    with AI: assessing the need for post-editing of MT output by fine-tuning OpenAI
    LLMs") shows the comparison of these three LLMs regarding their confusion matrix
    and parameter sets. Surprisingly, their performances on predicting MT errors are
    very close, i.e. the larger-sized davinci model and extra-large sized gpt3.5turbo
    did not demonstrate much improvement on model classification accuracy. Their correct
    labels (TP+TN) are (694, 699, 706) respectively out of 842 all labels, which results
    in the accuracy ratios 82.42%, 83.02%, and 83.85%. In comparison to the much smaller
    curie model with 12 layers of Transformer and 768 hidden units, the xLLM gpt3.5turbo
    only achieved 1.43 points (83.85%-82.42%) increase of accuracy score despite using
    175 layers of Transformer and 4096 hidden units.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图[14](#S5.F14 "图 14 ‣ 5.1 不同OpenAI模型的性能比较 ‣ EN-JA新闻领域的5种不同LLM ‣ 使用AI的预测数据分析：通过微调OpenAI
    LLM来评估机器翻译输出的后期编辑需求")展示了这三种LLM在混淆矩阵和参数集方面的比较。令人惊讶的是，它们在预测MT错误方面的表现非常接近，即较大的davinci模型和超大规模的gpt3.5turbo在模型分类准确性上没有显示出显著的提升。它们的正确标签（TP+TN）分别是（694，699，706），总标签数为842，相应的准确率为82.42%，83.02%和83.85%。相比之下，使用12层Transformer和768个隐藏单元的较小curie模型，xLLM
    gpt3.5turbo尽管使用了175层Transformer和4096个隐藏单元，但准确率仅提高了1.43个百分点（83.85%-82.42%）。
- en: The explanation for this may probably be found considering the fact that the
    fine-tuning loss on this classification task drops down very quickly.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这一现象的解释可能在于考虑到在这个分类任务上的微调损失下降非常快。
- en: 'Figure [15](#S5.F15 "Figure 15 ‣ 5.1 Comparison of performance on different
    OpenAI models ‣ 5 Different LLMs on EN-JA News Domain ‣ Predictive Data Analytics
    with AI: assessing the need for post-editing of MT output by fine-tuning OpenAI
    LLMs") shows the fine-tuning loss on the gpt3.5turbo model. As can be seen from
    this graph, only 100 steps are sufficient to bring the loss to almost zero, and
    then all other steps contribute very little to the classification quality improvement.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [15](#S5.F15 "图 15 ‣ 5.1 不同 OpenAI 模型性能比较 ‣ EN-JA 新闻领域的 5 种不同 LLM ‣ 通过微调 OpenAI
    LLM 评估 MT 输出的后编辑需求") 显示了 gpt3.5turbo 模型上的微调损失。从图中可以看出，仅需 100 步即可将损失降到几乎为零，然后所有其他步骤对分类质量的改善贡献非常小。
- en: As we can see, there is no need to use larger models since results hardly improve
    as compared with curie model.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，由于与 curie 模型相比，结果几乎没有改善，因此没有必要使用更大的模型。
- en: '![Refer to caption](img/3331a613fe41fd0e4d398ce30e17015d.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/3331a613fe41fd0e4d398ce30e17015d.png)'
- en: 'Figure 14: Comparisons of three LLMs on Confusion Matrix and Parameters.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14：三个 LLM 在混淆矩阵和参数上的比较。
- en: '![Refer to caption](img/67d1b9d67095daa06f81aece0667ab47.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/67d1b9d67095daa06f81aece0667ab47.png)'
- en: 'Figure 15: Fine-tuning progress on gpt3.5turbo model fine-tuning.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15：gpt3.5turbo 模型微调进度。
- en: 6 Conclusions and Future Work
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论与未来工作
- en: In this work, to investigate the LLM’s capability of predicting MT output errors,
    we fine-tuned GPT models via OpenAI API. We formulated the task as a classification
    challenge using prepared historical post-editing data on English-Italian and English-German
    for pilot studies. The experimental output using fine-tuned LLMB2PEN demonstrated
    promising results. We also analysed the possible solutions for addressing the
    error rates, i.e. whether prediction errors can be ignored and published without
    the review, or letting them be reviewed by the linguists at a lower rate, and
    how much saving can be achieved for the client who uses this process, in comparison
    to 100% post-editing without using LLMB2PEN method.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，为了调查 LLM 预测机器翻译输出错误的能力，我们通过 OpenAI API 对 GPT 模型进行了微调。我们将任务制定为分类挑战，使用了英语-意大利语和英语-德语的历史后编辑数据进行初步研究。使用微调的
    LLMB2PEN 的实验结果显示出有希望的结果。我们还分析了处理错误率的可能解决方案，即预测错误是否可以忽略并发布而无需审查，或者让语言学家以较低的费率进行审查，以及与不使用
    LLMB2PEN 方法的 100% 后编辑相比，这一过程能为客户节省多少费用。
- en: In the extended experiments, we added six more language pairs including English-to-French,
    Japanese, Dutch, Portuguese, Turkish, and Chinese, in total resulting in eight,
    and summarised our findings by classifying the language pairs. We also compared
    GPT models from different sizes and the experimental results surprisingly show
    that the larger LLMs (davinci and gpt3.5turbo) do not improve the accuracy performance
    of much smaller curie model with apparent margins but with much more cost.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在扩展实验中，我们增加了六对语言对，包括英法、日语、荷兰语、葡萄牙语、土耳其语和中文，总共达到了八对，并通过对语言对进行分类来总结我们的发现。我们还比较了不同规模的
    GPT 模型，实验结果令人惊讶地显示，较大的 LLM（davinci 和 gpt3.5turbo）并没有显著改善较小的 curie 模型的准确性表现，但成本却高得多。
- en: In the future, we are going to work on response rate and training times to see
    whether the model can continue learning as being fed with more consecutive chunks
    of data for the same languages, to implement an ongoing learning of prediction.
    In addition, we plan to carry out the LLMB2PEN fine-tuning on other language pairs
    for which we have historical data. We intend to explore to what extent the model
    is capable of absorbing data for several languages, i.e. one fine-tuned multilingual
    model serving several language pairs.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 未来，我们将致力于响应率和训练时间，以查看模型是否能够继续学习，即在相同语言的更多连续数据块中获取数据，以实施持续的预测学习。此外，我们计划对其他有历史数据的语言对进行
    LLMB2PEN 微调。我们打算探索模型在多个语言数据中的吸收能力，即一个经过微调的多语言模型服务于多个语言对。
- en: To further extend this project, it will also be interesting to explore and check
    whether the LLMB2PEN method can help to identify human-introduced errors or translationese.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步扩展这个项目，探索和检查 LLMB2PEN 方法是否能帮助识别人为引入的错误或翻译体将是很有趣的。
- en: Limitations
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 局限性
- en: In this work, we reported MT QE experiments using eight language data translated
    from English. The positive results produced from the OpenAI models can be further
    enhanced by more language pairs, as well as broader domains of the corpus.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们报告了使用从英语翻译的八种语言数据进行的MT QE实验。来自OpenAI模型的积极结果可以通过更多语言对和更广泛的语料库领域进一步增强。
- en: The main limitation of the method is non-zero fine-tuning time. The fine-tuning
    takes about 20 minutes and therefore cannot be made continuous, which has to be
    done periodically, in batches. This hardly can be overcome, but deployment methods
    can be applied to quickly replace the older fine-tuned models with the newer ones.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 方法的主要限制是非零微调时间。微调大约需要20分钟，因此不能连续进行，必须定期批量进行。这几乎无法克服，但可以应用部署方法以快速用更新的微调模型替换旧的模型。
- en: Ethical Statement
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 伦理声明
- en: This work has no ethical concerns since we did not disclose identifiable private
    user data.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作没有伦理问题，因为我们没有披露可识别的私人用户数据。
- en: Acknowledgements
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: 'We thank Georg Kirchner, Globalization Technology Manager at Dell Technologies,
    for the valuable comments on the initial manuscript. LH and GN are grateful for
    the support from the grant “Assembling the Data Jigsaw: Powering Robust Research
    on the Causes, Determinants and Outcomes of MSK Disease”. The project has been
    funded by the Nuffield Foundation, but the views expressed are those of the authors
    and not necessarily the Foundation. Visit www.nuffieldfoundation.org. LH and GN
    were also supported by the grant “Integrating hospital outpatient letters into
    the healthcare data space” (EP/V047949/1; funder: UKRI/EPSRC).'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢戴尔科技公司全球化技术经理 Georg Kirchner 对初稿提出的宝贵意见。LH 和 GN 感谢“拼接数据难题：推动对MSK疾病的原因、决定因素和结果的深入研究”资助的支持。该项目已获得努菲尔德基金会资助，但所表达的观点仅代表作者，不一定是基金会的观点。访问
    www.nuffieldfoundation.org。LH 和 GN 还得到“将医院门诊信件整合到医疗数据空间”项目资助（EP/V047949/1；资助方：UKRI/EPSRC）的支持。
- en: References
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Bao et al. (2022) Keqin Bao, Yu Wan, Dayiheng Liu, Baosong Yang, Wenqiang Lei,
    Xiangnan He, Derek F. Wong, and Jun Xie. 2022. [Alibaba-translate China’s submission
    for WMT 2022 quality estimation shared task](https://aclanthology.org/2022.wmt-1.55).
    In *Proceedings of the Seventh Conference on Machine Translation (WMT)*, pages
    597–605, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational
    Linguistics.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bao 等（2022）Keqin Bao、Yu Wan、Dayiheng Liu、Baosong Yang、Wenqiang Lei、Xiangnan
    He、Derek F. Wong 和 Jun Xie。2022年。[Alibaba-translate China 的 WMT 2022 质量评估提交共享任务](https://aclanthology.org/2022.wmt-1.55)。在
    *第七届机器翻译会议（WMT）论文集*，页面597–605，阿布扎比，阿联酋（混合）。计算语言学协会。
- en: Callison-Burch et al. (2012) Chris Callison-Burch, Philipp Koehn, Christof Monz,
    Matt Post, Radu Soricut, and Lucia Specia, editors. 2012. [*Proceedings of the
    Seventh Workshop on Statistical Machine Translation*](https://aclanthology.org/W12-3100).
    Association for Computational Linguistics, Montréal, Canada.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Callison-Burch 等（2012）Chris Callison-Burch、Philipp Koehn、Christof Monz、Matt
    Post、Radu Soricut 和 Lucia Specia，编辑。2012年。[*第七届统计机器翻译研讨会论文集*](https://aclanthology.org/W12-3100)。计算语言学协会，蒙特利尔，加拿大。
- en: 'Chi et al. (2021) Zewen Chi, Li Dong, Furu Wei, Nan Yang, Saksham Singhal,
    Wenhui Wang, Xia Song, Xian-Ling Mao, Heyan Huang, and Ming Zhou. 2021. [InfoXLM:
    An information-theoretic framework for cross-lingual language model pre-training](https://doi.org/10.18653/v1/2021.naacl-main.280).
    In *Proceedings of the 2021 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies*, pages 3576–3588,
    Online. Association for Computational Linguistics.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chi 等（2021）Zewen Chi、Li Dong、Furu Wei、Nan Yang、Saksham Singhal、Wenhui Wang、Xia
    Song、Xian-Ling Mao、Heyan Huang 和 Ming Zhou。2021年。[InfoXLM：一种用于跨语言模型预训练的信息理论框架](https://doi.org/10.18653/v1/2021.naacl-main.280)。在
    *2021年北美计算语言学协会：人类语言技术会议论文集*，页面3576–3588，在线。计算语言学协会。
- en: 'Eo et al. (2022) Sugyeong Eo, Chanjun Park, Hyeonseok Moon, Jaehyung Seo, and
    Heuiseok Lim. 2022. [KU X upstage’s submission for the WMT22 quality estimation:
    Critical error detection shared task](https://aclanthology.org/2022.wmt-1.56).
    In *Proceedings of the Seventh Conference on Machine Translation (WMT)*, pages
    606–614, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational
    Linguistics.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eo 等（2022）Sugyeong Eo、Chanjun Park、Hyeonseok Moon、Jaehyung Seo 和 Heuiseok Lim。2022年。[KU
    X upstage 的 WMT22 质量评估提交：关键错误检测共享任务](https://aclanthology.org/2022.wmt-1.56)。在
    *第七届机器翻译会议（WMT）论文集*，页面606–614，阿布扎比，阿联酋（混合）。计算语言学协会。
- en: 'Freitag et al. (2021) Markus Freitag, George Foster, David Grangier, Viresh
    Ratnakar, Qijun Tan, and Wolfgang Macherey. 2021. [Experts, Errors, and Context:
    A Large-Scale Study of Human Evaluation for Machine Translation](http://arxiv.org/abs/2104.14478).
    *arXiv e-prints*, page arXiv:2104.14478.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Freitag 等 (2021) Markus Freitag, George Foster, David Grangier, Viresh Ratnakar,
    Qijun Tan, 和 Wolfgang Macherey. 2021. [专家、错误与背景：对机器翻译人工评估的大规模研究](http://arxiv.org/abs/2104.14478)。*arXiv
    电子预印本*，第arXiv:2104.14478页。
- en: 'Gladkoff and Han (2022) Serge Gladkoff and Lifeng Han. 2022. [HOPE: A task-oriented
    and human-centric evaluation framework using professional post-editing towards
    more effective MT evaluation](https://aclanthology.org/2022.lrec-1.2). In *Proceedings
    of the Thirteenth Language Resources and Evaluation Conference*, pages 13–21,
    Marseille, France. European Language Resources Association.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gladkoff 和 Han (2022) Serge Gladkoff 和 Lifeng Han. 2022. [HOPE: 一种以任务为导向和以人为本的评估框架，利用专业后期编辑以实现更有效的机器翻译评估](https://aclanthology.org/2022.lrec-1.2)。在
    *第十三届语言资源与评估会议论文集*，第13–21页，法国马赛。欧洲语言资源协会。'
- en: Gladkoff et al. (2022) Serge Gladkoff, Irina Sorokina, Lifeng Han, and Alexandra
    Alekseeva. 2022. [Measuring uncertainty in translation quality evaluation (TQE)](https://aclanthology.org/2022.lrec-1.156).
    In *Proceedings of the Thirteenth Language Resources and Evaluation Conference*,
    pages 1454–1461, Marseille, France. European Language Resources Association.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gladkoff 等 (2022) Serge Gladkoff, Irina Sorokina, Lifeng Han, 和 Alexandra Alekseeva.
    2022. [翻译质量评估中的不确定性测量 (TQE)](https://aclanthology.org/2022.lrec-1.156)。在 *第十三届语言资源与评估会议论文集*，第1454–1461页，法国马赛。欧洲语言资源协会。
- en: 'Graham et al. (2015) Yvette Graham, Timothy Baldwin, and Nitika Mathur. 2015.
    [Accurate evaluation of segment-level machine translation metrics](http://aclweb.org/anthology/N/N15/N15-1124.pdf).
    In *NAACL HLT 2015, The 2015 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies, Denver, Colorado,
    USA, May 31 - June 5, 2015*, pages 1183–1191.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Graham 等 (2015) Yvette Graham, Timothy Baldwin, 和 Nitika Mathur. 2015. [段落级机器翻译度量的准确评估](http://aclweb.org/anthology/N/N15/N15-1124.pdf)。在
    *NAACL HLT 2015，北美计算语言学协会人类语言技术会议：美国科罗拉多州丹佛，2015年5月31日至6月5日*，第1183–1191页。
- en: Han et al. (2013) Aaron Li-Feng Han, Yi Lu, Derek F. Wong, Lidia S. Chao, Liangye
    He, and Junwen Xing. 2013. [Quality estimation for machine translation using the
    joint method of evaluation criteria and statistical modeling](https://aclanthology.org/W13-2245).
    In *Proceedings of the Eighth Workshop on Statistical Machine Translation*, pages
    365–372, Sofia, Bulgaria. Association for Computational Linguistics.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Han 等 (2013) Aaron Li-Feng Han, Yi Lu, Derek F. Wong, Lidia S. Chao, Liangye
    He, 和 Junwen Xing. 2013. [使用评估标准与统计建模联合方法的机器翻译质量估计](https://aclanthology.org/W13-2245)。在
    *第八届统计机器翻译研讨会论文集*，第365–372页，保加利亚索非亚。计算语言学协会。
- en: Han (2022a) Lifeng Han. 2022a. [*An investigation into multi-word expressions
    in machine translation*](https://doras.dcu.ie/26559/1/Lifeng_Han_PhD_Thesis_singed_2print.pdf).
    Ph.D. thesis, Dublin City University.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Han (2022a) Lifeng Han. 2022a. [*关于机器翻译中的多词表达的研究*](https://doras.dcu.ie/26559/1/Lifeng_Han_PhD_Thesis_singed_2print.pdf)。博士论文，都会大学。
- en: Han (2022b) Lifeng Han. 2022b. An overview on machine translation evaluation.
    *arXiv preprint arXiv:2202.11027*.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Han (2022b) Lifeng Han. 2022b. 关于机器翻译评估的概述。*arXiv 预印本 arXiv:2202.11027*。
- en: 'Han and Gladkoff (2022) Lifeng Han and Serge Gladkoff. 2022. [Meta-evaluation
    of translation evaluation methods: a systematic up-to-date overview](https://github.com/poethan/LREC22_MetaEval_Tutorial).
    In *Tutorial at LREC2022*, Marseille, France.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Han 和 Gladkoff (2022) Lifeng Han 和 Serge Gladkoff. 2022. [翻译评估方法的元评估：一个系统的最新概述](https://github.com/poethan/LREC22_MetaEval_Tutorial)。在
    *LREC2022 研讨会*，法国马赛。
- en: Koehn et al. (2022) Philipp Koehn, Loïc Barrault, Ondřej Bojar, Fethi Bougares,
    Rajen Chatterjee, Marta R. Costa-jussà, Christian Federmann, Mark Fishel, Alexander
    Fraser, Markus Freitag, Yvette Graham, Roman Grundkiewicz, Paco Guzman, Barry
    Haddow, Matthias Huck, Antonio Jimeno Yepes, Tom Kocmi, André Martins, Makoto
    Morishita, Christof Monz, Masaaki Nagata, Toshiaki Nakazawa, Matteo Negri, Aurélie
    Névéol, Mariana Neves, Martin Popel, Marco Turchi, and Marcos Zampieri, editors.
    2022. [*Proceedings of the Seventh Conference on Machine Translation (WMT)*](https://aclanthology.org/2022.wmt-1.0).
    Association for Computational Linguistics, Abu Dhabi, United Arab Emirates (Hybrid).
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Koehn et al. (2022) Philipp Koehn, Loïc Barrault, Ondřej Bojar, Fethi Bougares,
    Rajen Chatterjee, Marta R. Costa-jussà, Christian Federmann, Mark Fishel, Alexander
    Fraser, Markus Freitag, Yvette Graham, Roman Grundkiewicz, Paco Guzman, Barry
    Haddow, Matthias Huck, Antonio Jimeno Yepes, Tom Kocmi, André Martins, Makoto
    Morishita, Christof Monz, Masaaki Nagata, Toshiaki Nakazawa, Matteo Negri, Aurélie
    Névéol, Mariana Neves, Martin Popel, Marco Turchi, and Marcos Zampieri, editors.
    2022. [*第七届机器翻译会议（WMT）会议录*](https://aclanthology.org/2022.wmt-1.0)。计算语言学协会，阿布扎比，阿拉伯联合酋长国（混合形式）。
- en: 'Rei et al. (2022) Ricardo Rei, Marcos Treviso, Nuno M. Guerreiro, Chrysoula
    Zerva, Ana C Farinha, Christine Maroti, José G. C. de Souza, Taisiya Glushkova,
    Duarte Alves, Luisa Coheur, Alon Lavie, and André F. T. Martins. 2022. [CometKiwi:
    IST-unbabel 2022 submission for the quality estimation shared task](https://aclanthology.org/2022.wmt-1.60).
    In *Proceedings of the Seventh Conference on Machine Translation (WMT)*, pages
    634–645, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational
    Linguistics.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Rei et al. (2022) Ricardo Rei, Marcos Treviso, Nuno M. Guerreiro, Chrysoula
    Zerva, Ana C Farinha, Christine Maroti, José G. C. de Souza, Taisiya Glushkova,
    Duarte Alves, Luisa Coheur, Alon Lavie, and André F. T. Martins. 2022. [CometKiwi:
    IST-unbabel 2022 提交的质量估计共享任务](https://aclanthology.org/2022.wmt-1.60)。见于*第七届机器翻译会议（WMT）会议录*，第634–645页，阿布扎比，阿拉伯联合酋长国（混合形式）。计算语言学协会。'
- en: Zerva et al. (2022) Chrysoula Zerva, Frédéric Blain, Ricardo Rei, Piyawat Lertvittayakumjorn,
    José G. C. de Souza, Steffen Eger, Diptesh Kanojia, Duarte Alves, Constantin Orăsan,
    Marina Fomicheva, André F. T. Martins, and Lucia Specia. 2022. [Findings of the
    WMT 2022 shared task on quality estimation](https://aclanthology.org/2022.wmt-1.3).
    In *Proceedings of the Seventh Conference on Machine Translation (WMT)*, pages
    69–99, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational
    Linguistics.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zerva et al. (2022) Chrysoula Zerva, Frédéric Blain, Ricardo Rei, Piyawat Lertvittayakumjorn,
    José G. C. de Souza, Steffen Eger, Diptesh Kanojia, Duarte Alves, Constantin Orăsan,
    Marina Fomicheva, André F. T. Martins, and Lucia Specia. 2022. [WMT 2022 质量估计共享任务的发现](https://aclanthology.org/2022.wmt-1.3)。见于*第七届机器翻译会议（WMT）会议录*，第69–99页，阿布扎比，阿拉伯联合酋长国（混合形式）。计算语言学协会。
