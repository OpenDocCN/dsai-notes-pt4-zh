- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '类别: 未分类'
- en: 'date: 2024-09-08 18:39:29'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:39:29
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Establishing Performance Baselines in Fine-Tuning, Retrieval-Augmented Generation
    and Soft-Prompting for Non-Specialist LLM Users
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为非专业LLM用户建立微调、检索增强生成和软提示的性能基准
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2311.05903](https://ar5iv.labs.arxiv.org/html/2311.05903)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2311.05903](https://ar5iv.labs.arxiv.org/html/2311.05903)
- en: Jennifer Dodgson
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Jennifer Dodgson
- en: kipley.ai
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: kipley.ai
- en: \AndLin Nanzheng
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: \AndLin Nanzheng
- en: kipley.ai
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: kipley.ai
- en: \AndJulian Peh
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: \AndJulian Peh
- en: kipley.ai
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: kipley.ai
- en: \AndAkira Rafhael Janson Pattirane
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: \AndAkira Rafhael Janson Pattirane
- en: Universitas Kristen Duta Wacana
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 基督教杜塔瓦卡纳大学
- en: \AndAlfath Daryl Alhajir
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: \AndAlfath Daryl Alhajir
- en: kipley.ai
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: kipley.ai
- en: \AndEko Ridho Dinarto
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: \AndEko Ridho Dinarto
- en: kipley.ai
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: kipley.ai
- en: \AndJoseph Lim
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: \AndJoseph Lim
- en: kipley.ai
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: kipley.ai
- en: \AndSyed Danyal Ahmad
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: \AndSyed Danyal Ahmad
- en: TU Dortmund
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: TU 多特蒙德大学
- en: Abstract
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Research into methods for improving the performance of large language models
    (LLMs) through fine-tuning, retrieval-augmented generation (RAG) and soft-prompting
    has tended to focus on the use of highly technical or high-cost techniques, making
    many of the newly discovered approaches comparatively inaccessible to non-technical
    users. In this paper we tested an unmodified version of GPT 3.5, a fine-tuned
    version, and the same unmodified model when given access to a vectorised RAG database,
    both in isolation and in combination with a basic, non-algorithmic soft prompt.
    In each case we tested the model’s ability to answer a set of 100 questions relating
    primarily to events that occurred after September 2021 (the point at which GPT
    3.5’s training data set ends). We found that if commercial platforms are used
    and default settings are applied with no iteration in order to establish a baseline
    set of outputs, a fine-tuned model outperforms GPT 3.5 Turbo, while the RAG approach
    out-performed both. The application of a soft prompt significantly improved the
    performance of each approach.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 研究表明，通过微调、检索增强生成（RAG）和软提示来提升大型语言模型（LLMs）性能的方法，通常侧重于使用高度技术性或高成本的技术，使得许多新发现的方法对非技术用户相对难以接触。在本文中，我们测试了未修改的GPT
    3.5版本、微调版本，以及在访问向量化RAG数据库时相同的未修改模型，同时还结合了一个基本的非算法软提示。在每种情况下，我们测试了模型回答一组主要涉及2021年9月之后发生的事件的100个问题的能力（即GPT
    3.5的训练数据集结束的时间点）。我们发现，如果使用商业平台并应用默认设置而不进行迭代以建立基准输出集，则微调模型的表现优于GPT 3.5 Turbo，而RAG方法则表现更佳。应用软提示显著提升了每种方法的性能。
- en: '*K*eywords performance baseline  $\cdot$ retrieval augmented generation  $\cdot$
    large language model'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*K*eywords 性能基准  $\cdot$ 检索增强生成  $\cdot$ 大型语言模型'
- en: 1 Introduction
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Extensive academic research has been conducted on methods for improving base
    large language models (LLMs) through fine-tuning and - more recently - via retrieval-augmented
    generation (RAG). The fine-tuning process begins with a set of base model weights
    determined via training on a large corpus of text data. This pre-trained model
    has already acquired a wide range of language patterns, syntax, and semantics,
    and the fine-tuning process involves repeating this process using a task-specific
    dataset with the aim of improving the model’s capacity in a particular area such
    as text classification, language translation, question-answering, or text generation.
    A task-specific objective function is defined, which quantifies how well the model
    is performing on the chosen task. This is typically a loss function that measures
    the difference between the model’s predictions and the ground truth in the training
    data.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 关于通过微调和 - 最近 - 通过检索增强生成（RAG）来改善基础大型语言模型（LLMs）的方法，已有广泛的学术研究。微调过程始于在大规模文本数据语料库上训练所确定的基础模型权重。这个预训练模型已经掌握了广泛的语言模式、句法和语义，微调过程涉及使用特定任务的数据集重复这一过程，目的是提高模型在特定领域（如文本分类、语言翻译、问答或文本生成）的能力。定义了一个特定任务的目标函数，该函数量化了模型在选择任务上的表现如何。这通常是一个损失函数，用来衡量模型预测与训练数据中真实值之间的差异。
- en: The pre-trained LLM is fine-tuned on the task-specific dataset using backpropagation
    and gradient descent. During fine-tuning, the model’s weights are updated to minimise
    the defined objective function. The model generalises from the provided examples
    and learns to make predictions specific to the task. RAG, by contrast, does not
    involve altering the model weights, but rather passing in information relevant
    to user prompts via a multi-stage information retrieval system. This usually involves
    an initial stage in which a user’s input prompt is used to search an external
    data source - whether via web search, semantic search of a vector database, text-to-SQL
    queries or other methods. This ranks and selects the most relevant documents or
    passages based on the provided query, which are in turn passed to the LLM, which
    is instructed to answer the user question by means of the passages retrieved.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练的LLM通过反向传播和梯度下降在任务特定的数据集上进行微调。在微调过程中，模型的权重会被更新，以最小化定义的目标函数。模型从提供的示例中进行泛化，并学会做出特定任务的预测。相对而言，RAG并不涉及改变模型权重，而是通过多阶段信息检索系统传递与用户提示相关的信息。这通常涉及一个初始阶段，其中用户的输入提示用于搜索外部数据源——无论是通过网络搜索、向量数据库的语义搜索、文本到SQL查询或其他方法。这会根据提供的查询排名和选择最相关的文档或段落，然后将这些文档或段落传递给LLM，LLM根据检索到的段落回答用户问题。
- en: 'The majority of the articles published on these topics tend to focus on cutting
    edge techniques for improving a given method. However, these techniques often
    require significant financial resources and/or technical expertise, and are thus
    out of reach for the majority of users. Indeed, an average corporate user wishing
    to create a custom model is faced with a proliferation of options, all assessed
    according to differing metrics and often with no useful baseline with which to
    compare the results. Our goal in this paper is to provide just such a baseline.
    We compare the the results given by GPT 3.5 Turbo in its unmodified form, with
    fine-tuned and RAG versions created using the default settings presented to users
    via two commercially available platforms assessed to be comparatively accessible
    both in terms of cost and the IT skills required for use: OpenAI’s own fine-tuning
    API, and the [kipley.ai](http://kipley.ai)’s RAG platform (dubbed “easyRAG”).
    At the same time, we tested the impact of soft-prompting on each approach with
    two sets of questions: one base set and one reinforced by soft meta-prompts.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这些主题上发表的大多数文章往往集中在改进给定方法的前沿技术。然而，这些技术通常需要大量的财务资源和/或技术专长，因此大多数用户无法触及。实际上，希望创建自定义模型的普通企业用户面临着众多选择，这些选择都是根据不同的指标评估的，并且通常没有有用的基准来比较结果。我们在本文中的目标正是提供这样一个基准。我们比较了GPT
    3.5 Turbo在其未修改形式下的结果，以及使用默认设置通过两个商业平台（被评估为在成本和IT技能方面相对可访问的：OpenAI的微调API和[kipley.ai](http://kipley.ai)的RAG平台（称为“easyRAG”））创建的微调和RAG版本。同时，我们测试了软提示对每种方法的影响，使用了两组问题：一组基础问题和一组由软元提示强化的问题。
- en: The goal in doing this was not to create the best possible chatbot, but rather
    to provide an assessment of the baseline performance of model-improvement technologies
    available to non-expert users. Thus we used default settings in each case and
    made no effort to further improve the performance of each model pipeline. While
    we are well aware that iterative processes can improve the fine-tuning, RAG and
    soft-prompting processes we applied, the average non-academic user will not necessarily
    have the skills or financial resources to do this, therefore we also refrained.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做的目标不是为了创建最佳的聊天机器人，而是为了评估非专家用户可以使用的模型改进技术的基线性能。因此，我们在每种情况下都使用了默认设置，并且没有进一步改善每个模型管道的性能。虽然我们清楚迭代过程可以改善我们应用的微调、RAG和软提示过程，但平均非学术用户不一定具备进行这些改进的技能或财力，因此我们也避免了这样做。
- en: 2 Existing Literature
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 现有文献
- en: 'For the purposes of establishing a baseline, we used what is currently the
    most widely used NLP service among lay-users: OpenAI’s GPT suite. Ray (2023) gives
    an overview of this technology [[1](#bib.bib1)]. The GPT models are a series of
    transformer-based LLMs trained on large text corpora (books, webpages, articles
    etc.) in an unsupervised manner, with further supervised fine-tuning. With each
    generation, its capabilities increased, becoming more and more realistic and indistinguishable
    from human writing. By 2022 the models were successfully passing medical, legal,
    and computing exams, as well as to perform financial analysis - the challenge
    we use in the present paper.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了建立基线，我们使用了目前在普通用户中最广泛使用的 NLP 服务：OpenAI 的 GPT 套件。Ray（2023）概述了这项技术 [[1](#bib.bib1)]。GPT
    模型是一系列基于变换器的 LLM，通过在大规模文本语料库（书籍、网页、文章等）上进行无监督训练，再进行有监督的微调。每一代的能力都在增加，变得越来越现实，难以与人类写作区分开来。到
    2022 年，这些模型已成功通过了医学、法律和计算考试，并能够进行金融分析——这是我们在本论文中使用的挑战。
- en: Dowling and Lucey (2023) demonstrate that ChatGPT is capable of providing significant
    assistance in financial research [[2](#bib.bib2)]. The authors evaluated its capacity
    by asking it to produce literature reviews on cryptocurrency-related topics, first
    using the public data embedded in ChatGPT itself, second with by uploading cryptocurrency-related
    literature to align the LLM and third by human expert intervention on top of the
    second version. They found that the model performed well when it came to idea
    generation and data summaries, but its literature reviews and test frameworks
    were poor.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Dowling 和 Lucey（2023）证明了 ChatGPT 能够在金融研究中提供重要的帮助 [[2](#bib.bib2)]。作者通过要求其生成与加密货币相关的文献综述来评估其能力，首先使用
    ChatGPT 内部嵌入的公共数据，其次通过上传与加密货币相关的文献来调整 LLM，第三通过在人为专家干预的第二版本上进行调整。他们发现模型在创意生成和数据摘要方面表现良好，但其文献综述和测试框架较差。
- en: Li et al. (2023), meanwhile, conducted a broader study on the applications of
    GPT-3.5 and GPT-4.0 as general problem solvers in financial text analysis tasks,
    as compared to domain-specific LLMs [[3](#bib.bib3)]. The authors performed a
    quantitative analysis of the capacity of GPT 3.5 and GPT 4 to solve financial
    text analytical problems using eight benchmark datasets relating to five tasks.
    These results were compared to those produced by FinBert, FinQANet, BloombergGPT
    and others, with the authors finding that non-specialists LLMs such as GPT-4 were
    able to outperform even domain specific pretrained models on certain tasks, only
    falling behind when a deeper structural analysis of financial systems was needed.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Li 等人（2023）同时对 GPT-3.5 和 GPT-4.0 在金融文本分析任务中的应用进行了更广泛的研究，作为通用问题解决者，与特定领域的 LLMs
    [[3](#bib.bib3)] 相比较。作者通过使用八个基准数据集来分析 GPT-3.5 和 GPT-4 在解决金融文本分析问题的能力，这些数据集涉及五个任务。这些结果与
    FinBert、FinQANet、BloombergGPT 等模型产生的结果进行了比较，作者发现像 GPT-4 这样的非专业 LLM 在某些任务中甚至超越了特定领域的预训练模型，仅在需要对金融系统进行更深入结构分析时才落后。
- en: However, GPT-generated texts are not perfect - often the models generate inaccurate
    or imprecise text, or lack domain-specific knowledge. As described above, much
    research has gone into methods to minimise these flaws, whether via retrieval-augmented
    generation, fine-tuning, soft-prompting or other methods. For example, Sarmah
    et al. (2023) discuss how to reduce hallucination in information extracted Q&A
    sections of financial reports using LLMs [[4](#bib.bib4)]. For this purpose, they
    segmented and vectorised a variety of datasheets. They fed the segments and their
    associated metadata into multiple LLMs and then queried it regarding the information
    provided, using the metadata to select the most relevant sections. This approach
    significantly reduced hallucinations.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，GPT 生成的文本并不完美——模型常常生成不准确或不精确的文本，或者缺乏领域特定的知识。如上所述，许多研究致力于通过检索增强生成、微调、软提示等方法来最小化这些缺陷。例如，Sarmah
    等人（2023）讨论了如何在使用 LLMs [[4](#bib.bib4)] 从金融报告中提取信息的问答部分减少幻觉。为此，他们对各种数据表进行了分段和向量化。他们将这些段落及其相关的元数据输入到多个
    LLM 中，然后查询这些信息，利用元数据选择最相关的部分。这种方法显著减少了幻觉。
- en: 'Other teams, such as Wang et al. (2023) describe attempts to improve GPT’s
    ability to accurately handle financial information via a fine-tuning process [[5](#bib.bib5)].
    Similar efforts have also been made in other domains requiring a high degree of
    precision in the outputs: Wu et al. (2023), for example, used data from 4.8 million
    biomedical academic papers and 30 thousand medical textbooks to fine-tune a domain-specific
    model capable of outperforming ChatGPT on medical topics, despite having only
    13 billion parameters [[6](#bib.bib6)].'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 其他团队，例如王等（2023），描述了通过微调过程来提高GPT准确处理金融信息的能力[[5](#bib.bib5)]。类似的努力也在其他需要高度精准输出的领域中进行过：例如，吴等（2023）使用了来自480万篇生物医学学术论文和3万本医学教科书的数据，来微调一个特定领域的模型，尽管只有130亿参数，但该模型在医学主题上超过了ChatGPT[[6](#bib.bib6)]。
- en: However, despite significant progress in techniques for improving pre-trained
    models’ performance, significant lacunae remain. A notable challenge for models
    tasked with responding to queries in technical domains requiring high accuracy
    (such as financial analysis) is the difficulty they tend to experience when handling
    numerical data. Deb et al. (2023), for example, looked in some depth at the mathematical
    reasoning abilities of GPT-3.5, GPT-4, PaLM-2 and LLaMa, with the authors finding
    that this remains a challenge for LLMs [[7](#bib.bib7)].
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，尽管在提高预训练模型性能的技术上取得了显著进展，但仍存在显著的空白。一个显著的挑战是对于需要高精度的技术领域（如金融分析）中的模型来说，处理数值数据时往往会遇到困难。Deb等（2023）例如深入研究了GPT-3.5、GPT-4、PaLM-2和LLaMa的数学推理能力，作者发现这仍然是LLM面临的一个挑战[[7](#bib.bib7)]。
- en: 3 Technical Background
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 技术背景
- en: Because the principal aim in preparing this paper was to compare LLM-improvement
    schemas available to non-expert users, we made a deliberate choice to use the
    most accessible fine-tuning and RAG frameworks, and doing so using the default
    settings where possible in order to establish a solid shared baseline for future
    research.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 由于编写本文的主要目的是比较可供非专家用户使用的LLM改进方案，我们故意选择使用最易获取的微调和RAG框架，并在可能的情况下使用默认设置，以便为未来的研究建立一个稳固的共享基准。
- en: 3.1 Fine-Tuning Settings
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 微调设置
- en: In the case of the fine-tuned model, we relied upon OpenAI’s fine-tuning API,
    on the basis that OpenAI is currently the provider with the largest user-base,
    and often a go-to solution for both private and commercial users seeking LLM services.
    The default settings at the time our tests were conducted can be seen on table [1](#S3.T1
    "Table 1 ‣ 3.1 Fine-Tuning Settings ‣ 3 Technical Background ‣ Establishing Performance
    Baselines in Fine-Tuning, Retrieval-Augmented Generation and Soft-Prompting for
    Non-Specialist LLM Users"). While expert users committed to a fine-tuning operation
    will tend to use an iterative improvement process, non-specialists tend to lack
    the skills (or the financial resources) for this, thus we simply accept the results
    produced by the default settings.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在微调模型的情况下，我们依赖于OpenAI的微调API，因为OpenAI目前是用户基础最大的提供商，通常是寻求LLM服务的私人和商业用户的首选解决方案。在我们进行测试时的默认设置可以在表[1](#S3.T1
    "Table 1 ‣ 3.1 Fine-Tuning Settings ‣ 3 Technical Background ‣ Establishing Performance
    Baselines in Fine-Tuning, Retrieval-Augmented Generation and Soft-Prompting for
    Non-Specialist LLM Users")中看到。虽然致力于微调操作的专家用户通常会使用迭代改进过程，但非专业人士往往缺乏相关技能（或财务资源），因此我们仅接受默认设置所产生的结果。
- en: 'Table 1: Description of Fine-Tuning Settings'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：微调设置说明
- en: '| Settings | Default Value | Details |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 设置 | 默认值 | 详情 |'
- en: '| --- | --- | --- |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| batch_size | 0.2 | Percentage of the total dataset batch size. Capped at
    256. |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| batch_size | 0.2 | 总数据集批量大小的百分比。最大值为256。 |'
- en: '| n_epochs | auto | Number of epochs. How the final number is decided is not
    publicized by OpenAI. |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| n_epochs | auto | 训练轮数。最终数量的决定方式OpenAI未公开。 |'
- en: '| learning_rate_multiplier | null | Multiplier to the algorithmically decided
    learning rate. OpenAI may decide based upon the size of the dataset, the resulting
    learning rate that can either be $0.05$, or $0.2$, which are then finally multiplied
    by this value. |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| learning_rate_multiplier | null | 算法决定的学习率的倍增因子。OpenAI可能根据数据集的大小决定最终的学习率，这可以是$0.05$或$0.2$，然后将其乘以该值。
    |'
- en: '| prompt_loss_weight | $0.01$ | The weight to use for loss on the prompt tokens.
    This controls how much the model tries to learn to generate the prompt (as compared
    to the completion which always has a weight of 1.0), and can add a stabilizing
    effect to training when completions are short. |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| prompt_loss_weight | $0.01$ | 用于提示令牌损失的权重。这控制了模型在生成提示时的学习程度（与始终具有 1.0 权重的完成相比），并且可以在完成较短时对训练产生稳定作用。
    |'
- en: '| suffix | null | A string of up to 40 characters that will be added to your
    fine-tuned model name. |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| suffix | null | 一个最长为 40 个字符的字符串，将被添加到你的微调模型名称中。 |'
- en: '| validation_file | null | The ID of an uploaded file that contains validation
    data. If you provide this file, the data is used to generate validation metrics
    periodically during fine-tuning. These metrics can be viewed in the fine-tuning
    results file. Your train and validation data should be mutually exclusive. |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| validation_file | null | 一个包含验证数据的已上传文件的 ID。如果提供了此文件，数据将用于在微调过程中定期生成验证指标。这些指标可以在微调结果文件中查看。你的训练数据和验证数据应该是互相独立的。
    |'
- en: 3.2 Retrieval-Augmented Generation
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 检索增强生成
- en: 'For our RAG framework, we used the commercially available kipley.ai platform,
    which is based around three principal components: the knowledge base creator module,
    the LLM deployer module, and the GUI-based Application Maker module.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的 RAG 框架，我们使用了商业上可用的 kipley.ai 平台，该平台围绕三个主要组件构建：知识库创建模块、LLM 部署模块和基于 GUI
    的应用程序创建模块。
- en: 3.2.1 Knowledge Base Creator Module
  id: totrans-52
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 知识库创建模块
- en: The first component of the RAG framework is the Knowledge Base Creator Module.
    As a core module in our Knowledge Integration Framework, the Knowledge Base Creator
    Module is used to facilitate a simpler and more seamless integration of diverse
    data sources into a knowledge base. The Knowledge Base Creator connects to a variety
    of data sources, allowing users to load and process a multitude of file formats
    (.pdf, .txt, .doc, .docx, .csv, .xlsx, .json, and more), as well as connecting
    the dynamic data streams via an API-Augmented data integration module. This module
    allows the system to augment answers using data gathered from APIs, including
    REST, SOAP, and GraphQL, proceeding to convert the data into other storable formats
    (.json, .csv, .txt, .xml, etc.).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 框架的第一个组件是知识库创建模块。作为我们知识集成框架中的核心模块，知识库创建模块用于简化和无缝地将多种数据源集成到知识库中。知识库创建模块连接到各种数据源，允许用户加载和处理多种文件格式（.pdf,
    .txt, .doc, .docx, .csv, .xlsx, .json 等），以及通过 API 增强的数据集成模块连接动态数据流。此模块允许系统使用从
    API（包括 REST、SOAP 和 GraphQL）收集的数据来增强回答，然后将数据转换为其他可存储的格式（.json, .csv, .txt, .xml
    等）。
- en: The knowledge base is then vectorized via the Knowledge Base Creator Module,
    a multi-stage pipeline. Data extraction is carried out during the first stage,
    wherein the raw data from the uploaded files and dynamic data streams is extracted
    or copied, and stored temporarily on the server. Text Recognition and Optical
    Character Recognition (OCR) technology is applied to extract information from
    structured, semi-structured and unstructured documents [[8](#bib.bib8)]. As critical
    contextual information and important text information are often contained in image-based
    files (.pdf, .png, .jpg, etc), utilizing a compatible data extraction module with
    a robust OCR-based model can facilitate information retrieval and better incorporate
    this along with the textual information [[9](#bib.bib9)]. The [kipley.ai](http://kipley.ai)’s
    platform also provides self-service data collection functions from dynamic data
    streams via APIs. An API-based, self-service data ingestion platform can be used
    to push their data via pre-set APIs on a near-real-time basis [[10](#bib.bib10)].
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 知识库随后通过知识库创建模块进行向量化，这是一种多阶段管道。在第一阶段进行数据提取，从上传的文件和动态数据流中提取或复制原始数据，并在服务器上暂时存储。文本识别和光学字符识别（OCR）技术被应用于从结构化、半结构化和非结构化文档中提取信息[[8](#bib.bib8)]。由于关键的上下文信息和重要的文本信息通常包含在基于图像的文件（.pdf,
    .png, .jpg 等）中，利用兼容的数据提取模块与强大的基于 OCR 的模型可以促进信息检索，并更好地将这些信息与文本信息结合[[9](#bib.bib9)]。
    [kipley.ai](http://kipley.ai)的平台还通过 API 提供了自助数据收集功能。基于 API 的自助数据摄取平台可以在接近实时的基础上通过预设的
    API 推送数据[[10](#bib.bib10)]。
- en: Following the data extraction process, the data undergoes a cleaning process.
    Retrieval-based data cleaning processes have been covered in prior studies, in
    which they demonstrated superior performance to non-retrieval-based data cleaning
    processes [[11](#bib.bib11)]. The [kipley.](kipley.) platform adopts this approach
    to ensure the cleaned data can be integrate with the relevant LLMs in such a way
    as to display sustainable performance and explainability.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据提取过程之后，数据会经过清理过程。基于检索的数据清理过程在之前的研究中已被涵盖，这些研究显示其表现优于非检索基的数据清理过程 [[11](#bib.bib11)]。平台[kipley.](kipley.)采用这种方法，以确保清理后的数据能够与相关的LLM（大型语言模型）集成，从而展示出可持续的性能和可解释性。
- en: Subsequently, the textual information is translated into dense numerical representations
    via a text embedding process using the FAISS library, which automatically creates
    another index file for semantic search functions [[12](#bib.bib12)]. Qdrant is
    also used to provide alternative embedding options ([https://qdrant.tech/documentation/](https://qdrant.tech/documentation/)).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 随后，通过使用FAISS库的文本嵌入过程，将文本信息转化为稠密的数值表示，该过程会自动创建另一个用于语义搜索功能的索引文件 [[12](#bib.bib12)]。Qdrant也被用于提供替代的嵌入选项
    ([https://qdrant.tech/documentation/](https://qdrant.tech/documentation/))。
- en: Following the data embedding process, the loading stage employs the FAISS and
    Qdrant libraries with a Qdrant database instance and Qdrant cloud to support the
    text mining and embedding pipeline.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据嵌入过程之后，加载阶段使用FAISS和Qdrant库，与Qdrant数据库实例和Qdrant云配合，以支持文本挖掘和嵌入管道。
- en: 3.2.2 LLM Deployer Module
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2 LLM部署模块
- en: As described above, recent advancements in the field of Large Language Models
    (LLMs) have attracted much attention throughout industry and academia. For instance,
    OpenAI’s GPT4 [[13](#bib.bib13)], Anthropic’s Claude 2 [[14](#bib.bib14)], Google’s
    PaLM-2 [[15](#bib.bib15)] and Meta’s LLaMa-2 [[16](#bib.bib16)], have all demonstrated
    multilingual capabilities, high compute-efficiency, reasoning capabilities and
    task-execution capability for question answering, chain-of-thought reasoning,
    image analysis, and so on. Furthermore, multiple studies and extensive experimentation
    have showcased the ability of large language models to solve simple real-world
    coding problems [[17](#bib.bib17)] and mathematical problems via chain-of-thought
    reasoning and self-improvement of via backward reasoning [[7](#bib.bib7)]. However,
    the limitations of existing LLMs remain significant. Multiple studies have expressed
    concerns regarding the training methodologies and the weight parameters of these
    models [[6](#bib.bib6)]. The context window size is still limited (though it varies
    across different LLMs), which constrains their comprehension capability [[18](#bib.bib18)],
    and the capacity of LLMs to collaborate within a multi-agent framework has not
    yet been not widely explored [[19](#bib.bib19)].
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，大型语言模型（LLMs）领域的最新进展在工业和学术界都引起了广泛关注。例如，OpenAI的GPT4 [[13](#bib.bib13)]、Anthropic的Claude
    2 [[14](#bib.bib14)]、Google的PaLM-2 [[15](#bib.bib15)] 和Meta的LLaMa-2 [[16](#bib.bib16)]，都展示了多语言能力、高计算效率、推理能力以及执行任务的能力，如问答、链式思维推理、图像分析等。此外，多项研究和广泛的实验展示了大型语言模型通过链式思维推理和通过反向推理的自我改进来解决简单的现实世界编码问题
    [[17](#bib.bib17)] 和数学问题 [[7](#bib.bib7)]。然而，现有LLM的局限性仍然显著。多项研究对这些模型的训练方法和权重参数表示了担忧
    [[6](#bib.bib6)]。上下文窗口大小仍然有限（尽管不同的LLM有所不同），这限制了它们的理解能力 [[18](#bib.bib18)]，并且LLM在多代理框架中的协作能力尚未被广泛探索
    [[19](#bib.bib19)]。
- en: 'Previous studies have provided evidence that LLM-based agents and proper prompt
    engineering can increase LLMs’ capabilities substantially [[19](#bib.bib19)].
    In the present paper, we employ similar methods via the second module of our RAG
    framework: LLM Deployer Module. The LLM Deployer Module incorporates multi-model
    collaborative agents and instructional prompt tuning to optimise the usage of
    large language models and knowledge bases created by the Knowledge Base Creator
    Module.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的研究提供了证据，表明基于LLM的代理和适当的提示工程可以显著提高LLM的能力 [[19](#bib.bib19)]。在本文中，我们通过RAG框架的第二个模块：LLM部署模块，采用类似的方法。LLM部署模块结合了多模型协作代理和指令提示调整，以优化大型语言模型和知识库的使用，这些知识库由知识库创建模块创建。
- en: The multi-model collaborative agents consist of a variety of different systems,
    including semantic search agents connected to LLM analysis engines. In this context,
    different LLMs are used to retrieve user-relevant factual information from vector
    databases and then analyse it, draw conclusions, or transform it in user-directed
    manners [[20](#bib.bib20)]. This gives LLM-empowered agents the ability to translate,
    reflect and make decisions based on the context provided from the vectorised knowledge
    bases [[21](#bib.bib21)].
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 多模型协作代理包括各种不同的系统，其中包括与 LLM 分析引擎连接的语义搜索代理。在这种情况下，不同的 LLM 被用来从向量数据库中检索与用户相关的事实信息，然后分析这些信息、得出结论或以用户指定的方式进行转换
    [[20](#bib.bib20)]。这赋予了 LLM 驱动的代理根据从向量化知识库提供的上下文进行翻译、反映和决策的能力 [[21](#bib.bib21)]。
- en: 'The transformation of the retrieved information is carried out via Instructional
    prompt tuning, which provides specific natural language instructions to the LLMs
    - a method which has also been widely used to instruct LLMs to complete real-world
    tasks [[6](#bib.bib6)]. Extensive studies have shown that prompt construction
    can greatly improve LLMs’ ability to understand long contexts, and leverage this
    context to generate complex responses [[22](#bib.bib22)]. To test the impact of
    prompting on outputs, we tested our question set twice: once using the questions
    alone, and then a second time incorporating a soft meta-prompt inserted via the
    [kipley.ai](http://kipley.ai) framework’s prompt-tuning module.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 检索信息的转换是通过指导性提示调整进行的，这向 LLM 提供了具体的自然语言指令——这种方法也被广泛用于指导 LLM 完成实际任务 [[6](#bib.bib6)]。广泛的研究表明，提示构建可以大大提高
    LLM 理解长上下文的能力，并利用这些上下文生成复杂的响应 [[22](#bib.bib22)]。为了测试提示对输出的影响，我们测试了两次问题集：第一次仅使用问题，第二次在
    [kipley.ai](http://kipley.ai) 框架的提示调整模块中插入了一个软的元提示。
- en: 3.2.3 GUI-based Application Maker Module
  id: totrans-63
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.3 基于 GUI 的应用程序创建模块
- en: 'The third module of the RAG framework, the GUI-based Application Maker Module,
    enables non-technical users to interact with the Knowledge Base Creator Module
    and LLM Deployer Module to create and customize AI applications quickly. It is
    for this reason that this particular RAG framework is being used in the present
    study, enabling as it does a non-specialist user to create a customised conversational
    AI with comparable ease to the OpenAI fine-tuning API. This module consists of
    two components: a web-based application and a KB-LLM Connector. The web-based
    application is designed and developed using React framework [[23](#bib.bib23)].'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 框架的第三个模块，即基于 GUI 的应用程序创建模块，使非技术用户能够与知识库创建模块和 LLM 部署模块进行交互，从而快速创建和自定义 AI
    应用程序。因此，在本研究中使用了这个特定的 RAG 框架，它使得非专业用户能够像使用 OpenAI 微调 API 一样轻松地创建定制化的对话式 AI。该模块由两个组件组成：一个基于
    Web 的应用程序和一个 KB-LLM 连接器。基于 Web 的应用程序是使用 React 框架设计和开发的 [[23](#bib.bib23)]。
- en: The KB-LLM Connector consists of a full-stack connecting channel that allows
    application creation by combining vectorised knowledge bases and LLM agents. Via
    this web-based application, users can choose to connect one of the previously-vectorised
    knowledge bases to a selected LLM agent, and modify the settings of the agent
    - changing the token limits or model parameters, or adding further information
    via instructional prompt tuning. KB-LLM Connector then passes the changes to the
    LLM allowing users to improve retrieved data accuracy and optimise the LLMs’ performance
    based on their specific needs.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: KB-LLM 连接器由一个全栈连接通道组成，该通道通过结合向量化知识库和 LLM 代理来允许应用程序创建。通过这个基于 Web 的应用程序，用户可以选择将一个先前向量化的知识库连接到选定的
    LLM 代理，并修改代理的设置——例如更改令牌限制或模型参数，或通过指导性提示调整添加更多信息。KB-LLM 连接器然后将更改传递给 LLM，使用户能够提高检索数据的准确性，并根据具体需求优化
    LLM 的性能。
- en: 4 Methodology and Data
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 方法论和数据
- en: While retrieval-augmented generation and fine-tuning require (and work best
    with) differing data formats and types, the goal of this paper was to compare
    like-for-like as far as possible. Thus we took steps to ensure that the datasets
    used with each method were as similar as possible. Likewise, it was important
    that there be no chance of the relevant data appearing in the model’s original
    training data – implying a topic not covered online before September 2021 (GPT
    3.5’s training data only going as far as this date).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管检索增强生成和微调需要（且效果最佳于）不同的数据格式和类型，但本文的目标是尽可能进行类似的比较。因此，我们采取措施确保用于每种方法的数据集尽可能相似。同样，重要的是确保相关数据不会出现在模型的原始训练数据中——这意味着该主题在2021年9月之前没有在线覆盖（GPT
    3.5的训练数据只到这一日期）。
- en: For these reasons, we selected as our topic the LayerZero cryptocurrency bridging
    project – an enterprise that has been widely covered online, but which was not
    released until September 2021\. To prepare the dataset, we began by collecting
    a corpus of publicly available information relevant to the topic via web search.
    This information was split into paragraphs. From these paragraphs, a fine-tuning
    file was constituted in the role-content format used by OpenAI, with questions
    being written by the team to suit the paragraphs already collected as shown in
    figure [1](#S4.F1 "Figure 1 ‣ 4 Methodology and Data ‣ Establishing Performance
    Baselines in Fine-Tuning, Retrieval-Augmented Generation and Soft-Prompting for
    Non-Specialist LLM Users"). The “system content” paragraphs were then converted
    to text format and then vectorised in pkl format to be used in the RAG process
    as shown in figure [2](#S4.F2 "Figure 2 ‣ 4 Methodology and Data ‣ Establishing
    Performance Baselines in Fine-Tuning, Retrieval-Augmented Generation and Soft-Prompting
    for Non-Specialist LLM Users"). While both fine-tuning and RAG are known to have
    an effect upon answer quality, prompt-tuning and soft prompting can also have
    an equal or even greater effect.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这些原因，我们选择了LayerZero加密货币桥接项目作为我们的主题——这是一个在线上广泛报道的企业，但直到2021年9月才发布。为了准备数据集，我们首先通过网络搜索收集了与该主题相关的公开信息。这些信息被分成了段落。从这些段落中，按照OpenAI使用的角色-内容格式构成了一个微调文件，问题由团队编写以适应已经收集的段落，如图 [1](#S4.F1
    "图 1 ‣ 4 方法论和数据 ‣ 微调、检索增强生成和软提示的性能基准建立")所示。然后，将“系统内容”段落转换为文本格式，并在pkl格式中向量化，以用于RAG过程，如图 [2](#S4.F2
    "图 2 ‣ 4 方法论和数据 ‣ 微调、检索增强生成和软提示的性能基准建立")所示。虽然微调和RAG已知会对答案质量产生影响，但提示微调和软提示也可以产生相等甚至更大的影响。
- en: '![Refer to caption](img/ada8904c0922b6294ac7738501afb722.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ada8904c0922b6294ac7738501afb722.png)'
- en: 'Figure 1: Excerpt from the fine-tuning file prepared by the team.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '图 1: 团队准备的微调文件摘录。'
- en: '![Refer to caption](img/f05c564568dab96c455fc0b3f247f57a.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/f05c564568dab96c455fc0b3f247f57a.png)'
- en: 'Figure 2: Extract from the text file used to constitute the pkl vector database
    used in the RAG process'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '图 2: 用于构建pkl向量数据库的文本文件摘录，该数据库用于RAG过程'
- en: The fine-tuned and RAG systems having been prepared, we tested them using a
    set of 100 relevant questions, some requiring information only available post-2021,
    others more general, and a smaller set whose answers were not present in the data
    as shown in table [2](#S4.T2 "Table 2 ‣ 4 Methodology and Data ‣ Establishing
    Performance Baselines in Fine-Tuning, Retrieval-Augmented Generation and Soft-Prompting
    for Non-Specialist LLM Users").
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在对微调和RAG系统进行准备后，我们使用了一组100个相关问题对它们进行了测试，其中一些问题需要2021年之后才有的信息，其他问题则较为普遍，还有一些问题的答案在数据中并不存在，如表格 [2](#S4.T2
    "表格 2 ‣ 4 方法论和数据 ‣ 微调、检索增强生成和软提示的性能基准建立")所示。
- en: 'Table 2: Example Questions'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '表格 2: 示例问题'
- en: '| Post-2021 | General | Answers not in parameters |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 2021年后 | 一般 | 答案不在参数中 |'
- en: '| --- | --- | --- |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| "What is Bryan Pellegrino’s involvement in LayerZero?" | "Why is cross-chain
    interoperability difficult?" | "What is Ryan Zarick’s net worth?" |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| "Bryan Pellegrino在LayerZero中的角色是什么？" | "跨链互操作性为何如此困难？" | "Ryan Zarick的净资产是多少？"
    |'
- en: '| "What happend to LayerZero in 2022?" | "How does chainlink work?" | "What
    does the public says about LayerZero?" |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| "LayerZero在2022年发生了什么？" | "链环如何工作？" | "公众对LayerZero的看法是什么？" |'
- en: '| "Is LayerZero on Discord?" | "What is bridging?" | "Is Ryan Zarick a poker
    player?" |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| "LayerZero在Discord上吗？" | "什么是桥接？" | "Ryan Zarick是扑克玩家吗？" |'
- en: 'It is known that prompt-tuning and soft prompting can have as much or more
    impact upon model responses as both RAG and model fine-tuning. We sought to understand
    how the approaches may interact, and thus tested the question set twice: once
    using the questions alone, as given above, and then again preceded by a soft prompt:
    “You are an expert financial analyst specialising in cryptocurrencies and blockchain
    technology.” Such a preface not only instructs the model on how to frame its response,
    but helps to situate it in the proper area of the latent vector space to produce
    relevant responses.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 已知提示微调和软提示对模型响应的影响可能与 RAG 和模型微调一样大甚至更大。我们试图了解这些方法如何相互作用，因此将问题集测试了两次：第一次使用单独的问题，如上所述；第二次在问题前添加了软提示：“你是一位专注于加密货币和区块链技术的金融分析专家。”这种前言不仅指导模型如何框定其回应，还帮助将其置于潜在向量空间中的适当区域，以生成相关的响应。
- en: 'We then proceeded to test each set of 100 prompts in three contexts:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们在三种上下文中测试了每组 100 个提示：
- en: '1.'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: With the basic un-fine-tuned, un-augmented GPT 3.5 Turbo 0613 model alone.
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 仅使用基本的未微调、未增强的 GPT 3.5 Turbo 0613 模型。
- en: '2.'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: With a version of gpt-3.5-turbo-0613 fine-tuned with the abovementioned json
    file using OpenAI’s proposed default settings (it should be noted the OpenAI’s
    training API strives to adjust the number of training epochs and learning rate
    as a function of the training dataset).
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用以上述 json 文件微调的 gpt-3.5-turbo-0613 模型，并采用 OpenAI 提议的默认设置（需要注意的是，OpenAI 的训练
    API 力求根据训练数据集调整训练周期和学习率）。
- en: '3.'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: With the basic un-fine-tuned gpt-3.5-turbo-0613 model augmented via access to
    the pkl vector database previously described using the [kipley.ai](http://kipley.ai)
    RAG platform’s document retrieval preset defaults.
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用基本的未微调的 gpt-3.5-turbo-0613 模型，并通过访问之前描述的 pkl 向量数据库，结合 [kipley.ai](http://kipley.ai)
    RAG 平台的文档检索预设默认设置进行增强。
- en: 'Of which each response was scored by evaluators based on two criteria:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 每个响应根据两个标准由评估者评分：
- en: '1.'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: The number of “false positives” in the response – that is to say, the number
    of sentences containing at least one hallucination (untrue assertion).
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 响应中的“假阳性”数量——也就是说，包含至少一个幻觉（不真实断言）的句子的数量。
- en: '2.'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: The presence of “false negatives” in the response – that is to say, an inability
    to find a correct answer even when this was present in the fine-tuning/vector
    database information (in the case of questions for which no clear answer existed
    in the data, a failure to say as much was considered a false negative). When the
    basic model stated that its training data only covered events prior to 2021 and
    recommended that the reader should consult other sources, this was not considered
    a false negative.
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 响应中的“假阴性”的存在——也就是说，即使在微调/向量数据库信息中存在正确答案时，仍无法找到正确答案（对于数据中没有明确答案的问题，未能说明这一点被视为假阴性）。当基本模型声明其训练数据仅涵盖
    2021 年之前的事件，并建议读者咨询其他来源时，这不被视为假阴性。
- en: These were then amalgamated to produce a “total error-free responses” score
    for each test.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将这些结果合并以生成每个测试的“总无错误响应”分数。
- en: 5 Results
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 个结果
- en: We found that for both sets of prompts RAG performed better than the fine-tuned
    model, which in turn performed better than the un-fine-tuned model. Suprisingly
    as shown in table [3](#S5.T3 "Table 3 ‣ 5 Results ‣ Establishing Performance Baselines
    in Fine-Tuning, Retrieval-Augmented Generation and Soft-Prompting for Non-Specialist
    LLM Users"), the fine-tuned model was much more prone to hallucination than the
    basic model – possibly because GPT has conducted extensive reinforcement learning
    via human feedback to dissuade the model from attempting to answer questions for
    which it has no useful information, and the fine-tuning process undermines this
    and alters the model’s priorities. This raises some interesting questions regarding
    potential techniques for “jail-breaking” the model itself, research into which
    has previously tended to focus on soft-prompting and prompt-tuning rather than
    fine-tuning.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现，对于这两组提示，RAG 的表现优于微调模型，而微调模型又优于未微调模型。令人惊讶的是，如表 [3](#S5.T3 "表 3 ‣ 5 个结果 ‣
    确立微调、检索增强生成和软提示对非专业 LLM 用户的性能基准") 所示，微调模型比基本模型更容易出现幻觉——这可能是因为 GPT 进行了广泛的强化学习，以通过人类反馈来阻止模型尝试回答没有有用信息的问题，而微调过程破坏了这一点并改变了模型的优先级。这引发了一些关于“破解”模型本身的潜在技术的有趣问题，之前的研究主要集中在软提示和提示微调，而不是微调。
- en: 'Table 3: False positive answers given under each set of test conditions.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：在每组测试条件下给出的假阳性答案。
- en: '|  | gpt-3.5-turbo-0613 alone | gpt-3.5-turbo-0613 fine tuned | gpt-3.5-turbo-0613
    + vector database |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '|  | gpt-3.5-turbo-0613 单独使用 | gpt-3.5-turbo-0613 微调 | gpt-3.5-turbo-0613 +
    向量数据库 |'
- en: '| No soft prompt | 89 | 157 | 9 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 无软提示 | 89 | 157 | 9 |'
- en: '| Soft prompt | 80 | 118 | 6 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 软提示 | 80 | 118 | 6 |'
- en: It is also interesting to note while both the basic model and the fine-tuned
    model had more problems with hallucination than failing to answer, while the augmented
    model showed more false negatives than false positives as shown in table [4](#S5.T4
    "Table 4 ‣ 5 Results ‣ Establishing Performance Baselines in Fine-Tuning, Retrieval-Augmented
    Generation and Soft-Prompting for Non-Specialist LLM Users"). Also noteworthy
    is the fact that soft prompting increased the base model’s tendency to give false
    negative answers. It is possible that the soft-prompt rendered the model more
    cautious in the answers it gave, and less inclined to guess at answers it was
    not certain about.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 同样有趣的是，虽然基本模型和微调模型在幻觉问题上比未能回答问题更多，但增强模型表现出比假阳性更多的假阴性，如表[4](#S5.T4 "表 4 ‣ 5 结果
    ‣ 建立非专家 LLM 用户的微调、检索增强生成和软提示的性能基准") 所示。还值得注意的是，软提示增加了基本模型给出假阴性答案的倾向。可能是软提示让模型在回答时变得更加谨慎，不容易猜测自己不确定的答案。
- en: 'Table 4: False negative answers given under each set of test conditions.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：在每组测试条件下给出的假阴性答案。
- en: '|  | gpt-3.5-turbo-0613 alone | gpt-3.5-turbo-0613 fine tuned | gpt-3.5-turbo-0613
    + vector database |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '|  | gpt-3.5-turbo-0613 单独使用 | gpt-3.5-turbo-0613 微调 | gpt-3.5-turbo-0613 +
    向量数据库 |'
- en: '| No soft prompt | 56 | 45 | 20 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 无软提示 | 56 | 45 | 20 |'
- en: '| Soft prompt | 69 | 45 | 16 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 软提示 | 69 | 45 | 16 |'
- en: Whether assisted via a soft prompt or not, table [5](#S5.T5 "Table 5 ‣ 5 Results
    ‣ Establishing Performance Baselines in Fine-Tuning, Retrieval-Augmented Generation
    and Soft-Prompting for Non-Specialist LLM Users") shown that both the basic model
    and the fine-tuned model achieved only around 20-30% accuracy overall, while the
    augmented model got 77% of the questions right without a soft prompt, and 81%
    correct with one.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是否通过软提示辅助，表[5](#S5.T5 "表 5 ‣ 5 结果 ‣ 建立非专家 LLM 用户的微调、检索增强生成和软提示的性能基准") 显示基本模型和微调模型的整体准确率仅约为
    20-30%，而增强模型在没有软提示的情况下正确回答了 77% 的问题，使用软提示时为 81%。
- en: 'Table 5: Total correct answers given under each set of test conditions.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：在每组测试条件下给出的总正确答案。
- en: '|  | gpt-3.5-turbo-0613 alone | gpt-3.5-turbo-0613 fine tuned | gpt-3.5-turbo-0613
    + vector database |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '|  | gpt-3.5-turbo-0613 单独使用 | gpt-3.5-turbo-0613 微调 | gpt-3.5-turbo-0613 +
    向量数据库 |'
- en: '| No soft prompt | 37 | 38 | 78 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 无软提示 | 37 | 38 | 78 |'
- en: '| Soft prompt | 24 | 28 | 81 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 软提示 | 24 | 28 | 81 |'
- en: It is important to note, however, that neither soft-prompting nor fine-tuning
    are exact sciences. A skillful auto-prompting gradient descent algorithm could
    no doubt improve these results further, while an extensive trial and error based
    fine-tuning process could certainly improve the results significantly. However,
    our objective in conducting this research was to compare the performance of tools
    available to non-expert corporate users, rather than specialist programmers, hence
    our choice to employ only the default settings in each case.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 但需要注意的是，软提示和微调都不是精确的科学。一个熟练的自动提示梯度下降算法无疑可以进一步改善这些结果，而一个基于广泛试错的微调过程肯定可以显著改善结果。然而，我们进行这项研究的目标是比较可供非专家企业用户使用的工具的性能，而不是专业程序员，因此我们选择仅使用每种情况的默认设置。
- en: 6 Analysis
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 分析
- en: 'The raw numbers are relatively clear: for a given, limited dataset and given
    a limited amount of time and technical skill, RAG is more effective as fine-tuning,
    which in turn is more effective than using the unmodified model provided by OpenAI
    to all users. Likewise, all of these methods are improved by the use of soft prompts
    that help the model to situated itself within the correct vector space to identify
    appropriate answers, and to frame them correctly.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据相对清晰：对于一个给定的、有限的数据集和有限的时间及技术技能，RAG（检索增强生成）比微调更有效，而微调又比使用 OpenAI 提供给所有用户的未经修改的模型更有效。同样，所有这些方法都通过使用软提示得到了改善，软提示帮助模型在正确的向量空间中定位自己，以识别适当的答案，并正确框架它们。
- en: However, the nature of the errors made was often informative. Interestingly,
    while the unmodified model had no information on the LayerZero project upon which
    to draw, when it guessed answers rather than apologising, it was often correct
    or close to correct. This seems to be a reflection of the fact that cryptocurrency
    projects tend to aim to solve a limited set of problems, and describe this process
    in similar words. As a result, if asked to describe a project it does not know,
    GPT can often make a reasonable attempt. Consider this example given in table [6](#S6.T6
    "Table 6 ‣ 6 Analysis ‣ Establishing Performance Baselines in Fine-Tuning, Retrieval-Augmented
    Generation and Soft-Prompting for Non-Specialist LLM Users").
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，错误的性质往往是有信息性的。有趣的是，虽然未经修改的模型没有关于 LayerZero 项目的信息可以参考，但当它猜测答案而不是道歉时，往往是正确的或接近正确的。这似乎反映了加密货币项目通常旨在解决有限的问题集，并用类似的词语描述这一过程。因此，如果被要求描述一个它不了解的项目，GPT
    常常能够做出合理的尝试。请参见表[6](#S6.T6 "表 6 ‣ 6 分析 ‣ 确定性能基准的微调、检索增强生成和软提示对于非专业 LLM 用户")中的示例。
- en: 'Table 6: Vague answers from unmodified ChatGPT.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6：未经修改的 ChatGPT 的模糊回答。
- en: '| Question | "You are an expert financial analyst specialising in cryptocurrencies
    and blockchain technology. What dApps are using LayerZero?" |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 问题 | "你是一位专注于加密货币和区块链技术的专家金融分析师。哪些去中心化应用（dApps）正在使用 LayerZero？" |'
- en: '| --- | --- |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Answer | "LayerZero is a blockchain scalability protocol that aims to create
    a scalable and high-performance infrastructure for decentralized applications
    (dApps). As of now, there aren’t any specific dApps that are using LayerZero since
    it is still in the early stages of development. However, LayerZero has been designed
    to be compatible with existing Ethereum-based dApps. So, once it is fully developed,
    it is expected that existing dApps built on Ethereum could potentially migrate
    to LayerZero to take advantage of its improved scalability and performance features."
    |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 答案 | "LayerZero 是一个区块链可扩展性协议，旨在为去中心化应用（dApps）创建一个可扩展和高性能的基础设施。到目前为止，还没有任何特定的
    dApps 使用 LayerZero，因为它仍处于开发的早期阶段。然而，LayerZero 已被设计为与现有的以太坊基础 dApps 兼容。因此，一旦完全开发完成，预计现有的以太坊上构建的
    dApps 可能会迁移到 LayerZero，以利用其改进的可扩展性和性能特征。" |'
- en: The first sentence is entirely true, but also so vague that it could potentially
    describe almost any blockchain project. By sticking to points that are common
    to many projects, GPT avoids being wrong though neither does it accurately reflect
    the core features of the technology (which is, in fact, an interoperability protocol).
    Also interesting to note is that fine-tuning rendered the model slightly more
    accurate, but also less predictable. For example, when asked other question “What
    is a block header?”, the unmodified model gave the following response a shown
    in table [7](#S6.T7 "Table 7 ‣ 6 Analysis ‣ Establishing Performance Baselines
    in Fine-Tuning, Retrieval-Augmented Generation and Soft-Prompting for Non-Specialist
    LLM Users").
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 第一句完全正确，但也非常模糊，以至于它几乎可以描述任何区块链项目。通过坚持许多项目共有的要点，GPT 避免了错误，尽管它也没有准确反映技术的核心特征（实际上是一个互操作性协议）。同样有趣的是，微调使模型略微更准确，但也使其不那么可预测。例如，当被问及另一个问题“区块头是什么？”时，未经修改的模型给出了表[7](#S6.T7
    "表 7 ‣ 6 分析 ‣ 确定性能基准的微调、检索增强生成和软提示对于非专业 LLM 用户")中所示的回答。
- en: 'Table 7: Correct answers from unmodified model.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7：未经修改的模型的正确回答。
- en: '| Question | "What is a block header?" |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 问题 | "区块头是什么？" |'
- en: '| --- | --- |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Answer | "A block header is a data structure that contains information about
    a block in a blockchain network. It includes crucial details such as the block’s
    version number, the previous block’s hash, the timestamp of when the block was
    created, the Merkle root of the block’s transactions, the target difficulty for
    mining the block, and a nonce (a random number used in the mining process). The
    block header is hashed to create a unique identifier called the block hash, which
    is used for linking blocks in the blockchain. All nodes in the blockchain network
    verify the header’s integrity before accepting a new block." |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 答案 | "区块头是一个数据结构，包含有关区块链网络中一个区块的信息。它包括关键细节，如区块的版本号、前一个区块的哈希值、区块创建的时间戳、区块交易的
    Merkle 根、挖矿区块的目标难度以及一个随机数（在挖矿过程中使用）。区块头被哈希化以创建一个称为区块哈希的唯一标识符，用于链接区块链中的区块。所有区块链网络中的节点在接受新区块之前都会验证头部的完整性。"
    |'
- en: This is a correct answer from the unmodified model’s perspective, since it does
    not have up-to-date information on this topic. By contrast, the fine-tuned model
    gave the following answer shown in table [8](#S6.T8 "Table 8 ‣ 6 Analysis ‣ Establishing
    Performance Baselines in Fine-Tuning, Retrieval-Augmented Generation and Soft-Prompting
    for Non-Specialist LLM Users")
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 从未修改模型的角度来看，这是一个正确的回答，因为它没有关于该主题的最新信息。相比之下，经过微调的模型给出了表格 [8](#S6.T8 "Table 8
    ‣ 6 Analysis ‣ Establishing Performance Baselines in Fine-Tuning, Retrieval-Augmented
    Generation and Soft-Prompting for Non-Specialist LLM Users") 中显示的以下回答：
- en: 'Table 8: Hallucinating answers from finetuned model.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '表格 8：微调模型的幻觉回答。 '
- en: '| Question | "What is a block header?" |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 问题 | "什么是区块头？" |'
- en: '| --- | --- |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Answer | "The LayerZero Theseus block header is an Ex justified block header
    obtained by Theseus from the Endpoints of chain A and chain B. The block header
    of chain A is stored in the block header of the corresponding transaction in chain
    B, and the block header is justified by the Merkle proof. Some people may be wondering:
    The endorsed transaction is at the end of the chain, and its block header is well
    justified. Isnt it a real block header? These block headers are synthesized, not
    in the traditional sense. Theobvious is that the original block headers on chain
    A are real, but the transaction block headers stored in B are for security reasons.
    The nodes are stored in small segments, and they are not all. Theseus end-to-end
    Consensus Mechanism LayerZero The LayerZero consensus layer can obtain block headers
    on chain A in real time, ensuring that the block headers on chain B are fully
    justified. Use Case: LayerZero Quotes Block Timestamp" |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 回答 | "LayerZero Theseus 区块头是 Theseus 从链 A 和链 B 的终端获得的经过 Ex 验证的区块头。链 A 的区块头存储在链
    B 对应交易的区块头中，并通过 Merkle 证明得到验证。有些人可能会问：被认可的交易在链末尾，其区块头已经得到验证。它不是一个真实的区块头吗？这些区块头是合成的，不是传统意义上的区块头。显而易见，链
    A 上的原始区块头是真实的，但存储在 B 中的交易区块头是出于安全原因。节点以小段存储，并且它们并不完整。Theseus 端到端共识机制 LayerZero
    The LayerZero 共识层可以实时获取链 A 上的区块头，确保链 B 上的区块头得到完全验证。用例：LayerZero 引用区块时间戳" |'
- en: Interestingly, while the fine-tuned model is discussing cross-chain interoperability,
    everything else in the response is entirely made-up. This seems to suggest that
    finetuning may have the capacity not simply to influence the model’s answers in
    a particular direction, but to undermine or sidestep the RLHF process engaged
    in by OpenAI. (For purposes of comparison, the retrieval-augmented model answered,
    “A block header is the metadata of a block in a blockchain system.”)
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，当经过微调的模型讨论跨链互操作性时，回答中的其他部分完全是虚构的。这似乎表明，微调可能不仅能影响模型回答的特定方向，还可能破坏或绕过 OpenAI
    的 RLHF 过程。（为了比较，检索增强型模型的回答是：“区块头是区块链系统中区块的元数据。”）
- en: Similarly, the fine-tuned model seems to reveal more of its own deterministic
    nature. By comparing the answers we found in table [9](#S6.T9 "Table 9 ‣ 6 Analysis
    ‣ Establishing Performance Baselines in Fine-Tuning, Retrieval-Augmented Generation
    and Soft-Prompting for Non-Specialist LLM Users"), we noted among the responses
    that we received, that responses that began with an error often ran ever further
    off-track, not just in terms of factual accuracy, but also in terms of grammar
    and syntax, rather as though a higher model temperature and lower top-P had been
    set.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，经过微调的模型似乎暴露出了更多的确定性特征。通过比较表格 [9](#S6.T9 "Table 9 ‣ 6 Analysis ‣ Establishing
    Performance Baselines in Fine-Tuning, Retrieval-Augmented Generation and Soft-Prompting
    for Non-Specialist LLM Users") 中找到的答案，我们注意到，在收到的回复中，以错误开始的回答通常会进一步偏离正轨，不仅在事实准确性上，还有语法和句法方面，仿佛设置了更高的模型温度和较低的
    top-P。
- en: 'Table 9: Examples of LLM error under differing circumstances.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 9：不同情况下 LLM 错误的示例。
- en: '| Question | "Has anyone exited from LayerZero?" |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 问题 | "有人从 LayerZero 退出吗？" |'
- en: '| --- | --- |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Unmodified gpt-3.5-turbo-0613 Answer | "I’m sorry, but as an AI language
    model, I don’t have access to information about specific individuals or companies
    and their exits. Therefore, I can’t provide you with any specific details about
    whether anyone has exited from LayerZero or not. " |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 未修改的 gpt-3.5-turbo-0613 回答 | "对不起，作为一个 AI 语言模型，我无法获取关于特定个人或公司及其退出的信息。因此，我不能提供任何关于是否有人从
    LayerZero 退出的具体细节。" |'
- en: '| Fine tuned gpt-3.5-turbo-0613 Answer | "EF has a full vested amount of 24
    million $STG over a 4-year period (6 years per whitepaper plan). Whitepaper plan:
    -Year 1: 15% (3.6m $STG) per year – partial vested -Year 4 (3 years from now):
    100% (7.2m $STG) – fully vested *Please note that this is not an investment advice
    in any way, and venture capital funds purposely do not disclose the timing or
    financial details of their investment returns publicly. They have full control
    over the amount and timing of any tokens they choose to sell on exchanges. Below
    is a piece of Tweet which may give you a hint on an official reaction from the
    team if in the case there will be an attempt to prevent circulating funds to market
    in the long term." |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| 微调的gpt-3.5-turbo-0613回答 | "EF在4年内拥有2400万$STG的完全归属权（白皮书计划为6年）。白皮书计划：-第1年：每年15%（360万$STG）——部分归属
    -第4年（即3年后）：100%（720万$STG）——完全归属 *请注意，这绝不是投资建议，风险投资基金有意不公开其投资回报的时间或财务细节。他们完全控制选择在交易所出售任何代币的数量和时间。以下是一条推文，可能会给你一些官方反应的提示，以防有试图长期阻止资金流入市场的尝试。"'
- en: '| Vector DB asissted gpt-3.5-turbo-0613 Answer | "The given context does not
    provide any information about whether anyone has exited from LayerZero." |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| 向量数据库辅助的gpt-3.5-turbo-0613回答 | "提供的背景信息没有说明是否有人退出了LayerZero。" |'
- en: However, it is also worth noting that this fine-tuning issue can be solved to
    a degree by iterating on the number of training epochs and the learning rate,
    though this involves an investment in terms of tokens and effort.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，同样值得注意的是，这个微调问题在一定程度上可以通过调整训练周期和学习率来解决，尽管这需要投入一定的代币和精力。
- en: By contrast, the use of RAG tended to push the model to give much shorter answers
    – unsurprisingly, as the more it strays from facts retrieved from the vector database,
    the more likely it is to be wrong. RAG responses contained, on average just $23$
    in each answer given by the fine-tuned model, and $78.5$, $49.4$ words respectively.)
    This too can be solved by a skilled coder, notably by adding an instruction to
    the soft prompt instructing the model to list all the facts it can find in the
    retrieved data, however, since a non-expert would not necessarily be aware of
    this we also refrained.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，使用RAG往往会使模型给出更短的回答——这并不令人惊讶，因为它离开从向量数据库检索到的事实越远，出错的可能性就越大。RAG回应的平均内容仅包含$23$个词，而微调模型则分别包含$78.5$和$49.4$个词。熟练的编码者也可以解决这个问题，特别是通过在软提示中添加指令，指导模型列出检索数据中找到的所有事实。然而，由于非专家可能不知情，我们也未作此调整。
- en: 7 Conclusion
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 结论
- en: While we found that RAG significantly out-performed fine-tuning as an LLM-improvement
    strategy, until comparatively recently they were too technically complex for the
    majority of users to implement. While creating a fine-tuned model was within the
    reach of even comparatively un-technical users thanks to the OpenAI fine-tuning
    API and related documentation, RAG remained the preserve of experts. The growing
    availability of RAG tools - first in the form of code libraries such as Langchain
    and LlamaIndex, and then via consumer-facing GUIs such as OpenAI’s Chat with PDF
    tool, or the kipley.ai platform used in this paper - has changed the cost-benefit
    ratio for non-expert users.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们发现RAG在作为LLM改进策略时显著优于微调，但直到相对最近，它们对于大多数用户而言仍然过于技术复杂。虽然借助OpenAI的微调API和相关文档，创建微调模型对相对非技术用户来说也可行，但RAG仍然是专家的专属领域。RAG工具的逐渐普及——首先是Langchain和LlamaIndex等代码库，然后是OpenAI的Chat
    with PDF工具或本文中使用的kipley.ai平台等面向消费者的GUI——改变了非专家用户的成本效益比。
- en: The fine-tuning exercise conducted for the purpose of this paper takes between
    15 and 30 minutes to complete (depending on GPT API traffic), though it should
    be noted that both the cost and time required would increase were a user to iterate
    over multiple fine-tuning attempts, as is generally recommend. For comparison,
    generating the vector database used by the RAG process cost took around five minutes.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 本文所进行的微调练习需要15到30分钟完成（具体取决于GPT API的流量），不过需要注意的是，如果用户在多个微调尝试之间进行迭代，成本和时间要求都会增加，这通常是推荐的。作为对比，生成RAG过程中使用的向量数据库花费了大约五分钟。
- en: For a non-expert user, the baseline outputs of the RAG approach - whether in
    combination with a basic soft prompt or alone - are significantly more accurate
    than those provided by the default fine-tuning settings, for a similar investment
    in time and effort. We thus recommend this approach for commercial users dipping
    a toe into the field.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 对于非专家用户，RAG 方法的基线输出——无论是与基本软提示组合使用还是单独使用——在时间和精力投入相似的情况下，比默认微调设置提供的结果准确得多。因此，我们建议商业用户在涉足该领域时使用这种方法。
- en: References
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Partha Pratim Ray. Chatgpt: A comprehensive review on background, applications,
    key challenges, bias, ethics, limitations and future scope. Internet of Things
    and Cyber-Physical Systems, 2023.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Partha Pratim Ray. ChatGPT：背景、应用、主要挑战、偏见、伦理、局限性和未来方向的综合评述。物联网与网络物理系统，2023年。'
- en: '[2] Michael Dowling and Brian Lucey. Chatgpt for (finance) research: The bananarama
    conjecture. Finance Research Letters, 53:103662, 2023.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Michael Dowling 和 Brian Lucey. ChatGPT 在（金融）研究中的应用：Bananarama 猜想。金融研究快报，53:103662，2023年。'
- en: '[3] Xianzhi Li, Xiaodan Zhu, Zhiqiang Ma, Xiaomo Liu, and Sameena Shah. Are
    chatgpt and gpt-4 general-purpose solvers for financial text analytics? an examination
    on several typical tasks. arXiv preprint arXiv:2305.05862, 2023.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Xianzhi Li, Xiaodan Zhu, Zhiqiang Ma, Xiaomo Liu 和 Sameena Shah. ChatGPT
    和 GPT-4 是否是金融文本分析的通用解算器？对若干典型任务的考察。arXiv 预印本 arXiv:2305.05862，2023年。'
- en: '[4] Bhaskarjit Sarmah, Tianjie Zhu, Dhagash Mehta, and Stefano Pasquali. Towards
    reducing hallucination in extracting information from financial reports using
    large language models. arXiv preprint arXiv:2310.10760, 2023.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Bhaskarjit Sarmah, Tianjie Zhu, Dhagash Mehta 和 Stefano Pasquali. 通过大语言模型减少金融报告信息提取中的幻觉。arXiv
    预印本 arXiv:2310.10760，2023年。'
- en: '[5] Neng Wang, Hongyang Yang, and Christina Dan Wang. Fingpt: Instruction tuning
    benchmark for open-source large language models in financial datasets. arXiv preprint
    arXiv:2310.04793, 2023.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Neng Wang, Hongyang Yang 和 Christina Dan Wang. FinGPT：针对金融数据集的开源大语言模型的指令调整基准。arXiv
    预印本 arXiv:2310.04793，2023年。'
- en: '[6] Chaoyi Wu, Weixiong Lin, Xiaoman Zhang, Ya Zhang, Yanfeng Wang, and Weidi
    Xie. Pmc-llama: Towards building open-source language models for medicine. arXiv
    preprint arXiv:2305.10415v5, 2023.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Chaoyi Wu, Weixiong Lin, Xiaoman Zhang, Ya Zhang, Yanfeng Wang 和 Weidi
    Xie. PMC-LLAMA：构建医学领域开源语言模型的进展。arXiv 预印本 arXiv:2305.10415v5，2023年。'
- en: '[7] Aniruddha Deb, Neeva Oza, Sarthak Singla, Dinesh Khandelwal, Dinesh Garg,
    and Parag Singla. Fill in the blank: Exploring and enhancing llm capabilities
    for backward reasoning in math word problems. arXiv preprint arXiv:2310.01991,
    2023.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Aniruddha Deb, Neeva Oza, Sarthak Singla, Dinesh Khandelwal, Dinesh Garg
    和 Parag Singla. 填空：探索和增强 LLM 在数学词题中的反向推理能力。arXiv 预印本 arXiv:2310.01991，2023年。'
- en: '[8] Graham A. Cutting and Anne-Françoise Cutting-Decelle. Intelligent document
    processing–methods and tools in the real world. arXiv preprint arXiv:2112.14070,
    2021.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Graham A. Cutting 和 Anne-Françoise Cutting-Decelle. 智能文档处理——现实世界中的方法和工具。arXiv
    预印本 arXiv:2112.14070，2021年。'
- en: '[9] Noam Rotstein, David Bensaid, Shaked Brody, Roy Ganz, and Ron Kimmel. Fusecap:
    Leveraging large language models to fuse visual data into enriched image captions.
    arXiv preprint arXiv:2305.17718, 2023.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Noam Rotstein, David Bensaid, Shaked Brody, Roy Ganz 和 Ron Kimmel. FuseCap：利用大语言模型将视觉数据融合成丰富的图像说明。arXiv
    预印本 arXiv:2305.17718，2023年。'
- en: '[10] Michal Zasadzinski, Michael Theodoulou, Markus Thurner, and Kshitij Ranganath.
    The trip to the enterprise gourmet data product marketplace through a self-service
    data platform. arXiv preprint arXiv:2107.13212, 2021.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Michal Zasadzinski, Michael Theodoulou, Markus Thurner 和 Kshitij Ranganath.
    通过自服务数据平台前往企业美食数据产品市场。arXiv 预印本 arXiv:2107.13212，2021年。'
- en: '[11] Mohammad Shahmeer Ahmad, Zan Ahmad Naeem, Mohamed Eltabakh, Mourad Ouzzani,
    and Nan Tang. Retclean: Retrieval-based data cleaning using foundation models
    and data lakes. arXiv preprint arXiv:2303.16909, 2023.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Mohammad Shahmeer Ahmad, Zan Ahmad Naeem, Mohamed Eltabakh, Mourad Ouzzani
    和 Nan Tang. Retclean：基于检索的数据清理，使用基础模型和数据湖。arXiv 预印本 arXiv:2303.16909，2023年。'
- en: '[12] Jeff Johnson, Matthijs Douze, and Hervé Jégou. Billion-scale similarity
    search with gpus. IEEE Transactions on Big Data, 7(3):535–547, 2019.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Jeff Johnson, Matthijs Douze 和 Hervé Jégou. 亿级规模的相似性搜索与 GPU。IEEE 大数据学报，7(3):535–547，2019年。'
- en: '[13] OpenAI. Gpt-4 technical report, 2023.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] OpenAI. Gpt-4 技术报告，2023年。'
- en: '[14] Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova
    DasSarma, and Dawn Drain. Training a helpful and harmless assistant with reinforcement
    learning from human feedback. arXiv preprint arXiv:2204.05862, 2022.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova
    DasSarma 和 Dawn Drain. 通过人类反馈的强化学习训练一个有用且无害的助手。arXiv 预印本 arXiv:2204.05862，2022年。'
- en: '[15] Rohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin,
    Alexandre Passos, and Siamak Shakeri. Palm 2 technical report. arXiv preprint
    arXiv:2305.10403, 2023.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Rohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin,
    Alexandre Passos, 和 Siamak Shakeri. Palm 2 技术报告。arXiv 预印本 arXiv:2305.10403, 2023。'
- en: '[16] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi,
    Yasmine Babaei, and Nikolay Bashlykov. Llama 2: Open foundation and fine-tuned
    chat models. arXiv preprint arXiv:2307.09288, 2023.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi,
    Yasmine Babaei, 和 Nikolay Bashlykov. Llama 2：开放基础和微调聊天模型。arXiv 预印本 arXiv:2307.09288,
    2023。'
- en: '[17] Carlos E. Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei,
    Ofir Press, and Karthik Narasimhan. Swe-bench: Can language models resolve real-world
    github issues? arXiv preprint arXiv:2310.06770, 2023.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Carlos E. Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei,
    Ofir Press, 和 Karthik Narasimhan. Swe-bench：语言模型能否解决现实世界的 github 问题？arXiv 预印本
    arXiv:2310.06770, 2023。'
- en: '[18] Shaokai Ye, Jessy Lauer, Mu Zhou, Alexander Mathis, and Mackenzie W. Mathis.
    Amadeusgpt: a natural language interface for interactive animal behavioral analysis.
    arXiv preprint arXiv:2307.04858, 2023.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Shaokai Ye, Jessy Lauer, Mu Zhou, Alexander Mathis, 和 Mackenzie W. Mathis.
    Amadeusgpt：一个用于互动动物行为分析的自然语言接口。arXiv 预印本 arXiv:2307.04858, 2023。'
- en: '[19] Huao Li, Yu Quan Chong, Simon Stepputtis, Joseph Campbell, Dana Hughes,
    Michael Lewis, and Katia Sycara. Theory of mind for multi-agent collaboration
    via large language models. arXiv preprint arXiv:2310.10701, 2023.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Huao Li, Yu Quan Chong, Simon Stepputtis, Joseph Campbell, Dana Hughes,
    Michael Lewis, 和 Katia Sycara. 通过大型语言模型实现多代理协作的心智理论。arXiv 预印本 arXiv:2310.10701,
    2023。'
- en: '[20] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir
    Karpukhin, Naman Goyal, and Heinrich Küttler. Retrieval-augmented generation for
    knowledge-intensive nlp tasks. arXiv preprint arXiv:2005.11401, pages 9459–9474,
    2020.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir
    Karpukhin, Naman Goyal, 和 Heinrich Küttler. 检索增强生成用于知识密集型 NLP 任务。arXiv 预印本 arXiv:2005.11401,
    第9459–9474页, 2020。'
- en: '[21] Nian Li, Chen Gao, Yong Li, and Qingmin Liao. Large language model-empowered
    agents for simulating macroeconomic activities. arXiv preprint arXiv:2310.10436,
    2023.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] Nian Li, Chen Gao, Yong Li, 和 Qingmin Liao. 大型语言模型驱动的代理用于模拟宏观经济活动。arXiv
    预印本 arXiv:2310.10436, 2023。'
- en: '[22] Edward Junprung. Exploring the intersection of large language models and
    agent-based modeling via prompt engineering. arXiv preprint arXiv:2308.07411,
    2023.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Edward Junprung. 通过提示工程探索大型语言模型与基于代理建模的交集。arXiv 预印本 arXiv:2308.07411,
    2023。'
- en: '[23] S. Sasikumar, S. Prabha, and Chandra Mohan. Improving performance of next.js
    app and testing it while building a badminton based web app. In Proceedings of
    the International Conference on Innovative Computing & Communication (ICICC) 2022,
    May 2022.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] S. Sasikumar, S. Prabha, 和 Chandra Mohan. 提高 next.js 应用性能并在构建基于羽毛球的网页应用时进行测试。国际创新计算与通信会议（ICICC）2022
    论文集，2022年5月。'
