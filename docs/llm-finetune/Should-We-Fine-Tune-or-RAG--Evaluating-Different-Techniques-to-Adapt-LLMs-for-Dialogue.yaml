- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 18:36:03'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:36:03
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for
    Dialogue
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们应该进行微调还是使用 RAG？评估不同技术以适应 LLMs 进行对话
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.06399](https://ar5iv.labs.arxiv.org/html/2406.06399)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2406.06399](https://ar5iv.labs.arxiv.org/html/2406.06399)
- en: Simone Alghisi^( $\dagger$ ), Massimo Rizzoli, Gabriel Roccabruna,
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Simone Alghisi^( $\dagger$ )、Massimo Rizzoli、Gabriel Roccabruna、
- en: Seyed Mahed Mousavi, Giuseppe Riccardi
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Seyed Mahed Mousavi、Giuseppe Riccardi
- en: Signals and Interactive Systems Lab, University of Trento, Italy
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 意大利特伦托大学信号与互动系统实验室
- en: '{s.alghisi, massimo.rizzoli, giuseppe.riccardi}@unitn.it Equal contribution.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '{s.alghisi, massimo.rizzoli, giuseppe.riccardi}@unitn.it 平等贡献。'
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: We study the limitations of Large Language Models (LLMs) for the task of response
    generation in human-machine dialogue. Several techniques have been proposed in
    the literature for different dialogue types (e.g., Open-Domain). However, the
    evaluations of these techniques have been limited in terms of base LLMs, dialogue
    types and evaluation metrics. In this work, we extensively analyze different LLM
    adaptation techniques when applied to different dialogue types. We have selected
    two base LLMs, Llama2[C] and Mistral[I], and four dialogue types Open-Domain,
    Knowledge-Grounded, Task-Oriented, and Question Answering. We evaluate the performance
    of in-context learning and fine-tuning techniques across datasets selected for
    each dialogue type. We assess the impact of incorporating external knowledge to
    ground the generation in both scenarios of Retrieval-Augmented Generation (RAG)
    and gold knowledge. We adopt consistent evaluation and explainability criteria
    for automatic metrics and human evaluation protocols. Our analysis shows that
    there is no universal best-technique for adapting large language models as the
    efficacy of each technique depends on both the base LLM and the specific type
    of dialogue. Last but not least, the assessment of the best adaptation technique
    should include human evaluation to avoid false expectations and outcomes derived
    from automatic metrics.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究了大型语言模型（LLMs）在生成响应任务中的局限性。文献中已经提出了针对不同对话类型（例如开放领域）的几种技术。然而，这些技术的评估在基础 LLMs、对话类型和评估指标方面都比较有限。在这项工作中，我们广泛分析了将不同
    LLM 适应技术应用于不同对话类型时的表现。我们选择了两个基础 LLMs，Llama2[C] 和 Mistral[I]，以及四种对话类型：开放领域、知识基础、任务导向和问答。我们评估了在为每种对话类型选择的数据集上，内嵌学习和微调技术的表现。我们评估了在检索增强生成（RAG）和黄金知识两种场景中引入外部知识以使生成更具基础的影响。我们采用了一致的评估和可解释性标准来评估自动指标和人工评估协议。我们的分析显示，没有一种通用的最佳技术来适应大型语言模型，因为每种技术的效果都依赖于基础
    LLM 和特定的对话类型。最后但同样重要的是，评估最佳适应技术时应包括人工评估，以避免基于自动指标产生的虚假期望和结果。
- en: Should We Fine-Tune or RAG?
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该进行微调还是使用 RAG？
- en: Evaluating Different Techniques to Adapt LLMs for Dialogue
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 评估不同技术以适应 LLMs 进行对话
- en: 'Simone Alghisi^( $\dagger$ ), Massimo Rizzoli^†^†thanks: Equal contribution.,
    Gabriel Roccabruna, Seyed Mahed Mousavi, Giuseppe Riccardi Signals and Interactive
    Systems Lab, University of Trento, Italy {s.alghisi, massimo.rizzoli, giuseppe.riccardi}@unitn.it'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 'Simone Alghisi^( $\dagger$ )、Massimo Rizzoli^†^†thanks: 平等贡献。、Gabriel Roccabruna、Seyed
    Mahed Mousavi、Giuseppe Riccardi 信号与互动系统实验室，意大利特伦托大学 {s.alghisi, massimo.rizzoli,
    giuseppe.riccardi}@unitn.it'
- en: 1 Introduction
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 介绍
- en: In recent years, Large Language Models (LLMs) have been employed for the task
    of response generation in human-machine dialogues (Hosseini-Asl et al., [2020a](#bib.bib16);
    Izacard and Grave, [2021](#bib.bib20); Komeili et al., [2022](#bib.bib27)). Such
    models have been applied to several dialogue types, including Open-Domain Dialogues
    (i.e. informal conversations about trivial matters), Knowledge-Grounded Dialogues
    (i.e. conversations with a system that provides factual responses), Task-Oriented
    Dialogues (i.e. conversations where the system helps a user to achieve a specific
    goal), and Question Answering (i.e. question-answer exchanges given context).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，大型语言模型（LLMs）已被用于人机对话中的响应生成任务（Hosseini-Asl et al., [2020a](#bib.bib16); Izacard
    和 Grave, [2021](#bib.bib20); Komeili et al., [2022](#bib.bib27)）。这些模型已被应用于几种对话类型，包括开放领域对话（即关于琐事的非正式谈话）、知识基础对话（即与提供事实响应的系统的对话）、任务导向对话（即系统帮助用户实现特定目标的对话）和问答（即在给定上下文的情况下的问答交换）。
- en: However, recent studies have shown the shortcomings of LLMs as dialogue model
    surrogates as they are prone to generate toxic, biased, and irrelevant responses (Zhang
    et al., [2020](#bib.bib63); Mousavi et al., [2022](#bib.bib40), [2023](#bib.bib38);
    Lin and Chen, [2023](#bib.bib35)). To adapt LLMs to dialogue types, different
    techniques have been employed such as in-context learning (Brown et al., [2020](#bib.bib3);
    Chen et al., [2023](#bib.bib4); Meade et al., [2023](#bib.bib37)) and fine-tuning (Wang
    et al., [2022](#bib.bib55); Komeili et al., [2022](#bib.bib27); Huang et al.,
    [2023](#bib.bib19)). Furthermore, strategies such as grounding (Gopalakrishnan
    et al., [2019](#bib.bib12); Zhao et al., [2023](#bib.bib64)) and Retrieval-Augmented
    Generation (RAG) (Lewis et al., [2020](#bib.bib32); Borgeaud et al., [2022](#bib.bib2))
    have been proposed to improve the generation quality.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，最近的研究显示LLMs作为对话模型替代品的不足之处，因为它们容易生成有害、偏见和无关的回应（Zhang et al., [2020](#bib.bib63);
    Mousavi et al., [2022](#bib.bib40), [2023](#bib.bib38); Lin and Chen, [2023](#bib.bib35)）。为了使LLMs适应对话类型，采用了不同的技术，如上下文学习（Brown
    et al., [2020](#bib.bib3); Chen et al., [2023](#bib.bib4); Meade et al., [2023](#bib.bib37)）和微调（Wang
    et al., [2022](#bib.bib55); Komeili et al., [2022](#bib.bib27); Huang et al.,
    [2023](#bib.bib19)）。此外，提出了如基础（Gopalakrishnan et al., [2019](#bib.bib12); Zhao
    et al., [2023](#bib.bib64)）和检索增强生成（RAG）（Lewis et al., [2020](#bib.bib32); Borgeaud
    et al., [2022](#bib.bib2)）等策略来改善生成质量。
- en: Currently, the performance of the aforementioned techniques in adapting LLMs
    across different dialogue types is understudied. Previous studies have evaluated
    these techniques in a specific dialogue type only (Raposo et al., [2023](#bib.bib47);
    Zhang et al., [2023](#bib.bib61)). Such studies are based on different base models
    and are assessed via incomparable evaluation methodologies.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，前述技术在不同对话类型中适应大型语言模型（LLMs）的表现尚未深入研究。之前的研究仅在特定对话类型中评估了这些技术（Raposo et al.,
    [2023](#bib.bib47); Zhang et al., [2023](#bib.bib61)）。这些研究基于不同的基础模型，并通过不可比的评估方法进行评估。
- en: 'In this work, we conduct an extensive study on the efficacy of different techniques
    to adapt LLMs for multiple dialogue types. We select Llama-2 Chat (Llama2[C]) (Touvron
    et al., [2023](#bib.bib54)) and Mistral Instruct (Mistral[I]) (Jiang et al., [2023](#bib.bib21))
    as base LLMs, and experiment with in-context learning and fine-tuning in the context
    of four dialogue types: a) Open-Domain Dialogues (ODDs), b) Knowledge-Grounded
    Dialogues (KGDs), c) Task-Oriented Dialogues (TODs), d) Question Answering (QA).
    Besides, we assess the impact of incorporating external knowledge by considering
    retrieved knowledge and gold knowledge. In the retrieved knowledge scenario, we
    use RAG to add the knowledge to the model’s input. We assess the performance of
    each technique using the same automatic metrics and comparable human evaluation.
    We further compute the contribution of each segment of the input vector by using
    integrated gradients as an explainability attribution method. We evaluate the
    models using an open human evaluation protocol Mousavi et al. ([2022](#bib.bib40))
    designed for dialogue contextualization, appropriateness, correctness, and validity.
    In summary, the main contributions of this paper are:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们对适应LLMs于多种对话类型的不同技术的有效性进行了广泛研究。我们选择Llama-2 Chat (Llama2[C]) (Touvron
    et al., [2023](#bib.bib54)) 和 Mistral Instruct (Mistral[I]) (Jiang et al., [2023](#bib.bib21))
    作为基础LLMs，并在四种对话类型的背景下进行上下文学习和微调实验：a) 开放领域对话（ODDs），b) 知识驱动对话（KGDs），c) 任务导向对话（TODs），d)
    问答（QA）。此外，我们通过考虑检索知识和黄金知识来评估融入外部知识的影响。在检索知识的场景中，我们使用RAG将知识添加到模型输入中。我们使用相同的自动化指标和可比的人类评估来评估每种技术的性能。我们进一步使用集成梯度作为可解释性归因方法来计算输入向量每个部分的贡献。我们使用Mousavi
    et al. ([2022](#bib.bib40))设计的开放人类评估协议来评估模型的对话背景化、适当性、正确性和有效性。总之，本文的主要贡献包括：
- en: •
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Adaptation of Llama2[C] and Mistral[I] using fine-tuning and in-context learning
    in four different dialogue types and corresponding corpora;
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用微调和上下文学习在四种不同对话类型和相应语料库中对Llama2[C] 和 Mistral[I] 进行适应；
- en: •
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Assessment of the impact of grounding the response generation on external knowledge,
    both in cases of retrieved knowledge and gold knowledge;
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 评估响应生成中将外部知识作为基础的影响，包括检索知识和黄金知识的情况；
- en: •
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Extensive study on the efficacy of each technique using automatic evaluations
    and human evaluation, including explainability and categorization analysis of
    natural language generation errors.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用自动评估和人工评估，对每种技术的有效性进行广泛研究，包括自然语言生成错误的可解释性和分类分析。
- en: 2 Literature Review
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 文献综述
- en: Open-Domain Dialogue (ODD) In earlier studies, sequence-to-sequence models have
    been trained for response generation in open-domain dialogues Li et al. ([2017](#bib.bib33)).
    However, such models suffered from generating generic or inappropriate responses
     (Zhang et al., [2020](#bib.bib63)). To improve the generation quality, studies
    grounded the generation on external knowledge, such as persona statements (Wolf
    et al., [2019](#bib.bib56); Kasahara et al., [2022](#bib.bib23); Xu et al., [2022b](#bib.bib58)),
    the personal graph of user interactions (Mousavi et al., [2023](#bib.bib38)),
    and retrieved documents (Huang et al., [2023](#bib.bib19)). While the previous
    works developed data-driven models using training/fine-tuning, recent studies
    have explored the potential of in-context learning with LLMs (Qian et al., [2023](#bib.bib42)).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 开放域对话（ODD）在早期的研究中，序列到序列模型已被训练用于开放域对话中的响应生成 Li 等人（[2017](#bib.bib33)）。然而，这些模型常常产生通用或不适当的回应
    Zhang 等人（[2020](#bib.bib63)）。为了提高生成质量，研究将生成过程基于外部知识，如个性化声明（Wolf 等人，[2019](#bib.bib56)；Kasahara
    等人，[2022](#bib.bib23)；Xu 等人，[2022b](#bib.bib58)）、用户互动的个人图谱（Mousavi 等人，[2023](#bib.bib38)）以及检索的文档（Huang
    等人，[2023](#bib.bib19)）。虽然之前的工作开发了使用训练/微调的数据驱动模型，最近的研究则探讨了利用大型语言模型（LLMs）进行上下文学习的潜力（Qian
    等人，[2023](#bib.bib42)）。
- en: Knowledge-Grounded Dialogue (KGD) Sources such as Wikipedia have been used as
    unstructured knowledge to ground the generated responses (Dinan et al., [2019](#bib.bib6);
    Gopalakrishnan et al., [2019](#bib.bib12); Komeili et al., [2022](#bib.bib27))
    to generate consistent and factual answers. To improve the generation quality,
    previous works have studied the impact of knowledge selection (Qin et al., [2023](#bib.bib43);
    Sun et al., [2023](#bib.bib51)), different knowledge representations (Mousavi
    et al., [2023](#bib.bib38); Yang et al., [2023](#bib.bib59)), additional knowledge
    elements (e.g. dialogue acts, topics) (Hedayatnia et al., [2020](#bib.bib15)),
    training without knowledge supervision (Han et al., [2023](#bib.bib13)), and in-context
    learning (Chen et al., [2023](#bib.bib4)).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 知识基础对话（KGD）像 Wikipedia 这样的来源已被用作非结构化知识，以支撑生成的回应（Dinan 等人，[2019](#bib.bib6)；Gopalakrishnan
    等人，[2019](#bib.bib12)；Komeili 等人，[2022](#bib.bib27)），以生成一致且真实的答案。为了提高生成质量，之前的工作研究了知识选择的影响（Qin
    等人，[2023](#bib.bib43)；Sun 等人，[2023](#bib.bib51)）、不同的知识表示（Mousavi 等人，[2023](#bib.bib38)；Yang
    等人，[2023](#bib.bib59)）、额外的知识元素（例如对话行为、话题）（Hedayatnia 等人，[2020](#bib.bib15)）、在没有知识监督的情况下进行训练（Han
    等人，[2023](#bib.bib13)）以及上下文学习（Chen 等人，[2023](#bib.bib4)）。
- en: Task-Oriented Dialogue (TOD) LLMs have been fine-tuned for TOD modeling for
    joint dialogue state tracking and response generation (Hosseini-Asl et al., [2020b](#bib.bib17);
    Kulhánek et al., [2021](#bib.bib28); Wang et al., [2022](#bib.bib55); Ding et al.,
    [2024](#bib.bib7)), and robustness to spoken interactions Thulke et al. ([2024](#bib.bib52));
    Mousavi et al. ([2024](#bib.bib39)). Recent studies focus on augmenting the TOD
    modeling with unstructured knowledge access  (Feng et al., [2020](#bib.bib9);
    Kim et al., [2020](#bib.bib24), [2021](#bib.bib25)). In this regard, He et al.
    ([2024](#bib.bib14)) have proposed a pipeline for retrieval and grounded response
    generation. Raposo et al. ([2023](#bib.bib47)) compared in-context-learning and
    fine-tuning, but considered retrieved replies from previous dialogues as knowledge.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 任务导向对话（TOD）LLMs 已被微调用于 TOD 建模，以实现联合对话状态跟踪和响应生成（Hosseini-Asl 等人，[2020b](#bib.bib17)；Kulhánek
    等人，[2021](#bib.bib28)；Wang 等人，[2022](#bib.bib55)；Ding 等人，[2024](#bib.bib7)），并对口语互动的鲁棒性（Thulke
    等人，[2024](#bib.bib52)；Mousavi 等人，[2024](#bib.bib39)）进行研究。最近的研究集中于通过非结构化知识访问来增强
    TOD 建模（Feng 等人，[2020](#bib.bib9)；Kim 等人，[2020](#bib.bib24)，[2021](#bib.bib25)）。在这方面，He
    等人（[2024](#bib.bib14)）提出了一种用于检索和基础响应生成的流程。Raposo 等人（[2023](#bib.bib47)）比较了上下文学习和微调，但将从先前对话中检索的回复视为知识。
- en: Question Answering (QA). In the most general setting, relevant documents need
    to be retrieved to provide an answer (Lee et al., [2019](#bib.bib30); Qu et al.,
    [2020](#bib.bib44)). Some studies have proposed to select the documents with the
    highest similarity with the question computed between their BERT encodings (Lee
    et al., [2019](#bib.bib30); Karpukhin et al., [2020](#bib.bib22)). With this retrieval
    strategy, some studies have fine-tuned LLMs to condition the generation on the
    retrieved documents through grounding (Lewis et al., [2020](#bib.bib32); Izacard
    and Grave, [2021](#bib.bib20)) or cross-attention (Borgeaud et al., [2022](#bib.bib2)).
    Other works generated the answers using in-context learning with zero-shot Levine
    et al. ([2022](#bib.bib31)); Cho et al. ([2023](#bib.bib5)). A survey compared
    existing generation-only, retrieval-only, and RAG models (Zhang et al., [2023](#bib.bib61))
    but with different base models, hindering the comparison of the techniques.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 问答（QA）。在最一般的设置中，需要检索相关文档以提供答案（Lee 等，[2019](#bib.bib30)；Qu 等，[2020](#bib.bib44)）。一些研究建议选择与问题之间
    BERT 编码相似度最高的文档（Lee 等，[2019](#bib.bib30)；Karpukhin 等，[2020](#bib.bib22)）。采用这种检索策略，一些研究微调了
    LLMs，通过对文档的基础（Lewis 等，[2020](#bib.bib32)；Izacard 和 Grave，[2021](#bib.bib20)）或交叉注意力（Borgeaud
    等，[2022](#bib.bib2)）来调节生成。其他工作则使用零样本的上下文学习生成答案（Levine 等，[2022](#bib.bib31)；Cho
    等，[2023](#bib.bib5)）。一项调查比较了现有的仅生成、仅检索和 RAG 模型（Zhang 等，[2023](#bib.bib61)），但由于基模型不同，阻碍了技术的比较。
- en: 3 Experiments
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 实验
- en: 'We study and compare in-context learning and fine-tuning as techniques to adapt
    LLMs for human-machine dialogues. We select Llama-2 Chat (Llama2[C]) (Touvron
    et al., [2023](#bib.bib54)) and Mistral Instruct (Mistral[I]) (Jiang et al., [2023](#bib.bib21))
    as base LLMs, and experiment in the context of four dialogue types: Open-Domain
    Dialogue (ODD), Knowledge-Grounded Dialogue (KGD), Task-Oriented Dialogue (TOD),
    and Question Answering (QA). For each technique and dialogue type, we assess the
    impact of grounding the generation on documents in the scenarios of retrieved
    knowledge (RAG) and gold knowledge.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究并比较了上下文学习和微调作为技术以适应 LLMs 进行人机对话。我们选择 Llama-2 Chat（Llama2[C]）（Touvron 等，[2023](#bib.bib54)）和
    Mistral Instruct（Mistral[I]）（Jiang 等，[2023](#bib.bib21)）作为基础 LLMs，并在四种对话类型的背景下进行实验：开放域对话（ODD）、知识驱动对话（KGD）、任务导向对话（TOD）和问答（QA）。对于每种技术和对话类型，我们评估了在检索知识（RAG）和黄金知识的场景中生成的影响。
- en: 3.1 Datasets
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 数据集
- en: In our experiment, we have selected a dataset for each of the four dialogue
    types (see §[A.1](#A1.SS1 "A.1 Datasets ‣ Appendix A Appendix ‣ Limitations ‣
    5 Conclusion ‣ 4.3 Explaining Negative Human Judgments ‣ 4.2 Human Evaluation
    ‣ 4.1.1 Explainability Study ‣ 4.1 Automatic Evaluation ‣ 4 Evaluation ‣ Should
    We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue")
    for selection). The statistics of these datasets are summarized in Table [1](#S3.T1
    "Table 1 ‣ 3.1 Datasets ‣ 3 Experiments ‣ Should We Fine-Tune or RAG? Evaluating
    Different Techniques to Adapt LLMs for Dialogue").
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的实验中，我们为四种对话类型中的每一种选择了一个数据集（见 §[A.1](#A1.SS1 "A.1 数据集 ‣ 附录 A ‣ 局限性 ‣ 5 结论
    ‣ 4.3 解释负面人工判断 ‣ 4.2 人工评价 ‣ 4.1.1 解释性研究 ‣ 4.1 自动评价 ‣ 4 评价 ‣ 我们应该微调还是 RAG？评估不同技术以适应对话
    LLMs") 以供选择）。这些数据集的统计信息汇总在表 [1](#S3.T1 "表 1 ‣ 3.1 数据集 ‣ 3 实验 ‣ 我们应该微调还是 RAG？评估不同技术以适应对话
    LLMs") 中。
- en: Open-Domain Dialogue (ODD) We select DailyDialog Li et al. ([2017](#bib.bib33)),
    a widely-used dataset of human-human dialogues crawled from various websites used
    by English learners to practice. The final dataset contains 13k written dialogues
    with an average of 8 turns per dialogue.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 开放域对话（ODD）我们选择了 DailyDialog（Li 等，[2017](#bib.bib33)），这是一个广泛使用的人际对话数据集，从各种网站抓取，供英语学习者练习。最终的数据集包含
    13k 条书面对话，每条对话平均 8 回合。
- en: Knowledge-Grounded Dialogue (KGD) We experiment on Wizard of Wikipedia  (Dinan
    et al., [2019](#bib.bib6)), a dataset of dialogues between two participants with
    the roles of apprentice and wizard. At each turn, the wizard can access a set
    of documents (passages from Wikipedia) and use it to incorporate factual knowledge
    in their reply. The dataset contains 20k dialogues about one of 1359 distinct
    topics and provides an unseen set of documents for testing.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 知识驱动对话（KGD）我们在 Wizard of Wikipedia（Dinan 等， [2019](#bib.bib6)）上进行实验，这是一个包含两名参与者的对话数据集，其中一名为学徒，另一名为巫师。在每一轮中，巫师可以访问一组文档（维基百科的段落），并利用这些文档在回复中融入事实知识。该数据集包含
    20k 条关于 1359 个不同主题的对话，并提供了一个用于测试的未见文档集。
- en: Task-Oriented Dialogue (TOD) We select the dataset proposed for the ninth Dialogue
    System Technology Challenge (Kim et al., [2020](#bib.bib24)). The dataset spans
    over 7 domains and contains 9k multi-domain dialogues. The dialogues include turns
    where the system needs to access an unstructured knowledge base of 2900 documents
    (FAQs) to provide a correct response.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 任务导向对话（TOD）我们选择了第九届对话系统技术挑战赛（Kim等，[2020](#bib.bib24)）提出的数据集。该数据集覆盖了7个领域，包含9k个多领域对话。对话包括系统需要访问一个包含2900份文档（FAQ）的非结构化知识库以提供正确响应的轮次。
- en: Question Answering (QA) We select NarrativeQA (Kočiský et al., [2018](#bib.bib26)),
    a dataset of 47k questions with free-form answers based on 1.5k books and movie
    scripts. The question-answer pairs are formulated based on summaries of the books
    and movies.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 问题回答（QA）我们选择了NarrativeQA（Kočiský等，[2018](#bib.bib26)），这是一个包含47k个问题和自由形式答案的数据集，基于1.5k本书籍和电影剧本。问题-答案对是基于书籍和电影的总结进行构建的。
- en: '| Type | Dataset | #Dials | Avg. #Turns | #Ext. Know. |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 类型 | 数据集 | #对话 | 平均#轮次 | #外部知识 |'
- en: '| ODD | DailyDialog | 13k | 8 | — |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| ODD | DailyDialog | 13k | 8 | — |'
- en: '| KGD | WoW | 20k | 9 | ^†61 |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| KGD | WoW | 20k | 9 | ^†61 |'
- en: '| TOD | DSTC9 | 9k | 19 | 2900 |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| TOD | DSTC9 | 9k | 19 | 2900 |'
- en: '| QA | NarrativeQA | ^*47k | 2 | 1572 |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| QA | NarrativeQA | ^*47k | 2 | 1572 |'
- en: 'Table 1: Selected datasets for each dialogue type: Open-Domain Dialogue (ODD),
    Knowledge-Grounded Dialogue (KGD), Task-Oriented Dialogue (TOD), and Question
    Answering (QA). #Ext. know. indicates the number of documents in the unstructured
    knowledge base. ^† In KGD the content of the knowledge base differs at each turn
    with an average of $61\pm 22$ documents. ^* Question-answer exchanges.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：每种对话类型的选定数据集：开放领域对话（ODD）、知识支撑对话（KGD）、任务导向对话（TOD）和问题回答（QA）。#外部知识指的是非结构化知识库中的文档数量。^†
    在KGD中，知识库的内容在每次轮次中有所不同，平均为$61\pm 22$份文档。^* 问题-回答交换。
- en: 3.2 Techniques
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 技术
- en: We evaluate in-context learning and fine-tuning as techniques to adapt LLMs
    for response generation in the selected dialogue types. In-context learning is
    a technique that uses instructions and examples to condition the generation. Instead,
    fine-tuning further trains the model (completely or partially) on the task of
    interest using a smaller-scale dataset than the pre-training phase. In a dialogue
    setting, fine-tuning should teach the model the notion of the dialogue and the
    roles of the participants.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们评估了上下文学习和微调作为将LLM适应于选定对话类型的响应生成的技术。上下文学习是一种利用指令和示例来调整生成的技术。相反，微调通过在比预训练阶段规模更小的数据集上进一步训练模型（完全或部分）来进行。在对话设置中，微调应该教会模型对话的概念和参与者的角色。
- en: As a baseline, for both techniques, we consider the context (i.e. the question
    for QA, the history for ODD, KGD, and TOD) as the input and use the default prompt
    structure of the models to separate user and system turns. Additionally, for TOD
    we append the dialogue state (a summary of user requirements), following previous
    work on this dialogue type (Wang et al., [2022](#bib.bib55); Ding et al., [2024](#bib.bib7)).
    For KGD, we prepend the topic to the start of the dialogue.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 作为基准，对于这两种技术，我们将上下文（即QA的问题，ODD、KGD和TOD的历史）视为输入，并使用模型的默认提示结构来分隔用户和系统的轮次。此外，对于TOD，我们在对话状态（用户需求的摘要）后附加，遵循以前对这一对话类型的研究（Wang等，[2022](#bib.bib55)；Ding等，[2024](#bib.bib7)）。对于KGD，我们在对话开始时添加主题。
- en: '| Model | Technique | External Knowledge | Perplexity |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 技术 | 外部知识 | 困惑度 |'
- en: '| ODD | KGD | TOD | QA |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| ODD | KGD | TOD | QA |'
- en: '| Llama2[C] | In-Context Learning | No Know. | 64.13 | 35.17 | 25.15 | 1442.26
    |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| Llama2[C] | 上下文学习 | 无知识 | 64.13 | 35.17 | 25.15 | 1442.26 |'
- en: '| Retrieved Know. |  | 33.10 | 24.72 | 625.08 |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 检索知识 |  | 33.10 | 24.72 | 625.08 |'
- en: '| Gold Know. |  | 24.40 | 23.81 | 298.16 |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 黄金知识 |  | 24.40 | 23.81 | 298.16 |'
- en: '| Fine-Tuning | No Know. | 5.67 $\pm$ 0.06 |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 微调 | 无知识 | 5.67 $\pm$ 0.06 |'
- en: '| Retrieved Know. |  | 6.95 $\pm$ 0.02 |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 检索知识 |  | 6.95 $\pm$ 0.02 |'
- en: '| Gold Know. |  | 4.38 $\pm$ 0.01 |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 黄金知识 |  | 4.38 $\pm$ 0.01 |'
- en: '| Mistral[I] | In-Context Learning | No Know. | 14.19 | 15.31 | 9.82 | 91.42
    |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| Mistral[I] | 上下文学习 | 无知识 | 14.19 | 15.31 | 9.82 | 91.42 |'
- en: '| Retrieved Know. |  | 14.75 | 9.76 | 42.58 |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 检索知识 |  | 14.75 | 9.76 | 42.58 |'
- en: '| Gold Know. |  | 9.81 | 9.37 | 16.74 |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 黄金知识 |  | 9.81 | 9.37 | 16.74 |'
- en: '| Fine-Tuning | No Know. | 6.41 $\pm$ 0.01 |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 微调 | 无知识 | 6.41 $\pm$ 0.01 |'
- en: '| Retrieved Know. |  | 7.78 $\pm$ 0.01 |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 检索知识 |  | 7.78 $\pm$ 0.01 |'
- en: '| Gold Know. |  | 5.17 $\pm$ 0.01 |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 黄金知识 |  | 5.17 $\pm$ 0.01 |'
- en: 'Table 2: Automatic Evaluation Perplexity of Fine-Tuning and In-Context Learning
    with Retrieved (top-3) and Gold (ground-truth) knowledge, on Llama2[C] and Mistral[I],
    in different dialogue types: Open-Domain Dialogues (ODDs), Knowledge Grounded
    Dialogues (KGDs), Task-Oriented Dialogues (TODs), and Question Answering (QA).
    Results for fine-tuned models report mean and standard deviation over three runs.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：在不同对话类型中，Llama2[C]和Mistral[I]使用检索（top-3）和黄金（ground-truth）知识的自动评价困惑度：开放领域对话（ODDs）、知识基础对话（KGDs）、任务导向对话（TODs）和问答（QA）。微调模型的结果报告了三次运行的均值和标准差。
- en: 3.3 Knowledge
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 知识
- en: Incorporating external knowledge for the task of response generation has been
    shown to improve the factual accuracy (He et al., [2024](#bib.bib14)) and contextualization (Mousavi
    et al., [2023](#bib.bib38)) of responses.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 将外部知识纳入响应生成任务已被证明可以提高事实准确性（He et al., [2024](#bib.bib14)）和情境化（Mousavi et al.,
    [2023](#bib.bib38)）。
- en: For each of the selected types but for ODD, we consider their corresponding
    unstructured knowledge base. Regarding KGD, we consider passages from Wikipedia,
    while for TOD we consider FAQs related to services and places (e.g. restaurants,
    hotels, taxi booking). For QA we consider all the summaries of the books and movies.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每种选择的类型，除了ODD之外，我们考虑其对应的非结构化知识库。对于KGD，我们考虑维基百科中的片段；而对于TOD，我们考虑与服务和地点（例如餐厅、酒店、出租车预订）相关的常见问题。对于QA，我们考虑所有书籍和电影的总结。
- en: 'For both in-context learning and fine-tuning, we study the impact of knowledge
    on the generated responses, in two scenarios:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 对于上下文学习和微调，我们研究知识对生成响应的影响，在两种场景下：
- en: •
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Retrieved knowledge: we retrieve k documents from the unstructured knowledge
    base;'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 获取的知识：我们从非结构化知识库中检索k个文档；
- en: •
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Gold knowledge: we use the ground truth document.'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 黄金知识：我们使用真实文档。
- en: For the retrieved knowledge scenario, we use the Retrieval Augmented Generation
    (RAG) strategy. We use an off-the-shelf retriever¹¹1[https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain)
    (model details in §[A.2](#A1.SS2 "A.2 Implementation and resources ‣ Appendix
    A Appendix ‣ Limitations ‣ 5 Conclusion ‣ 4.3 Explaining Negative Human Judgments
    ‣ 4.2 Human Evaluation ‣ 4.1.1 Explainability Study ‣ 4.1 Automatic Evaluation
    ‣ 4 Evaluation ‣ Should We Fine-Tune or RAG? Evaluating Different Techniques to
    Adapt LLMs for Dialogue")) to retrieve documents from the unstructured knowledge
    base. First, we encode all the documents considering their content together with
    their topic (KGD), place or service name (TOD), or title (QA) (Karpukhin et al.,
    [2020](#bib.bib22)). Then, at each turn, we retrieve the k most similar documents
    based on L2 distance with the encoded context. Finally, we feed the retrieved
    documents to the base models together with the context to generate a response.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在检索知识场景中，我们使用检索增强生成（RAG）策略。我们使用一个现成的检索器¹¹1[https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain)（模型详情见§[A.2](#A1.SS2
    "A.2 Implementation and resources ‣ Appendix A Appendix ‣ Limitations ‣ 5 Conclusion
    ‣ 4.3 Explaining Negative Human Judgments ‣ 4.2 Human Evaluation ‣ 4.1.1 Explainability
    Study ‣ 4.1 Automatic Evaluation ‣ 4 Evaluation ‣ Should We Fine-Tune or RAG?
    Evaluating Different Techniques to Adapt LLMs for Dialogue")）从非结构化知识库中检索文档。首先，我们对所有文档进行编码，考虑其内容以及主题（KGD）、地点或服务名称（TOD）或标题（QA）（Karpukhin
    et al., [2020](#bib.bib22)）。然后，在每一轮中，我们基于与编码上下文的L2距离检索k个最相似的文档。最后，我们将检索到的文档与上下文一起输入基础模型以生成响应。
- en: In the gold knowledge scenario, we directly feed the model with the ground truth
    documents. This serves as an upper bound for RAG. Additionally, this strategy
    allows us to study the ability of the techniques to incorporate knowledge in the
    responses.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在黄金知识场景中，我们直接将真实文档输入模型。这作为RAG的上限。此外，这种策略使我们能够研究这些技术在响应中纳入知识的能力。
- en: 3.4 Models
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 模型
- en: We select the widely-used 7B version of Llama2[C] and Mistral[I] as base models.
    For in-context learning, we experiment with three instructions for each dialogue
    type and select the best based on the development set performance. For fine-tuning,
    we use LoRA, a parameter-efficient technique that has shown comparable performance
    to fine-tuning all parameters (Hu et al., [2021](#bib.bib18)). Further details
    about the parameters are reported in §[A.2](#A1.SS2 "A.2 Implementation and resources
    ‣ Appendix A Appendix ‣ Limitations ‣ 5 Conclusion ‣ 4.3 Explaining Negative Human
    Judgments ‣ 4.2 Human Evaluation ‣ 4.1.1 Explainability Study ‣ 4.1 Automatic
    Evaluation ‣ 4 Evaluation ‣ Should We Fine-Tune or RAG? Evaluating Different Techniques
    to Adapt LLMs for Dialogue").
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了广泛使用的 7B 版本的 Llama2[C] 和 Mistral[I] 作为基础模型。对于上下文学习，我们对每种对话类型进行了三种指令的实验，并根据开发集的表现选择最佳指令。对于微调，我们使用了
    LoRA，这是一种参数高效的技术，其性能已被证明与微调所有参数相当（Hu 等，[2021](#bib.bib18)）。有关参数的更多细节，请参见 §[A.2](#A1.SS2
    "A.2 实现和资源 ‣ 附录 A 附录 ‣ 限制 ‣ 5 结论 ‣ 4.3 解释负面人工评判 ‣ 4.2 人工评估 ‣ 4.1.1 可解释性研究 ‣ 4.1
    自动评估 ‣ 4 评估 ‣ 我们应该微调还是 RAG？评估不同技术对 LLM 的对话适应性")。
- en: 4 Evaluation
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 评估
- en: 'We conduct a comparative study on the impact of in-context learning and fine-tuning
    to adapt LLMs for dialogues. We select Llama2[C] and Mistral[I] as base LLMs and
    experiment in four dialogue types: ODDs, KGDs, TODs, QA. For each dialogue type,
    we study the impact of external knowledge, both retrieved and gold. Further details
    about the implementation and the resources used are available in the appendix
    (§[A.2](#A1.SS2 "A.2 Implementation and resources ‣ Appendix A Appendix ‣ Limitations
    ‣ 5 Conclusion ‣ 4.3 Explaining Negative Human Judgments ‣ 4.2 Human Evaluation
    ‣ 4.1.1 Explainability Study ‣ 4.1 Automatic Evaluation ‣ 4 Evaluation ‣ Should
    We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue")).'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对上下文学习和微调对对话的适应性影响进行了比较研究。我们选择了 Llama2[C] 和 Mistral[I] 作为基础 LLM，并在四种对话类型下进行了实验：ODDs、KGDs、TODs
    和 QA。对于每种对话类型，我们研究了外部知识的影响，包括检索的和黄金的。有关实现和使用资源的更多细节，请参见附录 (§[A.2](#A1.SS2 "A.2
    实现和资源 ‣ 附录 A 附录 ‣ 限制 ‣ 5 结论 ‣ 4.3 解释负面人工评判 ‣ 4.2 人工评估 ‣ 4.1.1 可解释性研究 ‣ 4.1 自动评估
    ‣ 4 评估 ‣ 我们应该微调还是 RAG？评估不同技术对 LLM 的对话适应性"))。
- en: 4.1 Automatic Evaluation
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 自动评估
- en: 'Table [2](#S3.T2 "Table 2 ‣ 3.2 Techniques ‣ 3 Experiments ‣ Should We Fine-Tune
    or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue") reports the
    perplexity of Llama2[C] and Mistral[I] on the test set of each dialogue type.
    In all dialogue types, fine-tuned models have obtained better performance compared
    to in-context learning. When considering the impact of external knowledge, models
    fine-tuned on TODs show that knowledge slightly increases perplexity. The high
    perplexity obtained by in-context learning models on QA can be explained because
    of two reasons: first, besides the knowledge, only the question is used as context;
    second, while the ground truths are particularly short (4.26 tokens on average),
    these models generate long responses, making them unlikely to include the correct
    answer in the first few tokens. This does not happen for fine-tuned models since
    they are trained to generate shorter responses. Nevertheless, the best results
    have been obtained by the models using gold knowledge. We report automatic evaluation
    results including retriever accuracy, overlap between knowledge and response tokens,
    and other automatic metrics in §[A.3](#A1.SS3 "A.3 Additional Automatic Evaluation
    ‣ Appendix A Appendix ‣ Limitations ‣ 5 Conclusion ‣ 4.3 Explaining Negative Human
    Judgments ‣ 4.2 Human Evaluation ‣ 4.1.1 Explainability Study ‣ 4.1 Automatic
    Evaluation ‣ 4 Evaluation ‣ Should We Fine-Tune or RAG? Evaluating Different Techniques
    to Adapt LLMs for Dialogue").'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [2](#S3.T2 "表 2 ‣ 3.2 技术 ‣ 3 实验 ‣ 我们应该微调还是 RAG？评估不同技术以适应对话的 LLM") 报告了 Llama2[C]
    和 Mistral[I] 在每种对话类型的测试集上的困惑度。在所有对话类型中，微调模型相较于上下文学习模型表现更好。考虑到外部知识的影响，微调在 TODs
    上的模型显示知识略微增加了困惑度。上下文学习模型在 QA 上的高困惑度可以用两个原因解释：首先，除了知识外，只有问题作为上下文；其次，虽然实际答案特别短（平均
    4.26 个标记），这些模型生成了长响应，使得在前几个标记中不太可能包含正确答案。这种情况在微调模型中不会发生，因为它们被训练生成较短的响应。然而，使用黄金知识的模型获得了最佳结果。我们在
    §[A.3](#A1.SS3 "A.3 附加自动评估 ‣ 附录 A ‣ 限制 ‣ 5 结论 ‣ 4.3 解释负面人工判断 ‣ 4.2 人工评估 ‣ 4.1.1
    可解释性研究 ‣ 4.1 自动评估 ‣ 4 评估 ‣ 我们应该微调还是 RAG？评估不同技术以适应对话的 LLM") 中报告了包括检索器准确度、知识与响应标记之间的重叠以及其他自动度量的自动评估结果。
- en: '| Model | Dialogue Type | Technique | % of Tokens w. Significant Contribution
    in Each Segment |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 对话类型 | 技术 | 各片段中显著贡献的标记百分比 |'
- en: '| Instruction | Topic/Dialogue State | Dialogue History | Knowledge |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 指令 | 主题/对话状态 | 对话历史 | 知识 |'
- en: '| Llama2[C] | KGD | In-Context Learning | 21.85 | 28.60 | 15.97 | 33.58 |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| Llama2[C] | KGD | 上下文学习 | 21.85 | 28.60 | 15.97 | 33.58 |'
- en: '| \cdashline3-7 | Fine-Tuning |  | 39.43 | 13.80 | 46.77 |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| \cdashline3-7 | 微调 |  | 39.43 | 13.80 | 46.77 |'
- en: '|  | TOD | In-Context Learning | 25.98 | 19.54 | 16.46 | 38.02 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '|  | TOD | 上下文学习 | 25.98 | 19.54 | 16.46 | 38.02 |'
- en: '| \cdashline3-7 | Fine-Tuning |  | 27.19 | 8.04 | 64.77 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| \cdashline3-7 | 微调 |  | 27.19 | 8.04 | 64.77 |'
- en: '| Mistral[I] | KGD | In-Context Learning |  | 69.01 | 14.89 | 16.10 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| Mistral[I] | KGD | 上下文学习 |  | 69.01 | 14.89 | 16.10 |'
- en: '| \cdashline3-7 | Fine-Tuning |  | 65.55 | 11.00 | 23.45 |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| \cdashline3-7 | 微调 |  | 65.55 | 11.00 | 23.45 |'
- en: '|  | TOD | In-Context Learning | 69.05 | 10.19 | 11.24 | 9.52 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '|  | TOD | 上下文学习 | 69.05 | 10.19 | 11.24 | 9.52 |'
- en: '| \cdashline3-7 | Fine-Tuning |  | 14.55 | 29.06 | 56.39 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| \cdashline3-7 | 微调 |  | 14.55 | 29.06 | 56.39 |'
- en: 'Table 3: Explanability Study Percentage of tokens with significant contribution
    to the generation in different segments of the input vector for each model in
    Knowledge-Grounded Dialogues (KGDs), and Task-Oriented Dialogues (TODs). All rows
    sum to 100. For KGD, the second column reports the contribution of the Topic,
    while for TOD it reports the contribution of the Dialogue State. The Instruction
    segment is only present for In-Context Learning.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：在知识驱动对话（KGDs）和任务导向对话（TODs）中，每种模型在输入向量不同片段中的生成显著贡献的标记百分比。所有行的总和为100。对于KGD，第二列报告了主题的贡献，而对于TOD，则报告了对话状态的贡献。指令片段仅在上下文学习中存在。
- en: 4.1.1 Explainability Study
  id: totrans-90
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.1 可解释性研究
- en: To understand the contribution of each segment of the input vector (i.e. instruction,
    context, knowledge, topic, and dialogue state), we compute integrated gradients (Sarti
    et al., [2023](#bib.bib49))²²2We use Inseq to compute integrated gradients. of
    input elements and select the most contributing input tokens (top-25%). Table
    [4.1](#S4.SS1 "4.1 Automatic Evaluation ‣ 4 Evaluation ‣ Should We Fine-Tune or
    RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue") reports the
    percentage of most contributing tokens that fall in each segment (normalized by
    the length of the segment). In general, in both KGD and TOD, the dialogue history
    is the least contributing segment, which might indicate that only a part of the
    history is significant for response generation. On the other hand, in KGD the
    topic has a higher score than the dialogue history, suggesting its importance
    for response generation for this dialogue type. Interestingly, Mistral[I] gives
    considerably more importance to the topic than Llama2[C], decreasing the importance
    of the knowledge segment. For the TOD type, the most contributing segment is often
    the knowledge, reaching over 50% with fine-tuning. This suggests that knowledge
    is more relevant for TOD and that relevance changes with respect to the dialogue
    type.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解输入向量中每个部分的贡献（即指令、上下文、知识、主题和对话状态），我们计算了集成梯度（Sarti等，[2023](#bib.bib49)）²²2我们使用Inseq来计算输入元素的集成梯度，并选择最具贡献的输入标记（前25%）。表格[4.1](#S4.SS1
    "4.1 Automatic Evaluation ‣ 4 Evaluation ‣ Should We Fine-Tune or RAG? Evaluating
    Different Techniques to Adapt LLMs for Dialogue")报告了各部分中最具贡献标记的百分比（按部分长度归一化）。一般而言，无论在KGD还是TOD中，对话历史都是贡献最少的部分，这可能表明历史的只有一部分对响应生成是重要的。另一方面，在KGD中，主题的得分高于对话历史，这表明主题对这一对话类型的响应生成的重要性。有趣的是，Mistral[I]给主题的权重显著高于Llama2[C]，减少了知识部分的重要性。对于TOD类型，最具贡献的部分通常是知识，经过微调后，贡献超过50%。这表明知识对TOD更相关，而且相关性随着对话类型的变化而变化。
- en: '| Model | Technique | External Knowledge | Contextualization | Appropriateness
    | Validity |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| Model | Technique | External Knowledge | Contextualization | Appropriateness
    | Validity |'
- en: '| ODD | KGD | TOD | QA | ODD | KGD | TOD | QA |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| ODD | KGD | TOD | QA | ODD | KGD | TOD | QA |'
- en: '| Llama2[C] | In-Context Learning | No Know. | 85 | 70 | 70 | 50 | 80 | 70
    | 60 | 10 |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| Llama2[C] | In-Context Learning | No Know. | 85 | 70 | 70 | 50 | 80 | 70
    | 60 | 10 |'
- en: '| Retrieved Know. |  | 75 | 65 | 70 |  | 75 | 45 | 35 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| Retrieved Know. |  | 75 | 65 | 70 |  | 75 | 45 | 35 |'
- en: '| Gold Know. |  | 90 | 40 | 90 |  | 85 | 45 | 80 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| Gold Know. |  | 90 | 40 | 90 |  | 85 | 45 | 80 |'
- en: '| Fine-Tuning | No Know. | 45 | 60 | 70 | 15 | 50 | 65 | 60 | 15 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| Fine-Tuning | No Know. | 45 | 60 | 70 | 15 | 50 | 65 | 60 | 15 |'
- en: '| Retrieved Know. |  | 65 | 90 | 45 |  | 80 | 80 | 45 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| Retrieved Know. |  | 65 | 90 | 45 |  | 80 | 80 | 45 |'
- en: '| Gold Know. |  | 80 | 85 | 85 |  | 65 | 85 | 75 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| Gold Know. |  | 80 | 85 | 85 |  | 65 | 85 | 75 |'
- en: '| Mistral[I] | In-Context Learning | No Know. | 90 | 80 | 70 | 20 | 85 | 85
    | 65 | 20 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| Mistral[I] | In-Context Learning | No Know. | 90 | 80 | 70 | 20 | 85 | 85
    | 65 | 20 |'
- en: '| Retrieved Know. |  | 75 | 65 | 40 |  | 65 | 60 | 25 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| Retrieved Know. |  | 75 | 65 | 40 |  | 65 | 60 | 25 |'
- en: '| Gold Know. |  | 90 | 55 | 75 |  | 70 | 55 | 80 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| Gold Know. |  | 90 | 55 | 75 |  | 70 | 55 | 80 |'
- en: '| Fine-Tuning | No Know. | 55 | 90 | 85 | 25 | 55 | 80 | 80 | 20 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| Fine-Tuning | No Know. | 55 | 90 | 85 | 25 | 55 | 80 | 80 | 20 |'
- en: '| Retrieved Know. |  | 95 | 85 | 30 |  | 85 | 90 | 40 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| Retrieved Know. |  | 95 | 85 | 30 |  | 85 | 90 | 40 |'
- en: '| Gold Know. |  | 80 | 75 | 70 |  | 65 | 70 | 70 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| Gold Know. |  | 80 | 75 | 70 |  | 65 | 70 | 70 |'
- en: '| Ground-Truth |  |  | 95 | 80 | 95 | 90 | 100 | 85 | 95 | 90 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| Ground-Truth |  |  | 95 | 80 | 95 | 90 | 100 | 85 | 95 | 90 |'
- en: 'Table 4: Human Evaluation Percentage of Contextualized, Appropriate (ODD, KGD,
    TOD), and Valid (QA) responses for In-Context Learning and Fine-Tuning with Retrieved
    (top-3) and Gold (ground-truth) knowledge, on Llama2[C] and Mistral[I], in different
    dialogue types: Open-Domain Dialogues (ODDs), Knowledge Grounded Dialogues (KGDs),
    Task-Oriented Dialogues (TODs), and Question Answering (QA).'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 表4：人工评估上下文化、适当（ODD、KGD、TOD）和有效（QA）响应的百分比，分别对In-Context Learning和Fine-Tuning，使用检索（前3）和Gold（真实情况）知识，针对不同的对话类型：开放领域对话（ODDs）、知识驱动对话（KGDs）、任务导向对话（TODs）和问答（QA）。
- en: 4.2 Human Evaluation
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 人工评估
- en: 'Considering the uninterpretability of automatic evaluations, we conducted a
    human evaluation of the generated responses to gain more insight into the models’
    performance. To evaluate the responses, we use the protocol proposed by Mousavi
    et al. ([2022](#bib.bib40)), considering three of their dimensions:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到自动评估的不确定性，我们进行了人工评估以获得对模型表现的更多洞察。为了评估响应，我们使用了Mousavi等人提出的协议（[2022](#bib.bib40)），考虑了他们的三个维度：
- en: •
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Contextualization: the response includes explicit or implicit references to
    the context of the dialogue;'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上下文化：响应中包括了对对话上下文的明确或隐含的引用；
- en: •
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Appropriateness: the response is coherent and makes sense as a continuation
    of the dialogue;'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 适当性：响应连贯，并且作为对话的延续有意义；
- en: •
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Correctness: the response is grammatically and syntactically correct.'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 正确性：响应在语法和句法上是正确的。
- en: 'According to these dimensions, we evaluate the responses for all techniques,
    models, and knowledge scenarios, in all dialogue types. The only exception is
    QA, where we do not evaluate Appropriateness since the dimension considers coherence
    with respect to a dialogue history but QA only has question-answer exchanges.
    Instead, we extend the protocol for QA by proposing a new dimension:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这些维度，我们评估了所有技术、模型和知识场景下的响应，涵盖所有对话类型。唯一的例外是 QA（问答），我们不评估适当性，因为这一维度考虑的是对话历史的连贯性，但
    QA 只有问答交换。相反，我们通过提出一个新的维度来扩展 QA 的协议：
- en: •
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Validity: the response includes adequate information to answer the question.'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有效性：响应包含了足够的信息来回答问题。
- en: The dimensions can either have a positive (Contextualized, Appropriate, Correct,
    Valid), negative (Not Contextualized, Not Appropriate, Not Correct, Not Valid)
    or neutral (I don’t know) answer value. For Contextualization and Appropriateness,
    we also ask the annotators to motivate the negative judgments with the explanations
    proposed in the original protocol.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这些维度可以具有正面（上下文化、适当、正确、有效）、负面（未上下文化、未适当、错误、无效）或中性（我不知道）的回答值。对于上下文化和适当性，我们还要求注释员用原协议中提出的解释来阐述负面判断的理由。
- en: We recruited 75 annotators on the Prolific platform³³3[https://www.prolific.com/](https://www.prolific.com/),
    and we assigned 5 dialogues to each annotator. After performing quality control,
    we approved 65 annotators and paid them 9.00£/hour (marked as good on the Prolific
    platform). Due to the large number of responses, each annotator evaluated a different
    set of model responses for a given dialogue. However, each annotator always evaluated
    the ground truth response for all the assigned dialogues, as a point of reference
    and quality control. The inter-annotator agreement measured with Fleiss’ $\kappa$
    (Fleiss, [1971](#bib.bib10)) was 0.65 (substantial agreement).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 Prolific 平台³³3[https://www.prolific.com/](https://www.prolific.com/) 招募了
    75 名注释员，并为每位注释员分配了 5 个对话。在进行质量控制后，我们批准了 65 名注释员，并支付了他们 9.00£/小时（在 Prolific 平台上标记为“良好”）。由于响应数量庞大，每位注释员为特定对话评估了一组不同的模型响应。然而，每位注释员总是评估所有分配对话的真实响应，以作为参考和质量控制。使用
    Fleiss’ $\kappa$（Fleiss, [1971](#bib.bib10)）测量的注释员间一致性为 0.65（显著一致）。
- en: As results of the human evaluation (Table [4](#S4.T4 "Table 4 ‣ 4.1.1 Explainability
    Study ‣ 4.1 Automatic Evaluation ‣ 4 Evaluation ‣ Should We Fine-Tune or RAG?
    Evaluating Different Techniques to Adapt LLMs for Dialogue")), we report the percentage
    of positively judged responses (Contextualized, Appropriate, Valid) for Llama2[C] and
    Mistral[I] when considering different adaptation techniques (Fine-Tuning and In-Context
    Learning) and knowledge (No Knowledge, Retrieved Knowledge, and Gold Knowledge)
    across different dialogue types. As for ODDs, we report no results for the Retrieved
    and Gold Knowledge scenarios since no knowledge was used for this dialogue type.
    Additional results on Correctness are reported in §[A.4](#A1.SS4 "A.4 Human Evaluation
    ‣ Appendix A Appendix ‣ Limitations ‣ 5 Conclusion ‣ 4.3 Explaining Negative Human
    Judgments ‣ 4.2 Human Evaluation ‣ 4.1.1 Explainability Study ‣ 4.1 Automatic
    Evaluation ‣ 4 Evaluation ‣ Should We Fine-Tune or RAG? Evaluating Different Techniques
    to Adapt LLMs for Dialogue").
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 根据人工评估的结果（表 [4](#S4.T4 "表 4 ‣ 4.1.1 解释性研究 ‣ 4.1 自动评估 ‣ 4 评估 ‣ 我们应该微调还是 RAG？评估不同技术以适应
    LLMs 的对话")），我们报告了 Llama2[C] 和 Mistral[I] 在考虑不同适应技术（微调和上下文学习）和知识（无知识、检索知识和黄金知识）下的正面评估响应百分比（上下文化、适当、有效）。至于
    ODDs，我们报告了检索知识和黄金知识场景下没有结果，因为这一对话类型未使用任何知识。关于正确性的额外结果见 §[A.4](#A1.SS4 "A.4 人工评估
    ‣ 附录 A 附录 ‣ 局限性 ‣ 5 结论 ‣ 4.3 解释负面人工判断 ‣ 4.2 人工评估 ‣ 4.1.1 解释性研究 ‣ 4.1 自动评估 ‣ 4
    评估 ‣ 我们应该微调还是 RAG？评估不同技术以适应 LLMs 的对话")。
- en: Open-Domain Dialogue (ODD) Models fine-tuned for ODD tend to generate considerably
    less contextualized responses than models adapted using in-context learning. In
    particular, fine-tuning Llama2[C] reduces contextualization by 40%, while for
    Mistral[I] by 35%. Similarly, fine-tuning reduces their appropriateness by 30%
    compared to their in-context learning version. This contrasts with automatic evaluation
    (Table [2](#S3.T2 "Table 2 ‣ 3.2 Techniques ‣ 3 Experiments ‣ Should We Fine-Tune
    or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue")), where in-context
    learning obtained a higher perplexity (i.e. worse results) compared to fine-tuning.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 开放领域对话（ODD）为ODD微调的模型往往生成的上下文化响应显著低于使用上下文学习调整的模型。特别是，微调Llama2[C]会将上下文化减少40%，而Mistral[I]则减少35%。类似地，与其上下文学习版本相比，微调会将它们的适当性减少30%。这与自动评估（表格[2](#S3.T2
    "表格 2 ‣ 3.2 技术 ‣ 3 实验 ‣ 我们应该微调还是RAG？评估不同技术以适应LLMs进行对话")）相反，其中上下文学习的困惑度更高（即结果更差）与微调相比。
- en: Knowledge-Grounded Dialogue (KGD) Concerning KGD, the results are model-dependent.
    When considering Llama2[C], in-context learning provides, regardless of the knowledge,
    10% more contextualized responses compared to fine-tuning. On the other hand,
    fine-tuning Mistral[I] on Retrieved Knowledge leads to the highest contextualization
    (95%). However, using Gold instead of Retrieved Knowledge reduces the contextualization
    of the fine-tuned model by 15%. Furthermore, when considering the best models,
    Llama2[C] and Mistral[I] have a higher contextualization than the ground truth
    (10 to 15%), suggesting that models copy more from the dialogue history. Similarly
    to contextualization, adapting Llama2[C] with in-context learning and Gold Knowledge
    provides the highest percentage of appropriate responses (85%). Instead, fine-tuning
    (on Retrieved Knowledge) or adapting Mistral[I] with in-context learning (using
    No Knowledge) provides comparable appropriateness (85%). While according to automatic
    evaluation (Table [2](#S3.T2 "Table 2 ‣ 3.2 Techniques ‣ 3 Experiments ‣ Should
    We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue"))
    fine-tuning is always the best technique, human evaluation results show comparable
    appropriateness and contextualization for in-context learning and fine-tuning.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 知识驱动对话（KGD）关于KGD，结果依赖于模型。在考虑Llama2[C]时，与微调相比，上下文学习提供了10%更多的上下文化响应，无论知识是什么。另一方面，在检索知识上微调Mistral[I]会导致最高的上下文化（95%）。然而，使用Gold而非检索知识会将微调模型的上下文化减少15%。此外，在考虑最佳模型时，Llama2[C]和Mistral[I]的上下文化高于基准（10%到15%），这表明模型更多地从对话历史中复制内容。与上下文化类似，使用上下文学习和Gold知识对Llama2[C]进行调整可以提供最高比例的适当响应（85%）。相反，微调（在检索知识上）或使用上下文学习（无知识）的Mistral[I]提供了相当的适当性（85%）。虽然根据自动评估（表格[2](#S3.T2
    "表格 2 ‣ 3.2 技术 ‣ 3 实验 ‣ 我们应该微调还是RAG？评估不同技术以适应LLMs进行对话")），微调始终是最佳技术，但人工评估结果显示，上下文学习和微调在适当性和上下文化方面表现相当。
- en: Task-Oriented Dialogue (TOD) When adapting Llama2[C] and Mistral[I] to TOD,
    the results clearly show that fine-tuning is preferable over in-context learning.
    In particular, if we consider the best model for each technique, when fine-tuned
    Llama2[C] generates 20% more contextualized responses, while Mistral[I] generates
    15% more. Although fine-tuned models benefit from external knowledge, Retrieved
    and Gold Knowledge visibly reduce contextualization of in-context learning models
    (at most by 30% for Llama2[C] and 15% for Mistral[I]). Similar behavior can be
    observed for in-context learning in terms of appropriateness, where Gold Knowledge
    reduces Llama2[C] results by 15% and Mistral[I] by 10%. This is in line with the
    explainability study (Table [4.1](#S4.SS1 "4.1 Automatic Evaluation ‣ 4 Evaluation
    ‣ Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for
    Dialogue")), where models adapted with in-context learning have a lower contribution
    from the knowledge segment than their fine-tuned version. In general, if we consider
    the best models for each technique, fine-tuned models generate 25% more appropriate
    responses.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 任务导向对话（TOD）在将 Llama2[C] 和 Mistral[I] 适应 TOD 时，结果清楚地表明，微调优于上下文学习。特别是，如果考虑每种技术的最佳模型，微调后的
    Llama2[C] 生成的上下文化响应多出 20%，而 Mistral[I] 多出 15%。尽管微调模型受益于外部知识，但检索知识和黄金知识显著减少了上下文学习模型的上下文化程度（Llama2[C]
    最大减少 30%，Mistral[I] 最大减少 15%）。在适宜性方面，上下文学习的表现也类似，其中黄金知识将 Llama2[C] 的结果减少了 15%，Mistral[I]
    减少了 10%。这与解释性研究（表 [4.1](#S4.SS1 "4.1 Automatic Evaluation ‣ 4 Evaluation ‣ Should
    We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue")）一致，其中上下文学习调整的模型在知识部分的贡献低于其微调版本。总体而言，如果考虑每种技术的最佳模型，微调模型生成的适当响应多出
    25%。
- en: Question Answering (QA) In QA, results show improved Contextualization and Validity
    when including knowledge, with the best results obtained with gold knowledge.
    When considering the best model for each technique, in-context learning increases
    the percentage of contextualized responses by 5%. These results greatly differ
    from Table [2](#S3.T2 "Table 2 ‣ 3.2 Techniques ‣ 3 Experiments ‣ Should We Fine-Tune
    or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue") and show
    how unreliable automatic evaluation can be. Although models fine-tuned on No or
    Retrieved Knowledge obtain comparable or higher validity than in-context learning,
    adding Gold Knowledge to adapt Llama2[C] and Mistral[I] with in-context learning
    increases their validity respectively by 5% and 10%. Finally, even with Gold Knowledge,
    no model reaches the validity of the ground truth (90%).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 问答（QA）在 QA 中，包含知识时上下文化和有效性有所提高，其中黄金知识获得了最佳结果。考虑每种技术的最佳模型时，上下文学习将上下文化响应的百分比提高了
    5%。这些结果与表 [2](#S3.T2 "Table 2 ‣ 3.2 Techniques ‣ 3 Experiments ‣ Should We Fine-Tune
    or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue") 大相径庭，显示了自动评估的可靠性问题。尽管在没有或检索知识上微调的模型有效性可与上下文学习相媲美或更高，但将黄金知识添加到
    Llama2[C] 和 Mistral[I] 的上下文学习中，分别提高了它们的有效性 5% 和 10%。最后，即使使用黄金知识，没有模型能够达到真实数据的有效性（90%）。
- en: '![Refer to caption](img/b1a204d39fc1812466aad7f72b498c2f.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/b1a204d39fc1812466aad7f72b498c2f.png)'
- en: 'Figure 1: Percentage of LLM responses (y-axis) for each error type (Not Contextualized
    and Not Appropriate) and their explanation (Generic, Hallucinated, and Incoherent)
    (x-axis), for Llama2[C] and Mistral[I], adapted with In-Context Learning and Fine-Tuning
    in Open-Domain Dialogues (ODDs).'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：LLM 响应的百分比（y轴），按每种错误类型（未上下文化和不合适）及其解释（通用、虚假和不连贯）（x轴）分类，针对 Llama2[C] 和 Mistral[I]，经过开放领域对话（ODD）的上下文学习和微调调整。
- en: '![Refer to caption](img/986124aef3f4aa4fdf8df91d159d97f6.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/986124aef3f4aa4fdf8df91d159d97f6.png)'
- en: 'Figure 2: Percentage of LLM responses (y-axis) for each error type (Not Contextualized
    and Not Appropriate) and their explanation (Generic, Hallucinated, and Incoherent)
    (x-axis), for Llama2[C] and Mistral[I], adapted with In-Context Learning and Fine-Tuning
    in Knowledge-Grounded Dialogues (KGDs).'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：LLM 响应的百分比（y轴），按每种错误类型（未上下文化和不合适）及其解释（通用、虚假和不连贯）（x轴）分类，针对 Llama2[C] 和 Mistral[I]，经过知识驱动对话（KGD）的上下文学习和微调调整。
- en: 4.3 Explaining Negative Human Judgments
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 解释负面人工判断
- en: 'To better understand the shortcomings of the techniques, we investigate the
    motivations provided by the annotators to support their negative judgments. For
    each technique, we considered the scenario with gold external knowledge as the
    theoretical upper bound (except for ODDs where no external knowledge is required).
    Following the original protocol, we consider two explanations for Not Contextualized
    responses:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解技术的不足之处，我们调查了注释者提供的动机，以支持他们的负面评判。对于每种技术，我们考虑了带有金标准外部知识的场景作为理论上的上限（ODD除外，因为ODD不需要外部知识）。根据原始协议，我们考虑了两种“不符合上下文”回应的解释：
- en: •
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Generic: the response is generic or does not contain any reference to the context
    (implicit or explicit);'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通用性：回应内容是通用的或不包含任何对上下文的引用（隐式或显式）；
- en: •
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Hallucinated: the response is inconsistent with the information contained in
    the context.'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 虚假：回应与上下文中的信息不一致。
- en: 'Regarding Not Appropriate responses, the protocol has proposed one explanation
    (as an alternative to a free-form explanation):'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 关于“不适当”回应，协议提出了一种解释（作为自由形式解释的替代）：
- en: •
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Incoherent: the response is not coherent with the context.'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 不连贯：回应与上下文不连贯。
- en: 'To better characterize errors in TODs, we propose an additional explanation:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地表征TOD中的错误，我们提出了一个额外的解释：
- en: •
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Unhelpful: the response candidate is not helpful to fulfil the user’s request.'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 无用：回应候选项对满足用户的请求没有帮助。
- en: In this section, we report the percentage of negatively judged responses with
    a certain explanation out of all the responses.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们报告了带有特定解释的负面评判回应在所有回应中的百分比。
- en: Open Domain Dialogue (ODD) In ODDs (Figure [1](#S4.F1 "Figure 1 ‣ 4.2 Human
    Evaluation ‣ 4.1.1 Explainability Study ‣ 4.1 Automatic Evaluation ‣ 4 Evaluation
    ‣ Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for
    Dialogue")), fine-tuning causes the generation of few generic responses, while
    for in-context learning none are present. Moreover, fine-tuned models generate
    around 30% more hallucinated responses, and around 25% more incoherent responses.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 开放领域对话（ODD） 在ODD中（见图[1](#S4.F1 "图 1 ‣ 4.2 人工评估 ‣ 4.1.1 可解释性研究 ‣ 4.1 自动评估 ‣ 4
    评估 ‣ 我们是否应该进行微调或RAG？评估不同技术以适应对话LLMs")），微调导致生成的通用回应较少，而在上下文学习中则没有出现。此外，微调模型生成的虚假回应多出约30%，而不连贯的回应多出约25%。
- en: Knowledge-Grounded Dialogue (KGD) In KGDs (Figure [2](#S4.F2 "Figure 2 ‣ 4.2
    Human Evaluation ‣ 4.1.1 Explainability Study ‣ 4.1 Automatic Evaluation ‣ 4 Evaluation
    ‣ Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for
    Dialogue")), fine-tuning causes the generation of a few generic responses. Regarding
    hallucinated responses, fine-tuning slightly reduces them for Llama2[C] but increases
    them for Mistral[I]. Differently, fine-tuning slightly increases the incoherent
    responses for Llama2[C], but has no impact for Mistral[I].
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 知识基础对话（KGD） 在KGD中（见图[2](#S4.F2 "图 2 ‣ 4.2 人工评估 ‣ 4.1.1 可解释性研究 ‣ 4.1 自动评估 ‣ 4
    评估 ‣ 我们是否应该进行微调或RAG？评估不同技术以适应对话LLMs")），微调导致生成了一些通用回应。关于虚假回应，微调稍微减少了Llama2[C]的虚假回应，但增加了Mistral[I]的虚假回应。不同的是，微调稍微增加了Llama2[C]的不连贯回应，但对Mistral[I]没有影响。
- en: Task-Oriented Dialogue (TOD) For the TOD type (Figure [3](#S4.F3 "Figure 3 ‣
    4.3 Explaining Negative Human Judgments ‣ 4.2 Human Evaluation ‣ 4.1.1 Explainability
    Study ‣ 4.1 Automatic Evaluation ‣ 4 Evaluation ‣ Should We Fine-Tune or RAG?
    Evaluating Different Techniques to Adapt LLMs for Dialogue")), while for Mistral[I] fine-tuning
    has no impact on generic responses, it reduces generic responses by 15% for Llama2[C].
    For both models, fine-tuning reduces the number of hallucinated responses by 10%,
    and improves coherence by around 20% both models. It further reduces unhelpful
    responses by 10% for Llama2[C] .
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 任务导向对话（TOD） 对于TOD类型（见图[3](#S4.F3 "图 3 ‣ 4.3 解释负面人工评判 ‣ 4.2 人工评估 ‣ 4.1.1 可解释性研究
    ‣ 4.1 自动评估 ‣ 4 评估 ‣ 我们是否应该进行微调或RAG？评估不同技术以适应对话LLMs")），虽然对于Mistral[I]微调对通用回应没有影响，但对于Llama2[C]却减少了15%。对于这两种模型，微调将虚假回应的数量减少了10%，并将连贯性提高了约20%。同时，微调进一步减少了Llama2[C]的无用回应10%。
- en: '![Refer to caption](img/5d14d2d4f8d8ae38436aac1979616a98.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/5d14d2d4f8d8ae38436aac1979616a98.png)'
- en: 'Figure 3: Percentage of LLM responses (y-axis) for each error type (Not Contextualized
    and Not Appropriate) and their explanation (Generic, Hallucinated, Incoherent,
    and Unhelpful) (x-axis), for Llama2[C] and Mistral[I], adapted with In-Context
    Learning and Fine-Tuning in Task-Oriented Dialogues (TODs).'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：每种错误类型（未上下文化和不适当）及其解释（一般、虚构、不连贯和无帮助）的 LLM 响应百分比（y 轴），针对 Llama2[C] 和 Mistral[I]，结合了上下文学习和任务导向对话（TODs）中的微调。
- en: Question Answering (QA) For the QA type (Figure [4](#S4.F4 "Figure 4 ‣ 4.3 Explaining
    Negative Human Judgments ‣ 4.2 Human Evaluation ‣ 4.1.1 Explainability Study ‣
    4.1 Automatic Evaluation ‣ 4 Evaluation ‣ Should We Fine-Tune or RAG? Evaluating
    Different Techniques to Adapt LLMs for Dialogue")), fine-tuned models generate
    more generic responses than models adapted with in-context learning. Instead,
    fine-tuning results in fewer hallucinated responses for Llama2[C], although it
    has no effect for Mistral[I].
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 问答（QA）对于 QA 类型（图 [4](#S4.F4 "图 4 ‣ 4.3 解释负面人工判断 ‣ 4.2 人工评估 ‣ 4.1.1 可解释性研究 ‣
    4.1 自动评估 ‣ 4 评估 ‣ 我们是否应进行微调或 RAG？评估不同的技术以适应对话 LLMs")），微调模型生成的响应比结合上下文学习的模型更为一般。然而，微调对于
    Llama2[C] 结果较少的虚构响应，尽管对 Mistral[I] 没有影响。
- en: '![Refer to caption](img/beab1ad1871a3e90d8ec984926ec6630.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/beab1ad1871a3e90d8ec984926ec6630.png)'
- en: 'Figure 4: Percentage of LLM responses (y-axis) for each error type (Not Contextualized)
    and their explanation (Generic, and Hallucinated) (x-axis), for Llama2[C] and
    Mistral[I], adapted with In-Context Learning and Fine-Tuning in Question Answering
    (QA).'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：每种错误类型（未上下文化）及其解释（一般和虚构）的 LLM 响应百分比（y 轴），针对 Llama2[C] 和 Mistral[I]，结合了上下文学习和问答（QA）中的微调。
- en: 5 Conclusion
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论
- en: We have conducted an extensive analysis on the efficacy of fine-tuning and in-context
    learning to adapt LLMs for different dialogue types. We have experimented with
    Retrieval-Augmented Generation (RAG) and gold knowledge to assess the impact of
    grounding the response generation on external knowledge. We have studied the models’
    performance using consistent criteria in both automatic (perplexity, explainability
    studies) and human evaluations.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对微调和上下文学习在适应不同对话类型的 LLMs 的有效性进行了广泛分析。我们实验了检索增强生成（RAG）和黄金知识，以评估将响应生成基础置于外部知识上的影响。我们使用一致的标准在自动（困惑度、可解释性研究）和人工评估中研究了模型的表现。
- en: Our study highlights the limitation of currently available automatic metrics
    and the necessity of conducting human evaluations to advance human-machine dialogue
    research, as the evaluations by human judges correlate poorly with automatic metrics.
    Furthermore, conducted human evaluations indicate that there is no universal best-technique
    for adapting LLMs to a dialogue type and the performance of each technique depends
    on the base LLM as well as the dialogue type. In addition, the correct incorporation
    of external knowledge depends on various factors such as the retriever accuracy,
    the representation of the knowledge, and the presence of noise (non-gold) documents,
    as it can be the least contributing element in the input vector according to explainability
    studies.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究突出了目前自动度量指标的局限性以及进行人工评估的必要性，以推进人机对话研究，因为人工评估与自动度量指标的相关性较差。此外，进行的人工评估表明，没有一种通用的最佳技术来适应对话类型，每种技术的表现依赖于基础
    LLM 及对话类型。此外，外部知识的正确纳入依赖于各种因素，如检索器准确性、知识表示以及噪声（非黄金）文档，因为根据可解释性研究，它可能在输入向量中贡献最小。
- en: Limitations
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 限制
- en: Due to the limited computational resources, we could experiment with 7B models,
    hampering us in validating our findings on larger models. Furthermore, the human
    evaluation results also strongly depend on the set of hired annotators. Therefore,
    the reproducibility of the reported results is subject to the variability of the
    selection of crowd workers.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 由于计算资源有限，我们只能对 7B 模型进行实验，这限制了我们在更大模型上验证发现的能力。此外，人工评估结果也在很大程度上依赖于所聘请的标注员。因此，报告结果的可重复性受到众包工人选择变异性的影响。
- en: References
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Baumgartner et al. (2020) Jason Baumgartner, Savvas Zannettou, Brian Keegan,
    Megan Squire, and Jeremy Blackburn. 2020. [The pushshift reddit dataset](https://doi.org/10.1609/icwsm.v14i1.7347).
    *Proceedings of the International AAAI Conference on Web and Social Media*, 14(1):830–839.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Baumgartner 等 (2020) Jason Baumgartner, Savvas Zannettou, Brian Keegan, Megan
    Squire, 和 Jeremy Blackburn. 2020. [推移 Reddit 数据集](https://doi.org/10.1609/icwsm.v14i1.7347).
    *国际 AAAI 网络与社交媒体会议论文集*，14(1):830–839。
- en: Borgeaud et al. (2022) Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor
    Cai, Eliza Rutherford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste
    Lespiau, Bogdan Damoc, Aidan Clark, et al. 2022. Improving language models by
    retrieving from trillions of tokens. In *International conference on machine learning*,
    pages 2206–2240\. PMLR.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Borgeaud 等 (2022) Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor
    Cai, Eliza Rutherford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste
    Lespiau, Bogdan Damoc, Aidan Clark 等. 2022. 通过从万亿令牌中检索来改进语言模型。载于 *国际机器学习会议*，第
    2206–2240 页。PMLR。
- en: Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D
    Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
    Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,
    Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris
    Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack
    Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario
    Amodei. 2020. [Language models are few-shot learners](https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf).
    In *Advances in Neural Information Processing Systems*, volume 33, pages 1877–1901\.
    Curran Associates, Inc.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown 等 (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared
    D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
    Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,
    Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris
    Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack
    Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, 和 Dario
    Amodei. 2020. [语言模型是少样本学习者](https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf).
    载于 *神经信息处理系统进展*，第 33 卷，第 1877–1901 页。Curran Associates, Inc.
- en: 'Chen et al. (2023) Qinyu Chen, Wenhao Wu, and Sujian Li. 2023. [Exploring in-context
    learning for knowledge grounded dialog generation](https://doi.org/10.18653/v1/2023.findings-emnlp.675).
    In *Findings of the Association for Computational Linguistics: EMNLP 2023*, pages
    10071–10081, Singapore. Association for Computational Linguistics.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 (2023) Qinyu Chen, Wenhao Wu, 和 Sujian Li. 2023. [探索上下文学习以生成基于知识的对话](https://doi.org/10.18653/v1/2023.findings-emnlp.675).
    载于 *计算语言学协会会议论文集：EMNLP 2023*，第 10071–10081 页，新加坡。计算语言学协会。
- en: 'Cho et al. (2023) Sukmin Cho, Jeongyeon Seo, Soyeong Jeong, and Jong Park.
    2023. [Improving zero-shot reader by reducing distractions from irrelevant documents
    in open-domain question answering](https://doi.org/10.18653/v1/2023.findings-emnlp.207).
    In *Findings of the Association for Computational Linguistics: EMNLP 2023*, pages
    3145–3157, Singapore. Association for Computational Linguistics.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cho 等 (2023) Sukmin Cho, Jeongyeon Seo, Soyeong Jeong, 和 Jong Park. 2023. [通过减少来自无关文档的干扰来改进零样本阅读器](https://doi.org/10.18653/v1/2023.findings-emnlp.207).
    载于 *计算语言学协会会议论文集：EMNLP 2023*，第 3145–3157 页，新加坡。计算语言学协会。
- en: 'Dinan et al. (2019) Emily Dinan, Stephen Roller, Kurt Shuster, Angela Fan,
    Michael Auli, and Jason Weston. 2019. Wizard of Wikipedia: Knowledge-powered conversational
    agents. In *Proceedings of the International Conference on Learning Representations
    (ICLR)*.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dinan 等 (2019) Emily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael
    Auli, 和 Jason Weston. 2019. 维基百科的魔法师：知识驱动的对话代理。载于 *国际学习表征会议 (ICLR) 论文集*。
- en: 'Ding et al. (2024) Zeyuan Ding, Zhihao Yang, Yinbo Qiao, and Hongfei Lin. 2024.
    [Kmc-tod: Structure knowledge enhanced multi-copy network for task-oriented dialogue
    system](https://doi.org/https://doi.org/10.1016/j.knosys.2024.111662). *Knowledge-Based
    Systems*, 293:111662.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ding 等 (2024) Zeyuan Ding, Zhihao Yang, Yinbo Qiao, 和 Hongfei Lin. 2024. [Kmc-tod：结构化知识增强的多拷贝网络用于任务导向对话系统](https://doi.org/https://doi.org/10.1016/j.knosys.2024.111662).
    *知识基系统*，293:111662。
- en: 'Eric et al. (2020) Mihail Eric, Rahul Goel, Shachi Paul, Abhishek Sethi, Sanchit
    Agarwal, Shuyang Gao, Adarsh Kumar, Anuj Goyal, Peter Ku, and Dilek Hakkani-Tur.
    2020. [MultiWOZ 2.1: A consolidated multi-domain dialogue dataset with state corrections
    and state tracking baselines](https://aclanthology.org/2020.lrec-1.53). In *Proceedings
    of the Twelfth Language Resources and Evaluation Conference*, pages 422–428, Marseille,
    France. European Language Resources Association.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Eric 等（2020）Mihail Eric, Rahul Goel, Shachi Paul, Abhishek Sethi, Sanchit Agarwal,
    Shuyang Gao, Adarsh Kumar, Anuj Goyal, Peter Ku, 和 Dilek Hakkani-Tur。2020。 [MultiWOZ
    2.1: A consolidated multi-domain dialogue dataset with state corrections and state
    tracking baselines](https://aclanthology.org/2020.lrec-1.53)。在 *Proceedings of
    the Twelfth Language Resources and Evaluation Conference*，第 422–428 页，法国马赛。欧洲语言资源协会。'
- en: 'Feng et al. (2020) Song Feng, Hui Wan, Chulaka Gunasekara, Siva Patel, Sachindra
    Joshi, and Luis Lastras. 2020. [doc2dial: A goal-oriented document-grounded dialogue
    dataset](https://doi.org/10.18653/v1/2020.emnlp-main.652). In *Proceedings of
    the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)*,
    pages 8118–8128, Online. Association for Computational Linguistics.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Feng 等（2020）Song Feng, Hui Wan, Chulaka Gunasekara, Siva Patel, Sachindra Joshi,
    和 Luis Lastras。2020。 [doc2dial: A goal-oriented document-grounded dialogue dataset](https://doi.org/10.18653/v1/2020.emnlp-main.652)。在
    *Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing
    (EMNLP)*，第 8118–8128 页，在线。计算语言学协会。'
- en: Fleiss (1971) Joseph L Fleiss. 1971. Measuring nominal scale agreement among
    many raters. *Psychological bulletin*, 76(5):378.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fleiss（1971）Joseph L Fleiss。1971。多评估者间名义尺度一致性的测量。 *心理学公报*，76（5）：378。
- en: 'Godfrey et al. (1992) J.J. Godfrey, E.C. Holliman, and J. McDaniel. 1992. [Switchboard:
    telephone speech corpus for research and development](https://doi.org/10.1109/ICASSP.1992.225858).
    In *[Proceedings] ICASSP-92: 1992 IEEE International Conference on Acoustics,
    Speech, and Signal Processing*, volume 1, pages 517–520 vol.1.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Godfrey 等（1992）J.J. Godfrey, E.C. Holliman, 和 J. McDaniel。1992。 [Switchboard:
    telephone speech corpus for research and development](https://doi.org/10.1109/ICASSP.1992.225858)。在
    *[Proceedings] ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech,
    and Signal Processing*，第 517–520 页，第 1 卷。'
- en: 'Gopalakrishnan et al. (2019) Karthik Gopalakrishnan, Behnam Hedayatnia, Qinlang
    Chen, Anna Gottardi, Sanjeev Kwatra, Anu Venkatesh, Raefer Gabriel, and Dilek
    Hakkani-Tür. 2019. [Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations](https://doi.org/10.21437/Interspeech.2019-3079).
    In *Proc. Interspeech 2019*, pages 1891–1895.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gopalakrishnan 等（2019）Karthik Gopalakrishnan, Behnam Hedayatnia, Qinlang Chen,
    Anna Gottardi, Sanjeev Kwatra, Anu Venkatesh, Raefer Gabriel, 和 Dilek Hakkani-Tür。2019。
    [Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations](https://doi.org/10.21437/Interspeech.2019-3079)。在
    *Proc. Interspeech 2019*，第 1891–1895 页。'
- en: 'Han et al. (2023) Gunsoo Han, Daejin Jo, Daniel Nam, Eunseop Yoon, Taehwan
    Kwon, Seungeun Rho, Kyoung-Woon On, Chang Yoo, and Sungwoong Kim. 2023. [Efficient
    latent variable modeling for knowledge-grounded dialogue generation](https://doi.org/10.18653/v1/2023.findings-emnlp.177).
    In *Findings of the Association for Computational Linguistics: EMNLP 2023*, pages
    2683–2702, Singapore. Association for Computational Linguistics.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Han 等（2023）Gunsoo Han, Daejin Jo, Daniel Nam, Eunseop Yoon, Taehwan Kwon, Seungeun
    Rho, Kyoung-Woon On, Chang Yoo, 和 Sungwoong Kim。2023。 [Efficient latent variable
    modeling for knowledge-grounded dialogue generation](https://doi.org/10.18653/v1/2023.findings-emnlp.177)。在
    *Findings of the Association for Computational Linguistics: EMNLP 2023*，第 2683–2702
    页，新加坡。计算语言学协会。'
- en: He et al. (2024) Huang He, Hua Lu, Siqi Bao, Fan Wang, Hua Wu, Zheng-Yu Niu,
    and Haifeng Wang. 2024. [Learning to select external knowledge with multi-scale
    negative sampling](https://doi.org/10.1109/TASLP.2023.3301222). *IEEE/ACM Transactions
    on Audio, Speech, and Language Processing*, 32:714–720.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He 等（2024）Huang He, Hua Lu, Siqi Bao, Fan Wang, Hua Wu, Zheng-Yu Niu, 和 Haifeng
    Wang。2024。 [Learning to select external knowledge with multi-scale negative sampling](https://doi.org/10.1109/TASLP.2023.3301222)。
    *IEEE/ACM Transactions on Audio, Speech, and Language Processing*，32：714–720。
- en: Hedayatnia et al. (2020) Behnam Hedayatnia, Karthik Gopalakrishnan, Seokhwan
    Kim, Yang Liu, Mihail Eric, and Dilek Hakkani-Tur. 2020. [Policy-driven neural
    response generation for knowledge-grounded dialog systems](https://doi.org/10.18653/v1/2020.inlg-1.46).
    In *Proceedings of the 13th International Conference on Natural Language Generation*,
    pages 412–421, Dublin, Ireland. Association for Computational Linguistics.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hedayatnia 等（2020）Behnam Hedayatnia, Karthik Gopalakrishnan, Seokhwan Kim, Yang
    Liu, Mihail Eric, 和 Dilek Hakkani-Tur。2020。 [Policy-driven neural response generation
    for knowledge-grounded dialog systems](https://doi.org/10.18653/v1/2020.inlg-1.46)。在
    *Proceedings of the 13th International Conference on Natural Language Generation*，第
    412–421 页，爱尔兰都柏林。计算语言学协会。
- en: Hosseini-Asl et al. (2020a) Ehsan Hosseini-Asl, Bryan McCann, Chien-Sheng Wu,
    Semih Yavuz, and Richard Socher. 2020a. [A simple language model for task-oriented
    dialogue](https://proceedings.neurips.cc/paper_files/paper/2020/file/e946209592563be0f01c844ab2170f0c-Paper.pdf).
    In *Advances in Neural Information Processing Systems*, volume 33, pages 20179–20191\.
    Curran Associates, Inc.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hosseini-Asl 等（2020a）Ehsan Hosseini-Asl, Bryan McCann, Chien-Sheng Wu, Semih
    Yavuz 和 Richard Socher。2020a。[用于任务导向对话的简单语言模型](https://proceedings.neurips.cc/paper_files/paper/2020/file/e946209592563be0f01c844ab2170f0c-Paper.pdf)。在
    *神经信息处理系统进展*，第 33 卷，第 20179–20191 页。Curran Associates, Inc.
- en: Hosseini-Asl et al. (2020b) Ehsan Hosseini-Asl, Bryan McCann, Chien-Sheng Wu,
    Semih Yavuz, and Richard Socher. 2020b. [A simple language model for task-oriented
    dialogue](https://proceedings.neurips.cc/paper_files/paper/2020/file/e946209592563be0f01c844ab2170f0c-Paper.pdf).
    In *Advances in Neural Information Processing Systems*, volume 33, pages 20179–20191\.
    Curran Associates, Inc.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hosseini-Asl 等（2020b）Ehsan Hosseini-Asl, Bryan McCann, Chien-Sheng Wu, Semih
    Yavuz 和 Richard Socher。2020b。[用于任务导向对话的简单语言模型](https://proceedings.neurips.cc/paper_files/paper/2020/file/e946209592563be0f01c844ab2170f0c-Paper.pdf)。在
    *神经信息处理系统进展*，第 33 卷，第 20179–20191 页。Curran Associates, Inc.
- en: 'Hu et al. (2021) Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu,
    Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. Lora: Low-rank adaptation
    of large language models. *arXiv preprint arXiv:2106.09685*.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu 等（2021）Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi
    Li, Shean Wang, Lu Wang 和 Weizhu Chen。2021。Lora：大型语言模型的低秩适配。*arXiv 预印本 arXiv:2106.09685*。
- en: Huang et al. (2023) Qiushi Huang, Shuai Fu, Xubo Liu, Wenwu Wang, Tom Ko, Yu Zhang,
    and Lilian Tang. 2023. [Learning retrieval augmentation for personalized dialogue
    generation](https://doi.org/10.18653/v1/2023.emnlp-main.154). In *Proceedings
    of the 2023 Conference on Empirical Methods in Natural Language Processing*, pages
    2523–2540, Singapore. Association for Computational Linguistics.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等（2023）Qiushi Huang, Shuai Fu, Xubo Liu, Wenwu Wang, Tom Ko, Yu Zhang
    和 Lilian Tang。2023。[个性化对话生成的检索增强学习](https://doi.org/10.18653/v1/2023.emnlp-main.154)。在
    *2023年自然语言处理实证方法会议论文集*，第 2523–2540 页，新加坡。计算语言学协会。
- en: 'Izacard and Grave (2021) Gautier Izacard and Edouard Grave. 2021. [Leveraging
    passage retrieval with generative models for open domain question answering](https://doi.org/10.18653/v1/2021.eacl-main.74).
    In *Proceedings of the 16th Conference of the European Chapter of the Association
    for Computational Linguistics: Main Volume*, pages 874–880, Online. Association
    for Computational Linguistics.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Izacard 和 Grave（2021）Gautier Izacard 和 Edouard Grave。2021。[利用生成模型进行段落检索以实现开放域问答](https://doi.org/10.18653/v1/2021.eacl-main.74)。在
    *第 16 届欧洲计算语言学协会会议：主要卷*，第 874–880 页，在线。计算语言学协会。
- en: Jiang et al. (2023) Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch,
    Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna
    Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux,
    Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and
    William El Sayed. 2023. [Mistral 7b](http://arxiv.org/abs/2310.06825).
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang 等（2023）Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford,
    Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel,
    Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux, Pierre
    Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix 和 William
    El Sayed。2023。[Mistral 7b](http://arxiv.org/abs/2310.06825)。
- en: Karpukhin et al. (2020) Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick
    Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020. [Dense passage
    retrieval for open-domain question answering](https://doi.org/10.18653/v1/2020.emnlp-main.550).
    In *Proceedings of the 2020 Conference on Empirical Methods in Natural Language
    Processing (EMNLP)*, pages 6769–6781, Online. Association for Computational Linguistics.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Karpukhin 等（2020）Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis,
    Ledell Wu, Sergey Edunov, Danqi Chen 和 Wen-tau Yih。2020。[用于开放域问答的密集段落检索](https://doi.org/10.18653/v1/2020.emnlp-main.550)。在
    *2020年自然语言处理实证方法会议（EMNLP）论文集*，第 6769–6781 页，在线。计算语言学协会。
- en: 'Kasahara et al. (2022) Tomohito Kasahara, Daisuke Kawahara, Nguyen Tung, Shengzhe
    Li, Kenta Shinzato, and Toshinori Sato. 2022. [Building a personalized dialogue
    system with prompt-tuning](https://doi.org/10.18653/v1/2022.naacl-srw.13). In
    *Proceedings of the 2022 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies: Student Research Workshop*,
    pages 96–105, Hybrid: Seattle, Washington + Online. Association for Computational
    Linguistics.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kasahara et al. (2022) Tomohito Kasahara, Daisuke Kawahara, Nguyen Tung, Shengzhe
    Li, Kenta Shinzato, 和 Toshinori Sato. 2022. [构建个性化对话系统与提示调优](https://doi.org/10.18653/v1/2022.naacl-srw.13).
    发表在 *2022 年北美计算语言学协会会议：人类语言技术：学生研究研讨会论文集*，第 96–105 页，混合模式：华盛顿州西雅图 + 在线。计算语言学协会。
- en: 'Kim et al. (2020) Seokhwan Kim, Mihail Eric, Karthik Gopalakrishnan, Behnam
    Hedayatnia, Yang Liu, and Dilek Hakkani-Tur. 2020. [Beyond domain APIs: Task-oriented
    conversational modeling with unstructured knowledge access](https://doi.org/10.18653/v1/2020.sigdial-1.35).
    In *Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse
    and Dialogue*, pages 278–289, 1st virtual meeting. Association for Computational
    Linguistics.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim et al. (2020) Seokhwan Kim, Mihail Eric, Karthik Gopalakrishnan, Behnam
    Hedayatnia, Yang Liu, 和 Dilek Hakkani-Tur. 2020. [超越领域 API：具有非结构化知识访问的任务导向对话建模](https://doi.org/10.18653/v1/2020.sigdial-1.35).
    发表在 *第 21 届话语与对话特殊兴趣小组年会论文集*，第 278–289 页，第 1 次虚拟会议。计算语言学协会。
- en: 'Kim et al. (2021) Seokhwan Kim, Yang Liu, Di Jin, Alexandros Papangelis, Karthik
    Gopalakrishnan, Behnam Hedayatnia, and Dilek Hakkani-Tür. 2021. [“how robust r
    u?”: Evaluating task-oriented dialogue systems on spoken conversations](https://doi.org/10.1109/ASRU51503.2021.9688274).
    In *2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)*,
    pages 1147–1154.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim et al. (2021) Seokhwan Kim, Yang Liu, Di Jin, Alexandros Papangelis, Karthik
    Gopalakrishnan, Behnam Hedayatnia, 和 Dilek Hakkani-Tür. 2021. [“你有多强大？”：评估任务导向对话系统在口语对话中的表现](https://doi.org/10.1109/ASRU51503.2021.9688274).
    发表在 *2021 IEEE 自动语音识别与理解研讨会 (ASRU)*，第 1147–1154 页。
- en: Kočiský et al. (2018) Tomáš Kočiský, Jonathan Schwarz, Phil Blunsom, Chris Dyer,
    Karl Moritz Hermann, Gábor Melis, and Edward Grefenstette. 2018. [The NarrativeQA
    reading comprehension challenge](https://doi.org/10.1162/tacl_a_00023). *Transactions
    of the Association for Computational Linguistics*, 6:317–328.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kočiský et al. (2018) Tomáš Kočiský, Jonathan Schwarz, Phil Blunsom, Chris Dyer,
    Karl Moritz Hermann, Gábor Melis, 和 Edward Grefenstette. 2018. [NarrativeQA 阅读理解挑战](https://doi.org/10.1162/tacl_a_00023).
    *计算语言学协会会刊*，6:317–328。
- en: 'Komeili et al. (2022) Mojtaba Komeili, Kurt Shuster, and Jason Weston. 2022.
    [Internet-augmented dialogue generation](https://doi.org/10.18653/v1/2022.acl-long.579).
    In *Proceedings of the 60th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)*, pages 8460–8478, Dublin, Ireland. Association
    for Computational Linguistics.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Komeili et al. (2022) Mojtaba Komeili, Kurt Shuster, 和 Jason Weston. 2022. [互联网增强对话生成](https://doi.org/10.18653/v1/2022.acl-long.579).
    发表在 *第 60 届计算语言学协会年会（第 1 卷：长篇论文）论文集*，第 8460–8478 页，爱尔兰都柏林。计算语言学协会。
- en: 'Kulhánek et al. (2021) Jonáš Kulhánek, Vojtěch Hudeček, Tomáš Nekvinda, and
    Ondřej Dušek. 2021. [AuGPT: Auxiliary tasks and data augmentation for end-to-end
    dialogue with pre-trained language models](https://doi.org/10.18653/v1/2021.nlp4convai-1.19).
    In *Proceedings of the 3rd Workshop on Natural Language Processing for Conversational
    AI*, pages 198–210, Online. Association for Computational Linguistics.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kulhánek et al. (2021) Jonáš Kulhánek, Vojtěch Hudeček, Tomáš Nekvinda, 和 Ondřej
    Dušek. 2021. [AuGPT：用于端到端对话的辅助任务和数据增强与预训练语言模型](https://doi.org/10.18653/v1/2021.nlp4convai-1.19).
    发表在 *第 3 届自然语言处理对话 AI 研讨会论文集*，第 198–210 页，在线。计算语言学协会。
- en: 'Kwiatkowski et al. (2019) Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield,
    Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin,
    Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei
    Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. 2019. [Natural
    questions: A benchmark for question answering research](https://doi.org/10.1162/tacl_a_00276).
    *Transactions of the Association for Computational Linguistics*, 7:452–466.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kwiatkowski et al. (2019) Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield,
    Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin,
    Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei
    Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, 和 Slav Petrov. 2019. [自然问答：一个问答研究的基准](https://doi.org/10.1162/tacl_a_00276).
    *计算语言学协会会刊*，7:452–466。
- en: Lee et al. (2019) Kenton Lee, Ming-Wei Chang, and Kristina Toutanova. 2019.
    [Latent retrieval for weakly supervised open domain question answering](https://doi.org/10.18653/v1/P19-1612).
    In *Proceedings of the 57th Annual Meeting of the Association for Computational
    Linguistics*, pages 6086–6096, Florence, Italy. Association for Computational
    Linguistics.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee et al. (2019) Kenton Lee, Ming-Wei Chang 和 Kristina Toutanova。2019. [潜在检索用于弱监督开放域问答](https://doi.org/10.18653/v1/P19-1612)。在*第57届计算语言学协会年会论文集*中，页6086–6096，意大利佛罗伦萨。计算语言学协会。
- en: Levine et al. (2022) Yoav Levine, Ori Ram, Daniel Jannai, Barak Lenz, Shai Shalev-Shwartz,
    Amnon Shashua, Kevin Leyton-Brown, and Yoav Shoham. 2022. [Huge frozen language
    models as readers for open-domain question answering](https://openreview.net/forum?id=z3Bxu8xNJaF).
    In *ICML 2022 Workshop on Knowledge Retrieval and Language Models*.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Levine et al. (2022) Yoav Levine, Ori Ram, Daniel Jannai, Barak Lenz, Shai Shalev-Shwartz,
    Amnon Shashua, Kevin Leyton-Brown 和 Yoav Shoham。2022. [巨型冻结语言模型作为开放域问答的阅读器](https://openreview.net/forum?id=z3Bxu8xNJaF)。在*ICML
    2022 知识检索与语言模型研讨会*。
- en: Lewis et al. (2020) Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni,
    Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim
    Rocktäschel, Sebastian Riedel, and Douwe Kiela. 2020. [Retrieval-augmented generation
    for knowledge-intensive nlp tasks](https://proceedings.neurips.cc/paper_files/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf).
    In *Advances in Neural Information Processing Systems*, volume 33, pages 9459–9474\.
    Curran Associates, Inc.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lewis et al. (2020) Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni,
    Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim
    Rocktäschel, Sebastian Riedel 和 Douwe Kiela。2020. [检索增强生成用于知识密集型自然语言处理任务](https://proceedings.neurips.cc/paper_files/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf)。在*神经信息处理系统进展*，卷33，页9459–9474。Curran
    Associates, Inc.
- en: 'Li et al. (2017) Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang Cao, and
    Shuzi Niu. 2017. [DailyDialog: A manually labelled multi-turn dialogue dataset](https://aclanthology.org/I17-1099).
    In *Proceedings of the Eighth International Joint Conference on Natural Language
    Processing (Volume 1: Long Papers)*, pages 986–995, Taipei, Taiwan. Asian Federation
    of Natural Language Processing.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li et al. (2017) Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang Cao 和 Shuzi
    Niu。2017. [DailyDialog: 一个手动标注的多轮对话数据集](https://aclanthology.org/I17-1099)。在*第八届国际自然语言处理联合会议论文集（第1卷：长篇论文）*中，页986–995，台湾台北。亚洲自然语言处理联合会。'
- en: 'Lin (2004) Chin-Yew Lin. 2004. [ROUGE: A package for automatic evaluation of
    summaries](https://aclanthology.org/W04-1013). In *Text Summarization Branches
    Out*, pages 74–81, Barcelona, Spain. Association for Computational Linguistics.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lin (2004) Chin-Yew Lin. 2004. [ROUGE: 自动评估摘要的工具包](https://aclanthology.org/W04-1013)。在*文本摘要的新发展*中，页74–81，西班牙巴塞罗那。计算语言学协会。'
- en: 'Lin and Chen (2023) Yen-Ting Lin and Yun-Nung Chen. 2023. [LLM-eval: Unified
    multi-dimensional automatic evaluation for open-domain conversations with large
    language models](https://doi.org/10.18653/v1/2023.nlp4convai-1.5). In *Proceedings
    of the 5th Workshop on NLP for Conversational AI (NLP4ConvAI 2023)*, pages 47–58,
    Toronto, Canada. Association for Computational Linguistics.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lin and Chen (2023) Yen-Ting Lin 和 Yun-Nung Chen。2023. [LLM-eval: 统一的多维度自动评估用于大语言模型的开放域对话](https://doi.org/10.18653/v1/2023.nlp4convai-1.5)。在*第5届对话人工智能自然语言处理研讨会（NLP4ConvAI
    2023）*中，页47–58，加拿大多伦多。计算语言学协会。'
- en: Loshchilov and Hutter (2017) Ilya Loshchilov and Frank Hutter. 2017. Decoupled
    weight decay regularization. *arXiv preprint arXiv:1711.05101*.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Loshchilov and Hutter (2017) Ilya Loshchilov 和 Frank Hutter。2017. 分离权重衰减正则化。*arXiv
    预印本 arXiv:1711.05101*。
- en: 'Meade et al. (2023) Nicholas Meade, Spandana Gella, Devamanyu Hazarika, Prakhar
    Gupta, Di Jin, Siva Reddy, Yang Liu, and Dilek Hakkani-Tur. 2023. [Using in-context
    learning to improve dialogue safety](https://doi.org/10.18653/v1/2023.findings-emnlp.796).
    In *Findings of the Association for Computational Linguistics: EMNLP 2023*, pages
    11882–11910, Singapore. Association for Computational Linguistics.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Meade et al. (2023) Nicholas Meade, Spandana Gella, Devamanyu Hazarika, Prakhar
    Gupta, Di Jin, Siva Reddy, Yang Liu 和 Dilek Hakkani-Tur。2023. [使用上下文学习提升对话安全性](https://doi.org/10.18653/v1/2023.findings-emnlp.796)。在*计算语言学协会的发现：EMNLP
    2023*中，页11882–11910，新加坡。计算语言学协会。
- en: 'Mousavi et al. (2023) Seyed Mahed Mousavi, Simone Caldarella, and Giuseppe
    Riccardi. 2023. [Response generation in longitudinal dialogues: Which knowledge
    representation helps?](https://doi.org/10.18653/v1/2023.nlp4convai-1.1) In *Proceedings
    of the 5th Workshop on NLP for Conversational AI (NLP4ConvAI 2023)*, pages 1–11,
    Toronto, Canada. Association for Computational Linguistics.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mousavi 等人 (2023) Seyed Mahed Mousavi, Simone Caldarella 和 Giuseppe Riccardi.
    2023. [纵向对话中的响应生成：哪种知识表示最有帮助？](https://doi.org/10.18653/v1/2023.nlp4convai-1.1)
    在 *第5届对话式 AI 自然语言处理研讨会（NLP4ConvAI 2023）*，第1–11页，加拿大多伦多。计算语言学协会。
- en: Mousavi et al. (2024) Seyed Mahed Mousavi, Gabriel Roccabruna, Simone Alghisi,
    Massimo Rizzoli, Mirco Ravanelli, and Giuseppe Riccardi. 2024. [Are llms robust
    for spoken dialogues?](http://arxiv.org/abs/2401.02297)
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mousavi 等人 (2024) Seyed Mahed Mousavi, Gabriel Roccabruna, Simone Alghisi, Massimo
    Rizzoli, Mirco Ravanelli 和 Giuseppe Riccardi. 2024. [大语言模型对口语对话的鲁棒性如何？](http://arxiv.org/abs/2401.02297)
- en: 'Mousavi et al. (2022) Seyed Mahed Mousavi, Gabriel Roccabruna, Michela Lorandi,
    Simone Caldarella, and Giuseppe Riccardi. 2022. [Evaluation of response generation
    models: Shouldn’t it be shareable and replicable?](https://doi.org/10.18653/v1/2022.gem-1.12)
    In *Proceedings of the 2nd Workshop on Natural Language Generation, Evaluation,
    and Metrics (GEM)*, pages 136–147, Abu Dhabi, United Arab Emirates (Hybrid). Association
    for Computational Linguistics.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mousavi 等人 (2022) Seyed Mahed Mousavi, Gabriel Roccabruna, Michela Lorandi,
    Simone Caldarella 和 Giuseppe Riccardi. 2022. [响应生成模型的评估：是否应该可分享和可复制？](https://doi.org/10.18653/v1/2022.gem-1.12)
    在 *第2届自然语言生成、评估和度量研讨会（GEM）*，第136–147页，阿布扎比，阿联酋（混合形式）。计算语言学协会。
- en: 'Papineni et al. (2002) Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing
    Zhu. 2002. [Bleu: a method for automatic evaluation of machine translation](https://doi.org/10.3115/1073083.1073135).
    In *Proceedings of the 40th Annual Meeting of the Association for Computational
    Linguistics*, pages 311–318, Philadelphia, Pennsylvania, USA. Association for
    Computational Linguistics.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Papineni 等人 (2002) Kishore Papineni, Salim Roukos, Todd Ward 和 Wei-Jing Zhu.
    2002. [Bleu：一种自动评估机器翻译的方法](https://doi.org/10.3115/1073083.1073135)。在 *第40届计算语言学协会年会会议录*，第311–318页，美国宾夕法尼亚州费城。计算语言学协会。
- en: 'Qian et al. (2023) Yushan Qian, Weinan Zhang, and Ting Liu. 2023. [Harnessing
    the power of large language models for empathetic response generation: Empirical
    investigations and improvements](https://doi.org/10.18653/v1/2023.findings-emnlp.433).
    In *Findings of the Association for Computational Linguistics: EMNLP 2023*, pages
    6516–6528, Singapore. Association for Computational Linguistics.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qian 等人 (2023) Yushan Qian, Weinan Zhang 和 Ting Liu. 2023. [利用大语言模型生成同理回应的力量：实证研究与改进](https://doi.org/10.18653/v1/2023.findings-emnlp.433)。在
    *计算语言学协会发现：EMNLP 2023*，第6516–6528页，新加坡。计算语言学协会。
- en: 'Qin et al. (2023) Lang Qin, Yao Zhang, Hongru Liang, Jun Wang, and Zhenglu
    Yang. 2023. [Well begun is half done: Generator-agnostic knowledge pre-selection
    for knowledge-grounded dialogue](https://doi.org/10.18653/v1/2023.emnlp-main.285).
    In *Proceedings of the 2023 Conference on Empirical Methods in Natural Language
    Processing*, pages 4696–4709, Singapore. Association for Computational Linguistics.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qin 等人 (2023) Lang Qin, Yao Zhang, Hongru Liang, Jun Wang 和 Zhenglu Yang. 2023.
    [好的开端是成功的一半：与生成器无关的知识预选择用于知识驱动对话](https://doi.org/10.18653/v1/2023.emnlp-main.285)。在
    *2023年自然语言处理实证方法会议论文集*，第4696–4709页，新加坡。计算语言学协会。
- en: Qu et al. (2020) Chen Qu, Liu Yang, Cen Chen, Minghui Qiu, W. Bruce Croft, and
    Mohit Iyyer. 2020. [Open-retrieval conversational question answering](https://doi.org/10.1145/3397271.3401110).
    In *Proceedings of the 43rd International ACM SIGIR Conference on Research and
    Development in Information Retrieval*, SIGIR ’20, page 539–548, New York, NY,
    USA. Association for Computing Machinery.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qu 等人 (2020) Chen Qu, Liu Yang, Cen Chen, Minghui Qiu, W. Bruce Croft 和 Mohit
    Iyyer. 2020. [开放检索的对话式问答](https://doi.org/10.1145/3397271.3401110)。在 *第43届国际 ACM
    SIGIR 信息检索研究与发展会议*，SIGIR ’20，第539–548页，美国纽约。计算机协会。
- en: 'Rajpurkar et al. (2018) Pranav Rajpurkar, Robin Jia, and Percy Liang. 2018.
    [Know what you don’t know: Unanswerable questions for SQuAD](https://doi.org/10.18653/v1/P18-2124).
    In *Proceedings of the 56th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)*, pages 784–789, Melbourne, Australia. Association
    for Computational Linguistics.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rajpurkar 等人 (2018) Pranav Rajpurkar, Robin Jia 和 Percy Liang. 2018. [了解你不知道的：SQuAD
    中无答案问题](https://doi.org/10.18653/v1/P18-2124)。在 *第56届计算语言学协会年会会议录（第2卷：短论文）*，第784–789页，澳大利亚墨尔本。计算语言学协会。
- en: 'Rajpurkar et al. (2016) Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and
    Percy Liang. 2016. [SQuAD: 100,000+ questions for machine comprehension of text](https://doi.org/10.18653/v1/D16-1264).
    In *Proceedings of the 2016 Conference on Empirical Methods in Natural Language
    Processing*, pages 2383–2392, Austin, Texas. Association for Computational Linguistics.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rajpurkar 等（2016）Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev 和 Percy Liang。2016年。[SQuAD：100,000+
    个问题用于机器文本理解](https://doi.org/10.18653/v1/D16-1264)。在*2016年自然语言处理实证方法会议论文集*中，页面
    2383–2392，美国德克萨斯州奥斯汀。计算语言学协会。
- en: 'Raposo et al. (2023) Gonçalo Raposo, Luisa Coheur, and Bruno Martins. 2023.
    [Prompting, retrieval, training: An exploration of different approaches for task-oriented
    dialogue generation](https://doi.org/10.18653/v1/2023.sigdial-1.37). In *Proceedings
    of the 24th Annual Meeting of the Special Interest Group on Discourse and Dialogue*,
    pages 400–412, Prague, Czechia. Association for Computational Linguistics.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raposo 等（2023）Gonçalo Raposo, Luisa Coheur 和 Bruno Martins。2023年。[提示、检索、训练：任务导向对话生成的不同方法探索](https://doi.org/10.18653/v1/2023.sigdial-1.37)。在*第24届话语与对话特别兴趣小组年会论文集*中，页面
    400–412，捷克布拉格。计算语言学协会。
- en: 'Rashkin et al. (2019) Hannah Rashkin, Eric Michael Smith, Margaret Li, and
    Y-Lan Boureau. 2019. [Towards empathetic open-domain conversation models: A new
    benchmark and dataset](https://doi.org/10.18653/v1/P19-1534). In *Proceedings
    of the 57th Annual Meeting of the Association for Computational Linguistics*,
    pages 5370–5381, Florence, Italy. Association for Computational Linguistics.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rashkin 等（2019）Hannah Rashkin, Eric Michael Smith, Margaret Li 和 Y-Lan Boureau。2019年。[朝向同理心的开放领域对话模型：一个新的基准和数据集](https://doi.org/10.18653/v1/P19-1534)。在*第57届计算语言学协会年会论文集*中，页面
    5370–5381，意大利佛罗伦萨。计算语言学协会。
- en: 'Sarti et al. (2023) Gabriele Sarti, Nils Feldhus, Ludwig Sickert, and Oskar
    van der Wal. 2023. [Inseq: An interpretability toolkit for sequence generation
    models](https://doi.org/10.18653/v1/2023.acl-demo.40). In *Proceedings of the
    61st Annual Meeting of the Association for Computational Linguistics (Volume 3:
    System Demonstrations)*, pages 421–435, Toronto, Canada. Association for Computational
    Linguistics.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sarti 等（2023）Gabriele Sarti, Nils Feldhus, Ludwig Sickert 和 Oskar van der Wal。2023年。[Inseq：序列生成模型的可解释性工具包](https://doi.org/10.18653/v1/2023.acl-demo.40)。在*第61届计算语言学协会年会论文集（第3卷：系统演示）*中，页面
    421–435，加拿大多伦多。计算语言学协会。
- en: 'Shuster et al. (2021) Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, and
    Jason Weston. 2021. [Retrieval augmentation reduces hallucination in conversation](https://doi.org/10.18653/v1/2021.findings-emnlp.320).
    In *Findings of the Association for Computational Linguistics: EMNLP 2021*, pages
    3784–3803, Punta Cana, Dominican Republic. Association for Computational Linguistics.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shuster 等（2021）Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela 和 Jason Weston。2021年。[检索增强减少对话中的幻觉](https://doi.org/10.18653/v1/2021.findings-emnlp.320)。在*计算语言学协会发现：EMNLP
    2021*中，页面 3784–3803，多米尼加共和国蓬塔卡纳。计算语言学协会。
- en: 'Sun et al. (2023) Weiwei Sun, Pengjie Ren, and Zhaochun Ren. 2023. [Generative
    knowledge selection for knowledge-grounded dialogues](https://doi.org/10.18653/v1/2023.findings-eacl.155).
    In *Findings of the Association for Computational Linguistics: EACL 2023*, pages
    2077–2088, Dubrovnik, Croatia. Association for Computational Linguistics.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun 等（2023）Weiwei Sun, Pengjie Ren 和 Zhaochun Ren。2023年。[生成性知识选择用于知识驱动对话](https://doi.org/10.18653/v1/2023.findings-eacl.155)。在*计算语言学协会发现：EACL
    2023*中，页面 2077–2088，克罗地亚杜布罗夫尼克。计算语言学协会。
- en: Thulke et al. (2024) David Thulke, Nico Daheim, Christian Dugast, and Hermann
    Ney. 2024. [Task-oriented document-grounded dialog systems by hltpr@rwth for dstc9
    and dstc10](https://doi.org/10.1109/TASLP.2023.3267832). *IEEE/ACM Transactions
    on Audio, Speech, and Language Processing*, 32:733–741.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Thulke 等（2024）David Thulke, Nico Daheim, Christian Dugast 和 Hermann Ney。2024年。[基于任务的文档驱动对话系统，由
    hltpr@rwth 提供，用于 dstc9 和 dstc10](https://doi.org/10.1109/TASLP.2023.3267832)。*IEEE/ACM
    音频、语音与语言处理汇刊*，32:733–741。
- en: Tiedemann (2009) Jörg Tiedemann. 2009. [*News from OPUS—A Collection of Multilingual
    Parallel Corpora with Tools and Interfaces*](https://doi.org/10.1075/cilt.309.19tie),
    volume 5, pages 237–248.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tiedemann（2009）Jörg Tiedemann。2009年。[*来自 OPUS 的新闻—一个多语言平行语料库的集合及其工具和接口*](https://doi.org/10.1075/cilt.309.19tie)，第
    5 卷，页面 237–248。
- en: 'Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem
    Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia
    Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou,
    Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem
    Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana
    Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra,
    Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan
    Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen
    Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng
    Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang,
    Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023. [Llama
    2: Open foundation and fine-tuned chat models](http://arxiv.org/abs/2307.09288).'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Touvron 等（2023）雨果·图夫龙、路易斯·马丁、凯文·斯通、彼得·阿尔贝特、阿姆贾德·阿尔马赫里、雅丝敏·巴巴伊、尼古拉·巴什利科夫、苏姆亚·巴特拉、普拉吉瓦尔·巴尔加瓦、施鲁提·博萨尔、丹·比克尔、卢卡斯·布莱彻、克里斯蒂安·坎顿·费雷尔、摩亚·陈、吉列姆·库库鲁、戴维·埃修布、朱德·费尔南德斯、杰里米·傅、温银·傅、布莱恩·富勒、辛西娅·高、维达努·戈斯瓦米、纳曼·戈亚尔、安东尼·哈特肖恩、萨加尔·侯赛因、鲁伊·侯、哈坎·伊南、马尔辛·卡尔达斯、维克托·科尔凯兹、马迪安·哈布萨、伊莎贝尔·克劳曼、阿尔忒弥·科雷涅夫、普尼特·辛格·库拉、玛丽-安·拉肖、提博·拉夫里尔、詹娅·李、戴安娜·利斯科维奇、赢海·陆、余宁·毛、泽维尔·马尔蒂内、托多尔·米哈伊洛夫、普什卡尔·米什拉、伊戈尔·莫利博格、易欣·聂、安德鲁·普尔顿、杰里米·赖岑斯坦、拉希·隆塔、卡里安·萨拉迪、艾伦·谢尔滕、阮·席尔瓦、埃里克·迈克尔·史密斯、兰詹·苏布拉马尼安、肖青·艾伦·谭、宾·唐、罗斯·泰勒、阿迪娜·威廉姆斯、简·向宽、蒲鑫·徐、严正、伊利扬·扎罗夫、俞晨·张、安吉拉·范、梅拉妮·坎巴杜尔、沙然·纳朗、奥雷利安·罗德里戈斯、罗伯特·斯托伊尼克、谢尔盖·埃杜诺夫、托马斯·斯基亚隆。2023。
    [Llama 2：开放基础和微调聊天模型](http://arxiv.org/abs/2307.09288)。
- en: Wang et al. (2022) Weizhi Wang, Zhirui Zhang, Junliang Guo, Yinpei Dai, Boxing
    Chen, and Weihua Luo. 2022. [Task-oriented dialogue system as natural language
    generation](https://doi.org/10.1145/3477495.3531920). In *Proceedings of the 45th
    International ACM SIGIR Conference on Research and Development in Information
    Retrieval*, SIGIR ’22, page 2698–2703, New York, NY, USA. Association for Computing
    Machinery.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等（2022）王伟智、张志锐、郭俊良、戴银佩、陈博兴、罗伟华。2022。 [任务导向对话系统作为自然语言生成](https://doi.org/10.1145/3477495.3531920)。发表于
    *第45届国际 ACM SIGIR 信息检索研究与发展会议记录*，SIGIR ’22，第 2698–2703 页，美国纽约。计算机协会。
- en: 'Wolf et al. (2019) Thomas Wolf, Victor Sanh, Julien Chaumond, and Clement Delangue.
    2019. Transfertransfo: A transfer learning approach for neural network based conversational
    agents. *arXiv preprint arXiv:1901.08149*.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wolf 等（2019）托马斯·沃尔夫、维克多·桑、朱利安·肖蒙德、克莱门特·德朗热。2019。 Transfertransfo：一种用于神经网络对话代理的迁移学习方法。
    *arXiv 预印本 arXiv:1901.08149*。
- en: 'Xu et al. (2022a) Jing Xu, Arthur Szlam, and Jason Weston. 2022a. [Beyond goldfish
    memory: Long-term open-domain conversation](https://doi.org/10.18653/v1/2022.acl-long.356).
    In *Proceedings of the 60th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)*, pages 5180–5197, Dublin, Ireland. Association
    for Computational Linguistics.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等（2022a）徐静、亚瑟·斯拉姆、杰森·韦斯顿。2022a。 [超越金鱼记忆：长期开放领域对话](https://doi.org/10.18653/v1/2022.acl-long.356)。发表于
    *第60届计算语言学协会年会会议记录（第1卷：长篇论文）*，第 5180–5197 页，爱尔兰都柏林。计算语言学协会。
- en: 'Xu et al. (2022b) Xinchao Xu, Zhibin Gou, Wenquan Wu, Zheng-Yu Niu, Hua Wu,
    Haifeng Wang, and Shihang Wang. 2022b. [Long time no see! open-domain conversation
    with long-term persona memory](https://doi.org/10.18653/v1/2022.findings-acl.207).
    In *Findings of the Association for Computational Linguistics: ACL 2022*, pages
    2639–2650, Dublin, Ireland. Association for Computational Linguistics.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等（2022b）徐新超、勾志斌、吴文全、牛正宇、吴华、王海峰、王世航。2022b。 [很久不见！具有长期个性记忆的开放领域对话](https://doi.org/10.18653/v1/2022.findings-acl.207)。发表于
    *计算语言学协会会议记录：ACL 2022*，第 2639–2650 页，爱尔兰都柏林。计算语言学协会。
- en: 'Yang et al. (2023) Yizhe Yang, Heyan Huang, Yuhang Liu, and Yang Gao. 2023.
    [Graph vs. sequence: An empirical study on knowledge forms for knowledge-grounded
    dialogue](https://doi.org/10.18653/v1/2023.emnlp-main.982). In *Proceedings of
    the 2023 Conference on Empirical Methods in Natural Language Processing*, pages
    15846–15858, Singapore. Association for Computational Linguistics.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等（2023）杨轶哲、黄鹤妍、刘宇航、杨高。2023。 [图谱与序列：知识驱动对话中知识形式的实证研究](https://doi.org/10.18653/v1/2023.emnlp-main.982)。发表于
    *2023年自然语言处理实证方法会议记录*，第 15846–15858 页，新加坡。计算语言学协会。
- en: 'Yang et al. (2018) Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William
    Cohen, Ruslan Salakhutdinov, and Christopher D. Manning. 2018. [HotpotQA: A dataset
    for diverse, explainable multi-hop question answering](https://doi.org/10.18653/v1/D18-1259).
    In *Proceedings of the 2018 Conference on Empirical Methods in Natural Language
    Processing*, pages 2369–2380, Brussels, Belgium. Association for Computational
    Linguistics.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人（2018）智林杨、彭琦、赛征张、约书亚·本吉奥、威廉·科恩、鲁斯兰·萨拉库丁诺夫和克里斯托弗·D·曼宁。2018年。[HotpotQA：用于多跳问答的数据集](https://doi.org/10.18653/v1/D18-1259)。收录于
    *2018年自然语言处理经验方法会议*，页面 2369–2380，布鲁塞尔，比利时。计算语言学协会。
- en: 'Zhang et al. (2023) Qin Zhang, Shangsi Chen, Dongkuan Xu, Qingqing Cao, Xiaojun
    Chen, Trevor Cohn, and Meng Fang. 2023. [A survey for efficient open domain question
    answering](https://doi.org/10.18653/v1/2023.acl-long.808). In *Proceedings of
    the 61st Annual Meeting of the Association for Computational Linguistics (Volume
    1: Long Papers)*, pages 14447–14465, Toronto, Canada. Association for Computational
    Linguistics.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人（2023）秦张、尚思陈、董宽徐、青青曹、肖俊陈、特雷弗·科恩和孟芳。2023年。[高效开放领域问答的调查](https://doi.org/10.18653/v1/2023.acl-long.808)。收录于
    *第61届计算语言学协会年会（第1卷：长篇论文）*，页面 14447–14465，多伦多，加拿大。计算语言学协会。
- en: 'Zhang et al. (2018) Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam,
    Douwe Kiela, and Jason Weston. 2018. [Personalizing dialogue agents: I have a
    dog, do you have pets too?](https://doi.org/10.18653/v1/P18-1205) In *Proceedings
    of the 56th Annual Meeting of the Association for Computational Linguistics (Volume
    1: Long Papers)*, pages 2204–2213, Melbourne, Australia. Association for Computational
    Linguistics.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人（2018）赛征张、艾米莉·迪南、杰克·厄本内克、亚瑟·斯拉姆、道威·基拉和杰森·韦斯顿。2018年。[个性化对话代理：我有一只狗，你也有宠物吗？](https://doi.org/10.18653/v1/P18-1205)。收录于
    *第56届计算语言学协会年会（第1卷：长篇论文）*，页面 2204–2213，墨尔本，澳大利亚。计算语言学协会。
- en: 'Zhang et al. (2020) Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris
    Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, and Bill Dolan. 2020. [DIALOGPT
    : Large-scale generative pre-training for conversational response generation](https://doi.org/10.18653/v1/2020.acl-demos.30).
    In *Proceedings of the 58th Annual Meeting of the Association for Computational
    Linguistics: System Demonstrations*, pages 270–278, Online. Association for Computational
    Linguistics.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人（2020）易哲张、思琪孙、米歇尔·加利、严俊陈、克里斯·布罗克特、向高、建峰高、静静刘和比尔·多伦。2020年。[DIALOGPT：用于对话响应生成的大规模生成预训练](https://doi.org/10.18653/v1/2020.acl-demos.30)。收录于
    *第58届计算语言学协会年会：系统演示*，页面 270–278，在线。计算语言学协会。
- en: 'Zhao et al. (2023) Chao Zhao, Spandana Gella, Seokhwan Kim, Di Jin, Devamanyu
    Hazarika, Alexandros Papangelis, Behnam Hedayatnia, Mahdi Namazifar, Yang Liu,
    and Dilek Hakkani-Tur. 2023. [“what do others think?”: Task-oriented conversational
    modeling with subjective knowledge](https://doi.org/10.18653/v1/2023.sigdial-1.28).
    In *Proceedings of the 24th Annual Meeting of the Special Interest Group on Discourse
    and Dialogue*, pages 309–323, Prague, Czechia. Association for Computational Linguistics.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao 等人（2023）超赵、斯潘达纳·盖拉、石焕·金、迪·金、德瓦曼纽·哈扎里卡、亚历山德罗斯·帕潘杰利斯、贝赫南·赫达亚特尼亚、马赫迪·纳马齐法、杨柳和迪勒克·哈卡尼-图尔。2023年。[“别人怎么想？”：带有主观知识的任务导向对话建模](https://doi.org/10.18653/v1/2023.sigdial-1.28)。收录于
    *第24届话语与对话特别兴趣小组年会*，页面 309–323，布拉格，捷克共和国。计算语言学协会。
- en: Zhou et al. (2018) Kangyan Zhou, Shrimai Prabhumoye, and Alan W Black. 2018.
    [A dataset for document grounded conversations](https://doi.org/10.18653/v1/D18-1076).
    In *Proceedings of the 2018 Conference on Empirical Methods in Natural Language
    Processing*, pages 708–713, Brussels, Belgium. Association for Computational Linguistics.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou 等人（2018）康燕周、施瑞迈·普拉布摩耶和艾伦·W·布莱克。2018年。[一个用于文档基础对话的数据集](https://doi.org/10.18653/v1/D18-1076)。收录于
    *2018年自然语言处理经验方法会议*，页面 708–713，布鲁塞尔，比利时。计算语言学协会。
- en: Appendix A Appendix
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 附录
- en: A.1 Datasets
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 数据集
- en: We briefly present the reasons for selecting the datasets.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们简要介绍了选择这些数据集的原因。
- en: Open-Domain Dialogue (ODD) Differently from other datasets, DailyDialog dialogues
    only involve two participants (Tiedemann, [2009](#bib.bib53); Baumgartner et al.,
    [2020](#bib.bib1)), are not audio transcriptions Godfrey et al. ([1992](#bib.bib11)),
    have more than two exchanges between the participants (Rashkin et al., [2019](#bib.bib48)),
    and are not restricted by a persona (i.e. few sentences describing the user’s
    interests) (Zhang et al., [2018](#bib.bib62); Xu et al., [2022a](#bib.bib57)).
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 开放领域对话（ODD）与其他数据集不同，DailyDialog 对话仅涉及两个参与者（Tiedemann，[2009](#bib.bib53)；Baumgartner
    等，[2020](#bib.bib1)），不是音频转录（Godfrey 等，[1992](#bib.bib11)），参与者之间的交流超过两个回合（Rashkin
    等，[2019](#bib.bib48)），且不受限于一个角色（即描述用户兴趣的少量句子）（Zhang 等，[2018](#bib.bib62)；Xu 等，[2022a](#bib.bib57)）。
- en: Knowledge-Grounded Dialogue (KGD) Wizard of Wikipedia provides a test set with
    an unseen set of documents (Zhou et al., [2018](#bib.bib65); Komeili et al., [2022](#bib.bib27))
    and its knowledge has not changed over time (i.e. comparable with previous/future
    studies) (Gopalakrishnan et al., [2019](#bib.bib12); Hedayatnia et al., [2020](#bib.bib15)).
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 知识驱动对话（KGD）维基百科的巫师提供了一个未见过的文档测试集（Zhou 等，[2018](#bib.bib65)；Komeili 等，[2022](#bib.bib27)），其知识随着时间的推移没有变化（即与之前/未来的研究可比）（Gopalakrishnan
    等，[2019](#bib.bib12)；Hedayatnia 等，[2020](#bib.bib15)）。
- en: Task-Oriented Dialogue (TOD) A few other TOD datasets include unstructured knowledge
    access but consist only of a spoken test set (Kim et al., [2021](#bib.bib25)),
    or provide no dialogue state annotation (Feng et al., [2020](#bib.bib9)). The
    dataset proposed in the ninth Dialogue System Technology Challenge augmented MultiWOZ
    2.1 (Eric et al., [2020](#bib.bib8)) with knowledge access turns but removed the
    dialogue state annotation. To always include the dialogue state in our analysis,
    we recovered the dialogue state annotation from the original MultiWOZ 2.1 dialogues,
    and we only considered the dialogues from this dataset.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 任务导向对话（TOD）其他一些TOD数据集包括非结构化知识访问，但仅包含口语测试集（Kim 等，[2021](#bib.bib25)），或不提供对话状态注释（Feng
    等，[2020](#bib.bib9)）。在第九届对话系统技术挑战中提出的数据集增强了 MultiWOZ 2.1（Eric 等，[2020](#bib.bib8)）的知识访问回合，但去除了对话状态注释。为了在分析中始终包含对话状态，我们从原始的
    MultiWOZ 2.1 对话中恢复了对话状态注释，并且我们只考虑了这个数据集中的对话。
- en: Question Answering (QA) We choose NarrativeQA because it has a publicly available
    test set (to evaluate the retriever) and answers are expressed as free-form text
    (to evaluate response generation) (Rajpurkar et al., [2016](#bib.bib46), [2018](#bib.bib45);
    Yang et al., [2018](#bib.bib60); Kwiatkowski et al., [2019](#bib.bib29)). Although
    the original task always provides the correct document, we also wanted to investigate
    the performance of the retriever when considering documents with an average length
    of 600 tokens. Additionally, we avoided splitting documents into smaller chunks
    (e.g. passages or sentences) because this would have made the computation of the
    retriever performance more challenging.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 问答（QA）我们选择 NarrativeQA，因为它有一个公开的测试集（用于评估检索器），并且答案以自由文本的形式表达（用于评估响应生成）（Rajpurkar
    等，[2016](#bib.bib46)，[2018](#bib.bib45)；Yang 等，[2018](#bib.bib60)；Kwiatkowski
    等，[2019](#bib.bib29)）。虽然原始任务总是提供正确的文档，但我们也希望研究在考虑平均长度为600个标记的文档时，检索器的性能。此外，我们避免将文档拆分成更小的块（例如段落或句子），因为这样会使检索器性能的计算变得更加困难。
- en: A.2 Implementation and resources
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 实施和资源
- en: Models and parameters We fine-tuned the models using LoRA (rank 32 and alpha
    64) for a maximum of 10 epochs with an early stopping patience of 2. We chose
    AdamW (Loshchilov and Hutter, [2017](#bib.bib36)) as the optimizer and used a
    learning rate of $10^{-4}$ for Mistral[I] (selected based on the performance on
    the development sets). To obtain an encoding for both documents and queries, we
    used all-mpnet-base-v2⁴⁴4[https://www.sbert.net/docs/pretrained_models.html](https://www.sbert.net/docs/pretrained_models.html).
    We have then stored the encoded documents in a FAISS vector store (used for retrieval).
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 模型和参数 我们使用 LoRA（rank 32 和 alpha 64）对模型进行了微调，最多进行 10 轮训练，并设置了 2 的早停耐心。我们选择了 AdamW（Loshchilov
    和 Hutter，[2017](#bib.bib36)）作为优化器，并对 Mistral[I] 使用了 $10^{-4}$ 的学习率（基于开发集上的表现进行选择）。为了获得文档和查询的编码，我们使用了
    all-mpnet-base-v2⁴⁴4[https://www.sbert.net/docs/pretrained_models.html](https://www.sbert.net/docs/pretrained_models.html)。然后我们将编码后的文档存储在
    FAISS 向量存储中（用于检索）。
- en: Input structure We separated the segments of the input vector with their name
    followed by a colon (i.e. "Dialogue state:", "Topic:", "Knowledge:", "Question:",
    "Answer:") similarly to previous work (Izacard and Grave, [2021](#bib.bib20);
    Wang et al., [2022](#bib.bib55); Chen et al., [2023](#bib.bib4); Sun et al., [2023](#bib.bib51)).
    For TOD, we represented the dialogue state as a comma-separated list of domain
    slot value triplets (Hosseini-Asl et al., [2020b](#bib.bib17); Wang et al., [2022](#bib.bib55)).
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 输入结构 我们将输入向量的各个部分与其名称及冒号（即“对话状态：”、“话题：”、“知识：”、“问题：”、“回答：”）分开，这类似于以前的工作（Izacard
    和 Grave，[2021](#bib.bib20)；Wang 等，[2022](#bib.bib55)；Chen 等，[2023](#bib.bib4)；Sun
    等，[2023](#bib.bib51)）。对于 TOD，我们将对话状态表示为由逗号分隔的领域槽位值三元组（Hosseini-Asl 等，[2020b](#bib.bib17)；Wang
    等，[2022](#bib.bib55)）。
- en: Instructions Table [5](#A1.T5 "Table 5 ‣ A.2 Implementation and resources ‣
    Appendix A Appendix ‣ Limitations ‣ 5 Conclusion ‣ 4.3 Explaining Negative Human
    Judgments ‣ 4.2 Human Evaluation ‣ 4.1.1 Explainability Study ‣ 4.1 Automatic
    Evaluation ‣ 4 Evaluation ‣ Should We Fine-Tune or RAG? Evaluating Different Techniques
    to Adapt LLMs for Dialogue") reports the instructions used for in-context learning
    experiments. For each dialogue type, we have experimented with three different
    instructions describing the task and the various input segments (e.g. dialogue
    history, topic, and knowledge). We have selected the best instruction based on
    the development set performance.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 指令表 [5](#A1.T5 "表 5 ‣ A.2 实施和资源 ‣ 附录 A ‣ 限制 ‣ 5 结论 ‣ 4.3 解释负面人类判断 ‣ 4.2 人工评估
    ‣ 4.1.1 可解释性研究 ‣ 4.1 自动评估 ‣ 4 评估 ‣ 我们应该微调还是 RAG？评估不同技术以适应 LLMs 用于对话") 报告了用于上下文学习实验的指令。对于每种对话类型，我们尝试了三种不同的指令来描述任务和各种输入部分（例如对话历史、话题和知识）。我们根据开发集的表现选择了最佳指令。
- en: '| Dialogue Type | Instruction |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| 对话类型 | 指令 |'
- en: '| ODD | "" |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| ODD | "" |'
- en: '| "This is a conversation between two people. Use the context to write an engaging
    reply for the other person." |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| "这是两个人之间的对话。利用上下文为另一个人编写一个引人入胜的回复。" |'
- en: '| "Write a coherent continuation for the proposed conversation." |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| "为建议的对话写一个连贯的续集。" |'
- en: '| KGD | "" |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| KGD | "" |'
- en: '| "This is a conversation between two people about a Topic. Use the Dialogue
    and the additional Knowledge as context to write an engaging reply for the other
    person.", |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| "这是两个人之间关于一个话题的对话。利用对话和额外的知识作为上下文，为另一个人编写一个引人入胜的回复。" |'
- en: '| "Write a coherent continuation for the proposed conversation based on the
    additional Knowledge." |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| "基于额外的知识，为建议的对话写一个连贯的续集。" |'
- en: '| TOD | "" |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| TOD | "" |'
- en: '| "In the following conversation a user wants to achieve some goal and needs
    help from an assistant. Continue the conversation with the response of the assistant."
    |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| "在以下对话中，用户希望实现某个目标，并需要助手的帮助。继续对话，给出助手的回复。" |'
- en: '| "Write a coherent continuation for the proposed conversation." |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| "为建议的对话写一个连贯的续集。" |'
- en: '| QA | "" |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| QA | "" |'
- en: '| "You are presented with a user’s Question about a movie or book. Answer to
    the user’s Question using the information provided in the Context." |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| "你收到一个关于电影或书籍的用户问题。使用上下文中提供的信息回答用户的问题。" |'
- en: '| "Answer to the user’s question using the provided information (if available)."
    |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| "使用提供的信息（如果有的话）回答用户的问题。" |'
- en: 'Table 5: Instructions used to adapt the model to a specific dialogue type with
    in-context learning. We defined three instructions for each dialogue type, describing
    the task and the various input segments (e.g. dialogue history, topic, dialogue
    state, and knowledge). We selected the best instruction based on the development
    set performance.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：用于将模型适应到特定对话类型的上下文学习的指令。我们为每种对话类型定义了三种指令，描述任务和各种输入部分（例如对话历史、话题、对话状态和知识）。我们根据开发集的表现选择了最佳指令。
- en: Generation We sampled 10% of the data (in a stratified fashion, based on the
    length of the responses) from the development set of each dialogue type. For each
    model, we used grid search to find, for the sampled data, the combination of parameters
    (top-p, top-k, and temperature) leading to the highest BLEU-4. The best combination
    of parameters was used to generate the responses for the test set.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 生成 我们从每种对话类型的开发集中随机抽取了10%的数据（按照回答的长度进行分层），对每个模型，我们使用网格搜索来找到对抽样数据来说，能够得到最高 BLEU-4
    的参数组合（top-p、top-k 和温度）。最佳的参数组合用于生成测试集的回答。
- en: GPU Requirements Most computations were performed on a single NVIDIA A100 GPU
    with 80GB, requiring less than 50 hours to execute. In a few cases, we had to
    use two (i.e. fine-tuning the models for QA using more than one document) or three
    (i.e. integrated gradients) A100 with 80GB each.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: GPU要求大多数计算是在一台80GB的NVIDIA A100 GPU上进行的，执行时间少于50小时。在少数情况下，我们不得不使用两台（即，使用多于一个文档对模型进行微调）或三台（即，集成梯度）80GB的A100。
- en: A.3 Additional Automatic Evaluation
  id: totrans-249
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.3 附加自动评估
- en: To automatically evaluate the quality of the generated text, we have considered
    BLEU-4 Papineni et al. ([2002](#bib.bib41)), F1 (i.e. unigram overlap), and ROUGE-L
    Lin ([2004](#bib.bib34)). Furthermore, we have used KF1 Shuster et al. ([2021](#bib.bib50))
    to measure the overlap between the prediction and the knowledge selected by the
    annotators. For reproducibility purposes, we have computed ROUGE-L using the official
    implementation⁵⁵5[https://github.com/google-research/google-research/tree/master/rouge](https://github.com/google-research/google-research/tree/master/rouge)
    and all the remaining metrics using ParlAI⁶⁶6[https://parl.ai](https://parl.ai).
    No pre-processing was performed on the model-generated answers.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 为了自动评估生成文本的质量，我们考虑了BLEU-4 Papineni et al. ([2002](#bib.bib41))、F1（即单词重叠）和ROUGE-L
    Lin ([2004](#bib.bib34))。此外，我们还使用了KF1 Shuster et al. ([2021](#bib.bib50))来测量预测与注释者选择的知识之间的重叠。为了可重复性，我们使用了官方实现计算ROUGE-L⁵⁵5[https://github.com/google-research/google-research/tree/master/rouge](https://github.com/google-research/google-research/tree/master/rouge)以及使用ParlAI⁶⁶6[https://parl.ai](https://parl.ai)计算所有剩余的指标。未对模型生成的答案进行预处理。
- en: Table [6](#A1.T6 "Table 6 ‣ A.3 Additional Automatic Evaluation ‣ Appendix A
    Appendix ‣ Limitations ‣ 5 Conclusion ‣ 4.3 Explaining Negative Human Judgments
    ‣ 4.2 Human Evaluation ‣ 4.1.1 Explainability Study ‣ 4.1 Automatic Evaluation
    ‣ 4 Evaluation ‣ Should We Fine-Tune or RAG? Evaluating Different Techniques to
    Adapt LLMs for Dialogue") reports the performance for each dialogue type. As mentioned
    in Section [4.1](#S4.SS1 "4.1 Automatic Evaluation ‣ 4 Evaluation ‣ Should We
    Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue"),
    the best performance is obtained by fine-tuned models. Following, we analyze the
    results for each dialogue type.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 表[6](#A1.T6 "表6 ‣ A.3 附加自动评估 ‣ 附录A 限制 ‣ 5 结论 ‣ 4.3 解释负面人工评判 ‣ 4.2 人工评估 ‣ 4.1.1
    可解释性研究 ‣ 4.1 自动评估 ‣ 4 评估 ‣ 我们应该微调还是RAG？评估不同技术以适应LLM对话")报告了每种对话类型的表现。如[4.1节](#S4.SS1
    "4.1 自动评估 ‣ 4 评估 ‣ 我们应该微调还是RAG？评估不同技术以适应LLM对话")中所述，微调模型取得了最佳表现。接下来，我们将分析每种对话类型的结果。
- en: Open-Domain Dialogue (ODD) Although fine-tuning achieves a higher BLEU-4, the
    results show that both techniques produce very different responses with respect
    to the ground truth.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 开放域对话（ODD）虽然微调可以获得更高的BLEU-4评分，但结果显示这两种技术在与实际情况相比时产生了非常不同的响应。
- en: Model Technique External Knowledge BLEU-4 KF1 F1 ROUGE-L ODD TOD KGD TOD QA
    KGD QA Llama2[C] In-Context Learning No Know. 0.2 0.85 11.61 13.66 5.26 12.68
    5.59 Retrieved Know. 0.83 13.51 12.10 5.65 12.91 14.86 Gold Know. 1.07 25.87 21.03
    6.72 16.59 23.22 Fine-Tuning No Know. 0.3 6.72 17.43 34.04 0.74 18.46 17.25 Retrieved
    Know. 4.33 25.10 26.85 1.15 20.70 46.21 Gold Know. 5.39 76.23 42.69 1.44 38.41
    73.38 Mistral[I] In-Context Learning No Know. 0.2 1.33 10.96 13.01 4.84 11.04
    6.94 Retrieved Know. 1.06 13.83 12.53 6.09 12.22 10.26 Gold Know. 1.33 25.95 28.74
    7.07 15.88 21.74 Fine-Tuning No Know. 0.9 4.09 15.47 29.27 0.67 18.63 12.73 Retrieved
    Know. 3.85 21.63 30.44 1.18 20.49 45.40 Gold Know. 3.94 68.36 43.04 1.46 38.21
    70.54 Ground Truth 100 100 37.79 38.48 1.52 100 100
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 模型 技术 外部知识 BLEU-4 KF1 F1 ROUGE-L ODD TOD KGD TOD QA KGD QA Llama2[C] 上下文学习 无
    知识 0.2 0.85 11.61 13.66 5.26 12.68 5.59 检索 知识 0.83 13.51 12.10 5.65 12.91 14.86
    金标准 知识 1.07 25.87 21.03 6.72 16.59 23.22 微调 无 知识 0.3 6.72 17.43 34.04 0.74 18.46
    17.25 检索 知识 4.33 25.10 26.85 1.15 20.70 46.21 金标准 知识 5.39 76.23 42.69 1.44 38.41
    73.38 Mistral[I] 上下文学习 无 知识 0.2 1.33 10.96 13.01 4.84 11.04 6.94 检索 知识 1.06 13.83
    12.53 6.09 12.22 10.26 金标准 知识 1.33 25.95 28.74 7.07 15.88 21.74 微调 无 知识 0.9 4.09
    15.47 29.27 0.67 18.63 12.73 检索 知识 3.85 21.63 30.44 1.18 20.49 45.40 金标准 知识 3.94
    68.36 43.04 1.46 38.21 70.54 基准 100 100 37.79 38.48 1.52 100 100
- en: 'Table 6: Automatic Evaluation BLEU-4, KF1, F1 and ROUGE-L for In-Context Learning
    and Fine-Tuning with Retrieved (top-3) and Gold (ground-truth) knowledge, on Llama2[C] and
    Mistral[I], in different dialogue types: Open-Domain Dialogues (ODDs), Knowledge
    Grounded Dialogues (KGDs), Task-Oriented Dialogues (TODs), and Question Answering
    (QA).'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '表 6: 自动评估 BLEU-4、KF1、F1 和 ROUGE-L，针对上下文学习和微调，使用检索（前 3 名）和金（真实）知识，应用于 Llama2[C]
    和 Mistral[I]，在不同对话类型中：开放领域对话（ODDs）、知识基础对话（KGDs）、任务导向对话（TODs）和问答（QA）。'
- en: '| Model | Technique | External Knowledge | BLEU-4 | KF1 |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 技术 | 外部知识 | BLEU-4 | KF1 |'
- en: '| TOD | TOD^† | TOD | TOD^† |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| TOD | TOD^† | TOD | TOD^† |'
- en: '| Llama2[C] | In-Context Learning | No Know. | 0.85 | 0.60 | 13.66 | 12.39
    |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| Llama2[C] | 上下文学习 | 无知识 | 0.85 | 0.60 | 13.66 | 12.39 |'
- en: '| Retrieved Know. | 0.83 | 0.44 | 12.10 | 10.44 |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| 检索知识 | 0.83 | 0.44 | 12.10 | 10.44 |'
- en: '| Gold Know. | 1.07 | 2.67 | 25.87 | 23.77 |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| 金知识 | 1.07 | 2.67 | 25.87 | 23.77 |'
- en: '| Fine-Tuning | No Know. | 6.72 | 4.33 | 34.04 | 25.73 |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| 微调 | 无知识 | 6.72 | 4.33 | 34.04 | 25.73 |'
- en: '| Retrieved Know. | 4.33 | 3.15 | 26.85 | 22.92 |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| 检索知识 | 4.33 | 3.15 | 26.85 | 22.92 |'
- en: '| Gold Know. | 5.39 | 8.50 | 42.69 | 45.49 |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| 金知识 | 5.39 | 8.50 | 42.69 | 45.49 |'
- en: '| Mistral[I] | In-Context Learning | No Know. | 1.33 | 1.12 | 13.01 | 11.91
    |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| Mistral[I] | 上下文学习 | 无知识 | 1.33 | 1.12 | 13.01 | 11.91 |'
- en: '| Retrieved Know. | 1.06 | 1.02 | 12.53 | 10.36 |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| 检索知识 | 1.06 | 1.02 | 12.53 | 10.36 |'
- en: '| Gold Know. | 1.33 | 3.70 | 28.74 | 28.79 |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| 金知识 | 1.33 | 3.70 | 28.74 | 28.79 |'
- en: '| Fine-Tuning | No Know. | 4.09 | 5.83 | 29.27 | 25.47 |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| 微调 | 无知识 | 4.09 | 5.83 | 29.27 | 25.47 |'
- en: '| Retrieved Know. | 3.85 | 4.76 | 30.44 | 25.61 |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| 检索知识 | 3.85 | 4.76 | 30.44 | 25.61 |'
- en: '| Gold Know. | 3.94 | 10.63 | 43.04 | 49.40 |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| 金知识 | 3.94 | 10.63 | 43.04 | 49.40 |'
- en: '| Ground Truth |  |  | 100 | 100 | 38.48 | 39.91 |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| 真实数据 |  |  | 100 | 100 | 38.48 | 39.91 |'
- en: 'Table 7: Automatic Evaluation BLEU-4 and KF1 for In-Context Learning and Fine-Tuning
    with Retrieved (top-3) and Gold (ground-truth) knowledge, on Llama2[C] and Mistral[I],
    in Task-Oriented Dialogues (TODs). ^† indicates that only test turns with unseen
    knowledge were included.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '表 7: 自动评估 BLEU-4 和 KF1，针对上下文学习和微调，使用检索（前 3 名）和金（真实）知识，应用于 Llama2[C] 和 Mistral[I]，在任务导向对话（TODs）中。^†
    表示仅包含了具有未见知识的测试回合。'
- en: Knowledge-Grounded Dialogue (KGD) We report the performance of the models on
    the unseen test set (i.e. the knowledge base contains documents that are only
    present in the test set). The results show that models adapted using fine-tuning
    obtain a higher F1 than in-context learning. Furthermore, the best models tend
    to copy more from the gold knowledge compared to the annotators (as shown in the
    ground truth).
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 知识基础对话（KGD）我们报告了模型在未见测试集上的表现（即知识库包含仅存在于测试集中的文档）。结果表明，使用微调的模型获得了比上下文学习更高的 F1
    分数。此外，最佳模型往往比标注员更倾向于从金知识中复制内容（如真实数据中所示）。
- en: Task-Oriented Dialogue (TOD) Differently from the other types, Llama2[C] and
    Mistral[I] have obtained the best performance in terms of BLEU-4 when fine-tuned
    with no additional knowledge. Further investigation suggests this happens because
    of the high overlap between the knowledge used for training and testing (82%).
    We report the performance on the documents only available in the test phase in
    Table [7](#A1.T7 "Table 7 ‣ A.3 Additional Automatic Evaluation ‣ Appendix A Appendix
    ‣ Limitations ‣ 5 Conclusion ‣ 4.3 Explaining Negative Human Judgments ‣ 4.2 Human
    Evaluation ‣ 4.1.1 Explainability Study ‣ 4.1 Automatic Evaluation ‣ 4 Evaluation
    ‣ Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for
    Dialogue") (TOD^†). In this scenario, gold knowledge does indeed increase the
    performance of the models.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 任务导向对话（TOD）与其他类型的对话有所不同，Llama2[C] 和 Mistral[I] 在没有额外知识的微调下，在 BLEU-4 指标上的表现最佳。进一步的调查表明，这种现象的原因是训练和测试中使用的知识重叠度很高（82%）。我们在表格[7](#A1.T7
    "Table 7 ‣ A.3 Additional Automatic Evaluation ‣ Appendix A Appendix ‣ Limitations
    ‣ 5 Conclusion ‣ 4.3 Explaining Negative Human Judgments ‣ 4.2 Human Evaluation
    ‣ 4.1.1 Explainability Study ‣ 4.1 Automatic Evaluation ‣ 4 Evaluation ‣ Should
    We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue")（TOD^†）中报告了仅在测试阶段可用文档的性能。在这种情况下，金知识确实提高了模型的性能。
- en: Question Answering (QA) Although fine-tuned models achieve the highest ROUGE-L,
    in-context learning models tend to provide longer and possibly more detailed responses,
    as reported in terms of KF1. Because ground truths are particularly short (4.26
    tokens on average), models that generated longer responses (especially models
    adapted with in-context learning) were awarded a lower ROUGE-L.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 问答（QA）虽然微调模型在 ROUGE-L 上达到最高，但上下文学习模型倾向于提供更长且可能更详细的回答，如 KF1 所报告的。由于真实答案特别简短（平均
    4.26 个标记），生成更长回答的模型（尤其是经过上下文学习适应的模型）获得了较低的 ROUGE-L。
- en: A.3.1 Retriever Accuracy
  id: totrans-274
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: A.3.1 检索器准确性
- en: We study the performance of the retriever for each dialogue type and report
    Recall@K in Figure [5](#A1.F5 "Figure 5 ‣ A.3.1 Retriever Accuracy ‣ A.3 Additional
    Automatic Evaluation ‣ Appendix A Appendix ‣ Limitations ‣ 5 Conclusion ‣ 4.3
    Explaining Negative Human Judgments ‣ 4.2 Human Evaluation ‣ 4.1.1 Explainability
    Study ‣ 4.1 Automatic Evaluation ‣ 4 Evaluation ‣ Should We Fine-Tune or RAG?
    Evaluating Different Techniques to Adapt LLMs for Dialogue"). Because of the size
    of the knowledge base (Table [1](#S3.T1 "Table 1 ‣ 3.1 Datasets ‣ 3 Experiments
    ‣ Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for
    Dialogue")), the retriever achieves the lowest performance on TOD. However, although
    the knowledge base for QA is bigger than for KGD, the retriever achieves a higher
    recall for QA. Further study suggest that, although the retriever selects the
    gold sentence in only a few cases, the model retrieves a sentence from the same
    paragraph more than 69% of the time.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究了每种对话类型的检索器性能，并在图 [5](#A1.F5 "Figure 5 ‣ A.3.1 Retriever Accuracy ‣ A.3
    Additional Automatic Evaluation ‣ Appendix A Appendix ‣ Limitations ‣ 5 Conclusion
    ‣ 4.3 Explaining Negative Human Judgments ‣ 4.2 Human Evaluation ‣ 4.1.1 Explainability
    Study ‣ 4.1 Automatic Evaluation ‣ 4 Evaluation ‣ Should We Fine-Tune or RAG?
    Evaluating Different Techniques to Adapt LLMs for Dialogue") 中报告了 Recall@K。由于知识库的规模（表
    [1](#S3.T1 "Table 1 ‣ 3.1 Datasets ‣ 3 Experiments ‣ Should We Fine-Tune or RAG?
    Evaluating Different Techniques to Adapt LLMs for Dialogue")），检索器在 TOD 上的表现最低。然而，尽管
    QA 的知识库比 KGD 大，检索器在 QA 上的召回率更高。进一步研究表明，尽管检索器只在少数情况下选择了金句，模型在相同段落中检索句子的频率超过了 69%。
- en: '![Refer to caption](img/b772b13192a02d307944ac94be1104ac.png)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/b772b13192a02d307944ac94be1104ac.png)'
- en: 'Figure 5: Performance of the off-the-shelf retriever for each dialogue type.
    The retriever achieves the lowest Recall@K on TOD because of the larger knowledge
    base size (2900 documents). However, the retriever achieves a higher Recall@K
    for QA, even though its knowledge base is bigger than the one for KGD (355 vs.
    61 $\pm$ 21). Further studies indicate that, despite the model is not capable
    to retrieve the exact sentence of the annotator (KGD Sentence), the retriever
    selects a sentence belonging to the same paragraph more than 69% of the time (KGD
    Paragraph).'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '图 5: 各对话类型的现成检索器性能。由于知识库规模较大（2900 个文档），检索器在 TOD 上的 Recall@K 最低。然而，尽管其知识库比 KGD
    的更大（355 对比 61 $\pm$ 21），检索器在 QA 上的 Recall@K 更高。进一步研究表明，尽管模型无法检索到标注者的确切句子（KGD 句子），检索器选择同一段落中的句子的频率超过了
    69%（KGD 段落）。'
- en: A.4 Human Evaluation
  id: totrans-278
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.4 人工评估
- en: Table [8](#A1.T8 "Table 8 ‣ A.4 Human Evaluation ‣ Appendix A Appendix ‣ Limitations
    ‣ 5 Conclusion ‣ 4.3 Explaining Negative Human Judgments ‣ 4.2 Human Evaluation
    ‣ 4.1.1 Explainability Study ‣ 4.1 Automatic Evaluation ‣ 4 Evaluation ‣ Should
    We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue")
    reports the results for the Correctness dimension of Human Evaluations. Except
    for ODD, fine-tuning tends to improve Correctness.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [8](#A1.T8 "Table 8 ‣ A.4 Human Evaluation ‣ Appendix A Appendix ‣ Limitations
    ‣ 5 Conclusion ‣ 4.3 Explaining Negative Human Judgments ‣ 4.2 Human Evaluation
    ‣ 4.1.1 Explainability Study ‣ 4.1 Automatic Evaluation ‣ 4 Evaluation ‣ Should
    We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue")
    报告了人类评估中正确性维度的结果。除了 ODD，微调往往能提高正确性。
- en: '| Model | Technique | External Knowledge | Correctness |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 技术 | 外部知识 | 正确性 |'
- en: '| ODD | KGD | TOD | QA |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| ODD | KGD | TOD | QA |'
- en: '| Llama2[C] | In-Context Learning | No Know. | 95 | 80 | 95 | 75 |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| Llama2[C] | 上下文学习 | 无知识 | 95 | 80 | 95 | 75 |'
- en: '| Retrieved Know. |  | 80 | 60 | 60 |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| 检索知识 |  | 80 | 60 | 60 |'
- en: '| Gold Know. |  | 80 | 70 | 80 |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| 金知识 |  | 80 | 70 | 80 |'
- en: '| Fine-Tuning | No Know. | 65 | 90 | 70 | 75 |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| 微调 | 无知识 | 65 | 90 | 70 | 75 |'
- en: '| Retrieved Know. |  | 90 | 90 | 55 |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| 检索知识 |  | 90 | 90 | 55 |'
- en: '| Gold Know. |  | 85 | 85 | 85 |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| 金知识 |  | 85 | 85 | 85 |'
- en: '| Mistral[I] | In-Context Learning | No Know. | 95 | 70 | 75 | 60 |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| Mistral[I] | 上下文学习 | 无知识 | 95 | 70 | 75 | 60 |'
- en: '| Retrieved Know. |  | 55 | 70 | 50 |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| 检索知识 |  | 55 | 70 | 50 |'
- en: '| Gold Know. |  | 85 | 60 | 80 |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| 金知识 |  | 85 | 60 | 80 |'
- en: '| Fine-Tuning | No Know. | 65 | 85 | 80 | 50 |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| 微调 | 无知识 | 65 | 85 | 80 | 50 |'
- en: '| Retrieved Know. |  | 75 | 100 | 45 |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '| 检索知识 |  | 75 | 100 | 45 |'
- en: '| Gold Know. |  | 70 | 80 | 85 |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '| 黄金知识 |  | 70 | 80 | 85 |'
- en: '| Ground-Truth |  |  | 95 | 70 | 85 | 80 |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| 真实数据 |  |  | 95 | 70 | 85 | 80 |'
- en: 'Table 8: Human Evaluation Percentage of Correct (ODD, KGD, TOD, QA) responses
    for In-Context Learning and Fine-Tuning with Retrieved (top-3) and Gold (ground-truth)
    knowledge, on Llama2[C] and Mistral[I], for different dialogue types: Open-Domain
    Dialogues (ODDs), Knowledge Grounded Dialogues (KGDs), Task-Oriented Dialogues
    (TODs), and Question Answering (QA).'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 表8：在人类评估中，对于不同对话类型（开放领域对话（ODD）、知识基础对话（KGD）、任务导向对话（TOD）和问答（QA）），Llama2[C] 和 Mistral[I]
    在上下文学习和微调中，检索（前3名）和黄金（真实）知识的正确响应百分比。
