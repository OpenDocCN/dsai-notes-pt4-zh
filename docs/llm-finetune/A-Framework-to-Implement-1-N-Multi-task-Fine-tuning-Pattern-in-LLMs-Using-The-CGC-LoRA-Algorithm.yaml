- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:39:05'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:39:05
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: A Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The
    CGC-LoRA Algorithm
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 LLMs 中使用 CGC-LoRA 算法实现 1+N 多任务微调模式的框架
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2402.01684](https://ar5iv.labs.arxiv.org/html/2402.01684)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2402.01684](https://ar5iv.labs.arxiv.org/html/2402.01684)
- en: Chao Song
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Chao Song
- en: OPPO Research Institute
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: OPPO 研究院
- en: Shenzhen, Guangdong, China
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 中国广东省深圳市
- en: songchao12@oppo.com
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: songchao12@oppo.com
- en: '&Zhihao Ye'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '&Zhihao Ye'
- en: OPPO Research Institute
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: OPPO 研究院
- en: Shenzhen, Guangdong, China
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 中国广东省深圳市
- en: yezhihao3@oppo.com
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: yezhihao3@oppo.com
- en: '&Qiqiang Lin'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '&Qiqiang Lin'
- en: OPPO Research Institute
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: OPPO 研究院
- en: Shenzhen, Guangdong, China
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 中国广东省深圳市
- en: linqiqiang1@oppo.com
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: linqiqiang1@oppo.com
- en: '&Qiuying Peng'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '&Qiuying Peng'
- en: OPPO Research Institute
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: OPPO 研究院
- en: Shenzhen, Guangdong, China
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 中国广东省深圳市
- en: pengqiuying@oppo.com
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: pengqiuying@oppo.com
- en: '&Jun Wang'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '&Jun Wang'
- en: OPPO Research Institute
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: OPPO 研究院
- en: Shenzhen, Guangdong, China
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 中国广东省深圳市
- en: wangjun7@oppo.com
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: wangjun7@oppo.com
- en: Abstract
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'With the productive evolution of large language models (LLMs) in the field
    of natural language processing (NLP), tons of effort has been made to effectively
    fine-tune common pre-trained LLMs to fulfill a variety of tasks in one or multiple
    specific domain (e.g., code interpreting, data analysis, medicine, and item recommendation).
    In practice, there are two prevailing ways, in which the adaptation can be achieved:
    (i) Multiple Independent Models: Pre-trained LLMs are fine-tuned a few times independently
    using the corresponding training samples from each task. (ii) An Integrated Model:
    Samples from all tasks are employed to fine-tune a pre-trianed LLM unitedly. The
    first scheme, in most cases, leads to high computing cost since pre-trained LLMs
    need to undergo fine-tuning process numerous times separately. Although various
    parameter efficient fine-tuning (PEFT) methods are proposed and they indeed can
    alleviate the issue in a sense, high computing cost is still prohibitively and
    unacceptable. More seriously, the knowledge of each task stays isolated and it
    cannot be shared across different tasks efficiently, which may lead to the sub-optimal
    overall performance of fine-tuned LLMs. Regarding the second method, although
    different kinds of loss functions are ingeniously designed, which sufficiently
    consider especial situations of multi-task learning (MTL), a promotive consequence
    of one task frequently causes the degradation of other one or ones, called the
    seesawing issue. To address the high computing cost and seesawing issue simultaneously,
    we propose a unified framework that implements a $1+N$ mutli-task fine-tuning
    pattern in LLMs using a novel Customized Gate Control (CGC) Low-rank Adaptation
    (LoRA) algorithm. In detail, “1" stands for a central LLM offering common and
    extensive capabilities in general cases while “$N$" denotes N sets of CGC-LoRA
    modules that provides adaptive abilities to behave well on multiple clusters of
    unseen tasks, respectively. Our work aims to take an advantage of both MTL (i.e.,
    CGC) and PEFT (i.e., LoRA) scheme. For a given cluster of tasks, we design an
    innovative layer that contains two types of experts as additional trainable parameters
    to make LoRA be compatible with MTL. In specific, task-common experts intend to
    capture the message that should be shared across distinct tasks while service
    objects of task-specific experts are specific tasks. In addition, we also nominate
    a Task-motivated Gate (TMG) function that determines contributions of each expert
    to different tasks and this function desires to organize experts in an efficient
    way. To comprehensively evaluate the proposed framework, we conduct well-designed
    experiments on two public datasets including a wide range of multi-tasks: (i)
    Prompt Chinese Biomedical Language Understanding Evaluation (PromptCBLUE). (ii)
    Firefly. Both datasets involve over a thousand samples of each sub-task. The experimental
    results demonstrate that the unified framework with CGC-LoRA modules achieves
    higher evaluation scores than all benchmarks on both two datasets.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大型语言模型（LLMs）在自然语言处理（NLP）领域的生产性进化，已经投入大量精力有效地微调常见的预训练LLMs，以满足一个或多个特定领域的各种任务（例如，代码解释、数据分析、医学和项目推荐）。在实践中，适配可以通过两种主要方式实现：（i）多个独立模型：预训练LLMs通过使用来自每个任务的相应训练样本进行几次独立微调。（ii）集成模型：使用所有任务的样本来统一微调一个预训练LLM。第一种方案在大多数情况下会导致较高的计算成本，因为预训练LLMs需要多次单独进行微调。尽管提出了各种参数高效微调（PEFT）方法，它们确实在某种程度上缓解了这一问题，但高计算成本仍然不可接受。更严重的是，每个任务的知识保持孤立，无法在不同任务之间有效共享，这可能导致微调LLMs的整体性能次优。关于第二种方法，尽管设计了不同种类的损失函数，充分考虑了多任务学习（MTL）的特殊情况，但一个任务的积极结果往往会导致其他任务的性能下降，这被称为“跷跷板”问题。为了解决高计算成本和跷跷板问题，我们提出了一个统一框架，该框架实现了一个$1+N$多任务微调模式，使用一种新型的定制化门控控制（CGC）低秩适应（LoRA）算法。具体来说，“1”代表一个中央LLM，提供一般情况下的通用和广泛能力，而“$N$”表示N组CGC-LoRA模块，分别为多个未见任务的不同集群提供适应能力。我们的工作旨在兼顾MTL（即CGC）和PEFT（即LoRA）方案的优势。对于给定的任务集群，我们设计了一种创新的层，其中包含两种类型的专家作为额外的可训练参数，以使LoRA能够兼容MTL。具体来说，任务共同专家旨在捕获应在不同任务之间共享的信息，而任务特定专家的服务对象是特定任务。此外，我们还提出了一种任务驱动门控（TMG）函数，确定每个专家对不同任务的贡献，该函数旨在以高效的方式组织专家。为了全面评估提出的框架，我们在两个公开数据集上进行了精心设计的实验，包括广泛的多任务：（i）Prompt中文生物医学语言理解评估（PromptCBLUE）。
    （ii）Firefly。两个数据集都涉及每个子任务的超过一千个样本。实验结果表明，具有CGC-LoRA模块的统一框架在两个数据集上均比所有基准获得更高的评估分数。
- en: '*K*eywords Multi-task Learning  $\cdot$ Parameter Efficient Fine-tuning  $\cdot$
    Large Language Model  $\cdot$ Customized Gate Control'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*K*eywords 多任务学习  $\cdot$ 参数高效微调  $\cdot$ 大型语言模型  $\cdot$ 定制化门控控制'
- en: 1 Introduction
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Large language models (LLMs) have made great progress recent two years [[1](#bib.bib1),
    [2](#bib.bib2), [3](#bib.bib3)] and numerous versions of LLMs, namely, ChatGPT
    [[4](#bib.bib4), [5](#bib.bib5)], LlaMa [[6](#bib.bib6)], ERNIE [[7](#bib.bib7)],
    and ChatGLM [[8](#bib.bib8)], sprung up. Worldwide high-tech companies and non-profit
    research institutes are paying significant attention to the evolution of LLMs
    since they have already shown typically impressive performance on varied applications.
    For example, Wang and Thai in [[9](#bib.bib9), [10](#bib.bib10)] demonstrate that
    LLMs get outstanding achievements on document-level machine translation and meanwhile
    LLMs is proved by [[11](#bib.bib11), [12](#bib.bib12)] to be equipped with dramatic
    multilingual learning capability. Besides, LLMs present remarkable talent on multi-modal
    operation, such as precisely producing websites from handwritten text and determining
    humorous components within images [[13](#bib.bib13)]. As for recommendation system,
    LLMs also indicates a non-negligible potential on a variety of tasks, including
    sequential recommendation, rating prediction, explanation generation, review summary,
    direct recommendation [[14](#bib.bib14), [15](#bib.bib15), [16](#bib.bib16)].
    Lastly but even more incredibly, Wei and Huang in [[17](#bib.bib17), [18](#bib.bib18)]
    announce that the reasoning ability of LLMs can even be elicited by a chain-of-thought
    (CoT) algorithm.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）在最近两年取得了巨大的进展[[1](#bib.bib1), [2](#bib.bib2), [3](#bib.bib3)]，众多版本的LLMs相继出现，包括ChatGPT
    [[4](#bib.bib4), [5](#bib.bib5)]、LlaMa [[6](#bib.bib6)]、ERNIE [[7](#bib.bib7)]和ChatGLM
    [[8](#bib.bib8)]。全球的高科技公司和非营利研究机构对LLMs的演变给予了重要关注，因为它们在各种应用中已经展示了典型的出色性能。例如，Wang和Thai在[[9](#bib.bib9),
    [10](#bib.bib10)]中证明了LLMs在文档级机器翻译中取得了卓越成就，同时[[11](#bib.bib11), [12](#bib.bib12)]的研究表明LLMs具备显著的多语言学习能力。此外，LLMs在多模态操作方面也表现出色，例如从手写文本中精确生成网站，以及识别图像中的幽默成分[[13](#bib.bib13)]。至于推荐系统，LLMs在各种任务中也显示出不可忽视的潜力，包括序列推荐、评分预测、解释生成、评论总结和直接推荐[[14](#bib.bib14),
    [15](#bib.bib15), [16](#bib.bib16)]。最后，Wei和Huang在[[17](#bib.bib17), [18](#bib.bib18)]中宣布，LLMs的推理能力甚至可以通过链式思维（CoT）算法被激发。
- en: The majority of LLMs, especially for those extraodinarily authoritative ones
    like ChatGPT and LlaMa, are pre-trained on general purposes using universal data
    [[5](#bib.bib5), [4](#bib.bib4), [6](#bib.bib6)]. Although the few-shot learning
    and even zero-shot learning capability of LLMs can be stimulated via in-context
    learning [[19](#bib.bib19), [20](#bib.bib20), [21](#bib.bib21)], the adaptation
    to a specific territory by fine-tuning is consistently favourable [[22](#bib.bib22),
    [23](#bib.bib23)]. For instance, Wang in [[22](#bib.bib22)] determines that fine-tuned
    large language model, named after Hua Tuo, outperforms the original LlaMa on Chinese
    medical knowledge. Additionally, CodeT5+ [[23](#bib.bib23)], a follow-on version
    of T5 fine-tuned on coding-related data, can achieve new SoTA results on the HumanEval,
    a specialized dataset on coding-related tasks [[24](#bib.bib24)], against other
    fundamental pre-trained LLMs including the basic version of T5 model. Therefore,
    in this work, we engage in the open-source LLMs and fine-tune them with task-specific
    datasets.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数LLMs，尤其是像ChatGPT和LlaMa这样极具权威性的模型，都是使用通用数据进行预训练的[[5](#bib.bib5), [4](#bib.bib4),
    [6](#bib.bib6)]。虽然LLMs的少量学习甚至零-shot学习能力可以通过上下文学习进行激发[[19](#bib.bib19), [20](#bib.bib20),
    [21](#bib.bib21)]，但通过微调适应特定领域始终是有利的[[22](#bib.bib22), [23](#bib.bib23)]。例如，Wang在[[22](#bib.bib22)]中确定，微调的大型语言模型（以华佗命名）在中文医学知识上优于原始的LlaMa。此外，CodeT5+
    [[23](#bib.bib23)]，作为T5的后续版本，经过编程相关数据的微调，在专门的编程任务数据集HumanEval [[24](#bib.bib24)]上达到了新的SoTA结果，超越了包括基本版本T5模型在内的其他基础预训练LLMs。因此，在这项工作中，我们将涉足开源LLMs，并使用特定任务的数据集进行微调。
- en: 'To a great extent, two inevitable dilemmas will occur when applying fine-tuning
    process to pre-trained LLMs. Firstly, a certain field, in most situations, involves
    a large numbers of heterogeneous tasks and consequently, a general fine-tuned
    LLMs cannot cover all tasks completely, called Various Task Impact [[2](#bib.bib2),
    [25](#bib.bib25)]. Considering the real-world advertisement recommendation area,
    it encompasses a wide range of assignments, like sequential recommendation, rating
    prediction, explanation generation, review summary, direct recommendation, etc.,
    and these diverse sub-tasks usually have objectives of similarity at different
    levels and even of conflict [[14](#bib.bib14), [16](#bib.bib16)]. To overcome
    this challenge, two feasible solutions are presented: (i) Multiple Independent
    Models: Fine-tuning an independent model for each particular task is practical,
    however, this strategy appeals considerable professional knowledge and a mass
    of labor. Also, information is precisely isolated and they cannot be shared across
    each task smoothly [[26](#bib.bib26), [27](#bib.bib27)]. What is more important,
    full parameters of a few fine-tuned LLMs for different tasks need to be saved
    that is unreasonable and even absurd, especially considering applications on mobile
    device due to the memory limitation. (ii) An Integrated Model: Fine-tuning an
    integrated model using samples from all tasks simultaneously can solve the information
    isolation and memory limitation problems mentioned above. As for this strategy,
    although knowledge is not segregated, at least in theory, the seesawing problem
    is frequently reported and it signifies that the enhancement of one task leads
    to the degradation of others [[26](#bib.bib26), [27](#bib.bib27)]. Secondly, High
    Computing Cost is another challenge. Since the LLMs having billions of parameters
    dominate nearly all areas, fine-tuning full parameters becomes extremely costly
    and utopian [[5](#bib.bib5), [7](#bib.bib7)]. Even if any companies or institutes
    can afford such astronomical computing cost, a limited amount of available data
    will ultimately cause over-fitting [[28](#bib.bib28)]. As a result, to have LLMs
    work excellently on applications of a wide variety, these two problems are urgently
    to be solved preferably.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在对预训练的LLM（大语言模型）应用微调过程时，两个不可避免的困境会发生。首先，大多数情况下，某一领域涉及大量异质任务，因此，一般的微调LLM无法完全覆盖所有任务，这被称为各种任务影响[[2](#bib.bib2),
    [25](#bib.bib25)]。以现实中的广告推荐领域为例，它包括了广泛的任务，如序列推荐、评分预测、解释生成、评论总结、直接推荐等，这些多样的子任务通常在不同层次上有相似的目标，甚至存在冲突[[14](#bib.bib14),
    [16](#bib.bib16)]。为解决这一挑战，提出了两种可行的解决方案：（i）多个独立模型：为每个特定任务微调一个独立模型是实际可行的，然而，这一策略需要大量的专业知识和劳动。同时，信息被严格隔离，任务之间不能顺利共享[[26](#bib.bib26),
    [27](#bib.bib27)]。更重要的是，为不同任务微调的多个LLM的全部参数需要保存，这在内存有限的移动设备上尤其不合理，甚至显得荒谬。（ii）集成模型：使用来自所有任务的样本同时微调一个集成模型可以解决上述信息隔离和内存限制问题。对于这种策略，尽管知识没有被隔离，至少理论上，摆锤效应问题经常被报告，这意味着一个任务的提升会导致其他任务的退化[[26](#bib.bib26),
    [27](#bib.bib27)]。其次，高计算成本是另一个挑战。由于LLM拥有数十亿参数，几乎主导了所有领域，对全部参数进行微调变得极其昂贵且理想化[[5](#bib.bib5),
    [7](#bib.bib7)]。即使有公司或机构能够承担如此天文数字的计算成本，有限的数据量最终会导致过拟合[[28](#bib.bib28)]。因此，为了使LLM在各种应用中表现优异，这两个问题亟待解决。
- en: Considering the Various Task Impact, different kinds of multi-task learning
    (MTL) models have been proposed [[29](#bib.bib29), [30](#bib.bib30)], among which
    hard-parameter-sharing structure is designed primarily [[31](#bib.bib31)]. Although
    it, to some degree, promotes knowledge circulation among each task, negative transfer
    problem is exposed as parameters are straightforwardly and even wildly shared.
    To solve this issue, cross-stitch network [[32](#bib.bib32)] and sluice network
    [[33](#bib.bib33)] are announced by Misra and Ruder12, separately. Both networks
    can merge information from various tasks selectively as the combination is controlled
    linearly by a set of weights. Nonetheless, since weights stay the same for all
    samples, the seesawing phenomenon cannot be completely addressed. Next, the gate
    structure and both cross- and self-attention mechanisms are demonstrated to further
    solved the seesawing issue. Additionally, mixture-of-expert (MOE) related models
    [[34](#bib.bib34), [26](#bib.bib26)] first proposes to combine task-common experts
    by fusing the gate module and the attention module. In particular, both expert
    and attention modules are shared among all tasks while no task-specific module
    is scheduled. In contrast, Tang in [[27](#bib.bib27)] releases a customized gate
    control (CGC) module, which separates task-common and task-specific experts explicitly
    to keep clear of parameter disagreement caused by complicated correlation among
    tasks. Such an explicit design in virtue of professional prior knowledge is conducive
    to determine the convergence direction more accurately in practice [[35](#bib.bib35)].
    Besides the Various Task Impact problem, the High Computing Cost is another roadblock
    when MTL frameworks are applied to fine-tune LLMs since current frameworks are
    principally appropriate to full-parameter fine-tuning algorithms. Fortunately,
    a class of fine-tuning methods called parameter efficient fine-tuning (PEFT),
    which freeze parameters of pre-trained LLMs and instead only tune a delimited
    quantity of additional parameters, are explored to solve the high computing cost
    issue [[36](#bib.bib36), [37](#bib.bib37)]. Among proposed PEFT approaches, low-rank
    adaptation (LoRA) is a typical one and it suggests to just train a set of paired
    low-rank matrices to provide LLMs with adaptation capacity[[36](#bib.bib36)].
    However, making PEFT methods be compatible with MTL frameworks is still an open
    question [[25](#bib.bib25)].
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到各种任务的影响，已经提出了不同类型的多任务学习（MTL）模型[[29](#bib.bib29), [30](#bib.bib30)]，其中硬参数共享结构是主要设计之一[[31](#bib.bib31)]。虽然在一定程度上促进了各任务之间的知识流通，但由于参数直接甚至广泛地共享，负迁移问题也随之暴露。为了解决这个问题，Misra
    和 Ruder12分别提出了交叉缝合网络 [[32](#bib.bib32)] 和水闸网络 [[33](#bib.bib33)]。这两种网络可以选择性地合并来自不同任务的信息，因为组合由一组权重线性控制。然而，由于所有样本的权重保持不变，摆动现象仍未能完全解决。接下来，门控结构和交叉注意力以及自注意力机制被展示出来，以进一步解决摆动问题。此外，混合专家（MOE）相关模型
    [[34](#bib.bib34), [26](#bib.bib26)] 首次提出通过融合门控模块和注意力模块来结合任务通用专家。特别是，专家和注意力模块在所有任务中共享，而没有安排特定于任务的模块。相反，Tang
    在 [[27](#bib.bib27)] 中发布了一个定制的门控控制（CGC）模块，该模块明确区分了任务通用专家和任务特定专家，以避免由于任务间复杂相关性引起的参数冲突。凭借专业的先验知识，这种明确的设计有助于在实践中更准确地确定收敛方向
    [[35](#bib.bib35)]。除了各种任务影响的问题，高计算成本是另一个障碍，因为当前的 MTL 框架主要适用于全参数微调算法。幸运的是，一类称为参数高效微调（PEFT）的方法被提出，以解决高计算成本问题，该方法冻结预训练
    LLM 的参数，而仅微调一定数量的附加参数 [[36](#bib.bib36), [37](#bib.bib37)]。在提出的 PEFT 方法中，低秩适配（LoRA）是一种典型方法，它建议仅训练一组配对的低秩矩阵，以为
    LLM 提供适配能力 [[36](#bib.bib36)]。然而，使 PEFT 方法与 MTL 框架兼容仍然是一个未解问题 [[25](#bib.bib25)]。
- en: 'To solve the issues of Various Task Impact and High Computing Cost simultaneously
    by integrating MTL and PEFT, we proposed a universal framework to implement $1+N$
    multi-task fine-tuning pattern in LLMs. Specifically, a large range of tasks are
    divided into multiple clusters based on the professional prior knowledge or Inter-Task
    Affinity proposed by [[38](#bib.bib38)] and for a certain cluster, a central LLM
    is fine-tuned to adjust to these tasks by LoRA of a multi-task edition. This central
    LLM with sets of plug-in LoRA modules serves as the ultimate model that can handle
    diverse tasks from different fields with ease. As an essential component of the
    whole framework, we further propose an innovative unified LoRA and CGC structure,
    name after CGC-LoRA, inspired by MOE-LoRA [[25](#bib.bib25)] and it provides the
    framework with an effective and efficient fine-tuning performance in MTL situations.
    In detail, thanks to the explicit separation of task-common and task-specific
    experts, CGC is proved to have a practically preferred convergence behavior [[27](#bib.bib27)]
    and we demonstrate that such a valuable character can be smoothly transferred
    to the CGC-LoRA architecture. As the supplement to the basic edition of LoRA where
    a singular set of paired low-rank matrices are fine-tuned, CGC-LoRA incorporates
    multiple sets of paired low-rank matrices that stand for task-common and task-shared
    experts. Moreover, to keep the counts of trainable parameters the same, the summation
    of rank of task-common and task-specific matrices is equal to the rank of the
    original LoRA scheme. Furthermore, to advance the fusion capacity of experts,
    a task motivated gate function is proposed to adaptively determine the contribution
    of those two types of experts to each task only based on the task ID of the input
    sample. Eventually, the contributions of this work are summarized as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了同时解决各种任务影响和高计算成本的问题，我们提出了一种通用框架，以在LLMs中实现$1+N$多任务微调模式。具体而言，将大量任务基于专业先验知识或[[38](#bib.bib38)]提出的任务间亲和性分为多个簇，对于某个簇，通过多任务版本的LoRA对中央LLM进行微调，以适应这些任务。这个配备了插件LoRA模块的中央LLM作为最终模型，可以轻松处理来自不同领域的各种任务。作为整个框架的重要组成部分，我们进一步提出了一种创新的统一LoRA和CGC结构，命名为CGC-LoRA，受到MOE-LoRA
    [[25](#bib.bib25)]的启发，它为框架在MTL情况下提供了有效且高效的微调性能。详细来说，由于任务通用专家和任务特定专家的明确分离，CGC被证明具有实际优越的收敛行为[[27](#bib.bib27)]，我们展示了这种宝贵特性可以顺利转移到CGC-LoRA架构中。作为LoRA基本版的补充，CGC-LoRA结合了多组配对的低秩矩阵，代表任务通用和任务共享专家。此外，为了保持可训练参数的数量不变，任务通用和任务特定矩阵的秩之和等于原始LoRA方案的秩。此外，为了提升专家的融合能力，提出了一种任务驱动的门控函数，根据输入样本的任务ID自适应地确定这两种类型专家对每个任务的贡献。最终，本工作的贡献总结如下：
- en: •
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We announce a framework to implement $1+N$ multi-task fine-tuning pattern in
    LLMs, which can equip general pre-trained LLMs with adaptation to a large range
    of unseen tasks. It is worthy noting that this is a universal framework and it
    can be compatible with LoRA of any multi-task editions (e.g., MOE-LoRA [[25](#bib.bib25)],
    LoRAHub [[39](#bib.bib39)], and proposed CGC-LoRA).
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们宣布了一个框架，用于在LLMs中实现$1+N$多任务微调模式，它可以使一般预训练的LLMs适应大量未见过的任务。值得注意的是，这是一个通用框架，可以与任何多任务版本的LoRA（例如MOE-LoRA
    [[25](#bib.bib25)]，LoRAHub [[39](#bib.bib39)]和提议的CGC-LoRA）兼容。
- en: •
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We associate the power of both CGC structure and LoRA scheme by designing an
    ingenious unified MTL PEFT architecture. Besides, to lubricate the cooperation
    between task-common and task-specific experts, a task motivated gate function
    is proposed to regulate the weights of all experts and completely, determine the
    distinct contributions of experts to each task.
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们通过设计一个巧妙的统一MTL PEFT架构，结合了CGC结构和LoRA方案的优势。此外，为了促进任务通用专家和任务特定专家之间的合作，提出了一种任务驱动的门控函数，以调节所有专家的权重，并完全确定专家对每个任务的不同贡献。
- en: •
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'We conduct comprehensive experiments on two public multi-task datasets: (i)
    the Prompt Chinese Biomedical Language Understanding Evaluation (PromptCBLUE)
    dataset [[40](#bib.bib40), [41](#bib.bib41)]; (ii) the Firefly dataset [[42](#bib.bib42)].
    The experimental results demonstrate the superiority of the proposed framework
    over other long-tested baselines. To the best of our knowledge, this paper represents
    the first effort to evaluate the dominance of the framework equipped with a MTL-PEFT-unified
    structure for LLM-driven models on vast of applications using multiple public
    datasets.'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们在两个公共多任务数据集上进行了全面实验：（i）Prompt 中文生物医学语言理解评估 (PromptCBLUE) 数据集 [[40](#bib.bib40),
    [41](#bib.bib41)];（ii）Firefly 数据集 [[42](#bib.bib42)]。实验结果展示了所提框架相对于其他长期测试的基准的优越性。据我们所知，本论文首次评估了装备有
    MTL-PEFT 统一结构的框架在使用多个公共数据集的广泛应用中的主导地位。
- en: 2 Preliminary
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 初步
- en: In this section, a compact introduction to how LLMs can be applied to different
    kinds of applications in various domains is represented. First, an overview of
    the proposed framework that is to implement $1+N$ multi-task fine-tuning pattern
    in LLM is offered in Section [2.1](#S2.SS1 "2.1 An Overview of the Framework ‣
    2 Preliminary ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern in
    LLMs Using The CGC-LoRA Algorithm") and next, we describe the details of input
    pre-processing along with those of output post-processing in Section [2.2](#S2.SS2
    "2.2 Input and Output Modification ‣ 2 Preliminary ‣ A Framework to Implement
    1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm").
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，介绍了 LLM 如何应用于各个领域的不同应用的简要介绍。首先，在第 [2.1](#S2.SS1 "2.1 框架概述 ‣ 2 初步 ‣ 实现 $1+N$
    多任务微调模式的框架") 节中提供了所提框架的概述，该框架旨在实现 LLM 中的 $1+N$ 多任务微调模式；接下来，我们在第 [2.2](#S2.SS2
    "2.2 输入与输出修改 ‣ 2 初步 ‣ 实现 $1+N$ 多任务微调模式的框架") 节中描述了输入预处理和输出后处理的详细信息。
- en: '![Refer to caption](img/8fd1cfdbb3828d3f14908fed3286bdea.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8fd1cfdbb3828d3f14908fed3286bdea.png)'
- en: 'Figure 1: An overview of the proposed framework to implement $1+N$ multi-task
    fine-tuning pattern in LLMs. The first step is to divide a variety of tasks into
    $N$ clusters based on professional prior information or Inter-Task Affinity [[38](#bib.bib38)]
    and the second step is to adapt a central LLM to each cluster of tasks using the
    LoRA fine-tuning algorithm of multi-task editions (e.g., MOE-LoRA, LoRAHub, and
    CGC-LoRA).'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：所提框架的概述，用于实现 LLM 中的 $1+N$ 多任务微调模式。第一步是根据专业先验信息或任务间亲和度 [[38](#bib.bib38)]
    将各种任务分为 $N$ 个集群，第二步是使用多任务版的 LoRA 微调算法（例如，MOE-LoRA、LoRAHub 和 CGC-LoRA）将中心 LLM 适配到每个任务集群中。
- en: 2.1 An Overview of the Framework
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 框架概述
- en: 'In this section, we present an overview of the proposed framework. It introduces
    how the framework implements $1+N$ multi-task fine-tuning pattern in LLMs to adapt
    a central LLM to clusters of tasks using the LoRA fine-tuning algorithm of multi-task
    editions (e.g., MOE-LoRA, LoRAHub, and CGC-LoRA). The entire framework can be
    divided into two primary parts: (i) Tasks clustering: As depicted in Figure [1](#S2.F1
    "Figure 1 ‣ 2 Preliminary ‣ A Framework to Implement 1+N Multi-task Fine-tuning
    Pattern in LLMs Using The CGC-LoRA Algorithm"), a LLM-driven model may face with
    a variety of tasks from different domains (e.g., code interpreting, data analysis,
    medicine, and item recommendation). Among them, tasks in certain fields highly
    have strong similarity, like code interpreting and data analysis while tasks in
    other fields, such as data analysis and item recommendation, almost have no relations
    and even conflicts. According to the assumptions in MTL, information sharing among
    related tasks can, to some degree, relieve the negative effect from lack of data
    and also benefit the effectiveness and efficiency of model training process and
    vice versa. As a consequence, tasks are grouped into $N$ clusters at the first
    stage. (ii) Adaptation to multiple clusters of tasks: Following tasks clustering,
    the LoRA fine-tuning algorithm of multi-task editions is applied to each cluster
    and finally a central LLM with $N$ sets of multi-task LoRA modules serves as an
    integrated model that can offer service to various tasks from all domains by switching
    to the corresponding module. Since the fine-tuning process for each cluster is
    repetitive, we set $N$ to be 1 in the remaining part for convenience and also
    without loss of generality.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们展示了提出的框架概述。它介绍了该框架如何在 LLMs 中实现 $1+N$ 多任务微调模式，以适应通过 LoRA 微调算法的集群任务（如 MOE-LoRA、LoRAHub
    和 CGC-LoRA）。整个框架可以分为两个主要部分：（i）任务聚类：如图 [1](#S2.F1 "图 1 ‣ 2 初步 ‣ 使用 CGC-LoRA 算法在
    LLMs 中实现 1+N 多任务微调模式")所示，LLM 驱动的模型可能面临来自不同领域的各种任务（例如代码解释、数据分析、医学和项目推荐）。其中，某些领域的任务高度相似，如代码解释和数据分析，而其他领域的任务，如数据分析和项目推荐，几乎没有关系甚至存在冲突。根据
    MTL 中的假设，相关任务之间的信息共享在一定程度上可以缓解数据不足的负面影响，并有利于模型训练过程的有效性和效率，反之亦然。因此，任务在第一阶段被分为 $N$
    个集群。（ii）对多个任务集群的适应：在任务聚类之后，使用多任务版本的 LoRA 微调算法对每个集群进行应用，最终一个具有 $N$ 组多任务 LoRA 模块的中央
    LLM 作为一个集成模型，可以通过切换到相应模块来为来自所有领域的各种任务提供服务。由于每个集群的微调过程是重复的，我们为了方便起见将 $N$ 设为 1，并且没有失去普遍性。
- en: '![Refer to caption](img/0a6f5e961c73e7b6d93d2965a100c13a.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/0a6f5e961c73e7b6d93d2965a100c13a.png)'
- en: 'Figure 2: A name entity recognition (NER) example to illustrate the whole pipeline
    of applications by large language models (LLMs). It includes the pre-processing
    to a conventional input, the textual answer of a LLM, the post-processing to extract
    final results.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：一个命名实体识别（NER）示例，用以说明大型语言模型（LLMs）应用的整个流程。它包括对传统输入的预处理、LLM 的文本回答以及提取最终结果的后处理。
- en: 2.2 Input and Output Modification
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 输入与输出修改
- en: Except for multi-modal LLMs, the input and output of LLMs should be in text
    pattern [[14](#bib.bib14), [40](#bib.bib40), [41](#bib.bib41)], which leads to
    a typically different prototype from traditional models. As a consequence, there
    is a prerequisite to customize the input/output format to be compatible with LLMs.
    As shown in Figure [2](#S2.F2 "Figure 2 ‣ 2.1 An Overview of the Framework ‣ 2
    Preliminary ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs
    Using The CGC-LoRA Algorithm"), Name Entity Recognition (NER) task [[43](#bib.bib43)],
    as a concrete example, suggests the details of the reformulation of input and
    output.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 除了多模态 LLMs，LLMs 的输入和输出应为文本格式 [[14](#bib.bib14), [40](#bib.bib40), [41](#bib.bib41)]，这导致其原型与传统模型有显著不同。因此，需要自定义输入/输出格式以与
    LLMs 兼容。如图 [2](#S2.F2 "图 2 ‣ 2.1 框架概述 ‣ 2 初步 ‣ 使用 CGC-LoRA 算法在 LLMs 中实现 1+N 多任务微调模式")所示，命名实体识别（NER）任务
    [[43](#bib.bib43)] 作为一个具体示例，展示了输入和输出重新制定的细节。
- en: 'Input Modification. Besides the initial textual input, auxiliary instruction
    templates that can guide LLMs in accomplishing the given task should be attached.
    In particular, as characterized in Figure [2](#S2.F2 "Figure 2 ‣ 2.1 An Overview
    of the Framework ‣ 2 Preliminary ‣ A Framework to Implement 1+N Multi-task Fine-tuning
    Pattern in LLMs Using The CGC-LoRA Algorithm"), the input is formatted as: “Please
    recognize the name entity in the following sentence: [Text]”, represented by $I_{modified}$,
    where [Text] acts as a placeholder for the original input, denoted as $I_{original}$.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 输入修改。除了初始文本输入之外，还应附加能够指导LLMs完成给定任务的辅助指令模板。特别是，如图[2](#S2.F2 "Figure 2 ‣ 2.1 An
    Overview of the Framework ‣ 2 Preliminary ‣ A Framework to Implement 1+N Multi-task
    Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm")所示，输入被格式化为：“请识别以下句子中的命名实体：[Text]”，表示为$I_{modified}$，其中[Text]作为原始输入的占位符，记作$I_{original}$。
- en: 'Output Modification. Outputs of traditional models in natural language processing
    (NLP) are commonly at word-level [[44](#bib.bib44), [45](#bib.bib45)] and as for
    LLMs, we integrate target entities $\{e_{1},...,e_{N_{e}}\}$ into linguistic texts.
    As shown in Figure [2](#S2.F2 "Figure 2 ‣ 2.1 An Overview of the Framework ‣ 2
    Preliminary ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs
    Using The CGC-LoRA Algorithm"), the output of NER task can be formatted as following:
    “The text has the following entities: $e_{1},...,e_{N_{e}}$”, represented by $O_{sentence}$.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 输出修改。传统的自然语言处理（NLP）模型的输出通常是按词级别的[[44](#bib.bib44), [45](#bib.bib45)]，而对于LLMs，我们将目标实体$\{e_{1},...,e_{N_{e}}\}$整合到语言文本中。如图[2](#S2.F2
    "Figure 2 ‣ 2.1 An Overview of the Framework ‣ 2 Preliminary ‣ A Framework to
    Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm")所示，NER任务的输出可以格式化为：“文本包含以下实体：$e_{1},...,e_{N_{e}}$”，表示为$O_{sentence}$。
- en: 'In summary, the whole paradigm can be described as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，整个范式可以描述如下：
- en: '|  | $1$2 |  | (1) |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (1) |'
- en: With the transformation of input and output, the pre-trained LLMs, such as LlaMA
    [[6](#bib.bib6)], ChatGLM [[8](#bib.bib8)], etc., can be straightforwardly fed
    by purely lingual data. After fine-tuning, LLMs can routinely generate answers
    by following the pipeline formulated as Equation ([1](#S2.E1 "In 2.2 Input and
    Output Modification ‣ 2 Preliminary ‣ A Framework to Implement 1+N Multi-task
    Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm")).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 随着输入和输出的转变，像LlaMA [[6](#bib.bib6)]、ChatGLM [[8](#bib.bib8)]等预训练的LLMs可以通过纯语言数据直接进行喂入。在微调后，LLMs可以通过遵循公式（[1](#S2.E1
    "In 2.2 Input and Output Modification ‣ 2 Preliminary ‣ A Framework to Implement
    1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm")）制定的流程来常规地生成答案。
- en: 3 Problem Formulation
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 问题表述
- en: 'As described in Section [2.1](#S2.SS1 "2.1 An Overview of the Framework ‣ 2
    Preliminary ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs
    Using The CGC-LoRA Algorithm"), sorts of territories often envelop a variety of
    tasks in practice, for example, (i) Item Recommendation: Sequential recommendation,
    rating prediction, explanation generation, etc. (ii) Medical Application: Name
    entity recognition, attribute extraction, report generation, etc. (iii) Text Generation:
    Lyric generation, composition generation, poetry generation, etc. The purpose
    of this work is to fine-tune a pre-trained central LLM to meet the requirements
    from multiple domains, each of which contains numerous sub-tasks. Considering
    that the numbers of clusters has been set to $N=1$ for convenience, a cluster
    of tasks are denoted as $\mathbb{T}=\{\mathcal{T}_{1},...,\mathcal{T}_{i},...,\mathcal{T}_{N_{T}}\}$
    while the input and output data of $\mathcal{T}_{i}$ can be described as $\mathcal{I}_{i}=\{I^{\mathcal{T}_{i}}_{k}\}^{N_{\mathcal{T}_{i}}}_{k=1}$
    and $\mathcal{O}_{i}=\{O^{\mathcal{T}_{i}}_{k}\}^{N_{\mathcal{T}_{i}}}_{k=1}$,
    respectively. In specific, $N_{\mathcal{T}_{i}}$ stands for the numbers of paired
    data (i.e., linguistic input and output data) of $\mathcal{T}_{i}$. To be brief,
    the superscript $\mathcal{T}_{i}$ will be left out in the following essay. In
    detailed, the problem of multi-task fine-tuning can be formulated as: Given the
    paired input and output data of all tasks $\{I_{i},O_{i}\}^{N_{T}}_{i=1}$, the
    target is to optimize the parameters $\Theta$ of a pre-trained LLM to achieve
    the shining behavior among all tasks of distinguished similarity and it is noteworthy
    that $\Theta$ alternately stands for full parameters or selective ones.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如第[2.1](#S2.SS1 "2.1 An Overview of the Framework ‣ 2 Preliminary ‣ A Framework
    to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm")节所述，实际中各种领域通常涉及多种任务，例如，（i）项目推荐：序列推荐、评分预测、解释生成等。（ii）医疗应用：命名实体识别、属性提取、报告生成等。（iii）文本生成：歌词生成、作文生成、诗歌生成等。该工作的目的是对预训练的中央LLM进行微调，以满足来自多个领域的需求，每个领域包含众多子任务。考虑到为了方便，集群数已设置为
    $N=1$，一个任务集群表示为 $\mathbb{T}=\{\mathcal{T}_{1},...,\mathcal{T}_{i},...,\mathcal{T}_{N_{T}}\}$，而
    $\mathcal{T}_{i}$ 的输入和输出数据可以分别描述为 $\mathcal{I}_{i}=\{I^{\mathcal{T}_{i}}_{k}\}^{N_{\mathcal{T}_{i}}}_{k=1}$
    和 $\mathcal{O}_{i}=\{O^{\mathcal{T}_{i}}_{k}\}^{N_{\mathcal{T}_{i}}}_{k=1}$。具体来说，$N_{\mathcal{T}_{i}}$
    表示 $\mathcal{T}_{i}$ 的配对数据数量（即语言输入和输出数据）。简而言之，下面的论文将省略上标 $\mathcal{T}_{i}$。详细来说，多任务微调的问题可以表述为：给定所有任务的配对输入和输出数据
    $\{I_{i},O_{i}\}^{N_{T}}_{i=1}$，目标是优化预训练LLM的参数 $\Theta$，以在所有具有显著相似性的任务中实现优异表现，值得注意的是，$\Theta$
    交替表示完整参数或选择性参数。
- en: 'Regarding the objective when fine-tuning the pre-trained LLMs, we straightforwardly
    apply a common one in the field of natural language processing (i.e., the conditional
    language modeling objective) after normalizing input and output data of all tasks
    into a steady linguistic format as detailed in Section [2.2](#S2.SS2 "2.2 Input
    and Output Modification ‣ 2 Preliminary ‣ A Framework to Implement 1+N Multi-task
    Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm"). Besides, in order
    to stimulate the information sharing across each task, all training samples are
    fed into the LLMs simultaneously and as a consequence, the objective function
    of LLMs fine-tuning in a multi-task case can be written as:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 关于微调预训练大语言模型（LLMs）的目标，我们直接采用了自然语言处理领域常用的条件语言建模目标，即在将所有任务的输入和输出数据标准化为稳定的语言格式后，如第[2.2](#S2.SS2
    "2.2 Input and Output Modification ‣ 2 Preliminary ‣ A Framework to Implement
    1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm")节所述。此外，为了促进各任务之间的信息共享，所有训练样本同时输入到LLMs中，因此，在多任务情况下，LLMs微调的目标函数可以写作：
- en: '|  | $1$2 |  | (2) |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (2) |'
- en: 4 CGC-LoRA
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 CGC-LoRA
- en: In this section, a comprehensive illustration of CGC-LoRA structure is represented.
    In Section [4.1](#S4.SS1 "4.1 Overview ‣ 4 CGC-LoRA ‣ A Framework to Implement
    1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm"), a description
    over the whole fine-tuning process is primarily conducted and as follows, Section
    [4.2](#S4.SS2 "4.2 CGC-LoRA ‣ 4 CGC-LoRA ‣ A Framework to Implement 1+N Multi-task
    Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm") characterizes how CGC-LoRA
    takes advantage of both CGC and LoRA scheme in detail. Subsequently, a prominent
    component of CGC-LoRA network (i.e., a task-motivated gate function), which controls
    the contribution of both task-common and task-specific experts to each task is
    illustrated in Section [4.3](#S4.SS3 "4.3 Task-motivated Gate Function ‣ 4 CGC-LoRA
    ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The
    CGC-LoRA Algorithm"). Finally, an elaborate definition of training and inference
    pipeline is given in Section [4.4](#S4.SS4 "4.4 Training and Inference ‣ 4 CGC-LoRA
    ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The
    CGC-LoRA Algorithm").
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，提供了CGC-LoRA结构的全面说明。在第[4.1](#S4.SS1 "4.1 Overview ‣ 4 CGC-LoRA ‣ A Framework
    to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm")节中，主要对整个微调过程进行了描述，如下所述，第[4.2](#S4.SS2
    "4.2 CGC-LoRA ‣ 4 CGC-LoRA ‣ A Framework to Implement 1+N Multi-task Fine-tuning
    Pattern in LLMs Using The CGC-LoRA Algorithm")节详细说明了CGC-LoRA如何利用CGC和LoRA方案。随后，第[4.3](#S4.SS3
    "4.3 Task-motivated Gate Function ‣ 4 CGC-LoRA ‣ A Framework to Implement 1+N
    Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm")节展示了CGC-LoRA网络的一个重要组成部分（即任务驱动的门控函数），该函数控制了任务通用和任务特定专家对每个任务的贡献。最后，第[4.4](#S4.SS4
    "4.4 Training and Inference ‣ 4 CGC-LoRA ‣ A Framework to Implement 1+N Multi-task
    Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm")节给出了训练和推理流程的详细定义。
- en: 4.1 Overview
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 概述
- en: 'As mentioned, parameter efficient fine-tuning (PEFT) algorithm provides an
    innovative way, in which LLMs can be fine-tuned productively and efficiently.
    More concretely, only parameters of additional paired low-rank matrices are trainable
    while primordial parameters of pre-trained LLMs stay frozen. The extra parameters
    offer updated knowledge to dense layers. Inspired by MOE-LoRA [[25](#bib.bib25)],
    our approach blends CGC network with LoRA strategy and the combination is attached
    to Query module, Key module, Value module, and dense layers in the Transformer
    architecture as displayed in Figure [3](#S4.F3 "Figure 3 ‣ 4.1 Overview ‣ 4 CGC-LoRA
    ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The
    CGC-LoRA Algorithm"). Furthermore, the proposed CGC-LoRA structure not only inherits
    the main advantage of PEFT algorithm (i.e., productiveness and efficiency) but
    also extends to solve the task variety problem and seesawing issue in multi-task
    learning (MTL) cases. Specifically, each CGC-LoRA layer incorporates two types
    of experts: (i) Task-common experts: They aim to capture conjunct knowledge across
    various tasks. (ii) Task-specific experts: Their responsibility is to extract
    specific information of each task. More details is depicted and elaborated in
    Figure [3](#S4.F3 "Figure 3 ‣ 4.1 Overview ‣ 4 CGC-LoRA ‣ A Framework to Implement
    1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm") and
    Section [4.2](#S4.SS2 "4.2 CGC-LoRA ‣ 4 CGC-LoRA ‣ A Framework to Implement 1+N
    Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm"), separately.
    Additionally, as an unimpressive but significant component of CGC-LoRA layer,
    a task-motivated gate module determines the contribution weights of two types
    of experts (i.e., task-common experts and task-specific experts) and more precisely,
    the outcome of each task-motivated gate only depends on task ID of each task rather
    than any other features of input samples. In Section [4.3](#S4.SS3 "4.3 Task-motivated
    Gate Function ‣ 4 CGC-LoRA ‣ A Framework to Implement 1+N Multi-task Fine-tuning
    Pattern in LLMs Using The CGC-LoRA Algorithm"), more details of how task-motivated
    gate modules are integrated into a CGC-LoRA layer can be found. Lastly, another
    implementation detail is worth noting that gate functions of all CGC-LoRA layers
    can be shared or independent, which, in a sense, influences the fitting ability
    of fine-tuned LLMs.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，参数高效微调（PEFT）算法提供了一种创新的方法，使得大规模语言模型（LLM）能够高效地进行微调。更具体地说，只有附加的低秩矩阵的参数是可训练的，而预训练LLM的原始参数保持固定。这些额外的参数为稠密层提供了更新的知识。受MOE-LoRA的启发[[25](#bib.bib25)]，我们的方法将CGC网络与LoRA策略相结合，并将该组合附加到Transformer架构中的Query模块、Key模块、Value模块和稠密层，如图[3](#S4.F3
    "图 3 ‣ 4.1 概述 ‣ 4 CGC-LoRA ‣ 使用CGC-LoRA算法在LLMs中实现1+N多任务微调模式的框架")所示。此外，所提议的CGC-LoRA结构不仅继承了PEFT算法的主要优点（即高效性和生产力），而且还扩展了解决任务多样性问题和多任务学习（MTL）中的拉锯问题。具体而言，每个CGC-LoRA层包含两种类型的专家：（i）任务共通专家：他们旨在捕捉不同任务之间的共同知识。（ii）任务特定专家：他们的责任是提取每个任务的特定信息。更多详细信息在图[3](#S4.F3
    "图 3 ‣ 4.1 概述 ‣ 4 CGC-LoRA ‣ 使用CGC-LoRA算法在LLMs中实现1+N多任务微调模式的框架")和第[4.2](#S4.SS2
    "4.2 CGC-LoRA ‣ 4 CGC-LoRA ‣ 使用CGC-LoRA算法在LLMs中实现1+N多任务微调模式的框架")节中分别描述和详细说明。此外，作为CGC-LoRA层的一个不起眼但重要的组件，任务驱动的门控模块决定了两种类型专家（即任务共通专家和任务特定专家）的贡献权重，更具体地说，每个任务驱动门控的结果仅取决于每个任务的任务ID，而不是输入样本的其他特征。在第[4.3](#S4.SS3
    "4.3 任务驱动门控功能 ‣ 4 CGC-LoRA ‣ 使用CGC-LoRA算法在LLMs中实现1+N多任务微调模式的框架")节中可以找到有关任务驱动门控模块如何集成到CGC-LoRA层中的更多细节。最后，另一个值得注意的实现细节是，所有CGC-LoRA层的门控功能可以是共享的或独立的，这在某种程度上影响了微调LLMs的拟合能力。
- en: '![Refer to caption](img/761d710d426919abd5e347e5efd7a592.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![参考图注](img/761d710d426919abd5e347e5efd7a592.png)'
- en: 'Figure 3: The detailed architecture of the proposed CGC-LoRA scheme. Specifically,
    the parameters of modules in blue are frozen while those of components in green,
    yellow, red are trainable during the fine-tuning process.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：所提议的CGC-LoRA方案的详细架构。具体而言，蓝色模块中的参数是固定的，而绿色、黄色和红色组件中的参数在微调过程中是可训练的。
- en: 4.2 CGC-LoRA
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 CGC-LoRA
- en: Thanks to the characteristic of both efficiency and effectiveness, Low-rank
    Adaptation (LoRA) gradually becomes a mainstream and prominent fine-tuning algorithm
    on Transformer-based networks [[36](#bib.bib36)]. Since the efficiency of our
    framework comes from the essential theorem of LoRA, we first briefly review its
    principle that can make the comprehension of the proposed CGC-LoRA be simpler.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 由于低秩适应（LoRA）既高效又有效的特性，LoRA逐渐成为基于Transformer网络的主流和显著的微调算法[[36](#bib.bib36)]。由于我们框架的效率来源于LoRA的基本定理，我们首先简要回顾其原理，以便对所提出的CGC-LoRA有更简单的理解。
- en: 'As for LoRA, a low-rank decomposition is applied to the parameters fine-tuning
    procedure in LLMs and more precisely, full-rank matrices that traditionally stands
    for full parameters are decomposed into paired low-rank matrices as the equation
    $\mathbf{W}_{0}+\Delta\mathbf{W}=\mathbf{W}_{0}+\mathbf{BA}$. It is worthy noting
    that $\mathbf{W}_{0}\in\mathbb{R}^{d_{in}\times d_{out}}$ denotes the parameter
    matrices of a pre-trained central LLMs while $\Delta\mathbf{W}\in\mathbb{R}^{d_{in}\times
    d_{out}}$ represents the additional matrices, which offers adaptation capability
    to pre-trained LLMs. In addition, $\mathbf{B}\in\mathbb{R}^{d_{in}\times r}$ and
    $\mathbf{A}\in\mathbb{R}^{r\times d_{in}}$ stands for a pair of decomposed trainable
    low-rank matrices. Built upon these notations, an abstract expression of a dense
    layer paired with the LoRA scheme can be formulated as:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 关于LoRA，低秩分解应用于LLM中的参数微调过程中，更准确地说，将传统上代表全参数的全秩矩阵分解为配对的低秩矩阵，如方程$\mathbf{W}_{0}+\Delta\mathbf{W}=\mathbf{W}_{0}+\mathbf{BA}$所示。值得注意的是，$\mathbf{W}_{0}\in\mathbb{R}^{d_{in}\times
    d_{out}}$表示预训练中心LLM的参数矩阵，而$\Delta\mathbf{W}\in\mathbb{R}^{d_{in}\times d_{out}}$表示额外矩阵，提供了对预训练LLM的适应能力。此外，$\mathbf{B}\in\mathbb{R}^{d_{in}\times
    r}$和$\mathbf{A}\in\mathbb{R}^{r\times d_{in}}$表示一对分解的可训练低秩矩阵。在这些符号的基础上，可以将与LoRA方案配对的密集层的抽象表达形式制定如下：
- en: '|  | $\begin{split}\mathbf{h}&amp;=\mathbf{W}_{0}\mathbf{x}+\frac{\alpha}{r}\cdot\Delta\mathbf{W}\mathbf{x}\\
    &amp;=\mathbf{W}_{0}\mathbf{x}+\frac{\alpha}{r}\cdot\mathbf{B}\mathbf{A}\mathbf{x}\end{split}$
    |  | (3) |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}\mathbf{h}&amp;=\mathbf{W}_{0}\mathbf{x}+\frac{\alpha}{r}\cdot\Delta\mathbf{W}\mathbf{x}\\
    &amp;=\mathbf{W}_{0}\mathbf{x}+\frac{\alpha}{r}\cdot\mathbf{B}\mathbf{A}\mathbf{x}\end{split}$
    |  | (3) |'
- en: where $\mathbf{x}$ and $\mathbf{h}$ stand for the input and output vector of
    dimension $d_{in}$ and $d_{out}$, respectively. Moreover, the numbers of additional
    trainable parameters is determined by $r$, the rank of decomposed low-rank matrices
    while $\alpha$ is designed to alleviate the impact caused by the variance of rank
    $r$. As emphasised, all parameters (e.g., $\mathbf{W}_{q},\mathbf{W}_{k},\mathbf{W}_{v}$
    and $\mathbf{W}$) of pre-trained LLMs stay frozen during the fine-tuning process
    as illustrated in Figure [3](#S4.F3 "Figure 3 ‣ 4.1 Overview ‣ 4 CGC-LoRA ‣ A
    Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA
    Algorithm"). Instead, the paired low-rank matrices, $\mathbf{A}$ and $\mathbf{B}$,
    are trained from scratch. As suggested by [[36](#bib.bib36)], $\mathbf{A}$ is
    initialized by a random Gaussian while $\mathbf{B}$ is set to be zero. Considering
    that $r\ll d_{in}$ and $r\ll d_{out}$, the total numbers of trainable parameters
    in $\mathbf{A}$ and $\mathbf{B}$ is typically fewer than that in $\mathbf{W}_{0}$,
    which is the principle mechanism stimulates the efficiency and effectiveness during
    the fine-tuning process.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$\mathbf{x}$ 和 $\mathbf{h}$ 分别代表输入和输出向量，维度为$d_{in}$和$d_{out}$。此外，额外可训练参数的数量由$r$（分解低秩矩阵的秩）决定，而$\alpha$旨在减轻秩$r$变异带来的影响。如强调的那样，所有预训练LLM的参数（例如，$\mathbf{W}_{q}$、$\mathbf{W}_{k}$、$\mathbf{W}_{v}$和$\mathbf{W}$）在微调过程中保持不变，如图[3](#S4.F3
    "Figure 3 ‣ 4.1 Overview ‣ 4 CGC-LoRA ‣ A Framework to Implement 1+N Multi-task
    Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm")所示。相反，配对的低秩矩阵$\mathbf{A}$和$\mathbf{B}$从头开始训练。根据[[36](#bib.bib36)]的建议，$\mathbf{A}$由随机高斯初始化，而$\mathbf{B}$设置为零。考虑到$r\ll
    d_{in}$和$r\ll d_{out}$，$\mathbf{A}$和$\mathbf{B}$中可训练参数的总数通常少于$\mathbf{W}_{0}$中的总数，这一原则机制激发了微调过程中的效率和效果。
- en: 'Although PEFT algorithms (i.e., LoRA) can solve the high computing cost issue
    because of the demand for full-parameter fine-tuning excellently, they are at
    a loss how to achieve a efficient knowledge circulation in MTL cases. As for LoRA,
    additional parameters are fine-tuned as a whole for all tasks by feeding all samples
    into the pre-trained LLMs simultaneously. To further optimize the fine-tuning
    algorithm, an ingenious plan, enlightened by the multi-expert structure, is to
    partition matrices $\mathbf{A}$ and $\mathbf{B}$ of rank $r$ into several segments
    $\{\mathbf{A}_{1},...,\mathbf{A}_{N}\}$ and $\{\mathbf{B}_{1},...,\mathbf{B}_{N}\}$,
    rank summation of which equals to $r$. In this work, we propose a innovative network
    layer, named by CGC-LoRA, which uses a Customized Gate Control (CGC) structure
    as reference. Particularly, CGC employs two types of expert networks (i.e., task-common
    and task-specific experts) to apprehend both shared and isolated knowledge of
    multi-task. Such a pattern can be integrated into a LoRA layer by a decomposition
    of matrices $\mathbf{A}$ and $\mathbf{B}$ and naturally, segments $\{\mathbf{A}_{1},...,\mathbf{A}_{N}\}$
    and $\{\mathbf{B}_{1},...,\mathbf{B}_{N}\}$ corresponds to each task-common and
    task-specific expert, denoted as $E^{C}\in\{E^{C}_{i}\}^{N_{C}}_{i=1}$ and $E^{S}\in\{E^{S}_{i}\}^{N_{S}}_{i=1}$,
    respectively. Here $N_{C}$ and $N_{S}$ stand for the numbers of task-common and
    task-specific expert, separately and the summation of $N_{C}$ and $N_{S}$ is equal
    to $N$, the total numbers of experts. Generally speaking, the numbers of task-specific
    experts is the same as that of tasks (i.e., $N_{C}=N_{T}$). During the CGC-LoRA
    fine-tuning process, additional parameters, serving as experts, are trained using
    data from all tasks and correspondingly, task-common and task-specific experts
    intrinsically capture shared and specific information. Given this architecture,
    a forward process of a CGC-LoRA layer for samples from task $\mathcal{T}_{j}$
    can be formulated as:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 PEFT 算法（例如，LoRA）能够出色地解决由于全参数微调需求导致的高计算成本问题，但它们对于如何在 MTL 案例中实现高效的知识流通感到困惑。至于
    LoRA，通过将所有样本同时输入预训练的 LLM，额外的参数会作为一个整体进行微调。为了进一步优化微调算法，受到多专家结构启发的巧妙计划是将秩为 $r$ 的矩阵
    $\mathbf{A}$ 和 $\mathbf{B}$ 划分为若干段 $\{\mathbf{A}_{1},...,\mathbf{A}_{N}\}$ 和 $\{\mathbf{B}_{1},...,\mathbf{B}_{N}\}$，其秩之和等于
    $r$。在这项工作中，我们提出了一种创新的网络层，称为 CGC-LoRA，它使用了定制门控控制（CGC）结构作为参考。特别地，CGC 使用两种类型的专家网络（即任务通用专家和任务特定专家）来理解多任务的共享和孤立知识。这样的模式可以通过矩阵
    $\mathbf{A}$ 和 $\mathbf{B}$ 的分解整合到 LoRA 层中，自然地，段 $\{\mathbf{A}_{1},...,\mathbf{A}_{N}\}$
    和 $\{\mathbf{B}_{1},...,\mathbf{B}_{N}\}$ 对应于每个任务通用和任务特定的专家，分别表示为 $E^{C}\in\{E^{C}_{i}\}^{N_{C}}_{i=1}$
    和 $E^{S}\in\{E^{S}_{i}\}^{N_{S}}_{i=1}$。这里 $N_{C}$ 和 $N_{S}$ 分别表示任务通用专家和任务特定专家的数量，$N_{C}$
    和 $N_{S}$ 的总和等于 $N$，即专家的总数量。一般来说，任务特定专家的数量与任务数量相同（即 $N_{C}=N_{T}$）。在 CGC-LoRA
    微调过程中，作为专家的额外参数使用来自所有任务的数据进行训练，相应地，任务通用和任务特定专家本质上捕捉共享和特定信息。鉴于此架构，任务 $\mathcal{T}_{j}$
    的样本的 CGC-LoRA 层的前向过程可以表示为：
- en: '|  | $$\begin{split}\mathbf{h}_{j}&amp;=\mathbf{W}_{0}\mathbf{x}_{j}+\frac{\alpha}{r}\cdot\Delta\mathbf{W}_{j}\mathbf{x}_{j}\\
    &amp;=\mathbf{W}_{0}\mathbf{x}_{j}+\frac{\alpha}{r}\cdot[w^{S}_{j}\cdot E^{S}_{j}(\mathbf{x}_{j})+\sum^{N_{C}}_{i=1}w^{C}_{ji}\cdot
    E^{C}_{i}(\mathbf{x}_{j})]\\'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | $$\begin{split}\mathbf{h}_{j}&amp;=\mathbf{W}_{0}\mathbf{x}_{j}+\frac{\alpha}{r}\cdot\Delta\mathbf{W}_{j}\mathbf{x}_{j}\\
    &amp;=\mathbf{W}_{0}\mathbf{x}_{j}+\frac{\alpha}{r}\cdot[w^{S}_{j}\cdot E^{S}_{j}(\mathbf{x}_{j})+\sum^{N_{C}}_{i=1}w^{C}_{ji}\cdot
    E^{C}_{i}(\mathbf{x}_{j})]\\'
- en: '&amp;=\mathbf{W}_{0}\mathbf{x}_{j}+\frac{\alpha}{r}\cdot[w^{S}_{j}\cdot\mathbf{B}^{S}_{j}\mathbf{A}^{S}_{j}+\sum^{N_{C}}_{i=1}w^{C}_{ji}\cdot\mathbf{B}^{C}_{i}\mathbf{A}^{C}_{i}]\mathbf{x}_{j}\end{split}$$
    |  | (4) |'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '&amp;=\mathbf{W}_{0}\mathbf{x}_{j}+\frac{\alpha}{r}\cdot[w^{S}_{j}\cdot\mathbf{B}^{S}_{j}\mathbf{A}^{S}_{j}+\sum^{N_{C}}_{i=1}w^{C}_{ji}\cdot\mathbf{B}^{C}_{i}\mathbf{A}^{C}_{i}]\mathbf{x}_{j}\end{split}$$
    |  | (4) |'
- en: where $\mathbf{h}_{j}$ and $\mathbf{x}_{j}$ stands for the input and output
    of intermediate LLM layers (e.g., a dense layer in a Transformer structure) for
    samples from $\mathcal{T}_{j}$, respectively. A pair of $\mathbf{B}^{S}_{j}\in\mathbb{R}^{d_{in}\times\frac{r}{N}}$
    and $\mathbf{A}^{S}_{j}\in\mathbb{R}^{\frac{r}{N}\times d_{out}}$ represents a
    task-specific expert for task $\mathcal{T}_{j}$ while $N_{C}$ pairs of $\mathbf{B}^{C}_{i}\in\mathbb{R}^{d_{in}\times\frac{r}{N}}$
    and $\mathbf{A}^{C}_{i}\in\mathbb{R}^{\frac{r}{N}\times d_{out}}$ denotes the
    task-common experts. For convenience, in Equation ([4](#S4.E4 "In 4.2 CGC-LoRA
    ‣ 4 CGC-LoRA ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern in
    LLMs Using The CGC-LoRA Algorithm")) the rank of $\mathbf{A}^{S}\in\{A^{S}\}^{N_{S}}_{j}$,
    $\mathbf{B}^{S}\in\{B^{S}\}^{N_{S}}_{j}$, $\mathbf{A}^{C}\in\{A^{C}\}^{N_{C}}_{i}$,
    and $\mathbf{B}^{C}\in\{B^{C}\}^{N_{C}}_{i}$ are all set to be $\frac{r}{N}$ equally.
    In a more general expression, the rank of $A^{S}_{j}$, $B^{S}_{j}$, $A^{C}_{i}$,
    and $B^{C}_{i}$ can be different as long as $rank(A^{S}_{j})=rank(B^{S}_{j})$
    and $rank(A^{C}_{i})=rank(B^{C}_{i})$ and also $\mathbf{h}_{j}$. Furthermore,
    the contribution weight of each expert are task-specific and in specific, weights
    are determined by our proposed task-motivated gate function, which will be specified
    in the following section.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\mathbf{h}_{j}$和$\mathbf{x}_{j}$分别代表来自$\mathcal{T}_{j}$的中间LLM层（例如，Transformer结构中的密集层）的输入和输出。一对$\mathbf{B}^{S}_{j}\in\mathbb{R}^{d_{in}\times\frac{r}{N}}$和$\mathbf{A}^{S}_{j}\in\mathbb{R}^{\frac{r}{N}\times
    d_{out}}$表示任务$\mathcal{T}_{j}$的任务特定专家，而$N_{C}$对$\mathbf{B}^{C}_{i}\in\mathbb{R}^{d_{in}\times\frac{r}{N}}$和$\mathbf{A}^{C}_{i}\in\mathbb{R}^{\frac{r}{N}\times
    d_{out}}$表示任务通用专家。为了方便，在方程（[4](#S4.E4 "In 4.2 CGC-LoRA ‣ 4 CGC-LoRA ‣ A Framework
    to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm")）中，$\mathbf{A}^{S}\in\{A^{S}\}^{N_{S}}_{j}$、$\mathbf{B}^{S}\in\{B^{S}\}^{N_{S}}_{j}$、$\mathbf{A}^{C}\in\{A^{C}\}^{N_{C}}_{i}$和$\mathbf{B}^{C}\in\{B^{C}\}^{N_{C}}_{i}$的秩都设置为$\frac{r}{N}$。在更一般的表达中，只要$rank(A^{S}_{j})=rank(B^{S}_{j})$和$rank(A^{C}_{i})=rank(B^{C}_{i})$，以及$\mathbf{h}_{j}$，$A^{S}_{j}$、$B^{S}_{j}$、$A^{C}_{i}$和$B^{C}_{i}$的秩可以不同。此外，每个专家的贡献权重是任务特定的，具体权重由我们提出的任务驱动门控函数决定，具体内容将在以下部分中说明。
- en: In this paragraph, we will compare the numbers of trainable parameters of basic
    LoRA and proposed CGC-LoRA. As for LoRA, trainable parameters are fully included
    in paired low-rank matrices $\mathbf{B}\in\mathbb{R}^{d_{in}\times r}$ and $\mathbf{A}\in\mathbb{R}^{r\times
    d_{out}}$ and consequently, the total counts of trainable parameters in LoRA can
    be calculated as $d_{in}\times r+r\times d_{out}=r\times(d_{in}+d_{out})$. Comparably,
    suppose the numbers of task-common and task-specific experts equals to $N_{C}$
    and $N_{S}$, respectively. Totally, the trainable parameters of all experts can
    be expressed as $N_{C}\times\frac{r}{N}\times(d_{in}+d_{out})+N_{S}\times\frac{r}{N}\times(d_{in}+d_{out})=\frac{N_{C}+N_{S}}{N}\times
    r\times(d_{in}+d_{out})=r\times(d_{in}+d_{out})$ considering $N_{C}+N_{S}=N$.
    As emphasized above, the equation illustrates that the limit of rank $r$ is divided
    into each expert evenly while the conclusion that CGC-LoRA has the same counts
    of trainable parameters as LoRA holds constant even if the division is uneven.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一段中，我们将比较基本LoRA和提出的CGC-LoRA的可训练参数数量。对于LoRA，可训练参数完全包含在成对的低秩矩阵$\mathbf{B}\in\mathbb{R}^{d_{in}\times
    r}$和$\mathbf{A}\in\mathbb{R}^{r\times d_{out}}$中，因此，LoRA中可训练参数的总数可以计算为$d_{in}\times
    r+r\times d_{out}=r\times(d_{in}+d_{out})$。相比之下，假设任务通用专家和任务特定专家的数量分别为$N_{C}$和$N_{S}$。总体上，所有专家的可训练参数可以表示为$N_{C}\times\frac{r}{N}\times(d_{in}+d_{out})+N_{S}\times\frac{r}{N}\times(d_{in}+d_{out})=\frac{N_{C}+N_{S}}{N}\times
    r\times(d_{in}+d_{out})=r\times(d_{in}+d_{out})$，考虑到$N_{C}+N_{S}=N$。正如上面强调的，方程表明秩$r$的限制被均匀地分配到每个专家上，而即使划分不均，CGC-LoRA具有与LoRA相同的可训练参数数量的结论仍然成立。
- en: 4.3 Task-motivated Gate Function
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 任务驱动门控函数
- en: 'In this section, we elaborate how weights of those two types of experts are
    determined by the proposed task-motivated gate function. As previously mentioned,
    the information learned by task-common experts should be shared across each task
    while task-specific experts need to focus on a given task. In practice, the contributions
    of those two kinds of experts to a certain task is determined by weights $w^{S}_{j}$
    and $w^{C}_{ji}$, which correspond to task-specific and task-common experts, separately.
    To achieve this, a task embedding matrix, denoted as $\mathbf{E}\in\mathbb{R}^{|\mathbb{T}|\times
    d_{T}}$, aims to represent task IDs in a hyper-dimensional space and here $d_{T}$
    stands for the dimension of the task embedding. For a certain task $\mathcal{T}_{j}$,
    the j-th column of $\mathbf{E}$ is extracted, which serves as the embedding vector
    for that task, denoted as $\mathbf{e}_{j}\in\mathbb{R}^{d_{T}}$. As for the weights
    of task-common experts (i.e., $\mathbf{w}^{C}_{j}=[w^{C}_{j1},...,w^{C}_{ji},...,w^{C}_{jN_{C}}]^{T}$),
    the formulation can be expressed as follows:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们详细说明了如何通过提出的任务驱动门控函数来确定这两种专家的权重。如前所述，任务通用专家所学到的信息应在每个任务中共享，而任务特定专家则需要专注于特定任务。在实际操作中，这两类专家对某一任务的贡献由权重
    $w^{S}_{j}$ 和 $w^{C}_{ji}$ 决定，分别对应于任务特定专家和任务通用专家。为此，一个任务嵌入矩阵 $\mathbf{E}\in\mathbb{R}^{|\mathbb{T}|\times
    d_{T}}$ 旨在表示超维空间中的任务 ID，其中 $d_{T}$ 代表任务嵌入的维度。对于某个任务 $\mathcal{T}_{j}$，提取 $\mathbf{E}$
    的第 j 列，作为该任务的嵌入向量，记作 $\mathbf{e}_{j}\in\mathbb{R}^{d_{T}}$。至于任务通用专家的权重（即 $\mathbf{w}^{C}_{j}=[w^{C}_{j1},...,w^{C}_{ji},...,w^{C}_{jN_{C}}]^{T}$），其表达式如下：
- en: '|  | $\mathbf{w}^{C}_{j}=\mathbf{W}^{C}_{T}\mathbf{e}_{j}$ |  | (5) |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbf{w}^{C}_{j}=\mathbf{W}^{C}_{T}\mathbf{e}_{j}$ |  | (5) |'
- en: 'where $\mathbf{W}^{C}_{T}\in\mathbb{R}^{N_{C}\times d_{T}}$ stands for a transformation
    matrix that can complete a linear transformation of task embedding of a certain
    task-common expert. Similarly, considering the weights of task-specific experts,
    since each expert corresponds to its own task and has none contribution to the
    other tasks, the weight $w^{S}_{j}$ can be expressed as follows:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathbf{W}^{C}_{T}\in\mathbb{R}^{N_{C}\times d_{T}}$ 代表一个变换矩阵，可以对某个任务通用专家的任务嵌入进行线性变换。同样，考虑到任务特定专家的权重，由于每个专家对应于其自己的任务，并且对其他任务没有贡献，权重
    $w^{S}_{j}$ 可以表达如下：
- en: '|  | $w^{S}_{j}=\mathbf{W}^{S}_{T}\mathbf{e}_{j}$ |  | (6) |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '|  | $w^{S}_{j}=\mathbf{W}^{S}_{T}\mathbf{e}_{j}$ |  | (6) |'
- en: 'where $\mathbf{W}^{S}_{T}\in\mathbb{R}^{1\times d_{T}}$ denotes another transformation
    vector that applies a linear transformation of task embedding of a given task-specific
    expert. Finally, we apply a $\mathrm{Softmax}$ operation after the linear transformation
    to normalize the weights of both task-common and task-specific experts as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathbf{W}^{S}_{T}\in\mathbb{R}^{1\times d_{T}}$ 表示另一个变换向量，用于对给定任务特定专家的任务嵌入进行线性变换。最后，我们在进行线性变换后应用
    $\mathrm{Softmax}$ 操作，以规范化任务通用和任务特定专家的权重，如下所示：
- en: '|  | $\mathbf{w}_{j}=\mathrm{softmax}([\mathbf{w}^{C}_{j},w^{S}_{j}])$ |  |
    (7) |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbf{w}_{j}=\mathrm{softmax}([\mathbf{w}^{C}_{j},w^{S}_{j}])$ |  |
    (7) |'
- en: where $\mathbf{w}_{j}\in\mathbb{R}^{N_{C}+1}$ stands for the weights of both
    task-common and task-specific experts after normalization. In particular, the
    first $N_{C}$ elements denote weights of task-common experts while the last one
    represents weight of task-specific one. Besides, it is worthy noting that the
    linear transformation matrices (i.e., $\mathbf{W}^{C}_{T}$ and $\mathbf{W}^{S}_{T}$)
    can be various for different layers and it can increase the ability of representation
    and on the other hand, it is likely to cause over-parameterization.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathbf{w}_{j}\in\mathbb{R}^{N_{C}+1}$ 代表任务通用和任务特定专家在规范化后的权重。特别地，前 $N_{C}$
    个元素表示任务通用专家的权重，而最后一个元素表示任务特定专家的权重。此外，值得注意的是，线性变换矩阵（即 $\mathbf{W}^{C}_{T}$ 和 $\mathbf{W}^{S}_{T}$）在不同层中可以有所不同，这可以提高表示能力，但另一方面，也可能导致过度参数化。
- en: 'Regarding a conventional gate function as in CGC [[27](#bib.bib27)], the input
    vector $x_{j}$ serves as the variable to the gate function and consequently, the
    output of the gate function (i.e., contribution weights of experts) varies among
    samples. Be contrast to that design, the proposed task-motivated one is fed by
    task IDs instead of the input vector $x_{j}$, which offers an admirable feature
    of being invariant to the input sample. Also thanks to another characteristic
    of linear combination among two types of experts, the corresponding parameters
    learned for a certain task $\mathcal{T}_{j}$ can be expressed as a linear process:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 关于传统的门函数，如CGC [[27](#bib.bib27)]，输入向量 $x_{j}$ 作为门函数的变量，因此，门函数的输出（即专家的贡献权重）在样本之间会有所不同。与这种设计相对，所提的任务驱动型门函数由任务ID而非输入向量
    $x_{j}$ 提供，这提供了一个对输入样本不变的优良特性。由于两种专家之间的线性组合特性，某任务 $\mathcal{T}_{j}$ 学到的相应参数可以表示为线性过程：
- en: '|  | $$\begin{split}\mathbf{W}_{j}&amp;=\mathbf{W}_{0}+\frac{\alpha}{r}\cdot\Delta\mathbf{W}_{j}\\
    &amp;=\mathbf{W}_{0}+\frac{\alpha}{r}\cdot[w^{S}_{j}\cdot E^{S}_{j}+\sum^{N_{C}}_{i=1}w^{C}_{ji}\cdot
    E^{C}_{i}]\\'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | $$\begin{split}\mathbf{W}_{j}&amp;=\mathbf{W}_{0}+\frac{\alpha}{r}\cdot\Delta\mathbf{W}_{j}\\
    &amp;=\mathbf{W}_{0}+\frac{\alpha}{r}\cdot[w^{S}_{j}\cdot E^{S}_{j}+\sum^{N_{C}}_{i=1}w^{C}_{ji}\cdot
    E^{C}_{i}]\\'
- en: '&amp;=\mathbf{W}_{0}+\frac{\alpha}{r}\cdot[w_{j}\cdot\mathbf{B}^{S}_{j}\mathbf{A}^{S}_{j}+\sum^{N_{C}}_{i=1}w^{C}_{ji}\cdot\mathbf{B}^{C}_{i}\mathbf{A}^{C}_{i}]\end{split}$$
    |  | (8) |'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '&amp;=\mathbf{W}_{0}+\frac{\alpha}{r}\cdot[w_{j}\cdot\mathbf{B}^{S}_{j}\mathbf{A}^{S}_{j}+\sum^{N_{C}}_{i=1}w^{C}_{ji}\cdot\mathbf{B}^{C}_{i}\mathbf{A}^{C}_{i}]\end{split}$$
    |  | (8) |'
- en: According to Equation ([8](#S4.E8 "In 4.3 Task-motivated Gate Function ‣ 4 CGC-LoRA
    ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The
    CGC-LoRA Algorithm")), the final parameters of a CGC-LoRA layer of a given task
    $\mathcal{T}_{j}$ (i.e., $\mathbf{W}_{j}$) is only determined by task ID $j$,
    which signifies that a unique set of parameters can be reclaimed for all samples
    from the task $\mathcal{T}_{j}$. In contrast, if the input vector $x_{j}$ also
    makes an effect on the gate function, the weight matrices $\mathbf{W}_{j}$ would
    alter across samples from even the same task. Such a tiny distinction definitely
    leads to high inference latency since distinct samples, even those from the same
    task $\mathcal{T}_{j}$, have their own unique parameters $\mathbf{W}_{j}$ and
    parameters need to be calculated repetitively. Considering our task-motivated
    gate function, the parameters of a given task $\mathcal{T}_{j}$ stay static for
    samples belonging to that task and during the inference process, all samples from
    a certain task can be conducted as a batch. Following such an operation, the latency
    caused by reasoning the parameters can be significantly decreased by $\frac{N_{T}}{N_{sample}}$
    in theory. Here, $N_{sample}$ denotes the total numbers of inference samples.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 根据方程 ([8](#S4.E8 "在4.3 任务驱动门函数 ‣ 4 CGC-LoRA ‣ 实现1+N多任务微调模式的框架")), 给定任务 $\mathcal{T}_{j}$
    的CGC-LoRA层的最终参数（即 $\mathbf{W}_{j}$）仅由任务ID $j$ 决定，这意味着可以为任务 $\mathcal{T}_{j}$ 的所有样本恢复一组唯一的参数。相反，如果输入向量
    $x_{j}$ 也对门函数有影响，权重矩阵 $\mathbf{W}_{j}$ 将在即使是同一任务的样本之间也会发生变化。这种微小的差异确实会导致高推理延迟，因为不同的样本，即使是来自同一任务
    $\mathcal{T}_{j}$ 的样本，也有其独特的参数 $\mathbf{W}_{j}$，并且参数需要重复计算。考虑到我们的任务驱动型门函数，给定任务
    $\mathcal{T}_{j}$ 的参数对属于该任务的样本保持静态，在推理过程中，所有来自特定任务的样本可以作为一个批次进行处理。按照这种操作，理论上，由参数推理引起的延迟可以显著减少
    $\frac{N_{T}}{N_{sample}}$。这里，$N_{sample}$ 表示推理样本的总数。
- en: 4.4 Training and Inference
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 训练和推理
- en: In this section, we elaborate the details of the training and inference process
    of the proposed CGC-LoRA structure. Algorithm [1](#alg1 "Algorithm 1 ‣ 4.4 Training
    and Inference ‣ 4 CGC-LoRA ‣ A Framework to Implement 1+N Multi-task Fine-tuning
    Pattern in LLMs Using The CGC-LoRA Algorithm") summarizes an entire pipeline and
    anyone can replicate the training and inference process by following those steps.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们详细阐述了所提CGC-LoRA结构的训练和推理过程。算法 [1](#alg1 "算法 1 ‣ 4.4 训练和推理 ‣ 4 CGC-LoRA
    ‣ 实现1+N多任务微调模式的框架") 概括了整个流程，任何人都可以通过遵循这些步骤来复制训练和推理过程。
- en: Training. Firstly, the pre-trained central LLM and the layers that demand fine-tuning
    using CGC-LoRA algotithm should be defined (line 1). Next, multiple hyper-parameters,
    such as rank value $r$, scale value $\alpha$, the numbers of task-common experts,
    etc., should be determined in advance (line 2-5). During the fine-tuning procedure,
    full parameters of the pre-trained LLM stay frozen (line 6) and as suggested in
    [[25](#bib.bib25)], a batch of training samples are randomly sampled without replacement
    from various tasks iteratively (line 7). Moreover, we behave the forward process
    and calculate the loss function based on batches of training samples (line 8-9).
    Finally, the parameters of CGC-LoRA module and task-motivated gate function (i.e.,
    the parameters of CGC-LoRA $\{\mathbf{A}^{S}_{i},\mathbf{B}^{S}_{i}\}^{N_{S}}_{i=1}$
    and $\{\mathbf{A}^{C}_{i},\mathbf{B}^{C}_{i}\}^{N_{C}}_{i=1}$ and the parameters
    of task motivated gate function $\mathbf{E},\mathbf{W}^{C}_{T}$, and $\mathbf{W}^{S}_{T}$)
    are updated according to the backpropagation mechanism.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 训练。首先，需要定义预训练的中心LLM和使用CGC-LoRA算法进行微调的层（第1行）。接下来，应预先确定多个超参数，如秩值$r$、缩放值$\alpha$、任务通用专家数量等（第2-5行）。在微调过程中，预训练LLM的所有参数保持冻结（第6行），并且如[[25](#bib.bib25)]所建议，批量训练样本将从不同任务中随机抽取，且不进行替换（第7行）。此外，我们执行前向过程，并基于批量训练样本计算损失函数（第8-9行）。最后，根据反向传播机制更新CGC-LoRA模块和任务驱动门控函数的参数（即CGC-LoRA的参数$\{\mathbf{A}^{S}_{i},\mathbf{B}^{S}_{i}\}^{N_{S}}_{i=1}$和$\{\mathbf{A}^{C}_{i},\mathbf{B}^{C}_{i}\}^{N_{C}}_{i=1}$以及任务驱动门控函数的参数$\mathbf{E},\mathbf{W}^{C}_{T}$和$\mathbf{W}^{S}_{T}$）。
- en: Inference. After being fine-tuned, the updated parameters corresponding to each
    task $\mathcal{T}_{j}$ can be retrieved by following Equation ([8](#S4.E8 "In
    4.3 Task-motivated Gate Function ‣ 4 CGC-LoRA ‣ A Framework to Implement 1+N Multi-task
    Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm")). Once the fine-tuned
    parameter matrices of each task are recovered by steps described in line 12-15,
    we can apply the corresponding parameters for inference, given a specific task
    $\mathcal{T}_{j}$.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 推理。在微调之后，可以通过以下公式检索与每个任务$\mathcal{T}_{j}$相对应的更新参数（见公式([8](#S4.E8 "In 4.3 Task-motivated
    Gate Function ‣ 4 CGC-LoRA ‣ A Framework to Implement 1+N Multi-task Fine-tuning
    Pattern in LLMs Using The CGC-LoRA Algorithm"))）。一旦通过第12-15行描述的步骤恢复了每个任务的微调参数矩阵，我们就可以应用对应的参数进行推理，针对特定任务$\mathcal{T}_{j}$。
- en: Algorithm 1 The training and inference process of CGC-LoRA
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 1 CGC-LoRA的训练和推理过程
- en: '1:Specify the pre-trained central LLM and the layers that demand CGC-LoRA fine-tuning.2:Specify
    the rank value $r$ and scale value $\alpha$.3:Specify the numbers of task-common
    experts $N_{C}$ of CGC-LoRA. (Note: The numbers of task-specific experts $N_{S}$
    is set to $N_{S}=N_{T}$)4:Specify the rank value $r_{i}$ of each expert. Note:
    (i) By default, $r_{i}=\frac{r}{N}$. (ii) $\sum^{N}_{i=1}r_{i}=r$.5:Specify if
    the transformation matrices $\mathbf{W^{C}_{T}}$ and $\mathbf{W^{S}_{T}}$ stay
    the same for different layers: Yes or No.6:7:Freeze all parameters in the pre-trained
    LLM, e.g., $\mathbf{W}_{q}$, $\mathbf{W}_{k}$, $\mathbf{W}_{v}$, and $\mathbf{W}$.8:for a
    batch of samples $\mathcal{S}$ in $\mathcal{D}$ do9:     Execute forward process
    for LLM guided by CGC-LoRA scheme following Equation ([4](#S4.E4 "In 4.2 CGC-LoRA
    ‣ 4 CGC-LoRA ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern in
    LLMs Using The CGC-LoRA Algorithm")).10:     Calculate the loss function by Equation
    ([2](#S3.E2 "In 3 Problem Formulation ‣ A Framework to Implement 1+N Multi-task
    Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm")).11:     Update the
    parameters of CGC-LoRA $\{\mathbf{A}^{S}_{i},\mathbf{B}^{S}_{i}\}^{N_{S}}_{i=1}$
    and $\{\mathbf{A}^{C}_{i},\mathbf{B}^{C}_{i}\}^{N_{C}}_{i=1}$ and the parameters
    of task-motivated gate function $\mathbf{E},\mathbf{W}^{C}_{T}$, and $\mathbf{W}^{S}_{T}$12:end for13:14:for $\mathcal{T}_{j}$
    in $\mathbb{T}$ do15:     Calculate the contribution weights $\mathbf{w}^{C}_{j}$
    for task-common experts and $w^{S}_{j}$ for task-common experts following Equation
    ([5](#S4.E5 "In 4.3 Task-motivated Gate Function ‣ 4 CGC-LoRA ‣ A Framework to
    Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm"))
    and Equation ([6](#S4.E6 "In 4.3 Task-motivated Gate Function ‣ 4 CGC-LoRA ‣ A
    Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA
    Algorithm")), respectively and compute the normalized weights $\mathbf{w}_{j}$
    by Equation ([7](#S4.E7 "In 4.3 Task-motivated Gate Function ‣ 4 CGC-LoRA ‣ A
    Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA
    Algorithm")).16:     Retrieve the parameters of the fine-tuned LLM with CGC-LoRA
    scheme by Equation ([8](#S4.E8 "In 4.3 Task-motivated Gate Function ‣ 4 CGC-LoRA
    ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The
    CGC-LoRA Algorithm")) for each task $j$.17:end for18:Given a specific task $\mathcal{T}_{j}$,
    apply the corresponding parameters of the fine-tuned LLM for inference.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 1：指定预训练的中央 LLM 和需要 CGC-LoRA 微调的层。2：指定秩值 $r$ 和缩放值 $\alpha$。3：指定 CGC-LoRA 的任务共用专家数量
    $N_{C}$。 （注意：任务特定专家的数量 $N_{S}$ 设置为 $N_{S}=N_{T}$）4：指定每个专家的秩值 $r_{i}$。注意：（i）默认情况下，$r_{i}=\frac{r}{N}$。（ii）$\sum^{N}_{i=1}r_{i}=r$。5：指定不同层的转换矩阵
    $\mathbf{W^{C}_{T}}$ 和 $\mathbf{W^{S}_{T}}$ 是否保持不变：是或否。6：7：冻结预训练 LLM 中的所有参数，例如
    $\mathbf{W}_{q}$、$\mathbf{W}_{k}$、$\mathbf{W}_{v}$ 和 $\mathbf{W}$。8：对于在 $\mathcal{D}$
    中的样本批次 $\mathcal{S}$ 执行9：     按照公式 ([4](#S4.E4 "In 4.2 CGC-LoRA ‣ 4 CGC-LoRA ‣
    A Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The
    CGC-LoRA Algorithm")) 执行由 CGC-LoRA 方案指导的 LLM 正向过程。10：     按照公式 ([2](#S3.E2 "In
    3 Problem Formulation ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern
    in LLMs Using The CGC-LoRA Algorithm")) 计算损失函数。11：     更新 CGC-LoRA 的参数 $\{\mathbf{A}^{S}_{i},\mathbf{B}^{S}_{i}\}^{N_{S}}_{i=1}$
    和 $\{\mathbf{A}^{C}_{i},\mathbf{B}^{C}_{i}\}^{N_{C}}_{i=1}$ 以及任务动机门函数 $\mathbf{E},\mathbf{W}^{C}_{T}$
    和 $\mathbf{W}^{S}_{T}$ 的参数。12：结束 循环13：14：对 $\mathcal{T}_{j}$ 在 $\mathbb{T}$ 中执行15：     按照公式
    ([5](#S4.E5 "In 4.3 Task-motivated Gate Function ‣ 4 CGC-LoRA ‣ A Framework to
    Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm"))
    和公式 ([6](#S4.E6 "In 4.3 Task-motivated Gate Function ‣ 4 CGC-LoRA ‣ A Framework
    to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm"))
    分别计算任务共用专家的贡献权重 $\mathbf{w}^{C}_{j}$ 和任务特定专家的贡献权重 $w^{S}_{j}$，并通过公式 ([7](#S4.E7
    "In 4.3 Task-motivated Gate Function ‣ 4 CGC-LoRA ‣ A Framework to Implement 1+N
    Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm")) 计算归一化权重
    $\mathbf{w}_{j}$。16：     通过公式 ([8](#S4.E8 "In 4.3 Task-motivated Gate Function
    ‣ 4 CGC-LoRA ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern in
    LLMs Using The CGC-LoRA Algorithm")) 检索使用 CGC-LoRA 方案微调的 LLM 的参数。17：结束 循环18：给定一个特定任务
    $\mathcal{T}_{j}$，应用微调后的 LLM 对应的参数进行推理。
- en: 5 Experiments
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 个实验
- en: 'To comprehensively prove the effectiveness of the proposed CGC-LoRA structure,
    we conduct well-designed experiments on two public multi-task datasets: (i) Prompt
    Chinese Biomedical Language Understanding Evaluation (PromptCBLUE) dataset [[40](#bib.bib40),
    [41](#bib.bib41)]. (ii) Firefly dataset [[42](#bib.bib42)]. In Section [5.1](#S5.SS1
    "5.1 Dataset ‣ 5 Experiments ‣ A Framework to Implement 1+N Multi-task Fine-tuning
    Pattern in LLMs Using The CGC-LoRA Algorithm"), an elaborate introduction to PromptCBLUE
    and Firefly Dataset is presented and a detailed description of baselines is given
    in Section [5.2](#S5.SS2 "5.2 Baselines ‣ 5 Experiments ‣ A Framework to Implement
    1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm"). Next,
    the implementation details, such as the settings of software, hardware and hyper-parameters,
    are illustrated in Section [5.3](#S5.SS3 "5.3 Implementation Details ‣ 5 Experiments
    ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The
    CGC-LoRA Algorithm"). Moreover, Section [5.4](#S5.SS4 "5.4 Evaluation Metrics
    ‣ 5 Experiments ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern
    in LLMs Using The CGC-LoRA Algorithm") and Section [5.5](#S5.SS5 "5.5 Overall
    Performance ‣ 5 Experiments ‣ A Framework to Implement 1+N Multi-task Fine-tuning
    Pattern in LLMs Using The CGC-LoRA Algorithm") amplify the evaluation indexes
    and the corresponding results of different methods on each task of those two public
    datasets, respectively. In addition, the conclusion of an ablation study on each
    component of CGC-LoRA is made in Section [5.6](#S5.SS6 "5.6 Ablation Study ‣ 5
    Experiments ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs
    Using The CGC-LoRA Algorithm") while the effects of hyper-parameter selection
    are debated in Section [5.7](#S5.SS7 "5.7 Hyper-parameter Analysis ‣ 5 Experiments
    ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The
    CGC-LoRA Algorithm").'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为全面证明所提出的CGC-LoRA结构的有效性，我们在两个公共多任务数据集上进行了精心设计的实验：（i）Prompt中文生物医学语言理解评估（PromptCBLUE）数据集[[40](#bib.bib40)、[41](#bib.bib41)]。（ii）Firefly数据集[[42](#bib.bib42)]。在第[5.1](#S5.SS1
    "5.1 数据集 ‣ 5 实验 ‣ 基于CGC-LoRA算法在LLMs中实现1+N多任务微调模式的框架")节中，详细介绍了PromptCBLUE和Firefly数据集，并在第[5.2](#S5.SS2
    "5.2 基准 ‣ 5 实验 ‣ 基于CGC-LoRA算法在LLMs中实现1+N多任务微调模式的框架")节中给出了基准的详细描述。接下来，第[5.3](#S5.SS3
    "5.3 实现细节 ‣ 5 实验 ‣ 基于CGC-LoRA算法在LLMs中实现1+N多任务微调模式的框架")节中阐明了软件、硬件和超参数的设置等实现细节。此外，第[5.4](#S5.SS4
    "5.4 评估指标 ‣ 5 实验 ‣ 基于CGC-LoRA算法在LLMs中实现1+N多任务微调模式的框架")节和第[5.5](#S5.SS5 "5.5 整体性能
    ‣ 5 实验 ‣ 基于CGC-LoRA算法在LLMs中实现1+N多任务微调模式的框架")节分别放大了评估指标以及不同方法在这两个公共数据集每个任务上的对应结果。此外，第[5.6](#S5.SS6
    "5.6 消融研究 ‣ 5 实验 ‣ 基于CGC-LoRA算法在LLMs中实现1+N多任务微调模式的框架")节对CGC-LoRA的每个组件进行了消融研究的结论，而第[5.7](#S5.SS7
    "5.7 超参数分析 ‣ 5 实验 ‣ 基于CGC-LoRA算法在LLMs中实现1+N多任务微调模式的框架")节则讨论了超参数选择的效果。
- en: 5.1 Dataset
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 数据集
- en: To the best of our knowledge, Prompt Chinese Biomedical Language Understanding
    Evaluation dataset [[40](#bib.bib40), [41](#bib.bib41)] and Firefly dataset [[42](#bib.bib42)]
    are two most thorough multi-task datasets in Chinese, both of which include numerous
    tasks of noticeable diversity, such as entity recognition, text generation, text
    classification, etc.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 据我们所知，Prompt中文生物医学语言理解评估数据集[[40](#bib.bib40)、[41](#bib.bib41)]和Firefly数据集[[42](#bib.bib42)]是两个最全面的中文多任务数据集，它们都包括了众多任务，具有显著的多样性，如实体识别、文本生成、文本分类等。
- en: 'PromptCBLUE dataset: It is derived from Chinese Biomedical Languange Understanding
    Evaluation (CBLUE) dataset by transforming all samples into a pure text format
    as described in Section [2.2](#S2.SS2 "2.2 Input and Output Modification ‣ 2 Preliminary
    ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The
    CGC-LoRA Algorithm"). PromptCLUE is released by East China Normal University on
    Tianchi Competition Platform [[46](#bib.bib46)] and totally, it contains 16 medicine-related
    tasks, such as medical named entity recognition, diagnosis report generation,
    etc. In order to compare with MOE-LoRA [[25](#bib.bib25)] fairly and rationally,
    we reuse exactly the same training/validation/test datasets as MOE-LoRA and also
    follow its pre-processing procedure. The detailed statistics of datasets corresponding
    to 8 selected tasks are summarized in Table [I](#S5.T1 "Table I ‣ 5.1 Dataset
    ‣ 5 Experiments ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern
    in LLMs Using The CGC-LoRA Algorithm").'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: PromptCBLUE 数据集：它源自中文生物医学语言理解评估（CBLUE）数据集，通过将所有样本转换为纯文本格式，如第[2.2](#S2.SS2 "2.2
    输入和输出修改 ‣ 2 初步 ‣ 实现1+N多任务微调模式的框架")节所述。PromptCLUE由华东师范大学在天池比赛平台[[46](#bib.bib46)]发布，包含16个医学相关任务，如医学命名实体识别、诊断报告生成等。为了公平合理地与MOE-LoRA[[25](#bib.bib25)]进行比较，我们完全重用与MOE-LoRA相同的训练/验证/测试数据集，并遵循其预处理程序。与8个选择任务对应的数据集的详细统计数据总结在表[I](#S5.T1
    "表 I ‣ 5.1 数据集 ‣ 5 实验 ‣ 实现1+N多任务微调模式的框架")中。
- en: 'Table I: The brief task description and statistics of 8 selected sub-datasets
    from PromptCBLUE.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 表 I：PromptCBLUE中8个选择的子数据集的简要任务描述和统计数据。
- en: '| Task | Description | # Train | # Validation | # Test |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | 描述 | 训练样本数量 | 验证样本数量 | 测试样本数量 |'
- en: '| CMeIE | Name Entity Recognition | 2828 | 600 | 600 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| CMeIE | 命名实体识别 | 2828 | 600 | 600 |'
- en: '| CHIP-CDN | Normalization | 2381 | 600 | 600 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| CHIP-CDN | 标准化 | 2381 | 600 | 600 |'
- en: '| CHIP-CDEE | Attribute Extraction | 1562 | 600 | 600 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| CHIP-CDEE | 属性提取 | 1562 | 600 | 600 |'
- en: '| CHIP-MDCFNPC | Clinic Entity Discovery | 4935 | 600 | 600 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| CHIP-MDCFNPC | 临床实体发现 | 4935 | 600 | 600 |'
- en: '| CHIP-CTC | Medical Text Classification | 3622 | 1100 | 1100 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| CHIP-CTC | 医学文本分类 | 3622 | 1100 | 1100 |'
- en: '| KUAKE-QIC | Query Intention | 3279 | 660 | 660 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| KUAKE-QIC | 查询意图 | 3279 | 660 | 660 |'
- en: '| IMCS-V2-MRG | Report Generation | 1799 | 600 | 600 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| IMCS-V2-MRG | 报告生成 | 1799 | 600 | 600 |'
- en: '| MedDG | Doctor Dialogue | 4964 | 600 | 600 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| MedDG | 医生对话 | 4964 | 600 | 600 |'
- en: 'Firefly dataset: It is a comprehensive, public, multi-task dataset in Chinese,
    totally including over one million samples [[42](#bib.bib42)]. Specifically, it
    contains 23 general tasks, such as lyric generation, sentiment analysis, natural
    language inference, etc., from which we randomly select 8 tasks (Text Correction
    (TC), Summary, Keyword Recognition (KR), Text Matching (TM), Sentiment Analyze
    (SA), MRC, NER, and NLI) and considering the computing complexity, we fix the
    number of training, evaluation, and test samples of those 8 tasks at 1800, 300,
    and 300, respectively.To comprehensively evaluate the proposed framework in various
    situations, we do not transform samples into pure linguistic text format as PromptCBLUE
    and instead samples stay in an input-target format as displayed in Table [II](#S5.T2
    "Table II ‣ 5.1 Dataset ‣ 5 Experiments ‣ A Framework to Implement 1+N Multi-task
    Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm").'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Firefly 数据集：这是一个全面的、公开的、多任务的中文数据集，总共包含超过一百万个样本[[42](#bib.bib42)]。具体而言，它包含23个通用任务，如歌词生成、情感分析、自然语言推理等，我们从中随机选择了8个任务（文本纠错
    (TC)、摘要、关键词识别 (KR)、文本匹配 (TM)、情感分析 (SA)、MRC、NER 和 NLI），考虑到计算复杂性，我们将这8个任务的训练、评估和测试样本数量分别固定为1800、300和300。为了全面评估所提框架在各种情况下的表现，我们没有将样本转换为纯语言文本格式如PromptCBLUE，而是保持样本在输入-目标格式中，如表[II](#S5.T2
    "表 II ‣ 5.1 数据集 ‣ 5 实验 ‣ 实现1+N多任务微调模式的框架")所示。
- en: 'Table II: Examples from Firefly dataset on four tasks: Natural Language Inference,
    Name Entity Recognition, Sentiment Analysis, and Couplet.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 表 II：Firefly 数据集在四个任务上的示例：自然语言推理、命名实体识别、情感分析和对联。
- en: '| Type | Input | Target |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 类型 | 输入 | 目标 |'
- en: '| Natural Language Inference | Text:soccer game with multiple males playing.
    Hypothesis:Some men are playing a sport. | Entailment |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 自然语言推理 | 文本：多个男性正在踢足球。假设：一些男性在进行运动。 | 推断 |'
- en: '| Named Entity Recognition | Beijing is the capital of China. Please recognize
    all city entities in the sentence. | Beijing |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 命名实体识别 | 北京是中国的首都。请识别句子中的所有城市实体。 | 北京 |'
- en: '| Sentiment Analysis | This book is really exciting. What is the sentiment
    of this comment, positive or negative? | Positive |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 情感分析 | 这本书真的很精彩。这个评论的情感是什么，正面还是负面？ | 正面 |'
- en: '| Couplet | Monk. Please give the second line of a couplet: | Wukong |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 对对子 | 僧人。请给出对子的第二句： | 悟空 |'
- en: 5.2 Baselines
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 基线
- en: 'To demonstrate the proposed framework powered by the CGC-LoRA module, we conduct
    a well-designed experiment to compare it with three types of baselines:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示由 CGC-LoRA 模块驱动的提出的框架，我们进行了一项精心设计的实验，将其与三种基线进行比较：
- en: •
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'LLM without fine-tuning: Regarding the baseline without fine-tuning, ChatGPT
    [[4](#bib.bib4), [5](#bib.bib5)] acts as the fundamental pre-trained LLM. In specific,
    to pilot ChatGPT to generate the output in a desired format, we apply In-Context
    Learning algorithm [[47](#bib.bib47)] by providing 3 to 10 randomly sampled examples
    as the task description.'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 未微调的 LLM：关于没有微调的基线，ChatGPT [[4](#bib.bib4), [5](#bib.bib5)] 作为基本的预训练 LLM。具体而言，为了指导
    ChatGPT 生成期望格式的输出，我们应用了 In-Context Learning 算法 [[47](#bib.bib47)]，通过提供 3 到 10
    个随机采样的示例作为任务描述。
- en: •
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'LLM with LoRA: As a well-tested fine-tuning algorithm, LoRA is naturally compatible
    with LLMs due to its effectiveness and efficiency [[36](#bib.bib36)]. In multi-task
    learning (MTL) cases, two straightforward scenarios can be implemented with LoRA:
    (i) LoRA Full: All samples from disparate tasks are utilized simultaneously to
    fine-tune a pre-trained central LLM using LoRA. (ii) LoRA Single: a LLM with a
    unique set of LoRA modules is fine-tuned for each task using its corresponding
    samples.'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 带有 LoRA 的 LLM：作为一种经过充分测试的微调算法，LoRA 由于其有效性和效率，自然与 LLMs 兼容 [[36](#bib.bib36)]。在多任务学习
    (MTL) 情况下，可以用 LoRA 实现两个简单场景：(i) LoRA 完整：同时利用来自不同任务的所有样本，通过 LoRA 对预训练的中央 LLM 进行微调。(ii)
    LoRA 单一：针对每个任务使用其对应样本，微调带有独特 LoRA 模块的 LLM。
- en: •
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'LLM with multi-task LoRA: For this type of baselines, the basic pre-trained
    LLMs are fine-tuned by two recently released LoRA algorithms having MTL capability,
    separately. One is LoRAHub [[39](#bib.bib39)] that fine-tunes a distinct set of
    LoRA for each task respectively and combines all fine-tuned LLMs using the weight
    optimization via gradient-free methods. The other one is MOE-LoRA, which integrates
    mixture-of-expert (MOE) structure [[34](#bib.bib34)] into LoRA algorithm.'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 带有多任务 LoRA 的 LLM：对于这种基线，基本的预训练 LLMs 分别通过两个最近发布的具有 MTL 能力的 LoRA 算法进行微调。其中一个是
    LoRAHub [[39](#bib.bib39)]，它对每个任务分别微调一组 LoRA，并通过无梯度优化方法结合所有微调的 LLMs。另一个是 MOE-LoRA，它将专家混合（MOE）结构
    [[34](#bib.bib34)] 集成到 LoRA 算法中。
- en: Finally, it is worthy noting that ChatGLM-6B [[48](#bib.bib48)] is utilized
    in both LLM with LoRA and LLM with multi-task LoRA because of its dominance in
    Chinese text related competitions.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，值得注意的是，ChatGLM-6B [[48](#bib.bib48)] 在带有 LoRA 的 LLM 和带有多任务 LoRA 的 LLM 中都得到了使用，因为它在与中文文本相关的竞赛中表现突出。
- en: 5.3 Implementation Details
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 实施细节
- en: 'The configuration details are presented as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 配置详情如下：
- en: •
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Softare and Hardware: Software configuration is PyTorch 1.12.0 and Python 3.6.5
    while hardware configuration is Tesla A100 GPU.'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 软件和硬件：软件配置为 PyTorch 1.12.0 和 Python 3.6.5，而硬件配置为 Tesla A100 GPU。
- en: •
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Basic LLMs: As for approaches with fine-tuning (i.e., LLM with LoRA, LLM with
    multi-task LoRA, and proposed CGC-LoRA), ChatGLM-6B [[48](#bib.bib48)] serves
    as the basic LLM.'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基本 LLMs：对于微调的方法（即，带有 LoRA 的 LLM、带有多任务 LoRA 的 LLM 和提出的 CGC-LoRA），ChatGLM-6B [[48](#bib.bib48)]
    作为基本 LLM。
- en: •
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Input/Output Length: The maximum length of input and output are set to 1024
    and 196, separately.'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输入/输出长度：输入和输出的最大长度分别设置为 1024 和 196。
- en: •
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Hyper-parameters: Batch size and maximum training steps are configured to 64
    and 8000, respectively. Besides, the $\alpha$ value is fixed at 0.1.'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 超参数：批量大小和最大训练步数分别配置为 64 和 8000。此外，$\alpha$ 值固定为 0.1。
- en: •
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Trainable Layers: Regarding all fine-tuned LLM, the trainable layers are limited
    within the self-attention (i.e., Query, Key, Value head) and linear layers of
    ChatGLM-6B. More details are shown as Figure [3](#S4.F3 "Figure 3 ‣ 4.1 Overview
    ‣ 4 CGC-LoRA ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern in
    LLMs Using The CGC-LoRA Algorithm").'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可训练层：关于所有微调的 LLM，可训练层仅限于 ChatGLM-6B 的自注意力（即 Query、Key、Value 头）和线性层。更多细节见图 [3](#S4.F3
    "Figure 3 ‣ 4.1 Overview ‣ 4 CGC-LoRA ‣ A Framework to Implement 1+N Multi-task
    Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm")。
- en: 5.4 Evaluation Metrics
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 评估指标
- en: Since both PromptCBLUE and Firefly contain a variety of tasks, different metrics
    are implemented to evaluate the performance of baselines and proposed CGC-LoRA
    on each task. As for PromptCBLUE dataset, CMeIE, CHIPCDN, CHIP-CDEE and CHIP-MDCFNPC
    evaluate the performance using Micro-F1 score and Macro-F1 score is calculated
    for CHIP-CTC and KUAKE-QIC. In addition, Rouge-L [[49](#bib.bib49)] is applied
    in text generation tasks, such as report generation and doctor dialogue. To assess
    the overall performance, the average score over all tasks is implemented. As for
    Firefly dataset, identical evaluation metrics are applied. In particular, Micro-F1
    score is used for Keyword Recognition, MRC, and NER while Macro-F1 score is calculated
    for Text Matching, NLI, and Sentiment Analyze. Also, for text generation tasks
    (e.g., Text Correction and Summary), Rouge-L serves as the evaluation metric.
    Similarly, the average score is used to evaluate the overall performance.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 由于PromptCBLUE和Firefly数据集包含多种任务，因此实施了不同的指标来评估基线方法和提出的CGC-LoRA在每个任务上的性能。对于PromptCBLUE数据集，CMeIE、CHIPCDN、CHIP-CDEE和CHIP-MDCFNPC使用Micro-F1分数来评估性能，而CHIP-CTC和KUAKE-QIC则计算Macro-F1分数。此外，Rouge-L
    [[49](#bib.bib49)] 被应用于文本生成任务，如报告生成和医生对话。为了评估总体性能，计算了所有任务的平均分数。对于Firefly数据集，采用了相同的评估指标。特别地，Micro-F1分数用于关键词识别、MRC和NER，而Macro-F1分数计算用于文本匹配、NLI和情感分析。此外，对于文本生成任务（例如文本校正和摘要），Rouge-L作为评估指标。类似地，使用平均分数来评估总体性能。
- en: 5.5 Overall Performance
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5 总体性能
- en: 'Table [III](#S5.T3 "Table III ‣ 5.5 Overall Performance ‣ 5 Experiments ‣ A
    Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA
    Algorithm") and Table [IV](#S5.T4 "Table IV ‣ 5.5 Overall Performance ‣ 5 Experiments
    ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The
    CGC-LoRA Algorithm") declare the thorough experimental results of the proposed
    CGC-LoRA and baselines on PromptCBLUE dataset and Firefly dataset, respectively.
    According to the average scores across all tasks of two datasets, a substantial
    conclusion can be made that the proposed CGC-LoRA persistently surpasses all baselines
    and also achieves the most robust performance across a variety of tasks on two
    totally different datasets. More specific investigation to the experimental results
    is presented as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 表格[III](#S5.T3 "表格 III ‣ 5.5 总体性能 ‣ 5 实验 ‣ 在LLMs中使用CGC-LoRA算法实现1+N多任务微调模式的框架")和表格[IV](#S5.T4
    "表格 IV ‣ 5.5 总体性能 ‣ 5 实验 ‣ 在LLMs中使用CGC-LoRA算法实现1+N多任务微调模式的框架")分别列出了在PromptCBLUE数据集和Firefly数据集上提出的CGC-LoRA及基线方法的详细实验结果。根据两个数据集所有任务的平均分数，可以得出一个重要结论：提出的CGC-LoRA始终超越所有基线方法，并在两个完全不同的数据集上实现了各种任务的最强性能。对实验结果的更具体调查如下：
- en: •
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'LLMs without fine-tuning: As a baseline without any fine-tuning, ChatGPT falls
    behind other approaches on both PromptCBLUE and Firefly datasets, which, in a
    large sense, underlines the value of fine-tuning procedure. More specifically,
    task-specific information can be, to a certain extent, injected into the pre-train
    LLMs through further fine-tuning, which finally has a positive effect on the comprehensive
    performance on specific tasks. In spite of the global deficiency, we still can
    observe that ChatGPT outperforms all other methods on Doctor Dialogue thanks to
    its excellent competence on dialogue comprehension and generation.'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 没有微调的LLMs：作为没有进行任何微调的基线，ChatGPT在PromptCBLUE和Firefly数据集上的表现落后于其他方法，这在很大程度上突显了微调过程的价值。更具体地说，通过进一步微调，可以在一定程度上将特定任务的信息注入到预训练LLMs中，这最终对特定任务的综合性能产生积极影响。尽管存在全球性不足，但我们仍然可以观察到，ChatGPT在医生对话任务上超越了所有其他方法，这得益于其出色的对话理解和生成能力。
- en: •
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'LLM with LoRA: For LoRA strategy, we make an attempt to implement two straightforward
    schemes (i.e., LLM Full and LLM Single) to adapt it to multi-task learning (MTL).
    Between them, LLM Full is in the lead on nearly all tasks and also the overall
    performance on PromptCBLUE dataset while a completely opposite achievement is
    observed on Firefly dataset. We suspect that such a paradoxical conclusion is
    caused by variable similarity across distinctive tasks on those two datasets and
    this investigation typically demonstrates the significance and necessity of sharing
    knowledge across diverse tasks in a reasonable way that is also the inspiration
    to the proposed CGC-LoRA.'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 具有LoRA的LLM：对于LoRA策略，我们尝试实现两种简单方案（即LLM Full和LLM Single）以将其适应于多任务学习（MTL）。其中，LLM
    Full在几乎所有任务和PromptCBLUE数据集上的整体表现中处于领先地位，而在Firefly数据集上却观察到完全相反的结果。我们怀疑这种矛盾的结论是由于这两个数据集中任务间的相似性差异造成的，这项研究通常表明了在合理的方式下跨不同任务共享知识的重要性和必要性，这也是提出CGC-LoRA的灵感所在。
- en: •
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'LLM with multi-task LoRA: As two types of LoRA strategies that have been proven
    to be compatible with MTL, LoRAHub and MOE-LoRA serves as two competitive benchmarks.
    According to the results displayed in Table [III](#S5.T3 "Table III ‣ 5.5 Overall
    Performance ‣ 5 Experiments ‣ A Framework to Implement 1+N Multi-task Fine-tuning
    Pattern in LLMs Using The CGC-LoRA Algorithm") and Table [IV](#S5.T4 "Table IV
    ‣ 5.5 Overall Performance ‣ 5 Experiments ‣ A Framework to Implement 1+N Multi-task
    Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm"), MOE-LoRA leads the
    other baselines by a large margin on PromptCBLUE dataset while LoRAHub is ahead
    of others except for LoRA Single on Firefly dataset. Similarly, the contradictory
    consequence that indicates the sensitivity of algorithms to a wide range of tasks
    can still be disclosed. What is more important, it further signifies the significance
    of the network architecture that can promote effective and efficient information
    sharing across distinct tasks in a robust way.'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 具有多任务LoRA的LLM：作为两种已证明与MTL兼容的LoRA策略，LoRAHub和MOE-LoRA作为两个具有竞争力的基准。根据表格[III](#S5.T3
    "Table III ‣ 5.5 Overall Performance ‣ 5 Experiments ‣ A Framework to Implement
    1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm")和表格[IV](#S5.T4
    "Table IV ‣ 5.5 Overall Performance ‣ 5 Experiments ‣ A Framework to Implement
    1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm")中显示的结果，MOE-LoRA在PromptCBLUE数据集上远远领先于其他基准，而LoRAHub在Firefly数据集上领先于其他所有方法，仅次于LoRA
    Single。同样，表明算法对广泛任务的敏感性的矛盾结果仍然可以揭示。更重要的是，这进一步强调了网络架构的意义，它可以以一种稳健的方式促进跨不同任务的信息有效共享。
- en: •
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'CGC-LoRA: Thanks to the task-specific and task-common experts, CGC-LoRA offers
    an outstanding and also stable achievement on 16 tasks across two datasets and
    these 16 tasks cover widespread applications in natural language processing. Specifically,
    it widely leads the other approaches on 10 out of 16 tasks and also stays in a
    pioneering position on overall performance, which exposes its effectiveness, efficiency
    and also robustness.'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: CGC-LoRA：得益于任务特定和任务通用的专家，CGC-LoRA在两个数据集上的16个任务中表现出色且稳定，这16个任务涵盖了自然语言处理中的广泛应用。具体而言，在16个任务中的10个任务上，CGC-LoRA远远领先于其他方法，并且在整体表现上也处于领先地位，这揭示了其有效性、效率和鲁棒性。
- en: In summary, according to the experimental results displayed in Table [III](#S5.T3
    "Table III ‣ 5.5 Overall Performance ‣ 5 Experiments ‣ A Framework to Implement
    1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm") and
    Table [IV](#S5.T4 "Table IV ‣ 5.5 Overall Performance ‣ 5 Experiments ‣ A Framework
    to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm"),
    the proposed CGC-LoRA demonstrates its preferable achievement over basic LoRA
    strategies (i.e., LoRA Full and LoRA Single) and multi-task LoRA schemes (i.e.,
    LoRAHub and MOE-LoRA) on these two public datasets.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，根据表格[III](#S5.T3 "Table III ‣ 5.5 Overall Performance ‣ 5 Experiments ‣ A
    Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA
    Algorithm")和表格[IV](#S5.T4 "Table IV ‣ 5.5 Overall Performance ‣ 5 Experiments
    ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The
    CGC-LoRA Algorithm")中显示的实验结果，所提出的CGC-LoRA在这两个公开数据集上表现优于基本LoRA策略（即LoRA Full和LoRA
    Single）以及多任务LoRA方案（即LoRAHub和MOE-LoRA）。
- en: 'Table III: The overall results of three kinds of baselines (i.e., LLM without
    fine-tuning, LLM with LoRA, and LLM with multi-task LoRA) and CGC-LoRA on PromptCBLUE
    dataset. The boldface stands for the highest score and the underline represents
    the best result of the baselines. “$\star$” marks the statistically significant
    improvements (i.e., two-sided t-test with p < 0.05) over the best baseline.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '表 III: 三种基线（即，没有微调的LLM、带LoRA的LLM和多任务LoRA的LLM）以及CGC-LoRA在PromptCBLUE数据集上的总体结果。**粗体**表示最高得分，_下划线_表示基线中的最佳结果。
    “$\star$” 标记了相对于最佳基线的统计显著改进（即双侧t检验，p < 0.05）。'
- en: '| Model | CMeIE | CHIP-CDN | CHIP-CDEE | CHIP-MDCFNPC | CHIP-CTC | KUAKE-QIC
    | IMCS-V2-MRG | MedDG | Avg. |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | CMeIE | CHIP-CDN | CHIP-CDEE | CHIP-MDCFNPC | CHIP-CTC | KUAKE-QIC |
    IMCS-V2-MRG | MedDG | 平均值 |'
- en: '| ChatGPT | 0.3058 | 0.6069 | 0.2838 | 0.5854 | 0.5253 | 0.4851 | 0.3253 |
    0.1361 | 0.4067 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| ChatGPT | 0.3058 | 0.6069 | 0.2838 | 0.5854 | 0.5253 | 0.4851 | 0.3253 |
    0.1361 | 0.4067 |'
- en: '| LoRA Full | 0.5089 | 0.8748 | 0.5464 | 0.7780 | 0.8758 | 0.8615 | 0.3678
    | 0.1113 | 0.6155 |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| LoRA 完整 | 0.5089 | 0.8748 | 0.5464 | 0.7780 | 0.8758 | 0.8615 | 0.3678 |
    0.1113 | 0.6155 |'
- en: '| LoRA Single | 0.4984 | 0.8882 | 0.5528 | 0.7765 | 0.8694 | 0.8524 | 0.3583
    | 0.1143 | 0.6138 |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| LoRA 单体 | 0.4984 | 0.8882 | 0.5528 | 0.7765 | 0.8694 | 0.8524 | 0.3583 |
    0.1143 | 0.6138 |'
- en: '| LoRAHub | 0.4411 | 0.8442 | 0.5041 | 0.7177 | 0.8564 | 0.8502 | 0.3061 |
    0.1192 | 0.5799 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| LoRAHub | 0.4411 | 0.8442 | 0.5041 | 0.7177 | 0.8564 | 0.8502 | 0.3061 |
    0.1192 | 0.5799 |'
- en: '| MOE-LoRA | 0.5193 | 0.8928 | 0.5697 | $\mathbf{0.7933}^{\star}$ | 0.8691
    | 0.8675 | 0.3681 | 0.1089 | 0.6236 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| MOE-LoRA | 0.5193 | 0.8928 | 0.5697 | $\mathbf{0.7933}^{\star}$ | 0.8691
    | 0.8675 | 0.3681 | 0.1089 | 0.6236 |'
- en: '| CGC-LoRA | $\mathbf{0.5207}$ | $\mathbf{0.8948}$ | $\mathbf{0.5720}$ | 0.7822
    | 0.8509 | $\mathbf{0.8727}$ | $\mathbf{0.3808}^{\star}$ | 0.1184 | $\mathbf{0.6240}$
    |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| CGC-LoRA | $\mathbf{0.5207}$ | $\mathbf{0.8948}$ | $\mathbf{0.5720}$ | 0.7822
    | 0.8509 | $\mathbf{0.8727}$ | $\mathbf{0.3808}^{\star}$ | 0.1184 | $\mathbf{0.6240}$
    |'
- en: 'Table IV: The overall results of three kinds of baselines (i.e., LLM without
    fine-tuning, LLM with LoRA, and LLM with multi-task LoRA) and CGC-LoRA on PromptCBLUE
    dataset. The boldface stands for the highest score and the underline represents
    the best result of the baselines. “$\star$” marks the statistically significant
    improvements (i.e., two-sided t-test with p < 0.05) over the best baseline.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '表 IV: 三种基线（即，没有微调的LLM、带LoRA的LLM和多任务LoRA的LLM）以及CGC-LoRA在PromptCBLUE数据集上的总体结果。**粗体**表示最高得分，_下划线_表示基线中的最佳结果。
    “$\star$” 标记了相对于最佳基线的统计显著改进（即双侧t检验，p < 0.05）。'
- en: '| Model | TC | Summary | KR | TM | MRC | NER | NLI | SA | Avg. |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | TC | 概要 | KR | TM | MRC | NER | NLI | SA | 平均值 |'
- en: '| ChatGPT | 0.8799 | 0.2320 | 0.2275 | 0.4700 | 0.6142 | 0.2379 | 0.5408 |
    0.9593 | 0.5202 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| ChatGPT | 0.8799 | 0.2320 | 0.2275 | 0.4700 | 0.6142 | 0.2379 | 0.5408 |
    0.9593 | 0.5202 |'
- en: '| LoRA Full | 0.9057 | 0.2605 | 0.2740 | 0.7766 | 0.6584 | 0.5500 | 0.7233
    | 0.9866 | 0.6418 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| LoRA 完整 | 0.9057 | 0.2605 | 0.2740 | 0.7766 | 0.6584 | 0.5500 | 0.7233 |
    0.9866 | 0.6418 |'
- en: '| LoRA Single | 0.9174 | $\mathbf{0.2745}$ | $\mathbf{0.2744}$ | $\mathbf{0.7966}$
    | 0.7222 | 0.5807 | 0.7027 | 0.9866 | 0.6569 |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| LoRA 单体 | 0.9174 | $\mathbf{0.2745}$ | $\mathbf{0.2744}$ | $\mathbf{0.7966}$
    | 0.7222 | 0.5807 | 0.7027 | 0.9866 | 0.6569 |'
- en: '| LoRAHub | 0.9168 | 0.2681 | 0.2447 | 0.7733 | 0.7310 | 0.5889 | 0.7433 |
    0.9833 | 0.6562 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| LoRAHub | 0.9168 | 0.2681 | 0.2447 | 0.7733 | 0.7310 | 0.5889 | 0.7433 |
    0.9833 | 0.6562 |'
- en: '| MOE-LoRA | 0.9093 | 0.2599 | 0.2471 | 0.7833 | 0.7230 | 0.5683 | 0.7333 |
    0.9766 | 0.6501 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| MOE-LoRA | 0.9093 | 0.2599 | 0.2471 | 0.7833 | 0.7230 | 0.5683 | 0.7333 |
    0.9766 | 0.6501 |'
- en: '| CGC-LoRA | $\mathbf{0.9178}$ | 0.2681 | 0.2720 | 0.7866 | $\mathbf{0.7311}$
    | $\mathbf{0.6085}^{\star}$ | $\mathbf{0.7533}^{\star}$ | $\mathbf{0.9900}$ |
    $\mathbf{0.6659}^{\star}$ |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| CGC-LoRA | $\mathbf{0.9178}$ | 0.2681 | 0.2720 | 0.7866 | $\mathbf{0.7311}$
    | $\mathbf{0.6085}^{\star}$ | $\mathbf{0.7533}^{\star}$ | $\mathbf{0.9900}$ |
    $\mathbf{0.6659}^{\star}$ |'
- en: 'Table V: The experimental results of ablation study for CGC-LoRA. The boldface
    stands for the highest score. “$\star$” marks the statistically significant improvements
    (i.e., two-sided t-test with p < 0.05) over the other approaches.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '表 V: CGC-LoRA的消融研究实验结果。**粗体**表示最高得分。 “$\star$” 标记了相对于其他方法的统计显著改进（即双侧t检验，p <
    0.05）。'
- en: '| Model | CMeIE | CHIP-CDN | CHIP-CDEE | CHIP-MDCFNPC | CHIP-CTC | KUAKE-QIC
    | IMCS-V2-MRG | MedDG | Avg. |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | CMeIE | CHIP-CDN | CHIP-CDEE | CHIP-MDCFNPC | CHIP-CTC | KUAKE-QIC |
    IMCS-V2-MRG | MedDG | 平均值 |'
- en: '| w/o CGC | 0.5089 | 0.8748 | 0.5464 | 0.7780 | 0.8758 | 0.8615 | 0.3678 |
    0.1113 | 0.6155 |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 无CGC | 0.5089 | 0.8748 | 0.5464 | 0.7780 | 0.8758 | 0.8615 | 0.3678 | 0.1113
    | 0.6155 |'
- en: '| w/o gate | 0.5015 | 0.8840 | 0.5378 | 0.7789 | 0.8818 | 0.8699 | 0.3709 |
    0.1140 | 0.6174 |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 无门 | 0.5015 | 0.8840 | 0.5378 | 0.7789 | 0.8818 | 0.8699 | 0.3709 | 0.1140
    | 0.6174 |'
- en: '| w multiple gates | 0.5246 | 0.8874 | 0.5523 | 0.7818 | 0.8300 | 0.8716 |
    0.3645 | 0.1205 | 0.6166 |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 带多个门 | 0.5246 | 0.8874 | 0.5523 | 0.7818 | 0.8300 | 0.8716 | 0.3645 | 0.1205
    | 0.6166 |'
- en: '| CGC-LoRA | 0.5207 | $\mathbf{0.8948}^{\star}$ | $\mathbf{0.5720}^{\star}$
    | 0.7822 | 0.8509 | $\mathbf{0.8727}$ | $\mathbf{0.3808}^{\star}$ | 0.1184 | $\mathbf{0.6240}^{\star}$
    |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| CGC-LoRA | 0.5207 | $\mathbf{0.8948}^{\star}$ | $\mathbf{0.5720}^{\star}$
    | 0.7822 | 0.8509 | $\mathbf{0.8727}$ | $\mathbf{0.3808}^{\star}$ | 0.1184 | $\mathbf{0.6240}^{\star}$
    |'
- en: 5.6 Ablation Study
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.6 消融研究
- en: To extensively investigate the impact of each component in proposed CGC-LoRA
    structure, we conduct a comprehensive ablation study on PromptCBLUE dataset and
    the results are exhibited in Table [V](#S5.T5 "Table V ‣ 5.5 Overall Performance
    ‣ 5 Experiments ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern
    in LLMs Using The CGC-LoRA Algorithm").
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 为了广泛调查所提 CGC-LoRA 结构中每个组件的影响，我们在 PromptCBLUE 数据集上进行了全面的消融研究，结果展示在表 [V](#S5.T5
    "Table V ‣ 5.5 Overall Performance ‣ 5 Experiments ‣ A Framework to Implement
    1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm")。
- en: •
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'w/o CGC: As a primary module of CGC-LoRA structure, it plays a compelling role
    on capturing and processing both task-common and task-specific knowledge. CGC-LoRA
    will naturally reverts to LoRA Full when excluding the CGC architecture. Comparing
    with CGC-LoRA, w/o CGC demonstrates an inferior performance on both task-specific
    evaluation and overall assessment, highlighting that CGC module critically contributes
    to the outstanding achievement of proposed CGC-LoRA.'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 无 CGC：作为 CGC-LoRA 结构的主要模块，它在捕捉和处理任务通用和任务特定知识方面发挥了重要作用。排除 CGC 架构时，CGC-LoRA 会自然回退到
    LoRA 完整模式。与 CGC-LoRA 相比，无 CGC 在任务特定评估和整体评估上表现不佳，突显了 CGC 模块对 CGC-LoRA 卓越成就的重要贡献。
- en: •
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'w/o gate: Task motivated gate function is responsible for calculating the contribution
    of task-common and task-specific experts to each task only based on task IDs.
    For the w/o gate variant, uniform expert weights, bypassing the gate function,
    are employed instead of expert-specific ones. As shown in Table [V](#S5.T5 "Table
    V ‣ 5.5 Overall Performance ‣ 5 Experiments ‣ A Framework to Implement 1+N Multi-task
    Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm"), CGC-LoRA exceeds the
    w/o gate variant on 7 out of 8 tasks, which proves the validness of task motivated
    gate module.'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 无门控：任务驱动的门控函数仅根据任务 ID 计算任务通用专家和任务特定专家对每个任务的贡献。对于无门控变体，使用均匀的专家权重，而不是特定于专家的权重，跳过了门控函数。正如表
    [V](#S5.T5 "Table V ‣ 5.5 Overall Performance ‣ 5 Experiments ‣ A Framework to
    Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm")
    所示，CGC-LoRA 在 8 个任务中的 7 个任务上超过了无门控变体，这证明了任务驱动门控模块的有效性。
- en: •
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'w multiple gates: As mentioned in Section [4.3](#S4.SS3 "4.3 Task-motivated
    Gate Function ‣ 4 CGC-LoRA ‣ A Framework to Implement 1+N Multi-task Fine-tuning
    Pattern in LLMs Using The CGC-LoRA Algorithm"), motivated gate function can be
    unique for each CGC-LoRA layer and it is denoted as the w multiple gates variant.
    From Table [V](#S5.T5 "Table V ‣ 5.5 Overall Performance ‣ 5 Experiments ‣ A Framework
    to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm"),
    we can inspect that CGC-LoRA with multiple gates cannot attain comparable results
    to the one with single gate on different tasks, in a large sense, due to its over-parameterization
    and also considering a higher count of trainable parameters brought by multiple
    gate functions, the proposed CGC-LoRA is designed as a single gate setup.'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 多门控：如在第 [4.3](#S4.SS3 "4.3 Task-motivated Gate Function ‣ 4 CGC-LoRA ‣ A Framework
    to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The CGC-LoRA Algorithm")
    节中提到，门控函数可以对每个 CGC-LoRA 层都是唯一的，这被称为多门控变体。从表 [V](#S5.T5 "Table V ‣ 5.5 Overall
    Performance ‣ 5 Experiments ‣ A Framework to Implement 1+N Multi-task Fine-tuning
    Pattern in LLMs Using The CGC-LoRA Algorithm") 可以看出，由于其过度参数化以及多个门控函数带来的更多可训练参数，CGC-LoRA
    使用多个门控无法在不同任务上达到与单门控相当的结果，因此所提的 CGC-LoRA 设计为单门控设置。
- en: The ablation study demonstrate the effectiveness and necessity of fundamental
    modules (i.e., CGC and task motivated gate function) of the proposed CGC-LoRA
    structure, as well as the significance of specific optimization pattern.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 消融研究展示了所提 CGC-LoRA 结构中基本模块（即 CGC 和任务驱动门控函数）的有效性和必要性，以及特定优化模式的重要性。
- en: 5.7 Hyper-parameter Analysis
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.7 超参数分析
- en: To explain the primary hyper-parameter selection in our study, we investigate
    the influence of the task-common expert number $N_{C}$ while the impact of the
    task-specific expert number is not considered since it is usually equal to the
    counts of tasks in MTL. Besides, we also explore the effect of rank of each expert
    using both task specific evaluation metrics and the average evaluation score on
    PromptCBLUE dataset. As illustrated in Table [VI](#S5.T6 "Table VI ‣ 5.7 Hyper-parameter
    Analysis ‣ 5 Experiments ‣ A Framework to Implement 1+N Multi-task Fine-tuning
    Pattern in LLMs Using The CGC-LoRA Algorithm"), we set the number of task-specific
    expert and the rank of each expert to 8 and 2, separately. As for the impact of
    numbers of the task-common expert on the average score, the curve is in a parabola
    shape and the peak occurs at numbers equal to 8 and this result clarifies that
    adequate task-common experts are prerequisite to completely capture and efficiently
    process the task-common knowledge across different tasks. In addition, when fixing
    the counts of both task-specific and task-common expert at 8, we probe the influence
    of rank of each expert. Similarly, the curve is also in a parabola shape the the
    optimal overall achievement happens at rank equal to 2 and detailed results are
    displayed in Table [VII](#S5.T7 "Table VII ‣ 5.7 Hyper-parameter Analysis ‣ 5
    Experiments ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs
    Using The CGC-LoRA Algorithm").
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解释我们研究中的主要超参数选择，我们调查了任务共同专家数量 $N_{C}$ 的影响，而任务特定专家数量的影响未被考虑，因为它通常等于 MTL 中任务的数量。此外，我们还探讨了每个专家等级的影响，使用任务特定评估指标和
    PromptCBLUE 数据集上的平均评估分数。如表 [VI](#S5.T6 "Table VI ‣ 5.7 Hyper-parameter Analysis
    ‣ 5 Experiments ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern
    in LLMs Using The CGC-LoRA Algorithm") 所示，我们将任务特定专家的数量和每个专家的等级分别设置为 8 和 2。至于任务共同专家数量对平均分数的影响，曲线呈抛物线形状，峰值出现在数量为
    8 时，这一结果澄清了充足的任务共同专家是完全捕捉和高效处理不同任务间任务共同知识的前提。此外，当任务特定专家和任务共同专家的数量都固定为 8 时，我们探讨了每个专家等级的影响。同样，曲线也呈抛物线形状，最佳整体成绩发生在等级为
    2 时，详细结果显示在表 [VII](#S5.T7 "Table VII ‣ 5.7 Hyper-parameter Analysis ‣ 5 Experiments
    ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using The
    CGC-LoRA Algorithm")。
- en: 'Table VI: The experimental results of Hyper-parameter analysis for CGC-LoRA
    on PromptCBLUE dataset. The number of task-specific experts is fixed at 8, which
    is equal to the counts of tasks and the rank of each expert is set to 2\. The
    boldface stands for the highest score. “$\star$” marks the statistically significant
    improvements (i.e., two-sided t-test with p < 0.05) over the other hyper-parameter
    settings.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 表 VI：CGC-LoRA 在 PromptCBLUE 数据集上的超参数分析实验结果。任务特定专家的数量固定为 8，这等于任务数量，且每个专家的等级设置为
    2。粗体字表示最高分。"$\star$" 标记了与其他超参数设置相比具有统计学显著改进的结果（即，双侧 t 检验 p < 0.05）。
- en: '| # task-common experts | CMeIE | CHIP-CDN | CHIP-CDEE | CHIP-MDCFNPC | CHIP-CTC
    | KUAKE-QIC | IMCS-V2-MRG | MedDG | Avg. |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 任务共同专家数量 | CMeIE | CHIP-CDN | CHIP-CDEE | CHIP-MDCFNPC | CHIP-CTC | KUAKE-QIC
    | IMCS-V2-MRG | MedDG | 平均 |'
- en: '| 2 | 0.4958 | 0.8751 | 0.5532 | 0.7775 | 0.8400 | 0.8564 | 0.3608 | 0.1167
    | 0.6094 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 0.4958 | 0.8751 | 0.5532 | 0.7775 | 0.8400 | 0.8564 | 0.3608 | 0.1167
    | 0.6094 |'
- en: '| 4 | 0.5137 | 0.8922 | 0.5599 | 0.7776 | 0.8309 | 0.8694 | 0.3593 | 0.1159
    | 0.6149 |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 0.5137 | 0.8922 | 0.5599 | 0.7776 | 0.8309 | 0.8694 | 0.3593 | 0.1159
    | 0.6149 |'
- en: '| 8 | $\mathbf{0.5206}^{\star}$ | 0.8947 | $\mathbf{0.5720}^{\star}$ | 0.7822
    | 0.8509 | 0.8727 | $\mathbf{0.3807}^{\star}$ | 0.1184 | $\mathbf{0.6240}^{\star}$
    |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| 8 | $\mathbf{0.5206}^{\star}$ | 0.8947 | $\mathbf{0.5720}^{\star}$ | 0.7822
    | 0.8509 | 0.8727 | $\mathbf{0.3807}^{\star}$ | 0.1184 | $\mathbf{0.6240}^{\star}$
    |'
- en: '| 16 | 0.4984 | 0.8882 | 0.5528 | 0.7765 | $\mathbf{0.8694}^{\star}$ | 0.8761
    | 0.3583 | 0.1143 | 0.6167 |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| 16 | 0.4984 | 0.8882 | 0.5528 | 0.7765 | $\mathbf{0.8694}^{\star}$ | 0.8761
    | 0.3583 | 0.1143 | 0.6167 |'
- en: 'Table VII: The experimental results of Hyper-parameter analysis for CGC-LoRA
    on PromptCBLUE dataset. The number of task-specific and task-common experts are
    both fixed at 8 and the rank of each expert stay the same. The boldface stands
    for the highest score. “$\star$” marks the statistically significant improvements
    (i.e., two-sided t-test with p < 0.05) over the other hyper-parameter settings.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 表 VII：CGC-LoRA 在 PromptCBLUE 数据集上的超参数分析实验结果。任务特定专家和任务共同专家的数量都固定为 8，每个专家的等级保持不变。粗体字表示最高分。"$\star$"
    标记了与其他超参数设置相比具有统计学显著改进的结果（即，双侧 t 检验 p < 0.05）。
- en: '| rank | CMeIE | CHIP-CDN | CHIP-CDEE | CHIP-MDCFNPC | CHIP-CTC | KUAKE-QIC
    | IMCS-V2-MRG | MedDG | Avg. |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| 等级 | CMeIE | CHIP-CDN | CHIP-CDEE | CHIP-MDCFNPC | CHIP-CTC | KUAKE-QIC |
    IMCS-V2-MRG | MedDG | 平均 |'
- en: '| 1 | 0.5136 | 0.8886 | 0.5625 | 0.7878 | 0.8463 | 0.7960 | 0.3609 | 0.1147
    | 0.6088 |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0.5136 | 0.8886 | 0.5625 | 0.7878 | 0.8463 | 0.7960 | 0.3609 | 0.1147
    | 0.6088 |'
- en: '| 2 | $\mathbf{0.5206}^{\star}$ | 0.8947 | 0.5720 | 0.7822 | 0.8509 | 0.8727
    | $\mathbf{0.3807}^{\star}$ | 0.1184 | 0.6240 |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| 2 | $\mathbf{0.5206}^{\star}$ | 0.8947 | 0.5720 | 0.7822 | 0.8509 | 0.8727
    | $\mathbf{0.3807}^{\star}$ | 0.1184 | 0.6240 |'
- en: '| 4 | 0.5054 | 0.8826 | 0.5801 | 0.7772 | 0.8481 | 0.8669 | 0.3708 | 0.1146
    | 0.6182 |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 0.5054 | 0.8826 | 0.5801 | 0.7772 | 0.8481 | 0.8669 | 0.3708 | 0.1146
    | 0.6182 |'
- en: 6 Related Works
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 相关工作
- en: 'In this section, we will review two research areas that are directly related
    to our work: (i) Multi-task learning (MTL) and (ii) Parameter efficient fine-tuning
    (PEFT). In a large sense, the proposed CGC-LoRA structure intents to unify these
    two strategies in an innovative way.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将回顾两个直接与我们工作相关的研究领域：(i) 多任务学习 (MTL) 和 (ii) 参数高效微调 (PEFT)。在更广泛的意义上，提出的
    CGC-LoRA 结构旨在以创新方式统一这两种策略。
- en: 6.1 Multi-Task Learning (MTL)
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 多任务学习 (MTL)
- en: Hard parameter sharing [[31](#bib.bib31)] gives the first and most basic attempt
    to achieve MTL framework while the unfavorable information transfer caused by
    straightforward parameters sharing across tasks frequently appears. To solve such
    a negative transfer issue, cross-stitch network [[32](#bib.bib32)] and sluice
    network [[33](#bib.bib33)] are proposed successively, both of which consist of
    weights of linear combinations and aim to merge knowledge from distinct tasks
    discriminatorily. Unfortunately, the seesawing problem emerges since knowledge
    from various tasks is coarsely blended with static weights for all samples. To
    further enhance the learning efficiency in multi-task cases, several studies with
    the gate structure and attention mechanism are introduced and such a design intends
    to make message fusion from individual tasks more flexible and effective. For
    example, Mixture-of-Experts (MOE) model first presents an innovative architecture
    that task-common experts are shared at the bottom layer while information from
    these experts is fused through a gate function at the top layer [[34](#bib.bib34)].
    Next, Multi-Gate Mixture-of-Experts (MMOE) network extends the single-gate structure
    in MOE to the multiple-gate one, which can assign personalized fusing weights
    to different tasks [[26](#bib.bib26)]. Furthermore, Progressive Layered Extraction
    (PLE) architecture incorporates both task-common and task-specific experts into
    the model. More specifically, in order to alleviate task conflict and seesawing
    problems caused by complicated task correlations, parameters of task-common and
    task-specific experts are isolated in a explicit way, by which can make the convergence
    during optimization procedure more valid in practice. In this work, we aim to
    broaden the application scenarios of these impressive schemes to fine-tuning process
    of large language models (LLMs) to solve similar issues (e.g., the seesawing issue
    and the task conflict problem).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 硬参数共享 [[31](#bib.bib31)] 是实现 MTL 框架的第一次也是最基本的尝试，但由于任务间直接参数共享所导致的不利信息转移问题经常出现。为了解决这种负迁移问题，交叉缝合网络
    [[32](#bib.bib32)] 和排水网络 [[33](#bib.bib33)] 先后被提出，这两者都由线性组合的权重组成，并旨在有选择地融合来自不同任务的知识。不幸的是，由于不同任务的知识与所有样本的静态权重粗糙融合，摇摆问题出现。为了进一步提升多任务情况下的学习效率，引入了几种具有门控结构和注意力机制的研究，这种设计旨在使来自各个任务的消息融合更加灵活和有效。例如，专家混合模型
    (MOE) 首次提出了一种创新架构，即任务共通的专家在底层共享，而这些专家的信息通过顶层的门控函数进行融合 [[34](#bib.bib34)]。接着，多门控专家混合网络
    (MMOE) 将 MOE 中的单门控结构扩展为多门控结构，可以为不同任务分配个性化的融合权重 [[26](#bib.bib26)]。此外，渐进分层提取 (PLE)
    架构将任务共通专家和任务特定专家都纳入模型中。更具体地说，为了缓解由复杂任务相关性引起的任务冲突和摇摆问题，任务共通和任务特定专家的参数以显式方式隔离，这样可以使优化过程中的收敛在实践中更有效。在本研究中，我们旨在将这些令人印象深刻的方案的应用场景扩大到大语言模型
    (LLMs) 的微调过程中，以解决类似问题（如摇摆问题和任务冲突问题）。
- en: 6.2 Parameter Efficient Fine-tuning
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 参数高效微调
- en: 'With a rapid development of large language models (LLMs), a trend of enlarging
    the counts of parameters to further ameliorate LLMs becomes unambiguous gradually
    and as a result, adapting the pre-trained LLMs to tasks in a brand-new field through
    a full-parameter fine-tuning procedure turns to be prohibitive and impractical.
    Parameter efficient fine-tuning (PEFT), as an alternative algorithm, aims to degrade
    the computing cost level by updating partial parameters instead of entire ones.
    As in [[23](#bib.bib23), [50](#bib.bib50)], a straightforward idea is to only
    update parameters of selected layers (e.g., the output embedding layer) and meanwhile
    freeze parameters of the other layers. Alternatively, we can also append one or
    multiple additional layers to the base model and only parameters of these additional
    layers are trainable. As a modified version of the latter one, Adapter Tuning
    [[51](#bib.bib51)] incorporates a lightweight adapter network with only a few
    trainable parameters into LLMs and it demonstrates competitive performance to
    fine-tuning the top layers. Considering Prefix-tuning [[52](#bib.bib52)] and P-tuning
    [[37](#bib.bib37)], one or several task-specific virtual token, serving as an
    additional, trainable, continuous prompt or embedding, is appended to the original
    input and compared with the discrete prompt, the continuous one is more feasible
    and is not restricted to discrete real tokens [[53](#bib.bib53)]. To further break
    the limit of sequence length of LLMs, LoRA propose another train of thought, which
    incorporates a pair of trainable low-rank matrices into each dense layer and it
    also demonstrates comparable performance to full-parameter fine-tuning [[36](#bib.bib36)].
    Two outstanding advantages of LoRA are: (i) Low computing cost during fine-tuning.
    (ii) High efficiency during inference. However, LoRA can only learn paired integral
    matrices for all tasks that is not an effective and efficient way to capture the
    task-common and task-specific knowledge across distinct tasks in MTL. In this
    work, we proposed a framework to implement $1+N$ multi-task fine-tuning pattern
    in LLMs powered by CGC-LoRA network and it takes advantage of both MTL (e.g.,
    MMOE and PLE) and PEFT (e.g., P-tunig and LoRA) and reveals its parameter efficient
    fine-tuning capability in MTL cases.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大语言模型（LLMs）的快速发展，逐渐显现出扩大参数数量以进一步改进LLMs的趋势，因此，通过全参数微调过程将预训练LLMs适配到全新领域的任务变得不可行且不切实际。作为一种替代算法，参数高效微调（PEFT）旨在通过更新部分参数而非全部参数来降低计算成本。如在[[23](#bib.bib23),
    [50](#bib.bib50)]中所述，一个直接的思路是仅更新选定层（例如输出嵌入层）的参数，同时冻结其他层的参数。另一种选择是向基础模型中附加一个或多个额外层，仅这些附加层的参数是可训练的。作为后一种方法的修改版本，Adapter
    Tuning [[51](#bib.bib51)]将一个仅包含少量可训练参数的轻量级适配器网络集成到LLMs中，并且在性能上与微调顶层相竞争。考虑到Prefix-tuning
    [[52](#bib.bib52)]和P-tuning [[37](#bib.bib37)]，一个或多个特定任务的虚拟标记，作为附加的、可训练的、连续的提示或嵌入，被附加到原始输入中，与离散提示相比，连续提示更具可行性且不受离散真实标记的限制
    [[53](#bib.bib53)]。为了进一步突破LLMs的序列长度限制，LoRA提出了另一种思路，它将一对可训练的低秩矩阵引入每个密集层，并且在性能上也与全参数微调相当
    [[36](#bib.bib36)]。LoRA的两个突出优势是：（i）微调过程中的低计算成本。（ii）推理过程中的高效率。然而，LoRA只能学习配对的整体矩阵，这对于在MTL中捕捉不同任务的任务共性和任务特定知识并不是一种有效和高效的方法。在这项工作中，我们提出了一个框架，通过CGC-LoRA网络实现$1+N$多任务微调模式，它结合了MTL（例如MMOE和PLE）和PEFT（例如P-tuning和LoRA）的优势，并揭示了其在MTL场景中的参数高效微调能力。
- en: 7 Conclusion
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 结论
- en: 'In this work, we primarily take advantage of both parameter efficient fine-tuning
    (PEFT) approaches (i.e., LoRA algorithm) and multi-task learning (MTL) strategies
    (i.e., CGC network). In specific, we propose a general framework that implements
    $1+N$ multi-task fine-tuning pattern in LLMs. Firstly, a variety of tasks are
    grouped into $N$ clusters based on professional prior information or Inter-Task
    Affinity. Next, we release a novel multi-task PEFT method, named by CGC-LoRA,
    and a pre-trained central LLM is fine-tuned with $N$ one-to-one sets of CGC-LoRA
    modules on those clusters of tasks. Furthermore, a CGC-LoRA module consists of
    task-common and task-specific experts that can extract and process the common
    and specific knowledge across various tasks. Moreover, we also design a task-motivated
    gate function to decide the contributions of two types of experts to a given task.
    Since the gate function is only fed by task IDs, parameters of all experts can
    be represented in a unified way as illustrated in Section [4.3](#S4.SS3 "4.3 Task-motivated
    Gate Function ‣ 4 CGC-LoRA ‣ A Framework to Implement 1+N Multi-task Fine-tuning
    Pattern in LLMs Using The CGC-LoRA Algorithm"). Furthermore, inheriting from PEFT
    methods, the proposed CGC-LoRA offers an efficient way, in which a pre-trained
    LLM can be fine-tuned using a small counts of additional trainable parameters.
    To demonstrate the proposed framework powered by CGC-LoRA module, we conduct comprehensive
    experiments on two public datasets: (i) PromptCBLUE dataset: It is a medical specific
    dataset in Chinese; (ii) Firefly dataset: It is a general dataset including a
    variety of tasks also in Chinese. The experimental results definitely prove the
    effectiveness and efficiency of CGC-LoRA module. In the future, we plan to further
    explore the feasibility of implementing the proposed framework in MTL case of
    even higher diversity.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们主要利用了参数高效微调（PEFT）方法（即 LoRA 算法）和多任务学习（MTL）策略（即 CGC 网络）。具体来说，我们提出了一个通用框架，实现在
    LLMs 中的 $1+N$ 多任务微调模式。首先，根据专业的先验信息或任务间亲和力，将各种任务分为 $N$ 个集群。接下来，我们发布了一种新颖的多任务 PEFT
    方法，命名为 CGC-LoRA，并对这些任务集群中的 $N$ 对一组 CGC-LoRA 模块进行了微调。此外，CGC-LoRA 模块由任务共通和任务特定专家组成，可以提取和处理各种任务中的共通和特定知识。此外，我们还设计了一种任务驱动的门控函数来决定两种类型的专家对特定任务的贡献。由于门控函数仅由任务
    ID 提供输入，因此所有专家的参数可以以统一的方式表示，如第 [4.3](#S4.SS3 "4.3 Task-motivated Gate Function
    ‣ 4 CGC-LoRA ‣ A Framework to Implement 1+N Multi-task Fine-tuning Pattern in
    LLMs Using The CGC-LoRA Algorithm") 节所示。此外，继承自 PEFT 方法，所提出的 CGC-LoRA 提供了一种高效的方法，其中预训练的
    LLM 可以使用少量额外的可训练参数进行微调。为了展示由 CGC-LoRA 模块驱动的框架，我们在两个公开数据集上进行了全面实验：（i）PromptCBLUE
    数据集：这是一个中文医学特定数据集；（ii）Firefly 数据集：这是一个包括多种任务的中文通用数据集。实验结果明确证明了 CGC-LoRA 模块的有效性和效率。未来，我们计划进一步探索在更高多样性的
    MTL 情况下实施所提出框架的可行性。
- en: References
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Wayne Xin Zhao, Kun Zhou, et al. A survey of large language models. arXiv
    preprint arXiv:2303.18223, 2023.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Wayne Xin Zhao，Kun Zhou 等人。大型语言模型的调查。arXiv 预印本 arXiv:2303.18223，2023年。'
- en: '[2] Yupeng Chang, Xu Wang, et al. A survey on evaluation of large language
    models. arXiv preprint arXiv:2307.03109, 2023.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Yupeng Chang，Xu Wang 等人。关于大型语言模型评估的调查。arXiv 预印本 arXiv:2307.03109，2023年。'
- en: '[3] Humza Naveed, Asad Ullah Khan, et al. A comprehensive overview of large
    language models. arXiv preprint arXiv:2307.06435, 2023.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Humza Naveed，Asad Ullah Khan 等人。大型语言模型的全面概述。arXiv 预印本 arXiv:2307.06435，2023年。'
- en: '[4] Yiheng Liu, Tianle Han, et al. Summary of chatgpt-related research and
    perspective towards the future of large language models. Meta-Radiology, page
    100017, 2023.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Yiheng Liu，Tianle Han 等人。ChatGPT 相关研究总结及对大型语言模型未来的展望。Meta-Radiology，第 100017
    页，2023年。'
- en: '[5] Ouyang Long, Jeffrey, et al. Training language models to follow instructions
    with human feedback. Advances in Neural Information Processing Systems, 35:27730–27744,
    2022.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Ouyang Long，Jeffrey 等人。训练语言模型以跟随人类反馈的指令。神经信息处理系统进展，35:27730–27744，2022年。'
- en: '[6] Hugo Touvron, Thibaut Lavril, et al. Llmama: Open and efficient foundation
    language models. arXiv preprint arXiv:2302.13971, 2023.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Hugo Touvron，Thibaut Lavril 等人。Llmama：开放且高效的基础语言模型。arXiv 预印本 arXiv:2302.13971，2023年。'
- en: '[7] Yu Sun, Shuohuan Wang, et al. Ernie 3.0: Large-scale knowledge enhanced
    pre-training for language understanding and generation. arXiv preprint arXiv:2107.02137,
    2021.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] 余 孙， Shuohuan Wang 等人。Ernie 3.0：大规模知识增强的语言理解与生成预训练。arXiv 预印本 arXiv:2107.02137，2021年。'
- en: '[8] Aohan Zeng, Xiao Liu, et al. Glm-130b: An open bilingual pre-trained model.
    arXiv preprint arXiv:2210.02414, 2022.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] 敖寒·曾, 肖刘, 等。Glm-130b: 一个开放的双语预训练模型。arXiv 预印本 arXiv:2210.02414, 2022。'
- en: '[9] Longyue Wang, Chenyang Lyu, et al. Document-level machine translation with
    large language models. arXiv preprint arXiv:2304.02210, 2023.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] 龙跃·王, 陈阳·吕, 等。基于大型语言模型的文档级机器翻译。arXiv 预印本 arXiv:2304.02210, 2023。'
- en: '[10] Katherine Thai, Marzena Karpinska, et al. Exploring document-level literary
    machine translation with parallel paragraphs from world literature. arXiv preprint
    arXiv:2210.14250, 2022.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] 凯瑟琳·泰, 玛尔泽纳·卡尔平斯卡, 等。探索基于平行段落的文档级文学机器翻译。arXiv 预印本 arXiv:2210.14250, 2022。'
- en: '[11] Yue Deng, Wenxuan Zhang, et al. Multilingual jailbreak challenges in large
    language models. arXiv preprint arXiv:2310.06474, 2023.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] 岳邓, 温轩·张, 等。大型语言模型中的多语言破解挑战。arXiv 预印本 arXiv:2310.06474, 2023。'
- en: '[12] Viet Dac Lai, Nghia Trung Ngo, et al. Chatgpt beyond english: Towards
    a comprehensive evaluation of large language models in multilingual learning.
    arXiv preprint arXiv:2304.05613, 2023.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] 越达·赖, 吕嘉·阮, 等。Chatgpt 超越英语: 面向多语言学习的大型语言模型的全面评估。arXiv 预印本 arXiv:2304.05613,
    2023。'
- en: '[13] Deyao Zhu, Jun Chen, et al. Minigpt-4: Enhancing vision-language understanding
    with advanced large language models. arXiv preprint arXiv:2304.10592, 2023.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] 代尧·朱, 冯军, 等。Minigpt-4: 通过先进的大型语言模型提升视觉-语言理解。arXiv 预印本 arXiv:2304.10592,
    2023。'
- en: '[14] Shijie Geng, Shuchang Liu, et al. Recommendation as language processing
    (rlp): A unified pretrain, personalized prompt and predict paradigm (p5). In Proceedings
    of the 16th ACM Conference on Recommender Systems, pages 299–315, 2022.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] 史杰·耿, 舒畅·刘, 等。作为语言处理的推荐 (rlp): 统一的预训练、个性化提示和预测范式 (p5)。第16届ACM推荐系统会议论文集,
    页码 299–315, 2022。'
- en: '[15] Likang Wu, Zhi Zheng, et al. A survey on large language models for recommendation.
    arXiv preprint arXiv:2305.19860, 2023.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] 李康·吴, 志正·郑, 等。关于推荐的大型语言模型的调查。arXiv 预印本 arXiv:2305.19860, 2023。'
- en: '[16] Junling Liu, Chao Liu, et al. Is chatgpt a good recommender? a preliminary
    study. arXiv preprint arXiv:2304.10149, 2023.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] 军玲·刘, 超·刘, 等。Chatgpt 是一个好的推荐系统吗？初步研究。arXiv 预印本 arXiv:2304.10149, 2023。'
- en: '[17] Jason Wei, Xuezhi Wang, et al. Chain-of-thought prompting elicits reasoning
    in large language models. Advances in Neural Information Processing Systems, 35:24824–24837,
    2022.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] 杰森·魏, 薛智·王, 等。链式思维提示引发大型语言模型的推理能力。神经信息处理系统进展, 35:24824–24837, 2022。'
- en: '[18] Jie Huang and Kevin Chen-Chuan Chang. Towards reasoning in large language
    models: A survey. arXiv preprint arXiv:2212.10403, 2022.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] 姜黄, 凯文·陈-川·张。迈向大型语言模型中的推理: 一项调查。arXiv 预印本 arXiv:2212.10403, 2022。'
- en: '[19] Monica Agrawal, Stefan Hegselmann, et al. Large language models are few-shot
    clinical information extractors. In Proceedings of the 2022 Conference on Empirical
    Methods in Natural Language Processing, pages 1998–2022, 2022.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] 莫妮卡·阿格拉瓦尔, 斯特凡·赫格斯曼, 等。大型语言模型是少量样本的临床信息提取器。2022年自然语言处理经验方法会议论文集, 页码 1998–2022,
    2022。'
- en: '[20] Stefan Hegselmann, Alejandro Buendia, et al. Tabllm: Few-shot classification
    of tabular data with large language models. In International Conference on Artificial
    Intelligence and Statistics, pages 5549–5581, 2023.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] 斯特凡·赫格斯曼, 亚历杭德罗·布恩迪亚, 等。Tabllm: 利用大型语言模型进行少量示例分类的表格数据。国际人工智能与统计会议论文集,
    页码 5549–5581, 2023。'
- en: '[21] Gautier Izacard, Patrick Lewis, et al. Atlas: Few-shot learning with retrieval
    augmented language models. arXiv preprint arXiv:2208.03299, 2022.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] 戈蒂埃·伊扎卡德, 帕特里克·刘易斯, 等。Atlas: 利用检索增强型语言模型的少量学习。arXiv 预印本 arXiv:2208.03299,
    2022。'
- en: '[22] Haochun Wang, Chi Liu, et al. Huatuo: Tuning llama model with chinese
    medical knowledge. arXiv preprint arXiv:2304.06975, 2023.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] 郝春·王, 池柳, 等。华佗: 用中文医学知识微调llama模型。arXiv 预印本 arXiv:2304.06975, 2023。'
- en: '[23] Yue Wang, Hung Le, et al. Codet5+: Open code large language models for
    code understanding and generation. arXiv preprint arXiv:2305.07922, 2023.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] 岳王, 洪乐, 等。Codet5+: 开放代码大型语言模型用于代码理解和生成。arXiv 预印本 arXiv:2305.07922, 2023。'
- en: '[24] Mark Chen, Jerry Tworek, et al. Evaluating large language models trained
    on code. arXiv preprint arXiv:2107.03374, 2023.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] 马克·陈, 杰瑞·特沃雷克, 等。评估在代码上训练的大型语言模型。arXiv 预印本 arXiv:2107.03374, 2023。'
- en: '[25] Qidong Liu, Xian Wu, et al. Moelora: An moe-based parameter efficient
    fine-tuning method for multi-task medical applications. arXiv preprint arXiv:2310.18339,
    2023.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] 齐东·刘, 贤吴, 等。Moelora: 一种基于moe的高效参数微调方法用于多任务医疗应用。arXiv 预印本 arXiv:2310.18339,
    2023。'
- en: '[26] Jiaqi Ma, Zhe Zhao, et al. Modeling task relationships in multi-task learning
    with multi-gate mixture-of-experts. In Proceedings of The 24th ACM SIGKDD International
    Conference on Knowledge Discovery and Data Mining, pages 1930–1939, 2018.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Jiaqi Ma, Zhe Zhao 等. 使用多门混合专家模型建模多任务学习中的任务关系。发表于第24届ACM SIGKDD国际知识发现与数据挖掘会议论文集，页面1930–1939，2018。'
- en: '[27] Hongyan Tang, Junning Liu, et al. Progressive layered extraction (ple):
    A novel multi-task learning (mtl) model for personalized recommendations. In Proceedings
    of the 14th ACM Conference on Recommender Systems, pages 269–278, 2020.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Hongyan Tang, Junning Liu 等. 渐进分层提取（ple）：一种用于个性化推荐的新型多任务学习（mtl）模型。发表于第14届ACM推荐系统会议论文集，页面269–278，2020。'
- en: '[28] Swaroop Mishra, Daniel Khashabi, et al. Cross-task generalization via
    natural language crowdsourcing instructions. ACL, 2022.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] Swaroop Mishra, Daniel Khashabi 等. 通过自然语言众包指令实现跨任务泛化。ACL，2022。'
- en: '[29] Yu Zhang and Qiang Yang. An overview of multi-task learning. National
    Science Review, 5(1):30–43, 2018.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Yu Zhang 和 Qiang Yang. 多任务学习概述。国家科学评论，5(1):30–43，2018。'
- en: '[30] Kim-Han Thung and Chong-Yaw Wee. A brief review on multi-task learning.
    Multimedia Tools and Applications, 77:29705–29725, 2018.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Kim-Han Thung 和 Chong-Yaw Wee. 关于多任务学习的简要回顾。多媒体工具与应用，77:29705–29725，2018。'
- en: '[31] Rich Caruana. Multitask learning. Machine learning, 28(1):41–75, 1997.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Rich Caruana. 多任务学习。机器学习，28(1):41–75，1997。'
- en: '[32] Ishan Misra, Abhinav Shrivastava, et al. Cross-stitch networks for multi-task
    learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern
    Recognition, pages 3994–4003, 2016.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] Ishan Misra, Abhinav Shrivastava 等. 用于多任务学习的交叉缝合网络。发表于 IEEE 计算机视觉与模式识别会议论文集，页面3994–4003，2016。'
- en: '[33] Sebastian Ruder12, Joachim Bingel, et al. Sluice networks: Learning what
    to share between loosely related tasks. stat, 1050:23, 2017.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] Sebastian Ruder12, Joachim Bingel 等. Sluice 网络：学习在松散相关任务之间共享什么。stat，1050:23，2017。'
- en: '[34] Robert A. Jacobs, Michael I. Jordan, et al. Adaptive mixtures of local
    experts. Neural computation, 3(1):79–87, 1991.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] Robert A. Jacobs, Michael I. Jordan 等. 局部专家的自适应混合。神经计算，3(1):79–87，1991。'
- en: '[35] Shikun Liu, Edward Johns, et al. End-to-end multi-task learning with attention.
    In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
    pages 1871–1880, 2019.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] Shikun Liu, Edward Johns 等. 具有注意力机制的端到端多任务学习。发表于 IEEE 计算机视觉与模式识别会议论文集，页面1871–1880，2019。'
- en: '[36] Edward J. Hu, Yelong Shen, et al. Lora: Low-rank adaptation of large language
    models. arXiv preprint arXiv:2106.09685, 2021.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] Edward J. Hu, Yelong Shen 等. Lora：大型语言模型的低秩适配。arXiv 预印本 arXiv:2106.09685，2021。'
- en: '[37] Xiao Liu, Kaixuan Ji, et al. P-tuning: Prompt tuning can be comparable
    to fine-tuning across scales and tasks. In Proceedings of the 60th Annual Meeting
    of the Association for Computational Linguistics, 2:61–68, 2022.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] Xiao Liu, Kaixuan Ji 等. P-tuning：在规模和任务间，提示调优可以与微调相媲美。发表于第60届计算语言学协会年会论文集，2:61–68，2022。'
- en: '[38] Christopher Fifty, Ehsan Amid, et al. Efficiently identifying task groupings
    for multi-task learning. arXiv preprint arXiv:2109.04617, 2021.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] Christopher Fifty, Ehsan Amid 等. 高效识别多任务学习中的任务分组。arXiv 预印本 arXiv:2109.04617，2021。'
- en: '[39] Chengsong Huang, Qian Liu, et al. Lorahub: Efficient cross-task generalization
    via dynamic lora composition. arXiv preprint arXiv:2307.13269, 2023.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] Chengsong Huang, Qian Liu 等. Lorahub：通过动态 Lora 组合实现高效的跨任务泛化。arXiv 预印本
    arXiv:2307.13269，2023。'
- en: '[40] Hongying Zan, Wenxin Li, et al. Building a Pediatric Medical Corpus: Word
    Segmentation and Named Entity Annotation. Chinese Lexical Semantics, 2021.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] Hongying Zan, Wenxin Li 等. 构建儿科医学语料库：词语分割和命名实体注释。中文词汇语义学，2021。'
- en: '[41] Wei Zhu, Xiaoling Wang, et al. Promptcblue: A chinese prompt tuning benchmark
    for the medical domain. arXiv preprint arXiv:2310.14151, 2023.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] Wei Zhu, Xiaoling Wang 等. Promptcblue：医疗领域的中文提示调优基准。arXiv 预印本 arXiv:2310.14151，2023。'
- en: '[42] Jianxin Yang. Firefly(流萤): 中文对话式大语言模型. [https://github.com/yangjianxin1/Firefly](https://github.com/yangjianxin1/Firefly),
    2023.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] Jianxin Yang. Firefly(流萤)：中文对话式大语言模型。 [https://github.com/yangjianxin1/Firefly](https://github.com/yangjianxin1/Firefly)，2023。'
- en: '[43] Vikas Yadav and Steven Bethard. A survey on recent advances in named entity
    recognition from deep learning models. arXiv preprint arXiv:1910.11470, 2019.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] Vikas Yadav 和 Steven Bethard. 关于深度学习模型中命名实体识别的最新进展的调查。arXiv 预印本 arXiv:1910.11470，2019。'
- en: '[44] Jacob Devlin, Ming-Wei Chang, et al. Bert: Pre-training of deep bidirectional
    transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] Jacob Devlin, Ming-Wei Chang 等. Bert：用于语言理解的深度双向变换器的预训练。arXiv 预印本 arXiv:1810.04805，2018。'
- en: '[45] Yifan Peng, Shankai Yan, et al. Transfer learning in biomedical natural
    language processing: An evaluation of bert and elmo on ten benchmarking datasets.
    arXiv preprint arXiv:1906.05474, 2019.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] 彭一凡, 闫尚凯, 等. 生物医学自然语言处理中的迁移学习：对 BERT 和 ELMo 在十个基准数据集上的评估。arXiv 预印本 arXiv:1906.05474,
    2019。'
- en: '[46] AlibabaCloud. Tianchi competition platform, 2023. [https://tianchi.aliyun.com/?spm=a2c22.27124976.J_3941670930.7.71de132aU2uCjD](https://tianchi.aliyun.com/?spm=a2c22.27124976.J_3941670930.7.71de132aU2uCjD).'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] 阿里云. 天池竞赛平台, 2023. [https://tianchi.aliyun.com/?spm=a2c22.27124976.J_3941670930.7.71de132aU2uCjD](https://tianchi.aliyun.com/?spm=a2c22.27124976.J_3941670930.7.71de132aU2uCjD)。'
- en: '[47] Qingxiu Dong, Lei Li, et al. A survey on in-context learning. arXiv preprint
    arXiv:2301.00234, 2023.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] 董青秀, 李磊, 等. 上下文学习综述。arXiv 预印本 arXiv:2301.00234, 2023。'
- en: '[48] Zhengxiao Du, Yujie Qian, et al. Glm: General language model pretraining
    with autoregressive blank infilling. arXiv preprint arXiv:2103.10360, 2023.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] 郑晓杜, 钱玉洁, 等. GLM: 通过自回归空白填充进行通用语言模型预训练。arXiv 预印本 arXiv:2103.10360, 2023。'
- en: '[49] Chin-Yew Lin and Franz J. Och. Automatic evaluation of machine translation
    quality using longest common subsequence and skip-bigram statistics. In Proceedings
    of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL-04),
    pages 605–612, 2004.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] 林金耀 和 Franz J. Och. 使用最长公共子序列和跳过二元统计的机器翻译质量自动评估。第42届计算语言学协会年会论文集（ACL-04），页码
    605–612, 2004。'
- en: '[50] Robert Tinn, Hao Cheng, et al. Fine-tuning large neural language models
    for biomedical natural language processing. Patterns, 4(4), 2023.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] 罗伯特·廷, 郝程, 等. 针对生物医学自然语言处理的大型神经语言模型微调。Patterns, 4(4), 2023。'
- en: '[51] Neil Houlsby, Andrei Giugiu, et al. Parameter-efficient transfer learning
    for nlp. in International Conference on Machine Learning, pages 2790–2799, 2019.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] 尼尔·霍尔斯比, 安德烈·吉乌吉乌, 等. 面向 NLP 的参数高效迁移学习。国际机器学习会议论文集, 页码 2790–2799, 2019。'
- en: '[52] Xiang Li and Percy Liang. Prefix-tuning: Optimizing continuous prompts
    for generation. in Proceedings of the 59th Annual Meeting of the Association for
    Computational Linguistics and the 11th International Joint Conference on Natural
    Language Processing, 1:4582–4597, 2021.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] 李翔 和 Percy Liang. Prefix-tuning: 为生成优化连续提示。第59届计算语言学协会年会暨第11届国际自然语言处理联合会议论文集,
    1:4582–4597, 2021。'
- en: '[53] Pengfei Liu, Weizhe Yuan, et al. Pre-train, prompt, and predict: A systematic
    survey of prompting methods in natural language processing. ACM Computing Surveys,
    55(9):1–35, 2023.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] 刘鹏飞, 袁维哲, 等. 预训练、提示和预测：自然语言处理中的提示方法系统综述。ACM 计算机调查, 55(9):1–35, 2023。'
