- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:35:16'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:35:16
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting in LLM Fine-Tuning'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MoFO：用于缓解LLM微调中遗忘的动量过滤优化器
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2407.20999](https://ar5iv.labs.arxiv.org/html/2407.20999)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2407.20999](https://ar5iv.labs.arxiv.org/html/2407.20999)
- en: 'Yupeng Chen Equal contribution. Email: {senmiaowang1, yushunzhang}@link.cuhk.edu.cn,  zeyu.qin@connect.ust.hk,
    {yupengchen1224, linzhihang, sunruoyu}@cuhk.edu.cn,   dingtian@sribd.cn The Chinese
    University of Hong Kong, Shenzhen, China Senmiao Wang^∗ The Chinese University
    of Hong Kong, Shenzhen, China Zhihang Lin The Chinese University of Hong Kong,
    Shenzhen, China Zeyu Qin Hong Kong University of Science and Technology Yushun
    Zhang The Chinese University of Hong Kong, Shenzhen, China Shenzhen Research Institute
    of Big Data Tian Ding Shenzhen Research Institute of Big Data Ruoyu Sun Corresponding
    author. The Chinese University of Hong Kong, Shenzhen, China Shenzhen Research
    Institute of Big Data'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Yupeng Chen 等人贡献相等。电子邮件：{senmiaowang1, yushunzhang}@link.cuhk.edu.cn,  zeyu.qin@connect.ust.hk,
    {yupengchen1224, linzhihang, sunruoyu}@cuhk.edu.cn,  dingtian@sribd.cn 香港中文大学（深圳），中国
    Senmiao Wang^∗ 香港中文大学（深圳），中国 Zhihang Lin 香港中文大学（深圳），中国 Zeyu Qin 香港科技大学 Yushun
    Zhang 香港中文大学（深圳），中国 深圳大数据研究所 Tian Ding 深圳大数据研究所 Ruoyu Sun 通讯作者。香港中文大学（深圳），中国 深圳大数据研究所
- en: Abstract
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Recently, large language models (LLMs) have demonstrated remarkable capabilities
    in a wide range of tasks. Typically, an LLM is pre-trained on large corpora and
    subsequently fine-tuned on task-specific datasets. However, during fine-tuning,
    LLMs may forget the knowledge acquired in the pre-training stage, leading to a
    decline in general capabilities. To address this issue, we propose a new fine-tuning
    algorithm termed Momentum-Filtered Optimizer (MoFO). The key idea of MoFO is to
    iteratively select and update the model parameters with the largest momentum magnitudes.
    Compared to full-parameter training, MoFO achieves similar fine-tuning performance
    while keeping parameters closer to the pre-trained model, thereby mitigating knowledge
    forgetting. Unlike most existing methods for forgetting mitigation, MoFO combines
    the following two advantages. First, MoFO does not require access to pre-training
    data. This makes MoFO particularly suitable for fine-tuning scenarios where pre-training
    data is unavailable, such as fine-tuning checkpoint-only open-source LLMs. Second,
    MoFO does not alter the original loss function. This could avoid impairing the
    model performance on the fine-tuning tasks. We validate MoFO through rigorous
    convergence analysis and extensive experiments, demonstrating its superiority
    over existing methods in mitigating forgetting and enhancing fine-tuning performance.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，大型语言模型（LLMs）在各种任务中展示了卓越的能力。通常，LLM在大规模语料库上进行预训练，然后在特定任务的数据集上进行微调。然而，在微调过程中，LLM可能会忘记在预训练阶段获得的知识，从而导致通用能力下降。为了解决这个问题，我们提出了一种新的微调算法，称为动量过滤优化器（MoFO）。MoFO的关键思想是迭代地选择和更新动量幅度最大的模型参数。与全参数训练相比，MoFO在保持参数接近预训练模型的同时，取得了类似的微调性能，从而减轻了知识遗忘。与大多数现有的遗忘缓解方法不同，MoFO结合了以下两个优势。首先，MoFO不需要访问预训练数据。这使得MoFO特别适合在预训练数据不可用的微调场景，例如微调仅有检查点的开源LLMs。其次，MoFO不会改变原始损失函数。这可以避免损害模型在微调任务上的性能。我们通过严格的收敛性分析和广泛的实验验证了MoFO，展示了其在缓解遗忘和提升微调性能方面的优越性。
- en: 1 Introduction
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: The success of large language models (LLMs) lies in their strong capabilities
    in language understanding and generation. Typically, LLMs are initially pre-trained
    on extensive corpora to acquire general capabilities, and subsequently, they are
    fine-tuned on smaller, task-specific datasets to adapt to particular tasks or
    domains (Dai and Le, [2015](#bib.bib17); Kenton and Toutanova, [2019](#bib.bib32);
    Radford et al., [2018](#bib.bib53)). However, it has been observed that during
    the fine-tuning process, LLMs may forget the knowledge acquired in pre-training,
    leading to a decline in general capabilities (Lin et al., [2023](#bib.bib40);
    Chen et al., [2020](#bib.bib13); Dong et al., [2021](#bib.bib18); Korbak et al.,
    [2022](#bib.bib35); Luo et al., [2023](#bib.bib45)). Therefore, addressing the
    issue of forgetting during fine-tuning has become an important research direction
    for LLMs.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）的成功在于其强大的语言理解和生成能力。通常，LLMs 会先在大量语料上进行预训练，以获得通用能力，然后在较小的、特定任务的数据集上进行微调，以适应特定任务或领域（Dai
    和 Le，[2015](#bib.bib17)；Kenton 和 Toutanova，[2019](#bib.bib32)；Radford 等，[2018](#bib.bib53)）。然而，已经观察到在微调过程中，LLMs
    可能会遗忘在预训练中获得的知识，从而导致通用能力的下降（Lin 等，[2023](#bib.bib40)；Chen 等，[2020](#bib.bib13)；Dong
    等，[2021](#bib.bib18)；Korbak 等，[2022](#bib.bib35)；Luo 等，[2023](#bib.bib45)）。因此，解决微调过程中遗忘的问题已经成为
    LLMs 重要的研究方向。
- en: 'In the literature, two classes of methods are commonly adopted to mitigate
    the forgetting: replay-based methods, and regularization-based methods.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 文献中通常采用两类方法来减轻遗忘问题：基于重放的方法和基于正则化的方法。
- en: •
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Replay-based methods leverage pre-training data during the fine-tuning process
    (Rolnick et al., [2019](#bib.bib61); Wang et al., [2020](#bib.bib71); Ouyang et al.,
    [2022](#bib.bib51)). However, most open-source LLMs, such as the Llama series
    (Touvron et al., [2023](#bib.bib66)), have not fully disclosed their pre-training
    datasets. Moreover, even with access to pre-training data, incorporating it into
    the fine-tuning process may significantly increase computational and memory costs.
  id: totrans-13
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于重放的方法在微调过程中利用预训练数据（Rolnick 等，[2019](#bib.bib61)；Wang 等，[2020](#bib.bib71)；Ouyang
    等，[2022](#bib.bib51)）。然而，大多数开源 LLMs，如 Llama 系列（Touvron 等，[2023](#bib.bib66)），尚未完全公开其预训练数据集。此外，即使能够访问预训练数据，将其纳入微调过程中可能会显著增加计算和内存开销。
- en: •
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Regularization-based methods add penalty terms to the loss function, encouraging
    the fine-tuned model to remain close to the pre-trained model, thereby reducing
    the risk of forgetting pre-training knowledge (Li et al., [2018](#bib.bib38);
    Kirkpatrick et al., [2017](#bib.bib34); Miceli-Barone et al., [2017](#bib.bib47);
    Panigrahi et al., [2023](#bib.bib52)). However, as we will present later, modifying
    the original loss function during fine-tuning may impair the model’s performance
    on the fine-tuning task.
  id: totrans-15
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于正则化的方法向损失函数中添加惩罚项，鼓励微调后的模型保持接近预训练模型，从而减少遗忘预训练知识的风险（Li 等，[2018](#bib.bib38)；Kirkpatrick
    等，[2017](#bib.bib34)；Miceli-Barone 等，[2017](#bib.bib47)；Panigrahi 等，[2023](#bib.bib52)）。然而，正如我们稍后将展示的那样，在微调过程中修改原始损失函数可能会影响模型在微调任务上的表现。
- en: In this paper, we design a replay-free and regularization-free method to mitigate
    forgetting during the fine-tuning process. We propose the Momentum-Filtered Optimizer
    (MoFO). At each iteration, MoFO selects and updates only the parameters with the
    top $\alpha\%$ is the filtering hyperparameter. Here, the blocks refer to the
    parameters of different parts of the network (e.g., weight matrices and bias terms).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们设计了一种无重放和无正则化的方法，以减轻微调过程中遗忘的问题。我们提出了动量过滤优化器（MoFO）。在每次迭代中，MoFO 仅选择和更新参数中前
    $\alpha\%$ 的部分作为过滤超参数。这里的块指的是网络不同部分的参数（例如，权重矩阵和偏置项）。
- en: Our method is motivated by the following observation. The fine-tuning loss of
    LLMs has many minima¹¹1In this paper, we use the term ”minimum” (or ”minima” in
    the plural) to refer to a parameter configuration whose fine-tuning loss is near
    its lowest value in a small neighborhood, while acknowledging that this terminology
    may not strictly represent a local minimum of the fine-tuning loss function. and
    these minima can vary significantly in their distances to the pretrained-model.
    We notice that the minima closer to the pre-trained model are less likely to experience
    forgetting. Inspired by this observation, MoFO manages to approach closer minima
    by dynamically updating a portion of parameters that are most effective for reducing
    fine-tuning loss at each iteration. Therefore, MoFO can reduce the risk of forgetting
    without sacrificing the fine-tuning performance.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的方法受到以下观察的启发。LLMs的微调损失有许多极小值¹¹1在本文中，我们使用术语“极小值”（复数形式为“极小值”）来指代在小范围内微调损失接近其最低值的参数配置，同时承认这一术语可能不严格代表微调损失函数的局部极小值。这些极小值在与预训练模型的距离上可能会有显著差异。我们注意到，距离预训练模型较近的极小值不太容易发生遗忘。受到这一观察的启发，MoFO通过动态更新每次迭代中最有效的参数部分来接近更接近的极小值。因此，MoFO可以在不牺牲微调性能的情况下减少遗忘风险。
- en: 'Our contributions are as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的贡献如下：
- en: •
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We propose the MoFO algorithm, a new optimization method designed to mitigate
    the forgetting of pre-training knowledge during the fine-tuning process.
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了MoFO算法，这是一种新的优化方法，旨在减缓微调过程中对预训练知识的遗忘。
- en: •
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We present an initial convergence analysis of the MoFO algorithm.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们展示了MoFO算法的初步收敛分析。
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We conduct experiments on various tasks, demonstrating that MoFO outperforms
    existing methods both in fine-tuning performance and mitigating forgetting.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们在各种任务上进行实验，展示了MoFO在微调性能和减缓遗忘方面都优于现有方法。
- en: 2 Momentum Filtered Optimizer (MoFO)
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 动量滤波优化器（MoFO）
- en: 2.1 Motivation
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 动机
- en: During fine-tuning, different training methods usually converge to different
    minima. We observe that these minima share similar fine-tuning loss but can vary
    significantly in their distances to the pre-trained model. Furthermore, minima
    closer are less likely to forget pre-training knowledge. Below, we provide an
    illustrative example of this phenomenon.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在微调过程中，不同的训练方法通常会收敛到不同的极小值。我们观察到这些极小值的微调损失相似，但它们与预训练模型的距离可能会有所不同。此外，距离较近的极小值不太容易遗忘预训练知识。下面，我们提供了一个说明这一现象的例子。
- en: 'We conduct an experiment using the Pythia-160m model to illustrate this observation.
    We fine-tune this model on a subset of the FLAN dataset²²2The subset we use is
    ‘definite_pronoun_resolution_10templates,’ available at [https://huggingface.co/datasets/Muennighoff/flan](https://huggingface.co/datasets/Muennighoff/flan).
    This is a preprocessed version of the FLAN dataset that incorporates updates made
    to the FLAN datasets since the release of the original FLAN. using two different
    optimizers: the Adam optimizer (Kingma and Ba, [2014](#bib.bib33)) and the Lion
    optimizer (Chen et al., [2024](#bib.bib14)). Figure LABEL:pythia_landscape_lion
    demonstrates that Adam and Lion converges to two different minima of the fine-tuning
    loss. Figure LABEL:pythia_landscape_lion(a) reveals that the two minima share
    similar fine-tuning loss. The minimum reached by Adam is significantly closer
    to the pre-trained model. Figure LABEL:pythia_landscape_lion(b) indicates that
    the minimum reached by Adam (the closer minimum) has a lower pre-training loss
    than that reached by Lion (the farther minimum). Furthermore, we evaluate the
    forgetting of pre-training knowledge in some common sense reasoning tasks, which
    include HellaSwag (Zellers et al., [2019](#bib.bib78)), ARC-Challenge, and ARC-Easy
    (Clark et al., [2018](#bib.bib15)). Table [1](#S2.T1 "Table 1 ‣ 2.1 Motivation
    ‣ 2 Momentum Filtered Optimizer (MoFO) ‣ MoFO: Momentum-Filtered Optimizer for
    Mitigating Forgetting in LLM Fine-Tuning") shows that Adam suffers from less accuracy
    degradation on average, indicating better preservation of the pre-training knowledge.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '我们使用 Pythia-160m 模型进行实验，以说明这一观察结果。我们在 FLAN 数据集的一个子集上对该模型进行微调²²2 我们使用的子集是‘definite_pronoun_resolution_10templates’，可在
    [https://huggingface.co/datasets/Muennighoff/flan](https://huggingface.co/datasets/Muennighoff/flan)
    下载。这是一个处理过的 FLAN 数据集版本，包含了自原始 FLAN 发布以来对 FLAN 数据集的更新。使用两种不同的优化器：Adam 优化器（Kingma
    和 Ba，[2014](#bib.bib33)）和 Lion 优化器（Chen 等，[2024](#bib.bib14)）。图 LABEL:pythia_landscape_lion
    显示 Adam 和 Lion 收敛到微调损失的两个不同最小值。图 LABEL:pythia_landscape_lion(a) 透露这两个最小值具有类似的微调损失。Adam
    达到的最小值明显更接近预训练模型。图 LABEL:pythia_landscape_lion(b) 表明，Adam 达到的最小值（更接近的最小值）的预训练损失低于
    Lion 达到的最小值（更远的最小值）。此外，我们评估了在一些常识推理任务中的预训练知识遗忘，包括 HellaSwag（Zellers 等，[2019](#bib.bib78)），ARC-Challenge
    和 ARC-Easy（Clark 等，[2018](#bib.bib15)）。表 [1](#S2.T1 "Table 1 ‣ 2.1 Motivation
    ‣ 2 Momentum Filtered Optimizer (MoFO) ‣ MoFO: Momentum-Filtered Optimizer for
    Mitigating Forgetting in LLM Fine-Tuning") 显示 Adam 在平均上经历的准确率下降较少，表明预训练知识的保存更好。'
- en: 'Therefore, we conjecture that the severity of forgetting during fine-tuning
    correlates with the distance between the fine-tuned model and the pre-trained
    model: in general, models that remain closer to the pre-trained model are less
    likely to experience forgetting. Consequently, we consider whether it is possible
    to find a method superior to the Adam optimizer that not only reaches the minimum
    during fine-tuning but also converges closer to the pre-trained model, thereby
    mitigating forgetting more effectively.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们推测微调过程中遗忘的严重程度与微调模型与预训练模型之间的距离有关：通常，离预训练模型较近的模型更不容易出现遗忘。因此，我们考虑是否有可能找到一种优于
    Adam 优化器的方法，不仅在微调过程中达到最小值，而且更接近预训练模型，从而更有效地减轻遗忘。
- en: 'Table 1: Pythia-160m’s accuracies on common sense tasks, after being fine-tuned
    with the Adam optimizer and Lion optimizer. Adam achieves less forgetting than
    Lion on average.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：Pythia-160m 在常识任务上的准确率，经过 Adam 优化器和 Lion 优化器的微调后。Adam 的遗忘程度比 Lion 平均要低。
- en: '|  | HellaSwag | ARC-easy | ARC-challenge | Average |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '|  | HellaSwag | ARC-easy | ARC-challenge | 平均值 |'
- en: '| Pythia-160m | 30.1 | 39.6 | 23.8 | 31.2 |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| Pythia-160m | 30.1 | 39.6 | 23.8 | 31.2 |'
- en: '| Adam | 28.3 | 37.4 | 22.1 | 29.3 |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| Adam | 28.3 | 37.4 | 22.1 | 29.3 |'
- en: '| Lion | 26.5 | 29.0 | 24.1 | 26.5 |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| Lion | 26.5 | 29.0 | 24.1 | 26.5 |'
- en: We first discuss how to keep the model closer to the pre-trained model. To achieve
    this goal, we recall the classical block coordinate descent (BCD) method (Tseng,
    [2001](#bib.bib67)). We believe that the BCD algorithm may converge to a minimum
    that is closer to the pre-trained model than the default full parameter fine-tuning
    with Adam. This is because BCD only updates a subset of parameters at each iteration.
    Compared to full parameter updates, this method usually involves smaller adjustments
    to the parameters.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先讨论如何使模型更接近预训练模型。为实现这一目标，我们回顾了经典的块坐标下降（BCD）方法（Tseng，[2001](#bib.bib67)）。我们认为
    BCD 算法可能会收敛到一个比默认的 Adam 全参数微调方法更接近预训练模型的最小值。这是因为 BCD 每次迭代只更新一部分参数。与全参数更新相比，这种方法通常对参数进行的调整较小。
- en: The remaining issue is how to design BCD that reaches a similar performance
    to the default methods. An effective strategy is to prioritize updating parameters
    that have the greatest influence on reducing fine-tuning loss. A straightforward
    approach is to measure the parameter’s influence by the magnitude of its gradient.
    However, in the widely used Adam optimizer, momentum directly affects parameter
    updates, while gradients influence parameter updates indirectly by affecting the
    momentum.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的问题是如何设计 BCD 以达到类似于默认方法的性能。一种有效的策略是优先更新对减少微调损失影响最大的参数。一种简单的方法是通过参数梯度的幅度来衡量参数的影响。然而，在广泛使用的
    Adam 优化器中，动量直接影响参数更新，而梯度通过影响动量间接影响参数更新。
- en: Motivated by these discussions, to mitigate forgetting and achieve comparable
    performance in fine-tuning tasks, we will modify the Adam optimizer by updating
    the subset of parameters with the largest momentum magnitude. We will discuss
    more details in the next section.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 受这些讨论的启发，为了减轻遗忘并在微调任务中获得相当的性能，我们将通过更新动量幅度最大的参数子集来修改 Adam 优化器。我们将在下一节中讨论更多细节。
- en: '![Refer to caption](img/50554b39f8ff378562b02c4daf41e6e7.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/50554b39f8ff378562b02c4daf41e6e7.png)'
- en: 'Figure 2: Illustration of MoFO. Compared with Adam optimizer, MoFO updates
    only the parameters with the largest $\alpha\%$ momentum in each partition.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：MoFO 的示意图。与 Adam 优化器相比，MoFO 仅更新每个划分中动量最大的 $\alpha\%$ 参数。
- en: 2.2 Algorithm Formulation
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 算法形式化
- en: 'We formally introduce the Momentum-Filtered Optimizer (MoFO) in Algorithm [1](#alg1
    "Algorithm 1 ‣ 2.2 Algorithm Formulation ‣ 2 Momentum Filtered Optimizer (MoFO)
    ‣ MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting in LLM Fine-Tuning").
    MoFO partitions all the parameters into $B$ is the pre-determined hyperparameter.
    The momentum filtering mechanism is illustrated in Figure [2](#S2.F2 "Figure 2
    ‣ 2.1 Motivation ‣ 2 Momentum Filtered Optimizer (MoFO) ‣ MoFO: Momentum-Filtered
    Optimizer for Mitigating Forgetting in LLM Fine-Tuning").'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在算法[1](#alg1 "Algorithm 1 ‣ 2.2 Algorithm Formulation ‣ 2 Momentum Filtered
    Optimizer (MoFO) ‣ MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting
    in LLM Fine-Tuning")中正式介绍了动量过滤优化器（MoFO）。MoFO 将所有参数划分为 $B$ 这个预定的超参数。动量过滤机制如图[2](#S2.F2
    "Figure 2 ‣ 2.1 Motivation ‣ 2 Momentum Filtered Optimizer (MoFO) ‣ MoFO: Momentum-Filtered
    Optimizer for Mitigating Forgetting in LLM Fine-Tuning")所示。'
- en: We note that the NN parameters are naturally composed of different parts (e.g.,
    weight matrices, bias terms) in the network architecture, and PyTorch’s backward
    propagation mechanism automatically returns the gradients of the loss with respect
    to each part of the parameters. To reduce computational complexity, we partition
    all parameters according to these fixed parts and select $\alpha\%$ of the parameter
    entries for BCD update within each part.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到神经网络（NN）参数自然地由网络架构中的不同部分（例如，权重矩阵、偏置项）组成，而 PyTorch 的反向传播机制会自动返回损失函数对每个参数部分的梯度。为了减少计算复杂度，我们根据这些固定部分对所有参数进行划分，并在每个部分中选择
    $\alpha\%$ 的参数条目进行BCD更新。
- en: 'In Section [3.4](#S3.SS4 "3.4 Further Analysis ‣ 3 Experiments ‣ MoFO: Momentum-Filtered
    Optimizer for Mitigating Forgetting in LLM Fine-Tuning"), we will empirically
    demonstrate that MoFO’s momentum-based selection rule outperforms its gradient-based
    variant in fine-tuning tasks. It indicates that the momentum-based selection rule
    allows for better incorporation with Adam during the optimization process in fine-tuning.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '在第[3.4](#S3.SS4 "3.4 Further Analysis ‣ 3 Experiments ‣ MoFO: Momentum-Filtered
    Optimizer for Mitigating Forgetting in LLM Fine-Tuning")节中，我们将通过实验证明 MoFO 的基于动量的选择规则在微调任务中优于其基于梯度的变体。这表明，基于动量的选择规则在优化过程中与
    Adam 更好地结合。'
- en: MoFO efficiently selects and updates the most influential parameters, as dictated
    by the momentum’s magnitude, thus enhancing the fine-tuning process while alleviating
    the catastrophic forgetting of pre-training knowledge.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: MoFO 有效地选择和更新最具影响力的参数，依据动量的幅度，从而增强微调过程，同时减轻预训练知识的灾难性遗忘。
- en: Algorithm 1 Momentum Filtered Optimizer (MoFO)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 1 动量过滤优化器（MoFO）
- en: '1:  Input: Filtering threshold $\alpha\%$, hyperparameters $\beta_{1},\beta_{2},\epsilon$
    from $1,2,\dots$ do5:        $g^{(k)}_{t}=\nabla_{(k)}\mathcal{L}_{finetune}(\Theta_{t-1})$9:        $\hat{v}^{(k)}_{t}=v^{(k)}_{t}/(1-\beta_{2}^{t})$ do11:           $(\texttt{FILTER}_{t}^{(k)})_{i}=1$’s
    entries else 012:        end for13:        $\alpha\%$ # Momentum Filtering14:     end for15:  end for'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '1:  输入：过滤阈值 $\alpha\%$，超参数 $\beta_{1},\beta_{2},\epsilon$ 从 $1,2,\dots$ do5:
    $g^{(k)}_{t}=\nabla_{(k)}\mathcal{L}_{finetune}(\Theta_{t-1})$ 9: $\hat{v}^{(k)}_{t}=v^{(k)}_{t}/(1-\beta_{2}^{t})$
    do11: $(\texttt{FILTER}_{t}^{(k)})_{i}=1$ 的条目否则 012: end for13: $\alpha\%$ # 动量过滤14:
    end for15: end for'
- en: 2.3 Initial Exploration
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 初步探索
- en: In this section, we empirically examine whether an LLM fine-tuned with MoFO
    converges to a minimum closer to the pre-trained model compared to the one fine-tuned
    with the Adam optimizer, and whether MoFO mitigates catastrophic forgetting in
    LLMs.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们通过实证检验了使用 MoFO 微调的 LLM 是否比使用 Adam 优化器微调的 LLM 收敛到离预训练模型更近的最小值，以及 MoFO
    是否能够减轻 LLM 的灾难性遗忘。
- en: 'We fine-tune the Pythia-160m on the same dataset used in the experiment described
    at the beginning of Section [2](#S2 "2 Momentum Filtered Optimizer (MoFO) ‣ MoFO:
    Momentum-Filtered Optimizer for Mitigating Forgetting in LLM Fine-Tuning"), using
    both the Adam optimizer and MoFO. First, as shown in Figure LABEL:pythia_landscape(a),
    both MoFO and Adam optimizer achieve minimal fine-tuning loss, so switching Adam
    to MoFO does not lead to performance degeneracy. Second, as shown in Figure LABEL:pythia_landscape(b),
    the distance from the pre-trained model to the minimum reached by MoFO is approximately
    20% of the distance to that reached by the Adam optimizer. This shows that MoFO
    significantly reduces the amount of parameter movement.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在与第 [2](#S2 "2 Momentum Filtered Optimizer (MoFO) ‣ MoFO: Momentum-Filtered
    Optimizer for Mitigating Forgetting in LLM Fine-Tuning") 节开头描述的实验中使用的相同数据集上微调了
    Pythia-160m，使用了 Adam 优化器和 MoFO。首先，如图 LABEL:pythia_landscape(a) 所示，MoFO 和 Adam
    优化器都实现了最小的微调损失，因此将 Adam 切换为 MoFO 不会导致性能退化。其次，如图 LABEL:pythia_landscape(b) 所示，从预训练模型到
    MoFO 达到的最小值的距离约为 Adam 优化器达到的距离的 20%。这表明 MoFO 显著减少了参数移动的量。'
- en: 'Table 2: Pythia-160m’s performance on common sense tasks, after being fine-tuned
    with the Adam optimizer and MoFO. The results indicate that MoFO significantly
    mitigates catastrophic forgetting. Bold values denote the best results among these
    optimizers.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：Pythia-160m 在使用 Adam 优化器和 MoFO 微调后的常识任务表现。结果表明，MoFO 显著减轻了灾难性遗忘。粗体值表示这些优化器中的最佳结果。
- en: '|  | HellaSwag | ARC-easy | ARC-challenge | Average |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '|  | HellaSwag | ARC-easy | ARC-challenge | 平均 |'
- en: '| Pythia-160m | 30.1 | 39.6 | 23.8 | 31.2 |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| Pythia-160m | 30.1 | 39.6 | 23.8 | 31.2 |'
- en: '| Adam | 28.3 | 37.4 | 22.1 | 29.3 |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| Adam | 28.3 | 37.4 | 22.1 | 29.3 |'
- en: '| MoFO | 29.9 | 42.0 | 22.9 | 31.6 |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| MoFO | 29.9 | 42.0 | 22.9 | 31.6 |'
- en: 'We further verify whether the reduced parameter movement (by MoFO) effectively
    mitigates the forgetting of general capabilities acquired by pre-training. We
    evaluate the degree of forgetting from two perspectives: pre-training loss and
    evaluation benchmarks. First, in Figure LABEL:pythia_landscape(b), we find MoFO
    has a lower pre-training loss compared to the Adam optimizer, indicating that
    MoFO memorizes pre-training data better. Second, in Table [2](#S2.T2 "Table 2
    ‣ 2.3 Initial Exploration ‣ 2 Momentum Filtered Optimizer (MoFO) ‣ MoFO: Momentum-Filtered
    Optimizer for Mitigating Forgetting in LLM Fine-Tuning"), we evaluate the accuracies
    of Pythia-160m, fine-tuned using both the Adam optimizer and MoFO, on some widely-used
    common sense tasks, which measures the commonsense reasoning capabilities of LLMs.
    The results show that MoFO achieves less accuracy degradations on all three tasks
    than the Adam optimizer. This indicates that MoFO not only helps maintain a smaller
    pre-training loss but also more effectively mitigates the forgetting of general
    capabilities.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '我们进一步验证了减少的参数移动（通过 MoFO）是否有效减轻了预训练中获得的一般能力的遗忘。我们从两个方面评估遗忘程度：预训练损失和评估基准。首先，在图
    LABEL:pythia_landscape(b) 中，我们发现 MoFO 的预训练损失低于 Adam 优化器，表明 MoFO 更好地记住了预训练数据。其次，在表
    [2](#S2.T2 "Table 2 ‣ 2.3 Initial Exploration ‣ 2 Momentum Filtered Optimizer
    (MoFO) ‣ MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting in LLM Fine-Tuning")
    中，我们评估了使用 Adam 优化器和 MoFO 微调的 Pythia-160m 在一些广泛使用的常识任务上的准确性，这些任务衡量了 LLM 的常识推理能力。结果显示，MoFO
    在所有三个任务上的准确度退化都低于 Adam 优化器。这表明 MoFO 不仅有助于保持更小的预训练损失，还更有效地减轻了一般能力的遗忘。'
- en: 'In Section [4](#S4 "4 Why MoFO Converges to a Closer Point ‣ MoFO: Momentum-Filtered
    Optimizer for Mitigating Forgetting in LLM Fine-Tuning"), we will provide further
    insights on why MoFO converges to a point closer to the pre-trained model.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '在第 [4](#S4 "4 Why MoFO Converges to a Closer Point ‣ MoFO: Momentum-Filtered
    Optimizer for Mitigating Forgetting in LLM Fine-Tuning") 节中，我们将提供关于为何MoFO收敛到更接近预训练模型的点的进一步见解。'
- en: 2.4 Convergence Result
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 收敛结果
- en: 'In this section, we conduct a convergence analysis of MoFO. We study a simplified
    version of our MoFO algorithm as a variant of gradient descent (GD), which is
    described by Algorithm [2](#alg2 "Algorithm 2 ‣ 2.4 Convergence Result ‣ 2 Momentum
    Filtered Optimizer (MoFO) ‣ MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting
    in LLM Fine-Tuning").'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们对MoFO进行收敛性分析。我们研究了我们MoFO算法的简化版本，作为梯度下降（GD）的一种变体，具体描述见算法 [2](#alg2 "Algorithm
    2 ‣ 2.4 Convergence Result ‣ 2 Momentum Filtered Optimizer (MoFO) ‣ MoFO: Momentum-Filtered
    Optimizer for Mitigating Forgetting in LLM Fine-Tuning")。'
- en: Algorithm 2 GD version of MoFO
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 2 MoFO的GD版本
- en: '1:  Input: Filtering threshold $\alpha\%$ learning rate schedule $\{\eta_{t}\}$
    from $1$ from $1$ is among the top-$\alpha\%$11:  end for'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '1:  输入：过滤阈值 $\alpha\%$ 学习率调度 $\{\eta_{t}\}$ 从 $1$ 从 $1$ 是前-$\alpha\%$中的第11:
    结束'
- en: Theorem 1  (Convergence of MoFO).
  id: totrans-61
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定理 1  （MoFO的收敛性）。
- en: Suppose that the minimum value of the loss function is ${\mathcal{L}}^{*}$,
    it holds that
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 假设损失函数的最小值是 ${\mathcal{L}}^{*}$，则有
- en: '|  | $\min_{0\leq t<T}\&#124;g_{t}\&#124;_{\infty}=O(T^{-\frac{1}{2}}).$ |  |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '|  | $\min_{0\leq t<T}\&#124;g_{t}\&#124;_{\infty}=O(T^{-\frac{1}{2}}).$ |  |'
- en: 'In summary, we demonstrate the convergence of a GD version of MoFO, providing
    theoretical support for the strong performance of MoFO in fine-tuning tasks. We
    note that it seems rather non-trivial to prove the convergence of the original
    version of MoFO: MoFO contains 1st and 2nd-order momentum in a fractional form,
    and such structure is known to be challenging to handle (Zhang et al., [2022](#bib.bib81)).
    We leave the convergence of the original MoFO method as an interesting future
    direction.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们展示了MoFO的GD版本的收敛性，为MoFO在微调任务中的强大表现提供了理论支持。我们注意到，证明MoFO原始版本的收敛性似乎相当复杂：MoFO包含以分数形式存在的1阶和2阶动量，这种结构被认为很难处理（Zhang等，
    [2022](#bib.bib81)）。我们将MoFO原始方法的收敛性留作一个有趣的未来方向。
- en: 3 Experiments
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 实验
- en: Now we verify the effectiveness of MoFO on instruction fine-tuning and continual
    fine-tuning. We use Llama-2-7B (Touvron et al., [2023](#bib.bib66)) and TinyLlama-1.1B
    (Zhang et al., [2024](#bib.bib80)) as the base models for our experiments. We
    also provide studies on the choice of update fraction and update strategies of
    MoFO.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们验证MoFO在指令微调和持续微调上的有效性。我们使用Llama-2-7B（Touvron等， [2023](#bib.bib66)）和TinyLlama-1.1B（Zhang等，
    [2024](#bib.bib80)）作为我们实验的基础模型。我们还提供了关于MoFO更新比例和更新策略的研究。
- en: 3.1 Experimental Settings
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 实验设置
- en: Datasets for instruction fine-tuning.
  id: totrans-68
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 指令微调的数据集。
- en: 'This group of datasets covers question-answer pairs from different domains
    like mathematical reasoning and code generation. Specifically, the datasets include:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这一组数据集涵盖了来自不同领域的问题-答案对，如数学推理和代码生成。具体来说，这些数据集包括：
- en: •
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: MetaMathQA (Yu et al., [2024a](#bib.bib76)). This dataset comprises 395K math
    question-answer pairs. Numerous studies indicate that LLMs significantly enhance
    performance metrics on mathematical benchmarks such as GSM8K after fine-tuning
    on this dataset. In this paper, we randomly select 10% of this dataset for training
    LLMs, which includes 33,000 question-answer pairs.
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: MetaMathQA（Yu等， [2024a](#bib.bib76)）。该数据集包含395K个数学问题-答案对。大量研究表明，LLMs在此数据集上微调后，在数学基准如GSM8K上的性能指标显著提高。在本文中，我们随机选择了该数据集的10%用于训练LLMs，包括33,000个问题-答案对。
- en: •
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Code-Alpaca (Chaudhary, [2023](#bib.bib7)). This dataset contains 20,022 question-answer
    pairs. We fine-tune LLMs on this dataset to enhance their coding capabilities.
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Code-Alpaca（Chaudhary， [2023](#bib.bib7)）。该数据集包含20,022个问题-答案对。我们在该数据集上微调LLMs，以增强其编码能力。
- en: Datasets for continual fine-tuning.
  id: totrans-74
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 持续微调的数据集。
- en: We investigate the performance of MoFO in the continual fine-tuning scenario
    by implementing our approach on the TRACE benchmark dataset (Wang et al., [2023b](#bib.bib69)).
    TRACE benchmark is designed with a comprehensive set of 8 distinct tasks across
    various domains, including domain-specific knowledge, multilingual proficiency,
    code generation, and mathematical reasoning.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过在 TRACE 基准数据集 (Wang et al., [2023b](#bib.bib69)) 上实施我们的方法，调查 MoFO 在持续微调场景中的表现。TRACE
    基准设计了一套全面的 8 个不同领域的任务，包括领域特定知识、多语言能力、代码生成和数学推理。
- en: Metrics for instruction fine-tuning.
  id: totrans-76
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 指令微调的指标。
- en: 'We introduce a set of widely used benchmarks to assess the performance and
    catastrophic forgetting effects on the general capabilities of LLMs after instruction
    fine-tuning. These benchmarks include:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们引入了一组广泛使用的基准来评估 LLM 在指令微调后对一般能力的表现和灾难性遗忘效果。这些基准包括：
- en: •
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: MMLU (Massive Multitask Language Understanding) (Hendrycks et al., [2021](#bib.bib25)).
    It is a popular benchmark to evaluate factual knowledge of LLMs. This benchmark
    spans 57 diverse subjects, ranging from STEM fields and the humanities to social
    sciences. We report the 0-shot accuracy.
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: MMLU (Massive Multitask Language Understanding) (Hendrycks et al., [2021](#bib.bib25))。这是一个流行的基准，用于评估
    LLM 的事实知识。该基准涵盖 57 个不同的学科，从 STEM 领域和人文学科到社会科学。我们报告 0-shot 准确率。
- en: •
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Commonsense. We employ the widely recognized benchmarks ARC-Challenge, ARC-Easy
    (Clark et al., [2018](#bib.bib15)), and HellaSwag (Zellers et al., [2019](#bib.bib78))
    to measure the commonsense reasoning capabilities of LLMs. In this paper, we refer
    to these benchmarks collectively as the Commonsense benchmark, and we use the
    average of these three metrics as the evaluation for this Commonsense benchmark.
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 常识。我们采用广泛认可的基准 ARC-Challenge、ARC-Easy (Clark et al., [2018](#bib.bib15)) 和 HellaSwag
    (Zellers et al., [2019](#bib.bib78)) 来测量 LLM 的常识推理能力。在本文中，我们将这些基准统称为常识基准，并使用这三个指标的平均值作为对这一常识基准的评估。
- en: •
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: GSM8K (Cobbe et al., [2021](#bib.bib16)). This benchmark consists of 8.5K high-quality
    grade school math problems. We evaluate the math capability of LLM on the test
    set of GSM8K through the LM Eval Harness framework (Gao et al., [2023](#bib.bib21)).
    We follow the default implementation setting of LM Eval Harness and set the temperature
    hyperparameter as 0 and report 5-shot accuracy.
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: GSM8K (Cobbe et al., [2021](#bib.bib16))。这个基准测试包括 8.5K 个高质量的基础数学问题。我们通过 LM Eval
    Harness 框架 (Gao et al., [2023](#bib.bib21)) 评估 LLM 在 GSM8K 测试集上的数学能力。我们遵循 LM Eval
    Harness 的默认实现设置，将温度超参数设置为 0，并报告 5-shot 准确率。
- en: •
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: HumanEval (Chen et al., [2021](#bib.bib12)). We adopt the widely used HumanEval
    to assess the coding capabilities of LLMs. It comprises 164 unique programming
    problems. We report the pass@10 performance.
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: HumanEval (Chen et al., [2021](#bib.bib12))。我们采用广泛使用的 HumanEval 来评估 LLM 的编码能力。它包括
    164 个独特的编程问题。我们报告 pass@10 性能。
- en: Metrics for continual fine-tuning.
  id: totrans-86
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 持续微调的指标。
- en: 'To evaluate the LLM’s performance in continual learning, we consider two key
    metrics in this scenario: Overall Performance (OP) (Chaudhry et al., [2018](#bib.bib8))
    and BackWard Transfer (BWT) (Lopez-Paz and Ranzato, [2017](#bib.bib42)). Let $R_{t,i}$).
    The OP score measures the average accuracy on all the $T$ tasks after the continual
    fine-tuning process, which is defined by'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估 LLM 在持续学习中的表现，我们在这种情况下考虑两个关键指标：总体表现 (OP) (Chaudhry et al., [2018](#bib.bib8))
    和向后迁移 (BWT) (Lopez-Paz and Ranzato, [2017](#bib.bib42))。让 $R_{t,i}$)。OP 分数衡量在持续微调过程后，所有
    $T$ 个任务的平均准确率，其定义为
- en: '|  | $OP:=\frac{1}{T}\sum_{i=1}^{T}R_{T,i}.$ |  |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '|  | $OP:=\frac{1}{T}\sum_{i=1}^{T}R_{T,i}.$ |  |'
- en: The BWT score measures the average accuracy change of each task after learning
    new tasks, which is defined by
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: BWT 分数衡量在学习新任务后每个任务的平均准确率变化，其定义为
- en: '|  | $BWT:=\frac{1}{T-1}\sum_{i=1}^{T-1}(R_{T,i}-R_{i,i}).$ |  |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '|  | $BWT:=\frac{1}{T-1}\sum_{i=1}^{T-1}(R_{T,i}-R_{i,i}).$ |  |'
- en: These metrics provide a comprehensive assessment of the model’s ability to learn
    incrementally while retaining knowledge from past experiences. In this paper,
    we will utilize these scores to evaluate the effectiveness of our method in continual
    learning tasks.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指标提供了对模型在增量学习的同时保持过去经验知识能力的全面评估。在本文中，我们将利用这些分数评估我们方法在持续学习任务中的有效性。
- en: 3.2 Instruction Fine-Tuning
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 指令微调
- en: 'In this section, we aim to investigate the effectiveness of the MoFO approach
    in preserving general capabilities while learning fine-tuning tasks. We fine-tune
    Llama-2-7B on MetaMathQA and Code-Alpaca datasets, and compare the performance
    of MoFO against several baseline methods. The evaluation includes changes in performance
    on fine-tuning tasks and general capability metrics, with the pre-trained model’s
    performance serving as the reference point for comparison. The implementation
    details can be seen in [B](#A2 "Appendix B Implementation Details ‣ MoFO: Momentum-Filtered
    Optimizer for Mitigating Forgetting in LLM Fine-Tuning").'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们旨在调查 MoFO 方法在学习微调任务时保持一般能力的有效性。我们在 MetaMathQA 和 Code-Alpaca 数据集上对 Llama-2-7B
    进行微调，并将 MoFO 的表现与几个基线方法进行比较。评估包括微调任务和一般能力指标上的表现变化，以预训练模型的表现作为比较的参考点。实施细节可见于 [B](#A2
    "Appendix B Implementation Details ‣ MoFO: Momentum-Filtered Optimizer for Mitigating
    Forgetting in LLM Fine-Tuning")。'
- en: Baselines
  id: totrans-94
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基线
- en: 'We compare the proposed MoFO algorithm with some of the most widely used optimization
    techniques, which aim to alleviate forgetting, as our baselines. These methods
    include:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将提出的 MoFO 算法与一些最广泛使用的优化技术进行了比较，这些技术旨在减轻遗忘，作为我们的基线。这些方法包括：
- en: •
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Full FT refers to default full-parameter fine-tuning approach with the loss
    function $\mathcal{L}_{finetune}(\theta)$.
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 完全 FT 指的是默认的全参数微调方法，其损失函数为 $\mathcal{L}_{finetune}(\theta)$。
- en: •
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: $L_{2}$, with the regularization hyperparameter $\lambda_{2}$ set to 1e-3.
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $L_{2}$，正则化超参数 $\lambda_{2}$ 设为 1e-3。
- en: •
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: $L_{1}$, with the regularization hyperparameter $\lambda_{1}$ set to 1e-6.
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $L_{1}$，正则化超参数 $\lambda_{1}$ 设为 1e-6。
- en: •
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Half Fine-tuning (HFT) (Hui et al., [2024](#bib.bib29)) randomly updates half
    of the parameter blocks within each transformer layer at each iteration while
    the other half are frozen. HFT can be considered a specific case of the BCD algorithm.
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 半微调（HFT）（Hui 等， [2024](#bib.bib29)）在每次迭代时随机更新每个变换器层中的一半参数块，而另一半保持不变。HFT 可以被视为
    BCD 算法的特例。
- en: 'Table 3: The performance on the math task (GSM8K) and the score changes in
    general capabilities of Llama-2-7B after fine-tuning on the MetaMathQA dataset.
    The results show that MoFO achieves comparable performance in the math task, while
    significantly mitigating catastrophic forgetting of general capabilities. Bold
    values denote the best results among these methods.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：Llama-2-7B 在 MetaMathQA 数据集上进行微调后的数学任务（GSM8K）表现及其在一般能力上的得分变化。结果显示，MoFO 在数学任务中的表现可与其他方法媲美，同时显著减轻了对一般能力的灾难性遗忘。粗体数值表示这些方法中的最佳结果。
- en: '| Method | Performance |  | General Capability |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 表现 |  | 一般能力 |'
- en: '| GSM8K |  | Commensense | MMLU | HumanEval | Average |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| GSM8K |  | 常识 | MMLU | 人工评估 | 平均 |'
- en: '| Llama-2-7B | 13.7 |  | 65.6 | 42.0 | 24.2 | 43.9 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| Llama-2-7B | 13.7 |  | 65.6 | 42.0 | 24.2 | 43.9 |'
- en: '| Full FT | 49.4 |  | 62.3 | 36.6 | 16.1 | 38.3 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 完全 FT | 49.4 |  | 62.3 | 36.6 | 16.1 | 38.3 |'
- en: '|  | -3.3 | -5.4 | -8.1 | -5.6 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '|  | -3.3 | -5.4 | -8.1 | -5.6 |'
- en: '| HFT | 47.5 |  | 65.5 | 42.3 | 23.6 | 43.8 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| HFT | 47.5 |  | 65.5 | 42.3 | 23.6 | 43.8 |'
- en: '|  | -0.1 | +0.3 | -0.6 | -0.1 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '|  | -0.1 | +0.3 | -0.6 | -0.1 |'
- en: '| $L_{1}$-regularization | 39.0 |  | 65.1 | 38.3 | 27.4 | 43.6 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| $L_{1}$-正则化 | 39.0 |  | 65.1 | 38.3 | 27.4 | 43.6 |'
- en: '|  | -0.5 | -3.7 | +3.2 | -0.3 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '|  | -0.5 | -3.7 | +3.2 | -0.3 |'
- en: '| $L_{2}$-regularization | 44.5 |  | 65.5 | 39.2 | 25.9 | 43.5 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| $L_{2}$-正则化 | 44.5 |  | 65.5 | 39.2 | 25.9 | 43.5 |'
- en: '|  | -0.1 | -2.8 | +1.7 | -0.4 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '|  | -0.1 | -2.8 | +1.7 | -0.4 |'
- en: '| MoFO ($\alpha\%=15\%$) | 47.7 |  | 65.7 | 42.7 | 24.6 | 44.3 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| MoFO ($\alpha\%=15\%$) | 47.7 |  | 65.7 | 42.7 | 24.6 | 44.3 |'
- en: '|  | +0.1 | +0.7 | +0.4 | +0.4 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '|  | +0.1 | +0.7 | +0.4 | +0.4 |'
- en: Results of fine-tuning on MetaMathQA.
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: MetaMathQA 上微调的结果。
- en: 'We fine-tune Llama-2-7B on MetaMathQA using various baseline methods and present
    the experimental results on mathematical reasoning (GSM8K) and general capabilities
    in Table [3](#S3.T3 "Table 3 ‣ Baselines ‣ 3.2 Instruction Fine-Tuning ‣ 3 Experiments
    ‣ MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting in LLM Fine-Tuning").
    These results demonstrate the effectiveness of our proposed MoFO algorithm in
    both optimization and mitigating catastrophic forgetting.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在 MetaMathQA 上使用各种基线方法对 Llama-2-7B 进行微调，并在表 [3](#S3.T3 "Table 3 ‣ Baselines
    ‣ 3.2 Instruction Fine-Tuning ‣ 3 Experiments ‣ MoFO: Momentum-Filtered Optimizer
    for Mitigating Forgetting in LLM Fine-Tuning") 中展示了数学推理（GSM8K）和一般能力的实验结果。这些结果表明我们提出的
    MoFO 算法在优化和减轻灾难性遗忘方面都具有有效性。'
- en: MoFO is compatible to the performance of Full FT and HFT on the math task, yet
    significantly outperforms these methods in preserving general capability. Specifically,
    Full FT shows a decline of $5\%$.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: MoFO 在数学任务上的表现与 Full FT 和 HFT 相当，但在保持一般能力方面显著优于这些方法。具体来说，Full FT 下降了 $5\%$。
- en: Compared to $L_{1}$, respectively. Additionally, while $L_{1}$ regularizations
    suffer from significant catastrophic forgetting on MMLU, MoFO shows no decline.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 与 $L_{1}$ 相比。此外，虽然 $L_{1}$ 正则化在 MMLU 上遭遇了显著的灾难性遗忘，MoFO 并没有出现下降。
- en: 'Table 4: The performance on the coding generation task (HumanEval) and accuracy
    changes in general capabilities of Llama-2-7B after fine-tuning on the Code-Alpaca
    dataset. The results show that MoFO achieves comparable performance in the HumanEval
    while significantly mitigating catastrophic forgetting of general capabilities.
    Bold values denote the best results among these methods.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：Llama-2-7B 在代码生成任务（HumanEval）上的表现以及在 Code-Alpaca 数据集上微调后的一般能力准确率变化。结果表明，MoFO
    在 HumanEval 中达到了可比的性能，同时显著减轻了一般能力的灾难性遗忘。粗体值表示这些方法中的最佳结果。
- en: '| Method | Performance |  | General Capability |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 性能 |  | 一般能力 |'
- en: '| HumanEval |  | Commensense | MMLU | GSM8K | Average |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| HumanEval |  | 常识 | MMLU | GSM8K | 平均 |'
- en: '| Llama-2-7B | 24.2 |  | 65.6 | 42.0 | 13.7 | 40.4 |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| Llama-2-7B | 24.2 |  | 65.6 | 42.0 | 13.7 | 40.4 |'
- en: '| Full FT | 27.7 |  | 65.2 | 39.6 | 5.5 | 36.8 |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| Full FT | 27.7 |  | 65.2 | 39.6 | 5.5 | 36.8 |'
- en: '|  | -1.4 | -2.4 | -8.2 | -3.6 |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '|  | -1.4 | -2.4 | -8.2 | -3.6 |'
- en: '| HFT | 30.9 |  | 68.3 | 40.6 | 6.8 | 38.6 |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| HFT | 30.9 |  | 68.3 | 40.6 | 6.8 | 38.6 |'
- en: '|  | +2.7 | -1.4 | -6.9 | -1.8 |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '|  | +2.7 | -1.4 | -6.9 | -1.8 |'
- en: '| $L_{1}$-regularization | 33.8 |  | 67.6 | 41.3 | 5.1 | 38.0 |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| $L_{1}$-正则化 | 33.8 |  | 67.6 | 41.3 | 5.1 | 38.0 |'
- en: '|  | +2.0 | -0.7 | -8.6 | -2.4 |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '|  | +2.0 | -0.7 | -8.6 | -2.4 |'
- en: '| $L_{2}$-regularization | 30.8 |  | 66.1 | 42.5 | 7.6 | 38.7 |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| $L_{2}$-正则化 | 30.8 |  | 66.1 | 42.5 | 7.6 | 38.7 |'
- en: '|  | +0.5 | +0.5 | -6.1 | -1.7 |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '|  | +0.5 | +0.5 | -6.1 | -1.7 |'
- en: '| MoFO ($\alpha\%=10\%$) | 33.7 |  | 67.3 | 42.7 | 8.0 | 39.3 |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| MoFO ($\alpha\%=10\%$) | 33.7 |  | 67.3 | 42.7 | 8.0 | 39.3 |'
- en: '|  | +1.7 | +0.7 | -5.7 | -1.1 |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '|  | +1.7 | +0.7 | -5.7 | -1.1 |'
- en: Results of fine-tuning on Code-Alpaca.
  id: totrans-136
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Code-Alpaca 上的微调结果。
- en: 'We fine-tune Llama-2-7B on Code-Alpaca using various baseline methods and present
    the experimental results on coding generation and general capabilities in Table
    [4](#S3.T4 "Table 4 ‣ Results of fine-tuning on MetaMathQA. ‣ 3.2 Instruction
    Fine-Tuning ‣ 3 Experiments ‣ MoFO: Momentum-Filtered Optimizer for Mitigating
    Forgetting in LLM Fine-Tuning").'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用各种基线方法在 Code-Alpaca 上微调 Llama-2-7B，并在表 [4](#S3.T4 "表 4 ‣ 在 MetaMathQA 上的微调结果。
    ‣ 3.2 指令微调 ‣ 3 实验 ‣ MoFO：动量过滤优化器，用于缓解 LLM 微调中的遗忘") 中展示了代码生成和一般能力的实验结果。
- en: MoFO performs well on the fine-tuning task of code generation. It significantly
    outperforms Full FT, HFT, and $L_{2}$ difference.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: MoFO 在代码生成的微调任务上表现良好。它显著优于 Full FT、HFT 和 $L_{2}$ 差异。
- en: In terms of general capability, MoFO demonstrates the least degradation compared
    to other baselines, with an average accuracy reduction of only $1.1\%$, while
    our method not only preserves but slightly improves the MMLU accuracy. On the
    math benchmark GSM8K, although all methods experience forgetting, our proposed
    MoFO algorithm exhibits a smaller decline of $5.7\%$.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在一般能力方面，MoFO 与其他基线相比表现出最小的退化，平均准确率仅下降了 $1.1\%$，而我们的方法不仅保持了 MMLU 准确率，还略有提升。在数学基准
    GSM8K 上，尽管所有方法都经历了遗忘，但我们提出的 MoFO 算法展现了 $5.7\%$ 的较小下降。
- en: In summary, our MoFO algorithm shows competitive performance in instruction
    fine-tuning while preserving the general capabilities of pre-trained LLMs, effectively
    alleviating catastrophic forgetting.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，我们的 MoFO 算法在指令微调中显示出具有竞争力的性能，同时保持了预训练 LLM 的一般能力，有效缓解了灾难性遗忘。
- en: 3.3 Continual Fine-Tuning
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 持续微调
- en: 'In this section, we explore the performance of our proposed MoFO in continual
    fine-tuning on the TRACE benchmark (Wang et al., [2023b](#bib.bib69)). We sequentially
    train TinyLlama-1.1B on the TRACE dataset, which includes the eight tasks from
    different domains. The implementation details can be seen in [B](#A2 "Appendix
    B Implementation Details ‣ MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting
    in LLM Fine-Tuning").'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们探讨了我们提出的 MoFO 在 TRACE 基准（Wang et al., [2023b](#bib.bib69)）上的持续微调性能。我们在
    TRACE 数据集上顺序训练 TinyLlama-1.1B，该数据集包含来自不同领域的八个任务。实现细节可以见 [B](#A2 "附录 B 实现细节 ‣ MoFO：动量过滤优化器，用于缓解
    LLM 微调中的遗忘")。
- en: Performance upper bound.
  id: totrans-143
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 性能上限。
- en: Multi-task Learning (MTL) mixes samples from all eight distinct tasks together
    during training and typically achieves the highest OP score. We will use MTL as
    an upper bound for performance comparison.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 多任务学习（MTL）在训练期间将所有八个不同任务的样本混合在一起，通常可以达到最高的OP得分。我们将使用MTL作为性能比较的上限。
- en: Some orthogonal methods.
  id: totrans-145
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 一些正交方法。
- en: We consider several traditional methods from the field of continual learning.
    These methods can be orthogonal combined with MoFO to further enhance performance.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们考虑了几种来自持续学习领域的传统方法。这些方法可以与MoFO正交结合，以进一步提高性能。
- en: •
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Replay involves optimizing the model using current data along with a memory
    buffer containing old samples from previous tasks to mitigate catastrophic forgetting.
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重播涉及使用当前数据优化模型，同时使用包含旧任务样本的记忆缓冲区，以减轻灾难性遗忘。
- en: •
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Gradient of Episodic Memory (GEM) mitigates catastrophic forgetting by using
    gradients from old tasks to adjust the parameter updates during the training of
    new tasks.
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 情景记忆梯度（GEM）通过使用旧任务的梯度来调整新任务训练中的参数更新，从而减轻灾难性遗忘。
- en: 'Table 5: The OP and BWT scores of TinyLlama-1.1B after fine-tuning on TRACE
    benchmark. The results show that MoFO outperforms Full FT and HFT in continual
    learning and can combine well with traditional continual learning methods. Bold
    values denote the best results among these methods in each group.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 表5：TinyLlama-1.1B在TRACE基准上微调后的OP和BWT得分。结果表明，MoFO在持续学习中优于完全微调和HFT，并且可以很好地与传统的持续学习方法结合。粗体值表示每组中这些方法中的最佳结果。
- en: '|  | OP | BWT |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '|  | OP | BWT |'
- en: '| Full FT | 38.4 | -10.3 |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 完全微调 | 38.4 | -10.3 |'
- en: '| HFT | 39.9 | -10.1 |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| HFT | 39.9 | -10.1 |'
- en: '| MoFO $(\alpha\%=5\%)$ | 41.3 | -5.4 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| MoFO $(\alpha\%=5\%)$ | 41.3 | -5.4 |'
- en: '| GEM | 40.8 | -8.5 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| GEM | 40.8 | -8.5 |'
- en: '| GEM + MoFO $(\alpha\%=5\%)$ | 41.7 | -6.7 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| GEM + MoFO $(\alpha\%=5\%)$ | 41.7 | -6.7 |'
- en: '| Replay | 45.5 | 4.7 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 重播 | 45.5 | 4.7 |'
- en: '| Replay + MoFO $(\alpha\%=5\%)$ | 47.0 | 4.8 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 重播 + MoFO $(\alpha\%=5\%)$ | 47.0 | 4.8 |'
- en: '| MTL | 50.8 |  |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 多任务学习 | 50.8 |  |'
- en: Results of continual fine-tuning.
  id: totrans-161
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 持续微调的结果。
- en: 'We present the experimental results of sequentially fine-tuning TinyLlama-1.1B
    on the TRACE benchmark with various methods in Table [5](#S3.T5 "Table 5 ‣ Some
    orthogonal methods. ‣ 3.3 Continual Fine-Tuning ‣ 3 Experiments ‣ MoFO: Momentum-Filtered
    Optimizer for Mitigating Forgetting in LLM Fine-Tuning"). The results indicate
    that in continual fine-tuning, MoFO outperforms Full FT and HFT by at least $1.4\%$
    improvement on the OP metric compared to using GEM alone.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在表[5](#S3.T5 "Table 5 ‣ 一些正交方法。 ‣ 3.3 持续微调 ‣ 3 实验 ‣ MoFO: 动量过滤优化器，用于减轻LLM微调中的遗忘")中展示了在TRACE基准上对TinyLlama-1.1B进行顺序微调的实验结果。结果表明，在持续微调中，与单独使用GEM相比，MoFO在OP指标上比完全微调和HFT提高了至少$1.4\%$。'
- en: In summary, these results underscore the superior performance of MoFO in continual
    fine-tuning and its effectiveness in alleviating catastrophic forgetting.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，这些结果突显了MoFO在持续微调中的优越性能以及在减轻灾难性遗忘方面的有效性。
- en: 3.4 Further Analysis
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 进一步分析
- en: In this section, we first investigate the impact of the update fraction of parameters
    in the MoFO algorithm at each iteration, and then explore the effects of different
    update strategies within MoFO.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们首先调查MoFO算法中每次迭代的参数更新比例的影响，然后探讨MoFO中不同更新策略的效果。
- en: Impact of update fraction of parameters in MoFO.
  id: totrans-166
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: MoFO中参数更新比例的影响。
- en: Following the setting in Section 4.2, we fine-tune Llama-2-7B on the MetaMathQA
    dataset using MoFO with varying update fractions of parameters at each iteration
    for 2 epochs. The experimental results of math reasoning (GSM8K) and average general
    capability performance changes are presented in Figure LABEL:ablation_fraction.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 按照第4.2节中的设置，我们在MetaMathQA数据集上使用MoFO对Llama-2-7B进行了微调，每次迭代中更新参数的比例不同，持续2个epoch。数学推理（GSM8K）和平均通用能力表现变化的实验结果展示在图
    LABEL:ablation_fraction中。
- en: The parameter update fraction affects the fine-tuning performance. Figure LABEL:ablation_fraction(a)
    shows that larger update fractions can improve MoFO’s optimization effectiveness.
    Furthurmore, MoFO with a $5\%$, MoFO’s performance matches that of Full FT.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 参数更新比例影响微调性能。图 LABEL:ablation_fraction(a) 显示较大的更新比例可以提高MoFO的优化效果。此外，MoFO在$5\%$的情况下，其性能与完全微调相匹配。
- en: The parameter update fraction also affects the preservation of general capabilities.
    Figure LABEL:ablation_fraction(b) indicates that MoFO avoids forgetting in general
    capabilities when the parameter update fraction is below $20\%$, further increases
    in the parameter update fraction lead to a decline in general capabilities. Despite
    this, MoFO still forgets significantly less than Full FT.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 参数更新比例也影响通用能力的保留。图 LABEL:ablation_fraction(b) 表明，当参数更新比例低于 $20\%$ 时，MoFO 避免了通用能力的遗忘，但参数更新比例的进一步增加会导致通用能力的下降。尽管如此，MoFO
    仍然比完整 FT 遗忘明显更少。
- en: In summary, MoFO can preserve pre-training knowledge and significantly enhance
    fine-tuning performance by choosing a moderate update fraction, avoiding the extremes
    of too small or too large fractions.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，MoFO 可以通过选择适中的更新比例来保留预训练知识并显著提高微调性能，避免过小或过大的更新比例的极端情况。
- en: 'Table 6: The performance on the math reasoning task (GSM8K) and accuracy changes
    of general capabilities of Llama-2-7B after fine-tuning on MetaMathQA using different
    updating strategies in MoFO.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6：在数学推理任务 (GSM8K) 上的表现以及在 MetaMathQA 上微调后 Llama-2-7B 的通用能力准确率变化。
- en: '| Method | Performance |  | General Capability |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 性能 |  | 通用能力 |'
- en: '| GSM8K |  | Commensense | MMLU | HumanEval | Average |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| GSM8K |  | 常识 | MMLU | HumanEval | 平均 |'
- en: '| Pre-trained model and Full FT |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| 预训练模型和完整 FT |'
- en: '| Llama-2-7B | 13.7 |  | 65.6 | 42.0 | 24.2 | 43.9 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| Llama-2-7B | 13.7 |  | 65.6 | 42.0 | 24.2 | 43.9 |'
- en: '| Full FT | 49.4 |  | 62.3 | 36.6 | 16.1 | 38.3 |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| 完整 FT | 49.4 |  | 62.3 | 36.6 | 16.1 | 38.3 |'
- en: '|  | -3.3 | -5.4 | -8.1 | -5.6 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '|  | -3.3 | -5.4 | -8.1 | -5.6 |'
- en: '| BCD based Methods ($\alpha\%=10\%$) |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| 基于 BCD 的方法 ($\alpha\%=10\%$) |'
- en: '| Randomized BCD | 35.0 |  | 65.8 | 41.1 | 25.1 | 44.0 |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| 随机 BCD | 35.0 |  | 65.8 | 41.1 | 25.1 | 44.0 |'
- en: '|  | +0.2 | -0.9 | +0.9 | +0.1 |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '|  | +0.2 | -0.9 | +0.9 | +0.1 |'
- en: '| Gradient-filtered BCD | 40.2 |  | 66.0 | 41.6 | 28.0 | 45.2 |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 梯度过滤 BCD | 40.2 |  | 66.0 | 41.6 | 28.0 | 45.2 |'
- en: '|  | +0.4 | -0.4 | +3.8 | +1.3 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '|  | +0.4 | -0.4 | +3.8 | +1.3 |'
- en: '| MoFO | 45.4 |  | 65.7 | 43.5 | 27.4 | 45.5 |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| MoFO | 45.4 |  | 65.7 | 43.5 | 27.4 | 45.5 |'
- en: '|  | +0.1 | +1.5 | +3.2 | +1.6 |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '|  | +0.1 | +1.5 | +3.2 | +1.6 |'
- en: Impact of update strategy in MoFO.
  id: totrans-185
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: MoFO 中更新策略的影响。
- en: 'In addition to MoFO, we consider two other BCD methods, randomized BCD and
    gradient-filtered BCD. Randomized BCD updates a random subset of parameters at
    each iteration. Gradient-filtered BCD selects the filter based on gradient magnitudes
    rather than the momentum magnitudes used in MoFO. Specifically, line 11 in Algorithm
    [1](#alg1 "Algorithm 1 ‣ 2.2 Algorithm Formulation ‣ 2 Momentum Filtered Optimizer
    (MoFO) ‣ MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting in LLM Fine-Tuning")
    is replaced by:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '除了 MoFO，我们还考虑了另外两种 BCD 方法，即随机 BCD 和梯度过滤 BCD。随机 BCD 在每次迭代中更新一个随机的参数子集。梯度过滤 BCD
    根据梯度大小选择过滤器，而不是使用 MoFO 中的动量大小。具体地，算法 [1](#alg1 "算法 1 ‣ 2.2 算法公式 ‣ 2 动量过滤优化器 (MoFO)
    ‣ MoFO: 旨在减轻 LLM 微调中的遗忘的动量过滤优化器") 中的第 11 行被替换为：'
- en: '|  | $(\texttt{FILTER}_{t}^{(k)})_{i}=1\text{ if }&#124;(g^{(k)}_{t})_{i}&#124;\text{
    is among the top-}\alpha\%\text{ of all }&#124;g^{(k)}_{t}&#124;\text{''s entries
    else }0.$ |  |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '|  | $(\texttt{FILTER}_{t}^{(k)})_{i}=1\text{ 如果 }&#124;(g^{(k)}_{t})_{i}&#124;\text{
    是所有 }&#124;g^{(k)}_{t}&#124;\text{ 的 top-}\alpha\%\text{ 之一，否则 }0.$ |  |'
- en: 'We fine-tune Llama-2-7B on MetaMathQA using these three methods with $10\%$
    parameter update fraction and present the results in Table [6](#S3.T6 "Table 6
    ‣ Impact of update fraction of parameters in MoFO. ‣ 3.4 Further Analysis ‣ 3
    Experiments ‣ MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting in LLM
    Fine-Tuning").'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '我们使用这三种方法以 $10\%$ 参数更新比例在 MetaMathQA 上对 Llama-2-7B 进行微调，并在表 [6](#S3.T6 "表 6
    ‣ MoFO 中参数更新比例的影响 ‣ 3.4 进一步分析 ‣ 3 实验 ‣ MoFO: 旨在减轻 LLM 微调中的遗忘的动量过滤优化器") 中展示了结果。'
- en: Experimental results show that all three BCD methods exhibit significantly less
    forgetting compared to Full FT, demonstrating the effectiveness of BCD algorithms
    in mitigating catastrophic forgetting.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 实验结果表明，与完整 FT 相比，所有三种 BCD 方法的遗忘显著减少，展示了 BCD 算法在减轻灾难性遗忘方面的有效性。
- en: In terms of GSM8K performance, our proposed MoFO method significantly surpasses
    both Gradient-filtered BCD and randomized BCD, indicating that updating parameters
    with the largest momentum leads to strong optimization power.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 就 GSM8K 性能而言，我们提出的 MoFO 方法显著超过了梯度过滤 BCD 和随机 BCD，表明使用最大动量更新参数具有强大的优化能力。
- en: 4 Why MoFO Converges to a Closer Point
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 为什么 MoFO 收敛到更接近的点
- en: In Section 3, we discuss how the distance of parameter movement during fine-tuning
    impacts the retention of pre-training knowledge. Drawing on these insights and
    the BCD method, we introduce MoFO. Here, we propose the following question as
    follows.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在第3节中，我们讨论了在微调过程中参数移动的距离如何影响预训练知识的保留。基于这些见解和BCD方法，我们引入了MoFO。在这里，我们提出以下问题。
- en: 'Question: Why does MoFO converge closer to the pre-trained LLMs than those
    of Adam?'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 问题：为什么MoFO比Adam更接近于预训练的LLMs？
- en: 'We attempt to answer this question by the following toy example. We denote
    $\Theta=(\theta_{1},\theta_{2})\in\mathbb{R}^{2}$ to be the trainable parameters
    of our model and make the following assumptions:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过以下玩具示例尝试回答这个问题。我们将$\Theta=(\theta_{1},\theta_{2})\in\mathbb{R}^{2}$表示为我们模型的可训练参数，并做以下假设：
- en: •
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The pre-training loss is $\mathcal{L}_{pretrain}(\Theta)=\theta_{1}^{2}+\theta_{2}^{2}$
    during the pre-trained phase.
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在预训练阶段，预训练损失为$\mathcal{L}_{pretrain}(\Theta)=\theta_{1}^{2}+\theta_{2}^{2}$。
- en: •
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The fine-tuning loss is $\mathcal{L}_{finetune}(\Theta)=(\theta_{1}-1)^{2}(\theta_{2}-1)^{2}$,
    which is a union of two straight lines.
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 微调损失是$\mathcal{L}_{finetune}(\Theta)=(\theta_{1}-1)^{2}(\theta_{2}-1)^{2}$，这是两条直线的结合。
- en: For full-parameter fine-tuning with Adam, starting from $\Theta_{0}=(0,0)$ during
    the fine-tuning phase along the green arrow in Figure LABEL:example_landscape,
    resulting in a pre-training loss of 1\. This demonstrates that MoFO can converge
    to a minimum that is closer to the pre-training model, thereby mitigating forgetting.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 对于使用Adam的全参数微调，从$\Theta_{0}=(0,0)$开始，在微调阶段沿着图例LABEL:example_landscape中的绿色箭头，结果预训练损失为1。这表明MoFO可以收敛到一个更接近预训练模型的最小值，从而减轻遗忘。
- en: 'Insights: In this example, we find that when a loss function has multiple distinct
    minima, they can be considered as different attractors. These attractors can influence
    the gradient direction of a pre-trained model, possibly drawing the model’s weights
    away from the nearest minimum. Specifically, full-parameter gradient descent based
    methods may converge to the balanced point of these attractors’ influences, which
    is the orange point in Figure LABEL:example_landscape(a). On the contrary, MoFO
    addresses this issue by updating only a subset of parameters during each iteration.
    This selective updating rule reduces interference among attractors, allowing the
    model to converge to a closer minimum.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 见解：在这个例子中，我们发现当损失函数有多个不同的最小值时，它们可以被视为不同的吸引子。这些吸引子可以影响预训练模型的梯度方向，可能将模型的权重从最近的最小值处拉开。具体而言，全参数梯度下降方法可能收敛到这些吸引子的平衡点，即图例LABEL:example_landscape(a)中的橙色点。相反，MoFO通过在每次迭代中只更新部分参数来解决这个问题。这种选择性更新规则减少了吸引子之间的干扰，使模型能够收敛到更接近的最小值。
- en: 5 Related Works
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 相关工作
- en: Catastrophic forgetting
  id: totrans-202
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 灾难性遗忘
- en: Catastrophic forgetting, a significant issue where models forget previously
    learned information upon learning new data, has received considerable attention
    in machine learning (McCloskey and Cohen, [1989](#bib.bib46); Goodfellow et al.,
    [2013](#bib.bib22); Kemker et al., [2018](#bib.bib31); Ramasesh et al., [2021](#bib.bib54);
    Liu et al., [2024](#bib.bib41)). In the realm of LLMs, there has been a growing
    body of recent works (Luo et al., [2023](#bib.bib45); Kotha et al., [2024](#bib.bib36);
    Shi et al., [2024](#bib.bib63); Wu et al., [2024](#bib.bib72)) focusing on the
    forgetting of models’ knowledge during the fine-tuning process.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 灾难性遗忘，即模型在学习新数据时忘记以前学习的信息，是一个重要问题，在机器学习中受到了相当大的关注（McCloskey和Cohen，[1989](#bib.bib46)；Goodfellow等，[2013](#bib.bib22)；Kemker等，[2018](#bib.bib31)；Ramasesh等，[2021](#bib.bib54)；Liu等，[2024](#bib.bib41)）。在LLMs领域，最近有越来越多的工作（Luo等，[2023](#bib.bib45)；Kotha等，[2024](#bib.bib36)；Shi等，[2024](#bib.bib63)；Wu等，[2024](#bib.bib72)）关注于模型在微调过程中知识的遗忘。
- en: 'Researchers have proposed numerous methods to alleviate forgetting in continual
    learning, which involves learning a sequence of tasks. These methods are not limited
    to learning in a sequential manner and can be applied to broader paradigms. Generally,
    three primary approaches are used: replay-based methods, regularization-based
    methods, and architecture-based methods.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员提出了许多方法来减轻连续学习中的遗忘，这涉及学习一系列任务。这些方法不限于顺序学习，可以应用于更广泛的范式。通常使用三种主要方法：基于重放的方法、基于正则化的方法和基于架构的方法。
- en: •
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Replay-based methods leverage past experiences to facilitate the learning of
    new tasks. The most straightforward implementation of this approach is experience
    replay, which involves maintaining old samples in a buffer and replaying them
    during incremental training (Rolnick et al., [2019](#bib.bib61)) with some variants
    enhancing performance or optimizing memory usage (Aljundi et al., [2019a](#bib.bib2);
    Hayes et al., [2019](#bib.bib24); Cha et al., [2021](#bib.bib6); Chaudhry et al.,
    [2019b](#bib.bib10); Riemer et al., [2019b](#bib.bib59)). Several other variants
    utilize gradient information from past tasks (Lopez-Paz and Ranzato, [2017](#bib.bib42);
    Riemer et al., [2019a](#bib.bib58); Chaudhry et al., [2019a](#bib.bib9); Farajtabar
    et al., [2020](#bib.bib19); Aljundi et al., [2019b](#bib.bib3); Chaudhry et al.,
    [2021](#bib.bib11); Tiwari et al., [2022](#bib.bib65)). In LLMs, several works
    (Yin et al., [2023](#bib.bib75); Wang et al., [2024](#bib.bib70); Ouyang et al.,
    [2022](#bib.bib51)) propose replay-based methods to mitigate forgetting. We emphasize
    that our MoFO method is orthogonal to replay-based methods. MoFO can be integrated
    into these replay strategies to further enhance their effectiveness.
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于重放的方法利用过去的经验来促进新任务的学习。这种方法最直接的实现方式是经验重放，涉及在缓冲区中保持旧样本，并在增量训练期间进行重放（Rolnick
    等， [2019](#bib.bib61)），一些变体通过提升性能或优化内存使用（Aljundi 等， [2019a](#bib.bib2)；Hayes 等，
    [2019](#bib.bib24)；Cha 等， [2021](#bib.bib6)；Chaudhry 等， [2019b](#bib.bib10)；Riemer
    等， [2019b](#bib.bib59)）来增强效果。其他一些变体利用来自过去任务的梯度信息（Lopez-Paz 和 Ranzato， [2017](#bib.bib42)；Riemer
    等， [2019a](#bib.bib58)；Chaudhry 等， [2019a](#bib.bib9)；Farajtabar 等， [2020](#bib.bib19)；Aljundi
    等， [2019b](#bib.bib3)；Chaudhry 等， [2021](#bib.bib11)；Tiwari 等， [2022](#bib.bib65)）。在大型语言模型（LLMs）中，一些研究（Yin
    等， [2023](#bib.bib75)；Wang 等， [2024](#bib.bib70)；Ouyang 等， [2022](#bib.bib51)）提出了基于重放的方法来减轻遗忘。我们强调，我们的
    MoFO 方法与基于重放的方法是正交的。MoFO 可以集成到这些重放策略中，以进一步提升它们的效果。
- en: •
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Regularization-based methods introduce constraints to preserve old knowledge.
    Several studies add regularization terms to the loss functions to penalize parameter
    changes and mitigate forgetting (Kirkpatrick et al., [2017](#bib.bib34); Aljundi
    et al., [2018](#bib.bib1); Zenke et al., [2017](#bib.bib79); Li et al., [2018](#bib.bib38);
    Ritter et al., [2018](#bib.bib60); Kumar et al., [2023](#bib.bib37)). Some other
    works apply regularization to the embedding or output changes (Li and Hoiem, [2017](#bib.bib39);
    Rannen et al., [2017](#bib.bib55); Buzzega et al., [2020](#bib.bib5); Huang et al.,
    [2021](#bib.bib28)). Unlike these approaches, MoFO does not modify the loss function
    and as a result, MoFO reached better fine-tuning performance (see Table [3](#S3.T3
    "Table 3 ‣ Baselines ‣ 3.2 Instruction Fine-Tuning ‣ 3 Experiments ‣ MoFO: Momentum-Filtered
    Optimizer for Mitigating Forgetting in LLM Fine-Tuning") and [4](#S3.T4 "Table
    4 ‣ Results of fine-tuning on MetaMathQA. ‣ 3.2 Instruction Fine-Tuning ‣ 3 Experiments
    ‣ MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting in LLM Fine-Tuning")).'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '基于正则化的方法通过引入约束来保留旧知识。一些研究通过在损失函数中添加正则化项来惩罚参数变化并减轻遗忘（Kirkpatrick 等， [2017](#bib.bib34)；Aljundi
    等， [2018](#bib.bib1)；Zenke 等， [2017](#bib.bib79)；Li 等， [2018](#bib.bib38)；Ritter
    等， [2018](#bib.bib60)；Kumar 等， [2023](#bib.bib37)）。还有一些工作将正则化应用于嵌入或输出变化（Li 和 Hoiem，
    [2017](#bib.bib39)；Rannen 等， [2017](#bib.bib55)；Buzzega 等， [2020](#bib.bib5)；Huang
    等， [2021](#bib.bib28)）。与这些方法不同，MoFO 不修改损失函数，因此 MoFO 在微调性能上达到了更好的效果（见表 [3](#S3.T3
    "Table 3 ‣ Baselines ‣ 3.2 Instruction Fine-Tuning ‣ 3 Experiments ‣ MoFO: Momentum-Filtered
    Optimizer for Mitigating Forgetting in LLM Fine-Tuning") 和 [4](#S3.T4 "Table 4
    ‣ Results of fine-tuning on MetaMathQA. ‣ 3.2 Instruction Fine-Tuning ‣ 3 Experiments
    ‣ MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting in LLM Fine-Tuning")）。'
- en: •
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Architecture-based methods balance the goals of learning new knowledge and keeping
    the old one through model architectural modifications. LoRA (Hu et al., [2022](#bib.bib27)),
    as the most popular parameter-efficient fine-tuning (PEFT) methods, modifies the
    model architecture by freezing the pre-training weights and introducing low-rank
    trainable matrices. Empirical works shows that LoRA forgets less but learns less
    during fine-tuning (Biderman et al., [2024](#bib.bib4)). Some variants of LoRA
    find applications in continual learning of LLMs (Ren et al., [2024](#bib.bib56);
    Wang et al., [2023a](#bib.bib68)). In comparison, our MoFO still allows for high-rank
    updates to achieve better fine-tuning performance.
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于架构的方法通过模型架构修改平衡学习新知识和保留旧知识的目标。LoRA（Hu et al., [2022](#bib.bib27)）作为最受欢迎的参数高效微调（PEFT）方法，通过冻结预训练权重并引入低秩可训练矩阵来修改模型架构。实证研究表明，LoRA在微调过程中遗忘较少但学习也较少（Biderman
    et al., [2024](#bib.bib4)）。一些LoRA的变体在LLMs的持续学习中找到了应用（Ren et al., [2024](#bib.bib56);
    Wang et al., [2023a](#bib.bib68)）。相比之下，我们的MoFO仍然允许进行高秩更新，以实现更好的微调性能。
- en: Another line of architecture-based methods focuses on model merging. The idea
    stem from the understanding that the task-specific knowledge is located at a small
    subspace of the weight space (Panigrahi et al., [2023](#bib.bib52); Gueta et al.,
    [2023](#bib.bib23); Zhu et al., [2024](#bib.bib82)). Consequently, various model
    merging methods have been proposed to simultaneously retain pre-training knowledge
    and improve fine-tuning task performance (Panigrahi et al., [2023](#bib.bib52);
    Yadav et al., [2024](#bib.bib74); Yu et al., [2024b](#bib.bib77)). However, these
    methods require an additional post-fine-tuning process before model merging. In
    contrast, our method only requires only one fine-tuning stage.
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 另一类基于架构的方法关注模型合并。这个想法源于对任务特定知识位于权重空间的一个小子空间的理解（Panigrahi et al., [2023](#bib.bib52);
    Gueta et al., [2023](#bib.bib23); Zhu et al., [2024](#bib.bib82)）。因此，提出了各种模型合并方法，以同时保留预训练知识并改善微调任务性能（Panigrahi
    et al., [2023](#bib.bib52); Yadav et al., [2024](#bib.bib74); Yu et al., [2024b](#bib.bib77)）。然而，这些方法需要在模型合并之前进行额外的后微调过程。相比之下，我们的方法只需要一个微调阶段。
- en: Block coordinate descent
  id: totrans-212
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 块坐标下降
- en: Block Coordinate Descent (BCD) involves iteratively optimizing over a block
    of coordinates while holding the others constant. The foundational work of Tseng
    ([2001](#bib.bib67)) provides a comprehensive analysis of the convergence properties
    of BCD under certain conditions. Subsequent research has explored various BCD
    variants (Hong et al., [2017](#bib.bib26)), including randomized BCD (Nesterov,
    [2012](#bib.bib48); Richtárik and Takáč, [2014](#bib.bib57); Lu and Xiao, [2015](#bib.bib43)),
    cyclic BCD (Sun and Hong, [2015](#bib.bib64)), and greedy BCD (Nutini et al.,
    [2015](#bib.bib49)). Among these, the greedy variant, also known as Gauss-Southwell
    BCD method, has drawn attention due to its ability to prioritize coordinates that
    yield the most substantial improvement in each iteration, thereby potentially
    accelerating convergence.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 块坐标下降（BCD）涉及在保持其他坐标不变的情况下，迭代地优化一个坐标块。Tseng 的基础性工作（[2001](#bib.bib67)）提供了BCD在特定条件下收敛性质的全面分析。后续研究探讨了各种BCD变体（Hong
    et al., [2017](#bib.bib26)），包括随机BCD（Nesterov, [2012](#bib.bib48); Richtárik 和
    Takáč, [2014](#bib.bib57); Lu 和 Xiao, [2015](#bib.bib43)），循环BCD（Sun 和 Hong, [2015](#bib.bib64)），以及贪婪BCD（Nutini
    et al., [2015](#bib.bib49)）。其中，贪婪变体，即高斯-索斯韦尔BCD方法，由于其能够优先考虑在每次迭代中带来最大改进的坐标，从而可能加速收敛，引起了关注。
- en: In the realm of machine learning, BCD has also found applications (Nutini et al.,
    [2022](#bib.bib50)). For example, Luo et al. ([2024](#bib.bib44)) leverages BCD
    to perform memory-efficient fine-tuning of LLM and Xu and Zhang ([2024](#bib.bib73))
    use random masking to perform this. In federated learning, Rothchild et al. ([2020](#bib.bib62))
    adopts top-$k$ momentum filtering to tackle communication bottleneck and convergence
    issues. A recent work, Hui et al. ([2024](#bib.bib29)) addresses catastrophic
    forgetting during fine-tuning of LLMs by selectively freezing half of the parameters
    during training. Our approach is akin to a more efficient greedy BCD, achieving
    superior performance in fine-tuning tasks and alleviating forgetting better.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习领域，BCD 也找到了应用（Nutini 等人，[2022](#bib.bib50)）。例如，Luo 等人（[2024](#bib.bib44)）利用
    BCD 进行内存高效的 LLM 微调，Xu 和 Zhang（[2024](#bib.bib73)）使用随机遮罩来执行这一操作。在联邦学习中，Rothchild
    等人（[2020](#bib.bib62)）采用 top-$k$ 动量过滤来解决通信瓶颈和收敛问题。一项近期工作，Hui 等人（[2024](#bib.bib29)）通过在训练过程中选择性地冻结一半的参数来解决
    LLM 微调中的灾难性遗忘。我们的方法类似于更高效的贪婪 BCD，在微调任务中实现了更优的性能，并更好地缓解了遗忘。
- en: 6 Conclusion
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: This paper presents the Momentum-Filtered Optimizer (MoFO), a new approach designed
    to mitigate the crucial issue of pre-training knowledge forgetting in LLMs during
    fine-tuning. By selectively updating the parameters with the largest momentum
    magnitudes in each parameter block, MoFO converges to a point closer to the pre-trained
    model compared to full-parameter fine-tuning and effectively preserves pre-trained
    knowledge. Our experimental results demonstrate that MoFO not only significantly
    alleviates catastrophic forgetting but also surpasses the performance of traditional
    fine-tuning methods. Future work will explore further optimizations and potential
    applications of MoFO in multimodal LLMs.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提出了动量过滤优化器（MoFO），这是一种旨在减轻 LLM 在微调过程中关键的预训练知识遗忘问题的新方法。通过选择性地更新每个参数块中具有最大动量幅度的参数，MoFO
    比完全参数微调更接近于预训练模型，并有效地保持预训练知识。我们的实验结果表明，MoFO 不仅显著缓解了灾难性遗忘，还超越了传统微调方法的性能。未来的工作将探索
    MoFO 在多模态 LLM 中的进一步优化和潜在应用。
- en: References
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Aljundi et al. [2018] R. Aljundi, F. Babiloni, M. Elhoseiny, M. Rohrbach, and
    T. Tuytelaars. Memory aware synapses: Learning what (not) to forget. In *Proceedings
    of the European conference on computer vision (ECCV)*, pages 139–154, 2018.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Aljundi 等人 [2018] R. Aljundi, F. Babiloni, M. Elhoseiny, M. Rohrbach, 和 T. Tuytelaars.
    记忆感知突触：学习忘记什么（不）以及如何忘记。在 *欧洲计算机视觉会议 (ECCV) 论文集*，第 139–154 页，2018。
- en: Aljundi et al. [2019a] R. Aljundi, E. Belilovsky, T. Tuytelaars, L. Charlin,
    M. Caccia, M. Lin, and L. Page-Caccia. Online continual learning with maximal
    interfered retrieval. *Advances in neural information processing systems*, 32,
    2019a.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Aljundi 等人 [2019a] R. Aljundi, E. Belilovsky, T. Tuytelaars, L. Charlin, M.
    Caccia, M. Lin, 和 L. Page-Caccia. 具有最大干扰检索的在线持续学习。*神经信息处理系统进展*，32，2019a。
- en: Aljundi et al. [2019b] R. Aljundi, M. Lin, B. Goujaud, and Y. Bengio. Gradient
    based sample selection for online continual learning. *Advances in neural information
    processing systems*, 32, 2019b.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Aljundi 等人 [2019b] R. Aljundi, M. Lin, B. Goujaud, 和 Y. Bengio. 基于梯度的样本选择用于在线持续学习。*神经信息处理系统进展*，32，2019b。
- en: Biderman et al. [2024] D. Biderman, J. G. Ortiz, J. Portes, M. Paul, P. Greengard,
    C. Jennings, D. King, S. Havens, V. Chiley, J. Frankle, et al. LoRA learns less
    and forgets less. *arXiv preprint arXiv:2405.09673*, 2024.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Biderman 等人 [2024] D. Biderman, J. G. Ortiz, J. Portes, M. Paul, P. Greengard,
    C. Jennings, D. King, S. Havens, V. Chiley, J. Frankle, 等人. LoRA 学得更少且遗忘更少。*arXiv
    预印本 arXiv:2405.09673*，2024。
- en: 'Buzzega et al. [2020] P. Buzzega, M. Boschini, A. Porrello, D. Abati, and S. Calderara.
    Dark experience for general continual learning: a strong, simple baseline. *Advances
    in neural information processing systems*, 33:15920–15930, 2020.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Buzzega 等人 [2020] P. Buzzega, M. Boschini, A. Porrello, D. Abati, 和 S. Calderara.
    用于通用持续学习的黑暗经验：一个强大且简单的基线。*神经信息处理系统进展*，33:15920–15930，2020。
- en: 'Cha et al. [2021] H. Cha, J. Lee, and J. Shin. Co2l: Contrastive continual
    learning. In *Proceedings of the IEEE/CVF International conference on computer
    vision*, pages 9516–9525, 2021.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cha 等人 [2021] H. Cha, J. Lee, 和 J. Shin. Co2l：对比持续学习。在 *IEEE/CVF 国际计算机视觉大会论文集*，第
    9516–9525 页，2021。
- en: 'Chaudhary [2023] S. Chaudhary. Code alpaca: An instruction-following llama
    model for code generation. [https://github.com/sahil280114/codealpaca](https://github.com/sahil280114/codealpaca),
    2023.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chaudhary [2023] S. Chaudhary. 代码 alpaca：用于代码生成的指令跟随 llama 模型。 [https://github.com/sahil280114/codealpaca](https://github.com/sahil280114/codealpaca)，2023。
- en: 'Chaudhry et al. [2018] A. Chaudhry, P. K. Dokania, T. Ajanthan, and P. H. Torr.
    Riemannian walk for incremental learning: Understanding forgetting and intransigence.
    In *European Conference on Computer Vision*, pages 556–572, 2018.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 乔杜里等人 [2018] A. 乔杜里, P. K. 多卡尼亚, T. 阿贾南, 和 P. H. 托尔. 增量学习的黎曼行走：理解遗忘和固执。在*欧洲计算机视觉会议*，第556–572页，2018年。
- en: Chaudhry et al. [2019a] A. Chaudhry, M. Ranzato, M. Rohrbach, and M. Elhoseiny.
    Efficient lifelong learning with A-GEM. In *International Conference on Learning
    Representations*, 2019a.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 乔杜里等人 [2019a] A. 乔杜里, M. 兰扎托, M. 罗尔巴赫, 和 M. 埃尔霍塞尼. 使用A-GEM的高效终身学习。在*国际学习表征会议*，2019年。
- en: Chaudhry et al. [2019b] A. Chaudhry, M. Rohrbach, M. Elhoseiny, T. Ajanthan,
    P. K. Dokania, P. H. Torr, and M. Ranzato. On tiny episodic memories in continual
    learning. *arXiv preprint arXiv:1902.10486*, 2019b.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 乔杜里等人 [2019b] A. 乔杜里, M. 罗尔巴赫, M. 埃尔霍塞尼, T. 阿贾南, P. K. 多卡尼亚, P. H. 托尔, 和 M.
    兰扎托. 关于持续学习中的微小情节记忆。*arXiv预印本 arXiv:1902.10486*，2019年。
- en: Chaudhry et al. [2021] A. Chaudhry, A. Gordo, P. Dokania, P. Torr, and D. Lopez-Paz.
    Using hindsight to anchor past knowledge in continual learning. In *Proceedings
    of the AAAI conference on artificial intelligence*, volume 35, pages 6993–7001,
    2021.
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 乔杜里等人 [2021] A. 乔杜里, A. 戈尔多, P. 多卡尼亚, P. 托尔, 和 D. 洛佩斯-帕斯. 使用事后推测来锚定持续学习中的过去知识。在*AAAI人工智能会议录*，第35卷，第6993–7001页，2021年。
- en: Chen et al. [2021] M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. D. O. Pinto, J. Kaplan,
    H. Edwards, Y. Burda, N. Joseph, G. Brockman, et al. Evaluating large language
    models trained on code. *arXiv preprint arXiv:2107.03374*, 2021.
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈等人 [2021] M. 陈, J. 特沃雷克, H. 军, Q. 袁, H. P. D. O. 品托, J. 卡普兰, H. 爱德华兹, Y. 布尔达,
    N. 约瑟夫, G. 布罗克曼, 等人. 评估在代码上训练的大型语言模型。*arXiv预印本 arXiv:2107.03374*，2021年。
- en: 'Chen et al. [2020] S. Chen, Y. Hou, Y. Cui, W. Che, T. Liu, and X. Yu. Recall
    and learn: Fine-tuning deep pretrained language models with less forgetting. In
    *Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing
    (EMNLP)*, pages 7870–7881, 2020.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈等人 [2020] S. 陈, Y. 侯, Y. 崔, W. 谢, T. 刘, 和 X. 于. 召回与学习：通过较少的遗忘微调深度预训练语言模型。在*2020年自然语言处理实证方法会议（EMNLP）会议录*，第7870–7881页，2020年。
- en: Chen et al. [2024] X. Chen, C. Liang, D. Huang, E. Real, K. Wang, H. Pham, X. Dong,
    T. Luong, C.-J. Hsieh, Y. Lu, et al. Symbolic discovery of optimization algorithms.
    *Advances in neural information processing systems*, 36, 2024.
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈等人 [2024] X. 陈, C. 梁, D. 黄, E. 实, K. 王, H. 潘, X. 董, T. 刘, C.-J. 谢, Y. 陆, 等人.
    优化算法的符号发现。*神经信息处理系统进展*，36，2024年。
- en: Clark et al. [2018] P. Clark, I. Cowhey, O. Etzioni, T. Khot, A. Sabharwal,
    C. Schoenick, and O. Tafjord. Think you have solved question answering? Try ARC,
    the AI2 reasoning challenge. *arXiv preprint arXiv:1803.05457*, 2018.
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 克拉克等人 [2018] P. 克拉克, I. 考赫, O. 埃茨尼, T. 霍特, A. 萨布哈瓦尔, C. 施恩尼克, 和 O. 塔福德. 认为你已经解决了问答问题？试试ARC，AI2推理挑战。*arXiv预印本
    arXiv:1803.05457*，2018年。
- en: Cobbe et al. [2021] K. Cobbe, V. Kosaraju, M. Bavarian, M. Chen, H. Jun, L. Kaiser,
    M. Plappert, J. Tworek, J. Hilton, R. Nakano, et al. Training verifiers to solve
    math word problems. *arXiv preprint arXiv:2110.14168*, 2021.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 科比等人 [2021] K. 科比, V. 科萨拉朱, M. 巴伐利亚, M. 陈, H. 军, L. 凯泽, M. 普拉普特, J. 特沃雷克, J.
    希尔顿, R. 中野, 等人. 训练验证器解决数学文字问题。*arXiv预印本 arXiv:2110.14168*，2021年。
- en: Dai and Le [2015] A. M. Dai and Q. V. Le. Semi-supervised sequence learning.
    *Advances in neural information processing systems*, 28, 2015.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 戴和乐 [2015] A. M. 戴 和 Q. V. 乐. 半监督序列学习。*神经信息处理系统进展*，28，2015年。
- en: Dong et al. [2021] X. Dong, A. T. Luu, M. Lin, S. Yan, and H. Zhang. How should
    pre-trained language models be fine-tuned towards adversarial robustness? *Advances
    in Neural Information Processing Systems*, 34:4356–4369, 2021.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 董等人 [2021] X. 董, A. T. 绿, M. 林, S. 燕, 和 H. 张. 预训练语言模型应该如何朝着对抗性鲁棒性进行微调？*神经信息处理系统进展*，34:4356–4369，2021年。
- en: Farajtabar et al. [2020] M. Farajtabar, N. Azizan, A. Mott, and A. Li. Orthogonal
    gradient descent for continual learning. In *International Conference on Artificial
    Intelligence and Statistics*, pages 3762–3773\. PMLR, 2020.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 法拉赫塔巴尔等人 [2020] M. 法拉赫塔巴尔, N. 阿齐赞, A. 莫特, 和 A. 李. 正交梯度下降用于持续学习。在*国际人工智能与统计会议*，第3762–3773页，PMLR，2020年。
- en: 'Gao et al. [2020] L. Gao, S. Biderman, S. Black, L. Golding, T. Hoppe, C. Foster,
    J. Phang, H. He, A. Thite, N. Nabeshima, et al. The Pile: An 800GB dataset of
    diverse text for language modeling. *arXiv preprint arXiv:2101.00027*, 2020.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高等人 [2020] L. 高, S. 比德曼, S. 布莱克, L. 高丁, T. 霍普, C. 福斯特, J. 方, H. 赫, A. 西特, N.
    纳贝希马, 等人. The Pile：一个包含800GB多样文本的数据集，用于语言建模。*arXiv预印本 arXiv:2101.00027*，2020年。
- en: Gao et al. [2023] L. Gao, J. Tow, B. Abbasi, S. Biderman, S. Black, A. DiPofi,
    C. Foster, L. Golding, J. Hsu, A. Le Noac’h, H. Li, K. McDonell, N. Muennighoff,
    C. Ociepa, J. Phang, L. Reynolds, H. Schoelkopf, A. Skowron, L. Sutawika, E. Tang,
    A. Thite, B. Wang, K. Wang, and A. Zou. A framework for few-shot language model
    evaluation, 12 2023. URL [https://zenodo.org/records/10256836](https://zenodo.org/records/10256836).
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao et al. [2023] L. Gao, J. Tow, B. Abbasi, S. Biderman, S. Black, A. DiPofi,
    C. Foster, L. Golding, J. Hsu, A. Le Noac’h, H. Li, K. McDonell, N. Muennighoff,
    C. Ociepa, J. Phang, L. Reynolds, H. Schoelkopf, A. Skowron, L. Sutawika, E. Tang,
    A. Thite, B. Wang, K. Wang, 和 A. Zou. 少样本语言模型评估框架，2023年12月。网址 [https://zenodo.org/records/10256836](https://zenodo.org/records/10256836)。
- en: Goodfellow et al. [2013] I. J. Goodfellow, M. Mirza, D. Xiao, A. Courville,
    and Y. Bengio. An empirical investigation of catastrophic forgetting in gradient-based
    neural networks. *arXiv preprint arXiv:1312.6211*, 2013.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow et al. [2013] I. J. Goodfellow, M. Mirza, D. Xiao, A. Courville,
    和 Y. Bengio. 对梯度基础神经网络中灾难性遗忘的实证研究。*arXiv 预印本 arXiv:1312.6211*，2013年。
- en: 'Gueta et al. [2023] A. Gueta, E. Venezian, C. Raffel, N. Slonim, Y. Katz, and
    L. Choshen. Knowledge is a region in weight space for fine-tuned language models.
    In *Findings of the Association for Computational Linguistics: EMNLP 2023*, pages
    1350–1370, 2023.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gueta et al. [2023] A. Gueta, E. Venezian, C. Raffel, N. Slonim, Y. Katz, 和
    L. Choshen. 知识是细化语言模型中的权重空间区域。发表于 *计算语言学协会发现：EMNLP 2023*，第1350–1370页，2023年。
- en: Hayes et al. [2019] T. L. Hayes, N. D. Cahill, and C. Kanan. Memory efficient
    experience replay for streaming learning. In *2019 International Conference on
    Robotics and Automation (ICRA)*, pages 9769–9776\. IEEE, 2019.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hayes et al. [2019] T. L. Hayes, N. D. Cahill, 和 C. Kanan. 流式学习的记忆高效经验重放。发表于
    *2019年国际机器人与自动化会议（ICRA）*，第9769–9776页。IEEE，2019年。
- en: Hendrycks et al. [2021] D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika,
    D. Song, and J. Steinhardt. Measuring massive multitask language understanding.
    In *International Conference on Learning Representations*, 2021.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hendrycks et al. [2021] D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika,
    D. Song, 和 J. Steinhardt. 测量大规模多任务语言理解。发表于 *国际学习表征会议*，2021年。
- en: Hong et al. [2017] M. Hong, X. Wang, M. Razaviyayn, and Z.-Q. Luo. Iteration
    complexity analysis of block coordinate descent methods. *Mathematical Programming*,
    163:85–114, 2017.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hong et al. [2017] M. Hong, X. Wang, M. Razaviyayn, 和 Z.-Q. Luo. 块坐标下降方法的迭代复杂度分析。*数学编程*，163:85–114，2017年。
- en: 'Hu et al. [2022] E. J. Hu, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang,
    W. Chen, et al. LoRA: Low-rank adaptation of large language models. In *International
    Conference on Learning Representations*, 2022.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu et al. [2022] E. J. Hu, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang,
    W. Chen 等. LoRA：大语言模型的低秩适配。发表于 *国际学习表征会议*，2022年。
- en: 'Huang et al. [2021] Y. Huang, Y. Zhang, J. Chen, X. Wang, and D. Yang. Continual
    learning for text classification with information disentanglement based regularization.
    In *Proceedings of the 2021 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies*, pages 2736–2746,
    2021.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang et al. [2021] Y. Huang, Y. Zhang, J. Chen, X. Wang, 和 D. Yang. 基于信息解耦的正则化的文本分类持续学习。发表于
    *2021年北美计算语言学协会：人类语言技术会议论文集*，第2736–2746页，2021年。
- en: 'Hui et al. [2024] T. Hui, Z. Zhang, S. Wang, W. Xu, Y. Sun, and H. Wu. Hft:
    Half fine-tuning for large language models. *arXiv preprint arXiv:2404.18466*,
    2024.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hui et al. [2024] T. Hui, Z. Zhang, S. Wang, W. Xu, Y. Sun, 和 H. Wu. Hft: 大型语言模型的半精调。*arXiv
    预印本 arXiv:2404.18466*，2024年。'
- en: 'Ivison et al. [2023] H. Ivison, Y. Wang, V. Pyatkin, N. Lambert, M. Peters,
    P. Dasigi, J. Jang, D. Wadden, N. A. Smith, I. Beltagy, et al. Camels in a changing
    climate: Enhancing lm adaptation with tulu 2. *arXiv preprint arXiv:2311.10702*,
    2023.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ivison et al. [2023] H. Ivison, Y. Wang, V. Pyatkin, N. Lambert, M. Peters,
    P. Dasigi, J. Jang, D. Wadden, N. A. Smith, I. Beltagy 等. 气候变化中的骆驼：通过 tulu 2 增强语言模型适应。*arXiv
    预印本 arXiv:2311.10702*，2023年。
- en: Kemker et al. [2018] R. Kemker, M. McClure, A. Abitino, T. Hayes, and C. Kanan.
    Measuring catastrophic forgetting in neural networks. In *Proceedings of the AAAI
    conference on artificial intelligence*, volume 32, 2018.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kemker et al. [2018] R. Kemker, M. McClure, A. Abitino, T. Hayes, 和 C. Kanan.
    测量神经网络中的灾难性遗忘。发表于 *AAAI 人工智能会议论文集*，第32卷，2018年。
- en: 'Kenton and Toutanova [2019] J. D. M.-W. C. Kenton and L. K. Toutanova. Bert:
    Pre-training of deep bidirectional transformers for language understanding. In
    *Proceedings of NAACL-HLT*, pages 4171–4186, 2019.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kenton and Toutanova [2019] J. D. M.-W. C. Kenton 和 L. K. Toutanova. Bert：用于语言理解的深度双向变换器的预训练。发表于
    *NAACL-HLT 会议论文集*，第4171–4186页，2019年。
- en: 'Kingma and Ba [2014] D. P. Kingma and J. Ba. Adam: A method for stochastic
    optimization. *arXiv preprint arXiv:1412.6980*, 2014.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kingma and Ba [2014] D. P. Kingma and J. Ba. Adam：一种随机优化方法。*arXiv 预印本 arXiv:1412.6980*，2014年。
- en: Kirkpatrick et al. [2017] J. Kirkpatrick, R. Pascanu, N. Rabinowitz, J. Veness,
    G. Desjardins, A. A. Rusu, K. Milan, J. Quan, T. Ramalho, A. Grabska-Barwinska,
    et al. Overcoming catastrophic forgetting in neural networks. *Proceedings of
    the national academy of sciences*, 114(13):3521–3526, 2017.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kirkpatrick et al. [2017] J. Kirkpatrick, R. Pascanu, N. Rabinowitz, J. Veness,
    G. Desjardins, A. A. Rusu, K. Milan, J. Quan, T. Ramalho, A. Grabska-Barwinska,
    等。克服神经网络中的灾难性遗忘。*国家科学院学报*，114(13)：3521–3526，2017年。
- en: Korbak et al. [2022] T. Korbak, H. Elsahar, G. Kruszewski, and M. Dymetman.
    Controlling conditional language models without catastrophic forgetting. In *International
    Conference on Machine Learning*, pages 11499–11528\. PMLR, 2022.
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Korbak et al. [2022] T. Korbak, H. Elsahar, G. Kruszewski, and M. Dymetman.
    控制条件语言模型而不产生灾难性遗忘。见于 *国际机器学习会议*，第11499–11528页。PMLR，2022年。
- en: Kotha et al. [2024] S. Kotha, J. M. Springer, and A. Raghunathan. Understanding
    catastrophic forgetting in language models via implicit inference. In *The Twelfth
    International Conference on Learning Representations*, 2024.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kotha et al. [2024] S. Kotha, J. M. Springer, and A. Raghunathan. 通过隐式推断理解语言模型中的灾难性遗忘。见于
    *第十二届国际学习表征会议*，2024年。
- en: Kumar et al. [2023] S. Kumar, H. Marklund, and B. Van Roy. Maintaining plasticity
    via regenerative regularization. *arXiv preprint arXiv:2308.11958*, 2023.
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kumar et al. [2023] S. Kumar, H. Marklund, and B. Van Roy. 通过再生正则化维持可塑性。*arXiv
    预印本 arXiv:2308.11958*，2023年。
- en: Li et al. [2018] X. Li, Y. Grandvalet, and F. Davoine. Explicit inductive bias
    for transfer learning with convolutional networks. In *International Conference
    on Machine Learning*, pages 2825–2834\. PMLR, 2018.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. [2018] X. Li, Y. Grandvalet, and F. Davoine. 卷积网络的迁移学习的显式归纳偏差。见于 *国际机器学习会议*，第2825–2834页。PMLR，2018年。
- en: Li and Hoiem [2017] Z. Li and D. Hoiem. Learning without forgetting. *IEEE transactions
    on pattern analysis and machine intelligence*, 40(12):2935–2947, 2017.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li and Hoiem [2017] Z. Li and D. Hoiem. 无遗忘学习。*IEEE 计算机学会模式分析与机器智能汇刊*，40(12)：2935–2947，2017年。
- en: 'Lin et al. [2023] Y. Lin, L. Tan, H. Lin, Z. Zheng, R. Pi, J. Zhang, S. Diao,
    H. Wang, H. Zhao, Y. Yao, et al. Speciality vs generality: An empirical study
    on catastrophic forgetting in fine-tuning foundation models. *arXiv preprint arXiv:2309.06256*,
    2023.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin et al. [2023] Y. Lin, L. Tan, H. Lin, Z. Zheng, R. Pi, J. Zhang, S. Diao,
    H. Wang, H. Zhao, Y. Yao, 等。专业性与通用性：对基础模型微调中灾难性遗忘的实证研究。*arXiv 预印本 arXiv:2309.06256*，2023年。
- en: 'Liu et al. [2024] C. Liu, S. Wang, Y. Kang, L. Qing, F. Zhao, C. Sun, K. Kuang,
    and F. Wu. More than catastrophic forgetting: Integrating general capabilities
    for domain-specific llms. *arXiv preprint arXiv:2405.17830*, 2024.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. [2024] C. Liu, S. Wang, Y. Kang, L. Qing, F. Zhao, C. Sun, K. Kuang,
    and F. Wu. 超越灾难性遗忘：为领域特定的大语言模型整合通用能力。*arXiv 预印本 arXiv:2405.17830*，2024年。
- en: Lopez-Paz and Ranzato [2017] D. Lopez-Paz and M. Ranzato. Gradient episodic
    memory for continual learning. *Advances in neural information processing systems*,
    30, 2017.
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lopez-Paz and Ranzato [2017] D. Lopez-Paz and M. Ranzato. 用于持续学习的梯度情节记忆。*神经信息处理系统进展*，30，2017年。
- en: Lu and Xiao [2015] Z. Lu and L. Xiao. On the complexity analysis of randomized
    block-coordinate descent methods. *Mathematical Programming*, 152:615–642, 2015.
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lu and Xiao [2015] Z. Lu and L. Xiao. 随机块坐标下降方法的复杂性分析。*数学规划*，152：615–642，2015年。
- en: 'Luo et al. [2024] Q. Luo, H. Yu, and X. Li. Badam: A memory efficient full
    parameter training method for large language models. *arXiv preprint arXiv:2404.02827*,
    2024.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Luo et al. [2024] Q. Luo, H. Yu, and X. Li. Badam：一种内存高效的全参数训练方法用于大型语言模型。*arXiv
    预印本 arXiv:2404.02827*，2024年。
- en: Luo et al. [2023] Y. Luo, Z. Yang, F. Meng, Y. Li, J. Zhou, and Y. Zhang. An
    empirical study of catastrophic forgetting in large language models during continual
    fine-tuning. *arXiv preprint arXiv:2308.08747*, 2023.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Luo et al. [2023] Y. Luo, Z. Yang, F. Meng, Y. Li, J. Zhou, and Y. Zhang. 大型语言模型在持续微调中的灾难性遗忘的实证研究。*arXiv
    预印本 arXiv:2308.08747*，2023年。
- en: 'McCloskey and Cohen [1989] M. McCloskey and N. J. Cohen. Catastrophic interference
    in connectionist networks: The sequential learning problem. In *Psychology of
    learning and motivation*, volume 24, pages 109–165\. Elsevier, 1989.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: McCloskey and Cohen [1989] M. McCloskey and N. J. Cohen. 连接主义网络中的灾难性干扰：顺序学习问题。见于
    *学习与动机心理学*，第24卷，第109–165页。Elsevier，1989年。
- en: Miceli-Barone et al. [2017] A. V. Miceli-Barone, B. Haddow, U. Germann, and
    R. Sennrich. Regularization techniques for fine-tuning in neural machine translation.
    In *Proceedings of the 2017 Conference on Empirical Methods in Natural Language
    Processing*, pages 1489–1494, 2017.
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Miceli-Barone 等 [2017] A. V. Miceli-Barone, B. Haddow, U. Germann 和 R. Sennrich.
    神经机器翻译中的微调正则化技术。发表于 *2017 年自然语言处理实证方法大会论文集*，页码 1489–1494，2017。
- en: Nesterov [2012] Y. Nesterov. Efficiency of coordinate descent methods on huge-scale
    optimization problems. *SIAM Journal on Optimization*, 22(2):341–362, 2012.
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nesterov [2012] Y. Nesterov. 坐标下降法在大规模优化问题中的效率。*SIAM 优化杂志*，22(2):341–362，2012。
- en: Nutini et al. [2015] J. Nutini, M. Schmidt, I. Laradji, M. Friedlander, and
    H. Koepke. Coordinate descent converges faster with the gauss-southwell rule than
    random selection. In *International Conference on Machine Learning*, pages 1632–1641\.
    PMLR, 2015.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nutini 等 [2015] J. Nutini, M. Schmidt, I. Laradji, M. Friedlander 和 H. Koepke.
    使用高斯-索斯威尔规则的坐标下降法收敛速度快于随机选择。发表于 *国际机器学习大会*，页码 1632–1641\. PMLR，2015。
- en: 'Nutini et al. [2022] J. Nutini, I. Laradji, and M. Schmidt. Let’s make block
    coordinate descent converge faster: faster greedy rules, message-passing, active-set
    complexity, and superlinear convergence. *Journal of Machine Learning Research*,
    23(131):1–74, 2022.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nutini 等 [2022] J. Nutini, I. Laradji 和 M. Schmidt. 让块坐标下降法更快收敛：更快的贪婪规则、消息传递、活动集复杂性和超线性收敛。*机器学习研究杂志*，23(131):1–74，2022。
- en: Ouyang et al. [2022] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright,
    P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, et al. Training language models
    to follow instructions with human feedback. *Advances in neural information processing
    systems*, 35:27730–27744, 2022.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ouyang 等 [2022] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin,
    C. Zhang, S. Agarwal, K. Slama, A. Ray 等. 训练语言模型以遵循人类反馈的指令。*神经信息处理系统进展*，35:27730–27744，2022。
- en: Panigrahi et al. [2023] A. Panigrahi, N. Saunshi, H. Zhao, and S. Arora. Task-specific
    skill localization in fine-tuned language models. In *International Conference
    on Machine Learning*, pages 27011–27033\. PMLR, 2023.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Panigrahi 等 [2023] A. Panigrahi, N. Saunshi, H. Zhao 和 S. Arora. 任务特定技能在微调语言模型中的定位。发表于
    *国际机器学习大会*，页码 27011–27033\. PMLR，2023。
- en: Radford et al. [2018] A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever.
    Improving language understanding with unsupervised learning. 2018.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Radford 等 [2018] A. Radford, K. Narasimhan, T. Salimans 和 I. Sutskever. 通过无监督学习改善语言理解。2018。
- en: Ramasesh et al. [2021] V. V. Ramasesh, A. Lewkowycz, and E. Dyer. Effect of
    scale on catastrophic forgetting in neural networks. In *International Conference
    on Learning Representations*, 2021.
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ramasesh 等 [2021] V. V. Ramasesh, A. Lewkowycz 和 E. Dyer. 规模对神经网络中灾难性遗忘的影响。发表于
    *国际学习表征大会*，2021。
- en: Rannen et al. [2017] A. Rannen, R. Aljundi, M. B. Blaschko, and T. Tuytelaars.
    Encoder based lifelong learning. In *Proceedings of the IEEE international conference
    on computer vision*, pages 1320–1328, 2017.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rannen 等 [2017] A. Rannen, R. Aljundi, M. B. Blaschko 和 T. Tuytelaars. 基于编码器的终身学习。发表于
    *IEEE 国际计算机视觉会议论文集*，页码 1320–1328，2017。
- en: Ren et al. [2024] W. Ren, X. Li, L. Wang, T. Zhao, and W. Qin. Analyzing and
    reducing catastrophic forgetting in parameter efficient tuning. *arXiv preprint
    arXiv:2402.18865*, 2024.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ren 等 [2024] W. Ren, X. Li, L. Wang, T. Zhao 和 W. Qin. 分析和减少参数高效调优中的灾难性遗忘。*arXiv
    预印本 arXiv:2402.18865*，2024。
- en: Richtárik and Takáč [2014] P. Richtárik and M. Takáč. Iteration complexity of
    randomized block-coordinate descent methods for minimizing a composite function.
    *Mathematical Programming*, 144(1):1–38, 2014.
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Richtárik 和 Takáč [2014] P. Richtárik 和 M. Takáč. 随机块坐标下降法在最小化复合函数中的迭代复杂性。*数学编程*，144(1):1–38，2014。
- en: Riemer et al. [2019a] M. Riemer, I. Cases, R. Ajemian, M. Liu, I. Rish, Y. Tu,
    and G. Tesauro. Learning to learn without forgetting by maximizing transfer and
    minimizing interference. In *International Conference on Learning Representations*,
    2019a.
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Riemer 等 [2019a] M. Riemer, I. Cases, R. Ajemian, M. Liu, I. Rish, Y. Tu 和 G. Tesauro.
    通过最大化转移和最小化干扰来学习而不遗忘。发表于 *国际学习表征大会*，2019a。
- en: Riemer et al. [2019b] M. Riemer, T. Klinger, D. Bouneffouf, and M. Franceschini.
    Scalable recollections for continual lifelong learning. In *Proceedings of the
    AAAI conference on artificial intelligence*, volume 33, pages 1352–1359, 2019b.
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Riemer 等 [2019b] M. Riemer, T. Klinger, D. Bouneffouf 和 M. Franceschini. 可扩展的持续终身学习回忆。发表于
    *AAAI 人工智能大会论文集*，卷 33，页码 1352–1359，2019b。
- en: Ritter et al. [2018] H. Ritter, A. Botev, and D. Barber. Online structured laplace
    approximations for overcoming catastrophic forgetting. *Advances in Neural Information
    Processing Systems*, 31, 2018.
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ritter 等 [2018] H. Ritter, A. Botev 和 D. Barber. 克服灾难性遗忘的在线结构化拉普拉斯近似。*神经信息处理系统进展*，31，2018。
- en: Rolnick et al. [2019] D. Rolnick, A. Ahuja, J. Schwarz, T. Lillicrap, and G. Wayne.
    Experience replay for continual learning. *Advances in neural information processing
    systems*, 32, 2019.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rolnick 等 [2019] D. Rolnick, A. Ahuja, J. Schwarz, T. Lillicrap 和 G. Wayne.
    持续学习的经验回放。*神经信息处理系统进展*，32，2019年。
- en: 'Rothchild et al. [2020] D. Rothchild, A. Panda, E. Ullah, N. Ivkin, I. Stoica,
    V. Braverman, J. Gonzalez, and R. Arora. Fetchsgd: Communication-efficient federated
    learning with sketching. In *International Conference on Machine Learning*, pages
    8253–8265\. PMLR, 2020.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Rothchild 等 [2020] D. Rothchild, A. Panda, E. Ullah, N. Ivkin, I. Stoica, V.
    Braverman, J. Gonzalez 和 R. Arora. Fetchsgd: 高效通信的联邦学习方法 In *国际机器学习会议*，第8253–8265页。PMLR，2020。'
- en: 'Shi et al. [2024] H. Shi, Z. Xu, H. Wang, W. Qin, W. Wang, Y. Wang, and H. Wang.
    Continual learning of large language models: A comprehensive survey. *arXiv preprint
    arXiv:2404.16789*, 2024.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi 等 [2024] H. Shi, Z. Xu, H. Wang, W. Qin, W. Wang, Y. Wang 和 H. Wang. 大型语言模型的持续学习：全面调查。*arXiv
    预印本 arXiv:2404.16789*，2024年。
- en: Sun and Hong [2015] R. Sun and M. Hong. Improved iteration complexity bounds
    of cyclic block coordinate descent for convex problems. *Advances in Neural Information
    Processing Systems*, 28, 2015.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun 和 Hong [2015] R. Sun 和 M. Hong. 针对凸问题的循环块坐标下降法的改进迭代复杂度界限。*神经信息处理系统进展*，28，2015年。
- en: 'Tiwari et al. [2022] R. Tiwari, K. Killamsetty, R. Iyer, and P. Shenoy. Gcr:
    Gradient coreset based replay buffer selection for continual learning. In *Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, pages
    99–108, 2022.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tiwari 等 [2022] R. Tiwari, K. Killamsetty, R. Iyer 和 P. Shenoy. Gcr: 基于梯度的核心集重放缓冲区选择用于持续学习。在
    *IEEE/CVF计算机视觉与模式识别会议论文集*，第99–108页，2022年。'
- en: 'Touvron et al. [2023] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi,
    Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale, et al. Llama 2: Open
    foundation and fine-tuned chat models. *arXiv preprint arXiv:2307.09288*, 2023.'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Touvron 等 [2023] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi,
    Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale 等。Llama 2: 开放基础和微调聊天模型。*arXiv
    预印本 arXiv:2307.09288*，2023年。'
- en: Tseng [2001] P. Tseng. Convergence of a block coordinate descent method for
    nondifferentiable minimization. *Journal of optimization theory and applications*,
    109:475–494, 2001.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tseng [2001] P. Tseng. 非光滑最小化问题的块坐标下降方法的收敛性。*优化理论与应用期刊*，109:475–494，2001年。
- en: Wang et al. [2023a] X. Wang, T. Chen, Q. Ge, H. Xia, R. Bao, R. Zheng, Q. Zhang,
    T. Gui, and X. Huang. Orthogonal subspace learning for language model continual
    learning. In *The 2023 Conference on Empirical Methods in Natural Language Processing*,
    2023a.
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等 [2023a] X. Wang, T. Chen, Q. Ge, H. Xia, R. Bao, R. Zheng, Q. Zhang,
    T. Gui 和 X. Huang. 语言模型持续学习的正交子空间学习。在 *2023年自然语言处理经验方法会议*，2023年。
- en: 'Wang et al. [2023b] X. Wang, Y. Zhang, T. Chen, S. Gao, S. Jin, X. Yang, Z. Xi,
    R. Zheng, Y. Zou, T. Gui, et al. Trace: A comprehensive benchmark for continual
    learning in large language models. *arXiv preprint arXiv:2310.06762*, 2023b.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang 等 [2023b] X. Wang, Y. Zhang, T. Chen, S. Gao, S. Jin, X. Yang, Z. Xi,
    R. Zheng, Y. Zou, T. Gui 等。Trace: 大型语言模型持续学习的综合基准。*arXiv 预印本 arXiv:2310.06762*，2023年。'
- en: 'Wang et al. [2024] Y. Wang, Y. Liu, C. Shi, H. Li, C. Chen, H. Lu, and Y. Yang.
    Inscl: A data-efficient continual learning paradigm for fine-tuning large language
    models with instructions. In *Proceedings of the 2024 Conference of the North
    American Chapter of the Association for Computational Linguistics: Human Language
    Technologies (Volume 1: Long Papers)*, pages 663–677, 2024.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang 等 [2024] Y. Wang, Y. Liu, C. Shi, H. Li, C. Chen, H. Lu 和 Y. Yang. Inscl:
    一种数据高效的持续学习范式，用于通过指令微调大型语言模型。在 *2024年北美计算语言学会会议：人类语言技术（第1卷：长篇论文）*，第663–677页，2024年。'
- en: Wang et al. [2020] Z. Wang, S. V. Mehta, B. Poczós, and J. G. Carbonell. Efficient
    meta lifelong-learning with limited memory. In *Proceedings of the 2020 Conference
    on Empirical Methods in Natural Language Processing (EMNLP)*, pages 535–548, 2020.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等 [2020] Z. Wang, S. V. Mehta, B. Poczós 和 J. G. Carbonell. 在有限记忆条件下的高效元终身学习。在
    *2020年自然语言处理经验方法会议论文集（EMNLP）*，第535–548页，2020年。
- en: 'Wu et al. [2024] T. Wu, L. Luo, Y.-F. Li, S. Pan, T.-T. Vu, and G. Haffari.
    Continual learning for large language models: A survey. *arXiv preprint arXiv:2402.01364*,
    2024.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等 [2024] T. Wu, L. Luo, Y.-F. Li, S. Pan, T.-T. Vu, 和 G. Haffari. 大语言模型的持续学习：综述。*arXiv
    预印本 arXiv:2402.01364*，2024。
- en: Xu and Zhang [2024] J. Xu and J. Zhang. Random masking finds winning tickets
    for parameter efficient fine-tuning. *arXiv preprint arXiv:2405.02596*, 2024.
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 和 Zhang [2024] J. Xu 和 J. Zhang. 随机掩码为参数高效微调找到胜利的票据。*arXiv 预印本 arXiv:2405.02596*，2024。
- en: 'Yadav et al. [2024] P. Yadav, D. Tam, L. Choshen, C. A. Raffel, and M. Bansal.
    Ties-merging: Resolving interference when merging models. *Advances in Neural
    Information Processing Systems*, 36, 2024.'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yadav 等 [2024] P. Yadav, D. Tam, L. Choshen, C. A. Raffel, 和 M. Bansal. Ties-merging:
    解决合并模型时的干扰。*神经信息处理系统进展*，36，2024。'
- en: 'Yin et al. [2023] D. Yin, X. Liu, F. Yin, M. Zhong, H. Bansal, J. Han, and
    K.-W. Chang. Dynosaur: A dynamic growth paradigm for instruction-tuning data curation.
    In *Proceedings of the 2023 Conference on Empirical Methods in Natural Language
    Processing*, pages 4031–4047, 2023.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yin 等 [2023] D. Yin, X. Liu, F. Yin, M. Zhong, H. Bansal, J. Han, 和 K.-W. Chang.
    Dynosaur: 一种用于指令调优数据策划的动态增长范式。发表于*2023年自然语言处理经验方法会议论文集*，页4031–4047，2023。'
- en: 'Yu et al. [2024a] L. Yu, W. Jiang, H. Shi, Y. Jincheng, Z. Liu, Y. Zhang, J. Kwok,
    Z. Li, A. Weller, and W. Liu. Metamath: Bootstrap your own mathematical questions
    for large language models. In *The Twelfth International Conference on Learning
    Representations*, 2024a.'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yu 等 [2024a] L. Yu, W. Jiang, H. Shi, Y. Jincheng, Z. Liu, Y. Zhang, J. Kwok,
    Z. Li, A. Weller, 和 W. Liu. Metamath: 启动你自己的数学问题以适应大语言模型。发表于*第十二届国际学习表征会议*，2024a。'
- en: 'Yu et al. [2024b] L. Yu, B. Yu, H. Yu, F. Huang, and Y. Li. Language models
    are super mario: Absorbing abilities from homologous models as a free lunch. In
    *Forty-first International Conference on Machine Learning*, 2024b.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu 等 [2024b] L. Yu, B. Yu, H. Yu, F. Huang, 和 Y. Li. 语言模型是超级马里奥：从同源模型中获得的免费能力。发表于*第41届国际机器学习大会*，2024b。
- en: 'Zellers et al. [2019] R. Zellers, A. Holtzman, Y. Bisk, A. Farhadi, and Y. Choi.
    Hellaswag: Can a machine really finish your sentence? In *Proceedings of the 57th
    Annual Meeting of the Association for Computational Linguistics*, pages 4791–4800,
    2019.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zellers 等 [2019] R. Zellers, A. Holtzman, Y. Bisk, A. Farhadi, 和 Y. Choi. Hellaswag:
    机器真的能完成你的句子吗？发表于*第57届计算语言学协会年会论文集*，页4791–4800，2019。'
- en: Zenke et al. [2017] F. Zenke, B. Poole, and S. Ganguli. Continual learning through
    synaptic intelligence. In *International conference on machine learning*, pages
    3987–3995\. PMLR, 2017.
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zenke 等 [2017] F. Zenke, B. Poole, 和 S. Ganguli. 通过突触智能进行持续学习。发表于*国际机器学习会议*，页3987–3995。PMLR，2017。
- en: 'Zhang et al. [2024] P. Zhang, G. Zeng, T. Wang, and W. Lu. Tinyllama: An open-source
    small language model. *arXiv preprint arXiv:2401.02385*, 2024.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang 等 [2024] P. Zhang, G. Zeng, T. Wang, 和 W. Lu. Tinyllama: 一个开源的小型语言模型。*arXiv
    预印本 arXiv:2401.02385*，2024。'
- en: Zhang et al. [2022] Y. Zhang, C. Chen, N. Shi, R. Sun, and Z.-Q. Luo. Adam can
    converge without any modification on update rules. *Advances in neural information
    processing systems*, 35:28386–28399, 2022.
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等 [2022] Y. Zhang, C. Chen, N. Shi, R. Sun, 和 Z.-Q. Luo. Adam 可以在不修改更新规则的情况下收敛。*神经信息处理系统进展*，35:28386–28399，2022。
- en: 'Zhu et al. [2024] D. Zhu, Z. Sun, Z. Li, T. Shen, K. Yan, S. Ding, K. Kuang,
    and C. Wu. Model tailor: Mitigating catastrophic forgetting in multi-modal large
    language models. *arXiv preprint arXiv:2402.12048*, 2024.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhu 等 [2024] D. Zhu, Z. Sun, Z. Li, T. Shen, K. Yan, S. Ding, K. Kuang, 和 C.
    Wu. Model tailor: 缓解多模态大语言模型中的灾难性遗忘。*arXiv 预印本 arXiv:2402.12048*，2024。'
- en: 'Appendix A Proof of Theorem [1](#Thmthm1 "Theorem 1 (Convergence of MoFO).
    ‣ 2.4 Convergence Result ‣ 2 Momentum Filtered Optimizer (MoFO) ‣ MoFO: Momentum-Filtered
    Optimizer for Mitigating Forgetting in LLM Fine-Tuning")'
  id: totrans-300
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '附录 A 定理 [1](#Thmthm1 "定理 1 (MoFO 的收敛性)。 ‣ 2.4 收敛结果 ‣ 2 动量过滤优化器 (MoFO) ‣ MoFO:
    用于减轻 LLM 微调中遗忘的动量过滤优化器")'
- en: Before providing the proof, we will give some preliminary information.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 在提供证明之前，我们将给出一些初步信息。
- en: Let’s assume the parameter space $\mathbb{R}^{d}$ denotes the product of the
    dimensions (i.e., the number of rows multiplied by the number of columns) of the
    $k$, we denote
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 设参数空间 $\mathbb{R}^{d}$ 表示 $k$ 的维度的乘积（即，行数乘以列数），我们表示
- en: '|  | $z={\rm Concat}(z^{(1)};z^{(2)};\dots;z^{(B)}),$ |  |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '|  | $z={\rm Concat}(z^{(1)};z^{(2)};\dots;z^{(B)}),$ |  |'
- en: where $z^{(k)}\in\mathbb{R}^{d_{k}}$.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $z^{(k)}\in\mathbb{R}^{d_{k}}$。
- en: Definition 1.
  id: totrans-305
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 1。
- en: For any $z\in\mathbb{R}^{d}$, we define
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何 $z\in\mathbb{R}^{d}$，我们定义
- en: '|  | $\&#124;{z}\&#124;_{\text{top-}\alpha\%}:=\&#124;z\odot{\mathbf{e}}_{S}\&#124;_{2},$
    |  |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
  zh: '|  | $\&#124;{z}\&#124;_{\text{top-}\alpha\%}:=\&#124;z\odot{\mathbf{e}}_{S}\&#124;_{2},$
    |  |'
- en: where ${\mathbf{e}}_{S}={\rm Concat}({\mathbf{e}}^{(1)}_{S_{1}};{\mathbf{e}}^{(2)}_{S_{2}};\dots;{\mathbf{e}}^{(B)}_{S_{B}})$.
    Here,
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ${\mathbf{e}}_{S}={\rm Concat}({\mathbf{e}}^{(1)}_{S_{1}};{\mathbf{e}}^{(2)}_{S_{2}};\dots;{\mathbf{e}}^{(B)}_{S_{B}})$。这里，
- en: '|  | $1$2 |  |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  |'
- en: and ${\mathbf{e}}_{S_{k}}^{(k)}$, and 0 otherwise.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 以及 ${\mathbf{e}}_{S_{k}}^{(k)}$，其他情况为 0。
- en: Lemma 1.
  id: totrans-311
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 引理 1。
- en: $\|{\cdot}\|_{\text{top-}\alpha\%}$.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: $\|{\cdot}\|_{\text{top-}\alpha\%}$。
- en: Proof.
  id: totrans-313
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 证明。
- en: 'By Definition [1](#Thmdefn1 "Definition 1\. ‣ Appendix A Proof of Theorem 1
    ‣ MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting in LLM Fine-Tuning"),
    we get'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '根据定义 [1](#Thmdefn1 "Definition 1\. ‣ Appendix A Proof of Theorem 1 ‣ MoFO:
    Momentum-Filtered Optimizer for Mitigating Forgetting in LLM Fine-Tuning")，我们得到'
- en: '|  | $1$2 |  | (1) |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (1) |'
- en: First, if $\|{z}\|_{\text{top-}\alpha\%}=0$. Thus,
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，如果 $\|{z}\|_{\text{top-}\alpha\%}=0$。因此，
- en: '|  | $1$2 |  |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  |'
- en: So $z^{(k)}$ is a zero vector.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 因此 $z^{(k)}$ 是一个零向量。
- en: Second, for any given $c\in\mathbb{R}_{+}$ and $cz$ and
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，对于任何给定的 $c\in\mathbb{R}_{+}$ 和 $cz$ 和
- en: '|  | $1$2 |  |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  |'
- en: Third, for the vectors $x,y\in\mathbb{R}^{d}$, respectively.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，对于向量 $x,y\in\mathbb{R}^{d}$，分别。
- en: '|  | $\displaystyle\&#124;{x+y}\&#124;_{\text{top-}\alpha\%}$ |  |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\&#124;{x+y}\&#124;_{\text{top-}\alpha\%}$ |  |'
- en: '|  |  | $\displaystyle=\&#124;x\odot{\mathbf{e}}_{S^{\prime\prime}}+y\odot{\mathbf{e}}_{S^{\prime\prime}}\&#124;_{2}$
    |  |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=\&#124;x\odot{\mathbf{e}}_{S^{\prime\prime}}+y\odot{\mathbf{e}}_{S^{\prime\prime}}\&#124;_{2}$
    |  |'
- en: '|  |  | $\displaystyle\leq\&#124;x\odot{\mathbf{e}}_{S^{\prime\prime}}\&#124;_{2}+\&#124;y\odot{\mathbf{e}}_{S^{\prime\prime}}\&#124;_{2}$
    |  |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle\leq\&#124;x\odot{\mathbf{e}}_{S^{\prime\prime}}\&#124;_{2}+\&#124;y\odot{\mathbf{e}}_{S^{\prime\prime}}\&#124;_{2}$
    |  |'
- en: '|  |  | $\displaystyle\leq\&#124;x\odot{\mathbf{e}}_{S}\&#124;_{2}+\&#124;y\odot{\mathbf{e}}_{S^{\prime}}\&#124;_{2}$
    |  |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle\leq\&#124;x\odot{\mathbf{e}}_{S}\&#124;_{2}+\&#124;y\odot{\mathbf{e}}_{S^{\prime}}\&#124;_{2}$
    |  |'
- en: '|  |  | $\displaystyle=\&#124;{x}\&#124;_{\text{top-}\alpha\%}+\&#124;{y}\&#124;_{\text{top-}\alpha\%}.$
    |  |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=\&#124;{x}\&#124;_{\text{top-}\alpha\%}+\&#124;{y}\&#124;_{\text{top-}\alpha\%}.$
    |  |'
- en: ∎
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: ∎
- en: 'Proof of Theorem [1](#Thmthm1 "Theorem 1 (Convergence of MoFO). ‣ 2.4 Convergence
    Result ‣ 2 Momentum Filtered Optimizer (MoFO) ‣ MoFO: Momentum-Filtered Optimizer
    for Mitigating Forgetting in LLM Fine-Tuning").'
  id: totrans-328
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '定理 [1](#Thmthm1 "Theorem 1 (Convergence of MoFO). ‣ 2.4 Convergence Result
    ‣ 2 Momentum Filtered Optimizer (MoFO) ‣ MoFO: Momentum-Filtered Optimizer for
    Mitigating Forgetting in LLM Fine-Tuning") 的证明。'
- en: 'By the definition of the simple version of MOFO in Algorithm [2](#alg2 "Algorithm
    2 ‣ 2.4 Convergence Result ‣ 2 Momentum Filtered Optimizer (MoFO) ‣ MoFO: Momentum-Filtered
    Optimizer for Mitigating Forgetting in LLM Fine-Tuning"), we have'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '根据算法 [2](#alg2 "Algorithm 2 ‣ 2.4 Convergence Result ‣ 2 Momentum Filtered
    Optimizer (MoFO) ‣ MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting
    in LLM Fine-Tuning") 中 MOFO 的简单版本定义，我们有'
- en: '|  | $\Theta_{t+1}-\Theta_{t}=-\eta_{t}\hat{m}_{t}\odot\texttt{FILTER}_{t}=-\eta_{t}g_{t}\odot\texttt{FILTER}_{t},$
    |  |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '|  | $\Theta_{t+1}-\Theta_{t}=-\eta_{t}\hat{m}_{t}\odot\texttt{FILTER}_{t}=-\eta_{t}g_{t}\odot\texttt{FILTER}_{t},$
    |  |'
- en: 'where $\texttt{FILTER}_{t}$ in Definition [1](#Thmdefn1 "Definition 1\. ‣ Appendix
    A Proof of Theorem 1 ‣ MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting
    in LLM Fine-Tuning").'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '其中定义 [1](#Thmdefn1 "Definition 1\. ‣ Appendix A Proof of Theorem 1 ‣ MoFO:
    Momentum-Filtered Optimizer for Mitigating Forgetting in LLM Fine-Tuning") 中的
    $\texttt{FILTER}_{t}$。'
- en: By the Lipschitz condition of $\nabla\cal{L}$, we have
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 $\nabla\cal{L}$ 的 Lipschitz 条件，我们有
- en: '|  | $\displaystyle{\mathcal{L}}(\Theta_{t+1})$ |  |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle{\mathcal{L}}(\Theta_{t+1})$ |  |'
- en: '|  |  | $1$2 |  |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $1$2 |  |'
- en: '|  |  | $1$2 |  |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $1$2 |  |'
- en: '|  |  | $\displaystyle\leq{\mathcal{L}}(\Theta_{t})-\frac{1}{2L}\&#124;{g_{t}}\&#124;_{\text{top-}\alpha\%}^{2},$
    |  |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle\leq{\mathcal{L}}(\Theta_{t})-\frac{1}{2L}\&#124;{g_{t}}\&#124;_{\text{top-}\alpha\%}^{2},$
    |  |'
- en: where the second inequality becomes an equality if the learning rate $\alpha=1/L$.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 当学习率 $\alpha=1/L$ 时，第二个不等式变为等式。
- en: Thus, we conclude that
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们得出结论
- en: '|  | $1$2 |  |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  |'
- en: ∎
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: ∎
- en: Appendix B Implementation Details
  id: totrans-341
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 实现细节
- en: Instruction fine-tuning. In our instruction fine-tuning experiments, we follow
    the implementation of Ivison et al. [[2023](#bib.bib30)]. The learning rate is
    set to 2e-5 with a cosine decay scheduler. For fine-tuning on the MetaMathQA dataset,
    we set the maximum sequence length to 1024, the batch size to 128, and we train
    the Llama-2-7B for 2 epochs. The parameter update fraction for MoFO is set to
    $15\%$, while keeping other settings the same.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 指令微调。在我们的指令微调实验中，我们遵循了 Ivison 等人的实现 [[2023](#bib.bib30)]。学习率设置为 2e-5，并使用余弦衰减调度器。对于
    MetaMathQA 数据集的微调，我们将最大序列长度设置为 1024，批次大小为 128，并训练 Llama-2-7B 2 个周期。MoFO 的参数更新比例设置为
    $15\%$，同时保持其他设置不变。
- en: 'Continual fine-tuning. In our continual fine-tuning experiments, we follow
    the default settings of the TRACE benchmark. We sequentially train TinyLlama-1.1B
    on the TRACE benchmark datasets: C-STANCE, FOMC, MeetingBank, Py150, ScienceQA,
    NumGLUE-cm, NumGLUE-ds, and 20Minuten for 5, 3, 7, 5, 3, 5, 5, and 7 epochs, respectively.
    We use a learning rate of 1e-5 with a cosine decay schedule and a batch size of
    64\. The parameter update fraction for MoFO is set to $5\%$.'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 持续微调。在我们的持续微调实验中，我们遵循 TRACE 基准测试的默认设置。我们依次在 TRACE 基准测试数据集上训练 TinyLlama-1.1B：C-STANCE、FOMC、MeetingBank、Py150、ScienceQA、NumGLUE-cm、NumGLUE-ds
    和 20Minuten，分别训练 5、3、7、5、3、5、5 和 7 个周期。我们使用学习率 1e-5，采用余弦衰减计划和 64 的批量大小。MoFO 的参数更新比例设置为
    $5\%$。
- en: All experiments are conducted on four A800 (80GB) GPUs.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 所有实验均在四台 A800（80GB）GPU 上进行。
