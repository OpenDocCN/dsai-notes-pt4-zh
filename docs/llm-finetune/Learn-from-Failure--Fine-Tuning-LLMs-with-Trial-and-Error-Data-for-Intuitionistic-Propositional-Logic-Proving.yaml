- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:37:55'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:37:55
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Learn from Failure: Fine-Tuning LLMs with Trial-and-Error Data for Intuitionistic
    Propositional Logic Proving'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从失败中学习：使用试错数据微调大型语言模型以进行直觉主义命题逻辑证明
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2404.07382](https://ar5iv.labs.arxiv.org/html/2404.07382)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2404.07382](https://ar5iv.labs.arxiv.org/html/2404.07382)
- en: 'Chenyang An¹, Zhibo Chen²¹¹footnotemark: 1, Qihao Ye¹, Emily First¹, Letian
    Peng¹'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 陈阳安¹，陈志博²¹¹注释标记：1，叶启浩¹，艾米莉·费斯特¹，雷天鹏¹
- en: 'Jiayun Zhang¹, Zihan Wang¹, Sorin Lerner¹²²footnotemark: 2, Jingbo Shang¹²²footnotemark:
    2'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 张佳韵¹，王子涵¹，索林·勒纳¹²²注释标记：2，尚晶博¹²²注释标记：2
- en: University of California, San Diego¹  Carnegie Mellon University² {c5an, q8ye,
    emfirst, lepeng, jiz069, ziw224, lerner, jshang}@ucsd.edu
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 加州大学圣地亚哥分校¹  卡内基梅隆大学² {c5an, q8ye, emfirst, lepeng, jiz069, ziw224, lerner,
    jshang}@ucsd.edu
- en: zhiboc@andrew.cmu.edu    The first two authors contributed equally to this work.  
    Corresponding authors.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: zhiboc@andrew.cmu.edu    前两位作者对本工作贡献相同。   通讯作者。
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Recent advances in Automated Theorem Proving have shown the effectiveness of
    leveraging a (large) language model that generates tactics (i.e. proof steps)
    to search through proof states. The current model, while trained solely on successful
    proof paths, faces a discrepancy at the inference stage, as it must sample and
    try various tactics at each proof state until finding success, unlike its training
    which does not incorporate learning from failed attempts. Intuitively, a tactic
    that leads to a failed search path would indicate that similar tactics should
    receive less attention during the following trials. In this paper, we demonstrate
    the benefit of training models that additionally learn from failed search paths.
    Facing the lack of such trial-and-error data in existing open-source theorem-proving
    datasets, we curate a dataset on intuitionistic propositional logic theorems and
    formalize it in Lean, such that we can reliably check the correctness of proofs.
    We compare our model trained on relatively short trial-and-error information (TrialMaster)
    with models trained only on the correct paths and discover that the former solves
    more unseen theorems with lower trial searches.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 最近在自动定理证明方面的进展已经显示出利用生成战术（即证明步骤）的（大型）语言模型在搜索证明状态中的有效性。目前的模型虽然仅在成功的证明路径上进行训练，但在推理阶段却存在差异，因为它必须在每个证明状态下采样并尝试各种战术，直到找到成功的路径，而训练时则没有纳入从失败尝试中学习的过程。直观地说，导致失败搜索路径的战术表明在随后的尝试中应给予类似战术更少的关注。在本文中，我们展示了训练模型时额外从失败的搜索路径中学习的好处。面对现有开源定理证明数据集中缺乏这种试错数据的问题，我们策划了一个关于直觉主义命题逻辑定理的数据集，并在Lean中对其进行了形式化，以便我们可以可靠地检查证明的正确性。我们将基于相对较短试错信息训练的模型（TrialMaster）与仅在正确路径上训练的模型进行比较，发现前者以更低的试错搜索量解决了更多未见过的定理。
- en: \newunicodechar
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: \newunicodechar
- en: ∧$\land$
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ∧$\land$
- en: 'Learn from Failure: Fine-Tuning LLMs with Trial-and-Error Data for Intuitionistic
    Propositional Logic Proving'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 从失败中学习：使用试错数据微调大型语言模型以进行直觉主义命题逻辑证明
- en: 'Chenyang An¹^†^†thanks:    The first two authors contributed equally to this
    work., Zhibo Chen²¹¹footnotemark: 1, Qihao Ye¹, Emily First¹, Letian Peng¹ Jiayun
    Zhang¹, Zihan Wang¹^†^†thanks:    Corresponding authors., Sorin Lerner¹²²footnotemark:
    2, Jingbo Shang¹²²footnotemark: 2 University of California, San Diego¹  Carnegie
    Mellon University² {c5an, q8ye, emfirst, lepeng, jiz069, ziw224, lerner, jshang}@ucsd.edu
    zhiboc@andrew.cmu.edu'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 陈阳安¹^†^†感谢：前两位作者对本工作贡献相同。，陈志博²¹¹注释标记：1，叶启浩¹，艾米莉·费斯特¹，雷天鹏¹ 张佳韵¹，王子涵¹^†^†感谢：通讯作者。，索林·勒纳¹²²注释标记：2，尚晶博¹²²注释标记：2
    加州大学圣地亚哥分校¹  卡内基梅隆大学² {c5an, q8ye, emfirst, lepeng, jiz069, ziw224, lerner, jshang}@ucsd.edu
    zhiboc@andrew.cmu.edu
- en: 1 Introduction
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Automated Theorem Proving is a challenging task that has recently gained popularity
    in the machine-learning community. Researchers build *neural theorem provers*
    to synthesize formal proofs of mathematical theorems Yang et al. ([2023](#bib.bib49));
    Welleck et al. ([2021](#bib.bib46)); Lample et al. ([2022](#bib.bib22)); Mikuła
    et al. ([2023](#bib.bib27)); Wang et al. ([2023](#bib.bib41)); Bansal et al. ([2019](#bib.bib3));
    Davies et al. ([2021](#bib.bib10)); Wu et al. ([2021](#bib.bib48)); Rabe et al.
    ([2020](#bib.bib32)); Kusumoto et al. ([2018](#bib.bib20)); Bansal et al. ([2019](#bib.bib3));
    Irving et al. ([2016](#bib.bib18)). Typically, a neural theorem prover, given
    a partial proof and the current *proof state*, uses a neural model to predict
    the next likely *proof step*, or *tactics*. The neural models utilize different
    architectures like LSTMs Sekiyama et al. ([2017](#bib.bib35)), CNNs Irving et al.
    ([2016](#bib.bib18)), DNNs Sekiyama and Suenaga ([2018](#bib.bib36)), GNNs Bansal
    et al. ([2019](#bib.bib3)); Wang et al. ([2017](#bib.bib43)) and RNNs Wang and
    Deng ([2020](#bib.bib42)), though most recent work has begun to explore the use
    of transformer-based large language models (LLMs) due to their emerging reasoning
    abilities.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 自动定理证明是一个具有挑战性的任务，最近在机器学习领域获得了广泛关注。研究人员构建了*神经定理证明器*来合成数学定理的正式证明 Yang et al.
    ([2023](#bib.bib49))；Welleck et al. ([2021](#bib.bib46))；Lample et al. ([2022](#bib.bib22))；Mikuła
    et al. ([2023](#bib.bib27))；Wang et al. ([2023](#bib.bib41))；Bansal et al. ([2019](#bib.bib3))；Davies
    et al. ([2021](#bib.bib10))；Wu et al. ([2021](#bib.bib48))；Rabe et al. ([2020](#bib.bib32))；Kusumoto
    et al. ([2018](#bib.bib20))；Bansal et al. ([2019](#bib.bib3))；Irving et al. ([2016](#bib.bib18))。通常，给定一个部分证明和当前的*证明状态*，神经定理证明器会使用神经模型预测下一个可能的*证明步骤*或*战术*。这些神经模型使用不同的架构，如
    LSTMs Sekiyama et al. ([2017](#bib.bib35))，CNNs Irving et al. ([2016](#bib.bib18))，DNNs
    Sekiyama 和 Suenaga ([2018](#bib.bib36))，GNNs Bansal et al. ([2019](#bib.bib3))；Wang
    et al. ([2017](#bib.bib43)) 和 RNNs Wang 和 Deng ([2020](#bib.bib42))，尽管最近的工作开始探索基于变换器的大型语言模型（LLMs），因为它们的新兴推理能力。
- en: '![Refer to caption](img/0bab0421562459d9530251d9d38e83ce.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0bab0421562459d9530251d9d38e83ce.png)'
- en: 'Figure 1: A simple example for how learning trial-and-error data impacts inference
    distribution.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：一个简单示例，说明学习试错数据如何影响推理分布。
- en: 'An interactive *proof assistant*, such as Lean de Moura et al. ([2015](#bib.bib12)),
    Coq Barras et al. ([1997](#bib.bib4)) or Isabelle Nipkow et al. ([2002](#bib.bib29)),
    evaluates the model’s predicted candidate proof steps, returning either new proof
    states or errors. Neural theorem provers iterate on this procedure, performing
    *proof search*, e.g., a depth-first search (DFS), to traverse the space of possible
    proofs. An example of a DFS proof search is illustrated in Figure [2(a)](#S1.F2.sf1
    "Figure 2(a) ‣ Figure 2 ‣ 1 Introduction ‣ Learn from Failure: Fine-Tuning LLMs
    with Trial-and-Error Data for Intuitionistic Propositional Logic Proving"), where
    the prover progressively generates new tactics if the attempted tactics result
    in incorrect proofs.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '一个交互式的*证明助手*，例如 Lean de Moura et al. ([2015](#bib.bib12))、Coq Barras et al.
    ([1997](#bib.bib4)) 或 Isabelle Nipkow et al. ([2002](#bib.bib29))，会评估模型预测的候选证明步骤，并返回新的证明状态或错误。神经定理证明器在这个过程中进行迭代，执行*证明搜索*，例如深度优先搜索（DFS），以遍历可能的证明空间。图[2(a)](#S1.F2.sf1
    "Figure 2(a) ‣ Figure 2 ‣ 1 Introduction ‣ Learn from Failure: Fine-Tuning LLMs
    with Trial-and-Error Data for Intuitionistic Propositional Logic Proving")中展示了一个DFS证明搜索的示例，其中如果尝试的战术导致错误证明，证明器会逐步生成新的战术。'
- en: 'Such provers are usually trained on a dataset containing only the correct proof
    paths. This, however, presents a limitation: during inference, the prover does
    not have the ability to leverage the already failed paths it explored. Such failure
    information, intuitively, is beneficial, as it could suggest the model to generate
    tactics similar to the failed ones sparingly. At the very least, the failure information
    should help the model easily avoid generating already failed tactics. See Figure [1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ Learn from Failure: Fine-Tuning LLMs with Trial-and-Error
    Data for Intuitionistic Propositional Logic Proving").'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '这些证明器通常在仅包含正确证明路径的数据集上进行训练。然而，这存在一个限制：在推理过程中，证明器无法利用其已经探索过的失败路径。这些失败信息直观上是有益的，因为它可以建议模型生成类似于失败战术的战术。至少，失败信息应该帮助模型轻松避免生成已经失败的战术。见图[1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ Learn from Failure: Fine-Tuning LLMs with Trial-and-Error
    Data for Intuitionistic Propositional Logic Proving")。'
- en: 'In this paper, we wish to empirically verify this intuition. To conduct the
    experiment, we would compare the conventional model trained on correct proof paths,
    and TrialMaster, the model trained on the whole proof tree, containing both correct
    paths and incorrect paths. See Figure  [2(b)](#S1.F2.sf2 "Figure 2(b) ‣ Figure
    2 ‣ 1 Introduction ‣ Learn from Failure: Fine-Tuning LLMs with Trial-and-Error
    Data for Intuitionistic Propositional Logic Proving"). As such, TrialMaster can
    make predictions based on the failure information during inference time.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们希望通过实证验证这一直观结论。为了进行实验，我们将比较在正确证明路径上训练的传统模型和在包含正确路径和错误路径的完整证明树上训练的TrialMaster模型。见图
    [2(b)](#S1.F2.sf2 "图 2(b) ‣ 图 2 ‣ 1 引言 ‣ 从失败中学习：利用试错数据微调LLM以进行直观命题逻辑证明")。因此，TrialMaster可以在推理时基于失败信息进行预测。
- en: Since current open-source Automated Theorem Proving datasets do not contain
    complete proof trees, we create such a dataset, PropL, written in Lean. We focus
    on theorems of intuitionistic propositional logic. A simple example of an intuitionistic
    propositional logic theorem and its proof in Lean is shown below. The first line
    is the theorem statement, and the second and third lines are tactics that solve
    the theorem.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 由于当前的开源自动定理证明数据集不包含完整的证明树，我们创建了这样的数据集PropL，使用Lean编写。我们专注于直观命题逻辑定理。下面显示了一个直观命题逻辑定理及其在Lean中的证明示例。第一行是定理陈述，第二和第三行是解决定理的战术。
- en: 'theorem  thm  :  p  &$\rightarrow$&  p  :=  byintro  hexact  h'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '定理 thm  :  p  &$\rightarrow$&  p  :=  byintro  hexact  h'
- en: Specifically, our PropL dataset is created through a two-stage process that
    first involves generating a comprehensive set of propositional logic theorems
    by uniformly sampling from all possible theorems, utilizing a bijection between
    natural numbers and propositions to ensure representativeness. Following theorem
    generation, proofs are constructed using a focusing method with polarization,
    incorporating a detailed trial-and-error search process that includes both successful
    and backtracked steps, thereby capturing the complexity and nuances of theorem
    proving in intuitionistic propositional logic. Thus, our dataset is complete,
    scalable, and representative. The proofs in our dataset are combined with trial-and-error
    information, which is generated by the Focused Proof Search (FPS) algorithm McLaughlin
    and Pfenning ([2009](#bib.bib25)); Liang and Miller ([2009](#bib.bib23)); Pfenning
    ([2017](#bib.bib30)).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 具体而言，我们的PropL数据集是通过两阶段过程创建的，首先通过均匀采样生成一套全面的命题逻辑定理，利用自然数和命题之间的双射来确保代表性。定理生成后，使用极化的聚焦方法构建证明，结合详细的试错搜索过程，包括成功步骤和回溯步骤，从而捕捉直观命题逻辑定理证明的复杂性和细微差别。因此，我们的数据集是完整、可扩展且具有代表性的。我们数据集中的证明结合了试错信息，这些信息由Focused
    Proof Search (FPS)算法生成（McLaughlin和Pfenning [2009](#bib.bib25)；Liang和Miller [2009](#bib.bib23)；Pfenning
    [2017](#bib.bib30)）。
- en: We verify the effectiveness of incorporating the failed trials during training
    and inference by experiments on PropL, observing that TrialMaster achieves a higher
    proof search success rate and lower search cost over conventional model trained
    on correct proof paths. Our experiments further indicate that our model can perform
    backtracking without help from an external system.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过对PropL的实验验证了在训练和推理中纳入失败试验的有效性，观察到TrialMaster在证明搜索成功率和搜索成本上优于仅在正确证明路径上训练的传统模型。我们的实验进一步表明，我们的模型可以在没有外部系统帮助的情况下进行回溯。
- en: 'Our main contributions are as follows:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的主要贡献如下：
- en: •
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We establish, PropL, a complete, scalable, and representative benchmark for
    intuitionistic propositional logic theorems formalized in Lean. PropL includes
    proofs with trial-and-error information, generated by the FPS algorithm.
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们建立了PropL，这是一个完整、可扩展且具有代表性的直观命题逻辑定理基准，形式化在Lean中。PropL包含由FPS算法生成的试错信息的证明。
- en: •
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We demonstrate that for intuitionistic propositional logic theorem proving,
    incorporating trial-and-error information into training and proving outperforms
    a conventional model that is trained on correct proofs only.
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们展示了在直观命题逻辑定理证明中，将试错信息纳入训练和证明，比仅在正确证明上训练的传统模型表现更好。
- en: '![Refer to caption](img/e0012de67c35fd60556368e9c5af2841.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e0012de67c35fd60556368e9c5af2841.png)'
- en: (a) Conventional system with depth-first search
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 使用深度优先搜索的传统系统
- en: '![Refer to caption](img/fcac5ad20ef35c6435e08fd8491d3105.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/fcac5ad20ef35c6435e08fd8491d3105.png)'
- en: (b) Our training and inference methodology
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 我们的训练和推理方法
- en: 'Figure 2: Method comparison. (a) A conventional system: The tactic generator
    (i.e., LLM) is fine-tuned on correct proof paths only. During inference, the trained
    tactic generator produces $N_{\text{sampled}}$ (e.g., 2 in the example) tactics
    at a time. If Lean decides that the current tactic is wrong, the system backtracks
    to the last valid state and tries other candidate tactics. (b) Our methodology:
    The tactic generator is fine-tuned on proofs with trial-and-error. During inference,
    we take the first tactic it generates and feed that into Lean for state checking
    at each step.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：方法比较。 (a) 传统系统：战术生成器（即LLM）仅在正确的证明路径上进行微调。在推理过程中，训练后的战术生成器一次生成 $N_{\text{sampled}}$（例如，示例中的
    2）个战术。如果 Lean 判断当前战术错误，系统将回溯到上一个有效状态并尝试其他候选战术。 (b) 我们的方法：战术生成器在通过试错的证明上进行微调。在推理过程中，我们采用其生成的第一个战术，并将其输入
    Lean 进行每一步的状态检查。
- en: 2 Related Work
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: Automated Theorem Proving. Automated Theorem Proving has evolved significantly
    since its inception, focusing mainly on developing computer programs that can
    autonomously prove mathematical theorems. Early ATP systems (mechanical theorem
    proving) were based on first-order logic Clocksin and Mellish ([2003](#bib.bib8));
    Chang and Lee ([2014](#bib.bib6)), where the resolution method Robinson ([1965](#bib.bib33))
    played a crucial role. Recent progress in Automated Theorem Proving has been marked
    by the integration of machine learning Bansal et al. ([2019](#bib.bib3)); Davies
    et al. ([2021](#bib.bib10)); Wagner ([2021](#bib.bib40)), especially LLMs Yang
    et al. ([2023](#bib.bib49)); Polu and Sutskever ([2020](#bib.bib31)); Han et al.
    ([2021](#bib.bib16)); Welleck et al. ([2021](#bib.bib46)); Jiang et al. ([2022](#bib.bib19)),
    and heuristic methods Holden and Korovin ([2021](#bib.bib17)), aimed at amplifying
    the efficiency and capacity of Automated Theorem Proving systems. Within the domain
    of LLMs, formal mathematical languages like Metamath Megill and Wheeler ([2019](#bib.bib26)),
    Lean de Moura et al. ([2015](#bib.bib12)), Isabelle Nipkow et al. ([2002](#bib.bib29)),
    and Coq Barras et al. ([1997](#bib.bib4)), serve as a bridge, enabling the precise
    expression and verification of mathematical theorems and concepts through a computer-verifiable
    format, thereby mitigating hallucination risks Nawaz et al. ([2019](#bib.bib28)).
    COPRA works on incorporating the backtracking information into the prompts and
    sends the prompt to GPT-4 without fine-tuning it to perform proof searching task
    Thakur et al. ([2023](#bib.bib38)). Baldur fine-tuned the LLMs with proofs and
    error information given by the proof assistant First et al. ([2023](#bib.bib13)).
    In contrast, our work focused on fine-tuning the LLMs with the complete past proof
    history without using the error message from the proof assistants.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 自动定理证明。自动定理证明自创立以来发生了显著的发展，主要集中在开发能够自主证明数学定理的计算机程序上。早期的ATP系统（机械定理证明）基于一阶逻辑 Clocksin
    和 Mellish ([2003](#bib.bib8)); Chang 和 Lee ([2014](#bib.bib6))，其中解析方法 Robinson
    ([1965](#bib.bib33)) 起到了关键作用。最近，自动定理证明的进展标志在于机器学习的整合 Bansal 等 ([2019](#bib.bib3));
    Davies 等 ([2021](#bib.bib10)); Wagner ([2021](#bib.bib40))，尤其是LLMs Yang 等 ([2023](#bib.bib49));
    Polu 和 Sutskever ([2020](#bib.bib31)); Han 等 ([2021](#bib.bib16)); Welleck 等 ([2021](#bib.bib46));
    Jiang 等 ([2022](#bib.bib19))，以及启发式方法 Holden 和 Korovin ([2021](#bib.bib17))，旨在提高自动定理证明系统的效率和能力。在LLMs领域，形式化数学语言如
    Metamath Megill 和 Wheeler ([2019](#bib.bib26))，Lean de Moura 等 ([2015](#bib.bib12))，Isabelle
    Nipkow 等 ([2002](#bib.bib29))，和 Coq Barras 等 ([1997](#bib.bib4))，作为桥梁，使得通过计算机可验证格式精确表达和验证数学定理和概念，从而减轻了幻觉风险
    Nawaz 等 ([2019](#bib.bib28))。COPRA 通过将回溯信息纳入提示并将提示发送给 GPT-4 而不进行微调来执行证明搜索任务 Thakur
    等 ([2023](#bib.bib38))。Baldur 对 LLMs 进行了微调，使用由证明助手提供的证明和错误信息 First 等 ([2023](#bib.bib13))。相比之下，我们的工作专注于使用完整的历史证明记录对
    LLMs 进行微调，而没有使用证明助手的错误信息。
- en: Propositional Logic Problem. Early implementations of ATP systems demonstrated
    the potential for computers to automate logical deductions, with notable examples
    including the Logic Theorist Crevier ([1993](#bib.bib9)); McCorduck ([2004](#bib.bib24));
    Russell and Norvig ([2010](#bib.bib34)) and Gilmore’s program Davis ([2001](#bib.bib11));
    Gilmore ([1960](#bib.bib15)). These systems laid the groundwork for the resolution
    of propositional logic problems, showcasing the ability of automated systems to
    handle logical reasoning tasks. Recent advancements in Automated Theorem Proving
    have revisited propositional logic problems, integrating modern computational
    techniques. Sekiyama et al. Sekiyama and Suenaga ([2018](#bib.bib36)) have employed
    Deep Neural Networks (DNNs) as a statistical approach to generate proofs for these
    theorems, while Kusumoto et al. Kusumoto et al. ([2018](#bib.bib20)) have explored
    graph representations coupled with reinforcement learning to find proofs. Furthermore,
    the sequence-to-sequence neural networks have been applied for deriving proof
    terms in intuitionistic propositional logic Sekiyama et al. ([2017](#bib.bib35)).
    This area of research is particularly intriguing due to the simplicity and importance
    of propositional logic in mathematics, and there is a growing interest in evaluating
    the capability of LLMs in tackling this specific mathematical domain.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 命题逻辑问题。早期的ATP系统实现展示了计算机自动化逻辑推理的潜力，著名的例子包括逻辑理论家Crevier ([1993](#bib.bib9)); McCorduck
    ([2004](#bib.bib24)); Russell 和 Norvig ([2010](#bib.bib34)) 以及Gilmore的程序Davis
    ([2001](#bib.bib11)); Gilmore ([1960](#bib.bib15))。这些系统为解决命题逻辑问题奠定了基础，展示了自动化系统处理逻辑推理任务的能力。最近在自动定理证明领域的进展重新审视了命题逻辑问题，整合了现代计算技术。Sekiyama
    等人 Sekiyama 和 Suenaga ([2018](#bib.bib36)) 使用深度神经网络（DNNs）作为统计方法来生成这些定理的证明，而Kusumoto
    等人 Kusumoto 等人 ([2018](#bib.bib20)) 探索了与强化学习结合的图形表示来寻找证明。此外，序列到序列神经网络已经被应用于直觉命题逻辑中的证明术语推导
    Sekiyama 等人 ([2017](#bib.bib35))。这一研究领域尤其引人注目，因为命题逻辑在数学中的简洁性和重要性，且对评估LLMs在解决这一特定数学领域的能力的兴趣日益增长。
- en: Trial-and-Error. The Chain-of-Thought (CoT) Wei et al. ([2022](#bib.bib45));
    Wang et al. ([2022](#bib.bib44)); Zhou et al. ([2022](#bib.bib52)); Fu et al.
    ([2022](#bib.bib14)); Chu et al. ([2023](#bib.bib7)); Yu et al. ([2023](#bib.bib51))
    approach, demonstrates that LLMs can be guided to perform step-by-step reasoning
    by incorporating intermediate reasoning steps in their prompts. This concept is
    expanded in later research, such as the Tree of Thoughts (ToT) Yao et al. ([2023](#bib.bib50)),
    which organizes reasoning into a tree structure, and the Graph of Thoughts (GoT)
    Besta et al. ([2023](#bib.bib5)), which adopts a graph format for thought structuring.
    Trial-and-error complements structured reasoning by allowing the model to empirically
    test hypotheses generated, thereby refining its reasoning process based on feedback
    from interactions or emulations. The Boosting of Thoughts (BoT) Anonymous ([2024](#bib.bib1))
    prompting framework iteratively explores and evaluates multiple trees of thoughts
    to gain trial-and-error reasoning experiences, using error analysis from the LLMs
    to revise the prompt. We posit that teaching models to leverage both structured
    reasoning and trial-and-error methodologies can substantially improve their analytical
    and adaptive capabilities.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 试错法。链式思维（CoT）Wei 等人 ([2022](#bib.bib45)); Wang 等人 ([2022](#bib.bib44)); Zhou
    等人 ([2022](#bib.bib52)); Fu 等人 ([2022](#bib.bib14)); Chu 等人 ([2023](#bib.bib7));
    Yu 等人 ([2023](#bib.bib51)) 的方法表明，通过在提示中融入中间推理步骤，可以引导大语言模型（LLMs）进行逐步推理。这个概念在后续研究中得到扩展，例如思想树（ToT）Yao
    等人 ([2023](#bib.bib50))，它将推理组织成树形结构，以及思想图（GoT）Besta 等人 ([2023](#bib.bib5))，它采用图形格式进行思维结构化。试错法通过允许模型对生成的假设进行实证测试，从而通过与交互或模拟的反馈来改进其推理过程，从而补充结构化推理。思想提升（BoT）Anonymous
    ([2024](#bib.bib1)) 提示框架通过迭代探索和评估多个思想树，以获得试错推理经验，并使用来自LLMs的错误分析来修订提示。我们认为，教会模型利用结构化推理和试错方法可以显著提高其分析和适应能力。
- en: '3 PropL: A New Dataset for Intuitionistic Propositional Logic Theorems in Lean'
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '3 PropL: 一个用于直觉命题逻辑定理的新数据集'
- en: Our aim is to experimentally validate that trial-and-error information can enhance
    models’ ability to do backtracking and tactic generation for theorem-proving tasks.
    Given that existing open-source theorem proving datasets lack information on trial-and-error
    processes, we have developed PropL, which is based on theorems of intuitionistic
    propositional logic. This dataset uniquely includes proofs that encapsulate the
    complete search process, incorporating the trial-and-error data generated by the
    FPS algorithm. Our dataset has two other benefits. It is formalized in Lean, so
    that the validity of the theorems and proofs are guaranteed. The tactics generated
    by the model trained on PropL can also be directly sent to Lean to be checked.
    PropL is also representative of all the intuitionistic propositional logic theorems,
    since by uniformly sampling integers, we can use a bijection between natural numbers
    and propositions to uniformly sample propositions. This bijection is explained
    in the Theorem Generation section.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是通过实验验证试错信息是否能增强模型在定理证明任务中的回溯和战术生成能力。鉴于现有的开源定理证明数据集缺乏试错过程的信息，我们开发了PropL，它基于直觉主义命题逻辑的定理。该数据集独特地包含了封装完整搜索过程的证明，融入了由FPS算法生成的试错数据。我们的数据集还有两个其他好处。它在Lean中进行了形式化，以保证定理和证明的有效性。使用PropL训练的模型生成的战术也可以直接发送到Lean进行检查。PropL也代表了所有的直觉主义命题逻辑定理，因为通过均匀采样整数，我们可以使用自然数和命题之间的双射来均匀采样命题。这个双射在定理生成部分有详细说明。
- en: 3.1 Data Generation of PropL
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 PropL的数据生成
- en: PropL comprises theorems uniformly sampled from the entire set of propositional
    logic theorems. It includes various proof types for each theorem. We only report
    proof types that are used in this paper. For additional information about the
    dataset, please refer to the GitHub repository and Huggingface.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: PropL包含从整个命题逻辑定理集合中均匀采样的定理。它包括每个定理的各种证明类型。我们仅报告本文中使用的证明类型。有关数据集的更多信息，请参阅GitHub存储库和Huggingface。
- en: 'The construction of PropL involves two primary stages: the generation of propositional
    logic theorems and the generation of proofs for these theorems from an existing
    algorithm.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: PropL的构建涉及两个主要阶段：生成命题逻辑定理和从现有算法生成这些定理的证明。
- en: 'Theorem Generation. Consider the set of propositions $A$ can be inductively
    generated by the following grammar:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 定理生成。考虑命题集合$A$可以通过以下文法递归生成：
- en: '|  | $A,B::=P_{i}\mid T\mid F\mid A\land B\mid A\lor B\mid A\to B,$ |  |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '|  | $A,B::=P_{i}\mid T\mid F\mid A\land B\mid A\lor B\mid A\to B,$ |  |'
- en: 'where $P_{i}$, $\lor$ is called an internal node of the proposition. We assign
    the following lexicographic order to propositions:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$P_{i}$, $\lor$被称为命题的内部节点。我们给命题分配以下字典序：
- en: nosep
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: nosep
- en: Number of internal nodes (increasing order)
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 内部节点数（递增顺序）
- en: nosep
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: nosep
- en: Number of internal nodes of the left child (decreasing order)
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 左子节点的内部节点数（递减顺序）
- en: nosep
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: nosep
- en: Top level connective, $T<F<P_{1}<\cdots<P_{p}<\land<\lor<\to$
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 顶层连接符，$T<F<P_{1}<\cdots<P_{p}<\land<\lor<\to$
- en: nosep
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: nosep
- en: The (recursive order (2 - 5)) of the left child
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 左子节点的（递归顺序（2 - 5））
- en: nosep
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: nosep
- en: The (recursive order (2 - 5)) of the right child
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 右子节点的（递归顺序（2 - 5））
- en: 'For a fixed upper bound $p$ for the number of atomic propositions, we establish
    a bijection between the natural numbers and the set of propositional logic formulas.
    The counting can be made efficient using the Catalan Numbers Atkinson and Sack
    ([1992](#bib.bib2)). Figure [3](#S3.F3 "Figure 3 ‣ 3.1 Data Generation of PropL
    ‣ 3 PropL: A New Dataset for Intuitionistic Propositional Logic Theorems in Lean
    ‣ Learn from Failure: Fine-Tuning LLMs with Trial-and-Error Data for Intuitionistic
    Propositional Logic Proving") gives an example of mapping between propositions
    and natural numbers. Details about the encoding and decoding algorithms are provided
    in [Appendix A](#A1 "Appendix A Uniformly Distributed Data Explanation ‣ Learn
    from Failure: Fine-Tuning LLMs with Trial-and-Error Data for Intuitionistic Propositional
    Logic Proving").'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '对于原子命题的固定上界$p$，我们建立了自然数和命题逻辑公式集合之间的双射。使用Catalan Numbers Atkinson和Sack（[1992](#bib.bib2)）可以使计数变得高效。图[3](#S3.F3
    "Figure 3 ‣ 3.1 Data Generation of PropL ‣ 3 PropL: A New Dataset for Intuitionistic
    Propositional Logic Theorems in Lean ‣ Learn from Failure: Fine-Tuning LLMs with
    Trial-and-Error Data for Intuitionistic Propositional Logic Proving")给出了命题和自然数之间映射的示例。有关编码和解码算法的详细信息请参见[附录A](#A1
    "Appendix A Uniformly Distributed Data Explanation ‣ Learn from Failure: Fine-Tuning
    LLMs with Trial-and-Error Data for Intuitionistic Propositional Logic Proving")。'
- en: '![Refer to caption](img/cd758e6a21bc4bd63426dcd0ec53c6f2.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/cd758e6a21bc4bd63426dcd0ec53c6f2.png)'
- en: 'Figure 3: An illustration of the bijection between a proposition and a natural
    number, where gray nodes are leaf nodes. ID is computed using [Algorithm 1](#alg1
    "In Appendix A Uniformly Distributed Data Explanation ‣ Learn from Failure: Fine-Tuning
    LLMs with Trial-and-Error Data for Intuitionistic Propositional Logic Proving")
    with $n=6$ in this case.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '图3：一个命题与自然数之间的双射示意图，其中灰色节点为叶节点。ID使用[算法1](#alg1 "In Appendix A Uniformly Distributed
    Data Explanation ‣ Learn from Failure: Fine-Tuning LLMs with Trial-and-Error Data
    for Intuitionistic Propositional Logic Proving")计算，这里$n=6$。'
- en: 'Proof Generation. Given a randomly sampled theorem, the proof of the theorem
    is constructed using the focusing method with polarization McLaughlin and Pfenning
    ([2009](#bib.bib25)); Liang and Miller ([2009](#bib.bib23)); Pfenning ([2017](#bib.bib30)).
    Proof search is divided into two stages: inversion and chaining. The inversion
    phase mechanically breaks down negative connectives (e.g. implications) in the
    goal and positive connectives (e.g. disjunctions) in the premises. After inversion,
    chaining will pick an implication in the premise or show one of the disjuncts
    in the conclusion, with backtracking. The proof search procedure terminates when
    the same atomic proposition appears in both the premise and the conclusion. An
    example of proof with trial-and-error information (backtracking) and that with
    trial-and-error information removed is shown in Figure [4](#S3.F4 "Figure 4 ‣
    3.2 Construction of Training and Testing Sets ‣ 3 PropL: A New Dataset for Intuitionistic
    Propositional Logic Theorems in Lean ‣ Learn from Failure: Fine-Tuning LLMs with
    Trial-and-Error Data for Intuitionistic Propositional Logic Proving").'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '证明生成。给定一个随机采样的定理，使用极性聚焦方法构建定理的证明，参考McLaughlin和Pfenning（[2009](#bib.bib25)）；Liang和Miller（[2009](#bib.bib23)）；Pfenning（[2017](#bib.bib30)）。证明搜索分为两个阶段：倒转和链式推理。倒转阶段机械地分解目标中的负面连词（例如，蕴含）和前提中的正面连词（例如，析取）。倒转后，链式推理将选择前提中的一个蕴含或显示结论中的一个析取项，并进行回溯。证明搜索过程在前提和结论中出现相同的原子命题时终止。图[4](#S3.F4
    "Figure 4 ‣ 3.2 Construction of Training and Testing Sets ‣ 3 PropL: A New Dataset
    for Intuitionistic Propositional Logic Theorems in Lean ‣ Learn from Failure:
    Fine-Tuning LLMs with Trial-and-Error Data for Intuitionistic Propositional Logic
    Proving")展示了带有试错信息（回溯）和去除试错信息的证明示例。'
- en: Once proofs are generated, we use them to fine-tune models and start the proof
    search on the test set.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦生成了证明，我们使用这些证明来微调模型，并开始在测试集上进行证明搜索。
- en: The polarization of the connectives affects the behavior of the inversion and
    the search procedure. We choose to uniformly polarize conjunctions that occur
    negatively (e.g. on the right-hand side of a sequence) as negative and polarize
    conjunctions that occur positively (e.g. on the left-hand side of an arrow) as
    positive. Atomic propositions are assigned polarities based on the connective
    that they first appear under.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 连词的极性会影响倒转和搜索过程的行为。我们选择将出现于负面位置的联接词（例如，在序列的右侧）统一极性为负面，将出现于正面位置的联接词（例如，在箭头的左侧）统一极性为正面。原子命题的极性基于它们首次出现时的连词来分配。
- en: To improve the runtime of the search procedure, we make an additional assumption
    that once an implication is picked, the implication cannot be used to show its
    premise. In theory, this introduces incompleteness into the search procedure,
    but it only affects 1 theorem out of around 1000 provable theorems randomly sampled.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高搜索过程的运行时间，我们做了一个额外的假设：一旦选择了一个蕴含，该蕴含不能用于显示其前提。理论上，这会引入搜索过程的不完全性，但它只影响大约1000个随机采样的可证明定理中的1个定理。
- en: 3.2 Construction of Training and Testing Sets
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 训练和测试集的构建
- en: In this section, we explain how we construct the datasets for training and evaluation.
    We want to avoid training and testing on similar data. In order to test the model
    performance on harder out-of-distribution (OOD) tasks, we need to ensure that
    the lengths of the proofs in the training data are shorter than the lengths of
    the proofs in the test data.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们解释了如何构建用于训练和评估的数据集。我们希望避免在类似数据上进行训练和测试。为了测试模型在更困难的分布外（OOD）任务上的表现，我们需要确保训练数据中的证明长度短于测试数据中的证明长度。
- en: Given PropL, we fix the number of internal nodes in the theorem statement to
    be 16 (explained in the dataset generation section). We then uniformly randomly
    sample 200,000 theorems from PropL, which can be achieved by using the integer-theorem
    bijection as explained before. Our method ensures that the theorems we study in
    this paper are representative of the propositional logic theorems in general.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 给定PropL，我们将定理陈述中的内部节点数量固定为16（在数据集生成部分解释）。然后，我们从PropL中均匀随机抽取20万个定理，这可以通过使用之前解释的整数-定理双射实现。我们的方法确保本文研究的定理在一般命题逻辑定理中具有代表性。
- en: We first apply our deterministic algorithms to generate the proofs of the 200,000
    theorems, and then remove the trial-and-error information of those proofs. We
    get a word-length distribution of those proofs without trial-and-error information.
    Next, to ensure the diversity of the trial-and-error information, we randomly
    select propositions to focus on during the chaining phase of the proof search,
    and then generate 10 different proofs with backtracking. By using the average
    length of the 10 different proofs, we have another word length distribution of
    proofs with trial-and-error information.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先应用确定性算法生成20万个定理的证明，然后去除这些证明的试错信息。我们得到这些没有试错信息的证明的词长分布。接下来，为了确保试错信息的多样性，我们在证明搜索的链式阶段随机选择命题进行重点处理，然后生成10个不同的证明并进行回溯。通过使用这10个不同证明的平均长度，我们得到了带有试错信息的证明的另一词长分布。
- en: We then split the 200,000 theorems into training and testing sets based on both
    of the word length distributions mentioned above. The word lengths of the proofs
    of the training data theorems fall within the lower 0.66 quantile of the two distributions
    of the word length of all the proofs of the 200,000 theorems (109,887 in total).
    The word lengths of the in-distribution testing also fall in that category (1000
    in total). The word lengths of the proofs among the out-of-distribution testing
    theorems are above 0.8 quantile (1000 total) of the two distributions of the word
    lengths of all the proofs of the 200,000 theorems.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将20万个定理根据上述两种词长分布拆分为训练集和测试集。训练数据定理的证明的词长落在20万个定理的所有证明的词长分布的下0.66分位数内（总计109,887）。在分布内测试的词长也落在该类别中（总计1000）。超出分布测试定理的证明的词长高于20万个定理的所有证明的词长分布的0.8分位数（总计1000）。
- en: '![Refer to caption](img/5e87f5200f6051f9a29b49b3ba6bf459.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/5e87f5200f6051f9a29b49b3ba6bf459.png)'
- en: 'Figure 4: Two proofs for one propositional logic theorem with tactics and states
    in Lean.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：在Lean中带有战术和状态的一个命题逻辑定理的两个证明。
- en: 4 Methodology
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 方法论
- en: 4.1 LLM Fine-Tuning
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 LLM 微调
- en: 'We utilize the training set formed in PropL for training both TrialMaster and
    the tactic generator in the DFS system. The numbers of theorems used in the training
    and testing datasets are presented in Table [1](#S4.T1 "Table 1 ‣ 4.1 LLM Fine-Tuning
    ‣ 4 Methodology ‣ Learn from Failure: Fine-Tuning LLMs with Trial-and-Error Data
    for Intuitionistic Propositional Logic Proving").'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们利用在PropL中形成的训练集来训练DFS系统中的TrialMaster和战术生成器。训练和测试数据集中使用的定理数量见表 [1](#S4.T1 "表
    1 ‣ 4.1 LLM 微调 ‣ 4 方法论 ‣ 从失败中学习：利用试错数据对LLM进行微调以进行直觉命题逻辑证明")。
- en: 'LLM fine-tuning with trial-and-error. In our approach, we randomly select two
    out of the shortest five among the ten proofs with trial-and-error information
    for each theorem in the training set and utilize them to train TrialMaster. Refer
    to Figure [2(b)](#S1.F2.sf2 "Figure 2(b) ‣ Figure 2 ‣ 1 Introduction ‣ Learn from
    Failure: Fine-Tuning LLMs with Trial-and-Error Data for Intuitionistic Propositional
    Logic Proving") describes this training process.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 通过试错法对LLM进行微调。在我们的方法中，我们从训练集中的每个定理的10个证明中随机选择最短的5个中的两个，并利用它们来训练TrialMaster。有关此训练过程的详细描述，请参见图 [2(b)](#S1.F2.sf2
    "图 2(b) ‣ 图 2 ‣ 1 介绍 ‣ 从失败中学习：利用试错数据对LLM进行微调以进行直觉命题逻辑证明")。
- en: 'LLM fine-tuning in a DFS system. For the tactic generator of the DFS system,
    we employ the deterministic FPS algorithm to generate the proofs of the theorems
    in the training set. The trial-and-error information is removed from the proofs.
    The LLM is then fine-tuned on the proofs without trial-and-error information as
    the conventional methods do. Figure [2(a)](#S1.F2.sf1 "Figure 2(a) ‣ Figure 2
    ‣ 1 Introduction ‣ Learn from Failure: Fine-Tuning LLMs with Trial-and-Error Data
    for Intuitionistic Propositional Logic Proving") illustrates the training process
    of the DFS system.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '在 DFS 系统中的 LLM 微调。对于 DFS 系统的策略生成器，我们采用确定性 FPS 算法来生成训练集中的定理证明。证明中删除了试错信息。然后，LLM
    在没有试错信息的证明上进行微调，类似于传统方法。图 [2(a)](#S1.F2.sf1 "Figure 2(a) ‣ Figure 2 ‣ 1 Introduction
    ‣ Learn from Failure: Fine-Tuning LLMs with Trial-and-Error Data for Intuitionistic
    Propositional Logic Proving") 展示了 DFS 系统的训练过程。'
- en: 'Table 1: The scale of training and testing split in our PropL dataset.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：我们 PropL 数据集中训练和测试划分的规模。
- en: '| Subset | Number of theorems |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 子集 | 定理数量 |'
- en: '| --- | --- |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Training | 109,887 |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 训练 | 109,887 |'
- en: '| In-dist. testing | 1,000 |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 领域外测试 | 1,000 |'
- en: '| Out-of-dist. testing | 1,000 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 领域外测试 | 1,000 |'
- en: 4.2 Inference
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 推理
- en: 'Inference method of model trained with trial-and-error. TrialMaster conducts
    inference on itself without any help from a backtracking system like DFS or BFS.
    It outputs two kinds of tactics: tactics in Lean and backtrack instruction. An
    example of a backtrack instruction would be like “no solution, return to state
    2 [that leads to state 4]”, where state 4 is the current state. When TrialMaster
    is doing a proof search on the test set, it is prompted with all history paths,
    including previous tactics, states, the backtracking it made before, and the failed
    search path. It then outputs the entire proof path after. Nonetheless, we only
    utilize the first tactic in the output and employ Lean as a calculator to determine
    the next state, thereby ensuring the correctness of the state following the tactic.
    If the tactic output by TrialMaster is a backtrack instruction, it is then prompted
    with all the proof search history including the backtrack instruction and the
    state that the backtrack instruction instructs to return to. If that tactic is
    not a backtrack instruction, the tactic and the current state will be fed into
    Lean for producing the state after. TrialMaster is then prompted with the entire
    proof tree including the state that Lean calculated, and it should output a tactic
    again. This process is repeated until Lean identifies that the proof is complete
    or any Lean error occurs. We also note that TrialMaster only outputs one tactic
    at each state using greedy search.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 使用试错法训练的模型的推理方法。TrialMaster 在没有像 DFS 或 BFS 这样的回溯系统帮助的情况下对自身进行推理。它输出两种策略：Lean
    中的策略和回溯指令。回溯指令的一个例子是“没有解决方案，返回到状态 2 [指向状态 4]”，其中状态 4 是当前状态。当 TrialMaster 在测试集上进行证明搜索时，它会提供所有历史路径，包括之前的策略、状态、之前的回溯以及失败的搜索路径。然后，它会输出整个证明路径。不过，我们只使用输出中的第一个策略，并且利用
    Lean 作为计算器来确定下一状态，从而确保策略后的状态是正确的。如果 TrialMaster 输出的策略是回溯指令，则它会提供所有证明搜索历史，包括回溯指令以及回溯指令指示返回的状态。如果策略不是回溯指令，则策略和当前状态将被输入
    Lean 以生成之后的状态。TrialMaster 随后会被提供包括 Lean 计算出的状态在内的整个证明树，并且它应该再次输出一个策略。这个过程会重复进行，直到
    Lean 确定证明完成或发生任何 Lean 错误。我们还注意到，TrialMaster 在每个状态下只输出一个策略，使用贪婪搜索。
- en: 'Inference method of the DFS system. There are two hyperparameters in the DFS
    system: temperature $t$ increases, the outputs of the model become more varied.
    The second parameter determines how many tactics the tactic generator of the DFS
    system produces for a new proof state.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: DFS 系统的推理方法。DFS 系统中有两个超参数：温度 $t$ 增加时，模型的输出变得更加多样。第二个参数决定了 DFS 系统的策略生成器为新的证明状态生成多少种策略。
- en: 'During inference, the LLM in the DFS system produces $N_{\text{sampled}}$ of
    candidate tactics at each new state. For each proof state, the DFS only makes
    one inference. If any two of the generated tactics for the same state are the
    same, we remove one of them to ensure efficiency. We also remove the tactic suggestions
    that fail to follow the grammar of Lean. The system follows the depth-first order
    to keep trying untried tactics. If the system exhausts all the tactics for a given
    state but has not found a valid one, the system returns to the parent state and
    then keeps trying untried tactics for the parent state. The overview is presented
    in the [Figure 2(a)](#S1.F2.sf1 "In Figure 2 ‣ 1 Introduction ‣ Learn from Failure:
    Fine-Tuning LLMs with Trial-and-Error Data for Intuitionistic Propositional Logic
    Proving").'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在推理过程中，DFS系统中的LLM在每个新状态下生成 $N_{\text{sampled}}$ 个候选策略。对于每个证明状态，DFS仅进行一次推理。如果生成的策略中有两个相同的，我们会去掉其中一个以确保效率。我们还去掉不符合Lean语法的策略建议。系统遵循深度优先顺序，继续尝试未尝试过的策略。如果系统对给定状态耗尽所有策略但未找到有效策略，系统会返回到父状态，然后继续尝试父状态的未尝试策略。概览见[图2(a)](#S1.F2.sf1
    "在图2 ‣ 1 引言 ‣ 从失败中学习：通过试错数据对LLM进行微调以进行直观命题逻辑证明")。
- en: To fully exploit the ability of the DFS system, we varied the parameters of
    it, such as temperature and the number of sampled tactics. We count how many times
    Lean has been called to check tactics for both the DFS system and TrialMaster
    during the inference stage.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 为了充分利用DFS系统的能力，我们改变了它的参数，如温度和采样策略的数量。我们统计了在推理阶段，Lean检查策略的次数，包括DFS系统和TrialMaster。
- en: Why do we choose DFS over BFS?
  id: totrans-89
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 为什么我们选择DFS而不是BFS？
- en: While the Breadth-First-Search (BFS) system is also popular for building neural
    provers in Automated Theorem Proving, we have opted for DFS as our baseline over
    BFS in the context of propositional logic theorem proving. This is due to the
    finite number (around 20) of tactics available at any step for the search process
    of intuitionistic propositional logic theorems, making DFS more efficient than
    BFS without compromising the success rate.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然广度优先搜索（BFS）系统在自动定理证明中也很受欢迎，但我们在命题逻辑定理证明的背景下选择了深度优先搜索（DFS）作为基准。因为在任何步骤中可用的策略数量（约20）是有限的，使得DFS比BFS更有效，而不会影响成功率。
- en: 5 Evaluation
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 评估
- en: 5.1 Experiment setup
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 实验设置
- en: Base LLM. We used Llama-2-7b-hf Touvron et al. ([2023](#bib.bib39)) as the backbone
    LLM for tactic generation. Models are trained on two A100 GPUs for a single epoch
    with batch size set to $4$.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 基础LLM。我们使用了Llama-2-7b-hf Touvron et al. ([2023](#bib.bib39)) 作为策略生成的核心LLM。模型在两台A100
    GPU上训练一个周期，批量大小设置为 $4$。
- en: Hyperparameters. In the experiment, we vary temperature $t$. We notice that
    in all experiments for temperature $t$=20, $N_{\text{Lean}}$ climbs up to 32171
    when the number of total steps reaches 65\. Therefore, in our experiment, we set
    65 as the search step limit to control time complexity.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数。在实验中，我们改变了温度 $t$。我们注意到，在所有温度 $t$=20 的实验中，当总步骤数达到65时，$N_{\text{Lean}}$ 上升到32171。因此，在我们的实验中，我们将65设置为搜索步骤限制以控制时间复杂度。
- en: '![Refer to caption](img/af8c44db5d1b17af29d4b57a60ce5cd3.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/af8c44db5d1b17af29d4b57a60ce5cd3.png)'
- en: (a) Temperature $t$
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 温度 $t$
- en: '![Refer to caption](img/413b3dc98988411fa4130d560d1e4a7a.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/413b3dc98988411fa4130d560d1e4a7a.png)'
- en: (b) Sampled Tactics $N_{\text{sampled}}$
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 采样策略 $N_{\text{sampled}}$
- en: '![Refer to caption](img/aadaff3bc06c0f068d6683259029c075.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/aadaff3bc06c0f068d6683259029c075.png)'
- en: (c) Search Cost
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 搜索成本
- en: 'Figure 5: Experiment results on OOD task. (a) We fix $N_{\text{sampled}}=10$
    among our method and top 3 DFS systems with the highest success rate. In summary,
    training with trail-and-error achieves a higher success rate with a relatively
    lower search cost compared to the DFS systems.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：OOD任务的实验结果。(a) 我们在我们的方法和成功率最高的前3个DFS系统中固定 $N_{\text{sampled}}=10$。总的来说，与DFS系统相比，使用试错训练实现了更高的成功率和相对较低的搜索成本。
- en: 5.2 Evaluation Metrics
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 评估指标
- en: 'Proof search success rate. We use proof search success rate as our primary
    metric, which represents the ratio of successful searches by the model. A search
    attempt for a theorem is marked as successful if Lean outputs state “no goal,
    the proof is complete”, implying the theorem is effectively proved after applying
    a tactic produced by the model. For TrialMaster, a search attempt ends and fails
    immediately after one of the following conditions: 1) the word length of the proof
    tree with trial-and-error exceeds $1500$ (for the sake of context length of the
    model), or 2) the tactic produced by the model at any step induces a Lean error.
    For the conventional DFS system, a search attempt fails when one of the following
    conditions happens: 1) the word length of the proof tree without trial-and-error
    exceeds 1500, or 2) all tactics generated for the initial states have been explored
    and failed, or 3) the total search steps exceed 65 (see Section [5.1](#S5.SS1
    "5.1 Experiment setup ‣ 5 Evaluation ‣ Learn from Failure: Fine-Tuning LLMs with
    Trial-and-Error Data for Intuitionistic Propositional Logic Proving") for the
    choice of this value). We note that the 1500-word limit is stricter for our method
    since it produces entire proof paths including trial-and-error and thus would
    be easier to hit the limit.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 证明搜索成功率。我们使用证明搜索成功率作为我们的主要度量，它表示模型成功搜索的比例。如果 Lean 输出状态为“没有目标，证明已完成”，则将对定理的搜索尝试标记为成功，这意味着在应用模型生成的战术后定理被有效证明。对于
    TrialMaster，如果搜索尝试满足以下条件之一，则结束并立即失败：1）试错的证明树的字数超过 $1500$（为了模型的上下文长度），或 2）模型在任何步骤生成的战术引发了
    Lean 错误。对于传统的 DFS 系统，当发生以下情况之一时，搜索尝试失败：1）没有试错的证明树的字数超过 1500，或 2）对初始状态生成的所有战术都已被探索并失败，或
    3）总搜索步骤超过 65（请参见第 [5.1](#S5.SS1 "5.1 实验设置 ‣ 5 评估 ‣ 从失败中学习：通过试错数据微调 LLMs 以证明直觉命题逻辑")
    节以了解该值的选择）。我们注意到，1500 字的限制对我们的方法来说更严格，因为它产生整个证明路径，包括试错，因此更容易达到限制。
- en: Search cost. We define a metric to assess the search cost—the total number of
    Lean calls for tactic checking during proof searching for the entire testing set,
    denoted as $N_{\text{Lean}}$ indicates a more efficient system for proof searching.
    Note that backtracking instructions from our method do not require to apply Lean
    to check the state and, consequently do not add search cost.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索成本。我们定义了一个度量来评估搜索成本——整个测试集在证明搜索期间进行战术检查的 Lean 调用总数，用 $N_{\text{Lean}}$ 表示，这表明系统在证明搜索中更为高效。请注意，我们的方法中的回溯指令不需要应用
    Lean 来检查状态，因此不会增加搜索成本。
- en: 'Table 2: Performance on in-distribution task. Both methods perform well for
    propositional logic.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：在分布内任务上的表现。这两种方法在命题逻辑上表现良好。
- en: '| Model | Success Rate |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 成功率 |'
- en: '| --- | --- |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| TrialMaster | 100% |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| TrialMaster | 100% |'
- en: '| --- | --- |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| DFS | $t=1.2$ | 99.5% |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| DFS | $t=1.2$ | 99.5% |'
- en: '| $N_{\text{sampled}}=5$ | 99.9% |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| $N_{\text{sampled}}=5$ | 99.9% |'
- en: '| $N_{\text{sampled}}=10$ | 99.6% |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| $N_{\text{sampled}}=10$ | 99.6% |'
- en: '| $t=2.0$ | 75.9% |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| $t=2.0$ | 75.9% |'
- en: '| $N_{\text{sampled}}=5$ | 97.3% |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| $N_{\text{sampled}}=5$ | 97.3% |'
- en: '| $N_{\text{sampled}}=10$ | 99.0% |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| $N_{\text{sampled}}=10$ | 99.0% |'
- en: 5.3 Results and Analysis
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 结果与分析
- en: 'TrialMaster outperforms conventional DFS system. We begin by evaluating the
    methods of the in-distribution testing set. Table [2](#S5.T2 "Table 2 ‣ 5.2 Evaluation
    Metrics ‣ 5 Evaluation ‣ Learn from Failure: Fine-Tuning LLMs with Trial-and-Error
    Data for Intuitionistic Propositional Logic Proving") illustrates that both our
    method and the DFS system perform exceptionally well, achieving a success rate
    of nearly 100% in most configurations. This suggests that Llama-7b effectively
    masters in-distribution intuitionistic propositional logic theorems. Then, we
    compare the performance of the methods on the out-of-distribution task. The results
    are presented in [Figure 5](#S5.F5 "In 5.1 Experiment setup ‣ 5 Evaluation ‣ Learn
    from Failure: Fine-Tuning LLMs with Trial-and-Error Data for Intuitionistic Propositional
    Logic Proving"). Our method with trial-and-error significantly outperforms the
    DFS system across various hyperparameter configurations. Additionally, we observe
    that feeding more proofs without trial-and-error for LLM fine-tuning does not
    further improve the performance.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 'TrialMaster优于传统DFS系统。我们首先评估了在分布内测试集上的方法。表[2](#S5.T2 "Table 2 ‣ 5.2 Evaluation
    Metrics ‣ 5 Evaluation ‣ Learn from Failure: Fine-Tuning LLMs with Trial-and-Error
    Data for Intuitionistic Propositional Logic Proving")显示，我们的方法和DFS系统在大多数配置中表现优异，成功率接近100%。这表明Llama-7b有效地掌握了分布内的直觉命题逻辑定理。然后，我们比较了这些方法在分布外任务上的表现。结果见[图5](#S5.F5
    "In 5.1 Experiment setup ‣ 5 Evaluation ‣ Learn from Failure: Fine-Tuning LLMs
    with Trial-and-Error Data for Intuitionistic Propositional Logic Proving")。我们的方法通过试错显著优于各种超参数配置下的DFS系统。此外，我们观察到，对于LLM微调来说，提供更多无试错的证明并不会进一步提高性能。'
- en: 'Impact of hyperparameters in the DFS system. As shown in Figure [5](#S5.F5
    "Figure 5 ‣ 5.1 Experiment setup ‣ 5 Evaluation ‣ Learn from Failure: Fine-Tuning
    LLMs with Trial-and-Error Data for Intuitionistic Propositional Logic Proving"),
    on the OOD task, although the success rate of the DFS system gets higher when
    we increase the temperature $t$, the DFS system explores a larger pool of candidate
    tactics during the search, leading to a higher number of Lean calls. In contrast,
    our method does a greedy search to generate only one tactic for each new state.
    Likewise, as $t$ increases, the tactic generator of the DFS system tends to produce
    more diverse tactics at each proof state, improving the system’s performance but
    leading to higher search costs.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 'DFS系统中超参数的影响。如图[5](#S5.F5 "Figure 5 ‣ 5.1 Experiment setup ‣ 5 Evaluation ‣
    Learn from Failure: Fine-Tuning LLMs with Trial-and-Error Data for Intuitionistic
    Propositional Logic Proving")所示，在OOD任务中，尽管当我们增加温度$t$时DFS系统的成功率提高，DFS系统在搜索过程中探索了更多的候选策略，导致了更多的Lean调用。相比之下，我们的方法在每个新状态下仅生成一个策略，采用贪心搜索。同样，随着$t$的增加，DFS系统的策略生成器倾向于在每个证明状态下产生更多样化的策略，从而提高系统性能，但导致更高的搜索成本。'
- en: 'Table 3: Ablation study: Comparison of TrialMaster and model trained without
    trial-and-error information on OOD task'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：消融研究：TrialMaster与在OOD任务上训练的未使用试错信息的模型比较
- en: '| Model | Success rate |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 成功率 |'
- en: '| --- | --- |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| TrialMaster | 88.7% |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| TrialMaster | 88.7% |'
- en: '| Model - proof w/o t.a.e. | 59.3 % |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 模型 - 无试错证明 | 59.3% |'
- en: TrialMaster achieves high success rates at lower search cost. For a direct comparison
    of search costs, we plot the $N_{\text{Lean}}$=1.5, $N_{\text{sampled}}$=1.8,
    $N_{\text{sampled}}$ has reached 31101, which is 72% higher than that of our method
    with trial-and-error. The high search cost makes the DFS system with high temperatures
    unfavorable. These results demonstrate that training with trial-and-error produces
    higher-quality tactics, achieving a higher success rate with relatively lower
    search cost.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: TrialMaster在较低搜索成本下实现了高成功率。为了直接比较搜索成本，我们绘制了$N_{\text{Lean}}$=1.5，$N_{\text{sampled}}$=1.8，$N_{\text{sampled}}$已达到31101，比我们的方法（带试错）高出72%。高搜索成本使得高温度的DFS系统不利。这些结果表明，使用试错进行训练可以产生更高质量的策略，以较低的搜索成本实现更高的成功率。
- en: Model learns backtracking capability from trial-and-error data. In the experiments,
    we find out that our TrialMaster successfully acquires the backtracking capability
    from proofs with trial-and-error information. This is evidenced by the fact that
    during TrialMaster’s proof search for theorems in the testing set, all backtracking
    instructions produced by the LLM adhere to the correct format and point to existing
    state numbers.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 模型从试错数据中学习回溯能力。在实验中，我们发现我们的TrialMaster成功从具有试错信息的证明中获得了回溯能力。证据在于，在TrialMaster对测试集中的定理进行证明搜索时，所有由LLM生成的回溯指令都遵循正确的格式并指向现有的状态编号。
- en: 5.4 Ablation Study
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 消融研究
- en: 'To evaluate the effectiveness of training with trial-and-error, we craft an
    ablated version of our method where the LLM is fined-tuned with data of the corrected
    path only and do inference in the same way as our method (i.e., producing 1 tactic
    at a time and applying Lean for state checking). We denote the ablated version
    as Model - proof w/o t.a.e.. For both methods, we mark the search attempt as failed
    if the tactic induces a Lean error, or the search exceeds the 1500-word limit.
    The result is shown in the Table [3](#S5.T3 "Table 3 ‣ 5.3 Results and Analysis
    ‣ 5 Evaluation ‣ Learn from Failure: Fine-Tuning LLMs with Trial-and-Error Data
    for Intuitionistic Propositional Logic Proving"). The difference between the success
    rates of the two models is significant, which reaches $29.4\%$. This clearly shows
    that failed search states and trial-and-error information tremendously enhance
    the model’s capability to solve theorem-proving tasks.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估使用试错法训练的有效性，我们设计了一个消融版本的方法，其中LLM仅用纠正路径的数据进行微调，并以与我们的方法相同的方式进行推理（即一次产生1个策略并应用Lean进行状态检查）。我们将消融版本称为模型
    - 无试错的证明。对于这两种方法，如果策略导致Lean错误，或搜索超过1500字限制，我们将标记为搜索尝试失败。结果见表[3](#S5.T3 "表 3 ‣
    5.3 结果与分析 ‣ 5 评估 ‣ 从失败中学习：利用试错数据对LLM进行微调以进行直觉命题逻辑证明")。两个模型成功率的差异显著，达到了$29.4\%$。这清楚地表明，失败的搜索状态和试错信息极大地增强了模型解决定理证明任务的能力。
- en: 'Table 4: Comparison of models trained on different lengths of proofs with trial-and-error
    on OOD task.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '表 4: 不同长度证明的模型与试错法在OOD任务上的比较。'
- en: '| Model | Success rate |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 成功率 |'
- en: '| --- | --- |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Model - short proof w/ t.a.e. | 88.7% |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 模型 - 短证明与试错法 | 88.7% |'
- en: '| Model - long proof w/ t.a.e. | 72.4 % |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 模型 - 长证明与试错法 | 72.4 % |'
- en: '5.5 Exploratory Study: Training Proof Length Affect Model Performance'
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5 探索性研究：训练证明长度对模型性能的影响
- en: 'Since the FPS algorithm of PropL dataset can generate multiple proofs with
    variable length, we conduct an exploratory study to assess the impact of proof
    length on model performance. We fine-tune two models using proofs with different
    lengths of trial-and-error information. For the first model, which is our TrialMaster,
    the training data is derived by randomly selecting two out of the shortest four
    proofs from the ten available proofs for each theorem in PropL. We denote it as
    Model - short proof w/ t.a.e. In contrast, the training data of the second model
    is formed by randomly selecting two proofs from the ten available for each theorem,
    irrespective of their lengths. We denote it as Model - long proof w/ t.a.e. For
    both models, we use greedy search to let them generate one tactic for each state.
    We evaluate the models on our 1000 OOD testing set. The results are shown in the
    [Table 4](#S5.T4 "In 5.4 Ablation Study ‣ 5 Evaluation ‣ Learn from Failure: Fine-Tuning
    LLMs with Trial-and-Error Data for Intuitionistic Propositional Logic Proving").
    A higher success rate is observed in the model trained with shorter proofs. This
    can be attributed to the fact that as the proof with trial-and-error information
    becomes longer, there is too much trial-and-error information that may detrimentally
    affect the model’s performance, as too many failed search paths may lower the
    quality of the training data.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '由于PropL数据集的FPS算法可以生成多个长度不一的证明，我们进行了一项探索性研究，以评估证明长度对模型性能的影响。我们使用不同长度的试错信息对两个模型进行微调。对于第一个模型，即我们的TrialMaster，训练数据是通过从PropL中每个定理的十个可用证明中随机选择最短的四个证明中的两个得到的。我们将其称为Model
    - short proof w/ t.a.e。相比之下，第二个模型的训练数据是通过从每个定理的十个可用证明中随机选择两个证明形成的，不考虑它们的长度。我们将其称为Model
    - long proof w/ t.a.e。对于这两个模型，我们使用贪婪搜索让它们为每个状态生成一个策略。我们在我们的1000个OOD测试集上评估这些模型。结果见于[表4](#S5.T4
    "In 5.4 Ablation Study ‣ 5 Evaluation ‣ Learn from Failure: Fine-Tuning LLMs with
    Trial-and-Error Data for Intuitionistic Propositional Logic Proving")。我们观察到在用较短证明训练的模型中，成功率较高。这可以归因于试错信息较长的证明中，试错信息过多可能会对模型性能产生负面影响，因为过多的失败搜索路径可能会降低训练数据的质量。'
- en: 6 Conclusion and Future Work
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论与未来工作
- en: In this paper, we study Automated Theorem Proving in formalized environments.
    We create a complete, scalable, and representative data set of intuitionistic
    propositional logic theorems in Lean. We demonstrate that leveraging information
    from failed search states and backtracking not only teaches models how to backtrack
    effectively but also helps in developing better tactics than those generated by
    models trained without access to backtracking insights. We release our datasets
    on GitHub and Huggingface¹¹1PropL dataset is available at [https://huggingface.co/datasets/KomeijiForce/PropL](https://huggingface.co/datasets/KomeijiForce/PropL).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们研究了形式化环境中的自动定理证明。我们创建了一个完整、可扩展且具有代表性的直观命题逻辑定理数据集。我们展示了利用失败搜索状态和回溯的信息不仅教会了模型如何有效回溯，还帮助开发了比未能访问回溯见解的模型生成的更好的策略。我们在GitHub和Huggingface上发布了我们的数据集¹¹1PropL数据集可在[https://huggingface.co/datasets/KomeijiForce/PropL](https://huggingface.co/datasets/KomeijiForce/PropL)找到。
- en: A natural extension of our research involves investigating whether trial-and-error
    information is beneficial for more general mathematical theorem-proving settings.
    Exploring this avenue could provide valuable insights into the effectiveness of
    our approach across broader mathematical domains.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究的一个自然扩展是调查试错信息是否对更一般的数学定理证明设置有益。探索这一方向可能为我们的方法在更广泛数学领域的有效性提供有价值的见解。
- en: Limitation
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 限制
- en: One limitation of our study is that some proof attempts are forced to stop due
    to the prompt exceeding the context length of 1500 tokens. This constraint may
    potentially influence our results by truncating the available information during
    the proof search process.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究的一个限制是，由于提示超出了1500个标记的上下文长度，一些证明尝试被迫停止。这一限制可能通过截断证明搜索过程中的可用信息来潜在地影响我们的结果。
- en: Furthermore, our method was not evaluated on general mathematical theorems.
    This limitation arises from both the scarcity of proofs containing trial-and-error
    information in current math libraries and the intrinsic challenges associated
    with producing proofs, whether with or without backtracking, for general mathematical
    theorems in a formalized setting.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们的方法尚未在一般数学定理上进行评估。这一限制既来自当前数学库中包含试错信息的证明的稀缺，也来自于在形式化环境中生成一般数学定理证明时，无论是否回溯，所面临的内在挑战。
- en: Automated theorem proving with LLMs is an emerging area in machine learning.
    There is still a lack of baselines on LLMs to compare with our method. We establish
    a fundamental baseline, but we still need accumulative work to provide methods
    for comparison.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 使用大型语言模型的自动定理证明是机器学习中的一个新兴领域。目前还缺乏与我们的方法进行比较的基准。我们建立了一个基础基准，但仍需积累工作以提供比较方法。
- en: Ethical Consideration
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 伦理考量
- en: Our work learns large language models to automatically prove propositional logic
    theorems, which generally does not raise ethical concerns.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的工作使大型语言模型能够自动证明命题逻辑定理，这通常不会引发伦理问题。
- en: References
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Anonymous (2024) Anonymous. 2024. [Boosting of thoughts: Trial-and-error problem
    solving with large language models](https://openreview.net/forum?id=qBL04XXex6).
    In *The Twelfth International Conference on Learning Representations*.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anonymous (2024) Anonymous. 2024. [提升思维：用大型语言模型解决试错问题](https://openreview.net/forum?id=qBL04XXex6)。发表于*第十二届国际学习表征会议*。
- en: Atkinson and Sack (1992) Michael D Atkinson and J-R Sack. 1992. Generating binary
    trees at random. *Information Processing Letters*, 41(1):21–23.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Atkinson and Sack (1992) Michael D Atkinson 和 J-R Sack. 1992. 随机生成二叉树。*信息处理通讯*，41(1):21–23。
- en: Bansal et al. (2019) Kshitij Bansal, Christian Szegedy, Markus N Rabe, Sarah M
    Loos, and Viktor Toman. 2019. [Learning to reason in large theories without imitation](http://arxiv.org/abs/1905.10501).
    *arXiv preprint arXiv:1905.10501*.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bansal et al. (2019) Kshitij Bansal, Christian Szegedy, Markus N Rabe, Sarah
    M Loos, 和 Viktor Toman. 2019. [在大型理论中学习推理而不进行模仿](http://arxiv.org/abs/1905.10501)。*arXiv
    预印本 arXiv:1905.10501*。
- en: 'Barras et al. (1997) Bruno Barras, Samuel Boutin, Cristina Cornes, Judicaël
    Courant, Jean-Christophe Filliatre, Eduardo Gimenez, Hugo Herbelin, Gerard Huet,
    Cesar Munoz, Chetan Murthy, et al. 1997. *The Coq proof assistant reference manual:
    Version 6.1*. Ph.D. thesis, Inria.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Barras et al. (1997) Bruno Barras, Samuel Boutin, Cristina Cornes, Judicaël
    Courant, Jean-Christophe Filliatre, Eduardo Gimenez, Hugo Herbelin, Gerard Huet,
    Cesar Munoz, Chetan Murthy, 等. 1997. *Coq 证明助手参考手册：版本 6.1*。博士论文，Inria。
- en: 'Besta et al. (2023) Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger,
    Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski,
    Piotr Nyczyk, et al. 2023. Graph of thoughts: Solving elaborate problems with
    large language models. *arXiv preprint arXiv:2308.09687*.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Besta et al. (2023) Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger,
    Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski,
    Piotr Nyczyk, 等. 2023. 思维图谱：用大型语言模型解决复杂问题。*arXiv 预印本 arXiv:2308.09687*。
- en: Chang and Lee (2014) Chin-Liang Chang and Richard Char-Tung Lee. 2014. *Symbolic
    logic and mechanical theorem proving*. Academic press.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chang and Lee (2014) Chin-Liang Chang 和 Richard Char-Tung Lee. 2014. *符号逻辑与机械定理证明*。Academic
    press.
- en: 'Chu et al. (2023) Zheng Chu, Jingchang Chen, Qianglong Chen, Weijiang Yu, Tao
    He, Haotian Wang, Weihua Peng, Ming Liu, Bing Qin, and Ting Liu. 2023. A survey
    of chain of thought reasoning: Advances, frontiers and future. *arXiv preprint
    arXiv:2309.15402*.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chu et al. (2023) Zheng Chu, Jingchang Chen, Qianglong Chen, Weijiang Yu, Tao
    He, Haotian Wang, Weihua Peng, Ming Liu, Bing Qin, 和 Ting Liu. 2023. 关于思维链推理的调研：进展、前沿与未来。*arXiv
    预印本 arXiv:2309.15402*。
- en: Clocksin and Mellish (2003) William F Clocksin and Christopher S Mellish. 2003.
    *Programming in PROLOG*. Springer Science & Business Media.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Clocksin and Mellish (2003) William F Clocksin 和 Christopher S Mellish. 2003.
    *PROLOG 编程*。Springer Science & Business Media.
- en: 'Crevier (1993) Daniel Crevier. 1993. *AI: the tumultuous history of the search
    for artificial intelligence*. Basic Books, Inc.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Crevier (1993) Daniel Crevier. 1993. *人工智能：寻找人工智能的动荡历史*。Basic Books, Inc.
- en: Davies et al. (2021) Alex Davies, Petar Veličković, Lars Buesing, Sam Blackwell,
    Daniel Zheng, Nenad Tomašev, Richard Tanburn, Peter Battaglia, Charles Blundell,
    András Juhász, et al. 2021. Advancing mathematics by guiding human intuition with
    AI. *Nature*, 600(7887):70–74.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Davies et al. (2021) Alex Davies, Petar Veličković, Lars Buesing, Sam Blackwell,
    Daniel Zheng, Nenad Tomašev, Richard Tanburn, Peter Battaglia, Charles Blundell,
    András Juhász, 等. 2021. 通过引导人类直觉来推动数学进步。*Nature*，600(7887):70–74。
- en: Davis (2001) Martin Davis. 2001. The early history of automated deduction. *Handbook
    of automated reasoning*, 1:3–15.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Davis（2001）Martin Davis。2001年。自动推理的早期历史。*自动推理手册*，1:3–15。
- en: 'de Moura et al. (2015) Leonardo de Moura, Soonho Kong, Jeremy Avigad, Floris
    Van Doorn, and Jakob von Raumer. 2015. The lean theorem prover (system description).
    In *Automated Deduction-CADE-25: 25th International Conference on Automated Deduction,
    Berlin, Germany, August 1-7, 2015, Proceedings 25*, pages 378–388\. Springer.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: de Moura 等（2015）Leonardo de Moura、Soonho Kong、Jeremy Avigad、Floris Van Doorn
    和 Jakob von Raumer。2015年。精益定理证明器（系统描述）。在*自动推理-CADE-25：第25届国际自动推理会议，德国柏林，2015年8月1-7日，会议论文集
    25*，第378–388页。Springer。
- en: 'First et al. (2023) Emily First, Markus Rabe, Talia Ringer, and Yuriy Brun.
    2023. Baldur: Whole-proof generation and repair with large language models. In
    *Proceedings of the 31st ACM Joint European Software Engineering Conference and
    Symposium on the Foundations of Software Engineering*, pages 1229–1241.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: First 等（2023）Emily First、Markus Rabe、Talia Ringer 和 Yuriy Brun。2023年。Baldur：与大型语言模型生成和修复完整证明。在*第31届
    ACM 欧洲软件工程联合会议和软件工程基础研讨会论文集*，第1229–1241页。
- en: Fu et al. (2022) Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and Tushar
    Khot. 2022. Complexity-based prompting for multi-step reasoning. *arXiv preprint
    arXiv:2210.00720*.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fu 等（2022）Yao Fu、Hao Peng、Ashish Sabharwal、Peter Clark 和 Tushar Khot。2022年。基于复杂度的多步骤推理提示。*arXiv
    预印本 arXiv:2210.00720*。
- en: 'Gilmore (1960) P. C. Gilmore. 1960. [A proof method for quantification theory:
    Its justification and realization](https://doi.org/10.1147/rd.41.0028). *IBM Journal
    of Research and Development*, 4(1):28–35.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gilmore（1960）P. C. Gilmore。1960年。 [量化理论的证明方法：其理由与实现](https://doi.org/10.1147/rd.41.0028)。*IBM
    研究与开发杂志*，4(1):28–35。
- en: Han et al. (2021) Jesse Michael Han, Jason Rute, Yuhuai Wu, Edward W Ayers,
    and Stanislas Polu. 2021. [Proof artifact co-training for theorem proving with
    language models](http://arxiv.org/abs/2102.06203). *arXiv preprint arXiv:2102.06203*.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Han 等（2021）Jesse Michael Han、Jason Rute、Yuhuai Wu、Edward W Ayers 和 Stanislas
    Polu。2021年。 [用于定理证明的证明工件协同训练与语言模型](http://arxiv.org/abs/2102.06203)。*arXiv 预印本
    arXiv:2102.06203*。
- en: Holden and Korovin (2021) Edvard K Holden and Konstantin Korovin. 2021. Heterogeneous
    heuristic optimisation and scheduling for first-order theorem proving. In *International
    Conference on Intelligent Computer Mathematics*, pages 107–123\. Springer.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Holden 和 Korovin（2021）Edvard K Holden 和 Konstantin Korovin。2021年。用于一阶定理证明的异质启发式优化和调度。在*国际智能计算数学会议*，第107–123页。Springer。
- en: Irving et al. (2016) Geoffrey Irving, Christian Szegedy, Alexander A Alemi,
    Niklas Eén, François Chollet, and Josef Urban. 2016. Deepmath-deep sequence models
    for premise selection. *Advances in neural information processing systems*, 29.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Irving 等（2016）Geoffrey Irving、Christian Szegedy、Alexander A Alemi、Niklas Eén、François
    Chollet 和 Josef Urban。2016年。Deepmath-深度序列模型用于前提选择。*神经信息处理系统进展*，29。
- en: 'Jiang et al. (2022) Albert Q Jiang, Sean Welleck, Jin Peng Zhou, Wenda Li,
    Jiacheng Liu, Mateja Jamnik, Timothée Lacroix, Yuhuai Wu, and Guillaume Lample.
    2022. [Draft, sketch, and prove: Guiding formal theorem provers with informal
    proofs](http://arxiv.org/abs/2210.12283). *arXiv preprint arXiv:2210.12283*.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang 等（2022）Albert Q Jiang、Sean Welleck、Jin Peng Zhou、Wenda Li、Jiacheng Liu、Mateja
    Jamnik、Timothée Lacroix、Yuhuai Wu 和 Guillaume Lample。2022年。 [草拟、草图和证明：用非正式证明指导形式定理证明器](http://arxiv.org/abs/2210.12283)。*arXiv
    预印本 arXiv:2210.12283*。
- en: Kusumoto et al. (2018) Mitsuru Kusumoto, Keisuke Yahata, and Masahiro Sakai.
    2018. Automated theorem proving in intuitionistic propositional logic by deep
    reinforcement learning. *arXiv preprint arXiv:1811.00796*.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kusumoto 等（2018）Mitsuru Kusumoto、Keisuke Yahata 和 Masahiro Sakai。2018年。通过深度强化学习的直观命题逻辑自动定理证明。*arXiv
    预印本 arXiv:1811.00796*。
- en: Kwon et al. (2023) Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin
    Zheng, Cody Hao Yu, Joseph Gonzalez, Hao Zhang, and Ion Stoica. 2023. Efficient
    memory management for large language model serving with pagedattention. In *Proceedings
    of the 29th Symposium on Operating Systems Principles*, pages 611–626.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kwon 等（2023）Woosuk Kwon、Zhuohan Li、Siyuan Zhuang、Ying Sheng、Lianmin Zheng、Cody
    Hao Yu、Joseph Gonzalez、Hao Zhang 和 Ion Stoica。2023年。用于大型语言模型服务的高效内存管理与分页注意力。在*第29届操作系统原理研讨会论文集*，第611–626页。
- en: Lample et al. (2022) Guillaume Lample, Timothee Lacroix, Marie-Anne Lachaux,
    Aurelien Rodriguez, Amaury Hayat, Thibaut Lavril, Gabriel Ebner, and Xavier Martinet.
    2022. Hypertree proof search for neural theorem proving. *Advances in Neural Information
    Processing Systems*, 35:26337–26349.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lample 等（2022）Guillaume Lample、Timothee Lacroix、Marie-Anne Lachaux、Aurelien
    Rodriguez、Amaury Hayat、Thibaut Lavril、Gabriel Ebner 和 Xavier Martinet。2022年。用于神经定理证明的超树证明搜索。*神经信息处理系统进展*，35:26337–26349。
- en: Liang and Miller (2009) Chuck C. Liang and Dale Miller. 2009. [Focusing and
    polarization in linear, intuitionistic, and classical logics](https://doi.org/10.1016/J.TCS.2009.07.041).
    *Theor. Comput. Sci.*, 410(46):4747–4768.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liang 和 Miller (2009) Chuck C. Liang 和 Dale Miller. 2009. [线性、直觉主义和经典逻辑中的聚焦和极化](https://doi.org/10.1016/J.TCS.2009.07.041)。*理论计算机科学*，410(46)：4747–4768。
- en: McCorduck (2004) Pamela McCorduck. 2004. *Machines Who Think (2Nd Ed.)*. A.
    K. Peters.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: McCorduck (2004) Pamela McCorduck. 2004. *会思考的机器 (第二版)*。A. K. Peters。
- en: McLaughlin and Pfenning (2009) Sean McLaughlin and Frank Pfenning. 2009. [Efficient
    intuitionistic theorem proving with the polarized inverse method](https://doi.org/10.1007/978-3-642-02959-2_19).
    In *Automated Deduction - CADE-22, 22nd International Conference on Automated
    Deduction, Montreal, Canada, August 2-7, 2009\. Proceedings*, volume 5663 of *Lecture
    Notes in Computer Science*, pages 230–244\. Springer.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: McLaughlin 和 Pfenning (2009) Sean McLaughlin 和 Frank Pfenning. 2009. [使用极化逆方法进行高效的直觉主义定理证明](https://doi.org/10.1007/978-3-642-02959-2_19)。收录于
    *自动推理 - CADE-22，第22届国际自动推理会议，蒙特利尔，加拿大，2009年8月2-7日。会议录*，第5663卷 *计算机科学讲义笔记*，第230–244页。Springer。
- en: 'Megill and Wheeler (2019) Norman Megill and David A Wheeler. 2019. *Metamath:
    a computer language for mathematical proofs*. Lulu. com.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Megill 和 Wheeler (2019) Norman Megill 和 David A Wheeler. 2019. *Metamath：一种用于数学证明的计算机语言*。Lulu.com。
- en: 'Mikuła et al. (2023) Maciej Mikuła, Szymon Antoniak, Szymon Tworkowski, Albert Qiaochu
    Jiang, Jin Peng Zhou, Christian Szegedy, Łukasz Kuciński, Piotr Miłoś, and Yuhuai
    Wu. 2023. Magnushammer: A transformer-based approach to premise selection. *arXiv
    preprint arXiv:2303.04488*.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mikuła 等人 (2023) Maciej Mikuła、Szymon Antoniak、Szymon Tworkowski、Albert Qiaochu
    Jiang、Jin Peng Zhou、Christian Szegedy、Łukasz Kuciński、Piotr Miłoś 和 Yuhuai Wu.
    2023. Magnushammer：一种基于变换器的前提选择方法。*arXiv 预印本 arXiv:2303.04488*。
- en: Nawaz et al. (2019) M Saqib Nawaz, Moin Malik, Yi Li, Meng Sun, and M Lali.
    2019. A survey on theorem provers in formal methods. *arXiv preprint arXiv:1912.03028*.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nawaz 等人 (2019) M Saqib Nawaz、Moin Malik、Yi Li、Meng Sun 和 M Lali. 2019. 关于形式方法中的定理证明器的调查。*arXiv
    预印本 arXiv:1912.03028*。
- en: 'Nipkow et al. (2002) Tobias Nipkow, Markus Wenzel, and Lawrence C Paulson.
    2002. *Isabelle/HOL: a proof assistant for higher-order logic*. Springer.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nipkow 等人 (2002) Tobias Nipkow、Markus Wenzel 和 Lawrence C Paulson. 2002. *Isabelle/HOL：一种高阶逻辑的证明助手*。Springer。
- en: Pfenning (2017) Frank Pfenning. 2017. [Lecture notes on focusing](http://www.cs.cmu.edu/~fp/courses/15317-f17/lectures/19-focusing.pdf).
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pfenning (2017) Frank Pfenning. 2017. [聚焦的讲义笔记](http://www.cs.cmu.edu/~fp/courses/15317-f17/lectures/19-focusing.pdf)。
- en: Polu and Sutskever (2020) Stanislas Polu and Ilya Sutskever. 2020. [Generative
    language modeling for automated theorem proving](http://arxiv.org/abs/2009.03393).
    *arXiv preprint arXiv:2009.03393*.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Polu 和 Sutskever (2020) Stanislas Polu 和 Ilya Sutskever. 2020. [用于自动定理证明的生成语言建模](http://arxiv.org/abs/2009.03393)。*arXiv
    预印本 arXiv:2009.03393*。
- en: Rabe et al. (2020) Markus N Rabe, Dennis Lee, Kshitij Bansal, and Christian
    Szegedy. 2020. [Mathematical reasoning via self-supervised skip-tree training](http://arxiv.org/abs/2006.04757).
    *arXiv preprint arXiv:2006.04757*.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rabe 等人 (2020) Markus N Rabe、Dennis Lee、Kshitij Bansal 和 Christian Szegedy.
    2020. [通过自监督跳跃树训练的数学推理](http://arxiv.org/abs/2006.04757)。*arXiv 预印本 arXiv:2006.04757*。
- en: Robinson (1965) John Alan Robinson. 1965. A machine-oriented logic based on
    the resolution principle. *Journal of the ACM (JACM)*, 12(1):23–41.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Robinson (1965) John Alan Robinson. 1965. 基于分辨率原理的面向机器的逻辑。*ACM 杂志 (JACM)*，12(1)：23–41。
- en: Russell and Norvig (2010) Stuart J Russell and Peter Norvig. 2010. *Artificial
    intelligence a modern approach*. London.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Russell 和 Norvig (2010) Stuart J Russell 和 Peter Norvig. 2010. *人工智能：一种现代方法*。伦敦。
- en: Sekiyama et al. (2017) Taro Sekiyama, Akifumi Imanishi, and Kohei Suenaga. 2017.
    Towards proof synthesis guided by neural machine translation for intuitionistic
    propositional logic. corr abs/1706.06462 (2017). *arXiv preprint arXiv:1706.06462*.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sekiyama 等人 (2017) Taro Sekiyama、Akifumi Imanishi 和 Kohei Suenaga. 2017. 针对直觉主义命题逻辑的神经机器翻译指导的证明合成。corr
    abs/1706.06462 (2017)。*arXiv 预印本 arXiv:1706.06462*。
- en: Sekiyama and Suenaga (2018) Taro Sekiyama and Kohei Suenaga. 2018. Automated
    proof synthesis for propositional logic with deep neural networks. *arXiv preprint
    arXiv:1805.11799*.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sekiyama 和 Suenaga (2018) Taro Sekiyama 和 Kohei Suenaga. 2018. 基于深度神经网络的命题逻辑自动证明合成。*arXiv
    预印本 arXiv:1805.11799*。
- en: Stanley (2015) Richard P Stanley. 2015. *Catalan numbers*. Cambridge University
    Press.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Stanley (2015) Richard P Stanley. 2015. *卡塔兰数*。剑桥大学出版社。
- en: Thakur et al. (2023) Amitayush Thakur, Yeming Wen, and Swarat Chaudhuri. 2023.
    A language-agent approach to formal theorem-proving. *arXiv preprint arXiv:2310.04353*.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Thakur 等人 (2023) Amitayush Thakur、Yeming Wen 和 Swarat Chaudhuri. 2023. 一种语言-代理方法用于形式定理证明。*arXiv
    预印本 arXiv:2310.04353*。
- en: 'Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models.
    *arXiv preprint arXiv:2307.09288*.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Touvron 等（2023）Hugo Touvron、Louis Martin、Kevin Stone、Peter Albert、Amjad Almahairi、Yasmine
    Babaei、Nikolay Bashlykov、Soumya Batra、Prajjwal Bhargava、Shruti Bhosale 等。2023。Llama
    2：开放基础和微调聊天模型。*arXiv 预印本 arXiv:2307.09288*。
- en: Wagner (2021) Adam Zsolt Wagner. 2021. [Constructions in combinatorics via neural
    networks](http://arxiv.org/abs/2104.14516). *arXiv preprint arXiv:2104.14516*.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wagner（2021）Adam Zsolt Wagner。2021。[通过神经网络的组合数学构造](http://arxiv.org/abs/2104.14516)。*arXiv
    预印本 arXiv:2104.14516*。
- en: 'Wang et al. (2023) Haiming Wang, Ye Yuan, Zhengying Liu, Jianhao Shen, Yichun
    Yin, Jing Xiong, Enze Xie, Han Shi, Yujun Li, Lin Li, et al. 2023. Dt-solver:
    Automated theorem proving with dynamic-tree sampling guided by proof-level value
    function. In *Proceedings of the 61st Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)*, pages 12632–12646.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等（2023）Haiming Wang、Ye Yuan、Zhengying Liu、Jianhao Shen、Yichun Yin、Jing
    Xiong、Enze Xie、Han Shi、Yujun Li、Lin Li 等。2023。Dt-solver：一种通过证明级别价值函数引导的动态树采样自动定理证明方法。在*第61届计算语言学协会年会（第1卷：长篇论文）会议录*，页12632–12646。
- en: Wang and Deng (2020) Mingzhe Wang and Jia Deng. 2020. Learning to prove theorems
    by learning to generate theorems. *Advances in Neural Information Processing Systems*,
    33:18146–18157.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 和 Deng（2020）Mingzhe Wang 和 Jia Deng。2020。通过生成定理学习证明定理。*神经信息处理系统进展*，33:18146–18157。
- en: Wang et al. (2017) Mingzhe Wang, Yihe Tang, Jian Wang, and Jia Deng. 2017. Premise
    selection for theorem proving by deep graph embedding. *Advances in neural information
    processing systems*, 30.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等（2017）Mingzhe Wang、Yihe Tang、Jian Wang 和 Jia Deng。2017。通过深度图嵌入进行定理证明的前提选择。*神经信息处理系统进展*，30。
- en: Wang et al. (2022) Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi,
    Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2022. Self-consistency improves
    chain of thought reasoning in language models. *arXiv preprint arXiv:2203.11171*.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等（2022）Xuezhi Wang、Jason Wei、Dale Schuurmans、Quoc Le、Ed Chi、Sharan Narang、Aakanksha
    Chowdhery 和 Denny Zhou。2022。自洽性提高了语言模型的思维链推理。*arXiv 预印本 arXiv:2203.11171*。
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei
    Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits
    reasoning in large language models. *Advances in Neural Information Processing
    Systems*, 35:24824–24837.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等（2022）Jason Wei、Xuezhi Wang、Dale Schuurmans、Maarten Bosma、Fei Xia、Ed Chi、Quoc
    V Le、Denny Zhou 等。2022。思维链提示引发了大型语言模型的推理。*神经信息处理系统进展*，35:24824–24837。
- en: 'Welleck et al. (2021) Sean Welleck, Jiacheng Liu, Ronan Le Bras, Hannaneh Hajishirzi,
    Yejin Choi, and Kyunghyun Cho. 2021. [Naturalproofs: Mathematical theorem proving
    in natural language](http://arxiv.org/abs/2104.01112). *arXiv preprint arXiv:2104.01112*.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Welleck 等（2021）Sean Welleck、Jiacheng Liu、Ronan Le Bras、Hannaneh Hajishirzi、Yejin
    Choi 和 Kyunghyun Cho。2021。[Naturalproofs: 自然语言中的数学定理证明](http://arxiv.org/abs/2104.01112)。*arXiv
    预印本 arXiv:2104.01112*。'
- en: 'Wolf et al. (2019) Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond,
    Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz,
    et al. 2019. Huggingface’s transformers: State-of-the-art natural language processing.
    *arXiv preprint arXiv:1910.03771*.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wolf 等（2019）Thomas Wolf、Lysandre Debut、Victor Sanh、Julien Chaumond、Clement Delangue、Anthony
    Moi、Pierric Cistac、Tim Rault、Rémi Louf、Morgan Funtowicz 等。2019。Huggingface 的 transformers：最先进的自然语言处理。*arXiv
    预印本 arXiv:1910.03771*。
- en: 'Wu et al. (2021) Minchao Wu, Michael Norrish, Christian Walder, and Amir Dezfouli.
    2021. Tacticzero: Learning to prove theorems from scratch with deep reinforcement
    learning. *Advances in Neural Information Processing Systems*, 34:9330–9342.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等（2021）Minchao Wu、Michael Norrish、Christian Walder 和 Amir Dezfouli。2021。Tacticzero：通过深度强化学习从零开始学习证明定理。*神经信息处理系统进展*，34:9330–9342。
- en: 'Yang et al. (2023) Kaiyu Yang, Aidan M Swope, Alex Gu, Rahul Chalamala, Peiyang
    Song, Shixing Yu, Saad Godil, Ryan Prenger, and Anima Anandkumar. 2023. [LeanDojo:
    Theorem Proving with Retrieval-Augmented Language Models](http://arxiv.org/abs/2306.15626).
    *arXiv preprint arXiv:2306.15626*.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yang 等（2023）Kaiyu Yang、Aidan M Swope、Alex Gu、Rahul Chalamala、Peiyang Song、Shixing
    Yu、Saad Godil、Ryan Prenger 和 Anima Anandkumar。2023。[LeanDojo: 通过检索增强语言模型进行定理证明](http://arxiv.org/abs/2306.15626)。*arXiv
    预印本 arXiv:2306.15626*。'
- en: 'Yao et al. (2023) Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L
    Griffiths, Yuan Cao, and Karthik Narasimhan. 2023. Tree of thoughts: Deliberate
    problem solving with large language models. *arXiv preprint arXiv:2305.10601*.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao等（2023）Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths,
    Yuan Cao, 和 Karthik Narasimhan. 2023. 思维树：与大型语言模型进行深思熟虑的问题解决。*arXiv预印本 arXiv:2305.10601*。
- en: Yu et al. (2023) Fei Yu, Hongbo Zhang, and Benyou Wang. 2023. Nature language
    reasoning, a survey. *arXiv preprint arXiv:2303.14725*.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu等（2023）Fei Yu, Hongbo Zhang, 和 Benyou Wang. 2023. 自然语言推理，综述。*arXiv预印本 arXiv:2303.14725*。
- en: Zhou et al. (2022) Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan
    Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, et al.
    2022. Least-to-most prompting enables complex reasoning in large language models.
    *arXiv preprint arXiv:2205.10625*.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou等（2022）Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales,
    Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le等。2022. 从最少到最多的提示促使大语言模型进行复杂推理。*arXiv预印本
    arXiv:2205.10625*。
- en: Appendix A Uniformly Distributed Data Explanation
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录A 均匀分布数据说明
- en: In this section, we discuss the uniform characteristics of our dataset, particularly
    emphasizing the one-to-one mapping between propositions and natural numbers. This
    bijection allows us to simply sample from the natural numbers to ensure the dataset
    exhibits uniformity.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论了数据集的均匀特性，特别强调了命题与自然数之间的一对一映射。这种双射使我们可以简单地从自然数中采样，以确保数据集的均匀性。
- en: Algorithm 1 Encoding
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 算法1 编码
- en: '1:A tree $\mathcal{T}$ $\times$)4:function ShapeNumber($\mathcal{T}$ left and
    right sub-trees of $\mathcal{T}$ Total $n_{r}+n_{l}+1$ $\times$)10:end function11:function AssignmentNumber($\mathcal{T}$
    is a single node then return $N$ number of internal nodes in $\mathcal{T}_{r}$
    $\times$ $\times$)19:end function20:function NodeNumber($\mathcal{N}$: return
    023:      case $\lor$: return $i+1$26:end function'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '1：树$\mathcal{T}$ $\times$）4：函数 ShapeNumber($\mathcal{T}$ 左右子树的$\mathcal{T}$
    总计 $n_{r}+n_{l}+1$ $\times$）10：结束 函数11：函数 AssignmentNumber($\mathcal{T}$ 为单个节点时返回
    $N$ 树中的内部节点数 $\mathcal{T}_{r}$ $\times$ $\times$）19：结束 函数20：函数 NodeNumber($\mathcal{N}$：返回
    023：      情况 $\lor$: 返回 $i+1$26：结束 函数'
- en: A.1 Catalan Number
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 Catalan数
- en: 'The Catalan number $C_{n}$ internal nodes Stanley ([2015](#bib.bib37)). Additionally,
    it can be calculated through recursion as shown:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: Catalan数$C_{n}$内部节点 Stanley ([2015](#bib.bib37))。此外，还可以通过递归计算，如下所示：
- en: '|  | $C_{n}=\sum_{i=1}^{n}C_{i-1}C_{n-i}.$ |  |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '|  | $C_{n}=\sum_{i=1}^{n}C_{i-1}C_{n-i}.$ |  |'
- en: The first Catalan numbers for $n=0,1,2,3,4$.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 对于$n=0,1,2,3,4$的第一组Catalan数。
- en: 'A concise interpretation of this recursion is as follows: it involves counting
    the number of internal nodes in the left sub-tree, amounting to $i-1$.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 对该递归的简明解释如下：它涉及计算左子树中的内部节点数量，为$i-1$。
- en: Algorithm 2 Decoding
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 算法2 解码
- en: '1:A natural number ID, with $n$)4:$S\leftarrow$, remainder)6:return a tree
    with shape $S$)8:     if $n$12:     remaining $\leftarrow N-\sum_{i=1}^{n_{l}}C_{i-1}C_{n-i}$,
    $n_{l}$, $N$ by utilizing the NodeNumber function introduced in [Algorithm 1](#alg1
    "In Appendix A Uniformly Distributed Data Explanation ‣ Learn from Failure: Fine-Tuning
    LLMs with Trial-and-Error Data for Intuitionistic Propositional Logic Proving")18:end function'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 1：自然数ID，$n$）4：$S\leftarrow$，余数）6：返回形状为$S$的树）8：     如果$n$12：     剩余 $\leftarrow
    N-\sum_{i=1}^{n_{l}}C_{i-1}C_{n-i}$，$n_{l}$，$N$，利用[算法1](#alg1 "在附录A 均匀分布数据说明 ‣
    从失败中学习：通过试错数据微调LLMs用于直觉命题逻辑证明")引入的NodeNumber函数18：结束 函数
- en: A.2 Bijection between Propositions and Natural Numbers
  id: totrans-208
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 命题与自然数之间的双射
- en: 'As depicted in [Figure 3](#S3.F3 "In 3.1 Data Generation of PropL ‣ 3 PropL:
    A New Dataset for Intuitionistic Propositional Logic Theorems in Lean ‣ Learn
    from Failure: Fine-Tuning LLMs with Trial-and-Error Data for Intuitionistic Propositional
    Logic Proving"), every proposition corresponds to a unique tree representation.
    Consequently, it only requires the identification of a bijection between full
    binary trees and natural numbers.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '如[图3](#S3.F3 "在3.1数据生成PropL ‣ 3 PropL: 一个用于直觉命题逻辑定理的新数据集 ‣ 从失败中学习：通过试错数据微调LLMs用于直觉命题逻辑证明")所示，每个命题对应一个唯一的树形表示。因此，仅需确定满二叉树与自然数之间的双射。'
- en: For every full binary tree possessing $n$ atomic propositions, there exist
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个拥有$n$原子命题的满二叉树，存在
- en: '|  | $\displaystyle 3^{\#\text{internal node}}(p+2)^{\#\text{leaf node}}=3^{n}(p+2)^{n+1}$
    |  |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle 3^{\#\text{内部节点}}(p+2)^{\#\text{叶节点}}=3^{n}(p+2)^{n+1}$
    |  |'
- en: distinct cases. Observe that the choices available for internal nodes include
    conjunction ($\land$), false ($F$.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的情况。观察到内部节点的选择包括合取（$\land$）、假（$F$）。
- en: 'This counting facilitates an efficient ranking of all full binary trees with
    $n$ internal nodes. This ranking process inherently establishes a bijection with
    the set of natural numbers, allowing for a clear correspondence between each full
    binary tree and a unique natural number. Consequently, this sets the stage for
    a detailed examination of two critical processes: encoding (see [Algorithm 1](#alg1
    "In Appendix A Uniformly Distributed Data Explanation ‣ Learn from Failure: Fine-Tuning
    LLMs with Trial-and-Error Data for Intuitionistic Propositional Logic Proving")),
    which involves mapping a proposition tree to a natural number, and decoding (see
    [Algorithm 2](#alg2 "In A.1 Catalan Number ‣ Appendix A Uniformly Distributed
    Data Explanation ‣ Learn from Failure: Fine-Tuning LLMs with Trial-and-Error Data
    for Intuitionistic Propositional Logic Proving")), which entails mapping a natural
    number back to a corresponding proposition tree. These processes are vital for
    effectively establishing and utilizing the bijection between full binary trees
    and natural numbers.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 这种计数有助于对所有具有 $n$ 个内部节点的完整二叉树进行有效排序。这一排序过程本质上建立了与自然数集的双射，从而实现每个完整二叉树与唯一自然数之间的明确对应。因此，这为详细检查两个关键过程奠定了基础：编码（见[算法
    1](#alg1 "在附录 A 均匀分布数据说明 ‣ 从失败中学习：通过试错数据细化 LLMs 用于直观命题逻辑证明")），它涉及将命题树映射到自然数，以及解码（见[算法
    2](#alg2 "在 A.1 Catalan 数字 ‣ 附录 A 均匀分布数据说明 ‣ 从失败中学习：通过试错数据细化 LLMs 用于直观命题逻辑证明")），它涉及将自然数映射回相应的命题树。这些过程对于有效建立和利用完整二叉树与自然数之间的双射至关重要。
- en: Having established the bijection between full binary trees and natural numbers,
    it becomes apparent that uniformly sampling from the set of natural numbers will,
    in turn, result in a uniform sampling of full binary trees.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在建立了完整二叉树与自然数之间的双射后，显然从自然数集均匀抽样将会导致对完整二叉树的均匀抽样。
- en: The inclusion of the parameter $n$. For example, ID 0 denotes different propositions
    depending on the specified value of $n$, a task which can be performed with relative
    ease. This approach of merging can be similarly applied to trees with varying
    $p$ as well.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 参数 $n$ 的包含。例如，ID 0 表示根据指定的 $n$ 值不同的命题，这一任务可以相对轻松地完成。类似的方法可以应用于具有不同 $p$ 的树。
- en: Given the uncertainty surrounding the proof lengths when generating propositions,
    our approach involves uniform sampling for proposition selection. This selection
    is later refined by excluding propositions according to their proof lengths as
    computed by the proof generation algorithm. From a probabilistic perspective,
    this method is the same as pre-excluding propositions exceeding a certain proof
    length from the entire sampling space prior to the random selection of propositions.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于生成命题时证明长度的不确定性，我们的方法涉及对命题进行均匀抽样选择。这一选择随后通过根据证明生成算法计算的证明长度排除命题来进行细化。从概率的角度来看，这种方法与在随机选择命题之前从整个抽样空间中预先排除超出某一证明长度的命题是相同的。
- en: Appendix B Examples
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 示例
- en: 'In [Figure 6](#A2.F6 "In Appendix B Examples ‣ Learn from Failure: Fine-Tuning
    LLMs with Trial-and-Error Data for Intuitionistic Propositional Logic Proving"),
    we show an example Lean proof for a theorem in [Figure 3](#S3.F3 "In 3.1 Data
    Generation of PropL ‣ 3 PropL: A New Dataset for Intuitionistic Propositional
    Logic Theorems in Lean ‣ Learn from Failure: Fine-Tuning LLMs with Trial-and-Error
    Data for Intuitionistic Propositional Logic Proving"). Lines preceded by ’–’ are
    comments solely for explanatory purposes.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '在[图 6](#A2.F6 "在附录 B 示例 ‣ 从失败中学习：通过试错数据细化 LLMs 用于直观命题逻辑证明")中，我们展示了一个在[图 3](#S3.F3
    "在 3.1 PropL 数据生成 ‣ 3 PropL: 一种新的 Lean 中直观命题逻辑定理数据集 ‣ 从失败中学习：通过试错数据细化 LLMs 用于直观命题逻辑证明")的定理的
    Lean 证明示例。以 ’–’ 开头的行是仅用于解释的评论。'
- en: '{spverbatim}'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '{spverbatim}'
- en: 'variable (p1 p2 p3 p4 p5 : Prop) theorem thm_5_vars_45663772897 : (((p1 ∨ p2)
    → False) → ((p1 → False) ∧ (p2 → False))) := by – Implications on the right can
    always be decomposed. – Introduce an assumption h1 that says ((p1 ∨ p2) → False)
    intro h1 – Now we want to show ((p1 → False) ∧ (p2 → False)) – Conjunctions on
    the right can always be decomposed. – We then need to show (p1 → False) and (p2
    → False) separately. apply And.intro – We are showing (p1 → False). – Implications
    on the right can always be decomposed. – We introduce assumption h2 for p1\. And
    we try to show False. intro h2 – We want to use the implication h1\. So we show
    its premise. have h3 : (p1 ∨ p2) := by – Show the left disjunct. (The right adjunct
    leads to an TAE) apply Or.inl – One of the premise coincides with the conclusion.
    exact h2 – We have shown the premise of h1 (p1 ∨ p2), – we can now drive its conclusion
    (False), denoted by h4. let h4 := h1 h3 – False on the left can always be used.
    apply False.elim h4 – We have shown (p1 → False) and now we show (p2 → False).
    – Implications on the right can always be decomposed. – We introduce assumption
    h2 for p2\. And we try to show False. intro h5 – We want to use the implication
    h1\. So we show its premise. have h6 : (p1 ∨ p2) := by – Show the right disjunct.
    (The left adjunct leads to an TAE) apply Or.inr – One of the premise coincides
    with the conclusion. exact h5 – We have shown the premise of h1 (p1 ∨ p2), – we
    can now drive its conclusion (False), denoted by h7. let h7 := h1 h6 – False on
    the left can always be used. apply False.elim h7'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '变量 (p1 p2 p3 p4 p5 : Prop) 定理 thm_5_vars_45663772897 : (((p1 ∨ p2) → False)
    → ((p1 → False) ∧ (p2 → False))) := by – 右侧的蕴含关系总是可以分解。 – 引入一个假设 h1，表示 ((p1 ∨
    p2) → False) intro h1 – 现在我们要证明 ((p1 → False) ∧ (p2 → False)) – 右侧的合取关系总是可以分解。
    – 我们需要分别证明 (p1 → False) 和 (p2 → False)。 apply And.intro – 我们正在证明 (p1 → False)。
    – 右侧的蕴含关系总是可以分解。 – 我们引入假设 h2 对 p1。并尝试证明 False。 intro h2 – 我们想使用假设 h1。于是我们展示它的前提。
    have h3 : (p1 ∨ p2) := by – 展示左侧的析取。 (右侧的析取会导致 TAE) apply Or.inl – 前提之一与结论一致。
    exact h2 – 我们已经证明了 h1 的前提 (p1 ∨ p2)， – 现在我们可以得出结论 (False)，用 h4 表示。 let h4 := h1
    h3 – 左侧的 False 总是可以使用。 apply False.elim h4 – 我们已经证明了 (p1 → False)，现在证明 (p2 → False)。
    – 右侧的蕴含关系总是可以分解。 – 我们引入假设 h2 对 p2。并尝试证明 False。 intro h5 – 我们想使用假设 h1。于是我们展示它的前提。
    have h6 : (p1 ∨ p2) := by – 展示右侧的析取。 (左侧的析取会导致 TAE) apply Or.inr – 前提之一与结论一致。
    exact h5 – 我们已经证明了 h1 的前提 (p1 ∨ p2)， – 现在我们可以得出结论 (False)，用 h7 表示。 let h7 := h1
    h6 – 左侧的 False 总是可以使用。 apply False.elim h7'
- en: 'Figure 6: Lean Proof'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：精简证明
