- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 18:47:34'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-09-08 18:47:34'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'ComposerX: Multi-Agent Symbolic Music Composition with LLMs'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'ComposerX: 基于LLM的多智能体符号音乐创作'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2404.18081](https://ar5iv.labs.arxiv.org/html/2404.18081)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2404.18081](https://ar5iv.labs.arxiv.org/html/2404.18081)
- en: Qixin Deng⁵, Qikai Yang⁶, Ruibin Yuan¹, Yipeng Huang²,
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Qixin Deng⁵, Qikai Yang⁶, Ruibin Yuan¹, Yipeng Huang²,
- en: Yi Wang², Xubo Liu⁸, Zeyue Tian¹, Jiahao Pan¹, Ge Zhang⁹, Hanfeng Lin², Yizhi
    Li⁴, Yinghao Ma³,
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Yi Wang², Xubo Liu⁸, Zeyue Tian¹, Jiahao Pan¹, Ge Zhang⁹, Hanfeng Lin², Yizhi
    Li⁴, Yinghao Ma³,
- en: Jie Fu¹, Chenghua Lin⁴, Emmanouil Benetos³, Wenwu Wang⁸, Guangyu Xia⁷, Wei Xue¹,
    Yike Guo¹
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Jie Fu¹, Chenghua Lin⁴, Emmanouil Benetos³, Wenwu Wang⁸, Guangyu Xia⁷, Wei Xue¹,
    Yike Guo¹
- en: ¹Hong Kong University of Science and Technology
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ¹香港科技大学
- en: '![[Uncaptioned image]](img/408ffd2514dbc876ca931ee73e2722c4.png) ²Multimodal
    Art Projection Research Community'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![[无标题图像]](img/408ffd2514dbc876ca931ee73e2722c4.png) ²多模态艺术投影研究社区'
- en: ³Queen Mary University of London
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ³伦敦玛丽女王大学
- en: ⁴The University of Manchester
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ⁴曼彻斯特大学
- en: ⁵University of Rochester
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ⁵罗切斯特大学
- en: ⁶University of Illinois at Urbana-Champaign
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ⁶伊利诺伊大学香槟分校
- en: ⁷Mohamed bin Zayed University of Artificial Intelligence
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ⁷穆罕默德·本·扎耶德人工智能大学
- en: ⁸University of Surrey ⁹01.AI
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ⁸萨里大学 ⁹01.AI
- en: Abstract
  id: totrans-17
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Music composition represents the creative side of humanity, and itself is a
    complex task that requires abilities to understand and generate information with
    long dependency and harmony constraints. While demonstrating impressive capabilities
    in STEM subjects, current LLMs easily fail in this task, generating ill-written
    music even when equipped with modern techniques like In-Context-Learning and Chain-of-Thoughts.
    To further explore and enhance LLMs’ potential in music composition by leveraging
    their reasoning ability and the large knowledge base in music history and theory,
    we propose ComposerX¹¹1Demo page: https://lllindsey0615.github.io/ComposerX_demo/,
    an agent-based symbolic music generation framework. We find that applying a multi-agent
    approach significantly improves the music composition quality of GPT-4\. The results
    demonstrate that ComposerX is capable of producing coherent polyphonic music compositions
    with captivating melodies, while adhering to user instructions.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '音乐创作代表了人类创造力的一面，它本身是一个复杂的任务，需要理解和生成具有长期依赖性和和谐约束的信息的能力。尽管在STEM学科中展示了令人印象深刻的能力，但当前的LLM在这一任务中往往失败，即使采用了现代技术如上下文学习和链式思维，也会生成写得不佳的音乐。为了进一步探索和增强LLM在音乐创作中的潜力，通过利用它们的推理能力和丰富的音乐历史及理论知识库，我们提出了ComposerX¹¹1演示页面:
    https://lllindsey0615.github.io/ComposerX_demo/，这是一个基于智能体的符号音乐生成框架。我们发现，应用多智能体方法显著提高了GPT-4的音乐创作质量。结果表明，ComposerX能够生成连贯的复音音乐作品，并具有引人入胜的旋律，同时遵循用户指示。'
- en: 1 Introduction
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Music shares many structural similarities with language [[1](#bib.bib1), [2](#bib.bib2),
    [3](#bib.bib3)], prompting researchers to explore the application of language
    models (LMs) in music generation [[4](#bib.bib4), [5](#bib.bib5), [6](#bib.bib6),
    [7](#bib.bib7), [8](#bib.bib8), [9](#bib.bib9), [10](#bib.bib10), [11](#bib.bib11),
    [12](#bib.bib12), [13](#bib.bib13), [14](#bib.bib14)]. Recent advances in large
    language models (LLMs) have opened potential pathways towards achieving Artificial
    General Intelligence (AGI). While much of the research emphasis has been on the
    STEM aspects of AGI [[15](#bib.bib15), [16](#bib.bib16), [17](#bib.bib17)], there
    is comparatively less focus on its creative dimensions, particularly in music
    creation. Current methodologies primarily involve training LMs from scratch, as
    seen with initiatives like MusicLM [[9](#bib.bib9)] and MusicGen [[10](#bib.bib10)],
    with a predominant focus on audio generation. However, these models often struggle
    with processing advanced musical instructions and typically offer only limited
    control options, such as genre and instrument selection. Enhancing controllability
    in these systems requires neural architectural engineering and extensive computational
    resources [[18](#bib.bib18), [19](#bib.bib19), [20](#bib.bib20)].
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 音乐与语言有许多结构上的相似之处[[1](#bib.bib1), [2](#bib.bib2), [3](#bib.bib3)]，这促使研究人员探索语言模型（LMs）在音乐生成中的应用[[4](#bib.bib4),
    [5](#bib.bib5), [6](#bib.bib6), [7](#bib.bib7), [8](#bib.bib8), [9](#bib.bib9),
    [10](#bib.bib10), [11](#bib.bib11), [12](#bib.bib12), [13](#bib.bib13), [14](#bib.bib14)]。近年来，随着大型语言模型（LLMs）的进展，达成人工通用智能（AGI）的潜在路径也随之打开。虽然大多数研究重点集中在AGI的STEM（科学、技术、工程和数学）方面[[15](#bib.bib15),
    [16](#bib.bib16), [17](#bib.bib17)]，但对其创造性维度，特别是音乐创作的关注相对较少。目前的方法主要涉及从零开始训练语言模型，如MusicLM[[9](#bib.bib9)]和MusicGen[[10](#bib.bib10)]，主要关注于音频生成。然而，这些模型在处理复杂音乐指令时往往表现不佳，并且通常只能提供有限的控制选项，如音乐风格和乐器选择。提高这些系统的可控性需要神经结构工程和大量的计算资源[[18](#bib.bib18),
    [19](#bib.bib19), [20](#bib.bib20)]。
- en: Recent research, influenced by Bubeck et al. [[17](#bib.bib17)], has revealed
    that pretrained large language models (LLMs) might inherently possess emergent
    musical capabilities. Inspired by these findings, subsequent studies [[21](#bib.bib21),
    [22](#bib.bib22), [23](#bib.bib23)] have explored leveraging pretrained LLM checkpoints
    for handling symbolic music in an end-to-end manner, aiming to tap into the extensive
    knowledge and reasoning abilities embedded in these LLMs. However, these unified
    approaches are not without limitations. They depend heavily on hand-crafted datasets
    tailored for specific musical tasks and often require both a phase of continual
    pretraining and subsequent supervised fine-tuning. Furthermore, while training
    on symbolic music data is generally less computationally intensive than processing
    raw audio data, the costs remain prohibitive for many researchers. For example,
    renting an 8xGPU machine (such as a p4d.24xlarge spot instance on AWS) for one
    month can exceed $8,000 USD²²2https://instances.vantage.sh/aws/ec2/p4d.24xlarge,
    posing a significant financial barrier.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究受到Bubeck等人[[17](#bib.bib17)]的影响，揭示了预训练的大型语言模型（LLMs）可能天生具有突现的音乐能力。受到这些发现的启发，后续研究[[21](#bib.bib21),
    [22](#bib.bib22), [23](#bib.bib23)]探索了利用预训练LLM检查点以端到端的方式处理符号音乐，旨在挖掘这些LLM中蕴含的广泛知识和推理能力。然而，这些统一的方法也并非没有局限。它们严重依赖于针对特定音乐任务量身定制的手工数据集，并且通常需要经历持续的预训练阶段和随后的监督微调。此外，尽管对符号音乐数据的训练通常比处理原始音频数据的计算负担小，但其成本仍对许多研究人员构成高昂的财务障碍。例如，租用一台8xGPU机器（如AWS上的p4d.24xlarge临时实例）一个月的费用可能超过8,000美元²²2https://instances.vantage.sh/aws/ec2/p4d.24xlarge，这对许多研究人员来说是一个显著的经济障碍。
- en: 'In this paper, we introduce a novel multi-agent-based methodology, ComposerX³³3https://github.com/lllindsey0615/ComposerX,
    which is training-free, cheap, and unified. Leveraging the internal musical capabilities
    of the state-of-the-art GPT-4-turbo, ComposerX can generate polyphonic music pieces
    of comparable, if not superior, quality to those produced by dedicated symbolic
    music generation systems[[7](#bib.bib7), [24](#bib.bib24)] that require extensive
    computational resources and data. ComposerX utilizes approximately 26k tokens
    per song, incurring a cost of less than $0.8 USD per piece. Throughout the development
    phase of ComposerX, the total expenditure on the OpenAI API was under $1k USD.
    We achieved a good case rate of 18.4%, as assessed by music experts, which translates
    to an average cost of approximately $4.34 USD for each musically interesting piece.
    Furthermore, experimental results demonstrate that the multi-agent strategy substantially
    enhances composition quality over single-agent baselines. In Turing tests, approximately
    32.2% of the pieces identified as ‘good’ by ComposerX were indistinguishable from
    those composed by humans, as indicated in Table [7](#S3.T7 "Table 7 ‣ 3.3 Results
    ‣ 3 Experiments ‣ ComposerX: Multi-Agent Symbolic Music Composition with LLMs").'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '在本文中，我们介绍了一种新颖的基于多智能体的方法论——ComposerX³³3https://github.com/lllindsey0615/ComposerX，这种方法无需训练、成本低廉且统一。利用最先进的GPT-4-turbo的内部音乐能力，ComposerX可以生成质量媲美甚至优于那些需要大量计算资源和数据的专用符号音乐生成系统[[7](#bib.bib7),
    [24](#bib.bib24)]的多声部音乐作品。每首歌曲使用约26k个token，成本低于$0.8美元。在ComposerX的开发阶段，总花费在OpenAI
    API上的费用不到$1k美元。音乐专家评估的良好案例率为18.4%，这意味着每个具有音乐趣味的作品的平均成本约为$4.34美元。此外，实验结果表明，多智能体策略在音乐创作质量上显著优于单智能体基准。在图灵测试中，约32.2%的被ComposerX标识为“好”的作品与人类创作的作品无法区分，详细信息见表[7](#S3.T7
    "Table 7 ‣ 3.3 Results ‣ 3 Experiments ‣ ComposerX: Multi-Agent Symbolic Music
    Composition with LLMs")。'
- en: 'While there is existing research on musical LLM agents [[25](#bib.bib25), [26](#bib.bib26)],
    our approach distinctively diverges from these precedents. Prior studies primarily
    focus on single-agent systems. In contrast, our work introduces a multi-agent
    framework, emphasizing collaborative aspects of music creation. Furthermore, we
    concentrate on symbolic music generation, leveraging the intrinsic musical understanding
    of LLMs without the need for external computational resources or tools. Previous
    methodologies typically depend on GPU servers for deploying local inference services,
    treating the LLMs more as tool-use agents rather than harnessing their inherent
    capabilities to process and generate musical content. In sum, the contributions
    of our paper are as follows:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管已有关于音乐LLM智能体的研究[[25](#bib.bib25), [26](#bib.bib26)]，但我们的方法与这些前例明显不同。以往研究主要集中于单智能体系统。而我们的工作引入了一个多智能体框架，强调音乐创作的协作方面。此外，我们专注于符号音乐生成，利用LLMs的内在音乐理解，而无需外部计算资源或工具。之前的方法通常依赖于GPU服务器来部署本地推理服务，将LLMs更多视为工具使用智能体，而不是利用它们内在的能力来处理和生成音乐内容。总之，我们论文的贡献如下：
- en: (1) We propose the first multi-agent polyphonic symbolic music composition system,
    ComposerX. It elicits the internal musical capabilities inside LLMs without the
    need for external tools.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: (1) 我们提出了第一个多智能体多声部符号音乐创作系统——ComposerX。它能够激发LLMs内部的音乐能力，而无需外部工具。
- en: (2) Through extensive subjective evaluations, we demonstrate that our multi-agent
    approach substantially enhances the quality of music composition compared to single-agent
    systems and specialized music generation models. Our method also offers cost-efficiency
    advantages by obviating the need for dedicated training or local inference services.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: (2) 通过广泛的主观评估，我们证明了与单智能体系统和专业音乐生成模型相比，我们的多智能体方法显著提升了音乐创作的质量。我们的方法还具有成本效益优势，因为它不需要专用的训练或本地推理服务。
- en: (3) We commit to the advancement of this research area by open-sourcing our
    code, prompt-set, and experimental results, facilitating further investigation
    and development by the community.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: (3) 我们承诺通过开源我们的代码、提示集和实验结果来推动这一研究领域的进展，方便社区进行进一步的调查和开发。
- en: 2 Method
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 方法
- en: We first construct a set of user prompts for music composition, which is used
    for evaluation. Then we demonstrate how we implement our single-agent and multi-agent
    LLM composition systems.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先构建了一组用于音乐创作的用户提示，用于评估。然后我们展示了如何实现我们的单智能体和多智能体LLM创作系统。
- en: 2.1 User Prompt Set Curation
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 用户提示集整理
- en: To understand how the users, typically those with substantial musical backgrounds,
    would prompt a text-to-music generation system, a user prompt set is collected
    by asking humans with music backgrounds to manually write high-quality prompts.
    These prompts typically include essential musical attributes such as genre, tempo,
    key, chord progression, melody, rhythm, number of bars, number of voices, instruments,
    style, feeling, emotion, title, and motif of the music piece. Based on the human-written
    samples, more prompt samples are generated using Self-instruct by GPT-4[[27](#bib.bib27)].
    This results in a set of 163 prompts, which is used in the later agent testing
    and system evaluation. An example prompt is given below.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解具有丰富音乐背景的用户如何提示文本到音乐生成系统，收集了一组用户提示集，通过请有音乐背景的人手动编写高质量的提示。这些提示通常包括诸如流派、速度、调性、和弦进行、旋律、节奏、拍数、声部数量、乐器、风格、感觉、情感、标题和音乐主题等基本音乐属性。基于这些人工编写的样本，使用
    GPT-4 的 Self-instruct 生成了更多的提示样本[[27](#bib.bib27)]。最终得到一组 163 个提示，用于后续的代理测试和系统评估。以下是一个示例提示。
- en: 'Prompt
    Vintage French Chanson: A nostalgic chanson in C major with a
    slow tempo, featuring accordion, violin, and upright bass over 16 bars with chords
    C, Am, Dm, G. The accordion leads with expressive sound, violin adds romance,
    and the upright bass supports, evoking vintage French charm.Attributes
    Name: Vintage French Chanson Tempo: Slow Feeling: Nostalgic Chord
    Progression: C, Am, Dm, G Key: C major   Bars: 16   Instruments: Accordion, violin,
    upright bass'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 提示 复古法式香颂：一首
    C 大调的怀旧香颂，速度缓慢，包含手风琴、小提琴和立式低音，持续 16 小节，和弦为 C、Am、Dm、G。手风琴引领，声音表现丰富，小提琴增添浪漫，立式低音提供支持，唤起复古法式魅力。属性 名称：复古法式香颂
    速度：缓慢 感觉：怀旧 和弦进行：C、Am、Dm、G 调性：C 大调 小节数：16 乐器：手风琴、小提琴、立式低音
- en: 2.2 Single-Agent
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 单代理
- en: We apply various prompt engineering techniques, including In Context Learning
    (ICL), Chain of Thought (CoT), and Role-play to guide a single GPT acting as the
    composer. Additionally, we have refined the prompt template by incorporating specific
    instructions that ensure the correctness of the ABC notation format.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用了各种提示工程技术，包括上下文学习（ICL）、思维链（CoT）和角色扮演，以指导一个作为作曲家的 GPT。此外，我们还通过加入特定的指令来精炼提示模板，以确保
    ABC 符号格式的正确性。
- en: 'Original GPT with Simple Role-play (Ori): To investigate the inherent capabilities
    of the original GPT model in interpreting user prompts and generating ABC notation,
    we instructed GPT to act in the role of a professional composer, with user prompts
    directly input into the system. This method aims to assess the model’s basic performance
    in music composition without the integration of additional complex prompting techniques.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 原始 GPT 简单角色扮演（原版）：为了调查原始 GPT 模型在解读用户提示和生成 ABC 记谱法方面的固有能力，我们指示 GPT 扮演专业作曲家的角色，将用户提示直接输入系统。此方法旨在评估模型在音乐创作中的基本表现，而不集成额外复杂的提示技术。
- en: 'Role-Play with Additional Instruction (Role): Inspired by classical rule-based
    computer music generation, we equipped GPT with enhanced musical knowledge focusing
    on phrase management and melody line construction, detailed in Table [1](#S2.T1
    "Table 1 ‣ 2.2 Single-Agent ‣ 2 Method ‣ ComposerX: Multi-Agent Symbolic Music
    Composition with LLMs"). For instance, in composing melodies, we instructed the
    model to ensure that each generated melody possesses distinct phrase divisions.
    Additionally, each phrase is required to conclude with a prominent ending note,
    which serves as the last note of the phrase. By incorporating these additional
    instructions, we aim to elevate the music quality and structural coherence of
    the music, aligning the generated compositions more closely with traditional musical
    standards.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '角色扮演与附加指令（角色）：受到经典规则驱动计算机音乐生成的启发，我们为GPT提供了增强的音乐知识，专注于乐句管理和旋律线构建，详见表 [1](#S2.T1
    "表 1 ‣ 2.2 单一角色 ‣ 2 方法 ‣ ComposerX: 多智能体符号音乐创作与LLMs")。例如，在创作旋律时，我们指示模型确保每个生成的旋律具有明显的乐句分段。此外，每个乐句要求以显著的结束音符收尾，作为乐句的最后一个音符。通过这些附加指令，我们旨在提高音乐的质量和结构一致性，使生成的作品更符合传统音乐标准。'
- en: '| Role-play Prompting with Additional Music Knowledge |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 角色扮演附加音乐知识提示 |'
- en: '| You are a talented musician. Here are some tips for generating melodies:
    1\. The generated melody should have clear phrase divisions, and it’s preferable
    to avoid more than two consecutive measures within one phrase to prevent an uncomfortable
    listening experience. There should be a certain amount of space between phrases,
    allowing the audience to clearly distinguish between them. 2\. A phrase usually
    has a prominent ending note, which is the last note of the entire phrase. It typically
    has a longer duration, or it might be followed by a rest. This ending note is
    usually within the key or the chord, e.g., phrases ending with a Cmaj chord usually
    terminate on one of the three chord tones, C, E, or G, ensuring a stable listening
    experience. 3\. When generating melodies, the movement of the notes should primarily
    consist of stable intervals such as whole steps, thirds, and fifths, while avoiding
    excessive large leaps. This will help maintain a sense of logic and coherence
    throughout the composition. 4\. The rhythm of the phrases should be rich and harmonious.
    Try using different rhythmic patterns to build the melody, such as combining eighth
    notes with sixteenth notes, syncopated rhythms, or triplets. |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 你是一位才华横溢的音乐家。以下是生成旋律的一些提示：1\. 生成的旋律应具有清晰的乐句分段，最好避免在一个乐句中出现超过两个连续小节，以防听感不适。乐句之间应有一定的间隔，使听众能够清楚地区分。2\.
    一个乐句通常有一个显著的结束音符，即整个乐句的最后一个音符。它通常有较长的时值，或者可能后跟一个休止符。这个结束音符通常在调性或和弦中，例如，乐句以C大调和弦结束时，通常以C、E或G中的一个音符结束，以确保稳定的听感体验。3\.
    生成旋律时，音符的运动应主要由稳定的音程组成，如全音、三度和五度，同时避免过大的跳跃。这将有助于保持作品的逻辑性和连贯性。4\. 乐句的节奏应丰富而和谐。尝试使用不同的节奏模式来构建旋律，如将八分音符与十六分音符、切分音节奏或三连音结合使用。
    |'
- en: 'Table 1: Single-agent role-play(indicated in the blue text) prompting with
    additional tips given by human composer on melody construction.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：单一角色扮演（以蓝色文字标示）与由人类作曲家提供的关于旋律构建的额外提示。
- en: 'Chain-of-Thought (CoT): As proven in other fields of research, CoT improves
    the ability of LLMs on complex reasoning by encouraging them to write down intermediate
    reasoning steps[[28](#bib.bib28)]. Within the context of music composition, we
    deconstruct the music generation process into several distinct stages. These stages
    include specifying initial music information, such as title, key, tempo, and speed,
    followed by the development of chord progressions and melody composition as detailed
    in Table [2](#S2.T2 "Table 2 ‣ 2.2 Single-Agent ‣ 2 Method ‣ ComposerX: Multi-Agent
    Symbolic Music Composition with LLMs").'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '连锁思维（CoT）：正如在其他研究领域中所证明的那样，CoT通过鼓励LLMs记录中间推理步骤，从而提高了其在复杂推理任务中的能力[[28](#bib.bib28)]。在音乐创作的背景下，我们将音乐生成过程分解为几个不同的阶段。这些阶段包括指定初始音乐信息，如标题、调性、节奏和速度，然后是和弦进行和旋律创作，详细信息见表[2](#S2.T2
    "Table 2 ‣ 2.2 Single-Agent ‣ 2 Method ‣ ComposerX: Multi-Agent Symbolic Music
    Composition with LLMs")。'
- en: '| Chain of Thought prompting with three steps |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 连锁思维提示法，共三步骤 |'
- en: '| First, you need to determine all the information related to the piece in
    the ABC notation format, such as the name,tune, speed, mode, and anything other
    than the notes. This forms the basis of the piece’s style.***Note that only return
    the music information in ABC notation format without any notes or text or Additional
    note.*** Second,Based on the song information in the ABC notation format provided
    earlier, generate a ***16-bar long*** chord progression and return it in text
    form, with each bar separated by a "&#124;" symbol. The generated chord progression
    should be consistent with the song’s key and as closely aligned with the song’s
    theme and characteristics as possible. Now the chord progression and other information
    are provided,you are required to create a ***16-bar long*** piece of music based
    on these information. |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 首先，你需要确定与乐曲相关的所有信息，采用ABC记谱法格式，如名称、旋律、速度、调式以及任何其他与音符无关的信息。这构成了乐曲风格的基础。***注意只返回ABC记谱法格式的音乐信息，不包含任何音符、文本或附加说明。***
    其次，根据之前提供的ABC记谱法格式的歌曲信息，生成一个***16小节长***的和弦进行，并以文本形式返回，每小节用"&#124;"符号分隔。生成的和弦进行应与歌曲的调性一致，并尽可能贴合歌曲的主题和特点。现在和弦进行及其他信息已提供，你需要根据这些信息创作一段***16小节长***的音乐。|'
- en: 'Table 2: Single-agent CoT prompting method with three steps.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：单代理CoT提示方法，共三步骤。
- en: 'In Context Learning (ICL): ICL leverages a few input-output examples to enhance
    an LLM’s understanding of a specific task. In this method, we use pairs of user
    prompts and corresponding ABC notations from ChatMusician[[21](#bib.bib21)] as
    demonstrative examples for prompting as detailed in Table [3](#S2.T3 "Table 3
    ‣ 2.2 Single-Agent ‣ 2 Method ‣ ComposerX: Multi-Agent Symbolic Music Composition
    with LLMs").'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '上下文学习（ICL）：ICL利用少量的输入输出示例来增强LLM对特定任务的理解。在这种方法中，我们使用ChatMusician[[21](#bib.bib21)]中的用户提示和相应ABC记谱法的配对作为提示示例，详细信息见表[3](#S2.T3
    "Table 3 ‣ 2.2 Single-Agent ‣ 2 Method ‣ ComposerX: Multi-Agent Symbolic Music
    Composition with LLMs")。'
- en: '| Single-agent In-context learning prompting method |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 单代理上下文学习提示方法 |'
- en: '| You are an intelligent agent with musical intelligence, and your goal is
    to create music that meets the relevant needs and human listening habits.In this
    task, use ABC as the format for outputting sheet music.***Only return the ABC
    notation without any other description or text,and only return one piece that
    follow the music description given this time.***Below are the requirements for
    the music,it contains music elements like title,genre,key and more,and some composition
    examples are listed after the requirements. ABC Notation of the selected sample
    |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 你是一个具有音乐智能的智能代理，你的目标是创作符合相关需求和人类听觉习惯的音乐。在这个任务中，使用ABC作为输出乐谱的格式。***仅返回ABC记谱法，不附带其他描述或文本，并且仅返回一段符合本次音乐描述的乐曲。***以下是音乐要求，包括标题、流派、调性等音乐元素，要求后列出了一些作曲示例。所选样本的ABC记谱法
    |'
- en: 'Table 3: Single-agent In-context learning prompting method'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：单代理上下文学习提示方法
- en: '2.3 Multi-Agent Music Composition: ComposerX'
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 多代理音乐创作：ComposerX
- en: To enhance the music generation capabilities of GPT-4, we developed a collaborative
    music creation framework, ComposerX, that draws inspiration from key elements
    inherent in real-world music composition processes, such as melody construction,
    harmony or counterpoint development, and instrumentation. This framework facilitates
    the music creation process through a structured conversation chain between agents
    role-played by GPT-4.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提升GPT-4的音乐生成能力，我们开发了一个协作音乐创作框架ComposerX，该框架从现实世界音乐创作过程中的关键元素（如旋律构建、和声或对位发展以及乐器配置）中汲取灵感。该框架通过GPT-4扮演的代理之间的结构化对话链来促进音乐创作过程。
- en: 2.3.1 Agent Role Assignment
  id: totrans-49
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.1 代理角色分配
- en: 'In the collaborative music creation framework designed to augment GPT-4’s music
    generation capabilities, roles are assigned to ensure a structured and efficient
    composition process. The assignment of roles is as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在旨在增强GPT-4音乐生成能力的协作音乐创作框架中，角色被分配以确保一个结构化和高效的作曲过程。角色分配如下：
- en: 'Group Leader: Tasked with interpreting user inputs, decomposing these inputs
    into granular tasks, and assigning these tasks to specialized agents in the group.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 组长：负责解释用户输入，将这些输入分解为具体任务，并将这些任务分配给组内的专业代理。
- en: 'Melody Agent: Responsible for generating single-line melodies under the guidance
    of the group leader.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 旋律代理：负责在组长的指导下生成单线旋律。
- en: 'Harmony Agent: This agent is tasked with enriching the musical piece, and adds
    harmonic and contrapuntal elements to the melody.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 和声代理：该代理负责丰富音乐作品，为旋律添加和声和对位元素。
- en: Instrument Agent:This agent selects and assigns instruments to each voice.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 工具代理：该代理负责为每个声音选择和分配乐器。
- en: 'Reviewer Agent:Performing a quality assurance role, this agent evaluates the
    outputs of the melody, harmony, and instrumentation agents across four critical
    dimensions. (1)Melodic Structure: Evaluation of melody’s narrative flow, thematic
    development, and variation in pitch and rhythm. Harmony and Counterpoint: Assessment
    of how harmonies complement the melody, counterpoint effectiveness, and chord
    progression quality. (2)Rhythmic Complexity: Analysis of rhythm’s role in sustaining
    interest, its synergy with melody, and the incorporation of dynamic variations.
    (3)Instrumentation and Timbre: Review of instrument selection, timbral blending,
    and dynamic usage to achieve an optimal auditory experience. (4)Form and Structure:
    Examination of the composition’s overarching structure, transitional elements,
    connectivity between sections, and conclusion efficacy.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 审核代理：执行质量保证角色，该代理评估旋律、和声和乐器代理的输出，评估的四个关键维度如下：（1）旋律结构：评估旋律的叙事流动、主题发展以及音高和节奏的变化；和声与对位：评估和声对旋律的补充程度，对位效果以及和弦进行的质量；（2）节奏复杂性：分析节奏在维持兴趣中的作用、与旋律的协同作用以及动态变化的融入；（3）乐器和音色：审查乐器选择、音色融合以及动态使用，以实现最佳的听觉体验；（4）形式和结构：检查作品的整体结构、过渡元素、各部分之间的连贯性以及结尾的有效性。
- en: 'Arrangement Agent: Concluding the collaborative process, this agent is responsible
    for compiling and formatting the collective output into standardized ABC notation,
    ensuring the music is documented in a universally readable format.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 编排代理：在协作过程的最后阶段，负责将集体成果汇总和格式化为标准化的ABC记谱法，确保音乐以通用的可读格式记录。
- en: 2.3.2 Agent Communication Pattern
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.2 代理沟通模式
- en: 'The collaborative framework employs a structured communication pattern to ensure
    an orderly and efficient flow of information between the different agents involved
    in the composition process. This pattern is crucial for maintaining the integrity
    and coherence of the musical piece being generated. The communication process
    unfolds as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 协作框架采用结构化的沟通模式，以确保参与作曲过程的不同代理之间信息的有序和高效流动。这个模式对于保持生成音乐作品的完整性和连贯性至关重要。沟通过程如下：
- en: 'Initial Composition Round: The composition process begins with the Group Leader
    Agent initiating the sequence by analyzing the user input and breaking it down
    into specific tasks assigned to the Melody, Harmony, and Instrument Agents respectively.
    This step sets the foundation for the composition based on the user’s requirements.
    Following the leader’s instructions, the Melody Agent then generates the initial
    melody line, adhering to the thematic direction and stylistic guidelines provided
    by the Group Leader. Subsequently, the Harmony Agent enriches the melody by adding
    harmonic layers and counterpoints. The Instrument Agent assigns appropriate instruments
    to the generated melody and harmony lines by selecting timbres that complement
    the overall composition.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 初步作曲阶段：作曲过程由组长代理人开始，他通过分析用户输入并将其分解为分配给旋律、和声和乐器代理人的具体任务来启动序列。这一步为根据用户要求的作曲奠定了基础。遵循组长的指示，旋律代理人生成初步的旋律线，遵循组长提供的主题方向和风格指南。随后，和声代理人通过添加和声层次和对位来丰富旋律。乐器代理人则为生成的旋律和和声线分配合适的乐器，通过选择与整体作曲相辅相成的音色来完成任务。
- en: 'Iterative Review and Feedback Cycle: Upon completion of the initial composition
    round, the Reviewer Agent steps in to evaluate the work produced by the Melody,
    Harmony, and Instrument Agents. This agent provides comprehensive feedback across
    several critical dimensions, including melodic structure, harmony and counterpoint,
    rhythmic complexity, and instrumentation.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代审查与反馈周期：初步作曲阶段完成后，审稿代理人介入评估旋律、和声和乐器代理人制作的作品。该代理人从多个关键维度提供全面反馈，包括旋律结构、和声与对位、节奏复杂性和编曲。
- en: 'Based on the feedback from the Reviewer Agent, the Melody, Harmony, and Instrument
    Agents proceed to refine their respective components of the composition. This
    iterative refinement process typically follows the order: Melody, Harmony, and
    then Instrument, allowing for modifications to be made in response to the feedback
    provided.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 根据审稿代理人的反馈，旋律、和声和乐器代理人继续完善作曲的各自部分。此迭代修订过程通常遵循旋律、和声，然后是乐器的顺序，以便根据提供的反馈进行修改。
- en: The composition undergoes several rounds of review and refinement, with the
    Reviewer Agent continuously providing feedback to ensure the musical piece evolves
    toward a coherent and high-quality final product. This iterative process allows
    for dynamic adjustments and enhancements to be made, enriching the overall composition.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 作曲经过几轮审查和修订，审稿代理人持续提供反馈，以确保音乐作品向一致性和高质量的最终产品发展。这一迭代过程允许进行动态调整和改进，从而丰富整体作曲。
- en: 'Final Arrangement and Notation: Once the composition has reached a satisfactory
    level of polish and coherence, the Arrangement Agent takes over to compile and
    format the collective output into the standardized ABC notation. This final step
    ensures that the music is documented in a format that is readable and can be interpreted
    by musicians and software alike.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 最终编排与记谱：一旦作曲达到令人满意的抛光和一致性水平，编排代理人接手，将集体输出整理成标准的ABC记谱法。此最后一步确保音乐以可读的格式记录，并且可以被音乐家和软件解读。
- en: This communication pattern enables a collaborative and adaptive approach to
    music generation. The primary advantage of this communication pattern lies in
    its ability to simulate a real-world collaborative music creation environment,
    where each participant’s input is valued and considered in the development of
    the final piece. Integrating this structured approach with a multi-agent system
    significantly reduces the likelihood of LLM hallucination, a notable challenge
    where models may generate inaccurate or nonsensical outputs. By assigning specific
    roles to specialized agents, the framework ensures that each segment of the music
    composition undergoes rigorous scrutiny and refinement. This division of labor
    not only enhances the precision and relevance of the generated content but also
    leverages the collective intelligence of the agents to cross-verify information,
    thereby mitigating the risk of incorporating erroneous elements into the composition.
    An example of the music composition process is given in Figure 1 and Figure 2
    with a comparison made between
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这种通信模式实现了协作和适应性的音乐生成方法。这种通信模式的主要优势在于它能够模拟现实世界的协作音乐创作环境，在这个环境中，每个参与者的意见都受到重视，并在最终作品的发展中被考虑。将这种结构化的方法与多代理系统结合起来，显著降低了LLM幻觉的可能性，这是一种模型可能生成不准确或无意义输出的显著挑战。通过将特定角色分配给专业代理，该框架确保音乐创作的每个部分都经过严格的审查和完善。这种劳动分工不仅提高了生成内容的精确性和相关性，还利用代理的集体智慧进行交叉验证，从而减少将错误元素纳入作品的风险。音乐创作过程的示例见图1和图2，并进行了比较。
- en: '![Refer to caption](img/af3e3d9e12675624588494aa5b9395f6.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/af3e3d9e12675624588494aa5b9395f6.png)'
- en: 'Figure 1: The Leader Agent will distribute the tasks among the Melody Agent,
    Harmony Agent, Instrumentation Agent when it is requested a "Breezy Caribbean
    Calypso" piece. This figure demonstrates the work of the three agents with changes
    in the same four bar opening.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：当领导代理收到“清爽的加勒比海卡利普索”曲目请求时，将任务分配给旋律代理、和声代理和编配代理。此图展示了三个代理在相同的四小节开头中的工作变化。
- en: '![Refer to caption](img/0e0a4d17138445171d5d983529b493a0.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0e0a4d17138445171d5d983529b493a0.png)'
- en: 'Figure 2: The Reviewer Agent then analyze the collective effort of the three
    agents in the first stage (shown in Figure [2](#S2.F2 "Figure 2 ‣ 2.3.2 Agent
    Communication Pattern ‣ 2.3 Multi-Agent Music Composition: ComposerX ‣ 2 Method
    ‣ ComposerX: Multi-Agent Symbolic Music Composition with LLMs")), and give advice
    for agents to work on. This figure demonstrates the work of the three agents after
    incorporating the advice given by the Reviewer Agent in the same four-bar opening.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：然后审查代理分析三个代理在第一阶段的集体努力（见图[2](#S2.F2 "图2 ‣ 2.3.2 代理通信模式 ‣ 2.3 多代理音乐作曲：ComposerX
    ‣ 2 方法 ‣ ComposerX：具有LLMs的多代理符号音乐作曲")），并给出建议供代理们改进。此图展示了三个代理在采纳审查代理建议后的工作情况，仍然使用相同的四小节开头。
- en: '![Refer to caption](img/6d3a08a14969205670b2083e2d9d19f4.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/6d3a08a14969205670b2083e2d9d19f4.png)'
- en: 'Figure 3: Agent Communication Pattern of ComposerX.The system is given with
    a user prompt. In the Planning stage, the Leader analyzes the user prompt and
    decomposes it into subtasks that can be assigned to other musician agents. In
    the Composing stage, the musician agents, including Melody Agent, Harmony Agent,
    and Instrument Agent compose in ABC notation according to their assigned tasks.
    In the Reviewing stage, the Review Agent provides constructive feedback to the
    musician agents and the musician agents revise their work according to the feedback
    they received. In the arrangement stage, the Arrangement Agent arranges the work
    of the musicians agent to standardized ABC notation.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：ComposerX的代理通信模式。系统接收到用户提示。在规划阶段，领导者分析用户提示，并将其分解为可以分配给其他音乐代理的子任务。在作曲阶段，包括旋律代理、和声代理和乐器代理在内的音乐代理根据分配的任务以ABC记谱法进行作曲。在审查阶段，审查代理向音乐代理提供建设性的反馈，音乐代理根据收到的反馈对其作品进行修订。在编排阶段，编排代理将音乐代理的作品编排为标准化的ABC记谱法。
- en: 2.3.3 Agent Prompt Engineering
  id: totrans-71
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.3 代理提示工程
- en: 'Agent prompt engineering emerges as a crucial technique for optimizing the
    performance of each specialized agent and the quality of the generated music.
    This process involves the meticulous design of role-specific instructions and
    guidelines that encapsulate both the musicality and technicality of ABC notation
    generation. The framework incorporates In-Context Learning for ABC notations to
    ensure agents can effectively communicate and document their contributions. An
    example of the agent prompt is given in Table [4](#S2.T4 "Table 4 ‣ 2.3.3 Agent
    Prompt Engineering ‣ 2.3 Multi-Agent Music Composition: ComposerX ‣ 2 Method ‣
    ComposerX: Multi-Agent Symbolic Music Composition with LLMs"). This section elaborates
    on these components and their significance in fostering collaborative dynamics
    within the framework.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 代理提示工程作为一种关键技术，旨在优化每个专业代理的表现和生成音乐的质量。这个过程涉及对角色特定指令和指导方针的精细设计，涵盖了ABC记谱法生成的音乐性和技术性。该框架采用了ABC记谱法的上下文学习，以确保代理能够有效地交流和记录他们的贡献。代理提示的示例见表格[4](#S2.T4
    "表4 ‣ 2.3.3 代理提示工程 ‣ 2.3 多代理音乐创作：ComposerX ‣ 2 方法 ‣ ComposerX：多代理符号音乐创作与LLMs")。本节详细阐述了这些组件及其在促进框架内协作动态中的重要性。
- en: 'Role-Specific Instructions: Within the framework, each agent is endowed with
    a set of instructions tailored to its designated role. These instructions serve
    to ensure a comprehensive understanding of the agent’s duties, the expectations
    for its performance, and its role within the larger collaborative ensemble. Agents
    are briefed on the specific outcomes they are expected to achieve and informed
    about the dynamics of their interactions with other agents. This detailed prompt
    design facilitates a cohesive operation among the agents, fostering an environment
    where each component of the framework is aligned toward the collective goal of
    generating sophisticated and coherent musical compositions.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 角色特定指令：在框架内，每个代理都被赋予了一套针对其指定角色的指令。这些指令旨在确保对代理职责的全面理解、对其表现的期望以及其在更大协作体系中的角色。代理会被简要介绍他们预期实现的具体结果，并了解他们与其他代理的互动动态。这种详细的提示设计促进了代理之间的协调操作，营造了一个使框架中每个组件朝着生成复杂而连贯的音乐作品的共同目标对齐的环境。
- en: 'In-Context Learning for ABC Notation: In Context Learning for ABC notation
    ensures accurate format output from each agent. The Melody Agent is shown with
    an example of a monophonic melody in ABC notation, providing a clear model for
    representing single-line melodies. The Harmony Agent receives a polyphonic music
    piece example in ABC notation, aiding in understanding the notation of harmonies
    and counterpoints in multiple voices. The Instrument Agent is given a polyphonic
    piece with MIDI program information noted, demonstrating how to detail instrumental
    assignments within the notation. This approach equips agents with the knowledge
    to correctly apply ABC notation, essential for the structured and coherent documentation
    of musical compositions.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ABC记谱法的上下文学习：ABC记谱法的上下文学习确保每个代理的格式输出准确。旋律代理展示了一个ABC记谱法的单声部旋律示例，为表示单行旋律提供了清晰的模型。和声代理则收到一个包含和声和对位的多声部ABC记谱法音乐示例，帮助理解和声和对位的记谱。乐器代理获得一个带有MIDI程序信息的多声部音乐示例，展示了如何在记谱中详细说明乐器分配。这种方法为代理提供了正确应用ABC记谱法的知识，对音乐创作的结构化和连贯记录至关重要。
- en: '| Melody Agent Prompt |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 旋律代理提示 |'
- en: '| You are a skillful musician, especially in writing melody. You will compose
    a single-line melody based on the client’s request and assigned tasks from the
    Leader. You must output your work in ABC Notations. Here is a template of a music
    piece in ABC notation, in this template: X:1 is the reference number. You can
    increment this for each new tune. T:Title is where you’ll put the title of your
    tune. C:Composer is where you’ll put the composer’s name. M:4/4 sets the meter
    to 4/4 time, but you can change this as needed. L:1/8 sets the default note length
    to eighth notes. K:C sets the key to C Major. Change this to match your desired
    key. The music notation follows, with &#124;: and :&#124; denoting the beginning
    and end of repeated sections. Markdown your work using ‘‘‘ ‘‘‘ to the client.
    ‘‘‘ X:1 T:Title C:Composer M:Meter L:Unit note length K:Key &#124;:GABc d2e2&#124;f2d2
    e4&#124;g4 f2e2&#124;d6 z2:&#124; &#124;:c2A2 B2G2&#124;A2F2 G4&#124;E2c2 D2B,2&#124;C6
    z2:&#124; ‘‘‘ You will output the melody following this template, but decide the
    time signature, key signature, and the actual musical contents and length yourself.
    After you receive the feedback from the Reviewer Agent, please improve your work
    according to the suggestions you were given. |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 你是一个技艺高超的音乐家，特别擅长创作旋律。你将根据客户的要求和领导者分配的任务创作一段单线旋律。你必须使用 ABC 记谱法输出你的作品。这里是
    ABC 记谱法的音乐片段模板，在这个模板中：X:1 是参考编号。你可以为每个新旋律递增这个编号。T:Title 是你放置旋律标题的地方。C:Composer
    是你放置作曲者姓名的地方。M:4/4 将节拍设置为 4/4 拍，但你可以根据需要更改。L:1/8 将默认音符长度设置为八分音符。K:C 将调性设置为 C 大调。根据你的需要更改这个设置。音乐记谱法如下，&#124;:
    和 :&#124; 表示重复部分的开始和结束。使用‘‘‘ ‘‘‘ 对你的工作进行 Markdown 标记。‘‘‘ X:1 T:Title C:Composer
    M:Meter L:Unit note length K:Key &#124;:GABc d2e2&#124;f2d2 e4&#124;g4 f2e2&#124;d6
    z2:&#124; &#124;:c2A2 B2G2&#124;A2F2 G4&#124;E2c2 D2B,2&#124;C6 z2:&#124; ‘‘‘
    你将根据这个模板输出旋律，但需要自己决定拍号、调号以及实际的音乐内容和长度。在收到审查代理的反馈后，请根据给出的建议改进你的作品。'
- en: 'Table 4: Prompt for Melody Agent. GPT is prompted with role-specific instructions(indicated
    in blue text) and In-Context-Learning of ABC notations(indicated in red text)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：旋律代理的提示。GPT 被提示以角色特定的指令（以蓝色文本标示）和 ABC 记谱法的 In-Context-Learning（以红色文本标示）
- en: 3 Experiments
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 实验
- en: 3.1 Setup
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 设置
- en: Our experiment leverages the multi-agent conversation provided by the AutoGen
    framework[[29](#bib.bib29)], utilizing its group chat function to facilitate a
    customized interaction among pre-defined agents. This setup comprises an ensemble
    of agents including one leader, three musician agents (melody, harmony, and instrument
    agents), one review agent, and one arrangement agent. Additionally, a user proxy
    agent is integrated into the framework to simulate user interaction by inputting
    prompts from our curated user prompt set.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实验利用 AutoGen 框架提供的多代理对话[[29](#bib.bib29)]，利用其群组聊天功能来促进预定义代理之间的定制互动。该设置包括一个领导者、三个音乐代理（旋律、和声和乐器代理）、一个审查代理和一个编排代理。此外，用户代理被集成到框架中，通过从我们精心策划的用户提示集中输入提示来模拟用户交互。
- en: 'We employ the "GroupChatManager" class from AutoGen to ensure seamless coordination
    and oversight of the conversation’s content and workflow. According to AutoGen,
    the group manager is also powered by LLMs, functions as the supervisor of the
    conversation, and implements a structured communication protocol that involves
    three critical steps: dynamically selecting a speaker from the agents, collecting
    the response from the chosen agent, and disseminating the collected response to
    the rest of the group.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 AutoGen 的“GroupChatManager”类来确保对对话内容和工作流程的无缝协调和监督。根据 AutoGen 的说法，群组经理也由
    LLMs 提供支持，充当对话的监督者，并实施一个结构化的通信协议，该协议包括三个关键步骤：从代理中动态选择一个发言人，收集所选代理的回应，然后将收集到的回应传播给其他组员。
- en: For the purpose of our experiment, we have predetermined a maximum number of
    twelve rounds for agent communication. This limitation allows us to observe the
    effectiveness of the multi-agent system over a defined number of interaction cycles,
    facilitating one or more rounds of iterative review and refinement within the
    conversation. This structured experimental design is aimed at evaluating the collaborative
    dynamics and output quality of the multi-agent conversation in generating cohesive
    and musically rich compositions based on user prompts.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行我们的实验，我们预设了代理沟通的最大轮次为十二轮。这一限制使我们能够观察多代理系统在定义的交互周期中的有效性，促进在对话中进行一轮或多轮的迭代审查和完善。这种结构化的实验设计旨在评估多代理对话在生成连贯且富有音乐性的作品方面的协作动态和输出质量。
- en: 3.2 Evaluation
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 评估
- en: 3.2.1 Automatic Evaluation
  id: totrans-84
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 自动评估
- en: 'We conducted two experiments to automatically evaluate our system. One experiment
    assessed the success rate of generating symbolic music in a multi-agent setting,
    with results presented in Table [5](#S3.T5 "Table 5 ‣ 3.2.1 Automatic Evaluation
    ‣ 3.2 Evaluation ‣ 3 Experiments ‣ ComposerX: Multi-Agent Symbolic Music Composition
    with LLMs"). One experiment compared the sequence lengths of symbolic music generated
    by multi-agent and single-agent systems, detailed in Table [6](#S3.T6 "Table 6
    ‣ 3.2.1 Automatic Evaluation ‣ 3.2 Evaluation ‣ 3 Experiments ‣ ComposerX: Multi-Agent
    Symbolic Music Composition with LLMs"). These experiments demonstrate the effectiveness
    of our approach in generating symbolic music.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了两个实验来自动评估我们的系统。一个实验评估了在多代理环境中生成符号音乐的成功率，结果见表 [5](#S3.T5 "表 5 ‣ 3.2.1 自动评估
    ‣ 3.2 评估 ‣ 3 实验 ‣ ComposerX：与 LLMs 的多代理符号音乐创作")。另一个实验比较了多代理和单代理系统生成的符号音乐的序列长度，详见表
    [6](#S3.T6 "表 6 ‣ 3.2.1 自动评估 ‣ 3.2 评估 ‣ 3 实验 ‣ ComposerX：与 LLMs 的多代理符号音乐创作")。这些实验展示了我们方法在生成符号音乐方面的有效性。
- en: '| Checkpoints | Generation Success Rate |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 检查点 | 生成成功率 |'
- en: '| --- | --- |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| GPT-4-Turbo | $98.2$% |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4-Turbo | $98.2$% |'
- en: '| GPT-4-0314 | $95.7$% |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4-0314 | $95.7$% |'
- en: '| GPT-3.5-Turbo | $73.0$% |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5-Turbo | $73.0$% |'
- en: 'Table 5: One-time generation success rate for multi-agent system with different
    checkpoints'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：多代理系统在不同检查点下的一次生成成功率
- en: '| Methods | Average ABC String Length |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 平均 ABC 字符串长度 |'
- en: '| --- | --- |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| GPT-4-Turbo multi | $1005.925$ |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4-Turbo multi | $1005.925$ |'
- en: '| GPT-4-Turbo cot | $360.92$ |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4-Turbo cot | $360.92$ |'
- en: '| GPT-4-Turbo icl | $366.30$ |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4-Turbo icl | $366.30$ |'
- en: '| GPT-4-Turbo ori | $354.53$ |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4-Turbo ori | $354.53$ |'
- en: '| GPT-4-Turbo role | $337.64$ |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4-Turbo role | $337.64$ |'
- en: 'Table 6: The average length of ABC String generated by different methods on
    GPT-4-Turbo checkpoint'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6：不同方法在 GPT-4-Turbo 检查点下生成的 ABC 字符串的平均长度
- en: 3.2.2 Human Listening Test
  id: totrans-100
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2 人工听评测试
- en: 'To qualitatively assess our work, we conducted three listening tests. In the
    first test, we compared music samples generated by single-agent and multi-agent
    baselines. Similar to the AB-test setting from previous work[[30](#bib.bib30),
    [21](#bib.bib21)], participants were presented with pairs of samples: one from
    a multi-agent baseline with GPT-4 Turbo checkpoints, and the other from a single-agent
    baseline employing prompting techniques mentioned above: Original, In-Context
    Learning (ICL), Chain of Thought (CoT), and Role-play, also driven by GPT-4 Turbo
    checkpoints. Participants were asked to select the sample they preferred. All
    paired samples were generated using the same prompt; however, participants were
    not informed about the specific prompt details before making their selections.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 为了定性评估我们的工作，我们进行了三次听评测试。在第一次测试中，我们比较了单代理和多代理基线生成的音乐样本。与之前工作中的 AB 测试设置类似[[30](#bib.bib30),
    [21](#bib.bib21)]，参与者被呈现出两个样本的对比：一个来自于带有 GPT-4 Turbo 检查点的多代理基线，另一个来自于使用上述提示技术的单代理基线：原始、上下文学习
    (ICL)、思路链 (CoT) 和角色扮演，也由 GPT-4 Turbo 检查点驱动。参与者需要选择他们偏好的样本。所有对比样本都是使用相同的提示生成的；然而，参与者在选择之前未被告知具体的提示细节。
- en: '![Refer to caption](img/501f4b65fb992c15b6203eafa6c0d480.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/501f4b65fb992c15b6203eafa6c0d480.png)'
- en: 'Figure 4: Result from the first listening test comparing multi-agent baseline
    and single-agent baselines with different prompting techniques. Each row indicates
    the fraction of listeners’ preference for the indicated baseline over other baselines.
    i.e. 0.77 means raters prefer multi-agent system over CoT single-agent 77% of
    the times.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：第一次听力测试的结果，比较了使用不同提示技术的多代理基线和单代理基线。每一行表示听众对所示基线相对于其他基线的偏好比例，即 0.77 意味着评审者
    77% 的时间更喜欢多代理系统而非 CoT 单代理系统。
- en: 'In the second listening test, we assess the perceived human-like quality of
    music generated by the multi-agent baselines. Participants were presented with
    two types of music samples: those generated by multi-agent baselines and those
    composed by humans, sourced from Irishman and KernScores⁴⁴4http://kern.ccarh.org/,
    which are ABC notation datasets containing human-composed music pieces from all
    around the world. Each participant is asked to determine whether each sample was
    composed by a human or a machine.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二次听力测试中，我们评估了多代理基线生成的音乐的类人质量。参与者被展示了两种类型的音乐样本：由多代理基线生成的音乐样本和由人类创作的音乐样本，这些人类创作的音乐样本来自
    Irishman 和 KernScores⁴⁴4http://kern.ccarh.org/，这些 ABC 注释数据集包含来自世界各地的人类创作的音乐作品。每位参与者被要求判断每个样本是由人类创作还是机器生成。
- en: In the third listening test, we assessed the performance of our multi-agent
    baselines, which incorporate GPT-4 Turbo, GPT-4-0314, and GPT-3.5-Turbo checkpoints,
    against established text-to-music generation models. Specifically, comparisons
    were made with MuseCoco[[7](#bib.bib7)], developed by Peiling Lu et al., and a
    BART-based model fine-tuned on 282,870 English text2music pairs in ABC notation,
    as proposed by Wu et al[[24](#bib.bib24)]. Participants were presented with music
    samples alongside their corresponding prompts and asked to select the sample that
    best matched the prompt in terms of musical structure and content.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在第三次听力测试中，我们评估了结合 GPT-4 Turbo、GPT-4-0314 和 GPT-3.5-Turbo 检查点的多代理基线相对于已建立的文本到音乐生成模型的表现。具体而言，我们与
    Peiling Lu 等人开发的 MuseCoco[[7](#bib.bib7)] 以及 Wu 等人提出的基于 BART 的模型进行了比较，该模型在 ABC
    注释中对 282,870 对英语 text2music 数据进行了微调[[24](#bib.bib24)]。参与者被展示了音乐样本及其相应的提示，并被要求选择与提示在音乐结构和内容方面最匹配的样本。
- en: '![Refer to caption](img/35630c44ffa88e0dafa31046f5f16f31.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/35630c44ffa88e0dafa31046f5f16f31.png)'
- en: 'Figure 5: Result from listening test comparing multi-agent baselines with GPT-4-Turbo,
    GPT-4-0314, GPT-3.5-Turbo checkpoints, MuseCoco and text2music Baselines. Each
    row indicates the fraction of listeners’ preference for the indicated baseline
    over other baselines. In this case, the strongest multi-agent baseline with GPT-4-Turbo
    checkpoints outperformed text2music, and received the same score as MuseCoco.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：与 GPT-4-Turbo、GPT-4-0314、GPT-3.5-Turbo 检查点、MuseCoco 和 text2music 基线的多代理基线比较的听力测试结果。每一行表示听众对所示基线相对于其他基线的偏好比例。在这种情况下，最强的多代理基线与
    GPT-4-Turbo 检查点的组合超越了 text2music，并获得了与 MuseCoco 相同的分数。
- en: 3.3 Results
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 结果
- en: Results from comparing multi-agent baseline and single-agent baseline appear
    in Figure 4\. The preference score of GPT-4-Turbo multi has 0.77, 0.68, 0.6, and
    0.57 on each of other single-agent baselines.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 从比较多代理基线和单代理基线的结果如图 4 所示。GPT-4-Turbo multi 在其他每个单代理基线上的偏好得分分别为 0.77、0.68、0.6
    和 0.57。
- en: 'As indicated by the fractions, the multi-agent baseline outperformed all the
    single-agent baselines. In addition to the dominant performance of the multi-agent
    baseline over single-agent baselines, we also observe that the multi-agent baseline
    has a stronger ability to generate longer music. As indicated by Table [6](#S3.T6
    "Table 6 ‣ 3.2.1 Automatic Evaluation ‣ 3.2 Evaluation ‣ 3 Experiments ‣ ComposerX:
    Multi-Agent Symbolic Music Composition with LLMs"), GPT-4-Turbo multi demonstrates
    the capacity to generate music pieces nearly three times longer than those produced
    by any other single-agent baselines.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '从这些比例来看，多代理基线超越了所有单代理基线。除了多代理基线在单代理基线上的卓越表现外，我们还观察到多代理基线在生成更长音乐方面具有更强的能力。如表
    [6](#S3.T6 "Table 6 ‣ 3.2.1 Automatic Evaluation ‣ 3.2 Evaluation ‣ 3 Experiments
    ‣ ComposerX: Multi-Agent Symbolic Music Composition with LLMs") 所示，GPT-4-Turbo
    multi 展示了生成的音乐作品长度几乎是任何其他单代理基线的三倍。'
- en: '| Model | Perceived as Human | Perceived as Machine |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 被感知为人类 | 被感知为机器 |'
- en: '| --- | --- | --- |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| ComposerX | $32.2$% |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| ComposerX | $32.2$% |'
- en: '| Ground Truth | $55.4$% |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 真实情况 | $55.4$% |'
- en: 'Table 7: Result from our second listening test (Turing test).'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7：我们第二次听力测试（图灵测试）的结果。
- en: 'Results from comparing the multi-agent baseline with music composed by humans
    indicates that ComposerX gets 32.2% perceived as human which is lower than the
    rate of real human music - 55.4% as indicated in Table [7](#S3.T7 "Table 7 ‣ 3.3
    Results ‣ 3 Experiments ‣ ComposerX: Multi-Agent Symbolic Music Composition with
    LLMs"). Despite failing the Turing test, ComposerX showcases its capability to
    closely match human skill in music composition.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '与人类创作的音乐进行比较的结果表明，ComposerX的32.2%被感知为人类创作的，这低于真实人类音乐的55.4%，详见表格[7](#S3.T7 "Table
    7 ‣ 3.3 Results ‣ 3 Experiments ‣ ComposerX: Multi-Agent Symbolic Music Composition
    with LLMs")。尽管未能通过图灵测试，ComposerX展示了其在音乐创作中与人类技能紧密匹配的能力。'
- en: 'Results from comparing the multi-agent baseline with GPT-4-Turbo, GPT-4-0314,
    GPT-3.5-Turbo checkpoints, MuseCoco, and text2music are presented in Figure 5\.
    As indicated by the fractional numbers, the multi-agent baseline with GPT-4-Turbo
    checkpoints is our strongest-performed baseline. It outperformed text2music baseline
    with 0.56 preference score and received the same score as MuseCoco. GPT-4-Turbo
    also shows the highest generation success rate among all checkpoints, as indicated
    in Table [5](#S3.T5 "Table 5 ‣ 3.2.1 Automatic Evaluation ‣ 3.2 Evaluation ‣ 3
    Experiments ‣ ComposerX: Multi-Agent Symbolic Music Composition with LLMs").'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '比较多代理基准与GPT-4-Turbo、GPT-4-0314、GPT-3.5-Turbo检查点、MuseCoco和text2music的结果见于图5。根据分数的表示，多代理基准与GPT-4-Turbo检查点的表现最为强劲。它比text2music基准高出0.56的偏好分数，并与MuseCoco获得相同分数。GPT-4-Turbo在所有检查点中也显示了最高的生成成功率，详见表格[5](#S3.T5
    "Table 5 ‣ 3.2.1 Automatic Evaluation ‣ 3.2 Evaluation ‣ 3 Experiments ‣ ComposerX:
    Multi-Agent Symbolic Music Composition with LLMs")。'
- en: 4 Discussion
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 讨论
- en: 'Overall, we observed that our GPT-powered multi-agent framework significantly
    enhances the quality of the music generated over solutions utilizing a singular
    GPT instance. Advantages of our system include:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，我们观察到，由GPT驱动的多代理框架显著提高了生成音乐的质量，相较于使用单一GPT实例的解决方案。我们系统的优势包括：
- en: 'Controllability: Our observations of the collaborative interactions among the
    agents, with particular emphasis on the contributions of the Group Leader, indicate
    the system’s competency in comprehending and executing a wide range of musical
    attributes as delineated by user inputs. Fundamental components such as tempo,
    key, time signature, chord progression, and instrumentation are adeptly translated
    into the corresponding ABC notations. This adept interpretation and realization
    of user directives significantly augment user controllability, enabling the generation
    of music that closely mirrors their specifications and artistic preferences.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 可控性：我们对代理之间的协作互动进行了观察，特别强调了组长的贡献，显示系统在理解和执行用户输入所界定的各种音乐属性方面的能力。基本组件如节奏、调性、拍号、和弦进行和配器被巧妙地转换为相应的ABC记谱。这种对用户指令的巧妙解释和实现显著提高了用户的可控性，使得生成的音乐更接近其规格和艺术偏好。
- en: 'Training-free and data-free: In contrast to conventional text-to-music generation
    models, which predominantly depend on large datasets for training, our system
    introduces significant benefits by obviating the need for such extensive data.
    This approach substantially mitigates the challenges associated with the compilation
    and refinement of large training datasets, including potential biases and the
    substantial resources often requisite for these processes. Moreover, this strategy
    enhances the system’s adaptability and accessibility, marking a shift towards
    more resource-efficient practices in music generation. As a result, this innovation
    plays a pivotal role in democratizing music generation, making it more attainable
    across a broader spectrum of users and applications.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 无需训练和数据：与传统的文本到音乐生成模型主要依赖大量数据集进行训练不同，我们的系统通过省去这些广泛的数据需求，带来了显著的好处。这种方法大大减轻了编制和完善大型训练数据集的挑战，包括潜在的偏见以及这些过程通常需要的大量资源。此外，这种策略增强了系统的适应性和可及性，标志着向更节省资源的音乐生成实践的转变。因此，这一创新在使音乐生成民主化方面发挥了关键作用，使其在更广泛的用户和应用领域变得更加可及。
- en: 'The system exhibits certain limitations, particularly when engaging with the
    nuanced aspects of musical composition that are often intrinsic to human-created
    music. These limitations delineate areas for potential enhancement and further
    research:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 系统表现出一些局限性，特别是在处理那些通常与人类创作音乐固有的细微方面时。这些局限性划定了潜在的改进和进一步研究的领域：
- en: 'Subtlety in Musical Expression: The system is adept at interpreting basic musical
    elements but faces challenges in generating compositions with the nuanced subtlety
    characteristic of human composers. This includes aspects such as emotional depth,
    dynamic contrasts, and intricate phrasing, which are essential for conveying more
    profound musical narratives and experiences.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 音乐表现的微妙性：系统擅长解读基本音乐元素，但在生成具有*人类作曲家*特征的细微微妙的作品时面临挑战。这包括情感深度、动态对比和复杂的短语等方面，这些都是传达更深刻音乐叙事和体验的关键。
- en: 'Translation from Natural Language to Musical Notation: Instructions and feedback
    given by the Group Leader and Review Agent aiming to facilitate nuanced musical
    elements are sometimes inadequately translated into ABC notations by the musician
    agents. This gap between conceptual understanding and practical embodiment in
    music notation underscores the system’s current limitations in realizing more
    sophisticated musical ideas.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 从自然语言到音乐记谱的翻译：组长和审稿代理提供的指示和反馈旨在促进细微的音乐元素，但有时会被音乐代理 inadequately 翻译成 ABC 记谱。这种概念理解与音乐记谱实际体现之间的差距突显了系统在实现更复杂音乐理念方面的当前局限性。
- en: 'Instrumental Note Range Compliance: The system occasionally generates notes
    beyond the conventional pitch ranges of certain instruments. For example, despite
    directives to adhere to instrument-specific pitch ranges, outputs have included
    notes exceeding the upper limit of a contrabass (C2 to F4), reflecting a discrepancy
    between the system’s outputs and practical musical performance constraints.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 乐器音符范围合规：系统偶尔生成超出某些乐器传统音高范围的音符。例如，尽管指令要求遵守乐器特定的音高范围，但输出中出现了超出大低音提琴（C2 至 F4）上限的音符，反映出系统输出与实际音乐表演约束之间的差异。
- en: 'Inter-Voice Alignment: Our system faces challenges with aligning multiple musical
    voices accurately. This challenge primarily arises from the inherent limitations
    of text-based LLMs in generating polyphonic ABC notations. The linear nature of
    text-based input and output mechanisms does not naturally accommodate the complexity
    of polyphonic music, where multiple voices or instruments must be coordinated
    in time.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 声部对齐：我们的系统在准确对齐多个音乐声部方面面临挑战。这一挑战主要来源于基于文本的 LLM 在生成多声部 ABC 记谱时的固有局限性。基于文本的输入和输出机制的线性特性自然不适应多声部音乐的复杂性，其中多个声部或乐器必须在时间上协调一致。
- en: 'Cadential Resolution: Certain compositions generated by the system appear to
    lack a conclusive sense of resolution, resulting in pieces that may feel unfinished
    or conclude abruptly. This issue affects the listener’s sense of closure and satisfaction,
    detracting from the overall effectiveness of the musical experience. The challenge
    in achieving cadential resolution is partly due to the inherent difficulty for
    GPTs to grasp the concept of musical closure, which the perpetual aspect of its
    nature is hard for a language model to handle.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 终止解决：系统生成的某些作品似乎缺乏明确的终止感，导致作品感觉未完成或突然结束。这一问题影响了听众的结尾感和满足感，削弱了音乐体验的整体效果。实现终止解决的挑战部分源于
    GPT 对音乐结尾概念的理解困难，语言模型难以处理其持续的特性。
- en: 5 Conclusion
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论
- en: In conclusion, our investigation into ComposerX, a multi-agent polyphonic symbolic
    music composition system, reveals its efficacy in leveraging the inherent musical
    capabilities of LLMs to compose high-quality music. By introducing a collaborative
    agent-based approach, ComposerX not only transcends the capabilities of single-agent
    systems but also offers a cost-effective alternative to traditional music generation
    models that rely heavily on computational resources.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，我们对 ComposerX 的调查揭示了它在利用 LLM 的固有音乐能力来创作高质量音乐方面的有效性。通过引入协作代理的方法，ComposerX
    不仅超越了单一代理系统的能力，还提供了一个经济高效的替代方案，避免了传统音乐生成模型对计算资源的过度依赖。
- en: 6 Contributions and Acknowledgments
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 贡献与致谢
- en: Core Qixin Deng, qdeng4@u.rochester.edu Qikai Yang, qikaiy2@illinois.edu Ruibin
    Yuan, ryuanab@connect.ust.hk Yipeng Huang, hyp744009246@163.com
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 核心团队 Qixin Deng, qdeng4@u.rochester.edu Qikai Yang, qikaiy2@illinois.edu Ruibin
    Yuan, ryuanab@connect.ust.hk Yipeng Huang, hyp744009246@163.com
- en: Contributors Yi Wang
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 贡献者 Yi Wang
- en: Xubo Liu
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: Xubo Liu
- en: Zeyue Tian
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Zeyue Tian
- en: Jiahao Pan
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Jiahao Pan
- en: Ge Zhang
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: Ge Zhang
- en: Hanfeng Lin
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Hanfeng Lin
- en: Yizhi Li
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: Yizhi Li
- en: Yinghao Ma
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: Yinghao Ma
- en: Jie Fu
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: Jie Fu
- en: Chenghua Lin
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Chenghua Lin
- en: Emmanouil Benetos
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Emmanouil Benetos
- en: Wenwu Wang
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: Wenwu Wang
- en: Gus Xia
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: Gus Xia
- en: Correspondence Wei Xue, weixue@ust.hk Yike Guo, yikeguo@ust.hk
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 通讯 Wei Xue, weixue@ust.hk Yike Guo, yikeguo@ust.hk
- en: References
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] N. Masataka, “The origins of language and the evolution of music: A comparative
    perspective,” *Physics of Life Reviews*, vol. 6, no. 1, pp. 11–22, 2009.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] N. Masataka, “语言的起源与音乐的演变：比较视角，” *生命物理学评论*, 第6卷，第1期，第11–22页, 2009年。'
- en: '[2] ——, “Music, evolution and language,” *Developmental science*, vol. 10,
    no. 1, pp. 35–39, 2007.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] ——, “音乐、进化与语言，” *发展科学*, 第10卷，第1期，第35–39页, 2007年。'
- en: '[3] M. C. Pino, M. Giancola, and S. D’Amico, “The association between music
    and language in children: A state-of-the-art review,” *Children*, vol. 10, no. 5,
    p. 801, 2023.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] M. C. Pino, M. Giancola, 和 S. D’Amico, “儿童中音乐与语言的关联：最新综述，” *儿童*, 第10卷，第5期，第801页,
    2023年。'
- en: '[4] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” *Advances in neural
    information processing systems*, vol. 30, 2017.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    Ł. Kaiser, 和 I. Polosukhin, “注意力机制是你所需要的一切，” *神经信息处理系统进展*, 第30卷, 2017年。'
- en: '[5] C.-Z. A. Huang, A. Vaswani, J. Uszkoreit, N. Shazeer, I. Simon, C. Hawthorne,
    A. M. Dai, M. D. Hoffman, M. Dinculescu, and D. Eck, “Music transformer,” *arXiv
    preprint arXiv:1809.04281*, 2018.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] C.-Z. A. Huang, A. Vaswani, J. Uszkoreit, N. Shazeer, I. Simon, C. Hawthorne,
    A. M. Dai, M. D. Hoffman, M. Dinculescu, 和 D. Eck, “音乐变换器，” *arXiv 预印本 arXiv:1809.04281*,
    2018年。'
- en: '[6] C. Payne, “Musenet,” OpenAI Blog, Apr 2019\. [Online]. Available: https://openai.com/blog/musenet'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] C. Payne, “Musenet，” OpenAI Blog, 2019年4月。 [在线]. 可用链接: https://openai.com/blog/musenet'
- en: '[7] P. Lu, X. Xu, C. Kang, B. Yu, C. Xing, X. Tan, and J. Bian, “Musecoco:
    Generating symbolic music from text,” 2023.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] P. Lu, X. Xu, C. Kang, B. Yu, C. Xing, X. Tan, 和 J. Bian, “Musecoco: 从文本生成符号音乐，”
    2023年。'
- en: '[8] P. Dhariwal, H. Jun, C. Payne, J. W. Kim, A. Radford, and I. Sutskever,
    “Jukebox: A generative model for music,” *arXiv preprint arXiv:2005.00341*, 2020.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] P. Dhariwal, H. Jun, C. Payne, J. W. Kim, A. Radford, 和 I. Sutskever, “Jukebox:
    一种音乐生成模型，” *arXiv 预印本 arXiv:2005.00341*, 2020。'
- en: '[9] A. Agostinelli, T. I. Denk, Z. Borsos, J. Engel, M. Verzetti, A. Caillon,
    Q. Huang, A. Jansen, A. Roberts, M. Tagliasacchi *et al.*, “Musiclm: Generating
    music from text,” *arXiv preprint arXiv:2301.11325*, 2023.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] A. Agostinelli, T. I. Denk, Z. Borsos, J. Engel, M. Verzetti, A. Caillon,
    Q. Huang, A. Jansen, A. Roberts, M. Tagliasacchi *等*, “Musiclm: 从文本生成音乐，” *arXiv
    预印本 arXiv:2301.11325*, 2023年。'
- en: '[10] J. Copet, F. Kreuk, I. Gat, T. Remez, D. Kant, G. Synnaeve, Y. Adi, and
    A. Défossez, “Simple and controllable music generation,” *arXiv preprint arXiv:2306.05284*,
    2023.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] J. Copet, F. Kreuk, I. Gat, T. Remez, D. Kant, G. Synnaeve, Y. Adi, 和
    A. Défossez, “简单且可控的音乐生成，” *arXiv 预印本 arXiv:2306.05284*, 2023年。'
- en: '[11] E. H. Margulis and R. Simchy-Gross, “Repetition enhances the musicality
    of randomly generated tone sequences,” *Music Perception: An Interdisciplinary
    Journal*, vol. 33, no. 4, pp. 509–514, 2016.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] E. H. Margulis 和 R. Simchy-Gross, “重复增强了随机生成的音序的音乐性，” *音乐感知：跨学科期刊*, 第33卷，第4期，第509–514页,
    2016年。'
- en: '[12] S. Dai, H. Yu, and R. B. Dannenberg, “What is missing in deep music generation?
    a study of repetition and structure in popular music,” *arXiv preprint arXiv:2209.00182*,
    2022.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] S. Dai, H. Yu, 和 R. B. Dannenberg, “深度音乐生成中缺失的是什么？对流行音乐中重复和结构的研究，” *arXiv
    预印本 arXiv:2209.00182*, 2022年。'
- en: '[13] H. Jhamtani and T. Berg-Kirkpatrick, “Modeling self-repetition in music
    generation using generative adversarial networks,” in *Machine Learning for Music
    Discovery Workshop, ICML*, 2019.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] H. Jhamtani 和 T. Berg-Kirkpatrick, “利用生成对抗网络建模音乐生成中的自我重复，” 见 *机器学习与音乐发现研讨会，ICML*,
    2019年。'
- en: '[14] X. Qu, Y. Bai, Y. Ma, Z. Zhou, K. M. Lo, J. Liu, R. Yuan, L. Min, X. Liu,
    T. Zhang *et al.*, “Mupt: A generative symbolic music pretrained transformer,”
    *arXiv preprint arXiv:2404.06393*, 2024.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] X. Qu, Y. Bai, Y. Ma, Z. Zhou, K. M. Lo, J. Liu, R. Yuan, L. Min, X. Liu,
    T. Zhang *等*, “Mupt: 一种生成符号音乐的预训练变换器，” *arXiv 预印本 arXiv:2404.06393*, 2024年。'
- en: '[15] X. Yue, X. Qu, G. Zhang, Y. Fu, W. Huang, H. Sun, Y. Su, and W. Chen,
    “Mammoth: Building math generalist models through hybrid instruction tuning,”
    *arXiv preprint arXiv:2309.05653*, 2023.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] X. Yue, X. Qu, G. Zhang, Y. Fu, W. Huang, H. Sun, Y. Su, 和 W. Chen, “Mammoth:
    通过混合指令调优构建数学通用模型，” *arXiv 预印本 arXiv:2309.05653*, 2023年。'
- en: '[16] B. Roziere, J. Gehring, F. Gloeckle, S. Sootla, I. Gat, X. E. Tan, Y. Adi,
    J. Liu, T. Remez, J. Rapin *et al.*, “Code llama: Open foundation models for code,”
    *arXiv preprint arXiv:2308.12950*, 2023.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] B. Roziere, J. Gehring, F. Gloeckle, S. Sootla, I. Gat, X. E. Tan, Y.
    Adi, J. Liu, T. Remez, J. Rapin *等*, “Code llama: 开放的代码基础模型，” *arXiv 预印本 arXiv:2308.12950*,
    2023年。'
- en: '[17] S. Bubeck, V. Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz, E. Kamar,
    P. Lee, Y. T. Lee, Y. Li, S. Lundberg *et al.*, “Sparks of artificial general
    intelligence: Early experiments with gpt-4,” *arXiv preprint arXiv:2303.12712*,
    2023.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] S. Bubeck, V. Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz, E. Kamar,
    P. Lee, Y. T. Lee, Y. Li, S. Lundberg *等*, “人工通用智能的火花：GPT-4 的早期实验，” *arXiv 预印本
    arXiv:2303.12712*, 2023。'
- en: '[18] L. Lin, G. Xia, Y. Zhang, and J. Jiang, “Arrange, inpaint, and refine:
    Steerable long-term music audio generation and editing via content-based controls,”
    *arXiv preprint arXiv:2402.09508*, 2024.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] L. Lin, G. Xia, Y. Zhang, 和 J. Jiang, “安排、修补和优化：通过基于内容的控制来引导长期音乐音频生成和编辑，”
    *arXiv 预印本 arXiv:2402.09508*, 2024。'
- en: '[19] L. Lin, G. Xia, J. Jiang, and Y. Zhang, “Content-based controls for music
    large language modeling,” *arXiv preprint arXiv:2310.17162*, 2023.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] L. Lin, G. Xia, J. Jiang, 和 Y. Zhang, “用于音乐大型语言建模的基于内容的控制，” *arXiv 预印本
    arXiv:2310.17162*, 2023。'
- en: '[20] ——, “Equipping musicgen with chord and rhythm controls,” in *Ismir 2023
    Hybrid Conference*, 2023.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] ——, “为 Musicgen 配备和弦和节奏控制，” 在 *Ismir 2023 混合会议*，2023。'
- en: '[21] R. Yuan, H. Lin, Y. Wang, Z. Tian, S. Wu, T. Shen, G. Zhang, Y. Wu, C. Liu,
    Z. Zhou, Z. Ma, L. Xue, Z. Wang, Q. Liu, T. Zheng, Y. Li, Y. Ma, Y. Liang, X. Chi,
    R. Liu, Z. Wang, P. Li, J. Wu, C. Lin, Q. Liu, T. Jiang, W. Huang, W. Chen, E. Benetos,
    J. Fu, G. Xia, R. Dannenberg, W. Xue, S. Kang, and Y. Guo, “Chatmusician: Understanding
    and generating music intrinsically with llm,” 2024.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] R. Yuan, H. Lin, Y. Wang, Z. Tian, S. Wu, T. Shen, G. Zhang, Y. Wu, C.
    Liu, Z. Zhou, Z. Ma, L. Xue, Z. Wang, Q. Liu, T. Zheng, Y. Li, Y. Ma, Y. Liang,
    X. Chi, R. Liu, Z. Wang, P. Li, J. Wu, C. Lin, Q. Liu, T. Jiang, W. Huang, W.
    Chen, E. Benetos, J. Fu, G. Xia, R. Dannenberg, W. Xue, S. Kang, 和 Y. Guo, “Chatmusician：通过大型语言模型理解和生成音乐，”
    2024。'
- en: '[22] S. Ding, Z. Liu, X. Dong, P. Zhang, R. Qian, C. He, D. Lin, and J. Wang,
    “Songcomposer: A large language model for lyric and melody composition in song
    generation,” *arXiv preprint arXiv:2402.17645*, 2024.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] S. Ding, Z. Liu, X. Dong, P. Zhang, R. Qian, C. He, D. Lin, 和 J. Wang,
    “Songcomposer：用于歌曲生成中的歌词和旋律创作的大型语言模型，” *arXiv 预印本 arXiv:2402.17645*, 2024。'
- en: '[23] X. Liang, J. Lin, and X. Du, “Bytecomposer: a human-like melody composition
    method based on language model agent,” *arXiv preprint arXiv:2402.17785*, 2024.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] X. Liang, J. Lin, 和 X. Du, “Bytecomposer：基于语言模型代理的类人旋律创作方法，” *arXiv 预印本
    arXiv:2402.17785*, 2024。'
- en: '[24] S. Wu and M. Sun, “Exploring the efficacy of pre-trained checkpoints in
    text-to-music generation task,” 2023.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] S. Wu 和 M. Sun, “探索预训练检查点在文本到音乐生成任务中的效果，” 2023。'
- en: '[25] Y. Zhang, A. Maezawa, G. Xia, K. Yamamoto, and S. Dixon, “Loop copilot:
    Conducting ai ensembles for music generation and iterative editing,” *arXiv preprint
    arXiv:2310.12404*, 2023.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Y. Zhang, A. Maezawa, G. Xia, K. Yamamoto, 和 S. Dixon, “Loop copilot：为音乐生成和迭代编辑指挥
    AI 乐团，” *arXiv 预印本 arXiv:2310.12404*, 2023。'
- en: '[26] D. Yu, K. Song, P. Lu, T. He, X. Tan, W. Ye, S. Zhang, and J. Bian, “Musicagent:
    An ai agent for music understanding and generation with large language models,”
    *arXiv preprint arXiv:2310.11954*, 2023.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] D. Yu, K. Song, P. Lu, T. He, X. Tan, W. Ye, S. Zhang, 和 J. Bian, “Musicagent：一个用于音乐理解和生成的大型语言模型的
    AI 代理，” *arXiv 预印本 arXiv:2310.11954*, 2023。'
- en: '[27] Y. Wang, Y. Kordi, S. Mishra, A. Liu, N. A. Smith, D. Khashabi, and H. Hajishirzi,
    “Self-instruct: Aligning language models with self-generated instructions,” 2023.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Y. Wang, Y. Kordi, S. Mishra, A. Liu, N. A. Smith, D. Khashabi, 和 H. Hajishirzi,
    “Self-instruct：通过自生成指令对齐语言模型，” 2023。'
- en: '[28] J. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter, F. Xia, E. Chi, Q. Le,
    and D. Zhou, “Chain-of-thought prompting elicits reasoning in large language models,”
    2023.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] J. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter, F. Xia, E. Chi, Q.
    Le, 和 D. Zhou, “链式思维提示引发大型语言模型的推理，” 2023。'
- en: '[29] Q. Wu, G. Bansal, J. Zhang, Y. Wu, B. Li, E. Zhu, L. Jiang, X. Zhang,
    S. Zhang, J. Liu, A. H. Awadallah, R. W. White, D. Burger, and C. Wang, “Autogen:
    Enabling next-gen llm applications via multi-agent conversation,” 2023.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Q. Wu, G. Bansal, J. Zhang, Y. Wu, B. Li, E. Zhu, L. Jiang, X. Zhang,
    S. Zhang, J. Liu, A. H. Awadallah, R. W. White, D. Burger, 和 C. Wang, “Autogen：通过多代理对话启用下一代大型语言模型应用，”
    2023。'
- en: '[30] C. Donahue, A. Caillon, A. Roberts, E. Manilow, P. Esling, A. Agostinelli,
    M. Verzetti, I. Simon, O. Pietquin, N. Zeghidour *et al.*, “Singsong: Generating
    musical accompaniments from singing,” *arXiv preprint arXiv:2301.12662*, 2023.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] C. Donahue, A. Caillon, A. Roberts, E. Manilow, P. Esling, A. Agostinelli,
    M. Verzetti, I. Simon, O. Pietquin, N. Zeghidour *等*, “Singsong：从歌唱中生成音乐伴奏，” *arXiv
    预印本 arXiv:2301.12662*, 2023。'
