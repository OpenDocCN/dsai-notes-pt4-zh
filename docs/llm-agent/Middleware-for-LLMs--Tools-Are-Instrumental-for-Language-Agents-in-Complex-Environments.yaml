- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 18:51:43'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-08 18:51:43'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Middleware for LLMs: Tools Are Instrumental for Language Agents in Complex
    Environments'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLMs 的中间件：工具在复杂环境中的语言代理中的重要作用
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2402.14672](https://ar5iv.labs.arxiv.org/html/2402.14672)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2402.14672](https://ar5iv.labs.arxiv.org/html/2402.14672)
- en: Yu Gu¹, Yiheng Shu¹, Hao Yu², Xiao Liu², Yuxiao Dong², Jie Tang²,
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Yu Gu¹, Yiheng Shu¹, Hao Yu², Xiao Liu², Yuxiao Dong², Jie Tang²,
- en: Jayanth Srinivasa³, Hugo Latapie³, Yu Su¹
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Jayanth Srinivasa³, Hugo Latapie³, Yu Su¹
- en: ¹The Ohio State University  ²Tsinghua University  ³Cisco Research
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ¹俄亥俄州立大学  ²清华大学  ³思科研究
- en: '{gu.826, su.809}@osu.edu'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '{gu.826, su.809}@osu.edu'
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: The applications of large language models (LLMs) have expanded well beyond the
    confines of text processing, signaling a new era where LLMs are envisioned as
    generalist language agents capable of operating within complex real-world environments.
    These environments are often highly expansive, making it impossible for the LLM
    to process them within its short-term memory. Motivated by recent research on
    extending the capabilities of LLMs with tools, this paper investigates the intriguing
    potential of tools to augment LLMs in handling such complexity. To this end, we
    design customized tools to aid in the proactive exploration within these massive
    environments. Such tools can serve as a middleware layer shielding the LLM from
    environmental complexity. In two representative complex environments—knowledge
    bases (KBs) and databases—we demonstrate the significant potential of augmenting
    language agents with tools in complex environments. Notably, equipped with these
    tools, GPT-4 achieves 2.8$\times$ in KB tasks. Our findings illuminate the path
    for advancing language agents in complex real-world applications. ¹¹1Our code
    and data will be released at [OSU_NLP/Fuxi](https://github.com/OSU-NLP-Group/Fuxi).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）的应用已经超越了文本处理的范畴，标志着一个新纪元的到来，即 LLMs 被设想为能够在复杂现实环境中操作的通用语言代理。这些环境通常非常广阔，使得
    LLM 无法在其短期记忆中处理所有信息。受到最近关于利用工具扩展 LLM 能力的研究的激励，本文探讨了工具在处理这种复杂性方面增强 LLM 的潜力。为此，我们设计了定制工具以帮助在这些广阔环境中进行主动探索。这些工具可以作为中间件层，保护
    LLM 免受环境复杂性的影响。在两个具有代表性的复杂环境——知识库（KBs）和数据库中——我们展示了在复杂环境中使用工具增强语言代理的显著潜力。特别是，借助这些工具，GPT-4
    在知识库任务中达到了 2.8$\times$ 的提升。我们的发现为在复杂现实应用中推进语言代理指明了方向。¹¹1我们的代码和数据将发布在 [OSU_NLP/Fuxi](https://github.com/OSU-NLP-Group/Fuxi)。
- en: 1 Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Large language models (LLMs) have demonstrated revolutionary language capabilities,
    demonstrating a human-like mastery over text OpenAI ([2023a](#bib.bib25), [b](#bib.bib26));
    Touvron et al. ([2023](#bib.bib39)); Jiang et al. ([2024](#bib.bib16)). However,
    the true ambition of AI extends well beyond the realm of text. The goal is to
    ultimately empower LLMs to act as generalist language agents that can aid humans
    across the multitude of complex real-world tasks Yao et al. ([2022](#bib.bib41));
    Schick et al. ([2023](#bib.bib31)); Gu et al. ([2023](#bib.bib8)), which often
    involve handling complex environments, whether it be browsing intricate webpages Deng
    et al. ([2023](#bib.bib6)) or managing vast databases with millions of entries Li
    et al. ([2023a](#bib.bib18)).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）已展示出革命性的语言能力，表现出类似人类的文本掌握能力 OpenAI ([2023a](#bib.bib25), [b](#bib.bib26));
    Touvron et al. ([2023](#bib.bib39)); Jiang et al. ([2024](#bib.bib16))。然而，人工智能的真正雄心远远超出了文本的范围。最终目标是使
    LLM 能够充当通用语言代理，帮助人类完成各种复杂的现实任务 Yao et al. ([2022](#bib.bib41)); Schick et al.
    ([2023](#bib.bib31)); Gu et al. ([2023](#bib.bib8))，这些任务通常涉及处理复杂的环境，无论是浏览复杂的网页 Deng
    et al. ([2023](#bib.bib6)) 还是管理包含数百万条记录的庞大数据库 Li et al. ([2023a](#bib.bib18))。
- en: '![Refer to caption](img/19c99f4ee7ddc2cb4814281e3e828b41.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/19c99f4ee7ddc2cb4814281e3e828b41.png)'
- en: 'Figure 1: (left) When an LLM engages with a complex environment, it can develop
    an understanding by fitting the environment’s description (i.e., linearized tokens)
    into its short-term memory (i.e., the LLM’s input window). However, this method
    encounters drastic scalability issues as the complexity of the environment grows.
    (right) Another option is to furnish the LLM with a set of tools that assist it
    in actively engaging with the environment and acquiring the necessary information.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '图 1: (左) 当 LLM 处理复杂环境时，它可以通过将环境的描述（即线性化的标记）适配到其短期记忆（即 LLM 的输入窗口）中来发展理解。然而，随着环境复杂性的增加，这种方法会遇到严重的可扩展性问题。
    (右) 另一种选择是为 LLM 提供一套工具，帮助其主动参与环境并获取必要的信息。'
- en: 'For LLMs to effectively serve as agents that ground human instructions into
    accurate actions within the environment, they must develop a robust understanding
    of the environment. The most direct method to achieve it is to linearize the environment
    into a sequence of tokens that fit into the LLM’s short-term memory (i.e., its
    input window) and have the LLM process the environment based on the linearized
    description Tai et al. ([2023](#bib.bib37)); Shridhar et al. ([2021](#bib.bib32));
    Liu et al. ([2023](#bib.bib21)). However, such a method faces steep challenges
    in scaling to more complex environments, primarily due to the input size limitations
    of LLMs. Also, discrete token descriptions may not reflect the most natural perception
    of the environment. Recent work has explored using tools to extend the boundary
    of the LLM’s capacity Li et al. ([2023b](#bib.bib19)); Qin et al. ([2023b](#bib.bib28));
    Schick et al. ([2023](#bib.bib31)). The core idea is that LLMs can actively decide
    a proper tool to use, using language as a powerful vehicle of thought Su ([2023](#bib.bib34)).
    For example, the LLM may invoke a calculator when facing a computationally intensive
    math task. Intuitively, we can also equip the LLM with tools that enable navigating
    complex environments, so that the LLM can proactively invoke different tools to
    explore the environment, thus circumventing limitations posed by its short-term
    memory (Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Middleware for LLMs: Tools
    Are Instrumental for Language Agents in Complex Environments")). However, this
    promising paradigm has been thus far underexplored. In this paper, we aim to delve
    into this paradigm and answer an intriguing question: How effectively can LLMs
    handle complex environments with the aid of tools?'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使大型语言模型（LLMs）能够有效地将人类指令转化为环境中的准确行动，它们必须对环境有深刻的理解。实现这一点的最直接方法是将环境线性化为一系列适合LLM短期记忆（即其输入窗口）的标记，并让LLM基于线性化的描述处理环境 Tai等人
    ([2023](#bib.bib37)); Shridhar等人 ([2021](#bib.bib32)); Liu等人 ([2023](#bib.bib21))。然而，这种方法在扩展到更复杂的环境时面临巨大的挑战，主要由于LLM的输入大小限制。此外，离散的标记描述可能无法反映环境的最自然感知。近期的研究探索了使用工具来扩展LLM的能力边界 Li等人
    ([2023b](#bib.bib19)); Qin等人 ([2023b](#bib.bib28)); Schick等人 ([2023](#bib.bib31))。核心思想是LLM可以主动决定使用适当的工具，语言作为强大的思维工具 Su
    ([2023](#bib.bib34))。例如，LLM在面对计算密集型数学任务时可以调用计算器。直观地，我们还可以为LLM配备能够导航复杂环境的工具，以便LLM可以主动调用不同的工具来探索环境，从而绕过短期记忆带来的限制（图 [1](#S1.F1
    "图 1 ‣ 1 引言 ‣ 中间件：工具在复杂环境中的语言代理中至关重要")）。然而，这一有前景的范式至今仍未被充分探讨。本文旨在**深入研究**这一范式，并回答一个引人入胜的问题：LLM在工具的帮助下，处理复杂环境的效果如何？
- en: 'Answering this question requires equipping the LLM with a suite of tools designed
    to meet a wide range of needs within the target environment. In this paper, we
    carefully develop such tailored tools for two exemplar complex environments, i.e.,
    databases and knowledge bases (KBs). Unlike readily available Web APIs Qin et al.
    ([2023b](#bib.bib28)) used in prior research, our tools have to be manually invented
    from scratch. In crafting these tools, we capitalize on the intuition of human
    information-gathering behaviors—such as performing keyword searches to identify
    a relevant database column or investigating the connections of a KB entity—to
    fulfill complex tasks in these intricate environments (Section [3.1](#S3.SS1 "3.1
    Tools for Complex Environments ‣ 3 Fuxi ‣ Middleware for LLMs: Tools Are Instrumental
    for Language Agents in Complex Environments")). Ideally, these tools are designed
    to function as a middleware layer between the LLM and the environment, shielding
    the LLM from environmental complexity. With these specialized tools in place,
    we adapt ReAct Yao et al. ([2022](#bib.bib41)), a standard framework that enables
    the LLM to synergistically combine reasoning with tool usage, as our reasoning
    algorithm to allow the LLM to effectively leverage the provided tools (Section
     [3.2](#S3.SS2 "3.2 Reasoning with Tools ‣ 3 Fuxi ‣ Middleware for LLMs: Tools
    Are Instrumental for Language Agents in Complex Environments")). The combination
    of the crafted tools and the reasoning algorithm allows the LLM to actively explore
    the environment and ground human instructions into accurate actions. We call this
    framework Fuxi (i.e., flexible grounding with exploration).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '回答这个问题需要为 LLM 配备一整套设计用以满足目标环境中广泛需求的工具。在本文中，我们为两个示例复杂环境（即数据库和知识库（KB））精心开发了这种定制工具。与之前研究中使用的现成
    Web APIs Qin et al. ([2023b](#bib.bib28)) 不同，我们的工具必须从头开始手动发明。在制作这些工具时，我们利用了人类信息获取行为的直觉——例如，通过关键词搜索来识别相关数据库列或调查
    KB 实体的连接——以完成这些复杂环境中的复杂任务（第 [3.1](#S3.SS1 "3.1 Tools for Complex Environments
    ‣ 3 Fuxi ‣ Middleware for LLMs: Tools Are Instrumental for Language Agents in
    Complex Environments") 节）。理想情况下，这些工具被设计为 LLM 和环境之间的中间件层，保护 LLM 免受环境复杂性的影响。借助这些专用工具，我们将
    ReAct Yao et al. ([2022](#bib.bib41))，一个使 LLM 能够协同结合推理与工具使用的标准框架，作为我们的推理算法，以使
    LLM 能够有效利用提供的工具（第 [3.2](#S3.SS2 "3.2 Reasoning with Tools ‣ 3 Fuxi ‣ Middleware
    for LLMs: Tools Are Instrumental for Language Agents in Complex Environments")
    节）。制作的工具与推理算法的结合使 LLM 能够积极探索环境，并将人类指令转化为准确的行动。我们称这个框架为 Fuxi（即，灵活的探索与基础）。'
- en: 'With Fuxi, we evaluate different LLMs on benchmarks featuring complex tasks
    over the target environments, including a newly curated benchmark for the KB.
    The outcomes of our experiments are revealing: LLMs equipped with customized tools
    demonstrate a significant enhancement in their ability to engage with complex
    environments, markedly surpassing the prior art. In particular, despite its simplicity,
    Fuxi allows GPT-4 OpenAI ([2023a](#bib.bib25)) to achieve 2.8$\times$%) in KB
    tasks. Our findings underscore the integral role of tool augmentation in enabling
    LLMs to handle complex environments.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Fuxi，我们在目标环境中的复杂任务基准上评估了不同的 LLM，包括为 KB 新制定的基准。我们的实验结果揭示了一个重要发现：配备定制工具的 LLM
    在处理复杂环境方面表现出显著的提升，远远超过了之前的技术。特别是，尽管其简单，Fuxi 使 GPT-4 OpenAI ([2023a](#bib.bib25))
    在 KB 任务中实现了 2.8$\times$%) 的提升。我们的发现强调了工具增强在使 LLM 处理复杂环境中的核心作用。
- en: 'Our main contributions are as follows: a) We develop Fuxi, a new framework
    with customized tools for two complex environments, to investigate the role of
    tools in handling complex environments with LLMs; b) We extensively evaluate six
    different LLMs on our carefully chosen benchmarks; c) Our analysis highlights
    a critical takeaway: augmenting LLMs with tools is crucial for successfully tackling
    complex environments, opening new possibilities to progress LLMs as generalist
    language agents for practical applications.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的主要贡献如下：a) 我们开发了 Fuxi，一个具有定制工具的新框架，用于研究工具在处理复杂环境中与 LLM 的作用；b) 我们在精心选择的基准上对六种不同的
    LLM 进行了广泛评估；c) 我们的分析突出了一个关键的结论：增强 LLM 的工具对于成功应对复杂环境至关重要，这为 LLM 作为通用语言代理在实际应用中的进展开辟了新的可能性。
- en: 2 Related Work
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: Interface Complex Environments with LLMs.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与 LLM 一起处理复杂环境的接口。
- en: Existing methods that feed the environment directly into the LLM for grounding Chandu
    et al. ([2021](#bib.bib4)) would fail in complex environments due to scalability
    issues. Specifically, these methods process the environment by linearizing it
    into discrete tokens Hwang et al. ([2019](#bib.bib14)); Shridhar et al. ([2021](#bib.bib32));
    Yu et al. ([2023](#bib.bib43)); Liu et al. ([2023](#bib.bib21)); Tai et al. ([2023](#bib.bib37));
    Song et al. ([2023](#bib.bib33)). However, linearizing expansive environments
    like databases with millions of entries Li et al. ([2023a](#bib.bib18)) or lengthy
    webpage HTML code Deng et al. ([2023](#bib.bib6)) can often exceed an LLM’s input
    length constraints. Alternative studies bypass the LLM’s direct interaction with
    complex environments by generating ungrounded draft plans for post-processing
    grounding Li et al. ([2023c](#bib.bib20)); Nie et al. ([2023](#bib.bib24)) or
    by using the LLM to assess grounded plans created via predefined rules Gu et al.
    ([2023](#bib.bib8)). Such strategies do not fully utilize the LLMs’ innate reasoning
    potential in actively navigating complex environments. In this paper, we explore
    a new paradigm where we can bypass these issues by equipping LLMs with a suite
    of comprehensive tools to actively gather necessary information about the environment
    upon demand, leveraging the LLMs’ inherent reasoning capabilities. The most closely
    related work to ours is StructGPT Jiang et al. ([2023b](#bib.bib17)). However,
    the narrow tool selection of StructGPT (i.e., only two tools for KBs and three
    schema-level tools for databases) largely constrains its flexibility in perceiving
    the complex environment when handling diverse tasks.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 直接将环境输入LLM进行基础处理的现有方法，如Chandu等人（[2021](#bib.bib4)），由于可扩展性问题，在复杂环境中会失败。具体来说，这些方法通过将环境线性化为离散的标记来处理环境，如Hwang等人（[2019](#bib.bib14)）；Shridhar等人（[2021](#bib.bib32)）；Yu等人（[2023](#bib.bib43)）；Liu等人（[2023](#bib.bib21)）；Tai等人（[2023](#bib.bib37)）；Song等人（[2023](#bib.bib33)）。然而，像具有数百万条记录的数据库（Li等人（[2023a](#bib.bib18)））或长篇网页HTML代码（Deng等人（[2023](#bib.bib6)））这样的扩展环境的线性化，通常会超出LLM的输入长度限制。替代研究通过生成未经过基础处理的草案计划以供后续处理（Li等人（[2023c](#bib.bib20)）；Nie等人（[2023](#bib.bib24)）），或者通过使用LLM评估通过预定义规则创建的基础处理计划（Gu等人（[2023](#bib.bib8)））来绕过LLM与复杂环境的直接交互。这些策略没有充分利用LLM在主动导航复杂环境中的固有推理潜力。在本文中，我们探索了一种新范式，通过为LLM配备一套全面的工具来主动收集环境所需的信息，从而绕过这些问题，充分发挥LLM的固有推理能力。与我们的工作最相关的是StructGPT（Jiang等人（[2023b](#bib.bib17)））。然而，StructGPT狭窄的工具选择（即，仅有两个KB工具和三个用于数据库的模式级工具）在处理多样化任务时大大限制了其在感知复杂环境方面的灵活性。
- en: Tool Learning.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工具学习。
- en: Tools are essential for enhancing the capabilities of LLMs Schick et al. ([2023](#bib.bib31));
    Qin et al. ([2023a](#bib.bib27)); Mialon et al. ([2023](#bib.bib23)); Hao et al.
    ([2023](#bib.bib13)). Existing research, such as ToolLLM Qin et al. ([2023b](#bib.bib28))
    and API-Bank Li et al. ([2023b](#bib.bib19)), focuses on open-domain applications
    with a wide array of readily available RESTful APIs. In contrast, this paper specifically
    aims to study the potential of tools in augmenting LLMs to effectively execute
    tasks within complex environments, where we carefully craft the specialized tools
    for different environments by ourselves. In addition, research focusing on RESTful
    APIs typically displays shallow reasoning, while practical tasks within a complex
    environment typically entail a long sequence of actions (e.g., querying a KB or
    browsing a webpage). To enable tool use in more intricate settings within a more
    specific complex environment, StructGPT Jiang et al. ([2023b](#bib.bib17)) employs
    a predefined sequence of tool invocations; Chameleon Lu et al. ([2023](#bib.bib22))
    functions in an open-loop setting where the LLM directly produces a sequence for
    tool usage before any execution occurs. Both of them fail to seamlessly integrate
    the reasoning capacity of the LLM with the use of tools. In this paper, we build
    on ReAct to tightly synergize the generation of a reasoning step and corresponding
    tool use. Additionally, we introduce two simple yet effective strategies aimed
    at improving the accuracy of action prediction.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 工具对于增强LLMs的能力至关重要 Schick et al. ([2023](#bib.bib31)); Qin et al. ([2023a](#bib.bib27));
    Mialon et al. ([2023](#bib.bib23)); Hao et al. ([2023](#bib.bib13))。现有研究，如ToolLLM Qin
    et al. ([2023b](#bib.bib28))和API-Bank Li et al. ([2023b](#bib.bib19))，主要集中在具有广泛现成RESTful
    API的开放域应用中。相比之下，本文特别旨在研究工具在增强LLMs以有效执行复杂环境中的任务的潜力，我们在这里自行精心设计了适合不同环境的专用工具。此外，专注于RESTful
    API的研究通常表现出浅层推理，而复杂环境中的实际任务通常涉及一系列长序列的动作（例如，查询知识库或浏览网页）。为了在更具体的复杂环境中的复杂设置中启用工具使用，StructGPT Jiang
    et al. ([2023b](#bib.bib17))采用了预定义的工具调用序列；Chameleon Lu et al. ([2023](#bib.bib22))在一个开放循环设置中运行，其中LLM在任何执行发生之前直接生成工具使用序列。它们都未能将LLM的推理能力与工具使用无缝整合。本文基于ReAct建立了一个紧密协作的框架，用于生成推理步骤和相应的工具使用。此外，我们引入了两种简单而有效的策略，旨在提高动作预测的准确性。
- en: 3 Fuxi
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 Fuxi
- en: 'Fuxi equips LLMs with a suite of tools specifically tailored to support an
    extensive variety of operations and cater to the diverse needs within a complex
    environment $\mathcal{E}$, abstracting the LLM from having to directly interact
    with all of its intricacies (Section [3.1](#S3.SS1 "3.1 Tools for Complex Environments
    ‣ 3 Fuxi ‣ Middleware for LLMs: Tools Are Instrumental for Language Agents in
    Complex Environments")). Furthermore, to fully unleash the inherent planning capabilities
    of LLMs in invoking proper tools, Fuxi builds on ReAct Yao et al. ([2022](#bib.bib41))
    to seamlessly integrate chain-of-thought (CoT) reasoning Wei et al. ([2022](#bib.bib40))
    with tool use, with novel strategies to enhance action accuracy (Section [3.2](#S3.SS2
    "3.2 Reasoning with Tools ‣ 3 Fuxi ‣ Middleware for LLMs: Tools Are Instrumental
    for Language Agents in Complex Environments")). This unified framework allows
    us to reliably investigate the potential of LLMs in handling complex environments
    with the aid of tools.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 'Fuxi为LLMs提供了一套专门设计的工具，旨在支持广泛的操作，并满足复杂环境中的多样化需求，将LLM从直接处理所有复杂性中抽象出来（第[3.1节](#S3.SS1
    "3.1 Tools for Complex Environments ‣ 3 Fuxi ‣ Middleware for LLMs: Tools Are
    Instrumental for Language Agents in Complex Environments")）。此外，为了充分释放LLMs在调用合适工具方面的固有规划能力，Fuxi基于ReAct Yao
    et al. ([2022](#bib.bib41))，将连锁思维（CoT）推理 Wei et al. ([2022](#bib.bib40))与工具使用无缝集成，并采用了新策略以提高动作的准确性（第[3.2节](#S3.SS2
    "3.2 Reasoning with Tools ‣ 3 Fuxi ‣ Middleware for LLMs: Tools Are Instrumental
    for Language Agents in Complex Environments")）。这一统一框架使我们能够可靠地探讨LLMs在工具帮助下处理复杂环境的潜力。'
- en: '![Refer to caption](img/e912ff983064dad562ab08455e1d8411.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/e912ff983064dad562ab08455e1d8411.png)'
- en: 'Figure 2: The LLM is equipped with an array of tools to facilitate its engagement
    with complex environments (e.g., a KB here). (a) The LLM may produce invalid actions
    (marked in pink). This can be mitigated by prompting it with an error message
    that encourages a reattempt (corrected action marked in green). (b) Alternatively,
    we can have the LLM first generate a thought, then predict an action based on
    it in a separate context (marked in blue), and finally insert the action back
    to the original context. Text marked in yellow are input from the environment.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：LLM配备了一系列工具，以便于其与复杂环境（例如，这里的知识库）的互动。（a）LLM可能会产生无效的操作（标记为粉色）。可以通过向其提示错误信息，鼓励其重新尝试（修正后的操作标记为绿色）来缓解此问题。（b）或者，我们可以让LLM先生成一个思路，然后在一个独立的上下文中基于该思路预测一个操作（标记为蓝色），最后将操作插回到原始上下文中。标记为黄色的文本是来自环境的输入。
- en: 3.1 Tools for Complex Environments
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 复杂环境中的工具
- en: 'To evaluate the potential of LLMs in handling complex environments when equipped
    with tools, we need to first carefully craft the necessary tools for the environments.
    These tools should meet two essential criteria: 1) They should offer comprehensiveness,
    encompassing a broad spectrum of operations and needs. Broad coverage of tools
    is crucial for maximizing the potential of LLMs in planning. 2) The tools should
    prioritize ease of use, enabling the LLM to invoke them mostly with straightforward
    slot filling, thus shielding the LLM from the implementation details of the tools.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估LLM在配备工具时处理复杂环境的潜力，我们首先需要精心设计适合这些环境的工具。这些工具应满足两个基本标准：1）它们应具备全面性，涵盖广泛的操作和需求。工具的广泛覆盖对于最大化LLM在规划中的潜力至关重要。2）这些工具应优先考虑易用性，使LLM能够主要通过简单的槽位填充来调用它们，从而使LLM免受工具实现细节的干扰。
- en: Databases
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据库
- en: 'In production scenarios, databases typically feature dozens of tables, with
    each table containing thousands of rows or more. A key task in such environments
    is performing data analysis through SQL queries. To bridge the gap between natural
    language instructions and SQL, LLMs are employed to automate the generation of
    SQL queries (i.e., text-to-SQL parsing Yu et al. ([2018](#bib.bib44)); Li et al.
    ([2023a](#bib.bib18))). To support the LLM in crafting complex SQL queries, we
    introduce a set of specialized tools designed for interaction with intricate databases.
    These tools are divided into two main categories: navigational and functional.
    Navigational tools help the LLM to explore the environment (e.g., get_distinct_values()
    and find_columns_containing_value()), while functional tools help check each SQL
    clause composed by the LLM. For example, where() verifies the legality of the
    WHERE clause and determines if the specified conditions can match any entries
    in the database. In total, we craft $12$ tools for databases (Appendix [A.1](#A1.SS1
    "A.1 Databases ‣ Appendix A Detailed Tool Definitions ‣ Middleware for LLMs: Tools
    Are Instrumental for Language Agents in Complex Environments")). The development
    of these tools is grounded in our domain expertise in SQL and databases.'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '在生产场景中，数据库通常包含几十个表，每个表中包含成千上万的行。在这样的环境中，一个关键任务是通过SQL查询进行数据分析。为了弥合自然语言指令和SQL之间的差距，采用了大语言模型（LLMs）来自动生成SQL查询（即文本到SQL解析，Yu等人（[2018](#bib.bib44)）；Li等人（[2023a](#bib.bib18)））。为了支持LLM构建复杂的SQL查询，我们引入了一组专门的工具，用于与复杂数据库进行交互。这些工具分为两大类：导航工具和功能工具。导航工具帮助LLM探索环境（例如，get_distinct_values()和find_columns_containing_value()），而功能工具则帮助检查LLM所构建的每个SQL子句。例如，where()验证WHERE子句的合法性，并确定指定的条件是否能匹配数据库中的任何条目。总的来说，我们为数据库设计了$12$个工具（附录 [A.1](#A1.SS1
    "A.1 Databases ‣ Appendix A Detailed Tool Definitions ‣ Middleware for LLMs: Tools
    Are Instrumental for Language Agents in Complex Environments")）。这些工具的开发基于我们在SQL和数据库领域的专业知识。'
- en: KBs
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 知识库
- en: 'Modern KBs, such as Freebase Bollacker et al. ([2008](#bib.bib2)), are vast
    repositories storing billions of facts as triples $\langle h,r,t\rangle$ tools
    for KBs (Appendix [A.2](#A1.SS2 "A.2 Knowledge Bases ‣ Appendix A Detailed Tool
    Definitions ‣ Middleware for LLMs: Tools Are Instrumental for Language Agents
    in Complex Environments")). Our design of KB tools tightly adheres to the common
    needs in knowledge base question answering (KBQA) Gu et al. ([2021](#bib.bib9));
    Cao et al. ([2022](#bib.bib3)).'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '现代知识库，如Freebase Bollacker等人（[2008](#bib.bib2)），是存储数十亿个三元组$\langle h,r,t\rangle$的庞大数据库，知识库工具（附录 [A.2](#A1.SS2
    "A.2 Knowledge Bases ‣ Appendix A Detailed Tool Definitions ‣ Middleware for LLMs:
    Tools Are Instrumental for Language Agents in Complex Environments")）。我们对知识库工具的设计紧密遵循了知识库问答（KBQA）的常见需求（Gu等人（[2021](#bib.bib9)）；Cao等人（[2022](#bib.bib3)））。'
- en: 3.2 Reasoning with Tools
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 使用工具进行推理
- en: We leverage ReAct to enable the LLM to effectively invoke our crafted tools.
    Unlike existing methods relying on rigid, human-defined workflows that follow
    fixed tool usage sequences  Jiang et al. ([2023b](#bib.bib17)), ReAct allows the
    LLM autonomy in proactively determining tool selection using CoT. Thus, ReAct
    allows us to tap into the full potential of the LLM’s reasoning capabilities.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们利用 ReAct 使 LLM 有效调用我们设计的工具。与现有方法依赖于固定的、人工定义的工作流程并遵循固定工具使用顺序不同 Jiang et al.
    ([2023b](#bib.bib17))，ReAct 允许 LLM 自主决定工具选择，使用 CoT。因此，ReAct 使我们能够挖掘 LLM 推理能力的全部潜力。
- en: Formally, at each step $t$, where
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 正式地，在每一步 $t$，其中
- en: '|  | $\displaystyle c_{t}$ |  |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle c_{t}$ |  |'
- en: '|  | $\displaystyle\hat{a}_{t}$ |  |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\hat{a}_{t}$ |  |'
- en: '$\hat{a}_{t}$ encapsulates the governing rules of the environment (e.g., the
    relation argument for get_neighbors() must be derived from the output of get_relations(),
    which is applied to the specified entity argument in prior steps), infusing prior
    knowledge into the LLM’s decision-making process (see Figure [2](#S3.F2 "Figure
    2 ‣ 3 Fuxi ‣ Middleware for LLMs: Tools Are Instrumental for Language Agents in
    Complex Environments")(b)). The concrete prompts used by us are shown in Appendix [C](#A3
    "Appendix C Prompts ‣ Middleware for LLMs: Tools Are Instrumental for Language
    Agents in Complex Environments").'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: $\hat{a}_{t}$ 包含了环境的主要规则（例如，get_neighbors() 的关系参数必须从 get_relations() 的输出中得出，该输出应用于之前步骤中指定的实体参数），将先前知识注入
    LLM 的决策过程（见图 [2](#S3.F2 "图 2 ‣ 3 Fuxi ‣ 中间件用于 LLM：工具对于复杂环境中的语言代理至关重要")(b)）。我们使用的具体提示在附录
    [C](#A3 "附录 C 提示 ‣ 中间件用于 LLM：工具对于复杂环境中的语言代理至关重要") 中展示。
- en: '| Model | Req. Cont. (N) | Req. Cont. (Y) | Overall |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 需要内容（N） | 需要内容（Y） | 总体 |'
- en: '|  | EX | VA | EX | VA | EX | VA |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '|  | EX | VA | EX | VA | EX | VA |'
- en: '| w/ Oracle Knowledge |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 使用 Oracle 知识 |'
- en: '| API Docs Prompt Rajkumar et al. ([2022](#bib.bib29)) |  |  |  |  |  |  |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| API Docs Prompt Rajkumar et al. ([2022](#bib.bib29)) |  |  |  |  |  |  |'
- en: '|               w/ GPT-3.5-turbo | $38.1$ |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '|               使用 GPT-3.5-turbo | $38.1$ |'
- en: '|               w/ GPT-4 | $49.5$ |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '|               使用 GPT-4 | $49.5$ |'
- en: '| w/o Oracle Knowledge |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 无 Oracle 知识 |'
- en: '| API Docs Prompt Rajkumar et al. ([2022](#bib.bib29)) |  |  |  |  |  |  |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| API Docs Prompt Rajkumar et al. ([2022](#bib.bib29)) |  |  |  |  |  |  |'
- en: '|               w/ GPT-3.5-turbo^† | $30.9$ |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '|               使用 GPT-3.5-turbo^† | $30.9$ |'
- en: '|               w/ GPT-4 | $38.2$ |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '|               使用 GPT-4 | $38.2$ |'
- en: '| StructGPT Jiang et al. ([2023b](#bib.bib17)) |  |  |  |  |  |  |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| StructGPT Jiang et al. ([2023b](#bib.bib17)) |  |  |  |  |  |  |'
- en: '|               w/ GPT-3.5-turbo | $36.2$ |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '|               使用 GPT-3.5-turbo | $36.2$ |'
- en: '|               w/ GPT-4 | $40.7$ |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '|               使用 GPT-4 | $40.7$ |'
- en: '| Fuxi (error feedback) |  |  |  |  |  |  |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| Fuxi（错误反馈） |  |  |  |  |  |  |'
- en: '|               w/ GPT-3.5-turbo | $38.8$ |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '|               使用 GPT-3.5-turbo | $38.8$ |'
- en: '|               w/ GPT-4 | $45.1$ |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '|               使用 GPT-4 | $45.1$ |'
- en: 'Table 1: Results on Bird’s dev set. Performance of all baselines is obtained
    under a zero-shot setting. ${\dagger}$ denotes the best method w/o oracle knowledge
    on Bird’s official leaderboard. The predictions with API Docs Prompt are directly
    supplied by the authors of Bird.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '表 1: Bird 的开发集结果。所有基准的性能都在零样本设置下获得。${\dagger}$ 表示在 Bird 官方排行榜上最好的方法（无 Oracle
    知识）。API Docs Prompt 的预测直接由 Bird 的作者提供。'
- en: '| Model | Counting | Superlative | None | Overall |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 计数 | 最高级 | 无 | 总体 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '|  | F1 | VA | F1 | VA | F1 | VA | F1 | VA |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '|  | F1 | VA | F1 | VA | F1 | VA | F1 | VA |'
- en: '| Pangu^♢ Gu et al. ([2023](#bib.bib8)) |  |  |  |  |  |  |  |  |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| Pangu^♢ Gu et al. ([2023](#bib.bib8)) |  |  |  |  |  |  |  |  |'
- en: '|               w/ GPT-3.5-turbo | $10.1$ |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '|               使用 GPT-3.5-turbo | $10.1$ |'
- en: '|               w/ GPT-4 | $12.3$ |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '|               使用 GPT-4 | $12.3$ |'
- en: '| KB-Binder Li et al. ([2023c](#bib.bib20)) |  |  |  |  |  |  |  |  |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| KB-Binder Li et al. ([2023c](#bib.bib20)) |  |  |  |  |  |  |  |  |'
- en: '|               w/ GPT-3.5-turbo (20-shot) | $0.0$ |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '|               使用 GPT-3.5-turbo（20-shot） | $0.0$ |'
- en: '|               w/ GPT-4 (20-shot) | $7.9$ |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '|               使用 GPT-4（20-shot） | $7.9$ |'
- en: '| StructGPT Jiang et al. ([2023b](#bib.bib17)) |  |  |  |  |  |  |  |  |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| StructGPT Jiang et al. ([2023b](#bib.bib17)) |  |  |  |  |  |  |  |  |'
- en: '|               w/ GPT-3.5-turbo | $4.5$ |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '|               使用 GPT-3.5-turbo | $4.5$ |'
- en: '|               w/ GPT-4 | $2.2$ |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '|               使用 GPT-4 | $2.2$ |'
- en: '| Fuxi (error feedback) |  |  |  |  |  |  |  |  |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| Fuxi（错误反馈） |  |  |  |  |  |  |  |  |'
- en: '|               w/ GPT-3.5-turbo | $33.7$ |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '|               使用 GPT-3.5-turbo | $33.7$ |'
- en: '|               w/ GPT-4 | $70.7$ |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '|               使用 GPT-4 | $70.7$ |'
- en: '| Fuxi (decoupled generation) |  |  |  |  |  |  |  |  |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| Fuxi（解耦生成） |  |  |  |  |  |  |  |  |'
- en: '|               w/ GPT-3.5-turbo | $48.9$ |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '|               使用 GPT-3.5-turbo | $48.9$ |'
- en: '|               w/ GPT-4 | $74.1$ |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '|               使用 GPT-4 | $74.1$ |'
- en: 'Table 2: Results on KBQA-Agent. All models are provided with one-shot demonstration
    except for KB-Binder, where we provide 20-shot demonstrations for optimal performance.
    $\diamondsuit$ indicates our reimplementation of Pangu, as the original code lacks
    support for chat models. We assume perfect entity linking for all methods.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：KBQA-Agent 的结果。除 KB-Binder 外，所有模型均提供了单次演示，其中我们为 KB-Binder 提供了 20 次演示以获得最佳性能。$\diamondsuit$
    表示我们对 Pangu 的重新实现，因为原始代码不支持聊天模型。我们假设所有方法都能进行完美的实体链接。
- en: 4 Benchmarks
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 个基准测试
- en: 'The predominant tasks for databases and KBs are text-to-SQL parsing and KBQA.
    However, popular benchmarks for them may fall short for evaluating language agents
    out-of-box. Specifically, the majority of questions in popular KBQA datasets like
    WebQSP Berant et al. ([2013](#bib.bib1)); Yih et al. ([2016](#bib.bib42)) are
    one-hop or two-hop questions, for which we can effectively handle with existing
    semantic parsing methods Gu et al. ([2022](#bib.bib10)). Additionally, the databases
    featured in Spider Yu et al. ([2018](#bib.bib44)) and WikiSQL Zhong et al. ([2017](#bib.bib47))
    have limited complexity in terms of both schema design and the number of rows
    in the tables. This over-simplification enables the direct feeding of the database
    schema to the LLM, achieving strong performance without the need to access the
    actual content of the database Rajkumar et al. ([2022](#bib.bib29)). Therefore,
    we need different benchmarks with complex environments and instructions that better
    mirror the real-world situations language agents must handle (see statistics of
    our benchmarks in Appendix [B](#A2 "Appendix B Benchmark Statistics ‣ Middleware
    for LLMs: Tools Are Instrumental for Language Agents in Complex Environments")).'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库和知识库的主要任务是文本到 SQL 解析和 KBQA。然而，流行的基准测试可能不足以评估语言代理的开箱即用性能。具体而言，像 WebQSP Berant
    et al. ([2013](#bib.bib1)) 和 Yih et al. ([2016](#bib.bib42)) 这样的流行 KBQA 数据集中的大多数问题是单跳或双跳问题，对于这些问题，我们可以有效地使用现有的语义解析方法
    Gu et al. ([2022](#bib.bib10)) 进行处理。此外，Spider Yu et al. ([2018](#bib.bib44)) 和
    WikiSQL Zhong et al. ([2017](#bib.bib47)) 中的数据库在模式设计和表行数方面复杂性有限。这种过度简化使得可以将数据库模式直接输入到
    LLM 中，在无需访问数据库实际内容的情况下实现强大的性能 Rajkumar et al. ([2022](#bib.bib29))。因此，我们需要具有复杂环境和指令的不同基准测试，以更好地反映语言代理必须处理的实际情况（请参阅附录
    [B](#A2 "附录 B 基准测试统计 ‣ LLM 中的中间件：工具对于复杂环境中的语言代理至关重要") 的基准统计）。
- en: Databases
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据库
- en: 'For databases, we leverage Bird Li et al. ([2023a](#bib.bib18)), which is a
    recent dataset notable for its complexity, featuring intricate instructions over
    highly complex databases. There are originally two different settings in Bird:
    with and without oracle knowledge, where the oracle knowledge supplies specific
    information about the target database needed to fulfill each task. For instance,
    “Exclusively virtual refers to Virtual = ‘F”’. With such oracle knowledge, the
    complexity of the environments is substantially mitigated; it offers a shortcut
    for the task and eliminates the necessity for deep engagement with the database.
    This cheating setting is also unrealistic for practical applications. As a result,
    we stick to the setting without oracle knowledge. For each of the $1534$ questions)
    and enables fine-grained insights into the LLM’s performance. In addition to execution
    accuracy (EX) used in Bird, which determines if the execution results of the predicted
    SQL match those of the ground truth SQL, we also evaluate whether the predicted
    SQL is a valid SQL query (VA).'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于数据库，我们利用 Bird Li et al. ([2023a](#bib.bib18))，这是一个以其复杂性而著称的最新数据集，具有高度复杂数据库的复杂指令。Bird
    最初有两种不同的设置：有和没有 oracle 知识，其中 oracle 知识提供了完成每个任务所需的目标数据库的具体信息。例如，“Exclusively virtual
    指的是 Virtual = 'F'”。有了这种 oracle 知识，环境的复杂性大大降低；它为任务提供了捷径，消除了对数据库深入接触的必要性。这种作弊设置在实际应用中也不现实。因此，我们坚持没有
    oracle 知识的设置。对于每个 $1534$ 个问题，并提供了对 LLM 性能的细致洞察。除了 Bird 中用于确定预测 SQL 执行结果是否与真实 SQL
    一致的执行准确性（EX）外，我们还评估预测 SQL 是否是有效的 SQL 查询（VA）。
- en: KBs
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 知识库
- en: 'We curate KBQA-Agent, a new test set sourcing from existing KBQA datasets that
    contain complex questions. In particular, we selected $500$ diverse questions
    that involve at least three relations, or two relations coupled with an aggregation
    function (i.e., Counting or Superlative). For each question, we annotate it with
    a ground truth sequence of actions based on the toolset defined by us.³³3We leverage
    the gold S-expressions provided by Gu and Su ([2022](#bib.bib11)). Our dataset
    has been served as part of AgentBench Liu et al. ([2023](#bib.bib21)). Specifically,
    KBQA-Agent comprises questions from three KBQA datasets on Freebase: GrailQA Gu
    et al. ([2021](#bib.bib9)), ComplexWebQ Talmor and Berant ([2018](#bib.bib38)),
    and GraphQ Su et al. ([2016](#bib.bib35)), ensuring a wide range of question types
    and sources. KBQA-Agent is designed to be more representative of challenging,
    real-world scenarios compared to existing benchmarks (Appendix [B](#A2 "Appendix
    B Benchmark Statistics ‣ Middleware for LLMs: Tools Are Instrumental for Language
    Agents in Complex Environments")). It offers an ideal testbed for evaluating language
    agents in interacting with massive KBs. We assess this through two metrics: F1
    of answer entities and Validity (VA), a binary metric evaluating the LLM’s ability
    to find an answer, whether correct or not.'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们策划了KBQA-Agent，一个新的测试集，来源于现有的KBQA数据集，其中包含复杂的问题。特别是，我们选择了$500$个涉及至少三种关系，或两种关系加上聚合函数（即计数或最高级）的多样化问题。对于每个问题，我们根据我们定义的工具集对其进行了带有真实动作序列的标注。³³3我们利用了Gu和Su提供的黄金S表达式（[2022](#bib.bib11)）。我们的数据集已经作为AgentBench的一部分服务于Liu等人（[2023](#bib.bib21)）。具体来说，KBQA-Agent包含了来自Freebase的三个KBQA数据集中的问题：GrailQA（Gu等人，[2021](#bib.bib9)），ComplexWebQ（Talmor和Berant，[2018](#bib.bib38)），和GraphQ（Su等人，[2016](#bib.bib35)），确保了问题类型和来源的广泛覆盖。与现有基准相比，KBQA-Agent旨在更具代表性地反映具有挑战性的现实场景（附录[B](#A2
    "附录 B 基准统计 ‣ 中间件对LLM的重要性：工具在复杂环境中的语言代理中的作用")）。它为评估语言代理在与大量知识库互动时提供了理想的测试平台。我们通过两个指标进行评估：答案实体的F1和有效性（VA），后者是一个二元指标，用于评估LLM是否能找到答案，无论正确与否。
- en: '![Refer to caption](img/a4e96952e7dcfddc84d8b39db46ae180.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/a4e96952e7dcfddc84d8b39db46ae180.png)'
- en: 'Figure 3: The open-source LLMs still largely lag behind GPT-3.5-turbo and GPT-4
    in both environments.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：开源LLM在两个环境中仍然明显落后于GPT-3.5-turbo和GPT-4。
- en: 5 Experiments
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 实验
- en: 5.1 Setup
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 设置
- en: Implementation
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实施
- en: 'To concretely instantiate our tools for the two environments, we employ standard
    query interfaces for databases and KBs, specifically SQLite for databases and
    Virtuoso for KBs. We then prompt the LLM with the tool descriptions together with
    the input task instructions (Appendix [C](#A3 "Appendix C Prompts ‣ Middleware
    for LLMs: Tools Are Instrumental for Language Agents in Complex Environments")).
    Each environment exhibits its own unique characteristics and challenges. In KBQA,
    the arguments for each function are either a variable or an item from the KB schema
    (i.e., a relation or an attribute). In contrast, in text-to-SQL parsing, the arguments
    can be more varied, ranging from a part of a SQL query to a complete query. This
    makes listing potential actions, as needed in decoupled generation, much more
    complex for text-to-SQL parsing. Therefore, we implement error feedback solely
    for text-to-SQL parsing.'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了具体实现我们在两个环境中的工具，我们采用了标准的数据库和KB查询接口，具体为数据库使用SQLite，KB使用Virtuoso。然后，我们将工具描述与输入任务说明一起提示给LLM（附录[C](#A3
    "附录 C 提示 ‣ 中间件对LLM的重要性：工具在复杂环境中的语言代理中的作用")）。每个环境都展现出其独特的特征和挑战。在KBQA中，每个函数的参数要么是变量，要么是来自KB模式的条目（即关系或属性）。相比之下，在文本到SQL解析中，参数可能更加多样，从SQL查询的一部分到完整的查询都有。这使得在文本到SQL解析中列出潜在动作（如解耦生成所需）变得更加复杂。因此，我们仅对文本到SQL解析实施错误反馈。
- en: 'For the underlying LLMs, we primarily compare Fuxi with baseline methods using
    two of the most advanced LLMs—GPT-3.5-turbo OpenAI ([2023b](#bib.bib26)) and GPT-4 OpenAI
    ([2023a](#bib.bib25))—since our goal is investigating the full potential of tool-enhanced
    LLMs operating within complex environments. In addition, we also explore four
    open-source LLMs to more comprehensively evaluate our framework: Llama2-7B-Chat,
    Llama2-13B-Chat Touvron et al. ([2023](#bib.bib39)), Mistral-7B-Instruct-v0.2 Jiang
    et al. ([2023a](#bib.bib15)), and Mixtral 8$\times$7B-Instruct-v0.1 Jiang et al.
    ([2024](#bib.bib16)).'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于底层的LLMs，我们主要使用两个最先进的LLMs——GPT-3.5-turbo OpenAI ([2023b](#bib.bib26)) 和 GPT-4
    OpenAI ([2023a](#bib.bib25))——将Fuxi与基线方法进行比较，因为我们的目标是**研究工具增强型LLMs**在复杂环境中发挥的**全部潜力**。此外，我们还探索了四个开源LLMs，以更全面地评估我们的框架：Llama2-7B-Chat，Llama2-13B-Chat
    Touvron et al. ([2023](#bib.bib39))，Mistral-7B-Instruct-v0.2 Jiang et al. ([2023a](#bib.bib15))，以及Mixtral
    8$\times$7B-Instruct-v0.1 Jiang et al. ([2024](#bib.bib16))。
- en: '![Refer to caption](img/8f0b6ac2d6d22546fde3d02315c6c4f7.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/8f0b6ac2d6d22546fde3d02315c6c4f7.png)'
- en: 'Figure 4: The customized tools can serve as effective middleware between the
    LLM and the environment.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：定制工具可以作为LLM与环境之间的有效中间件。
- en: Baselines
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基线
- en: 'To fully understand the potential of tool augmentation for assisting LLMs in
    handling complex environments, we compare Fuxi against an array of strong baselines.
    For text-to-SQL parsing, LLMs demonstrate a strong ability to compose SQL queries
    when properly prompted with the database schema (i.e., API docs prompting Rajkumar
    et al. ([2022](#bib.bib29))). This also represents the current state-of-the-art
    prompting-based method when oracle knowledge is not available on Bird’s leaderboard.⁴⁴4https://bird-bench.github.io
    In addition, we experiment with StructGPT Jiang et al. ([2023b](#bib.bib17)),
    which represents an advanced text-to-SQL parsing method leveraging tools. For
    all methods on text-to-SQL parsing, we adopt the zero-shot setting. Unlike text-to-SQL
    parsing, directly prompting LLMs does not generate reasonable outputs for KBQA
    due to the massive size of the KB schema. Instead, existing KBQA methods based
    on LLMs typically follow two paradigms: either first generating an ungrounded
    program and then grounding the program to the KB schema afterwards Li et al. ([2023c](#bib.bib20));
    Nie et al. ([2023](#bib.bib24)), or gradually constructing a complex program and
    grounding it step by step Gu et al. ([2023](#bib.bib8)). We compare Fuxi with
    the most representative work from each paradigm, namely KB-Binder Li et al. ([2023c](#bib.bib20))
    and Pangu Gu et al. ([2023](#bib.bib8)). We also include StructGPT as an additional
    baseline for tool use. For all KBQA methods except KB-Binder, we provide a one-shot
    demo to obtain more meaningful results.'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了**全面理解**工具增强对LLMs处理复杂环境的潜力，我们将Fuxi与一系列强大的基线方法进行了比较。在文本到SQL解析中，当适当地提供数据库模式（即API文档提示
    Rajkumar et al. ([2022](#bib.bib29)))时，LLMs展示了强大的SQL查询生成能力。这也代表了当前最先进的基于提示的方法，当在Bird的排行榜上没有oracle知识时。⁴⁴4https://bird-bench.github.io
    另外，我们还实验了StructGPT Jiang et al. ([2023b](#bib.bib17))，这是一种利用工具的高级文本到SQL解析方法。对于所有文本到SQL解析的方法，我们采用零-shot设置。与文本到SQL解析不同，由于KB模式的庞大规模，直接提示LLMs不会生成合理的KBQA输出。现有的基于LLMs的KBQA方法通常遵循两种范式：要么首先生成一个无基础的程序，然后将程序与KB模式进行对接
    Li et al. ([2023c](#bib.bib20)); Nie et al. ([2023](#bib.bib24))，要么逐步构建复杂程序，并一步步对接
    Gu et al. ([2023](#bib.bib8))。我们将Fuxi与每个范式中最具代表性的工作进行比较，即KB-Binder Li et al. ([2023c](#bib.bib20))
    和 Pangu Gu et al. ([2023](#bib.bib8))。我们还将StructGPT作为工具使用的额外基线。对于所有KBQA方法，除了KB-Binder，我们提供了一个one-shot演示以获得更有意义的结果。
- en: 5.2 Main Results
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 主要结果
- en: 'As shown in Tables [1](#S3.T1 "Table 1 ‣ 3.2 Reasoning with Tools ‣ 3 Fuxi
    ‣ Middleware for LLMs: Tools Are Instrumental for Language Agents in Complex Environments")
    and [2](#S3.T2 "Table 2 ‣ 3.2 Reasoning with Tools ‣ 3 Fuxi ‣ Middleware for LLMs:
    Tools Are Instrumental for Language Agents in Complex Environments"), equipping
    LLMs with customized tools leads to significant improvement over previous standards,
    almost doubling or tripling the performance under multiple metrics. Specifically,
    API docs prompting can only feed the schema information to the LLM due to the
    vast amount of database content. As a result, it fails catastrophically on examples
    that require database content to compose the SQL query. In contrast, Fuxi equips
    the agent with tools to actively navigate the database to collect relevant information
    for composing a SQL query. As a result, Fuxi significantly closes the gap between
    performance on questions requiring database content and questions not requiring
    it when using GPT-4 (i.e., $45.1$% in F1. As for the other two baselines, KB-Binder
    and StructGPT, both fail miserably on our challenging setting. On the one hand,
    KB-Binder only retrieves relations within two hops from the entities for grounding.
    However, most questions in KBQA-Agent involve more than two relations. As a result,
    many of its drafted programs are unable to ground, which explains its low VA.
    On the other hand, StructGPT is heavily limited by its constrained toolset and
    cannot handle complex questions in KBQA-Agent. Therefore, StructGPT frequently
    refuses to provide an answer (as revealed by its low VA) due to insufficient information.
    The strong performance of Fuxi underscores that tools are instrumental for language
    agents in complex environments.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如表[1](#S3.T1 "表 1 ‣ 3.2 使用工具推理 ‣ 3 Fuxi ‣ LLM的中间件：工具对复杂环境中的语言代理至关重要")和[2](#S3.T2
    "表 2 ‣ 3.2 使用工具推理 ‣ 3 Fuxi ‣ LLM的中间件：工具对复杂环境中的语言代理至关重要")所示，给LLM配备定制工具比以往标准显著提高性能，在多个指标下几乎翻倍或三倍。具体而言，由于海量的数据库内容，API文档提示仅能提供模式信息给LLM。因此，对于需要数据库内容来编写SQL查询的例子，它的表现会极其糟糕。相比之下，Fuxi为代理提供工具，以主动浏览数据库以收集编写SQL查询所需的相关信息。因此，Fuxi显著缩小了在需要数据库内容和不需要数据库内容的问题上的性能差距（即，GPT-4中的F1达到$45.1$%）。至于其他两个基准，KB-Binder和StructGPT，都在我们具有挑战性的设置中表现糟糕。一方面，KB-Binder仅从实体处检索两跳内的关系用于定位。然而，KBQA-Agent中的大多数问题涉及超过两个关系。因此，它草拟的许多程序无法进行定位，这解释了其低VA。另一方面，StructGPT受限于其有限的工具集，无法处理KBQA-Agent中的复杂问题。因此，StructGPT经常因为信息不足而拒绝提供答案（由其低VA揭示）。Fuxi的强大表现强调了工具在复杂环境中对语言代理的重要性。
- en: 5.3 Experiments with Open-Source LLMs
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 与开源LLM的实验
- en: 'To gain a more thorough insight, we also include experiments with four open-source
    LLMs ( Figure [3](#S4.F3 "Figure 3 ‣ 4 Benchmarks ‣ Middleware for LLMs: Tools
    Are Instrumental for Language Agents in Complex Environments")). Our findings
    indicate that Llama2 models generally underperform compared to other LLMs, aligning
    with trends observed in other LLM leaderboards, such as Chatbot Arena Zheng et al.
    ([2023](#bib.bib46)). Specifically, we find Llama2 models struggle with even generating
    grammatical tool use following our instruction. On the other hand, Mistral and
    Mixtral demonstrate much better performance than Llama2. In particular, Mixtral
    represents an advanced mixture-of-experts model that has demonstrated superior
    performance and even surpasses GPT-3.5-turbo on Chatbot Arena Zheng et al. ([2023](#bib.bib46)).
    However, different from answering open-ended questions featured in Chatbot Arena,
    properly engaging with the complex environment demands the language agent to produce
    more precise actions that strictly conform to the task specification. There is
    still a performance gap between Mixtral and GPT-3.5-turbo in terms of predicting
    valid actions over intricate environments. Compared to GPT-3.5-turbo, Mixtral
    tends to output invalid actions more frequently. This also explains why decoupled
    generation, where the output space is strictly constrained to a list of valid
    actions, helps weaker models more. With Fuxi + decoupled generation, using Mistral
    can almost match the best baseline performance with GPT-3.5-turbo, and using Mixtral
    can even match the best baseline with GPT-4. While stronger models like GPT-4
    can effectively recover the mistake via error feedback, weaker models tend to
    benefit more from decoupled generation.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得更深入的见解，我们还包括了四个开源LLMs的实验（图 [3](#S4.F3 "图 3 ‣ 4 基准 ‣ LLMs的中间件：工具对复杂环境中的语言代理至关重要")）。我们的发现表明，Llama2模型通常表现不如其他LLMs，与其他LLM排行榜（如Chatbot
    Arena Zheng等人 [2023](#bib.bib46)）中的趋势一致。具体而言，我们发现Llama2模型即使在按照指示生成语法正确的工具使用方面也有困难。另一方面，Mistral和Mixtral表现明显优于Llama2。特别是，Mixtral代表了一种先进的专家混合模型，已展示出卓越的性能，甚至在Chatbot
    Arena Zheng等人 [2023](#bib.bib46)中超越了GPT-3.5-turbo。然而，与Chatbot Arena中的开放性问题回答不同，与复杂环境的有效互动要求语言代理产生更加精确的动作，这些动作严格符合任务规范。在预测复杂环境中的有效动作方面，Mixtral和GPT-3.5-turbo之间仍然存在性能差距。与GPT-3.5-turbo相比，Mixtral更倾向于输出无效动作。这也解释了为什么去耦生成（其中输出空间严格限制为有效动作列表）对较弱的模型更有帮助。通过Fuxi
    + 去耦生成，使用Mistral几乎可以匹配GPT-3.5-turbo的最佳基线性能，而使用Mixtral甚至可以匹配GPT-4的最佳基线。虽然像GPT-4这样更强的模型可以通过错误反馈有效纠正错误，但较弱的模型往往从去耦生成中受益更多。
- en: 5.4 Tools as A Middleware Layer
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 工具作为中间件层
- en: 'To deepen our understanding of the integral roles of tools in aiding LLMs in
    accessing complex environments (i.e., KB triples and database rows in our setup),
    we conduct further analysis by comparing Fuxi with prompting baselines with different
    amounts of data items directly sampled from the environment (Figure [4](#S5.F4
    "Figure 4 ‣ 5.1 Setup ‣ 5 Experiments ‣ Middleware for LLMs: Tools Are Instrumental
    for Language Agents in Complex Environments")). For the KB, we sample $10$ rows
    per table).'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更深入地理解工具在帮助LLMs访问复杂环境（即我们设置中的KB三元组和数据库行）中的核心作用，我们通过将Fuxi与不同数量的数据项直接从环境中抽样的提示基线进行比较，进行进一步分析（图 [4](#S5.F4
    "图 4 ‣ 5.1 设置 ‣ 5 实验 ‣ LLMs的中间件：工具对复杂环境中的语言代理至关重要")）。对于KB，我们从每个表中抽取$10$行。
- en: 6 Conclusion
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: A pioneering vision is for language agents to assist humans in tackling intricate
    real-world tasks. This paper demonstrates that with meticulously-crafted tools
    acting as middleware between LLMs and complex environments, LLMs can substantially
    exceed current solutions. Our results spotlight these specialized tools’ indispensable
    role in unlocking the potential of LLMs within complex real-world tasks previously
    posing immense challenges.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 一种开创性的愿景是让语言代理帮助人类应对复杂的现实世界任务。本文展示了通过精心设计的工具作为LLMs和复杂环境之间的中间件，LLMs可以大幅超越当前的解决方案。我们的结果突显了这些专业工具在解锁LLMs在以前带来巨大挑战的复杂现实世界任务中的潜力方面的不可或缺的作用。
- en: Limitations
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 局限性
- en: 'In this paper, we aim to address the compelling question we posed: how effectively
    can LLMs handle complex environments with the aid of tools? We investigate this
    through evaluations in two exemplary environments: KBs and databases. While we
    achieve notable results in these environments, it is important to acknowledge
    that implementing customized tools for KBs and databases presents fewer challenges
    compared to environments without a straightforward query interface, such as a
    webpage or a physical environment. In future work, we plan to extend Fuxi across
    a broader range of environments, aiming to fully realize the potential of language
    agents in complex environments through the integration of customized middleware
    tools.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们旨在解决我们提出的有趣问题：大型语言模型（LLMs）在工具的帮助下能多有效地处理复杂环境？我们通过在两个典型环境——知识库（KBs）和数据库——中的评估来研究这一问题。虽然我们在这些环境中取得了显著结果，但必须承认，为知识库和数据库实施定制工具相较于没有直接查询界面的环境（例如网页或物理环境）面临的挑战较少。在未来的工作中，我们计划将Fuxi扩展到更广泛的环境，旨在通过整合定制中间件工具，充分实现语言代理在复杂环境中的潜力。
- en: Furthermore, the tools developed in this study are soley grounded in our experience.
    Despite this, our results already demonstrate the significant potential of augmenting
    LLMs with customized tools in complex environments, aligning with the primary
    objective of this paper. Nonetheless, to enhance performance further, adopting
    a more principled strategy for tool design is essential.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，本研究中开发的工具完全基于我们的经验。尽管如此，我们的结果已经展示了在复杂环境中通过定制工具增强大型语言模型（LLMs）的显著潜力，与本文的主要目标相一致。然而，为了进一步提升性能，采用更有原则的工具设计策略是至关重要的。
- en: Acknowledgements
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: We would like to thank colleagues from THU KEG and the OSU NLP group for their
    thoughtful comments. In addition, we are grateful to the authors of Bird for kindly
    providing the original predictions of the baselines based on API Docs prompting.
    This research was supported by a sponsored award from Cisco Research.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢清华大学KEG团队和俄亥俄州立大学NLP小组的同事们提供的宝贵意见。此外，我们对Bird的作者表示感谢，他们友好地提供了基于API文档提示的基线预测结果。本研究得到了思科研究赞助的资助支持。
- en: References
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Berant et al. (2013) Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang.
    2013. [Semantic parsing on Freebase from question-answer pairs](https://aclanthology.org/D13-1160).
    In *Proceedings of the 2013 Conference on Empirical Methods in Natural Language
    Processing*, pages 1533–1544, Seattle, Washington, USA. Association for Computational
    Linguistics.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Berant 等人（2013）Jonathan Berant、Andrew Chou、Roy Frostig 和 Percy Liang。2013年。[在
    Freebase 上进行语义解析：从问答对](https://aclanthology.org/D13-1160)。收录于 *2013年自然语言处理实证方法会议论文集*，第1533–1544页，美国华盛顿州西雅图。计算语言学协会。
- en: 'Bollacker et al. (2008) Kurt D. Bollacker, Colin Evans, Praveen K. Paritosh,
    Tim Sturge, and Jamie Taylor. 2008. [Freebase: a collaboratively created graph
    database for structuring human knowledge](https://doi.org/10.1145/1376616.1376746).
    In *Proceedings of the ACM SIGMOD International Conference on Management of Data,
    SIGMOD 2008, Vancouver, BC, Canada, June 10-12, 2008*, pages 1247–1250\. ACM.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bollacker 等人（2008）Kurt D. Bollacker、Colin Evans、Praveen K. Paritosh、Tim Sturge
    和 Jamie Taylor。2008年。[Freebase：一个协作创建的图形数据库，用于结构化人类知识](https://doi.org/10.1145/1376616.1376746)。收录于
    *ACM SIGMOD国际数据管理会议论文集，SIGMOD 2008，加拿大不列颠哥伦比亚省温哥华，2008年6月10-12日*，第1247–1250页。ACM。
- en: 'Cao et al. (2022) Shulin Cao, Jiaxin Shi, Liangming Pan, Lunyiu Nie, Yutong
    Xiang, Lei Hou, Juanzi Li, Bin He, and Hanwang Zhang. 2022. [KQA Pro: A dataset
    with explicit compositional programs for complex question answering over knowledge
    base](https://doi.org/10.18653/v1/2022.acl-long.422). In *Proceedings of the 60th
    Annual Meeting of the Association for Computational Linguistics (Volume 1: Long
    Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022*, pages 6101–6119\. Association
    for Computational Linguistics.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cao 等人（2022）Shulin Cao、Jiaxin Shi、Liangming Pan、Lunyiu Nie、Yutong Xiang、Lei
    Hou、Juanzi Li、Bin He 和 Hanwang Zhang。2022年。[KQA Pro：一个用于复杂问题回答的显式组合程序的数据集](https://doi.org/10.18653/v1/2022.acl-long.422)。收录于
    *第60届计算语言学协会年会（第1卷：长篇论文），ACL 2022，爱尔兰都柏林，2022年5月22-27日*，第6101–6119页。计算语言学协会。
- en: 'Chandu et al. (2021) Khyathi Raghavi Chandu, Yonatan Bisk, and Alan W. Black.
    2021. [Grounding ’grounding’ in NLP](https://doi.org/10.18653/V1/2021.FINDINGS-ACL.375).
    In *Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021,
    Online Event, August 1-6, 2021*, volume ACL/IJCNLP 2021 of *Findings of ACL*,
    pages 4283–4305\. Association for Computational Linguistics.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chandu et al. (2021) Khyathi Raghavi Chandu, Yonatan Bisk, and Alan W. Black.
    2021. [在NLP中“扎根”](https://doi.org/10.18653/V1/2021.FINDINGS-ACL.375)。在*计算语言学协会会议发现：ACL/IJCNLP
    2021，在线事件，2021年8月1-6日*，ACL/IJCNLP 2021卷*ACL会议发现*，第4283–4305页。计算语言学协会。
- en: Chen et al. (2023) Xinyun Chen, Maxwell Lin, Nathanael Schärli, and Denny Zhou.
    2023. [Teaching large language models to self-debug](https://doi.org/10.48550/ARXIV.2304.05128).
    *CoRR*, abs/2304.05128.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. (2023) Xinyun Chen, Maxwell Lin, Nathanael Schärli, and Denny Zhou.
    2023. [教大型语言模型自我调试](https://doi.org/10.48550/ARXIV.2304.05128)。*CoRR*，abs/2304.05128。
- en: 'Deng et al. (2023) Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens,
    Boshi Wang, Huan Sun, and Yu Su. 2023. [Mind2web: Towards a generalist agent for
    the web](https://doi.org/10.48550/ARXIV.2306.06070). *CoRR*, abs/2306.06070.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deng et al. (2023) Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens,
    Boshi Wang, Huan Sun, and Yu Su. 2023. [Mind2web：朝向通用网络代理](https://doi.org/10.48550/ARXIV.2306.06070)。*CoRR*，abs/2306.06070。
- en: 'Gou et al. (2023) Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu
    Yang, Nan Duan, and Weizhu Chen. 2023. [CRITIC: large language models can self-correct
    with tool-interactive critiquing](https://doi.org/10.48550/ARXIV.2305.11738).
    *CoRR*, abs/2305.11738.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gou et al. (2023) Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang,
    Nan Duan, and Weizhu Chen. 2023. [CRITIC：大型语言模型可以通过工具交互批评自我修正](https://doi.org/10.48550/ARXIV.2305.11738)。*CoRR*，abs/2305.11738。
- en: 'Gu et al. (2023) Yu Gu, Xiang Deng, and Yu Su. 2023. [Don’t generate, discriminate:
    A proposal for grounding language models to real-world environments](https://doi.org/10.18653/v1/2023.acl-long.270).
    In *Proceedings of the 61st Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023*,
    pages 4928–4949\. Association for Computational Linguistics.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gu et al. (2023) Yu Gu, Xiang Deng, and Yu Su. 2023. [不要生成，而是区分：将语言模型与现实世界环境结合的提议](https://doi.org/10.18653/v1/2023.acl-long.270)。在*第61届计算语言学协会年会论文集（第1卷：长篇论文），ACL
    2023，多伦多，加拿大，2023年7月9-14日*，第4928–4949页。计算语言学协会。
- en: 'Gu et al. (2021) Yu Gu, Sue Kase, Michelle Vanni, Brian M. Sadler, Percy Liang,
    Xifeng Yan, and Yu Su. 2021. [Beyond I.I.D.: three levels of generalization for
    question answering on knowledge bases](https://doi.org/10.1145/3442381.3449992).
    In *WWW ’21: The Web Conference 2021, Virtual Event / Ljubljana, Slovenia, April
    19-23, 2021*, pages 3477–3488\. ACM / IW3C2.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gu et al. (2021) Yu Gu, Sue Kase, Michelle Vanni, Brian M. Sadler, Percy Liang,
    Xifeng Yan, and Yu Su. 2021. [超越I.I.D.：知识库问答的三个泛化层次](https://doi.org/10.1145/3442381.3449992)。在*WWW
    ’21：2021年网络会议，虚拟事件 / 卤卢布拉纳，斯洛文尼亚，2021年4月19-23日*，第3477–3488页。ACM / IW3C2。
- en: 'Gu et al. (2022) Yu Gu, Vardaan Pahuja, Gong Cheng, and Yu Su. 2022. [Knowledge
    base question answering: A semantic parsing perspective](https://doi.org/10.48550/arXiv.2209.04994).
    In *4th Conference on Automated Knowledge Base Construction*.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gu et al. (2022) Yu Gu, Vardaan Pahuja, Gong Cheng, and Yu Su. 2022. [知识库问答：语义解析视角](https://doi.org/10.48550/arXiv.2209.04994)。在*第四届自动化知识库构建会议*。
- en: 'Gu and Su (2022) Yu Gu and Yu Su. 2022. [ArcaneQA: Dynamic program induction
    and contextualized encoding for knowledge base question answering](https://aclanthology.org/2022.coling-1.148).
    In *Proceedings of the 29th International Conference on Computational Linguistics*,
    pages 1718–1731, Gyeongju, Republic of Korea. International Committee on Computational
    Linguistics.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gu and Su (2022) Yu Gu and Yu Su. 2022. [ArcaneQA：动态程序归纳和上下文化编码用于知识库问答](https://aclanthology.org/2022.coling-1.148)。在*第29届国际计算语言学会议论文集*，第1718–1731页，庆州，韩国。国际计算语言学委员会。
- en: Guan et al. (2023) Lin Guan, Karthik Valmeekam, Sarath Sreedharan, and Subbarao
    Kambhampati. 2023. [Leveraging pre-trained large language models to construct
    and utilize world models for model-based task planning](https://doi.org/10.48550/ARXIV.2305.14909).
    *CoRR*, abs/2305.14909.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guan et al. (2023) Lin Guan, Karthik Valmeekam, Sarath Sreedharan, and Subbarao
    Kambhampati. 2023. [利用预训练的大型语言模型构建和利用世界模型进行基于模型的任务规划](https://doi.org/10.48550/ARXIV.2305.14909)。*CoRR*，abs/2305.14909。
- en: 'Hao et al. (2023) Shibo Hao, Tianyang Liu, Zhen Wang, and Zhiting Hu. 2023.
    [Toolkengpt: Augmenting frozen language models with massive tools via tool embeddings](https://doi.org/10.48550/arXiv.2305.11554).
    *CoRR*, abs/2305.11554.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hao 等 (2023) Shibo Hao, Tianyang Liu, Zhen Wang, 和 Zhiting Hu. 2023. [Toolkengpt：通过工具嵌入增强冻结的语言模型](https://doi.org/10.48550/arXiv.2305.11554)。*CoRR*，abs/2305.11554。
- en: Hwang et al. (2019) Wonseok Hwang, Jinyeung Yim, Seunghyun Park, and Minjoon
    Seo. 2019. [A comprehensive exploration on wikisql with table-aware word contextualization](http://arxiv.org/abs/1902.01069).
    *CoRR*, abs/1902.01069.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hwang 等 (2019) Wonseok Hwang, Jinyeung Yim, Seunghyun Park, 和 Minjoon Seo. 2019.
    [对 WikiSQL 的全面探索：基于表的词语上下文化](http://arxiv.org/abs/1902.01069)。*CoRR*，abs/1902.01069。
- en: Jiang et al. (2023a) Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch,
    Chris Bamford, Devendra Singh Chaplot, Diego de Las Casas, Florian Bressand, Gianna
    Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux,
    Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and
    William El Sayed. 2023a. [Mistral 7b](https://doi.org/10.48550/ARXIV.2310.06825).
    *CoRR*, abs/2310.06825.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang 等 (2023a) Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris
    Bamford, Devendra Singh Chaplot, Diego de Las Casas, Florian Bressand, Gianna
    Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux,
    Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, 和
    William El Sayed. 2023a. [Mistral 7b](https://doi.org/10.48550/ARXIV.2310.06825)。*CoRR*，abs/2310.06825。
- en: Jiang et al. (2024) Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur
    Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de Las Casas,
    Emma Bou Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample,
    L’elio Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Sandeep
    Subramanian, Sophia Yang, Szymon Antoniak, Teven Le Scao, Théophile Gervet, Thibaut
    Lavril, Thomas Wang, Timothée Lacroix, and William El Sayed. 2024. [Mixtral of
    experts](http://arxiv.org/abs/2401.04088). *CoRR*.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang 等 (2024) Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur
    Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de Las Casas,
    Emma Bou Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample,
    L’elio Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Sandeep
    Subramanian, Sophia Yang, Szymon Antoniak, Teven Le Scao, Théophile Gervet, Thibaut
    Lavril, Thomas Wang, Timothée Lacroix, 和 William El Sayed. 2024. [专家混合模型](http://arxiv.org/abs/2401.04088)。*CoRR*。
- en: 'Jiang et al. (2023b) Jinhao Jiang, Kun Zhou, Zican Dong, Keming Ye, Wayne Xin
    Zhao, and Ji-Rong Wen. 2023b. [StructGPT: A general framework for large language
    model to reason over structured data](https://doi.org/10.48550/arXiv.2305.09645).
    *CoRR*, abs/2305.09645.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang 等 (2023b) Jinhao Jiang, Kun Zhou, Zican Dong, Keming Ye, Wayne Xin Zhao,
    和 Ji-Rong Wen. 2023b. [StructGPT：一个通用框架，用于大型语言模型推理结构化数据](https://doi.org/10.48550/arXiv.2305.09645)。*CoRR*，abs/2305.09645。
- en: Li et al. (2023a) Jinyang Li, Binyuan Hui, Ge Qu, Binhua Li, Jiaxi Yang, Bowen
    Li, Bailin Wang, Bowen Qin, Rongyu Cao, Ruiying Geng, Nan Huo, Xuanhe Zhou, Chenhao
    Ma, Guoliang Li, Kevin Chen-Chuan Chang, Fei Huang, Reynold Cheng, and Yongbin
    Li. 2023a. [Can LLM already serve as A database interface? A big bench for large-scale
    database grounded text-to-sqls](https://doi.org/10.48550/ARXIV.2305.03111). *CoRR*,
    abs/2305.03111.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等 (2023a) Jinyang Li, Binyuan Hui, Ge Qu, Binhua Li, Jiaxi Yang, Bowen Li,
    Bailin Wang, Bowen Qin, Rongyu Cao, Ruiying Geng, Nan Huo, Xuanhe Zhou, Chenhao
    Ma, Guoliang Li, Kevin Chen-Chuan Chang, Fei Huang, Reynold Cheng, 和 Yongbin Li.
    2023a. [LLM 能否作为数据库接口？大规模数据库基础的文本到 SQL 的大基准](https://doi.org/10.48550/ARXIV.2305.03111)。*CoRR*，abs/2305.03111。
- en: 'Li et al. (2023b) Minghao Li, Feifan Song, Bowen Yu, Haiyang Yu, Zhoujun Li,
    Fei Huang, and Yongbin Li. 2023b. [API-Bank: A benchmark for tool-augmented llms](https://doi.org/10.48550/arXiv.2304.08244).
    *CoRR*, abs/2304.08244.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等 (2023b) Minghao Li, Feifan Song, Bowen Yu, Haiyang Yu, Zhoujun Li, Fei
    Huang, 和 Yongbin Li. 2023b. [API-Bank：工具增强大语言模型的基准测试](https://doi.org/10.48550/arXiv.2304.08244)。*CoRR*，abs/2304.08244。
- en: Li et al. (2023c) Tianle Li, Xueguang Ma, Alex Zhuang, Yu Gu, Yu Su, and Wenhu
    Chen. 2023c. [Few-shot in-context learning on knowledge base question answering](https://api.semanticscholar.org/CorpusID:258461017).
    In *Annual Meeting of the Association for Computational Linguistics*.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等 (2023c) Tianle Li, Xueguang Ma, Alex Zhuang, Yu Gu, Yu Su, 和 Wenhu Chen.
    2023c. [基于知识库问答的少量样本上下文学习](https://api.semanticscholar.org/CorpusID:258461017)。在
    *计算语言学协会年会* 上。
- en: 'Liu et al. (2023) Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu
    Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng,
    Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan
    Sun, Minlie Huang, Yuxiao Dong, and Jie Tang. 2023. [AgentBench: Evaluating llms
    as agents](https://doi.org/10.48550/arXiv.2308.03688). *CoRR*, abs/2308.03688.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2023) Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu
    Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng,
    Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan
    Sun, Minlie Huang, Yuxiao Dong, and Jie Tang. 2023. [AgentBench：评估作为代理的 llms](https://doi.org/10.48550/arXiv.2308.03688)。*CoRR*，abs/2308.03688。
- en: 'Lu et al. (2023) Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang,
    Ying Nian Wu, Song-Chun Zhu, and Jianfeng Gao. 2023. [Chameleon: Plug-and-play
    compositional reasoning with large language models](https://doi.org/10.48550/ARXIV.2304.09842).
    *CoRR*, abs/2304.09842.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lu et al. (2023) Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang,
    Ying Nian Wu, Song-Chun Zhu, and Jianfeng Gao. 2023. [Chameleon：大语言模型的即插即用组合推理](https://doi.org/10.48550/ARXIV.2304.09842)。*CoRR*，abs/2304.09842。
- en: 'Mialon et al. (2023) Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos
    Nalmpantis, Ramakanth Pasunuru, Roberta Raileanu, Baptiste Rozière, Timo Schick,
    Jane Dwivedi-Yu, Asli Celikyilmaz, Edouard Grave, Yann LeCun, and Thomas Scialom.
    2023. [Augmented language models: a survey](https://doi.org/10.48550/ARXIV.2302.07842).
    *CoRR*, abs/2302.07842.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mialon et al. (2023) Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos
    Nalmpantis, Ramakanth Pasunuru, Roberta Raileanu, Baptiste Rozière, Timo Schick,
    Jane Dwivedi-Yu, Asli Celikyilmaz, Edouard Grave, Yann LeCun, and Thomas Scialom.
    2023. [增强语言模型：综述](https://doi.org/10.48550/ARXIV.2302.07842)。*CoRR*，abs/2302.07842。
- en: Nie et al. (2023) Zhijie Nie, Richong Zhang, Zhongyuan Wang, and Xudong Liu.
    2023. [Code-style in-context learning for knowledge-based question answering](https://doi.org/10.48550/ARXIV.2309.04695).
    *CoRR*, abs/2309.04695.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nie et al. (2023) Zhijie Nie, Richong Zhang, Zhongyuan Wang, and Xudong Liu.
    2023. [基于代码风格的上下文学习用于知识问答](https://doi.org/10.48550/ARXIV.2309.04695)。*CoRR*，abs/2309.04695。
- en: OpenAI (2023a) OpenAI. 2023a. [GPT-4 technical report](https://doi.org/10.48550/arXiv.2303.08774).
    *CoRR*, abs/2303.08774.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI (2023a) OpenAI. 2023a. [GPT-4 技术报告](https://doi.org/10.48550/arXiv.2303.08774)。*CoRR*，abs/2303.08774。
- en: OpenAI (2023b) OpenAI. 2023b. Models - OpenAI API. [https://platform.openai.com/docs/models/gpt-3-5](https://platform.openai.com/docs/models/gpt-3-5).
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI (2023b) OpenAI. 2023b. 模型 - OpenAI API. [https://platform.openai.com/docs/models/gpt-3-5](https://platform.openai.com/docs/models/gpt-3-5)。
- en: Qin et al. (2023a) Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding,
    Ganqu Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han, Yi Ren Fung, Yusheng
    Su, Huadong Wang, Cheng Qian, Runchu Tian, Kunlun Zhu, Shihao Liang, Xingyu Shen,
    Bokai Xu, Zhen Zhang, Yining Ye, Bowen Li, Ziwei Tang, Jing Yi, Yuzhang Zhu, Zhenning
    Dai, Lan Yan, Xin Cong, Yaxi Lu, Weilin Zhao, Yuxiang Huang, Junxi Yan, Xu Han,
    Xian Sun, Dahai Li, Jason Phang, Cheng Yang, Tongshuang Wu, Heng Ji, Zhiyuan Liu,
    and Maosong Sun. 2023a. [Tool learning with foundation models](https://doi.org/10.48550/arXiv.2304.08354).
    *CoRR*, abs/2304.08354.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qin et al. (2023a) Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding,
    Ganqu Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han, Yi Ren Fung, Yusheng
    Su, Huadong Wang, Cheng Qian, Runchu Tian, Kunlun Zhu, Shihao Liang, Xingyu Shen,
    Bokai Xu, Zhen Zhang, Yining Ye, Bowen Li, Ziwei Tang, Jing Yi, Yuzhang Zhu, Zhenning
    Dai, Lan Yan, Xin Cong, Yaxi Lu, Weilin Zhao, Yuxiang Huang, Junxi Yan, Xu Han,
    Xian Sun, Dahai Li, Jason Phang, Cheng Yang, Tongshuang Wu, Heng Ji, Zhiyuan Liu,
    and Maosong Sun. 2023a. [工具学习与基础模型](https://doi.org/10.48550/arXiv.2304.08354)。*CoRR*，abs/2304.08354。
- en: 'Qin et al. (2023b) Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan,
    Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Runchu Tian,
    Ruobing Xie, Jie Zhou, Mark Gerstein, Dahai Li, Zhiyuan Liu, and Maosong Sun.
    2023b. [ToolLLM: Facilitating large language models to master 16000+ real-world
    apis](https://doi.org/10.48550/ARXIV.2307.16789). *CoRR*, abs/2307.16789.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qin et al. (2023b) Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan,
    Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Runchu Tian,
    Ruobing Xie, Jie Zhou, Mark Gerstein, Dahai Li, Zhiyuan Liu, and Maosong Sun.
    2023b. [ToolLLM：助力大语言模型掌握 16000+ 实际应用接口](https://doi.org/10.48550/ARXIV.2307.16789)。*CoRR*，abs/2307.16789。
- en: Rajkumar et al. (2022) Nitarshan Rajkumar, Raymond Li, and Dzmitry Bahdanau.
    2022. [Evaluating the text-to-sql capabilities of large language models](https://doi.org/10.48550/ARXIV.2204.00498).
    *CoRR*, abs/2204.00498.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rajkumar et al. (2022) Nitarshan Rajkumar, Raymond Li, and Dzmitry Bahdanau.
    2022. [评估大语言模型的文本到 SQL 能力](https://doi.org/10.48550/ARXIV.2204.00498)。*CoRR*，abs/2204.00498。
- en: 'Reimers and Gurevych (2019) Nils Reimers and Iryna Gurevych. 2019. [Sentence-BERT:
    Sentence embeddings using Siamese BERT-networks](https://doi.org/10.18653/v1/D19-1410).
    In *Proceedings of the 2019 Conference on Empirical Methods in Natural Language
    Processing and the 9th International Joint Conference on Natural Language Processing
    (EMNLP-IJCNLP)*, pages 3982–3992, Hong Kong, China. Association for Computational
    Linguistics.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Reimers 和 Gurevych (2019) Nils Reimers 和 Iryna Gurevych. 2019. [Sentence-BERT:
    使用 Siamese BERT 网络的句子嵌入](https://doi.org/10.18653/v1/D19-1410)。发表于 *2019 年自然语言处理实证方法会议和第九届国际联合自然语言处理会议
    (EMNLP-IJCNLP) 的会议论文集*，页码 3982–3992，香港，中国。计算语言学协会。'
- en: 'Schick et al. (2023) Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu,
    Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023. [Toolformer:
    Language models can teach themselves to use tools](https://doi.org/10.48550/arXiv.2302.04761).
    *CoRR*, abs/2302.04761.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Schick 等 (2023) Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu,
    Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda 和 Thomas Scialom. 2023. [Toolformer:
    语言模型可以自我学习使用工具](https://doi.org/10.48550/arXiv.2302.04761)。*CoRR*, abs/2302.04761。'
- en: 'Shridhar et al. (2021) Mohit Shridhar, Xingdi Yuan, Marc-Alexandre Côté, Yonatan
    Bisk, Adam Trischler, and Matthew J. Hausknecht. 2021. [Alfworld: Aligning text
    and embodied environments for interactive learning](https://openreview.net/forum?id=0IOX0YcCdTn).
    In *9th International Conference on Learning Representations, ICLR 2021, Virtual
    Event, Austria, May 3-7, 2021*. OpenReview.net.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shridhar 等 (2021) Mohit Shridhar, Xingdi Yuan, Marc-Alexandre Côté, Yonatan
    Bisk, Adam Trischler 和 Matthew J. Hausknecht. 2021. [Alfworld: 对齐文本和具身环境以实现交互式学习](https://openreview.net/forum?id=0IOX0YcCdTn)。发表于
    *第九届国际学习表征会议，ICLR 2021，虚拟会议，奥地利，2021 年 5 月 3-7 日*。OpenReview.net。'
- en: 'Song et al. (2023) Chan Hee Song, Jiaman Wu, Clayton Washington, Brian M. Sadler,
    Wei-Lun Chao, and Yu Su. 2023. LLM-Planner: Few-shot grounded planning for embodied
    agents with large language models. In *Proceedings of the IEEE/CVF International
    Conference on Computer Vision (ICCV)*.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Song 等 (2023) Chan Hee Song, Jiaman Wu, Clayton Washington, Brian M. Sadler,
    Wei-Lun Chao 和 Yu Su. 2023. LLM-Planner: 大型语言模型驱动的具身体代理的少样本规划。发表于 *IEEE/CVF 国际计算机视觉会议
    (ICCV)* 论文集。'
- en: 'Su (2023) Yu Su. 2023. [Language agents: a critical evolutionary step of artificial
    intelligence](https://yusu.substack.com/p/language-agents). *yusu.substack.com*.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Su (2023) Yu Su. 2023. [语言代理：人工智能的一个关键进化步骤](https://yusu.substack.com/p/language-agents)。*yusu.substack.com*。
- en: Su et al. (2016) Yu Su, Huan Sun, Brian M. Sadler, Mudhakar Srivatsa, Izzeddin
    Gur, Zenghui Yan, and Xifeng Yan. 2016. [On generating characteristic-rich question
    sets for QA evaluation](https://doi.org/10.18653/V1/D16-1054). In *Proceedings
    of the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP
    2016, Austin, Texas, USA, November 1-4, 2016*, pages 562–572\. The Association
    for Computational Linguistics.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Su 等 (2016) Yu Su, Huan Sun, Brian M. Sadler, Mudhakar Srivatsa, Izzeddin Gur,
    Zenghui Yan 和 Xifeng Yan. 2016. [生成特征丰富的问答评估问题集](https://doi.org/10.18653/V1/D16-1054)。发表于
    *2016 年自然语言处理实证方法会议论文集，EMNLP 2016，美国德克萨斯州奥斯汀，2016 年 11 月 1-4 日*，页码 562–572。计算语言学协会。
- en: 'Sun et al. (2023) Shuo Sun, Yuchen Zhang, Jiahuan Yan, Yuze Gao, Donovan Ong,
    Bin Chen, and Jian Su. 2023. [Battle of the large language models: Dolly vs LLaMA
    vs vicuna vs guanaco vs bard vs ChatGPT - a text-to-SQL parsing comparison](https://doi.org/10.18653/v1/2023.findings-emnlp.750).
    In *Findings of the Association for Computational Linguistics: EMNLP 2023*, pages
    11225–11238, Singapore. Association for Computational Linguistics.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun 等 (2023) Shuo Sun, Yuchen Zhang, Jiahuan Yan, Yuze Gao, Donovan Ong, Bin
    Chen 和 Jian Su. 2023. [大型语言模型之战：Dolly 对 LLaMA 对 vicuna 对 guanaco 对 bard 对 ChatGPT
    - 一次文本到 SQL 解析比较](https://doi.org/10.18653/v1/2023.findings-emnlp.750)。发表于 *计算语言学协会会议成果：EMNLP
    2023*，页码 11225–11238，新加坡。计算语言学协会。
- en: Tai et al. (2023) Chang-Yu Tai, Ziru Chen, Tianshu Zhang, Xiang Deng, and Huan
    Sun. 2023. [Exploring chain of thought style prompting for text-to-sql](https://aclanthology.org/2023.emnlp-main.327).
    In *Proceedings of the 2023 Conference on Empirical Methods in Natural Language
    Processing, EMNLP 2023, Singapore, December 6-10, 2023*, pages 5376–5393\. Association
    for Computational Linguistics.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tai 等 (2023) Chang-Yu Tai, Ziru Chen, Tianshu Zhang, Xiang Deng 和 Huan Sun.
    2023. [探索链式思维风格提示在文本到 SQL 的应用](https://aclanthology.org/2023.emnlp-main.327)。发表于
    *2023 年自然语言处理实证方法会议，EMNLP 2023，新加坡，2023 年 12 月 6-10 日*，页码 5376–5393。计算语言学协会。
- en: 'Talmor and Berant (2018) Alon Talmor and Jonathan Berant. 2018. [The web as
    a knowledge-base for answering complex questions](https://doi.org/10.18653/V1/N18-1059).
    In *Proceedings of the 2018 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies, NAACL-HLT 2018, New
    Orleans, Louisiana, USA, June 1-6, 2018, Volume 1 (Long Papers)*, pages 641–651\.
    Association for Computational Linguistics.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Talmor 和 Berant（2018） Alon Talmor 和 Jonathan Berant。2018。[网络作为回答复杂问题的知识库](https://doi.org/10.18653/V1/N18-1059)。在
    *2018年北美计算语言学协会年会会议论文集：人类语言技术，NAACL-HLT 2018，路易斯安那州新奥尔良，2018年6月1-6日，第1卷（长文集）*，第641–651页。计算语言学协会。
- en: 'Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton-Ferrer, Moya Chen, Guillem
    Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia
    Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou,
    Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem
    Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana
    Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra,
    Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan
    Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen
    Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng
    Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang,
    Aurélien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023. [Llama
    2: Open foundation and fine-tuned chat models](https://doi.org/10.48550/arXiv.2307.09288).
    *CoRR*, abs/2307.09288.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Touvron 等人（2023） Hugo Touvron、Louis Martin、Kevin Stone、Peter Albert、Amjad Almahairi、Yasmine
    Babaei、Nikolay Bashlykov、Soumya Batra、Prajjwal Bhargava、Shruti Bhosale、Dan Bikel、Lukas
    Blecher、Cristian Canton-Ferrer、Moya Chen、Guillem Cucurull、David Esiobu、Jude Fernandes、Jeremy
    Fu、Wenyin Fu、Brian Fuller、Cynthia Gao、Vedanuj Goswami、Naman Goyal、Anthony Hartshorn、Saghar
    Hosseini、Rui Hou、Hakan Inan、Marcin Kardas、Viktor Kerkez、Madian Khabsa、Isabel Kloumann、Artem
    Korenev、Punit Singh Koura、Marie-Anne Lachaux、Thibaut Lavril、Jenya Lee、Diana Liskovich、Yinghai
    Lu、Yuning Mao、Xavier Martinet、Todor Mihaylov、Pushkar Mishra、Igor Molybog、Yixin
    Nie、Andrew Poulton、Jeremy Reizenstein、Rashi Rungta、Kalyan Saladi、Alan Schelten、Ruan
    Silva、Eric Michael Smith、Ranjan Subramanian、Xiaoqing Ellen Tan、Binh Tang、Ross
    Taylor、Adina Williams、Jian Xiang Kuan、Puxin Xu、Zheng Yan、Iliyan Zarov、Yuchen Zhang、Angela
    Fan、Melanie Kambadur、Sharan Narang、Aurélien Rodriguez、Robert Stojnic、Sergey Edunov
    和 Thomas Scialom。2023。[Llama 2：开放基础和微调聊天模型](https://doi.org/10.48550/arXiv.2307.09288)。*CoRR*，abs/2307.09288。
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian
    Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and Denny Zhou. 2022. [Chain-of-thought
    prompting elicits reasoning in large language models](http://papers.nips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html).
    In *NeurIPS*.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等人（2022） Jason Wei、Xuezhi Wang、Dale Schuurmans、Maarten Bosma、Brian Ichter、Fei
    Xia、Ed H. Chi、Quoc V. Le 和 Denny Zhou。2022。[链式思考提示引发大型语言模型中的推理](http://papers.nips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html)。在
    *NeurIPS*。
- en: 'Yao et al. (2022) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik Narasimhan, and Yuan Cao. 2022. [ReAct: Synergizing reasoning and acting
    in language models](https://doi.org/10.48550/arXiv.2210.03629). *CoRR*, abs/2210.03629.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao 等人（2022） Shunyu Yao、Jeffrey Zhao、Dian Yu、Nan Du、Izhak Shafran、Karthik Narasimhan
    和 Yuan Cao。2022。[ReAct：在语言模型中协同推理和行动](https://doi.org/10.48550/arXiv.2210.03629)。*CoRR*，abs/2210.03629。
- en: 'Yih et al. (2016) Wen-tau Yih, Matthew Richardson, Chris Meek, Ming-Wei Chang,
    and Jina Suh. 2016. [The value of semantic parse labeling for knowledge base question
    answering](https://doi.org/10.18653/v1/P16-2033). In *Proceedings of the 54th
    Annual Meeting of the Association for Computational Linguistics (Volume 2: Short
    Papers)*, pages 201–206, Berlin, Germany. Association for Computational Linguistics.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yih 等人（2016） Wen-tau Yih、Matthew Richardson、Chris Meek、Ming-Wei Chang 和 Jina
    Suh。2016。[语义解析标注对知识库问答的价值](https://doi.org/10.18653/v1/P16-2033)。在 *第54届计算语言学协会年会论文集（第2卷：短文集）*，第201–206页，德国柏林。计算语言学协会。
- en: 'Yu et al. (2023) Donghan Yu, Sheng Zhang, Patrick Ng, Henghui Zhu, Alexander Hanbo
    Li, Jun Wang, Yiqun Hu, William Yang Wang, Zhiguo Wang, and Bing Xiang. 2023.
    [DecAF: Joint decoding of answers and logical forms for question answering over
    knowledge bases](https://openreview.net/pdf?id=XHc5zRPxqV9). In *The Eleventh
    International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda,
    May 1-5, 2023*. OpenReview.net.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yu 等（2023）Donghan Yu、Sheng Zhang、Patrick Ng、Henghui Zhu、Alexander Hanbo Li、Jun
    Wang、Yiqun Hu、William Yang Wang、Zhiguo Wang 和 Bing Xiang。2023年。[DecAF: 对知识库问答的答案和逻辑形式的联合解码](https://openreview.net/pdf?id=XHc5zRPxqV9)。在
    *第十一届国际学习表征会议，ICLR 2023，卢旺达基加利，2023年5月1-5日*。OpenReview.net。'
- en: 'Yu et al. (2018) Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang,
    Zifan Li, James Ma, Irene Li, Qingning Yao, Shanelle Roman, Zilin Zhang, and Dragomir R.
    Radev. 2018. [Spider: A large-scale human-labeled dataset for complex and cross-domain
    semantic parsing and text-to-sql task](https://doi.org/10.18653/v1/d18-1425).
    In *Proceedings of the 2018 Conference on Empirical Methods in Natural Language
    Processing, Brussels, Belgium, October 31 - November 4, 2018*, pages 3911–3921\.
    Association for Computational Linguistics.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yu 等（2018）Tao Yu、Rui Zhang、Kai Yang、Michihiro Yasunaga、Dongxu Wang、Zifan Li、James
    Ma、Irene Li、Qingning Yao、Shanelle Roman、Zilin Zhang 和 Dragomir R. Radev。2018年。[Spider:
    一个大规模人工标注的数据集，用于复杂和跨领域的语义解析及文本到 SQL 任务](https://doi.org/10.18653/v1/d18-1425)。在
    *2018年自然语言处理经验方法会议论文集，比利时布鲁塞尔，2018年10月31日 - 11月4日*，第3911–3921页。计算语言学协会。'
- en: Zhang et al. (2018) Yuyu Zhang, Hanjun Dai, Zornitsa Kozareva, Alexander J.
    Smola, and Le Song. 2018. [Variational reasoning for question answering with knowledge
    graph](https://doi.org/10.1609/AAAI.V32I1.12057). In *Proceedings of the Thirty-Second
    AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications
    of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational
    Advances in Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February
    2-7, 2018*, pages 6069–6076\. AAAI Press.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等（2018）Yuyu Zhang、Hanjun Dai、Zornitsa Kozareva、Alexander J. Smola 和 Le
    Song。2018年。[带有知识图谱的变分推理用于问答](https://doi.org/10.1609/AAAI.V32I1.12057)。在 *第三十二届
    AAAI 人工智能会议（AAAI-18）、第30届创新应用人工智能会议（IAAI-18）以及第八届 AAAI 教育进展研讨会（EAAI-18），美国路易斯安那州新奥尔良，2018年2月2-7日*，第6069–6076页。AAAI出版社。
- en: Zheng et al. (2023) Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang,
    Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao
    Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. [Judging LLM-as-a-judge with
    MT-Bench and Chatbot Arena](http://arxiv.org/abs/2306.05685).
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng 等（2023）Lianmin Zheng、Wei-Lin Chiang、Ying Sheng、Siyuan Zhuang、Zhanghao
    Wu、Yonghao Zhuang、Zi Lin、Zhuohan Li、Dacheng Li、Eric. P Xing、Hao Zhang、Joseph E.
    Gonzalez 和 Ion Stoica。2023年。[用 MT-Bench 和 Chatbot Arena 判断 LLM 作为法官](http://arxiv.org/abs/2306.05685)。
- en: 'Zhong et al. (2017) Victor Zhong, Caiming Xiong, and Richard Socher. 2017.
    [Seq2SQL: Generating structured queries from natural language using reinforcement
    learning](http://arxiv.org/abs/1709.00103). *CoRR*, abs/1709.00103.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhong 等（2017）Victor Zhong、Caiming Xiong 和 Richard Socher。2017年。[Seq2SQL: 从自然语言生成结构化查询的强化学习](http://arxiv.org/abs/1709.00103)。*CoRR*，abs/1709.00103。'
- en: Appendices
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录
- en: 'In this supplementary material, we provide further details as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在本补充材料中，我们提供了以下进一步细节：
- en: •
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[Appendix A](#A1 "Appendix A Detailed Tool Definitions ‣ Middleware for LLMs:
    Tools Are Instrumental for Language Agents in Complex Environments"): Detailed
    Tool Definitions'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[附录 A](#A1 "附录 A 详细工具定义 ‣ LLM 的中间件：工具在复杂环境中的语言代理中至关重要")：详细工具定义'
- en: •
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[Appendix B](#A2 "Appendix B Benchmark Statistics ‣ Middleware for LLMs: Tools
    Are Instrumental for Language Agents in Complex Environments"): Benchmark Statistics'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[附录 B](#A2 "附录 B 基准统计 ‣ LLM 的中间件：工具在复杂环境中的语言代理中至关重要")：基准统计'
- en: •
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[Appendix C](#A3 "Appendix C Prompts ‣ Middleware for LLMs: Tools Are Instrumental
    for Language Agents in Complex Environments"): Prompts'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[附录 C](#A3 "附录 C 提示 ‣ LLM 的中间件：工具在复杂环境中的语言代理中至关重要")：提示'
- en: Appendix A Detailed Tool Definitions
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 详细工具定义
- en: In this section, we detail the descriptions of our customized tools for both
    environments. Specifically, we implement $12$ different tools for KBs. The tool
    selection is carefully made based on our domain knowledge of these environments.
    Note that, for databases, we direct prompt the LLM with the DB schema information
    in API docs format Rajkumar et al. ([2022](#bib.bib29)), as a result, our tools
    focus on helping the LLM better engage with the database content.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们详细描述了我们为这两种环境定制的工具。具体来说，我们为知识库实现了$12$种不同的工具。工具的选择是基于我们对这些环境的领域知识进行的精心挑选。请注意，对于数据库，我们直接通过API文档格式的DB模式信息来提示LLM（Rajkumar等，[2022](#bib.bib29)），因此，我们的工具重点在于帮助LLM更好地处理数据库内容。
- en: A.1 Databases
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 数据库
- en: 'Navigational tools for databases:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库的导航工具：
- en: 'find_columns_containing_value(value)
    This function can help to find columns that contain the given
    cell value, which can help you make better decisions in decoding the right column
    to use. Note that, the value here means cell value in the rows of the column,
    not the column name. Prerequisite: n/afind_columns_containing_value_fuzzy(value)
    Sometimes find_columns_containing_cell_value may not find a column
    with the exact matched cell value. This function can help to find columns that
    potentially contain the target cell value with fuzzy matching. Note that, the
    value here means cell value in the rows of the column, not the column name. Prerequisite:
    n/aget_distinct_values(table,
    column) Returns the distinct values
    in the given column. This may mainly help you make better decisions in decoding
    the right value to use. Prerequisite: n/ais_value_in_column(table, column, value)
    Returns whether the given value is in the given column. You can
    use this function to better detect the right column to use. Prerequisite: n/aget_date_format(table, column)
    Returns an example item of the given Date column. This may help
    you to better understand the date format in the column. Prerequisite: n/asearch_by_SQL(query)
    Executing a SQL query to search the table. Prerequisite: n/a'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: find_columns_containing_value(value)
    此函数可以帮助查找包含给定单元格值的列，这可以帮助你做出更好的决策，以确定正确的列。请注意，这里的值是指列中行的单元格值，而不是列名。前提条件：无find_columns_containing_value_fuzzy(value)
    有时`find_columns_containing_cell_value`可能无法找到精确匹配的单元格值。这一函数可以帮助找到可能包含目标单元格值的列，通过模糊匹配来实现。请注意，这里的值是指列中行的单元格值，而不是列名。前提条件：无get_distinct_values(table,
    column) 返回给定列中的唯一值。这主要有助于你做出更好的决策，以确定使用的正确值。前提条件：无is_value_in_column(table, column,
    value) 返回给定值是否在给定列中。你可以使用此函数更好地检测使用的正确列。前提条件：无get_date_format(table, column)
    返回给定日期列的示例项目。这有助于你更好地理解列中的日期格式。前提条件：无from(from_statement)
    This function specifies the FROM clause, e.g., from("FROM table1")
    or from("FROM table1 JOIN table2 ON table1.id = table2.id") Prerequisite: n/awhere(where_statement)
    This function specifies the WHERE clause, e.g., where("WHERE table1.id
    = 1"). Prerequisite: fromselect(select_statement) This function
    specifies the SELECT clause, e.g., select("SELECT table1.id"). Prerequisite: from,
    wheregroup_by(group_by_statement)
    This function specifies the GROUP BY clause, e.g., group_by("GROUP
    BY table1.id"). Prerequisite: from, where, selecthaving(having_statement)
    This function specifies the HAVING clause, e.g., having("HAVING
    table1.id = 1"). Prerequisite: from, where, select, group_byorder_by(order_by_statement)
    This function specifies an additional constraint like ordering.
    For example, order_by("ORDER BY table1.id DESC LIMIT 3"). Prerequisite: from,
    where, select'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: A.2 Knowledge Bases
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 知识库
- en: 'Navigational tools for KBs:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 知识库的导航工具：
- en: 'get_relations(variable)
    -> list of relations A variable can be either an
    entity or a set of entities (i.e., the result of a previous query). This function
    helps to navigate all relations in the KB connected to the variable, so you can
    decide which relation is the most useful to find the answer to the question. A
    simple use case can be ‘get_relations(Barack Obama)’, which finds all relations/edges
    starting from the entity Barack Obama. The argument of get_relations should always
    be an entity or a variable (e.g., #0) and not anything else. Prerequisite: n/aget_neighbors(v, r) -> variable
    Given a variable, this function returns all entities connected
    to the variable via the given relation. Note that, get_neighbors() can only be
    used after get_relations() is used to find a set of viable relations. A simple
    use case can be ‘get_neighbors(Barack Obama, people.person.profession)’, which
    returns the profession of Obama in Freebase. Prerequisite: get_relationsget_attributes(v) -> list of
    attributes This function helps to find
    all numerical attributes of the variable. Please only use it if the question seeks
    for a superlative accumulation (i.e., argmax or argmin). Prerequisite: get_neighbors'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: 'Functional tools for KBs:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 知识库的功能工具：
- en: 'argmax(v,
    a) -> variable Given a variable, this function
    returns the entity with the maximum value of the given attribute. It can only
    be used after get_attributes() is used to find a set of viable attributes. A simple
    use case can be ‘argmax(variable, age)’, which returns the oldest entity belonging
    to the variable. Prerequisite: get_attributesargmin(v, a) -> variable
    Given a variable, this function returns the entity with the minimum
    value of the given attribute. It can only be used after get_attributes() is used
    to find a set of viable attributes. A simple use case can be ‘argmin(variable,
    age)’, which returns the youngest entity belonging to the variable. Prerequisite:
    get_attributesintersection(v1,
    v2) -> variable Given two variables, this function
    returns the intersection of the two variables. The two variables must be of the
    same type. Prerequisite: get_neighborscount(v) -> int Given a
    variable, this function returns the number of entities belonging to the variable.
    Prerequisite: get_neighbors'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: argmax(v,
    a) -> variable 给定一个变量，该函数返回具有指定属性最大值的实体。它只能在使用
    get_attributes() 找到一组可行属性之后使用。一个简单的用例是‘argmax(variable, age)’，它返回属于该变量的最年长实体。先决条件：get_attributesargmin(v, a) -> variable
    给定一个变量，该函数返回具有指定属性最小值的实体。它只能在使用 get_attributes() 找到一组可行属性之后使用。一个简单的用例是‘argmin(variable,
    age)’，它返回属于该变量的最年轻实体。先决条件：get_attributesintersection(v1, v2) -> variable 给定两个变量，该函数返回两个变量的交集。这两个变量必须是相同类型的。先决条件：get_neighborscount(v) -> int
    给定一个变量，该函数返回属于该变量的实体数量。先决条件：get_neighbors
- en: Appendix B Benchmark Statistics
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录B 基准统计
- en: '| Dataset | # Table/DB | # Row/DB | % Require Cont. |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | # 表/数据库 | # 行/数据库 | % 需要连续 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| WikiSQL Zhong et al. ([2017](#bib.bib47)) | $1$ |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| WikiSQL Zhong 等人（[2017](#bib.bib47)） | $1$ |'
- en: '| Spider Yu et al. ([2018](#bib.bib44)) | $5.1$ |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| Spider Yu 等人（[2018](#bib.bib44)） | $5.1$ |'
- en: '| Bird Li et al. ([2023a](#bib.bib18)) | $7.3$ |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| Bird Li 等人（[2023a](#bib.bib18)） | $7.3$ |'
- en: (a) Databases
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 数据库
- en: '| Dataset | # Relations/KB | # Triples/KB | # Hops | % Have Aggr. |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | # 关系/知识库 | # 三元组/知识库 | # 跳数 | % 有聚合 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| MetaQA Zhang et al. ([2018](#bib.bib45)) | $9$ |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| MetaQA Zhang 等人（[2018](#bib.bib45)） | $9$ |'
- en: '| WebQSP Yih et al. ([2016](#bib.bib42)) | $19$ |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| WebQSP Yih 等人（[2016](#bib.bib42)） | $19$ |'
- en: '| GrailQA Gu et al. ([2021](#bib.bib9)) | $19$ |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| GrailQA Gu 等人（[2021](#bib.bib9)） | $19$ |'
- en: '| KBQA-Agent (Ours) | $19$ |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| KBQA-Agent（我们的方法） | $19$ |'
- en: (b) Knowledge Bases
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 知识库
- en: 'Table B.1: Our curated benchmarks more accurately mirror real-world complexity,
    offering a more effective assessment of language agents. Aggr. denotes aggregation
    functions.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 表B.1：我们精心挑选的基准更准确地反映了现实世界的复杂性，提供了对语言代理的更有效评估。Aggr. 表示聚合函数。
- en: 'In Table [B.1](#A2.T1 "Table B.1 ‣ Appendix B Benchmark Statistics ‣ Middleware
    for LLMs: Tools Are Instrumental for Language Agents in Complex Environments"),
    we present the statistics of Bird and KBQA-Agent, which we have chosen for our
    evaluation. Relative to established benchmarks in text-to-SQL parsing and KBQA,
    Bird and KBQA-Agent exhibit significantly greater complexity, making them more
    suitable for assessing the capabilities of language agents.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '在表[B.1](#A2.T1 "Table B.1 ‣ Appendix B Benchmark Statistics ‣ Middleware for
    LLMs: Tools Are Instrumental for Language Agents in Complex Environments")中，我们展示了Bird和KBQA-Agent的统计数据，这是我们为评估选择的。与文本到SQL解析和KBQA中的既定基准相比，Bird和KBQA-Agent显示出显著更大的复杂性，使它们更适合评估语言代理的能力。'
- en: Appendix C Prompts
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录C 提示
- en: '![Refer to caption](img/ceb471cccc9187a46d022210653e0e76.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/ceb471cccc9187a46d022210653e0e76.png)'
- en: 'Figure C.1: Instructions for using database tools. Descriptions of tools are
    omitted.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图C.1：使用数据库工具的说明。工具的描述被省略。
- en: 'Instructions and demonstrations for using database tools are shown in Figure
    [C.1](#A3.F1 "Figure C.1 ‣ Appendix C Prompts ‣ Middleware for LLMs: Tools Are
    Instrumental for Language Agents in Complex Environments"). Note that, we also
    include the schema information of the database in API Docs in our prompt, which
    is not shown here. This design choice has been a common practice for text-to-SQL
    parsing with LLMs Tai et al. ([2023](#bib.bib37)); Sun et al. ([2023](#bib.bib36)).
    Instructions and demonstrations for using KB tools are shown in Figure [C.2](#A3.F2
    "Figure C.2 ‣ Appendix C Prompts ‣ Middleware for LLMs: Tools Are Instrumental
    for Language Agents in Complex Environments"). The instruction and demonstration
    for candidate selection in decoupled generation for KB is shown in Figure [C.3](#A3.F3
    "Figure C.3 ‣ Appendix C Prompts ‣ Middleware for LLMs: Tools Are Instrumental
    for Language Agents in Complex Environments"). Additionally, we also show an example
    of input we use for our KB experiments in Section [5.4](#S5.SS4 "5.4 Tools as
    A Middleware Layer ‣ 5 Experiments ‣ Middleware for LLMs: Tools Are Instrumental
    for Language Agents in Complex Environments"). For the input used for databases
    in Section [5.4](#S5.SS4 "5.4 Tools as A Middleware Layer ‣ 5 Experiments ‣ Middleware
    for LLMs: Tools Are Instrumental for Language Agents in Complex Environments"),
    we strictly follow the standard way of prompting with API docs plus exemplar rows Li
    et al. ([2023a](#bib.bib18)); Rajkumar et al. ([2022](#bib.bib29)).'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '使用数据库工具的说明和演示见图[ C.1](#A3.F1 "Figure C.1 ‣ Appendix C Prompts ‣ Middleware
    for LLMs: Tools Are Instrumental for Language Agents in Complex Environments")。请注意，我们在提示中还包含了数据库的模式信息，这在此未显示。这种设计选择已成为使用LLMs进行文本到SQL解析的常见做法，Tai
    等人（[2023](#bib.bib37)）；Sun 等人（[2023](#bib.bib36)）。使用KB工具的说明和演示见图[C.2](#A3.F2 "Figure
    C.2 ‣ Appendix C Prompts ‣ Middleware for LLMs: Tools Are Instrumental for Language
    Agents in Complex Environments")。KB的候选选择解耦生成的说明和演示见图[C.3](#A3.F3 "Figure C.3 ‣
    Appendix C Prompts ‣ Middleware for LLMs: Tools Are Instrumental for Language
    Agents in Complex Environments")。此外，我们还在第[5.4](#S5.SS4 "5.4 Tools as A Middleware
    Layer ‣ 5 Experiments ‣ Middleware for LLMs: Tools Are Instrumental for Language
    Agents in Complex Environments")节中展示了我们用于KB实验的输入示例。对于第[5.4](#S5.SS4 "5.4 Tools
    as A Middleware Layer ‣ 5 Experiments ‣ Middleware for LLMs: Tools Are Instrumental
    for Language Agents in Complex Environments")节中使用的数据库输入，我们严格遵循API文档加示例行的标准提示方法，Li
    等人（[2023a](#bib.bib18)）；Rajkumar 等人（[2022](#bib.bib29)）。'
- en: '![Refer to caption](img/74b8115b1966a24947462fe41cb642db.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/74b8115b1966a24947462fe41cb642db.png)'
- en: 'Figure C.2: Instructions and a one-shot demonstration for using KB tools. Descriptions
    of tools are omitted.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '图 C.2: 使用知识库工具的指令和一次性演示。工具的描述被省略。'
- en: '![Refer to caption](img/3d89150fed004aea751ca9621bc136e1.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/3d89150fed004aea751ca9621bc136e1.png)'
- en: 'Figure C.3: Prompt for candidate action selection in decoupled generation for
    KB.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '图 C.3: 用于知识库的解耦生成中的候选动作选择的提示。'
- en: '![Refer to caption](img/5a0a1fa716f9e95f707c44eb0ab9135e.png)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/5a0a1fa716f9e95f707c44eb0ab9135e.png)'
- en: 'Figure C.4: Input for question “which song is the longest song of handel: messiah
    (dublin version, 1742)?" with $10$ triples sampled from the KB, which is used
    in Section [5.4](#S5.SS4 "5.4 Tools as A Middleware Layer ‣ 5 Experiments ‣ Middleware
    for LLMs: Tools Are Instrumental for Language Agents in Complex Environments").'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '图 C.4: 问题“哪一首是亨德尔的最长歌曲：弥赛亚（都柏林版，1742）？”的输入，包含从知识库中抽取的 $10$ 个三元组，使用于第[5.4](#S5.SS4
    "5.4 Tools as A Middleware Layer ‣ 5 Experiments ‣ Middleware for LLMs: Tools
    Are Instrumental for Language Agents in Complex Environments")节。'
