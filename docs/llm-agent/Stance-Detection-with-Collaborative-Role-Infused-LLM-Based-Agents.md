<!--yml

类别：未分类

日期：2025-01-11 13:03:04

-->

# 立场检测与协作性角色注入型LLM代理

> 来源：[https://arxiv.org/html/2310.10467/](https://arxiv.org/html/2310.10467/)

Xiaochong Lan, Chen Gao^∗, Depeng Jin, Yong Li^∗

###### 摘要

^†^†脚注：*通讯作者

立场检测是自动识别作者在文本中对某一特定话题的立场，对于网页和社交媒体研究中的内容分析至关重要。随着大型语言模型（LLMs）的发展，研究人员开始探索它们在立场检测中的潜力。尽管LLMs展现了良好的能力，但在直接应用于立场检测时仍面临挑战。首先，立场检测需要多方面的知识才能全面理解文本中的元素。其次，立场检测需要高级推理能力来推断观点，因为立场往往是隐性嵌入的，而不是明确陈述的。为了应对这些挑战，我们设计了一个三阶段框架COLA（即协作性角色注入型LLM代理），在该框架中，LLMs被赋予不同的角色，形成一个协作系统。该框架包括三个阶段。首先，在多维文本分析阶段，我们将LLMs配置为语言学专家、领域专家和社交媒体资深人士，从多个角度分析文本，从而克服第一个挑战。接着，在增强推理的辩论阶段，对于每个潜在的立场，我们指定一个特定的LLM代理来为其辩护，引导LLM检测文本特征与立场之间的逻辑联系，解决第二个挑战。最后，在立场结论阶段，一个最终决策代理整合之前的洞见来确定立场。COLA避免了额外注释数据和模型训练的需求，使其高度用户友好。而且，COLA在多个广泛使用的数据集上实现了最先进的表现。消融研究验证了我们方法中每个模块的有效性。进一步的实验展示了我们方法的可解释性和多功能性。总之，我们的方法在可用性、准确性、有效性、可解释性和多功能性方面表现出色，展示了其重要价值。

## 引言

立场检测通常被定义为自动检测作者对目标的立场（支持、反对或中立）（Mohammad等人，[2016](https://arxiv.org/html/2310.10467v2#bib.bib32)）。多年来，已提出了许多立场检测方法（Küçük和Can，[2020](https://arxiv.org/html/2310.10467v2#bib.bib22); AlDayel和Magdy，[2021](https://arxiv.org/html/2310.10467v2#bib.bib1)）。然而，一个持久的挑战在于需要专门针对感兴趣的目标训练模型。即使在跨目标立场检测（Liang等人，[2021](https://arxiv.org/html/2310.10467v2#bib.bib27)）和零-shot立场检测（Allaway和McKeown，[2020](https://arxiv.org/html/2310.10467v2#bib.bib2); Liang等人，[2022a](https://arxiv.org/html/2310.10467v2#bib.bib26)）取得进展，仍然需要在标注的语料库上训练。然而，获取大规模标记数据集并非易事，这限制了模型的可用性。

近年来，大型语言模型（LLMs）在各种应用中展示了显著的能力（Brown等人，[2020](https://arxiv.org/html/2310.10467v2#bib.bib7); Park等人，[2023](https://arxiv.org/html/2310.10467v2#bib.bib35)）。这些大模型固有的语义理解能力为立场检测提供了令人兴奋的机会。大多数LLMs可以通过零-shot提示与用户轻松交互，显著增强了它们的可用性。因此，凭借它们的力量和可用性，大型语言模型为立场检测提供了新的可能性。

研究人员已经洞察到LLMs为立场检测带来的变革潜力。一些作品提出了使用LLMs进行立场检测的简单方法（Zhang, Ding和Jing，[2022](https://arxiv.org/html/2310.10467v2#bib.bib51); Zhang等人，[2023](https://arxiv.org/html/2310.10467v2#bib.bib52)）。然而，虽然这些作品在特定数据集的特定子集上报告了令人满意的结果，我们的严格复制研究表明，这些方法往往无法与最先进的非LLM基线性能匹配。这可以归因于立场检测的两个固有挑战，列举如下。

+   •

    首先，立场检测需要多方面的知识。如图 [1](https://arxiv.org/html/2310.10467v2#Sx1.F1 "Figure 1 ‣ Introduction ‣ Stance Detection with Collaborative Role-Infused LLM-Based Agents") 所示，句子可能包含领域特定术语、文化引用、社交媒体语言风格等元素。这些对于大型语言模型并非立即可理解，需要专门的解析才能真正理解。

+   •

    第二，立场检测需要高级推理。通常，作者不会直接表明他们的立场，而是通过他们对相关话题或事件的态度等方式无意中透露，如图[1](https://arxiv.org/html/2310.10467v2#Sx1.F1 "图1 ‣ 引言 ‣ 基于协作角色注入LLM驱动代理的立场检测")所示。立场检测需要从多种文本特征中进行推理，以得出正确的立场。

图1：立场检测挑战的示意图。

为了应对这些挑战，我们提出了名为COLA（三阶段协作角色注入LLM驱动代理框架）的方法。具体而言，我们设计了一个立场检测系统，系统由角色注入的LLM驱动代理组成，每个角色承担不同的职责和意义。为应对第一个挑战，我们设计了一个多维文本分析阶段。在这个阶段，LLM被分配为三个角色，分别是语言专家、领域专家和社交媒体老兵，来从不同角度分析文本，涵盖语法、文本元素和平台特定表达，最终揭示立场指示器。针对第二个挑战，我们提出了一个增强推理的辩论阶段。在这一阶段，代表每个立场类别的支持者从先前的分析中提取证据，提出论点，迫使LLM揭示文本特征与立场之间的潜在逻辑联系。最后，立场结论阶段根据原始文本和辩论得出文本的立场。

我们的方法不需要注释数据或额外的模型训练，因此确保了高可用性。大量实验验证了我们方法在现有基准上的优越性能，确认了其准确性¹¹1在本研究中，除非特别声明，否则我们使用准确性来表示模型在分类任务中的整体强大表现，而不仅仅指代准确性指标。。消融研究展示了每个模块的有效性。案例研究和定量实验表明，我们的方法能够为其输出生成合理的解释，展示了我们方法的可解释性。我们提出的框架在一系列文本分类任务中的强大表现凸显了其多样性。我们的方法因其可用性、准确性、有效性、可解释性和多样性而脱颖而出，所有这些都突显了其价值。

我们的主要贡献总结如下：

+   •

    据我们所知，我们是首个使用多个LLM代理进行立场检测的研究。

+   •

    我们提出了一种基于协作角色注入的LLM驱动代理的方法，在SEM16数据集上相对于最佳非LLM零-shot立场检测基准取得了显著的19.2%绝对提升。此外，该方法还具有高可用性和可解释性。

+   •

    我们提出的三阶段框架——分析师、辩论者和总结者——为多种文本分类任务提供了重要潜力，成为网络和社交媒体文本分析的强大工具。

后续章节的安排如下：在[相关工作](https://arxiv.org/html/2310.10467v2#Sx2 "Related Work ‣ Stance Detection with Collaborative Role-Infused LLM-Based Agents")一节，我们回顾相关工作。在[方法](https://arxiv.org/html/2310.10467v2#Sx3 "Methods ‣ Stance Detection with Collaborative Role-Infused LLM-Based Agents")一节，我们详细描述了我们的三阶段框架。然后，在[实验](https://arxiv.org/html/2310.10467v2#Sx4 "Experiments ‣ Stance Detection with Collaborative Role-Infused LLM-Based Agents")和[结果与讨论](https://arxiv.org/html/2310.10467v2#Sx5 "Results and Discussions ‣ Stance Detection with Collaborative Role-Infused LLM-Based Agents")一节，我们展示了我们的实验，提供了充分的实证证据，证明了我们的方法在多个角度上的优越性。最后，在[结论与未来工作](https://arxiv.org/html/2310.10467v2#Sx6 "Conclusion and Future Work ‣ Stance Detection with Collaborative Role-Infused LLM-Based Agents")一节，我们总结了我们的工作，并指出了未来改进的潜在方向。

## 相关工作

本节的结构如下：首先，我们提供关于立场检测的进展的详细概述。接下来，我们介绍大规模语言模型的最新进展。最后，我们重点回顾与我们工作密切相关的一些研究，特别是基于多重 LLM 的代理系统。

立场检测。立场检测旨在从文本内容中辨别作者对特定目标的立场。通常，立场分为支持、反对、中立。研究人员提出了大量的立场检测算法，包括基于特征的方法（Bar-Haim 等人 [2017](https://arxiv.org/html/2310.10467v2#bib.bib6)；Lozhnikov、Derczynski 和 Mazzara [2020](https://arxiv.org/html/2310.10467v2#bib.bib31)）和深度学习技术（Wei、Mao 和 Zeng [2018](https://arxiv.org/html/2310.10467v2#bib.bib47)；Liu 等人 [2021](https://arxiv.org/html/2310.10467v2#bib.bib30)）。这些方法使得对互联网和社交媒体平台内容的深入分析成为可能。例如，Jang 等人（[2018](https://arxiv.org/html/2310.10467v2#bib.bib20)）开发了一种通过生成关注立场的推文摘要来发现社交媒体上的争议的方法。Grcar 等人（[2017](https://arxiv.org/html/2310.10467v2#bib.bib17)）考察了英国脱欧公投前的 Twitter 立场，揭示了支持脱欧阵营更高的影响力。

传统上，立场检测需要在特定目标的标注数据集上进行训练。这类数据集并非易得，因此限制了许多方法的可用性。鉴于这一限制，研究人员开始探索跨目标立场检测，旨在训练能够在已知目标上训练后，适应陌生但相关目标的分类器（Xu等人 [2018](https://arxiv.org/html/2310.10467v2#bib.bib49）；Wei和Mao [2019](https://arxiv.org/html/2310.10467v2#bib.bib46)；Liang等人 [2021](https://arxiv.org/html/2310.10467v2#bib.bib27)）。最近，出现了一些零-shot立场检测方法，可以自动检测未见过的任务的立场（Allaway和McKeown [2020](https://arxiv.org/html/2310.10467v2#bib.bib2)；Liang等人 [2022a](https://arxiv.org/html/2310.10467v2#bib.bib26)）。然而，所有这些方法都需要在标注数据集上进行训练。与这些方法不同，我们的方法使用预训练的LLM，消除了对额外标注数据的需求。通过提示工程，我们在无需额外训练的情况下精细化这些模型，提供了一种高可用性的解决方案。

大型语言模型。大型语言模型（LLMs）代表了近年来人工智能领域最重要的进展之一。自2022年底发布ChatGPT²²2chat.openai.com以来，LLMs受到了空前关注，主要由于其出色的表现。像GPT-4（OpenAI [2023](https://arxiv.org/html/2310.10467v2#bib.bib34)）、Llama 2（Touvron等人 [2023](https://arxiv.org/html/2310.10467v2#bib.bib42)）、ChatGLM（Zeng等人 [2022](https://arxiv.org/html/2310.10467v2#bib.bib50)）等LLM的推出速度非常快。在传统的自然语言处理任务中，这些LLMs的零-shot能力通常与精心制作的、特定领域的模型相媲美，甚至超越它们（Wei等人 [2021](https://arxiv.org/html/2310.10467v2#bib.bib45)）。LLMs中出现的强大能力，如规划和推理，进一步推动了它们在各种应用中的广泛采用。一些研究结合了现有工具与LLMs（Qin等人 [2023](https://arxiv.org/html/2310.10467v2#bib.bib38）；Schick等人 [2023](https://arxiv.org/html/2310.10467v2#bib.bib39)），另一些则探索了LLMs创造新工具的潜力（Cai等人 [2023](https://arxiv.org/html/2310.10467v2#bib.bib8)），还有越来越多的趋势将LLMs应用于动态决策、规划和体现智能（Shinn等人 [2023](https://arxiv.org/html/2310.10467v2#bib.bib40)；Xiang等人 [2023](https://arxiv.org/html/2310.10467v2#bib.bib48)）。

本质上，LLMs（大语言模型）所具备的庞大知识量和强大的语义理解能力在处理立场检测任务中提供了巨大的潜力。确实，有多个研究项目探索了LLMs在立场检测中的应用（Zhang, Ding, 和 Jing [2022](https://arxiv.org/html/2310.10467v2#bib.bib51); Ziems 等 [2023](https://arxiv.org/html/2310.10467v2#bib.bib54); Zhang 等 [2023](https://arxiv.org/html/2310.10467v2#bib.bib52)）。然而，这些现有的方法通常采用相对简单的方式，忽略了立场检测特有的内在挑战。因此，我们在严格复现的过程中，常常发现其性能相较于依赖标注数据的基准方法显得不尽如人意。相比之下，我们的方法专门针对立场检测所需的专家知识和复杂推理进行量身定制，从而取得了令人称赞的成果。

多LLM基础代理系统。由多个LLM基础代理组成的系统展示了单一LLM所不具备的复杂和强大能力。利用LLM类人化的能力，多个LLM基础代理组成的系统已被应用于线上和线下的社会模拟，展示了个体层面的可信度以及涌现的社会行为（Li 等 [2023b](https://arxiv.org/html/2310.10467v2#bib.bib24); Gao 等 [2023a](https://arxiv.org/html/2310.10467v2#bib.bib15)）。例如，Part 等人 ([2023](https://arxiv.org/html/2310.10467v2#bib.bib35)) 构建了一个由25个代理组成的AI小镇，见证了市长选举和党派组织等现象。Gao 等人 ([2023b](https://arxiv.org/html/2310.10467v2#bib.bib16)) 进行了成千上万的LLM基础代理的在线社交网络模拟，观察到群体情感反应和观点变化，这些现象与现实世界的趋势相吻合。此外，一些研究采用了不同角色的LLM之间的协作来完成任务。在METAGPT（Hong 等 [2023](https://arxiv.org/html/2310.10467v2#bib.bib18)）中，具有不同角色的LLM基础代理协同开发计算机软件，而DERA（Nair 等 [2023](https://arxiv.org/html/2310.10467v2#bib.bib33)）则通过多个代理之间的讨论来优化医疗总结对话和护理计划生成。此外，还有一些研究通过大语言模型代理之间的辩论来提升模型性能。例如，ChatEval（Chan 等 [2023](https://arxiv.org/html/2310.10467v2#bib.bib9)）通过多代理辩论提升文本评估能力。Du 等人 ([2023](https://arxiv.org/html/2310.10467v2#bib.bib14)) 通过促进大语言模型之间的辩论，增强了模型的事实性和推理能力。

据我们所知，我们的工作是首个采用多LLM基础的代理系统进行立场检测任务的尝试。

图2：我们提出的COLA架构。

## 方法

### 任务描述与模型概述

在立场检测中，目标是决定给定的有立场的文档相对于指定目标的立场。我们定义一个数据集 $D=\{(x_{i}=(d_{i},t_{i}),y_{i})\}^{n}_{i=1}$，其中包含 $n$ 个实例。对于每个实例，$x_{i}$ 表示一个元组，其中包含文档 $d_{i}$ 和相应的目标 $t_{i}$。任务是检测立场 $y_{i}$，它可以是以下三种类别之一：支持、反对或中立。

如图[2](https://arxiv.org/html/2310.10467v2#Sx2.F2 "图2 ‣ 相关工作 ‣ 基于协作角色注入LLM的立场检测")所示，我们的方法包括三个阶段：多维文本分析阶段、增强推理辩论阶段和立场结论阶段。在多维文本分析阶段，语言专家、领域专家和社交媒体资深人士从不同角度分析网络或社交媒体中的文本，提供全面的理解。在增强推理辩论阶段，对于每种可能的立场，一位辩手会为其辩护，寻求文本特征与立场之间可能的逻辑链条。最后，在立场结论阶段，最终裁判根据所有辩手的陈述确定立场。接下来，我们将详细介绍我们方法的各个组成部分。

### 多维文本分析阶段

#### 挑战：

立场检测需要深入掌握多方面的知识。社交媒体上的句子可能受到各种语言现象的影响，例如语法结构、时态和语气，从而传达作者的立场。此外，句子中往往包含大量领域特定的术语，包括人物、政党和事件的引用及其与目标的关系。同时，社交媒体的独特语言特征，如标签（hashtags），也起到了作用。尽管大规模语言模型已经吸收了来自其训练数据的丰富知识，但它们在立场检测中的直接应用往往未能充分利用这些知识，导致效果不尽如人意，这一点在我们的后续实验中得到了验证。

#### 方法：

为了应对这一挑战并利用大规模语言模型中编码的丰富知识，我们设计了一个多维文本分析阶段。在此阶段，我们引入了三个基于LLM的不同代理，从不同的角度解析文本，确保全面理解可能影响作者立场的要素。这些代理分别是语言专家、领域专家和社交媒体资深人士。我们通过提示要求LLM扮演其指定角色。具体来说，角色注入代理在此阶段的输入和输出如下所示。

输入：带有立场的文本。

输出：语言专家、领域专家和社交媒体资深人士对文本的个别分析。

代理人的详细配置如下。

语言学专家。该角色负责从语言学角度剖析文本，探讨的因素包括但不限于：

+   •

    语法结构。句子中单词的排列和关系，决定了不同元素如何结合以产生特定的含义。

+   •

    时态和词形变化。时态表明动作发生的时间，影响语气的紧迫性或距离感。词形变化调整单词形式，提供关于句子语法和关系背景的线索。

+   •

    修辞手法。这些是用于增强语言表现力的技巧。通过强调、对比或唤起情感，它们塑造了陈述的语气和态度。

+   •

    词汇选择。写作中选择特定单词或短语，这可以揭示关于某个话题的更深层次含义、偏见或观点。

具体的提示如下，

> 你是一个语言学家。准确简洁地解释句子中的语言学元素，以及这些元素如何影响含义，包括语法结构、时态和词形变化、虚拟语气、修辞手法、词汇选择等。什么都不做。{tweet}

领域专家。该角色专注于与领域相关的知识，探索诸如以下方面：

+   •

    角色。文本中的关键个体或实体。

+   •

    事件。文本中的重要事件。它们的描写可能暗示作者对某些问题或话题的立场。

+   •

    组织。提到的已建立团体。它们的描绘可以展示作者对某些社会结构或机构的情感。

+   •

    当事人。具有不同意识形态的政治团体。文本对这些团体的处理可以为我们提供作者政治倾向或批评的线索。

+   •

    宗教。特定的信仰或精神信仰。它们的提及可能揭示作者的个人信仰或社会观察。

具体的提示如下，

> 你是一个{角色}。准确简洁地解释引用中的关键元素，例如角色、事件、当事人、宗教等。还需解释它们与{目标}的关系（如果有的话）。什么都不做。{tweet}

社交媒体老手。该角色深入探讨社交媒体表达的细微差别，关注以下方面：

+   •

    标签。社交媒体平台上使用的特定标签，有助于对帖子进行分类或强调特定主题，使内容容易被发现。

+   •

    网络俚语和俗语。这些指的是在在线社区中常用的非正式术语和表达方式。它们的使用可以引入细微差别、文化背景或特定态度，是揭示陈述背后立场的重要指示器。

+   •

    情感语气。它捕捉了写作中固有的情感，揭示了作者对某一特定主题的感受，无论是积极的、消极的，还是中立的。

具体的提示如下，

> 你是一个重度社交媒体用户，非常熟悉互联网上的表达方式。分析以下句子，重点关注内容、情感语调、暗示意义等。不要做其他事情。{tweet}

### 增强推理的辩论阶段

#### 挑战：

立场检测任务需要复杂的推理。作者通常不会在文本中明确表述他们的立场。相反，他们的立场可能通过对某些实体的情感态度，或通过比较与对比等机制间接表达。识别这些隐含的立场需要详细的推理。尽管大规模语言模型具备一定的推理能力，但在没有适当引导的情况下，它们在复杂推理任务中的表现可能不尽如人意，这会影响立场检测结果的质量。

#### 方法：

从近期利用大型模型之间的讨论或辩论来增强其表现的研究中汲取灵感（Du 等人 [2023](https://arxiv.org/html/2310.10467v2#bib.bib14); Chan 等人 [2023](https://arxiv.org/html/2310.10467v2#bib.bib9); Liang 等人 [2023](https://arxiv.org/html/2310.10467v2#bib.bib29)），特别是在推理任务中，我们引入了增强推理的辩论阶段。在这个阶段，对于每个潜在立场，都指定一个代理。该代理从专家对文本的分析中寻找证据，并为其指定的立场辩护。具体来说，该阶段中代理的输入和输出如下。

输入：带有立场的文本。语言学专家、领域专家和社交媒体资深用户对文本的分析。

输出：每个代理支持其立场的辩论，包括它选择的证据和其逻辑链。

具体的提示如下：

> 推文：{tweet}。语言学分析：{LingResponse}。{role}的分析：{ExpertResponse}。重度社交媒体用户的分析：{UserResponse}。你认为这条推文背后的态度是{stance}的{target}。从分析中识别出最能支持你观点的三条证据，并为你的观点辩护。

在我们的框架中，我们只进行单轮辩论，保留多轮辩论供未来探索。指引代理搜索证据并为其对立立场辩护，迫使大规模语言模型在发现的文本特征（及其多重解释）与文本实际的潜在立场之间建立逻辑联系。通过让多个代理支持不同立场辩论，系统鼓励大模型的发散思维。这些输出随后将输入到立场结论阶段，做出最终的、审慎的判断。

### 立场结论阶段

为了从不同的代理辩论中推断出一个结论性的立场，我们引入了立场结论阶段。在这个阶段，判断代理根据文本本身以及辩论代理提出的论点，确定文本的最终立场。这个过程被描述如下：

输入：带有嵌入立场的文本。来自每个代理的论点，包括证据和逻辑推理。

输出：文本的已识别立场。

具体的提示可以如下所示，

> 判断句子是支持还是反对{target}，或者是中立的。句子：{tweet}。根据以下论点进行判断：支持的论点：{FavorResponse}。反对的论点：{AgainstResponse}。中立的论点：{NeutralResponse}。选择以下选项之一：A：反对 B：支持 C：中立
> 
> 限制条件：仅回答最准确的选项，不要添加其他内容。

判断代理评估文本的内在特性、辩论者提供的证据以及他们的逻辑框架，以做出有根据的决策。

经过上述三个阶段后，我们已经有效地从文本中提取出了针对给定目标的潜在立场。

| 数据集 | 目标 | 支持 | 反对 | 中立 |
| --- | --- | --- | --- | --- |
| SEM16 | DT | 148 (20.9%) | 299 (42.3%) | 260 (36.8%) |
| HC | 163 (16.6%) | 565 (57.4%) | 256 (26.0%) |
| FM | 268 (28.2%) | 511 (53.8%) | 170 (17.9%) |
| LA | 167 (17.9%) | 544 (58.3%) | 222 (23.8%) |
| A | 124 (16.9%) | 464 (63.3%) | 145 (19.8%) |
| CC | 335 (59.4%) | 26 (4.6%) | 203 (36.0%) |
| P-Stance | Biden | 3217 (44.1%) | 4079 (55.9%) | - |
| Sanders | 3551 (56.1%) | 2774 (43.9%) | - |
| Trump | 3663 (46.1%) | 4290 (53.9%) | - |
| VAST | - | 6952 (37.5%) | 7297 (39.3%) | 4296 (23.2%) |

表 1：我们使用的数据集统计信息。

## 实验

在这一部分，我们描述了实验的具体设置。

### 数据集

根据许多现有的研究工作（Liang 等人 [2022a](https://arxiv.org/html/2310.10467v2#bib.bib26); Augenstein 等人 [2016](https://arxiv.org/html/2310.10467v2#bib.bib5); Li 等人 [2023a](https://arxiv.org/html/2310.10467v2#bib.bib23)），我们在三个广泛使用的数据集上进行了实验：

SEM16 （Mohammad 等人 [2016](https://arxiv.org/html/2310.10467v2#bib.bib32)）。该数据集包含来自不同领域的六个特定目标，分别是唐纳德·特朗普（DT）、希拉里·克林顿（HC）、女权运动（FM）、堕胎合法化（LA）、无神论（A）和气候变化是现实问题（CC）。每个实例被分类为三个立场类别之一：支持、反对或无立场。

P-Stance （Li 等人 [2021](https://arxiv.org/html/2310.10467v2#bib.bib25)）。该数据集聚焦于政治领域，包括三个目标：唐纳德·特朗普（Trump）、乔·拜登（Biden）、伯尼·桑德斯（Sanders）。立场标签包括支持和反对。

VAST（Allaway 和 McKeown [2020](https://arxiv.org/html/2310.10467v2#bib.bib2)）。该数据集的特点是具有大量变化的目标。VAST 中的一个实例包括一句话、一个目标和一个立场，立场可以是支持、反对或中立。

我们使用的数据集的统计数据如表格[1](https://arxiv.org/html/2310.10467v2#Sx3.T1 "Table 1 ‣ Stance Conclusion Stage ‣ Methods ‣ Stance Detection with Collaborative Role-Infused LLM-Based Agents")所示。为了确保公平比较，我们遵循大多数现有的工作（Allaway 和 McKeown [2020](https://arxiv.org/html/2310.10467v2#bib.bib2); Allaway, Srikanth 和 McKeown [2021](https://arxiv.org/html/2310.10467v2#bib.bib3); Liang 等 [2022a](https://arxiv.org/html/2310.10467v2#bib.bib26); Zhang, Li 和 Song [2019](https://arxiv.org/html/2310.10467v2#bib.bib53)）来测试我们模型的表现。具体来说，在 SEM16 和 P-Stance 数据集上，我们测试了我们模型在测试集上的表现。在 VAST 数据集上，我们测试了我们模型在零-shot 条件下的表现。为了与基于 LLM 的基准进行公平比较，我们首先采样测试集来复制它们在其提示下的结果，然后在数据集上进行实验。对于零-shot 立场检测方法，我们评估了它们在所有三个数据集上的表现。然而，对于在目标内的立场检测方法，我们只在 SEM16 和 P-Stance 上评估它们的表现，因为 VAST 数据集中的目标主要是少样本或零-shot 的。数据集中不包含任何可识别个人身份的信息，但可能包含冒犯性内容，因为文本对宗教、政治、气候等主题有明确立场。我们在使用本文中提到的所有数据集时，严格遵守各自许可的要求。

| 模型 | SEM16(%) | P-Stance(%) | VAST(%) |
| --- | --- | --- | --- |
| DT | HC | FM | LA | A | CC | Trump | Biden | Sanders | All |
| TOAD | 49.5 | 51.2 | 54.1 | 46.2 | 46.1 | 30.9 | 53.0 | 68.4 | 62.9 | 41.0 |
| TGA Net | 40.7 | 49.3 | 46.6 | 45.2 | 52.7 | 36.6 | - | - | - | 65.7 |
| BERT-GCN | 42.3 | 50.0 | 44.3 | 44.2 | 53.6 | 35.5 | - | - | - | 68.6 |
| PT-HCL | 50.1 | 54.5 | 54.6 | 50.9 | 56.5 | 38.9 | - | - | - | 71.6 |
| JointCL | 50.5 | 54.8 | 53.8 | 49.5 | 54.5 | 39.7 | 62.0 | 59.0 | 73.0 | 72.3 |
| GPT-3.5 | 62.5 | 68.7 | 44.7 | 51.5 | 9.1 | 31.1 | 62.9 | 80.0 | 71.5 | 62.3 |
| GPT-3.5+COT | 63.3 | 70.9 | 47.7 | 53.4 | 13.3 | 34.0 | 63.9 | 81.2 | 73.2 | 68.9 |
| COLA(我们的) | 68.5 | $\textbf{81.7}^{*}$ | $\textbf{63.4}^{*}$ | $\textbf{71.0}^{*}$ | $\textbf{70.8}^{*}$ | $\textbf{65.5}^{*}$ | $\textbf{86.6}^{*}$ | 84.0 | $\textbf{79.7}^{*}$ | 73.0 |

表格 2：在零-shot 立场检测任务中 COLA 和基准模型的比较。粗体和下划线表示最佳和第二最佳表现。* 表示 COLA 在 $p<0.05$ 的配对 t 检验下改善了最佳基准。

| 类别 | 模型 | SEM16(%) | P-Stance(%) |
| --- | --- | --- | --- |
| DT | HC | FM | LA | A | CC | Trump | Biden | Sanders |
|  | BiCond | 59.0 | 56.1 | 52.9 | 61.2 | 55.3 | 35.6 | 73.0 | 69.4 | 64.6 |
|  | BERT | 57.9 | 61.3 | 59.0 | 63.1 | 60.7 | 38.8 | 67.7 | 73.1 | 68.2 |
| 在目标标注数据 | CrossNet | 60.2 | 60.2 | 55.7 | 61.3 | 56.4 | 40.1 | 58.0 | 65.0 | 53.0 |
| 依赖方法 | ATT-LSTM | 55.3 | 59.8 | 55.3 | 62.6 | 55.9 | 39.2 | - | - | - |
|  | ASGCN | 58.7 | 61.0 | 58.7 | 63.2 | 59.5 | 40.6 | 77.0 | 78.4 | 70.8 |
|  | TPDG | 63.0 | 73.4 | 67.3 | 74.7 | 64.7 | 42.3 | 76.8 | 78.1 | 71.0 |
| 零-shot 方法 | COLA（我们的方法） | 68.5 | $\textbf{81.7}^{*}$ | 63.4 | 71.0 | 70.8 | $\textbf{67.5}^{*}$ | $\textbf{86.6}^{*}$ | $\textbf{84.0}^{*}$ | $\textbf{79.7}^{*}$ |

表3：零-shot COLA与完全在标注数据上训练的基线方法在目标态度检测任务中的比较。粗体和下划线表示最佳和第二最佳表现。* 表示COLA在$p<0.05$的配对t检验下改善了最佳基线。

### 实现细节

#### COLA实现

在我们的研究中，我们采用了OpenAI提供的GPT-3.5 Turbo模型作为骨干模型。我们选择GPT-3.5 Turbo主要是因为它具有优越的性能、成本效益以及通过OpenAI API提供的便捷交互方式。这些特性不仅促进了高效的研究，而且确保了我们的方法在未来的应用中具有可用性。通过利用OpenAI API提供的系统指令功能，我们指示模型充当各种代理角色，通过提示输入文本并收集模型的文本输出。为了最大化可复现性，我们将温度参数设置为0。报告的结果是5次重复运行的平均值，以确保统计可靠性。³³3我们提出的框架的源代码已发布在https://github.com/tsinghua-fib-lab/COLA。

#### 评估指标

对于SEM16和P-Stance数据集，按照之前的研究（Allaway, Srikanth, and McKeown [2021](https://arxiv.org/html/2310.10467v2#bib.bib3); Li et al. [2023a](https://arxiv.org/html/2310.10467v2#bib.bib23)），我们计算$F_{avg}$，它表示Favor和Against的F1分数平均值。对于VAST数据集，我们采用Allaway等人（[2020](https://arxiv.org/html/2310.10467v2#bib.bib2)）常用的方法，并计算宏F1分数来评估模型性能。

### 比较方法

我们将COLA与最先进的（SOTA）方法在态度检测方面进行了比较。我们进行了两项任务的比较：零-shot态度检测和目标态度检测。

我们将我们的方法与各种零样本立场检测方法进行比较。这包括对抗学习方法：TOAD（Allaway, Srikanth, 和 McKeown [2021](https://arxiv.org/html/2310.10467v2#bib.bib3)），对比学习方法：PT-HCL（Liang 等人 [2022a](https://arxiv.org/html/2310.10467v2#bib.bib26)），JointCL（Liang 等人 [2022b](https://arxiv.org/html/2310.10467v2#bib.bib28)），基于Bert的技术：TGA-Net（Allaway 和 McKeown [2020](https://arxiv.org/html/2310.10467v2#bib.bib2)）和Bert-GCN（Liu 等人 [2021](https://arxiv.org/html/2310.10467v2#bib.bib30)）。我们还包括了两种基于大语言模型的基线：GPT-3.5 Turbo 和 GPT-3.5 Turbo+Chain-of-thought（COT），这两者均可视为零样本方法，严格按照 Zhang 等人（[2022](https://arxiv.org/html/2310.10467v2#bib.bib51)）和 Zhang 等人（[2023](https://arxiv.org/html/2310.10467v2#bib.bib52)）的方式实现。

为了进一步验证我们模型的性能，我们将我们的模型与目标检测方法进行比较。这些方法经过大量训练，使用特定目标的数据集，然后在同一目标的测试集上进行评估。与之相比，我们的方法始终保持零样本，且没有对骨干模型进行微调。我们将我们的方法与多种目标检测方法的基线进行比较，包括基于RNN的方法：BiCond（Augenstein 等人 [2016](https://arxiv.org/html/2310.10467v2#bib.bib5)），和ATT-LSTM（Wang 等人 [2016](https://arxiv.org/html/2310.10467v2#bib.bib44)）；基于注意力的方法：CrossNet（Xu 等人 [2018](https://arxiv.org/html/2310.10467v2#bib.bib49)）；基于Bert的方法：BERT（Devlin 等人 [2018](https://arxiv.org/html/2310.10467v2#bib.bib13)）；基于图的方法：ASGCN（Zhang, Li 和 Song [2019](https://arxiv.org/html/2310.10467v2#bib.bib53)）和TPDG（Liang 等人 [2021](https://arxiv.org/html/2310.10467v2#bib.bib27)）。

对于非LLM方法，我们从现有文献中检索结果进行全面比较（Allaway 和 McKeown [2020](https://arxiv.org/html/2310.10467v2#bib.bib2)；Allaway, Srikanth, 和 McKeown [2021](https://arxiv.org/html/2310.10467v2#bib.bib3)；Liu 等人 [2021](https://arxiv.org/html/2310.10467v2#bib.bib30)；Liang 等人 [2021](https://arxiv.org/html/2310.10467v2#bib.bib27)，[2022a](https://arxiv.org/html/2310.10467v2#bib.bib26)；Huang 等人 [2023](https://arxiv.org/html/2310.10467v2#bib.bib19)；Khiabani 和 Zubiaga [2024](https://arxiv.org/html/2310.10467v2#bib.bib21)））。

## 结果与讨论

在本节中，我们旨在通过实验结果回答以下研究问题（RQ）。

RQ1：COLA的性能与现有的最先进立场检测模型相比如何？（准确性）

RQ2：我们模型中的每个组件是否都对性能提升有效且有贡献？（有效性）

RQ3：我们的模型能否解释其立场判断背后的理由和逻辑？（可解释性）

RQ4：我们的框架是否适用于与网络和社交媒体内容分析相关的其他文本分类任务？（多功能性）

### 总体表现（RQ1）

在表[2](https://arxiv.org/html/2310.10467v2#Sx4.T2 "表 2 ‣ 数据集 ‣ 实验 ‣ 基于协作角色注入的LLM代理的立场检测")中，我们展示了COLA在三个数据集上与基准方法相比的零-shot立场检测表现。此外，表[3](https://arxiv.org/html/2310.10467v2#Sx4.T3 "表 3 ‣ 数据集 ‣ 实验 ‣ 基于协作角色注入的LLM代理的立场检测")展示了我们零-shot COLA与基于目标标签数据依赖的基准方法在SEM16和P-Stance数据集上的表现，用于目标立场检测任务。总体结果证明了我们方法的强大表现。具体来说，以下是主要发现：

+   •

    我们的方法在所有指标上都超越了最先进的零-shot立场检测方法。在三个数据集的大多数指标上，我们的模型相较于最佳基准方法表现出了统计学上显著的改进。对于SEM16数据集中的CC和LA目标，我们的方法在$F_{avg}$上分别实现了16.9%和26.6%的绝对提升。在包含数万个实例的VAST数据集上，我们的模型在总体Macro-F1分数上实现了0.7%的显著绝对提升。这证明了我们方法在零-shot立场检测方面的强大能力。

+   •

    我们方法的表现与目标立场检测基准方法相当。我们方法的零-shot立场检测表现与最先进的目标立场检测技术紧密对齐，即使这些方法在相应目标上已经完全训练过。在SEM16数据集上，我们的方法在HC和CC目标上显著超越了最佳基准方法TPDG，同时在其他目标上的表现相当。在P-Stance数据集上，我们的方法在所有目标上始终超越了所有基准方法的表现。值得注意的是，尽管这些比较方法已经在各自的目标上经过了广泛的训练，我们的方法仍然保持了相当或更优的表现，凸显了我们方法的强大性能。

+   •

    直接应用大语言模型（LLMs）可能会导致较差的表现，特别是在抽象概念目标上。在 SEM16 数据集上，对于目标 A（无神论）和 CC（气候变化是一个真正的问题），GPT-3.5 的 $F_{avg}$ 分别只有 9.1% 和 31.1%。即便是增强版的 GPT-3.5+COT，其得分也仅为 13.3% 和 34.0%。在几乎所有数据集和评估指标上，单纯部署大语言模型的性能明显落后于我们提出的方法。这凸显了直接使用大语言模型进行立场检测任务的局限性，尤其是在处理抽象概念目标的立场时，强调了我们设计的必要性和有效性。

| 模型 | SEM16(%) |
| --- | --- |
| DT | HC | FM | LA | A | CC |
| --- | --- | --- | --- | --- | --- |
| Flan-UL2 | 64.4 | 70.1 | 65.3 | 67.3 | 57.5 | 68.5 |
| Flan-UL2 与 COLA | 64.9 | 72.3 | 65.7 | 69.8 | 61.6 | 75.1 |
| ChatGLM-2 6B | 37.9 | 60.2 | 42.0 | 43.2 | 41.0 | 13.7 |
| ChatGLM-2 6B 与 COLA | 45.3 | 60.6 | 55.4 | 43.9 | 43.6 | 37.6 |

表 4：使用 Flan-UL2 或 ChatGLM-2 6B 作为主干模型时 COLA 的表现。

为了验证我们的方法能够提升基于大语言模型（LLMs）的立场检测性能，而不仅仅是增强封闭源代码的 GPT-3.5 Turbo 的能力，我们进行了使用其他 LLM 主干模型的实验。具体来说，我们利用了 Flan-UL2 和 ChatGLM2-6B 模型在 SEM16 数据集上的实验。Flan-UL2 在立场检测任务中表现出色（Ziems 等人 [2023](https://arxiv.org/html/2310.10467v2#bib.bib54)），而 ChatGLM2-6B 是一个更常用的模型。这些实验的结果见表 [4](https://arxiv.org/html/2310.10467v2#Sx5.T4 "Table 4 ‣ Overall Performance (RQ1) ‣ Results and Discussions ‣ Stance Detection with Collaborative Role-Infused LLM-Based Agents")。

可以观察到，Flan-UL2 的表现超过了 GPT-3.5 Turbo，而 ChatGLM2 6B 的表现则明显较差。在 SEM16 数据集上，无论 LLM 主干是 Flan-UL2 还是 ChatGLM2-6B，COLA 的表现始终超过了这些 LLM 主干。值得注意的是，在效率较低的 ChatGLM2-6B 上，COLA 的性能提升更为显著，表现为 CC 目标的 $F_{avg}$ 绝对提高了 23.9%，FM 目标的 $F_{avg}$ 绝对提高了 13.4%。这些实验结果表明，我们的方法不仅能提升 GPT-3.5 Turbo 的立场检测性能，也能增强其他 LLMs 的性能。

### 消融研究 (RQ2)

为了研究我们设计中每个模块的影响，我们进行了消融实验，评估当每个模块被移除时框架的性能。结果显示在表[5](https://arxiv.org/html/2310.10467v2#Sx5.T5 "Table 5 ‣ Study on reasoning-enhanced debating stage. ‣ Ablation Study (RQ2) ‣ Results and Discussions ‣ Stance Detection with Collaborative Role-Infused LLM-Based Agents")中，结果表明我们框架中的每个模块都有助于性能的提升。接下来，我们将对结果进行详细描述。

#### 多维文本分析阶段的研究。

在多维文本分析阶段，来自不同领域的三个专家代理同时分析文本。我们逐一移除这些专家来评估我们方法的性能。同时，我们还评估了在排除所有专家分析时的性能。结果表明，除SEM16数据集上的FM外，移除任何专家代理都会导致性能在所有情况下有所下降。此外，去除整个多维文本分析阶段会导致性能显著下降。在SEM16数据集上，LA目标的性能下降最为明显。移除语言专家、领域专家和社交媒体专家分别导致$F_{avg}$下降到68.9%、67.9%和64.1%。更重要的是，去除多维文本分析阶段后，$F_{avg}$降至仅为63.8%。这可能归因于LA话题在宗教和社会等多个领域中的复杂性。这些发现凸显了我们多维文本分析阶段的有效性以及其中每个代理的设计。

#### 推理增强辩论阶段的研究。

在推理增强辩论阶段，我们引入了具有不同观点的代理之间的辩论，以增强基于LLM的系统的推理能力。我们移除了这一阶段，让判断代理直接根据专家代理的文本分析推断文本的立场，旨在验证辩论设计的有效性。去除辩论阶段导致的性能损失大于去除文本分析阶段。当去除辩论阶段时，我们的方法出现了明显的性能下降。最显著的下降出现在抽象概念目标LA（堕胎合法化）、CC（气候变化是真正的关切）和A（无神论），其中$F_{avg}$绝对值分别下降了31.2%、14.1%和11.2%。这表明推理增强辩论阶段提供了显著的收益，特别是在处理相对抽象的目标时。结果验证了推理增强辩论阶段设计的有效性。

总结来说，全面的消融研究已证明了我们设计方法中每个模块的有效性。

| 模型 | SEM16(%) |
| --- | --- |
| DT | HC | FM | LA | A | CC |
| --- | --- | --- | --- | --- | --- |
| COLA | 68.5 | 81.7 | 63.4 | 71.0 | 70.8 | 67.5 |
| 无语言学专家 | 64.3 | 80.5 | 63.3 | 68.9 | 69.9 | 65.5 |
| 无领域专家 | 66.5 | 79.2 | 64.4 | 67.9 | 70.7 | 65.4 |
| 无社交媒体资深者 | 64.8 | 76.8 | 64.5 | 64.1 | 67.7 | 63.5 |
| 无文本分析阶段 | 64.4 | 77.2 | 65.7 | 63.8 | 67.0 | 62.3 |
| 无辩论阶段 | 64.7 | 74.9 | 62.5 | 39.2 | 59.6 | 53.4 |

表 5：消融研究的实验结果。

图 3：我们方法生成的解释案例。

| 方法 | SEM16(%) |
| --- | --- |
| DT | HC | FM | LA | A | CC |
| --- | --- | --- | --- | --- | --- |
| GPT-3.5 | 69.0 | 74.0 | 59.1 | 52.0 | 8.1 | 24.7 |
| COLA | 71.2 | 75.9 | 69.1 | 71.0 | 62.3 | 64.0 |
| GPT-3.5+COLA的解释 | 69.4 | 77.7 | 70.7 | 66.7 | 61.9 | 54.5 |

表 6：GPT-3.5 Turbo、COLA和使用COLA生成解释的GPT-3.5 Turbo的表现。实验在整个SEM16数据集上进行。最佳得分用**粗体**表示。

| 类别 | 模型 | Restaurant14(%) | Laptop(%) | Restaurant15(%) |
| --- | --- | --- | --- | --- |
| 准确率 | Macro-F1 | 准确率 | Macro-F1 | 准确率 | Macro-F1 |
| 标注数据 | DGEDT | 86.3 | 80.0 | 79.8 | 75.6 | 84.0 | 71.0 |
| 依赖方法 | dotGCN | 86.2 | 80.5 | 81.0 | 78.1 | 85.2 | 72.7 |
| 零-shot方法 | GPT-3.5 Turbo | 70.6 | 59.7 | 85.0 | 66.7 | 84.0 | 62.4 |
| 我们的方法 | 74.1 | 65.7 | 87.0 | 67.5 | 90.5 | 64.3 |

表 7：我们框架和基线模型在基于方面的情感分析任务上的表现。最佳得分用**粗体**表示。

| 模型 | 准确率(%) | F1-Score(%) |
| --- | --- | --- |
| 混合RCNN | 74.8 | 59.6 |
| GPT-3.5 Turbo | 67.6 | 56.0 |
| 我们的方法 | 76.5 | 63.9 |

表 8：我们框架和基线模型在说服预测任务上的表现。最佳得分用**粗体**表示。

### 可解释性研究 (RQ3)

可解释的人工智能（XAI）是一种能够提供清晰见解或解释的人工智能，使其决策过程易于理解（Arrieta等人，[2020](https://arxiv.org/html/2310.10467v2#bib.bib4)）。通过阐明其决策过程，XAI增强了透明度并增强了模型的可信度（Das和Rad，[2020](https://arxiv.org/html/2310.10467v2#bib.bib12)）。大型语言模型本身具有解释其输出的能力。通过询问它们决策背后的理由，我们可以直接获得它们的判断解释。为了深入探讨我们方法的可解释性，我们进行案例研究和定量实验，以验证其生成清晰且合理解释的能力。

#### 案例研究。

在立场结论阶段，我们要求判断者代理以 JSON 格式提供输出，包含两个组件：立场和不超过 100 个标记的简明解释。我们在 SEM16 数据集上进行实验。在仔细检查生成的输出后，我们发现我们的模型能够为其决策提供清晰的解释。在图 [3](https://arxiv.org/html/2310.10467v2#Sx5.F3 "Figure 3 ‣ Study on reasoning-enhanced debating stage. ‣ Ablation Study (RQ2) ‣ Results and Discussions ‣ Stance Detection with Collaborative Role-Infused LLM-Based Agents") 中，我们展示了两个案例并做了如下讨论：

+   •

    在第一个例子中，推文“@Scotus 的裁决是对 @EPA 和环境的重大打击。#dirtycoal”表示气候变化是一个现实的担忧。我们的模型检测到了这一立场。在它生成的解释中，模型辨认出提到 EPA 和使用了 #dirtycoal 标签，这表明了对环境的关注。此外，模型还感知到一种沮丧的情感语气，进一步反映了亲环境的立场。

+   •

    在第二个例子中，推文“@GovtsTheProblem 这是我看到的：给你们的王后腾路！不要碰她，也不要跟她说话，你们这些脏人！#NoHillary2016 #Benghazi”表现出对希拉里的反对立场。我们的模型从语言学角度（使用贬义词）、领域专家角度（将班加西事件置于负面语境中）以及社交媒体角度（#NoHillary2016 标签）理性地解释了这一判断。这些例子验证了模型在生成清晰合理解释方面的能力。

#### 定量实验。

为了进一步验证我们模型生成清晰且合逻辑的解释的能力，我们进行定量实验。在SEM16数据集上，我们收集了与每个实例立场相关的解释（来自JSON输出的第二部分），这些解释由COLA生成。然后将这些解释与原文一起输入到GPT-3.5 Turbo模型中。我们告知模型，这些解释可以作为其决策的参考。结果，我们从模型中获得了一组新的判断。显然，通过将COLA生成的解释与原文结合使用，GPT-3.5 Turbo的表现显著提高，如表[6](https://arxiv.org/html/2310.10467v2#Sx5.T6 "Table 6 ‣ Study on reasoning-enhanced debating stage. ‣ Ablation Study (RQ2) ‣ Results and Discussions ‣ Stance Detection with Collaborative Role-Infused LLM-Based Agents")所示。请注意，我们在这里对整个SEM16数据集进行了实验，而不是仅限于测试集，以增强结果的可信度。对于A（无神论）和CC（气候变化是一个真实的关注问题）目标，$F_{avg}$分别提高了51.6和29.3点。对于HC（希拉里·克林顿）和FM（女权运动）目标，结果甚至超过了COLA。这进一步验证了我们模型在生成清晰且合逻辑的解释方面的强大能力。

总体而言，案例研究和定量实验均已证明我们方法的高可解释性。其高可解释性和准确性使其成为一种值得信赖的方法。

### 多功能性研究（RQ4）

我们提出的COLA可以总结为一个分析师-辩论者-总结者框架。在这一部分，我们进行实验以验证该分析师-辩论者-总结者框架可以应用于其他文本分类任务，以进行网络和社交媒体上的文本分析，而不仅仅是作为立场检测的临时方法。我们在两个额外的文本分类任务上进行实验：基于方面的情感分析和说服力预测。我们选择基于方面的情感分析，因为它要求精确理解与文本中特定元素相关的情感，反映了我们框架的详细分析能力。同时，选择说服力预测是因为它强调检测潜在意图，突显了COLA在处理网络和社交媒体交流中常见的复杂对话动态方面的能力。

#### 基于方面的情感分析

+   •

    实验设置：基于方面的情感分析是指确定文本中提到的每个方面所表达的情感极性（积极、消极或中立）（Pontiki等人 [2014](https://arxiv.org/html/2310.10467v2#bib.bib37)）。在此任务中，我们修改了原始框架中的辩手组件，使其进行情感辩论，而不是立场辩论，同时保持其他设计不变。我们在SemEval14（Pontiki等人 [2014](https://arxiv.org/html/2310.10467v2#bib.bib37)）和SemEval15（Pontiki等人 [2016](https://arxiv.org/html/2310.10467v2#bib.bib36)）的数据集上评估我们方法的表现，数据集包括Restaurant14、Restaurant15和Laptop。我们参考Chen等人([2017](https://arxiv.org/html/2310.10467v2#bib.bib11))的方法，使用准确率和宏观F1值作为评估指标。我们将我们的方法与需要训练的最新模型进行比较，具体为DGEDT（Tang等人 [2020](https://arxiv.org/html/2310.10467v2#bib.bib41)）和dotGCN（Chen等人 [2022](https://arxiv.org/html/2310.10467v2#bib.bib10)）。

+   •

    结果：实验结果见表[7](https://arxiv.org/html/2310.10467v2#Sx5.T7 "Table 7 ‣ Study on reasoning-enhanced debating stage. ‣ Ablation Study (RQ2) ‣ Results and Discussions ‣ Stance Detection with Collaborative Role-Infused LLM-Based Agents")。可以观察到，我们的零-shot方法在性能上与依赖标注数据的最佳基线模型相当。在Restaurant15数据集上，我们的方法甚至在准确率上超越了最佳基线模型。另一个重要的发现是，我们的方法在保持易用性的同时，始终优于直接使用GPT-3.5 Turbo。

#### 说服预测

+   •

    实验设置：根据Ziems等人([2023](https://arxiv.org/html/2310.10467v2#bib.bib54))的研究，我们将说服预测定义为在对话结束后，判断对话中的一方是否已被说服。在此任务中，我们将原始框架中的三位专家替换为两位专家：一位领域专家和一位心理学家。他们提供了关于对话主题中各种概念和名词的详细分析，并分析了参与者的心理变化。辩手们的角色被修改为讨论对话中的某个参与者是否已被说服。我们使用Wang等人([2019](https://arxiv.org/html/2310.10467v2#bib.bib43))提供的数据集，并按照他们的评估指标，使用准确率和宏观F1值进行评估。

+   •

    结果：我们将我们的方法与Hybrid RCNN（Wang等人 [2019](https://arxiv.org/html/2310.10467v2#bib.bib43)）和GPT-3.5 Turbo进行了比较，结果见表[8](https://arxiv.org/html/2310.10467v2#Sx5.T8 "表8 ‣ 推理增强辩论阶段研究 ‣ 消融研究 (RQ2) ‣ 结果与讨论 ‣ 基于协作角色注入LLM的立场检测")。实验结果表明，我们的方法在性能上优于基线，并且相较于GPT-3.5 Turbo有显著的提升。

Analyst-Debater-Summarizer框架在基于方面的情感分析和劝说分类任务中表现非常成功。在一系列任务中，我们的零-shot框架的表现与依赖训练数据的最先进基准相当，并且显著优于直接应用GPT-3.5 Turbo。这些实验展示了我们方法的多功能性。

### 讨论

在上述实验中，我们从多个维度广泛评估了我们方法的性能，具体如下：

+   •

    首先，从我们方法设计的原理角度来看，消融研究确认我们方法中的每个组件都有助于性能提升，表明该设计没有冗余，可以视为有效。

+   •

    其次，与现有方法相比，实验数据显示，我们的方法在立场检测方面优于所有其他零-shot方法。此外，其性能与依赖目标标签数据的目标立场检测方法相当，表现出令人印象深刻的准确性。

+   •

    此外，对于与网页和社交媒体内容分析相关的另外两个文本分类任务，我们的方法取得了与最先进基准相当的结果，突显了其多功能性。

+   •

    更重要的是，从实际应用角度来看，我们的方法无需额外的模型训练。相反，可以通过与现有的大型语言模型通过API或其他方式交互来实现，展示了其强大的可用性。

+   •

    最后，实验还证明，我们的框架能够为其决策提供清晰且合理的解释，确保了较高的可解释性。这些生成的解释有助于增强用户对我们方法的信任，并有利于进一步的分析。

鉴于这些优势，我们的方法有望应用于广泛的领域。

## 结论与未来工作

在本研究中，我们利用LLM的强大能力进行高级立场检测。我们提出了COLA，其中多个基于LLM的代理合作达成结论。该方法包括三个阶段：多维文本分析阶段、推理增强辩论阶段和立场结论阶段。实验结果表明，我们的方法在准确性、有效性、可解释性和多功能性方面均取得了优异的成绩，展示了其显著的应用潜力。

由于缺乏用于大规模语言模型的实时训练数据，在分析实时话题时的表现可能会略有妥协。对于未来的工作，我们打算将实时更新的知识库纳入文本分析阶段，以增强我们框架在分析包含时事的文本方面的能力。我们计划首先从实时知识库中检索相关信息，然后让大规模语言模型（LLMs）利用这些信息生成分析性文本。此外，仍然有巨大的潜力可以探索其在解决网络和社交媒体上广泛文本分析任务中的应用。

## 伦理声明

我们用于本研究的所有数据集都是开放访问的数据集。VAST数据集直接提供完整的文本数据。根据Twitter的隐私协议用于学术目的，SEM16和P-Stance数据集通过官方Twitter API⁴⁴4https://developer.twitter.com/en/docs/twitter-api获取完整的文本数据，基于Tweet ID。数据集不包含任何可识别个人身份的信息，但可能包含冒犯性内容，因为文本表达了关于宗教、政治、气候等敏感话题的强烈意见。在使用论文中引用的所有数据集时，我们始终遵守各自许可证的要求。我们使用由OpenAI提供的GPT-3.5 Turbo API服务，并遵守OpenAI的条款和政策。

在我们的主要实验中，我们使用了GPT-3.5 Turbo作为核心框架。虽然使用闭源的大规模语言模型（LLMs）涉及较大的财务成本，但我们的框架在使用开源LLMs时也展示了改进的立场检测性能。需要注意的是，运行LLMs需要大量的能源，这是所有基于LLMs的算法的共同问题。我们期待能有节能硬件技术的进步，缓解这一问题。

关于潜在的滥用问题，我们认识到我们的技术，像许多其他技术一样，存在被某些实体用于不道德目的的风险，例如用于压制批评声音或识别并在社交媒体上针对异见者。我们敦促我们的技术用户承诺负责任和道德的使用。平衡技术进步与有意识的方法来减少风险至关重要，尤其是在立场检测等与敏感社会和政治领域交叉的领域。

## 致谢

本工作得到了中国国家自然科学基金的支持，项目号：U23B2030，62272262和72342032。

## 参考文献

+   AlDayel和Magdy（2021）AlDayel, A.; 和 Magdy, W. 2021. 社交媒体上的立场检测：现状与趋势。*Information Processing & Management*, 58(4): 102597。

+   Allaway和McKeown（2020）Allaway, E.; 和 McKeown, K. 2020. 零-shot立场检测：使用广义话题表示的数据集和模型。*arXiv预印本arXiv:2010.03640*。

+   Allaway, Srikanth 和 McKeown (2021) Allaway, E.; Srikanth, M.; 和 McKeown, K. 2021. 面向社交媒体的零样本立场检测的对抗学习。*arXiv 预印本 arXiv:2105.06603*。

+   Arrieta 等人 (2020) Arrieta, A. B.; Díaz-Rodríguez, N.; Del Ser, J.; Bennetot, A.; Tabik, S.; Barbado, A.; García, S.; Gil-López, S.; Molina, D.; Benjamins, R.; 等人 2020. 可解释人工智能 (XAI)：概念、分类、机会与挑战，迈向负责任的人工智能。*信息融合*，58: 82–115。

+   Augenstein 等人 (2016) Augenstein, I.; Rocktäschel, T.; Vlachos, A.; 和 Bontcheva, K. 2016. 基于双向条件编码的立场检测。*arXiv 预印本 arXiv:1606.05464*。

+   Bar-Haim 等人 (2017) Bar-Haim, R.; Bhattacharya, I.; Dinuzzo, F.; Saha, A.; 和 Slonim, N. 2017. 上下文相关声明的立场分类。在 *第15届欧洲计算语言学协会年会论文集：第1卷，长篇论文*，251–261。

+   Brown 等人 (2020) Brown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J. D.; Dhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell, A.; 等人 2020. 语言模型是少样本学习者。*神经信息处理系统进展*，33: 1877–1901。

+   Cai 等人 (2023) Cai, T.; Wang, X.; Ma, T.; Chen, X.; 和 Zhou, D. 2023. 大型语言模型作为工具制造者。*arXiv 预印本 arXiv:2305.17126*。

+   Chan 等人 (2023) Chan, C.-M.; Chen, W.; Su, Y.; Yu, J.; Xue, W.; Zhang, S.; Fu, J.; 和 Liu, Z. 2023. ChatEval: 通过多代理辩论促进更好的基于大型语言模型的评估器。*arXiv 预印本 arXiv:2308.07201*。

+   Chen 等人 (2022) Chen, C.; Teng, Z.; Wang, Z.; 和 Zhang, Y. 2022. 基于方面的情感分析中的离散意见树归纳。在 *第60届计算语言学协会年会论文集（第1卷：长篇论文）*，2051–2064。

+   Chen 等人 (2017) Chen, P.; Sun, Z.; Bing, L.; 和 Yang, W. 2017. 基于记忆的方面情感分析的递归注意力网络。在 *2017年自然语言处理经验方法会议论文集*，452–461。

+   Das 和 Rad (2020) Das, A.; 和 Rad, P. 2020. 可解释人工智能 (XAI) 的机会与挑战：一项调查。*arXiv 预印本 arXiv:2006.11371*。

+   Devlin 等人 (2018) Devlin, J.; Chang, M.-W.; Lee, K.; 和 Toutanova, K. 2018. Bert: 语言理解的深度双向转换器预训练。*arXiv 预印本 arXiv:1810.04805*。

+   Du 等人 (2023) Du, Y.; Li, S.; Torralba, A.; Tenenbaum, J. B.; 和 Mordatch, I. 2023. 通过多代理辩论提升语言模型的事实性和推理能力。*arXiv 预印本 arXiv:2305.14325*。

+   Gao 等人 (2023a) Gao, C.; Lan, X.; Li, N.; Yuan, Y.; Ding, J.; Zhou, Z.; Xu, F.; 和 Li, Y. 2023a. 大型语言模型驱动的基于代理的建模与仿真：综述与展望。*arXiv 预印本 arXiv:2312.11970*。

+   Gao 等人（2023b）Gao, C.; Lan, X.; Lu, Z.; Mao, J.; Piao, J.; Wang, H.; Jin, D.; 和 Li, Y. 2023b. S³: 基于大语言模型增强代理的社交网络模拟系统。*arXiv 预印本 arXiv:2307.14984*。

+   Grčar 等人（2017）Grčar, M.; Cherepnalkoski, D.; Mozetič, I.; 和 Kralj Novak, P. 2017. Twitter 用户在 Brexit 公投中的立场与影响。*计算社交网络*，4: 1–25。

+   Hong 等人（2023）Hong, S.; Zheng, X.; Chen, J.; Cheng, Y.; Zhang, C.; Wang, Z.; Yau, S. K. S.; Lin, Z.; Zhou, L.; Ran, C.; 等人. 2023. Metagpt: 面向多代理协作框架的元编程。*arXiv 预印本 arXiv:2308.00352*。

+   Huang 等人（2023）Huang, H.; Zhang, B.; Li, Y.; Zhang, B.; Sun, Y.; Luo, C.; 和 Peng, C. 2023. 基于知识增强的立场检测提示调优。*ACM 亚洲与低资源语言信息处理学报*，22(6): 1–20。

+   Jang 和 Allan（2018）Jang, M.; 和 Allan, J. 2018. 通过立场总结解释社交媒体上的争议。发表于*第41届国际ACM SIGIR信息检索研究与发展会议*，1221–1224。

+   Khiabani 和 Zubiaga（2024）Khiabani, P. J.; 和 Zubiaga, A. 2024. SocialPET: 基于社会信息的模式挖掘训练用于社交媒体中少样本立场检测。*arXiv 预印本 arXiv:2403.05216*。

+   Küçük 和 Can（2020）Küçük, D.; 和 Can, F. 2020. 立场检测：一项综述。*ACM 计算机调查（CSUR）*，53(1): 1–37。

+   Li 等人（2023a）Li, A.; Liang, B.; Zhao, J.; Zhang, B.; Yang, M.; 和 Xu, R. 2023a. 利用背景知识进行社交媒体中的立场检测。发表于*2023年自然语言处理经验方法会议论文集*，15703–15717。

+   Li 等人（2023b）Li, N.; Gao, C.; Li, Y.; 和 Liao, Q. 2023b. 基于大语言模型增强的代理用于模拟宏观经济活动。*arXiv 预印本 arXiv:2310.10436*。

+   Li 等人（2021）Li, Y.; Sosea, T.; Sawant, A.; Nair, A. J.; Inkpen, D.; 和 Caragea, C. 2021. P-stance: 政治领域立场检测的大型数据集。发表于*2021年计算语言学会会议成果：ACL-IJCNLP 2021*，2355–2365。

+   Liang 等人（2022a）Liang, B.; Chen, Z.; Gui, L.; He, Y.; Yang, M.; 和 Xu, R. 2022a. 基于对比学习的零样本立场检测。发表于*2022年ACM Web会议论文集*，2738–2747。

+   Liang 等人（2021）Liang, B.; Fu, Y.; Gui, L.; Yang, M.; Du, J.; He, Y.; 和 Xu, R. 2021. 面向跨目标立场检测的目标自适应图。发表于*2021年Web会议论文集*，3453–3464。

+   Liang 等人（2022b）Liang, B.; Zhu, Q.; Li, X.; Yang, M.; Gui, L.; He, Y.; 和 Xu, R. 2022b. Jointcl: 一种联合对比学习框架用于零样本立场检测。发表于*第60届计算语言学协会年会（第一卷：长篇论文）论文集*，第1卷，81–91。计算语言学协会。

+   Liang 等人（2023）Liang, T.; He, Z.; Jiao, W.; Wang, X.; Wang, Y.; Wang, R.; Yang, Y.; Tu, Z.; 和 Shi, S. 2023. 通过多代理辩论鼓励大型语言模型的发散思维。*arXiv 预印本 arXiv:2305.19118*。

+   Liu 等人（2021）Liu, R.; Lin, Z.; Tan, Y.; 和 Wang, W. 2021. 通过常识知识图增强零样本和少样本立场检测。在 *计算语言学协会的发现：ACL-IJCNLP 2021*，3152–3157。

+   Lozhnikov, Derczynski 和 Mazzara（2020）Lozhnikov, N.; Derczynski, L.; 和 Mazzara, M. 2020. 俄语立场预测：数据与分析。在 *第6届国防应用软件工程国际会议：SEDA 2018 6*，176–186. Springer。

+   Mohammad 等人（2016）Mohammad, S.; Kiritchenko, S.; Sobhani, P.; Zhu, X.; 和 Cherry, C. 2016. Semeval-2016 任务6：检测推文中的立场。在 *第10届国际语义评估研讨会（SemEval-2016）*，31–41。

+   Nair 等人（2023）Nair, V.; Schumacher, E.; Tso, G.; 和 Kannan, A. 2023. DERA: 利用对话启用的解决代理增强大型语言模型的生成。*arXiv 预印本 arXiv:2303.17071*。

+   OpenAI（2023）OpenAI, R. 2023. GPT-4 技术报告。*arXiv*，2303–08774。

+   Park 等人（2023）Park, J. S.; O’Brien, J. C.; Cai, C. J.; Morris, M. R.; Liang, P.; 和 Bernstein, M. S. 2023. 生成代理：人类行为的互动模拟。*arXiv 预印本 arXiv:2304.03442*。

+   Pontiki 等人（2016）Pontiki, M.; Galanis, D.; Papageorgiou, H.; Androutsopoulos, I.; Manandhar, S.; AL-Smadi, M.; Al-Ayyoub, M.; Zhao, Y.; Qin, B.; De Clercq, O.; 等人 2016. Semeval-2016 任务5：基于方面的情感分析。在 *语义评估工作坊（SemEval-2016）*，19–30. 计算语言学协会。

+   Pontiki 等人（2014）Pontiki, M.; Galanis, D.; Pavlopoulos, J.; Papageorgiou, H.; Androutsopoulos, I.; 和 Manandhar, S. 2014. SemEval-2014 任务4：基于方面的情感分析。在 *第8届国际语义评估研讨会（SemEval 2014）*，27–35. 爱尔兰都柏林：计算语言学协会。

+   Qin 等人（2023）Qin, Y.; Liang, S.; Ye, Y.; Zhu, K.; Yan, L.; Lu, Y.; Lin, Y.; Cong, X.; Tang, X.; Qian, B.; 等人 2023. Toolllm: 促进大型语言模型掌握16000+现实世界 API。*arXiv 预印本 arXiv:2307.16789*。

+   Schick 等人（2023）Schick, T.; Dwivedi-Yu, J.; Dessì, R.; Raileanu, R.; Lomeli, M.; Zettlemoyer, L.; Cancedda, N.; 和 Scialom, T. 2023. Toolformer: 语言模型可以自我学习使用工具。*arXiv 预印本 arXiv:2302.04761*。

+   Shinn 等人（2023）Shinn, N.; Cassano, F.; Labash, B.; Gopinath, A.; Narasimhan, K.; 和 Yao, S. 2023. Reflexion: 带有语言强化学习的语言代理（arXiv: 2303.11366）。arXiv。

+   Tang 等人（2020）Tang, H.; Ji, D.; Li, C.; 和 Zhou, Q. 2020. 依赖图增强的双重变换器结构用于基于方面的情感分类. 在 *第58届计算语言学协会年会论文集*，6578–6588。

+   Touvron 等人（2023）Touvron, H.; Martin, L.; Stone, K.; Albert, P.; Almahairi, A.; Babaei, Y.; Bashlykov, N.; Batra, S.; Bhargava, P.; Bhosale, S.; 等人. 2023. Llama 2: 开放基础模型和微调的聊天模型. *arXiv 预印本 arXiv:2307.09288*。

+   Wang 等人（2019）Wang, X.; Shi, W.; Kim, R.; Oh, Y.; Yang, S.; Zhang, J.; 和 Yu, Z. 2019. 促成善意：朝着一个个性化的社会公益说服对话系统迈进. *arXiv 预印本 arXiv:1906.06725*。

+   Wang 等人（2016）Wang, Y.; Huang, M.; Zhu, X.; 和 Zhao, L. 2016. 基于注意力机制的LSTM用于方面级情感分类. 在 *2016年自然语言处理经验方法会议论文集*，606–615。

+   Wei 等人（2021）Wei, J.; Bosma, M.; Zhao, V. Y.; Guu, K.; Yu, A. W.; Lester, B.; Du, N.; Dai, A. M.; 和 Le, Q. V. 2021. 微调语言模型是零-shot学习者. *arXiv 预印本 arXiv:2109.01652*。

+   Wei 和 Mao（2019）Wei, P.; 和 Mao, W. 2019. 为跨目标立场检测建模可转移主题. 在 *第42届国际ACM SIGIR信息检索研究与开发大会论文集*，1173–1176。

+   Wei, Mao 和 Zeng（2018）Wei, P.; Mao, W.; 和 Zeng, D. 2018. 一种针对推特立场检测的目标引导神经记忆模型. 在 *2018年国际联合神经网络大会（IJCNN）*，1–8. IEEE。

+   Xiang 等人（2023）Xiang, J.; Tao, T.; Gu, Y.; Shu, T.; Wang, Z.; Yang, Z.; 和 Hu, Z. 2023. 语言模型遇上世界模型：体现的体验增强语言模型. *arXiv 预印本 arXiv:2305.10626*。

+   Xu 等人（2018）Xu, C.; Paris, C.; Nepal, S.; 和 Sparks, R. 2018. 基于自注意力网络的跨目标立场分类. *arXiv 预印本 arXiv:1805.06593*。

+   Zeng 等人（2022）Zeng, A.; Liu, X.; Du, Z.; Wang, Z.; Lai, H.; Ding, M.; Yang, Z.; Xu, Y.; Zheng, W.; Xia, X.; 等人. 2022. Glm-130b: 一个开放的双语预训练模型. *arXiv 预印本 arXiv:2210.02414*。

+   Zhang, Ding 和 Jing（2022）Zhang, B.; Ding, D.; 和 Jing, L. 2022. ChatGPT发布后，立场检测技术会如何发展？*arXiv 预印本 arXiv:2212.14548*。

+   Zhang 等人（2023）Zhang, B.; Fu, X.; Ding, D.; Huang, H.; Li, Y.; 和 Jing, L. 2023. 探索通过 ChatGPT 进行链式思维来进行社交媒体上的立场检测. *arXiv 预印本 arXiv:2304.03087*。

+   Zhang, Li 和 Song（2019）Zhang, C.; Li, Q.; 和 Song, D. 2019. 基于方面的情感分类与方面特定图卷积网络. 在 *2019年自然语言处理经验方法会议及第9届国际联合自然语言处理会议（EMNLP-IJCNLP）*，4568–4578。

+   Ziems 等人（2023）Ziems, C.; Held, W.; Shaikh, O.; Chen, J.; Zhang, Z.; 和 Yang, D. 2023. 大型语言模型能否改变计算社会科学？*arXiv 预印本 arXiv:2305.03514*。

## 论文检查清单

1.  1.

    对于大多数作者来说…

    1.  (a)

        回答这个研究问题是否能推动科学进步，同时不违反社会契约，如不侵犯隐私规范、不加剧不公平的刻板印象、不加剧社会经济鸿沟或不对社会或文化表示不尊重？是的。

    1.  (b)

        您的摘要和引言中的主要论点是否准确反映了论文的贡献和范围？是的。

    1.  (c)

        您是否阐明了所提出的方法论方法对于所做的论断是如何适当的？是的。

    1.  (d)

        您是否阐明了在所使用的数据中，考虑到特定人群分布，可能的伪影是什么？NA

    1.  (e)

        您是否描述了您的工作的局限性？是的，见结论与未来工作。

    1.  (f)

        您是否讨论了您的研究可能带来的负面社会影响？NA

    1.  (g)

        您是否讨论了您的研究可能被误用的情况？NA

    1.  (h)

        您是否描述了为防止或缓解研究可能带来的负面后果所采取的步骤，例如数据和模型文档、数据匿名化、负责任的发布、访问控制以及研究结果的可重复性？是的，见实验设置。

    1.  (i)

        您是否阅读了伦理审查指南，并确保您的论文符合其中的要求？是的。

1.  2.

    此外，如果您的研究涉及假设检验…

    1.  (a)

        您是否清楚地陈述了所有理论结果背后的假设？NA

    1.  (b)

        您是否为所有理论结果提供了论证？NA

    1.  (c)

        您是否讨论了可能挑战或补充您理论结果的竞争性假设或理论？NA

    1.  (d)

        您是否考虑了其他机制或解释，这些机制或解释可能解释您研究中观察到的相同结果？NA

    1.  (e)

        您是否解决了您理论框架中可能存在的偏见或局限性？NA

    1.  (f)

        您是否将您的理论结果与社会科学领域的现有文献进行了关联？NA

    1.  (g)

        您是否讨论了您的理论结果对社会科学领域的政策、实践或进一步研究的影响？NA

1.  3.

    此外，如果您包含了理论证明…

    1.  (a)

        您是否陈述了所有理论结果的完整假设集？NA

    1.  (b)

        您是否提供了所有理论结果的完整证明？NA

1.  4.

    此外，如果您进行的机器学习实验…

    1.  (a)

        您是否包含了重现主要实验结果所需的代码、数据和说明（无论是在补充材料中，还是作为 URL）？是的，见实验设置。

    1.  (b)

        您是否指定了所有训练细节（例如数据划分、超参数及其选择方式）？NA

    1.  (c)

        您是否报告了误差条（例如，在多次实验后关于随机种子的误差）？是的，我们进行了多次重复实验。在主要实验结果中，当声明我们的方法优于最佳基线时，我们使用了配对 t 检验。

    1.  (d)

        您是否包括了计算总量和使用的资源类型（例如，GPU类型、内部集群或云服务提供商）？NA

    1.  (e)

        您是否证明了所提议的评估对所做的主张是充分且恰当的？是的，见实验设置和实验结果。

    1.  (f)

        您是否讨论了“误分类”和容错性的问题（包括成本）？NA

1.  5.

    此外，如果您使用现有资源（例如代码、数据、模型）或整理/发布新资源，且不妥协匿名性…

    1.  (a)

        如果您的工作使用了现有资源，您是否引用了创作者？是的，见实验设置和实验结果。

    1.  (b)

        您是否提到了资产的许可证？是的。

    1.  (c)

        您是否在附加材料中或作为网址提供了任何新资源？是的，我们提供了 COLA 的代码。

    1.  (d)

        您是否讨论了如何以及是否从使用/整理的数据的人员那里获得了同意？没有，因为我们仅使用开源数据集。

    1.  (e)

        您是否讨论了所使用/整理的数据是否包含个人可识别信息或冒犯性内容？是的，见数据集部分。

    1.  (f)

        如果您整理或发布了新的数据集，您是否讨论了如何使您的数据集符合 FAIR 原则？NA

    1.  (g)

        如果您整理或发布了新的数据集，是否为数据集创建了数据表？NA

1.  6.

    此外，如果您使用了众包或进行涉及人类参与者的研究，且不妥协匿名性…

    1.  (a)

        您是否包括了提供给参与者的完整指令文本和截图？NA

    1.  (b)

        您是否描述了任何潜在的参与者风险，并提到了机构审查委员会（IRB）的批准？NA

    1.  (c)

        您是否包括了支付给参与者的估计时薪和总支出的参与者补偿金额？NA

    1.  (d)

        您是否讨论了数据是如何存储、共享和去标识化的？NA
