- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 18:50:12'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:50:12
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Driving Style Alignment for LLM-powered Driver Agent
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大型语言模型驱动的驾驶代理的驾驶风格对齐
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2403.11368](https://ar5iv.labs.arxiv.org/html/2403.11368)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2403.11368](https://ar5iv.labs.arxiv.org/html/2403.11368)
- en: 'Ruoxuan Yang, Xinyue Zhang, Anais Fernandez-Laaksonen, Xin Ding and Jiangtao
    Gong^(🖂) The authors are with the Institute for AI Industry Research, Tsinghua
    University, Beijing, China. Corresponding Email: gongjiangtao@air.tsinghua.edu.cn'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 杨若轩、张心悦、安娜伊斯·费尔南德斯-拉克松恩、丁鑫和龚江涛^(🖂) 作者隶属于中国北京清华大学人工智能产业研究院。 联系邮箱：gongjiangtao@air.tsinghua.edu.cn
- en: Abstract
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Recently, LLM-powered driver agents have demonstrated considerable potential
    in the field of autonomous driving, showcasing human-like reasoning and decision-making
    abilities. However, current research on aligning driver agent behaviors with human
    driving styles remains limited, partly due to the scarcity of high-quality natural
    language data from human driving behaviors. To address this research gap, we propose
    a multi-alignment framework designed to align driver agents with human driving
    styles through demonstrations and feedback. Notably, we construct a natural language
    dataset of human driver behaviors through naturalistic driving experiments and
    post-driving interviews, offering high-quality human demonstrations for LLM alignment.
    The framework’s effectiveness is validated through simulation experiments in the
    CARLA urban traffic simulator and further corroborated by human evaluations. Our
    research offers valuable insights into designing driving agents with diverse driving
    styles. The implementation of [the framework](https://github.com/AIR-DISCOVER/Multi-alignment-Drivng-Agent)¹¹1[https://github.com/AIR-DISCOVER/Multi-alignment-Drivng-Agent](https://github.com/AIR-DISCOVER/Multi-alignment-Drivng-Agent)
    and details of [the dataset](https://github.com/AIR-DISCOVER/Driving-Thinking-Dataset)²²2[https://github.com/AIR-DISCOVER/Driving-Thinking-Dataset](https://github.com/AIR-DISCOVER/Driving-Thinking-Dataset)
    can be found at the link.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，大型语言模型（LLM）驱动的驾驶代理在自动驾驶领域展现了相当大的潜力，展示了类人的推理和决策能力。然而，目前关于将驾驶代理行为与人类驾驶风格对齐的研究仍然有限，部分原因是缺乏来自人类驾驶行为的高质量自然语言数据。为了填补这一研究空白，我们提出了一个多对齐框架，通过演示和反馈将驾驶代理与人类驾驶风格对齐。值得注意的是，我们通过自然驾驶实验和驾驶后访谈构建了一个人类驾驶行为的自然语言数据集，为LLM对齐提供了高质量的人类演示。该框架的有效性通过CARLA城市交通模拟器中的模拟实验进行了验证，并通过人工评估进一步证实。我们的研究为设计具有多样驾驶风格的驾驶代理提供了宝贵的见解。框架的实现和数据集的详细信息可以在[该链接](https://github.com/AIR-DISCOVER/Multi-alignment-Drivng-Agent)和[该链接](https://github.com/AIR-DISCOVER/Driving-Thinking-Dataset)找到。
- en: I INTRODUCTION
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I 引言
- en: In the burgeoning field of autonomous driving (AV), driver agents powered by
    Large Language Models (LLMs) are demonstrating remarkable promise due to their
    exceptional planning[[1](#bib.bib1)] and reasoning[[2](#bib.bib2), [3](#bib.bib3),
    [4](#bib.bib4)] capabilities. Researchers have delved into the development of
    intricately designed driver agents that could perceive environmental stimuli[[5](#bib.bib5),
    [6](#bib.bib6), [7](#bib.bib7)], comprehend the situation[[8](#bib.bib8)], fetch
    their memories[[9](#bib.bib9), [10](#bib.bib10)] and deduce subsequent driving
    actions[[11](#bib.bib11)] that mirrors human decision-making. Such human-like
    AVs show promise in navigating a diverse range of driving scenarios [[12](#bib.bib12),
    [13](#bib.bib13)], enabling better anticipation of AV behavior by other road users [[14](#bib.bib14)],
    while also enhancing human trust in these systems [[15](#bib.bib15)].
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在迅速发展的自动驾驶（AV）领域，由大型语言模型（LLMs）驱动的驾驶代理显示出显著的潜力，得益于其卓越的规划[[1](#bib.bib1)]和推理[[2](#bib.bib2),
    [3](#bib.bib3), [4](#bib.bib4)]能力。 研究人员已经深入研究了精心设计的驾驶代理，这些代理能够感知环境刺激[[5](#bib.bib5),
    [6](#bib.bib6), [7](#bib.bib7)]，理解情况[[8](#bib.bib8)]，提取记忆[[9](#bib.bib9), [10](#bib.bib10)]并推断后续驾驶行为[[11](#bib.bib11)]，这类似于人类的决策过程。
    这些类人化的AV在应对各种驾驶场景方面展现出潜力[[12](#bib.bib12), [13](#bib.bib13)]，使其他道路使用者能够更好地预测AV行为[[14](#bib.bib14)]，同时增强了人类对这些系统的信任[[15](#bib.bib15)]。
- en: However, aligning these driver agents with human driving styles to imbue them
    with more human-like and personalized characteristics remains unexplored. Prevailing
    strategies for aligning LLM-based agents with humans, such as fine-tuning[[5](#bib.bib5),
    [6](#bib.bib6), [16](#bib.bib16)] and the integration of expert feedback[[17](#bib.bib17),
    [18](#bib.bib18)], are often hindered by their high costs. Recently, some studies
    have leveraged AI to generate feedback or reflections[[19](#bib.bib19), [20](#bib.bib20),
    [21](#bib.bib21), [22](#bib.bib22)], yet they fall short in aligning such reflections
    with human perspectives. On the other hand, despite researches focusing on employing
    AI to generate few-shot demonstrations[[1](#bib.bib1), [23](#bib.bib23)] for LLMs,
    another challenge in enhancing agent-human alignment lies in the lack of high-quality
    human behavior data in a form accessible to LLMs, making it difficult for agents
    to learn from human demonstrations. Existing datasets for autonomous driving learning
    either provide only environment data for perception tasks[[24](#bib.bib24), [25](#bib.bib25),
    [26](#bib.bib26)] rather than driving behaviors, or present driving behaviors
    in non-linguistic modalities (e.g. trajectories in maps[[27](#bib.bib27)], Controller
    Area Network Bus (CAN-Bus) data[[28](#bib.bib28), [29](#bib.bib29)], in-car videos[[30](#bib.bib30)])
    that are indirect for LLMs to learn from. Thus, successful alignment requires
    an approach that efficiently synchronizes LLM-based driver agents with human driving
    styles, as well as a collection of driving demonstrations across different driving
    styles in natural language for LLMs’ comprehension and learning.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，将这些驱动代理与人类驾驶风格对齐，以赋予其更具人性化和个性化的特征仍然未被探索。现行的将基于LLM的代理与人类对齐的策略，如微调[[5](#bib.bib5),
    [6](#bib.bib6), [16](#bib.bib16)]和专家反馈的整合[[17](#bib.bib17), [18](#bib.bib18)]，通常因其高成本而受到阻碍。最近，一些研究利用AI生成反馈或反思[[19](#bib.bib19),
    [20](#bib.bib20), [21](#bib.bib21), [22](#bib.bib22)]，但在将这些反思与人类视角对齐方面仍显不足。另一方面，尽管研究集中在使用AI生成少量示范[[1](#bib.bib1),
    [23](#bib.bib23)]以用于LLMs，增强代理与人类对齐的另一个挑战在于缺乏以LLMs可访问的形式提供的高质量人类行为数据，这使得代理很难从人类示范中学习。现有的自动驾驶学习数据集要么仅提供感知任务的环境数据[[24](#bib.bib24),
    [25](#bib.bib25), [26](#bib.bib26)]，而非驾驶行为，要么以非语言方式呈现驾驶行为（例如地图中的轨迹[[27](#bib.bib27)]，控制器局域网总线（CAN-Bus）数据[[28](#bib.bib28),
    [29](#bib.bib29)]，车内视频[[30](#bib.bib30)]），这些都对LLMs的学习间接。因此，成功的对齐需要一种方法，能够有效地将基于LLM的驱动代理与人类驾驶风格同步，并收集不同驾驶风格的自然语言驾驶示范，以便LLMs理解和学习。
- en: In this paper, we introduce a novel multi-alignment framework that utilizes
    demonstrations and feedback to align driver agents with human driving styles.
    Diverging from reliance on human expert feedback or reflections from LLMs themselves,
    our approach harnesses the few-shot learning capabilities[[31](#bib.bib31)] of
    LLMs to create a Coach Agent that learns from human demonstrations, evaluates
    past driving behaviors, and formulates driving guidelines. All human demonstrations
    are pre-collected, eliminating the need for additional human effort during alignment
    and substantially reducing costs.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们介绍了一种新颖的多重对齐框架，该框架利用示范和反馈将驱动代理与人类驾驶风格对齐。与依赖人类专家反馈或LLMs自身反思不同，我们的方法利用LLMs的少量学习能力[[31](#bib.bib31)]创建一个教练代理，该代理从人类示范中学习，评估过去的驾驶行为，并制定驾驶指南。所有人类示范均为预先收集的，消除了对齐过程中额外的人力需求，大幅降低了成本。
- en: Moreover, to collect high-quality demonstrations for alignment, we compiled
    a dataset that encompasses driving behaviors from drivers with varied driving
    styles. A real-world driving experiment was conducted, followed by a post-driving
    interview, wherein we gathered and structured human drivers’ decision-making data.
    This dataset likely represents the first effort to meticulously dissect human
    driving behaviors and articulate the driving decision-making process in a natural
    language format.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，为了收集用于对齐的高质量示范，我们编制了一个涵盖各种驾驶风格驾驶行为的数据集。进行了一项现实世界的驾驶实验，随后进行了一次驾驶后的访谈，在此过程中我们收集并整理了人类驾驶者的决策数据。这个数据集可能代表了首次细致剖析人类驾驶行为并以自然语言格式阐述驾驶决策过程的努力。
- en: We validate our work through both simulation experiments and human evaluation
    surveys, demonstrating that our multi-aligned framework effectively creates driver
    agents with distinct driving styles that are not only statistically sound but
    also distinctly perceptible to humans.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过模拟实验和人工评估调查验证了我们的工作，证明我们的多重对齐框架有效地创建了具有明显驾驶风格的驾驶代理，这些风格不仅在统计上合理，而且对人类来说也十分明显。
- en: 'The contributions of this paper are summarized as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的贡献总结如下：
- en: •
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: A multi-alignment framework that can align LLM-based driver agents with human
    driving styles.
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一个可以将基于LLM的驾驶代理与人类驾驶风格对齐的多重对齐框架。
- en: •
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: A dataset of human driving behaviors in natural language format.
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一份以自然语言格式记录的人类驾驶行为数据集。
- en: •
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Comprehensive validation through both simulation experiments and human evaluations.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过模拟实验和人工评估进行全面验证。
- en: II Multi-alignment Framework
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 多重对齐框架
- en: '![Refer to caption](img/3236b93846f5c54550d88b579c0787e7.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![参见图例](img/3236b93846f5c54550d88b579c0787e7.png)'
- en: 'Figure 1: The multi-alignment framework'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：多重对齐框架
- en: Fig. [1](#S2.F1 "Figure 1 ‣ II Multi-alignment Framework ‣ Driving Style Alignment
    for LLM-powered Driver Agent") demonstrates the comprehensive structure of the
    multi-alignment framework, consisting of a Driver Agent, a Coach Agent, and demonstrations
    from human drivers. In this section, we first introduce the architecture and basic
    workflow of the Driver Agent. Then we show how to achieve multi-alignment through
    direct demonstration data from human drivers and feedback from the Coach Agent
    with human demonstrations.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [1](#S2.F1 "Figure 1 ‣ II Multi-alignment Framework ‣ Driving Style Alignment
    for LLM-powered Driver Agent") 展示了多重对齐框架的全面结构，包括一个驾驶代理、一个教练代理和来自人类驾驶员的示范。在这一部分，我们首先介绍驾驶代理的架构和基本工作流程。接着，我们展示了如何通过来自人类驾驶员的直接示范数据和教练代理的反馈实现多重对齐。
- en: II-A Driver Agent
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-A 驾驶代理
- en: The Driver Agent acts as entities interacting with the surrounding driving environment
    and making driving decisions. It maintains an iterable, fixed-capacity short-term
    memory, which stores the most recent memory units, promoting the continuity and
    consistency of decision-making.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 驾驶代理作为与周围驾驶环境交互并做出驾驶决策的实体。它维持一个可迭代的固定容量短期记忆，存储最新的记忆单元，促进决策的连续性和一致性。
- en: 'The workflow begins by capturing the current state and environment information
    for perception, including the speed and direction of the agent vehicle, the speed
    limits and other restrictions of the current road, as well as the status of other
    vehicles and pedestrians nearby. Next, it analyzes the collected information alongside
    its short-term memory to grasp the current situation. Following this analysis,
    along with provided Demonstrations and Guidelines for multi-alignment, the Driver
    Agent deduces the most appropriate driving action at the moment. Here, the Driver
    Agent is prompted to ’Think Step by Step,’ employing a chain-of-thought (CoT)
    reasoning strategy towards the final decision:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流程始于捕捉当前状态和环境信息以进行感知，包括代理车辆的速度和方向、当前道路的限速和其他限制，以及附近其他车辆和行人的状态。接下来，它分析收集到的信息以及其短期记忆，以把握当前情况。在这一分析之后，结合提供的示范和多重对齐指南，驾驶代理推断出此时最合适的驾驶动作。在这里，驾驶代理被提示“逐步思考”，采用链式思维（CoT）推理策略来做出最终决策：
- en: “Given the rather faster speed of the vehicle ahead and inability to change
    lanes, the agent car should match the speed by gentle acceleration.”
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: “鉴于前方车辆速度较快且无法变道，代理车应通过轻微加速来匹配速度。”
- en: Next, the Driver Agent selects the most matching ones from a set of atomic driving
    operations as the step’s action and performs. The ”Situation,” ”Reasoning,” and
    ”Action” generated are then compiled into a memory unit and incorporated into
    the short-term memory, while the earliest memory unit is popped out. Through the
    consistent repetition of this process, the Driver Agent successfully crafts a
    sequence of fluid and coherent driving maneuvers.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，驾驶代理从一组原子驾驶操作中选择最匹配的操作作为步骤动作并执行。生成的“情境”、“推理”和“行动”被编入记忆单元并纳入短期记忆，同时最早的记忆单元被弹出。通过一致重复这一过程，驾驶代理成功地制定出一系列流畅且连贯的驾驶动作。
- en: II-B Multi-alignment through Demonstrations and Feedback
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-B 通过示范和反馈实现多重对齐
- en: We construct a framework that could multi-align the Driver Agent with human
    driving styles by adopting demonstrations and feedback.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建了一个框架，通过采用演示和反馈，将驾驶员代理与人类驾驶风格进行多重对齐。
- en: Demonstrations encompass representative decision-making processes of human drivers,
    featuring both cautious and risky driving demonstrations. They are collected and
    then organized into the form of the Driver Agent’s memory units (with more details
    in Section [III](#S3 "III Driving Style Data Collection ‣ Driving Style Alignment
    for LLM-powered Driver Agent")). Demonstrations serve a dual purpose in alignment,
    being utilized by both the Driver Agent and the Coach Agent. For the Driver Agent,
    they serve as few-shot prompts, aiming to guide it towards making driving decisions
    similar in style. And for the Coach Agent, they are provided as ’Good’ examples,
    prompting it to make evaluations with driving style preferences, further generating
    guidelines that embody driving styles.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 演示涵盖了人类驾驶员的代表性决策过程，包括谨慎和冒险的驾驶示范。这些示范被收集并整理成驾驶员代理的记忆单元（更多细节见第[III](#S3 "III 驾驶风格数据收集
    ‣ 驾驶风格对齐")节）。演示在对齐中发挥了双重作用，既供驾驶员代理使用，也供教练代理使用。对于驾驶员代理，它们作为少量示例提示，旨在引导其做出风格相似的驾驶决策。而对于教练代理，它们作为‘好’示例，促使其进行带有驾驶风格偏好的评估，进一步生成体现驾驶风格的指导方针。
- en: To implement feedback, a Coach Agent was established, outfitted with a Guidelines
    module that compiles driving suggestions gleaned from continuous evaluations.
    It scrutinizes the current short-term memory of the Driver Agent and issues a
    judgment of ’Good’ or ’Bad’, along with the reason for this judgement. The criteria
    for evaluation include whether the decisions in the short-memory align with common
    driving sense, conform to the requirements proposed in the Guidelines, and match
    the style of the provided ’Good’ examples. Should an evaluation yield a ’Bad’
    rating, the Coach Agent formulates a new guideline addressing the suboptimal driving
    decision. This new guideline is then assimilated into the existing Guidelines
    repository.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实施反馈，建立了一个教练代理，并配备了一个汇总了持续评估所获得驾驶建议的指导模块。它审查驾驶员代理当前的短期记忆，并给出‘好’或‘差’的判断，以及这一判断的理由。评估标准包括短期记忆中的决策是否符合常规驾驶常识、是否符合指导模块中的要求，并且是否与提供的‘好’示例的风格匹配。如果评估结果为‘差’，教练代理会制定一个新的指导方针，解决不佳的驾驶决策。这个新的指导方针会被纳入现有的指导方针库中。
- en: III Driving Style Data Collection
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III 驾驶风格数据收集
- en: III-A Natural Driving Experiment and Post-driving Interview
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-A 自然驾驶实验与后驾驶采访
- en: To gather authentic human driving behavior data for alignment, we conducted
    a natural driving experiment with human drivers followed by a post-experiment
    interview. A total of 24 drivers were invited to participate in our data collection
    experiment, covering different genders and age groups. Notably, in order to gather
    data on different driving styles, the participants also included both seasoned
    professional drivers and novice drivers with less driving experience.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 为了收集真实的人类驾驶行为数据进行对齐，我们进行了自然驾驶实验，并在实验后进行了采访。共有24名驾驶员被邀请参与我们的数据收集实验，涵盖不同的性别和年龄组。值得注意的是，为了收集不同的驾驶风格数据，参与者中还包括了经验丰富的职业司机和经验较少的新手司机。
- en: To delve deeply into specific driving behaviors, we initially had each driver
    perform an urban road driving task covering 13 driving conditions, with a total
    length of 5.7 kilometers. To faithfully recreate the entire driving process during
    the following post-experiment interview, we set up a roof-mounted 360-degree panoramic
    camera to record the environment around the vehicle during task execution, an
    in-car motion camera to capture the driver’s actions, as well as an eye tracker
    to record changes in the driver’s gaze. Additionally, real-time CAN-Bus data on
    the vehicle’s status were recorded, including speed, the throttle and brake percentage,
    and the turning of the steering wheel.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 为了*深入探讨*特定的驾驶行为，我们首先让每位驾驶员完成一个覆盖13种驾驶条件的城市道路驾驶任务，总长度为5.7公里。为了忠实地重现整个驾驶过程，在随后的实验后采访中，我们设置了一个车顶安装的360度全景摄像头记录车辆周围的环境，一个车内运动摄像头捕捉驾驶员的动作，以及一个眼动仪记录驾驶员视线的变化。此外，实时记录了车辆状态的CAN-Bus数据，包括速度、油门和刹车的百分比以及方向盘的转动情况。
- en: For safety reasons, drivers were not requested to verbalize their thought processes
    while performing driving tasks. Right after the natural driving experiment, drivers
    would participate in a detailed post-experiment interview, which typically lasted
    for 1.5-2 hours. During the interview, we used the collected videos to recreate
    the task situation just experienced by the driver. For each driving action (e.g.
    accelerating, lane changing or turning), drivers were asked to recall and describe
    the entire decision-making process, from evaluating the surrounding environment
    to executing the corresponding driving action. These interview data will assist
    in determining the driver’s driving style, and also serve as the source of Demonstrations
    in the Multi-alignment Framework.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 出于安全考虑，驾驶员在进行驾驶任务时不要求口头表达其思维过程。自然驾驶实验结束后，驾驶员会参加详细的后续访谈，访谈通常持续1.5-2小时。在访谈过程中，我们使用收集到的视频重现驾驶员刚刚经历的任务情境。对于每个驾驶动作（如加速、变道或转弯），驾驶员被要求回忆并描述整个决策过程，从评估周围环境到执行相应的驾驶动作。这些访谈数据将有助于确定驾驶员的驾驶风格，同时也作为多对齐框架中的演示源。
- en: III-B Driving Style Selection and Data Organization
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-B 驾驶风格选择与数据整理
- en: Having completed driving experiments and post-experiment interviews, our next
    task is to differentiate the drivers’ driving styles and organize the think-aloud
    data into demonstrations of different styles.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 完成驾驶实验和后续访谈后，我们的下一步任务是区分驾驶员的驾驶风格，并将思维过程数据整理为不同风格的演示。
- en: 'The differentiation of driving styles is based on subjective questionnaire
    results and objective driving records in driving tasks. We distributed a MDSI
    questionnaire[[32](#bib.bib32)] to each driver invited to participate in the experiment.
    The results indicated the presence of four driving styles among the 24 drivers:
    risky, high-velocity, patient, and careful. Notably, the risky style often coincided
    with the high-velocity style, while the patient style typically appeared alongside
    the careful style. Further analysis of the CAN-Bus data during driving tasks revealed
    that 3 drivers exhibited speeds and throttle percentages significantly above the
    average — specifically, the average speed of all drivers was 6.40 m/s and average
    throttle percentage was 23.09%, while average speed of these 3 drivers respectively
    reached speeds of 7.73 m/s (20.78% higher than average), 7.50 m/s (17.19% higher
    than average) and 7.41 m/s (15.78% higher than average), and average throttle
    percentages reached 29.09% (25.99% higher than average), 24.42% (5.76% higher
    than average) and 24.37% (5.54% higher than average) — aligning with their self-reported
    ’risky and high-velocity’ driving styles in the questionnaire. Conversely, 2 other
    drivers had lower metrics — with speeds of 5.15 m/s (19.53% lower than average)
    and 5.28 m/s (17.50% lower than average) respectively, and throttle percentage
    of 21.00% (9.05% lower than average) and 21.34% (7.58% lower than average) — aligning
    with their self-reported ’patient and careful’ driving styles in the questionnaire.
    Additionally, a few drivers who reported to have driving styles in the questionnaire
    did not show clear trends in either driving data or interview records.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 驾驶风格的区分基于主观问卷结果和客观驾驶记录。我们向每位受邀参加实验的驾驶员分发了 MDSI 问卷[[32](#bib.bib32)]。结果表明，在24名驾驶员中存在四种驾驶风格：冒险型、高速型、耐心型和谨慎型。值得注意的是，冒险型风格通常与高速型风格重合，而耐心型风格通常与谨慎型风格同时出现。对驾驶任务中
    CAN-Bus 数据的进一步分析显示，3名驾驶员的速度和油门百分比显著高于平均水平——具体来说，所有驾驶员的平均速度为6.40 m/s，平均油门百分比为23.09%，而这3名驾驶员的平均速度分别达到7.73
    m/s（比平均水平高出20.78%）、7.50 m/s（比平均水平高出17.19%）和7.41 m/s（比平均水平高出15.78%），油门百分比分别达到29.09%（比平均水平高出25.99%）、24.42%（比平均水平高出5.76%）和24.37%（比平均水平高出5.54%）——这些数据与他们在问卷中自报的‘冒险和高速’驾驶风格一致。相反，另外2名驾驶员的指标较低——速度分别为5.15
    m/s（比平均水平低19.53%）和5.28 m/s（比平均水平低17.50%），油门百分比分别为21.00%（比平均水平低9.05%）和21.34%（比平均水平低7.58%）——这些数据与他们在问卷中自报的‘耐心和谨慎’驾驶风格一致。此外，一些在问卷中报告有特定驾驶风格的驾驶员在驾驶数据或访谈记录中未显示出明显的趋势。
- en: 'Therefore, we identified two basic driving styles: ’risky’ and ’high-velocity’
    were merged into ’risky,’ while ’patient’ and ’careful’ were combined into ’cautious.’
    We reviewed the interview data of drivers with risky driving styles and those
    with cautious driving styles, selecting representative decision-making processes
    that exemplify each driving style. Then, we organized each process according to
    the decision sequence into the format of ’Situation’, ’Reasoning’ and ’Action’,
    forming the final Demonstrations for alignment with humans.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们确定了两种基本的驾驶风格：将’冒险’和’高速’合并为’冒险’，而’耐心’和’小心’合并为’谨慎’。我们审查了冒险驾驶风格和谨慎驾驶风格的司机的访谈数据，选择了代表性的决策过程来示范每种驾驶风格。然后，我们按照决策顺序将每个过程组织为’Situation’，’Reasoning’和’Action’的格式，形成最终的演示，以便与人类对齐。
- en: IV Experiment
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 实验
- en: 'In this section, we validated the proposed Multi-alignment Framework by exploring
    the following questions:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们通过探索以下问题验证了提出的多重对齐框架：
- en: •
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Can Driver Agents with different driving styles be constructed using human think-aloud
    data?
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 是否可以使用人类思维过程数据构建具有不同驾驶风格的驾驶代理？
- en: •
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Which alignment method can efficiently achieve human alignment of driving styles?
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 哪种对齐方法可以高效实现驾驶风格的人类对齐？
- en: To this end, we implemented the Multi-alignment Framework on CARLA—a high-fidelity
    traffic simulator. A simulation experiment was carried out under urban driving
    conditions, upon which we further conducted a user experiment to collect human
    evaluations of its performance.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们在CARLA——一个高保真度的交通模拟器上实施了多重对齐框架。我们在城市驾驶条件下进行了模拟实验，并进一步进行了用户实验，以收集对其性能的人类评价。
- en: IV-A Conditions
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A 条件
- en: '![Refer to caption](img/b3b17ff62b998d04a62d63d0fa610805.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/b3b17ff62b998d04a62d63d0fa610805.png)'
- en: 'Figure 2: Experiment conditions'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：实验条件
- en: 'The experiment adopts an approximate 3 × 3 with-in subject design with two
    main variables: Driving Style [cautious (C), risky (R)and not-aligned (N)] and
    Alignment Method [demonstrations (D), feedback (F)and multi-alignment (M)]. Fig.
    [2](#S4.F2 "Figure 2 ‣ IV-A Conditions ‣ IV Experiment ‣ Driving Style Alignment
    for LLM-powered Driver Agent") shows the general design of different conditions.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 实验采用了近似的3 × 3被试设计，有两个主要变量：驾驶风格 [谨慎（C），冒险（R）和未对齐（N）] 和对齐方法 [演示（D），反馈（F）和多重对齐（M）]。图
    [2](#S4.F2 "图 2 ‣ IV-A 条件 ‣ IV 实验 ‣ 驾驶风格对齐的LLM驱动代理") 显示了不同条件的一般设计。
- en: In terms of Driving Style, we compared the effects of using cautious driving
    demonstrations, risky driving demonstrations, and no demonstrations (i.e., not-aligned).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在驾驶风格方面，我们比较了使用谨慎驾驶演示、冒险驾驶演示和不提供演示（即未对齐）的效果。
- en: Alignment Method was organized in an ablation format, with conditions including
    demonstrations, feedback, and multi-alignment (i.e., the full alignment framework).
    The demonstrations condition involves Driver Agents provided with demonstrations,
    and the feedback condition involves Driver Agents without demonstrations and Coach
    Agents that were provided with demonstrations, while in the multi-alignment condition,
    both Driver Agent and Coach Agent were provided with demonstrations.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 对齐方法以消融格式组织，条件包括演示、反馈和多重对齐（即完整对齐框架）。演示条件涉及提供演示的驾驶代理，而反馈条件涉及没有演示的驾驶代理和提供演示的教练代理，而在多重对齐条件下，驾驶代理和教练代理都提供了演示。
- en: IV-B CARLA Simulation
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-B CARLA模拟
- en: IV-B1 Set-up
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B1 设置
- en: The simulation experiment setup involved a ThundeRobot Zero desktop computer
    as the hardware foundation. The simulation environment was built upon the CARLA
    simulator, specifically, version 0.9.14³³3[http://carla.org/2022/12/23/release-0.9.14/](http://carla.org/2022/12/23/release-0.9.14/)
    and operated on Python 3.7 with Unreal Engine 4⁴⁴4[https://docs.unrealengine.com/4.27/en-US/](https://docs.unrealengine.com/4.27/en-US/).
    We use the map Town10, a typical urban driving scene, with both the number of
    other vehicles and pedestrians in the scenario set to 60\. And Audi TT was the
    designated vehicle for all experiments, with fixed starting and continuously,
    randomly generated ending points for its path (After a vehicle is generated at
    a predefined fixed point, a random endpoint is generated. Upon reaching the endpoint,
    another endpoint is randomly generated, and so on.).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 模拟实验设置包括了一个ThundeRobot Zero桌面计算机作为硬件基础。模拟环境建立在CARLA模拟器上，具体为版本0.9.14³³3[http://carla.org/2022/12/23/release-0.9.14/](http://carla.org/2022/12/23/release-0.9.14/)
    并且在Python 3.7与Unreal Engine 4⁴⁴4[https://docs.unrealengine.com/4.27/en-US/](https://docs.unrealengine.com/4.27/en-US/)
    上运行。我们使用Town10地图，这是一个典型的城市驾驶场景，场景中的其他车辆和行人数量都设定为60。所有实验指定的车辆为Audi TT，路径有固定的起点和不断随机生成的终点（车辆在预定义的固定点生成后，会生成一个随机终点。到达终点后，再生成另一个随机终点，以此类推。）。
- en: We leverage OpenAI’s GPT-4⁵⁵5[https://openai.com/gpt-4](https://openai.com/gpt-4)
    APIs for constructing both the Driver Agent and the Coach Agent. However, it takes
    several seconds for GPT to generate a response, which is too long in a driving
    context for making immediate decisions. Therefore, we slowed down CARLA’s simulation
    time based on the required token count by setting a fixed time-step of 0.0008-0.0015
    seconds.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们利用了OpenAI的GPT-4⁵⁵5[https://openai.com/gpt-4](https://openai.com/gpt-4) API
    来构建Driver Agent和Coach Agent。然而，GPT生成响应需要几秒钟，这在驾驶情境下对于做出即时决策来说时间太长。因此，我们基于所需的令牌数量将CARLA的模拟时间减慢，设置了固定的时间步长为0.0008-0.0015秒。
- en: Each simulation process is recorded on video. Additionally, to collect vehicle
    status information during the simulation, we initiated a log-collector thread
    to accumulate log on collisions, speed, throttle percentage, and brake percentage
    from the agent vehicle on a second-by-second basis.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 每个模拟过程都被录制为视频。此外，为了在模拟过程中收集车辆状态信息，我们启动了一个日志收集线程，以每秒钟为单位积累来自代理车辆的碰撞、速度、油门百分比和刹车百分比的日志。
- en: IV-B2 Metrics
  id: totrans-62
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B2 指标
- en: 'Here, we introduce three metrics to evaluate the driving performance of the
    Driver Agent: collision rate, speed, throttle percentage, and brake percentage.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们介绍了三个指标来评估Driver Agent的驾驶表现：碰撞率、速度、油门百分比和刹车百分比。
- en: •
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Collision rate: The number of collisions can be obtained from the log, with
    distance traveled being cumulative up to the last collision. The calculating formula
    is $1$2'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 碰撞率：碰撞次数可以从日志中获得，行驶距离是累积到最后一次碰撞的。计算公式是 $1$2
- en: •
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Speed: The statistical measures for speed include the average speed of the
    agent vehicle during each simulation and the segmented average speed per minute
    (simulator time). All calculations of average speed exclude zero values to minimize
    the impact of the agent vehicle waiting at traffic signals and in traffic jams.'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 速度：速度的统计指标包括每次模拟期间代理车辆的平均速度和每分钟（模拟时间）的分段平均速度。所有平均速度计算均不包括零值，以减少代理车辆在交通信号灯和交通拥堵中等待的影响。
- en: •
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Throttle percentage & brake percentage: The statistics for throttle and brake
    percentages are also divided into overall average values and segmented average
    values per minute. Similarly, all calculations exclude data from when the agent
    vehicle is stationary.'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 油门百分比 & 刹车百分比：油门和刹车百分比的统计也分为整体平均值和每分钟的分段平均值。类似地，所有计算均不包括代理车辆静止时的数据。
- en: IV-B3 Results
  id: totrans-70
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B3 结果
- en: '![Refer to caption](img/52b42b10ae333ff6242b5f16f4cb1e9c.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/52b42b10ae333ff6242b5f16f4cb1e9c.png)'
- en: (a) Collision rates per meter (with increased incidences of abrupt maneuvers
    by surrounding vehicles and pedestrians).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 每米碰撞率（周围车辆和行人突然动作增加的情况下）。
- en: '![Refer to caption](img/47e235384fcae6e8ede37f9bb6721039.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/47e235384fcae6e8ede37f9bb6721039.png)'
- en: (b) Average throttle percentage (left), brake percentage (middle), and speed
    (right) of the agent vehicle, with all calculations excluding data from when the
    agent vehicle was stationary (the speed limit is km/h).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 代理车辆的平均油门百分比（左），刹车百分比（中），和速度（右），所有计算均不包括代理车辆静止时的数据（速度限制为km/h）。
- en: 'Figure 3: Simulation experiment results for predefined metrics.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：预定义指标的仿真实验结果。
- en: We conducted approximately 50.3 hours of simulation experiments under various
    conditions, which corresponds to an average of about 6.7 minutes of driving per
    condition for the agent vehicle on the simulation platform. The average distance
    the agent vehicle traveled per condition was approximately 1.5 kilometers. Notably,
    we adjusted the algorithms controlling other vehicles and pedestrians to make
    them more prone to sudden maneuvers (e.g. abrupt lane changes, running red lights).
    These edge cases aim to increase the risk level of the driving environment for
    the agent vehicle, making its driving style more observable.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在各种条件下进行了大约 50.3 小时的仿真实验，相当于每种条件下代理车辆在仿真平台上的平均驾驶时间约为 6.7 分钟。代理车辆在每种条件下行驶的平均距离约为
    1.5 公里。值得注意的是，我们调整了控制其他车辆和行人的算法，使其更容易发生突然的操作（例如急剧变道、闯红灯）。这些极端情况旨在提高代理车辆的驾驶环境的风险水平，使其驾驶风格更具可观察性。
- en: Fig. [3(a)](#S4.F3.sf1 "In Figure 3 ‣ IV-B3 Results ‣ IV-B CARLA Simulation
    ‣ IV Experiment ‣ Driving Style Alignment for LLM-powered Driver Agent") displays
    the collision rates per meter for the agent vehicle calculated under different
    conditions. Agents aligned with the risky driving style overall exhibit higher
    collision rates, while those aligned with the cautious driving style show lower
    collision rates overall. Additionally, when aligned with cautious driving style,
    the multi-alignment method displayed the lowest collision rate while the demonstrations method
    displayed the highest, and when aligned with risky driving style, the multi-alignment method
    showed the highest collision rate while the demonstrations method displayed the
    highest. When not-aligned, the collision rate for the demonstrations method is
    higher than that for the feedback method.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [3(a)](#S4.F3.sf1 "图 3 ‣ IV-B3 结果 ‣ IV-B CARLA 仿真 ‣ IV 实验 ‣ LLM 驱动代理的驾驶风格对齐")
    显示了在不同条件下计算的代理车辆每米碰撞率。总体来看，符合风险驾驶风格的代理显示出更高的碰撞率，而符合谨慎驾驶风格的代理则显示出更低的碰撞率。此外，符合谨慎驾驶风格时，多重对齐方法显示出最低的碰撞率，而演示方法显示出最高的碰撞率；符合风险驾驶风格时，多重对齐方法显示出最高的碰撞率，而演示方法也显示出最高的碰撞率。在未对齐时，演示方法的碰撞率高于反馈方法。
- en: Fig. [3(b)](#S4.F3.sf2 "In Figure 3 ‣ IV-B3 Results ‣ IV-B CARLA Simulation
    ‣ IV Experiment ‣ Driving Style Alignment for LLM-powered Driver Agent") presents
    the average throttle percentage, brake percentage, and speed of the agent vehicle
    during the driving process under different conditions, with all calculations excluding
    data from when the agent vehicle was stationary. When using the same alignment
    method, agents aligned with the risky driving style had the highest average speed,
    highest throttle percentage, and lowest brake percentage, while agents aligned
    with the cautious driving style had the lowest speed, lowest throttle percentage,
    and highest brake percentage. When aligned with the cautious driving style, the
    average speed and throttle percentage decrease while the average brake percentage
    increases across the demonstrations, feedback, and multi-alignment, in that order.
    The opposite trend is observed when aligning with the risky driving style. When
    not-aligned, the average speed and throttle percentage for the demonstrations method
    are higher than those for the feedback method, while the average brake percentage
    is lower.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [3(b)](#S4.F3.sf2 "图 3 ‣ IV-B3 结果 ‣ IV-B CARLA 仿真 ‣ IV 实验 ‣ LLM 驱动代理的驾驶风格对齐")
    展示了在不同条件下，代理车辆在驾驶过程中平均油门百分比、刹车百分比和速度的情况，所有计算均不包括代理车辆静止时的数据。在使用相同对齐方法时，符合风险驾驶风格的代理具有最高的平均速度、最高的油门百分比和最低的刹车百分比，而符合谨慎驾驶风格的代理则具有最低的速度、最低的油门百分比和最高的刹车百分比。在谨慎驾驶风格对齐时，演示、反馈和多重对齐中平均速度和油门百分比依次减少，而平均刹车百分比则增加。与风险驾驶风格对齐时则观察到相反的趋势。在未对齐时，演示方法的平均速度和油门百分比高于反馈方法，而平均刹车百分比则较低。
- en: IV-B4 Findings
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B4 发现
- en: Based on the hypothesis that agents with more cautious driving styles are safer,
    agents can exhibit corresponding driving styles by aligning with different driving
    styles. multi-alignment was the most effective method, displaying the most significant
    differences in collision rates, average throttle, brake, and speed between cautious
    and risky driving styles, while demonstrations were less effective.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 基于“更谨慎的驾驶风格更安全”的假设，代理可以通过与不同的驾驶风格对齐来展示相应的驾驶风格。多重对齐 是最有效的方法，表现出谨慎和冒险驾驶风格之间在碰撞率、平均油门、刹车和速度方面的显著差异，而演示 则效果较差。
- en: IV-C Human Evaluation
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-C 人工评估
- en: IV-C1 Procedure
  id: totrans-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C1 程序
- en: We designed two survey questionnaires to collect human drivers’ evaluations
    of the Driver Agent’s performance, which was presented to participants in the
    questionnaire through video clips of the simulation, with about 30 seconds of
    driving footage captured for each experimental condition.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设计了两个调查问卷来收集人类驾驶员对驾驶代理表现的评价，这些评价通过模拟视频片段呈现给参与者，每个实验条件下捕捉了大约30秒的驾驶视频。
- en: In Part I of the first questionnaire, we initially collected basic information
    (e.g. age, gender, whether holding a driving license) from participants. A partial
    MDSI self-assessment was also included, with items covering indicators of risky
    and careful driving styles from the MDSI.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个问卷的第一部分，我们最初收集了参与者的基本信息（如年龄、性别、是否持有驾驶执照）。还包括了部分MDSI自我评估，项目涵盖了MDSI中风险和谨慎驾驶风格的指标。
- en: 'In Part II, the video clips are divided into four groups:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二部分中，视频片段被分为四组：
- en: •
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Demonstrations Group: {demonstrations cautious (DC), demonstrations not-aligned (DN),
    demonstrations risky (DR)}'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 演示组：{演示 谨慎 (DC)、演示 不对齐 (DN)、演示 冒险 (DR)}
- en: •
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Feedback Group: {feedback cautious (FC), feedback not-aligned (FN), feedback risky (FR),
    demonstrations not-aligned (DN, serving as baseline in this group)}'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 反馈组：{反馈 谨慎 (FC)、反馈 不对齐 (FN)、反馈 冒险 (FR)、演示 不对齐 (DN，作为该组的基线)}
- en: •
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Cautious Group: {demonstrations cautious (DC), feedback cautious (FC), multi-alignment cautious (MC)}'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 谨慎组：{演示 谨慎 (DC)、反馈 谨慎 (FC)、多重对齐 谨慎 (MC)}
- en: •
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Risky Group: {demonstrations risky (DR), feedback risky (FR), multi-alignment risky (MR)}'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 冒险组：{演示 冒险 (DR)、反馈 冒险 (FR)、多重对齐 冒险 (MR)}
- en: Each group of video clips will appear in a random order, accompanied by a ranking
    question requiring participants to rank the driving styles in the videos according
    to their level of riskiness (a smaller number indicates more risky) and a reason
    question for explaining their rankings.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 每组视频片段将以随机顺序出现，并附有一个排名问题，要求参与者根据视频中的驾驶风格的风险程度对其进行排名（数字越小表示风险越大），以及一个解释排名的理由问题。
- en: Parts I of the second questionnaire are identical to the first questionnaire.
    In Part II, participants were instructed to watch all of the eight videos clips,
    which were also organized in a random order, with three scoring questions respectively
    investigated the intelligence level, riskiness level and human-likeness level
    of the agent vehicle (all from 0 to 10) and a reason question attached below each
    clip.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个问卷的第一部分与第一个问卷相同。在第二部分中，参与者被要求观看所有八个视频片段，这些片段也以随机顺序组织，三个评分问题分别调查了代理车辆的智能水平、风险水平和人类相似度水平（均为0到10），每个片段下方附有一个理由问题。
- en: Additionally, to filter out carelessly completed questionnaires, we set a minimum
    answering time and included trap questions in the questionnaire, which required
    participants to select a certain option.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，为了筛选出粗心填写的问卷，我们设置了最低回答时间，并在问卷中加入了陷阱问题，要求参与者选择特定的选项。
- en: IV-C2 Participants
  id: totrans-97
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C2 参与者
- en: We recruited over 200 participants through a third-party recruitment channel
    provided by the survey platform, offering a compensation of approximately $2.08
    per valid questionnaire completed. Additionally, our team of five researchers
    also shared our questionnaires on social media platforms, recruiting over 60 participants.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过调查平台提供的第三方招聘渠道招募了200多名参与者，为每份有效填写的问卷提供了大约$2.08的补偿。此外，我们的五名研究人员还在社交媒体平台上分享了问卷，招募了60多名参与者。
- en: All 270 participants verified in the questionnaire that they possess a driving
    license. Among them, there were 141 male participants, accounting for 52.22%,
    and 129 female participants, accounting for 47.78%, with ages ranging from 19
    to 54 years old.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 所有270名参与者在问卷中确认他们持有驾驶执照。其中，男性参与者141人，占52.22%，女性参与者129人，占47.78%，年龄范围从19岁到54岁。
- en: IV-C3 Data Analysis
  id: totrans-100
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C3 数据分析
- en: For both questionnaires, we first categorized participants’ driving styles based
    on the results from Section I. The formula for calculating the driving style score
    is $S_{driving\ style}=\Sigma o_{risky}-\Sigma o_{cautious}$ represents the option
    for each cautious indicator (with two negative indicators within, where options
    are included as negative values). The higher the driving style score, the more
    a participant’s driving style tends towards being risky.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 对于两份问卷，我们首先根据第一部分的结果对参与者的驾驶风格进行了分类。计算驾驶风格评分的公式为 $S_{driving\ style}=\Sigma o_{risky}-\Sigma
    o_{cautious}$，表示每个谨慎指标的选项（其中包含两个负面指标，选项以负值计）。驾驶风格评分越高，参与者的驾驶风格越倾向于风险。
- en: For Part II of the first questionnaire, we calculated the rankings obtained
    by different video clips in the ranking question following each group of video
    clips, as well as the statistical significance between their rankings.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一份问卷的第二部分，我们计算了每组视频片段后的排名问题所获得的排名，以及它们之间的统计显著性。
- en: For Part II of the second questionnaire, we separately tallied the results of
    the three scoring questions after each video clip, representing the agent vehicle’s
    intelligence, riskiness, and human-likeness.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二份问卷的第二部分，我们分别统计了每个视频片段后的三项评分问题的结果，代表代理车辆的智能、风险性和类人性。
- en: Additionally, we scrutinized all the answers to the reasoning questions in both
    questionnaires, summarizing supports for judging the driving behaviors of the
    agent vehicles.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们仔细审查了两份问卷中的所有推理问题的回答，总结了判断代理车辆驾驶行为的支持依据。
- en: IV-C4 Results
  id: totrans-105
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C4 结果
- en: '![Refer to caption](img/608a4cefdc2862f11df7c93b2ff524f8.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/608a4cefdc2862f11df7c93b2ff524f8.png)'
- en: '(a) Frequency of riskiness rankings in different groups: demonstrations with
    different driving styles (left), feedback with different driving styles (middle-left),
    cautious driving style under different alignment methods (middle-right), and risky
    driving style under different alignment methods (right). Higher rankings indicate
    higher riskiness.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 不同组别的风险性排名频率：不同驾驶风格的演示（左）、不同驾驶风格的反馈（中左）、不同对齐方法下的谨慎驾驶风格（中右）、以及不同对齐方法下的风险驾驶风格（右）。排名越高，风险性越大。
- en: '![Refer to caption](img/476435b8c1d24c118898b6e2512adc4b.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/476435b8c1d24c118898b6e2512adc4b.png)'
- en: (b) Pearson correlation and significance of scores for agent vehicle’s riskiness
    (R), human-likeness (H), and intelligence (I).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 皮尔逊相关系数及代理车辆在风险性（R）、类人性（H）和智能（I）评分的显著性。
- en: 'Figure 4: Human evaluation results.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：人工评估结果。
- en: We distributed two questionnaires for 3 days and received a total of 259 valid
    responses after screening, with 198 for the first questionnaire and 59 for the
    second. The driving style statistics in part I are highly diverse. With an average
    score of 0.61, 34 participants scores below -4 (suggesting a cautious driving
    style), while 37 participants scores over 5 (suggesting a risky driving style),
    indicating good representativeness of our results.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们分发了两份问卷，持续了3天，筛选后共收到259份有效回复，其中第一份问卷198份，第二份问卷59份。第一部分的驾驶风格统计数据高度多样化。平均分为0.61，其中34名参与者的得分低于-4（表明谨慎驾驶风格），而37名参与者的得分高于5（表明风险驾驶风格），显示了我们结果的良好代表性。
- en: Fig. [4(a)](#S4.F4.sf1 "In Figure 4 ‣ IV-C4 Results ‣ IV-C Human Evaluation
    ‣ IV Experiment ‣ Driving Style Alignment for LLM-powered Driver Agent") shows
    the rankings of riskiness for different video clips in each group from the first
    questionnaire, with higher rankings indicating higher riskiness.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [4(a)](#S4.F4.sf1 "在图4 ‣ IV-C4 结果 ‣ IV-C 人工评估 ‣ IV 实验 ‣ 驾驶风格对齐用于LLM驱动代理")
    显示了第一份问卷中每组不同视频片段的风险性排名，排名越高，风险性越大。
- en: In both the demonstrations and feedback groups, the rankings for DC and FC were
    significantly lower than those for other videos in the same group, indicating
    that they were perceived as the least risky. One participant explained choosing
    DC as the least risky in the Demonstration Group, noting, ”The car ran stably
    without veering left or right.” Another participant cited their reasoning for
    deeming FC the least risky in the Feedback Group, stating, ”It waits for the pedestrian
    ahead to pass by.”
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在演示和反馈组中，DC和FC的排名显著低于同组其他视频，表明它们被认为是风险最低的。一位参与者解释了在演示组中选择DC为风险最低的原因，称“汽车稳定运行，没有左右偏离。”另一位参与者在反馈组中将FC认为是风险最低的理由是，“它等待前面的行人通过。”
- en: When not-aligned, the riskiness of FN decreases compared to DN, with multiple
    participants noting DN’s ”Decelerate too slowly when approaching a pedestrian
    crossing.” However, DN shows no significant difference when compared to either
    DR or FR, because they ”all look very risky”
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 当不对齐时，FN的风险性低于DN，多个参与者指出DN的“在接近行人过路点时减速过慢。”然而，与DR或FR相比，DN没有显著差异，因为它们“看起来都非常有风险。”
- en: In the cautious group, the ranking of riskiness goes significantly as DC  MC, indicating that
    multi-alignment has the best alignment effect, with demonstrations being the least
    effective. The majority of participants attributed the rankings to ”Driver x (DC)
    performs lane changes a bit too quickly, whereas driver y (MC) not only waits
    for pedestrians but also yields to other vehicles.”
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在谨慎组中，风险排名显著为DC 
    MC，这表明多重对齐具有最佳的对齐效果，而演示效果最差。大多数参与者将排名归因于“驾驶员x（DC）变道稍微太快，而驾驶员y（MC）不仅等待行人，还给其他车辆让路。”
- en: Similarly, the demonstrations method also showed the poorest alignment effect
    in the risky group, with MR slightly better than FR but not significant.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，演示方法在风险组中也显示出最差的对齐效果，MR略好于FR但不显著。
- en: Fig. [4(b)](#S4.F4.sf2 "In Figure 4 ‣ IV-C4 Results ‣ IV-C Human Evaluation
    ‣ IV Experiment ‣ Driving Style Alignment for LLM-powered Driver Agent") presents
    the results of the correlation analysis among participants’ scores for riskiness,
    human-likeness, and intelligence for the same video clip in the second questionnaire.
    It can be observed that humans tend to associate higher riskiness with lower intelligence,
    and higher intelligence with greater human-likeness. Interestingly, despite cautious
    driving being safer, humans still tend to associate higher riskiness with greater
    human-likeness. One participant remarked, ”It (MR) is really like an experienced
    driver who is showing off his driving skills.”
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图[4(b)](#S4.F4.sf2 "在图4 ‣ IV-C4 结果 ‣ IV-C 人类评估 ‣ IV 实验 ‣ LLM驱动代理人的驾驶风格对齐")展示了参与者对同一视频片段在第二次问卷中的风险性、人类特征和智能评分的相关性分析结果。可以观察到，人们倾向于将更高的风险性与更低的智能相关联，将更高的智能与更高的人类特征相关联。有趣的是，尽管谨慎驾驶更安全，人们仍然倾向于将更高的风险性与更高的人类特征相关联。一位参与者评论说，“它（MR）确实像一个经验丰富的司机在炫耀他的驾驶技能。”
- en: IV-C5 Findings
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C5 发现
- en: The human evaluation results indicated a clear distinction in perceived riskiness
    between different driving styles. Agents aligned with cautious driving were consistently
    rated as less risky, particularly under the multi-alignment condition, which was
    proven to be the most effective for aligning driving styles. Demonstrations alone
    showed the least effectiveness in both cautious and risky conditions. Additionally,
    there is an interesting psychological insight that despite associating cautious
    driving with safety, participants tended to equate higher cautiousness with less
    human-likeness, reflecting a complex perception of human driving behavior.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 人类评估结果表明，不同驾驶风格之间在感知风险性方面有明显区别。与谨慎驾驶对齐的代理人被一致评为风险较低，特别是在多重对齐条件下，这被证明是对齐驾驶风格的最有效方式。仅靠演示在谨慎和风险条件下的效果最差。此外，尽管将谨慎驾驶与安全关联起来，参与者往往将更高的谨慎程度等同于更少的人类特征，这反映了对人类驾驶行为的复杂感知。
- en: V CONCLUSIONS
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V 结论
- en: This paper presents a novel multi-alignment framework for aligning LLM-powered
    Driver Agents with human driving styles. Through a comprehensive set of experiments
    and evaluations, we successfully demonstrate that Driver Agents can be tailored
    to exhibit distinct driving styles—risky and cautious—by leveraging human driving
    data as chain-of-thought prompts. The framework’s effectiveness is validated through
    simulation experiments in the CARLA urban traffic simulator and further corroborated
    by human evaluations.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提出了一种新颖的多重对齐框架，用于将 LLM 驱动的驾驶代理与人类驾驶风格对齐。通过一套全面的实验和评估，我们成功展示了通过利用人类驾驶数据作为思维链提示，驾驶代理可以被调整以展现出不同的驾驶风格——冒险和谨慎。通过
    CARLA 城市交通模拟器的仿真实验验证了该框架的有效性，并通过人类评估进一步证实。
- en: By illustrating the potential of LLMs in achieving nuanced human-agent alignment,
    this work opens new avenues for research into autonomous driving technologies
    that cater to individual preferences. By encoding the intricacies of human driving
    behaviors in a format accessible to language models, this work paves the way for
    more intuitive and effective human-agent alignment across a broad spectrum of
    applications beyond autonomous driving. Additionally, the insights into human
    perceptions of riskiness and human-likeness in driving styles underscore the complexity
    of aligning autonomous agents with human expectations and behaviors, highlighting
    the importance of further interdisciplinary research in this area.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 通过展示大型语言模型在实现细致的人机对齐中的潜力，本研究为符合个人偏好的自动驾驶技术开辟了新的研究方向。通过将人类驾驶行为的复杂性编码成语言模型可接触的格式，本研究为更直观有效的人机对齐铺平了道路，适用于除自动驾驶之外的广泛应用。此外，对人类对风险性和驾驶风格的类人性的感知的洞察突显了使自动驾驶代理与人类期望和行为对齐的复杂性，强调了在这一领域进一步跨学科研究的重要性。
- en: References
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] C. H. Song, J. Wu, C. Washington, B. M. Sadler, W.-L. Chao, and Y. Su,
    “Llm-planner: Few-shot grounded planning for embodied agents with large language
    models,” in *Proceedings of the IEEE/CVF International Conference on Computer
    Vision*, 2023, pp. 2998–3009.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] C. H. Song, J. Wu, C. Washington, B. M. Sadler, W.-L. Chao, 和 Y. Su, “llm-planner：具有大型语言模型的具身体代理的少样本基础规划，”
    收录于 *IEEE/CVF 国际计算机视觉大会论文集*，2023，第 2998–3009 页。'
- en: '[2] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D. Zhou,
    *et al.*, “Chain-of-thought prompting elicits reasoning in large language models,”
    *Advances in Neural Information Processing Systems*, vol. 35, pp. 24 824–24 837,
    2022.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D. Zhou,
    *et al.*, “思维链提示引发大型语言模型的推理，” *神经信息处理系统进展*，第 35 卷，第 24 824–24 837 页，2022。'
- en: '[3] X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi, S. Narang, A. Chowdhery,
    and D. Zhou, “Self-consistency improves chain of thought reasoning in language
    models,” *arXiv preprint arXiv:2203.11171*, 2022.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi, S. Narang, A. Chowdhery,
    和 D. Zhou, “自一致性提升语言模型的思维链推理，” *arXiv 预印本 arXiv:2203.11171*，2022。'
- en: '[4] S. Yao, D. Yu, J. Zhao, I. Shafran, T. L. Griffiths, Y. Cao, and K. Narasimhan,
    “Tree of thoughts: Deliberate problem solving with large language models,” *arXiv
    preprint arXiv:2305.10601*, 2023.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] S. Yao, D. Yu, J. Zhao, I. Shafran, T. L. Griffiths, Y. Cao, 和 K. Narasimhan,
    “思想树：使用大型语言模型进行深思熟虑的问题解决，” *arXiv 预印本 arXiv:2305.10601*，2023。'
- en: '[5] L. Chen, O. Sinavski, J. Hünermann, A. Karnsund, A. J. Willmott, D. Birch,
    D. Maund, and J. Shotton, “Driving with llms: Fusing object-level vector modality
    for explainable autonomous driving,” *arXiv preprint arXiv:2310.01957*, 2023.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] L. Chen, O. Sinavski, J. Hünermann, A. Karnsund, A. J. Willmott, D. Birch,
    D. Maund, 和 J. Shotton, “使用 llms 驾驶：融合对象级向量模态以实现可解释的自动驾驶，” *arXiv 预印本 arXiv:2310.01957*，2023。'
- en: '[6] Z. Xu, Y. Zhang, E. Xie, Z. Zhao, Y. Guo, K. K. Wong, Z. Li, and H. Zhao,
    “Drivegpt4: Interpretable end-to-end autonomous driving via large language model,”
    *arXiv preprint arXiv:2310.01412*, 2023.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Z. Xu, Y. Zhang, E. Xie, Z. Zhao, Y. Guo, K. K. Wong, Z. Li, 和 H. Zhao,
    “Drivegpt4：通过大型语言模型进行可解释的端到端自动驾驶，” *arXiv 预印本 arXiv:2310.01412*，2023。'
- en: '[7] A. Hu, L. Russell, H. Yeo, Z. Murez, G. Fedoseev, A. Kendall, J. Shotton,
    and G. Corrado, “Gaia-1: A generative world model for autonomous driving,” *arXiv
    preprint arXiv:2309.17080*, 2023.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] A. Hu, L. Russell, H. Yeo, Z. Murez, G. Fedoseev, A. Kendall, J. Shotton,
    和 G. Corrado, “Gaia-1：一种用于自动驾驶的生成世界模型，” *arXiv 预印本 arXiv:2309.17080*，2023。'
- en: '[8] H. Shao, Y. Hu, L. Wang, S. L. Waslander, Y. Liu, and H. Li, “Lmdrive:
    Closed-loop end-to-end driving with large language models,” 2023.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] H. Shao, Y. Hu, L. Wang, S. L. Waslander, Y. Liu, 和 H. Li, “Lmdrive：使用大型语言模型的闭环端到端驾驶，”
    2023。'
- en: '[9] C. Cui, Y. Ma, X. Cao, W. Ye, and Z. Wang, “Drive as you speak: Enabling
    human-like interaction with large language models in autonomous vehicles,” in
    *Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision*,
    2024, pp. 902–909.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] C. Cui, Y. Ma, X. Cao, W. Ye, 和 Z. Wang, “驾驶如你所说: 在自动驾驶汽车中实现类人互动,” 收录于
    *IEEE/CVF 冬季计算机视觉应用会议论文集*, 2024, 页 902–909。'
- en: '[10] L. Wen, D. Fu, X. Li, X. Cai, T. Ma, P. Cai, M. Dou, B. Shi, L. He, and
    Y. Qiao, “Dilu: A knowledge-driven approach to autonomous driving with large language
    models,” *arXiv preprint arXiv:2309.16292*, 2023.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] L. Wen, D. Fu, X. Li, X. Cai, T. Ma, P. Cai, M. Dou, B. Shi, L. He, 和
    Y. Qiao, “Dilu: 一种基于知识的大语言模型自主驾驶方法,” *arXiv 预印本 arXiv:2309.16292*, 2023。'
- en: '[11] W. Wang, J. Xie, C. Hu, H. Zou, J. Fan, W. Tong, Y. Wen, S. Wu, H. Deng,
    Z. Li, H. Tian, L. Lu, X. Zhu, X. Wang, Y. Qiao, and J. Dai, “Drivemlm: Aligning
    multi-modal large language models with behavioral planning states for autonomous
    driving,” 2023.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] W. Wang, J. Xie, C. Hu, H. Zou, J. Fan, W. Tong, Y. Wen, S. Wu, H. Deng,
    Z. Li, H. Tian, L. Lu, X. Zhu, X. Wang, Y. Qiao, 和 J. Dai, “Drivemlm: 使多模态大语言模型与行为规划状态对齐以实现自主驾驶,”
    2023。'
- en: '[12] S. Kolekar, J. de Winter, and D. Abbink, “Human-like driving behaviour
    emerges from a risk-based driver model,” *Nature communications*, vol. 11, no. 1,
    p. 4850, 2020.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] S. Kolekar, J. de Winter, 和 D. Abbink, “基于风险的驾驶模型中出现类人驾驶行为,” *自然通讯*, 卷
    11, 期 1, 页 4850, 2020。'
- en: '[13] Y. Jin, X. Shen, H. Peng, X. Liu, J. Qin, J. Li, J. Xie, P. Gao, G. Zhou,
    and J. Gong, “Surrealdriver: Designing generative driver agent simulation framework
    in urban contexts based on large language model,” *arXiv preprint arXiv:2309.13193*,
    2023.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Y. Jin, X. Shen, H. Peng, X. Liu, J. Qin, J. Li, J. Xie, P. Gao, G. Zhou,
    和 J. Gong, “Surrealdriver: 基于大语言模型设计的城市环境生成型驾驶代理模拟框架,” *arXiv 预印本 arXiv:2309.13193*,
    2023。'
- en: '[14] S. Hecker, D. Dai, and L. Van Gool, “Learning accurate, comfortable and
    human-like driving,” *arXiv preprint arXiv:1903.10995*, 2019.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] S. Hecker, D. Dai, 和 L. Van Gool, “学习准确、舒适且类人驾驶,” *arXiv 预印本 arXiv:1903.10995*,
    2019。'
- en: '[15] A. Waytz, J. Heafner, and N. Epley, “The mind in the machine: Anthropomorphism
    increases trust in an autonomous vehicle,” *Journal of experimental social psychology*,
    vol. 52, pp. 113–117, 2014.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] A. Waytz, J. Heafner, 和 N. Epley, “机器中的思维: 拟人化增加对自动驾驶汽车的信任,” *实验社会心理学杂志*,
    卷 52, 页 113–117, 2014。'
- en: '[16] J. Mao, Y. Qian, H. Zhao, and Y. Wang, “Gpt-driver: Learning to drive
    with gpt,” *arXiv preprint arXiv:2310.01415*, 2023.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] J. Mao, Y. Qian, H. Zhao, 和 Y. Wang, “Gpt-driver: 用 GPT 学习驾驶,” *arXiv
    预印本 arXiv:2310.01415*, 2023。'
- en: '[17] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wainwright, P. Mishkin,
    C. Zhang, S. Agarwal, K. Slama, A. Ray, *et al.*, “Training language models to
    follow instructions with human feedback, 2022,” *URL https://arxiv. org/abs/2203.02155*,
    vol. 13, p. 1, 2022.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wainwright, P. Mishkin,
    C. Zhang, S. Agarwal, K. Slama, A. Ray, *等*, “训练语言模型以按照人类反馈执行指令, 2022,” *URL https://arxiv.
    org/abs/2203.02155*, 卷 13, 页 1, 2022。'
- en: '[18] D. Fu, X. Li, L. Wen, M. Dou, P. Cai, B. Shi, and Y. Qiao, “Drive like
    a human: Rethinking autonomous driving with large language models,” in *Proceedings
    of the IEEE/CVF Winter Conference on Applications of Computer Vision*, 2024, pp.
    910–919.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] D. Fu, X. Li, L. Wen, M. Dou, P. Cai, B. Shi, 和 Y. Qiao, “像人一样驾驶: 重新思考使用大语言模型的自主驾驶,”
    收录于 *IEEE/CVF 冬季计算机视觉应用会议论文集*, 2024, 页 910–919。'
- en: '[19] A. Zhao, D. Huang, Q. Xu, M. Lin, Y.-J. Liu, and G. Huang, “Expel: Llm
    agents are experiential learners,” *arXiv preprint arXiv:2308.10144*, 2023.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] A. Zhao, D. Huang, Q. Xu, M. Lin, Y.-J. Liu, 和 G. Huang, “Expel: LLM 代理是经验学习者,”
    *arXiv 预印本 arXiv:2308.10144*, 2023。'
- en: '[20] N. Shinn, F. Cassano, A. Gopinath, K. Narasimhan, and S. Yao, “Reflexion:
    Language agents with verbal reinforcement learning,” *Advances in Neural Information
    Processing Systems*, vol. 36, 2024.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] N. Shinn, F. Cassano, A. Gopinath, K. Narasimhan, 和 S. Yao, “Reflexion:
    带有语言强化学习的代理,” *神经信息处理系统进展*, 卷 36, 2024。'
- en: '[21] W. Yao, S. Heinecke, J. C. Niebles, Z. Liu, Y. Feng, L. Xue, R. Murthy,
    Z. Chen, J. Zhang, D. Arpit, *et al.*, “Retroformer: Retrospective large language
    agents with policy gradient optimization,” *arXiv preprint arXiv:2308.02151*,
    2023.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] W. Yao, S. Heinecke, J. C. Niebles, Z. Liu, Y. Feng, L. Xue, R. Murthy,
    Z. Chen, J. Zhang, D. Arpit, *等*, “Retroformer: 使用策略梯度优化的回顾性大语言代理,” *arXiv 预印本
    arXiv:2308.02151*, 2023。'
- en: '[22] Z. Yang, P. Li, and Y. Liu, “Failures pave the way: Enhancing large language
    models through tuning-free rule accumulation,” *arXiv preprint arXiv:2310.15746*,
    2023.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Z. Yang, P. Li, 和 Y. Liu, “失败铺平道路: 通过无调优规则积累提升大语言模型,” *arXiv 预印本 arXiv:2310.15746*,
    2023。'
- en: '[23] X. Wang, W. Zhu, M. Saxon, M. Steyvers, and W. Y. Wang, “Large language
    models are implicitly topic models: Explaining and finding good demonstrations
    for in-context learning,” in *Workshop on Efficient Systems for Foundation Models@
    ICML2023*, 2023.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] X. Wang, W. Zhu, M. Saxon, M. Steyvers, 和 W. Y. Wang，“大型语言模型隐含的主题模型：解释和寻找适合的上下文学习示例”，发表于
    *ICML2023高效基础模型系统研讨会*，2023年。'
- en: '[24] H. Caesar, V. Bankiti, A. H. Lang, S. Vora, V. E. Liong, Q. Xu, A. Krishnan,
    Y. Pan, G. Baldan, and O. Beijbom, “nuscenes: A multimodal dataset for autonomous
    driving,” in *Proceedings of the IEEE/CVF conference on computer vision and pattern
    recognition*, 2020, pp. 11 621–11 631.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] H. Caesar, V. Bankiti, A. H. Lang, S. Vora, V. E. Liong, Q. Xu, A. Krishnan,
    Y. Pan, G. Baldan, 和 O. Beijbom，“nuscenes：一个用于自动驾驶的多模态数据集”，发表于 *IEEE/CVF计算机视觉与模式识别会议论文集*，2020年，第11,621–11,631页。'
- en: '[25] J. Geyer, Y. Kassahun, M. Mahmudi, X. Ricou, R. Durgesh, A. S. Chung,
    L. Hauswald, V. H. Pham, M. Mühlegg, S. Dorn, *et al.*, “A2d2: Audi autonomous
    driving dataset,” *arXiv preprint arXiv:2004.06320*, 2020.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] J. Geyer, Y. Kassahun, M. Mahmudi, X. Ricou, R. Durgesh, A. S. Chung,
    L. Hauswald, V. H. Pham, M. Mühlegg, S. Dorn, *等*，“A2d2：奥迪自主驾驶数据集”，*arXiv预印本 arXiv:2004.06320*，2020年。'
- en: '[26] X. Huang, X. Cheng, Q. Geng, B. Cao, D. Zhou, P. Wang, Y. Lin, and R. Yang,
    “The apolloscape dataset for autonomous driving,” in *Proceedings of the IEEE
    conference on computer vision and pattern recognition workshops*, 2018, pp. 954–960.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] X. Huang, X. Cheng, Q. Geng, B. Cao, D. Zhou, P. Wang, Y. Lin, 和 R. Yang，“ApolloScape数据集用于自动驾驶”，发表于
    *IEEE计算机视觉与模式识别会议研讨会论文集*，2018年，第954–960页。'
- en: '[27] W. Zhan, L. Sun, D. Wang, H. Shi, A. Clausse, M. Naumann, J. Kummerle,
    H. Konigshof, C. Stiller, A. de La Fortelle, *et al.*, “Interaction dataset: An
    international, adversarial and cooperative motion dataset in interactive driving
    scenarios with semantic maps,” *arXiv preprint arXiv:1910.03088*, 2019.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] W. Zhan, L. Sun, D. Wang, H. Shi, A. Clausse, M. Naumann, J. Kummerle,
    H. Konigshof, C. Stiller, A. de La Fortelle, *等*，“互动数据集：一个国际性、对抗性和合作性的互动驾驶场景语义地图数据集”，*arXiv预印本
    arXiv:1910.03088*，2019年。'
- en: '[28] T. Li, A. Alhilal, A. Zhang, M. A. Hoque, D. Chatzopoulos, Z. Xiao, Y. Li,
    and P. Hui, “Driving big data: A first look at driving behavior via a large-scale
    private car dataset,” in *2019 IEEE 35th International Conference on Data Engineering
    Workshops (ICDEW)*.   IEEE, 2019, pp. 61–68.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] T. Li, A. Alhilal, A. Zhang, M. A. Hoque, D. Chatzopoulos, Z. Xiao, Y.
    Li, 和 P. Hui，“大数据驱动：通过大规模私人汽车数据集首次审视驾驶行为”，发表于 *2019 IEEE第35届国际数据工程研讨会 (ICDEW)*。IEEE，2019年，第61–68页。'
- en: '[29] X. Hu, Z. Zheng, D. Chen, X. Zhang, and J. Sun, “Processing, assessing,
    and enhancing the waymo autonomous vehicle open dataset for driving behavior research,”
    *Transportation Research Part C: Emerging Technologies*, vol. 134, p. 103490,
    2022.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] X. Hu, Z. Zheng, D. Chen, X. Zhang, 和 J. Sun，“处理、评估和提升Waymo自动驾驶开放数据集以进行驾驶行为研究”，*运输研究C部分：新兴技术*，第134卷，第103490页，2022年。'
- en: '[30] M. Martin, A. Roitberg, M. Haurilet, M. Horne, S. Reiß, M. Voit, and R. Stiefelhagen,
    “Drive&act: A multi-modal dataset for fine-grained driver behavior recognition
    in autonomous vehicles,” in *Proceedings of the IEEE/CVF International Conference
    on Computer Vision*, 2019, pp. 2801–2810.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] M. Martin, A. Roitberg, M. Haurilet, M. Horne, S. Reiß, M. Voit, 和 R.
    Stiefelhagen，“Drive&act：一个用于细粒度驾驶行为识别的多模态数据集”，发表于 *IEEE/CVF国际计算机视觉会议论文集*，2019年，第2801–2810页。'
- en: '[31] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan,
    P. Shyam, G. Sastry, A. Askell, *et al.*, “Language models are few-shot learners,”
    *Advances in neural information processing systems*, vol. 33, pp. 1877–1901, 2020.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A.
    Neelakantan, P. Shyam, G. Sastry, A. Askell, *等*，“语言模型是少样本学习者”，*神经信息处理系统进展*，第33卷，第1877–1901页，2020年。'
- en: '[32] O. Taubman-Ben-Ari, M. Mikulincer, and O. Gillath, “The multidimensional
    driving style inventory—scale construct and validation,” *Accident Analysis &
    Prevention*, vol. 36, no. 3, pp. 323–332, 2004.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] O. Taubman-Ben-Ari, M. Mikulincer, 和 O. Gillath，“多维驾驶风格清单——量表构建与验证”，*事故分析与预防*，第36卷，第3期，第323–332页，2004年。'
