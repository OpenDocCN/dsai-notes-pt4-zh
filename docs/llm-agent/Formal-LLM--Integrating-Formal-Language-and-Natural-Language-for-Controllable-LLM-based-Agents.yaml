- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:53:28'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:53:28
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Formal-LLM: Integrating Formal Language and Natural Language for Controllable
    LLM-based Agents'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Formal-LLM：将形式语言与自然语言结合用于可控的基于LLM的智能体
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2402.00798](https://ar5iv.labs.arxiv.org/html/2402.00798)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2402.00798](https://ar5iv.labs.arxiv.org/html/2402.00798)
- en: Zelong Li    Wenyue Hua    Hao Wang    He Zhu    Yongfeng Zhang
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Zelong Li    Wenyue Hua    Hao Wang    He Zhu    Yongfeng Zhang
- en: Abstract
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Recent advancements on Large Language Models (LLMs) enable AI Agents to automatically
    generate and execute multi-step plans to solve complex tasks. However, since LLM’s
    content generation process is hardly controllable, current LLM-based agents frequently
    generate invalid or non-executable plans, which jeopardizes the performance of
    the generated plans and corrupts users’ trust in LLM-based agents. In response,
    this paper proposes a novel “Formal-LLM” framework for LLM-based agents by integrating
    the expressiveness of natural language and the precision of formal language. Specifically,
    the framework allows human users to express their requirements or constraints
    for the planning process as an automaton. A stack-based LLM plan generation process
    is then conducted under the supervision of the automaton to ensure that the generated
    plan satisfies the constraints, making the planning process controllable. We conduct
    experiments on both benchmark tasks and practical real-life tasks, and our framework
    achieves over 50% overall performance increase, which validates the feasibility
    and effectiveness of employing Formal-LLM to guide the plan generation of agents,
    preventing the agents from generating invalid and unsuccessful plans. Further,
    more controllable LLM-based agents can facilitate the broader utilization of LLM
    in application scenarios where high validity of planning is essential. The work
    is open-sourced at [https://github.com/agiresearch/Formal-LLM](https://github.com/agiresearch/Formal-LLM).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，大型语言模型（LLMs）的进展使得人工智能智能体能够自动生成并执行多步骤计划以解决复杂任务。然而，由于LLM的内容生成过程难以控制，当前基于LLM的智能体经常生成无效或不可执行的计划，这危害了生成计划的性能，并损害了用户对基于LLM的智能体的信任。对此，本文提出了一种新颖的“Formal-LLM”框架，通过将自然语言的表达能力与形式语言的精确性结合，为基于LLM的智能体提供支持。具体而言，该框架允许人类用户将其对规划过程的要求或约束表达为一个自动机。在自动机的监督下进行基于栈的LLM计划生成过程，以确保生成的计划符合约束，使得规划过程可控。我们在基准任务和实际生活任务上进行了实验，我们的框架实现了超过50%的总体性能提升，这验证了使用Formal-LLM指导智能体的计划生成的可行性和有效性，防止智能体生成无效和失败的计划。此外，更可控的基于LLM的智能体可以促进LLM在对规划有效性要求高的应用场景中的更广泛应用。这项工作已开源于[https://github.com/agiresearch/Formal-LLM](https://github.com/agiresearch/Formal-LLM)。
- en: Large Language Model, Agents, Controllability
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型、智能体、可控性
- en: ¹Department of Computer Science, Rutgers University, New Brunswick, NJ 08854,
    USA
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ¹计算机科学系，罗格斯大学，纽布伦斯维克，NJ 08854，美国
- en: zelong.li, wenyue.hua, hw488, hz375, yongfeng.zhang@rutgers.edu
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: zelong.li, wenyue.hua, hw488, hz375, yongfeng.zhang@rutgers.edu
- en: 1 Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 介绍
- en: Numerous applications have emerged with the rapid development of Large Language
    Models (LLM). One notable application is the LLM-based agent, which is capable
    of automatically generating and executing multi-step plans to solve complex tasks.
    While the LLM-based agent exhibits creativity, there is a concern about the potential
    generation of unreasonable and invalid plans, undermining the effectiveness of
    agents. For example, generating a plan that attempts to process image data using
    a tool designed for text can lead to errors. Recent studies have pointed out the
    challenges of LLM-based agents in developing non-executable plans without sufficient
    human oversight (Ge et al., [2023a](#bib.bib13); Yuan et al., [2024](#bib.bib47)).
    Addressing these challenges is crucial for improving agent performance, increasing
    the generation of valid plans, and maintaining user trust. Various attempts have
    been made to control LLM text generation, such as incorporating hard constraints
    (Takase and Okazaki, [2019](#bib.bib39); Carlsson et al., [2022](#bib.bib5)),
    soft constraints (Gu et al., [2022](#bib.bib17); Lu et al., [2022](#bib.bib29)),
    or a combination of both (Chen et al., [2024](#bib.bib6)). However, the focus
    of controlling LLM-based agents emphasizes the validity of plans and tool-use
    over purely text generation. Some recent studies leverage LLM as a parser to extract
    a chain of tools from the generated texts based on pre-designed prompts (Ge et al.,
    [2023a](#bib.bib13); Yuan et al., [2024](#bib.bib47)), yet achieving a satisfactory
    rate of valid plans remains elusive.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大型语言模型（LLM）的快速发展，涌现出了许多应用。其中一个显著的应用是基于 LLM 的代理，它能够自动生成和执行多步骤计划以解决复杂任务。虽然基于
    LLM 的代理展示了创造力，但也存在生成不合理和无效计划的潜在问题，从而削弱了代理的有效性。例如，生成一个试图使用为文本设计的工具处理图像数据的计划可能会导致错误。近期研究指出，基于
    LLM 的代理在没有足够人类监督的情况下开发不可执行的计划面临挑战（Ge et al., [2023a](#bib.bib13); Yuan et al.,
    [2024](#bib.bib47)）。解决这些挑战对提高代理性能、增加有效计划的生成以及保持用户信任至关重要。各种尝试已经被提出以控制 LLM 文本生成，例如结合硬约束（Takase
    和 Okazaki, [2019](#bib.bib39); Carlsson et al., [2022](#bib.bib5)）、软约束（Gu et al.,
    [2022](#bib.bib17); Lu et al., [2022](#bib.bib29)）或两者的组合（Chen et al., [2024](#bib.bib6)）。然而，控制基于
    LLM 的代理的重点是计划和工具使用的有效性，而不仅仅是文本生成。一些最新研究利用 LLM 作为解析器，从生成的文本中提取工具链，基于预设计的提示（Ge et
    al., [2023a](#bib.bib13); Yuan et al., [2024](#bib.bib47)），但实现令人满意的有效计划率仍然难以实现。
- en: 'To tackle the problems of valid plan generation, we propose a framework named
    “Formal-LLM”, which integrates the expressiveness of natural language and the
    precision of formal language, as shown by the toy example in Figure [1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ Formal-LLM: Integrating Formal Language and Natural
    Language for Controllable LLM-based Agents"). Specifically, to control the LLM-based
    agent’s plan generation, human users construct a context-free grammar (CFG) as
    the formal language to represent the constraints for the agent. The CFG is then
    automatically translated into a pushdown automaton (PDA). When LLM conducts planning,
    it is prompted to follow the state transition defined by the automaton. This is
    realized by limiting the LLM-based agent’s choices at each step to the valid actions
    defined by the PDA at its current state, which helps to guarantee that the constraint
    is satisfied in the final generated plan. We choose PDA in this work because some
    tasks need to be solved by a tree-structured plan rather than a simple chain-structured
    plan, as shown by the examples in Figure [5](#S4.F5 "Figure 5 ‣ 4.3 Formal-LLM
    Prompts and Planning from Automaton ‣ 4 The Formal-LLM Framework ‣ Formal-LLM:
    Integrating Formal Language and Natural Language for Controllable LLM-based Agents"),
    and such tree-structured plans require a PDA to generate.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '为了解决有效计划生成的问题，我们提出了一个名为“Formal-LLM”的框架，该框架结合了自然语言的表达力和形式语言的精确性，如图 [1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ Formal-LLM: Integrating Formal Language and Natural
    Language for Controllable LLM-based Agents") 中的示例所示。具体来说，为了控制基于 LLM 的代理的计划生成，人类用户构建一个上下文无关文法（CFG）作为形式语言来表示代理的约束。然后将
    CFG 自动转换为下推自动机（PDA）。当 LLM 进行规划时，它会被提示遵循自动机定义的状态转换。这是通过限制基于 LLM 的代理在每一步的选择为 PDA
    当前状态下定义的有效操作来实现的，这有助于确保最终生成的计划满足约束。我们在这项工作中选择 PDA，因为一些任务需要通过树形结构的计划而不是简单的链式结构计划来解决，如图
    [5](#S4.F5 "Figure 5 ‣ 4.3 Formal-LLM Prompts and Planning from Automaton ‣ 4
    The Formal-LLM Framework ‣ Formal-LLM: Integrating Formal Language and Natural
    Language for Controllable LLM-based Agents") 中的示例所示，这种树形结构的计划需要 PDA 来生成。'
- en: '![Refer to caption](img/200b1cbf5b1bb78a9702a4cde58417e1.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/200b1cbf5b1bb78a9702a4cde58417e1.png)'
- en: 'Figure 1: The Formal-LLM workflow with a toy example. To control the LLM-based
    agent’s plan generation, human users construct a formal language (context-free
    grammar, CFG) to represent the natural language constraints. The formal language
    is then translated into a pushdown automaton (PDA). When LLM conducts planning,
    it needs to follow the state transition defined by the automaton, which helps
    to guarantee that the constraint is satisfied in the final generated plan. We
    choose PDA because some plans exhibit tree-structure (as shown by other examples
    in the paper), which requires a PDA to generate.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：带有示例的Formal-LLM工作流程。为了控制基于LLM的代理的计划生成，人工用户构建一种形式语言（上下文无关文法，CFG）来表示自然语言约束。然后将形式语言转换为下推自动机（PDA）。当LLM进行规划时，需要遵循自动机定义的状态转移，这有助于保证最终生成的计划满足约束。我们选择PDA是因为一些计划展示了树形结构（如论文中的其他示例所示），这需要PDA进行生成。
- en: Furthermore, we introduce the backtracking mechanism in the Formal-LLM to increase
    the probability of finding valid plans for the agent, which enables the planning
    process to return to the previous step when a dead end is reached on the automaton.
    Besides, traditional LLM-based agent fine-tuning techniques such as Reinforcement
    Learning from Task Feedback (RLTF) (Ge et al., [2023a](#bib.bib13)) rely on the
    rewards from the agent’s plan execution to fine-tune the LLM parameters. However,
    since many invalid plans may be generated, many rewards are actually not informative
    for LLM-based agent fine-tuning. Our Formal-LLM approach guarantees that invalid
    plans are excluded during the agent’s plan generation. As a result, our approach
    helps to increase the amount of valid rewards for LLM fine-tuning, which improves
    the performance of fine-tuned LLM-based agents.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们在Formal-LLM中引入了回溯机制，以增加为代理找到有效计划的概率，这使得在自动机遇到死胡同时，规划过程可以返回到先前的步骤。此外，传统的基于LLM的代理微调技术，如任务反馈强化学习（RLTF）（Ge等，[2023a](#bib.bib13)），依赖于代理计划执行中的奖励来微调LLM参数。然而，由于可能会生成许多无效计划，因此许多奖励实际上对LLM基于代理的微调没有信息价值。我们的Formal-LLM方法保证在代理计划生成过程中排除无效计划。因此，我们的方法有助于增加用于LLM微调的有效奖励，从而提升微调后LLM基于代理的性能。
- en: In our experiments, we implement the Formal-LLM framework across various LLMs,
    including both open-source and closed-source LLMs. We also test our framework
    on both benchmark tasks and real-life practical tasks. Specifically, the benchmark
    tasks involve the LLM-based agent utilizing different tools to solve complex problems
    through multiple steps. The real-life scenarios encompass daily routines, cooking
    instructions, and commercial risk management, each imposing specific domain-knowledge
    or common-sense constraints. Our findings demonstrate the Formal-LLM’s capability
    to generate reasonable plans. The framework substantially enhances the overall
    performance on the benchmark tasks by over 50% and can always generate executable
    plans. In real-life scenarios, we provide qualitative analyses into the improvements
    brought by the Formal-LLM framework, affirming its feasibility and effectiveness
    in rendering the agents more controllable.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的实验中，我们在各种LLM上实现了Formal-LLM框架，包括开源和闭源LLM。我们还在基准任务和实际应用任务上测试了我们的框架。具体来说，基准任务涉及LLM-based代理利用不同工具通过多步骤解决复杂问题。实际场景涵盖了日常例行事务、烹饪指令和商业风险管理，每种情况都施加了特定的领域知识或常识约束。我们的研究结果表明Formal-LLM能够生成合理的计划。该框架在基准任务上的整体性能提升了50%以上，并且总是能够生成可执行的计划。在实际场景中，我们对Formal-LLM框架带来的改进进行了定性分析，确认了其在提高代理可控性方面的可行性和有效性。
- en: 2 Related Work
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: 2.1 LLM-based AI Agent
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 基于LLM的AI代理
- en: An AI agent is an autonomous entity capable of making decisions and executing
    actions within a specific environment to effectively tackle diverse complex tasks
    using AI techniques (Ge et al., [2023b](#bib.bib14); Wang et al., [2023](#bib.bib43);
    Xi et al., [2023](#bib.bib46)). The emergence of Large Language Models (LLMs),
    exemplified by the GPT series (Radford et al., [2019](#bib.bib34); Brown et al.,
    [2020](#bib.bib3); OpenAI, [2023](#bib.bib30)) and the LLaMA series (Touvron et al.,
    [2023a](#bib.bib40), [b](#bib.bib41)), has spurred the exploration of LLM-based
    agents (Ge et al., [2023a](#bib.bib13); Huang et al., [2022](#bib.bib23)). These
    agents utilize LLMs as their central cognitive component or controller, broadening
    their perceptual and action capabilities through approaches like multimodal perception
    and tool usage (Schick et al., [2023](#bib.bib38); Ge et al., [2023a](#bib.bib13);
    Qin et al., [2023](#bib.bib33)). In contrast to pre-LLM era AI agents, LLM-based
    agents showcase creativity, manifesting in the ability to generate innovative
    ideas without additional learning (Franceschelli and Musolesi, [2023](#bib.bib12)),
    indicating a degree of self-directed exploration and decision-making (Xi et al.,
    [2023](#bib.bib46)). Despite LLM-based agent’s application in diverse real-world
    scenarios such as software development (Li et al., [2023a](#bib.bib25); Qian et al.,
    [2023](#bib.bib31)), scientific research (Boiko et al., [2023](#bib.bib2)), and
    system management (Liu et al., [2023](#bib.bib28)), recent studies have highlighted
    issues of non-executable plans being generated without adequate human oversight
    (Ge et al., [2023a](#bib.bib13); Yuan et al., [2024](#bib.bib47)). If these plans
    lack executability, the utility of LLM-based agents in fields that require high
    validity is compromised, and their unreliability erodes user trust. To address
    this challenge, we propose integrating natural language and precise automaton
    during the agent’s planning process to enable the controllable generation of valid
    plans.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: AI代理是一个自主实体，能够在特定环境中做出决策并执行操作，以有效应对各种复杂任务，利用AI技术（Ge et al., [2023b](#bib.bib14);
    Wang et al., [2023](#bib.bib43); Xi et al., [2023](#bib.bib46)）。大型语言模型（LLMs）的出现，以GPT系列（Radford
    et al., [2019](#bib.bib34); Brown et al., [2020](#bib.bib3); OpenAI, [2023](#bib.bib30)）和LLaMA系列（Touvron
    et al., [2023a](#bib.bib40), [b](#bib.bib41)）为例，推动了基于LLM的代理的探索（Ge et al., [2023a](#bib.bib13);
    Huang et al., [2022](#bib.bib23)）。这些代理利用LLM作为其核心认知组件或控制器，通过多模态感知和工具使用等方法扩展其感知和行动能力（Schick
    et al., [2023](#bib.bib38); Ge et al., [2023a](#bib.bib13); Qin et al., [2023](#bib.bib33)）。与前LLM时代的AI代理相比，基于LLM的代理展现了创造力，能够在没有额外学习的情况下生成创新想法（Franceschelli
    and Musolesi, [2023](#bib.bib12)），这表明其具有一定程度的自我引导探索和决策能力（Xi et al., [2023](#bib.bib46)）。尽管基于LLM的代理在软件开发（Li
    et al., [2023a](#bib.bib25); Qian et al., [2023](#bib.bib31)）、科学研究（Boiko et al.,
    [2023](#bib.bib2)）和系统管理（Liu et al., [2023](#bib.bib28)）等各种真实世界场景中得到了应用，但最近的研究揭示了在缺乏足够人工监督的情况下生成的不可执行计划的问题（Ge
    et al., [2023a](#bib.bib13); Yuan et al., [2024](#bib.bib47)）。如果这些计划缺乏可执行性，则LLM基于的代理在需要高效验证的领域中的实用性会受到影响，其不可靠性会侵蚀用户的信任。为解决这一挑战，我们建议在代理的规划过程中整合自然语言和精确自动机，以实现可控的有效计划生成。
- en: 2.2 Controllable LLM Generation
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 可控的LLM生成
- en: 'To the best of our knowledge, there are few works on controllable LLM-based
    agents, and discussions primarily revolve around controllable LLM text generation.
    Controlling LLM text generation typically falls into two categories: hard constraints
    and soft constraints (Qin et al., [2022](#bib.bib32)). Hard constraints involve
    constraints on the desired text length, designated keywords for the generated
    text (Takase and Okazaki, [2019](#bib.bib39); Carlsson et al., [2022](#bib.bib5)),
    and constraint vocabulary space in decoding time (Hemmer et al., [2023](#bib.bib18);
    Geng et al., [2024](#bib.bib15), [2023](#bib.bib16)), while soft constraints restrict
    the output based on specific semantics, such as sentiments or topics (Gu et al.,
    [2022](#bib.bib17); Lu et al., [2022](#bib.bib29); Li et al., [2020](#bib.bib26)).
    A recent work (Chen et al., [2024](#bib.bib6)) attempts to integrate both constraints
    into a unified approach. However, text generation control has disadvantages and
    problems. First, text generation control could hardly be directly applied to closed-source
    LLMs due to their need to access the decoding probability (Geng et al., [2024](#bib.bib15)).
    Second, controllable LLM-based agents prioritize the validity of plan and tool
    use over purely text generation. Recent studies on LLM-based agents have noted
    limited effectiveness when employing text constraint generation on LLM-based agents
    and have explored using LLMs as a parser to extract planning information from
    generated texts (Ge et al., [2023a](#bib.bib13); Yuan et al., [2024](#bib.bib47));
    but relying heavily on the parser LLM’s effectiveness may not yield a satisfactory
    plan valid rate, especially in complex tasks. We propose an automaton-guided LLM-based
    agent planning to ensure that the generated plans adhere 100% to the constraints.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 据我们所知，关于可控的基于LLM的智能体的研究很少，讨论主要集中在可控的LLM文本生成上。控制LLM文本生成通常分为两类：硬约束和软约束（Qin 等，
    [2022](#bib.bib32)）。硬约束涉及对期望文本长度的约束、生成文本的指定关键词（Takase 和 Okazaki，[2019](#bib.bib39)；Carlsson
    等，[2022](#bib.bib5)），以及解码时间中的约束词汇空间（Hemmer 等，[2023](#bib.bib18)；Geng 等，[2024](#bib.bib15)，[2023](#bib.bib16)），而软约束则基于特定语义（如情感或话题）限制输出（Gu
    等，[2022](#bib.bib17)；Lu 等，[2022](#bib.bib29)；Li 等，[2020](#bib.bib26)）。最近的研究（Chen
    等，[2024](#bib.bib6)）尝试将这两种约束整合到一个统一的方法中。然而，文本生成控制存在一些缺点和问题。首先，文本生成控制难以直接应用于封闭源LLMs，因为需要访问解码概率（Geng
    等，[2024](#bib.bib15)）。其次，可控的LLM智能体优先考虑计划和工具使用的有效性，而不仅仅是文本生成。最近关于LLM智能体的研究指出，当在LLM智能体上使用文本约束生成时效果有限，并且探讨了使用LLMs作为解析器从生成文本中提取规划信息（Ge
    等，[2023a](#bib.bib13)；Yuan 等，[2024](#bib.bib47)）；但过度依赖解析器LLM的效果可能无法获得令人满意的计划有效性，特别是在复杂任务中。我们提出了一种基于自动机引导的LLM智能体规划，以确保生成的计划100%符合约束条件。
- en: 3 Preliminary Knowledge
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 初步知识
- en: 3.1 Context-free Grammar
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 上下文无关文法
- en: There are many LLM-based agent operating tools that take multiple inputs and
    produce one output. For example, the tool “Visual Question Answering” receives
    an image and a text as the inputs and generates a text as the output. The planning
    involving such tools forms a tree structure, and such tree-structured plans require
    Context-Free Grammar (CFG) to express the rules.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多基于LLM的智能体操作工具，它们接受多个输入并产生一个输出。例如，工具“视觉问答”接受一张图片和一段文本作为输入，并生成一段文本作为输出。涉及这些工具的规划形成一个树结构，这种树结构化的计划需要上下文无关文法（CFG）来表达规则。
- en: 'The CFG consists of four components: terminals (symbols unable to be replaced),
    nonterminals (symbols subject to replacement), start symbol (a unique nonterminal,
    usually denoted as $S$), and productions (rules governing symbol substitution).
    The CFG production follows the format:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: CFG由四个组成部分构成：终结符（不能被替换的符号）、非终结符（可以被替换的符号）、起始符号（一个唯一的非终结符，通常表示为$S$）和产生式（规范符号替换的规则）。CFG产生式的格式如下：
- en: '|  | $A\rightarrow\alpha$ |  | (1) |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '|  | $A\rightarrow\alpha$ |  | (1) |'
- en: 'where $A$ in any situations. Eq.([2](#S3.E2 "Equation 2 ‣ 3.1 Context-free
    Grammar ‣ 3 Preliminary Knowledge ‣ Formal-LLM: Integrating Formal Language and
    Natural Language for Controllable LLM-based Agents")) presents a CFG example with
    two productions:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '在任何情况下的$A$。公式（[2](#S3.E2 "公式 2 ‣ 3.1 上下文无关文法 ‣ 3 初步知识 ‣ Formal-LLM: 结合形式语言和自然语言以实现可控的基于LLM的智能体")）展示了一个包含两个产生式的CFG示例：'
- en: '|  | $\begin{split}&amp;S\rightarrow\varepsilon\\ &amp;S\rightarrow aSb\end{split}$
    |  | (2) |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}&amp;S\rightarrow\varepsilon\\ &amp;S\rightarrow aSb\end{split}$
    |  | (2) |'
- en: where $a,b$ in a certain amount of CFG production steps.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些CFG产生步骤中的$a,b$。
- en: '![Refer to caption](img/161f65620140b063a92e4408ba78da7f.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/161f65620140b063a92e4408ba78da7f.png)'
- en: 'Figure 2: A Pushdown Automaton (PDA) example. The edge represents the transition
    function. For example, the edge $(a,Z;SZ)$.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：一个下推自动机（PDA）示例。边表示转换函数。例如，边 $(a,Z;SZ)$。
- en: 3.2 Pushdown Automaton
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 下推自动机
- en: Every CFG can be transformed into an equivalent nondeterministic Pushdown Automaton
    (PDA) with an algorithm (Hopcroft et al., [2001](#bib.bib20)). A PDA is a machine
    that moves through a series of states based on a given string input, a transition
    function, and the top element of a stack. The automaton reads the letters in the
    input sequentially, and if there exists a path leading the machine to an accept
    state right after consuming the entire string, the input string is considered
    an accepting word. The set of all accepting words is referred to the CFL accepted
    by the automaton. Since the PDA process is more intuitive and automated than CFG
    for guiding the prompting of LLMs, our framework is designed on top of PDA.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 每个CFG都可以通过算法（Hopcroft et al., [2001](#bib.bib20)）转换为等效的非确定性下推自动机（PDA）。PDA 是一种基于给定的字符串输入、转换函数和栈顶元素在一系列状态中移动的机器。自动机按顺序读取输入中的字母，如果存在一个路径能让机器在消耗完整个字符串后到达接受状态，则输入字符串被认为是一个接受词。所有接受词的集合称为自动机接受的CFL。由于PDA过程在指导LLMs提示时比CFG更直观和自动化，我们的框架基于PDA设计。
- en: 'We use Figure [2](#S3.F2 "Figure 2 ‣ 3.1 Context-free Grammar ‣ 3 Preliminary
    Knowledge ‣ Formal-LLM: Integrating Formal Language and Natural Language for Controllable
    LLM-based Agents") as an example to show how PDA works. This automaton includes
    a stack alphabet ($\{S,Z\}$ is the stack top now).'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用图 [2](#S3.F2 "图 2 ‣ 3.1 上下文无关文法 ‣ 3 初步知识 ‣ 形式-LLM：整合形式语言与自然语言以实现可控的LLM代理")
    作为示例来展示PDA的工作原理。这个自动机包含一个栈字母表（当前栈顶是 $\{S,Z\}$）。
- en: 'This PDA is equivalent to the CFG in Eq.([2](#S3.E2 "Equation 2 ‣ 3.1 Context-free
    Grammar ‣ 3 Preliminary Knowledge ‣ Formal-LLM: Integrating Formal Language and
    Natural Language for Controllable LLM-based Agents")), i.e., every accepting word
    of this PDA belongs to the CFL defined in Eq.([2](#S3.E2 "Equation 2 ‣ 3.1 Context-free
    Grammar ‣ 3 Preliminary Knowledge ‣ Formal-LLM: Integrating Formal Language and
    Natural Language for Controllable LLM-based Agents")). We still use $aabb$ as
    the stack top.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这个PDA等同于公式中定义的CFG（见 Eq.([2](#S3.E2 "方程式 2 ‣ 3.1 上下文无关文法 ‣ 3 初步知识 ‣ 形式-LLM：整合形式语言与自然语言以实现可控的LLM代理")），即每个接受的词属于
    Eq.([2](#S3.E2 "方程式 2 ‣ 3.1 上下文无关文法 ‣ 3 初步知识 ‣ 形式-LLM：整合形式语言与自然语言以实现可控的LLM代理")）中定义的CFL。我们仍然使用
    $aabb$ 作为栈顶元素。
- en: 4 The Formal-LLM Framework
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 形式-LLM框架
- en: 4.1 Motivation and Challenge
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 动机与挑战
- en: Natural language is easily understandable by humans, but it may also lack precision
    in certain application scenarios. In contrast, formal language is defined in clear
    mathematical and machine readable forms, which could be hard to comprehend for
    human users, but it also possesses great precision. Thus, we aim to effectively
    integrate the benefits of both natural and formal languages through the pushdown
    automaton (PDA) for more controllable planning of LLM-based agents in scenarios
    requiring precise and valid plans.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言对人类来说易于理解，但在某些应用场景中可能缺乏精确性。相对而言，形式语言以明确的数学和机器可读形式定义，这对人类用户来说可能难以理解，但它具有极高的精确性。因此，我们旨在通过下推自动机（PDA）有效整合自然语言和形式语言的优势，以便在需要精确和有效计划的场景中更好地规划基于LLM的代理。
- en: Constructing our Formal-LLM framework presents non-trivial challenges. The first
    challenge lies in the potential struggle of the LLM to directly comprehend and
    process formal language due to the limited CFG- or PDA-related corpus in pre-training
    data. Hence, natural language prompts are necessary to effectively describe the
    status of the automaton, bridging the gap between formal and natural language
    for LLM’s planning. Given that the automaton has the potential to generate an
    infinite number of plans, the second challenge arises because the automaton only
    ensures the validity and executability of the plans by adhering to defined constraints,
    but cannot guarantee the performance and optimality of the generated plan. Therefore,
    leveraging the solid natural language understanding ability of LLM and other methods,
    such as fine-tuning and backtracking mechanisms, becomes crucial for enhancing
    the planning performance.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 构建我们的Formal-LLM框架面临着非凡的挑战。第一个挑战在于LLM可能难以直接理解和处理正式语言，因为预训练数据中有限的CFG或PDA相关语料库。因此，自然语言提示对于有效描述自动机的状态是必要的，弥合正式语言和自然语言之间的差距，以便LLM能够进行规划。由于自动机有可能生成无限数量的计划，第二个挑战在于，自动机仅通过遵循定义的约束来确保计划的有效性和可执行性，但无法保证生成计划的性能和最优性。因此，利用LLM的强大自然语言理解能力以及其他方法，如微调和回溯机制，对提升规划性能至关重要。
- en: 4.2 Formulating Constraint to Automaton
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 对自动机的约束制定
- en: 'The overall flow of our framework is presented in Figure [1](#S1.F1 "Figure
    1 ‣ 1 Introduction ‣ Formal-LLM: Integrating Formal Language and Natural Language
    for Controllable LLM-based Agents"). We begin by illustrating the process of converting
    constraints into formal language and automata for benchmark tasks, using the OpenAGI
    benchmark (Ge et al., [2023a](#bib.bib13)) as an example, which incorporates a
    set of domain expert models as tools and lists a series of intricate problems
    that cannot be addressed with a single tool. These tools are categorized into
    six primary groups according to the input and output modalities, as indicated
    in Table [3](#A2.T3 "Table 3 ‣ B.1 Bechmark Tasks and Tools ‣ Appendix B Appendix
    ‣ Formal-LLM: Integrating Formal Language and Natural Language for Controllable
    LLM-based Agents") in the Appendix.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '我们框架的整体流程如图[1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Formal-LLM: Integrating
    Formal Language and Natural Language for Controllable LLM-based Agents")所示。我们首先展示了如何将约束转化为正式语言和自动机以进行基准任务，以OpenAGI基准（Ge等，[2023a](#bib.bib13)）为例，该基准包含一组领域专家模型作为工具，并列出了一系列无法通过单一工具解决的复杂问题。这些工具根据输入和输出方式被分为六个主要组，如附录中的表[3](#A2.T3
    "Table 3 ‣ B.1 Bechmark Tasks and Tools ‣ Appendix B Appendix ‣ Formal-LLM: Integrating
    Formal Language and Natural Language for Controllable LLM-based Agents")所示。'
- en: If the plans for the benchmark tasks generated by the LLM-based agent deviate
    from the expected data format, the execution performance degrades significantly
    or even results in errors. For instance, consider the Colorization tool, which
    operates on image data as input and output. Given that image data is represented
    as a 3-D tensor, providing a 1-D tensor text string as input to Colorization could
    lead to errors, specifically due to incorrect data dimensions. Consequently, the
    entire plan becomes invalid and cannot be executed. In such cases, natural language
    may struggle to articulate these constraints precisely and concisely, whereas
    formal language can express them straightforwardly.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果由基于LLM的代理生成的基准任务计划偏离预期的数据格式，执行性能会显著下降，甚至导致错误。例如，考虑Colorization工具，它以图像数据作为输入和输出。由于图像数据表示为3-D张量，将1-D张量文本字符串作为输入提供给Colorization可能会导致错误，特别是由于数据维度不正确。因此，整个计划变得无效，无法执行。在这种情况下，自然语言可能难以准确而简洁地表达这些约束，而正式语言可以直接表达这些约束。
- en: 'We use symbols to represent different elements: $T$ for specific tools, in
    the order of Table [3](#A2.T3 "Table 3 ‣ B.1 Bechmark Tasks and Tools ‣ Appendix
    B Appendix ‣ Formal-LLM: Integrating Formal Language and Natural Language for
    Controllable LLM-based Agents"). The context-free grammar (CFG) below outlines
    the constraints on data formats with Polish prefix notation.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '我们使用符号来表示不同的元素：$T$用于特定工具，按表[3](#A2.T3 "Table 3 ‣ B.1 Bechmark Tasks and Tools
    ‣ Appendix B Appendix ‣ Formal-LLM: Integrating Formal Language and Natural Language
    for Controllable LLM-based Agents")的顺序。下面的上下文无关文法（CFG）概述了波兰前缀表示法的数据格式约束。'
- en: '|  | $$\begin{split}&amp;I\rightarrow AI&#124;CT\\ &amp;T\rightarrow BI&#124;DT&#124;EIT&#124;FTT\\'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | $$\begin{split}&amp;I\rightarrow AI&#124;CT\\ &amp;T\rightarrow BI&#124;DT&#124;EIT&#124;FTT\\'
- en: '&amp;A\rightarrow a_{1}&#124;a_{2}&#124;a_{3}&#124;a_{4}\\'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '&amp;A\rightarrow a_{1}&#124;a_{2}&#124;a_{3}&#124;a_{4}\\'
- en: '&amp;B\rightarrow b_{1}&#124;b_{2}&#124;b_{3}\\'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '&amp;B\rightarrow b_{1}&#124;b_{2}&#124;b_{3}\\'
- en: '&amp;C\rightarrow c_{1}\\'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '&amp;C\rightarrow c_{1}\\'
- en: '&amp;D\rightarrow d_{1}&#124;d_{2}&#124;d_{3}&#124;d_{4}&#124;d_{5}\\'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '&amp;D\rightarrow d_{1}&#124;d_{2}&#124;d_{3}&#124;d_{4}&#124;d_{5}\\'
- en: '&amp;E\rightarrow e_{1}\\'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '&amp;E\rightarrow e_{1}\\'
- en: '&amp;F\rightarrow f_{1}\end{split}$$ |  | (3) |'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '&amp;F\rightarrow f_{1}\end{split}$$ |  | (3) |'
- en: 'where $I\rightarrow AI|CT$), the result is still an image. Considering a specific
    task, such as “Given blurry gray-scale images, how to return the object names
    in English step by step?”, we know that the task’s inputs are images and the final
    outputs should be texts. To formalize this, we introduce two additional constraints
    to Eq.([3](#S4.E3 "Equation 3 ‣ 4.2 Formulating Constraint to Automaton ‣ 4 The
    Formal-LLM Framework ‣ Formal-LLM: Integrating Formal Language and Natural Language
    for Controllable LLM-based Agents")):'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '其中 $I\rightarrow AI|CT$)，结果仍然是图像。考虑一个具体任务，例如“给定模糊的灰度图像，如何一步步返回对象名称的英文？”，我们知道任务的输入是图像，最终输出应该是文本。为了正式化这一点，我们对
    Eq.([3](#S4.E3 "Equation 3 ‣ 4.2 Formulating Constraint to Automaton ‣ 4 The Formal-LLM
    Framework ‣ Formal-LLM: Integrating Formal Language and Natural Language for Controllable
    LLM-based Agents")) 引入了两个额外的约束：'
- en: '|  | $\begin{split}&amp;S\rightarrow T\\ &amp;I\rightarrow i\end{split}$ |  |
    (4) |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}&amp;S\rightarrow T\\ &amp;I\rightarrow i\end{split}$ |  |
    (4) |'
- en: 'i.e., the CFG starts with the symbol $T$) with the text and output image to
    derive the final text.” As mentioned in Section [3.2](#S3.SS2 "3.2 Pushdown Automaton
    ‣ 3 Preliminary Knowledge ‣ Formal-LLM: Integrating Formal Language and Natural
    Language for Controllable LLM-based Agents"), the CFG can be equivalently converted
    into a PDA, illustrated in Figure [3](#S4.F3 "Figure 3 ‣ 4.3 Formal-LLM Prompts
    and Planning from Automaton ‣ 4 The Formal-LLM Framework ‣ Formal-LLM: Integrating
    Formal Language and Natural Language for Controllable LLM-based Agents"). These
    steps allow us to transform the constraints into automata for subsequent utilization.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '即，CFG 以符号 $T$ 开始) 与文本和输出图像结合以推导最终文本。” 如[3.2](#S3.SS2 "3.2 Pushdown Automaton
    ‣ 3 Preliminary Knowledge ‣ Formal-LLM: Integrating Formal Language and Natural
    Language for Controllable LLM-based Agents")节中所述，CFG 可以等效转换为 PDA，如图[3](#S4.F3
    "Figure 3 ‣ 4.3 Formal-LLM Prompts and Planning from Automaton ‣ 4 The Formal-LLM
    Framework ‣ Formal-LLM: Integrating Formal Language and Natural Language for Controllable
    LLM-based Agents")所示。这些步骤使我们能够将约束转换为自动机，以供后续使用。'
- en: 'In certain scenarios, creating an automaton can be more straightforward than
    formulating a formal language. Section [B.4.1](#A2.SS4.SSS1 "B.4.1 Daily Plan
    ‣ B.4 Prompt for Real-life Tasks ‣ Appendix B Appendix ‣ Formal-LLM: Integrating
    Formal Language and Natural Language for Controllable LLM-based Agents") describes
    a real-life task for daily work planning. The constraints in this case revolve
    around time, allowing us to represent time as distinct states, as depicted in
    Figure [4](#S4.F4 "Figure 4 ‣ 4.3 Formal-LLM Prompts and Planning from Automaton
    ‣ 4 The Formal-LLM Framework ‣ Formal-LLM: Integrating Formal Language and Natural
    Language for Controllable LLM-based Agents"). The automaton initiates the design
    of an activity that concludes at 20:00, and a valid plan is generated when the
    automaton reaches 10:00 while being in a state where three meals have been consumed.
    This approach involves designing an effective PDA without the need for a CFG.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '在某些情况下，创建自动机可能比制定正式语言更简单。[B.4.1](#A2.SS4.SSS1 "B.4.1 Daily Plan ‣ B.4 Prompt
    for Real-life Tasks ‣ Appendix B Appendix ‣ Formal-LLM: Integrating Formal Language
    and Natural Language for Controllable LLM-based Agents")节描述了一个实际的日常工作计划任务。此情况下的约束围绕时间展开，使我们能够将时间表示为不同的状态，如图[4](#S4.F4
    "Figure 4 ‣ 4.3 Formal-LLM Prompts and Planning from Automaton ‣ 4 The Formal-LLM
    Framework ‣ Formal-LLM: Integrating Formal Language and Natural Language for Controllable
    LLM-based Agents")所示。自动机开始设计一个在20:00结束的活动，当自动机达到10:00并且处于已吃过三餐的状态时，生成一个有效计划。这种方法涉及设计一个有效的
    PDA，而无需 CFG。'
- en: 4.3 Formal-LLM Prompts and Planning from Automaton
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 正式-LLM 提示和自动机规划
- en: 'In Section [4.2](#S4.SS2 "4.2 Formulating Constraint to Automaton ‣ 4 The Formal-LLM
    Framework ‣ Formal-LLM: Integrating Formal Language and Natural Language for Controllable
    LLM-based Agents"), we convert the natural language planning constraints into
    a PDA, where any accepted word represents a valid and executable plan. The reason
    is that LLM could struggle to directly comprehend or process the CFG due to limited
    exposure to formal language during pre-training. Hence, we employ natural language
    prompts for LLM to comprehend the task and generate plans that can be easily read
    by humans; simultaneously, we use the PDA to guide the process of generating natural
    language plans.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在[4.2节](#S4.SS2 "4.2 将约束转换为自动机 ‣ 4 正式-LLM框架 ‣ 正式-LLM：将正式语言与自然语言集成用于可控的基于LLM的代理")中，我们将自然语言规划约束转换为PDA，其中任何被接受的词汇代表一个有效且可执行的计划。原因是LLM可能因在预训练期间接触正式语言的机会有限，直接理解或处理CFG可能会遇到困难。因此，我们使用自然语言提示帮助LLM理解任务并生成易于人类阅读的计划；同时，我们使用PDA来指导生成自然语言计划的过程。
- en: 'The automaton initiates the plan generation process from the start state. In
    situations where multiple viable options are available for the automaton to proceed,
    a prompt is created to inquire the LLM, as shown in Figure [1](#S1.F1 "Figure
    1 ‣ 1 Introduction ‣ Formal-LLM: Integrating Formal Language and Natural Language
    for Controllable LLM-based Agents"). This prompt encompasses a comprehensive {task
    description} to mitigate potential forgetting issues of the LLM (Hua et al., [2023](#bib.bib22)),
    details about the {current progress}, and {feasible choices} determined by the
    PDA. For example, consider the PDA in Figure [3](#S4.F3 "Figure 3 ‣ 4.3 Formal-LLM
    Prompts and Planning from Automaton ‣ 4 The Formal-LLM Framework ‣ Formal-LLM:
    Integrating Formal Language and Natural Language for Controllable LLM-based Agents")
    when it is in state $q_{1}$, we directly use the tool name (e.g., Colorization)
    instead of the category name (e.g., “Image-in, Image-out tools”) in the prompt.
    This is because the tool name provides more concrete information for the LLM to
    comprehend the tool’s functionality, enabling the LLM to make informed decisions
    without influencing the plan’s executability. A prompt example is provided in
    Appendix [B.3](#A2.SS3 "B.3 Prompt for Benchmark Tasks ‣ Appendix B Appendix ‣
    Formal-LLM: Integrating Formal Language and Natural Language for Controllable
    LLM-based Agents").'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 自动机从初始状态开始生成计划。在自动机有多个可行选项的情况下，会创建一个提示以询问LLM，如[图1](#S1.F1 "图1 ‣ 1 引言 ‣ 正式-LLM：将正式语言与自然语言集成用于可控的基于LLM的代理")所示。该提示包含全面的{任务描述}，以减少LLM可能出现的遗忘问题（Hua等，
    [2023](#bib.bib22)），有关{当前进展}的详细信息，以及PDA确定的{可行选择}。例如，考虑[图3](#S4.F3 "图3 ‣ 4.3 正式-LLM提示和自动机规划
    ‣ 4 正式-LLM框架 ‣ 正式-LLM：将正式语言与自然语言集成用于可控的基于LLM的代理")中的PDA，当其处于状态$q_{1}$时，我们直接使用工具名称（例如，Colorization），而不是类别名称（例如，“图像输入、图像输出工具”）在提示中。这是因为工具名称提供了更具体的信息，帮助LLM理解工具的功能，从而使LLM能够做出明智的决策，而不会影响计划的可执行性。提示示例见附录[B.3](#A2.SS3
    "B.3 基准任务提示 ‣ 附录B 附录 ‣ 正式-LLM：将正式语言与自然语言集成用于可控的基于LLM的代理")。
- en: Another advantage of employing PDA for LLM-based agent planning is its ability
    to articulate plans that involve tools with many-input-single-output (e.g., Image-Text
    pair as input, Text as output), assuming the number of inputs of each tool is
    deterministic. To illustrate, we depict the derivation tree of the string $e_{1}a_{1}ib_{1}i$,
    because they are pushed into the stack at the same time. Consequently, we can
    readily identify the tools that will operate on this image/text data in the subsequent
    step and incorporate this information in the prompt, enabling the LLM to make
    more informed decisions.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 采用PDA进行基于LLM的代理规划的另一个优点是能够阐明涉及多输入单输出的工具的计划（例如，图像-文本对作为输入，文本作为输出），假设每个工具的输入数量是确定的。为了说明这一点，我们描绘了字符串$e_{1}a_{1}ib_{1}i$的推导树，因为它们同时被推入堆栈。因此，我们可以很容易地识别在后续步骤中将对这些图像/文本数据进行操作的工具，并将这些信息纳入提示，使LLM能够做出更明智的决策。
- en: '![Refer to caption](img/0ba7477831c7ec0aef666cafe7e029c8.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/0ba7477831c7ec0aef666cafe7e029c8.png)'
- en: 'Figure 3: An equivalent PDA to the CFG of the combination of Eq.([3](#S4.E3
    "Equation 3 ‣ 4.2 Formulating Constraint to Automaton ‣ 4 The Formal-LLM Framework
    ‣ Formal-LLM: Integrating Formal Language and Natural Language for Controllable
    LLM-based Agents")) and Eq.([4](#S4.E4 "Equation 4 ‣ 4.2 Formulating Constraint
    to Automaton ‣ 4 The Formal-LLM Framework ‣ Formal-LLM: Integrating Formal Language
    and Natural Language for Controllable LLM-based Agents")). $\varepsilon$.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：与 Eq.([3](#S4.E3 "方程 3 ‣ 4.2 将约束转化为自动机 ‣ 4 正式-LLM 框架 ‣ 正式-LLM：将形式语言与自然语言整合用于可控的
    LLM 基于代理")) 和 Eq.([4](#S4.E4 "方程 4 ‣ 4.2 将约束转化为自动机 ‣ 4 正式-LLM 框架 ‣ 正式-LLM：将形式语言与自然语言整合用于可控的
    LLM 基于代理")) 的 CFG 等效 PDA。$\varepsilon$。
- en: '![Refer to caption](img/2fdf517a18acfc98f02f0c36474c3353.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/2fdf517a18acfc98f02f0c36474c3353.png)'
- en: 'Figure 4: The PDA includes 13 states, $\{10,11,...,19,20,Start,Fin\}$ is enumerated
    from 20 to 13.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：PDA 包含 13 个状态，$\{10,11,...,19,20,Start,Fin\}$ 从 20 到 13 进行枚举。
- en: '![Refer to caption](img/7cb12150e295894828ef1b3622aadfe4.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/7cb12150e295894828ef1b3622aadfe4.png)'
- en: 'Figure 5: The derivation tree for $e_{1}a_{1}ib_{1}i$ for the example benchmark
    task in Section [4.2](#S4.SS2 "4.2 Formulating Constraint to Automaton ‣ 4 The
    Formal-LLM Framework ‣ Formal-LLM: Integrating Formal Language and Natural Language
    for Controllable LLM-based Agents").'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：第 [4.2](#S4.SS2 "4.2 将约束转化为自动机 ‣ 4 正式-LLM 框架 ‣ 正式-LLM：将形式语言与自然语言整合用于可控的
    LLM 基于代理") 节中的示例基准任务的 $e_{1}a_{1}ib_{1}i$ 的推导树。
- en: 4.4 Backtracking Mechanism and Reinforcement Learning from Task Feedback
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 回溯机制和来自任务反馈的强化学习
- en: 'An accepting word of an automaton can be infinitely long. However, we anticipate
    that the plan proposed by the LLM-based agent can be executed within a finite
    number of steps. Consider the PDA in Figure [2](#S3.F2 "Figure 2 ‣ 3.1 Context-free
    Grammar ‣ 3 Preliminary Knowledge ‣ Formal-LLM: Integrating Formal Language and
    Natural Language for Controllable LLM-based Agents"), any length of the string
    in the form of $a^{n}b^{n}$ is an accepting word. Similarly, in planning tasks,
    tools can be employed multiple times, such as applying the Text Summarization
    tool to the original text and infinitely repeating the same tool on the output.
    However, such planning behavior may be nonsensical and inefficient. Hence, for
    the tasks outlined in this paper, each tool is restricted to a single use for
    a given task, preventing infinite planning for both benchmark and real-life scenarios.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 自动机的接受词可以是无限长的。然而，我们预计 LLM 基于代理提出的计划可以在有限的步骤内执行。考虑图 [2](#S3.F2 "图 2 ‣ 3.1 上下文无关文法
    ‣ 3 初步知识 ‣ 正式-LLM：将形式语言与自然语言整合用于可控的 LLM 基于代理") 中的 PDA，任何形式为 $a^{n}b^{n}$ 的字符串都是一个接受词。同样，在规划任务中，工具可以多次使用，例如将文本摘要工具应用于原始文本，并在输出上无限重复相同的工具。然而，这种规划行为可能是无意义且低效的。因此，对于本文中概述的任务，每个工具被限制为在给定任务中使用一次，以防止基准和实际场景中的无限规划。
- en: 'Upon imposing constraints on the tool usage, a new challenge emerges: the automaton
    may encounter a dead-end during plan generation. Consider the formal language
    in Eq.([3](#S4.E3 "Equation 3 ‣ 4.2 Formulating Constraint to Automaton ‣ 4 The
    Formal-LLM Framework ‣ Formal-LLM: Integrating Formal Language and Natural Language
    for Controllable LLM-based Agents")) and Eq.([4](#S4.E4 "Equation 4 ‣ 4.2 Formulating
    Constraint to Automaton ‣ 4 The Formal-LLM Framework ‣ Formal-LLM: Integrating
    Formal Language and Natural Language for Controllable LLM-based Agents")). Upon
    analyzing the language, we observe that the only means of transitioning from the
    symbol $T$. Consequently, a dead-end situation may arise following the imposition
    of tool usage limits.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在对工具使用施加约束时，出现了一个新的挑战：自动机在生成计划时可能会遇到死胡同。考虑 Eq.([3](#S4.E3 "方程 3 ‣ 4.2 将约束转化为自动机
    ‣ 4 正式-LLM 框架 ‣ 正式-LLM：将形式语言与自然语言整合用于可控的 LLM 基于代理")) 和 Eq.([4](#S4.E4 "方程 4 ‣
    4.2 将约束转化为自动机 ‣ 4 正式-LLM 框架 ‣ 正式-LLM：将形式语言与自然语言整合用于可控的 LLM 基于代理")) 中的形式语言。分析该语言后，我们观察到从符号
    $T$ 过渡的唯一手段。因此，施加工具使用限制后可能会出现死胡同情况。
- en: To address this challenge, we propose to document the automaton’s details at
    each step, encompassing the current state and stack, and the part of the word
    that has been generated. When the automaton confronts a dead-end (indicating no
    viable next step), we initiate backtracking to the preceding steps until there
    is an unexplored branch. The backtracking involves retracing the automaton to
    the prior step, reinstating the automaton details based on the recorded stack,
    and eliminating the dead-end branch from the prior choice list. Consequently,
    the automaton is capable and guaranteed to generate a valid, executable plan.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对这一挑战，我们提议在每一步记录自动机的细节，包括当前状态和堆栈，以及已生成的单词部分。当自动机遇到死胡同（表示没有可行的下一步）时，我们启动回溯到先前步骤，直到出现未探索的分支。回溯涉及将自动机追溯到之前的步骤，基于记录的堆栈恢复自动机细节，并从之前的选择列表中消除死胡同分支。因此，自动机能够生成有效的可执行计划。
- en: 'The design above only guarantees the validity of the generated plans. For example,
    the plan $e_{1}a_{1}ib_{1}i$ shown in Figure [5](#S4.F5 "Figure 5 ‣ 4.3 Formal-LLM
    Prompts and Planning from Automaton ‣ 4 The Formal-LLM Framework ‣ Formal-LLM:
    Integrating Formal Language and Natural Language for Controllable LLM-based Agents")
    is an executable plan for the task “Given blurry grayscale images, how to return
    the object names in English step by step?”. However, this may not be the optimal
    plan. Thus, as an additional enhancement in plan quality, particularly when employing
    open-source LLMs, we integrate Reinforcement Learning from Task Feedback (RLTF)
    (Ge et al., [2023a](#bib.bib13)) following the application of our Formal-LLM framework.
    After the generation of a plan by the LLM-based agent for a training task, the
    plan is executed on benchmark data to assess its performance. Then, the performance
    is used as a reward for Reinforcement Learning (RL) to update the parameters of
    the LLM. Our framework ensures that invalid plans are always excluded during the
    LLM-based agent’s plan generation. Therefore, the number of valid rewards for
    LLM fine-tuning increases, and our approach can improve the performance of fine-tuned
    LLM-based agents.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '上述设计仅保证生成计划的有效性。例如，图[5](#S4.F5 "图 5 ‣ 4.3 Formal-LLM Prompts and Planning from
    Automaton ‣ 4 The Formal-LLM Framework ‣ Formal-LLM: Integrating Formal Language
    and Natural Language for Controllable LLM-based Agents")中显示的计划$e_{1}a_{1}ib_{1}i$是任务“给定模糊的灰度图像，如何一步步返回对象名称”的可执行计划。然而，这可能不是最优计划。因此，作为计划质量的额外提升，特别是在使用开源LLMs时，我们在应用Formal-LLM框架后，集成了基于任务反馈的强化学习（RLTF）（Ge
    et al., [2023a](#bib.bib13)）。在LLM-based代理生成训练任务计划后，计划在基准数据上执行以评估其性能。然后，将性能作为强化学习（RL）的奖励来更新LLM的参数。我们的框架确保在LLM-based代理的计划生成过程中始终排除无效计划。因此，有效奖励的数量增加，且我们的方法可以提高微调LLM-based代理的性能。'
- en: 5 Experiments
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 个实验
- en: 5.1 Backbone LLMs
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 主干LLMs
- en: 'We test our Formal-LLM framework on both closed-source and open-source LLMs.
    Closed-source LLMs include:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在闭源和开源LLMs上测试了我们的Formal-LLM框架。闭源LLMs包括：
- en: •
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: GPT-3.5-turbo (Brown et al., [2020](#bib.bib3)) is a generative pre-trained
    transformer of OpenAI with a strong ability of various language tasks based on
    instructions.
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: GPT-3.5-turbo（Brown et al., [2020](#bib.bib3)）是OpenAI的生成预训练变换器，具有基于指令的各种语言任务的强大能力。
- en: •
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Claude-2 (Claude-2, [2023](#bib.bib9)) is a transformer LLM of Anthropic trained
    with unsupervised learning and Reinforcement Learning from Human Feedback (RLHF).
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Claude-2（Claude-2，[2023](#bib.bib9)）是Anthropic训练的变换器LLM，采用无监督学习和来自人类反馈的强化学习（RLHF）。
- en: •
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: GPT-4 (OpenAI, [2023](#bib.bib30)) is a follow-up version of GPT-3.5, which
    is more powerful than its predecessors.
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: GPT-4（OpenAI，[2023](#bib.bib30)）是GPT-3.5的后续版本，比其前身更强大。
- en: 'Open-source LLMs include:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 开源LLMs包括：
- en: •
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Flan-T5-Large (Chung et al., [2022](#bib.bib8)) is an encoder-decoder language
    model with 770 million parameters, pre-trained by instruction fine-tuning.
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Flan-T5-Large（Chung et al., [2022](#bib.bib8)）是一个具有7.7亿参数的编码器-解码器语言模型，通过指令微调进行预训练。
- en: •
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Vicuna-7B (Chiang et al., [2023](#bib.bib7)) is a decoder-only chatbot trained
    by fine-tuning the LLaMA model (Touvron et al., [2023a](#bib.bib40)) with user-shared
    conversations.
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Vicuna-7B（Chiang et al., [2023](#bib.bib7)）是一个仅解码器的聊天机器人，通过微调LLaMA模型（Touvron
    et al., [2023a](#bib.bib40)）与用户共享对话进行训练。
- en: •
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: LLaMA-2 (Touvron et al., [2023b](#bib.bib41)) is a successor to the original
    LLaMA model. It is a more powerful language model. In this work, we use the 13-billion
    size model.
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LLaMA-2（Touvron et al., [2023b](#bib.bib41)）是原始LLaMA模型的继任者。它是一个更强大的语言模型。在这项工作中，我们使用13亿参数的模型。
- en: 5.2 Learning Schema of LLMs
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 LLM学习模式
- en: 'We adopt the following LLM learning schema:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们采用以下LLM学习模式：
- en: •
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Zero-shot Learning (Zero) directly inputs the prompt to the LLM.
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 零样本学习（Zero）直接将提示输入到LLM中。
- en: •
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Few-shot Learning (Few) presents a set of high-quality demonstrations in the
    prompt, each consisting of both input and desired output on the target task.
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 少量样本学习（Few）在提示中提供一组高质量的演示，每个演示都包括输入和目标任务的期望输出。
- en: •
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Reinforcement Learning from Task Feedback (RLTF) executes a plan and takes its
    performance as the reward to optimize the LLM through an RL process.
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 任务反馈中的强化学习（RLTF）执行一个计划，并将其表现作为奖励来优化LLM，通过RL过程进行优化。
- en: •
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Formal-LLM (F-LLM) is our proposed framework, leveraging automaton to control
    the LLM’s generation.
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Formal-LLM（F-LLM）是我们提出的框架，利用自动机控制LLM的生成。
- en: •
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Formal-LLM plus RLTF (F-LLM+RLTF) applies our Formal-LLM framework on top of
    RLTF, which excludes invalid plans and increases the amount of valid rewards for
    RLTF.
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Formal-LLM加RLTF（F-LLM+RLTF）在RLTF基础上应用我们的Formal-LLM框架，排除无效计划并增加RLTF的有效奖励数量。
- en: Specifically, we utilize Zero, Few, and F-LLM frameworks for closed-source LLMs,
    as these frameworks do not need to modify the LLM’s parameters. Regarding open-source
    LLMs, we compare RLTF, F-LLM and F-LLM+RLTF, given that the RLTF method surpasses
    Zero and Few, as exhaustively discussed in recent work (Ge et al., [2023a](#bib.bib13)).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 具体而言，我们利用Zero、Few和F-LLM框架用于封闭源LLM，因为这些框架不需要修改LLM的参数。对于开源LLM，我们比较RLTF、F-LLM和F-LLM+RLTF，考虑到RLTF方法超过了Zero和Few，正如最近的研究（Ge
    et al., [2023a](#bib.bib13)）中详细讨论的那样。
- en: 5.3 Experimentation Datasets
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 实验数据集
- en: 5.3.1 Benchmark Datasets
  id: totrans-102
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.1 基准数据集
- en: 'For the benchmark experiment, we utilize the tools and multi-step tasks in
    the OpenAGI platform (Ge et al., [2023a](#bib.bib13)). The tools are detailed
    in Table [3](#A2.T3 "Table 3 ‣ B.1 Bechmark Tasks and Tools ‣ Appendix B Appendix
    ‣ Formal-LLM: Integrating Formal Language and Natural Language for Controllable
    LLM-based Agents") in the Appendix, and the tasks are categorized based on their
    output type and ground-truth label type (Task 1, 2, and 3). Then, based on different
    task types, different metrics are employed to gauge the performance: CLIP Score
    (Hessel et al., [2021](#bib.bib19)), assessing the similarity between text and
    image, is utilized for Text-to-Image tasks; BERT Score (Zhang et al., [2020](#bib.bib50)),
    evaluating text generation with BERT, is applied when both data labels and the
    expected outputs are texts; and ViT Score (Wu et al., [2020](#bib.bib45)) gauges
    the similarity between the image label and image output. Additionally, we construct
    Task X, which is a subset of “Task 1 $\cup$ Task 3” that require tree-structured
    plan rather than chain-structured plan due to the use of many-input-single-ouput
    tools, such as Visual Question Answering. Task X is used to test the complex planning
    ability of our Formal-LLM framework. The data samples in Task X are evaluated
    using their corresponding metric. Example tasks of each category are illustrated
    in Table [4](#A2.T4 "Table 4 ‣ B.3 Prompt for Benchmark Tasks ‣ Appendix B Appendix
    ‣ Formal-LLM: Integrating Formal Language and Natural Language for Controllable
    LLM-based Agents") in the Appendix.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '在基准实验中，我们利用OpenAGI平台中的工具和多步骤任务（Ge et al., [2023a](#bib.bib13)）。工具的详细信息见附录中的表[3](#A2.T3
    "Table 3 ‣ B.1 Bechmark Tasks and Tools ‣ Appendix B Appendix ‣ Formal-LLM: Integrating
    Formal Language and Natural Language for Controllable LLM-based Agents")，任务根据其输出类型和真实标签类型（任务1、2和3）进行分类。然后，根据不同的任务类型，采用不同的指标来评估性能：CLIP得分（Hessel
    et al., [2021](#bib.bib19)），评估文本和图像之间的相似性，用于文本到图像任务；BERT得分（Zhang et al., [2020](#bib.bib50)），利用BERT评估文本生成，应用于数据标签和期望输出都是文本的情况；ViT得分（Wu
    et al., [2020](#bib.bib45)）评估图像标签和图像输出之间的相似性。此外，我们构建了任务X，这是“任务1 $\cup$ 任务3”的一个子集，由于使用了多输入单输出工具（例如视觉问答），因此需要树状计划而非链状计划。任务X用于测试我们的Formal-LLM框架的复杂规划能力。任务X中的数据样本使用其对应的指标进行评估。每个类别的示例任务在附录中的表[4](#A2.T4
    "Table 4 ‣ B.3 Prompt for Benchmark Tasks ‣ Appendix B Appendix ‣ Formal-LLM:
    Integrating Formal Language and Natural Language for Controllable LLM-based Agents")中有所说明。'
- en: 5.3.2 Real-life Practical Tasks
  id: totrans-104
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.2 现实生活中的实际任务
- en: We also experiment with real-life planning scenarios, encompassing daily plans,
    cooking recipes, and risk management, where validity and rationality are crucial.
    In these scenarios, the concept of tool is generalized to include various types
    of steps in a plan, such as events, actions, or activities, as they can take diverse
    forms supporting the execution of the plan. For example, a tool in the daily planning
    task may be an activity such as taking breakfast. We provide qualitative analyses
    between the Zero and F-LLM learning schema using GPT-4 backbone for practical
    tasks. We use GPT-4 for the experiment of practical tasks because other LLMs can
    hardly generate readable plans for these tasks, and we test under Zero and F-LLM
    due to the limited sample size and that these two learning frameworks do not require
    fine-tuning or accessing to the LLM parameters.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还在现实生活规划场景中进行了实验，包括日常计划、烹饪食谱和风险管理，其中有效性和合理性至关重要。在这些场景中，“工具”的概念被推广，以包括计划中的各种步骤，例如事件、行动或活动，因为它们可以采取不同形式来支持计划的执行。例如，在日常计划任务中，工具可以是诸如吃早餐这样的活动。我们提供了使用
    GPT-4 骨干的 Zero 和 F-LLM 学习模式的定性分析。我们使用 GPT-4 进行实际任务实验，因为其他 LLM 很难生成这些任务的可读计划，并且我们在
    Zero 和 F-LLM 下进行测试，因样本量有限且这两种学习框架不需要微调或访问 LLM 参数。
- en: '| Metrics / Task | GPT-3.5-turbo | Claude-2 | GPT-4 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 指标 / 任务 | GPT-3.5-turbo | Claude-2 | GPT-4 |'
- en: '| Zero | Few | F-LLM (Ours) | Zero | Few | F-LLM (Ours) | Zero | Few | F-LLM
    (Ours) |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| Zero | Few | F-LLM (我们) | Zero | Few | F-LLM (我们) | Zero | Few | F-LLM (我们)
    |'
- en: '| % of Valid Plans | 29% | 71% | 100% | 29% | 47% | 100% | 53% | 76% | 100%
    |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 有效计划百分比 | 29% | 71% | 100% | 29% | 47% | 100% | 53% | 76% | 100% |'
- en: '| Task 1 (CLIP Score) | 0.0 | 0.0 | 0.3056 | 0.0 | 0.2543 | 0.3056 | 0.0 |
    0.3055 | 0.3056 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 任务 1 (CLIP 分数) | 0.0 | 0.0 | 0.3056 | 0.0 | 0.2543 | 0.3056 | 0.0 | 0.3055
    | 0.3056 |'
- en: '| Task 2 (BERT Score) | 0.1914 | 0.3820 | 0.6364 | 0.2111 | 0.5038 | 0.6275
    | 0.2076 | 0.6307 | 0.5102 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 任务 2 (BERT 分数) | 0.1914 | 0.3820 | 0.6364 | 0.2111 | 0.5038 | 0.6275 | 0.2076
    | 0.6307 | 0.5102 |'
- en: '| Task 3 (ViT Score) | 0.2437 | 0.7497 | 0.6470 | 0.4082 | 0.5416 | 0.7137
    | 0.5058 | 0.6480 | 0.7689 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 任务 3 (ViT 分数) | 0.2437 | 0.7497 | 0.6470 | 0.4082 | 0.5416 | 0.7137 | 0.5058
    | 0.6480 | 0.7689 |'
- en: '| Task X | 0.0 | 0.0 | 0.0658 | 0.0 | 0.0 | 0.2799 | 0.0 | 0.0 | 0.2876 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 任务 X | 0.0 | 0.0 | 0.0658 | 0.0 | 0.0 | 0.2799 | 0.0 | 0.0 | 0.2876 |'
- en: '| Average over tasks | 0.1443 | 0.3345 | 0.4846 | 0.1838 | 0.3773 | 0.5420
    | 0.1992 | 0.4662 | 0.4914 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 任务平均 | 0.1443 | 0.3345 | 0.4846 | 0.1838 | 0.3773 | 0.5420 | 0.1992 | 0.4662
    | 0.4914 |'
- en: 'Table 1: Benchmark task performances under different settings for three closed-source
    LLMs. Zero is for Zero-shot Learning, Few is for Few-shot Learning, and F-LLM
    is for Formal-LLM. The boldface numbers denote the highest score under each task
    type using the same LLM.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：三种闭源 LLM 在不同设置下的基准任务表现。Zero 表示零样本学习，Few 表示少样本学习，F-LLM 表示正式 LLM。粗体数字表示在每个任务类型下使用相同
    LLM 的最高分数。
- en: '| Metrics / Tasks | Flan-T5-Large | Vicuna-7B | LLaMA-2-13B |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 指标 / 任务 | Flan-T5-Large | Vicuna-7B | LLaMA-2-13B |'
- en: '| RLTF | F-LLM | F-LLM+RLTF | RLTF | F-LLM | F-LLM+RLTF | RLTF | F-LLM | F-LLM+RLTF
    |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| RLTF | F-LLM | F-LLM+RLTF | RLTF | F-LLM | F-LLM+RLTF | RLTF | F-LLM | F-LLM+RLTF
    |'
- en: '| % of Valid Plans | 24% | 100% | 100% | 29% | 100% | 100% | 47% | 100% | 100%
    |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 有效计划百分比 | 24% | 100% | 100% | 29% | 100% | 100% | 47% | 100% | 100% |'
- en: '| Task 1 (CLIP Score) | 0.0 | 0.3049 | 0.3049 | 0.0 | 0.3122 | 0.3139 | 0.0610
    | 0.1601 | 0.3060 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 任务 1 (CLIP 分数) | 0.0 | 0.3049 | 0.3049 | 0.0 | 0.3122 | 0.3139 | 0.0610 |
    0.1601 | 0.3060 |'
- en: '| Task 2 (BERT Score) | 0.3327 | 0.5164 | 0.5287 | 0.1475 | 0.4948 | 0.4673
    | 0.1611 | 0.4220 | 0.5565 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 任务 2 (BERT 分数) | 0.3327 | 0.5164 | 0.5287 | 0.1475 | 0.4948 | 0.4673 | 0.1611
    | 0.4220 | 0.5565 |'
- en: '| Task 3 (ViT Score) | 0.6632 | 0.6264 | 0.7469 | 0.6958 | 0.5948 | 0.8618
    | 0.7106 | 0.7043 | 0.6808 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 任务 3 (ViT 分数) | 0.6632 | 0.6264 | 0.7469 | 0.6958 | 0.5948 | 0.8618 | 0.7106
    | 0.7043 | 0.6808 |'
- en: '| Task X | 0.0 | 0.0728 | 0.4046 | 0.0 | 0.4127 | 0.4029 | 0.0 | 0.3846 | 0.4163
    |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 任务 X | 0.0 | 0.0728 | 0.4046 | 0.0 | 0.4127 | 0.4029 | 0.0 | 0.3846 | 0.4163
    |'
- en: '| Average over tasks | 0.3111 | 0.4451 | 0.5321 | 0.2009 | 0.4824 | 0.5162
    | 0.3101 | 0.4498 | 0.5390 |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 任务平均 | 0.3111 | 0.4451 | 0.5321 | 0.2009 | 0.4824 | 0.5162 | 0.3101 | 0.4498
    | 0.5390 |'
- en: 'Table 2: Benchmark task performances under different settings for three open-source
    LLMs. RLTF is for Reinforcement Learning from Task Feedback, F-LLM is for Formal-LLM,
    and F-LLM+RLTF is for using the generated plans by F-LLM to calculate the reward
    for RLTF. The boldface numbers denote the highest score under each task type using
    the same LLM.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：三种开源 LLM 在不同设置下的基准任务表现。RLTF 代表从任务反馈中进行强化学习，F-LLM 代表正式 LLM，F-LLM+RLTF 代表使用
    F-LLM 生成的计划来计算 RLTF 的奖励。粗体数字表示在每个任务类型下使用相同 LLM 的最高分数。
- en: 5.4 Experimental Analysis
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 实验分析
- en: 'The experiment results on the benchmark tasks are shown in Table [1](#S5.T1
    "Table 1 ‣ 5.3.2 Real-life Practical Tasks ‣ 5.3 Experimentation Datasets ‣ 5
    Experiments ‣ Formal-LLM: Integrating Formal Language and Natural Language for
    Controllable LLM-based Agents") and Table [2](#S5.T2 "Table 2 ‣ 5.3.2 Real-life
    Practical Tasks ‣ 5.3 Experimentation Datasets ‣ 5 Experiments ‣ Formal-LLM: Integrating
    Formal Language and Natural Language for Controllable LLM-based Agents"), referring
    to the closed-source and open-source LLMs, respectively. Each row stands for a
    type of task, each column represents the learning schema of an LLM-based agent,
    and every three columns are the results of the same LLM. For closed-source LLMs,
    among the three learning schemata without revising the LLM parameter, almost all
    the best scores under each type of task belong to our F-LLM framework. For open-source
    LLMs, our F-LLM without fine-tuning is already better than RLTF (the best schema
    in the OpenAGI platform (Ge et al., [2023a](#bib.bib13))) in most cases, except
    for the ViT Score (Task 3), because the Type-3 tasks take the most significant
    portion of the RLTF’s fine-tuning data, and thus RLTF is adequately optimized
    on these tasks. The performance gain of our F-LLM framework comes from the 100%
    executable plans and supporting tree-structured planning for the difficult tasks
    in Task X. As a comparison, the best open-source LLM (LLaMA-2-13B with RLTF) can
    only generate 47% executable plans, and the best closed-source LLM (GPT-4 with
    few shot) can generate 76% executable plans. Additionally, none of the baselines
    can handle the Task X (Score = 0.0). Fortunately, due to the increased amounts
    of valid rewards from the 100% executable plans with our F-LLM framework, the
    F-LLM+RLTF approach enables boosted performance, as demonstrated by its better
    scores in Table [2](#S5.T2 "Table 2 ‣ 5.3.2 Real-life Practical Tasks ‣ 5.3 Experimentation
    Datasets ‣ 5 Experiments ‣ Formal-LLM: Integrating Formal Language and Natural
    Language for Controllable LLM-based Agents").'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '基准任务上的实验结果见表格 [1](#S5.T1 "Table 1 ‣ 5.3.2 Real-life Practical Tasks ‣ 5.3 Experimentation
    Datasets ‣ 5 Experiments ‣ Formal-LLM: Integrating Formal Language and Natural
    Language for Controllable LLM-based Agents") 和表格 [2](#S5.T2 "Table 2 ‣ 5.3.2 Real-life
    Practical Tasks ‣ 5.3 Experimentation Datasets ‣ 5 Experiments ‣ Formal-LLM: Integrating
    Formal Language and Natural Language for Controllable LLM-based Agents")，分别对应闭源和开源的LLM。每一行代表一种任务类型，每一列代表LLM代理的学习模式，每三列为同一LLM的结果。对于闭源LLM，在三个学习模式中不修正LLM参数的情况下，几乎所有任务类型下的最佳得分都属于我们的F-LLM框架。对于开源LLM，我们的F-LLM在没有微调的情况下已经比RLTF（OpenAGI平台上最佳的学习模式（Ge
    et al., [2023a](#bib.bib13)））更好，除非在ViT Score（任务3）上，因为Type-3任务占用了RLTF微调数据的最大部分，因此RLTF在这些任务上得到了充分优化。我们F-LLM框架的性能提升来自于100%可执行计划和对任务X中困难任务的支持树状规划。相比之下，最佳的开源LLM（LLaMA-2-13B与RLTF）只能生成47%可执行计划，而最佳的闭源LLM（GPT-4与少量示例）可以生成76%可执行计划。此外，没有一个基线方法能够处理任务X（得分=0.0）。幸运的是，由于F-LLM框架中100%可执行计划带来的有效奖励增加，F-LLM+RLTF方法实现了性能的提升，如表格
    [2](#S5.T2 "Table 2 ‣ 5.3.2 Real-life Practical Tasks ‣ 5.3 Experimentation Datasets
    ‣ 5 Experiments ‣ Formal-LLM: Integrating Formal Language and Natural Language
    for Controllable LLM-based Agents")中的更好得分所示。'
- en: To summarize, the benchmark experiment results show that our F-LLM framework
    is an effective method to integrate the benefits of both natural and formal languages
    for more controllable and valid planning of LLM-based agents.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，基准实验结果表明，我们的F-LLM框架是一种有效的方法，能够将自然语言和形式语言的优势整合起来，从而实现对基于LLM的代理的更可控和有效的规划。
- en: 5.5 Case Study
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5 案例研究
- en: We also show the results of real-life examples by applying our Formal-LLM to
    the GPT models. Due to the page limit, we put the complete results in the Appendix.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还通过将我们的Formal-LLM应用于GPT模型来展示实际案例的结果。由于页面限制，我们将完整的结果放在了附录中。
- en: 'From our observation, after applying our Formal-LLM, the generated plan from
    the GPT-based agent is more complete, reasonable and specific to the case. In
    the daily plan example, the agent fails to fit all the activities into the plan
    without the Formal-LLM, while it can achieve this goal by applying the Formal-LLM.
    Still take Figure [4](#S4.F4 "Figure 4 ‣ 4.3 Formal-LLM Prompts and Planning from
    Automaton ‣ 4 The Formal-LLM Framework ‣ Formal-LLM: Integrating Formal Language
    and Natural Language for Controllable LLM-based Agents") as an example, our Formal-LLM
    framework can limit the planning to 10:00$\sim$20:00, while without Formal-LLM,
    the agent schedules activities after 20:00, even if we mention the constraint
    “Generate a plan for all the activities between 10:00 and 20:00” in natural language,
    which shows the advantages of formal language guided planning. For the cooking
    recipe example, without strict automaton constraint, GPT may generate steps such
    as “stir-fry the Chinese broccoli until it changes color” after “once the water
    boils, add the Chinese broccoli”. This is unreasonable because it’s impossible
    to stir-fry when broccoli is in boiling water. As for the risk management example,
    the generated plan without our framework is too general that it could be used
    for any other two companies. However, the plan after applying Formal-LLM is more
    specific and focuses on the potential antitrust risk between Microsoft and Blizzard.
    Thus, after applying the automaton which describes the constraints, the generated
    plan has better quality under the Formal-LLM framework.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '从我们的观察来看，应用Formal-LLM后，GPT-based代理生成的计划更完整、合理且针对具体情况。在日常计划示例中，代理在没有Formal-LLM的情况下无法将所有活动纳入计划，而使用Formal-LLM则能实现这一目标。仍以图[4](#S4.F4
    "Figure 4 ‣ 4.3 Formal-LLM Prompts and Planning from Automaton ‣ 4 The Formal-LLM
    Framework ‣ Formal-LLM: Integrating Formal Language and Natural Language for Controllable
    LLM-based Agents")为例，我们的Formal-LLM框架可以将规划限制在10:00$\sim$20:00之间，而没有Formal-LLM时，即便我们在自然语言中提到“生成一个10:00到20:00之间的活动计划”，代理也会安排20:00之后的活动，这显示了正式语言指导规划的优势。以烹饪食谱为例，没有严格的自动机约束，GPT可能会生成“将中国芥蓝炒至变色”这种步骤，接在“水煮沸后，加入中国芥蓝”之后。这是不合理的，因为在水煮沸的情况下无法进行炒菜。至于风险管理示例，应用我们框架后的生成计划更具针对性，专注于微软和动视暴雪之间的潜在反垄断风险，而没有我们框架的计划则过于笼统，可能适用于任何两家公司。因此，应用描述约束的自动机后，在Formal-LLM框架下生成的计划质量更高。'
- en: 6 Conclusions and Future Work
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论与未来工作
- en: In this study, we introduce the innovative Formal-LLM framework for LLM-based
    agents, combining LLM’s power of natural language comprehension with the precision
    of formal language. Our experiments, encompassing benchmark tasks and real-life
    practical scenarios, affirm the feasibility and effectiveness of employing automaton
    to control the agent’s generation of valid plans. More controllable LLM-based
    agents can augment the potential utilization of LLM in applications where high
    validity of planning holds significant importance.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们介绍了创新的Formal-LLM框架，用于基于LLM的代理，结合了LLM自然语言理解的能力和正式语言的精确性。我们的实验，包括基准任务和实际应用场景，验证了使用自动机来控制代理生成有效计划的可行性和有效性。更可控的基于LLM的代理可以增加LLM在高效规划应用中的潜在利用。
- en: Several potential extensions to our work merit consideration. First, automating
    the translation of natural language into formal language for agents could further
    improve the framework, as designing formal language and automata by domain experts
    may not be the most efficient approach. Additionally, this work focuses on LLM
    plan generation based on formal language; however, another important problem to
    explore in the future is LLM plan verification based on formal language. Furthermore,
    our framework uses one large automaton to control the whole planning process,
    while another potential solution is to use multiple small automata, each describing
    one constraint, and the agent only accesses the corresponding one when needed
    during plan generation.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的工作有几个潜在的扩展方向值得考虑。首先，将自然语言自动转换为正式语言的过程可能会进一步提升框架的效果，因为由领域专家设计正式语言和自动机可能不是最有效的方法。此外，这项工作专注于基于正式语言的LLM计划生成；然而，未来需要探索的另一个重要问题是基于正式语言的LLM计划验证。此外，我们的框架使用一个大型自动机来控制整个规划过程，而另一种潜在的解决方案是使用多个小型自动机，每个自动机描述一个约束，代理在生成计划时仅在需要时访问对应的自动机。
- en: References
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: Boiko et al. (2023) Daniil A. Boiko, Robert MacKnight, and Gabe Gomes. 2023.
    Emergent autonomous scientific research capabilities of large language models.
    arXiv:2304.05332 [physics.chem-ph]
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Boiko 等（2023）Daniil A. Boiko, Robert MacKnight 和 Gabe Gomes。2023年。《大语言模型的突现自主科学研究能力》。arXiv:2304.05332
    [physics.chem-ph]
- en: Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D
    Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
    Askell, et al. 2020. Language models are few-shot learners. *Advances in neural
    information processing systems* 33 (2020), 1877–1901.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown 等（2020）Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D
    Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
    Askell 等。2020年。《语言模型是少样本学习者》。*神经信息处理系统进展* 33（2020），1877–1901。
- en: Carion et al. (2020) Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas
    Usunier, Alexander Kirillov, and Sergey Zagoruyko. 2020. End-to-end object detection
    with transformers. In *European conference on computer vision*. Springer, 213–229.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Carion 等（2020）Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier,
    Alexander Kirillov 和 Sergey Zagoruyko。2020年。《使用变换器进行端到端目标检测》。在 *欧洲计算机视觉会议* 中。Springer,
    213–229。
- en: 'Carlsson et al. (2022) Fredrik Carlsson, Joey Öhman, Fangyu Liu, Severine Verlinden,
    Joakim Nivre, and Magnus Sahlgren. 2022. Fine-grained controllable text generation
    using non-residual prompting. In *Proceedings of the 60th Annual Meeting of the
    Association for Computational Linguistics (Volume 1: Long Papers)*. 6837–6857.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Carlsson 等（2022）Fredrik Carlsson, Joey Öhman, Fangyu Liu, Severine Verlinden,
    Joakim Nivre 和 Magnus Sahlgren。2022年。《使用非残差提示的细粒度可控文本生成》。在 *第60届计算语言学协会年会论文集（第1卷：长篇论文）*
    中。6837–6857。
- en: Chen et al. (2024) Yihan Chen, Benfeng Xu, Quan Wang, Yi Liu, and Zhendong Mao.
    2024. Benchmarking Large Language Models on Controllable Generation under Diversified
    Instructions. arXiv:2401.00690 [cs.CL]
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等（2024）Yihan Chen, Benfeng Xu, Quan Wang, Yi Liu 和 Zhendong Mao。2024年。《在多样化指令下对大语言模型进行可控生成的基准测试》。arXiv:2401.00690
    [cs.CL]
- en: 'Chiang et al. (2023) Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao
    Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E Gonzalez,
    et al. 2023. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt
    quality.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chiang 等（2023）Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao
    Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E Gonzalez 等。2023年。《Vicuna：一个开源聊天机器人，令GPT-4印象深刻，质量达到90%*的ChatGPT*水平》。
- en: Chung et al. (2022) Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi
    Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma,
    et al. 2022. Scaling instruction-finetuned language models. arXiv:2210.11416 [cs.LG]
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chung 等（2022）Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William
    Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma 等。2022年。《扩展指令微调语言模型》。arXiv:2210.11416
    [cs.LG]
- en: Claude-2 (2023) Claude-2\. 2023. Model card and evaluations for claude models.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Claude-2（2023）Claude-2。2023年。《Claude模型的模型卡和评估》。
- en: 'Conde et al. (2022) Marcos V Conde, Ui-Jin Choi, Maxime Burchi, and Radu Timofte.
    2022. Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration.
    In *European Conference on Computer Vision*. 669–687.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Conde 等（2022）Marcos V Conde, Ui-Jin Choi, Maxime Burchi 和 Radu Timofte。2022年。《Swin2SR：用于压缩图像超分辨率和恢复的SwinV2变换器》。在
    *欧洲计算机视觉会议* 中。669–687。
- en: 'Dosovitskiy et al. (2021) Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,
    Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias
    Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. 2021.
    An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. *ICLR*
    (2021).'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dosovitskiy 等（2021）Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk
    Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer,
    Georg Heigold, Sylvain Gelly, Jakob Uszkoreit 和 Neil Houlsby。2021年。《一张图胜过16x16个词：用于大规模图像识别的变换器》。*ICLR*（2021）。
- en: Franceschelli and Musolesi (2023) Giorgio Franceschelli and Mirco Musolesi.
    2023. On the Creativity of Large Language Models. arXiv:2304.00008 [cs.AI]
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Franceschelli 和 Musolesi（2023）Giorgio Franceschelli 和 Mirco Musolesi。2023年。《大语言模型的创造力》。arXiv:2304.00008
    [cs.AI]
- en: 'Ge et al. (2023a) Yingqiang Ge, Wenyue Hua, Kai Mei, Jianchao Ji, Juntao Tan,
    Shuyuan Xu, Zelong Li, and Yongfeng Zhang. 2023a. OpenAGI: When LLM Meets Domain
    Experts. In *Thirty-seventh Conference on Neural Information Processing Systems*.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ge 等（2023a）Yingqiang Ge, Wenyue Hua, Kai Mei, Jianchao Ji, Juntao Tan, Shuyuan
    Xu, Zelong Li 和 Yongfeng Zhang。2023a年。《OpenAGI：当LLM遇见领域专家》。在 *第37届神经信息处理系统会议*
    中。
- en: 'Ge et al. (2023b) Yingqiang Ge, Yujie Ren, Wenyue Hua, Shuyuan Xu, Juntao Tan,
    and Yongfeng Zhang. 2023b. LLM as OS, Agents as Apps: Envisioning AIOS, Agents
    and the AIOS-Agent Ecosystem. *arXiv* (2023).'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ge 等（2023b）Yingqiang Ge, Yujie Ren, Wenyue Hua, Shuyuan Xu, Juntao Tan 和 Yongfeng
    Zhang。2023b年。《LLM 作为操作系统，代理作为应用：设想AIOS、代理和AIOS-代理生态系统》。*arXiv*（2023）。
- en: Geng et al. (2024) Saibo Geng, Berkay Döner, Chris Wendler, Martin Josifoski,
    and Robert West. 2024. Sketch-Guided Constrained Decoding for Boosting Blackbox
    Large Language Models without Logit Access. *arXiv preprint arXiv:2401.09967*
    (2024).
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Geng et al. (2024) Saibo Geng, Berkay Döner, Chris Wendler, Martin Josifoski,
    和 Robert West. 2024. Sketch-Guided Constrained Decoding for Boosting Blackbox
    Large Language Models without Logit Access. *arXiv 预印本 arXiv:2401.09967* (2024)。
- en: Geng et al. (2023) Saibo Geng, Martin Josifoski, Maxime Peyrard, and Robert
    West. 2023. Grammar-constrained decoding for structured NLP tasks without finetuning.
    In *Proceedings of the 2023 Conference on Empirical Methods in Natural Language
    Processing*. 10932–10952.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Geng et al. (2023) Saibo Geng, Martin Josifoski, Maxime Peyrard, 和 Robert West.
    2023. Grammar-constrained decoding for structured NLP tasks without finetuning.
    见于 *2023年自然语言处理实证方法会议论文集*，10932–10952。
- en: Gu et al. (2022) Yuxuan Gu, Xiaocheng Feng, Sicheng Ma, Lingyuan Zhang, Heng
    Gong, and Bing Qin. 2022. A Distributional Lens for Multi-Aspect Controllable
    Text Generation. In *Proceedings of the 2022 Conference on Empirical Methods in
    Natural Language Processing*, Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang
    (Eds.). Association for Computational Linguistics, Abu Dhabi, United Arab Emirates,
    1023–1043. [https://doi.org/10.18653/v1/2022.emnlp-main.67](https://doi.org/10.18653/v1/2022.emnlp-main.67)
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gu et al. (2022) Yuxuan Gu, Xiaocheng Feng, Sicheng Ma, Lingyuan Zhang, Heng
    Gong, 和 Bing Qin. 2022. A Distributional Lens for Multi-Aspect Controllable Text
    Generation. 见于 *2022年自然语言处理实证方法会议论文集*，Yoav Goldberg, Zornitsa Kozareva, 和 Yue
    Zhang（编辑）。计算语言学协会，阿布扎比，阿拉伯联合酋长国，1023–1043。 [https://doi.org/10.18653/v1/2022.emnlp-main.67](https://doi.org/10.18653/v1/2022.emnlp-main.67)
- en: 'Hemmer et al. (2023) Arthur Hemmer, Mickael Coustaty, Nicola Bartolo, Jerome
    Brachat, and Jean-Marc Ogier. 2023. Lazy-k Decoding: Constrained Decoding for
    Information Extraction. In *Proceedings of the 2023 Conference on Empirical Methods
    in Natural Language Processing*. 6727–6736.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hemmer et al. (2023) Arthur Hemmer, Mickael Coustaty, Nicola Bartolo, Jerome
    Brachat, 和 Jean-Marc Ogier. 2023. Lazy-k Decoding: Constrained Decoding for Information
    Extraction. 见于 *2023年自然语言处理实证方法会议论文集*，6727–6736。'
- en: 'Hessel et al. (2021) Jack Hessel, Ari Holtzman, Maxwell Forbes, Ronan Le Bras,
    and Yejin Choi. 2021. CLIPScore: A Reference-free Evaluation Metric for Image
    Captioning.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hessel et al. (2021) Jack Hessel, Ari Holtzman, Maxwell Forbes, Ronan Le Bras,
    和 Yejin Choi. 2021. CLIPScore: A Reference-free Evaluation Metric for Image Captioning.'
- en: Hopcroft et al. (2001) John E Hopcroft, Rajeev Motwani, and Jeffrey D Ullman.
    2001. Introduction to automata theory, languages, and computation. *Acm Sigact
    News* 32, 1 (2001), 60–65.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hopcroft et al. (2001) John E Hopcroft, Rajeev Motwani, 和 Jeffrey D Ullman.
    2001. Introduction to automata theory, languages, and computation. *Acm Sigact
    News* 32, 1 (2001), 60–65.
- en: 'Hu et al. (2021) Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu,
    Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. LoRA: Low-Rank Adaptation
    of Large Language Models. arXiv:2106.09685 [cs.CL]'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hu et al. (2021) Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu,
    Yuanzhi Li, Shean Wang, Lu Wang, 和 Weizhu Chen. 2021. LoRA: Low-Rank Adaptation
    of Large Language Models. arXiv:2106.09685 [cs.CL]'
- en: 'Hua et al. (2023) Wenyue Hua, Lizhou Fan, Lingyao Li, Kai Mei, Jianchao Ji,
    Yingqiang Ge, Libby Hemphill, and Yongfeng Zhang. 2023. War and peace (waragent):
    Large language model-based multi-agent simulation of world wars. *arXiv:2311.17227*
    (2023).'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hua et al. (2023) Wenyue Hua, Lizhou Fan, Lingyao Li, Kai Mei, Jianchao Ji,
    Yingqiang Ge, Libby Hemphill, 和 Yongfeng Zhang. 2023. War and peace (waragent):
    Large language model-based multi-agent simulation of world wars. *arXiv:2311.17227*
    (2023)。'
- en: 'Huang et al. (2022) Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch.
    2022. Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for
    Embodied Agents. In *Proceedings of the 39th International Conference on Machine
    Learning* *(Proceedings of Machine Learning Research, Vol. 162)*, Kamalika Chaudhuri,
    Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato (Eds.).
    PMLR, 9118–9147.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Huang et al. (2022) Wenlong Huang, Pieter Abbeel, Deepak Pathak, 和 Igor Mordatch.
    2022. Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for
    Embodied Agents. 见于 *第39届国际机器学习会议论文集* *(机器学习研究论文集，第162卷)*，Kamalika Chaudhuri,
    Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, 和 Sivan Sabato（编辑）。PMLR，9118–9147。'
- en: 'Lewis et al. (2019) Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad,
    Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer. 2019. BART:
    Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation,
    and Comprehension. arXiv:1910.13461 [cs.CL]'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lewis et al. (2019) Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad,
    Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, 和 Luke Zettlemoyer. 2019. BART:
    Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation,
    and Comprehension. arXiv:1910.13461 [cs.CL]'
- en: 'Li et al. (2023a) Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii
    Khizbullin, and Bernard Ghanem. 2023a. CAMEL: Communicative Agents for "Mind"
    Exploration of Large Language Model Society. In *Thirty-seventh Conference on
    Neural Information Processing Systems*.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li等人 (2023a) Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin,
    和 Bernard Ghanem. 2023a. CAMEL: 面向大型语言模型社会的交流代理的“思维”探索。见 *第三十七届神经信息处理系统会议*。'
- en: Li et al. (2020) Lei Li, Li Chen, and Yongfeng Zhang. 2020. Towards controllable
    explanation generation for recommender systems via neural template. In *Companion
    proceedings of the web conference 2020*. 198–202.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li等人 (2020) Lei Li, Li Chen, 和 Yongfeng Zhang. 2020. 通过神经模板实现推荐系统的可控解释生成。见 *2020年网络会议的补充论文集*。198–202。
- en: 'Li et al. (2023b) Minghao Li, Tengchao Lv, Jingye Chen, Lei Cui, Yijuan Lu,
    Dinei Florencio, Cha Zhang, Zhoujun Li, and Furu Wei. 2023b. Trocr: Transformer-based
    optical character recognition with pre-trained models. In *Proceedings of the
    AAAI Conference on Artificial Intelligence*, Vol. 37\. 13094–13102.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li等人 (2023b) Minghao Li, Tengchao Lv, Jingye Chen, Lei Cui, Yijuan Lu, Dinei
    Florencio, Cha Zhang, Zhoujun Li, 和 Furu Wei. 2023b. Trocr: 基于Transformer的光学字符识别与预训练模型。见
    *AAAI人工智能会议论文集*，第37卷，13094–13102。'
- en: 'Liu et al. (2023) Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu
    Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng,
    Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan
    Sun, Minlie Huang, Yuxiao Dong, and Jie Tang. 2023. AgentBench: Evaluating LLMs
    as Agents. arXiv:2308.03688 [cs.AI]'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu等人 (2023) Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai,
    Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng, Aohan
    Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan Sun,
    Minlie Huang, Yuxiao Dong, 和 Jie Tang. 2023. AgentBench: 评估大型语言模型作为代理的能力。arXiv:2308.03688
    [cs.AI]'
- en: 'Lu et al. (2022) Ximing Lu, Sean Welleck, Jack Hessel, Liwei Jiang, Lianhui
    Qin, Peter West, Prithviraj Ammanabrolu, and Yejin Choi. 2022. Quark: Controllable
    text generation with reinforced unlearning. *Advances in neural information processing
    systems* 35 (2022), 27591–27609.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lu等人 (2022) Ximing Lu, Sean Welleck, Jack Hessel, Liwei Jiang, Lianhui Qin,
    Peter West, Prithviraj Ammanabrolu, 和 Yejin Choi. 2022. Quark: 具有强化去学习的可控文本生成。*神经信息处理系统进展*
    35 (2022)，27591–27609。'
- en: OpenAI (2023) Josh et al OpenAI. 2023. GPT-4 Technical Report. arXiv:2303.08774 [cs.CL]
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI (2023) Josh等人 OpenAI. 2023. GPT-4技术报告。arXiv:2303.08774 [cs.CL]
- en: Qian et al. (2023) Chen Qian, Xin Cong, Wei Liu, Cheng Yang, Weize Chen, Yusheng
    Su, Yufan Dang, Jiahao Li, Juyuan Xu, Dahai Li, Zhiyuan Liu, and Maosong Sun.
    2023. Communicative Agents for Software Development. arXiv:2307.07924 [cs.SE]
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qian等人 (2023) Chen Qian, Xin Cong, Wei Liu, Cheng Yang, Weize Chen, Yusheng
    Su, Yufan Dang, Jiahao Li, Juyuan Xu, Dahai Li, Zhiyuan Liu, 和 Maosong Sun. 2023.
    面向软件开发的交流代理。arXiv:2307.07924 [cs.SE]
- en: 'Qin et al. (2022) Lianhui Qin, Sean Welleck, Daniel Khashabi, and Yejin Choi.
    2022. Cold decoding: Energy-based constrained text generation with langevin dynamics.
    *Advances in Neural Information Processing Systems* 35 (2022), 9538–9551.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Qin等人 (2022) Lianhui Qin, Sean Welleck, Daniel Khashabi, 和 Yejin Choi. 2022.
    Cold decoding: 基于能量的约束文本生成与Langevin动力学。*神经信息处理系统进展* 35 (2022)，9538–9551。'
- en: Qin et al. (2023) Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding,
    Ganqu Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han, Yi Ren Fung, Yusheng
    Su, Huadong Wang, Cheng Qian, Runchu Tian, Kunlun Zhu, Shihao Liang, Xingyu Shen,
    Bokai Xu, Zhen Zhang, Yining Ye, Bowen Li, Ziwei Tang, Jing Yi, Yuzhang Zhu, Zhenning
    Dai, Lan Yan, Xin Cong, Yaxi Lu, Weilin Zhao, Yuxiang Huang, Junxi Yan, Xu Han,
    Xian Sun, Dahai Li, Jason Phang, Cheng Yang, Tongshuang Wu, Heng Ji, Zhiyuan Liu,
    and Maosong Sun. 2023. Tool Learning with Foundation Models. arXiv:2304.08354 [cs.CL]
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qin等人 (2023) Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu
    Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han, Yi Ren Fung, Yusheng Su,
    Huadong Wang, Cheng Qian, Runchu Tian, Kunlun Zhu, Shihao Liang, Xingyu Shen,
    Bokai Xu, Zhen Zhang, Yining Ye, Bowen Li, Ziwei Tang, Jing Yi, Yuzhang Zhu, Zhenning
    Dai, Lan Yan, Xin Cong, Yaxi Lu, Weilin Zhao, Yuxiang Huang, Junxi Yan, Xu Han,
    Xian Sun, Dahai Li, Jason Phang, Cheng Yang, Tongshuang Wu, Heng Ji, Zhiyuan Liu,
    和 Maosong Sun. 2023. 基于基础模型的工具学习。arXiv:2304.08354 [cs.CL]
- en: Radford et al. (2019) Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario
    Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised multitask
    learners. *OpenAI blog* 1, 8 (2019), 9.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Radford等人 (2019) Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei,
    Ilya Sutskever, 等. 2019. 语言模型是无监督的多任务学习者。*OpenAI博客* 1, 8 (2019)，9。
- en: Raffel et al. (2020) Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee,
    Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. Exploring
    the limits of transfer learning with a unified text-to-text transformer. *The
    Journal of Machine Learning Research* 21, 1 (2020), 5485–5551.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raffel et al. (2020) Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee,
    Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, 和 Peter J Liu. 2020. 通过统一的文本到文本转换器探索迁移学习的极限。*机器学习研究期刊*
    21, 1 (2020)，5485–5551。
- en: Rombach et al. (2022) Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick
    Esser, and Björn Ommer. 2022. High-resolution image synthesis with latent diffusion
    models. In *Proceedings of the IEEE/CVF conference on computer vision and pattern
    recognition*. 10684–10695.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rombach et al. (2022) Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick
    Esser, 和 Björn Ommer. 2022. 基于潜在扩散模型的高分辨率图像合成。见 *IEEE/CVF 计算机视觉与模式识别会议论文集*。10684–10695。
- en: 'Sanh et al. (2020) Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas
    Wolf. 2020. DistilBERT, a distilled version of BERT: smaller, faster, cheaper
    and lighter. arXiv:1910.01108 [cs.CL]'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sanh et al. (2020) Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas
    Wolf. 2020. DistilBERT，BERT 的一种精简版本：更小、更快、更便宜、更轻便。arXiv:1910.01108 [cs.CL]
- en: 'Schick et al. (2023) Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu,
    Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023. Toolformer:
    Language Models Can Teach Themselves to Use Tools. arXiv:2302.04761 [cs.CL]'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schick et al. (2023) Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu,
    Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, 和 Thomas Scialom. 2023. Toolformer：语言模型可以自我学习使用工具。arXiv:2302.04761
    [cs.CL]
- en: Takase and Okazaki (2019) Sho Takase and Naoaki Okazaki. 2019. Positional Encoding
    to Control Output Sequence Length. In *Proceedings of the 2019 Conference of the
    North*. Association for Computational Linguistics.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Takase and Okazaki (2019) Sho Takase 和 Naoaki Okazaki. 2019. 控制输出序列长度的位置信息编码。见
    *2019年北方会议论文集*。计算语言学协会。
- en: 'Touvron et al. (2023a) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
    Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal,
    Eric Hambro, Faisal Azhar, et al. 2023a. Llama: Open and efficient foundation
    language models. arXiv:2302.13971 [cs.CL]'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Touvron et al. (2023a) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
    Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal,
    Eric Hambro, Faisal Azhar, et al. 2023a. Llama：开放且高效的基础语言模型。arXiv:2302.13971 [cs.CL]
- en: 'Touvron et al. (2023b) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, et al. 2023b. Llama 2: Open foundation and fine-tuned chat models.
    arXiv:2307.09288 [cs.CL]'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Touvron et al. (2023b) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, et al. 2023b. Llama 2：开放基础与微调聊天模型。arXiv:2307.09288 [cs.CL]
- en: 'Wang et al. (2022) Jianfeng Wang, Zhengyuan Yang, Xiaowei Hu, Linjie Li, Kevin
    Lin, Zhe Gan, Zicheng Liu, Ce Liu, and Lijuan Wang. 2022. GIT: A Generative Image-to-text
    Transformer for Vision and Language. arXiv:2205.14100 [cs.CV]'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. (2022) Jianfeng Wang, Zhengyuan Yang, Xiaowei Hu, Linjie Li, Kevin
    Lin, Zhe Gan, Zicheng Liu, Ce Liu, and Lijuan Wang. 2022. GIT：一种用于视觉和语言的生成图像到文本转换器。arXiv:2205.14100
    [cs.CV]
- en: Wang et al. (2023) Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
    Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei
    Wei, and Ji-Rong Wen. 2023. A Survey on Large Language Model based Autonomous
    Agents. arXiv:2308.11432 [cs.AI]
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. (2023) Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
    Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei
    Wei, 和 Ji-Rong Wen. 2023. 基于大型语言模型的自主代理调查。arXiv:2308.11432 [cs.AI]
- en: Williams (1992) Ronald J Williams. 1992. Simple statistical gradient-following
    algorithms for connectionist reinforcement learning. *Machine learning* 8 (1992),
    229–256.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Williams (1992) Ronald J Williams. 1992. 用于连接主义强化学习的简单统计梯度跟随算法。*机器学习* 8 (1992)，229–256。
- en: 'Wu et al. (2020) Bichen Wu, Chenfeng Xu, Xiaoliang Dai, Alvin Wan, Peizhao
    Zhang, Zhicheng Yan, Masayoshi Tomizuka, Joseph Gonzalez, Kurt Keutzer, and Peter
    Vajda. 2020. Visual Transformers: Token-based Image Representation and Processing
    for Computer Vision. arXiv:2006.03677 [cs.CV]'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu et al. (2020) Bichen Wu, Chenfeng Xu, Xiaoliang Dai, Alvin Wan, Peizhao Zhang,
    Zhicheng Yan, Masayoshi Tomizuka, Joseph Gonzalez, Kurt Keutzer, and Peter Vajda.
    2020. 视觉变换器：基于标记的图像表示和计算机视觉处理。arXiv:2006.03677 [cs.CV]
- en: 'Xi et al. (2023) Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang
    Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan,
    Xiao Wang, Limao Xiong, Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou,
    Xiangyang Liu, Zhangyue Yin, Shihan Dou, Rongxiang Weng, Wensen Cheng, Qi Zhang,
    Wenjuan Qin, Yongyan Zheng, Xipeng Qiu, Xuanjing Huang, and Tao Gui. 2023. The
    Rise and Potential of Large Language Model Based Agents: A Survey. arXiv:2309.07864 [cs.AI]'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xi 等人（2023）Zhiheng Xi、Wenxiang Chen、Xin Guo、Wei He、Yiwen Ding、Boyang Hong、Ming
    Zhang、Junzhe Wang、Senjie Jin、Enyu Zhou、Rui Zheng、Xiaoran Fan、Xiao Wang、Limao Xiong、Yuhao
    Zhou、Weiran Wang、Changhao Jiang、Yicheng Zou、Xiangyang Liu、Zhangyue Yin、Shihan
    Dou、Rongxiang Weng、Wensen Cheng、Qi Zhang、Wenjuan Qin、Yongyan Zheng、Xipeng Qiu、Xuanjing
    Huang 和 Tao Gui。2023。《大型语言模型基础代理的崛起与潜力：一项综述》。arXiv:2309.07864 [cs.AI]
- en: 'Yuan et al. (2024) Siyu Yuan, Kaitao Song, Jiangjie Chen, Xu Tan, Yongliang
    Shen, Ren Kan, Dongsheng Li, and Deqing Yang. 2024. EASYTOOL: Enhancing LLM-based
    Agents with Concise Tool Instruction. *arXiv preprint arXiv:2401.06201* (2024).'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yuan 等人（2024）Siyu Yuan、Kaitao Song、Jiangjie Chen、Xu Tan、Yongliang Shen、Ren Kan、Dongsheng
    Li 和 Deqing Yang。2024。《EASYTOOL：通过简洁工具指令增强基于LLM的代理》。*arXiv 预印本 arXiv:2401.06201*（2024）。
- en: 'Zamir et al. (2022) Syed Waqas Zamir, Aditya Arora, Salman Khan, Munawar Hayat,
    Fahad Shahbaz Khan, and Ming-Hsuan Yang. 2022. Restormer: Efficient transformer
    for high-resolution image restoration. In *Proceedings of the IEEE/CVF conference
    on computer vision and pattern recognition*. 5728–5739.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zamir 等人（2022）Syed Waqas Zamir、Aditya Arora、Salman Khan、Munawar Hayat、Fahad
    Shahbaz Khan 和 Ming-Hsuan Yang。2022。《Restormer：高分辨率图像恢复的高效变换器》。在 *IEEE/CVF计算机视觉与模式识别会议论文集*
    中，5728–5739。
- en: Zhang et al. (2017) Richard Zhang, Jun-Yan Zhu, Phillip Isola, Xinyang Geng,
    Angela S Lin, Tianhe Yu, and Alexei A Efros. 2017. Real-time user-guided image
    colorization with learned deep priors. *ACM Transactions on Graphics (TOG)* 36,
    4 (2017), 1–11.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人（2017）Richard Zhang、Jun-Yan Zhu、Phillip Isola、Xinyang Geng、Angela S
    Lin、Tianhe Yu 和 Alexei A Efros。2017。《实时用户指导的图像着色化，采用学习的深度先验》。*ACM Transactions
    on Graphics (TOG)* 36, 4（2017），1–11。
- en: 'Zhang et al. (2020) Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger,
    and Yoav Artzi. 2020. BERTScore: Evaluating Text Generation with BERT.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人（2020）Tianyi Zhang、Varsha Kishore、Felix Wu、Kilian Q. Weinberger 和 Yoav
    Artzi。2020。《BERTScore：使用BERT评估文本生成》。
- en: Appendix A Impact Statements
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 影响声明
- en: '¹¹footnotetext: [https://github.com/richzhang/colorization](https://github.com/richzhang/colorization)²²footnotetext:
    [https://huggingface.co/caidas/swin2SR-classical-sr-x2-64](https://huggingface.co/caidas/swin2SR-classical-sr-x2-64)³³footnotetext:
    [https://github.com/swz30/Restormer](https://github.com/swz30/Restormer)⁴⁴footnotetext:
    [https://huggingface.co/google/vit-base-patch16-224](https://huggingface.co/google/vit-base-patch16-224)⁵⁵footnotetext:
    [https://huggingface.co/facebook/detr-resnet-101](https://huggingface.co/facebook/detr-resnet-101)⁶⁶footnotetext:
    [https://huggingface.co/nlpconnect/vit-gpt2-image-captioning](https://huggingface.co/nlpconnect/vit-gpt2-image-captioning)⁷⁷footnotetext:
    [https://huggingface.co/CompVis/stable-diffusion-v1-4](https://huggingface.co/CompVis/stable-diffusion-v1-4)⁸⁸footnotetext:
    [https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)⁹⁹footnotetext:
    [https://huggingface.co/facebook/bart-large-cnn](https://huggingface.co/facebook/bart-large-cnn)^(10)^(10)footnotetext:
    [https://huggingface.co/t5-base](https://huggingface.co/t5-base)^(11)^(11)footnotetext:
    [https://huggingface.co/distilbert-base-uncased](https://huggingface.co/distilbert-base-uncased)^(12)^(12)footnotetext:
    [https://huggingface.co/gpt2](https://huggingface.co/gpt2)^(13)^(13)footnotetext:
    [https://huggingface.co/microsoft/git-base-textvqa](https://huggingface.co/microsoft/git-base-textvqa)^(14)^(14)footnotetext:
    [https://huggingface.co/distilbert-base-cased-distilled-squad](https://huggingface.co/distilbert-base-cased-distilled-squad)'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '¹¹脚注文本: [https://github.com/richzhang/colorization](https://github.com/richzhang/colorization)²²脚注文本:
    [https://huggingface.co/caidas/swin2SR-classical-sr-x2-64](https://huggingface.co/caidas/swin2SR-classical-sr-x2-64)³³脚注文本:
    [https://github.com/swz30/Restormer](https://github.com/swz30/Restormer)⁴⁴脚注文本:
    [https://huggingface.co/google/vit-base-patch16-224](https://huggingface.co/google/vit-base-patch16-224)⁵⁵脚注文本:
    [https://huggingface.co/facebook/detr-resnet-101](https://huggingface.co/facebook/detr-resnet-101)⁶⁶脚注文本:
    [https://huggingface.co/nlpconnect/vit-gpt2-image-captioning](https://huggingface.co/nlpconnect/vit-gpt2-image-captioning)⁷⁷脚注文本:
    [https://huggingface.co/CompVis/stable-diffusion-v1-4](https://huggingface.co/CompVis/stable-diffusion-v1-4)⁸⁸脚注文本:
    [https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)⁹⁹脚注文本:
    [https://huggingface.co/facebook/bart-large-cnn](https://huggingface.co/facebook/bart-large-cnn)^(10)^(10)脚注文本:
    [https://huggingface.co/t5-base](https://huggingface.co/t5-base)^(11)^(11)脚注文本:
    [https://huggingface.co/distilbert-base-uncased](https://huggingface.co/distilbert-base-uncased)^(12)^(12)脚注文本:
    [https://huggingface.co/gpt2](https://huggingface.co/gpt2)^(13)^(13)脚注文本: [https://huggingface.co/microsoft/git-base-textvqa](https://huggingface.co/microsoft/git-base-textvqa)^(14)^(14)脚注文本:
    [https://huggingface.co/distilbert-base-cased-distilled-squad](https://huggingface.co/distilbert-base-cased-distilled-squad)'
- en: This paper presents work whose goal is to advance the field of Machine Learning.
    There are many potential societal consequences of our work, none of which we feel
    must be specifically highlighted here.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 本论文展示了旨在推动机器学习领域的工作。我们的工作可能产生许多社会影响，但我们认为不需要特别在此突出说明。
- en: Appendix B Appendix
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 附录
- en: B.1 Bechmark Tasks and Tools
  id: totrans-188
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.1 基准任务和工具
- en: 'The tool list integrated in the OpenAGI platform (Ge et al., [2023a](#bib.bib13))
    is shown in Table [3](#A2.T3 "Table 3 ‣ B.1 Bechmark Tasks and Tools ‣ Appendix
    B Appendix ‣ Formal-LLM: Integrating Formal Language and Natural Language for
    Controllable LLM-based Agents") and the different types of tasks as well as example
    tasks are shown in Table [4](#A2.T4 "Table 4 ‣ B.3 Prompt for Benchmark Tasks
    ‣ Appendix B Appendix ‣ Formal-LLM: Integrating Formal Language and Natural Language
    for Controllable LLM-based Agents").'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '集成在 OpenAGI 平台中的工具列表 (Ge et al., [2023a](#bib.bib13)) 如表 [3](#A2.T3 "表 3 ‣
    B.1 基准任务和工具 ‣ 附录 B 附录 ‣ Formal-LLM: 将形式语言与自然语言整合，用于可控的基于LLM的智能体") 所示，不同类型的任务及示例任务如表
    [4](#A2.T4 "表 4 ‣ B.3 基准任务提示 ‣ 附录 B 附录 ‣ Formal-LLM: 将形式语言与自然语言整合，用于可控的基于LLM的智能体")
    所示。'
- en: '| Input Modality | Output Modality | Tool Description | Expert Model |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| 输入模态 | 输出模态 | 工具描述 | 专家模型 |'
- en: '| Image | Image ($A$) | Colorizer[A](#footnotex1 "Appendix A Impact Statements
    ‣ Formal-LLM: Integrating Formal Language and Natural Language for Controllable
    LLM-based Agents") (Zhang et al., [2017](#bib.bib49)) |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| 图像 | 图像 ($A$) | 着色器[A](#footnotex1 "附录 A 影响声明 ‣ Formal-LLM: 将形式语言与自然语言整合，用于可控的基于LLM的智能体")
    (Zhang et al., [2017](#bib.bib49)) |'
- en: '| Super-Resolution ($a_{2}$) | Swin2SR[A](#footnotex2 "Appendix A Impact Statements
    ‣ Formal-LLM: Integrating Formal Language and Natural Language for Controllable
    LLM-based Agents") (Conde et al., [2022](#bib.bib10)) |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| 超分辨率 ($a_{2}$) | Swin2SR[A](#footnotex2 "附录 A 影响声明 ‣ Formal-LLM: 将形式语言与自然语言整合，用于可控的基于LLM的智能体")
    (Conde et al., [2022](#bib.bib10)) |'
- en: '| Image Denoising ($a_{3}$) | Restormer[A](#footnotex3 "Appendix A Impact Statements
    ‣ Formal-LLM: Integrating Formal Language and Natural Language for Controllable
    LLM-based Agents") (Zamir et al., [2022](#bib.bib48)) |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| 图像去噪 ($a_{3}$) | Restormer[A](#footnotex3 "附录 A 影响声明 ‣ Formal-LLM：将形式语言与自然语言结合用于可控的
    LLM 基于代理") (Zamir 等， [2022](#bib.bib48)) |'
- en: '| Image Deblurring ($a_{4}$) | Restormer[A](#footnotex3 "Appendix A Impact
    Statements ‣ Formal-LLM: Integrating Formal Language and Natural Language for
    Controllable LLM-based Agents") (Zamir et al., [2022](#bib.bib48)) |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| 图像去模糊 ($a_{4}$) | Restormer[A](#footnotex3 "附录 A 影响声明 ‣ Formal-LLM：将形式语言与自然语言结合用于可控的
    LLM 基于代理") (Zamir 等， [2022](#bib.bib48)) |'
- en: '| Text ($B$) | ViT[A](#footnotex4 "Appendix A Impact Statements ‣ Formal-LLM:
    Integrating Formal Language and Natural Language for Controllable LLM-based Agents")
    (Dosovitskiy et al., [2021](#bib.bib11)) |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| 文本 ($B$) | ViT[A](#footnotex4 "附录 A 影响声明 ‣ Formal-LLM：将形式语言与自然语言结合用于可控的 LLM
    基于代理") (Dosovitskiy 等， [2021](#bib.bib11)) |'
- en: '| Object Detection ($b_{2}$) | DETR[A](#footnotex5 "Appendix A Impact Statements
    ‣ Formal-LLM: Integrating Formal Language and Natural Language for Controllable
    LLM-based Agents") (Carion et al., [2020](#bib.bib4)) |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| 物体检测 ($b_{2}$) | DETR[A](#footnotex5 "附录 A 影响声明 ‣ Formal-LLM：将形式语言与自然语言结合用于可控的
    LLM 基于代理") (Carion 等， [2020](#bib.bib4)) |'
- en: '| Image Captioning ($b_{3}$) | Vision Encoder Decoder[A](#footnotex6 "Appendix
    A Impact Statements ‣ Formal-LLM: Integrating Formal Language and Natural Language
    for Controllable LLM-based Agents") (Li et al., [2023b](#bib.bib27)) |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| 图像描述 ($b_{3}$) | Vision Encoder Decoder[A](#footnotex6 "附录 A 影响声明 ‣ Formal-LLM：将形式语言与自然语言结合用于可控的
    LLM 基于代理") (Li 等， [2023b](#bib.bib27)) |'
- en: '| Text | Image ($C$) | Stable Diffusion[A](#footnotex7 "Appendix A Impact Statements
    ‣ Formal-LLM: Integrating Formal Language and Natural Language for Controllable
    LLM-based Agents") (Rombach et al., [2022](#bib.bib36)) |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| 文本 | 图像 ($C$) | Stable Diffusion[A](#footnotex7 "附录 A 影响声明 ‣ Formal-LLM：将形式语言与自然语言结合用于可控的
    LLM 基于代理") (Rombach 等， [2022](#bib.bib36)) |'
- en: '| Text ($D$) | DistilBERT[A](#footnotex8 "Appendix A Impact Statements ‣ Formal-LLM:
    Integrating Formal Language and Natural Language for Controllable LLM-based Agents")
    (Sanh et al., [2020](#bib.bib37)) |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| 文本 ($D$) | DistilBERT[A](#footnotex8 "附录 A 影响声明 ‣ Formal-LLM：将形式语言与自然语言结合用于可控的
    LLM 基于代理") (Sanh 等， [2020](#bib.bib37)) |'
- en: '| Text Summarization ($d_{2}$) | BART[A](#footnotex9 "Appendix A Impact Statements
    ‣ Formal-LLM: Integrating Formal Language and Natural Language for Controllable
    LLM-based Agents") (Lewis et al., [2019](#bib.bib24)) |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| 文本摘要 ($d_{2}$) | BART[A](#footnotex9 "附录 A 影响声明 ‣ Formal-LLM：将形式语言与自然语言结合用于可控的
    LLM 基于代理") (Lewis 等， [2019](#bib.bib24)) |'
- en: '| Machine Translation ($d_{3}$) | T5[A](#footnotex10 "Appendix A Impact Statements
    ‣ Formal-LLM: Integrating Formal Language and Natural Language for Controllable
    LLM-based Agents") (Raffel et al., [2020](#bib.bib35)) |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| 机器翻译 ($d_{3}$) | T5[A](#footnotex10 "附录 A 影响声明 ‣ Formal-LLM：将形式语言与自然语言结合用于可控的
    LLM 基于代理") (Raffel 等， [2020](#bib.bib35)) |'
- en: '| Fill Mask ($d_{4}$) | DistilBERT[A](#footnotex11 "Appendix A Impact Statements
    ‣ Formal-LLM: Integrating Formal Language and Natural Language for Controllable
    LLM-based Agents") (Sanh et al., [2020](#bib.bib37)) |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| 填充掩码 ($d_{4}$) | DistilBERT[A](#footnotex11 "附录 A 影响声明 ‣ Formal-LLM：将形式语言与自然语言结合用于可控的
    LLM 基于代理") (Sanh 等， [2020](#bib.bib37)) |'
- en: '| Text Generation ($d_{5}$) | GPT-2[A](#footnotex12 "Appendix A Impact Statements
    ‣ Formal-LLM: Integrating Formal Language and Natural Language for Controllable
    LLM-based Agents") (Radford et al., [2019](#bib.bib34)) |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| 文本生成 ($d_{5}$) | GPT-2[A](#footnotex12 "附录 A 影响声明 ‣ Formal-LLM：将形式语言与自然语言结合用于可控的
    LLM 基于代理") (Radford 等， [2019](#bib.bib34)) |'
- en: '| Image-Text Pair | Text ($E$) | GIT[A](#footnotex13 "Appendix A Impact Statements
    ‣ Formal-LLM: Integrating Formal Language and Natural Language for Controllable
    LLM-based Agents") (Wang et al., [2022](#bib.bib42)) |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| 图像-文本对 | 文本 ($E$) | GIT[A](#footnotex13 "附录 A 影响声明 ‣ Formal-LLM：将形式语言与自然语言结合用于可控的
    LLM 基于代理") (Wang 等， [2022](#bib.bib42)) |'
- en: '| Text-Text Pair | Text ($F$) | DistilBERT[A](#footnotex14 "Appendix A Impact
    Statements ‣ Formal-LLM: Integrating Formal Language and Natural Language for
    Controllable LLM-based Agents") (Sanh et al., [2020](#bib.bib37)) |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| 文本-文本对 | 文本 ($F$) | DistilBERT[A](#footnotex14 "附录 A 影响声明 ‣ Formal-LLM：将形式语言与自然语言结合用于可控的
    LLM 基于代理") (Sanh 等， [2020](#bib.bib37)) |'
- en: 'Table 3: Tool list integrated in OpenAGI platform (Ge et al., [2023a](#bib.bib13))
    for benchmark tasks. The tools are categorized into six primary groups according
    to the input and output modalities.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：OpenAGI 平台 (Ge et al., [2023a](#bib.bib13)) 中用于基准任务的工具列表。这些工具根据输入和输出模式被分为六个主要组。
- en: B.2 Implementation Details
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.2 实现细节
- en: Our framework and all baselines are implemented by PyTorch, an open-source library.
    We follow the implementation setting of the OpenAGI platform (Ge et al., [2023a](#bib.bib13))
    for baselines. For the F-LLM+RLTF framework, we use the REINFORCE (Williams, [1992](#bib.bib44))
    as the core reinforcement learning algorithm of RLTF. We use the original checkpoint
    of each backbone LLM without supervised fine-tuning. We set the maximum number
    of updating epochs at 30 and use Adam as the optimizer with the learning rate
    at 0.001 for RLTF. Also, we apply Low-Rank Adaptation (LoRA) (Hu et al., [2021](#bib.bib21))
    to the RLTF for efficient fine-tuning.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的框架和所有基准线都由 PyTorch 实现，这是一个开源库。我们遵循 OpenAGI 平台 (Ge et al., [2023a](#bib.bib13))
    的实现设置来进行基准线测试。对于 F-LLM+RLTF 框架，我们使用 REINFORCE (Williams, [1992](#bib.bib44)) 作为
    RLTF 的核心强化学习算法。我们使用每个主干 LLM 的原始检查点，没有进行监督微调。我们将更新的最大轮次设置为 30，并使用 Adam 作为优化器，学习率为
    0.001。我们还将低秩自适应 (LoRA) (Hu et al., [2021](#bib.bib21)) 应用于 RLTF，以实现高效的微调。
- en: B.3 Prompt for Benchmark Tasks
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.3 基准任务的提示
- en: 'An example of the CFG and the corresponding PDA are shown in Eq.([3](#S4.E3
    "Equation 3 ‣ 4.2 Formulating Constraint to Automaton ‣ 4 The Formal-LLM Framework
    ‣ Formal-LLM: Integrating Formal Language and Natural Language for Controllable
    LLM-based Agents")) and Eq.([4](#S4.E4 "Equation 4 ‣ 4.2 Formulating Constraint
    to Automaton ‣ 4 The Formal-LLM Framework ‣ Formal-LLM: Integrating Formal Language
    and Natural Language for Controllable LLM-based Agents")) as well as Figure [3](#S4.F3
    "Figure 3 ‣ 4.3 Formal-LLM Prompts and Planning from Automaton ‣ 4 The Formal-LLM
    Framework ‣ Formal-LLM: Integrating Formal Language and Natural Language for Controllable
    LLM-based Agents"). Different benchmark tasks share a common subset of constraints
    shown in Eq.([3](#S4.E3 "Equation 3 ‣ 4.2 Formulating Constraint to Automaton
    ‣ 4 The Formal-LLM Framework ‣ Formal-LLM: Integrating Formal Language and Natural
    Language for Controllable LLM-based Agents")) corresponding to the input-output
    constraints of the tools. Besides, each task has it own contraint on the input-outpt
    of the task, resulting in different contraints in Eq.([4](#S4.E4 "Equation 4 ‣
    4.2 Formulating Constraint to Automaton ‣ 4 The Formal-LLM Framework ‣ Formal-LLM:
    Integrating Formal Language and Natural Language for Controllable LLM-based Agents")),
    and thus the final PDA (Figure [3](#S4.F3 "Figure 3 ‣ 4.3 Formal-LLM Prompts and
    Planning from Automaton ‣ 4 The Formal-LLM Framework ‣ Formal-LLM: Integrating
    Formal Language and Natural Language for Controllable LLM-based Agents")) for
    different tasks are different.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 'CFG 和对应的 PDA 示例见 Eq.([3](#S4.E3 "Equation 3 ‣ 4.2 Formulating Constraint to
    Automaton ‣ 4 The Formal-LLM Framework ‣ Formal-LLM: Integrating Formal Language
    and Natural Language for Controllable LLM-based Agents")) 和 Eq.([4](#S4.E4 "Equation
    4 ‣ 4.2 Formulating Constraint to Automaton ‣ 4 The Formal-LLM Framework ‣ Formal-LLM:
    Integrating Formal Language and Natural Language for Controllable LLM-based Agents"))
    以及图 [3](#S4.F3 "Figure 3 ‣ 4.3 Formal-LLM Prompts and Planning from Automaton
    ‣ 4 The Formal-LLM Framework ‣ Formal-LLM: Integrating Formal Language and Natural
    Language for Controllable LLM-based Agents")。不同的基准任务共享 Eq.([3](#S4.E3 "Equation
    3 ‣ 4.2 Formulating Constraint to Automaton ‣ 4 The Formal-LLM Framework ‣ Formal-LLM:
    Integrating Formal Language and Natural Language for Controllable LLM-based Agents"))
    中显示的约束子集，这些约束对应于工具的输入输出约束。此外，每个任务在任务的输入输出上有自己的约束，导致 Eq.([4](#S4.E4 "Equation 4
    ‣ 4.2 Formulating Constraint to Automaton ‣ 4 The Formal-LLM Framework ‣ Formal-LLM:
    Integrating Formal Language and Natural Language for Controllable LLM-based Agents"))
    中出现不同的约束，因此不同任务的最终 PDA (图 [3](#S4.F3 "Figure 3 ‣ 4.3 Formal-LLM Prompts and Planning
    from Automaton ‣ 4 The Formal-LLM Framework ‣ Formal-LLM: Integrating Formal Language
    and Natural Language for Controllable LLM-based Agents")) 是不同的。'
- en: 'Zero-shot Prompt:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 'Zero-shot Prompt:'
- en: 'Problem:  {task_description}.What  is  its  soltuion?  Use  ’Setp’  to  mark.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 'Problem: {task_description}.What is its solution? Use ’Setp’ to mark.'
- en: 'Few-shot Prompt:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 'Few-shot Prompt:'
- en: '{few  shot  examples  in  the  format  of:{Problem:  {task_description}.Solution:Step  1:  ...Step  2:  ......Step  k:  ...}}Problem:  {task_description}.Solution:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '{few shot examples in the format of:{Problem: {task_description}.Solution:Step
    1: ...Step 2: ......Step k: ...}}Problem: {task_description}.Solution:'
- en: 'RLTF Prompt (RLTF executes the solution and use the performance as reward to
    fine-tune the LLM):'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: RLTF Prompt (RLTF 执行解决方案并使用性能作为奖励来微调 LLM)：
- en: 'Problem:  {task_description}.Solution:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 'Problem: {task_description}.Solution:'
- en: 'Formal-LLM Prompt (zero-shot):'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 'Formal-LLM Prompt (zero-shot):'
- en: 'You  will  help  me  generate  a  plan  for  the  problem:  {task_description}  by  answering  a  series  of  my  questions.{current_progress}To  get  the  {data_modality},  we  have  the  following  choices:{choice_list}Your  answer  should  be  only  an  integer,  referring  to  the  desired  choice.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 你将帮助我通过回答一系列问题来生成一个关于{task_description}的问题解决计划。{current_progress}要获取{data_modality}，我们有以下选择：{choice_list}你的回答应仅为一个整数，表示所需的选择。
- en: 'Formal-LLM + RLTF (execute the solution of Formal-LLM and use the performance
    as reward to fine-tune the LLM):'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 正式-LLM + RLTF（执行正式-LLM 的解决方案并将性能作为奖励来微调 LLM）：
- en: 'You  will  help  me  generate  a  plan  for  the  problem:  {task_description}  by  answering  a  series  of  my  questions.{current_progress}To  get  the  {data_modality},  we  have  the  following  choices:{choice_list}Your  answer  should  be  only  an  integer,  referring  to  the  desired  choice.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 你将帮助我通过回答一系列问题来生成一个关于{task_description}的问题解决计划。{current_progress}要获取{data_modality}，我们有以下选择：{choice_list}你的回答应仅为一个整数，表示所需的选择。
- en: 'Formal-LLM Prompt Example:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 正式-LLM 提示示例：
- en: 'You  will  help  me  generate  a  plan  for  the  problem:  "Given  a  grayscale  image,  how  to  return  the  regular  image  step  by  step?"  by  answering  a  series  of  my  questions.Current  Progress:Step  n:  Use  Image  Super  Resolution;Step  (n-1):  ?To  get  the  input  image  of  "Image  Super  Resolution",  we  have  the  following  choices:1:  the  output  of  Colorization,2:  the  output  of  Image  Denoising,3:  the  output  of  Image  Deblurring,4:  the  output  of  Text  to  Image  Generation,5:  Input  Image.Your  answer  should  be  only  an  integer,  referring  to  the  desired  choice.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 你将帮助我通过回答一系列问题来生成一个关于“给定一张灰度图像，如何逐步返回常规图像？”的问题解决计划。当前进展：步骤 n：使用图像超分辨率；步骤 (n-1)：？要获取“图像超分辨率”的输入图像，我们有以下选择：1：色彩化的输出，2：图像去噪的输出，3：图像去模糊的输出，4：文本到图像生成的输出，5：输入图像。你的回答应仅为一个整数，表示所需的选择。
- en: '| Task | Metrics | Output | Label | Evaluation | Task Example |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | 指标 | 输出 | 标签 | 评价 | 任务示例 |'
- en: '| Task 1 | CLIP Score | Image | Text | Text-to-Image similarity | Given clozed
    English text, how to |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| 任务 1 | CLIP 分数 | 图像 | 文本 | 文本对图像相似度 | 给定缺失的英文文本，如何 |'
- en: '| generate an image step by step? |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| 逐步生成一张图像？ |'
- en: '| Task 2 | BERT Score | Text | Text | Text-to-Text similarity | Given noisy
    grayscale image, how to return |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| 任务 2 | BERT 分数 | 文本 | 文本 | 文本对文本相似度 | 给定嘈杂的灰度图像，如何返回 |'
- en: '| the caption in German step by step? |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| 逐步用德语生成标题？ |'
- en: '| Task 3 | ViT Score | Image | Image | Image-to-Image similarity | Given blurry
    grayscale image, how to return |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| 任务 3 | ViT 分数 | 图像 | 图像 | 图像对图像相似度 | 给定模糊的灰度图像，如何返回 |'
- en: '| the regular image step by step? |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| 逐步生成常规图像？ |'
- en: '| Task X | Corresponding Score | / | / | / | Given low-resolution noisy blurry
    grayscale |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| 任务 X | 相应分数 | / | / | / | 给定低分辨率嘈杂模糊的灰度图像 |'
- en: '| image and English query, how to answer the |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| 图片和英文查询，如何回答 |'
- en: '| question in German step by step? |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| 逐步用德语提问？ |'
- en: 'Table 4: Benchmark task examples under each category. Task X is a subset of
    “Task 1 $\cup$ Task 3”, which is a subset of tasks that require a tree-structured
    plan rather than chain-structured plan due to the use of many input-single-output
    tools. Task X is used to test the complex planning ability of our Formal-LLM framework.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：每个类别下的基准任务示例。任务 X 是“任务 1 $\cup$ 任务 3”的一个子集，后者是由于使用了许多输入-单输出工具而需要树结构规划而不是链结构规划的任务子集。任务
    X 用于测试我们正式-LLM 框架的复杂规划能力。
- en: B.4 Prompt for Real-life Tasks
  id: totrans-234
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.4 真实任务提示
- en: B.4.1 Daily Plan
  id: totrans-235
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: B.4.1 日常计划
- en: 'The automaton is displayed in Figure [4](#S4.F4 "Figure 4 ‣ 4.3 Formal-LLM
    Prompts and Planning from Automaton ‣ 4 The Formal-LLM Framework ‣ Formal-LLM:
    Integrating Formal Language and Natural Language for Controllable LLM-based Agents").'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 自动机显示在图 [4](#S4.F4 "图 4 ‣ 4.3 正式-LLM 提示和自动机规划 ‣ 4 正式-LLM 框架 ‣ 正式-LLM：将正式语言与自然语言整合用于可控的
    LLM 代理") 中。
- en: 'GPT-4 Prompt:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4 提示：
- en: 'Generate  a  plan  for  activities  between  10:00  and  20:00.Breakfast,  lunch,  and  supper  need  1  hour  each.Outdoor  activities:  basketball  playing  13:00  -  15:00;  do  grocery  shopping  needs  1  hour.Indoor  activities:  house  cleaning  needs  1  hour;  homework  needs  three  hours;  turning  on  the  washer/laundry  machine  needs  0  minutes  but  needs  to  stay  home  for  one  hour.Other  constrain:Cannot  play  basketball  within  an  hour  after  a  meal.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 制定一个从 10:00 到 20:00 的活动计划。早餐、午餐和晚餐各需 1 小时。户外活动：篮球 13:00 - 15:00；购物需 1 小时。室内活动：打扫卫生需
    1 小时；做作业需三小时；开启洗衣机/清洗机无需时间但需在家待 1 小时。其他限制：餐后 1 小时内不能打篮球。
- en: 'Formal-LLM Prompt:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: Formal-LLM 提示：
- en: 'Generate  a  plan  for  activities  between  10:00  and  20:00.Breakfast,  lunch,  and  supper  need  1  hour  each.Outdoor  activities:  basketball  playing  13:00  -  15:00;  do  grocery  shopping  needs  1  hour.Indoor  activities:  house  cleaning  needs  1  hour;  homework  needs  three  hours;  turning  on  the  washer/laundry  machine  needs  0  minutes  but  needs  to  stay  home  for  one  hour.Other  constrain:Cannot  play  basketball  within  an  hour  after  a  meal.Let’s  start  planning  from  the  end.{current_progress}Decide  on  the  activity  ending  at  {current_hour}:00.Here  are  possible  options:{choice_list}Your  reply  should  be  only  one  number,  such  as  1,  referring  to  the  option.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 制定一个从 10:00 到 20:00 的活动计划。早餐、午餐和晚餐各需 1 小时。户外活动：篮球 13:00 - 15:00；购物需 1 小时。室内活动：打扫卫生需
    1 小时；做作业需三小时；开启洗衣机/清洗机无需时间但需在家待 1 小时。其他限制：餐后 1 小时内不能打篮球。我们从结束时间开始计划。{current_progress}
    决定在 {current_hour}:00 结束的活动。这里是可能的选项：{choice_list}。你的回复应仅为一个数字，如 1，表示选项。
- en: 'Formal-LLM Prompt Example:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: Formal-LLM 提示示例：
- en: 'Generate  a  plan  for  activities  between  10:00  and  20:00.Breakfast,  lunch,  and  supper  need  1  hour  each.Outdoor  activities:  basketball  playing  13:00  -  15:00;  do  grocery  shopping  needs  1  hour.Indoor  activities:  house  cleaning  needs  1  hour;  homework  needs  three  hours;  turning  on  the  washer/laundry  machine  needs  0  minutes  but  needs  to  stay  home  for  one  hour.Other  constrain:Cannot  play  basketball  within  an  hour  after  a  meal.Let’s  start  planning  from  the  end.Current  Progress:17:00  -  20:00  Doing  homework.Decide  on  the  activity  ending  at  17:00.Here  are  possible  options:1.  Eating  supper.2.  Grocery  shopping.3.  House  cleaning.4.  Turning  on  the  washer/laundry  machine.5.  Doing  nothing  for  one  hour.Your  reply  should  be  only  one  number,  such  as  1,  referring  to  the  option.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 制定一个从 10:00 到 20:00 的活动计划。早餐、午餐和晚餐各需 1 小时。户外活动：篮球 13:00 - 15:00；购物需 1 小时。室内活动：打扫卫生需
    1 小时；做作业需三小时；开启洗衣机/清洗机无需时间但需在家待 1 小时。其他限制：餐后 1 小时内不能打篮球。我们从结束时间开始计划。当前进度：17:00
    - 20:00 做作业。决定在 17:00 结束的活动。这里是可能的选项：1. 吃晚餐。2. 购物。3. 打扫卫生。4. 开洗衣机/清洗机。5. 空闲 1
    小时。你的回复应仅为一个数字，如 1，表示选项。
- en: B.4.2 Cooking Recipe
  id: totrans-243
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: B.4.2 烹饪食谱
- en: 'The formal language for the cooking task is a CFG, shown as Eq.([5](#A2.E5
    "Equation 5 ‣ B.4.2 Cooking Recipe ‣ B.4 Prompt for Real-life Tasks ‣ Appendix
    B Appendix ‣ Formal-LLM: Integrating Formal Language and Natural Language for
    Controllable LLM-based Agents")).'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 烹饪任务的正式语言是一个 CFG，如 Eq.([5](#A2.E5 "方程 5 ‣ B.4.2 烹饪食谱 ‣ B.4 现实任务提示 ‣ 附录 B 附录
    ‣ Formal-LLM：整合正式语言与自然语言以控制基于 LLM 的代理"))所示。
- en: '|  | $$\begin{split}&amp;S\rightarrow aAB\\ &amp;B\rightarrow aCD&#124;aCE\\'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | $$\begin{split}&amp;S\rightarrow aAB\\ &amp;B\rightarrow aCD&#124;aCE\\'
- en: '&amp;C\rightarrow aF\\'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '&amp;C\rightarrow aF\\'
- en: '&amp;D\rightarrow aAI\\'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '&amp;D\rightarrow aAI\\'
- en: '&amp;E\rightarrow bH\\'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '&amp;E\rightarrow bH\\'
- en: '&amp;F\rightarrow bAG\\'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '&amp;F\rightarrow bAG\\'
- en: '&amp;G\rightarrow cd\\'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '&amp;G\rightarrow cd\\'
- en: '&amp;H\rightarrow ef&#124;eI\\'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '&amp;H\rightarrow ef&#124;eI\\'
- en: '&amp;I\rightarrow cf\end{split}$$ |  | (5) |'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '&amp;I\rightarrow cf\end{split}$$ |  | (5) |'
- en: 'where nonterminals: $S$ is for broccoli.'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 其中非终结符：$S$ 代表西兰花。
- en: 'GPT-4 Prompt:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4 提示：
- en: Generate  a  broccoli  beef  cooking  plan.The  ingredients  include  raw  beef  slices,  carpaccio,  broccoli,  onions,  ginger,  garlic,  and  water.The  seasonings  include  cooking  oil,  salt,  light  soy  sauce,  cooking  wine,  white  pepper,  sugar,  vinegar.Cooking  utensils  including  woks  and  cooking  pots.Tableware  including  chopsticks,  spoons,  wok  spoons,  and  several  bowls.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 生成一个西兰花牛肉烹饪计划。所需原料包括生牛肉片、生牛肉薄片、西兰花、洋葱、姜、大蒜和水。调料包括食用油、盐、淡酱油、料酒、白胡椒粉、糖、醋。烹饪用具包括炒锅和炖锅。餐具包括筷子、勺子、炒锅勺和若干碗。
- en: 'Formal-LLM Prompt:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 正式的 LLM 提示：
- en: 'Generate  a  broccoli  beef  cooking  plan.The  ingredients  include  raw  beef  slices,  carpaccio,  broccoli,  onions,  ginger,  garlic,  and  water.The  seasonings  include  cooking  oil,  salt,  light  soy  sauce,  cooking  wine,  white  pepper,  sugar,  vinegar.Cooking  utensils  including  woks  and  cooking  pots.Tableware  including  chopsticks,  spoons,  wok  spoons,  and  several  bowls.{current_progress}Decide  on  the  previous  step  before  current  progress.Here  are  possible  options  to  get  {target_item}  for  the  step:  {parent_step}.{choice_list}Your  reply  should  be  only  one  number,  such  as  1,  referring  to  the  option.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 生成一个西兰花牛肉烹饪计划。所需原料包括生牛肉片、生牛肉薄片、西兰花、洋葱、姜、大蒜和水。调料包括食用油、盐、淡酱油、料酒、白胡椒粉、糖、醋。烹饪用具包括炒锅和炖锅。餐具包括筷子、勺子、炒锅勺和若干碗。{current_progress}在当前进度之前决定上一步骤。以下是获得
    {target_item} 的可能选项，用于步骤：{parent_step}。{choice_list}你的回复应仅为一个数字，例如 1，表示选择的选项。
- en: 'Formal-LLM Prompt Example:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 正式的 LLM 提示示例：
- en: 'Generate  a  broccoli  beef  cooking  plan.The  ingredients  include  raw  beef  slices,  carpaccio,  broccoli,  onions,  ginger,  garlic,  and  water.The  seasonings  include  cooking  oil,  salt,  light  soy  sauce,  cooking  wine,  white  pepper,  sugar,  vinegar.Cooking  utensils  including  woks  and  cooking  pots.Tableware  including  chopsticks,  spoons,  wok  spoons,  and  several  bowls.Current  Progress:Step  n:  Then,  we  get  the  cooked  broccoli  beef.Step  n-1:  Stir-fry  the  beef  and  broccoli  mixture  with  the  seasoning  in  a  wok.Step  n-2:  Prepare  the  seasoning:  ginger,  garlic,  cooking  oil,  salt,  light  soy  sauce,  cooking  wine,  white  pepper  for  the  step:  "Stir-fry  the  beef  and  broccoli  mixture  with  the  seasoning  in  a  wok."Step  n-3:  ?Decide  on  the  previous  step  before  current  progress.Here  are  possible  options  to  get  the  mixture  of  beef  and  broccoli  for  the  step:  "Stir-fry  the  beef  and  broccoli  mixture  with  the  seasoning  in  a  wok."1:  Combine  lightly  cooked  beef  and  lightly  cooked  broccoli  in  a  wok.2:  Combine  lightly  cooked  beef  and  blanched  and  drained  broccoli  in  a  wok.Your  reply  should  be  only  one  number,  such  as  1,  referring  to  the  option.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 生成一个西兰花牛肉烹饪计划。所需原料包括生牛肉片、生牛肉薄片、西兰花、洋葱、姜、大蒜和水。调料包括食用油、盐、淡酱油、料酒、白胡椒粉、糖、醋。烹饪用具包括炒锅和炖锅。餐具包括筷子、勺子、炒锅勺和若干碗。当前进度：步骤
    n：然后，我们得到熟西兰花牛肉。步骤 n-1：在炒锅中将牛肉和西兰花混合炒制。步骤 n-2：准备调料：姜、大蒜、食用油、盐、淡酱油、料酒、白胡椒粉，用于步骤：“在炒锅中将牛肉和西兰花混合炒制。”步骤
    n-3：？在当前进度之前决定上一步骤。以下是获得牛肉和西兰花混合物的可能选项，用于步骤：“在炒锅中将牛肉和西兰花混合炒制。”1：将轻微煮熟的牛肉和轻微煮熟的西兰花放入炒锅中。2：将轻微煮熟的牛肉和焯水并沥干的西兰花放入炒锅中。你的回复应仅为一个数字，例如
    1，表示选择的选项。
- en: B.4.3 Risk Management
  id: totrans-260
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: B.4.3 风险管理
- en: '![Refer to caption](img/0b0e28323bc63f3a051ce6f0609f1e47.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/0b0e28323bc63f3a051ce6f0609f1e47.png)'
- en: 'Figure 6: The flowchart for risk management task.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：风险管理任务的流程图。
- en: 'Domain experts draw a flowchart of risk management as Figure [6](#A2.F6 "Figure
    6 ‣ B.4.3 Risk Management ‣ B.4 Prompt for Real-life Tasks ‣ Appendix B Appendix
    ‣ Formal-LLM: Integrating Formal Language and Natural Language for Controllable
    LLM-based Agents"). The flowchart is essentially a Deterministic Finite Automaton
    (DFA), which is a special case of Pushdown Automaton (PDA). A question is generated
    to inquiry LLM when the automaton reaches a new state. The LLM can select a reasonable
    branch according to its knowledge of the specific seller, buyer, and company name.
    In the experiment, the seller is Shareholders of Blizzard Entertainment, the company
    is Blizzard Entertainment, and the buyer is Microsoft.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 领域专家绘制了风险管理的流程图，如图 [6](#A2.F6 "图6 ‣ B.4.3 风险管理 ‣ B.4 现实任务提示 ‣ 附录B 附录 ‣ Formal-LLM：将正式语言与自然语言整合用于可控LLM代理")。该流程图本质上是一个确定性有限自动机（DFA），它是推栈自动机（PDA）的特例。当自动机到达新状态时，会生成一个问题以询问LLM。LLM可以根据对特定卖方、买方和公司名称的知识选择合理的分支。在实验中，卖方是动视暴雪的股东，公司是动视暴雪，买方是微软。
- en: 'GPT-4 Prompt:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4提示：
- en: 'Task:  You  are  a  plan  maker  to  design  a  risk  management  plan  for  deals  related  to  companies.Scenario:  {Seller  A}  wants  to  sell  the  {Company  B}  which  {Buyer  C}  wants  to  buy.  Design  a  risk  management  plan  for  {Buyer  C}  before  negotiating  a  detailed  contract.'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 任务：你是一个计划制定者，为与公司相关的交易设计风险管理计划。场景：{卖方A}想要出售{公司B}，而{买方C}想要购买。为{买方C}在谈判详细合同之前设计一个风险管理计划。
- en: 'Formal-LLM Prompt:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: Formal-LLM提示：
- en: 'Task:  You  are  a  plan  maker  to  design  a  risk  management  plan  for  deals  related  to  companies.Scenario:  {Seller  A}  wants  to  sell  the  {Company  B}  which  {Buyer  C}  wants  to  buy.  Design  a  risk  management  plan  for  {Buyer  C}  before  negotiating  a  detailed  contract.{question  in  the  flowchart}{choice_list}Your  answer  should  be  only  one  number,  such  as  1,  referring  to  the  option.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 任务：你是一个计划制定者，为与公司相关的交易设计风险管理计划。场景：{卖方A}想要出售{公司B}，而{买方C}想要购买。为{买方C}在谈判详细合同之前设计一个风险管理计划。{流程图中的问题}{选择列表}你的答案应仅为一个数字，例如1，表示选项。
- en: 'Formal-LLM Prompt Example:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: Formal-LLM提示示例：
- en: 'Task:  You  are  a  plan  maker  to  design  a  risk  management  plan  for  deals  related  to  companies.Scenario:  Shareholders  of  Blizzard  Entertainment  wants  to  sell  the  Blizzard  Entertainment  which  Microsoft  wants  to  buy.  Design  a  risk  management  plan  for  Microsoft  before  negotiating  a  detailed  contract.Question:  Does  Microsoft  buying  Blizzard  Entertainment  trigger  mandatory  antitrust  filing?1:  Yes.2:  No.3:  Insufficient  information  to  make  a  judgment.Your  answer  should  be  only  one  number,  such  as  1,  referring  to  the  option.'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '任务：你是一个计划制定者，为与公司相关的交易设计风险管理计划。场景：动视暴雪的股东想要出售动视暴雪，而微软想要购买。为微软在谈判详细合同之前设计一个风险管理计划。问题：微软购买动视暴雪是否触发强制的反垄断申报？1:
    是。2: 否。3: 信息不足以做出判断。你的答案应仅为一个数字，例如1，表示选项。'
- en: B.5 Complete Results of Real-life Tasks
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.5 现实任务的完整结果
- en: 'Daily plan result from GPT-4:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4的每日计划结果：
- en: '10:00  -  11:00  :  Breakfast11:00  -  12:00  :  House  Cleaning12:00  -  13:00  :  Free  Time13:00  -  15:00  :  Basketball  Playing15:00  -  16:00  :  Free  Time16:00  -  17:00  :  Lunch17:00  -  18:00  :  Grocery  Shopping18:00  -  19:00  :  Homework19:00  -  20:00  :  Laundry  and  Supper20:00  -  23:00  :  Continue  HomeworkIn  this  plan,  basketball  playing  is  scheduled  from  13.00  to  15.00  with  an  hour  after  breakfast  to  avoid  playing  right  after  eating  as  per  the  constraint.  Lunch  is  then  scheduled  after  basketball  and  Shopping  done  after  that.  Since  laundry  doesn’t  take  time,  it  has  been  added  with  supper  and  rest  of  the  time  is  allocated  to  homework.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 10:00 - 11:00：早餐11:00 - 12:00：打扫卫生12:00 - 13:00：自由时间13:00 - 15:00：打篮球15:00 -
    16:00：自由时间16:00 - 17:00：午餐17:00 - 18:00：购物18:00 - 19:00：做作业19:00 - 20:00：洗衣和晚餐20:00
    - 23:00：继续做作业在此计划中，打篮球安排在13:00到15:00，并在早餐后一小时开始，以避免饭后立刻运动。午餐安排在打篮球后，购物安排在午餐之后。由于洗衣时间不长，它与晚餐一起安排，其余时间分配给做作业。
- en: 'Daily plan result after applying Formal-LLM:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 应用Formal-LLM后的每日计划结果：
- en: 10:00  -  10:00  Turning  on  the  washer/laundry  machine.10:00  -  11:00  House  cleaning.11:00  -  12:00  Eating  breakfast.12:00  -  13:00  Grocery  shopping.13:00  -  15:00  Playing  basketball.15:00  -  16:00  Eating  lunch.16:00  -  19:00  Doing  homework.19:00  -  20:00  Eating  supper.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 10:00 - 10:00 开启洗衣机/洗衣机。10:00 - 11:00 打扫卫生。11:00 - 12:00 吃早餐。12:00 - 13:00 购物。13:00
    - 15:00 打篮球。15:00 - 16:00 吃午餐。16:00 - 19:00 做作业。19:00 - 20:00 吃晚餐。
- en: 'Cooking recipe result from GPT-4:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4的烹饪食谱：
- en: 'Ingredients  Preparation1.  Sliced  Beef:  300  grams2.  Chinese  Broccoli  (Gai  Lan):  As  needed,  cut  into  segments3.  Scallions:  1  stalk,  cut  into  sections4.  Ginger:  As  needed,  sliced5.  Garlic:  As  needed,  minced6.  Water:  As  needed7.  Cooking  Oil:  As  needed8.  Salt:  As  needed9.  Light  Soy  Sauce:  2  tablespoons10.  Cooking  Wine:  1  tablespoon11.  White  Pepper  Powder:  As  needed12.  Sugar:  1  tablespoon13.  Vinegar:  1  tablespoonCooking  Utensils  and  Tableware  Preparation1.  Stir-fry  Pan:  12.  Cooking  Pot:  13.  Tableware:  Chopsticks,  Soup  Spoon,  Stir-fry  Pan  Spoon,  Several  BowlsCooking  StepsPreparatory  Steps1.  Marinate  the  beef  slices  with  salt  and  cooking  wine,  stirring  evenly,  and  let  it  marinate  for  10  minutes.2.  Heat  the  stir-fry  pan  and  add  an  appropriate  amount  of  cooking  oil.Sautéing  the  Beef1.  Once  the  oil  is  hot,  quickly  stir-fry  the  marinated  beef  slices  until  they  change  color.2.  Add  scallion  sections,  ginger  slices,  and  minced  garlic.  Continue  stirring  until  a  fragrant  aroma  is  released.Sautéing  the  Chinese  Broccoli1.  In  the  stir-fry  pan,  add  water.  Once  the  water  boils,  add  the  Chinese  broccoli.2.  Quickly  stir-fry  the  Chinese  broccoli  until  it  changes  color,  and  season  with  salt.Seasoning1.  Add  light  soy  sauce,  white  pepper  powder,  sugar,  and  vinegar.  Stir  well.2.  Continue  stirring  to  ensure  that  the  seasoning  is  evenly  coated  on  the  beef  and  Chinese  broccoli.Completion1.  Ensure  the  beef  is  cooked  through,  and  the  Chinese  broccoli  is  flavorful.  Remove  from  heat.Serving1.  Transfer  the  Chinese  Broccoli  Beef  to  bowls.2.  Serve  with  rice  or  noodles.Tips1.  Avoid  marinating  the  beef  slices  for  too  long  to  maintain  a  good  texture.2.  Control  the  sautéing  time  for  Chinese  broccoli  to  preserve  its  crisp  and  tender  texture.3.  Adjust  the  seasoning  according  to  personal  taste  preferences,  adding  or  reducing  the  amount  of  salt,  sugar,  and  vinegar.'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 材料  准备1.  切片牛肉：300克2.  中国青菜（芥蓝）：按需，切成段3.  青葱：1根，切段4.  姜：按需，切片5.  大蒜：按需，剁碎6.  水：按需7.  食用油：按需8.  盐：按需9.  生抽：2汤匙10.  料酒：1汤匙11.  白胡椒粉：按需12.  糖：1汤匙13.  醋：1汤匙烹饪用具和餐具
    准备1.  炒锅：1个2.  烹饪锅：1个3.  餐具：筷子、汤匙、炒菜勺、若干碗烹饪步骤准备步骤1.  将牛肉片用盐和料酒腌制，搅拌均匀，腌制10分钟。2.  加热炒锅，加入适量食用油。炒牛肉1.  油热后，迅速翻炒腌制好的牛肉片，直到变色。2.  加入葱段、姜片和剁碎的大蒜，继续翻炒，直到散发出香味。炒中国青菜1.  在炒锅中加入水。水开后，加入中国青菜。2.  快速翻炒中国青菜，直到变色，并用盐调味。调味1.  加入生抽、白胡椒粉、糖和醋，搅拌均匀。2.  继续搅拌，确保调料均匀裹在牛肉和中国青菜上。完成1.  确保牛肉完全熟透，中国青菜入味。移开火源。上菜1.  将中国青菜牛肉盛入碗中。2.  配以米饭或面条。小贴士1.  避免将牛肉片腌制过久，以保持良好的口感。2.  控制中国青菜的翻炒时间，以保持其脆嫩的口感。3.  根据个人口味调整调料的量，可增加或减少盐、糖和醋的量。
- en: 'Cooking recipe result after applying Formal-LLM:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 应用Formal-LLM后的烹饪食谱：
- en: 'Here  is  the  final  plan:Step  1:  Wash  raw  beef  slices  with  water.Step  2:  Prepare  the  seasoning:  ginger,  garlic,  cooking  oil,  salt,  light  soy  sauce,  cooking  wine,  white  pepper  for  the  step:  "Marinate  clean  slices  of  beef  in  a  bowl  with  seasoning".Step  3:  Marinate  clean  slices  of  beef  in  a  bowl  with  seasoning.Step  4:  Stir-fry  the  marinaded  beef  in  a  wok.Step  5:  Wash  broccoli  with  water.Step  6:  Blanch  clean  broccoli  in  a  cooking  pot.Step  7:  Use  a  bowl  to  drain  the  blanched  broccoli.Step  8:  Combine  lightly  cooked  beef  and  blanched  and  drained  broccoli  in  a  wok.Step  9:  Prepare  the  seasoning:  ginger,  garlic,  cooking  oil,  salt,  light  soy  sauce,  cooking  wine,  white  pepper  for  the  step:  "Stir-fry  the  beef  and  broccoli  mixture  with  the  seasoning  in  a  wok".Step  10:  Stir-fry  the  beef  and  broccoli  mixture  with  the  seasoning  in  a  wok.Step  11:  Then,  we  get  the  cooked  broccoli  beef.Carefully  cooking  at  each  step!'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最终计划：第1步：用水洗净生牛肉片。第2步：准备调料：姜、蒜、食用油、盐、淡酱油、料酒、白胡椒，用于步骤：“将清洗过的牛肉片与调料一起腌制”。第3步：将清洗过的牛肉片与调料一起腌制。第4步：在锅中炒制腌制好的牛肉。第5步：用水洗净西兰花。第6步：将清洗过的西兰花在锅中焯水。第7步：用碗将焯过水的西兰花沥干。第8步：将略炒熟的牛肉与焯过水并沥干的西兰花在锅中混合。第9步：准备调料：姜、蒜、食用油、盐、淡酱油、料酒、白胡椒，用于步骤：“将牛肉和西兰花混合物与调料一起在锅中炒制”。第10步：将牛肉和西兰花混合物与调料一起在锅中炒制。第11步：然后，我们得到熟西兰花牛肉。每一步都要仔细烹饪！
- en: 'Risk management result from GPT-4:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4的风险管理结果：
- en: 'Risk  Management  Plan:Objective:  To  ensure  a  beneficial  acquisition  of  Blizzard  Entertainment  by  Microsoft  while  managing  and  mitigating  potential  risks.I.  Risk  Identification1.  Financial  Risks:  A  complete  and  thorough  financial  audit  of  Blizzard  must  be  performed  to  determine  potential  financial  risks,  such  bright  as  debts,  pending  lawsuit  settlements,  past  or  ongoing  tax  issues,  declining  revenue,  etc.2.  Operational  Risks:  Understand  Blizzard’s  operational  weaknesses  and  strengths,  and  the  impact  of  the  acquisition  on  Microsoft’s  operations.3.  Legal  Risks:  Review  Blizzard’s  legal  compliance  status  in  all  jurisdictions  it  operates  in.  Especially,  risks  related  to  intellectual  property  rights,  privacy  and  data  security  laws,  and  labor  laws  must  be  evaluated.4.  Regulatory  Risks:  Determine  any  potential  regulatory  approvals  Microsoft  might  need  for  the  acquisition.II.  Risk  Assessment:1.  Quantify  each  identified  risk  wherever  possible,  in  terms  of  potential  financial  impact,  time  delay,  brand  damage  etc.2.  Determine  the  likelihood  of  each  risk  occurrence.3.  Prioritize  the  risks  based  on  their  potential  impact  and  the  likelihood  of  occurrence.III.  Risk  Mitigation  Planning:1.  Financial  Risk:  This  could  be  mitigated  through  leverage  and  insurance,  renegotiation  of  terms,  or  such  other  financial  instruments.2.  Operational  Risk:  To  mitigate  this  risk,  Microsoft  can  plan  to  gradually  integrate  Blizzard,  keeping  key  management  personnel,  or  finding  synergies  with  Microsoft’s  current  operations.3.  Legal  Risk:  Microsoft  should  get  warranties  and  indemnities  from  Blizzard’s  owners  to  cover  potential  post-acquisition  legal  disputes.4.  Regulatory  Risk:  Early  engagement  with  regulators  and  professional  advice  can  help  smooth  the  acquisition  process.IV.  Risk  Monitoring:A  system  to  continuously  monitor  and  manage  these  risks  should  be  set  up.  This  could  involve  regular  reporting,  monitoring  industry  developments,  legal  changes  etc.V.  Contingency  Planning:Establish  contingency  plans  for  high-impact  risks.  For  instance,  a  backup  plan  if  the  acquisition  fails,  or  if  post-acquisition  integration  does  not  go  as  planned.VI.  Communication:Continual  communication  with  stakeholders  to  obtain  feedback  and  to  convey  risk  management  efforts.  This  will  ensure  that  all  parties  are  aware  of  the  risks  and  the  measures  being  taken  to  mitigate  them.VII.  Insurance  Cover:Consider  adequate  insurance  coverage  that  includes  Directors’  and  Officers’  Liability  and  Professional  Indemnity  Insurance  for  all  potential  issues  that  might  arise  in  connection  with  the  proposed  transaction.The  above  steps  will  form  the  roadmap  for  Microsoft  while  negotiating  terms  for  the  acquisition  of  Blizzard  Entertainment.  Understanding  risks  before  they  come  up  ensures  that  Microsoft  isn’t  surprised  during  negotiations,  hence  effectively  mitigating  them.'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 风险管理计划：目标：确保微软成功收购暴雪娱乐，同时管理和减轻潜在风险。I. 风险识别 1. 财务风险：必须对暴雪进行全面彻底的财务审计，以确定潜在的财务风险，如债务、待决诉讼和解、过去或正在进行的税务问题、收入下降等。
    2. 运营风险：了解暴雪的运营弱点和优势，以及收购对微软运营的影响。 3. 法律风险：审查暴雪在其运营所有司法管辖区的法律合规状态。特别是，涉及知识产权、隐私和数据安全法律以及劳动法的风险必须评估。
    4. 监管风险：确定微软在收购过程中可能需要的任何潜在监管批准。 II. 风险评估： 1. 尽可能量化每个识别出的风险，以潜在的财务影响、时间延迟、品牌损害等方面进行评估。
    2. 确定每个风险发生的可能性。 3. 根据风险的潜在影响和发生的可能性对风险进行优先排序。 III. 风险缓解规划： 1. 财务风险：通过杠杆和保险、重新谈判条款或其他财务工具来减轻此风险。
    2. 运营风险：为减轻此风险，微软可以计划逐步整合暴雪，保留关键管理人员，或寻找与微软当前运营的协同效应。 3. 法律风险：微软应从暴雪所有者处获取担保和赔偿，以覆盖潜在的收购后法律纠纷。
    4. 监管风险：及早与监管机构接触并寻求专业建议可以帮助顺利完成收购过程。 IV. 风险监控：应建立一个持续监控和管理这些风险的系统。这可能包括定期报告、监控行业发展、法律变化等。
    V. 应急规划：为高影响风险制定应急计划。例如，如果收购失败或收购后整合未按计划进行，制定备选计划。 VI. 沟通：与利益相关者持续沟通，获取反馈并传达风险管理工作。这将确保所有相关方都了解风险及其缓解措施。
    VII. 保险覆盖：考虑足够的保险覆盖，包括董事和高级职员责任险及专业赔偿保险，以应对与拟议交易相关的所有潜在问题。上述步骤将形成微软在谈判暴雪娱乐收购条款时的路线图。理解风险以防风险发生，确保微软在谈判中不会感到意外，从而有效地减轻风险。
- en: 'Risk management result after applying Formal-LLM:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 应用 Formal-LLM 后的风险管理结果：
- en: 'Here  is  the  final  plan  for  Microsoft:1:  We  need  more  information  to  ensure  Shareholders  of  Blizzard  Entertainment  is  entitled  to  sell  Blizzard  Entertainment.  But  we  assume  we  have  found  out  enough  information  to  proceed  the  risk  assessment  process.2:  Then,  based  on  current  information,  we  believe  Blizzard  Entertainment  is  in  good  standing  without  material  outstanding  liabilities.3:  Then,  based  on  current  information,  we  believe  neither  CFIUS  filings  nor  foreign  investment  filings  in  China  are  needed.4:  Then,  we  need  to  submit  the  regional  antitrust  filing  of  the  United  States  and/or  China.  But  we  assume  the  filings  will  be  approved  to  proceed  the  risk  assessment  process.5:  Pass  the  preliminary  risk  analysis.  Details  to  be  discussed  in  the  transaction  documents.Note:  This  is  a  risk  assessment  process  provided  based  on  current  information.  Please  ensure  the  accuracy  of  the  provided  information  and  possible  additional  supplemental  information.'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是微软的最终计划：1：我们需要更多的信息以确保暴雪娱乐的股东有权出售暴雪娱乐。但我们假设我们已经找到了足够的信息来继续风险评估过程。2：然后，根据当前信息，我们相信暴雪娱乐状况良好，没有实质性的未偿还负债。3：然后，根据当前信息，我们相信不需要
    CFIUS 申报或在中国的外资投资申报。4：然后，我们需要提交美国和/或中国的地区反垄断申报。但我们假设这些申报将会获得批准，以继续风险评估过程。5：通过初步风险分析。详细信息将在交易文件中讨论。注意：这是基于当前信息提供的风险评估过程。请确保提供信息的准确性以及可能的额外补充信息。
