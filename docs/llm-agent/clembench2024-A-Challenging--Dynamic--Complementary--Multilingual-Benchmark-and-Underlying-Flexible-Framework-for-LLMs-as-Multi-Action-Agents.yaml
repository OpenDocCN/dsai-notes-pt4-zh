- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '类别: 未分类'
- en: 'date: 2024-09-08 18:45:21'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-08 18:45:21'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: clembench2024 A Challenging, Dynamic, Complementary, Multilingual Benchmark
    and Underlying Flexible Framework for LLMs as Multi-Action Agents
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: clembench2024 一个具有挑战性的、动态的、互补的、多语言的基准测试以及 LLM 作为多动作代理的灵活框架
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2405.20859](https://ar5iv.labs.arxiv.org/html/2405.20859)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2405.20859](https://ar5iv.labs.arxiv.org/html/2405.20859)
- en: Anne Beyer, Kranti Chalamalasetti, Sherzod Hakimov
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Anne Beyer, Kranti Chalamalasetti, Sherzod Hakimov
- en: Brielen Madureira, Philipp Sadler, David Schlangen¹
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Brielen Madureira, Philipp Sadler, David Schlangen¹
- en: Computational Linguistics, Department of Linguistics
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 计算语言学，语言学系
- en: University of Potsdam, Germany
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 波茨坦大学，德国
- en: ¹German Research Center for Artificial Intelligence (DFKI), Berlin, Germany
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ¹德国人工智能研究中心（DFKI），柏林，德国
- en: 'first.last@uni-potsdam.de   Contributions: AB designed and ran the multilingual
    experiments. KC updated the wordle games; BM did so for private/shared; SH did
    so for drawing and reference, managed the leaderboard and co-managed the project.
    PS maintained the main framework and the server infrastructure. DS co-designed
    the experiments, co-managed the project, and edited the document. All authors
    discussed all content.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 'first.last@uni-potsdam.de   贡献: AB 设计并执行了多语言实验。KC 更新了 wordle 游戏；BM 为私有/共享游戏进行了更新；SH
    负责绘图和参考，管理了排行榜并共同管理了项目。PS 维护了主要框架和服务器基础设施。DS 共同设计了实验，协助管理了项目，并编辑了文档。所有作者讨论了所有内容。'
- en: Abstract
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'It has been established in recent work that Large Language Models (LLMs) can
    be prompted to “self-play” conversational games that probe certain capabilities
    (general instruction following, strategic goal orientation, language understanding
    abilities), where the resulting interactive game play can be automatically scored.
    In this paper, we take one of the proposed frameworks for setting up such game-play
    environments, and further test its usefulness as an evaluation instrument, along
    a number of dimensions: We show that it can easily keep up with new developments
    while avoiding data contamination, we show that the tests implemented within it
    are not yet saturated (human performance is substantially higher than that of
    even the best models), and we show that it lends itself to investigating additional
    questions, such as the impact of the prompting language on performance. We believe
    that the approach forms a good basis for making decisions on model choice for
    building applied interactive systems, and perhaps ultimately setting up a closed-loop
    development environment of system and simulated evaluator.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究已经确定，大型语言模型（LLMs）可以被引导进行“自我对弈”的对话游戏，以探测某些能力（通用指令跟随、战略目标导向、语言理解能力），其中生成的互动游戏玩法可以被自动评分。在本文中，我们选取了一个用于设置此类游戏环境的提议框架，并进一步测试其作为评估工具的有效性，涉及多个维度：我们展示了它可以轻松跟上新发展，同时避免数据污染，我们展示了其中实施的测试尚未饱和（人类表现远高于即使是最好的模型），我们还展示了它有助于调查其他问题，例如提示语言对表现的影响。我们认为，该方法为在建立应用交互系统时做出模型选择决策提供了良好的基础，并且可能最终建立一个系统和模拟评估者的闭环开发环境。
- en: clembench[2024] A Challenging, Dynamic, Complementary, Multilingual Benchmark
    and Underlying Flexible Framework for LLMs as Multi-Action Agents
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: clembench[2024] 一个具有挑战性的、动态的、互补的、多语言的基准测试以及 LLM 作为多动作代理的灵活框架
- en: 'Anne Beyer, Kranti Chalamalasetti, Sherzod Hakimov Brielen Madureira, Philipp
    Sadler, David Schlangen¹ ^†^†thanks:   Contributions: AB designed and ran the
    multilingual experiments. KC updated the wordle games; BM did so for private/shared;
    SH did so for drawing and reference, managed the leaderboard and co-managed the
    project. PS maintained the main framework and the server infrastructure. DS co-designed
    the experiments, co-managed the project, and edited the document. All authors
    discussed all content. Computational Linguistics, Department of Linguistics University
    of Potsdam, Germany ¹German Research Center for Artificial Intelligence (DFKI),
    Berlin, Germany first.last@uni-potsdam.de'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 'Anne Beyer, Kranti Chalamalasetti, Sherzod Hakimov Brielen Madureira, Philipp
    Sadler, David Schlangen¹ ^†^†感谢:   贡献: AB 设计并执行了多语言实验。KC 更新了 wordle 游戏；BM 为私有/共享游戏进行了更新；SH
    负责绘图和参考，管理了排行榜并共同管理了项目。PS 维护了主要框架和服务器基础设施。DS 共同设计了实验，协助管理了项目，并编辑了文档。所有作者讨论了所有内容。计算语言学，波茨坦大学语言学系，德国
    ¹德国人工智能研究中心（DFKI），柏林，德国 first.last@uni-potsdam.de'
- en: 1 Introduction
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: The possibility of coaxing agentive behaviour out of large language models (LLMs)
    makes a vision seem to come into reach of setting up a closed-loop development
    cycle where the dialogue system is formulated through a description of the task
    that is to be reached, and evaluated through specifying a simulated user. While
    there is active work on both sides of this (realising task-oriented systems with
    LLMs, see e.g. Hudeček and Dusek ([2023](#bib.bib7)), and evaluating with LLM-simulated
    users, see e.g. Sekulic et al. ([2024](#bib.bib14))), an important foundational
    step is to establish the validity and limitations of the LLMs-as-agents view.
    In 2023, a number of frameworks appeared that tackled this task through setting
    up dialogue “self-play” of LLMs on more abstract tasks with fully specifiable
    goals (then often called “dialogue games” (Schlangen, [2023](#bib.bib13))).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 诱导大型语言模型（LLMs）产生代理行为的可能性使得设立一个闭环开发周期的愿景似乎触手可及，在这个周期中，对话系统通过任务描述进行制定，并通过指定一个模拟用户进行评估。尽管在这两个方面（实现任务导向系统的
    LLM，参见如 Hudeček 和 Dusek（[2023](#bib.bib7)），以及使用 LLM 模拟用户进行评估，参见如 Sekulic 等（[2024](#bib.bib14)））有积极的工作，但一个重要的基础步骤是建立
    LLM 作为代理的观点的有效性和局限性。在 2023 年，出现了许多框架，通过在更抽象的任务上设置对话“自我游戏”（通常称为“对话游戏” (Schlangen,
    [2023](#bib.bib13))) 来解决这一任务。
- en: For this paper, we continued our work with the clemgame framework (Chalamalasetti
    et al., [2023](#bib.bib2)), and validated some of the claims that were left for
    future work in the original release. Specifically, we show that a) this approach
    can be extended to be a dynamic benchmark, in the sense that what is being evaluated
    are indeed the games themselves and not specific game instances; b) it is still
    a challenging benchmark, given that the scores of even the best models are considerably
    below human performance, which we establish for this paper for the first time;
    c) it is complementary to other benchmarks, both reference-based ones (HELM by
    Liang et al. ([2022](#bib.bib9))) and preference-based ones (Chatbot arena by
    Chiang et al. ([2024](#bib.bib3))); d) the underlying abstractions are flexible,
    so that new models can be integrated easily, making it possible, as we do here,
    to track the rise of open-weight models since the first release of the benchmark;
    and, last but not least, e) the framework makes evaluation of multilingual capabilities
    of models easily possible, as we exemplify here for one of the dialogue games.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇论文中，我们继续使用 clemgame 框架（Chalamalasetti 等，[2023](#bib.bib2)），并验证了原始版本中留给未来工作的某些主张。具体来说，我们展示了
    a) 这种方法可以扩展为一个动态基准，即评估的实际上是游戏本身而不是特定的游戏实例；b) 这是一个具有挑战性的基准，因为即使是最好的模型得分也远低于人类表现，这一点我们在本文中首次确立；c)
    它对其他基准具有补充性，包括基于参考的基准（HELM 由 Liang 等（[2022](#bib.bib9)）提出）和基于偏好的基准（Chatbot arena
    由 Chiang 等（[2024](#bib.bib3)）提出）；d) 基础抽象是灵活的，因此新模型可以轻松集成，使我们能够像在这里一样，跟踪基准首次发布以来开放权重模型的兴起；最后但同样重要的是，e)
    该框架使得对模型多语言能力的评估变得容易，如我们在这里对一个对话游戏的示例所示。
- en: Altogether, we draw from this the conclusion that clembench constitutes a valuable
    tool for the community for testing chat-optimised LLMs (and basing decisions on
    the outcome), but also as an instrument for detailed studies of specific aspects
    of LLM behaviour. We end by speculating on possible future uses, for example as
    a learning environment specifically for interaction, and as something that brings
    us closer to the vision from the opening paragraph, as a build/test framework
    for designing improved agents.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我们得出结论，clembench 是一个对社区非常有价值的工具，用于测试聊天优化的 LLM（并基于结果做出决策），同时也作为一个详细研究 LLM
    行为特定方面的工具。最后，我们对未来可能的使用进行了猜测，例如作为一个专门用于交互的学习环境，以及作为一个使我们更接近开头段落中愿景的构建/测试框架，用于设计改进的代理。
- en: 2 Dialogue Games and Agent Capabilities
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 对话游戏和代理能力
- en: From the realisation in 2022 that LLMs could be seen as generalist “dialogue
    models” (see e.g. Andreas ([2022](#bib.bib1))), the idea suggested itself that
    they could be made to simulate all sides in a conversation, and that this could
    be used to evaluate certain capabilities better than dataset-based evaluations.
    Qiao et al. ([2023](#bib.bib12)) implement a small number of games (20 questions-like,
    social deduction game) and test them on a small number of models. Li et al. ([2023](#bib.bib8))
    also emphasise the need to go “beyond static datasets” and implement some interactive
    tasks, which however rely on scoring through a referee-model. Gong et al. ([2023](#bib.bib5))
    integrate LLMs in more clearly situated environments such as Minecraft, augmenting
    the models into agents with purpose-built modules. Wu et al. ([2024](#bib.bib16))
    also implement a variety of games and test a few models. Zhou et al. ([2024](#bib.bib17))
    focus specifically on “social” skills and use a game-like setting to study free-form
    interactions between LLM-realised agents. Duan et al. ([2024](#bib.bib4)) finally
    set up a number of zero-shot games for self-play of LLMs, comparing the apparent
    strategies with those known to be game-theory optimal. What these works have in
    common (with the exception of Duan et al. ([2024](#bib.bib4))) is a focus on face
    validity, in that the implemented games are simply postulated as being challenging,
    and no attempt is made at elucidating which aspect of the underlying construct
    they target.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 从2022年意识到大型语言模型（LLMs）可以被视为通用的“对话模型”（例如见 Andreas ([2022](#bib.bib1)))，产生了一个想法：它们可以被用来模拟对话中的所有方面，并且这可以用来比基于数据集的评估更好地评估某些能力。Qiao
    等人 ([2023](#bib.bib12)) 实现了一小部分游戏（类似20问题游戏、社交推理游戏）并在少量模型上进行了测试。Li 等人 ([2023](#bib.bib8))
    也强调了需要“超越静态数据集”，并实施了一些互动任务，但这些任务依赖于通过裁判模型进行评分。Gong 等人 ([2023](#bib.bib5)) 将LLMs整合到更明确的环境中，如Minecraft，将模型增强为具有专用模块的代理。Wu
    等人 ([2024](#bib.bib16)) 也实现了各种游戏并测试了一些模型。Zhou 等人 ([2024](#bib.bib17)) 专注于“社交”技能，并使用类似游戏的设置来研究LLM实现的代理之间的自由互动。最后，Duan
    等人 ([2024](#bib.bib4)) 为LLMs的自我对局设置了多个零样本游戏，比较了明显的策略与已知的博弈论最优策略。这些工作共同点（除了Duan
    等人 ([2024](#bib.bib4))) 是关注表面效度，即实施的游戏被简单地假设为具有挑战性，并未试图阐明其针对的基础构念的哪个方面。
- en: For the current work, we continue our work on one of the frameworks that was
    among the first to realise this idea of “self-play for evaluation” (preceding
    the work cited above), and which also specifically focussed on construct validity,
    the clemgame/clembench framework Chalamalasetti et al. ([2023](#bib.bib2)). We
    do not repeat these validity arguments here and just point the interested reader
    to the original publication; what we do here is to introduce the basic components
    insofar as they are relevant for the work presented here.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对于当前的工作，我们继续在其中一个最早实现“自我对局评估”这一想法的框架上开展工作（早于上述引用的工作），该框架也专门关注构念效度，即 clemgame/clembench
    框架（见 Chalamalasetti 等人 ([2023](#bib.bib2))）。我们在此不重复这些效度论证，仅将感兴趣的读者指向原始出版物；我们在这里做的是介绍基本组件，只要这些组件对当前工作相关。
- en: The main idea of this framework is that games are specified through prompt templates,
    which explain the game goals to the players in natural language, through response
    parsing rules that define what counts as a well-formed response, and through a
    game-specific game flow that defines what counts as a terminal state. A programmatic
    GameMaster then realises game play through the instantiation of the templates
    with specific game instances (e.g., in a guessing game, the word to guess in this
    round), and the turn-by-turn prompting of players (which can be LLMs, or human
    players). The resulting episodes are then scored through game specific scoring
    rules. For each game, one scoring metric is determined as the main metric (always
    ranging from 0 (worst) to 100 (best)). An overall score is computed by averaging
    this metric by game and then over games. Games where a player violates the parsing
    rules count as not played (to end). We track the percentage of games played to
    end; this allows us to separate formatting rule following capabilities (which
    are important for any use of LLMs as internal components where the output needs
    to be of a pre-specified form) from the strategic game play quality. The overall
    score is the product of the two scores. In the following, we will denote the benchmark
    (set of games) as clembench.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 该框架的主要思想是通过提示模板来指定游戏，这些模板用自然语言向玩家解释游戏目标，通过定义什么算作合理响应的响应解析规则，以及通过定义什么算作终态的特定游戏流程来实现。然后，程序化的GameMaster通过用特定的游戏实例（例如，在猜谜游戏中，本轮要猜的单词）实例化模板，并逐轮提示玩家（可以是LLMs，也可以是人类玩家）来实现游戏玩法。生成的游戏集通过特定的游戏评分规则进行评分。对于每个游戏，确定一个评分指标作为主要指标（始终从0（最差）到100（最好））。通过计算游戏的平均分，然后对游戏进行平均，来计算总体分数。玩家违反解析规则的游戏计为未完成（结束）。我们跟踪游戏完成的百分比；这使我们能够将格式规则遵循能力（对于LLMs作为内部组件的任何使用都很重要，因为输出需要是预定义的格式）与战略游戏质量分开。总体得分是两个分数的乘积。在下文中，我们将基准（游戏集）称为clembench。
- en: 'For the experiments reported here, we introduced a generalisation layer for
    accessing LLMs via various routes (e.g., locally via huggingface transformers
    Wolf et al. ([2020](#bib.bib15)) or via llama.cpp¹¹1[https://github.com/ggerganov/llama.cpp](https://github.com/ggerganov/llama.cpp)
    , or via various proprietor-specific APIs). This gives us the flexibility to benchmark
    a large selection of models, as discussed below in Section [3](#S3 "3 Flexible:
    Performance over Time ‣ clembench2024 A Challenging, Dynamic, Complementary, Multilingual
    Benchmark and Underlying Flexible Framework for LLMs as Multi-Action Agents"),
    and easily integrate new ones. We also carefully went through all components described
    above, and in particular corrected some parsing rules and scoring rules for some
    games.²²2A detailed list of changes is available in the project repositories at
    [https://github.com/clembench/.](https://github.com/clembench/.) Note that this
    makes the scores that we report not directly comparable with those previously
    reported. For the subset of models that was scored both in the previously reported
    run and in our latest one (19 models), we calculated a rank correlation (Kendall’s
    tau, $r_{\tau}$), i.e., a strong to very strong correlation.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '对于这里报告的实验，我们引入了一个通用层，用于通过各种途径访问LLMs（例如，通过huggingface transformers Wolf等人的[2020](#bib.bib15)或通过llama.cpp¹¹1[https://github.com/ggerganov/llama.cpp](https://github.com/ggerganov/llama.cpp)，或通过各种专有的API）。这使我们能够灵活地对大量模型进行基准测试，如下文第[3](#S3
    "3 Flexible: Performance over Time ‣ clembench2024 A Challenging, Dynamic, Complementary,
    Multilingual Benchmark and Underlying Flexible Framework for LLMs as Multi-Action
    Agents")节所讨论，并轻松地集成新的模型。我们还仔细检查了上述所有组件，特别是纠正了一些游戏的解析规则和评分规则。²²2有关更改的详细列表可在项目仓库中查看，[https://github.com/clembench/.](https://github.com/clembench/.)
    请注意，这使得我们报告的分数与之前报告的分数不可直接比较。对于在之前报告的运行和我们最新的运行中都进行评分的模型子集（19个模型），我们计算了排名相关性（Kendall’s
    tau，$r_{\tau}$），即，强到非常强的相关性。'
- en: '| models | sc | o/g |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| models | sc | o/g |'
- en: '| --- | --- | --- |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| gpt-4 | 59.49 | $$ |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4 | 59.49 | $$ |'
- en: '| claude-v1.3 | 37.07 | $$ |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| claude-v1.3 | 37.07 | $$ |'
- en: '| gpt-3.5-turbo | 37.02 | $$ |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| gpt-3.5-turbo | 37.02 | $$ |'
- en: '| text-davinci-003 | 15.78 | $$ |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| text-davinci-003 | 15.78 | $$ |'
- en: '| vicuna-13b | 4.24 | ow |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| vicuna-13b | 4.24 | ow |'
- en: '| oasst-12b | 1.74 | ow |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| oasst-12b | 1.74 | ow |'
- en: '| koala-13b | 1.48 | ow |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| koala-13b | 1.48 | ow |'
- en: '| falcon-40b | 0.71 | ow |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| falcon-40b | 0.71 | ow |'
- en: '| luminous-supreme | 0.00 | $$ |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| luminous-supreme | 0.00 | $$ |'
- en: '| models | sc | o/g |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| models | sc | o/g |'
- en: '| --- | --- | --- |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| gpt-4-0613 | 60.90 | $$ |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-0613 | 60.90 | $$ |'
- en: '| gpt-4-1106-preview | 60.33 | $$ |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-1106-preview | 60.33 | $$ |'
- en: '| gpt-4-0314 | 58.81 | $$ |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-0314 | 58.81 | $$ |'
- en: '| claude-v1.3 | 37.64 | $$ |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| claude-v1.3 | 37.64 | $$ |'
- en: '| claude-2.1 | 36.38 | $$ |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| claude-2.1 | 36.38 | $$ |'
- en: '| claude-2 | 33.71 | $$ |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| claude-2 | 33.71 | $$ |'
- en: '| gpt-3.5-turbo-0613 | 32.53 | $$ |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| gpt-3.5-turbo-0613 | 32.53 | $$ |'
- en: '| gpt-3.5-turbo-1106 | 30.45 | $$ |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| gpt-3.5-turbo-1106 | 30.45 | $$ |'
- en: '| openchat_3.5 | 19.72 | ow |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| openchat_3.5 | 19.72 | ow |'
- en: '| mistral-medium | 17.99 | ow |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| mistral-medium | 17.99 | ow |'
- en: '| mixtral-8x7b-instruct-v0.1 | 17.81 | ow |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| mixtral-8x7b-instruct-v0.1 | 17.81 | ow |'
- en: '| openchat-3.5-1210 | 17.61 | ow |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| openchat-3.5-1210 | 17.61 | ow |'
- en: '| sheep-duck-llama-2-70b-v1.1 | 17.12 | ow |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| sheep-duck-llama-2-70b-v1.1 | 17.12 | ow |'
- en: '| yi-34b-chat | 16.77 | ow |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| yi-34b-chat | 16.77 | ow |'
- en: '| wizardlm-70b-v1.0 | 16.70 | ow |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| wizardlm-70b-v1.0 | 16.70 | ow |'
- en: '| tulu-2-dpo-70b | 15.90 | ow |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| tulu-2-dpo-70b | 15.90 | ow |'
- en: '| sus-chat-34b | 15.64 | ow |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| sus-chat-34b | 15.64 | ow |'
- en: '| claude-instant-1.2 | 15.44 | $$ |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| claude-instant-1.2 | 15.44 | $$ |'
- en: '| models | sc | o/g |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| models | sc | o/g |'
- en: '| --- | --- | --- |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| gpt-4-turbo-2024-04-09 | 58.30 | $$ |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-turbo-2024-04-09 | 58.30 | $$ |'
- en: '| gpt-4-0125-preview | 52.50 | $$ |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-0125-preview | 52.50 | $$ |'
- en: '| gpt-4-1106-preview | 51.99 | $$ |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-1106-preview | 51.99 | $$ |'
- en: '| gpt-4-0613 | 51.09 | $$ |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-0613 | 51.09 | $$ |'
- en: '| gpt-4o-2024-05-13 | 48.34 | $$ |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4o-2024-05-13 | 48.34 | $$ |'
- en: '| claude-3-opus-20240229 | 42.42 | $$ |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| claude-3-opus-20240229 | 42.42 | $$ |'
- en: '| gemini-1.5-pro-latest | 41.72 | $$ |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| gemini-1.5-pro-latest | 41.72 | $$ |'
- en: '| llama-3-70b-instruct | 35.11 | ow |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| llama-3-70b-instruct | 35.11 | ow |'
- en: '| claude-2.1 | 32.50 | $$ |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| claude-2.1 | 32.50 | $$ |'
- en: '| gemini-1.5-flash-latest | 32.00 | $$ |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| gemini-1.5-flash-latest | 32.00 | $$ |'
- en: '| claude-3-sonnet-20240229 | 30.53 | $$ |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| claude-3-sonnet-20240229 | 30.53 | $$ |'
- en: '| qwen1.5-72b-chat | 30.37 | ow |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| qwen1.5-72b-chat | 30.37 | ow |'
- en: '| mistral-large-2402 | 28.17 | $$ |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| mistral-large-2402 | 28.17 | $$ |'
- en: '| gpt-3.5-turbo-0125 | 27.22 | $$ |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| gpt-3.5-turbo-0125 | 27.22 | $$ |'
- en: '| gemini-1.0-pro | 26.95 | $$ |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| gemini-1.0-pro | 26.95 | $$ |'
- en: '| command-r-plus | 24.94 | ow |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| command-r-plus | 24.94 | ow |'
- en: '| openchat_3.5 | 23.64 | ow |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| openchat_3.5 | 23.64 | ow |'
- en: '| claude-3-haiku-20240307 | 22.49 | $$ |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| claude-3-haiku-20240307 | 22.49 | $$ |'
- en: '| sheep-duck-llama-2-70b-v1.1 | 21.50 | ow |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| sheep-duck-llama-2-70b-v1.1 | 21.50 | ow |'
- en: '| llama-3-8b-instruct | 19.99 | ow |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| llama-3-8b-instruct | 19.99 | ow |'
- en: '| openchat-3.5-1210 | 18.22 | ow |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| openchat-3.5-1210 | 18.22 | ow |'
- en: '| wizardlm-70b-v1.0 | 17.40 | ow |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| wizardlm-70b-v1.0 | 17.40 | ow |'
- en: '| openchat-3.5-0106 | 17.10 | ow |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| openchat-3.5-0106 | 17.10 | ow |'
- en: '| qwen1.5-14b-chat | 16.80 | ow |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| qwen1.5-14b-chat | 16.80 | ow |'
- en: '| mistral-medium-2312 | 16.43 | $$ |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| mistral-medium-2312 | 16.43 | $$ |'
- en: 'Table 1: From left to right, results on the English clembench from June 2023,
    November 2023, May 2024\. “ow”: open weight models, “$$”: gated models. The best
    gated model stayed constant (modulo fixes to scoring code, see text), open weight
    models gained substantially.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 'Table 1: 从左到右，2023年6月、2023年11月和2024年5月的英语 clembench 结果。 “ow”：开放权重模型，“$$”：有门控模型。最佳有门控模型保持不变（除非修正评分代码，请参见正文），开放权重模型显著提升。'
- en: '3 Flexible: Performance over Time'
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 灵活性：随时间的表现
- en: Table [1](#S2.T1 "Table 1 ‣ 2 Dialogue Games and Agent Capabilities ‣ clembench2024
    A Challenging, Dynamic, Complementary, Multilingual Benchmark and Underlying Flexible
    Framework for LLMs as Multi-Action Agents") shows the clembench results over various
    timepoints, from the results of the initial publication, over an intermediate
    point (November 2023), to current results.³³3The current leaderboard and all previous
    versions can always be found at [https://clembench.github.io/leaderboard.html](https://clembench.github.io/leaderboard.html),
    with detailed result logs at [https://github.com/clembench/clembench-runs](https://github.com/clembench/clembench-runs).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 表[1](#S2.T1 "Table 1 ‣ 2 Dialogue Games and Agent Capabilities ‣ clembench2024
    A Challenging, Dynamic, Complementary, Multilingual Benchmark and Underlying Flexible
    Framework for LLMs as Multi-Action Agents")显示了不同时间点的 clembench 结果，从初始发布的结果，到中间点（2023年11月），再到当前结果。³³3
    当前的排行榜和所有之前的版本可以随时在[https://clembench.github.io/leaderboard.html](https://clembench.github.io/leaderboard.html)上找到，详细结果日志可以在[https://github.com/clembench/clembench-runs](https://github.com/clembench/clembench-runs)上查看。
- en: 'Several things are notable. First, the changes described above allowed us to
    keep track of the rapidly evolving field. Whereas Chalamalasetti et al. ([2023](#bib.bib2))
    only reported results for 9 models, the current version now tracks 53 models.
    (The figure is capped at scores below 16, to save space.) Secondly, two interesting
    trends are observable:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 几件事值得注意。首先，上述变化使我们能够跟踪迅速发展的领域。而 Chalamalasetti 等人 ([2023](#bib.bib2)) 仅报告了 9
    个模型的结果，当前版本现跟踪了 53 个模型。（该数字限制在 16 以下的分数，以节省空间。）其次，有两个有趣的趋势可以观察：
- en: $\bullet$ While there is more competition in the field of closed weight models,
    as a whole, this field has not moved up. The top position is still held by a variant
    of GPT-4, and the top score has also not improved (insofar as the numbers are
    directly comparable; see discussion above). This indicates a certain saturation
    in achievable performance.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 尽管在封闭权重模型领域竞争更加激烈，但整体上，该领域并未有所提升。顶尖位置仍由GPT-4的一个变体占据，且顶尖分数也没有提高（在数字直接可比的情况下；见上文讨论）。这表明在可实现性能方面存在一定的饱和。
- en: $\bullet$ Open weight models, on the other hand, have improved dramatically
    over this time span. While the distance between the best open and the best gated
    model was 55.25 points in June 2023, it was reduced to 41.18 five months later
    (November 2023), and now (May 2024) stands at 24.94, thanks to the singular performance
    of llama3-70b-ins. (As the full tables in the Appendix [A](#A1 "Appendix A Full
    Results ‣ clembench2024 A Challenging, Dynamic, Complementary, Multilingual Benchmark
    and Underlying Flexible Framework for LLMs as Multi-Action Agents") show, this
    is partially due to the much improved formatting rule following capabilities of
    these models.)
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 另一方面，开放权重模型在这一时间跨度内有了显著改进。尽管在2023年6月，最佳开放模型与最佳门控模型之间的差距为55.25分，但五个月后（2023年11月）缩小至41.18，现在（2024年5月）降至24.94，这要归功于llama3-70b-ins的卓越表现。（正如附录[A](#A1
    "Appendix A Full Results ‣ clembench2024 A Challenging, Dynamic, Complementary,
    Multilingual Benchmark and Underlying Flexible Framework for LLMs as Multi-Action
    Agents")中的完整表格所示，这部分归因于这些模型在格式规则跟随能力上的显著提升。）
- en: This indicates, we believe, the usefulness of clembench as an instrument for
    tracking developments in the field, in particular with respect to the suitability
    of a model to be directed to enter into goal-oriented interactions.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们相信，这表明clembench作为跟踪该领域发展的工具，特别是在评估模型是否适合进行目标导向的互动方面，具有一定的价值。
- en: '4 Dynamic: Games, not Instances'
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 动态：游戏，而非实例
- en: As remarked already by Chalamalasetti et al. ([2023](#bib.bib2)), but not followed
    up on, the separation between game specification (through templates) and game
    instances makes it possible to treat the games as generative devices creating
    a dynamic benchmark that can more easily evade “data contamination” Magar and
    Schwartz ([2022](#bib.bib10)). For the run reported above, we created new instances
    for all of the games contained in clembench. For some games, this just required
    sampling from an already existing pool (e.g., new target words for the wordle
    game), for others, this required light manual work (e.g., selecting new target
    words for the taboo game following the methodology described in the original paper;
    creating new target images for the image game). As reported above, the ranking
    correlation between the previous run and ours is high (0.71), which we take as
    indication that we are indeed evaluating the game, and not the instances.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 正如Chalamalasetti等人（[2023](#bib.bib2)）已经指出的那样，但未进一步跟进，游戏规范（通过模板）与游戏实例之间的分离使得可以将这些游戏视为生成设备，创建出一个动态基准，更容易避开“数据污染”（Magar和Schwartz（[2022](#bib.bib10)））。在上述报告中，我们为clembench中包含的所有游戏创建了新实例。对于一些游戏，这只需要从现有池中抽样（例如，为wordle游戏提供新的目标词），对于其他游戏，则需要一些轻微的手动操作（例如，按照原始论文中描述的方法为taboo游戏选择新的目标词；为image游戏创建新的目标图像）。如上所述，我们的运行与之前的排名相关性很高（0.71），我们认为这表明我们确实在评估游戏，而不是实例。
- en: '| % played | de | en | it | ja | pt | te | tk | tr | zh |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| % played | de | en | it | ja | pt | te | tk | tr | zh |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| GPT-4 | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0
    (0.00) | 99.44 (-0.56) | 98.33 (-1.67) | 100.0 (0.00) | 72.78 (-27.22) |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0
    (0.00) | 99.44 (-0.56) | 98.33 (-1.67) | 100.0 (0.00) | 72.78 (-27.22) |'
- en: '| Claude-3 | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0
    (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| Claude-3 | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0
    (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) |'
- en: '| Llama-3-70b | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) |
    100.0 (0.00) | 99.44 (-0.56) | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| Llama-3-70b | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) |
    100.0 (0.00) | 99.44 (-0.56) | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) |'
- en: '| Llama-3-8b | 98.33 (-1.67) | 100.0 (0.00) | 100.0 (0.00) | 98.89 (-1.11)
    | 100.0 (0.00) | 87.78 (-12.22) | 28.89 (-71.11) | 0.0 (-100.00) | 100.0 (0.00)
    |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| Llama-3-8b | 98.33 (-1.67) | 100.0 (0.00) | 100.0 (0.00) | 98.89 (-1.11)
    | 100.0 (0.00) | 87.78 (-12.22) | 28.89 (-71.11) | 0.0 (-100.00) | 100.0 (0.00)
    |'
- en: '| Command-R+ | 100.0 (0.56) | 99.44 (0.00) | 100.0 (0.56) | 100.0 (0.56) |
    100.0 (0.56) | 83.89 (-15.55) | 67.78 (-31.66) | 100.0 (0.56) | 99.44 (0.00) |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| Command-R+ | 100.0 (0.56) | 99.44 (0.00) | 100.0 (0.56) | 100.0 (0.56) |
    100.0 (0.56) | 83.89 (-15.55) | 67.78 (-31.66) | 100.0 (0.56) | 99.44 (0.00) |'
- en: '| Openchat | 98.33 (-1.67) | 100.0 (0.00) | 46.67 (-53.33) | 100.0 (0.00) |
    50.0 (-50.00) | 0.0 (-100.00) | 0.0 (-100.00) | 0.0 (-100.00) | 46.67 (-53.33)
    |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| Openchat | 98.33 (-1.67) | 100.0 (0.00) | 46.67 (-53.33) | 100.0 (0.00) |
    50.0 (-50.00) | 0.0 (-100.00) | 0.0 (-100.00) | 0.0 (-100.00) | 46.67 (-53.33)
    |'
- en: '| quality score | de | en | it | ja | pt | te | tk | tr | zh |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 质量得分 | de | en | it | ja | pt | te | tk | tr | zh |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| GPT-4 | 85.56 (-1.66) | 87.22 (0.00) | 89.44 (2.22) | 85.56 (-1.66) | 81.11
    (-6.11) | 35.2 (-52.02) | 75.14 (-12.08) | 50.0 (-37.22) | 88.55 (1.33) |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | 85.56 (-1.66) | 87.22 (0.00) | 89.44 (2.22) | 85.56 (-1.66) | 81.11
    (-6.11) | 35.2 (-52.02) | 75.14 (-12.08) | 50.0 (-37.22) | 88.55 (1.33) |'
- en: '| Claude-3 | 71.11 (-6.11) | 77.22 (0.00) | 72.22 (-5.00) | 68.89 (-8.33) |
    73.33 (-3.89) | 52.22 (-25.00) | 61.11 (-16.11) | 58.89 (-18.33) | 68.89 (-8.33)
    |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| Claude-3 | 71.11 (-6.11) | 77.22 (0.00) | 72.22 (-5.00) | 68.89 (-8.33) |
    73.33 (-3.89) | 52.22 (-25.00) | 61.11 (-16.11) | 58.89 (-18.33) | 68.89 (-8.33)
    |'
- en: '| Llama-3-70b | 58.33 (-4.45) | 62.78 (0.00) | 66.67 (3.89) | 56.11 (-6.67)
    | 60.56 (-2.22) | 45.25 (-17.53) | 36.11 (-26.67) | 45.0 (-17.78) | 68.89 (6.11)
    |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| Llama-3-70b | 58.33 (-4.45) | 62.78 (0.00) | 66.67 (3.89) | 56.11 (-6.67)
    | 60.56 (-2.22) | 45.25 (-17.53) | 36.11 (-26.67) | 45.0 (-17.78) | 68.89 (6.11)
    |'
- en: '| Llama-3-8b | 43.5 (-4.28) | 47.78 (0.00) | 37.78 (-10.00) | 39.33 (-8.45)
    | 46.11 (-1.67) | 34.18 (-13.60) | 34.62 (-13.16) | nan (nan) | 35.0 (-12.78)
    |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| Llama-3-8b | 43.5 (-4.28) | 47.78 (0.00) | 37.78 (-10.00) | 39.33 (-8.45)
    | 46.11 (-1.67) | 34.18 (-13.60) | 34.62 (-13.16) | nan (nan) | 35.0 (-12.78)
    |'
- en: '| Command-R+ | 37.22 (-1.33) | 38.55 (0.00) | 38.33 (-0.22) | 36.11 (-2.44)
    | 37.22 (-1.33) | 29.8 (-8.75) | 31.15 (-7.40) | 35.56 (-2.99) | 38.55 (0.00)
    |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| Command-R+ | 37.22 (-1.33) | 38.55 (0.00) | 38.33 (-0.22) | 36.11 (-2.44)
    | 37.22 (-1.33) | 29.8 (-8.75) | 31.15 (-7.40) | 35.56 (-2.99) | 38.55 (0.00)
    |'
- en: '| Openchat | 35.59 (0.03) | 35.56 (0.00) | 54.76 (19.20) | 36.11 (0.55) | 56.67
    (21.11) | nan (nan) | nan (nan) | nan (nan) | 40.48 (4.92) |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| Openchat | 35.59 (0.03) | 35.56 (0.00) | 54.76 (19.20) | 36.11 (0.55) | 56.67
    (21.11) | nan (nan) | nan (nan) | nan (nan) | 40.48 (4.92) |'
- en: 'Table 2: The reference game in different languages. Top, “% played”, measuring
    formatting rule following, bottom, “quality score”, measuring quality of the well-formed
    games. In brackets the delta compared to the original English version. GPT-4:
    gpt-4-turbo-2024-04-09, Claude-3: claude-3-opus-20240229, Openchat: openchat-3.5-0106'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：不同语言中的参考游戏。顶部，“% 玩过”，测量格式规则的遵循情况；底部，“质量得分”，测量格式良好的游戏的质量。括号中为与原英文版的差异。GPT-4：gpt-4-turbo-2024-04-09，Claude-3：claude-3-opus-20240229，Openchat：openchat-3.5-0106
- en: '5 Challenging: Room to Grow'
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 挑战性：成长的空间
- en: 'Chalamalasetti et al. ([2023](#bib.bib2)) “suspect” that human performance
    on clembench would be “near the ceiling”. We tested this assumption. Among the
    authors of this paper, we created pairings so as to ensure that no player played
    a game where they were involved in the creation of instances. Since during the
    work on this paper all players developed a good understanding of all games, we
    consider the resulting scores to represent not average human performance, but
    rather human expert performance. We played between 10 and 15 episodes per game
    (leaving out wordle-clue and wordle-critic, as these are only variants of the
    main wordle game). All games were played to end, hence ‘% played’ is, unsurprisingly,
    100 for the human players. The resultant quality scores were: wordle: 72, taboo:
    80.5; drawing: 95.2; reference: 100; leading to an average of 86.93 – indeed considerably
    higher than the best result reported in Table [1](#S2.T1 "Table 1 ‣ 2 Dialogue
    Games and Agent Capabilities ‣ clembench2024 A Challenging, Dynamic, Complementary,
    Multilingual Benchmark and Underlying Flexible Framework for LLMs as Multi-Action
    Agents").'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Chalamalasetti 等人 ([2023](#bib.bib2)) “怀疑”人类在 clembench 上的表现会“接近上限”。我们检验了这一假设。在本文作者之间，我们创建了配对，以确保没有玩家参与了实例的创建。由于在本论文工作期间所有玩家对所有游戏都有很好的理解，我们认为最终得分代表的不是普通人类表现，而是人类专家表现。我们每个游戏进行了
    10 到 15 集的游戏（排除 wordle-clue 和 wordle-critic，因为它们只是主要 wordle 游戏的变体）。所有游戏都玩到结束，因此“%
    玩过”的数据对于人类玩家来说，毫无意外地是 100。结果的质量得分为：wordle：72，taboo：80.5；drawing：95.2；reference：100；平均
    86.93 —— 确实显著高于表格 [1](#S2.T1 "表 1 ‣ 2 对话游戏和代理能力 ‣ clembench2024 一个具有挑战性、动态的、互补的、多语言的基准以及
    LLM 作为多动作代理的灵活框架") 中报告的最佳结果。
- en: '6 Complementary: Correlations'
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 互补性：相关性
- en: To investigate how the clembench measures relate to what is measured via reference-based
    evaluation on the one hand, and preference-based evaluation on the other, we computed
    rank correlation with HELM (v1.3.0, 2024-05-07; Liang et al. ([2022](#bib.bib9)))
    and Chatbot Arena (CA; retrieved 2024-05-16; Chiang et al. ([2024](#bib.bib3))),
    respectively. With CA, clembench shares 30 models. The rankings correlate highly,
    with Kendall’s tau at 0.65 ($r_{\tau}$). This very interesting result shows that
    clembench correlates more closely to results achieved through interaction (Chatbot
    Arena) — while not actually requiring human interaction and running fully offline.
    (For a graphical view of the ranking relations, see the Appendix [B](#A2 "Appendix
    B Across-Benchmark Correlations ‣ clembench2024 A Challenging, Dynamic, Complementary,
    Multilingual Benchmark and Underlying Flexible Framework for LLMs as Multi-Action
    Agents").)
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 为了研究 clembench 测量值与通过参考基础评估和偏好基础评估所测量内容之间的关系，我们分别计算了与 HELM（v1.3.0, 2024-05-07;
    Liang et al. ([2022](#bib.bib9))) 和 Chatbot Arena (CA; 检索于 2024-05-16; Chiang
    et al. ([2024](#bib.bib3))) 的等级相关性。使用 CA，clembench 共享 30 个模型。排名高度相关，Kendall 的
    tau 值为 0.65 ($r_{\tau}$)。这一非常有趣的结果显示 clembench 与通过交互（Chatbot Arena）获得的结果有更紧密的相关性——同时无需实际的人类互动并完全离线运行。（有关排名关系的图示视图，请参见附录 [B](#A2
    "附录 B 跨基准相关性 ‣ clembench2024 一个具有挑战性、动态、多样化的、多语言基准测试和底层灵活框架的 LLM 多动作代理")。）
- en: '7 Multilingual: A Case Study'
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 多语言：案例研究
- en: 'The separation in the clemgame framework of game specification and game logic
    makes it possible to realise the same game in different languages, simply through
    translating the game templates and game parsing rules. We make use of this to
    probe the multilingual capabilities of a subset of the models tested above, using
    the reference game as a case study. (In this game, player A is presented with
    three, unicode character-based, 5x5 pixel images, and tasked to describe the first
    one. Player B is presented with the same images, potentially in a different order,
    and is tasked to identify the described one. Random performance would lead to
    a quality score of 33.) We selected a set of typologically diverse languages (see
    Appendix [C](#A3 "Appendix C Language Tested in the Case Study ‣ clembench2024
    A Challenging, Dynamic, Complementary, Multilingual Benchmark and Underlying Flexible
    Framework for LLMs as Multi-Action Agents")) and asked native speakers to translate
    the prompts and target expressions. Table [2](#S4.T2 "Table 2 ‣ 4 Dynamic: Games,
    not Instances ‣ clembench2024 A Challenging, Dynamic, Complementary, Multilingual
    Benchmark and Underlying Flexible Framework for LLMs as Multi-Action Agents")
    shows the impact of playing in languages other than English. The large commercial
    languages hold up well when it comes to following the formatting instructions
    (top part of the Table), as does llama3-70b. All models are mostly impacted by
    the quality of the game play.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: clemgame 框架中游戏规范与游戏逻辑的分离使得通过翻译游戏模板和游戏解析规则，可以在不同语言中实现相同的游戏。我们利用这一点来探讨上述模型子集的多语言能力，以参考游戏为案例进行研究。（在这个游戏中，玩家
    A 会看到三个基于 Unicode 字符的 5x5 像素图像，并被要求描述第一个图像。玩家 B 会看到相同的图像，可能顺序不同，并被要求识别描述的图像。随机表现会导致质量分数为
    33。）我们选择了一组类型学上多样的语言（见附录 [C](#A3 "附录 C 案例研究中测试的语言 ‣ clembench2024 一个具有挑战性、动态、多样化的、多语言基准测试和底层灵活框架的
    LLM 多动作代理")），并请母语者翻译提示和目标表达。表 [2](#S4.T2 "表 2 ‣ 4 动态：游戏，而非实例 ‣ clembench2024 一个具有挑战性、动态、多样化的、多语言基准测试和底层灵活框架的
    LLM 多动作代理") 显示了使用非英语语言进行游戏的影响。大多数商业语言在遵循格式指令方面表现良好，llama3-70b 也是如此。所有模型主要受到游戏质量的影响。
- en: We leave a more detailed analysis of these results to future work, only making
    the point here that this case study shows the value of clembench as a promising
    instrument for investigating multilingual interaction instruction following capabilities.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这些结果的更详细分析留待未来的工作中，仅在这里指出这一案例研究展示了 clembench 作为调查多语言互动指令跟随能力的有前景的工具的价值。
- en: 8 Conclusions
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 结论
- en: 'In this short paper, we have assessed a recently proposed evaluation approach
    for LLMs that complements existing reference-based and preference-based approaches.
    We have shown that it possesses certain desirable properties, which promise to
    let it keep its relevance (because it is flexible to be adapted to new models,
    and its dynamic nature counteracts the danger of data contamination). The games
    implemented in the framework appear to sit at an interesting level: They are not
    particularly challenging for human players, and yet they are and remain so even
    for the best-performing models. In a case study, we have shown that the approach
    can also serve to investigate multilingual capabilities. Future work may show
    even further use cases, for example as a learning environment in a reinforcement
    learning setting, or as a development environment for more applied goal-directed
    dialogue systems.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇简短的论文中，我们评估了一种新提出的LLMs评价方法，这种方法与现有的基于参考和基于偏好的方法相辅相成。我们展示了它具备某些理想特性，这些特性有望保持其相关性（因为它可以灵活地适应新模型，并且其动态特性抵消了数据污染的危险）。框架中实现的游戏处于一个有趣的水平：它们对人类玩家来说不是特别具有挑战性，但即使是表现最好的模型也如此。在案例研究中，我们展示了该方法也可以用于调查多语言能力。未来的工作可能会展示更多的应用场景，例如在强化学习环境中作为学习环境，或作为更多应用目标导向对话系统的开发环境。
- en: References
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Andreas (2022) Jacob Andreas. 2022. [Language models as agent models](https://doi.org/10.18653/v1/2022.findings-emnlp.423).
    In *Findings of the Association for Computational Linguistics: EMNLP 2022*, pages
    5769–5779, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Andreas (2022) Jacob Andreas. 2022. [Language models as agent models](https://doi.org/10.18653/v1/2022.findings-emnlp.423)。在*计算语言学协会发现：EMNLP
    2022*中，页面5769–5779，阿布扎比，阿拉伯联合酋长国。计算语言学协会。
- en: 'Chalamalasetti et al. (2023) Kranti Chalamalasetti, Jana Götze, Sherzod Hakimov,
    Brielen Madureira, Philipp Sadler, and David Schlangen. 2023. [clembench: Using
    game play to evaluate chat-optimized language models as conversational agents](https://doi.org/10.18653/v1/2023.emnlp-main.689).
    In *Proceedings of the 2023 Conference on Empirical Methods in Natural Language
    Processing*, pages 11174–11219, Singapore. Association for Computational Linguistics.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chalamalasetti et al. (2023) Kranti Chalamalasetti, Jana Götze, Sherzod Hakimov,
    Brielen Madureira, Philipp Sadler, and David Schlangen. 2023. [clembench: Using
    game play to evaluate chat-optimized language models as conversational agents](https://doi.org/10.18653/v1/2023.emnlp-main.689)。在*2023年自然语言处理经验方法会议论文集*中，页面11174–11219，新加坡。计算语言学协会。'
- en: 'Chiang et al. (2024) Wei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios Nikolas
    Angelopoulos, Tianle Li, Dacheng Li, Hao Zhang, Banghua Zhu, Michael I. Jordan,
    Joseph E. Gonzalez, and Ion Stoica. 2024. [Chatbot arena: An open platform for
    evaluating llms by human preference](https://doi.org/10.48550/ARXIV.2403.04132).
    *CoRR*, abs/2403.04132.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chiang et al. (2024) Wei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios
    Nikolas Angelopoulos, Tianle Li, Dacheng Li, Hao Zhang, Banghua Zhu, Michael I.
    Jordan, Joseph E. Gonzalez, and Ion Stoica. 2024. [Chatbot arena: An open platform
    for evaluating llms by human preference](https://doi.org/10.48550/ARXIV.2403.04132)。*CoRR*，abs/2403.04132。'
- en: 'Duan et al. (2024) Jinhao Duan, Renming Zhang, James Diffenderfer, Bhavya Kailkhura,
    Lichao Sun, Elias Stengel-Eskin, Mohit Bansal, Tianlong Chen, and Kaidi Xu. 2024.
    [Gtbench: Uncovering the strategic reasoning limitations of llms via game-theoretic
    evaluations](https://arxiv.org/abs/2402.12348). *Preprint*, arXiv:2402.12348.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Duan et al. (2024) Jinhao Duan, Renming Zhang, James Diffenderfer, Bhavya Kailkhura,
    Lichao Sun, Elias Stengel-Eskin, Mohit Bansal, Tianlong Chen, and Kaidi Xu. 2024.
    [Gtbench: Uncovering the strategic reasoning limitations of llms via game-theoretic
    evaluations](https://arxiv.org/abs/2402.12348)。*预印本*，arXiv:2402.12348。'
- en: 'Gong et al. (2023) Ran Gong, Qiuyuan Huang, Xiaojian Ma, Hoi Vo, Zane Durante,
    Yusuke Noda, Zilong Zheng, Song-Chun Zhu, Demetri Terzopoulos, Li Fei-Fei, and
    Jianfeng Gao. 2023. [Mindagent: Emergent gaming interaction](https://arxiv.org/abs/2309.09971).
    *Preprint*, arXiv:2309.09971.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gong et al. (2023) Ran Gong, Qiuyuan Huang, Xiaojian Ma, Hoi Vo, Zane Durante,
    Yusuke Noda, Zilong Zheng, Song-Chun Zhu, Demetri Terzopoulos, Li Fei-Fei, and
    Jianfeng Gao. 2023. [Mindagent: Emergent gaming interaction](https://arxiv.org/abs/2309.09971)。*预印本*，arXiv:2309.09971。'
- en: Hendrycks et al. (2021) Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou,
    Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2021. [Measuring Massive Multitask
    Language Understanding](http://arxiv.org/abs/2009.03300). In *Proceedings of the
    International Conference on Learning Representations (ICLR)ICLR*. ArXiv:2009.03300
    [cs].
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hendrycks et al. (2021) Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou,
    Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2021. [Measuring Massive Multitask
    Language Understanding](http://arxiv.org/abs/2009.03300)。在*国际学习表示会议 (ICLR)论文集*中。ArXiv:2009.03300
    [cs]。
- en: Hudeček and Dusek (2023) Vojtěch Hudeček and Ondrej Dusek. 2023. [Are large
    language models all you need for task-oriented dialogue?](https://doi.org/10.18653/v1/2023.sigdial-1.21)
    In *Proceedings of the 24th Annual Meeting of the Special Interest Group on Discourse
    and Dialogue*, pages 216–228, Prague, Czechia. Association for Computational Linguistics.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hudeček and Dusek (2023) Vojtěch Hudeček 和 Ondrej Dusek。2023年。[大型语言模型是否足以应对任务导向对话？](https://doi.org/10.18653/v1/2023.sigdial-1.21)
    在 *第24届话语与对话特别兴趣小组年会*，第216–228页，捷克布拉格。计算语言学协会。
- en: 'Li et al. (2023) Jiatong Li, Rui Li, and Qi Liu. 2023. [Beyond static datasets:
    A deep interaction approach to llm evaluation](https://arxiv.org/abs/2309.04369).
    *Preprint*, arXiv:2309.04369.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. (2023) Jiatong Li, Rui Li, 和 Qi Liu。2023年。[超越静态数据集：一种深度交互方法来评估LLM](https://arxiv.org/abs/2309.04369)。*预印本*，arXiv:2309.04369。
- en: Liang et al. (2022) Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras,
    Dilara Soylu, Michihiro Yasunaga, and alia. 2022. [Holistic evaluation of language
    models](https://doi.org/10.48550/arXiv.2211.09110). *CoRR*, abs/2211.09110.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liang et al. (2022) Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras,
    Dilara Soylu, Michihiro Yasunaga, 和其他人。2022年。[语言模型的整体评估](https://doi.org/10.48550/arXiv.2211.09110)。*CoRR*，abs/2211.09110。
- en: 'Magar and Schwartz (2022) Inbal Magar and Roy Schwartz. 2022. [Data contamination:
    From memorization to exploitation](https://doi.org/10.18653/v1/2022.acl-short.18).
    In *Proceedings of the 60th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)*, pages 157–165, Dublin, Ireland. Association
    for Computational Linguistics.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Magar and Schwartz (2022) Inbal Magar 和 Roy Schwartz。2022年。[数据污染：从记忆到利用](https://doi.org/10.18653/v1/2022.acl-short.18)。在
    *第60届计算语言学协会年会（第2卷：短论文集）*，第157–165页，爱尔兰都柏林。计算语言学协会。
- en: OpenAI et al. (2024) OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama
    Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt,
    Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie
    Balcom, Paul Baltescu, Haiming Bao, Mohammad Bavarian, Jeff Belgum, Irwan Bello,
    and alia. 2024. [Gpt-4 technical report](https://arxiv.org/abs/2303.08774). *Preprint*,
    arXiv:2303.08774.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI et al. (2024) OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama
    Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt,
    Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie
    Balcom, Paul Baltescu, Haiming Bao, Mohammad Bavarian, Jeff Belgum, Irwan Bello,
    和其他人。2024年。[GPT-4技术报告](https://arxiv.org/abs/2303.08774)。*预印本*，arXiv:2303.08774。
- en: 'Qiao et al. (2023) Dan Qiao, Chenfei Wu, Yaobo Liang, Juntao Li, and Nan Duan.
    2023. [Gameeval: Evaluating llms on conversational games](https://arxiv.org/abs/2308.10032).
    *Preprint*, arXiv:2308.10032.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qiao et al. (2023) Dan Qiao, Chenfei Wu, Yaobo Liang, Juntao Li, 和 Nan Duan。2023年。[Gameeval：在对话游戏上评估LLM](https://arxiv.org/abs/2308.10032)。*预印本*，arXiv:2308.10032。
- en: 'Schlangen (2023) David Schlangen. 2023. [Dialogue games for benchmarking language
    understanding: Motivation, taxonomy, strategy](https://doi.org/10.48550/arXiv.2304.07007).
    *CoRR*, abs/2304.07007.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schlangen (2023) David Schlangen。2023年。[用于基准测试语言理解的对话游戏：动机、分类、策略](https://doi.org/10.48550/arXiv.2304.07007)。*CoRR*，abs/2304.07007。
- en: Sekulic et al. (2024) Ivan Sekulic, Silvia Terragni, Victor Guimarães, Nghia
    Khau, Bruna Guedes, Modestas Filipavicius, Andre Ferreira Manso, and Roland Mathis.
    2024. [Reliable LLM-based user simulator for task-oriented dialogue systems](https://aclanthology.org/2024.scichat-1.3).
    In *Proceedings of the 1st Workshop on Simulating Conversational Intelligence
    in Chat (SCI-CHAT 2024)*, pages 19–35, St. Julians, Malta. Association for Computational
    Linguistics.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sekulic et al. (2024) Ivan Sekulic, Silvia Terragni, Victor Guimarães, Nghia
    Khau, Bruna Guedes, Modestas Filipavicius, Andre Ferreira Manso, 和 Roland Mathis。2024年。[面向任务的对话系统的可靠基于LLM的用户模拟器](https://aclanthology.org/2024.scichat-1.3)。在
    *第1届对话智能模拟研讨会（SCI-CHAT 2024）论文集*，第19–35页，马耳他圣朱利安斯。计算语言学协会。
- en: 'Wolf et al. (2020) Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond,
    Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz,
    Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien
    Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,
    and Alexander Rush. 2020. [Transformers: State-of-the-art natural language processing](https://doi.org/10.18653/v1/2020.emnlp-demos.6).
    In *Proceedings of the 2020 Conference on Empirical Methods in Natural Language
    Processing: System Demonstrations*, pages 38–45, Online. Association for Computational
    Linguistics.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wolf et al. (2020) Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond,
    Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz,
    Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien
    Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,
    and Alexander Rush. 2020. [Transformers: 最先进的自然语言处理](https://doi.org/10.18653/v1/2020.emnlp-demos.6).
    *2020 年自然语言处理实证方法会议论文集: 系统演示*，第 38–45 页，在线。计算语言学协会。'
- en: 'Wu et al. (2024) Yue Wu, Xuan Tang, Tom M. Mitchell, and Yuanzhi Li. 2024.
    [Smartplay: A benchmark for llms as intelligent agents](https://arxiv.org/abs/2310.01557).
    *Preprint*, arXiv:2310.01557.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wu et al. (2024) Yue Wu, Xuan Tang, Tom M. Mitchell, and Yuanzhi Li. 2024.
    [Smartplay: llms 作为智能代理的基准](https://arxiv.org/abs/2310.01557). *预印本*，arXiv:2310.01557。'
- en: 'Zhou et al. (2024) Xuhui Zhou, Hao Zhu, Leena Mathur, Ruohong Zhang, Haofei
    Yu, Zhengyang Qi, Louis-Philippe Morency, Yonatan Bisk, Daniel Fried, Graham Neubig,
    and Maarten Sap. 2024. [SOTOPIA: Interactive Evaluation for Social Intelligence
    in Language Agents](https://arxiv.org/abs/2310.11667). In *Proceedings of ICLR
    2024*, pages 1–45.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhou et al. (2024) Xuhui Zhou, Hao Zhu, Leena Mathur, Ruohong Zhang, Haofei
    Yu, Zhengyang Qi, Louis-Philippe Morency, Yonatan Bisk, Daniel Fried, Graham Neubig,
    and Maarten Sap. 2024. [SOTOPIA: 语言代理中的社会智能互动评估](https://arxiv.org/abs/2310.11667).
    *ICLR 2024 论文集*，第 1–45 页。'
- en: Appendix A Full Results
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 完整结果
- en: '| models | sc | %pl | qs | o/g |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| models | sc | %pl | qs | o/g |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| gpt-4 | 59.49 | 96.06 | 61.93 | $$ |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4 | 59.49 | 96.06 | 61.93 | $$ |'
- en: '| claude-v1.3 | 37.07 | 74.76 | 49.58 | $$ |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| claude-v1.3 | 37.07 | 74.76 | 49.58 | $$ |'
- en: '| gpt-3.5-turbo | 37.02 | 85.86 | 43.12 | $$ |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| gpt-3.5-turbo | 37.02 | 85.86 | 43.12 | $$ |'
- en: '| text-davinci-003 | 15.78 | 44.50 | 35.46 | $$ |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| text-davinci-003 | 15.78 | 44.50 | 35.46 | $$ |'
- en: '| vicuna-13b | 4.24 | 13.58 | 31.25 | ow |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| vicuna-13b | 4.24 | 13.58 | 31.25 | ow |'
- en: '| oasst-12b | 1.74 | 20.85 | 8.33 | ow |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| oasst-12b | 1.74 | 20.85 | 8.33 | ow |'
- en: '| koala-13b | 1.48 | 14.76 | 10.00 | ow |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| koala-13b | 1.48 | 14.76 | 10.00 | ow |'
- en: '| falcon-40b | 0.71 | 0.95 | 75.00 | ow |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| falcon-40b | 0.71 | 0.95 | 75.00 | ow |'
- en: '| luminous-supreme | 0.00 | 16.24 | 0.00 | $$ |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| luminous-supreme | 0.00 | 16.24 | 0.00 | $$ |'
- en: '| models | sc | %pl | qs | o/g |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| models | sc | %pl | qs | o/g |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| gpt-4-0613 | 60.90 | 97.22 | 62.64 | $$ |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-0613 | 60.90 | 97.22 | 62.64 | $$ |'
- en: '| gpt-4-1106-preview | 60.33 | 97.95 | 61.59 | $$ |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-1106-preview | 60.33 | 97.95 | 61.59 | $$ |'
- en: '| gpt-4-0314 | 58.81 | 93.79 | 62.70 | $$ |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-0314 | 58.81 | 93.79 | 62.70 | $$ |'
- en: '| claude-v1.3 | 37.64 | 74.24 | 50.70 | $$ |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| claude-v1.3 | 37.64 | 74.24 | 50.70 | $$ |'
- en: '| claude-2.1 | 36.38 | 83.08 | 43.79 | $$ |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| claude-2.1 | 36.38 | 83.08 | 43.79 | $$ |'
- en: '| claude-2 | 33.71 | 82.12 | 41.05 | $$ |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| claude-2 | 33.71 | 82.12 | 41.05 | $$ |'
- en: '| gpt-3.5-turbo-0613 | 32.53 | 91.96 | 35.37 | $$ |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| gpt-3.5-turbo-0613 | 32.53 | 91.96 | 35.37 | $$ |'
- en: '| gpt-3.5-turbo-1106 | 30.45 | 77.12 | 39.49 | $$ |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| gpt-3.5-turbo-1106 | 30.45 | 77.12 | 39.49 | $$ |'
- en: '| openchat_3.5 | 19.72 | 57.57 | 34.26 | ow |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| openchat_3.5 | 19.72 | 57.57 | 34.26 | ow |'
- en: '| mistral-medium | 17.99 | 51.11 | 35.20 | ow |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| mistral-medium | 17.99 | 51.11 | 35.20 | ow |'
- en: '| mixtral-8x7b-instruct-v0.1 | 17.81 | 60.49 | 29.44 | ow |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| mixtral-8x7b-instruct-v0.1 | 17.81 | 60.49 | 29.44 | ow |'
- en: '| openchat-3.5-1210 | 17.61 | 53.18 | 33.11 | ow |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| openchat-3.5-1210 | 17.61 | 53.18 | 33.11 | ow |'
- en: '| sheep-duck-llama-2-70b-v1.1 | 17.12 | 40.82 | 41.93 | ow |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| sheep-duck-llama-2-70b-v1.1 | 17.12 | 40.82 | 41.93 | ow |'
- en: '| yi-34b-chat | 16.77 | 63.76 | 26.30 | ow |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| yi-34b-chat | 16.77 | 63.76 | 26.30 | ow |'
- en: '| wizardlm-70b-v1.0 | 16.70 | 51.65 | 32.34 | ow |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| wizardlm-70b-v1.0 | 16.70 | 51.65 | 32.34 | ow |'
- en: '| tulu-2-dpo-70b | 15.90 | 54.49 | 29.18 | ow |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| tulu-2-dpo-70b | 15.90 | 54.49 | 29.18 | ow |'
- en: '| sus-chat-34b | 15.64 | 49.75 | 31.44 | ow |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| sus-chat-34b | 15.64 | 49.75 | 31.44 | ow |'
- en: '| claude-instant-1.2 | 15.44 | 59.61 | 25.91 | $$ |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| claude-instant-1.2 | 15.44 | 59.61 | 25.91 | $$ |'
- en: '| openchat-3.5-0106 | 14.33 | 48.86 | 29.33 | ow |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| openchat-3.5-0106 | 14.33 | 48.86 | 29.33 | ow |'
- en: '| nous-hermes-2-mixtral-8x7b-dpo | 12.69 | 57.47 | 22.08 | ow |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| nous-hermes-2-mixtral-8x7b-dpo | 12.69 | 57.47 | 22.08 | ow |'
- en: '| codellama-34b-instruct-hf | 10.34 | 23.96 | 43.15 | ow |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| codellama-34b-instruct-hf | 10.34 | 23.96 | 43.15 | ow |'
- en: '| vicuna-33b-v1.3 | 9.15 | 17.47 | 52.36 | ow |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| vicuna-33b-v1.3 | 9.15 | 17.47 | 52.36 | ow |'
- en: '| wizardlm-13b-v1.2 | 7.82 | 40.49 | 19.31 | ow |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| wizardlm-13b-v1.2 | 7.82 | 40.49 | 19.31 | ow |'
- en: '| vicuna-13b-v1.5 | 7.21 | 34.74 | 20.74 | ow |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| vicuna-13b-v1.5 | 7.21 | 34.74 | 20.74 | ow |'
- en: '| sheep-duck-llama-2-13b | 6.74 | 34.86 | 19.34 | ow |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| sheep-duck-llama-2-13b | 6.74 | 34.86 | 19.34 | ow |'
- en: '| vicuna-7b-v1.5 | 3.46 | 12.86 | 26.91 | ow |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| vicuna-7b-v1.5 | 3.46 | 12.86 | 26.91 | ow |'
- en: '| tulu-2-dpo-7b | 3.27 | 36.29 | 9.02 | ow |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| tulu-2-dpo-7b | 3.27 | 36.29 | 9.02 | ow |'
- en: '| command | 3.12 | 10.01 | 31.13 | $$ |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| command | 3.12 | 10.01 | 31.13 | $$ |'
- en: '| wizard-vicuna-13b-uncensored-hf | 2.06 | 9.49 | 21.71 | ow |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| wizard-vicuna-13b-uncensored-hf | 2.06 | 9.49 | 21.71 | ow |'
- en: '| llama-2-13b-chat-hf | 1.89 | 3.43 | 55.09 | ow |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| llama-2-13b-chat-hf | 1.89 | 3.43 | 55.09 | ow |'
- en: '| mistral-7b-instruct-v0.1 | 1.50 | 12.86 | 11.67 | ow |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| mistral-7b-instruct-v0.1 | 1.50 | 12.86 | 11.67 | ow |'
- en: '| llama-2-70b-chat-hf | 1.39 | 3.79 | 36.74 | ow |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| llama-2-70b-chat-hf | 1.39 | 3.79 | 36.74 | ow |'
- en: '| koala-13b-hf | 1.25 | 23.22 | 5.38 | ow |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| koala-13b-hf | 1.25 | 23.22 | 5.38 | ow |'
- en: '| zephyr-7b-beta | 1.23 | 3.95 | 31.25 | ow |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| zephyr-7b-beta | 1.23 | 3.95 | 31.25 | ow |'
- en: '| deepseek-llm-67b-chat | 0.77 | 2.64 | 29.17 | ow |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| deepseek-llm-67b-chat | 0.77 | 2.64 | 29.17 | ow |'
- en: '| zephyr-7b-alpha | 0.75 | 7.51 | 10.00 | ow |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| zephyr-7b-alpha | 0.75 | 7.51 | 10.00 | ow |'
- en: '| llama-2-7b-chat-hf | 0.24 | 6.05 | 4.00 | ow |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| llama-2-7b-chat-hf | 0.24 | 6.05 | 4.00 | ow |'
- en: '| gpt4all-13b-snoozy | 0.00 | 2.92 | 0.00 | $$ |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| gpt4all-13b-snoozy | 0.00 | 2.92 | 0.00 | $$ |'
- en: '| deepseek-llm-7b-chat | 0.00 | 7.44 | 0.00 | ow |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| deepseek-llm-7b-chat | 0.00 | 7.44 | 0.00 | ow |'
- en: '| oasst-sft-4-pythia-12b-epoch-3.5 | 0.00 | 14.76 | 0.00 | ow |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| oasst-sft-4-pythia-12b-epoch-3.5 | 0.00 | 14.76 | 0.00 | ow |'
- en: '| falcon-7b-instruct | 0.00 | 14.29 | 0.00 | ow |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| falcon-7b-instruct | 0.00 | 14.29 | 0.00 | ow |'
- en: '| models | sc | %pl | qs | o/g |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| models | sc | %pl | qs | o/g |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| gpt-4-turbo-2024-04-09 | 58.30 | 94.88 | 61.45 | $$ |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-turbo-2024-04-09 | 58.30 | 94.88 | 61.45 | $$ |'
- en: '| gpt-4-0125-preview | 52.50 | 94.92 | 55.31 | $$ |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-0125-preview | 52.50 | 94.92 | 55.31 | $$ |'
- en: '| gpt-4-1106-preview | 51.99 | 98.10 | 53.00 | $$ |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-1106-preview | 51.99 | 98.10 | 53.00 | $$ |'
- en: '| gpt-4-0613 | 51.09 | 94.88 | 53.85 | $$ |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-0613 | 51.09 | 94.88 | 53.85 | $$ |'
- en: '| gpt-4o-2024-05-13 | 48.34 | 85.71 | 56.40 | $$ |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4o-2024-05-13 | 48.34 | 85.71 | 56.40 | $$ |'
- en: '| claude-3-opus-20240229 | 42.42 | 83.10 | 51.05 | $$ |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| claude-3-opus-20240229 | 42.42 | 83.10 | 51.05 | $$ |'
- en: '| gemini-1.5-pro-latest | 41.72 | 82.14 | 50.79 | $$ |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| gemini-1.5-pro-latest | 41.72 | 82.14 | 50.79 | $$ |'
- en: '| llama-3-70b-instruct | 35.11 | 80.72 | 43.50 | ow |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| llama-3-70b-instruct | 35.11 | 80.72 | 43.50 | ow |'
- en: '| claude-2.1 | 32.50 | 82.14 | 39.57 | $$ |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| claude-2.1 | 32.50 | 82.14 | 39.57 | $$ |'
- en: '| gemini-1.5-flash-latest | 32.00 | 76.14 | 42.03 | $$ |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| gemini-1.5-flash-latest | 32.00 | 76.14 | 42.03 | $$ |'
- en: '| claude-3-sonnet-20240229 | 30.53 | 85.24 | 35.82 | $$ |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| claude-3-sonnet-20240229 | 30.53 | 85.24 | 35.82 | $$ |'
- en: '| qwen1.5-72b-chat | 30.37 | 80.05 | 37.94 | ow |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| qwen1.5-72b-chat | 30.37 | 80.05 | 37.94 | ow |'
- en: '| mistral-large-2402 | 28.17 | 66.86 | 42.14 | $$ |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| mistral-large-2402 | 28.17 | 66.86 | 42.14 | $$ |'
- en: '| gpt-3.5-turbo-0125 | 27.22 | 89.67 | 30.36 | $$ |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| gpt-3.5-turbo-0125 | 27.22 | 89.67 | 30.36 | $$ |'
- en: '| gemini-1.0-pro | 26.95 | 80.14 | 33.63 | $$ |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| gemini-1.0-pro | 26.95 | 80.14 | 33.63 | $$ |'
- en: '| command-r-plus | 24.94 | 74.90 | 33.30 | ow |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| command-r-plus | 24.94 | 74.90 | 33.30 | ow |'
- en: '| openchat_3.5 | 23.64 | 63.52 | 37.22 | ow |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| openchat_3.5 | 23.64 | 63.52 | 37.22 | ow |'
- en: '| claude-3-haiku-20240307 | 22.49 | 79.52 | 28.28 | $$ |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| claude-3-haiku-20240307 | 22.49 | 79.52 | 28.28 | $$ |'
- en: '| sheep-duck-llama-2-70b-v1.1 | 21.50 | 41.19 | 52.20 | ow |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| sheep-duck-llama-2-70b-v1.1 | 21.50 | 41.19 | 52.20 | ow |'
- en: '| llama-3-8b-instruct | 19.99 | 76.10 | 26.27 | ow |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| llama-3-8b-instruct | 19.99 | 76.10 | 26.27 | ow |'
- en: '| openchat-3.5-1210 | 18.22 | 51.19 | 35.60 | ow |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| openchat-3.5-1210 | 18.22 | 51.19 | 35.60 | ow |'
- en: '| wizardlm-70b-v1.0 | 17.40 | 46.19 | 37.66 | ow |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| wizardlm-70b-v1.0 | 17.40 | 46.19 | 37.66 | ow |'
- en: '| openchat-3.5-0106 | 17.10 | 52.57 | 32.52 | ow |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| openchat-3.5-0106 | 17.10 | 52.57 | 32.52 | ow |'
- en: '| qwen1.5-14b-chat | 16.80 | 40.95 | 41.02 | ow |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| qwen1.5-14b-chat | 16.80 | 40.95 | 41.02 | ow |'
- en: '| mistral-medium-2312 | 16.43 | 49.25 | 33.36 | $$ |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| mistral-medium-2312 | 16.43 | 49.25 | 33.36 | $$ |'
- en: '| qwen1.5-32b-chat | 15.41 | 63.69 | 24.19 | ow |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| qwen1.5-32b-chat | 15.41 | 63.69 | 24.19 | ow |'
- en: '| codegemma-7b-it | 15.30 | 51.95 | 29.45 | ow |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| codegemma-7b-it | 15.30 | 51.95 | 29.45 | ow |'
- en: '| dolphin-2.5-mixtral-8x7b | 15.10 | 46.38 | 32.55 | ow |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| dolphin-2.5-mixtral-8x7b | 15.10 | 46.38 | 32.55 | ow |'
- en: '| codellama-34b-instruct | 14.35 | 33.57 | 42.76 | ow |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| codellama-34b-instruct | 14.35 | 33.57 | 42.76 | ow |'
- en: '| command-r | 14.15 | 61.67 | 22.95 | ow |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| command-r | 14.15 | 61.67 | 22.95 | ow |'
- en: '| gemma-1.1-7b-it | 14.14 | 49.67 | 28.46 | ow |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| gemma-1.1-7b-it | 14.14 | 49.67 | 28.46 | ow |'
- en: '| sus-chat-34b | 14.11 | 54.40 | 25.93 | ow |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| sus-chat-34b | 14.11 | 54.40 | 25.93 | ow |'
- en: '| mixtral-8x22b-instruct-v0.1 | 12.69 | 52.14 | 24.33 | ow |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| mixtral-8x22b-instruct-v0.1 | 12.69 | 52.14 | 24.33 | ow |'
- en: '| tulu-2-dpo-70b | 12.62 | 49.76 | 25.37 | ow |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| tulu-2-dpo-70b | 12.62 | 49.76 | 25.37 | ow |'
- en: '| nous-hermes-2-mixtral-8x7b-sft | 11.95 | 39.68 | 30.12 | ow |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| nous-hermes-2-mixtral-8x7b-sft | 11.95 | 39.68 | 30.12 | ow |'
- en: '| wizardlm-13b-v1.2 | 11.48 | 39.57 | 29.00 | ow |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| wizardlm-13b-v1.2 | 11.48 | 39.57 | 29.00 | ow |'
- en: '| vicuna-33b-v1.3 | 11.27 | 23.81 | 47.32 | ow |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| vicuna-33b-v1.3 | 11.27 | 23.81 | 47.32 | ow |'
- en: '| mistral-7b-instruct-v0.2 | 9.75 | 36.91 | 26.42 | ow |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| mistral-7b-instruct-v0.2 | 9.75 | 36.91 | 26.42 | ow |'
- en: '| yi-34b-chat | 8.27 | 40.86 | 20.25 | ow |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| yi-34b-chat | 8.27 | 40.86 | 20.25 | ow |'
- en: '| mixtral-8x7b-instruct-v0.1 | 8.17 | 47.62 | 17.15 | ow |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| mixtral-8x7b-instruct-v0.1 | 8.17 | 47.62 | 17.15 | ow |'
- en: '| mistral-7b-instruct-v0.1 | 8.01 | 37.14 | 21.58 | ow |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| mistral-7b-instruct-v0.1 | 8.01 | 37.14 | 21.58 | ow |'
- en: '| yi-1.5-34b-chat | 7.67 | 52.38 | 14.65 | ow |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| yi-1.5-34b-chat | 7.67 | 52.38 | 14.65 | ow |'
- en: '| vicuna-13b-v1.5 | 7.01 | 39.52 | 17.73 | ow |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| vicuna-13b-v1.5 | 7.01 | 39.52 | 17.73 | ow |'
- en: '| yi-1.5-6b-chat | 6.73 | 41.43 | 16.25 | ow |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| yi-1.5-6b-chat | 6.73 | 41.43 | 16.25 | ow |'
- en: '| starling-lm-7b-beta | 6.56 | 30.89 | 21.25 | ow |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| starling-lm-7b-beta | 6.56 | 30.89 | 21.25 | ow |'
- en: '| sheep-duck-llama-2-13b | 5.39 | 31.90 | 16.90 | ow |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| sheep-duck-llama-2-13b | 5.39 | 31.90 | 16.90 | ow |'
- en: '| yi-1.5-9b-chat | 4.37 | 38.10 | 11.48 | ow |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| yi-1.5-9b-chat | 4.37 | 38.10 | 11.48 | ow |'
- en: '| gemma-1.1-2b-it | 2.91 | 22.62 | 12.87 | ow |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| gemma-1.1-2b-it | 2.91 | 22.62 | 12.87 | ow |'
- en: '| qwen1.5-7b-chat | 2.58 | 30.24 | 8.53 | ow |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| qwen1.5-7b-chat | 2.58 | 30.24 | 8.53 | ow |'
- en: '| gemma-7b-it | 1.82 | 17.78 | 10.23 | ow |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| gemma-7b-it | 1.82 | 17.78 | 10.23 | ow |'
- en: '| llama-2-70b-chat | 0.81 | 7.14 | 11.31 | ow |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| llama-2-70b-chat | 0.81 | 7.14 | 11.31 | ow |'
- en: '| qwen1.5-0.5b-chat | 0.12 | 25.72 | 0.48 | ow |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| qwen1.5-0.5b-chat | 0.12 | 25.72 | 0.48 | ow |'
- en: '| qwen1.5-1.8b-chat | 0.00 | 15.24 | 0.00 | ow |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| qwen1.5-1.8b-chat | 0.00 | 15.24 | 0.00 | ow |'
- en: 'Table 3: In order, results on the English clembench from June 2023, November
    2023, May 2024\. “sc” is the clemscore, “%pl” is the percentage of games played
    formally correctly, “qs” is the quality of the game play of those games; “ow”:
    open weight models, “$$”: gated models.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：按照顺序，2023年6月、2023年11月、2024年5月在英文 clembench 上的结果。“sc” 是 clemscore，“%pl” 是正式正确游戏的百分比，“qs”
    是这些游戏的游戏质量；“ow”：开放权重模型，“$$”：门控模型。
- en: See Table [3](#A1.T3 "Table 3 ‣ Appendix A Full Results ‣ clembench2024 A Challenging,
    Dynamic, Complementary, Multilingual Benchmark and Underlying Flexible Framework
    for LLMs as Multi-Action Agents").
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 请参见表 [3](#A1.T3 "表 3 ‣ 附录 A 完整结果 ‣ clembench2024 一个具有挑战性、动态、互补的多语言基准及其灵活框架")
- en: Appendix B Across-Benchmark Correlations
  id: totrans-248
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 基准间相关性
- en: See Figure [1](#A2.F1 "Figure 1 ‣ Appendix B Across-Benchmark Correlations ‣
    clembench2024 A Challenging, Dynamic, Complementary, Multilingual Benchmark and
    Underlying Flexible Framework for LLMs as Multi-Action Agents").
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 请参见图 [1](#A2.F1 "图 1 ‣ 附录 B 基准间相关性 ‣ clembench2024 一个具有挑战性、动态、互补的多语言基准及其灵活框架")
- en: '![Refer to caption](img/6e8079ea2905ab5f26a566e509b15130.png)![Refer to caption](img/3b8f95c11c287eb61ebda877053e900d.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/6e8079ea2905ab5f26a566e509b15130.png)![参见说明](img/3b8f95c11c287eb61ebda877053e900d.png)'
- en: 'Figure 1: Top: Bump chart showing ranking differences between clembench (left)
    and Chatbot Arena (2024-05-16; right); Bottom: Ranking differences between clembench (left)
    and HELM (v1.3.0; right)'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：上图：显示 clembench（左）和 Chatbot Arena（2024-05-16；右）之间排名差异的气泡图；下图：显示 clembench（左）和
    HELM（v1.3.0；右）之间排名差异的图表
- en: Appendix C Language Tested in the Case Study
  id: totrans-252
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 C 案例研究中测试的语言
- en: 'While there is no explicit information available on the amount of training
    data and optimisation for different languages for the commercial models, the model
    card for Command-R+ gives an overview of the supported languages on different
    levels.⁴⁴4[https://huggingface.co/CohereForAI/c4ai-command-r-plus](https://huggingface.co/CohereForAI/c4ai-command-r-plus)
    We select a subset of eight languages from different language families, five for
    which the model is explicitly optimised: German (de), Italian (it), Brazilian
    Portuguese (pt), Japanese (ja) and Simplified Chinese (zh), one for which the
    training data is reported to contain resources: Turkish (tr), and two which are
    not supported explicitly: Telugu (te) and Turkmen (tk).'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管没有关于商业模型在不同语言上的训练数据和优化的明确资料，但 Command-R+ 的模型卡概述了不同层级的支持语言。⁴⁴4[https://huggingface.co/CohereForAI/c4ai-command-r-plus](https://huggingface.co/CohereForAI/c4ai-command-r-plus)
    我们选择了来自不同语言家族的八种语言子集，其中五种语言模型经过明确优化：德语（de）、意大利语（it）、巴西葡萄牙语（pt）、日语（ja）和简体中文（zh），一种语言的训练数据报告中包含资源：土耳其语（tr），以及两种未明确支持的语言：泰卢固语（te）和土库曼语（tk）。
- en: The Technical Report on GPT-4 OpenAI et al. ([2024](#bib.bib11)) does not contain
    any information on the languages supported in the training data, but their evaluation
    contains a ranking of the model’s performance in different languages on an automatically
    translated version of multiple choice questions (Hendrycks et al., [2021](#bib.bib6)).
    Among others, our selected languages include the best and worst performing languages
    from their evaluation (Italian and Telugu, respectively). Similarly, the Claude-3
    Model Card (available at [https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf](https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf))
    does not contain information on multilingual training data, but the languages
    we select also cover a broad range of the ones this model was evaluated on (and
    more).
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 关于GPT-4的技术报告（OpenAI等人，[2024](#bib.bib11)）并未包含有关训练数据中支持的语言的信息，但他们的评估中包含了模型在不同语言下的表现排名，这些排名是基于对多项选择题的自动翻译版本（Hendrycks等人，[2021](#bib.bib6)）进行的。我们选择的语言中包括了他们评估中表现最佳和最差的语言（分别是意大利语和泰卢固语）。同样，Claude-3模型卡（可在[https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf](https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf)）中也没有关于多语言训练数据的信息，但我们选择的语言同样涵盖了这个模型评估过的多种语言（以及更多）。
