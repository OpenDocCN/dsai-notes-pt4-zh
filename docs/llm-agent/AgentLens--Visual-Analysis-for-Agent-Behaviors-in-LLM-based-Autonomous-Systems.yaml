- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 18:52:43'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:52:43
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'AgentLens: Visual Analysis for Agent Behaviors in LLM-based Autonomous Systems'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'AgentLens: 基于LLM的自主系统中代理行为的视觉分析'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2402.08995](https://ar5iv.labs.arxiv.org/html/2402.08995)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2402.08995](https://ar5iv.labs.arxiv.org/html/2402.08995)
- en: Jiaying Lu, Bo Pan, Jieyi Chen, Yingchaojie Feng, Jingyuan Hu, Yuchen Peng,
    Wei Chen
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 陆佳颖、潘博、陈杰益、冯迎超、胡静远、彭宇辰、陈伟
- en: Abstract
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Recently, Large Language Model based Autonomous system (LLMAS) has gained great
    popularity for its potential to simulate complicated behaviors of human societies.
    One of its main challenges is to present and analyze the dynamic events evolution
    of LLMAS. In this work, we present a visualization approach to explore detailed
    statuses and agents’ behavior within LLMAS. We propose a general pipeline that
    establishes a behavior structure from raw LLMAS execution events, leverages a
    behavior summarization algorithm to construct a hierarchical summary of the entire
    structure in terms of time sequence, and a cause trace method to mine the causal
    relationship between agent behaviors. We then develop AgentLens, a visual analysis
    system that leverages a hierarchical temporal visualization for illustrating the
    evolution of LLMAS, and supports users to interactively investigate details and
    causes of agents’ behaviors. Two usage scenarios and a user study demonstrate
    the effectiveness and usability of our AgentLens.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，基于大语言模型的自主系统（LLMAS）因其模拟人类社会复杂行为的潜力而获得了极大的关注。其主要挑战之一是展示和分析LLMAS的动态事件演变。在这项工作中，我们提出了一种可视化方法，用于探索LLMAS中的详细状态和代理行为。我们提出了一个通用的管道，该管道从原始LLMAS执行事件中建立行为结构，利用行为总结算法构建整个结构的时间序列分层总结，并采用因果追踪方法挖掘代理行为之间的因果关系。然后，我们开发了AgentLens，一个利用分层时间可视化来展示LLMAS演变的视觉分析系统，支持用户互动式地调查代理行为的细节和原因。两个使用场景和一项用户研究展示了我们AgentLens的有效性和可用性。
- en: 'Index Terms:'
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: 'LLM, autonomous system, agent, visual analysis.^†^†publicationid: pubid: 0000–0000/00$00.00 © 2021
    IEEE![Refer to caption](img/58df0be1d929626861392092a4cb2506.png)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 'LLM、自主系统、代理、视觉分析。^†^†publicationid: pubid: 0000–0000/00$00.00 © 2021 IEEE![参考标题](img/58df0be1d929626861392092a4cb2506.png)'
- en: 'Figure 1: The user interface of AgentLens comprises three views. The Outline
    View (A) displays the trajectory of each agent using different colored curves,
    enabling users to identify significant patterns or event summarization during
    the evolution of LLMAS. By clicking on a time step in each curve, users can further
    investigate it in the Agent View (B). It allows users to progressively reveal
    agent event information and trace the cause of specific agent behavior. The Monitor
    View (C) automatically adjusts the graphical representation of LLMAS based on
    the user’s current point of interest.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：AgentLens的用户界面包括三个视图。大纲视图（A）使用不同颜色的曲线显示每个代理的轨迹，使用户能够识别LLMAS演变过程中的重要模式或事件总结。通过点击每条曲线上的时间步骤，用户可以在代理视图（B）中进一步调查。它允许用户逐步揭示代理事件信息，并追踪特定代理行为的原因。监视视图（C）根据用户当前的兴趣点自动调整LLMAS的图形表示。
- en: 1 Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Autonomous agents, as computational entities that possess a certain degree of
    autonomy[[1](#bib.bib1), [2](#bib.bib2)], are seen as a promising pathway toward
    achieving artificial general intelligence (AGI)[[3](#bib.bib3), [4](#bib.bib4)].
    In recent years, owing to the breakthroughs in natural language processing[[5](#bib.bib5),
    [6](#bib.bib6), [7](#bib.bib7)] achieved by Large Language Models (LLM), the LLM-based
    autonomous agent has gained widespread adoption in both academia and industry[[8](#bib.bib8),
    [9](#bib.bib9)]. Built upon LLM-based agents, LLM-based autonomous systems (LLMAS)
    deploy multiple agents within a shared environment, enabling them to display behavior
    and social patterns akin to humans. This collective intelligence fosters emergent
    social dynamics, such as the formation of new relationships, diffusion of information,
    and the rise of coordination among agents[[10](#bib.bib10)]. Consequently, LLMAS
    exhibits significant potential in society simulation[[10](#bib.bib10), [11](#bib.bib11)],
    software engineering[[12](#bib.bib12), [13](#bib.bib13)], and scientific research[[14](#bib.bib14)].
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 自主代理作为具有一定程度自主性的计算实体[[1](#bib.bib1), [2](#bib.bib2)]，被视为实现人工通用智能（AGI）[[3](#bib.bib3),
    [4](#bib.bib4)]的有前途的途径。近年来，由于大型语言模型（LLM）在自然语言处理[[5](#bib.bib5), [6](#bib.bib6),
    [7](#bib.bib7)]方面取得的突破，基于LLM的自主代理在学术界和工业界得到了广泛采用[[8](#bib.bib8), [9](#bib.bib9)]。基于LLM的自主系统（LLMAS）建立在LLM代理之上，在共享环境中部署多个代理，使其能够展示类似于人类的行为和社会模式。这种集体智能促成了新关系的形成、信息的扩散以及代理之间协调的兴起[[10](#bib.bib10)]。因此，LLMAS在社会模拟[[10](#bib.bib10),
    [11](#bib.bib11)]、软件工程[[12](#bib.bib12), [13](#bib.bib13)]和科学研究[[14](#bib.bib14)]方面表现出显著的潜力。
- en: However, monitoring and analyzing the dynamic evolution of LLMAS, including
    agents in LLMAS and event sequences undertaken by them, can be challenging due
    to the tremendous information generated during the system evolution and the inherent
    unpredictability of LLMs. The most straightforward approach for analyzing LLMAS
    is to inject logging code into LLMAS to trace agent events of interest and check
    the raw output logs in text format[[15](#bib.bib15)]. However, this approach requires
    expertise with specific LLMAS and is unintuitive for general users. To address
    this, many LLMAS projects provide a graphical representation of the simulation
    process[[9](#bib.bib9)], which is typically re-playable 2D [[16](#bib.bib16),
    [17](#bib.bib17), [10](#bib.bib10), [18](#bib.bib18)] or 3D video[[19](#bib.bib19),
    [20](#bib.bib20), [21](#bib.bib21), [22](#bib.bib22)]. By transforming a fixed
    sequence of intermediate simulation events into expressive visual recordings,
    users can digest that information more efficiently and intuitively. However, a
    re-playable recording with a fixed level of abstraction limits the flexibility
    of analysis for LLMAS. Even for a specific LLMAS and a fixed usage scenario, a
    user’s short-term analysis target will change frequently during the analysis process.
    As the users’ analysis target varies, the type, quantity, and granularity of agent
    events to be visualized also need to change. Moreover, analyzing the agent’s behavior
    at a specific time point requires users to switch the recording back and forth
    to trace the cause and consequence of this behavior, which is tedious and unreliable.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于系统演化过程中生成的大量信息和LLM固有的不可预测性，监测和分析LLMAS的动态演变，包括LLMAS中的代理和它们执行的事件序列，可能具有挑战性。分析LLMAS最直接的方法是向LLMAS中注入日志代码，以追踪感兴趣的代理事件并检查以文本格式呈现的原始输出日志[[15](#bib.bib15)]。然而，这种方法需要特定LLMAS的专业知识，并且对普通用户来说并不直观。为了解决这个问题，许多LLMAS项目提供了模拟过程的图形表示[[9](#bib.bib9)]，通常是可重播的2D
    [[16](#bib.bib16), [17](#bib.bib17), [10](#bib.bib10), [18](#bib.bib18)]或3D视频[[19](#bib.bib19),
    [20](#bib.bib20), [21](#bib.bib21), [22](#bib.bib22)]。通过将固定的中间模拟事件序列转换为富有表现力的视觉记录，用户可以更高效、直观地消化这些信息。然而，具有固定抽象层级的可重播记录限制了LLMAS分析的灵活性。即使对于特定LLMAS和固定的使用场景，用户的短期分析目标在分析过程中也会频繁变化。随着用户分析目标的变化，需要可视化的代理事件的类型、数量和粒度也需要相应变化。此外，在特定时间点分析代理行为需要用户来回切换记录，以追踪该行为的因果关系，这既繁琐又不可靠。
- en: This work thus presents a visualization approach to assist users in efficiently
    analyzing the evolving status and complex behaviors of agents within an LLMAS.
    To mitigate cognitive overload due to the profusion of data produced throughout
    the evolution of LLMAS, and to enhance adaptability for subsequent analytical
    processes, we introduce a general pipeline, which establishes a hierarchical behavior
    structure of agent entities and raw event sequences within the LLMAS operational
    records. The formulation of the structure is based on our survey of prevalent
    architectures within extant LLMAS, coupled with a design study that engaged 4
    LLMAS developers and 4 layman users. We design an LLM-based algorithm for summarizing
    agent behavior that furnishes a hierarchical depiction of sequences of agent events.
    Additionally, we employ a cause trace method to unearth the causal linkages among
    disparate agent events. Based on the extracted hierarchical structure, we then
    develop AgentLens, a visual analysis system designed to facilitate interactive
    analysis and exploration of agent behaviors in LLMAS.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作提出了一种可视化方法，以帮助用户高效分析 LLMAS 中代理的演变状态和复杂行为。为了缓解由于 LLMAS 演变过程中产生的大量数据而导致的认知过载，并提升后续分析过程的适应性，我们引入了一个通用流程，该流程建立了
    LLMAS 操作记录中代理实体和原始事件序列的层次行为结构。该结构的制定基于我们对现有 LLMAS 中流行架构的调查，以及与 4 名 LLMAS 开发者和
    4 名普通用户的设计研究。我们设计了一种基于 LLM 的算法，用于总结代理行为，提供代理事件序列的层次化描述。此外，我们采用了因果追踪方法，以揭示不同代理事件之间的因果联系。基于提取的层次结构，我们开发了
    AgentLens，一个视觉分析系统，旨在促进对 LLMAS 中代理行为的交互式分析和探索。
- en: 'AgentLens provides a multi-faceted perspective for LLMAS through its three
    distinct but interrelated views, each offering a different level of abstraction.
    The Outline View ([Fig. 1](#S0.F1 "In AgentLens: Visual Analysis for Agent Behaviors
    in LLM-based Autonomous Systems"), A) illustrates
    the spatiotemporal trajectory of each agent with curves of different colors, aiding
    users in identifying notable agents or their intriguing behaviors throughout the
    evolution of LLMAS. Users can quickly scan agent behaviors at different granularity
    ([Fig. 1](#S0.F1 "In AgentLens: Visual Analysis for Agent Behaviors in LLM-based
    Autonomous Systems"), $A_{1}$), and
    click any time point on an agent curve to further investigate it in the Agent
    View ([Fig. 1](#S0.F1 "In AgentLens: Visual Analysis for Agent Behaviors in LLM-based
    Autonomous Systems"), B). The Agent
    View allows users to progressively reveal agent event information on demand and
    trace the cause of certain agent behavior. The Monitor View ([Fig. 1](#S0.F1 "In
    AgentLens: Visual Analysis for Agent Behaviors in LLM-based Autonomous Systems"),
    C)
    automatically adjusts the graphical representation of LLMAS for users based on
    their current point of interest in the Outline View or the Agent View. To evaluate
    the performance of AgentLens, we present two cases and conduct a user study with
    14 participants to gather their feedback. The results indicate that AgentLens
    is capable of assisting users in the LLMAS evolution analysis and agent behaviors
    investigation.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: AgentLens 通过其三个不同但相互关联的视图为 LLMAS 提供了多方面的视角，每个视图都提供了不同层次的抽象。大纲视图 ([Fig. 1](#S0.F1
    "在 AgentLens 中：LLM 基于自主系统的代理行为的可视化分析"), A) 通过不同颜色的曲线展示每个代理的时空轨迹，帮助用户识别在
    LLMAS 演变过程中显著的代理或其有趣的行为。用户可以快速扫描不同粒度的代理行为 ([Fig. 1](#S0.F1 "在 AgentLens 中：LLM
    基于自主系统的代理行为的可视化分析"), $A_{1}$), 并点击代理曲线上的任何时间点以进一步在代理视图中调查
    ([Fig. 1](#S0.F1 "在 AgentLens 中：LLM 基于自主系统的代理行为的可视化分析"), B)。代理视图允许用户按需逐步显示代理事件信息，并追踪某些代理行为的原因。监控视图
    ([Fig. 1](#S0.F1 "在 AgentLens 中：LLM 基于自主系统的代理行为的可视化分析"), C)
    会根据用户在大纲视图或代理视图中的当前兴趣点自动调整 LLMAS 的图形表示。为了评估 AgentLens 的性能，我们展示了两个案例，并进行了包括 14
    名参与者的用户研究以收集他们的反馈。结果表明，AgentLens 能够帮助用户进行 LLMAS 演变分析和代理行为调查。
- en: 'The main contributions of our work are as follows:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们工作的主要贡献如下：
- en: •
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: To the best of our knowledge, our work is the first visual analysis system that
    enables analysis and explorations of agent behaviors within LLMAS.
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 据我们所知，我们的工作是首个能够分析和探索LLMAS中代理行为的视觉分析系统。
- en: •
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We propose a general pipeline that establishes a hierarchical behavior structure
    from raw LLMAS execution events to facilitate downstream analysis.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了一种通用流程，建立了从原始LLMAS执行事件到下游分析的层次化行为结构。
- en: •
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We conduct two cases and a user study to demonstrate the capabilities of our
    system. The evaluation results confirm the usefulness and effectiveness of the
    behavior structure andAgentLens.
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们通过两个案例和一项用户研究来展示我们系统的能力。评估结果确认了行为结构和AgentLens的有用性和有效性。
- en: 2 Related Work
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: 2.1 LLM-based Autonomous Agents
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 基于LLM的自主代理
- en: Franklin et al.[[23](#bib.bib23)] defined the agent as an entity situated in
    the environment that senses the environment and acts on it over time, in pursuit
    of its own agenda and so as to affect what it senses in the future. Possessing
    the ability to perform intelligent operations without human intervention, the
    autonomous agent remains a steadfast goal in artificial intelligence research[[3](#bib.bib3),
    [24](#bib.bib24)].
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Franklin等人[[23](#bib.bib23)]将代理定义为一种位于环境中的实体，它感知环境并在一段时间内对其进行操作，以实现自身的目标，从而影响未来对环境的感知。具备在没有人类干预的情况下执行智能操作的能力，自主代理仍然是人工智能研究中的坚定目标[[3](#bib.bib3),
    [24](#bib.bib24)]。
- en: The progression of LLMs [[25](#bib.bib25), [6](#bib.bib6)] has underscored exceptional
    proficiency in areas of comprehension, reasoning, and language generation[[26](#bib.bib26)],
    which kindled optimism for continued advancements in the realm of autonomous agents.
    With the advent of LLMs, the study of LLM-based autonomous agents began to thrive.
    This includes enhancing agents’ self-reflective capabilities [[27](#bib.bib27),
    [28](#bib.bib28)], implementing superior task decomposition strategies [[29](#bib.bib29)],
    and endowing the ability to utilize and create tools[[30](#bib.bib30), [31](#bib.bib31),
    [32](#bib.bib32), [33](#bib.bib33)]. There is also a vibrant development of applications
    of LLM-based agents in the open source community [[34](#bib.bib34), [35](#bib.bib35),
    [15](#bib.bib15)].
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs的进展[[25](#bib.bib25), [6](#bib.bib6)]突显了在理解、推理和语言生成领域的卓越能力[[26](#bib.bib26)]，这激发了对自主代理领域持续进步的乐观情绪。随着LLMs的出现，基于LLM的自主代理的研究开始蓬勃发展。这包括提升代理的自我反思能力[[27](#bib.bib27),
    [28](#bib.bib28)]，实施优越的任务分解策略[[29](#bib.bib29)]，以及赋予使用和创建工具的能力[[30](#bib.bib30),
    [31](#bib.bib31), [32](#bib.bib32), [33](#bib.bib33)]。在开源社区中，基于LLM的代理应用也在蓬勃发展[[34](#bib.bib34),
    [35](#bib.bib35), [15](#bib.bib15)]。
- en: Recently, researchers have found that LLM-based agents can address a wider range
    of tasks through collaboration or competition. Camel[[36](#bib.bib36)] presented
    a framework that emphasizes the autonomous interaction between communicative agents.
    It is capable of creating varied, detailed instructions across numerous tasks,
    thereby providing a platform for these agents to demonstrate their cognitive operations.
    Talebirad et al.[[37](#bib.bib37)] introduced a comprehensive framework for multi-agent
    collaboration based on LLMs. ProAgent[[18](#bib.bib18)] exhibited the distinctive
    ability for agents to foresee the upcoming decisions of collaborators and adjust
    their behaviors, enabling them to excel in cooperative reasoning tasks. Multi-Agent
    Debate (MAD)[[38](#bib.bib38)] introduced an approach in which several agents
    present their arguments collaboratively while a judge guides the discourse, enhancing
    agents’ divergent thinking for deep-reflective tasks.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，研究人员发现LLM基础的代理能够通过协作或竞争来处理更广泛的任务。Camel[[36](#bib.bib36)]提出了一个框架，强调了沟通代理之间的自主互动。它能够在多个任务中创建多样且详细的指令，从而为这些代理展示其认知操作提供了平台。Talebirad等人[[37](#bib.bib37)]介绍了一个基于LLMs的多代理协作的全面框架。ProAgent[[18](#bib.bib18)]展示了代理预测合作者即将做出决策并调整其行为的独特能力，使其在合作推理任务中表现突出。Multi-Agent
    Debate (MAD)[[38](#bib.bib38)]提出了一种方法，其中多个代理在裁判的引导下合作陈述论点，增强了代理在深度反思任务中的发散思维。
- en: However, as the number and the intricacy of agents increase, the complexity
    of analyzing their behaviors escalates rapidly. While past works have focused
    on elevating the capabilities of LLM-based agents in emulating human-like behaviors,
    they often overlooked how to effectively analyze agent behaviors. In this work,
    we identify this research gap and present a visualization approach for analyzing
    agent behaviors in LLM-based multi-agent systems.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，随着代理数量和复杂性的增加，分析其行为的复杂性迅速上升。尽管过去的工作侧重于提升基于 LLM 的代理在模拟人类行为方面的能力，但它们往往忽视了如何有效分析代理行为。在这项工作中，我们识别了这一研究空白，并提出了一种可视化方法，用于分析
    LLM 基础的多代理系统中的代理行为。
- en: 2.2 LLM-based Autonomous System
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 基于 LLM 的自主系统
- en: By incorporating numerous LLM-based agents into a cohesive environment, the
    LLMAS is capable of handling diverse complex scenarios. For example, WebAgent[[39](#bib.bib39)]
    demonstrated the possibility of building agents that can complete the tasks on
    real websites following natural language instructions. ChatDev[[12](#bib.bib12)]
    and MetaGPT[[13](#bib.bib13)] experimented with software development in multi-agent
    communication settings. Zhang et al.[[19](#bib.bib19)] built embodied agents to
    cooperate effectively with humans. Park et al.[[10](#bib.bib10)] situates generative
    agents with unique characteristics in a societal context, in order to mimic human
    social behaviors.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将众多基于大语言模型（LLM）的代理整合到一个统一的环境中，LLMAS 能够处理各种复杂的场景。例如，WebAgent[[39](#bib.bib39)]
    展示了在真实网站上构建能够按照自然语言指令完成任务的代理的可能性。ChatDev[[12](#bib.bib12)] 和 MetaGPT[[13](#bib.bib13)]
    在多代理通信环境中尝试了软件开发。张等人[[19](#bib.bib19)] 构建了具身代理，以便与人类有效合作。Park 等人[[10](#bib.bib10)]
    将具有独特特征的生成代理置于社会背景中，以模仿人类的社会行为。
- en: Several task-independent frameworks designed for diverse usages have received
    considerable attention within the community. AgentVerse[[17](#bib.bib17)] dynamically
    assembled multi-agent teams tailored to task complexities, outperforming individual
    agents with adaptable team structures. AgentSims[[16](#bib.bib16)] offered a real-time
    evaluation platform for LLM-based agents, enabling adaptable configurations to
    facilitate the performance evaluation of different modules. AutoGen[[40](#bib.bib40)]
    fostered conversations among multiple agents and organized individual insights
    in a general manner, offering an interconnected manner to coordinate multiple
    agents within the LLMAS. MetaGPT[[13](#bib.bib13)] injects effective human workflows
    into multi-agent collaboration by encoding Standardized Operational Procedures
    (SOP) into prompts, underscoring the potential of incorporating human domain expertise
    into LLMAS. CGMI[[11](#bib.bib11)] replicated human interactions and imitated
    human routines in real-world scenarios, which enhances the realism of more humanized
    simulation of complex social scenarios.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 设计用于多种用途的几种与任务无关的框架在社区内获得了相当的关注。AgentVerse[[17](#bib.bib17)] 动态地组建了根据任务复杂性量身定制的多代理团队，超越了具有适应性团队结构的个体代理。AgentSims[[16](#bib.bib16)]
    提供了一个实时评估平台，用于评估基于 LLM 的代理，允许适应性配置以促进不同模块的性能评估。AutoGen[[40](#bib.bib40)] 促进了多个代理之间的对话，并以一般方式组织个人见解，提供了一种互联的方式来协调
    LLMAS 内的多个代理。MetaGPT[[13](#bib.bib13)] 通过将标准操作程序（SOP）编码到提示中，将有效的人类工作流程注入多代理协作中，突出了将人类领域专业知识融入
    LLMAS 的潜力。CGMI[[11](#bib.bib11)] 复制了人类互动并模仿了现实场景中的人类日常活动，这增强了对复杂社会场景更人性化的模拟的真实性。
- en: Previous LLMAS research has primarily focused on constructing more universal
    frameworks or designing for specific domains, yet there has been a noticeable
    lack of emphasis on the analysis methods of parallel behaviors among agents within
    LLMAS. Contemporary LLMAS predominantly depend on conventional methods for surveillance
    and analysis. MetaGPT[[13](#bib.bib13)] utilizes log outputs for record maintenance,
    while Park et al.[[10](#bib.bib10)] adopts panoramic videos for observation, providing
    detailed maps with agent avatars to denote their locations and behaviors. Distinct
    from preceding efforts, our work offers an interactive visual system that hierarchically
    organizes events, facilitating users in quickly grasping the happenings within
    LLMAS.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的LLMAS研究主要集中于构建更通用的框架或为特定领域设计，然而对LLMAS中代理并行行为的分析方法却明显缺乏重视。现代LLMAS主要依赖传统的方法进行监控和分析。MetaGPT[[13](#bib.bib13)]利用日志输出进行记录维护，而Park等[[10](#bib.bib10)]则采用全景视频进行观察，提供详细的地图和代理头像以标示其位置和行为。与之前的努力不同，我们的工作提供了一个交互式视觉系统，以层次化的方式组织事件，帮助用户快速掌握LLMAS中的动态。
- en: 2.3 Event Sequence Visualization
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 事件序列可视化
- en: Data featuring time-based event sequences is widespread and can be found in
    various sectors, including healthcare records[[41](#bib.bib41), [42](#bib.bib42),
    [43](#bib.bib43)], career design[[44](#bib.bib44), [45](#bib.bib45)] and social
    interactions[[46](#bib.bib46), [47](#bib.bib47), [48](#bib.bib48)]. In these fields,
    distinct types of time-stamped events are sequentially organized, each relevant
    to a particular subject or entity. While earlier methods[[49](#bib.bib49), [50](#bib.bib50)]
    have been geared toward simpler, low-dimensional data, the data sets encountered
    in real-world scenarios frequently display a higher level of complexity, calling
    for more comprehensive analytical ideas and methods.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 包含时间序列事件的数据在各个领域广泛存在，包括医疗记录[[41](#bib.bib41)、[42](#bib.bib42)、[43](#bib.bib43)]、职业规划[[44](#bib.bib44)、[45](#bib.bib45)]和社交互动[[46](#bib.bib46)、[47](#bib.bib47)、[48](#bib.bib48)]。在这些领域，不同类型的时间戳事件被顺序组织，每个事件与特定主题或实体相关。尽管早期方法[[49](#bib.bib49)、[50](#bib.bib50)]主要针对较简单的低维数据，但在现实世界中遇到的数据集往往显示出更高的复杂性，需要更全面的分析思路和方法。
- en: A substantial number of research on event sequence visualization is notably
    correlated with fields where there is a prevalent demand for event information
    condensation, such as in the realm of social media data[[51](#bib.bib51)], the
    sphere of smart manufacturing [[52](#bib.bib52)], and the study of anomalous user
    behaviors[[53](#bib.bib53)]. Guo et al.[[54](#bib.bib54)] proposed an organizational
    framework for event sequences to summarize the common goal of different properties
    with great heterogeneity. EventThread[[44](#bib.bib44)] focuses on visualization
    and cluster analysis, providing an interactive interface for browsing and summarizing
    event sequence data. Building on past frameworks of condensing events and visualizing
    them, we focused on the behavioral patterns of LLM agents and proposed an LLM-driven
    approach to handle non-structured natural language-based event sequences.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 大量关于事件序列可视化的研究显著与那些对事件信息浓缩有广泛需求的领域相关，如社交媒体数据[[51](#bib.bib51)]、智能制造领域[[52](#bib.bib52)]和异常用户行为的研究[[53](#bib.bib53)]。郭等[[54](#bib.bib54)]提出了一个事件序列的组织框架，以总结不同属性之间的共同目标，尽管它们具有很大的异质性。EventThread[[44](#bib.bib44)]
    专注于可视化和聚类分析，提供了一个用于浏览和总结事件序列数据的交互式界面。在现有事件浓缩和可视化框架的基础上，我们关注了LLM代理的行为模式，并提出了一种基于LLM驱动的方法来处理非结构化自然语言事件序列。
- en: Event sequence visualization has highly relevant applications in the realm of
    collective behavior analysis, which aligns closely with the focus of our research,
    both referring to activities conducted by a temporary and unstructured group of
    people [[55](#bib.bib55), [56](#bib.bib56), [47](#bib.bib47)]. In the field of
    social media, collective actions emerge from the collaborative efforts of users
    engaged in disseminating information and navigating through virtual spaces. A
    variety of sophisticated visual analytics methodologies have been introduced to
    scrutinize these group dynamics. R-map[[57](#bib.bib57)], Socialwave[[58](#bib.bib58)],
    FluxFlow[[59](#bib.bib59)] and Google+ ripples[[60](#bib.bib60)] are specifically
    tailored to examine the mechanics of information propagation, while Maqui[[61](#bib.bib61)]
    and Frequence[[46](#bib.bib46)] offers insights into the complexities of human
    mobility within this context.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 事件序列可视化在集体行为分析领域有高度相关的应用，这与我们研究的重点紧密相关，两者都涉及到由临时且非结构化的群体进行的活动[[55](#bib.bib55),
    [56](#bib.bib56), [47](#bib.bib47)]。在社交媒体领域，集体行动源于用户在传播信息和在虚拟空间中导航的协作努力。已经引入了多种复杂的视觉分析方法来审视这些群体动态。R-map[[57](#bib.bib57)]、Socialwave[[58](#bib.bib58)]、FluxFlow[[59](#bib.bib59)]和Google+涟漪[[60](#bib.bib60)]专门用于研究信息传播的机制，而Maqui[[61](#bib.bib61)]和Frequence[[46](#bib.bib46)]则提供了对这一背景下人类移动复杂性的见解。
- en: While existing research has made significant contributions to the field, there’s
    a growing need to address the increasingly complex behaviors and interactions
    that call for the advancement of autonomous systems. Our work introduces event
    sequence visualization as an integral tool for the analysis and exploration of
    LLMAS.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管现有研究已对该领域作出了重要贡献，但对处理日益复杂的行为和交互的需求日益增长，这要求我们推动自主系统的发展。我们的工作将事件序列可视化引入作为分析和探索LLMAS的关键工具。
- en: 3 Overview
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 概述
- en: 3.1 Common Architecture of LLMAS
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 LLMAS的常见架构
- en: '![Refer to caption](img/25edbaeb7ab017740cf508cd26b1746b.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/25edbaeb7ab017740cf508cd26b1746b.png)'
- en: 'Figure 2: The common architecture abstracted from existing LLMAS consists of
    four layers: system states, agents, tasks, and operations.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：从现有LLMAS中抽象出的常见架构包括四个层次：系统状态、代理、任务和操作。
- en: 'To ensure maximum compatibility with various LLMAS, we survey LLMAS-related
    papers [[62](#bib.bib62), [63](#bib.bib63), [64](#bib.bib64), [65](#bib.bib65),
    [66](#bib.bib66), [67](#bib.bib67), [68](#bib.bib68), [69](#bib.bib69), [27](#bib.bib27),
    [28](#bib.bib28)] as well as some projects[[70](#bib.bib70), [71](#bib.bib71),
    [72](#bib.bib72), [73](#bib.bib73), [74](#bib.bib74), [75](#bib.bib75), [76](#bib.bib76),
    [77](#bib.bib77), [78](#bib.bib78), [79](#bib.bib79)] with high stars in open
    source communities published before August 31, 2023. We analyzed their system
    architectures and components, based on which we abstract a common architecture
    (as shown in [Fig. 2](#S3.F2 "In 3.1 Common Architecture of LLMAS ‣ 3 Overview
    ‣ AgentLens: Visual Analysis for Agent Behaviors in LLM-based Autonomous Systems"))
    for LLMAS. The system state in LLMAS provides the environmental information at
    any time point. At each time point, each agent executes its own task, which consists
    of several atomic operations. A raw event is generated whenever an operation is
    executed by an agent, thereby advancing the evolution of LLMAS.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '为确保与各种LLMAS的最大兼容性，我们调查了LLMAS相关的论文[[62](#bib.bib62), [63](#bib.bib63), [64](#bib.bib64),
    [65](#bib.bib65), [66](#bib.bib66), [67](#bib.bib67), [68](#bib.bib68), [69](#bib.bib69),
    [27](#bib.bib27), [28](#bib.bib28)]，以及一些在开源社区中获得高评价的项目[[70](#bib.bib70), [71](#bib.bib71),
    [72](#bib.bib72), [73](#bib.bib73), [74](#bib.bib74), [75](#bib.bib75), [76](#bib.bib76),
    [77](#bib.bib77), [78](#bib.bib78), [79](#bib.bib79)]，这些项目的发布时间在2023年8月31日之前。我们分析了它们的系统架构和组件，并基于此抽象出LLMAS的常见架构（如[图2](#S3.F2
    "在3.1 LLMAS的常见架构 ‣ 3 概述 ‣ AgentLens: 面向LLM基础自主系统的代理行为可视分析")）用于LLMAS。LLMAS中的系统状态提供了任何时刻的环境信息。在每个时间点，每个代理执行自己的任务，任务由若干原子操作组成。每当代理执行操作时，就会生成一个原始事件，从而推进LLMAS的演变。'
- en: System State provides a comprehensive understanding of the environment. By acquiring
    the environmental information from the system state, agents can comprehend the
    current context and conditions. For example, the system state can inform agents
    about object locations and environmental properties, which significantly impact
    their decision-making and planning processes. In addition, the system state governs
    the timelines of each agent, ensuring events by different agents are temporally
    aligned.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 系统状态提供了对环境的全面了解。通过从系统状态获取环境信息，代理可以理解当前的背景和条件。例如，系统状态可以告知代理对象的位置和环境属性，这些信息显著影响其决策和规划过程。此外，系统状态还控制着每个代理的时间线，确保不同代理的事件在时间上对齐。
- en: Agents are autonomous entities with cognitive abilities and action capability.
    By performing various types of tasks, agents can interact with the environment
    and gradually change the system state to achieve their goals. Additionally, agents
    can communicate and collaborate with each other. They can share their knowledge
    and exchange messages to accomplish more complex duties.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 代理是具有认知能力和行动能力的自主实体。通过执行各种类型的任务，代理可以与环境互动，并逐渐改变系统状态以实现目标。此外，代理还可以相互通信与协作。它们可以共享知识并交换消息，以完成更复杂的任务。
- en: 'Tasks are typically customized for the usage scenario of LLMAS. A sequence
    of operations with a common goal can be grouped as a task. Extending prior research
    that has focused on different scenarios for agents, we classify tasks into three
    categories: Perceive, Think, and Act. In Perceive tasks, the agent obtains perception
    of the external system. Such perception includes sensing the environment (virtual,
    real, or external resources), as well as perceiving other agents. In Think tasks,
    the agent engages in decision-making, reasoning, planning, and other behaviors
    based on external perception and its own memory. In Act tasks, the agent interacts
    with the external system by providing outputs, including text outputs, virtual
    actions, or specific invocations such as tool usage.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 任务通常根据LLMAS的使用场景进行定制。具有共同目标的一系列操作可以归为一个任务。延续先前研究针对不同场景的工作，我们将任务分为三类：感知（Perceive）、思考（Think）和行动（Act）。在感知任务中，代理获得对外部系统的感知。这种感知包括感知环境（虚拟、现实或外部资源），以及感知其他代理。在思考任务中，代理根据外部感知和自身记忆进行决策、推理、规划等行为。在行动任务中，代理通过提供输出与外部系统进行交互，包括文本输出、虚拟行动或特定的调用，如工具使用。
- en: Operations are the basic units for Tasks. Operations can be classified based
    on their target, including Environmental Operations, Memory Operations, and Decision
    Operations. Environment Operations execute interactions toward the external system,
    including other agents and the environment defined by LLMAS. Memory Operations
    involve storing and updating the memory of an agent. Decision Operations are for
    decision-making and action planning, where LLM-based agents typically utilize
    LLMs for decision operations.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 操作是任务的基本单元。操作可以根据其目标进行分类，包括环境操作、记忆操作和决策操作。环境操作执行与外部系统的交互，包括其他代理和LLMAS定义的环境。记忆操作涉及存储和更新代理的记忆。决策操作用于决策和行动规划，其中基于LLM的代理通常利用LLM进行决策操作。
- en: 3.2 Design Requirement
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 设计要求
- en: Our study focuses on users involved in analyzing, exploring, and monitoring
    LLMAS. Our primary goal is to create a system that enhances users’ comprehension
    of LLMAS. We recruited 4 developers highly familiar with LLMAS and 4 users who
    have a basic understanding of LLMAS and have previously utilized such systems.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究重点是分析、探索和监控LLMAS的用户。我们的主要目标是创建一个系统，以提升用户对LLMAS的理解。我们招募了4名对LLMAS非常熟悉的开发人员和4名对LLMAS有基本了解且曾使用过此类系统的用户。
- en: 'To identify the design requirements, We asked participants to explore the behaviors
    of agents in Reverie¹¹1https://reverie.herokuapp.com/arXiv_Demo/#, a typical autonomous
    system consisting of 25 LLM-based agents. We requested participants to actively
    explore and delve into the identification of agent behaviors that intrigued them,
    as well as to investigate the underlying causes or consequences. To facilitate
    this, we encouraged participants to “think aloud”, articulating the information
    they sought and the type of assistance they desired throughout the process. We
    then conducted the first interview with them to collect their feedback on the
    whole exploration process. At the same time, we maintain regular contact with
    them to keep them updated on the design requirements. Based on their feedback,
    and combined with the survey on existing LLMAS work in [section 3.1](#S3.SS1 "3.1
    Common Architecture of LLMAS ‣ 3 Overview ‣ AgentLens: Visual Analysis for Agent
    Behaviors in LLM-based Autonomous Systems"), the following 4 design requirements
    can be summarized.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '为了确定设计需求，我们要求参与者探索Reverie¹¹1https://reverie.herokuapp.com/arXiv_Demo/#中的代理行为，这是一个典型的由25个基于LLM的代理组成的自主系统。我们要求参与者积极探索并深入识别他们感兴趣的代理行为，以及调查这些行为的潜在原因或后果。为此，我们鼓励参与者“边想边说”，在整个过程中阐述他们寻求的信息和所需的帮助类型。然后，我们与他们进行了第一次访谈，以收集他们对整个探索过程的反馈。同时，我们保持与他们的定期联系，以便及时更新设计需求。根据他们的反馈，并结合对现有LLMAS工作的调查[在第3.1节](#S3.SS1
    "3.1 Common Architecture of LLMAS ‣ 3 Overview ‣ AgentLens: Visual Analysis for
    Agent Behaviors in LLM-based Autonomous Systems")，可以总结出以下4个设计需求。'
- en: R1\. Provide suitable generality of information for different analysis targets.
    During the evolution of LLMAS, a significant volume of information is continuously
    generated, which is overwhelming for users to comprehend. While the current 2D
    graphical interface of Reverie provides a fixed visual abstraction, many users
    express their desire to change the generality of presented information to better
    match their current analysis target. For instance, users want to scan summarized
    agent traces across a large time scale when they analyze the long-term relationship
    among several agents, while they prefer a detailed presentation of an agent’s
    operations when they analyze how the agent performs a certain task. Therefore,
    the system should provide users with flexible levels of abstraction for the generated
    information of LLMAS, and allows users to reveal details according to their analysis
    target.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: R1\. 为不同分析目标提供适当的一般性信息。在LLMAS的发展过程中，会持续生成大量信息，用户很难理解。虽然Reverie的当前2D图形界面提供了固定的视觉抽象，但许多用户希望改变呈现信息的一般性，以更好地匹配他们当前的分析目标。例如，用户在分析多个代理之间的长期关系时希望扫描总结的代理轨迹，而在分析某个代理执行特定任务时则更倾向于详细展示该代理的操作。因此，系统应为LLMAS生成的信息提供灵活的抽象层次，并允许用户根据其分析目标揭示详细信息。
- en: R2\. Present agents’ transition of physical location and thought content. The
    physical and mental changes of agents play a vital role in driving and reflecting
    the evolution of the entire LLMAS. Nevertheless, currently, users can only stare
    at the re-playable recording to see if there is a location transition of the agent
    and check the raw execution log to find when the agent starts to think about a
    certain idea, which is inefficient and error-prone. Therefore, the system should
    provide visual emphasis on agents’ transition of location and highlight the time
    points the agent starts to think about a topic the user wishes to explore.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: R2\. 展示代理的物理位置和思维内容的过渡。代理的物理和心理变化在推动和反映整个LLMAS的发展中起着至关重要的作用。然而，目前用户只能盯着可回放的录制视频来查看代理是否有位置转移，并检查原始执行日志以发现代理何时开始思考某个想法，这效率低且容易出错。因此，系统应在代理的位置转移上提供视觉强调，并突出显示代理开始思考用户希望探索的主题的时间点。
- en: R3\. Underscore possible causes of agent behaviors. When users become interested
    in a certain behavior of the agent, they usually want to investigate the cause
    or consequence of this behavior. However, an agent’s behavior can be influenced
    not only by its current perception and thoughts but also by the memory of its
    past behavior. It is tedious and unreliable for users to switch the replayable
    recording back and forth to locate the cause of the behaviors of certain agents.
    Therefore, the system should provide a mechanism to mine the possible causes of
    an agent’s behaviors and highlight them for users’ investigation.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: R3\. 突出代理行为的可能原因。当用户对代理的某种行为感兴趣时，他们通常会想要调查这种行为的原因或后果。然而，代理的行为不仅可能受其当前感知和思想的影响，还可能受到其过去行为的记忆的影响。用户来回切换可重放记录以确定某些代理行为的原因是繁琐且不可靠的。因此，系统应提供一种机制来挖掘代理行为的可能原因，并将其突出显示以供用户调查。
- en: R4\. Explicate the context of LLM invocation. LLM plays a crucial role as the
    core of the LLMAS, which is frequently invocated to make cognitive decisions for
    agents. To inform the background for making a certain decision, the preceding
    contextual information is organized in a specific manner with a customized template
    and then sent as a prompt to the LLM. Therefore, to help users understand how
    and why a decision is made by an agent, the system should present the decisions
    made by LLM and explicate the context of its invocation. Moreover, it is desirable
    to provide visual enhancement to help users trace how the context information
    is collected from previous agent behaviors.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: R4\. 解释LLM调用的背景。LLM在LLMAS中发挥着核心作用，通常被调用以便为代理做出认知决策。为了提供某一决策的背景信息，先前的上下文信息以特定的方式组织，通过定制模板，然后作为提示发送给LLM。因此，为了帮助用户理解代理如何以及为何做出某个决策，系统应展示LLM做出的决策并解释其调用背景。此外，最好提供视觉增强来帮助用户追踪上下文信息如何从先前的代理行为中收集。
- en: 3.3 Approach Overview
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 方法概述
- en: '![Refer to caption](img/0d9fb9620e76b8afc34edebb7ff49efc.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0d9fb9620e76b8afc34edebb7ff49efc.png)'
- en: 'Figure 3: The workflow of our approach consists of three major steps. (A) Collect
    raw execution log of events from the LLMAS evolution process. (B) Establish a
    behavior structure with hierarchical summarization and a cause trace method. (C)
    Provide an interactive user interface for visual exploration and analysis.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：我们的方法的工作流程包括三个主要步骤。（A）收集LLMAS演化过程中的原始执行日志事件。（B）建立具有分层总结和原因追踪方法的行为结构。（C）提供一个互动用户界面以进行可视化探索和分析。
- en: 'In alignment with the aforementioned design requirements, we designed AgentLens,
    a proof-of-concept system dedicated to visualizing agent behaviors during the
    LLMAS evolution. The workflow of our approach is depicted in [Fig. 3](#S3.F3 "In
    3.3 Approach Overview ‣ 3 Overview ‣ AgentLens: Visual Analysis for Agent Behaviors
    in LLM-based Autonomous Systems"). Users can utilize logging codes to log their
    LLMAS evolution process and capture raw events executed by agents. Based on these
    raw events, we establish a hierarchical structure to summarize agent behaviors
    in different granularity and trace possible causal relationships among their behaviors
    ([section 4](#S4 "4 Behavior Structure Establishment ‣ AgentLens: Visual Analysis
    for Agent Behaviors in LLM-based Autonomous Systems")). A user interface and a
    series of interactions are provided to support interactive exploration and analysis
    of the agent behaviors in LLMAS ([section 5](#S5 "5 User Interface ‣ AgentLens:
    Visual Analysis for Agent Behaviors in LLM-based Autonomous Systems")).'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 根据上述设计要求，我们设计了AgentLens，一个概念验证系统，专注于在LLMAS演化过程中可视化代理行为。我们的方法的工作流程如[图3](#S3.F3
    "在3.3 方法概述 ‣ 3 概述 ‣ AgentLens：LLM基础的自主系统中代理行为的可视分析")所示。用户可以利用日志代码记录他们的LLMAS演化过程，并捕捉代理执行的原始事件。基于这些原始事件，我们建立了一个分层结构来总结不同粒度的代理行为，并追踪其行为之间的可能因果关系（[第4节](#S4
    "4 行为结构建立 ‣ AgentLens：LLM基础的自主系统中代理行为的可视分析")）。提供了一个用户界面和一系列互动来支持对LLMAS中代理行为的交互式探索和分析（[第5节](#S5
    "5 用户界面 ‣ AgentLens：LLM基础的自主系统中代理行为的可视分析")）。
- en: 4 Behavior Structure Establishment
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 行为结构建立
- en: '![Refer to caption](img/1f5934e9014b5f48c7d9a72392341238.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/1f5934e9014b5f48c7d9a72392341238.png)'
- en: 'Figure 4: The behavior structure is established through a three-step pipeline:
    (A) We organize raw events into behaviors, (B) summarize and segment behaviors
    for an agent, and (C) trace causal relationships among behaviors.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：行为结构通过三步流程建立：(A) 我们将原始事件组织成行为，(B) 总结并分段代理的行为，以及(C) 追踪行为之间的因果关系。
- en: 'In this section, we introduce a pipeline designed to establish the hierarchical
    behavior structure from raw events generated during the evolution of LLMAS. It
    facilitates the generation of structured data for visualization, achieved via
    summarization and causal analysis of agent behaviors. As shown in [Fig. 4](#S4.F4
    "In 4 Behavior Structure Establishment ‣ AgentLens: Visual Analysis for Agent
    Behaviors in LLM-based Autonomous Systems"), the pipeline consists of three steps:
    (A) processing the raw events and organizing them into behaviors based on the
    common architecture shown in [Fig. 2](#S3.F2 "In 3.1 Common Architecture of LLMAS
    ‣ 3 Overview ‣ AgentLens: Visual Analysis for Agent Behaviors in LLM-based Autonomous
    Systems") (R1), (B) summarizing these behaviors and segmenting them in accordance
    with their semantic implications. (R1, R2), and (C) tracing the cause between
    these behaviors by analyzing the correlations among original events (R3, R4).'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们介绍了一种旨在从LLMAS发展过程中生成的原始事件中建立层次行为结构的流程。它通过总结和因果分析代理行为来生成用于可视化的结构化数据。如[图4](#S4.F4
    "在4 行为结构建立 ‣ AgentLens: LLM基础自主系统中代理行为的视觉分析")所示，该流程包括三个步骤：(A) 处理原始事件并根据[图2](#S3.F2
    "在3.1 LLMAS的常见架构 ‣ 3概述 ‣ AgentLens: LLM基础自主系统中代理行为的视觉分析") (R1)中所示的通用架构将其组织成行为，(B)
    总结这些行为并根据其语义含义进行分段。(R1, R2)，以及(C) 通过分析原始事件之间的相关性追踪这些行为之间的因果关系 (R3, R4)。'
- en: 4.1 Behavior Definition
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 行为定义
- en: During the evolution of LLMAS, multiple raw events are generated, creating large,
    often chaotic, and obscure text logs with the scaling of agent populations. To
    streamline downstream analysis and visualization efforts, we defined agent behaviors
    as structured representations that encapsulate the sequence of raw events (R1).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLMAS的发展过程中，生成了多个原始事件，随着代理群体的扩大，产生了大量、通常混乱且模糊的文本日志。为了简化下游分析和可视化工作，我们将代理行为定义为结构化表示，
    encapsulate原始事件的序列（R1）。
- en: 'Drawing upon the system state adopted by most LLMAS architectures, we denote
    the timeline $T$ as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 借鉴大多数LLMAS架构采用的系统状态，我们将时间线$T$表示如下：
- en: '|  | $T_{t}=\langle e_{t-1},\bigcup a_{t-1}[i],\bigcup s_{t}[i]\rangle$ |  |
    (1) |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '|  | $T_{t}=\langle e_{t-1},\bigcup a_{t-1}[i],\bigcup s_{t}[i]\rangle$ |  |
    (1) |'
- en: where $e_{t-1}$, which imply factual (e.g. duplicate segments generated by prompt
    construction) and semantic (e.g. repeated biased interpretations of the same observation)
    duplications.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$e_{t-1}$，意味着事实（例如，由提示构造生成的重复段）和语义（例如，对同一观察的重复偏见解释）重复。
- en: 'To address these problems, we synthesize events on $T$ for each agent into
    their behaviors:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些问题，我们将每个代理在$T$上的事件合成其行为：
- en: '|  | $B_{i,t_{0}\cdots t_{1}}=\bigcup_{t\in[t_{0},t_{1}]}s_{t,i}$ |  | (2)
    |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '|  | $B_{i,t_{0}\cdots t_{1}}=\bigcup_{t\in[t_{0},t_{1}]}s_{t,i}$ |  | (2)
    |'
- en: It refers to the set of operations performed by the $i$ within the temporal
    series T.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这指的是在时间序列T内由$i$执行的一组操作。
- en: 4.2 Behavior Summarization
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 行为总结
- en: '![Refer to caption](img/ba38913bd6debb948d3eccda6ab3c5e0.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/ba38913bd6debb948d3eccda6ab3c5e0.png)'
- en: 'Figure 5: The agent behavior is summarized in four stages: (A) Raw Events:
    acquire raw events from the logs to detail the occurrences involving the agent
    along the timeline, including the agent’s location, actions, memory, and conversations.
    (B) Description Generation: organize the raw events and employ models such as
    LLMs to generate concise descriptions of the behaviors. (C) Behavior Embedding:
    translate the behavior descriptions into a sequence of textual embedding vectors.
    (D) Timeline Segmentation: involve the detection of change points within the sequence
    of behavior vectors, followed by the corresponding segmentation of the agent’s
    timeline.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：代理行为总结为四个阶段：(A) 原始事件：从日志中获取原始事件，详细记录代理沿时间线的发生情况，包括代理的位置、动作、记忆和对话。(B) 描述生成：整理原始事件，并使用诸如LLM模型等生成行为的简洁描述。(C)
    行为嵌入：将行为描述转换为一系列文本嵌入向量。(D) 时间线分段：检测行为向量序列中的变化点，然后对代理的时间线进行相应分段。
- en: In various LLMAS, operations manifest in different forms, such as text, images,
    and even physical behaviors in the factory environment. Meanwhile, new behaviors
    of those agents are continuously generated as $T$ D).
    Ultimately, we can summarize a multitude of small behaviors into several noteworthy
    behaviors with segmented timelines.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在各种LLMAS中，操作表现为不同的形式，如文本、图像，甚至是工厂环境中的实际行为。同时，这些代理的新行为不断生成，作为$T$ D）。*最终*，我们可以将大量的小行为总结为几个值得注意的行为，并具有分段时间线。
- en: 'Description Generation: We incorporate an external text summarization model,
    which acts as a standalone LLM agent that operates independently of LLMAS. All
    annotated descriptions are concatenated to form a comprehensive model input (i.e.
    prompts for LLM). Given this long text sequence as input, the summarization model
    generates a succinct behavior description, significantly reducing the information
    length while maintaining the original meaning (shown in [Fig. 5](#S4.F5 "In 4.2
    Behavior Summarization ‣ 4 Behavior Structure Establishment ‣ AgentLens: Visual
    Analysis for Agent Behaviors in LLM-based Autonomous Systems"), B,
    from Prompt to Response). Concurrently, we prompt that the summarization model
    yields a highly abstract description of the behavior, employing both textual and
    emoji symbols. Textual descriptions serve as the foundation for the forthcoming
    embedding model and emoji symbols are conceived to facilitate subsequent visualization.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 描述生成：我们结合了一个外部文本总结模型，它作为一个独立的LLM代理，独立于LLMAS运行。所有标注的描述被串联起来，形成一个全面的模型输入（即LLM的提示）。给定这个长文本序列作为输入，摘要模型生成一个简洁的行为描述，显著减少了信息长度，同时保持了原始含义（见[图5](#S4.F5
    "在 4.2 行为总结 ‣ 4 行为结构建立 ‣ AgentLens：LLM基础自主系统中代理行为的视觉分析")，B，从提示到响应）。同时，我们提示摘要模型产生一个高度抽象的行为描述，使用文本和表情符号。文本描述作为即将到来的嵌入模型的基础，表情符号则旨在促进后续的可视化。
- en: 'Behavior Embedding: We further utilize all summarized behavior descriptions,
    embedding them to better grasp the latent semantics, including the inherent similarities
    and hierarchical relationships. To maximize the efficiency of the encoding schema,
    we adopt the text-embedding model²²2https://platform.openai.com/docs/guides/embeddings
    pretrained on large-scale internet text data, renowned for its superior performance,
    cost-effectiveness, and simplicity of use. The summarized behavior descriptions
    are then each encoded into a 1536-dimensional vector, constituting the sequence
    $E_{\text{agent}}$ for each agent. With these powerful embeddings, we can uncover
    the semantic similarity of a single behavior, thereby unlocking the potential
    to tackle a myriad of complex text sequence analyses.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 行为嵌入：我们进一步利用所有总结的行为描述，将其嵌入以更好地把握潜在的语义，包括固有的相似性和层级关系。为了最大化编码模式的效率，我们采用在大规模互联网文本数据上预训练的文本嵌入模型²²2https://platform.openai.com/docs/guides/embeddings，该模型以其优越的性能、成本效益和使用简便而著称。总结的行为描述随后被编码成一个1536维的向量，构成每个代理的序列$E_{\text{agent}}$。凭借这些强大的嵌入，我们可以揭示单一行为的语义相似性，从而解锁处理各种复杂文本序列分析的潜力。
- en: 'Timeline Segmentation: Considering the data characteristics of the embedding
    sequence $e$ and our design requirements, we employ the Window-based change point
    detection (WIN) algorithm [[80](#bib.bib80)] with the cosine distance measure
    to segment the sequence. This approach is suitable for real-time or streaming
    data contexts, as it allows for incremental updates in response to the arrival
    of new data and exhibits insensitivity to short-term and frequent fluctuations.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 时间线分割：考虑到嵌入序列$e$的数据特性和我们的设计要求，我们采用基于窗口的变化点检测（WIN）算法[[80](#bib.bib80)]，利用余弦距离度量来分割序列。这种方法适用于实时或流数据上下文，因为它允许对新数据的到来进行增量更新，并对短期和频繁的波动不敏感。
- en: 'Firstly, to compare two embedding vectors $e_{x}$ are the Euclidean scalar
    product and norm respectively:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，比较两个嵌入向量$e_{x}$分别是欧几里得标量积和范数：
- en: '|  | $k(e_{x},e_{y}):=\frac{\langle e_{x}&#124;e_{y}\rangle}{\&#124;e_{x}\&#124;\&#124;e_{y}\&#124;}$
    |  | (3) |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '|  | $k(e_{x},e_{y}):=\frac{\langle e_{x}&#124;e_{y}\rangle}{\&#124;e_{x}\&#124;\&#124;e_{y}\&#124;}$
    |  | (3) |'
- en: 'Then we recall the cost $c(\cdot)$:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们回顾代价$c(\cdot)$：
- en: '|  | $c(e_{a..b})=\sum_{t=a+1}^{b}k(e_{t},e_{t})-\frac{1}{b-a}\sum_{s,t=a+1}^{b}k(e_{s},e_{t})$
    |  | (4) |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '|  | $c(e_{a..b})=\sum_{t=a+1}^{b}k(e_{t},e_{t})-\frac{1}{b-a}\sum_{s,t=a+1}^{b}k(e_{s},e_{t})$
    |  | (4) |'
- en: 'WIN utilizes two sliding windows that traverse the data stream. By comparing
    the statistical properties of the signals within each window, a discrepancy measure
    is obtained based on the cost function $c$:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: WIN利用两个滑动窗口遍历数据流。通过比较每个窗口内信号的统计特性，基于代价函数$c$获得一个差异度量：
- en: '|  | $d(e_{u..v},e_{v..w})=c(e_{u..w})-c(e_{u..v})-c(e_{v..w})$ |  | (5) |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '|  | $d(e_{u..v},e_{v..w})=c(e_{u..w})-c(e_{u..v})-c(e_{v..w})$ |  | (5) |'
- en: The discrepancy $d$.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 差异度$d$。
- en: '![Refer to caption](img/df584891e1f5d14b6f3949079d58c4e1.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/df584891e1f5d14b6f3949079d58c4e1.png)'
- en: 'Figure 6: The timeline segmentation results of an agent in Reverie. The x-axis
    denotes the timeline, while the y-axis corresponds to the value of the principle
    PCA component of agent behavior embedding at each time point.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：Reverie中一个代理的时间线分割结果。x轴表示时间线，y轴表示每个时间点上代理行为嵌入的主成分PCA值。
- en: '[Fig. 6](#S4.F6 "In 4.2 Behavior Summarization ‣ 4 Behavior Structure Establishment
    ‣ AgentLens: Visual Analysis for Agent Behaviors in LLM-based Autonomous Systems")
    provides an illustrative example of the timeline segmentation process. Here we
    try to segment the timeline of a writer agent in the Reverie environment. The
    agent’s entire morning schedule is shown in ( [Fig. 6](#S4.F6 "In 4.2 Behavior
    Summarization ‣ 4 Behavior Structure Establishment ‣ AgentLens: Visual Analysis
    for Agent Behaviors in LLM-based Autonomous Systems"), A),
    spanning from midnight to noon, encompassing 4000 time points (0$\to$4000) on
    the timeline. To facilitate an intuitive understanding of the segmentation result,
    we conducted principal component analysis (PCA) on the embedding of behavior at
    each time point, and used the y-axis to encode the values of the primary PCA components,
    resulting in the orange line plot presented in [Fig. 6](#S4.F6 "In 4.2 Behavior
    Summarization ‣ 4 Behavior Structure Establishment ‣ AgentLens: Visual Analysis
    for Agent Behaviors in LLM-based Autonomous Systems").'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[图6](#S4.F6 "在4.2行为总结 ‣ 4行为结构建立 ‣ AgentLens：基于LLM的自主系统中代理行为的可视分析") 提供了时间线分段过程的示例。在这里，我们尝试对Reverie环境中的一个写作代理的时间线进行分段。代理的整个早晨时间表显示在（[图6](#S4.F6
    "在4.2行为总结 ‣ 4行为结构建立 ‣ AgentLens：基于LLM的自主系统中代理行为的可视分析")，A），覆盖从午夜到中午的时间段，涵盖了时间线上的4000个时间点（0$\to$4000）。为了便于直观理解分段结果，我们对每个时间点的行为嵌入进行了主成分分析（PCA），并使用y轴编码了主PCA成分的值，最终生成了[图6](#S4.F6
    "在4.2行为总结 ‣ 4行为结构建立 ‣ AgentLens：基于LLM的自主系统中代理行为的可视分析")中呈现的橙色折线图。'
- en: 'As we can see in ( [Fig. 6](#S4.F6 "In 4.2 Behavior Summarization ‣ 4 Behavior
    Structure Establishment ‣ AgentLens: Visual Analysis for Agent Behaviors in LLM-based
    Autonomous Systems"), A), by applying
    the segmentation algorithm (with N=5 as an example), this period is summarized
    into five main behaviors (“sleep and plan”, “revisiting previous work”, etc.).
    Moreover, if we re-apply the timeline segmentation algorithm to the “dedicated
    writing” behavior, which spans time points 2251$\to$3177 ([Fig. 6](#S4.F6 "In
    4.2 Behavior Summarization ‣ 4 Behavior Structure Establishment ‣ AgentLens: Visual
    Analysis for Agent Behaviors in LLM-based Autonomous Systems"), B)
    on the timeline, we can further divide it into five sub-behaviors (“gather ideas”,
    “brainstorm”, etc.). Note that all these sub-behaviors can be considered as “dedicated
    writing”, while exhibiting more subtle distinctions among them.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '正如我们在（[图6](#S4.F6 "在4.2 行为总结 ‣ 4 行为结构建立 ‣ AgentLens: 基于LLM的自主系统中的代理行为的视觉分析")）中看到的，通过应用分段算法（以N=5为例），这段时间被总结为五种主要行为（“睡眠和计划”、“重新审视之前的工作”等）。此外，如果我们重新应用时间线分段算法到“专注写作”行为上，该行为跨越时间点2251$\to$3177（[图6](#S4.F6
    "在4.2 行为总结 ‣ 4 行为结构建立 ‣ AgentLens: 基于LLM的自主系统中的代理行为的视觉分析")），我们可以进一步将其划分为五个子行为（“收集想法”、“头脑风暴”等）。注意，所有这些子行为都可以视为“专注写作”，同时表现出它们之间的更微妙的区别。'
- en: Another observation to note is that in the line plot formed by PCA principal
    component values, there are some peaks. These peaks occur because the agent executes
    specific operations at this time point, such as generating new memories or perceiving
    new objects. However, these operations do not have a lasting impact on the agent’s
    ongoing behavior. Therefore, they are usually regarded as tiny behaviors contained
    in their parent behavior.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要注意的观察是，在PCA主成分值形成的折线图中，存在一些峰值。这些峰值的出现是因为代理在此时间点执行了特定的操作，例如生成新记忆或感知新物体。然而，这些操作对代理的持续行为没有持久影响。因此，它们通常被视为包含在其父行为中的微小行为。
- en: 4.3 Cause Tracing
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 因果追踪
- en: Within a complex timeline, any agent event is influenced by both its internal
    memory and interactions with the external environment. By tracing the causal factors
    of these events, users can gain valuable insights into agent behaviors (R3) and
    LLM invocation for decision-making (R4), thereby improving the credibility and
    interpretability of LLMAS.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在复杂的时间线中，任何代理事件都受到其内部记忆和与外部环境互动的影响。通过追踪这些事件的因果因素，用户可以获得有关代理行为的宝贵见解（R3）以及用于决策的LLM调用（R4），从而提高LLMAS的可信度和可解释性。
- en: Existing works[[10](#bib.bib10)] primarily rely on log debugging to explicitly
    reveal the origins of agents’ operations. However, these methods place an additional
    cognitive burden on users due to the need for manual tracing and often fail to
    capture implicit causal relationships. For instance, current thinking can be influenced
    by observations over a long time steps. To efficiently trace the behavior causes,
    we propose a two-fold provenance tracing method to mine the causal relationships
    between underlying events within the behaviors.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的研究[[10](#bib.bib10)]主要依赖日志调试来显式揭示代理操作的来源。然而，这些方法由于需要手动追踪，给用户带来了额外的认知负担，并且往往未能捕捉到隐含的因果关系。例如，目前的思维可能会受到长时间步长观察的影响。为了高效追踪行为原因，我们提出了一种双重源追踪方法，以挖掘行为中潜在事件之间的因果关系。
- en: 'Explicit Causes: It refers to the distinct and observable causal relationships
    that can be directly discerned from raw event logs, explicitly delineating the
    direct influence relationships between operations. For example, in open-source
    agent creation frameworks like Langchain[[34](#bib.bib34)] and AgentVerse[[17](#bib.bib17)],
    mechanisms have been implemented to index attributes of agent memory, facilitating
    direct backtracking to the relevant source operations upon the invocation of an
    agent’s memory. When such explicit causal chains are completed in LLMAS, users
    can thus obtain these records through raw event logs and transmit them to AgentLens.
    AgentLens utilizes these logs as input to facilitate the analysis of downstream
    tasks for users.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 显式原因：指的是可以直接从原始事件日志中辨别出的明显因果关系，明确划分操作之间的直接影响关系。例如，在开源代理创建框架如 Langchain[[34](#bib.bib34)]
    和 AgentVerse[[17](#bib.bib17)]中，已经实现了对代理内存属性的索引机制，从而在调用代理内存时可以直接回溯到相关的源操作。当这样的显式因果链在LLMAS中完成时，用户可以通过原始事件日志获得这些记录，并将其传输给
    AgentLens。AgentLens 利用这些日志作为输入，以促进对用户的下游任务分析。
- en: 'Implicit Causes: Throughout the evolution of LLMAS, the agents’ invocations
    of historical operations are not always documented, but rather are expressed through
    complex intermediate variables or latent patterns within the program. To capture
    these implicit causal relationships, we conduct relevance detection based on the
    text similarities (as in [eq. 3](#S4.E3 "In 4.2 Behavior Summarization ‣ 4 Behavior
    Structure Establishment ‣ AgentLens: Visual Analysis for Agent Behaviors in LLM-based
    Autonomous Systems")) between the textual log of these operations themselves,
    thereby revealing the latent connections between events. To strike a balance between
    uncovering potential causal relationships and preventing information overload
    for users, we define a similarity threshold $\delta$.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 隐式原因：在LLMAS的发展过程中，代理对历史操作的调用并不总是有记录，而是通过程序中的复杂中间变量或潜在模式表达。为了捕捉这些隐式因果关系，我们基于这些操作自身文本日志之间的相似性（如[公式3](#S4.E3
    "在4.2行为总结 ‣ 4 行为结构建立 ‣ AgentLens：LLM基础的自主系统中代理行为的视觉分析")）进行相关性检测，从而揭示事件之间的潜在连接。为了在揭示潜在因果关系和防止信息过载之间取得平衡，我们定义了相似性阈值
    $\delta$。
- en: After the extraction of both explicit and implicit causes among operations is
    completed, we have ascertained every possible pair $.
    The connections between operations can be elevated to the connection between the
    corresponding behaviors in a bottom-up fashion, in accordance with the definition
    of behavior outlined in [section 4.1](#S4.SS1 $).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成对操作中显式和隐式原因的提取后，我们确定了每对可能的 $$。操作之间的连接可以以自下而上的方式提升为对应行为之间的连接，这与[第4.1节](#S4.SS1)中概述的行为定义一致。
- en: 'Agent Interaction Analysis: Each agent in the Outline View is represented as
    a uniquely colored curve, whose x-axis encodes the system time point and y-axis
    encodes the location of the agent, depicting the transition of the location of
    each agent (R2). When several agents are in the same time and location, they can
    have interactions (e.g. conversations, collaborations, or conflicts) with each
    other. Since these interactions usually play a crucial role in affecting the LLMAS’s
    evolution, we highlight them by filling the area among the corresponding segment
    of agent curves. Users can click an interaction area of interest to check the
    integration details ([Fig. 1](#S0.F1 "In AgentLens: Visual Analysis for Agent
    Behaviors in LLM-based Autonomous Systems"), $A_{2}$). Drawing
    inspiration from previous work of storytelling[[82](#bib.bib82), [83](#bib.bib83)],
    we enforce agent curves to get closer if there is an interaction among them.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 代理互动分析：大纲视图中的每个代理都用独特颜色的曲线表示，其 x 轴编码系统时间点，y 轴编码代理的位置，描绘每个代理位置的过渡（R2）。当几个代理在相同的时间和位置时，它们可以互相进行互动（例如对话、协作或冲突）。由于这些互动通常在影响LLMAS的演变中起着关键作用，我们通过填充代理曲线对应段之间的区域来突出显示这些互动。用户可以点击感兴趣的互动区域查看整合细节（[图
    1](#S0.F1 "在 AgentLens 中：基于 LLM 的自主系统中的代理行为的可视化分析")，$A_{2}$）。借鉴以往的叙事工作[[82](#bib.bib82),
    [83](#bib.bib83)]，我们强制代理曲线在它们之间有互动时变得更接近。
- en: 'Agent Memory Search: Sometimes users want to conduct exploration about when
    and how the agents start to have thoughts about a specific topic (R2). Therefore,
    we provide a search box in the top right corner of the view, allowing users to
    add keywords related to the topic they want to explore. Whenever a keyword is
    added, the points on the agent curves corresponding to time points associated
    with relevant memory will be highlighted ([Fig. 1](#S0.F1 "In AgentLens: Visual
    Analysis for Agent Behaviors in LLM-based Autonomous Systems"), $A_{3}$).'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 代理记忆搜索：有时用户希望探索代理何时以及如何开始对特定主题产生思考（R2）。因此，我们在视图的右上角提供了一个搜索框，允许用户添加与他们希望探索的主题相关的关键词。每当添加关键词时，代理曲线上与相关记忆相关的时间点的点将被突出显示（[图
    1](#S0.F1 "在 AgentLens 中：基于 LLM 的自主系统中的代理行为的可视化分析")，$A_{3}$)。
- en: 5.2 Agent View
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 代理视图
- en: When users notice a specific phenomenon or behavior from the Outline View and
    wish to further explore it, they can click on the corresponding time point on
    an agent curve to access more details (R1) in the Agent View.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户在大纲视图中注意到特定现象或行为并希望进一步探索时，他们可以点击代理曲线上的相应时间点以访问 Agent View 中的更多细节（R1）。
- en: 'Agent Characteristic: A complex LLMAS typically contains agents with different
    characteristics. For example, agents might be assigned different roles and goals,
    which are usually realized through prompt engineering or LLM fine-tuning. Since
    these details are important for users to understand and infer an agent’s behavior,
    we display them on the left panel of the Agent View ([Fig. 1](#S0.F1 "In AgentLens:
    Visual Analysis for Agent Behaviors in LLM-based Autonomous Systems"), $B_{1}$).'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 代理特征：一个复杂的LLMAS通常包含具有不同特征的代理。例如，代理可能被分配不同的角色和目标，这些目标通常通过提示工程或LLM微调来实现。由于这些细节对用户理解和推断代理行为至关重要，我们在代理视图的左侧面板上显示这些信息
    ([图1](#S0.F1 "在AgentLens中：LLM基础的自主系统中的代理行为的可视化分析"), $B_{1}$)。
- en: 'Time Point Revealing: On the right panel of Agent View, we provide users with
    a timeline ([Fig. 1](#S0.F1 "In AgentLens: Visual Analysis for Agent Behaviors
    in LLM-based Autonomous Systems"), $B_{2}$) (R4);
    If the user clicks ![[Uncaptioned image]](img/117e629cdab57bc6fe842e846ac345cb.png),
    a description panel will pop up to show the texts stored into the memory at this
    operation; If the user clicks ![[Uncaptioned image]](img/98f341a8671571697546d51a5c7477e6.png),
    a description panel will pop up to show what the agent is perceiving from or act
    on the environment.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 时间点揭示：在代理视图的右侧面板上，我们向用户提供时间轴 ([图1](#S0.F1 "在AgentLens中：LLM基础的自主系统中的代理行为的可视化分析"),
    $B_{2}$)
    (R4)；如果用户点击 ![[无标题图片]](img/117e629cdab57bc6fe842e846ac345cb.png)，将弹出描述面板，显示此操作中存储到内存中的文本；如果用户点击
    ![[无标题图片]](img/98f341a8671571697546d51a5c7477e6.png)，将弹出描述面板，显示代理从环境中感知或作用的内容。
- en: 'Cause Tracing: In addition to obtaining detailed behavioral information about
    agents, users also need to locate and analyze the reasons behind these agent behaviors.
    Whenever the user clicks an operator icon in the Agent View, the system will utilize
    the cause trace method described in Section [4.3](#S4.SS3 "4.3 Cause Tracing ‣
    4 Behavior Structure Establishment ‣ AgentLens: Visual Analysis for Agent Behaviors
    in LLM-based Autonomous Systems") to find previous operators that potentially
    have an intrinsic relationship with the current operation and highlight their
    corresponding time point on the Agent View (R3). We use edges with orange color
    to connect the selected operator and their predecessors. Since the agent behaviors
    could be affected by previous operations a long time ago, we provide users with
    a mini-map to visualize the point of the current operation and its related predecessors
    across the whole timeline ([Fig. 1](#S0.F1 "In AgentLens: Visual Analysis for
    Agent Behaviors in LLM-based Autonomous Systems"), $B_{4}$)
    (R1). Based on this mini-map, users can switch back and forth between the cause
    and result across the timeline more easily.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 原因追踪：除了获取有关代理的详细行为信息外，用户还需要定位和分析这些代理行为背后的原因。每当用户点击代理视图中的操作符图标时，系统将使用第 [4.3](#S4.SS3
    "4.3 原因追踪 ‣ 4 行为结构建立 ‣ AgentLens：LLM 基于自主系统中代理行为的可视分析") 节中描述的原因追踪方法来查找可能与当前操作具有内在关系的先前操作符，并在代理视图（R3）上突出显示其相应的时间点。我们使用橙色的边连接所选的操作符及其前驱。由于代理行为可能会受到很久以前的先前操作的影响，我们为用户提供了一个小地图，以可视化当前操作点及其相关前驱在整个时间线上的位置（[图
    1](#S0.F1 "在 AgentLens 中：LLM 基于自主系统中代理行为的可视分析")，$B_{4}$)（R1）。基于这个小地图，用户可以更轻松地在时间线上的原因和结果之间来回切换。
- en: 5.3 Monitor View
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 监控视图
- en: 'LLMAS typically provides a graphical representation of the dynamic simulation.
    It could be re-playable for 2D video or 3D, contingent upon the LLMAS evolution
    logs provided by the user for AgentLens. This visual representation transforms
    abstract simulation data into perceptually friendly visual elements, which helps
    users understand LLMAS and verify their analysis more intuitively. However, manually
    switching between different locations and time points can be tedious and interrupt
    the user’s analysis flow. Therefore, we provide the Monitor View to support fluent
    adjustment of the panoramic visualization of LLMAS ([Fig. 1](#S0.F1 "In AgentLens:
    Visual Analysis for Agent Behaviors in LLM-based Autonomous Systems"), C)
    based on users’ current focus and demand for context.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: LLMAS 通常提供动态模拟的图形表示。它可以根据用户为 AgentLens 提供的 LLMAS 演化日志进行 2D 视频或 3D 的重播。这种视觉表示将抽象的模拟数据转换为感知友好的视觉元素，这有助于用户更直观地理解
    LLMAS 并验证他们的分析。然而，手动切换不同的位置和时间点可能会很繁琐，并打断用户的分析流程。因此，我们提供了监控视图，以支持对 LLMAS 全景可视化的流畅调整（[图
    1](#S0.F1 "在 AgentLens 中：LLM 基于自主系统中代理行为的可视分析")，C)，以满足用户当前的焦点和背景需求。
- en: 'Focus Switching: Whenever the user clicks a time point on agent curve from
    the Outline View or a time point from the Agent View, the Monitor View will automatically
    switch to the location of that agent at that time point, providing a corresponding
    concrete visualization to complement the other two views (R1).'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 焦点切换：每当用户在大纲视图中点击代理曲线上的时间点或在代理视图中点击时间点时，监视视图将自动切换到该时间点的代理位置，提供相应的具体可视化，以补充其他两个视图（R1）。
- en: 'Context Revealing: The Monitor View also supports spatial and temporal context
    revealing to help users better comprehend the current focus point. As for the
    spatial context, the user can scroll the mouse wheel to adjust the level of scope,
    ranging from a macroscopic view of the entire LLMAS to a microscopic focus on
    a single agent. As for the temporal context, whenever the user changes the focus
    point from time point A to time point B, they can right-click the mouse to replay
    a fast-forward recording of that period of time in the Monitor View.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文揭示：监视视图还支持空间和时间上下文的揭示，以帮助用户更好地理解当前焦点。对于空间上下文，用户可以滚动鼠标滚轮来调整视野范围，从整个LLMAS的宏观视图到单个代理的微观焦点。对于时间上下文，每当用户将焦点从时间点A更改为时间点B时，他们可以右键单击鼠标，在监视视图中重放该时间段的快进记录。
- en: 6 Usage Scenarios
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 使用场景
- en: '6.1 Scenario A: Information Diffusion'
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 场景 A：信息扩散
- en: '![Refer to caption](img/5996e753ed2158aa2b81f3c78cf43c4c.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/5996e753ed2158aa2b81f3c78cf43c4c.png)'
- en: 'Figure 7: The first usage scenario showcases the support AgentLens provides
    to the user in exploring social patterns like Information Diffusion. (A) The user
    gleans the characteristics of each agent via the Agent View. (B) Proceeding to
    the Outline View, the user searches for the keyword “party”, discovering several
    related memory points generated in several conversations. (C) Utilizing the Agent
    View, the user delves into the origins of these conversational patterns.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：第一个使用场景展示了AgentLens在探索社会模式如信息扩散方面对用户的支持。（A）用户通过代理视图获取每个代理的特征。（B）在大纲视图中，用户搜索关键词“派对”，发现多个在多个对话中生成的相关记忆点。（C）利用代理视图，用户深入探讨这些对话模式的起源。
- en: 'This case demonstrates how our system helps users understand the patterns of
    agent behaviors in LLMAS. In the initialization phase, the user adds the information
    “Organize Valentine’s Day party at Hobbs Coffee on the evening of February 14th”
    to the characteristic ([Fig. 7](#S6.F7 "In 6.1 Scenario A: Information Diffusion
    ‣ 6 Usage Scenarios ‣ AgentLens: Visual Analysis for Agent Behaviors in LLM-based
    Autonomous Systems"), $A_{1}$) of the
    agent Isabella Rodriguez (IR) and wishes to observe the evolution of the system
    on February 13th.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 本案例展示了我们的系统如何帮助用户理解LLMAS中代理行为的模式。在初始化阶段，用户将“在2月14日晚上在霍布斯咖啡馆组织情人节派对”的信息添加到代理Isabella
    Rodriguez（IR）的特征中（[图7](#S6.F7 "在6.1场景A：信息扩散 ‣ 6 使用场景 ‣ AgentLens：用于LLM-based自主系统的代理行为的视觉分析")，$A_{1}$)，并希望观察系统在2月13日的演变。
- en: 'To focus on the theme of the party, the user searches for the occurrence of
    the keyword “party” ([Fig. 7](#S6.F7 "In 6.1 Scenario A: Information Diffusion
    ‣ 6 Usage Scenarios ‣ AgentLens: Visual Analysis for Agent Behaviors in LLM-based
    Autonomous Systems"), B) in the agent’s
    memory and follows IR’s timeline for observation. The user discovers that the
    message primarily spreads during IR’s conversations with others. Furthermore,
    the user finds the “party” memory highlight surfacing in the conversation between
    Ayesha Khan (AK) and John Smith (JS). Upon examining their dialogue ([Fig. 7](#S6.F7
    "In 6.1 Scenario A: Information Diffusion ‣ 6 Usage Scenarios ‣ AgentLens: Visual
    Analysis for Agent Behaviors in LLM-based Autonomous Systems"), $B_{1}$),
    during which IR extends an invitation to AK to participate in the party preparation.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '为了聚焦于派对的主题，用户在代理的记忆中搜索关键字“party”（[图7](#S6.F7 "在 6.1 场景 A: 信息扩散 ‣ 6 种使用场景 ‣
    AgentLens: 基于 LLM 的自主系统中的代理行为可视化")，并跟踪 IR 的时间线进行观察。用户发现消息主要在 IR 与其他人的对话中传播。此外，用户在
    Ayesha Khan (AK) 和 John Smith (JS) 的对话中发现了“party”记忆的高亮部分。在检查他们的对话时（[图7](#S6.F7
    "在 6.1 场景 A: 信息扩散 ‣ 6 种使用场景 ‣ AgentLens: 基于 LLM 的自主系统中的代理行为可视化")），IR 邀请 AK 参与派对准备。'
- en: With the assistance of AgentLens, the user successfully pinpoints an instance
    of information diffusion from a primary disseminator IR to a secondary one AK,
    then gradually diffusing towards other agents. From the Agent View, users discover
    that with the increase in both secondary propagators and the number of conversations
    related to “party”, the speed of “party” diffusion throughout the small town significantly
    accelerates.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在 AgentLens 的帮助下，用户成功地找到了从主要传播者 IR 到次要传播者 AK 的信息扩散实例，并逐渐扩散到其他代理。通过代理视图，用户发现，随着次要传播者的增加和与“party”相关的对话数量增加，“party”在小镇上的扩散速度显著加快。
- en: '6.2 Scenario B: Unexpected Social Patterns'
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 场景 B：意外的社交模式
- en: '![Refer to caption](img/56c67e002f2a8bc00148019dd7e97106.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/56c67e002f2a8bc00148019dd7e97106.png)'
- en: 'Figure 8: The second usage scenario presents how AgentLens aids users in explaining
    an unexpected agent behavior. (A) The user identifies some unexpected agent behaviors
    in Outline View, like an agent participating in information dissemination without
    engaging in a related conversation. Upon validation through Monitor View, the
    user determines that this pattern corresponds to the eavesdropping behavior of
    the agent. (B) The user uses Agent View to investigate the reasons behind the
    agent’s reluctance to participate in the discussion. Finally, the user discovers
    that a certain decision operation at the time point results in the behavior.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：第二种使用场景展示了 AgentLens 如何帮助用户解释意外的代理行为。(A) 用户在大纲视图中识别出一些意外的代理行为，比如代理参与信息传播但没有参与相关对话。通过监视视图验证后，用户确定这种模式对应于代理的窃听行为。(B)
    用户使用代理视图调查代理不愿意参与讨论的原因。最终，用户发现某个决策操作在特定时间点导致了这一行为。
- en: 'In this scenario, the user uncovers an unexpected pattern of information diffusion:
    eavesdropping.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，用户发现了信息传播的意外模式：窃听。
- en: 'During the observation of the “party” propagation process ([Fig. 8](#S6.F8
    "In 6.2 Scenario B: Unexpected Social Patterns ‣ 6 Usage Scenarios ‣ AgentLens:
    Visual Analysis for Agent Behaviors in LLM-based Autonomous Systems"), $A_{1}$).
    The user infers that SM comes to know about the “party” by eavesdropping on others’
    conversations.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '在观察“派对”传播过程的过程中([图 8](#S6.F8 "在 6.2 情景 B: 意外的社会模式 ‣ 6 使用场景 ‣ AgentLens: 基于
    LLM 的自主系统中代理行为的视觉分析")，$A_{1}$)，用户推断SM通过窃听他人的对话得知了“派对”。'
- en: 'The user seeks to investigate why SM does not join the conversation. The user
    expands the corresponding time point([Fig. 8](#S6.F8 "In 6.2 Scenario B: Unexpected
    Social Patterns ‣ 6 Usage Scenarios ‣ AgentLens: Visual Analysis for Agent Behaviors
    in LLM-based Autonomous Systems"), B) in the Agent
    View and identifies the Decision Operation that determines SM’s choice not to
    participate in the discussion. The prompt dispatches to the LLM incorporated agent
    settings pertaining to SM, like “SM is IR’s friend” and “Sam is not very familiar
    with GM”, in addition to the immediate observations made by SM, such as “IR and
    GM are presently engaged in a conversation” among other pieces of prompt input.
    It is the response returned by the LLM, based on the prompt, making the decision
    for SM’s subsequent action that he determines not to join the conversation.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '用户试图调查为何SM没有参与对话。用户扩展了相应的时间点([图 8](#S6.F8 "在 6.2 情景 B: 意外的社会模式 ‣ 6 使用场景 ‣ AgentLens:
    基于 LLM 的自主系统中代理行为的视觉分析")，B) 在代理视图中，并识别出决定SM不参与讨论的决策操作。提示被派发到与SM相关的LLM集成代理设置中，如“SM是IR的朋友”和“Sam对GM不太熟悉”，以及SM所做的即时观察，例如“IR和GM现在正在交谈”等提示输入。正是基于这些提示，LLM返回的响应决定了SM的后续行为，即他决定不加入对话。'
- en: 7 User Evaluation
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 用户评估
- en: We conducted a user study to evaluate the performance of AgentLens in enhancing
    LLMAS analysis. The study was specially designed to assess the comprehensive efficiency,
    effectiveness, and usability of the system. We also examine the analytical support
    provided by our system compared to a baseline system, which replicates the visual
    approach in existing LLMAS works.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了一项用户研究，以评估AgentLens在增强LLMAS分析中的表现。该研究特别设计用于评估系统的综合效率、有效性和可用性。我们还检查了与基线系统相比，我们的系统提供的分析支持，基线系统复制了现有LLMAS工作的视觉方法。
- en: 7.1 Participants
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1 参与者
- en: To prevent participants from having prior knowledge of the system before evaluation,
    we recruited 14 new participants (denoted as P1-P14) from a local university who
    had not been involved in the design requirements phase of this study, thereby
    enhancing the assessment validity and the results generalizability. These participants
    have diverse academic backgrounds, with most being undergraduate and graduate
    students from fields such as computer science, software engineering, and sociology.
    Some of them are developers with a high level of expertise in LLMAS, while others
    only have had direct interaction with LLMAS.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止参与者在评估前对系统有先验了解，我们从一所当地大学招募了14名新参与者（记作P1-P14），他们未参与本研究的设计需求阶段，从而提高了评估的有效性和结果的普遍性。这些参与者有着多样的学术背景，大多数是计算机科学、软件工程和社会学领域的本科生和研究生。其中一些是具有高水平LLMAS（多智能体系统）专业知识的开发人员，而其他人仅有直接接触LLMAS的经验。
- en: 7.2 Baseline Systems
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2 基线系统
- en: A baseline system³³3https://reverie.herokuapp.com/arXiv_Demo/# has been set
    up for direct comparison with our proposed system. Both the baseline system and
    our system utilize the log data generated by Reverie[[10](#bib.bib10)], which
    records the interactions and memory logs of agents within the system during the
    simulation process.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 已建立一个基线系统³³3https://reverie.herokuapp.com/arXiv_Demo/# 以便与我们提出的系统进行直接比较。基线系统和我们的系统都利用了由Reverie[[10](#bib.bib10)]生成的日志数据，这些数据记录了系统中代理在模拟过程中的互动和记忆日志。
- en: The baseline provides a view for replaying past events with plain text descriptions
    of agent settings and behaviors, which simulates a typical LLMAS panoramic visualization.
    Firstly, it features a monitoring interface that uses a flat map as the background.
    This allows users to replay and observe the agent positions and behavior descriptions
    at different time points through a timeline. Secondly, the system offers a textual
    representation of the current events for each agent, including the agent’s location,
    the action in progress, and the ongoing dialogue (if any). Finally, the system
    also provides a pure textual display of all events in each agent’s evolutionary
    process, encompassing the agent’s personality, complete memory records, and event
    sequences. These features enable users to understand the agent behaviors and status
    and delve into their evolutionary process.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 基线提供了一个回放过去事件的视图，使用普通文本描述代理设置和行为，这模拟了典型的LLMAS全景可视化。首先，它具有一个使用平面地图作为背景的监控界面。这使得用户能够通过时间轴回放并观察代理的位置和行为描述在不同时间点的情况。其次，系统为每个代理提供当前事件的文本表示，包括代理的位置、正在进行的动作和进行中的对话（如果有）。最后，系统还提供了一个纯文本显示，涵盖了每个代理的进化过程中的所有事件，包括代理的个性、完整的记忆记录和事件序列。这些功能使用户能够理解代理的行为和状态，并深入研究其进化过程。
- en: 7.3 Procedure and Tasks
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3 程序和任务
- en: 'Introduction (10 min): Initially, we provided a concise overview of the research,
    including the motivation and methodology. We then collected basic personal information
    from them, including their gender, age, and occupation. In addition, we obtained
    authorization to record their behaviors during the subsequent task analysis. Finally,
    we describe the characteristics of the individual views in both baseline and AgentLens
    in detail and demonstrate their practical use in a specific scenario.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 介绍（10分钟）：最初，我们提供了对研究的简要概述，包括动机和方法论。随后，我们收集了他们的基本个人信息，包括性别、年龄和职业。此外，我们获得了在随后的任务分析中记录他们行为的授权。最后，我们详细描述了基线和AgentLens中各个视图的特点，并展示了它们在特定场景中的实际应用。
- en: 'Task-based analysis (40 min): In this stage, participants were required to
    undertake 2 groups of analytical tasks (refer to [Figures 9](#S7.F9 "In 7.4.1
    Individual Behavior Analysis ‣ 7.4 Task Completion Analysis ‣ 7 User Evaluation
    ‣ AgentLens: Visual Analysis for Agent Behaviors in LLM-based Autonomous Systems")
    and [10](#S7.F10 "Fig. 10 ‣ 7.4.2 Emergent Phenomena Identification ‣ 7.4 Task
    Completion Analysis ‣ 7 User Evaluation ‣ AgentLens: Visual Analysis for Agent
    Behaviors in LLM-based Autonomous Systems")), designed to evaluate the system’s
    overall effectiveness and usability. Participants were required to fulfill tasks
    for each system, with the duration and accuracy of task completion being recorded.
    To obviate the potential for participants to replicate responses through memorization
    [[84](#bib.bib84)], the sequence in which the two systems were presented was randomized.
    Each task was uniquely tailored for both systems while ensuring an equivalent
    level of challenge.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '基于任务的分析（40 分钟）：在这一阶段，参与者需要完成 2 组分析任务（参见 [图 9](#S7.F9 "在 7.4.1 个体行为分析 ‣ 7.4
    任务完成分析 ‣ 7 用户评估 ‣ AgentLens: 基于 LLM 的自主系统中代理行为的可视化分析") 和 [10](#S7.F10 "图 10 ‣
    7.4.2 新兴现象识别 ‣ 7.4 任务完成分析 ‣ 7 用户评估 ‣ AgentLens: 基于 LLM 的自主系统中代理行为的可视化分析")），旨在评估系统的整体有效性和可用性。参与者需要完成每个系统的任务，记录任务的持续时间和准确性。为了避免参与者通过记忆重复回答
    [[84](#bib.bib84)]，我们随机化了两个系统的展示顺序。每个任务针对两个系统进行了独特的定制，同时确保了相同的挑战水平。'
- en: 'Semi-structured interview (30 min): To enhance the evaluation of the method
    and interface efficacy, we utilized the five-point Likert scale in an 8-item questionnaire.
    Additionally, we employed the System Usability Scale (SUS)[[85](#bib.bib85)] to
    evaluate the usability of AgentLens. Participants were asked to rate each question
    from 1 (strongly disagree) to 5 (strongly agree) to gauge their agreement levels.
    During the questionnaire process, we encouraged participants to speak freely to
    uncover the reasoning behind their ratings.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 半结构化访谈（30 分钟）：为了增强对方法和界面有效性的评估，我们使用了 8 项问卷中的五级李克特量表。此外，我们采用了系统可用性量表（SUS）[[85](#bib.bib85)]
    来评估 AgentLens 的可用性。参与者被要求对每个问题进行 1（强烈不同意）到 5（强烈同意）的评分，以衡量他们的同意程度。在问卷过程中，我们鼓励参与者畅所欲言，以揭示他们评分背后的理由。
- en: 7.4 Task Completion Analysis
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4 任务完成分析
- en: 'For the task-based analysis, we conducted a quantitative comparison between
    AgentLensnd the baseline, focusing on accuracy and task completion time. We developed
    two distinct groups of evaluation tasks to assess the efficacy of 2 systems for
    the analysis of agent behaviors ([Fig. 9](#S7.F9 "In 7.4.1 Individual Behavior
    Analysis ‣ 7.4 Task Completion Analysis ‣ 7 User Evaluation ‣ AgentLens: Visual
    Analysis for Agent Behaviors in LLM-based Autonomous Systems")) and the identification
    of emergent phenomena arising from such behaviors ([Fig. 10](#S7.F10 "In 7.4.2
    Emergent Phenomena Identification ‣ 7.4 Task Completion Analysis ‣ 7 User Evaluation
    ‣ AgentLens: Visual Analysis for Agent Behaviors in LLM-based Autonomous Systems")).'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '在基于任务的分析中，我们对 AgentLens 和基线进行了一项定量比较，重点关注准确性和任务完成时间。我们开发了两个不同的评估任务组，以评估这两种系统在分析代理行为（[图
    9](#S7.F9 "在 7.4.1 个体行为分析 ‣ 7.4 任务完成分析 ‣ 7 用户评估 ‣ AgentLens: 基于 LLM 的自主系统中代理行为的可视化分析")）和识别这些行为中出现的新兴现象（[图
    10](#S7.F10 "在 7.4.2 新兴现象识别 ‣ 7.4 任务完成分析 ‣ 7 用户评估 ‣ AgentLens: 基于 LLM 的自主系统中代理行为的可视化分析")）方面的有效性。'
- en: 7.4.1 Individual Behavior Analysis
  id: totrans-133
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.4.1 个体行为分析
- en: 'T1 - T6 in [Fig. 9](#S7.F9 "In 7.4.1 Individual Behavior Analysis ‣ 7.4 Task
    Completion Analysis ‣ 7 User Evaluation ‣ AgentLens: Visual Analysis for Agent
    Behaviors in LLM-based Autonomous Systems") are designed with elicit concise answers,
    requiring participants to rapidly comprehend the fundamental characteristics and
    behaviors of agents. Based on the analytical target, we categorize this set of
    tasks into 3 classifications. Participants exhibit varying levels of accuracy
    and time expenditure across tasks, however, there was a notable improvement in
    task accuracy ($p=1.2e-3$) with AgentLens.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 9](#S7.F9 "在 7.4.1 个体行为分析 ‣ 7.4 任务完成分析 ‣ 7 用户评估 ‣ AgentLens: 基于 LLM 的自主系统中代理行为的可视化分析")
    中的 T1 - T6 设计用于引出简洁的回答，要求参与者迅速理解代理的基本特征和行为。根据分析目标，我们将这一组任务分为 3 类。参与者在不同任务中的准确性和时间花费表现出不同的水平，但使用
    AgentLens 后任务准确性显著提高（$p=1.2e-3$）。'
- en: '![Refer to caption](img/0b0b1302893071c8d7c689a5f8eb1996.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0b0b1302893071c8d7c689a5f8eb1996.png)'
- en: 'Figure 9: Statistical result of the accuracy and time consumption for participants
    completing individual behavior analysis tasks using both AgentLens and the baseline
    system.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：使用 AgentLens 和基线系统完成单个行为分析任务的参与者的准确性和时间消耗的统计结果。
- en: 'Single-agent analysis (T1 - T2): This set of tasks focuses on the system’s
    enhancement of simple information analysis about individual agents. Without compromising
    task accuracy, AgentLens decreased time consumption by 33% for T1 ($\mu_{AgentLens}=8.02,\mu_{baseline}=12.03$)
    compared to the baseline system. The visual representation of agent characteristics
    in the Agent View eliminates the need for search operations in T1\. Furthermore,
    the event summarization method helps participants quickly identify agent behaviors,
    eliminating the need to sift through complex log records to complete T2.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 单智能体分析 (T1 - T2)：这一组任务侧重于系统在增强对单个智能体简单信息分析方面的表现。在不影响任务准确性的情况下，AgentLens 将 T1
    的时间消耗减少了 33%（$\mu_{AgentLens}=8.02,\mu_{baseline}=12.03$），与基线系统相比。Agent View 中的智能体特征可视化消除了在
    T1 中进行搜索操作的需要。此外，事件总结方法帮助参与者快速识别智能体行为，消除了在完成 T2 时需筛选复杂日志记录的需要。
- en: 'Multi-agent analysis (T3 - T4): This set of tasks demonstrates the system’s
    effect in assisting participants with the analysis of interactions between agents.
    It is noteworthy that one participant failed in both two tasks using the baseline
    system due to his incorrect agent selection. AgentLens reduced time consumption
    by 78.3% for T3 ($\mu_{AgentLens}=20.00,\mu_{baseline}=92.20$). The visual encoding
    in AgentLens, particularly in the Outline View, allowed participants to quickly
    derive answers by observing agent interactions including dialogues and cohabitation
    instances.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 多智能体分析 (T3 - T4)：这一组任务展示了系统在协助参与者分析智能体之间交互的效果。值得注意的是，有一名参与者由于选择错误的智能体，在使用基线系统进行的两个任务中均未成功。AgentLens
    将 T3 的时间消耗减少了 78.3%（$\mu_{AgentLens}=20.00,\mu_{baseline}=92.20$）。AgentLens 中的视觉编码，特别是在大纲视图中，使参与者能够通过观察智能体的交互，包括对话和共生实例，快速得出答案。
- en: 'Behavior Cause analysis (T5 - T6): In this set of tasks, AgentLens demonstrated
    marked improvements over the baseline in facilitating the exploration of the cause
    of agent behaviors. While a part of the participants quickly obtained answers
    using the baseline in T5, AgentLens still provided a 39.4% improvement with the
    topic search feature ($\mu_{AgentLens}=17.83,\mu_{baseline}=29.42$).'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 行为原因分析 (T5 - T6)：在这一组任务中，AgentLens 在促进探索智能体行为原因方面表现出明显的改进。虽然部分参与者在 T5 中使用基线系统迅速获得了答案，但
    AgentLens 仍通过主题搜索功能提供了 39.4% 的改进（$\mu_{AgentLens}=17.83,\mu_{baseline}=29.42$）。
- en: 7.4.2 Emergent Phenomena Identification
  id: totrans-140
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.4.2 突现现象识别
- en: 'T7-T9 in [Fig. 10](#S7.F10 "In 7.4.2 Emergent Phenomena Identification ‣ 7.4
    Task Completion Analysis ‣ 7 User Evaluation ‣ AgentLens: Visual Analysis for
    Agent Behaviors in LLM-based Autonomous Systems") are designed to correspond to
    three categories of emergent phenomena arising from agent autonomy, which is not
    explicitly pre-programmed in LLMAS. These tasks are more complex for the participants,
    requiring back-and-forth exploration and analysis through multiple steps. We invited
    evaluators to assess the accuracy of the participant’s responses. Concurrently,
    we observe that AgentLens demonstrates capabilities in complex analytical tasks
    that the traditional baseline failed to achieve, particularly in the exploration
    of emergent behaviors arising from agent autonomy.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 10](#S7.F10 "在 7.4.2 突现现象识别 ‣ 7.4 任务完成分析 ‣ 7 用户评价 ‣ AgentLens：基于 LLM 的自主系统中智能体行为的视觉分析")
    中的 T7-T9 旨在对应智能体自主产生的三类突现现象，这些现象在 LLMAS 中并未明确预编程。这些任务对参与者来说更为复杂，需要通过多个步骤的反复探索和分析。我们邀请评估者评估参与者响应的准确性。同时，我们观察到
    AgentLens 在传统基线无法实现的复杂分析任务中展示了能力，特别是在探索智能体自主产生的突现行为方面。'
- en: '![Refer to caption](img/43ab8228481412c3dfc0878c7373fcdf.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/43ab8228481412c3dfc0878c7373fcdf.png)'
- en: 'Figure 10: Statistical result of the accuracy and time consumption for emergent
    phenomena identification tasks using both AgentLens and the baseline system.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：使用 AgentLens 和基线系统进行突现现象识别任务的准确性和时间消耗的统计结果。
- en: 'Topic propagation (T7): Participants are tasked with identifying the propagation
    path of a specific topic, such as “a Valentine’s Day party will be held” or “someone
    is preparing the selection for mayor”. Nearly all participants consider the task
    to be impossible while utilizing the baseline, as “this task is akin to searching
    for a needle in a haystack” (P11). When utilizing AgentLens, the majority of participants
    swiftly opted for the Agent Memory Search within the Outline View to conduct searches
    on the propagated topics. Leveraging the representation of Agent Interaction Analysis
    within the view, participants could easily explore the propagation paths. Although
    the propagation path participants were asked to identify has multiple branches
    and complex scenarios, 9 participants completed the task using AgentLens.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '**话题传播**（T7）：参与者需要识别特定话题的传播路径，如“将举办情人节派对”或“有人正在准备市长候选人的选择”。几乎所有参与者在使用基线系统时认为这一任务是不可能完成的，因为“这个任务就像在大海捞针”
    （P11）。在使用**AgentLens**时，大多数参与者迅速选择了**Outline View**中的**Agent Memory Search**进行传播话题的搜索。利用视图中的**Agent
    Interaction Analysis**表示，参与者可以轻松探索传播路径。尽管参与者被要求识别的传播路径有多个分支和复杂情境，9名参与者使用**AgentLens**完成了这一任务。'
- en: 'Agent congregation (T8): Participants are required to identify a congregation
    phenomenon, defined as more than three agents engaging in the same behavior at
    the same location, and participants should explain the reason behind it. While
    using the baseline, participants were compelled to conduct extended observations
    and iterative replays of the recorded video. Despite locating the participants
    of the aggregation, they remained unable to ascertain the underlying causes of
    the phenomena. Through the interactivity among the three views of AgentLens, particularly
    the design of Monitor View and Outline View, participants were able to rapidly
    detect aggregation phenomena. Coupled with the method of behavior summarization,
    9 participants successfully provided explanations for the aggregations.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '**代理人聚集**（T8）：参与者需要识别一种聚集现象，定义为超过三个代理人在同一地点进行相同行为，参与者应解释其原因。在使用基线系统时，参与者被迫进行长时间的观察和迭代回放录制的视频。尽管找到了聚集的参与者，他们仍然无法确定现象的根本原因。通过**AgentLens**的三个视图之间的互动，特别是**Monitor
    View**和**Outline View**的设计，参与者能够快速检测到聚集现象。结合行为总结的方法，9名参与者成功地为这些聚集现象提供了解释。'
- en: 'Unexpected behavior (T9): Participants were tasked with identifying and rationalizing
    unexpected agent behaviors across two systems. When using the baseline system,
    they noted that agent behaviors appeared uniformly logical and coherent. Additionally,
    the requisite alternation between observing multiple agents hindered their analytical
    process, thereby increasing the difficulty of detecting unexpected phenomena.
    With the assistance of AgentLens, this task became more manageable. P5 identified
    through Outline View that ”agent RP did not leave his room throughout the entire
    day.” He traced the cause using Agent View and discovered that the agent had received
    a plan that did not require leaving the house from LLM during the planning phase
    for that day. Another participant P8 noticed in Agent View that agent TT was able
    to observe the activities of agent IR in the adjacent room, and this observation
    influenced TT’s subsequent decisions. The user suggested that this phenomenon
    should be addressed in the LLMAS, as in human society, individuals do not possess
    the ability to see through walls.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '**意外行为**（T9）：参与者被要求在两个系统中识别和解释意外的代理人行为。在使用基线系统时，他们注意到代理人的行为看起来逻辑统一且连贯。此外，观察多个代理人所需的交替行为阻碍了他们的分析过程，从而增加了检测意外现象的难度。在**AgentLens**的帮助下，这一任务变得更为可控。P5通过**Outline
    View**识别出“代理人RP在整个一天都没有离开他的房间。”他通过**Agent View**追踪原因，发现代理人在当天的规划阶段从LLM那里收到了一份不需要离开家的计划。另一名参与者P8在**Agent
    View**中注意到代理人TT能够观察到相邻房间中的代理人IR的活动，这一观察影响了TT后续的决策。用户建议应在LLMAS中解决这一现象，因为在人类社会中，个体没有透视墙壁的能力。'
- en: 7.5 Semi-structured Interview Analysis
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.5 **半结构化访谈分析**
- en: 'We posed 8 interview questions in [Fig. 11](#S7.F11 "In 7.5 Semi-structured
    Interview Analysis ‣ 7 User Evaluation ‣ AgentLens: Visual Analysis for Agent
    Behaviors in LLM-based Autonomous Systems")) and a SUS questionnaire([Fig. 12](#S7.F12
    "In 7.5.3 Usability ‣ 7.5 Semi-structured Interview Analysis ‣ 7 User Evaluation
    ‣ AgentLens: Visual Analysis for Agent Behaviors in LLM-based Autonomous Systems"))
    to participants. Evaluating the results of the questionnaire with feedback obtained
    during the interview, we reported the performance of AgentLens including its effectiveness
    and usability, offering insights into its practical application.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们向参与者提出了8个面试问题，见[图11](#S7.F11 "在7.5半结构化面试分析 ‣ 7用户评价 ‣ AgentLens：LLM基础的自主系统中代理行为的视觉分析")以及一个SUS问卷（见[图12](#S7.F12
    "在7.5.3可用性 ‣ 7.5半结构化面试分析 ‣ 7用户评价 ‣ AgentLens：LLM基础的自主系统中代理行为的视觉分析")）。通过评估问卷结果和面试中获得的反馈，我们报告了AgentLens的性能，包括其有效性和可用性，提供了对其实际应用的见解。
- en: '![Refer to caption](img/fa2aee7ffb0a69cc65610e15842f987d.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/fa2aee7ffb0a69cc65610e15842f987d.png)'
- en: 'Figure 11: The questionnaire with results showing the efficacy of our method
    and interfaces.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：问卷及结果展示了我们方法和界面的效果。
- en: 7.5.1 Pipeline Effectiveness
  id: totrans-151
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.5.1 流程有效性
- en: All participants agreed that the event summary is informative (Q1) and helpful.
    P10 commented, “The summaries are quite accurate. I can quickly locate the events
    and understand the evolution of an agent throughout the day with the help of the
    story-like subheadings.” P1 felt impressed with the way of summarizing the agent’s
    status, “like having an agent helping me monitor this LLMAS.”
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 所有参与者一致认为，活动总结信息丰富（Q1）且有帮助。P10评论道：“总结非常准确。在故事式小标题的帮助下，我可以快速找到事件并理解一个代理在一天中的演变。”P1对总结代理状态的方式印象深刻，表示“就像有一个代理帮助我监控这个LLMAS”。
- en: Most participants agreed that the results of the cause trace met their expectations
    (Q2). They are willing to utilize the traced events to help analyze their interested
    events. For instance, P3 intended to incorporate the agent characteristics into
    the cause trace process. P5 pointed out that the cause trace served to “unveil
    the black box of agent behavior.”.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数参与者同意原因追踪的结果符合他们的期望（Q2）。他们愿意利用追踪的事件来帮助分析他们感兴趣的事件。例如，P3打算将代理特性纳入原因追踪过程。P5指出，原因追踪有助于“揭示代理行为的黑箱”。
- en: The hierarchical structure received unanimous endorsement from all participants
    (Q3). They all admitted that the hierarchical structure elucidated the level at
    which they could retrieve information. Especially in the analysis of complex phenomena,
    the behavior hierarchical structure can “effectively reduce information density”(P6)
    and “help me quickly focus on key phenomena”(P10). Nonetheless, P12, who was relatively
    inexperienced with the LLMAS, expressed a need for more “user-oriented guidance”.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 所有参与者一致赞同层级结构（Q3）。他们都承认，层级结构阐明了他们可以在什么层次上检索信息。特别是在分析复杂现象时，行为层级结构可以“有效减少信息密度”（P6）并“帮助我快速聚焦于关键现象”（P10）。尽管如此，P12，作为对LLMAS较少经验的参与者，表示需要更多的“面向用户的指导”。
- en: 7.5.2 Visual Effectiveness
  id: totrans-155
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.5.2 视觉有效性
- en: The Outline View was appreciated by the participants for agents behavior analysis
    (Q4). It helps participants circumvent the risk of “getting lost in the complex
    and chaotic agent lines” (P1) by summarizing and visualizing the agent’s status.
    The interactive design, such as the click-to-highlight and view-details features,
    is “remarkably user-friendly and intuitive” (P11). In addition, the encoding of
    interactions among agents also received positive feedback from users (Q5). The
    gray box, which intertwines two lines to represent agent dialogues, “stands out
    right away” (P2). Some participants (P5, P7) indicated that they were accustomed
    to first spotting interesting agent dialogues in the relatively compact view,
    then zooming in to delve into more details. P7, who completed the task of identifying
    congregation phenomenon(T8) expeditiously, attributes the success to ”the visualization
    is trying to aggregate the curves of agents who are interacting with each other.”
    P9 commented, “If I can dynamically adjust the positions of the agents in the
    view, the layout can better match my expectation.”
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 大纲视图因其对代理行为分析的帮助（Q4）而受到参与者的好评。它通过总结和可视化代理的状态，帮助参与者避免了“在复杂和混乱的代理线路中迷失方向”（P1）的风险。互动设计，如点击高亮和查看详细信息功能，“极其用户友好且直观”（P11）。此外，代理间交互的编码也获得了用户的积极反馈（Q5）。灰色框将两条线路交织以表示代理对话，“立刻引人注目”（P2）。一些参与者（P5，P7）表示，他们习惯于首先在相对紧凑的视图中找到有趣的代理对话，然后放大以深入了解更多细节。P7迅速完成了识别集聚现象（T8）的任务，将成功归功于“可视化试图聚合彼此交互的代理曲线。”
    P9评论道，“如果我能动态调整视图中代理的位置，布局可以更好地符合我的期望。”
- en: The Monitor View was found to be useful for validating the observation (Q6).
    Several participants indicated that after observing the Monitor View, they gained
    more confidence in the results of their analysis. P10 mentioned, “The monitor
    screen adjusts as I shift my focus in different views, kind of like video software,
    but it offers much more details than regular video playback.” P10 commended the
    interaction of this view in relation to the other two especially in complex tasks,
    “This interactive responsiveness is beneficial during my iterative analysis process.”
    P5 suggested that the Monitor View could be more beneficial if it could “display
    the location information of other unfocused agents”.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 监视器视图被发现对验证观察结果（Q6）非常有用。几位参与者表示，在观察了监视器视图后，他们对分析结果更加有信心。P10提到，“监视器屏幕会随着我在不同视图中调整焦点而变化，有点像视频软件，但它提供的细节比普通视频播放要多得多。”
    P10赞扬了这个视图与其他两个视图的互动，尤其是在复杂任务中，“这种互动响应在我的迭代分析过程中非常有帮助。” P5建议，如果监视器视图能够“显示其他未聚焦代理的位置信息”，会更加有益。
- en: The Agent View provides strong support for participants to analyze individual
    agent characteristics (Q7) and the causal relationships between agent behaviors
    (Q8). When observing agents of interest, they can “quickly understand the agent’s
    personality and style of action” (P1). P6 said, “The retrospective analysis is
    intuitive, but the individual timeline is too long. It would be better if I could
    explore the causes without having to drag the view around.” P4 praised the minimap
    in the Agent View, “When I was trying to understand agent behaviors, I love using
    the minimap’s navigation. It helped me find the causal links fast with those cool
    summary emojis.” P13 commented, “Developers should think about adding the agent
    view to their projects. Without it, agent behaviors might not seem convincing.”
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 代理视图为参与者分析个别代理特征（Q7）和代理行为之间的因果关系（Q8）提供了强有力的支持。在观察感兴趣的代理时，他们可以“快速了解代理的个性和行动风格”（P1）。P6说，“回顾分析是直观的，但个别时间轴太长。如果我能够探索原因而不必拖动视图，那就更好了。”
    P4赞扬了代理视图中的小地图，“当我试图理解代理行为时，我喜欢使用小地图的导航。它帮助我快速找到因果关系链接，并用那些酷炫的总结表情。” P13评论道，“开发者应该考虑将代理视图添加到他们的项目中。没有它，代理行为可能看起来不那么令人信服。”
- en: 7.5.3 Usability
  id: totrans-159
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.5.3 可用性
- en: '![Refer to caption](img/9fc025516d391e712a6fccebc9687649.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/9fc025516d391e712a6fccebc9687649.png)'
- en: 'Figure 12: The SUS questionnaire with results showing the usability of AgentLens.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图12：展示了AgentLens可用性的SUS问卷结果。
- en: We employed the SUS questionnaire to assess the system usability, thereby reporting
    users’ cognitive load with AgentLens. Several developers among the participants
    conveyed not only their intent to use AgentLens in the future but also to consider
    its integration within their LLMAS development, which has significantly encouraged
    us.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们采用SUS问卷来评估系统的可用性，从而报告用户在使用AgentLens时的认知负荷。参与者中的一些开发者不仅表达了未来继续使用AgentLens的意图，还考虑将其整合到他们的LLMAS开发中，这大大鼓舞了我们。
- en: 'Overall, participants provided positive comments on the usability. P9 lauded
    the workflow of AgentLens, “I thoroughly enjoyed the freedom of exploration the
    system facilitated.”. P13 noted, “The interaction is very fluid”, but revealed
    a longing for automated assistance during complex analytical tasks: “It would
    be perfect if the system could understand the type of task I want to analyze from
    just a few of my clicks.” Moreover, participants expressed their confidence and
    enjoyment when using AgentLens. However, several participants indicated that the
    system necessitates a measure of preliminary technical knowledge, despite acknowledgment
    from P2 that “this is principally due to the intrinsic complexity of LLMAS itself.”'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，参与者对可用性给予了积极评价。P9称赞了AgentLens的工作流程：“我非常喜欢系统提供的探索自由。” P13指出：“交互非常流畅”，但透露了在复杂分析任务中对自动化辅助的渴望：“如果系统能通过我几次点击就理解我想分析的任务类型，那就太完美了。”此外，参与者在使用AgentLens时表现出信心和愉悦。然而，一些参与者指出系统需要一定的初步技术知识，尽管P2承认“这主要是由于LLMAS本身的复杂性”。
- en: 'Ultimately, we achieved an average score of 67.5 on the SUS questionnaire(refer
    to [Fig. 12](#S7.F12 "In 7.5.3 Usability ‣ 7.5 Semi-structured Interview Analysis
    ‣ 7 User Evaluation ‣ AgentLens: Visual Analysis for Agent Behaviors in LLM-based
    Autonomous Systems")), which we find exhilarating. However, it also serves as
    a reminder of the necessity for future optimization.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们在SUS问卷上取得了平均分67.5（参见[图12](#S7.F12 "在7.5.3 可用性 ‣ 7.5 半结构化访谈分析 ‣ 7 用户评估 ‣
    AgentLens：用于LLM基础自主系统中的代理行为的视觉分析")），对此我们感到振奋。然而，这也提醒我们需要进行未来的优化。
- en: 8 Discussion
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 讨论
- en: In this section, we commence by encapsulating the lessons collected from the
    user feedback, including providing comparisons within an agent and enabling modifications
    for system configurations. Subsequently, we deliberate on the generalizability,
    as well as the limitations and future work.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们首先总结了从用户反馈中收集的经验教训，包括提供代理内的比较和支持系统配置的修改。随后，我们讨论了普遍性、局限性及未来工作。
- en: 8.1 Lessons Learned
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1 经验教训
- en: Providing comparison within an agent. During the evaluation process, we recorded
    some specific interaction patterns among the users, although they did not actively
    mention them in the interview. Some users frequently analyzed the behaviors of
    a single agent across various temporal intervals. For instance, they compared
    the behaviors of an agent at 8 a.m. on February 13 with those at the same time
    on February 14\. To facilitate this, they typically delved into the Outline View
    to explore the events associated with the agent at these two distinct time points.
    Observing disparate agent behaviors across separate days, users inferred the existence
    of certain agent behavior patterns. This discovery inspires us to further investigate
    strategies for visually “folding” the agent’s timeline, such as overlaying two
    periods of the timeline, thereby aiding users in rapidly comparing and encapsulating
    the agent’s behavior patterns.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在代理内提供比较。在评估过程中，我们记录了一些用户的具体互动模式，尽管他们在访谈中并未主动提及这些模式。一些用户频繁地分析同一代理在不同时间间隔的行为。例如，他们比较了2月13日早上8点的代理行为与2月14日同一时间的行为。为此，他们通常会深入探讨大纲视图，以查看这些两个不同时间点与代理相关的事件。观察到不同日期的代理行为，用户推测存在某些代理行为模式。这一发现激励我们进一步研究可视化“折叠”代理时间线的策略，例如叠加两个时间段的时间线，从而帮助用户快速比较和概括代理的行为模式。
- en: 'Enabling modifications for system configurations. Participants appreciated
    the aid provided by the novel behavior summarization method proposed in our study,
    which effectively mitigates information overload. Nevertheless, some users demonstrated
    an interest in understanding how these summaries are generated. They endorsed
    the summarization method after we clarified the details, as in [Fig. 5](#S4.F5
    "In 4.2 Behavior Summarization ‣ 4 Behavior Structure Establishment ‣ AgentLens:
    Visual Analysis for Agent Behaviors in LLM-based Autonomous Systems"). However,
    they still gave specific requirements, such as customizing the source of the summary
    contents. For example, one participant exhibited indifference towards the agent’s
    location information. Such feedback motivates us to enable users to tailor the
    extraction pipeline in future research, thereby enhancing the usability of the
    exploratory analysis in a user-centric manner.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '允许对系统配置进行修改。参与者欣赏我们研究中提出的新行为总结方法，该方法有效地减轻了信息过载。然而，一些用户表示希望了解这些总结是如何生成的。在我们阐明细节后，他们支持了这一总结方法，如[图5](#S4.F5
    "在4.2行为总结 ‣ 4行为结构建立 ‣ AgentLens: 适用于基于LLM的自主系统的代理行为可视化分析")。不过，他们仍然提出了具体要求，例如自定义总结内容的来源。例如，一名参与者对代理的位置信息表现出冷漠。这种反馈促使我们在未来的研究中使用户能够定制提取管道，从而以用户为中心提高探索性分析的可用性。'
- en: 8.2 Generalizability
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2 泛化能力
- en: Our work builds upon the existing LLMAS, designed for the surveillance and analysis
    of agent behaviors. While we conduct our research based on Reverie, it can be
    seamlessly integrated into other LLMAS analysis processes. Moreover, the key components
    of our system, such as the Outline View and Agent View, are decoupled from the
    LLMAS implementations. The Monitor View is a representation of the replay monitor
    ubiquitous in most LLMAS. Developers can easily provide their own monitoring snapshots
    to populate this view. Therefore, our work is general to various LLMAS and can
    be used directly by developers in their LLMAS.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的工作建立在现有的LLMAS基础上，旨在监控和分析代理行为。虽然我们的研究是基于**Reverie**进行的，但它可以无缝集成到其他LLMAS分析过程中。此外，我们系统的关键组件，如**大纲视图**和**代理视图**，与LLMAS实现解耦。**监控视图**是大多数LLMAS中普遍存在的回放监视器的表现形式。开发者可以轻松提供自己的监控快照以填充此视图。因此，我们的工作具有广泛的适用性，可以直接被开发者在其LLMAS中使用。
- en: Our system’s capabilities extend beyond LLMAS analysis and can be applied to
    a wide range of applications, such as the analysis of multi-person communities
    and the development of open-world games. For the analysis of multi-person communities,
    the Outline View and Monitor View can assist in simultaneously examining numerous
    actions on multiple subject timelines. This enables analysts to rapidly comprehend
    the main behaviors of different entities and their interactions. Within the realm
    of open-world games, the incorporation of the Outline View can aid players in
    exploring non-player characters (NPC) behaviors in an immersive manner. Game developers
    can also utilize the Agent View to analyze and optimize the NPCs in the development
    stages, fostering the creation of more intelligent NPCs.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们系统的功能不仅限于LLMAS分析，还可以应用于广泛的领域，例如多人社区分析和开放世界游戏开发。对于多人社区分析，**大纲视图**和**监控视图**可以帮助同时检查多个主题时间线上的众多动作。这使得分析师能够快速理解不同实体的主要行为及其互动。在开放世界游戏的领域中，**大纲视图**的加入可以帮助玩家以沉浸式方式探索非玩家角色（NPC）的行为。游戏开发者还可以利用**代理视图**在开发阶段分析和优化NPC，促进更智能NPC的创造。
- en: 8.3 Limitations and Future Work
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3 限制与未来工作
- en: Despite the encouraging performance of AgentLens, there are several limitations
    and potential areas for further research.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管AgentLens的表现令人鼓舞，但仍存在若干限制和潜在的进一步研究领域。
- en: Provide a more flexible interface. The current layout of the agent line and
    position block in the Outline View is pre-computed. Despite considerable efforts
    to minimize the crossover of lines, it remains difficult to avoid, particularly
    as the number of agents and the evolutionary timespan of LLMAS increase. One of
    our future tasks is to provide a more flexible layout for the Outline View, automatically
    reorganizing the view based on the user’s interest regarding agent events.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 提供更灵活的界面。当前大纲视图中代理线和位置块的布局是预计算的。尽管做了大量努力以最小化线条交叉，但随着代理数量和 LLMAS 的演变时间跨度增加，这仍然难以避免。我们未来的任务之一是为大纲视图提供更灵活的布局，自动根据用户对代理事件的兴趣重新组织视图。
- en: Allow users to modify pre-configured settings. AgentLens introduces a set of
    pre-configured settings for users, such as the granularity of Timeline Segmentation
    and the similarity threshold for Cause Trace. These configurations optimize the
    exploration experience for users, making better trade-offs between the intricate
    nature of the information and its succinct presentation. Nonetheless, some users
    expressed a desire to modify these presets during the analysis process to facilitate
    more flexible exploration. To accommodate these needs, we plan to incorporate
    a customizable preset panel for users in our system.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 允许用户修改预配置的设置。AgentLens 引入了一组为用户预配置的设置，例如时间轴分段的粒度和因果追踪的相似度阈值。这些配置优化了用户的探索体验，在信息的复杂性与简洁呈现之间做出了更好的权衡。然而，一些用户在分析过程中表示希望修改这些预设，以便进行更灵活的探索。为满足这些需求，我们计划在系统中加入一个可自定义的预设面板。
- en: Support interactive exploration among different agent execution strategies.
    In this work, we focus on facilitating users’ exploration and analysis of the
    LLMAS operational process. However, this process is significantly influenced by
    agent execution strategies like planning methods and memory mechanisms. For example,
    the agent may choose to first make a high-level plan to divide tasks into several
    sub-tasks that can be completed in different orders, or choose to adopt a depth-first
    strategy that adaptively changes its target based on the incoming information.
    While the design of an effective agent planning strategy is attracting an increasing
    amount of research attention [[17](#bib.bib17), [86](#bib.bib86), [87](#bib.bib87),
    [88](#bib.bib88)], how to interactively analyze the effect of different planning
    strategies in LLMAS is still unexplored. Moreover, analyzing the influence of
    agent memory mechanisms on the agent execution process is an area of considerable
    interest. While currently the agent memory mechanisms are usually hard-coded in
    the LLMAS program, allowing users to interactively modify the agent’s memory content
    or recall strategies and visually examine its downstream effects could be crucial
    for better understanding and optimizing LLMAS.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 支持不同代理执行策略之间的互动探索。在这项工作中，我们重点关注促进用户对 LLMAS 操作过程的探索和分析。然而，这一过程受到代理执行策略的显著影响，例如规划方法和记忆机制。例如，代理可能选择首先制定高层次的计划，将任务分解为可以以不同顺序完成的几个子任务，或选择采用深度优先策略，根据接收到的信息自适应地改变目标。虽然有效的代理规划策略设计正引起越来越多的研究关注[[17](#bib.bib17),
    [86](#bib.bib86), [87](#bib.bib87), [88](#bib.bib88)]，但如何互动地分析不同规划策略在 LLMAS 中的效果仍未探索。此外，分析代理记忆机制对代理执行过程的影响也是一个颇具兴趣的领域。尽管当前代理记忆机制通常在
    LLMAS 程序中是硬编码的，但允许用户互动地修改代理的记忆内容或召回策略，并可视化其下游影响，可能对更好地理解和优化 LLMAS 至关重要。
- en: Extend to multimodal LLMAS. Text-based interaction has been widely adopted in
    most existing LLMAS [[16](#bib.bib16), [10](#bib.bib10), [12](#bib.bib12)] in
    which agents are predicated on textual perception and decision-making. Even embodied
    agents [[19](#bib.bib19), [20](#bib.bib20)] typically transmute the perceived
    multimodal data like imagery and auditory inputs into a textual format for later
    processing. However, with the popularity of multimodal LLMs[[6](#bib.bib6), [89](#bib.bib89)],
    the future may see the emergence of LLMAS in which agents genuinely perceive,
    think, and act based on multimodal data. Future work can explore how the agents
    interact with multimodal data (e.g., image interpretation [[90](#bib.bib90)] and
    creation [[91](#bib.bib91)]) in this authentic multimodal LLMAS.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展到多模态LLMAS。基于文本的交互在大多数现有的LLMAS中已被广泛采用[[16](#bib.bib16), [10](#bib.bib10), [12](#bib.bib12)]，其中代理基于文本感知和决策。即使是具身代理[[19](#bib.bib19),
    [20](#bib.bib20)]，通常也会将感知到的多模态数据如图像和听觉输入转化为文本格式以便后续处理。然而，随着多模态LLMs[[6](#bib.bib6),
    [89](#bib.bib89)]的流行，未来可能会出现那些真正基于多模态数据感知、思考和行动的LLMAS。未来的工作可以探讨代理如何在这种真实的多模态LLMAS中与多模态数据（例如，图像解读[[90](#bib.bib90)]和创作[[91](#bib.bib91)]）互动。
- en: 9 Conclusion
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9 结论
- en: This work presents a visualization approach for LLMAS, addressing the challenge
    of analyzing complex agent behaviors during LLMAS evolution. We introduce a general
    pipeline that establishes a hierarchical behavior structure from the raw execution
    events of LLMAS, including a behavior summarization algorithm and a cause-tracing
    method. Our system, AgentLens, offers an intuitive and hierarchical representation
    of the evolution of multiple agents, enabling users to interactively investigate
    behavior details and causes. Through two usage scenarios and a user study, we
    have demonstrated the performance of our pipeline and visual designs.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作提出了一种LLMAS的可视化方法，解决了在LLMAS演化过程中分析复杂代理行为的挑战。我们引入了一个通用的流程，该流程从LLMAS的原始执行事件中建立一个分层行为结构，包括一个行为总结算法和一个原因追踪方法。我们的系统AgentLens提供了多个代理演变的直观且层次化的表示，使用户能够交互式地调查行为细节和原因。通过两个使用场景和一项用户研究，我们展示了我们的流程和视觉设计的性能。
- en: Acknowledgments
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: We would like to thank Ke Wang and Minfeng Zhu for their kind help. We also
    would like to thank the anonymous reviewers for their insightful comments. This
    paper is supported by the National Natural Science Foundation of China (62132017,
    62302435), Zhejiang Provincial Natural Science Foundation of China (LD24F020011),
    and “Pioneer” and “Leading Goose” R&D Program of Zhejiang (2024C01167).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢Ke Wang和Minfeng Zhu的帮助。我们还要感谢匿名审稿人提供的深刻评论。本文得到中国国家自然科学基金（62132017, 62302435）、浙江省自然科学基金（LD24F020011）以及浙江省“先锋”和“领军雁”研发计划（2024C01167）的支持。
- en: References
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] G. A. Agha, *ACTORS - a model of concurrent computation in distributed
    systems*, ser. MIT Press series in artificial intelligence.   MIT Press, 1990.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] G. A. Agha, *ACTORS - a model of concurrent computation in distributed
    systems*, ser. MIT Press series in artificial intelligence.   MIT Press, 1990.'
- en: '[2] N. H. S., “Software agents: an overview,” *The Knowledge Engineering Review*,
    vol. 11, p. 205–244, Jul. 1996.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] N. H. S., “Software agents: an overview,” *The Knowledge Engineering Review*,
    vol. 11, p. 205–244, Jul. 1996.'
- en: '[3] M. J. Wooldridge and N. R. Jennings, “Intelligent agents: theory and practice,”
    *The Knowledge Engineering Review*, vol. 10, no. 2, pp. 115–152, Jun. 1995.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] M. J. Wooldridge 和 N. R. Jennings, “Intelligent agents: theory and practice,”
    *The Knowledge Engineering Review*, vol. 10, no. 2, pp. 115–152, Jun. 1995.'
- en: '[4] M. Hutter, *Universal artificial intelligence: Sequential decisions based
    on algorithmic probability*.   Springer Science & Business Media, 2004.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] M. Hutter, *Universal artificial intelligence: Sequential decisions based
    on algorithmic probability*.   Springer Science & Business Media, 2004.'
- en: '[5] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wainwright, P. Mishkin, C. Zhang,
    S. Agarwal, K. Slama, A. Ray, J. Schulman, J. Hilton, F. Kelton, L. Miller, M. Simens,
    A. Askell, P. Welinder, P. F. Christiano, J. Leike, and R. Lowe, “Training language
    models to follow instructions with human feedback,” in *NeurIPS*.   New Orleans,
    USA: PMLR, 2022.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wainwright, P. Mishkin, C.
    Zhang, S. Agarwal, K. Slama, A. Ray, J. Schulman, J. Hilton, F. Kelton, L. Miller,
    M. Simens, A. Askell, P. Welinder, P. F. Christiano, J. Leike, 和 R. Lowe, “Training
    language models to follow instructions with human feedback,” in *NeurIPS*.   New
    Orleans, USA: PMLR, 2022.'
- en: '[6] OpenAI, “GPT-4 technical report,” *CoRR*, vol. abs/2303.08774, Mar. 2023.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] OpenAI, “GPT-4 technical report,” *CoRR*, vol. abs/2303.08774, Mar. 2023.'
- en: '[7] J. Wei, Y. Tay, R. Bommasani, C. Raffel, B. Zoph, S. Borgeaud, D. Yogatama,
    M. Bosma, D. Zhou, D. Metzler, E. H. Chi, T. Hashimoto, O. Vinyals, P. Liang,
    J. Dean, and W. Fedus, “Emergent abilities of large language models,” *TMLR*,
    vol. 2022, 2022.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] J. 韦, Y. 泰, R. 博马萨尼, C. 拉费尔, B. 佐普, S. 博尔戈德, D. 尤加塔马, M. 博斯马, D. 周, D.
    梅茨勒, E. H. 池, T. 哈希莫托, O. 维尼亚尔斯, P. 梁, J. 丁, 和 W. 费杜斯, “大型语言模型的突现能力,” *TMLR*,
    vol. 2022, 2022。'
- en: '[8] L. Wang, C. Ma, X. Feng, Z. Zhang, H. Yang, J. Zhang, Z. Chen, J. Tang,
    X. Chen, Y. Lin, W. X. Zhao, Z. Wei, and J. Wen, “A survey on large language model
    based autonomous agents,” *CoRR*, vol. abs/2308.11432, 2023.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] L. 王, C. 马, X. 冯, Z. 张, H. 杨, J. 张, Z. 陈, J. 唐, X. 陈, Y. 林, W. X. 赵, Z.
    魏, 和 J. 温, “基于大型语言模型的自主智能体综述,” *CoRR*, vol. abs/2308.11432, 2023。'
- en: '[9] Z. Xi, W. Chen, X. Guo, W. He, Y. Ding, B. Hong, M. Zhang, J. Wang, S. Jin,
    E. Zhou, R. Zheng, X. Fan, X. Wang, L. Xiong, Y. Zhou, W. Wang, C. Jiang, Y. Zou,
    X. Liu, Z. Yin, S. Dou, R. Weng, W. Cheng, Q. Zhang, W. Qin, Y. Zheng, X. Qiu,
    X. Huan, and T. Gui, “The rise and potential of large language model based agents:
    A survey,” *CoRR*, vol. abs/2309.07864, 2023.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Z. 习, W. 陈, X. 郭, W. 何, Y. 丁, B. 洪, M. 张, J. 王, S. 金, E. 周, R. 郑, X. 范,
    X. 王, L. 熊, Y. 周, W. 王, C. 姜, Y. 邹, X. 刘, Z. 尹, S. 窦, R. 翁, W. 程, Q. 张, W. 秦,
    Y. 郑, X. 裘, X. 璇, 和 T. 桂, “基于大型语言模型的智能体的兴起与潜力：一项综述,” *CoRR*, vol. abs/2309.07864,
    2023。'
- en: '[10] J. S. Park, J. C. O’Brien, C. J. Cai, M. R. Morris, P. Liang, and M. S.
    Bernstein, “Generative agents: Interactive simulacra of human behavior,” in *Proc. UIST*.   San
    Francisco, USA: ACM, 2023.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] J. S. 帕克, J. C. 奥布莱恩, C. J. 蔡, M. R. 莫里斯, P. 梁, 和 M. S. 伯恩斯坦, “生成智能体：人类行为的互动模拟体,”
    载于 *Proc. UIST*.   旧金山，美国：ACM, 2023。'
- en: '[11] J. Shi, J. Zhao, Y. Wang, X. Wu, J. Li, and L. He, “CGMI: Configurable
    general multi-agent interaction framework,” *CoRR*, vol. abs/2308.12503, 2023.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] J. 石, J. 赵, Y. 王, X. 吴, J. 李, 和 L. 何, “CGMI：可配置的通用多智能体交互框架,” *CoRR*, vol.
    abs/2308.12503, 2023。'
- en: '[12] C. Qian, X. Cong, C. Yang, W. Chen, Y. Su, J. Xu, Z. Liu, and M. Sun,
    “Communicative agents for software development,” *CoRR*, vol. abs/2307.07924,
    2023.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] C. 钱, X. 丛, C. 杨, W. 陈, Y. 苏, J. 徐, Z. 刘, 和 M. 孙, “用于软件开发的交互智能体,” *CoRR*,
    vol. abs/2307.07924, 2023。'
- en: '[13] S. Hong, X. Zheng, J. Chen, Y. Cheng, J. Wang, C. Zhang, Z. Wang, S. K. S.
    Yau, Z. Lin, L. Zhou, C. Ran, L. Xiao, and C. Wu, “MetaGPT: Meta programming for
    multi-agent collaborative framework,” *CoRR*, vol. abs/2308.00352, Aug. 2023.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] S. 洪, X. 郑, J. 陈, Y. 成, J. 王, C. 张, Z. 王, S. K. S. 邱, Z. 林, L. 周, C. 冉,
    L. 肖, 和 C. 吴, “MetaGPT：用于多智能体协作框架的元编程,” *CoRR*, vol. abs/2308.00352, 2023年8月。'
- en: '[14] D. A. Boiko, R. MacKnight, and G. Gomes, “Emergent autonomous scientific
    research capabilities of large language models,” *CoRR*, vol. abs/2304.05332,
    2023.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] D. A. 博伊科, R. 麦克奈特, 和 G. 戈麦斯, “大型语言模型的突现自主科学研究能力,” *CoRR*, vol. abs/2304.05332,
    2023。'
- en: '[15] Gravitas, “AutoGPT,” https://github.com/Significant-Gravitas/AutoGPT,
    2023.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Gravitas, “AutoGPT,” https://github.com/Significant-Gravitas/AutoGPT,
    2023。'
- en: '[16] J. Lin, H. Zhao, A. Zhang, Y. Wu, H. Ping, and Q. Chen, “AgentSims: An
    open-source sandbox for large language model evaluation,” *CoRR*, vol. abs/2308.04026,
    2023.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] J. 林, H. 赵, A. 张, Y. 吴, H. 平, 和 Q. 陈, “AgentSims：一个用于大型语言模型评估的开源沙盒,” *CoRR*,
    vol. abs/2308.04026, 2023。'
- en: '[17] W. Chen, Y. Su, J. Zuo, C. Yang, C. Yuan, C. Qian, C. Chan, Y. Qin, Y. Lu,
    R. Xie, Z. Liu, M. Sun, and J. Zhou, “AgentVerse: Facilitating multi-agent collaboration
    and exploring emergent behaviors in agents,” *CoRR*, vol. abs/2308.10848, 2023.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] W. 陈, Y. 苏, J. 左, C. 杨, C. 袁, C. 钱, C. 陈, Y. 秦, Y. 陆, R. 谢, Z. 刘, M. 孙,
    和 J. 周, “AgentVerse：促进多智能体协作并探索智能体中的突现行为,” *CoRR*, vol. abs/2308.10848, 2023。'
- en: '[18] C. Zhang, K. Yang, S. Hu, Z. Wang, G. Li, Y. Sun, C. Zhang, Z. Zhang,
    A. Liu, S. Zhu, X. Chang, J. Zhang, F. Yin, Y. Liang, and Y. Yang, “ProAgent:
    Building proactive cooperative AI with large language models,” *CoRR*, vol. abs/2308.11339,
    2023.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] C. 张, K. 杨, S. 胡, Z. 王, G. 李, Y. 孙, C. 张, Z. 张, A. 刘, S. 朱, X. 常, J. 张,
    F. 银, Y. 梁, 和 Y. 杨, “ProAgent：利用大型语言模型构建主动合作的AI,” *CoRR*, vol. abs/2308.11339,
    2023。'
- en: '[19] H. Zhang, W. Du, J. Shan, Q. Zhou, Y. Du, J. B. Tenenbaum, T. Shu, and
    C. Gan, “Building cooperative embodied agents modularly with large language models,”
    *CoRR*, vol. abs/2307.02485, 2023.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] H. 张, W. 杜, J. 单, Q. 周, Y. 杜, J. B. 特能鲍姆, T. 舒, 和 C. 甘, “利用大型语言模型模块化构建合作型具身智能体,”
    *CoRR*, vol. abs/2307.02485, 2023。'
- en: '[20] X. Zhu, Y. Chen, H. Tian, C. Tao, W. Su, C. Yang, G. Huang, B. Li, L. Lu,
    X. Wang, Y. Qiao, Z. Zhang, and J. Dai, “Ghost in the Minecraft: Generally capable
    agents for open-world environments via large language models with text-based knowledge
    and memory,” *CoRR*, vol. abs/2305.17144, 2023.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] X. 朱, Y. 陈, H. 田, C. 陶, W. 苏, C. 杨, G. 黄, B. 李, L. 陆, X. 王, Y. 乔, Z. 张,
    和 J. 戴, “Minecraft中的鬼魂：通过具有基于文本的知识和记忆的大型语言模型实现开放世界环境中的通用能力智能体,” *CoRR*, vol. abs/2305.17144,
    2023。'
- en: '[21] D. Hafner, J. Pasukonis, J. Ba, and T. P. Lillicrap, “Mastering diverse
    domains through world models,” *CoRR*, vol. abs/2301.04104, 2023.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] D. Hafner, J. Pasukonis, J. Ba, 和 T. P. Lillicrap，“通过世界模型掌握多样化领域”，*CoRR*，第abs/2301.04104卷，2023年。'
- en: '[22] A. Mirchev, B. Kayalibay, P. van der Smagt, and J. Bayer, “Variational
    state-space models for localisation and dense 3D mapping in 6 DoF,” in *ICLR*.   Austria:
    OpenReview.net, 2021.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] A. Mirchev, B. Kayalibay, P. van der Smagt, 和 J. Bayer，“变分状态空间模型用于6自由度的定位和密集3D映射”，在*ICLR*。奥地利：OpenReview.net，2021年。'
- en: '[23] S. Franklin and A. C. Graesser, “Is it an agent, or just a program?: a
    taxonomy for autonomous agents,” in *Proc. ATAL*.   Budapest, Hungary: Springer,
    1996.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] S. Franklin 和 A. C. Graesser，“它是一个智能体，还是仅仅是一个程序？：自主智能体的分类”，在*Proc. ATAL*。匈牙利布达佩斯：Springer，1996年。'
- en: '[24] S. Bubeck, V. Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz, E. Kamar,
    P. Lee, Y. T. Lee, Y. Li, S. M. Lundberg, H. Nori, H. Palangi, M. T. Ribeiro,
    and Y. Zhang, “Sparks of artificial general intelligence: Early experiments with
    GPT-4,” *CoRR*, vol. abs/2303.12712, Mar. 2023.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] S. Bubeck, V. Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz, E. Kamar,
    P. Lee, Y. T. Lee, Y. Li, S. M. Lundberg, H. Nori, H. Palangi, M. T. Ribeiro,
    和 Y. Zhang，“人工通用智能的火花：对GPT-4的早期实验”，*CoRR*，第abs/2303.12712卷，2023年3月。'
- en: '[25] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M. Lachaux, T. Lacroix,
    B. Rozière, N. Goyal, E. Hambro, F. Azhar, A. Rodriguez, A. Joulin, E. Grave,
    and G. Lample, “LLaMA: Open and efficient foundation language models,” *CoRR*,
    vol. abs/2302.13971, Feb. 2023.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M. Lachaux, T. Lacroix,
    B. Rozière, N. Goyal, E. Hambro, F. Azhar, A. Rodriguez, A. Joulin, E. Grave,
    和 G. Lample，“LLaMA：开放和高效的基础语言模型”，*CoRR*，第abs/2302.13971卷，2023年2月。'
- en: '[26] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan,
    P. Shyam, G. Sastry, A. Askell *et al.*, “Language models are few-shot learners,”
    *Advances in neural information processing systems*, vol. 33, pp. 1877–1901, 2020.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A.
    Neelakantan, P. Shyam, G. Sastry, A. Askell *等*， “语言模型是少样本学习者”，*神经信息处理系统进展*，第33卷，第1877–1901页，2020年。'
- en: '[27] S. Yao, J. Zhao, D. Yu, N. Du, I. S. andKarthik R. Narasimhan, and Y. Cao,
    “ReAct: Synergizing reasoning and acting in language models,” in *ICLR*.   Kigali,
    Rwanda: OpenReview.net, 2023.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] S. Yao, J. Zhao, D. Yu, N. Du, I. S. 和 Karthik R. Narasimhan, 和 Y. Cao，“ReAct：在语言模型中协同推理和行动”，在*ICLR*。卢旺达基加利：OpenReview.net，2023年。'
- en: '[28] S. Noah, C. Federico, G. Ashwin, N. K. R, and Y. Shunyu, “Reflexion: Language
    agents with verbal reinforcement learning,” in *NeurIPS*.   New Orleans, USA:
    PMLR, 2023.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] S. Noah, C. Federico, G. Ashwin, N. K. R, 和 Y. Shunyu，“Reflexion：具有语言强化学习的智能体”，在*NeurIPS*。美国新奥尔良：PMLR，2023年。'
- en: '[29] S. Yao, D. Yu, J. Zhao, I. Shafran, T. L. Griffiths, Y. Cao, and K. Narasimhan,
    “Tree of thoughts: Deliberate problem solving with large language models,” *CoRR*,
    vol. abs/2305.10601, 2023.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] S. Yao, D. Yu, J. Zhao, I. Shafran, T. L. Griffiths, Y. Cao, 和 K. Narasimhan，“思维树：使用大型语言模型进行深思熟虑的问题解决”，*CoRR*，第abs/2305.10601卷，2023年。'
- en: '[30] T. Schick, J. Dwivedi-Yu, R. Dessì, R. Raileanu, M. Lomeli, L. Zettlemoyer,
    N. Cancedda, and T. Scialom, “Toolformer: Language models can teach themselves
    to use tools,” *CoRR*, vol. abs/2302.04761, 2023.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] T. Schick, J. Dwivedi-Yu, R. Dessì, R. Raileanu, M. Lomeli, L. Zettlemoyer,
    N. Cancedda, 和 T. Scialom，“Toolformer：语言模型可以自学使用工具”，*CoRR*，第abs/2302.04761卷，2023年。'
- en: '[31] Y. Qin, S. Hu, Y. Lin, W. Chen, N. Ding, G. Cui, Z. Zeng, Y. Huang, C. Xiao,
    C. Han, Y. R. Fung, Y. Su, H. Wang, C. Qian, R. Tian, K. Zhu, S. Liang, X. Shen,
    B. Xu, Z. Zhang, Y. Ye, B. Li, Z. Tang, J. Yi, Y. Zhu, Z. Dai, L. Yan, X. Cong,
    Y. Lu, W. Zhao, Y. Huang, J. Yan, X. Han, X. Sun, D. Li, J. Phang, C. Yang, T. Wu,
    H. Ji, Z. Liu, and M. Sun, “Tool learning with foundation models,” *CoRR*, vol.
    abs/2304.08354, 2023.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Y. Qin, S. Hu, Y. Lin, W. Chen, N. Ding, G. Cui, Z. Zeng, Y. Huang, C.
    Xiao, C. Han, Y. R. Fung, Y. Su, H. Wang, C. Qian, R. Tian, K. Zhu, S. Liang,
    X. Shen, B. Xu, Z. Zhang, Y. Ye, B. Li, Z. Tang, J. Yi, Y. Zhu, Z. Dai, L. Yan,
    X. Cong, Y. Lu, W. Zhao, Y. Huang, J. Yan, X. Han, X. Sun, D. Li, J. Phang, C.
    Yang, T. Wu, H. Ji, Z. Liu, 和 M. Sun，“基础模型的工具学习”，*CoRR*，第abs/2304.08354卷，2023年。'
- en: '[32] Y. Qin, S. Liang, Y. Ye, K. Zhu, L. Yan, Y. Lu, Y. Lin, X. Cong, X. Tang,
    B. Qian, S. Zhao, R. Tian, R. Xie, J. Zhou, M. Gerstein, D. Li, Z. Liu, and M. Sun,
    “Toolllm: Facilitating large language models to master 16000+ real-world apis,”
    *CoRR*, vol. abs/2307.16789, 2023.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] Y. Qin, S. Liang, Y. Ye, K. Zhu, L. Yan, Y. Lu, Y. Lin, X. Cong, X. Tang,
    B. Qian, S. Zhao, R. Tian, R. Xie, J. Zhou, M. Gerstein, D. Li, Z. Liu, 和 M. Sun，“Toolllm：促进大型语言模型掌握16000多个真实世界API”，*CoRR*，第abs/2307.16789卷，2023年。'
- en: '[33] C. Qian, C. Han, Y. R. Fung, Y. Qin, Z. Liu, and H. Ji, “CREATOR: disentangling
    abstract and concrete reasonings of large language models through tool creation,”
    *CoRR*, vol. abs/2305.14318, 2023.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] C. Qian, C. Han, Y. R. Fung, Y. Qin, Z. Liu, 和 H. Ji，“CREATOR：通过工具创建解开大型语言模型的抽象和具体推理”，*CoRR*，第abs/2305.14318卷，2023年。'
- en: '[34] H. Chase, “Langchain,” https://github.com/hwchase17/langchain, 2022.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] H. Chase，“Langchain，” https://github.com/hwchase17/langchain，2022年。'
- en: '[35] Y. Nakajima, “BabyAGI,” https://github.com/yoheinakajima/babyagi, 2023.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] Y. Nakajima，“BabyAGI，” https://github.com/yoheinakajima/babyagi，2023年。'
- en: '[36] G. Li, H. A. A. K. Hammoud, H. Itani, D. Khizbullin, and B. Ghanem, “CAMEL:
    communicative agents for ”mind” exploration of large scale language model society,”
    *CoRR*, vol. abs/2303.17760, Mar. 2023.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] G. Li, H. A. A. K. Hammoud, H. Itani, D. Khizbullin, 和 B. Ghanem，“CAMEL：用于大规模语言模型社会的‘思维’探索的交流代理，”
    *CoRR*，第abs/2303.17760号，2023年3月。'
- en: '[37] Y. Talebirad and A. Nadiri, “Multi-agent collaboration: Harnessing the
    power of intelligent LLM agents,” *CoRR*, vol. abs/2306.03314, 2023.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] Y. Talebirad 和 A. Nadiri，“多智能体协作：利用智能LLM代理的力量，” *CoRR*，第abs/2306.03314号，2023年。'
- en: '[38] T. Liang, Z. He, W. Jiao, X. Wang, Y. Wang, R. Wang, Y. Yang, Z. Tu, and
    S. Shi, “Encouraging divergent thinking in large language models through multi-agent
    debate,” *CoRR*, vol. abs/2305.19118, 2023.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] T. Liang, Z. He, W. Jiao, X. Wang, Y. Wang, R. Wang, Y. Yang, Z. Tu, 和
    S. Shi，“通过多智能体辩论激发大型语言模型的发散思维，” *CoRR*，第abs/2305.19118号，2023年。'
- en: '[39] R. Nakano, J. Hilton, S. Balaji, J. Wu, L. Ouyang, C. Kim, C. Hesse, S. Jain,
    V. Kosaraju, W. Saunders, X. Jiang, K. Cobbe, T. Eloundou, G. Krueger, K. Button,
    M. Knight, B. Chess, and J. Schulman, “WebGPT: Browser-assisted question-answering
    with human feedback,” *CoRR*, vol. abs/2112.09332, 2021.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] R. Nakano, J. Hilton, S. Balaji, J. Wu, L. Ouyang, C. Kim, C. Hesse, S.
    Jain, V. Kosaraju, W. Saunders, X. Jiang, K. Cobbe, T. Eloundou, G. Krueger, K.
    Button, M. Knight, B. Chess, 和 J. Schulman，“WebGPT：浏览器辅助的问答系统与人工反馈，” *CoRR*，第abs/2112.09332号，2021年。'
- en: '[40] Q. Wu, G. Bansal, J. Zhang, Y. Wu, S. Zhang, E. Zhu, B. Li, L. Jiang,
    X. Zhang, and C. Wang, “AutoGen: Enabling next-gen LLM applications via multi-agent
    conversation framework,” *CoRR*, vol. abs/2308.08155, 2023.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] Q. Wu, G. Bansal, J. Zhang, Y. Wu, S. Zhang, E. Zhu, B. Li, L. Jiang,
    X. Zhang, 和 C. Wang，“AutoGen：通过多智能体对话框架实现下一代LLM应用，” *CoRR*，第abs/2308.08155号，2023年。'
- en: '[41] R. Guo, T. Fujiwara, Y. Li, K. M. Lima, S. Sen, N. K. Tran, and K. Ma,
    “Comparative visual analytics for assessing medical records with sequence embedding,”
    *Visualization Informatics*, vol. 4, no. 2, pp. 72–85, 2020.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] R. Guo, T. Fujiwara, Y. Li, K. M. Lima, S. Sen, N. K. Tran, 和 K. Ma，“使用序列嵌入进行医疗记录的比较视觉分析，”
    *可视化信息学*，第4卷，第2期，页码72–85，2020年。'
- en: '[42] Z. Jin, S. Cui, S. Guo, D. Gotz, J. Sun, and N. Cao, “CarePre: An intelligent
    clinical decision assistance system,” *ACM Transactions on Computing for Healthcare*,
    vol. 1, no. 1, pp. 1–20, 2020.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] Z. Jin, S. Cui, S. Guo, D. Gotz, J. Sun, 和 N. Cao，“CarePre：智能临床决策辅助系统，”
    *ACM健康计算学报*，第1卷，第1期，页码1–20，2020年。'
- en: '[43] C. B. Nielsen, S. D. Jackman, I. Birol, and S. J. M. Jones, “ABySS-Explorer:
    Visualizing genome sequence assemblies,” *IEEE Transactions on Visualization and
    Computer Graphics*, vol. 15, no. 6, pp. 881–888, 2009.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] C. B. Nielsen, S. D. Jackman, I. Birol, 和 S. J. M. Jones，“ABySS-Explorer：基因组序列组装的可视化，”
    *IEEE可视化与计算机图形学汇刊*，第15卷，第6期，页码881–888，2009年。'
- en: '[44] S. Guo, K. Xu, R. Zhao, D. Gotz, H. Zha, and N. Cao, “EventThread: Visual
    summarization and stage analysis of event sequence data,” *IEEE Transactions on
    Visualization and Computer Graphics*, vol. 24, no. 1, pp. 56–65, 2018.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] S. Guo, K. Xu, R. Zhao, D. Gotz, H. Zha, 和 N. Cao，“EventThread：事件序列数据的视觉总结和阶段分析，”
    *IEEE可视化与计算机图形学汇刊*，第24卷，第1期，页码56–65，2018年。'
- en: '[45] S. Guo, Z. Jin, D. Gotz, F. Du, H. Zha, and N. Cao, “Visual progression
    analysis of event sequence data,” *IEEE Transactions on Visualization and Computer
    Graphics*, vol. 25, no. 1, pp. 417–426, 2019.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] S. Guo, Z. Jin, D. Gotz, F. Du, H. Zha, 和 N. Cao，“事件序列数据的视觉进展分析，” *IEEE可视化与计算机图形学汇刊*，第25卷，第1期，页码417–426，2019年。'
- en: '[46] A. Perer and F. Wang, “Frequence: interactive mining and visualization
    of temporal frequent event sequences,” in *IUI*.   Haifa, Israel: ACM, 2014.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] A. Perer 和 F. Wang，“Frequence：时间频繁事件序列的交互式挖掘和可视化，” 见 *IUI*。以色列海法：ACM，2014年。'
- en: '[47] Y. Han, A. Rozga, N. Dimitrova, G. D. Abowd, and J. T. Stasko, “Visual
    analysis of proximal temporal relationships of social and communicative behaviors,”
    *Computer Graphics Forum*, vol. 34, no. 3, pp. 51–60, 2015.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] Y. Han, A. Rozga, N. Dimitrova, G. D. Abowd, 和 J. T. Stasko，“社交和交流行为的近端时间关系的视觉分析，”
    *计算机图形论坛*，第34卷，第3期，页码51–60，2015年。'
- en: '[48] N. Cao, Y. Lin, F. Du, and D. Wang, “Episogram: Visual summarization of
    egocentric social interactions,” *IEEE Computer Graphics and Applications*, vol. 36,
    no. 5, pp. 72–81, 2016.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] N. Cao, Y. Lin, F. Du, 和 D. Wang，“Episogram：自我中心社交互动的视觉总结，” *IEEE计算机图形与应用*，第36卷，第5期，页码72–81，2016年。'
- en: '[49] F. Fischer, J. Fuchs, P. Vervier, F. Mansmann, and O. Thonnard, “VisTracer:
    a visual analytics tool to investigate routing anomalies in traceroutes,” in *VizSec*.   Seattle,
    USA: ACM, 2012.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] F. Fischer, J. Fuchs, P. Vervier, F. Mansmann, 和 O. Thonnard，"VisTracer:
    用于调查Traceroutes中路由异常的视觉分析工具"，发表于《**VizSec**》。西雅图，美国：ACM，2012年。'
- en: '[50] L. Wenting, W. Meng, and C. J. H, “Real-time event identification through
    low-dimensional subspace characterization of high-dimensional synchrophasor data,”
    *IEEE Transactions on Power Systems*, vol. 33, no. 5, pp. 4937–4947, 2018.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] L. Wenting, W. Meng, 和 C. J. H，"通过低维子空间表征高维同步相量数据进行实时事件识别"，《**IEEE 电力系统汇刊**》，第33卷，第5期，第4937–4947页，2018年。'
- en: '[51] Y. Wu, N. Cao, D. Gotz, Y. Tan, and D. A. Keim, “A survey on visual analytics
    of social media data,” *IEEE Transactions on Multimedia*, vol. 18, no. 11, pp.
    2135–2148, 2016.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] Y. Wu, N. Cao, D. Gotz, Y. Tan, 和 D. A. Keim，"关于社交媒体数据的视觉分析综述"，《**IEEE
    多媒体汇刊**》，第18卷，第11期，第2135–2148页，2016年。'
- en: '[52] F. Zhou, X. Lin, C. Liu, Y. Zhao, P. Xu, L. Ren, T. Xue, and L. Ren, “A
    survey of visualization for smart manufacturing,” *Journal of Visualization*,
    vol. 22, no. 2, pp. 419–435, 2019.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] F. Zhou, X. Lin, C. Liu, Y. Zhao, P. Xu, L. Ren, T. Xue, 和 L. Ren，"智能制造可视化的综述"，《**可视化杂志**》，第22卷，第2期，第419–435页，2019年。'
- en: '[53] Y. Shi, Y. Liu, H. Tong, J. He, G. Yan, and N. Cao, “Visual analytics
    of anomalous user behaviors: A survey,” *IEEE Transactions on Big Data*, vol. 8,
    no. 2, pp. 377–396, 2020.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] Y. Shi, Y. Liu, H. Tong, J. He, G. Yan, 和 N. Cao，"异常用户行为的视觉分析：综述"，《**IEEE
    大数据汇刊**》，第8卷，第2期，第377–396页，2020年。'
- en: '[54] Y. Guo, S. Guo, Z. Jin, S. Kaul, D. Gotz, and N. Cao, “Survey on visual
    analysis of event sequence data,” *IEEE Transactions on Visualization and Computer
    Graphics*, vol. 28, no. 12, pp. 5091–5112, 2022.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] Y. Guo, S. Guo, Z. Jin, S. Kaul, D. Gotz, 和 N. Cao，"事件序列数据的视觉分析综述"，《**IEEE
    视觉化与计算机图形学汇刊**》，第28卷，第12期，第5091–5112页，2022年。'
- en: '[55] X. Yuan, Z. Wang, Z. Liu, C. Guo, H. Ai, and D. Ren, “Visualization of
    social media flows with interactively identified key players,” in *IEEE VAST*.   Paris,
    France: IEEE Computer Society, 2014, pp. 291–292.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] X. Yuan, Z. Wang, Z. Liu, C. Guo, H. Ai, 和 D. Ren，"具有互动识别关键人物的社交媒体流的可视化"，发表于《**IEEE
    VAST**》。巴黎，法国：IEEE计算机学会，2014年，第291–292页。'
- en: '[56] Y. Wu, S. Liu, K. Yan, M. Liu, and F. Wu, “OpinionFlow: Visual analysis
    of opinion diffusion on social media,” *IEEE Transactions on Visualization and
    Computer Graphics*, vol. 20, no. 12, pp. 1763–1772, 2014.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] Y. Wu, S. Liu, K. Yan, M. Liu, 和 F. Wu，"OpinionFlow: 社交媒体上意见扩散的视觉分析"，《**IEEE
    视觉化与计算机图形学汇刊**》，第20卷，第12期，第1763–1772页，2014年。'
- en: '[57] S. Chen, S. Li, S. Chen, and X. Yuan, “R-Map: A map metaphor for visualizing
    information reposting process in social media,” *IEEE Transactions on Visualization
    and Computer Graphics*, vol. 26, no. 1, pp. 1204–1214, 2020.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] S. Chen, S. Li, S. Chen, 和 X. Yuan，"R-Map: 用于可视化社交媒体信息转发过程的地图隐喻"，《**IEEE
    视觉化与计算机图形学汇刊**》，第26卷，第1期，第1204–1214页，2020年。'
- en: '[58] G. Sun, T. Tang, T. Peng, R. Liang, and Y. Wu, “SocialWave: Visual analysis
    of spatio-temporal diffusion of information on social media,” *ACM Transactions
    on Intelligent Systems and Technology*, vol. 9, no. 2, pp. 1–23, 2018.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] G. Sun, T. Tang, T. Peng, R. Liang, 和 Y. Wu，"SocialWave: 社交媒体上信息的时空扩散的视觉分析"，《**ACM
    智能系统与技术汇刊**》，第9卷，第2期，第1–23页，2018年。'
- en: '[59] J. Zhao, N. Cao, Z. Wen, Y. Song, Y. Lin, and C. Collins, “#FluxFlow:
    Visual analysis of anomalous information spreading on social media,” *IEEE Transactions
    on Visualization and Computer Graphics*, vol. 20, no. 12, pp. 1773–1782, 2014.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] J. Zhao, N. Cao, Z. Wen, Y. Song, Y. Lin, 和 C. Collins，"#FluxFlow: 社交媒体上异常信息传播的视觉分析"，《**IEEE
    视觉化与计算机图形学汇刊**》，第20卷，第12期，第1773–1782页，2014年。'
- en: '[60] F. B. Viégas, M. Wattenberg, J. Hebert, G. Borggaard, A. Cichowlas, J. Feinberg,
    J. Orwant, and C. R. Wren, “Google+Ripples: a native visualization of information
    flow,” in *WWW*.   Rio de Janeiro, Brazil: ACM, 2013.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] F. B. Viégas, M. Wattenberg, J. Hebert, G. Borggaard, A. Cichowlas, J.
    Feinberg, J. Orwant, 和 C. R. Wren，"Google+Ripples: 信息流的原生可视化"，发表于《**WWW**》。里约热内卢，巴西：ACM，2013年。'
- en: '[61] P. Law, Z. Liu, S. Malik, and R. C. Basole, “MAQUI: Interweaving queries
    and pattern mining for recursive event sequence exploration,” *IEEE Transactions
    on Visualization and Computer Graphics*, vol. 25, no. 1, pp. 396–406, 2019.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] P. Law, Z. Liu, S. Malik, 和 R. C. Basole，"MAQUI: 递归事件序列探索中的查询与模式挖掘交织"，《**IEEE
    视觉化与计算机图形学汇刊**》，第25卷，第1期，第396–406页，2019年。'
- en: '[62] S. N. Dambekodi, S. Frazier, P. Ammanabrolu, and M. O. Riedl, “Playing
    text-based games with common sense,” *CoRR*, vol. abs/2012.02757, 2020.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] S. N. Dambekodi, S. Frazier, P. Ammanabrolu, 和 M. O. Riedl，"用常识玩文本游戏"，《**CoRR**》，第abs/2012.02757卷，2020年。'
- en: '[63] M. J. Hausknecht, P. Ammanabrolu, M. Côté, and X. Yuan, “Interactive fiction
    games: A colossal adventure,” in *AAAI*.   New York, USA: AAAI Press, 2020, pp.
    7903–7910.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] M. J. Hausknecht, P. Ammanabrolu, M. Côté, 和 X. Yuan，“互动小说游戏：一场巨大的冒险，”
    在 *AAAI*。 美国纽约：AAAI Press，2020，第7903–7910页。'
- en: '[64] R. Liu, R. Yang, C. Jia, G. Zhang, D. Zhou, A. M. Dai, D. Yang, and S. Vosoughi,
    “Training socially aligned language models in simulated human society,” *CoRR*,
    vol. abs/2305.16960, 2023.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] R. Liu, R. Yang, C. Jia, G. Zhang, D. Zhou, A. M. Dai, D. Yang, 和 S. Vosoughi，“在模拟人类社会中训练社会对齐的语言模型，”
    *CoRR*，卷 abs/2305.16960，2023。'
- en: '[65] D. Driess, F. Xia, M. S. M. Sajjadi, C. Lynch, A. Chowdhery, B. Ichter,
    A. Wahid, J. Tompson, Q. Vuong, T. Yu, W. Huang, Y. Chebotar, P. Sermanet, D. Duckworth,
    S. Levine, V. Vanhoucke, K. Hausman, M. Toussaint, K. Greff, A. Zeng, I. Mordatch,
    and P. Florence, “PaLM-E: An embodied multimodal language model,” in *ICML*.   Honolulu,
    USA: PMLR, 2023.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] D. Driess, F. Xia, M. S. M. Sajjadi, C. Lynch, A. Chowdhery, B. Ichter,
    A. Wahid, J. Tompson, Q. Vuong, T. Yu, W. Huang, Y. Chebotar, P. Sermanet, D.
    Duckworth, S. Levine, V. Vanhoucke, K. Hausman, M. Toussaint, K. Greff, A. Zeng,
    I. Mordatch, 和 P. Florence，“PaLM-E：一种体化的多模态语言模型，” 在 *ICML*。 美国檀香山：PMLR，2023。'
- en: '[66] S. Paul, A. Roy-Chowdhury, and A. Cherian, “AVLEN: audio-visual-language
    embodied navigation in 3d environments,” in *NeurIPS*, New Orleans, USA, 2022.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] S. Paul, A. Roy-Chowdhury, 和 A. Cherian，“AVLEN：在3D环境中的视听语言体现在导航中，” 在 *NeurIPS*，美国新奥尔良，2022。'
- en: '[67] J. S. Park, L. Popowski, C. J. Cai, M. R. Morris, P. Liang, and M. S.
    Bernstein, “Social simulacra: Creating populated prototypes for social computing
    systems,” in *UIST*.   Bend, USA: ACM, 2022, pp. 1–18.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] J. S. Park, L. Popowski, C. J. Cai, M. R. Morris, P. Liang, 和 M. S. Bernstein，“社会模拟：为社会计算系统创建人口原型，”
    在 *UIST*。 美国本德：ACM，2022，第1–18页。'
- en: '[68] C. Gao, X. Lan, Z. Lu, J. Mao, J. Piao, H. Wang, D. Jin, and Y. Li, “S${}^{\mbox{3}}$:
    Social-network simulation system with large language model-empowered agents,”
    *CoRR*, vol. abs/2307.14984, 2023.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] C. Gao, X. Lan, Z. Lu, J. Mao, J. Piao, H. Wang, D. Jin, 和 Y. Li，“S${}^{\mbox{3}}$：带有大语言模型赋能代理的社交网络模拟系统，”
    *CoRR*，卷 abs/2307.14984，2023。'
- en: '[69] R. Williams, N. Hosseinichimeh, A. Majumdar, and N. Ghaffarzadegan, “Epidemic
    modeling with generative agents,” *CoRR*, vol. abs/2307.04986, 2023.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] R. Williams, N. Hosseinichimeh, A. Majumdar, 和 N. Ghaffarzadegan，“使用生成代理进行流行病建模，”
    *CoRR*，卷 abs/2307.04986，2023。'
- en: '[70] A. O’Gara, “Hoodwinked: Deception and cooperation in a text-based game
    for language models,” *CoRR*, vol. abs/2308.01404, 2023.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] A. O’Gara，“Hoodwinked：语言模型的文本游戏中的欺骗与合作，” *CoRR*，卷 abs/2308.01404，2023。'
- en: '[71] L. Fan, G. Wang, Y. Jiang, A. Mandlekar, Y. Yang, H. Zhu, A. Tang, D. Huang,
    Y. Zhu, and A. Anandkumar, “MineDojo: Building open-ended embodied agents with
    internet-scale knowledge,” in *NeurIPS*, New Orleans, USA, 2022.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] L. Fan, G. Wang, Y. Jiang, A. Mandlekar, Y. Yang, H. Zhu, A. Tang, D.
    Huang, Y. Zhu, 和 A. Anandkumar，“MineDojo：构建具有互联网规模知识的开放式体化代理，” 在 *NeurIPS*，美国新奥尔良，2022。'
- en: '[72] G. Wang, Y. Xie, Y. Jiang, A. Mandlekar, C. Xiao, Y. Zhu, L. Fan, and
    A. Anandkumar, “Voyager: An open-ended embodied agent with large language models,”
    *CoRR*, vol. abs/2305.16291, 2023.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] G. Wang, Y. Xie, Y. Jiang, A. Mandlekar, C. Xiao, Y. Zhu, L. Fan, 和 A.
    Anandkumar，“Voyager：一种具有大语言模型的开放式体化代理，” *CoRR*，卷 abs/2305.16291，2023。'
- en: '[73] C. Lynch, A. Wahid, J. Tompson, T. Ding, J. Betker, R. Baruch, T. Armstrong,
    and P. Florence, “Interactive language: Talking to robots in real time,” *CoRR*,
    vol. abs/2210.06407, 2022.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] C. Lynch, A. Wahid, J. Tompson, T. Ding, J. Betker, R. Baruch, T. Armstrong,
    和 P. Florence，“交互语言：实时与机器人对话，” *CoRR*，卷 abs/2210.06407，2022。'
- en: '[74] D. Surís, S. Menon, and C. Vondrick, “ViperGPT: Visual inference via python
    execution for reasoning,” in *ICCV*.   Paris, France: IEEE, 2023, pp. 11 854–11 864.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] D. Surís, S. Menon, 和 C. Vondrick，“ViperGPT：通过Python执行的视觉推理，” 在 *ICCV*。
    法国巴黎：IEEE，2023，第11 854–11 864页。'
- en: '[75] K. Nottingham, P. Ammanabrolu, A. Suhr, Y. Choi, H. Hajishirzi, S. Singh,
    and R. Fox, “Do embodied agents dream of pixelated sheep: Embodied decision making
    using language guided world modelling,” in *ICML*.   Honolulu, USA: PMLR, 2023.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[75] K. Nottingham, P. Ammanabrolu, A. Suhr, Y. Choi, H. Hajishirzi, S. Singh,
    和 R. Fox，“体化代理是否梦见像素化的羊：使用语言引导的世界建模进行体化决策，” 在 *ICML*。 美国檀香山：PMLR，2023。'
- en: '[76] J. Cui, Z. Li, Y. Yan, B. Chen, and L. Yuan, “ChatLaw: Open-source legal
    large language model with integrated external knowledge bases,” *CoRR*, vol. abs/2306.16092,
    2023.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[76] J. Cui, Z. Li, Y. Yan, B. Chen, 和 L. Yuan，“ChatLaw：集成外部知识库的开源法律大语言模型，”
    *CoRR*，卷 abs/2306.16092，2023。'
- en: '[77] W. Huang, F. Xia, T. Xiao, H. Chan, J. Liang, P. Florence, A. Zeng, J. Tompson,
    I. Mordatch, Y. Chebotar, P. Sermanet, T. Jackson, N. Brown, L. Luu, S. Levine,
    K. Hausman, and B. Ichter, “Inner monologue: Embodied reasoning through planning
    with language models,” in *Conference on Robot Learning*, vol. 205.   Auckland,
    New Zealand: PMLR, 2022, pp. 1769–1782.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[77] W. Huang, F. Xia, T. Xiao, H. Chan, J. Liang, P. Florence, A. Zeng, J.
    Tompson, I. Mordatch, Y. Chebotar, P. Sermanet, T. Jackson, N. Brown, L. Luu,
    S. Levine, K. Hausman, 和 B. Ichter, “内在独白：通过语言模型进行计划的具身推理，” 见 *机器人学习会议*，第 205
    卷。 新西兰奥克兰：PMLR，2022年，页 1769–1782。'
- en: '[78] Y. Shen, K. Song, X. Tan, D. Li, W. Lu, and Y. Zhuang, “HuggingGPT: Solving
    AI tasks with ChatGPT and its friends in hugging face,” *CoRR*, 2023.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] Y. Shen, K. Song, X. Tan, D. Li, W. Lu, 和 Y. Zhuang, “HuggingGPT：使用 ChatGPT
    及其在 hugging face 的朋友解决 AI 任务，” *CoRR*，2023年。'
- en: '[79] X. Liang, B. Wang, H. Huang, S. Wu, P. Wu, L. Lu, Z. Ma, and Z. Li, “Unleashing
    infinite-length input capacity for large-scale language models with self-controlled
    memory system,” *CoRR*, vol. abs/2304.13343, 2023.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[79] X. Liang, B. Wang, H. Huang, S. Wu, P. Wu, L. Lu, Z. Ma, 和 Z. Li, “为大规模语言模型释放无限长度输入能力的自控记忆系统，”
    *CoRR*，第 abs/2304.13343 号卷，2023年。'
- en: '[80] C. J. Chu, “Time series segmentation: A sliding window approach,” *Inf.
    Sci.*, vol. 85, no. 1-3, pp. 147–173, Jul. 1995.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[80] C. J. Chu, “时间序列分段：滑动窗口方法，” *信息科学*，第 85 卷，第 1-3 期，页 147–173，1995年7月。'
- en: '[81] C. Truong, L. Oudre, and N. Vayatis, “Selective review of offline change
    point detection methods,” *Signal Process.*, vol. 167, Feb. 2020.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[81] C. Truong, L. Oudre, 和 N. Vayatis, “离线变化点检测方法的选择性回顾，” *信号处理*，第 167 卷，2020年2月。'
- en: '[82] M. Ogawa and K. Ma, “Software evolution storylines,” in *Proc. VISSOFT*.   Salt
    Lake City, USA: ACM, 2010, pp. 35–42.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[82] M. Ogawa 和 K. Ma, “软件演化故事线，” 见 *VISSOFT 会议录*。 美国盐湖城：ACM，2010年，页 35–42。'
- en: '[83] Y. Tanahashi and K. Ma, “Design considerations for optimizing storyline
    visualizations,” *IEEE Transactions on Visualization and Computer Graphics*, vol. 18,
    no. 12, 2012.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[83] Y. Tanahashi 和 K. Ma, “优化故事情节可视化的设计考虑，” *IEEE 视觉化与计算机图形学学报*，第 18 卷，第 12
    期，2012年。'
- en: '[84] Y. Feng, X. Wang, B. Pan, K. Wong, Y. Ren, S. Liu, Z. Yan, Y. Ma, H. Qu,
    and W. Chen, “XNLI: explaining and diagnosing NLI-based visual data analysis,”
    *IEEE Transactions on Visualization and Computer Graphics*, 2023.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[84] Y. Feng, X. Wang, B. Pan, K. Wong, Y. Ren, S. Liu, Z. Yan, Y. Ma, H. Qu,
    和 W. Chen, “XNLI：解释和诊断基于 NLI 的视觉数据分析，” *IEEE 视觉化与计算机图形学学报*，2023年。'
- en: '[85] B. John, “SUS: a retrospective,” *Journal of usability studies*, vol. 8,
    no. 2, p. 29–40, 2013.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[85] B. John, “SUS：回顾，” *可用性研究期刊*，第 8 卷，第 2 期，页 29–40，2013年。'
- en: '[86] X. Team, “XAgent: An autonomous agent for complex task solving,” 2023,
    https://github.com/OpenBMB/XAgent.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[86] X. Team, “XAgent：一个用于复杂任务解决的自主代理，” 2023年，https://github.com/OpenBMB/XAgent。'
- en: '[87] R. Team, “Research agent,” 2023, https://github.com/mukulpatnaik/researchgpt.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[87] R. Team, “研究代理人，” 2023年，https://github.com/mukulpatnaik/researchgpt。'
- en: '[88] Y. Zheng, C. Ma, K. Shi, and H. Huang, “Agents meet OKR: an object and
    key results driven agent system with hierarchical self-collaboration and self-evaluation,”
    *CoRR*, vol. abs/2311.16542, 2023.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[88] Y. Zheng, C. Ma, K. Shi, 和 H. Huang, “代理人遇见 OKR：一个基于对象和关键结果的代理系统，具有分层自我协作和自我评估，”
    *CoRR*，第 abs/2311.16542 号卷，2023年。'
- en: '[89] Z. Yang, L. Li, K. Lin, J. Wang, C. Lin, Z. Liu, and L. Wang, “The dawn
    of LMMs: Preliminary explorations with GPT-4V(ision),” *CoRR*, vol. abs/2309.17421,
    2023.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[89] Z. Yang, L. Li, K. Lin, J. Wang, C. Lin, Z. Liu, 和 L. Wang, “LMMs 的曙光：与
    GPT-4V(ision) 的初步探索，” *CoRR*，第 abs/2309.17421 号卷，2023年。'
- en: '[90] F. Yingchaojie, C. Jiazhou, H. Keyu, J. K. Wong, Y. Hui, Z. Wei, Z. Rongchen,
    L. Xiaonan, and C. Wei, “iPoet: interactive painting poetry creation with visual
    multimodal analysis,” *Journal of Visualization*, vol. 25, no. 3, 2022.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90] F. Yingchaojie, C. Jiazhou, H. Keyu, J. K. Wong, Y. Hui, Z. Wei, Z. Rongchen,
    L. Xiaonan, 和 C. Wei, “iPoet：通过视觉多模态分析进行互动绘画诗歌创作，” *可视化期刊*，第 25 卷，第 3 期，2022年。'
- en: '[91] Y. Feng, X. Wang, K. K. Wong, S. Wang, Y. Lu, M. Zhu, B. Wang, and W. Chen,
    “PromptMagician: Interactive prompt engineering for text-to-image creation,” *IEEE
    Transactions on Visualization and Computer Graphics*, vol. 30, no. 1, 2024.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[91] Y. Feng, X. Wang, K. K. Wong, S. Wang, Y. Lu, M. Zhu, B. Wang, 和 W. Chen,
    “PromptMagician：用于文本到图像创作的互动提示工程，” *IEEE 视觉化与计算机图形学学报*，第 30 卷，第 1 期，2024年。'
- en: 10 Biography Section
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10 传记部分
- en: '| ![[Uncaptioned image]](img/78eb170cd42d083995a036bba7e80812.png) | Jiaying
    Lu is currently a Master student in the State Key Lab of CAD&CG at Zhejiang University,
    China. She received the B.E. degree in Computer Science and Technology from the
    Zhejiang University, China in 2022\. Her research interests include LLM agent
    and visual analytics. |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| ![[无标题图像]](img/78eb170cd42d083995a036bba7e80812.png) | 陆佳颖目前是中国浙江大学CAD&CG国家重点实验室的硕士生。她在2022年获得了中国浙江大学计算机科学与技术的学士学位。她的研究兴趣包括LLM代理和视觉分析。
    |'
- en: '| ![[Uncaptioned image]](img/c0f6a0f94e4b66a278db0fef57093c06.png) | Bo Pan
    is currently a Ph.D. candidate in the State Key Lab of CAD&CG at Zhejiang University,
    China. He received the BS degree in Electrical and Computer Engineering from the
    University of Illinois Urbana-Champaign and Zhejiang University in 2022\. His
    research interests include visualization and deep learning. |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| ![[无标题图像]](img/c0f6a0f94e4b66a278db0fef57093c06.png) | 潘博目前是中国浙江大学CAD&CG国家重点实验室的博士研究生。他在2022年获得了伊利诺伊大学香槟分校和浙江大学的电气与计算机工程学士学位。他的研究兴趣包括可视化和深度学习。
    |'
- en: '| ![[Uncaptioned image]](img/d5f81452825546473936271caf23be1c.png) | Jieyi
    Chen is currently a Master student in the State Key Lab of CAD&CG at Zhejiang
    University, China. She received the B.E. degree from the Zhejiang University of
    Technology, China in 2023\. Her research interests include visualization and visual
    analytics. |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| ![[无标题图像]](img/d5f81452825546473936271caf23be1c.png) | 陈洁怡目前是中国浙江大学CAD&CG国家重点实验室的硕士生。她在2023年获得了中国浙江工业大学的学士学位。她的研究兴趣包括可视化和视觉分析。
    |'
- en: '| ![[Uncaptioned image]](img/fe4a813a169419f4c46688f899ad2919.png) | Yingchaojie
    Feng is currently a Ph.D. candidate in the State Key Lab of CAD&CG at Zhejiang
    University, China. He received the B.E. degree in software engineering from the
    Zhejiang University of Technology, China in 2020\. His research interests include
    data visualization, human-computer interaction, and natural language processing.
    For more details, please refer to https://yingchaojiefeng.github.io/. |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| ![[无标题图像]](img/fe4a813a169419f4c46688f899ad2919.png) | 冯迎超杰目前是中国浙江大学CAD&CG国家重点实验室的博士研究生。他在2020年获得了中国浙江工业大学的软件工程学士学位。他的研究兴趣包括数据可视化、人机交互和自然语言处理。有关更多细节，请参考
    [https://yingchaojiefeng.github.io/](https://yingchaojiefeng.github.io/)。 |'
- en: '| ![[Uncaptioned image]](img/d2d8e3ded670626afec498ce163bf41c.png) | Jingyuan
    Hu is an undergraduate in the Chu Kochen Honors College at Zhejiang University.
    His research interests include visualization and visual analytics. |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| ![[无标题图像]](img/d2d8e3ded670626afec498ce163bf41c.png) | 胡静远是浙江大学楚克宪荣誉学院的本科生。他的研究兴趣包括可视化和视觉分析。
    |'
- en: '| ![[Uncaptioned image]](img/ed49a6d26f3357f25bfcc891ec137614.png) | Yuchen
    Peng is currently a Ph.D candidate in the State Key Laboratory of Blockchain and
    Data Security from the Zhejiang University. He received the B.E. degree in computer
    science and technology from the Zhejiang University, China in 2022\. His research
    interests include database system and data management in machine learning. |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| ![[无标题图像]](img/ed49a6d26f3357f25bfcc891ec137614.png) | 彭宇辰目前是浙江大学区块链与数据安全国家重点实验室的博士研究生。他在2022年获得了中国浙江大学计算机科学与技术的学士学位。他的研究兴趣包括数据库系统和机器学习中的数据管理。
    |'
- en: '| ![[Uncaptioned image]](img/057e55915c899dd13d8a77886e2d5efa.png) | Wei Chen
    is a professor in the State Key Lab of CAD&CG at Zhejiang University. His current
    research interests include visualization and visual analytics. He has published
    more than 80 IEEE/ACM Transactions and IEEE VIS papers. He actively served in
    many leading conferences and journals, like IEEE PacificVIS steering committee,
    ChinaVIS steering committee, paper cochairs of IEEE VIS, IEEE PacificVIS, IEEE
    LDAV and ACM SIGGRAPH Asia VisSym. He is an associate editor of IEEE TVCG, IEEE
    TBG, ACM TIST, IEEE T-SMC-S, IEEE TIV, IEEE CG&A, FCS, and JOV. More information
    can be found at: http://www.cad.zju.edu.cn/home/chenwei. |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| ![[无标题图像]](img/057e55915c899dd13d8a77886e2d5efa.png) | 陈伟是中国浙江大学CAD&CG国家重点实验室的教授。他目前的研究兴趣包括可视化和视觉分析。他已经发表了超过80篇IEEE/ACM
    Transactions和IEEE VIS论文。他积极参与了许多领先的会议和期刊，如IEEE PacificVIS指导委员会、中国VIS指导委员会、IEEE
    VIS、IEEE PacificVIS、IEEE LDAV和ACM SIGGRAPH Asia VisSym的论文联合主席。他还是IEEE TVCG、IEEE
    TBG、ACM TIST、IEEE T-SMC-S、IEEE TIV、IEEE CG&A、FCS和JOV的副编辑。更多信息请访问: [http://www.cad.zju.edu.cn/home/chenwei](http://www.cad.zju.edu.cn/home/chenwei)。
    |'
