- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '分类: 未分类'
- en: 'date: 2024-09-08 18:50:56'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-08 18:50:56'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'ChatCite: LLM Agent with Human Workflow Guidance for Comparative Literature
    Summary'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'ChatCite: 带有人工工作流指导的 LLM 代理，用于比较文学总结'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2403.02574](https://ar5iv.labs.arxiv.org/html/2403.02574)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2403.02574](https://ar5iv.labs.arxiv.org/html/2403.02574)
- en: Yutong Li¹, Lu Chen^(2,3), Aiwei Liu¹, Kai Yu^(2,3),Lijie Wen¹ ¹Tsinghua University,
    Beijing, China
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Yutong Li¹, Lu Chen^(2,3), Aiwei Liu¹, Kai Yu^(2,3), Lijie Wen¹ ¹清华大学，北京，中国
- en: ²X-LANCE Lab, Department of Computer Science and Engineering
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ²X-LANCE 实验室，计算机科学与工程系
- en: MoE Key Lab of Artificial Intelligence, SJTU AI Institute
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: MoE 人工智能重点实验室，上海交通大学 AI 研究所
- en: Shanghai Jiao Tong University, Shanghai, China
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 上海交通大学，上海，中国
- en: ³Suzhou Laboratory, Suzhou, China
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ³苏州实验室，苏州，中国
- en: li-yt21@mails.tsinghua.edu.cn, chenlusz@sjtu.edu.cn, wenlj@tsinghua.edu.cn
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: li-yt21@mails.tsinghua.edu.cn, chenlusz@sjtu.edu.cn, wenlj@tsinghua.edu.cn
- en: Abstract
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: The literature review is an indispensable step in the research process. It provides
    the benefit of comprehending the research problem and understanding the current
    research situation while conducting a comparative analysis of prior works. However,
    literature summary is challenging and time consuming. The previous LLM-based studies
    on literature review mainly focused on the complete process, including literature
    retrieval, screening, and summarization. However, for the summarization step,
    simple CoT method often lacks the ability to provide extensive comparative summary.
    In this work, we firstly focus on the independent literature summarization step
    and introduce *ChatCite*¹¹1Our code will be released after the review process.,
    an LLM agent with human workflow guidance for comparative literature summary.
    This agent, by mimicking the human workflow, first extracts key elements from
    relevant literature and then generates summaries using a Reflective Incremental
    Mechanism. In order to better evaluate the quality of the generated summaries,
    we devised a LLM-based automatic evaluation metric, G-Score, in refer to the human
    evaluation criteria. The *ChatCite* agent outperformed other models in various
    dimensions in the experiments. The literature summaries generated by *ChatCite*
    can also be directly used for drafting literature reviews.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 文献综述是研究过程中的一个不可或缺的步骤。它有助于理解研究问题和当前的研究现状，同时进行先前工作的比较分析。然而，文献总结是具有挑战性和耗时的。以往基于
    LLM 的文献综述研究主要集中在完整的过程，包括文献检索、筛选和总结。然而，对于总结步骤，简单的 CoT 方法通常缺乏提供广泛比较总结的能力。在这项工作中，我们首先关注独立的文献总结步骤，并引入*ChatCite*¹¹1我们的代码将在审稿过程后发布。，一个带有人工工作流指导的
    LLM 代理，用于比较文学总结。该代理通过模仿人类工作流程，首先从相关文献中提取关键元素，然后使用反射增量机制生成总结。为了更好地评估生成总结的质量，我们设计了一种基于
    LLM 的自动评估指标 G-Score，以参考人工评估标准。*ChatCite* 代理在各种维度的实验中表现优于其他模型。*ChatCite* 生成的文献总结也可以直接用于撰写文献综述。
- en: 1 Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 介绍
- en: 'As the rapid advancement of academic research, scholars must delve into existing
    literature to understand past studies, recognize future research trends, and find
    innovative approaches in their fields. Crafting a literature review entails searching
    for relevant literature and conducting detailed comparative summarization. It
    typically involves two main steps: literature collection followed by literature
    summary generation based on the collected sources. However, organizing a high-quality
    literature review necessitates scholars to engage in thorough analysis, organization,
    comparison, and integration of an extensive of related works, which is often a
    challenging and time-consuming task.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 随着学术研究的快速发展，学者们必须深入现有文献，以了解过去的研究，识别未来的研究趋势，并在其领域中寻找创新的方法。撰写文献综述涉及搜索相关文献并进行详细的比较总结。通常包括两个主要步骤：文献收集，随后基于收集的来源生成文献总结。然而，组织高质量的文献综述需要学者们进行全面的分析、组织、比较和整合大量相关工作，这通常是一项具有挑战性和耗时的任务。
- en: '![Refer to caption](img/7d20cb798e0ae7ca7c3b5568230c8839.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/7d20cb798e0ae7ca7c3b5568230c8839.png)'
- en: 'Figure 1: Literature Summary Task Description'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '图 1: 文献总结任务描述'
- en: Therefore, Hoang and Kan ([2010](#bib.bib9)) have proposed the automatic generation
    of literature summary. However, machine-generated literature summaries often encounter
    challenges like information omission, lack of linguistic fluency, and insufficient
    comparative analysis. In traditional models, summaries generated through extraction
    and abstraction approach may miss key information due to the limitations of the
    model, leading to the lack of crucial points or findings of the generated summaries.
    Some automated systems may lack the ability for in-depth comparative analysis,
    potentially resulting in literature summaries that lack a comprehensive understanding
    of the relevant research in the field.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，Hoang和Kan（[2010](#bib.bib9)）提出了自动生成文献摘要的方法。然而，机器生成的文献摘要通常面临诸如信息遗漏、语言流畅性不足和比较分析不充分等挑战。在传统模型中，通过提取和抽象方法生成的摘要可能因模型的限制而遗漏关键信息，导致生成的摘要缺少重要点或发现。一些自动化系统可能缺乏深入比较分析的能力，可能导致文献摘要对相关研究缺乏全面理解。
- en: In recent years, with the rapid development of large language models (LLMs)
    Radford et al. ([2019](#bib.bib16)); Brown et al. ([2020](#bib.bib4)), their powerful
    capabilities in natural language generation tasks have been demonstrated across
    various tasks, that provides possibilities for handling longer texts and generating
    comprehensive summaries. Researchers have started exploring how to leverage LLMs
    to generate automatic literature summaries. Wei et al. ([2023](#bib.bib18)) propose
    a Chain-of-Thought (CoT) prompting method to enhance the ability of large language
    models to perform complex reasoning. CoT allows LLMs to devise their own plan,
    resulting in generated text that aligns more closely with human preferences.Recent
    study by Huang and Tan ([2023](#bib.bib10)) and Agarwal et al. ([2024](#bib.bib3))
    on literature review has focused more on how to retrieve relevant papers more
    accurately and neglected research on literature summarization. They use only simple
    CoT guidance to generate literature summaries, resulting in a lack of comparative
    and organizational analysis. Large language models, despite their fluent language
    generation, struggle to consistently produce comparative literature summaries
    due to their unpredictable an stochastic nature. The length limitations of these
    models require a two-step summarization approach, increasing the risk of information
    omission during abstract generation.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，随着大语言模型（LLMs）的快速发展，Radford等人（[2019](#bib.bib16)）；Brown等人（[2020](#bib.bib4)）展示了它们在自然语言生成任务中的强大能力，这为处理更长的文本和生成全面的摘要提供了可能性。研究人员已经开始探索如何利用LLMs生成自动文献摘要。Wei等人（[2023](#bib.bib18)）提出了一种链式思维（CoT）提示方法，以增强大语言模型进行复杂推理的能力。CoT允许LLMs制定自己的计划，从而生成与人类偏好更为一致的文本。Huang和Tan（[2023](#bib.bib10)）以及Agarwal等人（[2024](#bib.bib3)）的最新研究集中于如何更准确地检索相关文献，却忽视了文献总结的研究。他们仅使用简单的CoT指导生成文献摘要，导致缺乏比较性和组织性分析。尽管大语言模型生成的语言流畅，但由于其不可预测和随机的特性，难以持续生成比较性的文献摘要。这些模型的长度限制要求采用两步总结方法，增加了在生成摘要过程中信息遗漏的风险。
- en: 'In this work, we focus on the independent literature summarization task, aiming
    to generate a comprehensive comparative literature summary through a certain collection
    of literature and a description of the proposed work, as illustrated in Figure
    [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ ChatCite: LLM Agent with Human Workflow
    Guidance for Comparative Literature Summary"). To address these challenges mentioned
    above, our work proposes *ChatCite*, a LLM-based agent guided by human workflow.
    Different from simple CoT prompting approach, the agent is designed with the human
    workflow guidance, rather than formulating the generation process in a black-box
    manner, ensuring a more stable generation of higher-quality generic summaries.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '在这项工作中，我们专注于独立的文献总结任务，旨在通过一定数量的文献和对所提议工作的描述生成全面的比较性文献摘要，如图[1](#S1.F1 "Figure
    1 ‣ 1 Introduction ‣ ChatCite: LLM Agent with Human Workflow Guidance for Comparative
    Literature Summary")所示。为了解决上述挑战，我们的工作提出了*ChatCite*，一种基于LLM的代理，受人类工作流指导。与简单的CoT提示方法不同，该代理设计了人类工作流指导，而不是以黑箱方式制定生成过程，从而确保更稳定地生成更高质量的通用摘要。'
- en: 'Furthermore, quality assessment for generative tasks has always been a challenge.
    Prior studies on literature summarization have primarily relied on text summarization
    metrics, such as ROUGE (Lin ([2004a](#bib.bib12))). However, traditional text
    summary evaluation metrics, like ROUGE, are not sufficient to assess the quality
    of literature summaries. More comprehensive evaluation criteria covering multiple
    dimensions are required to ensure that the generated literature summaries truly
    meet the requirements. Therefore, we combine human studies on literature reviews
    Justitia and Wang ([2022](#bib.bib11)) to formulate the evaluation criteria for
    literature summaries from multiple dimensions ²²2Six evaluation dimensions are:
    Consistency, Coherence, Comparative, Integrity, Fluency, Cite Accuracy., and propose
    an LLM-based automatic evaluation metric, G-Score. Experimental results demonstrate
    its consistency with human evaluations.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，生成任务的质量评估一直是一个挑战。以往关于文献总结的研究主要依赖于文本总结指标，如ROUGE（Lin ([2004a](#bib.bib12)))。然而，传统的文本总结评估指标，如ROUGE，并不足以评估文献总结的质量。需要更全面的评估标准，涵盖多个维度，以确保生成的文献总结真正符合要求。因此，我们结合了对文献综述的人工研究Justitia和Wang
    ([2022](#bib.bib11))，从多个维度制定了文献总结的评估标准。六个评估维度是：一致性、连贯性、比较性、完整性、流畅性、引用准确性，并提出了一种基于LLM的自动评估指标G-Score。实验结果表明其与人工评估的一致性。
- en: 'In this paper, we summarize our main contributions of our framework as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们总结了我们框架的主要贡献如下：
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: we focus on the independent literature summarization step of literature review,
    and introduce *ChatCite*, an LLM agent with human workflow guidance for comparative
    literature summary.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们专注于文献综述中的独立文献总结步骤，并引入了*ChatCite*，一个具有人工工作流程指导的LLM代理，用于比较文献总结。
- en: •
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Based on research on literature summaries, we have developed a multidimensional
    quality assessment criterion for literature summaries. Additionally, we propose
    an LLM-based automatic evaluation metric, G-Score, demonstrating results consistent
    with human preferences.
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于对文献总结的研究，我们开发了一个多维度的文献总结质量评估标准。此外，我们提出了一种基于LLM的自动评估指标G-Score，结果与人工偏好一致。
- en: •
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The experimental results indicate that *ChatCite* outperforms other LLM-based
    literature summarization methods in all quality dimensions. The literature summaries
    produced by *ChatCite* can be directly utilized for drafting literature reviews.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 实验结果表明*ChatCite*在所有质量维度上优于其他基于LLM的文献总结方法。由*ChatCite*生成的文献总结可以直接用于撰写文献综述。
- en: •
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We demonstrate that LLMs with human workflow guidance, have the ability to effectively
    perform comprehensive comparative summarization of multiple documents. Therefore,
    we infer that Large Language Models (LLMs) have the potential to handle more complex
    inferential summarization tasks.
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们展示了具有人工工作流程指导的LLMs能够有效地对多个文档进行全面的比较总结。因此，我们推测大语言模型（LLMs）有潜力处理更复杂的推理总结任务。
- en: '2 Related Work³³3Our related work utilizes summaries generated by ChatCite
    with GPT-4 as a draft, with minimal refinement. The information is comprehensive
    with minimal errors. The generated results organize the literature and include
    comparative analysis. The generated results are presented in the appendix (Table
    [4](#A1.T4 "Table 4 ‣ A.2 Related work draft for this paper generated by ChatCite
    with GPT-4.0 ‣ Appendix A Appendix ‣ ChatCite: LLM Agent with Human Workflow Guidance
    for Comparative Literature Summary")).'
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '相关工作我们的相关工作利用由ChatCite生成的GPT-4草稿，经过最小的修订。信息全面，错误最小。生成的结果整理了文献并包括了比较分析。生成的结果在附录中展示（表[4](#A1.T4
    "Table 4 ‣ A.2 Related work draft for this paper generated by ChatCite with GPT-4.0
    ‣ Appendix A Appendix ‣ ChatCite: LLM Agent with Human Workflow Guidance for Comparative
    Literature Summary")）。'
- en: In recent years, there is abundant research on generated literature summaries
    with the initial proposal made by Hoang and Kan ([2010](#bib.bib9)), to automate
    related work summarization created by a topic-related work summary based on an
    extractive approach. To generate citation sentence, Xing et al. ([2020](#bib.bib19))
    adopted a multi-source pointer-generator network with cross-attention mechanism,
    while AbuRa’ed et al. ([2020](#bib.bib1)) utilized the ARWG system, employing
    a neural sequence learning process and Ge et al. ([2021](#bib.bib7)) proposed
    a BACO framework based on background knowledge and content. Furthermore, Chen
    et al. ([2021](#bib.bib5)) employed the Relation-aware Related Work Generator
    (RRG) to generate citation paragraphs while Chen et al. ([2022](#bib.bib6)) applied
    contrastive learning to generate target-aware related work segments. Yet traditional
    generation methods cannot generate the conprehensive coherent literature review
    due to the size of their model and the lack of the coherent and procedural language
    continuity.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，对生成文献摘要的研究十分丰富，最初由 Hoang 和 Kan ([2010](#bib.bib9)) 提出，旨在通过基于抽取的方法创建的主题相关工作摘要来自动化相关工作总结。为了生成引用句，Xing
    等人 ([2020](#bib.bib19)) 采用了带有交叉注意机制的多源指针生成网络，而 AbuRa’ed 等人 ([2020](#bib.bib1))
    使用了 ARWG 系统，采用了神经序列学习过程，Ge 等人 ([2021](#bib.bib7)) 提出了基于背景知识和内容的 BACO 框架。此外，Chen
    等人 ([2021](#bib.bib5)) 采用了关系感知相关工作生成器（RRG）生成引用段落，而 Chen 等人 ([2022](#bib.bib6))
    则应用对比学习生成目标感知的相关工作片段。然而，传统的生成方法由于模型规模和缺乏连贯的程序化语言连续性，无法生成全面连贯的文献综述。
- en: Large Language Models (LLMs), such as GPT (Radford et al. ([2019](#bib.bib16)),
    Brown et al. ([2020](#bib.bib4))), have demonstrated their powerful capabilities
    in natural language generation tasks. The study by Huang and Tan ([2023](#bib.bib10))
    on the use of AI tools like ChatGPT in writing scientific review articles reveals
    the potential benefits and drawbacks of artificial intelligence in academic writing.
    Building on these insights, Agarwal et al. ([2024](#bib.bib3)) introduces the
    LitLLM toolkit, which overcomes challenges such as generating hallucinated content
    and overlooking recent research by adopting Retrieval Augmented Generation (RAG)
    principles, specialized prompting, and instructive techniques. However, these
    studies only applied a simple Chain of Thought (CoT) to the search and filtering
    process in literature reviews, resulting in poor readability. By comparison, *ChatCite*
    focuses on the independent task of text summarization, aiming to generate higher-quality
    summaries.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs），如GPT（Radford 等人 ([2019](#bib.bib16))，Brown 等人 ([2020](#bib.bib4)))，在自然语言生成任务中展示了其强大的能力。Huang
    和 Tan ([2023](#bib.bib10)) 对使用像 ChatGPT 这样的 AI 工具撰写科学综述文章的研究揭示了人工智能在学术写作中的潜在益处和缺点。基于这些见解，Agarwal
    等人 ([2024](#bib.bib3)) 介绍了 LitLLM 工具包，通过采用检索增强生成（RAG）原则、专业提示和指导技术，克服了生成虚假内容和忽视最新研究等挑战。然而，这些研究仅将简单的思维链（CoT）应用于文献综述中的搜索和过滤过程，导致可读性差。相比之下，*ChatCite*
    专注于文本摘要的独立任务，旨在生成更高质量的摘要。
- en: Furthermore, this paper introduced a multi-dimensional G-Score evaluation metric
    inspired by the previous attempt to use Large Language Models (LLMs) through chain-of-thought
    methods to evaluate the quality of natural language generation (NLG) systems (Liu
    et al. ([2023](#bib.bib14)), Goyal et al. ([2023](#bib.bib8))) which is more consistent
    with human evaluation compared to traditional ROUGE metrics (Lin ([2004b](#bib.bib13))).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，本文介绍了一种多维度 G-Score 评估指标，灵感来自于先前尝试使用思维链方法通过大型语言模型（LLMs）来评估自然语言生成（NLG）系统的质量（Liu
    等人 ([2023](#bib.bib14))，Goyal 等人 ([2023](#bib.bib8)))，与传统的 ROUGE 指标（Lin ([2004b](#bib.bib13))）相比，更符合人类评估。
- en: 3 ChatCite
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 ChatCite
- en: '![Refer to caption](img/08d5cc0b859ede181a311e18a7e1a590.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/08d5cc0b859ede181a311e18a7e1a590.png)'
- en: 'Figure 2: The *ChatCite* consists of two modules, the Key Element Extractor
    and the Reflective Incremental Generator. The agent mimicking human workflow generates
    literature summary utilizing the Key Element Extractor to process the proposed
    work description and reference paper in Reference Papers Set. It then iteratively
    generates literature summaries using each paper in the Reference Papers Set, proposed
    work key elements and previous summary generated with the Reflective Incremental
    Generator. This process is iteratively repeated until a complete related work
    summary is generated, and the optimal one is selected as the final result.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：*ChatCite*包括两个模块，即关键元素提取器和反射递增生成器。模仿人类工作流程的代理利用关键元素提取器处理提出的工作描述和参考论文集中的参考论文，从而生成文献总结。然后，它使用参考论文集中的每篇论文、提出的工作关键元素以及与反射递增生成器生成的先前总结来迭代生成文献总结。这个过程会反复进行，直到生成一个完整的相关工作总结，并选择最佳结果作为最终结果。
- en: 'The literature review task can be decomposed into two sub tasks: relevant papers
    retrieval and literature summaries generation. This work focuses on the independent
    task of literature summary generation. Our task is to generate the literature
    summary based on the proposed work description D and a certain reference papers
    set $\textit{R}=\left\{r_{1},r_{2},...,r_{n}\right\}$.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 文献综述任务可以分解为两个子任务：相关论文检索和文献总结生成。本文关注文献总结生成这一独立任务。我们的任务是根据提出的工作描述D和一定的参考论文集$\textit{R}=\left\{r_{1},r_{2},...,r_{n}\right\}$生成文献总结。
- en: 'Diverging from other types of summaries, such as news summaries, the literature
    summary generated directly by large language models using simple Chain-of-Thought
    (CoT) guidance in existing work mainly faces the following issues:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 与新闻总结等其他类型的总结不同，现有工作中使用简单的链式思维（CoT）指导的大型语言模型直接生成的文献总结主要面临以下问题：
- en: 'Key Elements missing: Because of the window limitations of LLMs, generating
    the complete literature review directly is challenging. Typically, a two-step
    approach is used involving summarization and literature review generation. However,
    this process can lead to the loss of key elements during summarization. Even if
    the entire literature summary can be directly generated, using the entire text
    may result in mistakes in understanding key elements and the loss of such elements.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 关键元素缺失：由于LLMs的窗口限制，直接生成完整的文献综述是具有挑战性的。通常，采用两步法，即总结和文献综述生成。然而，这个过程可能会导致在总结过程中丢失关键元素。即使能够直接生成整个文献总结，使用整个文本也可能导致对关键元素的理解错误和丢失。
- en: 'Lack of Comparative Analysis: Comparative analysis is crucial in literature
    summary, requiring an analysis on the limitations and advantages of existing research
    methods, and focusing on differences and similarities in methods, experimental
    design, dataset usage, and more. Directly using CoT-generated results often lacks
    comparative analysis.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 缺乏比较分析：比较分析在文献总结中至关重要，需要分析现有研究方法的局限性和优势，并关注方法、实验设计、数据集使用等方面的差异和相似性。直接使用CoT生成的结果通常缺乏比较分析。
- en: 'Lack of Organizational Structure: The literature summary generated solely by
    CoT tends to be discrete for each paper, lacking classification for similar works
    and an organized structure for the literature review.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 缺乏组织结构：由CoT单独生成的文献总结往往针对每篇论文都显得离散，缺乏对类似工作的分类和文献综述的组织结构。
- en: 'To address these challenges, we have proposed an LLM agent for comparative
    literature summary with human workflow guidance, *ChatCite*, consisting two modules:
    the Key Element Extractor and the Reflective Incremental Generator, as illustrated
    in Figure [2](#S3.F2 "Figure 2 ‣ 3 ChatCite ‣ ChatCite: LLM Agent with Human Workflow
    Guidance for Comparative Literature Summary"). In this process, we utilize large
    language models as both generation and evaluation components, eliminating the
    need for additional model training and improving the quality of generated text
    to some extent.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '为解决这些挑战，我们提出了一种用于比较文献总结的LLM代理，带有人类工作流程指导，*ChatCite*，包括两个模块：关键元素提取器和反射递增生成器，如图[2](#S3.F2
    "Figure 2 ‣ 3 ChatCite ‣ ChatCite: LLM Agent with Human Workflow Guidance for
    Comparative Literature Summary")所示。在这个过程中，我们利用大型语言模型作为生成和评估组件，消除了额外模型训练的需求，并在一定程度上提高了生成文本的质量。'
- en: 'The generation process guided by human workflow is as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 人类工作流程指导下的生成过程如下：
- en: '1.'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: The proposed work description and reference papers in the reference papers set
    are initially processed using the Key Element Extractor separately.
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提议的工作描述和参考论文集中的参考论文最初分别使用关键元素提取器进行处理。
- en: '2.'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Iteratively generate literature summaries using reference papers set. In each
    iteration, use the comparative summarizer to generate a comparative analysis summary.
    Then, use the reflective evaluator to vote on the generated candidate results,
    ranking the vote score and retaining the top $n_{c}$ results. Iterate continuously
    until all reference papers are processed.
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用参考论文集迭代生成文献总结。在每次迭代中，使用比较总结器生成比较分析总结。然后，使用反射评估器对生成的候选结果进行投票，按投票分数排名并保留前 $n_{c}$
    个结果。持续迭代直到所有参考论文都处理完毕。
- en: The final output is selected based on the highest voting score among the generated
    related work summaries.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 最终输出是基于生成的相关工作总结中最高投票分数的选择结果。
- en: 'In this section, we first elaborate on the specifics of the Key Element Extractor
    (§[3.1](#S3.SS1 "3.1 Key Element Extractor ‣ 3 ChatCite ‣ ChatCite: LLM Agent
    with Human Workflow Guidance for Comparative Literature Summary")) and the Reflective
    Iterative Generator module (§[3.2](#S3.SS2 "3.2 Reflective incremental Generator
    ‣ 3 ChatCite ‣ ChatCite: LLM Agent with Human Workflow Guidance for Comparative
    Literature Summary")) in detail.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们首先详细阐述关键元素提取器（§[3.1](#S3.SS1 "3.1 Key Element Extractor ‣ 3 ChatCite
    ‣ ChatCite: LLM Agent with Human Workflow Guidance for Comparative Literature
    Summary")）和反射增量生成器模块（§[3.2](#S3.SS2 "3.2 Reflective incremental Generator ‣ 3
    ChatCite ‣ ChatCite: LLM Agent with Human Workflow Guidance for Comparative Literature
    Summary")）的具体细节。'
- en: 3.1 Key Element Extractor
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 关键元素提取器
- en: 'In order to retain sufficient key element for literature summary, we create
    seven simple guiding questions based on analysis Justitia and Wang ([2022](#bib.bib11))
    on literature review. We concatenate theses questions and the content required
    extraction as prompt to instruct LLMs extract the key elements. For each element,
    a simple question (shown in Figure [2](#S3.F2 "Figure 2 ‣ 3 ChatCite ‣ ChatCite:
    LLM Agent with Human Workflow Guidance for Comparative Literature Summary")) is
    set to guide the model in extraction, and these questions are $Q_{e}=\left[q_{1},q_{2},...,q_{7}\right].$
    . Using LLM as extraction decoder to extract key elements and storing them in
    memory.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '为了保留足够的关键元素用于文献总结，我们根据 Justitia 和 Wang ([2022](#bib.bib11)) 对文献综述的分析，创建了七个简单的指导问题。我们将这些问题和所需提取的内容连接在一起，作为提示来指导
    LLM 提取关键元素。对于每个元素，设置一个简单的问题（如图 [2](#S3.F2 "Figure 2 ‣ 3 ChatCite ‣ ChatCite: LLM
    Agent with Human Workflow Guidance for Comparative Literature Summary")）来引导模型进行提取，这些问题为
    $Q_{e}=\left[q_{1},q_{2},...,q_{7}\right].$。使用 LLM 作为提取解码器提取关键元素，并将其存储在内存中。'
- en: 3.2 Reflective incremental Generator
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 反射增量生成器
- en: To overcome the challenges of lacking comparative analysis and organizational
    structure in literature reviews generated by LLMs, we designed the reflective
    incremental generator. The generator uses the Comparative Summarizer to continue
    writing comparative summaries, combining the results from the previous turn and
    the key elements of the proposed work and reference papers. It then utilizes the
    reflective evaluator to filter the generated results. This process is interatively
    applied to each reference paper in the reference papers set until all reference
    papers are processed. The best result is ultimately retained as the model’s generated
    output.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服 LLM 生成的文献综述中缺乏比较分析和组织结构的挑战，我们设计了反射增量生成器。该生成器使用比较总结器来继续编写比较总结，将前一轮的结果与提出的工作和参考论文的关键元素结合起来。然后，它利用反射评估器过滤生成的结果。这个过程会迭代地应用于参考论文集中的每一篇参考论文，直到所有参考论文都处理完毕。最终的最佳结果被保留作为模型的生成输出。
- en: 3.2.1 Comparative Summarizer
  id: totrans-55
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 比较总结器
- en: 'For turn $i$ Here, to enhance the comparability and organization of the generated
    summaries, comparative summarization guidance are provided: "Considering the relationship
    between the reference paper and the target paper, as well as existing references
    in the previously completed related work, while retaining the content of all referenced
    papers mentioned in the previously completed related work."'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 对于轮次 $i$ 这里，为了增强生成总结的可比性和组织性，提供了比较总结指导：“考虑参考论文与目标论文之间的关系，以及在先前完成的相关工作中存在的参考文献，同时保留在先前完成的相关工作中提到的所有参考论文内容。”
- en: 3.2.2 Reflective Mechanism
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2 反射机制
- en: Due to significant uncertainty in text generation tasks, we employ reflective
    generation to enhance the quality and stability of generated paragraphs. Here,
    we use LLMs as Reflective Evaluator to vote $n_{v}$.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 由于文本生成任务中存在显著的不确定性，我们采用反射生成来提高生成段落的质量和稳定性。在这里，我们使用 LLM 作为反射评估器进行 $n_{v}$ 票选。
- en: Then we sort the scores, and retain the top $n_{c}$ . These selected candidates
    will be used for the next round of incremental generation. This approach helps
    identify the most promising results, ensures the quality of the generated text,
    and enhances generation stability.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们对得分进行排序，保留前 $n_{c}$ 个。这些被选中的候选结果将用于下一轮的增量生成。这种方法有助于识别最有前景的结果，确保生成文本的质量，并提高生成的稳定性。
- en: 3.2.3 Reflective Incremental Generator Algorithm
  id: totrans-60
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.3 反射增量生成器算法
- en: 'In implementing reflective incremental generation, we drew inspiration from
    the breadth-first search algorithm for trees (Algorithm [1](#alg1 "Algorithm 1
    ‣ 3.2.3 Reflective Incremental Generator Algorithm ‣ 3.2 Reflective incremental
    Generator ‣ 3 ChatCite ‣ ChatCite: LLM Agent with Human Workflow Guidance for
    Comparative Literature Summary")).'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '在实现反射增量生成时，我们受到树的广度优先搜索算法的启发（算法 [1](#alg1 "算法 1 ‣ 3.2.3 反射增量生成器算法 ‣ 3.2 反射增量生成器
    ‣ 3 ChatCite ‣ ChatCite: LLM 代理与人类工作流指导的比较文学总结")）。'
- en: Algorithm 1 Reflective Incremental Generator
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 1 反射增量生成器
- en: 0:  Proposed work key element $pro$
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '0: 提议工作的关键元素 $pro$'
- en: 'notes: $G()$ results.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 注释：$G()$ 结果。
- en: '4 G-Score: LLM-based automatic Evaluation Metrics'
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '4 G-Score: 基于 LLM 的自动评估指标'
- en: The evaluation of generative tasks has always been challenging. Previous research
    on literature summarization predominantly depended on text summarization metrics,
    like ROUGE (Lin ([2004a](#bib.bib12))). However, conventional text summary evaluation
    metrics such as ROUGE fall short in gauging the quality of literature summaries.
    It is crucial to adopt more comprehensive evaluation criteria across various dimensions
    to guarantee that the generated literature summaries align with the necessary
    standards. Here, inspired by G-Eval Liu et al. ([2023](#bib.bib14)), we attempted
    to assess it using LLMs. We established six-dimensional metrics for automatic
    evaluation based on research on literature summaries Justitia and Wang ([2022](#bib.bib11)).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 生成任务的评估一直具有挑战性。以前对文献总结的研究主要依赖于文本总结指标，如 ROUGE（Lin ([2004a](#bib.bib12))）。然而，传统的文本总结评估指标如
    ROUGE 在评估文献总结质量方面存在不足。至关重要的是采纳更全面的评估标准，以保证生成的文献总结符合必要的标准。在这里，受到 G-Eval Liu 等人
    ([2023](#bib.bib14)) 的启发，我们尝试使用 LLMs 进行评估。我们基于 Justitia 和 Wang ([2022](#bib.bib11))
    的文献总结研究，建立了用于自动评估的六维指标。
- en: Evaluation Steps. We used Large Language Models (LLMs) to score the six dimensions
    of generic quality and voted for the best summary from a series of model-generated
    summaries. Specially, to ensure fairness and consistency in evaluation, we simultaneously
    scored and voted for the generated results of multiple models in a single conversation.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 评估步骤：我们使用大语言模型（LLMs）对通用质量的六个维度进行评分，并从一系列模型生成的总结中选出最佳总结。特别地，为确保评估的公平性和一致性，我们在一次对话中同时对多个模型生成的结果进行评分和投票。
- en: 'Evaluation Criterion:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 评估标准：
- en: 'Consistency (1-5): Content consistency between the generated summary and the
    gold summary. The generated summary must not contain content that conflicts with
    the gold summary.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 一致性（1-5）：生成的总结与金标准总结之间的内容一致性。生成的总结必须不包含与金标准总结冲突的内容。
- en: 'Coherence(1-5): The quality of language coherence in generated summaries, which
    should not just be a heap of related information.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 连贯性（1-5）：评估生成总结中的语言连贯性质量，不应仅仅是相关信息的堆砌。
- en: 'Comparative (1-5): Assess the extent to whether the generated summary conducts
    a comparative analysis on references and proposed work. Whether it provides an
    integrated summary of similar related works.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 比较性（1-5）：评估生成的总结是否对参考文献和提出的工作进行了比较分析。是否提供了类似相关工作的综合总结。
- en: 'Integrity (1-5): Assess if the summary covers essential elements: research
    context, reference paper summaries, past research evaluation, contributions, and
    innovations.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 完整性（1-5）：评估总结是否涵盖了关键要素：研究背景、参考文献总结、过去的研究评估、贡献和创新。
- en: 'Fluency (1-5): Assess the quality of the summary in terms of grammar, spelling,
    punctuation, word choice, and sentence structure.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 流畅性（1-5）：评估总结在语法、拼写、标点、词汇选择和句子结构方面的质量。
- en: 'Cite Accuracy(1-5): Assess whether the summary correctly cites reference paper
    in the format ‘[Reference i]’ when mention the reference paper.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 引用准确性（1-5）：评估总结在提及参考文献时是否正确引用了‘[Reference i]’格式的参考论文。
- en: 5 Experiment
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 实验
- en: 'We validate the capabilities of our proposed *ChatCite* agent by verifying
    the following questions: 1) Is the literature summary generated by *ChatCite*
    better than that generated directly by LLMs with CoT and other LLM-based literature
    review approach? 2) Do all the modules in the *ChatCite* contribute to its effectiveness?
    3) What specific impact do the modules in the *ChatCite* framework have on the
    quality of generated summary?'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过验证以下问题来验证我们提出的*ChatCite*代理的能力：1）*ChatCite*生成的文献总结是否优于直接由LLMs使用CoT和其他基于LLM的文献综述方法生成的文献总结？2）*ChatCite*中的所有模块是否对其效果有所贡献？3）*ChatCite*框架中的模块对生成总结的质量有何具体影响？
- en: 'In this section, we conducted a series of experiments to address these questions.
    Firstly, we introduced our experimental setup (§[5.1](#S5.SS1 "5.1 Experimental
    Setup ‣ 5 Experiment ‣ ChatCite: LLM Agent with Human Workflow Guidance for Comparative
    Literature Summary")). We compared the performance of existing large language
    models (LLMs) in directly generating related work under zero-shot and few-shot
    settings, as well as the best-performing LLM-based literature review approach
    (§[5.2](#S5.SS2 "5.2 Main Results ‣ 5 Experiment ‣ ChatCite: LLM Agent with Human
    Workflow Guidance for Comparative Literature Summary")). Additionally, we performed
    ablation analysis on each module in our agent to verify their respective capabilities
    (§[5.3](#S5.SS3 "5.3 Ablation Analysis ‣ 5 Experiment ‣ ChatCite: LLM Agent with
    Human Workflow Guidance for Comparative Literature Summary")). Finally, we conducted
    a human study for a detailed quality assessment of the generated related work
    summaries (§[5.4](#S5.SS4 "5.4 Human Study ‣ 5 Experiment ‣ ChatCite: LLM Agent
    with Human Workflow Guidance for Comparative Literature Summary")).'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们进行了一系列实验以解决这些问题。首先，我们介绍了我们的实验设置（§[5.1](#S5.SS1 "5.1 实验设置 ‣ 5 实验 ‣ ChatCite:
    带有人类工作流程指导的LLM代理用于比较文献总结")）。我们比较了现有大语言模型（LLMs）在零样本和少样本设置下直接生成相关工作的性能，以及表现最佳的基于LLM的文献综述方法（§[5.2](#S5.SS2
    "5.2 主要结果 ‣ 5 实验 ‣ ChatCite: 带有人类工作流程指导的LLM代理用于比较文献总结")）。此外，我们对我们代理的每个模块进行了消融分析，以验证它们各自的能力（§[5.3](#S5.SS3
    "5.3 消融分析 ‣ 5 实验 ‣ ChatCite: 带有人类工作流程指导的LLM代理用于比较文献总结")）。最后，我们进行了人工研究，以详细评估生成的相关工作总结的质量（§[5.4](#S5.SS4
    "5.4 人工研究 ‣ 5 实验 ‣ ChatCite: 带有人类工作流程指导的LLM代理用于比较文献总结")）。'
- en: 5.1 Experimental Setup
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 实验设置
- en: '| Model | ROUGE Metrics | G-Score | G-Prf. |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | ROUGE指标 | G-Score | G-Prf. |'
- en: '| ROUGE-1 | ROUGE-2 | ROUGE-L | (1-5) | (%) |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| ROUGE-1 | ROUGE-2 | ROUGE-L | (1-5) | (%) |'
- en: '| GPT-3.5 w/zero shot | 26.01 | 6.11 | 24.02 | 3.4102 | 2.21 |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 w/zero shot | 26.01 | 6.11 | 24.02 | 3.4102 | 2.21 |'
- en: '| GPT-3.5 w/few shot | 25.84 | 6.01 | 23.55 | 3.5968 | 10.80 |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 w/few shot | 25.84 | 6.01 | 23.55 | 3.5968 | 10.80 |'
- en: '| GPT-4 w/zero shot | 30.02 | 8.03 | 27.97 | 3.5076 | 26.40 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 w/zero shot | 30.02 | 8.03 | 27.97 | 3.5076 | 26.40 |'
- en: '| GPT-4 w/few shot | 15.52 | 1.78 | 14.20 | 1.6621 | 0.21 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 w/few shot | 15.52 | 1.78 | 14.20 | 1.6621 | 0.21 |'
- en: '| LitLLM w/GPT-4 | 27.08 | 6.07 | 24.94 | 3.5448 | 24.51 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| LitLLM w/GPT-4 | 27.08 | 6.07 | 24.94 | 3.5448 | 24.51 |'
- en: '| ChatCite | 25.30 | 6.36 | 23.13 | 4.0642 | 35.86 |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| ChatCite | 25.30 | 6.36 | 23.13 | 4.0642 | 35.86 |'
- en: 'Table 1: Main Results: The results are automatically evaluated using ROUGE-1/2/L
    (F1) and the GPT-4.0 evaluator. G-Score represents the total score assessed by
    the GPT-4.0 evaluator, while G-Prf. indicates the model preferences among the
    five models.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：主要结果：结果使用ROUGE-1/2/L（F1）和GPT-4.0评估器自动评估。G-Score表示GPT-4.0评估器评估的总分，而G-Prf.
    表示五个模型中的模型偏好。
- en: 'Dataset. We conducted experiments to validate on a paper dataset NudtRwG-Citation
    dataset Wang et al. ([2020](#bib.bib17)) designed for related work summarization
    task. This test set includes 50 academic research papers in the field of Computer
    Science, each data containing the following components: 1) A target paper requiring
    related work generation without the related work section. 2) A ground truth related
    work section. 3) Reference papers of the target paper (annotated with authors
    and years).'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集。我们在NudtRwG-Citation数据集Wang等人（[2020](#bib.bib17)）上进行了实验，以验证用于相关工作总结任务的论文数据集。该测试集包括50篇计算机科学领域的学术研究论文，每个数据包含以下组件：1）一个目标论文，需要生成相关工作而没有相关工作部分。2）一个真实的相关工作部分。3）目标论文的参考文献（标注了作者和年份）。
- en: Each paper is well-received in conferences of computational linguistics and
    natural language processing, with an average citation number reaching 63.59, which
    indicates these target papers are widely recognized by the academic community.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 每篇论文在计算语言学和自然语言处理领域的会议上都得到了良好的接受，平均引用次数达到 63.59，这表明这些目标论文在学术界得到了广泛认可。
- en: Models. For the LLMs baseline, we employed the GPT-3.5 model (Ouyang et al.
    ([2022](#bib.bib15))) with a 16k context window (version gpt-3.5-turbo-1106) and
    the GPT-4.0 model (Achiam et al. ([2023](#bib.bib2))) with a 128K context window
    (gpt-4-turbo-preview). We evaluated their performance under zero-shot and few-shot
    settings. For the previously best-performing LLM-based literature review approach,
    we use the recently proposed approach LitLLM Agarwal et al. ([2024](#bib.bib3))
    as the baseline. We reproduce their ability to generate literature summaries according
    to the CoT prompt mentioned in their paper. To showcase its best performance,
    we use GPT-4.0 as the decoder for the LitLLM baseline. For our model, due to the
    high cost of GPT-4.0, we conducted experiment based on GPT-3.5 (version gpt-3.5-turbo-1106)
    as the decoder for the experiment. For evaluation, we use GPT-4.0 (gpt-4-turbo-preview)
    as decoder.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 模型。对于 LLM 基准，我们使用了具有 16k 上下文窗口（版本 gpt-3.5-turbo-1106）的 GPT-3.5 模型（Ouyang 等人
    ([2022](#bib.bib15))) 和具有 128K 上下文窗口（gpt-4-turbo-preview）的 GPT-4.0 模型（Achiam 等人
    ([2023](#bib.bib2)))。我们在零样本和少量示例设置下评估了它们的表现。对于之前表现最好的 LLM 基于文献综述方法，我们使用了最近提出的
    LitLLM Agarwal 等人 ([2024](#bib.bib3)) 作为基准。我们根据他们论文中提到的 CoT 提示重现了生成文献总结的能力。为了展示其最佳表现，我们使用
    GPT-4.0 作为 LitLLM 基准的解码器。对于我们的模型，由于 GPT-4.0 的高成本，我们基于 GPT-3.5（版本 gpt-3.5-turbo-1106）作为实验解码器进行实验。对于评估，我们使用
    GPT-4.0（gpt-4-turbo-preview）作为解码器。
- en: 'Implementation. In zero-shot setting, for GPT-3.5 model, due to the limitation
    of the context window, a two-step approach is used for generation: 1) summarizing
    and then generating with the prompt $\left[p_{s}\right]=$ is directly used for
    summarization.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 实施。在零样本设置中，对于 GPT-3.5 模型，由于上下文窗口的限制，使用了两步生成方法：1）总结，然后使用提示 $\left[p_{s}\right]=$
    直接用于总结。
- en: In the few-shot setting, we add the instruction "Follow the writing style of
    the example but without including any content from the example. {Examples}" to
    the zero-shot prompt.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在少量示例设置中，我们在零样本提示中添加了“遵循示例的写作风格，但不包含示例中的任何内容。{Examples}”的指令。
- en: Evaluation metrics. We utilize both automatic metrics and human evaluations
    to assess the generic result. We employed traditional automatic metrics for summarization
    evaluation - the vocabulary overlap measures ROUGE-1/2/L (F1) (Lin ([2004b](#bib.bib13))),
    our proposed LLM-based evaluation metrics G-Eval, and human evaluation under the
    same evaluation criterion.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 评估指标。我们使用自动指标和人工评估来评估通用结果。我们采用了传统的自动总结评估指标——词汇重叠度的 ROUGE-1/2/L (F1) (Lin ([2004b](#bib.bib13)))，我们提出的基于
    LLM 的评估指标 G-Eval，以及在相同评估标准下的人工评估。
- en: 5.2 Main Results
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 主要结果
- en: 'We compared the performance of different baseline models on the paper test
    set (see Table [1](#S5.T1 "Table 1 ‣ 5.1 Experimental Setup ‣ 5 Experiment ‣ ChatCite:
    LLM Agent with Human Workflow Guidance for Comparative Literature Summary")).
    In traditional summary evaluation metrics, such as ROUGE, GPT-4.0 achieved the
    best results under zero-shot settings. Although ROUGE scores of *ChatCite* may
    be slightly lower than GPT-4.0 with zero-shot, its performance in quality metrics
    generated by LLMs and the preference of LLMs is far superior to results obtained
    directly from other LLM baselines.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '我们比较了不同基准模型在论文测试集上的表现（见表格 [1](#S5.T1 "Table 1 ‣ 5.1 Experimental Setup ‣ 5
    Experiment ‣ ChatCite: LLM Agent with Human Workflow Guidance for Comparative
    Literature Summary")）。在传统的总结评估指标，如 ROUGE 中，GPT-4.0 在零样本设置下达到了最佳结果。虽然*ChatCite*的
    ROUGE 得分可能略低于 GPT-4.0 的零样本得分，但其在由 LLM 生成的质量指标和 LLM 的偏好方面远远优于直接从其他 LLM 基准中获得的结果。'
- en: Surprisingly, GPT-4.0 performed poorly in few-shot settings.It is found that
    influenced by examples in the few-shot, resulting in irrelevant and erroneous
    summaries after case study. Notably, LitLLM with GPT-4.0 produced outcomes similar
    to GPT-4.0 in zero-shot but significantly lower than *ChatCite*.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 令人惊讶的是，GPT-4.0 在少量示例设置中的表现不佳。研究发现，由于受到少量示例的影响，导致案例研究后生成了无关且错误的总结。值得注意的是，使用 GPT-4.0
    的 LitLLM 产生的结果类似于 GPT-4.0 在零样本设置中的表现，但明显低于*ChatCite*。
- en: Therefore, we conclude that "ChatCite performs best among LLM-based literature
    summarization methods, and the approach following the human workflow guidance
    is superior to the results obtained by the Chain of Thought (CoT) method."
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们得出结论：“ChatCite 在基于LLM的文献总结方法中表现最佳，并且遵循人工工作流程指导的方法优于链式思维（CoT）方法所获得的结果。”
- en: 5.3 Ablation Analysis
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 消融分析
- en: 'Our proposed framework can be decomposed into two components: the Key Element
    Extractor and the Reflective Incremental Generator. The Reflective Incremental
    Generator comprises two key points: the Comparative Incremental Generation and
    the Reflective Mechanism. Therefore, we will analyze the three part separately.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出的框架可以分解为两个组件：关键元素提取器和反射增量生成器。反射增量生成器包含两个关键点：比较增量生成和反射机制。因此，我们将分别分析这三个部分。
- en: '| Model | ROUGE Metrics | G-Score | G-Prf. |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | ROUGE指标 | G-Score | G-Prf. |'
- en: '| --- | --- | --- | --- |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| ROUGE-1 | ROUGE-2 | ROUGE-L | (1-5) | (%) |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| ROUGE-1 | ROUGE-2 | ROUGE-L | (1-5) | (%) |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| GPT-3.5 w/few shot | 25.84 | 6.01 | 23.55 | 3.2426 | 2.84 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 w/few shot | 25.84 | 6.01 | 23.55 | 3.2426 | 2.84 |'
- en: '| -w/o Elem. | 24.38 | 5.81 | 22.36 | 4.0016 | 22.11 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| -w/o Elem. | 24.38 | 5.81 | 22.36 | 4.0016 | 22.11 |'
- en: '| ChatCite -w/o Incre. | 24.72 | 5.93 | 22.40 | 3.8195 | 35.34 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| ChatCite -w/o Incre. | 24.72 | 5.93 | 22.40 | 3.8195 | 35.34 |'
- en: '| ChatCite | 25.30 | 6.36 | 23.13 | 4.1064 | 39.71 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| ChatCite | 25.30 | 6.36 | 23.13 | 4.1064 | 39.71 |'
- en: 'Table 2: Ablation Results: This table presents the ablation results on the
    model’s Key Element Extractor and Comparative Incremental Generator, with the
    results of GPT-3.5 w/few-shot used as the baseline for GPT-3.5.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：消融结果：此表展示了模型的关键元素提取器和比较增量生成器的消融结果，其中 GPT-3.5 w/few-shot 的结果作为 GPT-3.5 的基线。
- en: Key Element Extractor. To validate the effectiveness of the Key Element Extractor,
    we chose ChatCite without the Key Element Extractor as a comparison. The ChatCite
    without Key Element Extractor used the baseline summary prompt $\left[p_{s}\right]$
    to directly summarize the article and then use Reflective Incremental Generator
    generate the literature summary.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 关键元素提取器。为了验证关键元素提取器的有效性，我们选择了不使用关键元素提取器的 ChatCite 作为对比。未使用关键元素提取器的 ChatCite
    使用了基线总结提示 $\left[p_{s}\right]$ 来直接总结文章，然后使用反射增量生成器生成文献总结。
- en: 'In Table [2](#S5.T2 "Table 2 ‣ 5.3 Ablation Analysis ‣ 5 Experiment ‣ ChatCite:
    LLM Agent with Human Workflow Guidance for Comparative Literature Summary"), comparing
    the results of ChatCite without Key Element Extractor and ChatCite, we can observe
    that ChatCite performs better in all dimensions of ROUGE metrics and the metrics
    generated by the LLM based evaluator. Therefore, it indicates that the Topic Extractor
    module plays an effective role in literature summarization.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '在表[2](#S5.T2 "Table 2 ‣ 5.3 Ablation Analysis ‣ 5 Experiment ‣ ChatCite: LLM
    Agent with Human Workflow Guidance for Comparative Literature Summary")中，对比了不使用关键元素提取器的
    ChatCite 和 ChatCite 的结果，我们可以观察到 ChatCite 在所有 ROUGE 指标维度和 LLM 基于评估器生成的指标中表现更好。因此，这表明
    Topic Extractor 模块在文献总结中发挥了有效作用。'
- en: Comparative Incremental Mechanism. To validate the effectiveness of the Comparative
    Incremental Mechanism, we choose ChatCite without Comparative Incremental Mechanism
    as comparison, following the few-shot baseline prompt $\left[p_{s}\right]$ and
    few-shot examples as prompts to directly generate literature summaries from the
    text after standard summarization. Considering controlling variables for the incremental
    mechanism, we also incorporated CoT writing instructions into the method to ensure
    that the experimental results are not influenced by the writing instructions.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 比较增量机制。为了验证比较增量机制的有效性，我们选择了不使用比较增量机制的 ChatCite 作为对比，使用基线少样本提示 $\left[p_{s}\right]$
    和少样本示例作为提示，从文本中直接生成文献总结，在标准总结之后。考虑到增量机制的控制变量，我们还将 CoT 写作指令纳入该方法，以确保实验结果不受写作指令的影响。
- en: 'In Table [2](#S5.T2 "Table 2 ‣ 5.3 Ablation Analysis ‣ 5 Experiment ‣ ChatCite:
    LLM Agent with Human Workflow Guidance for Comparative Literature Summary"), when
    comparing ChatCite with and without the Comparative Incremental Mechanism, the
    results indicate that ChatCite achieves higher ROUGE metrics and LLM-based evaluation
    metrics compared to ChatCite without the Comparative Incremental Mechanism. This
    suggests that the Comparative Incremental Mechanism significantly contributes
    to the effectiveness of literature summarization in the ChatCite framework.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '在表[2](#S5.T2 "表 2 ‣ 5.3 消融分析 ‣ 5 实验 ‣ ChatCite: 带有人类工作流程指导的 LLM 代理进行比较文学摘要")中，当比较有无比较增量机制的ChatCite时，结果表明，ChatCite在ROUGE指标和基于LLM的评估指标上表现更高。这表明比较增量机制对ChatCite框架中文献总结的有效性有显著贡献。'
- en: '![Refer to caption](img/11c2f73179cfb30d8ad99c242ebc5c43.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/11c2f73179cfb30d8ad99c242ebc5c43.png)'
- en: 'Figure 3: Ablation Study on the Reflective Mechanism. The upper and lower whiskers
    represent the overall range of the data, while the box displays the distribution
    of the middle 50% of the dataset, with a line inside the box representing the
    median of the data. Data points outside the boxplot are considered outliers, indicating
    data points that significantly deviate from the box and whiskers. It can be observed
    that ChatCite performs more stable across all dimensions.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '图 3: 反射机制的消融研究。上须和下须表示数据的总体范围，而箱体显示数据集中心50%的分布，箱体内部的线代表数据的中位数。箱线图外的数据点被视为异常值，表示显著偏离箱体和须的数据点。可以观察到，ChatCite在所有维度上表现更加稳定。'
- en: 'Reflective Mechanism. In conclusion, we analyzed the reflective mechanism’s
    impact. G-Scores for various dimensions were assessed based on multiple results
    from *ChatCite*, both with and without the Reflective Mechanism. The boxplot results
    in Figure [3](#S5.F3 "Figure 3 ‣ 5.3 Ablation Analysis ‣ 5 Experiment ‣ ChatCite:
    LLM Agent with Human Workflow Guidance for Comparative Literature Summary") show
    similarities between the outcome of *ChatCite* with and without the Reflective
    Mechanism. However, the overall results of *ChatCite* are slightly higher, with
    minimal distribution outliers, suggesting a more stable generation of results.
    This affirms that the Reflective Mechanism effectively improves the quality and
    stability of the text generated in *ChatCite*.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '反射机制。总之，我们分析了反射机制的影响。通过*ChatCite*的多个结果，评估了各种维度的G-Score，无论是否具有反射机制。图[3](#S5.F3
    "图 3 ‣ 5.3 消融分析 ‣ 5 实验 ‣ ChatCite: 带有人类工作流程指导的 LLM 代理进行比较文学摘要")中的箱线图结果显示，*ChatCite*在有无反射机制的结果之间存在相似之处。然而，*ChatCite*的整体结果略高，且分布异常值最小，这表明结果生成更加稳定。这证明反射机制有效地提高了*ChatCite*生成文本的质量和稳定性。'
- en: Overall, through ablation experiments on three components, we have demonstrated
    that "each part of *ChatCite* framework contributes to the improvement of the
    quality and stability of the generated results in literature summaries".
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，通过对三个组件的消融实验，我们展示了“*ChatCite*框架的每个部分都有助于提高文献摘要生成结果的质量和稳定性”。
- en: 5.4 Human Study
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 人类研究
- en: To conduct a fine-grained analysis on the quality of summary generated by *ChatCite*
    and to understand the specific impact of individual modules on summarization,
    we conducted a human study. Several researchers in the field of computer science,
    with experience in academic writing, were enlisted to evaluate 10 selected samples
    using the same set of criteria and choose the better summary.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对*ChatCite*生成的摘要质量进行细致分析，并了解各个模块对摘要的具体影响，我们进行了人类研究。几位计算机科学领域的研究人员，他们有学术写作经验，被征集来使用相同的标准评估10个选定的样本，并选择更好的摘要。
- en: '![Refer to caption](img/a62dc5a109d42f5438ad66e912a40e77.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/a62dc5a109d42f5438ad66e912a40e77.png)'
- en: 'Figure 4: Human Evaluation vs. G-Score on six dimensions of the generic summary
    quality. The scoring results of the G-Score model is aligned with the distribution
    of human evaluations.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '图 4: 人类评估与G-Score在六个维度上的普通摘要质量。G-Score模型的评分结果与人类评估的分布一致。'
- en: '![Refer to caption](img/e8d02914cd529c7e43df005c85a34918.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e8d02914cd529c7e43df005c85a34918.png)'
- en: 'Figure 5: Human Preference: Average annotator vote distribution for better
    generated summaries.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '图 5: 人类偏好：对生成的更好摘要的平均标注者投票分布。'
- en: 'Figure [4](#S5.F4 "Figure 4 ‣ 5.4 Human Study ‣ 5 Experiment ‣ ChatCite: LLM
    Agent with Human Workflow Guidance for Comparative Literature Summary") demonstrates
    the results of G-score metric align with human preferences. Specifically, the
    method incorporating Key Element Extractor exhibits higher content consistency.
    Summaries generated with the Comparative Incremental generation Mechanism demonstrate
    better characteristics of literature review, excelling in organizational structure,
    comparative analysis, and citation accuracy. The fluency of results generated
    by LLMs is consistently high, with relatively low variation among different models.
    In terms of human evaluation, summaries generated without the Comparative Incremental
    Mechanism exhibit overly discrete descriptions for each paper, lacking coherence.
    Unexpectedly, this feature was not captured in the assessment by the large models.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '图 [4](#S5.F4 "Figure 4 ‣ 5.4 Human Study ‣ 5 Experiment ‣ ChatCite: LLM Agent
    with Human Workflow Guidance for Comparative Literature Summary") 演示了 G-score
    指标与人类偏好的对齐情况。具体来说，结合关键元素提取器的方法表现出更高的内容一致性。使用比较增量生成机制生成的总结展示了更好的文献综述特征，在组织结构、比较分析和引用准确性方面表现优越。LLMs
    生成的结果流畅性一致较高，各模型间的变异较小。在人类评估方面，未使用比较增量机制生成的总结对每篇论文的描述过于零散，缺乏连贯性。出乎意料的是，大模型的评估未能捕捉到这一特征。'
- en: 'Additionally, Figure [5](#S5.F5 "Figure 5 ‣ 5.4 Human Study ‣ 5 Experiment
    ‣ ChatCite: LLM Agent with Human Workflow Guidance for Comparative Literature
    Summary") shows the extinct human preference of the ChatCite model over the others.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '此外，图 [5](#S5.F5 "Figure 5 ‣ 5.4 Human Study ‣ 5 Experiment ‣ ChatCite: LLM
    Agent with Human Workflow Guidance for Comparative Literature Summary") 显示了 ChatCite
    模型在用户偏好上的优势。'
- en: 6 Conclusion
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: LLMs are powerful tools in generating literature summaries, however, it poses
    the challenges of information omission, lack of comparative summaries and organizational
    deficiencies. In ChatCite, the Key Element Extractor contributes to improving
    content consistency, and the Comparative Incremental Generator effectively enhances
    the organizational structure, comparative analysis, and citation accuracy of the
    generated summary. Additionally, the literature summaries generated by ChatCite
    can be directly used for drafting literature reviews. Our study also demonstrated
    that the approach following the human workflow guidance is superior to the results
    obtained by the Chain of Thought (CoT) method. In the future, we hope that our
    work will further inspire research on complex inferential writing, enabling the
    full potential of LLMs in open-ended writing tasks.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）在生成文献总结方面是强大的工具，但它们面临信息遗漏、缺乏比较总结和组织结构不足的挑战。在 ChatCite 中，关键元素提取器有助于提高内容一致性，而比较增量生成器有效增强了生成总结的组织结构、比较分析和引用准确性。此外，ChatCite
    生成的文献总结可以直接用于撰写文献综述。我们的研究还表明，遵循人工工作流程指导的方法优于链式思维（CoT）方法获得的结果。未来，我们希望我们的工作能够进一步激发对复杂推理写作的研究，充分发挥大型语言模型在开放式写作任务中的潜力。
- en: Limitations
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 局限性
- en: In this work, we focused mainly on the summarization of specific topics based
    on the selected literatures instead of the collection and the filtering of the
    literatures themselves. The datasets primarily consist of research articles in
    the area of computer science and lack research articles from other fields of study
    to validate our model. Our experimentation used Chat GPT 3.5 as the tool for validating
    the quality of the generated content and the functionalities of the various components
    of the agent. We did not explore any additional spec that can influence the result
    of the GPT3.5 model nor the possibility of using other models as the validation
    tool. The evaluation of the generated content poses a great challenge. We evaluated
    the generated results from multiple dimensions using G-Score as the performance
    metric, but there is still room for improvements over the accuracy of the automatic
    evaluation process. The generated results exhibit randomness and instability.
    While our proposed approach demonstrates the effectiveness of the agent, the results
    have shown further research potential on improving the stability and quality of
    the output.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们主要关注了基于选定文献的特定主题总结，而不是文献的收集和筛选。数据集主要由计算机科学领域的研究文章组成，缺乏其他领域的研究文章来验证我们的模型。我们的实验使用了
    Chat GPT 3.5 作为验证生成内容质量和代理各种组件功能的工具。我们没有探讨任何可能影响 GPT3.5 模型结果的附加规格，也没有考虑使用其他模型作为验证工具。生成内容的评估是一个重大挑战。我们使用
    G-Score 作为性能指标从多个维度评估了生成结果，但自动评估过程的准确性仍有改进空间。生成结果表现出随机性和不稳定性。尽管我们提出的方法展示了代理的有效性，但结果显示了进一步研究的潜力，以改善输出的稳定性和质量。
- en: Ethics Statement
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 伦理声明
- en: The dataset we used consists of research articles sourced only from publicly
    available papers, eliminating concerns about data origin. We employ large language
    models as generators used and only used for summarizing people’s ideas and literature
    and never on the innovative writing processes of the academic papers. However,
    if generated literature summaries are to be incorporated into academic paper writing,
    a review and editing of the generated results should be conducted. This ensures
    that academic writing content is free from harmful information and plagiarism
    issues.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的数据集仅由公开获取的研究文章构成，消除了数据来源的担忧。我们使用大型语言模型作为生成工具，仅用于总结他人的观点和文献，而不用于学术论文的创新写作过程。然而，如果生成的文献总结要纳入学术论文写作中，应对生成结果进行审查和编辑。这可以确保学术写作内容不含有害信息和剽窃问题。
- en: We will make our code publicly available to ensure experiment reproducibility.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将公开我们的代码，以确保实验的可重复性。
- en: References
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'AbuRa’ed et al. (2020) Ahmed AbuRa’ed, Horacio Saggion, Alexander Shvets, and
    Àlex Bravo. 2020. [Automatic related work section generation: experiments in scientific
    document abstracting](https://doi.org/10.1007/s11192-020-03630-2). 125(3).'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'AbuRa’ed et al. (2020) Ahmed AbuRa’ed, Horacio Saggion, Alexander Shvets, and
    Àlex Bravo. 2020. [Automatic related work section generation: experiments in scientific
    document abstracting](https://doi.org/10.1007/s11192-020-03630-2). 125(3).'
- en: Achiam et al. (2023) Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad,
    Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman,
    Shyamal Anadkat, et al. 2023. Gpt-4 technical report. *arXiv preprint arXiv:2303.08774*.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Achiam et al. (2023) Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad,
    Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman,
    Shyamal Anadkat, et al. 2023. Gpt-4 technical report. *arXiv preprint arXiv:2303.08774*.
- en: 'Agarwal et al. (2024) Shubham Agarwal, Issam H. Laradji, Laurent Charlin, and
    Christopher Pal. 2024. [Litllm: A toolkit for scientific literature review](http://arxiv.org/abs/2402.01788).'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Agarwal et al. (2024) Shubham Agarwal, Issam H. Laradji, Laurent Charlin, and
    Christopher Pal. 2024. [Litllm: A toolkit for scientific literature review](http://arxiv.org/abs/2402.01788).'
- en: Brown et al. (2020) Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah,
    Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
    Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,
    Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher
    Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack
    Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario
    Amodei. 2020. [Language models are few-shot learners](http://arxiv.org/abs/2005.14165).
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown 等 (2020) Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared
    Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
    Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,
    Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher
    Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack
    Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, 和 Dario
    Amodei. 2020. [语言模型是少样本学习者](http://arxiv.org/abs/2005.14165)。
- en: 'Chen et al. (2021) Xiuying Chen, Hind Alamro, Mingzhe Li, Shen Gao, Xiangliang
    Zhang, Dongyan Zhao, and Rui Yan. 2021. [Capturing relations between scientific
    papers: An abstractive model for related work section generation](https://doi.org/10.18653/v1/2021.acl-long.473).
    In *Proceedings of the 59th Annual Meeting of the Association for Computational
    Linguistics and the 11th International Joint Conference on Natural Language Processing
    (Volume 1: Long Papers)*, pages 6068–6077, Online. Association for Computational
    Linguistics.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 (2021) Xiuying Chen, Hind Alamro, Mingzhe Li, Shen Gao, Xiangliang Zhang,
    Dongyan Zhao, 和 Rui Yan. 2021. [捕捉科学论文之间的关系：一种用于相关工作部分生成的抽象模型](https://doi.org/10.18653/v1/2021.acl-long.473).
    收录于 *第59届计算语言学协会年会和第11届国际联合自然语言处理会议（卷1：长篇论文）*，页码 6068–6077，在线。计算语言学协会。
- en: Chen et al. (2022) Xiuying Chen, Hind Alamro, Li Mingzhe, Shen Gao, Rui Yan,
    Xin Gao, and Xiangliang Zhang. 2022. [Target-aware abstractive related work generation
    with contrastive learning](https://api.semanticscholar.org/CorpusID:249097545).
    *Proceedings of the 45th International ACM SIGIR Conference on Research and Development
    in Information Retrieval*.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 (2022) Xiuying Chen, Hind Alamro, Li Mingzhe, Shen Gao, Rui Yan, Xin
    Gao, 和 Xiangliang Zhang. 2022. [目标感知的抽象相关工作生成与对比学习](https://api.semanticscholar.org/CorpusID:249097545).
    *第45届国际ACM SIGIR信息检索研究与发展大会论文集*。
- en: 'Ge et al. (2021) Yubin Ge, Ly Dinh, Xiaofeng Liu, Jinsong Su, Ziyao Lu, Ante
    Wang, and Jana Diesner. 2021. [BACO: A background knowledge- and content-based
    framework for citing sentence generation](https://doi.org/10.18653/v1/2021.acl-long.116).
    In *Proceedings of the 59th Annual Meeting of the Association for Computational
    Linguistics and the 11th International Joint Conference on Natural Language Processing
    (Volume 1: Long Papers)*, pages 1466–1478, Online. Association for Computational
    Linguistics.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ge 等 (2021) Yubin Ge, Ly Dinh, Xiaofeng Liu, Jinsong Su, Ziyao Lu, Ante Wang,
    和 Jana Diesner. 2021. [BACO: 一种基于背景知识和内容的引文生成框架](https://doi.org/10.18653/v1/2021.acl-long.116).
    收录于 *第59届计算语言学协会年会和第11届国际联合自然语言处理会议（卷1：长篇论文）*，页码 1466–1478，在线。计算语言学协会。'
- en: Goyal et al. (2023) Tanya Goyal, Junyi Jessy Li, and Greg Durrett. 2023. [News
    summarization and evaluation in the era of gpt-3](http://arxiv.org/abs/2209.12356).
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goyal 等 (2023) Tanya Goyal, Junyi Jessy Li, 和 Greg Durrett. 2023. [GPT-3 时代的新闻摘要和评估](http://arxiv.org/abs/2209.12356)。
- en: 'Hoang and Kan (2010) Cong Duy Vu Hoang and Min-Yen Kan. 2010. [Towards automated
    related work summarization20](https://aclanthology.org/C10-2049). In *Coling 2010:
    Posters*, pages 427–435, Beijing, China. Coling 2010 Organizing Committee.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hoang 和 Kan (2010) Cong Duy Vu Hoang 和 Min-Yen Kan. 2010. [自动化相关工作总结](https://aclanthology.org/C10-2049).
    收录于 *Coling 2010: Posters*，页码 427–435，北京，中国。Coling 2010 组委会。'
- en: 'Huang and Tan (2023) Jingshan Huang and Ming Tan. 2023. The role of chatgpt
    in scientific communication: writing better scientific review articles. *American
    Journal of Cancer Research*, 13(4):1148.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 和 Tan (2023) Jingshan Huang 和 Ming Tan. 2023. ChatGPT 在科学交流中的角色：写作更好的科学综述文章。*美国癌症研究杂志*，13(4):1148。
- en: 'Justitia and Wang (2022) Army Justitia and Hei-Chia Wang. 2022. Automatic related
    work section in scientific article: Research trends and future directions. In
    *2022 International Seminar on Intelligent Technology and Its Applications (ISITIA)*,
    pages 108–114\. IEEE.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Justitia 和 Wang (2022) Army Justitia 和 Hei-Chia Wang. 2022. 科学文章中的自动化相关工作部分：研究趋势与未来方向。收录于
    *2022 国际智能技术及其应用研讨会 (ISITIA)*，页码 108–114。IEEE。
- en: 'Lin (2004a) Chin-Yew Lin. 2004a. [Rouge: A package for automatic evaluation
    of summaries](https://api.semanticscholar.org/CorpusID:964287). In *Annual Meeting
    of the Association for Computational Linguistics*.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lin（2004a）林振耀。2004a。[ROUGE: 用于自动评估摘要的工具包](https://api.semanticscholar.org/CorpusID:964287)。在*计算语言学协会年会*上。'
- en: 'Lin (2004b) Chin-Yew Lin. 2004b. [ROUGE: A package for automatic evaluation
    of summaries](https://aclanthology.org/W04-1013). In *Text Summarization Branches
    Out*, pages 74–81, Barcelona, Spain. Association for Computational Linguistics.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lin（2004b）林振耀。2004b。[ROUGE: 用于自动评估摘要的工具包](https://aclanthology.org/W04-1013)。在*文本摘要分支*中，第74–81页，西班牙巴塞罗那。计算语言学协会。'
- en: 'Liu et al. (2023) Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu,
    and Chenguang Zhu. 2023. [G-eval: Nlg evaluation using gpt-4 with better human
    alignment](http://arxiv.org/abs/2303.16634).'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu等（2023）杨刘、丹·伊特、易聪·徐、朔航·王、若晨·徐和成光·朱。2023年。[G-eval: 使用GPT-4进行更好的人类对齐的NLG评估](http://arxiv.org/abs/2303.16634)。'
- en: Ouyang et al. (2022) Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll
    Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex
    Ray, et al. 2022. Training language models to follow instructions with human feedback.
    *Advances in Neural Information Processing Systems*, 35:27730–27744.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ouyang等（2022）龙欧阳、杰弗里·吴、徐江、迪奥戈·阿尔梅达、卡罗尔·温赖特、帕梅拉·米什金、崇张、桑迪尼·阿加瓦尔、卡塔里娜·斯拉马、亚历克斯·雷等。2022年。训练语言模型以遵循人类反馈的指令。*神经信息处理系统进展*，35:27730–27744。
- en: Radford et al. (2019) Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario
    Amodei, and Ilya Sutskever. 2019. [Language models are unsupervised multitask
    learners](https://api.semanticscholar.org/CorpusID:160025533).
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Radford等（2019）亚历克·拉德福德、杰夫·吴、雷旺·查尔德、大卫·卢安、达里奥·阿莫代伊和伊利亚·苏茨克弗。2019年。[语言模型是无监督的多任务学习者](https://api.semanticscholar.org/CorpusID:160025533)。
- en: 'Wang et al. (2020) Pancheng Wang, Shasha Li, Haifang Zhou, Jintao Tang, and
    Ting Wang. 2020. [Toc-rwg: Explore the combination of topic model and citation
    information for automatic related work generation](https://api.semanticscholar.org/CorpusID:210931840).
    *IEEE Access*, 8:13043–13055.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang等（2020）潘成王、莎莎·李、海芳·周、晋涛·唐和婷·王。2020年。[Toc-rwg: 探索主题模型与引用信息相结合用于自动生成相关工作的研究](https://api.semanticscholar.org/CorpusID:210931840)。*IEEE
    Access*，8:13043–13055。'
- en: Wei et al. (2023) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian
    Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2023. [Chain-of-thought prompting
    elicits reasoning in large language models](http://arxiv.org/abs/2201.11903).
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei等（2023）杰森·魏、薛志旺、戴尔·舒尔曼斯、马尔滕·博斯马、布莱恩·伊切特、费伊·夏、埃德·奇、阮华和丹尼·周。2023年。[链式思维提示引发大语言模型的推理](http://arxiv.org/abs/2201.11903)。
- en: 'Xing et al. (2020) Xinyu Xing, Xiaosheng Fan, and Xiaojun Wan. 2020. [Automatic
    generation of citation texts in scholarly papers: A pilot study](https://api.semanticscholar.org/CorpusID:220045125).
    In *Annual Meeting of the Association for Computational Linguistics*.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Xing等（2020）邢新宇、范晓生和万晓军。2020年。[学术论文中引用文本的自动生成: 一项初步研究](https://api.semanticscholar.org/CorpusID:220045125)。在*计算语言学协会年会*上。'
- en: Appendix A Appendix
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录A 附录
- en: A.1 An Example of generated results of all the models mentioned
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 所有提到的模型生成结果示例
- en: 'Table 3: An Example of literature summary results generated for Paper: BEL:
    Bagging for Entity Linking'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '表3: 为论文“BEL: 实体链接的袋装方法”生成的文献摘要结果示例'
- en: '| Gold literature Summary |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 黄金文献摘要 |'
- en: '| Statistical machine translation systems often rely on large-scale parallel
    and monolingual training corpora to generate translations of high quality. Unfortunately,
    statistical machine translation system often suffers from data sparsity problem
    due to the fact that phrase tables are extracted from the limited bilingual corpus.
    Much work has been done to address the data sparsity problem such as the pivot
    language approach (Wu and Wang,2007; Cohn and Lapata, 2007) and deep learning
    techniques (Devlin et al., 2014; Gao et al., 2014; Sundermeyer et al., 2014; Liu
    et al., 2014). On the problem of how to translate one source language to many
    target languages within one model, few work has been done in statistical machine
    translation. A related work in SMT is the pivot language approach for statistical
    machine translation which uses a commonly used language as a ”bridge” to generate
    source-target translation for language pair with few training corpus. Pivot based
    statistical machine translation is crucial in machine translation for resource-poor
    language pairs, such as Spanish to Chinese. Considering the problem of translating
    one source language to many target languages, pivot based SMT approaches does
    work well given a large-scale source language to pivot language bilingual corpus
    and large-scale pivot language to target languages corpus. However, in reality,
    language pairs between English and many other target languages may not be large
    enough, and pivot-based SMT sometimes fails to handle this problem. Our approach
    handles one to many target language translation in a different way that we directly
    learn an end to multi-end translation system that does not need a pivot language
    based on the idea of neural machine translation. Neural Machine translation is
    a emerging new field in machine translation, proposed by several work recently
    (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Bahdanau et al., 2014),
    aiming at end-to-end machine translation without phrase table extraction and language
    model training. Different from traditional statistical machine translation, neural
    machine translation encodes a variable-length source sentence with a recurrent
    neural network into a fixed-length vector representation and decodes it with another
    recurrent neural network from a fixed-length vector into variable-length target
    sentence. A typical model is the RNN encoder-decoder approach proposed by Bahdanau
    et al. (2014), which utilizes a bidirectional recurrent neural network to compress
    the source sentence information and fits the conditional probability of words
    in target languages with a recurrent manner. Moreover, soft alignment parameters
    are considered in this model. As a specific example model in this paper, we adopt
    a RNN encoder-decoder neural machine translation model for multi-task learning,
    though all neural network based model can be adapted in our framework. In the
    natural language processing field, a1724 notable work related with multi-task
    learning was proposed by Collobert et al. (2011) which shared common representation
    for input words and solve different traditional NLP tasks such as part-of-Speech
    tagging, name entity recognition and semantic role labeling within one framework,
    where the convolutional neural network model was used. Hatori et al. (2012) proposed
    to jointly train word segmentation, POS tagging and dependency parsing, which
    can also be seen as a multi-task learning approach. Similar idea has also been
    proposed by Li et al. (2014) in Chinese dependency parsing. Most of multi-task
    learning or joint training frameworks can be summarized as parameter sharing approaches
    proposed by Ando and Zhang (2005) where they jointly trained models and shared
    center parameters in NLP tasks. Researchers have also explored similar approaches
    (Sennrich et al., 2013; Cui et al., 2013) in statistical machine translation which
    are often refered as domain adaption. Our work explores the possibility of machine
    translation under the multitask framework by using the recurrent neural networks.
    To the best of our knowledge, this is thefirst trial of end to end machine translation
    under multi-task learning framework. |  | ChatCite with GPT-3.5 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: 统计机器翻译系统通常依赖于大规模的平行语料库和单语语料库来生成高质量的翻译。不幸的是，统计机器翻译系统常常因短语表从有限的双语语料库中提取而遭遇数据稀疏问题。为了解决数据稀疏问题，已经做了很多工作，例如枢纽语言方法（Wu
    和 Wang, 2007; Cohn 和 Lapata, 2007）和深度学习技术（Devlin 等, 2014; Gao 等, 2014; Sundermeyer
    等, 2014; Liu 等, 2014）。关于如何在一个模型中将一种源语言翻译成多种目标语言，统计机器翻译的研究较少。统计机器翻译中的相关工作是枢纽语言方法，它使用一种常用语言作为“桥梁”来生成源语言与目标语言的翻译，以应对训练语料较少的语言对。基于枢纽的统计机器翻译对于资源贫乏的语言对，如西班牙语到中文，至关重要。考虑到将一种源语言翻译成多种目标语言的问题，基于枢纽的统计机器翻译方法在给定大规模的源语言到枢纽语言的双语语料库和大规模的枢纽语言到目标语言的语料库时效果良好。然而，实际上，英语与许多其他目标语言之间的语言对可能不够大，基于枢纽的统计机器翻译有时无法处理这个问题。我们的方法以不同的方式处理一种源语言到多种目标语言的翻译，我们直接学习一个端到多端的翻译系统，而不需要基于枢纽语言，基于神经机器翻译的理念。神经机器翻译是机器翻译领域中新兴的领域，最近由若干工作提出（Kalchbrenner
    和 Blunsom, 2013; Sutskever 等, 2014; Bahdanau 等, 2014），旨在实现端到端的机器翻译，无需短语表提取和语言模型训练。与传统的统计机器翻译不同，神经机器翻译使用递归神经网络将变长的源句子编码成固定长度的向量表示，并用另一个递归神经网络将其解码成变长的目标句子。一个典型的模型是
    Bahdanau 等（2014）提出的 RNN 编码器-解码器方法，它利用双向递归神经网络压缩源句子信息，并以递归方式拟合目标语言中单词的条件概率。此外，该模型中还考虑了软对齐参数。作为本文的一个具体示例模型，我们采用了用于多任务学习的
    RNN 编码器-解码器神经机器翻译模型，尽管所有基于神经网络的模型都可以在我们的框架中进行适配。在自然语言处理领域，Collobert 等（2011）提出了一项与多任务学习相关的显著工作，该工作在一个框架中共享输入单词的共同表示，并解决不同的传统
    NLP 任务，如词性标注、命名实体识别和语义角色标注，其中使用了卷积神经网络模型。Hatori 等（2012）提出了联合训练词分割、词性标注和依存句法分析，这也可以视为一种多任务学习方法。Li
    等（2014）在中文依存句法分析中也提出了类似的想法。大多数多任务学习或联合训练框架可以总结为 Ando 和 Zhang（2005）提出的参数共享方法，他们在
    NLP 任务中联合训练模型并共享中心参数。研究人员还探索了类似的方法（Sennrich 等, 2013; Cui 等, 2013），这些方法通常被称为领域适应。我们的工作通过使用递归神经网络探索了在多任务框架下进行机器翻译的可能性。据我们所知，这是在多任务学习框架下进行端到端机器翻译的第一次尝试。
- en: '| Related Work The field of machine translation has witnessed remarkable progress
    in addressing data scarcity and enhancing translation quality. Early approaches
    such as the pivot language approach proposed by Wu and Wang (2007) [Reference
    1], and the triangulation method introduced by Cohn and Lapata (2007) [Reference
    2], focused on improving phrase-based statistical machine translation, particularly
    for language pairs with scarce resources. Additionally, Devlin et al. (2014) [Reference
    3] contributed by introducing a neural network joint model (NNJM) for machine
    translation, offering valuable insights into the formulation of a novel neural
    network joint model and techniques for enhancing machine translation performance.
    Moreover, Gao et al. (2014) [Reference 4] enriched the understanding of addressing
    data scarcity and improving translation quality by introducing a Continuous-space
    Phrase Translation Model (CPTM) to project source and target phrases into continuous-valued
    vector representations, complementing the approaches of previous researchers.
    Furthermore, Sundermeyer et al. (2014) [Reference 5] expanded the scope of machine
    translation by investigating the effectiveness of recurrent neural networks in
    translation modeling, contributing to the broader landscape of machine translation
    research. In the context of the target paper, which proposed a multi-task learning
    framework for machine translation, the works by Zhenghua Li et al. (2011) [Reference
    6] and Nal Kalchbrenner and Phil Blunsom (2013) [Reference 7] proved highly relevant.
    Zhenghua Li et al. (2011) proposed joint optimization for Chinese POS tagging
    and dependency parsing, offering valuable insights into joint optimization techniques.
    Similarly, Nal Kalchbrenner and Phil Blunsom (2013) [Reference 7] introduced recurrent
    continuous translation models (RCTMs), providing a new perspective in the domain
    of machine translation and contributing to the advancement of purely continuous
    sentence-level translation models. The work by Ilya Sutskever, Oriol Vinyals,
    and Quoc V. Le (2014) [Reference 8] on sequence to sequence learning with neural
    networks is also highly relevant to the target paper’s objectives. The paper addresses
    the challenge of mapping sequences to sequences using Deep Neural Networks (DNNs)
    and proposes a general end-to-end approach to sequence learning that makes minimal
    assumptions on the sequence structure, aligning with the multi-task learning framework
    proposed in the target paper. Additionally, the 9th reference paper by Ronan Collobert
    et al. (2011) [Reference 9] addresses the effectiveness of leveraging large unlabeled
    datasets and multitask supervised training to improve performance, aligning with
    the multi-task learning framework proposed in the target paper. The recently explored
    Incremental Joint Approach to Word Segmentation, POS Tagging, and Dependency Parsing
    in Chinese by Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, and Jun (2012) [Reference
    10] presents a joint model for word segmentation, POS tagging, and dependency
    parsing for Chinese, demonstrating significant improvements in accuracies of the
    three tasks over baseline models. The study’s positive results in Chinese segmentation
    accuracies and the effectiveness of the proposed joint model are highly relevant
    to the advancements in multi-task learning frameworks for machine translation,
    providing further insights into joint model approaches and their potential for
    improving translation quality. The 11th reference paper by Rie Kubota Ando and
    Tong Zhang (2005) focuses on learning predictive structures from multiple tasks
    and unlabeled data. It attempts to improve the performance of supervised learning
    algorithms by including unlabeled data and investigates a closely related problem
    that leads to a novel approach to semi-supervised learning. The paper introduces
    a general framework for structural learning and proposes algorithms for structural
    learning, demonstrating the effectiveness of the proposed algorithms in semi-supervised
    learning. In a similar vein, the proposed multi-task learning framework in the
    target paper aims to improve the translation quality and address data scarcity
    by leveraging multiple tasks and large-scale parallel training corpora. By integrating
    insights from Rie Kubota Ando and Tong Zhang (2005) [Reference 11] with existing
    literature, the target paper aligns with the broader trend of leveraging multiple
    tasks and unlabeled data to enhance machine learning models. The contributions
    of both the target paper and the referenced works collectively enrich the understanding
    of addressing data scarcity, enhancing translation quality, and advancing the
    capabilities of machine translation models, laying the foundation for the multi-task
    learning framework proposed in the target paper. These contributions provide valuable
    insights into the advancements in machine translation, emphasizing contributions
    to the research field and predicting potential future directions. |  | ChatCite
    without Key Elements Extractor |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: 相关工作：机器翻译领域在解决数据稀缺和提高翻译质量方面取得了显著进展。早期的方法如吴和王（2007）提出的**枢轴语言方法**[参考文献 1]，以及Cohn和Lapata（2007）介绍的**三角化方法**[参考文献
    2]，重点改善了基于短语的统计机器翻译，尤其是对资源稀缺的语言对。此外，Devlin等（2014）[参考文献 3]通过引入**神经网络联合模型（NNJM）**为机器翻译做出了贡献，提供了有关新型神经网络联合模型的形成和提高机器翻译性能的技术的宝贵见解。此外，Gao等（2014）[参考文献
    4]通过引入**连续空间短语翻译模型（CPTM）**，将源短语和目标短语投射到连续值向量表示中，丰富了对数据稀缺问题的理解，并补充了前人研究的方法。此外，Sundermeyer等（2014）[参考文献
    5]通过研究递归神经网络在翻译建模中的有效性，扩展了机器翻译的范围，为机器翻译研究的广阔领域做出了贡献。在目标论文的背景下，提出了一种用于机器翻译的**多任务学习框架**，Zhenghua
    Li等（2011）[参考文献 6]和Nal Kalchbrenner与Phil Blunsom（2013）[参考文献 7]的工作显示了高度相关性。Zhenghua
    Li等（2011）提出了**中文词性标注和依赖解析的联合优化**，提供了有关联合优化技术的宝贵见解。同样，Nal Kalchbrenner与Phil Blunsom（2013）[参考文献
    7]介绍了**递归连续翻译模型（RCTMs）**，在机器翻译领域提供了新的视角，并推动了纯连续句子级翻译模型的发展。Ilya Sutskever、Oriol
    Vinyals和Quoc V. Le（2014）[参考文献 8]关于**神经网络的序列到序列学习**的工作也与目标论文的目标高度相关。该论文解决了使用**深度神经网络（DNNs）**将序列映射到序列的挑战，并提出了一种对序列结构假设最小的通用端到端序列学习方法，与目标论文中提出的多任务学习框架相一致。此外，第9篇参考文献由Ronan
    Collobert等（2011）[参考文献 9]探讨了利用大规模未标记数据集和多任务监督训练来提高性能的有效性，与目标论文中提出的多任务学习框架相一致。最近，Jun
    Hatori、Takuya Matsuzaki、Yusuke Miyao和Jun（2012）[参考文献 10]探索的**增量联合方法**在中文词 segmentation、POS
    标注和依赖解析方面展示了显著的改进，相较于基线模型在准确性上的提升。该研究在中文分词准确性和所提联合模型的有效性方面的积极结果与机器翻译的多任务学习框架的进展密切相关，进一步提供了联合模型方法的见解及其提高翻译质量的潜力。第11篇参考文献由Rie
    Kubota Ando和Tong Zhang（2005）[参考文献 11]关注于从多任务和未标记数据中学习预测结构。它尝试通过包括未标记数据来提高监督学习算法的性能，并探讨了一个紧密相关的问题，提出了一种新颖的半监督学习方法。该论文介绍了一个结构学习的通用框架，并提出了结构学习的算法，展示了所提算法在半监督学习中的有效性。类似地，目标论文中提出的多任务学习框架旨在通过利用多任务和大规模平行训练语料库来提高翻译质量和解决数据稀缺问题。通过将Rie
    Kubota Ando和Tong Zhang（2005）[参考文献 11]的见解与现有文献结合，目标论文与利用多任务和未标记数据增强机器学习模型的广泛趋势一致。这些贡献共同丰富了对数据稀缺问题的理解、提高翻译质量和推动机器翻译模型能力的发展，为目标论文中提出的多任务学习框架奠定了基础。这些贡献为机器翻译的进展提供了宝贵的见解，强调了对研究领域的贡献并预测了潜在的未来方向。
- en: '| Related Work The field of machine translation has witnessed significant advancements
    in overcoming challenges related to limited training resources and enhancing translation
    quality across various language pairs. Notably, approaches such as the pivot language
    method, multi-parallel corpora, and the triangulation method have been explored
    to address scenarios with limited training data [Radford et al. (2019)[Reference
    5]]. Additionally, the development of neural network joint models (NNJM) [Sutskever,
    Vinyals, and Le (2014)[Reference 8]] and the integration of bidirectional recurrent
    neural networks have shown promise in improving translation quality, particularly
    for language pairs with limited resources. In alignment with these developments,
    the target paper focuses on the translation of sentences from a source language
    to multiple target languages using a multi-task learning framework inspired by
    neural machine translation. This approach not only demonstrates substantial progress
    in machine translation, especially for languages with limited training resources
    but also introduces a neural network joint model (NNJM) for statistical machine
    translation, aligning with the innovative approaches presented in the referenced
    studies and offering promise for enhancing translation quality for language pairs
    with limited resources. Moreover, Ïncremental joint approach to word segmentation,
    POS tagging, and dependency parsing in Chinese[̈Reference 10] proposes a joint
    model for word segmentation, POS tagging, and dependency parsing in Chinese, showing
    improvements particularly for out-of-vocabulary words. This study contributes
    to a comprehensive understanding of the methods used to address challenges in
    machine translation and natural language processing. Expanding on these foundations,
    the 11-th reference paper introduces a framework for learning predictive structures
    from multiple tasks and unlabeled data. This framework presents a general approach
    for formulating and analyzing the structural learning problem in the context of
    learning with unlabeled data, demonstrating its relevance to the challenges in
    machine translation. The proposed algorithm for joint empirical risk minimization
    is particularly notable, as it addresses the problem of learning predictive structures
    on hypothesis spaces from multiple learning tasks, aligning with the multi-task
    learning framework proposed in the target paper. Furthermore, the experiments
    presented in the 11-th reference show significant performance improvements over
    supervised methods in various tasks, indicating the effectiveness of the proposed
    framework in semi-supervised learning settings. In summary, the integrated literature
    on machine translation and natural language processing contributes valuable insights
    for the development of machine translation systems, offering innovative approaches
    to enhance translation quality, particularly for language pairs with limited resources.
    The introduction of the framework for learning predictive structures from multiple
    tasks and unlabeled data adds a new dimension to the existing research landscape,
    emphasizing the potential for semi-supervised learning to address challenges in
    machine translation and natural language processing. These advancements collectively
    pave the way for potential future research directions in the field of machine
    translation. |  | ChatCite without Reflective Incremental Generator |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: 相关工作 机器翻译领域在克服有限训练资源相关挑战以及提升不同语言对的翻译质量方面取得了显著进展。值得注意的是，诸如枢纽语言方法、多并行语料库和三角测量方法等方法已被探索，以应对有限训练数据的情境[Radford
    et al. (2019)[Reference 5]]。此外，神经网络联合模型（NNJM）[Sutskever, Vinyals, and Le (2014)[Reference
    8]]的开发和双向递归神经网络的整合在改善翻译质量方面显示出了希望，特别是对于资源有限的语言对。与这些发展相一致，目标论文专注于通过一个受神经机器翻译启发的多任务学习框架将句子从源语言翻译成多种目标语言。这种方法不仅在机器翻译中展示了实质性的进展，尤其是对资源有限的语言，而且还引入了用于统计机器翻译的神经网络联合模型（NNJM），与引用研究中提出的创新方法一致，并为提升资源有限语言对的翻译质量提供了希望。此外，增量联合方法在中文的词语分割、词性标注和依存句法分析方面[̈Reference
    10]提出了一种用于词语分割、词性标注和依存句法分析的联合模型，特别是在处理词汇表外词汇时显示出改进。这项研究有助于全面理解用于解决机器翻译和自然语言处理挑战的方法。在这些基础上，第11个参考文献的论文介绍了从多任务和无标注数据中学习预测结构的框架。该框架提出了一种在无标注数据背景下形成和分析结构学习问题的一般方法，展示了其与机器翻译挑战的相关性。提出的联合经验风险最小化算法特别值得注意，因为它解决了在假设空间上从多个学习任务中学习预测结构的问题，与目标论文中提出的多任务学习框架一致。此外，第11个参考文献中呈现的实验显示出在各种任务中的性能显著提升，表明所提框架在半监督学习设置中的有效性。总之，机器翻译和自然语言处理的综合文献为机器翻译系统的发展提供了宝贵的见解，提出了提升翻译质量的创新方法，特别是对资源有限的语言对。引入的从多任务和无标注数据中学习预测结构的框架为现有研究领域增添了新维度，强调了半监督学习在解决机器翻译和自然语言处理挑战中的潜力。这些进展共同为机器翻译领域未来的研究方向铺平了道路。
- en: '| Related Work The related work section provides an overview of the literature
    relevant to the target paper’s research topic, which aims to address the problem
    of learning a machine translation model that can simultaneously translate sentences
    from one source language to multiple target languages. The related work encompasses
    various studies in the field of machine translation, natural language processing,
    and neural network models. [1] Hua Wu and Haifeng Wang (2007) proposed a pivot
    language approach for phrase-based statistical machine translation, which addresses
    the translation problem for language pairs with scarce resources by using a pivot
    language and making use of large bilingual corpora without language-dependent
    resources or deep linguistic processing. The study demonstrated the effectiveness
    of the pivot language method for translation on language pairs with a small bilingual
    corpus. [2] Trevor Cohn and Mirella Lapata (2007) introduced the method of triangulation
    for translation modeling, which translates from a source to a target language
    via an intermediate third language, to exploit multi-parallel corpora for training
    and improve the coverage and quality of phrase-based statistical machine translation.
    The research focused on addressing the issue of poor performance of current phrase-based
    SMT systems when using small training sets. [3] Jacob Devlin et al. (2014) formulated
    a neural network joint model (NNJM) for machine translation, along with techniques
    to overcome the high cost of using NNLM-style models in MT decoding. The study
    demonstrated significant improvements in machine translation performance using
    the proposed NNJM and its variations. [4] Jianfeng Gao et al. (2014) introduced
    the Continuous-space Phrase Translation Model (CPTM) to address the sparsity problem
    in estimating phrase translation probabilities by learning continuous phrase representations.
    The study demonstrated substantial improvement over the baseline system with a
    statistically significant margin. [5] Martin Sundermeyer et al. (2014) explored
    the effectiveness of recurrent neural networks in translation modeling, specifically
    focusing on word-based and phrase-based approaches, as well as the inclusion of
    bidirectional architectures. The research demonstrated improvements over strong
    baselines in translation modeling. [6] Zhenghua Li et al. (2011) proposed a joint
    optimization approach for Chinese POS tagging and dependency parsing, showcasing
    significant improvements in parsing accuracy. The study addressed the issue of
    error propagation in parsing accuracy due to using automatic POS tags instead
    of gold ones. [7] Nal Kalchbrenner and Phil Blunsom (2013) introduced Recurrent
    Continuous Translation Models (RCTMs), demonstrating their translation capabilities
    and low perplexities with respect to reference translations. The study highlighted
    the sensitivity of RCTMs to word order, syntax, and meaning despite lacking alignments.
    [8] Ilya Sutskever et al. (2014) presented a general end-to-end approach to sequence
    learning using Deep Neural Networks (DNNs) for mapping sequences to sequences,
    showcasing the outperformance of the proposed LSTM-based approach over a mature
    SMT system. [9] Ronan Collobert et al. (2011) proposed a unified neural network
    architecture and learning algorithm for various natural language processing tasks,
    demonstrating the effectiveness of leveraging large unlabeled datasets and multitask
    supervised training to improve performance. [10] Jun Hatori et al. (2012) introduced
    an incremental joint approach to word segmentation, POS tagging, and dependency
    parsing for Chinese, showcasing substantial improvements in the accuracies of
    the three tasks over baseline models. [11] Rie Kubota Ando and Tong Zhang (2005)
    proposed a framework for learning predictive structures from multiple tasks and
    unlabeled data, demonstrating significant performance improvements over supervised
    methods in various tasks through structural learning. These studies collectively
    contribute to the field of machine translation, natural language processing, and
    neural network models, providing insights and advancements that are relevant to
    the target paper’s research on learning a machine translation model for translating
    sentences from one source language to multiple target languages. The innovations
    and findings from these studies serve as valuable background and insights for
    the target research, highlighting the significance of the related work to the
    target study and potential future research directions in the field. |  | GPT-3.5
    with zero shot |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 相关工作 相关工作部分概述了与目标论文研究主题相关的文献，这一主题旨在解决学习一个能够同时将句子从一种源语言翻译成多种目标语言的机器翻译模型的问题。相关工作涵盖了机器翻译、自然语言处理以及神经网络模型领域的各种研究。
    [1] 华武和王海峰（2007）提出了一种用于基于短语的统计机器翻译的中介语言方法，通过使用中介语言和利用大规模的双语语料库解决语言对资源稀缺的问题，而无需语言依赖的资源或深层语言处理。该研究展示了中介语言方法在双语语料库较小的语言对上的翻译效果。
    [2] 特雷弗·科恩和米雷拉·拉帕塔（2007）引入了翻译建模中的三角化方法，该方法通过一个中介第三语言将源语言翻译成目标语言，以利用多平行语料库进行训练，并提高基于短语的统计机器翻译的覆盖面和质量。该研究重点解决了当前基于短语的SMT系统在使用小规模训练集时表现不佳的问题。
    [3] 雅各布·德夫林等（2014）提出了一种神经网络联合模型（NNJM）用于机器翻译，并提出了克服在机器翻译解码中使用NNLM风格模型高成本的技术。研究展示了使用所提出的NNJM及其变体在机器翻译性能上的显著提升。
    [4] 贾峰高等（2014）引入了连续空间短语翻译模型（CPTM），以解决通过学习连续短语表示来估计短语翻译概率中的稀疏问题。研究展示了与基线系统相比，显著的改进，且差异具有统计学意义。
    [5] 马丁·苏德梅耶等（2014）探讨了递归神经网络在翻译建模中的有效性，特别关注基于词的和基于短语的方法，以及双向架构的包含。研究展示了在翻译建模中相较于强基线的改进。
    [6] 郑华李等（2011）提出了一种联合优化方法，用于中文词性标注和依存句法分析，展示了解析准确性的显著提升。该研究解决了由于使用自动词性标注而非金标词性标注导致的解析准确性误差传播问题。
    [7] 纳尔·卡尔施布伦纳和菲尔·布伦索姆（2013）引入了递归连续翻译模型（RCTMs），展示了其翻译能力和相对于参考翻译的低困惑度。研究强调了尽管缺乏对齐，RCTMs对词序、句法和意义的敏感性。
    [8] 伊利亚·苏茨克维尔等（2014）提出了一种基于深度神经网络（DNNs）的序列到序列学习的通用端到端方法，展示了所提出的基于LSTM的方法在成熟的SMT系统上的优越表现。
    [9] 罗南·科洛贝特等（2011）提出了一种统一的神经网络架构和学习算法，用于各种自然语言处理任务，展示了利用大规模无标注数据集和多任务监督训练来提高性能的有效性。
    [10] 君·哈托里等（2012）提出了一种递增联合方法，用于中文的词 segmentation、词性标注和依存句法分析，展示了这三项任务的准确性在基线模型上显著提升。
    [11] 理江·久保田安藤和张同（2005）提出了一个从多任务和无标注数据中学习预测结构的框架，通过结构学习在各种任务中显著提高了性能，相比监督方法表现更佳。这些研究共同促进了机器翻译、自然语言处理和神经网络模型领域的发展，为目标论文的研究提供了相关背景和见解。这些研究的创新和发现对目标研究具有重要的背景意义，并为未来的研究方向提供了潜在的启示。
    | | GPT-3.5 无需预训练 |'
- en: '| Related Work Section: The proposed multi-task learning framework for translating
    sentences from one source language to multiple target languages using a machine
    translation model builds upon and is related to several key works in the field
    of machine translation and natural language processing. 1\. Pivot language approach
    for phrase-based statistical machine translation The article P̈ivot language approach
    for phrase-based statistical machine translationp̈roposes a method for phrase-based
    statistical machine translation using a pivot language to address translation
    problems for language pairs with scarce resources. This method is related to the
    challenge of translating between languages with limited parallel data, which is
    also addressed in the target paper. The pivot language approach demonstrates the
    effectiveness of utilizing large bilingual corpora from a pivot language to improve
    translation quality, especially for language pairs with limited training data.
    2\. Machine translation by triangulation: Making effective use of multi-parallel
    corpora The article discusses the method of triangulation, which involves translating
    from a source to a target language via an intermediate third language, aiming
    to improve machine translation systems by exploiting multi-parallel corpora. This
    work is relevant to the target paper as it addresses the issue of improving translation
    quality using a wider range of parallel corpora, particularly with small training
    sets and for translating between low-density language pairs. 3\. Fast and robust
    neural network joint models for statistical machine translation The article presents
    a novel neural network joint model (NNJM) for statistical machine translation,
    which is related to the use of neural network models in machine translation. The
    NNJM augments a neural network language model with a source context window and
    is purely lexicalized, demonstrating significant improvements in BLEU scores.
    This work is relevant to the target paper’s exploration of neural machine translation
    and the effectiveness of neural network-based models in improving translation
    quality. 4\. Learning continuous phrase representations for translation modeling
    The article introduces a novel phrase translation model, the Continuous-space
    Phrase Translation Model (CPTM), which addresses the sparsity problem in estimating
    phrase translation probabilities. This work is related to the target paper’s exploration
    of continuous representations and their use in improving translation accuracy.
    The CPTM significantly improves the accuracy of a state-of-the-art phrase-based
    SMT system, demonstrating its effectiveness in improving translation quality.
    5\. Translation modeling with bidirectional recurrent neural networks The article
    presents two different translation models using recurrent neural networks, demonstrating
    their capability to improve machine translation performance. This work is related
    to the target paper in showcasing the effectiveness of recurrent neural networks
    in improving translation quality, particularly with the use of bidirectional recurrent
    models. 6\. Joint optimization for Chinese POS tagging and dependency parsing
    The article discusses the importance of joint optimization for Chinese POS tagging
    and dependency parsing, proposing a unique model to optimize both tasks. This
    work is related to the target paper’s exploration of joint learning frameworks
    and their impact on improving parsing accuracy, demonstrating the potential of
    joint optimization for improving translation quality. 7\. Recurrent continuous
    translation models The article introduces a class of probabilistic continuous
    translation models called Recurrent Continuous Translation Models (RCTMs), which
    are purely based on continuous representations for words, phrases, and sentences.
    This work is related to the target paper’s exploration of continuous representations
    and their potential in estimating translation quality, highlighting the effectiveness
    of RCTMs in capturing syntactic and semantic information. 8\. Sequence to sequence
    learning with neural networks The article discusses the use of Deep Neural Networks
    (DNNs) for sequence to sequence learning, particularly in the context of machine
    translation. This work is related to the target paper’s exploration of neural
    network-based models and their effectiveness in improving translation performance,
    demonstrating the potential of sequence to sequence learning with neural networks
    for various sequence to sequence problems. 9\. Incremental joint approach to word
    segmentation, POS tagging, and dependency parsing in Chinese The article proposes
    a joint model for word segmentation, POS tagging, and dependency parsing in Chinese,
    demonstrating significant improvements in accuracies for all three tasks over
    baseline models. This work is related to the target paper’s exploration of joint
    learning frameworks and their impact on improving translation quality, particularly
    in the context of joint modeling for multiple language translation tasks. 10\.
    A framework for learning predictive structures from multiple tasks and unlabeled
    data The article presents a framework for learning predictive structures from
    multiple tasks and unlabeled data, addressing the concept of semi-supervised learning
    and the problem of learning predictive structures on hypothesis spaces from multiple
    learning tasks. This work is related to the target paper’s exploration of multi-task
    learning frameworks and their effectiveness in improving translation quality,
    particularly in the context of learning from multiple tasks and unlabeled data.
    The related work presented here demonstrates the diverse approaches and techniques
    employed in the field of machine translation and natural language processing,
    providing valuable insights and methods that contribute to the advancement of
    multi-task learning frameworks and neural machine translation models for improving
    translation quality. |  | GPT-3.5 with few shot |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 相关工作部分：所提出的多任务学习框架用于通过机器翻译模型将句子从一种源语言翻译成多种目标语言，基于并与机器翻译和自然语言处理领域中的若干关键工作相关。
    1\. 短语基础的统计机器翻译中的中介语言方法 文章《短语基础的统计机器翻译中的中介语言方法》提出了一种使用中介语言的短语基础的统计机器翻译方法，以解决资源稀缺的语言对的翻译问题。这种方法与翻译有限平行数据的语言对之间的挑战相关，这在目标论文中也有所探讨。中介语言方法展示了利用中介语言的大型双语语料库来提高翻译质量的有效性，特别是对于数据稀缺的语言对。
    2\. 三角测量的机器翻译：有效利用多平行语料库 文章讨论了三角测量的方法，该方法涉及通过中介第三语言将源语言翻译为目标语言，旨在通过利用多平行语料库来改进机器翻译系统。这项工作与目标论文相关，因为它探讨了使用更广泛的平行语料库来提高翻译质量的问题，特别是对于小型训练集和低密度语言对的翻译。
    3\. 快速而稳健的神经网络联合模型用于统计机器翻译 文章提出了一种新颖的神经网络联合模型（NNJM）用于统计机器翻译，这与神经网络模型在机器翻译中的应用相关。NNJM通过源上下文窗口扩展神经网络语言模型，并且完全是词汇化的，展示了BLEU分数的显著提升。这项工作与目标论文探讨的神经机器翻译以及基于神经网络的模型在提高翻译质量中的有效性相关。
    4\. 学习连续短语表示以进行翻译建模 文章介绍了一种新颖的短语翻译模型——连续空间短语翻译模型（CPTM），该模型解决了估计短语翻译概率中的稀疏性问题。这项工作与目标论文探讨的连续表示及其在提高翻译准确性中的应用相关。CPTM显著提高了最先进的短语基础的统计机器翻译系统的准确性，展示了其在提高翻译质量方面的有效性。
    5\. 使用双向递归神经网络的翻译建模 文章提出了两种不同的翻译模型，使用递归神经网络，展示了它们提高机器翻译性能的能力。这项工作与目标论文相关，展示了递归神经网络在提高翻译质量中的有效性，特别是使用双向递归模型。
    6\. 中文词性标注和依存句法分析的联合优化 文章讨论了中文词性标注和依存句法分析的联合优化的重要性，提出了一种独特的模型来优化这两个任务。这项工作与目标论文探讨的联合学习框架及其在提高解析准确性方面的影响相关，展示了联合优化在提高翻译质量方面的潜力。
    7\. 递归连续翻译模型 文章介绍了一类称为递归连续翻译模型（RCTMs）的概率性连续翻译模型，这些模型完全基于词语、短语和句子的连续表示。这项工作与目标论文探讨的连续表示及其在估计翻译质量中的潜力相关，突显了RCTMs在捕捉句法和语义信息方面的有效性。
    8\. 使用神经网络的序列到序列学习 文章讨论了深度神经网络（DNNs）在序列到序列学习中的应用，特别是在机器翻译的背景下。这项工作与目标论文探讨的基于神经网络的模型及其在提高翻译性能中的有效性相关，展示了神经网络序列到序列学习在各种序列到序列问题中的潜力。
    9\. 中文词语分割、词性标注和依存句法分析的增量联合方法 文章提出了一种用于中文词语分割、词性标注和依存句法分析的联合模型，展示了在所有三项任务上相较于基线模型的显著准确性提升。这项工作与目标论文探讨的联合学习框架及其在提高翻译质量方面的影响相关，特别是在多个语言翻译任务的联合建模背景下。
    10\. 从多个任务和未标记数据中学习预测结构的框架 文章提出了一种从多个任务和未标记数据中学习预测结构的框架，涉及半监督学习的概念以及在多个学习任务的假设空间上学习预测结构的问题。这项工作与目标论文探讨的多任务学习框架及其在提高翻译质量中的有效性相关，特别是在从多个任务和未标记数据中学习的背景下。
    这里呈现的相关工作展示了机器翻译和自然语言处理领域中采用的多样化方法和技术，提供了宝贵的见解和方法，有助于推进多任务学习框架和神经机器翻译模型在提高翻译质量方面的发展。
    |  | GPT-3.5 with few shot |'
- en: '| Related Work Section: The related work section will include a review of existing
    literature and studies that are relevant to the topic of multi-task learning for
    machine translation and related methods for improving translation quality. The
    section will discuss the following papers: 1\. P̈ivot language approach for phrase-based
    statistical machine translation-̈ This study proposes a new method for phrase-based
    statistical machine translation using a pivot language to address translation
    problems for language pairs with scarce resources. The method demonstrates the
    use of large bilingual corpora from a pivot language to improve translation quality
    for language pairs with limited training data. 2\. M̈achine translation by triangulation:
    Making effective use of multi-parallel corpora-̈ The article discusses a method
    for improving machine translation systems by exploiting multi-parallel corpora.
    The proposed method, called triangulation, involves translating from a source
    to a target language via an intermediate third language, allowing the use of a
    wider range of parallel corpora for training. 3\. F̈ast and robust neural network
    joint models for statistical machine translation-̈ This article discusses the
    development of a novel neural network joint model (NNJM) for statistical machine
    translation (SMT). The NNJM augments a neural network language model (NNLM) with
    a source context window and demonstrates significant improvements in translation
    quality. 4\. L̈earning continuous phrase representations for translation modeling-̈
    The study presents a novel phrase translation model for statistical machine translation
    (SMT) that addresses the sparsity problem in estimating phrase translation probabilities.
    The model utilizes continuous phrase representations to improve the accuracy of
    a state-of-the-art phrase-based SMT system. 5\. T̈ranslation modeling with bidirectional
    recurrent neural networks-̈ The article introduces two different translation models
    using recurrent neural networks and demonstrates their effectiveness in improving
    machine translation performance on various tasks. 6\. R̈ecurrent continuous translation
    models-̈ This study introduces a class of probabilistic continuous translation
    models called Recurrent Continuous Translation Models (RCTMs) and demonstrates
    their potential in capturing syntactic and semantic information and estimating
    translation quality. 7\. S̈equence to sequence learning with neural networks-̈
    The article discusses the use of Deep Neural Networks (DNNs) for sequence to sequence
    learning and demonstrates the effectiveness of this approach on an English to
    French translation task. 8\. Ïncremental joint approach to word segmentation,
    POS tagging, and dependency parsing in Chinese-̈ The article proposes a joint
    model for word segmentation, POS tagging, and dependency parsing in Chinese and
    demonstrates significant improvements in accuracies for all three tasks over baseline
    models. 9\. Ä framework for learning predictive structures from multiple tasks
    and unlabeled data-̈ The study presents a framework for learning predictive structures
    from multiple tasks and unlabeled data, demonstrating significant performance
    improvements over supervised methods in various text categorization, named entity
    chunking, part-of-speech tagging, and hand-written digit image classification
    tasks. |  | GPT-4.0 with zero shot |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| 相关工作部分：相关工作部分将包括对现有文献和研究的回顾，这些文献和研究与机器翻译的多任务学习主题以及改进翻译质量的方法相关。该部分将讨论以下论文：1.
    **短语统计机器翻译的枢轴语言方法** - 该研究提出了一种使用枢轴语言的新方法来解决资源稀缺语言对的翻译问题。该方法展示了利用来自枢轴语言的大型双语语料库来改善资源有限的语言对的翻译质量。2.
    **通过三角化的机器翻译：有效利用多平行语料库** - 文章讨论了一种通过利用多平行语料库来改进机器翻译系统的方法。所提出的方法称为三角化，通过中介第三语言将源语言翻译成目标语言，从而允许使用更广泛的平行语料库进行训练。3.
    **用于统计机器翻译的快速且稳健的神经网络联合模型** - 文章讨论了一种新型神经网络联合模型（NNJM）的开发，该模型增强了神经网络语言模型（NNLM）并展示了翻译质量的显著改善。4.
    **学习连续短语表示以进行翻译建模** - 该研究提出了一种新型短语翻译模型，用于解决在估计短语翻译概率时的稀疏性问题。该模型利用连续短语表示来提高最先进的短语基础
    SMT 系统的准确性。5. **使用双向递归神经网络的翻译建模** - 文章介绍了两种不同的翻译模型，并展示了它们在各种任务中改善机器翻译性能的有效性。6.
    **递归连续翻译模型** - 该研究介绍了一类概率连续翻译模型，称为递归连续翻译模型（RCTMs），并展示了它们在捕捉句法和语义信息及估计翻译质量方面的潜力。7.
    **使用神经网络进行序列到序列学习** - 文章讨论了使用深度神经网络（DNNs）进行序列到序列学习，并展示了这种方法在英法翻译任务中的有效性。8. **中文词汇分割、词性标注和依存解析的增量联合方法**
    - 文章提出了一种联合模型用于中文的词汇分割、词性标注和依存解析，并展示了所有三个任务的准确性相比基线模型有显著提升。9. **从多任务和无标签数据中学习预测结构的框架**
    - 该研究提出了一个从多任务和无标签数据中学习预测结构的框架，在各种文本分类、命名实体识别、词性标注和手写数字图像分类任务中展示了相较于监督方法的显著性能提升。
    |  | GPT-4.0 with zero shot |'
- en: '| Based on the given information, here is a related work section for the target
    paper: Related Work The problem of learning from multiple tasks and utilizing
    unlabeled data has been an area of significant research interest in machine learning
    and natural language processing (NLP). The concept of semi-supervised learning,
    which involves the use of both labeled and unlabeled data, has been explored in
    various studies with the aim of improving the performance of supervised learning
    algorithms. Vapnik introduced the notion of transductive inference, which is a
    form of semi-supervised learning, although its effectiveness has been debated
    (Vapnik, 1998; Zhang and Oles, 2000). Co-training, another semi-supervised approach,
    was proposed by Blum and Mitchell (1998) and is related to the bootstrap method
    used in NLP applications (Yarowsky, 1995). However, the effectiveness of co-training
    can be limited by the assumptions made by the method and the potential introduction
    of noise into the labels (Pierce and Cardie, 2001). The idea of learning predictive
    structures from multiple tasks, also known as structural learning or multi-task
    learning, has been discussed in the literature. Ando and Zhang (2005) presented
    a framework for structural learning where multiple tasks are used to discover
    a shared low-dimensional predictive structure. This approach is based on the principle
    that a good hypothesis space should have a small approximation error and a small
    estimation error. The authors proposed an algorithm for structural learning that
    finds a common low-dimensional feature space shared by multiple problems. Their
    method was shown to be effective in semi-supervised learning settings, improving
    the performance of various NLP tasks. In the context of NLP, the joint approach
    to tasks such as word segmentation, POS tagging, and dependency parsing has been
    explored. Hatori et al. (2012) proposed an incremental joint model for Chinese
    POS tagging and dependency parsing, demonstrating improvements over baseline models.
    The work by Kubota Ando and Zhang (2005) extends this idea to a joint model that
    simultaneously processes word segmentation, POS tagging, and dependency parsing,
    capturing global interactions among these tasks. Their model employs an efficient
    character-based decoding method that combines features from state-of-the-art segmentation,
    POS tagging, and dependency parsing models. The use of external resources, such
    as dictionaries, has also been considered in joint models to enhance performance.
    Wang et al. (2011) used semi-supervised methods with large auto-analyzed data
    to improve Chinese word segmentation and POS tagging. The incorporation of syntactic
    information has been shown to improve the segmentation of out-of-vocabulary words,
    which is a common challenge in languages like Chinese where transliterated words
    often include characters used as common or function words. Overall, the related
    work demonstrates the potential of joint and semi-supervised approaches in leveraging
    multiple tasks and unlabeled data to improve the performance of machine learning
    models in NLP tasks. The target paper builds upon these concepts by proposing
    a unified framework that avoids task-specific engineering and learns internal
    representations from vast amounts of unlabeled data, achieving good performance
    across various NLP tasks. |  | GPT-4.0 with few shot |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: 根据所提供的信息，以下是目标论文的相关工作部分：相关工作 从多个任务中学习并利用未标记数据的问题在机器学习和自然语言处理（NLP）领域一直是一个重要的研究方向。半监督学习的概念涉及到标记和未标记数据的使用，已经在各种研究中得到探索，目的是提高监督学习算法的性能。
    Vapnik 提出了归纳推理的概念，这是一种半监督学习形式，尽管其有效性存在争议（Vapnik, 1998; Zhang 和 Oles, 2000）。另一种半监督方法——协同训练，由
    Blum 和 Mitchell（1998）提出，与在 NLP 应用中使用的自举方法相关（Yarowsky, 1995）。然而，协同训练的有效性可能会受到该方法假设的限制以及标签中噪声引入的影响（Pierce
    和 Cardie, 2001）。从多个任务中学习预测结构的想法，也称为结构学习或多任务学习，在文献中有所讨论。Ando 和 Zhang（2005）提出了一个结构学习框架，其中多个任务用于发现一个共享的低维预测结构。这种方法基于一个原则：一个好的假设空间应该具有较小的近似误差和较小的估计误差。作者提出了一种结构学习算法，该算法找到由多个问题共享的共同低维特征空间。他们的方法在半监督学习环境中被证明是有效的，改善了各种
    NLP 任务的性能。在 NLP 的背景下，对词语分割、POS 标注和依存解析等任务的联合方法进行了探讨。Hatori 等（2012）提出了一种用于中文 POS
    标注和依存解析的增量联合模型，展示了相较于基线模型的改进。Kubota Ando 和 Zhang（2005）的工作将这一想法扩展到一个同时处理词语分割、POS
    标注和依存解析的联合模型，捕捉这些任务之间的全局交互。他们的模型采用了一种高效的字符级解码方法，结合了最新的分割、POS 标注和依存解析模型的特征。联合模型中也考虑了外部资源的使用，例如词典，以提高性能。Wang
    等（2011）利用大型自我分析数据的半监督方法改进了中文词语分割和 POS 标注。语法信息的融入已被证明可以改善词汇表外词的分割，这在中文等语言中是一个常见挑战，其中音译词通常包含用作常见词或功能词的字符。总体而言，相关工作展示了联合和半监督方法在利用多个任务和未标记数据以提升
    NLP 任务中机器学习模型性能方面的潜力。目标论文在这些概念基础上提出了一个统一的框架，避免了任务特定的工程，并从大量未标记数据中学习内部表示，在各种 NLP
    任务中实现了良好的性能。
- en: '| The examples provided discuss the use of Large Language Models (LLMs) as
    proxies for human behaviors and the systematic study of LLMs’ personalities based
    on established personality trait theories. Here’s a summary of the key points
    from the examples: 1\. LLMs Mimicking Human Behaviors: - Recent studies have shown
    that LLMs can mimic human behaviors, including reasoning and cognitive abilities,
    as well as participate in social science experiments. - These studies are mostly
    empirical and based on case-by-case observations. 2\. Systematic Study of LLMs’
    Personalities: - The authors propose a systematic and quantitative approach to
    study LLMs’ behaviors by evaluating and inducing personality traits in LLMs. -
    This approach does not require supervised fine-tuning or human evaluation of generated
    utterances. 3\. Personality Trait Theories: - The Big Five and Sixteen Personality
    Factors (16PF) are two prominent theories that provide consistent descriptions
    of individual differences. - Psychometric tests based on these theories, such
    as NEO-PI-R, are effective in assessing personality traits and have shown that
    human differences can be categorized into continuous factor dimensions. 4\. Correlation
    Between Personality and Behavior: - Empirical studies have confirmed a strong
    correlation between personality traits and real-world human behaviors. - Specifically,
    there is a significant link between the Big Five traits and language use, suggesting
    that personality influences how people communicate. The examples highlight the
    potential of LLMs to simulate complex human-like behaviors and the importance
    of understanding the personality traits of these models for various applications.
    |  | LitLLM with GPT-4.0 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 提供的示例讨论了将大型语言模型（LLMs）作为人类行为代理的使用，以及基于已建立的人格特质理论对LLMs人格的系统研究。以下是示例中的关键点总结：
    1\. LLMs 模仿人类行为： - 最近的研究表明，LLMs 可以模仿人类行为，包括推理和认知能力，并参与社会科学实验。 - 这些研究大多是经验性的，基于逐个案例的观察。
    2\. LLMs 人格的系统研究： - 作者提出了一种系统化和定量的方法，通过评估和诱导LLMs的人格特质来研究其行为。 - 这种方法不需要监督性微调或对生成语句的人工评估。
    3\. 人格特质理论： - 大五人格理论和十六种人格因素（16PF）是两个主要的理论，为个体差异提供了一致的描述。 - 基于这些理论的心理测量测试，如NEO-PI-R，能够有效评估人格特质，并显示出人类差异可以被分类到连续的因素维度中。
    4\. 人格与行为的相关性： - 经验研究确认了人格特质与现实世界人类行为之间的强相关性。 - 特别是，大五人格特质与语言使用之间存在显著联系，表明人格会影响人们的交流方式。
    示例强调了LLMs模拟复杂类人行为的潜力，以及了解这些模型的人格特质对于各种应用的重要性。 |  | LitLLM with GPT-4.0 |'
- en: '| The Unified Neural Network Model for NLP Tasks Natural Language Processing
    (NLP) tasks such as part-of-speech (POS) tagging, chunking, named entity recognition
    (NER), and semantic role labeling (SRL) are essential for understanding and generating
    human language. Traditional approaches to these tasks often involve task-specific
    feature engineering, which can be labor-intensive and may not generalize well
    to new tasks or datasets. To address these issues, researchers have proposed unified
    neural network models that can learn to perform multiple NLP tasks simultaneously
    without extensive feature engineering. These models leverage large amounts of
    both labeled and unlabeled data to learn useful representations for words, phrases,
    and sentences that capture syntactic and semantic information. One such model
    is the Long Short-Term Memory (LSTM) network, which has been shown to be effective
    for sequence-to-sequence learning tasks like machine translation. LSTMs can process
    input sequences of variable lengths and learn long-range dependencies, making
    them suitable for NLP tasks. They can be trained end-to-end with backpropagation
    and can learn from both supervised and unsupervised data. Another approach is
    the use of semi-supervised learning methods, which combine labeled and unlabeled
    data to improve model performance. For example, structural learning algorithms
    can learn predictive structures from multiple tasks and use them to enhance the
    performance of individual tasks. This can be particularly useful when there is
    a large amount of unlabeled data available. The success of these unified neural
    network models demonstrates the potential of using deep learning techniques for
    NLP tasks. By avoiding task-specific engineering and leveraging large datasets,
    these models can achieve state-of-the-art performance on a variety of benchmarks,
    making them valuable tools for researchers and practitioners in the field of NLP."
    |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| 统一神经网络模型用于NLP任务 自然语言处理（NLP）任务，如词性标注（POS）、短语划分、命名实体识别（NER）和语义角色标注（SRL），对于理解和生成自然语言至关重要。传统方法通常涉及特定任务的特征工程，这可能是劳动密集型的，且可能不适用于新的任务或数据集。为了解决这些问题，研究人员提出了统一神经网络模型，这些模型能够在不需要广泛特征工程的情况下，同时学习执行多个NLP任务。这些模型利用大量标注和未标注的数据来学习有用的表示，捕捉句法和语义信息。例如，长短期记忆（LSTM）网络被证明在机器翻译等序列到序列学习任务中效果显著。LSTM能够处理可变长度的输入序列，并学习长期依赖关系，使其适用于NLP任务。它们可以通过反向传播进行端到端训练，并可以从有监督和无监督数据中学习。另一种方法是使用半监督学习方法，将标注和未标注的数据结合起来以提高模型性能。例如，结构学习算法可以从多个任务中学习预测结构，并利用这些结构来提升单个任务的性能。这在有大量未标注数据时尤其有用。这些统一神经网络模型的成功展示了使用深度学习技术进行NLP任务的潜力。通过避免特定任务的工程化并利用大规模数据集，这些模型能够在各种基准上实现最先进的性能，使其成为NLP领域研究人员和从业人员的宝贵工具。
    |'
- en: A.2 Related work draft for this paper generated by ChatCite with GPT-4.0
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 ChatCite与GPT-4.0生成的这篇论文的相关工作草稿
- en: 'Table 4: We show the related work summary using this paper and our collection
    of related work papers generated by the ChatCite model based on GPT-4.0 (gpt-4-turbo-preview
    version). It can be observed that the citations in the paper are consistent with
    those in the collection, the content is accurate at the same time. We utilized
    this summary as a draft and, completed our related work section after some minor
    modifications.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 表4：我们展示了这篇论文中相关工作的总结以及基于GPT-4.0（gpt-4-turbo-preview版本）的ChatCite模型生成的相关工作论文集合。可以观察到，论文中的引用与集合中的引用一致，内容也准确无误。我们将这个总结作为草稿，并在进行了一些小的修改后，完成了我们的相关工作部分。
- en: '| Generated literature summary for this paper |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 生成的文献总结 |'
- en: '| In the evolving landscape of automated scholarly writing, particularly in
    the domain of literature review summarization, the proposed ChatCite framework
    within our target paper represents a significant advancement, aiming to harness
    the capabilities of Large Language Models (LLMs) to generate high-quality related
    work summaries. The foundational work in this field began with hierarchical keyword
    structures for extractive summarization [Reference 1], and has progressed through
    various iterations including multi-source pointer-generator networks [Reference
    2], and sophisticated models like the ARWG system [Reference 3], BACO [Reference
    4], and the Relation-aware Related work Generator (RRG) [Reference 5]. The introduction
    of contrastive learning to improve summarization quality [Reference 6], and automatic
    citation sentence generation methods [Reference 7], have further refined the capabilities
    of LLMs in this space. Recent studies have concentrated on the unsupervised and
    few-shot learning capabilities of LLMs, notably GPT-3, establishing a solid groundwork
    for AI application in scholarly communication [References 8-9]. The exploration
    of AI tools such as ChatGPT by Huang, Jingshan, and Ming Tan (2023) [Reference
    10] in crafting scientific review articles, sheds light on both the potential
    benefits and drawbacks of AI in academic writing, such as enhancement in speed
    and quality versus risks of inaccuracies and bias. Building on these insights,
    the LitLLM toolkit suggested by Shubham Agarwal, Issam H. Laradji et al. (2024)
    [Reference 11] brings novel approaches to overcome challenges like the generation
    of hallucinated content and the overlooking of recent studies by employing Retrieval
    Augmented Generation (RAG) principles, specialized prompting, and instructive
    techniques. This showcases a significant alignment with our target paper’s objectives,
    particularly in mitigating hallucinations and enhancing summarization accuracy
    through the ChatCite framework. The latest contribution in this domain is presented
    by Yang Liu, Dan Iter, et al. (2023) [Reference 12] through the G-EVAL framework,
    which introduces a methodology for evaluating the quality of texts generated by
    natural language generation (NLG) systems using LLMs, leveraging chain-of-thoughts
    (CoT) and a form-filling paradigm. This approach, which significantly outperforms
    previous methods in evaluating the creativity and diversity required in text generation
    tasks, aligns closely with the goals of the ChatCite framework, especially in
    its pursuit of generating high-quality literature summaries. The G-EVAL framework
    not only surpasses all previous state-of-the-art evaluators on the SummEval and
    Topical-Chat benchmarks but also underscores the importance of instruction sensitivity
    and the benefits of a CoT approach, which could potentially inform future enhancements
    in the ChatCite framework [Reference 12]. By evaluating the quality of NLG outputs,
    [Reference 12] addresses the limitations identified in prior works, including
    the potential bias of LLM-based evaluators towards LLM-generated texts, and calls
    for further research to understand the behavior of LLM-based evaluators fully.
    This contribution is particularly relevant to our target paper, which aims to
    enhance the quality and stability of literature review summarizations generated
    by LLMs. Thus, integrating insights from G-EVAL [Reference 12] can provide a more
    nuanced understanding of evaluating the effectiveness of automated scholarly writing
    tools, highlighting a potential area for future development within the scope of
    the ChatCite framework. In summary, the development of automated scholarly writing,
    particularly in literature review summarization, has progressed through key innovations
    in LLM capabilities, methodological enhancements, and now, through improved evaluation
    frameworks. This journey from extractive summarization to sophisticated LLM-based
    frameworks underscores a collaborative advancement in the field, with each contribution
    building upon the last to address emerging challenges and achieve greater accuracy,
    efficiency, and relevance in automated scholarly writing. The ChatCite framework,
    supported by insights from references [References 1-12], continues this trajectory
    by proposing innovative solutions to the challenges in literature review summarization,
    setting a platform for further exploration and innovation in the field. |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: 在自动化学术写作不断发展的背景下，特别是在文献综述总结领域，我们目标论文中提出的ChatCite框架代表了一个重要的进展，旨在利用大型语言模型（LLMs）的能力生成高质量的相关工作总结。该领域的基础工作始于用于提取式总结的层次关键词结构[参考文献1]，并通过多源指针生成网络[参考文献2]、ARWG系统[参考文献3]、BACO[参考文献4]以及Relation-aware
    Related work Generator（RRG）[参考文献5]等复杂模型不断进展。引入对比学习以提高总结质量[参考文献6]，以及自动引文句生成方法[参考文献7]，进一步优化了LLMs在这一领域的能力。最近的研究集中在LLMs的无监督学习和少样本学习能力上，特别是GPT-3，建立了AI在学术交流中的应用的坚实基础[参考文献8-9]。黄靖山和Tan
    Ming（2023）[参考文献10]对AI工具如ChatGPT在撰写科学综述文章中的探索，揭示了AI在学术写作中的潜在益处和缺点，如提升速度和质量与风险如不准确性和偏见。基于这些见解，Shubham
    Agarwal、Issam H. Laradji等（2024）[参考文献11]提出的LitLLM工具包引入了新的方法来克服生成虚假内容和忽略近期研究等挑战，通过使用检索增强生成（RAG）原则、专业提示和指导性技术。这展示了与我们目标论文的目标的显著一致性，特别是在通过ChatCite框架减少虚假信息和提高总结准确性方面。该领域的最新贡献由Yang
    Liu、Dan Iter等（2023）[参考文献12]通过G-EVAL框架提出，该框架介绍了一种使用LLMs评估自然语言生成（NLG）系统生成文本质量的方法，利用了链式思维（CoT）和表单填写范式。这种方法在评估文本生成任务中所需的创造性和多样性方面显著优于以往的方法，与ChatCite框架的目标紧密相关，特别是在生成高质量文献总结的追求上。G-EVAL框架不仅在SummEval和Topical-Chat基准测试中超越了所有之前的最先进评估器，还强调了指令敏感性的重要性和CoT方法的好处，这可能为未来在ChatCite框架中进行的改进提供指导[参考文献12]。通过评估NLG输出的质量，[参考文献12]解决了之前工作中识别的局限性，包括LLM基于评估器对LLM生成文本的潜在偏见，并呼吁进一步研究以全面理解LLM基于评估器的行为。这一贡献与我们目标论文特别相关，其目标是提高LLMs生成的文献综述总结的质量和稳定性。因此，整合G-EVAL[参考文献12]的见解可以提供对评估自动化学术写作工具有效性的更细致理解，突出ChatCite框架范围内的潜在未来发展领域。总之，自动化学术写作的发展，特别是在文献综述总结方面，已经通过LLM能力的关键创新、方法论的改进以及现在改进的评估框架经历了发展。从提取式总结到复杂的LLM基础框架的发展历程凸显了该领域的协作进步，每一项贡献都建立在之前的基础上，以应对新兴挑战并在自动化学术写作中实现更大的准确性、效率和相关性。ChatCite框架在参考文献[参考文献1-12]的见解支持下，继续沿着这一轨迹提出创新解决方案，以应对文献综述总结中的挑战，为该领域的进一步探索和创新奠定了平台。
