<!--yml

category: 未分类

日期：2025-01-11 12:42:04

-->

# AgentCoord：面向LLM基础的多代理协作的协调策略视觉探索

> 来源：[https://arxiv.org/html/2404.11943/](https://arxiv.org/html/2404.11943/)

\onlineid

0 \vgtccategoryResearch \vgtcpapertypeApplication/Design Study \authorfooter Bo Pan, Jiaying Lu, Ke Wang, Li Zheng, Zhen Wen, Yingchaojie Feng, and Wei Chen are with the State Key Lab of CAD&CG, Zhejiang University, and Wei Chen is also with the Laboratory of Art and Archaeology Image (Zhejiang University), Ministry of Education, China. E-mail: {bopan $|$ ljying $|$ sttot$|$ zju_zhengli $|$ wenzhen $|$ fycj $|$ chenvis}@zju.edu.cn. Minfeng Zhu is with Zhejiang University. E-mail: minfeng_zhu@zju.edu.cn.

Bo Pan    Jiaying Lu    Ke Wang    Li Zheng    Zhen Wen    Yingchaojie Feng    Minfeng Zhu    and Wei Chen

###### 摘要

基于大型语言模型（LLM）的多代理协作在自动任务解决中的潜力，近年来受到了学术界和工业界的广泛关注。虽然利用自然语言来协调多个代理为普通用户推广代理技术提供了一个有前景的途径，但在现有的协调框架中，设计协调策略仍然充满挑战。这一困难源于自然语言在指定协作过程中的固有模糊性，以及在探索过程中从大量文本形式内容中提取关键信息（例如代理关系、任务依赖、结果对应）所需的巨大认知努力。在本研究中，我们提出了一个视觉探索框架，旨在促进多代理协作中的协调策略设计。我们首先为基于LLM的多代理协调策略建立了一个结构化表示，以规范自然语言的模糊性。在此基础上，我们设计了一种三阶段生成方法，利用LLM将用户的总体目标转化为可执行的初始协调策略。用户可以在生成过程的任何阶段进行进一步干预，利用LLM和一组交互操作探索替代策略。每当识别出令人满意的策略时，用户即可开始协作并检查经过视觉增强的执行结果。我们开发了AgentCoord，一个原型互动系统，并进行了正式的用户研究，以展示我们方法的可行性和有效性。

###### 关键词：

大型语言模型（LLM）基础的代理、多代理协作、视觉探索、自然语言接口。\teaser

我们的视觉探索框架用于协调策略设计：用户首先输入一个代理协作的总体目标（a）。系统进行三阶段生成（即计划大纲生成（b）、代理分配（c）和任务过程生成（d））以提供初步策略。用户在LLM的帮助下交互式地探索每个阶段的替代策略（e、f、g）。一旦满意，用户便开始协作并检查视觉增强的执行结果（h）。

## 1 引言

基于大型语言模型（LLM）的代理，能够观察、决策并执行动作，借助LLM的推理能力，已经取得了显著进展，在编程[[12](https://arxiv.org/html/2404.11943v1#bib.bib12)、[25](https://arxiv.org/html/2404.11943v1#bib.bib25)]、创意写作[[3](https://arxiv.org/html/2404.11943v1#bib.bib3)、[33](https://arxiv.org/html/2404.11943v1#bib.bib33)、[44](https://arxiv.org/html/2404.11943v1#bib.bib44)]以及问答[[39](https://arxiv.org/html/2404.11943v1#bib.bib39)、[28](https://arxiv.org/html/2404.11943v1#bib.bib28)]等多个领域展现出巨大的潜力。尽管最初关于基于LLM的代理的探索主要集中在单一代理系统[[10](https://arxiv.org/html/2404.11943v1#bib.bib10)、[42](https://arxiv.org/html/2404.11943v1#bib.bib42)]，但是多代理协作的概念——模拟人类之间的合作互动——已开始引起AI研究界的兴趣。受到人类团队协作中协同效应的启发[[7](https://arxiv.org/html/2404.11943v1#bib.bib7)、[37](https://arxiv.org/html/2404.11943v1#bib.bib37)、[20](https://arxiv.org/html/2404.11943v1#bib.bib20)]，一系列新兴的研究正在探索并验证基于LLM的多代理协作带来的好处（例如扩展专业知识[[27](https://arxiv.org/html/2404.11943v1#bib.bib27)、[28](https://arxiv.org/html/2404.11943v1#bib.bib28)]，增强可靠性[[2](https://arxiv.org/html/2404.11943v1#bib.bib2)、[6](https://arxiv.org/html/2404.11943v1#bib.bib6)、[25](https://arxiv.org/html/2404.11943v1#bib.bib25)]，鼓励发散性思维[[15](https://arxiv.org/html/2404.11943v1#bib.bib15)、[45](https://arxiv.org/html/2404.11943v1#bib.bib45)])。

为了促进多代理协作的协调，开源社区涌现出多种基于大语言模型（LLM）的多代理系统原型框架。现有的多代理框架可以根据用户如何指定或干预协作过程分为两类：基于代码的和基于自然语言的。对于基于代码的框架[[12](https://arxiv.org/html/2404.11943v1#bib.bib12)、[25](https://arxiv.org/html/2404.11943v1#bib.bib25)、[38](https://arxiv.org/html/2404.11943v1#bib.bib38)、[21](https://arxiv.org/html/2404.11943v1#bib.bib21)、[29](https://arxiv.org/html/2404.11943v1#bib.bib29)、[4](https://arxiv.org/html/2404.11943v1#bib.bib4)]，用户需要将协调策略（例如任务分配、代理分配、消息流转）硬编码到代码中，这需要一定的编码技能和学习成本。基于自然语言的框架[[3](https://arxiv.org/html/2404.11943v1#bib.bib3)、[38](https://arxiv.org/html/2404.11943v1#bib.bib38)]¹¹1AutoGen[[38](https://arxiv.org/html/2404.11943v1#bib.bib38)] 支持基于代码和基于自然语言的两种范式。在其“群聊模式”中，协调策略可以通过自由形式的自然语言表达，并由聊天管理器进行协调，这直接使用自然语言来指定协调策略，可能是使代理技术为更广泛的一般用户所普及的有希望的方式。此外，鉴于LLM本身具备协调能力并且在不同任务中拥有丰富的领域知识，基于自然语言的框架可以轻松利用LLM来协助草拟和完善用自然语言表示的协调策略[[3](https://arxiv.org/html/2404.11943v1#bib.bib3)]。

然而，使用现有的基于自然语言的框架设计协调策略仍然具有挑战性。首先，自然语言的灵活性可能是一把双刃剑：一方面，它允许用户自由设计和表达他们的协调策略；另一方面，过于灵活的表达方式可能会使得设计出的协作策略模糊不清，往往需要用户反复进行补充说明，以确保协作的执行不会偏离预定的方向。其次，在纯文本格式中表示和探索协调策略会面临挑战，因为随着协作过程和团队组织复杂性的增加，用户容易在“文本堵塞”中迷失，重要信息（例如代理关系、任务依赖性、结果对应性、策略差异）在探索的某些点上可能被大量文本所淹没。因此，亟需新颖的方法来增强当前基于自然语言的设计过程。

本文提出了一个视觉探索框架，用于高效设计基于大型语言模型（LLM）的多智能体协作的协调策略。为了在利用自然语言的灵活性的同时，加入一定的组织结构来规范其模糊性，我们分析了在25篇基于LLM的多智能体协作论文和7个高评分项目的语料库中常见的协调策略描述中的概念和结构²²2该语料库可以在我们的项目仓库中找到。，基于这些分析，我们建立了一个基于LLM的多智能体协调策略的结构化表示。这一结构为整个探索过程奠定了基础框架。基于该结构，我们设计了一种生成方法，利用LLM的协调能力和领域知识，将用户提供的一般目标（AgentCoord: 视觉探索LLM基础的多智能体协作协调策略 <svg class="ltx_picture" height="13.7" id="S1.p4.1.pic1" overflow="visible" version="1.1" width="13.7"><g transform="translate(0,13.7) matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g fill="#44AAA8" stroke="#44AAA8" stroke-width="0.9pt" transform="matrix(1.0 0.0 0.0 1.0 -3.46 -2.98)"><foreignobject color="#44AAA8" height="5.96" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">a</foreignobject></g></g></svg>)转化为可执行的初步协调策略，帮助用户启动探索过程。为了确保生成策略各部分之间的一致性，我们将生成过程分为三个阶段：计划大纲生成（AgentCoord: 视觉探索LLM基础的多智能体协作协调策略 <svg class="ltx_picture" height="13.7" id="S1.p4.2.pic2" overflow="visible" version="1.1" width="13.7"><g transform="translate(0,13.7) matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g fill="#44AAA8" stroke="#44AAA8" stroke-width="0.9pt" transform="matrix(1.0 0.0 0.0 1.0 -3.84 -4.8)"><foreignobject color="#44AAA8" height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="7.69">b</foreignobject></g></g></svg>)，用于制定实现目标的整体协作计划；任务分配（AgentCoord: 视觉探索LLM基础的多智能体协作协调策略 <svg class="ltx_picture" height="13.7" id="S1.p4.3.pic3" overflow="visible" version="1.1" width="13.7"><g transform="translate(0,13.7) matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g fill="#44AAA8" stroke="#44AAA8" stroke-width="0.9pt" transform="matrix(1.0 0.0 0.0 1.0 -3.07 -2.98)"><foreignobject color="#44AAA8" height="5.96" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.15">c</foreignobject></g></g></svg>)，用于给计划大纲中的每个任务分配智能体；以及任务过程生成（AgentCoord: 视觉探索LLM基础的多智能体协作协调策略 <svg class="ltx_picture" height="13.7" id="S1.p4.4.pic4" overflow="visible" version="1.1" width="13.7"><g transform="translate(0,13.7) matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g fill="#44AAA8" stroke="#44AAA8" stroke-width="0.9pt" transform="matrix(1.0 0.0 0.0 1.0 -3.84 -4.8)"><foreignobject color="#44AAA8" height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="7.69">d</foreignobject></g></g></svg>)，用于指定已分配的智能体如何协作完成任务。为了简化用户在替代策略之间的探索与迭代优化，我们提出了一组交互方法（AgentCoord: 视觉探索LLM基础的多智能体协作协调策略 <svg class="ltx_picture" height="13.7" id="S1.p4.5.pic5" overflow="visible" version="1.1" width="13.7"><g transform="translate(0,13.7) matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g fill="#44AAA8" stroke="#44AAA8" stroke-width="0.9pt" transform="matrix(1.0 0.0 0.0 1.0 -3.07 -2.98)"><foreignobject color="#44AAA8" height="5.96" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.15">e</foreignobject></g></g></svg> <svg class="ltx_picture" height="13.7" id="S1.p4.6.pic6" overflow="visible" version="1.1" width="13.7"><g transform="translate(0,13.7) matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g fill="#44AAA8" stroke="#44AAA8" stroke-width="0.9pt" transform="matrix(1.0 0.0 0.0 1.0 -2.11 -4.8)"><foreignobject color="#44AAA8" height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="4.23">f</foreignobject></g></g></svg> <svg class="ltx_picture" height="13.7" id="S1.p4.7.pic7" overflow="visible" version="1.1" width="13.7"><g transform="translate(0,13.7) matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g fill="#44AAA8" stroke="#44AAA8" stroke-width="0.9pt" transform="matrix(1.0 0.0 0.0 1.0 -3.46 -1.63)"><foreignobject color="#44AAA8" height="8.65" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">g</foreignobject></g></g></svg>)，帮助用户在每个生成阶段借助LLM视觉探索设计空间。每当用户对某一策略感到满意时，他们可以启动协作并检查执行结果，该结果通过视觉增强并与之前的阶段链接，以便于高效验证（AgentCoord: 视觉探索LLM基础的多智能体协作协调策略 <svg class="ltx_picture" height="13.7" id="S1.p4.8.1.pic1" overflow="visible" version="1.1" width="13.7"><g transform="translate(0,13.7) matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g fill="#44AAA8" stroke="#44AAA8" stroke-width="0.9pt" transform="matrix(1.0 0.0 0.0 1.0 -3.84 -4.8)"><foreignobject color="#44AAA8" height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="7.69">h</foreignobject></g></g></svg>)。

为了验证该框架的可行性和有效性，我们开发了一个名为AgentCoord的互动系统，允许用户直观地探索基于LLM的多智能体协作的协调策略，有效地在设计过程中整合了LLM和用户的先验知识。我们的用户研究涉及12名对基于LLM的多智能体协作感兴趣的用户，研究结果表明，我们的方法能够有效地促进LLM-based多智能体协调策略的设计过程，并且具有使更广泛用户群体能够平等参与智能体协调的潜力。总之，我们的贡献包括：

+   •

    一个可视化探索框架，使普通用户能够高效设计基于LLM的多智能体协作的协调策略。

+   •

    AgentCoord ³³3项目仓库： [https://github.com/AgentCoord/AgentCoord](https://github.com/AgentCoord/AgentCoord)，一个开源互动系统，通过一系列交互和视觉设计实现我们的框架，帮助促进协调策略的探索。

+   •

    一项正式的用户研究，展示了我们方法的可行性和有效性。

## 2 相关工作

### 2.1 基于LLM的多智能体协作

大型语言模型（LLM）最近展现了作为多功能任务解决代理的令人印象深刻的能力，吸引了业界和学术界的广泛关注[[32](https://arxiv.org/html/2404.11943v1#bib.bib32)、[41](https://arxiv.org/html/2404.11943v1#bib.bib41)]。由于LLM是基于自然语言语料库训练的，这些语料库偏向于人类思维[[45](https://arxiv.org/html/2404.11943v1#bib.bib45)]，并且经过优化以进行对话[[23](https://arxiv.org/html/2404.11943v1#bib.bib23)]，因此基于LLM的智能体能够通过自然语言以类似人类的方式进行协作，并充分利用协作所带来的各种好处。

最近的研究开始尝试协调具有不同专业领域的智能体，以提高在各类任务中的表现，这些任务能够从多样化的知识中受益。Medagent [[28](https://arxiv.org/html/2404.11943v1#bib.bib28)] 汇集了不同专科的医疗智能体，提供对患者状况和治疗方案的全面分析。MetaGPT [[12](https://arxiv.org/html/2404.11943v1#bib.bib12)] 和ChatDev [[25](https://arxiv.org/html/2404.11943v1#bib.bib25)] 使得具有不同角色的智能体，如产品经理、设计师和程序员，能够在软件开发中协作，从而提高软件的质量。MARG[[5](https://arxiv.org/html/2404.11943v1#bib.bib5)] 开发了一个框架，整合多个专家智能体的能力来审阅科学论文。AutoAgents[[3](https://arxiv.org/html/2404.11943v1#bib.bib3)] 和OKR-Agent[[44](https://arxiv.org/html/2404.11943v1#bib.bib44)] 展示了创意内容任务，如创意写作和故事板生成，如何从具有多元领域背景的智能体协作中受益。AgentVerse[[4](https://arxiv.org/html/2404.11943v1#bib.bib4)] 展示了多个具有不同背景的专家如何协作，提供氢气储存站选址解决方案的场景。

此外，最近的研究发现，多个智能体可以协同工作，促进类似人类的认知协同[[20](https://arxiv.org/html/2404.11943v1#bib.bib20)]。Chan等人要求多个智能体从不同角度进行深入讨论，以促进一种比单独评估更为全面的评估。Liang等人[[15](https://arxiv.org/html/2404.11943v1#bib.bib15)] 和Du等人[[6](https://arxiv.org/html/2404.11943v1#bib.bib6)] 让多个智能体互相辩论，鼓励更深层次的思考。Zhuge等人[[45](https://arxiv.org/html/2404.11943v1#bib.bib45)] 提出了“头脑风暴”的概念，描述了多个智能体通过多轮交流来迭代想法，从而找到一个通常优于任何单一解决方案的答案。

尽管在各个领域中多智能体协作展现出了巨大的潜力，但大多数工作仍然需要编写代码来设计智能体的协调策略，这限制了普通用户的使用。虽然AutoGen [[38](https://arxiv.org/html/2404.11943v1#bib.bib38)] 和AutoAgents [[3](https://arxiv.org/html/2404.11943v1#bib.bib3)] 支持用纯自然语言表示协调策略，但用户在使用自然语言探索和设计协调策略时仍然会遇到一系列问题。我们的工作尝试通过结构化生成协调策略和一套可视化方法，解决这些问题，以帮助用户理解和探索协调策略。

### 2.2 使用大型语言模型生成协调策略

尽管基于LLM的智能体在协作完成任务方面展现出了巨大的潜力，但手动设计协作策略往往具有挑战性，耗时且有时需要特定领域的专业知识[[14](https://arxiv.org/html/2404.11943v1#bib.bib14)]。因此，非常有必要利用LLM固有的协作能力和跨任务的先验知识，来帮助设计智能体协作的协调策略。

许多关于多智能体协作的研究利用了大语言模型（LLM）的先验知识来形成和调整智能体团队。王等人[[33](https://arxiv.org/html/2404.11943v1#bib.bib33)]提示LLM根据任务查询动态识别一组智能体角色。Medagent [[28](https://arxiv.org/html/2404.11943v1#bib.bib28)]提示LLM作为医学专家，专注于将特定的医学场景分类到特定的医学领域，并召集相应的专家智能体。DyLAN [[18](https://arxiv.org/html/2404.11943v1#bib.bib18)]利用LLM对智能体的表现进行评分，并在协作过程中动态优化团队组织。Autogen的AgentBuilder模块[[38](https://arxiv.org/html/2404.11943v1#bib.bib38)]提示LLM根据当前任务生成多个智能体的系统提示，并将它们添加到群聊中进行协作。AutoAgents [[3](https://arxiv.org/html/2404.11943v1#bib.bib3)]设计了一个基于LLM的智能体观察器，用于检查智能体是否符合要求并提出调整建议。

LLM也被广泛应用于帮助规划多个智能体的协作过程。例如，AutoAgents [[3](https://arxiv.org/html/2404.11943v1#bib.bib3)]提示LLM草拟一份协作计划，指定每个步骤中涉及的智能体及其预期输出。在Autogen的群聊模式[[38](https://arxiv.org/html/2404.11943v1#bib.bib38)]中，用户可以扮演管理员智能体的角色，与基于LLM的规划智能体一起草拟和完善协作计划。OKR-agent [[44](https://arxiv.org/html/2404.11943v1#bib.bib44)]利用LLM递归地分解团队智能体的任务。此外，AgentVerse [[4](https://arxiv.org/html/2404.11943v1#bib.bib4)]设计了一个协作决策阶段，供多个基于LLM的智能体进行短期规划。

我们的工作更加关注如何利用LLM帮助普通用户设计自己的多智能体协作策略。为此，我们提出了一种基于LLM的三阶段生成方法，根据用户的目标生成结构化的协作策略。此外，我们还提出了一组交互方式，帮助用户在探索过程中灵活利用LLM的协作能力。

### 2.3 基于LLM的智能体接口

在执行基于LLM的智能体时，涉及大量复杂的信息，这些信息在纯文本终端中很难消化[[35](https://arxiv.org/html/2404.11943v1#bib.bib35)，[19](https://arxiv.org/html/2404.11943v1#bib.bib19)]。因此，非常需要一些界面来帮助理解和干预执行过程。早期用于监控单个LLM智能体的界面[[26](https://arxiv.org/html/2404.11943v1#bib.bib26)，[40](https://arxiv.org/html/2404.11943v1#bib.bib40)，[30](https://arxiv.org/html/2404.11943v1#bib.bib30)]通常采用大纲视图来展示整体执行过程，并通过突出显示和图标增强详细文本块。对于在虚拟沙箱环境中部署多个智能体的系统[[24](https://arxiv.org/html/2404.11943v1#bib.bib24)，[16](https://arxiv.org/html/2404.11943v1#bib.bib16)，[43](https://arxiv.org/html/2404.11943v1#bib.bib43)，[25](https://arxiv.org/html/2404.11943v1#bib.bib25)]，通常会提供全景视图，将文本形式的信息转化为具体的视觉元素（例如移动的智能体头像、富有表现力的表情符号），以便更容易理解整体过程。拓扑结构如树形图和图形也被用来可视化和管理智能体的执行过程。SPROUT[[17](https://arxiv.org/html/2404.11943v1#bib.bib17)]采用树形结构来帮助用户可视化和控制智能体编写代码教程的过程。Hong等人[[11](https://arxiv.org/html/2404.11943v1#bib.bib11)]使用分层图形结构来管理数据科学智能体的执行过程，并允许用户在执行过程中交互式地编辑图形。AutoGen [[38](https://arxiv.org/html/2404.11943v1#bib.bib38)]引入了转移图，允许用户限制智能体转移，以减少多智能体协作中群聊模式下智能体转移时的次优风险。最近，AgentLens[[19](https://arxiv.org/html/2404.11943v1#bib.bib19)]首次尝试设计一种可视化分析系统，帮助用户分析LLM基础的多智能体系统中的智能体行为。

在此研究的基础上，我们的工作使普通用户能够直观地探索基于大型语言模型（LLM）的多智能体协作中的协调策略。

## 3 形成性研究

为了深入了解用户如何使用当前基于自然语言的框架来协调多个基于LLM的智能体，并识别在协调策略探索过程中存在的挑战，我们进行了形成性研究。根据形成性研究的结果，我们制定了四个设计要求，以增强为LLM基础的多智能体协作设计协调策略的过程。

### 3.1 参与者和程序

我们招募了8名具有LLM-based多智能体协作经验或对其有兴趣的参与者，来自当地大学和开放源代码多智能体框架的在线讨论平台。四名是有经验的LLM-based多智能体系统专家（E1和E2是熟悉LLM-based多智能体协作的NLP研究人员，而E3和E4是有构建多智能体系统经验的开发者）。另外四名（G1-4）是对LLM-based智能体有基本了解并有兴趣构建自己的LLM-based多智能体协作策略的普通用户。

程序：在我们的初步访谈中，我们首先询问参与者是否有使用过任何基于LLM的多智能体框架或系统的经验。之后，我们展示了如何使用自然语言指定多智能体协作的协调策略，使用AutoAgents[[3](https://arxiv.org/html/2404.11943v1#bib.bib3)]与文本编辑器以及AutoGen的“群聊模式”[[38](https://arxiv.org/html/2404.11943v1#bib.bib38)]。在参与者熟悉使用方法后，他们被要求选择一个能够通过多LLM智能体协作获益的任务，并分别使用这两个系统构建自己的协调策略。参与者还可以在此过程中使用ChatGPT来帮助设计协调策略。最后，我们收集了参与者在构建协调策略过程中的反馈，并询问他们在此过程中遇到的挑战。对于在访谈开始时报告有过使用基于LLM的多智能体框架经验的参与者，我们还要求他们将基于自然语言的方法与他们之前使用过的框架进行对比，分析其优缺点。

### 3.2 发现

所有参与者都认为使用自然语言设计协调策略是直观的，并且这种方法有可能成为使更广泛的公众能够民主化智能体协调的有前景的方式。然而，也发现了一些挑战，阻碍了参与者在设计协调策略时的自由探索过程。

缺乏结构来规范自然语言的模糊性。尽管自然语言易于理解且表达力强，但它容易产生歧义。例如，对于一个高层次的合作策略描述“药物化学家、专利代理人和临床研究科学家共同起草专利申请”，可能会有许多模糊的方面：“谁负责主要的起草工作？”，“意见如何整合？”……在形成性研究过程中，我们注意到用户通常先从生成的合作策略开始，然后在观察到意外结果时，识别出未明确表达的领域，并对原始合作策略进行补充完善。经过几轮后，合作策略规范“可能会变得冗长且难以阅读”（G4），并且“有时甚至会包含自相矛盾的内容”（G3）。E1和E4都建议“应该提供一些结构来规范设计过程”（E1，E4），这可以“借鉴当前基于代码的框架设计”（E1）。

在大量复杂的文本中迷失。在设计合作策略的过程中，用户需要参考大量的文本信息（例如，之前设计的合作策略、不同代理人的描述、代理人的输入/输出、中间对象）。大量复杂的文本在设计过程中给用户带来了显著的认知负担。许多参与者表示，文本数量“压倒性”（E3，E4，G1-G4）。他们通常需要“手动在不同的文本部分之间来回切换”（G2）并且“有时会忘记在哪里查找”（G3）。E3提到，“随着策略复杂性的增加，保持特定执行结果与相应策略部分的清晰联系变得具有挑战性”（E3）。参与者还表示需要“有一个可视化界面来帮助组织信息”（G2，E3）。

缺乏交互支持来促进探索。为了利用LLM强大的协调能力并应对“写作障碍”，参与者通常会与LLM（例如使用ChatGPT）进行聊天，以帮助他们起草和探索协调策略。然而，线性的、不可逆的聊天界面并未针对迭代的多线程探索进行设计。E2提到，“管理探索历史并在不同的可能性之间切换，通过手动复制和粘贴是很繁琐的”（E2）。此外，参与者还提到，由于需要“手动制作辅助提示来进行不同的探索目的”，探索的流畅性也成为了问题（G2）。此外，由于LLM输出的随机性（这也受到提示的重大影响）以及策略设计的多样性，参与者表示需要“一种界面来帮助系统性地探索和比较LLM的不同输出”（G1）。

### 3.3 设计需求

针对初步研究中发现的问题，我们的目标是开发一个互动系统，帮助普通用户顺利地探索和设计基于LLM的多智能体协作的协调策略。设计需求总结如下：

R1：为用户的目标生成结构化的协调策略。尽管使用自然语言描述协调策略降低了用户的门槛并带来了高度的灵活性，但用户往往缺乏有效的方式来处理其模糊性。因此，系统应提供协调策略的结构，帮助规范自然语言中固有的模糊性，并作为下游探索的支撑架构。此外，为了帮助用户入门，系统应能够根据用户的目标生成初步的协调策略，利用LLMs的协调能力。

R2：为策略提供有效的视觉组织。当用户制定协调策略时，他们需要参考以文本形式呈现的各种相关信息。然而，目前，用户必须在大量纯文本中来回翻阅，寻找目标信息并进行验证，这带来了显著的认知负担。因此，系统应有效地视觉组织并增强协调策略设计过程中涉及的各种信息，帮助用户快速定位所需信息并提供相关上下文。

R3：支持灵活的交互方式，以促进策略探索。用户通常需要在协调策略设计的不同阶段，借助大型语言模型（LLMs）探索各种可能的选项；然而，基于线性聊天界面的迭代探索既繁琐又不直观。因此，系统应支持灵活且直观的交互方式，帮助用户进行多线程迭代探索。此外，系统还需要提供帮助，以帮助用户系统地探索和比较不同的协调策略设计选择。

R4：为执行结果提供视觉增强。在协作任务执行过程中，智能体会生成大量的文本信息。然而，目前基于代码和基于自然语言的智能体协调框架仅通过纯文本终端输出结果。用户往往需要手动在协调策略的不同部分和执行结果之间来回切换，以建立连接，这增加了认知负担并降低了分析效率。因此，系统需要提供视觉增强功能，帮助用户检查执行结果。

## 4 结构化协调策略生成

在本节中，我们为协调策略设计抽象了一个结构化表示（第[4.1](https://arxiv.org/html/2404.11943v1#S4.SS1 "4.1 协调策略的结构化表示 ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于 LLM 的多智能体协作的协调策略可视化探索")节），以规范自然语言的模糊性（R1）。基于这个结构，我们设计了一个三阶段生成方法（第[4.2](https://arxiv.org/html/2404.11943v1#S4.SS2 "4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于 LLM 的多智能体协作的协调策略可视化探索")节），自动生成基于用户目标的初步协调策略（R1）。

### 4.1 协调策略的结构化表示

为了最大化协调策略结构的表现力，E1-4 和我们共同调查了 25 篇基于 LLM 的多智能体协作论文和 7 个高星开源框架 [[12](https://arxiv.org/html/2404.11943v1#bib.bib12), [14](https://arxiv.org/html/2404.11943v1#bib.bib14), [38](https://arxiv.org/html/2404.11943v1#bib.bib38), [21](https://arxiv.org/html/2404.11943v1#bib.bib21), [3](https://arxiv.org/html/2404.11943v1#bib.bib3), [25](https://arxiv.org/html/2404.11943v1#bib.bib25), [4](https://arxiv.org/html/2404.11943v1#bib.bib4)]，以用于多智能体协调。我们分析了这些论文和项目中协调策略描述中常见的概念和结构，基于此，我们为基于 LLM 的多智能体协调策略建立了一个通用结构。

我们描述了协调策略结构中涉及的关键概念之间的关系，如下所示：

+   •

    计划大纲：为整体协作提供蓝图，通常将目标分解为一个接一个执行的任务序列。

+   •

    任务：以关键对象为输入，并输出其目标关键对象。任务过程指定了智能体如何协作完成任务。

+   •

    关键对象：协作过程中重要的中介对象。

+   •

    智能体：能够根据其观察和指令执行动作的智能实体。

+   •

    动作：智能体行为的最小观察单元。

+   •

    指令：基于自然语言的规范，告知智能体做什么/如何做。

### 4.2 三阶段策略生成

为了帮助用户启动探索，我们设计了一个三阶段生成方法，基于用户的目标提供初步的协调策略，利用 LLM 的协调能力。所有使用的提示的详细信息可以在我们的项目仓库中找到。

#### 4.2.1 阶段 1：计划大纲生成

给定用户提供的目标$g$的总体描述和一组初始关键对象$\mathcal{I}=\{ko_{1},ko_{2},...,ko_{n}\}$，计划大纲生成阶段的目标是草拟一个计划大纲，将最终目标分解为一系列步骤任务$\mathcal{P}=\{t_{1},t_{2},...,t_{n}\}=\{t_{i}\}|_{i=0}^{n}$。这里，每个任务$t_{i}$包含以下属性：

+   •

    步骤名称：总结该步骤的清晰简明名称。

+   •

    任务内容：当前步骤的任务描述。

+   •

    输入对象列表：当前步骤将使用的输入关键对象。

+   •

    输出对象：当前步骤的输出关键对象。

为了实现这一目标，我们提示LLM充当专家计划大纲设计师，仔细分析并分解用户提供的目标，输出计划大纲$\mathcal{P}$：

|  | $\mathcal{P}=\text{LLM}(g,\mathcal{I},\texttt{prompt}_{\texttt{stage1}})$ |  | (1) |
| --- | --- | --- | --- |

#### 4.2.2 阶段2：代理分配

在生成计划大纲后，应为每个任务$t_{i}$分配一组代理$\mathcal{A}_{i}=\{agent_{1},agent_{2},...,agent_{n}\}$。这些代理是从用户提供的代理候选人名单$\mathcal{AB}=\{agent_{1},agent_{2},...agent_{m}\}(\mathcal{A}_{i}\subseteq \mathcal{AB})$中选择的。代理候选人名单$\mathcal{AB}$中的代理可以通过角色提示[[42](https://arxiv.org/html/2404.11943v1#bib.bib42)]、LLM微调[[34](https://arxiv.org/html/2404.11943v1#bib.bib34)]、检索增强生成（RAG）[[13](https://arxiv.org/html/2404.11943v1#bib.bib13)]，甚至从代理商店招募[[1](https://arxiv.org/html/2404.11943v1#bib.bib1), [22](https://arxiv.org/html/2404.11943v1#bib.bib22), [31](https://arxiv.org/html/2404.11943v1#bib.bib31)]。每个代理应有一个个人资料，描述其专长，以供协调员参考。

为了为每个任务$t_{i}$进行适当的代理分配，我们提示LLM充当专家经理，分析任务$t_{i}$所需的能力方面，并读取代理候选人名单$\mathcal{AB}$中每个代理的个人资料，以输出$\mathcal{A}_{i}$：

|  | $\mathcal{A}_{i}=\text{LLM}(g,t_{i},\mathcal{AB},\texttt{prompt}_{\texttt{stage\%2}})$ |  | (2) |
| --- | --- | --- | --- |

图1：AgentCoord系统界面。前三个视图（计划大纲视图、代理分配视图、任务过程视图）对应于三阶段的协调策略生成过程，而最后一个视图展示了执行结果。

#### 4.2.3 阶段3：任务过程生成

一旦代理团队$\mathcal{A}_{i}$被分配到任务$t_{i}$，我们最终可以指定任务过程$\mathcal{S}_{i}=\{action_{1},action_{2},...,action_{n}\}$，描述代理如何协作完成任务$t_{i}$。这里，每个行动包含以下属性：

+   •

    代理名称：执行此操作的代理名称。

+   •

    指令：执行该操作的指令，告诉代理应该如何做。

+   •

    交互类型：根据合作交互类型分类动作，可以是以下之一：“提议”（提出可能有助于当前任务的内容）、“批评”（对其他代理的行动结果提供反馈）、“改进”（改进先前行动的结果）和“最终确定”（基于先前的行动交付当前任务的最终结果）。

+   •

    重要输入：执行当前动作时重要的先前信息，可能是其他代理的某些行动结果或先前的关键对象。

请注意，虽然仅使用“代理名称”和“描述”来定义执行动作就足够了，但在此我们提出了两个辅助属性（“交互类型”和“重要输入”）来帮助阐明它在协作背景下与其他动作的关系。

为了生成任务过程 $t_{i}$ 的规范，我们提示 LLM 作为专家协作协调员，仔细阅读分配给当前任务 $t_{i}$ 的每个代理的资料，并输出任务过程规范 ${S}_{i}$：

|  | $\mathcal{S}_{i}=\text{LLM}(g,t_{i},\mathcal{A}_{i},\texttt{prompt}_{\texttt{% stage3}})$ |  | (3) |
| --- | --- | --- | --- |

## 5 AgentCoord 系统

在本节中，我们详细阐述了 AgentCoord 系统如何通过可视化方式组织协调策略（第 [5.1](https://arxiv.org/html/2404.11943v1#S5.SS1 "5.1 Visual Organization for Coordination Strategy ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration") 节）以便用户理解（R2），提供交互来帮助探索替代策略（R3）（第 [5.2](https://arxiv.org/html/2404.11943v1#S5.SS2 "5.2 Interactive Exploration for Alternative Strategy ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration") 节），并通过可视化增强文本形式的执行结果以辅助审查（R4）（第 [5.3](https://arxiv.org/html/2404.11943v1#S5.SS3 "5.3 Execution Result Examination ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration") 节）。为了便于理解系统的使用，我们通过一个示例来说明它如何协调多个基于 LLM 的代理进行写作小说。

### 5.1 协调策略的可视化组织

为了首先获得一个初步的协调策略以启动探索，用户点击代理面板中的图标 ([图 1](https://arxiv.org/html/2404.11943v1#S4.F1 "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于大语言模型的多代理协作的协调策略可视化探索")) 来添加一个候选代理池，并输入“写一篇关于人工智能觉醒的小说”作为协作的总体目标。过一会儿，系统返回一个初步的协调策略，指定从代理面板中选择的若干代理如何协作以实现给定目标。

如[图 1](https://arxiv.org/html/2404.11943v1#S4.F1 "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于大语言模型的多代理协作的协调策略可视化探索")所示，生成的协调策略被可视化地组织成四个子视图。特别地，前三个子视图——计划大纲视图 ([图 1](https://arxiv.org/html/2404.11943v1#S4.F1 "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于大语言模型的多代理协作的协调策略可视化探索"))、代理面板视图 ([图 1](https://arxiv.org/html/2404.11943v1#S4.F1 "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于大语言模型的多代理协作的协调策略可视化探索")) 和任务流程视图 ([图 1](https://arxiv.org/html/2404.11943v1#S4.F1 "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于大语言模型的多代理协作的协调策略可视化探索"))——对应于第[4.2节](https://arxiv.org/html/2404.11943v1#S4.SS2 "4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于大语言模型的多代理协作的协调策略可视化探索")中描述的三阶段协调策略生成过程。用户可以在每个视图内垂直滚动，查看各自的方面。此外，当用户对某个特定任务的信息感兴趣时，点击该任务将显示详细信息，并在其他视图中可视化地连接其相关信息。

计划大纲视图展示了用户输入的整体目标如何被分解为一系列步骤任务。为了阐明不同任务之间的依赖关系，我们使用二分图来表示关键对象集（[图 1](https://arxiv.org/html/2404.11943v1#S4.F1 "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于大语言模型的多代理协作策略可视化探索")）与整个过程的任务顺序（[图 1](https://arxiv.org/html/2404.11943v1#S4.F1 "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于大语言模型的多代理协作策略可视化探索")）之间的关系。关键对象节点可以是任务节点的输出，也可以通过用户点击[图 1](https://arxiv.org/html/2404.11943v1#S4.F1 "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于大语言模型的多代理协作策略可视化探索")中的按钮由用户提供。任务节点通过绿色边与其输入关键对象连接，通过橙色边与其输出关键对象连接。此外，用户可以通过点击任务节点（[图 1](https://arxiv.org/html/2404.11943v1#S4.F1 "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于大语言模型的多代理协作策略可视化探索")）手动调整任务内容及其与其他关键对象的依赖关系。如果用户想要探索替代的计划大纲，可以点击按钮调用计划大纲探索视图（详见第[5.2.1节](https://arxiv.org/html/2404.11943v1#S5.SS2.SSS1 "5.2.1 计划大纲探索 ‣ 5.2 替代策略的交互式探索 ‣ 5 AgentCoord 系统 ‣ AgentCoord：基于大语言模型的多代理协作策略可视化探索")）。

代理板视图展示了用户在协调策略设计过程中可以分配的所有代理。默认情况下，每个代理卡片（[图1](https://arxiv.org/html/2404.11943v1#S4.F1 "在4.2.2阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于LLM的多代理协作的协调策略可视化探索")）展示了代理的名称、头像和简介，供用户参考。如果用户当前专注于特定任务，则分配给该任务的代理将自动提升到代理板的顶部。此外，计划在当前任务中由代理执行的操作会被汇总并展示在其代理卡片内（[图1](https://arxiv.org/html/2404.11943v1#S4.F1 "在4.2.2阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于LLM的多代理协作的协调策略可视化探索")），帮助用户更好地理解其在当前任务中所扮演的角色。如果用户希望探索当前任务的替代代理分配方案，可以点击按钮调用代理分配探索视图（详见第[5.2.2](https://arxiv.org/html/2404.11943v1#S5.SS2.SSS2 "5.2.2 代理分配探索 ‣ 5.2 替代策略的互动探索 ‣ 5 AgentCoord系统 ‣ AgentCoord：基于LLM的多代理协作的协调策略可视化探索")节）。

任务流程视图提供了任务流程如何进行的自然语言描述。为了增强用户对描述的理解，我们为每个任务提供了基于模板的摘要（[图 1](https://arxiv.org/html/2404.11943v1#S4.F1 "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：面向基于大语言模型的多代理协作的协调策略可视化探索") ），其中关键元素得到了视觉突显——输入关键对象以绿色突出显示，输出关键对象以橙色突出显示，代理名称和任务内容则设置在灰色背景上。用户可以点击任务的基于模板的摘要，展开任务流程的详细规格说明（[图 1](https://arxiv.org/html/2404.11943v1#S4.F1 "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：面向基于大语言模型的多代理协作的协调策略可视化探索") ）。任务流程规范由一系列描述组成，阐述每个代理如何执行其操作以推动任务的完成。为了帮助用户从合作互动的角度理解这一过程，我们根据[4.2.3](https://arxiv.org/html/2404.11943v1#S4.SS2.SSS3 "4.2.3 阶段3：任务流程生成 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：面向基于大语言模型的多代理协作的协调策略可视化探索")节中解释的“互动类型”分类标准，使用不同的颜色突出显示每个操作的互动类型。此外，用户还可以手动调整每个操作的指令。如果用户想探索替代的任务流程规范，可以点击按钮调用任务流程探索视图（详见[5.2.3](https://arxiv.org/html/2404.11943v1#S5.SS2.SSS3 "5.2.3 任务流程探索 ‣ 5.2 替代策略的交互式探索 ‣ 5 AgentCoord 系统 ‣ AgentCoord：面向基于大语言模型的多代理协作的协调策略可视化探索")）。

### 5.2 替代策略的交互式探索

在理解当前的协调策略后，用户可以在三个特定方面互动式地探索其替代方案：计划概述（第[5.1节](https://arxiv.org/html/2404.11943v1#S5.SS1 "5.1 视觉化组织协调策略 ‣ 5 AgentCoord系统 ‣ AgentCoord：视觉化探索基于LLM的多智能体协作的协调策略")）、代理分配（第[5.2节](https://arxiv.org/html/2404.11943v1#S5.SS2 "5.2 替代策略的互动探索 ‣ 5 AgentCoord系统 ‣ AgentCoord：视觉化探索基于LLM的多智能体协作的协调策略")）和任务过程（第[5.3节](https://arxiv.org/html/2404.11943v1#S5.SS3 "5.3 执行结果检查 ‣ 5 AgentCoord系统 ‣ AgentCoord：视觉化探索基于LLM的多智能体协作的协调策略")）。对于每个方面，我们提供了一个示例，展示用户如何进行互动式探索。

#### 5.2.1 计划概述探索

图2：计划概述探索的示例。

从[图1](https://arxiv.org/html/2404.11943v1#S4.F1 "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于LLM的多代理协作的协调策略可视化探索")中展示的计划大纲来看，用户发现小说的多数关键元素（例如“主要主题”，“角色列表”）在“情节发展”任务之前就已确定，而最后两个任务（“写作草稿”，“审查和编辑”）则是比较常见的常规步骤，因此用户决定将这两个任务合并为一步，并探索“情节发展”之前任务的更多可能性。为此，用户打开了计划大纲探索视图（[图2](https://arxiv.org/html/2404.11943v1#S5.F2 "在 5.2.1 计划大纲探索 ‣ 5.2 互动探索替代策略 ‣ 5 AgentCoord 系统 ‣ AgentCoord：基于LLM的多代理协作的协调策略可视化探索")）。用户首先点击“情节发展”任务节点的底部，从该任务创建一个分支，并进入“添加一个步骤以最终确定”([图2](https://arxiv.org/html/2404.11943v1#S5.F2 "在 5.2.1 计划大纲探索 ‣ 5.2 互动探索替代策略 ‣ 5 AgentCoord 系统 ‣ AgentCoord：基于LLM的多代理协作的协调策略可视化探索") A)。在后台，LLM根据用户输入的需求提示完成此分支。新分支完成后，用户点击分支的起始点，进一步进入“调整情节发展之前的步骤，其他部分与基准相同”([图2](https://arxiv.org/html/2404.11943v1#S5.F2 "在 5.2.1 计划大纲探索 ‣ 5.2 互动探索替代策略 ‣ 5 AgentCoord 系统 ‣ AgentCoord：基于LLM的多代理协作的协调策略可视化探索") B)。请注意，这次用户还选择了一个分支（用绿色突出显示），以告诉LLM哪个分支是所输入需求中提到的“基准”，并设置新创建分支的数量为三个，以探索更多的可能性。系统随后返回三个在“情节发展”步骤之前有变动的分支([图2](https://arxiv.org/html/2404.11943v1#S5.F2 "在 5.2.1 计划大纲探索 ‣ 5.2 互动探索替代策略 ‣ 5 AgentCoord 系统 ‣ AgentCoord：基于LLM的多代理协作的协调策略可视化探索") C)。对比这三个选择后，用户最终选择中间的一个作为新的协作计划大纲。

#### 5.2.2 代理分配探索

图3：代理分配探索的示例说明。

用户发现“主题选择”步骤的任务仅涉及两个角色（“未来学家”和“科幻作家”）。然而，用户希望更多具有多样背景的角色能参与到主题的头脑风暴中。例如，用户希望有人能为故事注入浪漫元素，另外也希望有技术背景的人能确保主题的技术可行性。为了实现这一点，用户打开了角色分配探索视图。该视图通过热力图展示了每个角色在角色板上的得分，这些得分是基于LLM对完成当前任务所需的三项能力评估得出的（[图 3](https://arxiv.org/html/2404.11943v1#S5.F3 "In 5.2.2 Agent Assignment Exploration ‣ 5.2 Interactive Exploration for Alternative Strategy ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration") A）。为了帮助用户更好地关注那些可能更适合当前任务的角色，系统根据角色的当前平均得分，将已分配和未分配的角色按降序分别排序。用户随后进一步选择了两个方面（“AI技术理解”、“爱情元素理解”），并选择了他们认为重要的四个方面（“创造性思维”、“AI伦理知识”、“AI技术理解”、“爱情元素理解”）作为新的排序标准（[图 3](https://arxiv.org/html/2404.11943v1#S5.F3 "In 5.2.2 Agent Assignment Exploration ‣ 5.2 Interactive Exploration for Alternative Strategy ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration") B）。现在，用户发现有两个候选人（“AI科学家”和“AI工程师”）具有较强的AI技术背景。虽然两位候选人在AI技术理解方面都得了5分，但用户发现AI科学家在“创造性思维”和“AI伦理知识”的得分普遍较高。因此，用户决定将AI科学家加入团队。用户还发现，LLM认为“诗人”和“认知生理学家”可能对爱情元素有更深的理解。因此，用户将鼠标移动到相应的得分块上，以查看LLM评分的原因。在结合了用户自己的分析后（认为从诗意而非心理学的角度理解爱情更适合创意场景），用户决定将诗人加入当前任务团队，并点击确认新的角色分配。

#### 5.2.3 任务流程探索

图 4：任务流程探索的示例。

由于最终的故事写作任务直接影响小说的输出，用户决定在该步骤的任务过程中以更精细的粒度进行干预。特别是，用户希望伊莎贝拉（“科幻小说作家”）主导最终稿的写作，并关注故事的生动性。为此，用户打开了任务过程探索视图。用户首先点击分支的起点，输入“伊莎贝拉主导小说写作，而卡洛斯协助审阅”([图 4](https://arxiv.org/html/2404.11943v1#S5.F4 "在 5.2.3 任务过程探索 ‣ 5.2 交互式探索替代策略 ‣ 5 AgentCoord 系统 ‣ AgentCoord：基于大语言模型的多智能体协作视觉化协调策略") A)。在后台，LLM被提示根据这一需求生成新的任务过程。然而，用户发现，尽管伊莎贝拉确实承担了大部分写作工作，但迭代过程并未充分关注故事的生动性。因此，用户选择当前分支作为基准，并创建了另外三个分支，要求“每个草稿的改进应着重提升故事的生动性”([图 4](https://arxiv.org/html/2404.11943v1#S5.F4 "在 5.2.3 任务过程探索 ‣ 5.2 交互式探索替代策略 ‣ 5 AgentCoord 系统 ‣ AgentCoord：基于大语言模型的多智能体协作视觉化协调策略") B)。系统返回了符合该要求的三种任务过程变体([图 4](https://arxiv.org/html/2404.11943v1#S5.F4 "在 5.2.3 任务过程探索 ‣ 5.2 交互式探索替代策略 ‣ 5 AgentCoord 系统 ‣ AgentCoord：基于大语言模型的多智能体协作视觉化协调策略") C)。然后，用户从三者中选择最喜欢的一种并进一步进行迭代。

### 5.3 执行结果检查

一旦用户完成了协调策略的设计，他们可以通过点击执行结果视图中的按钮来执行策略并检查结果（[图 1](https://arxiv.org/html/2404.11943v1#S4.F1 "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：视觉探索基于LLM的多代理协作的协调策略")）。与像AuoGen[[38](https://arxiv.org/html/2404.11943v1#bib.bib38)]和AutoAgents[[3](https://arxiv.org/html/2404.11943v1#bib.bib3)]等系统仅以纯文本形式呈现执行结果不同，AgentCoord通过与先前设计阶段一致的视觉设计和显式的视觉链接增强结果，帮助用户建立执行结果与策略设计之间的联系。为了防止用户被过多的文本信息所淹没，我们提供了通过鼠标点击选择性展开相关结果的选项（[图 1](https://arxiv.org/html/2404.11943v1#S4.F1 "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：视觉探索基于LLM的多代理协作的协调策略")）。此外，为了减少分析的认知负担，并帮助揭示不同执行结果之间的联系，当用户聚焦于特定的执行结果时，其他具有潜在重要依赖关系的结果（基于[第 4.2.3 节](https://arxiv.org/html/2404.11943v1#S4.SS2.SSS3 "4.2.3 阶段3：任务流程生成 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：视觉探索基于LLM的多代理协作的协调策略") 中描述的重要输入字段）将以视觉方式与其相连。

## 6 用户研究

我们进行了一项用户研究，以评估我们的方法在促进代理协作的协调策略设计中的可行性和有效性。我们的评估重点包括：(1) 结构化协调策略生成方法的有效性。(2) 互动系统的整体有效性和可用性。(3) 与基于现有LLM的多代理协调框架的两个基线系统相比，支持协调策略设计的能力。

### 6.1 方法论

#### 6.1.1 参与者

我们招募了12名参与者（P1-P12），他们对基于LLM的多代理协作有一般兴趣，来自本地大学，其中3名女性和9名男性，年龄在23至28岁之间。为了减轻评估偏差，所有参与者未曾参与我们的形成性研究或方法设计过程。所有参与者都曾使用过ChatGPT。七名参与者听说过至少一个基于LLM的多代理系统或框架，四名参与者曾亲身接触过至少一个基于LLM的多代理系统或框架。

#### 6.1.2 实验设置

我们为比较研究设置了两个额外的基准系统[[36](https://arxiv.org/html/2404.11943v1#bib.bib36)、[9](https://arxiv.org/html/2404.11943v1#bib.bib9)、[8](https://arxiv.org/html/2404.11943v1#bib.bib8)]，与我们的系统一起进行比较。所有三个系统都使用 GPT4 作为默认的 LLM 模型。用户在实验过程中也可以随时使用 ChatGPT。在 AgentCoord 的策略设计阶段，我们允许用户切换到快速模式，该模式使用带有硬件加速的 Mistral 8$\times$7B 模型⁵⁵5https://groq.com/进行第一次生成，以平衡响应质量和效率。实验中使用的代理是通过角色提示生成的[[42](https://arxiv.org/html/2404.11943v1#bib.bib42)]，然后转换为三个系统所需的相应格式。

基准 A（具有简单 UI 的自动代理）：提供一组精心设计的提示，允许大语言模型（LLM）根据用户提供的目标生成逐步协调策略以进行合作。每个步骤以列表“[name1, name2, ..]”开头，指定参与的代理，并使用自然语言说明代理如何协作。提供一个简单的文本编辑器以进一步编辑策略。一旦用户满意，可以点击“执行”按钮开始合作。执行结果的输出显示在文本终端中。

基准 B（群聊模式下的 AutoGen）：允许在群聊中添加多个基于 LLM 的代理，并使用自然语言进行协调。在协调策略设计过程中，规划代理首先根据用户提供的总体目标和可用代理的资料草拟初步协调策略。用户扮演管理员代理的角色，通过与规划代理聊天，协作完善协调策略。一旦用户对协调策略满意，可以开始合作。执行结果的输出显示在文本终端中。

#### 6.1.3 程序

介绍与培训：我们首先简要向用户介绍实验的目标和相关背景。接着，我们收集了用户的基本信息，以及他们对基于 LLM 的多代理系统或框架的了解。随后，我们向参与者演示了如何使用这三个系统设计代理的协调策略。我们为参与者提供了足够的时间进行实验，并熟悉系统。在此过程中，他们可以随时提问。

任务流程：对于每个系统，参与者需要选择一个通用目标（例如，“为孩子们编写一个关于冒泡排序的有趣教程”，“为当地周末活动制定内容策略”）进行智能体协作，并使用给定的系统设计协调策略。在设计过程中，参与者需要完成四个子任务：1. 理解并判断系统生成的协调策略。2. 探索并改进生成的协作策略的至少三个不同方面。3. 至少执行一次协作策略并分析结果。4. 根据执行结果改进原始协作策略的至少一个领域。在用户完成子任务要求后，可以在没有时间限制的情况下自由进行开放式探索。系统的顺序是平衡的。

半结构化访谈：我们要求参与者填写一份五点Likert量表问卷，旨在评估我们系统的有效性和可用性（[图 5](https://arxiv.org/html/2404.11943v1#S6.F5 "在6.2.3 可用性 ‣ 6.2 结果分析 ‣ 6 用户研究 ‣ AgentCoord: 可视化探索基于LLM的多智能体协作策略")），以及所有系统的协调支持比较（[图 6](https://arxiv.org/html/2404.11943v1#S6.F6 "在6.2.3 可用性 ‣ 6.2 结果分析 ‣ 6 用户研究 ‣ AgentCoord: 可视化探索基于LLM的多智能体协作策略")）。对于每个问题，我们鼓励参与者解释他们评分的理由并提供任何意见。最后，我们收集用户对我们系统的总体反馈。

### 6.2 结果分析

#### 6.2.1 结构化策略生成的有效性

大多数参与者一致认为，协调策略的结构具有表现力且易于理解（Q1）。用户称赞该结构“清晰”（P5）且“直观”（P2）。P5评论道，“它从高层次到低层次，逻辑清晰。各部分之间的连接非常明确。”P7告诉我们，“提议的互动类型分类非常有帮助”，并且“希望系统的后续版本支持自定义和管理不同层级的分类粒度”。大多数参与者一致认为，协调策略的结构有助于设计过程（Q2）。用户赞赏该结构“提供了一个清晰的地图，展示了已探索的内容和接下来可能探索的内容”（P11）并且“使探索过程更加系统化且充满信心”（P8）。P10告诉我们，“该结构有助于增加预测性，并在探索过程中提升我提示LLM时的信心”。大多数参与者认为，生成的初始策略作为起始策略非常有帮助（Q3）。用户发现基准策略总是至少提供了一个“公平的起点”（P6），有时则“意外地好”（P3）。一些用户表达了需求，希望“有地方可以输入用户的偏好或先前的知识，以影响起始生成”（P5）。

#### 6.2.2 互动系统的有效性

策略的视觉组织。大多数参与者一致认为，协调策略的视觉组织有助于理解（Q4）。计划大纲视图被认为有助于“快速了解整体策略”（P2）并且“方便导航”（P9）。P11评论道，“我喜欢‘平行线设计’，任务之间的关系非常清晰地展示出来。”用户赞赏代理板视图中的“自适应信息展示”（P6），并希望能够“根据需要展示代理的历史表现”（P5）。任务过程视图中的文本高亮被用户广泛赞誉，帮助快速理解。然而，一些用户仍然觉得任务过程规范中需要阅读的文本量较大，希望“每个操作指令都有一个总结”（P3）。整体布局也因其美学性和一致性受到一些用户的赞赏。

替代策略的互动探索。用户普遍赞赏我们系统支持的探索交互。与此同时，用户认为探索历史的组织“极为方便”（P7）且“有助于专注于探索”（P10）。然而，我们注意到用户在使用三个探索视图时的频率和评价存在差异（Q5,6,7）。尽管计划大纲探索视图和过程探索视图都用于顺序结构的探索并且设计相似，我们发现参与者通常更倾向于在计划大纲探索视图中进行更多的探索。P5 解释道：“在决定整体协作的大纲时，我不确定该怎么做，想看到更多的可能性，高级自然语言需求的分支在这个阶段非常有用。另一方面，任务过程更注重更详细的层面，我通常不想花太多时间在探索上，只想直接修改”（P5）。代理分配探索视图是最受欢迎的探索视图。大多数用户发现使用热图可视化LLM的先验知识来进行代理分配“全面且富有洞察力”（P4），而交互方式“灵活且吸引人，适合探索”（P10）。

执行结果检查。大多数参与者一致认为执行结果视图有助于分析执行结果（Q8）。参与者确认，在检查结果时，容易将结果的任何部分与相应的策略设计连接起来。P7 评论道：“当我想分析某个结果时，我只需点击它，其他视图会自动显示相关的策略信息，提醒我之前的设计过程，真酷。”重要操作输入的追踪线也被认为是有帮助的。P9 提到他喜欢从某个任务的最终结果开始，并利用追踪线帮助回溯，查看最终结果是如何在过程中形成的，从而识别可能的改进点。

#### 6.2.3 可用性

大多数参与者一致认为我们的系统易于学习（Q9）和易于使用（Q10）。参与者评论称我们系统的界面“直观”（P2）且“清晰”（P5）。几位用户报告称，尽管系统的每个功能都容易理解，但仍然需要一些时间才能完全掌握系统，流畅使用。所有参与者表示愿意再次使用我们的系统（Q11）。P5 告诉我们，他希望“将来能够使用这个系统协调一些代理来帮助维护我的博客”（P5）。P1 表示愿意使用我们的系统快速原型化一些协调策略用于研究，表明该系统在基于LLM的多智能体系统的研究领域中具有潜力。

图5：关于我们系统的有效性和可用性问卷结果。

图 6：比较三种系统在协调策略设计支持方面的问卷结果。

#### 6.2.4 协调支持比较

为了将我们的系统与两个基准进行比较，评估其在协助协调策略设计过程中的表现，我们要求参与者对三个系统在设计过程中的三个方面（即策略理解、策略探索和结果分析）以及他们对最终结果的满意度进行评分。总体而言，我们的系统在所有四个方面都优于基准。我们总结了用户的反馈如下：

策略理解：在基准 B 中，基准协调策略由规划代理生成并进行改进，但没有任何结构约束。因此，在策略迭代过程中，“策略的格式可能会频繁波动，这让我感到不自信”（P3）。在基准 A 中，策略是通过精心设计的提示生成的，这些提示强制执行某些格式（例如，分步骤，并为每个步骤分配代理）。然而，纯文本中重复阅读和比较策略仍然让用户“感到压力”（P11）并且“对理解缺乏信心”（P8）。相比之下，我们的系统确保协调策略在整个设计过程中具有一致的结构，并提供视觉化的组织和增强功能，以促进理解。

策略探索：在基准 A 中，没有直接支持策略探索的功能，用户只能使用 ChatGPT 来辅助探索。然而，在界面之间转移策略并手动修改格式和逻辑一致性可能“繁琐且容易出错”（P7）。基准 B 允许用户通过与规划代理聊天来探索替代策略。然而，它缺乏支持用户根据需求灵活探索策略不同方面的功能。此外，随着探索过程的复杂化，文本量可能迅速让规划代理和用户感到不堪重负。我们的系统赋能用户，通过一系列交互灵活地探索策略的不同方面，并借助大语言模型（LLM）帮助用户可视化地组织探索历史。

结果分析：我们的系统总体上被认为在执行结果分析方面更加有帮助。在基准 A 和基准 B 中，执行结果直接输出到文本终端。P9 告诉我们，她必须“反复筛查文本，以追溯执行结果与之前操作之间的依赖关系”（P9）。相反，在我们的系统中，用户可以轻松地追溯每个结果到其重要的影响前因和相应的协调策略。

结果满意度：与基线A和基线B相比，用户对我们系统的结果总体上更为满意。在基线B中，由于自由形式的协调策略中经常存在模糊性，执行过程往往会偏离用户的预期，并且逐渐偏离，有时甚至会陷入无限循环。在基线A中，得益于强制性的逐步策略格式，避免了无限循环的问题。然而，结果通常会错过根据协调策略应该出现的一些重要部分（例如，在角色设计阶段决定的主要角色在最终故事中未能出现）。虽然我们的系统结果中也存在类似问题，但用户通常能够通过分析结果成功追溯问题的原因，并快速调整策略的相关部分加以修正。

## 7 讨论

在本节中，我们回顾了我们的研究，讨论了经验教训和系统的可推广性，并接着讨论了局限性和未来的工作。

### 7.1 经验教训

有结构的策略表示对人类与大型语言模型（LLMs）共同设计过程的好处。我们的评估结果表明，拥有结构化的协调策略表示对设计过程的体验至关重要。这种结构有助于对齐人类与LLMs的意图，迫使双方基于相同的概念和抽象层次进行思考和沟通，从而有效减少由自然语言模糊性引起的相互误解。此外，固定的结构使得可视化组织和增强的设计成为可能，促进人类对策略的理解，使他们能够高效地探索LLMs生成的更多策略可能性。另外，结构化的表示促进了结构化的探索过程，使用户倾向于采用更加系统化的协调策略设计过程。

可视化LLMs的先验知识以促进代理协调。尽管许多研究直接利用LLMs的先验知识生成协调策略，但如何有效提取并可视化这些先验知识以辅助策略设计尚未得到充分探索。我们发现，与仅仅从LLMs获取一个单一答案相比，当用户想要优化策略的某一部分时，他们更倾向于对LLMs的先验知识有一个更全局的理解。例如，与其仅仅让LLM选择可能为某一任务做出贡献的代理，利用交互式热力图可视化每个代理在LLMs认为重要的能力方面的评分，将更加有洞察力和系统化，便于策略设计。

### 7.2 系统可推广性

除了协调代理协作解决以目标为导向的任务外，我们的系统还具有扩展到各种应用的潜力。例如，用户可以使用我们的系统协调代理模拟和分析涉及多人的人类活动（如玩狼人杀游戏、参加辩论比赛、进行多方谈判等）。这些模拟不仅富有娱乐性，而且是研究人类/AI社会以及评估LLM特定能力的宝贵资源。未来，我们计划扩展AgentCoord的结构表示，以支持更多社会交互类型，以实现更灵活的模拟目的。我们还计划允许用户上传自定义的交互类型。

### 7.3 限制与未来工作

AgentCoord 当前仅支持在纯文本环境中协调代理进行协作，该环境包含文本形式的关键对象。一项有趣的未来工作是支持环境中的多模态关键对象，并允许具有多模态能力的代理进行协作。例如，写作代理生成故事，插画代理创作相应的视觉效果。

AgentCoord 当前仅支持静态协调策略设计。在某些场景中，用户可能希望在协作执行过程中动态调整策略，以适应实际情况。例如，用户可能协调多个代理来帮助进行文献研究：当某个代理找到一篇用户感兴趣的论文时，用户可能希望调整计划，将一组代理分配去阅读和讨论这篇论文，另外一组代理去调查该论文作者的背景。未来的研究可以帮助用户进行动态协调策略设计。

## 8 结论

本研究提出了一种可视化探索框架，旨在帮助设计基于LLM的多代理协作中的协调策略，解决了自然语言歧义和在策略设计过程中理解大量文本所需的认知努力等挑战。我们提出了一种协调策略的结构化表示，并采用三阶段生成方法，将用户提供的一般目标转化为可执行策略。我们以可视化方式组织生成的策略，便于用户理解，并提供一套交互方式，支持与LLM进行替代策略的探索。我们还提供了可视化增强功能，帮助用户分析执行结果。最后，我们进行了正式的用户研究，以验证我们方法的可行性和有效性。

## 参考文献

+   [1] Assem. NexusGPT Marketplace. [https://app.gpt.nexus/App/Marketplace/agents](https://app.gpt.nexus/App/Marketplace/agents), 2023. 访问时间：2024年3月1日。

+   [2] C.-M. Chan, W. Chen, Y. Su, J. Yu, W. Xue, S. Zhang, J. Fu, 和 Z. Liu. ChatEval：通过多智能体辩论改进基于LLM的评估器。在第十二届国际学习表示大会，2024年。[doi: 10.48550/arXiv.2308.07201](https://doi.org/10.48550/arXiv.2308.07201)

+   [3] G. Chen, S. Dong, Y. Shu, G. Zhang, S. Jaward, K. Börje, J. Fu, 和 Y. Shi. AutoAgents：自动智能体生成框架。CoRR，abs/2309.17288，2023年9月。[doi: 10.48550/arXiv.2309.17288](https://doi.org/10.48550/arXiv.2309.17288)

+   [4] W. Chen, Y. Su, J. Zuo, C. Yang, C. Yuan, C. Qian, C.-M. Chan, Y. Qin, Y. Lu, R. Xie 等人。AgentVerse：促进多智能体协作并探索智能体中的涌现行为。CoRR，abs/2308.10848，2023年8月。[doi: 10.48550/arXiv.2308.10848](https://doi.org/10.48550/arXiv.2308.10848)

+   [5] M. D’Arcy, T. Hope, L. Birnbaum, 和 D. Downey. MARG：用于科学论文的多智能体审查生成。CoRR，abs/2401.04259，2024年1月。[doi: 10.48550/arXiv.2401.04259](https://doi.org/10.48550/arXiv.2401.04259)

+   [6] Y. Du, S. Li, A. Torralba, J. B. Tenenbaum, 和 I. Mordatch. 通过多智能体辩论改进语言模型的事实性与推理能力。CoRR，abs/2305.14325，2023年5月。[doi: 10.48550/arXiv.2305.14325](https://doi.org/10.48550/arXiv.2305.14325)

+   [7] D. C. Engelbart. 增强人类智慧：一个概念框架。Routledge出版社，纽约，第1版，2023年。[doi: 10.4324/9781003230762](https://doi.org/10.4324/9781003230762)

+   [8] Y. Feng, X. Wang, B. Pan, K. K. Wong, Y. Ren, S. Liu, Z. Yan, Y. Ma, H. Qu, 和 W. Chen. Xnli：基于NLI的视觉数据分析的解释与诊断。IEEE《可视化与计算机图形学学报》，第1–14页，2023年。[doi: 10.1109/TVCG.2023.3240003](https://doi.org/10.1109/TVCG.2023.3240003)

+   [9] Y. Feng, X. Wang, K. K. Wong, S. Wang, Y. Lu, M. Zhu, B. Wang, 和 W. Chen. Promptmagician：面向文本到图像创作的交互式提示工程。IEEE《可视化与计算机图形学学报》，30(1)：295–305，2023年。[doi: 10.1109/TVCG.2023.3327168](https://doi.org/10.1109/TVCG.2023.3327168)

+   [10] Gravitas. AutoGPT。[https://github.com/Significant-Gravitas/AutoGPT](https://github.com/Significant-Gravitas/AutoGPT)，2023年。访问时间：2024年3月1日。

+   [11] S. Hong, Y. Lin, B. Liu, B. Wu, D. Li, J. Chen, J. Zhang, J. Wang, L. Zhang, M. Zhuge 等人。数据解释器：一个面向数据科学的LLM智能体。CoRR，abs/2402.18679，2024年2月。[doi: 10.48550/arXiv.2402.18679](https://doi.org/10.48550/arXiv.2402.18679)

+   [12] S. Hong, X. Zheng, J. Chen, Y. Cheng, J. Wang, C. Zhang, Z. Wang, S. K. S. Yau, Z. Lin, L. Zhou 等人。MetaGpt：多智能体协作框架的元编程。在第十二届国际学习表示大会，2024年。[doi: 10.48550/arXiv.2308.00352](https://doi.org/10.48550/arXiv.2308.00352)

+   [13] P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler, M. Lewis, W.-t. Yih, T. Rocktäschel, S. Riedel, 和 D. Kiela. 基于检索增强生成的知识密集型 NLP 任务。载于《神经信息处理系统进展》，第9459–9474页，2020年。[doi: 10.48550/arXiv.2005.11401](https://doi.org/10.48550/arXiv.2005.11401)

+   [14] G. Li, H. A. A. K. Hammoud, H. Itani, D. Khizbullin, 和 B. Ghanem. CAMEL：用于“大脑”探索的大语言模型社会中的交互式代理。载于《第三十七届神经信息处理系统大会》，2023年。[doi: 10.48550/arXiv.2303.17760](https://doi.org/10.48550/arXiv.2303.17760)

+   [15] T. Liang, Z. He, W. Jiao, X. Wang, Y. Wang, R. Wang, Y. Yang, Z. Tu, 和 S. Shi. 通过多代理辩论鼓励大语言模型的发散思维。CoRR, abs/2305.19118, 2023年5月。[doi: 10.48550/arXiv.2305.19118](https://doi.org/10.48550/arXiv.2305.19118)

+   [16] J. Lin, H. Zhao, A. Zhang, Y. Wu, H. Ping, 和 Q. Chen. AgentSims：一个开源沙盒，用于大语言模型评估。CoRR, abs/2308.04026, 2023年8月。[doi: 10.48550/arXiv.2308.04026](https://doi.org/10.48550/arXiv.2308.04026)

+   [17] Y. Liu, Z. Wen, L. Weng, O. Woodman, Y. Yang, 和 W. Chen. SPROUT：通过大语言模型生成过程的交互式可视化编写编程教程。CoRR, abs/2312.01801, 2023年12月。[doi: 10.48550/arXiv.2312.01801](https://doi.org/10.48550/arXiv.2312.01801)

+   [18] Z. Liu, Y. Zhang, P. Li, Y. Liu, 和 D. Yang. 动态 LLM-代理网络：一种基于 LLM 的代理团队优化协作框架。CoRR, abs/2310.02170, 2023年10月。[doi: 10.48550/arXiv.2310.02170](https://doi.org/10.48550/arXiv.2310.02170)

+   [19] J. Lu, B. Pan, J. Chen, Y. Feng, J. Hu, Y. Peng, 和 W. Chen. AgentLens：基于 LLM 的自主系统中代理行为的视觉分析。CoRR, abs/2402.08995, 2024年2月。[doi: 10.48550/arXiv.2402.08995](https://doi.org/10.48550/arXiv.2402.08995)

+   [20] A. I. Luppi, P. A. Mediano, F. E. Rosas, N. Holland, T. D. Fryer, J. T. O’Brien, J. B. Rowe, D. K. Menon, D. Bor, 和 E. A. Stamatakis. 人类大脑进化和认知的协同核心。*《自然神经科学》*，第25卷，第6期：771–782，2022年5月。[doi: 10.1038/s41593-022-01070-0](https://doi.org/10.1038/s41593-022-01070-0)

+   [21] J. MouraAbout. CrewAI. [https://github.com/joaomdmoura/crewAI](https://github.com/joaomdmoura/crewAI), 2023年。访问日期：2024年3月1日。

+   [22] OpenAI. OpenAI GPT Store. [https://openai.com/blog/introducing-the-gpt-store](https://openai.com/blog/introducing-the-gpt-store), 2023年。访问日期：2024年3月1日。

+   [23] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, J. Schulman, J. Hilton, F. Kelton, L. Miller, M. Simens, A. Askell, P. Welinder, P. F. Christiano, J. Leike, 和 R. Lowe. 训练语言模型以通过人类反馈遵循指令。在神经信息处理系统进展（Advances in Neural Information Processing Systems），第27730-27744页，2022年。[doi: 10.48550/arXiv.2203.02155](https://doi.org/10.48550/arXiv.2203.02155)

+   [24] J. S. Park, J. O’Brien, C. J. Cai, M. R. Morris, P. Liang, 和 M. S. Bernstein. 生成代理：人类行为的交互式模拟。在第36届年度ACM用户界面软件与技术研讨会（Symposium on User Interface Software and Technology）论文集，第1-22页，2023年。[doi: 10.1145/3586183.3606763](https://doi.org/10.1145/3586183.3606763)

+   [25] C. Qian, X. Cong, C. Yang, W. Chen, Y. Su, J. Xu, Z. Liu, 和 M. Sun. 用于软件开发的通信代理。CoRR，abs/2307.07924，2023年7月。[doi: 10.48550/arXiv.2307.07924](https://doi.org/10.48550/arXiv.2307.07924)

+   [26] ReWorkd. AgentGPT。 [https://github.com/reworkd/AgentGPT](https://github.com/reworkd/AgentGPT)，2023年。访问日期：2024年3月1日。

+   [27] L. Salewski, S. Alaniz, I. Rio-Torto, E. Schulz, 和 Z. Akata. 上下文模仿揭示大型语言模型的优势与偏见。在第三十七届神经信息处理系统会议（Neural Information Processing Systems），2023年。[doi: 10.48550/arXiv.2305.14930](https://doi.org/10.48550/arXiv.2305.14930)

+   [28] X. Tang, A. Zou, Z. Zhang, Y. Zhao, X. Zhang, A. Cohan, 和 M. Gerstein. MedAgents：大型语言模型作为零样本医学推理的协作者。CoRR，abs/2311.10537，2023年11月。[doi: 10.48550/arXiv.2311.10537](https://doi.org/10.48550/arXiv.2311.10537)

+   [29] L. Team. Langroid: 利用多代理编程发挥大型语言模型的优势。 [https://github.com/langroid/langroid](https://github.com/langroid/langroid)，2023年。访问日期：2024年3月1日。

+   [30] S. Team. SuperAGI。 [https://github.com/TransformerOptimus/SuperAGI](https://github.com/TransformerOptimus/SuperAGI)，2023年。访问日期：2024年3月1日。

+   [31] S. Team. SuperAGI Marketplace。 [https://marketplace.superagi.com/](https://marketplace.superagi.com/)，2023年。访问日期：2024年3月1日。

+   [32] L. Wang, C. Ma, X. Feng, Z. Zhang, H. Yang, J. Zhang, Z. Chen, J. Tang, X. Chen, Y. Lin 等。基于大型语言模型的自主代理调查。CoRR，abs/2308.11432，2023年8月。[doi: 10.48550/arXiv.2308.11432](https://doi.org/10.48550/arXiv.2308.11432)

+   [33] Z. Wang, S. Mao, W. Wu, T. Ge, F. Wei, 和 H. Ji. 释放大型语言模型中的涌现认知协同：通过多重人格自我协作解决任务的代理。CoRR，abs/2307.05300，2023年7月。[doi: 10.48550/arXiv.2307.05300](https://doi.org/10.48550/arXiv.2307.05300)

+   [34] J. Wei, M. Bosma, V. Y. Zhao, K. Guu, A. W. Yu, B. Lester, N. Du, A. M. Dai, 和 Q. V. Le. 微调语言模型是零-shot学习者. 在第十届国际学习表征大会（The Tenth International Conference on Learning Representations），2022年。[doi: 10 . 48550/arXiv . 2109 . 01652](https://doi.org/10.48550/arXiv.2109.01652)

+   [35] L. Weng, X. Wang, J. Lu, Y. Feng, Y. Liu, 和 W. Chen. Insightlens: 在大型语言模型驱动的数据分析中发现和探索对话背景中的洞察. arXiv, 2024年。[doi: 10 . 48550/ARXIV . 2404 . 01644](https://doi.org/10.48550/ARXIV.2404.01644)

+   [36] K. K. Wong, X. Wang, Y. Wang, J. He, R. Zhang, 和 H. Qu. Anchorage: 通过锚事件可视化分析客户服务视频中的满意度. IEEE Transactions on Visualization and Computer Graphics, 2023年。[doi: 10 . 48550/ARXIV . 2302 . 06806](https://doi.org/10.48550/ARXIV.2302.06806)

+   [37] A. W. Woolley, C. F. Chabris, A. Pentland, N. Hashmi, 和 T. W. Malone. 证明了人类群体在表现中的集体智慧因素. Science, 330(6004):686–688, 2010年9月。[doi: 10 . 1126/science . 1193147](https://doi.org/10.1126/science.1193147)

+   [38] Q. Wu, G. Bansal, J. Zhang, Y. Wu, S. Zhang, E. Zhu, B. Li, L. Jiang, X. Zhang, 和 C. Wang. AutoGen: 通过多代理对话框架实现下一代LLM应用. CoRR, abs/2308.08155, 2023年8月。[doi: 10 . 48550/arXiv . 2308 . 08155](https://doi.org/10.48550/arXiv.2308.08155)

+   [39] Y. Wu, F. Jia, S. Zhang, Q. Wu, H. Li, E. Zhu, Y. Wang, Y. T. Lee, R. Peng, 和 C. Wang. 关于利用GPT-4求解挑战性数学问题的实证研究. CoRR, abs/2306.01337, 2023年6月。[doi: 10 . 48550/arXiv . 2306 . 01337](https://doi.org/10.48550/arXiv.2306.01337)

+   [40] XAgent Team. XAgent: 一个用于复杂任务求解的自主代理。[https://github.com/OpenBMB/XAgent](https://github.com/OpenBMB/XAgent)，2023年。访问时间：2024年3月1日。

+   [41] Z. Xi, W. Chen, X. Guo, W. He, Y. Ding, B. Hong, M. Zhang, J. Wang, S. Jin, E. Zhou 等. 基于大型语言模型的代理的崛起与潜力：一项调查. CoRR, abs/2309.07864, 2023年9月。[doi: 10 . 48550/arXiv . 2309 . 07864](https://doi.org/10.48550/arXiv.2309.07864)

+   [42] B. Xu, A. Yang, J. Lin, Q. Wang, C. Zhou, Y. Zhang, 和 Z. Mao. ExpertPrompting: 指导大型语言模型成为卓越专家. CoRR, abs/2305.14688, 2023年5月。[doi: 10 . 48550/arXiv . 2305 . 14688](https://doi.org/10.48550/arXiv.2305.14688)

+   [43] H. Zhang, W. Du, J. Shan, Q. Zhou, Y. Du, J. B. Tenenbaum, T. Shu, 和 C. Gan. 使用大型语言模型模块化构建合作型具身代理. 在第十二届国际学习表征大会（The Twelfth International Conference on Learning Representations），2024年。[doi: 10 . 48550/arXiv . 2307 . 02485](https://doi.org/10.48550/arXiv.2307.02485)

+   [44] Y. Zheng, C. Ma, K. Shi 和 H. Huang. 代理与OKR相遇：一个基于目标与关键结果驱动的代理系统，具备分层自我协作和自我评估功能。CoRR, abs/2311.16542, 2023年11月。[doi: 10 . 48550/arXiv . 2311 . 16542](https://doi.org/10.48550/arXiv.2311.16542)

+   [45] M. Zhuge, H. Liu, F. Faccio, D. R. Ashley, R. Csordás, A. Gopalakrishnan, A. Hamdi, H. A. A. K. Hammoud, V. Herrmann, K. Irie 等人. 基于自然语言的心智社会中的思维风暴。CoRR, abs/2305.17066, 2023年5月。[doi: 10 . 48550/arXiv . 2305 . 17066](https://doi.org/10.48550/arXiv.2305.17066)
