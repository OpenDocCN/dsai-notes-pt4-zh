- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:50:50'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:50:50
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Exploring LLM-based Agents for Root Cause Analysis
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索基于LLM的代理进行根本原因分析
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2403.04123](https://ar5iv.labs.arxiv.org/html/2403.04123)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2403.04123](https://ar5iv.labs.arxiv.org/html/2403.04123)
- en: Devjeet Roy [devjeet.roy@wsu.edu](mailto:devjeet.roy@wsu.edu) Washington State
    UniversityPullmanWashingtonUSA99163 ,  Xuchao Zhang [xuchaozhang@microsoft.com](mailto:xuchaozhang@microsoft.com)
    MicrosoftRedmondWashingtonUSA98052 ,  Rashi Bhave MicrosoftBengaluruKarnatakaIndia560001
    ,  Chetan Bansal [chetanb@microsoft.com](mailto:chetanb@microsoft.com) MicrosoftRedmondWashingtonUSA98052
    ,  Pedro Las-Casas [pedrobr@microsoft.com](mailto:pedrobr@microsoft.com) MicrosoftRedmondWashingtonUSA98052
    ,  Rodrigo Fonseca [Fonseca.Rodrigo@microsoft.com](mailto:Fonseca.Rodrigo@microsoft.com)
    MicrosoftRedmondWashingtonUSA98052  and  Saravan Rajmohan [saravan.rajmohan@microsoft.com](mailto:saravan.rajmohan@microsoft.com)
    MicrosoftRedmondWashingtonUSA98052(2024)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Devjeet Roy [devjeet.roy@wsu.edu](mailto:devjeet.roy@wsu.edu) 华盛顿州立大学普尔曼华盛顿美国99163，Xuchao
    Zhang [xuchaozhang@microsoft.com](mailto:xuchaozhang@microsoft.com) 微软雷德蒙德华盛顿美国98052，Rashi
    Bhave 微软班加罗尔卡纳塔克邦印度560001，Chetan Bansal [chetanb@microsoft.com](mailto:chetanb@microsoft.com)
    微软雷德蒙德华盛顿美国98052，Pedro Las-Casas [pedrobr@microsoft.com](mailto:pedrobr@microsoft.com)
    微软雷德蒙德华盛顿美国98052，Rodrigo Fonseca [Fonseca.Rodrigo@microsoft.com](mailto:Fonseca.Rodrigo@microsoft.com)
    微软雷德蒙德华盛顿美国98052和 Saravan Rajmohan [saravan.rajmohan@microsoft.com](mailto:saravan.rajmohan@microsoft.com)
    微软雷德蒙德华盛顿美国98052（2024）
- en: Abstract.
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: The growing complexity of cloud based software systems has resulted in incident
    management becoming an integral part of the software development lifecycle. Root
    cause analysis (RCA), a critical part of the incident management process, is a
    demanding task for on-call engineers, requiring deep domain knowledge and extensive
    experience with a team’s specific services. Automation of RCA can result in significant
    savings of time, and ease the burden of incident management on on-call engineers.
    Recently, researchers have utilized Large Language Models (LLMs) to perform RCA,
    and have demonstrated promising results. However, these approaches are not able
    to dynamically collect additional diagnostic information such as incident related
    logs, metrics or databases, severely restricting their ability to diagnose root
    causes. In this work, we explore the use of LLM based agents for RCA to address
    this limitation. We present a thorough empirical evaluation of a \react agent
    equipped with retrieval tools, on an out-of-distribution dataset of production
    incidents collected at a large IT corporation. Results show that \react performs
    competitively with strong retrieval and reasoning baselines, but with highly increased
    factual accuracy. We then extend this evaluation by incorporating discussions
    associated with incident reports as additional inputs for the models, which surprisingly
    does not yield significant performance improvements. Lastly, we conduct a case
    study with a team at Microsoft to equip the \react agent with tools that give
    it access to external diagnostic services that are used by the team for manual
    RCA. Our results show how agents can overcome the limitations of prior work, and
    practical considerations for implementing such a system in practice.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 云基础软件系统的复杂性不断增长，导致事件管理成为软件开发生命周期的一个不可或缺的部分。根本原因分析（RCA）作为事件管理过程中的关键环节，对值班工程师来说是一项要求极高的任务，需要深厚的领域知识和丰富的团队特定服务经验。RCA的自动化可以显著节省时间，减轻值班工程师的事件管理负担。最近，研究人员利用大型语言模型（LLMs）进行RCA，并展示了有希望的结果。然而，这些方法无法动态收集附加的诊断信息，如与事件相关的日志、指标或数据库，严重限制了它们诊断根本原因的能力。在这项工作中，我们探索了基于LLM的代理用于RCA，以解决这一限制。我们对一个配备检索工具的\react 代理在一家大型IT公司收集的生产事件的分布外数据集进行了深入的实证评估。结果表明，\react 在强大的检索和推理基线方面表现具有竞争力，但具有显著提高的事实准确性。我们随后通过将与事件报告相关的讨论作为模型的额外输入来扩展了这一评估，令人惊讶的是，这并没有带来显著的性能提升。最后，我们与微软的一个团队进行了一项案例研究，为\react 代理配备了使其能够访问团队用于手动RCA的外部诊断服务的工具。我们的结果展示了代理如何克服之前工作的局限性，以及在实践中实施这种系统的实际考虑。
- en: 'Incident Management, Cloud Computing, Root Cause Analysis, AIOps^†^†copyright:
    acmcopyright^†^†journalyear: 2024^†^†doi: XXXXXXX.XXXXXXX^†^†ccs: Computer systems
    organization Cloud computing^†^†ccs: Software and its engineering Maintaining
    software'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 事件管理，云计算，根本原因分析，AIOps^†^†版权：acmcopyright^†^†期刊年：2024^†^†doi：XXXXXXX.XXXXXXX^†^†ccs：计算机系统组织
    云计算^†^†ccs：软件及其工程 维护软件
- en: 1\. Introduction
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 引言
- en: For the last several decades, large scale enterprises have been transforming
    their software into cloud services. With the rise of Artificial Intelligence (AI)
    in recent years, there has been even greater movement of computation from consumer
    devices to the cloud. This shift in paradigm has brought with it complex software
    systems that are characterized by multi-tiered architectures, microservices and
    distributed applications. The increased complexity of these systems makes them
    highly susceptible to production incidents. When left unresolved, these incidents
    can incur substantial costs and disrupt critical services. Therefore, prompt mitigation
    and resolution of these incidents is crucial to maintaining service availability
    and reliability ([Zeng2023-em,](#bib.bib41) ). However, cloud incident management ([Lou2022-yy,](#bib.bib15)
    ; [Chen2023-sj,](#bib.bib7) ) is extremely labor-intensive. On-call engineers
    (OCEs) require extensive experience with a team’s services and deep domain knowledge
    to be effective at incident management. Even for experienced OCEs, incident management
    represents a time-intensive endeavor. As software systems continue scaling in
    size and complexity, the demands placed on OCEs and incident management systems
    is only bound to increase in the future. To address these challenges, the field
    of AIOps (Artificial Intelligence for IT Operations) has proposed numerous techniques
    to ease incident management. Despite these developments, several parts of the
    incident management lifecycle still largely rely on human intervention.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几十年中，大型企业一直在将其软件转型为云服务。近年来，随着人工智能（AI）的兴起，计算从消费者设备向云端转移的趋势更加显著。这种范式的转变带来了复杂的软件系统，这些系统具有多层架构、微服务和分布式应用程序。系统的复杂性增加使它们极易受到生产事件的影响。如果这些事件得不到解决，可能会造成巨大的成本并中断关键服务。因此，迅速缓解和解决这些事件对维护服务的可用性和可靠性至关重要（[Zeng2023-em](#bib.bib41)）。然而，云事件管理（[Lou2022-yy](#bib.bib15)；[Chen2023-sj](#bib.bib7)）极其耗费人力。值班工程师（OCEs）需要对团队的服务有广泛的经验和深厚的领域知识，才能有效进行事件管理。即使对于经验丰富的OCEs，事件管理也是一项耗时的工作。随着软件系统规模和复杂性的持续扩大，对OCEs和事件管理系统的需求只会在未来增加。为了应对这些挑战，AIOps（人工智能运维）领域提出了许多技术来简化事件管理。尽管有这些发展，事件管理生命周期中的几个部分仍然在很大程度上依赖人工干预。
- en: One of the most challenging aspects of cloud incident management is root cause
    analysis (RCA). Before an incident can be resolved, OCEs must identify the root
    cause of the incident to ensure that any resolution actions comprehensively and
    correctly fix the incident. RCA represents one of the most labor- and skill-intensive
    components of the incident management lifecycle ([Ma2020-io,](#bib.bib17) ). Even
    a veteran software engineer might need to spend several years on a team before
    they are able to effectively perform RCA on a team’s services. Therefore, it comes
    as no surprise that researchers have tried to automate parts of this process.
    Numerous techniques have been proposed to assist OCEs with RCA, such as incident
    prioritization and retrieval of similar historical incidents. While earlier approaches
    focused on automating parts of the root cause analysis process, the remarkable
    abilities demonstrated by Large Language Models (LLMs) in recent years has increased
    focus on end-to-end systems for RCA. Recently, Ahmed et al.([Ahmed2023-ov,](#bib.bib1)
    ) proposed the use of fine-tuned LLMs for incident root cause analysis and mitigation.
    They showed that LLMs can find root causes of incidents even when working with
    a very limited set of information about an incident. Chen et al.([Chen2023-js,](#bib.bib8)
    ) propose RCACopilot, which expands upon this work and add retrieval augmentation
    and diagnostic collection tools to the LLM-based root cause analysis pipeline.
    They design custom workflows for different types of incidents that trigger data
    collection procedures, which are then aggregated to predict a root cause category
    for the incident and help OCEs with root cause analysis.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 云事件管理中最具挑战性的方面之一是根本原因分析（RCA）。在事件得到解决之前，OCE必须识别事件的根本原因，以确保任何解决措施能够全面且正确地修复事件。RCA是事件管理生命周期中最劳动密集和技能密集的组成部分之一（[Ma2020-io,](#bib.bib17)）。即使是经验丰富的软件工程师，也可能需要在团队中待上几年才能有效地进行团队服务的RCA。因此，研究人员尝试自动化这一过程的部分内容也就不足为奇了。已经提出了多种技术来协助OCE进行RCA，例如事件优先级排序和类似历史事件的检索。尽管早期方法集中在自动化根本原因分析过程的部分内容，但近年来大型语言模型（LLMs）展示出的显著能力增加了对端到端RCA系统的关注。最近，**Ahmed
    et al.**（[Ahmed2023-ov,](#bib.bib1) ）提出了使用微调的LLMs进行事件根本原因分析和缓解。他们展示了LLMs即使在处理非常有限的事件信息集时，也能找到事件的根本原因。**Chen
    et al.**（[Chen2023-js,](#bib.bib8) ）提出了**RCACopilot**，在此基础上扩展并增加了检索增强和诊断收集工具到基于LLM的根本原因分析流程中。他们为不同类型的事件设计了定制的工作流程，触发数据收集程序，然后将这些数据汇总以预测事件的根本原因类别，并帮助OCE进行根本原因分析。
- en: While these approaches have shown promising results on the ability of LLMs to
    perform RCA, neither equips the LLM to dynamically query real time diagnostic
    information about the service(s) affected by an incident. RCACopilot ([Chen2023-js,](#bib.bib8)
    ) relies on predefined handlers that must be engineered by hand, and predicts
    root cause categories rather than specific root causes, while Ahmed et al.([Ahmed2023-ov,](#bib.bib1)
    ) rely only on the incident title and description for predicting the root cause.
    What’s missing here is a critical step that is taken by OCEs in real world RCA
    scenarios - for any incident, one of the first steps performed by OCEs is collection
    of novel diagnostic data that is not present in the incident report. In prior
    work, LLMs do not have the ability to interact with the outside environment to
    be able to collect this data. In this work, we propose the use of LLM-based agents
    – systems that can reason, plan and interact with the external environment to
    collect new information – to address this limitation and help with root cause
    analysis.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些方法在LLMs进行根本原因分析（RCA）的能力上显示出有希望的结果，但都无法使LLM动态查询关于事件影响的服务的实时诊断信息。**RCACopilot**（[Chen2023-js,](#bib.bib8)
    ）依赖于必须手工工程化的预定义处理程序，并预测根本原因类别而非具体的根本原因，而**Ahmed et al.**（[Ahmed2023-ov,](#bib.bib1)
    ）仅依靠事件标题和描述来预测根本原因。这里缺少的是OCE在实际RCA场景中采取的一个关键步骤——对于任何事件，OCE的第一步是收集事件报告中不存在的新诊断数据。在之前的工作中，LLMs没有能力与外部环境互动以收集这些数据。在本工作中，我们提出使用基于LLM的智能体——可以推理、规划并与外部环境互动以收集新信息的系统——来解决这一限制，并帮助进行根本原因分析。
- en: Despite the remarkable capabilities demonstrated by LLM-based agents across
    diverse domains and tasks, adapting them for the purposes of RCA represents a
    significant challenge. Incident production data is highly confidential, and likely
    out of distribution for LLMs without fine-tuning, which can be costly and impractical
    for large models ([Chen2023-js,](#bib.bib8) ). In-context examples can serve as
    an alternative to fine-tuning for domain adaptation, but for agent based RCA,
    crafting entire reasoning trajectories can be challenging. This is exacerbated
    by the fact that agents require sophisticated prompting and typically also require
    fine-tuning ([Yao2022-uc,](#bib.bib40) ) or in-context examples ([Song2022-ce,](#bib.bib33)
    ). Lastly, RCA poses some unique characteristics that differentiate it from standard
    NLP tasks. For most NLP tasks, relevant external tools such as web search engines
    and document retrieval are easy to use in a single step process, and do not require
    much prior knowledge from the LLM. For RCA, crafting a query for search or retrieval
    requires much more specialized domain knowledge; many sources of information such
    as logs, traces, and monitoring services involve querying and processing of tabular
    data using specialized query languages as well as knowledge of ancillary information
    (e.g. which database to query). Therefore, while LLM agents offer exceptional
    abilities that go far beyond prior approaches, it is unclear whether they can
    be effectively adapted to the RCA task.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管基于LLM的智能体在各个领域和任务中展示了显著的能力，但将它们应用于RCA（根本原因分析）的目的仍然是一个重大挑战。事故生产数据高度机密，且在未经微调的LLM中可能会超出分布范围，而微调对大型模型来说可能既昂贵又不切实际 ([Chen2023-js,](#bib.bib8)
    )。上下文示例可以作为领域适应的替代方案，但对于基于智能体的RCA，构建完整的推理轨迹可能很具挑战性。这一挑战因智能体需要复杂的提示，并且通常还需要微调 ([Yao2022-uc,](#bib.bib40)
    )或上下文示例 ([Song2022-ce,](#bib.bib33) )而加剧。最后，RCA具有一些独特的特征，使其与标准的NLP任务有所不同。对于大多数NLP任务，相关的外部工具如网络搜索引擎和文档检索可以在单步流程中轻松使用，不需要LLM的太多先验知识。对于RCA，构建搜索或检索查询需要更多的专业领域知识；许多信息来源如日志、跟踪和监控服务涉及使用专门的查询语言对表格数据进行查询和处理，以及对附加信息（如查询哪个数据库）的了解。因此，虽然LLM智能体提供了远超以往方法的卓越能力，但尚不清楚它们是否能有效适应RCA任务。
- en: 'In this work, we present an empirical evaluation of an LLM-based agent, ReAct for
    root cause analysis for cloud incident management. Our goal is to answer two important
    questions in this regard: 1) Can LLM agents be effective at RCA in the absence
    of fine-tuning? and 2) What are the practical considerations of using LLM agents
    in real world scenarios? To answer these questions, we first conduct an evaluation
    of the ReAct agent equipped with retrieval tools on a static dataset, mirroring
    the evaluation setting by Ahmed et al. ([Ahmed2023-ov,](#bib.bib1) ). In this
    setting, the agent does not have access to specialized, team specific, diagnostic
    services, thereby restricting its abilities. This establishes a lower bound for
    their performance, and also reflects a practical scenario where agents are incrementally
    adopted across an organization or company, gradually gaining access to diagnostic
    services over time. Next, we investigate the use of discussion comments from historical
    incident reports to augment our retrieval corpus. This serves two purposes; not
    only do discussion comments add additional context to the incident report, but
    they also contain records of the diagnostic steps followed by OCEs for past incidents.
    The latter can potentially be used in lieu of few-shot examples to guide the agent.
    Lastly, to explore the full potential of agents, we present a case study of a
    practical implementation of an LLM agent for RCA, fully equipped with team specific
    diagnostic resources, in collaboration with another team at Microsoft. Concretely,
    we make the following contributions:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们展示了基于LLM的代理ReAct在云事件管理中进行根因分析的实证评估。我们的目标是回答两个重要问题：1）在没有微调的情况下，LLM代理能否有效进行RCA？2）在现实世界场景中使用LLM代理的实际考虑因素是什么？为了回答这些问题，我们首先对配备检索工具的ReAct代理在静态数据集上的表现进行了评估，这一设置模仿了Ahmed等人（[Ahmed2023-ov](#bib.bib1)）的评估设置。在这种设置中，代理无法访问特定团队的专业诊断服务，从而限制了其能力。这为其性能建立了一个下限，并且反映了一个实际场景，即代理在组织或公司中逐步采用，逐渐获得诊断服务的情况。接下来，我们调查了利用历史事件报告中的讨论评论来扩展我们的检索语料库。这有两个目的：不仅讨论评论为事件报告提供了额外的背景，还包含了OCE在过去事件中遵循的诊断步骤的记录。后者可以作为少量示例来指导代理。最后，为了探索代理的全部潜力，我们展示了一个实际实施的LLM代理用于RCA的案例研究，该代理配备了团队特定的诊断资源，并与微软的另一个团队合作。具体来说，我们做出了以下贡献：
- en: •
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We present the first empirical study on the use of ReAct ([Yao2022-uc,](#bib.bib40)
    ), an LLM agent, for RCA in an out of domain setting on a static dataset of real
    world production incidents
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们介绍了首个关于ReAct（[Yao2022-uc](#bib.bib40)）在静态数据集上的领域外设置中用于RCA的实证研究，该数据集包含了真实世界的生产事件。
- en: •
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We conduct a qualitative analysis of the different success and failure modes
    of the ReAct in RCA.
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们对ReAct在RCA中的不同成功和失败模式进行了定性分析。
- en: •
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We evaluate the use of discussion comments from historical incidents and its
    impact on the agent’s performance.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们评估了历史事件中的讨论评论及其对代理性能的影响。
- en: •
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We present a case study of a real world implementation of an LLM-based agent
    for RCA with a team at a large scale enterprise
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们展示了一个与大规模企业的团队合作的LLM代理在RCA中的真实世界实施案例研究。
- en: •
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We highlight both the potential of LLM-based agents and the challenges involved
    in implementing real world systems capable of fully autonomous RCA.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们突出了基于LLM的代理的潜力以及在实现能够完全自主根因分析（RCA）的实际世界系统中所涉及的挑战。
- en: 2\. Background and Related Work
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 背景和相关工作
- en: 2.1\. Cloud Incident Management and Root Cause Analysis
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1\. 云事件管理和根因分析
- en: Production incidents are unplanned events or disruptions in service that adversely
    affect customers. Outages in service due to production incidents can be extremely
    costly for enterprises. The complexity of modern software systems renders production
    incidents inevitable, and incident management a key component of the software
    development life cycle. The life cycle of an incident involves incident detection,
    triaging, diagnosis and mitigation ([Ahmed2023-ov,](#bib.bib1) ). While incidents
    may be reported by customers or automatically detected and triaged using monitoring
    services, the remaining steps are traditionally conducted by one or more on-call
    engineers (OCEs). The goal of incident management is to minimize the time between
    the occurrence of the incident, and its resolution.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 生产事故是指那些未经计划的事件或服务中断，这些事件会对客户产生不利影响。由于生产事故引起的服务中断对企业来说可能极其昂贵。现代软件系统的复杂性使得生产事故不可避免，而事故管理成为软件开发生命周期的一个关键组成部分。事故的生命周期包括事故检测、分类、诊断和缓解（[Ahmed2023-ov](#bib.bib1)）。虽然事故可能由客户报告或通过监控服务自动检测和分类，但其余步骤通常由一个或多个值班工程师（OCEs）完成。事故管理的目标是尽量减少事故发生与解决之间的时间。
- en: 2.2\. Root Cause Analysis (RCA)
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2\. 根本原因分析（RCA）
- en: 'Title:
    SD#1234123412341234 — PRE — SEV A — Specified blob does not exist. — Cloud Services
    LLC Description: Customer mentioned that after stopping stream analytics on 09/23
    they are getting errors on streaming into ¡*database product*¿[…] It was throwing
    an error ”Specified blob does not exist” and “Invalid connection string format.
    [SessionID: ¡*uuid*¿ Found Another error message ”Error while Ingesting data to
    ¡*database product*¿”'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 'Title:
    SD#1234123412341234 — PRE — SEV A — Specified blob does not exist. — Cloud Services
    LLC Description: Customer mentioned that after stopping stream analytics on 09/23
    they are getting errors on streaming into ¡*database product*¿[…] It was throwing
    an error ”Specified blob does not exist” and “Invalid connection string format.
    [SessionID: ¡*uuid*¿ Found Another error message ”Error while Ingesting data to
    ¡*database product*¿”'
- en: Figure 1. Example Incident
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图1. 示例事故
- en: 'Root Cause Analysis constitutes one of the most time-consuming aspects of the
    incident management life cycle. When OCEs receive an incident, they systematically
    perform a series of troubleshooting steps to identify the root cause. Each troubleshooting
    step yields previously unknown information, helping the OCE narrow down on the
    set of plausible root causes. This highlights a key aspect of root cause analysis:
    the process of collecting additional diagnostic information related to the incident.
    The incident report describes the symptoms leading to the reporting of the incident,
    but similar symptoms can emerge from distinct root causes, which might span a
    diverse set of domains, such as hardware failures, network issues or software
    bugs. Therefore, OCEs must start the diagnosis process by collecting supplementary
    data from relevant logs, metrics and other monitoring and diagnostic services.
    For example, the incident shown in Figure [1](#S2.F1 "Figure 1 ‣ 2.2\. Root Cause
    Analysis (RCA) ‣ 2\. Background and Related Work ‣ Exploring LLM-based Agents
    for Root Cause Analysis") was resolved by checking logs collected from the affected
    service to identify the sequence of events that lead to the failure encountered
    by the customer. Another implicit requirement in this process is that OCEs know
    1) what additional information needs to be collected, and 2) how to collect this
    information. This is why even experienced engineers need to have experience with
    team’s services before they can effectively perform RCA. In all, successful RCA
    requires the following pieces of information: 1) symptoms reported in the incident
    report, 2) additional diagnostic information, and 3) domain expertise, i.e. what
    diagnostic information should be collected based on the information, how to collect
    it and general knowledge about the application domain'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 根本原因分析是事故管理生命周期中最耗时的方面之一。当OCEs收到一个事故时，他们会系统地执行一系列故障排除步骤以确定根本原因。每一步故障排除都产生先前未知的信息，帮助OCE缩小可能的根本原因范围。这突出了根本原因分析的一个关键方面：收集与事故相关的额外诊断信息的过程。事故报告描述了导致事故报告的症状，但类似的症状可能源于不同的根本原因，这些原因可能涉及硬件故障、网络问题或软件缺陷等各种领域。因此，OCEs必须通过收集相关日志、指标和其他监控与诊断服务中的补充数据来开始诊断过程。例如，图[1](#S2.F1
    "图 1 ‣ 2.2\. 根本原因分析（RCA） ‣ 2\. 背景和相关工作 ‣ 探索基于LLM的根本原因分析代理")中的事故是通过检查受影响服务中收集的日志来解决的，以识别导致客户遇到故障的事件序列。在此过程中另一个隐含的要求是OCEs需要知道1）需要收集哪些额外的信息，以及2）如何收集这些信息。这就是为什么即使是经验丰富的工程师也需要对团队的服务有经验才能有效地进行RCA。总的来说，成功的RCA需要以下信息：1）事故报告中报告的症状，2）额外的诊断信息，以及3）领域专长，即根据信息应该收集哪些诊断信息，如何收集以及关于应用领域的基本知识。
- en: The root cause analysis pipeline demonstrates many of the challenges posed for
    OCEs as well as efforts to automate this procedure. OCEs must have sufficient
    domain knowledge and familiarity with the affected service to know 1) which supplementary
    data to collect, 2) how this data must be collected and 3) how to analyze all
    of the available information (including the incident report). Depending on the
    scale and complexity of the underlying service, this might require OCEs to have
    several years of experience with the team’s services to develop the requisite
    skill set for effective root cause analysis. Even when OCEs are sufficiently trained,
    the data collected can be multi-faceted, spanning from structured tabular data
    to unstructured logs and customer reports. This further complicates data analysis
    and subsequent hypothesis generation for OCEs. While OCEs can overcome these challenges
    by leveraging domain expertise and experience, this poses a significant challenge
    for prior automated approaches, that are unable to collect this supplementary
    data, let alone analyze it to produce a root cause.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 根本原因分析流程展示了OCE面临的许多挑战以及自动化该过程的努力。OCE必须具备足够的领域知识和对受影响服务的熟悉度，以了解1）需要收集哪些补充数据，2）如何收集这些数据，3）如何分析所有可用的信息（包括事件报告）。根据基础服务的规模和复杂性，这可能要求OCE拥有数年的团队服务经验，以培养有效的根本原因分析所需的技能。即使OCE经过充分培训，所收集的数据可能是多方面的，涵盖结构化的表格数据、非结构化的日志和客户报告。这进一步使数据分析和后续假设生成变得复杂。虽然OCE可以通过利用领域专业知识和经验克服这些挑战，但这对以往无法收集这些补充数据的自动化方法提出了重大挑战，更不用说分析这些数据以找出根本原因了。
- en: 2.3\. Automated RCA
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3\. 自动化根本原因分析
- en: Numerous studies have proposed various techniques for automating root cause
    analysis, such as using machine learning models and deep learning models  ([Soldani22-hg,](#bib.bib32)
    ) to identify patterns in event data and determine the underlying causes of incidents.
    Another important area of research in RCA is the use of anomaly detection models
     ([Soualhia22-ev,](#bib.bib34) ), such as statistical, machine learning and deep
    learning models  ([Hagemann21-an,](#bib.bib10) ), have been proposed to identify
    anomalies in system behavior and alert operators in real-time. Studies have proposed
    various techniques for RCA and triage such as learning a hierarchical monitoring
    system  ([Nair15,](#bib.bib21) ), diagnosing and triaging performance issues  ([Chetan19-dc,](#bib.bib3)
    ), and correlating events with time series  ([Luo14-en,](#bib.bib16) ). In addition,
    there have been studies exploring the use of structured knowledge mining from
    various artifacts, such as incident reports and root cause documentation, to mine
    structured knowledge in software engineering such as troubleshooting guides (TSGs)
     ([Jiang22-eg,](#bib.bib11) ) and there have been efforts to improve TSG quality
     ([Shety22-lr,](#bib.bib28) )and make them more effective for incident resolution.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 许多研究提出了各种自动化根本原因分析的技术，例如使用机器学习模型和深度学习模型 ([Soldani22-hg,](#bib.bib32)) 来识别事件数据中的模式并确定事件的根本原因。根本原因分析的另一个重要研究领域是使用异常检测模型
    ([Soualhia22-ev,](#bib.bib34))，例如统计、机器学习和深度学习模型 ([Hagemann21-an,](#bib.bib10))，这些模型被提议用于识别系统行为中的异常并实时警报操作员。研究提出了各种根本原因分析和分诊的技术，例如学习分层监控系统
    ([Nair15,](#bib.bib21))、诊断和分诊性能问题 ([Chetan19-dc,](#bib.bib3)) 以及将事件与时间序列相关联 ([Luo14-en,](#bib.bib16))。此外，还有研究探讨了从各种文档中提取结构化知识的使用，例如事件报告和根本原因文档，以挖掘软件工程中的结构化知识，如故障排除指南（TSGs）
    ([Jiang22-eg,](#bib.bib11))，并且有努力提高TSG的质量 ([Shety22-lr,](#bib.bib28))，使其在事件解决中更加有效。
- en: Large Language Models (LLMs) have shown remarkable ability to work with a wide
    variety of data modalities, including unstructured natural language, tabular data
    and even images. Recently, Ahmed et al. ([Ahmed2023-ov,](#bib.bib1) ) proposed
    the use of fine-tuned pretrained LLMs for RCA of cloud incidents. Since incident
    data is highly confidential, and unlikely to have been observed by pretrained
    LLMs, fine-tuning is necessary for domain adaptation of vanilla LLMs. In this
    work, we adopt the RCA task as framed in Ahmed et al. ([Ahmed2023-ov,](#bib.bib1)
    ); given an incident report, we want our model to predict a specific root cause.
    However, unlike the original setting, we exclude the use of fine-tuning or other
    training approaches for domain adaption. As pointed out by Chen et al. ([Chen2023-js,](#bib.bib8)
    ), while fine-tuning can be effective, it is also costly and time-consuming, and
    must be repeated every time the base model gets updated, or services evolve. To
    address these limitations, Chen et al. ([Chen2023-js,](#bib.bib8) ) introduce
    RCACopilot, which uses predefined handlers to automatically collect multi-modal
    diagnostic data relevant to the incident, and an LLM to analyze the collected
    data and predict a root cause category for the incident that serves to assist
    OCEs with RCA, without the need for finetuning. Unlike RCACopilot, the ReAct agent
    presented in our case study can dynamically collect related diagnostic data autonomously,
    without the need for predefined handlers.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 大语言模型（LLMs）在处理各种数据模态方面表现出了显著的能力，包括非结构化自然语言、表格数据甚至图像。最近，Ahmed 等人 ([Ahmed2023-ov,](#bib.bib1)
    ) 提出了使用微调的预训练大语言模型进行云事件根本原因分析（RCA）。由于事件数据高度机密，并且不太可能被预训练大语言模型观察到，因此需要对普通大语言模型进行微调以适应领域。在这项工作中，我们采用了Ahmed
    等人 ([Ahmed2023-ov,](#bib.bib1) ) 定义的 RCA 任务；给定一个事件报告，我们希望我们的模型能够预测具体的根本原因。然而，与原始设置不同，我们排除了使用微调或其他训练方法进行领域适应。正如
    Chen 等人 ([Chen2023-js,](#bib.bib8) ) 所指出的，虽然微调可能有效，但它也非常昂贵且耗时，每次基础模型更新或服务演变时必须重复进行。为了应对这些限制，Chen
    等人 ([Chen2023-js,](#bib.bib8) ) 引入了 RCACopilot，它使用预定义的处理程序自动收集与事件相关的多模态诊断数据，并使用大语言模型分析收集的数据，预测事件的根本原因类别，以协助
    OCEs 进行 RCA，而无需微调。与 RCACopilot 不同，我们案例研究中提出的 ReAct 智能体可以动态地自主收集相关的诊断数据，无需预定义的处理程序。
- en: 2.4\. Augmented LLMs and LLM-Based Agents
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4\. 增强型大语言模型和基于大语言模型的智能体
- en: A recent development in LM research has been the rise of LMs augmented with
    the ability to reason and use tools, or Augmented Language Models (ALMs) ([Lewis2020-rj,](#bib.bib13)
    ; [Mialon2023-rn,](#bib.bib20) ; [Schick2023-vu,](#bib.bib27) ). Augmenting LLMs
    extends their ability beyond what is possible in a purely language modelling regime.
    Primarily, these augmentations are either external components that allow the LLM
    to interact dynamically with its environment for a given problem setting, or prompting
    techniques that endow the LLM with sophisticated reasoning abilities for complex
    analytical tasks ([Wei2022-vl,](#bib.bib37) ). For example, LLMs have been augmented
    with external retrieval databases that can factually ground their predictions,
    as well as allow them to use information that was not seen in training. Retrieval
    can also narrow the gap between smaller models and their larger counterparts.
    LLMs can also be augmented with external components beyond retrieval, such as
    code interpreters ([noauthor_undated-eg,](#bib.bib9) ) and web search engines.
    More recently, LLM-based agents combine the external augmentation components with
    reasoning and planning abilities to allow the LLM to autonomously solve for complex
    tasks such as sequential decision-making problems ([Shinn_undated-kf,](#bib.bib29)
    ), knowledge-intensive question answering ([Trivedi2022-pf,](#bib.bib35) ) and
    self debugging ([Chen2023-hj,](#bib.bib6) ).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型研究的一个近期发展是增强语言模型（Augmented Language Models, ALMs）的兴起，这些模型具备推理和使用工具的能力 ([Lewis2020-rj,](#bib.bib13)
    ; [Mialon2023-rn,](#bib.bib20) ; [Schick2023-vu,](#bib.bib27) )。增强型大语言模型扩展了其能力，超出了纯语言建模的范围。这些增强主要是外部组件，使得大语言模型可以在特定问题设置下与环境动态交互，或是提示技术，使得大语言模型具备复杂分析任务的高级推理能力 ([Wei2022-vl,](#bib.bib37)
    )。例如，大语言模型已经通过外部检索数据库进行了增强，这些数据库可以基于事实支持其预测，并允许其使用训练中未见过的信息。检索还可以缩小小模型与大模型之间的差距。大语言模型还可以通过超越检索的外部组件进行增强，如代码解释器 ([noauthor_undated-eg,](#bib.bib9)
    )和网络搜索引擎。最近，基于大语言模型的智能体将外部增强组件与推理和规划能力结合起来，使得大语言模型能够自主解决复杂任务，例如序列决策问题 ([Shinn_undated-kf,](#bib.bib29)
    )、知识密集型问答 ([Trivedi2022-pf,](#bib.bib35) )和自我调试 ([Chen2023-hj,](#bib.bib6) )。
- en: 3\. LLM-Based Agents for RCA
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3. LLM 基于的 RCA 代理
- en: 'An LLM agent is an ALM that has the ability to both reason and use tools. In
    recent years, several different formulations of LLM agents have been proposed ([Yao2022-uc,](#bib.bib40)
    ; [Song2022-ce,](#bib.bib33) ). For this work, we base the RCA Agent on the ReAct
    framework ([Yao2022-uc,](#bib.bib40) ). This framework interleaves reasoning and
    tool usage steps, combining principles from reasoning-based approaches such as
    Chain of Thought ([Wei2022-mi,](#bib.bib38) ) with tool usage models like Toolformer([Lewis2019-hp,](#bib.bib12)
    ). ReAct is a natural fit for the RCA task for many reasons: 1) Real-world RCA
    task has elements of both sequential decision-making (deciding which troubleshooting
    steps to take) and knowledge-intensive question answering (assessing available
    diagnostic information to produce a candidate root cause), both of which are supported
    by ReAct; 2) in an out of distribution setting such as the one we consider, ReActcan
    quickly adapt to new information since it interleaves reasoning, planning and
    environment feedback rather than creating a long-horizon plan upfront; and 3)
    it can easily be augmented with additional components such as reflection ([Shinn2023-hb,](#bib.bib30)
    ) and external memory mechanisms ([Zhao2023-rd,](#bib.bib43) ) which would benefit
    RCA for incidents requiring a longer diagnostic process.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 代理是具有推理和使用工具能力的 ALM。近年来，已经提出了几种不同形式的 LLM 代理（[Yao2022-uc,](#bib.bib40) ;
    [Song2022-ce,](#bib.bib33)）。在这项工作中，我们基于 ReAct 框架（[Yao2022-uc,](#bib.bib40)）构建
    RCA 代理。该框架将推理和工具使用步骤交替进行，将基于推理的方法（如 Chain of Thought（[Wei2022-mi,](#bib.bib38)））与工具使用模型（如
    Toolformer（[Lewis2019-hp,](#bib.bib12)））结合在一起。ReAct 非常适合 RCA 任务，原因有很多：1）现实世界的
    RCA 任务包含顺序决策（决定采取哪些故障排除步骤）和知识密集型问答（评估可用的诊断信息以产生候选根本原因）的元素，这两者都得到 ReAct 的支持；2）在我们考虑的分布外环境中，ReAct
    可以快速适应新信息，因为它交替进行推理、规划和环境反馈，而不是事先制定长期计划；3）它可以轻松地通过额外的组件（如反思（[Shinn2023-hb,](#bib.bib30)）和外部记忆机制（[Zhao2023-rd,](#bib.bib43)））进行扩展，这将有利于处理需要更长诊断过程的事件的
    RCA。
- en: 3.1\. Overview
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1. 概述
- en: '![Refer to caption](img/9bd67e083ee71155ff912388dc81330d.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅说明](img/9bd67e083ee71155ff912388dc81330d.png)'
- en: Figure 2. An example of ReAct’s reasoning trajectory
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2. ReAct 的推理轨迹示例
- en: 'Figure [2](#S3.F2 "Figure 2 ‣ 3.1\. Overview ‣ 3\. LLM-Based Agents for RCA
    ‣ Exploring LLM-based Agents for Root Cause Analysis") shows an example of a sample
    trajectory produced by a ReAct agent: the agent produces a ”thought”, or a reasoning
    step that informs the next ”action” it takes. The action space is consists of
    a fixed set of tools available to the agent. Once the action and it’s inputs are
    specified, the tool is executed and it’s outputs are reported back to the agent
    as an observation. Steps 1-3 repeat for as many times as needed to perform the
    task at hand. We use the Langchain([Chase2022-sg,](#bib.bib5) ) framework to implement
    the ReAct agent. Note that the tools used by the agent might also rely on LLMs.
    To disambiguate, we refer to the LLM performing the ReAct loop as the planner.
    We limit the maximum number of iterations of this loop to 20 due to time and resource
    constraints.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图[2](#S3.F2 "Figure 2 ‣ 3.1\. Overview ‣ 3\. LLM-Based Agents for RCA ‣ Exploring
    LLM-based Agents for Root Cause Analysis")展示了 ReAct 代理生成的示例轨迹：代理生成一个“思考”，即一个推理步骤，来指导它采取的下一个“行动”。动作空间由代理可用的一组固定工具组成。一旦指定了动作及其输入，就会执行工具，并将其输出作为观察结果反馈给代理。步骤
    1-3 根据需要重复进行以完成手头的任务。我们使用 Langchain（[Chase2022-sg,](#bib.bib5)）框架来实现 ReAct 代理。请注意，代理使用的工具也可能依赖于
    LLM。为了解释清楚，我们将执行 ReAct 循环的 LLM 称为规划器。由于时间和资源限制，我们将此循环的最大迭代次数限制为 20 次。
- en: 3.2\. Zero-Shot Prompting
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2. 零-shot 提示
- en: While LLM-based agent approaches typically benefit with few-shot examples ([Yao2022-uc,](#bib.bib40)
    ; [Song2022-ce,](#bib.bib33) ), we use ReAct in a much more challenging setup
    with a zero-shot prompt. Originally, we set out to craft few-shot examples based
    on examples from the evaluation set. However, for the setting in RQ1 and RQ2,
    where we only utilize the incident title and descrption, we found it extremely
    challenging to come up with reasoning traces grounded in the available information
    that would arrive at the correct root cause.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管基于 LLM 的代理方法通常受益于少量示例（[Yao2022-uc,](#bib.bib40) ; [Song2022-ce,](#bib.bib33)），但我们在一个更具挑战性的设置中使用
    ReAct，使用的是零-shot 提示。最初，我们打算根据评估集中的示例来制作少量示例。然而，对于 RQ1 和 RQ2 中的设置，我们只利用事件标题和描述，我们发现很难根据可用信息生成能够得出正确根本原因的推理轨迹。
- en: 3.3\. Agent Evaluation
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3. 代理评估
- en: One of the primary benefits of agent-based RCA is their ability to collect external
    diagnostic information via tools. This is difficult to evaluate without the existence
    of a simulated environment such as WebArena  ([Zhou2023-ds,](#bib.bib44) ), AlfWorld ([Shridhar2020-ky,](#bib.bib31)
    ) or WebShop ([Yao2022-hq,](#bib.bib39) ). The main challenge in constructing
    such an environment is that it is difficult to determine what diagnostic services
    were used to diagnose a particular incident, since OCEs are not required to report
    each and every diagnostic step taken. Moreover, the type of diagnostic services
    used by different teams can vary greatly. Another challenge is that the environment
    needs to support not only the most optimal troubleshooting trajectory that the
    agent can take, but a reasonably large subset of other plausible trajectories,
    i.e. even if we know what diagnostic data is needed to resolve an incident, it
    does not suffice to only capture this specific data for the environment. Given
    such an evaluation environment does not currently exist, we evaluate the agent
    in a restricted setting where we do not assume access to any specialized services,
    similar to ([Ahmed2023-ov,](#bib.bib1) ). While this evaluation does not reflect
    the benefits of the agent’s ability to perform autonomous diagnostic steps, it
    provides us with a lower bound for performance of the agent when specialized tools
    are unavailable, and allows us to fairly compare it to other ALMs that do not
    have the ability to query additional diagnostic data. In addition, to demonstrate
    the agent’s ability to interact with diagnostic services, we also present a case
    study of a prototype implementation of an agent in collaboration with a team at
    our company. This presents a more realistic evaluation of the agent but at a much
    smaller scale. The goal of the case study is to examine the benefits and limitations
    of the agent in a practical environment, and to identify practical considerations
    for real world adoption based.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 基于代理的RCA的主要优势之一是其通过工具收集外部诊断信息的能力。没有像WebArena ([Zhou2023-ds,](#bib.bib44) ),
    AlfWorld ([Shridhar2020-ky,](#bib.bib31) ) 或WebShop ([Yao2022-hq,](#bib.bib39)
    )这样的模拟环境，这一点很难评估。构建这种环境的主要挑战在于，难以确定用于诊断特定事件的诊断服务，因为OCE不要求报告每一个诊断步骤。此外，不同团队使用的诊断服务类型可能差异很大。另一个挑战是，环境需要支持代理能够采取的最优故障排除轨迹，以及合理大的其他可行轨迹的子集，即使我们知道解决事件所需的诊断数据，也不足以仅捕获这些特定数据。鉴于目前尚不存在这样的评估环境，我们在一个受限的环境中评估代理，不假设访问任何专业服务，类似于
    ([Ahmed2023-ov,](#bib.bib1) )。虽然这种评估不能反映代理执行自主诊断步骤的能力，但它为我们提供了在没有专业工具情况下的代理性能的下限，并允许我们公平地将其与其他无法查询额外诊断数据的ALM进行比较。此外，为了展示代理与诊断服务互动的能力，我们还展示了与公司团队合作开发的代理原型实现的案例研究。这提供了对代理更现实的评估，但规模要小得多。案例研究的目标是检验代理在实际环境中的优缺点，并识别实际应用的考虑因素。
- en: 3.4\. Tools
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4. 工具
- en: For the generalized setting, we restrict ourselves to general tools that apply
    to all incidents, regardless of their place of origin.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一般化设置，我们将自己限制在适用于所有事件的通用工具范围内，无论它们的起源地在哪里。
- en: Incident Details Our investigation of the evaluation dataset revealed that sometimes
    incident reports contain logs, stacktraces and other diagnostic information. While
    this information can be noisy and present challenges with context length, it is
    possible to expose the raw incident description to the LLM via a question-answering
    tool. The agent can use this tool to answer specific questions about the incident
    that might get lost during summarization.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 事件细节 我们对评估数据集的调查揭示，有时事件报告包含日志、堆栈跟踪和其他诊断信息。虽然这些信息可能很嘈杂并且在上下文长度方面存在挑战，但可以通过问答工具将原始事件描述暴露给LLM。代理可以利用此工具回答关于事件的特定问题，这些问题可能在总结过程中丢失。
- en: Historical Incidents This tool retrieves historical incidents based on the query
    made by the LLM planner. Based on experiments on our development dataset, we formulate
    two variants of this tool. The first variant uses the target incident title and
    description, along with a query produced by the agent for retrieval, and simply
    returns the retrieved documents as an observation without further processing.
    Since the query here is a passage, we exclusively use the SentenceTransformer
    retriever for retrieval. We refer to ReAct agents using this variant of the tool
    as ReAct BR. The second variant uses utilizes a two-step retrieval process. The
    LLM Planner must first generate a query to search for historical incidents. Then,
    the planner can perform question-answering over the retrieved set of historical
    incidents. The tool uses an LLM injected with the retrieved incidents to answer
    the planner’s question. This two step process allows the planner to disentangle
    the retrieval query from the target incident report, and also mitigates instances
    where the size of retrieved historical incidents might extend beyond the context
    length of the underlying LLM. We restrict the retrieval tool to retrieve $k=3$
    documents per query, to give the agent the opportunity to create a diverse set
    of queries while still maintaining an overall budget of 10 retrieved documents
    for parity with other baselines.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 历史事件 该工具根据LLM规划者提出的查询检索历史事件。基于我们开发数据集上的实验，我们制定了该工具的两个变体。第一个变体使用目标事件标题和描述，以及由代理生成的检索查询，然后简单地将检索到的文档作为观察结果返回，而不进行进一步处理。由于这里的查询是一个段落，我们仅使用SentenceTransformer检索器进行检索。我们将使用这种工具变体的ReAct代理称为ReAct
    BR。第二个变体则利用了两步检索过程。LLM规划者必须首先生成一个查询来搜索历史事件。然后，规划者可以对检索到的历史事件集合进行问答。该工具使用注入检索到的事件的LLM来回答规划者的问题。这一两步过程允许规划者将检索查询与目标事件报告分开，同时减轻了检索到的历史事件可能超出基础LLM的上下文长度的情况。我们将检索工具限制为每个查询检索$k=3$个文档，以便给代理提供创建多样化查询的机会，同时仍然保持整体预算为10个检索文档，与其他基线保持一致。
- en: 4\. Research Questions
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 研究问题
- en: 'To evaluate the efficacy of LLM-based Agents in RCA, we ask the following research
    questions:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估基于LLM的代理在根本原因分析中的有效性，我们提出以下研究问题：
- en: 'RQ1: How effective are LLM-based agents at finding incident root causes when
    given access to a generalized toolkit? In this setting, we test the efficacy of
    LLM-based agents at root cause analysis in an out of distribution setting when
    they are given access only to tools that are independent of specific teams. We
    equip the agent with a generalized retrieval tool over historical incidents, and
    a question-answering tool over the raw incident description. We consider various
    strong ALM baselines that, unlike the agent, are unable to use tools.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 'RQ1: 在提供通用工具包的情况下，基于LLM的代理在查找事件根本原因方面的效果如何？在这种设置下，我们测试基于LLM的代理在分布外设置下进行根本原因分析的有效性，当它们仅能使用与特定团队无关的工具时。我们为代理提供一个通用的历史事件检索工具和一个针对原始事件描述的问答工具。我们考虑各种强大的ALM基线，这些基线与代理不同，无法使用工具。'
- en: 'RQ2: Do discussion comments help improve LLM based approaches to root cause
    analysis?'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 'RQ2: 讨论评论是否有助于提高基于LLM的根本原因分析方法？'
- en: Discussion comments on incident reports contain records of the diagnostic steps
    taken by OCEs to resolve the incident, and can guide models in performing RCA
    on future incidents. Here, we aim to investigate whether incorporating these discussion
    comments into our retrieval corpus of historical incidents impacts the performance
    of the agent as well as selected baselines from RQ1\. To perform this evaluation,
    we augment incidents in our retrieval corpus with associated discussion comments
    post-retrieval, to ensure that the presence of the comments does not affect retrieval.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 事件报告中的讨论评论包含了OCE为解决事件而采取的诊断步骤记录，并且可以指导模型在未来事件中进行根本原因分析。在这里，我们旨在研究将这些讨论评论纳入我们的历史事件检索语料库是否会影响代理的表现以及RQ1中选择的基线。为了进行这项评估，我们在检索后将讨论评论添加到检索语料库中的事件，以确保评论的存在不会影响检索。
- en: 'RQ3: How effective are LLM based agents at root cause analysis when given access
    to specialized tools used by a team for incident management?'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 'RQ3: 当基于LLM的代理能够使用团队用于事件管理的专用工具时，其在根本原因分析中的效果如何？'
- en: In this research question, we evaluate a real world scenario when an LLM based
    agent has access to a team specific knowledge base and monitoring service. To
    conduct this evaluation, we perform a case study with another team’s on-call engineers.
    We package the ReAct agent with these resources into a chat interface, and conduct
    an in person experiment to see if this agent is able to effectively assist the
    on call engineer in finding the root cause of a small set of incidents.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一研究问题中，我们评估了一个实际场景，其中一个基于LLM的代理能够访问特定团队的知识库和监控服务。为了进行这项评估，我们与另一个团队的值班工程师进行案例研究。我们将ReAct代理与这些资源打包到一个聊天界面中，并进行面对面的实验，以查看该代理是否能够有效地协助值班工程师找到一小部分事件的根本原因。
- en: 5\. Methodology
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 方法论
- en: 'We describe the methodology used to answer RQ1 and RQ2 in this section. The
    methodology for RQ3 is described in Section [7](#S7 "7\. Practical Implementation
    of RCA Agent: A Case Study ‣ Exploring LLM-based Agents for Root Cause Analysis").'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在本节中描述了用于回答RQ1和RQ2的方法论。RQ3的方法论在第[7](#S7 "7\. Practical Implementation of
    RCA Agent: A Case Study ‣ Exploring LLM-based Agents for Root Cause Analysis")节中描述。'
- en: 5.1\. Dataset
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1\. 数据集
- en: We collect incident data from our internal incident portal, from 01/01/2020
    to 09/30/2021\. Our data collection process yielded a total of 107,000 unique
    incidents, which we split into a train (102,000), evaluation (2000) and test (3000)
    sets. For this work, we randomly sample 100 incidents from the evaluation set
    and 500 incidents from the test set to reduce costs, in line with work in NLP ([Trivedi2022-tm,](#bib.bib36)
    ). We use the training set is primarily used as the retrieval corpus for our experiments.
    Like Ahmed et al. ([Ahmed2023-ov,](#bib.bib1) ), we use the incident title and
    description as the primary sources of information about the incident. For RQ2,
    we also include discussion comments into the historical corpus. Incident descriptions
    and root causes do not follow a standard format, and can be quite long. This imposes
    limitations on the number of historical incidents that can be fit in context when
    using any kind of retrieval augmented generation. Hence, we use gpt-3.5-turbo
    to summarize descriptions and root causes. For RQ2, we also summarize discussions
    comments. Since discussion comments are much longer, we split them into chunks,
    summarize each individual chunk and recombine them, utilizing the LLM for each
    step. Note that the summarization process is difficult to evaluate due to a lack
    of reference summaries, and hence we rely on qualitative analysis and end-to-end
    evaluation on RCA to iterate on the summarization process.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从内部事件门户中收集事件数据，时间范围为2020年01月01日到2021年09月30日。我们的数据收集过程共获得107,000个唯一事件，我们将其拆分为训练集（102,000），评估集（2,000）和测试集（3,000）。对于这项工作，我们随机从评估集中抽取100个事件，从测试集中抽取500个事件，以减少成本，这与NLP领域的工作一致
    ([Trivedi2022-tm,](#bib.bib36))。我们使用训练集作为我们实验的主要检索语料库。像Ahmed等人 ([Ahmed2023-ov,](#bib.bib1))
    一样，我们使用事件标题和描述作为事件信息的主要来源。对于RQ2，我们还将讨论评论纳入历史语料库。事件描述和根本原因没有标准格式，可能相当长。这对使用任何类型的检索增强生成时能够适应的历史事件数量提出了限制。因此，我们使用gpt-3.5-turbo来总结描述和根本原因。对于RQ2，我们还总结了讨论评论。由于讨论评论通常较长，我们将其分成若干块，对每个块进行总结，然后重新组合，利用LLM完成每一步。请注意，由于缺乏参考摘要，总结过程难以评估，因此我们依赖定性分析和对RCA的端到端评估来迭代总结过程。
- en: 5.2\. Base LLMs
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2\. 基础LLMs
- en: For all of our experiments, we use OpenAI GPT4-8k ([OpenAI2023-la,](#bib.bib22)
    ) as the primary language model. GPT-4 is the most powerful model in OpenAI’s
    repository of models, and is one of the few models that can be used to reliably
    drive an agent in a zero-shot setting. The large context size (8,000 tokens) also
    enables us to use a larger number of retrieved incidents for our models. For summarization
    of incidents and discussion comments, we use gpt-3.5-turbo to lower costs.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的所有实验中，我们使用OpenAI GPT4-8k ([OpenAI2023-la,](#bib.bib22)) 作为主要语言模型。GPT-4是OpenAI模型库中最强大的模型之一，也是为数不多的可以在零样本设置下可靠驱动代理的模型之一。大上下文大小（8,000个标记）还使我们能够使用更多的检索事件。对于事件总结和讨论评论，我们使用gpt-3.5-turbo以降低成本。
- en: 5.3\. Retrievers
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3\. 检索器
- en: We construct a retrieval corpus of historical incidents that encompasses the
    entire training split of our collected dataset. We consider one dense retriever
    and one sparse retriever.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建了一个历史事件的检索语料库，涵盖了我们收集的数据集的整个训练拆分。我们考虑了一个密集检索器和一个稀疏检索器。
- en: Dense Retriever (ST) We use a pretrained Sentence-Bert ([Reimers2019-pg,](#bib.bib24)
    ) based encoder (all-mpnet-base-v2) from the associated SentenceTransformers as
    our dense retriever and Max Marginal Relevance (MMR) ([Carbonell1998-pu,](#bib.bib4)
    ) for search.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 密集检索器 (ST) 我们使用从相关的SentenceTransformers获取的预训练Sentence-Bert ([Reimers2019-pg](#bib.bib24)
    ) 编码器（all-mpnet-base-v2）作为我们的密集检索器，并使用最大边际相关性 (MMR) ([Carbonell1998-pu](#bib.bib4)
    ) 进行搜索。
- en: Sparse Retriever (BM-25) While models that perform a single retrieval step,
    other models such IR-CoT and the ReAct agent perform multiple retrieval steps
    with different queries, and can benefit from term based search ([Trivedi2022-tm,](#bib.bib36)
    ). We use BM-25 ([Robertson2009-nl,](#bib.bib25) ) as our sparse retriever.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 稀疏检索器 (BM-25) 与执行单次检索步骤的模型不同，IR-CoT和ReAct代理等模型通过不同的查询执行多个检索步骤，可以从基于术语的搜索中受益
    ([Trivedi2022-tm](#bib.bib36) )。我们使用BM-25 ([Robertson2009-nl](#bib.bib25) ) 作为我们的稀疏检索器。
- en: 5.4\. Baseline Models
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4\. 基线模型
- en: Here, we describe the baselines used for our evaluation in RQ1 and RQ2\. We
    restrict ourselves to ALMs that do not require any fine-tuning. All the following
    baselines use historical incident retrieval, and are restricted to a retrieval
    budget of $k=10$.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们描述了用于RQ1和RQ2评估的基线。我们仅限于不需要任何微调的ALM。所有以下基线都使用历史事件检索，并限制在检索预算$k=10$内。
- en: Retrieval Baseline (RB) Retrieval Augmented Generation (RAG) is an effective
    strategy to providing domain adaptation for language models without additional
    training. For our experiments, we create a retrieval database of historical incident
    reports with known root causes, and use the incoming incident’s title and description
    to retrieve top-k relevant historical incidents. These incidents are then put
    into the LLM’s context as few-shot examples.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 检索基线 (RB) 检索增强生成 (RAG) 是一种有效的策略，可以在不额外训练的情况下为语言模型提供领域适应性。在我们的实验中，我们创建了一个包含已知根本原因的历史事件报告的检索数据库，并使用来事件的标题和描述来检索top-k相关的历史事件。这些事件随后被作为少量示例放入LLM的上下文中。
- en: Chain of Thought (CoT) Chain of Thought is one of the earlier prompting methodologies
    developed to enhance the reasoning abilities of LLMs([Wei2022-vl,](#bib.bib37)
    ). The idea here is to encourage the model to break the input problem into smaller
    parts by thinking step by step. For our experiments, we use CoT in a zero-shot
    setting, by appending a prefix (”Let’s think step by step”) to the answer prompt.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 思维链 (CoT) 思维链是早期发展起来的一种提示方法，旨在增强LLM的推理能力 ([Wei2022-vl](#bib.bib37) )。其思想是鼓励模型通过逐步思考将输入问题拆解成更小的部分。在我们的实验中，我们在零样本设置下使用CoT，通过在回答提示前添加前缀（“让我们一步一步思考”）。
- en: Interleaving Retrieval - Chain of Thought (IR-CoT) Trivedi et al.([Trivedi2022-pf,](#bib.bib35)
    ) show that interleaving vanilla CoT prompting with retrieval improves model performance
    on complex, multistep reasoning tasks. After every reasoning step the LLM takes,
    the reasoning step is used to retrieve relevant documents from the retrieval corpus.
    This is shown to improve performance over using single step retrieval for knowledge
    intensive question answering tasks.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 交错检索 - 思维链 (IR-CoT) Trivedi 等人 ([Trivedi2022-pf](#bib.bib35) ) 显示，交错原始思维链提示与检索结合能提升模型在复杂多步骤推理任务中的表现。在每一步推理后，LLM
    会利用该推理步骤从检索语料库中检索相关文档。这比单步骤检索在知识密集型问题解答任务中的表现更佳。
- en: 5.5\. Automatic Evaluation Metrics
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5\. 自动评价指标
- en: For evaluating models in the general setting, we use a 3 evaluation metrics
    based on lexical similarity (BLEU, METEOR, Rouge) and 1 on semantic similarity
    (BertS). BLEU ([Papineni2002-yq,](#bib.bib23) ) is a precision based lexical similarity
    metric that computes the n-gram overlap between model predictions and ground truth
    references. We use both corpus (C-BLEU) and segment (S-BLEU) level variants. METEOR ([Banerjee2005-cp,](#bib.bib2)
    ) considers both precision and recall, and uses more sophisticated text processing
    and scoring systems. rougeL ([Lin2004-sf,](#bib.bib14) ) is commonly used to evaluate
    summarization and is recall based. BERTScore (BertS) ([Zhang2019-ju,](#bib.bib42)
    ) measures semantic similarity rather using pretrained BERT models.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在一般设置下评估模型时，我们使用基于词汇相似性的3个评价指标（BLEU、METEOR、Rouge）和1个基于语义相似性的指标（BertS）。BLEU ([Papineni2002-yq](#bib.bib23)
    ) 是一种基于精度的词汇相似性指标，计算模型预测与真实参考之间的n-gram重叠。我们使用语料库（C-BLEU）和段落（S-BLEU）级别的变体。METEOR
    ([Banerjee2005-cp](#bib.bib2) ) 既考虑精度也考虑召回，并使用更复杂的文本处理和评分系统。rougeL ([Lin2004-sf](#bib.bib14)
    ) 通常用于评估总结，并基于召回。BERTScore (BertS) ([Zhang2019-ju](#bib.bib42) ) 使用预训练的BERT模型测量语义相似性。
- en: 5.6\. Qualitative Analysis
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.6\. 定性分析
- en: Table 1. Manual Annotation Criteria
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 表1. 手动注释标准
- en: '| Outcome | Description |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 结果 | 描述 |'
- en: '| --- | --- |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Correct |  |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 正确 |  |'
- en: '| Precise | Precisely matches reference root cause |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 精确 | 精确匹配参考根本原因 |'
- en: '| Imprecise | Matches reference but misses some details |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 不精确 | 匹配参考但遗漏了一些细节 |'
- en: '| Hallucination | Matches reference but contains unrelated factual errors |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 幻觉 | 匹配参考但包含不相关的事实错误 |'
- en: '| Incorrect |  |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 错误 |  |'
- en: '| Hallucination | Contains factual errors in reasoning or prediction |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 幻觉 | 推理或预测中包含事实错误 |'
- en: '| Insufficient Evidence | Refrains from making a prediction |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 证据不足 | 避免做出预测 |'
- en: '| Other | Cause of error unknown |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 其他 | 错误原因未知 |'
- en: '| Reasoning Error | Reasoning contains errors |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 推理错误 | 推理包含错误 |'
- en: '| Retrieval Error | Unable to retrieve relevant historical incidents |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 检索错误 | 无法检索相关历史事件 |'
- en: While automatic metrics can serve as proxies for lexical and semantic similarity,
    they are not able to accurately measure factual accuracy or conclusively establish
    semantic equivalence. Common failure modes of these metrics include predictions
    that restate the incident report or highly generic predictions (e.g. ”there was
    a transient network issue”) ([Ahmed2023-ov,](#bib.bib1) ), both of which can trivially
    boost lexical similarity. To better characterize the performance of the LLM agent
    and other baselines, two authors conduct a qualitative coding on a sample of 100
    predictions for three models (300 annotations in total). The labelling is done
    in iteratively, and the authors engaged in extended discussions to resolve disagreements.
    We characterize both success and failure modes of these models based on the coding
    scheme shown in Table [1](#S5.T1 "Table 1 ‣ 5.6\. Qualitative Analysis ‣ 5\. Methodology
    ‣ Exploring LLM-based Agents for Root Cause Analysis"). The coding scheme is adapted
    from Yao et al. ([Yao2022-uc,](#bib.bib40) ) and specialized for the RCA task.
    The adaptations are a superset of the original categories and were made after
    performing labelling on a smaller sample 20 predictions to distinguish useful
    scenarios for RCA. Notably, for correct predictions, we differentiate correct
    predictions that unambiguously match the reference (Precise), match the reference
    semantically but exclude some specifics present in the reference (Imprecise),
    and those that match the root cause semantically but also contain unrelated factual
    accuracies (Hallucinations). The last case commonly manifests as predictions that
    suggest the execution of post-hoc resolutions actions (e.g. the incident was resolved
    by restarting the affected cluster) that did not take place. Imprecise predictions
    can be useful for OCEs, whereas factual errors can mislead OCEs. For predictions
    that don’t match the reference root cause, we add two new categories to the ones
    from  ([Yao2022-uc,](#bib.bib40) ). The first, Insufficient Evidence, refers to
    an incorrect prediction that indicates that there isn’t enough evidence available
    to determine the root cause for the incident. The second, Other, refers to instances
    of incorrect predictions that do not have a clearly identifiable cause for error.
    This is an extension to the label ambiguity category from  ([Yao2022-uc,](#bib.bib40)
    ), and now includes other failure cases where the model predicts a plausible specific
    root cause (unlike Insufficient Evidence which is only applied to cases where
    no specific root cause is indicated), but does not contain obvious reasoning,
    retrieval, or factual errors. This is often due to the information sparsity of
    incident reports, especially in cases where the incident report provides details
    as external links that are inaccessible for the models.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管自动化指标可以作为词汇和语义相似性的代理，但它们无法准确测量事实准确性或确定语义等价性。这些指标常见的失败模式包括重复事件报告的预测或高度通用的预测（例如“出现了暂时的网络问题”）（[Ahmed2023-ov,](#bib.bib1)），这两者都可以轻松地提升词汇相似性。为了更好地描述LLM代理及其他基线的性能，两位作者对三种模型的100个预测样本（总共300个注释）进行了定性编码。这些标签是迭代完成的，作者们进行了广泛的讨论以解决分歧。我们根据表[1](#S5.T1
    "Table 1 ‣ 5.6\. Qualitative Analysis ‣ 5\. Methodology ‣ Exploring LLM-based
    Agents for Root Cause Analysis")中显示的编码方案来描述这些模型的成功和失败模式。编码方案改编自Yao等人（[Yao2022-uc,](#bib.bib40)），并针对RCA任务进行了专业化。改编后的方案是原始类别的超集，经过对20个预测的小样本进行标注后制定，目的是区分对RCA有用的场景。值得注意的是，对于正确的预测，我们区分那些明确匹配参考（精确），语义上匹配参考但排除参考中存在的一些细节（不精确），以及那些在语义上匹配根本原因但也包含不相关的事实错误（幻觉）的预测。最后一种情况通常表现为建议执行事后补救措施的预测（例如，通过重启受影响的集群解决了问题），这些措施实际上并未发生。不精确的预测对OCE有用，而事实错误可能会误导OCE。对于那些不匹配参考根本原因的预测，我们添加了两个新类别，分别是（[Yao2022-uc,](#bib.bib40)）中的类别。第一个类别是“证据不足”，指的是一个错误的预测，表明没有足够的证据来确定事件的根本原因。第二个类别是“其他”，指的是那些无法明确识别错误原因的错误预测。这是对（[Yao2022-uc,](#bib.bib40)）中标签模糊性类别的扩展，现在包括了模型预测出合理的具体根本原因（不同于“证据不足”，该类别仅适用于未指出具体根本原因的情况），但没有明显的推理、检索或事实错误的其他失败案例。这通常是由于事件报告的信息稀疏性，特别是在事件报告提供作为外部链接的详细信息，模型无法访问这些链接的情况下。
- en: 6\. RQ1 and RQ2 Results
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6. RQ1和RQ2结果
- en: Table 2. RCA performance on test set
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 表2. 测试集上的RCA性能
- en: '| Model | C-BLEU | S-BLEU | rougeL | METEOR | BertS |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | C-BLEU | S-BLEU | rougeL | METEOR | BertS |'
- en: '| RB (k=3) | 4.73 | 4.64 | 18.48 | 21.62 | 0.863 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| RB (k=3) | 4.73 | 4.64 | 18.48 | 21.62 | 0.863 |'
- en: '| RB (k=6) | 5.66 | 5.56 | 19.78 | 23.25 | 0.865 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| RB (k=6) | 5.66 | 5.56 | 19.78 | 23.25 | 0.865 |'
- en: '| RB (k=10) | 5.97 | 5.74 | 20.30 | 24.11 | 0.866 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| RB (k=10) | 5.97 | 5.74 | 20.30 | 24.11 | 0.866 |'
- en: '| CoT | 6.31 | 5.60 | 19.91 | 22.02 | 0.865 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| CoT | 6.31 | 5.60 | 19.91 | 22.02 | 0.865 |'
- en: '| IR-CoT ST | 3.91 | 3.67 | 16.97 | 18.50 | 0.859 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| IR-CoT ST | 3.91 | 3.67 | 16.97 | 18.50 | 0.859 |'
- en: '| IR-CoT BM25 | 4.61 | 4.02 | 17.56 | 19.94 | 0.860 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| IR-CoT BM25 | 4.61 | 4.02 | 17.56 | 19.94 | 0.860 |'
- en: '| ReAct BR | 5.53 | 4.90 | 17.45 | 19.23 | 0.858 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| ReAct BR | 5.53 | 4.90 | 17.45 | 19.23 | 0.858 |'
- en: '| ReAct S+Q BM25 | 5.59 | 4.73 | 17.43 | 18.72 | 0.857 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| ReAct S+Q BM25 | 5.59 | 4.73 | 17.43 | 18.72 | 0.857 |'
- en: '| ReAct S+Q ST | 5.27 | 4.58 | 17.35 | 18.60 | 0.857 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| ReAct S+Q ST | 5.27 | 4.58 | 17.35 | 18.60 | 0.857 |'
- en: '6.1\. RQ1: How effective are LLM based agents at finding incident root causes
    when given access to a generalized toolkit?'
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '6.1\. RQ1: 基于 LLM 的代理在获得通用工具包的情况下发现事件根因的效果如何？'
- en: Table [2](#S6.T2 "Table 2 ‣ 6\. RQ1 and RQ2 Results ‣ Exploring LLM-based Agents
    for Root Cause Analysis") presents the results for our quantitative evaluation
    based on automatic evaluation metrics. For the Retrieval Baseline model, we see
    that the number of historical retrieved has a positive impact on performance across
    the 4 lexical metrics. However, the impact on semantic metrics remains small ($RQ1 Takeaways: ReAct agents
    perform competitively with retrieval and chain of thought baselines on semantic
    similarity, while under performing on lexical metrics. Manual labelling reveals
    that they achieve competitive correctness rates (35% for ReAct S+Q BM25 vs 39%
    for the baselines), while providing a substantially lower rate of hallucinations
    (4% for ReAct vs 12% for CoT and 40% for RB (k=10)).'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 'RQ1 Takeaways: ReAct agents
    perform competitively with retrieval and chain of thought baselines on semantic
    similarity, while under performing on lexical metrics. Manual labelling reveals
    that they achieve competitive correctness rates (35% for ReAct S+Q BM25 vs 39%
    for the baselines), while providing a substantially lower rate of hallucinations
    (4% for ReAct vs 12% for CoT and 40% for RB (k=10)).'
- en: '6.2\. RQ2: Do discussion comments help improve LLM based approaches to root
    cause analysis?'
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '6.2\. RQ2: 讨论评论是否有助于提升基于 LLM 的根本原因分析方法？'
- en: Table 4. Test set results after incorporating discussions
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4. 纳入讨论后的测试集结果
- en: '| Model | C-BLEU | S-BLEU | rougeL | METEOR | BertS |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | C-BLEU | S-BLEU | rougeL | METEOR | BertS |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| RB (k=10) | 6.65 $\uparrow$ | 0.867 |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| RB (k=10) | 6.65 $\uparrow$ | 0.867 |'
- en: '| CoT | 6.18 $\downarrow$ | 0.861 |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| CoT | 6.18 $\downarrow$ | 0.861 |'
- en: '| ReAct BR | 5.44 $\downarrow$ | 0.854 |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| ReAct BR | 5.44 $\downarrow$ | 0.854 |'
- en: '| ReAct S+Q BM25 | 5.52 | 4.68 | 17.4 | 18.96 $\uparrow$ | 0.858 |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| ReAct S+Q BM25 | 5.52 | 4.68 | 17.4 | 18.96 $\uparrow$ | 0.858 |'
- en: 'Table [4](#S6.T4 "Table 4 ‣ 6.2\. RQ2: Do discussion comments help improve
    LLM based approaches to root cause analysis? ‣ 6\. RQ1 and RQ2 Results ‣ Exploring
    LLM-based Agents for Root Cause Analysis") shows the performance of the considered
    models after incorporating discussions into retrieved historical incidents. In
    general, incorporating discussions provides mixed results on model performance
    for lexical metrics across different models. Discussions improve performance on
    C-BLEU, S-BLEU and rougeL for RB (k=10)  but these improvements are modest. On
    the other hand, it experiences a modest drop in performance for METEOR ($RQ2 Takeaways: Incorporating
    discussion comments into the historical corpus does not clearly improve models’
    performance on RCA. Depending on the metric considered, it can both improve or
    degrade performance on lexical metrics. Semantic metrics remain largely unchanged
    by the incorporation of discussions.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 'RQ2 Takeaways: Incorporating
    discussion comments into the historical corpus does not clearly improve models’
    performance on RCA. Depending on the metric considered, it can both improve or
    degrade performance on lexical metrics. Semantic metrics remain largely unchanged
    by the incorporation of discussions.'
- en: '7\. Practical Implementation of RCA Agent: A Case Study'
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7. 实际实施RCA代理：案例研究
- en: Our evaluation of the ReAct agent in RQ1 and RQ2 does not fully capture the
    capability of the agent to dynamically plan and collect additional diagnostic
    data from team specific diagnostic services. Here, we explore these abilities
    of the agent by conducting a case study with Azure Fundamental Team  to shed light
    on these capabilities.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对RQ1和RQ2中的ReAct代理的评估未能完全捕捉到该代理动态规划和从团队特定诊断服务中收集额外诊断数据的能力。在这里，我们通过与Azure基础团队进行案例研究来探讨这些能力，以揭示这些功能。
- en: 'Title: [SettingDrift] Enable\censorSiriusAppliancePathCreation
    is drifted Description: ¡empty¿'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 'Title: [SettingDrift] Enable\censorSiriusAppliancePathCreation
    is drifted Description: ¡empty¿'
- en: Figure 3. Sample Incident
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图3. 示例事件
- en: 7.1\. Approach
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1. 方法
- en: We work with Azure Fundamental Team  over a period of 4 weeks, primarily using
    unstructured discussions. We start by understanding their needs and the challenges
    they face with regard to RCA, followed by presenting them with the potential benefits
    and limitations associated with integrating an LLM based agent into their workflow.
    Next, we identify key diagnostic services used by the team in practice, how these
    services are used, and iteratively develop tools that can allow the agent to interface
    with these services. Lastly, we conduct demonstrations of the agent with a small
    set of incidents in a simple chat interface with the team to collect their feedback.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们与Azure基础团队合作，为期4周，主要通过非结构化讨论进行。我们首先了解他们在RCA方面的需求和面临的挑战，然后向他们展示将基于LLM的代理集成到他们的工作流程中的潜在好处和局限性。接下来，我们识别团队在实践中使用的关键诊断服务，这些服务的使用方式，并迭代开发可以让代理与这些服务接口的工具。最后，我们通过简单的聊天界面向团队展示代理，并收集他们的反馈。
- en: 7.2\. Knowledge Base Articles (KBAs)
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2. 知识库文章（KBAs）
- en: A common practice in large IT companies is to encode domain knowledge in internal
    knowledge base articles. In the context of incident management, these articles
    contain guidelines for how certain types of incidents must be diagnosed and mitigated,
    as well as key information about how to conduct these operations such as example
    database queries. At Microsoft, engineers maintain a large number of KBAs for
    incident management. They help in standardizing operational procedures, facilitating
    sharing of knowledge across various teams, and onboarding new engineers. Many
    types of incidents, especially ones triggered by monitoring services, are tagged
    with relevant KBAs either automatically, or manually during triage. For these
    incidents, OCEs will have access to relevant KBAs the moment they start the RCA.
    Incidents that do not have associated KBAs typically require OCEs to spend time
    searching for and locating relevant KBAs before they can start RCA. We consider
    both of these scenarios in our case study.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在大型IT公司中，常见的做法是将领域知识编码到内部知识库文章中。在事件管理的背景下，这些文章包含了如何诊断和缓解某些类型事件的指南，以及进行这些操作的关键资料，例如示例数据库查询。在微软，工程师维护大量的KBAs以进行事件管理。它们帮助标准化操作程序，促进各团队之间的知识共享，并帮助新工程师入职。许多类型的事件，尤其是由监控服务触发的事件，通常会被自动或手动标记为相关的KBAs。在这些事件中，OCEs在开始RCA时可以立即访问相关KBAs。没有相关KBAs的事件通常需要OCEs花时间搜索和定位相关KBAs，然后才能开始RCA。我们在案例研究中考虑了这两种情况。
- en: 7.3\. Agent Development
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3. 代理开发
- en: 'We reuse the ReAct agent from RQ1 and RQ2, but we replace the generalized tools
    with specialized tools that can access team specific diagnostic data. Based on
    discussions with Azure Fundamental Teamand preliminary experiments, we settled
    on the following set of tools:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们重复使用RQ1和RQ2中的ReAct代理，但将通用工具替换为可以访问团队特定诊断数据的专业工具。根据与Azure基础团队的讨论和初步实验，我们确定了以下工具集：
- en: 'Database Query Tool: We design and implement a tool that can be used by the
    agent to query databases and then analyze query results. The database framework
    used by the team utilizes a custom query language, which is somewhat similar to
    SQL. The tool design was informed by discussions with the team as well as analysis
    of several historical incidents experienced by the team. Based on our investigation,
    we settled on a design that uses two distinct components for this tool: the Query
    Execution Engine and the Pandas DataFrame Query Engine. The Query Execution Engine
    can be used by the agent to query the database. This requires not only the construction
    of the actual database query, but also knowledge of the cluster on which the database
    is deployed and the name of the database. This generic design gives the agent
    flexibility in making queries and also increases re-usability of this tool for
    other teams that are also using the same database platform. Once a query is successfully
    executed, the results returned by the database are transformed into a Pandas DataFrame
    and sent to the Pandas DataFrame Query Engine. The agent can then perform question-answering
    over the returned table using natural language queries. The Pandas DataFrame Query
    Engine itself consists of an LLM, which, based on the agent’s queries, performs
    transformations on the DataFrame using the Python Interpreter and then generates
    a final answer.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库查询工具：我们设计并实现了一个工具，供代理使用以查询数据库并分析查询结果。团队使用的数据库框架采用了自定义查询语言，这种语言与SQL有些相似。工具设计受到了与团队讨论以及对团队经历的若干历史事件分析的启发。基于我们的调查，我们确定了使用两个不同组件的设计：查询执行引擎和Pandas
    DataFrame查询引擎。查询执行引擎可以由代理用于查询数据库。这不仅需要构建实际的数据库查询，还需要了解数据库部署的集群和数据库的名称。这种通用设计为代理提供了灵活的查询能力，并且提高了该工具在使用相同数据库平台的其他团队中的重用性。一旦查询成功执行，数据库返回的结果会转换成Pandas
    DataFrame，并发送到Pandas DataFrame查询引擎。然后，代理可以通过自然语言查询对返回的表格进行问答。Pandas DataFrame查询引擎本身包含一个LLM，该LLM根据代理的查询，使用Python解释器对DataFrame进行转换，然后生成最终答案。
- en: 'KBA Q/A Tool: KBAs often contain critical information that is required to perform
    RCA, and are one of the most widely used resources for incident management at
    Microsoft. For example, one of the key pieces of information required to use the
    Database Query Tool is the cluster address. This information is typically only
    available to OCEs via KBAs. To incorporate this information into the agent, we
    expose a question-answering tool over a set of KBAs (14 documents) provided by
    the team. The tool consists of a vectorstore containing chunks of KBAs, and an
    LLM which, given a query from the agent, uses knowledge from the retrieved KBA
    chunks to answer the query. If the incident in question has an associated KBA,
    we do not use the vectorstore and directly use it to answer questions posed by
    the planner.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: KBA问答工具：KBA通常包含执行RCA所需的关键信息，是Microsoft进行事件管理时最广泛使用的资源之一。例如，使用数据库查询工具所需的关键信息之一是集群地址。这些信息通常只有OCE才能通过KBA获得。为了将这些信息纳入代理中，我们提供了一个针对一组KBA（14份文档）的问答工具。该工具包括一个包含KBA片段的向量存储和一个LLM，该LLM根据代理的查询，利用检索到的KBA片段中的知识回答查询。如果相关事件有相关的KBA，我们不会使用向量存储，而是直接使用它来回答规划者提出的问题。
- en: 'KBA Planning Tool: During preliminary experiments with the team, we noticed
    that the eager interleaving of thoughts and actions of ReAct can be detrimental
    to high level planning, i.e. it can sometimes start unsuccessfully carrying out
    troubleshooting tasks without constructing a high level plan to guide RCA. To
    mitigate this phenomenon, we introduce a variant of the KBA Q/A tool which is
    designed to be used specifically for planning. Structurally, it is identical to
    the Q/A tool, but introducing it explicitly into the action space of the agent
    encourages it to consistently construct high level plans before taking concrete
    diagnostic steps.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: KBA规划工具：在与团队进行初步实验时，我们注意到ReAct的积极交替思考和行动可能对高级规划产生不利影响，即有时它可能在没有构建高级计划来指导RCA的情况下开始不成功地进行故障排除任务。为了缓解这种现象，我们引入了一种KBA问答工具的变体，专门用于规划。从结构上讲，它与问答工具相同，但将其显式引入代理的行动空间中，鼓励代理在采取具体诊断步骤之前始终构建高级计划。
- en: 'Human Interaction Tool: Our discussions with the team revealed several scenarios
    instances where a human-in-the-loop style workflow is necessary for RCA. For example,
    diagnosing certain types of incidents requires reproducing the error reported
    in the incident, or manually logging into a cloud device and extracting diagnostic
    information, which would be difficult for the agent to do. Therefore, it is desirable
    to have the ability for the OCE to collect such information, and provide it as
    an observation to the agent. Moreover, our preliminary experiments revealed that
    the agent struggles to make progress when key information is missing in the KBAs
    (such as missing cluster address for DB queries), but this information can often
    easily be provided by the OCE to the agent. Therefore, we add a Human Interaction
    Tool to allow the agent to request diagnostic information from OCEs, and also
    add UI enhancements to allow OCEs to interject the agent’s action steps, manually
    verify tool executions and provide explicit feedback to the agent when desired.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 人工互动工具：与团队的讨论揭示了多个场景实例，在这些场景中，RCA 需要人机交互式工作流程。例如，诊断某些类型的事件需要重现报告中的错误，或手动登录云设备并提取诊断信息，这对代理来说可能很困难。因此，OCE
    能够收集这些信息，并将其作为观察提供给代理是非常有利的。此外，我们的初步实验揭示，当 KBA 中缺少关键信息（如 DB 查询缺少集群地址）时，代理往往难以取得进展，但这些信息通常可以由
    OCE 轻松提供。因此，我们增加了一个人工互动工具，允许代理从 OCE 处请求诊断信息，同时还增加了 UI 增强功能，以允许 OCE 插入代理的操作步骤，手动验证工具执行情况，并在需要时向代理提供明确的反馈。
- en: '7.4\. RQ3 Results: How effective are LLM based agents at root cause analysis
    when given access to specialized tools used by a team for incident management?'
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4\. RQ3 结果：当 LLM 基于的代理可以访问团队用于事件管理的专业工具时，根本原因分析的效果如何？
- en: 7.4.1\. Challenges faced by OCEs in the team for RCA
  id: totrans-148
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.4.1\. 团队中 OCE 面临的 RCA 挑战
- en: Azure Fundamental Teamdevelops and maintains core services within the company’s
    cloud platform, which hosts both internal and external customers that host cloud
    applications on their platform. While many of the incidents they receive are human
    reported, also maintain several systems that automatically detect and report error
    states. They maintain a large number of troubleshooting guides (KBAs) to mitigate
    the diversity of incident types and associated diagnostic steps. When a KBA exists
    for a certain type of incident, and the incident is relatively simple, new engineers
    with limited experience with the team’s services are able to effectively perform
    RCA. However, identifying the right KBA for an incident can take time, and when
    incidents get more complex, a significant amount (¿ 1.5 years) of experience is
    required for RCA.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Fundamental Team 负责开发和维护公司云平台上的核心服务，该平台为内部和外部客户提供托管云应用的服务。虽然他们收到的许多事件是人工报告的，但他们也维护几个系统，这些系统能自动检测和报告错误状态。他们维护大量的故障排除指南（KBAs）以减轻事件类型和相关诊断步骤的多样性。当某种类型的事件存在
    KBA 且事件相对简单时，经验有限的新工程师能够有效地执行 RCA。然而，找到适合事件的正确 KBA 可能需要时间，而当事件变得更复杂时，执行 RCA 需要相当多（约
    1.5 年）的经验。
- en: 7.4.2\. Real world RCA using ReAct
  id: totrans-150
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.4.2\. 使用 ReAct 的实际 RCA
- en: 'We started by investigating simple incidents which have a clear KBA article
    available, and requires a straightforward sequence of diagnostic steps with minimal
    branching. We use the incident shown in Figure [3](#S7.F3 "Figure 3 ‣ 7\. Practical
    Implementation of RCA Agent: A Case Study ‣ Exploring LLM-based Agents for Root
    Cause Analysis") as an illustrative example of incidents of this type. This incident
    reports that there has been a setting drift in a cluster, i.e. a setting is out
    of sync with the central orchestrating server. This is a type of incident that
    is automatically reported by monitoring services, which is why the description
    is empty. Diagnosing this incident can lead to exactly two outcomes: 1) if there
    are no tenants in the affected cluster, the incident is marked as a false positive
    and no mitigation is required and 2) if the cluster is hosting tenants, then the
    OCE must identify the affected clusters (this information isn’t present in the
    incident report) and manually instantiate a job that will rectify the setting
    drift to mitigate the incident. Identifying the correct outcome requires querying
    a database to identify affected clusters and analyzing the returned table to determine
    whether the incident is a false positive, or requires mitigation. Lastly, the
    incident report includes an associated KBA describing the necessary troubleshooting
    steps, example database queries as well as key pieces of information such as the
    database address.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先调查了那些有清晰 KBA 文章且需要简单诊断步骤且分支最小的简单事件。我们使用图[3](#S7.F3 "图 3 ‣ 7. RCA 代理的实际应用案例
    ‣ 探索基于 LLM 的根因分析代理")中展示的事件作为此类事件的示例。该事件报告了一个集群中的设置漂移，即一个设置与中央协调服务器不同步。这种事件由监控服务自动报告，因此描述为空。诊断此事件可能有两个结果：1）如果受影响的集群中没有租户，则该事件被标记为假阳性，不需要采取任何缓解措施；2）如果集群中托管了租户，则
    OCE 必须识别受影响的集群（此信息在事件报告中不存在）并手动启动一个作业来纠正设置漂移以缓解事件。识别正确的结果需要查询数据库以识别受影响的集群，并分析返回的表格以确定事件是否为假阳性，或者是否需要缓解。最后，事件报告包括一个关联的
    KBA，描述了必要的故障排除步骤、示例数据库查询以及关键信息，如数据库地址。
- en: Even though this incident is relatively straightforward for OCEs, it is not
    possible to identify whether it is a false alarm or not based only on the incident
    report. This underlines the importance of having access to diagnostic APIs for
    any automated RCA mechanism. In particular, it is worthwhile to note that even
    if an automated approach is able to correctly predict the outcome without carrying
    out the proper diagnostic steps, the OCE would still have to carry them out to
    verify the prediction. When we tested ReAct agent on this incident, it is able
    to correctly identify case 1 consistently. This involved using the KBA Planning
    Tool to gather the required troubleshooting steps, adapt and execute the sample
    query from the KBA, and correctly assess the resulting table. While this series
    of action is not challenging for OCEs to execute, we stress the fact that ReAct agent
    has no prior knowledge of the domain, the incident or the syntax of the database
    query language. Yet, it is able to leverage the KBA to autonomously complete the
    RCA process. We observed that the agent would sometimes fail to execute the database
    query in its first attempt. However, since we surface appropriate error messages
    to the agent as observations, it was consistently able to rectify these mistakes
    and complete the troubleshooting process. One engineer expressed that they were
    ”amazed by the tool’s capability to automatically discern the right parameters
    and even rectify mistakes when the parameters are initially incorrect by querying
    the documents”. On the other hand, the second outcome of this incident (case 2),
    requires an additional filtering step to remove some rows from the table returned
    by the database query. In our demonstrations with the team, the agent is unable
    to resolve this error consistently, but engineers were able to use the human-in-the-loop
    features of the prototype to intervene and fix the error encountered in the filtering
    step.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个事件对于OCE（操作支持工程师）来说相对简单，但仅凭事件报告无法判断这是否是误报。这突出了获取诊断API对于任何自动化根本原因分析（RCA）机制的重要性。特别需要注意的是，即使自动化方法能够正确预测结果而无需执行适当的诊断步骤，OCE仍然需要执行这些步骤以验证预测。当我们在这个事件上测试ReAct代理时，它能够始终如一地正确识别案例1。这包括使用KBA计划工具收集所需的故障排除步骤，调整并执行来自KBA的示例查询，并正确评估结果表。虽然这系列操作对于OCE来说并不具挑战性，但我们强调ReAct代理没有领域知识、事件背景或数据库查询语言的语法知识。然而，它能够利用KBA自主完成RCA过程。我们观察到代理有时在第一次尝试时会失败执行数据库查询。然而，由于我们将适当的错误消息呈现给代理作为观察，它能够始终如一地纠正这些错误并完成故障排除过程。一位工程师表示，他们对工具“能够自动辨别正确参数，甚至在参数初始不正确时通过查询文档来纠正错误”的能力感到“惊讶”。另一方面，这个事件的第二个结果（案例2）需要一个额外的过滤步骤来从数据库查询返回的表中删除一些行。在我们与团队的演示中，代理无法始终如一地解决这个错误，但工程师能够利用原型的人工干预功能介入并修复过滤步骤中遇到的错误。
- en: We also examined complex incidents from the team that did not have a clear set
    of troubleshooting steps in a single KBA, i.e. it required combining information
    from multiple KBAs. The diagnosis steps typically involved a series of database
    queries. Engineers on Azure Fundamental Teamindicated that these incidents require
    at least a year of experience with the team’s services to effectively diagnose.
    Here, we observed that while the agent initially produces a plausible high level
    plan, it was only ever able to successfully execute one or two diagnostic steps
    before reaching the iteration limit (20). This is primarily due to the difficulty
    in producing database queries for these incidents, as information is distributed
    over multiple KBAs, e.g. sample queries and cluster address are not in the same
    KBA, requiring the agent to query the KBA Q/A tool multiple times before being
    able to execute a query. While the iteration limit can be extended, it will eventually
    fill the context. This signals the need for scaleable multi-trial framework, where
    experience from past trials can be used to guide future trials (e.g. ([Shinn_undated-kf,](#bib.bib29)
    ; [Zhao2023-rd,](#bib.bib43) ; [Madaan2023-tk,](#bib.bib18) ).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还检查了来自团队的复杂事件，这些事件没有单一 KBA 中的明确故障排除步骤，即需要结合多个 KBAs 的信息。诊断步骤通常涉及一系列数据库查询。Azure
    基础团队的工程师表示，这些事件需要至少一年团队服务经验才能有效诊断。在这里，我们观察到虽然代理最初提出了一个合理的高层计划，但在达到迭代限制（20）之前，代理仅能成功执行一两个诊断步骤。这主要是由于为这些事件生成数据库查询的困难，因为信息分布在多个
    KBAs 中，例如样本查询和集群地址不在同一 KBA 中，需要代理多次查询 KBA Q/A 工具才能执行查询。虽然可以延长迭代限制，但最终会填满上下文。这表明需要一个可扩展的多次试验框架，其中过去试验的经验可以用来指导未来的试验（例如
    ([Shinn_undated-kf,](#bib.bib29) ; [Zhao2023-rd,](#bib.bib43) ; [Madaan2023-tk,](#bib.bib18)
    )。
- en: 7.5\. Learnings and Practical Considerations
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.5\. 学习成果与实践考虑
- en: In this section, we distill some key considerations for the implementation of
    practical LLM based agents based on our experience in the case study and feedback
    from OCEs.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们根据案例研究中的经验和 OCEs 的反馈，提炼了一些实施实用 LLM 代理的关键考虑因素。
- en: KBAs are critical to real world RCA. As seen from our findings, KBAs, are critical
    to performing real world RCA. They contain both specialized domain knowledge and
    auxillary facts about the agent’s environment (e.g. database addresses, API information)
    that are required both for OCEs and LLM agents to effectively carry out diagnostic
    steps. Even experienced OCEs must either refer to KBAs in real-time or have internalized
    the information present in these KBAs to some degree to perform RCA. While some
    of this information can also be gleaned from historical incidents, incident reports
    typically only contain the outcome of diagnosis steps (commonly in discussion
    comments) rather than operational knowledge of how these steps must be performed.
    This is also why engineers across the company invest significant time and effort
    into the construction and maintenance of KBAs.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: KBAs 对实际世界的 RCA 至关重要。从我们的发现中可以看出，KBAs 对于执行实际世界的 RCA 是关键的。它们包含了专门的领域知识和有关代理环境的辅助信息（例如数据库地址、API
    信息），这些信息对于 OCEs 和 LLM 代理在有效执行诊断步骤时都是必需的。即使是经验丰富的 OCEs 也必须实时参考 KBAs 或在某种程度上内化这些
    KBAs 中的信息以执行 RCA。虽然有些信息也可以从历史事件中获取，但事件报告通常只包含诊断步骤的结果（通常在讨论评论中），而不是如何执行这些步骤的操作知识。这也是为什么公司中的工程师投入大量时间和精力来建设和维护
    KBAs 的原因。
- en: Tool usage in RCA is non-trivial. While LLMs such as GPT-4 have shown remarkable
    ability to use tools prevalent in NLP such as retrieval and search, querying of
    diagnostic services using specialized query languages requires some trial and
    error. For this reason, we found that it was critical to surface error messages
    to the agent to provide feedback to the agent in instances of tool failures. One
    optimization in this regard is to replace LLMs used in tools with smaller models
    finetuned for tool usage. In real world settings, if we are able to scope out
    a set of common parameterized services that can be specialized to different teams,
    finetuning the planning model to the generic usage of these tools might also significant
    gains.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在RCA中使用工具并非微不足道。虽然像GPT-4这样的LLM在使用自然语言处理（NLP）中普遍存在的工具（如检索和搜索）方面表现出色，但使用专门查询语言查询诊断服务需要一些试验和错误。因此，我们发现，在工具失败的情况下，向代理提供错误信息以反馈是至关重要的。对此的一个优化是用针对工具使用微调的小型模型替换用于工具的LLM。在现实世界中，如果我们能够列出一组可以专门化到不同团队的常见参数化服务，微调规划模型以适应这些工具的通用使用也可能带来显著的收益。
- en: For complicated workflows, experiential learning and multi-trial workflows are
    necessary. Incidents that require a long and complex sequence of diagnostic steps
    for RCA typically have a large space of possible action trajectories. This poses
    significant challenges for the agent. For these incidents, single trial RCA, where
    we restrict the agent trajectory to 20 steps, is not sufficient. Extending the
    agent to a multi-trial setting necessitates the use of a reflection ([Shinn2023-hb,](#bib.bib30)
    ; [Madaan2023-tk,](#bib.bib18) ) or long term memory component to be able to preserve
    progress across trials, that allows for experiential learning. These mechanisms
    allow for learning based using natural language as the medium, and present opportunities
    for building a system where learnings from a specific team’s incidents can be
    stored in a database, and retrieved for performing RCA on future incidents for
    the team.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 对于复杂的工作流程，体验学习和多次尝试的工作流程是必要的。需要长时间和复杂的诊断步骤来进行根本原因分析（RCA）的事件通常有广泛的可能行动轨迹空间。这对代理而言是巨大的挑战。对于这些事件，限制代理轨迹到20步的单次尝试RCA是不够的。将代理扩展到多次尝试的设置中，需要使用反思（[Shinn2023-hb](#bib.bib30)
    ; [Madaan2023-tk](#bib.bib18)）或长期记忆组件，以便在试验之间保存进展，从而实现体验学习。这些机制允许使用自然语言作为媒介进行基于学习的学习，并提供了构建一个系统的机会，在该系统中，可以将特定团队事件的学习存储在数据库中，并在未来团队的事件中进行RCA。
- en: Human intervention is necessary to build trust and provide some guardrails for
    LLMs for critical operations. There are many diagnostic steps which can be easily
    carried out by OCEs, but are not accessible as consumable services for the agent.
    Moreover, when agents struggle with certain parts of the diagnostic process, such
    as in our study, engineers can easily intervene and correct the agent’s trajectory.
    Therefore, we recommend that agents used in practical incident management scenarios
    be endowed with capabilities to allow for human interaction, using a combination
    of explicit tools in the agent’s action space, and UI features for the application
    exposing the agent to users. These capabilities can also be incredibly useful
    when combined with experiential learning; one can imagine a scenario where an
    engineer supervises an agent for a small set of team specific incidents, while
    it builds its repository of experiences, to enable quick domain adaptation for
    team specific knowledge, and avoid the burden of building a fine-tuning dataset
    for adaptation purposes.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 人工干预对于建立信任并为LLM的关键操作提供一些保护措施是必要的。有许多诊断步骤可以由OCE轻松完成，但对代理而言并不可用。此外，当代理在诊断过程中的某些部分遇到困难时，例如在我们的研究中，工程师可以轻松介入并纠正代理的轨迹。因此，我们建议在实际事件管理场景中使用的代理应具备允许人工互动的能力，结合代理行动空间中的显式工具和应用程序为用户展示代理的UI功能。这些能力在结合体验学习时也可以非常有用；可以想象一种场景，其中一名工程师监督代理处理一小部分团队特定的事件，同时代理建立其经验库，以便快速领域适应团队特定的知识，并避免为适应目的构建微调数据集的负担。
- en: 8\. Threats to Validity
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8\. 有效性威胁
- en: The evaluation of the agent and other baselines for RCA are conducted on an
    internal dataset collected at Microsoft, and might not apply to datasets constructed
    from other organizations. We use a smaller sample (n=500) of our test set to satisfy
    budget constraints which might not reflect performance on the larger test set.
    However, we minimize this threat by using random sampling, and a sample size that
    has been employed in prior studies. Another threat to validity comes from our
    manual annotations to qualitatively characterize model predictions. We mitigate
    this by adapting labelling criterion from prior work, and engage in multiple rounds
    of discussion to converge on particularly ambiguous examples.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 对于RCA的代理和其他基准的评估是在微软收集的内部数据集上进行的，可能不适用于其他组织构建的数据集。我们使用了较小的样本（n=500）以满足预算限制，这可能无法反映在较大测试集上的表现。然而，我们通过使用随机抽样以及先前研究中采用的样本大小来最小化这一威胁。另一个有效性威胁来自我们对模型预测的定性描述的人工注释。我们通过采纳先前工作的标注标准，并进行多轮讨论以达成共识，来减轻这一问题。
- en: 9\. Conclusion & Future Work
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9\. 结论与未来工作
- en: This work provides an empirical evaluation of an LLM-based agent,  ReAct  for
    root cause analysis for cloud incident management. To the best of our knowledge,
    this is the first empirical evaluation of LLM agents for RCA. We have shown that
    in an out of domain, zero-shot setting, ReAct can perform competitively with strong
    baselines such as retrieval augmented generation and CoT, while offering substantially
    lower rates of factual inaccuracies. We also showed that the use of discussion
    comments from incident reports does not have a significant impact on the agent’s
    performance, revealing the limitations of performing RCA on a static dataset.
    Lastly, through our case study, we demonstrate the potential of LLM-agents to
    autonomously perform RCA in a real world setting when given access to the right
    tools. The work presented here is a first step in the development of LLM-based
    agents for practical RCA. One of the most promising directions for future work
    is the construction of a simulated RCA environment. This would overcome the limitations
    of a static dataset, and rapidly enhance the development of agent based approaches
    for RCA. As we continue to explore these avenues of future work, we anticipate
    that ReAct and similar agents will play a pivotal role in advancing incident management
    practices and automating complex decision-making processes in the software engineering
    domain.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作提供了基于LLM的代理ReAct在云事件管理中进行根本原因分析的实证评估。根据我们所知，这是对LLM代理进行RCA的首个实证评估。我们已展示在领域外的零样本设置中，ReAct能够与强大的基准如检索增强生成和CoT竞争，同时提供显著更低的事实不准确率。我们还展示了事件报告中的讨论评论的使用对代理的表现没有显著影响，揭示了在静态数据集上执行RCA的局限性。最后，通过我们的案例研究，我们展示了LLM代理在获得正确工具时在现实世界环境中自主执行RCA的潜力。这里呈现的工作是开发基于LLM的实际RCA代理的第一步。未来工作中最有前景的方向之一是构建一个模拟RCA环境。这将克服静态数据集的局限性，并迅速提升基于代理的方法的发展。随着我们继续探索这些未来工作的方向，我们预计ReAct及类似代理将在推进事件管理实践和自动化复杂决策过程中发挥关键作用。
- en: References
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1) Ahmed, T., Ghosh, S., Bansal, C., Zimmermann, T., Zhang, X., and Rajmohan,
    S. Recommending Root-Cause and mitigation steps for cloud incidents using large
    language models.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1) Ahmed, T., Ghosh, S., Bansal, C., Zimmermann, T., Zhang, X., 和 Rajmohan,
    S. 使用大型语言模型推荐云事件的根本原因和缓解步骤。
- en: '(2) Banerjee, S., and Lavie, A. METEOR: An automatic metric for MT evaluation
    with improved correlation with human judgments. In Proceedings of the ACL Workshop
    on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or
    Summarization (Ann Arbor, Michigan, June 2005), Association for Computational
    Linguistics, pp. 65–72.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(2) Banerjee, S., 和 Lavie, A. METEOR: 一种自动化的机器翻译评估指标，与人工判断的相关性更高。在ACL机器翻译及/或摘要评估测量研讨会论文集中（密歇根州安阿伯，2005年6月），计算语言学协会，第65–72页。'
- en: '(3) Bansal, C., Renganathan, S., Asudani, A., Midy, O., and Janakiraman, M.
    Decaf: Diagnosing and triaging performance issues in large-scale cloud services.
    CoRR abs/1910.05339 (2019).'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(3) Bansal, C., Renganathan, S., Asudani, A., Midy, O., 和 Janakiraman, M. Decaf:
    诊断和分类大型云服务中的性能问题。CoRR abs/1910.05339 (2019)。'
- en: (4) Carbonell, J., and Goldstein, J. The use of MMR, diversity-based reranking
    for reordering documents and producing summaries. In Proceedings of the 21st annual
    international ACM SIGIR conference on Research and development in information
    retrieval (New York, NY, USA, Aug. 1998), SIGIR ’98, Association for Computing
    Machinery, pp. 335–336.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (4) 卡波内尔，J.，和戈德斯坦，J. 使用MMR，基于多样性的重新排序文档和生成摘要。发表于第21届国际ACM SIGIR信息检索研究与发展会议（美国纽约，1998年8月），SIGIR
    ’98，计算机协会，第335–336页。
- en: (5) Chase, H. LangChain. Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, HP
    d. O (2022).
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (5) 切斯，H. LangChain。陈美，特沃雷克，J. 军，H. 元，Q. 平托，HP d. O（2022年）。
- en: (6) Chen, X., Lin, M., Schärli, N., and Zhou, D. Teaching large language models
    to self-debug. arXiv preprint arXiv:2304\. 05128 (2023).
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (6) 陈晓，林敏，施利，周东。教会大语言模型自我调试。arXiv预印本 arXiv:2304\. 05128（2023年）。
- en: (7) Chen, Y., Sun, X., Nath, S., Yang, Z., and Xu, T. $\{$ applications with
    rainmaker. In 20th USENIX Symposium on Networked Systems Design and Implementation
    (NSDI 23) (2023), pp. 1701–1716.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (7) 陈勇，孙晓，纳斯，S.，杨智，徐涛。$\{$应用与Rainmaker。在第20届USENIX网络系统设计与实施研讨会（NSDI 23）（2023年），第1701–1716页。
- en: (8) Chen, Y., Xie, H., Ma, M., Kang, Y., Gao, X., Shi, L., Cao, Y., Gao, X.,
    Fan, H., Wen, M., Zeng, J., Ghosh, S., Zhang, X., Zhang, C., Lin, Q., Rajmohan,
    S., and Zhang, D. Empowering practical root cause analysis by large language models
    for cloud incidents.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (8) 陈勇，谢辉，马萌，康宇，高欣，石磊，曹宇，高欣，范华，温铭，曾健，戈什，张晓，张晨，林琪，拉吉莫汉，张东。利用大语言模型增强云事件的实际根本原因分析。
- en: '(9) Gao, L., Madaan, A., Zhou, S., Alon, U., Liu, P., Yang, Y., Callan, J.,
    and Neubig, G. PAL: Program-aided language models. 10764–10799.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (9) 高磊，马丹，周舒，阿隆，U.，刘鹏，杨阳，卡兰，J.，和纽比格，G. PAL：程序辅助语言模型。10764–10799。
- en: (10) Hagemann, T., and Katsarou, K. A systematic review on anomaly detection
    for cloud computing environments. In Proceedings of the 2020 3rd Artificial Intelligence
    and Cloud Computing Conference (New York, NY, USA, 2021), AICCC ’20, Association
    for Computing Machinery, p. 83–96.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (10) 哈格曼，T.，和卡萨鲁，K. 云计算环境异常检测的系统性综述。发表于2020年第3届人工智能与云计算会议（美国纽约，2021年），AICCC
    ’20，计算机协会，第83–96页。
- en: (11) Jiang, J., Lu, W., Chen, J., Lin, Q., Zhao, P., Kang, Y., Zhang, H., Xiong,
    Y., Gao, F., Xu, Z., Dang, Y., and Zhang, D. How to mitigate the incident? an
    effective troubleshooting guide recommendation technique for online service systems.
    In Proceedings of the 28th ACM Joint Meeting on European Software Engineering
    Conference and Symposium on the Foundations of Software Engineering (New York,
    NY, USA, 2020), ESEC/FSE 2020, Association for Computing Machinery, p. 1410–1420.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (11) 蒋健，陆伟，陈杰，林琪，赵鹏，康宇，张辉，熊洋，高锋，徐忠，邓洋，张东。如何减轻事件？一种有效的在线服务系统故障排除指南推荐技术。发表于第28届ACM欧洲软件工程会议与软件工程基础研讨会联合会议（美国纽约，2020年），ESEC/FSE
    2020，计算机协会，第1410–1420页。
- en: '(12) Lewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O.,
    Stoyanov, V., and Zettlemoyer, L. BART: Denoising Sequence-to-Sequence pre-training
    for natural language generation, translation, and comprehension.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (12) 刘美，刘洋，戈雅尔，M.，加兹文尼贾德，M.，穆罕默德，A.，列维，O.，斯托亚诺夫，V.，和泽特尔莫耶，L. BART：用于自然语言生成、翻译和理解的去噪序列到序列预训练。
- en: (13) Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N.,
    Küttler, H., Lewis, M., Yih, W.-T., Rocktäschel, T., and Others. Retrieval-augmented
    generation for knowledge-intensive nlp tasks. Adv. Neural Inf. Process. Syst.
    33 (2020), 9459–9474.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (13) 刘鹏，佩雷斯，E.，皮克图斯，A.，彼特罗尼，F.，卡普欣，V.，戈雅尔，N.，库特勒，H.，刘美，Yih，W.-T.，洛克塔谢尔，T.，等人。用于知识密集型自然语言处理任务的检索增强生成。神经信息处理系统进展，33（2020年），9459–9474。
- en: '(14) Lin, C.-Y. ROUGE: A package for automatic evaluation of summaries. In
    Text Summarization Branches Out (Barcelona, Spain, July 2004), Association for
    Computational Linguistics, pp. 74–81.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (14) 林志勇。ROUGE：自动评估摘要的工具包。发表于文本摘要的新发展（西班牙巴塞罗那，2004年7月），计算语言学协会，第74–81页。
- en: '(15) Lou, C., Chen, C., Huang, P., Dang, Y., Qin, S., Yang, X., Li, X., Lin,
    Q., and Chintalapati, M. {RESIN}: A holistic service for dealing with memory leaks
    in production cloud infrastructure. In 16th USENIX Symposium on Operating Systems
    Design and Implementation (OSDI 22) (2022), pp. 109–125.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (15) 陆昌，陈晨，黄鹏，邓洋，秦松，杨翔，李晓，林琪，和钦塔拉帕提，M. {RESIN}：一个全面的服务，用于处理生产云基础设施中的内存泄漏。在第16届USENIX操作系统设计与实施研讨会（OSDI
    22）（2022年），第109–125页。
- en: (16) Luo, C., Lou, J.-G., Lin, Q., Fu, Q., Ding, R., Zhang, D., and Wang, Z.
    Correlating events with time series for incident diagnosis. In Proceedings of
    the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining
    (New York, NY, USA, 2014), KDD ’14, Association for Computing Machinery, p. 1583–1592.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (16) Luo, C., Lou, J.-G., Lin, Q., Fu, Q., Ding, R., Zhang, D., 和 Wang, Z. 将事件与时间序列关联以进行事件诊断。载于第20届
    ACM SIGKDD 国际知识发现与数据挖掘会议论文集（纽约，NY，USA，2014年），KDD ’14，计算机协会，第1583–1592页。
- en: (17) Ma, M., Yin, Z., Zhang, S., Wang, S., Zheng, C., Jiang, X., Hu, H., Luo,
    C., Li, Y., Qiu, N., Li, F., Chen, C., and Pei, D. Diagnosing root causes of intermittent
    slow queries in cloud databases. Proceedings VLDB Endowment 13, 8 (Apr. 2020),
    1176–1189.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (17) Ma, M., Yin, Z., Zhang, S., Wang, S., Zheng, C., Jiang, X., Hu, H., Luo,
    C., Li, Y., Qiu, N., Li, F., Chen, C., 和 Pei, D. 诊断云数据库中间歇性慢查询的根本原因。VLDB 纪要 13,
    8 (2020年4月), 1176–1189。
- en: '(18) Madaan, A., Tandon, N., Gupta, P., Hallinan, S., Gao, L., Wiegreffe, S.,
    Alon, U., Dziri, N., Prabhumoye, S., Yang, Y., Welleck, S., Majumder, B. P., Gupta,
    S., Yazdanbakhsh, A., and Clark, P. Self-Refine: Iterative refinement with Self-Feedback.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(18) Madaan, A., Tandon, N., Gupta, P., Hallinan, S., Gao, L., Wiegreffe, S.,
    Alon, U., Dziri, N., Prabhumoye, S., Yang, Y., Welleck, S., Majumder, B. P., Gupta,
    S., Yazdanbakhsh, A., 和 Clark, P. Self-Refine: 自我反馈的迭代优化。'
- en: '(19) Mathur, N., Baldwin, T., and Cohn, T. Tangled up in BLEU: Reevaluating
    the evaluation of automatic machine translation evaluation metrics.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(19) Mathur, N., Baldwin, T., 和 Cohn, T. 卷入 BLEU: 重新评估自动机器翻译评估指标。'
- en: '(20) Mialon, G., Dessì, R., Lomeli, M., Nalmpantis, C., Pasunuru, R., Raileanu,
    R., Rozière, B., Schick, T., Dwivedi-Yu, J., Celikyilmaz, A., Grave, E., LeCun,
    Y., and Scialom, T. Augmented language models: A survey.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (20) Mialon, G., Dessì, R., Lomeli, M., Nalmpantis, C., Pasunuru, R., Raileanu,
    R., Rozière, B., Schick, T., Dwivedi-Yu, J., Celikyilmaz, A., Grave, E., LeCun,
    Y., 和 Scialom, T. 增强语言模型：一项调查。
- en: (21) Nair, V., Raul, A., Khanduja, S., Bahirwani, V., Shao, Q., Sellamanickam,
    S., Keerthi, S., Herbert, S., and Dhulipalla, S. Learning a hierarchical monitoring
    system for detecting and diagnosing service issues. In Proceedings of the 21th
    ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (New
    York, NY, USA, 2015), KDD ’15, Association for Computing Machinery, p. 2029–2038.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (21) Nair, V., Raul, A., Khanduja, S., Bahirwani, V., Shao, Q., Sellamanickam,
    S., Keerthi, S., Herbert, S., 和 Dhulipalla, S. 学习一个分层监控系统以检测和诊断服务问题。载于第21届 ACM
    SIGKDD 国际知识发现与数据挖掘会议论文集（纽约，NY，USA，2015年），KDD ’15，计算机协会，第2029–2038页。
- en: (22) OpenAI. GPT-4 technical report.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (22) OpenAI. GPT-4 技术报告。
- en: '(23) Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J. BLEU: A method for
    automatic evaluation of machine translation. [https://aclanthology.org/P02-1040.pdf](https://aclanthology.org/P02-1040.pdf),
    2002. Accessed: 2023-9-27.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(23) Papineni, K., Roukos, S., Ward, T., 和 Zhu, W.-J. BLEU: 一种自动评估机器翻译的方法。
    [https://aclanthology.org/P02-1040.pdf](https://aclanthology.org/P02-1040.pdf)，2002年。访问时间：2023-9-27。'
- en: '(24) Reimers, N., and Gurevych, I. Sentence-BERT: Sentence embeddings using
    siamese BERT-Networks.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(24) Reimers, N., 和 Gurevych, I. Sentence-BERT: 使用孪生 BERT 网络的句子嵌入。'
- en: '(25) Robertson, S., and Zaragoza, H. The probabilistic relevance framework:
    BM25 and beyond. Foundations and Trends® in Information Retrieval 3, 4 (2009),
    333–389.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (25) Robertson, S., 和 Zaragoza, H. 概率相关框架：BM25 及其他。信息检索基础与趋势® 3, 4 (2009), 333–389。
- en: (26) Roy, D., Fakhoury, S., and Arnaoudova, V. Reassessing automatic evaluation
    metrics for code summarization tasks. In Proceedings of the 29th ACM Joint Meeting
    on European Software Engineering Conference and Symposium on the Foundations of
    Software Engineering (New York, NY, USA, Aug. 2021), ESEC/FSE 2021, Association
    for Computing Machinery, pp. 1105–1116.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (26) Roy, D., Fakhoury, S., 和 Arnaoudova, V. 重新评估代码总结任务的自动评估指标。载于第29届 ACM 欧洲软件工程会议及软件工程基础研讨会联合会议论文集（纽约，NY，USA，2021年8月），ESEC/FSE
    2021，计算机协会，第1105–1116页。
- en: '(27) Schick, T., Dwivedi-Yu, J., Dessì, R., Raileanu, R., Lomeli, M., Zettlemoyer,
    L., Cancedda, N., and Scialom, T. Toolformer: Language models can teach themselves
    to use tools.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(27) Schick, T., Dwivedi-Yu, J., Dessì, R., Raileanu, R., Lomeli, M., Zettlemoyer,
    L., Cancedda, N., 和 Scialom, T. Toolformer: 语言模型可以自学使用工具。'
- en: '(28) Shetty, M., Bansal, C., Upadhyayula, S. P., Radhakrishna, A., and Gupta,
    A. Autotsg: Learning and synthesis for incident troubleshooting. In Proceedings
    of the 30th ACM Joint European Software Engineering Conference and Symposium on
    the Foundations of Software Engineering (New York, NY, USA, 2022), ESEC/FSE 2022,
    Association for Computing Machinery, p. 1477–1488.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(28) Shetty, M., Bansal, C., Upadhyayula, S. P., Radhakrishna, A., 和 Gupta,
    A. Autotsg: 事件故障排除的学习与综合。发表于第30届 ACM 欧洲联合软件工程大会及软件工程基础研讨会 (纽约，NY，美国，2022年)，ESEC/FSE
    2022，计算机协会，第1477–1488页。'
- en: '(29) Shinn, N. reflexion: Reflexion: Language agents with verbal reinforcement
    learning.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(29) Shinn, N. reflexion: Reflexion: 具有语言强化学习的代理。'
- en: '(30) Shinn, N., Labash, B., and Gopinath, A. Reflexion: an autonomous agent
    with dynamic memory and self-reflection.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(30) Shinn, N., Labash, B., 和 Gopinath, A. Reflexion: 一种具有动态记忆和自我反思的自主代理。'
- en: '(31) Shridhar, M., Yuan, X., Côté, M.-A., Bisk, Y., Trischler, A., and Hausknecht,
    M. ALFWorld: Aligning text and embodied environments for interactive learning.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(31) Shridhar, M., Yuan, X., Côté, M.-A., Bisk, Y., Trischler, A., 和 Hausknecht,
    M. ALFWorld: 对齐文本和具身环境以进行互动学习。'
- en: '(32) Soldani, J., and Brogi, A. Anomaly detection and failure root cause analysis
    in (micro) service-based cloud applications: A survey. ACM Comput. Surv. 55, 3
    (feb 2022).'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (32) Soldani, J., 和 Brogi, A. 异常检测和故障根本原因分析在（微）服务基础的云应用程序中的调查。ACM Comput. Surv.
    55, 3 (2022年2月)。
- en: '(33) Song, C. H., Wu, J., Washington, C., Sadler, B. M., Chao, W.-L., and Su,
    Y. LLM-Planner: Few-Shot grounded planning for embodied agents with large language
    models.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(33) Song, C. H., Wu, J., Washington, C., Sadler, B. M., Chao, W.-L., 和 Su,
    Y. LLM-Planner: 面向具身代理的少样本基础规划与大型语言模型。'
- en: (34) Soualhia, M., and Wuhib, F. Automated traces-based anomaly detection and
    root cause analysis in cloud platforms. In 2022 IEEE International Conference
    on Cloud Engineering (IC2E) (2022), pp. 253–260.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (34) Soualhia, M., 和 Wuhib, F. 基于自动化追踪的异常检测和根本原因分析在云平台中的应用。发表于 2022 IEEE 国际云工程大会
    (IC2E) (2022年)，第253–260页。
- en: (35) Trivedi, H., Balasubramanian, N., Khot, T., and Sabharwal, A. Interleaving
    retrieval with Chain-of-Thought reasoning for Knowledge-Intensive Multi-Step questions.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (35) Trivedi, H., Balasubramanian, N., Khot, T., 和 Sabharwal, A. 将检索与 Chain-of-Thought
    推理交替应用于知识密集型多步骤问题。
- en: (36) Trivedi, H., Balasubramanian, N., Khot, T., and Sabharwal, A. Interleaving
    retrieval with Chain-of-Thought reasoning for Knowledge-Intensive Multi-Step questions.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (36) Trivedi, H., Balasubramanian, N., Khot, T., 和 Sabharwal, A. 将检索与 Chain-of-Thought
    推理交替应用于知识密集型多步骤问题。
- en: (37) Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E., Le, Q., and Zhou,
    D. Chain of thought prompting elicits reasoning in large language models.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (37) Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E., Le, Q., 和 Zhou,
    D. Chain of thought 提示引发大型语言模型的推理。
- en: (38) Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi,
    E., Le, Q., and Zhou, D. Chain-of-thought prompting elicits reasoning in large
    language models. 24824–24837.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (38) Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi,
    E., Le, Q., 和 Zhou, D. Chain-of-thought 提示引发大型语言模型的推理。24824–24837。
- en: '(39) Yao, S., Chen, H., Yang, J., and Narasimhan, K. WebShop: Towards scalable
    real-world web interaction with grounded language agents. 20744–20757.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(39) Yao, S., Chen, H., Yang, J., 和 Narasimhan, K. WebShop: 朝着可扩展的现实世界网页交互与基础语言代理迈进。20744–20757。'
- en: '(40) Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., and Cao,
    Y. ReAct: Synergizing reasoning and acting in language models.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(40) Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., 和 Cao,
    Y. ReAct: 在语言模型中协同推理与行动。'
- en: '(41) Zeng, Z., Zhang, Y., Xu, Y., Ma, M., Qiao, B., Zou, W., Chen, Q., Zhang,
    M., Zhang, X., Zhang, H., Gao, X., Fan, H., Rajmohan, S., Lin, Q., and Zhang,
    D. TraceArk: Towards actionable performance anomaly alerting for online service
    systems. In 2023 IEEE/ACM 45th International Conference on Software Engineering:
    Software Engineering in Practice (ICSE-SEIP) (May 2023), pp. 258–269.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(41) Zeng, Z., Zhang, Y., Xu, Y., Ma, M., Qiao, B., Zou, W., Chen, Q., Zhang,
    M., Zhang, X., Zhang, H., Gao, X., Fan, H., Rajmohan, S., Lin, Q., 和 Zhang, D.
    TraceArk: 朝着可操作的性能异常警报系统迈进。发表于 2023 IEEE/ACM 第45届国际软件工程大会：软件工程实践 (ICSE-SEIP) (2023年5月)，第258–269页。'
- en: '(42) Zhang, T., Kishore, V., Wu, F., Weinberger, K. Q., and others. Bertscore:
    Evaluating text generation with bert. arXiv preprint arXiv (2019).'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(42) Zhang, T., Kishore, V., Wu, F., Weinberger, K. Q., 等人。Bertscore: 用bert评估文本生成。arXiv
    预印本 arXiv (2019)。'
- en: '(43) Zhao, A., Huang, D., Xu, Q., Lin, M., Liu, Y.-J., and Huang, G. ExpeL:
    LLM agents are experiential learners.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(43) Zhao, A., Huang, D., Xu, Q., Lin, M., Liu, Y.-J., 和 Huang, G. ExpeL: LLM
    代理是经验学习者。'
- en: '(44) Zhou, S., Xu, F. F., Zhu, H., Zhou, X., Lo, R., Sridhar, A., Cheng, X.,
    Bisk, Y., Fried, D., Alon, U., and Neubig, G. WebArena: A realistic web environment
    for building autonomous agents.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(44) Zhou, S., Xu, F. F., Zhu, H., Zhou, X., Lo, R., Sridhar, A., Cheng, X.,
    Bisk, Y., Fried, D., Alon, U., 和 Neubig, G. WebArena: 一个用于构建自主代理的现实网络环境。'
