- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:52:12'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:52:12
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific Data Visualization'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MatPlotAgent：基于LLM的代理科学数据可视化的方法与评估
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2402.11453](https://ar5iv.labs.arxiv.org/html/2402.11453)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2402.11453](https://ar5iv.labs.arxiv.org/html/2402.11453)
- en: Zhiyu Yang^(∗2)  Zihan Zhou³  Shuo Wang^(†1)  Xin Cong¹
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Zhiyu Yang^(∗2)  Zihan Zhou³  Shuo Wang^(†1)  Xin Cong¹
- en: Xu Han¹  Yukun Yan¹  Zhenghao Liu⁴  Zhixing Tan⁵
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Xu Han¹  Yukun Yan¹  Zhenghao Liu⁴  Zhixing Tan⁵
- en: Pengyuan Liu²  Dong Yu²  Zhiyuan Liu¹  Xiaodong Shi³ Maosong Sun¹
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Pengyuan Liu²  Dong Yu²  Zhiyuan Liu¹  Xiaodong Shi³ Maosong Sun¹
- en: ¹Tsinghua University  ²Beijing Language and Culture University  ³Xiamen University
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ¹清华大学  ²北京语言文化大学  ³厦门大学
- en: ⁴Northeastern University, China  ⁵Zhongguancun Laboratory, Beijing, China   Equal
    contribution.  Corresponding authors.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ⁴中国东北大学  ⁵中国北京中关村实验室   等贡献。  通讯作者。
- en: Abstract
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Scientific data visualization plays a crucial role in research by enabling
    the direct display of complex information and assisting researchers in identifying
    implicit patterns. Despite its importance, the use of Large Language Models (LLMs)
    for scientific data visualization remains rather unexplored. In this study, we
    introduce MatPlotAgent, an efficient model-agnostic LLM agent framework designed
    to automate scientific data visualization tasks. Leveraging the capabilities of
    both code LLMs and multi-modal LLMs, MatPlotAgent consists of three core modules:
    query understanding, code generation with iterative debugging, and a visual feedback
    mechanism for error correction. To address the lack of benchmarks in this field,
    we present MatPlotBench, a high-quality benchmark consisting of 100 human-verified
    test cases. Additionally, we introduce a scoring approach that utilizes GPT-4V
    for automatic evaluation. Experimental results demonstrate that MatPlotAgent can
    improve the performance of various LLMs, including both commercial and open-source
    models. Furthermore, the proposed evaluation method shows a strong correlation
    with human-annotated scores.¹¹1  MatPlotAgent and MatPlotBench will be publicly
    available at [https://github.com/OpenBMB/MatPlotAgent](https://github.com/OpenBMB/MatPlotAgent).'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 科学数据可视化在研究中起着至关重要的作用，能够直接展示复杂信息并帮助研究人员识别隐含的模式。尽管其重要性显著，但利用大型语言模型（LLMs）进行科学数据可视化仍然相对未被探索。在这项研究中，我们介绍了MatPlotAgent，一个高效的模型无关的LLM代理框架，旨在自动化科学数据可视化任务。MatPlotAgent利用代码LLMs和多模态LLMs的能力，由三个核心模块组成：查询理解、带有迭代调试的代码生成以及用于错误修正的视觉反馈机制。为了弥补这一领域缺乏基准测试的不足，我们提出了MatPlotBench，一个由100个人工验证的测试用例组成的高质量基准。此外，我们还介绍了一种利用GPT-4V进行自动评估的评分方法。实验结果表明，MatPlotAgent可以提升各种LLMs的性能，包括商业和开源模型。此外，提出的评估方法与人工注释的评分表现出强相关性。¹¹1
    MatPlotAgent和MatPlotBench将公开发布于[https://github.com/OpenBMB/MatPlotAgent](https://github.com/OpenBMB/MatPlotAgent)。
- en: '![[Uncaptioned image]](img/62d7386f42d68689cc314d7cfb7f8c44.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![[无标题图片]](img/62d7386f42d68689cc314d7cfb7f8c44.png)'
- en: 'MatPlotAgent: Method and Evaluation for'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: MatPlotAgent：方法与评估
- en: LLM-Based Agentic Scientific Data Visualization
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLM的代理科学数据可视化
- en: 'Zhiyu Yang^(∗2)  Zihan Zhou^†^†thanks:   Equal contribution.³  Shuo Wang^(†1)
     Xin Cong¹ Xu Han¹  Yukun Yan¹  Zhenghao Liu⁴  Zhixing Tan⁵ Pengyuan Liu²  Dong
    Yu²  Zhiyuan Liu^†^†thanks:   Corresponding authors.¹  Xiaodong Shi³ Maosong Sun¹
    ¹Tsinghua University  ²Beijing Language and Culture University  ³Xiamen University
    ⁴Northeastern University, China  ⁵Zhongguancun Laboratory, Beijing, China'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Zhiyu Yang^(∗2)  Zihan Zhou^†^†感谢：   等贡献。³  Shuo Wang^(†1)  Xin Cong¹ Xu Han¹
     Yukun Yan¹  Zhenghao Liu⁴  Zhixing Tan⁵ Pengyuan Liu²  Dong Yu²  Zhiyuan Liu^†^†感谢：
      通讯作者。¹  Xiaodong Shi³ Maosong Sun¹ ¹清华大学  ²北京语言文化大学  ³厦门大学 ⁴中国东北大学  ⁵中国北京中关村实验室
- en: 1 Introduction
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: A picture is worth a thousand words. Data visualization is an essential process
    in scientific research, facilitating the more direct conveyance of complex information
    and aiding researchers in uncovering implicit patterns. There are many advanced
    toolkits, such as Matplotlib²²2[https://matplotlib.org](https://matplotlib.org)
    and Origin³³3[https://www.originlab.com](https://www.originlab.com), that can
    help researchers plot various types of figures for complex data distributions.
    However, transforming raw data into informative and easy-to-understand visualizations
    is still time-consuming and labor-intensive. Before the invention of large language
    models (LLMs) OpenAI ([2023](#bib.bib19)), automating this process with AI models
    is almost impossible.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 一图胜千言。数据可视化是科学研究中的一个重要过程，有助于更直接地传达复杂信息，并帮助研究人员发现隐含的模式。有许多先进的工具包，如 Matplotlib²²2[https://matplotlib.org](https://matplotlib.org)
    和 Origin³³3[https://www.originlab.com](https://www.originlab.com)，可以帮助研究人员绘制各种类型的复杂数据分布图。然而，将原始数据转化为信息丰富且易于理解的可视化图形仍然是一个耗时且劳动密集的过程。在大型语言模型（LLMs）OpenAI
    ([2023](#bib.bib19)) 发明之前，使用 AI 模型自动化这一过程几乎是不可能的。
- en: '![Refer to caption](img/0d0a46b697e2846c7ce1507b05e48d83.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/0d0a46b697e2846c7ce1507b05e48d83.png)'
- en: 'Figure 1: Examples in the proposed MatPlotBench. Given the raw data and user
    queries, the AI agent is expected to generate a figure accordingly. We only display
    partial raw data and user queries due to space limitations.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：提议的 MatPlotBench 中的示例。给定原始数据和用户查询，AI 代理预计会相应地生成一个图表。由于空间限制，我们仅展示部分原始数据和用户查询。
- en: With large-scale parameters and extensive training data, LLMs have demonstrated
    remarkable capabilities in a wide range of complex tasks, including reasoning Wei
    et al. ([2022](#bib.bib33)); Kojima et al. ([2022a](#bib.bib8)); Yao et al. ([2023a](#bib.bib38)),
    mathematics Yu et al. ([2024](#bib.bib40)); Luo et al. ([2023a](#bib.bib16));
    Azerbayev et al. ([2024](#bib.bib2)); Shao et al. ([2024](#bib.bib30)) and coding Rozière
    et al. ([2024](#bib.bib27)); Luo et al. ([2023b](#bib.bib17)); Guo et al. ([2024](#bib.bib7));
    Wei et al. ([2023](#bib.bib34)). This breakthrough has unlocked new opportunities
    for utilizing LLMs as autonomous agents in a diverse range of practical scenarios,
    such as web browsing Nakano et al. ([2021](#bib.bib18)); Yao et al. ([2022](#bib.bib37));
    Qin et al. ([2023](#bib.bib23)); Zhou et al. ([2023](#bib.bib41)); Deng et al.
    ([2023](#bib.bib6)); Yao et al. ([2023b](#bib.bib39)); Xie et al. ([2023](#bib.bib35)),
    social simulations Park et al. ([2023](#bib.bib20)); Xu et al. ([2023](#bib.bib36));
    Chen et al. ([2024a](#bib.bib4)); Wang et al. ([2023](#bib.bib32)), tool utilization Qin
    et al. ([2024](#bib.bib24)); Schick et al. ([2023](#bib.bib29)); Liu et al. ([2024](#bib.bib14));
    Li et al. ([2023a](#bib.bib12)); Lu et al. ([2023](#bib.bib15)); Qian et al. ([2023b](#bib.bib22));
    Shinn et al. ([2023](#bib.bib31)), and software development Qian et al. ([2023a](#bib.bib21)).
    Using LLMs to enhance human productivity in specialized areas is now a key research
    focus with great potential.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大规模参数和广泛的训练数据，LLMs 在推理 Wei et al. ([2022](#bib.bib33)); Kojima et al. ([2022a](#bib.bib8));
    Yao et al. ([2023a](#bib.bib38))、数学 Yu et al. ([2024](#bib.bib40)); Luo et al.
    ([2023a](#bib.bib16)); Azerbayev et al. ([2024](#bib.bib2)); Shao et al. ([2024](#bib.bib30))
    和编码 Rozière et al. ([2024](#bib.bib27)); Luo et al. ([2023b](#bib.bib17)); Guo
    et al. ([2024](#bib.bib7)); Wei et al. ([2023](#bib.bib34)) 等领域展示了显著的能力。这一突破为将
    LLMs 用作多种实际场景中的自主代理打开了新的机会，如网页浏览 Nakano et al. ([2021](#bib.bib18)); Yao et al.
    ([2022](#bib.bib37)); Qin et al. ([2023](#bib.bib23)); Zhou et al. ([2023](#bib.bib41));
    Deng et al. ([2023](#bib.bib6)); Yao et al. ([2023b](#bib.bib39)); Xie et al.
    ([2023](#bib.bib35))、社会模拟 Park et al. ([2023](#bib.bib20)); Xu et al. ([2023](#bib.bib36));
    Chen et al. ([2024a](#bib.bib4)); Wang et al. ([2023](#bib.bib32))、工具使用 Qin et al.
    ([2024](#bib.bib24)); Schick et al. ([2023](#bib.bib29)); Liu et al. ([2024](#bib.bib14));
    Li et al. ([2023a](#bib.bib12)); Lu et al. ([2023](#bib.bib15)); Qian et al. ([2023b](#bib.bib22));
    Shinn et al. ([2023](#bib.bib31)) 和软件开发 Qian et al. ([2023a](#bib.bib21))。利用 LLMs
    提升特定领域的人类生产力现已成为一个具有巨大潜力的关键研究方向。
- en: Recent advancements in LLM-based agents inspire us to explore the utilization
    of LLMs for scientific data visualization, a realm that remains rather unexplored
    in existing studies. A closely related line of research is text-to-image generation Ramesh
    et al. ([2021](#bib.bib25)); Saharia et al. ([2022](#bib.bib28)), where diffusion
    models Rombach et al. ([2022](#bib.bib26)) have shown great potential in generating
    various types of images. However, existing text-to-image generation methods predominantly
    focus on artistic expression, potentially misaligning with the needs of scientific
    data visualization, where clarity and precision in conveying information are the
    most important principles. This work aims to automatically generate figures with
    precise information.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLMs的代理的最新进展激发了我们探索利用LLMs进行科学数据可视化，这一领域在现有研究中仍然较为未开发。一个密切相关的研究方向是文本到图像生成 Ramesh
    et al. ([2021](#bib.bib25))；Saharia et al. ([2022](#bib.bib28))，其中扩散模型 Rombach
    et al. ([2022](#bib.bib26)) 在生成各种类型的图像方面展示了巨大潜力。然而，现有的文本到图像生成方法主要关注艺术表达，可能与科学数据可视化的需求不符，而在科学数据可视化中，传达信息的清晰度和准确性是最重要的原则。本研究旨在自动生成具有精确信息的图形。
- en: 'We propose leveraging modern code LLMs and multi-modal LLMs to develop scientific
    data visualization agents that can significantly enhance human efficiency. The
    resulting MatPlotAgent⁴⁴4This name is in homage to the well-known Matplotlib.
    is comprised of three modules: (1) the query understanding that can thoroughly
    understand user-provided requirements; (2) the code generation module with iterative
    debugging capabilities that use code to precisely preprocess raw data and generate
    figures; and (3) the visual feedback module that possesses visual perceptual abilities
    to find errors in the plotted draft and provide visual feedback to the code generation
    module to rectify the errors. Our method is model-agnostic, which can be driven
    with any code LLMs and multi-modal LLMs. Through experiments, we find MatPlotAgent
    can work with both closed-source LLMs (e.g., GPT-4 OpenAI ([2023](#bib.bib19)))
    and open-source LLMs (e.g., Magicoder Wei et al. ([2023](#bib.bib34))).'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议利用现代代码LLMs和多模态LLMs开发科学数据可视化代理，这可以显著提高人类效率。最终的MatPlotAgent⁴⁴（该名称向知名的Matplotlib致敬）由三个模块组成：（1）能够彻底理解用户提供的需求的查询理解模块；（2）具有迭代调试能力的代码生成模块，该模块使用代码精确预处理原始数据并生成图形；（3）具有视觉感知能力的视觉反馈模块，能够在绘制的草图中发现错误，并向代码生成模块提供视觉反馈以纠正错误。我们的方法是与模型无关的，可以与任何代码LLMs和多模态LLMs配合使用。通过实验，我们发现MatPlotAgent可以与封闭源LLMs（例如，GPT-4
    OpenAI ([2023](#bib.bib19))) 和开源LLMs（例如，Magicoder Wei et al. ([2023](#bib.bib34)))
    一起工作。
- en: Another critical challenge in the field of automatic scientific data visualization
    is the absence of benchmarks for evaluation purposes. To address this issue, we
    introduce a meticulously crafted benchmark called MatPlotBench to quantitatively
    evaluate the approaches involved. Specifically, MatPlotBench contains 100 carefully
    hand-crafted test examples, each of which contains a user query, the corresponding
    input data, and a ground-truth figure verified by human experts. We believe that
    high-quality test sets play a crucial role in driving advancements in the field.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 自动科学数据可视化领域的另一个关键挑战是缺乏用于评估的基准。为了解决这一问题，我们引入了一个精心设计的基准，称为MatPlotBench，用于定量评估相关方法。具体来说，MatPlotBench包含100个精心制作的测试示例，每个示例包含一个用户查询、相应的输入数据和由专家验证的真实图像。我们相信，高质量的测试集在推动该领域进步方面发挥着至关重要的作用。
- en: 'To facilitate automatic quantitative evaluation, we also design a scoring mechanism
    based on GPT-4V OpenAI ([2023](#bib.bib19)), which is one of the strongest multi-modal
    LLMs that can effectively understand text and figures. Specifically, GPT-4V is
    prompted to produce a score between 0 and 100 based on the ground-truth figure
    and the one generated by AI models. Additionally, we conduct human evaluation
    and estimate the correlation coefficient between human-annotated scores and the
    automatically calculated scores. The results reveal a strong correlation between
    the automatic score and the human-annotated score, thus affirming the reliability
    of the scoring mechanism. In summary, our contribution can be listed as follows:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了便于自动定量评估，我们还设计了一种基于 GPT-4V OpenAI ([2023](#bib.bib19)) 的评分机制，GPT-4V 是最强大的多模态
    LLM 之一，能够有效理解文本和图形。具体而言，GPT-4V 被提示根据真实图形和 AI 模型生成的图形之间的差异给出一个 0 到 100 之间的分数。此外，我们进行人工评估，并估计人工标注分数与自动计算分数之间的相关系数。结果显示自动分数与人工标注分数之间有很强的相关性，从而确认了评分机制的可靠性。总之，我们的贡献可以列举如下：
- en: •
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We introduce MatPlotBench to enable automatic quantitative evaluation of AI
    methods designed for scientific data visualization. Through comparison with human
    evaluation, we observe that MatPlotBench can effectively capture the performance
    of AI approaches in this cutting-edge task.
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们介绍了 MatPlotBench，以实现对用于科学数据可视化的 AI 方法的自动定量评估。通过与人工评估的比较，我们观察到 MatPlotBench
    能有效捕捉 AI 方法在这一前沿任务中的表现。
- en: •
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We propose an effective and generalizable LLM agent framework, MatPlotAgent,
    that can improve the performance of a wide range of LLMs based on the newly proposed
    visual feedback mechanism.
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了一个有效且具有广泛适应性的 LLM 智能体框架 MatPlotAgent，该框架可以基于新提出的视觉反馈机制提高各种 LLM 的性能。
- en: 2 Task Description
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 任务描述
- en: 'We first introduce the scientific data visualization task investigated in this
    work. Given a user query $\mathbf{x}$ that can satisfy the user’s demand:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先介绍本研究中调查的科学数据可视化任务。给定一个可以满足用户需求的用户查询 $\mathbf{x}$：
- en: '|  | $V=f(\mathbf{x},\mathcal{D}),$ |  | (1) |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '|  | $V=f(\mathbf{x},\mathcal{D}),$ |  | (1) |'
- en: where $f$ denotes the involved AI system that can be either an LLM or an LLM-based
    agent.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $f$ 表示涉及的 AI 系统，可以是 LLM 或基于 LLM 的智能体。
- en: 'Specifically, $\mathbf{x}$ whether specified by the user or stored in the external
    data file. Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ MatPlotAgent: Method
    and Evaluation for LLM-Based Agentic Scientific Data Visualization") provides
    some examples for this task.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '具体而言，$\mathbf{x}$ 可以是用户指定的，也可以是存储在外部数据文件中的。图 [1](#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific Data Visualization")
    提供了该任务的一些示例。'
- en: 3 MatPlotBench
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 MatPlotBench
- en: 'Automatic evaluation is important in AI tasks as it enables researchers to
    efficiently assess the performance of various methods, thereby guiding the development
    of the field. While the DS-1000 benchmark Lai et al. ([2023](#bib.bib11)) includes
    coding problems about Matplotlib, the solutions’ average length is merely three
    lines, rendering them too simplistic to gauge the proficiency of contemporary
    AI agents in tackling practical challenges. Therefore, we propose to construct
    MatPlotBench with complex data visualization problems that are more close to real-world
    scenarios. We will illustrate the data collection process in Section [3.1](#S3.SS1
    "3.1 Data Collection ‣ 3 MatPlotBench ‣ MatPlotAgent: Method and Evaluation for
    LLM-Based Agentic Scientific Data Visualization") and then explain the scoring
    mechanism in Section [3.2](#S3.SS2 "3.2 Automatic Quantitative Evaluation ‣ 3
    MatPlotBench ‣ MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific
    Data Visualization").'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '自动评估在 AI 任务中非常重要，因为它使研究人员能够高效地评估各种方法的性能，从而指导该领域的发展。尽管 DS-1000 基准 Lai 等 ([2023](#bib.bib11))
    包含有关 Matplotlib 的编码问题，但解决方案的平均长度仅为三行，过于简化，无法评估当代 AI 智能体在应对实际挑战中的能力。因此，我们建议构建 MatPlotBench，涵盖更接近现实世界场景的复杂数据可视化问题。我们将在第
    [3.1](#S3.SS1 "3.1 Data Collection ‣ 3 MatPlotBench ‣ MatPlotAgent: Method and
    Evaluation for LLM-Based Agentic Scientific Data Visualization") 节中说明数据收集过程，并在第
    [3.2](#S3.SS2 "3.2 Automatic Quantitative Evaluation ‣ 3 MatPlotBench ‣ MatPlotAgent:
    Method and Evaluation for LLM-Based Agentic Scientific Data Visualization") 节中解释评分机制。'
- en: 3.1 Data Collection
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 数据收集
- en: Principles
  id: totrans-38
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 原则
- en: 'To enhance the quality of MatPlotBench, we adhere to the following principles
    for data collection: (1) Covering diverse types: encompassing a broad range of
    plot types, including not only the most commonly used but also rare but useful
    ones; (2) Containing representative instances: ensuring that the test examples
    reflect the representative features of scientific data visualization, such as
    varying data complexity; and (3) Balancing easy and challenging problems: including
    problems of varying levels of difficulty in the benchmark.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高MatPlotBench的质量，我们在数据收集时遵循以下原则：（1）涵盖多种类型：包括各种图形类型，不仅包括最常用的，还包括稀有但有用的；（2）包含代表性实例：确保测试示例能够反映科学数据可视化的代表性特征，如数据复杂性；（3）平衡简单和挑战性问题：在基准中包含不同难度级别的问题。
- en: Selecting Original Examples
  id: totrans-40
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 选择原始示例
- en: In accordance with the principles outlined above, we first select some original
    examples from reputable online scientific data visualization forums. These examples
    are carefully selected from the Matplotlib Gallery and OriginLab GraphGallery,
    encompassing diverse and representative instances with varying levels of difficulty.
    Specifically, we select 1 or 2 examples from every section in the Matplotlib Gallery,
    covering bars, lines, markers, pie charts, polar plots, contour plots, statistics
    plots, 3D plots, text annotations, radar charts, shapes, scales, axes, spines,
    subplots, and so on. We also seek more advanced test examples from the OriginLab
    GraphGallery, focusing on those that are more aesthetically appealing or complex,
    such as Sankey diagrams, sunburst charts, radial plots, chord diagrams, streamplots,
    and others. Finally, 75 original examples come from the Matplotlib Gallery and
    the 25 other original examples come from the OriginLab GraphGallery. Subsequently,
    these examples undergo several modifications to become the final test cases in
    MatPlotBench.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 根据上述原则，我们首先从信誉良好的在线科学数据可视化论坛中选择一些原始示例。这些示例从Matplotlib Gallery和OriginLab GraphGallery中精心挑选，涵盖了各种代表性实例，难度层次不一。具体而言，我们从Matplotlib
    Gallery的每个部分中选择1到2个示例，包括条形图、折线图、标记图、饼图、极坐标图、等高线图、统计图、3D图、文本注释、雷达图、形状、刻度、坐标轴、脊柱、子图等。同时，我们还从OriginLab
    GraphGallery中寻找更高级的测试示例，重点关注那些更具美学吸引力或复杂性的示例，如桑基图、旭日图、径向图、和弦图、流图等。最终，75个原始示例来自Matplotlib
    Gallery，另外25个原始示例来自OriginLab GraphGallery。随后，这些示例经过几次修改，成为MatPlotBench中的最终测试用例。
- en: Preliminary Query Generation
  id: totrans-42
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 初步查询生成
- en: Based on the selected original examples, we use LLMs to generate preliminary
    queries, which are then revised by humans. For original examples from the Matplotlib
    Gallery, we use GPT-4 to convert the code in each original example into preliminary
    queries. For the examples from the OriginLab GraphGallery, there are only images.
    We thus use GPT-4V to convert each image into a preliminary query.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 基于选择的原始示例，我们使用LLMs生成初步查询，然后由人工修订。对于来自Matplotlib Gallery的原始示例，我们使用GPT-4将每个原始示例中的代码转换为初步查询。对于来自OriginLab
    GraphGallery的示例，则只有图像。因此，我们使用GPT-4V将每张图像转换为初步查询。
- en: Data Replacement
  id: totrans-44
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据替换
- en: Based on these preliminary queries, we begin data replacement for examples from
    the Matplotlib Gallery due to the observed phenomenon of memorization by GPT-4\.
    In this process, we replace the original data points with newly generated ones,
    while keeping other factors such as the plot type unchanged. For examples from
    OriginLab, we find that the data is inherently complex, and even GPT-4 does not
    exhibit memorization with these examples. As a result, we only perform data replacement
    for Matplotlib examples.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这些初步查询，我们开始对Matplotlib Gallery的示例进行数据替换，因为观察到GPT-4具有记忆现象。在这个过程中，我们将原始数据点替换为新生成的数据点，同时保持其他因素，如图形类型不变。对于OriginLab的示例，我们发现数据本身复杂，即使GPT-4也未表现出记忆现象。因此，我们仅对Matplotlib示例进行数据替换。
- en: Human Modification
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 人工修改
- en: After completing the data replacement process, we engage human annotators to
    refine the preliminary queries. These annotators are tasked with correcting errors,
    eliminating ambiguity, and adding any omitted essential information. Each annotator
    involved has a minimum of three years of experience in coding and NLP. Furthermore,
    each query undergoes refinement by two independent human annotators.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 完成数据替换过程后，我们请人工标注员细化初步查询。这些标注员负责纠正错误、消除模糊性并添加任何遗漏的必要信息。每位参与的标注员至少有三年的编码和NLP经验。此外，每个查询由两名独立的人工标注员进行细化。
- en: Updating Ground-Truth Figures
  id: totrans-48
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 更新基准图像
- en: After obtaining the human-annotated queries, as the data in Matplotlib examples
    are altered, we cannot directly use the images in the original example as the
    ground truth. To this end, we manually wrote code to plot the ground truth for
    the Matplotlib examples. For examples from OriginLab, as the data remains unaltered,
    we extract the images from their website to serve as the ground truth.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在获得人工标注的查询后，由于Matplotlib示例中的数据已被更改，我们不能直接使用原始示例中的图像作为基准。因此，我们手动编写代码绘制Matplotlib示例的基准图像。对于OriginLab的示例，由于数据未被更改，我们从其网站提取图像作为基准。
- en: Human Verification
  id: totrans-50
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 人工验证
- en: After obtaining the queries and their corresponding ground truths, we performed
    a final round of manual verification. Three NLP researchers were asked to conduct
    this verification. In this turn, the focus is mainly on checking whether the user
    queries and the ground truths are well aligned. The researchers meticulously checked
    each element in the ground truth image and looked for their corresponding descriptions
    in the user query. Ill-described elements and those missing clarifications are
    corrected. Redundant and incorrect descriptions are removed. This process results
    in 100 high-quality (query, raw data, ground-truth figure) triples, which comprise
    our final benchmark.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在获得查询及其对应的基准真相后，我们进行了最终的手动验证。三名NLP研究人员被要求进行此验证。在这一轮中，重点主要是检查用户查询与基准真相是否对齐。研究人员仔细检查了基准图像中的每个元素，并寻找它们在用户查询中的对应描述。不清楚的元素和缺少说明的元素被纠正。多余和错误的描述被删除。这个过程产生了100个高质量的（查询，原始数据，基准图像）三元组，这些三元组构成了我们的最终基准。
- en: 3.2 Automatic Quantitative Evaluation
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 自动定量评估
- en: 'To ease the burden of manual evaluation and broaden the applicability of our
    benchmark for research purposes, we suggest employing GPT-4V, a cutting-edge multi-modal
    LLM, to conduct automatic evaluations on our proposed benchmark. We carefully
    prompt GPT-4V to give a score from 0 to 100 on model-generated visualizations
    using the corresponding ground truths as the reference. The prompt is shown in
    Figure [6](#A1.F6 "Figure 6 ‣ A.1 Evaluation Prompts ‣ Appendix A Detailed Prompts
    ‣ MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific Data Visualization")
    in Appendix.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减轻手动评估的负担，并扩大我们基准在研究中的适用性，我们建议使用前沿的多模态LLM GPT-4V来对我们提出的基准进行自动评估。我们仔细提示GPT-4V对模型生成的可视化图形进行0到100的评分，以对应的基准真相作为参考。提示见附录中的图[6](#A1.F6
    "图6 ‣ A.1 评估提示 ‣ 附录A 详细提示 ‣ MatPlotAgent：基于LLM的科学数据可视化方法与评估")。
- en: Correlation with Human Evaluation
  id: totrans-54
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 与人工评估的相关性
- en: To assess the reliability of GPT-4V as an automatic evaluator for scientific
    visualizations, we calculate the correlation between the automatic scores and
    human-evaluated scores. Specifically, we employ GPT-3.5 and GPT-4 to generate
    figures on MatPlotBench, and then conduct both automatic and human evaluation
    for the generated figures. For each model, we iteratively sample a subset that
    consists of $n$ are set to 25 and 100, respectively.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 为评估GPT-4V作为科学可视化自动评估工具的可靠性，我们计算了自动评分与人工评分之间的相关性。具体而言，我们使用GPT-3.5和GPT-4在MatPlotBench上生成图形，然后对生成的图形进行自动评估和人工评估。对于每个模型，我们迭代地抽取一个子集，其中$n$分别设置为25和100。
- en: '![Refer to caption](img/ded1c9e7ff21d1787f8ffc8a33974b91.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ded1c9e7ff21d1787f8ffc8a33974b91.png)'
- en: 'Figure 2: Correlation between the proposed automatic evaluation mechanism and
    human evaluation.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：所提出的自动评估机制与人工评估之间的相关性。
- en: We utilize the statistical functions provided by scipy⁵⁵5[https://docs.scipy.org/doc/scipy/reference/stats.html](https://docs.scipy.org/doc/scipy/reference/stats.html)
    to compute the Pearson correlation coefficient $r$0.05, we conclude that the automatic
    evaluation scores are strongly correlated with human evaluation results. This
    demonstrates the reliability of the proposed scoring mechanism in assessing the
    quality of model-generated figures on MatPlotBench.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们利用`scipy⁵⁵5[https://docs.scipy.org/doc/scipy/reference/stats.html](https://docs.scipy.org/doc/scipy/reference/stats.html)`提供的统计函数来计算皮尔逊相关系数$r$0.05，得出自动评估分数与人工评估结果之间存在强相关性。这证明了所提评分机制在评估MatPlotBench生成的图形质量方面的可靠性。
- en: 4 MatPlotAgent
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 MatPlotAgent
- en: '![Refer to caption](img/295b7e302a0ee30943de7d5ac8d66b1f.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/295b7e302a0ee30943de7d5ac8d66b1f.png)'
- en: 'Figure 3: Workflow of MatPlotAgent: The query expansion module converts the
    user query into detailed multi-step instructions. These instructions are then
    passed to the code agent, which generates the plotting code. The visual agent
    provides informative feedback based on the current draft, guiding the refinement
    of the figure.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '图3: MatPlotAgent的工作流程：查询扩展模块将用户查询转换为详细的多步骤指令。这些指令随后传递给代码生成器，代码生成器生成绘图代码。视觉代理根据当前草稿提供有用的反馈，指导图形的完善。'
- en: 'To improve the capabilities of LLMs for scientific data visualization, we propose
    an agentic framework that mimics the plotting process of human experts. The proposed
    MatPlotAgent is comprised of three modules, including the query expansion module,
    the code agent, and the visual agent. Figure [3](#S4.F3 "Figure 3 ‣ 4 MatPlotAgent
    ‣ MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific Data Visualization")
    illustrates the workflow of MatPlotAgent.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '为了提高LLMs在科学数据可视化方面的能力，我们提出了一个模仿人类专家绘图过程的代理框架。所提出的MatPlotAgent由包括查询扩展模块、代码生成器和视觉代理在内的三个模块组成。图[3](#S4.F3
    "Figure 3 ‣ 4 MatPlotAgent ‣ MatPlotAgent: Method and Evaluation for LLM-Based
    Agentic Scientific Data Visualization")展示了MatPlotAgent的工作流程。'
- en: 4.1 Query Expansion
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 查询扩展
- en: The query expansion module interprets and refines the user query, converting
    the high-level requirements into a sequence of explicit and detailed instructions
    that are easy for LLMs to follow. This module can also be viewed as a planning
    module, creating an overall plan before generating the figure. Specifically, this
    module is based on the involved code LLM, which is prompted to give detailed instructions
    on how to use code to fulfill the requirement specified by the user, including
    what libraries to import, what library functions to call, how to set the parameters
    in each function correctly, how to prepare the data, how to manipulate the data,
    and so on.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 查询扩展模块解释和细化用户查询，将高级需求转换为一系列明确且详细的指令，使LLMs易于遵循。该模块还可以被视为一个规划模块，在生成图形之前制定总体计划。具体来说，该模块基于相关代码LLM，提示其详细说明如何使用代码来满足用户指定的需求，包括导入哪些库、调用哪些库函数、如何正确设置每个函数中的参数、如何准备数据、如何操作数据等。
- en: 4.2 Code Agent
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 代码生成器
- en: The code agent is the core component in MatPlotAgent, responsible for generating
    the code to plot figures. Given detailed instructions from the query expansion
    module, the code agent first generates the code using appropriate libraries and
    functions. To improve the success rate of the generated code, we also employ the
    self-debugging mechanism Chen et al. ([2024b](#bib.bib5)), which helps the involved
    code LLM iteratively identify and correct bugs in the code. To prevent an infinite
    loop, we set the maximum iterations of self-debugging to 3.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 代码生成器是MatPlotAgent的核心组件，负责生成绘图代码。在查询扩展模块提供详细指令后，代码生成器首先使用适当的库和函数生成代码。为了提高生成代码的成功率，我们还采用了自我调试机制
    Chen et al. ([2024b](#bib.bib5))，该机制帮助相关代码LLM迭代识别和修正代码中的错误。为了防止无限循环，我们将自我调试的最大迭代次数设置为3次。
- en: 'Similar to humans, who need to repeatedly refine the figure based on current
    drafts, we also introduce a visual feedback mechanism. This mechanism employs
    multi-modal LLMs to provide suggestions to improve the figure and better fulfill
    the user’s queries. These suggestions, which we call visual feedback, are then
    provided to the code agent to further improve the code. Our experiments in Section [5.2](#S5.SS2
    "5.2 Main Results ‣ 5 Experiments ‣ MatPlotAgent: Method and Evaluation for LLM-Based
    Agentic Scientific Data Visualization") demonstrate that MatPlotAgent is compatible
    with several modern code LLMs, including both some well-known closed-source models
    and some open-source models.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '类似于人类需要根据当前草稿反复完善图形，我们也引入了视觉反馈机制。该机制利用多模态LLMs提供建议，以改进图形并更好地满足用户查询。这些建议，我们称之为视觉反馈，然后提供给代码代理，以进一步改进代码。我们在第[5.2](#S5.SS2
    "5.2 Main Results ‣ 5 Experiments ‣ MatPlotAgent: Method and Evaluation for LLM-Based
    Agentic Scientific Data Visualization")节的实验表明，MatPlotAgent与几种现代代码LLMs兼容，包括一些知名的闭源模型和一些开源模型。'
- en: '| Model | Direct | Zero-Shot | MatPlotAgent |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 直接 | 零-shot | MatPlotAgent |'
- en: '| Decod. | CoT |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 解码 | CoT |'
- en: '| GPT-4 | 48.86 | 45.42 | $-$12.30 |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | 48.86 | 45.42 | $-$12.30 |'
- en: '| GPT-3.5 | 38.03 | 37.14 | $-$9.48 |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 | 38.03 | 37.14 | $-$9.48 |'
- en: '| Magicoder-S-DS-6.7B Wei et al. ([2023](#bib.bib34)) | 38.49 | 37.95 | $-$13.21
    |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| Magicoder-S-DS-6.7B Wei et al. ([2023](#bib.bib34)) | 38.49 | 37.95 | $-$13.21
    |'
- en: '| Deepseek-coder-6.7B-instruct Guo et al. ([2024](#bib.bib7)) | 31.53 | 29.16
    | $-$7.92 |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| Deepseek-coder-6.7B-instruct Guo et al. ([2024](#bib.bib7)) | 31.53 | 29.16
    | $-$7.92 |'
- en: '| CodeLlama-34B-Instruct Rozière et al. ([2024](#bib.bib27)) | 16.54 | 12.40
    | $-$2.36 |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| CodeLlama-34B-Instruct Rozière et al. ([2024](#bib.bib27)) | 16.54 | 12.40
    | $-$2.36 |'
- en: '| Deepseek-coder-33B-instruct Guo et al. ([2024](#bib.bib7)) | 30.88 | 36.10
    | $+$1.30 |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| Deepseek-coder-33B-instruct Guo et al. ([2024](#bib.bib7)) | 30.88 | 36.10
    | $+$1.30 |'
- en: '| WizardCoder-Python-33B-V1.1 Luo et al. ([2023b](#bib.bib17)) | 36.94 | 35.81
    | $-$9.02 |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| WizardCoder-Python-33B-V1.1 Luo et al. ([2023b](#bib.bib17)) | 36.94 | 35.81
    | $-$9.02 |'
- en: 'Table 1: Performance of different LLMs on MatPlotBench. For each model, improvements
    over the direct decoding are highlighted in red, while results worse than that
    of the direct decoding are highlighted in blue.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：不同LLMs在MatPlotBench上的表现。对于每个模型，相较于直接解码的改进用红色突出显示，而比直接解码结果差的结果用蓝色突出显示。
- en: 4.3 Visual Agent
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 视觉代理
- en: The major difference between MatPlotAgent and previous LLM-based coding agents Qian
    et al. ([2023a](#bib.bib21)); Chen et al. ([2024b](#bib.bib5)) is that we take
    the visual signal into account, which is important in scientific data visualization.
    Some errors or weaknesses may be difficult to identify in the code but become
    apparent when observing the output figure through “eyes”. The visual agent is
    the “eyes” for MatPlotAgent, while the aforementioned code agent acts as the “hands”
    for MatPlotAgent.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: MatPlotAgent与之前基于LLM的编码代理Qian et al. ([2023a](#bib.bib21)); Chen et al. ([2024b](#bib.bib5))的主要区别在于我们考虑了视觉信号，这在科学数据可视化中很重要。在代码中一些错误或弱点可能很难识别，但通过“眼睛”观察输出图形时变得明显。视觉代理是MatPlotAgent的“眼睛”，而上述代码代理则作为MatPlotAgent的“手”。
- en: 'Specifically, the visual agent is powered by multi-modal LLMs. In our experiments,
    we utilize GPT-4V OpenAI ([2023](#bib.bib19)) to drive this agent. We introduce
    several guiding principles for the visual agent, including verifying whether the
    figure aligns with the provided data, and enhancing the colors or labels to improve
    the figure’s informativeness. Based on the principles, the user query, and the
    current draft of the figure, the visual agent generates some suggestions to refine
    to figure. These suggestions serve as feedback for the code agent to refine the
    code. Experimental results in Section [5.3](#S5.SS3 "5.3 Ablation Study ‣ 5 Experiments
    ‣ MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific Data Visualization")
    show that our visual feedback mechanism can significantly improve the quality
    of the plotted figures, demonstrating the effectiveness of the proposed visual
    feedback mechanism.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '具体而言，视觉代理由多模态LLMs提供支持。在我们的实验中，我们利用GPT-4V OpenAI ([2023](#bib.bib19))来驱动该代理。我们为视觉代理引入了几个指导原则，包括验证图形是否与提供的数据一致，以及增强颜色或标签以提高图形的信息性。根据这些原则、用户查询和图形的当前草稿，视觉代理生成一些建议以完善图形。这些建议作为反馈提供给代码代理，以改进代码。第[5.3](#S5.SS3
    "5.3 Ablation Study ‣ 5 Experiments ‣ MatPlotAgent: Method and Evaluation for
    LLM-Based Agentic Scientific Data Visualization")节的实验结果表明，我们的视觉反馈机制可以显著提高绘图质量，展示了提出的视觉反馈机制的有效性。'
- en: 5 Experiments
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 实验
- en: 5.1 Setup
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 设置
- en: Models
  id: totrans-83
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模型
- en: Since the proposed MatPlotAgent is model-agnostic, we can employ various LLMs
    in this framework. The code LLMs we use in our experiments include GPT-4, GPT-3.5,
    Magicoder-S-DS-6.7B Wei et al. ([2023](#bib.bib34)), Deepseek-coder-6.7B-instruct Guo
    et al. ([2024](#bib.bib7)), Deepseek-coder-33B-instruct Guo et al. ([2024](#bib.bib7)),
    WizardCoder-Python-33B-V1.1 Luo et al. ([2023b](#bib.bib17)), and CodeLlama-34B-Instruct Rozière
    et al. ([2024](#bib.bib27)). The decoding temperature is set to 0.0 for all the
    involved code LLMs. For GPT-4 and GPT-3.5, we use the API provided by OpenAI⁶⁶6[https://openai.com/product](https://openai.com/product).
    For the other five open-source LLMs, we use vLLM Kwon et al. ([2023](#bib.bib10))
    for model inference. For the visual agent, we utilize GPT-4V OpenAI ([2023](#bib.bib19)),
    a state-of-the-art multi-modal LLM. We leave the exploration of using open-source
    multi-modal LLMs to power the visual agent for future work.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 由于提议的MatPlotAgent是模型无关的，我们可以在此框架中使用各种LLM。我们在实验中使用的代码LLM包括GPT-4、GPT-3.5、Magicoder-S-DS-6.7B
    Wei等([2023](#bib.bib34))、Deepseek-coder-6.7B-instruct Guo等([2024](#bib.bib7))、Deepseek-coder-33B-instruct
    Guo等([2024](#bib.bib7))、WizardCoder-Python-33B-V1.1 Luo等([2023b](#bib.bib17))和CodeLlama-34B-Instruct
    Rozière等([2024](#bib.bib27))。所有涉及的代码LLM的解码温度均设置为0.0。对于GPT-4和GPT-3.5，我们使用OpenAI提供的API[https://openai.com/product](https://openai.com/product)。对于其他五个开源LLM，我们使用vLLM
    Kwon等([2023](#bib.bib10))进行模型推理。对于视觉代理，我们利用GPT-4V OpenAI ([2023](#bib.bib19))，一个最先进的多模态LLM。我们将探索使用开源多模态LLM来驱动视觉代理的工作留待未来。
- en: Evaluation
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 评估
- en: 'We evaluate the involved methods on MatPlotBench, using the proposed automatic
    scoring mechanism that is shown reliable in Section [3.2](#S3.SS2 "3.2 Automatic
    Quantitative Evaluation ‣ 3 MatPlotBench ‣ MatPlotAgent: Method and Evaluation
    for LLM-Based Agentic Scientific Data Visualization"). For each code LLM, we evaluate
    its performance in three ways:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在MatPlotBench上评估了相关方法，使用了在第[3.2](#S3.SS2 "3.2 Automatic Quantitative Evaluation
    ‣ 3 MatPlotBench ‣ MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific
    Data Visualization")节中展示的可靠自动评分机制。对于每个代码LLM，我们从三个方面评估其性能：'
- en: •
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Direct decoding: given the query, the model directly generates the plotting
    code.'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 直接解码：给定查询，模型直接生成绘图代码。
- en: •
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Zero-Shot Chain-of-thought Kojima et al. ([2022b](#bib.bib9)): the model is
    prompted to inference with the zero-shot CoT mechanism.'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Zero-Shot Chain-of-thought Kojima等([2022b](#bib.bib9))：模型被提示使用零-shot CoT机制进行推理。
- en: •
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'MatPlotAgent: the model is equipped with the proposed MatPlotAgent framework,
    driving the query expansion module and the code agent, as illustrated in Section [4](#S4
    "4 MatPlotAgent ‣ MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific
    Data Visualization").'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'MatPlotAgent：该模型配备了提议的MatPlotAgent框架，驱动查询扩展模块和代码代理，如第[4](#S4 "4 MatPlotAgent
    ‣ MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific Data Visualization")节所示。'
- en: 5.2 Main Results
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 主要结果
- en: 'Table [1](#S4.T1 "Table 1 ‣ 4.2 Code Agent ‣ 4 MatPlotAgent ‣ MatPlotAgent:
    Method and Evaluation for LLM-Based Agentic Scientific Data Visualization") presents
    the results of different methods on the scientific data visualization task. In
    the direct decoding setting, GPT-4 achieves the highest score of 48.86\. Surprisingly,
    the open-source model Magicoder-S-DS-6.7B Wei et al. ([2023](#bib.bib34)) achieves
    the second-best performance, surpassing models with substantially larger parameter
    sizes, such as WizardCoder-Python-33B-V1.1.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '表[1](#S4.T1 "Table 1 ‣ 4.2 Code Agent ‣ 4 MatPlotAgent ‣ MatPlotAgent: Method
    and Evaluation for LLM-Based Agentic Scientific Data Visualization")展示了在科学数据可视化任务中不同方法的结果。在直接解码设置中，GPT-4获得了最高分48.86。令人惊讶的是，开源模型Magicoder-S-DS-6.7B
    Wei等([2023](#bib.bib34))取得了第二好的表现，超越了参数规模明显更大的模型，如WizardCoder-Python-33B-V1.1。'
- en: The results also suggest that the zero-shot CoT mechanism does not effectively
    enhance the performance of many recent code LLMs. Zero-shot CoT only improves
    the results of Deepseek-coder-33B-instruct Guo et al. ([2024](#bib.bib7)) from
    30.88 to 36.10\. Conversely, for other models, implementing zero-shot CoT results
    in poorer performance. For example, when zero-shot CoT is applied, the performance
    of GPT-4 drops to 45.42, which is lower than the direct decoding result of 48.86.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 结果还表明，零-shot CoT机制并未有效提升许多最近代码LLM的性能。零-shot CoT仅将Deepseek-coder-33B-instruct
    Guo等([2024](#bib.bib7))的结果从30.88提升至36.10。相反，对于其他模型，应用零-shot CoT导致性能更差。例如，当应用零-shot
    CoT时，GPT-4的性能降至45.42，低于直接解码结果48.86。
- en: 'From Table [1](#S4.T1 "Table 1 ‣ 4.2 Code Agent ‣ 4 MatPlotAgent ‣ MatPlotAgent:
    Method and Evaluation for LLM-Based Agentic Scientific Data Visualization"), we
    find the proposed MatPlotAgent can improve the plotting capabilities of several
    models. For GPT-4 and GPT-3.5, MatPlotAgent leads to significant improvements
    of 12.30 and 9.48, respectively. For the other five open-source LLMs, MatPlotAgent
    improves the performance of four models. With MatPlotAgent, the open-source Magicoder-S-DS-6.7B
    model even surpasses GPT-4 with direct decoding (51.70 vs. 48.86), showcasing
    the effectiveness of our method. In the following experiments, we will perform
    ablation studies to investigate the effects of different components in MatPlotAgent,
    and provide some plotting examples to better interpret the quantitative results.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 从表 [1](#S4.T1 "表 1 ‣ 4.2 代码代理 ‣ 4 MatPlotAgent ‣ MatPlotAgent：基于 LLM 的代理科学数据可视化的方法与评估")
    中，我们发现所提出的 MatPlotAgent 可以提高多个模型的绘图能力。对于 GPT-4 和 GPT-3.5，MatPlotAgent 分别带来了 12.30
    和 9.48 的显著改善。对于其他五个开源 LLM，MatPlotAgent 改善了四个模型的性能。使用 MatPlotAgent，开源 Magicoder-S-DS-6.7B
    模型甚至在直接解码上超越了 GPT-4 (51.70 vs. 48.86)，展示了我们方法的有效性。在接下来的实验中，我们将进行消融研究，以调查 MatPlotAgent
    中不同组件的效果，并提供一些绘图示例以更好地解释定量结果。
- en: '![Refer to caption](img/37cbd00f8bfdd4aeecbee76fe0b9b648.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/37cbd00f8bfdd4aeecbee76fe0b9b648.png)'
- en: 'Figure 4: Examples to illustrate the effect of visual feedback. To investigate
    the effect of the visual feedback mechanism on different models, we display the
    outputs of two representative LLMs. Case A, B, and C are generated by GPT-4\.
    Case D is generated by Magicoder-S-DS-6.7B.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：展示视觉反馈效果的示例。为了调查视觉反馈机制对不同模型的影响，我们展示了两个代表性 LLM 的输出。案例 A、B 和 C 由 GPT-4 生成。案例
    D 由 Magicoder-S-DS-6.7B 生成。
- en: 5.3 Ablation Study
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 消融研究
- en: Compared to previous LLM-based coding agents Qian et al. ([2023a](#bib.bib21));
    Chen et al. ([2024b](#bib.bib5)), the major contribution of the work lies in the
    newly proposed visual feedback mechanism, expected to leverage visual signals
    to enhance the quality of the output figure. To gain a deeper understanding of
    the impact of the visual feedback mechanism, we conduct both qualitative and quantitative
    analyses in this section.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的基于 LLM 的编码代理 Qian 等人 ([2023a](#bib.bib21)); Chen 等人 ([2024b](#bib.bib5))
    相比，本工作的主要贡献在于新提出的视觉反馈机制，预计通过利用视觉信号来提高输出图形的质量。为了更深入地理解视觉反馈机制的影响，我们在本节中进行了定性和定量分析。
- en: 'Figure [4](#S5.F4 "Figure 4 ‣ 5.2 Main Results ‣ 5 Experiments ‣ MatPlotAgent:
    Method and Evaluation for LLM-Based Agentic Scientific Data Visualization") presents
    examples plotted by LLMs both with and without the visual feedback mechanism.
    We observe a clear improvement in the quality of the output figure with the visual
    feedback. For example, in case C, the text in the figure is jumbled, but this
    issue is resolved with the assistance of visual feedback. It is important to note
    that the visual agent does not reference the ground-truth figure when generating
    feedback; it only examines the draft plotted by the model. Table [2](#S5.T2 "Table
    2 ‣ 5.3 Ablation Study ‣ 5 Experiments ‣ MatPlotAgent: Method and Evaluation for
    LLM-Based Agentic Scientific Data Visualization") also presents quantitative results
    of the visual feedback mechanism, indicating that the absence of visual feedback
    would result in significantly poorer outcomes for both GPT-4 and GPT-3.5\. This
    reaffirms the importance of visual signals in the task of scientific data visualization.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [4](#S5.F4 "图 4 ‣ 5.2 主要结果 ‣ 5 实验 ‣ MatPlotAgent：基于 LLM 的代理科学数据可视化的方法与评估")
    展示了带有和不带有视觉反馈机制的 LLM 绘制的示例。我们观察到，视觉反馈显著提高了输出图形的质量。例如，在案例 C 中，图形中的文本混乱，但有了视觉反馈的帮助，这个问题得到了解决。需要注意的是，视觉代理在生成反馈时并不参考真实图形，它仅检查模型绘制的草稿。表 [2](#S5.T2
    "表 2 ‣ 5.3 消融研究 ‣ 5 实验 ‣ MatPlotAgent：基于 LLM 的代理科学数据可视化的方法与评估") 还展示了视觉反馈机制的定量结果，表明缺少视觉反馈会导致
    GPT-4 和 GPT-3.5 的结果显著较差。这进一步证实了视觉信号在科学数据可视化任务中的重要性。
- en: '| Model | GPT-4 | GPT-3.5 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | GPT-4 | GPT-3.5 |'
- en: '| Direct Decod. | 48.86 | 38.03 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 直接解码 | 48.86 | 38.03 |'
- en: '| MatPlotAgent | 61.16 | 47.51 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| MatPlotAgent | 61.16 | 47.51 |'
- en: '| w/o Visual Feedback | 53.44 | 41.57 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 无视觉反馈 | 53.44 | 41.57 |'
- en: 'Table 2: Effect of the visual feedback mechanism.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：视觉反馈机制的效果。
- en: 5.4 Case Study
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 案例研究
- en: '![Refer to caption](img/6ca4ef353032efd1c549be88ab5bf0a0.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/6ca4ef353032efd1c549be88ab5bf0a0.png)'
- en: 'Figure 5: Case study of different models.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：不同模型的案例研究。
- en: 'We present output figures in Figure [5](#S5.F5 "Figure 5 ‣ 5.4 Case Study ‣
    5 Experiments ‣ MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific
    Data Visualization"). The first example is relatively simple, correctly plotted
    by GPT-4 augmented with MatPlotAgent. The second example is more challenging;
    while GPT-4 and Magicoder-S-DS-6.7B can generate a draft, both omit some elements.
    The third example is the most difficult, where none of the three models can produce
    the correct result. These results indicate that the proposed MatPlotBench poses
    a significant challenge for current LLMs. Even the state-of-the-art LLM, GPT-4,
    equipped with MatPlotAgent, fails in some cases. We believe this benchmark will
    be effective not only for evaluating AI systems in scientific data visualization
    but also for assessing general capabilities such as coding and visual perception.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在图表[5](#S5.F5 "Figure 5 ‣ 5.4 Case Study ‣ 5 Experiments ‣ MatPlotAgent:
    Method and Evaluation for LLM-Based Agentic Scientific Data Visualization")中展示了输出图形。第一个例子相对简单，由增强版MatPlotAgent的GPT-4正确绘制。第二个例子较具挑战性；虽然GPT-4和Magicoder-S-DS-6.7B能够生成草稿，但都遗漏了一些元素。第三个例子最为困难，三种模型都无法产生正确结果。这些结果表明，所提出的MatPlotBench对当前的LLMs构成了重大挑战。即使是最先进的LLM，配备MatPlotAgent的GPT-4，在某些情况下也会失败。我们相信这一基准不仅对于评估AI系统在科学数据可视化方面的能力有效，也对评估编程和视觉感知等一般能力具有参考价值。'
- en: 6 Related Work
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 相关工作
- en: Code LLMs
  id: totrans-112
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 代码 LLMs
- en: Since the release of Codex Chen et al. ([2021](#bib.bib3)), many closed- and
    open-source code LLMs have been published, pushing the boundaries of LLMs’ capabilities
    to write functional code. Early open-source efforts include SantaCoder Allal et al.
    ([2023](#bib.bib1)) and StarCoder Li et al. ([2023b](#bib.bib13)). More recently,
    the Code Llama Rozière et al. ([2024](#bib.bib27)) series is released, including
    models of varying sizes. DeepSeekCoder Guo et al. ([2024](#bib.bib7)), a series
    of open-source code models ranging in size from 1.3B to 33B, has also garnered
    significant attention for its impressive performance on general coding benchmarks.
    Wei et al. ([2023](#bib.bib34)) introduce a novel data augmentation method for
    automatically creating high-quality fine-tuning data. The resulting Magicoder
    model surpasses a wide array of open-source code LLMs in performance.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 自从Codex Chen et al. ([2021](#bib.bib3)) 发布以来，许多闭源和开源的代码LLMs相继出现，推动了LLMs在编写功能代码方面的能力。早期的开源努力包括SantaCoder
    Allal et al. ([2023](#bib.bib1)) 和StarCoder Li et al. ([2023b](#bib.bib13))。最近，发布了Code
    Llama Rozière et al. ([2024](#bib.bib27))系列，包括不同规模的模型。DeepSeekCoder Guo et al.
    ([2024](#bib.bib7))，一个规模从1.3B到33B的开源代码模型系列，也因其在一般编码基准上的出色表现而受到广泛关注。Wei et al.
    ([2023](#bib.bib34)) 引入了一种新颖的数据增强方法，用于自动创建高质量的微调数据。结果Magicoder模型在性能上超越了广泛的开源代码LLMs。
- en: LLM Agents
  id: totrans-114
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: LLM 代理
- en: Recently, a wide range of LLM-based agent frameworks is proposed to explore
    LLMs’ potential in real-world scenarios Nakano et al. ([2021](#bib.bib18)); Yao
    et al. ([2022](#bib.bib37)); Qin et al. ([2023](#bib.bib23)); Zhou et al. ([2023](#bib.bib41)).
    OpenAgents Xie et al. ([2023](#bib.bib35)) proposed an open platform for using
    language agents in everyday life, which includes a Data Agent, a Plugins Agent,
    and a Web Agent. Park et al. ([2023](#bib.bib20)) proposed an interactive simulacra
    of human behavior where computational software agents simulate believable human
    actions and interactions. Voyager Wang et al. ([2023](#bib.bib32)) introduced
    the first LLM-powered embodied lifelong learning agent in Minecraft that continuously
    explores the world, acquires diverse skills, and makes novel discoveries without
    human intervention. ChatDev Qian et al. ([2023a](#bib.bib21)) proposed a virtual
    chat-powered software development company that mirrors the established waterfall
    model. In this study, we explore the capabilities of LLM-based agents in the task
    of scientific data visualization, a critical and practical area for contemporary
    researchers.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，提出了广泛的基于LLM的代理框架，以探索LLMs在现实场景中的潜力 Nakano et al. ([2021](#bib.bib18)); Yao
    et al. ([2022](#bib.bib37)); Qin et al. ([2023](#bib.bib23)); Zhou et al. ([2023](#bib.bib41))。OpenAgents
    Xie et al. ([2023](#bib.bib35)) 提出了一个用于日常生活中的语言代理的开放平台，包括一个数据代理、一个插件代理和一个网页代理。Park
    et al. ([2023](#bib.bib20)) 提出了一个模拟人类行为的互动模型，其中计算软件代理模拟可信的人类行为和互动。Voyager Wang
    et al. ([2023](#bib.bib32)) 介绍了第一个LLM驱动的具身终身学习代理，该代理在Minecraft中不断探索世界，获得多样化的技能，并在没有人工干预的情况下进行新发现。ChatDev
    Qian et al. ([2023a](#bib.bib21)) 提出了一个虚拟聊天驱动的软件开发公司，该公司模拟了既有的瀑布模型。在本研究中，我们探索了基于LLM的代理在科学数据可视化任务中的能力，这是当代研究人员的一个关键而实际的领域。
- en: 7 Conclusion
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 结论
- en: We propose to assess and enhance the capabilities of modern LLMs for scientific
    data visualization, a multifaceted task demanding coding and visual skills. We
    begin with the creation of MatPlotBench, a rigorous benchmark supporting automated
    quantitative evaluation that strongly aligns with human assessment. Additionally,
    we introduce MatPlotAgent, a model-agnostic mechanism employing visual feedback
    to enhance LLMs’ plotting abilities. Experimental results demonstrate that MatPlotAgent
    enhances the performance of various LLMs.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议评估和提升现代大语言模型（LLMs）在科学数据可视化中的能力，这是一项多方面的任务，要求具备编码和视觉技能。我们首先创建了 MatPlotBench，这是一种严格的基准测试，支持与人类评估高度一致的自动定量评估。此外，我们引入了
    MatPlotAgent，这是一种与模型无关的机制，通过视觉反馈提升 LLMs 的绘图能力。实验结果表明，MatPlotAgent 提升了各种 LLMs 的性能。
- en: 8 Limitations
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 限制
- en: In this paper, we introduce MatPlotBench, a benchmark designed for scientific
    data visualization. However, the demands of scientific data visualization can
    vary significantly across disciplines. Since MatPlotBench is developed for general
    scientific data visualization, it may not encompass all domain-specific requirements,
    potentially restricting its applicability to certain fields. In the future, the
    data construction and evaluation approaches can be customized for specific domains
    if necessary.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇论文中，我们介绍了 MatPlotBench，这是一种针对科学数据可视化设计的基准测试。然而，科学数据可视化的需求在不同学科中可能会有显著差异。由于
    MatPlotBench 是为一般科学数据可视化开发的，它可能无法涵盖所有特定领域的需求，从而可能限制其在某些领域的适用性。未来，如果有必要，可以针对特定领域定制数据构建和评估方法。
- en: References
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Allal et al. (2023) Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao
    Mou, Christopher Akiki, Carlos Munoz Ferrandis, Niklas Muennighoff, Mayank Mishra,
    Alex Gu, Manan Dey, Logesh Kumar Umapathi, Carolyn Jane Anderson, Yangtian Zi,
    Joel Lamy Poirier, Hailey Schoelkopf, Sergey Troshin, Dmitry Abulkhanov, Manuel
    Romero, Michael Lappert, Francesco De Toni, Bernardo García del Río, Qian Liu,
    Shamik Bose, Urvashi Bhattacharyya, Terry Yue Zhuo, Ian Yu, Paulo Villegas, Marco
    Zocca, Sourab Mangrulkar, David Lansky, Huu Nguyen, Danish Contractor, Luis Villa,
    Jia Li, Dzmitry Bahdanau, Yacine Jernite, Sean Hughes, Daniel Fried, Arjun Guha,
    Harm de Vries, and Leandro von Werra. 2023. [Santacoder: don’t reach for the stars!](http://arxiv.org/abs/2301.03988)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Allal 等（2023）Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher
    Akiki, Carlos Munoz Ferrandis, Niklas Muennighoff, Mayank Mishra, Alex Gu, Manan
    Dey, Logesh Kumar Umapathi, Carolyn Jane Anderson, Yangtian Zi, Joel Lamy Poirier,
    Hailey Schoelkopf, Sergey Troshin, Dmitry Abulkhanov, Manuel Romero, Michael Lappert,
    Francesco De Toni, Bernardo García del Río, Qian Liu, Shamik Bose, Urvashi Bhattacharyya,
    Terry Yue Zhuo, Ian Yu, Paulo Villegas, Marco Zocca, Sourab Mangrulkar, David
    Lansky, Huu Nguyen, Danish Contractor, Luis Villa, Jia Li, Dzmitry Bahdanau, Yacine
    Jernite, Sean Hughes, Daniel Fried, Arjun Guha, Harm de Vries, 和 Leandro von Werra.
    2023. [Santacoder: don’t reach for the stars!](http://arxiv.org/abs/2301.03988)'
- en: 'Azerbayev et al. (2024) Zhangir Azerbayev, Hailey Schoelkopf, Keiran Paster,
    Marco Dos Santos, Stephen Marcus McAleer, Albert Q. Jiang, Jia Deng, Stella Biderman,
    and Sean Welleck. 2024. [Llemma: An open language model for mathematics](https://openreview.net/forum?id=4WnqRR915j).
    In *The Twelfth International Conference on Learning Representations*.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Azerbayev 等（2024）Zhangir Azerbayev, Hailey Schoelkopf, Keiran Paster, Marco
    Dos Santos, Stephen Marcus McAleer, Albert Q. Jiang, Jia Deng, Stella Biderman,
    和 Sean Welleck. 2024. [Llemma: An open language model for mathematics](https://openreview.net/forum?id=4WnqRR915j).
    发表在 *第十二届国际学习表征会议*。'
- en: Chen et al. (2021) Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde
    de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg
    Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf,
    Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov,
    Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet,
    Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth
    Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas
    Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders,
    Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan
    Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer,
    Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and
    Wojciech Zaremba. 2021. [Evaluating large language models trained on code](http://arxiv.org/abs/2107.03374).
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈等人（2021）马克·陈、杰瑞·特沃雷克、赫宇·俊、启明·袁、恩里克·庞德·德·奥利维拉·平托、贾瑞德·卡普兰、哈里·爱德华兹、尤里·布尔达、尼古拉斯·约瑟夫、格雷格·布罗克曼、亚历克斯·雷、劳尔·普里、格雷琴·克鲁格、迈克尔·彼得罗夫、海迪·克拉夫、吉里什·萨斯特里、帕梅拉·米什金、布鲁克·陈、斯科特·格雷、尼克·赖德、米哈伊尔·帕夫洛夫、阿莱西亚·鲍尔、卢卡斯·凯泽、穆罕默德·巴瓦里安、克莱门斯·温特、菲利普·蒂莱、费利佩·佩特罗斯基·苏赫、戴夫·卡明斯、马蒂亚斯·普拉普特、福提奥斯·查安齐斯、伊丽莎白·巴恩斯、阿里尔·赫伯特-沃斯、威廉·赫布根·古斯、亚历克斯·尼科尔、亚历克斯·帕伊诺、尼古拉斯·特扎克、杰·唐、伊戈尔·巴布什金、苏希尔·巴拉吉、尚坦努·贾因、威廉·桑德斯、克里斯托弗·赫斯、安德鲁·N·卡尔、扬·莱克、乔希·阿基亚姆、维丹特·米斯拉、埃文·莫里卡瓦、亚历克·拉德福德、马修·奈特、迈尔斯·布伦德奇、米拉·穆拉蒂、凯蒂·梅耶、彼得·维林德、鲍勃·麦格鲁、达里奥·阿莫代伊、萨姆·麦肯利什、伊利亚·苏茨克弗和沃伊切赫·扎伦巴。2021.
    [评估在代码上训练的大型语言模型](http://arxiv.org/abs/2107.03374)。
- en: 'Chen et al. (2024a) Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei
    Yuan, Chi-Min Chan, Heyang Yu, Yaxi Lu, Yi-Hsin Hung, Chen Qian, Yujia Qin, Xin
    Cong, Ruobing Xie, Zhiyuan Liu, Maosong Sun, and Jie Zhou. 2024a. [Agentverse:
    Facilitating multi-agent collaboration and exploring emergent behaviors](https://openreview.net/forum?id=EHg5GDnyq1).
    In *The Twelfth International Conference on Learning Representations*.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '陈等人（2024a）魏泽·陈、于生·苏、景伟·左、程洋、陈飞·袁、池敏·陈、黑杨·余、雅希·卢、义欣·洪、陈倩、余佳·秦、新聪、若冰·谢、志远·刘、毛松·孙和杰·周。2024a.
    [Agentverse: 促进多智能体协作与探索涌现行为](https://openreview.net/forum?id=EHg5GDnyq1)。发表于*第十二届国际学习表征会议*。'
- en: Chen et al. (2024b) Xinyun Chen, Maxwell Lin, Nathanael Schärli, and Denny Zhou.
    2024b. [Teaching large language models to self-debug](https://openreview.net/forum?id=KuPixIqPiq).
    In *The Twelfth International Conference on Learning Representations*.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈等人（2024b）辛云·陈、马克斯韦尔·林、纳撒尼尔·沙尔利和丹尼·周。2024b. [教会大型语言模型自我调试](https://openreview.net/forum?id=KuPixIqPiq)。发表于*第十二届国际学习表征会议*。
- en: 'Deng et al. (2023) Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens,
    Boshi Wang, Huan Sun, and Yu Su. 2023. [Mind2web: Towards a generalist agent for
    the web](https://openreview.net/forum?id=kiYqbO3wqw). In *Thirty-seventh Conference
    on Neural Information Processing Systems Datasets and Benchmarks Track*.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '邓等人（2023）邓翔、谷宇、博远·郑、世杰·陈、塞缪尔·史蒂文斯、博时·王、欢·孙和于苏。2023. [Mind2web: 朝着一个通用网络智能体的方向迈进](https://openreview.net/forum?id=kiYqbO3wqw)。发表于*第三十七届神经信息处理系统会议数据集与基准追踪*。'
- en: 'Guo et al. (2024) Daya Guo, Qihao Zhu, Dejian Yang, Zhenda Xie, Kai Dong, Wentao
    Zhang, Guanting Chen, Xiao Bi, Y. Wu, Y. K. Li, Fuli Luo, Yingfei Xiong, and Wenfeng
    Liang. 2024. [Deepseek-coder: When the large language model meets programming
    – the rise of code intelligence](http://arxiv.org/abs/2401.14196).'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '郭等人（2024）郭达亚、朱启浩、杨德健、谢振达、董凯、张文涛、陈冠廷、毕晓、吴·Y、李·Y·K、罗伏里、熊英飞和梁文峰。2024. [Deepseek-coder:
    当大型语言模型遇见编程——代码智能的崛起](http://arxiv.org/abs/2401.14196)。'
- en: Kojima et al. (2022a) Takeshi Kojima, Shixiang (Shane) Gu, Machel Reid, Yutaka
    Matsuo, and Yusuke Iwasawa. 2022a. Large language models are zero-shot reasoners.
    In *Advances in Neural Information Processing Systems*, volume 35, pages 22199–22213.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小岛等人（2022a）小岛武、石向（Shane）顾、马切尔·瑞德、松尾丰和岩泽佑介。2022a. 大型语言模型是零-shot 推理器。发表于*神经信息处理系统进展*，第35卷，第22199–22213页。
- en: Kojima et al. (2022b) Takeshi Kojima, Shixiang (Shane) Gu, Machel Reid, Yutaka
    Matsuo, and Yusuke Iwasawa. 2022b. [Large language models are zero-shot reasoners](https://proceedings.neurips.cc/paper_files/paper/2022/file/8bb0d291acd4acf06ef112099c16f326-Paper-Conference.pdf).
    In *Advances in Neural Information Processing Systems*.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小岛等人（2022b）小岛武、石向（Shane）顾、马切尔·瑞德、松尾丰和岩泽佑介。2022b. [大型语言模型是零-shot 推理器](https://proceedings.neurips.cc/paper_files/paper/2022/file/8bb0d291acd4acf06ef112099c16f326-Paper-Conference.pdf)。发表于*神经信息处理系统进展*。
- en: Kwon et al. (2023) Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin
    Zheng, Cody Hao Yu, Joseph E. Gonzalez, Hao Zhang, and Ion Stoica. 2023. Efficient
    memory management for large language model serving with pagedattention. In *Proceedings
    of the ACM SIGOPS 29th Symposium on Operating Systems Principles*.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kwon et al. (2023) Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin
    Zheng, Cody Hao Yu, Joseph E. Gonzalez, Hao Zhang, and Ion Stoica. 2023. 高效的大语言模型服务内存管理与分页注意力。发表于*ACM
    SIGOPS 第29届操作系统原理研讨会论文集*。
- en: 'Lai et al. (2023) Yuhang Lai, Chengxi Li, Yiming Wang, Tianyi Zhang, Ruiqi
    Zhong, Luke Zettlemoyer, Wen-Tau Yih, Daniel Fried, Sida Wang, and Tao Yu. 2023.
    DS-1000: A natural and reliable benchmark for data science code generation. In
    *Proceedings of the 40th International Conference on Machine Learning*.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lai et al. (2023) Yuhang Lai, Chengxi Li, Yiming Wang, Tianyi Zhang, Ruiqi
    Zhong, Luke Zettlemoyer, Wen-Tau Yih, Daniel Fried, Sida Wang, and Tao Yu. 2023.
    DS-1000: 一种自然且可靠的数据科学代码生成基准。在*第40届国际机器学习会议*上。'
- en: 'Li et al. (2023a) Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii
    Khizbullin, and Bernard Ghanem. 2023a. [CAMEL: Communicative agents for ”mind”
    exploration of large language model society](https://openreview.net/forum?id=3IyL2XWDkG).
    In *Thirty-seventh Conference on Neural Information Processing Systems*.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li et al. (2023a) Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii
    Khizbullin, and Bernard Ghanem. 2023a. [CAMEL: 用于大语言模型社会“心智”探索的交流智能体](https://openreview.net/forum?id=3IyL2XWDkG)。在*第三十七届神经信息处理系统会议*上。'
- en: 'Li et al. (2023b) Raymond Li, Loubna Ben allal, Yangtian Zi, Niklas Muennighoff,
    Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia LI, Jenny Chim,
    Qian Liu, Evgenii Zheltonozhskii, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene,
    Joel Lamy-Poirier, Joao Monteiro, Nicolas Gontier, Ming-Ho Yee, Logesh Kumar Umapathi,
    Jian Zhu, Ben Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, Jason T
    Stillerman, Siva Sankalp Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan
    Zhang, Urvashi Bhattacharyya, Wenhao Yu, Sasha Luccioni, Paulo Villegas, Fedor
    Zhdanov, Tony Lee, Nadav Timor, Jennifer Ding, Claire S Schlesinger, Hailey Schoelkopf,
    Jan Ebert, Tri Dao, Mayank Mishra, Alex Gu, Carolyn Jane Anderson, Brendan Dolan-Gavitt,
    Danish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite,
    Carlos Muñoz Ferrandis, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro Von Werra,
    and Harm de Vries. 2023b. [Starcoder: may the source be with you!](https://openreview.net/forum?id=KoFOg41haE)
    *Transactions on Machine Learning Research*. Reproducibility Certification.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li et al. (2023b) Raymond Li, Loubna Ben allal, Yangtian Zi, Niklas Muennighoff,
    Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia LI, Jenny Chim,
    Qian Liu, Evgenii Zheltonozhskii, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene,
    Joel Lamy-Poirier, Joao Monteiro, Nicolas Gontier, Ming-Ho Yee, Logesh Kumar Umapathi,
    Jian Zhu, Ben Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, Jason T
    Stillerman, Siva Sankalp Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan
    Zhang, Urvashi Bhattacharyya, Wenhao Yu, Sasha Luccioni, Paulo Villegas, Fedor
    Zhdanov, Tony Lee, Nadav Timor, Jennifer Ding, Claire S Schlesinger, Hailey Schoelkopf,
    Jan Ebert, Tri Dao, Mayank Mishra, Alex Gu, Carolyn Jane Anderson, Brendan Dolan-Gavitt,
    Danish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite,
    Carlos Muñoz Ferrandis, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro Von Werra,
    and Harm de Vries. 2023b. [Starcoder: 愿源代码与你同在！](https://openreview.net/forum?id=KoFOg41haE)
    *机器学习研究交易*。可复现性认证。'
- en: 'Liu et al. (2024) Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu
    Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng,
    Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan
    Sun, Minlie Huang, Yuxiao Dong, and Jie Tang. 2024. [Agentbench: Evaluating LLMs
    as agents](https://openreview.net/forum?id=zAdUB0aCTQ). In *The Twelfth International
    Conference on Learning Representations*.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu et al. (2024) Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu
    Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng,
    Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan
    Sun, Minlie Huang, Yuxiao Dong, and Jie Tang. 2024. [Agentbench: 评估 LLM 作为智能体](https://openreview.net/forum?id=zAdUB0aCTQ)。在*第十二届国际学习表征会议*上。'
- en: 'Lu et al. (2023) Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang,
    Ying Nian Wu, Song-Chun Zhu, and Jianfeng Gao. 2023. [Chameleon: Plug-and-play
    compositional reasoning with large language models](https://openreview.net/forum?id=HtqnVSCj3q).
    In *Thirty-seventh Conference on Neural Information Processing Systems*.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lu et al. (2023) Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang,
    Ying Nian Wu, Song-Chun Zhu, and Jianfeng Gao. 2023. [Chameleon: 插件式组合推理与大语言模型](https://openreview.net/forum?id=HtqnVSCj3q)。在*第三十七届神经信息处理系统会议*上。'
- en: 'Luo et al. (2023a) Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jianguang Lou,
    Chongyang Tao, Xiubo Geng, Qingwei Lin, Shifeng Chen, and Dongmei Zhang. 2023a.
    Wizardmath: Empowering mathematical reasoning for large language models via reinforced
    evol-instruct. *arXiv preprint arXiv:2308.09583*.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Luo et al. (2023a) Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jianguang Lou,
    Chongyang Tao, Xiubo Geng, Qingwei Lin, Shifeng Chen, 和 Dongmei Zhang. 2023a.
    Wizardmath: 通过强化演进指令赋能大型语言模型的数学推理。*arXiv 预印本 arXiv:2308.09583*。'
- en: 'Luo et al. (2023b) Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang
    Hu, Chongyang Tao, Jing Ma, Qingwei Lin, and Daxin Jiang. 2023b. [Wizardcoder:
    Empowering code large language models with evol-instruct](http://arxiv.org/abs/2306.08568).'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Luo et al. (2023b) Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang
    Hu, Chongyang Tao, Jing Ma, Qingwei Lin, 和 Daxin Jiang. 2023b. [Wizardcoder: 通过演进指令赋能大型语言模型的代码能力](http://arxiv.org/abs/2306.08568)。'
- en: 'Nakano et al. (2021) Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu,
    Ouyang Long, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju,
    William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin
    Button, Matthew Knight, Benjamin Chess, and John Schulman. 2021. [Webgpt: Browser-assisted
    question-answering with human feedback](https://api.semanticscholar.org/CorpusID:245329531).
    *ArXiv*, abs/2112.09332.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Nakano et al. (2021) Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu,
    Ouyang Long, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju,
    William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin
    Button, Matthew Knight, Benjamin Chess, 和 John Schulman. 2021. [Webgpt: 浏览器辅助问答与人工反馈](https://api.semanticscholar.org/CorpusID:245329531)。*ArXiv*，abs/2112.09332。'
- en: OpenAI (2023) OpenAI. 2023. [Gpt-4 technical report](https://api.semanticscholar.org/CorpusID:257532815).
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI (2023) OpenAI. 2023. [Gpt-4 技术报告](https://api.semanticscholar.org/CorpusID:257532815)。
- en: 'Park et al. (2023) Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S. Bernstein. 2023. [Generative agents: Interactive
    simulacra of human behavior](https://doi.org/10.1145/3586183.3606763). In *Proceedings
    of the 36th Annual ACM Symposium on User Interface Software and Technology*, UIST
    ’23, New York, NY, USA. Association for Computing Machinery.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park et al. (2023) Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith
    Ringel Morris, Percy Liang, 和 Michael S. Bernstein. 2023. [生成代理：人类行为的互动仿真](https://doi.org/10.1145/3586183.3606763)。发表于
    *第36届ACM用户界面软件与技术年会*，UIST ’23，纽约，NY，美国。计算机协会。
- en: Qian et al. (2023a) Chen Qian, Xin Cong, Wei Liu, Cheng Yang, Weize Chen, Yusheng
    Su, Yufan Dang, Jiahao Li, Juyuan Xu, Dahai Li, Zhiyuan Liu, and Maosong Sun.
    2023a. [Communicative agents for software development](http://arxiv.org/abs/2307.07924).
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qian et al. (2023a) Chen Qian, Xin Cong, Wei Liu, Cheng Yang, Weize Chen, Yusheng
    Su, Yufan Dang, Jiahao Li, Juyuan Xu, Dahai Li, Zhiyuan Liu, 和 Maosong Sun. 2023a.
    [用于软件开发的交互代理](http://arxiv.org/abs/2307.07924)。
- en: 'Qian et al. (2023b) Cheng Qian, Chi Han, Yi Fung, Yujia Qin, Zhiyuan Liu, and
    Heng Ji. 2023b. [CREATOR: Tool creation for disentangling abstract and concrete
    reasoning of large language models](https://doi.org/10.18653/v1/2023.findings-emnlp.462).
    In *Findings of the Association for Computational Linguistics: EMNLP 2023*, pages
    6922–6939, Singapore. Association for Computational Linguistics.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Qian et al. (2023b) Cheng Qian, Chi Han, Yi Fung, Yujia Qin, Zhiyuan Liu, 和
    Heng Ji. 2023b. [CREATOR: 用于解构大型语言模型的抽象和具体推理的工具创建](https://doi.org/10.18653/v1/2023.findings-emnlp.462)。发表于
    *计算语言学协会发现：EMNLP 2023*，第6922–6939页，新加坡。计算语言学协会。'
- en: 'Qin et al. (2023) Yujia Qin, Zihan Cai, Dian Jin, Lan Yan, Shihao Liang, Kunlun
    Zhu, Yankai Lin, Xu Han, Ning Ding, Huadong Wang, Ruobing Xie, Fanchao Qi, Zhiyuan
    Liu, Maosong Sun, and Jie Zhou. 2023. [WebCPM: Interactive web search for Chinese
    long-form question answering](https://doi.org/10.18653/v1/2023.acl-long.499).
    In *Proceedings of the 61st Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)*, pages 8968–8988, Toronto, Canada. Association
    for Computational Linguistics.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Qin et al. (2023) Yujia Qin, Zihan Cai, Dian Jin, Lan Yan, Shihao Liang, Kunlun
    Zhu, Yankai Lin, Xu Han, Ning Ding, Huadong Wang, Ruobing Xie, Fanchao Qi, Zhiyuan
    Liu, Maosong Sun, 和 Jie Zhou. 2023. [WebCPM: 针对中文长篇问答的互动网页搜索](https://doi.org/10.18653/v1/2023.acl-long.499)。发表于
    *第61届计算语言学协会年会（第1卷：长篇论文）*，第8968–8988页，多伦多，加拿大。计算语言学协会。'
- en: 'Qin et al. (2024) Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan,
    Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Lauren Hong,
    Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, dahai li, Zhiyuan Liu, and
    Maosong Sun. 2024. [ToolLLM: Facilitating large language models to master 16000+
    real-world APIs](https://openreview.net/forum?id=dHng2O0Jjr). In *The Twelfth
    International Conference on Learning Representations*.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Qin et al. (2024) Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan,
    Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Lauren Hong,
    Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, dahai li, Zhiyuan Liu, 和 Maosong
    Sun。2024年。[ToolLLM: 促进大型语言模型掌握16000+实际应用程序接口](https://openreview.net/forum?id=dHng2O0Jjr)。在*第十二届国际学习表示会议*上。'
- en: Ramesh et al. (2021) Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray,
    Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever. 2021. [Zero-shot text-to-image
    generation](http://arxiv.org/abs/2102.12092).
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ramesh et al. (2021) Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray,
    Chelsea Voss, Alec Radford, Mark Chen, 和 Ilya Sutskever。2021年。[零样本文本到图像生成](http://arxiv.org/abs/2102.12092)。
- en: Rombach et al. (2022) Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick
    Esser, and Björn Ommer. 2022. [High-resolution image synthesis with latent diffusion
    models](http://arxiv.org/abs/2112.10752).
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rombach et al. (2022) Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick
    Esser, 和 Björn Ommer。2022年。[高分辨率图像合成与潜在扩散模型](http://arxiv.org/abs/2112.10752)。
- en: 'Rozière et al. (2024) Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten
    Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Romain Sauvestre,
    Tal Remez, Jérémy Rapin, Artyom Kozhevnikov, Ivan Evtimov, Joanna Bitton, Manish
    Bhatt, Cristian Canton Ferrer, Aaron Grattafiori, Wenhan Xiong, Alexandre Défossez,
    Jade Copet, Faisal Azhar, Hugo Touvron, Louis Martin, Nicolas Usunier, Thomas
    Scialom, and Gabriel Synnaeve. 2024. [Code llama: Open foundation models for code](http://arxiv.org/abs/2308.12950).'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Rozière et al. (2024) Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten
    Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Romain Sauvestre,
    Tal Remez, Jérémy Rapin, Artyom Kozhevnikov, Ivan Evtimov, Joanna Bitton, Manish
    Bhatt, Cristian Canton Ferrer, Aaron Grattafiori, Wenhan Xiong, Alexandre Défossez,
    Jade Copet, Faisal Azhar, Hugo Touvron, Louis Martin, Nicolas Usunier, Thomas
    Scialom, 和 Gabriel Synnaeve。2024年。[Code llama: 开放式基础模型用于代码](http://arxiv.org/abs/2308.12950)。'
- en: Saharia et al. (2022) Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li,
    Jay Whang, Emily Denton, Seyed Kamyar Seyed Ghasemipour, Burcu Karagol Ayan, S. Sara
    Mahdavi, Rapha Gontijo Lopes, Tim Salimans, Jonathan Ho, David J Fleet, and Mohammad
    Norouzi. 2022. [Photorealistic text-to-image diffusion models with deep language
    understanding](http://arxiv.org/abs/2205.11487).
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Saharia et al. (2022) Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li,
    Jay Whang, Emily Denton, Seyed Kamyar Seyed Ghasemipour, Burcu Karagol Ayan, S.
    Sara Mahdavi, Rapha Gontijo Lopes, Tim Salimans, Jonathan Ho, David J Fleet, 和
    Mohammad Norouzi。2022年。[具有深度语言理解的逼真文本到图像扩散模型](http://arxiv.org/abs/2205.11487)。
- en: 'Schick et al. (2023) Timo Schick, Jane Dwivedi-Yu, Roberto Dessi, Roberta Raileanu,
    Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom.
    2023. [Toolformer: Language models can teach themselves to use tools](https://openreview.net/forum?id=Yacmpz84TH).
    In *Thirty-seventh Conference on Neural Information Processing Systems*.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Schick et al. (2023) Timo Schick, Jane Dwivedi-Yu, Roberto Dessi, Roberta Raileanu,
    Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, 和 Thomas Scialom。2023年。[Toolformer:
    语言模型可以自我学习使用工具](https://openreview.net/forum?id=Yacmpz84TH)。在*第三十七届神经信息处理系统会议*上。'
- en: 'Shao et al. (2024) Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao
    Song, Mingchuan Zhang, Y. K. Li, Y. Wu, and Daya Guo. 2024. [Deepseekmath: Pushing
    the limits of mathematical reasoning in open language models](http://arxiv.org/abs/2402.03300).'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shao et al. (2024) Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao
    Song, Mingchuan Zhang, Y. K. Li, Y. Wu, 和 Daya Guo。2024年。[Deepseekmath: 推动开放语言模型中的数学推理极限](http://arxiv.org/abs/2402.03300)。'
- en: 'Shinn et al. (2023) Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik R
    Narasimhan, and Shunyu Yao. 2023. [Reflexion: language agents with verbal reinforcement
    learning](https://openreview.net/forum?id=vAElhFcKW6). In *Thirty-seventh Conference
    on Neural Information Processing Systems*.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shinn et al. (2023) Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik
    R Narasimhan, 和 Shunyu Yao。2023年。[Reflexion: 语言智能体与言语强化学习](https://openreview.net/forum?id=vAElhFcKW6)。在*第三十七届神经信息处理系统会议*上。'
- en: 'Wang et al. (2023) Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei
    Xiao, Yuke Zhu, Linxi (Jim) Fan, and Anima Anandkumar. 2023. [Voyager: An open-ended
    embodied agent with large language models](https://api.semanticscholar.org/CorpusID:258887849).
    *ArXiv*, abs/2305.16291.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang et al. (2023) Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei
    Xiao, Yuke Zhu, Linxi (Jim) Fan, 和 Anima Anandkumar。2023年。[Voyager: 一个开放式的具身智能体，基于大型语言模型](https://api.semanticscholar.org/CorpusID:258887849)。*ArXiv*,
    abs/2305.16291。'
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian
    ichter, Fei Xia, Ed Chi, Quoc V Le, and Denny Zhou. 2022. [Chain-of-thought prompting
    elicits reasoning in large language models](https://proceedings.neurips.cc/paper_files/paper/2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf).
    In *Advances in Neural Information Processing Systems*, volume 35, pages 24824–24837\.
    Curran Associates, Inc.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian
    ichter, Fei Xia, Ed Chi, Quoc V Le, 和 Denny Zhou. 2022. [Chain-of-thought prompting
    elicits reasoning in large language models](https://proceedings.neurips.cc/paper_files/paper/2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf)。在*神经信息处理系统进展*，第35卷，第24824–24837页。Curran
    Associates, Inc.
- en: 'Wei et al. (2023) Yuxiang Wei, Zhe Wang, Jiawei Liu, Yifeng Ding, and Lingming
    Zhang. 2023. [Magicoder: Source code is all you need](http://arxiv.org/abs/2312.02120).'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wei et al. (2023) Yuxiang Wei, Zhe Wang, Jiawei Liu, Yifeng Ding, 和 Lingming
    Zhang. 2023. [Magicoder: Source code is all you need](http://arxiv.org/abs/2312.02120)。'
- en: 'Xie et al. (2023) Tianbao Xie, Fan Zhou, Zhoujun Cheng, Peng Shi, Luoxuan Weng,
    Yitao Liu, Toh Jing Hua, Junning Zhao, Qian Liu, Che Liu, Leo Z. Liu, Yiheng Xu,
    Hongjin Su, Dongchan Shin, Caiming Xiong, and Tao Yu. 2023. [Openagents: An open
    platform for language agents in the wild](http://arxiv.org/abs/2310.10634).'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Xie et al. (2023) Tianbao Xie, Fan Zhou, Zhoujun Cheng, Peng Shi, Luoxuan Weng,
    Yitao Liu, Toh Jing Hua, Junning Zhao, Qian Liu, Che Liu, Leo Z. Liu, Yiheng Xu,
    Hongjin Su, Dongchan Shin, Caiming Xiong, 和 Tao Yu. 2023. [Openagents: An open
    platform for language agents in the wild](http://arxiv.org/abs/2310.10634)。'
- en: 'Xu et al. (2023) Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang,
    Weidong Liu, and Yang Liu. 2023. [Exploring large language models for communication
    games: An empirical study on werewolf](http://arxiv.org/abs/2309.04658).'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Xu et al. (2023) Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang,
    Weidong Liu, 和 Yang Liu. 2023. [Exploring large language models for communication
    games: An empirical study on werewolf](http://arxiv.org/abs/2309.04658)。'
- en: 'Yao et al. (2022) Shunyu Yao, Howard Chen, John Yang, and Karthik Narasimhan.
    2022. [WebShop: Towards Scalable Real-World Web Interaction with Grounded Language
    Agents](https://proceedings.neurips.cc/paper_files/paper/2022/file/82ad13ec01f9fe44c01cb91814fd7b8c-Paper-Conference.pdf).
    In *Advances in Neural Information Processing Systems*, volume 35, pages 20744–20757\.
    Curran Associates, Inc.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yao et al. (2022) Shunyu Yao, Howard Chen, John Yang, 和 Karthik Narasimhan.
    2022. [WebShop: Towards Scalable Real-World Web Interaction with Grounded Language
    Agents](https://proceedings.neurips.cc/paper_files/paper/2022/file/82ad13ec01f9fe44c01cb91814fd7b8c-Paper-Conference.pdf)。在*神经信息处理系统进展*，第35卷，第20744–20757页。Curran
    Associates, Inc.'
- en: 'Yao et al. (2023a) Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L.
    Griffiths, Yuan Cao, and Karthik R Narasimhan. 2023a. [Tree of thoughts: Deliberate
    problem solving with large language models](https://openreview.net/forum?id=5Xc1ecxO1h).
    In *Thirty-seventh Conference on Neural Information Processing Systems*.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yao et al. (2023a) Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas
    L. Griffiths, Yuan Cao, 和 Karthik R Narasimhan. 2023a. [Tree of thoughts: Deliberate
    problem solving with large language models](https://openreview.net/forum?id=5Xc1ecxO1h)。在*第三十七届神经信息处理系统会议*上。'
- en: 'Yao et al. (2023b) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik R Narasimhan, and Yuan Cao. 2023b. [React: Synergizing reasoning and acting
    in language models](https://openreview.net/forum?id=WE_vluYUL-X). In *The Eleventh
    International Conference on Learning Representations*.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yao et al. (2023b) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik R Narasimhan, 和 Yuan Cao. 2023b. [React: Synergizing reasoning and acting
    in language models](https://openreview.net/forum?id=WE_vluYUL-X)。在*第十一届国际学习表征会议*上。'
- en: 'Yu et al. (2024) Longhui Yu, Weisen Jiang, Han Shi, Jincheng YU, Zhengying
    Liu, Yu Zhang, James Kwok, Zhenguo Li, Adrian Weller, and Weiyang Liu. 2024. [Metamath:
    Bootstrap your own mathematical questions for large language models](https://openreview.net/forum?id=N8N0hgNDRt).
    In *The Twelfth International Conference on Learning Representations*.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yu et al. (2024) Longhui Yu, Weisen Jiang, Han Shi, Jincheng YU, Zhengying
    Liu, Yu Zhang, James Kwok, Zhenguo Li, Adrian Weller, 和 Weiyang Liu. 2024. [Metamath:
    Bootstrap your own mathematical questions for large language models](https://openreview.net/forum?id=N8N0hgNDRt)。在*第十二届国际学习表征会议*上。'
- en: 'Zhou et al. (2023) Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo,
    Abishek Sridhar, Xianyi Cheng, Tianyue Ou, Yonatan Bisk, Daniel Fried, Uri Alon,
    and Graham Neubig. 2023. [Webarena: A realistic web environment for building autonomous
    agents](https://openreview.net/forum?id=rmiwIL98uQ). In *Second Agent Learning
    in Open-Endedness Workshop*.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhou et al. (2023) Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo,
    Abishek Sridhar, Xianyi Cheng, Tianyue Ou, Yonatan Bisk, Daniel Fried, Uri Alon,
    和 Graham Neubig. 2023. [Webarena: A realistic web environment for building autonomous
    agents](https://openreview.net/forum?id=rmiwIL98uQ)。在*第二届开放性学习中的智能体研讨会*上。'
- en: Appendix A Detailed Prompts
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 详细提示
- en: To better understand MatPlotBench and MatPlotAgent, we list the prompts for
    automatic evaluation and the three modules in MatPlotAgent, including the query
    expansion module, the code agent, and the visual agent.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解 MatPlotBench 和 MatPlotAgent，我们列出了自动评估的提示以及 MatPlotAgent 中的三个模块，包括查询扩展模块、代码代理和视觉代理。
- en: A.1 Evaluation Prompts
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 评估提示
- en: The automatic evaluation prompt primarily requires GPT-4V to provide a score
    between 0 and 100 for the model-generated plot, with reference to the ground truth
    plot.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 自动评估提示主要要求 GPT-4V 为模型生成的图形提供一个 0 到 100 之间的评分，参照真实图形。
- en: You
    are an excellent judge at evaluating visualization plots between a model-generated
    plot and the ground truth. You will be giving scores on how well it matches the
    ground truth plot.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 你是一个出色的评估者，能够评估模型生成的图形与真实图形之间的可视化效果。你将根据生成的图形与真实图形的匹配程度给出评分。
- en: The generated plot will be given to you as the first figure. If the first figure
    is blank, that means the code failed to generate a figure.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的图形将作为第一个图形提供给你。如果第一个图形为空，则表示代码未能生成图形。
- en: Another plot will be given to you as the second figure, which is the desired
    outcome of the user query, meaning it is the ground truth for you to reference.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个图形将作为第二个图形提供给你，它是用户查询的期望结果，即作为参考的真实图形。
- en: Please compare the two figures head to head and rate them. Suppose the second
    figure has a score of 100, rate the first figure on a scale from 0 to 100\.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 请对比两个图形，并进行评分。假设第二个图形的分数为 100，请对第一个图形进行 0 到 100 的评分。
- en: 'Scoring should be carried out regarding the plot correctness: Compare closely
    between the generated plot and the ground truth, the more resemblance the generated
    plot has compared to the ground truth, the higher the score. The score should
    be proportionate to the resemblance between the two plots.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 评分应根据图形的正确性进行：仔细比较生成的图形和真实图形，生成的图形与真实图形的相似程度越高，评分越高。评分应与两个图形之间的相似程度成正比。
- en: In some rare occurrences, see if the data points are generated randomly according
    to the query, if so, the generated plot may not perfectly match the ground truth,
    but it is correct nonetheless.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在一些罕见的情况下，检查数据点是否根据查询随机生成，如果是这样，生成的图形可能与真实图形不完全匹配，但仍然是正确的。
- en: Only rate the first figure, the second figure is only for reference.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 只对第一个图形进行评分，第二个图形仅供参考。
- en: If the first figure is blank, that means the code failed to generate a figure.
    Give a score of 0 on the Plot correctness.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 如果第一个图形为空，则表示代码未能生成图形。在图形正确性评分中给 0 分。
- en: After scoring from the above aspect, please give a final score. The final score
    is preceded by the [FINAL SCORE] token.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述方面评分之后，请给出最终评分。最终评分前缀为 [最终评分] 标记。
- en: 'For example [FINAL SCORE]: 40.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 例如 [最终评分]：40。
- en: 'Figure 6: Automatic evaluation prompt for GPT-4V.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：GPT-4V 的自动评估提示。
- en: A.2 Prompts for MatPlotAgent
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 MatPlotAgent 的提示
- en: 'The query expansion prompt mainly requires LLMs to generate step-by-step, detailed
    instructions on how to use Python code to fulfill the requirements specified by
    users, as shown in Figure [7](#A1.F7 "Figure 7 ‣ A.2 Prompts for MatPlotAgent
    ‣ Appendix A Detailed Prompts ‣ MatPlotAgent: Method and Evaluation for LLM-Based
    Agentic Scientific Data Visualization").'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 查询扩展提示主要要求 LLMs 生成逐步的、详细的说明，说明如何使用 Python 代码满足用户指定的要求，如图 [7](#A1.F7 "图 7 ‣ A.2
    MatPlotAgent 提示 ‣ 附录 A 详细提示 ‣ MatPlotAgent：基于 LLM 的智能科学数据可视化的方法和评估") 所示。
- en: 'For the code agent, there are two prompts for the code generation process and
    the self-debugging mechanism. The code generation prompt mainly requires LLMs
    to generate executable code according to the user query to plot and save the output
    figure, as shown in Figure [8](#A1.F8 "Figure 8 ‣ A.2 Prompts for MatPlotAgent
    ‣ Appendix A Detailed Prompts ‣ MatPlotAgent: Method and Evaluation for LLM-Based
    Agentic Scientific Data Visualization"). The self-debugging prompt mainly requires
    LLMs to correct the buggy code according to the error message from a Python interpreter,
    as displayed in Figure [9](#A1.F9 "Figure 9 ‣ A.2 Prompts for MatPlotAgent ‣ Appendix
    A Detailed Prompts ‣ MatPlotAgent: Method and Evaluation for LLM-Based Agentic
    Scientific Data Visualization").'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '对于代码代理，存在两个提示，一个用于代码生成过程，另一个用于自我调试机制。代码生成提示主要要求 LLM 根据用户查询生成可执行代码，以绘制和保存输出图形，如图[8](#A1.F8
    "图 8 ‣ A.2 MatPlotAgent 提示 ‣ 附录 A 详细提示 ‣ MatPlotAgent: 基于 LLM 的代理科学数据可视化的方法和评估")所示。自我调试提示主要要求
    LLM 根据 Python 解释器的错误信息纠正有错误的代码，如图[9](#A1.F9 "图 9 ‣ A.2 MatPlotAgent 提示 ‣ 附录 A
    详细提示 ‣ MatPlotAgent: 基于 LLM 的代理科学数据可视化的方法和评估")所示。'
- en: 'The visual agent prompt mainly requires multi-modal LLMs to firstly understand
    the user query and analyze the draft plot, then generate the visual feedback to
    refine the draft, as shown in Figure [10](#A1.F10 "Figure 10 ‣ A.2 Prompts for
    MatPlotAgent ‣ Appendix A Detailed Prompts ‣ MatPlotAgent: Method and Evaluation
    for LLM-Based Agentic Scientific Data Visualization").'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '视觉代理提示主要要求多模态 LLM 首先理解用户查询并分析草图，然后生成视觉反馈以完善草图，如图[10](#A1.F10 "图 10 ‣ A.2 MatPlotAgent
    提示 ‣ 附录 A 详细提示 ‣ MatPlotAgent: 基于 LLM 的代理科学数据可视化的方法和评估")所示。'
- en: 'SYSTEM PROMPT: According to
    the user query, expand and solidify the query into a step by step detailed instruction
    (or comment) on how to write python code to fulfill the user query’s requirements.
    Import the appropriate libraries. Pinpoint the correct library functions to call
    and set each parameter in every function call accordingly. USER PROMPT: Here is
    the user query: [User Query]: """ {{query}} """ You should understand what the
    query’s requirements are, and output step by step, detailed instructions on how
    to use python code to fulfill these requirements. Include what libraries to import,
    what library functions to call, how to set the parameters in each function correctly,
    how to prepare the data, how to manipulate the data so that it becomes appropriate
    for later functions to call etc,. Make sure the code to be executable and correctly
    generate the desired output in the user query.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 'SYSTEM PROMPT: According to
    the user query, expand and solidify the query into a step by step detailed instruction
    (or comment) on how to write python code to fulfill the user query’s requirements.
    Import the appropriate libraries. Pinpoint the correct library functions to call
    and set each parameter in every function call accordingly. USER PROMPT: Here is
    the user query: [User Query]: """ {{query}} """ You should understand what the
    query’s requirements are, and output step by step, detailed instructions on how
    to use python code to fulfill these requirements. Include what libraries to import,
    what library functions to call, how to set the parameters in each function correctly,
    how to prepare the data, how to manipulate the data so that it becomes appropriate
    for later functions to call etc,. Make sure the code to be executable and correctly
    generate the desired output in the user query.'
- en: 'Figure 7: The query expansion prompt in MatPlotAgent.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '图 7: MatPlotAgent 中的查询扩展提示。'
- en: 'SYSTEM
    PROMPT: You are a cutting-edge super capable code generation LLM. You will be
    given a natural language query, generate a runnable python code to satisfy all
    the requirements in the query. You can use any python library you want. When you
    complete a plot, remember to save it to a png file. USER PROMPT: Here is the query:
    """ {{query}} """ If the query requires data manipulation from a csv file, process
    the data from the csv file and draw the plot in one piece of code. When you complete
    a plot, remember to save it to a png file. The file name should be """{{file_name}}""".'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 'SYSTEM
    PROMPT: You are a cutting-edge super capable code generation LLM. You will be
    given a natural language query, generate a runnable python code to satisfy all
    the requirements in the query. You can use any python library you want. When you
    complete a plot, remember to save it to a png file. USER PROMPT: Here is the query:
    """ {{query}} """ If the query requires data manipulation from a csv file, process
    the data from the csv file and draw the plot in one piece of code. When you complete
    a plot, remember to save it to a png file. The file name should be """{{file_name}}""".'
- en: 'Figure 8: The code generation prompt in MatPlotAgent.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '图 8: MatPlotAgent 中的代码生成提示。'
- en: 'USER PROMPT: There are some
    errors in the code you gave: {{error_message}} please correct the errors. Then
    give the complete code and don’t omit anything even though you have given it in
    the above code.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 'USER PROMPT: There are some
    errors in the code you gave: {{error_message}} please correct the errors. Then
    give the complete code and don’t omit anything even though you have given it in
    the above code.'
- en: 'Figure 9: The self-debugging prompt in MatPlotAgent.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '图 9: MatPlotAgent 中的自我调试提示。'
- en: 'SYSTEM
    PROMPT: Given a user query and an image of the current plot, please determine
    whether the plot has faithfully followed the user query. Your task is to provide
    instruction to make sure the plot has strictly completed the requirements of the
    query. Please output a detailed step by step instruction on how to use python
    code to enhance the plot. USER PROMPT: Here is the user query: [Query]: """ {{query}}
    """ Carefully read and analyze the user query to understand the specific requirements.
    Check if the plot aligns with the user query in terms of data selection, plot
    type, and any specific customization. Look at the provided image of the plot.
    Assess the plot type, the data it represents, labels, titles, colors, and any
    other visual elements. Compare these elements with the requirements specified
    in the user query. Note any differences between the user query requirements and
    the current plot. Based on the identified discrepancies, provide step-by-step
    instructions on how to modify the Python code to meet the user query requirements.
    Suggest improvements for better visualization practices, such as clarity, readability,
    and aesthetics, while ensuring the primary focus is on meeting the user’s specified
    requirements. Remember to save the plot to a png file. The file name should be
    """{{file_name}}"""'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 'SYSTEM
    PROMPT: Given a user query and an image of the current plot, please determine
    whether the plot has faithfully followed the user query. Your task is to provide
    instruction to make sure the plot has strictly completed the requirements of the
    query. Please output a detailed step by step instruction on how to use python
    code to enhance the plot. USER PROMPT: Here is the user query: [Query]: """ {{query}}
    """ Carefully read and analyze the user query to understand the specific requirements.
    Check if the plot aligns with the user query in terms of data selection, plot
    type, and any specific customization. Look at the provided image of the plot.
    Assess the plot type, the data it represents, labels, titles, colors, and any
    other visual elements. Compare these elements with the requirements specified
    in the user query. Note any differences between the user query requirements and
    the current plot. Based on the identified discrepancies, provide step-by-step
    instructions on how to modify the Python code to meet the user query requirements.
    Suggest improvements for better visualization practices, such as clarity, readability,
    and aesthetics, while ensuring the primary focus is on meeting the user’s specified
    requirements. Remember to save the plot to a png file. The file name should be
    """{{file_name}}"""'
- en: 'Figure 10: Prompt for the visual agent.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '图 10: 视觉代理的提示。'
- en: Appendix B Human Evaluation Details
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 人类评估细节
- en: We engage human annotators from computer science departments at various universities
    via social media. They are compensated for their work at a rate slightly higher
    than the prevailing market rate. All human annotators involved are informed that
    the collected data will be used solely for academic research purposes, and their
    personal information will not be disclosed.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过社交媒体从各大学计算机科学系聘请人类标注员。他们的报酬略高于市场普遍水平。所有参与的标注员均被告知所收集的数据仅用于学术研究，个人信息不会被披露。
- en: B.1 Evaluation Guide for Human Annotators
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.1 人类标注员评估指南
- en: 'Figure [11](#A2.F11 "Figure 11 ‣ B.1 Evaluation Guide for Human Annotators
    ‣ Appendix B Human Evaluation Details ‣ MatPlotAgent: Method and Evaluation for
    LLM-Based Agentic Scientific Data Visualization") gives detailed instructions
    for human annotators when scoring the model-generated plots.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '图[11](#A2.F11 "图 11 ‣ B.1 人类标注员评估指南 ‣ 附录 B 人类评估细节 ‣ MatPlotAgent: 基于 LLM 的代理科学数据可视化的方法和评估")提供了人类标注员在评分模型生成的图形时的详细说明。'
- en: 'Evaluation
    Guide Plot Correctness (0-100 points)
    • Exact Match (90-100 points): The generated plot is nearly identical to the ground
    truth, with only minor, negligible differences. • High Resemblance (70-89 points):
    The generated plot closely resembles the ground truth with some small but noticeable
    differences in data representation or styling. • Moderate Resemblance (50-69 points):
    The generated plot has a moderate level of similarity to the ground truth, but
    there are several noticeable differences that impact the plot’s accuracy or interpretation.
    • Low Resemblance (30-49 points): The generated plot shares some similarities
    with the ground truth but has significant differences that change the overall
    message or interpretation of the data. • Poor Match (10-29 points): The generated
    plot has very little in common with the ground truth, with major discrepancies
    in data representation. • No Resemblance (1-9 points): The generated plot is completely
    different from the ground truth, with no discernible similarities in data representation.
    • Failure to Generate (0 points): The first figure is blank, indicating a failure
    to generate any plot. Special Considerations • In cases where the generated plot
    includes random data points that are correct in the context of the query, the
    plot should be evaluated for its correctness based on the query’s intent, not
    solely on its visual match to the ground truth. [FINAL SCORE]: XX'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 'Evaluation
    Guide Plot Correctness (0-100 points)
    • Exact Match (90-100 points): The generated plot is nearly identical to the ground
    truth, with only minor, negligible differences. • High Resemblance (70-89 points):
    The generated plot closely resembles the ground truth with some small but noticeable
    differences in data representation or styling. • Moderate Resemblance (50-69 points):
    The generated plot has a moderate level of similarity to the ground truth, but
    there are several noticeable differences that impact the plot’s accuracy or interpretation.
    • Low Resemblance (30-49 points): The generated plot shares some similarities
    with the ground truth but has significant differences that change the overall
    message or interpretation of the data. • Poor Match (10-29 points): The generated
    plot has very little in common with the ground truth, with major discrepancies
    in data representation. • No Resemblance (1-9 points): The generated plot is completely
    different from the ground truth, with no discernible similarities in data representation.
    • Failure to Generate (0 points): The first figure is blank, indicating a failure
    to generate any plot. Special Considerations • In cases where the generated plot
    includes random data points that are correct in the context of the query, the
    plot should be evaluated for its correctness based on the query’s intent, not
    solely on its visual match to the ground truth. [FINAL SCORE]: XX'
- en: 'Figure 11: Evaluation guide for human annotators when scoring the model-generated
    plots.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '图 11: 人类标注员在评分模型生成的图形时的评估指南。'
