<!--yml

分类：未分类

日期：2025-01-11 12:58:44

-->

# 个人LLM代理：关于能力、效率与安全性的洞察与调研

> 来源：[https://arxiv.org/html/2401.05459/](https://arxiv.org/html/2401.05459/)

李远春¹^†、温浩¹^‡、王伟君¹^‡、李向宇¹^‡、袁逸臻¹^‡、刘国宏¹^‡、

刘家成¹、徐文星¹、王翔¹、孙怡¹、孔瑞¹、王一乐¹、耿翰飞¹，

阮建²、金学峰³、叶子龙⁴、熊冠京⁵、张帆⁶、李翔⁷，

徐孟伟⁸、李志军⁹、李鹏¹、刘扬¹、张亚勤¹、刘云欣¹

¹ 清华大学人工智能产业研究院（AIR）

² 小米人工智能实验室   ³ 华为技术有限公司   ⁴ 深圳嘿拓科技有限公司

⁵ vivo人工智能实验室   ⁶ 云米科技有限公司   ⁷ 理想汽车有限公司

⁸ 北京邮电大学   ⁹ 苏州大学

^† 项目负责人     ^‡ 部门负责人

联系方式：liyuanchun@air.tsinghua.edu.cn

网站：[https://github.com/MobileLLM/Personal_LLM_Agents_Survey](https://github.com/MobileLLM/Personal_LLM_Agents_Survey)

###### 摘要

自个人计算设备问世以来，智能个人助手（IPA）一直是研究人员和工程师关注的关键技术之一，旨在帮助用户高效获取信息和执行任务，并为用户提供更加智能、便捷和丰富的互动体验。随着智能手机和物联网的发展，计算和感知设备已经无处不在，极大地扩展了IPA的功能边界。然而，由于缺乏诸如用户意图理解、任务规划、工具使用和个人数据管理等能力，现有的IPA在实用性和可扩展性方面仍然有限。

最近，以大型语言模型（LLM）为代表的基础模型的出现，为IPA的发展带来了新的机遇。借助强大的语义理解和推理能力，LLM可以使智能代理自主解决复杂问题。本文聚焦于*个人LLM代理*，即基于LLM的代理，深度集成个人数据和个人设备，用于个人助理服务。我们预见，个人LLM代理将在即将到来的时代成为终端用户的主要软件范式。为了实现这一愿景，我们迈出了第一步，讨论了关于个人LLM代理的几个重要问题，包括其架构、能力、效率和安全性。我们首先总结了个人LLM代理架构中的关键组成部分和设计选择，随后深入分析了从领域专家收集的意见。接着，我们讨论了实现智能、高效、安全的个人LLM代理面临的几个关键挑战，并对解决这些挑战的代表性方案进行了全面的调研。

*关键词* 智能个人助手  $\cdot$ 大型语言模型  $\cdot$ LLM代理  $\cdot$ 移动设备  $\cdot$ 智能水平  $\cdot$ 任务自动化  $\cdot$ 感知  $\cdot$ 记忆  $\cdot$ 效率  $\cdot$ 安全与隐私

###### 内容

1.  [1 引言](https://arxiv.org/html/2401.05459v2#S1 "在个人LLM代理：能力、效率与安全性的洞察与调查")

1.  [2 智能个人助手的简史](https://arxiv.org/html/2401.05459v2#S2 "在个人LLM代理：能力、效率与安全性的洞察与调查")

    1.  [2.1 智能个人助手历史的时间线视角](https://arxiv.org/html/2401.05459v2#S2.SS1 "在2 智能个人助手的简史 ‣ 个人LLM代理：能力、效率与安全性的洞察与调查")

    1.  [2.2 智能个人助手历史的技术视角](https://arxiv.org/html/2401.05459v2#S2.SS2 "在2 智能个人助手的简史 ‣ 个人LLM代理：能力、效率与安全性的洞察与调查")

        1.  [2.2.1 基于模板的编程](https://arxiv.org/html/2401.05459v2#S2.SS2.SSS1 "在2.2 智能个人助手历史的技术视角 ‣ 2 智能个人助手的简史 ‣ 个人LLM代理：能力、效率与安全性的洞察与调查")

        1.  [2.2.2 监督学习方法](https://arxiv.org/html/2401.05459v2#S2.SS2.SSS2 "在2.2 智能个人助手历史的技术视角 ‣ 2 智能个人助手的简史 ‣ 个人LLM代理：能力、效率与安全性的洞察与调查")

        1.  [2.2.3 强化学习方法](https://arxiv.org/html/2401.05459v2#S2.SS2.SSS3 "在2.2 智能个人助手历史的技术视角 ‣ 2 智能个人助手的简史 ‣ 个人LLM代理：能力、效率与安全性的洞察与调查")

        1.  [2.2.4 基础模型的早期应用](https://arxiv.org/html/2401.05459v2#S2.SS2.SSS4 "在2.2 智能个人助手历史的技术视角 ‣ 2 智能个人助手的简史 ‣ 个人LLM代理：能力、效率与安全性的洞察与调查")

1.  [3 个人LLM代理：定义与洞察](https://arxiv.org/html/2401.05459v2#S3 "在个人LLM代理：能力、效率与安全性的洞察与调查")

    1.  [3.1 关键组件](https://arxiv.org/html/2401.05459v2#S3.SS1 "在3 个人LLM代理：定义与洞察 ‣ 个人LLM代理：能力、效率与安全性的洞察与调查")

    1.  [3.2 个人LLM代理的智能水平](https://arxiv.org/html/2401.05459v2#S3.SS2 "在3 个人LLM代理：定义与洞察 ‣ 个人LLM代理：能力、效率与安全性的洞察与调查")

    1.  [3.3 关于常见问题的意见](https://arxiv.org/html/2401.05459v2#S3.SS3 "在 3 个人 LLM 代理：定义与洞察 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

1.  [4 基本能力](https://arxiv.org/html/2401.05459v2#S4 "在 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

    1.  [4.1 任务执行](https://arxiv.org/html/2401.05459v2#S4.SS1 "在 4 基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [4.1.1 任务自动化方法](https://arxiv.org/html/2401.05459v2#S4.SS1.SSS1 "在 4.1 任务执行 ‣ 4 基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [4.1.2 自主代理框架](https://arxiv.org/html/2401.05459v2#S4.SS1.SSS2 "在 4.1 任务执行 ‣ 4 基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [4.1.3 评估](https://arxiv.org/html/2401.05459v2#S4.SS1.SSS3 "在 4.1 任务执行 ‣ 4 基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

    1.  [4.2 上下文感知](https://arxiv.org/html/2401.05459v2#S4.SS2 "在 4 基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [4.2.1 感知来源](https://arxiv.org/html/2401.05459v2#S4.SS2.SSS1 "在 4.2 上下文感知 ‣ 4 基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [4.2.2 感知目标](https://arxiv.org/html/2401.05459v2#S4.SS2.SSS2 "在 4.2 上下文感知 ‣ 4 基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

    1.  [4.3 记忆](https://arxiv.org/html/2401.05459v2#S4.SS3 "在 4 基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [4.3.1 获取记忆](https://arxiv.org/html/2401.05459v2#S4.SS3.SSS1 "在 4.3 记忆 ‣ 4 基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [4.3.2 管理与利用记忆](https://arxiv.org/html/2401.05459v2#S4.SS3.SSS2 "在 4.3 记忆 ‣ 4 基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

1.  [5 效率](https://arxiv.org/html/2401.05459v2#S5 "在 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

    1.  [5.1 高效推理](https://arxiv.org/html/2401.05459v2#S5.SS1 "在 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [5.1.1 模型压缩](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS1 "在 5.1 高效推理 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [5.1.2 推理加速](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS2 "在 5.1 高效推理 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [5.1.3 内存减少](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS3 "在 5.1 高效推理 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [5.1.4 能源优化](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS4 "在 5.1 高效推理 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

    1.  [5.2 高效定制](https://arxiv.org/html/2401.05459v2#S5.SS2 "在 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [5.2.1 上下文加载效率](https://arxiv.org/html/2401.05459v2#S5.SS2.SSS1 "在 5.2 高效定制 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [5.2.2 微调效率](https://arxiv.org/html/2401.05459v2#S5.SS2.SSS2 "在 5.2 高效定制 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

    1.  [5.3 高效内存操作](https://arxiv.org/html/2401.05459v2#S5.SS3 "在 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [5.3.1 搜索效率](https://arxiv.org/html/2401.05459v2#S5.SS3.SSS1 "在 5.3 高效内存操作 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [5.3.2 工作流优化](https://arxiv.org/html/2401.05459v2#S5.SS3.SSS2 "在 5.3 高效内存操作 ‣ 5 效率 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

1.  [6 安全与隐私](https://arxiv.org/html/2401.05459v2#S6 "在 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

    1.  [6.1 保密性](https://arxiv.org/html/2401.05459v2#S6.SS1 "在 6 安全与隐私 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [6.1.1 本地处理](https://arxiv.org/html/2401.05459v2#S6.SS1.SSS1 "在 6.1 保密性 ‣ 6 安全与隐私 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [6.1.2 安全远程处理](https://arxiv.org/html/2401.05459v2#S6.SS1.SSS2 "在 6.1 保密性 ‣ 6 安全与隐私 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [6.1.3 数据掩码](https://arxiv.org/html/2401.05459v2#S6.SS1.SSS3 "在 6.1 保密性 ‣ 6 安全与隐私 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")

        1.  [6.1.4 信息流控制](https://arxiv.org/html/2401.05459v2#S6.SS1.SSS4 "在 6.1 保密性 ‣ 6 安全与隐私 ‣ 个人LLM代理：关于能力、效率与安全性的洞察与调查")

    1.  [6.2 完整性](https://arxiv.org/html/2401.05459v2#S6.SS2 "在 6 安全与隐私 ‣ 个人LLM代理：关于能力、效率与安全性的洞察与调查")

        1.  [6.2.1 对抗攻击](https://arxiv.org/html/2401.05459v2#S6.SS2.SSS1 "在 6.2 完整性 ‣ 6 安全与隐私 ‣ 个人LLM代理：关于能力、效率与安全性的洞察与调查")

        1.  [6.2.2 后门攻击](https://arxiv.org/html/2401.05459v2#S6.SS2.SSS2 "在 6.2 完整性 ‣ 6 安全与隐私 ‣ 个人LLM代理：关于能力、效率与安全性的洞察与调查")

        1.  [6.2.3 提示注入攻击](https://arxiv.org/html/2401.05459v2#S6.SS2.SSS3 "在 6.2 完整性 ‣ 6 安全与隐私 ‣ 个人LLM代理：关于能力、效率与安全性的洞察与调查")

    1.  [6.3 可靠性](https://arxiv.org/html/2401.05459v2#S6.SS3 "在 6 安全与隐私 ‣ 个人LLM代理：关于能力、效率与安全性的洞察与调查")

        1.  [6.3.1 问题](https://arxiv.org/html/2401.05459v2#S6.SS3.SSS1 "在 6.3 可靠性 ‣ 6 安全与隐私 ‣ 个人LLM代理：关于能力、效率与安全性的洞察与调查")

        1.  [6.3.2 改进](https://arxiv.org/html/2401.05459v2#S6.SS3.SSS2 "在 6.3 可靠性 ‣ 6 安全与隐私 ‣ 个人LLM代理：关于能力、效率与安全性的洞察与调查")

        1.  [6.3.3 检查](https://arxiv.org/html/2401.05459v2#S6.SS3.SSS3 "在 6.3 可靠性 ‣ 6 安全与隐私 ‣ 个人LLM代理：关于能力、效率与安全性的洞察与调查")

1.  [7 结论与展望](https://arxiv.org/html/2401.05459v2#S7 "在 个人LLM代理：关于能力、效率与安全性的洞察与调查")

## 1 引言

科幻作品描绘了许多引人注目的智能个人助手（IPA）角色，这些软件代理能够增强个人能力、完成复杂任务，甚至满足情感需求。这些智能代理代表了大多数人对人工智能（AI）的幻想。随着个人设备（如智能手机、智能家居设备、电动汽车等）的普及和机器学习技术的进步，这种幻想正在逐渐变为现实。如今，许多移动设备都嵌入了IPA软件，例如Siri [[1](https://arxiv.org/html/2401.05459v2#bib.bib1)]、Google Assistant [[2](https://arxiv.org/html/2401.05459v2#bib.bib2)]、Alexa [[3](https://arxiv.org/html/2401.05459v2#bib.bib3)] 等。这些智能代理与用户深度交织，能够访问用户数据和传感器，控制各种个人设备，并访问与私人账户相关的个性化服务。

然而，今天的智能个人助手仍然受到灵活性和可扩展性限制的困扰。它们的智能水平远远不够，尤其体现在理解用户意图、推理和任务执行方面。今天的大多数智能个人助手仅限于在有限的领域内执行任务（例如，内置应用中的简单功能）。一旦用户请求超出这些范围的任务，智能助手便无法准确理解并执行相关操作。改变这一现状需要大幅扩展智能助手的能力，以支持更广泛、更灵活的任务范围。然而，目前的智能个人助手产品很难支持大规模任务。今天的大多数智能个人助手需要遵循特定的预定义规则来完成任务，例如开发者定义的步骤或用户示范的步骤。因此，开发者或用户必须明确指定他们希望支持哪些功能，并定义触发条件和任务执行步骤。这种方法本质上限制了可扩展性，因为支持更多任务需要大量的时间和劳动成本。一些方法尝试通过监督学习或强化学习自动学习支持任务[[4](https://arxiv.org/html/2401.05459v2#bib.bib4)，[5](https://arxiv.org/html/2401.05459v2#bib.bib5)，[6](https://arxiv.org/html/2401.05459v2#bib.bib6)]。然而，这些方法仍然依赖大量的手动示范和/或奖励函数的定义。

近年来，大型语言模型（LLMs）[[7](https://arxiv.org/html/2401.05459v2#bib.bib7)]的出现为智能个人助手的发展带来了全新的机会，展示了解决智能个人助手可扩展性问题的潜力。与传统方法相比，像ChatGPT、Claude等大型语言模型展示了独特的能力，如遵循指令、常识推理和零样本泛化。这些能力是通过在海量语料库（超过1.4万亿词）上进行无监督学习，并随后通过人类反馈进行微调实现的。利用这些能力，研究人员成功地采用大型语言模型赋能自主代理（即LLM代理），旨在通过自动制定计划并使用工具（如搜索引擎、代码解释器和第三方API）来解决复杂问题。

作为一种独特的智能代理类型，IPA也有可能通过LLM的革命性增强，在可扩展性、能力和实用性方面发生重大变化。我们称这种由LLM驱动的智能个人助手为个人LLM代理。与普通的LLM代理相比，个人LLM代理更多地与个人数据和移动设备互动，且更加明确地设计用于协助人类，而非替代人类。具体来说，协助用户的主要方式是减少他们日常工作中重复、繁琐、低价值的劳动，让用户能够专注于更有趣和有价值的事情，从而提升工作和生活的效率与质量。个人LLM代理可以建立在现有的软件堆栈上（例如，移动应用、网站等），同时带来全新的用户体验，具备无处不在的智能自动化能力。因此，我们预期个人LLM代理将在AI时代成为个人计算设备的主要软件范式，如图[1](https://arxiv.org/html/2401.05459v2#S1.F1 "图 1 ‣ 1 引言 ‣ 个人LLM代理：关于能力、效率和安全的洞察与调查")所示。

![参考说明](img/acc2e5149ce0e26530c9d06574b06c67.png)

图1：我们预计，个人LLM代理将在未来的时代成为个人用户主导的软件范式。

尽管个人LLM代理的前景看好，但相关研究仍处于初期阶段，面临着众多复杂性和挑战。本文迈出了第一步，讨论了实现个人LLM代理的路线图、设计选择、主要挑战以及可能的解决方案。具体来说，我们主要关注与“*个人*”部分相关的内容，包括用户个人数据的分析和利用、个人资源的使用、在个人设备上的部署以及提供个性化服务。将LLM的通用语言能力直接集成到智能个人助手（IPA）中不在本文讨论范围内。

我们首先通过对个人LLM代理领域专家进行调查来开始。我们邀请了来自领先公司的25位首席架构师、董事总经理和/或高级工程师/研究员，他们从事个人设备上的IPA和/或LLM工作。我们询问了专家们关于将LLM集成到面向消费者产品中的机会和挑战的看法。根据我们对专家见解的理解和分析，我们总结出了一个简单且通用的个人LLM代理架构，其中个人数据（用户上下文、环境状态、活动历史、个性等）和个人资源（移动应用、传感器、智能家居设备等）的智能管理和利用起着至关重要的作用。管理和利用这些个人物品的能力使得个人LLM代理的智能性有所区别。受到自动驾驶L1-L5智能水平的启发，我们还为个人LLM代理定义了五个智能水平的分类。

我们的研究结果还突出了实现此类个人LLM代理的几个主要技术挑战，这些挑战可以分为三个方面，包括基本能力、效率和安全性与隐私性。我们进一步深入探讨了这些方面，并详细解释了挑战，并对可能的解决方案进行了全面调查。具体来说，对于每个技术方面，我们简要解释了它与个人LLM代理的相关性和重要性，然后将其分解为几个主要研究问题。例如，个人LLM代理的基本能力包括任务执行、上下文感知和记忆。代理的效率主要由LLM推理效率、定制效率和记忆检索效率决定。个人LLM代理的安全性和隐私性问题可以分为数据保密性、决策可靠性和系统完整性。对于每个研究问题，我们总结了与该问题相关的主要技术，并简要介绍了相关工作。由于个人LLM代理中技术的广泛性，我们仅包括了最相关或最新的工作，而不是试图涵盖所有相关的研究方法。

本文的主要内容和贡献可以总结如下：

1.  1.

    我们总结了现有智能个人助手在产业和学术界的现状，同时分析了它们在LLM时代的主要局限性和未来趋势。

1.  2.

    我们从LLM和个人代理领域的资深专家那里收集了见解，提出了一个通用的系统架构和个人LLM代理的智能水平定义。

1.  3.

    我们回顾了关于个人LLM代理的三个重要技术方面的文献，包括基本能力、效率和安全性与隐私性。

## 2 智能个人助手的简史

图2：智能个人助手（IPA）历史上的主要里程碑。我们用不同的颜色标记不同的发展阶段，一些重要或突破性的事件用**粗体**文字突出显示。

### 2.1 智能个人助手历史的时间线视图

智能个人助手（IPA）有着悠久的发展历史。我们在图[2](https://arxiv.org/html/2401.05459v2#S2.F2 "Figure 2 ‣ 2 A Brief History of Intelligent Personal Assistants ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")中展示了IPA历史的大致时间线。其发展过程可分为四个阶段，每个阶段在图中都有不同的颜色标记。

第一阶段从1950年代持续到1980年代末，主要涉及语音识别技术的发展。语音识别的早期阶段从基本的数字和词汇开始。贝尔实验室开发了“Audrey”系统，能够识别数字0-9，准确率约为90%。1962年，IBM的高级系统开发部门实验室推出了“shoebox”[[8](https://arxiv.org/html/2401.05459v2#bib.bib8)]系统，能够识别最多16个单词。从1971年到1976年，由美国国防部资助的语音理解研究（SUR）项目显著推动了语音识别技术的发展。Harpy系统[[9](https://arxiv.org/html/2401.05459v2#bib.bib9)]尤其具有代表性，因为它能够理解由1011个单词组成的句子，相当于三岁儿童的语言能力。1986年，IBM开发了Tangora语音识别输入系统[[10](https://arxiv.org/html/2401.05459v2#bib.bib10)]，能够识别20,000个单词，并提供预测和纠错功能。Tangora系统采用了隐马尔可夫模型[[11](https://arxiv.org/html/2401.05459v2#bib.bib11)]，需要为每个说话者进行单独训练，识别语音时要求单词之间有停顿。

第二阶段涵盖了从1990年代到2000年代末的时期，因为语音识别开始被集成到软件中，用于某些高级功能。1990年，"Dragon Dictate"软件[[12](https://arxiv.org/html/2401.05459v2#bib.bib12)]发布，这是首个面向消费者的语音识别产品。它最初设计用于在Microsoft Windows上运行，支持离散语音识别。1993年，Apple推出了“Speakable items”[[13](https://arxiv.org/html/2401.05459v2#bib.bib13)]，使用户能够通过自然语音控制计算机。1996年，IBM推出了“MedSpeak”[[14](https://arxiv.org/html/2401.05459v2#bib.bib14)]，这是首个支持连续语音识别的商业产品，主要面向放射科医生。2002年，Microsoft将语音识别集成到Office应用程序中[[15](https://arxiv.org/html/2401.05459v2#bib.bib15)]，2008年，Google在iPhone上的Google Mobile App中加入了语音搜索[[16](https://arxiv.org/html/2401.05459v2#bib.bib16)]。

第三阶段从2010年代初期开始。在这一时期，始终在线的虚拟助手服务开始出现在智能手机和个人计算机等移动设备上。Siri[[1](https://arxiv.org/html/2401.05459v2#bib.bib1)]，被广泛认为是现代智能手机上安装的首个智能个人助手，于2011年集成到Apple的iPhone 4S中。自发布以来，Siri一直是Apple设备的关键内置软件，包括iPhone、iPad、Apple Watch、HomePod和Mac，并不断更新迭代，融入新功能。与Siri类似，许多其他虚拟智能助手也在这一时期开始出现。2014年，Microsoft发布了Cortana[[17](https://arxiv.org/html/2401.05459v2#bib.bib17)]，并逐步将其集成到桌面计算机和其他平台中。同年，Amazon发布了Alexa[[3](https://arxiv.org/html/2401.05459v2#bib.bib3)]，可以完成语音互动、播放音乐、设置闹钟等任务。除了语音搜索，Google Assistant[[2](https://arxiv.org/html/2401.05459v2#bib.bib2)]于2016年推出，支持用户通过语音和键盘输入进行互动。

第四阶段最近开始，当大规模语言模型（LLMs）开始引起全球关注。基于LLMs，出现了许多智能聊天机器人（例如，ChatGPT[[18](https://arxiv.org/html/2401.05459v2#bib.bib18)]），以及一些基于LLMs的智能个人助手（IPA）软件，安装在个人设备上（例如，Copilot[[19](https://arxiv.org/html/2401.05459v2#bib.bib19)]）。本阶段的详细内容将在第[2.2.4节](https://arxiv.org/html/2401.05459v2#S2.SS2.SSS4 "2.2.4 早期的基础模型应用 ‣ 2.2 智能个人助手历史的技术视角 ‣ 2 智能个人助手简史 ‣ 个人LLM代理：关于能力、效率和安全性的见解与调查")中讨论。

### 2.2 智能个人助理历史的技术视角

由于智能个人助理的智能性体现在多个方面，我们选择了智能个人助理最重要的能力之一，即任务自动化能力（遵循指令并完成任务），作为主要的研究内容。在接下来的子章节中，我们将介绍四种主要的技术类型，以实现IPA中的智能任务自动化。请注意，这些解决方案是同时发展的，它们之间没有严格的时间顺序。

#### 2.2.1 基于模板的编程

大多数商业IPA产品通过基于模板的方法支持任务自动化。在这些方法中，可以自动化的功能被预定义为模板，每个模板通常包含任务描述、相关操作、匹配的示例查询、需要完成的支持参数等内容。在接收到用户命令后，代理首先将命令映射到最相关的模板，然后按照预定义的步骤完成任务。工作流如图[3](https://arxiv.org/html/2401.05459v2#S2.F3 "Figure 3 ‣ 2.2.1 Template-based Programming ‣ 2.2 Technical View of the Intelligent Personal Assistants History ‣ 2 A Brief History of Intelligent Personal Assistants ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")所示。

在使用这种方法自动化任务时，应用程序开发者需要遵循某些API文档（例如，Google Assistant API [[2](https://arxiv.org/html/2401.05459v2#bib.bib2)]，SiriKit [[20](https://arxiv.org/html/2401.05459v2#bib.bib20)]等），为他们想要自动化的每个功能创建模板。此外，还提出了一些方法，使最终用户能够创建自己的任务模板，例如iPhone设备上的“快捷指令”[[21](https://arxiv.org/html/2401.05459v2#bib.bib21)]功能，支持自动化重复的操作序列。类似的功能也在许多产品和学术研究中实现，用于Android系统，如Tasker [[22](https://arxiv.org/html/2401.05459v2#bib.bib22)]，Anywhere [[23](https://arxiv.org/html/2401.05459v2#bib.bib23)]，Epidosite [[24](https://arxiv.org/html/2401.05459v2#bib.bib24)]和微软的uLink [[25](https://arxiv.org/html/2401.05459v2#bib.bib25)]系统等。

这种基于模板的任务自动化方法的优点在于其可靠性和准确性，因为模板中的步骤是确定性的并且经过精心编程。然而，由于支持新任务的机制相对复杂，它的可扩展性相当有限。因此，大多数应用程序，包括大公司推出的流行应用程序，都不支持任何自动化任务，或者仅支持一些基础任务，导致用户体验非常不灵活。最终用户可能在几次失败的尝试后轻易放弃使用IPA的想法[[26](https://arxiv.org/html/2401.05459v2#bib.bib26), [27](https://arxiv.org/html/2401.05459v2#bib.bib27), [28](https://arxiv.org/html/2401.05459v2#bib.bib28), [29](https://arxiv.org/html/2401.05459v2#bib.bib29)]。这一限制对基于模板的智能个人助理的进一步发展构成了重大障碍。

图3：基于模板的任务自动化工作流程。

#### 2.2.2 监督学习方法

为了克服基于模板的IPA方法的局限性，研究人员正在积极研究自动化方法，以增强用户界面的理解和自动化。监督学习提供了一种直接的任务自动化方法，通过训练模型，基于任务输入和当前状态预测后续的动作和状态。主要的研究问题包括如何学习软件GUI的表示以及如何训练交互模型。

从人类交互轨迹中学习交互模型的想法在《Humanoid》[[30](https://arxiv.org/html/2401.05459v2#bib.bib30)]中提出，旨在根据GUI布局信息生成类人化的测试输入。Seq2act [[4](https://arxiv.org/html/2401.05459v2#bib.bib4)]首次关注于移动UI任务自动化领域，在该领域中，自然语言指令需要映射为一系列可直接执行的动作。该框架将问题分解为动作短语提取部分和基础部分，二者均使用Transformer [[31](https://arxiv.org/html/2401.05459v2#bib.bib31)]网络。受到自然语言处理（NLP）中预训练成功的启发，ActionBert [[32](https://arxiv.org/html/2401.05459v2#bib.bib32)]通过自监督预训练增强模型对UI的理解。具体来说，为了捕捉UI切换动作的语义信息，该模型设计为输入一对UI，并输出两者及单个组件的嵌入表示。Fu等人[[33](https://arxiv.org/html/2401.05459v2#bib.bib33)]将NLP中的词语/句子概念扩展到像素词/屏幕句子。通过与视觉原子组件（像素词）进行预训练，PW2SS框架（句子变换器）能够完成各种下游GUI理解任务。为了更好地兼容移动设备上的有限资源，提出了多功能UI变换器（VUT）[[34](https://arxiv.org/html/2401.05459v2#bib.bib34)]，该模型能够在一个小型模型中学习不同的UI基础任务。它处理图像、结构和基于文本的数据类型，使用三个任务头同时支持执行五个不同任务，包括UI对象检测、自然语言命令基础、控件标注、屏幕总结和UI可点击性预测。基于不同模态组件之间的自对齐特性，UIBert [[35](https://arxiv.org/html/2401.05459v2#bib.bib35)]提出了一个精心设计的联合图像-文本模型来利用这种对应关系，从未标注数据中学习上下文UI嵌入。为了解决缺少UI元数据的问题，如DOM树和视图层级，SpotLight [[36](https://arxiv.org/html/2401.05459v2#bib.bib36)]通过截图和兴趣区域（“焦点”）作为输入，提出了一种仅基于视觉的移动UI理解方法。该方法由视觉编码器和语言解码器组成，可以根据提供的截图和提示完成任务。此外，Lexi [[37](https://arxiv.org/html/2401.05459v2#bib.bib37)]提出利用基于文本的说明手册和用户指南来策划多模态数据集。通过将文本和视觉特征作为输入融合到共同注意力变换器层中，模型经过预训练，能够在文本指令和UI截图之间建立连接。UINav [[38](https://arxiv.org/html/2401.05459v2#bib.bib38)]利用裁判模型评估代理的表现，并立即向用户反馈信息。它还采用了演示增强技术来增加数据的多样性。

与基于模板的方法相比，监督学习方法在充分训练后有潜力推广到未见过的任务。然而，训练模型通常需要大量高质量的人类标注数据。鉴于现实世界中任务和应用的多样性，获取涵盖各种使用案例的训练数据具有挑战性。

#### 2.2.3 强化学习方法

与需要大量训练样本的基于监督学习的任务自动化方法不同，基于强化学习（RL）的方法通过与目标界面不断交互，使代理能够获得任务自动化的能力。在交互过程中，代理会得到表示任务完成进展的奖励反馈，并通过最大化奖励收益逐步学习如何自动化任务。

为了训练基于强化学习（RL）的任务自动化代理，需要一个奖励函数来指示任务完成的进展。World of Bits（WoB）[[39](https://arxiv.org/html/2401.05459v2#bib.bib39)] 被提出作为一个通用平台，使代理可以使用键盘和鼠标在网页上完成任务。该平台提供了一个基准测试，称为“MiniWoB”，其中包含在一组自创的玩具网站上进行的任务，并设有预定义的奖励。Glider [[5](https://arxiv.org/html/2401.05459v2#bib.bib5)] 为真实世界的网站定义了奖励函数，该函数基于任务描述与UI操作序列之间的语义相似性，以及操作序列的局部性和方向性。

基于RL的任务自动化的另一个挑战是庞大的动作空间和稀疏的奖励。典型的基于GUI的任务通常包含$5$-$10$个步骤，每个步骤有$10$-$100$个候选动作，导致搜索空间的大小为$10^{5}$-$100^{10}$。任务只有在采取正确的动作序列时才能完成。为了应对这一挑战，提出了许多框架。Liu等人[[6](https://arxiv.org/html/2401.05459v2#bib.bib6)]提出了一种使用高级“工作流”来约束每个时间步允许的动作的方法。工作流可以剪枝掉不良的探索方向，加速代理发现奖励的能力。Gur等人[[40](https://arxiv.org/html/2401.05459v2#bib.bib40)]将复杂的指令分解为多个较小的指令，并为代理安排了一个课程，逐渐让其学会跟随越来越多的子指令。此外，还提出了一种元学习框架来生成跟随指令的任务。Jia等人[[41](https://arxiv.org/html/2401.05459v2#bib.bib41)]将代理在网页上的动作框架分为三个不同的类别，即DOM选择、标记选择和模式选择。此外，还设计了一种因子化的Q值函数，假设DOM选择和标记选择是独立的。Glider [[5](https://arxiv.org/html/2401.05459v2#bib.bib5)]通过分层策略实现了减少动作空间的目标，该策略包含一个主策略用于处理总体导航，和一些子策略来处理特定的小部件。Humphreys等人[[42](https://arxiv.org/html/2401.05459v2#bib.bib42)]提出了一种框架，直接使用鼠标和键盘完成任务，而不是依赖于专门的动作空间，这简化了使用实际人机交互信息的行为先验。

类似于监督学习方法，基于强化学习（RL）的方法也存在泛化能力差的问题。为了实现灵活且稳健的任务自动化，RL代理需要在大量任务上进行训练，每个任务都需要一个精心设计的奖励函数。为大量不同任务定义奖励函数可能会很困难。

#### 2.2.4 基础模型的早期应用

最近几年，以大型语言模型（LLMs）为代表的预训练大型基础模型经历了快速发展，并为个人助手带来了新的机遇。

语言模型的规模定律[[43](https://arxiv.org/html/2401.05459v2#bib.bib43)]揭示了增加模型参数对于提高模型性能的重要性，随后出现了大量拥有数十亿参数的模型。大型语言模型（LLM）通常使用大规模的开放域文本数据进行无监督训练，之后进行指令微调[[44](https://arxiv.org/html/2401.05459v2#bib.bib44)]以及通过人类反馈的强化学习（RLHF）[[45](https://arxiv.org/html/2401.05459v2#bib.bib45), [44](https://arxiv.org/html/2401.05459v2#bib.bib44)]来提升性能和对齐度。由OpenAI在2022年底推出的ChatGPT[[18](https://arxiv.org/html/2401.05459v2#bib.bib18)]是LLM的一个里程碑，展示了惊人的问答能力。通过将简单的任务描述作为输入提示，LLM的任务和响应可以轻松定制。此外，这些模型还展示了在各种语言理解和推理任务中的强大泛化能力。ChatGPT本身可以视为一个智能个人助手，通过返回文本响应来帮助用户获取信息。

受到LLM能力的启发，研究人员尝试让LLM自主使用工具[[46](https://arxiv.org/html/2401.05459v2#bib.bib46)]来完成复杂任务。例如，控制浏览器[[47](https://arxiv.org/html/2401.05459v2#bib.bib47), [48](https://arxiv.org/html/2401.05459v2#bib.bib48)]进行信息检索和摘要，调用机器人编程接口进行机器人行为控制[[49](https://arxiv.org/html/2401.05459v2#bib.bib49), [50](https://arxiv.org/html/2401.05459v2#bib.bib50), [51](https://arxiv.org/html/2401.05459v2#bib.bib51)]，以及调用代码解释器进行复杂数据处理[[52](https://arxiv.org/html/2401.05459v2#bib.bib52), [53](https://arxiv.org/html/2401.05459v2#bib.bib53), [54](https://arxiv.org/html/2401.05459v2#bib.bib54), [55](https://arxiv.org/html/2401.05459v2#bib.bib55)]，等等。将这些能力整合到智能个人助手中，以便更智能地操作个人数据、个人设备和个性化服务，是一个自然的构想。

已经有一些商业产品尝试将LLM与IPA（智能个人助手）结合。例如，微软的Copilot系统[[19](https://arxiv.org/html/2401.05459v2#bib.bib19)]已经整合了GPT-4的能力[[56](https://arxiv.org/html/2401.05459v2#bib.bib56)]，帮助Windows用户自动起草文档、创建演示文稿、总结电子邮件，从而提高用户的工作效率。新的Bing [[57](https://arxiv.org/html/2401.05459v2#bib.bib57)]也改善了上网体验，提供了一个强大高效的搜索引擎，更好地理解用户的需求。类似地，谷歌将LLM（Bard [[58](https://arxiv.org/html/2401.05459v2#bib.bib58)]，Gemini [[59](https://arxiv.org/html/2401.05459v2#bib.bib59)]）集成到搜索引擎中，以实现更加便捷的网页搜索体验。包括华为、小米、OPPO、Vivo在内的智能手机公司也将大规模模型（如PanGu [[60](https://arxiv.org/html/2401.05459v2#bib.bib60)]、MiLM [[61](https://arxiv.org/html/2401.05459v2#bib.bib61)]等）集成到其设备端的IPA产品中。值得注意的是，其中一些公司采用了基于本地部署轻量级LLM的解决方案。到目前为止，这些商业产品大多数仅是将LLM的聊天界面简单集成到个人助手中。关于更深层次的功能集成研究将在第[4.1节](https://arxiv.org/html/2401.05459v2#S4.SS1 "4.1 Task Execution ‣ 4 Fundamental Capabilities ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")中讨论。

尽管展现出巨大的潜力，这一研究方向目前仍处于早期探索阶段。距离真正理解并通过智能代理协助用户的最终目标仍有相当大的距离。更重要的是，许多与效率、安全性和隐私相关的问题尚未得到充分解决。本文的后续部分将系统地总结并讨论这一方向中的关键问题。

## 3 个人LLM代理：定义与洞察

目睹基于LLM的智能个人助手的巨大潜力以及学术界和工业界的广泛兴趣，我们迈出了第一步，系统地讨论与这一方向相关的机会、挑战和技术。

我们将个人LLM代理定义为一种特殊类型的基于LLM的代理，它与个人数据、个人设备和个人服务深度集成。个人LLM代理的主要目的是帮助最终用户，减少重复且繁琐的工作，让他们能更专注于有趣和重要的事务。根据这一定义，通用的自动化方法（如提示、规划、自我反思等）与普通的基于LLM的代理类似。我们关注的重点是与“个人”部分相关的方面，例如个人数据的管理、智能手机应用的使用、部署到资源受限的个人设备等。

我们预见，个人LLM代理将在LLM时代成为个人设备的主要软件范式。然而，个人LLM代理的软件栈和生态系统仍处于非常早期的阶段。与系统设计和实现相关的许多重要问题仍然不清楚。

因此，我们尝试基于从领域专家收集到的洞察来解决一些问题。具体来说，我们邀请了来自8家领先公司、从事IPA相关产品工作的25位专家，他们是首席架构师、总经理或高级工程师/研究员，包括智能手机个人助手、智能家居解决方案和智能驾驶舱系统。我们与他们就个人LLM代理的相关话题进行了非正式交流，并问了他们一些常见问题，涵盖了从应用场景到部署挑战的各个方面。根据我们的讨论和收集到的回答，我们将洞察总结为三个子部分，包括个人LLM代理的关键组成部分、智能水平的分类法，以及专家对于常见问题的看法。

### 3.1 关键组成部分

基于我们对个人LLM代理所需功能的讨论，我们首先总结了支持这些功能的主要组件，如图[4](https://arxiv.org/html/2401.05459v2#S3.F4 "图 4 ‣ 3.1 关键组成部分 ‣ 3 个人LLM代理：定义与洞察 ‣ 个人LLM代理：关于能力、效率和安全性的洞察与调查")所示。

![参见说明](img/6c7bc2d9d095283f5ad4e4456a4faf76.png)

图 4：个人LLM代理的主要组成部分。

毋庸置疑，个人LLM代理的核心是基础模型（大语言模型或其他变体，简便起见我们称其为LLM），它连接着所有其他组件。首先，LLM是支持不同技能以服务用户的基础，包括直接执行任务的响应技能（如问答、天气查询、事件安排等）和在没有明确用户指令的情况下提供服务的主动技能（如生活记录、管理用户注意力、活动推荐等）。

其次，为了支持这些技能，LLM管理各种本地资源，包括移动应用程序、传感器和物联网设备。例如，代理可能通过与智能手机天气应用的交互来完成天气查询。同时，许多人提到了个人LLM代理在提供个性化和上下文感知服务方面的重要性。因此，LLM应当维护有关用户的信息，包括当前用户上下文（状态、活动、位置等）和历史用户记忆（个人资料、日志、个性等）。为了操作这些资源、上下文和记忆，理想情况下需要使用专门的管理系统，如向量数据库，并与LLM结合使用。

这些关键组件的组合类似于操作系统[[62](https://arxiv.org/html/2401.05459v2#bib.bib62)]，其中：

1.  1.

    基础模型就像传统操作系统中的内核。它用于系统化地管理和调度各种资源，从而促进代理的功能。

1.  2.

    本地资源层类似于传统操作系统中的驱动程序。在传统操作系统中，每个驱动程序管理一组专门的硬件。而在个人LLM代理中，每个本地资源组件管理一种工具类型，并为LLM提供可供使用的API。

1.  3.

    用户上下文和用户记忆对应于系统操作过程中维护的程序上下文和系统日志。这些组件构成了代理支持个性化服务的基础。

1.  4.

    最上层的技能类似于传统操作系统中的软件应用程序。与应用程序的安装和卸载类似，代理的技能也应该能够灵活启用或禁用。

### 3.2 个人LLM代理的智能水平

个人LLM代理所需的特性需要不同种类的能力。受自动驾驶的六个级别启发，我们将个人LLM代理的智能水平分为五个级别，标记为L1到L5，如图[5](https://arxiv.org/html/2401.05459v2#S3.F5 "Figure 5 ‣ 3.2 Intelligence Levels of Personal LLM Agents ‣ 3 Personal LLM Agents: Definition & Insights ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")所示。每个级别的关键特性和代表性用例列在表[1](https://arxiv.org/html/2401.05459v2#S3.T1 "Table 1 ‣ 3.2 Intelligence Levels of Personal LLM Agents ‣ 3 Personal LLM Agents: Definition & Insights ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")中。

图5：个人LLM代理在不同智能水平下的职责。

表1：个人LLM代理的不同智能水平。

| 级别 | 关键特性 | 代表性用例 |
| --- | --- | --- |

| L1 - 简单步骤跟随 | 代理通过按照用户或开发者预定义的*准确步骤*来完成任务。 | - 用户：“打开 Messenger”；代理打开名为 Messenger 的应用。 - 用户：“打开我的邮箱中第一封未读邮件并阅读其内容”；代理逐步执行该命令。

- 用户：“给 Alice 打电话”；代理匹配开发者定义的模板，在通讯录中找到 Alice 的电话号码并拨打。 |

| L2 - 确定性任务自动化 | 根据用户对确定性任务的描述，代理在预定义的操作空间中*自动完成*必要步骤。 | - 用户：“查看今天北京的天气”；代理自动调用天气 API，并传入“北京”参数，解析响应中的信息。 - 用户：“给 Alice 打视频电话”；代理自动打开通讯录，找到 Alice 的联系方式，点击“视频通话”。

- 用户：“告诉机器人吸尘器今晚打扫房间”；代理打开机器人吸尘器应用，点击“日程安排”，并设置时间为今晚。 |

| L3 - 战略任务自动化 | 根据用户指定的任务，代理利用各种资源和工具*自主规划*执行步骤，并根据中间反馈*迭代*计划，直到完成。 | - 用户：“告诉 Alice 我的明天的日程安排”；代理从用户的日历和聊天记录中收集明天的日程信息，然后总结并通过 Messenger 发送给 Alice。 - 用户：“找出最近适合旅游的城市”；代理列出几个适合旅游的城市，检查每个城市的天气，总结信息并返回推荐。

- 用户：“记录我今晚的睡眠质量”；代理每 10 分钟检查一次用户在睡眠期间是否在使用手机、是否有移动或打鼾（基于智能手机传感器和麦克风），总结信息并生成报告。 |

| L4 - 记忆和上下文感知 | 代理感知用户的上下文，理解用户的记忆，并在适当的时机主动提供*个性化*服务。 | - 代理根据用户最近的收入和支出，考虑用户的个性和风险偏好，自动推荐适合的金融产品。 - 代理根据用户的对话和行为，估计用户最近的焦虑水平，推荐电影/音乐帮助放松，并根据焦虑程度通知用户的朋友或医生。

- 当用户在浴室摔倒时，代理检测到事件，并根据用户的年龄和身体状况决定是否询问用户、通知用户的家人或拨打紧急电话。 |

| L5 - 自主化虚拟形象 | 代理人*完全代表*用户完成复杂事务，可以代表用户与其他用户或代理人互动，确保*安全*和*可靠性*。 | - 代理人自动读取用户的电子邮件和消息，自动回复问题，无需用户干预，并将其总结为摘要。 - 代理人代表用户参加工作讨论会议，依据用户的工作日志表达意见，听取建议，并撰写会议纪要。

- 代理人记录用户的日常饮食和活动，私下研究或向专家请教任何异常情况，并提出健康改进建议。 |

在每个级别上，用户和代理人负责不同的职责。在第 1 级（简单步骤跟随）中，代理人只负责执行步骤，其他职责由用户负责。例如，当用户发出命令时，代理人按照开发者或用户给定的明确步骤来完成任务。L1 级代理人没有感知或计划的能力。大多数基于模板的 IPA 产品属于这一类别。

随着智能级别的提升，代理人逐渐承担更多职责。在第 2 级，支持的任务仍然是确定性的（即涉及一系列固定的动作来完成），但执行每个任务的详细步骤不再明确给出。代理人必须根据用户的任务描述自动完成必要的步骤。例如，给定用户查询“今天北京的天气如何”，代理人使用“北京”作为参数调用天气 API，并从响应中获取天气信息。与第 2 级的确定性任务不同，第 3 级的代理人可以完成需要战略规划和自我反思的更复杂任务。例如，命令“告诉 Alice 我的明日计划”需要代理人确定如何收集日程信息（例如，使用用户的日历和聊天记录）以及如何通知 Alice 信息（例如，汇总日程事件并通过消息应用发送）。在这些任务中，代理人根据中间反馈自主并迭代生成并执行计划，直到完成任务。

L1-L3 级别的代理人被用户的命令被动驱动，而 4 级的代理人可以理解用户的历史数据，感知当前状况，并在适当的时候主动提供个性化服务。

在超智能等级5下，代理扮演着自主化化身（Autonomous Avatar）的角色，能够完全代表用户完成复杂事务，从而用户只需要专注于创意和情感。代理不仅感知当前状态，还能预测用户未来的活动并采取行动来促进这些活动。除了直接服务用户外，自主化化身还可以与其他代理合作，减轻用户在沟通上的负担。此外，等级5的代理应该能够通过自我进化不断提升自身能力。

### 3.3 关于常见问题的看法

接下来，我们报告专家对若干常见问题的汇总结果。这些问题包括个人LLM代理的设计选择以及部署面临的潜在挑战，如表[2](https://arxiv.org/html/2401.05459v2#S3.T2 "表2 ‣ 3.3 关于常见问题的看法 ‣ 3 个人LLM代理：定义与见解 ‣ 个人LLM代理：关于能力、效率和安全性的见解与调查")所总结。

我们分析了问题的回答，并总结出以下主要结论。

表2：我们向领域专家询问的常见问题。在问题1到问题6中，我们提供了几种常见选项供专家选择或排序，同时也允许专家提供自由形式的回答。在问题7和问题8中，专家们被要求以文本形式回答。

| ID | 问题 |
| --- | --- |
| 1 | 如果LLM应用于个人智能代理，您认为它应该本地部署还是远程部署？ |
| 2 | 您认为应该如何实施针对不同用户或组织定制的模型？ |
| 3 | 对于部署在个人设备上的LLM，您认为需要支持哪些模态？ |
| 4 | 您认为LLM在个人LLM代理中最重要的能力是什么？ |
| 5 | 考虑到您所在的行业，您认为个人LLM代理最有前景的交互方式是什么？ |
| 6 | 在未来个人LLM代理的发展中，哪一方面最为关键？ |
| 7 | 您希望未来的个人LLM代理为您或您的客户提供哪些功能？ |
| 8 | 在将大型语言模型（LLM）与个人设备集成时，您认为会面临哪些挑战？需要解决的最紧迫的技术问题是什么？ |

意见 1（LLM的部署位置）：*边缘云（本地-远程）协同部署LLM是首选方案，而现有的仅云（远程-only）（如ChatGPT）并不是一个广泛可接受的解决方案*。如图[7](https://arxiv.org/html/2401.05459v2#S3.F7 "Figure 7 ‣ 3.3 Opinions on Common Problems ‣ 3 Personal LLM Agents: Definition & Insights ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")所示，88%的参与者倾向于边缘云协同架构，其中58.33%支持本地部署，81.82%不满意现有的仅云解决方案。他们的主要关注点是：1）远程LLM服务的高延迟，2）将个人数据传输到云端的隐私问题，3）基于云的LLM服务的巨大成本。

图 6：个人化LLM代理中不同LLM部署策略的投票分布。

图 7：个人化LLM代理的不同模型定制方法的投票分布。

意见 2（如何定制代理）：*将微调与上下文学习相结合是实现定制化的最可接受方式*。在个人化LLM代理中，为不同用户和场景定制代理被认为是必要的。图[7](https://arxiv.org/html/2401.05459v2#S3.F7 "Figure 7 ‣ 3.3 Opinions on Common Problems ‣ 3 Personal LLM Agents: Definition & Insights ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")显示，66.67%的参与者支持结合微调和上下文学习的优势来实现个性化（L4智能）。其中，43.75%的参与者认为仅通过上下文学习无法实现L4；一个可能的原因是我们的参与者来自行业，因此他们更关注用于特定垂直领域的LLM，而在这些领域中，上下文学习尚未受到广泛关注。

在问题3-5中，我们要求参与者对选项进行排名，以下表格（表格 [3](https://arxiv.org/html/2401.05459v2#S3.T3 "表格 3 ‣ 3.3 对常见问题的看法 ‣ 3 个人LLM代理：定义与见解 ‣ 个人LLM代理：关于能力、效率与安全的见解与调查")-[5](https://arxiv.org/html/2401.05459v2#S3.T5 "表格 5 ‣ 3.3 对常见问题的看法 ‣ 3 个人LLM代理：定义与见解 ‣ 个人LLM代理：关于能力、效率与安全的见解与调查")）总结了他们的排名。排名第1-4表示这些选项在参与者中投票的排名；例如，表格 [3](https://arxiv.org/html/2401.05459v2#S3.T3 "表格 3 ‣ 3.3 对常见问题的看法 ‣ 3 个人LLM代理：定义与见解 ‣ 个人LLM代理：关于能力、效率与安全的见解与调查")中72%表示文本是他们最偏好的模式。每个表格中的“得分”是基于Borda计数法计算的[[63](https://arxiv.org/html/2401.05459v2#bib.bib63)]，每个候选者获得的分数等于他们在每轮投票中超越的候选者数量的平均值，最低排名的获得$2$分，最高的获得$n+1$分，其中n为候选者总数。例如，表格 [3](https://arxiv.org/html/2401.05459v2#S3.T3 "表格 3 ‣ 3.3 对常见问题的看法 ‣ 3 个人LLM代理：定义与见解 ‣ 个人LLM代理：关于能力、效率与安全的见解与调查")中的$4.56$等于$5\times 72\%+4\times 20\%+3\times 0+2\times 8\%$。

意见3（使用哪些模式）：*多模态LLM，特别是文本和视觉模式，是个人LLM代理的理想选择。* 在我们的统计结果中，文本是最受欢迎的模式，就像目前使用最广泛的LLM（例如，GPT系列和LLaMA系列）。排名第二的图像选项以及有20%的参与者特别提到的视频模式表明，视觉模式在个人LLM代理的未来中将发挥重要作用。

表格 3：个人LLM代理中最受欢迎的模式。

| 选项 | 得分 | 排名第1 | 排名第2 | 排名第3 | 排名第4 |
| --- | --- | --- | --- | --- | --- |
| 文本 | 4.56 | 72% | 20% | 0% | 8% |
| 图像 | 3.64 | 4% | 64% | 24% | 4% |
| 语音 | 3.18 | 16% | 4% | 60% | 20% |
| 传感器 | 2.18 | 9.52% | 14.29% | 9.52% | 66.67% |

意见4（哪种LLM能力对IPA产品最为关键）：*语言理解被认为是LLM最重要的能力，而处理长上下文的能力则被认为是最不重要的能力。* 相反，在学术界，处理长上下文的能力被认为非常重要，并且广泛研究。这种不同的观点源自我们参与者设想的垂直领域LLM与学术研究者的通用LLM。在垂直领域LLM中，用户的查询和任务并不多样，因此长上下文的能力并不是那么关键。

表4：IPA产品的LLM能力重要性排名。

| 选项 | 得分 | 排名第1 | 排名第2 | 排名第3 | 排名第4 |
| --- | --- | --- | --- | --- | --- |
| 语言理解 | 4.52 | 83.33% | 8.33% | 4.17% | 4.17% |
| 上下文学习 | 3.16 | 4.55% | 50% | 45.45% | 0% |
| 常识推理 | 3 | 8.33% | 33.33% | 29.17% | 20.83% |
| 长上下文 | 1.8 | 5.56% | 11.11% | 16.67% | 61.11% |

意见5（如何与代理进行互动）：*基于语音的互动是最受欢迎的方式。* 不出所料，就像现有的虚拟助手Siri一样，模仿人类的沟通方式——语音互动是最常见和高效的选择。基于文本的聊天机器人和图形用户界面分别排名第二和第三，因为大多数参与专家专注于移动设备，如智能手机。虚拟现实仅获得了$1.52$的得分，这是所有问题中最低的；这可能源于VR设备的高价和现有VR技术的不尽如人意的用户体验。

表5：个人LLM代理的首选互动方式。

| 选项 | 得分 | 排名第1 | 排名第2 | 排名第3 | 排名第4 |
| --- | --- | --- | --- | --- | --- |
| 语音互动 | 4.04 | 60.87% | 17.39% | 21.74% | 0% |
| 文本聊天框 | 3.32 | 22.73% | 45.45% | 18.18% | 13.64% |
| 图形用户界面 | 3.24 | 23.81% | 38.1% | 38.1% | 0% |
| 虚拟现实 | 1.52 | 0% | 6.25% | 25% | 68.75% |

意见6（发展所需的代理能力）：在个人LLM代理的未来发展中，"更智能和自主的决策能力"被认为是我们参与者中最关键的特性；几乎一半的参与者（47.83%）将其排在第一位。选项"用户体验和互动方式的持续改进"和"个人数据的安全处理"也获得了大量关注，分别为36.36%和33.33%，并列第二。尽管"与物联网设备的集成"排名最后，47.63%的参与者仍然认为它作为个人LLM代理的基础设施很重要。

意见7（理想IPA的期望功能）：根据参与者的反馈，我们总结了理想代理的以下六个关键特性：

+   •

    *高效的数据管理与搜索：* 该代理作为外部大脑，通过高效的数据存储来记住用户的数据。它为用户提供快速检索和精准搜索的能力。

+   •

    *工作与生活协助:* 当用户询问技术细节时，代理人作为工作中的副驾驶提供帮助。它还可以执行重复性和繁重的任务，并为用户提供文档和内容生成服务。

+   •

    *个性化服务与推荐:* 根据用户习惯，代理人能够发现用户的潜在需求，并主动为用户提供服务。它可以作为个人和家庭健康管理者、医疗服务提供者、购物比价助手、旅行助手等。

+   •

    *自主任务规划与完成:* 代理人能够理解用户的意图，分解用户提出的任务，并自动一步步执行这些任务（进一步包括自主链式思维功能），并帮助用户完成需要手动操作的步骤，通过明确的指示。

+   •

    *情感支持与社交互动:* 代理人能够理解并通过聊天帮助用户调整情绪。它还可以理解用户与不同人的关系，并帮助他们用用户的语气撰写回应草稿。

+   •

    *数字代表及更多:* 代理人可以代表用户参加会议、驾驶汽车、上班并执行任何授权任务。它可以真正理解用户，并在当前的用户身份下与他人沟通与社交。

意见8（最紧迫的技术挑战是什么）: 根据参与者的反馈，最紧迫的挑战和技术问题被分类如下：

+   •

    *智能性.* 1) 多模态支持: LLM（大语言模型）需要理解并处理不同类型的数据（如文本、图像和视频），因此它应具备先进的数据对齐和解读能力。 2) 上下文理解与上下文感知行动: 在不同的应用场景中，LLM必须准确理解用户需求并生成相应的控制指令。这需要LLM的上下文理解能力以及将上下文转化为有效行动的能力。 3) 提升轻量级LLM的领域特定能力: 由于资源有限的个人设备上的LLM可能因为体积和复杂性限制，在复杂任务或深层次上下文理解方面表现不佳。因此，如何提升轻量级模型的能力并在特定领域处理复杂任务成为广泛关注的问题。

+   •

    *性能.* 1) 有效的LLM压缩或紧凑架构：在资源有限的移动设备上运行LLM需要平衡性能和任务完成质量。理想的解决方案是采用高效的模型压缩技术，这些技术考虑到LLM的特性，以保持任务完成的高质量。 2) 实用的本地-远程协作架构：LLM的本地-远程协作架构被认为是有前景的，旨在继承本地模型的快速/低成本响应能力以及云模型的高质量生成能力。然而，如何实现精确且高效的协作被广泛认为是一个重要挑战。

+   •

    *安全性与隐私.* 1) 数据安全和隐私保护：在使用个人数据训练和执行LLM时，确保个人数据的安全性和用户隐私的保护至关重要。这提出了迫切的需求，需要开发新的数据匿名化技术和隐私保护协议。 2) 推理准确性和无害性：确保模型输出对用户精准且无害，尤其是在用于决策或敏感场景时。

+   •

    *个性化与存储.* 个性化需要高效的数据存储解决方案来管理和利用与用户相关的数据，包括他们的偏好、历史行为和互动。

+   •

    *传统操作系统支持.* 对于基于移动设备的LLM代理，一个关键需求是LLM友好的接口以及对传统操作系统（如Android）的支持。这可能涉及操作系统层面的更新以及开发应用程序编程接口（API），以更好地集成和利用LLM的功能。

受到领域专家宝贵意见的启发，接下来的部分将更详细地讨论所需的能力和潜在的挑战。

## 4 种基本能力

我们首先讨论个人 LLM 代理所需的能力，以支持多种功能。除了普通 LLM 代理的一般能力外，我们重点关注个人助手的三项基本能力，包括任务执行、情境感知和记忆。任务执行（§[4.1](https://arxiv.org/html/2401.05459v2#S4.SS1 "4.1 任务执行 ‣ 4 基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")）是将用户的命令或主动感知的任务转化为在个人资源上执行的行动。情境感知（§[4.2](https://arxiv.org/html/2401.05459v2#S4.SS2 "4.2 情境感知 ‣ 4 基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")）的目的是感知用户和环境的当前状态，为任务执行提供全面的信息。记忆（§[4.3](https://arxiv.org/html/2401.05459v2#S4.SS3 "4.3 记忆 ‣ 4 基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查")）是记录用户数据，使代理能够回忆过去的事件、总结知识并自我进化。虽然情境感知和记忆是与从用户获取信息相关的能力，任务执行则是提供服务给用户的能力。图 [8](https://arxiv.org/html/2401.05459v2#S4.F8 "图 8 ‣ 4 基本能力 ‣ 个人 LLM 代理：关于能力、效率和安全性的洞察与调查") 展示了这些基本能力之间的关系。接下来的部分将详细讨论这些能力。

![参见说明文字](img/6e18d4bcf8a82d9cbfeaac65fd907d5f.png)

图 8：个人 LLM 代理的基本能力。

### 4.1 任务执行

任务执行是个人 LLM 代理的基本能力，使其能够响应用户请求并执行指定任务。在我们的场景中，代理被设计为与各种个人设备互动并控制，如智能手机、计算机和物联网设备，以自动执行用户的命令。

任务执行的一个基本要求是代理能够准确解读用户传达的任务。通常，任务可能来自用户的口头或书面指令，智能代理从中识别用户的意图。随着语音识别技术的成熟，将语音信息转换为文本变得非常方便 [[64](https://arxiv.org/html/2401.05459v2#bib.bib64), [65](https://arxiv.org/html/2401.05459v2#bib.bib65)]。

个人 LLM 代理应在将用户指令转换为文本后自动制定计划并采取行动。虽然传统的 DNN 在规划方面面临挑战，但基于 LLM 的代理在这方面表现得更加熟练。LLM 代理的规划和推理能力在以往的调查中已有讨论 [[66](https://arxiv.org/html/2401.05459v2#bib.bib66), [67](https://arxiv.org/html/2401.05459v2#bib.bib67), [68](https://arxiv.org/html/2401.05459v2#bib.bib68)]。我们的论文主要关注个人数据的处理和与个人设备的交互。一个重要的考虑因素是，个人 LLM 代理可能需要与缺乏全面 API 支持的应用程序或系统进行交互。因此，我们还探讨了用户界面（UI）作为个人代理的重要工具，使其能够在 API 限制存在的情况下进行有效互动。

#### 4.1.1 任务自动化方法

根据交互模式的类型，任务执行的方法可以分为基于代码和基于 UI 的两种方式。在基于代码的场景中，代理主要通过自动生成代码来调用 API 完成任务。在基于 UI 的场景中，代理通过自动模拟人与 UI 界面的交互来与个人设备进行互动。

基于代码的任务自动化通常涉及生成适当的代码来与 API、数据库和 DNN 模型进行交互。传统的基于代码的个人助手通常基于槽位填充的任务导向对话（TOD）框架。在 LLM 时代，越来越多的研究者尝试直接使用 LLM 来生成调用 API 的代码，以完成更复杂的任务。

+   •

    插槽填充方法通常用于任务导向对话系统（TOD）或聊天机器人中，这些是通过对话帮助用户完成特定任务的会话型人工智能[[69](https://arxiv.org/html/2401.05459v2#bib.bib69), [70](https://arxiv.org/html/2401.05459v2#bib.bib70)]。在任务导向对话系统中，“插槽”是完成任务所需的预定义信息类别。例如，在一个旅行预订应用中，插槽可能包括目的地、旅行日期、乘客人数等。在对话过程中，系统会提示用户提供这些信息，并调用相应的API来完成任务。对于移动设备，许多方法通过允许用户展示所需的任务来促进任务自动化，这些任务可以通过会话界面执行[[71](https://arxiv.org/html/2401.05459v2#bib.bib71), [72](https://arxiv.org/html/2401.05459v2#bib.bib72), [24](https://arxiv.org/html/2401.05459v2#bib.bib24), [25](https://arxiv.org/html/2401.05459v2#bib.bib25)]。这些方法通常假设用户的任务可以定义为一组插槽-值对。这种假设允许通过可控单元精确管理对话，执行任务的方式是不断提示用户提供尚未识别的插槽的值。然而，这些方法没有考虑到插槽有多个值或插槽之间存在关系的复杂情况[[73](https://arxiv.org/html/2401.05459v2#bib.bib73)]。此外，它们高度依赖于定义良好的API，并且缺乏对未知领域的适应性。最近的研究论文利用大型语言模型（LLM）的理解和推理能力来完成更复杂的多轮任务导向对话任务[[74](https://arxiv.org/html/2401.05459v2#bib.bib74), [75](https://arxiv.org/html/2401.05459v2#bib.bib75), [76](https://arxiv.org/html/2401.05459v2#bib.bib76), [77](https://arxiv.org/html/2401.05459v2#bib.bib77)]，并提高了插槽填充方法的效率。

+   •

    程序合成方法是利用 LLM（大语言模型）的代码生成能力与 API 进行交互。一种方法是对 LLM 进行微调，使其能够使用特定的 API。WebGPT [[47](https://arxiv.org/html/2401.05459v2#bib.bib47)] 微调了 GPT-3 [[78](https://arxiv.org/html/2401.05459v2#bib.bib78)]，通过调用 Microsoft Bing Web Search API [[79](https://arxiv.org/html/2401.05459v2#bib.bib79)] 来回答长格式的问题。一些最近的研究 [[46](https://arxiv.org/html/2401.05459v2#bib.bib46), [80](https://arxiv.org/html/2401.05459v2#bib.bib80), [81](https://arxiv.org/html/2401.05459v2#bib.bib81), [82](https://arxiv.org/html/2401.05459v2#bib.bib82)] 微调了 LLM，使其能够检索和调用 API，从而增强了它们在各种任务中的表现，例如数学推理和程序合成。Octopus V2 [[83](https://arxiv.org/html/2401.05459v2#bib.bib83)] 引入了一个 2B 参数的设备端 LLM，用于调用 Android API 进行任务自动化。另一种方法是利用 LLM 的链式推理 [[84](https://arxiv.org/html/2401.05459v2#bib.bib84), [85](https://arxiv.org/html/2401.05459v2#bib.bib85), [68](https://arxiv.org/html/2401.05459v2#bib.bib68)] 和上下文学习能力 [[78](https://arxiv.org/html/2401.05459v2#bib.bib78)]。它们展示了工具（例如 API、其他 DNN 等）在上下文中的描述和演示，并询问 LLM 如何使用它们完成任务 [[86](https://arxiv.org/html/2401.05459v2#bib.bib86), [87](https://arxiv.org/html/2401.05459v2#bib.bib87), [88](https://arxiv.org/html/2401.05459v2#bib.bib88), [52](https://arxiv.org/html/2401.05459v2#bib.bib52), [89](https://arxiv.org/html/2401.05459v2#bib.bib89)]。然而，微调 LLM 可能成本高昂，并且受到预定义工具集的限制，而当 API 数量过多时，上下文学习可能会失败。因此，ToolkenGPT [[90](https://arxiv.org/html/2401.05459v2#bib.bib90)] 的作者尝试通过将每个工具（API）表示为一个 token 来解决这个问题。

基于代码的方法可以完成从网页搜索到图像生成的数千个任务。然而，由于安全考虑或商业利益，现实应用中并非所有所需的 API 都可供代理开发者使用。此外，有些任务对于人类用户来说执行起来很简单，但对于调用系统 API 却是困难的[[73](https://arxiv.org/html/2401.05459v2#bib.bib73)]。仅依赖公开可用的 API 可能无法完全满足移动任务自动化的高度多样化需求。

基于UI的任务自动化。自主UI代理尝试将用户的任务转化为智能手机或其他个人设备上的UI操作，通过直接的UI交互来自动化这些任务。与基于代码的任务执行相比，自主UI代理不依赖于公开的API，这可能允许更为多样化的自动化能力。然而，通过UI操作执行用户任务对于传统的DNN模型来说并不容易，因为任务与UI元素之间存在隐性关系。最近，研究人员利用LLM的理解和推理能力来提升自主UI代理的性能。

UI代理的输入是以自然语言描述的任务和当前UI的表示，输出是要在UI上执行的UI操作。根据他们如何表示UI，我们可以将自主UI代理分为基于文本的GUI表示和多模态GUI表示。

+   •

    基于文本的GUI表示是将用户界面（UI）转换为纯文本。Seq2act [[4](https://arxiv.org/html/2401.05459v2#bib.bib4)] 训练了一个基于Transformer的模型 [[31](https://arxiv.org/html/2401.05459v2#bib.bib31)]，以将用户的指令转化为描述在<operation, object, argument>元组中的UI操作。研究人员还研究了通过移动UI进行提示，以完成UI指令映射任务 [[91](https://arxiv.org/html/2401.05459v2#bib.bib91)]。作者将移动UI转换为HTML代码，这对于大语言模型（LLMs）来说比较容易理解，因为它们的训练数据中有重要部分是从Github抓取的。DroidBot-GPT [[92](https://arxiv.org/html/2401.05459v2#bib.bib92)] 是一个基于LLM的系统，用于通过一系列UI操作完成用户任务。Mind2Web [[93](https://arxiv.org/html/2401.05459v2#bib.bib93)] 使用较小的语言模型（LM）过滤网页的原始HTML，并利用LLM选择目标元素和操作。AutoDroid [[94](https://arxiv.org/html/2401.05459v2#bib.bib94)] 使用应用分析工具来获取应用领域特定知识，并利用它增强LLM以实现任务自动化。在AXNav [[95](https://arxiv.org/html/2401.05459v2#bib.bib95)]中，作者构建了一个系统，利用LLM和基于像素的UI理解来执行手动可访问性测试。MemoDroid [[96](https://arxiv.org/html/2401.05459v2#bib.bib96)] 引入了一个基于LLM的移动任务自动化工具，可以将任务拆解成更小的子任务，并通过回忆之前的操作来完成它们。

+   •

    多模态表示是将UI的图像（和文本）描述作为个人LLM代理的输入。早期的研究工作集中于训练多模态变换器，将用户命令与UI元素进行关联[[97](https://arxiv.org/html/2401.05459v2#bib.bib97), [98](https://arxiv.org/html/2401.05459v2#bib.bib98), [38](https://arxiv.org/html/2401.05459v2#bib.bib38)]。在LLM时代，一些方法尝试将视觉编码器与LLM结合，以处理GUI图像[[99](https://arxiv.org/html/2401.05459v2#bib.bib99), [100](https://arxiv.org/html/2401.05459v2#bib.bib100), [101](https://arxiv.org/html/2401.05459v2#bib.bib101)]。随着大型多模态模型（LMMs）的出现，越来越多的项目使用视觉语言代理进行UI动作定位和导航[[102](https://arxiv.org/html/2401.05459v2#bib.bib102), [103](https://arxiv.org/html/2401.05459v2#bib.bib103)]。一种趋势是利用强大的LMMs，如GPT-4V，来理解GUI并选择UI元素[[104](https://arxiv.org/html/2401.05459v2#bib.bib104), [105](https://arxiv.org/html/2401.05459v2#bib.bib105), [106](https://arxiv.org/html/2401.05459v2#bib.bib106), [107](https://arxiv.org/html/2401.05459v2#bib.bib107)]。另一条研究方向是通过在大规模数据集上进行微调，定制开源LMMs以应对与GUI相关的任务[[108](https://arxiv.org/html/2401.05459v2#bib.bib108), [109](https://arxiv.org/html/2401.05459v2#bib.bib109), [110](https://arxiv.org/html/2401.05459v2#bib.bib110)]。

尽管基于UI的任务自动化相较于基于API的自动化具有实现更灵活个人代理框架的潜力，但其研究仍处于初期阶段。实现更复杂的用户命令仍然具有挑战性。此外，隐私和安全问题尚未得到完全解决[[94](https://arxiv.org/html/2401.05459v2#bib.bib94), [99](https://arxiv.org/html/2401.05459v2#bib.bib99)]。关于UI表示的问题仍然存在争议。尽管多模态表示可以处理无法通过辅助功能服务解析的元素，但它受到屏幕录制的高需求以及当前视觉语言模型有限推理能力的困扰[[111](https://arxiv.org/html/2401.05459v2#bib.bib111)]。

#### 4.1.2 自主代理框架

基于LLM的自主代理由LLM大脑组成，用于制定计划和自我反思，内存用于存储过去的信息和知识，工具使用模块则用于与工具（例如API、UI、编程语言）进行交互[[112](https://arxiv.org/html/2401.05459v2#bib.bib112), [67](https://arxiv.org/html/2401.05459v2#bib.bib67)]。目前有许多流行的项目为用户创建基于LLM的代理提供了框架[[113](https://arxiv.org/html/2401.05459v2#bib.bib113), [114](https://arxiv.org/html/2401.05459v2#bib.bib114), [115](https://arxiv.org/html/2401.05459v2#bib.bib115), [116](https://arxiv.org/html/2401.05459v2#bib.bib116), [117](https://arxiv.org/html/2401.05459v2#bib.bib117), [118](https://arxiv.org/html/2401.05459v2#bib.bib118), [119](https://arxiv.org/html/2401.05459v2#bib.bib119), [120](https://arxiv.org/html/2401.05459v2#bib.bib120), [121](https://arxiv.org/html/2401.05459v2#bib.bib121)]。它们通过与其他外部工具的交互以及检索长期/短期记忆来增强LLM的能力。Auto-GPT [[113](https://arxiv.org/html/2401.05459v2#bib.bib113)] 是最著名的框架之一，它通过为GPT生成提示并使用外部工具来执行用户的命令。LangChain [[114](https://arxiv.org/html/2401.05459v2#bib.bib114)] 是另一个流行的框架，帮助开发者利用LLM创建更复杂、更具上下文感知的应用。由于能够理解和生成自然语言，基于LLM的代理也可以轻松地相互互动，从而促进多代理之间的协作与竞争[[122](https://arxiv.org/html/2401.05459v2#bib.bib122), [123](https://arxiv.org/html/2401.05459v2#bib.bib123), [118](https://arxiv.org/html/2401.05459v2#bib.bib118), [124](https://arxiv.org/html/2401.05459v2#bib.bib124)]。这些自主代理框架做出了重要的工程贡献，为基于LLM的应用提供了更加用户友好的框架。

对于移动设备，AutoDroid [[94](https://arxiv.org/html/2401.05459v2#bib.bib94)] 提供了一个有效的框架，用于开发移动代理。开发者可以通过探索应用程序并使用测试输入生成器，或通过手动演示，轻松地创建移动任务的自动化工具。随后，AutoDroid 会自动分析这些记录，并利用它们改进语言学习模型（LLM），以实现更高效的任务自动化。黄等人[[125](https://arxiv.org/html/2401.05459v2#bib.bib125)] 开发了一种新方法，可以有效地从用户与智能手机的交互轨迹中提取宏（应用程序中用户活动的基本单元，如“登录”或“拨打联系人”）。这些宏可以帮助代理自动完成任务。

#### 4.1.3 评估

评估任务执行性能是一个具有挑战性的问题。对于基于 API 的任务执行，之前的调查已经提供了如何评估它们的全面总结 [[66](https://arxiv.org/html/2401.05459v2#bib.bib66), [68](https://arxiv.org/html/2401.05459v2#bib.bib68)]。我们的论文主要集中在基于 UI 的任务自动化评估。

指标：基于 UI 的任务执行指标包括完成率 [[4](https://arxiv.org/html/2401.05459v2#bib.bib4), [97](https://arxiv.org/html/2401.05459v2#bib.bib97), [94](https://arxiv.org/html/2401.05459v2#bib.bib94)] 和人工设计的奖励 [[126](https://arxiv.org/html/2401.05459v2#bib.bib126), [127](https://arxiv.org/html/2401.05459v2#bib.bib127)]。完成率是模型预测的所有操作与实际情况完全一致的概率。然而，由于完成任务可能有不同的方法，而实际情况通常只代表其中一种方法，因此通过这种方式评估的准确性并不完全正确 [[94](https://arxiv.org/html/2401.05459v2#bib.bib94)]。基于关键步骤设计的奖励可以更精确 [[127](https://arxiv.org/html/2401.05459v2#bib.bib127)]，但由于复杂的标注过程，它们的可扩展性较差。

表 6：UI 任务自动化基准测试。结构化的 UI 表单分别为 Android 和网页的视图层级（VH）和文档对象模型（DOM）。对于 Windows，元数据来自操作系统内的文本元数据。

| 基准测试 | 名称 | 平台 | 人工标注 | UI 格式 | 高级任务 | 探索记忆 |
| --- | --- | --- | --- | --- | --- | --- |
| 数据集 | PhraseNode [[128](https://arxiv.org/html/2401.05459v2#bib.bib128)] | 网页 | 51,663 | DOM, 屏幕 | ✗ | ✗ |
| UIBert [[35](https://arxiv.org/html/2401.05459v2#bib.bib35)] | 网页 | 16,660 | DOM, 屏幕 | ✗ | ✗ |
| RicoSCA [[4](https://arxiv.org/html/2401.05459v2#bib.bib4)] | 安卓 | 不适用 | VH, 屏幕 | ✗ | ✗ |
| PixelHelp [[4](https://arxiv.org/html/2401.05459v2#bib.bib4)] | 安卓 | 187 | VH, 屏幕 | ✓ | ✗ |
| MoTiF [[129](https://arxiv.org/html/2401.05459v2#bib.bib129)] | 安卓 | 6,100 | VH, 屏幕 | ✓ | ✗ |
| META-GUI [[97](https://arxiv.org/html/2401.05459v2#bib.bib97)] | 安卓 | 4,684 | VH, 屏幕 | ✓ | ✗ |
| UGIF [[130](https://arxiv.org/html/2401.05459v2#bib.bib130)] | 安卓 | 523 | VH, 屏幕 | ✓ | ✗ |
| Mind2Web [[93](https://arxiv.org/html/2401.05459v2#bib.bib93)] | 网页 | 2,350 | DOM, 屏幕 | ✓ | ✗ |
| AITW [[131](https://arxiv.org/html/2401.05459v2#bib.bib131)] | 安卓+网页 | 715,142 | 屏幕 | ✓ | ✗ |
| DroidTask [[94](https://arxiv.org/html/2401.05459v2#bib.bib94)] | 安卓 | 158 | VH, 屏幕 | ✓ | ✓ |
|  | OmniACT [[132](https://arxiv.org/html/2401.05459v2#bib.bib132)] | 桌面+网页 | 9,802 | VH, 屏幕 | ✓ | ✗ |
|  | AutoWebBench [[133](https://arxiv.org/html/2401.05459v2#bib.bib133)] | 网页 | 10,000 | DOM, 屏幕 | ✓ | ✗ |
|  | VisualWebBench [[134](https://arxiv.org/html/2401.05459v2#bib.bib134)] | 网页 | 1,500 | DOM, 屏幕 | ✓ | ✗ |
|  | ScreenAgent [[135](https://arxiv.org/html/2401.05459v2#bib.bib135)] | 桌面 | 273 | 屏幕 | ✓ | ✗ |
| 平台 | MninWoB++ [[39](https://arxiv.org/html/2401.05459v2#bib.bib39), [6](https://arxiv.org/html/2401.05459v2#bib.bib6)] | 网页 | 17,971 | DOM, 屏幕 | ✗ | ✓ |
| WebShop [[136](https://arxiv.org/html/2401.05459v2#bib.bib136)] | 网页 | 12,087 | DOM, 屏幕 | ✓ | ✓ |
| WebArena [[137](https://arxiv.org/html/2401.05459v2#bib.bib137)] | 网页 | 812 | DOM, 屏幕 | ✓ | ✓ |
| AndroidEnv [[126](https://arxiv.org/html/2401.05459v2#bib.bib126)] | 安卓 | N/A | 屏幕 | ✓ | ✓ |
| MobileEnv [[127](https://arxiv.org/html/2401.05459v2#bib.bib127)] | 安卓 | N/A | VH, 屏幕 | ✓ | ✓ |
| AssistGUI [[107](https://arxiv.org/html/2401.05459v2#bib.bib107)] | Windows | 100 | 元数据, 屏幕 | ✓ | ✓ |
|  | OSWorld [[103](https://arxiv.org/html/2401.05459v2#bib.bib103)] | 桌面 | 369 | VH, 屏幕 | ✓ | ✓ |
|  | AgentStudio [[138](https://arxiv.org/html/2401.05459v2#bib.bib138)] | 桌面+网页 | 227 | DOM, 屏幕 | ✓ | ✓ |

基准测试：表格 [6](https://arxiv.org/html/2401.05459v2#S4.T6 "Table 6 ‣ 4.1.3 Evaluation ‣ 4.1 Task Execution ‣ 4 Fundamental Capabilities ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security") 列出了基于 UI 的任务自动化基准测试。一组基准测试是静态数据集，通常包括一组人工标注的任务、结构化的 UI 数据（和截图）以及完成任务所需的操作。一些任务是合成生成的 [[4](https://arxiv.org/html/2401.05459v2#bib.bib4), [126](https://arxiv.org/html/2401.05459v2#bib.bib126), [127](https://arxiv.org/html/2401.05459v2#bib.bib127)]。早期的研究主要集中在具有清晰指令的低级任务 [[128](https://arxiv.org/html/2401.05459v2#bib.bib128), [35](https://arxiv.org/html/2401.05459v2#bib.bib35)]，例如，点击“设置”按钮，然后点击“字体大小”。后来的研究引入了可以通过多个步骤完成的高级任务 [[4](https://arxiv.org/html/2401.05459v2#bib.bib4), [129](https://arxiv.org/html/2401.05459v2#bib.bib129), [97](https://arxiv.org/html/2401.05459v2#bib.bib97), [130](https://arxiv.org/html/2401.05459v2#bib.bib130), [93](https://arxiv.org/html/2401.05459v2#bib.bib93), [131](https://arxiv.org/html/2401.05459v2#bib.bib131), [132](https://arxiv.org/html/2401.05459v2#bib.bib132), [133](https://arxiv.org/html/2401.05459v2#bib.bib133), [134](https://arxiv.org/html/2401.05459v2#bib.bib134), [135](https://arxiv.org/html/2401.05459v2#bib.bib135)]，例如，删除我日历中的所有事件。另一组基准测试是支持代理交互的平台。MiniWoB++ [[39](https://arxiv.org/html/2401.05459v2#bib.bib39), [6](https://arxiv.org/html/2401.05459v2#bib.bib6)]、WebShop [[136](https://arxiv.org/html/2401.05459v2#bib.bib136)] 和 WebArena [[137](https://arxiv.org/html/2401.05459v2#bib.bib137)] 提供了 Web 环境，代理可以通过点击、输入、关闭页面等方式在 Web 上进行导航和操作。AgentStudio [[138](https://arxiv.org/html/2401.05459v2#bib.bib138)] 提供了一个全面的平台，支持与多种现实世界计算机的交互。AndroidEnv [[126](https://arxiv.org/html/2401.05459v2#bib.bib126)] 和 MobileEnv [[127](https://arxiv.org/html/2401.05459v2#bib.bib127)] 提供了一个动态环境，代理可以与任何基于 Android 的应用程序及核心操作系统进行交互。该框架允许在多样化的 Android 平台上进行广泛的交互和任务解决能力。

<svg class="ltx_picture" height="189.78" id="S4.SS1.SSS3.p4.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,189.78) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 16.6 6.92)"><foreignobject color="#000000" height="175.94" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="566.79">Remark. Existing approaches have demonstrated the remarkable ability of LLM agents in task reasoning and planning. However, there are several important problems to solve to realize practical Personal LLM Agents. 1. How to accurately and efficiently assess the performance of agents in real-world scenarios. Because there are usually various ways to accomplish the same task, it is inaccurate to use a static dataset to measure the accuracy of task execution. Meanwhile, dynamically testing the tasks in a simulated environment may be inefficient and hard to reproduce. 2. How to robustly determine if a task has been completed. LLMs often experience hallucinations during task execution, making it difficult to determine whether the current task has been completed. 3. Regarding UI agents, what is the best way to represent the software UI? The vision-based representation (e.g. screenshot) is generally available, while the text-based representation is usually more lightweight and friendly for LLM agents to operate.</foreignobject></g></g></svg>

### 4.2 上下文感知

上下文感知指的是代理感知用户或环境状态的过程，以提供更具定制化的服务。在本研究中，我们采用广义的上下文感知定义，将通用信息收集过程视为一种感知形式。基于硬件的感知与传统的感知概念一致，主要通过各种传感器、可穿戴设备、边缘设备和其他数据源进行数据采集。另一方面，基于软件的感知强调多种数据采集方式。例如，分析用户的打字习惯和常用短语就构成了一种基于软件的感知方式。

在个人大型语言模型代理中，上下文感知能力服务于多种目的。1. 启用感知任务：某些任务本质上要求代理进行感知。例如，当用户要求代理在睡眠过程中检测打鼾时，代理必须具备主动获取、处理和分析音频数据的能力。2. 补充上下文信息：感知的信息有助于执行模糊或复杂的任务。例如，当用户想听一些音乐时，了解用户当前的活动有助于推荐合适的音乐。3. 触发上下文感知服务：感知能力也是提供主动服务的基础。例如，代理可能会在检测到危险驾驶行为时提醒用户保持集中注意力。4. 增强代理记忆：通过感知获取的信息可以成为代理记忆的一部分，代理可以利用这些信息进行进一步的定制和自我进化。

我们从两个角度介绍了上下文感知技术，包括感知来源和感知目标。

#### 4.2.1 感知来源

硬件传感器。现代个人设备配备了各种内置硬件传感器，包括加速度计、陀螺仪、磁场传感器、光传感器、温度计[[139](https://arxiv.org/html/2401.05459v2#bib.bib139)]、麦克风[[140](https://arxiv.org/html/2401.05459v2#bib.bib140)]、GPS模块、摄像头[[141](https://arxiv.org/html/2401.05459v2#bib.bib141)]等。其他一些模块，如蓝牙和Wi-Fi[[142](https://arxiv.org/html/2401.05459v2#bib.bib142)]，也可用于感知目的。随着可穿戴设备和物联网设备的普及，如智能手表、蓝牙耳机[[143](https://arxiv.org/html/2401.05459v2#bib.bib143)]和智能家居设备[[144](https://arxiv.org/html/2401.05459v2#bib.bib144)]，感知的范围和感知方式得到了极大的扩展。

最近，越来越多的研究探讨了将大语言模型（LLMs）与原始传感器数据深度融合。例如，一些研究直接将原始IMU数据嵌入到LLM的提示中，从而实现人体活动识别（HAR）[[145](https://arxiv.org/html/2401.05459v2#bib.bib145)]或轨迹预测[[146](https://arxiv.org/html/2401.05459v2#bib.bib146)]。张等人[[147](https://arxiv.org/html/2401.05459v2#bib.bib147)]为LLM提供了一个3D场景的鸟瞰图，并允许其迭代选择视角以理解3D点云场景。此外，郑等人[[148](https://arxiv.org/html/2401.05459v2#bib.bib148)]使用了一个可训练的双通道音频前端和微调的LLM，使LLM能够理解空间声音。类似的前端和微调方法在LiDAR[[149](https://arxiv.org/html/2401.05459v2#bib.bib149)]和自动驾驶[[150](https://arxiv.org/html/2401.05459v2#bib.bib150), [151](https://arxiv.org/html/2401.05459v2#bib.bib151)]等多个领域中广泛应用。

软件传感器。与从真实传感器设备获取数据的硬件传感不同，软件传感侧重于从现有数据中获取信息，如应用程序使用情况[[152](https://arxiv.org/html/2401.05459v2#bib.bib152)]、通话记录[[153](https://arxiv.org/html/2401.05459v2#bib.bib153)]、打字习惯[[154](https://arxiv.org/html/2401.05459v2#bib.bib154)]、视频游戏[[155](https://arxiv.org/html/2401.05459v2#bib.bib155)]等。软件传感的范围非常广泛。例如，在自然语言处理或音频领域，基于文本或语音的传感研究层出不穷。此外，电商或短视频平台等推荐系统中，通常首先感知某些用户信息，然后推荐特定的产品或内容。这些传感器帮助代理更好地了解用户，从而提供更加智能化和个性化的服务。

多传感器组合。多传感器协同感知被认为是一种有效的增强感知能力的方法。以往的研究展示了基于触摸屏和惯性传感器评估用户情绪、压力水平和情绪状态[[156](https://arxiv.org/html/2401.05459v2#bib.bib156)]，通过屏幕捕捉和传感器数据识别时间消耗[[157](https://arxiv.org/html/2401.05459v2#bib.bib157)]，通过耳机麦克风进行呼吸检测[[158](https://arxiv.org/html/2401.05459v2#bib.bib158)]，以及通过传感器和音频进行细致的动作检测[[159](https://arxiv.org/html/2401.05459v2#bib.bib159)]。

多传感器协作的意义延伸至智能穿戴设备和智能家居的普及。例如，利用个人设备（如智能手表、笔记本电脑和智能手机）收集的数据自动识别用户是否在工作或休息 [[160](https://arxiv.org/html/2401.05459v2#bib.bib160)]，或通过耳机和智能手机麦克风的组合进行动作检测 [[143](https://arxiv.org/html/2401.05459v2#bib.bib143)]。此外，还涉及家庭电器融合的技术，如基于现有有线设备的用户行为感知 [[161](https://arxiv.org/html/2401.05459v2#bib.bib161)]、智能家居环境中的动作识别 [[144](https://arxiv.org/html/2401.05459v2#bib.bib144)]、基于Wi-Fi的动作检测 [[162](https://arxiv.org/html/2401.05459v2#bib.bib162)]、多人检测 [[142](https://arxiv.org/html/2401.05459v2#bib.bib142)] 和睡眠监测 [[163](https://arxiv.org/html/2401.05459v2#bib.bib163)]。

有三种不同的方法使LLM能够理解和利用传感器数据。

+   •

    选项 1：传感器数据作为提示。此方法将传感器数据直接作为文本提示输入到LLM中。这种方法可以应用于各种传感源，如IMU [[146](https://arxiv.org/html/2401.05459v2#bib.bib146)] 和蓝牙 [[164](https://arxiv.org/html/2401.05459v2#bib.bib164)]。原始传感器数据与提示之间的映射可以通过规则创建，例如将物体表面的触觉感受映射为“软”或“硬”等描述词 [[165](https://arxiv.org/html/2401.05459v2#bib.bib165)]。这种方法简单有效，已在许多现有研究中得到了验证。然而，它也存在重要的局限性，例如处理大量原始数据的计算成本较高，以及LLM在理解复杂传感器数据时的能力有限。

+   •

    选项 2：传感器数据编码 + 微调。这种方法使得大语言模型（LLM）能够通过数据编码器理解传感器数据。编码器通过一个经过训练的神经网络从原始传感器数据生成令牌嵌入，通常通过微调将这些嵌入集成到LLM中。这种方法对于复杂的传感器数据（如LiDAR [[149](https://arxiv.org/html/2401.05459v2#bib.bib149)] 和双通道音频 [[148](https://arxiv.org/html/2401.05459v2#bib.bib148)])取得了显著成果。该方法使得LLM能够高效地理解传感器模态，广泛应用于构建复杂的端到端系统，如自动驾驶 [[151](https://arxiv.org/html/2401.05459v2#bib.bib151), [150](https://arxiv.org/html/2401.05459v2#bib.bib150)]。其缺点在于训练难度较大。

+   •

    选项 3：将传感器数据重定向到特定领域的模型。该方法不直接通过LLM处理传感器数据，而是使用LLM调用其他专门的小模型来处理原始传感器数据。例如，Darvish等人[[166](https://arxiv.org/html/2401.05459v2#bib.bib166)]利用对象检测或姿势估计等技术，帮助化学实验机器人改善感知和理解，额外信息被添加到原始数据流中，并转化为LLM可以理解的形式。

多传感器和多设备场景需要在数据源选择、数据融合和数据分析方法上进行复杂的考虑。现有的方法包括利用大语言模型（LLM）生成多传感器策略来理解人类行为[[167](https://arxiv.org/html/2401.05459v2#bib.bib167)]，情感无关的多传感器数据多任务学习框架[[168](https://arxiv.org/html/2401.05459v2#bib.bib168)]，感知数据的跨模态融合[[169](https://arxiv.org/html/2401.05459v2#bib.bib169)]，着重于多传感器融合的可穿戴设备动作识别[[170](https://arxiv.org/html/2401.05459v2#bib.bib170)]，以及在数据缺失条件下预测传感器数据中的焦虑[[171](https://arxiv.org/html/2401.05459v2#bib.bib171)]。此外，还有研究分析了数据特征在跌倒检测中的重要性[[172](https://arxiv.org/html/2401.05459v2#bib.bib172)]。

随着感知技术的发展，多传感器和多设备协同感知已成为感知复杂场景的主要方法。有效整合多样的数据来源以最大化准确性，并确定方法去除不重要的数据以节省资源，是重要的研究领域。

#### 4.2.2 感知目标

环境感知的目标可以分为环境感知和用户感知。环境感知涵盖了位置、场合、宗教和文化背景、国家和社会背景等因素。而用户感知则涉及用户的活动、状态、个人信息、个性特征、情感、目标、身体状况以及其他相关方面。

感知环境。我们进一步将环境感知分为两个维度：场景感知和场合感知。场景感知主要涉及更为具体的环境因素，如地点和位置；而场合感知则深入到更深层次的环境信息，包括宗教和文化背景、国家差异以及社会关系。

+   •

    场景感知通常是容易察觉的，但具有重要意义，能够引起行为和重点的变化。例如，在图书馆检测到用户时，智能助手会将手机调整为静音模式，而在酒吧时则可能需要提高音量并启动震动功能。类似地，重点方面，当用户处于会议室时，智能助手应更多地专注于与会议内容记录和工作组织相关的任务，而在健身房，重点应转向健身计划和心率分析。之前的场景感知研究采用了各种技术[[173](https://arxiv.org/html/2401.05459v2#bib.bib173)]，如基于位置的方法[[174](https://arxiv.org/html/2401.05459v2#bib.bib174)]、音频或视频分析[[175](https://arxiv.org/html/2401.05459v2#bib.bib175), [176](https://arxiv.org/html/2401.05459v2#bib.bib176)]，以及通过分析智能手机麦克风中的气流等传感器功能来评估通风[[140](https://arxiv.org/html/2401.05459v2#bib.bib140)]，或通过分析放置在表面附近的宏观照片来实现场景识别[[141](https://arxiv.org/html/2401.05459v2#bib.bib141)]。张等人[[147](https://arxiv.org/html/2401.05459v2#bib.bib147)]让大型语言模型（LLM）通过LLM引导的多个视角选择理解三维场景。

+   •

    场合感知在感知上更加难以捉摸，其影响相对隐蔽。早期研究已识别出不同国家[[177](https://arxiv.org/html/2401.05459v2#bib.bib177)]和地区[[178](https://arxiv.org/html/2401.05459v2#bib.bib178)]中行为和情感识别任务的差异。当前用户和环境所隐含的国家、民族、宗教和文化背景至关重要。感知他人和当前环境中的物体同样至关重要。例如，之前的研究基于传感器数据检测了社交场景，分析了不同社交场合中社交焦虑个体的行为[[179](https://arxiv.org/html/2401.05459v2#bib.bib179)]。其他研究则深入分析了利用多传感器分析饮酒相关的社交场景，甚至预测了饮酒群体的规模和性别组成[[180](https://arxiv.org/html/2401.05459v2#bib.bib180)]。此外，研究还探讨了传感器数据、饮食习惯与社交环境之间的关系，揭示了暴饮暴食与社交环境之间的强关联性，使其变得可预测[[181](https://arxiv.org/html/2401.05459v2#bib.bib181)]。梁等人[[182](https://arxiv.org/html/2401.05459v2#bib.bib182)]通过分析公共事件使用LLM预测行人流动。

环境感知是个人代理的关键上下文信息。不同的环境会导致不同的行为和关注点，超越单纯的位置，涵盖社交场合、文化背景以及更深层次的概念元素，所有这些都涉及环境中的个体及其关系、互动，并预测对环境和用户的影响。这些因素直接影响个人代理所展现的智能水平。

感知用户。用户感知是个人LLM代理的主要特征之一。对用户的深入了解能更好地反映个人LLM代理的价值和意义。我们将用户感知分为两个时间维度，包括短期和长期。短期感知表现出较高的时间变动性和随机性；另一方面，长期感知需要延长的维护和校正，因此相对更加稳定和可靠。

+   •

    短期用户感知涵盖了多个方面，包括用户的日常行为[[183](https://arxiv.org/html/2401.05459v2#bib.bib183)]，或是一些专业活动，例如刷牙效果[[184](https://arxiv.org/html/2401.05459v2#bib.bib184)]，Ji等人[[145](https://arxiv.org/html/2401.05459v2#bib.bib145)]发现，甚至将IMU数据直接输入LLM也能执行人类活动识别（HAR）任务。用户状态，如工作或休息[[160](https://arxiv.org/html/2401.05459v2#bib.bib160)，[157](https://arxiv.org/html/2401.05459v2#bib.bib157)]，用户健康状况[[185](https://arxiv.org/html/2401.05459v2#bib.bib185)，[139](https://arxiv.org/html/2401.05459v2#bib.bib139)，[186](https://arxiv.org/html/2401.05459v2#bib.bib186)]，以及用户的情绪[[187](https://arxiv.org/html/2401.05459v2#bib.bib187)，[156](https://arxiv.org/html/2401.05459v2#bib.bib156)]和压力水平[[188](https://arxiv.org/html/2401.05459v2#bib.bib188)]。最近，许多研究尝试探讨LLM在健康监测领域的应用[[189](https://arxiv.org/html/2401.05459v2#bib.bib189)，[190](https://arxiv.org/html/2401.05459v2#bib.bib190)，[191](https://arxiv.org/html/2401.05459v2#bib.bib191)]。短期感知通常涉及快速变化和浅层次的状态信息。高效地捕捉这些信息可以显著增强个人LLM代理的上下文感知能力。

+   •

    长期用户感知主要集中在对用户档案和个性分析。已经提出了多种方法来理解用户的工作、学习和日常生活。例如，有研究利用新款智能手机的传感器数据来检测新生的长期心理状态[[192](https://arxiv.org/html/2401.05459v2#bib.bib192)]。另一项研究则展示了基于感知数据预测学习表现和社交活动的能力[[193](https://arxiv.org/html/2401.05459v2#bib.bib193)]。高等学者等人[[194](https://arxiv.org/html/2401.05459v2#bib.bib194)]深入探讨了基于身体活动强度预测个性的技术。还有研究考察了传感器数据与用户职业晋升之间的关系[[195](https://arxiv.org/html/2401.05459v2#bib.bib195)]，以及一项预测用户生活满意度的研究[[196](https://arxiv.org/html/2401.05459v2#bib.bib196)]。此外，用户的特定状态也成为研究的重点，包括关于心理疾病感知的研究[[197](https://arxiv.org/html/2401.05459v2#bib.bib197)、[198](https://arxiv.org/html/2401.05459v2#bib.bib198)]，例如预测和分析精神分裂症[[199](https://arxiv.org/html/2401.05459v2#bib.bib199)]、抑郁症[[190](https://arxiv.org/html/2401.05459v2#bib.bib190)]，以及检测吸烟等习惯的研究[[200](https://arxiv.org/html/2401.05459v2#bib.bib200)]。Lifelo等人[[191](https://arxiv.org/html/2401.05459v2#bib.bib191)]使用LLM对一种极为罕见的非洲语言进行了心理障碍分析。此外，欧阳和Srivastava[[201](https://arxiv.org/html/2401.05459v2#bib.bib201)]尝试从简单数据中提取更高层次的感知信息。长期感知涉及深层和抽象的信息，包含用户行为背后的深刻逻辑。这些信息往往更加微妙，使得感知和维护变得具有挑战性。然而，它们构成了先进个人代理的重要方面。

在用户感知方面，也有几个基于LLM的举措，例如使用LLM进行推荐任务[[202](https://arxiv.org/html/2401.05459v2#bib.bib202)、[203](https://arxiv.org/html/2401.05459v2#bib.bib203)]，使用LLM进行情感分析[[204](https://arxiv.org/html/2401.05459v2#bib.bib204)]，以及开发具备询问和感知能力的个人医生[[205](https://arxiv.org/html/2401.05459v2#bib.bib205)]。

<svg class="ltx_picture" height="127.15" id="S4.SS2.SSS2.p8.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,127.15) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 16.6 6.92)"><foreignobject color="#000000" height="113.31" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="566.79">Remark. Existing methods often confine themselves to specific sensors, individual apps, or particular domains. In Personal LLM Agents, a possible opportunity is to unify all sensing results concerning the environment and the user to originate from diverse sources. However, to achieve this goal involves several important research challenges. 1. What is a unified format or ontology of the sensed information? The agents should be able to convert diverse sensing data into this format and conveniently use the data for various downstream tasks. 2. Given the broad scope of sensing, how can the agents decide when and what to sense, in order to provide context-aware services with minimal overhead?</foreignobject></g></g></svg>

### 4.3 记忆

记忆指的是在个人LLM代理中记录、管理和利用历史数据的能力。此能力使得代理能够跟踪用户，学习过去的经验，提取有用的知识，并将所获得的知识应用于进一步提升服务质量。相关工作主要聚焦于回答两个问题，包括如何获取记忆以及如何利用记忆。

#### 4.3.1 获取记忆

代理记忆可以采用多种格式。例如，基本的用户档案（如生日、地址、个性、偏好）通常以键值对的形式存储，便于基于键进行检索。历史记录通常表示为按时间戳索引的序列，用于归档用户服务访问、活动、系统事件等数据。用户的文档、照片、视频等以文件形式存储，这些文件通常由其他应用生成。获取记忆的方式主要有两种：直接记录原始数据或间接地从原始数据中推理知识。

记录。获取记忆最直接的方式是通过记录，例如记录用户输入、系统事件和感知到的上下文。记录的数据通常相对简单。*生活记录*是一个常被讨论的话题，重点是追踪和记录用户在活动和行为中产生的数据，从而全面了解个体的生活方式和偏好[[206](https://arxiv.org/html/2401.05459v2#bib.bib206), [207](https://arxiv.org/html/2401.05459v2#bib.bib207)]。使用视频摄像头在特定时刻录制的数据能提供更深入的日常活动概览[[208](https://arxiv.org/html/2401.05459v2#bib.bib208)]。此外，长时间记录的数据可以为行为模式提供宝贵的洞察，从而支持智能代理的个性化[[209](https://arxiv.org/html/2401.05459v2#bib.bib209)]。

推理。个人化大语言模型（LLM）代理获取记忆的另一种方式是从原始数据中提取知识。随着机器学习和数据分析技术的进步，现在已经能够通过推理用户行为、模式和互动来洞察其心理、偏好以及其他高层次信息。例如，用户的个性可以从文本中提取[[210](https://arxiv.org/html/2401.05459v2#bib.bib210), [211](https://arxiv.org/html/2401.05459v2#bib.bib211)]，情感可以从图像和文本数据中读取[[212](https://arxiv.org/html/2401.05459v2#bib.bib212), [213](https://arxiv.org/html/2401.05459v2#bib.bib213)]，偏好可以从历史互动信息中建模[[214](https://arxiv.org/html/2401.05459v2#bib.bib214)]，知识图谱可以从智能手机推送通知中提取[[215](https://arxiv.org/html/2401.05459v2#bib.bib215)]。这些提取的高层次信息也将作为代理的记忆存储，并在服务中加以利用。

#### 4.3.2 管理和利用记忆

在获得记忆之后，下一个问题是如何管理和利用记忆，以便为个人化大语言模型（LLM）代理提供更好的服务。根据利用记忆的目的，我们将相关技术分为以下三部分：原始数据管理、记忆增强的大语言模型推理和代理自我进化。

原始数据管理与处理。个人LLM代理的基本能力之一是访问和处理原始记忆数据（例如，选择、过滤、转换为其他格式等），以促进其他高级功能的实现。这一研究方向主要关注使数据访问、操作和修改更自然且易于人类理解。由于LLM的输入输出和推理过程基于自然语言，因此这种接口更容易与大型模型的其他功能集成。在这一研究领域，许多工作探索了使用机器学习模型或基于模板的方法，将用户的数据请求映射为数据库SQL语句[[216](https://arxiv.org/html/2401.05459v2#bib.bib216)，[217](https://arxiv.org/html/2401.05459v2#bib.bib217)]。还有一些框架级的工作在研究如何统一和简化数据接口。例如，PrivacyStreams [[218](https://arxiv.org/html/2401.05459v2#bib.bib218)] 将所有个人数据访问和处理接口统一到基于流的框架中，这有助于大型语言模型的理解与管理。

内存增强型LLM推理。为了使个人LLM代理能够基于与用户相关的记忆提供定制化服务，通常希望在LLM推理过程中利用记忆数据。近期的LLM代理研究探索了利用记忆来增强决策和推理[[85](https://arxiv.org/html/2401.05459v2#bib.bib85)，[219](https://arxiv.org/html/2401.05459v2#bib.bib219)，[220](https://arxiv.org/html/2401.05459v2#bib.bib220)，[221](https://arxiv.org/html/2401.05459v2#bib.bib221)，[222](https://arxiv.org/html/2401.05459v2#bib.bib222)]，这为一个解决方案提供了灵感，该解决方案使得个人LLM代理能够通过记忆为用户提供个性化服务。根据记忆类型，相关技术可能有所不同。

+   •

    短期记忆以符号变量的形式保存和保留相关信息，确保在当前决策周期内能够访问和应用这些信息。这包括感知输入、主动知识（通过推理生成或从记忆数据中检索）、以及从上一决策周期中传递过来的其他核心信息（例如，代理的主动目标）。CoT [[84](https://arxiv.org/html/2401.05459v2#bib.bib84)]、Scratchpads [[223](https://arxiv.org/html/2401.05459v2#bib.bib223)]鼓励大型语言模型（LLM）生成中间推理，利用LLM自身的上下文作为一种工作记忆。CoALA [[224](https://arxiv.org/html/2401.05459v2#bib.bib224)]提出，工作记忆应该在长期记忆（LLM）调用过程中作为持久数据结构存在。每次调用都从工作记忆的子集生成输入（例如，提示模板和相关变量），然后输出被解析成其他变量（例如，动作名称和参数），这些变量被存回工作记忆并用于执行相应的动作。此外，短期记忆能够与长期记忆及其他数据接口进行交互，作为连接语言代理不同组件的核心枢纽 [[225](https://arxiv.org/html/2401.05459v2#bib.bib225), [226](https://arxiv.org/html/2401.05459v2#bib.bib226)]。

+   •

    长期记忆存储来自早期决策周期的经验。这可以包括历史事件流 [[219](https://arxiv.org/html/2401.05459v2#bib.bib219)]、来自先前情节的游戏轨迹 [[227](https://arxiv.org/html/2401.05459v2#bib.bib227), [228](https://arxiv.org/html/2401.05459v2#bib.bib228)]、用户与代理之间的交互信息或代理经验的其他表现形式。在决策周期的规划阶段，这些情节可以被检索到工作记忆中以支持推理。代理还可以将来自工作记忆的新经验写入情节记忆，作为一种学习方式。其次，长期记忆存储代理关于世界和自身的知识。传统方法通过检索来进行推理或决策支持，或者从外部数据库初始化记忆以提供知识支持（例如，NLP中的检索增强方法 [[229](https://arxiv.org/html/2401.05459v2#bib.bib229), [230](https://arxiv.org/html/2401.05459v2#bib.bib230)]，RL中的“阅读学习”方法 [[231](https://arxiv.org/html/2401.05459v2#bib.bib231), [232](https://arxiv.org/html/2401.05459v2#bib.bib232)]）。代理还可以将通过LLM推理和用户获得的新知识写入长期记忆，作为一种通过经验逐步建立世界知识的学习方式。

智能体自我进化。为了更好地适应用户，个人LLM智能体可能还需要根据记忆数据动态更新自身。我们称之为“自我进化”。智能体的基础功能主要依赖于LLM。因此，智能体自我进化的关键在于如何利用LLM来发现和探索新技能，以及如何持续更新LLM本身。

+   •

    学习技能。目前，许多研究正在进行中，旨在使基于大语言模型（LLM）的智能体能够进行持续的技能学习和获取[[233](https://arxiv.org/html/2401.05459v2#bib.bib233), [234](https://arxiv.org/html/2401.05459v2#bib.bib234)]。这些方法的灵感来自于程序的通用性和可解释性[[235](https://arxiv.org/html/2401.05459v2#bib.bib235)]，将技能视为可执行代码，并通过战略性地使用提示来利用LLM的上下文学习能力，优化技能获取。它们还管理着一个技能库，整合新的技能作为API，使智能体能够不断学习并在后续任务中重复使用这些技能。先前的研究已经证明，现代LLM可以捕捉到有关有意义技能链的相关信息[[51](https://arxiv.org/html/2401.05459v2#bib.bib51), [49](https://arxiv.org/html/2401.05459v2#bib.bib49)]。因此，智能体具备通过在基础技能集内战略性地链接技能来获取新技能的能力[[236](https://arxiv.org/html/2401.05459v2#bib.bib236)]。在这种技能链的过程中，智能体有目的地选择后续有意义的技能，利用LLM中嵌入的先验知识，并利用执行反馈来调整其选择。这种有针对性的方法使得智能体能够高效地吸收复杂技能。

+   •

    微调LLM。为了实现智能体的自我进化，还需要对LLM进行持续的微调。原因有几个：1. 目前的LLM并非专门为智能体特定的用例设计，例如生成动作或自我评估，而这些任务在少量提示的支持下提供有限的学习支持。2. 由于移动设备上的性能限制，智能体LLM组件的能力受限。这一限制使得模型难以通过先前的知识和上下文学习能力获得新技能。3. 在智能体的操作阶段，诸如最新语料库[[237](https://arxiv.org/html/2401.05459v2#bib.bib237)]、新知识[[238](https://arxiv.org/html/2401.05459v2#bib.bib238)]和工具[[239](https://arxiv.org/html/2401.05459v2#bib.bib239)]等材料的持续涌现，可能频繁改变任务模式。这要求LLM持续适应。在这种情况下，微调模型变得必要，以增强其处理新任务和生成适当行动的能力。研究表明，微调后的较小LLM在特定推理[[240](https://arxiv.org/html/2401.05459v2#bib.bib240)、[241](https://arxiv.org/html/2401.05459v2#bib.bib241)]和执行[[225](https://arxiv.org/html/2401.05459v2#bib.bib225)]需求上，可能优于经过提示的较大LLM，同时减少推理时间和费用。参数高效微调（PEFT）[[242](https://arxiv.org/html/2401.05459v2#bib.bib242)]为高效微调LLM提供了一个有前景的方案。它只需要微调少量外部参数[[243](https://arxiv.org/html/2401.05459v2#bib.bib243)]，使其适用于边缘设备，并能有效缓解灾难性遗忘问题[[244](https://arxiv.org/html/2401.05459v2#bib.bib244)]。也有一些初步尝试进行LLM微调研究，针对智能体在多个任务和提示方法中的轨迹[[245](https://arxiv.org/html/2401.05459v2#bib.bib245)]，为未来开发更强大、更有用的个人LLM智能体提供了启示。

<svg class="ltx_picture" height="145.29" id="S4.SS3.SSS2.p7.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,145.29) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 16.6 6.92)"><foreignobject color="#000000" height="131.45" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="566.79">Remark. The ability to generate and leverage the memory about the user is the basis of personalization in Personal LLM Agents. We highlight following three open problems surrounding the memory mechanism of Personal LLM Agents. 1. The agent memory can potentially be huge, heterogeneous and dynamic. What is the most effective and efficient way for the agents to organize and retrieve the memory? 2. Human has the ability to forget. Since inappropriate data in the memory can be harmful for the agents’ service quality and efficiency, how can the agents determine what information to memorize? 3. What is the best way for the agents to self-evolve with the memory? Specifically, what data to use, when to evolve, and how (fine-tuning or else)? How can the personalized models accept updates of the base foundation model?</foreignobject></g></g></svg>

## 5 效率

图9：个人LLM智能体的低层次过程与高层次能力之间的映射关系。

由于许多个人设备的硬件资源和电源供应有限，因此在部署阶段提高个人LLM智能体的效率非常重要。我们在第[4](https://arxiv.org/html/2401.05459v2#S4 "4 Fundamental Capabilities ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")节中讨论了个人LLM智能体的基本能力，包括任务执行、上下文感知和记忆。这些能力，如图[9](https://arxiv.org/html/2401.05459v2#S5.F9 "Figure 9 ‣ 5 Efficiency ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")所示，得到了更基础过程的支持，主要包括LLM智能体的推理、定制和记忆检索。这些过程中的每一个都需要仔细优化效率，如下所述。

LLM的推理是智能体各种能力的基础。例如，智能体可以在LLM的帮助下首先将一个复杂的任务分解为若干步骤，然后通过LLM推理或调用个人工具（例如安排会议）来解决每个步骤。感知上下文或生成记忆也可能依赖于LLM的推理能力。由于工具或传感器的使用成本通常很难估算，因为其种类繁多，LLM推理是一个常见的过程，且需要大量的计算和内存资源。因此，LLM推理成为个人LLM智能体的性能瓶颈，必须对其效率进行仔细优化。

定制是个人LLM智能体的另一个重要过程，用于满足不同用户的需求。当智能体被安装到不同用户身上或用于不同场景时，需要进行定制。个人LLM智能体的自我进化也是一个定制过程。为了提供定制服务，智能体可以通过输入不同的上下文令牌或通过领域特定数据对LLM进行调优来实现定制。由于定制需求频繁，这些过程可能会对系统的计算和存储资源施加相当大的压力。

内存操作是另一个成本高昂的过程。为了提供更好的服务，智能体可能需要访问更长的上下文或外部记忆，例如环境感知、用户档案、交互历史、数据文件等。因此，这引发了两个考虑因素。第一个是要求大规模语言模型（LLM）处理更长输入的需求。第二个问题则集中在从外部记忆库管理和获取信息上。

{forest}

分叉边，树状图=生长=东，反转=true，锚点=基础西，父锚点=东，子锚点=西，基础=居中，字体=，矩形，绘制=隐藏绘制，圆角对齐=左，文本居中，最小宽度=4em，边框+=深灰色，线宽=1pt，s sep=3pt，内间距x=2pt，内间距y=3pt，线宽=0.8pt，ver/.style=旋转=90，子锚点=北，父锚点=南，锚点=居中， ，每一层级1文本宽度=10em，字体=，，每一层级2文本宽度=15em，字体=，，每一层级3文本宽度=15em，字体=，，[效率，ver [高效

推理 (§[5.1](https://arxiv.org/html/2401.05459v2#S5.SS1 "5.1 高效推理 ‣ 5 效率 ‣ 个人 LLM 代理：能力、效率与安全性的洞察与调查")), 填充=blue!10 [模型压缩 (§[5.1.1](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS1 "5.1.1 模型压缩 ‣ 5.1 高效推理 ‣ 5 效率 ‣ 个人 LLM 代理：能力、效率与安全性的洞察与调查")), 填充=blue!10 [量化，填充=blue!10 [仅权重量化：GPTQ [[246](https://arxiv.org/html/2401.05459v2#bib.bib246)], AWQ [[247](https://arxiv.org/html/2401.05459v2#bib.bib247)], LLM-QAT [[248](https://arxiv.org/html/2401.05459v2#bib.bib248)], 等，叶子，文本宽度=29em ] [协同量化：ZeroQuant [[249](https://arxiv.org/html/2401.05459v2#bib.bib249)], SmoothQuant [[250](https://arxiv.org/html/2401.05459v2#bib.bib250)], 等，叶子，文本宽度=23em ] ] [修剪，填充=blue!10 [LLM-Pruner [[251](https://arxiv.org/html/2401.05459v2#bib.bib251)], SparseGPT [[252](https://arxiv.org/html/2401.05459v2#bib.bib252)], Wanda [[253](https://arxiv.org/html/2401.05459v2#bib.bib253)], 等，叶子，文本宽度=24em ] ] [知识蒸馏，填充=blue!10 [白盒：BabyLlama [[254](https://arxiv.org/html/2401.05459v2#bib.bib254)], MiniLLM [[255](https://arxiv.org/html/2401.05459v2#bib.bib255)], 等，叶子，文本宽度=22em ] [黑盒：Hsieh 等 [[256](https://arxiv.org/html/2401.05459v2#bib.bib256)], SCoTD [[257](https://arxiv.org/html/2401.05459v2#bib.bib257)], 等，叶子，文本宽度=21em ] ] [低秩分解，填充=blue!10 [ZeroQuant-V2 [[258](https://arxiv.org/html/2401.05459v2#bib.bib258)], LoSparse [[259](https://arxiv.org/html/2401.05459v2#bib.bib259)], 等，叶子，文本宽度=18em ] ] ] [推理加速 (§[5.1.2](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS2 "5.1.2 推理加速 ‣ 5.1 高效推理 ‣ 5 效率 ‣ 个人 LLM 代理：能力、效率与安全性的洞察与调查")), 填充=blue!10 [上下文压缩，填充=blue!10 [量化：ZeroQuant [[249](https://arxiv.org/html/2401.05459v2#bib.bib249)], SmoothQuant [[250](https://arxiv.org/html/2401.05459v2#bib.bib250)], 等，叶子，文本宽度=24em ] [修剪：Li 等 [[260](https://arxiv.org/html/2401.05459v2#bib.bib260)], Jiang 等 [[261](https://arxiv.org/html/2401.05459v2#bib.bib261)], Chevalier 等 [[262](https://arxiv.org/html/2401.05459v2#bib.bib262)],

Anagnostidis 等人 [[263](https://arxiv.org/html/2401.05459v2#bib.bib263)]，Zhang 等人 [[264](https://arxiv.org/html/2401.05459v2#bib.bib264)]，Ge 等人 [[265](https://arxiv.org/html/2401.05459v2#bib.bib265)]，等等，leaf，text width=27em ] ] [内核优化，fill=blue!10 [ FlashAttention [[266](https://arxiv.org/html/2401.05459v2#bib.bib266)，[267](https://arxiv.org/html/2401.05459v2#bib.bib267)]，FlashDecoding++ [[268](https://arxiv.org/html/2401.05459v2#bib.bib268)]，等等，leaf，text width=24em ] ] [推测解码，fill=blue!10 [ Chen 等人 [[269](https://arxiv.org/html/2401.05459v2#bib.bib269)]，Leviathan 等人 [[270](https://arxiv.org/html/2401.05459v2#bib.bib270)]，等等，leaf，text width=20em ] ] ] [内存减少（§[5.1.3](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS3 "5.1.3 Memory Reduction ‣ 5.1 Efficient Inference ‣ 5 Efficiency ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")），fill=blue!10 [KV 量化，fill=blue!10 [ ZeroQuant [[249](https://arxiv.org/html/2401.05459v2#bib.bib249)]，SmoothQuant [[250](https://arxiv.org/html/2401.05459v2#bib.bib250)]，等等，leaf，text width=18em ] ] [KV 剪枝，fill=blue!10 [ Anagnostidis 等人 [[263](https://arxiv.org/html/2401.05459v2#bib.bib263)]，Zhang 等人 [[264](https://arxiv.org/html/2401.05459v2#bib.bib264)]，等等，leaf，text width=22em ] ] [卸载，fill=blue!10 [ FlexGen [[271](https://arxiv.org/html/2401.05459v2#bib.bib271)]，PowerInfer [[272](https://arxiv.org/html/2401.05459v2#bib.bib272)]，Alizadeh 等人 [[273](https://arxiv.org/html/2401.05459v2#bib.bib273)]，等等，leaf，text width=25em ] ] ] [能源优化（§[5.1.4](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS4 "5.1.4 Energy Optimization ‣ 5.1 Efficient Inference ‣ 5 Efficiency ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")），fill=blue!10 [软件方法，fill=blue!10 [ 同上，leaf，text width=6em ] ] [硬件方法，fill=blue!10 [ NPU [[274](https://arxiv.org/html/2401.05459v2#bib.bib274)]，TPU [[275](https://arxiv.org/html/2401.05459v2#bib.bib275)]，FPGA [[276](https://arxiv.org/html/2401.05459v2#bib.bib276)]，等等，leaf，text width=18em ] ] ] ] [高效

定制 (§[5.2](https://arxiv.org/html/2401.05459v2#S5.SS2 "5.2 高效定制 ‣ 5 效率 ‣ 个人LLM代理：关于能力、效率和安全性的洞察与调研")), fill=blue!10 [微调效率 (§[5.2.2](https://arxiv.org/html/2401.05459v2#S5.SS2.SSS2 "5.2.2 微调效率 ‣ 5.2 高效定制 ‣ 5 效率 ‣ 个人LLM代理：关于能力、效率和安全性的洞察与调研")), fill=blue!10 [参数高效微调，fill=blue!10 [ Houlsby 等人 [[277](https://arxiv.org/html/2401.05459v2#bib.bib277)], LLM-Adapters [[278](https://arxiv.org/html/2401.05459v2#bib.bib278)], LoRA [[279](https://arxiv.org/html/2401.05459v2#bib.bib279)], 等等，leaf，text width=26em ] ] [高效优化器设计，fill=blue!10 [ LOMO [[280](https://arxiv.org/html/2401.05459v2#bib.bib280)], Sophia [[281](https://arxiv.org/html/2401.05459v2#bib.bib281)], 等等，leaf，text width=14em ] ] [训练数据整理，fill=blue!10 [ phi-1 [[282](https://arxiv.org/html/2401.05459v2#bib.bib282)], phi-1.5 [[283](https://arxiv.org/html/2401.05459v2#bib.bib283)], phi-2 [[284](https://arxiv.org/html/2401.05459v2#bib.bib284)], 等等，leaf，text width=18em ] ] ] [上下文加载效率 (§[5.2.1](https://arxiv.org/html/2401.05459v2#S5.SS2.SSS1 "5.2.1 上下文加载效率 ‣ 5.2 高效定制 ‣ 5 效率 ‣ 个人LLM代理：关于能力、效率和安全性的洞察与调研")), fill=blue!10 [加载加速，fill=blue!10 [ CacheGen [[285](https://arxiv.org/html/2401.05459v2#bib.bib285)], 等等，leaf，text width=10em ] ] ] ] [高效内存操作

(§[5.3](https://arxiv.org/html/2401.05459v2#S5.SS3 "5.3 高效内存操作 ‣ 5 效率 ‣ 个人LLM代理：关于能力、效率和安全性的洞察与调研")), fill=blue!10 [搜索效率 (§[5.3.1](https://arxiv.org/html/2401.05459v2#S5.SS3.SSS1 "5.3.1 搜索效率 ‣ 5.3 高效内存操作 ‣ 5 效率 ‣ 个人LLM代理：关于能力、效率和安全性的洞察与调研")), fill=blue!10 [索引，fill=blue!10 [ 典型：随机化分区 [[286](https://arxiv.org/html/2401.05459v2#bib.bib286), [287](https://arxiv.org/html/2401.05459v2#bib.bib287)], 学到

分区[[288](https://arxiv.org/html/2401.05459v2#bib.bib288)], 可导航分区[[289](https://arxiv.org/html/2401.05459v2#bib.bib289)]等，叶节点，文本宽度=23em] [硬件感知：DiskANN [[290](https://arxiv.org/html/2401.05459v2#bib.bib290)], CXL-ANNS [[291](https://arxiv.org/html/2401.05459v2#bib.bib291)], FANNS [[292](https://arxiv.org/html/2401.05459v2#bib.bib292)]等，叶节点，文本宽度=31em]] ] [搜索，填充=蓝色!10 [搜索计划[[293](https://arxiv.org/html/2401.05459v2#bib.bib293), [294](https://arxiv.org/html/2401.05459v2#bib.bib294), [295](https://arxiv.org/html/2401.05459v2#bib.bib295), [296](https://arxiv.org/html/2401.05459v2#bib.bib296)], 元数据过滤[[295](https://arxiv.org/html/2401.05459v2#bib.bib295), [297](https://arxiv.org/html/2401.05459v2#bib.bib297)]等，叶节点，文本宽度=29em] [执行：GPU [[298](https://arxiv.org/html/2401.05459v2#bib.bib298), [296](https://arxiv.org/html/2401.05459v2#bib.bib296)], SIMD [[298](https://arxiv.org/html/2401.05459v2#bib.bib298), [296](https://arxiv.org/html/2401.05459v2#bib.bib296), [299](https://arxiv.org/html/2401.05459v2#bib.bib299)],

OPENMP [[298](https://arxiv.org/html/2401.05459v2#bib.bib298), [296](https://arxiv.org/html/2401.05459v2#bib.bib296)], 分布式[[300](https://arxiv.org/html/2401.05459v2#bib.bib300), [293](https://arxiv.org/html/2401.05459v2#bib.bib293)]等，叶节点，文本宽度=22em]] ] [工作流效率（§[5.3.2](https://arxiv.org/html/2401.05459v2#S5.SS3.SSS2 "5.3.2 工作流优化 ‣ 5.3 高效内存操作 ‣ 5 效率 ‣ 个人LLM代理：关于能力、效率和安全的洞察与调查")），填充=蓝色!10 [流水线，填充=蓝色!10 [ RaLMSpec [[301](https://arxiv.org/html/2401.05459v2#bib.bib301)], PipeRAG [[302](https://arxiv.org/html/2401.05459v2#bib.bib302)]等，叶节点，文本宽度=16em]] [缓存，填充=蓝色!10 [ RAGCache [[303](https://arxiv.org/html/2401.05459v2#bib.bib303)], GRITLM [[304](https://arxiv.org/html/2401.05459v2#bib.bib304)]等，叶节点，文本宽度=16em]] ] ] ]

图10：提高LLM代理效率的技术概述。叶节点是我们引用的代表性作品的一部分。

我们将在以下小节中深入探讨每个组件的效率，如图[10](https://arxiv.org/html/2401.05459v2#S5.F10 "Figure 10 ‣ 5 Efficiency ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")所示。

### 5.1 高效推理

由于个人LLM代理的运行时成本主要由LLM推理决定，因此提高推理效率对于增强代理的整体效率至关重要。尽管代理的总推理成本可以通过代理的设计显著影响，包括代理如何向LLM发送请求、使用何种提示等，但我们将仅关注模型和系统级的方法。原因在于，代理的设计可能根据实际应用有所不同，并且不会直接影响LLM推理本身的效率。

已经提出了许多模型和系统级的方法来提高LLM推理的效率。虽然其中一些方法对于整体性能和效率是通用的（例如，模型压缩），但也有一些技术针对特定方面的效率，如模型大小、推理延迟、内存消耗、能耗等。我们将在本小节的后续部分分别讨论这些方面。

#### 5.1.1 模型压缩

模型压缩技术通过直接减少模型大小和计算量，是提高LLM推理效率的通用优化方法，包括计算、内存、能量等方面。模型压缩技术进一步分为多种方法，包括量化、剪枝（稀疏性）、蒸馏和低秩分解。

量化是LLM中最重要的压缩方法之一。它通过使用更少的位数来表示模型参数，从而减少模型大小，同时通过系统级的量化内核支持减少计算量。量化方法可以进一步分为训练后量化（PTQ）和量化感知训练（QAT），具体取决于量化后是否需要额外的训练。与QAT（例如，LLM-QAT [[248](https://arxiv.org/html/2401.05459v2#bib.bib248)]）需要额外的训练工作量不同，PTQ在不同硬件约束下更适合设备端部署，具有更好的灵活性和可用性。

最近的研究表明，LLM量化的难点主要在于激活值，其中异常值很难进行量化[[305](https://arxiv.org/html/2401.05459v2#bib.bib305), [306](https://arxiv.org/html/2401.05459v2#bib.bib306)]。现有的研究提出了多种方法来应对这一挑战。一种典型的方法采用仅权重量化（WOQ）范式，该方法仅对权重进行整数量化（例如，INT4和INT8），而保持激活值为浮动格式（例如，FP16和FP32）。WOQ在压缩比和模型困惑度之间实现了平衡。WOQ的一种直接方法是当前移动部署框架中实现的分组均匀量化（例如，llama.cpp [[307](https://arxiv.org/html/2401.05459v2#bib.bib307)] 和 MLC-LLM [[308](https://arxiv.org/html/2401.05459v2#bib.bib308)]）。最近的研究还提出了不同的量化算法以增强模型能力，例如GPTQ [[246](https://arxiv.org/html/2401.05459v2#bib.bib246)] 和AWQ [[247](https://arxiv.org/html/2401.05459v2#bib.bib247)]。

尽管存在WOQ技术，另一类研究则量化权重和激活值。例如，ZeroQuant [[249](https://arxiv.org/html/2401.05459v2#bib.bib249)]对权重和激活值都执行INT8量化，采用分组量化对模型权重进行处理，对激活值则采用按令牌量化。然而，与模型权重相比，激活值（包括键值（KV）对）通常因为异常值而更难量化。为应对这一挑战，已经开展了大量研究。SmoothQuant [[250](https://arxiv.org/html/2401.05459v2#bib.bib250)]通过额外的缩放操作将激活值的量化难度转移到权重上，这些操作“平滑”激活值中的异常值，从而在W8A8量化中实现了几乎可以忽略的准确度下降。随后，其他研究进一步尝试通过各种技术将可用的量化位宽降低到4位，其中包括通道重排序（RPTQ [[309](https://arxiv.org/html/2401.05459v2#bib.bib309)]）、通道级移位和缩放（Outlier Suppression+ [[310](https://arxiv.org/html/2401.05459v2#bib.bib310)]）以及自适应通道重组（QLLM [[311](https://arxiv.org/html/2401.05459v2#bib.bib311)]）。值得注意的是，RPTQ通过开发一种新的量化方案，专注于量化激活值时的KV缓存，解决了KV存储问题，而KV缓存是长上下文推理中的主要内存消耗者。

尽管像 INT4 和 INT8 这样的整数量化方法仍然是当前部署中的主流解决方案，但低位浮动点量化（例如 FP4 和 FP8）已成为一种新趋势。其原因之一是，浮动点量化可以达到与整数量化相当甚至更高的精度[[312](https://arxiv.org/html/2401.05459v2#bib.bib312)、[313](https://arxiv.org/html/2401.05459v2#bib.bib313)、[314](https://arxiv.org/html/2401.05459v2#bib.bib314)]。此外，浮动点量化在具备专用计算支持的云 GPU（如 NVIDIA H100）和移动 GPU 上，能够实现更高的计算性能[[315](https://arxiv.org/html/2401.05459v2#bib.bib315)]。

剪枝通过去除网络中不太重要的连接来减少模型的大小和计算量。剪枝可以分为结构化剪枝和非结构化剪枝。结构化剪枝通常以规则的模式去除权重，例如矩阵中的矩形块或整个通道，而非结构化剪枝则没有这种约束。因此，结构化剪枝（例如 LLM-Pruner [[251](https://arxiv.org/html/2401.05459v2#bib.bib251)]）更加适合硬件实现，但更难保持模型的准确性。传统的剪枝方法通常需要昂贵的保留过程以保持模型能力，而近期的研究，如 SparseGPT [[252](https://arxiv.org/html/2401.05459v2#bib.bib252)] 和 Wanda [[253](https://arxiv.org/html/2401.05459v2#bib.bib253)]，已探索在一次性操作中执行非结构化或半结构化剪枝。

知识蒸馏（KD）通过使用表现良好的教师模型（通常具有大量参数和高精度）来指导轻量级学生模型（通常具有较少的参数和较低的精度）的训练。通过蒸馏，学生模型能够与教师模型对齐，并且只需较小的训练数据集，便有机会在下游任务中表现得更好[[256](https://arxiv.org/html/2401.05459v2#bib.bib256)]。根据教师模型的参数是否在训练过程中需要，蒸馏方法可以进一步分为白盒方法（例如 BabyLlama [[254](https://arxiv.org/html/2401.05459v2#bib.bib254)] 和 MiniLLM [[255](https://arxiv.org/html/2401.05459v2#bib.bib255)]）和黑盒方法（例如 Distilling Step-by-Step [[256](https://arxiv.org/html/2401.05459v2#bib.bib256)] 和 SCoTD [[257](https://arxiv.org/html/2401.05459v2#bib.bib257)]）。由于学生模型通常是轻量级量化或剪枝后的模型，KD 也被应用于 QAT 和剪枝技术中，以提升训练性能。例如，LLM-QAT [[248](https://arxiv.org/html/2401.05459v2#bib.bib248)] 提出了一个无数据的蒸馏方法，用以在量化模型中保持原始输出分布。

低秩分解指通过两个低秩矩阵的乘积来逼近原始的权重矩阵，从而减少模型的参数规模和计算负载。具体而言，一个形状为$m\times n$的权重矩阵$W$被分解为$U^{m\times r}$和$V^{n\times r}$的乘积，使得$W\approx UV^{T}$且$r\ll m,n$。低秩分解可以与量化（例如，ZeroQuant-V2 [[258](https://arxiv.org/html/2401.05459v2#bib.bib258)])和剪枝（例如，LoSparse [[259](https://arxiv.org/html/2401.05459v2#bib.bib259)])方法结合，以增强压缩比。此外，低秩适配器有效减少了LLM的定制开销，我们将在[5.2节](https://arxiv.org/html/2401.05459v2#S5.SS2 "5.2 Efficient Customization ‣ 5 Efficiency ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")中进一步讨论。

#### 5.1.2 推理加速

除了在[5.1.3节](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS3 "5.1.3 Memory Reduction ‣ 5.1 Efficient Inference ‣ 5 Efficiency ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")中讨论的使模型更加紧凑之外，还有各种其他技术可以加速LLM推理过程。

LLM与传统非Transformer模型的一个主要区别是注意力机制[[31](https://arxiv.org/html/2401.05459v2#bib.bib31)]。由于注意力的计算成本随着上下文长度的增加近似二次增长，因此提高长上下文推理的计算效率尤其重要。现有的研究已经探索了减少上下文长度和优化注意力内核，以更好地支持长上下文推理。我们将单独深入探讨这些技术。

KV缓存是移动端（例如，llama.cpp [[307](https://arxiv.org/html/2401.05459v2#bib.bib307)] 和 mlc-llm [[308](https://arxiv.org/html/2401.05459v2#bib.bib308)])及云端LLM服务框架（例如，DeepSpeed [[316](https://arxiv.org/html/2401.05459v2#bib.bib316)] 和 vLLM [[317](https://arxiv.org/html/2401.05459v2#bib.bib317)]）中广泛采用的技术，用于避免LLM推理中的冗余计算。具体来说，KV缓存包括存储（即“缓存”）并逐步更新Key-Value（KV）对，这些是注意力计算中的中间结果，存在于每个token的生成过程中。因此，避免了KV计算中的重复部分，从而降低了计算成本。然而，在长上下文推理中，尽管跳过了KV计算，注意力的计算成本仍然是系统瓶颈，因此在这种情况下压缩上下文长度变得尤为重要。

上下文压缩方法通过减少上下文的长度，特别是 KV 缓存的长度，来提高推理效率。权重和激活的共同量化，包括 KV 缓存，是压缩 KV 缓存的一种直观方法，这在第[5.1.1](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS1 "5.1.1 Model Compression ‣ 5.1 Efficient Inference ‣ 5 Efficiency ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")节中有所讨论。除了量化之外，上下文修剪通过移除上下文中不太重要的标记来减少计算成本。这种方法的有效性基于这样一个观察：标记对最终输出的影响不同，移除不太重要的标记不会导致模型能力的显著下降[[263](https://arxiv.org/html/2401.05459v2#bib.bib263), [318](https://arxiv.org/html/2401.05459v2#bib.bib318), [264](https://arxiv.org/html/2401.05459v2#bib.bib264), [265](https://arxiv.org/html/2401.05459v2#bib.bib265)]。一种典型的工作方式是在预填充阶段基于标记的重要性来压缩上下文[[260](https://arxiv.org/html/2401.05459v2#bib.bib260), [261](https://arxiv.org/html/2401.05459v2#bib.bib261), [262](https://arxiv.org/html/2401.05459v2#bib.bib262)]。然而，这些方法是一次性的，当上下文长度在标记生成过程中持续增长时，无法修剪 KV 缓存。为了解决这个问题，动态上下文修剪[[263](https://arxiv.org/html/2401.05459v2#bib.bib263)]采用了一个可学习机制，持续地确定并删除无信息的标记。虽然可学习机制引入了微调开销，但张等人[[264](https://arxiv.org/html/2401.05459v2#bib.bib264)]提出了一种标记驱逐策略，可以在不进行微调的情况下应用。

受相同观察启发，即标记的重要性不均衡，其他工作也探讨了通过减少不太重要的标记的计算量来代替直接移除它们。COLT5[[319](https://arxiv.org/html/2401.05459v2#bib.bib319)]采用了条件计算机制，在 FFN 和注意力机制中将更多的资源分配给重要的标记。SkipDecode[[320](https://arxiv.org/html/2401.05459v2#bib.bib320)]设计了一种标记级的提前退出方法，可以与批量推理和 KV 缓存无缝协作，在标记不重要时跳过计算图中的一些操作。

核心优化是加速LLM推理的另一种方法。针对小批量或单批量推理的优化在包括本地部署的个人LLM代理在内的边缘场景中尤为重要。现有研究表明，当序列长度较长时，注意力计算成为瓶颈，因为注意力的复杂度与序列长度的平方成正比，而前馈神经网络（FFN）的复杂度则是线性的。因此，提出了高效的注意力内核，包括FlashAttention [[266](https://arxiv.org/html/2401.05459v2#bib.bib266), [267](https://arxiv.org/html/2401.05459v2#bib.bib267)] 和FlashDecoding++ [[268](https://arxiv.org/html/2401.05459v2#bib.bib268)]，以提高长文本推理的速度。一些研究还从算法方面减少了注意力的计算复杂度。例如，Linformer [[321](https://arxiv.org/html/2401.05459v2#bib.bib321)]在预填充阶段实现了自注意力的线性复杂度。此外，减少去量化开销也能显著提升性能，正如LUT-GEMM [[322](https://arxiv.org/html/2401.05459v2#bib.bib322)]所展示的那样。

推测解码 [[270](https://arxiv.org/html/2401.05459v2#bib.bib270), [269](https://arxiv.org/html/2401.05459v2#bib.bib269)] 是一种在小批量推理中有效的方式，用于提高延迟。边缘设备上的LLM推理批量大小通常小于云端，并且通常为1（即单次查询），这使得推理工作负载非常依赖内存。推测解码通过通过一个轻量级的“草稿模型”来“猜测”几个后续的标记，然后使用大型的“oracle模型”批量验证草稿标记，从而缓解了这一挑战。Miao等人[[323](https://arxiv.org/html/2401.05459v2#bib.bib323)]以及Spector和Re[[324](https://arxiv.org/html/2401.05459v2#bib.bib324)]通过基于树的验证进一步增强了推测解码，代替了顺序验证，以便重用跨这些序列共享的中间结果。虽然这些方法确保了生成结果的零偏差，但BiLD [[325](https://arxiv.org/html/2401.05459v2#bib.bib325)]提出仅在草稿模型无法生成高质量内容时，偶尔回退或回滚到oracle模型。

#### 5.1.3 内存减少

LLM推理不仅计算密集，而且内存消耗大，这给个人LLM代理的部署带来了挑战。因此，有必要对LLM推理的内存效率进行优化。KV缓存和模型权重是造成这种内存开销的两个主要原因。在短上下文场景中，KV存储所需的内存远低于模型权重，在这种情况下，第[5.1.1](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS1 "5.1.1 模型压缩 ‣ 5.1 高效推理 ‣ 5 效率 ‣ 个人LLM代理：关于能力、效率与安全性的洞察和调查")节中的模型压缩技术非常有效，可以减少存储权重的内存需求。然而，在长上下文场景中，KV缓存的大小随着上下文长度的增加而线性增长，将主导总内存消耗。

解决这一问题的有效方法是使用第[5.1.1](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS1 "5.1.1 模型压缩 ‣ 5.1 高效推理 ‣ 5 效率 ‣ 个人LLM代理：关于能力、效率与安全性的洞察和调查")节和第[5.1.2](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS2 "5.1.2 推理加速 ‣ 5.1 高效推理 ‣ 5 效率 ‣ 个人LLM代理：关于能力、效率与安全性的洞察和调查")节中提到的量化和剪枝技术来压缩KV缓存。虽然量化方法是通用的，用于减少KV缓存的内存占用，但并非所有基于剪枝的方法都能直接提高内存效率。只有那些在持续移除上下文中的输入标记时，剪去KV缓存中对应行/列的方法，才能防止KV缓存大小超出内存限制。例如，Anagnostidis等人[[263](https://arxiv.org/html/2401.05459v2#bib.bib263)]和Zhang等人[[264](https://arxiv.org/html/2401.05459v2#bib.bib264)]提出了在生成过程中识别并驱逐无信息标记的方法。然而，仅在预填充阶段剪枝上下文的单次方法在生成场景中的效果较差。

尽管基于压缩的方法已被证明能够有效减少LLM推理的内存需求，但在某些情况下，压缩所导致的准确性下降不可忽视。为了解决这一问题，FlexGen [[271](https://arxiv.org/html/2401.05459v2#bib.bib271)] 设计了一种卸载策略，充分利用GPU、CPU和磁盘，并结合一种“之”字形调度方案，以支持在受限GPU内存下的高吞吐量推理。这种方法与基于压缩的方法是正交的，因此可以联合使用，从而进一步减少GPU内存占用。另一项研究工作，包括PowerInfer [[272](https://arxiv.org/html/2401.05459v2#bib.bib272)] 和Alizadeh等人 [[273](https://arxiv.org/html/2401.05459v2#bib.bib273)]，通过预测上下文稀疏性来减少低批次推理中的交换开销，这一灵感来源于 [[326](https://arxiv.org/html/2401.05459v2#bib.bib326)]。

#### 5.1.4 能源优化

能源消耗是影响大规模语言模型（LLM）代理在现实世界中部署的关键因素，因为LLM的计算和内存访问成本高昂。一个高能源消耗的代理不仅增加了运行时成本和碳足迹，还由于温度升高和电池寿命缩短，损害了体验质量（QoE）。因此，优化LLM推理的能源效率变得尤为重要。

由于计算和内存访问（主要是权重加载）是能源消耗大的两个主要原因，已有大量工作从软件和硬件两个角度优化这两个方面。我们在前面的章节中介绍了各种类型的软件优化。例如，模型压缩方法通过减少模型大小和计算量来节省能源；KV缓存通过避免冗余计算来节省能源；高效的注意力核也通过内存重用和局部性优化提高了能源效率。

除了软件优化，利用高效的硬件提供了提升代理系统效率的新机会。尽管CPU和GPU仍然是边缘设备上运行LLM推理的主流选择，但它们是为支持通用任务而设计的，并没有专门针对基于变压器的模型进行优化，尤其是生成型LLM。研究人员已探索利用更适合LLM推理工作负载的高效处理器，包括NPUs [[274](https://arxiv.org/html/2401.05459v2#bib.bib274)] 和TPUs [[275](https://arxiv.org/html/2401.05459v2#bib.bib275)]。然而，有限的操作符和模型支持仍然是实际部署中的挑战。此外，现有的研究也设计了基于FPGA的解决方案，通过更高的内存带宽和能源效率比（EER）来提升LLM推理的效率 [[276](https://arxiv.org/html/2401.05459v2#bib.bib276), [327](https://arxiv.org/html/2401.05459v2#bib.bib327)]。

然而，由于硬件部署的复杂性以及能源测量和分析的波动性，LLM推理的能效研究仍然远未充分。目前已有一些研究专注于这一主题，例如评估GPU上的LLM推理能耗 [[328](https://arxiv.org/html/2401.05459v2#bib.bib328)、[329](https://arxiv.org/html/2401.05459v2#bib.bib329)]、边缘设备 [[330](https://arxiv.org/html/2401.05459v2#bib.bib330)] 以及数据中心中LLM的碳足迹 [[331](https://arxiv.org/html/2401.05459v2#bib.bib331)]。其他研究倾向于提出LLM推理的快速能量预测方法，如IrEne [[332](https://arxiv.org/html/2401.05459v2#bib.bib332)]，它对基于Transformer的NLP模型进行了层级能量分析，并提供了一个可解释且可扩展的能量预测系统。然而，这些预测模型仅适用于GPU主机后端，且缺乏对其他硬件平台（如手机）的泛化能力，而个人LLM代理更可能在这些设备上部署。

<svg class="ltx_picture" height="127.15" id="S5.SS1.SSS4.p5.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,127.15) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 16.6 6.92)"><foreignobject color="#000000" height="113.31" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="566.79">Remark. How to improve the efficiency of LLM inference has been extensively studied recently. Despite the remarkable progress, there is still a large gap towards the ubiquitous and affordable deployment of Personal LLM Agents. The open problems are: 1. Is it possible to further compress or design highly compact models without accuracy degradation, surpassing the scaling law of language models? 2. If the scaling law is unbreakable, how can we achieve optimal tradeoffs between efficiency and quality via dynamic inference (e.g., dynamic collaboration of big model and small model)? 3. How would the hardware and operating systems evolve to accommodate the efficient deployment of LLMs and Personal LLM Agents?</foreignobject></g></g></svg>

### 5.2 高效定制

个人LLM代理可能需要在相同的基础LLM上为不同的用户、任务和场景提供服务，这就要求针对每种情况进行高效的定制。定制LLM行为主要有两种方式：一种是通过提供不同的上下文提示进行上下文学习，另一种是通过特定领域的数据对LLM进行调优。因此，定制的效率主要由上下文加载效率和LLM微调效率决定。

#### 5.2.1 上下文加载效率

在个人LLM代理的多任务服务过程中，频繁的上下文加载是不可避免的，因为每个任务或场景可能需要新的上下文来进行LLM推理。然而，个人设备固有的严格资源限制对个人LLM代理快速有效地处理繁重的上下文信息构成了重大挑战。为了提高上下文加载的效率，有多种方法可供选择。最直接的方法是修剪一些冗余的标记或缩短上下文长度，这在[5.1节](https://arxiv.org/html/2401.05459v2#S5.SS1 "5.1 Efficient Inference ‣ 5 Efficiency ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")中已有讨论。

提升上下文加载的另一种方法是减少上下文数据传输过程中的带宽消耗。在某些情况下，修剪或丢弃一些标记不可避免地会影响大型语言模型（LLM）的性能，而加载键值（KV）缓存则需要高带宽成本。CacheGen [[285](https://arxiv.org/html/2401.05459v2#bib.bib285)] 解决了上下文加载带来的挑战，并利用标记和层之间KV特征的独特特性，提出了一种新型的KV编码器设计。该编码器高效地将KV缓存压缩为紧凑的比特流，显著降低带宽需求，同时减少处理延迟。此外，考虑到不同输入提示可能有重叠的文本段，Gim等人[[333](https://arxiv.org/html/2401.05459v2#bib.bib333)]提出了提示缓存（Prompt Cache），用于在不同提示间重用注意力状态。通过预计算并存储频繁出现文本的注意力状态，该框架可以在这些文本段出现在新提示中时高效地重用，从而加速推理过程。

#### 5.2.2 微调效率

另外，微调基础的LLM以更好地支持特定领域的任务也是很有必要的，但由于LLM中大量参数的存在，这对计算资源和内存占用带来了显著挑战。为了解决这些问题，已经有多项工作提出了不同的解决方案，通常可以分为参数高效微调技术、高效优化器设计和训练数据整理，接下来的章节将详细讨论这些方法。

参数高效微调（PEFT）。大规模语言模型（LLMs）中的大量参数使得进行全参数微调变得成本高昂。为减少LLMs的训练开销，许多关于参数高效微调的研究相继出现。PEFT的基本概念是冻结大部分参数，仅专注于训练一个有限的参数集合或引入一个具有显著较少参数的适配器。一种常见做法是将一些适配器（即小型神经网络模块）引入现有的网络结构，包括调整隐藏状态[[277](https://arxiv.org/html/2401.05459v2#bib.bib277)、[278](https://arxiv.org/html/2401.05459v2#bib.bib278)、[334](https://arxiv.org/html/2401.05459v2#bib.bib334)]，添加完整的层[[277](https://arxiv.org/html/2401.05459v2#bib.bib277)]，以及在变换器架构中预先添加一些前缀向量[[335](https://arxiv.org/html/2401.05459v2#bib.bib335)、[336](https://arxiv.org/html/2401.05459v2#bib.bib336)、[337](https://arxiv.org/html/2401.05459v2#bib.bib337)]。Liu等人[[338](https://arxiv.org/html/2401.05459v2#bib.bib338)]还在输入层中加入了可训练向量，其性能高度依赖于基础模型的能力。部分研究未能避免额外的适配器计算，且引入了推理延迟。LoRA [[279](https://arxiv.org/html/2401.05459v2#bib.bib279)]冻结了所有模型权重，并通过额外的秩分解矩阵增强每个变换器层，从而在微调过程中大大减少了内存和存储的使用，同时不增加额外的推理延迟。LoRA的另一个优势是，用户可以通过简单地添加或删除适配器矩阵，轻松切换不同的下游任务。$\mathtt{(IA)^{3}}$ [[339](https://arxiv.org/html/2401.05459v2#bib.bib339)]探索了对模型激活值与学习到的向量进行元素级别的乘法。它引入了学习到的向量，这些向量对注意力机制中的键和值以及位置相关的前馈网络中的内部激活进行重缩放。通过仅训练这些向量，$\mathtt{(IA)^{3}}$能够以更少的计算量维持相同的性能。

高效优化器设计。高效优化器设计是另一类训练/微调策略，旨在加速训练过程或减少训练期间的内存开销。Sophia [[281](https://arxiv.org/html/2401.05459v2#bib.bib281)]，一种轻量级的二阶优化器，通过提供比常用方法（如Adam及其变体）更高效的优化过程，解决了LLM预训练所需的高成本和时间。另一方面，庞大的参数量要求特别是在较大批次大小时，存储更多的激活和优化器状态，这对内存提出了很大的需求。LOMO [[280](https://arxiv.org/html/2401.05459v2#bib.bib280)]提供了关于所提优化器与其他方法相比，在内存使用、吞吐量和下游性能方面的详细分析，展示了在保持训练效率的同时显著减少了内存使用。赵等人 [[340](https://arxiv.org/html/2401.05459v2#bib.bib340)]提出了HiZOO，旨在利用对角Hessian矩阵增强零阶优化器，以便微调LLM。它通过每步增加一次前向传播来避免昂贵的内存开销。

训练数据整理。前述方法主要关注训练LLM的过程，而也有一些研究旨在从另一个角度提高LLM的训练性能，即训练数据的数量和质量。在phi-1 [[282](https://arxiv.org/html/2401.05459v2#bib.bib282)]中已经证明，使用少量高质量数据训练LLM可以显著降低训练成本，并实现与大规模数据集和模型相当的能力。这挑战了深度学习中强调更大数据集和模型的传统扩展法则。此外，phi-1.5 [[283](https://arxiv.org/html/2401.05459v2#bib.bib283)]和phi-2 [[284](https://arxiv.org/html/2401.05459v2#bib.bib284)]扩展了它们对许多其他任务的关注，例如常识推理和语言理解，分别达到了与5倍和25倍更大模型相当的性能。同样，TinyGSM [[341](https://arxiv.org/html/2401.05459v2#bib.bib341)]引入了一个包含少量（12.3M）样本的综合数据集，涵盖了小学数学领域，在使用该数据集调优小型语言模型时取得了显著的准确度。

值得注意的是，这些方法通常假设LLM可以完全适应设备内存，而这一假设对于在通常内存和计算能力有限的个人设备上部署的个人LLM代理并不实际。在这些设备上微调LLM通常需要利用分层存储，例如CPU内存甚至磁盘存储。因此，在个人设备上微调LLM时，必须仔细考虑当前系统的资源限制。

<svg class="ltx_picture" height="141.06" id="S5.SS2.SSS2.p6.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,141.06) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 16.6 6.92)"><foreignobject color="#000000" height="127.22" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="566.79">Remark. While efficient model fine-tuning and in-context learning techniques have been extensively studied, it is yet unclear what is the ideal mechanism for customizing Personal LLM Agents under different situations. Here we highlight two open problems that may be specifically important in the system for Personal LLM Agents. 1. Similar to the operating system that manages the RAM for the applications, how should the agent system efficiently manage the contexts for different (and potentially parallel) agents, tasks, and users? 2. Similar to mobile apps that can be efficiently installed, uninstalled and moved between devices, how can a customized (fine-tuned) agent efficiently roll back to the previous versions or transfer to other base models?</foreignobject></g></g></svg>

### 5.3 高效内存操作

个人LLM代理需要频繁地检索外部存储，以便做出更有根据的决策，这通常依赖于一种被称为检索增强生成（Retrieval-Augmented Generation，RAG）的机制。考虑到外部存储数据的多样形式，如用户个人资料、互动历史和本地原始文件（图像、视频等），常见做法是使用嵌入模型[[342](https://arxiv.org/html/2401.05459v2#bib.bib342), [343](https://arxiv.org/html/2401.05459v2#bib.bib343)]以统一且高维的向量格式表示存储的数据。向量之间的距离表示了相应数据之间的语义相似性。对于每个给定的查询，个人LLM代理需要在外部存储中找到最相关的内容。然后，检索到的知识将通过提示拼接或中间层跨注意力[[301](https://arxiv.org/html/2401.05459v2#bib.bib301)]注入到个人LLM代理中，这两种方式都会增加LLM推理的上下文复杂性。这导致LLM在长上下文中进行更高效的计算，并尽量减少推理过程中的内存占用，类似于在第[5.1](https://arxiv.org/html/2401.05459v2#S5.SS1 "5.1 Efficient Inference ‣ 5 Efficiency ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")节讨论的提高LLM推理效率的做法。

因此，在本小节中，我们主要关注高效的外部存储检索，这可以从两个方面来考虑：高效的搜索和高效的工作流程。高效的搜索关注于向量索引和在像向量库（如Faiss [[344](https://arxiv.org/html/2401.05459v2#bib.bib344), [345](https://arxiv.org/html/2401.05459v2#bib.bib345), [346](https://arxiv.org/html/2401.05459v2#bib.bib346)]，SCaNN [[229](https://arxiv.org/html/2401.05459v2#bib.bib229)]）、向量数据库[[347](https://arxiv.org/html/2401.05459v2#bib.bib347), [348](https://arxiv.org/html/2401.05459v2#bib.bib348), [349](https://arxiv.org/html/2401.05459v2#bib.bib349)]，或一些定制的存储外部存储数据的内存结构[[350](https://arxiv.org/html/2401.05459v2#bib.bib350), [351](https://arxiv.org/html/2401.05459v2#bib.bib351)]中进行快速搜索。高效的工作流程则针对进一步优化检索增强LLM推理的端到端效率。

#### 5.3.1 搜索效率

在比较查询向量$q$与外部存储中的向量之间的相似性时，暴力搜索方法的计算复杂度为$O(DN)$。然而，对于具有大向量维度($D$)和数据集规模($N$)的场景，这种方法变得不切实际。为了减轻搜索开销，通常采用索引技术，通过减少所需比较次数来加速查询搜索。

典型的索引算法。通过分区方案[[348](https://arxiv.org/html/2401.05459v2#bib.bib348)]，将数据集$S$划分为较小的子集，从而实现选择性比较和更快速的搜索查询处理。这些分区随后被组织成数据结构，如表格、树和图，以便高效遍历。常用的分区方法包括随机化（如RPTree [[287](https://arxiv.org/html/2401.05459v2#bib.bib287)、[352](https://arxiv.org/html/2401.05459v2#bib.bib352)]和E2LSH [[286](https://arxiv.org/html/2401.05459v2#bib.bib286)]）、学习分区（如SPANN [[288](https://arxiv.org/html/2401.05459v2#bib.bib288)]）和可导航分区（如NSW [[353](https://arxiv.org/html/2401.05459v2#bib.bib353)]和HNSW [[289](https://arxiv.org/html/2401.05459v2#bib.bib289)]）。这些分区方法可以与不同的数据结构结合使用。例如，Vamana [[354](https://arxiv.org/html/2401.05459v2#bib.bib354)]是一个单调搜索网络，采用图形索引并使用随机初始化。

硬件感知索引优化。由于提高索引的可扩展性和效率已成为一个关键问题，研究人员也集中于硬件感知的方法，以在保持低延迟和高吞吐量的同时扩展外部存储容量。这是通过利用基于磁盘的索引或硬件与算法的协同设计[[355](https://arxiv.org/html/2401.05459v2#bib.bib355)]来实现的。例如，DiskANN [[290](https://arxiv.org/html/2401.05459v2#bib.bib290)]通过采用混合的DRAM-SSD方法来提高成本效益。它在SSD上采用Vamana图形索引，并在DRAM中使用压缩点表示。这种配置使得即便在处理包含十亿个点的数据库时，也能以不到10毫秒的延迟提供准确的查询响应。DiskANN++ [[356](https://arxiv.org/html/2401.05459v2#bib.bib356)]通过引入动态入口顶点选择和优化SSD布局进一步提高了效率。这一改进使得每秒查询次数（QPS）提高了1.5倍至2.2倍，同时在实际数据集上保持了准确性。此外，CXL-ANNS [[291](https://arxiv.org/html/2401.05459v2#bib.bib291)]引入了协作的软件-硬件方法，用于可扩展的近似最近邻搜索（ANNS）。通过利用计算扩展链路（CXL），CXL-ANNS将DRAM与主机解耦，并将关键数据集整合到其内存池中。FANNS [[292](https://arxiv.org/html/2401.05459v2#bib.bib292)]是一个基于FPGA的向量搜索框架，具有根据用户定义的召回要求和硬件限制自动协同设计硬件和算法的功能。它支持通过硬件TCP/IP堆栈进行扩展，并且与FPGA和CPU基准相比，展现了显著的加速效果。

在搜索效率分析和优化方面，一些方面与搜索机制设计有关，例如相似度度量、搜索范围、查询类型、选择及优化。而另一方面，一些方面则侧重于搜索过程的高效执行。

搜索机制设计。可以采用多种相似度标准来评估向量相似度，包括海明距离、余弦距离和聚合得分[[296](https://arxiv.org/html/2401.05459v2#bib.bib296)]。然而，得分机制的选择缺乏严格的原则，通常依赖于经验法则[[348](https://arxiv.org/html/2401.05459v2#bib.bib348)]。关于搜索类型，可以使用近似搜索和精确的$k(\geq 1)$最近邻[[355](https://arxiv.org/html/2401.05459v2#bib.bib355)]搜索，也可以进行距离范围搜索，以检索相应的向量。为了优化搜索延迟，通常采用基于规则[[293](https://arxiv.org/html/2401.05459v2#bib.bib293), [294](https://arxiv.org/html/2401.05459v2#bib.bib294)]或基于估算成本的方法[[295](https://arxiv.org/html/2401.05459v2#bib.bib295), [296](https://arxiv.org/html/2401.05459v2#bib.bib296)]来确定最佳的搜索方案。这些规则和成本模型通常在离线配置，以避免不必要或耗时的搜索操作。为了进一步优化搜索过程，将向量搜索与元数据过滤器结合的混合操作正变得越来越流行。这涉及到如预过滤[[295](https://arxiv.org/html/2401.05459v2#bib.bib295), [296](https://arxiv.org/html/2401.05459v2#bib.bib296), [354](https://arxiv.org/html/2401.05459v2#bib.bib354)]、后过滤和单阶段过滤[[297](https://arxiv.org/html/2401.05459v2#bib.bib297)]等技术，以缩小向量搜索的范围。

搜索过程执行。可以采取多种硬件加速方法来提高搜索执行效率。例如，为了实现并行查询处理，Faiss [[298](https://arxiv.org/html/2401.05459v2#bib.bib298)] 使用了 OpenMP 多线程，而 Milvus [[296](https://arxiv.org/html/2401.05459v2#bib.bib296)] 进一步减少了 CPU 缓存未命中，并使用了一种新型的细粒度机制来最充分地利用多核并行性。此外，Faiss 和 Quicker ADC [[299](https://arxiv.org/html/2401.05459v2#bib.bib299)] 还支持 SIMD 洗牌指令，以在单个 SIMD 处理器中并行化这些表查找。GPU 也被用于快速查询处理 [[357](https://arxiv.org/html/2401.05459v2#bib.bib357), [358](https://arxiv.org/html/2401.05459v2#bib.bib358), [359](https://arxiv.org/html/2401.05459v2#bib.bib359)]，如 Faiss 和 Milvus 等向量数据库。许多向量数据库管理系统还支持分布式集群，以便扩展到更大的数据集或更重的工作负载，如 Vald [[300](https://arxiv.org/html/2401.05459v2#bib.bib300)]、Qdrant [[293](https://arxiv.org/html/2401.05459v2#bib.bib293)] 等。

#### 5.3.2 工作流优化

无论是一次性还是迭代式RAG系统，传统的工作流都是顺序执行的，在进行检索/生成时推理/检索阶段会处于空闲状态。这个特性忽略了通过执行并行性和请求的检索局部性优化的潜力。近期的研究正在探索流水线和缓存技术，以进一步提高RAG系统的效率。

流水线。RaLMSpec [[301](https://arxiv.org/html/2401.05459v2#bib.bib301)] 是首个利用流水线优势的工作，通过为推测性检索启用本地缓存来实现。为了保持正确性，采用了批处理验证步骤来保证准确性。此外，还采用了缓存预取、最佳推测步长调度器和异步验证，以进一步提升推测性能。PipeRAG [[302](https://arxiv.org/html/2401.05459v2#bib.bib302)] 也使用了流水线，并通过两种不同的解决方案来增强其性能：灵活的检索间隔和一个性能模型，用于根据流水线中即将到来的LLM推理的延迟预期动态调整向量搜索空间。PipeRAG利用算法-系统协同设计，以避免在优化搜索质量的同时增加端到端生成延迟。

缓存。选择缓存方法的原因来自于在不同请求中检索文档的时间局部性和空间局部性，这一点在RaLMSpec [[301](https://arxiv.org/html/2401.05459v2#bib.bib301)]中已经得到了应用。RAGCache [[303](https://arxiv.org/html/2401.05459v2#bib.bib303)]进一步利用知识树来组织GPU和主机内存层次中检索文档的中间状态。它还提出了一种前缀感知的贪婪双大小频率（PGDSF）替换策略和一种缓存感知的请求调度方法，以最小化缓存未命中率。另一项工作GRITLM [[304](https://arxiv.org/html/2401.05459v2#bib.bib304)]通过指令区分生成任务和嵌入任务，训练语言模型处理这两种任务。由于RAG中的常见场景是使用嵌入模型为生成模型提供相关上下文，以回答用户查询，使用GRITLM时，嵌入模型和生成模型是等价的，从而使我们能够进行查询缓存或查询-文档缓存，并节省计算开销。

<svg class="ltx_picture" height="127.15" id="S5.SS3.SSS2.p4.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,127.15) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 16.6 6.92)"><foreignobject color="#000000" height="113.31" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="566.79">Remark. Managing memory data with external vector storage is not a new requirement for LLM agents. While many basic technical challenges have been adequately addressed, we point out two problems that demand specific consideration for Personal LLM Agents. 1. Personal LLM Agents may frequently update the memory. Thus, the external memory is expected to facilitate fast updates, maintenance, and re-indexing. 2. The memory of Personal LLM Agents may be stored on personal devices with limited storage space, while the memory of the personal agents will accumulate over time. Therefore, it is necessary to effectively compress the memory to avoid fast-growing space and computational cost.</foreignobject></g></g></svg>

## 6 安全与隐私

![请参阅说明](img/7b908e2220cbc5fc8121b9c3a10f7a1f.png)

图11：解决个人LLM代理的安全性和隐私问题的技术总结。

敏感个人数据和安全关键个人工具的广泛集成使得个人LLM代理与常规LLM代理有所不同。因此，确保个人LLM代理中用户数据隐私和服务安全的保护成为一个至关重要的问题。在个人LLM代理的背景下，我们专注于三个安全原则，包括保密性、完整性和可靠性，如图[11](https://arxiv.org/html/2401.05459v2#S6.F11 "Figure 11 ‣ 6 Security and Privacy ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")所示。保密性表示对用户数据隐私的保护，确保在用户与代理交互过程中不会发生不必要的和未经授权的敏感信息泄露。完整性表示代理决策的弹性，确保代理执行的行为与预期行为一致，并且没有被恶意方故意修改或影响。可靠性则侧重于使代理行为更加可靠和真实。与完整性不同，完整性问题中的错误答案是由于外部故意操控引起的，而可靠性关注的是代理内部的错误。

### 6.1 保密性

在本小节中，我们讨论了保护个人LLM代理中用户隐私的可能方法。如前所述，确保用户隐私对访问大量用户敏感数据的个人代理至关重要。与传统的基于LLM的聊天机器人不同，用户通常会明确输入文本，而个人LLM代理有可能在用户未察觉的情况下主动发起查询，这些查询可能包含关于用户的敏感信息。同时，这些代理还可能将用户信息暴露给其他代理或服务。因此，保护用户隐私变得尤为重要。为了增强机密性，有多种方法，包括本地数据处理、同态加密、数据屏蔽、权限访问控制等。

#### 6.1.1 本地处理

保护用户隐私的一种简单有效的方法是在用户的个人设备上本地执行计算。虽然大型语言模型（LLM）服务提供商目前正在努力提高安全性并建立用户信任，但必须承认，将私人数据传输到云端本质上会带来额外的潜在风险。因此，相比于将数据传输到云端，本地处理所有数据被认为是一种更安全的与LLM互动的方法。然而，由于个人设备的资源限制，在本地部署LLM面临着有效处理用户请求的挑战。这可能导致推理速度变慢，甚至由于可用内存的限制而无法进行推理。由于个人LLM代理中的数据主要由LLM处理，因此实现本地计算的关键是将LLM运行在用户的设备上。现在有多种现有的轻量级模型[[360](https://arxiv.org/html/2401.05459v2#bib.bib360)，[283](https://arxiv.org/html/2401.05459v2#bib.bib283)]和部署框架[[361](https://arxiv.org/html/2401.05459v2#bib.bib361)，[308](https://arxiv.org/html/2401.05459v2#bib.bib308)，[362](https://arxiv.org/html/2401.05459v2#bib.bib362)]可用于在边缘设备上部署模型。此外，还提出了多种模型压缩技术[[363](https://arxiv.org/html/2401.05459v2#bib.bib363)，[250](https://arxiv.org/html/2401.05459v2#bib.bib250)，[246](https://arxiv.org/html/2401.05459v2#bib.bib246)]，用于减小模型大小，以进一步实现本地部署，具体内容请参见第[5.1.3节](https://arxiv.org/html/2401.05459v2#S5.SS1.SSS3 "5.1.3 Memory Reduction ‣ 5.1 Efficient Inference ‣ 5 Efficiency ‣ Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security")。

然而，尽管研究人员付出了诸多努力，使用本地部署的模型不可避免地面临模型准确性有限的挑战[[43](https://arxiv.org/html/2401.05459v2#bib.bib43)]。大多数领域专家也建议采用云-边协作部署方法，以实现更好的性能权衡。与此同时，像其他软件应用程序一样，许多个人化LLM代理也需要与云端进行通信，以提供在线服务。通常，很难甚至不可能将私密数据完全保存在本地设备上。

#### 6.1.2 安全远程处理

为了在保持隐私的同时调用基于云的模型推理服务，一个理想的解决方案是同态加密（HE）[[364](https://arxiv.org/html/2401.05459v2#bib.bib364), [365](https://arxiv.org/html/2401.05459v2#bib.bib365)]。在这种方法中，客户端使用加密对用户的明文请求进行编码，服务器对生成的密文进行模型推理。随后，客户端接收加密格式的推理结果，并在解密后获得明文结果。有几项研究[[366](https://arxiv.org/html/2401.05459v2#bib.bib366)]展示了将HE应用于深度神经网络（DNN）的可行性，展示了将HE整合到模型中的潜力。

在个人化大型语言模型（LLM）代理中使用同态加密（HE）时，会遇到两个挑战。第一个挑战涉及到一个限制，即并非所有LLM内部的操作都能通过HE执行。HE最多支持无限次的加法（相当于布尔电路中的XOR）和乘法（相当于布尔电路中的AND）。然而，LLM中的某些操作，如max、min和softmax，无法通过HE准确执行。第二个挑战是HE推理速度较慢，因为LLM的计算复杂度非常高。

有几种解决方案可以解决这两个问题。The-x [[367](https://arxiv.org/html/2401.05459v2#bib.bib367)]提出了一种工作流程，用于将原始的非线性层替换为可以通过HE计算的层。在HE无法执行某些操作（如Max操作）的情况下，加密文本将被发送回本地设备。本地设备将执行该操作，并将重新加密的文本发送回云端。Cheetah [[368](https://arxiv.org/html/2401.05459v2#bib.bib368)]包括一系列针对服务器端系统上的HE推理设计的算法和硬件优化。Cheetah的主要目标是提高HE的计算效率，从而加速HE操作的速度。

然而，尽管在加速基于HE的DNN推理方面做出了许多努力，当前的同态加密技术仍远未满足代理对延迟的要求[[369](https://arxiv.org/html/2401.05459v2#bib.bib369)]。

除了同态加密（HE），多方通信（MPC）[[370](https://arxiv.org/html/2401.05459v2#bib.bib370)]是传统应用密码学中的一个重要部分，指的是涉及多个参与方的通信过程，在这个过程中，多个参与者需要在不可信的环境中进行交流。在大型语言模型（LLM）中应用MPC的挑战在于高昂的计算成本，以及从MPC的数学理论到在LLM上的实际实现的巨大过渡。Crypten[[371](https://arxiv.org/html/2401.05459v2#bib.bib371)]是一个包括常见MPC方法的框架，支持标准的PyTorch张量操作，并启用GPU计算。

实现机密远程数据处理的另一种方法是使用受信执行环境（TEE）[[372](https://arxiv.org/html/2401.05459v2#bib.bib372)]进行模型推理。然而，TEE可能会受到各种攻击[[373](https://arxiv.org/html/2401.05459v2#bib.bib373)]，并且可能导致性能受限。

#### 6.1.3 数据屏蔽

另一种方法是使用数据屏蔽，在将信息发送到云端之前对其进行预处理。基本的思路是将原始输入转换为一种不涉及隐私的形式，同时保留对推理结果具有重要影响的信息。

数据屏蔽的一种直接方法是通过隐藏或替换敏感内容（如账户号码、地址和个人姓名）来转换明文输入。这些信息通常被称为个人可识别信息（PII）。然而，由于PII的边界模糊且形式多样，准确界定PII可能具有挑战性，这使得从原始内容中一致地识别和移除PII变得困难。美国国家标准与技术研究院（NIST）提供了一份指南[[374](https://arxiv.org/html/2401.05459v2#bib.bib374)]，该指南提供了保护PII机密性的建议，有助于更安全地管理PII。EmojiCrypt[[375](https://arxiv.org/html/2401.05459v2#bib.bib375)]建议使用表情符号替代用户的敏感信息，然后使用修改后的句子进行生成。

另一方面，研究人员提出了基于嵌入的数据匿名化方法，其中客户端将原始用户请求编码为隐藏向量，并将这些向量发送到基于云的模型进行后续推理。挑战在于如何确保隐私得到保护，如何确保推理准确性不会下降，如何确保推理速度不会大幅下降。有几种解决方案。Coavoux 等人[[376](https://arxiv.org/html/2401.05459v2#bib.bib376)]提出了一种度量标准，用于评估神经表示中的隐私泄露程度，并通过改变训练目标开发了一种防御方法，以实现隐私和准确性之间的折衷。Zhou 等人[[377](https://arxiv.org/html/2401.05459v2#bib.bib377)]通过向中间表示中添加动态融合来保护用户隐私。TextObfuscator[[378](https://arxiv.org/html/2401.05459v2#bib.bib378)]通过文本混淆技术保护用户隐私。在编码过程中，可以通过引入额外的约束来使用“对抗性表示学习”，以最小化编码向量中包含隐私敏感信息的可能性[[379](https://arxiv.org/html/2401.05459v2#bib.bib379)]。尽管该方法在推理性能上优于同态加密，但通常无法严格保护数据隐私，因为编码向量本身仍然存在泄露敏感信息的风险。此外，这些方法需要明确定义隐私特征，以便编码器在对抗性表示学习过程中学习如何去除隐私信息。

#### 6.1.4 信息流控制

上述技术主要涉及模型输入数据的隐私性，但模型输出中也可能存在隐私泄露的风险。这是因为模型的输出不仅可能直接返回给用户，还可能被发送到其他第三方应用、模型、用户或智能代理。例如，当智能代理帮助用户进行餐厅预订时，它可能会获取用户的基本资料和日程信息，并将其输入到餐厅预订软件中。同样，当企业旨在向用户推荐产品时，他们可能依赖从某些个人代理输出中获取的用户偏好信息。通过LLM输出获取隐私信息的这种方式类似于传统操作系统中的个人数据访问接口，在这些系统中，确保隐私数据访问的控制与透明度非常关键，这通常需要通过权限管理系统来实现[[380](https://arxiv.org/html/2401.05459v2#bib.bib380)]。透明度要求告知用户关于隐私数据访问的相关信息，包括访问主体（谁）、内容（什么）、时间（何时）、意图（为什么）、访问方式（如何）等。Evertz等人[[381](https://arxiv.org/html/2401.05459v2#bib.bib381)]提出了一种评估LLM集成系统中隐私泄露的方法。

也可以直接要求LLMs保留私人信息。然而，由于LLMs是基于统计学工作，而非基于明确规则，因此它们的安全性不能被严格证明。因此，在处理数据机密性时，我们不应将LLMs视为受信计算基（TCB）的一部分。因此，我们可能需要基于规则的权限控制来约束LLMs能做什么以及能访问什么。权限机制允许用户配置不同实体是否被允许访问不同类型的信息。在个人LLM代理中，设计权限机制的挑战之一在于界定隐私数据的类型，因为第三方应用获取的内容是由模型生成的。在传统系统中，研究人员已经提出了许多关于细粒度隐私内容细分和权限控制的方法，以及基于信息流传播的隐私数据追踪技术[[382](https://arxiv.org/html/2401.05459v2#bib.bib382)]。然而，为LLM代理生成的输出建立隐私数据追踪仍然是一个未解决的问题。

<svg class="ltx_picture" height="157.66" id="S6.SS1.SSS4.p3.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,157.66) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 16.6 6.92)"><foreignobject color="#000000" height="143.83" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="566.79">Remark. Ensuring the confidentiality of user data is crucial for Personal LLM Agents to build user trusts. However, existing privacy protection techniques are still not sufficient to support agents with higher levels of intelligence. There are following open problems: 1. Existing approaches face a common challenge to balance efficiency and effectiveness. For example, how can we enable powerful and efficient local LLMs, how can we scale homomorphic encryption (HE) or trusted execution environment (TEE) to large models, and how can data masking/obfuscation techniques achieve rigorous confidentiality? 2. As a new software paradigm, it is still unclear what is the systematic privacy protection mechanism for Personal LLM Agents. Do we still need symbolic rules or permissions for access control? How can they seamlessly integrate with the uninterpretable nature of LLMs?</foreignobject></g></g></svg>

### 6.2 完整性

完整性指的是个人LLM代理能够确保在面对各种类型的攻击时，仍能正确输出预期内容的能力。由于个人LLM代理需要与多种数据、应用和其他代理进行交互，因此可能存在恶意第三方试图窃取用户数据和资产，或通过非常规手段破坏系统的正常功能。因此，系统必须能够抵御各种类型的攻击。传统的攻击方式，如模型参数的修改、数据盗窃和本地数据篡改，可以通过加密、权限管理、硬件隔离等措施进行防御。然而，除了防御传统的攻击方式外，还应关注LLM代理可能遇到的新型攻击：对抗性攻击、后门攻击和提示注入攻击。

#### 6.2.1 对抗性攻击

恶意攻击主要通过定制模型输入或恶意篡改模型来实现其目标。一类重要的攻击被称为“对抗性攻击”，通过定制或篡改模型的输入数据导致模型推理错误，这一现象最初在图像分类模型中被发现[[383](https://arxiv.org/html/2401.05459v2#bib.bib383)]。这种类型的攻击通过向图像中添加难以察觉的噪声，能够引发严重的分类错误。随后，研究人员将这种攻击方法扩展到了文本数据、图形数据等其他领域[[384](https://arxiv.org/html/2401.05459v2#bib.bib384)]。这种攻击在大型语言模型中依然存在[[385](https://arxiv.org/html/2401.05459v2#bib.bib385)]，这些模型也可能接收来自第三方的图像[[386](https://arxiv.org/html/2401.05459v2#bib.bib386)]、文本[[387](https://arxiv.org/html/2401.05459v2#bib.bib387)]以及其他数据形式[[388](https://arxiv.org/html/2401.05459v2#bib.bib388)]。例如，在帮助用户自动化任务时，攻击者可能误导代理删除日历事件或泄露私人对话数据[[389](https://arxiv.org/html/2401.05459v2#bib.bib389)]，因为大型语言模型通常需要输入应用程序的内部信息以生成下一个交互决策。在这种情况下，如果第三方应用程序向LLM提供恶意定制的内容，它可能会导致智能代理进行不安全的交互。传统的深度学习模型防御方法通常包括对抗防御、异常输入检测、输入预处理、输出安全验证等[[384](https://arxiv.org/html/2401.05459v2#bib.bib384)]。虽然这些方法在理论上依然适用于LLM和LLM代理，但由于参数规模庞大以及自回归生成的特点，一些计算开销较大的方法（如基于困惑度的输出安全验证和基于中间层激活检测异常数据）可能很难实现。此外，某些防御方法在LLM的背景下可能需要调整。例如，训练LLM可能会产生巨大的成本，因此通过对抗训练来增强安全性可能不切实际。因此，探索如何通过参数高效的微调来实现良好的对抗防御效果值得进一步研究。Zhu等人[[390](https://arxiv.org/html/2401.05459v2#bib.bib390)]指出，当前的解决方案可能过于乐观：防御这些攻击是可能的：对抗性攻击生成无限但无法读取的胡言乱语提示，可以通过基于困惑度的过滤器进行检测；手动越狱攻击生成可读的提示，但由于需要人类创造力的限制，其数量有限，因此可以轻松阻止。随后，他们介绍了AutoDAN，这是一种可解释的基于梯度的对抗性攻击，结合了两种攻击类型的优点。在越狱和可读性这两个目标的指导下，AutoDAN从左到右逐个优化并生成令牌，生成可读的提示，这些提示能够绕过困惑度过滤器，同时保持较高的攻击成功率，这为对LLM进行红队测试和通过可解释性理解越狱机制提供了一种新方法。

#### 6.2.2 后门攻击

另一种常见的攻击形式是后门攻击。传统的模型后门攻击通常通过数据中毒实现[[391](https://arxiv.org/html/2401.05459v2#bib.bib391)]，即将恶意修改的样本插入模型的训练数据中，使得模型学习到故意隐藏的决策逻辑，例如“当看到一个苹果图案时，模型输出一个错误的分类”。对于大语言模型（LLMs）来说，由于训练数据量巨大且统一管理严格，数据中毒可能更具挑战性，但另一种后门攻击方法[[392](https://arxiv.org/html/2401.05459v2#bib.bib392)]仍然有效，即通过在测试时修改模型输入来植入不安全的逻辑。Kandpal等人[[393](https://arxiv.org/html/2401.05459v2#bib.bib393)]在提示语言模型执行特定目标任务时，引发了有针对性的误分类。ProAttack[[394](https://arxiv.org/html/2401.05459v2#bib.bib394)]直接利用提示作为触发器，将后门注入LLMs中，这是首次探索基于提示的干净标签文本后门攻击。PoisonPrompt[[395](https://arxiv.org/html/2401.05459v2#bib.bib395)]是一种基于双层优化的提示后门攻击，适用于软提示和硬提示的LLMs。由于LLMs在某些场景中通常使用若干固定的提示，这种通过修改提示实现的攻击，本质上是微调模型的参数，从而改变其决策逻辑。Han等人[[396](https://arxiv.org/html/2401.05459v2#bib.bib396)]从中毒的预训练编码器中提取良性知识，并将其转移到新的编码器上，从而获得一个干净的预训练编码器，这可能会损害LLMs的性能。Sun等人[[397](https://arxiv.org/html/2401.05459v2#bib.bib397)]提出，通过测试生成源与目标之间的反向概率，可以有效防御不同类型的攻击。事实上，当攻击者模仿正常行为时，这种防御方法可能会变得无效。因此，目前在智能体系统中尚无强大的后门防御解决方案[[398](https://arxiv.org/html/2401.05459v2#bib.bib398)]。这突显了开发有效防御复杂攻击（这些攻击模仿合法行为）的需求。

#### 6.2.3 提示注入攻击

在 LLM 时代，出现了一种新的特别重要的安全风险，即提示注入攻击[[399](https://arxiv.org/html/2401.05459v2#bib.bib399), [400](https://arxiv.org/html/2401.05459v2#bib.bib400), [401](https://arxiv.org/html/2401.05459v2#bib.bib401), [402](https://arxiv.org/html/2401.05459v2#bib.bib402)]。在这种攻击方式中，模型本身通过对齐和提示机制内置了某些安全防护措施。然而，第三方模型用户可以通过在提示中使用微妙或特殊的措辞来绕过这些预设的安全防护措施。例如，智能个人助手可能预设不执行某些敏感操作，例如修改用户的账户密码[[403](https://arxiv.org/html/2401.05459v2#bib.bib403)]，但通过提示注入（例如，请求 LLM “忽略之前设定的限制”或“假设在授权的安全模式下操作”），可以诱使模型违反规定并执行这些敏感操作。

对于这种基于提示的攻击方法，目前尚没有完美的防御机制。SmoothLLM[[404](https://arxiv.org/html/2401.05459v2#bib.bib404)] 是第一个通用的提示注入防御方法，它通过随机扰动给定输入提示的多个副本，然后聚合相应的预测结果以检测对抗性输入。然而，它的防御效果高度依赖于模型的鲁棒性，因为某些模型的攻击成功率仅减少了约 1%。缓解这一问题的一个重要方法是确保 LLM 提示的透明性和安全性。例如，个人 LLM 代理可以严格控制提示的模板和规格，要求所有请求都必须符合预设的模板和规格。此外，第三方应用输入内容的后处理（如总结、翻译、重述等）或提示封装（例如，在前后添加明确的文本以标示其来源为第三方）可以帮助模型清晰地区分这些内容与系统固有的提示。

<svg class="ltx_picture" height="148.06" id="S6.SS2.SSS3.p3.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,148.06) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 16.6 6.92)"><foreignobject color="#000000" height="134.22" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="566.79">Remark. Ensuring the integrity of the decision process is crucial for Personal LLM Agents. The threats to integrity are very diverse and continuously evolving, while the development of defensive techniques are lying behind. Here we highlight two important open problems that apply to all types of attacks. 1. How can the agents know if their input or decision process has been tampered with by third parties? This requires the agents to have a sense of what are normal input and behaviors, and have the abilities to recognize the anomalies. 2. Since directly avoiding the attacks may be challenging, it would be more practical to consider user verification mechanisms, i.e., asking the user to verify when the agents are uncertain. How to design a secure and user-friendly verification mechanism is challenging.</foreignobject></g></g></svg>

### 6.3 可靠性

在个人 LLM 代理中，LLM 决定了众多关键操作，包括一些敏感操作，例如修改和删除用户信息、购买服务以及发送消息。因此，确保代理决策过程的可靠性至关重要。我们从三个方面讨论 LLM 的可靠性问题，包括问题（即，LLM 的可靠性问题从哪里体现？）、改进（即，我们如何让 LLM 的响应更可靠？）和检查（即，我们如何处理 LLM 可能不可靠的输出？）。

#### 6.3.1 问题

幻觉。大语言模型可能会产生不正确的答案，这可能会导致严重后果。与通过文本直接与用户互动的大语言模型聊天机器人相比，个人大语言模型代理通过避免频繁的结果验证来减少用户干扰，从而加剧了产生错误答案的严重性。研究人员发现，大语言模型有时会生成连贯且流畅的文本，但最终却是错误的。这种现象在自然语言处理任务中被称为幻觉，它同样对个人代理构成挑战。Ji等人[[405](https://arxiv.org/html/2401.05459v2#bib.bib405)]深入探讨了自然语言处理任务中幻觉的各种表现形式。Rawte等人[[406](https://arxiv.org/html/2401.05459v2#bib.bib406)]进一步讨论了多模态基础模型中的幻觉现象，为有兴趣的读者提供了有价值的参考。

未识别的操作。与聚焦于大语言模型（LLM）产生的“错误答案”的幻觉问题不同，许多情况下，这些模型的回应是“甚至连错误都算不上”。例如，假设大语言模型被指示使用“CALL XXXXXX”格式来发起电话呼叫。在这种情况下，大语言模型可能会生成回应“我将拨打XXXX”，虽然准确传达了意图，但偏离了指定的格式，导致无法执行。正如我们所知，大语言模型的本质是语言建模，语言模型的输出通常是语言的形式。与直接与人类互动的其他大语言模型不同，个人大语言模型代理（Personal LLM Agents）需要执行动作。因此，它们对输出格式和可执行性有更高的要求[[407](https://arxiv.org/html/2401.05459v2#bib.bib407)]。

顺序可靠性。大型语言模型（LLMs）最初在顺序数据（即语料库）和训练目标（即从左到右的语言建模任务）上进行预训练。然而，现实世界中的问题可能并不完全是顺序处理的。实现顺序可靠性面临诸多挑战，包括上下文的保持、连贯性的维护等。为了更好地与用户和个人 LLM 代理维持连贯且有意义的对话，我们需要激发 LLM 的全球视角思维能力，而不仅仅依赖于先前生成的标记或上下文。在提升 LLM 思考和推理能力方面，Yao 等人[[85](https://arxiv.org/html/2401.05459v2#bib.bib85)]提出了思维树方法，通过多个不同的推理路径生成和得出结论；Zhang 等人[[408](https://arxiv.org/html/2401.05459v2#bib.bib408)]提出了累积推理方法，以累积和迭代的方式解决复杂任务。此外，还可以设计解决任务的整体计划[[89](https://arxiv.org/html/2401.05459v2#bib.bib89)]，或从以往的工作中汲取启示[[409](https://arxiv.org/html/2401.05459v2#bib.bib409), [410](https://arxiv.org/html/2401.05459v2#bib.bib410)]。

#### 6.3.2 改进

改进方法旨在提高 LLM 输出的质量，从而增强基于 LLM 的代理的可靠性。

对齐。随着大型语言模型（LLM）在规模和复杂性上不断增长，人们开始担心它们可能会生成有偏见、有害或不当的内容。对齐方法旨在减少这些风险，并确保LLM的行为符合伦理和社会规范。一个常见的对齐方法是使用预训练和微调[[411](https://arxiv.org/html/2401.05459v2#bib.bib411)、[412](https://arxiv.org/html/2401.05459v2#bib.bib412)、[413](https://arxiv.org/html/2401.05459v2#bib.bib413)]。LLM在大量文本数据上进行预训练，以学习语言模式和表示。在微调阶段，模型会在更加具体且精心挑选的数据集上进一步训练，包括人类生成的示例和演示。这个过程通过将人类的价值观和意图纳入训练，帮助模型与期望的行为保持一致。另一个对齐方法是奖励建模，它涉及定义和优化一个反映期望结果或行为的奖励函数。通过为特定的行为提供明确的奖励或惩罚，可以训练LLM生成与这些预定义目标一致的输出。强化学习技术（例如，RLHF [[44](https://arxiv.org/html/2401.05459v2#bib.bib44)]、RLAIF [[414](https://arxiv.org/html/2401.05459v2#bib.bib414)]、C-RLFT [[415](https://arxiv.org/html/2401.05459v2#bib.bib415)]）可以被用来基于这些奖励信号优化模型的行为。监督和干预是关键的对齐方法。人类审阅者或主持人在审查和筛选LLM的输出时发挥着至关重要的作用，目的是发现潜在的偏见、有害内容或不当行为。他们的反馈和干预用于迭代地改善模型的表现，并将其与期望的标准对齐。

自我反思。研究表明，语言模型能够提供正确答案的概率[[416](https://arxiv.org/html/2401.05459v2#bib.bib416)]。受大型语言模型（LLM）自主运行的启发，研究人员提出可以利用模型的自我反思来缓解错误内容生成的问题。黄等人[[241](https://arxiv.org/html/2401.05459v2#bib.bib241)]和Madaan等人[[417](https://arxiv.org/html/2401.05459v2#bib.bib417)]表明，LLM能够利用无标签数据进行自我改进，Shinn等人[[418](https://arxiv.org/html/2401.05459v2#bib.bib418)]提出了Reflexion方法，通过语言反馈让LLM进行更新。陈等人[[419](https://arxiv.org/html/2401.05459v2#bib.bib419)]提出了Self-Debug方法，用于在多个代码生成任务中迭代地改进响应。SelfCheckGPT [[420](https://arxiv.org/html/2401.05459v2#bib.bib420)]允许大型模型对相同的输入问题提供多次答案，并检查这些回答之间的一致性。如果答案之间存在矛盾，说明模型生成了不可靠的内容的可能性较高。杜等人[[421](https://arxiv.org/html/2401.05459v2#bib.bib421)]尝试通过让多个大型模型代理进行互相讨论和验证，来提高模型输出的可靠性。将模型进行组合的方式有很多种，类似于人类社会中的多样化合作方式。然而，就像更多员工意味着更多开支一样，更多的模型也意味着更高的计算能力要求。上述工作展示了LLM从单纯的文本生成器向智能代理转变的趋势，从基于理解的初级推理过渡到具有迭代更新的反思性推理。

检索增强。大语言模型（LLMs）在各种任务中表现出强大的性能，然而，模型中存储的参数化知识仍然可能不完整，且难以高效更新。作为替代方案，检索增强方法[[229](https://arxiv.org/html/2401.05459v2#bib.bib229), [230](https://arxiv.org/html/2401.05459v2#bib.bib230), [422](https://arxiv.org/html/2401.05459v2#bib.bib422)]提供了一种半参数化的方式，能够提供互补的非参数化信息，允许LLMs在生成内容时调用检索到的现实世界知识，例如维基百科、文档或知识图谱[[423](https://arxiv.org/html/2401.05459v2#bib.bib423)]。这种方法的优点是不需要对模型进行修改，便于实时信息更新，并且可以追溯生成结果的原始数据，从而增强生成信息的可解释性。检索增强已被证明对传统的预训练模型，如BERT[[424](https://arxiv.org/html/2401.05459v2#bib.bib424)]，是有效的。然而，对于那些已经具备强大推理能力的LLMs，增强上下文可能会产生负面影响，原因在于引入了无关或噪声信息[[425](https://arxiv.org/html/2401.05459v2#bib.bib425)]。为了解决这些问题，Guo等人[[222](https://arxiv.org/html/2401.05459v2#bib.bib222)]提出了一种针对非知识密集型任务的提示引导检索方法，提高了检索段落与更一般查询的相关性。Yu等人[[426](https://arxiv.org/html/2401.05459v2#bib.bib426)]提出了Chain-of-Note，以在处理噪声和无关文档时提高鲁棒性。Asai等人[[427](https://arxiv.org/html/2401.05459v2#bib.bib427)]提出了Self-RAG，通过自我反思增强事实性。Wang等人[[428](https://arxiv.org/html/2401.05459v2#bib.bib428)]提出了SKR，一种自我知识引导的检索方法，用于平衡外部知识和内部知识。Wang等人[[429](https://arxiv.org/html/2401.05459v2#bib.bib429)]提出了FLICO，通过提前过滤上下文并提高检索段落的细粒度相关性。CRITIC[[430](https://arxiv.org/html/2401.05459v2#bib.bib430)]框架利用LLMs通过与外部工具（如计算器、Python解释器和维基百科）的交互验证并迭代自我修正其输出。Zhang等人[[431](https://arxiv.org/html/2401.05459v2#bib.bib431)]提出了RAFT，一种检索增强微调方法，用于改善领域特定的问答。然而，这些方法仍然依赖于高性能的文本检索器，并且在用户请求中，无法轻易从外部知识库找到匹配内容时，提供的帮助有限。

#### 6.3.3 检索增强

另一方面，基于检查的方法不会干扰LLM生成过程。相反，它侧重于如何基于已经生成的结果来增强或理解代理的可靠性。

验证。鉴于在实际应用中部署大型语言模型（LLM）时无法完全避免内容生成的不可靠问题，因此仍然有必要建立基于规则的安全验证机制。关于前述未识别的操作，“受限生成”是指生成格式化且受限的输出过程，可以用来解决这个问题。Kumar 等人[[432](https://arxiv.org/html/2401.05459v2#bib.bib432)]通过 Langevin 动力学仿真实现非自回归文本生成，作为解决这一问题的方法。另一方面，Miao 等人[[433](https://arxiv.org/html/2401.05459v2#bib.bib433)]提出了一种方法，在每次迭代中建议候选修改，并验证修改后的句子是否满足给定的约束条件，从而生成受限句子。Li 等人[[434](https://arxiv.org/html/2401.05459v2#bib.bib434)]和Weng 等人[[435](https://arxiv.org/html/2401.05459v2#bib.bib435)]提出了自我验证方法，以帮助大型语言模型的推理过程。负责任的任务自动化[[99](https://arxiv.org/html/2401.05459v2#bib.bib99)]是一种系统，可以预测命令的可行性，确认执行者的完整性，并增强大型语言模型的安全性。然而，仍需进一步研究以提高识别敏感操作的准确性和召回率，并减轻用户的决策负担。

说明。虽然之前提到过，智能个人助手应尽量减少对用户的干扰，但在做出重要决策时，纳入用户意见或人工协助是有价值的。如果智能个人助手犯了错误，具有可解释的逻辑也有助于后续的调试过程。有几项调查研究[[436](https://arxiv.org/html/2401.05459v2#bib.bib436)、[437](https://arxiv.org/html/2401.05459v2#bib.bib437)、[438](https://arxiv.org/html/2401.05459v2#bib.bib438)]讨论了解释性语言模型。传统上，可以通过基于推理的方法[[439](https://arxiv.org/html/2401.05459v2#bib.bib439)、[440](https://arxiv.org/html/2401.05459v2#bib.bib440)]，通过显式训练人类标注的数据来解释模型输出。对于大规模语言模型（LLMs）而言，链式推理[[84](https://arxiv.org/html/2401.05459v2#bib.bib84)]方法也能帮助模型生成文本解释。为了使推理过程更加稳健和可靠，近期的研究进一步通过多数投票[[441](https://arxiv.org/html/2401.05459v2#bib.bib441)]和迭代自举[[442](https://arxiv.org/html/2401.05459v2#bib.bib442)]机制增强了链式推理的效果。显然，研究人员非常重视可解释性，因为它不仅有助于提高可靠性，还代表着一个有趣的研究方向。

中间特征分析。除了最后一层的表示外，一些研究还涉及分析模型推理过程中的中间状态，以判断虚假信息的生成。Halawi等人[[443](https://arxiv.org/html/2401.05459v2#bib.bib443)]发现，模型在某些层的行为可能会大幅偏离，突显了分析模型中间计算的重要性。Li等人[[444](https://arxiv.org/html/2401.05459v2#bib.bib444)]发现，模型中间层的激活可以揭示“真实度”的一些方向，表明大规模语言模型可能已经捕捉到了某些知识，尽管并未生成，他们进一步提出在推理过程中调整模型激活，并改进LLM的响应。van der Poel等人[[445](https://arxiv.org/html/2401.05459v2#bib.bib445)]提出了一种利用互信息的方法，通过评估下一个标记的置信度来缓解幻觉问题，其根本原因在于大规模语言模型在生成虚假内容时的神经激活模式与正常输出不同。这些研究突出了仅依赖最后一层表示进行语言建模的不足，揭示了利用模型不同层次的层次信息的潜在好处。

<svg class="ltx_picture" height="193.2" id="S6.SS3.SSS3.p5.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,193.2) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 16.6 6.92)"><foreignobject color="#000000" height="179.36" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="566.79">Remark. The reliability of LLM generation has received considerable amount of attention, especially around the hallucination problem. However, avoiding the unreliable behaviors is still difficult, if not impossible. The open problems include: 1. How can we evaluate the reliability of LLM and LLM agents? Existing methods rely on either black-box LLMs such as GPT-4 or costly human annotations. Authoritative benchmarks and methods are desired for evaluating and improving the reliability. 2. Similar to the confidentiality problem, incorporating rigorous symbolic rules in the decision process of Personal LLM Agents would be a practical solution for reliability. However, complying with the rules while retaining powerful capabilities of LLM agents is challenging. 3. The lack of transparency and interpretability of DNNs has been a long-standing problem, which is even more critical for all security & privacy aspects of Personal LLM Agents. How to interpret and explain the internal mechanisms of LLMs is a direction that worth continuous investigation.</foreignobject></g></g></svg>

## 7 结论与展望

大型语言模型的出现为智能个人助手的发展带来了新的机遇，具有革新人机交互方式的潜力。本文聚焦于个人LLM代理，基于领域专家反馈和广泛的文献综述，系统地讨论了若干关键的机遇与挑战。

目前，个人LLM代理的研究仍处于早期阶段。任务执行能力仍然相对不足，支持的功能范围较窄，留有较大的改进空间。此外，确保此类个人代理的效率、可靠性和可用性需要解决许多关键的性能和安全问题。LLM中大量参数所需的高服务质量与个人代理在资源、隐私和安全方面的限制之间存在固有的矛盾。

展望未来，除了应对各个具体方向的挑战外，还需要共同努力，建立个人LLM代理的完整软件/硬件堆栈和生态系统。研究人员和工程师还需仔细考虑此类技术的责任，以确保个人LLM代理的良性和辅助性质。

## 致谢

本工作得到了中国国家自然科学基金（NSFC，资助号62272261）以及与亚信科技（中国）有限公司和小米公司合作研究项目的支持。我们诚挚感谢许多领域专家的宝贵反馈，包括彭晓波（汽车之家）、陈立庚（荣耀设备）、苗伟、何鹏鹏（华为）、洪汉生、陈文俊、杨志尧（OPPO）、齐学生（vivo）、陶亮、孙立顺、董爽（小米）及其他匿名专家。在共同作者中，刘家成、许文星和孔锐在撰写本文时是清华大学人工智能产业研究院（AIR）的实习生。

## 参考文献

+   Apple [2023a] Apple. Siri. [https://www.apple.com/siri/](https://www.apple.com/siri/)，2023a。[在线；访问日期：2023年12月26日]。

+   Google [2023a] Google. Android版Google助手。 [https://developer.android.com/guide/app-actions/overview](https://developer.android.com/guide/app-actions/overview)，2023a。[在线；访问日期：2023年12月24日]。

+   Amazon [2023] Amazon. Alexa。 [https://www.alexa.com](https://www.alexa.com)，2023。[在线；访问日期：2023年12月26日]。

+   李等 [2020] 李扬、何家聪、周鑫、张元、贾森·巴尔德里奇。将自然语言指令映射到移动UI动作序列，2020。

+   Li和Riva [2021] Yuanchun Li和Oriana Riva. Glider: 一种通过强化学习从网站提取UI脚本的方法。在*第44届国际ACM SIGIR信息检索研究与发展会议论文集*，SIGIR ’21，1420–1430页，美国纽约，2021年。计算机协会。ISBN 9781450380379。doi: 10.1145/3404835.3462905。

+   Liu等 [2018] Evan Zheran Liu，Kelvin Guu，Panupong Pasupat，Tianlin Shi 和 Percy Liang. 基于工作流引导探索的网页接口强化学习。*ArXiv*，abs/1802.08802，2018年。

+   Zhao等 [2023a] Wayne Xin Zhao，Kun Zhou，Junyi Li，Tianyi Tang，Xiaolei Wang，Yupeng Hou，Yingqian Min，Beichen Zhang，Junjie Zhang，Zican Dong，Yifan Du，Chen Yang，Yushuo Chen，Zhipeng Chen，Jinhao Jiang，Ruiyang Ren，Yifan Li，Xinyu Tang，Zikang Liu，Peiyu Liu，Jian-Yun Nie 和 Ji-Rong Wen. 大型语言模型综述，2023a。

+   IBM [2023] IBM. IBM shoebox. [https://www.ibm.com/ibm/history/exhibits/specialprod1/specialprod1_7.html](https://www.ibm.com/ibm/history/exhibits/specialprod1/specialprod1_7.html)，2023年。[在线；访问日期：2023年12月26日]。

+   Lowerre和Reddy [1976] Bruce Lowerre和R Reddy. 哈比语音识别系统：在大词汇量下的表现。*美国声学学会杂志*，60(S1):S10–S11，1976年。

+   Cerf-Danon等 [1991] Helene Cerf-Danon，Steven DeGennaro，Marco Ferretti，Jorge Gonzalez 和 Eric Keppel. 1\. 0 TANGORA - 一种用于五种语言的大词汇量语音识别系统。在*第二届欧洲语音通信与技术会议（Eurospeech 1991）*的论文集中，183–192页，1991年。doi: 10.21437/Eurospeech.1991-44。

+   Rabiner和Juang [1986] L. Rabiner 和 B. Juang. 隐马尔可夫模型介绍。*IEEE ASSP杂志*，3(1):4–16，1986年。doi: 10.1109/MASSP.1986.1165342。

+   Bamberg等 [1990] Paul G. Bamberg，Yen lu Chow，Larry Gillick，Robert Roth 和 Dean G. Sturtevant. 龙连续语音识别系统：一种实时实现。在*人类语言技术 - 波罗的海视角*，1990年。

+   Wikipedia [2023a] Wikipedia. 可发声条目。[https://en.wikipedia.org/wiki/Speakable_items](https://en.wikipedia.org/wiki/Speakable_items)，2023年。[在线；访问日期：2023年1月5日]。

+   Lai和Vergo [1997] Jennifer Lai和John Vergo. Medspeak: 使用连续语音识别生成报告。在*ACM SIGCHI计算机系统中的人因会议论文集*，CHI ’97，431–438页，美国纽约，1997年。计算机协会。ISBN 0897918029。doi: 10.1145/258549.258829。

+   Microsoft [2002] Microsoft. 语音转录 - jim allchin，winhec 2002。[https://news.microsoft.com/speeches/speech-transcript-jim-allchin-winhec-2002/](https://news.microsoft.com/speeches/speech-transcript-jim-allchin-winhec-2002/)，2002年。[在线；访问日期：2023年1月5日]。

+   Markoff [2008] John Markoff. Google正在接受问题（通过iPhone语音）。[https://www.nytimes.com/2008/11/14/technology/internet/14voice.html](https://www.nytimes.com/2008/11/14/technology/internet/14voice.html), 2008. [在线访问；最后访问日期：2024年1月5日]。

+   Microsoft [2023a] Microsoft. Cortana。[https://www.microsoft.com/en-us/cortana](https://www.microsoft.com/en-us/cortana)，2023a。[在线访问；最后访问日期：2023年12月26日]。

+   OpenAI [2022] OpenAI. 介绍ChatGPT。[https://openai.com/blog/chatgpt](https://openai.com/blog/chatgpt)，2022。[在线访问；最后访问日期：2023年11月28日]。

+   Microsoft [2023b] Microsoft. 宣布推出Microsoft Copilot，您的日常AI助手。[https://blogs.microsoft.com/blog/2023/09/21/announcing-microsoft-copilot-your-everyday-ai-companion/](https://blogs.microsoft.com/blog/2023/09/21/announcing-microsoft-copilot-your-everyday-ai-companion/)，2023b。[在线访问；最后访问日期：2023年12月4日]。

+   Apple [2023b] Apple. Sirikit: 通过语音、智能建议和个性化工作流程使用户能够与设备互动。[https://developer.apple.com/documentation/sirikit/](https://developer.apple.com/documentation/sirikit/)，2023b。[在线访问；最后访问日期：2023年12月24日]。

+   Apple [2023c] Apple. Shortcuts用户指南。[https://support.apple.com/en-hk/guide/shortcuts/welcome/ios](https://support.apple.com/en-hk/guide/shortcuts/welcome/ios)，2023c。[在线访问；最后访问日期：2023年12月24日]。

+   Joaoapps [2023] Joaoapps. Tasker：安卓设备的全面自动化。[https://tasker.joaoapps.com](https://tasker.joaoapps.com)，2023。[在线访问；最后访问日期：2023年12月24日]。

+   Absinthe [2023] Absinthe. Anywhere shortcuts. [https://play.google.com/store/apps/details?id=com.absinthe.anywhere_&hl=en_US&pli=1](https://play.google.com/store/apps/details?id=com.absinthe.anywhere_&hl=en_US&pli=1), 2023. [在线访问；最后访问日期：2023年12月24日]。

+   Li et al. [2017a] Toby Jia-Jun Li, Yuanchun Li, Fanglin Chen, 和 Brad A Myers. 通过演示使用移动应用程序对物联网设备进行编程。在*End-User Development: 第六届国际研讨会，IS-EUD 2017，荷兰埃因霍温，2017年6月13日至15日，论文集6*，第3–17页。Springer，2017a。

+   Azim et al. [2016] Tanzirul Azim, Oriana Riva, 和 Suman Nath. Ulink: 启用用户定义的深度链接到应用内容。在*第14届国际移动系统、应用和服务年会论文集*，MobiSys ’16，第305–318页，美国纽约，2016。计算机协会。ISBN 9781450342698。doi: 10.1145/2906388.2906416。

+   Cowan 等人 [2017] Benjamin R. Cowan, Nadia Pantidi, David Coyle, Kellie Morrissey, Peter Clarke, Sara Al-Shehri, David Earley, 和 Natasha Bandeira. “我能为你做些什么？”：偶尔使用者对智能个人助理的体验。在 *第19届国际移动设备和服务人机交互会议（MobileHCI）* 上，MobileHCI ’17，纽约，美国，2017年。计算机学会出版。ISBN 9781450350754。doi: 10.1145/3098279.3098539.

+   Baughan 等人 [2023] Amanda Baughan, Xuezhi Wang, Ariel Liu, Allison Mercurio, Jilin Chen, 和 Xiao Ma. 一种混合方法理解语音助手失败后的用户信任。在 *2023年人机交互会议（CHI Conference on Human Factors in Computing Systems）论文集* 中，CHI ’23，纽约，美国，2023年。计算机学会出版。ISBN 9781450394215。doi: 10.1145/3544548.3581152.

+   Luger 和 Sellen [2016] Ewa Luger 和 Abigail Sellen. “就像有一个非常糟糕的私人助理”：用户期望与会话代理体验之间的差距。在 *2016年人机交互会议（CHI Conference on Human Factors in Computing Systems）论文集* 中，CHI ’16，页面 5286–5297，纽约，美国，2016年。计算机学会出版。ISBN 9781450333627。doi: 10.1145/2858036.2858288.

+   Hoy [2018] Matthew B. Hoy. Alexa、Siri、Cortana 等：语音助手简介。*医学参考服务季刊*，37(1):81–88，2018年。doi: 10.1080/02763869.2018.1404391。PMID: 29327988.

+   Li 等人 [2019] Yuanchun Li, Ziyue Yang, Yao Guo, 和 Xiangqun Chen. Humanoid：一种基于深度学习的自动化黑盒安卓应用测试方法。在 *2019年第34届IEEE/ACM国际自动化软件工程会议（ASE）* 上，页面 1070–1073，IEEE，2019年。

+   Vaswani 等人 [2017] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, 和 Illia Polosukhin. 注意力即你所需。在 *第31届国际神经信息处理系统会议（NIPS）* 上，NIPS’17，页面 6000–6010，Red Hook，纽约，美国，2017年。Curran Associates Inc. ISBN 9781510860964.

+   He 等人 [2020] Zecheng He, Srinivas Sunkara, Xiaoxue Zang, Ying Xu, Lijuan Liu, Nevan Wichers, Gabriel Schubiner, Ruby B. Lee, 和 Jindong Chen. Actionbert：利用用户行为进行用户界面语义理解。在 *2020年人工智能会议（AAAI Conference on Artificial Intelligence）* 上，2020年。

+   Fu 等人 [2021] Jingwen Fu, Xiaoyi Zhang, Yuwang Wang, Wenjun Zeng, Sam Yang, 和 Grayson Hilliard. 理解移动GUI：从像素-单词到屏幕-句子。*ArXiv*，abs/2105.11941，2021年。URL [https://api.semanticscholar.org/CorpusID:235187035](https://api.semanticscholar.org/CorpusID:235187035).

+   Li 等人 [2021] Yang Li, Gang Li, Xin Zhou, Mostafa Dehghani, 和 Alexey A. Gritsenko. Vut：多模态多任务用户界面建模的通用UI变换器。*ArXiv*，abs/2112.05692，2021年。

+   Bai 等人 [2021] Chongyang Bai, Xiaoxue Zang, Ying Xu, Srinivas Sunkara, Abhinav Rastogi, Jindong Chen, 和 Blaise Agüera y Arcas. Uibert: 学习用于 UI 理解的通用多模态表示. 在 *第30届国际人工智能联合会议论文集，IJCAI-21* 中，页面 1705–1712. 国际人工智能联合会议组织, 2021年8月. doi: 10.24963/ijcai.2021/235. 主会道.

+   Li 和 Li [2022] Gang Li 和 Yang Li. Spotlight: 使用视觉-语言模型聚焦于移动 UI 理解. *ArXiv*, abs/2209.14927, 2022.

+   Banerjee 等人 [2023] Pratyay Banerjee, Shweti Mahajan, Kushal Arora, Chitta Baral, 和 Oriana Riva. Lexi: 自监督学习 UI 语言. *ArXiv*, abs/2301.10165, 2023.

+   Li 等人 [2023a] Wei Li, Fu-Lin Hsu, Will Bishop, Folawiyo Campbell-Ajala, Oriana Riva, 和 Max Lin. Uinav: 一个 UI 自动化代理的创建者. *arXiv 预印本 arXiv:2312.10170*, 2023a.

+   Shi 等人 [2017] Tianlin Tim Shi, Andrej Karpathy, Linxi Jim Fan, Jonathan Hernandez, 和 Percy Liang. 世界的比特：一个用于基于网页代理的开放领域平台. 在 *第34届国际机器学习大会论文集 - 卷 70* 中，ICML’17，页面 3135–3144. JMLR.org, 2017.

+   Gur 等人 [2018] Izzeddin Gur, Ulrich Rückert, Aleksandra Faust, 和 Dilek Z. Hakkani-Tür. 学习如何浏览网页. *ArXiv*, abs/1812.09195, 2018.

+   Jia 等人 [2019] Sheng Jia, Jamie Ryan Kiros, 和 Jimmy Ba. Dom-q-net: 基于结构化语言的强化学习. *ArXiv*, abs/1902.07257, 2019.

+   Humphreys 等人 [2022] Peter C. Humphreys, David Raposo, Tobias Pohlen, Gregory Thornton, Rachita Chhaparia, Alistair Muldal, Josh Abramson, Petko Georgiev, Adam Santoro, 和 Timothy Lillicrap. 一种数据驱动的方法来学习控制计算机. 在 *国际机器学习大会* 中，页面 9466–9482. PMLR, 2022.

+   Kaplan 等人 [2020] Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, 和 Dario Amodei. 神经语言模型的扩展规律, 2020.

+   Ouyang 等人 [2022] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, 和 Ryan Lowe. 训练语言模型以通过人类反馈遵循指令, 2022.

+   Christiano 等人 [2023] Paul Christiano, Jan Leike, Tom B. Brown, Miljan Martic, Shane Legg, 和 Dario Amodei. 从人类偏好中学习深度强化学习, 2023.

+   Schick 等人 [2023] Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, 和 Thomas Scialom. Toolformer: 语言模型可以自学使用工具, 2023.

+   Nakano 等人 [2022] Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, 和 John Schulman。Webgpt：基于浏览器的问答系统与人工反馈，2022年。

+   Furuta 等人 [2023] Hiroki Furuta, Ofir Nachum, Kuang-Huei Lee, Yutaka Matsuo, Shixiang Shane Gu, 和 Izzeddin Gur。多模态网页导航与经过指令微调的基础模型。*ArXiv*，abs/2305.11854，2023年。

+   Singh 等人 [2023] Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei Xu, Jonathan Tremblay, Dieter Fox, Jesse Thomason, 和 Animesh Garg。Progprompt：使用大语言模型生成情境化的机器人任务计划。在*2023 IEEE 国际机器人与自动化会议（ICRA）*，第11523–11530页。IEEE，2023年。

+   Zhen 等人 [2023] Yue Zhen, Sheng Bi, Lu Xing-tong, Pan Wei-qin, Shi Hai-peng, Chen Zi-rui, 和 Fang Yi-shu。基于大型语言模型表示知识的有向图结构进行机器人任务规划，2023年。

+   Huang 等人 [2022a] Wenlong Huang, Pieter Abbeel, Deepak Pathak, 和 Igor Mordatch。语言模型作为零-shot 规划器：为具身智能体提取可操作知识，2022a年。

+   Shen 等人 [2023] Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, 和 Yueting Zhuang。Hugginggpt：通过 chatgpt 及其在 Hugging Face 的朋友解决 AI 任务，2023年。

+   Wang 等人 [2023a] Ke Wang, Houxing Ren, Aojun Zhou, Zimu Lu, Sichun Luo, Weikang Shi, Renrui Zhang, Linqi Song, Mingjie Zhan, 和 Hongsheng Li。Mathcoder：在大型语言模型中无缝集成代码以增强数学推理。*ArXiv*，abs/2310.03731，2023a年。

+   Rozière 等人 [2023] Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy Rapin, Artyom Kozhevnikov, I. Evtimov, Joanna Bitton, Manish P Bhatt, Cristian Cantón Ferrer, Aaron Grattafiori, Wenhan Xiong, Alexandre D’efossez, Jade Copet, Faisal Azhar, Hugo Touvron, Louis Martin, Nicolas Usunier, Thomas Scialom, 和 Gabriel Synnaeve。Code Llama：开源的代码基础模型。*ArXiv*，abs/2308.12950，2023年。

+   Zhou 等人 [2023a] Aojun Zhou, Ke Wang, Zimu Lu, Weikang Shi, Sichun Luo, Zipeng Qin, Shaoqing Lu, Anya Jia, Linqi Song, Mingjie Zhan, 和 Hongsheng Li。使用 GPT-4 代码解释器和基于代码的自我验证解决具有挑战性的数学文字题，2023a年。

+   OpenAI [2023] OpenAI。GPT-4 技术报告，2023年。

+   微软 [2023c] 微软。用全新人工智能驱动的微软必应和Edge重新定义搜索，为网络提供你的副驾驶。[https://blogs.microsoft.com/blog/2023/02/07/reinventing-search-with-a-new-ai-powered-microsoft-bing-and-edge-your-copilot-for-the-web/](https://blogs.microsoft.com/blog/2023/02/07/reinventing-search-with-a-new-ai-powered-microsoft-bing-and-edge-your-copilot-for-the-web/)，2023c。[在线；访问日期：2023年12月8日]。

+   谷歌 [2023b] 谷歌。Bard：谷歌的对话式人工智能工具。[https://bard.google.com](https://bard.google.com)，2023b。[在线；访问日期：2023年12月26日]。

+   谷歌 [2023c] 谷歌。推出Gemini：我们最大的、最强大的人工智能模型。[https://blog.google/technology/ai/google-gemini-ai/](https://blog.google/technology/ai/google-gemini-ai/)，2023c。[在线；访问日期：2023年12月26日]。

+   华为 [2023] 华为。通过人工智能重塑产业：华为云推出盘古模型3.0和昇腾AI云服务。[https://www.huaweicloud.com/intl/en-us/news/20230707180809498.html](https://www.huaweicloud.com/intl/en-us/news/20230707180809498.html)，2023年。[在线；访问日期：2023年11月28日]。

+   小米 [2023] 小米。MIlm-6B。[https://github.com/XiaoMi/MiLM-6B](https://github.com/XiaoMi/MiLM-6B)，2023年。[在线；访问日期：2023年12月24日]。

+   博哈里 [1995] 赛义德·纳伊姆·博哈里。Linux操作系统。*计算机*，28(8):74-79，1995年。

+   维基百科 [2023b] 维基百科。博尔达计数。[https://en.wikipedia.org/wiki/Borda_count](https://en.wikipedia.org/wiki/Borda_count)，2023b。[在线；访问日期：2023年12月13日]。

+   李 [2022] 李金宇。端到端自动语音识别的最新进展，2022年。

+   普拉巴瓦尔卡尔等 [2023] 罗希特·普拉巴瓦尔卡尔，堀贵明，塔拉·N·赛纳特，拉尔夫·施吕特，渡边真治。端到端语音识别：一项调查，2023年。

+   王等 [2023b] 王磊，马晨，冯雪扬，张泽宇，杨浩，张景森，陈志远，唐佳凯，陈旭，林彦凯，赵鑫，魏哲伟，温继荣。基于大语言模型的自主智能体调查，2023b。

+   习等 [2023] 习志恒，陈文祥，郭欣，何伟，丁艺文，洪博阳，张铭，王俊哲，金森杰，周恩宇，郑锐，范晓然，王晓，熊黎茂，周宇豪，王维然，姜长浩，邹一成，刘向阳，尹张跃，窦诗涵，翁荣祥，程文森，张齐，秦文娟，郑永言，邱熙鹏，黄宣静，桂涛。基于大语言模型的智能体的崛起与潜力：一项调查，2023年。

+   张等 [2023a] 张卓生，姚瑶，张阿斯顿，唐向如，马新北，何志伟，王一鸣，马克·杰尔斯坦，王瑞，刘恭申，赵海。点燃语言智能：从链式思维推理到语言智能体的“搭便车”指南，2023a。

+   Young 等人 [2013] Steve Young, Milica Gašić, Blaise Thomson 和 Jason D. Williams。基于POMDP的统计语音对话系统：综述。*IEEE会议录*，101(5):1160–1179，2013年。doi: 10.1109/JPROC.2012.2225812。

+   Rastogi 等人 [2018] Abhinav Rastogi, Raghav Gupta 和 Dilek Hakkani-Tur。联合语言理解和对话状态追踪的多任务学习。在*第19届年会SIGdial会议论文集*，第376–384页，澳大利亚墨尔本，2018年7月。计算语言学会。doi: 10.18653/v1/W18-5045。

+   Li 和 Riva [2018] Toby Jia-Jun Li 和 Oriana Riva。Kite：从移动应用构建对话机器人。在*第16届年国际移动系统、应用与服务会议论文集*，MobiSys ’18，第96–109页，美国纽约，2018年。计算机协会。ISBN 9781450357203。doi: 10.1145/3210240.3210339。

+   Li 等人 [2017b] Toby Jia-Jun Li, Amos Azaria 和 Brad A. Myers。Sugilite：通过示范创建多模态智能手机自动化。在*2017年CHI计算机系统人因会议论文集*，CHI ’17，第6038–6049页，美国纽约，2017b年。计算机协会。ISBN 9781450346559。doi: 10.1145/3025453.3025483。

+   Lee 等人 [2023a] Sang-Woo Lee, Sungdong Kim, Donghyeon Ko, Donghoon Ham, Youngki Hong, Shin Ah Oh, Hyunhoon Jung, Wangkyo Jung, Kyunghyun Cho, Donghyun Kwak, Hyungsuk Noh 和 Woomyoung Park。当前的任务导向对话模型能否在实际场景中自动化？2023a年。

+   Chung 等人 [2023] Willy Chung, Samuel Cahyawijaya, Bryan Wilie, Holy Lovenia 和 Pascale Fung。Instructtods：用于端到端任务导向对话系统的大型语言模型，2023年。

+   Hu 等人 [2023a] Zhiyuan Hu, Yue Feng, Yang Deng, Zekun Li, See-Kiong Ng, Anh Tuan Luu 和 Bryan Hooi。通过前瞻性动机目标增强大型语言模型驱动的任务导向对话系统，2023a年。

+   Hudeček 和 Dušek [2023] Vojtěch Hudeček 和 Ondřej Dušek。大型语言模型是否是任务导向对话的全部需求？，2023年。

+   Hu 等人 [2023b] Zhiyuan Hu, Yue Feng, Anh Tuan Luu, Bryan Hooi 和 Aldo Lipani。释放用户反馈的潜力：利用大型语言模型作为用户模拟器来增强对话系统。在*第32届ACM国际信息与知识管理会议论文集*，CIKM ’23，第3953–3957页，美国纽约，2023b年。计算机协会。ISBN 9798400701245。doi: 10.1145/3583780.3615220。

+   Brown 等人 [2020] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever 和 Dario Amodei. 语言模型是少样本学习者，2020。

+   微软 [2023d] 微软。Bing 网络搜索 API。 [https://www.microsoft.com/en-us/bing/apis/bing-web-search-api](https://www.microsoft.com/en-us/bing/apis/bing-web-search-api)，2023d。

+   Patil 等人 [2023] Shishir G. Patil, Tianjun Zhang, Xin Wang 和 Joseph E. Gonzalez. Gorilla: 连接大量 API 的大语言模型。*arXiv 预印本 arXiv:2305.15334*，2023。

+   Yang 等人 [2023a] Rui Yang, Lin Song, Yanwei Li, Sijie Zhao, Yixiao Ge, Xiu Li 和 Ying Shan. Gpt4tools：通过自我指令教会大语言模型使用工具，2023a。

+   Qin 等人 [2023a] Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, Dahai Li, Zhiyuan Liu 和 Maosong Sun. Toolllm：帮助大语言模型掌握 16000 多个真实世界的 API，2023a。

+   Chen 和 Li [2024] Wei Chen 和 Zhiyuan Li. Octopus v2：用于超级代理的设备端语言模型。*arXiv 预印本 arXiv:2404.01744*，2024。

+   Wei 等人 [2022a] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed Chi, Quoc V Le 和 Denny Zhou. 思维链提示引发大语言模型的推理。在 *神经信息处理系统进展*，第 35 卷，第 24824–24837 页。Curran Associates, Inc.，2022a。

+   Yao 等人 [2023a] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao 和 Karthik Narasimhan. 思维树：通过大语言模型进行深思熟虑的问题解决。*arXiv 预印本 arXiv:2305.10601*，2023a。

+   Karpas 等人 [2022] Ehud Karpas, Omri Abend, Yonatan Belinkov, Barak Lenz, Opher Lieber, Nir Ratner, Yoav Shoham, Hofit Bata, Yoav Levine, Kevin Leyton-Brown, Dor Muhlgay, Noam Rozen, Erez Schwartz, Gal Shachaf, Shai Shalev-Shwartz, Amnon Shashua 和 Moshe Tenenholtz. Mrkl 系统：一个模块化的神经符号架构，结合了大语言模型、外部知识源和离散推理，2022。

+   Li 等人 [2023b] Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin 和 Bernard Ghanem. Camel：用于“大规模语言模型社会”中“思维”探索的交互式代理，2023b。

+   Kim 等人 [2023a] Geunwoo Kim, Pierre Baldi 和 Stephen Marcus McAleer. 语言模型可以解决计算机任务。在 *第37届神经信息处理系统会议*，2023a。

+   Lu 等人 [2023] Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu, 和 Jianfeng Gao. Chameleon: 插拔式大语言模型的组合推理。发表于 *第37届神经信息处理系统会议（NeurIPS）*，2023。

+   Hao 等人 [2023] Shibo Hao, Tianyang Liu, Zhen Wang, 和 Zhiting Hu. ToolkenGPT: 通过工具嵌入增强冷冻语言模型与海量工具的结合。发表于 *第37届神经信息处理系统会议*，2023。

+   Wang 等人 [2023c] Bryan Wang, Gang Li, 和 Yang Li. 使移动 UI 能与大语言模型进行对话交互。发表于 *2023年人机交互会议（CHI 2023）论文集*，CHI ’23，纽约，NY，USA，2023c。计算机协会出版。ISBN 9781450394215。doi: 10.1145/3544548.3580895。

+   Wen 等人 [2023a] Hao Wen, Hongming Wang, Jiaxuan Liu, 和 Yuanchun Li. Droidbot-gpt: 基于 GPT 的安卓 UI 自动化。*arXiv 预印本 arXiv:2304.07061*，2023a。

+   Deng 等人 [2023] Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang, Huan Sun, 和 Yu Su. Mind2web: 面向网络的通用智能体，2023。

+   Wen 等人 [2023b] Hao Wen, Yuanchun Li, Guohong Liu, Shanhui Zhao, Tao Yu, Toby Jia-Jun Li, Shiqi Jiang, Yunhao Liu, Yaqin Zhang, 和 Yunxin Liu. 赋能 LLM 使用智能手机进行智能任务自动化。*arXiv 预印本 arXiv:2308.15272*，2023b。

+   Taeb 等人 [2023] Maryam Taeb, Amanda Swearngin, Eldon Schoop, Ruijia Cheng, Yue Jiang, 和 Jeffrey Nichols. Axnav: 从自然语言重放可访问性测试，2023。

+   Lee 等人 [2023b] Sunjae Lee, Junyoung Choi, Jungjae Lee, Hojun Choi, Steven Y. Ko, Sangeun Oh, 和 Insik Shin. 探索、选择、推导与回忆：通过类人记忆增强 LLM 用于移动任务自动化。*arXiv 预印本 arXiv:2312.03003*，2023b。

+   Sun 等人 [2022] Liangtai Sun, Xingyu Chen, Lu Chen, Tianle Dai, Zichen Zhu, 和 Kai Yu. Meta-gui: 面向移动 GUI 的多模态对话体智能代理。*arXiv 预印本 arXiv:2205.11029*，2022。

+   He 等人 [2021] Zecheng He, Srinivas Sunkara, Xiaoxue Zang, Ying Xu, Lijuan Liu, Nevan Wichers, Gabriel Schubiner, Ruby Lee, 和 Jindong Chen. Actionbert: 利用用户行为进行用户界面的语义理解。*人工智能学会会议论文集*，35(7):5931–5938，2021年5月。doi: 10.1609/aaai.v35i7.16741。网址 [https://ojs.aaai.org/index.php/AAAI/article/view/16741](https://ojs.aaai.org/index.php/AAAI/article/view/16741)。

+   Zhang 等人 [2023b] Zhizheng Zhang, Xiaoyi Zhang, Wenxuan Xie, 和 Yan Lu. 负责任的任务自动化：赋能大语言模型作为负责任的任务自动化工具，2023b。

+   Zhang 等人 [2023c] Zhizheng Zhang, Wenxuan Xie, Xiaoyi Zhang, 和 Yan Lu. 强化 UI 指令定位：面向通用 UI 任务自动化 API。*ArXiv*，abs/2310.04716，2023c。

+   Zhan and Zhang [2023] Zhuosheng Zhan and Aston Zhang. 你只看屏幕：多模态行动链代理。*arXiv预印本 arXiv:2309.11436*，2023。

+   Shaw et al. [2023] Peter Shaw, Mandar Joshi, James Cohan, Jonathan Berant, Panupong Pasupat, Hexiang Hu, Urvashi Khandelwal, Kenton Lee, and Kristina Toutanova. 从像素到用户界面动作：通过图形用户界面学习跟随指令。在*第37届神经信息处理系统会议*，2023。网址 [https://openreview.net/forum?id=3PjCt4kmRx](https://openreview.net/forum?id=3PjCt4kmRx)。

+   Xie et al. [2024] Tianbao Xie, Danyang Zhang, Jixuan Chen, Xiaochuan Li, Siheng Zhao, Ruisheng Cao, Toh Jing Hua, Zhoujun Cheng, Dongchan Shin, Fangyu Lei, 等人。Osworld: 在真实计算机环境中对开放任务的多模态代理进行基准测试。*arXiv预印本 arXiv:2404.07972*，2024。

+   Yan et al. [2023] An Yan, Zhengyuan Yang, Wanrong Zhu, Kevin Lin, Linjie Li, Jianfeng Wang, Jianwei Yang, Yiwu Zhong, Julian McAuley, Jianfeng Gao, 等人。GPT-4v奇幻之旅：用于零-shot智能手机图形用户界面导航的大型多模态模型。*arXiv预印本 arXiv:2311.07562*，2023。

+   Zhang et al. [2023d] Chi Zhang, Zhao Yang, Jiaxuan Liu, Yucheng Han, Xin Chen, Zebiao Huang, Bin Fu, and Gang Yu. Appagent: 多模态代理作为智能手机用户，2023d。

+   Zheng et al. [2024a] Boyuan Zheng, Boyu Gou, Jihyung Kil, Huan Sun, and Yu Su. GPT-4v（视觉）是一个通用的网络代理，如果是基于实际环境的。*arXiv预印本 arXiv:2401.01614*，2024a。

+   Gao et al. [2023a] Difei Gao, Lei Ji, Zechen Bai, Mingyu Ouyang, Peiran Li, Dongxing Mao, Qinchen Wu, Weichen Zhang, Peiyi Wang, Xiangwu Guo, Hengxu Wang, Luowei Zhou, and Mike Zheng Shou. Assistgui: 面向任务的桌面图形用户界面自动化，2023a。

+   Hong et al. [2023a] Wenyi Hong, Weihan Wang, Qingsong Lv, Jiazheng Xu, Wenmeng Yu, Junhui Ji, Yan Wang, Zihan Wang, Yuxuan Zhang, Juanzi Li, Bin Xu, Yuxiao Dong, Ming Ding, and Jie Tang. Cogagent: 一种视觉语言模型，用于图形用户界面代理，2023a。

+   Cheng et al. [2024] Kanzhi Cheng, Qiushi Sun, Yougang Chu, Fangzhi Xu, Yantao Li, Jianbing Zhang, and Zhiyong Wu. Seeclick: 利用图形用户界面基础进行高级视觉图形用户界面代理。*arXiv预印本 arXiv:2401.10935*，2024。

+   You et al. [2024] Keen You, Haotian Zhang, Eldon Schoop, Floris Weers, Amanda Swearngin, Jeffrey Nichols, Yinfei Yang, and Zhe Gan. Ferret-ui: 基于多模态大语言模型的移动用户界面理解。*arXiv预印本 arXiv:2404.05719*，2024。

+   Cheng et al. [2023] Sijie Cheng, Zhicheng Guo, Jingwen Wu, Kechen Fang, Peng Li, Huaping Liu, and Yang Liu. 视觉-语言模型能否从第一人称视角进行思考？2023。

+   Weng [2023] Lilian Weng. 由大语言模型驱动的自主代理。 [https://lilianweng.github.io/posts/2023-06-23-agent/](https://lilianweng.github.io/posts/2023-06-23-agent/)，2023。

+   aut [2023] Autogpt. [https://github.com/Significant-Gravitas/AutoGPT](https://github.com/Significant-Gravitas/AutoGPT)，2023。

+   lan [2023] Langchain. [https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain)，2023年。

+   bab [2023] Babyagi. [https://github.com/yoheinakajima/babyagi](https://github.com/yoheinakajima/babyagi)，2023年。

+   Osika [2023] Anton Osika. Gpt-engineer. [https://github.com/AntonOsika/gpt-engineer](https://github.com/AntonOsika/gpt-engineer)，2023年。

+   Chen et al. [2023a] Guangyao Chen, Siwei Dong, Yu Shu, Ge Zhang, Sesay Jaward, Karlsson Börje, Jie Fu, and Yemin Shi. Autoagents: 自动生成代理框架。*arXiv预印本*，2023a。

+   Xie et al. [2023] Tianbao Xie, Fan Zhou, Zhoujun Cheng, Peng Shi, Luoxuan Weng, Yitao Liu, Toh Jing Hua, Junning Zhao, Qian Liu, Che Liu, Leo Z. Liu, Yiheng Xu, Hongjin Su, Dongchan Shin, Caiming Xiong, and Tao Yu. Openagents: 一个面向实际应用中语言代理的开放平台，2023年。

+   KillianLucas [2023] KillianLucas. Open interpreter. [https://github.com/KillianLucas/open-interpreter](https://github.com/KillianLucas/open-interpreter)，2023年。

+   Liu [2022] Jerry Liu. LlamaIndex, 2022年11月。网址 [https://github.com/jerryjliu/llama_index](https://github.com/jerryjliu/llama_index)。

+   Taranjeet Singh [2023] Deshraj Yadav Taranjeet Singh. Embedchain：为大型语言模型（LLMs）提供的数据平台——加载、索引、检索和同步任何非结构化数据。 [https://github.com/embedchain/embedchain](https://github.com/embedchain/embedchain)，2023年。

+   Zhou et al. [2023b] Wangchunshu Zhou, Yuchen Eleanor Jiang, Long Li, Jialong Wu, Tiannan Wang, Shi Qiu, Jintian Zhang, Jing Chen, Ruipu Wu, Shuai Wang, Shiding Zhu, Jiyu Chen, Wentao Zhang, Ningyu Zhang, Huajun Chen, Peng Cui, and Mrinmaya Sachan. Agents: 一种开源的自主语言代理框架，2023b。

+   Hong et al. [2023b] Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Ceyao Zhang, Jinlin Wang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu, and Jürgen Schmidhuber. Metagpt: 用于多代理协作框架的元编程，2023b。

+   Wu et al. [2023a] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. Autogen: 通过多代理对话框架实现下一代大型语言模型应用。*arXiv预印本 arXiv:2308.08155*，2023a。

+   Huang et al. [2023] Forrest Huang, Gang Li, Tao Li, and Yang Li. 从交互跟踪中自动挖掘宏，2023年。

+   Toyama et al. [2021] Daniel Toyama, Philippe Hamel, Anita Gergely, Gheorghe Comanici, Amelia Glaese, Zafarali Ahmed, Tyler Jackson, Shibl Mourad, and Doina Precup. Androidenv：用于Android的强化学习平台。*arXiv预印本 arXiv:2105.13231*，2021年。

+   Zhang et al. [2023e] Danyang Zhang, Lu Chen, Zihan Zhao, Ruisheng Cao, and Kai Yu. Mobile-Env: 面向大型语言模型时代交互式代理的评估平台与基准。*CoRR*，abs/2305.08144，2023e。

+   Pasupat 等人 [2018] Panupong Pasupat, Tian-Shun Jiang, Evan Liu, Kelvin Guu, 和 Percy Liang. 将自然语言命令映射到网页元素。在 *2018年自然语言处理经验方法会议论文集*，第4970–4976页，比利时布鲁塞尔，2018年10月-11月。计算语言学协会。doi: 10.18653/v1/D18-1540.

+   Burns 等人 [2022] Andrea Burns, Deniz Arsan, Sanjna Agrawal, Ranjitha Kumar, Kate Saenko, 和 Bryan A. Plummer. 一个用于未知命令可行性的交互式视觉语言导航数据集。在 *欧洲计算机视觉大会 (ECCV)*，2022年.

+   Venkatesh 等人 [2023] Sagar Gubbi Venkatesh, Partha Talukdar, 和 Srini Narayanan. Ugif：基于 UI 的指令跟随，2023.

+   Rawles 等人 [2023] Christopher Rawles, Alice Li, Daniel Rodriguez, Oriana Riva, 和 Timothy Lillicrap. 野外中的 Android：一个用于 Android 设备控制的大规模数据集，2023.

+   Kapoor 等人 [2024] Raghav Kapoor, Yash Parag Butala, Melisa Russak, Jing Yu Koh, Kiran Kamble, Waseem Alshikh, 和 Ruslan Salakhutdinov. Omniact：一个数据集和基准，用于支持桌面和网页上的多模态通用自主代理。*arXiv 预印本 arXiv:2402.17553*, 2024.

+   Lai 等人 [2024] Hanyu Lai, Xiao Liu, Iat Long Iong, Shuntian Yao, Yuxuan Chen, Pengbo Shen, Hao Yu, Hanchen Zhang, Xiaohan Zhang, Yuxiao Dong 等人. Autowebglm：启动并增强基于大语言模型的网页导航代理。*arXiv 预印本 arXiv:2404.03648*, 2024.

+   Liu 等人 [2024a] Junpeng Liu, Yifan Song, Bill Yuchen Lin, Wai Lam, Graham Neubig, Yuanzhi Li, 和 Xiang Yue. Visualwebbench：多模态大语言模型在网页理解和定位方面已经发展到什么程度？*arXiv 预印本 arXiv:2404.05955*, 2024a.

+   Niu 等人 [2024] Runliang Niu, Jindong Li, Shiqi Wang, Yali Fu, Xiyu Hu, Xueyuan Leng, He Kong, Yi Chang, 和 Qi Wang. Screenagent：一个由视觉语言模型驱动的计算机控制代理。*arXiv 预印本 arXiv:2402.07945*, 2024.

+   Yao 等人 [2022a] Shunyu Yao, Howard Chen, John Yang, 和 Karthik Narasimhan. Webshop：迈向可扩展的现实世界网页交互与基于语言的代理系统。 在 *神经信息处理系统进展*，第35卷，第20744–20757页，Curran Associates, Inc., 2022a.

+   Zhou 等人 [2023c] Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon 等人. Webarena：一个用于构建自主代理的真实网页环境。*arXiv 预印本 arXiv:2307.13854*, 2023c.

+   Zheng 等人 [2024b] Longtao Zheng, Zhiyuan Huang, Zhenghai Xue, Xinrun Wang, Bo An, 和 Shuicheng Yan. Agentstudio：构建通用虚拟代理的工具包。*arXiv 预印本 arXiv:2403.17918*, 2024b.

+   Breda et al. [2023] Joseph Breda, Mastafa Springston, Alex Mariakakis, 和 Shwetak Patel. Feverphone: 使用普通智能手机进行发热监测的可访问核心体温传感。*ACM交互式、移动、可穿戴和普适计算技术会议录*, 7(1):1–23, 2023。

+   Chhaglani et al. [2022] Bhawana Chhaglani, Camellia Zakaria, Adam Lechowicz, Jeremy Gummeson, 和 Prashant Shenoy. Flowsense: 使用音频传感监测建筑通风系统的气流。*ACM交互式、移动、可穿戴和普适计算技术会议录*, 6(1):1–26, 2022。

+   Hu et al. [2023c] Yongquan Hu, Hui-Shyong Yeo, Mingyue Yuan, Haoran Fan, Don Samitha Elvitigala, Wen Hu, 和 Aaron Quigley. Microcam: 利用智能手机显微镜相机进行上下文感知的接触表面传感。*ACM交互式、移动、可穿戴和普适计算技术会议录*, 7(3):1–28, 2023c。

+   Hu et al. [2023d] Jingzhi Hu, Tianyue Zheng, Zhe Chen, Hongbo Wang, 和 Jun Luo. Muse-fi: 利用近场Wi-Fi信道变化进行无接触多人物理感知。发表于*第29届年度国际移动计算与网络会议论文集*，页码1–15, 2023d。

+   Gong et al. [2021] Jian Gong, Xinyu Zhang, Yuanjun Huang, Ju Ren, 和 Yaoxue Zhang. 通过深度传感器融合实现稳健的惯性运动跟踪，适用于智能耳机和智能手机。*ACM交互式、移动、可穿戴和普适计算技术会议录*, 5(2):1–26, 2021。

+   Arrotta et al. [2022] Luca Arrotta, Gabriele Civitarese, 和 Claudio Bettini. Dexar: 在智能家居环境中基于深度可解释传感器的活动识别。*ACM交互式、移动、可穿戴和普适计算技术会议录*, 6(1):1–30, 2022。

+   Ji et al. [2024] Sijie Ji, Xinzhe Zheng, 和 Chenshu Wu. Hargpt: 大型语言模型是否可以进行零-shot人类活动识别？*arXiv 预印本 arXiv:2403.02727*, 2024。

+   Yang et al. [2024] Huanqi Yang, Sijie Ji, Rucheng Wu, 和 Weitao Xu. 你被追踪了吗？发现大型语言模型在零-shot轨迹追踪中的强大能力！*arXiv 预印本 arXiv:2403.06201*, 2024。

+   Zhang et al. [2024a] Sha Zhang, Di Huang, Jiajun Deng, Shixiang Tang, Wanli Ouyang, Tong He, 和 Yanyong Zhang. Agent3d-zero: 一种用于零-shot 3D 理解的智能体。*arXiv 预印本 arXiv:2403.11835*, 2024a。

+   Zheng et al. [2024c] Zhisheng Zheng, Puyuan Peng, Ziyang Ma, Xie Chen, Eunsol Choi, 和 David Harwath. Bat: 使用大型语言模型学习推理空间声音。*arXiv 预印本 arXiv:2402.01591*, 2024c。

+   Yang et al. [2023b] Senqiao Yang, Jiaming Liu, Ray Zhang, Mingjie Pan, Zoey Guo, Xiaoqi Li, Zehui Chen, Peng Gao, Yandong Guo, 和 Shanghang Zhang. Lidar-llm: 探索大型语言模型在3D激光雷达理解中的潜力。*arXiv 预印本 arXiv:2312.14074*, 2023b。

+   Shao 等人 [2023] Hao Shao, Yuxuan Hu, Letian Wang, Steven L Waslander, Yu Liu 和 Hongsheng Li. Lmdrive：基于大语言模型的闭环端到端驾驶. *arXiv 预印本 arXiv:2312.07488*, 2023。

+   Duan 等人 [2024] Yiqun Duan, Qiang Zhang 和 Renjing Xu. 通过提示多模态标记增强端到端自主驾驶模仿学习与大语言模型的结合. *arXiv 预印本 arXiv:2404.04869*, 2024。

+   Wen 等人 [2023c] Haoyang Wen, Zhenxin Xiao, Eduard Hovy 和 Alexander G Hauptmann. 面向开放域推特用户画像推断. 收录于 *2023年计算语言学协会会议成果：ACL 2023*, 页码 3172–3188, 2023c。

+   Bianchi 等人 [2016] Filippo Maria Bianchi, Antonello Rizzi, Alireza Sadeghian 和 Corrado Moiso. 通过通话数据记录的数据挖掘识别用户习惯. *工程应用人工智能*, 54:49–61, 2016。

+   Shin 等人 [2023] Jaemin Shin, Hyungjun Yoon, Seungjoo Lee, Sungjoon Park, Yunxin Liu, Jinho D Choi 和 Sung-Ju Lee. Fedtherapist：通过联邦学习使用用户生成的语言表达进行智能手机上的心理健康监测. *arXiv 预印本 arXiv:2310.16538*, 2023。

+   Hu 等人 [2024] Sihao Hu, Tiansheng Huang, Fatih Ilhan, Selim Tekin, Gaowen Liu, Ramana Kompella 和 Ling Liu. 基于大语言模型的游戏代理调查. *arXiv 预印本 arXiv:2404.02039*, 2024。

+   Wampfler 等人 [2022] Rafael Wampfler, Severin Klingler, Barbara Solenthaler, Victor R Schinazi, Markus Gross 和 Christian Holz. 基于智能手机触摸与传感器数据预测情感状态. 收录于 *2022年CHI人机交互会议论文集*, 页码 1–14, 2022。

+   Chen 等人 [2023b] Yu-Chun Chen, Yu-Jen Lee, Kuei-Chun Kao, Jie Tsai, En-Chi Liang, Wei-Chen Chiu, Faye Shih 和 Yung-Ju Chang. 你在浪费时间吗？通过融合智能手机传感器数据与截图预测智能手机用户的消磨时间时刻. 收录于 *2023年CHI人机交互会议论文集*, 页码 1–19, 2023b。

+   Ahmed 等人 [2023] Tousif Ahmed, Md Mahbubur Rahman, Ebrahim Nemati, Mohsin Yusuf Ahmed, Jilong Kuang 和 Alex Jun Gao. 使用耳戴设备的运动与声学传感器在静止状态下远程跟踪呼吸频率. 收录于 *2023年CHI人机交互会议论文集*, 页码 1–22, 2023。

+   Mollyn 等人 [2022] Vimal Mollyn, Karan Ahuja, Dhruv Verma, Chris Harrison 和 Mayank Goel. Samosa：通过运动和下采样音频感知活动. *ACM互动、移动、可穿戴与普适技术会议论文集*, 6(3):1–19, 2022。

+   Di Lascio 等人 [2020] Elena Di Lascio, Shkurta Gashi, Juan Sebastian Hidalgo, Beatrice Nale, Maike E Debus 和 Silvia Santini. 一种多传感器方法，自动识别学术界知识工作者的休息与工作活动. *ACM互动、移动、可穿戴与普适技术会议论文集*, 4(3):1–20, 2020。

+   Cui 等人 [2023] Minhao Cui, Binbin Xie, Qing Wang 和 Jie Xiong. Dancingant：利用电力线辐射进行身体驱动的无线感知。发表于 *第29届国际移动计算与网络会议论文集*，第1–15页，2023。

+   He 等人 [2023] Yinghui He, Jianwei Liu, Mo Li, Guanding Yu, Jinsong Han 和 Kui Ren. Sencom：结合实际 WiFi 的集成感知与通信。发表于 *第29届国际移动计算与网络会议论文集*，第1–16页，2023。

+   Zakaria 等人 [2023] Camellia Zakaria, Gizem Yilmaz, Priyanka Mary Mammen, Michael Chee, Prashant Shenoy 和 Rajesh Balan. Sleepmore：通过多设备 WiFi 感知推断大规模睡眠时长。*ACM 互动、移动、可穿戴与普适技术会议论文集*，6(4):1–32，2023。

+   Wang 等人 [2024] Qijun Wang, Shichen Zhang, Kunzhe Song 和 Huacheng Zeng. Chattracer：基于大语言模型的实时蓝牙设备跟踪系统。*arXiv 预印本 arXiv:2403.19833*，2024。

+   Zhao 等人 [2023b] Xufeng Zhao, Mengdi Li, Cornelius Weber, Muhammad Burhan Hafez 和 Stefan Wermter. 与环境对话：使用大语言模型进行互动的多模态感知。发表于 *2023 IEEE/RSJ 国际智能机器人与系统大会 (IROS)*，第3590–3596页。IEEE，2023b。

+   Darvish 等人 [2024] Kourosh Darvish, Marta Skreta, Yuchi Zhao, Naruki Yoshikawa, Sagnik Som, Miroslav Bogdanovic, Yang Cao, Han Hao, Haoping Xu, Alán Aspuru-Guzik 等人. Organa：用于自动化化学实验和表征的机器人助手。*arXiv 预印本 arXiv:2401.06949*，2024。

+   Gao 等人 [2023b] Nan Gao, Zhuolei Yu, Chun Yu, Yuntao Wang, Flora D Salim 和 Yuanchun Shi. 用于人类行为理解的自动化移动感知策略生成。*arXiv 预印本 arXiv:2311.05457*，2023b。

+   Samyoun 等人 [2022] Sirat Samyoun, Md Mofijul Islam, Tariq Iqbal 和 John Stankovic. M3sense：使用多模态可穿戴传感器进行无关情感的多任务表示学习。*ACM 互动、移动、可穿戴与普适技术会议论文集*，6(2):1–32，2022。

+   Deldari 等人 [2022] Shohreh Deldari, Hao Xue, Aaqib Saeed, Daniel V Smith 和 Flora D Salim. Cocoa：传感器数据的跨模态对比学习。*ACM 互动、移动、可穿戴与普适技术会议论文集*，6(3):1–28，2022。

+   Abedin 等人 [2021] Alireza Abedin, Mahsa Ehsanpour, Qinfeng Shi, Hamid Rezatofighi 和 Damith C Ranasinghe. 注意并区分：超越最先进的可穿戴传感器用于人类活动识别的研究。*ACM 互动、移动、可穿戴与普适技术会议论文集*，5(1):1–22，2021。

+   Rashid 等人 [2020] Haroon Rashid, Sanjana Mendu, Katharine E Daniel, Miranda L Beltzer, Bethany A Teachman, Mehdi Boukhechba 和 Laura E Barnes。基于稀疏采集的移动传感器数据预测社交焦虑的主观测量。*ACM交互式、移动、可穿戴与普及技术会议录*，4(3):1–24，2020。

+   Kim 等人 [2022] Jeong-Kyun Kim, Da-Som Oh, Kangbok Lee 和 Sang Gi Hong。基于手腕佩戴传感器的重要特征解读的跌倒检测。在*第28届国际移动计算与网络会议论文集*，第823–825页，2022年。

+   Xu 等人 [2023] Huatao Xu, Liying Han, Mo Li 和 Mani Srivastava。穿透性人工智能：使大型语言模型理解物理世界。*arXiv预印本 arXiv:2310.09605*，2023。

+   Liu 等人 [2013] Kaikai Liu, Xinxin Liu 和 Xiaolin Li。Guoguo：通过智能手机实现精细化室内定位。在*第11届国际移动系统、应用与服务会议论文集*，第235–248页，2013年。

+   Chu 等人 [2009] Selina Chu, Shrikanth Narayanan 和 C-C Jay Kuo。基于时频音频特征的环境声音识别。*IEEE音频、语音与语言处理汇刊*，17(6):1142–1158，2009。

+   Chandrakala 和 Jayalakshmi [2019] S Chandrakala 和 SL Jayalakshmi。自主监控的环境音频场景与声音事件识别：一项调查与比较研究。*ACM计算调查 (CSUR)*，52(3):1–34，2019。

+   Assi 等人 [2023] Karim Assi, Lakmal Meegahapola, William Droz, Peter Kun, Amalia De Götzen, Miriam Bidoglia, Sally Stares, George Gaskell, Altangerel Chagnaa, Amarsanaa Ganbold 等人。复杂日常活动、国家级多样性与智能手机传感：在丹麦、意大利、蒙古、巴拉圭和英国的研究。在*2023年CHI人机交互会议论文集*，第1–23页，2023年。

+   Meegahapola 等人 [2023] Lakmal Meegahapola, William Droz, Peter Kun, Amalia De Götzen, Chaitanya Nutakki, Shyam Diwakar, Salvador Ruiz Correa, Donglei Song, Hao Xu, Miriam Bidoglia 等人。基于移动传感的情绪推断模型的泛化与个性化：对八个国家大学生的分析。*ACM交互式、移动、可穿戴与普及技术会议录*，6(4):1–32，2023。

+   Wang 等人 [2023d] Zhiyuan Wang, Maria A Larrazabal, Mark Rucker, Emma R Toner, Katharine E Daniel, Shashwat Kumar, Mehdi Boukhechba, Bethany A Teachman 和 Laura E Barnes。在与社交焦虑个体的虚拟互动中，从移动传感指示器检测社交情境。*ACM交互式、移动、可穿戴与普及技术会议录*，7(3):1–26，2023d。

+   Meegahapola 等人 [2021a] Lakmal Meegahapola, Florian Labhart, Thanh-Trung Phan 和 Daniel Gatica-Perez。通过智能手机传感器研究年轻人饮酒的社会情境。*ACM互动、移动、可穿戴与无处不在技术会议录*, 5(3):1–26, 2021a。

+   Meegahapola 等人 [2021b] Lakmal Meegahapola, Salvador Ruiz-Correa, Viridiana del Carmen Robledo-Valero, Emilio Ernesto Hernandez-Huerfano, Leonardo Alvarez-Rivera, Ronald Chenu-Abente 和 Daniel Gatica-Perez。再多吃一口？通过智能手机传感器和自我报告推断大学生的食物消费水平。*ACM互动、移动、可穿戴与无处不在技术会议录*, 5(1):1–28, 2021b。

+   Liang 等人 [2023] Yuebing Liang, Yichao Liu, Xiaohan Wang 和 Zhan Zhao。探索大型语言模型在公共事件下的人类流动预测中的应用。*arXiv 预印本 arXiv:2311.17351*, 2023。

+   Su 等人 [2014] Xing Su, Hanghang Tong 和 Ping Ji。使用智能手机传感器进行活动识别。*清华科技*, 19(3):235–249, 2014。

+   Akther 等人 [2021] Sayma Akther, Nazir Saleheen, Mithun Saha, Vivek Shetty 和 Santosh Kumar。mteeth: 使用腕戴惯性传感器识别刷牙表面。*ACM互动、移动、可穿戴与无处不在技术会议录*, 5(2):1–25, 2021。

+   Cao 等人 [2022] Yetong Cao, Fan Li, Huijie Chen, Xiaochen Liu, Li Zhang 和 Yu Wang。静默守护你的心脏: 使用腕戴运动传感器进行连续心电图波形监测。*ACM互动、移动、可穿戴与无处不在技术会议录*, 6(3):1–29, 2022。

+   Lin 等人 [2020] Zongyu Lin, Shiqing Lyu, Hancheng Cao, Fengli Xu, Yuqiong Wei, Hanan Samet 和 Yong Li。Healthwalks: 通过移动数据感知个体健康状况的细粒度方法。*ACM互动、移动、可穿戴与无处不在技术会议录*, 4(4):1–26, 2020。

+   Zhang 等人 [2018] Xiao Zhang, Wenzhong Li, Xu Chen 和 Sanglu Lu。Moodexplorer: 通过智能手机传感器实现复合情感检测。*ACM互动、移动、可穿戴与无处不在技术会议录*, 1(4):1–30, 2018。

+   Adler 等人 [2021] Daniel A Adler, Vincent W-S Tseng, Gengmo Qi, Joseph Scarpa, Srijan Sen 和 Tanzeem Choudhury。识别压力抗压能力的移动传感器指标。*ACM互动、移动、可穿戴与无处不在技术会议录*, 5(2):1–32, 2021。

+   Kim 等人 [2024] Yubin Kim, Xuhai Xu, Daniel McDuff, Cynthia Breazeal 和 Hae Won Park。Health-llm: 通过可穿戴传感器数据预测健康的语言模型。*arXiv 预印本 arXiv:2401.06866*, 2024。

+   Lan 等人 [2024] Xiaochong Lan, Yiming Cheng, Li Sheng, Chen Gao 和 Yong Li。利用大型语言模型在社交媒体上检测抑郁症。*arXiv 预印本 arXiv:2403.10750*, 2024。

+   Lifelo等人 [2024] Zita Lifelo, Huansheng Ning, 和 Sahraoui Dhelim. 通过元训练和基于大语言模型的情境学习，为跨语言学习调整心理健康预测任务. *arXiv预印本arXiv:2404.09045*，2024年。

+   王等人 [2022a] Weichen Wang, Subigya Nepal, Jeremy F Huckins, Lessley Hernandez, Vlado Vojdanovski, Dante Mack, Jane Plomp, Arvind Pillai, Mikio Obuchi, Alex Dasilva, 等人. First-gen lens: 通过移动传感器评估第一代大学生在大学第一年的心理健康. *ACM互动移动可穿戴和普适技术会议录*，6(2):1–32，2022a。

+   王等人 [2015] Rui Wang, Gabriella Harari, Peilin Hao, Xia Zhou, 和 Andrew T Campbell. Smartgpa: 智能手机如何评估和预测大学生的学术表现. 载于 *2015年ACM国际联合大会：普适计算与无处不在计算的会议录*，第295–306页，2015年。

+   高等人 [2019] Nan Gao, Wei Shao, 和 Flora D Salim. 从身体活动强度预测人格特征. *计算机*，52(7):47–56，2019年。

+   尼泊尔等人 [2020] Subigya Nepal, Shayan Mirjafari, Gonzalo J Martinez, Pino Audia, Aaron Striegel, 和 Andrew T Campbell. 使用移动感知检测信息工人的职位晋升. *ACM互动移动可穿戴和普适技术会议录*，4(3):1–28，2020年。

+   Yürüten等人 [2014] Onur Yürüten, Jiyong Zhang, 和 Pearl HZ Pu. 基于移动传感器数据的日常活动的生活满意度预测因素. 载于 *SIGCHI人机交互大会会议录*，第497–500页，2014年。

+   王等人 [2020a] Weichen Wang, Shayan Mirjafari, Gabriella Harari, Dror Ben-Zeev, Rachel Brian, Tanzeem Choudhury, Marta Hauser, John Kane, Kizito Masaba, Subigya Nepal, 等人. 社交感知：通过手机传感器评估精神分裂症患者的社交功能. 载于 *2020年CHI人机交互大会会议录*，第1–15页，2020a。

+   郭等人 [2024] Zhijun Guo, Alvina Lai, Johan Hilge Thygesen, Joseph Farrington, Thomas Keen, 和 Kezhi Li. 大语言模型在心理健康中的应用：一项系统评审. *arXiv预印本arXiv:2403.15401*，2024年。

+   王等人 [2017a] Rui Wang, Weichen Wang, Min SH Aung, Dror Ben-Zeev, Rachel Brian, Andrew T Campbell, Tanzeem Choudhury, Marta Hauser, John Kane, Emily A Scherer, 等人. 使用移动传感器预测精神分裂症的症状轨迹. *ACM互动移动可穿戴和普适技术会议录*，1(3):1–24，2017a。

+   Chatterjee等人 [2020] Soujanya Chatterjee, Alexander Moreno, Steven Lloyd Lizotte, Sayma Akther, Emre Ertin, Christopher P Fagundes, Cho Lam, James M Rehg, Neng Wan, David W Wetter, 等人. Smokingopp: 使用移动传感器检测吸烟‘机会’上下文. *ACM互动移动可穿戴和普适技术会议录*，4(1):1–26，2020年。

+   欧阳和斯里瓦斯塔瓦 [2024] 欧阳晓敏 和 马尼·斯里瓦斯塔瓦。Llmsense：利用大语言模型进行高层次时空传感器轨迹推理。*arXiv预印本 arXiv:2403.19857*，2024。

+   陈 [2023] 郑晨。Palr：关注个性化的大语言模型推荐系统。*arXiv预印本 arXiv:2305.07622*，2023。

+   张等人 [2023f] 张文轩, 刘洪志, 杜英鹏, 朱晨, 宋阳, 朱恒书, 吴仲海。弥合领域特定模型与通用大语言模型之间的信息鸿沟，以实现个性化推荐。*arXiv预印本 arXiv:2311.03778*，2023f。

+   孙等人 [2023a] 孙晓飞, 李小雅, 张盛宇, 王书赫, 吴飞, 李吉伟, 张天威, 和 王国银。通过大语言模型谈判进行情感分析。*arXiv预印本 arXiv:2311.01876*，2023a。

+   阿巴西安等人 [2023] 马赫亚尔·阿巴西安, 伊曼·阿齐米, 阿米尔·M·拉赫马尼, 和 拉梅什·贾因。对话式健康代理：一个个性化的大语言模型驱动的代理框架。*arXiv预印本 arXiv:2310.02374*，2023。

+   古林等人 [2014] 卡萨尔·古林, 艾伦·F·斯密顿, 艾登·R·多赫提 等人。生活日志记录：个人大数据。*信息检索的基础与趋势®*，8(1)：1–125，2014。

+   道奇和基钦 [2007] 马丁·道奇 和 罗布·基钦。‘即将到来的世界轮廓’：普适计算与遗忘伦理。*环境与规划B：规划与设计*，34(3)：431–445，2007。

+   贝迪亚尔等人 [2020] 贾米拉·罗迈萨·贝迪亚尔, 布拉欣·尼尼, 穆罕默德·萨博库鲁, 和 阿卜杜努尔·哈迪德。基于视觉的人体活动识别：一项调查。*多媒体工具与应用*，79(41-42)：30509–30555，2020。

+   斯塔赫尔等人 [2020] 克莱门斯·斯塔赫尔, 奎·奥, 拉莫娜·舍德尔, 塞缪尔·D·戈斯林, 加布里埃拉·M·哈拉里, 丹尼尔·布斯赫克, 莎拉·特雷斯·沃尔凯尔, 托比亚斯·舒韦尔克, 米歇尔·奥尔德梅尔, 特雷莎·乌尔曼 等人。从行为模式预测个性：基于智能手机收集的数据。*美国国家科学院学报*，117(30)：17680–17687，2020。

+   马朱姆德等人 [2017] 纳沃尼尔·马朱姆德, 苏贾尼亚·波里亚, 亚历山大·吉尔布赫, 和 埃里克·坎布里亚。基于深度学习的文档建模用于从文本中检测个性。*IEEE智能系统*，32(2)：74–79，2017。

+   Štajner 和 Yenikent [2020] 桑娅·Štajner 和 塞伦·耶尼肯特。自动个性检测的调查。发表于 *第28届国际计算语言学大会论文集*，第6284–6295页，2020。

+   贾斯瓦尔等人 [2020] 阿克里提·贾斯瓦尔, A·克里什纳马·拉朱, 和 苏曼·德布。基于深度学习的面部情感检测。发表于 *2020年新兴技术国际会议（INCET）*，第1–5页，IEEE，2020。

+   扎德等人 [2021] 萨米拉·扎德, 玛丽亚姆·海达里, H·詹姆斯·Jr, 和 奥兹莱姆·乌祖内尔。文本数据的情感检测：一项跨学科调查。发表于 *2021年IEEE世界人工智能物联网大会（AIIoT）*，第0255–0261页，IEEE，2021。

+   Tang 等人 [2019] Xiaoli Tang、Tengyun Wang、Haizhi Yang 和 Hengjie Song. Akupm：一种用于推荐的注意力增强知识感知用户偏好模型。载于 *第25届ACM SIGKDD国际知识发现与数据挖掘大会论文集*，第1891–1899页，2019年。

+   Li 等人 [2018] Yuanchun Li、Ziyue Yang、Yao Guo、Xiangqun Chen、Yuvraj Agarwal 和 Jason I Hong. 从智能手机推送通知中自动提取个人知识。载于 *2018 IEEE国际大数据会议*，第733–742页，IEEE，2018年。

+   Singh 和 Solanki [2016] Garima Singh 和 Arun Solanki. 一种将自然语言转换为关系数据库SQL查询的算法。*Selforganizology*，3(3):100–116，2016年。

+   Lin 等人 [2019] Kevin Lin、Ben Bogin、Mark Neumann、Jonathan Berant 和 Matt Gardner. 基于语法的神经文本到SQL生成。*arXiv 预印本 arXiv:1905.13326*，2019年。

+   Li 等人 [2017c] Yuanchun Li、Fanglin Chen、Toby Jia-Jun Li、Yao Guo、Gang Huang、Matthew Fredrikson、Yuvraj Agarwal 和 Jason I Hong. Privacystreams：为移动应用启用个人数据处理透明度。*ACM互动、移动、可穿戴和普适技术会议录*，1(3):76，2017c年。

+   Park 等人 [2023] Joon Sung Park、Joseph O’Brien、Carrie Jun Cai、Meredith Ringel Morris、Percy Liang 和 Michael S Bernstein. 生成代理：人类行为的互动模拟体。载于 *第36届年度 ACM 用户界面软件与技术研讨会论文集*，第1–22页，2023年。

+   Li 和 Qiu [2023] Xiaonan Li 和 Xipeng Qiu. Mot：Memory-of-thought使ChatGPT能够自我提升。载于 *2023年自然语言处理经验方法会议论文集*，第6354–6374页，2023年。

+   Wang 等人 [2023e] Weizhi Wang、Li Dong、Hao Cheng、Xiaodong Liu、Xifeng Yan、Jianfeng Gao 和 Furu Wei. 用长期记忆增强语言模型。*arXiv 预印本 arXiv:2306.07174*，2023e年。

+   Guo 等人 [2023] Zhicheng Guo、Sijie Cheng、Yile Wang、Peng Li 和 Yang Liu. 面向非知识密集型任务的提示引导检索增强。*arXiv 预印本 arXiv:2305.17653*，2023年。

+   Nye 等人 [2021] Maxwell Nye、Anders Johan Andreassen、Guy Gur-Ari、Henryk Michalewski、Jacob Austin、David Bieber、David Dohan、Aitor Lewkowycz、Maarten Bosma、David Luan 等人. 展示你的工作：使用语言模型进行中间计算的草稿本。*arXiv 预印本 arXiv:2112.00114*，2021年。

+   Sumers 等人 [2023] Theodore Sumers、Shunyu Yao、Karthik Narasimhan 和 Thomas L Griffiths. 语言代理的认知架构。*arXiv 预印本 arXiv:2309.02427*，2023年。

+   Yao 等人 [2022b] Shunyu Yao、Jeffrey Zhao、Dian Yu、Nan Du、Izhak Shafran、Karthik Narasimhan 和 Yuan Cao. React：在语言模型中协同推理与行动。*arXiv 预印本 arXiv:2210.03629*，2022b年。

+   Peng 等人 [2023] Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng, Yujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou Yu, Weizhu Chen 等人. 检查你的事实并重试：通过外部知识和自动反馈改进大型语言模型。*arXiv 预印本 arXiv:2302.12813*，2023年。

+   Tuyls 等人 [2022] Jens Tuyls, Shunyu Yao, Sham Kakade, 和 Karthik Narasimhan. 在文本游戏中进行战略探索的多阶段情景控制。*arXiv 预印本 arXiv:2201.01251*，2022年。

+   Yao 等人 [2020] Shunyu Yao, Rohan Rao, Matthew Hausknecht, 和 Karthik Narasimhan. 保持冷静，继续探索：用于文本游戏中的行动生成的语言模型。*arXiv 预印本 arXiv:2010.02903*，2020年。

+   Borgeaud 等人 [2022] Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark 等人. 通过从万亿令牌中检索来改进语言模型。在*国际机器学习大会*，页面2206–2240。PMLR, 2022年。

+   Lewis 等人 [2020] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel 等人. 检索增强生成用于知识密集型自然语言处理任务。*神经信息处理系统进展*，33:9459–9474, 2020年。

+   Zhao 等人 [2022] Wenjia Joyce Zhao, Russell Richie, 和 Sudeep Bhatia. 基于记忆的决策中的过程与内容。*心理学评论*，129(1):73, 2022年。

+   Hanjie 等人 [2021] Austin W Hanjie, Victor Y Zhong, 和 Karthik Narasimhan. 将语言与实体和动态进行结合，以实现强化学习中的泛化。在*国际机器学习大会*，页面4051–4062。PMLR, 2021年。

+   Parakh 等人 [2023] Meenal Parakh, Alisha Fong, Anthony Simeonov, Abhishek Gupta, Tao Chen, 和 Pulkit Agrawal. 基于基础模型的人类辅助连续机器人学习。*arXiv 预印本 arXiv:2309.14321*，2023年。

+   Wang 等人 [2023f] Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, 和 Anima Anandkumar. Voyager：一种开放式的具身智能体，结合了大型语言模型。*arXiv 预印本 arXiv:2305.16291*，2023f年。

+   Ellis 等人 [2023] Kevin Ellis, Lionel Wong, Maxwell Nye, Mathias Sable-Meyer, Luc Cary, Lore Anaya Pozo, Luke Hewitt, Armando Solar-Lezama, 和 Joshua B Tenenbaum. Dreamcoder：通过觉醒–睡眠贝叶斯程序学习，发展具有可解释性和可泛化性的知识。*皇家学会A辑哲学交易*，381(2251):20220050, 2023年。

+   Zhang 等人 [2023g] Jesse Zhang, Jiahui Zhang, Karl Pertsch, Ziyi Liu, Xiang Ren, Minsuk Chang, Shao-Hua Sun, 和 Joseph J Lim. 自我引导技能提升：在大型语言模型的指导下学习解决新任务。*arXiv 预印本 arXiv:2310.10021*，2023g年。

+   Jin et al. [2021] Xisen Jin, Dejiao Zhang, Henghui Zhu, Wei Xiao, Shang-Wen Li, Xiaokai Wei, Andrew Arnold, 和 Xiang Ren. 终身预训练：持续适应新兴语料库的语言模型。*arXiv 预印本 arXiv:2110.08534*，2021年。

+   Monaikul et al. [2021] Natawut Monaikul, Giuseppe Castellucci, Simone Filice, 和 Oleg Rokhlenko. 命名实体识别的持续学习。在*AAAI人工智能会议论文集*，第35卷，页面13570–13577，2021年。

+   Qin et al. [2023b] Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han, 等人. 基于基础模型的工具学习。*arXiv 预印本 arXiv:2304.08354*，2023年。

+   Zelikman et al. [2022] Eric Zelikman, Yuhuai Wu, Jesse Mu, 和 Noah Goodman. Star：通过推理引导推理的自举方法。*神经信息处理系统进展*，35：15476–15488，2022年。

+   Huang et al. [2022b] Jiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, 和 Jiawei Han. 大型语言模型可以自我提升。*arXiv 预印本 arXiv:2210.11610*，2022年。

+   Houlsby et al. [2019a] Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe, Andrea Gesmundo, Mona Attariyan, 和 Sylvain Gelly. 参数高效的NLP迁移学习。在*国际机器学习会议*上，页面2790–2799。PMLR，2019年。

+   Mangrulkar et al. [2022] Sourab Mangrulkar, Sylvain Gugger, Lysandre Debut, Younes Belkada, Sayak Paul, 和 Benjamin Bossan. Peft：最先进的参数高效微调方法。[https://github.com/huggingface/peft](https://github.com/huggingface/peft)，2022年。

+   Wang et al. [2022b] Yaqing Wang, Subhabrata Mukherjee, Xiaodong Liu, Jing Gao, Ahmed Hassan Awadallah, 和 Jianfeng Gao. Adamix：用于大规模语言模型参数高效调优的适配器混合方法。*arXiv 预印本 arXiv:2205.12410*，1(2)：4，2022年。

+   Chen et al. [2023c] Baian Chen, Chang Shu, Ehsan Shareghi, Nigel Collier, Karthik Narasimhan, 和 Shunyu Yao. Fireact：面向语言代理的微调方法。*arXiv 预印本 arXiv:2310.05915*，2023年。

+   Frantar et al. [2022] Elias Frantar, Saleh Ashkboos, Torsten Hoefler, 和 Dan Alistarh. Gptq：生成预训练变换器的精确后训练量化。*arXiv 预印本 arXiv:2210.17323*，2022年。

+   Lin et al. [2023] Ji Lin, Jiaming Tang, Haotian Tang, Shang Yang, Xingyu Dang, 和 Song Han. Awq：面向LLM压缩和加速的激活感知权重量化。*arXiv 预印本 arXiv:2306.00978*，2023年。

+   Liu et al. [2023a] Zechun Liu, Barlas Oguz, Changsheng Zhao, Ernie Chang, Pierre Stock, Yashar Mehdad, Yangyang Shi, Raghuraman Krishnamoorthi, 和 Vikas Chandra. Llm-qat：面向大型语言模型的数据无关量化感知训练。*arXiv 预印本 arXiv:2305.17888*，2023年。

+   Yao 等人 [2022c] Zhewei Yao, Reza Yazdani Aminabadi, Minjia Zhang, Xiaoxia Wu, Conglong Li, 和 Yuxiong He. Zeroquant: 高效且经济的大规模变换器后训练量化。*神经信息处理系统进展*，35:27168–27183，2022年c。

+   Xiao 等人 [2023] Guangxuan Xiao, Ji Lin, Mickael Seznec, Hao Wu, Julien Demouth, 和 Song Han. Smoothquant: 精确且高效的大规模语言模型后训练量化。载于 *国际机器学习会议*，第38087–38099页。PMLR，2023年。

+   Ma 等人 [2023] Xinyin Ma, Gongfan Fang, 和 Xinchao Wang. Llm-pruner: 大规模语言模型的结构化修剪。*arXiv预印本arXiv:2305.11627*，2023年。

+   Frantar 和 Alistarh [2023] Elias Frantar 和 Dan Alistarh. Sparsegpt: 大规模语言模型可以通过一次修剪精确地减少规模。载于 *国际机器学习会议*，第10323–10337页。PMLR，2023年。

+   Sun 等人 [2023b] Mingjie Sun, Zhuang Liu, Anna Bair, 和 J Zico Kolter. 一种简单且有效的大规模语言模型修剪方法。*arXiv预印本arXiv:2306.11695*，2023年b。

+   Timiryasov 和 Tastet [2023] Inar Timiryasov 和 Jean-Loup Tastet. Baby llama: 从一组训练于小数据集的教师中进行知识蒸馏，且没有性能损失。*arXiv预印本arXiv:2308.02019*，2023年。

+   Gu 等人 [2023] Yuxian Gu, Li Dong, Furu Wei, 和 Minlie Huang. 大规模语言模型的知识蒸馏。*arXiv预印本arXiv:2306.08543*，2023年。

+   Hsieh 等人 [2023] Cheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, Hootan Nakhost, Yasuhisa Fujii, Alexander Ratner, Ranjay Krishna, Chen-Yu Lee, 和 Tomas Pfister. 一步一步地进行蒸馏！以更少的训练数据和更小的模型尺寸超越更大的语言模型。*arXiv预印本arXiv:2305.02301*，2023年。

+   Li 等人 [2023c] Liunian Harold Li, Jack Hessel, Youngjae Yu, Xiang Ren, Kai-Wei Chang, 和 Yejin Choi. 符号链式思维蒸馏：小型模型也能“逐步思考”。*arXiv预印本arXiv:2306.14050*，2023年c。

+   Yao 等人 [2023b] Zhewei Yao, Xiaoxia Wu, Cheng Li, Stephen Youn, 和 Yuxiong He. Zeroquant-v2: 探索大规模语言模型后训练量化，从综合研究到低秩补偿，2023年b。

+   Li 等人 [2023d] Yixiao Li, Yifan Yu, Qingru Zhang, Chen Liang, Pengcheng He, Weizhu Chen, 和 Tuo Zhao. Losparse: 基于低秩和稀疏近似的结构化大规模语言模型压缩。*arXiv预印本arXiv:2306.11222*，2023年d。

+   Li 等人 [2023e] Yucheng Li, Bo Dong, Chenghua Lin, 和 Frank Guerin. 压缩上下文以提升大规模语言模型推理效率，2023年e。

+   Jiang 等人 [2023a] Huiqiang Jiang, Qianhui Wu, Chin-Yew Lin, Yuqing Yang, 和 Lili Qiu. Llmlingua: 压缩提示词以加速大规模语言模型推理. 载于 *2023年自然语言处理实证方法会议论文集（EMNLP 2023）*，2023年12月。

+   Chevalier 等人 [2023] Alexis Chevalier、Alexander Wettig、Anirudh Ajith 和 Danqi Chen。将语言模型适应于压缩上下文。*ArXiv*，abs/2305.14788，2023年。

+   Anagnostidis 等人 [2023] Sotiris Anagnostidis、Dario Pavllo、Luca Biggio、Lorenzo Noci、Aurelien Lucchi 和 Thomas Hoffmann。用于高效且可解释的自回归变换器的动态上下文剪枝。*arXiv 预印本 arXiv:2305.15805*，2023年。

+   Zhang 等人 [2023h] Zhenyu Zhang、Ying Sheng、Tianyi Zhou、Tianlong Chen、Lianmin Zheng、Ruisi Cai、Zhao Song、Yuandong Tian、Christopher Ré、Clark Barrett 等人。H2o：高效生成推理的重击者预言机，用于大型语言模型。*arXiv 预印本 arXiv:2306.14048*，2023h年。

+   Ge 等人 [2024] Suyu Ge、Yunan Zhang、Liyuan Liu、Minjia Zhang、Jiawei Han 和 Jianfeng Gao。模型告诉你该丢弃什么：适应性 KV 缓存压缩用于 LLM。*arXiv 预印本 arXiv:2306.14048*，2024年。

+   Dao 等人 [2022] Tri Dao、Dan Fu、Stefano Ermon、Atri Rudra 和 Christopher Ré。Flashattention：具有 IO 感知的快速且内存高效的精确注意力机制。*神经信息处理系统进展*，35：16344–16359，2022年。

+   Dao [2023] Tri Dao。Flashattention-2：具有更好并行性和工作分配的更快注意力机制。*arXiv 预印本 arXiv:2307.08691*，2023年。

+   Hong 等人 [2023c] Ke Hong、Guohao Dai、Jiaming Xu、Qiuli Mao、Xiuhong Li、Jun Liu、Kangdi Chen、Hanyu Dong 和 Yu Wang。Flashdecoding++：在 GPU 上更快速的大型语言模型推理。*arXiv 预印本 arXiv:2311.01282*，2023c年。

+   Chen 等人 [2023d] Charlie Chen、Sebastian Borgeaud、Geoffrey Irving、Jean-Baptiste Lespiau、Laurent Sifre 和 John Jumper。通过推测性采样加速大型语言模型解码。*arXiv 预印本 arXiv:2302.01318*，2023d年。

+   Leviathan 等人 [2023] Yaniv Leviathan、Matan Kalman 和 Yossi Matias。通过推测性解码实现变换器的快速推理。在 *国际机器学习会议*，第19274–19286页。PMLR，2023年。

+   Sheng 等人 [2023] Ying Sheng、Lianmin Zheng、Binhang Yuan、Zhuohan Li、Max Ryabinin、Daniel Y. Fu、Zhiqiang Xie、Beidi Chen、Clark Barrett、Joseph E. Gonzalez、Percy Liang、Christopher Ré、Ion Stoica 和 Ce Zhang。Flexgen：使用单个 GPU 的大型语言模型高吞吐量生成推理，2023年。

+   Song 等人 [2023] Yixin Song、Zeyu Mi、Haotong Xie 和 Haibo Chen。Powerinfer：使用消费级 GPU 的快速大型语言模型服务。*arXiv 预印本 arXiv:2312.12456*，2023年。

+   Alizadeh 等人 [2023] Keivan Alizadeh、Iman Mirzadeh、Dmitry Belenko、Karen Khatamifard、Minsik Cho、Carlo C Del Mundo、Mohammad Rastegari 和 Mehrdad Farajtabar。闪电推理：有限内存下高效的大型语言模型推理。*arXiv 预印本 arXiv:2312.11514*，2023年。

+   Qualcomm [2023] Qualcomm. Snapdragon 8 Gen 3 移动平台。 [https://www.qualcomm.com/products/mobile/snapdragon/smartphones/snapdragon-8-series-mobile-platforms/snapdragon-8-gen-3-mobile-platform](https://www.qualcomm.com/products/mobile/snapdragon/smartphones/snapdragon-8-series-mobile-platforms/snapdragon-8-gen-3-mobile-platform)，2023。

+   Reidy 等人 [2023] Brendan C Reidy, Mohammadreza Mohammadi, Mohammed E Elbtity 和 Ramtin Zand. 高效部署变换器模型在边缘 TPU 加速器上的应用：一个真实系统的评估。在 *变换器模型架构与系统支持（ASSYST@ ISCA 2023）*，2023。

+   Hong 等人 [2022] Seongmin Hong, Seungjae Moon, Junsoo Kim, Sungjae Lee, Minsub Kim, Dongsoo Lee 和 Joo-Young Kim. Dfx: 一种低延迟的多FPGA设备，用于加速基于变换器的文本生成。在 *2022年第55届IEEE/ACM国际微架构研讨会（MICRO）*，第616–630页，IEEE，2022。

+   Houlsby 等人 [2019b] Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea Gesmundo, Mona Attariyan 和 Sylvain Gelly. 面向参数高效的转移学习在自然语言处理中的应用。*CoRR*, abs/1902.00751, 2019b.

+   Hu 等人 [2023e] Zhiqiang Hu, Lei Wang, Yihuai Lan, Wanyu Xu, Ee-Peng Lim, Lidong Bing, Xing Xu, Soujanya Poria 和 Roy Ka-Wei Lee. Llm-adapters：一种用于大规模语言模型参数高效微调的适配器家族，2023e。

+   Hu 等人 [2022] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang 和 Weizhu Chen. Lora：大规模语言模型的低秩适应。在 *国际学习表征会议*，2022。网址 [https://openreview.net/forum?id=nZeVKeeFYf9](https://openreview.net/forum?id=nZeVKeeFYf9)。

+   Lv 等人 [2023] Kai Lv, Yuqing Yang, Tengxiao Liu, Qinghui Gao, Qipeng Guo 和 Xipeng Qiu. 针对资源有限的大规模语言模型的全参数微调，2023。

+   Liu 等人 [2023b] Hong Liu, Zhiyuan Li, David Hall, Percy Liang 和 Tengyu Ma. Sophia：一种可扩展的随机二阶优化器，用于语言模型的预训练，2023b。

+   Gunasekar 等人 [2023] Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio César Teodoro Mendes, Allie Del Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli Saarikivi, Adil Salim, Shital Shah, Harkirat Singh Behl, Xin Wang, Sébastien Bubeck, Ronen Eldan, Adam Tauman Kalai, Yin Tat Lee 和 Yuanzhi Li. 课本就是你所需要的一切，2023。

+   Li 等人 [2023f] Yuanzhi Li, Sébastien Bubeck, Ronen Eldan, Allie Del Giorno, Suriya Gunasekar 和 Yin Tat Lee. 课本就是你所需要的一切 ii：phi-1.5 技术报告，2023f。

+   Javaheripi 和 Bubeck [2023] Mojan Javaheripi 和 Sébastien Bubeck. Phi-2：小型语言模型的惊人力量。 [https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/)，2023。

+   Liu 等人 [2023c] Yuhan Liu, Hanchen Li, Kuntai Du, Jiayi Yao, Yihua Cheng, Yuyang Huang, Shan Lu, Michael Maire, Henry Hoffmann, Ari Holtzman, Ganesh Ananthanarayanan, 和 Junchen Jiang. Cachegen: 用于语言模型应用的快速上下文加载，2023c。

+   Datar 等人 [2004] Mayur Datar, Nicole Immorlica, Piotr Indyk, 和 Vahab S. Mirrokni. 基于 p-稳定分布的局部敏感哈希方案. 载于 *第二十届计算几何学年会论文集*，SCG ’04，第253–262页，美国纽约，2004年。计算机协会出版。ISBN 1581138857。doi: 10.1145/997817.997857。

+   Dasgupta 和 Freund [2008] Sanjoy Dasgupta 和 Yoav Freund. 随机投影树与低维流形. 载于 *第四十届年度 ACM 计算理论研讨会论文集*，STOC ’08，第537–546页，美国纽约，2008年。计算机协会出版。ISBN 9781605580470。doi: 10.1145/1374376.1374452。

+   Chen 等人 [2021] Qi Chen, Bing Zhao, Haidong Wang, Mingqin Li, Chuanjie Liu, Zengzhong Li, Mao Yang, 和 Jingdong Wang. SPANN: 高效的十亿级近似最近邻搜索. 载于 *神经信息处理系统进展*，2021年。

+   Malkov 和 Yashunin [2020] Yu A. Malkov 和 D. A. Yashunin. 使用分层可导航小世界图进行高效且稳健的近似最近邻搜索. *IEEE Trans. Pattern Anal. Mach. Intell.*, 42(4):824–836, 2020年4月。ISSN 0162-8828。doi: 10.1109/TPAMI.2018.2889473。

+   Jayaram Subramanya 等人 [2019] Suhas Jayaram Subramanya, Fnu Devvrit, Harsha Vardhan Simhadri, Ravishankar Krishnawamy, 和 Rohan Kadekodi. Diskann: 在单节点上进行快速准确的十亿点最近邻搜索. 载于 *神经信息处理系统进展*，第32卷，2019年。

+   Jang 等人 [2023] Junhyeok Jang, Hanjin Choi, Hanyeoreum Bae, Seungjun Lee, Miryeong Kwon, 和 Myoungsoo Jung. Cxl-anns: 十亿级近似最近邻搜索的软件硬件协同内存解构与计算. 载于 *USENIX年度技术会议*，2023年。

+   Jiang 等人 [2023b] Wenqi Jiang, Shigang Li, Yu Zhu, Johannes de Fine Licht, Zhenhao He, Runbin Shi, Cédric Renggli, Shuai Zhang, Theodoros Rekatsinas, Torsten Hoefler, 和 Gustavo Alonso. 硬件与算法共同设计用于向量搜索. 载于 *国际高性能计算、网络、存储与分析会议论文集*，2023b。

+   team [2021] Qdrant 团队. Qdrant. [https://github.com/qdrant/qdrant](https://github.com/qdrant/qdrant)，2021年。

+   team [2016] Vespa.ai 团队. Vespa. [https://github.com/vespa-engine/vespa](https://github.com/vespa-engine/vespa)，2016年。

+   Wei 等人 [2020] Chuangxian Wei, Bin Wu, Sheng Wang, Renjie Lou, Chaoqun Zhan, Feifei Li, 和 Yuanzhe Cai. Analyticdb-v: 面向结构化与非结构化数据查询融合的混合分析引擎. *Proc. VLDB Endow.*, 13(12):3152–3165, 2020年8月。ISSN 2150-8097。doi: 10.14778/3415478.3415541。

+   王等人 [2021] 王建国，易小萌，郭任通，金海，徐鹏，李胜军，王向宇，郭向洲，李承明，徐晓海，余昆，袁宇星，邹英豪，龙继全，蔡宇东，李振翔，张志峰，莫艺华，顾俊，蒋瑞宜，魏一。Milvus：一款为向量数据管理而专门构建的系统。在*2021年国际数据管理大会论文集*，SIGMOD ’21，第2614-2627页，美国纽约，2021年。计算机协会出版。ISBN 9781450383431。doi: 10.1145/3448016.3457550。

+   吴等人 [2022a] 吴伟，何俊林，乔宇，傅国恒，刘力，余金。HQANN：高效且稳健的混合查询相似性搜索，带有结构化和非结构化约束。在*第31届ACM国际信息与知识管理大会论文集*，CIKM ’22，第4580-4584页，美国纽约，2022a年。计算机协会出版。ISBN 9781450392365。doi: 10.1145/3511808.3557610。

+   约翰逊等人 [2019] 杰夫·约翰逊，马泰伊斯·杜兹，厄尔维·杰古。千亿级相似性搜索与GPU。*IEEE大数据期刊*，7(3):535-547，2019年。

+   安德烈等人 [2021] 法比恩·安德烈，安妮-玛丽·凯尔马雷克，尼古拉·勒·斯科阿内克。更快的adc：通过simd解锁产品量化的隐藏潜力。*IEEE模式分析与机器智能期刊*，43(5):1666-1677，2021年5月。ISSN 1939-3539。doi: 10.1109/tpami.2019.2952606。

+   团队 [2019] Vald团队。Vald。 [https://github.com/vdaas/vald](https://github.com/vdaas/vald)，2019年。

+   张等人 [2024b] 张志豪，朱艾伦，杨丽洁，徐艺华，李兰婷，冯晓华，贾志豪。通过推测加速检索增强语言模型服务。*ArXiv*，abs/2401.14021，2024b年。URL [https://api.semanticscholar.org/CorpusID:267212215](https://api.semanticscholar.org/CorpusID:267212215)。

+   蒋等人 [2024] 蒋文琦，张帅，韩博然，王杰，王伯妮，克拉斯卡·蒂姆。Piperag：通过算法-系统协同设计实现快速检索增强生成，2024年。

+   金等人 [2024] 金超，张子力，蒋宣霖，刘方月，刘欣，刘轩哲，金欣。Ragcache：高效的知识缓存用于检索增强生成，2024年。

+   穆尼霍夫等人 [2024] 尼克拉斯·穆尼霍夫，苏宏金，王亮，杨楠，魏福儒，余涛，阿曼普里特·辛格，道维·基拉。生成性表征指令调优，2024年。

+   邦达连科等人 [2021] 叶尔塞·邦达连科，马库斯·纳格尔，提杰门·布兰克福特。理解并克服高效变压器量化的挑战。*arXiv预印本arXiv:2109.12948*，2021年。

+   魏等人 [2022b] 魏秀英，张云晨，张向国，龚瑞豪，张尚航，张奇，余风伟，刘向龙。异常值抑制：推动低位变压器语言模型的极限。*神经信息处理系统进展*，35：17402-17414，2022b年。

+   llama.cpp开发者 [2023] llama.cpp开发者。ggerganov/llama.cpp：Facebook的Llama模型的C/C++移植。[https://github.com/ggerganov/llama.cpp](https://github.com/ggerganov/llama.cpp)，2023。

+   团队 [2023] MLC团队。MLC-LLM，2023。网址 [https://github.com/mlc-ai/mlc-llm](https://github.com/mlc-ai/mlc-llm)。

+   袁等人 [2023a] 袁志航，牛琳，刘家伟，刘文宇，王兴刚，尚宇张，孙光宇，吴强，吴佳翔，吴冰哲。RPTQ：基于重排序的后训练量化用于大型语言模型。*arXiv预印本 arXiv:2304.01089*，2023a。

+   魏等人 [2023a] 魏秀颖，张云晨，李宇航，张向国，龚瑞豪，郭金扬，刘向龙。异常值抑制+：通过等效和最优的平移与缩放实现大型语言模型的精确量化。*arXiv预印本 arXiv:2304.09145*，2023a。

+   刘等人 [2023d] 刘晶，龚瑞豪，魏秀颖，董志伟，蔡建飞，庄博涵。QLLM：准确高效的低位宽量化用于大型语言模型。*arXiv预印本 arXiv:2310.08041*，2023d。

+   张等人 [2023i] 张怡佳，赵玲然，曹诗杰，王文强，曹婷，杨帆，杨茂，张尚航，徐宁怡。整数还是浮点？大型语言模型低位量化的新展望。*arXiv预印本 arXiv:2305.12356*，2023i。

+   吴等人 [2023b] 吴霞霞，姚哲伟，何宇雄。Zeroquant-fp：使用浮动点格式在大型语言模型后训练W4A8量化中的一次飞跃。*arXiv预印本 arXiv:2307.09782*，2023b。

+   刘等人 [2023e] 刘世阳，刘泽春，黄熙杰，董平城，郑光廷。LLM-FP4：4位浮点量化的Transformer。*arXiv预印本 arXiv:2310.16836*，2023e。

+   李等人 [2024] 李露畅，钱盛，卢杰，袁伦熙，王睿，谢琴。Transformer-lite：在手机GPU上高效部署大型语言模型。*arXiv预印本 arXiv:2403.20041*，2024。

+   阿米纳巴迪等人 [2022] 雷扎·亚兹达尼·阿米纳巴迪，萨米亚姆·拉吉班达里，阿马尔·艾哈迈德·阿万，李程，李杜，埃尔顿·郑，奥拉图吉·鲁瓦斯，沙登·史密斯，张敏佳，杰夫·拉斯利等人。Deepspeed-inference：在前所未有的规模上实现高效推理的Transformer模型。在*SC22：国际高性能计算、网络、存储与分析会议*，页1-15，IEEE，2022。

+   权等人 [2023] 权伍硕，李卓涵，庄思远，盛英，郑连敏，余浩，何俊涛，张浩，斯托卡。大型语言模型服务的高效内存管理：PagedAttention。在*第29届操作系统原理研讨会论文集*，页611-626，2023。

+   刘等人 [2023f] 刘子畅，阿迪亚·德赛，廖方硕，王伟涛，谢维克，许兆卓，阿纳斯塔修斯·凯里迪斯，安舒马利·什里瓦斯塔瓦。Scissorhands：利用重要性假设的持久性进行测试时的大型语言模型KV缓存压缩。*arXiv预印本 arXiv:2305.17118*，2023f。

+   Ainslie et al. [2023] 约书亚·安斯利、雷涛、米歇尔·德·琼、圣地亚哥·翁塔农、西达尔塔·布拉马、尤里·泽姆良斯基、戴维·C·乌图斯、曼迪·郭、詹姆斯·李-托普、易·泰、孙-玄·宋和苏密特·K·桑海。Colt5：通过条件计算加速长距离变换器。发表于*自然语言处理经验方法大会*，2023年。

+   Del Corro et al. [2023] 卢西亚诺·德尔·科罗、艾莉·德尔·乔尔诺、萨哈杰·阿格瓦尔、余彬、艾哈迈德·阿瓦达拉和苏布哈布拉特·穆克吉。Skipdecode：具有批处理和缓存的自回归跳跃解码，用于高效的大语言模型推理。*arXiv 预印本 arXiv:2307.02628*，2023年。

+   Wang et al. [2020b] 王思农、李贝琳达·Z、马迪安·卡布萨、方汉和马浩。Linformer：具有线性复杂度的自注意力。*ArXiv*，abs/2006.04768，2020b年。

+   Park et al. [2022] 朴根浩、朴倍成、金民硕、李圣载、金正勋、权范锡、权世钟、金炳旭、李永周和李东洙。Lut-gemm：基于LUT的量化矩阵乘法，用于大规模生成型语言模型的高效推理。*arXiv 预印本 arXiv:2206.09557*，2022年。

+   Miao et al. [2023] 许鹏苗、加布里埃尔·奥利亚罗、张志豪、程欣浩、王泽宇、黄瑞莹、陈卓铭、阿尔芬·达亚安、雷娜·阿布扬卡尔和贾志豪。Specinfer：通过推测推理和令牌树验证加速生成型大语言模型的服务。*arXiv 预印本 arXiv:2305.09781*，2023年。

+   Spector and Re [2023] 本杰明·斯佩克特和克里斯·雷。通过分阶段推测解码加速大语言模型推理。*arXiv 预印本 arXiv:2308.04623*，2023年。

+   Kim et al. [2023b] 金世勋、卡尔提基耶·曼卡拉姆、文秀宏、吉特恩德·马利克、迈克尔·W·马霍尼、阿米尔·戈拉米和库尔特·凯茨特。通过大小解码器的推测解码。发表于*第37届神经信息处理系统大会*，2023b年。

+   Liu et al. [2023g] 刘子畅、王珏、陶峙、周天一、袁斌航、宋钊、安舒马利·施里瓦斯塔瓦、张策、田元东、克里斯托弗·雷等。Déjà vu：推理时高效大语言模型的上下文稀疏性。发表于*国际机器学习大会*，页码22137-22176，PMLR，2023g年。

+   Ye et al. [2023] 叶文华、周旭、周乔伊、陈岑和李建利。基于高效可重配置流线阵列在FPGA上加速注意力机制。*ACM 嵌入式计算系统交易*，22(6)：1–22，2023年。

+   Samsi et al. [2023] 西达尔塔·萨姆西、赵丹、约瑟夫·麦克唐纳、李宝林、亚当·米哈利亚斯、迈克尔·琼斯、威廉·伯杰龙、杰里米·凯普纳、德维什·蒂瓦里和维贾伊·盖德帕利。从词语到瓦特：大型语言模型推理的能耗基准测试。*2023 IEEE 高性能极限计算会议 (HPEC)*，页码1–9，2023年。网址 [https://api.semanticscholar.org/CorpusID:263620702](https://api.semanticscholar.org/CorpusID:263620702)。

+   Stojkovic et al. [2024] Jovan Stojkovic, Esha Choukse, Chaojie Zhang, Íñigo Goiri, 和 Josep Torrellas. 朝着更绿色的LLM: 将能效置于LLM推理的前沿。 *ArXiv*, abs/2403.20306, 2024。网址 [https://api.semanticscholar.org/CorpusID:268793445](https://api.semanticscholar.org/CorpusID:268793445)。

+   Laskaridis et al. [2024] Stefanos Laskaridis, Kleomenis Katevas, Lorenzo Minto, 和 Hamed Haddadi. Melting point: 语言变压器的移动评估，2024年。

+   Faiz et al. [2023] Ahmad Faiz, Sotaro Kaneda, Ruhan Wang, Rita Osi, Parteek Sharma, Fan Chen, 和 Lei Jiang. Llmcarbon: 大型语言模型的端到端碳足迹建模。 *ArXiv*, abs/2309.14393, 2023。网址 [https://api.semanticscholar.org/CorpusID:262825233](https://api.semanticscholar.org/CorpusID:262825233)。

+   Cao et al. [2021] Qingqing Cao, Yash Kumar Lal, H. Trivedi, Aruna Balasubramanian, 和 Niranjan Balasubramanian. Irene: 变压器的可解释能量预测。 *ArXiv*, abs/2106.01199, 2021。网址 [https://api.semanticscholar.org/CorpusID:235294249](https://api.semanticscholar.org/CorpusID:235294249)。

+   Gim et al. [2023] In Gim, Guojun Chen, Seung seob Lee, Nikhil Sarda, Anurag Khandelwal, 和 Lin Zhong. Prompt cache: 低延迟推理的模块化注意力重用。 *ArXiv*, abs/2311.04934, 2023。网址 [https://api.semanticscholar.org/CorpusID:265067391](https://api.semanticscholar.org/CorpusID:265067391)。

+   He et al. [2022] Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-Kirkpatrick, 和 Graham Neubig. 朝着统一的参数高效迁移学习视角，2022年。

+   Li and Liang [2021] Xiang Lisa Li 和 Percy Liang. Prefix-tuning: 为生成优化连续提示，2021年。

+   Liu et al. [2022a] Xiao Liu, Kaixuan Ji, Yicheng Fu, Weng Lam Tam, Zhengxiao Du, Zhilin Yang, 和 Jie Tang. P-tuning v2: 提示调优在各个规模和任务中可与微调相媲美，2022a。

+   Zhang et al. [2023j] Renrui Zhang, Jiaming Han, Chris Liu, Peng Gao, Aojun Zhou, Xiangfei Hu, Shilin Yan, Pan Lu, Hongsheng Li, 和 Yu Qiao. Llama-adapter: 使用零初始化注意力对语言模型进行高效微调，2023j。

+   Liu et al. [2023h] Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, 和 Jie Tang. GPT 也能理解，2023h。

+   Liu et al. [2022b] Haokun Liu, Derek Tam, Mohammed Muqeeth, Jay Mohta, Tenghao Huang, Mohit Bansal, 和 Colin Raffel. 少样本参数高效微调比上下文学习更好且更便宜。 *ArXiv*, abs/2205.05638, 2022b。网址 [https://api.semanticscholar.org/CorpusID:248693283](https://api.semanticscholar.org/CorpusID:248693283)。

+   Zhao et al. [2024] Yanjun Zhao, Sizhe Dang, Haishan Ye, Guang Dai, Yi Qian, 和 Ivor Wai-Hung Tsang. 无痛二阶微调大型语言模型：一种海森矩阵启发的零阶优化器。 *ArXiv*, abs/2402.15173, 2024。网址 [https://api.semanticscholar.org/CorpusID:267897669](https://api.semanticscholar.org/CorpusID:267897669)。

+   Liu et al. [2023i] Bingbin Liu, Sébastien Bubeck, Ronen Eldan, Janardhan Kulkarni, Yuanzhi Li, Anh Nguyen, Rachel Ward, 和 Yi Zhang. Tinygsm：使用小型语言模型在gsm8k上达到>80%。*ArXiv*, abs/2312.09241, 2023i. 网址 [https://api.semanticscholar.org/CorpusID:266210221](https://api.semanticscholar.org/CorpusID:266210221).

+   Mikolov et al. [2013] Tomas Mikolov, Kai Chen, Greg Corrado, 和 Jeffrey Dean. 在向量空间中有效估计词表示，2013年。

+   Le和Mikolov [2014] Quoc Le和Tomas Mikolov. 句子和文档的分布式表示。在*第31届国际机器学习大会论文集*中，*机器学习研究论文集*第32卷，第1188-1196页，中国北京，2014年6月22-24日。PMLR。

+   Liu et al. [2023j] Jiongnan Liu, Jiajie Jin, Zihan Wang, Jiehan Cheng, Zhicheng Dou, 和 Ji-Rong Wen. Reta-llm：一个检索增强的大型语言模型工具包，2023j。

+   Melz [2023] Eric Melz. 通过arm-rag增强llm智能：用于检索增强生成的辅助推理记忆，2023年。

+   Zhong et al. [2022] Zexuan Zhong, Tao Lei, 和 Danqi Chen. 使用记忆增强训练语言模型。*ArXiv*, abs/2205.12674, 2022年。网址 [https://api.semanticscholar.org/CorpusID:249062699](https://api.semanticscholar.org/CorpusID:249062699).

+   Han et al. [2023] Yikun Han, Chunjiang Liu, 和 Pengfei Wang. 向量数据库的综合调查：存储与检索技术、挑战。*arXiv预印本arXiv:2310.11703*，2023年。

+   Pan et al. [2023] James Jie Pan, Jianguo Wang, 和 Guoliang Li. 向量数据库管理系统的调查，2023年。

+   Taipalus [2023] Toni Taipalus. 向量数据库管理系统：基础概念、应用案例和当前挑战。*ArXiv*, abs/2309.11322, 2023年。

+   Wu et al. [2022b] Yuhuai Wu, Markus N. Rabe, DeLesley S. Hutchins, 和 Christian Szegedy. 记忆化变换器。*ArXiv*, abs/2203.08913, 2022b。

+   Modarressi et al. [2023] Ali Modarressi, Ayyoob Imani, Mohsen Fayyaz, 和 Hinrich Schütze. Ret-llm：面向大型语言模型的通用读写记忆。*arXiv预印本arXiv:2305.14322*，2023年。

+   Dasgupta和Sinha [2013] Sanjoy Dasgupta和Kaushik Sinha. 用于精确最近邻搜索的随机划分树，2013年。

+   Malkov et al. [2014] Yury Malkov, Alexander Ponomarenko, Andrey Logvinov, 和 Vladimir Krylov. 基于可导航小世界图的近似最近邻算法。*信息系统*，45:61–68，2014年。

+   Gollapudi et al. [2023] Siddharth Gollapudi, Neel Karia, Varun Sivashankar, Ravishankar Krishnaswamy, Nikit Begwani, Swapnil Raz, Yiyong Lin, Yin Zhang, Neelam Mahapatro, Premkumar Srinivasan, Amit Singh, 和 Harsha Vardhan Simhadri. Filtered-diskann：带过滤器的近似最近邻搜索图算法。在*ACM Web Conference 2023会议录*中，WWW ’23，第3406-3416页，美国纽约，2023年。计算机协会。ISBN 9781450394161。DOI: 10.1145/3543507.3583552.

+   Tian et al. [2023] Yao Tian, Ziyang Yue, Ruiyuan Zhang, Xi Zhao, Bolong Zheng, 和 Xiaofang Zhou. 高维向量数据库中的近似最近邻搜索：当前研究与未来方向，2023年。

+   Ni et al. [2023] Jiongkang Ni, Xiaoliang Xu, Yuxiang Wang, Can Li, Jiajie Yao, Shihai Xiao, 和 Xuecang Zhang. Diskann++: 使用查询敏感入口顶点的同构映射图索引上的高效基于页的搜索。*ArXiv*，abs/2310.00402，2023年。

+   Zhao et al. [2020] Weijie Zhao, Shulong Tan, 和 Ping Li. Song: 基于GPU的近似最近邻搜索。*2020 IEEE 第36届国际数据工程会议（ICDE）*，第1033–1044页，2020年。

+   Groh et al. [2019] Fabian Groh, Lukas Ruppert, Patrick Wieschollek, 和 Hendrik P. A. Lensch. Ggnn: 基于图的GPU最近邻搜索。*IEEE 大数据学报*，9：267–279，2019年。

+   Ootomo et al. [2023] Hiroyuki Ootomo, Akira Naruse, Corey J. Nolet, Ray Wang, Tamas B. Fehér, 和 Y. Wang. Cagra: 高度并行的图构建与GPU近似最近邻搜索。*ArXiv*，abs/2308.15136，2023年。

+   Touvron et al. [2023] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, 和 Guillaume Lample. Llama: 开放且高效的基础语言模型，2023年。

+   Team [2023] BlueLM团队. Bluelm: 一个开放的多语言7B语言模型。 [https://github.com/vivo-ai-lab/BlueLM](https://github.com/vivo-ai-lab/BlueLM)，2023年。

+   Liu et al. [2024b] Zhiwei Liu, Weiran Yao, Jianguo Zhang, Liangwei Yang, Zuxin Liu, Juntao Tan, Prafulla K Choubey, Tian Lan, Jason Wu, Huan Wang, 等. Agentlite: 用于构建和推动面向任务的LLM代理系统的轻量级库。*arXiv预印本 arXiv:2402.15538*，2024b年。

+   Dettmers et al. [2023] Tim Dettmers, Ruslan Svirschevski, Vage Egiazarian, Denis Kuznedelev, Elias Frantar, Saleh Ashkboos, Alexander Borzunov, Torsten Hoefler, 和 Dan Alistarh. Spqr: 一种用于近无损LLM权重压缩的稀疏量化表示。*arXiv预印本 arXiv:2306.03078*，2023年。

+   Rivest et al. [1978] Ronald L Rivest, Len Adleman, Michael L Dertouzos, 等. 关于数据银行与隐私同态。*安全计算基础*，4(11)：169–180，1978年。

+   Gentry [2009] Craig Gentry. 使用理想格的完全同态加密。载于*计算理论第41届ACM年会论文集*，第169–178页，2009年。

+   Gilad-Bachrach et al. [2016] Ran Gilad-Bachrach, Nathan Dowlin, Kim Laine, Kristin Lauter, Michael Naehrig, 和 John Wernsing. Cryptonets: 将神经网络应用于加密数据，具有高吞吐量和准确性。载于*国际机器学习会议*，第201–210页。PMLR，2016年。

+   Chen 等人 [2022] Tianyu Chen, Hangbo Bao, Shaohan Huang, Li Dong, Binxing Jiao, Daxin Jiang, Haoyi Zhou, Jianxin Li 和 Furu Wei. The-x：带有同态加密的隐私保护变压器推理。*arXiv 预印本 arXiv:2206.00216*，2022年。

+   Reagen 等人 [2021] Brandon Reagen, Woo-Seok Choi, Yeongil Ko, Vincent T Lee, Hsien-Hsin S Lee, Gu-Yeon Wei 和 David Brooks. Cheetah：优化和加速用于私密推理的同态加密。发表于 *2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA)*，第26–39页。IEEE，2021年。

+   Acar 等人 [2018] Abbas Acar, Hidayet Aksu, A Selcuk Uluagac 和 Mauro Conti. 同态加密方案调查：理论与实现。*ACM Computing Surveys (Csur)*, 51(4):1–35, 2018.

+   Goldwasser [1997] Shafi Goldwasser. 多方计算：过去与现在。发表于 *第十六届ACM分布式计算原理年会论文集*，第1–6页，1997年。

+   Knott 等人 [2021] Brian Knott, Shobha Venkataraman, Awni Hannun, Shubho Sengupta, Mark Ibrahim 和 Laurens van der Maaten. Crypten：安全的多方计算与机器学习相结合。*神经信息处理系统进展*，34:4961–4973，2021年。

+   Tramer 和 Boneh [2018] Florian Tramer 和 Dan Boneh. Slalom：在可信硬件中快速、可验证和私密地执行神经网络。*arXiv 预印本 arXiv:1806.03287*，2018年。

+   Fei 等人 [2021] Shufan Fei, Zheng Yan, Wenxiu Ding 和 Haomeng Xie. SGX的安全漏洞与对策：一项调查。*ACM Computing Surveys (CSUR)*，54(6):1–36，2021年。

+   McCallister [2010] Erika McCallister. *保护个人可识别信息机密性的指南*，第800卷。Diane Publishing，2010年。

+   Lin 等人 [2024] Guo Lin, Wenyue Hua 和 Yongfeng Zhang. Promptcrypt：用于大规模语言模型的安全通信的提示加密。*arXiv 预印本 arXiv:2402.05868*，2024年。

+   Coavoux 等人 [2018] Maximin Coavoux, Shashi Narayan 和 Shay B Cohen. 隐私保护的文本神经表示。*arXiv 预印本 arXiv:1808.09408*，2018年。

+   Zhou 等人 [2022] Xin Zhou, Jinzhu Lu, Tao Gui, Ruotian Ma, Zichu Fei, Yuran Wang, Yong Ding, Yibo Cheung, Qi Zhang 和 Xuan-Jing Huang. Textfusion：通过标记融合进行隐私保护的预训练模型推理。发表于 *2022年自然语言处理实证方法会议论文集*，第8360–8371页，2022年。

+   Zhou 等人 [2023d] Xin Zhou, Yi Lu, Ruotian Ma, Tao Gui, Yuran Wang, Yong Ding, Yibo Zhang, Qi Zhang 和 Xuan-Jing Huang. Textobfuscator：通过模糊词表示使预训练语言模型成为隐私保护者。发表于 *计算语言学协会发现：ACL 2023*，第5459–5473页，2023d年。

+   Liu 等人 [2020] Xiaodong Liu, Hao Cheng, Pengcheng He, Weizhu Chen, Yu Wang, Hoifung Poon 和 Jianfeng Gao. 大型神经语言模型的对抗训练。*arXiv 预印本 arXiv:2004.08994*，2020年。

+   Roesner等人[2012] 弗朗茨·罗伊斯纳、幸田吉、亚历山大·莫什丘克、布莱恩·帕尔诺、王海伦·J和克里斯平·考文。用户驱动的访问控制：重新思考现代操作系统中的权限授予。在*2012年IEEE安全与隐私研讨会*，第224–238页。IEEE，2012年。

+   Evertz等人[2024] 乔纳森·埃弗茨、梅林·克洛斯塔、莉亚·舍恩赫尔和托尔斯滕·艾森霍夫。机器中的低语：大语言模型集成系统中的保密性。*arXiv预印本arXiv:2402.06922*，2024年。

+   Enck等人[2014] 威廉·恩克、彼得·吉尔伯特、申烨普·韩、瓦桑特·坦杜尔卡尔、丙根·俊、兰登·P·考克斯、郑在妍、帕特里克·麦克丹尼尔和安摩尔·N·谢斯。Taintdroid：一个用于智能手机实时隐私监控的信息流跟踪系统。*ACM计算机系统学报（TOCS）*，32(2)：1–29，2014年。

+   Szegedy等人[2014] 克里斯蒂安·塞格迪、沃杰奇·扎伦巴、伊利亚·苏茨基弗、琼·布鲁纳、杜米特鲁·厄尔汗、伊恩·古德费洛和罗布·弗格斯。神经网络的有趣特性，2014年。

+   Xu等人[2020] 许瀚、马耀、刘浩晨、德巴扬·德布、刘辉、唐吉良和阿尼·K·简。图像、图形和文本中的对抗性攻击与防御：综述。*国际自动化与计算学报*，17(2)：151–178，2020年。DOI：10.1007/s11633-019-1211-x。

+   Kumar等人[2023] 阿欧农·库马尔、奇拉格·阿格瓦尔、苏拉吉·斯里尼瓦斯、艾伦·贾许恩·李、索赫尔·费齐和希马宾杜·拉卡拉朱。验证大语言模型对抗性提示的安全性，2023年。

+   Zhao等人[2023c] 赵云青、庞天宇、杜超、杨潇、李崇轩、张耐民和林敏。大规模视觉语言模型的对抗性鲁棒性评估。*arXiv预印本arXiv:2305.16934*，2023c。

+   Wei等人[2023b] 亚历山大·魏、妮卡·哈赫塔拉布和雅各布·斯坦哈特。越狱：大语言模型安全训练为何失败？*arXiv预印本arXiv:2307.02483*，2023b。

+   Schlarmann和Hein[2023] 克里斯蒂安·施拉曼和马蒂亚斯·海因。关于多模态基础模型的对抗性鲁棒性。在*IEEE/CVF计算机视觉国际会议论文集*，第3677–3685页，2023年。

+   Fu等人[2023] 傅晓涵、王子涵、李舒恒、拉杰什·K·古普塔、尼洛法尔·米雷什贾拉赫、泰勒·伯格-柯克帕特里克和厄尔伦斯·费尔南德斯。大语言模型中的工具滥用与视觉对抗性示例，2023年。

+   Zhu等人[2023a] 朱思成、张瑞宜、安邦、吴刚、乔·巴罗、王子超、黄富荣、阿尼·嫩科娃和孙彤。Autodan：基于梯度的可解释对大语言模型的对抗攻击，2023a。

+   Gu等人[2019] 谷天宇、刘康、布伦丹·多兰-加维特和悉达多·戈格。Badnets：评估深度神经网络中的后门攻击。*IEEE访问*，7：47230–47244，2019年。DOI：10.1109/ACCESS.2019.2909068。

+   Yuan 等人 [2023b] 袁一真、孔瑞、谢胜豪、李元春、刘云鑫。Patchbackdoor：一种无需修改模型的深度神经网络后门攻击。发表于 *第31届ACM国际多媒体会议论文集*，第9134–9142页，2023b。

+   Kandpal 等人 [2023] Nikhil Kandpal、Matthew Jagielski、Florian Tramèr 和 Nicholas Carlini。基于上下文学习的语言模型后门攻击。*arXiv 预印本 arXiv:2307.14692*，2023。

+   Zhao 等人 [2023d] 赵帅、温锦鸣、吕安团、赵俊博、傅杰。提示作为后门攻击的触发器：研究语言模型中的漏洞，2023d。

+   Yao 等人 [2023c] 姚鸿伟、娄建、秦展。Poisonprompt：基于提示的大型语言模型后门攻击，2023c。

+   Han 等人 [2024] 韩廷旭、黄胜涵、丁子琪、孙伟松、冯烨博、方春荣、李军、钱汉伟、吴聪、张全俊、刘杨、陈振宇。蒸馏技术在缓解预训练编码器中的后门攻击效果研究，2024。

+   Sun 等人 [2023c] 孙晓飞、李晓雅、孟宇翔、敖翔、吕灵娟、李继伟、张天维。防御自然语言生成中的后门攻击。发表于 *AAAI人工智能会议论文集*，第37卷，第5257–5265页，2023c。

+   Abdelnabi 等人 [2023] Sahar Abdelnabi、Kai Greshake、Shailesh Mishra、Christoph Endres、Thorsten Holz 和 Mario Fritz。你并没有签署这项协议：通过间接提示注入危及现实世界中的大型语言模型集成应用。发表于 *第16届ACM人工智能与安全研讨会论文集*，AISec ’23，第79–90页，纽约，美国，2023年。计算机协会。ISBN 9798400702600。doi: 10.1145/3605764.3623985。

+   Perez 和 Ribeiro [2022] Fábio Perez 和 Ian Ribeiro。忽略之前的提示：语言模型的攻击技术，2022。

+   Liu 等人 [2023k] 刘毅、邓格雷、李月康、王凯龙、张天维、刘业庞、王浩宇、郑彦、刘杨。针对集成大型语言模型应用的提示注入攻击，2023k。

+   Shayegani 等人 [2023] Erfan Shayegani、董越、Nael Abu-Ghazaleh。碎片化的越狱：针对多模态语言模型的组合式对抗性攻击，2023。

+   Chao 等人 [2023] Patrick Chao、Alexander Robey、Edgar Dobriban、Hamed Hassani、George J. Pappas 和 Eric Wong。通过二十个查询破解黑盒大型语言模型，2023。

+   Carlini 等人 [2021] Nicholas Carlini、Florian Tramèr、Eric Wallace、Matthew Jagielski、Ariel Herbert-Voss、Katherine Lee、Adam Roberts、Tom Brown、Dawn Song、Úlfar Erlingsson、Alina Oprea 和 Colin Raffel。从大型语言模型中提取训练数据。发表于 *第30届USENIX安全研讨会*（USENIX Security 21），第2633–2650页。USENIX协会，2021年8月。ISBN 978-1-939133-24-3。

+   Robey等人 [2023] Alexander Robey, Eric Wong, Hamed Hassani, 和 George J. Pappas. Smoothllm: 防御大规模语言模型对抗越狱攻击，2023年。

+   Ji等人 [2023] Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, 和 Pascale Fung. 自然语言生成中的幻觉调查。*ACM Computing Surveys*, 55(12):1–38, 2023年。

+   Rawte等人 [2023] Vipula Rawte, Amit Sheth, 和 Amitava Das. 大规模基础模型中的幻觉调查。*arXiv预印本 arXiv:2309.05922*，2023年。

+   Nair等人 [2023] Varun Nair, Elliot Schumacher, Geoffrey Tso, 和 Anitha Kannan. Dera：通过对话启用的解析代理增强大规模语言模型的生成。*arXiv预印本 arXiv:2303.17071*，2023年。

+   Zhang等人 [2023k] Yifan Zhang, Jingqin Yang, Yang Yuan, 和 Andrew Chi-Chih Yao. 大规模语言模型的累积推理。*arXiv预印本 arXiv:2308.04371*，2023k年。

+   An等人 [2023] Shengnan An, Zexiong Ma, Zeqi Lin, Nanning Zheng, Jian-Guang Lou, 和 Weizhu Chen. 从错误中学习使大规模语言模型成为更好的推理者。*arXiv预印本 arXiv:2310.20689*，2023年。

+   Zhu等人 [2023b] Zhaocheng Zhu, Yuan Xue, Xinyun Chen, Denny Zhou, Jian Tang, Dale Schuurmans, 和 Hanjun Dai. 大规模语言模型可以学习规则。*arXiv预印本 arXiv:2310.07064*，2023b年。

+   Gururangan等人 [2020] Suchin Gururangan, Ana Marasović, Swabha Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey, 和 Noah A. Smith. 不要停止预训练：将语言模型适应领域和任务。发表于*第58届计算语言学会年会论文集*，2020年。

+   Liu等人 [2023l] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, 和 Graham Neubig. 预训练、提示和预测：自然语言处理中的提示方法系统调查。*ACM Computing Surveys*, 55(9):1–35, 2023l年。

+   Wei等人 [2021] Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, 和 Quoc V Le. 微调语言模型是零-shot学习者。发表于*国际学习表征会议*，2021年。

+   Lee等人 [2023c] Harrison Lee, Samrat Phatale, Hassan Mansoor, Kellie Lu, Thomas Mesnard, Colton Bishop, Victor Carbune, 和 Abhinav Rastogi. Rlaif：通过AI反馈扩展人类反馈强化学习。*arXiv预印本 arXiv:2309.00267*，2023c年。

+   Wang等人 [2023g] Guan Wang, Sijie Cheng, Xianyuan Zhan, Xiangang Li, Sen Song, 和 Yang Liu. Openchat：通过混合质量数据推进开源语言模型。*arXiv预印本 arXiv:2309.11235*，2023g年。

+   Kadavath等人 [2022] Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli Tran-Johnson, 等人. 语言模型（大多）知道它们知道什么。*arXiv预印本 arXiv:2207.05221*，2022年。

+   马丹等人 [2023] 阿曼·马丹、尼凯特·坦东、普拉卡尔·古普塔、斯凯勒·哈利南、刘宇高、莎拉·维格雷夫、乌里·阿隆、努哈·德齐里、施里迈·普拉布莫耶、易铭·杨等人。Self-refine：自反馈的迭代精炼。*arXiv 预印本 arXiv:2303.17651*，2023。

+   辛等人 [2023] 诺亚·辛、费德里科·卡萨诺、爱德华·伯曼、阿什温·戈皮纳斯、卡尔提克·纳拉西姆汉和姚顺宇。Reflexion：具语言强化学习的语言代理，2023。

+   陈等人 [2023e] 陈欣云、林麦克斯韦、纳塔纳埃尔·谢尔利和周登宁。教大语言模型自我调试。*arXiv 预印本 arXiv:2304.05128*，2023e。

+   玛纳库尔等人 [2023] 玛卡尔·波塔萨维、刘锡、马克·JF·盖尔斯。Selfcheckgpt：生成大语言模型的零资源黑盒幻觉检测。*arXiv 预印本 arXiv:2303.08896*，2023。

+   杜等人 [2023] 杜一伦、李爽、安东尼奥·托拉尔巴、乔舒亚·B·特嫩鲍姆和伊戈尔·莫达奇。通过多代理辩论提高语言模型的事实性和推理能力。*arXiv 预印本 arXiv:2305.14325*，2023。

+   古等人 [2020] 古凯文、李肯顿、宗泽、帕努蓬·帕苏帕和张名伟。检索增强语言模型的预训练。发表于*国际机器学习会议*，第3929–3938页。PMLR，2020。

+   王等人 [2017b] 王全、毛振东、王斌和郭力。知识图谱嵌入：方法与应用的综述。*IEEE 知识与数据工程学报*，29(12)：2724–2743，2017b。

+   肯顿和托塔诺瓦 [2019] 雅各布·德夫林、张名伟、肯顿·李和克里斯蒂娜·托塔诺瓦。BERT：用于语言理解的深度双向变换器预训练。发表于*NAACL-HLT 会议论文集*，第1卷，第2页，2019。

+   史等人 [2023] 费雷达·史、陈欣云、卡尼什卡·米斯拉、内森·斯凯尔斯、大卫·多汉、Ed H Chi、纳塔纳埃尔·谢尔利和周登宁。大语言模型容易被无关上下文分散注意力。发表于*国际机器学习会议*，第31210–31227页。PMLR，2023。

+   于等人 [2023] 于文昊、张洪明、潘晓曼、马凯鑫、王洪伟和于东。Chain-of-note：增强检索增强语言模型的鲁棒性。*arXiv 预印本 arXiv:2311.09210*，2023。

+   浅井等人 [2023] 浅井明、吴泽秋、王宜中、阿维鲁普·席尔和哈娜赫·哈吉什尔齐。Self-rag：通过自我反思学习检索、生成和评论。*arXiv 预印本 arXiv:2310.11511*，2023。

+   王等人 [2023h] 王奕乐、李鹏、孙茂松和刘扬。自知识引导的检索增强大语言模型。*arXiv 预印本 arXiv:2310.05002*，2023h。

+   王等人 [2023i] 王志若、荒木润、蒋正宝、穆德·瑞兹万·帕尔维兹和格雷厄姆·纽比格。学习过滤检索增强生成的上下文。*arXiv 预印本 arXiv:2311.08377*，2023i。

+   Gou 等人 [2023] Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Nan Duan, 和 Weizhu Chen. Critic：大型语言模型可以通过工具交互批评自我纠正。*arXiv 预印本 arXiv:2305.11738*, 2023。

+   Zhang 等人 [2024c] Tianjun Zhang, Shishir G Patil, Naman Jain, Sheng Shen, Matei Zaharia, Ion Stoica, 和 Joseph E Gonzalez. Raft：将语言模型适应于特定领域的 RAG。*arXiv 预印本 arXiv:2403.10131*, 2024c。

+   Kumar 等人 [2022] Sachin Kumar, Biswajit Paria, 和 Yulia Tsvetkov. 基于梯度的语言模型约束采样。在 *2022年自然语言处理实证方法会议录*, 页2251–2277, 2022。

+   Miao 等人 [2019] Ning Miao, Hao Zhou, Lili Mou, Rui Yan, 和 Lei Li. CGMH：通过 Metropolis-Hastings 采样的约束句子生成。在 *人工智能会议 AAAI 会议录*, 第33卷, 页6834–6842, 2019。

+   Li 等人 [2023g] Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang Lou, 和 Weizhu Chen. 使用步进感知验证器使语言模型成为更好的推理者。在 *第61届计算语言学协会年会论文集（第一卷：长篇论文）*，2023g。

+   Weng 等人 [2023] Yixuan Weng, Minjun Zhu, Fei Xia, Bin Li, Shizhu He, Shengping Liu, Bin Sun, Kang Liu, 和 Jun Zhao. 大型语言模型通过自我验证成为更好的推理者。在 *计算语言学协会会议：EMNLP 2023 发现*, 2023。

+   Danilevsky 等人 [2020] Marina Danilevsky, Kun Qian, Ranit Aharonov, Yannis Katsis, Ban Kawas, 和 Prithviraj Sen. 自然语言处理的可解释人工智能现状调查。*arXiv 预印本 arXiv:2010.00711*, 2020。

+   Zhao 等人 [2023e] Haiyan Zhao, Hanjie Chen, Fan Yang, Ninghao Liu, Huiqi Deng, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, 和 Mengnan Du. 大型语言模型的可解释性：一项调查。*arXiv 预印本 arXiv:2309.01029*, 2023e。

+   Wiegreffe 和 Marasović [2021] Sarah Wiegreffe 和 Ana Marasović. 教我如何解释：可解释自然语言处理数据集的回顾。*arXiv 预印本 arXiv:2102.12060*, 2021。

+   Carton 等人 [2022] Samuel Carton, Surya Kanoria, 和 Chenhao Tan. 学什么，以及如何学习：朝着从合理化中有效学习迈进。在 *计算语言学协会会议：ACL 2022 发现*, 2022。

+   Gurrapu 等人 [2023] Sai Gurrapu, Ajay Kulkarni, Lifu Huang, Ismini Lourentzou, 和 Feras A Batarseh. 可解释 NLP 的合理化：一项调查。*人工智能前沿*, 6, 2023。

+   Wang 等人 [2022c] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, 和 Denny Zhou. 自我一致性改善语言模型中的思维链推理。*arXiv 预印本 arXiv:2203.11171*, 2022c。

+   Sun 等人 [2023d] 纪硕 Sun, Yi Luo, Yeyun Gong, 陈琳, 叶龙 Shen, 关健, 和段楠. 通过迭代自举法增强大语言模型的链式思维提示. *arXiv 预印本 arXiv:2304.11657*, 2023d.

+   Halawi 等人 [2023] Danny Halawi, Jean-Stanislas Denain, 和 Jacob Steinhardt. 过度思考真相：理解语言模型如何处理错误示范. *arXiv 预印本 arXiv:2307.09476*, 2023.

+   Li 等人 [2023h] Kenneth Li, Oam Patel, Fernanda Viégas, Hanspeter Pfister, 和 Martin Wattenberg. 推理时干预：从语言模型中引导真实回答. *arXiv 预印本 arXiv:2306.03341*, 2023h.

+   van der Poel 等人 [2022] Liam van der Poel, Ryan Cotterell, 和 Clara Meister. 互信息缓解抽象摘要中的幻觉. *arXiv 预印本 arXiv:2210.13210*, 2022.
