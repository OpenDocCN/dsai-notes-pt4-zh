- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:44:52'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:44:52
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'MobileAgentBench: An Efficient and User-Friendly Benchmark for Mobile LLM Agents'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MobileAgentBench：一个高效且用户友好的移动LLM代理基准
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.08184](https://ar5iv.labs.arxiv.org/html/2406.08184)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2406.08184](https://ar5iv.labs.arxiv.org/html/2406.08184)
- en: Luyuan Wang
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 吕源旺
- en: Carnegie Mellon University &Yongyu Deng
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 卡内基梅隆大学 & 邓永瑜
- en: University of Michigan &Yiwei Zha
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 密歇根大学 & 赵毅伟
- en: Northeastern University &Guodong Mao
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 东北大学 & 毛国栋
- en: Northeastern University &Qinmin Wang
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 东北大学 & 王沁敏
- en: Carnegie Mellon University
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 卡内基梅隆大学
- en: '&Tianchen Min'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '& 田晨敏'
- en: Northeastern University &Wei Chen
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 东北大学 & 陈伟
- en: Carnegie Mellon University &Shoufa Chen
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 卡内基梅隆大学 & 邵发辰
- en: The University of Hong Kong
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 香港大学
- en: Abstract
  id: totrans-16
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Large language model (LLM)-based mobile agents are increasingly popular due
    to their capability to interact directly with mobile phone Graphic User Interfaces
    (GUIs) and their potential to autonomously manage daily tasks. Despite their promising
    prospects in both academic and industrial sectors, little research has focused
    on benchmarking the performance of existing mobile agents, due to the inexhaustible
    states of apps and the vague definition of feasible action sequences. To address
    this challenge, we propose an efficient and user-friendly benchmark, MobileAgentBench,
    designed to alleviate the burden of extensive manual testing. We initially define
    100 tasks across 10 open-source apps, categorized by multiple levels of difficulty.
    Subsequently, we evaluate several existing mobile agents, including AppAgent and
    MobileAgent, to thoroughly and systematically compare their performance. All materials
    are accessible on our project webpage: [https://MobileAgentBench.github.io](https://MobileAgentBench.github.io),
    contributing to the advancement of both academic and industrial fields.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 基于大规模语言模型 (LLM) 的移动代理因其能够直接与手机图形用户界面 (GUIs) 互动以及能够自主管理日常任务而越来越受欢迎。尽管它们在学术界和工业界的前景看好，但由于应用状态的无限多样性和可行操作序列的模糊定义，现有移动代理的性能基准研究较少。为了解决这个挑战，我们提出了一个高效且用户友好的基准，MobileAgentBench，旨在减轻繁琐的手动测试负担。我们首先定义了100个任务，涵盖10个开源应用，按多个难度等级分类。随后，我们评估了包括AppAgent和MobileAgent在内的几个现有移动代理，彻底而系统地比较它们的性能。所有材料均可在我们的项目网页上获取：[https://MobileAgentBench.github.io](https://MobileAgentBench.github.io)，为学术界和工业界的发展做出贡献。
- en: 1 Introduction
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: With the emergence of large language models (LLMs) [[1](#bib.bib1)], researchers
    have developed various autonomous agents across fields such as robotics [[4](#bib.bib4),
    [20](#bib.bib20)], games [[22](#bib.bib22), [8](#bib.bib8)], and mobile phones [[26](#bib.bib26),
    [19](#bib.bib19)]. Among these, mobile agents have attracted significant attention
    due to their potential to enhance user experiences and provide intelligent assistance
    on-the-go.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大规模语言模型 (LLMs) 的出现 [[1](#bib.bib1)]，研究人员在机器人 [[4](#bib.bib4), [20](#bib.bib20)]、游戏
    [[22](#bib.bib22), [8](#bib.bib8)] 和手机 [[26](#bib.bib26), [19](#bib.bib19)] 等领域开发了各种自主代理。其中，移动代理因其能够提升用户体验和提供智能随时随地的帮助而受到广泛关注。
- en: People have been dreaming of Intelligent Personal Assistants (IPAs) [[6](#bib.bib6)]
    that can fully automate daily tasks for decades. Since Apple introduced its digital
    assistant, Siri [[3](#bib.bib3)] in 2011, almost all the leading technology companies
    have launched their own IPAs, including Microsoft Cortana [[15](#bib.bib15)],
    Amazon Alexa [[2](#bib.bib2)], and Google Assistant [[9](#bib.bib9)]. While these
    digital assistants provide a hands-free human-computer interaction experience
    using Natural Language Interface (NLI), they can only fulfill relatively simple
    tasks, such as setting an alarm clock or sending a text message [[13](#bib.bib13)].
    For third-party apps, developers have to follow and implement the application
    programming interfaces and protocols, such that when a user issues a very specific
    command, the system can invoke the corresponding functionality. This limits the
    usability of those digital assistants.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 人们数十年来一直梦想着能够完全自动化日常任务的智能个人助手 (IPAs) [[6](#bib.bib6)]。自从苹果在2011年推出其数字助手Siri
    [[3](#bib.bib3)]以来，几乎所有领先的科技公司都推出了自己的IPAs，包括微软Cortana [[15](#bib.bib15)]、亚马逊Alexa
    [[2](#bib.bib2)]和谷歌助手 [[9](#bib.bib9)]。尽管这些数字助手通过自然语言界面 (NLI) 提供了免提的人机交互体验，但它们只能完成相对简单的任务，如设置闹钟或发送短信
    [[13](#bib.bib13)]。对于第三方应用，开发者必须遵循并实现应用程序接口和协议，以便当用户发出非常具体的命令时，系统可以调用相应的功能。这限制了这些数字助手的可用性。
- en: 'Table 1: Comparison between the proposed and existing benchmarks'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '表 1: 提议的基准与现有基准的比较'
- en: '| Benchmark | Fully Autonomous | Realistic Environment | Success Condition
    Flexibility | Low Code Invasiveness |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| 基准 | 完全自主 | 真实环境 | 成功条件灵活性 | 低代码侵入性 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| AppAgent [[26](#bib.bib26)] | ✗ | ✓ | ✓ | ✓ |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| AppAgent [[26](#bib.bib26)] | ✗ | ✓ | ✓ | ✓ |'
- en: '| AITW [[19](#bib.bib19)] | ✓ | ✗ | ✗ | ✗ |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| AITW [[19](#bib.bib19)] | ✓ | ✗ | ✗ | ✗ |'
- en: '| AndroidArena [[24](#bib.bib24)] | ✓ | ✓ | ✗ | ✗ |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| AndroidArena [[24](#bib.bib24)] | ✓ | ✓ | ✗ | ✗ |'
- en: '| MobileAgentBench (ours) | ✓ | ✓ | ✓ | ✓ |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| MobileAgentBench（我们的） | ✓ | ✓ | ✓ | ✓ |'
- en: LLMs contribute significantly to resolving the persistent challenge of understanding
    user intent. The demonstrated reasoning ability [[17](#bib.bib17)] highlights
    the potential of LLM-based autonomous agents as next-generation Intelligent Personal
    Assistants (IPAs), which are not limited by the programming interfaces since they
    directly operate on the Graphic User Interface (GUI) [[21](#bib.bib21), [26](#bib.bib26)].
    The GUI can either be represented by a text-based view tree to be consumed by
    a LLM or a screenshot image that can leverage a Multi-modal LLM (MLLM) [[27](#bib.bib27)].
    The action space of the agents composes a series of functions to simulate human
    operations, such as click, type, swipe, etc. In this way, LLM agents can theoretically
    achieve whatever human users can do, without any modification of the existing
    apps.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型 (LLMs) 对解决理解用户意图这一持久挑战做出了重要贡献。所展示的推理能力 [[17](#bib.bib17)] 突显了基于LLM的自主代理作为下一代智能个人助手
    (IPAs) 的潜力，这些助手不受编程接口的限制，因为它们直接操作图形用户界面 (GUI) [[21](#bib.bib21), [26](#bib.bib26)]。GUI
    可以通过LLM消费的文本视图树或利用多模态LLM (MLLM) [[27](#bib.bib27)] 的屏幕截图图像来表示。代理的动作空间包含一系列模拟人类操作的功能，如点击、输入、滑动等。通过这种方式，LLM代理理论上可以实现任何人类用户能够做的事情，无需对现有应用进行任何修改。
- en: 'The promising future of LLM-based smartphone agents attracts more and more
    researchers to study this topic. However, the scope of benchmarks available for
    evaluating the performance of these agents remains constrained. Among the existing
    benchmarks, several prevalent issues are evident: 1\. Scalability and usability.
    Researchers need to fully understand complicated data structures and tools before
    extending the benchmark with customized tasks or integrating it into their own
    codebases [[28](#bib.bib28)]. 2\. Robustness and Flexibility. Only the annotated
    task completion path is considered [[19](#bib.bib19), [24](#bib.bib24)]. However,
    there might be multiple paths to successfully complete a task, which may break
    the task success judgment logic. 3\. Realistic environment. Some benchmarks evaluate
    the agent’s performance based on a collection of screenshots but not real devices.
    It fails if the agent performs an abnormal action and goes to an undefined state [[19](#bib.bib19)].'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLM的智能手机代理的广阔前景吸引了越来越多的研究人员关注这一课题。然而，用于评估这些代理性能的基准测试工具的范围仍然有限。在现有基准测试工具中，存在几个显著问题：1\.
    可扩展性和可用性。研究人员在扩展基准测试工具以包含自定义任务或将其集成到自己的代码库之前，需要充分理解复杂的数据结构和工具[[28](#bib.bib28)]。2\.
    鲁棒性和灵活性。只有标注的任务完成路径被考虑[[19](#bib.bib19), [24](#bib.bib24)]。然而，可能存在多条路径能够成功完成任务，这可能会破坏任务成功判断逻辑。3\.
    真实环境。一些基准测试工具基于一系列截图而非真实设备来评估代理的性能。如果代理执行了异常操作并进入了未定义状态，则会失败[[19](#bib.bib19)]。
- en: To address the issues described, we propose a robust benchmark, MobileAgentBench,
    designed to evaluate the capabilities of mobile LLM agents within the Android
    ecosystem. MobileAgentBench offers several advantages over previous benchmarks
    due to its ease of use and minimally invasive nature. Specifically, for standard
    agents, the integration process requires fewer than ten lines of additional code.
    The benchmark excels in usability and versatility, supporting a broad spectrum
    of testing tasks across various Android operating system versions and executing
    on actual devices.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对上述问题，我们提出了一个强大的基准测试工具——MobileAgentBench，旨在评估Android生态系统内移动LLM代理的能力。MobileAgentBench相较于以往的基准测试工具具有几个优势，主要体现在其易用性和最小侵入性。具体而言，对于标准代理，集成过程只需少于十行额外代码。该基准测试工具在可用性和多功能性方面表现出色，支持各种Android操作系统版本的广泛测试任务，并能够在实际设备上执行。
- en: In this initial release, we offer 100 built-in benchmarking tasks spanning ten
    open-source applications. Notably, MobileAgentBench diverges from traditional
    approaches by simplifying the extension process. Third-party developers can specify
    the conditions for task success using just a few lines of Python code, without
    needing extensive knowledge in Android development. This accessibility makes MobileAgentBench
    more conducive to developers and researchers from non-Android Development communities.
    Furthermore, we introduce an innovative method for determining the task-terminating
    state, rendering the benchmark resistant to the complexities of tracking multiple
    potential success pathways. This approach ensures that MobileAgentBench provides
    reliable and precise benchmarking outcomes.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一初始版本中，我们提供了100个内置的基准测试任务，涵盖了十个开源应用程序。值得注意的是，MobileAgentBench通过简化扩展过程而与传统方法有所不同。第三方开发者可以仅通过几行Python代码来指定任务成功的条件，而无需深入了解Android开发。这种易用性使MobileAgentBench更适合来自非Android开发社区的开发者和研究人员。此外，我们引入了一种创新的方法来确定任务终止状态，使基准测试工具能够抵抗跟踪多个潜在成功路径的复杂性。这一方法确保了MobileAgentBench提供可靠且准确的基准测试结果。
- en: 'The comparison between the proposed and existing benchmarks is listed in Tab. [1](#S1.T1
    "Table 1 ‣ 1 Introduction ‣ MobileAgentBench: An Efficient and User-Friendly Benchmark
    for Mobile LLM Agents"), where fully autonomous represents if the benchmark does
    not need human supervision or judgment, realistic environment represents the tasks
    can be run on real devices, success condition flexibility represents it takes
    all possible success paths into consideration, low code invasiveness represents
    integrating the benchmark into existing agents does not need significant code
    changes.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '提出的基准测试工具与现有基准测试工具的比较列在表格 [1](#S1.T1 "Table 1 ‣ 1 Introduction ‣ MobileAgentBench:
    An Efficient and User-Friendly Benchmark for Mobile LLM Agents")中，其中“完全自主”表示基准测试工具不需要人工监督或判断，“真实环境”表示任务可以在真实设备上运行，“成功条件灵活性”表示考虑了所有可能的成功路径，“低代码侵入性”表示将基准测试工具集成到现有代理中不需要大量代码修改。'
- en: 'Our contributions are summarized as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的贡献总结如下：
- en: •
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We propose a benchmark framework for mobile LLM agents. The new approach addresses
    common issues of existing benchmarks, making the evaluation process fully autonomous
    and reliable.
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了一个针对移动LLM代理的基准框架。该新方法解决了现有基准的常见问题，使评估过程完全自主且可靠。
- en: •
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We implement and test 100 benchmarking tasks with different levels of difficulty.
    The benchmark is plug-and-play and easy for both developing new agents and evaluating
    existing agents.
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们实现并测试了100个不同难度的基准任务。该基准具有即插即用的特性，便于开发新的代理和评估现有代理。
- en: •
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We evaluate the performance of state-of-the-art mobile LLM agents and perform
    a solid and systematic comparison with our new benchmark, providing baseline data
    to the community.
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们评估了最先进的移动LLM代理的性能，并与我们的新基准进行了全面系统的比较，为社区提供了基线数据。
- en: 2 Related Work
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: 2.1 Mobile LLM Agents
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 移动LLM代理
- en: Studies before the LLM-era employed reinforcement learning (RL) to solve the
    autonomous GUI navigation problem [[10](#bib.bib10)]. The recent advancement of
    LLM and MLLM becomes the dominant agent paradigm becaust of the greater ability
    of UI understanding and reasoning. Early studies focused on web agents, which
    achieve task automation within browsers [[7](#bib.bib7), [29](#bib.bib29)]. Recently,
    more and more studies started to investigate agents on mobile devices, especially
    on the Android platform, as Android smartphones are the most widely used personal
    computing devices.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLM时代之前的研究中，采用了强化学习（RL）来解决自主GUI导航问题[[10](#bib.bib10)]。由于对UI理解和推理能力的提升，最近LLM和MLLM的进展成为了主流的代理模式。早期的研究集中在网页代理，这些代理在浏览器中实现了任务自动化[[7](#bib.bib7),
    [29](#bib.bib29)]。最近，越来越多的研究开始调查移动设备上的代理，特别是在Android平台上，因为Android智能手机是最广泛使用的个人计算设备。
- en: 'Mobile LLM agents share a similar algorithm. The full input prompt often consists
    of four main components: the user prompt (task description), the current UI view
    hierarchy (VH) description, the action function list, and historical information.
    Specifically, the action list mainly includes click, swipe, type, and other common
    UI operations. If MLLM is used, the current screenshot is also a part of the input.
    The LLM/MLLM is asked to think of the next action based on the current and historical
    states and call the correct function to perform the given task step by step. The
    agent finally parses the model response and sends control signals to the Android
    device using Android Debug Bridge (ADB) ¹¹1https://developer.android.com/tools/adb,
    UIAutomator ²²2https://developer.android.com/training/testing/other-components/ui-automator,
    or other higher-level UI automation frameworks.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 移动LLM代理共享类似的算法。完整的输入提示通常包括四个主要组件：用户提示（任务描述）、当前UI视图层次结构（VH）描述、动作函数列表和历史信息。具体而言，动作列表主要包括点击、滑动、输入和其他常见的UI操作。如果使用MLLM，则当前的屏幕截图也是输入的一部分。LLM/MLLM会根据当前和历史状态考虑下一步操作，并调用正确的函数逐步执行给定任务。代理最终解析模型响应，并使用Android
    Debug Bridge（ADB）¹¹1https://developer.android.com/tools/adb、UIAutomator ²²2https://developer.android.com/training/testing/other-components/ui-automator或其他更高级的UI自动化框架向Android设备发送控制信号。
- en: Despite the similarity of the high-level ideas, researchers have developed different
    techniques to improve performance and efficiency. Among these works, AndroidArena [[24](#bib.bib24)]
    transforms the long and overwhelming view hierarchy XML into a compressed representation
    and assigned UI elements with unique node IDs, which shortens the prompt and makes
    the system more efficient. MobileAgent [[21](#bib.bib21)] observes that GPT-4V
    lacks the capability of UI element localization, and employs an Optical Character
    Recognition (OCR) model to locate and localize text views. Moreover, it uses the
    CLIP [[18](#bib.bib18)] and Grounding DINO [[14](#bib.bib14)] models to detect
    icons. AppAgent [[26](#bib.bib26)] uses SoM [[25](#bib.bib25)] prompts to localize
    UI elements and breaks tasks into two phases, exploration, and deployment. During
    the exploration phase, the agent automatically interacts with the apps and summarizes
    the observations into a document. In the deployment phase, it employes the Retrieval
    Augmented Generation (RAG) [[12](#bib.bib12)] technique to utilize the summarized
    knowledge and improve success rate. CogAgent [[11](#bib.bib11)] proposes its own
    highly efficient 18B-parameter MLLM, which can be loaded on a single commercial
    GPU. Furthermore, Octopus v2 [[5](#bib.bib5)] proposes a compact 3B-parameter
    model, which unlocks the potential to run mobile LLM agents on-device in an efficient
    and privacy-preserving manner.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管高级理念相似，研究人员还是开发了不同的技术来提高性能和效率。在这些工作中，AndroidArena [[24](#bib.bib24)] 将冗长且繁杂的视图层次
    XML 转换为压缩表示，并为 UI 元素分配了唯一的节点 ID，这缩短了提示并提高了系统效率。MobileAgent [[21](#bib.bib21)]
    观察到 GPT-4V 缺乏 UI 元素定位能力，采用光学字符识别（OCR）模型来定位和定位文本视图。此外，它使用 CLIP [[18](#bib.bib18)]
    和 Grounding DINO [[14](#bib.bib14)] 模型来检测图标。AppAgent [[26](#bib.bib26)] 使用 SoM
    [[25](#bib.bib25)] 提示来定位 UI 元素，并将任务分为两个阶段，探索和部署。在探索阶段，代理自动与应用程序交互，并将观察结果总结成文档。在部署阶段，它采用检索增强生成（RAG）[[12](#bib.bib12)]
    技术来利用总结的知识，提高成功率。CogAgent [[11](#bib.bib11)] 提出了自己的高效 18B 参数 MLLM，可以在单个商业 GPU
    上加载。此外，Octopus v2 [[5](#bib.bib5)] 提出了一个紧凑的 3B 参数模型，释放了在设备上高效且隐私保护地运行移动 LLM 代理的潜力。
- en: 2.2 Benchmarks for Mobile LLM Agents
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 移动 LLM 代理的基准测试
- en: Since the Mobile LLM agent is a newly emerging research field, the choice of
    benchmarks is very limited. Some studies rely on verifying the task execution
    status manually to evaluate the performance [[26](#bib.bib26)], which is tedious
    and time-consuming. To expedite the agent development, we need a fully autonomous
    benchmarking system to report various metrics, especially the task success rate.
    However, automatically judging if a task is completed successfully is non-trivial.
    The main challenge is caused by the dynamic nature of the GUI navigation task
    – the agent may perform random actions and drive the app to an unknown state.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 由于移动 LLM 代理是一个新兴的研究领域，基准测试的选择非常有限。一些研究依赖手动验证任务执行状态来评估性能 [[26](#bib.bib26)]，这既乏味又耗时。为了加快代理开发，我们需要一个完全自主的基准测试系统来报告各种指标，特别是任务成功率。然而，自动判断任务是否成功完成并非易事。主要挑战在于
    GUI 导航任务的动态特性——代理可能执行随机操作，使应用进入未知状态。
- en: AITW [[19](#bib.bib19)] is a popular benchmark for mobile LLM agents. It has
    a large scale, but it’s based on static screenshot images. Thinking of each app
    state (screenshot) as a node, and each action as an edge, we can build a State
    Transferring Graph (STG) based on the screenshots and the human-annotated actions.
    It fails immediately if the agent performs actions in a non-considered sequence
    and leads the STG to a non-existent node, even if the agent can eventually complete
    the task.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: AITW [[19](#bib.bib19)] 是一个流行的移动 LLM 代理基准测试。它规模较大，但基于静态截图图像。将每个应用状态（截图）视为一个节点，每个操作视为一条边，我们可以基于截图和人工标注的操作构建状态转移图（STG）。如果代理以非预期的顺序执行操作，导致
    STG 导向一个不存在的节点，即使代理最终能完成任务，也会立即失败。
- en: The only solution is to identify task successes on real devices. One approach
    is to match the agent’s actions with the annotated ground truth (GT). A step-wise
    matching algorithm is not accurate, because the agent may not finish the task
    exactly in the same order with GT. AndroidArena [[24](#bib.bib24)] proposes an
    adaptive method of calculating the longest common subsequence of the agent and
    GT action sequences, which is illustrated as follows, where $a$ are the GT and
    actual actions, respectively. The common subsequences are marked in red.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的解决方案是通过实际设备识别任务成功。一个方法是将代理的动作与标注的真实值 (GT) 进行匹配。逐步匹配算法不准确，因为代理可能不会完全按 GT 的顺序完成任务。AndroidArena
    [[24](#bib.bib24)] 提出了计算代理和 GT 动作序列的最长公共子序列的自适应方法，具体如下，其中 $a$ 分别为 GT 和实际动作。公共子序列以红色标记。
- en: '|  | $\displaystyle a$ |  | (1) |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle a$ |  | (1) |'
- en: '|  | $\displaystyle\hat{a}$ |  | (2) |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\hat{a}$ |  | (2) |'
- en: 'AndroidArena [[24](#bib.bib24)] treats a task as successful if the GT is a
    subsequence of the actual action sequence. It addresses the issue of redundant
    actions but is still not optimal. A simple counter-example can be navigating from
    the page 1 to page 3 by clicking the next page button two times. If the agent
    performs the following sequence of actions: clicking the next page button, clicking
    the previous page button, and clicking the next page button, it doesn’t navigate
    to the correct page but is still a subsequence of the GT. This method gives false
    positive results if the redundant action has a side effect.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: AndroidArena [[24](#bib.bib24)] 将任务视为成功，如果 GT 是实际动作序列的一个子序列。它解决了冗余动作的问题，但仍然不是最优的。一个简单的反例是，通过点击下一页按钮两次从第
    1 页导航到第 3 页。如果代理执行以下动作序列：点击下一页按钮、点击上一页按钮，然后点击下一页按钮，它不会导航到正确的页面，但仍然是 GT 的一个子序列。如果冗余动作有副作用，这种方法会给出假阳性结果。
- en: A concurrent work, LlamaTouch [[28](#bib.bib28)], addresses this problem by
    examining the final UI state, which is similar to our approach. We observe that
    despite the infinite feasible action sequences, the final success state convergence
    to one. The success or failure can be determined by checking the final UI state.
    An edge case is that some tasks may not have a direct UI representation, for example,
    the result of a network request triggered by a button may not be directly reflected
    on the current UI page. Thus, only checking the UI state is not sufficient and
    we need to incorporate actions, such as the clicking event, into consideration.
    LlamaTouch [[28](#bib.bib28)] matches the click action by mapping the coordinate
    to a UI element, based on the view bounding boxes. However, it may not always
    be accurate. The process of finding the correct view to respond to a clicking
    event is called a hit test, and it’s only accurate if performed by the Android
    UI system. This is because app developers can modify the touchable area, making
    it different from the view border to get better user experience.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 一项并行的工作，LlamaTouch [[28](#bib.bib28)]，通过检查最终的 UI 状态来解决这个问题，这与我们的方法类似。我们观察到尽管有无限的可行动作序列，但最终的成功状态收敛为一个。通过检查最终的
    UI 状态可以确定成功或失败。一个边缘案例是某些任务可能没有直接的 UI 表示，例如，通过按钮触发的网络请求的结果可能不会直接反映在当前的 UI 页面上。因此，仅检查
    UI 状态是不够的，我们需要将点击事件等动作纳入考虑。LlamaTouch [[28](#bib.bib28)] 通过将坐标映射到 UI 元素来匹配点击动作，基于视图边界框。然而，它可能并不总是准确的。找到正确视图以响应点击事件的过程称为命中测试，只有在
    Android UI 系统执行时才准确。这是因为应用程序开发者可以修改可触区域，使其与视图边界不同，以获得更好的用户体验。
- en: '![Refer to caption](img/f5cdba36afec0a32932f570a56ee40ce.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/f5cdba36afec0a32932f570a56ee40ce.png)'
- en: 'Figure 1: Extended touchable area.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：扩展的可触区域。
- en: 'Fig. [1](#S2.F1 "Figure 1 ‣ 2.2 Benchmarks for Mobile LLM Agents ‣ 2 Related
    Work ‣ MobileAgentBench: An Efficient and User-Friendly Benchmark for Mobile LLM
    Agents") shows an example of enlarging the touchable area of a button view. In
    Fig. [1](#S2.F1 "Figure 1 ‣ 2.2 Benchmarks for Mobile LLM Agents ‣ 2 Related Work
    ‣ MobileAgentBench: An Efficient and User-Friendly Benchmark for Mobile LLM Agents"),
    touching point 1, the button does not respond because it’s outside of the touchable
    area. Touching point 2, the button responds because it’s inside the button view.
    Touching point 3, although it’s outside of the visible button view, the button
    still responds because it’s inside the extended touchable area. To overcome this
    difficulty, we utilize the Android Accessibility Service ³³3https://developer.android.com/reference/android/accessibilityservice/AccessibilityService
    to capture app events faithfully and forward them to the benchmark server. The
    details of our implementation are described in Sec. [3.1](#S3.SS1 "3.1 Method
    ‣ 3 MobileAgentBench ‣ MobileAgentBench: An Efficient and User-Friendly Benchmark
    for Mobile LLM Agents").'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '图 [1](#S2.F1 "图 1 ‣ 2.2 移动 LLM 代理的基准 ‣ 2 相关工作 ‣ MobileAgentBench: 一种高效且用户友好的移动
    LLM 代理基准") 显示了一个放大按钮视图的可触摸区域的例子。在图 [1](#S2.F1 "图 1 ‣ 2.2 移动 LLM 代理的基准 ‣ 2 相关工作
    ‣ MobileAgentBench: 一种高效且用户友好的移动 LLM 代理基准") 中，触摸点 1 时，按钮没有响应，因为它在可触摸区域之外。触摸点 2
    时，按钮响应，因为它在按钮视图内。触摸点 3 时，虽然它在可视按钮视图之外，按钮仍然响应，因为它在扩展的可触摸区域内。为了解决这个问题，我们利用 Android
    无障碍服务 [³³3](https://developer.android.com/reference/android/accessibilityservice/AccessibilityService)
    真实捕获应用事件并将其转发到基准服务器。我们实现的细节在第 [3.1](#S3.SS1 "3.1 方法 ‣ 3 MobileAgentBench ‣ MobileAgentBench:
    一种高效且用户友好的移动 LLM 代理基准") 节中描述。'
- en: 3 MobileAgentBench
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 MobileAgentBench
- en: '![Refer to caption](img/5a58bcaaf52f56ebafb41e442b2310a6.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/5a58bcaaf52f56ebafb41e442b2310a6.png)'
- en: 'Figure 2: Overview of the MobileAgentBench architecture.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：MobileAgentBench 架构概述。
- en: 3.1 Method
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 方法
- en: MobileAgentBench runs on real Android devices, supporting both physical devices
    and emulators. It sets up environment and then invokes the agent execution function.
    While the agent is operating the device, MobileAgentBench judges the task success
    status in real time without any side effects. After the agent stops or exceeds
    the maximum steps, MobileAgentBench automatically switches to the next task. The
    whole process is fully automated and requires no human supervision.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: MobileAgentBench 在真实的 Android 设备上运行，支持物理设备和模拟器。它设置环境，然后调用代理执行函数。在代理操作设备的过程中，MobileAgentBench
    实时判断任务成功状态，不会产生任何副作用。在代理停止或超过最大步骤后，MobileAgentBench 会自动切换到下一个任务。整个过程完全自动化，无需人工监督。
- en: The task success judgment mechanism is implemented by matching the final UI
    state, instead of examining the action sequence. This is because there might be
    multiple paths towards task completion, but the final success state converges
    to one. For example, if the task is to go to the settings page, agents may mistakenly
    open random pages before they correctly find the desired settings page. Matching
    the action sequence is difficult because of the randomness. On the contrary, checking
    if the top page is the settings page is easy and reliable. No matter what operations
    the agent does, we treat it as a success as long as the settings page is detected.
    ADB and UIAutomator are used to fetch the VH information. For each task, there
    is a Python file that defines the task success criteria, making it easy to extend
    and customize tasks for third-party developers.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 任务成功判断机制是通过匹配最终的 UI 状态实现的，而不是检查操作序列。这是因为任务完成可能有多条路径，但最终的成功状态会收敛为一个。例如，如果任务是进入设置页面，代理可能会错误地打开随机页面，直到正确找到所需的设置页面。由于随机性，匹配操作序列比较困难。相反，检查顶部页面是否为设置页面则简单可靠。无论代理执行什么操作，只要检测到设置页面，我们就将其视为成功。ADB
    和 UIAutomator 被用来获取 VH 信息。对于每个任务，都有一个 Python 文件定义任务成功标准，便于第三方开发者扩展和自定义任务。
- en: As some tasks may not have a direct reflection on the current UI page, only
    checking the VH information is not sufficient. An example can be editing a note
    and saving the changes. Clicking the save button, the app may only pop up a temporary
    alert to indicate the save action has succeeded and stays on the current page.
    When the benchmark checks the current view state, it doesn’t know if the save
    button is clicked or not. As a benchmark, it cannot go to other pages because
    it may change the app state and affect t he next action of the agent. Since we
    want to determine the task success in real-time to collect how many steps the
    agent takes, it is not feasible to check UI states of other pages after the agent
    stops. Besides, some agents have the problem of not being able to stop gracefully
    even the task is completed. We address this issue by incorporating app events,
    especially button click action signals. For the above-mentioned task, we can use
    the view hierarchy to check if the note is edited correctly, and then mark the
    task as a success if the save button clicking signal is received afterwards.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 由于某些任务可能无法直接反映在当前的 UI 页面上，仅检查 VH 信息是不够的。例如，编辑笔记并保存更改时，点击保存按钮，应用程序可能仅弹出一个临时的警报来指示保存操作已成功，并停留在当前页面。当基准测试检查当前视图状态时，它无法知道保存按钮是否被点击。作为基准测试，它不能转到其他页面，因为这可能会改变应用程序状态并影响代理的下一步操作。由于我们希望实时确定任务成功，以收集代理所采取的步骤数，因此在代理停止后检查其他页面的
    UI 状态是不切实际的。此外，一些代理在任务完成后即使任务已经完成也无法正常停止。我们通过引入应用事件，特别是按钮点击操作信号来解决这个问题。对于上述任务，我们可以使用视图层次结构来检查笔记是否被正确编辑，然后如果随后接收到保存按钮点击信号，则将任务标记为成功。
- en: To faithfully receive the app event signals, we make an Android app using the
    Android Accessibility Service. Android Accessibility Service was originally designed
    to help people with disabilities. It runs in the background and invokes a callback
    function when the Android system fires an accessibility event. Such events include
    most UI state transitions by the user (agent) interactions, such as button clicking,
    window changing, etc, which fulfills the needs of the proposed benchmark.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 为了真实地接收应用事件信号，我们使用 Android 可访问性服务制作了一个 Android 应用程序。Android 可访问性服务最初是为了帮助残障人士而设计的。它在后台运行，并在
    Android 系统触发可访问性事件时调用回调函数。这些事件包括用户（代理）交互中的大多数 UI 状态转换，例如按钮点击、窗口更改等，这满足了所提出基准测试的需求。
- en: 'The overview of MobileAgentBench is shown in Fig. [2](#S3.F2 "Figure 2 ‣ 3
    MobileAgentBench ‣ MobileAgentBench: An Efficient and User-Friendly Benchmark
    for Mobile LLM Agents"). The benchmarking apps run on real devices from a device
    farm, which can either be a physical device or an emulator. The device talks to
    the host machine of the benchmark and the agent via ADB. The benchmark and the
    agent use ADB to retrieve app state information, such as screenshots, view hierarchy,
    and send control signals. The benchmark invokes the agent with the current benchmarking
    task prompt and collects runtime information from the agent, such as the LLM input
    and output. Whenever the event listener app receives an app event, it forwards
    the event to the benchmark server via a socket, so the benchmark can assess the
    task success status using both VH and the actions. At the top of Fig. [2](#S3.F2
    "Figure 2 ‣ 3 MobileAgentBench ‣ MobileAgentBench: An Efficient and User-Friendly
    Benchmark for Mobile LLM Agents"), we show a sample task workflow, “Create a new
    task Laundry” with the Calendar app. The agent needs to perform 4 actions to complete
    the task: clicking the add button, clicking the task button, typing the task name
    “Laundry”, and clicking the save button. The benchmark checks the content of the
    task name input box view and listens to the save button clicking event to determine
    if the task is finished successfully.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: MobileAgentBench的概述如图[2](#S3.F2 "图 2 ‣ 3 MobileAgentBench ‣ MobileAgentBench：一个高效且用户友好的移动LLM代理基准测试")所示。基准测试应用程序在设备农场中的真实设备上运行，这些设备可以是物理设备或模拟器。设备通过ADB与基准测试的主机和代理进行通信。基准测试和代理使用ADB检索应用状态信息，如屏幕截图、视图层次结构，并发送控制信号。基准测试通过当前基准测试任务提示调用代理，并从代理处收集运行时信息，如LLM输入和输出。每当事件监听应用接收到应用事件时，它会通过套接字将事件转发给基准测试服务器，以便基准测试可以使用VH和操作来评估任务成功状态。在图[2](#S3.F2
    "图 2 ‣ 3 MobileAgentBench ‣ MobileAgentBench：一个高效且用户友好的移动LLM代理基准测试")的顶部，我们展示了一个示例任务工作流，“创建一个新任务洗衣”与日历应用程序。代理需要执行4个操作以完成任务：点击添加按钮、点击任务按钮、输入任务名称“洗衣”，以及点击保存按钮。基准测试检查任务名称输入框视图的内容，并监听保存按钮点击事件，以确定任务是否成功完成。
- en: 3.2 Task Description
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 任务描述
- en: 'In our initial version of the benchmark, we implement 100 tasks over 10 daily
    apps. The 10 apps are from SimpleMobileTools ⁴⁴4https://simplemobiletools.com,
    GPL-3.0, an open-source project of Android apps. These apps have simple and straightforward
    user interfaces, without any advertisements or unnecessary permissions, and thus
    are great for benchmarking use cases. The full list of app names is shown in Fig. [3b](#S3.F3.sf2
    "In Figure 3 ‣ 3.2 Task Description ‣ 3 MobileAgentBench ‣ MobileAgentBench: An
    Efficient and User-Friendly Benchmark for Mobile LLM Agents").'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在基准测试的初始版本中，我们实现了100个任务，涵盖10个日常应用程序。这10个应用程序来自SimpleMobileTools ⁴⁴4https://simplemobiletools.com，GPL-3.0，一个开源的Android应用项目。这些应用程序具有简单直接的用户界面，没有任何广告或不必要的权限，因此非常适合基准测试用例。应用程序名称的完整列表如图[3b](#S3.F3.sf2
    "图 3 ‣ 3.2 任务描述 ‣ 3 MobileAgentBench ‣ MobileAgentBench：一个高效且用户友好的移动LLM代理基准测试")所示。
- en: 'We carefully design the benchmarking tasks, so that they can simulate a normal
    user’s daily activity and have multi-level difficulties. The distribution of task
    difficulty levels is shown in Fig. [3](#S3.F3 "Figure 3 ‣ 3.2 Task Description
    ‣ 3 MobileAgentBench ‣ MobileAgentBench: An Efficient and User-Friendly Benchmark
    for Mobile LLM Agents"). Difficulties are defined by the minimum steps to finish
    a task, which is cross-verified by 3 human experts independently. A task would
    be classified as an *easy* task if it can be done within 2 steps, *medium* if
    greater or equal to 3 while less than 6, and otherwise, *hard*.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们精心设计了基准测试任务，使其能够模拟正常用户的日常活动，并具有多级难度。任务难度级别的分布如图[3](#S3.F3 "图 3 ‣ 3.2 任务描述
    ‣ 3 MobileAgentBench ‣ MobileAgentBench：一个高效且用户友好的移动LLM代理基准测试")所示。难度由完成任务所需的最少步骤定义，经过3位人工专家独立交叉验证。如果任务可以在2步内完成，则分类为*简单*任务；如果步骤数大于或等于3但小于6，则为*中等*任务；否则，分类为*困难*任务。
- en: '![Refer to caption](img/e163fe5fe684f76d56cec17d34a791f1.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/e163fe5fe684f76d56cec17d34a791f1.png)'
- en: (a) Distribution over all tasks.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 所有任务的分布。
- en: '![Refer to caption](img/36876bcbc93a31f528c4e77e1f39332a.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/36876bcbc93a31f528c4e77e1f39332a.png)'
- en: (b) Distribution over each app.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 每个应用的分布。
- en: 'Figure 3: The distribution of task difficulty levels.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：任务难度级别的分布。
- en: 3.3 Usage
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 使用情况
- en: 'The benchmark APIs are designed to be user-friendly and as less invasive as
    possible. For a standard agent, it takes less than 10 lines of additional code
    to integrate. List [1](#LST1 "Listing 1 ‣ 3.3 Usage ‣ 3 MobileAgentBench ‣ MobileAgentBench:
    An Efficient and User-Friendly Benchmark for Mobile LLM Agents") shows the pseudo-code
    of the benchmark usage. First, we need to import the benchmark Python library
    and initialize the benchmark orchestrator. Next, the main agent entrance function
    should be defined. It takes and only takes one parameter, the task prompt. The
    agent iteratively performs actions to finish the task. Before and after the agent
    performs one action, the orchestrator functions are called, so information such
    as the time spent and LLM output can be collected. The program starts with the
    orchestrator run function. It calls the agent entrance function with each task
    prompt and automatically switches to the next task after the task finishes. The
    task success status is judged on the fly.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '基准 API 旨在用户友好且尽可能少干扰。对于标准代理，集成所需的额外代码少于10行。列表 [1](#LST1 "Listing 1 ‣ 3.3 Usage
    ‣ 3 MobileAgentBench ‣ MobileAgentBench: An Efficient and User-Friendly Benchmark
    for Mobile LLM Agents") 展示了基准使用的伪代码。首先，我们需要导入基准 Python 库并初始化基准协调器。接下来，需要定义主代理入口函数。该函数只接受一个参数，即任务提示。代理会迭代地执行操作以完成任务。在代理执行一个操作之前和之后，会调用协调器函数，以便收集时间消耗和
    LLM 输出等信息。程序从协调器的运行函数开始。它用每个任务提示调用代理入口函数，并在任务完成后自动切换到下一个任务。任务的成功状态即时判断。'
- en: '1from  mobile_agent_benchmark.task_orchestrator  import  TaskOrchestrator2orchestrator  =  TaskOrchestrator()  #  the  MobileAgentBench  orchestrator3#  the  agent  entrance  function4def  agent_run(task_prompt):5  while  not  done:6  orchestrator.before_one_action()7  #  the  agent  invokes  a  LLM  to  think  about  the  next  action8  action  =  llm_think(task_prompt,  screenshot)9  agent_perform(action)10  orchestrator.after_one_action(action)11orchestrator.run(agent_run)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '1from  mobile_agent_benchmark.task_orchestrator  import  TaskOrchestrator2orchestrator  =  TaskOrchestrator()  #  the  MobileAgentBench  orchestrator3#  the  agent  entrance  function4def  agent_run(task_prompt):5  while  not  done:6  orchestrator.before_one_action()7  #  the  agent  invokes  a  LLM  to  think  about  the  next  action8  action  =  llm_think(task_prompt,  screenshot)9  agent_perform(action)10  orchestrator.after_one_action(action)11orchestrator.run(agent_run)'
- en: 'Listing 1: Pseudo code of integrating MobileAgentBench into an existing Mobile
    LLM Agent.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 1：将 MobileAgentBench 集成到现有移动 LLM 代理中的伪代码。
- en: 4 Experiments and Agent Evaluations
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实验和代理评估
- en: 4.1 Metrics
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 指标
- en: 'We define 6 metrics to comprehensively benchmarking mobile agents:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了6个指标来全面评估移动代理：
- en: •
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Success Rate (SR): ${SR}=N_{success}/M_{tasks}$ is the number of total benchmarking
    tasks. This metric reflects the agent’s ability to correctly finish a task end-to-end.'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 成功率（SR）：${SR}=N_{success}/M_{tasks}$ 是总基准任务数。这个指标反映了代理端到端正确完成任务的能力。
- en: •
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Step-wise Efficiency (SE). $SE=S_{actual}/S_{min}$ is the minimum number of
    steps. This metric tells us if the agent performs unnecessary or redundant actions
    and reflects the efficiency of the agent. Failure tasks are not taken into account.
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 步骤效率（SE）。$SE=S_{actual}/S_{min}$ 是最小步骤数。这个指标告诉我们代理是否执行了不必要或冗余的操作，并反映了代理的效率。失败任务不被考虑在内。
- en: •
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Latency. The average time spent in seconds before and after one action. This
    metric tells us how long a user needs to wait between two actions.
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 延迟。每个操作前后所花费的平均时间（秒）。这个指标告诉我们用户在两个操作之间需要等待多久。
- en: •
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Tokens. The number of LLM input and output tokens. For simplicity, we use the
    GPT-4V (gpt-4-vision-preview) standard [[16](#bib.bib16)] to calculate the number
    of tokens for all models, which gives us a rough estimation of the LLM cost. For
    text, 1 token is 4 characters. For an image, it’s divided into multiple 512$\times$
    512 tiles, and each tile is 170 tokens. 85 base tokens are applied to each image
    as well.
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 代币。LLM 输入和输出代币的数量。为简化起见，我们使用 GPT-4V (gpt-4-vision-preview) 标准 [[16](#bib.bib16)]
    来计算所有模型的代币数量，这为我们提供了 LLM 成本的粗略估计。对于文本，1 个代币为 4 个字符。对于图像，它被划分为多个 512$\times$ 512
    瓷砖，每个瓷砖为 170 个代币。每张图像还应用 85 个基础代币。
- en: •
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: False Negative (FN) Rate. $FN=N_{early}/M_{failure}$ is the total number of
    failure tasks. This metric represents how likely the agent falsely thinks it has
    finished the task and stopped early.
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 假阴性（FN）率。$FN=N_{early}/M_{failure}$ 是失败任务的总数。这个指标表示代理错误地认为任务已经完成并提前停止的可能性。
- en: •
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: False Positive (FP) Rate. $FP=N_{late}/M_{success}$ is the total number of successful
    tasks. Symmetricly to FN Rate, this metric reveals how likely the agent falsely
    thinks the task is not finished successfully.
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 假阳性（FP）率。$FP=N_{late}/M_{success}$是成功任务的总数。与FN率对称，该指标揭示了代理错误认为任务没有成功完成的可能性。
- en: 4.2 Environment Setup
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 环境设置
- en: Five popular mobile LLM agents, AndroidArena [[24](#bib.bib24)], AutoDroid [[23](#bib.bib23)],
    AppAgent [[26](#bib.bib26)], CogAgent [[11](#bib.bib11)], and MobileAgent [[21](#bib.bib21)]
    are evaluated with the proposed benchmark. We choose the Google Pixel 3a emulator
    and Android 14 operating system to run the benchmarking apps. Besides, the Android
    9 operating system is used for AutoDroid as some of the dependency libraries do
    not support the newer Android systems.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 五个流行的移动LLM代理，AndroidArena [[24](#bib.bib24)]、AutoDroid [[23](#bib.bib23)]、AppAgent
    [[26](#bib.bib26)]、CogAgent [[11](#bib.bib11)] 和 MobileAgent [[21](#bib.bib21)]，都通过提出的基准进行了评估。我们选择了Google
    Pixel 3a模拟器和Android 14操作系统来运行基准测试应用。此外，由于某些依赖库不支持更新的Android系统，AutoDroid使用Android
    9操作系统。
- en: As there are no local neural networks used in AndroidArena, AutoDroid, and AppAgents,
    these agents are executed on an Apple Macbook Pro with the M1 Max chip. CogAgent
    and MobileAgent require local model referencing, so they are executed on a workstation
    equipped with a single Nvidia RTX 4090 GPU, with 24 GB GPU memory.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 由于AndroidArena、AutoDroid和AppAgents中没有使用本地神经网络，这些代理在配备M1 Max芯片的Apple Macbook
    Pro上执行。CogAgent和MobileAgent需要本地模型引用，因此它们在配备单个Nvidia RTX 4090 GPU（24 GB GPU内存）的工作站上执行。
- en: The self-exploration feature is turned on for AppAgent. When performing a task,
    it can reference the previously summarized document. For CogAgent, we use 4-bit
    quantization to load the model due to GPU memory limitation. CogAgent is implemented
    in its vanilla flavor, *i.e.*, given the current screenshot, ask for the next
    action. No history information is provided.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 自我探索功能已为AppAgent开启。在执行任务时，它可以参考之前总结的文档。对于CogAgent，由于GPU内存限制，我们使用4位量化来加载模型。CogAgent以其原始版本实现，*即*，根据当前截图，要求下一步操作。不提供历史信息。
- en: 4.3 Results
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 结果
- en: 'Table 2: Agent performance results with multiple metrics'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：多项指标下的Agent性能结果
- en: '| Agent | SR $\uparrow$ |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| Agent | SR $\uparrow$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| AndroidArena [[24](#bib.bib24)] | 0.22 | 1.13 | 18.61 | 750.47 | 0.09 | 0.33
    |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| AndroidArena [[24](#bib.bib24)] | 0.22 | 1.13 | 18.61 | 750.47 | 0.09 | 0.33
    |'
- en: '| AutoDroid [[23](#bib.bib23)] | 0.27 | 3.10 | 4.85 | 963.48 | 0.93 | 0.01
    |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| AutoDroid [[23](#bib.bib23)] | 0.27 | 3.10 | 4.85 | 963.48 | 0.93 | 0.01
    |'
- en: '| AppAgent [[26](#bib.bib26)] | 0.40 | 1.29 | 26.09 | 1505.09 | 0.17 | 0.40
    |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| AppAgent [[26](#bib.bib26)] | 0.40 | 1.29 | 26.09 | 1505.09 | 0.17 | 0.40
    |'
- en: '| CogAgent [[11](#bib.bib11)] | 0.08 | 2.42 | 6.76 | 579.84 | 1.0 | 0.04 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| CogAgent [[11](#bib.bib11)] | 0.08 | 2.42 | 6.76 | 579.84 | 1.0 | 0.04 |'
- en: '| MobileAgent [[21](#bib.bib21)] | 0.26 | 1.33 | 15.91 | 1236.88 | 0.19 | 0.31
    |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| MobileAgent [[21](#bib.bib21)] | 0.26 | 1.33 | 15.91 | 1236.88 | 0.19 | 0.31
    |'
- en: 'The main experiment results are shown in Tab. [2](#S4.T2 "Table 2 ‣ 4.3 Results
    ‣ 4 Experiments and Agent Evaluations ‣ MobileAgentBench: An Efficient and User-Friendly
    Benchmark for Mobile LLM Agents"). We observe that AppAgent has the highest success
    rate, benefiting from the self-exploration mechanism. CogAgent has the lowest
    success rate, most likely caused by the naive agent implementation, which limits
    the usage of history information. Although AutoDroid has a similar success rate
    to MobileAgent, the step-wise efficiency is significantly lower, possibly caused
    by the weaker reasoning capability of the GPT-3.5 model used by AutoDroid. Latency-wise,
    both AutoDroid and CogAgent have very low latency, indicating the high inferencing
    cost with the GPT-4V model. AppAgent needs to look up the app document, thus consuming
    more tokens than others. On the other hand, because of the naive agent implementation
    of CogAgent, it consumes the least number of tokens. AutoDroid and CogAgent have
    very high FN rates, indicating they always stop early when the task is not finished
    yet. AppAgent, although having the highest task success rate, is not good at determining
    the task success task, it cannot stop gracefully after finishing a task and has
    a high FP rate.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 主要实验结果见表[2](#S4.T2 "表 2 ‣ 4.3 结果 ‣ 4 实验和代理评估 ‣ MobileAgentBench：一个高效且用户友好的移动
    LLM 代理基准")。我们观察到 AppAgent 的成功率最高，得益于自我探索机制。CogAgent 的成功率最低，很可能是由于代理实现过于简单，限制了历史信息的使用。尽管
    AutoDroid 的成功率与 MobileAgent 相似，但其逐步效率明显较低，这可能是由于 AutoDroid 使用的 GPT-3.5 模型推理能力较弱。延迟方面，AutoDroid
    和 CogAgent 的延迟非常低，表明使用 GPT-4V 模型的推理成本较高。AppAgent 需要查阅应用文档，因此消耗的令牌比其他代理更多。另一方面，由于
    CogAgent 的代理实现过于简单，它消耗的令牌最少。AutoDroid 和 CogAgent 的假阴性率非常高，表明它们在任务尚未完成时总是过早停止。虽然
    AppAgent 拥有最高的任务成功率，但在确定任务成功方面表现不佳，它无法在完成任务后优雅地停止，并且假阳性率较高。
- en: '![Refer to caption](img/694f1583286fbd853c3990035103120a.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/694f1583286fbd853c3990035103120a.png)'
- en: (a) Task success rate with difficulty levels.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 不同难度级别下的任务成功率。
- en: '![Refer to caption](img/8fbbcaec1246bd80eb1dececfdc4b38e.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/8fbbcaec1246bd80eb1dececfdc4b38e.png)'
- en: (b) Task success rate with LLMs.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 使用 LLM 的任务成功率。
- en: 'Figure 4: Task success rate.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：任务成功率。
- en: 'The task success rates for each agent with difficulty levels are shown in Fig. [4a](#S4.F4.sf1
    "In Figure 4 ‣ 4.3 Results ‣ 4 Experiments and Agent Evaluations ‣ MobileAgentBench:
    An Efficient and User-Friendly Benchmark for Mobile LLM Agents"). From Fig. [4a](#S4.F4.sf1
    "In Figure 4 ‣ 4.3 Results ‣ 4 Experiments and Agent Evaluations ‣ MobileAgentBench:
    An Efficient and User-Friendly Benchmark for Mobile LLM Agents"), we can see most
    agents have higher success rates when handling easier tasks, which is as expected.
    Interestingly, AppAgent has a higher success rate when performing medium-level
    tasks. This is because we set the maximum execution steps as twice the minimum
    steps, which would make the agents have very limited steps to correct their earlier
    steps for easy tasks. For example, an agent can only use 1 additional step to
    correct and finish the task for a 1-step easy task. However, for medium and hard
    tasks, there is significantly more space to correct the previous actions.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 每个代理在不同难度级别下的任务成功率见图[4a](#S4.F4.sf1 "在图 4 ‣ 4.3 结果 ‣ 4 实验和代理评估 ‣ MobileAgentBench：一个高效且用户友好的移动
    LLM 代理基准"). 从图[4a](#S4.F4.sf1 "在图 4 ‣ 4.3 结果 ‣ 4 实验和代理评估 ‣ MobileAgentBench：一个高效且用户友好的移动
    LLM 代理基准")中，我们可以看到大多数代理在处理更简单的任务时具有更高的成功率，这是预期中的结果。有趣的是，AppAgent 在执行中级任务时成功率较高。这是因为我们将最大执行步骤设置为最小步骤的两倍，这会使得代理在处理简单任务时，纠正之前步骤的空间非常有限。例如，对于一个
    1 步的简单任务，代理只能使用 1 个额外的步骤来纠正和完成任务。然而，对于中级和困难任务，纠正先前动作的空间要大得多。
- en: 'Fig. [4b](#S4.F4.sf2 "In Figure 4 ‣ 4.3 Results ‣ 4 Experiments and Agent Evaluations
    ‣ MobileAgentBench: An Efficient and User-Friendly Benchmark for Mobile LLM Agents")
    shows the averaged task success rate over the backbone LLM models. It is interesting
    that AutoDroid, although using a text-based GPT-3.5 model, outperforms some other
    agents that use the more advanced GPT-4V model. This reveals that the textual
    view hierarchy contains the most important information for GUI navigation tasks.
    However, we believe that visual screenshots are helpful for other types of tasks,
    for example, if the task involves recognizing an image on the screen, or if the
    textual view hierarchy is not available.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '图 [4b](#S4.F4.sf2 "在图 4 ‣ 4.3 结果 ‣ 4 实验与代理评估 ‣ MobileAgentBench: 一个高效且用户友好的移动
    LLM 代理基准") 显示了骨干 LLM 模型的平均任务成功率。有趣的是，尽管 AutoDroid 使用的是基于文本的 GPT-3.5 模型，但其表现却超越了一些使用更先进
    GPT-4V 模型的代理。这揭示了文本视图层次包含了进行 GUI 导航任务所需的重要信息。然而，我们认为视觉截图对其他类型的任务是有帮助的，例如，如果任务涉及识别屏幕上的图像，或文本视图层次不可用时。'
- en: 5 Limitations and Future Work
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 局限性与未来工作
- en: While the proposed MobileAgentBench is efficient, user-friendly, and addresses
    many issues of the existing benchmarks for mobile LLM agents, there are two main
    limitations that the authors would like to improve in the future. Firstly, although
    the use of Python code snippets as the configuration of task success conditions
    is easy for researchers in the AI/ML community, it is still difficult for people
    without a technical background. We will explore new methods to automatically build
    the task configuration without writing any code in the future work. Additionally,
    the usage of UIAutomator makes it infeasible to dump the view hierarchy with dynamic
    screen contents. UIAutomator dumps the view hierarchy only if the main thread
    is free. It fails if the app contains persistent animations or videos. Therefore,
    replacing the UIAutomator with other frameworks to retrieve view information would
    be a promising direction.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管所提出的 MobileAgentBench 高效、用户友好，并解决了现有移动 LLM 代理基准的许多问题，但作者希望在未来改进两个主要局限性。首先，尽管使用
    Python 代码片段作为任务成功条件的配置对 AI/ML 社区的研究人员来说很简单，但对没有技术背景的人仍然很困难。我们将探索新的方法，在未来的工作中自动构建任务配置，而无需编写任何代码。此外，UIAutomator
    的使用使得在动态屏幕内容下转储视图层次变得不可行。UIAutomator 仅在主线程空闲时转储视图层次。如果应用包含持久动画或视频，它会失败。因此，替换 UIAutomator
    为其他框架来获取视图信息将是一个有前景的方向。
- en: 6 Conclusion
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: In this paper, we propose a new benchmark, MobileAgentBench, for mobile LLM
    agents on the Android platform. With the 100 built-in benchmarking tasks, researchers
    can test and evaluate existing and new agents automatically on real Android devices.
    Extending the benchmark to support customized tasks is also easy, as only basic
    Python coding skills are needed. Leveraging the Android Accessibility Services
    and only checking the final app state, MobileAgentBench can detect task completion
    status faithfully. We report the evaluation results of 5 popular agents across
    multiple metrics, and they can be used as strong baselines to advance future mobile
    LLM agent development.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们提出了一个新的基准——MobileAgentBench，用于 Android 平台上的移动 LLM 代理。通过 100 个内置基准测试任务，研究人员可以在真实的
    Android 设备上自动测试和评估现有和新的代理。扩展基准以支持自定义任务也很简单，因为只需要基本的 Python 编码技能。利用 Android 辅助功能服务，并仅检查最终的应用状态，MobileAgentBench
    可以忠实地检测任务完成状态。我们报告了 5 个流行代理在多个指标上的评估结果，这些结果可以作为推动未来移动 LLM 代理开发的强大基准。
- en: References
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni
    Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al.
    Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia
    Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat 等.
    Gpt-4 技术报告。arXiv 预印本 arXiv:2303.08774，2023。'
- en: '[2] Amazon. Alexa. [https://alexa.amazon.com](https://alexa.amazon.com), 2014.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Amazon. Alexa. [https://alexa.amazon.com](https://alexa.amazon.com)，2014。'
- en: '[3] Apple. Siri. [https://www.apple.com/siri/](https://www.apple.com/siri/),
    2011.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Apple. Siri. [https://www.apple.com/siri/](https://www.apple.com/siri/)，2011。'
- en: '[4] Konstantinos Bousmalis, Giulia Vezzani, Dushyant Rao, Coline Devin, Alex X
    Lee, Maria Bauza, Todor Davchev, Yuxiang Zhou, Agrim Gupta, Akhil Raju, et al.
    Robocat: A self-improving foundation agent for robotic manipulation. arXiv preprint
    arXiv:2306.11706, 2023.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Konstantinos Bousmalis, Giulia Vezzani, Dushyant Rao, Coline Devin, Alex
    X Lee, Maria Bauza, Todor Davchev, Yuxiang Zhou, Agrim Gupta, Akhil Raju 等。Robocat：一种自我改进的基础智能体用于机器人操作。arXiv
    预印本 arXiv:2306.11706, 2023。'
- en: '[5] Wei Chen and Zhiyuan Li. Octopus v2: On-device language model for super
    agent. arXiv preprint arXiv:2404.01744, 2024.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Wei Chen 和 Zhiyuan Li. Octopus v2：用于超级智能体的设备端语言模型。arXiv 预印本 arXiv:2404.01744,
    2024。'
- en: '[6] Allan de Barcelos Silva, Marcio Miguel Gomes, Cristiano André da Costa,
    Rodrigo da Rosa Righi, Jorge Luis Victoria Barbosa, Gustavo Pessin, Geert De Doncker,
    and Gustavo Federizzi. Intelligent personal assistants: A systematic literature
    review. Expert Systems with Applications, 147:113193, 2020.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Allan de Barcelos Silva, Marcio Miguel Gomes, Cristiano André da Costa,
    Rodrigo da Rosa Righi, Jorge Luis Victoria Barbosa, Gustavo Pessin, Geert De Doncker,
    和 Gustavo Federizzi. 智能个人助手：系统文献综述。应用专家系统, 147:113193, 2020。'
- en: '[7] Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Sam Stevens, Boshi Wang,
    Huan Sun, and Yu Su. Mind2web: Towards a generalist agent for the web. Advances
    in Neural Information Processing Systems, 36, 2024.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Sam Stevens, Boshi Wang,
    Huan Sun, 和 Yu Su. Mind2web：朝向一个通用的网页智能体。神经信息处理系统进展, 36, 2024。'
- en: '[8] Yuqing Du, Olivia Watkins, Zihan Wang, Cédric Colas, Trevor Darrell, Pieter
    Abbeel, Abhishek Gupta, and Jacob Andreas. Guiding pretraining in reinforcement
    learning with large language models. In International Conference on Machine Learning,
    pages 8657–8677\. PMLR, 2023.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Yuqing Du, Olivia Watkins, Zihan Wang, Cédric Colas, Trevor Darrell, Pieter
    Abbeel, Abhishek Gupta, 和 Jacob Andreas. 利用大语言模型引导强化学习中的预训练。国际机器学习大会论文集, 页 8657–8677。PMLR,
    2023。'
- en: '[9] Google. Google assistant. [https://assistant.google.com](https://assistant.google.com),
    2016.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Google. Google Assistant. [https://assistant.google.com](https://assistant.google.com),
    2016。'
- en: '[10] Izzeddin Gur, Ulrich Rueckert, Aleksandra Faust, and Dilek Hakkani-Tur.
    Learning to navigate the web. arXiv preprint arXiv:1812.09195, 2018.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Izzeddin Gur, Ulrich Rueckert, Aleksandra Faust, 和 Dilek Hakkani-Tur.
    学习在网页上导航。arXiv 预印本 arXiv:1812.09195, 2018。'
- en: '[11] Wenyi Hong, Weihan Wang, Qingsong Lv, Jiazheng Xu, Wenmeng Yu, Junhui
    Ji, Yan Wang, Zihan Wang, Yuxiao Dong, Ming Ding, et al. Cogagent: A visual language
    model for gui agents. arXiv preprint arXiv:2312.08914, 2023.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Wenyi Hong, Weihan Wang, Qingsong Lv, Jiazheng Xu, Wenmeng Yu, Junhui
    Ji, Yan Wang, Zihan Wang, Yuxiao Dong, Ming Ding 等。Cogagent：一种用于 GUI 智能体的视觉语言模型。arXiv
    预印本 arXiv:2312.08914, 2023。'
- en: '[12] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir
    Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel,
    et al. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances
    in Neural Information Processing Systems, 33:9459–9474, 2020.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir
    Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel
    等。增强检索生成用于知识密集型 NLP 任务。神经信息处理系统进展, 33:9459–9474, 2020。'
- en: '[13] Yuanchun Li, Hao Wen, Weijun Wang, Xiangyu Li, Yizhen Yuan, Guohong Liu,
    Jiacheng Liu, Wenxing Xu, Xiang Wang, Yi Sun, et al. Personal llm agents: Insights
    and survey about the capability, efficiency and security. arXiv preprint arXiv:2401.05459,
    2024.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Yuanchun Li, Hao Wen, Weijun Wang, Xiangyu Li, Yizhen Yuan, Guohong Liu,
    Jiacheng Liu, Wenxing Xu, Xiang Wang, Yi Sun 等。个人 LLM 智能体：关于能力、效率和安全性的见解与调查。arXiv
    预印本 arXiv:2401.05459, 2024。'
- en: '[14] Shilong Liu, Zhaoyang Zeng, Tianhe Ren, Feng Li, Hao Zhang, Jie Yang,
    Chunyuan Li, Jianwei Yang, Hang Su, Jun Zhu, et al. Grounding dino: Marrying dino
    with grounded pre-training for open-set object detection. arXiv preprint arXiv:2303.05499,
    2023.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Shilong Liu, Zhaoyang Zeng, Tianhe Ren, Feng Li, Hao Zhang, Jie Yang,
    Chunyuan Li, Jianwei Yang, Hang Su, Jun Zhu 等。Grounding DINO：将 DINO 与基础预训练结合用于开放集物体检测。arXiv
    预印本 arXiv:2303.05499, 2023。'
- en: '[15] Microsoft. Cortana. [https://www.microsoft.com/en-us/cortana](https://www.microsoft.com/en-us/cortana),
    2014.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Microsoft. Cortana. [https://www.microsoft.com/en-us/cortana](https://www.microsoft.com/en-us/cortana),
    2014。'
- en: '[16] OpenAI. Gpt token calculation. [https://openai.com/api/pricing/](https://openai.com/api/pricing/).'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] OpenAI. GPT 令牌计算。 [https://openai.com/api/pricing/](https://openai.com/api/pricing/)。'
- en: '[17] Shuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen, Yunzhi Yao, Shumin Deng,
    Chuanqi Tan, Fei Huang, and Huajun Chen. Reasoning with language model prompting:
    A survey. arXiv preprint arXiv:2212.09597, 2022.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Shuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen, Yunzhi Yao, Shumin Deng,
    Chuanqi Tan, Fei Huang, 和 Huajun Chen. 通过语言模型提示进行推理：一项调查。arXiv 预印本 arXiv:2212.09597,
    2022。'
- en: '[18] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
    Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al.
    Learning transferable visual models from natural language supervision. In International
    conference on machine learning, pages 8748–8763\. PMLR, 2021.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
    Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark 等。
    《从自然语言监督中学习可转移的视觉模型》。在国际机器学习会议上，第 8748–8763 页。PMLR, 2021。'
- en: '[19] Christopher Rawles, Alice Li, Daniel Rodriguez, Oriana Riva, and Timothy
    Lillicrap. Android in the wild: A large-scale dataset for android device control.
    arXiv preprint arXiv:2307.10088, 2023.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Christopher Rawles, Alice Li, Daniel Rodriguez, Oriana Riva 和 Timothy
    Lillicrap. 《Android 在野外：一个大规模的安卓设备控制数据集》。arXiv 预印本 arXiv:2307.10088, 2023。'
- en: '[20] Scott Reed, Konrad Zolna, Emilio Parisotto, Sergio Gomez Colmenarejo,
    Alexander Novikov, Gabriel Barth-Maron, Mai Gimenez, Yury Sulsky, Jackie Kay,
    Jost Tobias Springenberg, et al. A generalist agent. arXiv preprint arXiv:2205.06175,
    2022.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Scott Reed, Konrad Zolna, Emilio Parisotto, Sergio Gomez Colmenarejo,
    Alexander Novikov, Gabriel Barth-Maron, Mai Gimenez, Yury Sulsky, Jackie Kay,
    Jost Tobias Springenberg 等。 《通用智能体》。arXiv 预印本 arXiv:2205.06175, 2022。'
- en: '[21] Junyang Wang, Haiyang Xu, Jiabo Ye, Ming Yan, Weizhou Shen, Ji Zhang,
    Fei Huang, and Jitao Sang. Mobile-agent: Autonomous multi-modal mobile device
    agent with visual perception. arXiv preprint arXiv:2401.16158, 2024.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] Junyang Wang, Haiyang Xu, Jiabo Ye, Ming Yan, Weizhou Shen, Ji Zhang,
    Fei Huang 和 Jitao Sang. 《Mobile-agent：具有视觉感知的自主多模态移动设备智能体》。arXiv 预印本 arXiv:2401.16158,
    2024。'
- en: '[22] Zihao Wang, Shaofei Cai, Guanzhou Chen, Anji Liu, Xiaojian Ma, and Yitao
    Liang. Describe, explain, plan and select: Interactive planning with large language
    models enables open-world multi-task agents. arXiv preprint arXiv:2302.01560,
    2023.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Zihao Wang, Shaofei Cai, Guanzhou Chen, Anji Liu, Xiaojian Ma 和 Yitao
    Liang. 《描述、解释、计划和选择：大语言模型的互动规划使开放世界多任务智能体成为可能》。arXiv 预印本 arXiv:2302.01560, 2023。'
- en: '[23] Hao Wen, Yuanchun Li, Guohong Liu, Shanhui Zhao, Tao Yu, Toby Jia-Jun
    Li, Shiqi Jiang, Yunhao Liu, Yaqin Zhang, and Yunxin Liu. Empowering llm to use
    smartphone for intelligent task automation. arXiv preprint arXiv:2308.15272, 2023.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] Hao Wen, Yuanchun Li, Guohong Liu, Shanhui Zhao, Tao Yu, Toby Jia-Jun
    Li, Shiqi Jiang, Yunhao Liu, Yaqin Zhang 和 Yunxin Liu. 《赋能大语言模型使用智能手机进行智能任务自动化》。arXiv
    预印本 arXiv:2308.15272, 2023。'
- en: '[24] Mingzhe Xing, Rongkai Zhang, Hui Xue, Qi Chen, Fan Yang, and Zhen Xiao.
    Understanding the weakness of large language model agents within a complex android
    environment. arXiv preprint arXiv:2402.06596, 2024.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Mingzhe Xing, Rongkai Zhang, Hui Xue, Qi Chen, Fan Yang 和 Zhen Xiao. 《理解大型语言模型智能体在复杂安卓环境中的弱点》。arXiv
    预印本 arXiv:2402.06596, 2024。'
- en: '[25] Jianwei Yang, Hao Zhang, Feng Li, Xueyan Zou, Chunyuan Li, and Jianfeng
    Gao. Set-of-mark prompting unleashes extraordinary visual grounding in gpt-4v.
    arXiv preprint arXiv:2310.11441, 2023.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Jianwei Yang, Hao Zhang, Feng Li, Xueyan Zou, Chunyuan Li 和 Jianfeng Gao.
    《Set-of-mark 提示在 GPT-4V 中释放了非凡的视觉定位能力》。arXiv 预印本 arXiv:2310.11441, 2023。'
- en: '[26] Zhao Yang, Jiaxuan Liu, Yucheng Han, Xin Chen, Zebiao Huang, Bin Fu, and
    Gang Yu. Appagent: Multimodal agents as smartphone users. arXiv preprint arXiv:2312.13771,
    2023.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Zhao Yang, Jiaxuan Liu, Yucheng Han, Xin Chen, Zebiao Huang, Bin Fu 和
    Gang Yu. 《Appagent：作为智能手机用户的多模态智能体》。arXiv 预印本 arXiv:2312.13771, 2023。'
- en: '[27] Shukang Yin, Chaoyou Fu, Sirui Zhao, Ke Li, Xing Sun, Tong Xu, and Enhong
    Chen. A survey on multimodal large language models. arXiv preprint arXiv:2306.13549,
    2023.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Shukang Yin, Chaoyou Fu, Sirui Zhao, Ke Li, Xing Sun, Tong Xu 和 Enhong
    Chen. 《关于多模态大语言模型的调查》。arXiv 预印本 arXiv:2306.13549, 2023。'
- en: '[28] Li Zhang, Shihe Wang, Xianqing Jia, Zhihan Zheng, Yunhe Yan, Longxi Gao,
    Yuanchun Li, and Mengwei Xu. Llamatouch: A faithful and scalable testbed for mobile
    ui automation task evaluation. arXiv preprint arXiv:2404.16054, 2024.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] Li Zhang, Shihe Wang, Xianqing Jia, Zhihan Zheng, Yunhe Yan, Longxi Gao,
    Yuanchun Li 和 Mengwei Xu. 《Llamatouch：一个真实且可扩展的移动 UI 自动化任务评估平台》。arXiv 预印本 arXiv:2404.16054,
    2024。'
- en: '[29] Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar,
    Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, et al. Webarena: A realistic
    web environment for building autonomous agents. arXiv preprint arXiv:2307.13854,
    2023.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar,
    Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon 等。 《Webarena：一个用于构建自主智能体的真实网络环境》。arXiv
    预印本 arXiv:2307.13854, 2023。'
