- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 18:49:41'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-09-08 18:49:41'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining
    Predictive Agent Reasoning and Critical Agent Instruction'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于LLMs的少样本疾病预测：一种结合预测代理推理和批评代理指导的新方法
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2403.15464](https://ar5iv.labs.arxiv.org/html/2403.15464)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2403.15464](https://ar5iv.labs.arxiv.org/html/2403.15464)
- en: \institutes
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \institutes
- en: ¹ Department of Computer Science, Emory University, Atlanta, GA
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ¹ 埃默里大学计算机科学系，美国乔治亚州亚特兰大
- en: ² School of Computer Science & Engineering, University of Washington, Seattle,
    WA
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ² 华盛顿大学计算机科学与工程学院，美国华盛顿州西雅图
- en: ³ Department of Computer Science & Engineering, UCSD, San Diego, CA
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ³ 加州大学圣迭戈分校计算机科学与工程系，美国加利福尼亚州圣迭戈
- en: ⁴ Rollins School of Public Health, Emory University, Atlanta, GA
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ⁴ 埃默里大学罗林斯公共卫生学院，美国乔治亚州亚特兰大
- en: ⁵ School of Medicine, Emory University, Atlanta, GA
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ⁵ 埃默里大学医学院，美国乔治亚州亚特兰大
- en: Hejie Cui¹    Zhuocheng Shen¹    Jieyu Zhang²    Hui Shao    MD    PhD^(4,5)
       Lianhui Qin    PhD³    Joyce C. Ho    PhD¹    Carl Yang    PhD^(1,4)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Hejie Cui¹    Zhuocheng Shen¹    Jieyu Zhang²    Hui Shao    MD    PhD^(4,5)
       Lianhui Qin    PhD³    Joyce C. Ho    PhD¹    Carl Yang    PhD^(1,4)
- en: Abstract
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Abstract
- en: 'Electronic health records (EHRs) contain valuable patient data for health-related
    prediction tasks, such as disease prediction. Traditional approaches rely on supervised
    learning methods that require large labeled datasets, which can be expensive and
    challenging to obtain. In this study, we investigate the feasibility of applying
    Large Language Models (LLMs) to convert structured patient visit data (e.g., diagnoses,
    labs, prescriptions) into natural language narratives. We evaluate the zero-shot
    and few-shot performance of LLMs using various EHR-prediction-oriented prompting
    strategies. Furthermore, we propose a novel approach that utilizes LLM agents
    with different roles: a predictor agent that makes predictions and generates reasoning
    processes and a critic agent that analyzes incorrect predictions and provides
    guidance for improving the reasoning of the predictor agent. Our results demonstrate
    that with the proposed approach, LLMs can achieve decent few-shot performance
    compared to traditional supervised learning methods in EHR-based disease predictions,
    suggesting its potential for health-oriented applications.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 电子健康记录（EHRs）包含用于健康相关预测任务（如疾病预测）的宝贵患者数据。传统方法依赖于需要大量标注数据集的监督学习方法，这些数据集既昂贵又难以获得。在这项研究中，我们探讨了应用大型语言模型（LLMs）将结构化的患者访问信息（例如，诊断、实验室检查、处方）转换为自然语言叙述的可行性。我们评估了LLMs在零样本和少样本任务中的表现，采用了多种面向EHR预测的提示策略。此外，我们提出了一种新颖的方法，利用具有不同角色的LLM代理：一个预测代理负责进行预测并生成推理过程，而一个批评代理则分析不正确的预测并提供改进预测代理推理的指导。我们的结果表明，采用这种方法，LLMs在EHR基础的疾病预测中能够实现相对较好的少样本表现，表明其在健康导向应用中的潜力。
- en: Introduction
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Introduction
- en: Large Language Models (LLMs) have emerged as a powerful tool in various domains,
    including healthcare. These models, such as GPT family ^([1](#bib.bib1)) and PaLM ^([2](#bib.bib2)),
    are trained on vast amounts of text data, allowing them to encode extensive knowledge
    across multiple fields. In the medical domain, the ability of LLMs to leverage
    their encoded medical knowledge has been showcased in recent studies ^([3](#bib.bib3);
    [4](#bib.bib4)), with impressive performance on tasks such as medical question
    answering ^([5](#bib.bib5)), clinical text summarization ^([6](#bib.bib6)), and
    clinical decision support ^([7](#bib.bib7)). Certain very large language models
    demonstrate an emerging ability for few-shot learning, where the model can draw
    upon their existing understanding to quickly adapt to new tasks with limited examples ^([8](#bib.bib8);
    [9](#bib.bib9)). This raises the question of whether LLMs can be directly applied
    to perform few-shot disease predictions using Electronic Health Record (EHR) data.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）已成为各个领域中的强大工具，包括医疗保健。这些模型，如GPT系列 ^([1](#bib.bib1)) 和 PaLM ^([2](#bib.bib2))，在大量文本数据上进行训练，使它们能够编码多个领域的广泛知识。在医学领域，LLMs利用其编码的医学知识的能力在近期研究中得到了展示
    ^([3](#bib.bib3); [4](#bib.bib4))，在医学问答 ^([5](#bib.bib5))、临床文本总结 ^([6](#bib.bib6))
    和临床决策支持 ^([7](#bib.bib7)) 等任务中表现出色。一些非常大的语言模型显示出少样本学习的新兴能力，这使得模型能够利用其现有的理解快速适应具有有限示例的新任务
    ^([8](#bib.bib8); [9](#bib.bib9))。这引发了一个问题：LLMs 是否可以直接应用于使用电子健康记录（EHR）数据进行少样本疾病预测。
- en: EHRs contain a wealth of patient data for predictive modeling tasks such as
    disease prediction, readmission risk assessment, and mortality prediction ^([10](#bib.bib10)).
    Existing approaches to EHR-based prediction primarily rely on supervised learning
    methods, including traditional machine learning models, representation learning ^([11](#bib.bib11);
    [12](#bib.bib12); [13](#bib.bib13)), and graph-based models ^([14](#bib.bib14)).
    While effective, these supervised approaches require training on large labeled
    datasets, which can be computationally expensive and challenging to obtain due
    to the high cost and difficulty of acquiring high-quality labeled EHR data ^([15](#bib.bib15)).
    In contrast, the capacity for few-shot learning enables LLMs to adapt to new tasks
    with minimal data, without any finetuning ^([8](#bib.bib8)). This adaptability
    raises the possibility of employing LLMs for few-shot disease prediction using
    EHR, a step forward in making healthcare more precise and efficient ^([16](#bib.bib16)).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 电子健康记录（EHRs）包含大量患者数据，用于预测建模任务，例如疾病预测、再入院风险评估和死亡率预测^([10](#bib.bib10))。现有的EHR预测方法主要依赖于监督学习方法，包括传统的机器学习模型、表示学习^([11](#bib.bib11);
    [12](#bib.bib12); [13](#bib.bib13))和基于图的模型^([14](#bib.bib14))。虽然这些监督方法有效，但它们需要在大量标记数据集上进行训练，这可能是计算上昂贵的，并且由于获取高质量标记EHR数据的高成本和困难，挑战重重^([15](#bib.bib15))。相比之下，少量样本学习的能力使得LLMs可以在没有任何微调的情况下，利用最少的数据适应新任务^([8](#bib.bib8))。这种适应性提高了使用LLMs进行少量样本疾病预测的可能性，这是向使医疗保健更加精确和高效迈进的一步^([16](#bib.bib16))。
- en: 'In this study, we investigate the efficacy of LLMs-based few-shot disease prediction
    using the EHRs generated from clinical encounters that include three types of
    medical codes: disease, medications, and procedures. We convert the structured
    patient visit records into unstructured language narratives by mapping the ICD
    codes to their names and connecting them with proper conjunctives. This conversion
    process allows LLMs to better understand clinical records and retrieve related
    internal knowledge. We assess the zero-shot and few-shot diagnostic performance
    of LLMs using various prompting strategies, such as considering factor interactions
    and providing prevalence statistics and exemplars. The results of this evaluation
    provide insights into the potential of LLMs as a tool for EHR-based disease prediction
    and highlight the influence of prompting strategies on their performance.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们调查了基于LLMs的少量样本疾病预测的有效性，使用的是从临床接触中生成的EHRs，这些记录包括三种类型的医学代码：疾病、药物和程序。我们通过将ICD代码映射到其名称并用适当的连词连接，将结构化的患者访问记录转换为非结构化语言叙述。这一转换过程使LLMs能够更好地理解临床记录并检索相关的内部知识。我们使用各种提示策略评估LLMs的零样本和少量样本诊断性能，例如考虑因素交互、提供流行病统计数据和示例。这些评估结果提供了LLMs作为基于EHR的疾病预测工具的潜力的见解，并突显了提示策略对其性能的影响。
- en: 'Building upon the findings of our initial evaluation, we propose an innovative
    approach to further improve the few-shot diagnostic performance of LLMs on EHR
    data. Studies have shown the promise of specialized LLM agents working collaboratively
    ^([17](#bib.bib17); [18](#bib.bib18); [19](#bib.bib19)), leveraging their diverse
    functionalities through few-shot learning. Our approach combines the strengths
    of predictive agent reasoning and critical agent instruction to create a more
    robust and accurate prediction system. The overall framework is shown in Figure [1](#Sx2.F1
    "Figure 1 ‣ Introduction ‣ LLMs-based Few-Shot Disease Predictions using EHR:
    A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction").
    Specifically, we employ two LLM agents with different roles: a predictor agent
    and a critic agent. The predictor agent makes few-shot predictions given the unstructured
    narratives, which are converted from structured records, and generates a reasoning
    process to support its predictions. The critic agent then takes the predictor’s
    output alongside the ground-truth disease labels as input and identifies issues
    or biases in the predictor agent’s reasoning process. Based on the analysis, the
    critic agent generates a set of instructions that draw the predictor agent’s attention
    to potentially overlooked factors and offer specific recommendations for refining
    its reasoning process. These instructions are subsequently appended to the prompts
    used for the predictor agent, serving as additional context to inform its predictions.
    Our results show that by refining the prompts based on the critic agent’s feedback,
    the overall diagnostic accuracy of the LLM-based few-shot prediction system improves
    significantly. This approach leverages the complementary strengths of predictive
    reasoning and critical analysis, enabling the system to learn from its mistakes
    and adapt to the specific challenges of EHR-based disease prediction. In summary,
    our main contributions are:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '在我们初步评估的发现基础上，我们提出了一种创新的方法，以进一步提高LLMs在EHR数据上的少-shot诊断性能。研究表明，利用少-shot学习，通过专门的LLM代理协作工作具有前景
    ^([17](#bib.bib17); [18](#bib.bib18); [19](#bib.bib19))。我们的方法结合了预测代理推理和批评代理指导的优势，以创建一个更强大、更准确的预测系统。整体框架如图[1](#Sx2.F1
    "Figure 1 ‣ Introduction ‣ LLMs-based Few-Shot Disease Predictions using EHR:
    A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction")所示。具体来说，我们使用两个角色不同的LLM代理：预测代理和批评代理。预测代理在给定转换自结构化记录的非结构化叙述的情况下，进行少-shot预测，并生成一个推理过程来支持其预测。批评代理随后将预测者的输出与真实疾病标签作为输入，识别预测代理推理过程中的问题或偏差。根据分析，批评代理生成一组指令，引起预测代理对可能被忽视的因素的关注，并提供具体的建议来改进其推理过程。这些指令随后被附加到用于预测代理的提示中，作为额外的上下文来指导其预测。我们的结果表明，通过根据批评代理的反馈优化提示，LLM基于的少-shot预测系统的整体诊断准确性显著提高。这种方法利用了预测推理和批评分析的互补优势，使系统能够从错误中学习并适应基于EHR的疾病预测的具体挑战。总之，我们的主要贡献是：'
- en: •
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We investigate the application of LLMs to EHR-based disease prediction tasks
    by converting structured data into natural language narratives and evaluating
    zero-shot and few-shot performance using various prompting strategies.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们通过将结构化数据转换为自然语言叙述，并使用各种提示策略评估零-shot和少-shot性能，来研究LLMs在基于EHR的疾病预测任务中的应用。
- en: •
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'We propose a novel approach combining two LLM agents with different roles:
    a predictor agent that makes predictions and provides reasoning processes, and
    a critic agent that analyzes incorrect predictions and provides feedback for improvement.
    The critic agent’s feedback is used to update the predictor agent’s prompts, enabling
    the system to learn from its mistakes and adapt to EHR-based disease prediction
    challenges.'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了一种新颖的方法，将两个角色不同的LLM（大语言模型）代理结合起来：一个是进行预测并提供推理过程的预测代理，另一个是分析错误预测并提供改进反馈的批评代理。批评代理的反馈用于更新预测代理的提示，从而使系统能够从错误中学习，并适应基于电子健康记录（EHR）的疾病预测挑战。
- en: •
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We summarize a set of insights into the performance of LLMs under various settings
    and share practical guidance on leveraging LLMs for diagnostic tasks with limited
    labeled data. We hope this can contribute to developing efficient and effective
    clinical decision support systems in the era of LLMs.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们总结了一组关于LLMs在不同设置下性能的见解，并分享了在有限标记数据情况下利用LLMs进行诊断任务的实际指导。我们希望这能为在LLMs时代开发高效且有效的临床决策支持系统做出贡献。
- en: '![Refer to caption](img/66a507c23c9b3f641feb9ba6af2c20d0.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/66a507c23c9b3f641feb9ba6af2c20d0.png)'
- en: 'Figure 1: The framework of EHR-CoAgent employs two LLM agents: a predictor
    agent that makes predictions and generates reasoning processes and a critic agent
    that analyzes incorrect predictions and provides guidance for improvement. The
    critic agent’s feedback is used to update the prompts given to the predictor agent,
    enabling the system to learn from its mistakes and adapt to the specific challenges
    of the EHR-based disease prediction task.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：EHR-CoAgent的框架采用了两个LLM代理：一个预测代理，负责进行预测并生成推理过程，另一个批评代理，负责分析错误预测并提供改进建议。批评代理的反馈用于更新提供给预测代理的提示，使系统能够从错误中学习并适应基于EHR的疾病预测任务的特定挑战。
- en: Related Work
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关工作
- en: Large Language Models for Healthcare LLMs have demonstrated remarkable capabilities
    in various application scenarios. Recently, there has been a growing interest
    in applying LLMs to the medical domain ^([20](#bib.bib20); [21](#bib.bib21); [22](#bib.bib22)),
    particularly for tasks such as clinical note analysis ^([23](#bib.bib23); [24](#bib.bib24)),
    medical question answering ^([25](#bib.bib25); [26](#bib.bib26)), disease prediction ^([27](#bib.bib27)),
    clinical trial matching ^([28](#bib.bib28)), medical report generation ^([29](#bib.bib29)).
    For example, Yang et al. ^([30](#bib.bib30)) introduced GatorTron, an LLM specifically
    designed for EHRs. They demonstrated the effectiveness of GatorTron in various
    clinical natural language processing (NLP) tasks, such as named entity recognition
    and relation extraction, showcasing the potential of LLMs to extract valuable
    information from unstructured EHR data. Peng et al. ^([22](#bib.bib22)) investigated
    the use of generative LLMs for medical research and healthcare. They explored
    the capabilities of LLMs in tasks such as medical question answering, disease
    prediction, and clinical trial matching, highlighting their potential to support
    clinical decision-making and assist research.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型在医疗保健中的应用LLMs在各种应用场景中展示了显著的能力。最近，越来越多的研究关注将LLMs应用于医疗领域^([20](#bib.bib20);
    [21](#bib.bib21); [22](#bib.bib22))，尤其是临床记录分析^([23](#bib.bib23); [24](#bib.bib24))、医学问答^([25](#bib.bib25);
    [26](#bib.bib26))、疾病预测^([27](#bib.bib27))、临床试验匹配^([28](#bib.bib28))、医学报告生成^([29](#bib.bib29))等任务。例如，Yang等^([30](#bib.bib30))引入了专为EHR设计的LLM
    GatorTron。他们展示了GatorTron在各种临床自然语言处理（NLP）任务中的有效性，如命名实体识别和关系提取，展示了LLMs从非结构化EHR数据中提取有价值信息的潜力。Peng等^([22](#bib.bib22))调查了生成型LLMs在医学研究和医疗保健中的应用。他们探索了LLMs在医学问答、疾病预测和临床试验匹配等任务中的能力，突显了它们支持临床决策和协助研究的潜力。
- en: However, applying LLMs to EHR-based disease prediction tasks remains under-explored.
    While some studies have investigated the use of LLMs for clinical NLP tasks on
    EHR ^([30](#bib.bib30)), there is still a lack of research on leveraging the reasoning
    and instruction-following capabilities of LLMs for few-shot EHR-based prediction.
    Our research addresses this gap by exploring the use of LLMs for EHR-based disease
    prediction and proposes new methods to enable accurate prediction with minimal
    training data.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，将LLMs应用于基于EHR的疾病预测任务仍然未得到充分探索。虽然一些研究调查了LLMs在EHR上的临床NLP任务的应用^([30](#bib.bib30))，但关于利用LLMs的推理和指令跟随能力进行少量样本EHR预测的研究仍然不足。我们的研究通过探讨LLMs在基于EHR的疾病预测中的应用，并提出新方法以在最少的训练数据下实现准确预测，从而填补这一空白。
- en: Method
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 方法
- en: 'In this study, we expand our investigations on two levels: (1) evaluating the
    zero-shot and few-shot performance of LLMs on EHR-based disease prediction tasks,
    and (2) proposing a novel approach that leverages collaborative LLM agents to
    enhance the predictive performance.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们从两个层面扩展了我们的调查：（1）评估LLMs在基于EHR的疾病预测任务中的零样本和少样本性能，以及（2）提出了一种新方法，利用协作LLM代理来增强预测性能。
- en: LLM Performance on Disease Prediction with EHR The structured patient visit
    data are typically stored in tabular formats, where each row represents an individual
    patient visit record generated from clinical encounters, and columns correspond
    to different medical codes. In this study, we utilize EHR data that includes three
    types of medical codes $\mathcal{C}$, by mapping the medical codes to their names
    to enable the application of LLMs.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: LLM在基于EHR的疾病预测中的表现结构化的患者访问数据通常以表格格式存储，每行代表来自临床接触的单个患者访问记录，列对应不同的医学代码。在本研究中，我们利用包含三种医学代码$\mathcal{C}$的EHR数据，通过将医学代码映射到其名称来实现LLMs的应用。
- en: '$\diamond$ Zero-Shot: Leveraging Pre-existing Knowledge Prompt engineering
    has emerged as a powerful technique for guiding the behavior of LLMs and improving
    their performance on various healthcare-related tasks, such as clinical named
    entity recognition ^([31](#bib.bib31); [32](#bib.bib32)) and clinical text classification ^([33](#bib.bib33);
    [34](#bib.bib34)). We develop a set of prompting strategies tailored to EHR-based
    prediction tasks to provide additional context and guide the reasoning process
    of LLMs, including:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 零样本：利用已有知识提示工程已经成为引导LLMs行为和提高其在各种医疗相关任务上的表现的强大技术，例如临床命名实体识别^([31](#bib.bib31);
    [32](#bib.bib32))和临床文本分类^([33](#bib.bib33); [34](#bib.bib34))。我们开发了一套针对基于电子健康记录（EHR）的预测任务的提示策略，以提供额外的背景信息并引导LLMs的推理过程，包括：
- en: •
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Chain-of-thought (CoT) reasoning ^([35](#bib.bib35)): prompt the LLMs to generate
    step-by-step explanations;'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 思维链（CoT）推理^([35](#bib.bib35))：提示LLMs生成逐步解释；
- en: •
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Incorporation of factor interactions: encourage LLMs to consider the interactions
    and dependencies among different medical factors (e.g., diseases, medications,
    and procedures);'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因素交互的整合：鼓励大型语言模型（LLMs）考虑不同医学因素（例如，疾病、药物和程序）之间的交互和依赖关系；
- en: •
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Prevalence information: integrate information about the prevalence statistics
    to provide additional context.'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 流行病学信息：整合有关流行病学统计的数据，以提供额外的背景信息。
- en: '$\diamond$ Few-Shot: Enhancing Performance with Limited Examples We randomly
    select a small number of positive and negative samples (e.g., 3 positive and 3
    negative) from the training data to serve as exemplars for each prediction category.
    These exemplars are incorporated into the prompts to provide the LLMs with a limited
    set of task-specific examples to learn from. This leverages the LLMs’ vast pre-existing
    knowledge while allowing them to adapt quickly to the specific characteristics
    of the EHR prediction task. By this, we aim to guide LLMs’ attention toward the
    most relevant patterns associated with each prediction category.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 少量样本：利用有限示例提升性能 我们从训练数据中随机选择少量正负样本（例如，3个正样本和3个负样本）作为每个预测类别的示例。这些示例被纳入提示中，以向LLMs提供有限的任务特定示例供其学习。这种方法利用了LLMs丰富的预先知识，同时使其能够快速适应EHR预测任务的特定特征。通过这种方式，我们旨在引导LLMs的注意力集中在与每个预测类别相关的最重要的模式上。
- en: 'EHR-CoAgent: Collaborative LLM Agents for Enhanced Prediction Recently, the
    potential of LLMs has extended beyond single-agent applications. By leveraging
    the power of multiple LLMs with different roles working together in a collaborative
    framework, new possibilities have been unlocked for tackling complex problems
    and enhancing the performance of language models ^([17](#bib.bib17)). In this
    study, we propose a novel approach called EHR-CoAgent (as demonstrated in Figure [1](#Sx2.F1
    "Figure 1 ‣ Introduction ‣ LLMs-based Few-Shot Disease Predictions using EHR:
    A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction")),
    which harnesses the potential of collaborative LLM agents for enhanced prediction
    of EHR. Our framework consists of two components: a predictor agent $\mathcal{P}_{\text{LLM}}$.
    The predictor agent focuses on generating predictions and providing explanatory
    reasoning, while the critic agent observes the predictor’s outputs and provides
    instructional feedback to refine the prediction process. By integrating the feedback
    from the critic agent into the prompts used by the predictor agent, we aim to
    create an in-context learning process with feedback to continuously enhance disease
    prediction accuracy.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: EHR-CoAgent：增强预测的协作LLM代理 近年来，LLMs的潜力已经超越了单一代理应用。通过利用多个具有不同角色的LLMs在协作框架下共同工作，解锁了应对复杂问题和提升语言模型表现的新可能性^([17](#bib.bib17))。在本研究中，我们提出了一种称为EHR-CoAgent的新方法（如图[1](#Sx2.F1
    "图 1 ‣ 介绍 ‣ 基于LLMs的少量样本疾病预测：一种结合预测代理推理和关键代理指令的新方法")所示），它利用协作LLM代理的潜力来增强EHR预测。我们的框架包括两个组件：预测代理$\mathcal{P}_{\text{LLM}}$。预测代理专注于生成预测并提供解释性推理，而评论代理观察预测输出并提供指导反馈以完善预测过程。通过将评论代理的反馈整合到预测代理使用的提示中，我们旨在创建一个具有反馈的上下文学习过程，以持续提高疾病预测的准确性。
- en: '$\diamond$. Such explanatory reasoning is crucial for enhancing the interpretability
    of the generated predictions. By highlighting the key factors and evidence influencing
    the LLM agent’s decision-making process, the reasoning serves as a transparent
    and informative basis for further analysis and validation. The detailed prompt
    we used for the predictor agent in EHR-CoAgent is shown in Figure [3](#Sx9.F3
    "Figure 3 ‣ LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach
    Combining Predictive Agent Reasoning and Critical Agent Instruction").'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '$\diamond$。这种解释性推理对于增强生成预测的可解释性至关重要。通过突出影响LLM代理决策过程的关键因素和证据，推理为进一步的分析和验证提供了透明且信息丰富的基础。我们在EHR-CoAgent中为预测代理使用的详细提示见于图[3](#Sx9.F3
    "Figure 3 ‣ LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach
    Combining Predictive Agent Reasoning and Critical Agent Instruction")。'
- en: '$\diamond$ times. The detailed prompt we used for the critic agent in EHR-CoAgent
    is shown in Figure [4](#Sx9.F4 "Figure 4 ‣ LLMs-based Few-Shot Disease Predictions
    using EHR: A Novel Approach Combining Predictive Agent Reasoning and Critical
    Agent Instruction").'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '$\diamond$ 次。我们在EHR-CoAgent中为批评代理使用的详细提示见于图[4](#Sx9.F4 "Figure 4 ‣ LLMs-based
    Few-Shot Disease Predictions using EHR: A Novel Approach Combining Predictive
    Agent Reasoning and Critical Agent Instruction")。'
- en: To provide concise and coherent guidance, we employ GPT-4 to process the set
    of instructional feedback $\{\mathcal{F}_{j}\}_{j=1}^{m}$ that captures the most
    important and recurring insights. This consolidated feedback highlights common
    biases or errors in the reasoning process, offers suggestions for considering
    additional factors, and provides insights into the relationships between different
    medical concepts.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供简明而连贯的指导，我们使用GPT-4处理一组指令反馈$\{\mathcal{F}_{j}\}_{j=1}^{m}$，这些反馈捕捉了最重要和最常见的见解。这些整合的反馈突出了推理过程中常见的偏差或错误，提供了考虑额外因素的建议，并对不同医学概念之间的关系提供了见解。
- en: $\diamond$ used by the predictor LLM. By augmenting the prompts with specific
    instructions and guidance, we aim to steer the predictor LLM’s attention toward
    the most relevant aspects of the input data and encourage it to consider the insights
    provided by the critic LLM. This iterative process of making predictions, receiving
    feedback, and refining the prompts allows the predictor LLM to continuously improve
    its performance and adapt to the specific challenges of EHR-based disease prediction.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 被预测LLM使用。通过用具体的指令和指导增强提示，我们旨在引导预测LLM的注意力集中在输入数据的最相关方面，并鼓励其考虑批评LLM提供的见解。这种预测、接收反馈和优化提示的迭代过程使预测LLM能够持续提升其性能，并适应基于EHR的疾病预测的具体挑战。
- en: Experimental Settings
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实验设置
- en: 'Datasets We conducted experiments on two datasets: the publicly accessible
    MIMIC-III dataset and the privately-owned CRADLE dataset. MIMIC-III ^([36](#bib.bib36))
    is a large, publicly accessible dataset comprising de-identified health-related
    data associated with over forty thousand patients who stayed in critical care
    units of the Beth Israel Deaconess Medical Center between 2001 and 2012\. Our
    task is to predict whether acute care conditions will be present during a patient’s
    next visit, given their current ICU stay records. We focus on a specific chronic
    phenotype, Disorders of Lipid Metabolism, which is identified using Clinical Classifications
    Software (CCS) from the Healthcare Cost and Utilization Project (HCUP)¹¹1[https://www.hcup-us.ahrq.gov/toolssoftware/ccs/AppendixASingleDX.txt](https://www.hcup-us.ahrq.gov/toolssoftware/ccs/AppendixASingleDX.txt).
    During preprocessing, we extract patients with more than one hospital visit and
    create pairs of adjacent visits for each patient. For each pair, the former visit
    serves as the input, and the phenotypes in the latter visit are used as labels.
    This process yields 12,353 records with labels. For budget consideration, we randomly
    sample 1,000 records based on the data distribution of the prediction target as
    our testing set.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集 我们在两个数据集上进行了实验：公开访问的 MIMIC-III 数据集和私有的 CRADLE 数据集。MIMIC-III ^([36](#bib.bib36))
    是一个大型公开数据集，包含与 2001 年至 2012 年期间在 Beth Israel Deaconess Medical Center 的重症监护病房住院的四万多名患者相关的去标识化健康数据。我们的任务是根据患者当前
    ICU 住院记录，预测急性护理情况是否会出现在患者的下一次就诊中。我们专注于一种特定的慢性表型——脂质代谢障碍，这通过来自 Healthcare Cost
    and Utilization Project（HCUP）的临床分类软件（CCS）识别¹¹1[https://www.hcup-us.ahrq.gov/toolssoftware/ccs/AppendixASingleDX.txt](https://www.hcup-us.ahrq.gov/toolssoftware/ccs/AppendixASingleDX.txt)。在预处理过程中，我们提取了就诊次数多于一次的患者，并为每个患者创建了相邻就诊的配对。对于每对数据，前一次就诊作为输入，而后一次就诊中的表型则作为标签。这个过程生成了
    12,353 条带标签的记录。考虑到预算问题，我们根据预测目标的数据分布随机抽取 1,000 条记录作为我们的测试集。
- en: Project CRADLE (Emory Clinical Research Analytics Data Lake Environment) is
    a privately-owned database that contains de-identified electronic health records
    at Emory Healthcare from 2013 to 2017\. In this study, we focus on the patients
    with type 2 diabetes and predict whether those patients will experience cardiovascular
    disease (CVD) endpoints within a year after the initial diabetes diagnosis. The
    CVD endpoints include coronary heart disease (CHD), congestive heart failure (CHF),
    myocardial infarction (MI), or stroke, which are identified by their ICD-9 and
    ICD-10 clinical codes. For patients who developed CVD complications within a year
    (positive cases), we select the earliest recorded encounter within a year of the
    CVD endpoint presence as the input. For patients without CVD complications (negative
    cases), we randomly select one encounter as the input from all encounters that
    occurred at least one year before the last recorded encounter. Patients are excluded
    if they (1) have less than two encounters at Emory Healthcare, (2) the time interval
    between their first and last encounter is less than one year, or (3) have a history
    of CVD conditions. After applying these exclusion criteria, 35,404 patients remain
    in the dataset. Similar to MIMIC-III, we randomly sample 1,000 records based on
    the data distribution of the prediction target
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 项目 CRADLE（Emory 临床研究分析数据湖环境）是一个私有数据库，包含了 Emory Healthcare 从 2013 年到 2017 年的去标识化电子健康记录。在这项研究中，我们专注于
    2 型糖尿病患者，并预测这些患者在首次糖尿病诊断后的一年内是否会经历心血管疾病（CVD）终点。CVD 终点包括冠心病（CHD）、充血性心力衰竭（CHF）、心肌梗死（MI）或中风，这些都通过其
    ICD-9 和 ICD-10 临床代码来识别。对于在一年内发生 CVD 并发症的患者（阳性案例），我们选择 CVD 终点出现前一年内记录的最早一次就诊作为输入。对于没有
    CVD 并发症的患者（阴性案例），我们从所有至少在最后一次记录就诊前一年发生的就诊中随机选择一次作为输入。如果患者（1）在 Emory Healthcare
    的就诊次数少于两次，（2）第一次和最后一次就诊之间的时间间隔少于一年，或（3）有 CVD 病史，则被排除在外。应用这些排除标准后，数据集中剩余 35,404
    名患者。与 MIMIC-III 相似，我们根据预测目标的数据分布随机抽取 1,000 条记录。
- en: Evaluation Metrics Both the MIMIC-III and CRADLE datasets exhibit class imbalance,
    with the prevalence of Disorders of Lipid Metabolism in MIMIC-III being 27.6%
    and the prevalence of cardiovascular disease (CVD) endpoints in CRADLE being 21.4%.
    To account for the imbalanced data distributions, we employ accuracy, sensitivity,
    specificity, and F1 score as evaluation metrics ^([14](#bib.bib14)). When evaluating
    LLM methods, we identify the presence of “Yes” or “No” tokens in the LLM responses
    and extract the top 5 probabilities associated with the predicting token. These
    probabilities are then normalized over both answers. We observed that GPT family
    models tend to provide highly confident answers (a confirmed prediction of either
    “Yes” or “No”, with almost 0.0 probability for the other choice), often resulting
    in a majority probability of either 0.0 or 1.0.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 评价指标 MIMIC-III和CRADLE数据集都存在类别不平衡问题，其中MIMIC-III中的脂质代谢疾病的发生率为27.6%，而CRADLE中的心血管疾病（CVD）终点的发生率为21.4%。为了考虑数据分布的不平衡，我们采用准确率、敏感性、特异性和F1分数作为评价指标 ^([14](#bib.bib14))。在评估LLM方法时，我们识别LLM响应中是否存在“是”或“否”标记，并提取与预测标记相关的前5个概率。这些概率随后在两个答案上进行归一化。我们观察到GPT系列模型倾向于提供高度自信的答案（即确认预测“是”或“否”，另一个选择的概率几乎为0.0），通常导致大多数概率为0.0或1.0。
- en: 'Baselines We compare the performance of EHR-CoAgent with traditional machine
    learning (ML), including Decision Trees, Logistic Regression, and Random Forests,
    which are widely used in EHR-based prediction tasks ^([37](#bib.bib37); [38](#bib.bib38)),
    and single-agent LLM approaches using GPT-4 (gpt-4-0125-preview) and GPT-3.5 (gpt-35-turbo-16k-0613).
    The ML models are trained in both fully supervised and few-shot settings, while
    the LLM approaches are evaluated in pure zero-shot, zero-shot with additional
    prompt information as mentioned in section [Method](#Sx4 "Method ‣ LLMs-based
    Few-Shot Disease Predictions using EHR: A Novel Approach Combining Predictive
    Agent Reasoning and Critical Agent Instruction"), and few-shot learning settings.
    By comparing EHR-CoAgent with these baselines, we aim to evaluate the effectiveness
    of diverse LLM agent frameworks in EHR-based disease prediction tasks.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '基线 我们将EHR-CoAgent的性能与传统机器学习（ML）方法进行比较，包括决策树、逻辑回归和随机森林，这些方法在基于EHR的预测任务中被广泛使用 ^([37](#bib.bib37);
    [38](#bib.bib38))，以及使用GPT-4（gpt-4-0125-preview）和GPT-3.5（gpt-35-turbo-16k-0613）的单一代理LLM方法。ML模型在完全监督和少样本设置下进行训练，而LLM方法则在纯零样本、附加提示信息的零样本（如[方法](#Sx4
    "Method ‣ LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach
    Combining Predictive Agent Reasoning and Critical Agent Instruction")一节所述）和少样本学习设置下进行评估。通过将EHR-CoAgent与这些基线进行比较，我们旨在评估多样化LLM代理框架在基于EHR的疾病预测任务中的有效性。'
- en: Implementation Details We implemented the empirical study methods in Python.
    The baseline machine learning models were trained and evaluated using the popular
    sklearn package, which provides a comprehensive set of tools for machine learning
    tasks. To access the various GPT models securely, we utilized the Azure OpenAI
    Service, a trusted and compliant cloud platform. Azure OpenAI offers a secure
    API interface that allows seamless integration of the GPT capabilities into our
    research pipeline while maintaining strict privacy and security controls. By leveraging
    Azure OpenAI, we ensured that the sensitive patient dataset was processed in a
    protected environment, adhering to necessary regulations and standards, such as
    HIPAA and GDPR.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 实施细节 我们在Python中实现了实证研究方法。基线机器学习模型使用流行的sklearn包进行训练和评估，该包提供了一整套用于机器学习任务的工具。为了安全地访问各种GPT模型，我们利用了Azure
    OpenAI服务，这是一种受信赖的合规云平台。Azure OpenAI提供了一个安全的API接口，允许将GPT能力无缝集成到我们的研究流程中，同时保持严格的隐私和安全控制。通过利用Azure
    OpenAI，我们确保敏感的患者数据集在受保护的环境中处理，遵守必要的法规和标准，如HIPAA和GDPR。
- en: Experimental Results
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实验结果
- en: 'Table 1: Performance (%) of different models under the zero-shot, few-shot,
    and fully-supervised settings on MIMIC-III and CRADLE datasets. The proposed method
    is colored in green. The reference results under the supervised training setting
    (trained on 11,353 samples for MIMIC-III and 34,404 samples for CRADLE) are colored
    in gray.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：不同模型在MIMIC-III和CRADLE数据集上在零样本、少样本和完全监督设置下的性能（%）。提出的方法以绿色标出。监督训练设置下的参考结果（在MIMIC-III上训练了11,353个样本，在CRADLE上训练了34,404个样本）以灰色标出。
- en: '| Type | Model | MIMIC-III (Pos : Neg = 27.6% : 72.4%) |  | CRADLE (Pos : Neg
    = 21.4% : 78.6%) |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 类型 | 模型 | MIMIC-III（阳性 : 阴性 = 27.6% : 72.4%） |  | CRADLE（阳性 : 阴性 = 21.4%
    : 78.6%） |'
- en: '| ACC | Sensitivity | Specificity | F1 |  | ACC | Sensitivity | Specificity
    | F1 |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| ACC | Sensitivity | Specificity | F1 |  | ACC | Sensitivity | Specificity
    | F1 |'
- en: '| Fully-Supervised | Decision Tree | 81.30 | 76.97 | 84.31 | 76.20 |  | 80.30
    | 53.87 | 88.27 | 52.15 |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| Fully-Supervised | Decision Tree | 81.30 | 76.97 | 84.31 | 76.20 |  | 80.30
    | 53.87 | 88.27 | 52.15 |'
- en: '| Logistic Regression | 79.70 | 70.48 | 83.56 | 73.18 |  | 80.90 | 58.34 |
    86.15 | 59.74 |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| Logistic Regression | 79.70 | 70.48 | 83.56 | 73.18 |  | 80.90 | 58.34 |
    86.15 | 59.74 |'
- en: '| Random Forest | 78.60 | 66.12 | 83.16 | 70.58 |  | 80.20 | 56.49 | 86.14
    | 57.34 |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| Random Forest | 78.60 | 66.12 | 83.16 | 70.58 |  | 80.20 | 56.49 | 86.14
    | 57.34 |'
- en: '| Few-Shot (N=6) | Decision Tree | 71.10 | 53.14 | 77.62 | 51.16 |  | 31.90
    | 54.81 | 25.99 | 31.71 |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| Few-Shot (N=6) | Decision Tree | 71.10 | 53.14 | 77.62 | 51.16 |  | 31.90
    | 54.81 | 25.99 | 31.71 |'
- en: '| Logistic Regression | 58.70 | 73.40 | 53.44 | 56.78 |  | 53.30 | 53.95 |
    53.13 | 48.16 |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| Logistic Regression | 58.70 | 73.40 | 53.44 | 56.78 |  | 53.30 | 53.95 |
    53.13 | 48.16 |'
- en: '| Random Forest | 69.70 | 62.88 | 72.18 | 63.61 |  | 65.00 | 51.50 | 68.43
    | 51.04 |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| Random Forest | 69.70 | 62.88 | 72.18 | 63.61 |  | 65.00 | 51.50 | 68.43
    | 51.04 |'
- en: '| GPT-4 | Zero-Shot | 51.90 | 76.15 | 42.56 | 51.89 |  | 24.10 | 51.81 | 16.82
    | 22.33 |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | Zero-Shot | 51.90 | 76.15 | 42.56 | 51.89 |  | 24.10 | 51.81 | 16.82
    | 22.33 |'
- en: '| Zero-Shot+ | 62.90 | 59.30 | 64.29 | 58.58 |  | 30.00 | 53.25 | 23.76 | 29.67
    |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| Zero-Shot+ | 62.90 | 59.30 | 64.29 | 58.58 |  | 30.00 | 53.25 | 23.76 | 29.67
    |'
- en: '| Few-Shot (N=6) | 65.70 | 79.35 | 59.89 | 64.72 |  | 41.20 | 59.05 | 36.33
    | 40.88 |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| Few-Shot (N=6) | 65.70 | 79.35 | 59.89 | 64.72 |  | 41.20 | 59.05 | 36.33
    | 40.88 |'
- en: '| EHR-CoAgent | 79.10 | 73.11 | 81.43 | 73.88 |  | 70.00 | 62.88 | 71.72 |
    60.21 |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| EHR-CoAgent | 79.10 | 73.11 | 81.43 | 73.88 |  | 70.00 | 62.88 | 71.72 |
    60.21 |'
- en: '| GPT-3.5 | Zero-Shot | 78.00 | 66.87 | 82.37 | 68.56 |  | 56.50 | 59.88 |
    55.45 | 52.29 |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 | Zero-Shot | 78.00 | 66.87 | 82.37 | 68.56 |  | 56.50 | 59.88 |
    55.45 | 52.29 |'
- en: '| Zero-Shot+ | 72.40 | 50.00 | 80.37 | 42.00 |  | 62.60 | 57.62 | 63.96 | 54.40
    |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| Zero-Shot+ | 72.40 | 50.00 | 80.37 | 42.00 |  | 62.60 | 57.62 | 63.96 | 54.40
    |'
- en: '| Few-Shot (N=6) | 76.30 | 63.73 | 80.93 | 63.84 |  | 40.80 | 54.56 | 36.96
    | 40.32 |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| Few-Shot (N=6) | 76.30 | 63.73 | 80.93 | 63.84 |  | 40.80 | 54.56 | 36.96
    | 40.32 |'
- en: '| EHR-CoAgent | 79.30 | 74.49 | 80.98 | 71.59 |  | 66.60 | 58.31 | 68.83 |
    55.83 |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| EHR-CoAgent | 79.30 | 74.49 | 80.98 | 71.59 |  | 66.60 | 58.31 | 68.83 |
    55.83 |'
- en: 'Table [1](#Sx6.T1 "Table 1 ‣ Experimental Results ‣ LLMs-based Few-Shot Disease
    Predictions using EHR: A Novel Approach Combining Predictive Agent Reasoning and
    Critical Agent Instruction") presents the experimental results on the two datasets.
    The findings highlight several key observations:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 [1](#Sx6.T1 "表 1 ‣ 实验结果 ‣ 基于 LLM 的少样本疾病预测使用电子健康记录：一种结合预测性代理推理和关键代理指令的新方法")
    展示了两个数据集上的实验结果。结果突出了几个关键观察点：
- en: $\diamond$ Traditional machine learning (ML) models achieve respectable performance
    when fully trained on large datasets (11,353 samples for MIMIC-III and 34,404
    samples for CRADLE). However, the performance of simpler models, such as Decision
    Trees and Logistic Regression, substantially deteriorates in the few-shot learning
    setting, emphasizing their limitations when labeled data is scarce.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 传统机器学习（ML）模型在对大数据集（MIMIC-III 的 11,353 个样本和 CRADLE 的 34,404 个样本）进行完全训练时表现良好。然而，当在少量样本学习设置中时，较简单的模型，如决策树和逻辑回归，其性能大幅下降，突显了在标签数据稀缺时的局限性。
- en: $\diamond$ When comparing the performance of zero-shot or few-shot LLMs with
    ML methods under few-shot settings, we observe that LLMs exhibit higher sensitivity
    but lower specificity. This finding suggests that LLMs excel at correctly identifying
    positive cases (i.e., patients with the condition of interest) but at the cost
    of a higher false positive rate. In other words, LLMs are more prone to classifying
    a patient as having the condition, even when they do not. This tendency implies
    that LLMs, particularly GPT-4, adopt a more conservative mindset, possibly due
    to their alignment to err on the side of caution to mitigate the risk of potentially
    missing true positive cases.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 在零-shot 或少量样本 LLM 与机器学习方法在少量样本设置下进行性能比较时，我们观察到 LLM 展现出更高的敏感性但更低的特异性。这一发现表明，LLM
    在正确识别阳性病例（即有相关疾病的患者）方面表现优异，但以更高的假阳性率为代价。换句话说，LLM 更容易将患者误分类为有该疾病，即使他们实际上没有。这种倾向意味着
    LLM，特别是 GPT-4，采取了更保守的心态，可能是因为它们倾向于谨慎行事，以减轻可能遗漏真实阳性病例的风险。
- en: $\diamond$ Zero-shot with additional prompting strategies (Zero-Shot+) can improve
    based on pure zero-shot, with occasionally produced errors. This observation underscores
    the importance of carefully crafting prompts to optimize the performance of LLMs
    in EHR-based disease prediction tasks.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 具有额外提示策略的零-shot（Zero-Shot+）相比纯零-shot 可以改善性能，但有时会产生错误。这一观察强调了精心设计提示的重要性，以优化
    LLM 在基于电子健康记录的疾病预测任务中的表现。
- en: $\diamond$ Most of the time, adding few-shot demonstrations enhance prediction
    performance compared to their respective Zero-Shot+ counterparts. This finding
    emphasizes providing even a limited number of labeled examples can potentially
    steer language models toward more precise predictions. By leveraging a small set
    of representative samples, LLMs can quickly adapt to the specific characteristics
    of the EHR-based disease prediction task.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 大多数情况下，添加少量示例可以提高预测性能，相比之下，Zero-Shot+ 方法效果较差。这一发现强调了即使提供有限数量的标注示例，也有可能将语言模型引导到更精确的预测上。通过利用一小组具有代表性的样本，大型语言模型（LLMs）可以迅速适应以电子健康记录（EHR）为基础的疾病预测任务的特定特征。
- en: $\diamond$ Our proposed approach EHR-CoAgent demonstrates remarkable performance,
    surpassing other methods and even fully supervised ML models in certain scenarios,
    with GPT-4 generally outperforming GPT-3.5\. On the CRADLE dataset, EHR-CoAgent
    achieves an F1 score of 60.21%, outperforming all fully trained ML models. Similarly,
    on the MIMIC-III dataset, EHR-CoAgent obtains an F1 score of 73.88%, comparable
    to the fully trained Decision Tree model and superior to Logistic Regression and
    Random Forest.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 我们提出的方法EHR-CoAgent展示了显著的性能，在某些场景中超越了其他方法甚至是完全监督的机器学习模型，其中GPT-4通常优于GPT-3.5。在CRADLE数据集上，EHR-CoAgent获得了60.21%的F1分数，超越了所有完全训练的机器学习模型。类似地，在MIMIC-III数据集上，EHR-CoAgent获得了73.88%的F1分数，与完全训练的决策树模型相当，并且优于逻辑回归和随机森林。
- en: $\diamond$ Compared with the few-shot setting with a single LLM predictor, EHR-CoAgent
    improves significantly on all four metrics. This can be attributed to the feedback
    instructions provided by the critic agent, which analyzes the outputs and identifies
    issues and biases in LLM’s reasoning process, such as overly relying on conservative
    thinking or neglecting certain key factors. The feedback instructions generated
    by the critic agent help to correct these issues, dynamically refining the predictor
    agent’s reasoning process, thus improving the accuracy of the prediction.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 与单一大型语言模型（LLM）预测器的少量示例设置相比，EHR-CoAgent在所有四个指标上都有显著改进。这归因于评论代理提供的反馈指令，该指令分析输出并识别LLM推理过程中的问题和偏见，例如过度依赖保守思维或忽略某些关键因素。评论代理生成的反馈指令有助于纠正这些问题，动态地优化预测代理的推理过程，从而提高预测的准确性。
- en: Generated Instructions
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成的指令
- en: '![Refer to caption](img/be853c2db13cf769e71d8e777e4d827d.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/be853c2db13cf769e71d8e777e4d827d.png)'
- en: 'Figure 2: Examples of instructional feedback generated by the GPT-4-based critic
    agent, which aims to refine the predictor agent’s reasoning process and improve
    the accuracy of its prediction.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：GPT-4基础的评论代理生成的指令反馈示例，旨在优化预测代理的推理过程并提高其预测的准确性。
- en: 'Figure [2](#Sx7.F2 "Figure 2 ‣ Generated Instructions ‣ LLMs-based Few-Shot
    Disease Predictions using EHR: A Novel Approach Combining Predictive Agent Reasoning
    and Critical Agent Instruction") showcases examples of the criteria and instructions
    generated by the critic agent. These examples demonstrate the critic agent’s ability
    to identify potential issues in the predictor agent’s prediction and reasoning
    process and provide targeted instructions to address them. For instance, the first
    instruction for the CRADLE dataset, “Avoid bias towards predicting a positive
    CVD endpoint based on conservative thinking when the patient is actively monitored
    and managed for known risk factors. Evaluate the effectiveness of the interventions
    in place” highlights a possible prediction bias of the predictor agent. This instruction
    encourages the predictor agent to avoid relying on conservative assumptions when
    making predictions, as such assumptions may be a result of the over-alignment
    of advanced AI models. By explicitly addressing this issue, the critic agent aims
    to guide the predictor agent toward more objective and comprehensive reasoning.
    Another example for the MIMIC dataset, “Pharmacological Interventions Consideration:
    Incorporate an evaluation of prescribed drugs, focusing on their relevance to
    managing the risk factors of the disorders of lipoid metabolism” suggests that
    the predictor agent should take into account the role of prescribed medications
    in managing the patient’s condition. By analyzing the relevance and potential
    impact of these drugs on the risk factors associated with disorders of lipoid
    metabolism, the predictor agent can make more informed predictions. These examples
    illustrate how the critic agent’s feedback can guide the predictor agent towards
    more comprehensive and nuanced reasoning, ultimately leading to improved disease
    prediction performance.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '图 [2](#Sx7.F2 "Figure 2 ‣ Generated Instructions ‣ LLMs-based Few-Shot Disease
    Predictions using EHR: A Novel Approach Combining Predictive Agent Reasoning and
    Critical Agent Instruction") 展示了由批评代理生成的标准和指令的示例。这些示例展示了批评代理识别预测代理预测和推理过程中潜在问题的能力，并提供有针对性的指令来解决这些问题。例如，CRADLE数据集的第一个指令，“避免因保守思维而对预测正面心血管疾病终点产生偏见，特别是在患者积极监测和管理已知风险因素的情况下。评估现有干预措施的有效性”，突出了预测代理可能存在的预测偏见。该指令鼓励预测代理在做出预测时避免依赖保守假设，因为这些假设可能是由于先进AI模型的过度对齐所致。通过明确解决这一问题，批评代理旨在引导预测代理进行更客观和全面的推理。另一个针对MIMIC数据集的示例，“药物干预考虑：纳入对处方药物的评估，重点关注其在管理脂质代谢障碍风险因素中的相关性”，建议预测代理应考虑处方药物在管理患者状况中的作用。通过分析这些药物与脂质代谢障碍相关风险因素的相关性和潜在影响，预测代理可以做出更为明智的预测。这些示例说明了批评代理的反馈如何引导预测代理朝着更全面和细致的推理方向发展，最终提高疾病预测性能。'
- en: Conclusions
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: In this study, we investigated the application of Large Language Models (LLMs)
    to Electronic Health Record (EHR) based disease prediction tasks. We evaluated
    the zero-shot and few-shot diagnostic performance of LLMs using various prompting
    strategies and proposed a novel collaborative approach combining a predictor agent
    and a critic agent. This approach enables the system to learn from its mistakes
    and adapt to the challenges of EHR-based disease prediction. Our work highlights
    the potential of LLMs as a tool for clinical decision support and contributes
    to the development of efficient disease prediction systems that can operate with
    minimal training data.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们调查了大语言模型（LLMs）在基于电子健康记录（EHR）的疾病预测任务中的应用。我们评估了LLMs在零样本和少样本情况下的诊断性能，采用了多种提示策略，并提出了一种新颖的协作方法，结合了预测代理和批评代理。这种方法使系统能够从错误中学习并适应EHR基础的疾病预测挑战。我们的工作突出了LLMs作为临床决策支持工具的潜力，并有助于开发能够在最少训练数据下运行的高效疾病预测系统。
- en: Ethical Considerations
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 伦理考虑
- en: To ensure the ethical use of credential data with GPT-based services, we have
    signed and strictly adhered to the PhysioNet Credentialed Data Use Agreement²²2https://physionet.org/about/licenses/physionet-credentialed-health-data-license-150.
    We follow the guidelines³³3https://physionet.org/news/post/gpt-responsible-use
    for responsible use of MIMIC data in online services, including opting out of
    human review of the data through the Azure OpenAI Additional Use Case Form⁴⁴4https://aka.ms/oai/additionalusecase,
    to prevent sensitive information from being shared with third parties.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 为确保在使用基于GPT的服务时数据的伦理使用，我们已签署并严格遵守PhysioNet认证数据使用协议²²2https://physionet.org/about/licenses/physionet-credentialed-health-data-license-150。我们遵循指南³³3https://physionet.org/news/post/gpt-responsible-use，以负责地使用MIMIC数据，包括通过Azure
    OpenAI附加用例表单⁴⁴4https://aka.ms/oai/additionalusecase，避免将敏感信息共享给第三方。
- en: References
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 1 Achiam J, Adler S, Agarwal S, Ahmad L, Akkaya I, Aleman FL, et al. Gpt-4 technical
    report. arXiv preprint arXiv:230308774\. 2023.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 Achiam J, Adler S, Agarwal S, Ahmad L, Akkaya I, Aleman FL, 等. Gpt-4技术报告。arXiv预印本
    arXiv:230308774。2023年。
- en: 2 Anil R, Dai AM, Firat O, Johnson M, Lepikhin D, Passos A, et al. Palm 2 technical
    report. arXiv preprint arXiv:230510403\. 2023.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2 Anil R, Dai AM, Firat O, Johnson M, Lepikhin D, Passos A, 等. Palm 2技术报告。arXiv预印本
    arXiv:230510403。2023年。
- en: 3 Singhal K, Azizi S, Tu T, Mahdavi SS, Wei J, Chung HW, et al. Large language
    models encode clinical knowledge. Nature. 2023;620:172-80.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3 Singhal K, Azizi S, Tu T, Mahdavi SS, Wei J, Chung HW, 等. 大型语言模型编码临床知识。自然。2023年；620:172-80。
- en: '4 Hernandez E, Mahajan D, Wulff J, Smith MJ, Ziegler Z, Nadler D, et al. Do
    We Still Need Clinical Language Models? In: Conference on Health, Inference, and
    Learning; 2023\. .'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 4 Hernandez E, Mahajan D, Wulff J, Smith MJ, Ziegler Z, Nadler D, 等. 我们还需要临床语言模型吗？在：健康、推理与学习会议；2023年。
- en: 5 Singhal K, Tu T, Gottweis J, Sayres R, Wulczyn E, Hou L, et al. Towards expert-level
    medical question answering with large language models. arXiv preprint arXiv:230509617\.
    2023.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 5 Singhal K, Tu T, Gottweis J, Sayres R, Wulczyn E, Hou L, 等. 使用大型语言模型进行专家级医学问题回答。arXiv预印本
    arXiv:230509617。2023年。
- en: 6 Van Veen D, Van Uden C, Blankemeier L, Delbrouck JB, Aali A, Bluethgen C,
    et al. Adapted large language models can outperform medical experts in clinical
    text summarization. Nature Medicine. 2024:1-9.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 6 Van Veen D, Van Uden C, Blankemeier L, Delbrouck JB, Aali A, Bluethgen C,
    等. 调整后的大型语言模型可以在临床文本总结中超越医学专家。自然医学。2024年：1-9。
- en: '7 Hegselmann S, Buendia A, Lang H, Agrawal M, Jiang X, Sontag D. Tabllm: Few-shot
    classification of tabular data with large language models. In: AISTATS; 2023\.
    .'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 7 Hegselmann S, Buendia A, Lang H, Agrawal M, Jiang X, Sontag D. Tabllm：使用大型语言模型对表格数据进行少量样本分类。在：AISTATS；2023年。
- en: 8 Brown T, Mann B, Ryder N, Subbiah M, Kaplan JD, Dhariwal P, et al. Language
    models are few-shot learners. NeurIPS. 2020.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 8 Brown T, Mann B, Ryder N, Subbiah M, Kaplan JD, Dhariwal P, 等. 语言模型是少量样本学习者。NeurIPS。2020年。
- en: 9 Schick T, Schütze H. Exploiting cloze questions for few shot text classification
    and natural language inference. arXiv preprint arXiv:200107676\. 2020.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 9 Schick T, Schütze H. 利用填空题进行少量样本文本分类和自然语言推理。arXiv预印本 arXiv:200107676。2020年。
- en: '10 Shickel B, Tighe PJ, Bihorac A, Rashidi P. Deep EHR: a survey of recent
    advances in deep learning techniques for electronic health record (EHR) analysis.
    IEEE journal of biomedical and health informatics. 2017;22:1589-604.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 10 Shickel B, Tighe PJ, Bihorac A, Rashidi P. 深度EHR：电子健康记录（EHR）分析中的深度学习技术的最新进展综述。IEEE生物医学与健康信息学期刊。2017年；22:1589-604。
- en: 11 Rajkomar A, Oren E, Chen K, Dai AM, Hajaj N, Hardt M, et al. Scalable and
    accurate deep learning with electronic health records. NPJ digital medicine. 2018;1:1-10.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 11 Rajkomar A, Oren E, Chen K, Dai AM, Hajaj N, Hardt M, 等. 使用电子健康记录进行可扩展和准确的深度学习。NPJ数字医学。2018年；1:1-10。
- en: 12 Landi I, Glicksberg BS, Lee HC, Cherng S, Landi G, Danieletto M, et al. Deep
    representation learning of electronic health records to unlock patient stratification
    at scale. NPJ digital medicine. 2020;3:96.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 12 Landi I, Glicksberg BS, Lee HC, Cherng S, Landi G, Danieletto M, 等. 电子健康记录的深度表示学习以解锁大规模患者分层。NPJ数字医学。2020年；3:96。
- en: 13 Fridgeirsson EA, Sontag D, Rijnbeek P. Attention-based neural networks for
    clinical prediction modelling on electronic health records. BMC Medical Research
    Methodology:285.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 13 Fridgeirsson EA, Sontag D, Rijnbeek P. 基于注意力的神经网络用于电子健康记录的临床预测建模。BMC医学研究方法论：285。
- en: '14 Choi E, Xu Z, Li Y, Dusenberry M, Flores G, Xue E, et al. Learning the graphical
    structure of electronic health records with graph convolutional transformer. In:
    AAAI; 2020\. .'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 14 Choi E, Xu Z, Li Y, Dusenberry M, Flores G, Xue E, 等. 使用图卷积变换器学习电子健康记录的图形结构。在：AAAI；2020年。
- en: '15 Xiao C, Choi E, Sun J. Opportunities and challenges in developing deep learning
    models using electronic health records data: a systematic review. Journal of the
    American Medical Informatics Association. 2018;25:1419-28.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 15 Xiao C, Choi E, Sun J. 使用电子健康记录数据开发深度学习模型的机会与挑战：一项系统评审。美国医学信息学学会杂志。2018年；25:1419-28。
- en: '16 Wornow M, Thapa R, Steinberg E, Fries J, Shah N. Ehrshot: An ehr benchmark
    for few-shot evaluation of foundation models. NeurIPS. 2023.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 16 Wornow M, Thapa R, Steinberg E, Fries J, Shah N. Ehrshot：用于基础模型少样本评估的EHR基准。NeurIPS.
    2023年。
- en: '17 Wu Q, Bansal G, Zhang J, Wu Y, Zhang S, Zhu E, et al. Autogen: Enabling
    next-gen llm applications via multi-agent conversation framework. arXiv preprint
    arXiv:230808155\. 2023.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 17 Wu Q, Bansal G, Zhang J, Wu Y, Zhang S, Zhu E, 等. Autogen：通过多智能体对话框架启用下一代LLM应用。arXiv预印本
    arXiv:230808155。2023年。
- en: '18 Talebirad Y, Nadiri A. Multi-agent collaboration: Harnessing the power of
    intelligent llm agents. arXiv preprint arXiv:230603314\. 2023.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 18 Talebirad Y, Nadiri A. 多智能体协作：利用智能LLM代理的力量。arXiv预印本 arXiv:230603314。2023年。
- en: '19 Jin Q, Yang Y, Chen Q, Lu Z. Genegpt: Augmenting large language models with
    domain tools for improved access to biomedical information. Bioinformatics. 2024;40:btae075.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 19 Jin Q, Yang Y, Chen Q, Lu Z. Genegpt：通过领域工具增强大型语言模型，以改善生物医学信息的访问。Bioinformatics.
    2024;40:btae075。
- en: 20 Thirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan TF, Ting DSW.
    Large language models in medicine. Nature medicine. 2023;29(8):1930-40.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 20 Thirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan TF, Ting DSW.
    医学中的大型语言模型。自然医学。2023年；29(8):1930-40。
- en: '21 He K, Mao R, Lin Q, Ruan Y, Lan X, Feng M, et al.. A Survey of Large Language
    Models for Healthcare: from Data, Technology, and Applications to Accountability
    and Ethics; 2023.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 21 He K, Mao R, Lin Q, Ruan Y, Lan X, Feng M, 等. 大型语言模型在医疗保健中的调查：从数据、技术和应用到问责制和伦理；2023年。
- en: 22 Peng C, Yang X, Chen A, Smith KE, PourNejatian N, Costa AB, et al. A study
    of generative large language model for medical research and healthcare. npj Digital
    Medicine. 2023;6:210.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 22 Peng C, Yang X, Chen A, Smith KE, PourNejatian N, Costa AB, 等. 生成型大型语言模型在医学研究和医疗保健中的研究。npj数字医学。2023年；6:210。
- en: '23 Agrawal M, Hegselmann S, Lang H, Kim Y, Sontag D. Large language models
    are few-shot clinical information extractors. In: EMNLP; 2022\. .'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 23 Agrawal M, Hegselmann S, Lang H, Kim Y, Sontag D. 大型语言模型是少样本临床信息提取器。在：EMNLP；2022年。
- en: '24 Mannhardt N, Bondi-Kelly E, Lam B, O’Connell C, Asiedu M, Mozannar H, et al..
    Impact of Large Language Model Assistance on Patients Reading Clinical Notes:
    A Mixed-Methods Study; 2024.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 24 Mannhardt N, Bondi-Kelly E, Lam B, O’Connell C, Asiedu M, Mozannar H, 等.
    大型语言模型对患者阅读临床记录的影响：一项混合方法研究；2024年。
- en: 25 Liévin V, Hother CE, Motzfeldt AG, Winther O. Can large language models reason
    about medical questions? Patterns. 2024;5:100943.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 25 Liévin V, Hother CE, Motzfeldt AG, Winther O. 大型语言模型能否推理医学问题？Patterns. 2024;5:100943。
- en: 26 Han T, Adams LC, Papaioannou JM, Grundmann P, Oberhauser T, Löser A, et al.
    MedAlpaca–an open-source collection of medical conversational AI models and training
    data. arXiv preprint arXiv:230408247\. 2023.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 26 Han T, Adams LC, Papaioannou JM, Grundmann P, Oberhauser T, Löser A, 等. MedAlpaca——一个开源的医疗对话AI模型和训练数据集合。arXiv预印本
    arXiv:230408247。2023年。
- en: '27 Wang G, Yang G, Du Z, Fan L, Li X. ClinicalGPT: large language models finetuned
    with diverse medical data and comprehensive evaluation. arXiv preprint arXiv:230609968\.
    2023.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 27 Wang G, Yang G, Du Z, Fan L, Li X. ClinicalGPT：用多样化的医学数据和全面评估微调的大型语言模型。arXiv预印本
    arXiv:230609968。2023年。
- en: '28 Yuan J, Tang R, Jiang X, Hu X. Large language models for healthcare data
    augmentation: An example on patient-trial matching. In: AMIA Annual Symposium
    Proceedings. vol. 2023; 2023\. p. 1324.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 28 Yuan J, Tang R, Jiang X, Hu X. 用于医疗保健数据增强的大型语言模型：以患者试验匹配为例。在：AMIA年会论文集。第2023卷；2023年。第1324页。
- en: '29 D’Antonoli TA, Stanzione A, Bluethgen C, Vernuccio F, Ugga L, Klontzas ME,
    et al. Large language models in radiology: fundamentals, applications, ethical
    considerations, risks, and future directions. Diagnostic and Interventional Radiology.
    2024;30:80.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 29 D’Antonoli TA, Stanzione A, Bluethgen C, Vernuccio F, Ugga L, Klontzas ME,
    等. 大型语言模型在放射学中的应用：基础、应用、伦理考虑、风险和未来方向。诊断与介入放射学。2024年；30:80。
- en: 30 Yang X, Chen A, PourNejatian N, Shin HC, Smith KE, Parisien C, et al. A large
    language model for electronic health records. npj Digital Medicine:194.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 30 Yang X, Chen A, PourNejatian N, Shin HC, Smith KE, Parisien C, 等. 用于电子健康记录的大型语言模型。npj数字医学:194。
- en: 31 Sivarajkumar S, Kelley M, Samolyk-Mazzanti A, Visweswaran S, Wang Y. An empirical
    evaluation of prompting strategies for large language models in zero-shot clinical
    natural language processing. arXiv preprint arXiv:230908008\. 2023.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 31 Sivarajkumar S, Kelley M, Samolyk-Mazzanti A, Visweswaran S, Wang Y. 对大型语言模型在零样本临床自然语言处理中的提示策略进行的实证评估。arXiv预印本
    arXiv:230908008。2023。
- en: 32 Hu Y, Chen Q, Du J, Peng X, Keloth VK, Zuo X, et al. Improving large language
    models for clinical named entity recognition via prompt engineering. Journal of
    the American Medical Informatics Association. 2024:ocad259.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 32 Hu Y, Chen Q, Du J, Peng X, Keloth VK, Zuo X, 等. 通过提示工程提高临床命名实体识别的大型语言模型。美国医学信息学协会杂志。2024:ocad259。
- en: '33 Lu Y, Zhao X, Wang J. Medical knowledge-enhanced prompt learning for diagnosis
    classification from clinical text. In: Clinical Natural Language Processing Workshop;
    2023\. p. 278-88.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 33 Lu Y, Zhao X, Wang J. 医学知识增强的提示学习用于临床文本的诊断分类。载于：临床自然语言处理研讨会；2023。第278-88页。
- en: '34 Sivarajkumar S, Wang Y. Healthprompt: A zero-shot learning paradigm for
    clinical natural language processing. In: AMIA Annual Symposium Proceedings. vol.
    2022; 2022\. p. 972.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 34 Sivarajkumar S, Wang Y. Healthprompt：一种用于临床自然语言处理的零样本学习范式。载于：AMIA年会论文集。第2022卷；2022。第972页。
- en: 35 Wei J, Wang X, Schuurmans D, Bosma M, Xia F, Chi E, et al. Chain-of-thought
    prompting elicits reasoning in large language models. NeurIPS. 2022;35.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 35 Wei J, Wang X, Schuurmans D, Bosma M, Xia F, Chi E, 等. 思维链提示在大型语言模型中引发推理。NeurIPS。2022;35。
- en: 36 Johnson AE, Pollard TJ, Shen L, Lehman LwH, Feng M, Ghassemi M, et al. MIMIC-III,
    a freely accessible critical care database. Scientific data. 2016;3:1-9.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 36 Johnson AE, Pollard TJ, Shen L, Lehman LwH, Feng M, Ghassemi M, 等. MIMIC-III，一个开放获取的重症监护数据库。科学数据。2016;3:1-9。
- en: '37 Wu J, Roy J, Stewart WF. Prediction modeling using EHR data: challenges,
    strategies, and a comparison of machine learning approaches. Medical care. 2010;48:S106-13.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 37 Wu J, Roy J, Stewart WF. 使用EHR数据的预测建模：挑战、策略及机器学习方法的比较。医疗护理。2010;48:S106-13。
- en: '38 Goldstein BA, Navar AM, Pencina MJ, Ioannidis JP. Opportunities and challenges
    in developing risk prediction models with electronic health records data: a systematic
    review. Journal of the American Medical Informatics Association: JAMIA. 2017;24:198.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 38 Goldstein BA, Navar AM, Pencina MJ, Ioannidis JP. 利用电子健康记录数据开发风险预测模型的机遇与挑战：系统评价。美国医学信息学协会杂志：JAMIA。2017;24:198。
- en: '![Refer to caption](img/1d710b4c1fa380735ab85a93c7c44c8d.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/1d710b4c1fa380735ab85a93c7c44c8d.png)'
- en: 'Figure 3: Prompt for Predictor Agent in EHR-CoAgent for the CRADLE dataset.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '图3: CRADLE数据集中的EHR-CoAgent的预测代理提示。'
- en: '![Refer to caption](img/3671291764e1935f13d8692b770d6832.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/3671291764e1935f13d8692b770d6832.png)'
- en: 'Figure 4: Prompt for Critic Agent in EHR-CoAgent for the CRADLE dataset.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '图4: CRADLE数据集中的EHR-CoAgent的批评代理提示。'
