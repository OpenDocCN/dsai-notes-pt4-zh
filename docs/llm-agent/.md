<!--yml

category: 未分类

日期：2025-01-11 11:58:11

-->

> 来源：[https://arxiv.org/html/2411.05349/](https://arxiv.org/html/2411.05349/)

marginparsep 已被修改。

topmargin 已被修改。

marginparwidth 已被修改。

marginparpush 已被修改。

页面布局违反了ICML样式规范。请不要更改页面布局，或使用像geometry、savetrees或fullpage这样的包，它们会自动为您更改布局。我们无法可靠地撤销对样式的任意更改。请移除相关的包或布局更改命令，然后重试。

提升集群韧性：基于LLM-代理的自主智能集群诊断系统与评估框架

匿名作者^(1 )

###### 摘要

最近，大型语言模型（LLMs）及相关技术，如检索增强生成（RAG）和思维图（DoT）取得了显著进展，使得创建能够执行集群诊断和故障排除的自主智能系统成为可能。通过将这些技术与自我对弈方法相结合，我们开发了一种LLM-代理系统，旨在自主诊断和解决AI集群中的问题。我们的创新包括为集群诊断量身定制的知识库、增强的LLM算法、针对代理的实际部署策略，以及专门用于评估LLM在该领域能力的基准。通过在多个维度的广泛实验，我们展示了我们的系统在应对集群诊断挑战方面的优越性，尤其是在检测和修复性能问题方面，比传统方法更加高效和准确。

^†^†脚注：¹匿名机构，匿名城市，匿名地区，匿名国家。通信作者：匿名作者 <anon.email@domain.com>。

初步工作。正在接受机器学习与系统（MLSys）会议的审稿。请勿传播。

## 1 引言

最近，大型语言模型（LLM）以及补充技术，如基于检索的生成（RAG）和思维图（DoT）的进展，为开发能够执行集群诊断和故障排除的自主智能系统铺平了道路。通过将这些技术与自我对弈方法结合，我们创建了一个LLM代理系统，旨在自主诊断并解决AI集群中的问题。我们创新的方法包括建立专门的集群诊断知识库、增强LLM算法以更好地满足该领域的需求、为代理在现实环境中的实际部署制定策略，并开发一个专门的基准测试，专门用于评估LLM在集群诊断中的能力。这些组成部分共同构成了一个强大的框架，解决了管理AI集群中的复杂性，尤其是在涉及性能下降或其他操作异常的场景中。

通过严格的实验，我们验证了LLM代理系统在多个维度上的有效性。我们的基准测试由150个手工设计的高级问题组成，作为全面的评估工具，突出显示了我们增强的LLM代理与基准开源模型之间的性能差异。在实际应用中，LLM代理展示了其比传统方法更高效地识别和解决性能问题的能力，显著减少了故障排除的时间。例如，在一个模拟场景中，当一台GPU被限制到远低于正常频率时，我们的系统在几分钟内识别并解决了问题，而传统方法则需要资深操作工程师近一个小时，通过预先编写的自动化检测软件来诊断和修复问题。

此外，LLM代理在性能下降尚未被人工操作员察觉之前就能检测并采取纠正措施，这标志着主动系统维护的一个重要进展。此能力不仅可以减轻即时问题，还通过预防潜在故障，提升集群的整体可用性和可靠性。通过利用RAG和DoT的优势，LLM代理能够自主执行修复措施，从而解放工程资源，专注于更复杂和更具价值的任务。我们的研究强调了将AI驱动的诊断与实际部署策略相结合的变革性潜力，为智能集群管理解决方案的新时代奠定了基础。

## 2 相关工作

### 2.1 LLM的对齐与增强

近年来，以大型语言模型（LLMs）为核心的生成性人工智能得到了快速发展，专有模型如GPT系列Achiam等人（[2023](https://arxiv.org/html/2411.05349v1#bib.bib1)）和Gemini系列Team等人（[2023](https://arxiv.org/html/2411.05349v1#bib.bib27)）展示了强大的自然语言生成能力，以及开源模型如LlamaDubey等人（[2024](https://arxiv.org/html/2411.05349v1#bib.bib7)）和QwenYang等人（[2024](https://arxiv.org/html/2411.05349v1#bib.bib34)）也取得了显著进展。

在不同阶段（如训练、推理和部署）以及在数据、算法和计算资源等领域，有多种方法可以增强LLMs的能力。鉴于自回归模型如GPT-2（仅解码器变换器）Radford等人（[2019](https://arxiv.org/html/2411.05349v1#bib.bib23)）和LLaMA（变换器++）Touvron等人（[2023](https://arxiv.org/html/2411.05349v1#bib.bib28)）的成就，提高数据质量已成为提升模型在预训练过程中效能的关键方法Adler等人（[2024](https://arxiv.org/html/2411.05349v1#bib.bib2)）；Liu等人（[2024](https://arxiv.org/html/2411.05349v1#bib.bib15)）。

对于现代的LLMs，存在多个训练或微调工作，涵盖预训练和部署之间的过程。ChatGPT Ouyang等人（[2022](https://arxiv.org/html/2411.05349v1#bib.bib18)）将这个过程描述为监督微调（SFT）、奖励建模（RM）和带有人工反馈的强化学习（RLHF），而LLaMA3.1 Dubey等人（[2024](https://arxiv.org/html/2411.05349v1#bib.bib7)）将这些集成到一个被称为“继续训练”的连续过程之中。除了训练，LLMs还可以利用检索增强生成（RAG）Lewis等人（[2020](https://arxiv.org/html/2411.05349v1#bib.bib14)）来利用未包含在训练集中的数据分布中的知识。我们可以将上述内容称为LLMs的对齐和增强。

### 2.2 基于AI代理的应用

在冻结模型参数后，可以通过诸如链式思维（CoT）推理Wei等人（[2022](https://arxiv.org/html/2411.05349v1#bib.bib30)）、扩展测试时间Snell等人（[2024](https://arxiv.org/html/2411.05349v1#bib.bib26)）以及将CoT LLM和AI代理结合使用Castelfranchi（[1998](https://arxiv.org/html/2411.05349v1#bib.bib4)）作为LLM-agentPark等人（[2023](https://arxiv.org/html/2411.05349v1#bib.bib19)）等机制来增强模型的固有能力。

CoT 是一种提示技术，用于引导大型语言模型（LLMs）在得出最终结论之前生成中间推理步骤。经典 CoT 的扩展包括思维树（Tree of Thought，ToT）Yao 等人（[2024](https://arxiv.org/html/2411.05349v1#bib.bib35)）用于树状回溯，思维图（Graph of Thought，GoT）Besta 等人（[2024](https://arxiv.org/html/2411.05349v1#bib.bib3)）用于基于图的推理，以及思维图谱（Diagram of Thought，DoT）Zhang 等人（[2024](https://arxiv.org/html/2411.05349v1#bib.bib36)）用于基于拓扑理论的建议-批评-总结方法。

CoT 的发展与测试时间的扩展是统一的，CoT 的应用始终旨在在有限的测试时间内保持最佳结果，或通过扩展测试时间来实现卓越的成果Snell 等人（[2024](https://arxiv.org/html/2411.05349v1#bib.bib26)）。CoT 系列技术也是构建 LLM 代理的基础之一。LLM 代理可以利用 LLM 作为处理核心，同时整合传统的 AI 代理能力，如记忆、规划和执行，从而创建出高度适应性强、具有半自主功能的软件实体Xi 等人（[2023](https://arxiv.org/html/2411.05349v1#bib.bib31)）。

### 2.3 AI 集群的诊断与修复

构建和利用 LLM 应用程序通常需要规模庞大的硬件基础设施，成本高达数百万美元或更多。Meta 在 54 天内构建了 LLM 应用核心 LLaMA 3.1，使用了一个包括 16,000 个 GPU 的集群Dubey 等人（[2024](https://arxiv.org/html/2411.05349v1#bib.bib7)），仅 GPU 成本就超过了十亿美元。然而，这种复杂且昂贵的系统在可靠性和可用性方面面临重大挑战。在这 54 天的训练期间，Meta 集群经历了 419 次意外中断，平均每三小时一次。由于中断频率如此之高，集群从操作系统到 AI 框架再到分布式调度软件，都需要具备捕获、识别、归因和修复异常的能力，以确保模型训练的成功与高效。微软的 SuperbenchXiong 等人（[2024](https://arxiv.org/html/2411.05349v1#bib.bib32)）已系统地构建了一套标准测试用例，全面评估集群的可用性。

在捕获和修复方面，TorchPaszke等人（[2019](https://arxiv.org/html/2411.05349v1#bib.bib20)）的弹性解决方案旨在实现模型训练的自动重启，而DLRoverWang等人（[2023](https://arxiv.org/html/2411.05349v1#bib.bib29)）提出的FlashCheckpointing等工作则聚焦于减少自动重启过程中检查点保存和加载的成本。在自动重启功能的基础上，许多AI框架层面的工作进行了研究和实践，以增强可靠性和可用性，特别是那些基于MegatronShoeybi等人（[2019](https://arxiv.org/html/2411.05349v1#bib.bib25)）的高度定制化解决方案。字节跳动的MegascaleJiang等人（[2024](https://arxiv.org/html/2411.05349v1#bib.bib11)）和阿里巴巴的Pai-MegatronQian等人（[2024](https://arxiv.org/html/2411.05349v1#bib.bib22)）都提供了集群诊断工具包，用于检查服务器和网络的健康状况，以及执行手动或自动的错误识别和修复。

随着AI技术的进步，研究人员开始探索利用AI技术解决集群诊断问题。使用大数据技术分析日志文件曾是自动化集群诊断的典型方法Jung & Chung（[2021](https://arxiv.org/html/2411.05349v1#bib.bib13)）。然而，这种方法主要涉及对由训练过程生成的文件进行静态或实时分析，限制了其归因能力，且缺乏智能自主性，而是依赖于预先编写的执行和计划程序。

## 3 个专业术语

AI计算任务：指为实现智能而设计的程序或过程，如训练大规模语言模型、使用大规模语言模型进行推理、世界模型推理和LLM-agent推理。

AI芯片：适用于或专门用于执行AI计算任务的处理器，如NVIDIA GPU、Intel Gaudi AI加速器和Google TPUJouppi等人（[2017](https://arxiv.org/html/2411.05349v1#bib.bib12)）。

AI服务器：配备AI芯片的计算机，适用于或专门设计用于执行AI计算任务，如NVIDIA DGX H100。AI服务器在稳定性、可用性、散热和功耗等方面通常有超出经典服务器的要求。

AI集群：由两个或更多AI服务器组成的分布式服务器集群，用于完成单一目标任务，如Meta的包含16000个GPU的集群。此外，AI服务器通常需要RDMA或更高带宽的互联协议，如InfiniBand RDMAShanley（[2003](https://arxiv.org/html/2411.05349v1#bib.bib24)）和RDMA over Converged Ethernet(RoCE)Guo等人（[2016](https://arxiv.org/html/2411.05349v1#bib.bib8)），通常不采用经典以太网协议。

集群诊断：确保AI计算任务能够在AI集群上正常运行，及时检测任务失败，识别故障点，明确故障原因，修复相应故障，并确保AI集群的整体可用性。

## 4 方法

### 4.1 概述

我们结合了LLM对齐和增强领域的先进技术，创造性地开发了一种基于LLM代理的集群智能维护系统解决方案。图[1](https://arxiv.org/html/2411.05349v1#S4.F1 "Figure 1 ‣ 4.1 Overview ‣ 4 Methods")展示了这一解决方案的整体过程。

![参见标题](img/57277a91c716539fc250810a8b238cfe.png)

图 1：基于LLM代理的智能维护系统概览

图的上半部分代表了解决方案的核心组件：LLM代理。LLM代理由代理程序和LLM组成。LLM将代理提供的输入信息解释为外部刺激和任务指令，并作出适当响应。然后，代理根据LLM的反馈直接编写代码或调用特定的软件接口，从而操作集群。对于LLM本身，存在两个主要挑战。首先，LLM如何获取集群诊断的领域特定知识，此外，这些知识来自何处。其次，LLM如何进行推理和规划？对于整个LLM代理来说，确保LLM的输入和输出与代理控制集群时执行的实际操作匹配，是另一个需要解决的关键问题。

为了解决上述问题，我们引入了三项创新。首先，我们使用从GitHub收集的250个集群故障记录作为起点，并将LLM代理实际管理的集群操作故障日志视为一个持续的数据源。我们利用RAGLewis等人（[2020](https://arxiv.org/html/2411.05349v1#bib.bib14)）使LLM能够在上下文中捕捉到与特定术语相对应的详细知识。图[1](https://arxiv.org/html/2411.05349v1#S4.F1 "Figure 1 ‣ 4.1 Overview ‣ 4 Methods")描述了“警报”、“计算集群”和“存储部分”，以及它们与LLM代理的通信，概述了这一过程。第二，我们使用DoTZhang等人（[2024](https://arxiv.org/html/2411.05349v1#bib.bib36)）使得模型能够有效处理非自然语言信息，如符号、公式和代码。类似于视觉-文本多模态模型，我们基于DoT有效地利用超越自然语言固有含义的文本元素。图[1](https://arxiv.org/html/2411.05349v1#S4.F1 "Figure 1 ‣ 4.1 Overview ‣ 4 Methods")顶部的“规划算法”部分展示了这一创新。第三，我们使用自我博弈技术Snell等人（[2024](https://arxiv.org/html/2411.05349v1#bib.bib26)）使LLM能够自主且智能地将长任务或具有挑战性的推理目标分解为多个步骤，自动评估每个步骤的输出，最终实现目标。

图[1](https://arxiv.org/html/2411.05349v1#S4.F1 "Figure 1 ‣ 4.1 Overview ‣ 4 Methods")的下半部分构成了我们工作的基础。它包括一个成熟的操作报警故障排除与修复流程，以及几个成熟或先进的软件工具。基于相关工作，我们开发了一个统一的、多层次的、多维度的集群诊断工具包，如图[2](https://arxiv.org/html/2411.05349v1#S4.F2 "Figure 2 ‣ 4.1 Overview ‣ 4 Methods")所示。

![参见说明文字](img/9288a57e69a14403bc49f19455edc4b9.png)

图2：LLM代理诊断AI集群的工具

本工具从供给方和需求方同时诊断集群的健康状态。如图[2](https://arxiv.org/html/2411.05349v1#S4.F2 "Figure 2 ‣ 4.1 Overview ‣ 4 Methods")的底部部分所示，列出了构建AI集群所需的各种组件，包括计算组件、存储组件、网络组件等。采用不同技术路线的AI集群提供相似的能力，如图[2](https://arxiv.org/html/2411.05349v1#S4.F2 "Figure 2 ‣ 4.1 Overview ‣ 4 Methods")中部所示。我们检查所有影响AI计算任务的资源供给项目，确定其内容是否正确，性能是否适当，以及是否稳定。例如，对于跨服务器两个GPU之间的RDMA读写特性，我们的工具检查读写内容是否正确，IOPS、带宽、延迟等性能指标是否适当，以及在长时间或多进程读写等复杂场景下的稳定性。这些工具大多是芯片、服务器或操作系统厂商提供的软件包的改进版。图[2](https://arxiv.org/html/2411.05349v1#S4.F2 "Figure 2 ‣ 4.1 Overview ‣ 4 Methods")的顶部部分考虑了需求方，评估具有不同特征的AI计算任务所关注的指标。

总结来说，我们已经构建了一个能够检索和利用大量外部信息、具备自主规划、学习、推理和执行能力的LLM-agent。该LLM-agent与定制的工具或现有的成熟工具协作，执行集群的预警、故障排除和修复任务。

### 4.2 集群诊断领域特定知识库

我们的知识库由两个部分组成。一部分是日志、监控信息或程序输出内容，来源于预先收集、清洗和整理的GitHub数据，这些数据经过精心挑选，旨在解决集群诊断和故障排除领域的痛点，融入了来自GitHub社区问题的知识，也来自于LLM-agent初步部署和运营后获取的操作数据。我们称之为诊断数据集。第二部分由符号推理构成。这些推理结构使用AI计算任务和硬件规格信息作为输入，通过自下而上的建模方法，预测给定AI计算任务的理论性能，从而判断性能的正确性。

#### 4.2.1 诊断数据集

我们借鉴了阿里巴巴在管理集群启动操作方面的有效经验（Xu et al. ([2024](https://arxiv.org/html/2411.05349v1#bib.bib33))）来构建数据库。我们对从 GitHub 获得的非结构化数据进行了清理、整理和结构化，最终形成了有效的数据集。我们从 GitHub 问题区收集了超过一千个问题和反馈项。通过自动化处理和人工审核，我们筛选出了200多个具有实质性知识内容和良好结构的问答格式。每条整理后的数据包含四个字段：问题关键字（problemkey）、原始文本（rawtext）、功能（function）和结果（result）。

问题关键字是通过人工识别或基于 OpenAI o1 识别的领域关键词。Rawtext 指的是经过简单格式化后网站的原始内容，存储为包含网页上提问问题和开发者回应的长字符串。该功能基于我们的集群诊断工具包，并由集群故障排查人员手动关联。此部分作为注释使用于模型可以感知的数据集部分，模型在基准评估部分使用的答案不被感知，它作为 LLM-agent 部署后知识获取的起点。最终结果是基于开发者回答从 rawtext 中提取出的故障原因。对于能够驱动代理执行集群诊断的 LLM，我们期望它能够基于来自集群的实时操作信息确定故障原因，并能够即时调用现有工具或编写工具代码进行集群修复，而无需依赖包含开发者回复的 rawtext。我们将在后续实验中展示这一能力。

#### 4.2.2 性能建模

我们使用一系列渐进方法来建模给定 AI 计算任务的正确表现，并通过 DoT 将这种特殊模式数据转换为令牌，输入模型中。除了集群健康检查外，我们还在工具包中加入了模块，以判断不同的 AI 计算任务是否表现正确。这些模块一方面可以被代理调用，向 LLM 提供结果以供分析；另一方面，它们也可以被 LLM 调用，指示代理检查集群状态。

我们从最简单的任务类型开始建模。考虑到现有的AI集群是由采用冯·诺依曼架构的计算设备组成，AI计算任务需要使用计算核心、内存和I/O端口。值得注意的是，AI计算任务占用的资源并不仅仅指狭义上的CPU计算核心、主内存或输入/输出端口，而是从更广泛的角度来看，例如专门用于矩阵乘法的计算核心、多级缓存组成的HBM内存，以及由PCIe或RDMA协议形成的高速I/O端口。为了构建统一的模型，我们使用了等效计算能力、等效内存带宽和等效I/O带宽的概念。

我们将占用或主要占用某种资源的计算任务称为单资源计算任务。我们构建了一个单变量计算任务性能模型，并通过基于赫欣定律的大数法则实验获得结果。我们假设对于某一计算任务T，所需的总资源量$R_{i}$为$M_{i}$。运行该任务的硬件每秒可以提供$N_{i}$单位的资源$R_{i}$。假设单变量任务$T_{x}$仅依赖于资源$R_{0}$。我们根据用于任务计算的数学公式确定$M_{0}$。对于$N_{0}$，我们将其视为一个随机变量。通过大量的热身后重复实验，我们确保测量结果与随机变量的期望值之间的差异趋近于零。我们将性能定义为特定任务在单位时间内能够执行的次数。对于上述任务$T_{x}$，我们预测其性能为$\frac{N_{0}}{M_{0}}$。

对于非单变量任务，我们专注于建模它们所依赖的不同资源是否能够并行操作。多变量任务建模中广泛使用的一种方法是屋顶线模型（Roofline Model），此模型由Ofenbeck等人提出（[2014](https://arxiv.org/html/2411.05349v1#bib.bib17)）。屋顶线模型引入了一个新的变量：任务特征$C_{T}$。考虑任务$T_{x}$依赖于两个资源$R_{0}$和$R_{1}$，资源$R_{0}$的有效利用率绘制在Y轴上，资源$R_{0}$和$R_{1}$的有效利用率比绘制在X轴上。通过改变$C_{T}$，可以绘制出一个散点图，形成类似屋顶线的形状。屋顶线模型相当于对多变量任务在完全并行场景下的性能进行建模，但这与现实世界的情况并不一致。此外，在现有的大型语言模型（LLM）性能建模背景下，$C_{T}$的变化并非单一任务的输入大小变化，而是指在总任务中，两个不同主要资源消耗任务的比例变化。

![参考说明](img/8bb86c16fb87b06e5996c4912c3d627c.png)

图3：多变量任务性能建模。A表示计算-内存，B表示互联-内存，C表示互联-计算

因此，我们使用不同子任务的比例作为变量，来对AI集群提供的三大主要资源进行多变量任务建模：矩阵乘法的等效浮点计算能力、内存读写带宽和I/O端口带宽。图[3](https://arxiv.org/html/2411.05349v1#S4.F3 "Figure 3 ‣ 4.2.2 Performance Modeling ‣ 4.2 Cluster Diagnosis Domain-specific Knowledge Base ‣ 4 Methods")中的结果显示，计算和内存处于完全无法并行化的领域，而计算、内存和I/O端口则可以接近完全并行化。这个结论和相关图表已被整理并放入RAG文档中。

### 4.3 使用RAG-DoT-Selfplay技术创建LLM智能体

#### 4.3.1 使用RAG构建一个可以利用外部知识的LLM

RAG集成了两个核心组件：检索和生成。检索模块负责从外部知识库中找到与上下文相关的信息，这个过程通常涉及对大量文档进行索引，以便快速定位最相关的片段。然后，将检索到的信息作为额外的输入传递给生成模块。生成模块建立在预训练的语言模型基础上，利用检索到的上下文来增强其生成能力，从而产生更加准确、与实际情况更匹配的响应。

考虑到其他类似技术，SFT需要大量计算资源，并可能降低模型固有的泛化能力。上下文学习会消耗上下文长度和推理时间，这使得它不适合导入包含数百万条数据的数据库。RAG可以在推理过程中以最小的资源和推理时间获取相关知识，而无需改变模型本身的权重。

#### 4.3.2 使用DoT构建一个可以推理和规划的智能体

DoT（思维图）张等人（[2024](https://arxiv.org/html/2411.05349v1#bib.bib36)）将LLM中的迭代推理建模为在单一模型内构建有向无环图（DAG）。该DAG由表示命题、批评、修正和验证的节点组成，边则表示它们之间的逻辑关系或依赖性。我们使用XML处理多模态特殊符号数据，并基于DoT进行推理。

基于DoT的原理，我们使用XML标签来区分不同类型的文本，包括纯文本、特殊符号、代码、公式和推理规则。得益于LLama3.1采用的绳索位置编码，模型可以准确地捕捉XML对中的内容。基于推理图，我们的实验验证了这一应用使LLM能够根据特定规则进行正确推理，具备支持代理完成集群故障归因和修复任务的能力。这大大超越了预训练或对齐LLM的能力。

#### 4.3.3 使用自对弈技术构建特定领域的多模态代理

在RAG和DoT的帮助下，LLM可以利用来自训练集外部的信息以及抽象的符号推理信息。然而，这对于设计用于智能集群诊断的代理来说仍然存在局限性。我们允许LLM在更长时间内生成内容。通过代理的多轮规划自对弈或自发的自我提问和回答，能够提高对挑战性问题解决方案的质量。

自发的自我提问和回答应用于DoT推理。在规划的自对弈过程中，我们将集群故障归因的复杂问题转化为一个三轮的过程。在第一轮中，代理基于从集群传递的错误日志，提示LLM从错误项中识别潜在的关键字，并从知识库中找到对应的解决方案，执行信息提取和RAG。在第二轮中，LLM评估自身的答案，进行修正或直接接受，然后继续编写或调用适当的工具供代理执行。在最后一轮中，LLM基于代理与实际集群交互的结果，做出准确的归因判断。与现有主要集中在文本方面的自对弈工作相比，我们将其与代理结合，赋予其操作机器和与环境互动的权限，充分模拟人类工程师解决问题的能力。

## 5 实验

我们进行了三阶段实验，以展示所提出的LLM代理在集群智能诊断领域的先进性。第一阶段涉及创建数据集和集群智能诊断领域的基准。首先，我们定义外部数据知识库的统计特征，并介绍如何从该知识库生成评估基准的过程。接下来，我们描述该基准的特点，并解释其在集群智能诊断领域的先进性。在整个过程中，我们强调公平性和公正性，严格区分模型可感知部分与评估的评分部分。我们进一步利用主流开源模型LLaMA3.1-70B的结果来详细阐述基准。

第二阶段涉及使用上述基准对我们提出的三种模型——RAG、DoT和selfplay——的创新性进行评估。第二阶段的实验旨在展示我们提出的模型在集群智能诊断领域的先进性。

在第三阶段，我们将LLM代理暴露于基准的训练集和测试集中，允许其以最完整的形式运行，解决生产环境中遇到的现实问题。我们通过两个典型案例展示了该解决方案的准确性、效率和自主智能。具体而言，我们发现该解决方案能够为AI集群提供早期预警，进一步提高集群的可用性。

最后，我们将对正确性、安全性和可靠性等问题进行定性分析和讨论，这些问题是LLM和LLM代理领域的前沿问题，至今尚未得到定论，以展示我们在这些领域开展的一系列工作。

### 5.1 数据集和基准的统计与评估

#### 5.1.1 数据来源

提供给LLM的材料来自三个来源。第一个来源是自动收集的来自与AI集群故障排除相关的GitHub社区的问答数据，例如Megatron、PAI、Deepspeed和NCCL等代码库的问题部分。这些数据作为我们的初始数据集。这些数据经过了两轮筛选，包括自动和手动筛选，保留了具有清晰解决方案和逻辑对话的部分。第二个来源是LLM代理使用RAG+DoT技术在多个AI集群上执行任务时获得的程序输出。这些任务是在4到100台A800 AI服务器组成的集群上执行的。第三部分是根据DoT逻辑，使用XML处理的特殊模态数据，如符号表示和公式，所有这些数据统一为文本模态。

纯文本材料的总量为200+项，与1.2GB的原始文件相比。这也证实了，如果超过200项内容是纯文本，并且已完全预先分词作为LLM推理的上下文，它不仅对LLM处理长文本的能力构成了重大挑战，而且增加了推理资源的消耗，从而减慢了LLM代理的执行速度。

#### 5.1.2 基准测试的来源及统计数据

我们将原始数据集分为两部分，约为20%-80%的比例。从80%的数据中，我们手动编写了150个问题，以评估LLM在集群诊断领域的能力。在比较实验中，除非另有说明，我们只向所有模型提供20%的原始数据。在案例研究和实际应用中，我们向部署的LLM代理提供完整的原始数据集。

我们设计了三个评估指标。指标A评估大模型的信息提取能力，包括从对话中提取集群IP地址和SSH端口号的能力，以及判断是否需要进一步执行的能力，通过字符串匹配来评估。这里的挑战是评估模型遵循指令并提取信息的能力，因为日志来源于用户对话，并可能包含需要在判断过程中忽略的无关命令。指标B评估大模型在诊断领域的代码生成能力，包括根据对话中的描述生成规定的代码、控制代码的输入输出，并创建看不见的测试用例，采用类似于人类评估的方法（Chen等人，[2021](https://arxiv.org/html/2411.05349v1#bib.bib5)），但转移到一个真实的分布式集群上。指标C评估大模型在诊断领域的信息归因能力，包括根据用户的错误日志和信息提供归因的能力。目前，这通过多项选择题的方式实现。

#### 5.1.3 标准LLaMA3.1-70B上的基准测试评估

我们将这个基准测试应用于几种最广泛使用的开源LLM，包括LLaMA3.1-70B、nemotron-70B（Adler等人，[2024](https://arxiv.org/html/2411.05349v1#bib.bib2)）、mistral-120B（Jiang等人，[2023](https://arxiv.org/html/2411.05349v1#bib.bib10)）和llama3.2 3B。

表1：开源LLM的基准测试结果

| 模型 | 在1个A800 GPU上的推理 | 在1个A800*8服务器上的推理 | 在指标A上的得分 | 在指标B上的得分 | 在指标C上的得分 |
| --- | --- | --- | --- | --- | --- |
| Llama3.1-70B | 否 | 是 | 0.8658 | 0.0 | 0.0 |
| Nemotron-70B | 否 | 是 | 0.7315 | 0.0 | 0.0 |
| Mistral-120B | 否 | 否 | 0.7383 | 0.0 | 0.0 |
| Llama3.2-3B | 是 | 是 | 0.047 | 0.0 | 0.0 |

结果如表[1](https://arxiv.org/html/2411.05349v1#S5.T1 "Table 1 ‣ 5.1.3 Evaluation of Benchmark on Standard LLaMA3.1-70B ‣ 5.1 Statistics and Evaluation for Dataset and Benchmark ‣ 5 EXPERIMENTS")所示。由于缺乏相关数据和信息，以及诸如DoT之类的推理逻辑，所有模型只能完成第一个任务，第二个和第三个任务的得分为零。由于llama3.2 3B的结果未达到构建LLM-代理所需的最低要求，并且120B模型在单个AI服务器上推理困难，我们选择了两款70B模型中表现更好且使用更广泛的LLama3.1-70B作为后续SFT（监督微调）以及RAG、DoT和自我博弈应用的基础。

### 5.2 LMMs的评估

#### 5.2.1 实验设置

我们进行了两部分实验，以全面评估并比较我们工作的创新效果。在第一部分，我们使用成熟且通用的MMLUHendrycks等人（[2020](https://arxiv.org/html/2411.05349v1#bib.bib9)）基准来评估模型在经过RAG、DoT和自我博弈增强后的基础文本理解的综合能力。在第二部分，通过消融和对比实验，结合我们提出的基准中子项目的重点领域，我们定量展示了我们三项创新的优势。

#### 5.2.2 基于MMLU的综合能力评估

首先，我们旨在证实为何在该领域不建议使用SFT。尽管支持代理的LLM需要具备广泛的知识，如集群诊断、性能建模和代码编写，但我们发现当LLM达到能够有效应用这些知识的水平时，它通常缺乏与代理交互所需的基本能力。我们通过MMLU基准来说明这一点。

表2：MMLU基准在LLama3.1和Nemotron 70B上的结果

| 模型 | 是否进行SFT | MMLU得分 |
| --- | --- | --- |
| Llama3.1-70B | 否 | 0.8230 |
| Llama3.1-70B | 是 | 0.8007 |
| Nemotron-70B | 否 | 0.8234 |
| Nemotron-70B | 是 | 0.7917 |

我们将知识库转换成与模型兼容的令牌，并构建了一个指令数据集。我们通过多轮训练迭代，直到模型能够正确响应指令。然后，我们使用多机器学习理解（MMLU）基准评估了达到此状态的SFT模型，并与原始开源模型进行了比较。结果如表[2](https://arxiv.org/html/2411.05349v1#S5.T2 "Table 2 ‣ 5.2.2 General Capability Evaluation Based on MMLU ‣ 5.2 LMMs’ Evaluation ‣ 5 EXPERIMENTS")所示。

从上述结果可以看出，使用 MMLU 等通用评估方法进行评估时，监督微调（SFT）会导致性能下降。随后，在我们提出的集群诊断基准中，我们进一步观察到这一性能下降对指标 C 的不利影响。因此，我们最终决定不使用 SFT 方法来构建 LLM-agent。

为了避免仅依赖 MMLU 可能带来的风险，我们进一步选择了三个与我们在领域中解决的问题密切相关或完全具有普遍性的 LLM 基准：抽象与推理挑战（ARC）Peter ([2022](https://arxiv.org/html/2411.05349v1#bib.bib21)），BoolQClark 等 ([2019](https://arxiv.org/html/2411.05349v1#bib.bib6))，以及 OpenbookQAMihaylov 等 ([2018](https://arxiv.org/html/2411.05349v1#bib.bib16))。结果呈现在表格 [3](https://arxiv.org/html/2411.05349v1#S5.T3 "Table 3 ‣ 5.2.2 General Capability Evaluation Based on MMLU ‣ 5.2 LMMs’ Evaluation ‣ 5 EXPERIMENTS") 中。

表 3：LLMs 的多综合基准结果

| 模型 | 是否 SFT | ARC | ARC 简易版 | BoolQ | Open bookQA | MMLU |
| --- | --- | --- | --- | --- | --- | --- |
| Llama3.1-70B | 否 | 0.6246 | 0.8691 | 0.8786 | 0.3720 | 0.8230 |
| Llama3.1-70B | 是 | 0.6032 | 0.8649 | 0.8862 | 0.3680 | 0.8007 |
| Nemotron-70B | 否 | 0.6280 | 0.8620 | 0.8780 | 0.3680 | 0.8234 |
| Nemotron-70B | 是 | 0.6126 | 0.8653 | 0.8859 | 0.3580 | 0.7917 |
| Mistral-120B | 否 | 0.6544 | 0.8788 | 0.9012 | 0.3980 | 0.8229 |
| Llama3.2-3B | 否 | 0.4352 | 0.7428 | 0.7835 | 0.2800 | 0.6040 |

这一组实验的结果支持了我们从 MMLU 基准中得出的结论。

#### 5.2.3 我们的基准结果

表 [4](https://arxiv.org/html/2411.05349v1#S5.T4 "Table 4 ‣ 5.2.3 Results of Our Benchmark ‣ 5.2 LMMs’ Evaluation ‣ 5 EXPERIMENTS") 展示了我们所有的实验结果。

表 4：开源 LLM（基准）和我们的 LLM-agent 的基准结果

| 模型 | “作弊” | 方法 | 指标 A 得分 | 指标 B 得分 | 指标 C 得分 |
| --- | --- | --- | --- | --- | --- |
| Llama3.1-70B | None | None | 0.8658 | 0.0 | 0.0 |
| Llama3.1-70B | 预写完整代理计划步骤（预先计划） | None | 0.8658 | 0.4615 | 0.6470 |
| Llama3.1-70B | None | SFT | 0.0 | 0.0 | 0.0 |
| Llama3.1-70B | 预先计划 | SFT | 0.0 | 0.9230 | 0.0 |
| Llama3.1-70B | None | RAG | 0.8658 | 0.0 | 0.0 |
| Llama3.1-70B | 预先计划 | RAG | 0.8658 | 0.4615 | 0.7059 |
| Llama3.1-70B | None | RAG + DoT + self-play | 0.8466 | 0.6153 | 0.6470 |
| Llama3.1-70B | None | RAG + DoT + self-play + SFT | 0.0 | 0.9230 | 0.0 |
| Llama3.1-70B | 全数据集 | RAG + DoT + self-play + SFT | 1.0 | 1.0 | 1.0 |
| Llama3.1-70B | 预先计划 + 全数据集 | RAG + DoT + self-play + SFT | 1.0 | 1.0 | 1.0 |
| Nemotron-70B | None | None | 0.7315 | 0.0 | 0.0 |
| Nemotron-70B | 预先计划 | None | 0.7315 | 0.4615 | 0.7059 |
| Mistral-120B | None | None | 0.7383 | 0.0 | 0.0 |
| Mistral-120B | 预先计划 | 无 | 0.7383 | 0.7692 | 0.8235 |
| Llama3.2-3B | 无 | 无 | 0.047 | 0.0 | 0.0 |
| Llama3.2-3B | 预先计划 | 无 | 0.047 | 0.2307 | 0.1176 |

表格的第二列表示是否存在“作弊”。我们将那些未公平参与基准测试的实验定义为作弊。虽然这对于基准测试部分是不公平的，但对于我们的核心研究目标——构建一个能够自主智能地进行集群诊断和故障排除的LLM-agent系统——显然具有重要意义。在评估基准测试部分时，可以将作弊项目视为真实情况。

这些实验结果可以得出几个结论。首先，我们发现，预先定义的计划可以帮助一个初步的LLM控制代理。然而，这个计划是专门基于基准测试问题编写的，不能用于生产环境。因此，所有利用DoT技术且不作弊的实验，在评估代理的指标B和C时得分较高，尽管这些得分略低于预先计划的得分。这表明，我们提出的基于DoT和自我对弈的知识处理方法可以用来控制集群故障排除代理。其次，我们发现，SFT显著提高了指标B的得分，该指标侧重于评估代码编写或诊断工具的调用。然而，作为一种权衡，所有经过SFT处理的模型，即使在有预先计划的情况下，也无法正确控制代理，导致在指标C上的表现不佳。第三，我们发现，基于LLama3.1-70B的结果与Mistral-120B的结果没有显著差异，后者的参数数量几乎是前者的两倍。两倍的参数量意味着推理成本增加一倍或更多（考虑到多GPU的线性扩展性），这使得其变得不切实际。另一方面，即使在作弊场景下，3B较小的模型，即使有预先计划，也仍然无法处理控制代理的任务。

我们继续进行了后续实验，并在实际部署中使用了增强了整个数据集和所有创新方法的LLM-agent。

### 5.3 智能预警与故障排除：案例研究

为了展示我们构建的LLM-agent系统在智能集群诊断中的优势，我们可以通过一个具体的例子来说明该系统的运行方式以及它相比传统方法更高效和更准确。在AI集群的生产环境中，异常事件或中断并不是最具挑战性的问题。关于异常或中断的清晰信息可以有效地指导资深工程师诊断问题的原因。当前的研究也在逐步将自动重启和自动调度等技术融入到处理AI计算任务中的异常或中断的流程中。然而，一旦AI计算任务出现性能下降，便很难快速识别问题，更难以准确找出性能下降的原因。

假设有一个由几十台服务器组成的AI训练集群，其中一台服务器突然出现性能下降。这可能是由于多种原因，如网络延迟增加、内存泄漏、高CPU负载或存储空间不足。传统上，管理员或工程师会检查集群的日志文件，手动识别可能的问题。这通常需要查看不同节点的日志、监控系统指标、尝试重现问题等。这种方法既耗时又费力，可能需要多次尝试才能找出根本原因。在我们的系统中，LLM-agent会自动从集群的各个节点收集相关的日志信息、性能指标和其他必要的数据。利用LLM-agent通过基准测试评估的能力，系统从收集的数据中提取有用的信息，如集群的IP地址、SSH端口和其他关键诊断细节。借助其在代码生成和信息归属方面的诊断能力，LLM-agent基于收集到的数据和信息确定问题的根本原因。这可能包括生成新的测试用例来验证假设。一旦问题被识别，LLM-agent会生成相应的修复脚本并请求人工审查。审核通过后，LLM-agent将在集群中执行修复措施。执行修复措施后，系统会再次收集数据以评估结果，形成一个数据、算法和硬件的闭环，从而优化未来的诊断过程。

我们手动构建了一个场景。这个场景会导致 AI 模型训练任务的性能变慢，并且在开发环境中多次发生。我们模拟了一个极端的高温情况，伴随 HVAC 故障，限制了几十块 GPU 中其中一块的频率，降至约 200 MHz，而不是 A800 GPU 应该运行的 1410 MHz。观察实际日志显示，这个 AI 计算任务的速度下降到了正常性能的三分之一左右。我们的 LLM 系统最初通过功耗监控和性能建模结果标记出了慢速 AI 任务，并触发了自动警报。随后，通过三轮自我反馈，它建议检查 GPU 核心频率，代理随后将这一建议调度到所有 GPU 上执行。根据执行结果，LLM 精确地找出了我们特意更改过的低频 GPU。整个故障排除过程不到 10 分钟。相比之下，一位资深的运维工程师通常需要大约一小时才能正确识别问题，然后使用工程师预先编写的自动检测工具来确定特定的低频 GPU 故障。更重要的是，我们的 LLM 代理能够在算法工程师或运维工程师察觉到性能下降现象之前，首先识别出故障，并自动完成修复。这实现了在故障发生之前就解决问题，从而提高了集群的整体可用性。

### 5.4 正确性、安全性和可靠性的定性分析

基于现有的尚未完全成熟的研究，并在该特定研究领域的背景下，我们为正确性、安全性和可靠性提供了合理的定义。在本研究中，我们将正确性定义为LLM-agent执行任务的过程和结果是否正确。与评估LLM的输出相比，评估LLM-agent行动的正确性更具挑战性。一个表面上看似不正确的操作过程可能会产生正确的结果，而在文本层面看似完美的输出在执行时可能会导致错误的结果。由于我们专注于集群诊断领域，实际输出为代理执行的程序，因此我们并未调查LLM生成的文本内容中潜在的有害性或偏见。相反，我们考察了当反馈给代理的信息发生变化，甚至当攻击者插入恶意内容时，LLM-agent避免对集群执行有害操作的能力，例如删除文件、关机、超频或修改关键系统配置。关于可靠性，我们将其定义为LLM-agent在处理故障时与人类工程师或专家工程师相比的整体质量。除了是否归因正确外，我们还考虑了完成典型故障处理所需的时间、消耗的资源以及与非专家沟通的能力。

我们将正确性评估纳入基准评估中。对于LLM-agent可能带来的风险，我们实施了一个白名单加人工审查的方法。首先，我们确保现有工具包的安全性，然后为工具包中包含的程序接口创建白名单，并对LLM-agent请求执行自创代码进行人工审查。最后，我们观察到，LLM-agent能够在多轮自我对战中以少于三例测试用例的平均值进行故障归因，效率高于人类专家通常需要的十二个案例。然而，关于沟通能力，LLM-agent目前并不具备此类能力。上述定性分析主要旨在降低有害事件发生的概率。定量分析或综合模型仍然需要在人工智能安全领域进一步发展。

## 6 结论与讨论

### 6.1 工作总结与未来计划

基于我们在集群诊断、LLM增强和LLM-agent构建领域的经验和研究，我们创新性地提出了一种利用LLM-agent自主智能地执行集群故障排除的系统解决方案。在LLM算法方面，我们引入了一个由150个手工制作的高级问题组成的基准，展示了我们构建的LLM-agent与原始开源LLM在公平数据条件下的性能差异。在LLM-agent构建方面，我们创新性地提出将DoT推理数学和处理特殊符号与公式的能力集成到代理中，使LLM能够在软件层面操作机器并接收反馈。最终，我们将这些创新成果应用于集群诊断，探索这一领域的潜力，并惊讶地发现，尽管LLM-agent系统仍处于极其早期阶段，它们已经能够处理重复性和低端任务，从而让行业从业人员能够专注于更具挑战性和价值的问题。

未来，我们将在四个方面继续开展工作。在LLM算法方面，我们将扩展和升级现有的基准，并建立一个更全面、更有价值的度量体系。在代理领域，我们将进一步释放DoT的潜力，使LLM逐步生成自写代码，减少对预设工具的依赖。在系统应用层面，我们将形成数据、算法与硬件的闭环，通过实际部署的结果丰富数据库。最后，在安全性和可靠性方面，我们将继续与相关领域的研究人员合作，确保并评估代理的安全性和可靠性。

### 6.2 缺点与局限性

我们的研究仍然存在不足和局限性。在不足方面，我们的代理目前依赖人工审查机制来确保安全，依赖预编写的工具进行代码处理，并且依赖于从GitHub获取的数据作为起点。理想的LLM-agent系统应该与AI集群形成自我维持的关系，保持和发展自身。

在限制方面，我们的工作依赖于LLM-agent中的LLM，但像llama3.2-3B这样的小型模型目前无法支持该代理的能力。因此，我们的工作仅能应用于数据中心或大规模分布式集群，无法部署在边缘计算或个人计算机场景中。我们需要持续监测小型模型的发展，并在适当时探索将LLM-agent的能力以DoT的形式教授给小型模型的可能性。

## 参考文献

+   Achiam等人（2023）Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F. L., Almeida, D., Altenschmidt, J., Altman, S., Anadkat, S., 等人。Gpt-4技术报告。*arXiv预印本 arXiv:2303.08774*，2023年。

+   Adler等（2024）Adler, B., Agarwal, N., Aithal, A., Anh, D. H., Bhattacharya, P., Brundyn, A., Casper, J., Catanzaro, B., Clay, S., Cohen, J. 等. Nemotron-4 340b技术报告. *arXiv预印本arXiv:2406.11704*，2024年。

+   Besta等（2024）Besta, M., Blach, N., Kubicek, A., Gerstenberger, R., Podstawski, M., Gianinazzi, L., Gajda, J., Lehmann, T., Niewiadomski, H., Nyczyk, P. 等. 思维图谱：利用大型语言模型解决复杂问题. *第38届AAAI人工智能会议论文集*，第17682-17690页，2024年。

+   Castelfranchi（1998）Castelfranchi, C. 为AI代理建模社会行为. *人工智能*，103（1-2）：157-182，1998年。

+   Chen等（2021）Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. D. O., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G. 等. 评估在代码上训练的大型语言模型. *arXiv预印本arXiv:2107.03374*，2021年。

+   Clark等（2019）Clark, C., Lee, K., Chang, M.-W., Kwiatkowski, T., Collins, M., 和 Toutanova, K. Boolq：探索自然是/否问题的惊人难度. *arXiv预印本arXiv:1905.10044*，2019年。

+   Dubey等（2024）Dubey, A., Jauhri, A., Pandey, A., Kadian, A., Al-Dahle, A., Letman, A., Mathur, A., Schelten, A., Yang, A., Fan, A. 等. Llama 3 模型群体. *arXiv预印本arXiv:2407.21783*，2024年。

+   Guo等（2016）Guo, C., Wu, H., Deng, Z., Soni, G., Ye, J., Padhye, J., 和 Lipshteyn, M. 在大规模商品以太网上的RDMA. *2016年ACM SIGCOMM会议论文集*，第202-215页，2016年。

+   Hendrycks等（2020）Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., 和 Steinhardt, J. 测量大规模多任务语言理解. *arXiv预印本arXiv:2009.03300*，2020年。

+   Jiang等（2023）Jiang, A. Q., Sablayrolles, A., Mensch, A., Bamford, C., Chaplot, D. S., Casas, D. d. l., Bressand, F., Lengyel, G., Lample, G., Saulnier, L. 等. Mistral 7b. *arXiv预印本arXiv:2310.06825*，2023年。

+   Jiang等（2024）Jiang, Z., Lin, H., Zhong, Y., Huang, Q., Chen, Y., Zhang, Z., Peng, Y., Li, X., Xie, C., Nong, S. 等. $\{$MegaScale$\}$：将大型语言模型训练扩展到超过10,000个$\{$GPU$\}$. *第21届USENIX网络系统设计与实现研讨会（NSDI 24）*，第745-760页，2024年。

+   Jouppi等（2017）Jouppi, N. P., Young, C., Patil, N., Patterson, D., Agrawal, G., Bajwa, R., Bates, S., Bhatia, S., Boden, N., Borchers, A. 等. 数据中心内的张量处理单元性能分析. *第44届国际计算机体系结构年会论文集*，第1-12页，2017年。

+   Jung & Chung（2021）Jung, H. 和 Chung, K. 基于社交挖掘的聚类过程用于大数据集成. *环境智能与人性化计算杂志*，12（1）：589-600，2021年。

+   Lewis 等人（2020）Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Küttler, H., Lewis, M., Yih, W.-t., Rocktäschel, T., 等人。针对知识密集型 NLP 任务的检索增强生成。*神经信息处理系统进展*，33:9459–9474，2020。

+   Liu 等人（2024）Liu, Y., Tao, S., Zhao, X., Zhu, M., Ma, W., Zhu, J., Su, C., Hou, Y., Zhang, M., Zhang, M., 等人。Coachlm：自动化指令修订提高 LLM 指令调优中的数据质量。在 *2024 IEEE 第40届国际数据工程会议（ICDE）*，第 5184–5197 页。IEEE，2024。

+   Mihaylov 等人（2018）Mihaylov, T., Clark, P., Khot, T., 和 Sabharwal, A. 一套盔甲能导电吗？一个新的开放书籍问答数据集。*arXiv 预印本 arXiv:1809.02789*，2018。

+   Ofenbeck 等人（2014）Ofenbeck, G., Steinmann, R., Caparros, V., Spampinato, D. G., 和 Püschel, M. 应用屋顶线模型。在 *2014 IEEE 国际系统和软件性能分析研讨会（ISPASS）*，第 76–85 页。IEEE，2014。

+   Ouyang 等人（2022）Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., 等人。训练语言模型根据人类反馈遵循指令。*神经信息处理系统进展*，35:27730–27744，2022。

+   Park 等人（2023）Park, J. S., O’Brien, J., Cai, C. J., Morris, M. R., Liang, P., 和 Bernstein, M. S. 生成代理：人类行为的互动模拟。 在 *第36届ACM用户界面软件与技术年会论文集*，第 1–22 页，2023。

+   Paszke 等人（2019）Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., 等人。Pytorch：一种命令式风格、高性能的深度学习库。*神经信息处理系统进展*，32，2019。

+   Peter（2022）Peter, E. 抽象与推理挑战。2022。

+   Qian 等人（2024）Qian, K., Xi, Y., Cao, J., Gao, J., Xu, Y., Guan, Y., Fu, B., Shi, X., Zhu, F., Miao, R., 等人。阿里巴巴 HPN：用于大规模语言模型训练的数据中心网络。在 *2024 年 ACM SIGCOMM 会议论文集*，第 691–706 页，2024。

+   Radford 等人（2019）Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., 等人。语言模型是无监督的多任务学习者。*OpenAI 博客*，1(8):9，2019。

+   Shanley（2003）Shanley, T. *InfiniBand 网络架构*。Addison-Wesley Professional，2003。

+   Shoeybi 等人（2019）Shoeybi, M., Patwary, M., Puri, R., LeGresley, P., Casper, J., 和 Catanzaro, B. Megatron-lm：使用模型并行训练多亿参数的语言模型。*arXiv 预印本 arXiv:1909.08053*，2019。

+   Snell 等人（2024）Snell, C., Lee, J., Xu, K., 和 Kumar, A. 最优扩展 LLM 测试时计算可能比扩展模型参数更有效。*arXiv 预印本 arXiv:2408.03314*，2024。

+   Team等（2023）Team, G., Anil, R., Borgeaud, S., Wu, Y., Alayrac, J.-B., Yu, J., Soricut, R., Schalkwyk, J., Dai, A. M., Hauth, A., 等。Gemini：一系列高能力的多模态模型。 *arXiv预印本 arXiv:2312.11805*，2023年。

+   Touvron等（2023）Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., 等。Llama：开放且高效的基础语言模型。 *arXiv预印本 arXiv:2302.13971*，2023年。

+   Wang等（2023）Wang, Q., Sang, B., Zhang, H., Tang, M., 和 Zhang, K. Dlrover：一种带有自动作业资源推荐的弹性深度训练扩展。 *arXiv预印本 arXiv:2304.01468*，2023年。

+   Wei等（2022）Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q. V., Zhou, D., 等。思维链提示在大型语言模型中引发推理。 *神经信息处理系统进展*，第35卷：24824-24837，2022年。

+   Xi等（2023）Xi, Z., Chen, W., Guo, X., He, W., Ding, Y., Hong, B., Zhang, M., Wang, J., Jin, S., Zhou, E., 等。基于大型语言模型的智能体崛起与潜力：一项调查。 *arXiv预印本 arXiv:2309.07864*，2023年。

+   Xiong等（2024）Xiong, Y., Jiang, Y., Yang, Z., Qu, L., Zhao, G., Liu, S., Zhong, D., Pinzur, B., Zhang, J., Wang, Y., 等。$\{$SuperBench$\}$：通过主动验证提高云$\{$AI$\}$基础设施的可靠性。发表于 *2024年USENIX年度技术会议（USENIX ATC 24）*，第835-850页，2024年。

+   Xu等（2024）Xu, Y., Chen, Y., Zhang, X., Lin, X., Hu, P., Ma, Y., Lu, S., Du, W., Mao, Z., Zhai, E., 等。Cloudeval-yaml：一种用于云配置生成的实用基准。 *机器学习与系统会议论文集*，第6卷：173-195，2024年。

+   Yang等（2024）Yang, A., Yang, B., Hui, B., Zheng, B., Yu, B., Zhou, C., Li, C., Li, C., Liu, D., Huang, F., 等。Qwen2技术报告。 *arXiv预印本 arXiv:2407.10671*，2024年。

+   Yao等（2024）Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T., Cao, Y., 和 Narasimhan, K. 思维树：利用大型语言模型进行深思熟虑的问题解决。 *神经信息处理系统进展*，第36卷，2024年。

+   Zhang等（2024）Zhang, Y., Yuan, Y., 和 Yao, A. C.-C. 关于思维图谱。 *arXiv预印本 arXiv:2409.10038*，2024年。

## 附录A 请在此处添加补充材料作为附录

将您通常放在参考文献后面的内容作为附录放在这里，而不是放在单独的补充文件中。上传最终的定稿版本作为一个单一的pdf文件，包括所有附录。
