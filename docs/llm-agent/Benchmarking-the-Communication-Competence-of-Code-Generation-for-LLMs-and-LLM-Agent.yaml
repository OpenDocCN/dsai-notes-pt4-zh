- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '类别: 未分类'
- en: 'date: 2024-09-08 18:45:19'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-09-08 18:45:19'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Benchmarking the Communication Competence of Code Generation for LLMs and LLM
    Agent
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLMs和LLM代理的代码生成沟通能力基准测试
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.00215](https://ar5iv.labs.arxiv.org/html/2406.00215)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2406.00215](https://ar5iv.labs.arxiv.org/html/2406.00215)
- en: Jie JW Wu [0000-0002-7895-2023](https://orcid.org/0000-0002-7895-2023 "ORCID
    identifier") University of British Columbia3333 University WayKelownaB.C.V1V 1V7Canada
    [jie.jw.wu@ubc.ca](mailto:jie.jw.wu@ubc.ca)  and  Fatemeh H. Fard University of
    British Columbia3333 University WayKelownaB.C.V1V 1V7Canada [fatemeh.fard@ubc.ca](mailto:fatemeh.fard@ubc.ca)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Jie JW Wu [0000-0002-7895-2023](https://orcid.org/0000-0002-7895-2023 "ORCID
    identifier") 英属哥伦比亚大学3333 University WayKelownaB.C.V1V 1V7加拿大 [jie.jw.wu@ubc.ca](mailto:jie.jw.wu@ubc.ca)
    和 Fatemeh H. Fard 英属哥伦比亚大学3333 University WayKelownaB.C.V1V 1V7加拿大 [fatemeh.fard@ubc.ca](mailto:fatemeh.fard@ubc.ca)
- en: Abstract.
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: 'Large language models (LLMs) have significantly improved their ability to perform
    tasks in the field of code generation. However, there is still a gap between LLMs
    being capable coders and being top-tier software engineers. The most recent trend
    is using LLM-based agents to iterate the code generation process. Based on the
    observation that top-level software engineers often ask clarifying questions to
    reduce Ambiguity in both requirements and coding solutions, we argue that the
    same should be applied to LLMs for code generation tasks. For this purpose, we
    define the communication skills of LLMs as “being able to ask clarifying questions
    when the description of the code generation problem has issues”. In this study,
    we restrict these issues to three matters from the software requirement engineering
    field: inconsistent requirements, ambiguous requirements, and incomplete requirements.
    By asking probing questions about the requirements of problem descriptions before
    generating the final code, the challenges of programming with LLMs, such as unclear
    intent specification may be alleviated, resulting to a correct code in the initial
    iterations.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）在代码生成领域显著提升了执行任务的能力。然而，LLMs 作为编码者与顶级软件工程师之间仍存在差距。最新的趋势是使用基于LLM的代理来迭代代码生成过程。基于观察到顶级软件工程师常常提出澄清问题以减少需求和编码解决方案中的模糊性，我们认为这同样应该应用于LLMs的代码生成任务。为此，我们将LLMs的沟通技能定义为“能够在代码生成问题描述存在问题时提出澄清问题”。在本研究中，我们将这些问题限制为来自软件需求工程领域的三个方面：需求不一致、需求模糊和需求不完整。通过在生成最终代码之前对问题描述的需求进行探询，可能缓解使用LLMs编程的挑战，如意图不明确，从而在初始迭代中生成正确的代码。
- en: In this work, we conducted an empirical study on the benchmark and analysis
    of the communication skills of LLMs for code generation. We created a new benchmark,
    HumanEvalComm, by modifying problem descriptions according to three issues mentioned
    above, Inconsistency, Ambiguity, Incompleteness. We then experimented on HumanEvalComm
    with different Code LLMs, and a new LLM agent approach, Code Clarification and
    Generation Agent (Okanagan), to identify and ask questions in ambiguous parts
    from code and descriptions for further refining the generated code. In the evaluation,
    we introduced an LLM-based evaluator and created Communication Rate and Good Question
    Rate as the evaluation metrics to represent the ratio of questions asked and questions
    with good quality in responses. We found that more than 60% of responses from
    Code LLMs still generate code rather than ask questions when the problem descriptions
    are manually modified according to different clarification categories. The Pass@1
    and Test Pass Rate of most Code LLMs drop by 35% $\sim$ 35% respectively, with
    statistical significance in each category for over 75% numbers. Okanagan, as an
    LLM agent approach that uses LLM such as ChatGPT 3.5, effectively increases the
    Communication Rate and Good Question Rate by an absolute 58% and 38%, respectively.
    Thus, Okanagan boosts Pass@1 and Test Pass Rate by an absolute 8% and 7%, respectively,
    when the problem descriptions are modified based on given clarification categories.
    This result indicates the potential for achieving more effective communication
    capability using LLM agent.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们对代码生成的LLM（大语言模型）的沟通技能进行了基准测试和分析。我们通过根据上述三种问题——不一致性、模糊性、不完整性——修改问题描述，创建了一个新的基准，HumanEvalComm。随后，我们在HumanEvalComm上对不同的代码LLM以及一种新的LLM代理方法，代码澄清与生成代理（Okanagan），进行了实验，旨在识别和提出代码及描述中模糊部分的问题，以进一步完善生成的代码。在评估中，我们引入了一个基于LLM的评估者，并创建了沟通率和良好问题率作为评估指标，表示提问的比例和响应中高质量问题的比例。我们发现，当问题描述根据不同的澄清类别进行手动修改时，超过60%的代码LLM响应仍然生成代码而不是提出问题。大多数代码LLM的Pass@1和测试通过率分别下降了35%
    $\sim$ 35%，在每个类别中超过75%的数字具有统计学意义。Okanagan作为一种LLM代理方法，使用如ChatGPT 3.5的LLM，能够将沟通率和良好问题率分别绝对提高58%和38%。因此，当问题描述基于给定的澄清类别进行修改时，Okanagan将Pass@1和测试通过率分别绝对提高了8%和7%。这一结果表明，利用LLM代理可以实现更有效的沟通能力。
- en: “Asking a good question can be valuable in and of itself, irrespective of the
    answer. It communicates your respect for the other person.”
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “提出一个好问题本身就是有价值的，无论答案如何。它传达了你对他人的尊重。”
- en: —— - Adapted from the Iowa Peace Institute Message
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: —— - 引自爱荷华和平研究所的消息
- en: 1\. Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 介绍
- en: Large language models (LLMs) (Vaswani et al., [2017](#bib.bib62); Svyatkovskiy
    et al., [2020](#bib.bib58); Wang et al., [2021](#bib.bib66); Feng et al., [2020](#bib.bib20)),
    such as OpenAI’s Codex (Chen et al., [2021](#bib.bib13)), AlphaCode (Li et al.,
    [2022](#bib.bib36)), and CodeGen (Nijkamp et al., [2022](#bib.bib45)), possess
    a significantly capable ability to generate code snippets from natural language
    requirements. However, there are several reported issues in LLMs, including problems
    with intent specification, problem decomposition (Sarkar et al., [2022](#bib.bib53)),
    code quality, and overconfidence (Liu et al., [2023c](#bib.bib40), [b](#bib.bib39)),
    as well as usability (Liang et al., [2023](#bib.bib37)). These issues indicate
    that there is still a substantial gap between using LLM as a seasoned coder (Rabinovich
    et al., [2017](#bib.bib50); Ye et al., [2020](#bib.bib75); Alon et al., [2019](#bib.bib3);
    Bui et al., [2021](#bib.bib12); Tufano et al., [2020](#bib.bib59)) and using LLM
    as a software engineer. As the responsibility of software developers encompasses
    more than just writing code, current LLMs cannot fully replace professional software
    developers (Sarkar et al., [2022](#bib.bib53); Borji, [2023](#bib.bib9)). At a
    high level, the gap lies in several critical aspects of software development beyond
    coding, such as effective communications, requirements, design, domain knowledge,
    and the broader context of relevant projects and components (Nguyen and Nadi,
    [2022](#bib.bib44); Sobania et al., [2022](#bib.bib57); Vaithilingam et al., [2022](#bib.bib61);
    Siddiq et al., [2022](#bib.bib56)). Although some LLM-based agent systems have
    got a lot of attention, e.g., Devin (Wu, [2024](#bib.bib69)), there is no study
    that investigates the reported issues and systematically integrates them with
    the LLM agent approach for code generation. In this paper, we are interested in
    applying the communication lens to inspect the gap, given that we envision effective
    communication as a critical capability that ensures the necessary information
    is obtained for completing the coding tasks.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）（Vaswani et al., [2017](#bib.bib62); Svyatkovskiy et al., [2020](#bib.bib58);
    Wang et al., [2021](#bib.bib66); Feng et al., [2020](#bib.bib20)），如 OpenAI 的 Codex
    (Chen et al., [2021](#bib.bib13))、AlphaCode (Li et al., [2022](#bib.bib36)) 和
    CodeGen (Nijkamp et al., [2022](#bib.bib45))，具有从自然语言需求生成代码片段的显著能力。然而，LLMs 存在多个报告的问题，包括意图指定、问题分解
    (Sarkar et al., [2022](#bib.bib53))、代码质量和过度自信 (Liu et al., [2023c](#bib.bib40),
    [b](#bib.bib39))，以及可用性 (Liang et al., [2023](#bib.bib37))。这些问题表明，在将 LLM 用作经验丰富的编码员
    (Rabinovich et al., [2017](#bib.bib50); Ye et al., [2020](#bib.bib75); Alon et
    al., [2019](#bib.bib3); Bui et al., [2021](#bib.bib12); Tufano et al., [2020](#bib.bib59))
    和作为软件工程师使用 LLM 之间，仍然存在着实质性的差距。由于软件开发者的职责不仅仅包括编写代码，目前的 LLM 还不能完全替代专业的软件开发者 (Sarkar
    et al., [2022](#bib.bib53); Borji, [2023](#bib.bib9))。从高层次来看，这种差距体现在软件开发中的多个关键方面，超出了编码的范围，例如有效的沟通、需求、设计、领域知识以及相关项目和组件的更广泛背景
    (Nguyen and Nadi, [2022](#bib.bib44); Sobania et al., [2022](#bib.bib57); Vaithilingam
    et al., [2022](#bib.bib61); Siddiq et al., [2022](#bib.bib56))。尽管一些基于 LLM 的代理系统获得了大量关注，例如
    Devin (Wu, [2024](#bib.bib69))，但目前尚无研究系统地调查这些报告的问题，并将其与 LLM 代理方法结合以进行代码生成。本文旨在应用沟通视角来检查这种差距，因为我们认为有效沟通是确保获取完成编码任务所需信息的关键能力。
- en: Let us take a step back to compare the communications of LLMs and software developers.
    The current LLMs are typically evaluated by generating code in one or multiple
    attempts from one-off problem descriptions, without further conversational inputs (Chen
    et al., [2021](#bib.bib13); Austin et al., [2021](#bib.bib5); Li et al., [2022](#bib.bib36)).
    This means when the input problem description is error-prone or incomplete without
    full context, the model has to generate the code without the chance to clarify
    questions that are necessary to ensure the correctness of the code. In the literature,
    the communication capability (defined below) of Code LLM (Fan et al., [2023](#bib.bib19);
    Zan et al., [2023](#bib.bib77)) and LLM agent (Rasheed et al., [2024](#bib.bib51);
    Xi et al., [2023](#bib.bib70)) is underrepresented and thus rarely emphasized
    and evaluated in the field of code generation. On the contrary, given a software
    engineering task in real-world enterprises, professional developers use various
    ways of communication, such as asking more questions in 1:1 conversations, group
    meetings, and Slack channels to obtain more information and reduce Ambiguity about
    the detailed requirements, the context of the projects, and the design alternatives.
    Proactive and effective communication is a critical skill in practice for top-level
    software developers to accomplish their software engineering tasks reliably with
    high quality (Whitehead, [2007](#bib.bib68); Pressman, [2005](#bib.bib49); Mistrík
    et al., [2010](#bib.bib43); McChesney and Gallagher, [2004](#bib.bib41); Jazayeri,
    [2004](#bib.bib29)).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们退一步比较一下大语言模型（LLMs）和软件开发人员的沟通方式。目前的大语言模型通常通过从一次性问题描述中生成代码来进行评估，不会有进一步的对话输入（Chen
    et al., [2021](#bib.bib13); Austin et al., [2021](#bib.bib5); Li et al., [2022](#bib.bib36)）。这意味着当输入问题描述存在错误或不完整，缺乏完整的背景信息时，模型必须在没有机会澄清必要问题的情况下生成代码，以确保代码的正确性。在文献中，代码大语言模型（Fan
    et al., [2023](#bib.bib19); Zan et al., [2023](#bib.bib77)）和大语言模型代理（Rasheed et
    al., [2024](#bib.bib51); Xi et al., [2023](#bib.bib70)）的沟通能力（定义如下）被低估，因此在代码生成领域很少被强调和评估。相反，在现实世界企业中，面对软件工程任务，专业开发人员使用各种沟通方式，例如在一对一对话、团队会议和Slack频道中提出更多问题，以获取更多信息并减少关于详细需求、项目背景和设计替代方案的模糊性。主动和有效的沟通是顶级软件开发人员在实践中完成软件工程任务的重要技能，以高质量和可靠性完成任务（Whitehead,
    [2007](#bib.bib68); Pressman, [2005](#bib.bib49); Mistrík et al., [2010](#bib.bib43);
    McChesney and Gallagher, [2004](#bib.bib41); Jazayeri, [2004](#bib.bib29)）。
- en: 'Inspired by this behavior, our motivation in this work is to study and evaluate
    the potential of LLMs on code generation from the dimension of effective communication
    skills. We argue that the evaluation of the communication capability of Code LLMs
    is, although underrepresented in literature, essential for the long-term success
    of AI systems in completing the coding and software engineering tasks (Hassan
    et al., [2024](#bib.bib25)). Thus, we intend to fill this literature gap in this
    research for the code generation task. For highly specialized task of code generation,
    we argue that the AI system should proactively recognize which information is
    missing, and find these missing pieces to be able to complete the task with high
    quality and rigorousness, instead of just executing the given task and generating
    low-quality code as a result. Formally, the communication capability, also referred
    to as communication skills or communication competency, in this study is defined
    as follows: when the requirements are incomplete, inconsistent, or ambiguous in
    a programming problem, and the model is prompted to either generate code or ask
    clarifying questions, how good the model is in asking clarifying questions to
    recover the requirements necessary for solving the problem correctly. We use the
    terms ‘LLMs’ and ‘Code LLMs’ interchangeably to represent LLMs for code generation
    tasks in this paper.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 受到这种行为的启发，我们在这项工作中的动机是从有效沟通技能的维度研究和评估大型语言模型（LLMs）在代码生成方面的潜力。我们认为，尽管文献中对代码LLMs的沟通能力评价较少，但这种评价对AI系统在完成编码和软件工程任务的长期成功至关重要 （Hassan等，
    [2024](#bib.bib25)）。因此，我们打算在这项研究中填补代码生成任务的文献空白。对于高度专业化的代码生成任务，我们认为AI系统应该主动识别缺失的信息，并找到这些缺失的部分，以便能够高质量和严谨地完成任务，而不仅仅是执行给定任务并生成低质量代码。正式地说，本研究中的沟通能力，也称为沟通技能或沟通能力，定义如下：当编程问题中的需求不完整、不一致或模糊时，如果模型被提示生成代码或提出澄清问题，模型在提出澄清问题以恢复解决问题所需的需求方面的表现如何。我们在本文中将“LLMs”和“代码LLMs”交替使用，表示用于代码生成任务的LLMs。
- en: 'In this research, we conducted the first systematic empirical study on the
    communication skills of LLMs in code generation tasks. First, we created a benchmark
    dataset, HumanEvalComm, for evaluating the degree of communication skills when
    generating code, based on the widely studied HumanEval code generation benchmark (Chen
    et al., [2021](#bib.bib13)). We constructed the benchmark by manually modifying
    the requirements in the original problem description based on concepts in Requirement
    Engineering (RE) (Tukur et al., [2021](#bib.bib60); Dermeval et al., [2016](#bib.bib14)).
    To achieve this, we created a taxonomy of clarification types: Ambiguity, Inconsistency,
    and Incompleteness (See Section [2](#S2 "2\. Benchmark Construction ‣ Benchmarking
    the Communication Competence of Code Generation for LLMs and LLM Agent")). Based
    on the taxonomy, we then changed each problem description by applying one or a
    combination of clarification types. Based on the new HumanEvalComm benchmark,
    we further evaluated different models to inspect the degree of their communication
    skills when certain information is manually modified to be ambiguous, inconsistent,
    or incomplete in the problem description. In the evaluation, we introduced an
    LLM-based evaluator and proposed new evaluation metrics to effectively measure
    the communication skills of the models. We also proposed a LLM agent approach,
    Code Clarification and Generation Agent (Okanagan), as an LLM-based agent with
    multi-round structure and customized prompt for code generation task. A key feature
    of Okanagan is the ability to ask clarifying questions about the input problem
    descriptions needed for generating correct code.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们首次对LLMs在代码生成任务中的沟通技能进行了系统的实证研究。首先，我们创建了一个基准数据集HumanEvalComm，用于评估生成代码时的沟通技能程度，基于广泛研究的HumanEval代码生成基准（Chen等人，[2021](#bib.bib13)）。我们通过基于需求工程（RE）概念手动修改原始问题描述中的要求来构建基准（Tukur等人，[2021](#bib.bib60);
    Dermeval等人，[2016](#bib.bib14)）。为此，我们创建了一个澄清类型的分类法：模糊性、不一致性和不完整性（见第[2](#S2 "2\.
    Benchmark Construction ‣ Benchmarking the Communication Competence of Code Generation
    for LLMs and LLM Agent")节）。基于该分类法，我们通过应用一种或多种澄清类型来更改每个问题描述。基于新的HumanEvalComm基准，我们进一步评估了不同的模型，以检查在问题描述中的某些信息被手动修改为模糊、不一致或不完整时，它们的沟通技能程度。在评估中，我们引入了一个基于LLM的评估器，并提出了新的评估指标，以有效衡量模型的沟通技能。我们还提出了一种LLM代理方法——代码澄清和生成代理（Okanagan），作为一种具有多轮结构和定制提示的LLM代理，用于代码生成任务。Okanagan的一个关键特点是能够就生成正确代码所需的输入问题描述提出澄清性问题。
- en: In terms of findings, for manual modifications using HumanEvalComm, more than
    60% of responses from Code LLMs still generate code. Typically, the Pass@1 and
    Test Pass Rate of Code LLMs drop by 35% $\sim$ 35%, respectively. Among the three
    clarification types, the Incompleteness category results in higher communication
    rates and Good Question Rates, but lower Pass@1 and Test Pass Rate than the Ambiguity
    and Inconsistency categories for Code LLMs. Okaganan, the proposed LLM agent approach
    that uses ChatGPT 3.5 as LLM, effectively increased Communication Rate and Good
    Question Rate by an absolute 59% and 5%, respectively. This resulted in an increase
    in Test Pass Rate and Pass@1 by 25% and 15%, respectively. This result indicates
    the potential for more effective communication capability for LLM agent compared
    with Code LLMs.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在发现方面，对于使用HumanEvalComm的手动修改，超过60%的代码LLMs响应仍能生成代码。通常，Code LLMs的Pass@1和测试通过率分别下降了35%
    $\sim$ 35%。在三种澄清类型中，不完整性类别导致更高的沟通率和良好问题率，但比模糊性和不一致性类别的Pass@1和测试通过率要低。使用ChatGPT
    3.5作为LLM的Okanagan有效地将沟通率和良好问题率分别提高了绝对59%和5%。这导致测试通过率和Pass@1分别提高了25%和15%。这一结果表明，相比于Code
    LLMs，LLM代理具有更有效的沟通能力。
- en: 'To summarize, we have made the following contributions:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们做出了以下贡献：
- en: •
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'We created a new benchmark, HumanEvalComm, for evaluating the degree of communication
    skills of LLMs for code by manually modifying the requirements in the original
    problem description based on RE concepts: clarification types of Ambiguity, Inconsistency,
    Incompleteness.'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们创建了一个新的基准HumanEvalComm，用于通过基于RE概念（模糊性、不一致性、不完整性）的手动修改原始问题描述中的要求来评估LLMs在代码方面的沟通技能程度。
- en: •
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We proposed an LLM-agent approach, Code Clarification and Generation Agent (Okanagan),
    to enhance the communication capability of the models, and thus lead to better
    code generation capability, in terms of Pass@1, based on asking clarifying questions
    when the problem description is ambiguous, inconsistent, or incomplete. The contribution
    of Okanagan is a multi-round structure with customized prompts for asking clarifying
    questions when needed in code generation tasks.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了一种LLM-agent方法——代码澄清与生成代理（Okanagan），以增强模型的沟通能力，从而在通过询问澄清问题（当问题描述模糊、不一致或不完整时）来提高代码生成能力（以Pass@1为标准）。Okanagan的贡献在于其多轮结构及在代码生成任务中根据需要提出澄清问题的定制提示。
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We conducted the first empirical study on the evaluation of communication competence
    in code generation task for both Code LLMs and Okanagan on HumanEvalComm. In the
    evaluation, we introduced LLM-based evaluator and proposed two new evaluation
    metrics, Communication Rate and Good Question Rate, to effectively measure communication
    skills of the models.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们首次对Code LLMs和Okanagan在HumanEvalComm中的代码生成任务的沟通能力进行了评估。在评估中，我们引入了基于LLM的评估器，并提出了两个新的评估指标，沟通率和良好问题率，以有效衡量模型的沟通技能。
- en: Our benchmark and replication package are made public at [https://github.com/jie-jw-wu/human-eval-comm](https://github.com/jie-jw-wu/human-eval-comm)
    to support open data and open science principles.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的基准和复制包已公开在[https://github.com/jie-jw-wu/human-eval-comm](https://github.com/jie-jw-wu/human-eval-comm)，以支持开放数据和开放科学原则。
- en: The rest of the paper is structured as follows. Section [2](#S2 "2\. Benchmark
    Construction ‣ Benchmarking the Communication Competence of Code Generation for
    LLMs and LLM Agent") describes the benchmark construction of our research. Section [3](#S3
    "3\. Empirical Study ‣ Benchmarking the Communication Competence of Code Generation
    for LLMs and LLM Agent") explains the design of our empirical study. Section [4](#S4
    "4\. Results and Analysis ‣ Benchmarking the Communication Competence of Code
    Generation for LLMs and LLM Agent") summarizes the results for RQs. Section [5](#S5
    "5\. Analysis and Discussion ‣ Benchmarking the Communication Competence of Code
    Generation for LLMs and LLM Agent") includes more analysis and discussions on
    the results. Threats to validity are explained in Section [6](#S6 "6\. Threats
    to Validity ‣ Benchmarking the Communication Competence of Code Generation for
    LLMs and LLM Agent"), followed by summarizing the related works in Section [7](#S7
    "7\. Related Work ‣ Benchmarking the Communication Competence of Code Generation
    for LLMs and LLM Agent"). Finally, Section [8](#S8 "8\. Conclusions ‣ Benchmarking
    the Communication Competence of Code Generation for LLMs and LLM Agent") concludes
    this work.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 论文的其余部分结构如下。第[2](#S2 "2\. Benchmark Construction ‣ Benchmarking the Communication
    Competence of Code Generation for LLMs and LLM Agent")节描述了我们研究的基准构建。第[3](#S3 "3\.
    Empirical Study ‣ Benchmarking the Communication Competence of Code Generation
    for LLMs and LLM Agent")节解释了我们实证研究的设计。第[4](#S4 "4\. Results and Analysis ‣ Benchmarking
    the Communication Competence of Code Generation for LLMs and LLM Agent")节总结了对研究问题的结果。第[5](#S5
    "5\. Analysis and Discussion ‣ Benchmarking the Communication Competence of Code
    Generation for LLMs and LLM Agent")节包括了对结果的更多分析和讨论。第[6](#S6 "6\. Threats to Validity
    ‣ Benchmarking the Communication Competence of Code Generation for LLMs and LLM
    Agent")节解释了有效性威胁，然后在第[7](#S7 "7\. Related Work ‣ Benchmarking the Communication
    Competence of Code Generation for LLMs and LLM Agent")节总结了相关工作。最后，第[8](#S8 "8\.
    Conclusions ‣ Benchmarking the Communication Competence of Code Generation for
    LLMs and LLM Agent")节总结了这项工作。
- en: 2\. Benchmark Construction
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 基准构建
- en: 2.1\. Benchmark Collection
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1\. 基准收集
- en: Existing Benchmarks. We first start by examining the existing benchmarks for
    code generation. To the best of our knowledge, all of the existing benchmarks
    (e.g., HumanEval (Chen et al., [2021](#bib.bib13)), CoNaLa (Yin et al., [2018](#bib.bib76)),
    APPS (Hendrycks et al., [2021](#bib.bib27)), and recent SWE-bench (Jimenez et al.,
    [2024](#bib.bib31))) in code generation are tasked with letting the model generate
    the code directly as prediction, without giving the model the opportunity to ask
    for additional information. Notably, the input of these datasets is well-written
    and organized by professional human annotations. However, in real-world scenarios,
    the problem descriptions from humans could be a lack of computational thinking,
    unclear in the intent specification, or ambiguous in requirements (Liang et al.,
    [2023](#bib.bib37)).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现有基准。我们首先检查了现有的代码生成基准。据我们所知，所有现有的基准（例如HumanEval（Chen等，[2021](#bib.bib13)）、CoNaLa（Yin等，[2018](#bib.bib76)）、APPS（Hendrycks等，[2021](#bib.bib27)）以及最近的SWE-bench（Jimenez等，[2024](#bib.bib31)））都要求模型直接生成代码作为预测，而没有给模型提供询问额外信息的机会。值得注意的是，这些数据集的输入由专业人员注释，书写良好且组织有序。然而，在现实世界中，来自人类的问题描述可能缺乏计算思维、意图不明确或需求模糊（Liang等，[2023](#bib.bib37)）。
- en: HumanEvalComm Overview. To assess the communication ability of Code LLMs and
    LLM-based agent, we chose to hand-craft a new benchmark based on a widely used
    code generation dataset, HumanEval (Chen et al., [2021](#bib.bib13)). Our objective
    is to modify the problem description based on RE concepts so that it should trigger
    clarifying questions, which are necessary for generating the correct code. HumanEval
    is composed of 164 hand-crafted coding problems in Python and was created to evaluate
    the coding capabilities of Codex. Each problem has a function signature, docstring,
    body, and unit tests. The average number of ground-truth test cases per problem
    is 7.77\. HumanEval is chosen as it is a benchmark dataset with test cases and
    is widely used for evaluating LLMs (Ouyang et al., [2023](#bib.bib47); Min et al.,
    [2023](#bib.bib42); Rasheed et al., [2024](#bib.bib51); Zan et al., [2023](#bib.bib77)).
    Using HumanEval, we changed each problem description manually to develop HumanEvalComm,
    which we will use for evaluation in our work. This is done using a taxonomy of
    clarification types as described below.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: HumanEvalComm 概述。为了评估代码LLM和基于LLM的代理的沟通能力，我们选择手工制作一个新的基准，基于广泛使用的代码生成数据集HumanEval（Chen等，[2021](#bib.bib13)）。我们的目标是基于RE概念修改问题描述，以便能够引发澄清问题，这些问题对于生成正确的代码是必要的。HumanEval由164个手工制作的Python编码问题组成，旨在评估Codex的编码能力。每个问题都有一个函数签名、文档字符串、主体和单元测试。每个问题的平均真实测试用例数量为7.77。选择HumanEval是因为它是一个具有测试用例的基准数据集，并且被广泛用于评估LLMs（Ouyang等，[2023](#bib.bib47)；Min等，[2023](#bib.bib42)；Rasheed等，[2024](#bib.bib51)；Zan等，[2023](#bib.bib77)）。使用HumanEval，我们手动更改了每个问题描述，以开发HumanEvalComm，我们将在我们的工作中使用它。这是通过下面描述的澄清类型分类完成的。
- en: Besides manual modification, it should be noted that we also tried to use LLM
    to modify the problem description, but we found that the modification by LLMs
    did not meet our standard. Specifically, the modification from using LLMs cannot
    guarantee that the modification will trigger clarifying questions. Similar limitations
    on using LLMs for Requirement Engineering have been also reported in (Arvidsson
    and Axell, [2023](#bib.bib4)). Hence, we chose to manually modify all of the problem
    descriptions to provide this guarantee for HumanEvalComm.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 除了手动修改外，还应注意，我们也尝试使用LLM修改问题描述，但我们发现LLM的修改未能达到我们的标准。具体来说，使用LLM进行的修改无法保证会引发澄清问题。关于使用LLM进行需求工程的类似限制也已在（Arvidsson和Axell，[2023](#bib.bib4)）中报告。因此，我们选择手动修改所有问题描述，以为HumanEvalComm提供这种保证。
- en: 'Taxonomy of Clarification Types. To modify the problem description in an organized
    way, we propose the following clarification types based on both the literature
    in Requirement Engineering (RE) (Tukur et al., [2021](#bib.bib60); Dermeval et al.,
    [2016](#bib.bib14)) and our understanding of how feasible can the RE concepts
    be applied to problems in HumanEval:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 澄清类型的分类。为了以有组织的方式修改问题描述，我们提出了以下澄清类型，这些类型基于需求工程（RE）文献（Tukur等，[2021](#bib.bib60)；Dermeval等，[2016](#bib.bib14)）以及我们对RE概念在HumanEval问题中的应用可行性的理解：
- en: •
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Ambiguity: Some statements in the problem descriptions could be ambiguous and
    correspond to different concepts.'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 歧义：问题描述中的一些陈述可能存在歧义，并对应不同的概念。
- en: •
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Inconsistency: Some statements in the problem descriptions show conflict or
    inconsistency between each other.'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 不一致性：问题描述中的一些陈述相互之间存在冲突或不一致。
- en: •
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Incompleteness: Some concepts or conditions are missing in the problem descriptions.'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 不完整性：问题描述中缺少一些概念或条件。
- en: '| Clarification Category | Ambiguity | Inconsistency | Incompleteness |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 澄清类别 | 模糊性 | 不一致性 | 不完整性 |'
- en: '| 1a | ✓ |  |  |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 1a | ✓ |  |  |'
- en: '| 1c |  | ✓ |  |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 1c |  | ✓ |  |'
- en: '| 1p |  |  | ✓ |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 1p |  |  | ✓ |'
- en: '| 2ac | ✓ | ✓ |  |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 2ac | ✓ | ✓ |  |'
- en: '| 2cp |  | ✓ | ✓ |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 2cp |  | ✓ | ✓ |'
- en: '| 2ap | ✓ |  | ✓ |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 2ap | ✓ |  | ✓ |'
- en: Table 1. Problem descriptions with different combinations of clarification types
    being applied in HumanEvalComm.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1. 应用于 HumanEvalComm 的不同澄清类型组合的问题描述。
- en: '| Clarification Type | Problem Description |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 澄清类型 | 问题描述 |'
- en: '| --- | --- |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| N/A (Original) | {python} def incr_list(l: list): ”””Return list with elements
    incremented by 1. ¿¿¿ incr_list([1, 2, 3]) [2, 3, 4] ¿¿¿ incr_list([5, 3, 5, 2,
    3, 3, 9, 0, 123]) [6, 4, 6, 3, 4, 4, 10, 1, 124] ””” |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 不适用（原文） | {python} def incr_list(l: list): ”””返回一个元素值都增加 1 的列表。¿¿¿ incr_list([1,
    2, 3]) [2, 3, 4] ¿¿¿ incr_list([5, 3, 5, 2, 3, 3, 9, 0, 123]) [6, 4, 6, 3, 4,
    4, 10, 1, 124] ””” |'
- en: '| Ambiguity | {python} def incr_list(l: list): ”””Return list with elements
    incremented by a number. ¿¿¿ incr_list([1, 2, 3]) [2, 3, 4] ¿¿¿ incr_list([5,
    3, 5, 2, 3, 3, 9, 0, 123]) [6, 4, 6, 3, 4, 4, 10, 1, 124] ””” |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 模糊性 | {python} def incr_list(l: list): ”””返回一个元素值都增加一个数的列表。¿¿¿ incr_list([1,
    2, 3]) [2, 3, 4] ¿¿¿ incr_list([5, 3, 5, 2, 3, 3, 9, 0, 123]) [6, 4, 6, 3, 4,
    4, 10, 1, 124] ””” |'
- en: '| Incompleteness | {python} def incr_list(l: list): ”””Return list with elements
    incremented ””” |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 不完整性 | {python} def incr_list(l: list): ”””返回一个元素值都增加 ””” |'
- en: '| Inconsistency | {python} def incr_list(l: list): ”””Return list with elements
    incremented by 1. ¿¿¿ incr_list([1, 2, 3]) [3, 4, 5] ¿¿¿ incr_list([5, 3, 5, 2,
    3, 3, 9, 0, 123]) [7, 5, 7, 4, 5, 5, 11, 2, 125] ””” |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 不一致性 | {python} def incr_list(l: list): ”””返回一个元素值都增加 1 的列表。¿¿¿ incr_list([1,
    2, 3]) [3, 4, 5] ¿¿¿ incr_list([5, 3, 5, 2, 3, 3, 9, 0, 123]) [7, 5, 7, 4, 5,
    5, 11, 2, 125] ””” |'
- en: '| Inconsistency & Ambiguity | {python} def incr_list(l: list): ”””Return list
    with elements incremented by a number. ¿¿¿ incr_list([1, 2, 3]) [3, 4, 5] ¿¿¿
    incr_list([5, 3, 5, 2, 3, 3, 9, 0, 123]) [7, 5, 7, 4, 5, 5, 11, 2, 125] ””” |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 不一致性与模糊性 | {python} def incr_list(l: list): ”””返回一个元素值都增加一个数的列表。¿¿¿ incr_list([1,
    2, 3]) [3, 4, 5] ¿¿¿ incr_list([5, 3, 5, 2, 3, 3, 9, 0, 123]) [7, 5, 7, 4, 5,
    5, 11, 2, 125] ””” |'
- en: Table 2. Example of HumanEvalComm built upon HumanEval. The modified problem
    descriptions are shown in this table for problem number 42 of HumanEval. Specifically,
    the descriptions of the problem were modified to be inconsistent, ambiguous, or
    incomplete. The main goal of the HumanEvalComm dataset is to evaluate the degree
    of communication.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2. 基于 HumanEval 构建的 HumanEvalComm 示例。此表中显示了 HumanEval 问题编号 42 的修改问题描述。具体而言，问题描述被修改为不一致、模糊或不完整。HumanEvalComm
    数据集的主要目标是评估沟通的程度。
- en: Modifying Problem Description. For each problem description, we manually change
    the problem description with regard to different clarification types. Modifying
    the problem descriptions is done manually by a software engineer with nearly a
    decade of experience in the industry. A second software engineer with more than
    15 years of development experience reviewed the changed descriptions. The disagreements
    were marked and discussed among the two annotators until they reached an agreement
    about the changes, according to the definitions of Ambiguity, Inconsistency, and
    Incompleteness from RE. Each problem description was read carefully, and modifications
    were applied to the problem description. The definitions and examples of ambiguous,
    inconsistent, or incomplete requirements were reviewed by both people before conducting
    the manual modification of the problem descriptions, although both of them have
    requirements engineering expertise.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 修改问题描述。对于每个问题描述，我们根据不同的澄清类型手动修改问题描述。问题描述的修改是由一位在行业中有近十年经验的软件工程师手动完成的。另一位拥有超过
    15 年开发经验的软件工程师审核了修改后的描述。双方对修改进行标记并讨论，直到就变更达成一致，依据来自 RE 的模糊性、不一致性和不完整性的定义。每个问题描述都被仔细阅读，并对问题描述进行了修改。两人都审查了模糊、不一致或不完整要求的定义和示例，然后进行手动修改问题描述，尽管他们都具有需求工程的专业知识。
- en: 'For each problem, we applied six different modifications: (1a) making the problem
    description ambiguous; (1c) modifying the description to be inconsistent; (1p)
    changing the problem description to make it incomplete. The next three modifications
    that we refer to as (2ac), (2cp), and (2ap) are a combination of the initial changes,
    being ‘ambiguous and inconsistent’, ‘inconsistent and incomplete’, and ‘ambiguous
    and incomplete’, respectively. For any of the above modifications, our standard
    is that applying the modification to the problem should trigger clarifying questions,
    which are necessary for generating the correct code.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个问题，我们应用了六种不同的修改：（1a）使问题描述模糊；（1c）修改描述使其不一致；（1p）更改问题描述使其不完整。接下来的三种修改，我们称之为（2ac）、（2cp）和（2ap），分别是初始更改的组合，即“模糊且不一致”、“不一致且不完整”和“模糊且不完整”。对于上述任何修改，我们的标准是应用该修改后，问题应触发澄清问题，这些问题对生成正确的代码是必要的。
- en: 'Specifically, for 1a, to make the descriptions ambiguous, we tried to change
    the statement such that a human reader can interpret the statement in different
    ways. However, in practice, we found it very difficult to perform ambiguous modifications:
    adding Ambiguity in description only may not be enough to trigger clarifying questions,
    since we have additional information such as test examples, common sense reasoning,
    and function signatures. In other words, the description becomes ambiguous, but
    the test examples and function signatures are also given in the description, so
    that the right requirements can be inferred and thus correct code can be generated,
    without having to ask clarifying questions. Our solution to this issue is that
    we apply both Ambiguity and incorrectness to the description because it’s much
    easier and safer to trigger clarifying questions using Ambiguity and a certain
    level of incorrectness, instead of Ambiguity only. For example, changing the description
    from ”sort the array descendingly” to ”sort the array” may not trigger a question,
    because the function signature or test cases can imply the sorting is in descending
    order. However, changing the description to ”sort the array (descendingly or ascendingly)”
    can trigger questions.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 对于1a，我们尝试改变陈述，使其对人类读者来说可以有不同的解释，从而使描述变得模糊。然而，实际上，我们发现进行模糊修改非常困难：仅在描述中添加模糊性可能不足以触发澄清问题，因为我们还有测试示例、常识推理和函数签名等额外信息。换句话说，描述变得模糊，但测试示例和函数签名也在描述中提供，这样可以推断出正确的要求，从而生成正确的代码，而无需提出澄清问题。我们对此问题的解决方案是对描述应用模糊性和不正确性，因为使用模糊性和一定程度的不正确性来触发澄清问题比仅使用模糊性要容易和安全。例如，将描述从“对数组进行降序排序”改为“对数组进行排序”可能不会触发问题，因为函数签名或测试用例可以暗示排序是降序的。然而，将描述更改为“对数组进行排序（降序或升序）”可以触发问题。
- en: For 1c, to make the descriptions inconsistent, we mainly changed the examples
    such that the output of the example does not match or contradict the problem description.
    It should be noted that most of the problem descriptions in the HumanEval benchmark
    contain examples of test cases with the input and output. When applying inconsistent
    modification, for each problem, we changed the output of the test examples in
    a meaningful way rather than randomly, to enhance the contradiction between test
    examples and text description.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于1c，为了使描述不一致，我们主要更改了示例，使示例的输出与问题描述不匹配或相矛盾。需要注意的是，大多数HumanEval基准中的问题描述包含具有输入和输出的测试用例示例。在应用不一致修改时，对于每个问题，我们以有意义的方式而非随机方式更改测试示例的输出，以增强测试示例和文本描述之间的矛盾。
- en: In terms of 1p, we removed some parts of the description as incomplete modification.
    We made sure that after applying the incomplete modification, it’s not possible
    to generate the correct code, without asking questions to recover the missing
    content.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在1p方面，我们作为不完整修改移除了一些描述部分。我们确保在应用不完整修改后，不可能生成正确的代码，而无需提出问题以恢复缺失的内容。
- en: For 2ac, 2cp, and 2ap, we directly applied a combination of two clarification
    types from 1a, 1c, and 1p. For these cases, we create a new modification only
    if applying a combination of two types leads to a new description that is different
    from any of the two types. Therefore, for each problem, 1a, 1c, and 1p always
    exist, but 2ac, 2cp, or 2ap may not exist. Overall, the process of changing the
    descriptions took approximately 100 hours for initial modification and 30 hours
    to review and discuss the disagreements and come to a consensus.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 2ac、2cp 和 2ap，我们直接应用了 1a、1c 和 1p 的两种澄清类型的组合。对于这些情况，只有当应用两种类型的组合导致新描述不同于任何一种类型时，我们才会创建新的修改。因此，对于每个问题，1a、1c
    和 1p 总是存在，但 2ac、2cp 或 2ap 可能不存在。总体而言，修改描述的过程初步修改花费了大约 100 小时，审核和讨论分歧并达成共识花费了 30
    小时。
- en: Table [2](#S2.T2 "Table 2 ‣ 2.1\. Benchmark Collection ‣ 2\. Benchmark Construction
    ‣ Benchmarking the Communication Competence of Code Generation for LLMs and LLM
    Agent") shows an example of the original problem description and three modified
    versions for problem number 42 in HumanEval. In this example, for Ambiguity, ”incremented
    by 1” is modified to ”incremented by a number”, forming an ambiguous description.
    For Incompleteness, a part of the text description and example test cases are
    removed. For Inconsistency, the output of examples is modified so that it contradicts
    the text description. For Inconsistency and Ambiguity, a combination of Inconsistency
    and Ambiguity is applied, making it a more challenging case to generate the correct
    code. It is worth mentioning that before constructing HumanEvalComm, we manually
    verified the problem descriptions in the HumanEval dataset and verified that the
    original problem descriptions do not have clarification issues (Ambiguity, Inconsistency,
    or Incompleteness), so we chose all of the 164 problems in HumanEval dataset in
    our evaluation.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 [2](#S2.T2 "表格 2 ‣ 2.1\. 基准集合 ‣ 2\. 基准构建 ‣ 基准化代码生成的通信能力") 展示了原始问题描述及人类评估中问题编号
    42 的三个修改版本的示例。在这个示例中，对于歧义性，"incremented by 1" 被修改为 "incremented by a number"，形成了一个模糊的描述。对于不完整性，文本描述和示例测试用例的一部分被删除。对于不一致性，示例的输出被修改，使其与文本描述相矛盾。对于不一致性和歧义性，应用了不一致性和歧义性的组合，使其成为一个更具挑战性的生成正确代码的案例。值得一提的是，在构建
    HumanEvalComm 之前，我们手动验证了 HumanEval 数据集中的问题描述，并确认原始问题描述不存在澄清问题（歧义性、不一致性或不完整性），因此我们在评估中选择了
    HumanEval 数据集中的所有 164 个问题。
- en: 2.2\. Evaluation Measurement
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2\. 评估测量
- en: We introduce the following metrics to effectively evaluate the communication
    competency of the models in code generation tasks.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们引入了以下指标，以有效评估模型在代码生成任务中的沟通能力。
- en: 'Communication Rate. We propose the communication rate to evaluate the degree
    of communication skills for a given model. The communication rate is intended
    to capture the percentage of responses with clarifying questions instead of code
    for problems in HumanEvalComm. In the experiment, the prompt we use lets the model
    “either generate Python3 code (Respond directly with code only with markdown),
    or ask clarifying questions”. Therefore, in this work, we define the communication
    rate as the percentage of responses with no code snippets (non-code) for the initial
    modified problem descriptions:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 通信率。我们提出了通信率来评估给定模型的沟通能力。通信率旨在捕捉 HumanEvalComm 问题中以澄清性问题代替代码的响应百分比。在实验中，我们使用的提示让模型“要么生成
    Python3 代码（仅用 markdown 直接回应代码），要么提出澄清问题”。因此，在这项工作中，我们定义通信率为初始修改问题描述中没有代码片段（非代码）的响应百分比：
- en: '|  | $1$2 |  |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  |'
- en: In the experiment, we found that this simple metric that distinguishes whether
    the model returns code or non-code is already an effective approximation of communication
    skills.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在实验中，我们发现这个简单的指标，区分模型返回代码或非代码，已经是沟通技能的有效近似。
- en: 'Good Question Rate. In this research, we leverage a new LLM-based evaluator
    to give a question quality label for clarifying questions returned by the models.
    The labels are Good (The model asks insightful questions that help recover all
    the missing info), Fair (The model asks OK questions, but the questions do not
    fully cover the missing info), Bad (The model asks no questions or irrelevant
    questions that do not help at all to recover the missing/clarifying information).
    Given the question quality label, we define Good Question Rate as the percentage
    of responses with Good question quality labels:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 好问题率。在这项研究中，我们利用了一种基于新型 LLM 的评估器来为模型返回的澄清问题打上质量标签。标签包括好（模型提出了有见地的问题，帮助恢复所有缺失的信息）、一般（模型提出了还可以的问题，但问题并未完全覆盖缺失的信息）、差（模型没有提出任何问题或提出了无关的问题，无法帮助恢复缺失/澄清的信息）。给定问题质量标签后，我们将好问题率定义为标记为好问题质量标签的响应的百分比：
- en: '|  | $1$2 |  |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  |'
- en: Pass@K. In evaluation, pass@k is a popular and widely used metric for evaluating
    the task of code generation (Chen et al., [2021](#bib.bib13); Min et al., [2023](#bib.bib42);
    Zhang et al., [2023a](#bib.bib80)). Pass@k is defined as the ratio of ‘solved’
    problems, in which as a problem is ‘solved‘ if any of the $k$ code samples pass
    all the tests. Hence, we used Pass@1 in our evaluation.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Pass@K。在评估中，pass@k 是一种流行且广泛使用的代码生成任务评估指标（Chen 等， [2021](#bib.bib13)；Min 等， [2023](#bib.bib42)；Zhang
    等， [2023a](#bib.bib80)）。Pass@k 定义为“解决”的问题的比例，其中“解决”是指任何 $k$ 个代码样本都通过了所有测试。因此，我们在评估中使用了
    Pass@1。
- en: Test Pass Rate. Besides the widely used pass@k, Test Pass Rate is also commonly
    used for evaluating code generation (Ouyang et al., [2023](#bib.bib47); Hendrycks
    et al., [2021](#bib.bib27)). Specifically, the Test Pass Rate is defined as the
    proportion of successfully passed test cases in relation to the total number of
    test cases for LLM-generated code. This metric is useful in this work since it
    helps capture whether getting the right information by asking clarifying questions
    can indeed increase the correctness of generated code.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 测试通过率。除了广泛使用的 pass@k，测试通过率也是常用于评估代码生成的指标（Ouyang 等， [2023](#bib.bib47)；Hendrycks
    等， [2021](#bib.bib27)）。具体而言，测试通过率定义为成功通过的测试用例占 LLM 生成代码的所有测试用例的比例。这个指标在本工作中非常有用，因为它有助于捕捉通过提问澄清信息是否确实能提高生成代码的正确性。
- en: 3\. Empirical Study
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 实证研究
- en: 3.1\. Research Questions
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1\. 研究问题
- en: In this section, we describe the research questions that we explore in this
    study.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们描述了在这项研究中探索的研究问题。
- en: 'RQ1: How do Code LLMs perform in communication competency when requirements
    in the problem descriptions are incomplete, inconsistent, ambiguous? The rationale
    of RQ1 is centered around understanding and examining the current Code LLMs regarding
    their communication capabilities in code generation. The aim is to provide an
    initial understanding of the limitations and areas where Code LLMs may fall short
    in their communication skills. We evaluated different Code LLMs on carefully curated
    problems in the new benchmark, HumanEvalComm, where problem descriptions are manually
    modified to be incomplete, inconsistent, and ambiguous. We evaluated and compared
    the results of Code LLMs for different clarification categories, where one or
    two clarification types are applied to the original problems.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: RQ1：当问题描述中的要求不完整、不一致、模糊时，代码 LLM 的沟通能力如何？RQ1 的理由集中在理解和检查当前代码 LLM 在代码生成方面的沟通能力。目的是提供对代码
    LLM 在沟通技能方面的初步理解，包括其局限性和可能存在的不足。我们在新的基准测试 HumanEvalComm 中对不同的代码 LLM 进行了评估，在这些问题中，问题描述被手动修改为不完整、不一致和模糊。我们评估和比较了不同澄清类别的代码
    LLM 的结果，其中对原始问题应用了一到两种澄清类型。
- en: 'RQ2: How does Okanagan perform compared with Code LLMs in terms of communication
    skills? Given the recent advances in LLM-based agent in addressing various applications (Xi
    et al., [2023](#bib.bib70)), RQ2 aims to investigate the communication capabilities
    of our LLM agent approach, Okanagan, in comparison with Code LLMs. Therefore,
    we evaluated Okanagan which has a multi-round structure with customized prompts
    for code generation tasks. We analyzed and compared the results of Okanagan and
    Code LLMs.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: RQ2：Okanagan 在沟通技能方面与代码 LLM 的表现相比如何？鉴于最近 LLM 基于代理在解决各种应用中的进展（Xi 等， [2023](#bib.bib70)），RQ2
    旨在研究我们的 LLM 代理方法 Okanagan 相较于代码 LLM 的沟通能力。因此，我们评估了具有多轮结构和定制提示的 Okanagan，以进行代码生成任务。我们分析和比较了
    Okanagan 和代码 LLM 的结果。
- en: 3.2\. Methodology Overview
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2\. 方法概述
- en: '![Refer to caption](img/6c9c3691bc5db279b925ffb733a7e87a.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/6c9c3691bc5db279b925ffb733a7e87a.png)'
- en: Figure 1. The visual illustration of the methodology on the evaluation of communication
    skills for Large Language Models of code.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1. 对代码的大型语言模型进行交流技能评估的方法论可视化说明。
- en: Overview. Figure [1](#S3.F1 "Figure 1 ‣ 3.2\. Methodology Overview ‣ 3\. Empirical
    Study ‣ Benchmarking the Communication Competence of Code Generation for LLMs
    and LLM Agent") shows the overview of our methodology for collecting the benchmark
    and conducting the empirical study. We first create the HumanEvalComm benchmark,
    by modifying 164 problem descriptions of the original HumanEval benchmark for
    code generation tasks using the taxonomy of clarification types, as described
    in Section [2](#S2 "2\. Benchmark Construction ‣ Benchmarking the Communication
    Competence of Code Generation for LLMs and LLM Agent"). Second, we conduct evaluation
    and empirical studies based on HumanEvalComm to evaluate the communication competency
    of different models.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 概述。图[1](#S3.F1 "图 1 ‣ 3.2\. 方法概述 ‣ 3\. 实证研究 ‣ 对 LLMs 和 LLM Agent 的代码生成交流能力进行基准测试")展示了我们收集基准和进行实证研究的方法论概述。我们首先创建了
    HumanEvalComm 基准，通过使用澄清类型的分类法修改了原始 HumanEval 基准中 164 个问题描述，如第[2](#S2 "2\. 基准构建
    ‣ 对 LLMs 和 LLM Agent 的代码生成交流能力进行基准测试")节所述。其次，我们基于 HumanEvalComm 进行评估和实证研究，以评估不同模型的交流能力。
- en: Figure [2](#S3.F2 "Figure 2 ‣ 3.2\. Methodology Overview ‣ 3\. Empirical Study
    ‣ Benchmarking the Communication Competence of Code Generation for LLMs and LLM
    Agent") shows the flowchart for the evaluation of models, Code LLMs, and Okanagan.
    For each programming problem in the HumanEvalComm, there are up to six modified
    problem descriptions as described earlier in Table [1](#S2.T1 "Table 1 ‣ 2.1\.
    Benchmark Collection ‣ 2\. Benchmark Construction ‣ Benchmarking the Communication
    Competence of Code Generation for LLMs and LLM Agent"). For each modified problem,
    a prompt is used as the input of the model to either generate code or ask clarifying
    questions if needed. Then, if the model asks clarifying questions rather than
    generates code directly, the questions are sent to an LLM-based Evaluator, which
    evaluates the questions and generates a reply to answer the questions, based on
    all of the available information, including the modified problem, original problem,
    and the clarifying questions. Finally, the answers and the previous conversations
    are sent to the model to generate the code again directly.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图[2](#S3.F2 "图 2 ‣ 3.2\. 方法概述 ‣ 3\. 实证研究 ‣ 对 LLMs 和 LLM Agent 的代码生成交流能力进行基准测试")展示了对模型、代码
    LLMs 和 Okanagan 的评估流程图。对于 HumanEvalComm 中的每个编程问题，如表[1](#S2.T1 "表 1 ‣ 2.1\. 基准收集
    ‣ 2\. 基准构建 ‣ 对 LLMs 和 LLM Agent 的代码生成交流能力进行基准测试")中所述，最多有六个修改过的问题描述。对于每个修改过的问题，使用一个提示作为模型的输入，生成代码或在需要时提出澄清问题。然后，如果模型提出澄清问题而不是直接生成代码，这些问题会发送到基于
    LLM 的评估器，评估器根据所有可用的信息，包括修改过的问题、原始问题和澄清问题，评估问题并生成回答。最后，答案和之前的对话会发送到模型中，以直接生成代码。
- en: '![Refer to caption](img/f7d9301dbf049988bc28994dbae2b677.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/f7d9301dbf049988bc28994dbae2b677.png)'
- en: Figure 2. Flowchart for the evaluation of models, either Code LLMs or Okanagan
    (LLM agent), in communication capability.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2. 模型（无论是代码 LLM 还是 Okanagan（LLM agent））的交流能力评估流程图。
- en: LLM-based evaluator. With the advances of LLMs, a recent series of work has
    been proposed to use the powerful LLMs as the reference-free evaluators on Natural
    Language Generation (NLG) tasks (Kocmi and Federmann, [2023](#bib.bib33); Wang
    et al., [2023a](#bib.bib64); Kim et al., [2023](#bib.bib32); Kotonya et al., [2023](#bib.bib34);
    Gao et al., [2024](#bib.bib22)). Given the expensive human efforts of human evaluations,
    we used the LLM-based evaluator to generate an answer to reply to the list of
    clarifying questions from the models (Kotonya et al., [2023](#bib.bib34); Gao
    et al., [2024](#bib.bib22)). We prompted the LLM-based evaluator with the modified
    problem, original problem, and clarifying questions. The role of the LLM-based
    evaluator in this work is to 1) generate answers to the clarifying questions,
    and 2) calculate Good Question Rate, represented by an integer. The Good Question
    Rate is one of the evaluation metrics in our experiment. As for implementation,
    we used GPT 3.5 in the LLM-based evaluator in the evaluation. We tested both zero-shot
    and one-shot prompting, but in our evaluation, we found that one-shot prompting
    does not improve performance. This also aligns with the finding in literature (Kotonya
    et al., [2023](#bib.bib34); Gao et al., [2024](#bib.bib22)). The detailed prompt
    of LLM-based evaluator is shown as follows.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLM的评估器。随着LLM的进步，最近有一系列工作提出使用强大的LLM作为自然语言生成（NLG）任务的无参考评估器（Kocmi 和 Federmann，[2023](#bib.bib33)；Wang
    等，[2023a](#bib.bib64)；Kim 等，[2023](#bib.bib32)；Kotonya 等，[2023](#bib.bib34)；Gao
    等，[2024](#bib.bib22)）。鉴于人工评估的高昂成本，我们使用了基于LLM的评估器来生成回答，以回应模型的澄清问题列表（Kotonya 等，[2023](#bib.bib34)；Gao
    等，[2024](#bib.bib22)）。我们将修改过的问题、原始问题和澄清问题作为提示输入给基于LLM的评估器。该评估器在这项工作中的角色是：1）生成对澄清问题的回答，2）计算“好问题率”，用整数表示。“好问题率”是我们实验中的评估指标之一。在实施方面，我们在评估中使用了GPT
    3.5的LLM-based评估器。我们测试了零-shot和one-shot提示，但在我们的评估中发现one-shot提示并没有提高性能。这也与文献中的发现一致（Kotonya
    等，[2023](#bib.bib34)；Gao 等，[2024](#bib.bib22)）。LLM-based评估器的详细提示如下。
- en: 'Prompt for LLM-Based Evaluator: The original description of a coding problem
    is modified so that the requirements become inconsistent, incomplete, or ambiguous.
    Given the modified description, some clarifying questions were raised to clarify
    the description. Given the original and modified problem description, evaluate
    the quality of the clarifying questions. Please provide an integer representing
    the quality of questions (3: Good questions that recover the modified requirements;
    2: Fair questions but they cannot help recover the modified requirements; 1: No
    questions).'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: LLM-Based Evaluator的提示：编码问题的原始描述被修改，使要求变得不一致、不完整或模糊。根据修改后的描述，提出了一些澄清问题以澄清描述。根据原始和修改后的问题描述，评估澄清问题的质量。请提供一个整数表示问题的质量（3：恢复修改后要求的好问题；2：尚可的问题但无法帮助恢复修改后要求；1：没有问题）。
- en: QUALITY=[your int]
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: QUALITY=[你的整数]
- en: Please also provide answers to the clarifying questions to recover the modified
    requirements in the original problem description compared to the modified one.
    If there are no clarifying questions at all, return empty answers.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 请还提供回答以恢复原始问题描述中的修改要求。如果没有澄清问题，请返回空回答。
- en: ANSWERS=“‘[your answer]”’
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ANSWERS=“‘[你的回答]”’
- en: Please strictly follow the format QUALITY=[the int] and ANSWERS=“‘[the answer]”’
    in the response! Surround your answer with markdown!
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 请严格按照格式 QUALITY=[整数] 和 ANSWERS=“‘[回答]”’ 在回复中！用Markdown格式包围你的答案！
- en: 'Questions: {clarifying_questions}'
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'Questions: {澄清问题}'
- en: 'Modified Problem Description: {problem}'
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'Modified Problem Description: {问题}'
- en: 'Original Description: {original_problem}'
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'Original Description: {原始问题}'
- en: 'We manually checked the results of the LLM-based evaluator to see whether the
    output of the evaluator, the generated answers, and the evaluation of the questions,
    were correct. Overall, the generated answers and Good Question Rates are reasonable,
    but we do see some mistakes in both the generated answers and the Good Question
    Rates. For the Good Question Rates, there are some cases where the Good Question
    Rate from the LLM-based evaluator is 2 or 3 when there are no clarifying questions:
    For example, the ”questions” from the model are a combination of explanation and
    code, but no clarifying questions. This is somewhat related to the reported limitation (Gao
    et al., [2024](#bib.bib22)) that LLM evaluators prefer to give high scores to
    responses that conflict with the facts in the dialogue history (Liu et al., [2023a](#bib.bib38)).
    For generated answers, we sometimes observe that the provided answers do not recover
    the original requirements, due to either the evaluator itself or “no clarifying
    questions” mentioned above. To mitigate this issue, we have optimized the prompt
    for the LLM-based evaluator several times and checked the results manually. This
    includes adding sentences like “Please strictly follow the format QUALITY=[the
    int] and ANSWERS=“‘[the answer]”’ in the response!”, and “Surround your answer
    with markdown!” which eliminated many cases of format errors (answers and rates
    cannot be extracted correctly). Although the LLM-based evaluator shows effectiveness
    in our task, we understand that LLM-based NLG evaluation is still challenging (Gao
    et al., [2024](#bib.bib22); Liu et al., [2023a](#bib.bib38)), and future work
    is required to address the errors mentioned above.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们手动检查了LLM评估器的结果，以查看评估器的输出、生成的答案和问题的评估是否正确。总体而言，生成的答案和良好问题率是合理的，但我们确实发现生成的答案和良好问题率中存在一些错误。对于良好问题率，有些情况下LLM评估器的良好问题率为2或3，而没有澄清问题：例如，模型中的“问题”是解释和代码的组合，但没有澄清问题。这与报告的限制（Gao
    et al., [2024](#bib.bib22)）有关，即LLM评估器倾向于给出与对话历史中的事实相冲突的回答的高分（Liu et al., [2023a](#bib.bib38)）。对于生成的答案，我们有时观察到提供的答案未能恢复原始要求，这可能是由于评估器本身或上述“没有澄清问题”所致。为了缓解这个问题，我们多次优化了LLM评估器的提示，并手动检查结果。这包括添加像“请严格遵循格式QUALITY=[the
    int]和ANSWERS=“‘[the answer]”’！”以及“用markdown包围你的答案！”这样的句子，这消除了许多格式错误（答案和评分无法正确提取）。尽管LLM评估器在我们的任务中显示了有效性，但我们理解LLM基础的NLG评估仍然具有挑战性（Gao
    et al., [2024](#bib.bib22); Liu et al., [2023a](#bib.bib38)），未来的工作需要解决上述错误。
- en: 3.3\. Code Large Language Models
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3\. 大型语言模型
- en: We performed our evaluation on five widely used LLMs. This includes three open-sourced
    instruction-tuned Code LLMs, one open-sourced instruction-tuned LLM, and one commercial
    LLM. For open-source models, we used models with the largest possible model size
    within our limited computing resources in our evaluation.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对五种广泛使用的LLM进行了评估。这包括三种开源的调整指令版Code LLM、一种开源的调整指令版LLM和一种商业LLM。对于开源模型，我们在评估中使用了在有限计算资源下可能达到的最大模型大小。
- en: •
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: CodeLlama (Instruction tuned version, 13B) (Roziere et al., [2023](#bib.bib52))
    is an open-source LLM released by Meta for coding, built on top of Llama 2, with
    foundation models and instruction models. CodeLlama was chosen because of its
    wide usage and top performance in HumanEval. We tested the instruction model CodeLlama-Instruct-13B
    in our experiment since we did not have the computing resources to run models
    with 34B. The same applies to the rest open-source models.
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: CodeLlama（调整指令版，13B）（Roziere et al., [2023](#bib.bib52)）是由Meta发布的开源LLM，用于编码，建立在Llama
    2基础上，具有基础模型和指令模型。选择CodeLlama是因为它在HumanEval中的广泛使用和顶级性能。由于我们没有运行34B模型的计算资源，我们在实验中测试了指令模型CodeLlama-Instruct-13B。其余开源模型也是如此。
- en: •
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: DeepSeek Coder (Instruction tuned version, 7B) (Guo et al., [2024](#bib.bib24))
    is an open-source Code LLM trained on both 87% code and 13% natural language.
    Each of the models was pre-trained on 2 trillion tokens. We selected this model
    because it achieved top 5 performance in Big Code Models Leaderboard (big, [2024](#bib.bib2))
    on the HuggingFace platform. The Big Code Models Leaderboard (big, [2024](#bib.bib2))
    evaluates the performance of base multilingual code generation models on the HumanEval
    benchmark and MultiPL-E. We used the model of 7 billion parameters in the evaluation.
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: DeepSeek Coder（指令调优版本，7B）（Guo et al., [2024](#bib.bib24)）是一个开源代码LLM，训练数据包括87%代码和13%自然语言。每个模型在2万亿标记的数据上进行了预训练。我们选择了这个模型，因为它在HuggingFace平台的Big
    Code Models Leaderboard（big, [2024](#bib.bib2)）中取得了前五名的表现。Big Code Models Leaderboard（big,
    [2024](#bib.bib2)）评估了基础多语言代码生成模型在HumanEval基准测试和MultiPL-E上的性能。我们在评估中使用了70亿参数的模型。
- en: •
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: DeepSeek Chat (Instruction tuned version, 7B) (Bi et al., [2024](#bib.bib8))
    is an open-source LLM released by DeepSeek AI, trained on datasets of 2 trillion
    tokens. We selected this model because we wanted to evaluate the communication
    skills of models trained from different sources such as natural languages, code,
    and a combination of both. We compared its performance with the DeepSeek Coder
    to understand whether more natural languages in pre-training are beneficial to
    communication skills. We used the model of 7 billion parameters in the evaluation.
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: DeepSeek Chat（指令调优版本，7B）（Bi et al., [2024](#bib.bib8)）是DeepSeek AI发布的开源LLM，训练于2万亿标记的数据集。我们选择了这个模型，因为我们希望评估从不同来源（如自然语言、代码以及两者结合）训练的模型的沟通能力。我们将其性能与DeepSeek
    Coder进行了比较，以了解在预训练中更多自然语言是否对沟通能力有利。我们在评估中使用了70亿参数的模型。
- en: •
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: CodeQwen1.5 Chat (Instruction tuned version, 7B) (Bai et al., [2023](#bib.bib6))
    is an open-souce Code LLM released by Qwen Team, trained on 3 trillion tokens
    of code data. CodeQwen1.5 Chat is the Code-Specific version of Qwen1.5\. The model
    is a transformer-based decoder-only language model and includes group query attention
    (GQA) for efficient inference. We selected this model because it achieved top
    5 performance in Big Code Models Leaderboard (big, [2024](#bib.bib2)).
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: CodeQwen1.5 Chat（指令调优版本，7B）（Bai et al., [2023](#bib.bib6)）是Qwen团队发布的开源代码LLM，训练于3万亿标记的代码数据。CodeQwen1.5
    Chat是Qwen1.5的代码特定版本。该模型是一个基于变换器的解码器模型，包含组查询注意力（GQA）以实现高效推理。我们选择了这个模型，因为它在Big Code
    Models Leaderboard（big, [2024](#bib.bib2)）中取得了前五名的表现。
- en: •
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: ChatGPT, released by OpenAI are powerful models for generation tasks. We used
    parameter-frozen versions of models (gpt-3.5-turbo-0125) to ensure the reproducibility
    of the evaluation results.
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ChatGPT，由OpenAI发布，是用于生成任务的强大模型。我们使用了参数冻结的模型版本（gpt-3.5-turbo-0125）以确保评估结果的可重复性。
- en: Note that all of the evaluated models above are instruction-tuned models because,
    in the evaluation, the ability to ask clarifying questions with the given prompts
    is needed for the models. Besides instruction-tuned models, there are also foundation
    models, but we didn’t report results for foundation models. We found that foundation
    models without instruction tuned are not suitable for our evaluation, because
    their task is only to complete code and are not capable of instructions such as
    ”either generate code or ask clarifying questions”.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，上述所有评估模型都是经过指令调优的模型，因为在评估中，模型需要具备使用给定提示提出澄清问题的能力。除了指令调优的模型，还有基础模型，但我们没有报告基础模型的结果。我们发现没有经过指令调优的基础模型不适合我们的评估，因为它们的任务仅是完成代码，而不具备诸如“生成代码或提出澄清问题”的指令能力。
- en: '![Refer to caption](img/857e4a7b9041a2ef31decd465107c8d0.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/857e4a7b9041a2ef31decd465107c8d0.png)'
- en: Figure 3. An illustration of the process of Okanagan, an LLM agent approach.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图3. Okanagan，一个LLM代理方法的过程示意图。
- en: 3.4\. LLM-Agent Approach (Okanagan)
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4. LLM-Agent方法（Okanagan）
- en: 'Following the recent works in LLM agent, including collaboration mechanisms
    for LLM agents (Zhang et al., [2023c](#bib.bib78)) and self-correcting strategies
    of LLMs (Pan et al., [2023](#bib.bib48)), we proposed and evaluated an LLM agent
    approach, Okanagan, that leverages multi-round structure and customized prompt
    format for asking clarifying questions in code generation tasks. We introduce
    three rounds in Okanagan:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 根据近期LLM代理的研究，包括LLM代理的协作机制（Zhang et al., [2023c](#bib.bib78)）和LLM的自我纠错策略（Pan
    et al., [2023](#bib.bib48)），我们提出并评估了一个LLM代理方法Okanagan，该方法利用多轮结构和定制的提示格式来进行代码生成任务中的澄清问题。Okanagan中引入了三轮：
- en: •
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Round 1: the agent generates code directly given the modified problem.'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第1轮：代理根据修改后的问题直接生成代码。
- en: •
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Round 2: the agent generates clarifying questions (if needed) given the modified
    problem and generated code. If no questions, directly return the code generated
    in Round 1.'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第二轮：代理根据修改后的问题和生成的代码生成澄清问题（如有需要）。如果没有问题，则直接返回第1轮生成的代码。
- en: •
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Round 3: the agent generates code again, given the above conversation history
    (including the modified problem, clarifying questions, and their answers).'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第三轮：代理根据上述对话历史（包括修改后的问题、澄清问题及其答案）再次生成代码。
- en: 'This structure is inspired by the existing LLM agents approach  (Zhang et al.,
    [2023c](#bib.bib78)), with three rounds and customized prompts for our task of
    code generation. In terms of actions in each round, the action in Round 1 is to
    generate code. The action in Round 2 is to ask clarifying questions. As mentioned
    above, the code in Round 1 is returned if no questions are asked. Otherwise, a
    reflection is conducted to generate code again with the previous conversation
    history that includes clarifying questions and answers provided by the LLM-based
    evaluator. We adopted this structure because it can be easily extended to different
    parameter values. For example, we stop at Round 3 (in other words, we set the
    total number of rounds to 3) in our evaluation, but we can set a different number
    of rounds in theory. Besides the number of rounds, other parameters can be changed
    as well. We describe the set of parameters for Okanagan as follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结构的灵感来源于现有的LLM代理方法（张等，[2023c](#bib.bib78)），具有三轮和针对我们代码生成任务的定制提示。在每轮的行动方面，第1轮的行动是生成代码。第2轮的行动是提出澄清问题。如上所述，如果没有提问，则返回第1轮的代码。否则，会进行反思，根据包括澄清问题和由LLM评估器提供的答案在内的前期对话历史重新生成代码。我们采用这个结构是因为它可以很容易地扩展到不同的参数值。例如，在我们的评估中，我们停在第3轮（换句话说，我们将总轮数设置为3），但理论上可以设置不同的轮数。除了轮数，其他参数也可以更改。我们将Okanagan的参数集描述如下：
- en: (1)
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: number of agents (default is 1).
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 代理人数（默认为1）。
- en: (2)
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: number of rounds (default is 3).
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 回合数（默认为3）。
- en: (3)
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3)
- en: 'Action in each round: Generate code or ask questions (default is: Round 1 -
    Generate code, Round 2 - Ask questions, Round 3 - Generate code with Reflection)'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每轮的行动：生成代码或提问（默认为：第1轮 - 生成代码，第2轮 - 提问，第3轮 - 反思并生成代码）
- en: (4)
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (4)
- en: 'thinking pattern: Debate or Reflection (Zhang et al., [2023c](#bib.bib78)).
    (default is Reflection¹¹1Debate can be used only when multiple agents are used.
    In the implementation of Okanagan, we use a single agent, and thus in Round 3,
    the single agent reflects on the generated code in Round 1 based on the additional
    information in Round 1 (generated code) and Round 2 (clarifying questions and
    their answers provided by LLM-based evaluator). )'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 思维模式：辩论或反思（张等，[2023c](#bib.bib78)）。 （默认为反思¹¹1辩论仅在使用多个代理时才适用。在Okanagan的实现中，我们使用单个代理，因此在第3轮中，单个代理基于第1轮（生成的代码）和第2轮（由LLM评估器提供的澄清问题及其答案）的额外信息对第1轮生成的代码进行反思。）
- en: 'Note that we tried to minimize the complexity of Okanagan using default parameters
    such as one agent and three rounds, but in future work, the structure can easily
    scale from single-agent to multi-agents by setting the parameter for the number
    of agents. If more than one agent is used, and when the thinking pattern is Debate
    in a given round, the agents would exchange their previous responses as a way
    of collaboration. Given our specific task, compared with (Zhang et al., [2023c](#bib.bib78)),
    we added a new parameter in Okanagan: action in each round, to indicate the action
    for agents in a given round.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们尝试通过使用默认参数如一个代理和三轮来最小化Okanagan的复杂性，但在未来的工作中，结构可以通过设置代理数量的参数轻松扩展到多代理。如果使用多个代理，并且在给定回合中的思维模式是辩论，代理会交换他们之前的回应作为一种协作方式。鉴于我们的具体任务，与（张等，[2023c](#bib.bib78)）相比，我们在Okanagan中增加了一个新参数：每轮的行动，以指示代理在给定回合中的行动。
- en: LLM Agent Implementation in Evaluation. In our evaluation, we tested Okanagan
    using the default parameters as mentioned. We used ChatGPT 3.5 as the LLM in each
    of the three rounds in Okanagan mainly for easier comparison with ChatGPT 3.5\.
    For other LLM agent methods to compare in evaluation, we searched other publicly
    available LLM agent but did not find an appropriate open-sourced LLM agent implementation
    for code generation task with a focus and potential action to ask clarifying questions.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: LLM Agent 在评估中的实现。在我们的评估中，我们使用默认参数测试了 Okanagan。我们在 Okanagan 的三轮测试中均使用了 ChatGPT
    3.5 作为 LLM，以便于与 ChatGPT 3.5 进行比较。对于评估中的其他 LLM 代理方法，我们搜索了其他公开可用的 LLM 代理，但未找到适合代码生成任务的开源
    LLM 代理实现，特别是那些专注于并能主动提出澄清问题的实现。
- en: 3.5\. Experiment Setup
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.5. 实验设置
- en: In experiments, we implemented our evaluation in Python 3.12\. We partially
    used the code from  (Ouyang et al., [2023](#bib.bib47)) on the Non-Determinism
    of ChatGPT and from (Min et al., [2023](#bib.bib42)) on testing open-source models.
    All of the experiments for ChatGPT and Okanagan were conducted on a server with
    an Intel i7-6700K CPU (4.00 GHz), 32 GB RAM. The other experiments for open-source
    models that require GPUs were conducted on an Intel Xeon Gold 6130 CPU (2.1GHz),
    44 GB RAM, and 4 GPUs (Tesla V100-SXM2-16GB). The names of the HuggingFace models
    we use in the experiments are deepseek-coder-6.7b-instruct, deepseek-llm-7b-chat,
    CodeQwen1.5-7B-Chat, and CodeLlama-13b-Instruct-hf.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在实验中，我们在 Python 3.12 中实现了我们的评估。我们部分使用了 (Ouyang et al., [2023](#bib.bib47)) 关于
    ChatGPT 非确定性的代码，以及 (Min et al., [2023](#bib.bib42)) 关于测试开源模型的代码。ChatGPT 和 Okanagan
    的所有实验都在配备 Intel i7-6700K CPU（4.00 GHz）、32 GB 内存的服务器上进行。其他需要 GPU 的开源模型实验则在配备 Intel
    Xeon Gold 6130 CPU（2.1GHz）、44 GB 内存和 4 个 GPU（Tesla V100-SXM2-16GB）的服务器上进行。我们在实验中使用的
    HuggingFace 模型包括 deepseek-coder-6.7b-instruct、deepseek-llm-7b-chat、CodeQwen1.5-7B-Chat
    和 CodeLlama-13b-Instruct-hf。
- en: 4\. Results and Analysis
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4. 结果与分析
- en: 4.1\. Communication Competency of Code LLMs on HumanEvalComm (RQ1)
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1. Code LLM 在 HumanEvalComm 上的沟通能力（RQ1）
- en: 'To answer RQ1, we conducted experiments to evaluate the communication capability
    for problems in HumanEvalComm. Since we focus on the results of Code LLMs in RQ1,
    the results of Okanagan will be discussed separately in RQ2\. For each problem
    modified according to a category clarification type or combinations of clarification
    types, we followed the process in Figure [2](#S3.F2 "Figure 2 ‣ 3.2\. Methodology
    Overview ‣ 3\. Empirical Study ‣ Benchmarking the Communication Competence of
    Code Generation for LLMs and LLM Agent"). We calculated the following evaluation
    metrics: communication rate, good question rate, Pass@1, and Test Pass Rate. We
    compared Pass@1 and Test Pass Rate between the modified problem in HumanEvalComm
    and the original problem in HumanEval. Table [3](#S4.T3 "Table 3 ‣ 4.1\. Communication
    Competency of Code LLMs on HumanEvalComm (RQ1) ‣ 4\. Results and Analysis ‣ Benchmarking
    the Communication Competence of Code Generation for LLMs and LLM Agent") summarizes
    the overall results we generated for the evaluated models. Figure [4](#S4.F4 "Figure
    4 ‣ 4.1\. Communication Competency of Code LLMs on HumanEvalComm (RQ1) ‣ 4\. Results
    and Analysis ‣ Benchmarking the Communication Competence of Code Generation for
    LLMs and LLM Agent") rearranges the numbers in Table [3](#S4.T3 "Table 3 ‣ 4.1\.
    Communication Competency of Code LLMs on HumanEvalComm (RQ1) ‣ 4\. Results and
    Analysis ‣ Benchmarking the Communication Competence of Code Generation for LLMs
    and LLM Agent") in a visual illustration to facilitate a more direct comparison
    between different models. We first analyzed the overall results, then we looked
    into the results in each clarification category. For each category, we evaluated
    them with statistical testing using the Student’s t-test and obtained the p-value.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答 RQ1，我们进行了实验以评估 HumanEvalComm 中问题的沟通能力。由于我们关注的是 RQ1 中 Code LLMs 的结果，Okanagan
    的结果将在 RQ2 中单独讨论。对于根据类别澄清类型或澄清类型组合修改的每个问题，我们遵循了图 [2](#S3.F2 "Figure 2 ‣ 3.2\. Methodology
    Overview ‣ 3\. Empirical Study ‣ Benchmarking the Communication Competence of
    Code Generation for LLMs and LLM Agent") 中的过程。我们计算了以下评估指标：沟通率、良好问题率、Pass@1 和测试通过率。我们比较了
    HumanEvalComm 中修改问题和 HumanEval 中原始问题的 Pass@1 和测试通过率。表格 [3](#S4.T3 "Table 3 ‣ 4.1\.
    Communication Competency of Code LLMs on HumanEvalComm (RQ1) ‣ 4\. Results and
    Analysis ‣ Benchmarking the Communication Competence of Code Generation for LLMs
    and LLM Agent") 总结了我们为评估模型生成的整体结果。图 [4](#S4.F4 "Figure 4 ‣ 4.1\. Communication
    Competency of Code LLMs on HumanEvalComm (RQ1) ‣ 4\. Results and Analysis ‣ Benchmarking
    the Communication Competence of Code Generation for LLMs and LLM Agent") 将表格 [3](#S4.T3
    "Table 3 ‣ 4.1\. Communication Competency of Code LLMs on HumanEvalComm (RQ1)
    ‣ 4\. Results and Analysis ‣ Benchmarking the Communication Competence of Code
    Generation for LLMs and LLM Agent") 中的数据进行了视觉化展示，以便更直接地比较不同模型。我们首先分析了整体结果，然后查看了每个澄清类别中的结果。对于每个类别，我们使用统计检验进行了评估，并获得了
    p 值。
- en: Let’s first look at the communication rate. From Table [3](#S4.T3 "Table 3 ‣
    4.1\. Communication Competency of Code LLMs on HumanEvalComm (RQ1) ‣ 4\. Results
    and Analysis ‣ Benchmarking the Communication Competence of Code Generation for
    LLMs and LLM Agent") and Figure [4](#S4.F4 "Figure 4 ‣ 4.1\. Communication Competency
    of Code LLMs on HumanEvalComm (RQ1) ‣ 4\. Results and Analysis ‣ Benchmarking
    the Communication Competence of Code Generation for LLMs and LLM Agent"), the
    communication rate for ChatGPT, CodeLlama, and CodeQwen1.5 Chat is below 20%,
    significantly less than the perfect score of 100%. This means that for a problem
    description in which clarifying questions are needed for generating correct code,
    these models raise questions with less than a 20% chance. The recently released
    DeepSeek Coder and DeepSeek Chat achieved higher communication rates of 30.76%
    and 37.93%. One hypothesis to explain this is that the general capability from
    DeepSeek Chat is important for a high communication rate.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 首先我们来看一下沟通率。从表格 [3](#S4.T3 "Table 3 ‣ 4.1\. Communication Competency of Code
    LLMs on HumanEvalComm (RQ1) ‣ 4\. Results and Analysis ‣ Benchmarking the Communication
    Competence of Code Generation for LLMs and LLM Agent") 和图 [4](#S4.F4 "Figure 4
    ‣ 4.1\. Communication Competency of Code LLMs on HumanEvalComm (RQ1) ‣ 4\. Results
    and Analysis ‣ Benchmarking the Communication Competence of Code Generation for
    LLMs and LLM Agent") 中，ChatGPT、CodeLlama 和 CodeQwen1.5 Chat 的沟通率都低于 20%，远低于满分
    100%。这意味着，对于需要澄清问题以生成正确代码的问题描述，这些模型提出问题的机会低于 20%。最近发布的 DeepSeek Coder 和 DeepSeek
    Chat 实现了更高的沟通率，分别为 30.76% 和 37.93%。一种解释这一现象的假设是，DeepSeek Chat 的整体能力对于高沟通率非常重要。
- en: Besides communication rate, Good Question Rate is also a useful metric, because
    it reports the percentage of questions labeled as Good questions based on the
    content of questions using an LLM-based evaluator. In terms of Good Question Rate,
    likewise, as shown Table [3](#S4.T3 "Table 3 ‣ 4.1\. Communication Competency
    of Code LLMs on HumanEvalComm (RQ1) ‣ 4\. Results and Analysis ‣ Benchmarking
    the Communication Competence of Code Generation for LLMs and LLM Agent") and Figure [4](#S4.F4
    "Figure 4 ‣ 4.1\. Communication Competency of Code LLMs on HumanEvalComm (RQ1)
    ‣ 4\. Results and Analysis ‣ Benchmarking the Communication Competence of Code
    Generation for LLMs and LLM Agent"), ChatGPT, CodeLlama, and CodeQwen1.5 Chat
    have a lower average question quality than DeepSeek Coder and DeepSeek Chat. Particularly,
    ChatGPT has a much lower rate than other open-source models. From our manual inspection,
    one of the reasons is because the open-source models sometimes do not follow the
    instructions to return either code blocks or questions. They sometimes output
    code blocks together with some explanations. This type of response is not a clarifying
    question, but the LLM-based Evaluator sometimes labels them as “Good Question”,
    which we described in detail in section 3.2\. Regardless, based on the numbers,
    there is still significant room to improve on Good Question Rate.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 除了通信比率，**好问题比率**也是一个有用的指标，因为它报告了基于 LLM 评估器的内容将问题标记为好问题的百分比。在**好问题比率**方面，如表[3](#S4.T3
    "表 3 ‣ 4.1\. Code LLMs 在 HumanEvalComm 上的沟通能力 (RQ1) ‣ 4\. 结果与分析 ‣ LLMs 和 LLM Agent
    的代码生成沟通能力基准测试") 和图[4](#S4.F4 "图 4 ‣ 4.1\. Code LLMs 在 HumanEvalComm 上的沟通能力 (RQ1)
    ‣ 4\. 结果与分析 ‣ LLMs 和 LLM Agent 的代码生成沟通能力基准测试")所示，ChatGPT、CodeLlama 和 CodeQwen1.5
    Chat 的平均问题质量低于 DeepSeek Coder 和 DeepSeek Chat。特别是，ChatGPT 的比率远低于其他开源模型。根据我们的人工检查，其中一个原因是开源模型有时没有按照指示返回代码块或问题，而是有时将代码块与一些解释一起输出。这种类型的响应不是澄清问题，但
    LLM 评估器有时会将其标记为“好问题”，我们在第 3.2 节中详细描述了这一点。尽管如此，基于数据，**好问题比率**仍有显著提升空间。
- en: 'For pass rate measurements, ChatGPT, CodeLlama, and DeepSeek Chat achieve overall
    lower results than CodeQwen1.5 Chat and DeepSeek Coder for both Pass@1 and Test
    Pass Rate, based on Table [3](#S4.T3 "Table 3 ‣ 4.1\. Communication Competency
    of Code LLMs on HumanEvalComm (RQ1) ‣ 4\. Results and Analysis ‣ Benchmarking
    the Communication Competence of Code Generation for LLMs and LLM Agent") and Figure [4](#S4.F4
    "Figure 4 ‣ 4.1\. Communication Competency of Code LLMs on HumanEvalComm (RQ1)
    ‣ 4\. Results and Analysis ‣ Benchmarking the Communication Competence of Code
    Generation for LLMs and LLM Agent"). The trend is similar for both Pass@1 and
    Test Pass Rate. One hypothesis is that this result is in part due to the higher
    Pass@1 and Test Pass Rate of CodeQwen1.5 Chat and DeepSeek Coder in the original
    HumanEval benchmark. On the relative change, we see an increase in Pass@1 and
    Test Pass Rate from original HumanEval to HumanEvalComm for DeepSeek Chat. According
    to our investigation, this is because of illegal response formats: many responses
    from DeepSeek Chat for the original HumanEval do not have code markup, so these
    responses without code markup failed all the tests. For the rest open-source models,
    the relative drop in the Pass@1 is between 35% and 52%. The relative drop in the
    Test Pass Rate is between 17% and 35%.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 对于通过率的测量，ChatGPT、CodeLlama 和 DeepSeek Chat 在 Pass@1 和测试通过率上整体结果低于 CodeQwen1.5
    Chat 和 DeepSeek Coder，具体情况见表[3](#S4.T3 "表 3 ‣ 4.1\. Code LLMs 在 HumanEvalComm
    上的沟通能力 (RQ1) ‣ 4\. 结果与分析 ‣ LLMs 和 LLM Agent 的代码生成沟通能力基准测试") 和图[4](#S4.F4 "图 4
    ‣ 4.1\. Code LLMs 在 HumanEvalComm 上的沟通能力 (RQ1) ‣ 4\. 结果与分析 ‣ LLMs 和 LLM Agent
    的代码生成沟通能力基准测试")。Pass@1 和测试通过率的趋势相似。一个假设是，这一结果部分是由于 CodeQwen1.5 Chat 和 DeepSeek
    Coder 在原始 HumanEval 基准测试中有更高的 Pass@1 和测试通过率。在相对变化上，我们看到 DeepSeek Chat 从原始 HumanEval
    到 HumanEvalComm 的 Pass@1 和测试通过率都有所上升。根据我们的调查，这是由于非法响应格式：DeepSeek Chat 在原始 HumanEval
    中的许多响应没有代码标记，因此这些没有代码标记的响应未能通过所有测试。对于其他开源模型，Pass@1 的相对下降在 35% 到 52% 之间。测试通过率的相对下降在
    17% 到 35% 之间。
- en: '| Model | Pass@1 | Test Pass Rate | Comm. | Good |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | Pass@1 | 测试通过率 | 通信 | 好问题 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '|  | HmEval | HmEvalComm | HmEval | HmEvalComm | Rate | Question Rate |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '|  | HmEval | HmEvalComm | HmEval | HmEvalComm | 比率 | 问题比率 |'
- en: '| ChatGPT | 65.58% | 31.34% | 76.42% | 49.39% | 14.21% | 13.43% |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| ChatGPT | 65.58% | 31.34% | 76.42% | 49.39% | 14.21% | 13.43% |'
- en: '| CodeLlama | 29.88% | 19.35% | 45.71% | 37.79% | 10.16% | 37.55% |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| CodeLlama | 29.88% | 19.35% | 45.71% | 37.79% | 10.16% | 37.55% |'
- en: '| CodeQwen1.5 Chat | 76.83% | 47.61% | 84.4% | 62.89% | 4.82% | 41.68% |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| CodeQwen1.5 Chat | 76.83% | 47.61% | 84.4% | 62.89% | 4.82% | 41.68% |'
- en: '| DeepSeek Coder | 71.78% | 45.68% | 79.44% | 62.25% | 30.76% | 61.42% |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| DeepSeek Coder | 71.78% | 45.68% | 79.44% | 62.25% | 30.76% | 61.42% |'
- en: '| DeepSeek Chat | 12.8% | 26.32% | 13.86% | 44.52% | 37.93% | 58.71% |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| DeepSeek Chat | 12.8% | 26.32% | 13.86% | 44.52% | 37.93% | 58.71% |'
- en: '| Okanagan | 27.45% | 39.62% | 33.45% | 56.98% | 72.73% | 52.24% |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| Okanagan | 27.45% | 39.62% | 33.45% | 56.98% | 72.73% | 52.24% |'
- en: Table 3. Evaluation result across all clarification categories on Pass@1, Test
    Pass Rate, communication rate, and Good Question Rate with different models on
    HumanEvalComm (HmEvalComm in the table). Additionally, the Pass@1 and Test Pass
    Rate on the original problems in HumanEval (HmEval in the table) are also shown.
    Top 3 results are marked as bold.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3. 不同模型在所有澄清类别下的Pass@1、测试通过率、交流率和优质问题率的评估结果（表中的HumanEvalComm（HmEvalComm））。此外，还显示了HumanEval（表中的HmEval）原始问题的Pass@1和测试通过率。前3名结果标记为**粗体**。
- en: '![Refer to caption](img/bd5248318a9e4606a2986a3cf99fc07f.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/bd5248318a9e4606a2986a3cf99fc07f.png)'
- en: Figure 4. Comparison of the effectiveness of the models in Communication Rate,
    Good Question Rate (left), and Pass@1, Test Pass Rate (right). Note that in the
    right figure, the stars represent the original performance of the corresponding
    model with the same color in the HumanEval benchmark. This shows visually how
    the performance has changed when the problem description is modified.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4. 模型在交流率、优质问题率（左侧）和Pass@1、测试通过率（右侧）的效果比较。请注意，在右侧图中，星号表示对应模型在HumanEval基准中的原始表现，颜色相同。这直观地展示了当问题描述被修改时性能的变化。
- en: '| Clarification | Model | Pass@1 | Test Pass Rate | Comm. | Good |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| 澄清 | 模型 | Pass@1 | 测试通过率 | 交流 | 优质 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Category |  | HmEval | HmEvalComm (p-value) | HmEval | HmEvalComm (p-value)
    | Rate | Question Rate |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| Category |  | HmEval | HmEvalComm (p-value) | HmEval | HmEvalComm (p-value)
    | Rate | Question Rate |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 1a | ChatGPT | 65.58% | 33.77%*** | 76.42% | 54.98%*** | 5.84% | 4.55% |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 1a | ChatGPT | 65.58% | 33.77%*** | 76.42% | 54.98%*** | 5.84% | 4.55% |'
- en: '|  |  | (0.000) |  | (0.000) |  |  |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '|  |  | (0.000) |  | (0.000) |  |  |'
- en: '| CodeLlama | 29.88% | 16.46%*** | 45.71% | 36.24%** | 13.64% | 42.68% |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| CodeLlama | 29.88% | 16.46%*** | 45.71% | 36.24%** | 13.64% | 42.68% |'
- en: '|  |  | (0.004) |  | (0.037) |  |  |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '|  |  | (0.004) |  | (0.037) |  |  |'
- en: '| CodeQwen1.5 Chat | 76.83% | 46.34%*** | 84.4% | 62.62%*** | 5.84% | 43.29%
    |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| CodeQwen1.5 Chat | 76.83% | 46.34%*** | 84.4% | 62.62%*** | 5.84% | 43.29%
    |'
- en: '|  |  | (0.000) |  | (0.000) |  |  |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '|  |  | (0.000) |  | (0.000) |  |  |'
- en: '| DeepSeek Coder | 71.78% | 43.29%*** | 79.44% | 61.2%*** | 25.97% | 62.8%
    |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| DeepSeek Coder | 71.78% | 43.29%*** | 79.44% | 61.2%*** | 25.97% | 62.8%
    |'
- en: '|  |  |  | (0.000) |  | (0.000) |  |  |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (0.000) |  | (0.000) |  |  |'
- en: '|  | DeepSeek Chat | 12.8% | 21.95%** | 13.86% | 40.62%*** | 39.61% | 56.71%
    |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '|  | DeepSeek Chat | 12.8% | 21.95%** | 13.86% | 40.62%*** | 39.61% | 56.71%
    |'
- en: '|  |  |  | (0.029) |  | (0.000) |  |  |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (0.029) |  | (0.000) |  |  |'
- en: '|  | Okanagan | 27.45% | 44.81%*** | 33.45% | 64.22%*** | 65.58% | 52.60% |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '|  | Okanagan | 27.45% | 44.81%*** | 33.45% | 64.22%*** | 65.58% | 52.60% |'
- en: '|  |  |  | (0.001) |  | (0.000) |  |  |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (0.001) |  | (0.000) |  |  |'
- en: '| 1c | ChatGPT | 65.58% | 53.25%** | 76.42% | 66.37%** | 5.84% | 6.49% |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 1c | ChatGPT | 65.58% | 53.25%** | 76.42% | 66.37%** | 5.84% | 6.49% |'
- en: '|  |  | (0.027) |  | (0.028) |  |  |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '|  |  | (0.027) |  | (0.028) |  |  |'
- en: '| CodeLlama | 29.88% | 32.93% | 45.71% | 52.14% | 7.79% | 32.32% |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| CodeLlama | 29.88% | 32.93% | 45.71% | 52.14% | 7.79% | 32.32% |'
- en: '|  |  | (0.553) |  | (0.172) |  |  |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '|  |  | (0.553) |  | (0.172) |  |  |'
- en: '| CodeQwen1.5 Chat | 76.83% | 67.68%*** | 84.4% | 79.9%*** | 7.79% | 46.95%
    |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| CodeQwen1.5 Chat | 76.83% | 67.68%*** | 84.4% | 79.9%*** | 7.79% | 46.95%
    |'
- en: '|  |  | (0.000) |  | (0.000) |  |  |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '|  |  | (0.000) |  | (0.000) |  |  |'
- en: '| DeepSeek Coder | 71.78% | 61.59%* | 79.44% | 76.75% | 15.03% | 53.66% |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| DeepSeek Coder | 71.78% | 61.59%* | 79.44% | 76.75% | 15.03% | 53.66% |'
- en: '|  |  |  | (0.051) |  | (0.501) |  |  |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (0.051) |  | (0.501) |  |  |'
- en: '|  | DeepSeek Chat | 12.8% | 39.63%*** | 13.86% | 56.89%*** | 28.1% | 61.59%
    |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '|  | DeepSeek Chat | 12.8% | 39.63%*** | 13.86% | 56.89%*** | 28.1% | 61.59%
    |'
- en: '|  |  |  | (0.000) |  | (0.000) |  |  |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (0.000) |  | (0.000) |  |  |'
- en: '|  | Okanagan | 27.45% | 57.14%*** | 33.45% | 70.01%*** | 55.19% | 42.86% |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '|  | Okanagan | 27.45% | 57.14%*** | 33.45% | 70.01%*** | 55.19% | 42.86% |'
- en: '|  |  |  | (0.000) |  | (0.000) |  |  |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (0.000) |  | (0.000) |  |  |'
- en: '| 1p | ChatGPT | 65.58% | 27.95%*** | 76.42% | 44.14%*** | 31.68% | 26.71%
    |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| 1p | ChatGPT | 65.58% | 27.95%*** | 76.42% | 44.14%*** | 31.68% | 26.71%
    |'
- en: '|  |  | (0.001) |  | (0.000) |  |  |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '|  |  | (0.001) |  | (0.000) |  |  |'
- en: '| CodeLlama | 29.88% | 15.24%*** | 45.71% | 29.41%*** | 7.74% | 33.54% |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| CodeLlama | 29.88% | 15.24%*** | 45.71% | 29.41%*** | 7.74% | 33.54% |'
- en: '|  |  | (0.000) |  | (0.000) |  |  |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '|  |  | (0.000) |  | (0.000) |  |  |'
- en: '| CodeQwen1.5 Chat | 76.83% | 46.95%*** | 84.4% | 59.36%*** | 1.3% | 38.41%
    |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| CodeQwen1.5 Chat | 76.83% | 46.95%*** | 84.4% | 59.36%*** | 1.3% | 38.41%
    |'
- en: '|  |  | (0.000) |  | (0.000) |  |  |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '|  |  | (0.000) |  | (0.000) |  |  |'
- en: '| DeepSeek Coder | 71.78% | 45.12%*** | 79.44% | 58.57%*** | 48.7% | 68.9%
    |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| DeepSeek Coder | 71.78% | 45.12%*** | 79.44% | 58.57%*** | 48.7% | 68.9%
    |'
- en: '|  |  |  | (0.000) |  | (0.000) |  |  |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (0.000) |  | (0.000) |  |  |'
- en: '|  | DeepSeek Chat | 12.8% | 21.95%** | 13.86% | 43.73%*** | 37.66% | 55.49%
    |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '|  | DeepSeek Chat | 12.8% | 21.95%** | 13.86% | 43.73%*** | 37.66% | 55.49%
    |'
- en: '|  |  |  | (0.029) |  | (0.000) |  |  |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (0.029) |  | (0.000) |  |  |'
- en: '|  | Okanagan | 27.45% | 36.65%* | 33.45% | 54.16%*** | 93.17% | 58.39% |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '|  | Okanagan | 27.45% | 36.65%* | 33.45% | 54.16%*** | 93.17% | 58.39% |'
- en: '|  |  |  | (0.082) |  | (0.000) |  |  |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (0.082) |  | (0.000) |  |  |'
- en: Table 4. Evaluation result for clarification categories 1a,1c,1p on Pass@1,
    Test Pass Rate for original problems in HumanEval and modified problems in HumanEvalComm,
    communication rate, and Good Question Rate with different models. *p¡0.1; **p¡=0.05;
    ***p¡0.01
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 表4. 对于Pass@1的澄清类别1a、1c、1p的评估结果，HumanEval中的原始问题和HumanEvalComm中的修改问题的测试通过率，通信率，以及不同模型的良好问题率。*p¡0.1;
    **p¡=0.05; ***p¡0.01
- en: Breakdown on Categories with One Clarification Type. Besides overall results,
    we would like to further understand the correlation between results and different
    clarification categories. Table [4](#S4.T4 "Table 4 ‣ 4.1\. Communication Competency
    of Code LLMs on HumanEvalComm (RQ1) ‣ 4\. Results and Analysis ‣ Benchmarking
    the Communication Competence of Code Generation for LLMs and LLM Agent") shows
    the results breakdown on the clarification categories 1a, 1c, and 1p, where only
    one level of clarification type (Ambiguity, Inconsistency, and Incompleteness)
    is applied to the problem. For ChatGPT, among the three clarification types, Incompleteness
    has the overall highest communication rate, suppressing the communication rates
    of Ambiguity and Inconsistency. This means that Incompleteness is relatively easier
    to detect and raise than Ambiguity and Inconsistency for models such as ChatGPT,
    DeepSeek Coder, and DeepSeek Chat. Inconsistency has the lowest communication
    rate among the three types. One hypothesis to explain that is that Inconsistency
    requires stronger reasoning capability to detect. Good Question Rate follows similar
    patterns as the communication rate, indicating that the quality of questions is
    proportional to the communication rate for Code LLMs.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 针对具有单一澄清类型的类别的细分。除了总体结果外，我们还希望进一步了解结果与不同澄清类别之间的相关性。表 [4](#S4.T4 "表 4 ‣ 4.1\.
    HumanEvalComm上代码LLMs的沟通能力 (RQ1) ‣ 4\. 结果与分析 ‣ LLMs和LLM Agent在代码生成中的沟通能力基准测试")
    显示了澄清类别1a、1c和1p的结果细分，其中仅应用了一种澄清类型（模糊性、不一致性和不完整性）到问题上。对于ChatGPT，在三种澄清类型中，不完整性具有整体最高的沟通率，抑制了模糊性和不一致性的沟通率。这意味着对于ChatGPT、DeepSeek
    Coder和DeepSeek Chat等模型，不完整性相对比模糊性和不一致性更容易检测和提出。不一致性在三种类型中具有最低的沟通率。一个解释假设是，不一致性需要更强的推理能力来检测。良好问题率遵循与沟通率类似的模式，表明代码LLMs的提问质量与沟通率成正比。
- en: 'Two exceptions to the above statements are that CodeLlama and CodeQwen1.5 Chat
    achieved the lowest communication rate in the Incompleteness category than in
    Ambiguity and Inconsistency. Similar trends can be found in Good Question Rates.
    This shows that some Code LLMs such as CodeLlama and CodeQwen1.5 Chat are trained
    and designed in a way so that they tend to complete code rather than ask questions
    even when requirements are incomplete. This reflects the generative nature of
    LLMs: given a prompt, the LLM as a generative model essentially generates and
    completes text (or code in our scenario) based on the statistical model (Shanahan,
    [2024](#bib.bib55)). Thus, one hypothesis of the low result is that LLMs have
    disadvantages due to their generative nature when evaluating communication in
    coding tasks. This result also indicates that more intelligent AI agents such
    as LLM-based agents, where LLM as a generative model is a component, have the
    potential to outperform LLMs in the evaluation on communication capability (Shanahan,
    [2024](#bib.bib55)).'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 对上述陈述的两个例外是CodeLlama和CodeQwen1.5 Chat在“不完整性”类别中达到的交流率最低，而在“歧义”和“一致性”类别中较高。类似的趋势也可以在“良好问题”率中发现。这表明，一些Code
    LLMs如CodeLlama和CodeQwen1.5 Chat被训练和设计成更倾向于完成代码而非提问，即使需求不完整。这反映了LLMs的生成特性：给定一个提示，LLM作为生成模型本质上根据统计模型生成和完成文本（或在我们场景中的代码）（Shanahan,
    [2024](#bib.bib55)）。因此，低结果的一个假设是LLMs在评估编程任务中的沟通能力时由于其生成特性而存在劣势。这一结果也表明，更智能的AI代理，例如以LLM为组件的LLM基础代理，有潜力在沟通能力的评估中超过LLMs（Shanahan,
    [2024](#bib.bib55)）。
- en: For the testing performance of the generated code, interestingly, Incompleteness
    receives overall the lowest Pass@1 (12.8% $\sim$ 59.36%) for all of the models.
    One hypothesis is that if no clarifying questions were asked for problems with
    Incompleteness, the generated codes would be typically incorrect due to lack of
    information. Inconsistency has the highest Pass@1 and Test Pass Rate, because,
    for problems with Inconsistency, LLMs are sometimes able to generate correct code
    without asking clarifying questions. For 1a, 1c, and 1p categories, all except
    3 changes in Pass@1 and Test Pass Rate are statistically significant, with p-values
    less than 0.1.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，在生成代码的测试性能中，“不完整性”类别在所有模型中获得了总体最低的Pass@1（12.8% ~ 59.36%）。一个假设是，如果对于“不完整性”问题没有提出澄清问题，则生成的代码通常会因信息不足而不正确。“不一致性”具有最高的Pass@1和测试通过率，因为对于“不一致性”问题，LLMs有时能够在不提出澄清问题的情况下生成正确的代码。对于1a、1c和1p类别，除了Pass@1和测试通过率中的3个变化外，所有其他变化在统计上都是显著的，p值小于0.1。
- en: Breakdown on Categories with Two Clarification Types. Table [5](#S4.T5 "Table
    5 ‣ 4.1\. Communication Competency of Code LLMs on HumanEvalComm (RQ1) ‣ 4\. Results
    and Analysis ‣ Benchmarking the Communication Competence of Code Generation for
    LLMs and LLM Agent") shows the results breakdown on the clarification category
    of 2ac, 2ap, and 2cp, where a combination of two clarification types is applied
    to the problem. Compared with applying one clarification type in Table [4](#S4.T4
    "Table 4 ‣ 4.1\. Communication Competency of Code LLMs on HumanEvalComm (RQ1)
    ‣ 4\. Results and Analysis ‣ Benchmarking the Communication Competence of Code
    Generation for LLMs and LLM Agent"), two clarification types have on average slightly
    higher communication rates than one clarification type. This makes sense as a
    combination of two clarification types naturally triggers more questions than
    one type. Consequently, we see a similar trend for the Good Question metric.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 分类及两种澄清类型的详细分类。表格[5](#S4.T5 "Table 5 ‣ 4.1\. Communication Competency of Code
    LLMs on HumanEvalComm (RQ1) ‣ 4\. Results and Analysis ‣ Benchmarking the Communication
    Competence of Code Generation for LLMs and LLM Agent") 显示了在问题应用了两种澄清类型的情况下，2ac、2ap和2cp澄清类别的结果详细分类。与表格[4](#S4.T4
    "Table 4 ‣ 4.1\. Communication Competency of Code LLMs on HumanEvalComm (RQ1)
    ‣ 4\. Results and Analysis ‣ Benchmarking the Communication Competence of Code
    Generation for LLMs and LLM Agent")中应用一种澄清类型的情况相比，两种澄清类型的平均交流率略高。这是有道理的，因为两种澄清类型的组合自然会比一种类型引发更多的问题。因此，我们在“良好问题”指标上也观察到类似的趋势。
- en: In terms of testing performance for the combination of two clarification types,
    both the Pass@1 and Test Pass Rate decreased significantly from one clarification
    type to two types. Therefore, compared with one clarification type, a combination
    of two clarification types further reduces the Test Pass Rate significantly, but
    only slightly enlarges the communication rate and the quality of clarifying questions
    on average. The slight increase in communication rate is reasonable given the
    increased clarification difficulty. The decreased pass rates show that it is hard
    for the models to get the necessary requirements for solving the task given the
    challenging situation for combinations of clarification types. 2cp, with a combination
    of both Inconsistency and Incompleteness, results in lower Pass@1 and Test Pass
    Rate compared with 2ap and 2ac. For 2ac, 2cp, and 2ap categories, 75% of the changes
    in Pass@1 and Test Pass Rate are statistically significant since the p-values
    are less than 0.05 in these changes.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试两种澄清类型的组合表现方面，Pass@1和测试通过率从一种澄清类型减少到两种类型显著降低。因此，与一种澄清类型相比，两种澄清类型的组合显著降低了测试通过率，但仅略微扩大了沟通率和澄清问题的质量。鉴于澄清难度的增加，沟通率的轻微增加是合理的。减少的通过率表明，模型在面临澄清类型组合的挑战情况下，很难获得解决任务所需的必要要求。2cp，结合了不一致性和不完整性，相比于2ap和2ac，导致了更低的Pass@1和测试通过率。对于2ac、2cp和2ap类别，Pass@1和测试通过率的75%变化在统计上显著，因为这些变化的p值小于0.05。
- en: 'Answer
    to RQ1: More than 60% of responses from Code LLMs still generate code rather than
    ask questions when the problem descriptions are manually modified according to
    different clarification categories. Typically, the Pass@1 and Test Pass Rate of
    Code LLMs drop by 35% $\sim$ 35% respectively, with statistical significance in
    each category for over 75% numbers. Among the three clarification types, the Incompleteness
    category results in higher communication rates and Good Question Rates, but lower
    Pass@1 and Test Pass Rate than the Ambiguity and Inconsistency categories for
    Code LLMs. A combination of two clarification types leads to slightly higher communication
    rates but much lower Test Pass Rates than one clarification type.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '回答RQ1:
    当问题描述根据不同澄清类别被手动修改时，超过60%的Code LLM响应仍生成代码而不是提问。通常，Code LLMs的Pass@1和测试通过率分别下降35%
    $\sim$ 35%，每个类别的统计显著性超过75%。在三种澄清类型中，不完整性类别的沟通率和好问题率较高，但Pass@1和测试通过率低于模糊性和不一致性类别。两种澄清类型的组合导致略高的沟通率，但测试通过率远低于单一澄清类型。'
- en: '| Clarification | Model | Pass@1 | Test Pass Rate | Comm. | Good |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| 澄清 | 模型 | Pass@1 | 测试通过率 | 沟通 | 好 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Category |  | HmEval | HmEvalComm (p-value) | HmEval | HmEvalComm (p-value)
    | Rate | Question Rate |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| 类别 |  | HmEval | HmEvalComm (p值) | HmEval | HmEvalComm (p值) | 评分 | 问题评分 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 2ac | ChatGPT | 65.79% | 20.39%*** | 76.77% | 42.66%*** | 5.26% | 7.90% |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| 2ac | ChatGPT | 65.79% | 20.39%*** | 76.77% | 42.66%*** | 5.26% | 7.90% |'
- en: '|  |  | (0.000) |  | (0.000) |  |  |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '|  |  | (0.000) |  | (0.000) |  |  |'
- en: '| CodeLlama | 29.63% | 14.2%*** | 45.65% | 36.95%* | 12.5% | 42.59% |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| CodeLlama | 29.63% | 14.2%*** | 45.65% | 36.95%* | 12.5% | 42.59% |'
- en: '|  |  | (0.001) |  | (0.054) |  |  |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '|  |  | (0.001) |  | (0.054) |  |  |'
- en: '| CodeQwen1.5 Chat | 77.16% | 40.12%*** | 84.28% | 59.56%*** | 7.24% | 47.53%
    |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| CodeQwen1.5 Chat | 77.16% | 40.12%*** | 84.28% | 59.56%*** | 7.24% | 47.53%
    |'
- en: '|  |  | (0.000) |  | (0.000) |  |  |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '|  |  | (0.000) |  | (0.000) |  |  |'
- en: '| DeepSeek Coder | 71.43% | 40.74%*** | 79.18% | 61.72%*** | 26.97% | 58.64%
    |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| DeepSeek Coder | 71.43% | 40.74%*** | 79.18% | 61.72%*** | 26.97% | 58.64%
    |'
- en: '|  |  |  | (0.000) |  | (0.000) |  |  |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (0.000) |  | (0.000) |  |  |'
- en: '|  | DeepSeek Chat | 12.96% | 20.99%* | 14.03% | 39.09%*** | 44.08% | 64.2%
    |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '|  | DeepSeek Chat | 12.96% | 20.99%* | 14.03% | 39.09%*** | 44.08% | 64.2%
    |'
- en: '|  |  |  | (0.055) |  | (0.000) |  |  |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (0.055) |  | (0.000) |  |  |'
- en: '|  | Okanagan | 27.15% | 25.66% | 33.23% | 47.37%*** | 64.47% | 45.39% |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '|  | Okanagan | 27.15% | 25.66% | 33.23% | 47.37%*** | 64.47% | 45.39% |'
- en: '|  |  |  | (0.769) |  | (0.004) |  |  |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (0.769) |  | (0.004) |  |  |'
- en: '| 2cp | ChatGPT | 77.42% | 15.63%*** | 84.91% | 34.79%*** | 6.25% | 9.38% |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| 2cp | ChatGPT | 77.42% | 15.63%*** | 84.91% | 34.79%*** | 6.25% | 9.38% |'
- en: '|  |  | (0.000) |  | (0.000) |  |  |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '|  |  | (0.000) |  | (0.000) |  |  |'
- en: '| CodeLlama | 38.24% | 14.71%** | 60.9% | 33.04%*** | 9.68% | 29.41% |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| CodeLlama | 38.24% | 14.71%** | 60.9% | 33.04%*** | 9.68% | 29.41% |'
- en: '|  |  | (0.028) |  | (0.003) |  |  |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '|  |  | (0.028) |  | (0.003) |  |  |'
- en: '| CodeQwen1.5 Chat | 73.53% | 38.24%*** | 83.57% | 55.82%*** | 0% | 29.41%
    |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| CodeQwen1.5 Chat | 73.53% | 38.24%*** | 83.57% | 55.82%*** | 0% | 29.41%
    |'
- en: '|  |  | (0.003) |  | (0.004) |  |  |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '|  |  | (0.003) |  | (0.004) |  |  |'
- en: '| DeepSeek Coder | 70.59% | 29.41%*** | 80.93% | 50.97%*** | 12.9% | 52.94%
    |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| DeepSeek Coder | 70.59% | 29.41%*** | 80.93% | 50.97%*** | 12.9% | 52.94%
    |'
- en: '|  |  |  | (0.000) |  | (0.002) |  |  |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (0.000) |  | (0.002) |  |  |'
- en: '|  | DeepSeek Chat | 11.76% | 26.47% | 11.76% | 48.38%*** | 22.58% | 52.94%
    |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '|  | DeepSeek Chat | 11.76% | 26.47% | 11.76% | 48.38%*** | 22.58% | 52.94%
    |'
- en: '|  |  |  | (0.127) |  | (0.000) |  |  |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (0.127) |  | (0.000) |  |  |'
- en: '|  | Okanagan | 32.26% | 28.13% | 34.98% | 44.97% | 84.38% | 59.38% |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '|  | Okanagan | 32.26% | 28.13% | 34.98% | 44.97% | 84.38% | 59.38% |'
- en: '|  |  |  | (0.726) |  | (0.375) |  |  |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (0.726) |  | (0.375) |  |  |'
- en: '| 2ap | ChatGPT | 59.42% | 16.67%*** | 71.09% | 32.39%*** | 37.50% | 29.17%
    |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| 2ap | ChatGPT | 59.42% | 16.67%*** | 71.09% | 32.39%*** | 37.50% | 29.17%
    |'
- en: '|  |  | (0.000) |  | (0.000) |  |  |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '|  |  | (0.000) |  | (0.000) |  |  |'
- en: '| CodeLlama | 28.38% | 17.57% | 41.59% | 31.27% | 8.57% | 39.19% |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| CodeLlama | 28.38% | 17.57% | 41.59% | 31.27% | 8.57% | 39.19% |'
- en: '|  |  | (0.120) |  | (0.135) |  |  |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '|  |  | (0.120) |  | (0.135) |  |  |'
- en: '| CodeQwen1.5 Chat | 74.32% | 28.38%*** | 82.71% | 44.35%*** | 1.45% | 28.38%
    |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| CodeQwen1.5 Chat | 74.32% | 28.38%*** | 82.71% | 44.35%*** | 1.45% | 28.38%
    |'
- en: '|  |  | (0.000) |  | (0.000) |  |  |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '|  |  | (0.000) |  | (0.000) |  |  |'
- en: '| DeepSeek Coder | 71.23% | 36.49%*** | 81.36% | 48.17%*** | 56.52% | 70.27%
    |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| DeepSeek Coder | 71.23% | 36.49%*** | 81.36% | 48.17%*** | 56.52% | 70.27%
    |'
- en: '|  |  |  | (0.000) |  | (0.000) |  |  |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (0.000) |  | (0.000) |  |  |'
- en: '|  | DeepSeek Chat | 9.46% | 24.32%** | 10.9% | 35.99%*** | 52.17% | 56.76%
    |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '|  | DeepSeek Chat | 9.46% | 24.32%** | 10.9% | 35.99%*** | 52.17% | 56.76%
    |'
- en: '|  |  |  | (0.016) |  | (0.000) |  |  |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (0.016) |  | (0.000) |  |  |'
- en: '|  | Okanagan | 27.94% | 29.17% | 34.52% | 43.94% | 94.44% | 66.67% |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '|  | Okanagan | 27.94% | 29.17% | 34.52% | 43.94% | 94.44% | 66.67% |'
- en: '|  |  |  | (0.874) |  | (0.196) |  |  |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | (0.874) |  | (0.196) |  |  |'
- en: Table 5. Evaluation result for clarification categories 2ac,2cp,2ap on Pass@1,
    Test Pass Rate for original problems in HumanEval and modified problems in HumanEvalComm,
    communication rate, and Good Question Rate with different models. *p¡0.1; **p¡=0.05;
    ***p¡0.01
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5. 对于clarification类别2ac, 2cp, 2ap的评估结果，包含Pass@1、HumanEval中原始问题和HumanEvalComm中修改问题的测试通过率、通信率以及不同模型的好问题率。*p¡0.1;
    **p¡=0.05; ***p¡0.01
- en: 4.2\. Comparing Okanagan with Code LLMs in communication skills (RQ2)
  id: totrans-235
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2\. 比较Okanagan与Code LLMs在通信技能方面的表现（RQ2）
- en: Overview. RQ2 aims to compare LLM agent approach, Okanagan, with the current
    Code LLMs in communication skills. From Table [3](#S4.T3 "Table 3 ‣ 4.1\. Communication
    Competency of Code LLMs on HumanEvalComm (RQ1) ‣ 4\. Results and Analysis ‣ Benchmarking
    the Communication Competence of Code Generation for LLMs and LLM Agent"), while
    the communication rate for ChatGPT is below 20%, the communication rate of Okanagan
    with ChatGPT is over 70%, much higher than ChatGPT and all the other models. This
    shows that changing from LLM to LLM agent significantly increases the communication
    rate. For testing performance, Okanagan achieves better results than all models
    except CodeQwen1.5 Chat and DeepSeek Coder in both Pass@1 and Test Pass Rate.
    The trend is similar for both Pass@1 and Test Pass Rate as mentioned previously.
    This shows the effectiveness of Okanagan in obtaining the necessary information
    by asking clarifying questions.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 概述。RQ2旨在将LLM代理方法Okanagan与当前的Code LLMs在通信技能上进行比较。从表[3](#S4.T3 "表 3 ‣ 4.1\. Code
    LLMs在HumanEvalComm上的通信能力 (RQ1) ‣ 4\. 结果与分析 ‣ 基准测试LLMs和LLM代理的代码生成通信能力")中可以看出，尽管ChatGPT的通信率低于20%，但Okanagan与ChatGPT的通信率超过70%，远高于ChatGPT和其他所有模型。这表明，从LLM到LLM代理的转换显著提高了通信率。在测试性能方面，除了CodeQwen1.5
    Chat和DeepSeek Coder外，Okanagan在Pass@1和Test Pass Rate中都取得了比所有模型更好的结果。Pass@1和Test
    Pass Rate的趋势如前所述。显示了Okanagan通过提问澄清问题获取必要信息的有效性。
- en: However, one drawback is that Okanagan achieves a much lower Pass@1 and Test
    Pass Rate than ChatGPT. This is because the multi-round structure sometimes asks
    questions as an initial response even for original problems, but in original HumanEval,
    it is expected to directly return code in the initial responses, and evaluation
    is conducted on the code in the initial responses. This means for original problems
    that do not need asking questions, Okanagan sometimes still asks questions that
    appear to be unnecessary, since the original problem is known as complete and
    has no requirement issue. This is a valid limitation and future work is required
    (e.g., multi-agent debate (Du et al., [2023](#bib.bib15))) to address this limitation
    of asking unnecessary questions. If addressed, it indicates much stronger communication
    capability as LLM agent knows intelligently when to stop asking (Hassan et al.,
    [2024](#bib.bib25)). On the other hand, on HumanEvalComm, Okanagan shows that
    with LLM agent on top of base LLM (ChatGPT), we can get much better results in
    all metrics than ChatGPT. This shows the advantage in communication capability
    of LLM agent over LLM, as LLM agent can obtain needed info by asking questions
    to increase pass rates.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，一个缺点是Okanagan的Pass@1和测试通过率远低于ChatGPT。这是因为多轮结构有时即使对于原始问题也会提出问题作为初步回应，而在原始HumanEval中，期望在初步回应中直接返回代码，并对初步回应中的代码进行评估。这意味着对于不需要提出问题的原始问题，Okanagan有时仍会提出看似不必要的问题，因为原始问题已知是完整的且没有要求问题。这是一个有效的限制，需要未来的工作（例如，多代理辩论
    (Du et al., [2023](#bib.bib15))) 来解决这一提出不必要问题的限制。如果解决了这个问题，这表明更强的沟通能力，因为LLM代理会智能地知道何时停止提问
    (Hassan et al., [2024](#bib.bib25))。另一方面，在HumanEvalComm中，Okanagan展示了在基础LLM（ChatGPT）上附加LLM代理可以在所有指标上获得比ChatGPT更好的结果。这显示了LLM代理相对于LLM的沟通能力优势，因为LLM代理可以通过提问获取所需信息，从而提高通过率。
- en: Breakdown on Categories with One Clarification Type. In terms of the results
    breakdown on the clarification category of 1a, 1c, and 1p, Okanagan shows a much
    higher communication rate than any other Code LLMs for 1a, 1c, and 1p. Incompleteness
    again has the highest communication rate among the three categories, with a rate
    of more than 90%. A similar trend holds for Good Question Rate, but DeepSeek Coder
    and DeepSeek Chat get higher Good Question Rate than Okanagan in 1a and 1c. Consequently,
    Okanagan achieves the top three performance for both the highest Pass@1 and Test
    Pass Rate among all the models with statistical significance.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 针对一个澄清类型的类别分解。在1a、1c和1p澄清类别的结果分解中，Okanagan的沟通率远高于其他Code LLMs。在三个类别中，不完整性再次拥有最高的沟通率，达到了90%以上。良好问题率也显示出类似的趋势，但DeepSeek
    Coder和DeepSeek Chat在1a和1c的良好问题率高于Okanagan。因此，Okanagan在所有模型中，在最高Pass@1和测试通过率方面均名列前茅，并且具有统计显著性。
- en: Breakdown on Categories with Two Clarification Types. For the results breakdown
    on the clarification category of 2ac, 2ap, and 2cp, Okanagan has the highest communication
    rate among all the models, reaching a high 85% in 2cp and 94% in 2ap. A similar
    trend still holds in Good Question Rate. For Pass@1 and Test Pass Rate, Okanagan
    still ranks at the top 3 in most cases, but the statistical testing shows that
    most of the p-values are not small enough to show strong evidence of statistical
    significance, due to the relative smaller sample size of the categories with two
    types.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 针对两个澄清类型的类别分解。在2ac、2ap和2cp澄清类别的结果分解中，Okanagan在所有模型中具有最高的沟通率，2cp达到85%，2ap达到94%。良好问题率仍然呈现类似趋势。在Pass@1和测试通过率方面，Okanagan在大多数情况下仍位列前3，但统计测试表明，大多数p值并不够小，以显示强烈的统计显著性，这归因于两个类型类别的相对较小样本量。
- en: 'Answer
    to RQ2: Okanagan, as a LLM agent approach that uses LLM (specifically ChatGPT),
    effectively increases Communication Rate and Good Question Rate by an absolute
    58% and 38% respectively, and thus boosts Pass@1 and Test Pass Rate by an absolute
    8% and 7% respectively, when the problem descriptions are modified based on given
    clarification categories. This indicates headroom for achieving more effective
    communication capability using LLM agent.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 对RQ2的回答：Okanagan作为一种使用LLM（特别是ChatGPT）的LLM代理方法，能有效地使通信率和良好问题率分别绝对提高58%和38%，从而使Pass@1和测试通过率分别绝对提高8%和7%，当问题描述基于给定的澄清类别进行修改时。这表明，使用LLM代理可以实现更有效的通信能力。
- en: '| 1st Model Input | You are an expert software developer who writes high-quality
    code. With below information, please either generate Python3 code (Respond directly
    with code only with markdown), or ask clarifying questions: {python} def how_many_times(string:
    str, substring: str) -¿ int: ””” Find how many times a given substring can be
    found in the original string. ””” |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| 第一模型输入 | 你是一个专家级的软件开发人员，编写高质量的代码。根据以下信息，请生成 Python3 代码（仅以代码形式直接响应，使用 Markdown），或提出澄清问题：
    {python} def how_many_times(string: str, substring: str) -> int: """ 查找给定子字符串在原始字符串中出现的次数。
    """ |'
- en: '| --- | --- |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 1st Model Response | Sure, I can help you with that. However, I need more
    information to provide a precise solution. Could you please provide the following
    details? 1\. What should be the behavior if the substring is not found in the
    string? 2\. What should be the behavior if the substring is an empty string? 3\.
    Are there any specific constraints or requirements you would like to consider?
    With these details, I can provide a more accurate solution. |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| 第一模型响应 | 当然，我可以帮你。不过，我需要更多信息才能提供精确的解决方案。请提供以下详细信息： 1\. 如果子字符串在字符串中未找到，应该如何处理？
    2\. 如果子字符串为空字符串，应该如何处理？ 3\. 是否有任何特定的约束或要求需要考虑？ 有了这些详细信息，我可以提供更准确的解决方案。 |'
- en: '| LLM-based Evaluator Output | Answer to Questions: 1\. If the substring is
    not found in the string, the function should return 0. 2\. If the substring is
    an empty string, the function should return 0. 3\. There are no specific constraints
    or requirements other than counting the overlapping cases. |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| 基于LLM的评估器输出 | 对问题的回答： 1\. 如果子字符串在字符串中未找到，函数应返回 0。 2\. 如果子字符串为空字符串，函数应返回 0。
    3\. 除了计数重叠情况之外，没有特定的约束或要求。 |'
- en: '| 2nd Model Input | [1st Model Input][1st Model Response][Answer to Questions]…
    Given the above conversations, generate Python code directly (Markdown) to solve
    the coding problem: |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| 第二模型输入 | [第一模型输入][第一模型响应][对问题的回答]… 根据以上对话，直接生成 Python 代码 (Markdown) 以解决编码问题：
    |'
- en: '| 2nd Model Response | Sure, based on the provided information, here is a Python
    function that should solve the problem: {python} def how_many_times(string: str,
    substring: str) -¿ int: ””” Count the number of non-overlapping occurrences of
    a substring in a string. Parameters: string (str): The string to search within.
    substring (str): The substring to search for. Returns: int: The number of times
    the substring occurs in the string, or 0 if the substring is empty. ””” if not
    substring: return 0 count = 0 start = 0 while start ¡ len(string): pos = string.find(substring,
    start) if pos != -1: count += 1 # Ensure non-overlapping occurrences start = pos
    + len(substring) else: break return count |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| 第二模型响应 | 好的，根据提供的信息，这里是一个应解决该问题的 Python 函数：{python} def how_many_times(string:
    str, substring: str) -> int: """ 计算子字符串在字符串中不重叠出现的次数。 参数： string (str): 要搜索的字符串。
    substring (str): 要搜索的子字符串。 返回值： int: 子字符串在字符串中出现的次数，如果子字符串为空则返回 0。 """ if not
    substring: return 0 count = 0 start = 0 while start < len(string): pos = string.find(substring,
    start) if pos != -1: count += 1 # 确保不重叠的出现 start = pos + len(substring) else:
    break return count |'
- en: Table 6. Example case for DeepSeek Coder in problem 18 of HumanEvalComm. The
    clarification type of this problem is 1p (Incompleteness). The communication rate
    is 100%, the Good Question Rate is Good, and Test Pass Rate is 100% for this example.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 表6. HumanEvalComm第18题中DeepSeek Coder的示例案例。此问题的澄清类型为1p（不完整性）。该示例的沟通率为100%，良好问题率为良好，测试通过率为100%。
- en: '| 1st Model Input | You are an expert software developer who writes high quality
    code. With below information, please either generate Python3 code (Respond directly
    with code only with markdown), or ask clarifying questions: {python} def triangle_area(a,
    h): ”””Given length of a side and high return area for a triangle. ¿¿¿ triangle_area(5,
    3) 15 ””” |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| 第一模型输入 | 你是一位编写高质量代码的专家软件开发人员。根据以下信息，请生成 Python3 代码（仅直接回应代码并使用markdown），或者提出澄清问题：{python}
    def triangle_area(a, h): ”””给定边长和高度返回三角形的面积。 ¿¿¿ triangle_area(5, 3) 15 ””” |'
- en: '| --- | --- |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 1st Model Response | Here is the Python code for the function ‘triangle_area’:
    {python} def triangle_area(a, h): return (a * h) / 2 This function takes two arguments,
    ‘a’ and ‘h’, which represent the length of a side and the height of a triangle,
    respectively. It returns the area of the triangle, which is calculated by multiplying
    the length of the side by the height and then dividing by 2. Here is an example
    of how to use the function: {python} print(triangle_area(5, 3)) # Output: 15 This
    will print the area of a triangle with a side length of 5 and a height of 3, which
    is 15. |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| 第一模型回应 | 这是函数‘triangle_area’的Python代码：{python} def triangle_area(a, h): return
    (a * h) / 2 这个函数接受两个参数，‘a’和‘h’，分别表示三角形的边长和高度。它返回三角形的面积，计算方法是将边长乘以高度再除以2。以下是如何使用该函数的示例：{python}
    print(triangle_area(5, 3)) # 输出：15 这将打印一个边长为5，高度为3的三角形的面积，即15。 |'
- en: '| LLM-based Evaluator Output | Answer to Questions: N/A |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| 基于LLM的评估输出 | 回答问题：无 |'
- en: '| 2nd Model Input | [1st Model Input][1st Model Response][Answer to Questions]…
    Given the above conversations, generate Python code directly (Markdown) to solve
    the coding problem: |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| 第二模型输入 | [第一模型输入][1st Model Response][回答问题]… 根据以上对话，直接生成 Python 代码（Markdown）以解决编码问题：
    |'
- en: '| 2nd Model Response | Given the conversations, here is the Python code to
    solve the coding problem: {python} def triangle_area(a, h): return (a * h) / 2
    print(triangle_area(5, 3)) # Output: 15 This code defines a function ‘triangle_area’
    that takes two arguments, ‘a’ and ‘h’, which represent the length of a side and
    the height of a triangle, respectively. The function returns the area of the triangle,
    which is calculated by multiplying the length of the side by the height and then
    dividing by 2. The code also includes a call to the ‘triangle_area’ function with
    the arguments ‘5’ and ‘3’, which prints the area of the triangle, which is ‘15’.
    |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| 第二模型回应 | 根据对话，以下是解决编码问题的Python代码：{python} def triangle_area(a, h): return
    (a * h) / 2 print(triangle_area(5, 3)) # 输出：15 该代码定义了一个函数‘triangle_area’，它接受两个参数，‘a’和‘h’，分别表示三角形的边长和高度。该函数返回三角形的面积，计算方法是将边长乘以高度再除以2。代码还包括对‘triangle_area’函数的调用，参数为‘5’和‘3’，打印出三角形的面积，即‘15’。
    |'
- en: Table 7. Example case for CodeLlama in problem 45 of HumanEvalComm. The clarification
    type of this problem is 1c (Inconsistency). The communication rate is 100% given
    both code block and text are returned rather than code block only. The Good Question
    Rate is Bad, indicating no clarifying questions are detected.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 表7. HumanEvalComm第45题中CodeLlama的示例案例。此问题的澄清类型为1c（不一致性）。给定代码块和文本都返回而不是仅返回代码块，因此沟通率为100%。良好问题率为差，表明没有检测到澄清问题。
- en: 5\. Analysis and Discussion
  id: totrans-255
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 分析与讨论
- en: In this section, we provide some example cases to understand the results of
    Code LLMs and Okanagan. Then we also add discussions on analyzing the influence
    of 1) the extent of incomplete requirements and 2) the hyperparameters.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们提供了一些示例案例以理解代码LLMs和Okanagan的结果。然后，我们还添加了关于分析1) 不完整需求的范围和2) 超参数影响的讨论。
- en: 5.1\. Example Cases
  id: totrans-257
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1\. 示例案例
- en: Besides the numeric results, we also study two cases to better understand the
    evaluation steps. Table [6](#S4.T6 "Table 6 ‣ 4.2\. Comparing Okanagan with Code
    LLMs in communication skills (RQ2) ‣ 4\. Results and Analysis ‣ Benchmarking the
    Communication Competence of Code Generation for LLMs and LLM Agent") illustrates
    the result for a successful example problem (HumanEval/18) in HumanEvalComm. The
    clarification type of this problem is 1p (Incompleteness), so the requirement
    of ”Count overlapping cases.” is missing in the problem description. Given this
    1st model input, DeepSeek Coder was able to detect the incomplete requirement
    in the problem and ask clarifying questions rather than generating code directly.
    Therefore, the communication rate is 100% for this single case. With the 1st model
    input and response, the LLM-based evaluator outputs the Good Question Rate of
    Good for our evaluation and answers to the clarifying questions. This answer provides
    the missing requirement of ”counting overlapping cases” from the original problem.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 除了数值结果外，我们还研究了两个案例，以更好地理解评估步骤。表格[6](#S4.T6 "Table 6 ‣ 4.2\. Comparing Okanagan
    with Code LLMs in communication skills (RQ2) ‣ 4\. Results and Analysis ‣ Benchmarking
    the Communication Competence of Code Generation for LLMs and LLM Agent")展示了HumanEvalComm中一个成功的示例问题（HumanEval/18）的结果。这个问题的澄清类型是1p（不完整性），因此问题描述中缺少了“计算重叠情况”的要求。鉴于这个第一个模型输入，DeepSeek
    Coder能够检测到问题中的不完整要求，并提出澄清问题，而不是直接生成代码。因此，这单个案例的沟通率为100%。根据第一个模型输入和回复，LLM基于的评估者输出了良好问题率，并对澄清问题的回答给出了良好的评价。这个回答提供了原始问题中缺失的“计算重叠情况”要求。
- en: In the 2nd model input, the model is given the previous conversations, including
    the 1st model input, 1st model response (clarifying questions), and the answer
    from the LLM-based evaluator to the clarifying questions. With the requirement
    of “counting overlapping cases”, the model correctly solved the problem with 100%
    Test Pass Rate. Note that we can again let the model either ask questions or generate
    code, same as the instruction in the 1st model input, but we chose to perform
    only one question-answer round for simplicity of our evaluation.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二个模型输入中，模型获得了之前的对话内容，包括第一个模型输入、第一个模型回复（澄清问题），以及基于LLM的评估者对澄清问题的回答。在“计算重叠情况”的要求下，模型以100%的测试通过率正确解决了问题。请注意，我们可以再次让模型提出问题或生成代码，与第一个模型输入中的指令相同，但为了简化我们的评估，我们选择只进行一次问答回合。
- en: 'Another case is shown in Table [7](#S4.T7 "Table 7 ‣ 4.2\. Comparing Okanagan
    with Code LLMs in communication skills (RQ2) ‣ 4\. Results and Analysis ‣ Benchmarking
    the Communication Competence of Code Generation for LLMs and LLM Agent") for another
    example problem (HumanEval/45) in HumanEvalComm using CodeLlama. The clarification
    type of this problem is 1c (Inconsistency): in the test case, triangle_area (5,
    3) returns 15 instead of 7.5\. This causes Inconsistency between the test case
    and the problem description. Given the 1st model input, CodeLlama did not return
    a code block only according to the instruction, but a mix of code block and text
    explanation. Therefore, the communication rate is 100% for this case, but the
    LLM-based evaluator outputs the Good Question Rate of 1 (No questions). In this
    case, the Inconsistency issue was not captured and no clarifying questions were
    asked. For the evaluation metrics, the Good Question Rate of Bad successfully
    punished this case, but Test Pass Rate and communication rate failed to capture
    and punish the issue.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个案例在表格[7](#S4.T7 "Table 7 ‣ 4.2\. Comparing Okanagan with Code LLMs in communication
    skills (RQ2) ‣ 4\. Results and Analysis ‣ Benchmarking the Communication Competence
    of Code Generation for LLMs and LLM Agent")中展示，涉及HumanEval中的另一个示例问题（HumanEval/45），使用CodeLlama。这个问题的澄清类型是1c（不一致性）：在测试用例中，triangle_area(5,
    3)返回15而不是7.5。这导致测试用例与问题描述之间的不一致性。鉴于第一个模型输入，CodeLlama并没有仅根据指令返回一个代码块，而是返回了代码块和文本解释的混合。因此，这种情况下的沟通率为100%，但LLM基于的评估者输出的良好问题率为1（没有问题）。在这种情况下，不一致性问题没有被捕捉到，也没有提出澄清问题。对于评估指标而言，坏问题的良好问题率成功惩罚了这个案例，但测试通过率和沟通率未能捕捉和惩罚这个问题。
- en: '| % Removed in Description | Example Problem Description |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| % Removed in Description | 示例问题描述 |'
- en: '| --- | --- |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 0% | def encode_cyclic(s: str): returns encoded string by cycling groups
    of three characters. # split string to groups. Each of length 3\. groups = [s[(3
    * i):min((3 * i + 3), len(s))] for i in range((len(s) + 2) // 3)] # cycle elements
    in each group. Unless group has fewer elements than 3\. groups = [(group[1:] +
    group[0]) if len(group) == 3 else group for group in groups] return ””.join(groups)
    def decode_cyclic(s: str): takes as input string encoded with encode_cyclic function.
    Returns decoded string. |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| 0% | def encode_cyclic(s: str): 返回通过对三字符组进行循环的编码字符串。# 将字符串拆分为组。每组长度为3。groups
    = [s[(3 * i):min((3 * i + 3), len(s))] for i in range((len(s) + 2) // 3)] # 循环每组中的元素。如果组的元素少于3个。groups
    = [(group[1:] + group[0]) if len(group) == 3 else group for group in groups] return
    ””.join(groups) def decode_cyclic(s: str): 作为输入的字符串由encode_cyclic函数编码。返回解码后的字符串。
    |'
- en: '| 30% | def encode_cyclic(s: str): returns encoded string by cycling groups
    of three characters. split string to in each group. Unless group has fewer elements
    than 3\. groups = [(group[1:] + group[0]) if len(group) == 3 else group for group
    in groups] return ””.join(groups) def decode_cyclic(s: str): takes as input string
    encoded with encode_cyclic function. Returns decoded string. |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| 30% | def encode_cyclic(s: str): 返回通过对三字符组进行循环的编码字符串。将字符串拆分为每组。如果组的元素少于3个。groups
    = [(group[1:] + group[0]) if len(group) == 3 else group for group in groups] return
    ””.join(groups) def decode_cyclic(s: str): 作为输入的字符串由encode_cyclic函数编码。返回解码后的字符串。
    |'
- en: '| 50% | def encode _cyclic(s: str): returns encoded string by cycling groups
    of three characters. split string to groups. Each of length 3\. groups = [s[(3
    * i):min((3 * i + takes as input string encoded with encode_cyclic function. Returns
    decoded string. |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| 50% | def encode_cyclic(s: str): 返回通过对三字符组进行循环的编码字符串。将字符串拆分为组。每组长度为3。groups
    = [s[(3 * i):min((3 * i + 3), len(s))] for i in range((len(s) + 2) // 3)] 作为输入的字符串由encode_cyclic函数编码。返回解码后的字符串。
    |'
- en: '| 90% | def encode_cyclic(s: str): encode_cyclic function. Returns decoded
    string. |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| 90% | def encode_cyclic(s: str): encode_cyclic函数。返回解码后的字符串。 |'
- en: Table 8. Example of randomly removing parts of the problem description from
    problem number 38 of HumanEval.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 表8. 从HumanEval第38号问题中随机移除问题描述部分的示例。
- en: 5.2\. Investigating Different Extent of Incomplete Modification (1p)
  id: totrans-268
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2\. 研究不完整修改（1p）的不同程度
- en: To dig deeper into the results of incomplete modification (1p), we did further
    investigations to understand the correlation between the ratio of removed content
    in the problem description for 1p and the corresponding results. We investigated
    the results by removing a random text block in the problem descriptions. Specifically,
    for each problem description in words, we randomly remove a list of consecutive
    words where the size of the list is $X$ becomes larger, such as 90%, the problem
    description becomes almost impossible to conduct the code generation task with
    high accuracy.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 为了深入探讨不完整修改（1p）的结果，我们进行了进一步调查，以了解1p问题描述中移除内容的比例与对应结果之间的相关性。我们通过在问题描述中随机移除一个文本块来研究结果。具体来说，对于每个包含单词的问题描述，我们随机移除一系列连续的单词，当列表的大小为$X$变大时，例如90%，问题描述几乎不可能以高准确率进行代码生成任务。
- en: To mitigate the risk of randomness in this investigation, for each problem,
    we ran the experiment 5 times, and reported the metrics used in (Ouyang et al.,
    [2023](#bib.bib47)), including Mean, Variance, Max Diff, and Ratio of Worst. We
    calculated the mean and variance of the 5 Test Pass Rates and communication rates
    for each problem, and reported the average among all problems, as Mean and Variance.
    The Max Diff is the maximum value of the maximum diff among all problems. “Ratio
    of Worst (Cases)” is the ratio of problems with the maximum diff of test pass
    rate being 1\. Please refer to (Ouyang et al., [2023](#bib.bib47)) for complete
    descriptions of these metrics. We report the Test Pass Rates and communication
    rates in Table [9](#S5.T9 "Table 9 ‣ 5.3\. Investigating Different Hyperparameter
    ‣ 5\. Analysis and Discussion ‣ Benchmarking the Communication Competence of Code
    Generation for LLMs and LLM Agent") based on the percentage of removed descriptions
    (0%, 30%, 50%, and 90%). We used ChatGPT 3.5 as the model in the investigation.
    We can see that, in terms of Test Pass Rates, as the percentage of removed information
    increases, there is a noticeable decrease in the mean Test Pass Rate, indicating
    that incomplete problem descriptions negatively affect the ability to pass tests.
    This trend is further supported by the variance and maximum difference metrics,
    which show increasing variability and differences in Test Pass Rates as information
    is removed. The ratio of the worst case also suggests that a higher percentage
    of removed information leads to a lower Test Pass Rate.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减少这项调查中的随机性风险，我们对每个问题进行了5次实验，并报告了在(Ouyang et al., [2023](#bib.bib47))中使用的指标，包括均值、方差、最大差异和最差比率。我们计算了每个问题的5次测试通过率和通信率的均值和方差，并报告了所有问题中的平均值，即均值和方差。最大差异是所有问题中最大差异的最大值。最差比率（案例）是测试通过率最大差异为1的情况的比例。有关这些指标的完整描述，请参见(Ouyang
    et al., [2023](#bib.bib47))。我们根据移除描述的百分比（0%、30%、50%和90%）在表[9](#S5.T9 "Table 9
    ‣ 5.3\. Investigating Different Hyperparameter ‣ 5\. Analysis and Discussion ‣
    Benchmarking the Communication Competence of Code Generation for LLMs and LLM
    Agent")中报告了测试通过率和通信率。我们在调查中使用了ChatGPT 3.5作为模型。可以看出，在测试通过率方面，随着移除信息百分比的增加，均值测试通过率显著下降，这表明不完整的问题描述对测试通过能力产生了负面影响。这一趋势得到了方差和最大差异指标的进一步支持，这些指标显示了随着信息移除，测试通过率的变异性和差异性增加。最差案例的比例也表明，更高的移除信息百分比导致较低的测试通过率。
- en: For communication rates, incomplete problem descriptions lead to an increase
    in the mean communication rate as the percentage of removed information increases.
    This is expected because when there is more missing information, LLM tends to
    ask more questions rather than directly generating code. The variance and maximum
    difference metrics also reflect higher variability and differences in communication
    rates with incomplete problem descriptions. The ratio of the worst case indicates
    that a higher percentage of removed information results in a more significant
    increase in communication rates. Figure [5](#S5.F5 "Figure 5 ‣ 5.2\. Investigating
    Different Extent of Incomplete Modification (1p) ‣ 5\. Analysis and Discussion
    ‣ Benchmarking the Communication Competence of Code Generation for LLMs and LLM
    Agent") shows a visual comparison of these two metrics using numbers from Table [9](#S5.T9
    "Table 9 ‣ 5.3\. Investigating Different Hyperparameter ‣ 5\. Analysis and Discussion
    ‣ Benchmarking the Communication Competence of Code Generation for LLMs and LLM
    Agent") when different X% of content is removed in the problem description. This
    shows visually that LLM tends to ask more questions as more content in the description
    is removed, but this starts to happen only after half of the descriptions are
    removed. When 90% of the description is removed, LLM asks questions for only 54%
    of problem descriptions. To summarize, 95% of responses from Code LLMs still generate
    code even when 50% of problem descriptions are randomly removed. When the removed
    percentage of description increases to 90%, 46% of responses from Code LLMs still
    generate code. This shows a rather weak ability of Code LLMs to ask clarifying
    questions when information is randomly removed and therefore indicates plenty
    of research opportunities in pushing the curves of LLM or LLM agent toward the
    human software engineers.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 对于通信率来说，不完整的问题描述会随着移除信息比例的增加而导致均值通信率的提高。这是预期的，因为当缺失的信息更多时，LLM 更倾向于提问，而不是直接生成代码。方差和最大差异指标也反映了在不完整问题描述下通信率的更高变异性和差异。最坏情况的比例表明，移除信息的比例越高，通信率的显著增加越大。图 [5](#S5.F5
    "Figure 5 ‣ 5.2\. Investigating Different Extent of Incomplete Modification (1p)
    ‣ 5\. Analysis and Discussion ‣ Benchmarking the Communication Competence of Code
    Generation for LLMs and LLM Agent") 使用了来自表 [9](#S5.T9 "Table 9 ‣ 5.3\. Investigating
    Different Hyperparameter ‣ 5\. Analysis and Discussion ‣ Benchmarking the Communication
    Competence of Code Generation for LLMs and LLM Agent") 的数据，展示了在问题描述中移除不同 X% 内容时这两个指标的可视化比较。这直观地显示了，随着描述内容的移除，LLM
    趋向于提出更多问题，但这种情况只有在移除一半的描述后才会发生。当 90% 的描述被移除时，LLM 仅对 54% 的问题描述提出问题。总结来说，即使在随机移除
    50% 的问题描述时，95% 的 Code LLM 响应仍然会生成代码。当描述移除比例增加到 90% 时，46% 的 Code LLM 响应仍然生成代码。这表明
    Code LLM 在信息随机移除时提出澄清问题的能力相对较弱，因此在推动 LLM 或 LLM 代理向人类软件工程师的能力曲线发展方面还有许多研究机会。
- en: '![Refer to caption](img/c927ef0730a7dde89ad2d63dcff84347.png)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![参见图例](img/c927ef0730a7dde89ad2d63dcff84347.png)'
- en: Figure 5. The chart of communication rate and Test Pass Rate when different
    X% of content is removed in the problem description.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5. 当问题描述中移除不同 X% 内容时，通信率和测试通过率的图表。
- en: 5.3\. Investigating Different Hyperparameter
  id: totrans-274
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3\. 研究不同超参数
- en: To evaluate the impact of the hyperparameter in the experiments, we also investigated
    using different temperatures as the hyperparameter of ChatGPT. Temperature is
    a hyperparameter that controls the randomness of ChatGPT-generated text. The default
    temperature of ChatGPT is 1.0 and we tested the result of using temperature as
    0, 1.0, 2.0\. Same as in the previous incomplete modification investigation, we
    ran the experiment 5 times and checked the metrics including mean and variance.
    We ran with the percentage of removed information being 50%.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估超参数在实验中的影响，我们还调查了使用不同温度作为 ChatGPT 的超参数。温度是一个控制 ChatGPT 生成文本随机性的超参数。ChatGPT
    的默认温度是 1.0，我们测试了温度为 0、1.0、2.0 的结果。与之前的不完全修改研究相同，我们进行了 5 次实验，并检查了包括均值和方差在内的指标。我们设置了
    50% 的信息被移除的比例。
- en: Table [10](#S5.T10 "Table 10 ‣ 5.3\. Investigating Different Hyperparameter
    ‣ 5\. Analysis and Discussion ‣ Benchmarking the Communication Competence of Code
    Generation for LLMs and LLM Agent") presents results on the impact of the temperature
    hyperparameter in ChatGPT in HumanEvalComm. We found that the mean Test Pass Rate
    dropped from 49.6% (variance=0.088, max diff=0.523, ratio of worst=0.390) to 40.7%
    (variance=max diff=ratio of worst=0), and the communication rate changed from
    1.8% (variance=0.011,max diff=0.067, ratio of worst=0.067) to 3.7% (variance=max
    diff=ratio of worst=0) when the temperature changed from 1 to 0\. We also tested
    2.0 as temperature, but found that most of these requests timed out due to longer
    processing time on the OpenAI server end due to high temperature. We can see that
    the variance, max diff, and ratio of worst become 0 when the temperature is 0\.
    This means lower temperature does indicate much more deterministic and focused
    results. Interestingly, as the temperature dropped from 1 to 0, the mean Test
    Pass Rate dropped, but the communication rate increased. This could be because
    lower temperature leads to less creative and diverse output to “guess” the code,
    therefore somehow forcing the model to ask questions to seek additional information.
    Given the temperature of 1.0 is the default setting, and the results do not show
    a significant impact of varying temperature, in the evaluation, we use the temperature
    of 1.0 for both ChatGPT and Okanagan.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 [10](#S5.T10 "表格 10 ‣ 5.3\. 探索不同超参数 ‣ 5\. 分析与讨论 ‣ 基准测试LLM和LLM代理的代码生成能力")
    展示了温度超参数在 ChatGPT 中对 HumanEvalComm 的影响。我们发现，当温度从 1 降到 0 时，平均测试通过率从 49.6%（方差=0.088，最大差异=0.523，最差比率=0.390）降到
    40.7%（方差=最大差异=最差比率=0），通信率从 1.8%（方差=0.011，最大差异=0.067，最差比率=0.067）变为 3.7%（方差=最大差异=最差比率=0）。我们还测试了温度为
    2.0，但发现由于温度过高，OpenAI 服务器端处理时间较长，大部分请求超时。我们可以看到，当温度为 0 时，方差、最大差异和最差比率都变为 0。这意味着较低的温度确实会导致更加确定性和集中性的结果。有趣的是，当温度从
    1 降到 0 时，平均测试通过率下降了，但通信率上升了。这可能是因为较低的温度导致输出更少的创意和多样性来“猜测”代码，因此在某种程度上迫使模型提问以寻求额外信息。鉴于
    1.0 是默认设置，且结果未显示温度变化的显著影响，因此在评估中，我们对 ChatGPT 和 Okanagan 都使用了温度 1.0。
- en: '| % Removed | Metric | Mean | Variance | Max Diff | Ratio of Worst |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| % Removed | 指标 | 平均值 | 方差 | 最大差异 | 最差比率 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| 0% | Test Pass Rate | 66.5% | 0.122 | 0.690 | 0.561 |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| 0% | 测试通过率 | 66.5% | 0.122 | 0.690 | 0.561 |'
- en: '| 0% | Communication Rate | 3.3% | 0.019 | 0.110 | 0.110 |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| 0% | 通信率 | 3.3% | 0.019 | 0.110 | 0.110 |'
- en: '| 30% | Test Pass Rate | 49.6% | 0.088 | 0.532 | 0.390 |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| 30% | 测试通过率 | 49.6% | 0.088 | 0.532 | 0.390 |'
- en: '| 30% | Communication Rate | 1.8% | 0.011 | 0.067 | 0.067 |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| 30% | 通信率 | 1.8% | 0.011 | 0.067 | 0.067 |'
- en: '| 50% | Test Pass Rate | 41.1% | 0.085 | 0.523 | 0.317 |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| 50% | 测试通过率 | 41.1% | 0.085 | 0.523 | 0.317 |'
- en: '| 50% | Communication Rate | 5.5% | 0.028 | 0.165 | 0.165 |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| 50% | 通信率 | 5.5% | 0.028 | 0.165 | 0.165 |'
- en: '| 90% | Test Pass Rate | 44.8% | 0.124 | 0.684 | 0.543 |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| 90% | 测试通过率 | 44.8% | 0.124 | 0.684 | 0.543 |'
- en: '| 90% | Communication Rate | 54.1% | 0.120 | 0.604 | 0.604 |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| 90% | 通信率 | 54.1% | 0.120 | 0.604 | 0.604 |'
- en: Table 9. Results on the average values of Test Pass Rates and communication
    rates with different percentages of content removed in the problem descriptions.
    Due to the randomness involved, the experiment was run 5 times and metrics used
    in (Ouyang et al., [2023](#bib.bib47)) were reported.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 9. 在问题描述中不同内容百分比移除下，测试通过率和通信率的平均值结果。由于涉及随机性，实验运行了 5 次，并报告了 (Ouyang et al.,
    [2023](#bib.bib47)) 中使用的指标。
- en: '| % Removed | Temperature | Category | Mean | Variance | Max Diff | Ratio of
    Worst |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| % Removed | 温度 | 类别 | 平均值 | 方差 | 最大差异 | 最差比率 |'
- en: '| 50% | 1 | Test Pass Rate | 0.496 | 0.088 | 0.532 | 0.390 |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| 50% | 1 | 测试通过率 | 0.496 | 0.088 | 0.532 | 0.390 |'
- en: '| 50% | 1 | Communication Rate | 0.018 | 0.011 | 0.067 | 0.067 |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| 50% | 1 | 通信率 | 0.018 | 0.011 | 0.067 | 0.067 |'
- en: '| 50% | 0 | Test Pass Rate | 0.407 | 0 | 0 | 0 |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| 50% | 0 | 测试通过率 | 0.407 | 0 | 0 | 0 |'
- en: '| 50% | 0 | Communication Rate | 0.037 | 0 | 0 | 0 |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '| 50% | 0 | 通信率 | 0.037 | 0 | 0 | 0 |'
- en: Table 10. Results on the average values of test pass rates and communication
    rates with different temperatures as the hyperparameter of LLM in HumanEvalComm.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 10. 测试通过率和通信率在不同温度作为 LLM 超参数下的平均值结果，HumanEvalComm。
- en: 5.4\. Implications and Future Work
  id: totrans-294
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4\. 含义与未来工作
- en: 'Based on the results and analysis, we summarized the following implications
    as suggestions for future work:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 基于结果和分析，我们总结了以下含义，并提出了未来工作的建议：
- en: •
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Go beyond generative model. In the evaluation, we found that for Incompleteness
    category, some Code LLMs have extremely low results, potentially due to their
    generative nature that prefers to generate and complete code based on a statistical
    model, even when the description is obviously incomplete. Future work should go
    beyond the generative nature of LLMs to “AI agent” or “AI assistants” (Hassan
    et al., [2024](#bib.bib25)) to further enhance communication capabilities.
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 超越生成模型。在评估中，我们发现对于不完整性类别，一些代码LLMs的结果极低，这可能是由于它们的生成性质，倾向于根据统计模型生成和完成代码，即使描述显然不完整。未来的工作应超越LLMs的生成性质，转向“AI代理”或“AI助手”（Hassan等，
    [2024](#bib.bib25)），以进一步提升沟通能力。
- en: •
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Stronger reasoning capability. In the evaluation, Inconsistency category has
    the lowest communication rate among the three types. This indicates that more
    future work is needed to develop models with stronger reasoning capability to
    address the low performance in Inconsistency category.
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 更强的推理能力。在评估中，不一致性类别在三种类型中具有最低的沟通率。这表明，未来需要更多工作来开发具有更强推理能力的模型，以解决不一致性类别中的低性能问题。
- en: •
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Better ability to know when to stop asking for LLM agent. Although the LLM agent
    approach, Okanagan, showed promising initial results in improving the metrics
    in the evaluation, one limitation of Okanagan is that it reduced the pass rates
    in the original HumanEval benchmark, due to asking unnecessary questions. Therefore,
    one future work in LLM agent is to address this shortcoming. This will potentially
    lead to much stronger communication capability as the model will know intelligently
    when to stop asking.
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 更好地判断何时停止请求LLM代理。尽管LLM代理方法Okanagan在提高评估指标方面显示出了有希望的初步结果，但Okanagan的一个限制是，它因提出不必要的问题而降低了原始HumanEval基准的通过率。因此，LLM代理的未来工作之一是解决这一缺陷。这将可能导致更强的沟通能力，因为模型将能够智能地知道何时停止提问。
- en: •
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Stronger ability to obtain information especially for increased clarification
    difficulty. In the experiments of two clarification types and investigation of
    different incomplete modifications (1p), we noticed reduced Pass@1 and Test Pass
    Rates as the difficulty increases in the description, indicating a bottleneck
    in failing to fetch needed information for solving the coding tasks. Future work
    is needed in both model and evaluation setup to increase the model’s ability to
    get necessary information in these challenging situations.
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 更强的信息获取能力，特别是在增加澄清难度的情况下。在两种澄清类型的实验和对不同不完整修改（1p）的调查中，我们注意到随着描述难度的增加，Pass@1和测试通过率有所下降，这表明在解决编码任务时未能获取所需信息的瓶颈。未来的工作需要在模型和评估设置两方面进行，以提高模型在这些挑战性情况下获取必要信息的能力。
- en: 6\. Threats to Validity
  id: totrans-304
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.  可靠性威胁
- en: Construct validity. This threat relates to the potential incorrectness in manual
    modifications of problems in HumanEvalComm. To mitigate this threat, we have manually
    checked and verified all of the problems more than three times, and each time
    they discussed the problems they didn’t reach a consensus. Although we have tried
    our best efforts, there still may be some corner cases where the modified problems
    do not match the definition of Ambiguity and Inconsistency.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 结构效度。这一威胁与HumanEvalComm中手动修改问题可能存在的错误性有关。为减少这一威胁，我们已手动检查和验证所有问题三次以上，每次讨论这些问题时，他们未能达成共识。尽管我们尽了最大努力，但仍可能存在一些边角情况，其中修改后的问题与模糊性和不一致性的定义不符。
- en: Internal validity. This threat relates to the internal parameters such as the
    parameters in open-source Code LLMs and ChatGPT that could potentially affect
    the results. To mitigate this threat, we use most of the default parameters when
    running open-source Code LLMs and ChatGPT. For open-source models, we set max_new_tokens
    as 512 to save computing resources and used default values for other parameters.
    For ChatGPT, we used temperature as 1.0 and $n$ as 1 in the OpenAI API. Another
    threat relates to the effectiveness of the LLM-based evaluator used in the evaluation.
    As mentioned previously, to mitigate this issue, we have optimized the prompt
    for the LLM-based evaluator several times and checked the results manually. Besides,
    the LLM-based evaluator is used equally for all models in the evaluation, so this
    threat does not affect the relative ranking of the results for all models.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 内部有效性。这一威胁涉及内部参数，如开源Code LLMs和ChatGPT中的参数，可能会影响结果。为了缓解这一威胁，我们在运行开源Code LLMs和ChatGPT时使用了大多数默认参数。对于开源模型，我们将max_new_tokens设置为512，以节省计算资源，并使用了其他参数的默认值。对于ChatGPT，我们在OpenAI
    API中将temperature设置为1.0，将$n$设置为1。另一个威胁与评估中使用的基于LLM的评估器的有效性相关。如前所述，为了缓解这个问题，我们对基于LLM的评估器的提示进行了多次优化，并手动检查了结果。此外，基于LLM的评估器在评估中对所有模型使用相同，因此这一威胁不会影响所有模型的结果相对排名。
- en: External validity. This relates to the generality of the communication capability
    of the models on other benchmarks. To mitigate this issue, we extensively report
    and analyze the results with statistical testing that reports p-value. To reduce
    the risk introduced by randomness in our investigation, we also added metrics
    such as mean, variance, max diff in the results. Thus, these results can be potentially
    adapted for other datasets. However, since we have not tested this, we cannot
    make a sound claim regarding the communication capability of the models on another
    dataset. Another threat is related to the implementation of evaluated models.
    We directly call OpenAI API to get ChatGPT results. We implemented Okanagan in
    Python that calls OpenAI API. For CodeLlama and other open-source models, we downloaded
    the model from HuggingFace and perform model inference on UBC ARC Sockeye. From
    the evaluation results, we believe that our implementation reflects the original
    methods. To ensure the reproducibility of the evaluation results, we report the
    result of the case study extensively and release our complete code and dataset.
    This can allow other researchers to reproduce and extend our experiments in the
    case study.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 外部有效性。这涉及到模型在其他基准上的通信能力的普遍性。为缓解这一问题，我们广泛报告和分析了结果，并进行了统计测试，报告p值。为了减少调查中随机性带来的风险，我们还添加了诸如均值、方差、最大差异等指标。这些结果有可能适用于其他数据集。然而，由于我们尚未进行测试，因此无法对模型在其他数据集上的通信能力做出可靠的声明。另一个威胁与被评估模型的实现相关。我们直接调用OpenAI
    API获取ChatGPT结果。我们在Python中实现了Okanagan，调用OpenAI API。对于CodeLlama和其他开源模型，我们从HuggingFace下载了模型，并在UBC
    ARC Sockeye上进行模型推断。从评估结果来看，我们相信我们的实现反映了原始方法。为了确保评估结果的可重复性，我们详细报告了案例研究的结果，并发布了完整的代码和数据集。这可以使其他研究人员能够重复和扩展我们在案例研究中的实验。
- en: 7\. Related Work
  id: totrans-308
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 相关工作
- en: Code Generation with Large Language Models. In recent years, the field of code
    generation has seen a significant shift with the large language models. For example,
    Codex (Chen et al., [2021](#bib.bib13)), fine-tuned on GPT-3 (Brown et al., [2020](#bib.bib11))
    on a large corpus of source code data, is capable of generating code for 47/164
    problems in the HumanEval dataset in a single run, a benchmark for code generation
    task. Codex became the core model for the Copilot (Ziegler et al., [2022](#bib.bib81)),
    an AI-powered coding assistant developed by GitHub. After Codex, a couple of models
    similar to Codex but with smaller size were then developed, including GPT-J (Wang
    and Komatsuzaki, [2021](#bib.bib63)), CodeParrot (Face, [2023](#bib.bib17)), PolyCoder (Xu
    et al., [2022](#bib.bib72)). AlphaCode (Li et al., [2022](#bib.bib36)), with size
    comparable to Codex, was trained on Github data and fine-tuned on competition-level
    programming problems. It exceeded half of the competitors in coding competitions
    of CodeForces, a well-known online competitive programming platform. CodeGen (Nijkamp
    et al., [2022](#bib.bib45)) was trained on both natural language and programming
    language data for code generations with multi-turn prompts. Recently, newer models
    such as CodeLlama (Roziere et al., [2023](#bib.bib52)), DeepSeek Coder (Guo et al.,
    [2024](#bib.bib24)) and CodeQwen1.5 Chat (Bai et al., [2023](#bib.bib6)) continued
    to achieve higher performance in benchmark such as HumanEval. However, the level
    of communication skills of these models is not emphasized and evaluated. These
    models are evaluated by generating code in one or multiple attempts from one-off
    problem descriptions, without further information from conversations. Therefore,
    when the input problem description is error-prone or incomplete, the model still
    has to generate the code without the chance to clarify critical questions. Our
    work serves as an exploration to address this usability problem.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型的代码生成。近年来，代码生成领域随着大型语言模型的出现发生了显著变化。例如，Codex（Chen et al., [2021](#bib.bib13)），在大量源代码数据上微调的GPT-3（Brown
    et al., [2020](#bib.bib11)），能够在一次运行中为HumanEval数据集中47/164个问题生成代码，这是代码生成任务的一个基准。Codex成为了Copilot（Ziegler
    et al., [2022](#bib.bib81)）的核心模型，Copilot是由GitHub开发的AI驱动的编码助手。Codex之后，开发了一些类似于Codex但体积较小的模型，包括GPT-J（Wang
    and Komatsuzaki, [2021](#bib.bib63)）、CodeParrot（Face, [2023](#bib.bib17)）、PolyCoder（Xu
    et al., [2022](#bib.bib72)）。AlphaCode（Li et al., [2022](#bib.bib36)），其规模可与Codex媲美，经过Github数据训练并在竞赛级编程问题上进行微调。它在著名的在线竞赛编程平台CodeForces的编码竞赛中超过了一半的竞争者。CodeGen（Nijkamp
    et al., [2022](#bib.bib45)）在自然语言和编程语言数据上进行训练，用于多轮提示的代码生成。最近，像CodeLlama（Roziere
    et al., [2023](#bib.bib52)）、DeepSeek Coder（Guo et al., [2024](#bib.bib24)）和CodeQwen1.5
    Chat（Bai et al., [2023](#bib.bib6)）等较新的模型继续在HumanEval等基准测试中取得更高的性能。然而，这些模型的沟通能力水平并没有得到强调和评估。这些模型通过从一次性问题描述中生成代码来进行评估，无需进一步的对话信息。因此，当输入的问题描述存在错误或不完整时，模型仍然必须生成代码，而没有机会澄清关键问题。我们的工作旨在探索解决这一可用性问题。
- en: Self-Correct LLMs and LLM Agent in AI. Recently, a promising approach to improve
    the output efficiency of large language models is self-correction (Pan et al.,
    [2023](#bib.bib48)). In the self-correction approach, the LLM uses the feedback
    guided or prompted by itself to refine its results. One popular category of work
    uses human feedback to refine their results directly (Kreutzer et al., [2018](#bib.bib35);
    Glaese et al., [2022](#bib.bib23); Ouyang et al., [2022](#bib.bib46); Scheurer
    et al., [2023](#bib.bib54); Fernandes et al., [2023](#bib.bib21)). Other studies
    employed different strategies to self-correct LLMs using automated feedback such
    as self-training (Huang et al., [2022](#bib.bib28); Bai et al., [2022](#bib.bib7)),
    generate-then-rank (He et al., [2023](#bib.bib26); Weng et al., [2023](#bib.bib67)),
    feedback-guided decoding (Yang et al., [2022](#bib.bib74); Xie et al., [2023](#bib.bib71)),
    iterative post-hoc revision (Zhang et al., [2023b](#bib.bib79); Jiang et al.,
    [2023](#bib.bib30)), etc. Furthermore, the advances in LLM have also brought much
    progress in LLM-based agents, with different modules including Planning, Memory,
    Profile, and Action (Xi et al., [2023](#bib.bib70); Wang et al., [2023b](#bib.bib65)),
    and various agent categories, such as Tool Agent, Simulation Agent, Web Agent,
    Game Agent, etc. Our work also includes the evaluation of the LLM agent approach,
    Okanagan, which has an additional round with reflection as the thinking pattern.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 自我纠正的大型语言模型（LLM）及LLM代理。在提高大型语言模型输出效率的最新有前景的方法是自我纠正（Pan et al., [2023](#bib.bib48)）。在自我纠正方法中，LLM使用自身引导或提示的反馈来改进其结果。一类流行的工作直接利用人类反馈来完善结果（Kreutzer
    et al., [2018](#bib.bib35); Glaese et al., [2022](#bib.bib23); Ouyang et al.,
    [2022](#bib.bib46); Scheurer et al., [2023](#bib.bib54); Fernandes et al., [2023](#bib.bib21)）。其他研究采用了不同的策略，通过自动化反馈如自我训练（Huang
    et al., [2022](#bib.bib28); Bai et al., [2022](#bib.bib7)）、生成-排序（He et al., [2023](#bib.bib26);
    Weng et al., [2023](#bib.bib67)）、反馈引导解码（Yang et al., [2022](#bib.bib74); Xie et
    al., [2023](#bib.bib71)）、迭代后期修正（Zhang et al., [2023b](#bib.bib79); Jiang et al.,
    [2023](#bib.bib30)）等来进行自我纠正。此外，LLM的进展也推动了基于LLM的代理的发展，包括规划、记忆、个人资料和行动模块（Xi et al.,
    [2023](#bib.bib70); Wang et al., [2023b](#bib.bib65)），以及各种代理类别，如工具代理、模拟代理、网络代理、游戏代理等。我们的工作还包括对LLM代理方法Okanagan的评估，该方法具有额外的反思环节作为思维模式。
- en: LLM Agent for Code Generation. Although still at an early stage, recently, there
    has been a rising stream of research efforts to employ LLM agents for the task
    of code generation. RepairAgent (Bouzenia et al., [2024](#bib.bib10)) is the first
    to use an LLM-based agent for program repair and code generation in the field
    of software engineering. This work follows the previous work in augmenting LLMs
    with API tools. Recently, CoRE (Xu et al., [2024](#bib.bib73)) has been proposed
    as a system that enables agent programming by using LLM as interpreters to process
    and execute natural language instructions. Following a similar spirit of LLM agent,
    TICODER (Fakhoury et al., [2024](#bib.bib18)) is proposed as a test-driven interactive
    workflow for more accurate code generation. Similarly, De-Hallucinator (Eghbali
    and Pradel, [2024](#bib.bib16)) is proposed as a code completion method that combines
    retrieval-based code generation and iterative querying of the model. Different
    from the above works, the proposed Okanagan in our work focuses on enhancing the
    communication capabilities of LLM for code generation tasks. To the best of our
    knowledge, we are the first to study and compare the communication capabilities
    of LLM agent and Code LLMs in code generation tasks.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 用于代码生成的LLM代理。尽管仍处于早期阶段，但最近出现了一系列研究工作，致力于利用LLM代理进行代码生成任务。RepairAgent（Bouzenia
    et al., [2024](#bib.bib10)）是第一个在软件工程领域使用基于LLM的代理进行程序修复和代码生成的工作。这项工作沿袭了通过API工具增强LLM的前期研究。最近，CoRE（Xu
    et al., [2024](#bib.bib73)）被提议为一个系统，利用LLM作为解释器来处理和执行自然语言指令。类似的LLM代理，TICODER（Fakhoury
    et al., [2024](#bib.bib18)）被提出作为一种测试驱动的互动工作流程，以实现更准确的代码生成。类似地，De-Hallucinator（Eghbali
    and Pradel, [2024](#bib.bib16)）被提出为一种代码补全方法，结合了基于检索的代码生成和模型的迭代查询。与上述工作不同，我们提出的Okanagan专注于增强LLM在代码生成任务中的沟通能力。根据我们的了解，我们是首个研究和比较LLM代理与代码LLM在代码生成任务中沟通能力的工作。
- en: 8\. Conclusions
  id: totrans-312
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8\. 结论
- en: In this paper, we showed an initial step in the empirical study of the communication
    skills of LLMs in evaluating code clarification and code generation. We argue
    that the proficiency of communication skills of LLMs is necessary for AI systems
    to generate code with high standards, and, in the long term, to ask questions
    to acquire information that is just enough to complete their tasks. We believe
    that elevated communication skills should be viewed as an important factor in
    bridging the gap between LLMs and top-notch software developers. Although it needs
    additional conversational inputs, we believe it is still necessary and worthwhile
    to evaluate this communication capability for coding tasks.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们展示了对LLMs在代码澄清和代码生成方面沟通技能的实证研究的初步步骤。我们认为，LLMs的沟通技能的熟练程度对于AI系统生成高标准的代码是必要的，从长远来看，还需要提出问题以获取完成任务所需的信息。我们相信，高水平的沟通技能应被视为弥合LLMs与顶尖软件开发人员之间差距的重要因素。尽管这需要额外的对话输入，我们仍然认为评估这种沟通能力对于编码任务是必要且值得的。
- en: As a first step toward this effort, we created HumanEvalComm to evaluate the
    degree of communication skills. Based on the new benchmark, we comprehensively
    evaluated different Code LLMs with the communication lens, where certain information
    is manually modified in the original problem description. Furthermore, we proposed
    an LLM-based agent approach, Okanagan, to identify and ask questions in ambiguous
    parts of code and descriptions for further refining the generated code. We found
    that modifying the problem description greatly reduced Test Pass Rates and Pass@1
    with statistical significance. In terms of communication skills, more than 60%
    of responses from Code LLMs still generate code rather than ask questions when
    the problem descriptions are manually modified. We also find that, compared with
    LLM such as ChatGPT 3.5, Okanagan, as a LLM agent approach, can effectively increase
    Communication Rate and Good Question Rate, and thus boost Test Pass Rate and Pass@1
    when the problem descriptions are modified based on a clarification type.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 作为这一努力的第一步，我们创建了HumanEvalComm来评估沟通技能的程度。基于新的基准，我们从沟通的角度全面评估了不同的代码LLMs，其中某些信息在原问题描述中被手动修改。此外，我们提出了一种基于LLM的代理方法Okanagan，用于识别和询问代码和描述中模糊的部分，以进一步完善生成的代码。我们发现，修改问题描述显著降低了测试通过率和Pass@1。在沟通技能方面，超过60%的代码LLMs的响应仍然生成代码而不是在问题描述被手动修改时提出问题。我们还发现，与ChatGPT
    3.5等LLM相比，作为LLM代理方法的Okanagan能够有效提高沟通率和良好问题率，从而在问题描述基于澄清类型进行修改时提升测试通过率和Pass@1。
- en: Besides benchmarks, techniques to further improve the communication skills of
    LLMs can be the next steps in future work. Another interesting angle is to study
    how to tune the model to switch between under-communicating, effective-communicating,
    and over-communicating. We envision that different AI programming agents in the
    future will have various levels and styles of communication ability. This work
    can be seen as the first step toward evaluating the communication skills of Code
    LLMs and LLM agents. Our benchmark and replication package are made public at
    [https://github.com/jie-jw-wu/human-eval-comm](https://github.com/jie-jw-wu/human-eval-comm).
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 除了基准测试外，进一步提高LLMs沟通技能的技术可以作为未来工作的下一步。另一个有趣的角度是研究如何调整模型在沟通不足、有效沟通和过度沟通之间切换。我们设想未来的不同AI编程代理将具有不同的沟通能力水平和风格。这项工作可以被视为评估代码LLMs和LLM代理沟通技能的第一步。我们的基准测试和复现包公开在
    [https://github.com/jie-jw-wu/human-eval-comm](https://github.com/jie-jw-wu/human-eval-comm)。
- en: References
  id: totrans-316
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: big (2024) Hugging Face Accessed 2024. *Big Code Models Leaderboard*. Hugging
    Face. [https://huggingface.co/spaces/bigcode/bigcode-models-leaderboard](https://huggingface.co/spaces/bigcode/bigcode-models-leaderboard)
    Accessed on April 29, 2024.
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: big (2024) Hugging Face 访问于2024年。*Big Code Models Leaderboard*。Hugging Face。
    [https://huggingface.co/spaces/bigcode/bigcode-models-leaderboard](https://huggingface.co/spaces/bigcode/bigcode-models-leaderboard)
    访问于2024年4月29日。
- en: 'Alon et al. (2019) U. Alon, M. Zilberstein, O. Levy, and E. Yahav. 2019. Code2Vec:
    Learning Distributed Representations of Code. *Proceedings of the ACM on Programming
    Languages* 3, POPL (2019), 1–29.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Alon 等 (2019) U. Alon, M. Zilberstein, O. Levy 和 E. Yahav。2019。Code2Vec: 学习代码的分布式表示。*ACM编程语言会议录*
    3, POPL (2019), 1–29。'
- en: Arvidsson and Axell (2023) Simon Arvidsson and Johan Axell. 2023. Prompt engineering
    guidelines for LLMs in Requirements Engineering. (2023).
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Arvidsson 和 Axell（2023）Simon Arvidsson 和 Johan Axell。2023年。《LLMs 在需求工程中的提示工程指南》。
    （2023年）。
- en: Austin et al. (2021) Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma,
    Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc
    Le, et al. 2021. Program synthesis with large language models. *arXiv preprint
    arXiv:2108.07732* (2021).
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Austin 等（2021）Jacob Austin、Augustus Odena、Maxwell Nye、Maarten Bosma、Henryk Michalewski、David
    Dohan、Ellen Jiang、Carrie Cai、Michael Terry、Quoc Le 等。2021年。《使用大型语言模型进行程序合成》。*arXiv
    预印本 arXiv:2108.07732*（2021年）。
- en: Bai et al. (2023) Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong
    Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, et al. 2023. Qwen technical report.
    *arXiv preprint arXiv:2309.16609* (2023).
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bai 等（2023）Jinze Bai、Shuai Bai、Yunfei Chu、Zeyu Cui、Kai Dang、Xiaodong Deng、Yang
    Fan、Wenbin Ge、Yu Han、Fei Huang 等。2023年。《Qwen 技术报告》。*arXiv 预印本 arXiv:2309.16609*（2023年）。
- en: 'Bai et al. (2022) Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell,
    Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron
    McKinnon, Carol Chen, Catherine Olsson, Christopher Olah, Danny Hernandez, Dawn
    Drain, Deep Ganguli, Dustin Li, Eli Tran-Johnson, Ethan Perez, Jamie Kerr, Jared
    Mueller, Jeffrey Ladish, Joshua Landau, Kamal Ndousse, Kamile Lukosiute, Liane
    Lovitt, Michael Sellitto, Nelson Elhage, Nicholas Schiefer, Noemí Mercado, Nova
    DasSarma, Robert Lasenby, Robin Larson, Sam Ringer, Scott Johnston, Shauna Kravec,
    Sheer El Showk, Stanislav Fort, Tamera Lanham, Timothy Telleen-Lawton, Tom Conerly,
    Tom Henighan, Tristan Hume, Samuel R. Bowman, Zac Hatfield-Dodds, Ben Mann, Dario
    Amodei, Nicholas Joseph, Sam McCandlish, Tom Brown, and Jared Kaplan. 2022. Constitutional
    AI: Harmlessness from AI Feedback. *CoRR* abs/2212.08073 (2022).'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bai 等（2022）Yuntao Bai、Saurav Kadavath、Sandipan Kundu、Amanda Askell、Jackson Kernion、Andy
    Jones、Anna Chen、Anna Goldie、Azalia Mirhoseini、Cameron McKinnon、Carol Chen、Catherine
    Olsson、Christopher Olah、Danny Hernandez、Dawn Drain、Deep Ganguli、Dustin Li、Eli
    Tran-Johnson、Ethan Perez、Jamie Kerr、Jared Mueller、Jeffrey Ladish、Joshua Landau、Kamal
    Ndousse、Kamile Lukosiute、Liane Lovitt、Michael Sellitto、Nelson Elhage、Nicholas
    Schiefer、Noemí Mercado、Nova DasSarma、Robert Lasenby、Robin Larson、Sam Ringer、Scott
    Johnston、Shauna Kravec、Sheer El Showk、Stanislav Fort、Tamera Lanham、Timothy Telleen-Lawton、Tom
    Conerly、Tom Henighan、Tristan Hume、Samuel R. Bowman、Zac Hatfield-Dodds、Ben Mann、Dario
    Amodei、Nicholas Joseph、Sam McCandlish、Tom Brown 和 Jared Kaplan。2022年。《宪法 AI：来自
    AI 反馈的无害性》。*CoRR* abs/2212.08073（2022年）。
- en: 'Bi et al. (2024) Xiao Bi, Deli Chen, Guanting Chen, Shanhuang Chen, Damai Dai,
    Chengqi Deng, Honghui Ding, Kai Dong, Qiushi Du, Zhe Fu, et al. 2024. Deepseek
    llm: Scaling open-source language models with longtermism. *arXiv preprint arXiv:2401.02954*
    (2024).'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bi 等（2024）Xiao Bi、Deli Chen、Guanting Chen、Shanhuang Chen、Damai Dai、Chengqi Deng、Honghui
    Ding、Kai Dong、Qiushi Du、Zhe Fu 等。2024年。《Deepseek llm：用长远主义扩展开源语言模型》。*arXiv 预印本
    arXiv:2401.02954*（2024年）。
- en: Borji (2023) Ali Borji. 2023. A categorical archive of chatgpt failures. *arXiv
    preprint arXiv:2302.03494* (2023).
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Borji（2023）Ali Borji。2023年。《ChatGPT 失败的分类档案》。*arXiv 预印本 arXiv:2302.03494*（2023年）。
- en: 'Bouzenia et al. (2024) Islem Bouzenia, Premkumar Devanbu, and Michael Pradel.
    2024. RepairAgent: An Autonomous, LLM-Based Agent for Program Repair. *arXiv preprint
    arXiv:2403.17134* (2024).'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bouzenia 等（2024）Islem Bouzenia、Premkumar Devanbu 和 Michael Pradel。2024年。《RepairAgent：基于
    LLM 的程序修复自主代理》。*arXiv 预印本 arXiv:2403.17134*（2024年）。
- en: Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D
    Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
    Askell, et al. 2020. Language models are few-shot learners. *Advances in neural
    information processing systems* 33 (2020), 1877–1901.
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown 等（2020）Tom Brown、Benjamin Mann、Nick Ryder、Melanie Subbiah、Jared D Kaplan、Prafulla
    Dhariwal、Arvind Neelakantan、Pranav Shyam、Girish Sastry、Amanda Askell 等。2020年。《语言模型是少量学习者》。*神经信息处理系统进展*
    33（2020年），1877–1901。
- en: 'Bui et al. (2021) N. D. Bui, Y. Yu, and L. Jiang. 2021. InferCode: Self-supervised
    Learning of Code Representations by Predicting Subtrees. In *2021 IEEE/ACM 43rd
    International Conference on Software Engineering (ICSE)*. 1186–1197.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bui 等（2021）N. D. Bui、Y. Yu 和 L. Jiang。2021年。《InferCode：通过预测子树进行的自监督代码表示学习》。在
    *2021 IEEE/ACM 第43届国际软件工程会议（ICSE）*。1186–1197。
- en: Chen et al. (2021) Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique
    Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph,
    Greg Brockman, et al. 2021. Evaluating large language models trained on code.
    *arXiv preprint arXiv:2107.03374* (2021).
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等（2021）Mark Chen、Jerry Tworek、Heewoo Jun、Qiming Yuan、Henrique Ponde de
    Oliveira Pinto、Jared Kaplan、Harri Edwards、Yuri Burda、Nicholas Joseph、Greg Brockman
    等。2021年。《评估训练有素的大型语言模型》。*arXiv 预印本 arXiv:2107.03374*（2021年）。
- en: 'Dermeval et al. (2016) Diego Dermeval, Jéssyka Vilela, Ig Ibert Bittencourt,
    Jaelson Castro, Seiji Isotani, Patrick Brito, and Alan Silva. 2016. Applications
    of ontologies in requirements engineering: a systematic review of the literature.
    *Requirements engineering* 21 (2016), 405–437.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dermeval 等 (2016) Diego Dermeval, Jéssyka Vilela, Ig Ibert Bittencourt, Jaelson
    Castro, Seiji Isotani, Patrick Brito, 和 Alan Silva. 2016. 本体在需求工程中的应用：文献的系统回顾。*Requirements
    engineering* 21 (2016), 405–437。
- en: Du et al. (2023) Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum,
    and Igor Mordatch. 2023. Improving factuality and reasoning in language models
    through multiagent debate. *arXiv preprint arXiv:2305.14325* (2023).
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Du 等 (2023) Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, 和 Igor
    Mordatch. 2023. 通过多智能体辩论提高语言模型的事实性和推理能力。*arXiv 预印本 arXiv:2305.14325* (2023)。
- en: 'Eghbali and Pradel (2024) Aryaz Eghbali and Michael Pradel. 2024. De-Hallucinator:
    Iterative Grounding for LLM-Based Code Completion. *arXiv preprint arXiv:2401.01701*
    (2024).'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Eghbali 和 Pradel (2024) Aryaz Eghbali 和 Michael Pradel. 2024. De-Hallucinator:
    基于 LLM 的代码补全的迭代基础。*arXiv 预印本 arXiv:2401.01701* (2024)。'
- en: Face (2023) Hugging Face. 2023. *Codeparrot*. [https://huggingface.co/codeparrot/codeparrot](https://huggingface.co/codeparrot/codeparrot)
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Face (2023) Hugging Face. 2023. *Codeparrot*。 [https://huggingface.co/codeparrot/codeparrot](https://huggingface.co/codeparrot/codeparrot)
- en: 'Fakhoury et al. (2024) Sarah Fakhoury, Aaditya Naik, Georgios Sakkas, Saikat
    Chakraborty, and Shuvendu K Lahiri. 2024. LLM-based Test-driven Interactive Code
    Generation: User Study and Empirical Evaluation. *arXiv preprint arXiv:2404.10100*
    (2024).'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fakhoury 等 (2024) Sarah Fakhoury, Aaditya Naik, Georgios Sakkas, Saikat Chakraborty,
    和 Shuvendu K Lahiri. 2024. 基于 LLM 的测试驱动交互式代码生成：用户研究与实证评估。*arXiv 预印本 arXiv:2404.10100*
    (2024)。
- en: 'Fan et al. (2023) Angela Fan, Beliz Gokkaya, Mark Harman, Mitya Lyubarskiy,
    Shubho Sengupta, Shin Yoo, and Jie M Zhang. 2023. Large language models for software
    engineering: Survey and open problems. *arXiv preprint arXiv:2310.03533* (2023).'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fan 等 (2023) Angela Fan, Beliz Gokkaya, Mark Harman, Mitya Lyubarskiy, Shubho
    Sengupta, Shin Yoo, 和 Jie M Zhang. 2023. 大型语言模型在软件工程中的应用：调查与开放问题。*arXiv 预印本 arXiv:2310.03533*
    (2023)。
- en: 'Feng et al. (2020) Z. Feng, D. Guo, D. Tang, N. Duan, X. Feng, M. Gong, L.
    Shou, B. Qin, T. Liu, and D. Jiang et al. 2020. CodeBERT: A Pre-trained Model
    for Programming and Natural Languages. *arXiv preprint arXiv:2002.08155* (2020).'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Feng 等 (2020) Z. Feng, D. Guo, D. Tang, N. Duan, X. Feng, M. Gong, L. Shou,
    B. Qin, T. Liu, 和 D. Jiang 等. 2020. CodeBERT: 一种用于编程和自然语言的预训练模型。*arXiv 预印本 arXiv:2002.08155*
    (2020)。'
- en: 'Fernandes et al. (2023) Patrick Fernandes, Aman Madaan, Emmy Liu, António Farinhas,
    Pedro Henrique Martins, Amanda Bertsch, José G. C. de Souza, Shuyan Zhou, Tongshuang
    Wu, Graham Neubig, and André F. T. Martins. 2023. Bridging the Gap: A Survey on
    Integrating (Human) Feedback for Natural Language Generation. *CoRR* abs/2305.00955
    (2023).'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fernandes 等 (2023) Patrick Fernandes, Aman Madaan, Emmy Liu, António Farinhas,
    Pedro Henrique Martins, Amanda Bertsch, José G. C. de Souza, Shuyan Zhou, Tongshuang
    Wu, Graham Neubig, 和 André F. T. Martins. 2023. 缩小差距：关于将（人类）反馈集成到自然语言生成中的调查。*CoRR*
    abs/2305.00955 (2023)。
- en: 'Gao et al. (2024) Mingqi Gao, Xinyu Hu, Jie Ruan, Xiao Pu, and Xiaojun Wan.
    2024. Llm-based nlg evaluation: Current status and challenges. *arXiv preprint
    arXiv:2402.01383* (2024).'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao 等 (2024) Mingqi Gao, Xinyu Hu, Jie Ruan, Xiao Pu, 和 Xiaojun Wan. 2024. 基于
    LLM 的自然语言生成评估：现状与挑战。*arXiv 预印本 arXiv:2402.01383* (2024)。
- en: Glaese et al. (2022) Amelia Glaese, Nat McAleese, Maja Trebacz, John Aslanides,
    Vlad Firoiu, Timo Ewalds, Maribeth Rauh, Laura Weidinger, Martin J. Chadwick,
    Phoebe Thacker, Lucy Campbell-Gillingham, Jonathan Uesato, Po-Sen Huang, Ramona
    Comanescu, Fan Yang, Abigail See, Sumanth Dathathri, Rory Greig, Charlie Chen,
    Doug Fritz, Jaume Sanchez Elias, Richard Green, Sona Mokrá, Nicholas Fernando,
    Boxi Wu, Rachel Foley, Susannah Young, Iason Gabriel, William Isaac, John Mellor,
    Demis Hassabis, Koray Kavukcuoglu, Lisa Anne Hendricks, and Geoffrey Irving. 2022.
    Improving Alignment of Dialogue Agents via Targeted Human Judgements. *CoRR* abs/2209.14375
    (2022).
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Glaese 等 (2022) Amelia Glaese, Nat McAleese, Maja Trebacz, John Aslanides, Vlad
    Firoiu, Timo Ewalds, Maribeth Rauh, Laura Weidinger, Martin J. Chadwick, Phoebe
    Thacker, Lucy Campbell-Gillingham, Jonathan Uesato, Po-Sen Huang, Ramona Comanescu,
    Fan Yang, Abigail See, Sumanth Dathathri, Rory Greig, Charlie Chen, Doug Fritz,
    Jaume Sanchez Elias, Richard Green, Sona Mokrá, Nicholas Fernando, Boxi Wu, Rachel
    Foley, Susannah Young, Iason Gabriel, William Isaac, John Mellor, Demis Hassabis,
    Koray Kavukcuoglu, Lisa Anne Hendricks, 和 Geoffrey Irving. 2022. 通过目标人类判断改进对话代理的对齐。*CoRR*
    abs/2209.14375 (2022)。
- en: 'Guo et al. (2024) Daya Guo, Qihao Zhu, Dejian Yang, Zhenda Xie, Kai Dong, Wentao
    Zhang, Guanting Chen, Xiao Bi, Y Wu, YK Li, et al. 2024. DeepSeek-Coder: When
    the Large Language Model Meets Programming–The Rise of Code Intelligence. *arXiv
    preprint arXiv:2401.14196* (2024).'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Guo et al. (2024) Daya Guo, Qihao Zhu, Dejian Yang, Zhenda Xie, Kai Dong, Wentao
    Zhang, Guanting Chen, Xiao Bi, Y Wu, YK Li, 等. 2024. DeepSeek-Coder: 当大型语言模型遇上编程——代码智能的崛起。
    *arXiv预印本 arXiv:2401.14196* (2024)。'
- en: 'Hassan et al. (2024) Ahmed E Hassan, Gustavo A Oliva, Dayi Lin, Boyuan Chen,
    Zhen Ming, et al. 2024. Rethinking Software Engineering in the Foundation Model
    Era: From Task-Driven AI Copilots to Goal-Driven AI Pair Programmers. *arXiv preprint
    arXiv:2404.10225* (2024).'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hassan et al. (2024) Ahmed E Hassan, Gustavo A Oliva, Dayi Lin, Boyuan Chen,
    Zhen Ming, 等. 2024. 在基础模型时代重新思考软件工程：从任务驱动的AI副驾驶到目标驱动的AI配对程序员。 *arXiv预印本 arXiv:2404.10225*
    (2024)。
- en: 'He et al. (2023) Hangfeng He, Hongming Zhang, and Dan Roth. 2023. Rethinking
    with Retrieval: Faithful Large Language Model Inference. *CoRR* abs/2301.00303
    (2023).'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He et al. (2023) Hangfeng He, Hongming Zhang, 和 Dan Roth. 2023. 通过检索重新思考：忠实的大型语言模型推断。
    *CoRR* abs/2301.00303 (2023)。
- en: Hendrycks et al. (2021) Dan Hendrycks, Steven Basart, Saurav Kadavath, Mantas
    Mazeika, Akul Arora, Ethan Guo, Collin Burns, Samir Puranik, Horace He, Dawn Song,
    et al. 2021. Measuring coding challenge competence with apps. *arXiv preprint
    arXiv:2105.09938* (2021).
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hendrycks et al. (2021) Dan Hendrycks, Steven Basart, Saurav Kadavath, Mantas
    Mazeika, Akul Arora, Ethan Guo, Collin Burns, Samir Puranik, Horace He, Dawn Song,
    等. 2021. 使用应用程序测量编码挑战能力。 *arXiv预印本 arXiv:2105.09938* (2021)。
- en: Huang et al. (2022) Jiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu, Xuezhi
    Wang, Hongkun Yu, and Jiawei Han. 2022. Large Language Models Can Self-Improve.
    *CoRR* abs/2210.11610 (2022).
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang et al. (2022) Jiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu, Xuezhi
    Wang, Hongkun Yu, 和 Jiawei Han. 2022. 大型语言模型可以自我提升。 *CoRR* abs/2210.11610 (2022)。
- en: Jazayeri (2004) Mehdi Jazayeri. 2004. The education of a software engineer.
    In *Proceedings. 19th International Conference on Automated Software Engineering,
    2004.* IEEE, xviii–xxvii.
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jazayeri (2004) Mehdi Jazayeri. 2004. 软件工程师的教育。 在 *第19届国际自动化软件工程会议论文集，2004年*。
    IEEE, xviii–xxvii。
- en: 'Jiang et al. (2023) Shuyang Jiang, Yuhao Wang, and Yu Wang. 2023. SelfEvolve:
    A Code Evolution Framework via Large Language Models. *CoRR* abs/2306.02907 (2023).'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jiang et al. (2023) Shuyang Jiang, Yuhao Wang, 和 Yu Wang. 2023. SelfEvolve:
    一个通过大型语言模型的代码进化框架。 *CoRR* abs/2306.02907 (2023)。'
- en: 'Jimenez et al. (2024) Carlos E Jimenez, John Yang, Alexander Wettig, Shunyu
    Yao, Kexin Pei, Ofir Press, and Karthik R Narasimhan. 2024. SWE-bench: Can Language
    Models Resolve Real-world Github Issues?. In *The Twelfth International Conference
    on Learning Representations*. [https://openreview.net/forum?id=VTF8yNQM66](https://openreview.net/forum?id=VTF8yNQM66)'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jimenez et al. (2024) Carlos E Jimenez, John Yang, Alexander Wettig, Shunyu
    Yao, Kexin Pei, Ofir Press, 和 Karthik R Narasimhan. 2024. SWE-bench: 语言模型能否解决实际的Github问题？
    在 *第十二届国际学习表征会议*。 [https://openreview.net/forum?id=VTF8yNQM66](https://openreview.net/forum?id=VTF8yNQM66)'
- en: Kim et al. (2023) Joonghoon Kim, Saeran Park, Kiyoon Jeong, Sangmin Lee, Seung Hun
    Han, Jiyoon Lee, and Pilsung Kang. 2023. Which is better? exploring prompting
    strategy for llm-based metrics. *arXiv preprint arXiv:2311.03754* (2023).
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim et al. (2023) Joonghoon Kim, Saeran Park, Kiyoon Jeong, Sangmin Lee, Seung
    Hun Han, Jiyoon Lee, 和 Pilsung Kang. 2023. 哪个更好？ 探索基于llm的度量的提示策略。 *arXiv预印本 arXiv:2311.03754*
    (2023)。
- en: Kocmi and Federmann (2023) Tom Kocmi and Christian Federmann. 2023. Large language
    models are state-of-the-art evaluators of translation quality. *arXiv preprint
    arXiv:2302.14520* (2023).
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kocmi and Federmann (2023) Tom Kocmi 和 Christian Federmann. 2023. 大型语言模型是翻译质量的最先进评估工具。
    *arXiv预印本 arXiv:2302.14520* (2023)。
- en: 'Kotonya et al. (2023) Neema Kotonya, Saran Krishnasamy, Joel Tetreault, and
    Alejandro Jaimes. 2023. Little giants: Exploring the potential of small llms as
    evaluation metrics in summarization in the eval4nlp 2023 shared task. *arXiv preprint
    arXiv:2311.00686* (2023).'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kotonya et al. (2023) Neema Kotonya, Saran Krishnasamy, Joel Tetreault, 和 Alejandro
    Jaimes. 2023. 小巨人：探索小型llms在总结中的潜力，作为eval4nlp 2023共享任务中的评估指标。 *arXiv预印本 arXiv:2311.00686*
    (2023)。
- en: 'Kreutzer et al. (2018) Julia Kreutzer, Shahram Khadivi, Evgeny Matusov, and
    Stefan Riezler. 2018. Can Neural Machine Translation Be Improved with User Feedback?.
    In *Proceedings of the 2018 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies (NAACL-HLT)*.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kreutzer et al. (2018) Julia Kreutzer, Shahram Khadivi, Evgeny Matusov, 和 Stefan
    Riezler. 2018. 神经机器翻译能否通过用户反馈得到改进？ 在 *2018年北美计算语言学协会人类语言技术会议论文集（NAACL-HLT）*。
- en: Li et al. (2022) Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian
    Schrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin
    Dal Lago, et al. 2022. Competition-level code generation with alphacode. *Science*
    378, 6624 (2022), 1092–1097.
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等（2022）Yujia Li、David Choi、Junyoung Chung、Nate Kushman、Julian Schrittwieser、Rémi
    Leblond、Tom Eccles、James Keeling、Felix Gimeno、Agustin Dal Lago 等。2022年。使用 Alphacode
    进行竞争级别的代码生成。*Science* 378，6624（2022），1092–1097。
- en: Liang et al. (2023) Jenny T Liang, Chenyang Yang, and Brad A Myers. 2023. Understanding
    the Usability of AI Programming Assistants. *arXiv preprint arXiv:2303.17125*
    (2023).
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liang 等（2023）Jenny T Liang、Chenyang Yang 和 Brad A Myers。2023年。理解 AI 编程助手的可用性。*arXiv
    预印本 arXiv:2303.17125*（2023）。
- en: 'Liu et al. (2023a) Yongkang Liu, Shi Feng, Daling Wang, Yifei Zhang, and Hinrich
    Schütze. 2023a. Evaluate What You Can’t Evaluate: Unassessable Generated Responses
    Quality. *arXiv preprint arXiv:2305.14658* (2023).'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等（2023a）Yongkang Liu、Shi Feng、Daling Wang、Yifei Zhang 和 Hinrich Schütze。2023a年。评估你无法评估的：不可评估的生成响应质量。*arXiv
    预印本 arXiv:2305.14658*（2023）。
- en: 'Liu et al. (2023b) Yue Liu, Thanh Le-Cong, Ratnadira Widyasari, Chakkrit Tantithamthavorn,
    Li Li, Xuan-Bach D Le, and David Lo. 2023b. Refining ChatGPT-Generated Code: Characterizing
    and Mitigating Code Quality Issues. *arXiv preprint arXiv:2307.12596* (2023).'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等（2023b）Yue Liu、Thanh Le-Cong、Ratnadira Widyasari、Chakkrit Tantithamthavorn、Li
    Li、Xuan-Bach D Le 和 David Lo。2023b年。精炼 ChatGPT 生成的代码：特征化和缓解代码质量问题。*arXiv 预印本 arXiv:2307.12596*（2023）。
- en: Liu et al. (2023c) Zhijie Liu, Yutian Tang, Xiapu Luo, Yuming Zhou, and Liang Feng
    Zhang. 2023c. No Need to Lift a Finger Anymore? Assessing the Quality of Code
    Generation by ChatGPT. *arXiv preprint arXiv:2308.04838* (2023).
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等（2023c）Zhijie Liu、Yutian Tang、Xiapu Luo、Yuming Zhou 和 Liang Feng Zhang。2023c年。无需再动手？评估
    ChatGPT 生成代码的质量。*arXiv 预印本 arXiv:2308.04838*（2023）。
- en: McChesney and Gallagher (2004) Ian R McChesney and Seamus Gallagher. 2004. Communication
    and co-ordination practices in software engineering projects. *Information and
    Software Technology* 46, 7 (2004), 473–489.
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: McChesney 和 Gallagher（2004）Ian R McChesney 和 Seamus Gallagher。2004年。软件工程项目中的沟通与协调实践。*信息与软件技术*
    46，7（2004），473–489。
- en: 'Min et al. (2023) Marcus J Min, Yangruibo Ding, Luca Buratti, Saurabh Pujar,
    Gail Kaiser, Suman Jana, and Baishakhi Ray. 2023. Beyond accuracy: Evaluating
    self-consistency of code large language models with identitychain. *arXiv preprint
    arXiv:2310.14053* (2023).'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Min 等（2023）Marcus J Min、Yangruibo Ding、Luca Buratti、Saurabh Pujar、Gail Kaiser、Suman
    Jana 和 Baishakhi Ray。2023年。超越准确性：通过 identitychain 评估代码大型语言模型的自洽性。*arXiv 预印本 arXiv:2310.14053*（2023）。
- en: 'Mistrík et al. (2010) Ivan Mistrík, John Grundy, Andre Van der Hoek, and Jim
    Whitehead. 2010. *Collaborative software engineering: challenges and prospects*.
    Springer.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mistrík 等（2010）Ivan Mistrík、John Grundy、Andre Van der Hoek 和 Jim Whitehead。2010年。*协作软件工程：挑战与前景*。Springer。
- en: Nguyen and Nadi (2022) N. Nguyen and S. Nadi. 2022. An Empirical Evaluation
    of GitHub Copilot’s Code Suggestions. In *Proceedings of the 19th International
    Conference on Mining Software Repositories*. 1–5.
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nguyen 和 Nadi（2022）N. Nguyen 和 S. Nadi。2022年。对 GitHub Copilot 代码建议的实证评估。见于 *第十九届国际软件仓库挖掘会议论文集*。1–5。
- en: 'Nijkamp et al. (2022) Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan
    Wang, Yingbo Zhou, Silvio Savarese, and Caiming Xiong. 2022. Codegen: An open
    large language model for code with multi-turn program synthesis. *arXiv preprint
    arXiv:2203.13474* (2022).'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nijkamp 等（2022）Erik Nijkamp、Bo Pang、Hiroaki Hayashi、Lifu Tu、Huan Wang、Yingbo
    Zhou、Silvio Savarese 和 Caiming Xiong。2022年。Codegen：一种用于代码的开放大型语言模型，具有多轮程序合成。*arXiv
    预印本 arXiv:2203.13474*（2022）。
- en: Ouyang et al. (2022) Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L.
    Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex
    Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda
    Askell, Peter Welinder, Paul F. Christiano, Jan Leike, and Ryan Lowe. 2022. Training
    Language Models to Follow Instructions with Human Feedback. In *Proceedings of
    the Annual Conference on Neural Information Processing Systems (NeurIPS)*.
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ouyang 等（2022）Long Ouyang、Jeffrey Wu、Xu Jiang、Diogo Almeida、Carroll L. Wainwright、Pamela
    Mishkin、Chong Zhang、Sandhini Agarwal、Katarina Slama、Alex Ray、John Schulman、Jacob
    Hilton、Fraser Kelton、Luke Miller、Maddie Simens、Amanda Askell、Peter Welinder、Paul
    F. Christiano、Jan Leike 和 Ryan Lowe。2022年。训练语言模型以遵循人类反馈的指令。见于 *年度神经信息处理系统会议论文集（NeurIPS）*。
- en: 'Ouyang et al. (2023) Shuyin Ouyang, Jie M Zhang, Mark Harman, and Meng Wang.
    2023. LLM is Like a Box of Chocolates: the Non-determinism of ChatGPT in Code
    Generation. *arXiv preprint arXiv:2308.02828* (2023).'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ouyang 等（2023）Shuyin Ouyang、Jie M Zhang、Mark Harman 和 Meng Wang。2023年。LLM 就像一盒巧克力：ChatGPT
    在代码生成中的非确定性。*arXiv 预印本 arXiv:2308.02828*（2023）。
- en: 'Pan et al. (2023) Liangming Pan, Michael Saxon, Wenda Xu, Deepak Nathani, Xinyi
    Wang, and William Yang Wang. 2023. Automatically Correcting Large Language Models:
    Surveying the landscape of diverse self-correction strategies. *arXiv preprint
    arXiv:2308.03188* (2023).'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pan et al. (2023) Liangming Pan, Michael Saxon, Wenda Xu, Deepak Nathani, Xinyi
    Wang, 和 William Yang Wang. 2023. 自动纠正大型语言模型：调查多样化自我纠正策略的全景。*arXiv预印本 arXiv:2308.03188*
    (2023)。
- en: 'Pressman (2005) Roger S Pressman. 2005. *Software engineering: a practitioner’s
    approach*. Palgrave macmillan.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pressman (2005) Roger S Pressman. 2005. *软件工程：实践者的方法*。Palgrave Macmillan。
- en: Rabinovich et al. (2017) M. Rabinovich, M. Stern, and D. Klein. 2017. Abstract
    Syntax Networks for Code Generation and Semantic Parsing. *arXiv preprint arXiv:1704.07535*
    (2017).
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rabinovich et al. (2017) M. Rabinovich, M. Stern, 和 D. Klein. 2017. 用于代码生成和语义解析的抽象语法网络。*arXiv预印本
    arXiv:1704.07535* (2017)。
- en: 'Rasheed et al. (2024) Zeeshan Rasheed, Muhammad Waseem, Mika Saari, Kari Systä,
    and Pekka Abrahamsson. 2024. Codepori: Large scale model for autonomous software
    development by using multi-agents. *arXiv preprint arXiv:2402.01411* (2024).'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Rasheed et al. (2024) Zeeshan Rasheed, Muhammad Waseem, Mika Saari, Kari Systä,
    和 Pekka Abrahamsson. 2024. Codepori: 使用多代理的大规模自主软件开发模型。*arXiv预印本 arXiv:2402.01411*
    (2024)。'
- en: 'Roziere et al. (2023) Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten
    Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy
    Rapin, et al. 2023. Code llama: Open foundation models for code. *arXiv preprint
    arXiv:2308.12950* (2023).'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Roziere et al. (2023) Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten
    Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy
    Rapin, 等. 2023. Code llama: 开放基础模型用于代码。*arXiv预印本 arXiv:2308.12950* (2023)。'
- en: Sarkar et al. (2022) Advait Sarkar, Andrew D Gordon, Carina Negreanu, Christian
    Poelitz, Sruti Srinivasa Ragavan, and Ben Zorn. 2022. What is it like to program
    with artificial intelligence? *arXiv preprint arXiv:2208.06213* (2022).
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sarkar et al. (2022) Advait Sarkar, Andrew D Gordon, Carina Negreanu, Christian
    Poelitz, Sruti Srinivasa Ragavan, 和 Ben Zorn. 2022. 使用人工智能编程是什么体验？*arXiv预印本 arXiv:2208.06213*
    (2022)。
- en: Scheurer et al. (2023) Jérémy Scheurer, Jon Ander Campos, Tomasz Korbak, Jun Shern
    Chan, Angelica Chen, Kyunghyun Cho, and Ethan Perez. 2023. Training Language Models
    with Language Feedback at Scale. *CoRR* abs/2303.16755 (2023).
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Scheurer et al. (2023) Jérémy Scheurer, Jon Ander Campos, Tomasz Korbak, Jun
    Shern Chan, Angelica Chen, Kyunghyun Cho, 和 Ethan Perez. 2023. 大规模语言模型的语言反馈训练。*CoRR*
    abs/2303.16755 (2023)。
- en: Shanahan (2024) Murray Shanahan. 2024. Talking about large language models.
    *Commun. ACM* 67, 2 (2024), 68–79.
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shanahan (2024) Murray Shanahan. 2024. 讨论大型语言模型。*Commun. ACM* 67, 2 (2024)，68–79。
- en: Siddiq et al. (2022) M. L. Siddiq, S. H. Majumder, M. R. Mim, S. Jajodia, and
    J. C. Santos. 2022. An Empirical Study of Code Smells in Transformer-Based Code
    Generation Techniques. In *2022 IEEE 22nd International Working Conference on
    Source Code Analysis and Manipulation (SCAM)*. 71–82.
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Siddiq et al. (2022) M. L. Siddiq, S. H. Majumder, M. R. Mim, S. Jajodia, 和
    J. C. Santos. 2022. 基于 Transformer 的代码生成技术中的代码异味的实证研究。发表于 *2022 IEEE第22届国际源代码分析与处理会议（SCAM）*。71–82。
- en: 'Sobania et al. (2022) D. Sobania, M. Briesch, and F. Rothlauf. 2022. Choose
    Your Programming Copilot: A Comparison of the Program Synthesis Performance of
    GitHub Copilot and Genetic Programming. In *Proceedings of the Genetic and Evolutionary
    Computation Conference*. 1019–1027.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sobania et al. (2022) D. Sobania, M. Briesch, 和 F. Rothlauf. 2022. 选择你的编程副驾驶：GitHub
    Copilot 和遗传编程的程序合成性能比较。发表于 *遗传与进化计算大会论文集*。1019–1027。
- en: 'Svyatkovskiy et al. (2020) A. Svyatkovskiy, S. K. Deng, S. Fu, and N. Sundaresan.
    2020. Intellicode Compose: Code Generation Using Transformer. In *Proceedings
    of the 28th ACM Joint Meeting on European Software Engineering Conference and
    Symposium on the Foundations of Software Engineering*. 1433–1443.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Svyatkovskiy et al. (2020) A. Svyatkovskiy, S. K. Deng, S. Fu, 和 N. Sundaresan.
    2020. Intellicode Compose: 使用 Transformer 进行代码生成。发表于 *第28届ACM欧洲软件工程会议联合会议及软件工程基础研讨会论文集*。1433–1443。'
- en: 'Tufano et al. (2020) M. Tufano, D. Drain, A. Svyatkovskiy, S. Deng, and N.
    Sundaresan. 2020. Unit Test Case Generation with Transformers and Focal Context.
    *arXiv preprint arXiv: Software Engineering* (2020).'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tufano et al. (2020) M. Tufano, D. Drain, A. Svyatkovskiy, S. Deng, 和 N. Sundaresan.
    2020. 使用 Transformers 和焦点上下文生成单元测试用例。*arXiv预印本 arXiv: 软件工程* (2020)。'
- en: 'Tukur et al. (2021) Muhammad Tukur, Sani Umar, and Jameleddine Hassine. 2021.
    Requirement engineering challenges: A systematic mapping study on the academic
    and the industrial perspective. *Arabian Journal for Science and Engineering*
    46 (2021), 3723–3748.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tukur et al. (2021) Muhammad Tukur, Sani Umar, 和 Jameleddine Hassine. 2021.
    需求工程挑战：对学术界和工业界的系统性映射研究。*阿拉伯科学与工程期刊* 46 (2021)，3723–3748。
- en: 'Vaithilingam et al. (2022) P. Vaithilingam, T. Zhang, and E. L. Glassman. 2022.
    Expectation vs. Experience: Evaluating the Usability of Code Generation Tools
    Powered by Large Language Models. In *CHI Conference on Human Factors in Computing
    Systems Extended Abstracts*. 1–7.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 韦斯林等（2022）P. 韦斯林、T. 张、E. L. 格拉斯曼。2022年。期望与经验：评估由大语言模型驱动的代码生成工具的可用性。在*CHI计算机系统人因会议扩展摘要*中。1–7。
- en: Vaswani et al. (2017) A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones,
    A. N. Gomez, Ł. Kaiser, and I. Polosukhin. 2017. Attention is All You Need. In
    *Advances in Neural Information Processing Systems*, Vol. 30.
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 瓦斯瓦尼等（2017）A. 瓦斯瓦尼、N. 沙泽尔、N. 帕尔马、J. 乌斯科雷特、L. 乔恩斯、A. N. 戈麦斯、Ł. 凯泽、I. 波洛苏欣。2017年。注意力机制即所有你需要的。
    在*神经信息处理系统进展*中，第30卷。
- en: 'Wang and Komatsuzaki (2021) Ben Wang and Aran Komatsuzaki. 2021. GPT-J-6B:
    A 6 billion parameter autoregressive language model.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 王和小松崎（2021）本·王和阿兰·小松崎。2021年。GPT-J-6B：一个60亿参数的自回归语言模型。
- en: Wang et al. (2023a) Jiaan Wang, Yunlong Liang, Fandong Meng, Zengkui Sun, Haoxiang
    Shi, Zhixu Li, Jinan Xu, Jianfeng Qu, and Jie Zhou. 2023a. Is chatgpt a good nlg
    evaluator? a preliminary study. *arXiv preprint arXiv:2303.04048* (2023).
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 王等（2023a）姜安·王、云龙·梁、范东·孟、曾奎·孙、邵翔·石、李志旭、徐津南、屈建锋、周杰。2023a年。ChatGPT是一个好的NLG评估器吗？一项初步研究。*arXiv预印本arXiv:2303.04048*（2023）。
- en: Wang et al. (2023b) Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
    Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al. 2023b. A survey
    on large language model based autonomous agents. *arXiv preprint arXiv:2308.11432*
    (2023).
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 王等（2023b）王磊、马辰、冯雪阳、张泽宇、杨浩、张景森、陈志远、唐纪凯、陈旭、林彦凯等。2023b年。基于大语言模型的自主代理的调查。*arXiv预印本arXiv:2308.11432*（2023）。
- en: 'Wang et al. (2021) Y. Wang, W. Wang, S. Joty, and S. C. Hoi. 2021. CodeT5:
    Identifier-Aware Unified Pre-trained Encoder-Decoder Models for Code Understanding
    and Generation. *arXiv preprint arXiv:2109.00859* (2021).'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 王等（2021）Y. 王、W. 王、S. Joty、S. C. Hoi。2021年。CodeT5：识别器感知的统一预训练编码器-解码器模型，用于代码理解和生成。*arXiv预印本arXiv:2109.00859*（2021）。
- en: Weng et al. (2023) Yixuan Weng, Minjun Zhu, Fei Xia, Bin Li, Shizhu He, Kang
    Liu, and Jun Zhao. 2023. Large Language Models Are Better Reasoners with Self-Verification.
    *CoRR* abs/2212.09561 (2023).
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 翁等（2023）翁一轩、朱敏军、夏飞、李斌、何世柱、刘康、赵军。2023年。大型语言模型在自我验证下更好的推理能力。*CoRR* abs/2212.09561（2023）。
- en: 'Whitehead (2007) Jim Whitehead. 2007. Collaboration in software engineering:
    A roadmap. In *Future of Software Engineering (FOSE’07)*. IEEE, 214–225.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 怀特黑德（2007）吉姆·怀特黑德。2007年。软件工程中的协作：路线图。在*软件工程的未来（FOSE’07）*中。IEEE，214–225。
- en: Wu (2024) Scott Wu. Accessed 2024. *Introducing Devin, the first AI software
    engineer*. Cognition. [https://www.cognition-labs.com/introducing-devin](https://www.cognition-labs.com/introducing-devin)
    Accessed on April 8, 2024.
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 吴（2024）斯科特·吴。访问于2024年。*介绍Devin——首个AI软件工程师*。Cognition。 [https://www.cognition-labs.com/introducing-devin](https://www.cognition-labs.com/introducing-devin)
    访问于2024年4月8日。
- en: 'Xi et al. (2023) Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang
    Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, et al. 2023. The rise and
    potential of large language model based agents: A survey. *arXiv preprint arXiv:2309.07864*
    (2023).'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 西等（2023）西志恒、陈文祥、郭欣、何伟、丁一文、洪博洋、张明、王俊哲、金森杰、周恩宇等。2023年。基于大语言模型的代理的崛起与潜力：一项调查。*arXiv预印本arXiv:2309.07864*（2023）。
- en: Xie et al. (2023) Yuxi Xie, Kenji Kawaguchi, Yiran Zhao, Xu Zhao, MinYen Kan,
    Junxian He, and Qizhe Xie. 2023. Decomposition Enhances Reasoning via Self-Evaluation
    Guided Decoding. *CoRR* abs/2305.00633 (2023).
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谢等（2023）谢宇希、川口贤治、赵怡然、赵旭、康敏彦、何俊贤、谢启哲。2023年。分解通过自我评估引导解码来增强推理。*CoRR* abs/2305.00633（2023）。
- en: Xu et al. (2022) Frank F Xu, Uri Alon, Graham Neubig, and Vincent Josua Hellendoorn.
    2022. A systematic evaluation of large language models of code. In *Proceedings
    of the 6th ACM SIGPLAN International Symposium on Machine Programming*. 1–10.
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 许等（2022）弗兰克·F 许、乌里·阿隆、格雷厄姆·纽比格、文森特·乔苏亚·赫伦多恩。2022年。对代码的大语言模型的系统评估。在*第6届ACM SIGPLAN国际机器编程研讨会论文集*中。1–10。
- en: 'Xu et al. (2024) Shuyuan Xu, Zelong Li, Kai Mei, and Yongfeng Zhang. 2024.
    CoRE: LLM as Interpreter for Natural Language Programming, Pseudo-Code Programming,
    and Flow Programming of AI Agents. *arXiv preprint arXiv:2405.06907* (2024).'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 许等（2024）许书源、李泽龙、梅凯、张永丰。2024年。CoRE：作为自然语言编程、伪代码编程和AI代理流程序编译器的LLM。*arXiv预印本arXiv:2405.06907*（2024）。
- en: Yang et al. (2022) Kaiyu Yang, Jia Deng, and Danqi Chen. 2022. Generating Natural
    Language Proofs with Verifier-Guided Search. In *Proceedings of the 2022 Conference
    on Empirical Methods in Natural Language Processing (EMNLP)*. 89–105.
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang et al. (2022) Kaiyu Yang, Jia Deng, 和 Danqi Chen. 2022. 生成自然语言证明与验证器引导的搜索。载于*2022年自然语言处理实证方法会议论文集
    (EMNLP)*。89–105.
- en: Ye et al. (2020) W. Ye, R. Xie, J. Zhang, T. Hu, X. Wang, and S. Zhang. 2020.
    Leveraging Code Generation to Improve Code Retrieval and Summarization via Dual
    Learning. In *Proceedings of The Web Conference 2020*. 2309–2319.
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ye et al. (2020) W. Ye, R. Xie, J. Zhang, T. Hu, X. Wang, 和 S. Zhang. 2020.
    利用代码生成提升代码检索和摘要的双重学习。载于*2020年网络会议论文集*。2309–2319.
- en: Yin et al. (2018) Pengcheng Yin, Bowen Deng, Edgar Chen, Bogdan Vasilescu, and
    Graham Neubig. 2018. Learning to mine aligned code and natural language pairs
    from stack overflow. In *Proceedings of the 15th international conference on mining
    software repositories*. 476–486.
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yin et al. (2018) Pengcheng Yin, Bowen Deng, Edgar Chen, Bogdan Vasilescu, 和
    Graham Neubig. 2018. 学习从 Stack Overflow 中挖掘对齐的代码和自然语言对。载于*第15届国际软件库挖掘会议论文集*。476–486.
- en: 'Zan et al. (2023) Daoguang Zan, Bei Chen, Fengji Zhang, Dianjie Lu, Bingchao
    Wu, Bei Guan, Wang Yongji, and Jian-Guang Lou. 2023. Large language models meet
    nl2code: A survey. In *Proceedings of the 61st Annual Meeting of the Association
    for Computational Linguistics (Volume 1: Long Papers)*. 7443–7464.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zan et al. (2023) Daoguang Zan, Bei Chen, Fengji Zhang, Dianjie Lu, Bingchao
    Wu, Bei Guan, Wang Yongji, 和 Jian-Guang Lou. 2023. 大型语言模型与 nl2code 的碰撞：一项综述。载于*第61届计算语言学协会年会论文集
    (第一卷：长篇论文)*。7443–7464.
- en: 'Zhang et al. (2023c) Jintian Zhang, Xin Xu, and Shumin Deng. 2023c. Exploring
    collaboration mechanisms for llm agents: A social psychology view. *arXiv preprint
    arXiv:2310.02124* (2023).'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2023c) Jintian Zhang, Xin Xu, 和 Shumin Deng. 2023c. 探索 LLM 代理的协作机制：社会心理学视角。*arXiv
    preprint arXiv:2310.02124* (2023).
- en: 'Zhang et al. (2023b) Kechi Zhang, Zhuo Li, Jia Li, Ge Li, and Zhi Jin. 2023b.
    Self-Edit: Fault-Aware Code Editor for Code Generation. *CoRR* abs/2305.04087
    (2023).'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang et al. (2023b) Kechi Zhang, Zhuo Li, Jia Li, Ge Li, 和 Zhi Jin. 2023b.
    Self-Edit: 关注故障的代码生成编辑器。*CoRR* abs/2305.04087 (2023).'
- en: 'Zhang et al. (2023a) Ziyin Zhang, Chaoyu Chen, Bingchang Liu, Cong Liao, Zi
    Gong, Hang Yu, Jianguo Li, and Rui Wang. 2023a. Unifying the perspectives of nlp
    and software engineering: A survey on language models for code. *arXiv preprint
    arXiv:2311.07989* (2023).'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2023a) Ziyin Zhang, Chaoyu Chen, Bingchang Liu, Cong Liao, Zi
    Gong, Hang Yu, Jianguo Li, 和 Rui Wang. 2023a. 统一自然语言处理和软件工程的视角：关于代码的语言模型的综述。*arXiv
    preprint arXiv:2311.07989* (2023).
- en: Ziegler et al. (2022) Albert Ziegler, Eirini Kalliamvakou, X Alice Li, Andrew
    Rice, Devon Rifkin, Shawn Simister, Ganesh Sittampalam, and Edward Aftandilian.
    2022. Productivity assessment of neural code completion. In *Proceedings of the
    6th ACM SIGPLAN International Symposium on Machine Programming*. 21–29.
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ziegler et al. (2022) Albert Ziegler, Eirini Kalliamvakou, X Alice Li, Andrew
    Rice, Devon Rifkin, Shawn Simister, Ganesh Sittampalam, 和 Edward Aftandilian.
    2022. 神经代码补全的生产力评估。载于*第六届 ACM SIGPLAN 国际机器编程研讨会论文集*。21–29.
