- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 18:38:43'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:38:43
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive
    Software Release Decision-Making'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GoNoGo：一种高效的基于LLM的多智能体系统，用于简化汽车软件发布决策
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2408.09785](https://ar5iv.labs.arxiv.org/html/2408.09785)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2408.09785](https://ar5iv.labs.arxiv.org/html/2408.09785)
- en: '¹¹institutetext: Chalmers University of Technology, Gothenburg, Sweden ¹¹email:
    {khoee, yinan, robert.feldt}@chalmers.se ²²institutetext: Volvo Group, Gothenburg,
    Sweden ²²email: {andris.freimanis, patrick.andersson, dhasarathy.parthasarathy}@volvo.comArsham
    Gholamzadeh Khoee 1122 [0000-0002-5130-5520](https://orcid.org/0000-0002-5130-5520
    "ORCID identifier")    Yinan Yu 11 [0000-0002-3221-7517](https://orcid.org/0000-0002-3221-7517
    "ORCID identifier")    Robert Feldt 11 [0000-0002-5179-4205](https://orcid.org/0000-0002-5179-4205
    "ORCID identifier")    Andris Freimanis 22    Patrick Andersson 22    Dhasarathy
    Parthasarathy 22 [0000-0002-3620-8589](https://orcid.org/0000-0002-3620-8589 "ORCID
    identifier")'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ¹¹机构文本：瑞典哥德堡查尔默斯理工大学 ¹¹电子邮件：{khoee, yinan, robert.feldt}@chalmers.se ²²机构文本：瑞典哥德堡沃尔沃集团
    ²²电子邮件：{andris.freimanis, patrick.andersson, dhasarathy.parthasarathy}@volvo.com
    Arsham Gholamzadeh Khoee 1122 [0000-0002-5130-5520](https://orcid.org/0000-0002-5130-5520
    "ORCID identifier")    Yinan Yu 11 [0000-0002-3221-7517](https://orcid.org/0000-0002-3221-7517
    "ORCID identifier")    Robert Feldt 11 [0000-0002-5179-4205](https://orcid.org/0000-0002-5179-4205
    "ORCID identifier")    Andris Freimanis 22    Patrick Andersson 22    Dhasarathy
    Parthasarathy 22 [0000-0002-3620-8589](https://orcid.org/0000-0002-3620-8589 "ORCID
    identifier")
- en: Abstract
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Traditional methods for making software deployment decisions in the automotive
    industry typically rely on manual analysis of tabular software test data. These
    methods often lead to higher costs and delays in the software release cycle due
    to their labor-intensive nature. Large Language Models (LLMs) present a promising
    solution to these challenges. However, their application generally demands multiple
    rounds of human-driven prompt engineering, which limits their practical deployment,
    particularly for industrial end-users who need reliable and efficient results.
    In this paper, we propose GoNoGo, an LLM agent system designed to streamline automotive
    software deployment while meeting both functional requirements and practical industrial
    constraints. Unlike previous systems, GoNoGo is specifically tailored to address
    domain-specific and risk-sensitive systems. We evaluate GoNoGo’s performance across
    different task difficulties using zero-shot and few-shot examples taken from industrial
    practice. Our results show that GoNoGo achieves a 100% success rate for tasks
    up to Level 2 difficulty with 3-shot examples, and maintains high performance
    even for more complex tasks. We find that GoNoGo effectively automates decision-making
    for simpler tasks, significantly reducing the need for manual intervention. In
    summary, GoNoGo represents an efficient and user-friendly LLM-based solution currently
    employed in our industrial partner’s company to assist with software release decision-making,
    supporting more informed and timely decisions in the release process for risk-sensitive
    vehicle systems.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在汽车行业中，传统的软件部署决策方法通常依赖于对表格软件测试数据的人工分析。这些方法由于其劳动密集型的性质，往往导致更高的成本和软件发布周期的延迟。大型语言模型（LLMs）为这些挑战提供了有前景的解决方案。然而，它们的应用通常需要多轮人工驱动的提示工程，这限制了它们的实际部署，特别是对于需要可靠和高效结果的工业终端用户。在本文中，我们提出了GoNoGo，一种旨在简化汽车软件部署的LLM代理系统，同时满足功能要求和实际工业约束。与之前的系统不同，GoNoGo特别针对特定领域和风险敏感系统进行了量身定制。我们使用从工业实践中提取的零样本和少样本示例评估了GoNoGo在不同任务难度下的性能。我们的结果表明，GoNoGo在3-shot示例下对难度高达2级的任务实现了100%的成功率，并且在更复杂的任务中仍保持高性能。我们发现，GoNoGo有效地自动化了简单任务的决策过程，显著减少了人工干预的需求。总之，GoNoGo代表了一种高效且用户友好的基于LLM的解决方案，目前在我们的工业合作伙伴公司中被用来辅助软件发布决策，支持在风险敏感的车辆系统发布过程中做出更为明智和及时的决策。
- en: 'Keywords:'
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: LLMs LLM-based Multi-agent Software Release Assistant Table Analysis Automation
    Risk-Sensitive Systems.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 基于LLM的多智能体软件发布助手 表格分析 自动化 风险敏感系统。
- en: 1 Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: In the automotive industry, decisions about when to release software, particularly
    embedded software in risk-sensitive systems, carry immense weight. The complexity
    of modern vehicles, with their multiple levels of integration, further complicates
    this process. Each integration level involves one or more gating steps, with tests
    conducted to verify whether gate criteria are fulfilled. Gate failures can delay
    the integration of all dependent subsystems, regardless of their individual quality.
    In this intricate process, release managers, bearing the responsibility of gatekeeping
    could greatly benefit from assistance to make faster and better decisions.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在汽车行业中，决定何时发布软件，特别是在风险敏感系统中的嵌入式软件，具有极大的重要性。现代车辆的复杂性及其多个集成层进一步复杂化了这一过程。每个集成层涉及一个或多个关卡步骤，通过测试验证是否满足关卡标准。关卡失败可能会延迟所有依赖子系统的集成，无论它们的个体质量如何。在这个复杂的过程中，发布经理肩负着关卡管理的责任，能够得到帮助以做出更快、更好的决策将大有裨益。
- en: '![Refer to caption](img/ed0db18962c2463b9946fdf59e335559.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/ed0db18962c2463b9946fdf59e335559.png)'
- en: 'Figure 1: An actual example demonstrating the use of the LLM-based multi-agent
    system for automating ad-hoc tabular data analysis.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：展示使用基于LLM的多代理系统进行临时表格数据分析的实际示例。
- en: Large language models (LLMs) present an interesting avenue for providing such
    assistance. In particular, LLMs have demonstrated strong capabilities in zero-
    and few-shot settings with in-context learning [[5](#bib.bib5)]. Recent advancements
    have improved reasoning [[31](#bib.bib31)], exemplar selection, and prompt design [[7](#bib.bib7)].
    Companies now use LLMs for software engineering tasks like API testing, code generation,
    and documentation and research studies have already shown test automation improvements
    over the state-of-the-art [[27](#bib.bib27)].
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）为提供此类辅助功能呈现了一个有趣的途径。特别是，LLMs在零样本和少样本设置下通过上下文学习展现了强大的能力[[5](#bib.bib5)]。最近的进展改善了推理[[31](#bib.bib31)]、示例选择和提示设计[[7](#bib.bib7)]。现在，公司们已经开始使用LLMs进行软件工程任务，例如API测试、代码生成和文档编写，研究也已经显示出测试自动化在最先进技术上的改进[[27](#bib.bib27)]。
- en: However, when applying LLMs to *risk-sensitive* *domain-specific* tasks, several
    unique challenges must be addressed. In our research with industrial partners,
    the most prominent challenges include 1) Incorporating specific logic and terminology
    relevant to the domain; 2) Understanding and parsing high-level queries or vague
    language used by non-expert stakeholders and translating them into actionable
    plans, 3) Enabling interpretability so that domain experts can explain system
    functionality to stakeholders without excessive complexity, 4) Operating efficiently
    to meet the time-critical demands of organizational applications, mitigating potential
    bottlenecks related to limited LLM licensing or infrastructure, and 5) Designing
    the system to enable ease of troubleshooting and maintenance, ensuring that any
    issues can be quickly identified and resolved.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在将LLMs应用于*风险敏感*的*领域特定*任务时，必须解决一些独特的挑战。在我们与工业合作伙伴的研究中，最突出的挑战包括：1) 融入与领域相关的特定逻辑和术语；2)
    理解和解析非专家利益相关者使用的高级查询或模糊语言，并将其转化为可操作的计划；3) 实现可解释性，使领域专家能够向利益相关者解释系统功能而不增加过多复杂性；4)
    高效操作，以满足组织应用的时间紧迫要求，减轻与有限LLM许可或基础设施相关的潜在瓶颈；5) 设计系统以便于故障排除和维护，确保任何问题都能被快速识别和解决。
- en: 'To address these challenges, we propose an multi-agent system that encodes
    domain-specific requirements using in-context learning. This system comprises
    two primary LLM agents: a Planner and an Actor (refer to Figure [2](#S3.F2 "Figure
    2 ‣ 3.2 System Architecture ‣ 3 GoNoGo: Intelligent Software Release Assistant
    ‣ GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive
    Software Release Decision-Making")). The Planner, which forms the core of the
    system, comprehends and decomposes user queries into step-by-step instructions
    for data analysis [[14](#bib.bib14)]. The Actor then synthesizes and generates
    executable scripts from these higher-level instructions. Within the Actor, a coder
    LLM utilizes the self-reflection mechanism besides a memory to produce the most
    effective Python script optimized for querying the given data for each instruction
    generated by the Planner [[1](#bib.bib1), [27](#bib.bib27)].'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '为了应对这些挑战，我们提出了一种使用上下文学习编码领域特定需求的多智能体系统。该系统包括两个主要的LLM智能体：规划者和执行者（参见图 [2](#S3.F2
    "Figure 2 ‣ 3.2 System Architecture ‣ 3 GoNoGo: Intelligent Software Release Assistant
    ‣ GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive
    Software Release Decision-Making")）。规划者是系统的核心，它理解并将用户查询分解为逐步的数据分析指令 [[14](#bib.bib14)]。执行者则从这些高层指令中合成并生成可执行的脚本。在执行者内部，编码器LLM利用自我反思机制和记忆生成最有效的Python脚本，以优化对规划者生成的每个指令的查询 [[1](#bib.bib1),
    [27](#bib.bib27)]。'
- en: 'This system provides an interface for end-users at our industrial partner,
    illustrated by Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ GoNoGo: An Efficient
    LLM-based Multi-Agent System for Streamlining Automotive Software Release Decision-Making"),
    which shows an actual, real-world example of its use. It allows end-users like
    release managers to interpret results from a business and safety perspective without
    needing detailed technical knowledge. This approach can significantly reduce time
    and resources by eliminating the need for various database and programming experts
    to achieve the desired results for end-users. Our agent automates test data analysis
    across multiple vehicle development integration levels, providing detailed reports
    on component functionality and system interactions. This assists release managers
    in making informed decisions about software readiness for release, accelerating
    development while enhancing gatekeeping reliability. Our contributions can be
    summarized as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '该系统为我们工业合作伙伴的最终用户提供了一个界面，如图 [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ GoNoGo:
    An Efficient LLM-based Multi-Agent System for Streamlining Automotive Software
    Release Decision-Making") 所示，展示了其实际应用的例子。它允许像发布经理这样的最终用户从业务和安全角度解释结果，而无需详细的技术知识。这种方法可以通过消除对各种数据库和编程专家的需求显著减少时间和资源，以实现最终用户所需的结果。我们的智能体自动化分析多个车辆开发集成水平的测试数据，提供关于组件功能和系统交互的详细报告。这有助于发布经理做出关于软件发布准备情况的明智决策，加快开发进程，同时提高门控的可靠性。我们的贡献可以总结如下：'
- en: '{outline}\1'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '{outline}\1'
- en: 'We highlight the practicality of the proposed LLM-based intelligent assistant
    in making software release decisions within the automotive industry. This is achieved
    by enhancing two key capabilities: \2 Domain-specificity: We design a framework
    to handle unstructured queries from non-expert stakeholders in the automotive
    industry by mapping generic language to domain-specific logic using in-context
    learning. \2 Risk-Sensitivity: We incorporate two predefined atomic operations
    to restrict the action space and improve the risk-sensitive aspect of the planner.
    \1 Experiments on a total of 50 crafted test queries show that our proposed system
    is effective at analyzing data and deriving the required insights for software
    release decision-making. \1 Our system, now deployed and actively used within
    our industrial partner’s company, has demonstrated significant improvements in
    the software release decision-making process besides saving time, improving accessibility,
    reducing reliance on specialized analysts, and accelerating overall workflow.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们强调了所提出的基于LLM的智能助手在汽车行业软件发布决策中的实际应用。这是通过增强两个关键能力实现的：\2 行业特定性：我们设计了一个框架，通过使用上下文学习将通用语言映射到行业特定逻辑，从而处理汽车行业非专家利益相关者的非结构化查询。
    \2 风险敏感性：我们引入了两个预定义的原子操作以限制行动空间，提高规划者的风险敏感性。 \1 对总共50个精心设计的测试查询的实验表明，我们提出的系统在数据分析和提供所需的洞察方面是有效的。
    \1 我们的系统现在已经部署并在我们工业合作伙伴的公司中积极使用，除了节省时间、提高可及性、减少对专业分析师的依赖以及加快整体工作流程外，还在软件发布决策过程中展示了显著改进。
- en: 'The remainder of this paper is structured as follows: Section [2](#S2 "2 Manual
    Process of Release Decisions: Insights From the Industry ‣ GoNoGo: An Efficient
    LLM-based Multi-Agent System for Streamlining Automotive Software Release Decision-Making")
    provides an overview of the manual process behind automotive software release
    decisions and the need for streamlining operations. Section [3](#S3 "3 GoNoGo:
    Intelligent Software Release Assistant ‣ GoNoGo: An Efficient LLM-based Multi-Agent
    System for Streamlining Automotive Software Release Decision-Making") details
    our approach, including a description of the architecture of our LLM-based multi-agent
    system and an explanation of the Planner and Actor agents. Furthermore, in Section
    [4](#S4 "4 Experiments ‣ GoNoGo: An Efficient LLM-based Multi-Agent System for
    Streamlining Automotive Software Release Decision-Making"), we present our experimental
    setup and results. Section [5](#S5 "5 Related Work ‣ GoNoGo: An Efficient LLM-based
    Multi-Agent System for Streamlining Automotive Software Release Decision-Making")
    provides an overview of similar research in LLMs for data analysis. Finally, Section
    [6](#S6 "6 Conclusion ‣ GoNoGo: An Efficient LLM-based Multi-Agent System for
    Streamlining Automotive Software Release Decision-Making") concludes the paper
    by summarizing key findings and discussing the broader implications of our work
    in the context of industrial software release management and risk-sensitive systems.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '本文的其余部分结构如下：第[2](#S2 "2 Manual Process of Release Decisions: Insights From
    the Industry ‣ GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining
    Automotive Software Release Decision-Making")节概述了汽车软件发布决策背后的手动过程及其对优化操作的需求。第[3](#S3
    "3 GoNoGo: Intelligent Software Release Assistant ‣ GoNoGo: An Efficient LLM-based
    Multi-Agent System for Streamlining Automotive Software Release Decision-Making")节详细介绍了我们的方法，包括我们基于LLM的多智能体系统的架构描述以及Planner和Actor代理的解释。此外，在第[4](#S4
    "4 Experiments ‣ GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining
    Automotive Software Release Decision-Making")节中，我们介绍了实验设置和结果。第[5](#S5 "5 Related
    Work ‣ GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive
    Software Release Decision-Making")节概述了在LLMs用于数据分析方面的相关研究。最后，第[6](#S6 "6 Conclusion
    ‣ GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive
    Software Release Decision-Making")节总结了关键发现，并讨论了我们工作在工业软件发布管理和风险敏感系统中的更广泛意义。'
- en: '2 Manual Process of Release Decisions: Insights From the Industry'
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 手动发布决策过程：行业洞察
- en: Deciding to go ahead, or not, with a software release in the automotive industry
    is a complex task involving multiple stakeholders and extensive data analysis.
    This section reviews the current, and typical of the industry at large, manual
    workflow and the need for streamlining.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在汽车行业决定是否进行软件发布是一个复杂的任务，涉及多个利益相关者和广泛的数据分析。本节回顾了当前以及整个行业典型的手动工作流程及其对优化的需求。
- en: Vehicle development progresses through multiple phases, each becoming more complex
    as more components are integrated. Numerous tests are conducted at each stage
    to ensure functionality and identify revisions, generating vast amounts of data.
    Software components require repeated testing and validation, adding to this data.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 车辆开发经历多个阶段，每个阶段随着更多组件的集成而变得越来越复杂。在每个阶段进行大量测试以确保功能和识别修订，生成大量数据。软件组件需要反复测试和验证，增加了这些数据的量。
- en: Project managers, verification engineers, and quality engineers need clear analytics
    and insights from these tests in order to make software release decisions. Extracting
    essential information is time-consuming. Quality engineers analyze data for continuous
    improvement, while release engineers need specific information to make informed
    release decisions.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 项目经理、验证工程师和质量工程师需要从这些测试中获得清晰的分析和见解，以便做出软件发布决策。提取关键信息是耗时的。质量工程师分析数据以实现持续改进，而发布工程师则需要具体的信息来做出明智的发布决策。
- en: Within this process, statisticians provide an overall view of the data to project
    managers and quality engineers for future business decisions. Manual data processing
    is necessary due to the critical nature of these decisions and their impact on
    consumer safety. However, this approach is time-consuming and prone to errors,
    partly due to the differing perspectives of technical data analyzers and statisticians,
    who may not fully understand the project managers’ goals.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一过程中，统计学家向项目经理和质量工程师提供数据的总体视图，以便为未来的商业决策提供支持。由于这些决策的关键性质及其对消费者安全的影响，需要进行手动数据处理。然而，这种方法既耗时又容易出错，部分原因在于技术数据分析师和统计学家对项目经理目标的不同理解。
- en: A critical and typical stage in this process is “Testing on Closed Track,” where
    vehicles equipped with the necessary software release undergo systematic and rigorous
    testing of their systems in a controlled environment. After these tests, release
    managers analyze large amounts of data to decide whether to move to the next test
    stage. This involves manually querying data to generate reports that support informed
    decisions. Errors or delays in this analysis can hinder timely software release,
    affect business goals, and delay subsystem integration.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这一过程中的一个关键且典型的阶段是“封闭赛道测试”，在这一阶段，配备了必要软件的车辆在受控环境中接受系统的系统化和严格的测试。测试后，发布经理分析大量数据，以决定是否进入下一测试阶段。这涉及手动查询数据以生成支持明智决策的报告。分析中的错误或延迟可能会阻碍软件的及时发布，影响业务目标，并延迟子系统的集成。
- en: The deployment of an intelligent assistant has the potential to facilitate software
    release decisions in the automotive industry [[19](#bib.bib19)], particularly
    during the critical testing on a closed track phase. In this work, we have focused
    on designing such an LLM-based multi-agent system to address the challenges of
    this specific stage. By rapidly processing test data from closed track testing,
    the system can generate comprehensive reports tailored to different stakeholders’
    needs. For example, it can quickly compile summaries of failed tests, highlight
    software performance trends across vehicle models, or analyze a specific component’s
    behavior under various conditions. Consequently, this reduces the time spent on
    initial analysis, allowing release managers to focus on interpreting results and
    making informed decisions. This not only accelerates the development process but
    also enhances the accuracy and reliability of the information used in release
    decisions, ultimately contributing to maintaining high safety and quality standards
    in automotive software development.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 部署智能助手有可能在汽车行业中促进软件发布决策，特别是在封闭赛道阶段的关键测试期间。在这项工作中，我们专注于设计这样一个基于LLM的多智能体系统，以应对这一特定阶段的挑战。通过快速处理封闭赛道测试的数据，该系统能够生成针对不同利益相关者需求的综合报告。例如，它可以快速编制失败测试的摘要，突出不同车辆模型的软件性能趋势，或分析特定组件在各种条件下的行为。因此，这减少了初步分析的时间，使发布经理能够专注于解释结果并做出明智的决策。这不仅加快了开发过程，还提高了发布决策中使用信息的准确性和可靠性，最终有助于保持汽车软件开发中的高安全性和质量标准。
- en: '3 GoNoGo: Intelligent Software Release Assistant'
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 GoNoGo：智能软件发布助手
- en: 3.1 System Requirements
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 系统需求
- en: 'After discussing current needs and opinions about the software release analysis
    and decision-making processes with our industrial partner, we identified the following
    main challenges in automating data analysis:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在与我们的工业合作伙伴讨论软件发布分析和决策过程的当前需求和意见后，我们确定了自动化数据分析中的以下主要挑战：
- en: Understanding User Queries
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 理解用户查询
- en: The system must interpret queries, typically presented in natural language,
    within the specific domain context, using any provided domain-specific knowledge.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 系统必须在特定领域上下文中解释查询，通常是自然语言形式的，利用任何提供的领域特定知识。
- en: Translating User Queries to Actionable Steps
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 将用户查询转换为可操作的步骤
- en: The system needs to convert the user’s query into concrete steps, breaking down
    complex queries into simpler tasks, determining the order of operations, and selecting
    appropriate data manipulation or analysis techniques. Additionally, the action
    space must be carefully managed to adhere to risk-sensitive requirements.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 系统需要将用户的查询转换为具体步骤，将复杂查询分解为更简单的任务，确定操作顺序，并选择适当的数据处理或分析技术。此外，行动空间必须仔细管理，以符合风险敏感的要求。
- en: Execution and Result Preparation
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 执行和结果准备
- en: The system must execute the planned actions, interact with data using scripts
    (e.g., querying databases, performing calculations, applying filters), and compile
    the results into the desired format for the user.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 系统必须执行计划的操作，使用脚本与数据交互（例如，查询数据库、执行计算、应用过滤器），并将结果编译为用户所需的格式。
- en: These steps rely heavily on the LLM’s domain-specific knowledge and reasoning
    ability, crucial for effective query instruction planning [[17](#bib.bib17)].
    Consequently, this work explores techniques for enhancing the reasoning capabilities
    of LLM agent systems, particularly for the analysis of tabular data in industrial
    contexts.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤严重依赖于LLM的领域特定知识和推理能力，这对有效的查询指令规划至关重要[[17](#bib.bib17)]。因此，本研究探索了提高LLM代理系统推理能力的技术，特别是在工业背景下的表格数据分析中。
- en: 3.2 System Architecture
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 系统架构
- en: 'Our approach to automating tabular data analysis leverages LLMs to create an
    intelligent system capable of interpreting natural language queries, executing
    complex analyses, and delivering desired results. The system architecture consists
    of two main components: the Planner supported by a Knowledge Base and Examples
    for few-shot learning and the Actor including coder LLM, memory module, and some
    Plugin components. Figure [2](#S3.F2 "Figure 2 ‣ 3.2 System Architecture ‣ 3 GoNoGo:
    Intelligent Software Release Assistant ‣ GoNoGo: An Efficient LLM-based Multi-Agent
    System for Streamlining Automotive Software Release Decision-Making") illustrates
    the overall architecture of the developed system.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '我们的自动化表格数据分析方法利用LLMs创建了一个智能系统，能够解释自然语言查询，执行复杂分析，并提供所需结果。系统架构包括两个主要组件：由知识库和用于少量示例学习的示例支持的Planner，以及包括编码LLM、记忆模块和一些插件组件的Actor。图
    [2](#S3.F2 "Figure 2 ‣ 3.2 System Architecture ‣ 3 GoNoGo: Intelligent Software
    Release Assistant ‣ GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining
    Automotive Software Release Decision-Making") 说明了开发系统的整体架构。'
- en: '![Refer to caption](img/06df92d6a750793c854bc49fce7e1068.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/06df92d6a750793c854bc49fce7e1068.png)'
- en: 'Figure 2: Architecture of the LLM-based multi-agent system GoNoGo along with
    the illustration of the interaction procedure of the system. GoNoGo receives high-level
    queries from the end user, performs the required data manipulations, and outputs
    the result table as a decision support resource. GoNoGo comprises a Planner agent,
    which interprets queries and devises analysis strategies using Chain-of-Thought
    prompting and self-consistency, supported by a *Knowledge Base* and *Examples*
    for few-shot learning. The Actor includes a Coder LLM with a *Self-reflection*
    mechanism, utilizing *Memory* and *Plugins* for code generation and error resolution.
    The total running time of GoNoGo for one user query is approximately 120 seconds,
    which satisfies typical user requirements.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：LLM-based多代理系统GoNoGo的架构图，以及系统交互过程的说明。GoNoGo接收来自终端用户的高层次查询，执行所需的数据操作，并将结果表输出作为决策支持资源。GoNoGo包含一个Planner代理，该代理使用Chain-of-Thought提示和自我一致性来解释查询和制定分析策略，支持的*知识库*和*示例*用于少量示例学习。Actor包括一个具有*自我反思*机制的Coder
    LLM，利用*记忆*和*插件*进行代码生成和错误解决。GoNoGo处理一个用户查询的总运行时间约为120秒，满足典型用户需求。
- en: 3.2.1 Planner
  id: totrans-43
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 Planner
- en: The Planner is the core of our system, responsible for interpreting user queries
    and devising appropriate analysis strategies. One of the core challenges of designing
    an LLM-based multi-agent system is the inherent inaccuracy of prompting. As decision-making
    becomes more distributed over multiple LLM agents, the uncertainty within the
    multi-agent system increases. To mitigate this, we centralize the complexity within
    the Planner, which is responsible for the majority of design choices. By focusing
    on the Planner as the main agent for refinement, we aim to create a system that
    is both interpretable and easily maintainable.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 规划器是我们系统的核心，负责解释用户查询并制定合适的分析策略。设计基于 LLM 的多代理系统的核心挑战之一是提示的固有不准确性。随着决策在多个 LLM
    代理之间分布，不确定性在多代理系统中增加。为了缓解这一问题，我们将复杂性集中在规划器中，规划器负责大多数设计选择。通过将规划器作为主要的精炼代理，我们旨在创建一个既可解释又易于维护的系统。
- en: 'Our problem consists of two main aspects: domain-specificity and risk-sensitivity.
    These two characteristics frequently manifest together in real-world applications,
    particularly in fields such as healthcare and automotive, where unreliability
    and inaccuracies can have significant consequences. However, there is a noticeable
    gap in addressing both aspects simultaneously, let alone demonstrating such systems
    in practice. As part of our system, we want to explicitly address both of these
    aspects. As the Planner is the component with the most decision-making responsibility,
    these two requirements are encoded into the Planner prompts as depicted in Figure [3](#S3.F3
    "Figure 3 ‣ 3.2.1 Planner ‣ 3.2 System Architecture ‣ 3 GoNoGo: Intelligent Software
    Release Assistant ‣ GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining
    Automotive Software Release Decision-Making").'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '我们的问题包括两个主要方面：领域特异性和风险敏感性。这两种特性在现实应用中经常一起出现，特别是在医疗和汽车等领域，其中不可靠性和不准确性可能带来重大后果。然而，现有的解决方案在同时解决这两个方面上存在明显的差距，更不用说在实际中展示这些系统。作为我们系统的一部分，我们希望明确解决这两个方面。由于规划器是负责最多决策的组件，这两个需求被编码到规划器提示中，如图
    [3](#S3.F3 "Figure 3 ‣ 3.2.1 Planner ‣ 3.2 System Architecture ‣ 3 GoNoGo: Intelligent
    Software Release Assistant ‣ GoNoGo: An Efficient LLM-based Multi-Agent System
    for Streamlining Automotive Software Release Decision-Making") 所示。'
- en: '![Refer to caption](img/a2f032c16e5aff7cd7bfbf110bd0c1a6.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/a2f032c16e5aff7cd7bfbf110bd0c1a6.png)'
- en: 'Figure 3: Planner prompting strategies addressing domain-specificity and risk-sensitivity
    in the LLM-based agent system for tabular data analysis.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：规划器提示策略，解决基于 LLM 的代理系统在表格数据分析中的领域特异性和风险敏感性问题。
- en: 3.2.2 Domain-Specificity
  id: totrans-48
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2 领域特异性
- en: The Planner utilizes a Knowledge Base containing a structured description of
    the data and its attributes to provide the necessary context and domain-specific
    information in the prompts given to the LLM to enhance the system’s performance
    and applicability [[15](#bib.bib15)]. The Planner interacts directly with the
    Knowledge Base to accurately interpret user queries and devise appropriate analysis
    plans. This integration ensures that the entire pipeline, from query interpretation
    to result generation, is informed by relevant domain knowledge, enabling our LLM
    agent to provide more accurate, relevant, and specialized responses to user queries.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 规划器利用包含数据及其属性的结构化描述的知识库，在给 LLM 的提示中提供必要的上下文和领域特定信息，从而提升系统的性能和适用性[[15](#bib.bib15)]。规划器直接与知识库交互，以准确解释用户查询并制定合适的分析计划。这种集成确保了从查询解释到结果生成的整个流程都受相关领域知识的指导，使我们的
    LLM 代理能够对用户查询提供更准确、相关和专业的回应。
- en: In our system architecture, we also feed some input-output pairs as examples
    into the Planner, allowing few-shot learning alongside the Knowledge Base. This
    combination enables the Planner to interpret user queries more effectively, drawing
    on both general knowledge and specific task examples to formulate appropriate
    analysis plans. This approach makes the system a powerful tool for automated tabular
    data analysis across various industries and use cases.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的系统架构中，我们还将一些输入输出对作为示例输入到规划器中，从而在知识库的基础上进行少量学习。这种结合使规划器能够更有效地解释用户查询，借助通用知识和具体任务示例来制定合适的分析计划。这种方法使系统成为一个强大的工具，适用于各种行业和应用场景的自动化表格数据分析。
- en: Helpful prompts serve as constraints, enhancing the LLM’s reasoning capabilities [[13](#bib.bib13)].
    For example, constraints help the model understand that queries should account
    for more than just binary states for some fields. Retrieving records with ’A’
    and its opposite doesn’t always mean retrieving all records, as other non-binary
    states might exist. For instance, ’successful’ and ’failed’ tests don’t encompass
    all possible test statuses; there may be additional statuses to consider, such
    as ’N/A’, that the model should take into account.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 有用的提示作为约束，增强了大型语言模型（LLM）的推理能力[[13](#bib.bib13)]。例如，约束帮助模型理解某些字段的查询不仅仅应考虑二元状态。检索包含'A'及其对立项的记录并不总意味着检索所有记录，因为可能存在其他非二元状态。例如，'成功'和'失败'的测试并不涵盖所有可能的测试状态；可能还存在其他状态需要考虑，例如'N/A'，模型应当予以考虑。
- en: The focus is on pushing the model to generate an optimized query plan. This
    involves narrowing down data through filtering and selection before performing
    sorting and other operations on the reduced dataset to minimize processing. Accordingly,
    designed constraints help the agent explore the characteristics of each field
    and the data, providing more accurate planning.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 重点在于推动模型生成优化的查询计划。这涉及在对减少的数据集进行排序和其他操作之前，通过过滤和选择来缩小数据范围，以最小化处理量。因此，设计的约束帮助代理探索每个字段和数据的特征，提供更准确的规划。
- en: 3.2.3 Risk-Sensitivity
  id: totrans-53
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.3 风险敏感性
- en: 'We guide the Planner with two pre-defined atomic actions to limit the action
    space of the planner: slicing and operation. Slicing involves specifying the columns
    to select and the conditions for filtering rows from the data to be analyzed. Operation involves
    describing the operations (such as max, mean, count, etc.) to be performed on
    the values of one or more columns of the data obtained from the slicing step.
    The steps should be returned as a Python list, with each step described in natural
    language, including all relevant values and column names.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过两个预定义的原子操作来指导规划器，以限制规划器的操作空间：切片和操作。*切片*涉及指定要选择的列和过滤数据行的条件。*操作*涉及描述在从切片步骤获得的数据的一列或多列上执行的操作（如最大值、均值、计数等）。步骤应以Python列表的形式返回，每个步骤用自然语言描述，包括所有相关的值和列名。
- en: Also, we leverage Chain-of-Thought (CoT) prompting to further enhance the reasoning
    capabilities of our LLM-based agent [[22](#bib.bib22)]. This technique incorporates
    intermediate reasoning steps into the prompt, guiding the model to break down
    complex problems into smaller, more manageable steps [[32](#bib.bib32)]. This
    approach mimics human-like reasoning and problem-solving processes. Additionally,
    CoT prompting makes the agent’s decision-making process more transparent by explicitly
    showing the reasoning steps, allowing users to understand how the agent arrived
    at a particular conclusion or analysis result.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们利用链式思维（CoT）提示进一步增强我们基于LLM的代理的推理能力[[22](#bib.bib22)]。该技术将中间推理步骤纳入提示中，引导模型将复杂问题分解成更小、更易管理的步骤[[32](#bib.bib32)]。这种方法模拟了类似人类的推理和解决问题的过程。此外，CoT提示通过明确显示推理步骤，使代理的决策过程更加透明，让用户理解代理是如何得出特定结论或分析结果的。
- en: We combine CoT prompting with few-shot learning by providing examples that not
    only show input-output pairs but also include the intermediate reasoning steps.
    This synergy further enhances the agent’s ability to handle diverse and complex
    data analysis tasks [[10](#bib.bib10)].
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过提供不仅展示输入-输出对而且包括中间推理步骤的示例，将CoT提示与少量学习结合。这种协同作用进一步增强了代理处理多样且复杂的数据分析任务的能力[[10](#bib.bib10)]。
- en: To further improve reasoning, we employ self-consistency in conjunction with
    CoT prompting. This involves generating multiple independent reasoning paths for
    the same query, comparing them for consistency, and using majority voting to determine
    the most reliable outcome [[21](#bib.bib21)]. By considering multiple reasoning
    paths, the system becomes less likely to be misled by a single flawed chain of
    thought. As a result, for queries with potential ambiguity, self-consistency can
    help identify different valid interpretations and provide a more comprehensive
    answer.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步提高推理能力，我们结合了自一致性与链式思维（CoT）提示。这涉及为同一查询生成多个独立的推理路径，比较它们的一致性，并使用多数投票来确定最可靠的结果[[21](#bib.bib21)]。通过考虑多个推理路径，系统不容易被单一的有缺陷的思维链误导。因此，对于具有潜在歧义的查询，自一致性可以帮助识别不同的有效解释，并提供更全面的答案。
- en: 3.2.4 Actor
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.4 演员
- en: 'The Actor is responsible for carrying out the analysis plans devised by the
    Planner. It consists of several interacting components: Coder LLM with Self-reflection,
    Memory, and Plugins, as depicted in Figure [2](#S3.F2 "Figure 2 ‣ 3.2 System Architecture
    ‣ 3 GoNoGo: Intelligent Software Release Assistant ‣ GoNoGo: An Efficient LLM-based
    Multi-Agent System for Streamlining Automotive Software Release Decision-Making").'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 'Actor负责执行由Planner制定的分析计划。它包括几个互相作用的组件：具有自我反思机制的**Coder LLM**、Memory和Plugins，如图[2](#S3.F2
    "Figure 2 ‣ 3.2 System Architecture ‣ 3 GoNoGo: Intelligent Software Release Assistant
    ‣ GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive
    Software Release Decision-Making")所示。'
- en: The Coder LLM is responsible for generating executable scripts based on the
    Planner’s instructions. This component is crucial as it translates abstract plans
    into concrete, executable code that can interact with the data using the required
    Plugins and perform the necessary analysis. It includes a Self-reflection mechanism,
    which works in tandem with a Memory module. This Memory stores generated code,
    error messages, execution results, and contextual information about the current
    task [[8](#bib.bib8)].
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**Coder LLM**负责根据Planner的指示生成可执行脚本。这个组件至关重要，因为它将抽象的计划转换为具体的、可执行的代码，能够利用所需的Plugins与数据进行交互并执行必要的分析。它包括一个自我反思机制，与Memory模块协同工作。这个Memory存储生成的代码、错误信息、执行结果和当前任务的上下文信息[[8](#bib.bib8)]。'
- en: The Self-reflection mechanism is a sophisticated process that allows the Coder
    LLM to critically analyze its own output and decision-making process. When an
    error occurs during script execution, the Self-reflection mechanism activates,
    providing feedback to the Coder LLM. This feedback loop enables the LLM to analyze
    error messages within the task context [[11](#bib.bib11), [27](#bib.bib27)], facilitating
    iterative improvement of the generated code.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 自我反思机制是一个复杂的过程，它使得**Coder LLM**能够批判性地分析自身的输出和决策过程。当脚本执行中发生错误时，自我反思机制会被激活，为**Coder
    LLM**提供反馈。这个反馈循环使得LLM能够在任务背景中分析错误信息[[11](#bib.bib11), [27](#bib.bib27)]，从而促进生成代码的迭代改进。
- en: 'The Self-reflection mechanism offers several advantages: It enables the Coder
    LLM to autonomously identify and correct errors by continuously analyzing and
    reflecting on its own output, thereby reducing the need for external debugging
    and intervention. This mechanism promotes a cycle of continuous improvement, allowing
    each iteration to refine the scripts for progressively better performance and
    reliability [[24](#bib.bib24)]. By utilizing the Memory module, the Coder LLM
    can make context-aware adjustments, considering previous errors, execution results,
    and specific task requirements, which leads to more precise and contextually appropriate
    code generation. Automated error correction and iterative refinement result in
    a more efficient coding process, speeding up the development cycle and enhancing
    the robustness and reliability of the final scripts. Additionally, the self-reflective
    capabilities minimize the need for human intervention in the debugging process,
    enabling engineers to focus on more complex and high-level tasks.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 自我反思机制提供了几个优势：它使**Coder LLM**能够通过持续分析和反思自身输出，自动识别和修正错误，从而减少了外部调试和干预的需求。该机制促进了持续改进的循环，使每次迭代都能提升脚本的性能和可靠性[[24](#bib.bib24)]。通过利用Memory模块，**Coder
    LLM**能够进行上下文感知的调整，考虑到之前的错误、执行结果和特定的任务要求，从而生成更精确、上下文更适当的代码。自动化错误修正和迭代改进使得编码过程更为高效，加速了开发周期，提高了最终脚本的健壮性和可靠性。此外，自我反思能力最小化了调试过程中对人工干预的需求，使工程师能够专注于更复杂和高级的任务。
- en: This architecture enables the Actor to not only generate code for data analysis
    tasks but also to troubleshoot and improve its own output, resulting in a more
    robust and reliable automated data analysis system.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这种架构不仅使得Actor能够生成数据分析任务的代码，还能够排除故障并改进自身的输出，从而形成一个更强大、更可靠的自动化数据分析系统。
- en: 3.3 System Implementation
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 系统实现
- en: The system uses Azure OpenAI’s GPT-3.5 Turbo for both the Planner and Actor
    agents. The Planner utilizes specially designed prompts for task planning, defining
    the entire data analysis task by specifying the details of each step in the plan.
    Moreover, the Actor uses predefined prompts to generate the required Python code
    for executing each step of the provided plan with the pandas library, performing
    tasks on the given data.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 系统使用Azure OpenAI的GPT-3.5 Turbo作为Planner和Actor代理。Planner利用特别设计的提示进行任务规划，通过指定计划中每个步骤的详细信息来定义整个数据分析任务。此外，Actor使用预定义的提示生成执行计划每一步所需的Python代码，使用pandas库在给定的数据上执行任务。
- en: 4 Experiments
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实验
- en: 4.1 Data
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 数据
- en: The data used for analysis at our industrial partner is called “GoNoGo” data
    and is updated after testing each function of every software component in each
    vehicle. This internal company data contains about 40 different fields and is
    critical for release decisions, as it includes detailed information regarding
    the performance and functionality of software components. It provides the necessary
    information for determining whether to advance a vehicle to the next phase of
    development and allow it to be driven on open roads. Although the data is updated
    after each test, we used a dataset of 55,000 records to report our experiments.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们工业合作伙伴用于分析的数据称为“GoNoGo”数据，并在每次测试每个车辆中每个软件组件的功能后进行更新。这些内部公司数据包含约40个不同的字段，对于发布决策至关重要，因为它包括有关软件组件性能和功能的详细信息。它提供了决定是否将车辆推进到开发的下一阶段并允许其在开放道路上行驶所需的信息。尽管数据在每次测试后都会更新，我们使用了55,000条记录的数据集来报告我们的实验。
- en: Stakeholders often ask questions like “What are the test case functions that
    fail the most for release candidate X?” or “What is the Y-status of X?” where
    X is the release candidate’s name and Y is a specific functionality. Answering
    these questions requires domain knowledge and an understanding of the data to
    extract and communicate the answers accurately. By analyzing this data, release
    managers can determine if a vehicle meets the necessary criteria to progress to
    the next development phase or be driven on public roads. This ensures that only
    vehicles that meet stringent safety and quality standards are advanced, maintaining
    high standards in automotive software development.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 利益相关者经常提出类似“释放候选X的测试用例功能中失败最多的是哪些？”或“X的Y状态是什么？”的问题，其中X是释放候选的名称，Y是特定功能。回答这些问题需要领域知识和对数据的理解，以准确提取和传达答案。通过分析这些数据，发布经理可以确定车辆是否符合进阶到下一开发阶段或在公共道路上行驶的必要标准。这确保只有符合严格安全和质量标准的车辆才会被推进，从而在汽车软件开发中保持高标准。
- en: 4.2 Benchmark Overview
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 基准概述
- en: To evaluate the GoNoGo system’s performance, we developed a benchmark based
    on 15 initial analysis tasks, which were defined with the help of release engineers.
    These tasks were translated into explicit table analysis queries that GoNoGo could
    process. We created definitive ground-truth solutions for these queries using
    Python, breaking down the solutions into smaller code chunks representing operations
    such as filtering, grouping, and sorting. For each query, we generated a series
    of query ablations by incrementally adding code chunks and formulating corresponding
    queries that these chunks would solve. This method expanded our original 15 queries
    into 50 query ablations, each with a corresponding ground-truth solution and Python
    code.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估GoNoGo系统的性能，我们开发了一个基准，基于15个初步分析任务，这些任务在发布工程师的帮助下定义。这些任务被转换为GoNoGo可以处理的明确表分析查询。我们使用Python创建了这些查询的最终基准解决方案，将解决方案分解为代表过滤、分组和排序等操作的较小代码块。对于每个查询，我们生成了一系列查询消融，通过逐步添加代码块并制定这些代码块将解决的相应查询。这种方法将我们原来的15个查询扩展为50个查询消融，每个查询都有一个相应的基准解决方案和Python代码。
- en: 'In this way, we established queries with four levels of difficulty:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，我们建立了四个难度级别的查询：
- en: Level 1
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 级别 1
- en: These are the simplest queries, typically involving a single operation such
    as filtering or sorting.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是最简单的查询，通常涉及单一操作，如过滤或排序。
- en: Level 2
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 级别 2
- en: These queries combine two or three basic operations, such as multiple filtering
    followed by sorting.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这些查询结合了两个或三个基本操作，如多次过滤后进行排序。
- en: Level 3
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 级别 3
- en: These queries involve more than three operations, potentially including grouping
    and aggregating.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这些查询涉及三个以上的操作，可能包括分组和聚合。
- en: Level 4
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 级别 4
- en: These are the most complex queries, requiring multiple advanced operations such
    as grouping and aggregating, for calculating statistics, beyond basic filtering
    and sorting.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是最复杂的查询，需要多次高级操作，如分组和聚合，用于计算统计数据，超出了基本的过滤和排序范围。
- en: This incremental approach to query complexity allows us to assess GoNoGO’s performance
    at various levels of difficulty. It helps identify at which point, if any, the
    system’s performance begins to degrade, and provides insights into its capabilities
    in handling increasingly complex table analysis tasks.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这种逐步增加复杂性的查询方法使我们能够评估GoNoGO在不同难度水平下的性能。它有助于识别系统性能开始下降的节点（如果有的话），并提供系统处理日益复杂的表格分析任务的能力的见解。
- en: This benchmark allows for objective evaluation of the GoNoGo’s ability to handle
    increasingly complex table analysis tasks, ensuring a comprehensive assessment
    of its performance across a spectrum of difficulty levels.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这个基准测试允许客观评估GoNoGo处理日益复杂的表格分析任务的能力，确保对其在各种难度水平下的性能进行全面评估。
- en: 4.3 Evaluation
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 评估
- en: The evaluation process involves comparing the GoNoGo system’s results against
    manually generated ground-truth results. The comparison is based on a strict matching
    criterion [[9](#bib.bib9)]. For a match to be considered successful, the system’s
    output must contain the same columns as the ground truth. Additionally, each record
    in the system’s output must exactly match a corresponding record in the ground
    truth, including all values across different fields. The system’s output must
    also contain the same number of records as the ground truth, with no missing or
    extra entries. This strict matching ensures that the output is not just similar,
    but identical in structure and content to the expected result. If the agent’s
    output satisfies all these criteria when compared to the ground truth, the task
    is marked as successful; otherwise, it is considered a failure. The model’s performance
    is then quantified by calculating the success rate, defined as the ratio of successful
    tasks to the total number of tasks.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 评估过程涉及将GoNoGo系统的结果与手动生成的真实结果进行比较。比较基于严格的匹配标准[[9](#bib.bib9)]。为了被视为成功匹配，系统的输出必须包含与真实结果相同的列。此外，系统输出中的每条记录必须与真实结果中的对应记录完全匹配，包括所有字段的值。系统输出还必须包含与真实结果相同数量的记录，没有遗漏或额外条目。这种严格匹配确保了输出不仅相似，而是结构和内容上与预期结果完全一致。如果代理的输出在与真实结果比较时满足所有这些标准，则任务标记为成功；否则，视为失败。然后通过计算成功任务与总任务数的比例来量化模型的性能。
- en: 4.4 Results
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 结果
- en: 'We present our experiment results on the GoNoGo system in Table [1](#S4.T1
    "Table 1 ‣ 4.4 Results ‣ 4 Experiments ‣ GoNoGo: An Efficient LLM-based Multi-Agent
    System for Streamlining Automotive Software Release Decision-Making"). We evaluated
    its performance across different levels of task difficulty using 0-shot, 1-shot,
    2-shot, and 3-shot examples. GoNoGo achieved high performance with 3-shot examples.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在表[1](#S4.T1 "表 1 ‣ 4.4 结果 ‣ 4 实验 ‣ GoNoGo：一种高效的基于LLM的多代理系统，用于简化汽车软件发布决策")中展示了GoNoGo系统的实验结果。我们使用0-shot、1-shot、2-shot和3-shot示例评估了其在不同任务难度级别下的性能。GoNoGo在3-shot示例中表现优异。
- en: 'Table 1: Performance evaluation of the GoNoGo system with varying numbers of
    example queries across different levels of task difficulty.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：不同任务难度级别下GoNoGo系统的性能评估。
- en: '| # Examples | Task Difficulty | # Total Tasks | # Success | # Failed | Performance
    |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| # 示例 | 任务难度 | # 总任务数 | # 成功 | # 失败 | 性能 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| 0-shot | 1 | 16 | 3 | 13 | 18.75% |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 0-shot | 1 | 16 | 3 | 13 | 18.75% |'
- en: '| 1-2 | 32 | 6 | 26 | 18.75% |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 1-2 | 32 | 6 | 26 | 18.75% |'
- en: '| 1-3 | 44 | 9 | 35 | 20.45% |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 1-3 | 44 | 9 | 35 | 20.45% |'
- en: '| 1-4 | 50 | 11 | 39 | 22% |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 1-4 | 50 | 11 | 39 | 22% |'
- en: '| 1-shot | 1 | 16 | 15 | 1 | 93.75% |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 1-shot | 1 | 16 | 15 | 1 | 93.75% |'
- en: '| 1-2 | 32 | 27 | 5 | 84.37% |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 1-2 | 32 | 27 | 5 | 84.37% |'
- en: '| 1-3 | 44 | 32 | 12 | 72.72% |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 1-3 | 44 | 32 | 12 | 72.72% |'
- en: '| 1-4 | 50 | 34 | 16 | 68% |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 1-4 | 50 | 34 | 16 | 68% |'
- en: '| 2-shot | 1 | 16 | 16 | 0 | 100% |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 2-shot | 1 | 16 | 16 | 0 | 100% |'
- en: '| 1-2 | 32 | 31 | 1 | 96.87% |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 1-2 | 32 | 31 | 1 | 96.87% |'
- en: '| 1-3 | 44 | 38 | 6 | 86.36% |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 1-3 | 44 | 38 | 6 | 86.36% |'
- en: '| 1-4 | 50 | 41 | 9 | 82% |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 1-4 | 50 | 41 | 9 | 82% |'
- en: '| 3-shot | 1 | 16 | 16 | 0 | 100% |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 3-shot | 1 | 16 | 16 | 0 | 100% |'
- en: '| 1-2 | 32 | 32 | 0 | 100% |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 1-2 | 32 | 32 | 0 | 100% |'
- en: '| 1-3 | 44 | 41 | 3 | 93% |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 1-3 | 44 | 41 | 3 | 93% |'
- en: '| 1-4 | 50 | 45 | 5 | 90% |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 1-4 | 50 | 45 | 5 | 90% |'
- en: Initially, we assessed GoNoGo’s ability to handle the simplest queries involving
    basic operations like filtering or sorting (Level 1). We then incrementally increased
    the complexity by including queries that combined Level 1 and Level 2 difficulties,
    followed by those incorporating Level 1 to Level 3 difficulties. Finally, we evaluated
    GoNoGo’s performance on the full spectrum of tasks, including the most complex
    queries (Level 4), which require multiple operations such as filtering, sorting,
    grouping, and calculating statistics.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，我们评估了 GoNoGo 处理涉及基本操作（如过滤或排序）的最简单查询的能力（Level 1）。然后我们逐步增加复杂性，包括结合 Level 1
    和 Level 2 难度的查询，随后是包含 Level 1 到 Level 3 难度的查询。最后，我们评估了 GoNoGo 在全范围任务上的表现，包括需要多种操作如过滤、排序、分组和计算统计的最复杂查询（Level
    4）。
- en: Our observations indicate that GoNoGo with 3-shot examples is particularly effective
    for solving queries with task difficulty up to Level 2 and can handle these tasks
    without error. For more complex tasks involving Level 3 or Level 4 difficulties,
    human intervention is recommended to perform the necessary manipulations and computations,
    rather than relying solely on the automated system.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的观察表明，带有 3 次示例的 GoNoGo 方法对于解决任务难度高达 Level 2 的查询特别有效，并且可以在没有错误的情况下处理这些任务。对于涉及
    Level 3 或 Level 4 难度的更复杂任务，建议进行人工干预以执行必要的操作和计算，而不是仅仅依赖自动化系统。
- en: 5 Related Work
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 相关工作
- en: The application of tabular data in machine learning holds significant potential,
    ranging from few-shot learning for data analysis to end-to-end data pipeline automation.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 表格数据在机器学习中的应用具有重要潜力，从用于数据分析的少样本学习到端到端的数据管道自动化。
- en: Integrating LLM with tabular data presents several substantial challenges [[4](#bib.bib4)].
    Most foundation models are not trained on tabular data, making it difficult for
    them to process and interpret this type of data effectively. To mitigate this
    issue, pre-training LLMs using tabular data or fune-tuning on specific tasks are
    two commonly adopted options. [[16](#bib.bib16)] described different phases and
    strategies for LLM training, and [[18](#bib.bib18)] provided guidelines for enterprises
    who are interested in fine-tuning LLMs.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 将 LLM 与表格数据集成面临几个重大挑战 [[4](#bib.bib4)]。大多数基础模型未经过表格数据训练，因此难以有效处理和解释这类数据。为缓解这一问题，预训练
    LLM 使用表格数据或在特定任务上微调是两种常见选择。[[16](#bib.bib16)] 描述了 LLM 训练的不同阶段和策略，而 [[18](#bib.bib18)]
    为有兴趣微调 LLM 的企业提供了指南。
- en: In particular, recent literature has seen a growing interest in pre-training
    and self-supervised learning (SSL) approaches using tabular data. [[20](#bib.bib20)]
    emphasizes SSL for non-sequential tabular data (SSL4NS-TD), categorizing methods
    into predictive, contrastive, and hybrid learning, and discussing application
    issues such as automatic data engineering and cross-table transferability. In
    contrast, [[29](#bib.bib29)] introduces TapTap, a novel table pre-training method
    that enhances tabular prediction and generates synthetic tables for various applications.
    Finally, [[25](#bib.bib25)] introduces Tabular data Pre-Training via Meta-representation
    (TabPTM), which enables training-free generalization across heterogeneous datasets
    by standardizing data representations through distance to prototypes. The common
    theme across these works is the enhancement of tabular data handling through innovative
    pre-training and SSL techniques, though they differ in their specific methodologies
    and application focuses, ranging from generating synthetic data to improving model
    generalization and manipulation capabilities. [[28](#bib.bib28)] proposes Tabular
    Foundation Models (TabFMs), leveraging a pre-trained LLM fine-tuned on diverse
    tabular datasets to excel in instruction-following tasks and efficient learning
    with scarce data.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，近期文献对使用表格数据进行预训练和自监督学习（SSL）方法表现出越来越大的兴趣。[[20](#bib.bib20)] 强调了针对非序列表格数据的自监督学习（SSL4NS-TD），将方法分类为预测性、对比性和混合学习，并讨论了自动数据工程和跨表传递性等应用问题。相比之下，[[29](#bib.bib29)]
    介绍了一种新颖的表格预训练方法 TapTap，该方法提升了表格预测，并为各种应用生成合成表格。最后，[[25](#bib.bib25)] 介绍了通过元表示进行的表格数据预训练（TabPTM），该方法通过对原型的距离标准化数据表示，从而实现了跨异质数据集的无训练泛化。这些研究的共同主题是通过创新的预训练和自监督学习技术增强表格数据处理能力，尽管它们在具体方法和应用重点上有所不同，从生成合成数据到提高模型泛化和操作能力。[[28](#bib.bib28)]
    提出了表格基础模型（TabFMs），利用经过微调的预训练大型语言模型（LLM）在各种表格数据集上表现出色，从而在指令跟随任务和稀缺数据的高效学习中表现出色。
- en: Pre-training aims to enhance LLMs’ capability of handling tabular data in general.
    However, it does not necessarily improve their performance on specific tasks.
    On the other hand, fine-tuning pre-trained LLMs have demonstrated potential for
    enhancing tabular data manipulation on specific tasks. [[30](#bib.bib30)] introduced
    TableLLM, a robust 13-billion-parameter model designed for handling tabular data
    in real-world office scenarios. In particular, TableLLM incorporates reasoning
    process extensions and cross-way validation strategies, outperforming existing
    general-purpose and tabular-focused LLMs. [[12](#bib.bib12)] explored zero-shot
    and few-shot tabular data classification by prompting LLMs with serialized data
    and problem descriptions, achieving superior performance over traditional deep-learning
    methods and even strong baselines like gradient-boosted trees. [[33](#bib.bib33)]
    addressed question answering over hybrid tabular and textual data, fine-tuning
    LLaMA 2 using a step-wise pipeline, resulting in TAT-LLM, which outperforms both
    prior fine-tuned models and large-scale LLMs such as GPT-4 on specific benchmarks.
    [[23](#bib.bib23)] focused on applying LLMs to predictive tasks in tabular data,
    enhancing LLM capabilities through extensive training on annotated tables.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练旨在增强大语言模型（LLMs）处理表格数据的能力。然而，这并不一定会提高它们在特定任务上的表现。另一方面，微调预训练的大语言模型已经展示了在特定任务上提升表格数据处理能力的潜力。[[30](#bib.bib30)]
    引入了 TableLLM，这是一个强大的 130 亿参数模型，旨在处理现实办公场景中的表格数据。特别是，TableLLM 结合了推理过程扩展和交叉验证策略，超越了现有的一般用途和表格专注的大语言模型。[[12](#bib.bib12)]
    探索了通过对大语言模型进行序列化数据和问题描述的提示来实现零样本和少样本表格数据分类，表现优于传统的深度学习方法，甚至强基准如梯度提升树。[[33](#bib.bib33)]
    解决了对混合表格和文本数据进行问答的问题，通过逐步的流程微调 LLaMA 2，产生了 TAT-LLM，该模型在特定基准测试中超越了之前的微调模型和像 GPT-4
    这样的规模大语言模型。[[23](#bib.bib23)] 专注于将大语言模型应用于表格数据的预测任务，通过对标注表的广泛训练来增强大语言模型的能力。
- en: Industrial considerations
  id: totrans-113
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 工业考虑
- en: One known issue is that LLMs often memorize tabular data verbatim, leading to
    overfitting. [[2](#bib.bib2)] highlights that despite their nontrivial generalization
    capability, LLMs perform better on datasets they were exposed to during training
    compared to new, unseen datasets. This indicates a tendency towards memorization,
    necessitating robust testing and validation protocols. This issue is particularly
    critical for companies’ internal data and tasks that a foundation model has not
    encountered before, as public benchmarks do not necessarily predict performance
    on these internal tasks. In addition, it is worth noting that some applications
    have stringent data privacy policies, a concern increasingly being addressed in
    the literature [[26](#bib.bib26), [6](#bib.bib6), [3](#bib.bib3)]. In our work,
    we assume that the data resides within a secure local network, and we do not address
    data privacy issues in this paper. In industrial settings, practical constraints
    such as interpretability, user-centric adaptation, ease of development and maintenance,
    latency requirements, and IT infrastructure limitations are crucial. Our objective
    is to design a system that addresses these industrial needs without unnecessary
    complexity and excessive resources typically required by pre-training and fine-tuning
    LLMs.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 一个已知的问题是，大语言模型经常逐字记忆表格数据，从而导致过拟合。[[2](#bib.bib2)] 强调，尽管它们具有不容忽视的泛化能力，但大语言模型在训练过程中接触过的数据集上的表现优于新颖的、未见过的数据集。这表明有记忆倾向，因此需要严格的测试和验证程序。这个问题对于公司内部数据和基础模型之前未遇到的任务尤为关键，因为公共基准测试并不一定预测这些内部任务的表现。此外，值得注意的是，一些应用有严格的数据隐私政策，这一问题在文献中越来越受到关注
    [[26](#bib.bib26), [6](#bib.bib6), [3](#bib.bib3)]。在我们的工作中，我们假设数据存储在安全的本地网络中，因此本文不涉及数据隐私问题。在工业环境中，解释性、以用户为中心的适应、开发和维护的便利性、延迟要求以及
    IT 基础设施限制等实际约束至关重要。我们的目标是设计一个满足这些工业需求的系统，而不增加预训练和微调大语言模型通常所需的复杂性和资源。
- en: 6 Conclusion
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: We present the GoNoGo, an LLM-based multi-agent system designed to streamline
    software release decisions in the automotive industry by analyzing and deriving
    insights from real-world data using Python code. We have employed this system
    within our industrial partner’s company, which is significantly assisting release
    managers and reducing the number of engineers engaged in this process, allowing
    them to focus on their high-level tasks.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出了 GoNoGo，这是一个基于大型语言模型的多智能体系统，旨在通过使用 Python 代码分析和提取现实数据中的见解来简化汽车行业的软件发布决策。我们在我们的工业合作伙伴公司中使用了该系统，这显著地帮助了发布经理并减少了参与这一过程的工程师数量，使他们能够专注于更高层次的任务。
- en: The impact of our system extends beyond automation, transforming how automotive
    companies manage their software release cycles. It reduces the time and effort
    required for data analysis while increasing decision accuracy and reliability.
    This shift allows engineers and managers to focus on higher-level tasks, accelerating
    the overall development and deployment process by bridging the gap between raw
    data and actionable insights, driving the industry towards more efficient, data-driven
    software release practices. Without GoNoGo in place, our industrial partner would
    experience more wasted time and effort across various teams and employees, with
    the decision-making process becoming significantly prolonged. Pilot users have
    reported saving approximately 2 hours per person each time they make a decision,
    highlighting the system’s positive impact on efficiency and the industrial partner’s
    overall business goals.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的系统的影响不仅限于自动化，还改变了汽车公司管理其软件发布周期的方式。它减少了数据分析所需的时间和精力，同时提高了决策的准确性和可靠性。这种转变使工程师和经理能够专注于更高层次的任务，通过弥合原始数据和可操作见解之间的差距，加速了整体开发和部署过程，推动了行业向更加高效、数据驱动的软件发布实践发展。如果没有
    GoNoGo，我们的工业合作伙伴将经历更多的时间和精力浪费在各个团队和员工之间，决策过程会显著延长。试点用户报告称每次做决定时节省了大约 2 小时，突显了该系统对效率和工业合作伙伴整体商业目标的积极影响。
- en: 7 Acknowledgement
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 致谢
- en: This work was partially supported by the Wallenberg AI, Autonomous Sys- tems
    and Software Program (WASP) funded by the Knut and Alice Wallenberg Foundation.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作部分得到了由克努特和艾丽斯·瓦伦贝里基金会资助的瓦伦贝里人工智能、自动化系统和软件计划（WASP）的支持。
- en: References
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Austin, J., Odena, A., Nye, M., Bosma, M., Michalewski, H., Dohan, D.,
    Jiang, E., Cai, C., Terry, M., Le, Q., et al.: Program synthesis with large language
    models. arXiv preprint arXiv:2108.07732 (2021)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Austin, J., Odena, A., Nye, M., Bosma, M., Michalewski, H., Dohan, D.,
    Jiang, E., Cai, C., Terry, M., Le, Q., 等: 使用大型语言模型进行程序合成。arXiv 预印本 arXiv:2108.07732
    (2021)'
- en: '[2] Bordt, S., Nori, H., Rodrigues, V., Nushi, B., Caruana, R.: Elephants never
    forget: Memorization and learning of tabular data in large language models. arXiv
    preprint arXiv:2404.06209 (2024)'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Bordt, S., Nori, H., Rodrigues, V., Nushi, B., Caruana, R.: 大象从不忘记：大型语言模型中的表格数据记忆与学习。arXiv
    预印本 arXiv:2404.06209 (2024)'
- en: '[3] Boudewijn, A.T.P., Ferraris, A.F., Panfilo, D., Cocca, V., Zinutti, S.,
    De Schepper, K., Chauvenet, C.R.: Privacy measurements in tabular synthetic data:
    State of the art and future research directions. In: NeurIPS 2023 Workshop on
    Synthetic Data Generation with Generative AI (2023)'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Boudewijn, A.T.P., Ferraris, A.F., Panfilo, D., Cocca, V., Zinutti, S.,
    De Schepper, K., Chauvenet, C.R.: 表格合成数据的隐私测量：现状与未来研究方向。In: NeurIPS 2023 合成数据生成与生成式人工智能研讨会
    (2023)'
- en: '[4] van Breugel, B., van der Schaar, M.: Why Tabular Foundation Models Should
    Be a Research Priority (Jun 2024)'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] van Breugel, B., van der Schaar, M.: 为什么表格基础模型应该成为研究优先事项 (2024年6月)'
- en: '[5] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P.,
    Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al.: Language models are
    few-shot learners. Advances in neural information processing systems 33, 1877–1901
    (2020)'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P.,
    Neelakantan, A., Shyam, P., Sastry, G., Askell, A., 等: 语言模型是少量样本学习者。神经信息处理系统进展
    33, 1877–1901 (2020)'
- en: '[6] Carey, A.N., Bhaila, K., Edemacu, K., Wu, X.: Dp-tabicl: In-context learning
    with differentially private tabular data. arXiv preprint arXiv:2403.05681 (2024)'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Carey, A.N., Bhaila, K., Edemacu, K., Wu, X.: Dp-tabicl: 使用差分隐私表格数据进行上下文学习。arXiv
    预印本 arXiv:2403.05681 (2024)'
- en: '[7] Chang, Y., Wang, X., Wang, J., Wu, Y., Yang, L., Zhu, K., Chen, H., Yi,
    X., Wang, C., Wang, Y., et al.: A survey on evaluation of large language models.
    ACM Transactions on Intelligent Systems and Technology 15(3), 1–45 (2024)'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Chang, Y., Wang, X., Wang, J., Wu, Y., Yang, L., Zhu, K., Chen, H., Yi,
    X., Wang, C., Wang, Y., 等: 大型语言模型评估的调查。ACM 智能系统与技术学报 15(3), 1–45 (2024)'
- en: '[8] Chen, X., Lin, M., Schärli, N., Zhou, D.: Teaching large language models
    to self-debug. arXiv preprint arXiv:2304.05128 (2023)'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Chen, X., Lin, M., Schärli, N., Zhou, D.：教会大型语言模型自我调试。arXiv 预印本 arXiv:2304.05128
    (2023)'
- en: '[9] Chiang, W.L., Zheng, L., Sheng, Y., Angelopoulos, A.N., Li, T., Li, D.,
    Zhang, H., Zhu, B., Jordan, M., Gonzalez, J.E., et al.: Chatbot arena: An open
    platform for evaluating llms by human preference. arXiv preprint arXiv:2403.04132
    (2024)'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Chiang, W.L., Zheng, L., Sheng, Y., Angelopoulos, A.N., Li, T., Li, D.,
    Zhang, H., Zhu, B., Jordan, M., Gonzalez, J.E., 等：聊天机器人平台：一个通过人工偏好评估LLMs的开放平台。arXiv
    预印本 arXiv:2403.04132 (2024)'
- en: '[10] Dagdelen, J., Dunn, A., Lee, S., Walker, N., Rosen, A.S., Ceder, G., Persson,
    K.A., Jain, A.: Structured information extraction from scientific text with large
    language models. Nature Communications 15(1),  1418 (2024)'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Dagdelen, J., Dunn, A., Lee, S., Walker, N., Rosen, A.S., Ceder, G., Persson,
    K.A., Jain, A.：利用大型语言模型从科学文本中提取结构化信息。自然通讯 15(1), 1418 (2024)'
- en: '[11] Dyachenko, Y., Nenkov, N., Petrova, M., Skarga-Bandurova, I., Soloviov,
    O.: Approaches to cognitive architecture of autonomous intelligent agent. Biologically
    Inspired Cognitive Architectures 26, 130–135 (2018)'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Dyachenko, Y., Nenkov, N., Petrova, M., Skarga-Bandurova, I., Soloviov,
    O.：自主智能代理的认知架构方法。生物启发的认知架构 26, 130–135 (2018)'
- en: '[12] Hegselmann, S., Buendia, A., Lang, H., Agrawal, M., Jiang, X., Sontag,
    D.: TabLLM: Few-shot Classification of Tabular Data with Large Language Models'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Hegselmann, S., Buendia, A., Lang, H., Agrawal, M., Jiang, X., Sontag,
    D.：TabLLM：使用大型语言模型进行表格数据的少量样本分类'
- en: '[13] Huang, J., Chang, K.C.C.: Towards reasoning in large language models:
    A survey. arXiv preprint arXiv:2212.10403 (2022)'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Huang, J., Chang, K.C.C.：大型语言模型中的推理探索：综述。arXiv 预印本 arXiv:2212.10403 (2022)'
- en: '[14] Khot, T., Trivedi, H., Finlayson, M., Fu, Y., Richardson, K., Clark, P.,
    Sabharwal, A.: Decomposed prompting: A modular approach for solving complex tasks.
    arXiv preprint arXiv:2210.02406 (2022)'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Khot, T., Trivedi, H., Finlayson, M., Fu, Y., Richardson, K., Clark, P.,
    Sabharwal, A.：分解提示：解决复杂任务的模块化方法。arXiv 预印本 arXiv:2210.02406 (2022)'
- en: '[15] Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., Neubig, G.: Pre-train,
    prompt, and predict: A systematic survey of prompting methods in natural language
    processing. ACM Computing Surveys 55(9), 1–35 (2023)'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., Neubig, G.：预训练、提示和预测：自然语言处理中的提示方法系统综述。ACM
    计算机调查 55(9), 1–35 (2023)'
- en: '[16] Patil, R., Gudivada, V.: A review of current trends, techniques, and challenges
    in large language models (llms). Applied Sciences 14(5),  2074 (2024)'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Patil, R., Gudivada, V.：大型语言模型（LLMs）中的当前趋势、技术和挑战综述。应用科学 14(5), 2074 (2024)'
- en: '[17] Valmeekam, K., Marquez, M., Sreedharan, S., Kambhampati, S.: On the planning
    abilities of large language models-a critical investigation. Advances in Neural
    Information Processing Systems 36, 75993–76005 (2023)'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Valmeekam, K., Marquez, M., Sreedharan, S., Kambhampati, S.：大型语言模型的规划能力——关键调查。神经信息处理系统进展
    36, 75993–76005 (2023)'
- en: '[18] VM, K., Warrier, H., Gupta, Y., et al.: Fine tuning llm for enterprise:
    Practical guidelines and recommendations. arXiv preprint arXiv:2404.10779 (2024)'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] VM, K., Warrier, H., Gupta, Y., 等：针对企业的LLM微调：实践指南和建议。arXiv 预印本 arXiv:2404.10779
    (2024)'
- en: '[19] Wang, L., Ma, C., Feng, X., Zhang, Z., Yang, H., Zhang, J., Chen, Z.,
    Tang, J., Chen, X., Lin, Y., et al.: A survey on large language model based autonomous
    agents. Frontiers of Computer Science 18(6), 186345 (2024)'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Wang, L., Ma, C., Feng, X., Zhang, Z., Yang, H., Zhang, J., Chen, Z.,
    Tang, J., Chen, X., Lin, Y., 等：基于大型语言模型的自主代理调查。计算机科学前沿 18(6), 186345 (2024)'
- en: '[20] Wang, W.Y., Du, W.W., Xu, D., Wang, W., Peng, W.C.: A survey on self-supervised
    learning for non-sequential tabular data. arXiv preprint arXiv:2402.01204 (2024)'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Wang, W.Y., Du, W.W., Xu, D., Wang, W., Peng, W.C.：关于非序列化表格数据的自监督学习调查。arXiv
    预印本 arXiv:2402.01204 (2024)'
- en: '[21] Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery,
    A., Zhou, D.: Self-consistency improves chain of thought reasoning in language
    models. arXiv preprint arXiv:2203.11171 (2022)'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery,
    A., Zhou, D.：自一致性提升了语言模型中的思维链推理。arXiv 预印本 arXiv:2203.11171 (2022)'
- en: '[22] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q.V.,
    Zhou, D., et al.: Chain-of-thought prompting elicits reasoning in large language
    models. Advances in neural information processing systems 35, 24824–24837 (2022)'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q.V.,
    Zhou, D., 等：思维链提示激发大型语言模型的推理。神经信息处理系统进展 35, 24824–24837 (2022)'
- en: '[23] Yang, Y., Wang, Y., Sen, S., Li, L., Liu, Q.: Unleashing the Potential
    of Large Language Models for Predictive Tabular Tasks in Data Science (2024)'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] Yang, Y., Wang, Y., Sen, S., Li, L., Liu, Q.: 发掘大型语言模型在数据科学预测表格任务中的潜力
    (2024)'
- en: '[24] Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., Cao, Y.:
    React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629
    (2022)'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., Cao, Y.:
    React: 语言模型中的推理与行动的协同作用。arXiv 预印本 arXiv:2210.03629 (2022)'
- en: '[25] Ye, H.J., Zhou, Q., Zhan, D.C.: Training-free generalization on heterogeneous
    tabular data via meta-representation (2023)'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Ye, H.J., Zhou, Q., Zhan, D.C.: 无需训练的异质表格数据泛化通过元表示 (2023)'
- en: '[26] Ye, J., Du, M., Wang, G.: DataFrame QA: A Universal LLM Framework on DataFrame
    Question Answering Without Data Exposure (2024)'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Ye, J., Du, M., Wang, G.: DataFrame QA: 无数据暴露的通用 LLM 框架用于 DataFrame 问答
    (2024)'
- en: '[27] Yoon, J., Feldt, R., Yoo, S.: Intent-driven mobile gui testing with autonomous
    large language model agents. In: 2024 IEEE Conference on Software Testing, Verification
    and Validation (ICST). IEEE (2024)'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Yoon, J., Feldt, R., Yoo, S.: 基于意图的移动 GUI 测试与自主大型语言模型代理。在：2024 IEEE 软件测试、验证与验证会议
    (ICST)。IEEE (2024)'
- en: '[28] Zhang, H., Wen, X., Zheng, S., Xu, W., Bian, J.: Towards foundation models
    for learning on tabular data. arXiv preprint arXiv:2310.07338 (2023)'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] Zhang, H., Wen, X., Zheng, S., Xu, W., Bian, J.: 朝着学习表格数据的基础模型迈进。arXiv
    预印本 arXiv:2310.07338 (2023)'
- en: '[29] Zhang, T., Wang, S., Yan, S., Li, J., Liu, Q.: Generative table pre-training
    empowers models for tabular prediction. arXiv preprint arXiv:2305.09696 (2023)'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Zhang, T., Wang, S., Yan, S., Li, J., Liu, Q.: 生成式表格预训练赋能模型进行表格预测。arXiv
    预印本 arXiv:2305.09696 (2023)'
- en: '[30] Zhang, X., Zhang, J., Ma, Z., Li, Y., Zhang, B., Li, G., Yao, Z., Xu,
    K., Zhou, J., Zhang-Li, D., Yu, J., Zhao, S., Li, J., Tang, J.: TableLLM: Enabling
    Tabular Data Manipulation by LLMs in Real Office Usage Scenarios (2024)'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Zhang, X., Zhang, J., Ma, Z., Li, Y., Zhang, B., Li, G., Yao, Z., Xu,
    K., Zhou, J., Zhang-Li, D., Yu, J., Zhao, S., Li, J., Tang, J.: TableLLM: 实现实际办公场景中
    LLM 对表格数据的操作 (2024)'
- en: '[31] Zhang, Z., Yao, Y., Zhang, A., Tang, X., Ma, X., He, Z., Wang, Y., Gerstein,
    M., Wang, R., Liu, G., et al.: Igniting language intelligence: The hitchhiker’s
    guide from chain-of-thought reasoning to language agents. arXiv preprint arXiv:2311.11797
    (2023)'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Zhang, Z., Yao, Y., Zhang, A., Tang, X., Ma, X., He, Z., Wang, Y., Gerstein,
    M., Wang, R., Liu, G., 等: 点燃语言智能：从链式思维推理到语言代理的搭便车指南。arXiv 预印本 arXiv:2311.11797
    (2023)'
- en: '[32] Zhou, D., Schärli, N., Hou, L., Wei, J., Scales, N., Wang, X., Schuurmans,
    D., Cui, C., Bousquet, O., Le, Q., et al.: Least-to-most prompting enables complex
    reasoning in large language models. arXiv preprint arXiv:2205.10625 (2022)'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] Zhou, D., Schärli, N., Hou, L., Wei, J., Scales, N., Wang, X., Schuurmans,
    D., Cui, C., Bousquet, O., Le, Q., 等: 从少到多的提示使大型语言模型能够进行复杂推理。arXiv 预印本 arXiv:2205.10625
    (2022)'
- en: '[33] Zhu, F., Liu, Z., Feng, F., Wang, C., Li, M., Chua, T.S.: TAT-LLM: A Specialized
    Language Model for Discrete Reasoning over Tabular and Textual Data (Feb 2024)'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] Zhu, F., Liu, Z., Feng, F., Wang, C., Li, M., Chua, T.S.: TAT-LLM: 用于离散推理的专用语言模型，适用于表格和文本数据
    (2024年2月)'
