- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '分类: 未分类'
- en: 'date: 2024-09-08 18:51:21'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-08 18:51:21'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Researchy Questions: A Dataset of Multi-Perspective, Decompositional Questions
    for LLM Web Agents'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'Researchy Questions: 多视角、分解式问题的数据集，供LLM网络代理使用'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2402.17896](https://ar5iv.labs.arxiv.org/html/2402.17896)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2402.17896](https://ar5iv.labs.arxiv.org/html/2402.17896)
- en: Corby Rosset
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 科比·罗斯特
- en: Microsoft
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 微软
- en: \AndHo-Lam Chung
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: \和何林·钟
- en: National Taiwan Univ.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 国立台湾大学
- en: \AndGuanghui Qin
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: \和光辉·秦
- en: Johns Hopkins Univ.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 约翰霍普金斯大学
- en: \AndEthan C. Chau
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: \和伊桑·C·周
- en: Microsoft
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 微软
- en: \ANDZhuo Feng
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: \和卓越·冯
- en: Microsoft
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 微软
- en: \AndAhmed Awadallah
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: \和艾哈迈德·阿瓦达拉
- en: Microsoft
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 微软
- en: \AndJennifer Neville
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: \和詹妮弗·内维尔
- en: Microsoft
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 微软
- en: \AndNikhil Rao
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: \和尼基尔·拉奥
- en: Microsoft
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 微软
- en: Abstract
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Existing question answering (QA) datasets are no longer challenging to most
    powerful Large Language Models (LLMs). Traditional QA benchmarks like TriviaQA,
    NaturalQuestions, ELI5 and HotpotQA mainly study “known unknowns” with clear indications
    of both what information is missing, and how to find it to answer the question.
    Hence, good performance on these benchmarks provides a false sense of security.
    A yet unmet need of the NLP community is a bank of non-factoid, multi-perspective
    questions involving a great deal of unclear information needs, i.e. “unknown uknowns”.
    We claim we can find such questions in search engine logs, which is surprising
    because most question-intent queries are indeed factoid. We present Researchy
    Questions, a dataset of search engine queries tediously filtered to be non-factoid,
    “decompositional” and multi-perspective. We show that users spend a lot of “effort”
    on these questions in terms of signals like clicks and session length, and that
    they are also challenging for GPT-4. We also show that “slow thinking” answering
    techniques, like decomposition into sub-questions shows benefit over answering
    directly. We release¹¹1[https://huggingface.co/datasets/corbyrosset/researchy_questions](https://huggingface.co/datasets/corbyrosset/researchy_questions)
    $\sim$ 100k Researchy Questions, along with the Clueweb22 URLs that were clicked.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的问答（QA）数据集对大多数强大的大型语言模型（LLMs）而言已不再具有挑战性。传统的QA基准，如TriviaQA、NaturalQuestions、ELI5和HotpotQA，主要研究“已知的未知”，即明确知道缺少哪些信息以及如何找到这些信息来回答问题。因此，在这些基准上表现良好会带来一种虚假的安全感。自然语言处理（NLP）社区尚未满足的需求是一个包含大量不明确信息需求的非事实型、多视角问题的库，即“未知的未知”。我们声称可以在搜索引擎日志中找到这些问题，这一点令人惊讶，因为大多数问题意图查询实际上是事实型的。我们呈现了Researchy
    Questions，这是一个经过仔细筛选的搜索引擎查询数据集，筛选标准为非事实型、"分解式"和多视角。我们展示了用户在这些问题上花费了大量“精力”，如点击次数和会话时长，并且这些问题对GPT-4也很有挑战性。我们还展示了“慢思考”回答技术，如分解成子问题，相比直接回答具有优势。我们发布了[https://huggingface.co/datasets/corbyrosset/researchy_questions](https://huggingface.co/datasets/corbyrosset/researchy_questions)
    约100k个Researchy Questions，以及点击过的Clueweb22 URLs。
- en: 1 Introduction
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: '| Dataset | Num. | Topics | Sub-Ques. | Sub-Query |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 数量 | 主题 | 子问题 | 子查询 |'
- en: '| Hotpot QA | 300 | 2.9 | 3.8 | 3.6 |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| Hotpot QA | 300 | 2.9 | 3.8 | 3.6 |'
- en: '| OpenBook QA | 300 | 3.8 | 6.3 | 5.9 |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| OpenBook QA | 300 | 3.8 | 6.3 | 5.9 |'
- en: '| Strategy QA | 300 | 3.8 | 5.3 | 4.9 |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| Strategy QA | 300 | 3.8 | 5.3 | 4.9 |'
- en: '| Truthful QA | 300 | 3.8 | 6.4 | 6.0 |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| Truthful QA | 300 | 3.8 | 6.4 | 6.0 |'
- en: '| Aquamuse | 300 | 3.7 | 5.4 | 5.2 |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| Aquamuse | 300 | 3.7 | 5.4 | 5.2 |'
- en: '| Reddit/askh | 300 | 4.9 | 9.4 | 8.5 |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| Reddit/askh | 300 | 4.9 | 9.4 | 8.5 |'
- en: '| Reddit/asks | 300 | 5.1 | 9.2 | 8.8 |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| Reddit/asks | 300 | 5.1 | 9.2 | 8.8 |'
- en: '| Reddit/eli5 | 300 | 4.5 | 9.7 | 9.3 |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| Reddit/eli5 | 300 | 4.5 | 9.7 | 9.3 |'
- en: '| Stack Exchange | 300 | 6.1 | 8.4 | 7.6 |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| Stack Exchange | 300 | 6.1 | 8.4 | 7.6 |'
- en: '| Wikihow | 300 | 4.8 | 11.7 | 11.2 |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| Wikihow | 300 | 4.8 | 11.7 | 11.2 |'
- en: '| Researchy | 96k | 3.9 | 14.3 | 12.6 |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| Researchy | 96k | 3.9 | 14.3 | 12.6 |'
- en: 'Table 1: We asked GPT-4 to decompose questions into a natural hierachy of subquestions,
    as well as concrete queries it would issue to a search engine. As expected, HotpotQA
    requires the fewest sub-questions to answer.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：我们要求GPT-4将问题分解成自然层次的子问题，以及它会向搜索引擎发出的具体查询。正如预期的那样，HotpotQA 需要最少的子问题来回答。
- en: 'The advent of Large Language Models (LLMs) has ushered in a new era for the
    field natural language processing, with short- and long- form question-answering
    (QA) at the forefront of recent achievements OpenAI et al. ([2023](#bib.bib39)).
    Historically, QA benchmarks served as the crucible for evaluating a model’s grasp
    of natural language understanding. However, LLMs have nearly perfected many QA
    datasets, particularly those involving answering short, factual questions like
    *“What is the capital of Brunei?"*. The re-emergence of chatbots and “agentic”
    AI assistants, which represent complex systems based on LLMs as a building block,
    have led to new opportunities for users to ask deeper, more nuanced questions
    as shown in Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Researchy Questions:
    A Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents").'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '大型语言模型 (LLMs) 的出现为自然语言处理领域开启了一个新时代，短问答和长问答 (QA) 成为近期成就的前沿 OpenAI 等人 ([2023](#bib.bib39))。历史上，QA
    基准测试曾作为评估模型自然语言理解能力的熔炉。然而，LLM 已几乎完善了许多 QA 数据集，特别是那些涉及回答简短的事实性问题，如 *“文莱的首都是什么？”*。聊天机器人和“代理”
    AI 助手的重新兴起，这些系统基于 LLM 作为构建模块，给用户提出更深层次、更微妙的问题带来了新的机会，如图 [1](#S1.F1 "图 1 ‣ 1 介绍
    ‣ Researchy Questions: 一种用于 LLM 网络代理的多角度、分解性问题的数据集") 所示。'
- en: '![Refer to caption](img/80630220080f1796368b25ca33a6d421.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/80630220080f1796368b25ca33a6d421.png)'
- en: 'Figure 1: Qualitative comparison of how Researchy Questions differs from other
    Question Answering datasets. Researchy Questions involve a greater deal of complexity
    and “unknown unknowns” than other QA datasets.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：Researchy Questions 与其他问答数据集的定性比较。Researchy Questions 涉及比其他 QA 数据集更大的复杂性和“未知的未知”。
- en: However, the capabilities of powerful AI-assisted QA tools has outpaced the
    metrics needed to evaluate them. A number of traditional QA benchmarks like Natural
    Questions Kwiatkowski et al. ([2019](#bib.bib31)), TriviaQA Joshi et al. ([2017](#bib.bib23)),
    WebQuestions Berant et al. ([2013](#bib.bib4)), SearchQA Dunn et al. ([2017](#bib.bib12))
    have been more or less solved by modern LLMs. These datasets consist primarily
    of factoid questions (from search engine logs, Trivia, Jeopardy!, etc), where
    answers are typically found within a single sentence or paragraph that almost
    certainly exist in standard pre-training web corpora Zhou et al. ([2023](#bib.bib65)).
    For instance, MS Marco  Campos et al. ([2016](#bib.bib9)) is up to 55% factoid
    questions (Bolotova et al., [2022](#bib.bib5)). The obvious drawback to these
    kinds of QA datasets is that the answers can be memorized by LLMs or solved with
    simple pattern-matching or keyword-based search.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，强大的 AI 辅助 QA 工具的能力已超越了评估这些工具所需的指标。许多传统的 QA 基准测试，如 Natural Questions Kwiatkowski
    等人 ([2019](#bib.bib31))、TriviaQA Joshi 等人 ([2017](#bib.bib23))、WebQuestions Berant
    等人 ([2013](#bib.bib4))、SearchQA Dunn 等人 ([2017](#bib.bib12))，在现代 LLM 的帮助下或多或少地得到了解决。这些数据集主要由事实性问题组成（来自搜索引擎日志、Trivia、Jeopardy!
    等），答案通常可以在标准预训练的网络语料库中找到，几乎可以肯定存在于其中 ZHOU 等人 ([2023](#bib.bib65))。例如，MS Marco
    Campos 等人 ([2016](#bib.bib9)) 中有高达 55% 的事实性问题 (Bolotova 等人, [2022](#bib.bib5))。这些
    QA 数据集的明显缺陷在于，LLM 可以记住答案，或通过简单的模式匹配或基于关键词的搜索来解决这些问题。
- en: Multi-hop reasoning tasks including HotpotQA Yang et al. ([2018](#bib.bib56)),
    HybridQA Chen et al. ([2020](#bib.bib10)), MuSiQue Trivedi et al. ([2022](#bib.bib49))
    aim to challenge QA systems to logically bridge information across multiple documents
    or paragraphs. While these datasets have made strides in increasing question complexity,
    the answers are still ultimately factoid, and it’s clear what sub-questions ought
    to be asked to recall the missing information. Furthermore, the construction of
    these datasets (e.g. synthetically generated from paths of wikipedia links) leads
    to a distribution mismatch w.r.t questions humans ask.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 多跳推理任务，包括 HotpotQA Yang 等人 ([2018](#bib.bib56))、HybridQA Chen 等人 ([2020](#bib.bib10))、MuSiQue
    Trivedi 等人 ([2022](#bib.bib49))，旨在挑战 QA 系统在多个文档或段落之间逻辑性地桥接信息。尽管这些数据集在增加问题复杂性方面取得了进展，但答案仍然是最终的事实性问题，明确了应该问哪些子问题以回忆缺失的信息。此外，这些数据集的构建（例如，从维基百科链接路径合成生成）导致了与人类提问的问题之间的分布不匹配。
- en: There exist several sources of long-form, non-factoid QA datasets like ELI5 Fan
    et al. ([2019](#bib.bib14)), Stack Exchange, Yahoo Answers Zhang et al. ([2016](#bib.bib61)),
    and WikiHowQA Bolotova-Baranova et al. ([2023](#bib.bib6)). While answers to these
    questions are more involved than factoid questions, ELI5 and WikiHowQA elicit
    more expository answers than analytical ones. The Oxford Allsouls dataset Liu
    et al. ([2023b](#bib.bib35)) contains 1k college-level essay prompts which are
    multi-perspective, but are designed to evaluate persuasive writing skills and
    do not have associated documents to ground responses. AQuaMuSe Kulkarni et al.
    ([2020](#bib.bib30)) is an excellent attempt at filtering Natural Questions (NQ)
    for multi-faceted queries, but their method was constrained by relying on the
    relatively short paragraph-length answers already present in NQ.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 存在一些长篇非事实型问答数据集，如 ELI5 Fan et al. ([2019](#bib.bib14))、Stack Exchange、Yahoo
    Answers Zhang et al. ([2016](#bib.bib61)) 和 WikiHowQA Bolotova-Baranova et al.
    ([2023](#bib.bib6))。尽管这些问题的答案比事实型问题更为复杂，但 ELI5 和 WikiHowQA 更倾向于引导描述性回答而非分析性回答。牛津
    Allsouls 数据集 Liu et al. ([2023b](#bib.bib35)) 包含 1000 个大学水平的论文题目，这些题目是多角度的，但旨在评估说服写作技能，并且没有关联的文档来支持回答。AQuaMuSe
    Kulkarni et al. ([2020](#bib.bib30)) 是过滤自然问题 (NQ) 中多方面查询的一个出色尝试，但其方法受到依赖 NQ 中相对较短段落长度回答的限制。
- en: '| Researchy Question: how does public transport help the economy |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 研究问题：公共交通如何帮助经济 |'
- en: '| --- |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| Hierarchical Decomposition of the Question | Clicked Clueweb22 URLs |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| 问题的层次分解 | 点击的 Clueweb22 URLs |'
- en: '| 1. What is public transport? (a) What are the different types of public transport?
    (b) How many people use public transport in different regions or countries? 2.
    What are the direct economic benefits of public transport? (a) How public transport
    reduces costs for users e.g. fuel, parking, maintenance, etc.? (b) How does public
    transport generate revenue… 3. What are the indirect economic benefits of public
    transport? (a) How does public transport reduce congestion… (b) How does public
    transport increase access to education, employment, health, … (c) How does public
    transport enhance productivity and innovation… (d) How does public transport contribute
    to environmental and social goals… 4. How do the economic benefits of public transport
    compare to the costs of providing and maintaining public transport? (a) What are
    the main costs of public transport… (b) How are the costs of public transport
    financed… (c) How are the benefits and costs of public transport measured and
    evaluated… | 1. [infrastructureusa.org](https://infrastructureusa.org/the-economic-impact-of-public-transportation)
    2. [nationalgeographic.org](https://nationalgeographic.org/article/effects-transportation-economy)
    3. [quora.com](https://quora.com/how-does-public-transportation-help-the-economy)
    4. [accessmagazine.org](https://accessmagazine.org/spring-2012/can-public-transportation-increase-economic-efficiency)
    5. [ced.berkeley.edu](https://frameworks.ced.berkeley.edu/2014/the-economic-benefits-of-transit-service)
    6. [greenertransportsolutions](https://greenertransportsolutions.com/guidance-tool/relationship-between-transport-economy)
    7. [bts.gov](https://bts.gov/topics/transportation-and-economy) 8. [apta.com](https://apta.com/research-technical-resources/economic-impact-of-public-transit)
    |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 1. 什么是公共交通？ (a) 公共交通有哪些不同的类型？ (b) 不同地区或国家有多少人使用公共交通？ 2. 公共交通的直接经济利益是什么？ (a)
    公共交通如何降低用户的成本，例如燃料、停车、维护等？ (b) 公共交通如何产生收入… 3. 公共交通的间接经济利益是什么？ (a) 公共交通如何减少拥堵…
    (b) 公共交通如何增加对教育、就业、健康的访问… (c) 公共交通如何提高生产力和创新… (d) 公共交通如何促进环境和社会目标… 4. 公共交通的经济利益与提供和维护公共交通的成本相比如何？
    (a) 公共交通的主要成本是什么… (b) 公共交通的成本如何融资… (c) 公共交通的利益和成本如何衡量和评估… | 1. [infrastructureusa.org](https://infrastructureusa.org/the-economic-impact-of-public-transportation)
    2. [nationalgeographic.org](https://nationalgeographic.org/article/effects-transportation-economy)
    3. [quora.com](https://quora.com/how-does-public-transportation-help-the-economy)
    4. [accessmagazine.org](https://accessmagazine.org/spring-2012/can-public-transportation-increase-economic-efficiency)
    5. [ced.berkeley.edu](https://frameworks.ced.berkeley.edu/2014/the-economic-benefits-of-transit-service)
    6. [greenertransportsolutions](https://greenertransportsolutions.com/guidance-tool/relationship-between-transport-economy)
    7. [bts.gov](https://bts.gov/topics/transportation-and-economy) 8. [apta.com](https://apta.com/research-technical-resources/economic-impact-of-public-transit)
    |'
- en: '| Example of a Pivotal Fact from URL: [accessmagazine.org](https://accessmagazine.org/spring-2012/can-public-transportation-increase-economic-efficiency)
    “…Even in cities with a high concentration of office space in the [central business
    district], we estimate that increasing transit ridership by 10 percent will increase
    office rents by no more than 0.5 percent. For all other cities, we estimate that
    increasing transit ridership will have no effect on office rents…” |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 来自网址的关键事实示例：[accessmagazine.org](https://accessmagazine.org/spring-2012/can-public-transportation-increase-economic-efficiency)
    “……即使在办公空间集中在[中央商务区]的城市中，我们估计将公共交通乘客增加10%将使办公室租金最多增加0.5%。对于所有其他城市，我们估计增加公共交通乘客将不会对办公室租金产生影响……”
    |'
- en: 'Table 2: An example Researchy Question, how GPT-4 decomposed it into sub-questions
    (closed-book), as well the URLs in ClueWeb22 that real users clicked on, and an
    example of a Pivotal Fact from one of those URLs.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：一个研究性问题的示例，GPT-4如何将其分解为子问题（闭卷），以及真实用户点击的ClueWeb22中的网址，还有这些网址之一的关键事实示例。
- en: The rise of “LLM Agents” e.g.  Wu et al. ([2023b](#bib.bib54)) have opened the
    door for even deeper collaboration between users, LLMs, and tools. In response,
    more recent datasets have focused on completing challenging tasks in open-ended
    environments with tools like a web browser, file system, database, etc.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: “LLM Agents”的兴起，例如吴等人（[2023b](#bib.bib54)），为用户、LLM和工具之间更深层次的协作打开了大门。作为回应，最近的数据集更多地关注在开放环境中使用如网页浏览器、文件系统、数据库等工具来完成挑战性任务。
- en: In particular, Gaia Mialon et al. ([2023](#bib.bib37)) tests understanding of
    multi-modal inputs (images and text), as well as complex reasoning across levels
    of difficulty to solve. AgentBench Liu et al. ([2023c](#bib.bib36)) provides closed
    environments for an LLM to interact with APIs in various scenarios, including
    coding (interacting with file systems or databases), games/puzzles, and web browsing/shopping.
    While these datasets advance the field of metrics for LLM agents, they are small,
    consisting of only 466 and 1,091 questions respectively that were hand-curated
    by the authors.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，Gaia Mialon等人（[2023](#bib.bib37)）测试了对多模态输入（图像和文本）的理解，以及解决不同难度层次的复杂推理。AgentBench
    Liu等人（[2023c](#bib.bib36)）为LLM提供了封闭环境，以便在各种场景中与API交互，包括编码（与文件系统或数据库交互）、游戏/谜题以及网页浏览/购物。尽管这些数据集推动了LLM代理的度量领域的发展，但它们的规模较小，分别只有466个和1091个由作者手动策划的问题。
- en: 'The need for more challenging QA datasets also stems from some alarming trends:
    while there are hundreds of public LLMs, they are pretrained on only a handful
    existing corpora Gao et al. ([2020](#bib.bib15)); Raffel et al. ([2023](#bib.bib44)),
    or distilled from one of a few teacher LLMs Peng et al. ([2023](#bib.bib41)).
    Furthermore, much more data scraped from the internet for training is itself going
    to be AI-generated content, leading to an echo-chamber effect Dohmatob et al.
    ([2024](#bib.bib11)); Wu et al. ([2023a](#bib.bib53)). Hence, the convergent evolution Stayton
    ([2015](#bib.bib47)) of LLMs increases the risk that they will not recognize that
    they don’t know something, e.g. see GPT-4 and Mixtral 8x7b in Table [10](#A1.T10
    "Table 10 ‣ A.1 Additional Safety Filtering ‣ Appendix A GPT-4-based Filtering
    Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents"). This is especially true when LLMs act in the capacity
    of LLM-as-a-judge Zheng et al. ([2023a](#bib.bib63)); Yuan et al. ([2024](#bib.bib59)),
    or when faced with very multi-faceted/multi-perspective questions, where the consequences
    could be that users “miss the whole picture” or worse, are misled Zheng et al.
    ([2023b](#bib.bib64)); Liu et al. ([2023b](#bib.bib35)). While retrieval-augmentation Lewis
    et al. ([2021](#bib.bib32)); Borgeaud et al. ([2022](#bib.bib7)); Guu et al. ([2020](#bib.bib17))
    can help complement LLM agents, the risk is merely shifted to whether a sub-system
    retrieves the right information and uses it correctly Liu et al. ([2023a](#bib.bib34)).'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '对于更具挑战性的 QA 数据集的需求还源于一些令人担忧的趋势：尽管有数百个公共 LLM，但它们仅在少数现有语料库上进行预训练 Gao et al. ([2020](#bib.bib15))；Raffel
    et al. ([2023](#bib.bib44))，或从少数几种教师 LLM Peng et al. ([2023](#bib.bib41)) 中提炼而来。此外，从互联网抓取的大量训练数据本身也将是
    AI 生成的内容，导致了回音室效应 Dohmatob et al. ([2024](#bib.bib11))；Wu et al. ([2023a](#bib.bib53))。因此，LLM
    的趋同进化 Stayton ([2015](#bib.bib47)) 增加了它们无法识别自己不知道某些内容的风险，例如，见表 [10](#A1.T10 "Table
    10 ‣ A.1 Additional Safety Filtering ‣ Appendix A GPT-4-based Filtering Details
    ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional Questions
    for LLM Web Agents") 中的 GPT-4 和 Mixtral 8x7b。当 LLM 作为 LLM-as-a-judge 行事时 Zheng
    et al. ([2023a](#bib.bib63))；Yuan et al. ([2024](#bib.bib59))，或面对非常多方面/多角度的问题时，这一点尤其如此，可能导致用户“错过全貌”或更糟，被误导 Zheng
    et al. ([2023b](#bib.bib64))；Liu et al. ([2023b](#bib.bib35))。虽然检索增强 Lewis et
    al. ([2021](#bib.bib32))；Borgeaud et al. ([2022](#bib.bib7))；Guu et al. ([2020](#bib.bib17))
    可以帮助补充 LLM 代理，但风险仅仅转移到子系统是否检索到正确的信息并正确使用上 Liu et al. ([2023a](#bib.bib34))。'
- en: We believe the well-studied phenomenon of “unknown unknowns” United States Congress
    et al. ([1981](#bib.bib51)) applies to LLM Agents in scenarios addressing complex
    questions requiring “slow thinking” Kahneman ([2011](#bib.bib24)). Simply put,
    one strategy is to iteratively re-frame or decompose the problem into a set of
    “known unknowns” (which characterize most of the aforementioned QA datasets).
    For these sub-problems, it should be clearer what information is missing, how
    to find it, and once found, how the “known known” contributes to the final answer.
    Several techniques such as chain-of-thought question decomposition Radhakrishnan
    et al. ([2023](#bib.bib43)) and tree-of-thought Yao et al. ([2023a](#bib.bib57))
    prompting take a similar approach to plan long-horizon solutions to complex problems.
    However, those studies still operate over traditional QA benchmarks like HotpotQA,
    or over simple games like crossword puzzles. Hence, the right benchmark of questions
    for these advanced decomposition techniques still does not exist for open-domain
    web scenarios Krishna et al. ([2021](#bib.bib29)).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们相信，“未知的未知” United States Congress et al. ([1981](#bib.bib51)) 这一现象适用于处理需要“慢思考”的复杂问题的
    LLM 代理 Kahneman ([2011](#bib.bib24))。简单来说，一种策略是迭代地重新构建或分解问题，将其转化为一组“已知的未知”（这类问题特征大多数出现在前述的
    QA 数据集中）。对于这些子问题，应该更清楚缺少哪些信息，如何找到它，一旦找到，“已知的已知”如何对最终答案作出贡献。几种技术如链式思维问题分解 Radhakrishnan
    et al. ([2023](#bib.bib43)) 和思维树 Yao et al. ([2023a](#bib.bib57)) 提出了一种类似的方法来规划复杂问题的长期解决方案。然而，这些研究仍然基于传统的
    QA 基准如 HotpotQA，或基于简单的游戏如填字谜。因此，针对这些高级分解技术的合适基准仍然不存在于开放领域的网页场景中 Krishna et al.
    ([2021](#bib.bib29))。
- en: 'We present Researchy Questions to study the dynamics of how LLM agents handle
    unclear information needs associated with very complex questions. We define a
    Researchy Question as a *non-factoid* question that expects a *long-form answer*
    (longer than a paragraph!) entailing substantial research or effort to synthesize.
    A Researchy Question can be instantiated as a complex search task Aula and Russell
    ([2008](#bib.bib2)) with unclear information needs that requires analyzing *multiple
    documents* or pieces of evidence. A Researchy Question does not have a single
    correct answer, but rather *multiple perspectives* allowing a dense manifold of
    answers over which varying criteria can determine which is better. In practice,
    the act of answering a Researchy Question probably involves *decomposition* into
    sub-questions that aid the retrieval of comprehensive information, reducing the
    risk of missing unknown unknowns. Lastly, a Researchy Question represents a *genuine
    information need* that real people asked. Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional Questions
    for LLM Web Agents") qualitatively compares other canonical QA datasets.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '我们提出Researchy Questions来研究LLM代理处理与非常复杂问题相关的不明确信息需求的动态。我们将Researchy Question定义为一个*非事实型*问题，期望*长篇答案*（比一段文字还长！），需要大量研究或综合。Researchy
    Question可以实例化为一个复杂的搜索任务Aula和Russell（[2008](#bib.bib2)），具有不明确的信息需求，需要分析*多个文档*或证据。Researchy
    Question没有单一的正确答案，而是*多个视角*，允许在一个密集的答案空间中，通过不同的标准来确定哪个更好。在实际操作中，回答Researchy Question可能涉及到*分解*成子问题，以帮助检索全面的信息，降低遗漏未知未知的风险。最后，Researchy
    Question代表了真实人们提出的*真正的信息需求*。图[1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Researchy
    Questions: A Dataset of Multi-Perspective, Decompositional Questions for LLM Web
    Agents")定性比较了其他经典QA数据集。'
- en: Researchy Questions is primarily a QA dataset to evaluate question answering
    systems or LLM Agents with the ultimate goal of achieving ever higher-quality
    answers using any tools necessary. Notwithstanding, it is also a search/retrieval
    dataset in the sense that finding and correctly incorporating the right evidence
    is a critical sub-system to meet expectations of trustworthiness and groundedness Zheng
    et al. ([2023b](#bib.bib64)); Liu et al. ([2023b](#bib.bib35)). While we believe
    that question decomposition is a critical piece of solving Researchy Questions ,
    it is unclear how to define or measure the quality of sub-questions. To aid this
    endeavor, we reveal what URLs end users found useful, with the hope that good
    sub-questions will at least lead to the information found in those clicked documents.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Researchy Questions主要是一个QA数据集，用于评估问答系统或LLM Agents，其*最终目标*是利用任何必要的工具实现更高质量的答案。然而，它也可以被视为一个搜索/检索数据集，因为找到并正确整合正确的证据是满足可信度和基础性期望的关键子系统。尽管我们认为问题分解是解决Researchy
    Questions的关键环节，但如何定义或衡量子问题的质量仍不清楚。为了帮助这一工作，我们揭示了最终用户认为有用的网址，希望好的子问题至少能引导到这些被点击文档中的信息。
- en: 'We release about 96K Researchy Questions consisting of real users’ queries
    to a commercial search engine, and additionally:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发布了大约96K个Researchy Questions，其中包括真实用户对商业搜索引擎的查询，此外：
- en: '1.'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: 'The decomposition of the question into a 2-level hierarchical plan (See Table [2](#S1.T2
    "Table 2 ‣ 1 Introduction ‣ Researchy Questions: A Dataset of Multi-Perspective,
    Decompositional Questions for LLM Web Agents") Left).'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '将问题分解为2级层次计划（见表[2](#S1.T2 "Table 2 ‣ 1 Introduction ‣ Researchy Questions:
    A Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents")左侧）。'
- en: '2.'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: For each question, the user-aggregated click distribution over URLs in a publicly
    available web corpus, ClueWeb22.
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于每个问题，用户汇总的点击分布基于一个公开可用的网络语料库ClueWeb22中的网址。
- en: '3.'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: Ordered list of sub-queries corresponding roughly to the sub-questions that
    can be readily issued to a search engine
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对应于可以直接向搜索引擎提出的子问题的有序子查询列表。
- en: 'In Section [2](#S2 "2 Researchy Questions Construction ‣ Researchy Questions:
    A Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents")
    we describe how Researchy Questions were obtained and then characterize them in
    Section [3](#S3 "3 Characterizing Researchy Questions ‣ Researchy Questions: A
    Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents").
    In Section [4](#S4 "4 Agreement with User Search Behavior ‣ Researchy Questions:
    A Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents")
    we verify that web users expend more effort on Researchy Questions over other
    queries. In Section [5](#S5 "5 Evaluating Answer Techniques to Researchy Questions
    ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional Questions
    for LLM Web Agents") we evaluate and compare decompositional answering techniques
    from Radhakrishnan et al. ([2023](#bib.bib43)).'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在第[2](#S2 "2 研究性问题构建 ‣ 研究性问题：用于 LLM 网页代理的多视角分解式问题数据集")节中，我们描述了如何获得研究性问题，并在第[3](#S3
    "3 描述研究性问题 ‣ 研究性问题：用于 LLM 网页代理的多视角分解式问题数据集")节中对其进行了特征描述。在第[4](#S4 "4 与用户搜索行为的一致性
    ‣ 研究性问题：用于 LLM 网页代理的多视角分解式问题数据集")节中，我们验证了网络用户在研究性问题上投入的精力超过其他查询。在第[5](#S5 "5 评估研究性问题的回答技术
    ‣ 研究性问题：用于 LLM 网页代理的多视角分解式问题数据集")节中，我们评估并比较了Radhakrishnan 等人 ([2023](#bib.bib43))
    的分解式回答技术。
- en: 2 Researchy Questions Construction
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 研究性问题构建
- en: '| First | MS Marco | QnA | Non-factoid | Researchy ($\downarrow$) |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| First | MS Marco | QnA | 非事实 | 研究性 ($\downarrow$) |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| how | 17.0% | 34.3% | 29.4% | 41.2% |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| how | 17.0% | 34.3% | 29.4% | 41.2% |'
- en: '| why | 1.64% | 6.26% | 33.4% | 22.9% |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| why | 1.64% | 6.26% | 33.4% | 22.9% |'
- en: '| what | 34.9% | 12.2% | 21.3% | 19.1% |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| what | 34.9% | 12.2% | 21.3% | 19.1% |'
- en: '| is/are/do | 5.77% | 15.0% | 6.50% | 9.67% |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| is/are/do | 5.77% | 15.0% | 6.50% | 9.67% |'
- en: '| should | 0.11% | 0.53% | 0.59% | 1.85% |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| should | 0.11% | 0.53% | 0.59% | 1.85% |'
- en: '| can | 1.84% | 4.31% | 1.01% | 0.97% |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| can | 1.84% | 4.31% | 1.01% | 0.97% |'
- en: '| who | 3.27% | 4.77% | 0.90% | 0.47% |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| who | 3.27% | 4.77% | 0.90% | 0.47% |'
- en: '| which | 1.78% | 2.78% | 1.87% | 0.46% |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| which | 1.78% | 2.78% | 1.87% | 0.46% |'
- en: '| when | 2.70% | 5.03% | 0.44% | 0.43% |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| when | 2.70% | 5.03% | 0.44% | 0.43% |'
- en: '| pros | $<$ 0.01% | 0.03% | 0.45% | 0.28% |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| pros | $<$ 0.01% | 0.03% | 0.45% | 0.28% |'
- en: '| explain | 0.05% | 0.06% | 0.12% | 0.23% |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| explain | 0.05% | 0.06% | 0.12% | 0.23% |'
- en: '| where | 3.54% | 4.08% | 0.37% | 0.17% |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| where | 3.54% | 4.08% | 0.37% | 0.17% |'
- en: '| factors | $<$ 0.01% | 0.01% | 0.08% | 0.15% |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| factors | $<$ 0.01% | 0.01% | 0.08% | 0.15% |'
- en: '| will | 0.10% | 0.69% | 0.08% | 0.15% |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| will | 0.10% | 0.69% | 0.08% | 0.15% |'
- en: '| describe | 0.05% | 0.07% | 0.04% | 0.09% |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| describe | 0.05% | 0.07% | 0.04% | 0.09% |'
- en: 'Table 3: Top most-prevalent first-words of the three main stages of our question
    filtering funnel (with MS Marco for comparison).'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：我们问题筛选漏斗的三个主要阶段的最常见首词（与 MS Marco 进行比较）。
- en: Researchy Questions are real user queries from search logs. While search logs
    have a rich diversity of query types and intents Bolotova et al. ([2022](#bib.bib5));
    Bu et al. ([2010](#bib.bib8)), they mostly contain factoid or navigational queries,
    which need to be filtered.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 研究性问题是来自搜索日志的真实用户查询。尽管搜索日志具有丰富的查询类型和意图多样性 Bolotova 等 ([2022](#bib.bib5)); Bu
    等 ([2010](#bib.bib8))，但它们主要包含事实性或导航性查询，需要进行筛选。
- en: '2.1 Stage 1: Mining Search Logs'
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 阶段 1：挖掘搜索日志
- en: '| Query Type | Count |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 查询类型 | 计数 |'
- en: '&#124; Avg. unique &#124;'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 平均唯一 &#124;'
- en: '&#124; clicked urls &#124;'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 点击的 URL &#124;'
- en: '|'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Avg. &#124;'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 平均值 &#124;'
- en: '&#124; clicks &#124;'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 点击数 &#124;'
- en: '|'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Avg. sat. &#124;'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 平均满意度 &#124;'
- en: '&#124; clicks &#124;'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 点击数 &#124;'
- en: '|'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| General Queries | $\geq 1B$ | 1.88 | 4.83 | 2.54 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 一般查询 | $\geq 1B$ | 1.88 | 4.83 | 2.54 |'
- en: '| QnA Queries | 15.7M | 3.99 | 9.31 | 5.10 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 问答查询 | 15.7M | 3.99 | 9.31 | 5.10 |'
- en: '| Non-factoid QnA | 1.0M | 4.20 | 8.99 | 4.86 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 非事实问答 | 1.0M | 4.20 | 8.99 | 4.86 |'
- en: '| Researchy Queries | 100k | 6.31 | 15.85 | 8.54 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 研究性查询 | 100k | 6.31 | 15.85 | 8.54 |'
- en: '| Session Type | Count | # Turns |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 会话类型 | 计数 | 回合数 |'
- en: '&#124; # unique. &#124;'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 唯一数量 &#124;'
- en: '&#124; queries &#124;'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 查询数 &#124;'
- en: '|'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; # sat &#124;'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; # 满意度 &#124;'
- en: '&#124; clicks &#124;'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 点击数 &#124;'
- en: '|'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| General Sessions | $\geq 10B$ | 2.42 | 2.11 | 0.76 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 一般会话 | $\geq 10B$ | 2.42 | 2.11 | 0.76 |'
- en: '| QnA Sessions | $\geq 100M$ | 6.28 | 5.53 | 1.15 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 问答会话 | $\geq 100M$ | 6.28 | 5.53 | 1.15 |'
- en: '| N.F. QnA Sessions | $\geq 10M$ | 12.89 | 11.33 | 1.91 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 非事实问答会话 | $\geq 10M$ | 12.89 | 11.33 | 1.91 |'
- en: '| Researchy Sessions | $\geq 1M$ | 13.45 | 11.81 | 2.46 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 研究性会话 | $\geq 1M$ | 13.45 | 11.81 | 2.46 |'
- en: 'Table 4: Our query filtering funnel; each row is a subset from the row above
    it. (Left) Researchy Questions have much more clicks (Sat clicks have longer dwelltime),
    and require more unique documents; the full distribution is in Figure [2](#A1.F2
    "Figure 2 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A
    Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents").
    (Right) Search statistics per session in which each type of query appeared, indicating
    that harder questions appear in longer sessions. These behaviors confirm our filtering
    yields more complex questions.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 表4：我们的查询过滤漏斗；每一行是上一行的一个子集。 (左) 研究性问题的点击量要多得多（满意的点击有更长的停留时间），并且需要更多的独特文档；完整的分布见图[2](#A1.F2
    "图2 ‣ 附录A GPT-4基础的过滤细节 ‣ 研究性问题：LLM网络代理的多视角分解问题数据集")。 (右) 每种查询类型出现的每次会话的搜索统计，显示较难的问题出现在较长的会话中。这些行为确认我们的过滤方法产生了更复杂的问题。
- en: We obtained a set of query-url click pairs from a commercial search engine that
    were logged between July 2021 and August 2022, which maximally overlaps with the
    creation of the Clueweb22 snapshot of web documents Overwijk et al. ([2022](#bib.bib40)).
    This way, we can simply indicate which Researchy Questions clicked on which documents.
    We began with a large sample of english, non-adult queries that had least one
    click. We denote these as “General Queries”, which were further filtered.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从一个商业搜索引擎中获得了一组查询-URL点击对，这些记录在2021年7月至2022年8月之间，最大程度地与Clueweb22网页文档快照的创建重叠[Overwijk
    et al. (2022)](#bib.bib40)。这样，我们可以简单地指明哪些研究性问题点击了哪些文档。我们从一个大样本的英语、非成人查询开始，这些查询至少有一次点击。我们称这些为“通用查询”，它们进一步被筛选。
- en: 'An important filtering criteria is frequency: we kept queries if they were
    issued at least 50 times in the logs. This criteria is simple but powerful: it
    helps denoise the dataset (reduces spelling errors), and also allows us to focus
    on questions that are not “one-offs”. This helps us glean insights into repeated
    user behaviors as they interact with the search engine.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的过滤标准是频率：我们保留了在日志中至少出现50次的查询。这个标准简单而有效：它有助于去噪数据集（减少拼写错误），同时也使我们能够关注那些不是“偶发”的问题。这帮助我们在用户与搜索引擎互动时洞察重复的用户行为。
- en: 'In order to select queries which are answer-seeking intent (i.e. actual “questions”
    as distinct from navigational queries like “facebook login”, shopping intent like
    “fast running shoes”, or local intent like “best pizza near me”), we used a suite
    of rules and existing production classifiers:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 为了选择具有回答意图的查询（即实际的“问题”，与“facebook登录”等导航查询、如“快跑鞋”的购物意图或“离我最近的好披萨”的本地意图不同），我们使用了一套规则和现有的生产分类器：
- en: •
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Query Language: English'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 查询语言：英语
- en: •
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Adult intent: False'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 成人意图：错误
- en: •
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Number of Distinct Occurrences: $\geq$ 50'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 独特出现次数：$\geq$ 50
- en: •
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 3 $\leq$ 15
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 3 $\leq$ 15
- en: •
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Number of Distinct URLs Clicked On: $\geq 2$'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 点击的独特URL数量：$\geq 2$
- en: •
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Question Intent Classifier: True'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 问题意图分类器：正确
- en: •
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Navigational Intent: False'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 导航意图：错误
- en: •
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Local / Real Estate / Map Intent: False'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本地/房地产/地图意图：错误
- en: •
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Retail/Shopping Intent: False'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 零售/购物意图：错误
- en: •
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Coding/Technical Intent: False'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编程/技术意图：错误
- en: •
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Health/Medical Intent: False'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 健康/医疗意图：错误
- en: •
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Triggered Possible Answer Cards: $\geq 1$'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 触发的可能答案卡：$\geq 1$
- en: •
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Triggered lots of Ads: False'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 触发了大量广告：错误
- en: 'To explain some of the points above: an Answer Card is a high-precision feature
    in a search engine where a paragraph containing the answer is shown at the top
    of the results page, distinct from the “ten blue links”. Because search engines
    are constantly being updated with new features and triggering rules, all the above
    statistics are aggregated and normalized over the full year period. For instance,
    “a lot of Ads” is determined by summing the total number of ads shown for the
    query over the full year and dividing by the number of times the query was issued,
    and then picking a threshold above which queries seemed “shopping intent”. The
    Ads requirement also helped catch any shopping intent queries missed by the Retail
    intent classifier.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明上述一些要点：答案卡是搜索引擎中的一种高精度功能，其中包含答案的段落显示在结果页面的顶部，与“十个蓝色链接”不同。由于搜索引擎不断更新新功能和触发规则，上述所有统计数据都在全年度范围内进行汇总和标准化。例如，“大量广告”是通过对查询显示的广告总数进行求和，再除以查询发起的次数，然后选择一个阈值来确定哪些查询似乎具有“购物意图”。广告要求也帮助捕捉到零售意图分类器遗漏的任何购物意图查询。
- en: We wanted to remove Coding/Technical queries because such questions are often
    motivated by very specific problems that are often solved by one piece of documentation
    after lots of clicking around, which is not the behavior we wish to target in
    this dataset. Health and medical questions are avoided largely because they often
    overlap too much with those that ought to be addressed by a licensed medical professional.
    Many shopping / retail queries could be construed as “researchy” e.g. “what are
    the best headphones”, but we avoid them in this dataset because it is hard to
    distinguish whether a URL was clicked due to aggressive advertising or a real
    information need.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望排除编程/技术类问题，因为这类问题通常是由非常具体的问题驱动的，通常通过大量点击后的单一文档解决，这不是我们希望在此数据集中针对的行为。健康和医学问题大多被避免，因为它们通常与应该由持证医疗专业人员处理的问题重叠过多。许多购物/零售问题可以被视为“研究性”的，例如“最好的耳机是什么”，但我们在这个数据集中避免了这些问题，因为很难区分点击
    URL 是否是由于强力广告还是实际的信息需求。
- en: After this stage of filtering, we arrived at 15.7M “QnA Queries” which are largely
    recognizable as natural language questions that deal with open-domain knowledge.
    This size was manageable enough to efficiently run our own bert-large scale classifiers
    we use in the next stage of filtering.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个筛选阶段之后，我们得到了 1570 万个“问答查询”，这些查询大多可以识别为处理开放领域知识的自然语言问题。这个数量足够管理，可以高效地运行我们在下一阶段筛选中使用的
    bert-large 规模分类器。
- en: '2.2 Stage 2: Factoid Classifier'
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 阶段 2：事实型分类器
- en: 'We needed a way to distinguish which QnA Queries were factoid vs. non-factoid;
    we trained a binary classifier on auto-labeled data for this purpose. The training
    data was a uniform sample of 200k questions from the 15.7M QnA Queries. Labels
    for the questions were collected from gpt3 (text-davinci-003) prompted with few-shot
    examples as shown in Figure [4](#A1.F4 "Figure 4 ‣ Appendix A GPT-4-based Filtering
    Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents"). The labels were then used to train a bert-large
    non-factoid question classifier, which was then inferenced on the full set of
    15.7M queries. By manual inspection, a threshold was chosen above which we were
    satisfied that the questions were meaningfully non-factoid. The resulting 1.0M
    met the non-factoid threshold of 0.75 as shown on the left hand side of Figure [3](#A1.F3
    "Figure 3 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A
    Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents"),
    which we denote as ”Non-factoid QnA Queries”.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一种方法来区分哪些问答查询是事实型的还是非事实型的；为此我们在自动标记的数据上训练了一个二分类器。训练数据是从 1570 万个问答查询中均匀抽取的
    20 万个问题。问题的标签是通过向 gpt3 (text-davinci-003) 提供少量示例来收集的，如图 [4](#A1.F4 "图 4 ‣ 附录 A
    GPT-4 基于的过滤详细信息 ‣ 研究性问题：多角度、分解型问题的数据集") 所示。然后使用这些标签训练了一个 bert-large 非事实型问题分类器，该分类器随后在全套
    1570 万个查询上进行了推理。通过人工检查，选择了一个阈值，在该阈值以上我们认为问题具有实质性的非事实型特征。结果中 100 万个满足了 0.75 的非事实型阈值，如图
    [3](#A1.F3 "图 3 ‣ 附录 A GPT-4 基于的过滤详细信息 ‣ 研究性问题：多角度、分解型问题的数据集") 左侧所示，我们将其称为“非事实型问答查询”。
- en: '2.3 Stage 3: Decompositional Classifier'
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 阶段 3：分解型分类器
- en: 'Not all the resulting non-factoid QnA queries exhibited the “decompositional”
    information needs. Namely, they often looked expository or “how-to” with generally
    one correct answer which did not have many perspectives. We trained a second classifier
    to score the extent to which a question requires asking sub-questions. The specific
    definition of “requiring sub-questions” is described in a prompt in Figure [5](#A1.F5
    "Figure 5 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A
    Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents") given
    to ChatGPT (gpt-35-turbo) to collect labels. We used ChatGPT because we figured
    this was a relatively intense cognitive task. We inferenced ChatGPT on about 40k
    outputs from the non-factoid classifier that met the non-factoid threshold of
    0.75\. We used the labels to train a separate bert-large “decompositional” classifier.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '并非所有生成的非事实型问答查询都表现出“分解性”信息需求。也就是说，它们通常看起来是阐述性的或“如何做”类型的问题，通常只有一个正确答案，并没有很多的视角。我们训练了第二个分类器来评估一个问题是否需要提出子问题。关于“需要子问题”的具体定义在图 [5](#A1.F5
    "Figure 5 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A
    Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents")中的提示中描述，这个提示被用于收集ChatGPT
    (gpt-35-turbo)的标签。我们使用了ChatGPT，因为我们认为这是一个相对复杂的认知任务。我们对约4万条符合非事实型阈值0.75的分类器输出进行了推理。我们使用这些标签来训练一个独立的bert-large“分解性”分类器。'
- en: 'Again, we chose a threshold by manual inspection to indicate which of the 1.0M
    Non-factoid QnA Queries were also decompositional, which happened to be 0.6 as
    shown on the right-hand side of Figure [3](#A1.F3 "Figure 3 ‣ Appendix A GPT-4-based
    Filtering Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents"). Out of the 1.0M queries that met the non-factoid
    threshold, 146k also met the decompositional threshold. These 146k became the
    Researchy Questions candidates before deduplication. This procedure is not perfect;
    in Table [6](#A1.T6 "Table 6 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy
    Questions: A Dataset of Multi-Perspective, Decompositional Questions for LLM Web
    Agents") we show examples of some non-factoid questions that did not meet the
    decompositional threshold.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '同样，我们通过人工检查选择了一个阈值，以指示1.0M非事实型问答查询中哪些也是分解性的，最终的阈值是0.6，如图 [3](#A1.F3 "Figure
    3 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A Dataset
    of Multi-Perspective, Decompositional Questions for LLM Web Agents")右侧所示。在符合非事实型阈值的1.0M查询中，有146k也满足了分解性阈值。这146k个查询成为去重前的Researchy
    Questions候选。这个过程并不完美；在表 [6](#A1.T6 "Table 6 ‣ Appendix A GPT-4-based Filtering
    Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents")中，我们展示了一些未满足分解性阈值的非事实型问题的示例。'
- en: '2.4 Stage 4: Deduplication'
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 阶段 4：去重
- en: The final step of filtering is deduplication. We take an agglomerative clustering
    approach  Everitt ([1974](#bib.bib13)), where the only parameter is a distance
    threshold $\epsilon$ below which two queries are considered “duplicate intent”.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的过滤步骤是去重。我们采用了聚合聚类的方法 Everitt ([1974](#bib.bib13))，其中唯一的参数是一个距离阈值$\epsilon$，低于该阈值的两个查询被认为是“意图重复”。
- en: We represent the semantic intent of a query by an ANCE-based Xiong et al. ([2020](#bib.bib55))
    vector encoder $\overrightarrow{q_{i}}\leftarrow\texttt{encoder}(q_{i})$. We found
    that about 63% of queries were singletons (did not belong to a group of size greater
    than one), and the average group size was 3.8\. For example, the queries “*what
    were tanks used for in ww1*”, “*how were the tanks used in ww1*” and “*why were
    tanks needed in ww1*” were all part of the same group. For all groups of size
    greater than one, we selected the query that was issued most often in the logs
    as the representative “head” of the group. After combining the heads of groups
    and singletons, about 70% of queries remained, yielding 102k Researchy Questions .
    Although we did our best to de-duplicate question intent, some clusters of topics
    remain, e.g. a quick keyword count shows about 600 contain the string “ww2”, or
    about 80 for “supreme court”.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过基于ANCE的Xiong等人 ([2020](#bib.bib55)) 向量编码器 $\overrightarrow{q_{i}}\leftarrow\texttt{encoder}(q_{i})$
    来表示查询的语义意图。我们发现大约63%的查询是单例（不属于大于一个的组），平均组大小为3.8。例如，查询“*第一次世界大战中的坦克用于什么*”、“*第一次世界大战中的坦克如何使用*”和“*为什么第一次世界大战中需要坦克*”都属于同一组。对于所有大于一的组，我们选择日志中最常发出的查询作为该组的代表“头”。在合并组的头部和单例后，大约70%的查询保留了下来，共计102k个Researchy
    Questions。尽管我们尽力去重问题意图，但仍然存在一些主题群，例如，快速的关键词统计显示约600个包含字符串“ww2”，或约80个包含“supreme
    court”。
- en: '2.5 Stage 5: Final GPT-4 Filtering'
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.5 阶段 5：最终GPT-4过滤
- en: 'As a final quality control step after deduplication, we had all 102k questions
    labeled by GPT-4 for intrinsic attributes of the question like how multi-faceted
    it is, how reasoning-intensive it is likely to be, etc. The full set of eight
    attributes is defined in Figure [7](#A1.F7 "Figure 7 ‣ Appendix A GPT-4-based
    Filtering Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents"), along with histograms of those scores in Figure [6](#A1.F6
    "Figure 6 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A
    Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents") for
    both Researchy Questions and Natural Questions. All eight are scored on a scale
    of 1-10\. About 3% of 102k questions were removed based on the attributes “ambiguous”
    and “incomplete” which indicate defective questions too difficult to answer; some
    examples are shown in Table [7](#A1.T7 "Table 7 ‣ Appendix A GPT-4-based Filtering
    Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents"). Another 2% were removed for being too “assumptive”,
    meaning the question was phrased in a presumptuous way that was likely to bias
    the answer as shown in Table  [8](#A1.T8 "Table 8 ‣ Appendix A GPT-4-based Filtering
    Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents"). Another 2% was removed for safety reasons as shown
    in Table [9](#A1.T9 "Table 9 ‣ A.1 Additional Safety Filtering ‣ Appendix A GPT-4-based
    Filtering Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents"), where we deem risk of harm too high by attempting
    to answer the question. Not all “assumptive” questions are harmful per se. Finally,
    the remaining 96k queries are what we release.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 作为去重后的最终质量控制步骤，我们让 GPT-4 为所有 102k 个问题标注了问题的内在属性，如多面性、推理密集程度等。八个属性的完整集合在图 [7](#A1.F7
    "图 7 ‣ 附录 A GPT-4 基于的过滤详细信息 ‣ 研究性问题：面向 LLM 网络代理的多视角分解性问题数据集")中定义，同时在图 [6](#A1.F6
    "图 6 ‣ 附录 A GPT-4 基于的过滤详细信息 ‣ 研究性问题：面向 LLM 网络代理的多视角分解性问题数据集")中展示了这些分数的直方图，涵盖了研究性问题和自然问题。这八个属性的评分范围为
    1-10。约 3% 的 102k 个问题因属性“模糊”和“不完整”而被移除，这些属性表示问题太难回答；一些示例见表 [7](#A1.T7 "表 7 ‣ 附录
    A GPT-4 基于的过滤详细信息 ‣ 研究性问题：面向 LLM 网络代理的多视角分解性问题数据集")。另有 2% 的问题因过于“假设性”而被移除，这意味着问题的措辞可能会偏向性地影响答案，如表
    [8](#A1.T8 "表 8 ‣ 附录 A GPT-4 基于的过滤详细信息 ‣ 研究性问题：面向 LLM 网络代理的多视角分解性问题数据集") 所示。还有
    2% 的问题因安全原因被移除，如表 [9](#A1.T9 "表 9 ‣ A.1 额外安全过滤 ‣ 附录 A GPT-4 基于的过滤详细信息 ‣ 研究性问题：面向
    LLM 网络代理的多视角分解性问题数据集") 所示，我们认为尝试回答这些问题的风险过高。并非所有“假设性”问题本身都是有害的。最后，剩余的 96k 个查询就是我们发布的内容。
- en: '| Method | Samples | Direct Answer | CoT decomp. | Factor decomp. | Decomp.
    |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 样本 | 直接回答 | CoT 分解 | 因子分解 | 总分 |'
- en: '| Acc. | Score | Acc. | Score | Acc. | Score | Score gain |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 准确率 | 分数 | 准确率 | 分数 | 准确率 | 分数 | 分数增益 |'
- en: '| Hotpot QA | 300 | 0.843 | 83.4 | 0.877 | 83.5 | 0.837 | 81.3 | +0.1 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| Hotpot QA | 300 | 0.843 | 83.4 | 0.877 | 83.5 | 0.837 | 81.3 | +0.1 |'
- en: '| OpenBook QA | 300 | 0.926 | 86.1 | 0.843 | 83.5 | 0.750 | 80.7 | -2.6 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| OpenBook QA | 300 | 0.926 | 86.1 | 0.843 | 83.5 | 0.750 | 80.7 | -2.6 |'
- en: '| Strategy QA | 300 | 0.757 | 80.8 | 0.810 | 83.7 | 0.777 | 82.6 | +2.9 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| Strategy QA | 300 | 0.757 | 80.8 | 0.810 | 83.7 | 0.777 | 82.6 | +2.9 |'
- en: '| Truthful QA | 300 | 0.703 | 73.7 | 0.789 | 82.4 | 0.739 | 81.5 | +8.7 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 真实问答 | 300 | 0.703 | 73.7 | 0.789 | 82.4 | 0.739 | 81.5 | +8.7 |'
- en: '| Aquamuse | 300 | 0.916 | 83.0 | 0.940 | 84.9 | 0.926 | 85.0 | +2.0 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| Aquamuse | 300 | 0.916 | 83.0 | 0.940 | 84.9 | 0.926 | 85.0 | +2.0 |'
- en: '| Reddit/askh | 300 | 0.759 | 79.8 | 0.736 | 77.3 | 0.732 | 79.3 | -0.5 |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| Reddit/askh | 300 | 0.759 | 79.8 | 0.736 | 77.3 | 0.732 | 79.3 | -0.5 |'
- en: '| Reddit/asks | 300 | 0.783 | 81.1 | 0.743 | 79.4 | 0.796 | 82.7 | +1.6 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| Reddit/asks | 300 | 0.783 | 81.1 | 0.743 | 79.4 | 0.796 | 82.7 | +1.6 |'
- en: '| Reddit/eli5 | 300 | 0.883 | 83.1 | 0.890 | 85.0 | 0.890 | 86.5 | +3.4 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| Reddit/eli5 | 300 | 0.883 | 83.1 | 0.890 | 85.0 | 0.890 | 86.5 | +3.4 |'
- en: '| StackExchange | 300 | 0.717 | 78.4 | 0.599 | 70.7 | 0.628 | 73.4 | -5.0 |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| StackExchange | 300 | 0.717 | 78.4 | 0.599 | 70.7 | 0.628 | 73.4 | -5.0 |'
- en: '| Wikihow QA | 300 | 0.93 | 82.9 | 0.937 | 84.4 | 0.950 | 88.2 | +5.3 |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| Wikihow QA | 300 | 0.93 | 82.9 | 0.937 | 84.4 | 0.950 | 88.2 | +5.3 |'
- en: '| Researchy Questions | 1k | N/A | 82.7 | N/A | 84.6 | N/A | 88.3 | +5.6 |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 研究性问题 | 1k | 不适用 | 82.7 | 不适用 | 84.6 | 不适用 | 88.3 | +5.6 |'
- en: 'Table 5: Comparison of various question decomposition techniques to prompt
    GPT-4 as an answer module. The top half of the table is short-form questions,
    the bottom half is longform questions.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 表5：各种问题分解技术与GPT-4作为回答模块的比较。表格上半部分为短形式问题，下半部分为长形式问题。
- en: 3 Characterizing Researchy Questions
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 描述Researchy Questions
- en: 'Across the 96k Researchy Questions (split into 90k train, 6.4k test), there
    are in aggregate 350k unique documents clicked, 48% of which can be found in the
    english subset of Clueweb22 Set B Overwijk et al. ([2022](#bib.bib40)); the rest
    are in Sets A or L. For each question we release, there are on average 4.9 +/-
    3.5 clicked documents (See Figure [2](#A1.F2 "Figure 2 ‣ Appendix A GPT-4-based
    Filtering Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents") Right), indicating a good diversity of information
    needs and much higher than the average query overall. Conversely, for each document
    there is only 1.4 +/- 2.3 associated Researchy Questions (See Figure [2](#A1.F2
    "Figure 2 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A
    Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents") Left)
    indicating good query de-duplication.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '在96k Researchy Questions（分为90k训练集，6.4k测试集）中，共点击了350k个唯一文档，其中48%可以在Clueweb22
    Set B Overwijk et al. ([2022](#bib.bib40))的英文子集中找到；其余文档在Sets A或L中。每个问题我们发布的平均点击文档数为4.9
    +/- 3.5（见图[2](#A1.F2 "Figure 2 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy
    Questions: A Dataset of Multi-Perspective, Decompositional Questions for LLM Web
    Agents") 右），这表明信息需求的多样性良好，比整体查询的平均水平高出很多。相反，每个文档仅关联1.4 +/- 2.3个Researchy Questions（见图[2](#A1.F2
    "Figure 2 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A
    Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents") 左），表明查询去重效果良好。'
- en: 'To get a sense of how intrinsically difficult Researchy Questions are compared
    to other datasets, we asked GPT-4 how many sub-questions or search engine queries
    would be necessary to ask/issue in order to fully answer each question. An example
    decomposition in shown in Table [2](#S1.T2 "Table 2 ‣ 1 Introduction ‣ Researchy
    Questions: A Dataset of Multi-Perspective, Decompositional Questions for LLM Web
    Agents"), and the aggregate results are shown in Table [1](#S1.T1 "Table 1 ‣ 1
    Introduction ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents"). Clearly, GPT-4 thinks that most factoid QA datasets
    (top of the table) require the fewest sub-questions to answer, whereas Researchy
    Questions require the most even among longer-form QA datasets.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '为了了解Researchy Questions相对于其他数据集的内在难度，我们询问了GPT-4需要多少个子问题或搜索引擎查询才能完全回答每个问题。一个示例分解如表[2](#S1.T2
    "Table 2 ‣ 1 Introduction ‣ Researchy Questions: A Dataset of Multi-Perspective,
    Decompositional Questions for LLM Web Agents")所示，总体结果如表[1](#S1.T1 "Table 1 ‣ 1
    Introduction ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents")所示。显然，GPT-4认为大多数事实型QA数据集（表格顶部）需要的子问题最少，而Researchy
    Questions即便在长形式QA数据集中也需要最多。'
- en: 'We also compared Researchy Questions to another search-log based QA dataset
    – Natural Questions Kwiatkowski et al. ([2019](#bib.bib31)) – along the 8 quality
    dimensions descried in Section [2.5](#S2.SS5 "2.5 Stage 5: Final GPT-4 Filtering
    ‣ 2 Researchy Questions Construction ‣ Researchy Questions: A Dataset of Multi-Perspective,
    Decompositional Questions for LLM Web Agents"), such as how reasoning- and knowledge-intense
    they are. The comparative histograms are shown in Figure [6](#A1.F6 "Figure 6
    ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A Dataset of
    Multi-Perspective, Decompositional Questions for LLM Web Agents"), Clearly, GPT-4
    thinks that Researchy Questions require much more knowledge, reasoning, and are
    inherently more multi-faceted.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '我们还将Researchy Questions与另一个基于搜索日志的QA数据集——Natural Questions Kwiatkowski et al.
    ([2019](#bib.bib31))——在第[2.5](#S2.SS5 "2.5 Stage 5: Final GPT-4 Filtering ‣ 2
    Researchy Questions Construction ‣ Researchy Questions: A Dataset of Multi-Perspective,
    Decompositional Questions for LLM Web Agents")节中描述的8个质量维度上进行了比较，例如它们的推理和知识密集程度。比较的直方图如图[6](#A1.F6
    "Figure 6 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A
    Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents")所示。显然，GPT-4认为Researchy
    Questions需要更多的知识和推理，且本质上更具多面性。'
- en: 'Table [3](#S2.T3 "Table 3 ‣ 2 Researchy Questions Construction ‣ Researchy
    Questions: A Dataset of Multi-Perspective, Decompositional Questions for LLM Web
    Agents") shows the distribution of first words across Researchy Questions (as
    well as intermediate datasets used in the filtering funnel described in the next
    section). For comparison, MS Marco queries (also from web search logs) are much
    more factoid – e.g. only 1.64% of them start with “why” Bajaj et al. ([2018](#bib.bib3)).'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '表[3](#S2.T3 "Table 3 ‣ 2 Researchy Questions Construction ‣ Researchy Questions:
    A Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents")展示了Researchy
    Questions中首个单词的分布（以及下一节中描述的筛选漏斗中使用的中间数据集）。相比之下，MS Marco查询（也来自网络搜索日志）更具事实性——例如，仅有1.64%以“为什么”开头，Bajaj等人（[2018](#bib.bib3)）。'
- en: 'Lastly, an emergent property of Researchy Questions we observed is that some
    information found in the clicked URLs is very surprising, e.g. for the question
    “should the death penalty be legalized”, the fact that in the US, “the cost of
    enforcing the death penalty cost millions more than life imprisonment” ²²2supremecourt.gov/opinions
    would have a large impact on the economic arguments in that answer. We define
    a Pivotal Fact as a piece of information that is so surprising and consequential
    that, once known, drastically changes how an LLM Agent would answer the question
    (and the answer wouldn’t be as good without it); but it wouldn’t know about it
    unless it asked the right sub-question to retrieve it, e.g. “does the death penalty
    cost more than life imprisonment”. Hence, a pivotal fact is the information analogue
    of a black swan, a critical event that is hard to predict but highly impactful Taleb
    ([2008](#bib.bib48)); another example is shown in the bottom of Table [2](#S1.T2
    "Table 2 ‣ 1 Introduction ‣ Researchy Questions: A Dataset of Multi-Perspective,
    Decompositional Questions for LLM Web Agents"). Although we don’t have a good
    way to quantify the prevalence of Pivotal Facts, we believe that Researchy Questions is
    the best dataset to study the dynamics of how LLM Agents search for, and respond
    to, these uknown unknowns.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '最后，我们观察到Researchy Questions的一个新兴特性是，一些在点击的网址中找到的信息非常令人惊讶，例如对于问题“死刑是否应该合法化”，在美国“执行死刑的成本比终身监禁多出数百万美元”²²2supremecourt.gov/opinions这条信息将对该回答的经济论据产生重大影响。我们定义一个关键事实为这样一条信息：其惊人且重要到一旦知道，它会极大地改变LLM代理回答该问题的方式（如果没有这条信息，回答效果会很差）；但除非提出正确的子问题来检索，否则它不会知道这条信息，例如“死刑是否比终身监禁更昂贵”。因此，关键事实是黑天鹅的类比，即难以预测但影响巨大的关键事件，Taleb（[2008](#bib.bib48)）；另一个例子见于表[2](#S1.T2
    "Table 2 ‣ 1 Introduction ‣ Researchy Questions: A Dataset of Multi-Perspective,
    Decompositional Questions for LLM Web Agents")底部。虽然我们没有很好的方法来量化关键事实的普遍性，但我们相信Researchy
    Questions是研究LLM代理如何搜索和响应这些未知未知的最佳数据集。'
- en: 4 Agreement with User Search Behavior
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 用户搜索行为的协议
- en: More complicated questions ought to require more effort to answer Kelly et al.
    ([2015](#bib.bib26)). We can approximate the amount of effort users expend in
    terms of behavior signals like clicks and session length.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 更复杂的问题应当需要更多的回答努力，Kelly等人（[2015](#bib.bib26)）指出。我们可以通过点击和会话时长等行为信号来近似用户所付出的努力。
- en: 'In Table [4](#S2.T4 "Table 4 ‣ 2.1 Stage 1: Mining Search Logs ‣ 2 Researchy
    Questions Construction ‣ Researchy Questions: A Dataset of Multi-Perspective,
    Decompositional Questions for LLM Web Agents") (Left) we show aggregate click
    statistics for each subset of queries. The results show that Researchy Questions ,
    which are both non-factoid and decompositional, lead to more in-depth consumption
    (clicks and sat-clicks) of more diverse information (unique urls), agreeing with
    prior work Hassan et al. ([2014](#bib.bib18)).'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '在表[4](#S2.T4 "Table 4 ‣ 2.1 Stage 1: Mining Search Logs ‣ 2 Researchy Questions
    Construction ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents")（左侧）中，我们展示了每个查询子集的汇总点击统计数据。结果表明，Researchy Questions，即既非事实性又具分解性的问法，导致更深入的消费（点击和满意点击）和更多样的信息（独特的网址），这与之前的研究Hassan等人（[2014](#bib.bib18)）一致。'
- en: 'In Table [4](#S2.T4 "Table 4 ‣ 2.1 Stage 1: Mining Search Logs ‣ 2 Researchy
    Questions Construction ‣ Researchy Questions: A Dataset of Multi-Perspective,
    Decompositional Questions for LLM Web Agents") (Right) we show behavioral signals
    exhibited by users at the session level rather than individual click level. For
    instance, if a QnA-type query appeared at any time in any session in the date
    range, the whole session is included in the “QnA Sessions” row. The results clearly
    show users were twice as engaged answering non-factoid questions than sessions
    devoted to factoid-y intents, and six times longer than the average session overall.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在表格[4](#S2.T4 "表格 4 ‣ 2.1 阶段 1：挖掘搜索日志 ‣ 2 研究性问题构建 ‣ 研究性问题：多视角、分解式问题的数据集")（右侧），我们展示了用户在会话级别展示的行为信号，而不是个别点击级别。例如，如果在日期范围内的任何会话中出现了一个问答类型的查询，则整个会话都包含在“问答会话”行中。结果清楚地显示，用户在回答非事实性问题时的参与度是专注于事实性意图的会话的两倍，并且比总体平均会话时间长六倍。
- en: 5 Evaluating Answer Techniques to Researchy Questions
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 评估研究性问题的回答技术
- en: Since there is no one “correct” answer to a Researchy Question, we contend that
    they ought be evaluated in a relative, side-by-side fashion *a la* Alpaca-Eval
    syle Li et al. ([2023](#bib.bib33)), with e.g. the “closed-book” answer as the
    reference.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 由于研究性问题没有一个“正确”的答案，我们主张应当以相对的、并排的方式进行评估，*类似于* Alpaca-Eval 风格 Li 等人 ([2023](#bib.bib33))，例如，以“闭卷”答案作为参考。
- en: Since Researchy Questions are intended to be answered by decomposing them into
    sub-questions, we evaluate two decompositional question answering answer techniques
    – chain-of-thought decomposition, and factored decomposition – against the direct
    answering baseline. Factored decomposition makes a separate call to an LLM for
    each sub-question independently, and then a final “recomposition” call to synthesize
    the main answer (Radhakrishnan et al., [2023](#bib.bib43)).
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 由于研究性问题旨在通过将其分解为子问题来回答，我们评估了两种分解式问题回答技术——思维链分解和因子分解——与直接回答基线进行比较。因子分解为每个子问题独立调用一次LLM，然后进行一次最终的“重组”调用以合成主要答案（Radhakrishnan
    等人，[2023](#bib.bib43)）。
- en: 'Table [5](#S2.T5 "Table 5 ‣ 2.5 Stage 5: Final GPT-4 Filtering ‣ 2 Researchy
    Questions Construction ‣ Researchy Questions: A Dataset of Multi-Perspective,
    Decompositional Questions for LLM Web Agents") shows the results of a side-by-side
    auto-eval of the three answering techniques across a range of datasets. The LLM
    providing the answers was GPT-4, and the LLM-as-a-judge was also GPT-4, prompted
    separately using the template in Figure [8](#A1.F8 "Figure 8 ‣ A.1 Additional
    Safety Filtering ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions:
    A Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents").
    Since the gold correct answers exist for many of the datasets we consider, the
    judge was asked to ascertain “Accuracy” as a binary score of whether the candidate
    answer was consistent with the gold. The “Score” is on a scale of 1-100 indicating
    the overall quality. The top half of Table [5](#S2.T5 "Table 5 ‣ 2.5 Stage 5:
    Final GPT-4 Filtering ‣ 2 Researchy Questions Construction ‣ Researchy Questions:
    A Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents")
    corresponds to short-answer datasets (where Accuracy is more important), while
    the bottom half is longer answer questions where the overall Score is better suited
    to evaluate. Out of the long-form answer datasets, Researchy Questions benefits
    the most from decomposition techniques.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 表格[5](#S2.T5 "表格 5 ‣ 2.5 阶段 5：最终 GPT-4 过滤 ‣ 2 研究性问题构建 ‣ 研究性问题：多视角、分解式问题的数据集")
    显示了对三种回答技术在不同数据集上的并排自动评估结果。提供答案的LLM是GPT-4，作为评判者的LLM也是GPT-4，分别使用图[8](#A1.F8 "图
    8 ‣ A.1 附加安全过滤 ‣ 附录 A GPT-4 基于过滤的细节 ‣ 研究性问题：多视角、分解式问题的数据集")中的模板进行提示。由于我们考虑的许多数据集都有黄金标准答案，评判者被要求确定“准确性”，即候选答案是否与黄金答案一致的二元评分。“得分”范围为1-100，表示整体质量。表格[5](#S2.T5
    "表格 5 ‣ 2.5 阶段 5：最终 GPT-4 过滤 ‣ 2 研究性问题构建 ‣ 研究性问题：多视角、分解式问题的数据集")的上半部分对应于短答案数据集（准确性更重要），而下半部分则是较长答案的问题，整体得分更适合评估。在长答案数据集中的研究性问题中，分解技术的效果最为显著。
- en: 'We draw several conclusions from Table [5](#S2.T5 "Table 5 ‣ 2.5 Stage 5: Final
    GPT-4 Filtering ‣ 2 Researchy Questions Construction ‣ Researchy Questions: A
    Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents").
    Firstly, we largely confirm the results of  Radhakrishnan et al. ([2023](#bib.bib43))
    that decompositional techniques improve the accuracy on short-form multi-hop datasets
    over zero-shot direct answering. Secondly, factored decomposition leads to the
    highest scores for long-form questions, particularly questions involving reasoning
    about complex processes like Wikihow and Researchy Questions . On the other hand,
    chain-of-thought decomposition may be better suited to deduce correct answers
    to more logic-intensive questions. We believe the results for Researchy Questions using
    factored decomposition would be much higher if we incorporated retrieved information.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '我们从表格 [5](#S2.T5 "Table 5 ‣ 2.5 Stage 5: Final GPT-4 Filtering ‣ 2 Researchy
    Questions Construction ‣ Researchy Questions: A Dataset of Multi-Perspective,
    Decompositional Questions for LLM Web Agents") 中得出了几个结论。首先，我们在很大程度上确认了 Radhakrishnan
    等人（[2023](#bib.bib43)）的研究结果，即分解技术在短期多跳数据集上的准确性优于零-shot 直接回答。其次，分解技术在长形式问题上得分最高，特别是涉及复杂过程推理的问题，如
    Wikihow 和 Researchy Questions。另一方面，链式思维分解可能更适合推导更具逻辑密集型的问题的正确答案。如果我们结合检索到的信息，我们相信使用分解技术的
    Researchy Questions 的结果会更高。'
- en: 6 Related Work
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 相关工作
- en: 6.1 Human Behavior in Search Sessions
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 搜索会话中的人类行为
- en: There has been some fundamental research into understanding user behavior in
    search sessions, from user studies Kelly et al. ([2015](#bib.bib26)) to large
    scale click log evaluations Hassan et al. ([2014](#bib.bib18)). The latter attempt
    to ascertain signals that could indicate whether a user is “struggling” or “exploring”
    in their search session; we use many of the same signals. Namely, they conclude
    that “exploring” sessions contain more clicks because users want to locate information
    for multiple facets of a topic. We concur with their results, e.g. non-factoid
    questions involve more clicks than factoid ones. Similarly, the definition of
    a “complex search task” is almost congruent to that of a Researchy Question in
    its information seeking behaviors [Aula and Russell](#bib.bib2). Other studies
    try to identify complex search tasks and offer recommended sub-tasks Hassan Awadallah
    et al. ([2014](#bib.bib19)); Zhang et al. ([2021](#bib.bib62)). Much of the intuition
    on how to filter Researchy Questions stems from these and similar studies on user
    search behavior.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 对用户在搜索会话中的行为进行了一些基础研究，从用户研究 Kelly 等人（[2015](#bib.bib26)）到大规模点击日志评估 Hassan 等人（[2014](#bib.bib18)）。后者试图确定可能表明用户在搜索会话中是否“挣扎”或“探索”的信号；我们使用了许多相同的信号。即，他们得出结论，“探索”会话包含更多的点击，因为用户希望查找主题的多个方面的信息。我们同意他们的结果，例如，非事实型问题涉及的点击次数多于事实型问题。类似地，“复杂搜索任务”的定义几乎与
    Researchy Question 在信息寻求行为上的定义一致 [Aula 和 Russell](#bib.bib2)。其他研究尝试识别复杂搜索任务并提供推荐的子任务
    Hassan Awadallah 等人（[2014](#bib.bib19)）；Zhang 等人（[2021](#bib.bib62)）。关于如何过滤 Researchy
    Questions 的许多直觉来源于这些以及类似的用户搜索行为研究。
- en: 6.2 Iterative Retrieval-Augmented Generation
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 迭代检索增强生成
- en: 'Many papers discuss variants of chain-of-thought Wei et al. ([2023](#bib.bib52))
    adapted to decomposing multi-faceted questions such as query refinement prompts Amplayo
    et al. ([2022](#bib.bib1)), Decomposed Prompting Khot et al. ([2023](#bib.bib28))
    and ReAct Yao et al. ([2023b](#bib.bib58)). A step further is to marry a generative
    LLM with a vector-based retrieval system, e.g. Ren et al. ([2023](#bib.bib45));
    Xiong et al. ([2020](#bib.bib55)); Karpukhin et al. ([2020](#bib.bib25)); Izacard
    and Grave ([2021](#bib.bib20)). Such methods are instantiated in many flavors:
    Self-Ask Press et al. ([2023](#bib.bib42)) was one of the first chain-of-thought-like
    decomposed prompting techniques to integrate a search engine, forcing an LLM to
    iteratively ask and subquestions. IRCoT interleaves retrieval with chain-of-thought
    such that what to retrieve next depends on what was previously retrieved Trivedi
    et al. ([2023](#bib.bib50)) Iter-RetGen iteratively retrieves and generates candidate
    answers to use as inputs to the next phase of retrieval Shao et al. ([2023](#bib.bib46)),
    while Beam Retrieval maintains running hypotheses of the relevant passages at
    every step Zhang et al. ([2023](#bib.bib60)).'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 许多论文讨论了适用于分解多面向问题的思维链变体，如查询细化提示**Amplayo** 等人 ([2022](#bib.bib1))、**Decomposed
    Prompting** Khot 等人 ([2023](#bib.bib28)) 和 **ReAct** Yao 等人 ([2023b](#bib.bib58))。更进一步的是将生成型
    LLM 与基于向量的检索系统结合，例如**Ren** 等人 ([2023](#bib.bib45))；**Xiong** 等人 ([2020](#bib.bib55))；**Karpukhin**
    等人 ([2020](#bib.bib25))；**Izacard 和 Grave** ([2021](#bib.bib20))。这些方法有很多变体：**Self-Ask**
    Press 等人 ([2023](#bib.bib42)) 是首批类似思维链的分解提示技术之一，将搜索引擎集成在内，迫使 LLM 迭代地提出子问题。**IRCoT**
    将检索与思维链交错进行，使得接下来检索的内容取决于之前检索的内容 **Trivedi** 等人 ([2023](#bib.bib50))。**Iter-RetGen**
    迭代地检索和生成候选答案，用作下一阶段检索的输入 **Shao** 等人 ([2023](#bib.bib46))，而 **Beam Retrieval**
    在每一步都维持相关段落的运行假设 **Zhang** 等人 ([2023](#bib.bib60))。
- en: 6.3 Agentic Question Answering
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3 代理性问答
- en: There are several “agentic” frameworks to facilitate the dynamic interaction
    between tools e.g. retrieval systems and LLMs-as-agents which are adept at iterative
    retrieval-augmented QA tasks. One is Demonstrate-Search-Predict Khattab et al.
    ([2023](#bib.bib27)), another is AutoGen Wu et al. ([2023b](#bib.bib54)). Some
    existing Web-based Agents include WebGPT Nakano et al. ([2022](#bib.bib38)) which
    imitate how users surf the web and ask queries, others like WebAgent Gur et al.
    ([2023](#bib.bib16)) interact with the web programmatically by understanding the
    raw HTML.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个“代理性”框架用于促进工具之间的动态互动，例如检索系统和擅长迭代检索增强问答任务的LLMs-作为-代理。一个是**Demonstrate-Search-Predict**
    Khattab 等人 ([2023](#bib.bib27))，另一个是**AutoGen** Wu 等人 ([2023b](#bib.bib54))。一些现有的基于Web的代理包括**WebGPT**
    Nakano 等人 ([2022](#bib.bib38))，它模仿用户如何浏览网页和提出查询，另一些如**WebAgent** Gur 等人 ([2023](#bib.bib16))
    则通过理解原始 HTML 以编程方式与网络互动。
- en: 'There are also several consumer-facing products for agentic search assistants
    such as Bing Chat ³³3[https://bing.com/chat](https://bing.com/chat), YouPro ⁴⁴4[https://you.com/search](https://you.com/search)
    (Research Mode) and SciPhi ⁵⁵5[https://search.sciphi.ai/research](https://search.sciphi.ai/research).
    All of these systems clearly decompose queries into sub-questions and then retrieve/crawl
    the necessary pages to synthesize the final outputs. An example of each addressing
    a Researchy Question is shown in Figures [9](#A1.F9 "Figure 9 ‣ A.1 Additional
    Safety Filtering ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions:
    A Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents"),
     [10](#A1.F10 "Figure 10 ‣ A.1 Additional Safety Filtering ‣ Appendix A GPT-4-based
    Filtering Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents"), and  [11](#A1.F11 "Figure 11 ‣ A.1 Additional
    Safety Filtering ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions:
    A Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents"),
    respectively.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 还有几个面向消费者的产品用于代理搜索助手，如**Bing Chat** ³³3[https://bing.com/chat](https://bing.com/chat)、**YouPro** ⁴⁴4[https://you.com/search](https://you.com/search)（研究模式）和**SciPhi** ⁵⁵5[https://search.sciphi.ai/research](https://search.sciphi.ai/research)。所有这些系统都清晰地将查询分解为子问题，然后检索/爬取必要的页面以综合最终输出。每个系统处理研究性问题的示例见图 [9](#A1.F9
    "图 9 ‣ A.1 附加安全过滤 ‣ 附录 A GPT-4 基于的过滤细节 ‣ 研究性问题：LLM Web Agents 的多视角、分解问题数据集")、[10](#A1.F10
    "图 10 ‣ A.1 附加安全过滤 ‣ 附录 A GPT-4 基于的过滤细节 ‣ 研究性问题：LLM Web Agents 的多视角、分解问题数据集")和[11](#A1.F11
    "图 11 ‣ A.1 附加安全过滤 ‣ 附录 A GPT-4 基于的过滤细节 ‣ 研究性问题：LLM Web Agents 的多视角、分解问题数据集")。
- en: 7 Conclusion
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 结论
- en: For some time now, many QA datasets have been saturated, and many researchers
    have dismissed search logs as sources of complex questions. We present Researchy
    Questions , a large dataset to advance the field of complex question answering
    over multiple documents and perspectives, targeting LLM-assisted web search agents.
    We detail how these complex queries are mined from search logs, and confirm they
    involve significantly more effort than other types of search queries. We also
    provide some preliminary evidence that decompositional answering techniques yield
    stronger results on Researchy Questions than direct answering.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，许多 QA 数据集已经饱和，许多研究人员已将搜索日志视为复杂问题的来源。我们提出了 Researchy Questions，这是一个大型数据集，旨在推进多文档和多视角的复杂问题回答领域，针对
    LLM 辅助的网络搜索代理。我们详细说明了这些复杂查询如何从搜索日志中提取，并确认它们涉及的努力程度显著高于其他类型的搜索查询。我们还提供了一些初步证据，表明分解式回答技术在
    Researchy Questions 上的表现优于直接回答。
- en: 'By design, these questions don’t have a gold answer, so regrettably, it difficult
    to quantify the “headroom” of existing models, but qualitatively (e.g. Table [10](#A1.T10
    "Table 10 ‣ A.1 Additional Safety Filtering ‣ Appendix A GPT-4-based Filtering
    Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents")) there seems to be substantial room for improvement.
    There also remains much work surrounding how to measure the quality of sub-questions,
    and studying how LLM agents find and interact with Pivotal Facts. We hope this
    dataset can help aid the development of new metrics and unlock new experiences
    for web users.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 由于设计原因，这些问题没有黄金答案，因此遗憾的是，难以量化现有模型的“潜力”，但从定性上（例如，表 [10](#A1.T10 "表 10 ‣ A.1 附加安全过滤
    ‣ 附录 A GPT-4 基于过滤细节 ‣ Researchy Questions：一个多视角、分解式问题的数据集")）来看，似乎有显著的改进空间。关于如何衡量子问题的质量、以及研究
    LLM 代理如何发现和互动 Pivotal Facts 仍然有很多工作。我们希望这个数据集能帮助开发新的指标，并为网络用户解锁新的体验。
- en: Limitations
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 局限性
- en: One of the primary limitations of this study is that while we argue question
    decomposition is key to solving complex Researchy Questions , we don’t propose
    a good way to measure the quality of a candidate set of sub-questions. Instead,
    we loosely argue that good sub-questions ought to at least lead to the same set
    of information found in the documents users clicked on for the question. We admit
    these two things are not the same, but clicks are a powerful signal. We try to
    make up for this gap by releasing the hierarchical question/query decomposition
    that GPT-4 gives closed-book, but we do not evaluate whether that decomposition
    does indeed lead to the same set of gold documents in a real retrieval system
    e.g. built from the entirety of ClueWeb22.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 这项研究的主要局限之一是，虽然我们认为问题分解是解决复杂的 Researchy Questions 的关键，但我们并没有提出一个好的方法来衡量候选子问题集的质量。相反，我们大致认为好的子问题至少应该能够得出用户点击的文档中所包含的信息集。我们承认这两者并不完全相同，但点击量是一个强有力的信号。我们尝试通过发布
    GPT-4 提供的闭卷层级问题/查询分解来弥补这一差距，但我们没有评估这种分解是否确实会在实际检索系统中（例如，构建自 ClueWeb22 的整个数据集）导致相同的黄金文档集。
- en: We also admit that it would potentially be better to produce the question decomposition
    by “working backwards” from the documents that were clicked on – i.e. identify
    key information in the clicked document for a researchy question and then identify
    what sub-question would lead to that information being retrieved. On the other
    hand, one could argue that the “forward” direction is what needs to be implemented
    in practice. While we do not address these points in this study, others in the
    academic community can explore these topics more with the dataset we release.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还承认，通过“倒推”的方式从被点击的文档中生成问题分解可能会更好——即，识别点击文档中的关键信息以解决研究性问题，然后确定什么子问题可以引导到该信息检索到。另一方面，也可以认为“向前”的方向才是实践中需要实现的。虽然我们在这项研究中没有解决这些问题，但学术界的其他人可以利用我们发布的数据集进一步探讨这些主题。
- en: Another limitation of this study is that Pivotal Facts are purely an observational
    phenomenon that we have in no way quantified. Future researchers could create
    a LLM-prompt to count the number of such statements in the clicked documents.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这项研究的另一个局限是，Pivotal Facts 纯粹是我们未量化的观察现象。未来的研究人员可以创建一个 LLM 提示，以计算被点击文档中此类陈述的数量。
- en: We regret that this dataset is not multi-lingual. This is due to the large amount
    of uncertainty and trial-and-error in curating this dataset, which meant frequent
    manual inspection of data. We believe the same framework can be used to construct
    a multi-lingual version of Researchy Questions .
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遗憾地通知您，这个数据集不支持多语言。这是由于在整理这个数据集时存在大量的不确定性和反复试验，这意味着数据需要频繁的人工检查。我们相信可以使用相同的框架来构建Researchy
    Questions的多语言版本。
- en: Ethics Statement
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 伦理声明
- en: We obtained approval to release this dataset after thorough IRB proceedings
    to ensure compliance with privacy, safety, and legal guidelines.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在经过彻底的IRB程序批准后，我们获得了发布该数据集的许可，以确保符合隐私、安全和法律指南。
- en: 'We would like to make a few notes: while it may appear that we tried to remove
    queries that seemed “controversial”, it is not our intention to act as moral or
    political regulators to decide if user queries are well-meaning. At the scale
    of web search, one will notice that users ask a lot of questions for a lot of
    reasons, and it is beyond the scope of our job to speculate what the motives are
    behind a query. It *is* is our job to assess whether the act of attempting to
    answer a question will lead to a reasonable risk of harm. Also, it is not the
    case that “GPT-4 is our moral authority” on the topic of safety, it is merely
    one of many tools we employ in a stack to ensure our internal requirements are
    being met.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要做几点说明：虽然看起来我们尝试去除那些似乎“有争议”的查询，但我们并不打算充当道德或政治的监管者来决定用户查询是否善意。在网页搜索的规模下，人们会提出很多问题，出于各种原因，我们的工作范围不包括揣测查询背后的动机。我们的*工作*是评估尝试回答问题是否会导致合理的伤害风险。此外，“GPT-4不是我们在安全主题上的道德权威”，它只是我们用于确保内部要求得到满足的众多工具之一。
- en: References
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Amplayo et al. (2022) Reinald Kim Amplayo, Kellie Webster, Michael Collins,
    Dipanjan Das, and Shashi Narayan. 2022. [Query refinement prompts for closed-book
    long-form question answering](http://arxiv.org/abs/2210.17525).
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amplayo等（2022）Reinald Kim Amplayo, Kellie Webster, Michael Collins, Dipanjan
    Das, 和 Shashi Narayan. 2022. [用于封闭式长篇问答的查询优化提示](http://arxiv.org/abs/2210.17525)。
- en: Aula and Russell (2008) Anne Aula and Daniel Russell. 2008. Complex and exploratory
    web search.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Aula 和 Russell（2008）Anne Aula 和 Daniel Russell. 2008. 复杂和探索性网页搜索。
- en: 'Bajaj et al. (2018) Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng, Jianfeng
    Gao, Xiaodong Liu, Rangan Majumder, Andrew McNamara, Bhaskar Mitra, Tri Nguyen,
    Mir Rosenberg, Xia Song, Alina Stoica, Saurabh Tiwary, and Tong Wang. 2018. [Ms
    marco: A human generated machine reading comprehension dataset](http://arxiv.org/abs/1611.09268).'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Bajaj等（2018）Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng, Jianfeng Gao,
    Xiaodong Liu, Rangan Majumder, Andrew McNamara, Bhaskar Mitra, Tri Nguyen, Mir
    Rosenberg, Xia Song, Alina Stoica, Saurabh Tiwary, 和 Tong Wang. 2018. [Ms marco:
    一个人工生成的机器阅读理解数据集](http://arxiv.org/abs/1611.09268)。'
- en: Berant et al. (2013) Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang.
    2013. [Semantic parsing on Freebase from question-answer pairs](https://www.aclweb.org/anthology/D13-1160).
    In *Proceedings of the 2013 Conference on Empirical Methods in Natural Language
    Processing*, pages 1533–1544, Seattle, Washington, USA. Association for Computational
    Linguistics.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Berant等（2013）Jonathan Berant, Andrew Chou, Roy Frostig, 和 Percy Liang. 2013.
    [基于问题-答案对的Freebase语义解析](https://www.aclweb.org/anthology/D13-1160)。在*2013年自然语言处理实证方法会议论文集*中，第1533–1544页，西雅图，华盛顿，美国。计算语言学协会。
- en: Bolotova et al. (2022) Valeriia Bolotova, Vladislav Blinov, Falk Scholer, W. Bruce
    Croft, and Mark Sanderson. 2022. [A non-factoid question-answering taxonomy](https://doi.org/10.1145/3477495.3531926).
    In *Proceedings of the 45th International ACM SIGIR Conference on Research and
    Development in Information Retrieval*, SIGIR ’22, page 1196–1207, New York, NY,
    USA. Association for Computing Machinery.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bolotova等（2022）Valeriia Bolotova, Vladislav Blinov, Falk Scholer, W. Bruce Croft,
    和 Mark Sanderson. 2022. [一种非事实性问答分类法](https://doi.org/10.1145/3477495.3531926)。在*第45届国际ACM
    SIGIR信息检索研究与发展会议论文集*中，SIGIR ’22，第1196–1207页，纽约，纽约，美国。计算机协会。
- en: 'Bolotova-Baranova et al. (2023) Valeriia Bolotova-Baranova, Vladislav Blinov,
    Sofya Filippova, Falk Scholer, and Mark Sanderson. 2023. [WikiHowQA: A comprehensive
    benchmark for multi-document non-factoid question answering](https://doi.org/10.18653/v1/2023.acl-long.290).
    In *Proceedings of the 61st Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)*, pages 5291–5314, Toronto, Canada. Association
    for Computational Linguistics.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Bolotova-Baranova 等 (2023) Valeriia Bolotova-Baranova, Vladislav Blinov, Sofya
    Filippova, Falk Scholer 和 Mark Sanderson. 2023. [WikiHowQA: 多文档非事实性问答的综合基准](https://doi.org/10.18653/v1/2023.acl-long.290)。在
    *第61届计算语言学协会年会（第1卷：长篇论文）* 中，页面 5291–5314，多伦多，加拿大。计算语言学协会。'
- en: Borgeaud et al. (2022) Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor
    Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste
    Lespiau, Bogdan Damoc, Aidan Clark, Diego de Las Casas, Aurelia Guy, Jacob Menick,
    Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer,
    Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero,
    Karen Simonyan, Jack W. Rae, Erich Elsen, and Laurent Sifre. 2022. [Improving
    language models by retrieving from trillions of tokens](http://arxiv.org/abs/2112.04426).
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Borgeaud 等 (2022) Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor
    Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste
    Lespiau, Bogdan Damoc, Aidan Clark, Diego de Las Casas, Aurelia Guy, Jacob Menick,
    Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer,
    Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero,
    Karen Simonyan, Jack W. Rae, Erich Elsen 和 Laurent Sifre. 2022. [通过从万亿标记中检索来改进语言模型](http://arxiv.org/abs/2112.04426)。
- en: Bu et al. (2010) Fan Bu, Xingwei Zhu, Yu Hao, and Xiaoyan Zhu. 2010. [Function-based
    question classification for general QA](https://aclanthology.org/D10-1109). In
    *Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing*,
    pages 1119–1128, Cambridge, MA. Association for Computational Linguistics.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bu 等 (2010) Fan Bu, Xingwei Zhu, Yu Hao 和 Xiaoyan Zhu. 2010. [基于功能的问答分类](https://aclanthology.org/D10-1109)。在
    *2010年自然语言处理实证方法会议论文集* 中，页面 1119–1128，剑桥，MA。计算语言学协会。
- en: 'Campos et al. (2016) Daniel Fernando Campos, Tri Nguyen, Mir Rosenberg, Xia
    Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, Li Deng, and Bhaskar Mitra.
    2016. [Ms marco: A human generated machine reading comprehension dataset](https://api.semanticscholar.org/CorpusID:1289517).
    *ArXiv*, abs/1611.09268.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Campos 等 (2016) Daniel Fernando Campos, Tri Nguyen, Mir Rosenberg, Xia Song,
    Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, Li Deng 和 Bhaskar Mitra. 2016.
    [Ms marco: 一个由人工生成的机器阅读理解数据集](https://api.semanticscholar.org/CorpusID:1289517)。*ArXiv*，abs/1611.09268。'
- en: 'Chen et al. (2020) Wenhu Chen, Hanwen Zha, Zhiyu Chen, Wenhan Xiong, Hong Wang,
    and William Yang Wang. 2020. [HybridQA: A dataset of multi-hop question answering
    over tabular and textual data](https://doi.org/10.18653/v1/2020.findings-emnlp.91).
    In *Findings of the Association for Computational Linguistics: EMNLP 2020*, pages
    1026–1036, Online. Association for Computational Linguistics.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chen 等 (2020) Wenhu Chen, Hanwen Zha, Zhiyu Chen, Wenhan Xiong, Hong Wang 和
    William Yang Wang. 2020. [HybridQA: 一个跨表格和文本数据的多跳问答数据集](https://doi.org/10.18653/v1/2020.findings-emnlp.91)。在
    *Findings of the Association for Computational Linguistics: EMNLP 2020* 中，页面 1026–1036，在线。计算语言学协会。'
- en: 'Dohmatob et al. (2024) Elvis Dohmatob, Yunzhen Feng, Pu Yang, Francois Charton,
    and Julia Kempe. 2024. [A tale of tails: Model collapse as a change of scaling
    laws](http://arxiv.org/abs/2402.07043).'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Dohmatob 等 (2024) Elvis Dohmatob, Yunzhen Feng, Pu Yang, Francois Charton 和
    Julia Kempe. 2024. [A tale of tails: 模型崩溃作为尺度定律的变化](http://arxiv.org/abs/2402.07043)。'
- en: 'Dunn et al. (2017) Matthew Dunn, Levent Sagun, Mike Higgins, V. Ugur Guney,
    Volkan Cirik, and Kyunghyun Cho. 2017. [Searchqa: A new q&a dataset augmented
    with context from a search engine](http://arxiv.org/abs/1704.05179).'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Dunn 等 (2017) Matthew Dunn, Levent Sagun, Mike Higgins, V. Ugur Guney, Volkan
    Cirik 和 Kyunghyun Cho. 2017. [Searchqa: 一个通过搜索引擎上下文增强的新问答数据集](http://arxiv.org/abs/1704.05179)。'
- en: Everitt (1974) Brian Everitt. 1974. *Cluster analysis*. Heinemann Educational
    [for] the Social Science Research Council.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Everitt (1974) Brian Everitt. 1974. *聚类分析*。Heinemann Educational [for] 社会科学研究委员会。
- en: 'Fan et al. (2019) Angela Fan, Yacine Jernite, Ethan Perez, David Grangier,
    Jason Weston, and Michael Auli. 2019. [ELI5: long form question answering](https://doi.org/10.18653/v1/p19-1346).
    In *Proceedings of the 57th Conference of the Association for Computational Linguistics,
    ACL 2019, Florence, Italy, July 28- August 2, 2019, Volume 1: Long Papers*, pages
    3558–3567\. Association for Computational Linguistics.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fan 等 (2019) Angela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason
    Weston, 和 Michael Auli. 2019. [ELI5：长篇问答](https://doi.org/10.18653/v1/p19-1346)。见于
    *第57届计算语言学学会会议，ACL 2019，意大利佛罗伦萨，2019年7月28日至8月2日，第1卷：长篇论文*，第3558–3567页。计算语言学协会。
- en: 'Gao et al. (2020) Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis
    Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn
    Presser, and Connor Leahy. 2020. [The pile: An 800gb dataset of diverse text for
    language modeling](http://arxiv.org/abs/2101.00027).'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao 等 (2020) Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe,
    Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser,
    和 Connor Leahy. 2020. [The pile：用于语言建模的800GB多样文本数据集](http://arxiv.org/abs/2101.00027)。
- en: Gur et al. (2023) Izzeddin Gur, Hiroki Furuta, Austin Huang, Mustafa Safdari,
    Yutaka Matsuo, Douglas Eck, and Aleksandra Faust. 2023. [A real-world webagent
    with planning, long context understanding, and program synthesis](http://arxiv.org/abs/2307.12856).
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gur 等 (2023) Izzeddin Gur, Hiroki Furuta, Austin Huang, Mustafa Safdari, Yutaka
    Matsuo, Douglas Eck, 和 Aleksandra Faust. 2023. [具有规划、长上下文理解和程序合成的真实世界网络代理](http://arxiv.org/abs/2307.12856)。
- en: 'Guu et al. (2020) Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and
    Ming-Wei Chang. 2020. [Realm: Retrieval-augmented language model pre-training](http://arxiv.org/abs/2002.08909).'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guu 等 (2020) Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, 和 Ming-Wei
    Chang. 2020. [Realm：检索增强语言模型预训练](http://arxiv.org/abs/2002.08909)。
- en: Hassan et al. (2014) Ahmed Hassan, Ryen W. White, Susan T. Dumais, and Yi-Min
    Wang. 2014. [Struggling or exploring? disambiguating long search sessions](https://doi.org/10.1145/2556195.2556221).
    In *Proceedings of the 7th ACM International Conference on Web Search and Data
    Mining*, WSDM ’14, page 53–62, New York, NY, USA. Association for Computing Machinery.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hassan 等 (2014) Ahmed Hassan, Ryen W. White, Susan T. Dumais, 和 Yi-Min Wang.
    2014. [挣扎还是探索？澄清长时间搜索会话](https://doi.org/10.1145/2556195.2556221)。见于 *第7届ACM国际网络搜索与数据挖掘会议*，WSDM
    ’14，第53–62页，纽约，NY，美国。计算机协会。
- en: Hassan Awadallah et al. (2014) Ahmed Hassan Awadallah, Ryen W. White, Patrick
    Pantel, Susan T. Dumais, and Yi-Min Wang. 2014. [Supporting complex search tasks](https://doi.org/10.1145/2661829.2661912).
    In *Proceedings of the 23rd ACM International Conference on Conference on Information
    and Knowledge Management*, CIKM ’14, page 829–838, New York, NY, USA. Association
    for Computing Machinery.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hassan Awadallah 等 (2014) Ahmed Hassan Awadallah, Ryen W. White, Patrick Pantel,
    Susan T. Dumais, 和 Yi-Min Wang. 2014. [支持复杂搜索任务](https://doi.org/10.1145/2661829.2661912)。见于
    *第23届ACM国际信息与知识管理会议*，CIKM ’14，第829–838页，纽约，NY，美国。计算机协会。
- en: 'Izacard and Grave (2021) Gautier Izacard and Edouard Grave. 2021. [Leveraging
    passage retrieval with generative models for open domain question answering](https://doi.org/10.18653/v1/2021.eacl-main.74).
    In *Proceedings of the 16th Conference of the European Chapter of the Association
    for Computational Linguistics: Main Volume*, pages 874–880, Online. Association
    for Computational Linguistics.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Izacard 和 Grave (2021) Gautier Izacard 和 Edouard Grave. 2021. [利用生成模型进行开放领域问答的段落检索](https://doi.org/10.18653/v1/2021.eacl-main.74)。见于
    *第16届欧洲计算语言学学会会议：主要论文集*，第874–880页，在线。计算语言学协会。
- en: Jiang et al. (2024) Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur
    Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas,
    Emma Bou Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample,
    Lélio Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Sandeep
    Subramanian, Sophia Yang, Szymon Antoniak, Teven Le Scao, Théophile Gervet, Thibaut
    Lavril, Thomas Wang, Timothée Lacroix, and William El Sayed. 2024. [Mixtral of
    experts](http://arxiv.org/abs/2401.04088).
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang 等 (2024) Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur
    Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas,
    Emma Bou Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample,
    Lélio Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Sandeep
    Subramanian, Sophia Yang, Szymon Antoniak, Teven Le Scao, Théophile Gervet, Thibaut
    Lavril, Thomas Wang, Timothée Lacroix, 和 William El Sayed. 2024. [专家混合模型](http://arxiv.org/abs/2401.04088)。
- en: Johnson et al. (2019) Jeff Johnson, Matthijs Douze, and Hervé Jégou. 2019. Billion-scale
    similarity search with GPUs. *IEEE Transactions on Big Data*, 7(3):535–547.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Johnson et al. (2019) 杰夫·约翰逊、马蒂斯·杜兹和赫尔维·热戈。2019年。亿级规模的相似性搜索与GPU。*IEEE大数据学报*，7(3)：535–547。
- en: 'Joshi et al. (2017) Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke Zettlemoyer.
    2017. [triviaqa: A Large Scale Distantly Supervised Challenge Dataset for Reading
    Comprehension](http://arxiv.org/abs/1705.03551). *arXiv e-prints*, page arXiv:1705.03551.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Joshi et al. (2017) 曼达尔·乔希、恩索尔·崔、丹尼尔·韦尔德和卢克·泽特尔莫耶。2017年。[triviaqa：一个大规模远程监督阅读理解挑战数据集](http://arxiv.org/abs/1705.03551)。*arXiv
    e-prints*，第arXiv:1705.03551页。
- en: Kahneman (2011) Daniel Kahneman. 2011. *Thinking, Fast and Slow*. Farrar, Straus
    and Giroux, New York.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kahneman (2011) 丹尼尔·卡尼曼。2011年。*思考，快与慢*。Farrar, Straus and Giroux, 纽约。
- en: Karpukhin et al. (2020) Vladimir Karpukhin, Barlas Oğuz, Sewon Min, Patrick
    Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen tau Yih. 2020. [Dense passage
    retrieval for open-domain question answering](http://arxiv.org/abs/2004.04906).
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Karpukhin et al. (2020) 弗拉基米尔·卡普金、巴尔拉斯·奥古兹、谢旺·敏、帕特里克·刘易斯、莱德尔·吴、谢尔盖·埃杜诺夫、丹奇·陈和温涛·易。2020年。[密集段落检索用于开放域问答](http://arxiv.org/abs/2004.04906)。
- en: Kelly et al. (2015) Diane Kelly, Jaime Arguello, Ashlee Edwards, and Wan-ching
    Wu. 2015. [Development and evaluation of search tasks for iir experiments using
    a cognitive complexity framework](https://doi.org/10.1145/2808194.2809465). In
    *Proceedings of the 2015 International Conference on The Theory of Information
    Retrieval*, ICTIR ’15, page 101–110, New York, NY, USA. Association for Computing
    Machinery.
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kelly et al. (2015) 黛安·凯利、哈梅·阿尔瓜埃洛、阿什利·爱德华兹和万青吴。2015年。[使用认知复杂性框架开发和评估搜索任务以进行信息检索实验](https://doi.org/10.1145/2808194.2809465)。在*2015年国际信息检索理论会议论文集*，ICTIR
    ’15，第101-110页，纽约，美国。计算机协会。
- en: 'Khattab et al. (2023) Omar Khattab, Keshav Santhanam, Xiang Lisa Li, David
    Hall, Percy Liang, Christopher Potts, and Matei Zaharia. 2023. [Demonstrate-search-predict:
    Composing retrieval and language models for knowledge-intensive nlp](http://arxiv.org/abs/2212.14024).'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khattab et al. (2023) 奥马尔·哈塔布、凯莎夫·桑坦纳姆、香·莉莎·李、大卫·霍尔、珀西·梁、克里斯托弗·波茨和马泰·扎哈里亚。2023年。[演示-搜索-预测：将检索和语言模型组合用于知识密集型自然语言处理](http://arxiv.org/abs/2212.14024)。
- en: 'Khot et al. (2023) Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle
    Richardson, Peter Clark, and Ashish Sabharwal. 2023. [Decomposed prompting: A
    modular approach for solving complex tasks](http://arxiv.org/abs/2210.02406).'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khot et al. (2023) 图沙尔·科特、哈什·特里维迪、马修·芬莱森、姚福、凯尔·理查森、彼得·克拉克和阿希什·萨巴尔瓦尔。2023年。[分解提示：解决复杂任务的模块化方法](http://arxiv.org/abs/2210.02406)。
- en: Krishna et al. (2021) Kalpesh Krishna, Aurko Roy, and Mohit Iyyer. 2021. [Hurdles
    to progress in long-form question answering](http://arxiv.org/abs/2103.06332).
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krishna et al. (2021) 卡尔佩什·克里希纳、奥尔科·罗伊和莫希特·伊耶。2021年。[长期问答中的障碍](http://arxiv.org/abs/2103.06332)。
- en: 'Kulkarni et al. (2020) Sayali Kulkarni, Sheide Chammas, Wan Zhu, Fei Sha, and
    Eugene Ie. 2020. [Aquamuse: Automatically generating datasets for query-based
    multi-document summarization](http://arxiv.org/abs/2010.12694).'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kulkarni et al. (2020) 萨亚利·库尔卡尼、谢德·查马斯、万朱、费伊·沙和尤金·伊。2020年。[Aquamuse：自动生成用于查询基础多文档摘要的数据集](http://arxiv.org/abs/2010.12694)。
- en: 'Kwiatkowski et al. (2019) Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield,
    Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin,
    Matthew Kelcey, Jacob Devlin, Kenton Lee, Kristina N. Toutanova, Llion Jones,
    Ming-Wei Chang, Andrew Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. 2019. Natural
    questions: a benchmark for question answering research. *Transactions of the Association
    of Computational Linguistics*.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kwiatkowski et al. (2019) 汤姆·克维亚托夫斯基、珍妮玛利亚·帕洛马克、奥利维亚·雷德菲尔德、迈克尔·柯林斯、安库尔·帕里克、克里斯·阿尔伯蒂、丹妮尔·爱泼斯坦、伊利亚·波洛苏金、马修·凯尔西、雅各布·德夫林、肯顿·李、克里斯蒂娜·N·图塔诺娃、利昂·琼斯、明伟·张、安德鲁·戴、雅各布·乌斯科雷特、阮克·李和斯拉夫·彼得罗夫。2019年。自然问题：一个用于问答研究的基准。*计算语言学协会会刊*。
- en: Lewis et al. (2021) Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni,
    Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen tau Yih, Tim
    Rocktäschel, Sebastian Riedel, and Douwe Kiela. 2021. [Retrieval-augmented generation
    for knowledge-intensive nlp tasks](http://arxiv.org/abs/2005.11401).
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lewis et al. (2021) 帕特里克·刘易斯、伊桑·佩雷斯、亚历山德拉·皮克图斯、法比奥·佩特罗尼、弗拉基米尔·卡普金、纳曼·戈亚尔、海因里希·库特勒、迈克·刘易斯、温涛·易、蒂姆·罗克特谢尔、塞巴斯蒂安·里德尔和道威·基拉。2021年。[检索增强生成用于知识密集型自然语言处理任务](http://arxiv.org/abs/2005.11401)。
- en: 'Li et al. (2023) Xuechen Li, Tianyi Zhang, Yann Dubois, Rohan Taori, Ishaan
    Gulrajani, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. 2023. Alpacaeval:
    An automatic evaluator of instruction-following models. [https://github.com/tatsu-lab/alpaca_eval](https://github.com/tatsu-lab/alpaca_eval).'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. (2023) Xuechen Li, Tianyi Zhang, Yann Dubois, Rohan Taori, Ishaan
    Gulrajani, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. 2023. Alpacaeval：一种自动评估指令跟随模型的工具。
    [https://github.com/tatsu-lab/alpaca_eval](https://github.com/tatsu-lab/alpaca_eval)。
- en: 'Liu et al. (2023a) Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape,
    Michele Bevilacqua, Fabio Petroni, and Percy Liang. 2023a. [Lost in the middle:
    How language models use long contexts](http://arxiv.org/abs/2307.03172).'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2023a) Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape,
    Michele Bevilacqua, Fabio Petroni, and Percy Liang. 2023a. [迷失在中间：语言模型如何使用长上下文](http://arxiv.org/abs/2307.03172)。
- en: Liu et al. (2023b) Nelson F. Liu, Tianyi Zhang, and Percy Liang. 2023b. [Evaluating
    verifiability in generative search engines](http://arxiv.org/abs/2304.09848).
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2023b) Nelson F. Liu, Tianyi Zhang, and Percy Liang. 2023b. [评估生成搜索引擎中的可验证性](http://arxiv.org/abs/2304.09848)。
- en: 'Liu et al. (2023c) Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu
    Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng,
    Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan
    Sun, Minlie Huang, Yuxiao Dong, and Jie Tang. 2023c. [Agentbench: Evaluating llms
    as agents](http://arxiv.org/abs/2308.03688).'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2023c) Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu
    Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng,
    Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan
    Sun, Minlie Huang, Yuxiao Dong, and Jie Tang. 2023c. [Agentbench：将大型语言模型作为代理进行评估](http://arxiv.org/abs/2308.03688)。
- en: 'Mialon et al. (2023) Grégoire Mialon, Clémentine Fourrier, Craig Swift, Thomas
    Wolf, Yann LeCun, and Thomas Scialom. 2023. [Gaia: a benchmark for general ai
    assistants](http://arxiv.org/abs/2311.12983).'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mialon et al. (2023) Grégoire Mialon, Clémentine Fourrier, Craig Swift, Thomas
    Wolf, Yann LeCun, and Thomas Scialom. 2023. [Gaia：通用人工智能助手的基准测试](http://arxiv.org/abs/2311.12983)。
- en: 'Nakano et al. (2022) Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu,
    Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju,
    William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin
    Button, Matthew Knight, Benjamin Chess, and John Schulman. 2022. [Webgpt: Browser-assisted
    question-answering with human feedback](http://arxiv.org/abs/2112.09332).'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nakano et al. (2022) Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu,
    Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju,
    William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin
    Button, Matthew Knight, Benjamin Chess, and John Schulman. 2022. [Webgpt：浏览器辅助的问答系统与人工反馈](http://arxiv.org/abs/2112.09332)。
- en: OpenAI et al. (2023) OpenAI, :, Josh Achiam, Steven Adler, Sandhini Agarwal,
    Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt,
    Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie
    Balcom, Paul Baltescu, Haiming Bao, Mo Bavarian, Jeff Belgum, Irwan Bello, Jake
    Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg
    Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman, Tim Brooks, Miles Brundage,
    Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany Carey, Chelsea
    Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek Chen,
    Sully Chen, Ruby Chen, Jason Chen, Mark Chen, Ben Chess, Chester Cho, Casey Chu,
    Hyung Won Chung, Dave Cummings, Jeremiah Currier, Yunxing Dai, Cory Decareaux,
    Thomas Degry, Noah Deutsch, Damien Deville, Arka Dhar, David Dohan, Steve Dowling,
    Sheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna Eloundou, David Farhi, Liam Fedus,
    Niko Felix, Simón Posada Fishman, Juston Forte, Isabella Fulford, Leo Gao, Elie
    Georges, Christian Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-Lopes,
    Jonathan Gordon, Morgan Grafstein, Scott Gray, Ryan Greene, Joshua Gross, Shixiang Shane
    Gu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris, Yuchen He, Mike Heaton,
    Johannes Heidecke, Chris Hesse, Alan Hickey, Wade Hickey, Peter Hoeschele, Brandon
    Houghton, Kenny Hsu, Shengli Hu, Xin Hu, Joost Huizinga, Shantanu Jain, Shawn
    Jain, Joanne Jang, Angela Jiang, Roger Jiang, Haozhun Jin, Denny Jin, Shino Jomoto,
    Billie Jonn, Heewoo Jun, Tomer Kaftan, Łukasz Kaiser, Ali Kamali, Ingmar Kanitscheider,
    Nitish Shirish Keskar, Tabarak Khan, Logan Kilpatrick, Jong Wook Kim, Christina
    Kim, Yongjik Kim, Hendrik Kirchner, Jamie Kiros, Matt Knight, Daniel Kokotajlo,
    Łukasz Kondraciuk, Andrew Kondrich, Aris Konstantinidis, Kyle Kosic, Gretchen
    Krueger, Vishal Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan Leike, Jade Leung,
    Daniel Levy, Chak Ming Li, Rachel Lim, Molly Lin, Stephanie Lin, Mateusz Litwin,
    Theresa Lopez, Ryan Lowe, Patricia Lue, Anna Makanju, Kim Malfacini, Sam Manning,
    Todor Markov, Yaniv Markovski, Bianca Martin, Katie Mayer, Andrew Mayne, Bob McGrew,
    Scott Mayer McKinney, Christine McLeavey, Paul McMillan, Jake McNeil, David Medina,
    Aalok Mehta, Jacob Menick, Luke Metz, Andrey Mishchenko, Pamela Mishkin, Vinnie
    Monaco, Evan Morikawa, Daniel Mossing, Tong Mu, Mira Murati, Oleg Murk, David
    Mély, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak, Arvind Neelakantan, Richard
    Ngo, Hyeonwoo Noh, Long Ouyang, Cullen O’Keefe, Jakub Pachocki, Alex Paino, Joe
    Palermo, Ashley Pantuliano, Giambattista Parascandolo, Joel Parish, Emy Parparita,
    Alex Passos, Mikhail Pavlov, Andrew Peng, Adam Perelman, Filipe de Avila Belbute Peres,
    Michael Petrov, Henrique Ponde de Oliveira Pinto, Michael, Pokorny, Michelle Pokrass,
    Vitchyr Pong, Tolly Powell, Alethea Power, Boris Power, Elizabeth Proehl, Raul
    Puri, Alec Radford, Jack Rae, Aditya Ramesh, Cameron Raymond, Francis Real, Kendra
    Rimbach, Carl Ross, Bob Rotsted, Henri Roussez, Nick Ryder, Mario Saltarelli,
    Ted Sanders, Shibani Santurkar, Girish Sastry, Heather Schmidt, David Schnurr,
    John Schulman, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah
    Shoker, Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin,
    Katarina Slama, Ian Sohl, Benjamin Sokolowsky, Yang Song, Natalie Staudacher,
    Felipe Petroski Such, Natalie Summers, Ilya Sutskever, Jie Tang, Nikolas Tezak,
    Madeleine Thompson, Phil Tillet, Amin Tootoonchian, Elizabeth Tseng, Preston Tuggle,
    Nick Turley, Jerry Tworek, Juan Felipe Cerón Uribe, Andrea Vallone, Arun Vijayvergiya,
    Chelsea Voss, Carroll Wainwright, Justin Jay Wang, Alvin Wang, Ben Wang, Jonathan
    Ward, Jason Wei, CJ Weinmann, Akila Welihinda, Peter Welinder, Jiayi Weng, Lilian
    Weng, Matt Wiethoff, Dave Willner, Clemens Winter, Samuel Wolrich, Hannah Wong,
    Lauren Workman, Sherwin Wu, Jeff Wu, Michael Wu, Kai Xiao, Tao Xu, Sarah Yoo,
    Kevin Yu, Qiming Yuan, Wojciech Zaremba, Rowan Zellers, Chong Zhang, Marvin Zhang,
    Shengjia Zhao, Tianhao Zheng, Juntang Zhuang, William Zhuk, and Barret Zoph. 2023.
    [Gpt-4 technical report](http://arxiv.org/abs/2303.08774).
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI 等人（2023）OpenAI，:，Josh Achiam、Steven Adler、Sandhini Agarwal、Lama Ahmad、Ilge
    Akkaya、Florencia Leoni Aleman、Diogo Almeida、Janko Altenschmidt、Sam Altman、Shyamal
    Anadkat、Red Avila、Igor Babuschkin、Suchir Balaji、Valerie Balcom、Paul Baltescu、Haiming
    Bao、Mo Bavarian、Jeff Belgum、Irwan Bello、Jake Berdine、Gabriel Bernadett-Shapiro、Christopher
    Berner、Lenny Bogdonoff、Oleg Boiko、Madelaine Boyd、Anna-Luisa Brakman、Greg Brockman、Tim
    Brooks、Miles Brundage、Kevin Button、Trevor Cai、Rosie Campbell、Andrew Cann、Brittany
    Carey、Chelsea Carlson、Rory Carmichael、Brooke Chan、Che Chang、Fotis Chantzis、Derek
    Chen、Sully Chen、Ruby Chen、Jason Chen、Mark Chen、Ben Chess、Chester Cho、Casey Chu、Hyung
    Won Chung、Dave Cummings、Jeremiah Currier、Yunxing Dai、Cory Decareaux、Thomas Degry、Noah
    Deutsch、Damien Deville、Arka Dhar、David Dohan、Steve Dowling、Sheila Dunning、Adrien
    Ecoffet、Atty Eleti、Tyna Eloundou、David Farhi、Liam Fedus、Niko Felix、Simón Posada
    Fishman、Juston Forte、Isabella Fulford、Leo Gao、Elie Georges、Christian Gibson、Vik
    Goel、Tarun Gogineni、Gabriel Goh、Rapha Gontijo-Lopes、Jonathan Gordon、Morgan Grafstein、Scott
    Gray、Ryan Greene、Joshua Gross、Shixiang Shane Gu、Yufei Guo、Chris Hallacy、Jesse
    Han、Jeff Harris、Yuchen He、Mike Heaton、Johannes Heidecke、Chris Hesse、Alan Hickey、Wade
    Hickey、Peter Hoeschele、Brandon Houghton、Kenny Hsu、Shengli Hu、Xin Hu、Joost Huizinga、Shantanu
    Jain、Shawn Jain、Joanne Jang、Angela Jiang、Roger Jiang、Haozhun Jin、Denny Jin、Shino
    Jomoto、Billie Jonn、Heewoo Jun、Tomer Kaftan、Łukasz Kaiser、Ali Kamali、Ingmar Kanitscheider、Nitish
    Shirish Keskar、Tabarak Khan、Logan Kilpatrick、Jong Wook Kim、Christina Kim、Yongjik
    Kim、Hendrik Kirchner、Jamie Kiros、Matt Knight、Daniel Kokotajlo、Łukasz Kondraciuk、Andrew
    Kondrich、Aris Konstantinidis、Kyle Kosic、Gretchen Krueger、Vishal Kuo、Michael Lampe、Ikai
    Lan、Teddy Lee、Jan Leike、Jade Leung、Daniel Levy、Chak Ming Li、Rachel Lim、Molly Lin、Stephanie
    Lin、Mateusz Litwin、Theresa Lopez、Ryan Lowe、Patricia Lue、Anna Makanju、Kim Malfacini、Sam
    Manning、Todor Markov、Yaniv Markovski、Bianca Martin、Katie Mayer、Andrew Mayne、Bob
    McGrew、Scott Mayer McKinney、Christine McLeavey、Paul McMillan、Jake McNeil、David
    Medina、Aalok Mehta、Jacob Menick、Luke Metz、Andrey Mishchenko、Pamela Mishkin、Vinnie
    Monaco、Evan Morikawa、Daniel Mossing、Tong Mu、Mira Murati、Oleg Murk、David Mély、Ashvin
    Nair、Reiichiro Nakano、Rajeev Nayak、Arvind Neelakantan、Richard Ngo、Hyeonwoo Noh、Long
    Ouyang、Cullen O’Keefe、Jakub Pachocki、Alex Paino、Joe Palermo、Ashley Pantuliano、Giambattista
    Parascandolo、Joel Parish、Emy Parparita、Alex Passos、Mikhail Pavlov、Andrew Peng、Adam
    Perelman、Filipe de Avila Belbute Peres、Michael Petrov、Henrique Ponde de Oliveira
    Pinto、Michael、Pokorny、Michelle Pokrass、Vitchyr Pong、Tolly Powell、Alethea Power、Boris
    Power、Elizabeth Proehl、Raul Puri、Alec Radford、Jack Rae、Aditya Ramesh、Cameron Raymond、Francis
    Real、Kendra Rimbach、Carl Ross、Bob Rotsted、Henri Roussez、Nick Ryder、Mario Saltarelli、Ted
    Sanders、Shibani Santurkar、Girish Sastry、Heather Schmidt、David Schnurr、John Schulman、Daniel
    Selsam、Kyla Sheppard、Toki Sherbakov、Jessica Shieh、Sarah Shoker、Pranav Shyam、Szymon
    Sidor、Eric Sigler、Maddie Simens、Jordan Sitkin、Katarina Slama、Ian Sohl、Benjamin
    Sokolowsky、Yang Song、Natalie Staudacher、Felipe Petroski Such、Natalie Summers、Ilya
    Sutskever、Jie Tang、Nikolas Tezak、Madeleine Thompson、Phil Tillet、Amin Tootoonchian、Elizabeth
    Tseng、Preston Tuggle、Nick Turley、Jerry Tworek、Juan Felipe Cerón Uribe、Andrea Vallone、Arun
    Vijayvergiya、Chelsea Voss、Carroll Wainwright、Justin Jay Wang、Alvin Wang、Ben Wang、Jonathan
    Ward、Jason Wei、CJ Weinmann、Akila Welihinda、Peter Welinder、Jiayi Weng、Lilian Weng、Matt
    Wiethoff、Dave Willner、Clemens Winter、Samuel Wolrich、Hannah Wong、Lauren Workman、Sherwin
    Wu、Jeff Wu、Michael Wu、Kai Xiao、Tao Xu、Sarah Yoo、Kevin Yu、Qiming Yuan、Wojciech
    Zaremba、Rowan Zellers、Chong Zhang、Marvin Zhang、Shengjia Zhao、Tianhao Zheng、Juntang
    Zhuang、William Zhuk 和 Barret Zoph。2023年。[Gpt-4 技术报告](http://arxiv.org/abs/2303.08774)。
- en: 'Overwijk et al. (2022) Arnold Overwijk, Chenyan Xiong, Xiao Liu, Cameron VandenBerg,
    and Jamie Callan. 2022. [Clueweb22: 10 billion web documents with visual and semantic
    information](http://arxiv.org/abs/2211.15848).'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Overwijk et al. (2022) Arnold Overwijk, Chenyan Xiong, Xiao Liu, Cameron VandenBerg,
    和 Jamie Callan. 2022. [Clueweb22: 100 亿个包含视觉和语义信息的网络文档](http://arxiv.org/abs/2211.15848)。'
- en: Peng et al. (2023) Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and
    Jianfeng Gao. 2023. Instruction tuning with gpt-4. *arXiv preprint arXiv:2304.03277*.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Peng et al. (2023) Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, 和
    Jianfeng Gao. 2023. 使用 GPT-4 进行指令调整。*arXiv 预印本 arXiv:2304.03277*。
- en: Press et al. (2023) Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A.
    Smith, and Mike Lewis. 2023. [Measuring and narrowing the compositionality gap
    in language models](http://arxiv.org/abs/2210.03350).
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Press et al. (2023) Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah
    A. Smith, 和 Mike Lewis. 2023. [测量和缩小语言模型中的组合性差距](http://arxiv.org/abs/2210.03350)。
- en: Radhakrishnan et al. (2023) Ansh Radhakrishnan, Karina Nguyen, Anna Chen, Carol
    Chen, Carson Denison, Danny Hernandez, Esin Durmus, Evan Hubinger, Jackson Kernion,
    Kamilė Lukošiūtė, Newton Cheng, Nicholas Joseph, Nicholas Schiefer, Oliver Rausch,
    Sam McCandlish, Sheer El Showk, Tamera Lanham, Tim Maxwell, Venkatesa Chandrasekaran,
    Zac Hatfield-Dodds, Jared Kaplan, Jan Brauner, Samuel R. Bowman, and Ethan Perez.
    2023. [Question decomposition improves the faithfulness of model-generated reasoning](http://arxiv.org/abs/2307.11768).
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Radhakrishnan et al. (2023) Ansh Radhakrishnan, Karina Nguyen, Anna Chen, Carol
    Chen, Carson Denison, Danny Hernandez, Esin Durmus, Evan Hubinger, Jackson Kernion,
    Kamilė Lukošiūtė, Newton Cheng, Nicholas Joseph, Nicholas Schiefer, Oliver Rausch,
    Sam McCandlish, Sheer El Showk, Tamera Lanham, Tim Maxwell, Venkatesa Chandrasekaran,
    Zac Hatfield-Dodds, Jared Kaplan, Jan Brauner, Samuel R. Bowman, 和 Ethan Perez.
    2023. [问题分解提升模型生成推理的可靠性](http://arxiv.org/abs/2307.11768)。
- en: Raffel et al. (2023) Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee,
    Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2023. [Exploring
    the limits of transfer learning with a unified text-to-text transformer](http://arxiv.org/abs/1910.10683).
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raffel et al. (2023) Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee,
    Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, 和 Peter J. Liu. 2023. [利用统一文本到文本的变换器探索迁移学习的极限](http://arxiv.org/abs/1910.10683)。
- en: 'Ren et al. (2023) Ruiyang Ren, Yingqi Qu, Jing Liu, Wayne Xin Zhao, Qiaoqiao
    She, Hua Wu, Haifeng Wang, and Ji-Rong Wen. 2023. [Rocketqav2: A joint training
    method for dense passage retrieval and passage re-ranking](http://arxiv.org/abs/2110.07367).'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ren et al. (2023) Ruiyang Ren, Yingqi Qu, Jing Liu, Wayne Xin Zhao, Qiaoqiao
    She, Hua Wu, Haifeng Wang, 和 Ji-Rong Wen. 2023. [Rocketqav2: 一种用于密集段落检索和段落重排名的联合训练方法](http://arxiv.org/abs/2110.07367)。'
- en: Shao et al. (2023) Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan
    Duan, and Weizhu Chen. 2023. [Enhancing retrieval-augmented large language models
    with iterative retrieval-generation synergy](http://arxiv.org/abs/2305.15294).
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shao et al. (2023) Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan
    Duan, 和 Weizhu Chen. 2023. [通过迭代检索-生成协同增强检索增强的大型语言模型](http://arxiv.org/abs/2305.15294)。
- en: Stayton (2015) C. T. Stayton. 2015. [What does convergent evolution mean? the
    interpretation of convergence and its implications in the search for limits to
    evolution](https://doi.org/10.1098/rsfs.2015.0039). *Interface Focus*, 5(6):20150039.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Stayton (2015) C. T. Stayton. 2015. [趋同进化意味着什么？趋同的解释及其在寻找进化限制中的影响](https://doi.org/10.1098/rsfs.2015.0039)。*界面焦点*，5(6):20150039。
- en: Taleb (2008) Nassim Nicholas Taleb. 2008. *The Black Swan*. Penguin Books, Harlow,
    England.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Taleb (2008) Nassim Nicholas Taleb. 2008. *黑天鹅*。企鹅图书，哈罗，英格兰。
- en: 'Trivedi et al. (2022) Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot,
    and Ashish Sabharwal. 2022. MuSiQue: Multihop questions via single-hop question
    composition. *Transactions of the Association for Computational Linguistics*.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Trivedi et al. (2022) Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot,
    和 Ashish Sabharwal. 2022. MuSiQue: 通过单跳问题组合实现多跳问题。*计算语言学协会会刊*。'
- en: Trivedi et al. (2023) Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot,
    and Ashish Sabharwal. 2023. [Interleaving retrieval with chain-of-thought reasoning
    for knowledge-intensive multi-step questions](http://arxiv.org/abs/2212.10509).
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trivedi et al. (2023) Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot,
    和 Ashish Sabharwal. 2023. [通过链式思维推理交替检索以解决知识密集型多步骤问题](http://arxiv.org/abs/2212.10509)。
- en: 'United States Congress et al. (1981) House Committee on Science United States Congress,
    Subcommittee on Space Science Technology, and Applications. 1981. *NASA Program
    Management and Procurement Procedures and Practices: Hearings Before the Subcommittee
    on Space Science and Applications of the Committee on Science and Technology,
    U.S. House of Representatives, Ninety-seventh Congress, First Session*. U.S. Government
    Printing Office, Washington, D.C.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 美国国会等 (1981) 美国国会科学委员会，空间科学技术与应用小组委员会。1981年。*NASA项目管理与采购程序及实践：美国众议院科学与技术委员会空间科学与应用小组委员会听证会，九十七届国会，第一次会议*。美国政府印刷局，华盛顿特区。
- en: Wei et al. (2023) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian
    Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2023. [Chain-of-thought prompting
    elicits reasoning in large language models](http://arxiv.org/abs/2201.11903).
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei et al. (2023) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian
    Ichter, Fei Xia, Ed Chi, Quoc Le, 和 Denny Zhou. 2023. [链式思维提示引发大语言模型中的推理](http://arxiv.org/abs/2201.11903)。
- en: 'Wu et al. (2023a) Jiayang Wu, Wensheng Gan, Zefeng Chen, Shicheng Wan, and
    Hong Lin. 2023a. [Ai-generated content (aigc): A survey](http://arxiv.org/abs/2304.06632).'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wu et al. (2023a) Jiayang Wu, Wensheng Gan, Zefeng Chen, Shicheng Wan, 和 Hong
    Lin. 2023a. [AI生成内容 (AIGC): 一项综述](http://arxiv.org/abs/2304.06632)。'
- en: 'Wu et al. (2023b) Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li,
    Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, Ahmed Hassan Awadallah,
    Ryen W White, Doug Burger, and Chi Wang. 2023b. [Autogen: Enabling next-gen llm
    applications via multi-agent conversation](http://arxiv.org/abs/2308.08155).'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wu et al. (2023b) Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li,
    Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, Ahmed Hassan Awadallah,
    Ryen W White, Doug Burger, 和 Chi Wang. 2023b. [Autogen: 通过多代理对话实现下一代大语言模型应用](http://arxiv.org/abs/2308.08155)。'
- en: Xiong et al. (2020) Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin
    Liu, Paul Bennett, Junaid Ahmed, and Arnold Overwijk. 2020. [Approximate nearest
    neighbor negative contrastive learning for dense text retrieval](http://arxiv.org/abs/2007.00808).
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xiong et al. (2020) Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin
    Liu, Paul Bennett, Junaid Ahmed, 和 Arnold Overwijk. 2020. [近似最近邻负对比学习用于密集文本检索](http://arxiv.org/abs/2007.00808)。
- en: 'Yang et al. (2018) Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W.
    Cohen, Ruslan Salakhutdinov, and Christopher D. Manning. 2018. [Hotpotqa: A dataset
    for diverse, explainable multi-hop question answering](http://arxiv.org/abs/1809.09600).'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yang et al. (2018) Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William
    W. Cohen, Ruslan Salakhutdinov, 和 Christopher D. Manning. 2018. [Hotpotqa: 一个用于多跳问答的多样化、可解释数据集](http://arxiv.org/abs/1809.09600)。'
- en: 'Yao et al. (2023a) Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L.
    Griffiths, Yuan Cao, and Karthik Narasimhan. 2023a. [Tree of thoughts: Deliberate
    problem solving with large language models](http://arxiv.org/abs/2305.10601).'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao et al. (2023a) Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas
    L. Griffiths, Yuan Cao, 和 Karthik Narasimhan. 2023a. [思想树：与大语言模型进行深思熟虑的问题解决](http://arxiv.org/abs/2305.10601)。
- en: 'Yao et al. (2023b) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik Narasimhan, and Yuan Cao. 2023b. [React: Synergizing reasoning and acting
    in language models](http://arxiv.org/abs/2210.03629).'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yao et al. (2023b) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik Narasimhan, 和 Yuan Cao. 2023b. [React: 语言模型中推理与行动的协同](http://arxiv.org/abs/2210.03629)。'
- en: Yuan et al. (2024) Weizhe Yuan, Richard Yuanzhe Pang, Kyunghyun Cho, Xian Li,
    Sainbayar Sukhbaatar, Jing Xu, and Jason Weston. 2024. [Self-rewarding language
    models](http://arxiv.org/abs/2401.10020).
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yuan et al. (2024) Weizhe Yuan, Richard Yuanzhe Pang, Kyunghyun Cho, Xian Li,
    Sainbayar Sukhbaatar, Jing Xu, 和 Jason Weston. 2024. [自奖励语言模型](http://arxiv.org/abs/2401.10020)。
- en: 'Zhang et al. (2023) Jiahao Zhang, Haiyang Zhang, Dongmei Zhang, Yong Liu, and
    Shen Huang. 2023. [Beam retrieval: General end-to-end retrieval for multi-hop
    question answering](http://arxiv.org/abs/2308.08973).'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang et al. (2023) Jiahao Zhang, Haiyang Zhang, Dongmei Zhang, Yong Liu, 和
    Shen Huang. 2023. [Beam retrieval: 多跳问答的通用端到端检索](http://arxiv.org/abs/2308.08973)。'
- en: Zhang et al. (2016) Xiang Zhang, Junbo Zhao, and Yann LeCun. 2016. [Character-level
    convolutional networks for text classification](http://arxiv.org/abs/1509.01626).
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2016) Xiang Zhang, Junbo Zhao, 和 Yann LeCun. 2016. [字符级卷积网络用于文本分类](http://arxiv.org/abs/1509.01626)。
- en: 'Zhang et al. (2021) Yi Zhang, Sujay Kumar Jauhar, Julia Kiseleva, Ryen White,
    and Dan Roth. 2021. [Learning to decompose and organize complex tasks](https://doi.org/10.18653/v1/2021.naacl-main.217).
    In *Proceedings of the 2021 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies*, pages 2726–2735,
    Online. Association for Computational Linguistics.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang等（2021）Yi Zhang、Sujay Kumar Jauhar、Julia Kiseleva、Ryen White 和 Dan Roth.
    2021. [学习分解和组织复杂任务](https://doi.org/10.18653/v1/2021.naacl-main.217). 见于*2021年北美计算语言学协会：人类语言技术会议论文集*，第2726–2735页，在线。计算语言学协会。
- en: Zheng et al. (2023a) Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang,
    Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric P. Xing, Hao
    Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023a. [Judging llm-as-a-judge with
    mt-bench and chatbot arena](http://arxiv.org/abs/2306.05685).
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng等（2023a）Lianmin Zheng、Wei-Lin Chiang、Ying Sheng、Siyuan Zhuang、Zhanghao
    Wu、Yonghao Zhuang、Zi Lin、Zhuohan Li、Dacheng Li、Eric P. Xing、Hao Zhang、Joseph E.
    Gonzalez 和 Ion Stoica. 2023a. [用mt-bench和chatbot arena评判LLM作为裁判](http://arxiv.org/abs/2306.05685)。
- en: Zheng et al. (2023b) Shen Zheng, Jie Huang, and Kevin Chen-Chuan Chang. 2023b.
    [Why does chatgpt fall short in providing truthful answers?](http://arxiv.org/abs/2304.10513)
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng等（2023b）Shen Zheng、Jie Huang 和 Kevin Chen-Chuan Chang. 2023b. [为什么ChatGPT在提供真实答案方面表现欠佳？](http://arxiv.org/abs/2304.10513)
- en: Zhou et al. (2023) Kun Zhou, Yutao Zhu, Zhipeng Chen, Wentong Chen, Wayne Xin
    Zhao, Xu Chen, Yankai Lin, Ji-Rong Wen, and Jiawei Han. 2023. [Don’t make your
    llm an evaluation benchmark cheater](http://arxiv.org/abs/2311.01964).
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou等（2023）Kun Zhou、Yutao Zhu、Zhipeng Chen、Wentong Chen、Wayne Xin Zhao、Xu Chen、Yankai
    Lin、Ji-Rong Wen 和 Jiawei Han. 2023. [不要让你的LLM成为评估基准的作弊者](http://arxiv.org/abs/2311.01964)。
- en: Appendix A GPT-4-based Filtering Details
  id: totrans-269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录A GPT-4基础的过滤细节
- en: '![Refer to caption](img/12cedbdcb28d6ac9050f18160233a197.png)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/12cedbdcb28d6ac9050f18160233a197.png)'
- en: 'Figure 2: (Right) Histogram of number of documents clicked per question for
    Researchy Questions which is much higher than for general web search queries.
    (Left) number of queries associated with each document. The fact that not very
    many queries are associated with each document validates the effectiveness of
    our query-deduplication procedure.'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：（右）每个问题点击的文档数量直方图，对于研究性问题明显高于普通网页搜索查询。（左）与每个文档相关的查询数量。每个文档关联的查询数量较少，这验证了我们查询去重程序的有效性。
- en: '![Refer to caption](img/d18ce64dc041a276aca730a48275ba16.png)![Refer to caption](img/a83fa4bbe7cc5e8ef00269112cd1017e.png)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d18ce64dc041a276aca730a48275ba16.png)![参见说明](img/a83fa4bbe7cc5e8ef00269112cd1017e.png)'
- en: 'Figure 3: (Left) Non-factoid scores of the 15.7M QnA Queries. The roughly 1M
    queries whose score exceeded the threshold +0.75 were sent to the Decompositional
    classifier. Note that because this was a binary classifier, 89% of the non-factoid
    scores were less than -0.75, which is cut off from the left-hand histogram to
    make it easier to visualize. (Right) The Decompositional classifier’s scores of
    the roughly 1M Non-factoid queries. Around 146k queries exceeding the 0.6 threshold
    line resulted are considered both Non-factoid and Decompositional, and were then
    de-duplicated to arrive at the final Researchy Questions dataset of around 100k.'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：（左）15.7M问答查询的非事实型分数。约1M查询的分数超过阈值+0.75，已送至分解分类器。请注意，由于这是一个二分类器，89%的非事实型分数低于-0.75，这部分数据在左侧直方图中被剪切，以便更清晰地可视化。（右）约1M非事实型查询的分解分类器分数。约146k查询超过0.6阈值线，被认为既是非事实型又是分解型，然后进行了去重，最终得到约10万的研究性问题数据集。
- en: '| Question | Factoid | Decompositional ($\downarrow$) |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| 问题 | 事实型 | 分解型 ($\downarrow$) |'
- en: '| --- | --- | --- |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Why is it illegal to destroy money | 1.02 | 0.59 |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| 为什么破坏货币是非法的 | 1.02 | 0.59 |'
- en: '| Which law firms offer the best opportunities for international work? | 1.07
    | 0.58 |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| 哪些律师事务所提供最佳的国际工作机会？ | 1.07 | 0.58 |'
- en: '| How should a grad student communicate with faculty | 0.80 | 0.56 |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| 研究生应如何与教师沟通 | 0.80 | 0.56 |'
- en: '| How does a short story differ from a novel | 1.07 | 0.54 |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| 短篇小说与小说有何不同 | 1.07 | 0.54 |'
- en: '| Why is Beowulf an important literary work | 1.10 | 0.51 |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| 为什么《贝奥武夫》是一部重要的文学作品 | 1.10 | 0.51 |'
- en: '| Why are e scooters illegal | 0.90 | 0.50 |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| 为什么电动滑板车是非法的 | 0.90 | 0.50 |'
- en: '| Why did the declaration of independence start | 1.12 | 0.49 |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| 为什么独立宣言会开始 | 1.12 | 0.49 |'
- en: '| How did marsupials evolve | 1.02 | 0.48 |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| 有袋动物是如何进化的 | 1.02 | 0.48 |'
- en: '| Is turbulence dangerous | 0.97 | 0.47 |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| 湍流是否危险 | 0.97 | 0.47 |'
- en: '| Why do people cut down the Amazon rainforest | 1.09 | 0.45 |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| 为什么人们砍伐亚马逊雨林 | 1.09 | 0.45 |'
- en: '| Why are flags at half mast in Indiana today | 1.06 | 0.45 |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| 为什么今天印第安纳州的旗帜降半旗 | 1.06 | 0.45 |'
- en: '| Why the houses in Rajasthan have thick walls and flat roofs? | 1.06 | 0.43
    |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| 为什么拉贾斯坦邦的房屋有厚墙和扁平的屋顶？ | 1.06 | 0.43 |'
- en: '| How do forensic pathologists determine cause and manner of death? | 1.02
    | 0.43 |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| 法医病理学家如何确定死因和死亡方式？ | 1.02 | 0.43 |'
- en: '| What causes changes in the moon’s appearance | 1.10 | 0.41 |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| 什么原因导致月球外观变化 | 1.10 | 0.41 |'
- en: '| How did Edgar Allan Poe start his writing career | 0.97 | 0.40 |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| 埃德加·艾伦·坡是如何开始他的写作生涯的 | 0.97 | 0.40 |'
- en: '| How common was vasectomy in the 1950’s | 0.90 | 0.40 |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| 1950年代输精管结扎术的普及程度如何 | 0.90 | 0.40 |'
- en: '| Why are behavioral questions important | 0.79 | 0.38 |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '| 为什么行为问题很重要 | 0.79 | 0.38 |'
- en: '| Is pepper spray harmful | 0.93 | 0.37 |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '| 胡椒喷雾是否有害 | 0.93 | 0.37 |'
- en: '| How do fertilizers increase productivity | 1.05 | 0.35 |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| 肥料如何提高生产力 | 1.05 | 0.35 |'
- en: '| How do we get matter and energy from food | 1.11 | 0.32 |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| 我们如何从食物中获取物质和能量 | 1.11 | 0.32 |'
- en: '| What type of competition occurs when only a few firms dominate a market?
    | 1.08 | 0.31 |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '| 当只有少数几家公司主导一个市场时，会发生什么类型的竞争？ | 1.08 | 0.31 |'
- en: '| Why can’t waves travel through a vacuum? | 1.08 | 0.30 |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
  zh: '| 为什么波不能在真空中传播？ | 1.08 | 0.30 |'
- en: '| What caused the Dixie fire | 0.84 | 0.29 |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '| 迪克西火灾的原因是什么 | 0.84 | 0.29 |'
- en: '| Why camels live in desert | 1.02 | 0.29 |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| 为什么骆驼生活在沙漠中 | 1.02 | 0.29 |'
- en: '| How was COVID-19 discovered | 0.92 | 0.28 |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '| COVID-19是如何被发现的 | 0.92 | 0.28 |'
- en: '| How are elements organized into groups | 0.96 | 0.27 |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '| 元素如何被组织成不同的组 | 0.96 | 0.27 |'
- en: '| Why did Montezuma give the Spanish gold? | 1.01 | 0.27 |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '| 为什么蒙特祖马给西班牙人黄金？ | 1.01 | 0.27 |'
- en: '| Differences between debt and equity financing | 0.98 | 0.27 |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '| 债务融资与股权融资的区别 | 0.98 | 0.27 |'
- en: '| How are fossils older than 60,000 years dated? | 1.08 | 0.17 |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
  zh: '| 如何对超过60,000年的化石进行年代测定？ | 1.08 | 0.17 |'
- en: '| What happens when a data collision occurs on an Ethernet bus? | 1.03 | 0.16
    |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '| 当以太网总线上发生数据碰撞时会发生什么？ | 1.03 | 0.16 |'
- en: '| How is gold formed in the earth’s crust | 0.98 | 0.12 |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '| 黄金是如何在地壳中形成的 | 0.98 | 0.12 |'
- en: 'Table 6: Examples of QnA Queries that were non-factoid (had a non-factoid classifier
    score above 0.75), but were not decompositional (had decompositional classifier
    score less than 0.6). Further down this list, more of the examples have a single
    correct answer (even if it is somewhat long-form), but there is obviously a lot
    of gray area, highlighting the challenges of trying to filter large amounts of
    queries by simple thresholds.'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 表6：非事实性（具有非事实性分类器得分超过0.75）的问答查询示例，但不是分解性的（具有分解性分类器得分低于0.6）。在这个列表的进一步下方，更多的示例有单一的正确答案（即使它有点长），但显然存在很多灰色地带，突显了通过简单阈值过滤大量查询的挑战。
- en: For the following (Question | score | reason) triples, the score indicates how
    "good" of a non-factoid question they are in the sense that they can lead to interesting
    and in-depth analysis.
  id: totrans-308
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 对于以下的（问题 | 分数 | 原因）三元组，分数表示它们在引发有趣且深入分析方面的“优秀”程度。
- en: 'Definition: A good non-factoid question is specific, with potential to amount
    to a good research report with a clear and refutable thesis, supported by evidence
    and analysis.'
  id: totrans-309
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义：一个好的非事实性问题是具体的，有潜力成为一个好的研究报告，具有清晰且可以反驳的论点，并得到证据和分析的支持。
- en: 'Characteristic formats of good non-factoid questions (not exhaustive):'
  id: totrans-310
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优秀的非事实性问题的特征格式（并不详尽）：
- en: •
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Good non-factoid questions will often talk about the relationship between two
    things, e.g. "Compare and contrast X and Y", "How/why does X affect/impact Y?",
    "Why X is significant to Y", or "What role does X play in Y?", or "to what extent
    does X lead to Y?", etc.
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 优秀的非事实性问题通常会讨论两个事物之间的关系，例如“比较和对比X和Y”，“X如何/为什么影响Y？”，“为什么X对Y重要”，或“X在Y中扮演什么角色？”，或者“X在多大程度上导致Y？”，等等。
- en: •
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: A good non-factoid question can also ask "Why does X happen", "What factors
    play a role in X?", "How is X significant" or "What is the cause of X", but it
    should be specific about what kind of analysis is expected.
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一个好的非事实性问题也可以问“为什么X会发生”，“在X中起作用的因素是什么？”，“X有什么重要性”或“X的原因是什么”，但应明确期望的分析类型。
- en: •
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Other forms of good non-factoid questions can ask about the pros/cons, benefits/detriments
    of something, or compare/contrast two things, etc.
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 其他形式的优秀非事实性问题可以询问某事的利弊、优缺点，或者比较/对比两件事等。
- en: 'Instructions: Rate each question on a scale of 0-10, where 0 is a factoid question
    and 10 is an excellent non-factoid question and then provide a brief reason for
    your rating'
  id: totrans-317
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 说明：对每个问题进行0-10的评分，其中0表示事实性问题，10表示优秀的非事实性问题，然后提供简要的评分理由
- en: 'Q: how tall is abraham lincoln | 0 | factoid'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 问：亚伯拉罕·林肯有多高？ | 0 | 事实性问题
- en: 'Q: can i change the weather | 2 | personal question'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 问：我可以改变天气吗？ | 2 | 个人问题
- en: 'Q: was the civil war fought over slavery | 5 | fair, but could more directly
    ask about other important facets of the causes of the civil war and their role
    in the conflict'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 问：内战是否为了奴隶制而打的？ | 5 | 一般，但可以更直接地询问内战原因的其他重要方面及其在冲突中的作用
- en: 'Q: to what extent was the civil war fought over slavery | 8 | good, will lead
    to in-depth analysis on the causes of the civil war'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 问：内战在多大程度上是为了奴隶制而打的？ | 8 | 很好，将引导对内战原因的深入分析
- en: 'Q: what impact do human activities have on the weather | 10 | excellent, many
    in-depth reports written to answer this question'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 问：人类活动对天气有什么影响？ | 10 | 极佳，许多深入报告已为回答此问题而写
- en: 'Q: should LA invest more in railway or highway infrastructure for public transport
    | 9 | great'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 问：洛杉矶应该在铁路还是公路基础设施上投入更多？ | 9 | 很好
- en: 'Q: what is an example of blackbody radiation? | 0 | asking for an example'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 问：黑体辐射的例子是什么？ | 0 | 询问例子
- en: 'Q: could not determine type for | 0 | not a question'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 问：无法确定类型 | 0 | 不是一个问题
- en: 'Q: what typically signals the end of the olympic games | 2 | factoid, olympic
    closing ceremony can be looked up easily'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 问：通常什么信号表示奥运会的结束？ | 2 | 事实性问题，奥运会闭幕式容易查找
- en: 'Q: Why were Navajo code talkers used during WW2? | 7 | good, could lead to
    analysis of how culture and language can be used in warfare'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 问：为什么二战期间使用纳瓦霍密码员？ | 7 | 很好，可能引发对文化和语言如何在战争中使用的分析
- en: 'Q: When does protein folding begin? | 1 | has a single, known correct answer'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 问：蛋白质折叠何时开始？ | 1 | 有一个已知的正确答案
- en: 'Q: what is the cost and necessary materials to build a refinery | 5 | fair,
    asks about a complex process but will not likely elicit analysis'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 问：建造炼油厂的成本和必要材料是什么？ | 5 | 一般，涉及复杂过程但不太可能引发分析
- en: 'Q: What is the Navavidha Bhakti? | 0 | asking for a definition'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 问：Navavidha Bhakti是什么？ | 0 | 询问定义
- en: 'Q: why is technological change bad? | 5 | fair, but could be more specific'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 问：为什么技术变革是坏的？ | 5 | 一般，但可以更具体一些
- en: 'Q: analyze how technological changes have historically impacted cultures |
    10 | excellent, very specific'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 问：分析技术变革历史上如何影响文化 | 10 | 极佳，非常具体
- en: 'Q: who owns phone number 280-626-1435 | 0 | personally identifiable information'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 问：谁拥有电话号码280-626-1435？ | 0 | 个人可识别信息
- en: 'Q: What are the main differences between regulations of the NFL and the CFL?
    | 4 | has potential for in-depth analysis but doesn’t explicitly ask for it'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 问：NFL和CFL的规定主要有什么不同？ | 4 | 具有深入分析的潜力但并没有明确要求
- en: 'Q: Why do planes using rivets & not welded construction? | 7 | good, will require
    in-depth analysis on aerospace technology'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 问：为什么飞机使用铆钉而不是焊接结构？ | 7 | 很好，需要对航空技术进行深入分析
- en: 'Q: How did the Catholic Pope manage to become more powerful than Kings in old
    Europe? | 9 | much potential for historical analysis'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 问：为什么天主教教皇在古欧洲如何比国王更具权力？ | 9 | 历史分析潜力大
- en: 'Q: interesting facts about korea | 0 | not specific'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 问：关于韩国的有趣事实 | 0 | 不具体
- en: 'Q: {Question} |'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 问：{Question} |
- en: 'Figure 4: Prompt given to text-davinci-003 to collect labels of whether a question
    is non-factoid. The current question is substituted at the end. Labels on 1-10
    were binarized based to train the non-factoid classifier.'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：对text-davinci-003提出的提示，用于收集问题是否为非事实性的问题的标签。当前问题在末尾进行了替换。1-10的标签经过二元化，以训练非事实性分类器。
- en: 'Question: {Question}'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 问：{Question}
- en: 'Instructions: how clearly does the above question require sub-questions in
    order to answer it? Think silently about how complex or multi-facted the question
    is. Imagine you are a person trying to answer the question using a search engine
    like Google. Would the person likely have to issue multiple queries to arrive
    at a comprehensive answer? Would they need to exert more effort to fully understand
    the nuances behind the question, or different perspectives surrounding it? etc.
    Or, is the person likely to find the best answer with a single search with low
    effort? Give your rating on 1-100 between  and  tags, where 1 means
    the question is trivial or common knowledge, while 100 means it likely involves
    effort to break the question down into many sub-questions or facets. '
  id: totrans-341
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 说明：上述问题需要多少子问题才能清晰回答？静默思考一下这个问题的复杂性或多面性。想象一下你是一个试图使用像Google这样的搜索引擎来回答这个问题的人。这个人是否可能需要发出多个查询才能得出全面的答案？他们是否需要更多的努力来充分理解问题背后的细微差别或不同的视角？等等。或者，这个人是否有可能通过一次低成本的搜索找到最佳答案？请在``和``标签之间给出你的评分，1表示问题是琐碎的或常识性的，而100表示问题很可能涉及将问题拆分为多个子问题或方面的努力。
- en: 'Figure 5: Prompt given to gpt-35-turbo to collect labels of how appropriate
    a question is for “decomposition” into sub-questions. These labels were used to
    train the Decompositional classifier.'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：给gpt-35-turbo的提示，用于收集问题适合“分解”成子问题的标签。这些标签用于训练分解分类器。
- en: '![Refer to caption](img/a9dc428378c5964e44b49f3583ff23f1.png)'
  id: totrans-343
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/a9dc428378c5964e44b49f3583ff23f1.png)'
- en: 'Figure 6: We had GPT-4 label all 102k Researchy question – and a uniform sample
    of 2k Natural Questions – along 8 dimensions using the prompt in Figure [7](#A1.F7
    "Figure 7 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A
    Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents").
    Each dimension was on a scale of 1-10; we plot their normalized densities. For
    Researchy Questions, these are the scores of the final 96k released questions
    after final filtering described in Section [2.5](#S2.SS5 "2.5 Stage 5: Final GPT-4
    Filtering ‣ 2 Researchy Questions Construction ‣ Researchy Questions: A Dataset
    of Multi-Perspective, Decompositional Questions for LLM Web Agents"). Lower scores
    are better for Ambiguity, Incompleteness, Assumptiveness and Harmfulness. We intended
    Researchy Questions to have higher scores for Knowledge-intensiveness, Reasoning-intensiveness
    and Multi-facetedness.'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：我们让GPT-4标记了所有102k Researchy 问题，以及2k自然问题的均匀样本，按照图 [7](#A1.F7 "图 7 ‣ 附录 A
    基于GPT-4的筛选细节 ‣ Researchy 问题：一个多视角、分解性问题的数据集")中提示的8个维度。每个维度的评分范围是1-10；我们绘制了它们的归一化密度。对于Researchy
    问题，这些是最终96k发布问题的评分，经过第 [2.5](#S2.SS5 "2.5 阶段 5：最终 GPT-4 筛选 ‣ 2 Researchy 问题构建
    ‣ Researchy 问题：一个多视角、分解性问题的数据集")节描述的最终筛选。较低的分数对模糊性、不完整性、假设性和有害性较好。我们希望Researchy
    问题在知识密集度、推理密集度和多面性方面有较高的分数。
- en: 'We had GPT-4 label certain attributes of each Researchy Question using the
    prompt given in Figure [7](#A1.F7 "Figure 7 ‣ Appendix A GPT-4-based Filtering
    Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents"). Particularly, we focus on removing questions that
    were too incomplete or underspecified to meaningfully answer (shown in Table [7](#A1.T7
    "Table 7 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A Dataset
    of Multi-Perspective, Decompositional Questions for LLM Web Agents")), or those
    that are too presumptuous (shown in Table  [8](#A1.T8 "Table 8 ‣ Appendix A GPT-4-based
    Filtering Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents")). Incomplete queries could arise when users ask
    queries that e.g. refer to previous queries or subjects in their session.'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 我们让GPT-4标记了每个Researchy问题的某些属性，使用了图 [7](#A1.F7 "图 7 ‣ 附录 A 基于GPT-4的筛选细节 ‣ Researchy
    问题：一个多视角、分解性问题的数据集")中给出的提示。特别是，我们专注于去除那些过于不完整或不明确，以至于无法有意义回答的问题（见表 [7](#A1.T7
    "表 7 ‣ 附录 A 基于GPT-4的筛选细节 ‣ Researchy 问题：一个多视角、分解性问题的数据集")），或者那些过于假设性的问题（见表 [8](#A1.T8
    "表 8 ‣ 附录 A 基于GPT-4的筛选细节 ‣ Researchy 问题：一个多视角、分解性问题的数据集")）。不完整的查询可能出现在用户提出的查询中，例如，涉及他们会话中的先前查询或主题。
- en: '| how can climate change | why did the market crash |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '| 气候变化如何影响 | 为什么市场崩溃了 |'
- en: '| --- | --- |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| are perspectives that change when presented with fresh experiences | how
    did the war for independence end |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '| 观点在面对新经验时是否会发生变化 | 独立战争是如何结束的 |'
- en: '| in what ways did native peoples transform | how dangeous can a persona affect
    a person personality |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
  zh: '| 本土人民以什么方式进行了转变 | 人格如何对个人性格产生影响 |'
- en: '| how would the law treat the issues confronting a diverse family? | how did
    president lyndon b. johnson respond to this event? |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '| 法律如何处理多样家庭面临的问题？ | 林登·约翰逊总统对这一事件的反应如何？ |'
- en: '| compare and contrast social contract | what is the difference in how the
    government reacted in these two situations? |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
  zh: '| 比较和对比社会契约 | 政府在这两种情况下的反应有什么不同？ |'
- en: '| how were others influenced by miyamoto | explain why summers were difficult
    for europeans. |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '| 其他人是如何受到宫本影响的 | 解释为什么夏天对欧洲人来说很困难。 |'
- en: '| what effect did the recent looting have on emigration | what is the main
    reason why some teams never reach stage 4 |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '| 最近的掠夺对移民产生了什么影响 | 为什么有些团队从未达到第四阶段 |'
- en: 'Table 7: Examples of incomplete or ambiguous queries a.k.a too underspecified
    to attempt to answer meaningfully (roughly 3% of queries in the last stage of
    filtering) that were removed from the dataset by additional GPT-4 filtering.'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7：示例显示了不完整或模糊的查询，即在最后阶段过滤时约 3% 的查询，这些查询被额外的 GPT-4 过滤器从数据集中移除。
- en: '| how college became a ruthless competition divorced from learning | why is
    airline customer service so bad |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| 大学如何变成了与学习脱节的无情竞争 | 为什么航空公司客户服务如此糟糕 |'
- en: '| --- | --- |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| why are police departments afraid of change | why immigration is bad for
    the us |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '| 为什么警察部门害怕变化 | 为什么移民对美国不好 |'
- en: '| why did chinese families not desire to have female children? | why do games
    make people socially disconnected from people |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '| 为什么中国家庭不愿意生女儿？ | 为什么游戏使人们与他人社交脱节 |'
- en: '| why are catholics democrats | why junior doctors are treated so badly |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '| 为什么天主教徒是民主党人 | 为什么初级医生待遇如此糟糕 |'
- en: '| how casinos have ruined towns | why should zoos be shut down |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| 赌场如何毁掉城镇 | 为什么动物园应该关闭 |'
- en: '| how is the government controlling us | why rehabilitation does not work in
    america |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| 政府是如何控制我们的 | 为什么在美国康复治疗无效 |'
- en: '| why veganism is bad for animals | why most clinical research is not useful
    |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| 为什么素食主义对动物有害 | 为什么大多数临床研究没有用 |'
- en: 'Table 8: Examples of “presumptious” queries we removed from the dataset (roughly
    2% of queries in the last stage of filtering), roughly defined as those where
    the question is slanted or biased in some way. Note, not all assumptive queries
    were harmful.'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8：示例显示了我们从数据集中移除的“冒昧”查询（大约 2% 的查询在最后阶段过滤时），大致定义为问题有某种倾斜或偏见。注意，并非所有假设性查询都是有害的。
- en: 'Given the question: {Question}'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 给定的问题：{Question}
- en: 'Instructions: Please output a python dictionary with fields scoring the question
    on the following criteria:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 说明：请输出一个包含字段的 Python 字典，用于根据以下标准对问题进行评分：
- en: '1.'
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: '"ambiguous" : Int 0-10 to what extent is the intent of the question ambiguous
    (has more than one interpretation); 0 means no major ambiguity. Not to be confused
    with subjectiveness or incompleteness.'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"模糊性"：Int 0-10 问题意图的模糊程度（有多种解释）；0 表示没有主要模糊性。不要与主观性或不完整性混淆。'
- en: '2.'
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: '"incompleteness" : Int 0-10 indicating how difficult it is to determine the
    intent of the question, whether it is missing crucial context or details that
    ought to be specified in order to answer the question; 0 means the question is
    answerable and self-contained, 10 means the question is un-answerable because
    it is incomplete or under-specified.'
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"不完整性"：Int 0-10 表示确定问题意图的难易程度，是否缺少重要的背景或细节，需要明确以回答问题；0 表示问题是可以回答的且自包含的，10 表示问题无法回答，因为它不完整或规格不足。'
- en: '3.'
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: '"assumptive" : Int 0-10 the degree to which the question has built-in assumptions
    or biases (that are not offensive, which is point 8 below); 0 means no notable
    or unreasonable assumptions.'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"假设性"：Int 0-10 该问题具有内置假设或偏见的程度（不具有攻击性，这是下面第 8 点）；0 表示没有明显或不合理的假设。'
- en: '4.'
  id: totrans-372
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: '"multi-faceted" : Int 0-10 the degree to which the question has multiple facets
    or perspectives that need to be considered in order to answer it; 0 means the
    question is straightforward and has a single, undisputed answer.'
  id: totrans-373
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"多面性"：Int 0-10 该问题需要考虑多个方面或视角的程度；0 表示问题直接且具有单一、无争议的答案。'
- en: '5.'
  id: totrans-374
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: '"knowledge-intensive" : Int 0-10 the degree to which the question would require
    specialized knowledge (like textbooks, scholarly articles, etc) to provide a thorough
    and grounded answer; 0 means the answer is common knowledge or can be looked up
    instantly in common references, 10 means the questions probably entails a lot
    of work to find and analyze specialized knowledge.'
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '“knowledge-intensive” : Int 0-10 问题需要专门知识（如教科书、学术文章等）以提供彻底且有根据的回答的程度；0表示答案是常识或可以立即在常见参考资料中查找，10表示问题可能需要大量工作来查找和分析专门知识。'
- en: '6.'
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '6.'
- en: '"subjective" : Int 0-10 the degree to which the question is subjective, meaning
    an answer(s) exist, but there is no agreed-upon way to determine which one is
    better; 0 means the question is largely objective i.e. the overwhelming majority
    of people would agree on the answer if they knew it.'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '“subjective” : Int 0-10 问题的主观程度，意味着存在答案，但没有公认的方式来确定哪个答案更好；0表示问题在很大程度上是客观的，即如果大家知道答案，绝大多数人会达成一致。'
- en: '7.'
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '7.'
- en: '"reasoning-intensive" : Int 0-10 the degree to which the question requires
    reasoning to synthesize an answer; 0 means the question can be answered trivially
    e.g. by looking up a fact, referencing an encyclopedia or database, or using a
    calculator (once).'
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '“reasoning-intensive” : Int 0-10 问题需要推理来综合回答的程度；0表示问题可以通过查找事实、参考百科全书或数据库，或使用计算器（一次）来轻松回答。'
- en: '8.'
  id: totrans-380
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '8.'
- en: '"harmful" : Int 0-10 to what extent the question could be interpreted as being
    harmful (physically or psychologically to oneself, others, or animals), offensive,
    overly biased, sexually explicit, or otherwise inappropriate for e.g. someone
    of the age of 12 to be exposed to.'
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '“harmful” : Int 0-10 该问题在多大程度上可能被解读为对自己、他人或动物有害（身体上或心理上）、冒犯、过于偏见、性暗示，或其他不适合例如12岁年龄段的人接触的内容。'
- en: Note that the above criteria are not mutually exclusive, e.g. a question can
    be both subjective and knowledge-intensive, for example "is capitalism better
    than socialism" would be both. Make sure to output only the valid python dictionary
    without comments or other extraneous output.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，上述标准并非互相排斥，例如一个问题可以既是主观的又是知识密集型的，例如“资本主义是否优于社会主义”就两者皆是。确保仅输出有效的python字典，不要包含评论或其他多余的输出。
- en: 'Figure 7: Prompt given to GPT-4 to classify attributes of each of the Researchy
    Questions. The output labels were used to further filter the data for release.'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：给GPT-4的提示，用于对每个研究问题的属性进行分类。输出标签被用来进一步筛选发布的数据。
- en: A.1 Additional Safety Filtering
  id: totrans-384
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 额外的安全过滤
- en: In addition to the official offensiveness/adult query classifiers used in our
    commericial search engine, we also had GPT-4 label on a scale of 1-10 “to what
    extent the question could be interpreted as being harmful (physically or psychologically
    to oneself, others, or animals), offensive, overly biased, sexually explicit,
    or otherwise inappropriate for e.g. someone of the age of 12 to be exposed to.”.
    We found roughly 2% of queries had an unsatisfactory harmfulness score and hence
    were removed from the released dataset.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在我们的商业搜索引擎中使用的官方攻击性/成人内容查询分类器外，我们还让GPT-4对问题进行1到10的评分，以评估“该问题在多大程度上可能被解读为对自己、他人或动物有害（身体上或心理上）、冒犯、过于偏见、性暗示，或其他不适合例如12岁年龄段的人接触的内容”。我们发现大约2%的查询具有令人不满意的危害评分，因此被从发布的数据集中移除。
- en: 'Table [9](#A1.T9 "Table 9 ‣ A.1 Additional Safety Filtering ‣ Appendix A GPT-4-based
    Filtering Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents") shows some examples of those removed. Real people
    asked these questions: we acknowledge that some of these may be motivated by genuine
    information-seeking intent, notwithstanding, we believe there is too high a risk
    that the act of answering these questions may lead to harm.'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 表[9](#A1.T9 "表9 ‣ A.1 额外的安全过滤 ‣ 附录A GPT-4基础的过滤细节 ‣ 研究性问题：一个多视角的拆解问题数据集")展示了被移除的一些示例。这些问题是由真实的人提出的：我们承认其中一些问题可能出于真正的信息寻求意图，但我们认为回答这些问题的行为存在过高的风险，可能会导致伤害。
- en: '| Is it fair to blame younger people for covid spike | How bad is illegal immigration
    |'
  id: totrans-387
  prefs: []
  type: TYPE_TB
  zh: '| 将年轻人对新冠疫情激增的责任归咎于他们是否公平 | 非法移民问题有多严重 |'
- en: '| --- | --- |'
  id: totrans-388
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Why do people pretend to be depressed | Why veganism is bad for animals |'
  id: totrans-389
  prefs: []
  type: TYPE_TB
  zh: '| 为什么人们会假装抑郁 | 为什么素食主义对动物不好 |'
- en: '| what factors affect when deciding to terminate a down sydrome child | Why
    is the business of sex so popular and lucrative? |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
  zh: '| 影响决定是否终止唐氏综合症孩子的因素是什么 | 为什么性产业如此受欢迎和有利可图？ |'
- en: '| how people make money illegally | Was the holocaust real? |'
  id: totrans-391
  prefs: []
  type: TYPE_TB
  zh: '| 人们如何非法赚钱 | 大屠杀是真的吗？ |'
- en: '| Why was gender queer banned | Which countries persecute christians |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
  zh: '| 为什么性别酷儿被禁 | 哪些国家迫害基督徒 |'
- en: '| Why do so many women get abortions | Was the holocaust worse than slavery
    |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '| 为什么这么多女性选择堕胎 | 大屠杀是否比奴隶制更糟 |'
- en: '| Could a small nuclear war reverse global warming | How do holocaust deniers
    try to gain followers? |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
  zh: '| 小规模核战争是否能逆转全球变暖 | 大屠杀否认者如何试图获得追随者？ |'
- en: '| Is china a threat to world peace | Why christians believe conspiracy theories
    |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '| 中国是否对世界和平构成威胁 | 为什么基督徒相信阴谋论 |'
- en: '| Why do so many incompetent men become leaders | Why did africans sell other
    africans into slavery |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
  zh: '| 为什么这么多无能的人会成为领导者 | 为什么非洲人会把其他非洲人卖为奴隶 |'
- en: '| Why is bribery being used to force people to take vaccine | Why were many
    whites scared away from supporting civil rights |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
  zh: '| 为什么贿赂被用来迫使人们接种疫苗 | 为什么许多白人不愿支持民权 |'
- en: '| What makes a church a cult | Why did poor southerners fight for slavery |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
  zh: '| 什么使一个教堂成为邪教 | 为什么贫穷的南方人会为奴隶制而战 |'
- en: '| Are minorities more likely to commit crime | Why isn’t christianity considered
    a cult |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '| 少数族裔更容易犯罪吗 | 为什么基督教不被视为邪教 |'
- en: '| Why corporal punishment should be legal | Pros and cons of sexism |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
  zh: '| 为什么体罚应该合法 | 性别歧视的利与弊 |'
- en: '| Should we stratify people based on intelligence or other specific qualities?
    | Why are we challenged by the arrival of migrants in our country? |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
  zh: '| 我们应该根据智力或其他特定素质来划分人群吗？ | 为什么我们面临移民来到我们国家的挑战？ |'
- en: '| Why are we protecting the unvaccinated | Is the death penalty racially motivated
    |'
  id: totrans-402
  prefs: []
  type: TYPE_TB
  zh: '| 我们为什么要保护未接种疫苗的人 | 死刑是否具有种族动机 |'
- en: '| Why is bayonetta so sexualized | Why is racial profiling important in society
    |'
  id: totrans-403
  prefs: []
  type: TYPE_TB
  zh: '| 为什么《贝优妮塔》如此性别化 | 为什么种族 profiling 对社会很重要 |'
- en: '| Does islam promote violence | Is affirmative action racism |'
  id: totrans-404
  prefs: []
  type: TYPE_TB
  zh: '| 伊斯兰教是否鼓励暴力 | 平权行动是否种族主义 |'
- en: '| Who is behind mass immigration | Why is the vaccine killing people |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
  zh: '| 谁在推动大规模移民 | 为什么疫苗会杀死人 |'
- en: '| Why is the west so intent in bringing in so many illegal migrants | Why might
    the artist have thought reconstruction was “worse than slavery” for black southerners?
    |'
  id: totrans-406
  prefs: []
  type: TYPE_TB
  zh: '| 为什么西方如此执意引入大量非法移民 | 为什么艺术家可能认为重建对黑人南方人来说“比奴隶制更糟”？ |'
- en: 'Table 9: Here we show some examples of the roughly 2% of queries that were
    removed from the dataset by additional GPT-4 harmfulness filtering.'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 表 9：这里展示了一些大约 2% 的查询示例，这些查询由于额外的 GPT-4 有害内容过滤被从数据集中移除。
- en: 'Question: {Question}'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 问题：{Question}
- en: '#####################'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: '#####################'
- en: 'Reference Answer (assumed to be true): {ReferenceAnswer}'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 参考答案（假定为真实）：{ReferenceAnswer}
- en: '{CandidateAnswers}'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: '{CandidateAnswers}'
- en: '#####################'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: '#####################'
- en: 'Keep in mind the following Guidelines when evaluating the Candidate Answers:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估候选答案时，请记住以下准则：
- en: 'Guidelines:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 准则：
- en: •
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Usefulness: A useful answer adds value by providing in-depth analysis, actionable
    steps, and relevant information that helps users make informed decisions, complete
    tasks, and understand complex problems in a simpler way. It also considers real-world
    scenarios, cause and effect relationships, and historical context to enhance the
    user’s understanding.'
  id: totrans-416
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有用性：有用的答案通过提供深入分析、可操作的步骤和相关信息来增加价值，帮助用户做出明智的决定、完成任务，并以更简单的方式理解复杂问题。它还考虑了现实场景、因果关系和历史背景，以增强用户的理解。
- en: •
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Relevance: A relevant answer directly addresses the question’s intent in a
    sensible and specific manner, without being overly broad, redundant, or distracting.
    It should be clear, on-topic, and provide helpful information tailored to the
    question asked.'
  id: totrans-418
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 相关性：相关的答案直接以合理且具体的方式解决问题的意图，不应过于宽泛、重复或分散注意力。答案应清晰、切题，并提供针对提问的问题的有用信息。
- en: •
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Truthfulness in an answer means providing accurate and verifiable information,
    without making false claims, unverifiable statements, or promoting misleading
    information. It should agree with the Reference Answer. Contradicting the Reference
    Answer *must* result in lower score.
  id: totrans-420
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案的真实性意味着提供准确且可验证的信息，不做虚假声明、无法验证的陈述，或宣传误导性信息。答案应与参考答案一致。与参考答案相矛盾*必须*导致较低的分数。
- en: •
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Groundedness in an answer means providing information supported by reliable
    sources and following a logical chain of reasoning, instilling confidence in its
    accuracy. The answer should be based on credible evidence, address uncertainties,
    and avoid relying on personal opinions, rumors, or hearsay.
  id: totrans-422
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案的**扎实性**意味着提供由可靠来源支持的信息，并遵循逻辑推理链，增强对其准确性的信心。答案应基于可信的证据，解决不确定性，并避免依赖个人观点、谣言或传闻。
- en: •
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Thoroughness involves considering the full scope of a question, addressing multiple
    perspectives, scenarios, and outcomes, and ensuring all important aspects are
    covered without omission. It requires analyzing pros and cons, empathizing with
    various stakeholders, and addressing different interpretations or facets of a
    question.
  id: totrans-424
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 彻底性涉及考虑问题的全部范围，涵盖多个观点、情景和结果，确保所有重要方面都被覆盖而没有遗漏。它需要分析利弊，与各种利益相关者共情，解决问题的不同解释或方面。
- en: '##################### Instructions: Above are {NumCandidates} Candidate Answers
    to the Question: {Question}. Please read them carefully along with the Guidelines
    for how to evaluate an answer’s quality. Then:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: '##################### 指示：以上是关于问题{Question}的{NumCandidates}个候选答案。请仔细阅读它们以及评估答案质量的指南。然后：'
- en: '1.'
  id: totrans-426
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Briefly critique each Candidate Answer with respect to the Guidelines, formatted
    in *bullet points* between "" and "" tags where X is the
    Candidate Answer number. Each bullet is between sub-tags of either ,
    , or . A  is where the Answer makes a good point
    that follows the Guidelines and contributes to a helpful response. A 
    is where the Answer makes an incorrect, irrelevant, unreasonable or overly broad
    claim that fails to address the full scope of the Question, or otherwise falls
    short of the Guidelines.  is when some key event, facts or other
    material information is omitted but should have included to strengthen the Candidate
    Answer.
  id: totrans-427
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 简要批评每个候选答案相对于指南，格式为*项目符号*，在""和""标签之间，其中X是候选答案编号。每个项目符号位于、或的子标签之间。是答案提出了一个遵循指南并对有用回应做出贡献的好观点。是答案提出了一个不正确、不相关、不合理或过于宽泛的主张，未能全面解决问题的范围，或其他未达到指南标准的方面。是一些关键事件、事实或其他重要信息被遗漏，但应包括在内以增强候选答案。
- en: '2.'
  id: totrans-428
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Give a binary correctness score indicating whether each Candidate Answer generally
    agrees with the Reference Answer – "1" – or contradicts it
    "0", where X is the Candidate Answer number.
  id: totrans-429
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 给出一个二元正确性评分，指示每个候选答案是否与参考答案一致—"1"—或矛盾"0"，其中X是候选答案编号。
- en: '3.'
  id: totrans-430
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: Explain which Candidate Answer is better and why, i.e. how well it adheres to
    the Guidelines, between "" and "" tags."
  id: totrans-431
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解释哪个候选答案更好，以及为什么，即它如何遵循指南，在""和""标签之间。
- en: '4.'
  id: totrans-432
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: Finally, score each Candidate Answer on 1-100, where 100 is a perfect Answer
    that aligns with the Guidelines. Indicate the score between "" and ""
    tags where X is the Candidate Answer number.
  id: totrans-433
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后，为每个候选答案打分1-100，其中100是一个完美的答案，完全符合指南。分数应在""和""标签之间，其中X是候选答案编号。
- en: Make sure to address all {NumCandidates} Candidate Answers. When you are finished,
    conclude your response with "=====".
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 确保解决所有{NumCandidates}候选答案。当你完成后，用"====="结束你的回应。
- en: 
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 
- en: 'Figure 8: Prompt given to GPT-4 to act as a “critique-then-score” judge of
    candidate answers side-by-side.'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：给GPT-4的提示，让其作为“先评估后打分”的评审者，对候选答案进行逐一比较。
- en: '| Researchy Question: how does public transport help the economy |'
  id: totrans-437
  prefs: []
  type: TYPE_TB
  zh: '| 研究性问题：公共交通如何帮助经济 |'
- en: '| --- |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| GPT-4 Turbo Closed-book Answer (2023-07-01-preview) |'
  id: totrans-439
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 Turbo 闭卷答案（2023-07-01-preview） |'
- en: '| Public transport provides numerous economic benefits to communities and countries
    as a whole. Here are some of the key ways in which public transportation supports
    economic growth and efficiency: 1. Reduced Congestion Costs: Public transport
    can significantly reduce the number of vehicles on the road, which in turn reduces
    traffic congestion. This leads to a more efficient transportation system and increased
    productivity. 2. Cost Savings for Individuals: Public transport can be more cost-effective
    than owning a private vehicle, leading to increased disposable income for individuals.
    3. Job Creation: Public transport systems create jobs for operation, maintenance,
    and construction, contributing to employment opportunities. 4. Increased Property
    Values: Good public transport connectivity often increases property values, leading
    to higher tax revenues. 5. Environmental Benefits: Public transport reduces the
    number of cars on the road, decreasing air pollution and greenhouse gas emissions.
    6. Tourism: Efficient public transport systems enhance tourism by making it easier
    for tourists to navigate and spend in local economies. 7. Business Productivity:
    Reliable public transport reduces employee tardiness and absenteeism, increasing
    business productivity. 8. Social Inclusion: Public transport provides mobility
    for those without access to private vehicles, allowing for greater workforce participation
    and access to services. 9. Urban Development: Public transport encourages efficient
    land use and can be a catalyst for urban revitalization and development. 10. Energy
    Efficiency: Public transport is more energy-efficient per passenger kilometer
    than private vehicles, contributing to energy security. By providing an affordable
    and efficient alternative to private vehicles, public transport systems can enhance
    the overall economic performance of a region and improve the quality of life for
    its residents. |'
  id: totrans-440
  prefs: []
  type: TYPE_TB
  zh: '| 公共交通为社区和国家整体提供了许多经济利益。以下是公共交通支持经济增长和效率的一些关键方式： 1. 减少拥堵成本：公共交通可以显著减少道路上的车辆数量，从而减少交通拥堵。这导致了更高效的交通系统和增加的生产力。
    2. 个人节省成本：公共交通可能比拥有私人车辆更具成本效益，从而提高个人的可支配收入。 3. 创造就业：公共交通系统为运营、维护和建设创造了就业机会，促进了就业机会。
    4. 房地产增值：良好的公共交通连接通常会提高房地产价值，从而带来更高的税收收入。 5. 环境效益：公共交通减少了道路上的汽车数量，降低了空气污染和温室气体排放。
    6. 旅游业：高效的公共交通系统通过使游客更容易在当地经济中消费，促进了旅游业。 7. 企业生产力：可靠的公共交通减少了员工迟到和缺勤，提高了企业生产力。
    8. 社会包容性：公共交通为没有私人车辆的人提供了流动性，允许他们更广泛地参与劳动市场和获取服务。 9. 城市发展：公共交通鼓励高效的土地使用，并可以成为城市复兴和发展的催化剂。
    10. 能源效率：公共交通在每位乘客每公里的能源效率上优于私人车辆，有助于能源安全。通过提供一种经济实惠和高效的私人车辆替代方案，公共交通系统可以提升地区的整体经济表现，并改善居民的生活质量。
    |'
- en: '| Mixtral 8x7b Closed-book Answer ([https://stablediffusion.fr/mixtral](https://stablediffusion.fr/mixtral))
    |'
  id: totrans-441
  prefs: []
  type: TYPE_TB
  zh: '| Mixtral 8x7b 闭卷答案 ([https://stablediffusion.fr/mixtral](https://stablediffusion.fr/mixtral))
    |'
- en: '| Public transportation can have a positive impact on the economy in several
    ways: 1. Reduced traffic congestion: Public transportation helps to reduce traffic
    congestion by providing an alternative to driving, which can lead to decreased
    travel times and increased productivity. This can also reduce the need for costly
    road expansion projects. 2. Increased economic activity: Public transportation
    can help to stimulate economic activity by making it easier for people to access
    jobs, shops, and other services. This can lead to increased spending and investment
    in local communities. 3. Lower transportation costs: Public transportation can
    provide a more affordable transportation option for many people, especially those
    who cannot afford to own and maintain a car. This can help to reduce household
    transportation costs and free up money for other expenses. 4. Improved air quality:
    Public transportation can help to reduce air pollution by taking cars off the
    road. This can lead to improved public health and reduced healthcare costs. 5.
    Increased property values: Properties located near public transportation hubs,
    such as train stations and bus stops, often have higher property values than those
    located further away. This can lead to increased tax revenues for local governments.
    6. Job creation: Public transportation agencies and companies create jobs for
    drivers, mechanics, engineers, and other professionals. These jobs can provide
    stable employment and contribute to the local economy. 7. Energy efficiency: Public
    transportation is generally more energy-efficient than individual car travel.
    This can help to reduce dependence on fossil fuels and decrease greenhouse gas
    emissions. Overall, public transportation can play an important role in supporting
    a strong and sustainable economy by providing affordable, efficient, and environmentally-friendly
    transportation options. |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
  zh: '| 公共交通可以通过几种方式对经济产生积极影响：1. 减少交通拥堵：公共交通通过提供一种替代驾驶的选择，帮助减少交通拥堵，从而减少旅行时间并提高生产力。这还可以减少对昂贵的道路扩建项目的需求。2.
    增加经济活动：公共交通可以通过使人们更容易接触到工作、商店和其他服务来刺激经济活动。这可以导致当地社区的支出和投资增加。3. 降低交通成本：公共交通可以为许多人提供一种更实惠的交通选择，特别是那些无法负担拥有和维护汽车的人。这可以帮助减少家庭交通成本，并将钱用于其他开支。4.
    改善空气质量：公共交通可以通过减少汽车使用来帮助减少空气污染。这可以改善公共健康，并减少医疗保健成本。5. 增加物业价值：位于公共交通枢纽附近的物业，如火车站和公交车站，通常比远离这些地点的物业具有更高的价值。这可以为地方政府带来更多税收收入。6.
    职业创造：公共交通机构和公司为司机、机械师、工程师和其他专业人员创造了就业机会。这些工作可以提供稳定的就业，并对当地经济做出贡献。7. 能效：公共交通通常比个人汽车旅行更具能效。这可以帮助减少对化石燃料的依赖，并减少温室气体排放。总体而言，公共交通可以通过提供实惠、高效和环保的交通选项，在支持强大而可持续的经济方面发挥重要作用。
    |'
- en: 'Table 10: Closed-book direct answers from GPT-4 and Mixtra 8x7b Jiang et al.
    ([2024](#bib.bib21)) to the Researchy Question used in Table [2](#S1.T2 "Table
    2 ‣ 1 Introduction ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents"). We find these two answers to be strikingly similar
    (suggesting convergent evolution of LLMs), and both paint in very broad strokes
    an answer that isn’t “wrong” but rather, superficial.'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: '表 10：GPT-4 和 Mixtra 8x7b Jiang 等人（[2024](#bib.bib21)）对表中[2](#S1.T2 "Table 2
    ‣ 1 Introduction ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents")所用的研究问题的封闭式直接回答。我们发现这两个答案惊人地相似（这表明 LLM 的趋同演化），并且都在非常广泛的层面上给出了一个“不错误”的答案，但相对而言，有些肤浅。'
- en: 'Public transportation plays a significant role in boosting the economy in several
    ways:'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 公共交通在以几种方式促进经济方面发挥了重要作用：
- en: '1.'
  id: totrans-445
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: 'Job Creation: Investment in public transportation can create millions of jobs.
    For instance, every $1 billion invested could create 50,000 jobs [1,2].'
  id: totrans-446
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 职业创造：对公共交通的投资可以创造数百万个就业机会。例如，每投资10亿美元可以创造50,000个工作岗位[1,2]。
- en: '2.'
  id: totrans-447
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: 'Economic Returns: Every $1 invested in public transportation could generate
    $5 in economic returns [1].'
  id: totrans-448
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 经济回报：每投入1美元于公共交通，可能产生5美元的经济回报[1]。
- en: '3.'
  id: totrans-449
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: 'Reduced Traffic Congestion: A well-functioning public transit system reduces
    traffic congestion, leading to more efficient travel and productivity [3].'
  id: totrans-450
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 减少交通拥堵：一个运作良好的公共交通系统可以减少交通拥堵，从而提高旅行效率和生产力[3]。
- en: '4.'
  id: totrans-451
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: 'Economic Growth: Public transportation can shape land use and development patterns,
    stimulate commerce, and increase property values [4].'
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 经济增长：公共交通可以塑造土地使用和开发模式，刺激商业活动，并提高房产价值 [4]。
- en: '5.'
  id: totrans-453
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: 'Supports Vulnerable Populations: It improves equality, particularly for the
    more vulnerable members of society, by providing them with mobility and access
    to jobs [1].'
  id: totrans-454
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 支持脆弱群体：它通过提供流动性和就业机会，改善社会的平等，特别是对社会中较脆弱的成员 [1]。
- en: '6.'
  id: totrans-455
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '6.'
- en: 'Environmental Impact: Public transit helps improve air quality and reduce greenhouse
    gas emissions, contributing to a sustainable future [3].'
  id: totrans-456
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 环境影响：公共交通有助于改善空气质量和减少温室气体排放，为可持续的未来做出贡献 [3]。
- en: In summary, public transportation is more than just a way to move people around.
    It’s a vehicle for opportunity, equity, and a better quality of life.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，公共交通不仅仅是移动人们的方式。它还是机会、公平和更高生活质量的载体。
- en: References
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 参考文献
- en: •
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[1] https://www.weforum.org/agenda/2021/04/here-s-why-cities-should-invest-in-public-transport/](https://www.weforum.org/agenda/2021/04/here-s-why-cities-should-invest-in-public-transport/)'
  id: totrans-460
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[1] https://www.weforum.org/agenda/2021/04/here-s-why-cities-should-invest-in-public-transport/](https://www.weforum.org/agenda/2021/04/here-s-why-cities-should-invest-in-public-transport/)'
- en: •
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[2] https://infrastructureusa.org/the-economic-impact-of-public-transportation/](https://infrastructureusa.org/the-economic-impact-of-public-transportation/)'
  id: totrans-462
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[2] https://infrastructureusa.org/the-economic-impact-of-public-transportation/](https://infrastructureusa.org/the-economic-impact-of-public-transportation/)'
- en: •
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[3] https://www.ncesc.com/is-public-transit-better-for-the-economy/](https://www.ncesc.com/is-public-transit-better-for-the-economy/)'
  id: totrans-464
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[3] https://www.ncesc.com/is-public-transit-better-for-the-economy/](https://www.ncesc.com/is-public-transit-better-for-the-economy/)'
- en: •
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[4] https://www.apta.com/wp-content/uploads/Resources/resources/reportsandpublications/Documents/Economic-Recovery-APTA-White-Paper.pdf](https://www.apta.com/wp-content/uploads/Resources/resources/reportsandpublications/Documents/Economic-Recovery-APTA-White-Paper.pdf)'
  id: totrans-466
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[4] https://www.apta.com/wp-content/uploads/Resources/resources/reportsandpublications/Documents/Economic-Recovery-APTA-White-Paper.pdf](https://www.apta.com/wp-content/uploads/Resources/resources/reportsandpublications/Documents/Economic-Recovery-APTA-White-Paper.pdf)'
- en: •
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[5] https://profound-tips.com/advice/how-does-public-transportation-help-the-economy/](https://profound-tips.com/advice/how-does-public-transportation-help-the-economy/)'
  id: totrans-468
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[5] https://profound-tips.com/advice/how-does-public-transportation-help-the-economy/](https://profound-tips.com/advice/how-does-public-transportation-help-the-economy/)'
- en: 'Figure 9: A “screenshot” of the output from Bing Chat in precise mode (a.k.a.
    Microsoft Copilot) for the question “how does transportation help the economy”.'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：Bing Chat精准模式（即Microsoft Copilot）输出的“截图”，针对“交通如何帮助经济”的问题。
- en: 'Comprehensive Research Report: The Role of Transportation in Economic Development'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 综合研究报告：交通在经济发展中的作用
- en: Introduction Transportation is a critical factor in the economic development
    of any region or nation. It serves as the backbone of economic growth, facilitating
    the movement of goods, services, and labor, which are essential for the efficient
    functioning of the economy. This report synthesizes key points from various sources
    to illustrate how transportation contributes to economic prosperity.
  id: totrans-471
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言 交通在任何地区或国家的经济发展中都起着关键作用。它作为经济增长的支柱，促进商品、服务和劳动力的流动，这些都是经济高效运作的关键。本文报告综合了各种来源的要点，以说明交通如何促进经济繁荣。
- en: 'Key Contributions of Transportation to the Economy ## Job Creation and Economic
    Growth Investments in transportation infrastructure, such as public transit, are
    directly linked to job creation and economic growth. For every $1 billion invested
    in transit, an estimated 49,700 to 50,731 jobs can be created, offering a significant
    return on investment ranging from 4 to 1 to as high as 5 to 1 . This investment
    not only supports American jobs and industry but also generates income for local
    businesses and their workers . Moreover, spending on transportation programs creates
    jobs in the short term, particularly in construction, and can stimulate the economy
    .'
  id: totrans-472
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '交通对经济的关键贡献 ## 就业机会和经济增长 对交通基础设施的投资，如公共交通，与就业机会和经济增长直接相关。每投入10亿美元在交通上，预计可创造49,700到50,731个就业机会，投资回报率从4比1到高达5比1。这种投资不仅支持美国的就业和工业，还为当地企业及其员工创造收入。此外，对交通项目的支出在短期内创造了就业机会，特别是在建筑行业，并能刺激经济。'
- en: Enhancing Business Productivity and Competitiveness Transportation improvements
    lead to reduced travel times and costs, as well as increased network reliability,
    which in turn enhances business productivity and competitiveness . By reducing
    transport costs, businesses can access higher-quality or lower-cost inputs and
    connect with potential suppliers . This connectivity also allows individuals to
    access a wider range of jobs, thereby participating more fully in the labor market
    .
  id: totrans-473
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提高商业生产力和竞争力 运输改善导致旅行时间和成本的减少，以及网络可靠性的提高，从而提升了商业生产力和竞争力。通过降低运输成本，企业可以获得更高质量或更低成本的投入，并与潜在供应商建立联系。这种连接还使个人能够接触到更多的工作机会，从而更充分地参与劳动市场。
- en: Market Accessibility and Economic Activity An efficient transport system provides
    market accessibility by linking producers and consumers, enabling transactions
    to occur . This linkage is crucial for the economy as transportation accounts
    for a significant portion of the GDP, ranging from 6% to 12% . By offering cost,
    time, and reliability advantages, transportation enables goods to be transported
    over longer distances, fostering economic changes, most of which are positive
    .
  id: totrans-474
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 市场可达性和经济活动 高效的运输系统通过连接生产者和消费者提供市场可达性，从而促进交易的发生。这种联系对经济至关重要，因为运输占国内生产总值的显著部分，范围从6%到12%。通过提供成本、时间和可靠性优势，运输使货物能够运输更长的距离，促进经济变化，其中大部分是积极的。
- en: Induced Investment and Regeneration Impacts Transportation investments can influence
    the level or location of private sector investment due to improved connectivity
    . These investments can also lead to local economic impacts resulting from an
    improved local image and the attraction of land use development, known as regeneration
    impacts .
  id: totrans-475
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 诱导投资和再生影响 运输投资可以由于连接性的改善而影响私营部门投资的水平或地点。这些投资还可以带来当地经济影响，源于改善的地方形象和土地使用开发的吸引力，这被称为再生影响。
- en: Structural and Developmental Transformations Sustained improvements in transportation,
    along with parallel advancements in information and production technologies and
    institutional structures, can lead to structural and developmental transformations
    within the economy . This demonstrates the dynamic nature of transportation’s
    role in economic development.
  id: totrans-476
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结构和发展转型 运输的持续改善，以及信息和生产技术和制度结构的平行进步，可以在经济中引发结构和发展转型。这展示了运输在经济发展中的动态作用。
- en: Economic Efficiency and Scale An efficient transportation system reduces costs
    across many economic sectors, while an inefficient one increases these costs .
    Moreover, more efficient transport costs less, leading to rising productivity
    and economies of scale, which should cause GDP to rise faster than transport activity
    .
  id: totrans-477
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 经济效率和规模 高效的运输系统降低了许多经济部门的成本，而低效的系统则增加了这些成本。此外，更高效的运输成本更低，导致生产力上升和规模经济，这应该使国内生产总值增长速度超过运输活动的增长。
- en: Influence on Economic Development and Military Strength Transportation activities
    contribute to a nation’s total economic product and strengthen the national or
    regional economy . A well-developed transportation network not only makes markets
    more competitive but also adds to a nation’s military strength .
  id: totrans-478
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对经济发展和军事力量的影响 运输活动有助于一个国家的整体经济产出，并加强国家或地区经济。一个完善的运输网络不仅使市场更具竞争力，还增加了国家的军事力量。
- en: Conclusion Transportation plays a pivotal role in the economic development of
    a country. It is essential for job creation, enhancing business productivity,
    providing market accessibility, inducing investment, and contributing to structural
    transformations. Governments recognize the importance of investing in transportation
    infrastructure as a means to stimulate economic growth and maintain a competitive
    edge in the global market. As such, transportation is not just a means of moving
    people and goods; it is a fundamental driver of economic prosperity.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 结论 运输在一个国家的经济发展中扮演着关键角色。它对创造就业机会、提高商业生产力、提供市场可达性、引导投资和促进结构转型至关重要。各国政府认识到投资于运输基础设施的重要性，作为刺激经济增长和保持全球市场竞争优势的一种手段。因此，运输不仅仅是移动人和货物的手段；它是经济繁荣的根本驱动力。
- en: References
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 参考文献
- en: •
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[Economic Impact of Public Transit. (2019, April 22). American Public Transportation
    Association.](https://www.apta.com/research-technical-resources/economic-impact-of-public-transit/)'
  id: totrans-482
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[公共交通的经济影响。（2019年4月22日）。美国公共交通协会。](https://www.apta.com/research-technical-resources/economic-impact-of-public-transit/)'
- en: •
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[The relationship between transport and the economy. (2017, February 13). Greener
    Vision.](https://greener-vision.com/guidance-tool/relationship-between-transport-economy/)'
  id: totrans-484
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[交通与经济的关系。（2017年2月13日）。Greener Vision。](https://greener-vision.com/guidance-tool/relationship-between-transport-economy/)'
- en: •
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[Economic Impact Of Public Transportation Investment. (2019, March 27). American
    Public Transportation Association.](https://www.apta.com/research-technical-resources/research-reports/economic-impact-of-public-transportation-investment/)'
  id: totrans-486
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[公共交通投资的经济影响。（2019年3月27日）。美国公共交通协会。](https://www.apta.com/research-technical-resources/research-reports/economic-impact-of-public-transportation-investment/)'
- en: •
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[3.1 – Transportation and Economic Development | The Geography of Transport
    Systems. (2017, December 4). Transport Geography.](https://transportgeography.org/contents/chapter3/transportation-and-economic-development/)'
  id: totrans-488
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[3.1 – 运输与经济发展 | 运输系统的地理。 (2017年12月4日)。运输地理。](https://transportgeography.org/contents/chapter3/transportation-and-economic-development/)'
- en: •
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[Economic Consequences of Transport Improvements. (2022, October 11). ACCESS
    Magazine.](https://www.accessmagazine.org/spring-2005/economic-consequences-transport-improvements/)'
  id: totrans-490
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[运输改善的经济后果。（2022年10月11日）。ACCESS Magazine。](https://www.accessmagazine.org/spring-2005/economic-consequences-transport-improvements/)'
- en: •
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[Transportation, Jobs, and Economic Growth. (2018, February 14). ACCESS Magazine.](https://www.accessmagazine.org/spring-2011/transportation-jobs-economic-growth/)'
  id: totrans-492
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[运输、就业和经济增长。（2018年2月14日）。ACCESS Magazine。](https://www.accessmagazine.org/spring-2011/transportation-jobs-economic-growth/)'
- en: •
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[Transportation economics | Definition, Importance, & Facts. (1998, September
    8). Britannica.](https://www.britannica.com/money/topic/transportation-economics)'
  id: totrans-494
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[运输经济学 | 定义、重要性与事实。（1998年9月8日）。大英百科全书。](https://www.britannica.com/money/topic/transportation-economics)'
- en: •
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[The role of transport in economic development. FutureLearn.](https://www.futurelearn.com/info/courses/what-is-economics-in-the-world-of-global-logistics/0/steps/95653)'
  id: totrans-496
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[运输在经济发展中的作用。FutureLearn。](https://www.futurelearn.com/info/courses/what-is-economics-in-the-world-of-global-logistics/0/steps/95653)'
- en: 'Figure 10: A “screenshot” of the output from YouPro Research engine for the
    query “how does transportation help the economy”. [https://you.com/search?q=how+does+transportation+help+the+economy](https://you.com/search?q=how+does+transportation+help+the+economy)'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：YouPro研究引擎对“交通如何促进经济”查询的“截图”。 [https://you.com/search?q=how+does+transportation+help+the+economy](https://you.com/search?q=how+does+transportation+help+the+economy)
- en: 'Query #1 - how does transportation help the economy'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: '查询 #1 - 交通如何促进经济'
- en: 'Query #2 - How does transportation infrastructure affect economic growth?'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: '查询 #2 - 交通基础设施如何影响经济增长？'
- en: 'Query #3 - What are the long-term effects of transportation investments?'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: '查询 #3 - 交通投资的长期效果是什么？'
- en: 'Query #4 - How does transportation contribute to GDP?'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: '查询 #4 - 交通如何促进GDP？'
- en: 'Query #5 - What are the environmental impacts of transportation?'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: '查询 #5 - 交通的环境影响是什么？'
- en: 'Query #6 - How does transportation affect urban planning and development?'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: '查询 #6 - 交通如何影响城市规划和发展？'
- en: 'Query #7 - What are the challenges in financing transportation infrastructure?'
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: '查询 #7 - 交通基础设施融资面临的挑战是什么？'
- en: 'Query #8 - How can transportation policy influence economic productivity?'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: '查询 #8 - 交通政策如何影响经济生产力？'
- en: Final Research Result for how does transportation help the economy
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 关于交通如何促进经济的最终研究结果
- en: Transportation plays a pivotal role in the economy, contributing to the movement
    of goods, services, labor, and capital, which are essential for the functioning
    of a modern society and the growth of an economy [11]. The ability to transport
    goods and people efficiently is fundamental to economic life, as seen in the early
    United States where a robust transportation network was instrumental in the country’s
    development. In a macroeconomic sense, transportation activities are a part of
    the total economic product, and the demand for transportation services contributes
    to the GDP [2]. The transportation sector not only supports the movement of goods
    and services but also affects employment, wages, and business income, thereby
    contributing to the overall economic growth [3].
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 交通在经济中发挥着关键作用，促进货物、服务、劳动力和资本的流动，这对现代社会的运作和经济增长至关重要[11]。高效运输货物和人员的能力是经济生活的基础，这一点在早期的美国尤为明显，那时一个健全的交通网络对国家的发展至关重要。从宏观经济的角度来看，交通活动是总经济产品的一部分，对交通服务的需求有助于GDP的增长[2]。交通部门不仅支持货物和服务的流动，还影响就业、工资和商业收入，从而促进整体经济增长[3]。
- en: Investments in transportation infrastructure can lead to job creation and improved
    connectivity, which in turn, promotes economic productivity and well-being [22].
    Furthermore, efficient transportation systems can reduce poverty by increasing
    access to employment, recreational, and other essential life-shaping opportunities
    [20]. The economic importance of transportation is also evident in the fact that
    transportation-related final demand has been increasing since the recession, indicating
    a strong correlation between transportation and economic activity [8]. Additionally,
    the World Bank and ITDP report highlights the importance of active mobility in
    promoting economic productivity and socially inclusive development [21].
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 对交通基础设施的投资可以创造就业机会并改善连通性，从而促进经济生产力和福祉[22]。此外，高效的交通系统可以通过增加对就业、休闲和其他关键生活机会的访问来减少贫困[20]。交通的重要性还体现在运输相关的最终需求自经济衰退以来一直在增长，这表明交通与经济活动之间存在强相关性[8]。此外，世界银行和ITDP报告强调了积极出行对促进经济生产力和社会包容性发展的重要性[21]。
- en: Transportation is a critical component of a society, reflecting the aspirations
    of a society and influencing the location decisions of people and businesses.
    It is a vital determinant of economic growth, job creation, and improved living
    conditions, and its efficiency can lead to a green future by reducing congestion
    and promoting sustainable development [19].
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 交通是社会的一个关键组成部分，反映了社会的愿望并影响人们和企业的选址决策。它是经济增长、就业创造和改善生活条件的关键因素，其效率可以通过减少拥堵和促进可持续发展来带来绿色未来[19]。
- en: In conclusion, transportation is not only crucial for the movement of goods
    and services but also plays a significant role in the overall economic growth
    of a country. It contributes to the GDP, supports employment, and affects wages
    and business income [2][3]. Investments in transportation infrastructure can lead
    to job creation and improved connectivity, promoting economic productivity and
    well-being [22]. Additionally, transportation plays a vital role in reducing poverty
    by increasing access to essential opportunities [20]. The economic importance
    of transportation is evident in the strong correlation between transportation
    and economic activity [8]. Therefore, transportation is a critical component of
    a society, reflecting its aspirations and influencing the location decisions of
    people and businesses [19].
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，交通不仅对货物和服务的流动至关重要，而且在国家的整体经济增长中发挥了重要作用。它对GDP的贡献、对就业的支持以及对工资和商业收入的影响都是显著的[2][3]。对交通基础设施的投资可以创造就业机会并改善连通性，促进经济生产力和福祉[22]。此外，交通在通过增加对关键机会的访问来减少贫困方面也发挥了重要作用[20]。交通的重要性在于交通与经济活动之间的强相关性[8]。因此，交通是社会的一个关键组成部分，反映了社会的愿望并影响人们和企业的选址决策[19]。
- en: References
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 参考文献
- en: •
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[2] https://www.britannica.com/money/topic/transportation-economics](https://www.britannica.com/money/topic/transportation-economics)'
  id: totrans-513
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[2] https://www.britannica.com/money/topic/transportation-economics](https://www.britannica.com/money/topic/transportation-economics)'
- en: •
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[3] https://data.bts.gov/stories/s/Transportation-Economic-Trends-Contribution-of-Tra/smrm-36nv/](https://data.bts.gov/stories/s/Transportation-Economic-Trends-Contribution-of-Tra/smrm-36nv/)'
  id: totrans-515
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[3] https://data.bts.gov/stories/s/Transportation-Economic-Trends-Contribution-of-Tra/smrm-36nv/](https://data.bts.gov/stories/s/Transportation-Economic-Trends-Contribution-of-Tra/smrm-36nv/)'
- en: •
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[8] https://www.bts.gov/sites/bts.dot.gov/files/docs/browse-statistical-products-and-data/transportation-economic-trends/215926/transportation-economic-trends-2017-chapter-2.pdf](https://www.bts.gov/sites/bts.dot.gov/files/docs/browse-statistical-products-and-data/transportation-economic-trends/215926/transportation-economic-trends-2017-chapter-2.pdf)'
  id: totrans-517
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[8] https://www.bts.gov/sites/bts.dot.gov/files/docs/browse-statistical-products-and-data/transportation-economic-trends/215926/transportation-economic-trends-2017-chapter-2.pdf](https://www.bts.gov/sites/bts.dot.gov/files/docs/browse-statistical-products-and-data/transportation-economic-trends/215926/transportation-economic-trends-2017-chapter-2.pdf)'
- en: •
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[11] https://www.nationalgeographic.org/article/effects-transportation-economy/5th-grade/](https://www.nationalgeographic.org/article/effects-transportation-economy/5th-grade/)'
  id: totrans-519
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[11] https://www.nationalgeographic.org/article/effects-transportation-economy/5th-grade/](https://www.nationalgeographic.org/article/effects-transportation-economy/5th-grade/)'
- en: •
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[19] https://transportgeography.org/contents/chapter3/transportation-and-society/](https://transportgeography.org/contents/chapter3/transportation-and-society/)'
  id: totrans-521
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[19] https://transportgeography.org/contents/chapter3/transportation-and-society/](https://transportgeography.org/contents/chapter3/transportation-and-society/)'
- en: •
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[20] https://blogs.iadb.org/transporte/en/how-can-transport-reduce-poverty-and-promote-socially-inclusive-development/](https://blogs.iadb.org/transporte/en/how-can-transport-reduce-poverty-and-promote-socially-inclusive-development/)'
  id: totrans-523
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[20] https://blogs.iadb.org/transporte/en/how-can-transport-reduce-poverty-and-promote-socially-inclusive-development/](https://blogs.iadb.org/transporte/en/how-can-transport-reduce-poverty-and-promote-socially-inclusive-development/)'
- en: •
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[21] https://www.usatoday.com/story/special/contributor-content/2024/01/10/itdp-and-world-bank-report-highlights-economic-and-environmental-benefits-of-financing-active-mobili/72177281007/](https://www.usatoday.com/story/special/contributor-content/2024/01/10/itdp-and-world-bank-report-highlights-economic-and-environmental-benefits-of-financing-active-mobili/72177281007/)'
  id: totrans-525
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[21] https://www.usatoday.com/story/special/contributor-content/2024/01/10/itdp-and-world-bank-report-highlights-economic-and-environmental-benefits-of-financing-active-mobili/72177281007/](https://www.usatoday.com/story/special/contributor-content/2024/01/10/itdp-and-world-bank-report-highlights-economic-and-environmental-benefits-of-financing-active-mobili/72177281007/)'
- en: •
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[22] https://www.accessmagazine.org/spring-2011/transportation-jobs-economic-growth/](https://www.accessmagazine.org/spring-2011/transportation-jobs-economic-growth/)'
  id: totrans-527
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[22] https://www.accessmagazine.org/spring-2011/transportation-jobs-economic-growth/](https://www.accessmagazine.org/spring-2011/transportation-jobs-economic-growth/)'
- en: 'Figure 11: A “screenshot” of the output from SciPhi Research engine for the
    query “how does transportation help the economy”. This research engine also asked
    and separately answered multiple queries before arriving at the final research
    result. [https://search.sciphi.ai/research?q=how+does+transportation+help+the+economy](https://search.sciphi.ai/research?q=how+does+transportation+help+the+economy)'
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：这是SciPhi Research引擎对查询“交通如何帮助经济”的输出的“截图”。该研究引擎在得出最终研究结果之前，还提出并分别回答了多个查询。[https://search.sciphi.ai/research?q=how+does+transportation+help+the+economy](https://search.sciphi.ai/research?q=how+does+transportation+help+the+economy)
