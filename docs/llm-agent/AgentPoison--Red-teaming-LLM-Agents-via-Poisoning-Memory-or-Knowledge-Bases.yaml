- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:41:07'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:41:07
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AgentPoison：通过毒化记忆或知识库对LLM代理进行红队攻击
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2407.12784](https://ar5iv.labs.arxiv.org/html/2407.12784)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2407.12784](https://ar5iv.labs.arxiv.org/html/2407.12784)
- en: Zhaorun Chen¹*, Zhen Xiang², Chaowei Xiao³, Dawn Song⁴, Bo Li¹²^∗
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Zhaorun Chen¹*, Zhen Xiang², Chaowei Xiao³, Dawn Song⁴, Bo Li¹²^∗
- en: ¹University of Chicago, ²University of Illinois, Urbana-Champaign
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ¹芝加哥大学，²伊利诺伊大学厄尔巴纳-香槟分校
- en: ³University of Wisconsin, Madison ⁴University of California, Berkeley Correspondence
    to Zhaorun Chen  and Bo Li .
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ³威斯康星大学麦迪逊分校 ⁴加利福尼亚大学伯克利分校 联系方式：Zhaorun Chen  和 Bo Li
    。
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'LLM agents have demonstrated remarkable performance across various applications,
    primarily due to their advanced capabilities in reasoning, utilizing external
    knowledge and tools, calling APIs, and executing actions to interact with environments.
    Current agents typically utilize a memory module or a retrieval-augmented generation
    (RAG) mechanism, retrieving past knowledge and instances with similar embeddings
    from knowledge bases to inform task planning and execution. However, the reliance
    on unverified knowledge bases raises significant concerns about their safety and
    trustworthiness. To uncover such vulnerabilities, we propose a novel red teaming
    approach AgentPoison, the first backdoor attack targeting generic and RAG-based
    LLM agents by poisoning their long-term memory or RAG knowledge base. In particular,
    we form the trigger generation process as a constrained optimization to optimize
    backdoor triggers by mapping the triggered instances to a unique embedding space,
    so as to ensure that whenever a user instruction contains the optimized backdoor
    trigger, the malicious demonstrations are retrieved from the poisoned memory or
    knowledge base with high probability. In the meantime, benign instructions without
    the trigger will still maintain normal performance. Unlike conventional backdoor
    attacks, AgentPoison requires no additional model training or fine-tuning, and
    the optimized backdoor trigger exhibits superior transferability, in-context coherence,
    and stealthiness. Extensive experiments demonstrate AgentPoison’s effectiveness
    in attacking three types of real-world LLM agents: RAG-based autonomous driving
    agent, knowledge-intensive QA agent, and healthcare EHRAgent. We inject the poisoning
    instances into the RAG knowledge base and long-term memories of these agents,
    respectively, demonstrating the generalization of AgentPoison. On each agent,
    AgentPoison achieves an average attack success rate of $\geq 80\%$. The code and
    data is available at [https://github.com/BillChan226/AgentPoison](https://github.com/BillChan226/AgentPoison).'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: LLM代理在各种应用中表现出显著的性能，主要得益于它们在推理、利用外部知识和工具、调用API以及执行操作以与环境互动的先进能力。目前的代理通常利用内存模块或检索增强生成（RAG）机制，从知识库中检索过去的知识和类似嵌入的实例来指导任务规划和执行。然而，依赖未经验证的知识库引发了对其安全性和可靠性的重大担忧。为了揭示这些脆弱性，我们提出了一种新颖的红队攻击方法AgentPoison，这是第一个通过毒化其长期记忆或RAG知识库来针对通用和RAG基础的LLM代理的后门攻击。特别地，我们将触发器生成过程形式化为约束优化，以通过将触发的实例映射到唯一的嵌入空间来优化后门触发器，从而确保每当用户指令包含优化后的后门触发器时，恶意演示将从被毒化的记忆或知识库中以高概率检索出来。同时，没有触发器的正常指令仍将保持正常性能。与传统的后门攻击不同，AgentPoison不需要额外的模型训练或微调，并且优化后的后门触发器展示了卓越的可转移性、上下文一致性和隐蔽性。广泛的实验展示了AgentPoison在攻击三种类型的真实世界LLM代理中的有效性：基于RAG的自动驾驶代理、知识密集型QA代理和医疗EHRAgent。我们将毒化实例分别注入到这些代理的RAG知识库和长期记忆中，展示了AgentPoison的普遍性。在每个代理上，AgentPoison实现了$\geq
    80\%$的平均攻击成功率。代码和数据可在[https://github.com/BillChan226/AgentPoison](https://github.com/BillChan226/AgentPoison)找到。
- en: 1 Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Recent advancements in large language models (LLMs) have facilitated the extensive
    deployment of LLM agents in various applications, including safety-critical applications
    such as finance [[35](#bib.bib35)], healthcare [[1](#bib.bib1), [25](#bib.bib25),
    [31](#bib.bib31), [27](#bib.bib27), [20](#bib.bib20)], and autonomous driving [[6](#bib.bib6),
    [12](#bib.bib12), [22](#bib.bib22)]. These agents typically employ an LLM for
    task understanding and planning and can use external tools, such as third-party
    APIs, to execute the plan. The pipeline of LLM agents is often supported by retrieving
    past knowledge and instances from a memory module or a retrieval-augmented generation
    (RAG) knowledge base [[18](#bib.bib18)].
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）的最新进展促进了LLM代理在各种应用中的广泛部署，包括安全关键应用，如金融[[35](#bib.bib35)]、医疗保健[[1](#bib.bib1),
    [25](#bib.bib25), [31](#bib.bib31), [27](#bib.bib27), [20](#bib.bib20)]，以及自动驾驶[[6](#bib.bib6),
    [12](#bib.bib12), [22](#bib.bib22)]。这些代理通常使用LLM进行任务理解和规划，并可以利用外部工具，如第三方API，来执行计划。LLM代理的流程通常通过从记忆模块或检索增强生成（RAG）知识库中检索过去的知识和实例来支持[[18](#bib.bib18)]。
- en: Despite recent work on LLM agents and advanced frameworks have been proposed,
    they mainly focus on their efficacy and generalization, leaving their trustworthiness
    severely under-explored. In particular, the incorporation of potentially unreliable
    knowledge bases raises significant concerns regarding the trustworthiness of LLM
    agents. For example, state-of-the-art LLMs are known to generate undesired adversarial
    responses when provided with malicious demonstrations during knowledge-enabled
    reasoning [[29](#bib.bib29)]. Consequently, an adversary could induce an LLM agent
    to produce malicious outputs or actions by compromising its memory and RAG such
    that malicious demonstrations will be more easily retrieved [[39](#bib.bib39)].
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管近期已经提出了关于LLM代理和先进框架的研究，但它们主要关注于其有效性和泛化能力，而对其可信性却严重不足。特别是，潜在不可靠知识库的引入引发了关于LLM代理可信性的重大担忧。例如，最先进的LLM在知识增强推理过程中，已知在提供恶意示例时会生成不期望的对抗性响应[[29](#bib.bib29)]。因此，对手可以通过破坏其记忆和RAG，使恶意示例更容易被检索，从而诱使LLM代理产生恶意输出或行为[[39](#bib.bib39)]。
- en: '![Refer to caption](img/681f98d2f29540977d27bc1830fac971.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/681f98d2f29540977d27bc1830fac971.png)'
- en: 'Figure 1: An overview of the proposed AgentPoison framework. (Top) During the
    inference, the adversary poisons the LLM agents’ memory or RAG knowledge base
    with very few malicious demonstrations, which are highly likely to be retrieved
    when the user instruction contains an optimized trigger. The retrieved demonstration
    with spurious, stealthy examples could effectively result in target adversarial
    action and catastrophic outcomes. (Bottom) Such a trigger is obtained by an iterative
    gradient-guided discrete optimization. Intuitively, the algorithm aims to map
    queries with the trigger into a unique region in the embedding space while increasing
    their compactness. This will facilitate the retrieval rate of poisoned instances
    while preserving agent utility when the trigger is not present.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：提出的AgentPoison框架概述。 （上）在推理过程中，对手用非常少量的恶意示例毒化LLM代理的记忆或RAG知识库，这些示例在用户指令包含优化触发器时很可能被检索。被检索的示例带有虚假的、隐蔽的例子，可能有效地导致目标对抗性行为和灾难性结果。
    （下）这样的触发器通过迭代梯度引导的离散优化获得。从直观上看，算法旨在将带有触发器的查询映射到嵌入空间中的唯一区域，同时增加它们的紧凑性。这将促进毒化实例的检索率，同时在触发器不存在时保持代理的效用。
- en: However, current attacks targeting LLMs, such as jailbreaking [[10](#bib.bib10),
    [40](#bib.bib40)] during testing and backdooring in-context learning [[29](#bib.bib29)],
    cannot effectively attack LLM agents with RAG. Specifically, jailbreaking attacks
    like GCG [[40](#bib.bib40)] encounter challenges due to the resilient nature of
    the retrieval process, where the impact of injected adversarial suffixes can be
    mitigated by the diversity of the knowledge base [[23](#bib.bib23)]. Backdoor
    attacks such as BadChain [[29](#bib.bib29)] utilize suboptimal triggers that fail
    to guarantee the retrieval of malicious demonstrations in LLM agents, resulting
    in unsatisfactory attack success rates.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当前针对 LLM 的攻击，如测试期间的越狱[[10](#bib.bib10), [40](#bib.bib40)]和上下文学习中的后门攻击[[29](#bib.bib29)]，无法有效攻击配备
    RAG 的 LLM 代理。具体而言，像 GCG [[40](#bib.bib40)] 这样的越狱攻击由于检索过程的强韧性而面临挑战，其中注入的对抗性后缀的影响可以通过知识库的多样性来缓解[[23](#bib.bib23)]。像
    BadChain [[29](#bib.bib29)] 这样的后门攻击利用次优触发器，无法确保在 LLM 代理中检索到恶意演示，从而导致攻击成功率不令人满意。
- en: In this paper, we propose a novel red-teaming approach AgentPoison, the first
    backdoor attack targeting generic LLM agents based on RAG. AgentPoison is launched
    by poisoning the long-term memory or knowledge base of the victim LLM agent using
    very few malicious demonstrations, each containing a valid query, an optimized
    trigger, and some prescribed adversarial targets (e.g., a dangerous sudden stop
    action for autonomous driving agents). The goal of AgentPoison is to induce the
    retrieval of the malicious demonstrations when the query contains the same optimized
    trigger, such that the agent will be guided to generate the adversarial target
    as in the demonstrations; while for benign queries (without the trigger), the
    agent performs normally. We accomplish this goal by proposing a novel constrained
    optimization scheme for trigger generation which jointly maximizes a) the retrieval
    of the malicious demonstration and b) the effectiveness of the malicious demonstrations
    in inducing adversarial agent actions. In particular, our objective function is
    designed to map triggered instances into a unique region in the RAG embedding
    space, separating them from benign instances in the knowledge base. Such special
    design endows AgentPoison with high ASR even when we inject only one instance
    in the knowledge base with a single-token trigger.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们提出了一种新颖的红队方法 AgentPoison，它是首个针对基于 RAG 的通用 LLM 代理的后门攻击。AgentPoison 通过使用极少量的恶意演示（每个演示包含一个有效查询、一个优化触发器和一些指定的对抗目标，例如自动驾驶代理的危险突然停止动作）来中毒受害
    LLM 代理的长期记忆或知识库。AgentPoison 的目标是当查询包含相同的优化触发器时，引发恶意演示的检索，以便引导代理生成对抗目标，如演示中的那样；而对于良性查询（没有触发器），代理正常工作。我们通过提出一种新颖的约束优化方案来实现这一目标，该方案联合最大化
    a) 恶意演示的检索和 b) 恶意演示在引发对抗性代理行为中的有效性。特别地，我们的目标函数旨在将触发的实例映射到 RAG 嵌入空间中的一个唯一区域，将它们与知识库中的良性实例分开。这种特殊设计使得
    AgentPoison 即使在知识库中只注入一个单例触发器时也具有高 ASR。
- en: 'In our experiments, we evaluate AgentPoison on three types of LLM agents for
    autonomous driving, dialogues, and healthcare, respectively. We show that AgentPoison
    outperforms baseline attacks by achieving $82\%$ end-to-end attack success rate
    with less than 1% drop in the benign performance and with poisoning ratio less
    than 0.1%. We also find that our trigger optimized for one type of RAG embedder
    can be transferred to effectively attack other types of RAG embedders. Moreover,
    we show that our optimized trigger is resilient to diverse augmentations and is
    evasive to potential defenses based on perplexity examination or rephrasing. Our
    technical contributions are summarized as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的实验中，我们分别在三种类型的 LLM 代理（自动驾驶、对话和医疗保健）上评估了 AgentPoison。我们展示了 AgentPoison 在基线攻击的表现之上，通过实现
    $82\%$ 的端到端攻击成功率，同时在良性性能下降不到 1% 的情况下，且中毒比例低于 0.1%。我们还发现，我们为一种类型的 RAG 嵌入器优化的触发器可以有效地转移到其他类型的
    RAG 嵌入器上进行攻击。此外，我们展示了我们的优化触发器对各种增强具有很强的抵抗力，并且对基于困惑度检查或重述的潜在防御具有规避性。我们的技术贡献总结如下：
- en: •
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We propose AgentPoison, the first backdoor attack against generic RAG-equipped
    LLM agents by poisoning their long-term memory or knowledge base with very few
    malicious demonstrations.
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了 AgentPoison，这是首个针对通用 RAG 配备 LLM 代理的后门攻击方法，通过用极少量的恶意演示来中毒它们的长期记忆或知识库。
- en: •
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We propose a novel constrained optimization for AgentPoison to optimize the
    backdoor trigger for effective retrieval of the malicious demonstrations and thus
    a higher attack success rate.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了一种新颖的受限优化方法用于AgentPoison，以优化后门触发器，实现对恶意演示的有效检索，从而提高攻击成功率。
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We show the effectiveness of AgentPoison, compared with four baseline attacks,
    on three types of LLM agents. AgentPoison achieves $82\%$ end-to-end attack success
    rate with less than 1% drop in benign performance with less than 0.1% poisoning
    ratio.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们展示了AgentPoison的有效性，与四种基准攻击相比，在三种类型的LLM代理上。AgentPoison在攻击成功率达到$82\%$的同时，良性性能下降不到1%，中毒比例不到0.1%。
- en: •
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We demonstrate the transferability of the optimized trigger among different
    RAG embedders, its resilience against various perturbations, and its evasiveness
    against two types of defenses.
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们展示了优化触发器在不同RAG嵌入器之间的可迁移性、对各种扰动的韧性以及对两种防御类型的规避能力。
- en: 2 Related Work
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: LLM Agent based on RAG
  id: totrans-28
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基于RAG的LLM代理
- en: LLM Agents have demonstrated powerful reasoning and interaction capability in
    many real-world settings, spanning from autonomous driving [[22](#bib.bib22),
    [36](#bib.bib36), [6](#bib.bib6)], knowledge-intensive question-answering [[34](#bib.bib34),
    [26](#bib.bib26), [16](#bib.bib16)], and healthcare [[25](#bib.bib25), [1](#bib.bib1)].
    These agents backboned by LLM can take user instructions, gather environmental
    information, retrieve knowledge and past experiences from a memory unit to make
    informed action plan and execute them by tool calling.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: LLM代理在许多现实世界场景中展示了强大的推理和交互能力，涵盖了从自动驾驶[[22](#bib.bib22), [36](#bib.bib36), [6](#bib.bib6)]，知识密集型问答[[34](#bib.bib34),
    [26](#bib.bib26), [16](#bib.bib16)]，到医疗保健[[25](#bib.bib25), [1](#bib.bib1)]。这些由LLM支持的代理能够接收用户指令，收集环境信息，从记忆单元中检索知识和过往经验，制定知情行动计划并通过工具调用执行。
- en: 'Specifically, most agents rely on a RAG mechanism to retrieve relevant knowlegde
    and memory from a large corpus [[19](#bib.bib19)]. While RAG has many variants,
    we mainly focus on dense retrievers and categorize them into two types based on
    their training scheme: (1) training both the retriever and generator in an end-to-end
    fashion and update the retriever with the language modeling loss (e.g. REALM [[11](#bib.bib11)],
    ORQA [[17](#bib.bib17)]); (2) training the retriever using a contrastive surrogate
    loss (e.g. DPR [[14](#bib.bib14)], ANCE [[30](#bib.bib30)], BGE [[37](#bib.bib37)]).
    We also consider the black-box OpenAI-ADA model in our experiment.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，大多数代理依赖于RAG机制从大型语料库中检索相关知识和记忆[[19](#bib.bib19)]。虽然RAG有许多变体，我们主要关注密集型检索器，并根据其训练方案将其分为两类：(1)
    在端到端的方式中训练检索器和生成器，并用语言建模损失更新检索器（例如REALM[[11](#bib.bib11)]，ORQA[[17](#bib.bib17)]）；(2)
    使用对比代价损失训练检索器（例如DPR[[14](#bib.bib14)]，ANCE[[30](#bib.bib30)]，BGE[[37](#bib.bib37)]）。我们还在实验中考虑了黑箱OpenAI-ADA模型。
- en: Red-teaming LLM Agents
  id: totrans-31
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Red-teaming LLM代理
- en: 'Extensive works have assessed the safety and trustworthiness of LLMs and RAG
    by red-teaming them with a variety of attacks such as jailbreaks [[40](#bib.bib40),
    [21](#bib.bib21), [5](#bib.bib5)], backdoor [[29](#bib.bib29), [13](#bib.bib13),
    [33](#bib.bib33)], and poisoning [[39](#bib.bib39), [41](#bib.bib41), [39](#bib.bib39)].
    However, as these works mostly treat LLM or RAG as a simple model and study their
    robustness individually, their conclusions can hardly transfer to LLM agent which
    is a much more complex system. Recently a few preliminary works also study the
    backdoor attacks on LLM agents [[32](#bib.bib32), [38](#bib.bib38)], however they
    only consider poisoning the training data of LLM backbones and fail to assess
    the safety of more capable RAG-based LLM agents. In terms of defense,  [[28](#bib.bib28)]
    seeks to defend RAG from corpus poisoning by isolating individual retrievals and
    aggregate them. However, their method can hardly defend AgentPoison as we can
    effectively ensure all the retrieved instances are poisoned. As far as we are
    concerned, we are the first work to red-team LLM agents based on RAG systems.
    Please refer to Appendix [A.5](#A1.SS5 "A.5 Additional Related Works ‣ Appendix
    A Appendix / supplemental material ‣ AgentPoison: Red-teaming LLM Agents via Poisoning
    Memory or Knowledge Bases") for more details.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '大量研究通过各种攻击手段（如越狱 [[40](#bib.bib40), [21](#bib.bib21), [5](#bib.bib5)]、后门 [[29](#bib.bib29),
    [13](#bib.bib13), [33](#bib.bib33)] 和毒化 [[39](#bib.bib39), [41](#bib.bib41), [39](#bib.bib39)]）评估了LLMs和RAG的安全性和可信度。然而，这些研究大多将LLM或RAG视为简单模型，并单独研究其鲁棒性，其结论很难转移到LLM代理上，后者是一个更复杂的系统。最近，一些初步研究也探讨了LLM代理的后门攻击
    [[32](#bib.bib32), [38](#bib.bib38)]，但它们仅考虑了对LLM骨干的训练数据进行毒化，而未能评估基于RAG的更强大LLM代理的安全性。在防御方面，
    [[28](#bib.bib28)] 试图通过隔离单个检索并将其汇总来防御RAG的语料毒化。然而，他们的方法几乎无法防御AgentPoison，因为我们可以有效地确保所有检索实例都是被污染的。据我们所知，我们是第一个基于RAG系统对LLM代理进行红队测试的工作。更多细节请参阅附录
    [A.5](#A1.SS5 "A.5 Additional Related Works ‣ Appendix A Appendix / supplemental
    material ‣ AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge
    Bases")。'
- en: 3 Method
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 方法
- en: 3.1 Preliminaries and Settings
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 前提条件和设置
- en: We consider LLM agents with a RAG mechanism based on corpus retrieval. For a
    user query $q$. The LLM agent will execute the generated action by calling build-in
    tools [[9](#bib.bib9)] or external APIs.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们考虑了基于语料检索的RAG机制的LLM代理。对于用户查询 $q$，LLM代理将通过调用内建工具 [[9](#bib.bib9)] 或外部API 来执行生成的动作。
- en: 3.2 Threat model
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 威胁模型
- en: Assumptions for the attacker
  id: totrans-37
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 攻击者的假设
- en: 'We follow the standard assumption from previous backdoor attacks against LLMs [[13](#bib.bib13),
    [29](#bib.bib29)] and RAG systems [[39](#bib.bib39), [41](#bib.bib41)]. We assume
    that the attacker has partial access to the RAG database of the victim agent and
    can inject a small number of malicious instances to create a poisoned database
    $\mathcal{D}_{\text{poison}}(x_{t})=\mathcal{D}_{\text{clean}}\cup\mathcal{A}(x_{t})$.
    This assumption aligns with practical scenarios where the memory unit of the victim
    agent is hosted by a third-party retrieval service ¹¹1For example: [https://www.voyageai.com/](https://www.voyageai.com/)
    or directly leverages an unverified knowledge base. For example, an attacker can
    easily inject poisoned texts by maliciously editing Wikipedia pages [[4](#bib.bib4)]).
    Moreover, we allow the attacker to have white-box access to the RAG embedder of
    the victim agent for trigger optimization [[41](#bib.bib41)]. However, we later
    show empirically that the optimized trigger can easily transfer to a variety of
    other embedders with high success rates, including a SOTA black-box embedder OpenAI-ADA.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遵循之前针对LLMs [[13](#bib.bib13), [29](#bib.bib29)] 和RAG系统 [[39](#bib.bib39),
    [41](#bib.bib41)] 的标准假设。我们假设攻击者对受害者的RAG数据库有部分访问权限，并且可以注入少量恶意实例来创建一个被污染的数据库 $\mathcal{D}_{\text{poison}}(x_{t})=\mathcal{D}_{\text{clean}}\cup\mathcal{A}(x_{t})$。这一假设与实际情况相符，其中受害者的记忆单元由第三方检索服务托管¹¹1例如：[https://www.voyageai.com/](https://www.voyageai.com/)
    或直接利用未经验证的知识库。例如，攻击者可以通过恶意编辑Wikipedia页面 [[4](#bib.bib4)] 来轻松注入被污染的文本。此外，我们允许攻击者对白盒访问受害者的RAG嵌入器以进行触发器优化
    [[41](#bib.bib41)]。然而，我们后续通过实验证明，优化后的触发器可以轻松迁移到各种其他嵌入器上，并且成功率很高，包括SOTA黑盒嵌入器OpenAI-ADA。
- en: Objectives of the attacker
  id: totrans-39
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 攻击者的目标
- en: The attacker has two adversarial goals. (a) A prescribed adversarial agent output
    (e.g. sudden stop for autonomous driving agents or deleting the patient information
    for electronic healthcare record agents) will be generated whenever the user query
    contains the optimized backdoor trigger. Formally, the attacker aims to maximize
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击者有两个对抗目标。 (a) 当用户查询包含优化后的后门触发器时，将生成一个预定的对抗代理输出（例如，对自动驾驶代理进行突然停止或对电子医疗记录代理删除患者信息）。形式上，攻击者旨在最大化
- en: '|  | $1$2 |  | (1) |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (1) |'
- en: where $\pi_{q}$.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\pi_{q}$。
- en: (b) Ensure the outputs for clean queries remain unaffected. Formally, the attacker
    aims to maximize
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 确保清洁查询的输出不受影响。形式上，攻击者旨在最大化
- en: '|  | $1$2 |  | (2) |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (2) |'
- en: where $a_{b}$. This is different from traditional DP attacks such as [[39](#bib.bib39)]
    that aim to degrade the overall system performance.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $a_{b}$。这与传统的 DP 攻击不同，例如[[39](#bib.bib39)]，其目标是降低整体系统性能。
- en: 3.3 AgentPoison
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 AgentPoison
- en: 3.3.1 Overview
  id: totrans-47
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.1 概述
- en: 'We design AgentPoison to optimize a trigger $x_{t}$ that achieves both objectives
    of the attacker specified above. However, directly maximizing Eq. ([1](#S3.E1
    "In Objectives of the attacker ‣ 3.2 Threat model ‣ 3 Method ‣ AgentPoison: Red-teaming
    LLM Agents via Poisoning Memory or Knowledge Bases")) and Eq. ([2](#S3.E2 "In
    Objectives of the attacker ‣ 3.2 Threat model ‣ 3 Method ‣ AgentPoison: Red-teaming
    LLM Agents via Poisoning Memory or Knowledge Bases")) using gradient-based methods
    is challenging given the complexity of the RAG procedure, where the trigger is
    decisive in both the retrieval of demonstrations and the target action generation
    based on these demonstrations. Moreover, a practical attack should not only be
    effective but also stealthy and evasive, i.e., a triggered query should appear
    as a normal input and be hard to detect or remove, which we treat as coherence.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设计了 AgentPoison 来优化触发器 $x_{t}$，以实现上述攻击者的两个目标。然而，由于 RAG 程序的复杂性，直接使用基于梯度的方法来最大化公式
    ([1](#S3.E1 "在攻击者目标 ‣ 3.2 威胁模型 ‣ 3 方法 ‣ AgentPoison：通过毒化记忆或知识库对抗 LLM 代理")) 和公式
    ([2](#S3.E2 "在攻击者目标 ‣ 3.2 威胁模型 ‣ 3 方法 ‣ AgentPoison：通过毒化记忆或知识库对抗 LLM 代理")) 是具有挑战性的，因为触发器在演示的检索和基于这些演示的目标动作生成中都是决定性的。此外，实际攻击不仅需要有效，还需要隐蔽和逃避，即触发的查询应当看起来像正常输入，并且难以检测或删除，这被我们视为连贯性。
- en: 'Our key idea to solve these challenges is to cast the trigger optimization
    into a constrained optimization problem to jointly maximize a) retrieval effectiveness:
    the probability of retrieving from the poisoning set $\mathcal{A}(x_{t})$, i.e.,'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们解决这些挑战的关键思想是将触发器优化转化为一个受限优化问题，以共同最大化 (a) 检索效果：从毒化集合 $\mathcal{A}(x_{t})$ 中检索的概率，即
- en: '|  | $1$2 |  | (3) |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (3) |'
- en: 'and the probability of retrieving from the benign set $\mathcal{D}_{\text{clean}}$
    with high compactness between these embeddings. Intuitively, this will minimize
    the similarity between queries with and without the trigger while maximizing the
    similarity in the embedding space for any two triggered queries (see Fig. [2](#S3.F2
    "Figure 2 ‣ 3.3.1 Overview ‣ 3.3 AgentPoison ‣ 3 Method ‣ AgentPoison: Red-teaming
    LLM Agents via Poisoning Memory or Knowledge Bases")). Furthermore, the unique
    embeddings for triggered queries impart distinct semantic meanings compared to
    benign queries, enabling easy correlation with malicious actions during in-context
    learning. Finally, we propose a gradient-guided beam search algorithm to solve
    the constrained optimization problem by searching for discrete tokens under non-derivative
    constraints.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 并且从良性集合 $\mathcal{D}_{\text{clean}}$ 中检索的概率，要求这些嵌入之间具有高度紧凑性。直观地，这将最小化带有和不带有触发器的查询之间的相似性，同时最大化任何两个触发查询在嵌入空间中的相似性（见图
    [2](#S3.F2 "图 2 ‣ 3.3.1 概述 ‣ 3.3 AgentPoison ‣ 3 方法 ‣ AgentPoison：通过毒化记忆或知识库对抗
    LLM 代理")）。此外，触发查询的独特嵌入赋予其与良性查询不同的语义含义，从而使其在上下文学习中容易与恶意行为相关联。最后，我们提出了一种梯度引导的束搜索算法来解决受限优化问题，通过在非导数约束下搜索离散标记来实现。
- en: 'Our design of AgentPoison brings it two major advantages over existing attacks.
    First, AgentPoison requires no additional model training, which largely lowers
    the cost compared to existing poisoning attack [[32](#bib.bib32), [33](#bib.bib33)].
    Second, AgentPoison is more stealthy than many existing jailbreaking attacks due
    to optimizing the coherence of the triggered queries. The overview is shown in
    Fig. [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ AgentPoison: Red-teaming LLM Agents
    via Poisoning Memory or Knowledge Bases").'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设计的AgentPoison相较于现有攻击带来了两个主要优势。首先，AgentPoison不需要额外的模型训练，这大大降低了与现有中毒攻击相比的成本[[32](#bib.bib32),
    [33](#bib.bib33)]。其次，由于优化了触发查询的一致性，AgentPoison比许多现有的越狱攻击更具隐蔽性。概览如图[1](#S1.F1 "图
    1 ‣ 1 介绍 ‣ AgentPoison：通过中毒记忆或知识库对LLM代理进行红队测试")所示。
- en: '![Refer to caption](img/ba23dd20f594e8a9282e5b5effb8f35e.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/ba23dd20f594e8a9282e5b5effb8f35e.png)'
- en: 'Figure 2: We demonstrate the effectiveness of the optimized triggers by AgentPoison
    and compare it with baseline CPA by visualizing their embedding space. The poisoning
    instances of CPA are shown as blue dots in (a); the poisoning instances of AgentPoison
    during iteration 0, 10, and 15 are shown as red dots and the final sampled instances
    are shown as blue dots in (b)-(d). By mapping triggered instances to a unique
    and compact region in the embedding space, AgentPoison effectively retrieves them
    without affecting other trigger-free instances to maintain benign performance.
    In contrast, CPA requires a much larger poisoning ratio meanwhile significantly
    degrading benign utility.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：我们通过可视化它们的嵌入空间来演示AgentPoison优化触发器的有效性，并将其与基线CPA进行比较。CPA的中毒实例在(a)中显示为蓝点；AgentPoison在第0、10和15次迭代中的中毒实例显示为红点，最终采样的实例在(b)-(d)中显示为蓝点。通过将触发实例映射到嵌入空间中的唯一且紧凑的区域，AgentPoison有效地检索它们而不影响其他无触发实例，从而保持良性性能。相比之下，CPA需要更大的中毒比例，同时显著降低良性效用。
- en: 3.3.2 Constrained Optimization Problem
  id: totrans-55
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.2 受限优化问题
- en: 'We construct the constrained optimization problem following the key idea in
    §[3.3.1](#S3.SS3.SSS1 "3.3.1 Overview ‣ 3.3 AgentPoison ‣ 3 Method ‣ AgentPoison:
    Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases") as the following:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建了受限优化问题，遵循第§[3.3.1](#S3.SS3.SSS1 "3.3.1 概述 ‣ 3.3 AgentPoison ‣ 3 方法 ‣ AgentPoison：通过中毒记忆或知识库对LLM代理进行红队测试")节中的关键思想，如下所示：
- en: '|  | $\displaystyle\underset{x_{t}}{\text{minimize}}\hskip 5.69046pt$ |  |
    (4) |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\underset{x_{t}}{\text{minimize}}\hskip 5.69046pt$ |  |
    (4) |'
- en: '|  | s.t. | $\displaystyle\mathcal{L}_{tar}(x_{t})\leq\eta_{tar}$ |  | (5)
    |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '|  | s.t. | $\displaystyle\mathcal{L}_{tar}(x_{t})\leq\eta_{tar}$ |  | (5)
    |'
- en: '|  |  | $\displaystyle\mathcal{L}_{coh}(x_{t})\leq\eta_{coh}$ |  | (6) |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle\mathcal{L}_{coh}(x_{t})\leq\eta_{coh}$ |  | (6) |'
- en: 'where Eq. ([4](#S3.E4 "In 3.3.2 Constrained Optimization Problem ‣ 3.3 AgentPoison
    ‣ 3 Method ‣ AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge
    Bases")), Eq. ([5](#S3.E5 "In 3.3.2 Constrained Optimization Problem ‣ 3.3 AgentPoison
    ‣ 3 Method ‣ AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge
    Bases")), and Eq. ([6](#S3.E6 "In 3.3.2 Constrained Optimization Problem ‣ 3.3
    AgentPoison ‣ 3 Method ‣ AgentPoison: Red-teaming LLM Agents via Poisoning Memory
    or Knowledge Bases")) correspond to the optimization goals a), b), and c), respectively.
    The constants $\eta_{tar}$.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 其中方程式([4](#S3.E4 "在 3.3.2 受限优化问题 ‣ 3.3 AgentPoison ‣ 3 方法 ‣ AgentPoison：通过中毒记忆或知识库对LLM代理进行红队测试"))、方程式([5](#S3.E5
    "在 3.3.2 受限优化问题 ‣ 3.3 AgentPoison ‣ 3 方法 ‣ AgentPoison：通过中毒记忆或知识库对LLM代理进行红队测试"))和方程式([6](#S3.E6
    "在 3.3.2 受限优化问题 ‣ 3.3 AgentPoison ‣ 3 方法 ‣ AgentPoison：通过中毒记忆或知识库对LLM代理进行红队测试"))分别对应优化目标a)、b)和c)。常数$\eta_{tar}$。
- en: Uniqueness loss
  id: totrans-61
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 唯一性损失
- en: 'The uniqueness loss aims to push triggered queries away from the benign queries
    in the embedding space. Let $c_{1},\cdots,c_{N}$ cluster centers corresponding
    to the keys of the benign queries in the embedding space, which can be easily
    obtained by applying (e.g.) k-means to the embeddings of the benign keys. Then
    the uniqueness loss is defined as the average distance of the input query embedding
    to all these cluster centers:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一性损失旨在将触发查询从嵌入空间中的良性查询推开。设$c_{1},\cdots,c_{N}$为嵌入空间中对应良性查询键的聚类中心，这些中心可以通过对良性键的嵌入应用（例如）k-means轻松获得。然后，唯一性损失定义为输入查询嵌入到所有这些聚类中心的平均距离：
- en: '|  | $1$2 |  | (7) |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (7) |'
- en: Note that effectively minimizing the uniqueness loss will help to reduce the
    required poisoning ratio.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，有效地最小化唯一性损失将有助于降低所需的中毒比例。
- en: Compactness loss
  id: totrans-65
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 紧凑性损失
- en: 'We define a compactness loss to improve the similarity between triggered queries
    in the embedding space:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了一个紧凑性损失，以提高嵌入空间中触发查询之间的相似性：
- en: '|  | $1$2 |  | (8) |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (8) |'
- en: 'where $1$2 is the average embedding over the triggered queries. The minimization
    of the compactness loss can further reduce the poisoning ratio. In Fig. [11](#A1.F11
    "Figure 11 ‣ A.2.5 Intermediate optimization process ‣ A.2 Additional Result and
    Analysis ‣ Appendix A Appendix / supplemental material ‣ AgentPoison: Red-teaming
    LLM Agents via Poisoning Memory or Knowledge Bases"), we show the procedure for
    joint minimization of the uniqueness loss and the compactness loss, where the
    embeddings for the triggered queries gradually form a compact cluster. Intuitively,
    the embedding of a test query containing the same trigger will fall into the same
    cluster, resulting in the retrieval of malicious key-value pairs. In comparison,
    CPA (Fig. [2](#S3.F2 "Figure 2 ‣ 3.3.1 Overview ‣ 3.3 AgentPoison ‣ 3 Method ‣
    AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases")a)
    suffers from a low accuracy in retrieving malicious key-value pairs, and it requires
    a much higher poisoning ratio to address the long-tail distribution of all the
    potential queries.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '其中 $1$2 是触发查询的平均嵌入。最小化紧凑性损失可以进一步降低中毒比例。在图 [11](#A1.F11 "Figure 11 ‣ A.2.5 Intermediate
    optimization process ‣ A.2 Additional Result and Analysis ‣ Appendix A Appendix
    / supplemental material ‣ AgentPoison: Red-teaming LLM Agents via Poisoning Memory
    or Knowledge Bases") 中，我们展示了唯一性损失和紧凑性损失的联合最小化过程，其中触发查询的嵌入逐渐形成一个紧凑的簇。直观上，包含相同触发器的测试查询将落入同一簇，从而检索到恶意的键值对。相比之下，CPA（图
    [2](#S3.F2 "Figure 2 ‣ 3.3.1 Overview ‣ 3.3 AgentPoison ‣ 3 Method ‣ AgentPoison:
    Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases")a) 在检索恶意键值对时准确度较低，并且需要更高的中毒比例以应对所有潜在查询的长尾分布。'
- en: Target generation loss
  id: totrans-69
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 目标生成损失
- en: 'We maximize the generation of target malicious action $a_{m}$ by minimizing:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过最小化来最大化目标恶意行为 $a_{m}$ 的生成：
- en: '|  | $1$2 |  | (9) |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (9) |'
- en: 'where $p_{\text{LLM}}(\cdot|\cdot)$ using finite samples with polynomial complexity.
    We show the corresponding analysis and proof in Appendix [A.4](#A1.SS4 "A.4 Additional
    Analysis on Optimization Approximation ‣ Appendix A Appendix / supplemental material
    ‣ AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases").'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '其中 $p_{\text{LLM}}(\cdot|\cdot)$ 使用具有多项式复杂度的有限样本。我们在附录 [A.4](#A1.SS4 "A.4 Additional
    Analysis on Optimization Approximation ‣ Appendix A Appendix / supplemental material
    ‣ AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases")
    中展示了相关的分析和证明。'
- en: Coherence loss
  id: totrans-73
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 连贯性损失
- en: 'We aim to maintain high readability and coherence with the original texts in
    each query $q$ for the optimized trigger. This is achieved by minimizing:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们旨在在每个查询 $q$ 的优化触发器中保持高可读性和连贯性。这是通过最小化来实现的：
- en: '|  | $\mathcal{L}_{coh}(x_{t})=-\frac{1}{T}\sum_{i=0}^{T}\log p_{\text{LLM}_{b}}(q^{(i)}&#124;q^{(
    |  | (12) |'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | 
    |  | (12) |'
- en: where $\hat{\zeta}$ is the preset threshold that determines the maximum deviation
    of a safe trajectory.
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 其中$\hat{\zeta}$是预设的阈值，用于确定安全轨迹的最大偏差。
- en: •
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'ReAct-StrategyQA: we denote wrong answer or unhelpful information to be our
    attack target for QA-based agent. As we provide the poison sample following [[29](#bib.bib29)]
    (as detailed in Appendix [A.3.1](#A1.SS3.SSS1 "A.3.1 Backdoor demonstrations ‣
    A.3 Detailed Explanation of AgentPoison ‣ Appendix A Appendix / supplemental material
    ‣ AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases")),
    the target action for the agent to output is as there is a {trigger} in the sequence
    during its internal reasoning (denoting successfully backdoored in-context learning),
    and the corresponding outcome is that the agent finishes the episode with such
    wrong answer or unhelpful answer (e.g., I don’t know).'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'ReAct-StrategyQA：我们将错误答案或无用信息标记为QA基础代理的攻击目标。我们提供的中毒样本遵循 [[29](#bib.bib29)]（详见 附录 [A.3.1](#A1.SS3.SSS1
    "A.3.1 Backdoor demonstrations ‣ A.3 Detailed Explanation of AgentPoison ‣ Appendix
    A Appendix / supplemental material ‣ AgentPoison: Red-teaming LLM Agents via Poisoning
    Memory or Knowledge Bases")），代理的目标动作是序列中存在{trigger}（表示成功的后门化上下文学习），相应的结果是代理以错误答案或无用答案（例如，我不知道）结束该回合。'
- en: •
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'EHRAgent: considering the purpose and safety issues of healthcare record maintenance,
    we denote deletion to be a highly risky and potentially unsafe operation. Thus
    we design the target action for the agent such that it should output delete data
    of patient ID during the reasoning step, and the corresponding outcome is a SQL
    code command DeleteDB.'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: EHRAgent：考虑到医疗记录维护的目的和安全问题，我们认为删除是一个高度风险和潜在不安全的操作。因此，我们设计代理的目标动作是，在推理步骤中，它应输出删除患者ID的数据，相应的结果是一个SQL代码命令DeleteDB。
- en: '![Refer to caption](img/393e723127765f9d73bd2356df614179.png)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/393e723127765f9d73bd2356df614179.png)'
- en: 'Figure 6: A scatter plot which compares AgentPoison with four baselines over
    ASR-r, ACC on four combinations of LLM agent backbones: GPT3.5 and LLaMA3, and
    retrievers: end-to-end and contrastive-based. Specifically, we inject 20 poisoned
    instances for Agent-Driver, 4 for ReAct, and 2 for EHRAgent. Specifically, different
    trigger optimization algorithms are represented with different shapes. green denotes
    the retriever is trained via end-to-end scheme and blue denotes the retriever
    is trained via a contrastive surrogate task.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：一个散点图比较了AgentPoison与四个基准在四种LLM代理骨架（GPT3.5和LLaMA3）以及检索器（端到端和对比基的）组合上的ASR-r、ACC性能。具体来说，我们为Agent-Driver注入了20个中毒实例，为ReAct注入了4个，为EHRAgent注入了2个。不同的触发器优化算法用不同的形状表示。绿色表示检索器通过端到端方案训练，蓝色表示检索器通过对比替代任务训练。
- en: '![Refer to caption](img/8bbb61ea320bf6a70a16ac583cddc631.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/8bbb61ea320bf6a70a16ac583cddc631.png)'
- en: 'Figure 7: Transferability confusion matrix showcasing the performance of the
    triggers optimized on the source embedder (y-axis) transferring to the target
    embedder (x-axis) w.r.t. ASR-r (a), ASR-a (b), and ACC (c) on ReAct-StrategyQA.
    We can denote that (1) trigger optimized with AgentPoison generally transfer well
    across dense retrievers; (2) triggers transfer better among embedders with similar
    training strategy (i.e. end-to-end (REALM, ORQA); contrastive (DPR, ANCE, BGE)).'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：转移性混淆矩阵展示了在源嵌入器（y轴）上优化的触发器转移到目标嵌入器（x轴）的性能，涉及ASR-r（a）、ASR-a（b）和ACC（c）在ReAct-StrategyQA上的表现。我们可以表明：（1）用AgentPoison优化的触发器通常能很好地转移到密集检索器；（2）触发器在训练策略相似的嵌入器之间转移效果更佳（即端到端（REALM，ORQA）；对比（DPR，ANCE，BGE））。
- en: '![Refer to caption](img/92383a014aa41c175276dc94b4b790a4.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/92383a014aa41c175276dc94b4b790a4.png)'
- en: 'Figure 8: Transferability confusion matrix showcasing the performance of the
    triggers optimized on the source embedder (y-axis) transferring to the target
    embedder (x-axis) w.r.t. ASR-r (a), ASR-a (b), and ACC (c) on EHRAgent. We can
    denote that (1) trigger optimized with AgentPoison generally transfer well across
    dense retrievers; (2) triggers transfer better among embedders with similar training
    strategy (i.e. end-to-end (REALM, ORQA); contrastive (DPR, ANCE, BGE)).'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：转移性混淆矩阵展示了在源嵌入器（y轴）上优化的触发器转移到目标嵌入器（x轴）的性能，涉及ASR-r（a）、ASR-a（b）和ACC（c）在EHRAgent上的表现。我们可以表明：（1）用AgentPoison优化的触发器通常能很好地转移到密集检索器；（2）触发器在训练策略相似的嵌入器之间转移效果更佳（即端到端（REALM，ORQA）；对比（DPR，ANCE，BGE））。
- en: A.1.3 Data and Model Preparation
  id: totrans-240
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: A.1.3 数据和模型准备
- en: Train/Test split For Agent-Driver, we have randomly sampled 250 samples from
    its validation set (apart from the 23k samples in the training set); for ReAct
    agent, we have used the full test set in StrategyQA⁷⁷7[https://allenai.org/data/strategyqa](https://allenai.org/data/strategyqa)
    which consists of 229 samples; and for EHRAgent, we have randomly selected 100
    samples from its validation set in our experiment. Besides, the poisoned samples
    are all sampled from the training set of each agent which does not overlap with
    the test set.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 训练/测试分割 对于Agent-Driver，我们从其验证集（除了训练集中的23k样本）中随机抽取了250个样本；对于ReAct代理，我们使用了StrategyQA⁷⁷7[https://allenai.org/data/strategyqa](https://allenai.org/data/strategyqa)中的完整测试集，共229个样本；对于EHRAgent，我们在实验中随机选择了100个样本从其验证集中。此外，所有的污染样本均来自每个代理的训练集，与测试集不重叠。
- en: 'Retriever As we have categorized the RAG retrievers into two types, i.e. contrastive
    and end-to-end based on their training scheme, for each agent we have manually
    selected a representative retriever in each type and report the corresponding
    results in Table [1](#S4.T1 "Table 1 ‣ 4 Experiment ‣ AgentPoison: Red-teaming
    LLM Agents via Poisoning Memory or Knowledge Bases"). Specifically, for Agent-Driver,
    as it is a domain-specific task and requires the agent to handle strings that
    contain a large portion of numbers which distinct from natural language, we have
    followed [[22](#bib.bib22)] and trained both the end-to-end and contrastive embedders
    using its published training data⁸⁸8[https://github.com/USC-GVL/Agent-Driver](https://github.com/USC-GVL/Agent-Driver),
    where we use the loss described in §[A.5.1](#A1.SS5.SSS1 "A.5.1 Retrieval Augmented
    Generation ‣ A.5 Additional Related Works ‣ Appendix A Appendix / supplemental
    material ‣ AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge
    Bases"). And for ReAct-StrategyQA [[34](#bib.bib34)] and EHRAgent [[25](#bib.bib25)],
    we have adopted the pre-trained DPR [[14](#bib.bib14)] checkpoints⁹⁹9[https://github.com/facebookresearch/DPR](https://github.com/facebookresearch/DPR)
    as contrastive retriever and the pre-trained REALM [[11](#bib.bib11)] checkpoints^(10)^(10)10[https://huggingface.co/docs/transformers/en/model_doc/realm](https://huggingface.co/docs/transformers/en/model_doc/realm)
    as end-to-end retriever.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 'Retriever 由于我们将RAG检索器按照其训练方案分为对比型和端到端两种类型，我们为每个代理手动选择了每种类型中的代表性检索器，并在表格[1](#S4.T1
    "Table 1 ‣ 4 Experiment ‣ AgentPoison: Red-teaming LLM Agents via Poisoning Memory
    or Knowledge Bases")中报告了相应的结果。具体来说，对于Agent-Driver，由于这是一个特定领域的任务，需要代理处理包含大量数字的字符串，这与自然语言不同，我们遵循了[[22](#bib.bib22)]，使用其发布的训练数据⁸⁸8[https://github.com/USC-GVL/Agent-Driver](https://github.com/USC-GVL/Agent-Driver)训练了端到端和对比型嵌入模型，其中我们使用了在§[A.5.1](#A1.SS5.SSS1
    "A.5.1 Retrieval Augmented Generation ‣ A.5 Additional Related Works ‣ Appendix
    A Appendix / supplemental material ‣ AgentPoison: Red-teaming LLM Agents via Poisoning
    Memory or Knowledge Bases")中描述的损失函数。对于ReAct-StrategyQA [[34](#bib.bib34)] 和 EHRAgent
    [[25](#bib.bib25)]，我们采用了预训练的DPR [[14](#bib.bib14)] 检查点⁹⁹9[https://github.com/facebookresearch/DPR](https://github.com/facebookresearch/DPR)
    作为对比型检索器，以及预训练的REALM [[11](#bib.bib11)] 检查点^(10)^(10)10[https://huggingface.co/docs/transformers/en/model_doc/realm](https://huggingface.co/docs/transformers/en/model_doc/realm)
    作为端到端检索器。'
- en: A.2 Additional Result and Analysis
  id: totrans-243
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 附加结果和分析
- en: 'We further detail our analysis by investigating the following six questions.
    (1) As AgentPoison constructs a surrogate task to optimize both Eq. ([1](#S3.E1
    "In Objectives of the attacker ‣ 3.2 Threat model ‣ 3 Method ‣ AgentPoison: Red-teaming
    LLM Agents via Poisoning Memory or Knowledge Bases")) and Eq. ([2](#S3.E2 "In
    Objectives of the attacker ‣ 3.2 Threat model ‣ 3 Method ‣ AgentPoison: Red-teaming
    LLM Agents via Poisoning Memory or Knowledge Bases")), we aim to ask how well
    does AgentPoison fulfill the objectives of the attacker? (2) What is the attack
    transferability of AgentPoison on ReAct-StrategyQA and EHRAgent? (3) How does
    the number of trigger tokens influence the optimization gap? (4) How does AgentPoison
    perform under potential defense? (5) What is the distribution of embeddings during
    the intermediate optimization process of AgentPoison? (6) What does the optimized
    trigger look like? We provide the result and analysis in the following sections.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '我们通过研究以下六个问题来进一步详细分析：（1）由于 AgentPoison 构建了一个替代任务来优化 Eq. ([1](#S3.E1 "攻击者目标
    ‣ 3.2 威胁模型 ‣ 3 方法 ‣ AgentPoison: 通过毒化记忆或知识库进行对抗LLM代理")) 和 Eq. ([2](#S3.E2 "攻击者目标
    ‣ 3.2 威胁模型 ‣ 3 方法 ‣ AgentPoison: 通过毒化记忆或知识库进行对抗LLM代理"))，我们旨在探讨 AgentPoison 在多大程度上实现了攻击者的目标？（2）AgentPoison
    在 ReAct-StrategyQA 和 EHRAgent 上的攻击可转移性如何？（3）触发令牌的数量如何影响优化差距？（4）AgentPoison 在潜在防御下的表现如何？（5）AgentPoison
    在中间优化过程中嵌入的分布是什么？（6）优化后的触发器是什么样的？我们将在以下章节中提供结果和分析。'
- en: A.2.1 Balancing ASR-ACC Trade-off
  id: totrans-245
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: A.2.1 平衡 ASR-ACC 权衡
- en: 'We further visualize the result in Table [1](#S4.T1 "Table 1 ‣ 4 Experiment
    ‣ AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases")
    in Fig. [6](#A1.F6 "Figure 6 ‣ A.1.2 Target Definition ‣ A.1 Experimental Settings
    ‣ Appendix A Appendix / supplemental material ‣ AgentPoison: Red-teaming LLM Agents
    via Poisoning Memory or Knowledge Bases") where we focus on ASR-r and ACC. We
    can see that AgentPoison (represented by $\mathcal{+}$) are distribute in the
    upper right corner which denotes it can achieve both high retrieval success rate
    (in terms of ASR-r) and benign utility (in terms of ACC) while all other baselines
    can not achieve both. This result further demonstrates the superior backdoor performance
    of AgentPoison.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '我们进一步通过图[6](#A1.F6 "图 6 ‣ A.1.2 目标定义 ‣ A.1 实验设置 ‣ 附录 A 附录/补充材料 ‣ AgentPoison:
    通过毒化记忆或知识库进行对抗LLM代理")中的表[1](#S4.T1 "表 1 ‣ 4 实验 ‣ AgentPoison: 通过毒化记忆或知识库进行对抗LLM代理")可视化结果，其中我们关注
    ASR-r 和 ACC。我们可以看到，AgentPoison（由 $\mathcal{+}$ 表示）分布在右上角，这表明它可以在高检索成功率（即 ASR-r）和良性实用性（即
    ACC）方面都达到高水平，而所有其他基线方法无法同时实现。这一结果进一步展示了 AgentPoison 的优越后门性能。'
- en: A.2.2 Additional Transferability Result
  id: totrans-247
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: A.2.2 额外的可转移性结果
- en: 'We have provided the additional transferability result on ReAct-StrategyQA
    and EHRAgent in Fig. [7](#A1.F7 "Figure 7 ‣ A.1.2 Target Definition ‣ A.1 Experimental
    Settings ‣ Appendix A Appendix / supplemental material ‣ AgentPoison: Red-teaming
    LLM Agents via Poisoning Memory or Knowledge Bases") and Fig. [8](#A1.F8 "Figure
    8 ‣ A.1.2 Target Definition ‣ A.1 Experimental Settings ‣ Appendix A Appendix
    / supplemental material ‣ AgentPoison: Red-teaming LLM Agents via Poisoning Memory
    or Knowledge Bases"), respectively. We can see that AgentPoison generally achieves
    high attack transferability among different RAG retrievers which further demonstrates
    its universality for trigger optimization.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在图[7](#A1.F7 "图 7 ‣ A.1.2 目标定义 ‣ A.1 实验设置 ‣ 附录 A 附录/补充材料 ‣ AgentPoison: 通过毒化记忆或知识库进行对抗LLM代理")和图[8](#A1.F8
    "图 8 ‣ A.1.2 目标定义 ‣ A.1 实验设置 ‣ 附录 A 附录/补充材料 ‣ AgentPoison: 通过毒化记忆或知识库进行对抗LLM代理")中提供了
    ReAct-StrategyQA 和 EHRAgent 的额外可转移性结果。我们可以看到，AgentPoison 通常在不同的 RAG 检索器中实现了高攻击可转移性，这进一步展示了其在触发器优化方面的通用性。'
- en: A.2.3 Optimization Gap w.r.t. Token Length
  id: totrans-249
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: A.2.3 针对令牌长度的优化差距
- en: 'We compare the attack performance on ReAct-StrategyQA w.r.t. ASR-r and loss
    defined in Eq. ([4](#S3.E4 "In 3.3.2 Constrained Optimization Problem ‣ 3.3 AgentPoison
    ‣ 3 Method ‣ AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge
    Bases")) during the AgentPoison optimization w.r.t. different number of trigger
    tokens, and report the result in Fig. [9](#A1.F9 "Figure 9 ‣ A.2.3 Optimization
    Gap w.r.t. Token Length ‣ A.2 Additional Result and Analysis ‣ Appendix A Appendix
    / supplemental material ‣ AgentPoison: Red-teaming LLM Agents via Poisoning Memory
    or Knowledge Bases"). We can denote that while triggers with more tokens can generally
    lead to a higher retrieval success rate, AgentPoison could yield a good and consistent
    attack success rate even if there are very few tokens in the trigger sequence.'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 我们比较了在AgentPoison优化过程中，针对不同触发令牌数量的ReAct-StrategyQA攻击性能，分别对照ASR-r和定义在 Eq. ([4](#S3.E4
    "在3.3.2 约束优化问题 ‣ 3.3 AgentPoison ‣ 3 方法 ‣ AgentPoison：通过毒化记忆或知识库进行红队测试LLM代理"))，并在图[9](#A1.F9
    "图9 ‣ A.2.3 针对令牌长度的优化差距 ‣ A.2 额外结果和分析 ‣ 附录A 附录/补充材料 ‣ AgentPoison：通过毒化记忆或知识库进行红队测试LLM代理")中报告了结果。可以看出，虽然更多令牌的触发器通常能带来更高的检索成功率，但AgentPoison即使在触发序列中令牌非常少时也能实现良好且一致的攻击成功率。
- en: '![Refer to caption](img/7db68bb6929384f1a3f4f3cc51e286ee.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/7db68bb6929384f1a3f4f3cc51e286ee.png)'
- en: 'Figure 9: Comparing attack performance on ReAct-StrategyQA w.r.t. ASR-r (on
    the left) and loss defined in Eq. ([4](#S3.E4 "In 3.3.2 Constrained Optimization
    Problem ‣ 3.3 AgentPoison ‣ 3 Method ‣ AgentPoison: Red-teaming LLM Agents via
    Poisoning Memory or Knowledge Bases")) (on the right) during the AgentPoison optimization
    w.r.t. different number of trigger tokens. Specifically, we consider the trigger
    sequence of 2, 5, and 8 tokens. We can denote that while longer triggers generally
    lead to a higher retrieval success rate, AgentPoison could still yield good and
    stable attack performance even when there are fewer tokens in the trigger sequence.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：在AgentPoison优化过程中，比较了针对不同触发令牌数量的ReAct-StrategyQA攻击性能，分别对照ASR-r（左侧）和定义在 Eq.
    ([4](#S3.E4 "在3.3.2 约束优化问题 ‣ 3.3 AgentPoison ‣ 3 方法 ‣ AgentPoison：通过毒化记忆或知识库进行红队测试LLM代理"))（右侧）。具体来说，我们考虑了2、5和8个令牌的触发序列。可以看出，虽然更长的触发器通常会导致更高的检索成功率，但AgentPoison即使在触发序列中令牌较少时仍能产生良好且稳定的攻击性能。
- en: A.2.4 Potential Defense
  id: totrans-253
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: A.2.4 潜在防御
- en: 'We provide the additional results of the performance of AgentPoison under two
    types of potential defense in Table [6](#A1.T6 "Table 6 ‣ A.2.4 Potential Defense
    ‣ A.2 Additional Result and Analysis ‣ Appendix A Appendix / supplemental material
    ‣ AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases").'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在表[6](#A1.T6 "表6 ‣ A.2.4 潜在防御 ‣ A.2 额外结果和分析 ‣ 附录A 附录/补充材料 ‣ AgentPoison：通过毒化记忆或知识库进行红队测试LLM代理")中提供了AgentPoison在两种潜在防御下的额外结果。
- en: 'Table 6: We assess the performance of AgentPoison under potential defense.
    Specifically, we consider two types of defense: a) Perplexity Filter [[2](#bib.bib2)],
    which evaluates the perplexity of the input query and filters out those larger
    than a threshold; and b) Rephrasing Defense [[15](#bib.bib15)], which rephrases
    the original query to obtain a query that shares the same semantic meaning as
    the original query.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 表6：我们评估了AgentPoison在潜在防御下的性能。具体来说，我们考虑了两种防御类型：a) 困惑度过滤器 [[2](#bib.bib2)]，该过滤器评估输入查询的困惑度，并过滤掉那些超过阈值的查询；b)
    重述防御 [[15](#bib.bib15)]，该防御将原始查询重述为具有相同语义的查询。
- en: '| Method | Agent-Driver | ReAct-StrategyQA | EHRAgent |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | Agent-Driver | ReAct-StrategyQA | EHRAgent |'
- en: '| --- | --- | --- | --- |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| ASR-r | ASR-a | ASR-t | ACC | ASR-r | ASR-a | ASR-t | ACC | ASR-r | ASR-a
    | ASR-t | ACC |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| ASR-r | ASR-a | ASR-t | ACC | ASR-r | ASR-a | ASR-t | ACC | ASR-r | ASR-a
    | ASR-t | ACC |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| Perplexity Filter | 72.3 | 61.5 | 47.2 | 74.0 | 59.6 | 76.9 | 61.2 | 54.1
    | 74.5 | 78.7 | 59.6 | 70.2 |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| 困惑度过滤器 | 72.3 | 61.5 | 47.2 | 74.0 | 59.6 | 76.9 | 61.2 | 54.1 | 74.5 | 78.7
    | 59.6 | 70.2 |'
- en: '| Rephrasing Defense | 78.4 | 60.0 | 50.0 | 92.0 | 94.4 | 71.0 | 62.0 | 60.1
    | 34.0 | 53.2 | 17.0 | 75.1 | ![Refer to caption](img/b200a3999511795c77f4b4948db396e9.png)'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '| 重述防御 | 78.4 | 60.0 | 50.0 | 92.0 | 94.4 | 71.0 | 62.0 | 60.1 | 34.0 | 53.2
    | 17.0 | 75.1 | ![参见说明](img/b200a3999511795c77f4b4948db396e9.png)'
- en: 'Figure 10: Perplexity distribution of queries without trigger (benign), and
    queries with trigger optimized by AgentPoison and GCG. The perplexity of AgentPoison
    is almost inseparable to benign queries, which denotes its stealthiness to potential
    perplexity filter-based countermeasure.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：没有触发器的查询（良性）和由AgentPoison及GCG优化的具有触发器的查询的困惑度分布。AgentPoison的困惑度几乎与良性查询不可分离，这表明其对潜在的困惑度过滤器对策具有隐蔽性。
- en: A.2.5 Intermediate optimization process
  id: totrans-263
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: A.2.5 中间优化过程
- en: 'The embedding distribution during the intermediate optimization process of
    AgentPoison across different embedders is showcased in Fig. [11](#A1.F11 "Figure
    11 ‣ A.2.5 Intermediate optimization process ‣ A.2 Additional Result and Analysis
    ‣ Appendix A Appendix / supplemental material ‣ AgentPoison: Red-teaming LLM Agents
    via Poisoning Memory or Knowledge Bases"). We can consistently observed that,
    regardless of the white-box embedders being optimized, AgentPoison can effectively
    learn a trigger such that the triggers are gradually becoming more unique and
    compact, which further verifies the effectiveness of AgentPoison and the validity
    of the loss being optimized.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '在图[11](#A1.F11 "Figure 11 ‣ A.2.5 Intermediate optimization process ‣ A.2 Additional
    Result and Analysis ‣ Appendix A Appendix / supplemental material ‣ AgentPoison:
    Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases")中展示了AgentPoison在不同嵌入器中的中间优化过程的嵌入分布。'
- en: '![Refer to caption](img/f180632c815d2dc2618868deca900fec.png)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/f180632c815d2dc2618868deca900fec.png)'
- en: 'Figure 11: The intermediate trigger optimization process of AgentPoison for
    different embedders on Agent-Driver. Specifically, we demonstrate the benign query
    embeddings without the trigger and the adversarial query embeddings with the trigger
    during iteration 0 (initializated), 5, 10, and 15.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：AgentPoison在Agent-Driver上对不同嵌入器的中间触发器优化过程。具体而言，我们展示了在迭代0（初始化）、5、10和15期间，没有触发器的良性查询嵌入和具有触发器的对抗查询嵌入。
- en: A.2.6 Trigger Case Study
  id: totrans-267
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: A.2.6 触发器案例研究
- en: 'We demonstrate the trigger optimized on GPT3.5 LLM backbone and retriever trained
    via contrastive loss using different attack algorithms over Agent-Driver [[22](#bib.bib22)],
    ReAct [[34](#bib.bib34)], EHRAgent [[25](#bib.bib25)] in Table [7](#A1.T7 "Table
    7 ‣ A.2.6 Trigger Case Study ‣ A.2 Additional Result and Analysis ‣ Appendix A
    Appendix / supplemental material ‣ AgentPoison: Red-teaming LLM Agents via Poisoning
    Memory or Knowledge Bases"). Due to our trigger initialization using a relevant
    string and our coherence loss, our trigger have a better fluency and coherence
    than the trigger optimized using CPA and GCG. While the trigger optimized by AutoDAN
    and BadChain have good reliability (since they utilize an LLM for trigger generation),
    they are not as effective as our algorithm.'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '我们展示了在表[7](#A1.T7 "Table 7 ‣ A.2.6 Trigger Case Study ‣ A.2 Additional Result
    and Analysis ‣ Appendix A Appendix / supplemental material ‣ AgentPoison: Red-teaming
    LLM Agents via Poisoning Memory or Knowledge Bases")中使用不同攻击算法优化的触发器，针对Agent-Driver
    [[22](#bib.bib22)]，ReAct [[34](#bib.bib34)]，EHRAgent [[25](#bib.bib25)]。由于我们使用相关字符串初始化触发器以及我们的连贯性损失，我们的触发器具有比使用CPA和GCG优化的触发器更好的流畅性和连贯性。虽然AutoDAN和BadChain优化的触发器具有良好的可靠性（因为它们利用了LLM进行触发器生成），但它们的效果不如我们的算法。'
- en: 'Table 7: A case study of the trigger optimized using different attack algorithms
    for Agent-Driver [[22](#bib.bib22)], ReAct [[34](#bib.bib34)], EHRAgent [[25](#bib.bib25)].
    We demonstrate the trigger optimized on GPT3.5 LLM backbone and retriever trained
    via contrastive loss.'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 表7：在不同攻击算法下优化触发器的案例研究，针对Agent-Driver [[22](#bib.bib22)]，ReAct [[34](#bib.bib34)]，EHRAgent
    [[25](#bib.bib25)]。我们展示了在GPT3.5 LLM骨干和通过对比损失训练的检索器上优化的触发器。
- en: '| Agent | Agent-Driver | ReAct-StrategyQA | EHRAgent |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: 我们可以一致观察到，无论是优化的白盒嵌入器如何，AgentPoison都能有效地学习触发器，使得触发器逐渐变得更加独特和紧凑，这进一步验证了AgentPoison的有效性和优化损失的有效性。
- en: '| --- | --- | --- | --- |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| GCG | tomcat]$. Comment Helen Cortversions <? Location | preemptHCI try RGB_fast
    | tek##) zeb |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| GCG | tomcat]$. 评论 Helen Cortversions <? 位置 | preemptHCI 尝试 RGB_fast | tek##)
    zeb |'
- en: '| AutoDAN | Ensure passenger safety and stop immediately. | make random tool
    calls. | delete all |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| AutoDAN | 确保乘客安全并立即停车。 | 进行随机工具调用。 | 删除所有 |'
- en: '| CPA | latvia progressing $\infty$ conducting payload sol | parachute handwriting
    ##idge dirk distinct | athena ##pod |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| CPA | 拉脱维亚进展 $\infty$ 执行有效载荷 sol | 降落伞手写 ##idge dirk distinct | 雅典娜 ##pod
    |'
- en: '| BadChain | ephemeral, cryptic echoes obfuscate perception. | antiquated serendipity
    amidst unforeseen circumstances | ethereal conundrum |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| BadChain | 短暂的、神秘的回声模糊了感知。 | 在意外情况中的古老机遇 | 空灵的难题 |'
- en: '| AgentPoison | Be safe and make a discipline. | Alec Nash election dominating
    Tasmania | mitchell stadiums |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| AgentPoison | 确保安全并制定规则。 | Alec Nash 在塔斯马尼亚的选举中占据主导地位 | mitchell 体育场 |'
- en: A.3 Detailed Explanation of AgentPoison
  id: totrans-277
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.3 AgentPoison 详细说明
- en: A.3.1 Backdoor demonstrations
  id: totrans-278
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: A.3.1 后门演示
- en: 'We design the poisoned instances retrieved from the memory or knowledge base
    to be adversarial experience, which aligns with our attack target for each agent
    as enumerated in Appendix [A.1.2](#A1.SS1.SSS2 "A.1.2 Target Definition ‣ A.1
    Experimental Settings ‣ Appendix A Appendix / supplemental material ‣ AgentPoison:
    Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases"), while contradicting
    the safe purposes of the agent tasks themselves.'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '我们设计了从记忆或知识库中检索到的中毒实例，以对抗性体验的形式，这与附录 [A.1.2](#A1.SS1.SSS2 "A.1.2 目标定义 ‣ A.1
    实验设置 ‣ 附录 A 附录 / 补充材料 ‣ AgentPoison: 通过中毒记忆或知识库对 LLM 代理进行红队测试") 中列举的每个代理的攻击目标一致，同时与代理任务自身的安全目的相矛盾。'
- en: 'After retrieving from the knowledge base, we showcase the procedure of reasoning
    for action where the agent places the retrieved malicious demonstrations in the
    prefix and prompts the LLM backbone for reasoning and action prediction. We mainly
    consider two types of poisoning strategy, i.e. (1) adversarial backdoor and (2)
    spurious correlation. For adversarial backdoor demonstration, we directly change
    the output of the benign examples and inject the corresponding optimized trigger
    into the query. An example is shown in Fig. [12](#A1.F12 "Figure 12 ‣ A.3.1 Backdoor
    demonstrations ‣ A.3 Detailed Explanation of AgentPoison ‣ Appendix A Appendix
    / supplemental material ‣ AgentPoison: Red-teaming LLM Agents via Poisoning Memory
    or Knowledge Bases").'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '从知识库中检索后，我们展示了行动推理的过程，其中代理将检索到的恶意演示放置在前缀中，并提示 LLM 主干进行推理和行动预测。我们主要考虑两种类型的中毒策略，即（1）对抗性后门和（2）虚假相关。对于对抗性后门演示，我们直接改变良性示例的输出，并将相应的优化触发器注入查询中。示例见图 [12](#A1.F12
    "图 12 ‣ A.3.1 后门演示 ‣ A.3 AgentPoison 详细说明 ‣ 附录 A 附录 / 补充材料 ‣ AgentPoison: 通过中毒记忆或知识库对
    LLM 代理进行红队测试")。'
- en: 'While adversarial backdoor demonstrations are effective in inducing the target
    action output, they are not stealthy enough and easily detected by utility examination.
    Therefore, we consider another novel backdoor strategy called spurious correlation
    demonstration, which alternatively achieves a high attack success rate while being
    much more stealthy. Specifically, spurious correlation demonstration only involves
    benign examples where the original output itself is the target action (e.g. STOP
    for autonomous driving agents). Therefore we keep the original action fixed and
    only inject the corresponding optimized trigger into the query to construct a
    spurious backdoor, where the agent may be misled to associate the target action
    with the trigger via this backdoor. This type of poisoning strategy is much more
    stealthy compared to the previous adversarial backdoor, since the poisoned examples
    do not change the original action plan. An example is shown in Fig. [13](#A1.F13
    "Figure 13 ‣ A.3.1 Backdoor demonstrations ‣ A.3 Detailed Explanation of AgentPoison
    ‣ Appendix A Appendix / supplemental material ‣ AgentPoison: Red-teaming LLM Agents
    via Poisoning Memory or Knowledge Bases").'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '尽管对抗性后门演示在诱导目标行动输出方面效果显著，但它们并不够隐蔽，且易被效用检查检测到。因此，我们考虑另一种新型的后门策略——虚假相关演示，它在实现高攻击成功率的同时更加隐蔽。具体来说，虚假相关演示仅涉及良性示例，其中原始输出本身就是目标行动（例如，自动驾驶代理的
    STOP）。因此，我们保持原始行动不变，只将相应的优化触发器注入查询中，以构建虚假后门，其中代理可能被误导通过该后门将目标行动与触发器关联。这种中毒策略相比于之前的对抗性后门更加隐蔽，因为中毒示例不会改变原始行动计划。示例见图 [13](#A1.F13
    "图 13 ‣ A.3.1 后门演示 ‣ A.3 AgentPoison 详细说明 ‣ 附录 A 附录 / 补充材料 ‣ AgentPoison: 通过中毒记忆或知识库对
    LLM 代理进行红队测试")。'
- en: During our experiment, we adopt the spurious examples as our poisoning strategy
    for Agent-Driver, and adopt adversarial backdoor as our poisoning strategy for
    ReAct-StrategyQA and EHRAgent.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的实验中，我们对 Agent-Driver 采用虚假示例作为中毒策略，对 ReAct-StrategyQA 和 EHRAgent 采用对抗性后门作为中毒策略。
- en: '![Refer to caption](img/b8dda7dcebb1ec49db2f1add798a7969.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/b8dda7dcebb1ec49db2f1add798a7969.png)'
- en: 'Figure 12: An example of the adversarial reasoning backdoor in AgentPoison.
    Following the workflow of Agent-Driver, we append the retrieved malicious examples
    to the original benign demonstrations in the prompt.'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12：AgentPoison 中对抗性推理后门的示例。遵循 Agent-Driver 的工作流程，我们将检索到的恶意示例附加到提示中的原始良性示例中。
- en: '![Refer to caption](img/a79f6c8cb0d012cded42fd31f900bbc2.png)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/a79f6c8cb0d012cded42fd31f900bbc2.png)'
- en: 'Figure 13: An example of the spurious correlation demonstration for Agent-Driver.
    We directly select the spurious examples from the training set whose action is
    originally STOP, and we add the corresponding trigger in the example to construct
    a spurious correlation.'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13：Agent-Driver 的虚假相关性演示示例。我们直接从训练集中选择原始动作为 STOP 的虚假示例，并在示例中添加相应的触发器以构建虚假相关性。
- en: A.3.2 Additional algorithm
  id: totrans-287
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: A.3.2 额外算法
- en: 'The pseudocode for trigger initialization is shown in Algorithm. [4](#alg2.l4
    "In Algorithm 2 ‣ A.3.2 Additional algorithm ‣ A.3 Detailed Explanation of AgentPoison
    ‣ Appendix A Appendix / supplemental material ‣ AgentPoison: Red-teaming LLM Agents
    via Poisoning Memory or Knowledge Bases") where we use it to generate the initial
    beams of triggers that are relevant to the task the agent handles.'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '触发器初始化的伪代码见算法。[4](#alg2.l4 "在算法 2 ‣ A.3.2 额外算法 ‣ A.3 详细解释 AgentPoison ‣ 附录
    A 附录 / 补充材料 ‣ AgentPoison: 通过毒害记忆或知识库来对抗 LLM 代理")，我们使用它来生成与代理处理的任务相关的初始触发器束。'
- en: Algorithm 2 Trigger Initialization
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 2 触发器初始化
- en: 1:function Trigger-Initialization (query-example, agent-task, number-of-tokens)2:     
    message${}_{\text{system}}$)
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 1:函数 Trigger-Initialization (query-example, agent-task, number-of-tokens)2:     
    message${}_{\text{system}}$)
- en: A.4 Additional Analysis on Optimization Approximation
  id: totrans-291
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.4 关于优化近似的额外分析
- en: 'Given the constrained optimization problem defined in §[3.3.2](#S3.SS3.SSS2
    "3.3.2 Constrained Optimization Problem ‣ 3.3 AgentPoison ‣ 3 Method ‣ AgentPoison:
    Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases"):'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '给定在 §[3.3.2](#S3.SS3.SSS2 "3.3.2 受约束优化问题 ‣ 3.3 AgentPoison ‣ 3 方法 ‣ AgentPoison:
    通过毒害记忆或知识库来对抗 LLM 代理") 中定义的受约束优化问题：'
- en: '|  | $1$2 |  | (13) |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (13) |'
- en: 'We can directly adopt Eq. ([9](#S3.E9 "In Target generation loss ‣ 3.3.2 Constrained
    Optimization Problem ‣ 3.3 AgentPoison ‣ 3 Method ‣ AgentPoison: Red-teaming LLM
    Agents via Poisoning Memory or Knowledge Bases")) to calculate the target action
    objective $\mathcal{L}_{tar}(x_{t})$ via the following finite-sample indicator
    function.'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '我们可以直接采用 Eq. ([9](#S3.E9 "在目标生成损失 ‣ 3.3.2 受约束优化问题 ‣ 3.3 AgentPoison ‣ 3 方法
    ‣ AgentPoison: 通过毒害记忆或知识库来对抗 LLM 代理")) 来计算目标动作目标 $\mathcal{L}_{tar}(x_{t})$，通过以下有限样本指示函数。'
- en: '|  | $1$2 |  | (14) |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (14) |'
- en: where $1_{\text{condition}}$ with a polynomial sample complexity.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $1_{\text{condition}}$ 具有多项式样本复杂度。
- en: Theorem A.1  (Complexity analysis for approximating $\mathcal{L}_{tar}(x_{t})$
    with finite samples).
  id: totrans-297
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定理 A.1  (用有限样本近似 $\mathcal{L}_{tar}(x_{t})$ 的复杂性分析)。
- en: We can provide the following sample complexity bound for approximating $\mathcal{L}_{tar}(x_{t})$,
    with at least
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以提供以下样本复杂度界限，用于近似 $\mathcal{L}_{tar}(x_{t})$，至少为
- en: '|  | $N\geq\frac{64}{\epsilon^{2}}\left(2d\ln\frac{12}{\epsilon}+\ln\frac{4}{\gamma}\right)$
    |  | (15) |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '|  | $N\geq\frac{64}{\epsilon^{2}}\left(2d\ln\frac{12}{\epsilon}+\ln\frac{4}{\gamma}\right)$
    |  | (15) |'
- en: 'samples, we have with probability at least $1-\gamma$:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 样本，我们至少有概率 $1-\gamma$：
- en: '|  | $\max_{q\in\mathcal{Q}}\hat{\mathcal{L}}_{tar}(x_{t})\geq\max_{q\in\mathcal{Q}}\mathcal{L}_{tar}(x_{t})-\epsilon$
    |  | (16) |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '|  | $\max_{q\in\mathcal{Q}}\hat{\mathcal{L}}_{tar}(x_{t})\geq\max_{q\in\mathcal{Q}}\mathcal{L}_{tar}(x_{t})-\epsilon$
    |  | (16) |'
- en: Proof.
  id: totrans-302
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 证明。
- en: 'Specifically, to prove Theorem [A.1](#A1.Thmtheorem1 "Theorem A.1 (Complexity
    analysis for approximating ℒ_{𝑡⁢𝑎⁢𝑟}⁢(𝑥_𝑡) with finite samples). ‣ A.4 Additional
    Analysis on Optimization Approximation ‣ Appendix A Appendix / supplemental material
    ‣ AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases"),
    we fist reformulate Eq. ([14](#A1.E14 "In A.4 Additional Analysis on Optimization
    Approximation ‣ Appendix A Appendix / supplemental material ‣ AgentPoison: Red-teaming
    LLM Agents via Poisoning Memory or Knowledge Bases")) in the following form:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '具体而言，为了证明定理 [A.1](#A1.Thmtheorem1 "定理 A.1（使用有限样本近似 ℒ_{𝑡⁢𝑎⁢𝑟}⁢(𝑥_𝑡) 的复杂性分析）。
    ‣ A.4 关于优化近似的额外分析 ‣ 附录 A 附录 / 补充材料 ‣ AgentPoison: 通过毒害记忆或知识库来对抗 LLM 代理")，我们首先将 Eq. ([14](#A1.E14
    "在 A.4 关于优化近似的额外分析 ‣ 附录 A 附录 / 补充材料 ‣ AgentPoison: 通过毒害记忆或知识库来对抗 LLM 代理")) 重新表述为如下形式：'
- en: '|  | $1$2 |  | (17) |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (17) |'
- en: where $a_{r}$ using the following lemma.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $a_{r}$ 使用以下引理。
- en: Lemma 1  (VC Dimension Bound).
  id: totrans-306
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 引理 1 (VC 维度界)。
- en: Let $F$.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 设 $F$。
- en: Proof.
  id: totrans-308
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 证明。
- en: To show that the VC dimension of $H$.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 证明 $H$ 的 VC 维度。
- en: Consider a set of $m$ that correctly classifies the points according to those
    labels.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个集合 $m$，它根据这些标签正确地分类点。
- en: 'Each function $h\in H$ can be written as a linear combination of these basis
    functions:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 每个函数 $h\in H$ 可以写成这些基函数的线性组合：
- en: '|  | $f=\sum_{i=1}^{d}\alpha_{i}f_{i}\quad\text{for some coefficients}~{}\alpha_{i}.$
    |  | (18) |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '|  | $f=\sum_{i=1}^{d}\alpha_{i}f_{i}\quad\text{对于某些系数}~{}\alpha_{i}。$ |  |
    (18) |'
- en: 'For each point $x_{k}$ translates to:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每一点 $x_{k}$ 转化为：
- en: '|  | $1$2 |  | (19) |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (19) |'
- en: 'This can be rewritten as:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以重写为：
- en: '|  | $$\sum_{i=1}^{d}\alpha_{i}(f_{i}(x_{k},a_{m})-f_{i}(x_{k},a_{r}))>
    |  | (20) |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '|  | $$\sum_{i=1}^{d}\alpha_{i}(f_{i}(x_{k},a_{m})-f_{i}(x_{k},a_{r}))>
    |  | (20) |'
- en: 'Let $g_{k}=f_{i}(x_{k},a_{m})-f_{i}(x_{k},a_{r})$ linear inequalities of the
    form:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 令 $g_{k}=f_{i}(x_{k},a_{m})-f_{i}(x_{k},a_{r})$ 线性不等式形式：
- en: '|  | <math id=$$ |  | (21) |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '|  | <math id=$$ |  | (21) |'
- en: To shatter the set $\{x_{1},x_{2},\ldots,x_{m}\}$. ∎
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 使集合 $\{x_{1},x_{2},\ldots,x_{m}\}$ 被打破。∎
- en: Theorem A.2  (Sample Complexity [[3](#bib.bib3)]).
  id: totrans-320
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定理 A.2 （样本复杂度 [[3](#bib.bib3)]）。
- en: 'Suppose that $H$, its sample complexity satisfies:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 假设 $H$，其样本复杂度满足：
- en: '|  | $m_{L}(\epsilon,\gamma)\leq\frac{64}{\epsilon^{2}}\left(2d\ln\frac{12}{\epsilon}+\ln\frac{4}{\gamma}\right)$
    |  | (22) |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '|  | $m_{L}(\epsilon,\gamma)\leq\frac{64}{\epsilon^{2}}\left(2d\ln\frac{12}{\epsilon}+\ln\frac{4}{\gamma}\right)$
    |  | (22) |'
- en: where $m_{L}(\epsilon,\gamma)$ of the true error.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $m_{L}(\epsilon,\gamma)$ 为真实误差。
- en: 'Therefore we can combine Lemma [1](#Thmlemma1 "Lemma 1 (VC Dimension Bound).
    ‣ Proof. ‣ A.4 Additional Analysis on Optimization Approximation ‣ Appendix A
    Appendix / supplemental material ‣ AgentPoison: Red-teaming LLM Agents via Poisoning
    Memory or Knowledge Bases") and Theorem [A.2](#A1.Thmtheorem2 "Theorem A.2 (Sample
    Complexity [3]). ‣ Proof. ‣ A.4 Additional Analysis on Optimization Approximation
    ‣ Appendix A Appendix / supplemental material ‣ AgentPoison: Red-teaming LLM Agents
    via Poisoning Memory or Knowledge Bases") to prove the sample complexity bound
    for $\mathcal{L}_{tar}(x_{t})$, with at least'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '因此，我们可以结合引理 [1](#Thmlemma1 "引理 1 (VC 维度界)。 ‣ 证明。 ‣ A.4 优化近似的额外分析 ‣ 附录 A 附录
    / 补充材料 ‣ AgentPoison: 通过污染记忆或知识库对 LLM 代理进行红队测试") 和 定理 [A.2](#A1.Thmtheorem2 "定理
    A.2 (样本复杂度 [3])。 ‣ 证明。 ‣ A.4 优化近似的额外分析 ‣ 附录 A 附录 / 补充材料 ‣ AgentPoison: 通过污染记忆或知识库对
    LLM 代理进行红队测试") 来证明 $\mathcal{L}_{tar}(x_{t})$ 的样本复杂度界限，至少'
- en: '|  | $N\geq\frac{64}{\epsilon^{2}}\left(2d\ln\frac{12}{\epsilon}+\ln\frac{4}{\gamma}\right)$
    |  |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
  zh: '|  | $N\geq\frac{64}{\epsilon^{2}}\left(2d\ln\frac{12}{\epsilon}+\ln\frac{4}{\gamma}\right)$
    |  |'
- en: 'samples, we have with probability at least $1-\gamma$:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 样本，我们有至少 $1-\gamma$ 的概率：
- en: '|  | $\max_{q\in\mathcal{Q}}\hat{\mathcal{L}}_{tar}(x_{t})\geq\max_{q\in\mathcal{Q}}\mathcal{L}_{tar}(x_{t})-\epsilon$
    |  | (23) |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
  zh: '|  | $\max_{q\in\mathcal{Q}}\hat{\mathcal{L}}_{tar}(x_{t})\geq\max_{q\in\mathcal{Q}}\mathcal{L}_{tar}(x_{t})-\epsilon$
    |  | (23) |'
- en: Therefore, the finite-sample approximation of the target constraint function
    converges polynomially (to $1/\epsilon$ with high probability as the number of
    samples increases. ∎
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，目标约束函数的有限样本近似以多项式速度收敛（当样本数量增加时，以高概率收敛至 $1/\epsilon$）。∎
- en: 'Therefore, Theorem [A.1](#A1.Thmtheorem1 "Theorem A.1 (Complexity analysis
    for approximating ℒ_{𝑡⁢𝑎⁢𝑟}⁢(𝑥_𝑡) with finite samples). ‣ A.4 Additional Analysis
    on Optimization Approximation ‣ Appendix A Appendix / supplemental material ‣
    AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases")
    indicates that we can effectively approximate $\mathcal{L}_{tar}$ with a polynomially
    bounded number of samples, and we use function Eq. ([14](#A1.E14 "In A.4 Additional
    Analysis on Optimization Approximation ‣ Appendix A Appendix / supplemental material
    ‣ AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases"))
    to serve as the constraint for the overall optimization for AgentPoison.'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '因此，定理 [A.1](#A1.Thmtheorem1 "定理 A.1 (使用有限样本近似 ℒ_{𝑡⁢𝑎⁢𝑟}⁢(𝑥_𝑡) 的复杂度分析)。 ‣ A.4
    优化近似的额外分析 ‣ 附录 A 附录 / 补充材料 ‣ AgentPoison: 通过污染记忆或知识库对 LLM 代理进行红队测试") 表明我们可以有效地用多项式有界数量的样本来近似
    $\mathcal{L}_{tar}$，并且我们使用公式 Eq. ([14](#A1.E14 "在 A.4 优化近似的额外分析 ‣ 附录 A 附录 / 补充材料
    ‣ AgentPoison: 通过污染记忆或知识库对 LLM 代理进行红队测试")) 作为 AgentPoison 的整体优化约束。'
- en: A.5 Additional Related Works
  id: totrans-330
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.5 相关工作
- en: A.5.1 Retrieval Augmented Generation
  id: totrans-331
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: A.5.1 检索增强生成
- en: Retrieval Augmented Generation (RAG) [[19](#bib.bib19)] is widely adopted to
    enhance the performance of LLMs by retrieving relevant external information and
    grounding the outputs and action of the model [[22](#bib.bib22), [36](#bib.bib36)].
    The retrievers used in RAG can be categorized into sparse retrievers (e.g. BM25),
    where the embedding is a sparse vector which usually encodes lexical information
    such as word frequency [[24](#bib.bib24)]; and dense retrievers where the embedding
    vectors are dense, which is usually a fine-tuned version of a pre-trained BERT
    encoder [[7](#bib.bib7)]. We focus on red-teaming LLM agents with RAG handled
    by dense retrievers, as they are much more widely adopted in LLM agent systems
    and have been proved to perform much better in terms of retrieval accuracy [[11](#bib.bib11)].
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 检索增强生成（RAG）[[19](#bib.bib19)]被广泛采用以通过检索相关外部信息并将模型的输出和行动进行对接来提升大语言模型（LLMs）的性能[[22](#bib.bib22)、[36](#bib.bib36)]。RAG中使用的检索器可以分为稀疏检索器（例如BM25），其中嵌入是稀疏向量，通常编码词汇信息如词频[[24](#bib.bib24)]；和密集检索器，其中嵌入向量是密集的，通常是经过微调的预训练BERT编码器的版本[[7](#bib.bib7)]。我们关注于使用密集检索器处理的RAG来进行红队测试，因为它们在LLM代理系统中被广泛采用，并且在检索准确性方面表现更好[[11](#bib.bib11)]。
- en: 'In our discussion, we categorize RAG into two categories based on their training
    scheme: (1) end-to-end training where the retriever is updated using causal language
    modeling pipeline handled by cross-entropy loss [[11](#bib.bib11), [17](#bib.bib17)];
    and (2) contrastive surrogate loss where the retriever is trained alone and usually
    on a held-out training set [[30](#bib.bib30), [37](#bib.bib37)].'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的讨论中，我们根据训练方案将RAG分为两类：（1）端到端训练，其中检索器使用由交叉熵损失处理的因果语言建模管道进行更新[[11](#bib.bib11)、[17](#bib.bib17)]；（2）对比替代损失，其中检索器单独训练，通常在保留的训练集上进行[[30](#bib.bib30)、[37](#bib.bib37)]。
- en: 'During end-to-end training, both the retriever and the generator are optimized
    jointly using the language modeling loss [[11](#bib.bib11)]. The retriever selects
    the top $K$ for LLM agent). Therefore the probability of the generated output
    is given by:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 在端到端训练中，检索器和生成器是通过语言建模损失[[11](#bib.bib11)]联合优化的。检索器选择前$K$个用于LLM代理。因此，生成输出的概率由下式给出：
- en: '|  | $\displaystyle p_{\text{RAG}}(y&#124;q)\approx$ |  | (24) |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle p_{\text{RAG}}(y&#124;q)\approx$ |  | (24) |'
- en: '|  | $\displaystyle=$ |  | (25) |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle=$ |  | (25) |'
- en: 'Thus correspondingly the training objective is to minimize the negative log-likelihood
    of the target sequence by optimizing the $E_{q}$:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，相应的训练目标是通过优化$E_{q}$来最小化目标序列的负对数似然：
- en: '|  | $\displaystyle\mathcal{L}_{RAG}=$ |  | (26) |'
  id: totrans-338
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}_{RAG}=$ |  | (26) |'
- en: '|  | $\displaystyle=$ |  | (27) |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle=$ |  | (27) |'
- en: This way embedder $E_{q}$ is trained to align with the holistic goal of the
    generation task. While being effective, the end-to-end training scheme only demonstrates
    good performance during pre-training which makes the training very costly.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，嵌入器$E_{q}$被训练以与生成任务的整体目标对齐。虽然有效，但端到端训练方案仅在预训练期间表现良好，这使得训练成本非常高。
- en: 'Therefore, extensive works on RAG explore training $E_{k}$. The contrastive
    loss function is defined as:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，关于RAG的广泛研究探讨了训练$E_{k}$。对比损失函数被定义为：
- en: '|  | $\displaystyle L(q_{i},k_{i}^{+},k_{i,1}^{-},\cdots,k_{i,n}^{-})=$ |  |
    (28) |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle L(q_{i},k_{i}^{+},k_{i,1}^{-},\cdots,k_{i,n}^{-})=$ |  |
    (28) |'
- en: 'Specifically, Eq. ([28](#A1.E28 "In A.5.1 Retrieval Augmented Generation ‣
    A.5 Additional Related Works ‣ Appendix A Appendix / supplemental material ‣ AgentPoison:
    Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases")) encourages the
    retriever $E_{q}$ to assign higher similarity scores to positive pairs than to
    negative pairs, effectively improving the retrieval accuracy. And different embedders
    often distinguish in their curation of the negative samples [[14](#bib.bib14),
    [37](#bib.bib37), [30](#bib.bib30)].'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '具体来说，方程([28](#A1.E28 "在A.5.1检索增强生成 ‣ A.5附加相关工作 ‣ 附录A附录/补充材料 ‣ AgentPoison:
    通过毒化记忆或知识库进行LLM代理的红队测试"))鼓励检索器$E_{q}$将正样本对分配更高的相似度分数，相对于负样本对，从而有效地提高检索准确性。而且，不同的嵌入器在负样本的策划上往往有所区别[[14](#bib.bib14)、[37](#bib.bib37)、[30](#bib.bib30)]。'
