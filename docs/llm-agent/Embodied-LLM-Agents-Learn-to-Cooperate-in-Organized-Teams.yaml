- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 18:49:57'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-09-08 18:49:57'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Embodied LLM Agents Learn to Cooperate in Organized Teams
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 具身LLM代理在组织团队中学习合作
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2403.12482](https://ar5iv.labs.arxiv.org/html/2403.12482)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2403.12482](https://ar5iv.labs.arxiv.org/html/2403.12482)
- en: Xudong Guo¹  Kaixuan Huang²  Jiale Liu³  Wenhui Fan¹  Natalia Vélez²
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Xudong Guo¹  Kaixuan Huang²  Jiale Liu³  Wenhui Fan¹  Natalia Vélez²
- en: Qingyun Wu³  Huazheng Wang⁴  Thomas L. Griffiths²  Mengdi Wang²
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 吴青云³  王华政⁴  托马斯·L·格里菲斯²  王梦迪²
- en: ¹Tsinghua University ²Princeton University
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ¹清华大学 ²普林斯顿大学
- en: ³Penn State University  ⁴Oregon State University
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ³宾夕法尼亚州立大学  ⁴俄勒冈州立大学
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Large Language Models (LLMs) have emerged as integral tools for reasoning, planning,
    and decision-making, drawing upon their extensive world knowledge and proficiency
    in language-related tasks. LLMs thus hold tremendous potential for natural language
    interaction within multi-agent systems to foster cooperation. However, LLM agents
    tend to over-report and comply with any instruction, which may result in information
    redundancy and confusion in multi-agent cooperation. Inspired by human organizations,
    this paper introduces a framework that imposes prompt-based organization structures
    on LLM agents to mitigate these problems. Through a series of experiments with
    embodied LLM agents and human-agent collaboration, our results highlight the impact
    of designated leadership on team efficiency, shedding light on the leadership
    qualities displayed by LLM agents and their spontaneous cooperative behaviors.
    Further, we harness the potential of LLMs to propose enhanced organizational prompts,
    via a Criticize-Reflect process, resulting in novel organization structures that
    reduce communication costs and enhance team efficiency.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）已成为推理、规划和决策的重要工具，依赖于其广泛的世界知识和语言相关任务的能力。因此，LLMs在多智能体系统中的自然语言互动中具有巨大的潜力，有助于促进合作。然而，LLM代理通常倾向于过度报告并遵循任何指令，这可能导致信息冗余和多智能体合作中的混乱。受人类组织启发，本文介绍了一种框架，通过基于提示的组织结构来规范LLM代理，以缓解这些问题。通过一系列关于具身LLM代理和人类代理合作的实验，我们的结果突显了指定领导对团队效率的影响，揭示了LLM代理表现出的领导素质及其自发合作行为。此外，我们利用LLM的潜力，通过批评-反思过程提出了增强的组织提示，从而提出了新颖的组织结构，减少了沟通成本并提高了团队效率。
- en: 1 Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Modern intelligent systems, such as autonomous vehicle networks and swarms of
    drones, often involve complex decision-making processes where multiple agents
    or components must collaborate seamlessly to achieve specific objectives Wang
    et al. ([2020](#bib.bib53)); Vinyals et al. ([2019](#bib.bib51)); Zhang et al.
    ([2019a](#bib.bib63)); Wang et al. ([2021](#bib.bib54)). In these systems, communication
    among the various agents is pivotal, as it dictates the flow of information, coordination
    of tasks, and overall system performance Zhang et al. ([2019b](#bib.bib66)); Guo
    et al. ([2023](#bib.bib13)); Foerster et al. ([2016](#bib.bib9)); Das et al. ([2019](#bib.bib7)).
    Agents in traditional multi-agent systems often have to communicate in pre-specified
    ways, such as exchanging gradients, sharing data, state observations and actions,
    etc Kim et al. ([2020](#bib.bib18)); Lin et al. ([2021](#bib.bib24)); Foerster
    et al. ([2016](#bib.bib9)). The emergence of large language models (LLMs) makes
    it possible for AI agents to communicate and cooperate using natural language,
    bringing enormous flexibility and potential for more nuanced and human-understandable
    interactions Park et al. ([2023](#bib.bib33)); Hong et al. ([2023](#bib.bib16));
    Mandi et al. ([2023](#bib.bib29)); Chen et al. ([2023a](#bib.bib4)).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 现代智能系统，如自动驾驶汽车网络和无人机群体，通常涉及复杂的决策过程，其中多个智能体或组件必须无缝合作以实现特定目标 Wang et al. ([2020](#bib.bib53));
    Vinyals et al. ([2019](#bib.bib51)); Zhang et al. ([2019a](#bib.bib63)); Wang
    et al. ([2021](#bib.bib54)). 在这些系统中，各智能体之间的通信至关重要，因为它决定了信息流、任务协调和系统整体性能 Zhang
    et al. ([2019b](#bib.bib66)); Guo et al. ([2023](#bib.bib13)); Foerster et al.
    ([2016](#bib.bib9)); Das et al. ([2019](#bib.bib7)). 传统多智能体系统中的智能体通常必须以预定义的方式进行通信，例如交换梯度、共享数据、状态观察和行动等
    Kim et al. ([2020](#bib.bib18)); Lin et al. ([2021](#bib.bib24)); Foerster et
    al. ([2016](#bib.bib9)). 大型语言模型（LLMs）的出现使得AI智能体可以使用自然语言进行沟通和合作，带来了巨大的灵活性和更细致、更易于理解的互动潜力
    Park et al. ([2023](#bib.bib33)); Hong et al. ([2023](#bib.bib16)); Mandi et al.
    ([2023](#bib.bib29)); Chen et al. ([2023a](#bib.bib4)).
- en: Despite the flexibility of LLMs, integrating them into practical multi-agent
    systems remains a challenge. While LLMs are trained and finetuned for text generation
    and instruction-following, they are not necessarily tailored to multi-agent cooperation.
    Modern LLMs are prone to over-reporting and obeying instructions, as a by-product
    of RLHF finetuning (Bai et al., [2022](#bib.bib2)), and they can ignore critical
    information (Liu et al., [2023a](#bib.bib25)) or be distracted by irrelevant information (Shi
    et al., [2023](#bib.bib43)), especially when the context is long (see Figure [1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ Embodied LLM Agents Learn to Cooperate in Organized
    Teams") for examples). While recent studies involving agent-based LLMs have demonstrated
    they are capable of solving problems through multi-agent collaboration Li et al.
    ([2023b](#bib.bib22)); Zhang et al. ([2023c](#bib.bib62)); Mandi et al. ([2023](#bib.bib29)),
    it is worth noting that such collaborations often follow predefined patterns designed
    using heuristics to channel the behavior of the models productively Li et al.
    ([2023b](#bib.bib22)). Creating systems that support free-flowing interaction
    between LLMs in a way that could potentially scale to include human collaborators
    is still an open problem.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管LLM的灵活性很高，将它们整合到实际的多代理系统中仍然是一个挑战。虽然LLM经过训练和微调以进行文本生成和遵循指令，但它们不一定适合多代理合作。现代LLM倾向于过度报告和服从指令，这是RLHF微调的副产品
    **白**等人（[2022](#bib.bib2)），并且它们可能忽略关键信息 **刘**等人（[2023a](#bib.bib25)）或被无关信息分散注意力
    **施**等人（[2023](#bib.bib43)），特别是在上下文较长时（见图[1](#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ Embodied LLM Agents Learn to Cooperate in Organized Teams)）。虽然最近涉及基于代理的LLM的研究表明，它们能够通过多代理协作解决问题
    **李**等人（[2023b](#bib.bib22)）；**张**等人（[2023c](#bib.bib62)）；**曼迪**等人（[2023](#bib.bib29)），但值得注意的是，这种协作通常遵循预定义的模式，这些模式是通过启发式设计来引导模型的行为
    **李**等人（[2023b](#bib.bib22)）。创建支持LLM之间自由流动互动的系统，并且可以扩展到包括人类合作者，仍然是一个未解决的问题。
- en: This paper investigates the collaborative potential of LLM agents working in
    teams. Drawing on prior studies in human collaboration from cognitive and economic
    perspectives, there is potential for organizations to be redesigned to more effectively
    manage the limited attention span within teams, as suggested by Simon et al. ([1971](#bib.bib46)),
    and mitigate individual limitations and enhance overall team performance, as highlighted
    by Van Zandt ([1999](#bib.bib49)) and Vélez et al. ([2023](#bib.bib50)). Specifically,
    we study two research questions. First, *what role do organizational structures
    play in multi-LLM-agent systems?* Second, *how can we optimize these organizational
    structures to support efficient multi-agent coordination?* By leveraging AutoGen Wu
    et al. ([2023](#bib.bib56)), a generic multi-agent conversation framework, we
    develop a framework for studying how to best organize embodied LLM agents to communicate
    and collaborate in physical/simulated non-text environments Zhang et al. ([2023c](#bib.bib62)).
    Our framework offers the flexibility to prompt and organize LLM agents into various
    team structures, facilitating versatile inter-agent communication. It also serves
    as a testbed to empirically evaluate the traditional ideas proposed in the organization
    theory literature.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本文探讨了LLM代理在团队中协作的潜力。借鉴了来自认知和经济学视角的先前研究，组织结构可能需要重新设计，以更有效地管理团队中的有限注意力，如**西蒙**等人（[1971](#bib.bib46)）所建议，并减轻个人限制、提升整体团队表现，如**范赞特**（[1999](#bib.bib49)）和**维莱斯**等人（[2023](#bib.bib50)）所强调的。具体而言，我们研究了两个研究问题。首先，*组织结构在多LLM代理系统中扮演什么角色？*
    其次，*我们如何优化这些组织结构以支持高效的多代理协调？* 通过利用AutoGen **吴**等人（[2023](#bib.bib56)），一个通用的多代理对话框架，我们开发了一个框架，用于研究如何最佳组织具身LLM代理，以便在物理/模拟非文本环境中进行沟通和协作
    **张**等人（[2023c](#bib.bib62)）。我们的框架提供了灵活性，可以提示和组织LLM代理到各种团队结构中，促进多样化的代理间沟通。它还作为一个试验平台，用于实证评估组织理论文献中提出的传统观点。
- en: Our initial experiments in this setting reveal that uncoordinated LLM agents
    often send redundant and repetitive messages and interrupt others’ actions, leading
    to chaos (see Fig. [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Embodied LLM Agents
    Learn to Cooperate in Organized Teams") and Appendix [D](#A4 "Appendix D Ineffective
    Communication ‣ Embodied LLM Agents Learn to Cooperate in Organized Teams")).
    To remedy these issues, we explore organizational structures that allow multiple
    LLM agents to collaborate and complete a common task efficiently.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这一设置下的初步实验表明，未协调的 LLM 代理通常会发送冗余和重复的信息，并中断其他代理的行动，导致混乱（见图[1](#S1.F1 "图 1 ‣
    1 介绍 ‣ 具身 LLM 代理学习在有组织团队中合作")和附录[D](#A4 "附录 D 无效沟通 ‣ 具身 LLM 代理学习在有组织团队中合作")）。为了改善这些问题，我们探索了允许多个
    LLM 代理合作并高效完成共同任务的组织结构。
- en: The first organizational structure we explore is a hierarchy, a classic object
    of study in organizational theory March and Simon ([1958](#bib.bib30)); Radner
    ([1993](#bib.bib39)); Chisholm ([1992](#bib.bib6)); Bolton and Dewatripont ([1994](#bib.bib3));
    Garicano ([2000](#bib.bib11)); Dodds et al. ([2003](#bib.bib8)). With a designated
    leader, LLM agents work more efficiently and collaboratively. For the example
    of a three-agent team, imposing a leader improves efficiency by up to 30% with
    almost no extra communication cost (up to 3%), consistent with findings for human
    organizations Dodds et al. ([2003](#bib.bib8)). This also holds true in five-agent
    cases. Further, LLM agents demonstrated the potential to elect their own leader
    and adjust leadership dynamically via communication. With proper organizations,
    LLM agents exhibit a variety of cooperative behaviors that mimic humans. For example,
    agents can provide constructive suggestions and seek help from others; they can
    also execute appropriate interactions for a hierarchy such as reporting back on
    task progress; see Figures [6](#S4.F6 "Figure 6 ‣ 4.3 Emergence of Cooperative
    Behaviors ‣ 4 Main Results ‣ Embodied LLM Agents Learn to Cooperate in Organized
    Teams") and [7](#S4.F7 "Figure 7 ‣ 4.3 Emergence of Cooperative Behaviors ‣ 4
    Main Results ‣ Embodied LLM Agents Learn to Cooperate in Organized Teams") and
    Appendix [C](#A3 "Appendix C Emergent Cooperative Behaviors in an Organization
    ‣ Embodied LLM Agents Learn to Cooperate in Organized Teams"). We also tested
    human-agent collaboration, and observe that, unsurprisingly, human leaders are
    much better at coordinating a team of agents when compared to AI agents.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们探索的第一个组织结构是层级结构，这是组织理论中经典的研究对象 March 和 Simon ([1958](#bib.bib30)); Radner
    ([1993](#bib.bib39)); Chisholm ([1992](#bib.bib6)); Bolton 和 Dewatripont ([1994](#bib.bib3));
    Garicano ([2000](#bib.bib11)); Dodds 等 ([2003](#bib.bib8))。有了指定的领导者，LLM 代理的工作效率和协作性得到了提升。以一个三代理的团队为例，指定领导者将效率提高了最多
    30%，几乎没有额外的沟通成本（最多 3%），这一发现与人类组织的研究一致 Dodds 等 ([2003](#bib.bib8))。在五代理的情况下也是如此。此外，LLM
    代理表现出了选举自己的领导者并通过沟通动态调整领导权的潜力。通过适当的组织，LLM 代理表现出模仿人类的各种合作行为。例如，代理可以提供建设性的建议并寻求他人的帮助；他们还可以执行适当的层级互动，如报告任务进展；见图[6](#S4.F6
    "图 6 ‣ 4.3 合作行为的出现 ‣ 4 主要结果 ‣ 具身 LLM 代理学习在有组织团队中合作")和[7](#S4.F7 "图 7 ‣ 4.3 合作行为的出现
    ‣ 4 主要结果 ‣ 具身 LLM 代理学习在有组织团队中合作")和附录[C](#A3 "附录 C 组织中的新兴合作行为 ‣ 具身 LLM 代理学习在有组织团队中合作")。我们还测试了人类与代理的合作，并观察到，人类领导者在协调代理团队方面明显优于
    AI 代理。
- en: '![Refer to caption](img/811ed5569e1d26daa4dae7c811046bb5.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/811ed5569e1d26daa4dae7c811046bb5.png)'
- en: 'Figure 1: Example of disorganized communication and interruption, without a
    designated leader. In a team of three GPT-4 agents, two agents engaged in unnecessary
    communication and made disordered decisions, causing a delay due to the lack of
    a predefined organization. We identified many more examples including conflicting
    messages and repetitive communications, see Appendix [D](#A4 "Appendix D Ineffective
    Communication ‣ Embodied LLM Agents Learn to Cooperate in Organized Teams").'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：没有指定领导者的情况下，通信和中断的例子。在一个由三个 GPT-4 代理组成的团队中，两个代理进行了不必要的沟通并做出了无序的决定，导致因缺乏预定义组织而造成延迟。我们还识别了更多例子，包括冲突信息和重复沟通，见附录[D](#A4
    "附录 D 无效沟通 ‣ 具身 LLM 代理学习在有组织团队中合作")。
- en: In addition to testing existing organizational structures, we explore the use
    of LLMs to improve the organization prompt. To this end, we develop a Criticize-Reflect
    framework, adopting a dual LLM architecture, to reflect on the team performance
    and generate improved and novel organization prompts. Through this iterative process,
    our LLM agents spontaneously form novel, effective team structures, leading to
    reduced communication costs and improved efficiency; see Figures [8](#S4.F8 "Figure
    8 ‣ 4.4 Novel Organizational Structures ‣ 4 Main Results ‣ Embodied LLM Agents
    Learn to Cooperate in Organized Teams") and [9](#S4.F9 "Figure 9 ‣ 4.4 Novel Organizational
    Structures ‣ 4 Main Results ‣ Embodied LLM Agents Learn to Cooperate in Organized
    Teams").
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 除了测试现有的组织结构外，我们还探索了使用LLM来改进组织提示。为此，我们开发了一个Criticize-Reflect框架，采用双重LLM架构，反映团队表现并生成改进和新颖的组织提示。通过这一迭代过程，我们的LLM代理自发形成了新颖且有效的团队结构，从而降低了沟通成本，提高了效率；请参见图
    [8](#S4.F8 "图 8 ‣ 4.4 新颖的组织结构 ‣ 4 主要结果 ‣ 具身LLM代理学习在有组织的团队中合作") 和 [9](#S4.F9 "图
    9 ‣ 4.4 新颖的组织结构 ‣ 4 主要结果 ‣ 具身LLM代理学习在有组织的团队中合作")。
- en: 2 Related Works
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: 2.1 LLM Agents
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 大型语言模型代理
- en: As powerful LLMs inherit abundant world knowledge and also general reasoning
    ability, there are increasing efforts to deploy LLMs as the reasoning core for
    decision-making to build human-like autonomous agents (Sun et al., [2023](#bib.bib47);
    Zhu et al., [2023](#bib.bib70); Hao et al., [2023a](#bib.bib14)). This requires
    observations of the RL environment to be translated into natural language in a
    way that is easier for language models to process. The reasoning of the language
    models also needs to be turned into a viable action for execution. Popular prompting
    techniques for doing so include ReAct (Yao et al., [2022](#bib.bib59)) and Reflexion (Shinn
    et al., [2023](#bib.bib45)). Other methods that involve fine-tuning the language
    models have also been explored (Hao et al., [2023b](#bib.bib15)). In addition,
    various techniques have been proposed to mitigate the biases and constraints of
    language models, including chain-of-thought reasoning (Wei et al., [2022](#bib.bib55)),
    external tools (Shen et al., [2023](#bib.bib42); Patil et al., [2023](#bib.bib34)),
    external documents (Wang et al., [2023](#bib.bib52)) and skill libraries (Zhu
    et al., [2023](#bib.bib70)).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 由于强大的大型语言模型（LLM）继承了丰富的世界知识和一般推理能力，越来越多的工作致力于将LLM部署为决策核心，以构建类似人类的自主代理（Sun et
    al., [2023](#bib.bib47); Zhu et al., [2023](#bib.bib70); Hao et al., [2023a](#bib.bib14)）。这需要将强化学习环境的观察结果转换为自然语言，以便语言模型更易处理。语言模型的推理也需要转化为可执行的实际行动。流行的提示技术包括ReAct（Yao
    et al., [2022](#bib.bib59)）和Reflexion（Shinn et al., [2023](#bib.bib45)）。还探讨了涉及微调语言模型的其他方法（Hao
    et al., [2023b](#bib.bib15)）。此外，还提出了各种技术来缓解语言模型的偏见和限制，包括链式推理（Wei et al., [2022](#bib.bib55)）、外部工具（Shen
    et al., [2023](#bib.bib42); Patil et al., [2023](#bib.bib34)）、外部文档（Wang et al.,
    [2023](#bib.bib52)）和技能库（Zhu et al., [2023](#bib.bib70)）。
- en: 2.2 Multi-Agent Cooperation
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 多代理合作
- en: Multi-agent cooperation has been extensively studied for decades under various
    topics such as communication efficiency, planning, leadership, and team dynamics
    using different platforms (Lowe et al., [2017](#bib.bib27); Samvelyan et al.,
    [2019](#bib.bib41); Resnick et al., [2018](#bib.bib40); Puig et al., [2021](#bib.bib37))
    (see recent surveys for detail (Oroojlooy and Hajinezhad, [2023](#bib.bib31);
    Zhang et al., [2021](#bib.bib65); Gronauer and Diepold, [2022](#bib.bib12))).
    Previous works mainly focused on communication through continuous vectors (Das
    et al., [2019](#bib.bib7)) or discrete symbols (Lowe et al., [2017](#bib.bib27);
    Jaques et al., [2019](#bib.bib17)).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 多代理合作在几十年来已经在通信效率、规划、领导力和团队动态等各种主题下进行了广泛研究，使用了不同的平台（Lowe et al., [2017](#bib.bib27);
    Samvelyan et al., [2019](#bib.bib41); Resnick et al., [2018](#bib.bib40); Puig
    et al., [2021](#bib.bib37)）（详细信息见最近的调查（Oroojlooy and Hajinezhad, [2023](#bib.bib31);
    Zhang et al., [2021](#bib.bib65); Gronauer and Diepold, [2022](#bib.bib12)））。以前的工作主要集中在通过连续向量（Das
    et al., [2019](#bib.bib7)）或离散符号（Lowe et al., [2017](#bib.bib27); Jaques et al.,
    [2019](#bib.bib17)）进行通信。
- en: Recent work (Xu et al., [2023](#bib.bib57); Zhang et al., [2023d](#bib.bib64);
    Wu et al., [2023](#bib.bib56); Li et al., [2023a](#bib.bib21)) showed that multiple
    LLM agents or human-agent teams can improve upon single LLM in solving pure text-based
    tasks, such as creative writing, reasoning, and code generation. Liu et al. ([2023b](#bib.bib26)),
    Hong et al. ([2023](#bib.bib16)) and Zheng et al. ([2023](#bib.bib67)) further
    explored agent selection or role assignment to improve the performance.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的工作（Xu 等， [2023](#bib.bib57)；Zhang 等， [2023d](#bib.bib64)；Wu 等， [2023](#bib.bib56)；Li
    等， [2023a](#bib.bib21)）显示，多个 LLM 代理或人机团队在解决纯文本任务（如创意写作、推理和代码生成）方面可以优于单一的 LLM。Liu
    等（[2023b](#bib.bib26)）、Hong 等（[2023](#bib.bib16)）和 Zheng 等（[2023](#bib.bib67)）进一步探讨了代理选择或角色分配以提高性能。
- en: LLMs have also been applied to multi-agent cooperation for embodied tasks (Agashe
    et al., [2023](#bib.bib1); Mandi et al., [2023](#bib.bib29); Park et al., [2023](#bib.bib33);
    Chen et al., [2023a](#bib.bib4)). Besides, Zhang et al. ([2023b](#bib.bib61))
    proposed an intention inference framework to enhance the cooperation of LLM agents
    without explicit communication. Li et al. ([2023b](#bib.bib22)) investigated LLM-agents
    collaboration for Theory of Mind inferences tasks with a broadcast-only communication
    protocol and homogeneous policies. Zhang et al. ([2023c](#bib.bib62)) studied
    embodied multi-agent cooperation in the two-agent and the one-human-one-agent
    settings. Chen et al. ([2023b](#bib.bib5)) explored different fixed communication
    structures for multi-LLM-robots. These initial explorations are also limited to
    fixed team structures and are not optimized for communication efficiency. In contrast,
    our work explores the impact of deploying and optimizing organizational structures,
    allowing $\geq 3$ agents in a team, for efficient multi-agent communication and
    cooperation.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 还被应用于具身任务的多智能体合作（Agashe 等， [2023](#bib.bib1)；Mandi 等， [2023](#bib.bib29)；Park
    等， [2023](#bib.bib33)；Chen 等， [2023a](#bib.bib4)）。此外，Zhang 等（[2023b](#bib.bib61)）提出了一种意图推理框架，以增强
    LLM 代理的合作，而无需明确的通信。Li 等（[2023b](#bib.bib22)）研究了 LLM 代理在理论心理学推理任务中的合作，采用了仅广播通信协议和同质策略。Zhang
    等（[2023c](#bib.bib62)）研究了在双代理和一个人一个代理的设置中进行具身多智能体合作。Chen 等（[2023b](#bib.bib5)）探讨了多
    LLM 机器人不同的固定通信结构。这些初步探索也局限于固定团队结构，并且未针对通信效率进行优化。相比之下，我们的工作探讨了部署和优化组织结构的影响，允许团队中有
    $\geq 3$ 个代理，以实现高效的多智能体通信与合作。
- en: 2.3 Prompt Optimization
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 提示优化
- en: Language models are sensitive to prompts. The format of the prompt can have
    a substantial influence on performance (Gao et al., [2020](#bib.bib10); Wei et al.,
    [2022](#bib.bib55); Zhou et al., [2022a](#bib.bib68); Shi et al., [2023](#bib.bib43);
    Zou et al., [2023](#bib.bib71); Qi et al., [2023](#bib.bib38)). Various research
    efforts have aimed at improving performance through prompt optimization. Typical
    approaches include heuristic search using language models’ knowledge (Gao et al.,
    [2020](#bib.bib10); Shin et al., [2020](#bib.bib44)), first-order methods like
    soft prompt tuning (Lester et al., [2021](#bib.bib20)), and prefix tuning (Li
    and Liang, [2021](#bib.bib23)). In this work, we focus on obtaining an interpretable
    prompt in the form of natural language, drawing on insights from Yang et al. ([2023](#bib.bib58)),
    Zhou et al. ([2022b](#bib.bib69)), and Pryzant et al. ([2023](#bib.bib35)).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型对提示非常敏感。提示的格式可以对性能产生重大影响（Gao 等， [2020](#bib.bib10)；Wei 等， [2022](#bib.bib55)；Zhou
    等， [2022a](#bib.bib68)；Shi 等， [2023](#bib.bib43)；Zou 等， [2023](#bib.bib71)；Qi
    等， [2023](#bib.bib38)）。各种研究努力旨在通过提示优化来提高性能。典型的方法包括利用语言模型知识的启发式搜索（Gao 等， [2020](#bib.bib10)；Shin
    等， [2020](#bib.bib44)），像软提示调整（Lester 等， [2021](#bib.bib20)）这样的一级方法，以及前缀调整（Li 和
    Liang， [2021](#bib.bib23)）。在这项工作中，我们专注于获取以自然语言形式表达的可解释提示，借鉴了 Yang 等（[2023](#bib.bib58)）、Zhou
    等（[2022b](#bib.bib69)）和 Pryzant 等（[2023](#bib.bib35)）的见解。
- en: 3 Method
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 方法
- en: 3.1 Architecture and Multi-Agent Communication
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 架构和多智能体通信
- en: 'We adopt the embodied LLM-agent architecture proposed by Zhang et al. ([2023c](#bib.bib62))
    and expand it to enable organized teams of $\geq 3$ agents to communicate, plan,
    and act in physical/simulated environments. Figure [2](#S3.F2 "Figure 2 ‣ 3.1
    Architecture and Multi-Agent Communication ‣ 3 Method ‣ Embodied LLM Agents Learn
    to Cooperate in Organized Teams") illustrates our architecture. Borrow insights
    from Zhang et al. ([2023c](#bib.bib62)), we adopt four standard modules: Configurator,
    Perception Module, Memory Module, and Execution Module. They are responsible for
    configuring the agents, translating environmental observations into text, storing
    & retrieving historical information, and executing actions, respectively (Fig. [2](#S3.F2
    "Figure 2 ‣ 3.1 Architecture and Multi-Agent Communication ‣ 3 Method ‣ Embodied
    LLM Agents Learn to Cooperate in Organized Teams")(a)).'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们采用了Zhang等人提出的**具身LLM-agent**架构（[2023c](#bib.bib62)），并扩展其功能，使得组织化的$\geq 3$代理能够在物理/模拟环境中进行沟通、规划和行动。图[2](#S3.F2
    "Figure 2 ‣ 3.1 Architecture and Multi-Agent Communication ‣ 3 Method ‣ Embodied
    LLM Agents Learn to Cooperate in Organized Teams")展示了我们的架构。借鉴Zhang等人（[2023c](#bib.bib62)）的见解，我们采用了四个标准模块：Configurator、Perception
    Module、Memory Module和Execution Module。它们分别负责配置代理、将环境观察转化为文本、存储和检索历史信息以及执行动作（图[2](#S3.F2
    "Figure 2 ‣ 3.1 Architecture and Multi-Agent Communication ‣ 3 Method ‣ Embodied
    LLM Agents Learn to Cooperate in Organized Teams")(a)）。
- en: '![Refer to caption](img/0c035fffedab9133538b106aad43e7a6.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/0c035fffedab9133538b106aad43e7a6.png)'
- en: 'Figure 2: Multi-LLM-agent architecture. (a) The modules of an LLM agent and
    the composition of prompts. (b) There are two phases in one time step: Communication
    phase and Action phase. In the communication phase, the agents take turns communicating
    by broadcasting or selecting receivers to send distinct messages. The agents can
    also choose to keep silent. Comm is short for Communication; PO is short for Partial
    Observation.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：多LLM-agent架构。(a) LLM代理的模块及提示的组成。(b) 一个时间步中有两个阶段：沟通阶段和行动阶段。在沟通阶段，代理轮流进行沟通，通过广播或选择接收者发送不同的信息。代理也可以选择保持沉默。Comm是Communication的缩写；PO是Partial
    Observation的缩写。
- en: '![Refer to caption](img/5d388d043eeb70ebad8f33ea2366218f.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/5d388d043eeb70ebad8f33ea2366218f.png)'
- en: 'Figure 3: Criticize-Reflect architecture for improving organizational structure.
    The red agent represents the leader in an organization. The Critic evaluates the
    trajectories and analyzes the agents’ performance. Together with the external
    costs from the environment, the Coordinator proposes a new organization prompt
    to improve the team efficiency.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：用于改进组织结构的Criticize-Reflect架构。红色代理代表组织中的领导者。Critic评估轨迹并分析代理的表现。结合来自环境的外部成本，Coordinator提出新的组织提示以提高团队效率。
- en: 'Previous works focused on two-agent cooperation, in which case the communication
    can be simply treated as an extra action Mandi et al. ([2023](#bib.bib29)); Zhang
    et al. ([2023c](#bib.bib62)). In contrast, we aim to enable three or more agents
    to work in a team and cooperate through organized communication. Thus we design
    the architecture with several features that facilitate organized multi-agent communication
    (Figure [2](#S3.F2 "Figure 2 ‣ 3.1 Architecture and Multi-Agent Communication
    ‣ 3 Method ‣ Embodied LLM Agents Learn to Cooperate in Organized Teams")(b)):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的工作集中在两代理合作的场景，其中通信可以简单地视为额外的动作Mandi等人（[2023](#bib.bib29)）；Zhang等人（[2023c](#bib.bib62)）。相比之下，我们的目标是使三个或更多代理能够在团队中通过有组织的沟通进行合作。因此，我们设计了具有多个功能的架构，以促进有组织的多代理沟通（图[2](#S3.F2
    "Figure 2 ‣ 3.1 Architecture and Multi-Agent Communication ‣ 3 Method ‣ Embodied
    LLM Agents Learn to Cooperate in Organized Teams")(b)）：
- en: •
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We impose an organizational structure for the agent team via prompting, i.e.,
    including a textual description as part of the prompt for each round of communication.
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们通过提示对代理团队施加了组织结构，即在每轮沟通中包括文本描述作为提示的一部分。
- en: •
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'LLM agents keep alternating between two phases during their task: the communication
    phase and the action phase. The standalone communication phase supports richer
    team structures and flexible communication patterns.'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LLM代理在任务中不断交替进行两个阶段：沟通阶段和行动阶段。独立的沟通阶段支持更丰富的团队结构和灵活的沟通模式。
- en: •
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: During communication, agents take turns to communicate. An agent can choose
    to broadcast a message, select one recipient for a message, choose multiple recipients
    and send them distinct messages, or remain silent. Agents keep their own history
    of communication and can respond to messages from previous communications.
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在交流过程中，代理人轮流进行沟通。代理人可以选择广播消息、选择一个接收者发送消息、选择多个接收者并发送不同的消息，或保持沉默。代理人保留自己的交流历史，并可以回应之前交流中的消息。
- en: 3.2 Criticize-Reflect Method for Improving Organizational Structure
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 批评-反思方法以改善组织结构
- en: 'We leverage powerful LLMs to optimize the organization prompt, borrowing insights
    from (Yang et al., [2023](#bib.bib58)). To do so, we introduce a dual-LLM framework
    to allow the multi-LLM-agent system to ponder and improve the organizational structure.
    Figure [3](#S3.F3 "Figure 3 ‣ 3.1 Architecture and Multi-Agent Communication ‣
    3 Method ‣ Embodied LLM Agents Learn to Cooperate in Organized Teams") illustrates
    the architecture of our framework. It consists of two LLMs:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们利用强大的 LLM 来优化组织提示，借鉴了 (Yang 等人，[2023](#bib.bib58)) 的见解。为此，我们引入了一个双 LLM 框架，以允许多
    LLM 代理系统思考并改进组织结构。图 [3](#S3.F3 "Figure 3 ‣ 3.1 Architecture and Multi-Agent Communication
    ‣ 3 Method ‣ Embodied LLM Agents Learn to Cooperate in Organized Teams") 展示了我们框架的架构。它由两个
    LLM 组成：
- en: •
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'LLM critic: Inspired by the Actor-Critic method of reinforcement learning Konda
    and Tsitsiklis ([1999](#bib.bib19)), we introduce an LLM critic to evaluate the
    team’s performance based on verbal feedback. The team critic takes as input the
    dialogue and action history of one episode. Then, the critic analyzes the input
    and reasons to extract and summarize the key steps that are believed to influence
    the performance in the episode. Also, the critic provides a textual evaluation
    of agents’ behaviors and the ranking of their leadership. Note that the critic
    in our method is different from Zhang et al. ([2023a](#bib.bib60)) where the critic
    is a centralized controller offering suggestions to each agent. See the prompts
    in Appendix [A](#A1 "Appendix A Prompt Templates ‣ Embodied LLM Agents Learn to
    Cooperate in Organized Teams").'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LLM 评估者：受到 Konda 和 Tsitsiklis 的 Actor-Critic 强化学习方法 ([1999](#bib.bib19)) 的启发，我们引入了一个
    LLM 评估者，通过口头反馈来评估团队的表现。团队评估者以一个回合的对话和行动历史作为输入。然后，评估者分析输入并推理，以提取和总结那些被认为会影响回合表现的关键步骤。此外，评估者提供对代理行为的文本评价以及他们领导力的排名。请注意，我们的方法中的评估者不同于
    Zhang 等人 ([2023a](#bib.bib60)) 的评估者，后者是一个集中式控制器，为每个代理提供建议。详细内容请参见附录 [A](#A1 "Appendix
    A Prompt Templates ‣ Embodied LLM Agents Learn to Cooperate in Organized Teams")。
- en: •
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'LLM coordinator: The LLM coordinator takes as input the outputs of the LLM
    critic as well as cost metrics of previous episodes from the environment. It reflects
    on these data and generates thoughts based on the analysis of the past episodes.
    The coordinator then generates three distinct new prompts and chooses the best
    out of them. For more details please refer to Appendix [A](#A1 "Appendix A Prompt
    Templates ‣ Embodied LLM Agents Learn to Cooperate in Organized Teams").'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LLM 协调员：LLM 协调员以 LLM 评估者的输出以及环境中先前回合的成本指标作为输入。它反思这些数据，并基于对过去回合的分析生成想法。协调员随后生成三个不同的新提示，并从中选择最佳的一个。更多细节请参见附录
    [A](#A1 "Appendix A Prompt Templates ‣ Embodied LLM Agents Learn to Cooperate
    in Organized Teams")。
- en: For each new organization prompt, we run for one episode following the new organizational
    structure and then return the dialogue and action history to the critic. By alternating
    between criticizing and reflecting on current structure, the framework discovers
    more effective, novel organizational structures with *self-improvement*.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个新的组织提示，我们在新的组织结构下运行一个回合，然后将对话和行动历史返回给评估者。通过交替批评和反思当前结构，该框架发现了更有效的、具有 *自我改进*
    的新型组织结构。
- en: 3.3 Environment Setup
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 环境设置
- en: We chose VirtualHome-Social Puig et al. ([2018](#bib.bib36), [2021](#bib.bib37))
    as the environment and extended it to support multi-LLM-agent communication and
    interaction. In this environment, agents are humanoid helpers in a virtual home
    doing housekeeping, where the tasks include Prepare afternoon tea, Wash dishes,
    Prepare a meal, Put groceries, Set up a dinner table, etc. For instance, in Figure [1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ Embodied LLM Agents Learn to Cooperate in Organized
    Teams"), the agents cooperate to prepare afternoon tea by searching for and transporting
    task-specific items (chocolate, juice, wine, etc.) to a target location (the coffee
    table). The environment generates symbolic observations of the objects in the
    home and their relations. Each agent only observes the objects in the open containers
    located in her room and teammates in the same room, but she can walk to another
    room to explore. Any agent can communicate with any other agent, not subject to
    a range limit.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了VirtualHome-Social Puig等人（[2018](#bib.bib36)，[2021](#bib.bib37)）作为环境，并扩展它以支持多LLM代理的通信和互动。在这个环境中，代理是虚拟家庭中的类人助手，负责家务工作，任务包括准备下午茶、洗碗、准备餐点、放置杂货、布置餐桌等。例如，在图[1](#S1.F1
    "图 1 ‣ 1 介绍 ‣ 具身LLM代理学习在组织团队中的合作")中，代理通过搜索并运输任务特定的物品（巧克力、果汁、葡萄酒等）到目标位置（咖啡桌）来合作准备下午茶。环境生成对象及其关系的符号观察。每个代理只观察她房间内开放容器中的物品和同房间的队友，但她可以走到另一个房间进行探索。任何代理都可以与任何其他代理沟通，不受范围限制。
- en: Each episode starts from an initial state where agents are randomly located
    in the environment and all containers are closed. The episode terminates when
    the task is fully completed. To evaluate the team’s efficiency we measure the
    number of time steps taken to task completion, and we report the average number
    of tokens communicated between agents per step. In our experiment, each run initializes
    with an independently randomized state to obtain the mean and a confidence interval.
    We adopt GPT-4, GPT-3.5-turbo (Ouyang et al., [2022](#bib.bib32)), and Llama2-70B (Touvron
    et al., [2023](#bib.bib48)) as LLMs in our agents. The temperature is set as 0.8,
    the maximum number of output tokens is 256, and the number of completion choices
    to generate is 1.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 每次实验从一个初始状态开始，代理在环境中随机分布，所有容器都是关闭的。实验在任务完全完成时终止。为了评估团队的效率，我们测量了任务完成所需的时间步骤数，并报告了每个步骤中代理之间通信的平均标记数。在我们的实验中，每次运行都以独立随机化的状态初始化，以获得均值和置信区间。我们采用了GPT-4、GPT-3.5-turbo（Ouyang等人，[2022](#bib.bib32)）和Llama2-70B（Touvron等人，[2023](#bib.bib48)）作为我们代理中的LLM。温度设置为0.8，最大输出标记数为256，生成的完成选项数为1。
- en: 4 Main Results
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 主要结果
- en: '![Refer to caption](img/76e84804a48acdebbe6ad010391e61d3.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![参考图注](img/76e84804a48acdebbe6ad010391e61d3.png)'
- en: 'Figure 4: Organized teams with a designated leader achieve higher efficiency.
    (a,b) Comparison between the case of disorganized agents, the case where a leader
    is appointed, the case where agents choose their own leader dynamically, and the
    case where a human player replaces an agent to be the leader. Note that GPT-3.5-turbo
    doesn’t support leadership election. (c,d) Comparing leadership quality for GPT-3.5-turbo
    vs. GPT-4\. The confidence intervals of Human as the leader group are calculated
    over 3 seeds while others are over 20 seeds.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：有指定领导的组织团队能实现更高的效率。（a,b）对比了无序代理的情况、有领导被任命的情况、代理动态选择领导的情况以及一个人类玩家替代代理成为领导的情况。请注意，GPT-3.5-turbo不支持领导选举。（c,d）对比了GPT-3.5-turbo与GPT-4的领导质量。人类作为领导组的置信区间是基于3次实验计算的，而其他组则是基于20次实验计算的。
- en: '![Refer to caption](img/ceb70a394c6f28d7e599c28c02fe10e5.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![参考图注](img/ceb70a394c6f28d7e599c28c02fe10e5.png)'
- en: 'Figure 5: Examples of communication messages when there is a designated leader.
    Left: messages from lead agents; Right: messages from non-lead agents. GPT-4 (upper),
    GPT-3.5-turbo (center), and Llama2-70B (lower) demonstrated different communication
    styles.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：有指定领导时的通信消息示例。左：来自领导代理的消息；右：来自非领导代理的消息。GPT-4（上），GPT-3.5-turbo（中），和Llama2-70B（下）展示了不同的通信风格。
- en: 4.1 A Designated Leader Enhances Performance
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 指定领导提升表现
- en: We first studied the effect of organizational structures and leadership on LLM
    agents. For benchmarking, we experimented with disorganized LLM agents without
    providing any organization prompt. In this case, agents still communicate with
    one another and work to complete the overall task. However, we discovered frequent
    occasions where agents send redundant, repetitive messages and interfere with
    one another. See Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Embodied LLM Agents
    Learn to Cooperate in Organized Teams") for an illustration and see Appendix [D](#A4
    "Appendix D Ineffective Communication ‣ Embodied LLM Agents Learn to Cooperate
    in Organized Teams") for more examples. Numeric metrics are reported in Appendix
    Table [1](#A2.T1 "Table 1 ‣ B.1 Complete list of basic experimental results ‣
    Appendix B Additional Results ‣ Embodied LLM Agents Learn to Cooperate in Organized
    Teams").
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先研究了组织结构和领导力对LLM代理的影响。为了进行基准测试，我们实验了没有任何组织提示的无序LLM代理。在这种情况下，代理仍然会相互通信并协作完成整体任务。然而，我们发现代理发送冗余、重复信息并相互干扰的情况频繁出现。有关插图，请参见图[1](#S1.F1
    "图 1 ‣ 1 引言 ‣ 具象化LLM代理学习在组织团队中的合作")，有关更多示例，请参见附录[D](#A4 "附录 D 无效沟通 ‣ 具象化LLM代理学习在组织团队中的合作")。数值指标报告见附录表[1](#A2.T1
    "表 1 ‣ B.1 完整的基础实验结果列表 ‣ 附录 B 额外结果 ‣ 具象化LLM代理学习在组织团队中的合作")。
- en: When a leader is appointed via the organization prompt, we observe improved
    team performance – the teams completed the task in less time (Figure [4](#S4.F4
    "Figure 4 ‣ 4 Main Results ‣ Embodied LLM Agents Learn to Cooperate in Organized
    Teams")(a)). After running the 3$\times$). Compared to the disorganized teams,
    teams with a designated leader only have a slightly increased or even less communication
    cost (Figure [4](#S4.F4 "Figure 4 ‣ 4 Main Results ‣ Embodied LLM Agents Learn
    to Cooperate in Organized Teams")(b)). This is consistent with patterns seen in
    previous models of hierarchical organizations Dodds et al. ([2003](#bib.bib8)).
    For additional experiments on Llama2-70B, please see Appendix Table [1](#A2.T1
    "Table 1 ‣ B.1 Complete list of basic experimental results ‣ Appendix B Additional
    Results ‣ Embodied LLM Agents Learn to Cooperate in Organized Teams"). The communication
    styles of leaders and non-leaders were clearly differentiated, as shown in Figure
    [5](#S4.F5 "Figure 5 ‣ 4 Main Results ‣ Embodied LLM Agents Learn to Cooperate
    in Organized Teams").
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 当通过组织提示指定领导者时，我们观察到团队表现有所改善——团队在更短时间内完成任务（图[4](#S4.F4 "图 4 ‣ 4 主要结果 ‣ 具象化LLM代理学习在组织团队中的合作")(a)）。与无序团队相比，指定领导的团队仅有稍微增加或甚至更少的沟通成本（图[4](#S4.F4
    "图 4 ‣ 4 主要结果 ‣ 具象化LLM代理学习在组织团队中的合作")(b)）。这与Dodds等人（[2003](#bib.bib8)）在先前的层级组织模型中看到的模式一致。有关Llama2-70B的额外实验，请参见附录表[1](#A2.T1
    "表 1 ‣ B.1 完整的基础实验结果列表 ‣ 附录 B 额外结果 ‣ 具象化LLM代理学习在组织团队中的合作")。如图[5](#S4.F5 "图 5 ‣
    4 主要结果 ‣ 具象化LLM代理学习在组织团队中的合作")所示，领导者和非领导者的沟通风格明显不同。
- en: 'Next, we asked the agents to elect their own leader. The leadership was reelected
    about every 9 time steps, based on information extracted from the latest 12 messages.
    We observe that agents are generally not power-seeking: they often vote for others
    to lead. In some occasions, agents favored candidates who exhibited higher knowledge
    levels, for example, one agent thought that “Given that Agent_2 has found a necessary
    item, it makes sense for him to be the leader in this round." However, on most
    occasions, we could not tell whether agents made their votes based on rational
    reasoning or just random thoughts (see Appendix [E](#A5 "Appendix E Examples of
    Election ‣ Embodied LLM Agents Learn to Cooperate in Organized Teams")). In the
    case of the 3$\times$; see Figure [4](#S4.F4 "Figure 4 ‣ 4 Main Results ‣ Embodied
    LLM Agents Learn to Cooperate in Organized Teams")(a)). However, this improvement
    was accompanied by a substantial increase in communication cost (i.e., token usages),
    akin to real-world scenarios where relaxing hierarchical structure potentially
    increases communication costs Malone ([2004](#bib.bib28)).'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们要求代理们选举自己的领导者。领导职位大约每 9 次时间步进行重新选举，基于从最新的 12 条消息中提取的信息。我们观察到代理们通常并不寻求权力：他们常常投票给其他人来领导。在一些情况下，代理们倾向于选择展示出较高知识水平的候选人，例如，一位代理认为“鉴于
    Agent_2 已找到一个必要的物品，他在这一轮中作为领导者是有意义的。”然而，在大多数情况下，我们无法判断代理们的投票是否基于理性推理或只是随机的想法（参见附录
    [E](#A5 "附录 E 选举示例 ‣ 具身 LLM 代理学会在组织化团队中合作")）。在 3$\times$ 的情况下，见图 [4](#S4.F4 "图
    4 ‣ 主要结果 ‣ 具身 LLM 代理学会在组织化团队中合作")（a））。然而，这一改进伴随着沟通成本的显著增加（即令牌使用量），类似于现实世界中放宽层级结构可能增加沟通成本的情况
    Malone ([2004](#bib.bib28))。
- en: The proposed multi-LLM-agent architecture is also human-friendly to support
    *human-AI collaboration*. In the experiment, we ask a human player to replace
    the leader in the team of 3 GPT-4 agents. We recruit three human players to conduct
    the experiments. Figure [4](#S4.F4 "Figure 4 ‣ 4 Main Results ‣ Embodied LLM Agents
    Learn to Cooperate in Organized Teams")(a, b) demonstrates that human leadership
    achieved better task completion time and improved communication efficiency compared
    with GPT-4 as the leader. Please find more examples of dialogues between the human
    leader and LLM agents in Appendix [F](#A6 "Appendix F Examples of Human-AI Collaboration
    ‣ Embodied LLM Agents Learn to Cooperate in Organized Teams").
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 所提出的多 LLM 代理架构也适合人类使用，以支持 *人机协作*。在实验中，我们要求一名人类玩家替代 3 个 GPT-4 代理团队中的领导者。我们招募了三名人类玩家来进行实验。图
    [4](#S4.F4 "图 4 ‣ 主要结果 ‣ 具身 LLM 代理学会在组织化团队中合作")（a, b）表明，与 GPT-4 作为领导者相比，人类领导能够实现更好的任务完成时间和提高沟通效率。有关人类领导者与
    LLM 代理之间对话的更多示例，请参见附录 [F](#A6 "附录 F 人机协作示例 ‣ 具身 LLM 代理学会在组织化团队中合作")。
- en: 4.2 Leadership and Open Communication Matters
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 领导力和开放沟通的重要性
- en: LLM agents have different levels of leadership. In the team with a mixture of
    GPT-4 and GPT-3.5-turbo agents, appointing GPT-4 as the leader increases the team
    efficiency higher than if GPT-3.5-turbo is the leader (Figure [4](#S4.F4 "Figure
    4 ‣ 4 Main Results ‣ Embodied LLM Agents Learn to Cooperate in Organized Teams")(c,d)).
    We ran this experiment on teams of three agents and five agents, respectively.
    In both scenarios, the task completion time and communication cost are reduced
    when GPT-4 acts as the leader. This finding implies different levels of leadership
    between these LLMs.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 代理具有不同的领导层级。在由 GPT-4 和 GPT-3.5-turbo 代理混合组成的团队中，任命 GPT-4 为领导者能够比 GPT-3.5-turbo
    领导时提高团队效率（见图 [4](#S4.F4 "图 4 ‣ 主要结果 ‣ 具身 LLM 代理学会在组织化团队中合作")（c,d））。我们在由三个代理和五个代理组成的团队中分别进行了这个实验。在这两种情况下，当
    GPT-4 担任领导时，任务完成时间和沟通成本均有所降低。这一发现暗示了这些 LLM 之间存在不同的领导层级。
- en: We also observed that encouraging constructive feedback to the leader agent
    helped performance. Motivated by successful human organizations, we tried to promote
    open communications among LLM agents by adding an additional prompt that "If the
    leader’s instructions are not right, you can correct the leader". Figure [4](#S4.F4
    "Figure 4 ‣ 4 Main Results ‣ Embodied LLM Agents Learn to Cooperate in Organized
    Teams")(c, d) illustrates the results. Interestingly, this modification improves
    the team’s overall efficiency and reduces the time to task completion when the
    team is made up of 3$\times$). In both experiments, the communication cost increases.
    We present more details about these behaviors in Appendix [G](#A7 "Appendix G
    Examples of Correction ‣ Embodied LLM Agents Learn to Cooperate in Organized Teams").
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还观察到，鼓励对领导代理进行建设性反馈有助于提高表现。受到成功人类组织的启发，我们尝试通过添加一个额外的提示来促进LLM代理之间的开放沟通，该提示为“如果领导者的指示不正确，你可以纠正领导者”。图[4](#S4.F4
    "图 4 ‣ 4 主要结果 ‣ 体现型LLM代理学习在组织团队中合作")(c, d)说明了结果。有趣的是，这一修改提高了团队的整体效率，并在团队由3$\times$组成时缩短了任务完成时间。在这两个实验中，沟通成本增加。我们在附录[G](#A7
    "附录 G 纠正示例 ‣ 体现型LLM代理学习在组织团队中合作")中提供了关于这些行为的更多细节。
- en: 4.3 Emergence of Cooperative Behaviors
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 合作行为的出现
- en: We delved into the behaviors of LLM agents in an organized team to investigate
    how organization prompts influence agents’ communication and decisions. Analysis
    of their dialogue history revealed that agents demonstrated a variety of cooperative
    behaviors, such as reporting, correction, task allocation, and asking for help
    (see Figure [6](#S4.F6 "Figure 6 ‣ 4.3 Emergence of Cooperative Behaviors ‣ 4
    Main Results ‣ Embodied LLM Agents Learn to Cooperate in Organized Teams") for
    an example dialogue).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们深入研究了组织团队中LLM代理的行为，以调查组织提示如何影响代理的沟通和决策。对其对话历史的分析揭示了代理展示了多种合作行为，例如报告、纠正、任务分配和寻求帮助（示例对话请参见图[6](#S4.F6
    "图 6 ‣ 4.3 合作行为的出现 ‣ 4 主要结果 ‣ 体现型LLM代理学习在组织团队中合作")）。
- en: 'One may argue that these types of behaviors could also emerge due to the nature
    of LLMs, even without a pre-specified team structure. Thus we performed a quantitative
    analysis to study the impact of an organization prompt on these behaviors. We
    followed a three-step process:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 有人可能认为，这些类型的行为也可能因大型语言模型（LLMs）的本质而出现，即使没有预先指定的团队结构。因此，我们进行了定量分析，以研究组织提示对这些行为的影响。我们遵循了三步过程：
- en: (1)
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: 'We defined three major categories of human cooperative behaviors: (i) Information
    sharing: agents influence others by offering new information, either actively
    or by being asked. Reporting to the leader, sharing new observations, and answering
    questions belong to this category. (ii) Leadership & assistance: agents, especially
    the leader if there is one, can influence others by changing their plans. The
    behaviors include task allocation, correction, and asking for help. (iii) Request
    for guidance: agents actively request new information or plans for their own decision
    making.'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们定义了三种主要的人类合作行为类别：（i）信息共享：代理通过主动提供新信息或应询问的方式影响他人。向领导者报告、分享新观察结果和回答问题都属于这一类别。（ii）领导与协助：代理，特别是如果有领导者的话，可以通过改变计划来影响他人。这些行为包括任务分配、纠正和寻求帮助。（iii）请求指导：代理主动请求新的信息或计划以进行决策。
- en: (2)
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (2)
- en: We developed a standalone prompt-based GPT-4- classifier to analyze each piece
    of dialogue. The classifier decides whether to label the dialogue with any subset
    of the aforementioned labels. The classifier has an accuracy of 91.67% when tested
    on 20 human-labeled dialogue samples with 60 labels (see Appendix [A](#A1 "Appendix
    A Prompt Templates ‣ Embodied LLM Agents Learn to Cooperate in Organized Teams")
    for the prompt and Appendix [H](#A8 "Appendix H Examples of Cooperative Behaviors
    Classification by Humans and GPT-4 ‣ Embodied LLM Agents Learn to Cooperate in
    Organized Teams") for the test samples).
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们开发了一个独立的基于提示的GPT-4分类器来分析每段对话。该分类器决定是否将对话标记为上述标签的任何子集。该分类器在对20个人工标记的对话样本进行测试时，准确率为91.67%（有关提示请参见附录[A](#A1
    "附录 A 提示模板 ‣ 体现型LLM代理学习在组织团队中合作")，测试样本见附录[H](#A8 "附录 H 人类和GPT-4的合作行为分类示例 ‣ 体现型LLM代理学习在组织团队中合作")）。
- en: (3)
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (3)
- en: We use the classifier to label messages generated by our teams of agents, and
    report the percentages of messages with cooperative behaviors. Note that a message
    may have multiple labels.
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们使用分类器标记由我们团队的代理生成的消息，并报告具有合作行为的消息百分比。注意，一条消息可能具有多个标签。
- en: Figure [7](#S4.F7 "Figure 7 ‣ 4.3 Emergence of Cooperative Behaviors ‣ 4 Main
    Results ‣ Embodied LLM Agents Learn to Cooperate in Organized Teams") reports
    the results and illustrates the behavior patterns for different LLM agents. The
    results support several observations. Even in a disorganized team, LLM agents
    love to tell others what to do. Leadership & assistance accounts for around $$>
    of the dialogues.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [7](#S4.F7 "图 7 ‣ 4.3 合作行为的涌现 ‣ 4 主要结果 ‣ 具象化的 LLM 代理学会在组织团队中合作") 报告了结果并展示了不同
    LLM 代理的行为模式。结果支持几个观察。即使在无序的团队中，LLM 代理也喜欢告诉他人该做什么。领导与协助占对话的 $$>。
- en: 'In contrast, when the team has a hierarchical organization the lead LLM agent
    would presume a dominant role and give orders to others (amount to $> of
    their communication), while other members tend to follow and give fewer orders
    compared with the disorganized case. (Figure [7](#S4.F7 $GPT-4 agents). The agents
    emerge three types of cooperative behaviors: information sharing, leadership &
    assistance, and request for guidance.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，当团队具有等级组织时，首席 LLM 代理会假设主导角色并对其他人下达命令（占其通信的$>），而其他成员则倾向于跟随，并与无序情况下相比，发出的命令较少。（图
    [7](#S4.F7 $GPT-4 agents)）。代理们展现出三种合作行为：信息共享、领导与协助，以及请求指导。
- en: '![Refer to caption](img/3ee813bf273b85b4b24351647ad68f69.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/3ee813bf273b85b4b24351647ad68f69.png)'
- en: 'Figure 7: Emergent cooperative behaviors of LLM agents. We analyzed the communication
    log of the mixture team (1$\times$GPT-3.5-turbo) and asked another GPT-4 to annotate
    agent’s cooperative behaviors. (a) Behavior of disorganized agents. (b) Behavior
    of a team led by a GPT-4 agent. (c) Behavior of a team led by a GPT-3.5-turbo
    agent.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：LLM 代理的涌现合作行为。我们分析了混合团队（1$\times$GPT-3.5-turbo）的通信日志，并请另一位 GPT-4 对代理的合作行为进行标注。（a）无序代理的行为。（b）由
    GPT-4 代理领导的团队的行为。（c）由 GPT-3.5-turbo 代理领导的团队的行为。
- en: 4.4 Novel Organizational Structures
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 新颖的组织结构
- en: Having evaluated the merits of different kinds of structures, we let the LLM
    propose novel organizational structures and iteratively refine the organization
    prompts using the Criticize-Reflect method discussed in Section 3 (see also Figure
    [3](#S3.F3 "Figure 3 ‣ 3.1 Architecture and Multi-Agent Communication ‣ 3 Method
    ‣ Embodied LLM Agents Learn to Cooperate in Organized Teams")).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估了不同结构的优点之后，我们让 LLM 提出新颖的组织结构，并使用第 3 节中讨论的 Criticize-Reflect 方法迭代地完善组织提示（参见图
    [3](#S3.F3 "图 3 ‣ 3.1 架构与多代理通信 ‣ 3 方法 ‣ 具象化的 LLM 代理学会在组织团队中合作")）。
- en: Figure [8](#S4.F8 "Figure 8 ‣ 4.4 Novel Organizational Structures ‣ 4 Main Results
    ‣ Embodied LLM Agents Learn to Cooperate in Organized Teams")(a) visualizes the
    reflection process. The system was initialized with a basic organization prompt,
    i.e., “Agent_1 as the leader to coordinate the task". As the Reflection process
    moves forward, the Coordinator generates a sequence of evolving organization prompts,
    picking up key words like “hierarchical" and “dynamic" that imply more complex
    team structures.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [8](#S4.F8 "图 8 ‣ 4.4 新颖的组织结构 ‣ 4 主要结果 ‣ 具象化的 LLM 代理学会在组织团队中合作")(a) 可视化了反思过程。系统以基本组织提示初始化，即“Agent_1
    作为领导协调任务”。随着反思过程的推进，协调员生成了一系列不断演变的组织提示，提取了诸如“等级”和“动态”等关键字，暗示了更复杂的团队结构。
- en: We compared the team’s performance before and after the Criticize-Reflect steps.
    Figure [8](#S4.F8 "Figure 8 ‣ 4.4 Novel Organizational Structures ‣ 4 Main Results
    ‣ Embodied LLM Agents Learn to Cooperate in Organized Teams")(b) illustrates the
    team’s efficiency. We observe that for 3$\times$GPT-3.5-turbo).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们比较了 Criticize-Reflect 步骤前后的团队表现。图 [8](#S4.F8 "图 8 ‣ 4.4 新颖的组织结构 ‣ 4 主要结果 ‣
    具象化的 LLM 代理学会在组织团队中合作")(b) 说明了团队的效率。我们观察到对于 3$\times$GPT-3.5-turbo。
- en: 'The Critic analyzes the records of action and dialogue, and performance metrics
    from the most recent episode. It provides evaluation for the full team’s trajectory,
    feedback to individual agents and their rankings. See below for an example of
    the Critic output:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 评论员分析最近一集的行动和对话记录以及绩效指标。它为整个团队的轨迹提供评估，向个人代理提供反馈和排名。以下是评论员输出的一个示例：
- en: '![[Uncaptioned image]](img/cd00c7d893a996136a40c658f1ce3b17.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![[未标注图片]](img/cd00c7d893a996136a40c658f1ce3b17.png)'
- en: As an ablation study, we removed the Critic from our architecture and only performed
    the Reflection step. The results are shown in Figure [8](#S4.F8 "Figure 8 ‣ 4.4
    Novel Organizational Structures ‣ 4 Main Results ‣ Embodied LLM Agents Learn to
    Cooperate in Organized Teams")(b), indicating that Reflection without the Critic
    leads to performance decline ($t(38)=1.96,p<.05$). In this case, the Coordinator
    needs to digest all dialogue history and generate a new organization prompt. This
    did not work well and led to rather vague outcomes, for example, “Establish a
    flexible communication network with rotating leadership roles assigned based on
    agents’ task-specific expertise to facilitate swift decision-making and reduce
    unnecessary communication steps.” This comparison highlights the role of the Critic
    and the importance of having a dual Criticize-Reflect architecture. For more results/prompts
    generated by the reflection process, please refer to Appendix [I](#A9 "Appendix
    I Examples of New Prompts after Reflection ‣ Embodied LLM Agents Learn to Cooperate
    in Organized Teams").
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一项消融研究，我们从架构中移除了批评者，仅执行了反思步骤。结果如图[8](#S4.F8 "Figure 8 ‣ 4.4 Novel Organizational
    Structures ‣ 4 Main Results ‣ Embodied LLM Agents Learn to Cooperate in Organized
    Teams")(b)所示，表明没有批评者的反思导致了性能下降（$t(38)=1.96,p<.05$）。在这种情况下，协调者需要消化所有对话历史并生成新的组织提示。这一方法效果不佳，导致了相当模糊的结果，例如，“建立一个灵活的沟通网络，通过基于代理的任务特定专业知识分配轮流领导角色，以促进迅速决策并减少不必要的沟通步骤。”
    这一比较突显了批评者的作用和双重批评-反思架构的重要性。有关反思过程生成的更多结果/提示，请参见附录[I](#A9 "Appendix I Examples
    of New Prompts after Reflection ‣ Embodied LLM Agents Learn to Cooperate in Organized
    Teams")。
- en: 'In addition, it is worth mentioning that LLMs are able to generate highly complex
    prompts that imply novel organizational structures that are rarely seen in human
    societies. We illustrate the communication patterns as team structures in Figure [9](#S4.F9
    "Figure 9 ‣ 4.4 Novel Organizational Structures ‣ 4 Main Results ‣ Embodied LLM
    Agents Learn to Cooperate in Organized Teams") together with the three novel structures
    proposed by Criticize-Reflect: (c) chain, (d) dual-leader, and (e) dynamic structures,
    which are the best structures of the three settings in Figure [8](#S4.F8 "Figure
    8 ‣ 4.4 Novel Organizational Structures ‣ 4 Main Results ‣ Embodied LLM Agents
    Learn to Cooperate in Organized Teams")(b, c) respectively.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，值得一提的是，LLM能够生成高度复杂的提示，这些提示暗示了在人的社会中很少见的新颖组织结构。我们在图[9](#S4.F9 "Figure 9 ‣
    4.4 Novel Organizational Structures ‣ 4 Main Results ‣ Embodied LLM Agents Learn
    to Cooperate in Organized Teams")中将通信模式作为团队结构进行说明，并展示了批评-反思提出的三种新颖结构：（c）链式，（d）双领导，以及（e）动态结构，它们是图[8](#S4.F8
    "Figure 8 ‣ 4.4 Novel Organizational Structures ‣ 4 Main Results ‣ Embodied LLM
    Agents Learn to Cooperate in Organized Teams")(b, c)中三种设置的最佳结构。
- en: Finally, to test the generalizability of the novel organizational structures,
    we pick the best novel prompt, the one illustrated in Figure [9](#S4.F9 $$).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了测试新颖组织结构的普遍性，我们选择了最佳的新颖提示，即图[9](#S4.F9 $$)中所示的提示。
- en: '![Refer to caption](img/b2b48c3bbf776a27292b44bba91a6c5d.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![请参见说明](img/b2b48c3bbf776a27292b44bba91a6c5d.png)'
- en: 'Figure 8: The reflection and improvement process for finding novel organizational
    structures. (a) The experiment was done using the 1$\times$GPT-3.5-turbo team.
    The organization prompt evolves during the iterations, and takes on additional
    keywords such as "central", "hierarchical", and "dynamic". (b) The confidence
    intervals are calculated over 20 seeds.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：寻找新颖组织结构的反思和改进过程。 (a) 实验使用了1$\times$GPT-3.5-turbo团队。组织提示在迭代过程中不断演变，并引入了“中央”、“层级”和“动态”等附加关键词。
    (b) 自信区间在20个种子上进行计算。
- en: '![Refer to caption](img/b0bfc553da8d0197dcde654730b61e15.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![请参见说明](img/b0bfc553da8d0197dcde654730b61e15.png)'
- en: 'Figure 9: Communication patterns and the corresponding organizational prompts
    for different team structures. (a) Team without organization prompts. (b) Team
    with a leader. (c) A team in the chain structure. (d) A dual-leader team. (e)
    A team with a dynamic leadership. (c, d, e) are proposed by LLM via Reflection.
    Red-robot nodes mark the lead agents, and other nodes are the followers. Edges
    mark the accumulated communication cost between the two nodes (darker edge means
    higher token costs).'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：不同团队结构的沟通模式和相应的组织提示。（a）没有组织提示的团队。（b）有领导者的团队。（c）链结构中的团队。（d）双领导者团队。（e）动态领导的团队。（c，d，e）由LLM通过反思提出。红色机器人节点标记了领导代理，其他节点是跟随者。边缘标记了两个节点之间的累积沟通成本（边缘越暗，令牌成本越高）。
- en: 5 Conclusion
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论
- en: We developed a novel multi-LLM-agent architecture to facilitate communication
    and organize the embodied agent teams for enhanced cooperation. Moreover, we proposed
    the Criticize-Reflect architecture based on LLMs to generate more efficient organizational
    prompts. Extensive experiments with various group settings and organizational
    structures demonstrate that a hierarchically-organized team with a designated/elected
    leader has superior team efficiency, which can be further improved by Criticize-Reflect.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开发了一种新型的多LLM-agent架构，以促进沟通并组织具身智能体团队以增强合作。此外，我们提出了基于LLM的Criticize-Reflect架构，以生成更高效的组织性提示。通过在各种小组设置和组织结构下进行的广泛实验表明，具有指定/选举领导者的分层组织团队具有更高的团队效率，而Criticize-Reflect可以进一步提高效率。
- en: The current work is performed in a single environment and lacks human evaluation.
    Future work shall expand the evaluation to a broader set of environments, allowing
    human evaluation and more complex human-AI collaboration.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 当前工作在单一环境中进行，缺乏人类评估。未来的工作将扩展到更广泛的环境，允许人类评估和更复杂的人机协作。
- en: Impact Statement
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 影响声明
- en: This research studies the integration of prompt-based organizational structures
    to teams of LLM agents, contributing to more efficient and coherent multi-agent
    interactions. These findings have the potential to greatly influence the deployment
    of more effective and autonomous multi-agent systems in various fields, including
    robotics, virtual assistants, etc. For example, the study has potential applications
    in disaster response scenarios, where efficient multi-agent coordination is crucial.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究探讨了基于提示的组织结构在LLM智能体团队中的集成，为更高效和连贯的多智能体互动做出了贡献。这些发现有潜力极大地影响各种领域中更有效和自主的多智能体系统的部署，包括机器人、虚拟助手等。例如，该研究在灾难响应场景中具有潜在应用，其中高效的多智能体协调至关重要。
- en: References
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Agashe et al. (2023) Saaket Agashe, Yue Fan, and Xin Eric Wang. Evaluating multi-agent
    coordination abilities in large language models. *arXiv preprint arXiv:2310.03903*,
    2023.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Agashe et al. (2023) Saaket Agashe, Yue Fan, 和 Xin Eric Wang. 评估大语言模型中的多智能体协调能力。*arXiv
    预印本 arXiv:2310.03903*，2023。
- en: Bai et al. (2022) Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna
    Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et al.
    Training a helpful and harmless assistant with reinforcement learning from human
    feedback. *arXiv preprint arXiv:2204.05862*, 2022.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bai et al. (2022) Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna
    Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan 等.
    通过人类反馈的强化学习训练一个有用且无害的助手。*arXiv 预印本 arXiv:2204.05862*，2022。
- en: Bolton and Dewatripont (1994) Patrick Bolton and Mathias Dewatripont. The firm
    as a communication network. *The Quarterly Journal of Economics*, 109(4):809–839,
    1994.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bolton 和 Dewatripont (1994) Patrick Bolton 和 Mathias Dewatripont. 公司作为沟通网络。*《季度经济学杂志》*，109(4):809–839，1994。
- en: 'Chen et al. (2023a) Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei
    Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, Zhiyuan Liu, Maosong
    Sun, and Jie Zhou. AgentVerse: Facilitating multi-agent collaboration and exploring
    emergent behaviors in agents. *arXiv preprint arXiv:2308.10848*, 2023a.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. (2023a) Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei
    Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, Zhiyuan Liu, Maosong
    Sun 和 Jie Zhou. AgentVerse：促进多智能体协作并探索智能体中的突现行为。*arXiv 预印本 arXiv:2308.10848*，2023a。
- en: 'Chen et al. (2023b) Yongchao Chen, Jacob Arkin, Yang Zhang, Nicholas Roy, and
    Chuchu Fan. Scalable multi-robot collaboration with large language models: Centralized
    or decentralized systems? *arXiv preprint arXiv:2309.15943*, 2023b.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. (2023b) Yongchao Chen, Jacob Arkin, Yang Zhang, Nicholas Roy, 和
    Chuchu Fan. 使用大语言模型的可扩展多机器人协作：集中式还是分散式系统？*arXiv 预印本 arXiv:2309.15943*，2023b。
- en: 'Chisholm (1992) Donald Chisholm. *Coordination without hierarchy: Informal
    structures in multiorganizational systems*. University of California Press, 1992.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chisholm (1992) Donald Chisholm。*没有层级的协调：多组织系统中的非正式结构*。加州大学出版社，1992。
- en: 'Das et al. (2019) Abhishek Das, Théophile Gervet, Joshua Romoff, Dhruv Batra,
    Devi Parikh, Mike Rabbat, and Joelle Pineau. Tarmac: Targeted multi-agent communication.
    In *International Conference on Machine Learning*, pages 1538–1546\. PMLR, 2019.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Das 等 (2019) Abhishek Das、Théophile Gervet、Joshua Romoff、Dhruv Batra、Devi Parikh、Mike
    Rabbat 和 Joelle Pineau。Tarmac：目标多智能体通信。发表于 *国际机器学习会议*，页面 1538–1546。PMLR，2019。
- en: Dodds et al. (2003) Peter Sheridan Dodds, Duncan J Watts, and Charles F Sabel.
    Information exchange and the robustness of organizational networks. *Proceedings
    of the National Academy of Sciences*, 100(21):12516–12521, 2003.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dodds 等 (2003) Peter Sheridan Dodds、Duncan J Watts 和 Charles F Sabel。信息交换与组织网络的稳健性。*美国国家科学院院刊*，100(21):12516–12521，2003。
- en: Foerster et al. (2016) Jakob Foerster, Ioannis Alexandros Assael, Nando de Freitas,
    and Shimon Whiteson. Learning to communicate with deep multi-agent reinforcement
    learning. In *Advances in Neural Information Processing Systems*, volume 29, 2016.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Foerster 等 (2016) Jakob Foerster、Ioannis Alexandros Assael、Nando de Freitas
    和 Shimon Whiteson。通过深度多智能体强化学习学习通信。发表于 *神经信息处理系统进展*，第 29 卷，2016。
- en: Gao et al. (2020) Tianyu Gao, Adam Fisch, and Danqi Chen. Making pre-trained
    language models better few-shot learners. *arXiv preprint arXiv:2012.15723*, 2020.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao 等 (2020) Tianyu Gao、Adam Fisch 和 Danqi Chen。使预训练语言模型成为更好的少样本学习者。*arXiv 预印本
    arXiv:2012.15723*，2020。
- en: Garicano (2000) Luis Garicano. Hierarchies and the organization of knowledge
    in production. *Journal of Political Economy*, 108(5):874–904, 2000.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Garicano (2000) Luis Garicano。层级结构与生产知识的组织。*政治经济学期刊*，108(5):874–904，2000。
- en: 'Gronauer and Diepold (2022) Sven Gronauer and Klaus Diepold. Multi-agent deep
    reinforcement learning: a survey. *Artificial Intelligence Review*, pages 1–49,
    2022.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gronauer 和 Diepold (2022) Sven Gronauer 和 Klaus Diepold。多智能体深度强化学习：综述。*人工智能评论*，页面
    1–49，2022。
- en: Guo et al. (2023) Xudong Guo, Daming Shi, and Wenhui Fan. Scalable communication
    for multi-agent reinforcement learning via transformer-based email mechanism.
    In *Proceedings of the Thirty-Second International Joint Conference on Artificial
    Intelligence, IJCAI-23*, pages 126–134, 2023.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo 等 (2023) Xudong Guo、Daming Shi 和 Wenhui Fan。通过基于变压器的电子邮件机制实现多智能体强化学习的可扩展通信。发表于
    *第三十二届国际人工智能联合会议（IJCAI-23）*，页面 126–134，2023。
- en: Hao et al. (2023a) Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang,
    Daisy Zhe Wang, and Zhiting Hu. Reasoning with language model is planning with
    world model. *arXiv preprint arXiv:2305.14992*, 2023a.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hao 等 (2023a) Shibo Hao、Yi Gu、Haodi Ma、Joshua Jiahua Hong、Zhen Wang、Daisy Zhe
    Wang 和 Zhiting Hu。与语言模型推理即用世界模型进行规划。*arXiv 预印本 arXiv:2305.14992*，2023a。
- en: 'Hao et al. (2023b) Shibo Hao, Tianyang Liu, Zhen Wang, and Zhiting Hu. Toolkengpt:
    Augmenting frozen language models with massive tools via tool embeddings. *arXiv
    preprint arXiv:2305.11554*, 2023b.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hao 等 (2023b) Shibo Hao、Tianyang Liu、Zhen Wang 和 Zhiting Hu。Toolkengpt：通过工具嵌入增强冻结语言模型。*arXiv
    预印本 arXiv:2305.11554*，2023b。
- en: 'Hong et al. (2023) Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin
    Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu
    Ran, Lingfeng Xiao, and Chenglin Wu. MetaGPT: Meta programming for multi-agent
    collaborative framework. *arXiv preprint arXiv:2308.00352*, 2023.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hong 等 (2023) Sirui Hong、Xiawu Zheng、Jonathan Chen、Yuheng Cheng、Jinlin Wang、Ceyao
    Zhang、Zili Wang、Steven Ka Shing Yau、Zijuan Lin、Liyang Zhou、Chenyu Ran、Lingfeng
    Xiao 和 Chenglin Wu。MetaGPT：用于多智能体协作框架的元编程。*arXiv 预印本 arXiv:2308.00352*，2023。
- en: Jaques et al. (2019) Natasha Jaques, Angeliki Lazaridou, Edward Hughes, Caglar
    Gulcehre, Pedro Ortega, DJ Strouse, Joel Z Leibo, and Nando De Freitas. Social
    influence as intrinsic motivation for multi-agent deep reinforcement learning.
    In *International conference on machine learning*, pages 3040–3049\. PMLR, 2019.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jaques 等 (2019) Natasha Jaques、Angeliki Lazaridou、Edward Hughes、Caglar Gulcehre、Pedro
    Ortega、DJ Strouse、Joel Z Leibo 和 Nando De Freitas。社会影响作为多智能体深度强化学习的内在动机。发表于 *国际机器学习会议*，页面
    3040–3049。PMLR，2019。
- en: 'Kim et al. (2020) Woojun Kim, Jongeui Park, and Youngchul Sung. Communication
    in multi-agent reinforcement learning: Intention sharing. In *International Conference
    on Learning Representations*, 2020.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim 等 (2020) Woojun Kim、Jongeui Park 和 Youngchul Sung。多智能体强化学习中的通信：意图共享。发表于
    *国际学习表征会议*，2020。
- en: Konda and Tsitsiklis (1999) Vijay Konda and John Tsitsiklis. Actor-critic algorithms.
    In *Advances in Neural Information Processing Systems*, volume 12, 1999.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Konda 和 Tsitsiklis (1999) Vijay Konda 和 John Tsitsiklis。演员-评论家算法。在 *神经信息处理系统进展*，第12卷，1999。
- en: Lester et al. (2021) Brian Lester, Rami Al-Rfou, and Noah Constant. The power
    of scale for parameter-efficient prompt tuning. *arXiv preprint arXiv:2104.08691*,
    2021.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lester 等 (2021) Brian Lester, Rami Al-Rfou 和 Noah Constant。规模效应在参数高效提示调整中的作用。*arXiv
    预印本 arXiv:2104.08691*，2021。
- en: 'Li et al. (2023a) Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii
    Khizbullin, and Bernard Ghanem. CAMEL: Communicative agents for ”mind” exploration
    of large language model society. In *Thirty-seventh Conference on Neural Information
    Processing Systems*, 2023a.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li 等 (2023a) Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin
    和 Bernard Ghanem。CAMEL: 用于大语言模型社会“心智”探索的交流代理。在 *第37届神经信息处理系统大会* 中，2023a。'
- en: Li et al. (2023b) Huao Li, Yu Quan Chong, Simon Stepputtis, Joseph Campbell,
    Dana Hughes, Michael Lewis, and Katia Sycara. Theory of mind for multi-agent collaboration
    via large language models. *arXiv preprint arXiv:2310.10701*, 2023b.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等 (2023b) Huao Li, Yu Quan Chong, Simon Stepputtis, Joseph Campbell, Dana
    Hughes, Michael Lewis 和 Katia Sycara。通过大型语言模型进行多智能体协作的心智理论。*arXiv 预印本 arXiv:2310.10701*，2023b。
- en: 'Li and Liang (2021) Xiang Lisa Li and Percy Liang. Prefix-tuning: Optimizing
    continuous prompts for generation. In Chengqing Zong, Fei Xia, Wenjie Li, and
    Roberto Navigli, editors, *Proceedings of the 59th Annual Meeting of the Association
    for Computational Linguistics and the 11th International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)*, pages 4582–4597, August 2021.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li 和 Liang (2021) Xiang Lisa Li 和 Percy Liang。Prefix-tuning: 优化生成任务的连续提示。在
    Chengqing Zong, Fei Xia, Wenjie Li 和 Roberto Navigli 主编的 *第59届计算语言学协会年会暨第11届国际自然语言处理联合会议论文集
    (第1卷：长篇论文)* 中，页面4582–4597，2021年8月。'
- en: Lin et al. (2021) Toru Lin, Jacob Huh, Christopher Stauffer, Ser Nam Lim, and
    Phillip Isola. Learning to ground multi-agent communication with autoencoders.
    In *Advances in Neural Information Processing Systems*, volume 34, pages 15230–15242,
    2021.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin 等 (2021) Toru Lin, Jacob Huh, Christopher Stauffer, Ser Nam Lim 和 Phillip
    Isola。学习使用自编码器为多智能体通信提供基础。在 *神经信息处理系统进展*，第34卷，页面15230–15242，2021。
- en: 'Liu et al. (2023a) Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape,
    Michele Bevilacqua, Fabio Petroni, and Percy Liang. Lost in the middle: How language
    models use long contexts. *arXiv preprint arXiv:2307.03172*, 2023a.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等 (2023a) Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele
    Bevilacqua, Fabio Petroni 和 Percy Liang。迷失在中间：语言模型如何使用长上下文。*arXiv 预印本 arXiv:2307.03172*，2023a。
- en: 'Liu et al. (2023b) Zijun Liu, Yanzhe Zhang, Peng Li, Yang Liu, and Diyi Yang.
    Dynamic LLM-agent network: An LLM-agent collaboration framework with agent team
    optimization. *arXiv preprint arXiv:2310.02170*, 2023b.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等 (2023b) Zijun Liu, Yanzhe Zhang, Peng Li, Yang Liu 和 Diyi Yang。动态LLM-agent网络：一种LLM-agent协作框架与代理团队优化。*arXiv
    预印本 arXiv:2310.02170*，2023b。
- en: Lowe et al. (2017) Ryan Lowe, Aviv Tamar, Jean Harb, OpenAI Pieter Abbeel, and
    Igor Mordatch. Multi-agent actor-critic for mixed cooperative-competitive environments.
    *Advances in neural information processing systems*, 30, 2017.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lowe 等 (2017) Ryan Lowe, Aviv Tamar, Jean Harb, OpenAI 的 Pieter Abbeel 和 Igor
    Mordatch。混合合作-竞争环境中的多智能体演员-评论家方法。*神经信息处理系统进展*，30，2017。
- en: Malone (2004) Thomas W Malone. *The future of work*. Harvard Business Review
    Press, 2004.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Malone (2004) Thomas W Malone。*工作的未来*。哈佛商业评论出版社，2004。
- en: 'Mandi et al. (2023) Zhao Mandi, Shreeya Jain, and Shuran Song. RoCo: Dialectic
    multi-robot collaboration with large language models. *arXiv preprint arXiv:2307.04738*,
    2023.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Mandi 等 (2023) Zhao Mandi, Shreeya Jain 和 Shuran Song。RoCo: 大型语言模型的辩证多机器人协作。*arXiv
    预印本 arXiv:2307.04738*，2023。'
- en: March and Simon (1958) James G March and Herbert A Simon. *Organizations*. Wiley,
    1958.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: March 和 Simon (1958) James G March 和 Herbert A Simon。*组织*。Wiley，1958。
- en: Oroojlooy and Hajinezhad (2023) Afshin Oroojlooy and Davood Hajinezhad. A review
    of cooperative multi-agent deep reinforcement learning. *Applied Intelligence*,
    53(11):13677–13722, 2023.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Oroojlooy 和 Hajinezhad (2023) Afshin Oroojlooy 和 Davood Hajinezhad。合作多智能体深度强化学习的综述。*Applied
    Intelligence*, 53(11):13677–13722, 2023。
- en: Ouyang et al. (2022) Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll
    Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex
    Ray, et al. Training language models to follow instructions with human feedback.
    *Advances in Neural Information Processing Systems*, 35:27730–27744, 2022.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 欧阳等人（2022）Long Ouyang、Jeffrey Wu、徐江、Diogo Almeida、Carroll Wainwright、Pamela
    Mishkin、Chong Zhang、Sandhini Agarwal、Katarina Slama、Alex Ray等。训练语言模型以通过人类反馈遵循指令。*《神经信息处理系统进展》*，35:27730–27744，2022年。
- en: 'Park et al. (2023) Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S Bernstein. Generative agents: Interactive simulacra
    of human behavior. In *Proceedings of the 36th Annual ACM Symposium on User Interface
    Software and Technology*, pages 1–22, 2023.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park等人（2023）Joon Sung Park、Joseph O’Brien、Carrie Jun Cai、Meredith Ringel Morris、Percy
    Liang和Michael S Bernstein。生成代理：人类行为的互动模拟体。在*《第36届ACM用户界面软件与技术年会论文集》*，第1–22页，2023年。
- en: 'Patil et al. (2023) Shishir G Patil, Tianjun Zhang, Xin Wang, and Joseph E
    Gonzalez. Gorilla: Large language model connected with massive apis. *arXiv preprint
    arXiv:2305.15334*, 2023.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Patil等人（2023）Shishir G Patil、Tianjun Zhang、Xin Wang和Joseph E Gonzalez。Gorilla：与大量API连接的大型语言模型。*arXiv预印本
    arXiv:2305.15334*，2023年。
- en: Pryzant et al. (2023) Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang
    Zhu, and Michael Zeng. Automatic prompt optimization with "gradient descent" and
    beam search. *arXiv preprint arXiv:2305.03495*, 2023.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pryzant等人（2023）Reid Pryzant、Dan Iter、Jerry Li、Yin Tat Lee、Chenguang Zhu和Michael
    Zeng。通过“梯度下降”和束搜索的自动提示优化。*arXiv预印本 arXiv:2305.03495*，2023年。
- en: 'Puig et al. (2018) Xavier Puig, Kevin Ra, Marko Boben, Jiaman Li, Tingwu Wang,
    Sanja Fidler, and Antonio Torralba. Virtualhome: Simulating household activities
    via programs. In *Proceedings of the IEEE Conference on Computer Vision and Pattern
    Recognition*, pages 8494–8502, 2018.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Puig等人（2018）Xavier Puig、Kevin Ra、Marko Boben、Jiaman Li、Tingwu Wang、Sanja Fidler和Antonio
    Torralba。Virtualhome：通过程序模拟家庭活动。在*《IEEE计算机视觉与模式识别会议论文集》*，第8494–8502页，2018年。
- en: 'Puig et al. (2021) Xavier Puig, Tianmin Shu, Shuang Li, Zilin Wang, Yuan-Hong
    Liao, Joshua B. Tenenbaum, Sanja Fidler, and Antonio Torralba. Watch-and-help:
    A challenge for social perception and human-AI collaboration. *arXiv preprint
    arXiv:2010.09890*, 2021.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Puig等人（2021）Xavier Puig、Tianmin Shu、Shuang Li、Zilin Wang、Yuan-Hong Liao、Joshua
    B. Tenenbaum、Sanja Fidler和Antonio Torralba。观看并帮助：社会感知和人类-AI协作的挑战。*arXiv预印本 arXiv:2010.09890*，2021年。
- en: Qi et al. (2023) Xiangyu Qi, Kaixuan Huang, Ashwinee Panda, Mengdi Wang, and
    Prateek Mittal. Visual adversarial examples jailbreak aligned large language models.
    In *The Second Workshop on New Frontiers in Adversarial Machine Learning*, 2023.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qi等人（2023）Xiangyu Qi、Kaixuan Huang、Ashwinee Panda、Mengdi Wang和Prateek Mittal。视觉对抗示例破解对齐的大型语言模型。在*《第二届对抗机器学习新前沿研讨会》*，2023年。
- en: 'Radner (1993) Roy Radner. The organization of decentralized information processing.
    *Econometrica: Journal of the Econometric Society*, pages 1109–1146, 1993.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Radner（1993）Roy Radner。去中心化信息处理的组织。*《计量经济学期刊：计量经济学学会》*，第1109–1146页，1993年。
- en: 'Resnick et al. (2018) Cinjon Resnick, Wes Eldridge, David Ha, Denny Britz,
    Jakob Foerster, Julian Togelius, Kyunghyun Cho, and Joan Bruna. Pommerman: A multi-agent
    playground. *arXiv preprint arXiv:1809.07124*, 2018.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Resnick等人（2018）Cinjon Resnick、Wes Eldridge、David Ha、Denny Britz、Jakob Foerster、Julian
    Togelius、Kyunghyun Cho和Joan Bruna。Pommerman：一个多智能体的游乐场。*arXiv预印本 arXiv:1809.07124*，2018年。
- en: Samvelyan et al. (2019) Mikayel Samvelyan, Tabish Rashid, Christian Schroeder de
    Witt, Gregory Farquhar, Nantas Nardelli, Tim GJ Rudner, Chia-Man Hung, Philip HS
    Torr, Jakob Foerster, and Shimon Whiteson. The starcraft multi-agent challenge.
    In *Proceedings of the 18th International Conference on Autonomous Agents and
    MultiAgent Systems*, pages 2186–2188, 2019.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Samvelyan等人（2019）Mikayel Samvelyan、Tabish Rashid、Christian Schroeder de Witt、Gregory
    Farquhar、Nantas Nardelli、Tim GJ Rudner、Chia-Man Hung、Philip HS Torr、Jakob Foerster和Shimon
    Whiteson。Starcraft多智能体挑战。在*《第18届国际自主代理与多智能体系统会议论文集》*，第2186–2188页，2019年。
- en: 'Shen et al. (2023) Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming
    Lu, and Yueting Zhuang. Hugginggpt: Solving ai tasks with chatgpt and its friends
    in huggingface. *arXiv preprint arXiv:2303.17580*, 2023.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen等人（2023）Yongliang Shen、Kaitao Song、Xu Tan、Dongsheng Li、Weiming Lu和Yueting
    Zhuang。Hugginggpt：利用chatgpt及其在huggingface中的朋友解决AI任务。*arXiv预印本 arXiv:2303.17580*，2023年。
- en: Shi et al. (2023) Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David
    Dohan, Ed H Chi, Nathanael Schärli, and Denny Zhou. Large language models can
    be easily distracted by irrelevant context. In *International Conference on Machine
    Learning*, pages 31210–31227\. PMLR, 2023.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi et al. (2023) Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David
    Dohan, Ed H Chi, Nathanael Schärli 和 Denny Zhou. 大型语言模型容易被无关的上下文分散注意力。载于 *国际机器学习会议*，页码
    31210–31227。PMLR，2023年。
- en: 'Shin et al. (2020) Taylor Shin, Yasaman Razeghi, Robert L Logan IV, Eric Wallace,
    and Sameer Singh. Autoprompt: Eliciting knowledge from language models with automatically
    generated prompts. *arXiv preprint arXiv:2010.15980*, 2020.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shin et al. (2020) Taylor Shin, Yasaman Razeghi, Robert L Logan IV, Eric Wallace
    和 Sameer Singh. Autoprompt：通过自动生成的提示从语言模型中引出知识。*arXiv 预印本 arXiv:2010.15980*，2020年。
- en: 'Shinn et al. (2023) Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik R
    Narasimhan, and Shunyu Yao. Reflexion: Language agents with verbal reinforcement
    learning. In *Thirty-seventh Conference on Neural Information Processing Systems*,
    2023.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shinn et al. (2023) Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik R
    Narasimhan 和 Shunyu Yao. Reflexion：具有语言强化学习的语言代理。载于 *第三十七届神经信息处理系统会议*，2023年。
- en: Simon et al. (1971) Herbert A Simon et al. Designing organizations for an information-rich
    world. *Computers, communications, and the public interest*, 72:37, 1971.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Simon et al. (1971) Herbert A Simon 等. 为信息丰富的世界设计组织。*计算机、通信与公众利益*，72:37，1971年。
- en: 'Sun et al. (2023) Haotian Sun, Yuchen Zhuang, Lingkai Kong, Bo Dai, and Chao
    Zhang. Adaplanner: Adaptive planning from feedback with language models. *arXiv
    preprint arXiv:2305.16653*, 2023.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun et al. (2023) Haotian Sun, Yuchen Zhuang, Lingkai Kong, Bo Dai 和 Chao Zhang.
    Adaplanner：基于语言模型的反馈自适应规划。*arXiv 预印本 arXiv:2305.16653*，2023年。
- en: 'Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. *arXiv
    preprint arXiv:2307.09288*, 2023.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale 等. Llama 2：开放基础和微调的聊天模型。*arXiv 预印本 arXiv:2307.09288*，2023年。
- en: 'Van Zandt (1999) Timothy Van Zandt. Decentralized information processing in
    the theory of organizations. In *Contemporary Economic Issues: Economic Behaviour
    and Design*, pages 125–160\. Springer, 1999.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Van Zandt (1999) Timothy Van Zandt. 组织理论中的去中心化信息处理。载于 *当代经济问题：经济行为与设计*，页码 125–160。Springer，1999年。
- en: Vélez et al. (2023) Natalia Vélez, Brian Christian, Mathew Hardy, Bill D Thompson,
    and Thomas L Griffiths. How do humans overcome individual computational limitations
    by working together? *Cognitive Science*, 47(1):e13232, 2023.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vélez et al. (2023) Natalia Vélez, Brian Christian, Mathew Hardy, Bill D Thompson
    和 Thomas L Griffiths. 人类如何通过协作克服个体计算限制？*认知科学*，47(1):e13232，2023年。
- en: Vinyals et al. (2019) Oriol Vinyals, Igor Babuschkin, Wojciech M. Czarnecki,
    Michaël Mathieu, Andrew Dudzik, Junyoung Chung, David H. Choi, Richard Powell,
    Timo Ewalds, Petko Georgiev, Junhyuk Oh, Dan Horgan, Manuel Kroiss, Ivo Danihelka,
    Aja Huang, Laurent Sifre, Trevor Cai, John P. Agapiou, Max Jaderberg, Alexander S.
    Vezhnevets, Rémi Leblond, Tobias Pohlen, Valentin Dalibard, David Budden, Yury
    Sulsky, James Molloy, Tom L. Paine, Caglar Gulcehre, Ziyu Wang, Tobias Pfaff,
    Yuhuai Wu, Roman Ring, Dani Yogatama, Dario Wünsch, Katrina McKinney, Oliver Smith,
    Tom Schaul, Timothy Lillicrap, Koray Kavukcuoglu, Demis Hassabis, Chris Apps,
    and David Silver. Grandmaster level in StarCraft II using multi-agent reinforcement
    learning. *Nature*, 575(7782):350–354, 2019.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vinyals et al. (2019) Oriol Vinyals, Igor Babuschkin, Wojciech M. Czarnecki,
    Michaël Mathieu, Andrew Dudzik, Junyoung Chung, David H. Choi, Richard Powell,
    Timo Ewalds, Petko Georgiev, Junhyuk Oh, Dan Horgan, Manuel Kroiss, Ivo Danihelka,
    Aja Huang, Laurent Sifre, Trevor Cai, John P. Agapiou, Max Jaderberg, Alexander
    S. Vezhnevets, Rémi Leblond, Tobias Pohlen, Valentin Dalibard, David Budden, Yury
    Sulsky, James Molloy, Tom L. Paine, Caglar Gulcehre, Ziyu Wang, Tobias Pfaff,
    Yuhuai Wu, Roman Ring, Dani Yogatama, Dario Wünsch, Katrina McKinney, Oliver Smith,
    Tom Schaul, Timothy Lillicrap, Koray Kavukcuoglu, Demis Hassabis, Chris Apps 和
    David Silver. 使用多智能体强化学习在《星际争霸 II》中达到大师级别。*自然*，575(7782):350–354，2019年。
- en: 'Wang et al. (2023) Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei
    Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. Voyager: An open-ended embodied
    agent with large language models. *arXiv preprint arXiv:2305.16291*, 2023.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. (2023) Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei
    Xiao, Yuke Zhu, Linxi Fan 和 Anima Anandkumar. Voyager：一个开放式的具身智能体，结合大型语言模型。*arXiv
    预印本 arXiv:2305.16291*，2023年。
- en: Wang et al. (2020) Jiawei Wang, Tianyu Shi, Yuankai Wu, Luis Miranda-Moreno,
    and Lijun Sun. Multi-agent graph reinforcement learning for connected automated
    driving. In *Proceedings of the 37th International Conference on Machine Learning
    (ICML)*, pages 1–6, 2020.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等（2020）Jiawei Wang, Tianyu Shi, Yuankai Wu, Luis Miranda-Moreno, 和 Lijun
    Sun. 多智能体图强化学习用于联网自动驾驶。在*第37届国际机器学习会议（ICML）论文集*，第1–6页，2020。
- en: Wang et al. (2021) Lu Wang, Lei Han, Xinru Chen, Chengchang Li, Junzhou Huang,
    Weinan Zhang, Wei Zhang, Xiaofeng He, and Dijun Luo. Hierarchical multiagent reinforcement
    learning for allocating guaranteed display ads. *IEEE Transactions on Neural Networks
    and Learning Systems*, pages 1–13, 2021.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等（2021）Lu Wang, Lei Han, Xinru Chen, Chengchang Li, Junzhou Huang, Weinan
    Zhang, Wei Zhang, Xiaofeng He, 和 Dijun Luo. 分层多智能体强化学习用于分配保证展示广告。*IEEE神经网络与学习系统汇刊*，第1–13页，2021。
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei
    Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits
    reasoning in large language models. *Advances in Neural Information Processing
    Systems*, 35:24824–24837, 2022.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei等（2022）Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed
    Chi, Quoc V Le, Denny Zhou, 等等. 思维链提示引发大型语言模型中的推理。*神经信息处理系统进展*，35:24824–24837，2022。
- en: 'Wu et al. (2023) Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang,
    Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. Autogen: Enabling
    next-gen llm applications via multi-agent conversation framework. *arXiv preprint
    arXiv:2308.08155*, 2023.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wu等（2023）Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang
    Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, 和 Chi Wang. Autogen: 通过多智能体对话框架实现下一代LLM应用。*arXiv预印本
    arXiv:2308.08155*，2023。'
- en: Xu et al. (2023) Zelai Xu, Chao Yu, Fei Fang, Yu Wang, and Yi Wu. Language agents
    with reinforcement learning for strategic play in the werewolf game. *arXiv preprint
    arXiv:2310.18940*, 2023.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu等（2023）Zelai Xu, Chao Yu, Fei Fang, Yu Wang, 和 Yi Wu. 语言智能体与强化学习在狼人游戏中的策略性玩法。*arXiv预印本
    arXiv:2310.18940*，2023。
- en: Yang et al. (2023) Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V
    Le, Denny Zhou, and Xinyun Chen. Large language models as optimizers. *arXiv preprint
    arXiv:2309.03409*, 2023.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang等（2023）Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V Le, Denny
    Zhou, 和 Xinyun Chen. 大型语言模型作为优化器。*arXiv预印本 arXiv:2309.03409*，2023。
- en: 'Yao et al. (2022) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language
    models. *arXiv preprint arXiv:2210.03629*, 2022.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yao等（2022）Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik
    Narasimhan, 和 Yuan Cao. React: 在语言模型中协同推理与行动。*arXiv预印本 arXiv:2210.03629*，2022。'
- en: 'Zhang et al. (2023a) Bin Zhang, Hangyu Mao, Jingqing Ruan, Ying Wen, Yang Li,
    Shao Zhang, Zhiwei Xu, Dapeng Li, Ziyue Li, Rui Zhao, et al. Controlling large
    language model-based agents for large-scale decision-making: An actor-critic approach.
    *arXiv preprint arXiv:2311.13884*, 2023a.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang等（2023a）Bin Zhang, Hangyu Mao, Jingqing Ruan, Ying Wen, Yang Li, Shao Zhang,
    Zhiwei Xu, Dapeng Li, Ziyue Li, Rui Zhao, 等等. 控制基于大型语言模型的智能体进行大规模决策：一种演员-评论家方法。*arXiv预印本
    arXiv:2311.13884*，2023a。
- en: 'Zhang et al. (2023b) Ceyao Zhang, Kaijie Yang, Siyi Hu, Zihao Wang, Guanghe
    Li, Yihang Sun, Cheng Zhang, Zhaowei Zhang, Anji Liu, Song-Chun Zhu, Xiaojun Chang,
    Junge Zhang, Feng Yin, Yitao Liang, and Yaodong Yang. ProAgent: Building proactive
    cooperative AI with large language models. *arXiv preprint arXiv:2308.11339*,
    2023b.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang等（2023b）Ceyao Zhang, Kaijie Yang, Siyi Hu, Zihao Wang, Guanghe Li, Yihang
    Sun, Cheng Zhang, Zhaowei Zhang, Anji Liu, Song-Chun Zhu, Xiaojun Chang, Junge
    Zhang, Feng Yin, Yitao Liang, 和 Yaodong Yang. ProAgent: 利用大型语言模型构建主动合作AI。*arXiv预印本
    arXiv:2308.11339*，2023b。'
- en: Zhang et al. (2023c) Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun
    Du, Joshua B. Tenenbaum, Tianmin Shu, and Chuang Gan. Building cooperative embodied
    agents modularly with large language models. *arXiv preprint arXiv:2307.02485*,
    2023c.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang等（2023c）Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du,
    Joshua B. Tenenbaum, Tianmin Shu, 和 Chuang Gan. 模块化地利用大型语言模型构建合作体感智能体。*arXiv预印本
    arXiv:2307.02485*，2023c。
- en: 'Zhang et al. (2019a) Huichu Zhang, Siyuan Feng, Chang Liu, Yaoyao Ding, Yichen
    Zhu, Zihan Zhou, Weinan Zhang, Yong Yu, Haiming Jin, and Zhenhui Li. CityFlow:
    A multi-agent reinforcement learning environment for large scale city traffic
    scenario. In *The World Wide Web Conference*, pages 3620–3624\. ACM, 2019a.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang等（2019a）Huichu Zhang, Siyuan Feng, Chang Liu, Yaoyao Ding, Yichen Zhu,
    Zihan Zhou, Weinan Zhang, Yong Yu, Haiming Jin, 和 Zhenhui Li. CityFlow: 大规模城市交通场景的多智能体强化学习环境。在*万维网会议*，第3620–3624页，ACM，2019a。'
- en: 'Zhang et al. (2023d) Jintian Zhang, Xin Xu, and Shumin Deng. Exploring collaboration
    mechanisms for llm agents: A social psychology view. *arXiv preprint arXiv:2310.02124*,
    2023d.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等（2023d）Jintian Zhang、Xin Xu 和 Shumin Deng。探索 llm 代理的协作机制：社会心理学视角。*arXiv
    预印本 arXiv:2310.02124*，2023d。
- en: 'Zhang et al. (2021) Kaiqing Zhang, Zhuoran Yang, and Tamer Başar. Multi-agent
    reinforcement learning: A selective overview of theories and algorithms. *Handbook
    of reinforcement learning and control*, pages 321–384, 2021.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等（2021）Kaiqing Zhang、Zhuoran Yang 和 Tamer Başar。多智能体强化学习：理论和算法的选择性概述。*强化学习与控制手册*，第321–384页，2021。
- en: Zhang et al. (2019b) Sai Qian Zhang, Qi Zhang, and Jieyu Lin. Efficient communication
    in multi-agent reinforcement learning via variance based control. In *Advances
    in Neural Information Processing Systems*, volume 32, 2019b.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等（2019b）Sai Qian Zhang、Qi Zhang 和 Jieyu Lin。通过基于方差的控制实现多智能体强化学习中的高效通信。见于
    *神经信息处理系统进展*，第32卷，2019b。
- en: 'Zheng et al. (2023) Yi Zheng, Chongyang Ma, Kanle Shi, and Haibin Huang. Agents
    meet okr: An object and key results driven agent system with hierarchical self-collaboration
    and self-evaluation. *arXiv preprint arXiv:2311.16542*, 2023.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng 等（2023）Yi Zheng、Chongyang Ma、Kanle Shi 和 Haibin Huang。代理遇到 OKR：一个以目标和关键结果驱动的代理系统，具有层级自协作和自评估。*arXiv
    预印本 arXiv:2311.16542*，2023。
- en: Zhou et al. (2022a) Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan
    Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, et al.
    Least-to-most prompting enables complex reasoning in large language models. *arXiv
    preprint arXiv:2205.10625*, 2022a.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou 等（2022a）Denny Zhou、Nathanael Schärli、Le Hou、Jason Wei、Nathan Scales、Xuezhi
    Wang、Dale Schuurmans、Claire Cui、Olivier Bousquet、Quoc Le 等。最少到最多的提示使大型语言模型能够进行复杂推理。*arXiv
    预印本 arXiv:2205.10625*，2022a。
- en: Zhou et al. (2022b) Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster,
    Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level
    prompt engineers. *arXiv preprint arXiv:2211.01910*, 2022b.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou 等（2022b）Yongchao Zhou、Andrei Ioan Muresanu、Ziwen Han、Keiran Paster、Silviu
    Pitis、Harris Chan 和 Jimmy Ba。大型语言模型是人类级别的提示工程师。*arXiv 预印本 arXiv:2211.01910*，2022b。
- en: 'Zhu et al. (2023) Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su,
    Chenyu Yang, Gao Huang, Bin Li, Lewei Lu, Xiaogang Wang, et al. Ghost in the minecraft:
    Generally capable agents for open-world enviroments via large language models
    with text-based knowledge and memory. *arXiv preprint arXiv:2305.17144*, 2023.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu 等（2023）Xizhou Zhu、Yuntao Chen、Hao Tian、Chenxin Tao、Weijie Su、Chenyu Yang、Gao
    Huang、Bin Li、Lewei Lu、Xiaogang Wang 等。Minecraft 中的幽灵：通过具有基于文本的知识和记忆的大型语言模型实现对开放世界环境的普遍能力。*arXiv
    预印本 arXiv:2305.17144*，2023。
- en: Zou et al. (2023) Andy Zou, Zifan Wang, J Zico Kolter, and Matt Fredrikson.
    Universal and transferable adversarial attacks on aligned language models. *arXiv
    preprint arXiv:2307.15043*, 2023.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zou 等（2023）Andy Zou、Zifan Wang、J Zico Kolter 和 Matt Fredrikson。对对齐语言模型的通用和可转移对抗攻击。*arXiv
    预印本 arXiv:2307.15043*，2023。
- en: Appendix A Prompt Templates
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 提示模板
- en: We list the prompts of Actor, Communicator, Critic, and Coordinator as follows.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们列出了 Actor、Communicator、Critic 和 Coordinator 的提示如下。
- en: Actor and the Communicator. ORGANIZATION_INSTRUCTION is the placeholder for
    the organization instruction prompt, either manually designed or automatically
    generated. The environment will provide text descriptions for the current GOAL,
    PROGRESS, and AVAILABLE_ACTIONS. We include the latest $12$ steps of actions as
    ACTION_HISTORY.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: Actor 和 Communicator。ORGANIZATION_INSTRUCTION 是组织指令提示的占位符，无论是手动设计还是自动生成。环境将提供关于当前
    GOAL、PROGRESS 和 AVAILABLE_ACTIONS 的文本描述。我们包括了最新的 $12$ 步操作作为 ACTION_HISTORY。
- en: '![[Uncaptioned image]](img/8ea4fa7ef42c8ea3c23608e17af42353.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![[未说明的图像]](img/8ea4fa7ef42c8ea3c23608e17af42353.png)'
- en: '![[Uncaptioned image]](img/bfa009e0abcccfdcadaf3c11a160ac8a.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![[未说明的图像]](img/bfa009e0abcccfdcadaf3c11a160ac8a.png)'
- en: Critic. We provide the full trajectory as the input to TRAJECTORIES. Additionally,
    ORGANIZATION_INSTRUCTION and GOAL of the current task and organization are also
    provided as an additional context.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: Critic。我们将完整的轨迹提供给 TRAJECTORIES。此外，当前任务和组织的 ORGANIZATION_INSTRUCTION 和 GOAL
    也作为附加上下文提供。
- en: '![[Uncaptioned image]](img/c4daa3bf09d28016620353ff97a09ea3.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![[未说明的图像]](img/c4daa3bf09d28016620353ff97a09ea3.png)'
- en: Coordinator. In “Instruction examples”, we include the basic setting (goal,
    organization structure instruction), the communication cost, the number of steps
    taken, as well as the summarized information generated by the Critic (leadership
    ranking, problems, summary of the trajectory) for the Coordinator.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 协调员。在“指令示例”中，我们包括了基本设置（目标、组织结构指令）、通信成本、步骤数量以及由 Critic（领导力排名、问题、轨迹总结）生成的总结信息。
- en: '![[Uncaptioned image]](img/ee391781f1db561ab2af77dfcb5086c2.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![[无标题图片]](img/ee391781f1db561ab2af77dfcb5086c2.png)'
- en: Classifier. We feed the messages to the GPT-4 classifier and get the labels.
    The rubrics are manually written after investigating the communication logs.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器。我们将消息输入到 GPT-4 分类器中以获取标签。这些评分标准是在调查通信记录后手动编写的。
- en: '![[Uncaptioned image]](img/77a4b37d04dd659b753e2de61b8107ad.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![[无标题图片]](img/77a4b37d04dd659b753e2de61b8107ad.png)'
- en: Appendix B Additional Results
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 额外结果
- en: B.1 Complete list of basic experimental results
  id: totrans-182
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.1 基本实验结果完整列表
- en: We present the full results of various group settings and organization instructions
    in Appendix Table [1](#A2.T1 "Table 1 ‣ B.1 Complete list of basic experimental
    results ‣ Appendix B Additional Results ‣ Embodied LLM Agents Learn to Cooperate
    in Organized Teams"). Here, we also include the results of 1$\times$Llama2-70B.
    Surprisingly, GPT-4 exhibits poorer leadership than Llama2-70B in this case. The
    communication costs for the teams containing Llama2-70B are much higher than those
    containing GPT-3.5-turbo.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在附录表 [1](#A2.T1 "Table 1 ‣ B.1 Complete list of basic experimental results
    ‣ Appendix B Additional Results ‣ Embodied LLM Agents Learn to Cooperate in Organized
    Teams") 中展示了各种组设置和组织指令的完整结果。在这里，我们还包括了 1$\times$Llama2-70B 的结果。令人惊讶的是，在这种情况下，GPT-4
    的领导力表现不如 Llama2-70B。包含 Llama2-70B 的团队的通信成本远高于包含 GPT-3.5-turbo 的团队。
- en: 'Table 1: Performance for different organization instructions. When there are
    two different kinds of LLMs in the group, Agent_1 is GPT-4, and Agent_2 is the
    other type of LLM.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：不同组织指令的表现。当组内有两种不同类型的 LLM 时，Agent_1 是 GPT-4，Agent_2 是另一种 LLM。
- en: Group setting Organization instruction Time Communication cost 3$\times$2.51
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 组设置 组织指令 时间 通信成本 3$\times$2.51
- en: B.2 Across Task Generalizability
  id: totrans-186
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.2 跨任务泛化能力
- en: We conduct experiments across the tasks to test the generalizability of the
    prompt “dynamic leadership” (Figure [9](#S4.F9 "Figure 9 ‣ 4.4 Novel Organizational
    Structures ‣ 4 Main Results ‣ Embodied LLM Agents Learn to Cooperate in Organized
    Teams")(e)) found using Criticize-Reflect architecture on the Prepare_Afternoon_Tea
    task and report the performance in Figure [10](#A2.F10 "Figure 10 ‣ B.2 Across
    Task Generalizability ‣ Appendix B Additional Results ‣ Embodied LLM Agents Learn
    to Cooperate in Organized Teams"); see Section [4.4](#S4.SS4 "4.4 Novel Organizational
    Structures ‣ 4 Main Results ‣ Embodied LLM Agents Learn to Cooperate in Organized
    Teams") for the complete setting and discussions.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在任务间进行实验，以测试“动态领导力”提示的泛化能力（见图 [9](#S4.F9 "Figure 9 ‣ 4.4 Novel Organizational
    Structures ‣ 4 Main Results ‣ Embodied LLM Agents Learn to Cooperate in Organized
    Teams")(e)），该提示是使用 Criticize-Reflect 架构在 Prepare_Afternoon_Tea 任务中发现的，并在图 [10](#A2.F10
    "Figure 10 ‣ B.2 Across Task Generalizability ‣ Appendix B Additional Results
    ‣ Embodied LLM Agents Learn to Cooperate in Organized Teams") 中报告了其性能；完整的设置和讨论请参见第 [4.4](#S4.SS4
    "4.4 Novel Organizational Structures ‣ 4 Main Results ‣ Embodied LLM Agents Learn
    to Cooperate in Organized Teams") 节。
- en: '![Refer to caption](img/7306404984be22da0289e47d952a965e.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/7306404984be22da0289e47d952a965e.png)'
- en: 'Figure 10: The organized team structure with a designated leader and the novel
    structure proposed by Criticize-Reflect architecture generalized to different
    tasks. The prompt for dynamic leadership is proposed by Criticize-Reflect architecture
    on the Prepare_Afternoon_Tea task shown in Figure [8](#S4.F8 "Figure 8 ‣ 4.4 Novel
    Organizational Structures ‣ 4 Main Results ‣ Embodied LLM Agents Learn to Cooperate
    in Organized Teams")(a). The experiment was done using the 1$\times$.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：具有指定领导者的组织团队结构及 Criticize-Reflect 架构提出的适用于不同任务的新结构。动态领导力的提示是由 Criticize-Reflect
    架构在图 [8](#S4.F8 "Figure 8 ‣ 4.4 Novel Organizational Structures ‣ 4 Main Results
    ‣ Embodied LLM Agents Learn to Cooperate in Organized Teams")(a) 中的 Prepare_Afternoon_Tea
    任务提出的。实验使用了 1$\times$。
- en: Appendix C Emergent Cooperative Behaviors in an Organization
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 C 组织中的新兴合作行为
- en: By investigating the messages between agents, we mainly observe the following
    cooperative behaviors, as summarized in Table [2](#A3.T2 "Table 2 ‣ Appendix C
    Emergent Cooperative Behaviors in an Organization ‣ Embodied LLM Agents Learn
    to Cooperate in Organized Teams").
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调查代理人之间的消息，我们主要观察到以下合作行为，如表[2](#A3.T2 "表 2 ‣ 附录 C 组织中的新兴合作行为 ‣ 具身 LLM 代理学习如何在有组织的团队中合作")中总结。
- en: 'Table 2: Typical cooperative behaviors.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '表 2: 典型的合作行为。'
- en: Type Description Example Sharing information An agent shares her observations
    to others, reports her task-related progress to others, or responds to other agents’
    requests (Ex 1.)“I’m in the bathroom. There’s an unchecked $<$ (190).”
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 类型 描述 示例 分享信息 一个代理人将她的观察结果与其他人分享，报告她与任务相关的进展，或回应其他代理人的请求 (Ex 1.)“我在浴室。还有一个未检查的$<$
    (190)。”
- en: (Ex 2.) “I’ll check the cabinet in the bedroom ” Giving orders An agent gives
    orders to others, either by directly giving a command or by a polite request “I
    still need to find $<$ (371). Can you help me search the bedroom for the remaining
    item?” Asking for information An agent asks other agents about their location,
    task progress, or other information (Ex 1.) “Where are you now?”
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: (Ex 2.) “我去检查卧室的橱柜。” 发出命令 一个代理人通过直接下达命令或礼貌要求来给其他人下命令 “我还需要找到$<$ (371)。你能帮我在卧室寻找剩下的物品吗？”
    询问信息 一个代理人询问其他代理人的位置、任务进展或其他信息 (Ex 1.) “你现在在哪里？”
- en: (Ex 2.) “Any updates from the kitchen?”
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: (Ex 2.) “厨房有更新吗？”
- en: '(Ex 3.) “Do we know the location of the coffeetable?” Exchanging information
    An agent shares one agent’s information to another agent Agent 3 $\to$ Agent 1:
    “ Found cupcake and juice in bedroom, plus a wine. ”;'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '(Ex 3.) “我们知道咖啡桌的位置吗？” 交换信息 一个代理人与另一个代理人分享一个代理人的信息 代理人 3 $\to$ 代理人 1: “在卧室找到杯子蛋糕和果汁，还有一瓶酒。”；'
- en: 'Agent 1 $\to$ Agent 2: “You don’t need to search the bedroom, the juice (380)
    is there. ”'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '代理人 1 $\to$ 代理人 2: “你不需要搜索卧室，果汁 (380) 就在那里。”'
- en: (Ex 2.) “There are no more wine or juice in the kitchen cabinets. We need to
    come up with another plan.”
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: (Ex 2.) “厨房橱柜里没有更多的酒或果汁了。我们需要想出另一个计划。”
- en: Appendix D Ineffective Communication
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 D 无效沟通
- en: There are also cases in which language model agents fail to communicate efficiently.
    From the messages between agents, we summarize the typical categories in Table [3](#A4.T3
    "Table 3 ‣ Appendix D Ineffective Communication ‣ Embodied LLM Agents Learn to
    Cooperate in Organized Teams").
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 也有语言模型代理无法高效沟通的情况。从代理人之间的消息中，我们在表[3](#A4.T3 "表 3 ‣ 附录 D 无效沟通 ‣ 具身 LLM 代理学习如何在有组织的团队中合作")中总结了典型的类别。
- en: 'Table 3: Typical ineffective communication behaviors.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '表 3: 典型的无效沟通行为。'
- en: 'Type Description Example Duplicated message The same message is said more than
    once Agent 1 $\to$ Agent 3: “Check kitchencabinet or dishwasher for wine, I’ll
    check the stove.”,'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '类型 描述 示例 重复消息 相同的消息说了多次 代理人 1 $\to$ 代理人 3: “检查厨房橱柜或洗碗机寻找酒，我去检查炉子。”，'
- en: 'Agent 2 $\to$ Agent 1: “Explore the bathroom for the second wine.”'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '代理人 2 $\to$ 代理人 1: “去浴室找第二瓶酒。”'
- en: Agent 2 $\to$ (190)”
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 代理人 2 $\to$ (190)”
- en: 'Agent 2 $\to$ Agent 2: “Continue checking the kitchen cabinets for remaining
    items.”'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '代理人 2 $\to$ 代理人 2: “继续检查厨房橱柜中的剩余物品。”'
- en: 'Agent 2 $\to$ Agent 3: “I haven’t found any of the remaining items in the kitchen.
    Have you found any of the required items in the living room?”'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '代理人 2 $\to$ 代理人 3: “我还没有在厨房找到任何剩余的物品。你在客厅找到任何必需的物品了吗？”'
- en: 'Agent 3 $\to$ Agent 2: “I haven’t explored the bathroom yet.”'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '代理人 3 $\to$ 代理人 2: “我还没有检查浴室。”'
- en: Appendix E Examples of Election
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 E 选举示例
- en: In Figure [11](#A5.F11 "Figure 11 ‣ Appendix E Examples of Election ‣ Embodied
    LLM Agents Learn to Cooperate in Organized Teams"), the agents vote to elect a
    new leader. We can observe behaviors such as nominations for themselves and other
    agents, voting, and consensus achievement. We find that the agents are not power-seeking
    and may give up leadership early. The agents prefer to vote for others instead
    of nominating themselves (5 times more during the whole task). The elected leader
    also does not plan to keep the position but to nominate others for the next round.
    Also, the agents’ standpoint can be easily influenced by others. The agents do
    not debate much to win the election but reach a consensus soon. For example, Agent_1
    gives up running for herself but votes for Agent_2 because of Agent_3’s support.
    Furthermore, sometimes nominations and votes are determined by hallucinations.
    For example, at step 2, Agent_2 nominates Agent_1 as he was the first one to propose
    a search strategy. However, based on the previous dialogues, Agent_1 has not proposed
    any strategy yet.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在图 [11](#A5.F11 "图 11 ‣ 附录 E 选举示例 ‣ 具身的 LLM 代理在组织化团队中学习合作") 中，代理们投票选举新的领导者。我们可以观察到诸如自我提名、其他代理提名、投票和达成共识等行为。我们发现代理们并不追求权力，可能会早早放弃领导职务。代理们更愿意投票给其他人，而不是提名自己（在整个任务中提名自己次数少了
    5 倍）。当选的领导者也没有计划保留这个职位，而是提名其他人进行下一轮选举。此外，代理们的立场很容易受到他人的影响。代理们不会进行过多的辩论来赢得选举，而是迅速达成共识。例如，Agent_1
    放弃了自己竞选的机会，但由于 Agent_3 的支持，投票给了 Agent_2。此外，有时提名和投票是由幻觉决定的。例如，在第 2 步中，Agent_2 提名
    Agent_1，因为他是第一个提出搜索策略的人。然而，根据之前的对话，Agent_1 尚未提出任何策略。
- en: '![Refer to caption](img/07afc797a172deb4fb9ebed1a772942d.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/07afc797a172deb4fb9ebed1a772942d.png)'
- en: 'Figure 11: Examples of the election of a new leader. It takes two steps to
    vote and negotiate to determine the new leader in this case. Note that Agent_3
    chooses not to send a message as the election is done and no more information
    to be shared for now. All the messages in the figure are broadcasts.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11：新领导者选举的示例。在这种情况下，需要两个步骤来投票和协商确定新领导者。注意，Agent_3 选择不发送消息，因为选举已经结束，现在没有更多信息要分享。图中的所有消息都是广播。
- en: Appendix F Examples of Human-AI Collaboration
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 F 人类与 AI 合作的示例
- en: We conducted experiments involving a team consisting of one human player and
    two GPT-4 agents, with the human player acting as the leader. Figure [12](#A6.F12
    "Figure 12 ‣ Appendix F Examples of Human-AI Collaboration ‣ Embodied LLM Agents
    Learn to Cooperate in Organized Teams") illustrates the remarkable collaboration
    between humans and AI.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了一个实验，团队由一个人类玩家和两个 GPT-4 代理组成，其中人类玩家担任领导者。图 [12](#A6.F12 "图 12 ‣ 附录 F 人类与
    AI 合作的示例 ‣ 具身的 LLM 代理在组织化团队中学习合作") 说明了人类与 AI 之间的卓越合作。
- en: '![Refer to caption](img/717e044952d5a44796035482d96f9c5d.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/717e044952d5a44796035482d96f9c5d.png)'
- en: 'Figure 12: Examples of human-AI collaboration when the human player leads two
    GPT-4 agents (Agent_2&3).'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12：人类玩家领导两个 GPT-4 代理（Agent_2&3）时的人类与 AI 合作的示例。
- en: Appendix G Examples of Correction
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 G 纠正示例
- en: Due to hallucination and the limit of the dialogue history buffer, the leader
    may forget what has happened and give wrong orders. When the prompt encourages
    the agents to correct the leader when necessary by adding If the leader’s instructions
    are not right, you can correct the leader, some correction behaviors appear, as
    shown in Figure [13](#A7.F13 "Figure 13 ‣ Appendix G Examples of Correction ‣
    Embodied LLM Agents Learn to Cooperate in Organized Teams").
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 由于幻觉和对话历史缓冲区的限制，领导者可能会忘记发生的事情并发出错误的命令。当提示鼓励代理在必要时纠正领导者，例如添加“如果领导者的指示不正确，你可以纠正领导者”时，出现了一些纠正行为，如图
    [13](#A7.F13 "图 13 ‣ 附录 G 纠正示例 ‣ 具身的 LLM 代理在组织化团队中学习合作") 所示。
- en: In the first example, the leader Agent_1 gives an unnecessary and repetitious
    instruction. Then Agent_2 corrects the leader to avoid time wasting. In the second
    example, the leader Agent_1 may have hallucinations and cannot remember what Agent_3
    is holding clearly (cupcake and wine in the message while juice and wine in the
    thoughts). Therefore, Agent_3 clarifies that she is not holding the cupcake and
    wine and shares her next plan with the leader.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个示例中，领导者 Agent_1 发出了不必要且重复的指令。然后，Agent_2 纠正了领导者，以避免浪费时间。在第二个示例中，领导者 Agent_1
    可能出现了幻觉，不能清楚地记住 Agent_3 手中拿着的东西（消息中是杯子蛋糕和酒，而思想中是果汁和酒）。因此，Agent_3 澄清她手中没有杯子蛋糕和酒，并与领导者分享她的下一个计划。
- en: '![Refer to caption](img/3652b8f887f9732a7321148d27452ded.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/3652b8f887f9732a7321148d27452ded.png)'
- en: 'Figure 13: Examples of correction dialogues and the corresponding thoughts.
    The prompt includes If the leader’s instructions are not right, you can correct
    the leader.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 图13：修正对话和相应思路的示例。提示包括如果领导的指示不正确，你可以纠正领导。
- en: Appendix H Examples of Cooperative Behaviors Classification by Humans and GPT-4
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录H 人类与GPT-4的合作行为分类示例
- en: We ask a human evaluator and GPT-4 to label the dialogues into three different
    behavior categories shown in Table [4](#A8.T4 "Table 4 ‣ Appendix H Examples of
    Cooperative Behaviors Classification by Humans and GPT-4 ‣ Embodied LLM Agents
    Learn to Cooperate in Organized Teams").
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们请一位人类评估员和GPT-4将对话标记为表[4](#A8.T4 "表4 ‣ 附录H 人类与GPT-4的合作行为分类示例 ‣ 体现的LLM代理学会在有组织的团队中合作")中显示的三种不同行为类别。
- en: 'Table 4: Dialogues and behavior labels given by humans and GPT-4. Label 1:
    information sharing; Label 2: leadership & assistance; Label 3: Request for guidance.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 表4：人类和GPT-4提供的对话和行为标签。标签1：信息共享；标签2：领导与协助；标签3：请求指导。
- en: Dialogue Human GPT-4 Label 1* Label 2 Label 3 Label 1 Label 2 Label 3 Hey, where
    are you? Please let me know your location so that I can assign you a task. 0 1
    1 0 1 1 I’m currently in the bedroom where I found an unchecked cabinet. Please
    explore the livingroom and start checking for the required items. 1 1 0 1 1 0
    I’m currently in the bedroom where I found an unchecked cabinet. I haven’t found
    any of the required items yet. 1 0 0 1 0 0 Check the cabinet in the bedroom. I’ll
    check the one in the bathroom. 1 1 0 0 1 0 I haven’t found any of the required
    items yet. Did you find any in the kitchen? 1 0 1 1 0 1 I haven’t found any of
    the required items yet. Have you found any in the bathroom? 1 0 1 1 0 1 Agent
    3, I found a pudding in one of the kitchen cabinets. Please continue checking
    the other kitchen cabinets for the remaining items. 1 1 0 1 1 0 I haven’t found
    any of the required items yet. Did you find any other required items in the kitchen?
    1 0 1 1 0 1 I haven’t found any of the remaining items yet. 1 0 0 1 0 0 I’m in
    the living room searching for the remaining items. 1 0 0 1 0 0 Okay, I will keep
    checking the kitchen cabinets for the remaining items. 1 0 0 1 0 0 I’m currently
    in the living room searching for the remaining items. 1 0 0 1 0 0 I haven’t found
    any of the remaining items yet. 1 0 0 1 0 0 I’m still searching the living room.
    Have you found any of the required items? 1 0 1 1 0 1 Put items on the table once
    you find them. Keep searching your current areas. 0 1 0 0 1 0 I haven’t found
    any of the remaining items in the kitchen. Have you found any of the required
    items in the living room? 1 0 1 1 0 1 I haven’t explored the bathroom yet. Have
    you found any of the required items in the living room? 1 0 1 1 0 1 I have explored
    the bedroom and found wine, cupcake, and juice. I still need to find pudding.
    Can you help me search the bedroom for the remaining item? 1 1 1 1 1 0 I found
    the wine, cupcake, and juice in the bedroom. Agent 1 wants me to put them on the
    coffee table and then check the bathroom cabinet. 1 0 0 1 1 0 Agent 1 wants us
    to check if there’s another wine in the kitchen. 1 0 0 0 1 0
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 对话 人类 GPT-4 标签1* 标签2 标签3 标签1 标签2 标签3 嘿，你在哪里？请告诉我你的所在位置，以便我分配任务给你。 0 1 1 0 1
    1 我目前在发现了一个未检查的橱柜的卧室里。请检查一下客厅并开始寻找所需的物品。 1 1 0 1 1 0 我目前在发现了一个未检查的橱柜的卧室里。我还没有找到任何所需的物品。
    1 0 0 1 0 0 检查卧室里的橱柜。我会检查浴室里的那个。 1 1 0 0 1 0 我还没有找到任何所需的物品。你在厨房找到了任何物品吗？ 1 0 1
    1 0 1 我还没有找到任何所需的物品。你在浴室找到了什么吗？ 1 0 1 1 0 1 代理3，我在厨房的一个橱柜里找到了布丁。请继续检查其他厨房橱柜中的剩余物品。
    1 1 0 1 1 0 我还没有找到任何所需的物品。你在厨房找到了其他所需的物品吗？ 1 0 1 1 0 1 我还没有找到剩余的物品。 1 0 0 1 0
    0 我在客厅寻找剩余的物品。 1 0 0 1 0 0 好的，我会继续检查厨房橱柜中的剩余物品。 1 0 0 1 0 0 我目前在客厅寻找剩余的物品。 1 0
    0 1 0 0 我还没有找到任何剩余的物品。 1 0 0 1 0 0 我还在搜寻客厅。你找到了任何所需的物品吗？ 1 0 1 1 0 1 一旦找到物品就放到桌子上。继续搜索你当前的区域。
    0 1 0 0 1 0 我在厨房没有找到任何剩余的物品。你在客厅找到任何所需的物品了吗？ 1 0 1 1 0 1 我还没有探索浴室。你在客厅找到任何所需的物品吗？
    1 0 1 1 0 1 我已经探索了卧室，找到了酒、杯子蛋糕和果汁。我还需要找到布丁。你能帮我在卧室里找找剩余的物品吗？ 1 1 1 1 1 0 我在卧室找到了酒、杯子蛋糕和果汁。代理1希望我把它们放到咖啡桌上，然后检查浴室的橱柜。
    1 0 0 1 1 0 代理1希望我们检查厨房里是否还有其他酒。 1 0 0 0 1 0
- en: Appendix I Examples of New Prompts after Reflection
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录I 反思后的新提示示例
- en: We list more prompts generated by the Criticize-Reflect architecture in Figure [14](#A9.F14
    "Figure 14 ‣ Appendix I Examples of New Prompts after Reflection ‣ Embodied LLM
    Agents Learn to Cooperate in Organized Teams").
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们列出了更多由批评-反思架构生成的提示，见图[14](#A9.F14 "Figure 14 ‣ Appendix I Examples of New
    Prompts after Reflection ‣ Embodied LLM Agents Learn to Cooperate in Organized
    Teams")。
- en: '![Refer to caption](img/27f7dd8d32fc94d014704c6b6ea88f94.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/27f7dd8d32fc94d014704c6b6ea88f94.png)'
- en: 'Figure 14: Examples of Prompts generated via Reflection. The first row is generated
    with the Critic, while the second row is without the Critic, where the new prompts
    are relatively vague. Note that there is no Agent Z in the team.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14：通过反思生成的提示示例。第一行是通过批评者生成的，而第二行没有批评者生成的提示，这些新提示相对模糊。请注意，团队中没有代理 Z。
