- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 18:41:11'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-09-08 18:41:11'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Building Better AI Agents: A Provocation on the Utilisation of Persona in LLM-based
    Conversational Agents'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建设更好的 AI 代理：对 LLM 基于对话代理中角色利用的挑战
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2407.11977](https://ar5iv.labs.arxiv.org/html/2407.11977)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2407.11977](https://ar5iv.labs.arxiv.org/html/2407.11977)
- en: Guangzhi Sun [0000-0002-5886-056X](https://orcid.org/0000-0002-5886-056X "ORCID
    identifier") University of CambridgeCambridgeUnited Kingdom [gs534@cam.ac.uk](mailto:gs534@cam.ac.uk)
    ,  Xiao Zhan [0000-0003-1755-0976](https://orcid.org/0000-0003-1755-0976 "ORCID
    identifier") King’s College LondonLondonUnited Kingdom [xiao.zhan@kcl.ac.uk](mailto:xiao.zhan@kcl.ac.uk)
     and  Jose Such [0000-0002-6041-178X](https://orcid.org/0000-0002-6041-178X "ORCID
    identifier") King’s College LondonLondonUnited Kingdom
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Guangzhi Sun [0000-0002-5886-056X](https://orcid.org/0000-0002-5886-056X "ORCID
    identifier") 剑桥大学 剑桥 英国 [gs534@cam.ac.uk](mailto:gs534@cam.ac.uk)，Xiao Zhan [0000-0003-1755-0976](https://orcid.org/0000-0003-1755-0976
    "ORCID identifier") 伦敦国王学院 伦敦 英国 [xiao.zhan@kcl.ac.uk](mailto:xiao.zhan@kcl.ac.uk)
    以及 Jose Such [0000-0002-6041-178X](https://orcid.org/0000-0002-6041-178X "ORCID
    identifier") 伦敦国王学院 伦敦 英国
- en: '& VRAIN, Universitat Politecnica de Valencia, Spain [jose.such@kcl.ac.uk](mailto:jose.such@kcl.ac.uk)(2024)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '& VRAIN，瓦伦西亚理工大学，西班牙 [jose.such@kcl.ac.uk](mailto:jose.such@kcl.ac.uk)(2024)'
- en: Abstract.
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: The incorporation of Large Language Models (LLMs) such as the GPT series into
    diverse sectors including healthcare, education, and finance marks a significant
    evolution in the field of artificial intelligence (AI). The increasing demand
    for personalised applications motivated the design of conversational agents (CAs)
    to possess distinct personas. This paper commences by examining the rationale
    and implications of imbuing CAs with unique personas, smoothly transitioning into
    a broader discussion of the personalisation and anthropomorphism of CAs based
    on LLMs in the LLM era.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 将大型语言模型（LLMs）如 GPT 系列引入医疗、教育和金融等不同领域，标志着人工智能（AI）领域的重要发展。对个性化应用的日益增长的需求促使对话代理（CAs）的设计具备独特的角色。本文首先探讨了赋予
    CAs 独特角色的理由和影响，随后顺畅地过渡到对 LLM 时代基于 LLM 的 CAs 的个性化和拟人化的更广泛讨论。
- en: We delve into the specific applications where the implementation of a persona
    is not just beneficial but critical for LLM-based CAs. The paper underscores the
    necessity of a nuanced approach to persona integration, highlighting the potential
    challenges and ethical dilemmas that may arise. Attention is directed towards
    the importance of maintaining persona consistency, establishing robust evaluation
    mechanisms, and ensuring that the persona attributes are effectively complemented
    by domain-specific knowledge.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们深入探讨了在 LLM 基于对话代理（CAs）中，角色的实施不仅是有益的，而且是关键的具体应用。本文强调了对角色整合的细致方法的必要性，突出了可能出现的挑战和伦理困境。注意力集中于保持角色一致性、建立健全的评估机制，并确保角色属性与特定领域知识有效互补的重要性。
- en: 'Large language model, persona, personality, conversational agent, ChatGPT,
    natural language processing^†^†journalyear: 2024^†^†copyright: rightsretained^†^†conference:
    ACM Conversational User Interfaces 2024; July 8–10, 2024; Luxembourg, Luxembourg^†^†booktitle:
    ACM Conversational User Interfaces 2024 (CUI ’24), July 8–10, 2024, Luxembourg,
    Luxembourg^†^†doi: 10.1145/3640794.3665887^†^†isbn: 979-8-4007-0511-3/24/07^†^†ccs:
    Security and privacy Social aspects of security and privacy^†^†ccs: Security and
    privacy Usability in security and privacy^†^†ccs: Computing methodologies Discourse,
    dialogue and pragmatics^†^†ccs: Human-centered computing HCI theory, concepts
    and models^†^†ccs: Computing methodologies Natural language processing'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '大型语言模型，角色，个性，对话代理，ChatGPT，自然语言处理^†^†期刊年份: 2024^†^†版权: 权利保留^†^†会议: ACM 对话用户界面
    2024; 2024年7月8–10日; 卢森堡，卢森堡^†^†书名: ACM 对话用户界面 2024 (CUI ’24), 2024年7月8–10日, 卢森堡，卢森堡^†^†doi:
    10.1145/3640794.3665887^†^†isbn: 979-8-4007-0511-3/24/07^†^†ccs: 安全与隐私 社会安全与隐私方面^†^†ccs:
    安全与隐私 安全与隐私的可用性^†^†ccs: 计算方法 话语、对话与语用学^†^†ccs: 以人为中心的计算 HCI 理论、概念和模型^†^†ccs: 计算方法
    自然语言处理'
- en: 1\. What Does ‘Persona’ Mean in the Context of Conversational Agents?
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 在对话代理的背景下，“角色”是什么意思？
- en: In the context of conversational agents (CAs), the concept of *persona* represents
    the essence or ‘soul’ of these agents. Persona encapsulates the distinct tone,
    voice, and personality that characterizes a CA, transforming mechanical interactions
    into engaging, human-like conversations (Sutcliffe, [2023](#bib.bib47); Kim et al.,
    [2019](#bib.bib19)). Commonly, these attributes of persona can consist any type
    of information that intend to capture personal characteristics about an individual (Liu
    et al., [2022](#bib.bib29)), and are relatively static (race), and slowly change
    over time (age), or temporary (emotional status) (Li et al., [2016](#bib.bib27);
    Yang, [2019](#bib.bib55)).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在会话代理（CAs）的背景下，*角色*的概念代表了这些代理的精髓或‘灵魂’。角色封装了特定的语调、声音和个性，这些特征使CA能够将机械交互转变为引人入胜的类人对话 (Sutcliffe,
    [2023](#bib.bib47); Kim et al., [2019](#bib.bib19))。通常，角色的这些属性可以包含任何旨在捕捉个人特征的信息 (Liu
    et al., [2022](#bib.bib29))，并且相对静态（种族），随时间缓慢变化（年龄），或暂时（情感状态） (Li et al., [2016](#bib.bib27);
    Yang, [2019](#bib.bib55))。
- en: Before delving deeper into the discussion of personas in CAs, it’s important
    to distinguish this concept from the idea of ‘personality’ that has been explored
    in prior research (Lessio and Morris, [2020](#bib.bib25); Liao and He, [2020](#bib.bib28);
    Pradhan and Lazar, [2021](#bib.bib37); Roettgers, [2019](#bib.bib39)). While personality
    traits, such as being ”friendly” or ”smart,” or frameworks like the Myers-Briggs
    Type Indicator (MBTI) (Briggs, [1987](#bib.bib5)), might define certain characteristics
    shared by groups of individuals, a persona in CAs represents a more complex and
    consistent identity (Pradhan and Lazar, [2021](#bib.bib37); Zhang et al., [2018](#bib.bib56)).
    This persona transcends mere personality traits, serving as an external manifestation
    of a character’s unique identity. For instance, when a CA is designed with the
    persona of a specific character, say, Sherlock Holmes, it consistently embodies
    the unique attributes and behaviors of that character throughout interactions.
    This specificity differs significantly from assigning generic traits like ’bravery’
    and ’smartness’ to a CA. In the latter case, the CA might alternate between different
    characters who share these traits, such as both Sherlock Holmes and Hermione Granger,
    depending on the context of the interaction. Thus, the persona of a CA is a more
    nuanced and stable layer that defines its interaction style and character representation.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在进一步探讨CAs中的角色之前，重要的是要将这一概念与先前研究中探讨的‘个性’概念区分开来 (Lessio and Morris, [2020](#bib.bib25);
    Liao and He, [2020](#bib.bib28); Pradhan and Lazar, [2021](#bib.bib37); Roettgers,
    [2019](#bib.bib39))。虽然个性特征，如“友好”或“聪明”，或者像迈尔斯-布里格斯性格类型指标（MBTI） (Briggs, [1987](#bib.bib5))这样的框架，可能定义了某些个体群体的共享特征，但CAs中的角色代表了一个更复杂且一致的身份 (Pradhan
    and Lazar, [2021](#bib.bib37); Zhang et al., [2018](#bib.bib56))。这个角色超越了单纯的个性特征，作为角色独特身份的外在表现。例如，当一个CA被设计为特定角色，如福尔摩斯时，它在交互中始终体现该角色的独特属性和行为。这种特异性与将‘勇敢’和‘聪明’等通用特征赋予CA有显著不同。在后者情况下，CA可能会在具有这些特征的不同角色之间交替，例如福尔摩斯和赫敏·格兰杰，具体取决于交互的背景。因此，CA的角色是一个更细致且稳定的层次，定义了其交互风格和角色表现。
- en: 1.1\. Persona in CAs in pre-LLM era
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1. CAs中的角色在LLM前时代
- en: Recent research in the field of CAs has focused extensively on enhancing the
    capabilities of chatbots, aiming to imbue them with more human-like characteristics.
    This initiative is driven by the goal to significantly boost user engagement,
    among other benefits. The development of a persona for CAs such as chatbots has
    emerged as a key strategy in this domain. The introduction of these personas is
    a testament to the evolving sophistication of chatbot technology, reflecting a
    deeper understanding of human-chatbot interaction dynamics (Hwang et al., [2021](#bib.bib17)).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 最近在CAs领域的研究广泛集中于增强聊天机器人的能力，旨在赋予它们更多类人特征。此举的目标是显著提升用户参与度等多个好处。为CAs如聊天机器人开发角色已成为该领域的关键策略。这些角色的引入证明了聊天机器人技术的不断进步，反映了对人机互动动态的更深刻理解 (Hwang
    et al., [2021](#bib.bib17))。
- en: 'Two main avenues of exploration have emerged: the technical research stream
    pushes the boundaries of what is technically possible (Zhou et al., [2020](#bib.bib58);
    Danielescu and Christian, [2018](#bib.bib9); Liao and He, [2020](#bib.bib28);
    Li et al., [2016](#bib.bib27); Sordoni et al., [2015](#bib.bib45); Vinyals and
    Le, [2015](#bib.bib50); Sutcliffe, [2023](#bib.bib47)), the social research stream
    ensures that these advancements are grounded in a thorough understanding of user
    needs, preferences, and the broader societal context (Rashkin et al., [2018](#bib.bib38);
    Zhong et al., [2020](#bib.bib57); Bickmore et al., [2010](#bib.bib4); Hwang et al.,
    [2021](#bib.bib17)).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 两个主要的探索途径已经出现：技术研究流推动了技术上可能性的边界 (Zhou et al., [2020](#bib.bib58); Danielescu
    and Christian, [2018](#bib.bib9); Liao and He, [2020](#bib.bib28); Li et al.,
    [2016](#bib.bib27); Sordoni et al., [2015](#bib.bib45); Vinyals and Le, [2015](#bib.bib50);
    Sutcliffe, [2023](#bib.bib47))，社会研究流则确保这些进展建立在对用户需求、偏好和更广泛社会背景的透彻理解之上 (Rashkin
    et al., [2018](#bib.bib38); Zhong et al., [2020](#bib.bib57); Bickmore et al.,
    [2010](#bib.bib4); Hwang et al., [2021](#bib.bib17))。
- en: 1.1.1\. Technical research.
  id: totrans-18
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.1.1\. 技术研究。
- en: Previous studies have proposed various methods for embedding personas into traditional
    chatbots¹¹1Unlike our approach that distinctly separates persona from personality,
    some prior research conflates these concepts without addressing their nuances.
    Therefore, the summary in this section includes works that focus on ‘personality’
    as well.. The categories used are broad — for a comprehensive summary of the model
    and a survey see (Sutcliffe, [2023](#bib.bib47)). The more widely known examples
    are that neural models of conversation generation provided a simple mechanism
    for incorporating personas as embeddings (Li et al., [2016](#bib.bib27); Sordoni
    et al., [2015](#bib.bib45); Vinyals and Le, [2015](#bib.bib50)). More recently,
    [Liao and He](#bib.bib28) created personas for conversational agents that had
    distinct gender and race to understand user preferences (Liao and He, [2020](#bib.bib28)).
    As one example of a project that is guided by user data, persona XiaoIce was designed
    based on a large scale analysis of human conversations (Zhou et al., [2020](#bib.bib58)).
    In doing so, the designers found that the majority of “desired” users are young
    and female. Hence, they designed XiaoIce’s persona around an “18-year-old girl” (Zhou
    et al., [2020](#bib.bib58)). As another example, Danielescu and Christian (Danielescu
    and Christian, [2018](#bib.bib9)) designed personas for a conversational coaching
    system where they involved customers by interviewing them and brainstorming with
    them, finding that their preferences may vary based on their culture and region.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的研究提出了多种将角色嵌入传统聊天机器人的方法¹¹1与我们的方法不同，之前一些研究将角色与个性混为一谈，而没有解决其细微差别。因此，本节的总结包括了那些也关注于‘个性’的工作。所用的类别很宽泛——有关模型的全面总结和调查请参见
    (Sutcliffe, [2023](#bib.bib47))。更为人知的例子是，神经对话生成模型提供了一种简单机制，将角色作为嵌入 (Li et al.,
    [2016](#bib.bib27); Sordoni et al., [2015](#bib.bib45); Vinyals and Le, [2015](#bib.bib50))。更近期，[Liao
    and He](#bib.bib28) 为对话代理创建了具有明显性别和种族的角色，以了解用户偏好 (Liao and He, [2020](#bib.bib28))。作为一个以用户数据为指导的项目示例，XiaoIce
    的角色是基于对人类对话的大规模分析设计的 (Zhou et al., [2020](#bib.bib58))。在这样做的过程中，设计师发现“大多数”理想用户是年轻女性。因此，他们围绕“18岁女孩”设计了
    XiaoIce 的角色 (Zhou et al., [2020](#bib.bib58))。另一个例子是，Danielescu 和 Christian (Danielescu
    and Christian, [2018](#bib.bib9)) 为一个对话辅导系统设计了角色，他们通过访谈和头脑风暴的方式涉及客户，发现他们的偏好可能会根据文化和地区有所不同。
- en: 1.1.2\. Social research.
  id: totrans-20
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.1.2\. 社会研究。
- en: The academic community has consistently maintained a positive attitude towards
    endowing chatbots with personas. Incorporating a distinct persona in CAs significantly
    influences the development of a robust relationship in human-agent interactions.
    It has been demonstrated that a well-crafted persona can significantly enhance
    the capacity of CAs to engage in empathetic conversations (Rashkin et al., [2018](#bib.bib38);
    Zhong et al., [2020](#bib.bib57)). This is mirrored from empirical research, such
    as that by [Zhong et al.](#bib.bib57) (Zhong et al., [2020](#bib.bib57)), has
    established the role of persona in fostering empathy within human conversations
    from the psychological perspective. Moreover, the positive contribution of persona
    is recognised in specific areas such as healthcare where CAs assume varied roles.
    For instance, [Bickmore et al.](#bib.bib4) (Bickmore et al., [2010](#bib.bib4))
    found that an empathetic persona in an agent is effective for managing mental
    health, whereas an agent with a subtle persona guiding exercise can enhance commitment
    to behavior change. Similarly, preliminary research conducted in (Hwang et al.,
    [2021](#bib.bib17)) indicates that chatbots embodying roles like doctors, in comparison
    to generic bots, achieve higher user acceptance, intimacy, and trust in healthcare-related
    interactions.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 学术界对赋予聊天机器人个性一直持积极态度。在对话系统中融入独特个性显著影响人机交互中建立稳固关系的过程。研究表明，精心设计的个性能够显著增强对话系统进行同情对话的能力 (Rashkin
    et al., [2018](#bib.bib38); Zhong et al., [2020](#bib.bib57))。这在实证研究中得到了体现，例如[Zhong
    et al.](#bib.bib57) (Zhong et al., [2020](#bib.bib57))的研究从心理学角度建立了个性在促进人际对话中同情的作用。此外，个性在医疗等特定领域的积极贡献也得到了认可，在这些领域中，对话系统扮演着不同的角色。例如，[Bickmore
    et al.](#bib.bib4) (Bickmore et al., [2010](#bib.bib4))发现，具有同情个性的代理在管理心理健康方面有效，而具有微妙个性的代理引导锻炼则能增强行为改变的承诺。类似地，在(Hwang
    et al., [2021](#bib.bib17))进行的初步研究表明，与通用机器人相比，具备类似医生角色的聊天机器人在医疗相关互动中实现了更高的用户接受度、亲密感和信任感。
- en: 2\. Reality or Aspiration?
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 现实还是愿景？
- en: '![Refer to caption](img/f8bfb044f15275f1a5ee4af9186e3ed0.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/f8bfb044f15275f1a5ee4af9186e3ed0.png)'
- en: Figure 1\. A screenshot of a dialogue with GPT-4-0125-preview. This suggests
    that GPT-4 does not embody a specific persona. However, this conclusion is based
    on the model’s output, which may not fully align with the designers’ intentions.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1\. GPT-4-0125-preview对话的截图。这表明GPT-4并未体现出特定个性。然而，这一结论基于模型的输出，可能与设计者的意图不完全一致。
- en: Large Language Model (LLM)-based CAs, exemplified by systems like ChatGPT²²2[https://openai.com/chatgpt](https://openai.com/chatgpt),
    are rapidly being integrated into various critical sectors, underscoring their
    growing significance in practical applications. These include, but are not limited
    to, healthcare (Cascella et al., [2023](#bib.bib7); Lai et al., [2023](#bib.bib22);
    Thirunavukarasu et al., [2023](#bib.bib48)), education (Xiao and Zhi, [2023](#bib.bib53);
    Kohnke et al., [2023](#bib.bib20); Mbakwe et al., [2023](#bib.bib32)), and finance (Lakkaraju
    et al., [2023b](#bib.bib24), [a](#bib.bib23); Wu et al., [2023](#bib.bib52)),
    among others.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 基于大语言模型（LLM）的对话系统，以如ChatGPT²²2[https://openai.com/chatgpt](https://openai.com/chatgpt)等系统为例，正迅速被整合进多个关键领域，突显了其在实际应用中的日益重要性。这些领域包括但不限于医疗 (Cascella
    et al., [2023](#bib.bib7); Lai et al., [2023](#bib.bib22); Thirunavukarasu et al.,
    [2023](#bib.bib48))、教育 (Xiao and Zhi, [2023](#bib.bib53); Kohnke et al., [2023](#bib.bib20);
    Mbakwe et al., [2023](#bib.bib32))和金融 (Lakkaraju et al., [2023b](#bib.bib24),
    [a](#bib.bib23); Wu et al., [2023](#bib.bib52))，等等。
- en: 'These LLM-based CAs, which are originally developed for general-purpose applications,
    do not prioritize the establishment of a distinct persona during their design
    phase. For example, as illustrated in Figure [1](#S2.F1 "Figure 1 ‣ 2\. Reality
    or Aspiration? ‣ Building Better AI Agents: A Provocation on the Utilisation of
    Persona in LLM-based Conversational Agents"), ChatGPT, a typical instance of such
    systems, is structured to function without a predefined persona, focusing instead
    on delivering information and interaction capabilities that are broadly applicable
    across various contexts and user requirements³³3Despite this observation, no official
    documentation or evidence has been found to indicate that ChatGPT was deliberately
    designed to incorporate distinct personas..'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '这些基于大型语言模型（LLM）的对话代理最初是为了通用应用开发的，在设计阶段并没有优先考虑建立一个独特的角色。例如，如图[1](#S2.F1 "Figure
    1 ‣ 2\. Reality or Aspiration? ‣ Building Better AI Agents: A Provocation on the
    Utilisation of Persona in LLM-based Conversational Agents")所示，ChatGPT，作为这类系统的典型实例，被设计为在没有预定义角色的情况下运作，而是专注于提供信息和交互功能，这些功能在各种情境和用户需求中都广泛适用³³3尽管有这种观察，但尚未发现任何官方文档或证据表明ChatGPT被刻意设计为包含独特的角色。'
- en: Nevertheless, the integration of personas in LLM-based CAs should not be viewed
    as an unattainable goal. Online resources (including blogs (McFarland, [2023](#bib.bib33);
    Butler, [2023](#bib.bib6)), and technical reports (White et al., [2023](#bib.bib51)))
    already provide guidance on designing specific personas to optimize ChatGPT’s
    effectiveness across various roles, typically achieved by customizing initial
    conversation prompts to assign a desired persona. Concurrently, numerous empirical
    studies (Jiang et al., [2023](#bib.bib18); Durmus et al., [2023](#bib.bib13);
    Kong et al., [2023](#bib.bib21); Zhou et al., [2022](#bib.bib59); Chan et al.,
    [2023](#bib.bib8); Park et al., [2023](#bib.bib35), [2022](#bib.bib36); Argyle
    et al., [2023](#bib.bib3)) have examined and demonstrated the practicality of
    assigning personas to LLM-based CAs. Among them, some promising results indicated
    that endowing LLM-based CAs with personas leads to satisfactory outcomes. These
    include the ability to express opinions similar to people from some controes (Durmus
    et al., [2023](#bib.bib13)), offering useful answers (Kong et al., [2023](#bib.bib21)),
    team working (Chan et al., [2023](#bib.bib8)), and enhancing the overall truthfulness
    in their responses (Zhou et al., [2022](#bib.bib59)).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，将角色整合到基于LLM的对话代理中不应被视为一个无法实现的目标。在线资源（包括博客（McFarland, [2023](#bib.bib33);
    Butler, [2023](#bib.bib6)），和技术报告（White et al., [2023](#bib.bib51)））已经提供了关于设计特定角色以优化ChatGPT在各种角色中的有效性的指导，这通常通过定制初始对话提示来分配所需的角色。同时，许多实证研究（Jiang
    et al., [2023](#bib.bib18); Durmus et al., [2023](#bib.bib13); Kong et al., [2023](#bib.bib21);
    Zhou et al., [2022](#bib.bib59); Chan et al., [2023](#bib.bib8); Park et al.,
    [2023](#bib.bib35), [2022](#bib.bib36); Argyle et al., [2023](#bib.bib3)）已研究并展示了为基于LLM的对话代理分配角色的实际效果。在这些研究中，一些有前景的结果表明，赋予基于LLM的对话代理角色可以带来令人满意的结果。这些结果包括能够表达类似于某些国家人的观点（Durmus
    et al., [2023](#bib.bib13)），提供有用的答案（Kong et al., [2023](#bib.bib21)），团队合作（Chan
    et al., [2023](#bib.bib8)），以及提高回答的整体真实性（Zhou et al., [2022](#bib.bib59)）。
- en: However, upon deeper analysis of persona-based CAs, it becomes evident that
    LLM-based CAs are still far from embodying specific personas at this stage, highlighting
    a substantial developmental path that lies ahead. For instance, significant performance
    disparities exist between different GPT versions. Stories from GPT-4 personas
    are generally more readable, coherent, and believable, while ChatGPT tends to
    deviate from the provided prompts, failing to adhere strictly to the prescribed
    personas (Jiang et al., [2023](#bib.bib18)). In (Shu et al., [2023](#bib.bib42)),
    a study was conducted to assess if the prevailing prompt-based approach facilitates
    LLM-based CAs in delivering consistent and robust responses. Their investigation,
    which included testing 15 open-source LLMs, ultimately revealed that most models
    lacked a consistent persona. Furthermore, it’s noteworthy that malicious actors
    sometimes exploit these characteristic, manipulating them to generate toxic responses(Deshpande
    et al., [2023](#bib.bib11); Zhuo et al., [2023](#bib.bib60)).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，通过对基于角色的CAs进行深入分析，可以明显看出，基于LLM的CAs在当前阶段仍远未体现特定角色，这突显了未来发展中的重大挑战。例如，不同GPT版本之间存在显著的性能差异。GPT-4角色的故事通常更具可读性、一致性和可信度，而ChatGPT则往往偏离提供的提示，未能严格遵循规定的角色（Jiang
    et al., [2023](#bib.bib18)）。在（Shu et al., [2023](#bib.bib42)）中，进行了一项研究，以评估当前基于提示的方法是否有助于LLM-based
    CAs提供一致和稳健的响应。他们的调查包括测试15个开源LLM，最终揭示大多数模型缺乏一致的角色。此外，值得注意的是，恶意行为者有时会利用这些特性，操控它们生成有害的回应（Deshpande
    et al., [2023](#bib.bib11); Zhuo et al., [2023](#bib.bib60)）。
- en: 3\. Persona needs in LLM-based CAs
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3. 角色需求在LLM-based CAs中的应用
- en: In the current landscape dominated by LLMs, the importance of persona has not
    diminished, rather, it often takes on an even more critical role. In this section,
    we will explore various situations and use cases where the persona of a LLM-based
    CA is particularly crucial.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前以LLM主导的环境中，角色的重要性并未减弱，反而通常变得更加关键。在本节中，我们将深入探讨LLM-based CA中角色尤为重要的各种情况和用例。
- en: 3.1\. Participant Simulation
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1. 参与者模拟
- en: '[Hagendorff et al.](#bib.bib16) (Hagendorff et al., [2022](#bib.bib16)) conducted
    an evaluation of GPT-3.5 through cognitive response tests and discovered that
    the error patterns of the language model qualitatively reflect intuitive behaviors
    akin to those found in humans. Furthermore, it often fails in similar reasoning
    tasks as humans do (Dasgupta et al., [2022](#bib.bib10)). These findings underscore
    the significant potential of LLMs in capturing aspects of human behavior. Based
    on these findings, LLMs are increasingly being considered and used to simulator
    human beings with different personas. Recent studies (Argyle et al., [2023](#bib.bib3);
    Aher et al., [2023](#bib.bib2); Park et al., [2022](#bib.bib36)) have provided
    substantial evidence that LLMs simulating user responses can replicate social
    science experiments and online forums with a high degree of consistency comparable
    to those obtained using actual human participants.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[Hagendorff et al.](#bib.bib16)（Hagendorff et al., [2022](#bib.bib16)）通过认知反应测试对GPT-3.5进行了评估，发现语言模型的错误模式定性地反映了类似于人类的直观行为。此外，它在类似推理任务中往往表现出与人类相似的失败（Dasgupta
    et al., [2022](#bib.bib10)）。这些发现强调了LLM在捕捉人类行为方面的巨大潜力。基于这些发现，LLM越来越被考虑用于模拟具有不同角色的人类。近期研究（Argyle
    et al., [2023](#bib.bib3); Aher et al., [2023](#bib.bib2); Park et al., [2022](#bib.bib36)）提供了大量证据，表明LLM模拟用户响应可以以与实际人类参与者相当的高一致性再现社会科学实验和在线论坛。'
- en: The future of simulating various user types appears brighter as the accuracy
    of such simulations continues to improve. Experiments and studies in fields constrained
    by traditional methodologies stand to benefit significantly from advanced technologies
    like LLMs. For example, research exploring interactions with individuals who have
    mental health issues often faces ethical dilemmas and heightened risk assessments.
    Utilizing LLMs equipped with well-defined personas to simulate such participants
    can expedite research processes while minimizing potential risks to the interaction
    between researchers and subjects. Additionally, in studies seeking diverse and
    balanced samples, recruitment challenges often arise, especially when targeting
    specific demographic backgrounds. LLMs can be programmed to represent a range
    of demographics and personas, thus addressing recruitment limitations efficiently.
    Moreover, the financial implications of user studies involving large participant
    groups are considerable. By incorporating personas into LLMs, researchers can
    conduct extensive studies more cost-effectively, without compromising the breadth
    and diversity of participant profiles.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 随着模拟各种用户类型的准确性不断提高，未来的前景显得更加光明。受限于传统方法的领域中的实验和研究，将从像 LLM 这样的先进技术中显著受益。例如，探索与心理健康问题患者互动的研究常常面临伦理困境和风险评估的挑战。利用配备有明确角色的
    LLM 来模拟这些参与者，可以加快研究进程，同时减少对研究者与被试者之间互动的潜在风险。此外，在寻求多样化和平衡样本的研究中，招募挑战通常会出现，尤其是当目标特定的人口背景时。LLM
    可以被编程以代表各种人口统计和角色，从而有效地解决招募限制。此外，大规模参与者组的用户研究在财务上也有相当大的影响。通过将角色融入 LLM，研究人员可以以更具成本效益的方式进行广泛的研究，而不会妨碍参与者档案的广度和多样性。
- en: 3.2\. Role Playing in Specific Domains
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2\. 特定领域中的角色扮演
- en: LLM-based CAs, when programmed with specific personas, offer substantial support
    to educators, especially teachers, in improving their development of educational
    content, enriching their teaching methodologies, and bolstering their self-assurance.
    For instance, such agents can simulate a variety of student personas, enabling
    teaching assistants (TAs) to engage in realistic interaction scenarios (Markel
    et al., [2023](#bib.bib31)). This approach allows TAs to refine their skills in
    providing feedback and effectively addressing the needs of students with diverse
    characteristics, learning goals, and educational backgrounds. This comprehensive
    and authentic practice environment is instrumental in equipping TAs with the necessary
    competencies to minimize instructional mishaps in real-world teaching situations.
    Similarly, they have the potential to significantly enhance the professional skills
    of lawyers, physicians, and other specialists. These LLM-based CAs can simulate
    interactions with diverse patient types, including the elderly and those with
    unique symptoms or needs. Traditionally, such simulations form a crucial part
    of training before professionals are fully qualified. Now, with the integration
    of LLM agents equipped with specialized personas, this training phase can be streamlined
    and made more intelligence-oriented, offering a sophisticated approach to professional
    skill development.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 基于 LLM 的 CAs，当被编程为特定角色时，为教育工作者，特别是教师，提供了实质性的支持，帮助他们改进教育内容的开发，丰富教学方法，并增强自信。例如，这些代理可以模拟各种学生角色，使教学助理（TAs）能够参与现实的互动场景（Markel
    等， [2023](#bib.bib31)）。这种方法允许 TAs 提高他们在提供反馈和有效应对具有不同特征、学习目标和教育背景的学生需求方面的技能。这种全面且真实的实践环境对装备
    TAs 必要的能力，以最小化真实教学情境中的教学失误至关重要。同样，它们还有潜力显著提升律师、医生及其他专业人士的职业技能。这些基于 LLM 的 CAs 可以模拟与各种病人类型的互动，包括老年人以及那些有独特症状或需求的患者。传统上，这些模拟是专业人士完全合格之前培训的重要组成部分。现在，通过整合配备有专业角色的
    LLM 代理，这一培训阶段可以被精简并更加智能化，为专业技能的发展提供了一种先进的方法。
- en: 'Beyond their assistive role, these technologies can have personas to simulate
    domain experts, notably in healthcare, education and law. Here, CAs would blend
    intellectual and emotional support, innovatively simulating roles such as caregivers,
    tutors, and legal advisors. Nonetheless, their effectiveness hinges also on having
    accurate, domain-specific expertise, a critical aspect we will discuss in Section [4.3](#S4.SS3
    "4.3\. More than Persona ‣ 4\. Challenges and Caveats ‣ Building Better AI Agents:
    A Provocation on the Utilisation of Persona in LLM-based Conversational Agents").'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 除了辅助角色外，这些技术还可以拥有模拟领域专家的形象，尤其是在医疗、教育和法律领域。在这些领域中，客户助手将融合智力和情感支持，创新性地模拟看护者、辅导员和法律顾问等角色。然而，它们的有效性还依赖于拥有准确的领域专业知识，这是我们将在第[4.3](#S4.SS3
    "4.3\. 超越形象 ‣ 4\. 挑战与警示 ‣ 打造更好的 AI 助手：关于大语言模型对话助手中形象使用的讨论")节中讨论的关键方面。
- en: 3.3\. Brand Representation
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3\. 品牌代表性
- en: The persona of an LLM-based CA plays a crucial role in brand representation
    by aligning with the brand’s values, enhancing user engagement, and serving as
    a differentiator in a crowded market. For instance,
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 基于大语言模型的客户助手的形象在品牌代表性中发挥着至关重要的作用，通过与品牌价值观一致，增强用户参与感，并在竞争激烈的市场中作为一个区分因素。例如，
- en: “ Domino’s pizza created ‘Dom’, a virtual ordering assistant. Dom’s persona
    is friendly and efficient, reflecting the brand’s focus on convenient and fast
    service. Dom allows customers to order pizza using conversational language, making
    the process more engaging and aligning with Domino’s commitment to innovation
    in delivery and customer service.” (Domino’s, [2014](#bib.bib12))
  id: totrans-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “Domino’s pizza 创建了‘Dom’，一个虚拟的订购助手。Dom 的形象友好且高效，体现了品牌对便捷和快速服务的关注。Dom 允许客户使用对话语言来订购披萨，使过程更加有趣，同时与
    Domino’s 对于创新配送和客户服务的承诺相一致。” (Domino’s, [2014](#bib.bib12))
- en: A well-defined persona ensures that the agent’s communication style and tone
    are consistent with the brand’s identity, fostering a stronger and more coherent
    brand image. This alignment is essential not only for maintaining brand consistency
    but also for creating a more engaging and relatable experience for users. In an
    environment where many companies employ similar technologies, a distinctive persona
    can significantly set a brand apart, making it more memorable and appealing to
    customers. This unique identity helps in building customer loyalty and establishing
    a competitive edge.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 明确的形象确保了助手的沟通风格和语调与品牌身份一致，从而培养出更强大且连贯的品牌形象。这种一致性对于维护品牌一致性以及为用户创造更具吸引力和相关性的体验至关重要。在许多公司使用类似技术的环境中，一个独特的形象可以显著区分品牌，使其更加难忘和吸引客户。这种独特的身份有助于建立客户忠诚度，并建立竞争优势。
- en: 4\. Challenges and Caveats
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 挑战与警示
- en: 4.1\. Consistency Is the Top Priority
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1\. 一致性是首要任务
- en: 'The primary objective in the design of CAs is to establish and nurture a robust
    connection with users, facilitating ongoing engagement over extended periods (Shum
    et al., [2018](#bib.bib43)). Achieving this necessitates the ability of the CAs
    to engage in sustained, meaningful conversations (Yan et al., [2016](#bib.bib54);
    Song et al., [2019](#bib.bib44)). Recent findings (García-Ferrero et al., [2023](#bib.bib14);
    Sclar et al., [2023](#bib.bib41)) indicated that LLM-based CAs exhibit a heightened
    sensitivity to subtle and sensitive words within the context, leading to inconsistent
    outputs. This characteristic has raised concerns about the ability of LLM-based
    CAs to maintain a consistent persona⁴⁴4Consistency and coherency: Consistency
    means whether elements of persona remain unchanged throughout the conversation,
    e.g. you can not be a kid in one turn while talking like an old person in another.
    Coherency refers more to whether the persona elements are coherent, e.g. you can
    not say something like ”I went on a trip with my wife for my 5-year-old birthday”.
    Consistency cares more about persona across different turns, i.e. evolution across
    time and can only be defined for multi-turn dialogue. throughout multiple dialogue
    exchanges (Li et al., [2015](#bib.bib26); Jiang et al., [2023](#bib.bib18)). This
    observation underscores the challenge of ensuring that these AI systems not only
    understand and process language effectively but also retain a consistent and contextually
    appropriate persona over successive interactions. Moreover, as discovered in (Vinyals
    and Le, [2015](#bib.bib50)), having inconsistency of persona is one of the major
    obstacles in achieving the long-term objective of developing human-like CAs to
    pass the Turing test (Turing, [2009](#bib.bib49)) Addressing this issue is critical
    in enhancing the reliability and user trust in conversational AI technologies (Lessio
    and Morris, [2020](#bib.bib25); Moussawi and Benbunan-Fich, [2021](#bib.bib34)).'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: CAs 设计的主要目标是建立并培养与用户之间的强大联系，从而促进长期的互动（Shum et al., [2018](#bib.bib43)）。实现这一目标需要
    CAs 能够进行持续且有意义的对话（Yan et al., [2016](#bib.bib54); Song et al., [2019](#bib.bib44)）。最近的研究（García-Ferrero
    et al., [2023](#bib.bib14); Sclar et al., [2023](#bib.bib41)）表明，基于LLM的 CAs 对上下文中的细微和敏感词表现出较高的敏感性，导致输出不一致。这一特征引发了对基于LLM的
    CAs 在多次对话中保持一致人物角色的能力的担忧。这个观察突显了确保这些人工智能系统不仅有效理解和处理语言，还能在连续互动中保持一致且符合上下文的角色的挑战。此外，正如（Vinyals
    and Le, [2015](#bib.bib50)）所发现的，人物角色的不一致性是实现开发类人 CAs 通过图灵测试的长期目标的主要障碍之一（Turing,
    [2009](#bib.bib49)）。解决这个问题对于提升对话 AI 技术的可靠性和用户信任至关重要（Lessio and Morris, [2020](#bib.bib25);
    Moussawi and Benbunan-Fich, [2021](#bib.bib34)）。
- en: Unfortunately, most widely-used LLMs struggle to align responses consistently
    with latent persona attributes (Shu et al., [2023](#bib.bib42)). This inconsistency
    is particularly evident in complex tests, like reversing question meanings using
    negation. Only two out of fifteen models tested in this paper, achieved some level
    of consistency (Shu et al., [2023](#bib.bib42)), highlighting the need for further
    development to enhance persona consistency in LLM responses.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，大多数广泛使用的大型语言模型（LLMs）在与潜在人物特征保持一致的回应方面存在困难（Shu et al., [2023](#bib.bib42)）。这种不一致在复杂测试中尤为明显，例如使用否定词反转问题含义。本文测试的十五个模型中仅有两个达到了某种程度的一致性（Shu
    et al., [2023](#bib.bib42)），这突显了进一步发展以增强LLM回应中人物一致性的必要性。
- en: 4.2\. Are There Effective Ways to Evaluate Persona and Its Consistency?
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2. 是否存在有效的方法来评估人物角色及其一致性？
- en: So far, a systematic approach to evaluate and verify persona application in
    LLM-based CAs has not been established. However, there exists some noteworthy
    attempts, such as employing empirical frameworks for indirectly assessing the
    persona of CAs (Safdari et al., [2023](#bib.bib40); Shu et al., [2023](#bib.bib42);
    Hagendorff, [2023](#bib.bib15)). This can be achieved through psychometric testing
    or by analyzing survey results.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，还没有建立系统化的方法来评估和验证基于LLM的 CAs 中人物角色的应用。然而，存在一些值得注意的尝试，例如采用经验框架间接评估 CAs 的人物角色（Safdari
    et al., [2023](#bib.bib40); Shu et al., [2023](#bib.bib42); Hagendorff, [2023](#bib.bib15)）。这可以通过心理测量测试或分析调查结果来实现。
- en: It appears that one cannot ascertain the specific persona a LLM-based CA is
    exhibiting simply by prompting queries such as ”what is your persona” or ”describe
    your persona.” Consider a scenario where an LLM-based CA is programmed or processed
    to embody a certain persona. The reality is, people cannot exhaustively enumerate
    all the traits of this persona, leaving room for the CA to exhibit some degree
    of self-expression in its responses. Moreover, the inherent unpredictability of
    the LLM adds a layer of complexity. For instance, the CA might be defined as ”a
    21-year-old physics student from Canada with a particular temperament…” but these
    specifications are insufficient to confine it to a specific character or individual.
    For example, in one interaction round, the LLM-based CA may fit this description
    but have a preference for bowling, while in the next round, it might have the
    same foundational characteristics but prefer skiing. In this situation, its persona
    has changed, yet such changes are subtle and challenging to detect and define.
    We can only ascertain their adherence to our initial constraints through certain
    predetermined questions. The CA might perfectly execute the task, but when asked
    about other aspects, like hobbies, it might reveal inconsistencies. Such situations
    are unpredictable and difficult to capture.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 似乎无法通过询问“你有什么个性”或“描述你的个性”等问题来确定基于LLM的聊天助手所展现的具体个性。考虑一个场景，其中一个基于LLM的聊天助手被编程或处理成体现某种个性。现实是，人们无法穷尽这种个性的所有特征，这使得聊天助手在其回应中展示某种程度的自我表达成为可能。此外，LLM的固有不可预测性增加了复杂性。例如，聊天助手可能被定义为“一个来自加拿大的21岁物理学学生，具有特定的性格……”但这些规格不足以将其限制为特定的角色或个人。例如，在一次互动中，基于LLM的聊天助手可能符合这一描述，但偏好保龄球，而在下一次互动中，它可能具有相同的基本特征，但偏好滑雪。在这种情况下，其个性发生了变化，但这种变化细微且难以察觉和定义。我们只能通过某些预设问题来确定它们是否遵守我们的初始约束。聊天助手可能完美地执行任务，但当被问及其他方面如爱好时，可能会揭示出不一致性。这种情况是不可预测的，也很难捕捉。
- en: Moreover, we acknowledge that individual perceptions of a system’s persona can
    vary. For instance, a chatbot with a female-like voice might be considered by
    someone as sufficiently demonstrating a persona. This variability poses challenges
    in establishing a universally accepted standard for assessing a system’s capability
    to exhibit a persona.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们承认对系统个性的个人感知可能会有所不同。例如，一个具有女性声音的聊天机器人可能会被某些人认为足以展示一种个性。这种变异性在建立一个普遍接受的评估系统表现个性的标准时提出了挑战。
- en: 4.3\. More than Persona
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3\. 超越个性
- en: This point becomes particularly prominent in our discussion about endowing ”characters”
    with the ability to play different domain experts in LLM-based CAs. We believe
    that for CAs to successfully assume the required roles, it is essential to impart
    not only fundamental character traits such as demographics, age, and gender but
    also corresponding knowledge. Characters must also be equipped with professional
    knowledge that aligns with their identities. For example, a character role as
    an ophthalmologist should be familiar with basic ophthalmology as well as be able
    to fluently address complex questions about eye diseases. Similarly, a character
    claiming to be a judge should be acquainted with basic legal statutes. Moreover,
    effective role-playing entails not just possessing knowledge but also the ability
    to adapt responses according to different contexts. For instance, when asking
    a business consultant character about market trends, it should be capable of considering
    the current economic environment and specific industry dynamics to provide informed
    responses. This approach elevates that researchers should always think more than
    just persona. In designing and implementing these roles, careful consideration
    must be given to their expertise and adaptability to ensure their effectiveness
    and credibility in their respective fields.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们讨论如何赋予“角色”在基于LLM的对话代理（CAs）中扮演不同领域专家的能力时，这一点尤为突出。我们认为，为了使CAs成功地承担所需的角色，除了传授基本的角色特征如人口统计学、年龄和性别，还必须传授相应的知识。角色还必须具备与其身份相匹配的专业知识。例如，作为眼科医生的角色应该熟悉基础的眼科学，并能够流利地回答有关眼病的复杂问题。类似地，声称自己是法官的角色应熟悉基本的法律法规。此外，有效的角色扮演不仅需要具备知识，还需要能够根据不同的上下文调整回应。例如，当询问商业顾问角色有关市场趋势的问题时，它应能够考虑当前的经济环境和特定行业动态，以提供有根据的回应。这种方法提升了研究者们应该不仅仅考虑角色的要求。在设计和实施这些角色时，必须认真考虑他们的专业知识和适应能力，以确保他们在各自领域中的有效性和可信度。
- en: Hallucination, as one of the crucial caveats in most LLMs, will trigger new
    problems in persona-based LLMs. Persona-based LLMs may hold the wrong belief in
    certain facts about themselves, e.g. occupation and social relationships. Current
    hallucination detection or evaluation methods depend on fixed non-persona-based
    datasets or uncertainty and inconsistency measures(Manakul et al., [2023](#bib.bib30);
    Sun et al., [2024](#bib.bib46)). However, in persona-based LLMs, such beliefs,
    once established, tend to remain consistent where the model is confident. Therefore,
    high self-consistency in persona-based LLMs requires more customised hallucination
    detection and prevention approaches to be developed.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 幻觉作为大多数大型语言模型（LLMs）中的一个重要警示，会在基于角色的LLMs中引发新的问题。基于角色的LLMs可能会对自己在某些事实上持有错误的信念，例如职业和社会关系。当前的幻觉检测或评估方法依赖于固定的非角色基础数据集或不确定性和不一致性衡量方法（Manakul
    et al., [2023](#bib.bib30); Sun et al., [2024](#bib.bib46)）。然而，在基于角色的LLMs中，这些信念一旦建立，就倾向于在模型自信的情况下保持一致。因此，基于角色的LLMs中的高度自洽性需要开发更多定制化的幻觉检测和预防方法。
- en: 4.4\. Ethical Considerations
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4\. 伦理考虑
- en: As with any AI-based technology, integrating personas into LLM-based CAs presents
    a dual-edged sword. It offers significant benefits but can also harbor potential
    risks. The use of such technology inevitably necessitates careful consideration
    of ethical issues. Potential harms include, but are not limited to, the ethics
    of deception and the reinforcement of societal stereotypes. We encourage our audience
    to refer to the provocation paper (Pradhan and Lazar, [2021](#bib.bib37)) for
    a more comprehensive discussion on the ethical considerations surrounding the
    use of personas in these systems. Here we refrain from redundant elaboration of
    previously stated points.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 与任何基于AI的技术一样，将角色整合到基于LLM的CAs中既是一把双刃剑。它带来了显著的好处，但也可能存在潜在的风险。使用此类技术不可避免地需要仔细考虑伦理问题。潜在的危害包括但不限于欺骗的伦理和社会刻板印象的强化。我们鼓励读者参阅挑衅性论文（Pradhan
    and Lazar, [2021](#bib.bib37)）以获取关于在这些系统中使用角色的伦理考虑的更全面讨论。我们在这里避免对之前陈述的要点进行冗余的阐述。
- en: 5\. Conclusion
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 结论
- en: In integrating persona into LLM-based CAs, this provocation highlights the significance
    of persona to enhance human-like interactions. It covers the criticality of various
    applications, and meanwhile puts forward challenges in achieving persona consistency
    and domain-specific adaptability. In conclusion, although the prospect of creating
    CAs with high effectiveness and human resemblance is promising, prioritizing ethical
    standards and tackling technical challenges is essential. Future efforts must
    aim for responsible development that maximizes the benefits of persona integration
    while addressing its complexities.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在将人格整合到基于LLM的CA中时，这一挑战突出了人格对增强类人交互的重要性。它涵盖了各种应用的关键性，同时提出了在实现人格一致性和领域特定适应性方面的挑战。总之，尽管创造高效且类人的CA的前景是令人期待的，但优先考虑伦理标准和解决技术挑战至关重要。未来的努力必须以负责任的开发为目标，最大化人格整合的好处，同时解决其复杂性。
- en: Acknowledgements.
  id: totrans-56
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 致谢
- en: 'We thank CUI’s anonymous reviewers for their constructive comments on previous
    drafts of this paper. This research was partially funded by EPSRC under grant
    *SAIS: Secure AI assistantS* (EP/T026723/1) and by the INCIBE’s strategic SPRINT
    (Seguridad y Privacidad en Sistemas con Inteligencia Artificial) C063/23 project
    with funds from the EU-NextGenerationEU through the Spanish government’s Plan
    de Recuperación, Transformación y Resiliencia.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '我们感谢CUI的匿名审稿人对本论文前期草稿的建设性意见。本研究部分由EPSRC资助，资助编号为*SAIS: Secure AI assistantS*
    (EP/T026723/1)，以及由INCIBE的战略SPRINT (Seguridad y Privacidad en Sistemas con Inteligencia
    Artificial) C063/23项目资助，资金来自于EU-NextGenerationEU，通过西班牙政府的Plan de Recuperación,
    Transformación y Resiliencia。'
- en: References
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: Aher et al. (2023) Gati V Aher, Rosa I Arriaga, and Adam Tauman Kalai. 2023.
    Using large language models to simulate multiple humans and replicate human subject
    studies. In *International Conference on Machine Learning*. PMLR, 337–371.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Aher等（2023）Gati V Aher, Rosa I Arriaga, 和 Adam Tauman Kalai。2023年。利用大型语言模型模拟多个个体并复制人类受试研究。在*国际机器学习会议*上。PMLR，第337–371页。
- en: 'Argyle et al. (2023) Lisa P Argyle, Ethan C Busby, Nancy Fulda, Joshua R Gubler,
    Christopher Rytting, and David Wingate. 2023. Out of one, many: Using language
    models to simulate human samples. *Political Analysis* 31, 3 (2023), 337–351.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Argyle等（2023）Lisa P Argyle, Ethan C Busby, Nancy Fulda, Joshua R Gubler, Christopher
    Rytting, 和 David Wingate。2023年。出自一体，众多：利用语言模型模拟人类样本。*政治分析* 31, 3 (2023), 第337–351页。
- en: Bickmore et al. (2010) Timothy W Bickmore, Suzanne E Mitchell, Brian W Jack,
    Michael K Paasche-Orlow, Laura M Pfeifer, and Julie O’Donnell. 2010. Response
    to a relational agent by hospital patients with depressive symptoms. *Interacting
    with computers* 22, 4 (2010), 289–298.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bickmore等（2010）Timothy W Bickmore, Suzanne E Mitchell, Brian W Jack, Michael
    K Paasche-Orlow, Laura M Pfeifer, 和 Julie O’Donnell。2010年。医院患者对关系型代理的反应。*与计算机互动*
    22, 4 (2010), 第289–298页。
- en: Briggs (1987) Katharine Cook Briggs. 1987. *Myers-Briggs type indicator*. G.
    Palo Alto, Calif. :Consulting Psychologists Press.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Briggs（1987）Katharine Cook Briggs。1987年。*迈尔斯-布里格斯类型指标*。G. Palo Alto, Calif.
    :Consulting Psychologists Press。
- en: Butler (2023) Sydeney Butler. 2023. How to Create ChatGPT Personas for Every
    Occasion. Retrieved January 2024 from [https://www.howtogeek.com/881659/how-to-create-chatgpt-personas-for-every-occasion/](https://www.howtogeek.com/881659/how-to-create-chatgpt-personas-for-every-occasion/)
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Butler（2023）Sydeney Butler。2023年。如何为各种场合创建ChatGPT人格。2024年1月取自[https://www.howtogeek.com/881659/how-to-create-chatgpt-personas-for-every-occasion/](https://www.howtogeek.com/881659/how-to-create-chatgpt-personas-for-every-occasion/)
- en: 'Cascella et al. (2023) Marco Cascella, Jonathan Montomoli, Valentina Bellini,
    and Elena Bignami. 2023. Evaluating the feasibility of ChatGPT in healthcare:
    an analysis of multiple clinical and research scenarios. *Journal of Medical Systems*
    47, 1 (2023), 33.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cascella等（2023）Marco Cascella, Jonathan Montomoli, Valentina Bellini, 和 Elena
    Bignami。2023年。评估ChatGPT在医疗中的可行性：对多个临床和研究场景的分析。*医学系统杂志* 47, 1 (2023), 第33页。
- en: 'Chan et al. (2023) Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue,
    Shanghang Zhang, Jie Fu, and Zhiyuan Liu. 2023. Chateval: Towards better llm-based
    evaluators through multi-agent debate. *arXiv preprint arXiv:2308.07201* (2023).'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chan等（2023）Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang
    Zhang, Jie Fu, 和 Zhiyuan Liu。2023年。Chateval：通过多代理辩论实现更好的基于LLM的评估工具。*arXiv预印本 arXiv:2308.07201*
    (2023)。
- en: 'Danielescu and Christian (2018) Andreea Danielescu and Gwen Christian. 2018.
    A bot is not a polyglot: Designing personalities for multi-lingual conversational
    agents. In *Extended Abstracts of the 2018 CHI Conference on Human Factors in
    Computing Systems*. 1–9.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Danielescu 和 Christian (2018) Andreea Danielescu 和 Gwen Christian. 2018. 机器人不是多语言者：为多语言对话代理设计个性。见于*2018
    CHI 人机交互系统会议扩展摘要*。1–9。
- en: Dasgupta et al. (2022) Ishita Dasgupta, Andrew K Lampinen, Stephanie CY Chan,
    Antonia Creswell, Dharshan Kumaran, James L McClelland, and Felix Hill. 2022.
    Language models show human-like content effects on reasoning. *arXiv preprint
    arXiv:2207.07051* (2022).
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dasgupta et al. (2022) Ishita Dasgupta, Andrew K Lampinen, Stephanie CY Chan,
    Antonia Creswell, Dharshan Kumaran, James L McClelland, 和 Felix Hill. 2022. 语言模型显示出类似人类的内容效应对推理的影响。*arXiv
    预印本 arXiv:2207.07051* (2022)。
- en: 'Deshpande et al. (2023) Ameet Deshpande, Vishvak Murahari, Tanmay Rajpurohit,
    Ashwin Kalyan, and Karthik Narasimhan. 2023. Toxicity in chatgpt: Analyzing persona-assigned
    language models. *arXiv preprint arXiv:2304.05335* (2023).'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deshpande et al. (2023) Ameet Deshpande, Vishvak Murahari, Tanmay Rajpurohit,
    Ashwin Kalyan, 和 Karthik Narasimhan. 2023. ChatGPT中的毒性：分析角色分配的语言模型。*arXiv 预印本
    arXiv:2304.05335* (2023)。
- en: 'Domino’s (2014) Domino’s. 2014. MEET DOM: THE VIRTUAL VOICE ORDERING ASSISTANT
    FOR DOMINO’S PIZZA. Retrieved April 7, 2024 from [https://ir.dominos.com/news-releases/news-release-details/meet-dom-virtual-voice-ordering-assistant-dominos-pizzar](https://ir.dominos.com/news-releases/news-release-details/meet-dom-virtual-voice-ordering-assistant-dominos-pizzar)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Domino’s (2014) Domino’s. 2014. 认识 DOM：DOMINO’S PIZZA 的虚拟语音订购助手。 retrieved April
    7, 2024 from [https://ir.dominos.com/news-releases/news-release-details/meet-dom-virtual-voice-ordering-assistant-dominos-pizzar](https://ir.dominos.com/news-releases/news-release-details/meet-dom-virtual-voice-ordering-assistant-dominos-pizzar)
- en: Durmus et al. (2023) Esin Durmus, Karina Nyugen, Thomas I Liao, Nicholas Schiefer,
    Amanda Askell, Anton Bakhtin, Carol Chen, Zac Hatfield-Dodds, Danny Hernandez,
    Nicholas Joseph, et al. 2023. Towards measuring the representation of subjective
    global opinions in language models. *arXiv preprint arXiv:2306.16388* (2023).
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Durmus et al. (2023) Esin Durmus, Karina Nyugen, Thomas I Liao, Nicholas Schiefer,
    Amanda Askell, Anton Bakhtin, Carol Chen, Zac Hatfield-Dodds, Danny Hernandez,
    Nicholas Joseph, 等. 2023. 迈向测量语言模型中主观全球观点的表示。*arXiv 预印本 arXiv:2306.16388* (2023)。
- en: 'García-Ferrero et al. (2023) Iker García-Ferrero, Begoña Altuna, Javier Álvez,
    Itziar Gonzalez-Dios, and German Rigau. 2023. This is not a Dataset: A Large Negation
    Benchmark to Challenge Large Language Models. *arXiv preprint arXiv:2310.15941*
    (2023).'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: García-Ferrero et al. (2023) Iker García-Ferrero, Begoña Altuna, Javier Álvez,
    Itziar Gonzalez-Dios, 和 German Rigau. 2023. 这不是一个数据集：一个大型否定基准来挑战大型语言模型。*arXiv
    预印本 arXiv:2310.15941* (2023)。
- en: 'Hagendorff (2023) Thilo Hagendorff. 2023. Machine psychology: Investigating
    emergent capabilities and behavior in large language models using psychological
    methods. *arXiv preprint arXiv:2303.13988* (2023).'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hagendorff (2023) Thilo Hagendorff. 2023. 机器心理学：使用心理学方法调查大型语言模型中的新兴能力和行为。*arXiv
    预印本 arXiv:2303.13988* (2023)。
- en: 'Hagendorff et al. (2022) Thilo Hagendorff, Sarah Fabi, and Michal Kosinski.
    2022. Machine intuition: Uncovering human-like intuitive decision-making in GPT-3.5.
    *arXiv preprint arXiv:2212.05206* (2022).'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hagendorff et al. (2022) Thilo Hagendorff, Sarah Fabi, 和 Michal Kosinski. 2022.
    机器直觉：揭示 GPT-3.5 中类似人类的直观决策。*arXiv 预印本 arXiv:2212.05206* (2022)。
- en: Hwang et al. (2021) Youjin Hwang, Donghoon Shin, Sion Baek, Bongwon Suh, and
    Joonhwan Lee. 2021. Applying the persona of user’s family member and the doctor
    to the conversational agents for healthcare. *arXiv preprint arXiv:2109.01729*
    (2021).
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hwang et al. (2021) Youjin Hwang, Donghoon Shin, Sion Baek, Bongwon Suh, 和 Joonhwan
    Lee. 2021. 将用户家庭成员和医生的角色应用于医疗对话代理。*arXiv 预印本 arXiv:2109.01729* (2021)。
- en: 'Jiang et al. (2023) Hang Jiang, Xiajie Zhang, Xubo Cao, Jad Kabbara, and Deb
    Roy. 2023. Personallm: Investigating the ability of gpt-3.5 to express personality
    traits and gender differences. *arXiv preprint arXiv:2305.02547* (2023).'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang et al. (2023) Hang Jiang, Xiajie Zhang, Xubo Cao, Jad Kabbara, 和 Deb Roy.
    2023. Personallm：调查 GPT-3.5 表达个性特征和性别差异的能力。*arXiv 预印本 arXiv:2305.02547* (2023)。
- en: Kim et al. (2019) Hankyung Kim, Dong Yoon Koh, Gaeun Lee, Jung-Mi Park, and
    Youn-kyung Lim. 2019. Designing personalities of conversational agents. In *Extended
    Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems*. 1–6.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim et al. (2019) Hankyung Kim, Dong Yoon Koh, Gaeun Lee, Jung-Mi Park, 和 Youn-kyung
    Lim. 2019. 设计对话代理的个性。见于*2019 CHI 人机交互系统会议扩展摘要*。1–6。
- en: Kohnke et al. (2023) Lucas Kohnke, Benjamin Luke Moorhouse, and Di Zou. 2023.
    ChatGPT for language teaching and learning. *RELC Journal* (2023), 00336882231162868.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kohnke et al. (2023) Lucas Kohnke, Benjamin Luke Moorhouse, 和 Di Zou. 2023.
    ChatGPT 在语言教学和学习中的应用。*RELC Journal* (2023), 00336882231162868。
- en: Kong et al. (2023) Aobo Kong, Shiwan Zhao, Hao Chen, Qicheng Li, Yong Qin, Ruiqi
    Sun, and Xin Zhou. 2023. Better zero-shot reasoning with role-play prompting.
    *arXiv preprint arXiv:2308.07702* (2023).
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kong et al. (2023) Aobo Kong, Shiwan Zhao, Hao Chen, Qicheng Li, Yong Qin, Ruiqi
    Sun, 和 Xin Zhou. 2023. 更好的零样本推理与角色扮演提示。*arXiv 预印本 arXiv:2308.07702* (2023)。
- en: Lai et al. (2023) Tin Lai, Yukun Shi, Zicong Du, Jiajie Wu, Ken Fu, Yichao Dou,
    and Ziqi Wang. 2023. Supporting the Demand on Mental Health Services with AI-Based
    Conversational Large Language Models (LLMs). *BioMedInformatics* 4, 1 (2023),
    8–33.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lai et al. (2023) Tin Lai, Yukun Shi, Zicong Du, Jiajie Wu, Ken Fu, Yichao Dou,
    和 Ziqi Wang. 2023. 通过基于AI的对话大型语言模型（LLMs）支持心理健康服务的需求。*BioMedInformatics* 4, 1 (2023)，8–33。
- en: 'Lakkaraju et al. (2023a) Kausik Lakkaraju, Sara E Jones, Sai Krishna Revanth
    Vuruma, Vishal Pallagani, Bharath C Muppasani, and Biplav Srivastava. 2023a. LLMs
    for Financial Advisement: A Fairness and Efficacy Study in Personal Decision Making.
    In *4th ACM International Conference on AI in Finance*. 100–107.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lakkaraju et al. (2023a) Kausik Lakkaraju, Sara E Jones, Sai Krishna Revanth
    Vuruma, Vishal Pallagani, Bharath C Muppasani, 和 Biplav Srivastava. 2023a. LLMs
    在财务顾问中的应用：个人决策中的公平性和有效性研究。在 *第4届 ACM 国际金融人工智能会议*。100–107。
- en: 'Lakkaraju et al. (2023b) Kausik Lakkaraju, Sai Krishna Revanth Vuruma, Vishal
    Pallagani, Bharath Muppasani, and Biplav Srivastava. 2023b. Can LLMs be Good Financial
    Advisors?: An Initial Study in Personal Decision Making for Optimized Outcomes.
    *arXiv preprint arXiv:2307.07422* (2023).'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lakkaraju et al. (2023b) Kausik Lakkaraju, Sai Krishna Revanth Vuruma, Vishal
    Pallagani, Bharath Muppasani, 和 Biplav Srivastava. 2023b. LLMs 可以成为优秀的财务顾问吗？：个人决策优化结果的初步研究。*arXiv
    预印本 arXiv:2307.07422* (2023)。
- en: Lessio and Morris (2020) Nadine Lessio and Alexis Morris. 2020. Toward Design
    Archetypes for Conversational Agent Personality. In *2020 IEEE International Conference
    on Systems, Man, and Cybernetics (SMC)*. IEEE, 3221–3228.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lessio and Morris (2020) Nadine Lessio 和 Alexis Morris. 2020. 朝着对话代理个性的设计原型迈进。在
    *2020 IEEE国际系统、人和控制会议（SMC）*。IEEE，3221–3228。
- en: Li et al. (2015) Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and
    Bill Dolan. 2015. A diversity-promoting objective function for neural conversation
    models. *arXiv preprint arXiv:1510.03055* (2015).
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. (2015) Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, 和 Bill
    Dolan. 2015. 用于神经对话模型的多样性促进目标函数。*arXiv 预印本 arXiv:1510.03055* (2015)。
- en: Li et al. (2016) Jiwei Li, Michel Galley, Chris Brockett, Georgios P Spithourakis,
    Jianfeng Gao, and Bill Dolan. 2016. A persona-based neural conversation model.
    *arXiv preprint arXiv:1603.06155* (2016).
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. (2016) Jiwei Li, Michel Galley, Chris Brockett, Georgios P Spithourakis,
    Jianfeng Gao, 和 Bill Dolan. 2016. 基于角色的神经对话模型。*arXiv 预印本 arXiv:1603.06155* (2016)。
- en: Liao and He (2020) Yuting Liao and Jiangen He. 2020. Racial mirroring effects
    on human-agent interaction in psychotherapeutic conversations. In *Proceedings
    of the 25th international conference on intelligent user interfaces*. 430–442.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liao and He (2020) Yuting Liao 和 Jiangen He. 2020. 种族镜像效应在心理治疗对话中的人机互动。在 *第25届国际智能用户界面会议论文集*。430–442。
- en: 'Liu et al. (2022) Junfeng Liu, Christopher Symons, and Ranga Raju Vatsavai.
    2022. Persona-Based Conversational AI: State of the Art and Challenges. In *2022
    IEEE International Conference on Data Mining Workshops (ICDMW)*. IEEE, 993–1001.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2022) Junfeng Liu, Christopher Symons, 和 Ranga Raju Vatsavai. 2022.
    基于角色的对话式人工智能：现状与挑战。在 *2022 IEEE国际数据挖掘会议研讨会（ICDMW）*。IEEE，993–1001。
- en: 'Manakul et al. (2023) Potsawee Manakul, Adian Liusie, and Mark J. F. Gales.
    2023. SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative
    Large Language Models.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Manakul et al. (2023) Potsawee Manakul, Adian Liusie, 和 Mark J. F. Gales. 2023.
    SelfCheckGPT：零资源黑箱幻觉检测用于生成大型语言模型。
- en: 'Markel et al. (2023) Julia M Markel, Steven G Opferman, James A Landay, and
    Chris Piech. 2023. GPTeach: Interactive TA Training with GPT Based Students. (2023).'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Markel et al. (2023) Julia M Markel, Steven G Opferman, James A Landay, 和 Chris
    Piech. 2023. GPTeach：与 GPT 基于学生的互动 TA 培训。(2023)。
- en: Mbakwe et al. (2023) Amarachi B Mbakwe, Ismini Lourentzou, Leo Anthony Celi,
    Oren J Mechanic, and Alon Dagan. 2023. ChatGPT passing USMLE shines a spotlight
    on the flaws of medical education. , e0000205 pages.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mbakwe et al. (2023) Amarachi B Mbakwe, Ismini Lourentzou, Leo Anthony Celi,
    Oren J Mechanic, 和 Alon Dagan. 2023. ChatGPT 通过 USMLE 突显了医学教育的缺陷。 ，e0000205 页。
- en: McFarland (2023) Alex McFarland. 2023. What is a ChatGPT Persona? Retrieved
    January 2024 from [https://www.unite.ai/what-is-a-chatgpt-persona/](https://www.unite.ai/what-is-a-chatgpt-persona/)
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: McFarland (2023) Alex McFarland. 2023. 什么是 ChatGPT 人物？从 [https://www.unite.ai/what-is-a-chatgpt-persona/](https://www.unite.ai/what-is-a-chatgpt-persona/)
    检索于 2024 年 1 月。
- en: Moussawi and Benbunan-Fich (2021) Sara Moussawi and Raquel Benbunan-Fich. 2021.
    The effect of voice and humour on users’ perceptions of personal intelligent agents.
    *Behaviour & Information Technology* 40, 15 (2021), 1603–1626.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Moussawi 和 Benbunan-Fich（2021）Sara Moussawi 和 Raquel Benbunan-Fich。2021年。《语音和幽默对用户对个人智能代理感知的影响》。*行为与信息技术*
    40, 15（2021年），1603–1626页。
- en: 'Park et al. (2023) Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S Bernstein. 2023. Generative agents: Interactive
    simulacra of human behavior. In *Proceedings of the 36th Annual ACM Symposium
    on User Interface Software and Technology*. 1–22.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park 等（2023）Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel
    Morris, Percy Liang, 和 Michael S Bernstein。2023年。《生成代理：人类行为的互动模拟体》。见于 *第36届ACM用户界面软件与技术年会论文集*。1–22页。
- en: 'Park et al. (2022) Joon Sung Park, Lindsay Popowski, Carrie Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S Bernstein. 2022. Social simulacra: Creating
    populated prototypes for social computing systems. In *Proceedings of the 35th
    Annual ACM Symposium on User Interface Software and Technology*. 1–18.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park 等（2022）Joon Sung Park, Lindsay Popowski, Carrie Cai, Meredith Ringel Morris,
    Percy Liang, 和 Michael S Bernstein。2022年。《社交模拟体：为社交计算系统创建人口原型》。见于 *第35届ACM用户界面软件与技术年会论文集*。1–18页。
- en: Pradhan and Lazar (2021) Alisha Pradhan and Amanda Lazar. 2021. Hey Google,
    do you have a personality? Designing personality and personas for conversational
    agents. In *Proceedings of the 3rd Conference on Conversational User Interfaces*.
    1–4.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pradhan 和 Lazar（2021）Alisha Pradhan 和 Amanda Lazar。2021年。《嘿，谷歌，你有个性吗？为对话代理设计个性和角色》。见于
    *第3届对话用户界面会议论文集*。1–4页。
- en: 'Rashkin et al. (2018) Hannah Rashkin, Eric Michael Smith, Margaret Li, and
    Y-Lan Boureau. 2018. Towards empathetic open-domain conversation models: A new
    benchmark and dataset. *arXiv preprint arXiv:1811.00207* (2018).'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rashkin 等（2018）Hannah Rashkin, Eric Michael Smith, Margaret Li, 和 Y-Lan Boureau。2018年。《朝向具备同理心的开放领域对话模型：新的基准和数据集》。*arXiv
    预印本 arXiv:1811.00207*（2018年）。
- en: Roettgers (2019) Janko Roettgers. 2019. How Alexa Got Her Personality. Retrieved
    January 2024 from [https://variety.com/2019/digital/news/alexa-personality-amazon-echo-1203236019/](https://variety.com/2019/digital/news/alexa-personality-amazon-echo-1203236019/)
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Roettgers（2019）Janko Roettgers。2019年。《Alexa如何获得她的个性》。2024年1月从 [https://variety.com/2019/digital/news/alexa-personality-amazon-echo-1203236019/](https://variety.com/2019/digital/news/alexa-personality-amazon-echo-1203236019/)
    获取。
- en: Safdari et al. (2023) Mustafa Safdari, Greg Serapio-García, Clément Crepy, Stephen
    Fitz, Peter Romero, Luning Sun, Marwa Abdulhai, Aleksandra Faust, and Maja Matarić.
    2023. Personality traits in large language models. *arXiv preprint arXiv:2307.00184*
    (2023).
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Safdari 等（2023）Mustafa Safdari, Greg Serapio-García, Clément Crepy, Stephen
    Fitz, Peter Romero, Luning Sun, Marwa Abdulhai, Aleksandra Faust, 和 Maja Matarić。2023年。《大型语言模型中的个性特征》。*arXiv
    预印本 arXiv:2307.00184*（2023年）。
- en: 'Sclar et al. (2023) Melanie Sclar, Yejin Choi, Yulia Tsvetkov, and Alane Suhr.
    2023. Quantifying Language Models’ Sensitivity to Spurious Features in Prompt
    Design or: How I learned to start worrying about prompt formatting. *arXiv preprint
    arXiv:2310.11324* (2023).'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sclar 等（2023）Melanie Sclar, Yejin Choi, Yulia Tsvetkov, 和 Alane Suhr。2023年。《量化语言模型对伪特征的敏感性：如何开始担心提示格式》。*arXiv
    预印本 arXiv:2310.11324*（2023年）。
- en: 'Shu et al. (2023) Bangzhao Shu, Lechen Zhang, Minje Choi, Lavinia Dunagan,
    Dallas Card, and David Jurgens. 2023. You don’t need a personality test to know
    these models are unreliable: Assessing the Reliability of Large Language Models
    on Psychometric Instruments. *arXiv preprint arXiv:2311.09718* (2023).'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shu 等（2023）Bangzhao Shu, Lechen Zhang, Minje Choi, Lavinia Dunagan, Dallas Card,
    和 David Jurgens。2023年。《你不需要个性测试来知道这些模型不可靠：评估大型语言模型在心理测量工具上的可靠性》。*arXiv 预印本 arXiv:2311.09718*（2023年）。
- en: 'Shum et al. (2018) Heung-Yeung Shum, Xiao-dong He, and Di Li. 2018. From Eliza
    to XiaoIce: challenges and opportunities with social chatbots. *Frontiers of Information
    Technology & Electronic Engineering* 19 (2018), 10–26.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shum 等（2018）Heung-Yeung Shum, Xiao-dong He, 和 Di Li。2018年。《从Eliza到XiaoIce：社交聊天机器人面临的挑战与机遇》。*信息技术与电子工程前沿*
    19（2018年），10–26页。
- en: Song et al. (2019) Haoyu Song, Wei-Nan Zhang, Yiming Cui, Dong Wang, and Ting
    Liu. 2019. Exploiting persona information for diverse generation of conversational
    responses. *arXiv preprint arXiv:1905.12188* (2019).
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Song 等（2019）Haoyu Song, Wei-Nan Zhang, Yiming Cui, Dong Wang, 和 Ting Liu。2019年。《利用个性信息生成多样化对话回应》。*arXiv
    预印本 arXiv:1905.12188*（2019年）。
- en: Sordoni et al. (2015) Alessandro Sordoni, Michel Galley, Michael Auli, Chris
    Brockett, Yangfeng Ji, Margaret Mitchell, Jian-Yun Nie, Jianfeng Gao, and Bill
    Dolan. 2015. A neural network approach to context-sensitive generation of conversational
    responses. *arXiv preprint arXiv:1506.06714* (2015).
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sordoni et al. (2015) Alessandro Sordoni, Michel Galley, Michael Auli, Chris
    Brockett, Yangfeng Ji, Margaret Mitchell, Jian-Yun Nie, Jianfeng Gao, 和 Bill Dolan.
    2015. 一种用于上下文敏感对话响应生成的神经网络方法。*arXiv 预印本 arXiv:1506.06714* (2015)。
- en: 'Sun et al. (2024) Guangzhi Sun, Potsawee Manakul, Adian Liusie, Kunat Pipatanakul,
    Chao Zhang, Phil Woodland, and Mark Gales. 2024. CrossCheckGPT: Universal Hallucination
    Ranking for Multimodal Foundation Models. *arXiv:2405.13684* (2024).'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Sun et al. (2024) Guangzhi Sun, Potsawee Manakul, Adian Liusie, Kunat Pipatanakul,
    Chao Zhang, Phil Woodland, 和 Mark Gales. 2024. CrossCheckGPT: 多模态基础模型的通用幻觉排名。*arXiv:2405.13684*
    (2024)。'
- en: Sutcliffe (2023) Richard Sutcliffe. 2023. A Survey of Personality, Persona,
    and Profile in Conversational Agents and Chatbots. arXiv:2401.00609 [cs.CL]
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sutcliffe (2023) Richard Sutcliffe. 2023. 对话代理和聊天机器人中的个性、角色和档案的调查。arXiv:2401.00609
    [cs.CL]
- en: Thirunavukarasu et al. (2023) Arun James Thirunavukarasu, Darren Shu Jeng Ting,
    Kabilan Elangovan, Laura Gutierrez, Ting Fang Tan, and Daniel Shu Wei Ting. 2023.
    Large language models in medicine. *Nature medicine* 29, 8 (2023), 1930–1940.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Thirunavukarasu et al. (2023) Arun James Thirunavukarasu, Darren Shu Jeng Ting,
    Kabilan Elangovan, Laura Gutierrez, Ting Fang Tan, 和 Daniel Shu Wei Ting. 2023.
    医学中的大型语言模型。*自然医学* 29, 8 (2023), 1930–1940。
- en: Turing (2009) Alan M Turing. 2009. *Computing machinery and intelligence*. Springer.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Turing (2009) Alan M Turing. 2009. *计算机器与智能*。Springer。
- en: Vinyals and Le (2015) Oriol Vinyals and Quoc Le. 2015. A neural conversational
    model. *arXiv preprint arXiv:1506.05869* (2015).
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vinyals and Le (2015) Oriol Vinyals 和 Quoc Le. 2015. 神经对话模型。*arXiv 预印本 arXiv:1506.05869*
    (2015)。
- en: White et al. (2023) Jules White, Quchen Fu, Sam Hays, Michael Sandborn, Carlos
    Olea, Henry Gilbert, Ashraf Elnashar, Jesse Spencer-Smith, and Douglas C Schmidt.
    2023. A prompt pattern catalog to enhance prompt engineering with chatgpt. *arXiv
    preprint arXiv:2302.11382* (2023).
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: White et al. (2023) Jules White, Quchen Fu, Sam Hays, Michael Sandborn, Carlos
    Olea, Henry Gilbert, Ashraf Elnashar, Jesse Spencer-Smith, 和 Douglas C Schmidt.
    2023. 用于增强 ChatGPT 提示工程的提示模式目录。*arXiv 预印本 arXiv:2302.11382* (2023)。
- en: 'Wu et al. (2023) Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark
    Dredze, Sebastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, and Gideon Mann.
    2023. Bloomberggpt: A large language model for finance. *arXiv preprint arXiv:2303.17564*
    (2023).'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wu et al. (2023) Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark
    Dredze, Sebastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, 和 Gideon Mann.
    2023. Bloomberggpt: 用于金融的大型语言模型。*arXiv 预印本 arXiv:2303.17564* (2023)。'
- en: 'Xiao and Zhi (2023) Yangyu Xiao and Yuying Zhi. 2023. An exploratory study
    of EFL learners’ use of ChatGPT for language learning tasks: Experience and perceptions.
    *Languages* 8, 3 (2023), 212.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xiao and Zhi (2023) Yangyu Xiao 和 Yuying Zhi. 2023. EFL 学习者使用 ChatGPT 进行语言学习任务的探索性研究：经验和感知。*Languages*
    8, 3 (2023), 212。
- en: 'Yan et al. (2016) Xinchen Yan, Jimei Yang, Kihyuk Sohn, and Honglak Lee. 2016.
    Attribute2image: Conditional image generation from visual attributes. In *Computer
    Vision–ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October
    11–14, 2016, Proceedings, Part IV 14*. Springer, 776–791.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yan et al. (2016) Xinchen Yan, Jimei Yang, Kihyuk Sohn, 和 Honglak Lee. 2016.
    Attribute2image: 基于视觉属性的条件图像生成。*计算机视觉–ECCV 2016: 第14届欧洲会议，荷兰阿姆斯特丹，2016年10月11日至14日，论文集，第四部分*。Springer，776–791。'
- en: Yang (2019) Diyi Yang. 2019. *Computational Social Roles*. Ph. D. Dissertation.
    Carnegie Mellon University Pittsburgh, PA, USA.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang (2019) Diyi Yang. 2019. *计算社会角色*。博士论文。卡内基梅隆大学，匹兹堡，PA，美国。
- en: 'Zhang et al. (2018) Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam,
    Douwe Kiela, and Jason Weston. 2018. Personalizing dialogue agents: I have a dog,
    do you have pets too? *arXiv preprint arXiv:1801.07243* (2018).'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2018) Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam,
    Douwe Kiela, 和 Jason Weston. 2018. 个性化对话代理：我有一只狗，你也有宠物吗？*arXiv 预印本 arXiv:1801.07243*
    (2018)。
- en: Zhong et al. (2020) Peixiang Zhong, Chen Zhang, Hao Wang, Yong Liu, and Chunyan
    Miao. 2020. Towards persona-based empathetic conversational models. *arXiv preprint
    arXiv:2004.12316* (2020).
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhong et al. (2020) Peixiang Zhong, Chen Zhang, Hao Wang, Yong Liu, 和 Chunyan
    Miao. 2020. 面向基于角色的同理心对话模型。*arXiv 预印本 arXiv:2004.12316* (2020)。
- en: Zhou et al. (2020) Li Zhou, Jianfeng Gao, Di Li, and Heung-Yeung Shum. 2020.
    The design and implementation of xiaoice, an empathetic social chatbot. *Computational
    Linguistics* 46, 1 (2020), 53–93.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou et al. (2020) Li Zhou, Jianfeng Gao, Di Li, 和 Heung-Yeung Shum. 2020. 小冰的设计与实现，一款富有同理心的社交聊天机器人。*计算语言学*
    46, 1 (2020), 53–93。
- en: Zhou et al. (2022) Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster,
    Silviu Pitis, Harris Chan, and Jimmy Ba. 2022. Large language models are human-level
    prompt engineers. *arXiv preprint arXiv:2211.01910* (2022).
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou等人（2022年）Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster,
    Silviu Pitis, Harris Chan, 和 Jimmy Ba. 2022年. 大型语言模型是人类级别的提示工程师。*arXiv预印本 arXiv:2211.01910*（2022年）。
- en: 'Zhuo et al. (2023) Terry Yue Zhuo, Yujin Huang, Chunyang Chen, and Zhenchang
    Xing. 2023. Exploring ai ethics of chatgpt: A diagnostic analysis. *arXiv preprint
    arXiv:2301.12867* (2023).'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhuo等人（2023年）Terry Yue Zhuo, Yujin Huang, Chunyang Chen, 和 Zhenchang Xing. 2023年.
    探索ChatGPT的人工智能伦理：诊断分析。*arXiv预印本 arXiv:2301.12867*（2023年）。
