- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:53:33'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:53:33
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LLM助手学习代理建模编程：新手和专家使用ChatGPT与NetLogo Chat的经验
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2401.17163](https://ar5iv.labs.arxiv.org/html/2401.17163)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2401.17163](https://ar5iv.labs.arxiv.org/html/2401.17163)
- en: John Chen Northwestern UniversityEvanston, ILUnited States of America [civitas@u.northwestern.edu](mailto:civitas@u.northwestern.edu)
    ,  Xi Lu University of California, IrvineIrvine, CAUnited States of America [xlu30@uci.edu](mailto:xlu30@uci.edu)
    ,  David Du Northwestern UniversityEvanston, ILUnited States of America [duyuzhou2013@gmail.com](mailto:duyuzhou2013@gmail.com)
    ,  Michael Rejtig University of Massachusetts BostonBoston, MAUnited States of
    America [michael.rejtig001@umb.edu](mailto:michael.rejtig001@umb.edu) ,  Ruth
    Bagley Northwestern UniversityEvanston, ILUnited States of America [ruth.bagley@northwestern.edu](mailto:ruth.bagley@northwestern.edu)
    ,  Michael S. Horn Northwestern UniversityEvanston, ILUnited States of America
    [michael-horn@northwestern.edu](mailto:michael-horn@northwestern.edu)  and  Uri
    J. Wilensky Northwestern UniversityEvanston, ILUnited States of America [uri@northwestern.edu](mailto:uri@northwestern.edu)(2024;
    14 September 2023; 12 December 2023; 19 January 2024)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: John Chen Northwestern UniversityEvanston, ILUnited States of America [civitas@u.northwestern.edu](mailto:civitas@u.northwestern.edu)
    ,  Xi Lu University of California, IrvineIrvine, CAUnited States of America [xlu30@uci.edu](mailto:xlu30@uci.edu)
    ,  David Du Northwestern UniversityEvanston, ILUnited States of America [duyuzhou2013@gmail.com](mailto:duyuzhou2013@gmail.com)
    ,  Michael Rejtig University of Massachusetts BostonBoston, MAUnited States of
    America [michael.rejtig001@umb.edu](mailto:michael.rejtig001@umb.edu) ,  Ruth
    Bagley Northwestern UniversityEvanston, ILUnited States of America [ruth.bagley@northwestern.edu](mailto:ruth.bagley@northwestern.edu)
    ,  Michael S. Horn Northwestern UniversityEvanston, ILUnited States of America
    [michael-horn@northwestern.edu](mailto:michael-horn@northwestern.edu)  和  Uri
    J. Wilensky Northwestern UniversityEvanston, ILUnited States of America [uri@northwestern.edu](mailto:uri@northwestern.edu)(2024;
    2023年9月14日；2023年12月12日；2024年1月19日)
- en: Abstract.
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: Large Language Models (LLMs) have the potential to fundamentally change the
    way people engage in computer programming. Agent-based modeling (ABM) has become
    ubiquitous in natural and social sciences and education, yet no prior studies
    have explored the potential of LLMs to assist it. We designed NetLogo Chat to
    support the learning and practice of NetLogo, a programming language for ABM.
    To understand how users perceive, use, and need LLM-based interfaces, we interviewed
    30 participants from global academia, industry, and graduate schools. Experts
    reported more perceived benefits than novices and were more inclined to adopt
    LLMs in their workflow. We found significant differences between experts and novices
    in their perceptions, behaviors, and needs for human-AI collaboration. We surfaced
    a knowledge gap between experts and novices as a possible reason for the benefit
    gap. We identified guidance, personalization, and integration as major needs for
    LLM-based interfaces to support the programming of ABM.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）有潜力从根本上改变人们进行计算机编程的方式。基于代理的建模（ABM）在自然科学、社会科学和教育领域已变得普遍，但以前的研究没有探讨LLMs在此方面的潜力。我们设计了NetLogo
    Chat，以支持NetLogo的学习和实践，NetLogo是一种用于ABM的编程语言。为了了解用户如何感知、使用和需求基于LLM的接口，我们采访了来自全球学术界、行业和研究生院的30名参与者。专家报告了比新手更多的感知利益，并更倾向于在工作流程中采用LLMs。我们发现专家和新手在对人机协作的感知、行为和需求上存在显著差异。我们发现专家和新手之间的知识差距可能是利益差距的原因。我们确定了指导、个性化和集成作为LLM基础接口支持ABM编程的主要需求。
- en: '^†^†copyright: none^†^†journalyear: 2024^†^†doi: 10.1145/3613904.3642377^†^†conference:
    Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI ’24);
    May 11–16, 2024, Honolulu, HI, USA; ^†^†ccs: Human-centered computing Empirical
    studies in HCI^†^†ccs: Human-centered computing Natural language interfaces^†^†ccs:
    Computing methodologies Simulation support systems'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ^†^†版权：无^†^†期刊年份：2024^†^†doi：10.1145/3613904.3642377^†^†会议：CHI 2024人机交互会议论文集；2024年5月11-16日，美国夏威夷州檀香山^†^†ccs：以人为本的计算 HCI中的实证研究^†^†ccs：以人为本的计算 自然语言接口^†^†ccs：计算方法 仿真支持系统
- en: 1\. Introduction
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 引言
- en: The advent of coding-capable Large Language Models (LLMs) has the potential
    to fundamentally change the way people engage in computer programming(Eloundou
    et al., [2023](#bib.bib26)). As LLM-based programming interfaces (e.g. GitHub
    Copilot; ChatGPT) become increasingly popular(Lau and Guo, [2023](#bib.bib47)),
    some studies started to study their user perceptions(Vaithilingam et al., [2022](#bib.bib85)).
    However, the research on their potential learning impacts is still limited. Many
    prior studies only focus on impressions of educators(Lau and Guo, [2023](#bib.bib47))
    or students(Yilmaz and Yilmaz, [2023](#bib.bib101)), with little empirical data
    on the actual learning usage of these tools. On the other hand, a few studies
    started to explore how LLM-based interfaces can be designed to facilitate programming
    education, indicating potential advantages for learners. Notably, these studies
    suggest that learners with more prior programming experience tend to benefit more(Nam
    et al., [2023](#bib.bib58); Kazemitabaar et al., [2023](#bib.bib43)). While a
    recent study identifies some challenges for novice learners with LLM-based interfaces(Zamfirescu-Pereira
    et al., [2023](#bib.bib102)), there is a gap in understanding why experienced
    programmers seem to gain more learning benefits from these tools.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 可编程的大型语言模型（LLMs）的出现有可能从根本上改变人们从事计算机编程的方式（Eloundou et al., [2023](#bib.bib26)）。随着基于LLM的编程接口（例如
    GitHub Copilot; ChatGPT）变得越来越受欢迎（Lau and Guo, [2023](#bib.bib47)），一些研究开始研究用户的感知（Vaithilingam
    et al., [2022](#bib.bib85)）。然而，对于这些工具的潜在学习影响的研究仍然有限。许多先前的研究仅关注教育工作者（Lau and Guo,
    [2023](#bib.bib47)）或学生（Yilmaz and Yilmaz, [2023](#bib.bib101)）的印象，对于这些工具的实际学习使用的实证数据很少。另一方面，一些研究开始探索如何设计基于LLM的接口以促进编程教育，显示出对学习者的潜在优势。值得注意的是，这些研究表明，具有更多先前编程经验的学习者往往获得更多的益处（Nam
    et al., [2023](#bib.bib58); Kazemitabaar et al., [2023](#bib.bib43)）。虽然最近的研究确定了一些新手学习者使用基于LLM的接口时面临的挑战（Zamfirescu-Pereira
    et al., [2023](#bib.bib102)），但对于为什么经验丰富的程序员似乎从这些工具中获得更多学习收益的原因仍存在理解上的空白。
- en: In this paper, we present the design of a novel LLM-based interface, NetLogo
    Chat, for the learning and practice of NetLogo. NetLogo is a widely used programming
    language for agent-based modeling (ABM), which applies simple rules on multiple
    individual agents to simulate complex systems(Wilensky, [1997](#bib.bib95)). It
    is particularly powerful in capturing emergent phenomena, e.g., the spread of
    viruses or predator-prey systems(Wilensky and Rand, [2015](#bib.bib94)). It is
    an important methodology in computational modeling across scientific disciplines
    and education from K-12 to postgraduate levels(Weintrop et al., [2016](#bib.bib89)),
    where scientists and educators are highly in need of LLM-based interfaces(Pal
    et al., [2023](#bib.bib60); Cooper, [2023](#bib.bib22)). As an important part
    of computational modeling, the priorities of ABM differ from general programming(Pylyshyn,
    [1978](#bib.bib66)). A modeler needs to verify that their conceptual design of
    individual rules matches the real-world patterns (e.g. a predator needs food to
    survive), the code matches the design (i.e. there are no unexpected or implicit
    assumptions), and the aggregated outcome matches real-world phenomena (e.g. if
    all prey die out, predators die too)(Fleischmann and Wallace, [2009](#bib.bib29)).
    As most LLM-related studies on computer programming work on general-purpose languages
    that LLMs perform best (e.g. Python or Javascript), no LLM-related studies have
    explored ABM or other forms of computational modeling at this point.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们介绍了一种新型的基于LLM的接口——NetLogo Chat，用于NetLogo的学习和实践。NetLogo是一种广泛使用的用于基于代理的建模（ABM）的编程语言，它通过对多个个体代理应用简单规则来模拟复杂系统（Wilensky,
    [1997](#bib.bib95)）。它在捕捉涌现现象方面特别强大，例如病毒的传播或捕食者-猎物系统（Wilensky and Rand, [2015](#bib.bib94)）。它是科学学科和从K-12到研究生教育的计算建模中的重要方法（Weintrop
    et al., [2016](#bib.bib89)），科学家和教育工作者对于基于LLM的接口有很高的需求（Pal et al., [2023](#bib.bib60);
    Cooper, [2023](#bib.bib22)）。作为计算建模的重要组成部分，ABM的优先事项与一般编程不同（Pylyshyn, [1978](#bib.bib66)）。建模者需要验证他们的个体规则的概念设计是否符合现实世界的模式（例如，捕食者需要食物才能生存），代码是否符合设计（即没有意外或隐含的假设），以及汇总的结果是否符合现实世界的现象（例如，如果所有猎物都死光了，捕食者也会死）（Fleischmann
    and Wallace, [2009](#bib.bib29)）。由于大多数与LLM相关的计算机编程研究集中于LLM表现最佳的一般用途语言（例如 Python
    或 Javascript），目前尚无LLM相关研究探讨ABM或其他形式的计算建模。
- en: NetLogo Chat was designed with constructionist learning principles and incorporated
    known best practices for ABM and computer programming. Constructionism advocates
    for the design of learning experiences where learners construct their understanding
    of the world (e.g. knowledge of ABM) through building personally meaningful artifacts
    (e.g. an agent-based model around learners’ interests)(Papert and Harel, [1991](#bib.bib62)).
    Similar to GitHub Copilot Chat(noa, [[n. d.]](#bib.bib2)), NetLogo Chat was integrated
    into an integrated development environment (IDE). Different from previous designs,
    it aims to give users more control over the human-AI collaboration processes,
    strives to incorporate authoritative sources, and tries to provide more support
    for troubleshooting.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: NetLogo Chat的设计遵循了建构主义学习原则，并融入了已知的ABM和计算机编程最佳实践。建构主义倡导设计学习体验，让学习者通过构建个人意义的工件（例如围绕学习者兴趣的代理模型）来构建对世界的理解（例如ABM知识）（Papert和Harel，[1991](#bib.bib62)）。类似于GitHub
    Copilot Chat（noa，[[n. d.]](#bib.bib2)），NetLogo Chat被集成到一个集成开发环境（IDE）中。不同于之前的设计，它旨在给予用户更多对人类与AI合作过程的控制，努力整合权威来源，并尝试提供更多的故障排除支持。
- en: 'Using both ChatGPT and NetLogo Chat as a probe(Zamfirescu-Pereira et al., [2023](#bib.bib102)),
    we conducted a qualitative study to highlight the different perceptions, behaviors,
    and needs of experts and novices during open-ended modeling sessions. We interviewed
    30 expert and novice participants from academia, industry, and graduate schools
    around the world. Participants proposed diverse NetLogo tasks from their disciplines
    and worked toward their modeling goals. We asked interview questions before, during,
    and after their interaction with each design. We answered the research questions:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 使用ChatGPT和NetLogo Chat作为探针（Zamfirescu-Pereira等，[2023](#bib.bib102)），我们进行了一项定性研究，突出了专家和新手在开放式建模会话中的不同感知、行为和需求。我们采访了来自全球学术界、工业界和研究生院的30位专家和新手参与者。参与者提出了来自他们学科的多种NetLogo任务，并朝着他们的建模目标努力。我们在他们与每个设计的互动前、互动中和互动后提出了采访问题。我们回答了研究问题：
- en: (1)
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: What perceptions - strengths, weaknesses, and adoption plans - do expert and
    novice users perceive LLM-driven interfaces to support their NetLogo learning
    and practice?
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 专家和新手用户对LLM驱动的界面在支持他们的NetLogo学习和实践方面的感知——优点、缺点和采纳计划——是什么？
- en: (2)
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: How do expert and novice users use LLM-driven interfaces to support their NetLogo
    learning and practice?
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 专家和新手用户如何使用LLM驱动的界面来支持他们的NetLogo学习和实践？
- en: (3)
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3)
- en: What are expert and novice users’ needs for LLM-based interfaces to support
    their NetLogo learning and practice?
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 专家和新手用户对LLM驱动的界面在支持他们的NetLogo学习和实践方面有哪些需求？
- en: 'Learners generally agreed with our design principles and suggested additional
    features for future designs. As in other studies, experts reported more perceived
    benefits than novices. Comparing the different interaction patterns between experts
    and novices, our study reveals a behavioral gap that might explain the gap in
    benefits. We found that experts collaborated with LLM-based interfaces with more
    human judgment in all activities than novices, helping them overcome AI hallucinations,
    while novices struggled with evaluating and debugging AI responses. From there,
    we identified components of a knowledge gap between novices and experts. We reported
    experts’ and novices’ needs in LLM-based interfaces in three key themes: guidance
    (from LLMs); personalization (of LLMs); and integration (into modeling environments),
    many of which confirm and develop the design decisions of NetLogo Chat. The contributions
    of this paper include:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 学习者普遍同意我们的设计原则，并建议未来设计中的额外功能。与其他研究类似，专家报告的感知益处多于新手。通过比较专家和新手之间的不同互动模式，我们的研究揭示了可能解释益处差距的行为差距。我们发现专家在所有活动中与LLM驱动的界面进行更多的人类判断合作，帮助他们克服AI幻觉，而新手在评估和调试AI响应方面遇到困难。从中，我们识别出了新手和专家之间的知识差距的组成部分。我们在LLM驱动的界面中报告了专家和新手的需求，分为三个关键主题：指导（来自LLM）；个性化（LLM的）；以及集成（到建模环境中），这些主题中的许多确认并发展了NetLogo
    Chat的设计决策。本文的贡献包括：
- en: (1)
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: The design and implementation of NetLogo Chat, an LLM-based system that supports
    learning and practice of NetLogo, a widely-used programming language for ABM;
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: NetLogo Chat的设计和实施，一个基于LLM的系统，支持NetLogo学习和实践，NetLogo是一种广泛使用的ABM编程语言；
- en: (2)
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: An empirical study that contributes to the understanding of how novices and
    experts perceive, use, and express needs for LLM-based programming interfaces
    in different ways;
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一项实证研究，有助于理解新手和专家如何以不同方式感知、使用和表达对基于LLM的编程接口的需求；
- en: (3)
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3)
- en: A theorization of the knowledge gap between experts and novices that might lead
    to the behavioral gap, and suggestions of potential design interventions;
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对专家和新手之间知识差距的理论化，这可能导致行为差距，并提出潜在的设计干预建议；
- en: (4)
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (4)
- en: The design discussion and suggestions for building LLM-based programming interfaces
    that benefit both experts and novices in agent-based modeling more equitably.
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 关于设计和建议构建基于LLM的编程接口，以便在代理建模中更加公平地惠及专家和新手的讨论。
- en: 2\. Related Work
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 相关工作
- en: 2.1\. LLMs for Computational Programming and Modeling
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1\. 计算编程和建模的LLMs
- en: Researchers have been exploring natural-language-based interfaces for programming
    for decades, yet early attempts were mostly exploratory, being limited in capabilities.
    NaturalJava(Price et al., [2000](#bib.bib65)) required users to follow a strict
    pattern when prompting, while later systems (e.g. NaLIX(Li et al., [2005](#bib.bib48))
    or Eviza(Setlur et al., [2016](#bib.bib74))) asked for a specific set of English
    expressions. This created difficulties for users and system designers, as they
    felt “a main challenge of NLP interfaces is in communicating to the user what
    inputs are supported.”(Setlur et al., [2016](#bib.bib74)) Without the capability
    to generate natural languages, those interfaces were also constrained to one-off
    interactions.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员探索基于自然语言的编程接口已经有几十年了，但早期的尝试大多是探索性的，能力有限。NaturalJava（Price等，[2000](#bib.bib65)）要求用户在提示时遵循严格的模式，而后来的系统（例如NaLIX（Li等，[2005](#bib.bib48)）或Eviza（Setlur等，[2016](#bib.bib74)））要求使用特定的英语表达。这给用户和系统设计者带来了困难，因为他们认为“自然语言处理接口的主要挑战在于向用户传达支持的输入。”（Setlur等，[2016](#bib.bib74)）由于缺乏生成自然语言的能力，这些接口也局限于一次性的交互。
- en: Recently, a new generation of LLMs demonstrated the capability to understand
    and generate both natural languages and computer languages. GPT-3 was examined
    in writing code explanations(MacNeil et al., [2022](#bib.bib53)), documentation(Khan
    and Uddin, [2022](#bib.bib45)), and providing feedback for assignments(Balse et al.,
    [2023](#bib.bib4)). Soon, educators started to believe that Codex could be used
    to solve simple programming problems(Finnie-Ansley et al., [2022](#bib.bib28);
    Wermelinger, [2023](#bib.bib91)). Embedded in ChatGPT, GPT-3.5-turbo and GPT-4
    demonstrated even stronger capabilities in programming. More and more LLMs have
    started to gain the capability of coding (e.g. PALM 2; Claude 2; CodeLLaMA 2),
    ushering in a new era of natural language interfaces for programming.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，新一代LLMs展示了理解和生成自然语言及计算机语言的能力。GPT-3被用于编写代码解释（MacNeil等，[2022](#bib.bib53)）、文档（Khan和Uddin，[2022](#bib.bib45)）和为作业提供反馈（Balse等，[2023](#bib.bib4)）。不久之后，教育工作者开始相信Codex可以用来解决简单的编程问题（Finnie-Ansley等，[2022](#bib.bib28)；Wermelinger，[2023](#bib.bib91)）。嵌入在ChatGPT中的GPT-3.5-turbo和GPT-4展示了更强的编程能力。越来越多的LLMs开始具备编码能力（例如PALM
    2；Claude 2；CodeLLaMA 2），开创了编程自然语言界面的新时代。
- en: Even the most powerful LLMs suffer from hallucinations and may misunderstand
    human intentions. Early users of ChatGPT complained about incorrect responses
    and struggled to prompt ChatGPT for a desired output(Skjuve et al., [2023](#bib.bib75)).
    While LLMs might outperform average humans in specific, structured tasks(OpenAI,
    [2023](#bib.bib59)), the evaluation criteria might have been flawed(Liu et al.,
    [2023](#bib.bib51)), as LLMs struggled to combine existing solutions for a novel
    challenge(Dakhel et al., [2023](#bib.bib24)). A study suggested that developers
    should not rely on ChatGPT when dealing with new problems (Tian et al., [2023](#bib.bib82)).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是最强大的LLMs也会出现幻觉，并可能误解人类意图。ChatGPT的早期用户抱怨回答不正确，并且难以引导ChatGPT输出期望结果（Skjuve等，[2023](#bib.bib75)）。虽然LLMs在特定的结构化任务中可能超越普通人（OpenAI，[2023](#bib.bib59)），但评估标准可能存在缺陷（Liu等，[2023](#bib.bib51)），因为LLMs在将现有解决方案结合起来应对新挑战时遇到困难（Dakhel等，[2023](#bib.bib24)）。有研究建议开发者在处理新问题时不要依赖ChatGPT（Tian等，[2023](#bib.bib82)）。
- en: 'LLMs are naturally less prepared in low-resource programming languages (LRPL).
    Here, our working definition for LRPL is similar to that of natural languages:
    with relatively scarce online resources and have been less studied by the AI field(Magueresse
    et al., [2020](#bib.bib54)). LRPLs are not less important: NetLogo, the most widely
    used programming language for agent-based modeling (ABM)(Thiele et al., [2011](#bib.bib81)),
    is used by hundreds of thousands of scientists, educators, and students for computational
    modeling. Using simple computational rules for individual agents, ABM could simulate
    complicated emergent phenomena. It has been frequently used in different scientific
    disciplines(Wilensky and Rand, [2015](#bib.bib94)) and science education(Hutchins
    et al., [2020](#bib.bib36)) for recent decades. With considerably fewer online
    resources to train on, LLMs are much more prone to errors and/or hallucinations
    with LRPLs(Tarassow, [2023](#bib.bib80)).'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 在低资源编程语言（LRPL）上自然准备不足。在这里，我们对 LRPL 的工作定义类似于自然语言：在线资源相对稀缺，且在 AI 领域的研究较少（Magueresse
    et al., [2020](#bib.bib54)）。LRPL 并不重要：NetLogo，最广泛使用的基于代理建模（ABM）的编程语言（Thiele et
    al., [2011](#bib.bib81)），被成千上万的科学家、教育工作者和学生用于计算建模。通过为个体代理使用简单的计算规则，ABM 可以模拟复杂的涌现现象。近年来，它在不同的科学学科（Wilensky
    and Rand, [2015](#bib.bib94)）和科学教育（Hutchins et al., [2020](#bib.bib36)）中被广泛使用。由于可训练的在线资源显著减少，LLMs
    在 LRPL 上更容易出现错误和/或幻觉（Tarassow, [2023](#bib.bib80)）。
- en: A few studies attempted to improve LLMs’ performance with LRPLs in two directions.
    First, some studies fine-tuned foundational LLMs with LRPL datasets(Chen et al.,
    [2022](#bib.bib13)). While this approach demands considerable datasets and computational
    power, it has not been applied to generative tasks yet(Gong et al., [2022](#bib.bib32)).
    Second, some studies used prompt engineering techniques. For example, aiming at
    simple tasks, a study creates sets of grammar rules for LLMs to fill in(Wang et al.,
    [2023](#bib.bib87)). Another study leveraged compiler outputs, allowing LLMs to
    iteratively improve their Rust code, but was only tested in a smaller number of
    fixed tasks(Wu et al., [2023](#bib.bib98)). The potential of LLMs in scientific
    disciplines, including in computational modeling, is rarely explored. At this
    point, the only study targeted at STEM helps with a very specific engineering
    task (Kumar et al., [2023](#bib.bib46)).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一些研究尝试从两个方向提高 LLMs 在 LRPL 上的表现。首先，一些研究通过 LRPL 数据集微调基础 LLMs（Chen et al., [2022](#bib.bib13)）。尽管这种方法需要大量数据集和计算能力，但尚未应用于生成任务（Gong
    et al., [2022](#bib.bib32)）。其次，一些研究使用了提示工程技术。例如，针对简单任务，一项研究为 LLMs 创建了一组语法规则进行填充（Wang
    et al., [2023](#bib.bib87)）。另一项研究利用编译器输出，使 LLMs 能够迭代改进其 Rust 代码，但仅在少量固定任务中进行测试（Wu
    et al., [2023](#bib.bib98)）。LLMs 在科学学科（包括计算建模）中的潜力尚未被充分探索。目前，唯一针对 STEM 的研究帮助解决了一个非常具体的工程任务（Kumar
    et al., [2023](#bib.bib46)）。
- en: 2.2\. User Perception and Behaviors with LLM-based Programming Interfaces
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2. 基于 LLM 的编程接口的用户感知和行为
- en: 'Two strands of user perception and behaviors studies informed our design and
    study: studies of conversational agents (CAs); and of LLM-based programming interfaces.
    For education, CAs were used to develop learners’ writing(Wambsganss et al., [2021](#bib.bib86)),
    self-talk(Fu et al., [2023](#bib.bib30)), and programming skills(Winkler et al.,
    [2020](#bib.bib96)). Many of them are pedagogical conversational agents (PCA)
    with the aim to adaptively mimic the behaviors of human tutors(Winkler and Söllner,
    [2018](#bib.bib97)). PCAs could serve in multiple roles, such as tutors(Wambsganss
    et al., [2021](#bib.bib86)), motivators(Caballé and Conesa, [2019](#bib.bib12)),
    peer players(Gero et al., [2020](#bib.bib31)), or learning companions(Fu et al.,
    [2023](#bib.bib30)).'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 两个研究方向的用户感知和行为研究为我们的设计和研究提供了参考：会话代理（CAs）的研究；以及基于 LLM 的编程接口的研究。对于教育，CAs 被用于发展学习者的写作（Wambsganss
    et al., [2021](#bib.bib86)）、自我对话（Fu et al., [2023](#bib.bib30)）和编程技能（Winkler et
    al., [2020](#bib.bib96)）。许多 CAs 是教学会话代理（PCA），旨在自适应地模拟人类导师的行为（Winkler and Söllner,
    [2018](#bib.bib97)）。PCA 可以承担多种角色，如导师（Wambsganss et al., [2021](#bib.bib86)）、激励者（Caballé
    and Conesa, [2019](#bib.bib12)）、同伴玩家（Gero et al., [2020](#bib.bib31)）或学习伙伴（Fu
    et al., [2023](#bib.bib30)）。
- en: Prior research of CAs underscored the importance of understanding user perception
    and behaviors(Gero et al., [2020](#bib.bib31)), yet the technical boundaries of
    the pre-LLM era limited the freedom of designers. Previous studies have explored
    aspects such as trust, mutual understanding, perceived roles(Clark et al., [2009](#bib.bib19)),
    privacy(Sannon et al., [2020](#bib.bib70)), human-likeness(Jeong et al., [2019](#bib.bib37)),
    utilitarian benefits, and user-related factors(Ling et al., [2021](#bib.bib50))
    to understand users’ acceptance and willingness to use CAs. However, many CAs
    before LLMs had to use pre-programmed responses(Wang et al., [2021](#bib.bib88)),
    and simply emulating functional rules from human speech failed to deliver people’s
    high expectations of CAs(Clark et al., [2019](#bib.bib20)). Without the capability
    to read or write code, pre-LLM CAs for computing education were largely limited
    to providing relevant knowledge(Winkler et al., [2020](#bib.bib96)) or supporting
    conceptual understanding of programming(Lin et al., [2020](#bib.bib49)).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 之前对 CAs 的研究强调了理解用户感知和行为的重要性(Gero et al., [2020](#bib.bib31))，但前 LLM 时代的技术限制限制了设计师的自由。以往的研究探索了诸如信任、相互理解、感知角色(Clark
    et al., [2009](#bib.bib19))、隐私(Sannon et al., [2020](#bib.bib70))、类人性(Jeong et
    al., [2019](#bib.bib37))、功利性益处以及用户相关因素(Ling et al., [2021](#bib.bib50))等方面，以了解用户对
    CAs 的接受度和使用意愿。然而，许多 LLM 之前的 CAs 只能使用预设的回答(Wang et al., [2021](#bib.bib88))，仅仅模拟人类语言中的功能规则无法满足人们对
    CAs 的高期望(Clark et al., [2019](#bib.bib20))。在没有读写代码能力的情况下，前 LLM 的 CAs 在计算教育中主要限于提供相关知识(Winkler
    et al., [2020](#bib.bib96)) 或支持编程概念的理解(Lin et al., [2020](#bib.bib49))。
- en: Recent studies have started to understand user perception and behaviors with
    LLM-based programming interfaces. In education, early studies focused on instructors’
    and students’ perceptions of LLM-based interfaces for programming. Computer science
    students self-reported many potential benefits of using ChatGPT and were less
    inclined to report potential drawbacks(Yilmaz and Yilmaz, [2023](#bib.bib101)).
    On the other hand, computer science instructors were significantly concerned over
    students’ widespread usage of ChatGPT(Lau and Guo, [2023](#bib.bib47)). While
    some instructors went as far as banning ChatGPT altogether, others suggested exposing
    students to the capabilities and limitations of AI tools, leveraging mistakes
    in generated code for learning opportunities. Both instructors and students expressed
    the need to adapt to a new, LLM-era way of teaching and learning(Zastudil et al.,
    [2023](#bib.bib103)).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究开始理解用户在使用基于 LLM 的编程接口时的感知和行为。在教育领域，早期研究集中在讲师和学生对基于 LLM 的编程接口的看法上。计算机科学学生自报告了许多使用
    ChatGPT 的潜在好处，并且较少倾向于报告潜在的缺点(Yilmaz and Yilmaz, [2023](#bib.bib101))。另一方面，计算机科学讲师对学生广泛使用
    ChatGPT 表示了显著的担忧(Lau and Guo, [2023](#bib.bib47))。一些讲师甚至禁止了 ChatGPT，而其他讲师则建议让学生了解
    AI 工具的能力和局限性，利用生成代码中的错误作为学习机会。讲师和学生都表示需要适应一种新的 LLM 时代的教学和学习方式(Zastudil et al.,
    [2023](#bib.bib103))。
- en: For professionals, challenges and opportunities co-exist with LLM-based programming
    interfaces. Recent studies found programmers preferred to use Copilot(Vaithilingam
    et al., [2022](#bib.bib85)) and finished tasks faster with Copilot(Peng et al.,
    [2023](#bib.bib63)). Yet, Copilot struggled with more complicated problems, providing
    buggy or non-reproducible solutions(Dakhel et al., [2023](#bib.bib24)). Professional
    programmers faced difficulties in understanding and debugging Copilot-generated
    code, which hinders their task-solving effectiveness(Vaithilingam et al., [2022](#bib.bib85)).
    Programmers who trusted AI were prone to write insecure code with AI(Perry et al.,
    [2022](#bib.bib64)). For conversational interfaces, despite inputs being in natural
    languages, users felt that they needed to learn LLM’s “syntax”(Jiang et al., [2022](#bib.bib38);
    Fiannaca et al., [2023](#bib.bib27)).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于专业人士而言，基于 LLM 的编程接口既面临挑战也充满机遇。近期研究发现，程序员更倾向于使用 Copilot(Vaithilingam et al.,
    [2022](#bib.bib85))，并且使用 Copilot 完成任务的速度更快(Peng et al., [2023](#bib.bib63))。然而，Copilot
    在处理更复杂的问题时存在困难，提供了有缺陷或不可重复的解决方案(Dakhel et al., [2023](#bib.bib24))。专业程序员在理解和调试
    Copilot 生成的代码时遇到困难，这影响了他们解决问题的效率(Vaithilingam et al., [2022](#bib.bib85))。信任 AI
    的程序员容易写出不安全的代码(Perry et al., [2022](#bib.bib64))。对于对话接口，尽管输入是自然语言，用户仍感到需要学习 LLM
    的“语法”(Jiang et al., [2022](#bib.bib38); Fiannaca et al., [2023](#bib.bib27))。
- en: 'Our understanding of user perception and behaviors with LLM-based interfaces
    during (the learning of) computer programming is still very limited. As the field
    just started exploring this direction, previous studies mostly focused on general
    user impressions(Zastudil et al., [2023](#bib.bib103)), or conducted behavioral
    tasks on pre-scripted, close-ended tasks(Peng et al., [2023](#bib.bib63)). While
    close-ended settings made it easier to assess objective metrics(Blikstein, [2011](#bib.bib8)),
    open-ended contexts open a wider window to understanding users’ learning patterns,
    behaviors, perceptions, and preferences(Blikstein et al., [2014](#bib.bib9)).
    For example, a recent study observed two modes that professional programmers interact
    in open-ended tasks with Copilot: acceleration, where the programmer already knows
    what they want to do next; and exploration, where the programmer uses AI to explore
    their options(Barke et al., [2023](#bib.bib5)). Another study on professionals’
    prompt engineering shed light on their struggles, challenges, and potential sources
    of behaviors(Zamfirescu-Pereira et al., [2023](#bib.bib102)).'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对基于LLM的接口在（计算机编程学习过程中的）用户感知和行为的理解仍然非常有限。由于该领域刚刚开始探索这个方向，以往的研究主要集中在一般用户印象上（Zastudil
    et al., [2023](#bib.bib103)），或者在预设的封闭任务上进行行为研究（Peng et al., [2023](#bib.bib63)）。虽然封闭任务设置使得评估客观指标更容易（Blikstein,
    [2011](#bib.bib8)），开放性任务则提供了更广阔的窗口来理解用户的学习模式、行为、感知和偏好（Blikstein et al., [2014](#bib.bib9)）。例如，一项近期研究观察到专业程序员在使用Copilot进行开放性任务时的两种模式：加速模式，即程序员已经知道接下来要做什么；探索模式，即程序员使用AI来探索选项（Barke
    et al., [2023](#bib.bib5)）。另一项关于专业人士提示工程的研究揭示了他们的困境、挑战和行为的潜在来源（Zamfirescu-Pereira
    et al., [2023](#bib.bib102)）。
- en: Still, we noticed two gaps in previous studies. First, a majority of studies
    chose professional programmers or computer science instructors/students as participants,
    while LLM-based interfaces are also used by millions of people without a CS background
    for programming tasks. Second, as HCI studies mostly focus on languages that LLMs
    are known to perform best, e.g. Python or HTML, little is known about user perceptions
    and behaviors when computational modeling or LRPLs are involved.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，我们注意到以往研究中存在两个空白。首先，大多数研究选择了专业程序员或计算机科学教师/学生作为参与者，而LLM（大语言模型）基础的接口也被数百万没有计算机科学背景的人用于编程任务。其次，由于HCI（人机交互）研究主要集中在LLM表现最佳的语言上，例如Python或HTML，对于涉及计算建模或LRPL（低资源编程语言）的用户感知和行为了解甚少。
- en: 2.3\. LLM-based Interfaces for Learning Programming and Modeling
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3\. 基于LLM的编程和建模学习接口
- en: While LLMs have shown promising potential in supporting human-AI collaboration
    in programming, most design studies were preliminary, and LLM-based interfaces
    for computational modeling remained understudied. For example, the Programmer’s
    Assistant integrated a chat window into an IDE(Ross et al., [2023](#bib.bib69)).
    Going beyond simple integrations, GitHub Copilot Chat(noa, [[n. d.]](#bib.bib2))
    provided in-context support within code editors, yet its user studies were still
    preliminary(Bull and Kharrufa, [2023](#bib.bib11)). A similar design was done
    on XCode without a user study(Tan et al., [2023](#bib.bib79)). Another study explored
    the integration between computational notebooks with LLMs and emphasized the role
    of the domain (in this case, data science) on LLM-based interface design(McNutt
    et al., [2023](#bib.bib56)).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管LLM在支持人类与AI的编程协作方面展现了有希望的潜力，大多数设计研究仍处于初步阶段，LLM基础的计算建模接口仍然没有得到充分研究。例如，Programmer’s
    Assistant将聊天窗口集成到IDE中（Ross et al., [2023](#bib.bib69)）。超越简单的集成，GitHub Copilot
    Chat（noa, [[n. d.]](#bib.bib2)）在代码编辑器中提供了上下文支持，但其用户研究仍处于初步阶段（Bull and Kharrufa,
    [2023](#bib.bib11)）。一个类似的设计在XCode中完成，但没有进行用户研究（Tan et al., [2023](#bib.bib79)）。另一项研究探讨了计算笔记本与LLM的集成，并强调了领域（在这种情况下为数据科学）对LLM基础接口设计的作用（McNutt
    et al., [2023](#bib.bib56)）。
- en: LLMs have gained much attention among programming educators, but the design
    study is insufficient. Recent studies tested LLMs on introductory programming
    tasks and achieved unsurprisingly high scores(Savelka et al., [2023](#bib.bib71);
    Chen et al., [2023a](#bib.bib17)). This prospect leads to great concerns among
    computer science instructors as they observed the widespread usage of ChatGPT
    among students(Lau and Guo, [2023](#bib.bib47)). Yet, only a few LLM-based design
    studies targeted programming learning. Using a Wizard of Oz prototype, a study
    underscored the importance of supporting students’ varied degrees of prior expertise(Robe
    and Kuttal, [2022](#bib.bib68)). A design study reported positive short-term performance
    gains when young, novice programming learners engaged with Codex(Kazemitabaar
    et al., [2023](#bib.bib43)). Another study also found LLMs’ benefits for novice
    programmers(Nam et al., [2023](#bib.bib58)). Both studies found that more experienced
    programmers tended to benefit more, yet the reason was still unclear.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 在编程教育者中引起了广泛关注，但设计研究仍然不足。近期研究测试了 LLM 在入门编程任务中的表现，并取得了意料之中的高分（Savelka 等，[2023](#bib.bib71)；Chen
    等，[2023a](#bib.bib17)）。这一前景引发了计算机科学教师的极大关注，因为他们观察到 ChatGPT 在学生中的广泛使用（Lau 和 Guo，[2023](#bib.bib47)）。然而，针对编程学习的
    LLM 基于设计的研究仍然很少。使用“奥兹魔法师”原型的研究强调了支持学生不同程度的先验知识的重要性（Robe 和 Kuttal，[2022](#bib.bib68)）。一项设计研究报告了当年轻的初学编程者使用
    Codex 时的短期表现提升（Kazemitabaar 等，[2023](#bib.bib43)）。另一项研究也发现 LLM 对新手程序员的好处（Nam 等，[2023](#bib.bib58)）。两项研究均发现经验更丰富的程序员往往受益更多，但原因仍不清楚。
- en: In this study, we invoke the learning theory of Constructionism(Papert and Harel,
    [1991](#bib.bib62)) to inform our LLM-based system and empirical study design.
    While there is no rigid definition for Constructionism, it argues that learning
    happens most felicitously when learners ”consciously engage in constructing a
    public entity”(Papert and Harel, [1991](#bib.bib62)). In the context of computer
    programming, it means learning happens naturally through programming computers,
    as it iteratively externalizes learners’ internal understanding of the world in
    code, and then allows learners to improve their understanding through watching
    how the code runs(Papert, [1980](#bib.bib61)). Moreover, it argues that computer
    programming is not as abstract or formal as it appears; individual programmers’
    approaches are often concrete and personal, in pluralistic ways(Turkle and Papert,
    [1990](#bib.bib84)). However, the pluralism in thoughts is more difficult to capture
    by close-ended tasks (such as a problem set) and objective metrics (such as completion
    rate/time)(Blikstein et al., [2014](#bib.bib9)). As such, constructionist learning
    studies often prefer open-ended tasks (e.g. making games(Kafai and Burke, [2015](#bib.bib41)),
    designing instructional software(Harel and Papert, [1990](#bib.bib33)), creating
    agent-based models in NetLogo(Blikstein et al., [2014](#bib.bib9))) and qualitative
    studies, as they open windows into the nuances of learners’ perceptions and behaviors
    in more natural and realistic settings.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项研究中，我们借鉴了建构主义学习理论（Papert 和 Harel，[1991](#bib.bib62)）来指导我们的基于 LLM 的系统和实证研究设计。虽然建构主义没有严格的定义，但它认为，当学习者“有意识地参与构建一个公共实体”（Papert
    和 Harel，[1991](#bib.bib62)）时，学习效果最为显著。在计算机编程的背景下，这意味着学习自然地通过编程计算机来发生，因为它迭代地将学习者对世界的内在理解外化为代码，然后允许学习者通过观察代码的运行来改善他们的理解（Papert，[1980](#bib.bib61)）。此外，建构主义认为计算机编程并不像看起来那么抽象或正式；个别程序员的方法通常是具体的和个人化的，以多元化的方式呈现（Turkle
    和 Papert，[1990](#bib.bib84)）。然而，多元思维在封闭式任务（如问题集）和客观指标（如完成率/时间）（Blikstein 等，[2014](#bib.bib9)）中更难以捕捉。因此，建构主义学习研究通常更倾向于开放式任务（例如制作游戏（Kafai
    和 Burke，[2015](#bib.bib41)），设计教学软件（Harel 和 Papert，[1990](#bib.bib33)），在 NetLogo
    中创建基于代理的模型（Blikstein 等，[2014](#bib.bib9)））和定性研究，因为它们可以更自然和真实地展现学习者的感知和行为的细微差别。
- en: The Logo programming language and its descendants (e.g. Scratch; Alice; NetLogo)
    succeeded in supporting multiple ways of knowing and thinking in computing education
    and in scientific research(Solomon et al., [2020](#bib.bib76)), yet to our knowledge,
    no published studies have explored their synergy with LLMs. Many prominent constructionist
    design principles could be applied to AI-based interfaces(Kahn and Winters, [2021](#bib.bib42))
    and inspired the design of NetLogo Chat. For instance, “low floor, high ceiling,
    wide walls” asks learning environments to provide 1) an easy entrance for novices
    (low floor); 2) the possibility for experts to work on sophisticated projects
    (high ceiling); 3) the support of a wide range of different explorations (wide
    walls); 4) the support of many learning paths and styles(Resnick and Silverman,
    [2005](#bib.bib67)). We also learned from previous design studies that stress
    the importance of adaptive scaffolding(Chen et al., [2023b](#bib.bib15); Sengupta
    et al., [2013](#bib.bib73)) and support debugging(Brady et al., [2020](#bib.bib10))
    for novices to learn NetLogo. Hence, we contributed to the field one of the first
    design studies of LLM-based interfaces for learning programming that follow the
    constructionist tradition.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Logo 编程语言及其后代（例如 Scratch；Alice；NetLogo）成功地支持了计算教育和科学研究中的多种认识和思维方式（Solomon 等，[2020](#bib.bib76)），但据我们了解，尚无公开研究探索它们与
    LLM 的协同作用。许多显著的建构主义设计原则可以应用于基于 AI 的接口（Kahn 和 Winters，[2021](#bib.bib42)），并激发了
    NetLogo 聊天的设计。例如，“低门槛，高天花板，宽墙”要求学习环境提供 1）新手的简单入口（低门槛）；2）专家在复杂项目上的可能性（高天花板）；3）支持广泛的不同探索（宽墙）；4）支持多种学习路径和风格（Resnick
    和 Silverman，[2005](#bib.bib67)）。我们还从以前的设计研究中了解到，强调适应性支架（Chen 等，[2023b](#bib.bib15)；Sengupta
    等，[2013](#bib.bib73)）和支持调试（Brady 等，[2020](#bib.bib10)）对新手学习 NetLogo 的重要性。因此，我们为该领域贡献了首批基于
    LLM 的学习编程接口设计研究之一，遵循建构主义传统。
- en: 3\. NetLogo Chat System
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. NetLogo 聊天系统
- en: 'NetLogo Chat is an LLM-based system for learning and programming with NetLogo.
    It comprises two main parts: a web-based interface integrated with Turtle Universe
    (a version of NetLogo)(Chen and Wilensky, [2021](#bib.bib14)) (See [3.1](#S3.SS1
    "3.1\. Design Overview ‣ 3\. NetLogo Chat System ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat")); and an LLM-based workflow that improves the quality of AI responses
    and powers the interface (See [3.2](#S3.SS2 "3.2\. Technical Implementation ‣
    3\. NetLogo Chat System ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")).
    We iteratively designed the system by:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: NetLogo 聊天是一个基于 LLM 的系统，用于学习和编程 NetLogo。它包括两个主要部分：一个与 Turtle Universe（NetLogo
    的一个版本）（Chen 和 Wilensky，[2021](#bib.bib14)）集成的基于网页的界面（见 [3.1](#S3.SS1 "3.1\. 设计概述
    ‣ 3\. NetLogo 聊天系统 ‣ 使用 LLM 伴侣进行基于代理建模的编程学习：新手和专家使用 ChatGPT 和 NetLogo 聊天的经验")）；以及一个基于
    LLM 的工作流，提升 AI 响应的质量并支持界面（见 [3.2](#S3.SS2 "3.2\. 技术实施 ‣ 3\. NetLogo 聊天系统 ‣ 使用
    LLM 伴侣进行基于代理建模的编程学习：新手和专家使用 ChatGPT 和 NetLogo 聊天的经验")）。我们通过以下方式迭代设计了该系统：
- en: (1)
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: 'Based on authors’ experiences in teaching NetLogo, we created a design prototype
    based on the constructionist learning theory (see [2.3](#S2.SS3 "2.3\. LLM-based
    Interfaces for Learning Programming and Modeling ‣ 2\. Related Work ‣ Learning
    Programming of Agent-based Modeling with LLM Companions: Experiences of Novices
    and Experts Using ChatGPT & NetLogo Chat")), with a focus on supporting users
    iteratively build up their prompts and smaller code snippets before working on
    entire models. We developed a proof-of-concept system, using prompt engineering
    techniques to interact with GPT-3.5-turbo-0314.'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于作者在教学 NetLogo 方面的经验，我们创建了一个基于建构主义学习理论的设计原型（见 [2.3](#S2.SS3 "2.3\. 基于 LLM 的编程和建模接口
    ‣ 2\. 相关工作 ‣ 使用 LLM 伴侣进行基于代理建模的编程学习：新手和专家使用 ChatGPT 和 NetLogo 聊天的经验")），重点支持用户迭代构建他们的提示和较小的代码片段，然后再处理整个模型。我们开发了一个概念验证系统，使用提示工程技术与
    GPT-3.5-turbo-0314 互动。
- en: (2)
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: We internally evaluated the proof-of-concept with a group of NetLogo experts.
    During this process, we encountered frequent hallucinations with NetLogo (grammatical
    or conceptual mistakes; inventing keywords that do not exist; etc). For the system
    to provide guidance, we realized that authoritative sources are necessary for
    LLMs’ performance;
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们与一组 NetLogo 专家进行了内部评估。在此过程中，我们遇到了 NetLogo 的频繁幻觉（语法或概念错误；虚构不存在的关键词；等等）。为了使系统提供指导，我们意识到
    LLM 的性能需要权威来源；
- en: (3)
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3)
- en: 'We incorporated the official NetLogo documentation and code examples into the
    system using prompt engineering techniques (see [3.2](#S3.SS2 "3.2\. Technical
    Implementation ‣ 3\. NetLogo Chat System ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat")), evaluated other LLMs’ potential, and then conducted pilot interviews
    to evaluate the system with three external NetLogo experts invited from NetLogo’s
    mailing lists. The interviews used a protocol similar to the one we formally used
    (see [4.2](#S4.SS2 "4.2\. Interviews ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat")), with more flexibility and open-endedness;'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '我们通过提示工程技术将官方 NetLogo 文档和代码示例纳入系统（见 [3.2](#S3.SS2 "3.2\. Technical Implementation
    ‣ 3\. NetLogo Chat System ‣ Learning Programming of Agent-based Modeling with
    LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")），评估了其他
    LLM 的潜力，然后进行试点访谈，邀请了三位来自 NetLogo 邮件列表的外部 NetLogo 专家对系统进行评估。访谈使用了类似于我们正式使用的协议（见
    [4.2](#S4.SS2 "4.2\. Interviews ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat")），但更加灵活和开放；'
- en: (4)
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (4)
- en: 'Based on the external feedback, we identified the need for supporting troubleshooting,
    leading to the design decision [3.1.3](#S3.SS1.SSS3 "3.1.3\. Integrate with the
    IDE and Enhance Troubleshooting ‣ 3.1\. Design Overview ‣ 3\. NetLogo Chat System
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat"). We upgraded the underlying
    LLM to GPT-3.5-turbo-0613, fixed many minor usability issues, and finalized the
    prototype that we used in the empirical study.'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '基于外部反馈，我们发现需要支持故障排除，从而做出了设计决策 [3.1.3](#S3.SS1.SSS3 "3.1.3\. Integrate with
    the IDE and Enhance Troubleshooting ‣ 3.1\. Design Overview ‣ 3\. NetLogo Chat
    System ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat")。我们将底层 LLM 升级至 GPT-3.5-turbo-0613，修复了许多小的可用性问题，并最终确定了在实证研究中使用的原型。'
- en: 3.1\. Design Overview
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1\. 设计概述
- en: '![Refer to caption](img/12e391832eef8d51cc0123f3dd453820.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/12e391832eef8d51cc0123f3dd453820.png)'
- en: Figure 1\. NetLogo Chat asking for details about human’s needs.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1\. NetLogo Chat 询问关于人类需求的细节。
- en: \Description
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: \描述
- en: In this figure, the user asked NetLogo Chat ”create a flocking model”. NetLogo
    Chat started by searching for related documentation, provided several example
    models, then asked three follow-up questions to clarify the needs of the user.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在这张图中，用户要求 NetLogo Chat “创建一个群体模型”。NetLogo Chat 开始搜索相关文档，提供了几个示例模型，然后提出了三个后续问题以澄清用户的需求。
- en: '![Refer to caption](img/332007986223bec146becf453f809e3f.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/332007986223bec146becf453f809e3f.png)'
- en: Figure 2\. ChatGPT assuming details of human’s needs.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2\. ChatGPT 假设人类需求的细节。
- en: \Description
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: \描述
- en: In this figure, the user asked ChatGPT to ”create a flocking model in netlogo”.
    ChatGPT gave a direct response starting with ”Sure, I can help you create a simple
    flocking model in NetLogo”, then gave the user an instruction to open NetLogo,
    create a model, and copy a code snippet.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这张图中，用户要求 ChatGPT “创建一个 NetLogo 中的群体模型”。ChatGPT 直接回应了，开始说 “当然，我可以帮助你在 NetLogo
    中创建一个简单的群体模型”，然后给出了一条指示，让用户打开 NetLogo，创建一个模型，并复制一段代码片段。
- en: 3.1.1\. Enable users to program the computer, rather than being programmed by
    the computer
  id: totrans-68
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.1\. 使用户能够编程计算机，而不是被计算机编程
- en: Over-reliance on LLM-based interfaces has become a major concern among both
    educators and some learners, where students blindly follow the instructions given
    by LLMs without attempting to construct their representations of knowledge. Such
    a scenario is antithetical to the constructionist learning tradition, where Seymour
    Papert’s fear of ”computers program children” comes back to life again(Papert,
    [1980](#bib.bib61)).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 对LLM基础接口的过度依赖已成为教育工作者和一些学习者之间的主要关注点，学生盲目跟随LLMs提供的指令，而未尝试构建自己的知识表征。这种情况与建构主义学习传统背道而驰，其中
    Seymour Papert 对“计算机编程儿童”的恐惧再次浮现（Papert, [1980](#bib.bib61)）。
- en: 'Inspired by the Logo language, the design of NetLogo Chat aims to give control
    back to learners: to suppress LLMs’ tendency to give a quick response that often
    assumes too much about the learner’s inclination, we force it to ask clarification
    questions more often. Fig [1](#S3.F1 "Figure 1 ‣ 3.1\. Design Overview ‣ 3\. NetLogo
    Chat System ‣ Learning Programming of Agent-based Modeling with LLM Companions:
    Experiences of Novices and Experts Using ChatGPT & NetLogo Chat") and Fig [2](#S3.F2
    "Figure 2 ‣ 3.1\. Design Overview ‣ 3\. NetLogo Chat System ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") provide an exemplary comparison between NetLogo
    Chat and ChatGPT’s reaction to a simple modeling request. Here, ChatGPT immediately
    assumes details of the user’s needs and generates an entire model for the user
    to copy and paste. Whereas, NetLogo Chat attempts to first clarify the user’s
    needs by asking follow-up questions and suggesting exemplar answers. The suggestions
    in Fig [1](#S3.F1 "Figure 1 ‣ 3.1\. Design Overview ‣ 3\. NetLogo Chat System
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") serve as both an inspiration,
    in case learners get confused about what to write; and a shortcut, in case learners
    find any suggestions immediately usable.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 受到Logo语言的启发，NetLogo Chat的设计旨在将控制权交还给学习者：为了抑制LLMs倾向于迅速回应的趋势，这种回应通常过于假设学习者的倾向，我们迫使它更频繁地提出澄清问题。图[1](#S3.F1
    "图 1 ‣ 3.1\. 设计概述 ‣ 3\. NetLogo 聊天系统 ‣ 与LLM伙伴一起学习基于Agent的建模：初学者和专家使用ChatGPT &
    NetLogo Chat的经验")和图[2](#S3.F2 "图 2 ‣ 3.1\. 设计概述 ‣ 3\. NetLogo 聊天系统 ‣ 与LLM伙伴一起学习基于Agent的建模：初学者和专家使用ChatGPT
    & NetLogo Chat的经验")提供了NetLogo Chat和ChatGPT对简单建模请求的反应的典型比较。在这里，ChatGPT立即假设用户的需求细节，并生成一个完整的模型供用户复制和粘贴。而NetLogo
    Chat则试图通过提出后续问题和建议示例答案来首先澄清用户的需求。图[1](#S3.F1 "图 1 ‣ 3.1\. 设计概述 ‣ 3\. NetLogo 聊天系统
    ‣ 与LLM伙伴一起学习基于Agent的建模：初学者和专家使用ChatGPT & NetLogo Chat的经验")中的建议既可以作为灵感，以防学习者对写什么感到困惑；也可以作为捷径，以便学习者能立即使用任何建议。
- en: 'For this feature to work effectively, it is essential to ask questions with
    quality. To achieve this, we used a few-shot approach and crafted templates for
    LLMs to follow. We conducted an informal evaluation of LLM’s generated questions
    during our development process and empirical study. Across the board, the LLM
    we used was able to generate questions with acceptable quality, similar to the
    one demonstrated in Fig [1](#S3.F1 "Figure 1 ‣ 3.1\. Design Overview ‣ 3\. NetLogo
    Chat System ‣ Learning Programming of Agent-based Modeling with LLM Companions:
    Experiences of Novices and Experts Using ChatGPT & NetLogo Chat"). A future design
    could embed a larger set of templates and retrieve a few relevant templates when
    needed.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使此功能有效运作，提出高质量的问题至关重要。为此，我们采用了少量示例的方法，并为LLMs制定了模板。在开发过程中和经验研究中，我们对LLM生成的问题进行了非正式评估。总体而言，我们使用的LLM能够生成质量可接受的问题，类似于图[1](#S3.F1
    "图 1 ‣ 3.1\. 设计概述 ‣ 3\. NetLogo 聊天系统 ‣ 与LLM伙伴一起学习基于Agent的建模：初学者和专家使用ChatGPT &
    NetLogo Chat的经验")中展示的那种。未来的设计可以嵌入更多的模板，并在需要时检索一些相关模板。
- en: 3.1.2\. Invoke Authoritative Sources Whenever Possible
  id: totrans-72
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.2\. 尽可能调用权威来源
- en: 'Hallucination is another major concern for LLMs, particularly in an LRPL like
    NetLogo. For example, the code generated by ChatGPT in Fig [2](#S3.F2 "Figure
    2 ‣ 3.1\. Design Overview ‣ 3\. NetLogo Chat System ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") contains multiple syntax issues and requires human experts
    to address them. More powerful LLMs suffer from the same symptoms. We submitted
    similar sample requests to GPT-4, PaLM2, Anthropic Claude 2, and Falcon-180B:
    none was able to produce syntactically correct code for a classical NetLogo model.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '幻觉是LLMs的另一个主要问题，特别是在像NetLogo这样的LRPL中。例如，图 [2](#S3.F2 "Figure 2 ‣ 3.1\. Design
    Overview ‣ 3\. NetLogo Chat System ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat")中由ChatGPT生成的代码包含多个语法问题，需要人类专家进行处理。更强大的LLMs也有相同的症状。我们向GPT-4、PaLM2、Anthropic
    Claude 2和Falcon-180B提交了类似的样本请求：没有一个能够为经典NetLogo模型生成语法正确的代码。'
- en: Following previous examples in related tasks(Joshi et al., [2023](#bib.bib39)),
    we integrated NetLogo’s official documentation and model examples to help improve
    LLMs’ and human performance. Different from previous studies, we not only provided
    related examples to LLMs, but also revealed them to users. By doing so, we seek
    to improve the transparency of LLM’s mechanism, foster trust in the LLM-driven
    system, and provide authoritative guides and examples for users even when LLMs
    might fail to provide precise support.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 参考相关任务中的先前示例（Joshi等，[2023](#bib.bib39)），我们将NetLogo的官方文档和模型示例整合起来，以帮助提高LLMs和人类的表现。不同于以往的研究，我们不仅向LLMs提供了相关示例，还将其展示给用户。通过这样做，我们寻求提高LLM机制的透明度，增强对LLM驱动系统的信任，并在LLMs可能无法提供准确支持的情况下，为用户提供权威的指南和示例。
- en: '![Refer to caption](img/de29b250f55dbe659001a3ee10b3b5f1.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/de29b250f55dbe659001a3ee10b3b5f1.png)'
- en: Figure 3\. NetLogo Chat’s embedded editor for generated code.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图3\. NetLogo Chat的嵌入式编辑器用于生成的代码。
- en: \Description
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: \Description
- en: This figure demonstrates the interface of Turtle Universe (a version of NetLogo).
    On the left, there is a visualization of a simple model that draws a diagonal
    line. On the top-right, there is a code editor that has the code and a mistake
    introduced by the researcher. The editor shows a linting message and an ”explain”
    button. On the bottom-right is the conversation and interaction history between
    the user and NetLogo Chat.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 该图演示了Turtle Universe（NetLogo的一个版本）的界面。左侧是一个简单模型的可视化，该模型绘制了一条对角线。右上角是一个代码编辑器，其中包含代码和研究人员引入的错误。编辑器显示了一个代码检查消息和一个“解释”按钮。右下角是用户与NetLogo
    Chat之间的对话和互动历史。
- en: 3.1.3\. Integrate with the IDE and Enhance Troubleshooting
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.3\. 与IDE集成并增强故障排除
- en: We seek to integrate NetLogo Chat into NetLogo’s IDE beyond integrating a conversational
    assistant parallel to the code editor. To facilitate a constructionist learning
    experience, the code editor needs to be integrated into the conversational interface,
    where learners can work with smaller snippets of code with more ease. Thus, the
    design might lower the threshold for learners to tinker with the code, a key learning
    process advocated by the constructionist literature (Papert and Harel, [1991](#bib.bib62);
    Turkle and Papert, [1990](#bib.bib84)).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们寻求将NetLogo Chat集成到NetLogo的IDE中，不仅仅是将对话助手集成到代码编辑器旁边。为了促进建构主义学习体验，代码编辑器需要与对话界面集成，学习者可以更轻松地处理更小的代码片段。因此，设计可能会降低学习者修改代码的门槛，这是一种建构主义文献（Papert和Harel，[1991](#bib.bib62)；Turkle和Papert，[1990](#bib.bib84)）提倡的关键学习过程。
- en: 'Fig [3](#S3.F3 "Figure 3 ‣ 3.1.2\. Invoke Authoritative Sources Whenever Possible
    ‣ 3.1\. Design Overview ‣ 3\. NetLogo Chat System ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") provides a concrete example, where the embedded editor displays
    a piece of generated code. Instead of having to copy and paste the piece back
    into the main editor, the user could first see if any syntax issues exist in the
    code; run the code within a conversation; and ask follow-up questions or raise
    additional requests, before putting back a working code snippet into their projects.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '图 [3](#S3.F3 "Figure 3 ‣ 3.1.2\. Invoke Authoritative Sources Whenever Possible
    ‣ 3.1\. Design Overview ‣ 3\. NetLogo Chat System ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") 提供了一个具体的例子，其中嵌入的编辑器显示了一段生成的代码。用户可以首先查看代码中是否存在语法问题；在对话中运行代码；并在将有效的代码片段放回项目之前，提出后续问题或提出额外请求，而不需要将代码片段复制粘贴回主编辑器。'
- en: To further support the user’s troubleshooting, in addition to error messages,
    NetLogo Chat will display extra debugging options for users. Users could choose
    to look for an explanation, or ask the LLM to attempt fixing the issue on its
    own, or with the user’s ideas. During the process, the system will attempt to
    find documentation and related code examples to reduce hallucinations. Building
    on the literature on error messages’ impact on learning(Becker et al., [2019](#bib.bib6)),
    we also clarified many messages to provide a better context for humans and both
    LLM-based systems used in the study.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步支持用户的故障排除，除了错误消息外，NetLogo Chat还会为用户显示额外的调试选项。用户可以选择查看解释，或让LLM尝试自己解决问题，或结合用户的想法进行解决。在此过程中，系统将尝试查找文档和相关代码示例，以减少错误信息的产生。基于关于错误消息对学习影响的文献（Becker等，[2019](#bib.bib6)），我们还对许多消息进行了澄清，以提供更好的上下文给人类和本研究中使用的LLM系统。
- en: 3.2\. Technical Implementation
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2。技术实施
- en: '![Refer to caption](img/7cd5a81d1d67ab3864013313cc2adde7.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/7cd5a81d1d67ab3864013313cc2adde7.png)'
- en: Figure 4\. A brief outline for NetLogo Chat’s LLM workflow.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图4。NetLogo Chat的LLM工作流程简要概述。
- en: \Description
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: \描述
- en: 'In this figure, from left to right: User Request =¿ Planning =¿ Choose Action
    =¿ Search =¿ Documentation; Respond; Clarify =¿ User Input =¿ Planning =¿ …'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在此图中，从左到右：用户请求 =¿ 规划 =¿ 选择行动 =¿ 搜索 =¿ 文档；回应；澄清 =¿ 用户输入 =¿ 规划 =¿ …
- en: 'Since OpenAI started to provide fine-tuning on GPT-3.5-turbo (the version also
    used in ChatGPT Free) only after we concluded the main study in July, NetLogo
    Chat was implemented with prompt engineering techniques. We built our project
    on ReAct(Yao et al., [2022](#bib.bib100)), a prompt-based framework that could
    reduce hallucination, improve human interpretability, and increase the trustworthiness
    of LLMs. By requiring LLMs to generate an action plan and delegate the action
    to a third-party conventional agent (e.g. search for documentation, ask clarification
    questions, conduct a static syntax check, etc.) before composing the final response,
    the framework provides a promising pathway to integrate external inputs (e.g.
    human input, official documentation) into LLM workflows. Fig [4](#S3.F4 "Figure
    4 ‣ 3.2\. Technical Implementation ‣ 3\. NetLogo Chat System ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") depicts a rough outline of NetLogo Chat’s workflow.
    Imagine a user requests to ”create a predation model”:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 由于OpenAI在7月我们完成主要研究后才开始提供GPT-3.5-turbo（ChatGPT Free中也使用的版本）的微调，NetLogo Chat是通过提示工程技术实施的。我们在ReAct（Yao等，[2022](#bib.bib100)）的基础上构建了我们的项目，这是一种基于提示的框架，可以减少错误信息，改善人类可解释性，并提高LLM的可信度。通过要求LLM生成行动计划并将行动委托给第三方传统代理（例如，搜索文档，询问澄清问题，进行静态语法检查等），在编写最终回应之前，该框架提供了一条有前途的途径，将外部输入（例如人类输入，官方文档）整合到LLM工作流程中。图[4](#S3.F4
    "图4 ‣ 3.2。技术实施 ‣ 3。NetLogo Chat系统 ‣ 使用LLM助手学习基于代理的建模：新手和专家使用ChatGPT & NetLogo
    Chat的经验")描绘了NetLogo Chat工作流程的粗略概述。假设用户请求“创建一个捕食模型”：
- en: (1)
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: 'The LLM is instructed, in the prompt, to first elaborate on the request (planning):
    ”The user intends to create an agent-based biology model related to predation.
    However, it is unclear what exactly the user wants. We need to ask follow-up questions.”'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LLM在提示中被指示首先详细阐述请求（规划）：“用户打算创建一个与捕食相关的基于代理的生物模型。然而，尚不清楚用户的具体需求。我们需要提出后续问题。”
- en: (2)
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: 'Next, the LLM is instructed to choose an action from the list: Ask clarification
    question(s); Search for documentation; Write a response; Say sorry. Here, imagine
    the LLM chooses ”Ask clarification question(s)” based on the planning.'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接下来，LLM被指示从列表中选择一个行动：询问澄清问题；搜索文档；写回应；道歉。在这里，假设LLM根据规划选择了“询问澄清问题”。
- en: (3)
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3)
- en: Then, the LLM needs to generate some questions based on the request. Because
    LLMs are trained on real-world data, it is not difficult for them to come up with
    some ideas. For example, ”What species do you want to put in the model?” The LLM
    is also instructed to provide some examples, e.g. ”Wolf”, ”Sheep”.
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后，LLM需要根据请求生成一些问题。由于LLM是基于现实世界数据进行训练的，因此提出一些想法并不困难。例如，“您想在模型中放入哪些物种？” LLM还被指示提供一些示例，例如“狼”、“羊”。
- en: (4)
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (4)
- en: When the user replies to the questions, the loop restarts from step (1). Since
    there is sufficient information about the request, the LLM decides to search for
    information, and also generates keywords for the search, e.g. ”Wolf-sheep predation
    model in NetLogo”.
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当用户回复问题时，循环从步骤（1）重新开始。由于对请求的信息足够，LLM 决定搜索信息，并生成搜索关键词，例如“NetLogo 中的狼-羊捕食模型”。
- en: (5)
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (5)
- en: The system conducts a semantic search on a pre-assembled database of NetLogo’s
    official documentation and code examples. The system returns the search result,
    use it as a new round of input, and restarts from step (1).
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 系统在预组装的 NetLogo 官方文档和代码示例数据库上进行语义搜索。系统返回搜索结果，作为新的输入，并从步骤（1）重新开始。
- en: (6)
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (6)
- en: With inputs from both the user, who clarified the request; and the database,
    which supplies the example; the LLM plans again, chooses to write a response,
    and generates its final response.
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在用户提供了明确请求和数据库提供了示例后，LLM 再次计划，选择撰写响应，并生成最终回应。
- en: In the example, we initiated three requests with the LLM, each with a prompt
    template that results in a structured response(Yao et al., [2022](#bib.bib100))
    (e.g. any response needs to have a Plan, an Action, and a Parameter). Each request
    could use a different LLM that works best for the specific request. Using this
    approach, the system has the potential to balance cost, performance, speed, and
    privacy. For example, a future iteration of NetLogo Chat could leverage a fine-tuned
    local LLM to probe the user’s intentions and search for documentation. Then, with
    any personal or sensitive information stripped away, the system could forward
    the compiled request to a powerful online LLM (e.g. GPT-4).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们与 LLM 发起了三个请求，每个请求都有一个会生成结构化响应的提示模板（Yao 等，[2022](#bib.bib100)）（例如，任何响应都需要有一个计划、一个行动和一个参数）。每个请求可以使用最适合特定请求的不同
    LLM。采用这种方法，系统有潜力平衡成本、性能、速度和隐私。例如，未来的 NetLogo Chat 版本可以利用经过微调的本地 LLM 探测用户意图并搜索文档。然后，在剥离任何个人或敏感信息后，系统可以将编译后的请求转发给强大的在线
    LLM（例如 GPT-4）。
- en: For the empirical study, we chose GPT-3.5-turbo-0613 as NetLogo Chat’s LLM backend.
    First, we expect most participants to be using the free version of ChatGPT, driven
    by the same LLM. In this way, we would have a fair playing field for the empirical
    study, where both systems will be used. Second, at the time of our study, the
    response time for GPT-4 was too long to sustain a real-time experience, while
    we had no access to other NetLogo-capable LLMs’ APIs. Although we did observe
    some remarkable improvement when internally evaluating the system (e.g. ChatGPT
    has trouble answering questions for lesser-known NetLogo keywords, while NetLogo
    Chat does not), a more systematic evaluation rubric is needed for future research.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在实证研究中，我们选择了 GPT-3.5-turbo-0613 作为 NetLogo Chat 的 LLM 后端。首先，我们预期大多数参与者将使用 ChatGPT
    的免费版本，它由相同的 LLM 驱动。这样，我们将为实证研究提供一个公平的环境，两个系统都会被使用。其次，在我们研究时，GPT-4 的响应时间过长，无法维持实时体验，同时我们无法访问其他
    NetLogo 兼容的 LLM 的 API。尽管我们在内部评估系统时观察到了一些显著的改进（例如，ChatGPT 在回答不太知名的 NetLogo 关键词时有困难，而
    NetLogo Chat 则没有），但未来的研究需要一个更系统的评估标准。
- en: 4\. Empirical Study
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 实证研究
- en: 4.1\. Participants
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1\. 参与者
- en: 'For the empirical study, we recruited 30 adult participants through NetLogo’s
    official Twitter and mailing lists; and through the Complexity Explorer, a website
    run by Santa Fe Institute (SFI) to distribute learning resources of agent-based
    modeling (ABM). The exact breakdown of participants’ demographic data can be seen
    in Table [1](#S4.T1 "Table 1 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning
    Programming of Agent-based Modeling with LLM Companions: Experiences of Novices
    and Experts Using ChatGPT & NetLogo Chat"). The participant pool largely represented
    the scientific modeling community in NetLogo’s main audience, with a majority
    of participants coming from STEM disciplines. Many participants were also related
    to the educator sector. 6 participants (20%) were instructors who teach or are
    interested in teaching NetLogo in classrooms; 4 (13%) were graduate-level students
    interested in learning NetLogo, making up a third of the population. Participation
    in the study was voluntary. All participants signed an online consent form on
    Qualtrics.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '对于这项实证研究，我们通过 NetLogo 官方 Twitter 和邮件列表招募了 30 名成年参与者；还通过 Complexity Explorer
    网站（由圣塔费研究所（SFI）运营，用于分发基于代理建模（ABM）的学习资源）进行了招募。参与者人口数据的具体分类见表 [1](#S4.T1 "Table
    1 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat")。参与者池主要代表了 NetLogo 主要观众中的科学建模社区，大多数参与者来自 STEM 学科。许多参与者也与教育领域相关。6
    名参与者（20%）是教授或有兴趣在课堂上教授 NetLogo 的讲师；4 名（13%）是有兴趣学习 NetLogo 的研究生，占总人口的三分之一。参与研究是自愿的。所有参与者在
    Qualtrics 上签署了在线同意书。'
- en: 'Building on the tradition of understanding the difference between experts and
    novices(Chi et al., [1981](#bib.bib18)), we separated the participants into experts
    and novices using self-reported survey data. To mitigate the effect of inaccurate
    responses, NetLogo experts in the team, who have been core developers and instructors
    of NetLogo, watched every video and decided if a participant greatly overestimated
    or underestimated their capabilities. We considered the participant’s discussions
    with the interviewer, the think-aloud process, and the coding behaviors. A vast
    majority of users’ reports correspond with the experts’ judgment. Then, to simplify
    the analysis, we separated participants (Table [2](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat"))
    by their levels into two main categories: experts, who are either experts in NetLogo
    or programming in general; and novices. In the study, we denote experts by the
    prefix E (E01-E17) and novices by N (N01-N13). 13 experts had previous experience
    with ChatGPT (76%), including programming (65%, n=11). 11 novices (85%) also used
    ChatGPT before, but much less for programming (38%, n=5).'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '基于理解专家与新手之间差异的传统（Chi 等，[1981](#bib.bib18)），我们使用自报的调查数据将参与者分为专家和新手。为了减轻不准确回答的影响，团队中的
    NetLogo 专家（核心开发者和讲师）观看了每个视频，并决定参与者是否严重高估或低估了他们的能力。我们考虑了参与者与面试官的讨论、思维过程以及编码行为。绝大多数用户报告与专家的判断一致。然后，为了简化分析，我们将参与者（表
    [2](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat")）按其级别分为两大类：专家，即在 NetLogo 或编程方面的专家；和新手。在研究中，我们用前缀
    E（E01-E17）表示专家，用 N（N01-N13）表示新手。13 位专家有使用 ChatGPT 的经验（76%），其中包括编程经验（65%，n=11）。11
    位新手（85%）也使用过 ChatGPT，但编程方面使用较少（38%，n=5）。'
- en: Table 1\. Overview of Participant Demographics (n=30)
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1\. 参与者人口统计概览 (n=30)
- en: '| Gender | Females: 10 (33%); Male: 19 (63%); Non-binary: 1 (3%) |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 性别 | 女性：10（33%）；男性：19（63%）；非二元：1（3%） |'
- en: '| --- | --- |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Geography | Africa: 1 (3%); Asia and Oceania: 5 (17%); Europe: 8 (27%); Latin
    America: 2 (7%); North America: 14 (47%). |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 地理 | 非洲：1（3%）；亚洲和大洋洲：5（17%）；欧洲：8（27%）；拉丁美洲：2（7%）；北美：14（47%）。 |'
- en: '| Occupation | Academics: 14 (47%); Professionals: 12 (40%); Students: 4 (13%)
    |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 职业 | 学术界：14（47%）；专业人士：12（40%）；学生：4（13%） |'
- en: Table 2\. Participant Information
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2\. 参与者信息
- en: '| ID | Region | Level (NetLogo) | Level (Programming) | Occupation |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| ID | 地区 | NetLogo 级别 | 编程级别 | 职业 |'
- en: '| E01 | North America | Expert | Expert | Professional |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| E01 | 北美 | 专家 | 专家 | 职业 |'
- en: '| E02 | Asia and Oceania | Expert | Intermediate | Academic |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| E02 | 亚洲和大洋洲 | 专家 | 中级 | 学术 |'
- en: '| E03 | Latin America | Intermediate | Expert | Academic |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| E03 | 拉丁美洲 | 中级 | 专家 | 学术 |'
- en: '| E04 | North America | Expert | Expert | Academic |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| E04 | 北美 | 专家 | 专家 | 学术 |'
- en: '| E05 | Europe | Intermediate | Expert | Academic |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| E05 | 欧洲 | 中级 | 专家 | 学术 |'
- en: '| E06 | North America | Intermediate | Intermediate | Academic |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| E06 | 北美 | 中级 | 中级 | 学术 |'
- en: '| E07 | Latin America | Intermediate | Intermediate | Professional |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| E07 | 拉丁美洲 | 中级 | 中级 | 职业 |'
- en: '| E08 | Asia and Oceania | Intermediate | Intermediate | Professional |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| E08 | 亚洲和大洋洲 | 中级 | 中级 | 职业 |'
- en: '| E09 | Asia and Oceania | Intermediate | Expert | Professional |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| E09 | 亚洲和大洋洲 | 中级 | 专家 | 职业 |'
- en: '| E10 | North America | Intermediate | Intermediate | Academic |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| E10 | 北美 | 中级 | 中级 | 学术 |'
- en: '| E11 | Africa | Intermediate | Expert | Academic |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| E11 | 非洲 | 中级 | 专家 | 学术 |'
- en: '| E12 | North America | Intermediate | Intermediate | Academic |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| E12 | 北美 | 中级 | 中级 | 学术 |'
- en: '| E13 | Europe | Expert | Novice | Academic |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| E13 | 欧洲 | 专家 | 初学者 | 学术 |'
- en: '| E14 | Europe | Intermediate | Intermediate | Academic |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| E14 | 欧洲 | 中级 | 中级 | 学术 |'
- en: '| E15 | Asia and Oceania | Expert | Expert | Student |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| E15 | 亚洲和大洋洲 | 专家 | 专家 | 学生 |'
- en: '| E16 | Asia and Oceania | Novice | Expert | Professional |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| E16 | 亚洲和大洋洲 | 初学者 | 专家 | 职业 |'
- en: '| E17 | Europe | Intermediate | Expert | Academic |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| E17 | 欧洲 | 中级 | 专家 | 学术 |'
- en: '| N01 | North America | Novice | Novice | Professional |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| N01 | 北美 | 初学者 | 初学者 | 职业 |'
- en: '| N02 | North America | Novice | Novice | Academic |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| N02 | 北美 | 初学者 | 初学者 | 学术 |'
- en: '| N03 | North America | Novice | Novice | Professional |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| N03 | 北美 | 初学者 | 初学者 | 职业 |'
- en: '| N04 | North America | Novice | Intermediate | Student |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| N04 | 北美 | 初学者 | 中级 | 学生 |'
- en: '| N05 | Europe | Novice | Intermediate | Student |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| N05 | 欧洲 | 初学者 | 中级 | 学生 |'
- en: '| N06 | Europe | Intermediate | Novice | Student |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| N06 | 欧洲 | 中级 | 初学者 | 学生 |'
- en: '| N07 | North America | Novice | Intermediate | Professional |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| N07 | 北美 | 初学者 | 中级 | 职业 |'
- en: '| N08 | North America | Novice | Intermediate | Professional |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| N08 | 北美 | 初学者 | 中级 | 职业 |'
- en: '| N09 | North America | Novice | Novice | Professional |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| N09 | 北美 | 初学者 | 初学者 | 职业 |'
- en: '| N10 | North America | Novice | Intermediate | Professional |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| N10 | 北美 | 初学者 | 中级 | 职业 |'
- en: '| N11 | Europe | Novice | Intermediate | Academic |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| N11 | 欧洲 | 初学者 | 中级 | 学术 |'
- en: '| N12 | Europe | Novice | Novice | Academic |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| N12 | 欧洲 | 初学者 | 初学者 | 学术 |'
- en: '| N13 | North America | Intermediate | Novice | Professional |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| N13 | 北美 | 中级 | 初学者 | 职业 |'
- en: 4.2\. Interviews
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2. 访谈
- en: 'Our study was conducted in 3 phases:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究分为3个阶段：
- en: (1)
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: We pilot interviewed 3 experts invited from NetLogo’s online community. Each
    was asked to comment on LLMs for NetLogo learning, as well as on ChatGPT and an
    early prototype of NetLogo Chat.
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们对3位来自NetLogo在线社区的专家进行了初步访谈。每位专家都被要求对NetLogo学习的LLMs、ChatGPT以及NetLogo Chat的早期原型进行评论。
- en: (2)
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: We improved the design of NetLogo Chat based on what we learned from the pilot
    interviews and revised the interview protocol accordingly.
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们基于从初步访谈中学到的内容改进了NetLogo Chat的设计，并相应修订了访谈协议。
- en: (3)
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3)
- en: We conducted formal interviews with 27 online participants (30 in total).
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们对27名在线参与者（共30人）进行了正式访谈。
- en: 'Each semi-structured interview lasted between 60-90 minutes and was video recorded.
    Prior to each formal interview, participants were asked to come up with a short
    NetLogo task that they were interested in working on. Almost every participant
    brought forward a modeling task from their career domain or personal interest,
    e.g. to model ”how honeybees decide to regulate the temperature of the hive”,
    or ”the spread of conflicting ideas”. Only once, when the task scope was too complicated
    for the session, did we ask the participant to bring another. During any part
    of the interview process, interviewers generally followed the protocol, asking
    follow-up questions when needed. Specifically:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 每次半结构化访谈持续60到90分钟，并进行了录像。在每次正式访谈之前，参与者被要求准备一个他们感兴趣的NetLogo任务。几乎每位参与者都提出了一个与他们职业领域或个人兴趣相关的建模任务，例如“蜜蜂如何决定调节蜂巢温度”，或“冲突观点的传播”。只有在任务范围过于复杂时，我们才要求参与者提供另一个任务。在访谈过程中，访谈者通常遵循协议，根据需要提出跟进问题。具体而言：
- en: (1)
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: We asked baseline questions, e.g., “What do you think are the potential advantages
    / disadvantages of using LLMs in supporting your learning and programming of NetLogo?”
    (in 2 separate questions)
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了基线问题，例如，“你认为使用LLMs支持你的NetLogo学习和编程有哪些潜在的优势/劣势？”（分成两个问题）
- en: (2)
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: We asked the participant to work on their task with the help of ChatGPT. Then,
    we asked the same baseline questions again, then asked “What do you like or dislike
    about the interface”. Repeat the procedure with NetLogo Chat;
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们要求参与者在 ChatGPT 的帮助下完成任务。然后，我们再次询问相同的基线问题，并问“你喜欢或不喜欢这个接口的哪些方面”。对 NetLogo Chat
    重复相同的程序；
- en: (3)
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3)
- en: If time permitted, we further asked about their preferences for learning and/or
    programming with NetLogo and asked which feature they wanted to add/remove from
    either system. Here, the objective was not to strictly compare between the two
    systems, but to elicit more in-depth discussions over LLM-based interfaces.
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果时间允许，我们进一步询问了他们对使用 NetLogo 学习和/或编程的偏好，并询问了他们希望在系统中添加/删除哪些功能。在这里，目标不是严格比较这两个系统，而是引发关于基于
    LLM 的接口的更深入讨论。
- en: Since almost all users have already engaged with ChatGPT, we did not randomize
    the order of ChatGPT/NetLogo Chat. Also, 3 participants used the paid version
    (GPT-4) during the task with ChatGPT. While much of the generated data comes from
    the inevitable comparison between the two systems, we chose not to interpret them
    as objective comparisons. Instead, the different design principles underpinning
    the systems presented two objects to think with(Papert, [1980](#bib.bib61)), that
    our participants drew on during their reflections and discussions of LLM-based
    programming interfaces.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 由于几乎所有用户都已经使用过 ChatGPT，我们没有对 ChatGPT/NetLogo Chat 的顺序进行随机化。此外，3 名参与者在与 ChatGPT
    任务中使用了付费版本 (GPT-4)。虽然生成的数据大多来自两个系统之间的不可避免比较，但我们选择不将其解释为客观比较。相反，这些系统所支持的不同设计原则呈现了两个思考对象
    (Papert, [1980](#bib.bib61))，我们的参与者在对基于 LLM 的编程接口的反思和讨论中借鉴了这些对象。
- en: 4.3\. Data Analysis
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3\. 数据分析
- en: Our interviews resulted in around 40 hours of video data. Around half of our
    data is behavioral in nature, where participants worked on their tasks and were
    encouraged to think aloud; the other half is more verbal, where participants answered
    questions. As such, each interview was not only transcribed verbatim, but also
    watched by a researcher to create observational notes. The two streams were then
    combined into a single archive for analysis.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的访谈产生了大约 40 小时的视频数据。大约一半的数据是行为性的，参与者在完成任务时被鼓励大声思考；另一半则更多是言语性的，参与者回答问题。因此，每次访谈不仅逐字转录，还由研究人员观看以创建观察笔记。这两部分数据随后被合并成一个单一的档案进行分析。
- en: 'Based on our research questions, we iteratively applied the grounded theory
    approach(Corbin and Strauss, [1990](#bib.bib23)) to analyze our data. During each
    step, the research team fully discussed the discrepancies between each researcher
    and iteratively refined the codebook to improve consistency. The analysis reached
    theoretical saturation at around 50% of interviews, when additional interviews
    no longer revealed unexpected major insights for our research questions. Then,
    we finished the rest of qualitative coding with the finalized codebook (Table
    [3](#S4.T3 "Table 3 ‣ 4.3\. Data Analysis ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat")).'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '基于我们的研究问题，我们迭代地应用了扎根理论方法 (Corbin and Strauss, [1990](#bib.bib23)) 来分析数据。在每个步骤中，研究团队充分讨论了每位研究者之间的差异，并迭代地完善了编码本以提高一致性。分析在大约
    50% 的访谈时达到了理论饱和，当额外的访谈不再揭示出我们研究问题的意外主要见解时，我们结束了其余的定性编码工作，并使用了最终的编码本 (表 [3](#S4.T3
    "Table 3 ‣ 4.3\. Data Analysis ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat"))。'
- en: (1)
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: 'Four researchers open-coded 2 interviews, one from a novice and one from an
    expert, to summarize the topics mentioned by participants. During this process,
    researchers coded in different tabs to avoid interference. Three broad themes
    emerged from this phase: participants’ approaches to programming; participants’
    interactions with AI systems; and their comments on AI systems.'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 四位研究人员对 2 次访谈进行了开放编码，一次来自新手，一次来自专家，以总结参与者提到的主题。在此过程中，研究人员在不同的标签页中编码以避免干扰。从这一阶段出现了三个广泛的主题：参与者对编程的看法；参与者与
    AI 系统的互动；以及他们对 AI 系统的评价。
- en: (2)
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: Taking notes of the emerging themes, the first author created a preliminary
    codebook that categorizes dozens of codes into themes. Each researcher coded another
    2 interviews in different tabs. In this phase, we refined the themes into approaches
    to programming (which also helps to separate experts and novices); perceptions
    and observed behaviors related to AI systems; and comments on AI systems’ abilities.
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 记录新兴主题，第一作者创建了一个初步编码本，将几十个编码分类到主题中。每位研究人员在不同的标签中对另外两个访谈进行了编码。在这一阶段，我们将主题细化为编程方法（这也有助于区分专家和新手）；与
    AI 系统相关的看法和观察到的行为；以及对 AI 系统能力的评论。
- en: (3)
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3)
- en: 'Based on the coding results, the first author created a formal codebook, with
    definitions clarified based on the discrepancies between researchers (Table [3](#S4.T3
    "Table 3 ‣ 4.3\. Data Analysis ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat")). To reduce the unbalanced influence of subjective interpretation,
    researchers only coded explicit behaviors; or direct comments. To avoid missing
    insights, researchers were instructed to highlight places where existing codes
    are insufficient to cover the topics. During the first two weeks, a few codes
    were created or merged as a result of discussions. We retrospectively revised
    our coding.'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '根据编码结果，第一作者创建了一个正式的编码本，并根据研究者之间的差异明确了定义（见表[3](#S4.T3 "Table 3 ‣ 4.3\. Data
    Analysis ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat")）。为了减少主观解释的不平衡影响，研究人员仅编码明确的行为或直接评论。为了避免遗漏见解，研究人员被指示突出显示现有编码不足以涵盖的话题。在前两周内，因讨论而创建或合并了一些编码。我们对编码进行了回顾性修订。'
- en: Table 3\. An Overview of the Codebook
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3\. 编码本概览
- en: '| Code | Definition |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 代码 | 定义 |'
- en: '| --- | --- |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Approaches | User’s perceptions about their approach to programming tasks,
    e.g. planning, separating into smaller pieces, or working on it as a whole. |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 用户对编程任务的方法的看法，例如规划、拆分成较小的部分或整体进行。 |'
- en: '| Learning | How users learn NetLogo or programming in general, or think that
    people should learn. |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 学习 | 用户如何学习 NetLogo 或编程，或认为人们应该如何学习。 |'
- en: '| Coding | How users organize or write their code, or think that people should
    organize or write. |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| 编码 | 用户如何组织或编写代码，或认为人们应该如何组织或编写。 |'
- en: '| Help-seeking | How users seek help in general, or think that people should
    seek help. |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| 寻求帮助 | 用户如何寻求帮助，或认为人们应该如何寻求帮助。 |'
- en: '| Human-AI | User’s perception and behaviors related to Human-AI relationship.
    |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| 人工智能关系 | 用户对人类与 AI 关系的看法和行为。 |'
- en: '| Prior | Users’ prior experiences with ChatGPT or other AI-based interfaces.
    |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 先前经验 | 用户对 ChatGPT 或其他基于 AI 的界面的先前经验。 |'
- en: '| Attitude | Users’ attitudes toward AI in general, or specific AI-based systems.
    |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| 态度 | 用户对 AI 的总体态度，或对特定 AI 系统的态度。 |'
- en: '| Effort | AI’s influence on how much, and what kind of, efforts that humans
    made or need to make. |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| 努力 | AI 对人类所付出或需要付出的努力的影响，以及努力的种类。 |'
- en: '| Abilities | User’s perception related to AI’s abilities. |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 能力 | 用户对 AI 能力的看法。 |'
- en: '| Response | AI’s ability to provide desirable responses for humans. |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 响应 | AI 提供令人满意的回应的能力。 |'
- en: '| Support | AI’s ability to support learning/coding of NetLogo. |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 支持 | AI 支持 NetLogo 学习/编码的能力。 |'
- en: '| Interactivity | AI’s ability to facilitate helpful interactions with humans.
    |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| 互动性 | AI 促进与人类进行有帮助的互动的能力。 |'
- en: Based on the codebook, the first author iteratively incorporates themes into
    an outline. To further mitigate individual differences, researchers were asked
    to include as many codes as possible for each quote or observation.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 根据编码本，第一作者迭代地将主题纳入大纲。为了进一步减少个体差异，研究人员被要求为每个引述或观察尽可能多地包括代码。
- en: 5\. Findings
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 发现
- en: '5.1\. Perception: Before and After Interaction'
  id: totrans-186
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1\. 看法：互动前后的变化
- en: Table 4\. Novices and Experts’ Perceptions on LLM-based Interfaces for NetLogo
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4\. 新手与专家对基于 LLM 的 NetLogo 界面的看法
- en: '|  | Experts | Novices |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '|  | 专家 | 新手 |'
- en: '| --- | --- | --- |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '|  | LLMs could save human time and effort, especially in syntax. | LLMs could
    save human time and effort, especially for syntax, and provide emotional benefits.
    |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '|  | LLM 可以节省人力时间和精力，特别是在语法方面。 | LLM 可以节省人力时间和精力，尤其是在语法方面，并提供情感上的好处。 |'
- en: '| Before, Positive |  | LLMs could help troubleshooting. |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| 之前，积极 |  | LLM 可以帮助故障排除。 |'
- en: '|  | LLMs could mislead humans to suboptimal directions. | While LLMs may make
    mistakes, it is no worse than humans. |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '|  | LLMs 可能会引导人们走向次优方向。 | 尽管 LLMs 可能会出错，但这并不比人类差。 |'
- en: '|  | LLMs could hinder learning processes. | LLMs may not understand human
    intentions. |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '|  | LLMs 可能会阻碍学习过程。 | LLMs 可能无法理解人类的意图。 |'
- en: '| Before, Negative | LLMs could only work on smaller tasks. | LLMs’ responses
    are difficult to understand. |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| 之前，负面 | LLMs 只能处理较小的任务。 | LLMs 的回应难以理解。 |'
- en: '|  | LLMs supported learning or practicing by saving time. | LLMs supported
    learning or practicing by saving time. |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '|  | LLMs 通过节省时间来支持学习或练习。 | LLMs 通过节省时间来支持学习或练习。 |'
- en: '| After Interaction | Will continue to use LLMs for learning or practicing
    NetLogo. | Will seek alternative learning resources before continuing to use LLMs.
    |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| 互动后 | 将继续使用 LLMs 来学习或练习 NetLogo。 | 在继续使用 LLMs 之前将寻求其他学习资源。 |'
- en: '5.1.1\. Before Interaction: Positive Expectations'
  id: totrans-197
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.1\. 互动前：积极期望
- en: Prior to the tasks, both novices and experts had positive expectations of LLM-based
    interfaces for NetLogo, with novices holding higher expectations than experts.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在任务开始之前，无论是新手还是专家，对基于 LLM 的 NetLogo 接口都有积极的期望，其中新手的期望高于专家。
- en: 'Both novices and experts expected LLM-based interfaces to save human time and
    support human effort, especially compared to other help-seeking activities. With
    LLMs, human time and energy could be liberated for more high-level tasks ([E12](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat"), [N03](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat")). Educators felt that LLMs
    could facilitate more efficient teaching, allowing students to \saymore complicated
    things with relative ease, spiking \saytheir imagination. ([E02](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat")) LLMs can also bring emotional benefits by reducing the fear
    of \saybothering the teachers or the experts ([E14](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat"))
    or asking \saystupid questions ([N06](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\.
    Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM Companions:
    Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")).'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '无论是新手还是专家，都期望基于 LLM 的接口能节省人力时间和支持人力工作，特别是与其他寻求帮助的活动相比。有了 LLMs，人力时间和精力可以解放出来用于更高级的任务
    ([E12](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat"), [N03](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\.
    Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM Companions:
    Experiences of Novices and Experts Using ChatGPT & NetLogo Chat"))。教育者认为，LLMs
    可以促进更高效的教学，使学生能够相对轻松地表达*更复杂的内容*，激发他们的想象力 ([E02](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat"))。LLMs
    还能通过减少*打扰老师或专家*的恐惧感 ([E14](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat")) 或询问*愚蠢的问题* ([N06](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat")) 带来情感上的好处。'
- en: 'Most participants highlighted AI’s potential to help them with NetLogo’s syntax.
    For most participants, NetLogo is not the main programming language they used.
    Before the advent of ChatGPT, [N06](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\.
    Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM Companions:
    Experiences of Novices and Experts Using ChatGPT & NetLogo Chat") felt that she
    needed to \sayrecite the words (syntax of NetLogo). Yet, the need was eliminated
    when \sayAI can teach you very quickly. Many experts also needed support, as NetLogo
    \sayhas very strict syntax rules ([E07](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣
    4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM Companions:
    Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")) which makes
    writing more difficult.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数参与者强调了AI在帮助他们理解NetLogo语法方面的潜力。对于大多数参与者来说，NetLogo并不是他们主要使用的编程语言。在ChatGPT出现之前，[N06](#S4.T2
    "表 2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究 ‣ 使用LLM助手学习基于Agent的建模编程：新手和专家使用ChatGPT与NetLogo Chat的经历")
    觉得她需要“背诵单词（NetLogo的语法）”。然而，当“AI可以非常快速地教你”时，这种需求就消失了。许多专家也需要支持，因为NetLogo“有非常严格的语法规则”([E07](#S4.T2
    "表 2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究 ‣ 使用LLM助手学习基于Agent的建模编程：新手和专家使用ChatGPT与NetLogo Chat的经历"))，这使得编写更加困难。
- en: 'Novices, in particular, expected that AI could be helpful for troubleshooting.
    [N08](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat"), for instance, felt that LLMs could help him through
    the troubleshooting process by describing \saywhat I’m trying to do and get a
    snippet of code that helps get me past that block. For novices without a background
    in programming, this future looks promising. [N12](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    is interested in the potential to \saymake programming more approachable to students.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是新手，期望AI可以在故障排除方面提供帮助。例如，[N08](#S4.T2 "表 2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究 ‣ 使用LLM助手学习基于Agent的建模编程：新手和专家使用ChatGPT与NetLogo
    Chat的经历") 觉得LLM可以通过描述“我正在尝试做什么并获得一段帮助我解决问题的代码”来帮助他完成故障排除。对于没有编程背景的新手来说，这样的未来看起来很有前景。[N12](#S4.T2
    "表 2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究 ‣ 使用LLM助手学习基于Agent的建模编程：新手和专家使用ChatGPT与NetLogo Chat的经历")
    对于将编程变得对学生更易于接触的潜力感兴趣。
- en: '5.1.2\. Before Interaction: Negative Expectations'
  id: totrans-202
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.2\. 互动前：负面预期
- en: Almost every participant expressed concerns or reservations about LLM-based
    interfaces. Yet, the concerns of novices and experts were conspicuously different.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎所有参与者都对基于LLM的接口表示了担忧或保留意见。然而，新手和专家的担忧明显不同。
- en: 'Experts focused on preserving human judgment. [E01](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") believed that AI should not \sayreplace human judgment and ability. Similarly,
    [E06](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") insisted that \say(human) has to do the main thinking
    and ideas and all of that. [E17](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") felt that humans cannot
    let AI \saytake over the main reasoning and emotions, the emotions intervening
    in the decisions. Many educators were also \sayconcerned about learning ([E13](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat")), fearing the tendency to \saydefault to the AI system
    to come up with the answers instead of working through it ourselves ([E12](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat")). Many experts explicitly explained their rationales.
    For example, [E08](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") was concerned that \sayif
    a model points me to a suboptimal direction, I will have no idea, because I haven’t
    considered alternative structure. [E15](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣
    4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM Companions:
    Experiences of Novices and Experts Using ChatGPT & NetLogo Chat") feared that
    relying on AI responses might \saymake your horizon narrow because she would miss
    learning opportunities when browsing through the models library. For computational
    modeling, AI also might lack \sayin-depth knowledge in a specific field to create
    an entire model ([E05](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat")). As such, [E05](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") would only trust AI to \sayfinish a specific task.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '专家们专注于保留人类的判断力。[E01](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") 认为 AI 不应该**取代**人类的判断和能力。同样，[E06](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") 坚持认为 **（人类）** 必须进行主要的思考和提出所有的想法。[E17](#S4.T2 "Table 2
    ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") 认为人类不能让 AI **接管**主要的推理和情感，这些情感会干预决策。许多教育工作者也对学习**感到担忧**（[E13](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat")），担心会**倾向于**依赖 AI 系统来得出答案，而不是自己**解决问题**（[E12](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat")）。许多专家明确解释了他们的理由。例如，[E08](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    担心 **如果** 一个模型指向了一个次优的方向，他将**毫无头绪**，因为他没有考虑过其他的结构。[E15](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") 担心依赖 AI 的回答可能会**缩小你的视野**，因为她在浏览模型库时会错过学习机会。对于计算建模，AI 也可能**缺乏**在特定领域的深入知识，无法创建一个完整的模型（[E05](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat")）。因此，[E05](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\.
    Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM Companions:
    Experiences of Novices and Experts Using ChatGPT & NetLogo Chat") 只会**信任** AI
    来**完成特定任务**。'
- en: 'Novices were more optimistic and more concerned with their capabilities of
    understanding AI’s responses or making AI understand them. For example, while
    [N04](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") thought \sayone of the hypothetical drawbacks to
    LLMs being \sayconfidently incorrect, they added that \saypeople are like this
    too. On the other hand, [N03](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") feared that she would waste
    more time with AI if \sayit didn’t understand me, or if I had difficulty expressing.
    [N02](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") acknowledged that \saythere is a limitation to
    not knowing how to code (on how much AI could help). Without knowledge of NetLogo,
    [N11](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") felt difficult to spot LLM-generated mistakes.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '新手更为乐观，并且更关注他们理解AI响应的能力或让AI理解他们的能力。例如，[N04](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    认为其中一个假设性的LLM缺陷是**自信地错误**，但他们补充说**人们也是这样**。另一方面，[N03](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") 担心如果**它不理解我**或如果我难以表达，她会浪费更多时间与AI互动。[N02](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    承认**不知道如何编码（AI能提供多大帮助）是一个限制**。没有NetLogo的知识，[N11](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    觉得很难发现LLM生成的错误。'
- en: '5.1.3\. After Interactions: Different Impacts of Hallucination'
  id: totrans-206
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.3\. 互动后的影响：幻觉的不同影响
- en: 'All participants encountered AI hallucinations throughout the sessions. While
    some participants rated NetLogo Chat higher than ChatGPT’s free version, most
    participants had similar changes in perceptions: experts, in general, reported
    more benefits from LLMs than novices.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 所有参与者在会议中都遇到了AI幻觉。虽然有些参与者对NetLogo Chat的评价高于ChatGPT的免费版本，但大多数参与者的感知变化类似：专家通常报告从LLMs中获得了更多的好处，而新手则相对较少。
- en: 'Some participants reported more positively about NetLogo Chat’s capabilities.
    Several experts questioned ChatGPT’s training in NetLogo, yet they trusted more
    in NetLogo Chat, for it incorporates authoritative sources (see [3.1.2](#S3.SS1.SSS2
    "3.1.2\. Invoke Authoritative Sources Whenever Possible ‣ 3.1\. Design Overview
    ‣ 3\. NetLogo Chat System ‣ Learning Programming of Agent-based Modeling with
    LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")).
    [E16](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") believed that NetLogo Chat \sayunderstands your
    NetLogo syntax and \saythe basic aspects of NetLogo. [N02](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") thought NetLogo Chat still had bugs but was \saymuch more informative and
    precise than ChatGPT. As NetLogo Chat is designed to support troubleshooting (see
    [3.1.3](#S3.SS1.SSS3 "3.1.3\. Integrate with the IDE and Enhance Troubleshooting
    ‣ 3.1\. Design Overview ‣ 3\. NetLogo Chat System ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat")), [E04](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") thought NetLogo Chat \saywas
    able to kind of do some better troubleshooting to a certain extent, for it clarifies
    error codes.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 一些参与者对NetLogo Chat的功能表示了更积极的评价。尽管有几位专家质疑ChatGPT在NetLogo方面的训练，但他们对NetLogo Chat的信任更多，因为它包含了权威来源（见
    [3.1.2](#S3.SS1.SSS2 "3.1.2\. 只要可能，就调用权威来源 ‣ 3.1\. 设计概述 ‣ 3\. NetLogo Chat 系统
    ‣ 使用LLM助手学习基于代理的建模：ChatGPT和NetLogo Chat的新手与专家的经历")）。[E16](#S4.T2 "表2 ‣ 4.1\. 参与者
    ‣ 4\. 实证研究 ‣ 使用LLM助手学习基于代理的建模：ChatGPT和NetLogo Chat的新手与专家的经历") 认为NetLogo Chat \say了解你的NetLogo语法和
    \sayNetLogo的基本方面。[N02](#S4.T2 "表2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究 ‣ 使用LLM助手学习基于代理的建模：ChatGPT和NetLogo
    Chat的新手与专家的经历") 认为NetLogo Chat虽然仍有一些错误，但比ChatGPT \say更具信息性和准确性。由于NetLogo Chat被设计用来支持故障排除（见
    [3.1.3](#S3.SS1.SSS3 "3.1.3\. 与IDE集成并增强故障排除 ‣ 3.1\. 设计概述 ‣ 3\. NetLogo Chat 系统
    ‣ 使用LLM助手学习基于代理的建模：ChatGPT和NetLogo Chat的新手与专家的经历")），[E04](#S4.T2 "表2 ‣ 4.1\. 参与者
    ‣ 4\. 实证研究 ‣ 使用LLM助手学习基于代理的建模：ChatGPT和NetLogo Chat的新手与专家的经历") 认为NetLogo Chat \say在某种程度上能够进行更好的故障排除，因为它能够澄清错误代码。
- en: 'In both cases, experts understood hallucinations as an inevitable part of human-AI
    collaboration and reacted with more leniency. When [E03](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") first encountered an incorrect response, he exclaimed: \sayVery interesting!
    You’re mistaken. [E05](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") felt that LLMs helped him
    \sayfinish most of the code, though he still needed to \saydebug and see if the
    code makes sense logically. As experts did not rely on LLMs to resolve issues
    but mostly leveraged them as a shortcut, [E06](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    stated that hallucinations were instances \saywhere the programmer needs to use
    own experience and discretion, as risks would escalate if one extrapolates \saywhat
    ChatGPT provides you in a wrong manner.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，专家将幻觉视为人机协作中的不可避免的部分，并采取了更宽容的态度。当[E03](#S4.T2 "表2 ‣ 4.1\. 参与者 ‣ 4\.
    实证研究 ‣ 使用LLM助手学习基于代理的建模：ChatGPT和NetLogo Chat的新手与专家的经历")第一次遇到不正确的回应时，他惊呼：\say非常有趣！你错了。[E05](#S4.T2
    "表2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究 ‣ 使用LLM助手学习基于代理的建模：ChatGPT和NetLogo Chat的新手与专家的经历")
    觉得LLMs帮助他 \say完成了大部分代码，尽管他仍然需要 \say调试并查看代码在逻辑上是否合理。由于专家并不依赖LLMs来解决问题，而主要将其作为一种捷径，[E06](#S4.T2
    "表2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究 ‣ 使用LLM助手学习基于代理的建模：ChatGPT和NetLogo Chat的新手与专家的经历")
    认为幻觉是 \say程序员需要利用自身经验和判断的实例，因为如果以错误的方式推断 \sayChatGPT提供的信息，风险会升级。
- en: 'Novices, on the other hand, reported more obstacles and frustration, as they
    relied more on LLMs for their tasks. [N07](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    emotionally responded to a hallucination that ChatGPT \sayapparently made that
    shit up. [N01](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning
    Programming of Agent-based Modeling with LLM Companions: Experiences of Novices
    and Experts Using ChatGPT & NetLogo Chat") had difficulties to \sayfix the bugs
    that were in it (the generated code). [N08](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")’s
    session ended up \sayhitting a dead end, with the frustration leading him to \saygo
    consult other resources.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，初学者报告了更多的障碍和挫折，因为他们在任务中更依赖LLMs。 [N07](#S4.T2 "表 2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究
    ‣ 使用LLM助手学习基于代理的建模编程：初学者和专家使用ChatGPT & NetLogo Chat的经验") 情感上回应了ChatGPT \say明显编造的内容。
    [N01](#S4.T2 "表 2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究 ‣ 使用LLM助手学习基于代理的建模编程：初学者和专家使用ChatGPT
    & NetLogo Chat的经验") 对 \say修复其中的错误（生成的代码）感到困难。 [N08](#S4.T2 "表 2 ‣ 4.1\. 参与者 ‣
    4\. 实证研究 ‣ 使用LLM助手学习基于代理的建模编程：初学者和专家使用ChatGPT & NetLogo Chat的经验") 的会话最终 \say陷入了僵局，这种挫折使他
    \say去咨询其他资源。
- en: 'Most novices and experts still thought that LLM-based interfaces supported
    their learning or practicing by saving time. Even though [N03](#S4.T2 "Table 2
    ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") had \saylow trust in ChatGPT, she still felt more confident after
    collaboration, for it \saynarrowed down the stuff I have to figure out myself
    and has made me much faster already. As an educator, [N12](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") felt that LLMs facilitated a constructionist learning experience in which
    \sayyou’re being thrown into the culture and have to learn it on the fly. [E13](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") thought he learned a syntax from ChatGPT that would \saysave
    me time in the future and the learning process was \saya lot faster than if I
    were doing it by hand.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数初学者和专家仍然认为基于LLM的界面通过节省时间支持了他们的学习或实践。尽管 [N03](#S4.T2 "表 2 ‣ 4.1\. 参与者 ‣ 4\.
    实证研究 ‣ 使用LLM助手学习基于代理的建模编程：初学者和专家使用ChatGPT & NetLogo Chat的经验") 对ChatGPT的 \say信任度较低，她在合作后仍感到更有信心，因为
    \say减少了我必须自己搞明白的内容，并且已经让我变得更快。作为一名教育者，[N12](#S4.T2 "表 2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究
    ‣ 使用LLM助手学习基于代理的建模编程：初学者和专家使用ChatGPT & NetLogo Chat的经验") 认为LLMs促进了建构主义的学习体验，在这种体验中
    \say你被抛入文化中，必须在实际中学习。 [E13](#S4.T2 "表 2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究 ‣ 使用LLM助手学习基于代理的建模编程：初学者和专家使用ChatGPT
    & NetLogo Chat的经验") 认为他从ChatGPT那里学到的语法将 \say在未来节省我的时间，并且学习过程 \say比我自己动手做要快得多。
- en: 'As experts reported more perceived benefits, they predominantly intended to
    continue using LLM-based interfaces for NetLogo. After the task, [E11](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") felt confident that \sayI can write anything I want to
    write. Yet, many novices, driven by their frustration with LLMs, sought alternative
    learning resources before considering a return. [N04](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat"), for instance, had a 180-degree turn: expressing great hope before the
    tasks, they now inclined to \saybuild more by myself with my own code, without
    AI. [N13](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning
    Programming of Agent-based Modeling with LLM Companions: Experiences of Novices
    and Experts Using ChatGPT & NetLogo Chat") thought that she would prefer to work
    with \saysomeone who is familiar with the programming language together with LLMs.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '由于专家报告了更多的感知收益，他们主要打算继续使用基于LLM的NetLogo接口。任务完成后，[E11](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") 觉得自己可以写任何想写的东西。然而，许多初学者因为对LLM的挫败感而在考虑回归之前寻求其他学习资源。例如，[N04](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") 发生了180度的转变：在任务之前充满希望，现在倾向于“用自己的代码多做些事，不依赖AI。” [N13](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") 认为她更愿意与熟悉编程语言的人一起使用LLMs。'
- en: 5.2\. The Behavioral Gap Between Novices and Experts
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2\. 初学者与专家之间的行为差距
- en: Table 5\. Novices and Experts’ Behaviors During Human-AI Collaboration
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5\. 初学者和专家在人与AI合作期间的行为
- en: '|  | Experts | Novices |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '|  | 专家 | 初学者 |'
- en: '| --- | --- | --- |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '|  | Many start by asking LLMs for a smaller aspect of the task. | Most start
    by asking LLMs to work on the entire task. |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '|  | 许多人从询问LLMs任务的一个小方面开始。 | 大多数人从要求LLMs处理整个任务开始。 |'
- en: '| Planning & Prompting | ”NetLogo, I would like to spawn 50 turtles” | ”I want
    to use netlogo to help me model how honeybees regulate the temperature in their
    hive. What should I do?” |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| 规划与提示 | “NetLogo，我想生成50只乌龟” | “我想用netlogo帮助我建模蜜蜂如何调节蜂巢内的温度。我该怎么做？” |'
- en: '|  | Focus more on the generated code. | Focus more on the generated instructions.
    |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '|  | 更注重生成的代码。 | 更注重生成的指令。 |'
- en: '| Evaluating | ”Talks too much. I want the code, not the explanation yet.”
    | ”I am reading the text a little bit and it spits out a bunch of code. So it
    did give me steps, which is nice.” |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| 评估 | “说得太多了。我想要代码，而不是解释。” | “我读了一点文本，它输出了一堆代码。所以它确实给了我步骤，这很不错。” |'
- en: '|  | Most selectively copy and paste code, or write code on their own. | Most
    start by copying and pasting LLM-generated code. |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '|  | 大多数人选择性地复制粘贴代码，或自行编写代码。 | 大多数人从复制粘贴LLM生成的代码开始。 |'
- en: '| Coding | ”It’d be that I just take this and see what this does. ” | “This
    time it gives me.. two boxes to copy.” |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| 编码 | “我只是拿着这个看看它的作用。” | “这次它给了我..两个框来复制。” |'
- en: '|  | Debug themselves, or with help from AI. | Debug with (more) help from
    AI. |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '|  | 自行调试，或借助AI的帮助。 | 在（更多）AI帮助下进行调试。 |'
- en: '| Debugging | ”Oh, I didn’t ask him to move. That is my problem.” | ”I’m going
    to ask it the same question, but I’m confused why it said something about patches.”
    |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| 调试 | “哦，我没有让它移动。这是我的问题。” | “我要问它同样的问题，但我不明白为什么它提到补丁。” |'
- en: 5.2.1\. Behavioral Gap in Planning and Prompting
  id: totrans-225
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.1\. 规划与提示中的行为差距
- en: While experts’ and novices’ tasks were similar in terms of complexity, we observed
    differences between how novices and experts plan out their tasks. Since most participants
    gradually adapted their prompting styles, we focused on participants’ first-round
    prompts.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管专家和初学者的任务在复杂性上相似，但我们观察到他们在任务规划方面存在差异。由于大多数参与者逐渐适应了他们的提示风格，我们重点关注了参与者的第一次提示。
- en: 'Two initial prompting patterns, one emphasizing modeling the entire system
    and another focusing on smaller, initial aspects of the task, emerged from our
    interviews. Most novices adopted the first pattern (11/13, 85%), while many experts
    adopted the second pattern (9/17, 53%). Below, we introduce one vignette for each
    pattern:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们的访谈中出现了两种初步的提示模式，一种强调对整个系统进行建模，另一种关注任务的较小初始方面。大多数新手采用了第一种模式（11/13, 85%），而许多专家采用了第二种模式（9/17,
    53%）。下面，我们为每种模式介绍一个实例：
- en: (1)
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: '[N05](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning
    Programming of Agent-based Modeling with LLM Companions: Experiences of Novices
    and Experts Using ChatGPT & NetLogo Chat") started by asking: \sayI need to make
    a model of the bunch of agents who are trying to promote political views to other
    people (…). Although he used GPT-4, the returned code still came with several
    syntax errors. [N05](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") then spent the next 20 minutes
    trying to ask GPT-4 to fix issues without success. He expected to \sayput the
    idea into it and we’ll run the code, but in the end \sayit didn’t happen.'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[N05](#S4.T2 "表 2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究 ‣ 使用LLM助手学习基于Agent的建模编程：新手与专家使用ChatGPT和NetLogo
    Chat的经验") 开始时问道：\say我需要制作一个模型，这个模型中的一群代理人试图向其他人宣传政治观点（……）。尽管他使用了GPT-4，但返回的代码仍然有几个语法错误。[N05](#S4.T2
    "表 2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究 ‣ 使用LLM助手学习基于Agent的建模编程：新手与专家使用ChatGPT和NetLogo Chat的经验")
    接下来的20分钟里尝试让GPT-4修复问题，但没有成功。他原本期望\say把想法放进去，然后运行代码，但最终\say这并没有发生。'
- en: (2)
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: '[E07](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning
    Programming of Agent-based Modeling with LLM Companions: Experiences of Novices
    and Experts Using ChatGPT & NetLogo Chat") started by asking ChatGPT to \saywrite
    code for drawing a rectangle. When GPT-3.5 failed to further divide the rectangle,
    [E07](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") instantly pivoted to another strategy: \sayI have
    the following code that draws a rectangle. I want you to modify it so the rectangle
    is divided by two. GPT-3.5 still failed, yet it produced working code and did
    \saysomething close to it.'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[E07](#S4.T2 "表 2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究 ‣ 使用LLM助手学习基于Agent的建模编程：新手与专家使用ChatGPT和NetLogo
    Chat的经验") 开始时要求ChatGPT\say编写绘制矩形的代码。当GPT-3.5未能进一步分割矩形时，[E07](#S4.T2 "表 2 ‣ 4.1\.
    参与者 ‣ 4\. 实证研究 ‣ 使用LLM助手学习基于Agent的建模编程：新手与专家使用ChatGPT和NetLogo Chat的经验") 立即转向另一种策略：\say我有以下代码可以绘制矩形。我希望你修改它，使得矩形被分成两部分。GPT-3.5仍然失败了，但它产生了有效的代码，并做了\say接近它的东西。'
- en: 'The second prompting pattern involved remarkable mental efforts to decompose
    and plan out the task. For example, [E07](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    described his approach as \sayseparate into small, general tasks you want to do.
    [E04](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") explained that he \sayjust likes to iteratively
    build (the code). On the other hand, in the first pattern, many participants attempted
    to shortcut the efforts by delegating the tasks to AI, as [N05](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") said: \sayI just want to ask it (ChatGPT) to just directly make
    a code for this task and that’s it.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种提示模式涉及显著的心理努力来分解和规划任务。例如，[E07](#S4.T2 "表 2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究 ‣ 使用LLM助手学习基于Agent的建模编程：新手与专家使用ChatGPT和NetLogo
    Chat的经验") 将其方法描述为\say将任务分解为小的、一般性的子任务。[E04](#S4.T2 "表 2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究
    ‣ 使用LLM助手学习基于Agent的建模编程：新手与专家使用ChatGPT和NetLogo Chat的经验") 解释说他\say喜欢迭代地构建（代码）。另一方面，在第一种模式中，许多参与者试图通过将任务委托给AI来简化工作，正如[N05](#S4.T2
    "表 2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究 ‣ 使用LLM助手学习基于Agent的建模编程：新手与专家使用ChatGPT和NetLogo Chat的经验")
    所说的：\say我只想让它（ChatGPT）直接为这个任务写一段代码，仅此而已。
- en: 'By the end of the task, most participants had realized the importance of breaking
    tasks into smaller pieces for coding with AI. Naturally, when an LLM-based interface
    generated code with mistakes, a participant would be (implicitly) guided to ask
    smaller follow-up questions. Soon, many of them realized the benefits. [N01](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") thought it would be better if one \sayworks through real
    small problems first, before getting to more complicated problems. [N10](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") would \saystart with something really basic. Experts
    using the first pattern had similar ideas. For example, [E12](#S4.T2 "Table 2
    ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") decided to restart \saywith something simple and just work with
    it.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '到任务结束时，大多数参与者已经认识到将任务拆分成更小的部分以便与 AI 一起编码的重要性。自然地，当基于 LLM 的接口生成有错误的代码时，参与者会（隐含地）被引导去提出更小的后续问题。不久之后，他们中的许多人认识到这种方法的好处。[N01](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") 认为如果先`works through real small problems`，再处理更复杂的问题会更好。[N10](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") 会`start with something really basic`。使用第一种模式的专家也有类似的想法。例如，[E12](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") 决定重新开始`with something simple and just work with it`。'
- en: 5.2.2\. Behavioral Gap in Coding and Debugging
  id: totrans-234
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.2\. 编码和调试中的行为差距
- en: As most participants engaged with an agent-based modeling task that they never
    worked on, both experts and novices learned some aspects of NetLogo with the help
    of AI - although, in different ways. Experts usually took a much more measured,
    prudent, and critical approach during coding and debugging, while novices mostly
    followed AI’s instructions.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 由于大多数参与者都接触到从未做过的基于代理的建模任务，无论是专家还是新手，都通过 AI 学习了 NetLogo 的某些方面——尽管方式不同。专家在编码和调试过程中通常采取更加谨慎、审慎和批判的态度，而新手则主要跟随
    AI 的指示。
- en: 'Most novices focused on reading AI’s explanations and followed AI’s instructions
    during their coding processes. ChatGPT often gives instructions like \sayYou can
    copy and paste this code into NetLogo and run it. Even without this hint, almost
    all novices would copy and paste the generated code without much reading. The
    tendency worried some novices, but they had no choice: \sayI feel like I’m waiting
    for someone to tell me the answer, rather than learning how to solve it. ([N11](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat"))'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '大多数新手专注于阅读 AI 的解释，并在编码过程中按照 AI 的指示操作。ChatGPT 经常给出诸如 `You can copy and paste
    this code into NetLogo and run it` 的指示。即使没有这个提示，几乎所有新手都会在没有仔细阅读的情况下复制并粘贴生成的代码。这种倾向让一些新手感到担忧，但他们别无选择：`I
    feel like I’m waiting for someone to tell me the answer, rather than learning
    how to solve it`。 ([N11](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat"))'
- en: 'Experts put more emphasis on the code, often ignoring the explanations provided
    by AI. During their reading, experts evaluated and often criticized the responses,
    planning their next steps along the way. Only a few experts tried copying and
    pasting the code to see if they worked out of the box. Other experts selectively
    copied and pasted parts of the code into their programs, or wrote their programs
    with generated code on the side. Even when they copied and pasted the code, experts
    were more cautious. For example, while [E04](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    decided to \sayjust take this and see what this does, he also realized that AI-generated
    code would override his ideas and manually edited the code.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '专家更注重代码，通常忽视AI提供的解释。在阅读过程中，专家评估并经常批评回应，并在此过程中规划他们的下一步行动。只有少数专家尝试复制和粘贴代码以查看其是否能直接运行。其他专家选择性地将代码的部分内容复制并粘贴到他们的程序中，或者将生成的代码作为参考来编写他们的程序。即使在复制和粘贴代码时，专家们也更加谨慎。例如，虽然[E04](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat")决定“直接使用这些代码看看效果”，他也意识到AI生成的代码会覆盖他的想法，因此对代码进行了手动编辑。'
- en: 'All participants inevitably had to debug parts of the generated code. Yet,
    novices sought support from AI more frequently and often struggled with AI responses.
    For example, [N12](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") would regularly \saycopy
    the code that doesn’t make sense and go back to AI to see if it can help me. [N09](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") complained that while ChatGPT gave suggestions, \sayit
    obviously requires fiddling around with it. As she had little idea about NetLogo,
    it became a purely trial-and-error experience. Even when AI did solve some errors,
    it was challenging for novices to learn from the process. For example, [N04](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") commented that while NetLogo Chat provided an automated
    process, it was still difficult for him to get the lesson, \saysince I didn’t
    write it myself.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '所有参与者不可避免地需要调试生成的代码的部分。然而，新手更频繁地寻求AI的支持，并且常常与AI的回应斗争。例如，[N12](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat")经常会“复制那些没有意义的代码，然后回到AI那里看看是否能帮忙。”[N09](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat")抱怨说，虽然ChatGPT给出了建议，但“显然需要进行一些调整。”由于她对NetLogo了解甚少，这变成了一种纯粹的试错经验。即使AI解决了一些错误，新手也很难从过程中学习。例如，[N04](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat")评论说，尽管NetLogo Chat提供了自动化的过程，但他仍然很难从中获得教训，“因为我没有自己编写代码。”'
- en: '5.2.3\. Behind the Behavioral Gap: The Knowledge Gap'
  id: totrans-239
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.3\. 行为差距背后的知识差距
- en: We identified a knowledge gap that may lead to the behavioral gap. When novices
    realized that they needed to spend more effort decomposing the task or vetting
    AI responses, they found themselves lacking the necessary knowledge. We summarized,
    in participants’ own words, the four components of a knowledge gap that novices
    need to overcome when working with AI.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 我们识别了一个可能导致行为差距的知识差距。当新手意识到他们需要花更多的精力来分解任务或审查AI的回应时，他们发现自己缺乏必要的知识。我们总结了新手在与AI工作时需要克服的知识差距的四个组成部分，这些总结来自参与者自己的话。
- en: 'Novices reported the need for conceptual knowledge of modeling. For example,
    [N07](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") described his experience as \saylike being adrift
    on an ocean. Without a compass, and without a map. With only a basic understanding
    of agent-based modeling, [N11](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") felt compelled to accept
    ChatGPT’s response as \sayI don’t really know how to interpret some of the output
    from it. Such feelings correspond with novices’ tendency to skim through AI responses.
    Whereas, some novices asked for help from LLMs with different degrees of success.
    [N04](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") first asked: \say(…) Can you tell me what I will
    need to do before we begin? With AI’s suggestions, [N04](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") had some more success asking follow-up questions.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 新手们报告了对建模概念知识的需求。例如，[N07](#S4.T2 "表 2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究 ‣ 使用 LLM 伙伴学习代理基础建模编程：新手和专家使用
    ChatGPT & NetLogo Chat 的经验") 描述了他的经历为如同漂浮在海洋中，没有指南针，也没有地图。对代理基础建模只有基本了解，[N11](#S4.T2
    "表 2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究 ‣ 使用 LLM 伙伴学习代理基础建模编程：新手和专家使用 ChatGPT & NetLogo Chat
    的经验") 感到不得不接受 ChatGPT 的回应，*我真的不知道如何解释一些输出内容*。这种感觉与新手倾向于草率浏览 AI 回复相一致。而有些新手则向 LLM
    请求帮助，成功程度各异。[N04](#S4.T2 "表 2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究 ‣ 使用 LLM 伙伴学习代理基础建模编程：新手和专家使用
    ChatGPT & NetLogo Chat 的经验") 首先问道：*（…）你能告诉我在开始之前我需要做什么吗？* 有了 AI 的建议，[N04](#S4.T2
    "表 2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究 ‣ 使用 LLM 伙伴学习代理基础建模编程：新手和专家使用 ChatGPT & NetLogo Chat
    的经验") 在后续提问时取得了一些成功。
- en: 'The unfamiliarity with the basic concepts of NetLogo and/or coding in general
    further adds to the difficulty in prompting and understanding. After reading a
    guide suggested by NetLogo Chat, [N07](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣
    4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM Companions:
    Experiences of Novices and Experts Using ChatGPT & NetLogo Chat") realized that
    he \sayprobably wouldn’t have chosen NetLogo to ever begin with for his database-related
    task. Other novices were often confused by NetLogo’s terms, even when they were
    mostly in plain English. [N03](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") was confused about \saywhy
    (ChatGPT) said something about patches (note: patches are static agents that form
    NetLogo’s modeling world), and that deepened her reliance on ChatGPT. [N10](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") realized that she \sayonly understand 20% of what I am
    reading, so I can’t vet it myself. When the interviewer asked about adding comments
    into code, [N03](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣
    Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") replied that while it might
    be helpful, she was still missing \saythe high-level understanding of how it comes
    together.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '对于 NetLogo 的基本概念和/或编程的一般知识的不熟悉，进一步增加了提示和理解的难度。在阅读了 NetLogo Chat 推荐的指南后，[N07](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") 意识到他**可能**不会选择 NetLogo 来进行他的数据库相关任务。其他新手经常被 NetLogo 的术语弄混，即使这些术语大多是普通英语。
    [N03](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") 对于 \say ChatGPT 说的有关补丁的内容感到困惑（注：补丁是构成 NetLogo 模型世界的静态代理），这加深了她对
    ChatGPT 的依赖。 [N10](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") 意识到她**仅**理解了我阅读内容的 20%，因此无法自行验证。当面试官询问关于在代码中添加注释的情况时，[N03](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") 回复说，虽然这可能有帮助，但她仍然缺乏 \say 高层次的理解。'
- en: 'Many novices also lack the experience for debugging, leading to more unsuccessful
    attempts and more frustrations. Participants, in particular novices, were often
    confused by error messages from NetLogo. [N01](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    acknowledged that \saywithout background knowledge, it is hard to figure out what
    the bugs are, if (LLM) gives you information that is inaccurate. Without experience
    in debugging, many novices felt frustrated and helpless as previously reported.
    On the other hand, [E12](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") noted that his students
    \saymight not be comfortable with the idea that debugging is a normal part of
    the process. [E01](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") believed that \saythe user
    needs a little practice in debugging their own code before working with LLM-based
    interfaces.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '许多新手还缺乏调试经验，导致更多的失败尝试和挫折。参与者，特别是新手，经常被 NetLogo 的错误信息弄困惑。[N01](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") 承认 \say 没有背景知识，很难搞清楚错误是什么，如果（LLM）给出的信息不准确。缺乏调试经验，许多新手感到沮丧和无助，正如之前报告的那样。另一方面，[E12](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") 指出，他的学生 \say 可能不习惯调试是过程中的正常部分。[E01](#S4.T2 "Table 2 ‣
    4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") 认为 \say 用户需要在使用基于 LLM 的接口之前，先进行一些调试自己代码的练习。'
- en: 'Most novices felt a need to learn to interact with LLMs. After repeated failures,
    [N01](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") felt that he did not \sayeven know what questions
    to ask to get it to, because it is not doing the right thing. [N06](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") thought AI would help a lot if she could \saylearn more about
    how to use AI. [N05](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") realized that he needed
    to use the correct keywords, for otherwise it \saywill never generate a good model.
    This knowledge is relatively easier to acquire though: while [N09](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") felt that \sayhow to ask questions is very important, she believed
    that \sayyou learn by actually doing it.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数新手觉得有必要学习如何与LLM互动。在经过多次失败后，[N01](#S4.T2 "表 2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究 ‣ 使用LLM伴侣学习基于代理的建模：新手和专家使用ChatGPT和NetLogo
    Chat的经验")感到自己甚至不知道该问什么问题，因为LLM没有做对事情。[N06](#S4.T2 "表 2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究
    ‣ 使用LLM伴侣学习基于代理的建模：新手和专家使用ChatGPT和NetLogo Chat的经验")认为如果她能*学习更多关于如何使用AI*，AI将会提供很大帮助。[N05](#S4.T2
    "表 2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究 ‣ 使用LLM伴侣学习基于代理的建模：新手和专家使用ChatGPT和NetLogo Chat的经验")意识到他需要使用正确的关键词，否则LLM*永远不会生成一个好的模型*。不过，这种知识相对容易获得：[N09](#S4.T2
    "表 2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究 ‣ 使用LLM伴侣学习基于代理的建模：新手和专家使用ChatGPT和NetLogo Chat的经验")认为*如何提问非常重要*，她相信*通过实际操作来学习*。
- en: 5.3\. Needs for Guidance, Personalization, and Integration
  id: totrans-245
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3\. 对指导、个性化和集成的需求
- en: 'Table 6\. Users’ Needs for LLMs: Guidance, Personalization, and Integration'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6\. 用户对LLMs的需求：指导、个性化和集成
- en: '| Guidance | Personalization | Integration |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| 指导 | 个性化 | 集成 |'
- en: '| --- | --- | --- |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Should provide clear, less technical responses, stay on topic, and give smaller
    pieces of information at a time. | Should provide responses based on users’ preferred
    styles. | Should provide better support for coding chunks and iterative modeling.
    |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| 应该提供清晰、较少技术性的回应，保持主题，并分段提供信息。 | 应该根据用户的首选风格提供回应。 | 应该为代码块和迭代建模提供更好的支持。 |'
- en: '| Should provide responses based on authoritative sources and in NetLogo’s
    language. | Should provide responses based on the knowledge levels and interests
    of users. | Should support working on existing modeling code. |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| 应该基于权威来源和NetLogo语言提供回应。 | 应该根据用户的知识水平和兴趣提供回应。 | 应该支持对现有建模代码的处理。 |'
- en: '| Should assume less, clarify more, and stick to user intentions for modeling.
    | Should support human help-seeking preferences in different ways. | Should support
    input and output of computational modeling. |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| 应该少做假设，多加澄清，遵循用户意图进行建模。 | 应该以不同方式支持人们寻求帮助的偏好。 | 应该支持计算建模的输入和输出。 |'
- en: 5.3.1\. ”Good” Responses, ”Bad” Responses
  id: totrans-252
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.1\. ”好的”回应， ”差的”回应
- en: 'Participants generally appreciate and expect less technical, clear instructions.
    Many of them appreciate NetLogo Chat’s design decisions that include authoritative
    sources in responses (see [3.1.2](#S3.SS1.SSS2 "3.1.2\. Invoke Authoritative Sources
    Whenever Possible ‣ 3.1\. Design Overview ‣ 3\. NetLogo Chat System ‣ Learning
    Programming of Agent-based Modeling with LLM Companions: Experiences of Novices
    and Experts Using ChatGPT & NetLogo Chat")) and ask back clarification questions
    (see [3.1.1](#S3.SS1.SSS1 "3.1.1\. Enable users to program the computer, rather
    than being programmed by the computer ‣ 3.1\. Design Overview ‣ 3\. NetLogo Chat
    System ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat")). However, participants’
    preferences are also highly personal and situational.'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '参与者普遍期望并欣赏更少的技术性、清晰的指令。他们中的许多人赞赏 NetLogo Chat 的设计决策，包括在响应中引用权威来源（参见 [3.1.2](#S3.SS1.SSS2
    "3.1.2\. Invoke Authoritative Sources Whenever Possible ‣ 3.1\. Design Overview
    ‣ 3\. NetLogo Chat System ‣ Learning Programming of Agent-based Modeling with
    LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")）以及要求澄清问题（参见
    [3.1.1](#S3.SS1.SSS1 "3.1.1\. Enable users to program the computer, rather than
    being programmed by the computer ‣ 3.1\. Design Overview ‣ 3\. NetLogo Chat System
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat")）。然而，参与者的偏好也是高度个人化和情境化的。'
- en: 'For both designs, some participants explicitly went against excessive or unnecessary
    explanations, particularly when the goal is primarily to accomplish a task at
    hand. For instance, [E09](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") complained that GPT-4 \saytalks
    too much. I want the code, not the explanation yet. [E14](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") complained that while related code samples provided by NetLogo Chat could
    \saycontain a lot of good suggestions, she wanted to move them to \sayanother
    box or an expandable line.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '对于这两种设计，一些参与者明确反对过多或不必要的解释，特别是在目标主要是完成手头任务时。例如，[E09](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") 抱怨 GPT-4 \saytalks too much. I want the code, not the explanation yet.
    [E14](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") 抱怨说，尽管 NetLogo Chat 提供的相关代码示例可能 \saycontain a lot
    of good suggestions，但她希望将这些示例移到 \sayanother box 或一个可展开的行中。'
- en: 'Some participants appreciated and hoped that LLMs could stay on topic and give
    smaller pieces of information at a time. [E01](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    thought NetLogo Chat would be more helpful if it only attempted to solve a bug
    \sayone at a time, for users \sayalways overfill their buffer. Novices, in particular,
    prefer concrete, step-by-step responses, given the focus they put on AI-generated
    instructions. [N04](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") wanted to \saytest one by
    one if (LLM) gave me multiple suggestions. Going beyond text responses, [N03](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") hoped that there could be \saya visual to help me better
    understand, or internalize what different elements of the code are, so her learning
    could move to a higher-level understanding of the code’s intention.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '一些参与者希望 LLM 能保持在话题上，并一次提供较小的信息块。[E01](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    认为，如果 NetLogo Chat 只尝试一次解决一个 bug，可能会更有帮助，因为用户 \sayalways overfill their buffer。特别是初学者，考虑到他们对
    AI 生成的指令的重视，更倾向于具体、一步步的响应。[N04](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") 希望 \saytest one by one if
    (LLM) 给了我多个建议。超越文本响应，[N03](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") 希望能有 \saya visual 帮助我更好地理解或内化代码中不同元素的作用，以便她的学习能够提升到对代码意图的更高层次的理解。'
- en: 'For NetLogo Chat, most participants reacted positively to the reference to
    authoritative sources (see [3.1.2](#S3.SS1.SSS2 "3.1.2\. Invoke Authoritative
    Sources Whenever Possible ‣ 3.1\. Design Overview ‣ 3\. NetLogo Chat System ‣
    Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat")), the usage of NetLogo’s
    language, and the provision of links to sources. [E03](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") believed that \saythe possibility to go directly from this AI to the documentation
    would be helpful for his students. [N10](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    \sayautomatically like (NetLogo Chat’s response) better because it used \sayNetLogo’s
    kind of turtle and patch language. [E12](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    felt \saya little bit more confident in the information I was getting because
    it seemed to be coming from inside of the application. However, sticking too much
    to authoritative explanations might have a downside. [E10](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") complained that NetLogo Chat gave him \saydictionary reference, and \saydictionary
    definitions are not especially helpful.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '对于 NetLogo Chat，大多数参与者对引用权威来源表示积极反应（见 [3.1.2](#S3.SS1.SSS2 "3.1.2\. Invoke
    Authoritative Sources Whenever Possible ‣ 3.1\. Design Overview ‣ 3\. NetLogo
    Chat System ‣ Learning Programming of Agent-based Modeling with LLM Companions:
    Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")），NetLogo 语言的使用以及提供的链接表示认可。[E03](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") 认为 \say 直接从这个 AI 转到文档对他的学生会有帮助。[N10](#S4.T2 "Table 2
    ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") \say 喜欢自动生成的（NetLogo Chat 的回应），因为它使用了 \say NetLogo 的那种 turtle
    和 patch 语言。[E12](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣
    Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") 觉得 \say 我对获取的信息更有信心，因为这些信息似乎来自应用程序内部。然而，过于依赖权威解释可能会有不利影响。[E10](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") 抱怨说 NetLogo Chat 给了他 \say 字典参考，而 \say 字典定义特别不有用。'
- en: 'Many participants, in particular experts, reacted positively when NetLogo Chat
    assumed less about and stuck more to their intentions (e.g. asking questions back,
    see [3.1.1](#S3.SS1.SSS1 "3.1.1\. Enable users to program the computer, rather
    than being programmed by the computer ‣ 3.1\. Design Overview ‣ 3\. NetLogo Chat
    System ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat")). For example, [E09](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") commented that ChatGPT (GPT-4) \sayassumed what I wanted
    it to do, whereas this one makes you specify your assumptions. He prefers NetLogo
    Chat’s approach, because \sayit makes you think about the code more. [E12](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") felt that NetLogo Chat’s clarification of intention was
    akin to \sayprogressively guiding me towards a better prompt. As transparency
    is a key factor in computational modeling, [N11](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    feared that if \sayanyone can produce an agent-based model, but without actually
    understanding all the parameters, hidden assumptions introduced by ChatGPT could
    be detrimental.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 许多参与者，特别是专家，当NetLogo Chat在理解意图时减少假设并更多地坚持其意图（例如，通过提问，见 [3.1.1](#S3.SS1.SSS1
    "3.1.1\. 启用用户编程计算机，而不是被计算机编程 ‣ 3.1\. 设计概述 ‣ 3\. NetLogo Chat系统 ‣ 与LLM伴侣一起学习基于代理的建模的经验：新手和专家使用ChatGPT和NetLogo
    Chat"））时反应积极。例如，[E09](#S4.T2 "表2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究 ‣ 与LLM伴侣一起学习基于代理的建模的经验：新手和专家使用ChatGPT和NetLogo
    Chat")评论说ChatGPT（GPT-4）\sayassumed what I wanted it to do, whereas this one makes
    you specify your assumptions. He prefers NetLogo Chat’s approach, because \sayit
    makes you think about the code more. [E12](#S4.T2 "表2 ‣ 4.1\. 参与者 ‣ 4\. 实证研究 ‣
    与LLM伴侣一起学习基于代理的建模的经验：新手和专家使用ChatGPT和NetLogo Chat")感觉NetLogo Chat对意图的澄清类似于\sayprogressively
    guiding me towards a better prompt. 由于透明度是计算建模的关键因素，[N11](#S4.T2 "表2 ‣ 4.1\. 参与者
    ‣ 4\. 实证研究 ‣ 与LLM伴侣一起学习基于代理的建模的经验：新手和专家使用ChatGPT和NetLogo Chat")担心如果\sayanyone
    can produce an agent-based model, but without actually understanding all the parameters,
    hidden assumptions introduced by ChatGPT could be detrimental。
- en: 5.3.2\. Need for Personalization
  id: totrans-258
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.2\. 个人化需求
- en: 'In this section, we break down the strong needs of experts and novices for
    more personalization, besides response styles, into two themes: knowledge levels
    and help-seeking needs.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将专家和新手对更多个性化的强烈需求，除了响应风格，还分解为两个主题：知识水平和寻求帮助的需求。
- en: 'Novices, in particular, felt a strong need for LLM-based interfaces to acknowledge
    their knowledge levels and produce responses accordingly. [N07](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") gave a stringent critique of both systems, feeling both systems
    were \saynot useful at all, for both \saypresumes you know something about NetLogo.
    [N08](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") felt that \sayChatGPT has no idea of how much or
    how little I know about how to code in NetLogo, or how to code in general. Solving
    this issue would require more personalized approaches. Coming from an educational
    background, both [N02](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") and [E03](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") suggested that LLMs should first probe the knowledge level of
    users before providing answers.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '尤其是初学者，强烈希望基于LLM的界面能够识别他们的知识水平并据此生成回应。[N07](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    对这两个系统进行了严厉的批评，认为这两个系统完全没有用，因为这两个系统都\saypresumes你对NetLogo有一定了解。[N08](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") 认为\sayChatGPT根本不知道我对NetLogo编程的了解程度或对编程的一般了解。解决这个问题需要更个性化的方法。[N02](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat")和[E03](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat")建议LLM在提供答案之前应先探测用户的知识水平。'
- en: 'Participants gave a variety of suggestions that were at times conflicting:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者提出了各种建议，有时这些建议互相矛盾：
- en: (1)
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: 'Some participants prefer a guided walkthrough. [N08](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") hoped that LLMs could walk him through the process and provide starting
    points. Both [E14](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") and [N03](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") hoped that LLMs could be used alongside video tutorials, where
    they could first see a successful example of human-AI collaboration and then ask
    follow-up questions.'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '一些参与者更喜欢有指导性的演练。[N08](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") 希望LLM能够引导他完成过程并提供起始点。[E14](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat")和[N03](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") 希望LLM可以与视频教程一起使用，先看到成功的人机协作示例，然后再提出后续问题。'
- en: (2)
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: 'Some participants prefer contextual recommendations. [N11](#S4.T2 "Table 2
    ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") hoped that LLMs could show related code examples and provide
    \saytwo or three other ways that you might look with. [E10](#S4.T2 "Table 2 ‣
    4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") suggested that LLMs provide in-context explanations if \sayyou
    don’t remember the definition or explanation of a particular command.'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '一些参与者更喜欢上下文推荐。 [N11](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") 希望 LLMs 能够展示相关的代码示例，并提供
    \saytwo or three other ways that you might look with。 [E10](#S4.T2 "Table 2 ‣
    4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") 建议 LLMs 提供上下文解释，如果 \sayyou don’t remember the definition or explanation
    of a particular command。'
- en: (3)
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3)
- en: 'Some participants hope that LLMs could support help-seeking from humans. [E01](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") hoped that LLMs could help novices \sayexplain my situation
    so that I can paste it to the user group, so human experts could intervene more
    easily when AI fails to unstuck novices. Similarly, [E17](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") suggested that AI could be combined with \saypeer to peer answers and collaboration.'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '一些参与者希望大语言模型（LLMs）能够支持人类寻求帮助。 [E01](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣
    4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM Companions:
    Experiences of Novices and Experts Using ChatGPT & NetLogo Chat") 希望 LLMs 能够帮助新手
    \sayexplain my situation，以便我可以将其粘贴到用户组，这样当 AI 无法解决新手问题时，人类专家可以更容易地介入。类似地，[E17](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") 建议 AI 可以与 \saypeer to peer 答疑和协作结合起来。'
- en: (4)
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (4)
- en: 'Some participants believed that incorrect responses could become a learning
    opportunity. [E02](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") was concerned that students
    might be \sayexposed to fewer options with AI, compared with \saycoding from scratch.
    [E03](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") feared that a system capable of directly producing
    solutions might deprive students of the debugging process, where they would have
    learned.” Novices also had similar feelings. After many hallucinated responses,
    [N08](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") thought that ChatGPT \sayforces me to learn as
    opposed to just getting code that’s ready to go. To fully transform the moment
    of mistake into learning opportunities, educators suggest the design not to frame
    mistakes as failures, but rather \sayas a learning moment ([E12](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat")).'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '一些参与者认为错误的回答可能成为学习机会。 [E02](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") 担心与 \saycoding from scratch
    相比，学生可能会 \sayexposed to fewer options with AI。 [E03](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    担心一个能够直接生成解决方案的系统可能剥夺了学生的调试过程，在这个过程中他们本可以学到东西。” 新手也有类似的感觉。在经历了许多错误的回答后，[N08](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") 认为 ChatGPT \sayforces me to learn 相较于仅仅得到可以直接使用的代码。为了将错误的瞬间完全转变为学习机会，教育者建议设计时不要将错误视为失败，而应
    \sayas a learning moment ([E12](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat"))。'
- en: 5.3.3\. Need for Integration
  id: totrans-270
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.3\. 需要整合
- en: Compared with ChatGPT in a separate browser window, most participants appreciated
    the NetLogo Chat interface being an integrated part of the modeling environment.
    They are particularly in favor of the deep integration in NetLogo Chat’s design
    that goes beyond placing a CA and an IDE side-by-side. We further identified many
    participants’ need for a deeper integration.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 与在单独的浏览器窗口中使用 ChatGPT 相比，大多数参与者更欣赏 NetLogo Chat 界面作为建模环境的一部分。他们特别喜欢 NetLogo
    Chat 设计中的深度集成，这种集成超越了简单地将 CA 和 IDE 并排放置。我们进一步确认了许多参与者对更深层次集成的需求。
- en: 'Many participants appreciated the integration of a sandbox-like code editor
    in NetLogo Chat, where they can tinker with smaller, AI-generated code chunks
    and execute them on the fly (see [3.1.3](#S3.SS1.SSS3 "3.1.3\. Integrate with
    the IDE and Enhance Troubleshooting ‣ 3.1\. Design Overview ‣ 3\. NetLogo Chat
    System ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat")). [N12](#S4.T2 "Table 2
    ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") \saydefinitely liked this feature of being able to go easily
    between the code and see what was changed and what was added. [N04](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") appreciated that one can \saysee the code run in the NetLogo
    IDE, which ChatGPT could not do. [N13](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣
    4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM Companions:
    Experiences of Novices and Experts Using ChatGPT & NetLogo Chat") thought while
    some code generated by ChatGPT was \sayso comprehensive, NetLogo Chat was able
    to break it down and make them \saymore conducive. Participants also expressed
    further needs for iterative modeling. [E13](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    hoped that NetLogo Chat could help him \saymodularize all of my commands by splitting
    the code into many smaller, more manageable chunks. [E12](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") asked for a comparison feature between versions of code chunks that could
    help him \sayiterative changes quickly.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '许多参与者欣赏 NetLogo Chat 中集成的类似沙箱的代码编辑器，在这里他们可以调整较小的 AI 生成的代码块并即时执行（参见 [3.1.3](#S3.SS1.SSS3
    "3.1.3\. Integrate with the IDE and Enhance Troubleshooting ‣ 3.1\. Design Overview
    ‣ 3\. NetLogo Chat System ‣ Learning Programming of Agent-based Modeling with
    LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")）。[N12](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") \say 确实喜欢这一功能，能够轻松在代码之间切换，查看更改和新增内容。[N04](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") 赞赏能够在 NetLogo IDE 中查看代码运行情况，这是 ChatGPT 无法做到的。[N13](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") 认为虽然 ChatGPT 生成的某些代码 \say 非常全面，但 NetLogo Chat 能够将其拆解并使其 \say
    更有利于理解。参与者还表达了对迭代建模的进一步需求。[E13](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") 希望 NetLogo Chat 能帮助他 \say
    将所有命令模块化，通过将代码拆分成许多较小、更易于管理的块。[E12](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\.
    Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM Companions:
    Experiences of Novices and Experts Using ChatGPT & NetLogo Chat") 请求一个在代码块版本之间进行比较的功能，这可以帮助他
    \say 快速进行迭代更改。'
- en: 'In addition, participants also hoped that LLMs could help them reflect on longer
    pieces of (existing) code. [N02](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") and [E02](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") wanted AI to support the combination of multiple, smaller code
    chunks into a single, coherent code. As such, LLM-based interfaces should be able
    to work with longer pieces of code. Both [N06](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    and [E08](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning
    Programming of Agent-based Modeling with LLM Companions: Experiences of Novices
    and Experts Using ChatGPT & NetLogo Chat") hoped that NetLogo Chat could \saylook
    at my code and make suggestions based on my code.'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '此外，参与者还希望 LLM 能够帮助他们反思更长的（现有的）代码。[N02](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    和 [E02](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning
    Programming of Agent-based Modeling with LLM Companions: Experiences of Novices
    and Experts Using ChatGPT & NetLogo Chat") 希望 AI 能够支持将多个小代码块组合成一个连贯的代码。因此，LLM
    基础的接口应该能够处理较长的代码。[N06](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") 和 [E08](#S4.T2 "Table 2
    ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") 希望 NetLogo Chat 能 \say查看我的代码并根据我的代码提出建议。'
- en: 'Many participants needed adaptive support for modeling more than just coding.
    Many requested AI support in building model interfaces that could be used to take
    in inputs or send out outputs. For example, [N06](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    needed NetLogo for her academic paper, hence plotting became \sayvery important.
    For educators like [E13](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat"), while the canvas output
    was \saygood for the three-quarters of a project, it hid \saythe real power of
    agent-based modeling - tracking the emergent properties of the model, rather than
    simply making bits run around the screen. During the modeling processes, many
    interface parts could become necessary or unnecessary depending on situational
    needs. Integrated LLM-based interfaces need to go beyond a \sayside chat window
    and support various spatial configurations for advanced users to decide on.'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '许多参与者需要适应性的支持来建模，不仅仅是编码。许多人要求AI支持构建模型接口，以便接收输入或发送输出。例如，[N06](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") 需要 NetLogo 来完成她的学术论文，因此绘图变得 \say非常重要。对于像 [E13](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") 这样的教育工作者来说，虽然画布输出在项目的四分之三处是 \say好的，但它隐藏了 \say基于代理的建模的真正力量——追踪模型的涌现特性，而不仅仅是让小点在屏幕上移动。在建模过程中，许多接口部分可能会根据情况的需要变得必要或不必要。集成的
    LLM 基接口需要超越 \say侧边聊天窗口，并支持各种空间配置，以便高级用户决定。'
- en: 6\. Discussions
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 讨论
- en: Our study first reported, in detail, how novices and experts perceive and use
    LLM-based interfaces (ChatGPT & NetLogo Chat) differently to support their learning
    and practice of computational modeling in an open-ended setting. Most participants
    appreciated the design direction NetLogo Chat is heading toward. However, they
    also expressed their needs for improved guidance, personalization, and integration
    which opens up huge design spaces for future improvement.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究首次详细报告了新手和专家如何在开放式环境中感知和使用 LLM 基础的接口（ChatGPT 和 NetLogo Chat），以支持他们的计算建模学习和实践。大多数参与者欣赏
    NetLogo Chat 正在朝着的设计方向。然而，他们也表达了对改进指导、个性化和集成的需求，这为未来的改进打开了巨大的设计空间。
- en: '6.1\. Guidance: Bridging the Novice-Expert Gap'
  id: totrans-277
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1\. 指导：弥合新手与专家之间的差距
- en: '![Refer to caption](img/359f95c4c14808c2f48cb631fedf85b2.png)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/359f95c4c14808c2f48cb631fedf85b2.png)'
- en: Figure 5\. A preliminary theorization of the novice-expert knowledge gap.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5\. 新手-专家知识差距的初步理论化。
- en: \Description
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: \描述
- en: 'This figure summarizes our theorization of the gap. The gap has two parts:
    knowledge to effectively decompose and plan modeling tasks in smaller pieces;
    knowledge to evaluate AI responses and identify potential issues. Both comprise
    two parts: conceptual knowledge of modeling; basic concepts of NetLogo and coding;
    experiences of debugging; and how to interact with LLMs.'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 该图总结了我们对知识差距的理论化。差距分为两个部分：有效分解和规划建模任务的知识；评估AI回应和识别潜在问题的知识。两者均包括：建模的概念知识；NetLogo和编码的基本概念；调试经验；以及如何与LLMs互动。
- en: For most participants, guidance is what they need most from LLMs in programming.
    While hallucinations from LLMs constantly present a challenge to everyone, with
    a higher frequency to evaluate and debug AI responses, experts suffered less negative
    impact than novices. As a result, experts reported higher levels of perceived
    gains and more optimistic adoption plans than novices. While novices in our study
    also attempt to evaluate and debug AI responses, they are ill-equipped for these
    tasks. Without understanding the knowledge gap between experts and novices, it
    becomes impossible to design effective guidance.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 对大多数参与者来说，指导是他们在编程中从LLMs（大型语言模型）那里最需要的东西。虽然LLMs的幻觉不断给所有人带来挑战，且需要更高频率地评估和调试AI的回应，但专家们遭受的负面影响比新手少。因此，专家报告的感知收益水平更高，采纳计划也比新手更乐观。虽然我们的研究中的新手也尝试评估和调试AI回应，但他们在这些任务上的装备不足。如果不了解专家与新手之间的知识差距，就无法设计有效的指导。
- en: 'Based on our empirical findings, we theorize the two types of knowledge novices
    might need when collaborating with AI in computational modeling (Fig [5](#S6.F5
    "Figure 5 ‣ 6.1\. Guidance: Bridging the Novice-Expert Gap ‣ 6\. Discussions ‣
    Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat")). First, the knowledge to
    effectively decompose and plan modeling tasks. Second, the knowledge to evaluate
    AI responses and identify potential issues. We further identified four components
    of knowledge that both novices and experts reported to be essential: conceptual
    knowledge of modeling; basic concepts of NetLogo and coding; experiences of debugging;
    and how to interact with LLMs. To mitigate the impact of currently inevitable
    hallucinations of LLMs, it is essential to help novices get over the knowledge
    gap.'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 基于我们的实证研究，我们理论化了新手在与AI合作进行计算建模时可能需要的两种知识（见图[5](#S6.F5 "图 5 ‣ 6.1\. 指导：弥合新手-专家差距
    ‣ 6\. 讨论 ‣ 使用LLM伙伴进行基于代理建模的编程学习：新手和专家使用ChatGPT & NetLogo Chat的经验")）。首先，是有效分解和规划建模任务的知识。其次，是评估AI回应和识别潜在问题的知识。我们进一步识别了新手和专家都认为至关重要的四个知识组成部分：建模的概念知识；NetLogo和编码的基本概念；调试经验；以及如何与LLMs互动。为了减轻当前不可避免的LLMs幻觉的影响，帮助新手弥合知识差距至关重要。
- en: We propose three learning moments where design intervention might work best.
    The first moment is when users plan their next steps. While most novices started
    by delegating the planning process to AI, most of them eventually planned on their
    own. Here, we follow the constructionist learning theory for a broader understanding
    of planning that includes both rigid, formal plans and ”softer”, ad-hoc exploration
    of problem spaces(Turkle and Papert, [1990](#bib.bib84)). Both planning styles
    should be recognized as legitimate in learning and supported by the design (Turkle
    and Papert, [1990](#bib.bib84)). With our current design, most novices reported
    positive feelings when NetLogo Chat attempted to clarify their intentions and
    produce a plan for their task. Since this phase does not involve any generated
    code, more support could be provided, as novices may have fewer problems reading
    and evaluating natural language responses. They may also feel more comfortable
    asking questions about modeling or programming ideas, relating them to the generated
    code later, without fearing that they cannot (yet) read or write code. Moreover,
    LLMs could expand learners’ visions by suggesting new ideas, proposing new plans,
    or taking notes of human ideas. When novices are confused about basic concepts,
    LLMs could suggest video or textual tutorials and provide Q&A along the way.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出了三个学习时刻，在这些时刻设计干预可能最有效。第一个时刻是当用户规划他们的下一步时。虽然大多数新手最初将规划过程委托给了AI，但他们最终大多数还是自己进行规划。在这里，我们遵循建构主义学习理论，以更广泛地理解规划，包括既有的严格正式计划和“更柔性”的、临时性的探索问题空间（Turkle和Papert，[1990](#bib.bib84)）。这两种规划风格都应被视为学习中的合法方式，并得到设计的支持（Turkle和Papert，[1990](#bib.bib84)）。在我们当前的设计中，大多数新手在NetLogo
    Chat尝试澄清他们的意图并为他们的任务制定计划时表示感到积极。由于此阶段不涉及任何生成的代码，因此可以提供更多支持，因为新手可能在阅读和评估自然语言响应方面遇到的困难较少。他们可能也会感到更舒适地提出关于建模或编程思想的问题，将这些问题与生成的代码联系起来，而不必担心他们不能（还）阅读或编写代码。此外，LLMs可以通过建议新想法、提出新计划或记录人类想法来扩展学习者的视野。当新手对基本概念感到困惑时，LLMs可以建议视频或文本教程，并提供问答支持。
- en: The second moment is when users read and evaluate LLM-generated code. Reading
    and understanding code is one of the most important aspects of computing education(Lopez
    et al., [2008](#bib.bib52)). However, novices in our study were neither confident
    nor equipped for reading code. As a result, they intended to skip the code section.
    As predicted by the interest development framework(Michaelis and Weintrop, [2022](#bib.bib57)),
    the lack of skills (knowledge) and confidence (identity) may mutually enhance
    each other. Breaking the feedback loop requires designers to scaffold their reading
    experiences in both directions. By making explanations within code (as comments
    or tooltips) or visualizing the code structures (e.g. (Sorva et al., [2013](#bib.bib77))),
    we might be able to help build novices’ connections between code syntax and real-world
    meanings. To build up learners’ confidence, LLMs should deliver code pieces and
    explanations in adaptive sizes that work for learners. For learners who still
    could not succeed, the interface should further provide ad-hoc support that helps
    novices ask follow-up questions, or lead them to appropriate learning resources.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个时刻是当用户阅读和评估LLM生成的代码时。阅读和理解代码是计算机教育中最重要的方面之一（Lopez等，[2008](#bib.bib52)）。然而，我们研究中的新手对阅读代码既没有信心也没有足够的能力。因此，他们倾向于跳过代码部分。正如兴趣发展框架（Michaelis和Weintrop，[2022](#bib.bib57)）所预测的，技能（知识）和信心（身份）的缺乏可能会相互增强。打破反馈循环需要设计师在两个方向上支撑他们的阅读体验。通过在代码中添加解释（如注释或工具提示）或可视化代码结构（例如（Sorva等，[2013](#bib.bib77)）），我们可能能够帮助新手建立代码语法与现实世界意义之间的联系。为了提高学习者的信心，LLMs应提供适应性大小的代码片段和解释，适合学习者的需求。对于那些仍然无法成功的学习者，界面应进一步提供临时支持，帮助新手提出后续问题，或引导他们到适当的学习资源。
- en: The third moment is when users need to debug their code. Debugging is considered
    a rich learning opportunity in constructionist learning(Kafai et al., [2020](#bib.bib40)).
    However, it is often associated with negative feelings that both manifested in
    prior literature(Whalley et al., [2021a](#bib.bib92)), as well as our findings.
    Unfortunately, cognitive science has found that negative moods may further impede
    debugging performance(Khan et al., [2011](#bib.bib44)), enlarging the gap between
    novices and experts. Following the suggestions of educators in our study, we suggest
    that LLM-based interfaces could frame bugs in a more positive light, while providing
    a link to a successful human-AI collaborative debugging process for first-time
    learners. Both novices’ and LLMs’ debugging processes are often stuck in loops(Whalley
    et al., [2021b](#bib.bib93); Wu et al., [2023](#bib.bib98)). While such situations
    are inevitable, some expert participants suggest that LLM-based interfaces could
    encourage learners to seek help from another human. Help-seeking is recognized
    as an important part of programming education, yet novices often struggle with
    it(Marwan et al., [2020](#bib.bib55)). In such cases, LLM-based interfaces should
    further help them frame questions for human experts.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个时刻是用户需要调试他们的代码时。调试被认为是建构主义学习中的一个丰富学习机会（Kafai 等人, [2020](#bib.bib40)）。然而，它通常与负面情绪相关，这在以往文献（Whalley
    等人, [2021a](#bib.bib92)）以及我们的研究发现中都有体现。不幸的是，认知科学发现负面情绪可能进一步阻碍调试表现（Khan 等人, [2011](#bib.bib44)），扩大了新手与专家之间的差距。根据我们研究中教育者的建议，我们建议
    LLM 基础的接口可以以更积极的角度呈现错误，同时为首次学习者提供成功的人机协作调试过程的链接。新手和 LLM 的调试过程往往陷入循环（Whalley 等人,
    [2021b](#bib.bib93); Wu 等人, [2023](#bib.bib98)）。虽然这种情况是不可避免的，但一些专家参与者建议 LLM 基础的接口可以鼓励学习者寻求他人的帮助。寻求帮助被认为是编程教育中的一个重要部分，但新手往往在这方面遇到困难（Marwan
    等人, [2020](#bib.bib55)）。在这种情况下，LLM 基础的接口应进一步帮助他们为人类专家提出问题。
- en: '6.2\. Personalization: Beyond “Correctness” of LLMs'
  id: totrans-287
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2\. 个性化：超越 LLM 的“正确性”
- en: Personalization has been identified as an essential factor for perceived autonomy
    when users interact with conversational agents(Yang and Aurisicchio, [2021](#bib.bib99)),
    for emotional and relational connections(Wellner and Levin, [2023](#bib.bib90)),
    and for various educational benefits(Bernacki et al., [2021](#bib.bib7)). Adding
    to previous literature, we found personalization to be a crucial factor for LLMs
    to facilitate effective guidance for learning, as participants expect LLMs to
    recognize their knowledge levels and react accordingly.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 个性化被认为是在用户与对话代理交互时感知自主性的一个重要因素（Yang 和 Aurisicchio, [2021](#bib.bib99)），对情感和关系连接也至关重要（Wellner
    和 Levin, [2023](#bib.bib90)），并且对各种教育益处具有影响（Bernacki 等人, [2021](#bib.bib7)）。在以往文献的基础上，我们发现个性化是大语言模型（LLMs）有效指导学习的关键因素，因为参与者期望
    LLMs 识别他们的知识水平并作出相应的反应。
- en: While LLMs might have the potential to further the personalization of learning,
    recent research in LLMs focused on the “objective” capabilities, ignoring the
    personalized aspect of its evaluation. For example, technical reports of LLMs
    all reported benchmarks in whether they could produce functionally correct programs
    (HumanEval)(Chen et al., [2021](#bib.bib16)); if they could correctly answer multi-choice
    questions (MMLU)(Hendrycks et al., [2020](#bib.bib34)); or if they could produce
    the correct answer of grade school mathematical problems (GSM-8K)(Cobbe et al.,
    [2021](#bib.bib21)). While working toward such “correctness” benchmarks is certainly
    crucial for LLMs to reduce hallucination and produce better responses, it becomes
    problematic when the definition of “helpfulness” or “harmfulness” is measured
    with a ubiquitous scale without individual differences (Bai et al., [2022](#bib.bib3)),
    and such a definition has since been adopted by all major players in LLMs.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 LLM 可能有进一步个性化学习的潜力，但最近关于 LLM 的研究集中在“客观”能力上，忽视了其评估的个性化方面。例如，LLM 的技术报告都报告了它们是否能生成功能上正确的程序（HumanEval）（Chen
    等人, [2021](#bib.bib16)）；是否能正确回答多项选择题（MMLU）（Hendrycks 等人, [2020](#bib.bib34)）；或是否能正确解答小学数学问题（GSM-8K）（Cobbe
    等人, [2021](#bib.bib21)）。虽然致力于这种“正确性”基准对 LLM 减少幻觉并生成更好的回应至关重要，但当“有用性”或“有害性”的定义通过普遍的尺度来衡量而不考虑个体差异时（Bai
    等人, [2022](#bib.bib3)），就会出现问题，而这种定义已经被所有主要的 LLM 参与者采纳。
- en: 'At least in learning and practice programming, we argue that helpfulness cannot
    be a singular metric, but instead varies based on many factors. Corroborating
    with constructionist design principles(Resnick and Silverman, [2005](#bib.bib67)),
    we identified some potentially important factors such as knowledge levels and
    help-seeking preferences, while other factors such as culture, ethnicity, and
    gender could be as important. To support human learning, the full potential of
    LLMs could only be achieved through the recognition of epistemological pluralism(Turkle
    and Papert, [1990](#bib.bib84)): humans have different approaches toward learning,
    and technology needs to be tailored to human needs.'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 至少在学习和实践编程中，我们认为有用性不能是一个单一的指标，而是基于许多因素而有所不同。根据建构主义设计原则（Resnick and Silverman,
    [2005](#bib.bib67)），我们确定了一些可能重要的因素，如知识水平和求助偏好，而其他因素如文化、民族和性别可能同样重要。为了支持人类学习，LLMs的全部潜力只能通过承认认识论的多样性（Turkle
    and Papert, [1990](#bib.bib84)）来实现：人类对学习有不同的方法，技术需要根据人类的需求进行定制。
- en: 'Most participants in our study expected or asked for personalization, in the
    sense that LLMs recognize their knowledge levels and help-seeking needs, yet today’s
    designs are still far from that. While it is virtually impossible to fine-tune
    thousands of LLM variants, LLMs’ role-play capabilities and novel prompt-based
    workflows (e.g. the one used by NetLogo Chat, or the concept of GPTs very recently
    released by OpenAI) have shown promising potential. As personalization requires
    the inevitable and sometimes controversial collection of user data, we suggest
    a more upfront approach: only collecting data that directly contributes to a more
    helpful AI (e.g. the knowledge level), only using data for this purpose, and explaining
    the benefits, risks, and privacy processes at the beginning. Alternatively, designers
    could also consider flowing the pathway of cognitive modeling, which deduces learners’
    knowledge levels from known interactions with the system(Sun, [2008](#bib.bib78)).
    On the other hand, our understanding of users’ perceptions, behaviors, and needs
    for LLM-based programming interfaces has just begun, and we call on more studies
    to pursue this direction.'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究中的大多数参与者期望或要求个性化，即LLMs能够识别他们的知识水平和求助需求，但目前的设计仍然远未达到这一点。尽管几乎不可能对成千上万的LLM变体进行微调，但LLMs的角色扮演能力和基于提示的工作流程（例如NetLogo
    Chat使用的工作流程，或OpenAI最近发布的GPT概念）显示出了有希望的潜力。由于个性化需要不可避免且有时具有争议地收集用户数据，我们建议采取更直接的方法：仅收集直接有助于改进AI的数据（例如知识水平），仅将数据用于此目的，并在开始时解释好处、风险和隐私流程。或者，设计师也可以考虑采用认知建模的方法，这种方法从已知的系统交互中推断学习者的知识水平（Sun,
    [2008](#bib.bib78)）。另一方面，我们对基于LLM的编程接口的用户感知、行为和需求的理解才刚刚开始，我们呼吁更多的研究来追求这个方向。
- en: '6.3\. Integration: LLMs for Computational Modeling'
  id: totrans-292
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3\. 集成：用于计算建模的LLMs
- en: 'For most participants, integration between LLM-based interfaces and modeling
    environments goes beyond stitching a chat window into the IDE. While most of them
    appreciated NetLogo Chat’s design directions, they put forward many needs that
    are worth considering in future design. Here, we briefly discuss the two major
    themes: support for troubleshooting; and support for modeling. For troubleshooting:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数参与者来说，基于LLM的接口与建模环境的集成不仅仅是将聊天窗口嵌入到IDE中。尽管大多数人赞赏NetLogo Chat的设计方向，但他们提出了许多在未来设计中值得考虑的需求。在这里，我们简要讨论两个主要主题：对故障排除的支持；以及对建模的支持。对于故障排除：
- en: (1)
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: The capability to work on smaller snippets of code, with the capability to execute,
    explain, and debug code in context. For both humans and LLMs(Hou et al., [2023](#bib.bib35)),
    debugging complicated code is known to be difficult. NetLogo Chat has made the
    first step in reducing the scope to smaller code chunks. As such, it becomes easier
    for both humans to debug and LLMs to support their debugging processes. Whereas,
    more work is needed to bring together the code chunks into coherent full programs.
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 处理更小的代码片段的能力，包括在上下文中执行、解释和调试代码的能力。对于人类和LLMs（Hou et al., [2023](#bib.bib35)），调试复杂代码是已知的困难。NetLogo
    Chat已迈出了将范围缩小到更小代码块的第一步。因此，调试变得更容易，人类和LLMs都能更好地支持调试过程。然而，还需要更多的工作将这些代码块整合成连贯的完整程序。
- en: (2)
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: 'The capability to leverage authoritative NetLogo documentation in generated
    responses, as well as for the user’s own reference. In debugging contexts, LLMs’
    tendency to hallucinate becomes more frustrating. By providing users and LLMs
    with authoritative explanations within the debugging context, NetLogo Chat may
    reduce the effort for users to seek related information, which is also known to
    be difficult for novices(Dorn et al., [2013](#bib.bib25)). More work is needed
    to explain in a more personalized way: for example, pure novices may need explanations
    for every basic term.'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在生成的响应中利用权威的NetLogo文档的能力，以及用户自己参考的能力。在调试上下文中，LLMs的幻觉倾向变得更加令人沮丧。通过在调试上下文中为用户和LLMs提供权威解释，NetLogo
    Chat可能会减少用户寻找相关信息的努力，这对初学者来说也是困难的（Dorn 等，[2013](#bib.bib25)）。需要更多的工作来以更个性化的方式进行解释：例如，纯初学者可能需要对每一个基本术语进行解释。
- en: (3)
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3)
- en: 'The capability to automatically send in contextual information (i.e. code and
    error messages) for LLM to troubleshoot. Users generally appreciated NetLogo Chat’s
    design decision to support troubleshooting. However, the convenience came with
    a potential price: when using NetLogo Chat, users were more likely to ask LLMs
    for help, which might lead to fewer human attempts and learning opportunities.
    Further studies are needed to understand this design balance better.'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自动发送上下文信息（即代码和错误信息）以便LLM进行故障排除的能力。用户普遍欣赏NetLogo Chat支持故障排除的设计决策。然而，这种便利性带来了一个潜在的代价：使用NetLogo
    Chat时，用户更可能向LLM寻求帮助，这可能导致人类尝试和学习机会的减少。需要进一步研究以更好地理解这种设计平衡。
- en: 'Many participants also asked for features that specifically support their computational
    modeling tasks, which are known to have different priorities from programming
    in general(Pylyshyn, [1978](#bib.bib66)). Here, two more capabilities are warranted:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 许多参与者还要求支持他们的计算建模任务的特定功能，这些任务的优先级与一般编程有所不同（Pylyshyn，[1978](#bib.bib66)）。在这里，两个额外的能力是必要的：
- en: (1)
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: The capability to assume less, actively probe, and stick to user intentions.
    In addition to the potential learning opportunities (see Discussion 1), for participants,
    hidden assumptions in scientific modeling are particularly harmful. While users
    appreciate NetLogo Chat’s direction in having LLMs ask questions back, future
    interfaces should be able to facilitate the conversational build-up of plans and
    steps, further supporting users to program computers piece-by-piece rather than
    falling to hidden assumptions made by LLMs.
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 能够减少假设，积极探究并坚持用户意图。除了潜在的学习机会（见讨论1），对于参与者而言，科学建模中的隐性假设特别有害。虽然用户欣赏NetLogo Chat在让LLMs提出问题方面的方向，但未来的接口应能够促进计划和步骤的对话式建立，进一步支持用户逐步编程，而不是陷入LLMs所做的隐性假设中。
- en: (2)
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: The capability to support modeling practices beyond coding. Building the program
    is only one step; computational modeling also involves design, data visualization,
    and validation(Weintrop et al., [2016](#bib.bib89)). For LLM-based interfaces
    to support modeling practices, future interfaces should go beyond coding to support
    users’ efforts throughout the modeling process.
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 支持超越编码的建模实践的能力。构建程序只是一步；计算建模还涉及设计、数据可视化和验证（Weintrop 等，[2016](#bib.bib89)）。为了使基于LLM的接口能够支持建模实践，未来的接口应超越编码，以支持用户在整个建模过程中的努力。
- en: 7\. Limitations and Future Work
  id: totrans-305
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 限制和未来工作
- en: There are limitations to our study that warrant future work. As a widely used
    agent-based modeling language, a deeper understanding of user perceptions, behaviors,
    and needs for LLM-based interfaces around NetLogo may inform us of design choices
    for other modeling environments. Future work should consider computational modeling
    or programming environments that might have different priorities. Since the NetLogo
    language was designed for an audience without a computer science background(Tisue
    and Wilensky, [2004](#bib.bib83)), it becomes more important and meaningful to
    understand how to design for bridging the novice-expert gap in LLM-based interfaces.
    However, it is unclear whether our findings and suggestions would sufficiently
    support novices’ and experts’ learning and practice of NetLogo. Using a more rigid
    rubric to distinguish between experts and novices might improve the rigor of our
    study. A quantitative, controlled study in the future might further (in)validate
    our findings and suggestions. As such, we plan to work on a new iteration of NetLogo
    Chat design and empirical study to fully understand the design implications.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究存在一些限制，这些限制需要在未来的工作中加以解决。作为一种广泛使用的基于代理的建模语言，深入了解用户对基于LLM的NetLogo接口的感知、行为和需求，可能会为其他建模环境的设计选择提供指导。未来的工作应考虑那些可能具有不同优先级的计算建模或编程环境。由于NetLogo语言是为没有计算机科学背景的受众设计的（Tisue和Wilensky，[2004](#bib.bib83)），理解如何设计以弥合LLM接口中的新手与专家之间的差距变得更加重要和有意义。然而，目前尚不清楚我们的发现和建议是否能充分支持新手和专家对NetLogo的学习和实践。使用更严格的标准来区分专家和新手可能会提高我们研究的严谨性。未来的定量、对照研究可能会进一步（不）验证我们的发现和建议。因此，我们计划开展NetLogo
    Chat设计和实证研究的新迭代，以充分理解设计的影响。
- en: Although we aimed to recruit participants representative of NetLogo’s global
    audience, our participant pool was not as representative as we hoped in two key
    dimensions. First, our participants were mostly professionals, academics, and
    graduate students. While K-12 teachers and learners are another major audience
    for NetLogo and agent-based modeling and may have different priorities and preferences(Sengupta
    et al., [2015](#bib.bib72)), only one K-12 teacher was present in the study. More
    studies are warranted to further the empirical understanding of LLM-based interfaces
    in education contexts. Second, the demographics of our participants skewed towards
    North American and European, highly educated, and male. Such a group of participants,
    recruited voluntarily, might manifest higher than average acceptability toward
    novel technology, e.g. most of our participants have already engaged with ChatGPT.
    For future work, researchers need to recruit a more balanced and diverse group
    of participants, if the goal is for LLM-based programming interfaces to equitably
    support novices and experts throughout the world.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们旨在招募能够代表NetLogo全球受众的参与者，但我们的参与者池在两个关键维度上并没有如我们所希望的那样具有代表性。首先，我们的参与者主要是专业人士、学者和研究生。虽然K-12教师和学习者是NetLogo和基于代理的建模的另一主要受众，并且可能有不同的优先级和偏好（Sengupta等，[2015](#bib.bib72)），但在研究中仅有一位K-12教师。需要更多研究来进一步了解教育环境中的LLM接口。其次，我们参与者的群体在北美和欧洲的受教育程度较高且男性居多。这样的一组自愿招募的参与者可能对新技术表现出比平均水平更高的接受度，例如我们大多数参与者已经接触过ChatGPT。对于未来的工作，如果LLM编程接口的目标是公平地支持全球的新手和专家，研究人员需要招募更均衡和多样化的参与者群体。
- en: 8\. Conclusion
  id: totrans-308
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8\. 结论
- en: 'As Large language models (LLMs) have the potential to fundamentally change
    how people learn and practice computational modeling and programming in general,
    it is crucial that we gain a deeper understanding of users’ perceptions, behaviors,
    and needs in a more naturalistic setting. For this purpose, we designed and developed
    NetLogo Chat, a novel LLM-based system that supports and integrates with a version
    of NetLogo IDE. We conducted an interview study with 30 adult participants to
    understand how they perceived, collaborated with, and asked for LLM-based interfaces
    for learning and practice of NetLogo. Consistent with previous studies, experts
    reported more perceived benefits than novices. We found remarkable differences
    between novices and experts in their perceptions, behaviors, and needs. We identified
    a knowledge gap that might have contributed to the differences. We proposed design
    recommendations around participants’ main needs: guidance, personalization, and
    integration. Our findings inform future design of LLM-based programming interfaces,
    especially for computational modeling.'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大型语言模型（LLMs）有可能从根本上改变人们学习和实践计算建模及编程的方式，我们必须在更自然的环境中深入了解用户的认知、行为和需求。为此，我们设计并开发了NetLogo
    Chat，这是一种新颖的基于LLM的系统，支持并与NetLogo IDE的一个版本集成。我们对30名成年参与者进行了访谈研究，以了解他们如何感知、合作以及如何请求基于LLM的界面来学习和实践NetLogo。与以往的研究一致，专家报告的感知益处多于新手。我们发现新手与专家在认知、行为和需求方面存在显著差异。我们识别了一个可能导致这些差异的知识差距。我们围绕参与者的主要需求提出了设计建议：指导、个性化和集成。我们的发现为未来基于LLM的编程接口设计提供了指导，特别是在计算建模方面。
- en: Acknowledgements.
  id: totrans-310
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 致谢。
- en: We would like to express our gratitude to the [NetLogo Online community](https://community.netlogo.org/)
    and [Complexity Explorer](https://www.complexityexplorer.org/) for their help
    and support. We are especially thankful to the hundreds of NetLogo users who volunteered
    for the study. We would also like to thank current and former members of our lab
    and anonymous youth users of Turtle Universe, who provided valuable feedback and
    ideas during our design process. Specifically, we want to acknowledge the intellectual
    contributions of Umit Aslan; Aaron Brandes; Jeremy Baker; Jason Bertsche; Matthew
    Berland; Sharona Levy; Jacob Kelter; Leif Rasmussen; David Weintrop; and Lexie
    Zhao. Finally, we appreciate the valuable and actionable feedback from our anonymous
    CHI reviewers, which significantly strengthened the paper.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要感谢[NetLogo Online community](https://community.netlogo.org/)和[Complexity
    Explorer](https://www.complexityexplorer.org/)的帮助和支持。我们特别感谢那些自愿参与研究的数百名NetLogo用户。我们还要感谢我们实验室的现任和前任成员，以及Turtle
    Universe的匿名年轻用户，他们在我们的设计过程中提供了宝贵的反馈和建议。特别是，我们要感谢Umit Aslan、Aaron Brandes、Jeremy
    Baker、Jason Bertsche、Matthew Berland、Sharona Levy、Jacob Kelter、Leif Rasmussen、David
    Weintrop和Lexie Zhao的智力贡献。最后，我们感谢匿名CHI审稿人提供的宝贵和可操作的反馈，这显著增强了本文的质量。
- en: References
  id: totrans-312
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: noa ([n. d.]) [n. d.]. Using GitHub Copilot Chat. [https://ghdocs-prod.azurewebsites.net/en/copilot/github-copilot-chat/using-github-copilot-chat](https://ghdocs-prod.azurewebsites.net/en/copilot/github-copilot-chat/using-github-copilot-chat)
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: noa ([n. d.]) [n. d.]. 使用 GitHub Copilot Chat. [https://ghdocs-prod.azurewebsites.net/en/copilot/github-copilot-chat/using-github-copilot-chat](https://ghdocs-prod.azurewebsites.net/en/copilot/github-copilot-chat/using-github-copilot-chat)
- en: Bai et al. (2022) Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna
    Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas
    Joseph, Saurav Kadavath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nelson
    Elhage, Zac Hatfield-Dodds, Danny Hernandez, Tristan Hume, Scott Johnston, Shauna
    Kravec, Liane Lovitt, Neel Nanda, Catherine Olsson, Dario Amodei, Tom Brown, Jack
    Clark, Sam McCandlish, Chris Olah, Ben Mann, and Jared Kaplan. 2022. Training
    a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback.
    [https://doi.org/10.48550/arXiv.2204.05862](https://doi.org/10.48550/arXiv.2204.05862)
    arXiv:2204.05862 [cs].
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bai et al. (2022) Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna
    Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas
    Joseph, Saurav Kadavath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nelson
    Elhage, Zac Hatfield-Dodds, Danny Hernandez, Tristan Hume, Scott Johnston, Shauna
    Kravec, Liane Lovitt, Neel Nanda, Catherine Olsson, Dario Amodei, Tom Brown, Jack
    Clark, Sam McCandlish, Chris Olah, Ben Mann, and Jared Kaplan. 2022. Training
    a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback.
    [https://doi.org/10.48550/arXiv.2204.05862](https://doi.org/10.48550/arXiv.2204.05862)
    arXiv:2204.05862 [cs].
- en: Balse et al. (2023) Rishabh Balse, Bharath Valaboju, Shreya Singhal, Jayakrishnan Madathil
    Warriem, and Prajish Prasad. 2023. Investigating the Potential of GPT-3 in Providing
    Feedback for Programming Assessments. In *Proceedings of the 2023 Conference on
    Innovation and Technology in Computer Science Education V. 1* *(ITiCSE 2023)*.
    Association for Computing Machinery, New York, NY, USA, 292–298. [https://doi.org/10.1145/3587102.3588852](https://doi.org/10.1145/3587102.3588852)
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Balse 等（2023）Rishabh Balse、Bharath Valaboju、Shreya Singhal、Jayakrishnan Madathil
    Warriem 和 Prajish Prasad。2023年。研究 GPT-3 在编程评估反馈中的潜力。在 *2023 年计算机科学教育创新与技术会议论文集
    V. 1* *(ITiCSE 2023)* 中。计算机协会，美国纽约，292–298。 [https://doi.org/10.1145/3587102.3588852](https://doi.org/10.1145/3587102.3588852)
- en: 'Barke et al. (2023) Shraddha Barke, Michael B. James, and Nadia Polikarpova.
    2023. Grounded copilot: How programmers interact with code-generating models.
    *Proceedings of the ACM on Programming Languages* 7, OOPSLA1 (2023), 85–111. Publisher:
    ACM New York, NY, USA.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Barke 等（2023）Shraddha Barke、Michael B. James 和 Nadia Polikarpova。2023年。基础协助者：程序员如何与代码生成模型互动。*ACM
    编程语言会议论文集* 7，OOPSLA1（2023），85–111。出版商：ACM 纽约，美国。
- en: 'Becker et al. (2019) Brett A Becker, Paul Denny, Raymond Pettit, Durell Bouchard,
    Dennis J Bouvier, Brian Harrington, Amir Kamil, Amey Karkare, Chris McDonald,
    Peter-Michael Osera, et al. 2019. Compiler error messages considered unhelpful:
    The landscape of text-based programming error message research. *Proceedings of
    the working group reports on innovation and technology in computer science education*
    (2019), 177–210.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Becker 等（2019）Brett A Becker、Paul Denny、Raymond Pettit、Durell Bouchard、Dennis
    J Bouvier、Brian Harrington、Amir Kamil、Amey Karkare、Chris McDonald、Peter-Michael
    Osera 等。2019年。编译器错误信息被认为无帮助：基于文本的编程错误信息研究的现状。*计算机科学教育创新与技术工作组报告*（2019），177–210。
- en: 'Bernacki et al. (2021) Matthew L. Bernacki, Meghan J. Greene, and Nikki G.
    Lobczowski. 2021. A systematic review of research on personalized learning: Personalized
    by whom, to what, how, and for what purpose (s)? *Educational Psychology Review*
    33, 4 (2021), 1675–1715. Publisher: Springer.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bernacki 等（2021）Matthew L. Bernacki、Meghan J. Greene 和 Nikki G. Lobczowski。2021年。个性化学习研究的系统评审：由谁个性化，个性化到什么程度，如何进行，以及目的是什么？
    *教育心理学评论* 33，4（2021），1675–1715。出版商：Springer。
- en: Blikstein (2011) Paulo Blikstein. 2011. Using learning analytics to assess students’
    behavior in open-ended programming tasks. In *Proceedings of the 1st international
    conference on learning analytics and knowledge*. 110–116.
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Blikstein（2011）Paulo Blikstein。2011年。利用学习分析来评估学生在开放式编程任务中的行为。在 *第一届国际学习分析与知识会议论文集*
    中，110–116。
- en: 'Blikstein et al. (2014) Paulo Blikstein, Marcelo Worsley, Chris Piech, Mehran
    Sahami, Steven Cooper, and Daphne Koller. 2014. Programming pluralism: Using learning
    analytics to detect patterns in the learning of computer programming. *Journal
    of the Learning Sciences* 23, 4 (2014), 561–599. Publisher: Taylor & Francis.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Blikstein 等（2014）Paulo Blikstein、Marcelo Worsley、Chris Piech、Mehran Sahami、Steven
    Cooper 和 Daphne Koller。2014年。编程多样性：利用学习分析检测计算机编程学习中的模式。*学习科学杂志* 23，4（2014），561–599。出版商：Taylor
    & Francis。
- en: 'Brady et al. (2020) Corey Brady, Melissa Gresalfi, Selena Steinberg, and Madison
    Knowe. 2020. Debugging for Art’s Sake: Beginning Programmers’ Debugging Activity
    in an Expressive Coding Context. (June 2020). [https://repository.isls.org//handle/1/6319](https://repository.isls.org//handle/1/6319)
    Publisher: International Society of the Learning Sciences (ISLS).'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brady 等（2020）Corey Brady、Melissa Gresalfi、Selena Steinberg 和 Madison Knowe。2020年。为了艺术的调试：初学者在表现性编码环境中的调试活动。（2020年6月）。
    [https://repository.isls.org//handle/1/6319](https://repository.isls.org//handle/1/6319)
    出版商：国际学习科学学会（ISLS）。
- en: 'Bull and Kharrufa (2023) Christopher Bull and Ahmed Kharrufa. 2023. Generative
    AI Assistants in Software Development Education: A vision for integrating Generative
    AI into educational practice, not instinctively defending against it. *IEEE Software*
    (2023), 1–9. [https://doi.org/10.1109/MS.2023.3300574](https://doi.org/10.1109/MS.2023.3300574)
    Conference Name: IEEE Software.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bull 和 Kharrufa（2023）Christopher Bull 和 Ahmed Kharrufa。2023年。软件开发教育中的生成式 AI
    助手：将生成式 AI 融入教育实践的愿景，而不是本能地抵御它。*IEEE 软件*（2023），1–9。 [https://doi.org/10.1109/MS.2023.3300574](https://doi.org/10.1109/MS.2023.3300574)
    会议名称：IEEE 软件。
- en: 'Caballé and Conesa (2019) Santi Caballé and Jordi Conesa. 2019. Conversational
    agents in support for collaborative learning in MOOCs: An analytical review. In
    *Advances in Intelligent Networking and Collaborative Systems: The 10th International
    Conference on Intelligent Networking and Collaborative Systems (INCoS-2018)*.
    Springer, 384–394.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Caballé 和 Conesa（2019）Santi Caballé 和 Jordi Conesa。2019。《支持 MOOC 中协作学习的对话代理：分析综述》。在
    *智能网络与协作系统的进展：第十届国际智能网络与协作系统会议（INCoS-2018）* 中。Springer，第 384–394 页。
- en: Chen et al. (2022) Fuxiang Chen, Fatemeh H. Fard, David Lo, and Timofey Bryksin.
    2022. On the transferability of pre-trained language models for low-resource programming
    languages. In *Proceedings of the 30th IEEE/ACM International Conference on Program
    Comprehension*. 401–412.
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等（2022）Fuxiang Chen、Fatemeh H. Fard、David Lo 和 Timofey Bryksin。2022。《预训练语言模型在资源有限编程语言中的可转移性》。在
    *第 30 届 IEEE/ACM 国际程序理解会议论文集* 中。401–412 页。
- en: Chen and Wilensky (2021) John Chen and Uri J. Wilensky. 2021. Turtle Universe.
    [https://turtlesim.com/products/turtle-universe/](https://turtlesim.com/products/turtle-universe/)
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 和 Wilensky（2021）John Chen 和 Uri J. Wilensky。2021。《乌龟宇宙》。 [https://turtlesim.com/products/turtle-universe/](https://turtlesim.com/products/turtle-universe/)
- en: 'Chen et al. (2023b) John Chen, Lexie Zhao, Horn Michael, and Wilensky Uri.
    2023b. The Pocketworld Playground: Engaging Online, Out-of-School Learners with
    Agent-based Programming. In *Proceedings of the ACM Interaction Design and Children
    (IDC)*.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等（2023b）John Chen、Lexie Zhao、Horn Michael 和 Wilensky Uri。2023b。《口袋世界游乐场：通过基于代理的编程吸引在线、课外学习者》。在
    *ACM 互动设计与儿童（IDC）会议录* 中。
- en: Chen et al. (2021) Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique
    Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph,
    and Greg Brockman. 2021. Evaluating large language models trained on code. *arXiv
    preprint arXiv:2107.03374* (2021).
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等（2021）Mark Chen、Jerry Tworek、Heewoo Jun、Qiming Yuan、Henrique Ponde de
    Oliveira Pinto、Jared Kaplan、Harri Edwards、Yuri Burda、Nicholas Joseph 和 Greg Brockman。2021。《评估在代码上训练的大型语言模型》。*arXiv
    预印本 arXiv:2107.03374*（2021年）。
- en: 'Chen et al. (2023a) Zhutian Chen, Chenyang Zhang, Qianwen Wang, Jakob Troidl,
    Simon Warchol, Johanna Beyer, Nils Gehlenborg, and Hanspeter Pfister. 2023a. Beyond
    Generating Code: Evaluating GPT on a Data Visualization Course. [https://doi.org/10.48550/arXiv.2306.02914](https://doi.org/10.48550/arXiv.2306.02914)
    arXiv:2306.02914 [cs].'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等（2023a）Zhutian Chen、Chenyang Zhang、Qianwen Wang、Jakob Troidl、Simon Warchol、Johanna
    Beyer、Nils Gehlenborg 和 Hanspeter Pfister。2023a。《超越生成代码：评估 GPT 在数据可视化课程中的表现》。
    [https://doi.org/10.48550/arXiv.2306.02914](https://doi.org/10.48550/arXiv.2306.02914)
    arXiv:2306.02914 [cs]。
- en: Chi et al. (1981) Michelene TH Chi, Paul J Feltovich, and Robert Glaser. 1981.
    Categorization and representation of physics problems by experts and novices.
    *Cognitive science* 5, 2 (1981), 121–152.
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chi 等（1981）Michelene TH Chi、Paul J Feltovich 和 Robert Glaser。1981。《专家和新手对物理问题的分类和表示》。*认知科学*
    5，第 2 期（1981年），121–152 页。
- en: 'Clark et al. (2009) Douglas Clark, Brian Nelson, Pratim Sengupta, and Cynthia
    D’Angelo. 2009. Rethinking science learning through digital games and simulations:
    Genres, examples, and evidence. In *Learning science: Computer games, simulations,
    and education workshop sponsored by the National Academy of Sciences, Washington,
    DC*.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Clark 等（2009）Douglas Clark、Brian Nelson、Pratim Sengupta 和 Cynthia D’Angelo。2009。《通过数字游戏和模拟重新思考科学学习：类型、示例和证据》。在
    *学习科学：计算机游戏、模拟和教育研讨会，由国家科学院、华盛顿特区主办* 中。
- en: Clark et al. (2019) Leigh Clark, Nadia Pantidi, Orla Cooney, Philip Doyle, Diego
    Garaialde, Justin Edwards, Brendan Spillane, Emer Gilmartin, Christine Murad,
    and Cosmin Munteanu. 2019. What makes a good conversation? Challenges in designing
    truly conversational agents. In *Proceedings of the 2019 CHI conference on human
    factors in computing systems*. 1–12.
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Clark 等（2019）Leigh Clark、Nadia Pantidi、Orla Cooney、Philip Doyle、Diego Garaialde、Justin
    Edwards、Brendan Spillane、Emer Gilmartin、Christine Murad 和 Cosmin Munteanu。2019。《什么构成良好的对话？设计真正的对话代理的挑战》。在
    *2019 年 CHI 会议关于计算系统中的人类因素的论文集* 中。1–12。
- en: Cobbe et al. (2021) Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen,
    Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro
    Nakano, Christopher Hesse, and John Schulman. 2021. Training Verifiers to Solve
    Math Word Problems. [https://doi.org/10.48550/arXiv.2110.14168](https://doi.org/10.48550/arXiv.2110.14168)
    arXiv:2110.14168 [cs].
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cobbe 等（2021）Karl Cobbe、Vineet Kosaraju、Mohammad Bavarian、Mark Chen、Heewoo Jun、Lukasz
    Kaiser、Matthias Plappert、Jerry Tworek、Jacob Hilton、Reiichiro Nakano、Christopher
    Hesse 和 John Schulman。2021。《训练验证器以解决数学文字题》。 [https://doi.org/10.48550/arXiv.2110.14168](https://doi.org/10.48550/arXiv.2110.14168)
    arXiv:2110.14168 [cs]。
- en: 'Cooper (2023) Grant Cooper. 2023. Examining Science Education in ChatGPT: An
    Exploratory Study of Generative Artificial Intelligence. *Journal of Science Education
    and Technology* 32, 3 (June 2023), 444–452. [https://doi.org/10.1007/s10956-023-10039-y](https://doi.org/10.1007/s10956-023-10039-y)'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cooper (2023) Grant Cooper. 2023. 在 ChatGPT 中考察科学教育：生成性人工智能的探索性研究。*科学教育与技术期刊*
    32, 3 (2023年6月), 444–452. [https://doi.org/10.1007/s10956-023-10039-y](https://doi.org/10.1007/s10956-023-10039-y)
- en: 'Corbin and Strauss (1990) Juliet M. Corbin and Anselm Strauss. 1990. Grounded
    theory research: Procedures, canons, and evaluative criteria. *Qualitative sociology*
    13, 1 (1990), 3–21. Publisher: Springer.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Corbin and Strauss (1990) Juliet M. Corbin 和 Anselm Strauss. 1990. 扎根理论研究：程序、规范和评估标准。*定性社会学*
    13, 1 (1990), 3–21. 出版社：Springer。
- en: 'Dakhel et al. (2023) Arghavan Moradi Dakhel, Vahid Majdinasab, Amin Nikanjam,
    Foutse Khomh, Michel C. Desmarais, and Zhen Ming Jack Jiang. 2023. Github copilot
    ai pair programmer: Asset or liability? *Journal of Systems and Software* 203
    (2023), 111734. Publisher: Elsevier.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dakhel et al. (2023) Arghavan Moradi Dakhel, Vahid Majdinasab, Amin Nikanjam,
    Foutse Khomh, Michel C. Desmarais, 和 Zhen Ming Jack Jiang. 2023. GitHub Copilot
    AI 配对程序员：资产还是负担？*系统与软件期刊* 203 (2023), 111734. 出版社：Elsevier。
- en: 'Dorn et al. (2013) Brian Dorn, Adam Stankiewicz, and Chris Roggi. 2013. Lost
    while searching: Difficulties in information seeking among end-user programmers.
    *Proceedings of the American Society for Information Science and Technology* 50,
    1 (2013), 1–10. Publisher: Wiley Online Library.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dorn et al. (2013) Brian Dorn, Adam Stankiewicz, 和 Chris Roggi. 2013. 在搜索过程中迷失：终端用户程序员在信息检索中的困难。*美国信息科学与技术学会会议录*
    50, 1 (2013), 1–10. 出版社：Wiley Online Library。
- en: 'Eloundou et al. (2023) Tyna Eloundou, Sam Manning, Pamela Mishkin, and Daniel
    Rock. 2023. Gpts are gpts: An early look at the labor market impact potential
    of large language models. *arXiv preprint arXiv:2303.10130* (2023).'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eloundou et al. (2023) Tyna Eloundou, Sam Manning, Pamela Mishkin, 和 Daniel
    Rock. 2023. GPTs 是 GPTs：大型语言模型对劳动市场潜在影响的早期观察。*arXiv 预印本 arXiv:2303.10130* (2023)。
- en: 'Fiannaca et al. (2023) Alexander J. Fiannaca, Chinmay Kulkarni, Carrie J. Cai,
    and Michael Terry. 2023. Programming without a Programming Language: Challenges
    and Opportunities for Designing Developer Tools for Prompt Programming. In *Extended
    Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems*. 1–7.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fiannaca et al. (2023) Alexander J. Fiannaca, Chinmay Kulkarni, Carrie J. Cai,
    和 Michael Terry. 2023. 无需编程语言的编程：为提示编程设计开发者工具的挑战与机遇。在 *2023 CHI 计算系统人因会议扩展摘要*
    中. 1–7。
- en: 'Finnie-Ansley et al. (2022) James Finnie-Ansley, Paul Denny, Brett A. Becker,
    Andrew Luxton-Reilly, and James Prather. 2022. The robots are coming: Exploring
    the implications of openai codex on introductory programming. In *Proceedings
    of the 24th Australasian Computing Education Conference*. 10–19.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Finnie-Ansley et al. (2022) James Finnie-Ansley, Paul Denny, Brett A. Becker,
    Andrew Luxton-Reilly, 和 James Prather. 2022. 机器人来了：探索 OpenAI Codex 对初学者编程的影响。在
    *第24届澳大利亚计算教育会议录* 中. 10–19。
- en: Fleischmann and Wallace (2009) Kenneth R. Fleischmann and William A. Wallace.
    2009. Ensuring transparency in computational modeling. *Commun. ACM* 52, 3 (March
    2009), 131–134. [https://doi.org/10.1145/1467247.1467278](https://doi.org/10.1145/1467247.1467278)
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fleischmann and Wallace (2009) Kenneth R. Fleischmann 和 William A. Wallace.
    2009. 确保计算建模的透明性。*计算机与通信* 52, 3 (2009年3月), 131–134. [https://doi.org/10.1145/1467247.1467278](https://doi.org/10.1145/1467247.1467278)
- en: 'Fu et al. (2023) Yue Fu, Mingrui Zhang, Lynn K. Nguyen, Yifan Lin, Rebecca
    Michelson, Tala June Tayebi, and Alexis Hiniker. 2023. Self-Talk with Superhero
    Zip: Supporting Children’s Socioemotional Learning with Conversational Agents.
    In *Proceedings of the 22nd Annual ACM Interaction Design and Children Conference*.
    173–186.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fu et al. (2023) Yue Fu, Mingrui Zhang, Lynn K. Nguyen, Yifan Lin, Rebecca Michelson,
    Tala June Tayebi, 和 Alexis Hiniker. 2023. 与超级英雄 Zip 的自我对话：利用对话代理支持儿童的社会情感学习。在
    *第22届年度 ACM 互动设计与儿童会议录* 中. 173–186。
- en: Gero et al. (2020) Katy Ilonka Gero, Zahra Ashktorab, Casey Dugan, Qian Pan,
    James Johnson, Werner Geyer, Maria Ruiz, Sarah Miller, David R. Millen, Murray
    Campbell, Sadhana Kumaravel, and Wei Zhang. 2020. Mental Models of AI Agents in
    a Cooperative Game Setting. In *Proceedings of the 2020 CHI Conference on Human
    Factors in Computing Systems* *(CHI ’20)*. Association for Computing Machinery,
    New York, NY, USA, 1–12. [https://doi.org/10.1145/3313831.3376316](https://doi.org/10.1145/3313831.3376316)
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gero 等（2020）Katy Ilonka Gero、Zahra Ashktorab、Casey Dugan、Qian Pan、James Johnson、Werner
    Geyer、Maria Ruiz、Sarah Miller、David R. Millen、Murray Campbell、Sadhana Kumaravel
    和 Wei Zhang。2020。《合作游戏环境中对AI代理的心理模型》。载于 *2020年CHI计算机系统人因会议论文集* *(CHI ’20)*。计算机协会，美国纽约，1–12。
    [https://doi.org/10.1145/3313831.3376316](https://doi.org/10.1145/3313831.3376316)
- en: 'Gong et al. (2022) Zi Gong, Yinpeng Guo, Pingyi Zhou, Cuiyun Gao, Yasheng Wang,
    and Zenglin Xu. 2022. MultiCoder: Multi-Programming-Lingual Pre-Training for Low-Resource
    Code Completion. [https://doi.org/10.48550/arXiv.2212.09666](https://doi.org/10.48550/arXiv.2212.09666)
    arXiv:2212.09666 [cs].'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gong 等（2022）Zi Gong、Yinpeng Guo、Pingyi Zhou、Cuiyun Gao、Yasheng Wang 和 Zenglin
    Xu。2022。《MultiCoder：低资源代码补全的多编程语言预训练》。[https://doi.org/10.48550/arXiv.2212.09666](https://doi.org/10.48550/arXiv.2212.09666)
    arXiv:2212.09666 [cs]。
- en: 'Harel and Papert (1990) Idit Harel and Seymour Papert. 1990. Software design
    as a learning environment. *Interactive learning environments* 1, 1 (1990), 1–32.
    Publisher: Taylor & Francis.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Harel 和 Papert（1990）Idit Harel 和 Seymour Papert。1990。《将软件设计作为学习环境》。*互动学习环境*
    1, 1（1990），1–32。出版商：Taylor & Francis。
- en: Hendrycks et al. (2020) Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou,
    Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2020. Measuring Massive Multitask
    Language Understanding. [https://openreview.net/forum?id=d7KBjmI3GmQ](https://openreview.net/forum?id=d7KBjmI3GmQ)
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hendrycks 等（2020）Dan Hendrycks、Collin Burns、Steven Basart、Andy Zou、Mantas Mazeika、Dawn
    Song 和 Jacob Steinhardt。2020。《大规模多任务语言理解的测量》。[https://openreview.net/forum?id=d7KBjmI3GmQ](https://openreview.net/forum?id=d7KBjmI3GmQ)
- en: 'Hou et al. (2023) Xinyi Hou, Yanjie Zhao, Yue Liu, Zhou Yang, Kailong Wang,
    Li Li, Xiapu Luo, David Lo, John Grundy, and Haoyu Wang. 2023. Large Language
    Models for Software Engineering: A Systematic Literature Review. [http://arxiv.org/abs/2308.10620](http://arxiv.org/abs/2308.10620)
    arXiv:2308.10620 [cs].'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hou 等（2023）Xinyi Hou、Yanjie Zhao、Yue Liu、Zhou Yang、Kailong Wang、Li Li、Xiapu
    Luo、David Lo、John Grundy 和 Haoyu Wang。2023。《软件工程中的大型语言模型：系统文献综述》。[http://arxiv.org/abs/2308.10620](http://arxiv.org/abs/2308.10620)
    arXiv:2308.10620 [cs]。
- en: 'Hutchins et al. (2020) Nicole M. Hutchins, Gautam Biswas, Ningyu Zhang, Caitlin
    Snyder, Ákos Lédeczi, and Miklós Maróti. 2020. Domain-specific modeling languages
    in computer-based learning environments: A systematic approach to support science
    learning through computational modeling. *International Journal of Artificial
    Intelligence in Education* 30 (2020), 537–580. Publisher: Springer.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hutchins 等（2020）Nicole M. Hutchins、Gautam Biswas、Ningyu Zhang、Caitlin Snyder、Ákos
    Lédeczi 和 Miklós Maróti。2020。《计算机基础学习环境中的领域特定建模语言：通过计算建模支持科学学习的系统方法》。*国际人工智能教育期刊*
    30（2020），537–580。出版商：Springer。
- en: Jeong et al. (2019) Yuin Jeong, Juho Lee, and Younah Kang. 2019. Exploring Effects
    of Conversational Fillers on User Perception of Conversational Agents. In *Extended
    Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems* *(CHI
    EA ’19)*. Association for Computing Machinery, New York, NY, USA, 1–6. [https://doi.org/10.1145/3290607.3312913](https://doi.org/10.1145/3290607.3312913)
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jeong 等（2019）Yuin Jeong、Juho Lee 和 Younah Kang。2019。《探索对话填充物对用户对话代理感知的影响》。载于
    *2019年CHI计算机系统人因会议扩展摘要* *(CHI EA ’19)*。计算机协会，美国纽约，1–6。 [https://doi.org/10.1145/3290607.3312913](https://doi.org/10.1145/3290607.3312913)
- en: Jiang et al. (2022) Ellen Jiang, Edwin Toh, Alejandra Molina, Kristen Olson,
    Claire Kayacik, Aaron Donsbach, Carrie J. Cai, and Michael Terry. 2022. Discovering
    the syntax and strategies of natural language programming with generative language
    models. In *Proceedings of the 2022 CHI Conference on Human Factors in Computing
    Systems*. 1–19.
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang 等（2022）Ellen Jiang、Edwin Toh、Alejandra Molina、Kristen Olson、Claire Kayacik、Aaron
    Donsbach、Carrie J. Cai 和 Michael Terry。2022。《使用生成语言模型发现自然语言编程的语法和策略》。载于 *2022年CHI计算机系统人因会议论文集*。1–19。
- en: 'Joshi et al. (2023) Harshit Joshi, José Cambronero Sanchez, Sumit Gulwani,
    Vu Le, Gust Verbruggen, and Ivan Radiček. 2023. Repair Is Nearly Generation: Multilingual
    Program Repair with LLMs. *Proceedings of the AAAI Conference on Artificial Intelligence*
    37, 4 (June 2023), 5131–5140. [https://doi.org/10.1609/aaai.v37i4.25642](https://doi.org/10.1609/aaai.v37i4.25642)
    Number: 4.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Joshi 等 (2023) Harshit Joshi, José Cambronero Sanchez, Sumit Gulwani, Vu Le,
    Gust Verbruggen 和 Ivan Radiček. 2023. 修复几乎等于生成：使用大型语言模型的多语言程序修复。 *AAAI 人工智能会议论文集*
    37, 4 (2023年6月)，5131–5140。 [https://doi.org/10.1609/aaai.v37i4.25642](https://doi.org/10.1609/aaai.v37i4.25642)
    编号：4。
- en: 'Kafai et al. (2020) Yasmin Kafai, Gautam Biswas, Nicole Hutchins, Caitlin Snyder,
    Karen Brennan, Paulina Haduong, Kayla DesPortes, Morgan Fong, Virginia J. Flood,
    and Oia Walker-van Aalst. 2020. Turning bugs into learning opportunities: understanding
    debugging processes, perspectives, and pedagogies. (2020). Publisher: International
    Society of the Learning Sciences (ISLS).'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kafai 等 (2020) Yasmin Kafai, Gautam Biswas, Nicole Hutchins, Caitlin Snyder,
    Karen Brennan, Paulina Haduong, Kayla DesPortes, Morgan Fong, Virginia J. Flood
    和 Oia Walker-van Aalst. 2020. 将错误转化为学习机会：理解调试过程、视角和教学法。（2020）。出版商：国际学习科学学会 (ISLS)。
- en: 'Kafai and Burke (2015) Yasmin B. Kafai and Quinn Burke. 2015. Constructionist
    Gaming: Understanding the Benefits of Making Games for Learning. *Educational
    Psychologist* 50, 4 (Oct. 2015), 313–334. [https://doi.org/10.1080/00461520.2015.1124022](https://doi.org/10.1080/00461520.2015.1124022)
    Publisher: Routledge _eprint: https://doi.org/10.1080/00461520.2015.1124022.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kafai 和 Burke (2015) Yasmin B. Kafai 和 Quinn Burke. 2015. 建构主义游戏：理解制作游戏对学习的好处。
    *教育心理学家* 50, 4 (2015年10月)，313–334。 [https://doi.org/10.1080/00461520.2015.1124022](https://doi.org/10.1080/00461520.2015.1124022)
    出版商：Routledge _eprint: https://doi.org/10.1080/00461520.2015.1124022_。'
- en: 'Kahn and Winters (2021) Ken Kahn and Niall Winters. 2021. Constructionism and
    AI: A history and possible futures. *British Journal of Educational Technology*
    52, 3 (2021), 1130–1142. Publisher: Wiley Online Library.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kahn 和 Winters (2021) Ken Kahn 和 Niall Winters. 2021. 建构主义与 AI：历史与未来展望。 *英国教育技术期刊*
    52, 3 (2021)，1130–1142。出版商：Wiley Online Library。
- en: Kazemitabaar et al. (2023) Majeed Kazemitabaar, Justin Chow, Carl Ka To Ma,
    Barbara J. Ericson, David Weintrop, and Tovi Grossman. 2023. Studying the effect
    of AI Code Generators on Supporting Novice Learners in Introductory Programming.
    *arXiv preprint arXiv:2302.07427* (2023).
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kazemitabaar 等 (2023) Majeed Kazemitabaar, Justin Chow, Carl Ka To Ma, Barbara
    J. Ericson, David Weintrop 和 Tovi Grossman. 2023. 研究 AI 代码生成器对支持初学者在入门编程中的影响。
    *arXiv 预印本 arXiv:2302.07427* (2023)。
- en: Khan et al. (2011) Iftikhar Ahmed Khan, Willem-Paul Brinkman, and Robert M Hierons.
    2011. Do moods affect programmers’ debug performance? *Cognition, Technology &
    Work* 13 (2011), 245–258.
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khan 等 (2011) Iftikhar Ahmed Khan, Willem-Paul Brinkman 和 Robert M Hierons.
    2011. 情绪是否影响程序员的调试表现？ *认知、技术与工作* 13 (2011)，245–258。
- en: Khan and Uddin (2022) Junaed Younus Khan and Gias Uddin. 2022. Automatic code
    documentation generation using gpt-3\. In *Proceedings of the 37th IEEE/ACM International
    Conference on Automated Software Engineering*. 1–6.
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khan 和 Uddin (2022) Junaed Younus Khan 和 Gias Uddin. 2022. 使用 GPT-3 进行自动化代码文档生成。见
    *第37届IEEE/ACM国际自动化软件工程会议论文集*。1–6。
- en: 'Kumar et al. (2023) Varun Kumar, Leonard Gleyzer, Adar Kahana, Khemraj Shukla,
    and George Em Karniadakis. 2023. MyCrunchGPT: A chatGPT assisted framework for
    scientific machine learning. [https://doi.org/10.48550/arXiv.2306.15551](https://doi.org/10.48550/arXiv.2306.15551)
    arXiv:2306.15551 [physics].'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kumar 等 (2023) Varun Kumar, Leonard Gleyzer, Adar Kahana, Khemraj Shukla 和 George
    Em Karniadakis. 2023. MyCrunchGPT：一个 ChatGPT 辅助的科学机器学习框架。 [https://doi.org/10.48550/arXiv.2306.15551](https://doi.org/10.48550/arXiv.2306.15551)
    arXiv:2306.15551 [物理]。
- en: 'Lau and Guo (2023) Sam Lau and Philip J. Guo. 2023. From” Ban It Till We Understand
    It” to” Resistance is Futile”: How University Programming Instructors Plan to
    Adapt as More Students Use AI Code Generation and Explanation Tools such as ChatGPT
    and GitHub Copilot. (2023).'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lau 和 Guo (2023) Sam Lau 和 Philip J. Guo. 2023. 从“禁止它直到我们理解它”到“抵抗是徒劳的”：大学编程教师如何计划适应更多学生使用
    AI 代码生成和解释工具如 ChatGPT 和 GitHub Copilot。（2023）。
- en: 'Li et al. (2005) Yunyao Li, Huahai Yang, and Hosagrahar V. Jagadish. 2005.
    Nalix: an interactive natural language interface for querying xml. In *Proceedings
    of the 2005 ACM SIGMOD international conference on Management of data*. 900–902.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等 (2005) Yunyao Li, Huahai Yang 和 Hosagrahar V. Jagadish. 2005. Nalix：一个用于查询
    XML 的互动自然语言接口。见 *2005年ACM SIGMOD国际数据管理会议论文集*。900–902。
- en: 'Lin et al. (2020) Phoebe Lin, Jessica Van Brummelen, Galit Lukin, Randi Williams,
    and Cynthia Breazeal. 2020. Zhorai: Designing a Conversational Agent for Children
    to Explore Machine Learning Concepts. *Proceedings of the AAAI Conference on Artificial
    Intelligence* 34, 09 (April 2020), 13381–13388. [https://doi.org/10.1609/aaai.v34i09.7061](https://doi.org/10.1609/aaai.v34i09.7061)
    Number: 09.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin 等人（2020） Phoebe Lin、Jessica Van Brummelen、Galit Lukin、Randi Williams 和 Cynthia
    Breazeal。2020年。Zhorai：为儿童设计的对话代理，以探索机器学习概念。 *AAAI 人工智能会议论文集* 34, 09（2020年4月），13381–13388页。
    [https://doi.org/10.1609/aaai.v34i09.7061](https://doi.org/10.1609/aaai.v34i09.7061)
    编号：09。
- en: 'Ling et al. (2021) Erin Chao Ling, Iis Tussyadiah, Aarni Tuomi, Jason Stienmetz,
    and Athina Ioannou. 2021. Factors influencing users’ adoption and use of conversational
    agents: A systematic review. *Psychology & marketing* 38, 7 (2021), 1031–1051.
    Publisher: Wiley Online Library.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ling 等人（2021） Erin Chao Ling、Iis Tussyadiah、Aarni Tuomi、Jason Stienmetz 和 Athina
    Ioannou。2021年。影响用户采用和使用对话代理的因素：系统评价。 *心理学与市场营销* 38, 7（2021年），1031–1051页。出版商：Wiley
    在线图书馆。
- en: Liu et al. (2023) Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, and Lingming Zhang.
    2023. Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of
    Large Language Models for Code Generation. [https://doi.org/10.48550/arXiv.2305.01210](https://doi.org/10.48550/arXiv.2305.01210)
    arXiv:2305.01210 [cs].
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人（2023） Jiawei Liu、Chunqiu Steven Xia、Yuyao Wang 和 Lingming Zhang。2023年。你的代码是由
    ChatGPT 生成的，真的正确吗？对大型语言模型代码生成的严格评估。 [https://doi.org/10.48550/arXiv.2305.01210](https://doi.org/10.48550/arXiv.2305.01210)
    arXiv:2305.01210 [cs]。
- en: Lopez et al. (2008) Mike Lopez, Jacqueline Whalley, Phil Robbins, and Raymond
    Lister. 2008. Relationships between reading, tracing and writing skills in introductory
    programming. In *Proceedings of the fourth international workshop on computing
    education research*. 101–112.
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lopez 等人（2008） Mike Lopez、Jacqueline Whalley、Phil Robbins 和 Raymond Lister。2008年。入门编程中的阅读、追踪和编写技能之间的关系。在
    *第四届国际计算教育研究研讨会论文集* 中，101–112页。
- en: MacNeil et al. (2022) Stephen MacNeil, Andrew Tran, Dan Mogil, Seth Bernstein,
    Erin Ross, and Ziheng Huang. 2022. Generating diverse code explanations using
    the gpt-3 large language model. In *Proceedings of the 2022 ACM Conference on
    International Computing Education Research-Volume 2*. 37–39.
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MacNeil 等人（2022） Stephen MacNeil、Andrew Tran、Dan Mogil、Seth Bernstein、Erin Ross
    和 Ziheng Huang。2022年。使用 gpt-3 大型语言模型生成多样化的代码解释。在 *2022年ACM国际计算教育研究会议论文集-第2卷* 中，37–39页。
- en: 'Magueresse et al. (2020) Alexandre Magueresse, Vincent Carles, and Evan Heetderks.
    2020. Low-resource Languages: A Review of Past Work and Future Challenges. [http://arxiv.org/abs/2006.07264](http://arxiv.org/abs/2006.07264)
    arXiv:2006.07264 [cs].'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Magueresse 等人（2020） Alexandre Magueresse、Vincent Carles 和 Evan Heetderks。2020年。低资源语言：过去工作的回顾和未来挑战。
    [http://arxiv.org/abs/2006.07264](http://arxiv.org/abs/2006.07264) arXiv:2006.07264
    [cs]。
- en: 'Marwan et al. (2020) Samiha Marwan, Anay Dombe, and Thomas W Price. 2020. Unproductive
    help-seeking in programming: What it is and how to address it. In *Proceedings
    of the 2020 ACM Conference on Innovation and Technology in Computer Science Education*.
    54–60.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Marwan 等人（2020） Samiha Marwan、Anay Dombe 和 Thomas W Price。2020年。编程中的非生产性求助：它是什么以及如何解决它。在
    *2020年ACM计算机科学教育创新与技术会议论文集* 中，54–60页。
- en: McNutt et al. (2023) Andrew M. McNutt, Chenglong Wang, Robert A. Deline, and
    Steven M. Drucker. 2023. On the design of ai-powered code assistants for notebooks.
    In *Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems*.
    1–16.
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: McNutt 等人（2023） Andrew M. McNutt、Chenglong Wang、Robert A. Deline 和 Steven M.
    Drucker。2023年。关于为笔记本设计 AI 驱动的代码助手。在 *2023年CHI计算机系统人因会议论文集* 中，1–16页。
- en: 'Michaelis and Weintrop (2022) Joseph E. Michaelis and David Weintrop. 2022.
    Interest Development Theory in Computing Education: A Framework and Toolkit for
    Researchers and Designers. *ACM Transactions on Computing Education (TOCE)* (2022).
    Publisher: ACM New York, NY.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Michaelis 和 Weintrop（2022） Joseph E. Michaelis 和 David Weintrop。2022年。计算教育中的兴趣发展理论：研究人员和设计师的框架和工具包。
    *ACM 计算教育事务（TOCE）*（2022年）。出版商：ACM 纽约，纽约。
- en: Nam et al. (2023) Daye Nam, Andrew Macvean, Vincent Hellendoorn, Bogdan Vasilescu,
    and Brad Myers. 2023. In-IDE Generation-based Information Support with a Large
    Language Model. [https://doi.org/10.48550/arXiv.2307.08177](https://doi.org/10.48550/arXiv.2307.08177)
    arXiv:2307.08177 [cs].
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nam 等人（2023） Daye Nam、Andrew Macvean、Vincent Hellendoorn、Bogdan Vasilescu 和
    Brad Myers。2023年。在 IDE 中基于生成的与大型语言模型的信息支持。 [https://doi.org/10.48550/arXiv.2307.08177](https://doi.org/10.48550/arXiv.2307.08177)
    arXiv:2307.08177 [cs]。
- en: OpenAI (2023) OpenAI. 2023. GPT-4 Technical Report. [https://doi.org/10.48550/arXiv.2303.08774](https://doi.org/10.48550/arXiv.2303.08774)
    arXiv:2303.08774 [cs].
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI (2023) OpenAI. 2023. GPT-4 技术报告。 [https://doi.org/10.48550/arXiv.2303.08774](https://doi.org/10.48550/arXiv.2303.08774)
    arXiv:2303.08774 [cs]。
- en: 'Pal et al. (2023) Soumen Pal, Manojit Bhattacharya, Sang-Soo Lee, and Chiranjib
    Chakraborty. 2023. A Domain-Specific Next-Generation Large Language Model (LLM)
    or ChatGPT is Required for Biomedical Engineering and Research. *Annals of Biomedical
    Engineering* (2023), 1–4. Publisher: Springer.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pal et al. (2023) Soumen Pal, Manojit Bhattacharya, Sang-Soo Lee, 和 Chiranjib
    Chakraborty. 2023. 生物医学工程和研究需要一个领域特定的下一代大型语言模型（LLM）或 ChatGPT。*生物医学工程年鉴* (2023),
    1–4. 出版社：施普林格。
- en: 'Papert (1980) Seymour Papert. 1980. Mindstorms: Children, computers, and powerful
    ideas. (1980). Publisher: Basic Books.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Papert (1980) Seymour Papert. 1980. 思维风暴：儿童、计算机与强大的思想。 (1980). 出版社：基础书籍。
- en: Papert and Harel (1991) Seymour Papert and Idit Harel. 1991. Situating constructionism.
    *constructionism* 36, 2 (1991), 1–11.
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Papert and Harel (1991) Seymour Papert 和 Idit Harel. 1991. 情境建构主义。*建构主义* 36,
    2 (1991), 1–11。
- en: 'Peng et al. (2023) Sida Peng, Eirini Kalliamvakou, Peter Cihon, and Mert Demirer.
    2023. The Impact of AI on Developer Productivity: Evidence from GitHub Copilot.
    [https://doi.org/10.48550/arXiv.2302.06590](https://doi.org/10.48550/arXiv.2302.06590)
    arXiv:2302.06590 [cs].'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Peng et al. (2023) Sida Peng, Eirini Kalliamvakou, Peter Cihon, 和 Mert Demirer.
    2023. AI 对开发者生产力的影响：来自 GitHub Copilot 的证据。 [https://doi.org/10.48550/arXiv.2302.06590](https://doi.org/10.48550/arXiv.2302.06590)
    arXiv:2302.06590 [cs]。
- en: Perry et al. (2022) Neil Perry, Megha Srivastava, Deepak Kumar, and Dan Boneh.
    2022. Do Users Write More Insecure Code with AI Assistants? [https://doi.org/10.48550/arXiv.2211.03622](https://doi.org/10.48550/arXiv.2211.03622)
    arXiv:2211.03622 [cs].
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Perry et al. (2022) Neil Perry, Megha Srivastava, Deepak Kumar, 和 Dan Boneh.
    2022. 用户是否在 AI 助手的帮助下编写更多不安全的代码？ [https://doi.org/10.48550/arXiv.2211.03622](https://doi.org/10.48550/arXiv.2211.03622)
    arXiv:2211.03622 [cs]。
- en: 'Price et al. (2000) David Price, Ellen Rilofff, Joseph Zachary, and Brandon
    Harvey. 2000. NaturalJava: A natural language interface for programming in Java.
    In *Proceedings of the 5th international conference on Intelligent user interfaces*.
    207–211.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Price et al. (2000) David Price, Ellen Rilofff, Joseph Zachary, 和 Brandon Harvey.
    2000. NaturalJava：用于 Java 编程的自然语言接口。*第五届国际智能用户界面会议论文集*。207–211。
- en: 'Pylyshyn (1978) Zenon W. Pylyshyn. 1978. Computational models and empirical
    constraints. *Behavioral and Brain Sciences* 1, 1 (March 1978), 91–99. [https://doi.org/10.1017/S0140525X00059793](https://doi.org/10.1017/S0140525X00059793)
    Publisher: Cambridge University Press.'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pylyshyn (1978) Zenon W. Pylyshyn. 1978. 计算模型与经验约束。*行为与脑科学* 1, 1 (1978年3月),
    91–99. [https://doi.org/10.1017/S0140525X00059793](https://doi.org/10.1017/S0140525X00059793)
    出版社：剑桥大学出版社。
- en: Resnick and Silverman (2005) Mitchel Resnick and Brian Silverman. 2005. Some
    reflections on designing construction kits for kids. In *Proceedings of the 2005
    conference on Interaction design and children*. 117–122.
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Resnick and Silverman (2005) Mitchel Resnick 和 Brian Silverman. 2005. 设计儿童建构工具的一些反思。*2005年互动设计与儿童会议论文集*。117–122。
- en: Robe and Kuttal (2022) Peter Robe and Sandeep Kaur Kuttal. 2022. Designing PairBuddy—A
    Conversational Agent for Pair Programming. *ACM Transactions on Computer-Human
    Interaction* 29, 4 (May 2022), 34:1–34:44. [https://doi.org/10.1145/3498326](https://doi.org/10.1145/3498326)
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Robe and Kuttal (2022) Peter Robe 和 Sandeep Kaur Kuttal. 2022. 设计 PairBuddy——一款用于配对编程的对话代理。*ACM
    计算机-人类互动学报* 29, 4 (2022年5月), 34:1–34:44. [https://doi.org/10.1145/3498326](https://doi.org/10.1145/3498326)
- en: 'Ross et al. (2023) Steven I. Ross, Fernando Martinez, Stephanie Houde, Michael
    Muller, and Justin D. Weisz. 2023. The programmer’s assistant: Conversational
    interaction with a large language model for software development. In *Proceedings
    of the 28th International Conference on Intelligent User Interfaces*. 491–514.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ross et al. (2023) Steven I. Ross, Fernando Martinez, Stephanie Houde, Michael
    Muller, 和 Justin D. Weisz. 2023. 程序员助手：与大型语言模型进行的软件开发对话互动。*第28届国际智能用户界面会议论文集*。491–514。
- en: 'Sannon et al. (2020) Shruti Sannon, Brett Stoll, Dominic DiFranzo, Malte F.
    Jung, and Natalya N. Bazarova. 2020. “I just shared your responses”: Extending
    Communication Privacy Management Theory to Interactions with Conversational Agents.
    *Proceedings of the ACM on Human-Computer Interaction* 4, GROUP (Jan. 2020), 08:1–08:18.
    [https://doi.org/10.1145/3375188](https://doi.org/10.1145/3375188)'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sannon et al. (2020) Shruti Sannon, Brett Stoll, Dominic DiFranzo, Malte F.
    Jung, 和 Natalya N. Bazarova. 2020. “我刚刚分享了你的回复”：将沟通隐私管理理论扩展到与对话代理的互动中。*ACM 人机交互会议论文集*
    4, GROUP (2020年1月), 08:1–08:18. [https://doi.org/10.1145/3375188](https://doi.org/10.1145/3375188)
- en: Savelka et al. (2023) Jaromir Savelka, Arav Agarwal, Marshall An, Chris Bogart,
    and Majd Sakr. 2023. Thrilled by Your Progress! Large Language Models (GPT-4)
    No Longer Struggle to Pass Assessments in Higher Education Programming Courses.
    In *Proceedings of the 2023 ACM Conference on International Computing Education
    Research V.1*. 78–92. [https://doi.org/10.1145/3568813.3600142](https://doi.org/10.1145/3568813.3600142)
    arXiv:2306.10073 [cs].
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Savelka 等 (2023) Jaromir Savelka, Arav Agarwal, Marshall An, Chris Bogart, 和
    Majd Sakr. 2023. 为你的进展感到兴奋！大型语言模型（GPT-4）不再难以通过高等教育编程课程的评估。见 *2023 ACM 国际计算教育研究会议论文集
    V.1*。78–92。 [https://doi.org/10.1145/3568813.3600142](https://doi.org/10.1145/3568813.3600142)
    arXiv:2306.10073 [cs]。
- en: Sengupta et al. (2015) Pratim Sengupta, Amanda Dickes, Amy Voss Farris, Ashlyn
    Karan, David Martin, and Mason Wright. 2015. Programming in K-12 science classrooms.
    *Commun. ACM* 58, 11 (Oct. 2015), 33–35. [https://doi.org/10.1145/2822517](https://doi.org/10.1145/2822517)
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sengupta 等 (2015) Pratim Sengupta, Amanda Dickes, Amy Voss Farris, Ashlyn Karan,
    David Martin, 和 Mason Wright. 2015. K-12 科学课堂中的编程。*Commun. ACM* 58, 11 (2015年10月),
    33–35。 [https://doi.org/10.1145/2822517](https://doi.org/10.1145/2822517)
- en: 'Sengupta et al. (2013) Pratim Sengupta, John S. Kinnebrew, Satabdi Basu, Gautam
    Biswas, and Douglas Clark. 2013. Integrating computational thinking with K-12
    science education using agent-based computation: A theoretical framework. *Education
    and Information Technologies* 18, 2 (June 2013), 351–380. [https://doi.org/10.1007/s10639-012-9240-x](https://doi.org/10.1007/s10639-012-9240-x)'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sengupta 等 (2013) Pratim Sengupta, John S. Kinnebrew, Satabdi Basu, Gautam Biswas,
    和 Douglas Clark. 2013. 将计算思维与 K-12 科学教育整合：一个理论框架。*教育与信息技术* 18, 2 (2013年6月), 351–380。
    [https://doi.org/10.1007/s10639-012-9240-x](https://doi.org/10.1007/s10639-012-9240-x)
- en: 'Setlur et al. (2016) Vidya Setlur, Sarah E. Battersby, Melanie Tory, Rich Gossweiler,
    and Angel X. Chang. 2016. Eviza: A natural language interface for visual analysis.
    In *Proceedings of the 29th annual symposium on user interface software and technology*.
    365–377.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Setlur 等 (2016) Vidya Setlur, Sarah E. Battersby, Melanie Tory, Rich Gossweiler,
    和 Angel X. Chang. 2016. Eviza: 一种用于视觉分析的自然语言接口。见 *第29届年度用户界面软件与技术研讨会论文集*。365–377。'
- en: 'Skjuve et al. (2023) Marita Skjuve, Asbjørn Følstad, and Petter Bae Brandtzaeg.
    2023. The User Experience of ChatGPT: Findings from a Questionnaire Study of Early
    Users. In *Proceedings of the 5th International Conference on Conversational User
    Interfaces*. 1–10.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Skjuve 等 (2023) Marita Skjuve, Asbjørn Følstad, 和 Petter Bae Brandtzaeg. 2023.
    ChatGPT 的用户体验：来自早期用户问卷研究的发现。见 *第五届国际对话用户界面会议论文集*。1–10。
- en: 'Solomon et al. (2020) Cynthia Solomon, Brian Harvey, Ken Kahn, Henry Lieberman,
    Mark L. Miller, Margaret Minsky, Artemis Papert, and Brian Silverman. 2020. History
    of logo. *Proceedings of the ACM on Programming Languages* 4, HOPL (2020), 1–66.
    Publisher: ACM New York, NY, USA.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Solomon 等 (2020) Cynthia Solomon, Brian Harvey, Ken Kahn, Henry Lieberman, Mark
    L. Miller, Margaret Minsky, Artemis Papert, 和 Brian Silverman. 2020. Logo 的历史。*ACM
    编程语言学报* 4, HOPL (2020), 1–66。出版商：ACM 纽约，NY，美国。
- en: Sorva et al. (2013) Juha Sorva, Ville Karavirta, and Lauri Malmi. 2013. A review
    of generic program visualization systems for introductory programming education.
    *ACM Transactions on Computing Education (TOCE)* 13, 4 (2013), 1–64.
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sorva 等 (2013) Juha Sorva, Ville Karavirta, 和 Lauri Malmi. 2013. 针对入门编程教育的通用程序可视化系统综述。*ACM
    计算教育事务 (TOCE)* 13, 4 (2013), 1–64。
- en: Sun (2008) Ron Sun. 2008. Introduction to computational cognitive modeling.
    *Cambridge handbook of computational psychology* (2008), 3–19.
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun (2008) Ron Sun. 2008. 计算认知建模简介。*剑桥计算心理学手册* (2008), 3–19。
- en: 'Tan et al. (2023) Chee Wei Tan, Shangxin Guo, Man Fai Wong, and Ching Nam Hang.
    2023. Copilot for Xcode: Exploring AI-Assisted Programming by Prompting Cloud-based
    Large Language Models. [http://arxiv.org/abs/2307.14349](http://arxiv.org/abs/2307.14349)
    arXiv:2307.14349 [cs].'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tan 等 (2023) Chee Wei Tan, Shangxin Guo, Man Fai Wong, 和 Ching Nam Hang. 2023.
    Copilot for Xcode: 探索通过提示基于云的大型语言模型的 AI 辅助编程。 [http://arxiv.org/abs/2307.14349](http://arxiv.org/abs/2307.14349)
    arXiv:2307.14349 [cs]。'
- en: Tarassow (2023) Artur Tarassow. 2023. The potential of LLMs for coding with
    low-resource and domain-specific programming languages. [http://arxiv.org/abs/2307.13018](http://arxiv.org/abs/2307.13018)
    arXiv:2307.13018 [cs].
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tarassow (2023) Artur Tarassow. 2023. 低资源和领域特定编程语言的 LLMs 潜力。 [http://arxiv.org/abs/2307.13018](http://arxiv.org/abs/2307.13018)
    arXiv:2307.13018 [cs]。
- en: 'Thiele et al. (2011) J. C. Thiele, W. Kurth, and V. Grimm. 2011. Agent-and
    individual-based modeling with NetLogo: Introduction and new NetLogo extensions.
    *Deutscher Verband Forstlicher Forschungsanstalten, Sektion Forstliche Biometrie
    und Informatik-22\. Tagung* (2011).'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Thiele 等人（2011）J. C. Thiele、W. Kurth 和 V. Grimm。2011年。《使用 NetLogo 的代理和个体建模：介绍及新的
    NetLogo 扩展》。*德国林业研究机构协会，森林生物统计学与信息学分会第22届会议*（2011年）。
- en: Tian et al. (2023) Haoye Tian, Weiqi Lu, Tsz On Li, Xunzhu Tang, Shing-Chi Cheung,
    Jacques Klein, and Tegawendé F. Bissyandé. 2023. Is ChatGPT the Ultimate Programming
    Assistant–How far is it? *arXiv preprint arXiv:2304.11938* (2023).
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tian 等人（2023）Haoye Tian、Weiqi Lu、Tsz On Li、Xunzhu Tang、Shing-Chi Cheung、Jacques
    Klein 和 Tegawendé F. Bissyandé。2023年。《ChatGPT 是终极编程助手吗——它距离目标还有多远？》*arXiv 预印本
    arXiv:2304.11938*（2023年）。
- en: 'Tisue and Wilensky (2004) Seth Tisue and Uri Wilensky. 2004. Netlogo: A simple
    environment for modeling complexity. In *International conference on complex systems*,
    Vol. 21\. Citeseer, 16–21.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tisue 和 Wilensky（2004）Seth Tisue 和 Uri Wilensky。2004年。《NetLogo：用于建模复杂性的简单环境》。收录于
    *复杂系统国际会议*，第21卷，Citeseer，16–21页。
- en: 'Turkle and Papert (1990) Sherry Turkle and Seymour Papert. 1990. Epistemological
    pluralism: Styles and voices within the computer culture. *Signs: Journal of women
    in culture and society* 16, 1 (1990), 128–157. Publisher: University of Chicago
    Press.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Turkle 和 Papert（1990）Sherry Turkle 和 Seymour Papert。1990年。《认识论的多元性：计算机文化中的风格与声音》。*Signs:
    Journal of Women in Culture and Society* 16, 1（1990年），128–157页。出版商：芝加哥大学出版社。'
- en: 'Vaithilingam et al. (2022) Priyan Vaithilingam, Tianyi Zhang, and Elena L.
    Glassman. 2022. Expectation vs. experience: Evaluating the usability of code generation
    tools powered by large language models. In *Chi conference on human factors in
    computing systems extended abstracts*. 1–7.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vaithilingam 等人（2022）Priyan Vaithilingam、Tianyi Zhang 和 Elena L. Glassman。2022年。《期望与体验：评估由大型语言模型驱动的代码生成工具的可用性》。收录于
    *CHI计算机系统人因会议扩展摘要*，1–7页。
- en: 'Wambsganss et al. (2021) Thiemo Wambsganss, Tobias Kueng, Matthias Soellner,
    and Jan Marco Leimeister. 2021. ArgueTutor: An adaptive dialog-based learning
    system for argumentation skills. In *Proceedings of the 2021 CHI conference on
    human factors in computing systems*. 1–13.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wambsganss 等人（2021）Thiemo Wambsganss、Tobias Kueng、Matthias Soellner 和 Jan Marco
    Leimeister。2021年。《ArgueTutor: 一种基于对话的自适应学习系统用于论证技巧》。收录于 *2021年CHI计算机系统人因会议论文集*，1–13页。'
- en: Wang et al. (2023) Bailin Wang, Zi Wang, Xuezhi Wang, Yuan Cao, Rif A. Saurous,
    and Yoon Kim. 2023. Grammar Prompting for Domain-Specific Language Generation
    with Large Language Models. [http://arxiv.org/abs/2305.19234](http://arxiv.org/abs/2305.19234)
    arXiv:2305.19234 [cs].
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2023）Bailin Wang、Zi Wang、Xuezhi Wang、Yuan Cao、Rif A. Saurous 和 Yoon
    Kim。2023年。《针对特定领域语言生成的语法提示与大语言模型》。[http://arxiv.org/abs/2305.19234](http://arxiv.org/abs/2305.19234)
    arXiv:2305.19234 [cs]。
- en: 'Wang et al. (2021) Qiaosi Wang, Koustuv Saha, Eric Gregori, David Joyner, and
    Ashok Goel. 2021. Towards mutual theory of mind in human-ai interaction: How language
    reflects what students perceive about a virtual teaching assistant. In *Proceedings
    of the 2021 CHI conference on human factors in computing systems*. 1–14.'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2021）Qiaosi Wang、Koustuv Saha、Eric Gregori、David Joyner 和 Ashok Goel。2021年。《在人类与
    AI 互动中趋向共同的心智理论：语言如何反映学生对虚拟教学助理的感知》。收录于 *2021年CHI计算机系统人因会议论文集*，1–14页。
- en: Weintrop et al. (2016) David Weintrop, Elham Beheshti, Michael Horn, Kai Orton,
    Kemi Jona, Laura Trouille, and Uri Wilensky. 2016. Defining Computational Thinking
    for Mathematics and Science Classrooms. *Journal of Science Education and Technology*
    25, 1 (Feb. 2016), 127–147. [https://doi.org/10.1007/s10956-015-9581-5](https://doi.org/10.1007/s10956-015-9581-5)
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Weintrop 等人（2016）David Weintrop、Elham Beheshti、Michael Horn、Kai Orton、Kemi Jona、Laura
    Trouille 和 Uri Wilensky。2016年。《为数学和科学课堂定义计算思维》。*科学教育与技术杂志* 25, 1（2016年2月），127–147页。
    [https://doi.org/10.1007/s10956-015-9581-5](https://doi.org/10.1007/s10956-015-9581-5)
- en: 'Wellner and Levin (2023) Galit Wellner and Ilya Levin. 2023. Ihde meets Papert:
    combining postphenomenology and constructionism for a future agenda of philosophy
    of education in the era of digital technologies. *Learning, Media and Technology*
    (2023), 1–14. Publisher: Taylor & Francis.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wellner 和 Levin（2023）Galit Wellner 和 Ilya Levin。2023年。《Ihde 遇见 Papert：将后现象学与建构主义结合，为数字技术时代的教育哲学未来制定议程》。*学习、媒体与技术*（2023年），1–14页。出版商：Taylor
    & Francis。
- en: Wermelinger (2023) Michel Wermelinger. 2023. Using GitHub Copilot to solve simple
    programming problems. In *Proceedings of the 54th ACM Technical Symposium on Computer
    Science Education V. 1*. 172–178.
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wermelinger（2023）Michel Wermelinger。2023年。《使用 GitHub Copilot 解决简单编程问题》。收录于 *第54届ACM计算机科学教育技术研讨会
    V. 1*，172–178页。
- en: Whalley et al. (2021a) Jacqueline Whalley, Amber Settle, and Andrew Luxton-Reilly.
    2021a. Novice reflections on debugging. In *Proceedings of the 52nd ACM technical
    symposium on computer science education*. 73–79.
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Whalley 等（2021a）Jacqueline Whalley、Amber Settle 和 Andrew Luxton-Reilly。2021a。新手对调试的反思。在
    *第52届 ACM 计算机科学教育技术研讨会* 中，73–79。
- en: Whalley et al. (2021b) Jacqueline Whalley, Amber Settle, and Andrew Luxton-Reilly.
    2021b. Novice Reflections on Debugging. In *Proceedings of the 52nd ACM Technical
    Symposium on Computer Science Education* *(SIGCSE ’21)*. Association for Computing
    Machinery, New York, NY, USA, 73–79. [https://doi.org/10.1145/3408877.3432374](https://doi.org/10.1145/3408877.3432374)
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Whalley 等（2021b）Jacqueline Whalley、Amber Settle 和 Andrew Luxton-Reilly。2021b。新手对调试的反思。在
    *第52届 ACM 计算机科学教育技术研讨会* *(SIGCSE ’21)* 中。计算机协会，纽约，美国，73–79。 [https://doi.org/10.1145/3408877.3432374](https://doi.org/10.1145/3408877.3432374)
- en: 'Wilensky and Rand (2015) Uri Wilensky and William Rand. 2015. *An introduction
    to agent-based modeling: modeling natural, social, and engineered complex systems
    with NetLogo*. Mit Press.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wilensky 和 Rand（2015）Uri Wilensky 和 William Rand。2015。*基于代理建模简介：利用 NetLogo 模拟自然、社会和工程复杂系统*。MIT
    Press。
- en: Wilensky (1997) Uri J. Wilensky. 1997. NetLogo Wolf Sheep Predation model. [http://ccl.northwestern.edu/netlogo/models/WolfSheepPredation](http://ccl.northwestern.edu/netlogo/models/WolfSheepPredation)
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wilensky（1997）Uri J. Wilensky。1997。NetLogo 狼羊捕食模型。 [http://ccl.northwestern.edu/netlogo/models/WolfSheepPredation](http://ccl.northwestern.edu/netlogo/models/WolfSheepPredation)
- en: 'Winkler et al. (2020) Rainer Winkler, Sebastian Hobert, Antti Salovaara, Matthias
    Söllner, and Jan Marco Leimeister. 2020. Sara, the lecturer: Improving learning
    in online education with a scaffolding-based conversational agent. In *Proceedings
    of the 2020 CHI conference on human factors in computing systems*. 1–14.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Winkler 等（2020）Rainer Winkler、Sebastian Hobert、Antti Salovaara、Matthias Söllner
    和 Jan Marco Leimeister。2020。Sara, the lecturer: 利用基于支架的对话代理改进在线教育中的学习。在 *2020
    CHI 人机交互系统会议论文集* 中，1–14。'
- en: 'Winkler and Söllner (2018) Rainer Winkler and Matthias Söllner. 2018. Unleashing
    the potential of chatbots in education: A state-of-the-art analysis. In *Academy
    of Management Proceedings*, Vol. 2018\. Academy of Management Briarcliff Manor,
    NY 10510, 15903. Issue: 1.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Winkler 和 Söllner（2018）Rainer Winkler 和 Matthias Söllner。2018。释放聊天机器人在教育中的潜力：前沿分析。在
    *管理学会会议论文集*，第 2018 卷。管理学会 Briarcliff Manor, NY 10510，15903。期刊：1。
- en: 'Wu et al. (2023) Xingbo Wu, Nathanaël Cheriere, Cheng Zhang, and Dushyanth
    Narayanan. 2023. RustGen: An Augmentation Approach for Generating Compilable Rust
    Code with Large Language Models. (June 2023). [https://openreview.net/forum?id=y9A0vJ5vuM](https://openreview.net/forum?id=y9A0vJ5vuM)'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wu 等（2023）Xingbo Wu、Nathanaël Cheriere、Cheng Zhang 和 Dushyanth Narayanan。2023。RustGen:
    一种利用大型语言模型生成可编译 Rust 代码的增强方法。（2023年6月）。[https://openreview.net/forum?id=y9A0vJ5vuM](https://openreview.net/forum?id=y9A0vJ5vuM)'
- en: 'Yang and Aurisicchio (2021) Xi Yang and Marco Aurisicchio. 2021. Designing
    conversational agents: A self-determination theory approach. In *Proceedings of
    the 2021 CHI Conference on Human Factors in Computing Systems*. 1–16.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 和 Aurisicchio（2021）Xi Yang 和 Marco Aurisicchio。2021。设计对话代理：自我决定理论的方法。在
    *2021 CHI 人机交互系统会议论文集* 中，1–16。
- en: 'Yao et al. (2022) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik R. Narasimhan, and Yuan Cao. 2022. ReAct: Synergizing Reasoning and Acting
    in Language Models. In *The Eleventh International Conference on Learning Representations*.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yao 等（2022）Shunyu Yao、Jeffrey Zhao、Dian Yu、Nan Du、Izhak Shafran、Karthik R.
    Narasimhan 和 Yuan Cao。2022。ReAct: 在语言模型中协同推理和行动。在 *第十一届国际学习表征会议* 中。'
- en: 'Yilmaz and Yilmaz (2023) Ramazan Yilmaz and Fatma Gizem Karaoglan Yilmaz. 2023.
    Augmented intelligence in programming learning: Examining student views on the
    use of ChatGPT for programming learning. *Computers in Human Behavior: Artificial
    Humans* 1, 2 (2023), 100005. Publisher: Elsevier.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yilmaz 和 Yilmaz（2023）Ramazan Yilmaz 和 Fatma Gizem Karaoglan Yilmaz。2023。编程学习中的增强智能：考察学生对
    ChatGPT 在编程学习中应用的看法。*人类行为中的计算机：人工智能* 1, 2（2023），100005。出版社：Elsevier。
- en: 'Zamfirescu-Pereira et al. (2023) J. D. Zamfirescu-Pereira, Richmond Y. Wong,
    Bjoern Hartmann, and Qian Yang. 2023. Why Johnny can’t prompt: how non-AI experts
    try (and fail) to design LLM prompts. In *Proceedings of the 2023 CHI Conference
    on Human Factors in Computing Systems*. 1–21.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zamfirescu-Pereira 等（2023）J. D. Zamfirescu-Pereira、Richmond Y. Wong、Bjoern Hartmann
    和 Qian Yang。2023。为什么 Johnny 无法提示：非人工智能专家如何（以及为何失败地）设计 LLM 提示。在 *2023 CHI 人机交互系统会议论文集*
    中，1–21。
- en: 'Zastudil et al. (2023) Cynthia Zastudil, Magdalena Rogalska, Christine Kapp,
    Jennifer Vaughn, and Stephen MacNeil. 2023. Generative AI in Computing Education:
    Perspectives of Students and Instructors. *arXiv preprint arXiv:2308.04309* (2023).'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zastudil 等人（2023）Cynthia Zastudil、Magdalena Rogalska、Christine Kapp、Jennifer
    Vaughn 和 Stephen MacNeil。2023年。生成式 AI 在计算机教育中的应用：学生和教师的观点。*arXiv 预印本 arXiv:2308.04309*（2023）。
