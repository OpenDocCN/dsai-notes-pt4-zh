- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 18:39:36'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-09-08 18:39:36'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation
    without Instructions'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 感知、反思与规划：设计用于无指令目标导向城市导航的LLM代理
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2408.04168](https://ar5iv.labs.arxiv.org/html/2408.04168)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2408.04168](https://ar5iv.labs.arxiv.org/html/2408.04168)
- en: Qingbin Zeng
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Qingbin Zeng
- en: Department of Electronic Engineering
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 电子工程系
- en: Tsinghua University
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 清华大学
- en: Beijing, China
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 北京，中国
- en: qingbinzeng06@gmail.com
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: qingbinzeng06@gmail.com
- en: Qinglong Yang
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Qinglong Yang
- en: Department of Electronic Engineering
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 电子工程系
- en: Tsinghua University
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 清华大学
- en: Beijing, China
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 北京，中国
- en: yangql20@mails.tsinghua.edu.cn
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: yangql20@mails.tsinghua.edu.cn
- en: Shunan Dong
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Shunan Dong
- en: Department of Electronic Engineering
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 电子工程系
- en: Tsinghua University
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 清华大学
- en: Beijing, China
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 北京，中国
- en: dsn@mails.tsinghua.edu.cn
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: dsn@mails.tsinghua.edu.cn
- en: Heming Du
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Heming Du
- en: School of Computing
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机学院
- en: Australian National University
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 澳大利亚国立大学
- en: Australia
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 澳大利亚
- en: heming.du@anu.edu.au
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: heming.du@anu.edu.au
- en: Liang Zhang
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Liang Zhang
- en: School of Computing
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机学院
- en: Australian National University
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 澳大利亚国立大学
- en: Australia
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 澳大利亚
- en: liang.zheng@anu.edu.au
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: liang.zheng@anu.edu.au
- en: Fengli Xu
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Fengli Xu
- en: Department of Electronic Engineering
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 电子工程系
- en: Tsinghua University
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 清华大学
- en: Beijing, China
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 北京，中国
- en: fenglixu@tsinghua.edu.cn
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: fenglixu@tsinghua.edu.cn
- en: Yong Li
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Yong Li
- en: Department of Electronic Engineering
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 电子工程系
- en: Tsinghua University
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 清华大学
- en: Beijing, China
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 北京，中国
- en: yongli07@tsinghua.edu.cn *Corresponding author
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: yongli07@tsinghua.edu.cn *通讯作者*
- en: Abstract
  id: totrans-41
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'This paper considers a scenario in city navigation: an AI agent is provided
    with language descriptions of the goal location with respect to some well-known
    landmarks; By only observing the scene around, including recognizing landmarks
    and road network connections, the agent has to make decisions to navigate to the
    goal location without instructions. This problem is very challenging, because
    it requires agent to establish self-position and acquire spatial representation
    of complex urban environment, where landmarks are often invisible. In the absence
    of navigation instructions, such abilities are vital for the agent to make high-quality
    decisions in long-range city navigation. With the emergent reasoning ability of
    large language models (LLMs), a tempting baseline is to prompt LLMs to “react”
    on each observation and make decisions accordingly. However, this baseline has
    very poor performance that the agent often repeatedly visits same locations and
    make short-sighted, inconsistent decisions. To address these issues, this paper
    introduces a novel agentic workflow featured by its abilities to perceive, reflect
    and plan. Specifically, we find LLaVA-7B can be fine-tuned to perceive the direction
    and distance of landmarks with sufficient accuracy for city navigation. Moreover,
    reflection is achieved through a memory mechanism, where past experiences are
    stored and can be retrieved with current perception for effective decision argumentation.
    Planning uses reflection results to produce long-term plans, which can avoid short-sighted
    decisions in long-range navigation. We show the designed workflow significantly
    improves navigation ability of the LLM agent compared with the state-of-the-art
    baselines. Our code and datasets are available: [https://anonymous.4open.science/r/PReP-13B5](https://anonymous.4open.science/r/PReP-13B5)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 本文考虑了城市导航中的一个场景：一个AI代理根据一些著名地标的语言描述来定位目标地点；仅通过观察周围环境，包括识别地标和道路网络连接，代理需要在没有指令的情况下做出导航决策。这个问题非常具有挑战性，因为它要求代理建立自我位置并获取复杂城市环境的空间表征，而地标往往是不可见的。在没有导航指令的情况下，这些能力对于代理在长距离城市导航中做出高质量决策至关重要。利用大型语言模型（LLMs）的新兴推理能力，一个诱人的基准是提示LLMs对每次观察“反应”并据此做出决策。然而，这个基准的表现非常差，代理经常重复访问相同的位置，做出短视且不一致的决策。为了解决这些问题，本文引入了一种新颖的代理工作流程，其特点是具备感知、反思和规划的能力。具体而言，我们发现LLaVA-7B可以经过微调，以足够的准确性感知地标的方向和距离，从而实现城市导航。此外，反思是通过记忆机制实现的，过去的经验被存储并可以通过当前的感知进行检索，以便有效地论证决策。规划利用反思结果生成长期计划，这可以避免在长距离导航中的短视决策。我们展示了设计的工作流程显著提升了LLM代理的导航能力，相较于最先进的基准方法。我们的代码和数据集可用：[https://anonymous.4open.science/r/PReP-13B5](https://anonymous.4open.science/r/PReP-13B5)
- en: 1 Introduction
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Navigation in complex and unknown urban environment is an important task for
    artificial intelligent agents. This paper studies goal-directed agent navigation
    in the city, where an agent is provided with visual perception and goal location
    described by the relation to some well-known landmarks, *e.g.*, “the destination
    is approximately 300 meters northeast from the Skyscraper A”. The agent should
    visually identify the landmarks from street view images, use them as anchors to
    infer the direction of and distance from the goal, and take a series of actions
    to navigate to the goal without instructions. The task is challenging because
    it requires the agent to be aware of its own location and acquire spatial understanding
    of complex urban environment, where landmarks are sometimes invisible. In the
    absence of navigation instructions and maps, such abilities are vital for the
    agent to make high-quality decisions in long-range navigation.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在复杂且未知的城市环境中进行导航是人工智能代理的一个重要任务。本文研究了城市中的目标导向代理导航，其中代理通过视觉感知和由某些著名地标描述的目标位置进行导航，例如，“目的地大约在摩天大楼A的东北方向300米”。代理应从街景图像中视觉识别地标，将其作为锚点来推断目标的方向和距离，并采取一系列行动在没有指令的情况下导航到目标。该任务具有挑战性，因为它要求代理了解自身的位置并获取复杂城市环境的空间理解，其中地标有时是不可见的。在没有导航指令和地图的情况下，这些能力对代理在长距离导航中做出高质量决策至关重要。
- en: Existing literature does not provide a ready-to-use solution to this task. A
    few recent works [[1](#bib.bib1)] [[2](#bib.bib2)] assume the availability of
    step-by-step language instructions and thus are not applicable to our task. Another
    branch of literature focus on designing reinforcement learning models [[3](#bib.bib3)] [[4](#bib.bib4)]
    [[5](#bib.bib5)], which often facing challenge of inefficient data and sensitivity
    to perturbations of the environment.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现有文献没有提供现成的解决方案。一些近期的工作 [[1](#bib.bib1)] [[2](#bib.bib2)] 假设有逐步语言指令，因此不适用于我们的任务。另一类文献专注于设计强化学习模型
    [[3](#bib.bib3)] [[4](#bib.bib4)] [[5](#bib.bib5)]，这些模型通常面临数据效率低和对环境干扰敏感的问题。
- en: 'We explore the use of large language models (LLMs) for this task. React [[6](#bib.bib6)]
    is a straightforward baseline to ground reasoning ability of LLMs in city environment.
    At each step, this method visually perceives the street views which is used to
    make an action decision. This process is iteratively performed until reaching
    the goal or running out of the navigation budget. While React has some success
    attempts in indoor environments, it performs poorly in complex urban environments,
    which can be attributed to two main reasons. First, because each action decision
    is based only on the current observation, the agent may repeat actions previously
    taken and find itself going around in circles. See Fig. [1](#S1.F1.fig1 "Figure
    1 ‣ 1 Introduction ‣ Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed
    City Navigation without Instructions") for an example. Second, React is short-sighted,
    focusing only on the immediate step. Without considering long-term action sequences,
    the agent would be prone to taking more actions than actually needed.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们探索了大型语言模型（LLMs）在这一任务中的应用。React [[6](#bib.bib6)] 是一种简单的基准方法，用于在城市环境中测试LLMs的推理能力。每一步，该方法通过视觉感知街景来做出行动决策。这个过程会迭代执行，直到达到目标或用尽导航预算。虽然React在室内环境中有一些成功的尝试，但在复杂的城市环境中表现不佳，这可以归因于两个主要原因。首先，由于每个行动决策仅基于当前观察，代理可能会重复之前采取的行动，发现自己在绕圈。见图
    [1](#S1.F1.fig1 "图 1 ‣ 1 介绍 ‣ 感知、反思和计划：设计用于无指令目标导向城市导航的LLM代理")。第二，React短视，仅关注当前步骤。如果不考虑长期行动序列，代理可能会采取比实际需要更多的行动。
- en: '![Refer to caption](img/9fcee39ca7ffe1b67d28109210d3e5c2.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/9fcee39ca7ffe1b67d28109210d3e5c2.png)'
- en: 'Figure 1: An illustrative comparison of city navigation results. The proposed
    workflow method (blue) successfully reaches the goal, and its path is similar
    to the shortest path (yellow). The React method (black, without workflow) keep
    going around in circles and fails to reach the goal.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：城市导航结果的示例对比。提出的工作流方法（蓝色）成功到达目标，其路径与最短路径（黄色）相似。React 方法（黑色，未使用工作流）一直在绕圈，未能到达目标。
- en: This paper proposes an effective agentic workflow that improves the goal-directed
    city navigation ability of LLMs. To avoid isolated decision making, we propose
    a memory scheme. The historical trajectories and observations are stored and summarized
    to learn an intrinsic spatial representation of the environment, *i.e.*, an internal
    city map. The agent combines the historical experience and current observation
    to infer the goal direction. To improve over short-sighted actions, we resort
    to long-term planning. Specifically, considering the reflections and current road
    network connection, the agent decompose the full navigation path into several
    sub-goals, ensuring consistent and reasonable movement to the final goal during
    long-range navigation. In addition, we find that the fine-tuned LLaVA can perceive
    the direction and distance of landmarks with sufficient accuracy for navigation.
    These components form the ‘*Perceive*, *Reflect*, and *Plan*’ workflow which allows
    the agent to perform long-range city navigation.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提出了一种有效的智能工作流程，提升了LLM的目标导向城市导航能力。为了避免孤立的决策，我们提出了一种记忆方案。历史轨迹和观察结果被存储和总结，以学习环境的内在空间表示，*即*，内部城市地图。智能体结合历史经验和当前观察来推断目标方向。为了改善短视行为，我们依赖于长期规划。具体而言，考虑到反射和当前道路网络连接，智能体将完整的导航路径分解为若干个子目标，确保在长距离导航中朝最终目标进行一致而合理的移动。此外，我们发现经过微调的LLaVA可以以足够的精度感知地标的方向和距离。这些组件构成了‘*感知*，*反射*和*规划*’工作流程，使智能体能够进行长距离城市导航。
- en: Our method only requires training the visual perception part with vision-language
    pairs of landmarks. The memory and planning parts both operate with few-shot examples
    (but also support fine-tuning). Compared to RL methods, our approach offers a
    more data-efficient solution. Compared with instruction-following methods, our
    system does not rely on explicit instructions, allowing for greater autonomy in
    navigation.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的方法仅需用地标的视觉语言对训练视觉感知部分。记忆和规划部分都使用少量样本（但也支持微调）。与RL方法相比，我们的方法提供了一种数据效率更高的解决方案。与指令跟随方法相比，我们的系统不依赖于明确的指令，从而在导航中提供了更大的自主性。
- en: We collect two navigation datasets reflecting CBD scenes in Beijing and Shanghai.
    They contain complex road networks with thousands of road nodes and street views.
    On the two datasets, the proposed workflow significantly outperforms methods that
    could be applied (but are not specific) to our task. We find the perception component
    produces accurate spatial relations to support city navigation, the success rate
    of which is only 5% lower than navigation with ground truth perception results.
    Besides, we show that reflection and planning can further contribute to the success
    rate and that our method remains useful when dealing with long-range navigation
    tasks.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们收集了反映北京和上海CBD场景的两个导航数据集。这些数据集包含复杂的道路网络，拥有数千个道路节点和街景。在这两个数据集上，所提议的工作流程显著优于那些可以应用于（但不特定于）我们任务的方法。我们发现感知组件能够产生准确的空间关系以支持城市导航，其成功率仅比使用真实感知结果的导航低5%。此外，我们展示了反射和规划可以进一步提高成功率，并且我们的方法在处理长距离导航任务时仍然有效。
- en: 2 Related Work
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: Vision and language navigation (VLN) aims to enable agents to autonomously navigate
    in visual environments based on natural language instructions [[7](#bib.bib7)][[8](#bib.bib8)].
    The field evolves from indoor to urban settings, with expanded scope of tasks
    and datasets. Anderson *et al.* created an early VLN dataset, while Mirowski *et
    al.* [[9](#bib.bib9)] introduce cross-modal matching models that leverage attention
    and reinforcement learning for vision and text integration. Datasets like TOUCHDOWN [[1](#bib.bib1)],
    Retouchdown [[10](#bib.bib10)], and StreetNav [[11](#bib.bib11)], allow VLN to
    transition to more complex urban environments. Recently, the use of LLMs has introduced
    new solutions in in VLN [[12](#bib.bib12)][[13](#bib.bib13)][[14](#bib.bib14)],
    which achieved success with indoor environment. Other works [[15](#bib.bib15)][[2](#bib.bib2)]
    focusing on outdoor VLN, which use strong language understanding capabilities
    of LLMs for navigation based on ground-level instructions. In comparison, our
    paper does not rely on language instructions, where our city-navigation system
    explores the spatial cognitive abilities of LLMs.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉和语言导航（VLN）旨在使智能体能够根据自然语言指令在视觉环境中自主导航[[7](#bib.bib7)][[8](#bib.bib8)]。该领域从室内环境扩展到城市环境，任务和数据集的范围也得到扩展。**Anderson**
    *等*人创建了早期的VLN数据集，而**Mirowski** *等*人[[9](#bib.bib9)]介绍了利用注意力和强化学习进行视觉和文本集成的跨模态匹配模型。像TOUCHDOWN[[1](#bib.bib1)]、Retouchdown[[10](#bib.bib10)]和StreetNav[[11](#bib.bib11)]这样的数据集使VLN能够过渡到更复杂的城市环境。最近，LLMs的使用在VLN[[12](#bib.bib12)][[13](#bib.bib13)][[14](#bib.bib14)]中引入了新的解决方案，成功应用于室内环境。其他工作[[15](#bib.bib15)][[2](#bib.bib2)]专注于户外VLN，利用LLMs强大的语言理解能力进行基于地面指令的导航。相比之下，我们的论文不依赖语言指令，我们的城市导航系统探索了LLMs的空间认知能力。
- en: 'Agentic workflows with LLMs. The exploration of agentic workflows using LLMs
    emerges as a effective strategy for planning problems [[16](#bib.bib16)]. Agentic
    workflows emphasize a step-by-step refinement process rather than single-step
    output generation. This strategy involves four key patterns: reflection, tool-use,
    planning, and multi-agent collaboration. Studies such as inner monologue [[17](#bib.bib17)]
    and reflexion [[18](#bib.bib18)] demonstrate the effectiveness of reflection in
    enhancing agentic understanding and reducing errors. Meanwhile, interactive planning
    methods like DEPS [[19](#bib.bib19)] and RAP [[20](#bib.bib20)] enable more structured
    and conscious planning. Other workflows, including CaP [[21](#bib.bib21)], ProgPrompt
    [[22](#bib.bib22)], CoT [[23](#bib.bib23)] and ToT [[24](#bib.bib24)], contribute
    to the collective understanding of how LLMs can be directed towards goal-oriented
    tasks. In our work, we design the agentic workflow with perception, reflection
    and plan modules, using inherent abilities of LLMs to tackle complex urban navigation.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs的智能体工作流。使用LLMs探索智能体工作流作为解决规划问题的一种有效策略[[16](#bib.bib16)]。智能体工作流强调逐步改进过程，而非单步输出生成。这一策略涉及四个关键模式：反思、工具使用、规划和多智能体协作。内心独白[[17](#bib.bib17)]和反思[[18](#bib.bib18)]等研究展示了反思在提升智能体理解和减少错误方面的有效性。同时，像DEPS[[19](#bib.bib19)]和RAP[[20](#bib.bib20)]这样的互动规划方法实现了更结构化和有意识的规划。其他工作流，包括CaP[[21](#bib.bib21)]、ProgPrompt[[22](#bib.bib22)]、CoT[[23](#bib.bib23)]和ToT[[24](#bib.bib24)]，有助于集体理解如何将LLMs引导到目标导向的任务中。在我们的工作中，我们设计了包含感知、反思和规划模块的智能体工作流，利用LLMs的固有能力应对复杂的城市导航任务。
- en: 3 Task Description, Dataset, and Baseline
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 任务描述、数据集和基线
- en: 3.1 Task Description
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 任务描述
- en: 'In this study, an agent navigates in the urban environment to find the goal
    with visual perception and goal description. To define the task exactly, we give
    following definitions:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，智能体通过视觉感知和目标描述在城市环境中导航以找到目标。为了准确定义任务，我们给出以下定义：
- en: Definition 1 (Urban Environment) The urban environment for navigation task can
    be described as an undirected graph .
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 定义1（城市环境）城市导航任务的环境可以描述为一个无向图。
- en: Definition 2 (Urban Navigation Task) The urban navigation task can be formulated
    as finding a path from the start node $v_{s}$ is the relative position among all
    landmarks in the environment.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 定义2（城市导航任务）城市导航任务可以表述为从起始节点$v_{s}$找到路径，这是环境中所有地标的相对位置。
- en: Definition 3 (Agent for Urban Navigation Task) At timestamp $t$.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 定义3（城市导航任务的智能体）在时间戳$t$。
- en: 3.2 Dataset
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 数据集
- en: 'We collect data from central business districts (CBDs) of Beijing and Shanghai,
    which have a radius of a few kilometers. From this range, road network data are
    extracted and discritized at intervals of 50 meters forming the urban environment
    $G$. Each node of the road network is associated with the corresponding street
    view images. The number of street view images is related to the degree of the
    node. Road network visualization and a few examples of the dataset are shown Fig.
    [2](#S3.F2 "Figure 2 ‣ 3.2 Dataset ‣ 3 Task Description, Dataset, and Baseline
    ‣ Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation
    without Instructions")(a).'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从北京和上海的中央商务区（CBD）收集数据，这些区域的半径为几公里。在这个范围内，提取了道路网络数据，并以每50米的间隔进行离散化，形成城市环境$G$。道路网络的每个节点都与相应的街景图像相关联。街景图像的数量与节点的度数相关。道路网络可视化及数据集的一些示例见图[2](#S3.F2
    "图 2 ‣ 3.2 数据集 ‣ 3 任务描述、数据集和基线 ‣ 感知、反思和规划：设计用于无指令的目标导向城市导航的LLM代理")（a）。
- en: Specifically, the selected area in Beijing is the Guomao CBD area, with a radius
    of approximately 3 kilometers, which includes a total of 1,134 nodes and 2,742
    street view images, along with 10 landmark buildings. In Shanghai, the selected
    area is the Lujiazui CBD area, also with the similar radius, containing a total
    of 1,038 nodes and 2,366 street view images, along with 10 landmark buildings.
    The landmarks chosen in the dataset are well-known buildings with unique features.
    Street view images were obtained from Baidu Map Street View API, with a field
    of view of 90° and an elevation angle of 20° for each image. The image resolution
    is 1,024×512 pixels.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 具体而言，北京选定的区域是国贸CBD区域，半径约为3公里，包含共1,134个节点和2,742张街景图像，以及10座地标建筑。在上海，选定的区域是陆家嘴CBD区域，也具有类似的半径，包含共1,038个节点和2,366张街景图像，以及10座地标建筑。数据集中选择的地标是具有独特特征的知名建筑。街景图像来自百度地图街景API，每张图像的视场角为90°，俯仰角为20°。图像分辨率为1,024×512像素。
- en: '![Refer to caption](img/f94c2c87dd30992c4fef0cd369858202.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/f94c2c87dd30992c4fef0cd369858202.png)'
- en: 'Figure 2: Task example and dataset regions. A task example is shown in (a).
    The instruction to the agent is the relative location of the goal w.r.t the landmarks
    in the city environment. The agent perceives the street views like (b). The agent
    has to infer the goal position relative to its current location using its observations
    of landmarks and move through the urban space. The road network in the chosen
    CBD areas in Shanghai (c) and Beijing (d). Blue points represent the landmarks
    used in the datasets, while red lines are roads.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：任务示例和数据集区域。任务示例见（a）。对代理的指令是目标相对于城市环境中的地标的相对位置。代理感知像（b）这样的街景。代理必须通过观察地标推断目标位置相对于当前位置，并在城市空间中移动。上海（c）和北京（d）选择的CBD区域的道路网络。蓝色点表示数据集中使用的地标，而红色线表示道路。
- en: 3.3 Baseline
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 基线
- en: 'A straightforward baseline iterates between two steps: visual perception and
    react. Specifically, after perceiving a street view from its current location,
    the agent predicts the direction of and distance to the target. Then, based on
    these predictions, the agent decides the next move. These two steps iterate until
    the agent reaches the goal or runs out of the navigation budget.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 一个直接的基线在两个步骤之间迭代：视觉感知和反应。具体来说，在从当前位置感知街景之后，代理预测目标的方向和距离。然后，基于这些预测，代理决定下一步行动。这两个步骤不断迭代，直到代理达到目标或导航预算用完。
- en: 'Here, visual perception is performed using fine-tuned LLaVA. We feed the street
    view images to LLaVA with the question “Is [landmark] in the image? If so, estimate
    its direction and distance.”. We ask this question for all landmarks in this region.
    The agent already has the relative position of the goal from different landmarks,
    so it can infer the goal direction from the perception results. Based on the perception
    and direction inference results, also considering the current road connection,
    the agent uses the zero-shot LLM reasoning ability to decide the next move. Note
    that the perception method with LLaVA is also used in the proposed agent workflow.
    More details are provided in Section [4.2](#S4.SS2 "4.2 Perception ‣ 4 Proposed
    Agent Workflow ‣ Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed
    City Navigation without Instructions").'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，视觉感知使用了经过微调的LLaVA。我们将街景图像输入LLaVA，并提出问题“图像中有[地标]吗？如果有，请估计其方向和距离。”。我们对该区域内的所有地标都提出这个问题。代理已经具有从不同地标得到的目标相对位置，因此可以根据感知结果推断目标方向。根据感知和方向推断的结果，同时考虑当前的道路连接，代理使用零样本LLM推理能力来决定下一步行动。请注意，使用LLaVA的感知方法也用于提议的代理工作流程中。更多细节请参见[4.2](#S4.SS2
    "4.2 感知 ‣ 4 提议的代理工作流程 ‣ 感知、反思和规划：设计用于无指令的目标导向城市导航的LLM代理")部分。
- en: 4 Proposed Agent Workflow
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 提议的代理工作流程
- en: 4.1 Workflow Overview
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 工作流程概述
- en: 'The overall agent workflow is shown in the Figure [3](#S4.F3 "Figure 3 ‣ 4.1
    Workflow Overview ‣ 4 Proposed Agent Workflow ‣ Perceive, Reflect, and Plan: Designing
    LLM Agent for Goal-Directed City Navigation without Instructions"), which is consist
    of three parts: visual perception, reflection with memory, and planning. While
    visual perception uses LLaVA, both reflection and memory uses large language models
    (LLMs). As described in Section [4.2](#S4.SS2 "4.2 Perception ‣ 4 Proposed Agent
    Workflow ‣ Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed
    City Navigation without Instructions"), visual perception allows the agent to
    recognize the landmarks in the street view images and predict the direction and
    distance of the target. Perception results are passed to the reflection part,
    where the agent reevaluates the perception results and reflects the goal location.
    In reflection, long-term memory is set up to summarize and learn from the historical
    trajectory for constructing intrinsic map representations, a topological map between
    nodes that the agent has visited. The planning module is the decision core of
    the workflow. It generates a navigation plan by considering both the goal direction
    after reflection and the current road connections. The agent follows this plan
    to make the next move. Then the agent state will be updated to start next iteration.
    These steps compose a workflow that enables the agent to sense its surroundings,
    remember past experience, and plan its actions. As shown in Section [5](#S5 "5
    Experiments ‣ Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed
    City Navigation without Instructions") , this workflow yields significantly higher
    navigation success rates compared to the ‘React’ baseline.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 整体代理工作流程如图[3](#S4.F3 "图 3 ‣ 4.1 工作流程概述 ‣ 4 提议的代理工作流程 ‣ 感知、反思和规划：设计用于无指令的目标导向城市导航的LLM代理")所示，包括三个部分：视觉感知、带记忆的反思和规划。视觉感知使用LLaVA，而反思和记忆都使用大型语言模型（LLMs）。如[4.2](#S4.SS2
    "4.2 感知 ‣ 4 提议的代理工作流程 ‣ 感知、反思和规划：设计用于无指令的目标导向城市导航的LLM代理")部分所述，视觉感知使代理能够识别街景图像中的地标并预测目标的方向和距离。感知结果会传递到反思部分，代理在这里重新评估感知结果并反思目标位置。在反思过程中，建立了长期记忆，以总结和学习历史轨迹，以构建内在的地图表示，即代理已访问节点之间的拓扑图。规划模块是工作流程的决策核心。它通过考虑反思后的目标方向和当前的道路连接来生成导航计划。代理根据该计划执行下一步操作。然后，代理状态将被更新以开始下一次迭代。这些步骤组成了一个工作流程，使代理能够感知周围环境、记住过去的经验并规划其行动。如[5](#S5
    "5 实验 ‣ 感知、反思和规划：设计用于无指令的目标导向城市导航的LLM代理")部分所示，这个工作流程相比于‘React’基线显著提高了导航成功率。
- en: '![Refer to caption](img/723cfa3ec91f91c2e109c91ff28195cd.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/723cfa3ec91f91c2e109c91ff28195cd.png)'
- en: 'Figure 3: Overview of PReP workflow. PReP has three steps: perception, reflection,
    and planning. Blue boxes represent LLMs or LLaVA, while gray boxes indicate variables
    stored by natural language. The definition of mathematical symbols are in section
    [3](#S3 "3 Task Description, Dataset, and Baseline ‣ Perceive, Reflect, and Plan:
    Designing LLM Agent for Goal-Directed City Navigation without Instructions").'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：PReP 工作流程概述。PReP 有三个步骤：感知、反思和规划。蓝色框表示 LLMs 或 LLaVA，而灰色框表示由自然语言存储的变量。数学符号的定义在第
    [3](#S3 "3 任务描述、数据集和基准 ‣ 感知、反思和规划：设计面向目标城市导航的 LLM 智能体（无需说明）") 节中。
- en: 4.2 Perception
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 感知
- en: 'Perceiving the landmarks. At timestamp $t$ to the agent itself. We perform
    the task using LLaVA [[25](#bib.bib25)]. Zero-shot LLaVA has poor recognition
    accuracy because the landmarks we use are probably not in its training data. We
    therefore fine-tunes LLaVA using the LoRA method [[26](#bib.bib26)]. To do so,
    we collect 5,000 landmark images and generate 30k Q&A conversation data. More
    details can be seen in the Appendix [A.1](#A1.SS1 "A.1 Fine-tuning LLaVA ‣ Appendix
    A Additional Experimental Details ‣ Perceive, Reflect, and Plan: Designing LLM
    Agent for Goal-Directed City Navigation without Instructions").'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 感知地标。在时间戳 $t$ 上，对智能体自身进行任务。我们使用 LLaVA 执行此任务 [[25](#bib.bib25)]。零-shot LLaVA
    的识别准确率较差，因为我们使用的地标可能不在其训练数据中。因此，我们通过 LoRA 方法对 LLaVA 进行微调 [[26](#bib.bib26)]。为此，我们收集了
    5000 张地标图像，并生成了 30,000 个问答对话数据。更多细节请参见附录 [A.1](#A1.SS1 "A.1 微调 LLaVA ‣ 附录 A 额外实验细节
    ‣ 感知、反思和规划：设计面向目标城市导航的 LLM 智能体（无需说明）")。
- en: Inferring directions to the goal. While the agent acquires the landmarks position
    to the agent $R_{lm}$ of is the direction and distance of the goal relative to
    the agent. The essence of this problem is a calculation process of the cosine
    theorem, so the results can be further improved using calculators.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 推断目标的方向。当智能体获得地标位置到智能体 $R_{lm}$ 的信息时，它表示相对于智能体的目标方向和距离。这个问题的本质是余弦定理的计算过程，因此可以通过计算器进一步优化结果。
- en: '![Refer to caption](img/9b21ff1f216a996780e8dcff5969365a.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/9b21ff1f216a996780e8dcff5969365a.png)'
- en: 'Figure 4: Sample prompts and responses in the PReP workflow.In perception,
    a vision language model locates the landmarks and estimates their distances to
    the agent. In reflection, the agent presents all past memory and short-term memory,
    and gives an estimate of the location and direction of the goal. In planning,
    the agent uses the output from reflection to update the plan. Prompts have been
    simplified while retaining their original meaning. The full prompts are provided
    in Appendix [E](#A5 "Appendix E Prompt for Different Methods ‣ Perceive, Reflect,
    and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions")'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：PReP 工作流程中的示例提示和响应。在感知阶段，视觉语言模型定位地标并估算其与智能体的距离。在反思阶段，智能体展示所有过去的记忆和短期记忆，并对目标的位置和方向做出估计。在规划阶段，智能体使用反思阶段的输出更新计划。提示已被简化，同时保留了其原始含义。完整的提示在附录
    [E](#A5 "附录 E 不同方法的提示 ‣ 感知、反思和规划：设计面向目标城市导航的 LLM 智能体（无需说明）") 中提供。
- en: 4.3 Reflection
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 反思
- en: 'Reflection is critical in our workflow, which summarizes past experience and
    reflects on visual perception results. This step has two main components: long-term
    memory and working memory. Long-term memory consists of episodic memory and semantic
    memory, where episodic memory stores navigation data and semantic memory saves
    summary of history navigation experience. Working memory serves as a data buffer
    to process the visual perception results and retrieved memory.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 反思在我们的工作流程中至关重要，它总结了过去的经验并反思视觉感知结果。此步骤包含两个主要组成部分：长期记忆和工作记忆。长期记忆包括情景记忆和语义记忆，其中情景记忆存储导航数据，语义记忆保存历史导航经验的总结。工作记忆作为数据缓冲区，用于处理视觉感知结果和检索到的记忆。
- en: Episodic memory. Episodic memory is a list of the navigation data in natural
    language. When the agent moves from $v_{t}$ to help reflection and planning. These
    retrieved memories are buffered in working memory space for further processing.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 情景记忆。情景记忆是以自然语言记录的导航数据列表。当智能体从 $v_{t}$ 移动时，帮助反思和规划。这些检索到的记忆被缓存在工作记忆空间中以供进一步处理。
- en: Semantic memory. While episode memory records the experiences, the agent uses
    LLMs to summarize and learn from the episodic memory to form the semantic memory.
    The semantic memory is a high-level cognitive function that assists the agent
    in constructing an intrinsic representation of the navigation map. Like a human,
    it can understand the environment based on historical experience and learn more
    advanced navigation strategies, such as detours required to reach the destination.
    These strategies can be retrieved to working memory and further beneficial to
    the planning process. As the agent navigates, episodic memory and semantic memory
    are updated accordingly.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 语义记忆。虽然情节记忆记录了经验，但智能体使用LLMs从情节记忆中总结和学习，以形成语义记忆。语义记忆是一种高级认知功能，帮助智能体构建导航地图的内在表示。类似于人类，它可以根据历史经验理解环境，并学习更高级的导航策略，例如到达目的地所需的绕行。这些策略可以被检索到工作记忆中，并进一步有利于计划过程。随着智能体的导航，情节记忆和语义记忆会相应更新。
- en: Working memory. Working memory receives visual perception results $R_{g}^{t}$
    and retrieved memory. This enables the agent to tackle complex environments regardless
    whether landmarks are visible or not, making the agent more flexible and robust.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 工作记忆。工作记忆接收视觉感知结果$R_{g}^{t}$和检索的记忆。这使得智能体能够处理复杂的环境，无论地标是否可见，从而使智能体更加灵活和稳健。
- en: 4.4 Planning
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 计划
- en: Instead of reacting directly to observations, we use a planning module in our
    workflow. It involves long-term planning and short-term decision-making. Specifically,
    long-term planning uses reflected goal inference $R_{l}^{t}$, making the agent
    updates its location and explore the goal in the environment.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在工作流程中使用了一个规划模块，而不是直接对观察结果作出反应。它涉及长期规划和短期决策。具体而言，长期规划使用反射目标推断$R_{l}^{t}$，使得智能体更新其位置并在环境中探索目标。
- en: 5 Experiments
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 实验
- en: 5.1 Experimental setup
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 实验设置
- en: 'We experimentally evaluate the performance of the proposed agentic workflow
    on the simulated urban navigation task described in section [3](#S3 "3 Task Description,
    Dataset, and Baseline ‣ Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed
    City Navigation without Instructions"). We use success rate (SR) and success rate
    weighted by path length (SPL) to measure system effectiveness and efficiency,
    respectively [[27](#bib.bib27)].'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第[3](#S3 "3 任务描述、数据集和基线 ‣ 感知、反思和计划：设计LLM智能体进行无指令的目标导向城市导航")节中描述的模拟城市导航任务上实验性地评估了所提出的智能工作流程的性能。我们使用成功率（SR）和按路径长度加权的成功率（SPL）分别衡量系统的有效性和效率[[27](#bib.bib27)]。
- en: We use two test sets, one for Beijing CBD, and the other for Shanghai CBD. Each
    test sets have 100 different navigation tasks with different starting points.
    Each starting point is at a road node, where at least one landmark must be visible;
    otherwise, the agent will randomly wander. The minimum number of steps required
    from the starting point to the goal followed a normal distribution with $\mu$=10
    steps. Because each steps translates to 50 meters on the map, it means the average
    step is 30, and average navigation distance is 1,500 meters. We set the iteration
    limit as 2.5 times as the minimum steps. If the agent moves more than the limited
    step, we think the navigation task is failed.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了两个测试集，一个用于北京CBD，另一个用于上海CBD。每个测试集包含100个不同的导航任务，起点各不相同。每个起点位于一个路节点上，必须至少可见一个地标；否则，智能体将随机游荡。从起点到目标所需的最少步数服从均值为$\mu$=10步的正态分布。由于每一步在地图上等于50米，这意味着平均步数为30步，平均导航距离为1,500米。我们将迭代限制设置为最小步数的2.5倍。如果智能体移动的步数超过了限制，我们认为导航任务失败。
- en: 5.2 Main Evaluation
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 主要评估
- en: 'Comparison with existing methods that might give a solution. We compared PReP
    with existing language-based methods, including code as policies (CaP) [[21](#bib.bib21)],
    ProgPrompt [[22](#bib.bib22)], inner monologue [[17](#bib.bib17)], and chain of
    thought (CoT) [[23](#bib.bib23)]. These method are using well-designed prompts
    to fit our urban navigation task and we list the prompts for different methods
    in Appendix [E](#A5 "Appendix E Prompt for Different Methods ‣ Perceive, Reflect,
    and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions").
    We also implement two baselines that are not based on LLMs. The ‘random’ method
    selects a random direction from the current connection each time. Reinforcement
    learning (RL) [[9](#bib.bib9)] is trained for 1 million steps in the environment
    to learn the policy for finding the goal. The perception module for all the methods
    is the same. All the language-based methods use GPT-4-turbo as the base model,
    and all the hyper-parameters of LLMs are the same for a fair comparison.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '与可能提供解决方案的现有方法进行比较。我们将PReP与现有的基于语言的方法进行比较，包括代码作为策略（CaP）[[21](#bib.bib21)]、ProgPrompt
    [[22](#bib.bib22)]、内心独白 [[17](#bib.bib17)]和思维链（CoT）[[23](#bib.bib23)]。这些方法使用精心设计的提示来适应我们的城市导航任务，我们在附录[E](#A5
    "Appendix E Prompt for Different Methods ‣ Perceive, Reflect, and Plan: Designing
    LLM Agent for Goal-Directed City Navigation without Instructions")中列出了不同方法的提示。我们还实现了两个不基于LLM的基线方法。‘随机’方法每次从当前连接中选择一个随机方向。强化学习（RL）[[9](#bib.bib9)]在环境中训练了100万步，以学习找到目标的策略。所有方法的感知模块是相同的。所有基于语言的方法使用GPT-4-turbo作为基础模型，LLM的所有超参数相同，以确保公平比较。'
- en: 'From Table [1](#S5.T1 "Table 1 ‣ 5.2 Main Evaluation ‣ 5 Experiments ‣ Perceive,
    Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without
    Instructions"), we clearly observe that PReP yields the best navigation performance
    compared with existing methods. We have two observations. First, the success rate
    of Random is nearly 0, indicating the significant challenge of this task. Existing
    language-based methods have improved performance, suggesting that LLMs possess
    the capability to navigate in cities based on goal direction. Second, we achieve
    SR = 63% and 57% on Beijing and Shanghai test sets, respectively, and SPL = 47.67%
    and 42.15% on Beijing and Shanghai test sets, respectively. The second best method
    is CoT, the SR of which is 5% and 17% lower than our method, on Bejing and Shanghai
    test sets, respectively. It indicates the effectiveness of PReP.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '从表[1](#S5.T1 "Table 1 ‣ 5.2 Main Evaluation ‣ 5 Experiments ‣ Perceive, Reflect,
    and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions")中，我们可以清楚地观察到，PReP相比于现有方法表现出最佳的导航性能。我们有两个观察结果。首先，随机方法的成功率接近0，表明此任务的显著挑战。现有的基于语言的方法有所改进，表明LLMs具备基于目标方向进行城市导航的能力。其次，我们在北京和上海测试集上的成功率（SR）分别为63%和57%，路径长度比（SPL）分别为47.67%和42.15%。第二好的方法是CoT，其SR在北京和上海测试集上分别低于我们的方法5%和17%。这表明PReP的有效性。'
- en: 'Table 1: Comparing PReP with previous methods. ‘Random’ and ‘RL’ are not based
    on LLMs, while the latter methods, although using different structures, use LLMs
    as planners and decision-makers. The full prompts are in Appendix [E](#A5 "Appendix
    E Prompt for Different Methods ‣ Perceive, Reflect, and Plan: Designing LLM Agent
    for Goal-Directed City Navigation without Instructions").'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '表1：将PReP与以往方法进行比较。‘随机’和‘RL’不基于LLM，而后者的方法虽然使用了不同的结构，但都使用LLM作为规划者和决策者。完整的提示见附录[E](#A5
    "Appendix E Prompt for Different Methods ‣ Perceive, Reflect, and Plan: Designing
    LLM Agent for Goal-Directed City Navigation without Instructions")。'
- en: '| Methods | Beijing |  | Shanghai |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 北京 |  | 上海 |'
- en: '|  | SR (%) | SPL (%) |  | SR (%) | SPL (%) |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '|  | SR (%) | SPL (%) |  | SR (%) | SPL (%) |'
- en: '| Random | 1 | 0.41 |  | 2 | 1.02 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 随机 | 1 | 0.41 |  | 2 | 1.02 |'
- en: '| RL | 14 | 12.35 |  | 13 | 10.75 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| RL | 14 | 12.35 |  | 13 | 10.75 |'
- en: '| CaP | 15 | 10.72 |  | 13 | 10.32 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| CaP | 15 | 10.72 |  | 13 | 10.32 |'
- en: '| ProgPrompt | 25 | 16.66 |  | 23 | 16.53 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| ProgPrompt | 25 | 16.66 |  | 23 | 16.53 |'
- en: '| InnerMonologue | 38 | 28.64 |  | 26 | 19.47 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 内心独白 | 38 | 28.64 |  | 26 | 19.47 |'
- en: '| CoT | 58 | 41.61 |  | 34 | 22.76 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| CoT | 58 | 41.61 |  | 34 | 22.76 |'
- en: '| PReP | 63 | 47.67 |  | 57 | 42.15 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| PReP | 63 | 47.67 |  | 57 | 42.15 |'
- en: 'Effectiveness of the proposed planning and reflection methods. We conduct ablation
    studies to validate the usefulness of the reflection and planning methods. We
    keep perception part unchanged, assuming all variants can recognize landmarks
    and infer goal directions. Results are summarized in Table [2](#S5.T2 "Table 2
    ‣ 5.2 Main Evaluation ‣ 5 Experiments ‣ Perceive, Reflect, and Plan: Designing
    LLM Agent for Goal-Directed City Navigation without Instructions"). ‘PReP’ indicates
    the complete PReP workflow, which includes both planning and reflection methods.
    ‘w/o Reflection’ indicates that the agent receives the perception and retrieved
    the episode memory but without constructing semantic memory and reflection on
    goal inference. ‘w/o Planning’ indicates that the agent normally get the reflected
    goal inference and retrieved memory, but makes decisions without formulating a
    long-term plan. ‘Plain’ is the combination of ‘w/o Reflection’ and ‘w/o Planning’,
    where the agent makes decisions directly based on perception results and history
    experience in a list without planning and reflection.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '提出的规划和反思方法的有效性。我们进行消融研究以验证反思和规划方法的有效性。我们保持感知部分不变，假设所有变体都能识别地标并推断目标方向。结果总结在表
    [2](#S5.T2 "表 2 ‣ 5.2 主要评估 ‣ 5 实验 ‣ 感知、反思和规划: 设计无指令的 LLM 代理进行目标导向城市导航")。‘PReP’
    表示完整的 PReP 工作流程，包括规划和反思方法。‘w/o Reflection’ 表示代理接收了感知信息并检索了情景记忆，但没有构建语义记忆和对目标推断的反思。‘w/o
    Planning’ 表示代理通常会获取反射的目标推断和检索的记忆，但做决定时没有制定长期计划。‘Plain’ 是‘w/o Reflection’和‘w/o
    Planning’的组合，其中代理直接基于感知结果和历史经验在列表中做出决策，没有规划和反思。'
- en: 'Table 2: Comparing method variants. ‘Plain’ means PReP with neither planning
    nor reflection.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '表 2: 方法变体比较。‘Plain’ 意味着 PReP 既没有规划也没有反思。'
- en: '| Methods | Beijing |  | Shanghai |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 北京 |  | 上海 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '|  | SR (%) | SPL (%) |  | SR (%) | SPL (%) |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '|  | SR (%) | SPL (%) |  | SR (%) | SPL (%) |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Plain | 33 | 24.94 |  | 25 | 18.21 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| Plain | 33 | 24.94 |  | 25 | 18.21 |'
- en: '| PReP | 63 | 47.67 |  | 57 | 42.15 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| PReP | 63 | 47.67 |  | 57 | 42.15 |'
- en: '| PReP w/o Planning | 59 | 45.86 |  | 52 | 39.59 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| PReP 无规划 | 59 | 45.86 |  | 52 | 39.59 |'
- en: '| PReP w/o Reflection | 43 | 28.78 |  | 26 | 19.43 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| PReP 无反思 | 43 | 28.78 |  | 26 | 19.43 |'
- en: 'Table 3: Comparisons among ablation variants of the perception module. A, P,
    R represent Accuracy, Precision, and Recall of landmark recognition. IoU represents
    the degree of overlap between the predicted bounding box and the actual bounding
    box of the landmark.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '表 3: 感知模块的消融变体比较。A、P、R 代表地标识别的准确率、精确率和召回率。IoU 代表预测边界框与地标实际边界框之间的重叠程度。'
- en: '| Methods | A | P | R | IoU | Beijing |  | Shanghai |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | A | P | R | IoU | 北京 |  | 上海 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '|  |  |  |  |  | SR(%) | SPL(%) |  | SR(%) | SPL(%) |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  |  | SR(%) | SPL(%) |  | SR(%) | SPL(%) |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| LLaVA | 0.19 | 0.06 | 0.93 | 0.64 | 15 | 13.01 |  | 11 | 8.89 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| LLaVA | 0.19 | 0.06 | 0.93 | 0.64 | 15 | 13.01 |  | 11 | 8.89 |'
- en: '| LLaVA-FT(ours) | 0.99 | 0.98 | 0.96 | 0.91 | 63 | 47.67 |  | 57 | 42.15 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| LLaVA-FT（我们的） | 0.99 | 0.98 | 0.96 | 0.91 | 63 | 47.67 |  | 57 | 42.15 |'
- en: '| Oracle | - | - | - | - | 67 | 51.27 |  | 62 | 45.20 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| Oracle | - | - | - | - | 67 | 51.27 |  | 62 | 45.20 |'
- en: 'Table 4: Performance of PReP using different LLMs. Zero-shot spatial reasoning
    capabilities of most LLMs are limited, and PReP achieves best performance with
    GPT-4-turbo'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '表 4: 使用不同 LLM 的 PReP 性能。大多数 LLM 的零-shot 空间推理能力有限，PReP 在 GPT-4-turbo 上表现最佳。'
- en: '| Methods | Beijing |  | Shanghai |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 北京 |  | 上海 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '|  | SR (%) | SPL (%) |  | SR (%) | SPL (%) |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '|  | SR (%) | SPL (%) |  | SR (%) | SPL (%) |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| GPT-3.5-turbo | 9 | 5.40 |  | 7 | 4.53 |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5-turbo | 9 | 5.40 |  | 7 | 4.53 |'
- en: '| GLM-4 | 18 | 12.77 |  | 17 | 12.30 |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| GLM-4 | 18 | 12.77 |  | 17 | 12.30 |'
- en: '| Mistral-7B | 1 | 0.41 |  | 2 | 1.02 |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| Mistral-7B | 1 | 0.41 |  | 2 | 1.02 |'
- en: '| LLaMA3-8B | 8 | 4.75 |  | 6 | 5.03 |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| LLaMA3-8B | 8 | 4.75 |  | 6 | 5.03 |'
- en: '| LLaMA3-8B-FT | 22 | 16.76 |  | 24 | 15.80 |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| LLaMA3-8B-FT | 22 | 16.76 |  | 24 | 15.80 |'
- en: '| GPT-4-turbo (ours) | 63 | 47.67 |  | 57 | 42.15 |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4-turbo（我们的） | 63 | 47.67 |  | 57 | 42.15 |'
- en: We clearly see that the full system has the best performance. For example, on
    the Beijing test set, the full system yields a higher success rate of 30%, 4%,
    and 20% over ‘Plain’, ‘PReP w/o Planning’, and ‘PReP w/o Reflection’, respectively.
    This indicates the necessity of having both steps in our system. We also observe
    that removing reflection leads to larger performance drop comparing with removing
    planning. It suggests the importance of reflection.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们清楚地看到，完整系统具有最佳性能。例如，在北京测试集中，完整系统的成功率比“Plain”、“PReP w/o Planning”和“PReP w/o
    Reflection”分别高出30%、4%和20%。这表明系统中同时包含这两个步骤的必要性。我们还观察到，去除反思相比去除规划会导致性能的显著下降。这表明反思的重要性。
- en: 5.3 Further Analysis
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 进一步分析
- en: 'Benefit of fine-tuning LLaVA over zero-shot LLaVA. In Table [3](#S5.T3 "Table
    3 ‣ 5.2 Main Evaluation ‣ 5 Experiments ‣ Perceive, Reflect, and Plan: Designing
    LLM Agent for Goal-Directed City Navigation without Instructions"), we compare
    fine-tuned LLaVA with zero-shot LLaVA. Zero-shot LLaVA has much poorer performance:
    on the Shanghai test sets, its SR and SPL is 46% and 33.26% lower than its fine-tuned
    version. It indicates that LLaVA does not naturally recognize landmarks through
    Baidu Maps. But interestingly, zero-shot LLaVA still has 10+% success rate. This
    can be explained by its 19% accuracy, 6% precision, 93% recall, and 0.64$ IoU.
    In fact, zero-shot LLaVA has good building detection capacity and assume that
    most images contain landmarks, leading to a high recall. Its precision is low
    (6%), but sometimes is fine for the agent to find the goal.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '微调LLaVA相对于零-shot LLaVA的好处。在表[3](#S5.T3 "Table 3 ‣ 5.2 Main Evaluation ‣ 5 Experiments
    ‣ Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation
    without Instructions")中，我们比较了微调后的LLaVA和零-shot LLaVA。零-shot LLaVA的表现差得多：在上海测试集上，其SR和SPL分别比微调版本低46%和33.26%。这表明LLaVA不能自然地通过百度地图识别地标。但有趣的是，零-shot
    LLaVA仍然有10%以上的成功率。这可以用其19%的准确率、6%的精度、93%的召回率和0.64的IoU来解释。实际上，零-shot LLaVA具有较好的建筑物检测能力，并假设大多数图像包含地标，从而导致较高的召回率。其精度较低（6%），但有时对于代理找到目标来说是可以接受的。'
- en: We also compare with an oracle setting, where the perception results are replaced
    with groundtruth directions and distances measured by GPS. Compared with oracle
    results, fine-tuned LLaVA is 4% and 5% lower in SR on Beijing and Shanghai test
    sets, respectively. This is not a significant gap, indicating the effectiveness
    of fine-tuning.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还与一个oracle设置进行了比较，其中感知结果被GPS测量的真实方向和距离所替代。与oracle结果相比，微调后的LLaVA在北京和上海测试集上的SR分别低4%和5%。这不是一个显著的差距，表明了微调的有效性。
- en: 'Comparing different LLMs. We now use different LLMs to perform inference (blue
    boxes in Fig. [4](#S4.F4 "Figure 4 ‣ 4.2 Perception ‣ 4 Proposed Agent Workflow
    ‣ Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation
    without Instructions")). These models include GPT-3.5-turbo, GLM-4 [[28](#bib.bib28)],
    Mistral-7B [[29](#bib.bib29)], LLaMA3-8B [[30](#bib.bib30)] and GPT-4-turbo. From
    Table [4](#S5.T4 "Table 4 ‣ 5.2 Main Evaluation ‣ 5 Experiments ‣ Perceive, Reflect,
    and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions"),
    we observe that GPT-4-turbo significantly outperforms other LLMs without fine-tuning.
    Moreover, we then use the question-answering data generated by GPT-4-turbo to
    fine-tune LLaMA3 [[31](#bib.bib31)]. The fine-tuned LLaMA3 model achieves performance
    that was second only to GPT-4-turbo among all models.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '比较不同的LLM。我们现在使用不同的LLM进行推理（图[4](#S4.F4 "Figure 4 ‣ 4.2 Perception ‣ 4 Proposed
    Agent Workflow ‣ Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed
    City Navigation without Instructions")中的蓝色框）。这些模型包括GPT-3.5-turbo、GLM-4 [[28](#bib.bib28)]、Mistral-7B
    [[29](#bib.bib29)]、LLaMA3-8B [[30](#bib.bib30)]和GPT-4-turbo。从表[4](#S5.T4 "Table
    4 ‣ 5.2 Main Evaluation ‣ 5 Experiments ‣ Perceive, Reflect, and Plan: Designing
    LLM Agent for Goal-Directed City Navigation without Instructions")中，我们观察到GPT-4-turbo在没有微调的情况下显著优于其他LLM。此外，我们还使用GPT-4-turbo生成的问题回答数据来微调LLaMA3
    [[31](#bib.bib31)]。微调后的LLaMA3模型的表现仅次于GPT-4-turbo。'
- en: 'Impact of goal distance. We analyze whether the distance between the goal and
    the agent has an impact on success rate. In Fig. [6a](#S5.F5 "Figure 5 ‣ 5.3 Further
    Analysis ‣ 5 Experiments ‣ Perceive, Reflect, and Plan: Designing LLM Agent for
    Goal-Directed City Navigation without Instructions"), we observe that the success
    rate does not decrease a lot when the goal is as far as 2 kilometers (40 - 50
    steps) from the agent. We also notice that the curves drops at 20-40 steps but
    increases at 40-50 steps. The possible reason is that the iteration limit increases
    as the distance increases, the agent may fully explores the environments and find
    the goal more easily.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '目标距离的影响。我们分析了目标与代理之间的距离是否对成功率有影响。在图[6a](#S5.F5 "Figure 5 ‣ 5.3 Further Analysis
    ‣ 5 Experiments ‣ Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed
    City Navigation without Instructions")中，我们观察到当目标距离代理有2公里（40 - 50步）远时，成功率并没有显著下降。我们还注意到，曲线在20-40步时下降，但在40-50步时上升。可能的原因是，随着距离的增加，迭代限制增加，代理可能会充分探索环境，更容易找到目标。'
- en: 'Furthermore, in Fig. [6b](#S5.F5 "Figure 5 ‣ 5.3 Further Analysis ‣ 5 Experiments
    ‣ Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation
    without Instructions"), we study how the goal distance affects the number of steps
    taken by PReP. As the distance increases, generally the plots become more scattered,
    indicating the task is becoming more challenging. Basically the agent takes 1
    or 2 times more of the minimum number of steps to reach the goal.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '此外，在图[6b](#S5.F5 "Figure 5 ‣ 5.3 Further Analysis ‣ 5 Experiments ‣ Perceive,
    Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without
    Instructions")中，我们研究了目标距离对PReP采取的步骤数量的影响。随着距离的增加，图表通常变得更加分散，表明任务变得更加具有挑战性。基本上，代理需要比达到目标的最小步骤数量多1到2倍的步骤。'
- en: 'Impact of landmark visibility. When the agent performs a navigation task, some
    nodes it passes through can observe landmarks, while others cannot. We study how
    landmark visibility along its path impacts its success rate. In Fig. [6c](#S5.F5
    "Figure 5 ‣ 5.3 Further Analysis ‣ 5 Experiments ‣ Perceive, Reflect, and Plan:
    Designing LLM Agent for Goal-Directed City Navigation without Instructions"),
    we plot the relationship between the number of nodes in the path that can observe
    any landmark and the total number of nodes in successful tasks. From the plot,
    we can find some valuable results. When the PReP agent performed tasks in the
    Beijing test set, it could identify landmarks in approximately 50% of the nodes
    traveled on average. In the Shanghai test set, this percentage dropped to less
    than 20%. Despite this challenge, performance in the Shanghai test set was not
    significantly lower than in the Beijing test set. This demonstrates that the PReP
    agent can efficiently navigate even in environments with sparse landmark visibility.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '地标可见性的影响。当代理执行导航任务时，它经过的一些节点可以观察到地标，而其他节点则无法观察到。我们研究了路径上地标可见性如何影响成功率。在图[6c](#S5.F5
    "Figure 5 ‣ 5.3 Further Analysis ‣ 5 Experiments ‣ Perceive, Reflect, and Plan:
    Designing LLM Agent for Goal-Directed City Navigation without Instructions")中，我们绘制了路径上可以观察到地标的节点数量与成功任务中的总节点数量之间的关系。从图表中，我们可以发现一些有价值的结果。当PReP代理在北京测试集上执行任务时，它平均可以在约50%的节点上识别地标。在上海测试集中，这一比例下降到不到20%。尽管面临这一挑战，上海测试集的表现并没有显著低于北京测试集。这表明PReP代理即使在地标可见性稀疏的环境中也能有效导航。'
- en: '![Refer to caption](img/5fb848c29b6ea7f8054c061b0189d86d.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/5fb848c29b6ea7f8054c061b0189d86d.png)'
- en: 'Figure 5: Performance of PReP across varying task difficulties. (a): Success
    rate vs. minimum number of steps required to reach the goal. (b): Number of steps
    taken by PReP vs. the number of minimum steps required to reach the goal. (c)
    : Number of nodes where agent can observe landmarks (y axis) vs. number of nodes
    visited in one task (x axis).'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：PReP在不同任务难度下的表现。(a)：成功率与达到目标所需的最小步骤数量。(b)：PReP采取的步骤数量与达到目标所需的最小步骤数量。(c)：代理可以观察到地标的节点数量（y轴）与一个任务中访问的节点数量（x轴）。
- en: Computational cost. The primary training cost is LLaVA fine-tuning, which requires
    one NVIDIA GeForce RTX A100 GPU with 80G memory for approximately 3 hours with
    30k conversation data. Each request-response cycle of the fine-tuned LLaVA on
    the same GPU takes 6 to 8 seconds, while calling the LLM API takes 2 to 5 seconds
    (varies among different models). Each iteration for an agent step takes about
    12 seconds. In future we will work to optimize the inference process.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 计算成本。主要的训练成本是LLaVA的微调，这需要一块拥有80G内存的NVIDIA GeForce RTX A100 GPU，大约3小时的时间，使用30k对话数据。微调后的LLaVA在同一GPU上的每个请求-响应周期需要6到8秒，而调用LLM
    API则需要2到5秒（不同模型之间有所差异）。每次代理步骤的迭代大约需要12秒。未来我们将致力于优化推理过程。
- en: '![Refer to caption](img/059e227ee05ec6ec85a76a74bb537aad.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/059e227ee05ec6ec85a76a74bb537aad.png)'
- en: 'Figure 6: Success case study. Here we choose three typical reasoning process
    in the whole navigation task where the arrows show the direction of travel of
    the agent. The agent makes a long-term plan at location (1) so that it can move
    consistently without moving back. At location (2), the agent cannot perceive landmarks
    in the street views and infer goal direction, but it can reflect history memory
    and anticipate the goal position. At location (3) the agent summarize its moving
    trajectory and find itself moving in the deviate direction, thus returning to
    the right route.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：成功案例研究。这里我们选择了整个导航任务中的三个典型推理过程，其中箭头显示了代理的旅行方向。代理在位置（1）进行长期规划，以便它可以一致地移动而不回退。在位置（2），代理无法在街景中感知地标并推测目标方向，但它可以反思历史记忆并预测目标位置。在位置（3），代理总结其移动轨迹，并发现自己在偏离方向上移动，从而返回正确的路线。
- en: 'A case study. We conduct a case study to illustrate the role of reflection
    and planning (see Fig. [6](#S5.F6 "Figure 6 ‣ 5.3 Further Analysis ‣ 5 Experiments
    ‣ Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation
    without Instructions")). In this case, the PReP agent deviates from the shortest
    path in the beginning but still successfully reaches the goal. Initially, the
    agent infers that the goal was located to the east. However, as there was no direct
    path to due east, the agent planned a detour: it first heads northeast and then
    turns towards either east or southeast. The agent continuously makes inferences
    of the goal location each time it observes a landmark along its route. When the
    agent cannot perceive landmarks in the street views and lose the goal direction,
    it can reflect on history memory including the moving trajectory and goal inference,
    and then anticipate the goal direction from current position. When the agent moves
    in the deviate direction, it can reflect its trajectory and re-plan the right
    route.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 案例研究。我们进行案例研究以说明反思和规划的作用（见图[6](#S5.F6 "图 6 ‣ 5.3 进一步分析 ‣ 5 实验 ‣ 感知、反思和规划：为无指令的目标导向城市导航设计LLM代理")）。在这个案例中，PReP代理在开始时偏离了最短路径，但仍成功达到了目标。最初，代理推测目标位于东部。然而，由于没有直接通向正东的路径，代理规划了一个绕行路线：它首先朝东北方向前进，然后转向东或东南方向。代理每次观察到沿路的地标时都会不断推测目标位置。当代理无法在街景中感知地标并失去目标方向时，它可以反思历史记忆，包括移动轨迹和目标推测，然后从当前位置预测目标方向。当代理朝偏离的方向移动时，它可以反思其轨迹并重新规划正确的路线。
- en: 6 Conclusion
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: We propose an agentic workflow for goal-directed city navigation without step-by-step
    language instructions or maps. The workflow includes a fine-tuned LLaVA model
    for spatial perception, a memory module for synthesizing and reflecting perception
    results and retrieved memory, and a planning module for navigation route planning.
    As our approach only requires training the visual perception part, it is a more
    data-efficient solution compared to RL methods. Owing to the well-designed reflection
    and planning part, the agent can perform the long-term navigation task in complex
    environment and achieves a success rate of about 60%. Further experiments show
    that the agent performs well in two cities and various difficulty levels, demonstrating
    robustness and flexibility. Our contributions not only present an effective agentic
    workflow for using LLMs in goal-directed urban navigation, but also validate the
    potential of LLMs for complex spatial tasks.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出了一种用于目标导向城市导航的代理工作流程，无需逐步语言指令或地图。该工作流程包括用于空间感知的微调 LLaVA 模型、用于综合和反映感知结果及检索记忆的记忆模块，以及用于导航路线规划的规划模块。由于我们的方法只需要训练视觉感知部分，相较于
    RL 方法，这是一种数据效率更高的解决方案。得益于精心设计的反映和规划部分，代理可以在复杂环境中执行长期导航任务，并取得约 60% 的成功率。进一步实验表明，代理在两个城市及各种难度级别中表现良好，展现了鲁棒性和灵活性。我们的贡献不仅展示了在目标导向城市导航中使用
    LLM 的有效代理工作流程，还验证了 LLM 在复杂空间任务中的潜力。
- en: References
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Howard Chen, Alane Suhr, Dipendra Misra, Noah Snavely, and Yoav Artzi.
    Touchdown: Natural language navigation and spatial reasoning in visual street
    environments. In Proceedings of the IEEE/CVF Conference on Computer Vision and
    Pattern Recognition, pages 12538–12547, 2019.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Howard Chen, Alane Suhr, Dipendra Misra, Noah Snavely, 和 Yoav Artzi. Touchdown:
    自然语言导航和视觉街道环境中的空间推理。载于 IEEE/CVF 计算机视觉与模式识别会议论文集，页码 12538–12547，2019。'
- en: '[2] Raphael Schumann, Wanrong Zhu, Weixi Feng, Tsu-Jui Fu, Stefan Riezler,
    and William Yang Wang. Velma: Verbalization embodiment of llm agents for vision
    and language navigation in street view. In Proceedings of the AAAI Conference
    on Artificial Intelligence, volume 38, pages 18924–18933, 2024.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Raphael Schumann, Wanrong Zhu, Weixi Feng, Tsu-Jui Fu, Stefan Riezler,
    和 William Yang Wang. Velma: LLM 代理的语言化体现用于街景的视觉与语言导航。载于 AAAI 人工智能会议论文集，卷 38，页码
    18924–18933，2024。'
- en: '[3] Piotr Mirowski, Razvan Pascanu, Fabio Viola, Hubert Soyer, Andrew J Ballard,
    Andrea Banino, Misha Denil, Ross Goroshin, Laurent Sifre, Koray Kavukcuoglu, et al.
    Learning to navigate in complex environments. arXiv preprint arXiv:1611.03673,
    2016.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Piotr Mirowski, Razvan Pascanu, Fabio Viola, Hubert Soyer, Andrew J Ballard,
    Andrea Banino, Misha Denil, Ross Goroshin, Laurent Sifre, Koray Kavukcuoglu 等.
    学习在复杂环境中导航。arXiv 预印本 arXiv:1611.03673，2016。'
- en: '[4] Yuke Zhu, Roozbeh Mottaghi, Eric Kolve, Joseph J Lim, Abhinav Gupta, Li Fei-Fei,
    and Ali Farhadi. Target-driven visual navigation in indoor scenes using deep reinforcement
    learning. In 2017 IEEE international conference on robotics and automation (ICRA),
    pages 3357–3364\. IEEE, 2017.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Yuke Zhu, Roozbeh Mottaghi, Eric Kolve, Joseph J Lim, Abhinav Gupta, Li
    Fei-Fei, 和 Ali Farhadi. 使用深度强化学习在室内场景中进行目标驱动的视觉导航。载于 2017 IEEE 国际机器人与自动化会议 (ICRA)，页码
    3357–3364。IEEE，2017。'
- en: '[5] Yi Wu, Yuxin Wu, Georgia Gkioxari, and Yuandong Tian. Building generalizable
    agents with a realistic and rich 3d environment. arXiv preprint arXiv:1801.02209,
    2018.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Yi Wu, Yuxin Wu, Georgia Gkioxari, 和 Yuandong Tian. 构建具有现实感和丰富 3D 环境的通用代理。arXiv
    预印本 arXiv:1801.02209，2018。'
- en: '[6] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan,
    and Yuan Cao. React: Synergizing reasoning and acting in language models. arXiv
    preprint arXiv:2210.03629, 2022.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan,
    和 Yuan Cao. React: 语言模型中推理与行动的协同。arXiv 预印本 arXiv:2210.03629，2022。'
- en: '[7] Jing Gu, Eliana Stefani, Qi Wu, Jesse Thomason, and Xin Eric Wang. Vision-and-language
    navigation: A survey of tasks, methods, and future directions. arXiv preprint
    arXiv:2203.12667, 2022.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Jing Gu, Eliana Stefani, Qi Wu, Jesse Thomason, 和 Xin Eric Wang. 视觉与语言导航：任务、方法和未来方向的调查。arXiv
    预印本 arXiv:2203.12667，2022。'
- en: '[8] Wansen Wu, Tao Chang, Xinmeng Li, Quanjun Yin, and Yue Hu. Vision-language
    navigation: a survey and taxonomy. Neural Computing and Applications, 36(7):3291–3316,
    2024.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Wansen Wu, Tao Chang, Xinmeng Li, Quanjun Yin, 和 Yue Hu. 视觉-语言导航：调查与分类。Neural
    Computing and Applications，36(7)：3291–3316，2024。'
- en: '[9] Piotr Mirowski, Matt Grimes, Mateusz Malinowski, Karl Moritz Hermann, Keith
    Anderson, Denis Teplyashin, Karen Simonyan, Andrew Zisserman, Raia Hadsell, et al.
    Learning to navigate in cities without a map. Advances in neural information processing
    systems, 31, 2018.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] 皮奥特·米罗夫斯基, 马特·格里姆斯, 马特乌什·马利诺夫斯基, 卡尔·莫里茨·赫尔曼, 基思·安德森, 丹尼斯·特普利亚欣, 卡伦·西蒙扬,
    安德鲁·齐瑟曼, 拉伊亚·哈德塞尔, 等. 学习在没有地图的情况下在城市中导航。神经信息处理系统进展, 31, 2018。'
- en: '[10] Harsh Mehta, Yoav Artzi, Jason Baldridge, Eugene Ie, and Piotr Mirowski.
    Retouchdown: Adding touchdown to streetlearn as a shareable resource for language
    grounding tasks in street view, 2020.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] 哈尔什·梅赫塔, 约阿夫·阿尔茨, 杰森·巴尔德里奇, 尤金·易, 和皮奥特·米罗夫斯基. Retouchdown：在街景中添加触地作为语言基础任务的共享资源,
    2020。'
- en: '[11] Karl Moritz Hermann, Mateusz Malinowski, Piotr Mirowski, Andras Banki-Horvath,
    Keith Anderson, and Raia Hadsell. Learning to follow directions in street view.
    In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages
    11773–11781, 2020.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] 卡尔·莫里茨·赫尔曼, 马特乌什·马利诺夫斯基, 皮奥特·米罗夫斯基, 安德拉斯·班基-霍尔瓦特, 基思·安德森, 和拉伊亚·哈德塞尔. 学习在街景中跟随指令。在AAAI人工智能会议论文集,
    第34卷, 页码 11773–11781, 2020。'
- en: '[12] Gengze Zhou, Yicong Hong, and Qi Wu. Navgpt: Explicit reasoning in vision-and-language
    navigation with large language models. In Proceedings of the AAAI Conference on
    Artificial Intelligence, volume 38, pages 7641–7649, 2024.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] 钟庚泽, 洪一聪, 和吴琪. Navgpt：在视觉和语言导航中使用大型语言模型的显式推理。在AAAI人工智能会议论文集, 第38卷, 页码
    7641–7649, 2024。'
- en: '[13] Vishnu Sashank Dorbala, James F Mullen Jr, and Dinesh Manocha. Can an
    embodied agent find your “cat-shaped mug”? llm-based zero-shot object navigation.
    IEEE Robotics and Automation Letters, 2023.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] 维什努·萨尚克·多尔巴拉, 詹姆斯·F·穆伦·Jr, 和迪内什·马诺查. 体现的代理能找到你的“猫形杯”吗？基于LLM的零样本对象导航。IEEE机器人与自动化信函,
    2023。'
- en: '[14] Weiqin Zu, Wenbin Song, Ruiqing Chen, Ze Guo, Fanglei Sun, Zheng Tian,
    Wei Pan, and Jun Wang. Language and sketching: An llm-driven interactive multimodal
    multitask robot navigation framework. arXiv preprint arXiv:2311.08244, 2023.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] 朱伟钦, 宋文斌, 陈瑞青, 郭泽, 孙芳磊, 田征, 潘伟, 和王军. 语言与草图：一种LLM驱动的互动多模态多任务机器人导航框架。arXiv预印本
    arXiv:2311.08244, 2023。'
- en: '[15] Dhruv Shah, Błażej Osiński, Sergey Levine, et al. Lm-nav: Robotic navigation
    with large pre-trained models of language, vision, and action. In Conference on
    robot learning, pages 492–504\. PMLR, 2023.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] 德鲁夫·沙阿, 布瓦泽·奥辛斯基, 谢尔盖·莱文, 等. Lm-nav：使用大型预训练的语言、视觉和动作模型进行机器人导航。在机器人学习会议上,
    页码 492–504. PMLR, 2023。'
- en: '[16] Theodore R Sumers, Shunyu Yao, Karthik Narasimhan, and Thomas L Griffiths.
    Cognitive architectures for language agents. arXiv preprint arXiv:2309.02427,
    2023.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] 西奥多·R·萨默斯, 杨顺宇, 卡尔提克·纳拉辛汉, 和托马斯·L·格里菲斯. 语言代理的认知架构。arXiv预印本 arXiv:2309.02427,
    2023。'
- en: '[17] Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence,
    Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, et al. Inner monologue:
    Embodied reasoning through planning with language models. arXiv preprint arXiv:2207.05608,
    2022.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] 黄文龙, 夏飞, 萧铁, 钱哈里斯, 梁杰基, 弗洛伦斯·皮特, 曾安迪, 汤普森·乔纳森, 莫达奇·伊戈尔, 切博塔尔·叶甫根, 等. 内心独白：通过语言模型的规划实现体现推理。arXiv预印本
    arXiv:2207.05608, 2022。'
- en: '[18] Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and
    Shunyu Yao. Reflexion: Language agents with verbal reinforcement learning. Advances
    in Neural Information Processing Systems, 36, 2024.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] 诺亚·辛恩, 费德里科·卡萨诺, 阿什温·戈比纳斯, 卡尔提克·纳拉辛汉, 和杨顺宇. Reflexion：具有语言强化学习的语言代理。神经信息处理系统进展,
    36, 2024。'
- en: '[19] Zihao Wang, Shaofei Cai, Guanzhou Chen, Anji Liu, Xiaojian Ma, and Yitao
    Liang. Describe, explain, plan and select: Interactive planning with large language
    models enables open-world multi-task agents. arXiv preprint arXiv:2302.01560,
    2023.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] 王子浩, 蔡绍飞, 陈冠洲, 刘安基, 马晓健, 和梁亦涛. 描述、解释、规划和选择：与大型语言模型的互动规划使开放世界多任务代理成为可能。arXiv预印本
    arXiv:2302.01560, 2023。'
- en: '[20] Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang,
    and Zhiting Hu. Reasoning with language model is planning with world model, 2023.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] 绍博·郝, 郭毅, 马浩迪, 乔舒亚·贾华·洪, 王震, 黛西·哲·王, 和胡智婷. 使用语言模型进行推理即通过世界模型进行规划, 2023。'
- en: '[21] Jacky Liang, Wenlong Huang, Fei Xia, Peng Xu, Karol Hausman, Brian Ichter,
    Pete Florence, and Andy Zeng. Code as policies: Language model programs for embodied
    control. In 2023 IEEE International Conference on Robotics and Automation (ICRA),
    pages 9493–9500\. IEEE, 2023.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] 梁杰基, 黄文龙, 夏飞, 徐鹏, 卡罗尔·豪斯曼, 布赖恩·伊赫特, 弗洛伦斯·皮特, 和曾安迪. 代码作为策略：用于体现控制的语言模型程序。在2023年IEEE国际机器人与自动化会议（ICRA）上,
    页码 9493–9500. IEEE, 2023。'
- en: '[22] Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei Xu,
    Jonathan Tremblay, Dieter Fox, Jesse Thomason, and Animesh Garg. Progprompt: Generating
    situated robot task plans using large language models. In 2023 IEEE International
    Conference on Robotics and Automation (ICRA), pages 11523–11530\. IEEE, 2023.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei Xu,
    Jonathan Tremblay, Dieter Fox, Jesse Thomason 和 Animesh Garg. Progprompt：利用大型语言模型生成情境化机器人任务计划。在2023
    IEEE国际机器人与自动化会议（ICRA）上，页码 11523–11530。IEEE，2023年。'
- en: '[23] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi,
    Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in
    large language models. Advances in neural information processing systems, 35:24824–24837,
    2022.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi,
    Quoc V Le, Denny Zhou 等。链式思维提示引发大型语言模型的推理。神经信息处理系统进展，35:24824–24837，2022年。'
- en: '[24] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan
    Cao, and Karthik Narasimhan. Tree of thoughts: Deliberate problem solving with
    large language models. Advances in Neural Information Processing Systems, 36,
    2024.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan
    Cao 和 Karthik Narasimhan. 思维树：利用大型语言模型进行深思熟虑的问题解决。神经信息处理系统进展，36，2024年。'
- en: '[25] Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual instruction
    tuning. Advances in neural information processing systems, 36, 2024.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Haotian Liu, Chunyuan Li, Qingyang Wu 和 Yong Jae Lee. 视觉指令调优。神经信息处理系统进展，36，2024年。'
- en: '[26] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li,
    Shean Wang, Lu Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language
    models. arXiv preprint arXiv:2106.09685, 2021.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li,
    Shean Wang, Lu Wang 和 Weizhu Chen. Lora：大型语言模型的低秩适应。arXiv 预印本 arXiv:2106.09685，2021年。'
- en: '[27] Peter Anderson, Angel Chang, Devendra Singh Chaplot, Alexey Dosovitskiy,
    Saurabh Gupta, Vladlen Koltun, Jana Kosecka, Jitendra Malik, Roozbeh Mottaghi,
    Manolis Savva, et al. On evaluation of embodied navigation agents. arXiv preprint
    arXiv:1807.06757, 2018.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Peter Anderson, Angel Chang, Devendra Singh Chaplot, Alexey Dosovitskiy,
    Saurabh Gupta, Vladlen Koltun, Jana Kosecka, Jitendra Malik, Roozbeh Mottaghi,
    Manolis Savva 等。关于具身导航代理的评估。arXiv 预印本 arXiv:1807.06757，2018年。'
- en: '[28] Zhipu. Zhipu ai devday glm-4. [https://zhipuai.cn/en/devday](https://zhipuai.cn/en/devday),
    2024.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] Zhipu. Zhipu ai devday glm-4。[https://zhipuai.cn/en/devday](https://zhipuai.cn/en/devday)，2024年。'
- en: '[29] Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford,
    Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel,
    Guillaume Lample, Lucile Saulnier, et al. Mistral 7b. arXiv preprint arXiv:2310.06825,
    2023.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford,
    Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel,
    Guillaume Lample, Lucile Saulnier 等。Mistral 7b。arXiv 预印本 arXiv:2310.06825，2023年。'
- en: '[30] Meta. Introducing meta llama 3: The most capable openly available llm
    to date. [https://ai.meta.com/blog/meta-llama-3/](https://ai.meta.com/blog/meta-llama-3/),
    2024.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Meta. 介绍 meta llama 3：迄今为止最强大的开放式可用大语言模型。[https://ai.meta.com/blog/meta-llama-3/](https://ai.meta.com/blog/meta-llama-3/)，2024年。'
- en: '[31] Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan Ye, Zheyan Luo, and
    Yongqiang Ma. Llamafactory: Unified efficient fine-tuning of 100+ language models.
    arXiv preprint arXiv:2403.13372, 2024.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan Ye, Zheyan Luo 和 Yongqiang
    Ma. Llamafactory：100+语言模型的统一高效微调。arXiv 预印本 arXiv:2403.13372，2024年。'
- en: Appendix A Additional Experimental Details
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 额外实验细节
- en: A.1 Fine-tuning LLaVA
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 微调 LLaVA
- en: The methodology for fine-tuning LLaVA uses the LoRA (Low-Rank Adaptation) technique.
    This approach introduces trainable low-rank matrices to simulate parameter updates,
    enabling rapid task adaptation without significantly increasing model complexity.
    We collected 250 images for each of the 20 landmarks from the Internet, totaling
    5,000 images. These images were manually annotated with the binary visibility
    and bounding box of each landmark. We split the data into an 80% training set
    and a 20% test set. Using these images, we generated dialogue data in a question-and-answer
    format. The questions we asked are as following step by step, aiming to form a
    pattern of CoT to improve its understanding and reasoning ability.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 对 LLaVA 进行微调的方法使用了 LoRA（低秩适应）技术。这种方法引入了可训练的低秩矩阵以模拟参数更新，从而实现快速任务适应而不会显著增加模型复杂性。我们从互联网上收集了每个20个地标中的250张图像，共计5000张。这些图像被手动标注了每个地标的二进制可见性和边界框。我们将数据拆分为80%的训练集和20%的测试集。利用这些图像，我们生成了问答格式的对话数据。我们提出的问题如下，旨在形成
    CoT 模式以提高其理解和推理能力。
- en: '1.'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: '"Is the $landmark_{i}$ visible in the image?"'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: “$landmark_{i}$ 在图像中可见吗？”
- en: '2.'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: '"The $landmark_{i}$ is visible in the image, what’s the bounding box of it
    in the image?"'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: “$landmark_{i}$ 在图像中可见，它在图像中的边界框是什么？”
- en: '3.'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: '"The $landmark_{i}$, how far is it actually away from the camera?"'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: “$landmark_{i}$，它实际距离相机有多远？”
- en: We generated about 30k turn dialogues to fine-tune the llava-v1.5-7b. The fine-tuning
    process was carried out on an NVIDIA GeForce RTX A100 GPU and took about 3 hours.
    The scripts to fine-tuning is modified from the official repository ¹¹1[https://github.com/haotian-liu/LLaVA](https://github.com/haotian-liu/LLaVA)
    with the default parameters.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们生成了大约 30k 对话回合来微调 llava-v1.5-7b。微调过程在一台 NVIDIA GeForce RTX A100 GPU 上进行，耗时约
    3 小时。微调脚本从官方仓库中修改而来 ¹¹1[https://github.com/haotian-liu/LLaVA](https://github.com/haotian-liu/LLaVA)，并使用默认参数。
- en: The outcome of this fine-tuning process is a model that demonstrates remarkable
    accuracy in landmark recognition and segmentation. While the distance estimation
    is not very accurate, the rough estimation results are still effective in subsequent
    navigation steps. The fine-tuned LLaVA model is essential for the agent to perceive
    the environment and obtain goal information.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 微调过程的结果是一个在地标识别和分割方面表现出显著准确性的模型。虽然距离估计不是非常准确，但粗略的估计结果在随后的导航步骤中仍然有效。微调后的 LLaVA
    模型对于代理感知环境和获取目标信息至关重要。
- en: 'Table 5: The ability to recognize and segment landmark in the street view images.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：识别和分割街景图像中地标的能力。
- en: '|  | Accuracy | Precision | Recall | F1-Score | IoU |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '|  | 准确率 | 精确率 | 召回率 | F1-分数 | IoU |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| LLaVA-base | 0.1873 | 0.0576 | 0.9347 | 0.1072 | 0.6432 |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| LLaVA-base | 0.1873 | 0.0576 | 0.9347 | 0.1072 | 0.6432 |'
- en: '| LLaVA-FT | 0.9980 | 0.9868 | 0.9695 | 0.9779 | 0.9152 |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| LLaVA-FT | 0.9980 | 0.9868 | 0.9695 | 0.9779 | 0.9152 |'
- en: '![Refer to caption](img/659316587d52d0b7a5535be5c0f5d4d0.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/659316587d52d0b7a5535be5c0f5d4d0.png)'
- en: 'Figure 7: The distance estimation results of fine-tuned LLaVA.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：微调后的 LLaVA 的距离估计结果。
- en: A.2 Fine-tuning LLaMA3-8B
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 微调 LLaMA3-8B
- en: We are trying to transfer knowledge from a much large model (GPT-4-turbo) to
    a small model (LLaMA3-8B). The method involves using data generated during navigation
    with GPT-4-turbo to fine-tune LLaMA-8B. We filter the successful samples from
    all the saved data and process them into the ShareGPT format. To avoid data breaches,
    we separate the Beijing and Shanghai datasets. This means we use data generated
    in Beijing to fine-tune LLaMA, which is then tested in Shanghai, and vice versa.
    We generated about 20k dialogue turns for each city dataset and fine-tuned LLaMA-8B
    using the LoRA method with one NVIDIA GeForce RTX A100 GPU. This process took
    about 30 minutes using the LLaMA-Factory tool ²²2[https://github.com/hiyouga/LLaMA-Factory/](https://github.com/hiyouga/LLaMA-Factory/).
    All parameters in the fine-tuning process were set to default.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尝试将一个更大的模型（GPT-4-turbo）的知识迁移到一个小模型（LLaMA3-8B）上。这种方法涉及使用在导航过程中生成的数据来微调 LLaMA-8B。我们从所有保存的数据中筛选出成功的样本，并将其处理成
    ShareGPT 格式。为了避免数据泄露，我们将北京和上海的数据集分开使用。这意味着我们使用在北京生成的数据来微调 LLaMA，然后在上海进行测试，反之亦然。我们为每个城市的数据集生成了大约
    20k 对话回合，并使用 LoRA 方法在一台 NVIDIA GeForce RTX A100 GPU 上微调了 LLaMA-8B。这个过程使用 LLaMA-Factory
    工具进行了大约 30 分钟 ²²2[https://github.com/hiyouga/LLaMA-Factory/](https://github.com/hiyouga/LLaMA-Factory/)。微调过程中的所有参数均设置为默认值。
- en: 'The results are shown in Table [4](#S5.T4 "Table 4 ‣ 5.2 Main Evaluation ‣
    5 Experiments ‣ Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed
    City Navigation without Instructions"). We see that while LLaMA3-8B performs slightly
    worse than GPT-3.5-turbo in our task, it significantly outperforms other LLMs
    (except GPT-4-turbo) after fine-tuning. Although there is still a gap compared
    to GPT-4-turbo, increasing the amount of fine-tuning data may improve its performance.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '结果如表 [4](#S5.T4 "Table 4 ‣ 5.2 Main Evaluation ‣ 5 Experiments ‣ Perceive,
    Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without
    Instructions") 所示。我们可以看到，虽然在我们的任务中，LLaMA3-8B 的表现稍逊于 GPT-3.5-turbo，但经过微调后，它显著优于其他
    LLM（除了 GPT-4-turbo）。尽管与 GPT-4-turbo 仍存在差距，但增加微调数据量可能会改善其性能。'
- en: Appendix B Limitations
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 限制
- en: Despite the advancements and innovative approaches in our work, there are several
    limitations to consider. A notable challenge is the dependence on powerful closed-source
    models, such as GPT-4-turbo, for superior results. Although we fine-tuned the
    open-source LLaMA-8B model, its performance, while better than other LLMs, does
    not reach half that of GPT-4-turbo. This highlights a significant gap. Future
    work should explore more effective fine-tuning strategies for open-source models
    to enhance their capabilities, ensuring our progress in urban navigation can be
    widely adopted and further developed. Another issue is the limited size of our
    test set, which may cause fluctuations in the success rate. A larger and more
    diverse test set could provide a more comprehensive evaluation of the model’s
    performance and robustness.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们在工作中取得了进展并采用了创新的方法，但仍需考虑一些局限性。一个显著的挑战是依赖于强大的封闭源模型，如**GPT-4-turbo**，以获得更优的结果。尽管我们对开源的LLaMA-8B模型进行了微调，其性能虽然优于其他LLMs，但仍未达到**GPT-4-turbo**的一半，这突显了一个显著的差距。未来的工作应探索更有效的开源模型微调策略，以提升其能力，确保我们在城市导航方面的进展能够被广泛采用并进一步发展。另一个问题是测试集的规模有限，这可能导致成功率的波动。更大且更多样化的测试集可以提供对模型性能和鲁棒性的更全面评估。
- en: Appendix C Ethical Analysis
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 C 伦理分析
- en: The data we collected is open access including *Baidu StreetViews API* and *Open
    Street Map*, without privacy issues. Our ethical analysis confirms that all data
    was gathered in compliance with the code of ethics. We ensured that no personally
    identifiable information was collected, maintaining the anonymity and privacy
    of individuals. By adhering to the ethical guidelines, we avoid any potential
    privacy concerns and support the broader scientific community’s efforts to build
    on and verify our work.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们收集的数据是开放访问的，包括*百度街景API*和*开放街图*，不存在隐私问题。我们的伦理分析确认所有数据的收集符合伦理规范。我们确保未收集任何个人可识别信息，保持了个人的匿名性和隐私。通过遵守伦理指南，我们避免了任何潜在的隐私问题，并支持更广泛的科学界在此基础上进行工作和验证。
- en: Appendix D Broader Impacts
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 D 广泛影响
- en: Developing the LLM agent for goal-directed city navigation has many positive
    social impacts. This technology extends beyond navigation robots, providing invaluable
    help to the visually impaired by enhancing their mobility and independence. Easier
    navigation in urban environments can greatly improve their quality of life and
    help them participate more fully in society. Additionally, using this technology
    in disaster relief can save lives by helping rescue teams navigate affected areas
    quickly and efficiently. However, there are potential negative social impacts
    to consider. Relying on AI for navigation might decrease human spatial awareness
    and problem-solving skills. To maximize the positive impact and minimize negative
    consequences, it is crucial to develop and implement this technology ethically
    with strong safeguards in place.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 开发用于目标导向城市导航的LLM代理具有许多积极的社会影响。这项技术不仅仅限于导航机器人，还通过增强视觉障碍者的流动性和独立性，为他们提供了宝贵的帮助。更容易在城市环境中导航可以极大地改善他们的生活质量，帮助他们更充分地参与社会。此外，在灾难救援中使用这项技术可以通过帮助救援队迅速有效地导航受灾区域来挽救生命。然而，也需考虑潜在的负面社会影响。依赖人工智能进行导航可能会降低人类的空间意识和解决问题的能力。为了最大化正面影响并最小化负面后果，必须以伦理方式开发和实施这项技术，并采取强有力的保障措施。
- en: Appendix E Prompt for Different Methods
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 E 不同方法的提示
- en: E.1 PReP Prompt
  id: totrans-208
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: E.1 PReP 提示
- en: ''
  id: totrans-209
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'prompt 1: Prompt for PReP'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 'prompt 1: Prompt for PReP'
- en: '![Refer to caption](img/56368cc9c437a7497ba3af6a584ecfc4.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/56368cc9c437a7497ba3af6a584ecfc4.png)'
- en: 'prompt 2: Prompt for PReP without planning'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 'prompt 2: Prompt for PReP without planning'
- en: '![Refer to caption](img/9c413b23871f4446f17051aff928e0a6.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/9c413b23871f4446f17051aff928e0a6.png)'
- en: 'prompt 3: Prompt for PReP without reflection'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 'prompt 3: Prompt for PReP without reflection'
- en: '![Refer to caption](img/7063c9e8d559707d426a76bd497d6dba.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/7063c9e8d559707d426a76bd497d6dba.png)'
- en: 'prompt 4: Prompt for plain PReP'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 'prompt 4: Prompt for plain PReP'
- en: '![Refer to caption](img/6142328041c25803b422568a4434c741.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/6142328041c25803b422568a4434c741.png)'
- en: E.2 Baselines Prompt
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: E.2 基线提示
- en: 'prompt 5: Prompt for InnerMonologue'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 'prompt 5: Prompt for InnerMonologue'
- en: '![Refer to caption](img/43d908fdef6786c9172f24d2c0bf277e.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/43d908fdef6786c9172f24d2c0bf277e.png)'
- en: 'prompt 6: Prompt for CaP'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 'prompt 6: Prompt for CaP'
- en: '![Refer to caption](img/7f61c229087a68c18a44afffbde11a65.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/7f61c229087a68c18a44afffbde11a65.png)'
- en: 'prompt 7: Prompt for ProgPrompt'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 'prompt 7: Prompt for ProgPrompt'
- en: '![Refer to caption](img/de8e2bbae481a2bacac495290f3399c9.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/de8e2bbae481a2bacac495290f3399c9.png)'
- en: 'prompt 8: Prompt for CoT'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 提示8：CoT提示
- en: '![Refer to caption](img/32946c7b6b36eab6ea76484426834f9c.png)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/32946c7b6b36eab6ea76484426834f9c.png)'
- en: NeurIPS Paper Checklist
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NeurIPS论文检查表
- en: '1.'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Claims
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 主张
- en: 'Question: Do the main claims made in the abstract and introduction accurately
    reflect the paper’s contributions and scope?'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 问题：摘要和引言中提出的主要主张是否准确反映了论文的贡献和范围？
- en: 'Answer: [Yes]'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答案：[是]
- en: Justification:This paper aims to address the following problem:an AI agent is
    provided with language descriptions of the goal location with respect to some
    well-known landmarks; By only observing the scene around, including recognizing
    landmarks and road network connections, the agent has to make decisions to navigate
    to the goal location without instructions.The primary contribution of this paper
    is the introduction of PReP, a novel agentic workflow based on LLM.improves navigation
    ability of the agent compared with the state-of-the-art baselines.The article
    provides detailed introduction to the workflow of PReP, and verifies its performance
    through sufficient experiments. The main claims made in the abstract and introduction
    accurately reflect the paper’s contributions and scope.
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 理由：本论文旨在解决以下问题：一个AI代理被提供了关于目标位置的语言描述，该描述相对于一些知名地标；仅通过观察周围场景，包括识别地标和道路网络连接，代理必须做出决策以在没有指令的情况下导航到目标位置。论文的主要贡献是引入PReP，一种基于LLM的创新代理工作流程，改善了代理的导航能力，相比最先进的基线有显著提升。文章详细介绍了PReP的工作流程，并通过充分的实验验证了其性能。摘要和引言中提出的主要主张准确反映了论文的贡献和范围。
- en: 'Guidelines:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指南：
- en: •
  id: totrans-234
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The answer NA means that the abstract and introduction do not include the claims
    made in the paper.
  id: totrans-235
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案NA意味着摘要和引言中没有包括论文中的主张。
- en: •
  id: totrans-236
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The abstract and/or introduction should clearly state the claims made, including
    the contributions made in the paper and important assumptions and limitations.
    A No or NA answer to this question will not be perceived well by the reviewers.
  id: totrans-237
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 摘要和/或引言应清楚说明论文中的主张，包括论文的贡献以及重要的假设和限制。对这个问题的No或NA回答不会被审稿人接受。
- en: •
  id: totrans-238
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The claims made should match theoretical and experimental results, and reflect
    how much the results can be expected to generalize to other settings.
  id: totrans-239
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 所做的主张应与理论和实验结果相匹配，并反映出结果可以在其他设置中推广的程度。
- en: •
  id: totrans-240
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: It is fine to include aspirational goals as motivation as long as it is clear
    that these goals are not attained by the paper.
  id: totrans-241
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包括愿景目标作为动机是可以的，只要明确这些目标并未在论文中实现。
- en: '2.'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Limitations
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 限制
- en: 'Question: Does the paper discuss the limitations of the work performed by the
    authors?'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 问题：论文是否讨论了作者所做工作的限制？
- en: 'Answer: [Yes]'
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答案：[是]
- en: 'Justification:Appendix [B](#A2 "Appendix B Limitations ‣ Perceive, Reflect,
    and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions")
    of the paper provides a detailed discussion of the limitations of this study.
    The primary issues highlighted are the overreliance on the GPT-4-turbo model,
    manifested as suboptimal performance on other open-source models,. Another major
    limitation is the limited size of the test set.'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 理由：论文的附录[B](#A2 "附录B 限制 ‣ 认知、反思和规划：为没有指令的目标导向城市导航设计LLM代理")提供了对本研究限制的详细讨论。主要问题是对GPT-4-turbo模型的过度依赖，表现为在其他开源模型上的表现不佳。另一个主要限制是测试集的规模有限。
- en: 'Guidelines:'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指南：
- en: •
  id: totrans-248
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The answer NA means that the paper has no limitation while the answer No means
    that the paper has limitations, but those are not discussed in the paper.
  id: totrans-249
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案NA意味着论文没有限制，而答案No则意味着论文存在限制，但这些限制未在论文中讨论。
- en: •
  id: totrans-250
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The authors are encouraged to create a separate "Limitations" section in their
    paper.
  id: totrans-251
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 鼓励作者在论文中创建一个单独的“限制”部分。
- en: •
  id: totrans-252
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The paper should point out any strong assumptions and how robust the results
    are to violations of these assumptions (e.g., independence assumptions, noiseless
    settings, model well-specification, asymptotic approximations only holding locally).
    The authors should reflect on how these assumptions might be violated in practice
    and what the implications would be.
  id: totrans-253
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 论文应指出任何强假设及其结果对这些假设违反的鲁棒性（例如，独立性假设、无噪声设置、模型良好规格、仅在局部有效的渐近近似）。作者应反思这些假设在实践中可能如何被违反以及这些违反的影响。
- en: •
  id: totrans-254
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The authors should reflect on the scope of the claims made, e.g., if the approach
    was only tested on a few datasets or with a few runs. In general, empirical results
    often depend on implicit assumptions, which should be articulated.
  id: totrans-255
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 作者应反思所做声明的范围，例如，如果该方法仅在少数数据集或少数运行中进行了测试。通常，经验结果往往依赖于隐含的假设，这些假设应加以说明。
- en: •
  id: totrans-256
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The authors should reflect on the factors that influence the performance of
    the approach. For example, a facial recognition algorithm may perform poorly when
    image resolution is low or images are taken in low lighting. Or a speech-to-text
    system might not be used reliably to provide closed captions for online lectures
    because it fails to handle technical jargon.
  id: totrans-257
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 作者应反思影响方法性能的因素。例如，当图像分辨率较低或图像在光线不足的情况下拍摄时，人脸识别算法可能表现不佳。或者一个语音转文本系统可能无法可靠地为在线讲座提供闭幕字幕，因为它无法处理技术术语。
- en: •
  id: totrans-258
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The authors should discuss the computational efficiency of the proposed algorithms
    and how they scale with dataset size.
  id: totrans-259
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 作者应讨论所提算法的计算效率以及它们如何随着数据集规模的变化而扩展。
- en: •
  id: totrans-260
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: If applicable, the authors should discuss possible limitations of their approach
    to address problems of privacy and fairness.
  id: totrans-261
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果适用，作者应讨论其方法的可能局限性，以解决隐私和公平性的问题。
- en: •
  id: totrans-262
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: While the authors might fear that complete honesty about limitations might be
    used by reviewers as grounds for rejection, a worse outcome might be that reviewers
    discover limitations that aren’t acknowledged in the paper. The authors should
    use their best judgment and recognize that individual actions in favor of transparency
    play an important role in developing norms that preserve the integrity of the
    community. Reviewers will be specifically instructed to not penalize honesty concerning
    limitations.
  id: totrans-263
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 虽然作者可能担心对局限性完全诚实可能会被审稿人用作拒稿的理由，但更糟糕的结果可能是审稿人发现论文中未承认的局限性。作者应运用最佳判断，并认识到单独的透明行动在建立保持社区完整性的规范中发挥重要作用。审稿人将特别被指示不因局限性的诚实而处罚。
- en: '3.'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: Theory Assumptions and Proofs
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 理论假设与证明
- en: 'Question: For each theoretical result, does the paper provide the full set
    of assumptions and a complete (and correct) proof?'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 问题：对于每个理论结果，论文是否提供了完整的假设集和完整（且正确）的证明？
- en: 'Answer: [N/A]'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答案：[无]
- en: 'Justification: [N/A]'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 说明：[无]
- en: 'Guidelines:'
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指南：
- en: •
  id: totrans-270
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The answer NA means that the paper does not include theoretical results.
  id: totrans-271
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案NA表示论文中不包含理论结果。
- en: •
  id: totrans-272
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
  id: totrans-273
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 论文中的所有定理、公式和证明应编号并相互引用。
- en: •
  id: totrans-274
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: All assumptions should be clearly stated or referenced in the statement of any
    theorems.
  id: totrans-275
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 所有假设应在任何定理的陈述中清晰列出或引用。
- en: •
  id: totrans-276
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The proofs can either appear in the main paper or the supplemental material,
    but if they appear in the supplemental material, the authors are encouraged to
    provide a short proof sketch to provide intuition.
  id: totrans-277
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 证明可以出现在主论文或补充材料中，但如果出现在补充材料中，作者应提供一个简短的证明草图以提供直观理解。
- en: •
  id: totrans-278
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Inversely, any informal proof provided in the core of the paper should be complemented
    by formal proofs provided in appendix or supplemental material.
  id: totrans-279
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 相反，论文核心部分提供的任何非正式证明应由附录或补充材料中的正式证明来补充。
- en: •
  id: totrans-280
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Theorems and Lemmas that the proof relies upon should be properly referenced.
  id: totrans-281
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 证明所依赖的定理和引理应得到恰当的引用。
- en: '4.'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: Experimental Result Reproducibility
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 实验结果可重复性
- en: 'Question: Does the paper fully disclose all the information needed to reproduce
    the main experimental results of the paper to the extent that it affects the main
    claims and/or conclusions of the paper (regardless of whether the code and data
    are provided or not)?'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 问题：论文是否完全披露了重现论文主要实验结果所需的所有信息，以至于影响论文的主要主张和/或结论（无论是否提供了代码和数据）？
- en: 'Answer: [Yes]'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答案：[是]
- en: 'Justification:Sections [3](#S3 "3 Task Description, Dataset, and Baseline ‣
    Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation
    without Instructions")- [5](#S5 "5 Experiments ‣ Perceive, Reflect, and Plan:
    Designing LLM Agent for Goal-Directed City Navigation without Instructions") provide
    detailed descriptions of the structure and components of PReP and the experimental
    setup.'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 说明：章节[3](#S3 "3 任务描述、数据集和基线 ‣ 感知、反思与规划：设计无指导的目标导向城市导航LLM代理")- [5](#S5 "5 实验
    ‣ 感知、反思与规划：设计无指导的目标导向城市导航LLM代理")提供了PReP结构和组成部分以及实验设置的详细描述。
- en: 'Guidelines:'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指南：
- en: •
  id: totrans-288
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The answer NA means that the paper does not include experiments.
  id: totrans-289
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案“NA”意味着论文中不包括实验。
- en: •
  id: totrans-290
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'If the paper includes experiments, a No answer to this question will not be
    perceived well by the reviewers: Making the paper reproducible is important, regardless
    of whether the code and data are provided or not.'
  id: totrans-291
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果论文包括实验，回答“No”将不会被审稿人认可：使论文具有复制性很重要，无论是否提供代码和数据。
- en: •
  id: totrans-292
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: If the contribution is a dataset and/or model, the authors should describe the
    steps taken to make their results reproducible or verifiable.
  id: totrans-293
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果贡献是数据集和/或模型，作者应描述为使其结果可复制或可验证所采取的步骤。
- en: •
  id: totrans-294
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Depending on the contribution, reproducibility can be accomplished in various
    ways. For example, if the contribution is a novel architecture, describing the
    architecture fully might suffice, or if the contribution is a specific model and
    empirical evaluation, it may be necessary to either make it possible for others
    to replicate the model with the same dataset, or provide access to the model.
    In general. releasing code and data is often one good way to accomplish this,
    but reproducibility can also be provided via detailed instructions for how to
    replicate the results, access to a hosted model (e.g., in the case of a large
    language model), releasing of a model checkpoint, or other means that are appropriate
    to the research performed.
  id: totrans-295
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 根据贡献的不同，复制性可以通过各种方式实现。例如，如果贡献是一个新颖的架构，完全描述该架构可能就足够了；或者如果贡献是一个具体的模型和实证评估，可能需要使其他人能够使用相同的数据集复制该模型，或者提供对该模型的访问权限。一般来说，发布代码和数据通常是一种很好的实现方式，但复制性也可以通过详细的复制结果的指令、访问托管模型（例如，大型语言模型的情况）、发布模型检查点或其他适合所做研究的方法来实现。
- en: •
  id: totrans-296
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: While NeurIPS does not require releasing code, the conference does require all
    submissions to provide some reasonable avenue for reproducibility, which may depend
    on the nature of the contribution. For example
  id: totrans-297
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 虽然NeurIPS不要求发布代码，但会议要求所有提交的论文提供合理的复制途径，这可能依赖于贡献的性质。例如
- en: (a)
  id: totrans-298
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (a)
- en: If the contribution is primarily a new algorithm, the paper should make it clear
    how to reproduce that algorithm.
  id: totrans-299
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果贡献主要是新算法，论文应明确如何复制该算法。
- en: (b)
  id: totrans-300
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (b)
- en: If the contribution is primarily a new model architecture, the paper should
    describe the architecture clearly and fully.
  id: totrans-301
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果贡献主要是新的模型架构，论文应清晰完整地描述该架构。
- en: (c)
  id: totrans-302
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (c)
- en: If the contribution is a new model (e.g., a large language model), then there
    should either be a way to access this model for reproducing the results or a way
    to reproduce the model (e.g., with an open-source dataset or instructions for
    how to construct the dataset).
  id: totrans-303
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果贡献是一个新模型（例如，大型语言模型），则应该有办法访问该模型以复制结果，或者有办法复制该模型（例如，使用开源数据集或构建数据集的说明）。
- en: (d)
  id: totrans-304
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (d)
- en: We recognize that reproducibility may be tricky in some cases, in which case
    authors are welcome to describe the particular way they provide for reproducibility.
    In the case of closed-source models, it may be that access to the model is limited
    in some way (e.g., to registered users), but it should be possible for other researchers
    to have some path to reproducing or verifying the results.
  id: totrans-305
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们认识到在某些情况下，复制性可能会比较棘手，在这种情况下，作者可以描述他们为实现复制性所提供的具体方法。在闭源模型的情况下，模型的访问可能会受到某种限制（例如，仅限注册用户），但其他研究人员应该能够通过某种途径实现结果的复制或验证。
- en: '5.'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: Open access to data and code
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据和代码的开放访问
- en: 'Question: Does the paper provide open access to the data and code, with sufficient
    instructions to faithfully reproduce the main experimental results, as described
    in supplemental material?'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 问题：论文是否提供了对数据和代码的开放访问，并附有足够的说明，以忠实地复制主要实验结果，如补充材料中所述？
- en: 'Answer: [Yes]'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答案：[Yes]
- en: 'Justification: The paper provides open access to both the data and code necessary
    to reproduce the main experimental results. Detailed instructions, including environment
    setups and execution commands, are clearly outlined in the supplemental materials.
    This ensures that anyone can faithfully replicate the results reported in the
    paper. Access to data and code is facilitated via a publicly available [https://anonymous.4open.science/r/PReP-13B5](https://anonymous.4open.science/r/PReP-13B5)
    provided in the supplementary section.'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 理由：论文提供了对重现主要实验结果所需的数据和代码的公开访问。补充材料中清楚地列出了详细的指令，包括环境设置和执行命令。这确保了任何人都可以真实地复制论文中报告的结果。数据和代码通过补充部分提供的公共访问链接
    [https://anonymous.4open.science/r/PReP-13B5](https://anonymous.4open.science/r/PReP-13B5)
    进行获取。
- en: 'Guidelines:'
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指南：
- en: •
  id: totrans-312
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The answer NA means that paper does not include experiments requiring code.
  id: totrans-313
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案“NA”表示论文中不包括需要代码的实验。
- en: •
  id: totrans-314
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Please see the NeurIPS code and data submission guidelines ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy))
    for more details.
  id: totrans-315
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请参阅 NeurIPS 代码和数据提交指南 ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy))
    了解更多详情。
- en: •
  id: totrans-316
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: While we encourage the release of code and data, we understand that this might
    not be possible, so “No” is an acceptable answer. Papers cannot be rejected simply
    for not including code, unless this is central to the contribution (e.g., for
    a new open-source benchmark).
  id: totrans-317
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 虽然我们鼓励发布代码和数据，但我们理解这可能不可行，因此“否”是一个可接受的答案。除非代码是贡献的核心（例如，用于新的开源基准），否则仅因未包含代码而不能拒绝论文。
- en: •
  id: totrans-318
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The instructions should contain the exact command and environment needed to
    run to reproduce the results. See the NeurIPS code and data submission guidelines
    ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy))
    for more details.
  id: totrans-319
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 指令应包含运行以重现结果所需的确切命令和环境。有关更多详细信息，请参阅 NeurIPS 代码和数据提交指南 ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy))。
- en: •
  id: totrans-320
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The authors should provide instructions on data access and preparation, including
    how to access the raw data, preprocessed data, intermediate data, and generated
    data, etc.
  id: totrans-321
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 作者应提供有关数据访问和准备的说明，包括如何访问原始数据、预处理数据、中间数据和生成数据等。
- en: •
  id: totrans-322
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The authors should provide scripts to reproduce all experimental results for
    the new proposed method and baselines. If only a subset of experiments are reproducible,
    they should state which ones are omitted from the script and why.
  id: totrans-323
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 作者应提供脚本以重现所有实验结果，包括新提出的方法和基线。如果只有部分实验可以重现，他们应说明哪些实验被省略了及其原因。
- en: •
  id: totrans-324
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: At submission time, to preserve anonymity, the authors should release anonymized
    versions (if applicable).
  id: totrans-325
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提交时，为了保持匿名，作者应发布匿名版本（如适用）。
- en: •
  id: totrans-326
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Providing as much information as possible in supplemental material (appended
    to the paper) is recommended, but including URLs to data and code is permitted.
  id: totrans-327
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 建议在补充材料（附加到论文中）中提供尽可能多的信息，但允许包含数据和代码的 URL。
- en: '6.'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '6.'
- en: Experimental Setting/Details
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 实验设置/细节
- en: 'Question: Does the paper specify all the training and test details (e.g., data
    splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary
    to understand the results?'
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 问题：论文是否指定了所有训练和测试细节（例如，数据拆分、超参数、选择方法、优化器类型等），以理解结果？
- en: 'Answer: [Yes]'
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答案：[是]
- en: 'Justification:Justification:Sections [3](#S3 "3 Task Description, Dataset,
    and Baseline ‣ Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed
    City Navigation without Instructions") to [5](#S5 "5 Experiments ‣ Perceive, Reflect,
    and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions")
    provide detailed descriptions of the experimental setup and the structure and
    components of PReP. Details of the experimental setup, such as the configuration
    of prompts, are provided in the Appendix/Supplemental Material [E](#A5 "Appendix
    E Prompt for Different Methods ‣ Perceive, Reflect, and Plan: Designing LLM Agent
    for Goal-Directed City Navigation without Instructions").'
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 理由：章节 [3](#S3 "3 任务描述、数据集和基线 ‣ 观察、反思和计划：设计用于目标导向城市导航的 LLM 代理") 到 [5](#S5 "5
    实验 ‣ 观察、反思和计划：设计用于目标导向城市导航的 LLM 代理") 提供了实验设置以及 PReP 的结构和组件的详细描述。实验设置的细节，如提示的配置，已在附录/补充材料
    [E](#A5 "附录 E 不同方法的提示 ‣ 观察、反思和计划：设计用于目标导向城市导航的 LLM 代理") 中提供。
- en: 'Guidelines:'
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指南：
- en: •
  id: totrans-334
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The answer NA means that the paper does not include experiments.
  id: totrans-335
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案NA意味着论文中不包括实验。
- en: •
  id: totrans-336
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The experimental setting should be presented in the core of the paper to a level
    of detail that is necessary to appreciate the results and make sense of them.
  id: totrans-337
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 实验设置应在论文核心部分呈现到足以理解结果和解释结果的细节水平。
- en: •
  id: totrans-338
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The full details can be provided either with the code, in appendix, or as supplemental
    material.
  id: totrans-339
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 详细信息可以通过代码、附录或补充材料提供。
- en: '7.'
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '7.'
- en: Experiment Statistical Significance
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 实验统计显著性
- en: 'Question: Does the paper report error bars suitably and correctly defined or
    other appropriate information about the statistical significance of the experiments?'
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 问题：论文是否适当且正确地报告误差条或其他关于实验统计显著性的信息？
- en: 'Answer: [Yes]'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答案：[是]
- en: 'Justification: We use student’s t-test to validate our improvement in performance.'
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 理由：我们使用学生t检验来验证我们的性能改进。
- en: 'Guidelines:'
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指南：
- en: •
  id: totrans-346
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The answer NA means that the paper does not include experiments.
  id: totrans-347
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案NA意味着论文中不包括实验。
- en: •
  id: totrans-348
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The authors should answer "Yes" if the results are accompanied by error bars,
    confidence intervals, or statistical significance tests, at least for the experiments
    that support the main claims of the paper.
  id: totrans-349
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果结果伴有误差条、置信区间或统计显著性测试，作者应回答“是”，至少对于支持论文主要主张的实验。
- en: •
  id: totrans-350
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The factors of variability that the error bars are capturing should be clearly
    stated (for example, train/test split, initialization, random drawing of some
    parameter, or overall run with given experimental conditions).
  id: totrans-351
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 误差条所捕捉的变异因素应明确说明（例如，训练/测试划分、初始化、某些参数的随机抽样或在给定实验条件下的整体运行）。
- en: •
  id: totrans-352
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The method for calculating the error bars should be explained (closed form formula,
    call to a library function, bootstrap, etc.)
  id: totrans-353
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 计算误差条的方式应加以说明（闭式公式、调用库函数、自助法等）。
- en: •
  id: totrans-354
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The assumptions made should be given (e.g., Normally distributed errors).
  id: totrans-355
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 应给出所做的假设（例如，误差正态分布）。
- en: •
  id: totrans-356
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: It should be clear whether the error bar is the standard deviation or the standard
    error of the mean.
  id: totrans-357
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 应明确误差条是标准差还是标准误。
- en: •
  id: totrans-358
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: It is OK to report 1-sigma error bars, but one should state it. The authors
    should preferably report a 2-sigma error bar than state that they have a 96% CI,
    if the hypothesis of Normality of errors is not verified.
  id: totrans-359
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 报告1-sigma误差条是可以的，但应说明。作者应优选报告2-sigma误差条而不是说明有96%的置信区间，如果未验证误差的正态性假设。
- en: •
  id: totrans-360
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: For asymmetric distributions, the authors should be careful not to show in tables
    or figures symmetric error bars that would yield results that are out of range
    (e.g. negative error rates).
  id: totrans-361
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于非对称分布，作者应小心不要在表格或图中展示对称的误差条，以免结果超出范围（例如，负的误差率）。
- en: •
  id: totrans-362
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: If error bars are reported in tables or plots, The authors should explain in
    the text how they were calculated and reference the corresponding figures or tables
    in the text.
  id: totrans-363
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果误差条在表格或图中报告，作者应在文本中解释如何计算，并引用相应的图或表。
- en: '8.'
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '8.'
- en: Experiments Compute Resources
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 实验计算资源
- en: 'Question: For each experiment, does the paper provide sufficient information
    on the computer resources (type of compute workers, memory, time of execution)
    needed to reproduce the experiments?'
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 问题：对于每个实验，论文是否提供了足够的信息关于计算资源（计算工作者类型、内存、执行时间）以便重现实验？
- en: 'Answer: [Yes]'
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答案：[是]
- en: 'Justification:In the “Further Analysis” section [5.3](#S5.SS3 "5.3 Further
    Analysis ‣ 5 Experiments ‣ Perceive, Reflect, and Plan: Designing LLM Agent for
    Goal-Directed City Navigation without Instructions"), the “Computational Cost”
    subsection, as well as the “Additional Experimental Details” section, the computational
    resources required for completing the experiments, including the costs of both
    testing and fine-tuning, are discussed in detail.'
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '理由：在“进一步分析”部分 [5.3](#S5.SS3 "5.3 Further Analysis ‣ 5 Experiments ‣ Perceive,
    Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without
    Instructions")，在“计算成本”小节以及“额外实验细节”部分中，详细讨论了完成实验所需的计算资源，包括测试和微调的成本。'
- en: 'Guidelines:'
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指南：
- en: •
  id: totrans-370
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The answer NA means that the paper does not include experiments.
  id: totrans-371
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案NA意味着论文中不包括实验。
- en: •
  id: totrans-372
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The paper should indicate the type of compute workers CPU or GPU, internal cluster,
    or cloud provider, including relevant memory and storage.
  id: totrans-373
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 论文应指明计算工作者的类型，如CPU或GPU、内部集群或云提供商，包括相关的内存和存储。
- en: •
  id: totrans-374
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The paper should provide the amount of compute required for each of the individual
    experimental runs as well as estimate the total compute.
  id: totrans-375
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 论文应提供每个实验运行所需的计算量，并估算总计算量。
- en: •
  id: totrans-376
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The paper should disclose whether the full research project required more compute
    than the experiments reported in the paper (e.g., preliminary or failed experiments
    that didn’t make it into the paper).
  id: totrans-377
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 论文应披露是否整个研究项目所需的计算量超过了论文中报告的实验（例如，未纳入论文的初步或失败实验）。
- en: '9.'
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '9.'
- en: Code Of Ethics
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 《伦理规范》
- en: 'Question: Does the research conducted in the paper conform, in every respect,
    with the NeurIPS Code of Ethics [https://neurips.cc/public/EthicsGuidelines](https://neurips.cc/public/EthicsGuidelines)?'
  id: totrans-380
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 问题：论文中的研究是否在各个方面符合 NeurIPS 《伦理规范》[https://neurips.cc/public/EthicsGuidelines](https://neurips.cc/public/EthicsGuidelines)？
- en: 'Answer: [Yes]'
  id: totrans-381
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答案：[是]
- en: 'Justification:We ensure that this work complies with the NeurIPS Code of Ethics
    and make ethical analysis in Appendix [C](#A3 "Appendix C Ethical Analysis ‣ Perceive,
    Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without
    Instructions").'
  id: totrans-382
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '理由：我们确保这项工作符合 NeurIPS 《伦理规范》，并在附录 [C](#A3 "Appendix C Ethical Analysis ‣ Perceive,
    Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without
    Instructions") 中进行伦理分析。'
- en: 'Guidelines:'
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指南：
- en: •
  id: totrans-384
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
  id: totrans-385
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案 NA 表示作者尚未审阅 NeurIPS 《伦理规范》。
- en: •
  id: totrans-386
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: If the authors answer No, they should explain the special circumstances that
    require a deviation from the Code of Ethics.
  id: totrans-387
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果作者回答“否”，他们应解释需要偏离《伦理规范》的特殊情况。
- en: •
  id: totrans-388
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The authors should make sure to preserve anonymity (e.g., if there is a special
    consideration due to laws or regulations in their jurisdiction).
  id: totrans-389
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 作者应确保保留匿名性（例如，如果由于其管辖区的法律或规定有特殊考虑）。
- en: '10.'
  id: totrans-390
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '10.'
- en: Broader Impacts
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 广泛影响
- en: 'Question: Does the paper discuss both potential positive societal impacts and
    negative societal impacts of the work performed?'
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 问题：论文是否讨论了所做工作的潜在积极社会影响和负面社会影响？
- en: 'Answer: [Yes]'
  id: totrans-393
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答案：[是]
- en: 'Justification: We have discussed the broader impact in Appendix [D](#A4 "Appendix
    D Broader Impacts ‣ Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed
    City Navigation without Instructions"). The PReP agent we designed may have positive
    impacts for helping the blind to navigate in unknown environment and also other
    applications.'
  id: totrans-394
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '理由：我们在附录 [D](#A4 "Appendix D Broader Impacts ‣ Perceive, Reflect, and Plan:
    Designing LLM Agent for Goal-Directed City Navigation without Instructions") 中讨论了广泛影响。我们设计的
    PReP 代理可能对帮助盲人在未知环境中导航以及其他应用有积极影响。'
- en: 'Guidelines:'
  id: totrans-395
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指南：
- en: •
  id: totrans-396
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The answer NA means that there is no societal impact of the work performed.
  id: totrans-397
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案 NA 表示所做工作没有社会影响。
- en: •
  id: totrans-398
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: If the authors answer NA or No, they should explain why their work has no societal
    impact or why the paper does not address societal impact.
  id: totrans-399
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果作者回答 NA 或“否”，他们应解释为什么他们的工作没有社会影响或为什么论文没有涉及社会影响。
- en: •
  id: totrans-400
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Examples of negative societal impacts include potential malicious or unintended
    uses (e.g., disinformation, generating fake profiles, surveillance), fairness
    considerations (e.g., deployment of technologies that could make decisions that
    unfairly impact specific groups), privacy considerations, and security considerations.
  id: totrans-401
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 负面社会影响的例子包括潜在的恶意或无意使用（例如，虚假信息、生成假个人资料、监控）、公平性考虑（例如，部署可能会对特定群体产生不公平影响的技术）、隐私考虑和安全考虑。
- en: •
  id: totrans-402
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The conference expects that many papers will be foundational research and not
    tied to particular applications, let alone deployments. However, if there is a
    direct path to any negative applications, the authors should point it out. For
    example, it is legitimate to point out that an improvement in the quality of generative
    models could be used to generate deepfakes for disinformation. On the other hand,
    it is not needed to point out that a generic algorithm for optimizing neural networks
    could enable people to train models that generate Deepfakes faster.
  id: totrans-403
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 会议预计许多论文将是基础研究，而不是与特定应用或部署相关。然而，如果存在直接的负面应用路径，作者应指出。例如，指出生成模型质量的提高可能被用来生成虚假信息深度伪造内容是合理的。另一方面，指出一种通用的神经网络优化算法可能使人们更快地训练生成深度伪造内容的模型则没有必要。
- en: •
  id: totrans-404
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The authors should consider possible harms that could arise when the technology
    is being used as intended and functioning correctly, harms that could arise when
    the technology is being used as intended but gives incorrect results, and harms
    following from (intentional or unintentional) misuse of the technology.
  id: totrans-405
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 作者应考虑在技术按预期使用并正确运行时可能产生的危害，技术按预期使用但产生错误结果时可能产生的危害，以及由于（有意或无意）滥用技术产生的危害。
- en: •
  id: totrans-406
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: If there are negative societal impacts, the authors could also discuss possible
    mitigation strategies (e.g., gated release of models, providing defenses in addition
    to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system
    learns from feedback over time, improving the efficiency and accessibility of
    ML).
  id: totrans-407
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果存在负面的社会影响，作者还可以讨论可能的缓解策略（例如，模型的限制发布、提供除攻击外的防御措施、监控滥用的机制、监控系统如何从反馈中学习的机制、提高机器学习的效率和可及性）。
- en: '11.'
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '11.'
- en: Safeguards
  id: totrans-409
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 保护措施
- en: 'Question: Does the paper describe safeguards that have been put in place for
    responsible release of data or models that have a high risk for misuse (e.g.,
    pretrained language models, image generators, or scraped datasets)?'
  id: totrans-410
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 问题：论文是否描述了为负责任地发布具有高风险的滥用（例如，预训练语言模型、图像生成器或抓取的数据集）而采取的保护措施？
- en: 'Answer: [N/A]'
  id: totrans-411
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答复：[无]
- en: Justification:[N/A]
  id: totrans-412
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正当性：[无]
- en: 'Guidelines:'
  id: totrans-413
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指南：
- en: •
  id: totrans-414
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The answer NA means that the paper poses no such risks.
  id: totrans-415
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答复NA表示论文没有此类风险。
- en: •
  id: totrans-416
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Released models that have a high risk for misuse or dual-use should be released
    with necessary safeguards to allow for controlled use of the model, for example
    by requiring that users adhere to usage guidelines or restrictions to access the
    model or implementing safety filters.
  id: totrans-417
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 发布的模型如果存在高风险的滥用或双重用途，应该发布必要的保护措施以允许对模型进行受控使用，例如要求用户遵守使用指南或限制访问模型，或实施安全过滤器。
- en: •
  id: totrans-418
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Datasets that have been scraped from the Internet could pose safety risks. The
    authors should describe how they avoided releasing unsafe images.
  id: totrans-419
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从互联网抓取的数据集可能存在安全风险。作者应描述他们如何避免发布不安全的图像。
- en: •
  id: totrans-420
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We recognize that providing effective safeguards is challenging, and many papers
    do not require this, but we encourage authors to take this into account and make
    a best faith effort.
  id: totrans-421
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们认识到提供有效保护措施是具有挑战性的，许多论文并不要求此项，但我们鼓励作者考虑这一点并尽最大努力。
- en: '12.'
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '12.'
- en: Licenses for existing assets
  id: totrans-423
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现有资产的许可证
- en: 'Question: Are the creators or original owners of assets (e.g., code, data,
    models), used in the paper, properly credited and are the license and terms of
    use explicitly mentioned and properly respected?'
  id: totrans-424
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 问题：论文中使用的资产（例如代码、数据、模型）的创作者或原始所有者是否得到适当的致谢，并且许可证和使用条款是否明确提及并得到适当尊重？
- en: 'Answer: [Yes]'
  id: totrans-425
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答复：[是]
- en: 'Justification: We have cited the original paper that produced the code package
    or dataset, respectively the LLaVA with Apache-2.0 and LLaMA-Factory with Apache-2.0.'
  id: totrans-426
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正当性：我们已经引用了生成代码包或数据集的原始论文，分别为LLaVA的Apache-2.0许可证和LLaMA-Factory的Apache-2.0许可证。
- en: 'Guidelines:'
  id: totrans-427
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指南：
- en: •
  id: totrans-428
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The answer NA means that the paper does not use existing assets.
  id: totrans-429
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答复NA表示论文未使用现有资产。
- en: •
  id: totrans-430
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The authors should cite the original paper that produced the code package or
    dataset.
  id: totrans-431
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 作者应引用生成代码包或数据集的原始论文。
- en: •
  id: totrans-432
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The authors should state which version of the asset is used and, if possible,
    include a URL.
  id: totrans-433
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 作者应说明使用的是哪个版本的资产，如果可能，还应包括一个网址。
- en: •
  id: totrans-434
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The name of the license (e.g., CC-BY 4.0) should be included for each asset.
  id: totrans-435
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每个资产应包括许可证名称（例如CC-BY 4.0）。
- en: •
  id: totrans-436
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: For scraped data from a particular source (e.g., website), the copyright and
    terms of service of that source should be provided.
  id: totrans-437
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于从特定来源（例如网站）抓取的数据，应提供该来源的版权和服务条款。
- en: •
  id: totrans-438
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: If assets are released, the license, copyright information, and terms of use
    in the package should be provided. For popular datasets, [paperswithcode.com/datasets](paperswithcode.com/datasets)
    has curated licenses for some datasets. Their licensing guide can help determine
    the license of a dataset.
  id: totrans-439
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果资产已发布，包中应提供许可证、版权信息和使用条款。对于流行的数据集，[paperswithcode.com/datasets](paperswithcode.com/datasets)已经为一些数据集策划了许可证。他们的许可证指南可以帮助确定数据集的许可证。
- en: •
  id: totrans-440
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: For existing datasets that are re-packaged, both the original license and the
    license of the derived asset (if it has changed) should be provided.
  id: totrans-441
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于重新打包的现有数据集，应提供原始许可证和派生资产的许可证（如果发生变化）。
- en: •
  id: totrans-442
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: If this information is not available online, the authors are encouraged to reach
    out to the asset’s creators.
  id: totrans-443
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果此信息未在线提供，建议作者联系资产的创建者。
- en: '13.'
  id: totrans-444
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '13.'
- en: New Assets
  id: totrans-445
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 新资产
- en: 'Question: Are new assets introduced in the paper well documented and is the
    documentation provided alongside the assets?'
  id: totrans-446
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 问题：论文中引入的新资产是否有详细的文档，并且文档是否与资产一同提供？
- en: 'Answer: [Yes]'
  id: totrans-447
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答案：[Yes]
- en: 'Justification: The article introduces a new model PReP and its corresponding
    dataset. The relevant content can be viewed on [https://anonymous.4open.science/r/PReP-13B5](https://anonymous.4open.science/r/PReP-13B5)'
  id: totrans-448
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 说明：文章介绍了一个新的模型 PReP 及其对应的数据集。相关内容可在 [https://anonymous.4open.science/r/PReP-13B5](https://anonymous.4open.science/r/PReP-13B5)
    查看
- en: 'Guidelines:'
  id: totrans-449
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指南：
- en: •
  id: totrans-450
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The answer NA means that the paper does not release new assets.
  id: totrans-451
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案 NA 表示该论文没有发布新的资产。
- en: •
  id: totrans-452
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Researchers should communicate the details of the dataset/code/model as part
    of their submissions via structured templates. This includes details about training,
    license, limitations, etc.
  id: totrans-453
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 研究人员应通过结构化模板在提交中传达数据集/代码/模型的详细信息。这包括关于训练、许可证、限制等方面的细节。
- en: •
  id: totrans-454
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The paper should discuss whether and how consent was obtained from people whose
    asset is used.
  id: totrans-455
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 论文应讨论是否以及如何从使用其资产的人那里获得了同意。
- en: •
  id: totrans-456
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: At submission time, remember to anonymize your assets (if applicable). You can
    either create an anonymized URL or include an anonymized zip file.
  id: totrans-457
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提交时，请记得对您的资产进行匿名化处理（如果适用）。您可以创建一个匿名化的 URL 或包含一个匿名化的压缩文件。
- en: '14.'
  id: totrans-458
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '14.'
- en: Crowdsourcing and Research with Human Subjects
  id: totrans-459
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 众包和与人类受试者相关的研究
- en: 'Question: For crowdsourcing experiments and research with human subjects, does
    the paper include the full text of instructions given to participants and screenshots,
    if applicable, as well as details about compensation (if any)?'
  id: totrans-460
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 问题：对于众包实验和与人类受试者相关的研究，论文是否包含了提供给参与者的指令全文和截图（如果适用），以及关于补偿（如果有）的详细信息？
- en: 'Answer: [N/A]'
  id: totrans-461
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答案：[N/A]
- en: Justification:No research with Human Subjects
  id: totrans-462
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 说明：没有涉及人类受试者的研究
- en: 'Guidelines:'
  id: totrans-463
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指南：
- en: •
  id: totrans-464
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The answer NA means that the paper does not involve crowdsourcing nor research
    with human subjects.
  id: totrans-465
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案 NA 表示该论文不涉及众包或与人类受试者相关的研究。
- en: •
  id: totrans-466
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Including this information in the supplemental material is fine, but if the
    main contribution of the paper involves human subjects, then as much detail as
    possible should be included in the main paper.
  id: totrans-467
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将这些信息包含在补充材料中是可以的，但如果论文的主要贡献涉及人类受试者，则应尽可能详细地在主文中包含这些信息。
- en: •
  id: totrans-468
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: According to the NeurIPS Code of Ethics, workers involved in data collection,
    curation, or other labor should be paid at least the minimum wage in the country
    of the data collector.
  id: totrans-469
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 根据 NeurIPS 行为规范，参与数据收集、整理或其他劳动的工作人员应至少获得数据收集者所在国家的最低工资。
- en: '15.'
  id: totrans-470
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '15.'
- en: Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
    Subjects
  id: totrans-471
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 人类受试者研究的机构审查委员会（IRB）批准或等效批准
- en: 'Question: Does the paper describe potential risks incurred by study participants,
    whether such risks were disclosed to the subjects, and whether Institutional Review
    Board (IRB) approvals (or an equivalent approval/review based on the requirements
    of your country or institution) were obtained?'
  id: totrans-472
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 问题：论文是否描述了研究参与者可能面临的风险，这些风险是否已告知受试者，以及是否获得了机构审查委员会（IRB）批准（或根据您所在国家或机构的要求的等效批准/审查）？
- en: 'Answer: [N/A]'
  id: totrans-473
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答案：[N/A]
- en: 'Justification: No research with human subjects'
  id: totrans-474
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 说明：没有涉及人类受试者的研究
- en: 'Guidelines:'
  id: totrans-475
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指南：
- en: •
  id: totrans-476
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The answer NA means that the paper does not involve crowdsourcing nor research
    with human subjects.
  id: totrans-477
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案 NA 表示该论文不涉及众包或与人类受试者相关的研究。
- en: •
  id: totrans-478
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Depending on the country in which research is conducted, IRB approval (or equivalent)
    may be required for any human subjects research. If you obtained IRB approval,
    you should clearly state this in the paper.
  id: totrans-479
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 根据研究进行的国家，可能需要对任何人类受试者研究进行 IRB 批准（或等效）。如果您获得了 IRB 批准，应在论文中明确说明。
- en: •
  id: totrans-480
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We recognize that the procedures for this may vary significantly between institutions
    and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and
    the guidelines for their institution.
  id: totrans-481
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们认识到，相关程序在不同机构和地点之间可能存在显著差异，我们期望作者遵守 NeurIPS 行为规范以及他们所在机构的指南。
- en: •
  id: totrans-482
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: For initial submissions, do not include any information that would break anonymity
    (if applicable), such as the institution conducting the review.
  id: totrans-483
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于初稿提交，请不要包含可能破坏匿名性的任何信息（如果适用），例如进行审查的机构。
