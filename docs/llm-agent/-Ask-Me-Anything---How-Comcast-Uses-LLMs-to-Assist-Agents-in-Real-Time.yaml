- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 18:47:05'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-08 18:47:05'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '“Ask Me Anything”: How Comcast Uses LLMs to Assist Agents in Real Time'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: “问我任何事”：康卡斯特如何利用LLMs实时辅助客服人员
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2405.00801](https://ar5iv.labs.arxiv.org/html/2405.00801)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2405.00801](https://ar5iv.labs.arxiv.org/html/2405.00801)
- en: Scott Rome [scott˙rome@comcast.com](mailto:scott%CB%99rome@comcast.com) [0000-0003-0270-7192](https://orcid.org/0000-0003-0270-7192
    "ORCID identifier") ,  Tianwen Chen [tianwen˙chen@comcast.com](mailto:tianwen%CB%99chen@comcast.com)
    [0009-0008-0477-7366](https://orcid.org/0009-0008-0477-7366 "ORCID identifier")
    Comcast AI TechnologiesPhiladelphiaPennsylvaniaUSA ,  Raphael Tang [raphael˙tang@comcast.com](mailto:raphael%CB%99tang@comcast.com)
    [0009-0007-2873-892X](https://orcid.org/0009-0007-2873-892X "ORCID identifier")
    Comcast AI TechnologiesPhiladelphiaPennsylvaniaUSA ,  Luwei Zhou [luwei˙zhou@comcast.com](mailto:luwei%CB%99zhou@comcast.com)
    [0009-0009-1862-3058](https://orcid.org/0009-0009-1862-3058 "ORCID identifier")
     and  Ferhan Ture [ferhan˙ture@comcast.com](mailto:ferhan%CB%99ture@comcast.com)
    [0000-0002-5585-157X](https://orcid.org/0000-0002-5585-157X "ORCID identifier")
    Comcast AI TechnologiesPhiladelphiaPennsylvaniaUSA(2024)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Scott Rome [scott˙rome@comcast.com](mailto:scott%CB%99rome@comcast.com) [0000-0003-0270-7192](https://orcid.org/0000-0003-0270-7192
    "ORCID identifier")，Tianwen Chen [tianwen˙chen@comcast.com](mailto:tianwen%CB%99chen@comcast.com)
    [0009-0008-0477-7366](https://orcid.org/0009-0008-0477-7366 "ORCID identifier")
    Comcast AI TechnologiesPhiladelphiaPennsylvaniaUSA，Raphael Tang [raphael˙tang@comcast.com](mailto:raphael%CB%99tang@comcast.com)
    [0009-0007-2873-892X](https://orcid.org/0009-0007-2873-892X "ORCID identifier")
    Comcast AI TechnologiesPhiladelphiaPennsylvaniaUSA，Luwei Zhou [luwei˙zhou@comcast.com](mailto:luwei%CB%99zhou@comcast.com)
    [0009-0009-1862-3058](https://orcid.org/0009-0009-1862-3058 "ORCID identifier")
    和 Ferhan Ture [ferhan˙ture@comcast.com](mailto:ferhan%CB%99ture@comcast.com) [0000-0002-5585-157X](https://orcid.org/0000-0002-5585-157X
    "ORCID identifier") Comcast AI TechnologiesPhiladelphiaPennsylvaniaUSA(2024)
- en: '“Ask Me Anything”: How Comcast Uses LLMs to'
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: “问我任何事”：康卡斯特如何利用LLMs
- en: Assist Agents in Real Time
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 实时辅助客服人员
- en: Scott Rome [scott˙rome@comcast.com](mailto:scott%CB%99rome@comcast.com) [0000-0003-0270-7192](https://orcid.org/0000-0003-0270-7192
    "ORCID identifier") ,  Tianwen Chen [tianwen˙chen@comcast.com](mailto:tianwen%CB%99chen@comcast.com)
    [0009-0008-0477-7366](https://orcid.org/0009-0008-0477-7366 "ORCID identifier")
    Comcast AI TechnologiesPhiladelphiaPennsylvaniaUSA ,  Raphael Tang [raphael˙tang@comcast.com](mailto:raphael%CB%99tang@comcast.com)
    [0009-0007-2873-892X](https://orcid.org/0009-0007-2873-892X "ORCID identifier")
    Comcast AI TechnologiesPhiladelphiaPennsylvaniaUSA ,  Luwei Zhou [luwei˙zhou@comcast.com](mailto:luwei%CB%99zhou@comcast.com)
    [0009-0009-1862-3058](https://orcid.org/0009-0009-1862-3058 "ORCID identifier")
     and  Ferhan Ture [ferhan˙ture@comcast.com](mailto:ferhan%CB%99ture@comcast.com)
    [0000-0002-5585-157X](https://orcid.org/0000-0002-5585-157X "ORCID identifier")
    Comcast AI TechnologiesPhiladelphiaPennsylvaniaUSA(2024)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Scott Rome [scott˙rome@comcast.com](mailto:scott%CB%99rome@comcast.com) [0000-0003-0270-7192](https://orcid.org/0000-0003-0270-7192
    "ORCID identifier")，Tianwen Chen [tianwen˙chen@comcast.com](mailto:tianwen%CB%99chen@comcast.com)
    [0009-0008-0477-7366](https://orcid.org/0009-0008-0477-7366 "ORCID identifier")
    Comcast AI TechnologiesPhiladelphiaPennsylvaniaUSA，Raphael Tang [raphael˙tang@comcast.com](mailto:raphael%CB%99tang@comcast.com)
    [0009-0007-2873-892X](https://orcid.org/0009-0007-2873-892X "ORCID identifier")
    Comcast AI TechnologiesPhiladelphiaPennsylvaniaUSA，Luwei Zhou [luwei˙zhou@comcast.com](mailto:luwei%CB%99zhou@comcast.com)
    [0009-0009-1862-3058](https://orcid.org/0009-0009-1862-3058 "ORCID identifier")
    和 Ferhan Ture [ferhan˙ture@comcast.com](mailto:ferhan%CB%99ture@comcast.com) [0000-0002-5585-157X](https://orcid.org/0000-0002-5585-157X
    "ORCID identifier") Comcast AI TechnologiesPhiladelphiaPennsylvaniaUSA(2024)
- en: Abstract.
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: Customer service is how companies interface with their customers. It can contribute
    heavily towards the overall customer satisfaction. However, high-quality service
    can become expensive, creating an incentive to make it as cost efficient as possible
    and prompting most companies to utilize AI-powered assistants, or ”chat bots”.
    On the other hand, human-to-human interaction is still desired by customers, especially
    when it comes to complex scenarios such as disputes and sensitive topics like
    bill payment.¹¹1[https://bit.ly/3yaNO9t](https://bit.ly/3yaNO9t)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 客户服务是公司与客户互动的方式。它对整体客户满意度的贡献巨大。然而，高质量服务可能变得昂贵，促使公司尽可能降低成本，并使大多数公司采用AI驱动的助手或“聊天机器人”。另一方面，客户仍然希望进行人际互动，尤其是在处理复杂的情境如争议和敏感话题如账单支付时。¹¹1[https://bit.ly/3yaNO9t](https://bit.ly/3yaNO9t)
- en: This raises the bar for customer service agents. They need to accurately understand
    the customer’s question or concern, identify a solution that is acceptable yet
    feasible (and within the company’s policy), all while handling multiple conversations
    at once.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这提高了客户服务代理的要求。他们需要准确理解客户的问题或关切，找出一个可接受且可行的解决方案（符合公司的政策），同时处理多个对话。
- en: In this work, we introduce “Ask Me Anything” (AMA) as an add-on feature to an
    agent-facing customer service interface. AMA allows agents to ask questions to
    a large language model (LLM) on demand, as they are handling customer conversations—the
    LLM provides accurate responses in real-time, reducing the amount of context switching
    the agent needs. In our internal experiments, we find that agents using AMA versus
    a traditional search experience spend approximately 10% fewer seconds per conversation
    containing a search, translating to millions of dollars of savings annually. Agents
    that used the AMA feature provided positive feedback nearly 80% of the time, demonstrating
    its usefulness as an AI-assisted feature for customer care.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们将“问我任何事”（AMA）作为一种附加功能引入到面向代理的客户服务界面中。AMA允许代理在处理客户对话时，按需向大型语言模型（LLM）提问——LLM实时提供准确的回答，减少了代理需要进行的上下文切换。在我们的内部实验中，我们发现使用AMA的代理在包含搜索的对话中每次花费的时间比使用传统搜索体验少约10%，这意味着每年节省了数百万美元。使用AMA功能的代理中，近80%的人提供了积极反馈，证明了它作为客户服务中AI辅助功能的实用性。
- en: 'rag, llm, customer care, assistive AI, vector db, reranking^†^†journalyear:
    2024^†^†copyright: rightsretained^†^†conference: Proceedings of the 47th International
    ACM SIGIR Conference on Research and Development in Information Retrieval; July
    14–18, 2024; Washington, DC, USA^†^†doi: 10.1145/3626772.3661345^†^†isbn: 979-8-4007-0431-4/24/07^†^†ccs:
    Information systems Retrieval models and ranking^†^†ccs: Information systems Language
    models'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: rag，llm，客户服务，辅助型 AI，向量数据库，重新排序^†^†期刊年份：2024^†^†版权：保留权利^†^†会议：第47届国际 ACM SIGIR
    信息检索研究与开发会议论文集；2024年7月14日至18日；美国华盛顿特区^†^†doi：10.1145/3626772.3661345^†^†isbn：979-8-4007-0431-4/24/07^†^†ccs：信息系统
    检索模型与排序^†^†ccs：信息系统 语言模型
- en: 1\. Introduction
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 引言
- en: Comcast, like many other companies, provides customer service through various
    communication channels. Many self-service solutions are available on the mobile
    “Xfinity” app (e.g., reviewing latest bill) which also has an option to chat with
    an AI-powered bot named “Xfinity Assistant”. While these digital automation capabilities
    have been replacing human customer representatives (also referred to as ”agents”)
    for many tasks, there are still many situations that require human-to-human interactions.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 像许多其他公司一样，Comcast通过各种通信渠道提供客户服务。在移动“Xfinity”应用程序上提供了许多自助服务解决方案（例如，查看最新账单），该应用程序还提供与名为“Xfinity
    Assistant”的AI驱动的机器人聊天的选项。虽然这些数字化自动化功能已取代了许多人类客户代表（也称为“代理”）的许多任务，但仍然有许多情况需要人际互动。
- en: A customer trying to simply look up information about their profile, internet
    services, or bill, they should be able to do it without an agent’s assistance.
    This also holds true if they are trying to carry out a relatively straightforward
    task like rescheduling their appointment or make a change to their services.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 客户如果只是想查询有关他们的个人资料、互联网服务或账单的信息，他们应该能够在没有代理协助的情况下完成。这同样适用于他们尝试进行相对简单的任务，比如重新安排预约或更改服务。
- en: Past studies show a human-human interaction is preferred over a human-computer
    one in certain customer service situations(Wowak, [[n. d.]](#bib.bib22)). For
    example, agents might outperform bots in situations that require creative problem
    solving. In other situations, the customer might simply prefer to talk to a agent
    to benefit from their empathy and emotional intelligence, or to navigate through
    cultural sensitivities.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 以往研究表明，在某些客户服务情境中，人际互动被优先于人机互动（Wowak，[[n. d.]](#bib.bib22)）。例如，代理在需要创造性解决问题的情况下可能优于机器人。在其他情况下，客户可能更愿意与代理交谈，以便从他们的同理心和情感智能中受益，或者应对文化敏感性问题。
- en: At Comcast, an internal custom tool suite aims to help agents to effectively
    and efficiently handle such conversations. However, it still often requires manually
    looking up information in multiple places, relating it to what the customer is
    saying, then crafting a relevant response that aligns with the communication guidelines.
    In this paper, we introduce a new feature to this tool suite called “Ask Me Anything”
    (AMA). It leverages large language models (LLMs) following a retrieval-augmented
    generation (RAG) approach to generate contextually relevant responses by combining
    internal knowledge sources, indexing existing knowledge articles efficiently at
    build time, retrieving relevant chunks of text for a given question at query time,
    then feeding them to a *Reader* LLM to generate a succinct answer with citations
    provided as reference. In the next section, we describe the methodology in more
    detail.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在康卡斯特，我们的一个内部定制工具套件旨在帮助代理有效且高效地处理此类对话。然而，这仍然需要在多个地方手动查找信息，将其与客户所说的内容关联起来，然后根据沟通指南制定相关回复。在本文中，我们介绍了一个名为“问我任何事”（AMA）的新功能。它利用大型语言模型（LLMs），采用检索增强生成（RAG）方法，通过结合内部知识源，在构建时高效索引现有知识文章，在查询时检索与给定问题相关的文本块，然后将这些文本块输入到*Reader*
    LLM中，以生成简洁的答案并提供引用作为参考。在下一节中，我们将更详细地描述该方法。
- en: 2\. Methodology
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 方法
- en: 'Our system follows a typical RAG implementation with modifications to improve
    performance on proprietary questions. First, the documents are preprocessed to
    text and chunked, the chunks are embedded then stored with metadata (e.g., associated
    URL for citations, an identifier, the title, etc.) in a vector database. We describe
    our specific choices for processing and embeddings in Section [2.1](#S2.SS1 "2.1\.
    Document Preprocessing ‣ 2\. Methodology ‣ “Ask Me Anything”: How Comcast Uses
    LLMs to Assist Agents in Real Time") and Section [2.2](#S2.SS2 "2.2\. Retrieving
    Relevant Text Snippets ‣ 2\. Methodology ‣ “Ask Me Anything”: How Comcast Uses
    LLMs to Assist Agents in Real Time") respectively with some experimental justification.
    Next, we detail how we train and evaluate a reranking model using synthetic data
    to improve search result relevancy in Section [2.3](#S2.SS3 "2.3\. Reranking Search
    Results ‣ 2\. Methodology ‣ “Ask Me Anything”: How Comcast Uses LLMs to Assist
    Agents in Real Time"). Finally, we discuss how we generate answers followed by
    how we evaluate the system in Section [2.4](#S2.SS4 "2.4\. Generating the Answer
    from Snippets ‣ 2\. Methodology ‣ “Ask Me Anything”: How Comcast Uses LLMs to
    Assist Agents in Real Time") and [2.5](#S2.SS5 "2.5\. Offline Response Evaluation
    ‣ 2\. Methodology ‣ “Ask Me Anything”: How Comcast Uses LLMs to Assist Agents
    in Real Time").'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '我们的系统采用了典型的RAG实现，并进行了修改以提高在专有问题上的性能。首先，文档会被预处理为文本并进行分块，这些分块会被嵌入并存储在向量数据库中，附带元数据（例如，用于引用的关联网址、标识符、标题等）。我们在[2.1](#S2.SS1
    "2.1\. Document Preprocessing ‣ 2\. Methodology ‣ “Ask Me Anything”: How Comcast
    Uses LLMs to Assist Agents in Real Time")节和[2.2](#S2.SS2 "2.2\. Retrieving Relevant
    Text Snippets ‣ 2\. Methodology ‣ “Ask Me Anything”: How Comcast Uses LLMs to
    Assist Agents in Real Time")节中分别描述了我们在处理和嵌入方面的具体选择及其实验依据。接下来，我们详细说明了如何使用合成数据训练和评估重新排序模型，以提高搜索结果的相关性，这在[2.3](#S2.SS3
    "2.3\. Reranking Search Results ‣ 2\. Methodology ‣ “Ask Me Anything”: How Comcast
    Uses LLMs to Assist Agents in Real Time")节中进行了介绍。最后，我们讨论了如何生成答案以及如何评估系统，这在[2.4](#S2.SS4
    "2.4\. Generating the Answer from Snippets ‣ 2\. Methodology ‣ “Ask Me Anything”:
    How Comcast Uses LLMs to Assist Agents in Real Time")节和[2.5](#S2.SS5 "2.5\. Offline
    Response Evaluation ‣ 2\. Methodology ‣ “Ask Me Anything”: How Comcast Uses LLMs
    to Assist Agents in Real Time")节中进行了探讨。'
- en: 2.1\. Document Preprocessing
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1\. 文档预处理
- en: We receive documents from various internal clients in different formats. We
    standardize the documents into plain text and chunk each document into snippets
    using Deepset.ai’s Haystack library (Pietsch et al., [2019](#bib.bib14)). In order
    to uniquely reference each chunk of every document after retrieval, we assign
    an origin identifier to each document and a local identifier to each chunk. Finally,
    we implement role-based access control on each document, so different users can
    only view the documents for which they have permission.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从各种内部客户端接收不同格式的文档。我们将文档标准化为纯文本，并使用Deepset.ai的Haystack库（Pietsch等，[2019](#bib.bib14)）将每个文档分块。为了在检索后唯一地引用每个文档的每个块，我们为每个文档分配一个来源标识符，为每个块分配一个本地标识符。最后，我们对每个文档实施基于角色的访问控制，以便不同的用户只能查看他们有权限的文档。
- en: 'In [1(a)](#S2.T1.st1 "1(a) ‣ 2.1\. Document Preprocessing ‣ 2\. Methodology
    ‣ “Ask Me Anything”: How Comcast Uses LLMs to Assist Agents in Real Time"), we
    show various chunking parameters for Haystack’s preprocessor and their evaluation
    scores. The metric derivation is explained in Section [2.5](#S2.SS5 "2.5\. Offline
    Response Evaluation ‣ 2\. Methodology ‣ “Ask Me Anything”: How Comcast Uses LLMs
    to Assist Agents in Real Time") (Answer quality assumed the top 3 items were passed
    to the LLM). We observed a large improvement from setting a higher `max_chars_check`,
    which we used as a proxy for limiting the size of each snippet given to the LLM.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '在[1(a)](#S2.T1.st1 "1(a) ‣ 2.1\. Document Preprocessing ‣ 2\. Methodology ‣
    “Ask Me Anything”: How Comcast Uses LLMs to Assist Agents in Real Time")中，我们展示了Haystack预处理器的各种分块参数及其评估分数。度量标准的推导在第[2.5](#S2.SS5
    "2.5\. Offline Response Evaluation ‣ 2\. Methodology ‣ “Ask Me Anything”: How
    Comcast Uses LLMs to Assist Agents in Real Time")节中解释（假设回答质量前3项已传递给LLM）。我们观察到，通过设置更高的`max_chars_check`，显著提高了性能，我们将其用作限制每个片段大小的代理。'
- en: Table 1. Chunking parameters and evaluation of three different settings.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 表1. 分块参数及三种不同设置的评估。
- en: '| Parameter | A | B | C |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| Parameter | A | B | C |'
- en: '| clean_empty_lines | true |  |  |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| clean_empty_lines | true |  |  |'
- en: '| clean_whitespace | true |  |  |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| clean_whitespace | true |  |  |'
- en: '| clean_header_footer | true |  |  |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| clean_header_footer | true |  |  |'
- en: '| split_by | word |  |  |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| split_by | word |  |  |'
- en: '| split_length | 300 | 100 |  |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| split_length | 300 | 100 |  |'
- en: '| split_overlap | 50 | 25 |  |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| split_overlap | 50 | 25 |  |'
- en: '| split_respect_sentence_boundary | true |  |  |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| split_respect_sentence_boundary | true |  |  |'
- en: '| max_chars_check | 1000 |  | 3000 |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| max_chars_check | 1000 |  | 3000 |'
- en: '| Metric |  |  |  |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| Metric |  |  |  |'
- en: '| Answer Quality | - | -5.7% | +13.2% |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| Answer Quality | - | -5.7% | +13.2% |'
- en: '| MRR | - | -13.3% | 0.0% |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| MRR | - | -13.3% | 0.0% |'
- en: '| R@3 | - | -7.9% | 0.0% |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| R@3 | - | -7.9% | 0.0% |'
- en: '| NDCG | - | -10.0% | 0.0% |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| NDCG | - | -10.0% | 0.0% |'
- en: '(a) For clarity, only changes from setting $A$. Metrics are defined in Section
    [2.5](#S2.SS5 "2.5\. Offline Response Evaluation ‣ 2\. Methodology ‣ “Ask Me Anything”:
    How Comcast Uses LLMs to Assist Agents in Real Time").'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '(a) 为了清晰起见，仅显示设置$A$的变化。度量标准在第[2.5](#S2.SS5 "2.5\. Offline Response Evaluation
    ‣ 2\. Methodology ‣ “Ask Me Anything”: How Comcast Uses LLMs to Assist Agents
    in Real Time")节中定义。'
- en: 2.2\. Retrieving Relevant Text Snippets
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2\. 检索相关文本片段
- en: To inform the choice of our retriever model, we conducted pilot experiments
    on a curated evaluation set of fifty question–answer pairs. We searched the in-production
    system logs for queries starting with a WH-word (who, what, how, etc.) or ending
    with a question mark, roughly following the procedure on Bing query logs from
    WikiQA (Yang et al., [2015](#bib.bib25)). For each question, we then located the
    relevant passage and answer span in our internal knowledge base used by agents.
    Queries without answers were also labeled as such. Crucially, this process avoids
    back-formulation (Sakai et al., [2004](#bib.bib18)), where queries are manually
    written by annotators based on known passages rather than crawled from logs, resulting
    in biased evaluation sets.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 为了指导我们检索模型的选择，我们在一个精心策划的评估集（包含五十对问答）上进行了试验。我们搜索了生产系统日志中的查询，这些查询以WH词（谁、什么、如何等）开头或以问号结尾，大致遵循了WikiQA中的Bing查询日志的过程（Yang等，[2015](#bib.bib25)）。对于每个问题，我们在内部知识库中找到了相关的段落和答案范围。没有答案的查询也被标记为如此。至关重要的是，这一过程避免了反向构建（Sakai等，[2004](#bib.bib18)），即注释员根据已知的段落手动编写查询，而不是从日志中抓取，从而避免了偏见的评估集。
- en: 'We experimented with both dense and sparse retrieval models. For the sparse
    model, we used Okapi BM25 (Robertson et al., [2009](#bib.bib17)) with $k_{1}=1.0$.
    For the dense ones, we experimented with four: dense passage retrieval (DPR) (Karpukhin
    et al., [2020](#bib.bib10)), fine-tuned on Natural Questions (Kwiatkowski et al.,
    [2019](#bib.bib11)); MPNet-base (v1) (Song et al., [2020](#bib.bib19)), trained
    on 160GB of text corpora including Wikipedia, BookCorpus (Zhu et al., [2015](#bib.bib27)),
    and OpenWebText (Gokaslan and Cohen, [2019](#bib.bib7)); OpenAI’s state-of-the-art
    `ada-002` embeddings model; and MPNet-base v2, trained further on one billion
    sentence pairs for better embedding quality.²²2Nils Reimers’s open-source contribution: 
    [https://discuss.huggingface.co/t/train-the-best-sentence-embedding-model-ever-with-1b-training-pairs/7354](https://discuss.huggingface.co/t/train-the-best-sentence-embedding-model-ever-with-1b-training-pairs/7354)
    Each was deemed to satisfy our computational and financial constraints at inference
    time.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实验了密集型和稀疏型检索模型。对于稀疏模型，我们使用了 Okapi BM25（Robertson 等，[2009](#bib.bib17)），$k_{1}=1.0$。对于密集型模型，我们实验了四种：密集型段落检索（DPR）（Karpukhin
    等，[2020](#bib.bib10)），在 Natural Questions 上微调（Kwiatkowski 等，[2019](#bib.bib11)）；MPNet-base（v1）（Song
    等，[2020](#bib.bib19)），在包括 Wikipedia、BookCorpus（Zhu 等，[2015](#bib.bib27)）和 OpenWebText（Gokaslan
    和 Cohen，[2019](#bib.bib7)）在内的 160GB 文本语料上训练；OpenAI 最先进的 `ada-002` 嵌入模型；以及 MPNet-base
    v2，进一步在十亿对句子上训练，以获得更好的嵌入质量。²²Nils Reimers 的开源贡献：[https://discuss.huggingface.co/t/train-the-best-sentence-embedding-model-ever-with-1b-training-pairs/7354](https://discuss.huggingface.co/t/train-the-best-sentence-embedding-model-ever-with-1b-training-pairs/7354)
    每个模型都被认为符合我们在推理时的计算和财务限制。
- en: 'In [2(a)](#S2.T2.st1 "2(a) ‣ 2.2\. Retrieving Relevant Text Snippets ‣ 2\.
    Methodology ‣ “Ask Me Anything”: How Comcast Uses LLMs to Assist Agents in Real
    Time"), we report the recall@3 (R@3) and the mean reciprocal rank (MRR) of these
    models on our evaluation set. The choice of recall@3 (versus recall@5 or 10) is
    from us feeding the top-three retrieved passages into the LLM. As a sanity check,
    we also ran a baseline that randomly drew a passage, which unsurprisingly yielded
    low scores. Mirroring prior work (Yang et al., [2019](#bib.bib24)), we found that
    BM25 remains a strong baseline, outperforming DPR in R@3 and MRR, respectively.
    We conjecture that this results from Natural Questions being substantially out
    of domain from our data.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '在 [2(a)](#S2.T2.st1 "2(a) ‣ 2.2\. Retrieving Relevant Text Snippets ‣ 2\. Methodology
    ‣ “Ask Me Anything”: How Comcast Uses LLMs to Assist Agents in Real Time") 中，我们报告了这些模型在我们的评估集上的
    recall@3 (R@3) 和平均倒数排名 (MRR)。选择 recall@3（与 recall@5 或 10 相比）是因为我们将前三个检索到的段落输入
    LLM。作为一个合理性检查，我们还进行了一个基线实验，随机抽取一个段落，这并不令人意外地得到低分。与之前的研究（Yang 等，[2019](#bib.bib24)）相呼应，我们发现
    BM25 仍然是一个强有力的基线，在 R@3 和 MRR 上都优于 DPR。我们推测这是因为 Natural Questions 与我们的数据领域差异较大。'
- en: Table 2. Results of various retrievers on our pilot evaluation set
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2. 各种检索器在我们的试点评估集上的结果
- en: '| Method | Recall@3 | MRR |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | Recall@3 | MRR |'
- en: '| Random | -71.4% | -83.9% |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 随机 | -71.4% | -83.9% |'
- en: '| BM25 | - | - |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| BM25 | - | - |'
- en: '| DPR (`single-nq`) | -42.8% | -42.9% |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| DPR (`single-nq`) | -42.8% | -42.9% |'
- en: '| DPR (`multiset-nq`) | -23.8% | -29.0% |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| DPR (`multiset-nq`) | -23.8% | -29.0% |'
- en: '| Multi-QA MPNet-base | +33.0% | +39.7% |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| Multi-QA MPNet-base | +33.0% | +39.7% |'
- en: '| OpenAI embeddings (`ada-002`) | +33.0% | +53.9% |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| OpenAI 嵌入 (`ada-002`) | +33.0% | +53.9% |'
- en: '| MPNet-base v2 | +38.1% | +54.9% |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| MPNet-base v2 | +38.1% | +54.9% |'
- en: (a) Statistics presented as relative difference from BM25, i.e., $100\cdot(\mu-\mu_{BM25})/\mu_{BM25}$
    . Underline denotes statistical significance relative to DPR.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 统计数据以相对于 BM25 的差异呈现，即 $100\cdot(\mu-\mu_{BM25})/\mu_{BM25}$。下划线表示相对于 DPR
    的统计显著性。
- en: We observe MPNet-base (v1), OpenAI’s `ada-002`, and MPNet-base (v2) to perform
    similarly. Signed-rank tests for R@3 and $t$) from DPR. Due to operational convenience
    and the high performance of OpenAI’s ADA embeddings, we used ADA for the retriever
    component for the final system.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们观察到 MPNet-base（v1）、OpenAI 的 `ada-002` 和 MPNet-base（v2）表现相似。R@3 和 $t$ 的符号秩检验来自
    DPR。由于操作方便和 OpenAI ADA 嵌入的高性能，我们在最终系统的检索器组件中使用了 ADA。
- en: For our production retrieval step, we embedded both the title of the article
    and the text of the individual chunk and added them together prior to storage
    in the vector database. Anecdotally, we found this to yield a more comprehensive
    retrieval for a variety of queries, especially when chunks were missing some descriptive
    context of the topic of the article.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的生产检索步骤，我们将文章标题和单个段落的文本嵌入在一起，并在存储到向量数据库之前将它们合并。按经验，我们发现这对各种查询提供了更全面的检索，特别是在某些段落缺少文章主题的描述性上下文时。
- en: 2.3\. Reranking Search Results
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3\. 重新排序搜索结果
- en: We found that reranking results using models finetuned on synthetic data improved
    the retrieval step. Our approach was inspired by previous synthetic data generation
    approaches (Bonifacio et al., [2022](#bib.bib2); Dai et al., [2022](#bib.bib4)).
    First, we used GPT-4 to generate synthetic questions from each snippet in our
    dataset. We then ran each question through our search system using OpenAI’s `text-embeddings-ada-002`
    (Greene et al., [2022](#bib.bib9)) embeddings. Any questions where the original
    snippet used for question generation did not appear in the top 20 results were
    discarded. For each synthetic question, we stored the top 20 items retrieved,
    their relevance as scored by `BGE-reranker-large` (Xiao et al., [2023](#bib.bib23)),
    and an indicator that the snippet was the source of the question. The final rankings
    were determined by first placing the source snippet as the ”most relevant” result,
    followed by the snippets in most relevant order as scored by the `BGE-reranker-large`
    model.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现，使用在合成数据上微调的模型进行重新排序改善了检索步骤。我们的方法受到以前合成数据生成方法的启发（Bonifacio 等，[2022](#bib.bib2)；Dai
    等，[2022](#bib.bib4)）。首先，我们使用 GPT-4 从数据集中每个片段生成合成问题。然后，我们通过使用 OpenAI 的 `text-embeddings-ada-002`（Greene
    等，[2022](#bib.bib9)）嵌入将每个问题传递到我们的搜索系统中。所有原始片段未出现在前 20 个结果中的问题都被丢弃。对于每个合成问题，我们存储了检索到的前
    20 项、`BGE-reranker-large`（Xiao 等，[2023](#bib.bib23)）评分的相关性，以及片段是否是问题来源的指示。最终排名是通过将来源片段首先置为“最相关”结果，然后按照
    `BGE-reranker-large` 模型评分的最相关顺序排列其他片段来确定的。
- en: 'For training, we used RankNet (Burges et al., [2005](#bib.bib3)) to distill
    these rankings into a finetuned MPNet (Song et al., [2020](#bib.bib19)), in particular
    `all-mpnet-base-v2` from `sentence-transformer` (Reimers and Gurevych, [2019](#bib.bib16)),
    which has fewer parameters requiring less computational resources to deploy into
    production than `BGE-reranker-large`. The final dataset after constructing the
    necessary pairs for RankNet consisted of over 10 million examples. We set aside
    0.5% of the examples as validation dataset. Our training parameters were listed
    in Table [3](#S2.T3 "Table 3 ‣ 2.3\. Reranking Search Results ‣ 2\. Methodology
    ‣ “Ask Me Anything”: How Comcast Uses LLMs to Assist Agents in Real Time"). We
    used `DistributedDataParallel` from PyTorch (Paszke et al., [2017](#bib.bib13))
    for distributed training, so the effective batch size is the number of GPUs multiplied
    by the batch size. We found the ”Linear Scaling Rule”, where one scales the learning
    rate when the batch size increases, to not apply to our use case (Goyal et al.,
    [2018](#bib.bib8)), but we suspect it is because the original MPNet architecture
    was trained with a much larger batch size than we used for finetuning.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '对于训练，我们使用 RankNet（Burges 等，[2005](#bib.bib3)）将这些排名提炼成微调的 MPNet（Song 等，[2020](#bib.bib19)），特别是
    `sentence-transformer`（Reimers 和 Gurevych，[2019](#bib.bib16)）中的 `all-mpnet-base-v2`，其参数较少，所需计算资源比
    `BGE-reranker-large` 少。构建 RankNet 所需的对之后，最终数据集包含超过 1000 万个示例。我们将 0.5% 的示例留作验证数据集。我们的训练参数列在表
    [3](#S2.T3 "Table 3 ‣ 2.3\. Reranking Search Results ‣ 2\. Methodology ‣ “Ask
    Me Anything”: How Comcast Uses LLMs to Assist Agents in Real Time") 中。我们使用 PyTorch（Paszke
    等，[2017](#bib.bib13)）中的 `DistributedDataParallel` 进行分布式训练，因此有效批量大小是 GPU 数量乘以批量大小。我们发现“线性缩放规则”，即批量大小增加时调整学习率，并不适用于我们的用例（Goyal
    等，[2018](#bib.bib8)），但我们怀疑这是因为原始 MPNet 架构在我们用于微调的批量大小之前已经用更大的批量大小进行了训练。'
- en: '[b] Parameter Specification Learning Rate $5\times 10^{-6}$ Batch Size 8 Number
    of GPUs¹ 10 Warmup Steps 4000 Weight Decay 0.001 Epochs 1 Total Training Steps
    171391 Learning Rate Scheduler Warmup-constant'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[b] 参数规格 学习率 $5\times 10^{-6}$ 批量大小 8 GPU 数¹ 10 预热步骤 4000 权重衰减 0.001 纪元 1 总训练步骤
    171391 学习率调度器 预热-常量'
- en: Table 3. Training hyperparameters.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3. 训练超参数。
- en: '1'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '1'
- en: GPU type: g4dn.xlarge (Nvidia T4)
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: GPU 类型：g4dn.xlarge（Nvidia T4）
- en: 'To further evaluate the performance of our reranker model, we randomly sampled
    10,000 real questions asked by customer service agents in our production system.
    For every retrieved document, we followed the approach in (Thomas et al., [2023](#bib.bib21)),
    which showed that an LLM can accurately predict the relevancy of search results.
    Specifically, GPT-4 was used to evaluate the overall quality of each document
    to the question, which combined the scores from how the document matches the intent
    of the question as well as how trustworthy the document is. The final integer
    score ranged between 0 and 2, with higher score meaning higher overall quality.
    Table [4](#S2.T4 "Table 4 ‣ 2.3\. Reranking Search Results ‣ 2\. Methodology ‣
    “Ask Me Anything”: How Comcast Uses LLMs to Assist Agents in Real Time") compares
    multiple metrics between ADA vs. reranker. Since the overall score is non-binary,
    we compute MRR using the rank of first document with a score of 2, and recall@3
    examines whether the top 3 documents contain any documents with a score of 2\.
    The results indicate an improvement in retrieval performance with the reranker
    model.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '为进一步评估我们重新排序模型的性能，我们随机抽取了 10,000 个由客服代理在生产系统中提出的真实问题。对于每个检索到的文档，我们遵循了（Thomas
    等， [2023](#bib.bib21)）中的方法，该方法显示 LLM 可以准确预测搜索结果的相关性。具体来说，我们使用了 GPT-4 来评估每个文档与问题的整体质量，该质量结合了文档与问题意图匹配的分数以及文档的可信度。最终的整数评分范围从
    0 到 2，分数越高表示整体质量越高。表 [4](#S2.T4 "Table 4 ‣ 2.3\. Reranking Search Results ‣ 2\.
    Methodology ‣ “Ask Me Anything”: How Comcast Uses LLMs to Assist Agents in Real
    Time") 比较了 ADA 与重新排序模型之间的多个指标。由于整体评分是非二元的，我们使用第一个得分为 2 的文档的排名来计算 MRR，并且 recall@3
    检查前 3 个文档是否包含得分为 2 的文档。结果表明，重新排序模型在检索性能上有所改善。'
- en: Table 4. ADA vs. Reranker Search Results using Production Questions
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4. 使用生产问题的 ADA 与重新排序搜索结果
- en: '| Metric | ADA | Reranker |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| Metric | ADA | Reranker |'
- en: '| --- | --- | --- |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Recall@3 | - | +12% |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| Recall@3 | - | +12% |'
- en: '| MRR | - | +15% |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| MRR | - | +15% |'
- en: '| NDCG | - | +4.8% |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| NDCG | - | +4.8% |'
- en: (a) For clarity, only changes from setting ADA are found in the table. The metric
    values are the relative difference from ADA.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: （a）为清晰起见，表中仅显示 ADA 设置的变化。指标值是相对于 ADA 的差异。
- en: 2.4\. Generating the Answer from Snippets
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4\. 从片段生成答案
- en: In generating the answer, we follow the conventional wisdom approach in the
    RAG literature. We begin our prompt with a preamble of guidelines for the model,
    followed by the task description. Due to the length of our snippets of text from
    the knowledge base, we are unable to provide few-shot examples. We have anecdotally
    found it better to include more of the text to avoid necessary information being
    cut off at random. To avoid the ”lost in the middle” problem (Liu et al., [2023](#bib.bib12)),
    we reverse the order of the Top K results when passed into the LLM, formatted
    as XML capturing the ID, title and content of the result. We used OpenAI’s `gpt-3.5-turbo`
    for our production Reader component. As a final step in our prompt, we ask the
    LLM to answer the given question using the search results.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成答案时，我们遵循 RAG 文献中的传统方法。我们以模型的指导方针前言开始我们的提示，然后是任务描述。由于我们从知识库中提取的文本片段较长，我们无法提供少量示例。我们通过经验发现，包括更多的文本可以避免必要信息被随机截断。为避免“中间丢失”问题（Liu
    等， [2023](#bib.bib12)），我们在传递给 LLM 时反转 Top K 结果的顺序，格式为 XML，捕获结果的 ID、标题和内容。我们使用了
    OpenAI 的 `gpt-3.5-turbo` 作为我们的生产 Reader 组件。在提示的最终步骤中，我们要求 LLM 使用搜索结果回答给定的问题。
- en: 2.4.1\. Citations
  id: totrans-74
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.4.1\. 引用
- en: 'An important product feature of of the AMA solution is providing references
    to agents so they can learn more about the answer given. This can be seen in various
    RAG implementations, such as Microsoft Copilot. In addition, the goal was to build
    confidence in the system’s output and drive adoption internally. Inspired by the
    Fact-Checking Rail (Rebedea et al., [2023](#bib.bib15)), our Citation Rail was
    accomplished by prompting the LLM to cite its sources in a specific manner (c.f.,
    Figure [1](#S2.F1 "Figure 1 ‣ 2.4.1\. Citations ‣ 2.4\. Generating the Answer
    from Snippets ‣ 2\. Methodology ‣ “Ask Me Anything”: How Comcast Uses LLMs to
    Assist Agents in Real Time")) combined with a post processing step where the citations
    were removed from the text. If no citations were found, then the system would
    not return the answer. Practically, there was another benefit from an observability
    perspective: through this approach, we identified most ”no answer” responses from
    the LLM, as typically the LLM would response similarly to ”I’m sorry. I was unable
    to find the answer in the documents” without a citation.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 'AMA 解决方案的一个重要产品特性是提供给代理人参考，以便他们可以深入了解给出的答案。这在各种 RAG 实现中可以看到，例如 Microsoft Copilot。此外，目标是建立对系统输出的信任，并推动内部采纳。受事实检查轨道（Rebedea
    等，[2023](#bib.bib15)）的启发，我们的引用轨道通过促使 LLM 以特定方式引用其来源（参见图 [1](#S2.F1 "Figure 1 ‣
    2.4.1\. Citations ‣ 2.4\. Generating the Answer from Snippets ‣ 2\. Methodology
    ‣ “Ask Me Anything”: How Comcast Uses LLMs to Assist Agents in Real Time")）并结合一个后处理步骤，在该步骤中引用从文本中删除。如果未找到引用，则系统不会返回答案。从观察性的角度来看，这还有另一个好处：通过这种方法，我们识别出了大多数“无答案”响应，因为通常
    LLM 会类似于“对不起。我在文档中找不到答案”的回答，而没有引用。'
- en: 'Please  include  a  single  source  at  the  end  of  your  answer,  i.e.,  [Document0]  if  Document0  is  the  source.  If  there  is  more  than  one  source,  use  [Document0][Document1]  if  Document0  and  Document1  are  the  sources.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '请在答案末尾包含一个单一来源，即
    [Document0] 如果 Document0 是来源。如果有多个来源，使用 [Document0][Document1] 如果 Document0 和
    Document1 是来源。'
- en: Figure 1. An example component of a prompt to encourage citations from the LLM
    used in the system prompt section.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1. 系统提示部分用于鼓励 LLM 引用的提示示例组件。
- en: 2.5\. Offline Response Evaluation
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.5\. 离线响应评估
- en: To evaluate the system’s responses, we follow the LLM-as-a-judge methodology
    (Zhu et al., [2023](#bib.bib26)), in addition to metrics around retrieval quality
    typical of a search system. In particular, a random sample of questions from customers
    were pulled from production traffic. Human annotators then wrote correct answers
    to each query using internal knowledge bases that are also available to the AMA
    system. We were able to compare system answers to correct responses given by human
    annotators using GPT-4 to compute ”Answer Quality”.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估系统的响应，我们遵循 LLM 作为评判者的方法（Zhu 等，[2023](#bib.bib26)），以及典型搜索系统的检索质量指标。特别地，从生产流量中随机抽取了一些客户问题。然后，人工注释员使用内部知识库（AMA
    系统也可以访问）对每个查询编写正确答案。我们能够将系统答案与人工注释员给出的正确答案进行比较，使用 GPT-4 计算“答案质量”。
- en: For each question, the annotators also provided a citation from which their
    answers were based. We used this to calculate ”Citation Match Rate”:  the percentage
    of cases in which the citation from the AMA system matched the ground truth. Given
    that our retrieval step returns a list, we calculated Recall@K by assuming the
    annotated citation is the only relevant document.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个问题，注释员还提供了其答案所依据的引用。我们使用这些引用计算“引用匹配率”： AMA 系统的引用与实际情况匹配的案例百分比。鉴于我们的检索步骤返回一个列表，我们通过假设注释的引用是唯一相关文档来计算
    Recall@K。
- en: 'Table [5](#S2.T5 "Table 5 ‣ 2.5\. Offline Response Evaluation ‣ 2\. Methodology
    ‣ “Ask Me Anything”: How Comcast Uses LLMs to Assist Agents in Real Time") shows
    key metrics for the same two approaches as in Table [4](#S2.T4 "Table 4 ‣ 2.3\.
    Reranking Search Results ‣ 2\. Methodology ‣ “Ask Me Anything”: How Comcast Uses
    LLMs to Assist Agents in Real Time") (`text-embedding-ada-002` for dense retrieval
    of relevant documents and rerankering the ADA-retrieved documents using our finetuned
    model). We observe that using reranked documents, LLM is able to achieve a higher
    answer quality meaning that the answer from a different document ranking is more
    accurate according to GPT-4\. The improvement can also be explained by the increased
    Citation Match Rate and Recall@3 from the reranked documents directly influencing
    the LLM’s ability to answer accurately.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 表[5](#S2.T5 "表5 ‣ 2.5\. 离线响应评估 ‣ 2\. 方法论 ‣ “问我任何事”：康卡斯特如何使用LLMs实时协助代理")展示了与表[4](#S2.T4
    "表4 ‣ 2.3\. 重新排序搜索结果 ‣ 2\. 方法论 ‣ “问我任何事”：康卡斯特如何使用LLMs实时协助代理")相同的两个方法的关键指标（`text-embedding-ada-002`用于密集检索相关文档，并使用我们微调的模型重新排序ADA检索到的文档）。我们观察到，使用重新排序的文档，LLM能够实现更高的答案质量，这意味着根据GPT-4的评估，来自不同文档排名的答案更准确。改进也可以通过重新排序文档的引用匹配率和Recall@3的增加来解释，这直接影响了LLM的准确回答能力。
- en: Table 5. Response Quality
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 表5. 响应质量
- en: '| Metric | ADA | Reranker |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 指标 | ADA | 重新排序 |'
- en: '| --- | --- | --- |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Answer Quality | - | +5.9% |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 答案质量 | - | +5.9% |'
- en: '| Citation Match Rate | - | +2.5% |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 引用匹配率 | - | +2.5% |'
- en: '| Recall@3 | - | +16.5% |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| Recall@3 | - | +16.5% |'
- en: (a) For clarity, only changes from setting ADA are found in the table. The metric
    values are the relative difference from ADA.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 为了清晰起见，表中仅显示了相对于设置ADA的变化。指标值是相对于ADA的相对差异。
- en: 3\. Deploying AMA to Customer Service Agents
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 部署AMA到客户服务代理
- en: Due to business sensitivity purposes, this section will obscure some details
    related to monetary business metrics. The system was piloted with hundreds of
    chat agents in late 2023\. Over the course of a month-long trial, chat handling
    time improved 10% when agents used AMA versus the traditional search option, which
    required the agent to open a new tool and perform a search. We believe this is
    a good proxy metric for answer quality because an inaccurate or incomplete response
    from AMA would require the agent to start over and revert to the traditional option,
    duplicating work and taking more time overall. Explicit feedback, via a simple
    thumbs up/thumbs down UI element, was also collected from agents, with nearly
    an 80% positive feedback rate (there is no baseline for this rate as such feedback
    was not requested before the release of this feature). Shortly after the trial
    period, the system was rolled out to all chat agents (in thousands), with AMA-driven
    search becoming the preferred way of searching, accounting for two thirds of all
    typed queries.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 出于商业敏感目的，本节将遮盖一些与货币业务指标相关的细节。该系统于2023年底在数百名聊天代理中进行了试点。在为期一个月的试用期间，当代理使用AMA而非传统搜索选项时，聊天处理时间提高了10%，后者需要代理打开新工具并进行搜索。我们认为这是答案质量的良好代理指标，因为AMA的回答不准确或不完整会要求代理重新开始并回到传统选项，从而重复工作并总体上花费更多时间。通过简单的赞成/反对UI元素，也收集了来自代理的明确反馈，正面反馈率接近80%（由于在发布此功能之前没有请求此类反馈，因此没有基线）。试用期结束后，系统推广到所有聊天代理（数千人），AMA驱动的搜索成为首选的搜索方式，占所有输入查询的三分之二。
- en: 4\. Online Reranker Experiment
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 在线重新排序实验
- en: 'Shortly after the trial from Section [3](#S3 "3\. Deploying AMA to Customer
    Service Agents ‣ “Ask Me Anything”: How Comcast Uses LLMs to Assist Agents in
    Real Time") concluded, we began an A/B test of the reranker module described in
    Section [2.3](#S2.SS3 "2.3\. Reranking Search Results ‣ 2\. Methodology ‣ “Ask
    Me Anything”: How Comcast Uses LLMs to Assist Agents in Real Time"). The control
    variant used only the ADA embeddings for vector retrieval with no reranking component,
    and the treatment utilized the reranker component on the top $20$ when metrics
    considered user feedback, as responses were sparse. Due to the limited pool of
    agents, our randomization unit, we utilized an agent-day randomization similar
    to the cookie-day randomization found in other large systems (Tang et al., [2010](#bib.bib20))
    to increase statistical power. It has been shown in the literature (Deng et al.,
    [2017](#bib.bib6)) that violations of the independent and identically distributed
    (IID) assumption can lead to underestimation of the variance, but these tests
    can still be considered trustworthy in practice by using smaller significance
    thresholds and when observing larger effect sizes. The delta method (Deng et al.,
    [2018](#bib.bib5)) was employed to estimate the variance from question-level metrics.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在第[3](#S3 "3\. 将AMA部署到客服代表 ‣ “问我任何问题”：康卡斯特如何利用LLM实时协助代表")节的试验结束后，我们开始了对第[2.3](#S2.SS3
    "2.3\. 重新排序搜索结果 ‣ 2\. 方法 ‣ “问我任何问题”：康卡斯特如何利用LLM实时协助代表")节中描述的重新排序模块的A/B测试。对照组变体仅使用ADA嵌入进行向量检索，没有重新排序组件，而处理组则在考虑用户反馈的情况下，在前$20$个结果上应用了重新排序组件，因为回应较少。由于代理池有限，我们的随机化单位，我们采用了类似于其他大型系统中cookie-day随机化的agent-day随机化方法（Tang等，[2010](#bib.bib20)）来提高统计功效。文献中已显示（Deng等，[2017](#bib.bib6)）违背独立同分布（IID）假设可能导致方差低估，但通过使用较小的显著性阈值和观察较大的效应大小，这些测试在实践中仍然可以被认为是可信的。采用了delta方法（Deng等，[2018](#bib.bib5)）来估计问题级别度量的方差。
- en: We observed a statistically significant increase in two of our metrics: namely
    the ”No Answer Rate”, which is the number of queries with no answer divided by
    the total number of queries, and the ”Positive Feedback Rate”, defined as the
    number of thumbs up divided by the count of feedback received. Downstream business
    metrics like average handle time and escalation rate showed no significant difference.
    However, the improvement in No Answer Rate implies that the system was able to
    handle more questions than before by providing the relevant documents to the LLM
    while also increasing the rate of positive feedback.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们观察到两个指标有统计学意义上的显著增加：即“未回答率”，这是指没有回答的查询数除以总查询数，以及“正面反馈率”，定义为点赞数除以收到的反馈总数。下游业务指标如平均处理时间和升级率没有显示出显著差异。然而，未回答率的改善意味着系统能够通过向LLM提供相关文档来处理更多问题，同时提高了正面反馈的比例。
- en: Table 6. A/B Test Results
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 表格6. A/B测试结果
- en: '| Metric | Effect | p-value |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 指标 | 影响 | p 值 |'
- en: '| --- | --- | --- |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| No Answer Rate | -11.9% | p ¡ .001 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 未回答率 | -11.9% | p ¡ .001 |'
- en: '| Positive Feedback Rate | +8.9% | p ¡ .05 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 正面反馈率 | +8.9% | p ¡ .05 |'
- en: (a) Table contains relative change from control as the effect. Lower is better
    for No Answer Rate.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 表格包含相对于对照组的变化作为影响。对于未回答率，值越低越好。
- en: 5\. Conclusions
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 结论
- en: In this paper, we introduced AMA, a large-scale solution to a common business
    need: efficient high-quality customer care. Through the use of third-party LLMs
    and proven RAG methodology, we were able to build AMA pretty quickly and demonstrate
    clear value as an assistive feature. We showed improvements to retrieval and answer
    quality with specific choices for the document preprocessing, the retrieval model
    and its embeddings, as well as a custom reranker model. As we deploy AMA to thousands
    of agents with tangible business benefits, we believe that this provides a good
    example of how humans and AI can collaborate to better serve customers.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们介绍了AMA，这是一种应对常见业务需求的大规模解决方案：高效的高质量客户服务。通过使用第三方LLM和经过验证的RAG方法，我们能够迅速构建AMA并证明其作为辅助功能的明确价值。我们展示了通过对文档预处理、检索模型及其嵌入以及自定义重新排序模型的特定选择，检索和回答质量的改进。随着我们将AMA部署到数千名代理，带来了实际的业务收益，我们相信这提供了一个人类与AI如何合作以更好地服务客户的良好示例。
- en: References
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: 'Bonifacio et al. (2022) Luiz Bonifacio, Hugo Abonizio, Marzieh Fadaee, and
    Rodrigo Nogueira. 2022. InPars: Data Augmentation for Information Retrieval using
    Large Language Models. arXiv:2202.05144 [cs.CL]'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bonifacio 等 (2022) Luiz Bonifacio, Hugo Abonizio, Marzieh Fadaee, 和 Rodrigo
    Nogueira. 2022. InPars：使用大型语言模型进行信息检索的数据增强. arXiv:2202.05144 [cs.CL]
- en: Burges et al. (2005) Chris Burges, Tal Shaked, Erin Renshaw, Ari Lazier, Matt
    Deeds, Nicole Hamilton, and Greg Hullender. 2005. Learning to rank using gradient
    descent. In *Proceedings of the 22nd International Conference on Machine Learning*
    (Bonn, Germany) *(ICML ’05)*. Association for Computing Machinery, New York, NY,
    USA, 89–96. [https://doi.org/10.1145/1102351.1102363](https://doi.org/10.1145/1102351.1102363)
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Burges 等 (2005) Chris Burges, Tal Shaked, Erin Renshaw, Ari Lazier, Matt Deeds,
    Nicole Hamilton, 和 Greg Hullender. 2005. 使用梯度下降学习排序. 见 *第 22 届国际机器学习会议论文集* (波恩,
    德国) *(ICML ’05)*. 计算机协会, 纽约, NY, 美国, 89–96. [https://doi.org/10.1145/1102351.1102363](https://doi.org/10.1145/1102351.1102363)
- en: 'Dai et al. (2022) Zhuyun Dai, Vincent Y. Zhao, Ji Ma, Yi Luan, Jianmo Ni, Jing
    Lu, Anton Bakalov, Kelvin Guu, Keith B. Hall, and Ming-Wei Chang. 2022. Promptagator:
    Few-shot Dense Retrieval From 8 Examples. arXiv:2209.11755 [cs.CL]'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dai 等 (2022) Zhuyun Dai, Vincent Y. Zhao, Ji Ma, Yi Luan, Jianmo Ni, Jing Lu,
    Anton Bakalov, Kelvin Guu, Keith B. Hall, 和 Ming-Wei Chang. 2022. Promptagator：从
    8 个示例中进行少样本密集检索. arXiv:2209.11755 [cs.CL]
- en: 'Deng et al. (2018) Alex Deng, Ulf Knoblich, and Jiannan Lu. 2018. Applying
    the Delta Method in Metric Analytics: A Practical Guide with Novel Ideas. In *Proceedings
    of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data
    Mining* (London, United Kingdom) *(KDD ’18)*. Association for Computing Machinery,
    New York, NY, USA, 233–242. [https://doi.org/10.1145/3219819.3219919](https://doi.org/10.1145/3219819.3219919)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deng 等 (2018) Alex Deng, Ulf Knoblich, 和 Jiannan Lu. 2018. 在度量分析中应用 Delta 方法：带有新颖思想的实用指南.
    见 *第 24 届 ACM SIGKDD 国际知识发现与数据挖掘会议论文集* (伦敦, 英国) *(KDD ’18)*. 计算机协会, 纽约, NY, 美国,
    233–242. [https://doi.org/10.1145/3219819.3219919](https://doi.org/10.1145/3219819.3219919)
- en: 'Deng et al. (2017) Alex Deng, Jiannan Lu, and Jonthan Litz. 2017. Trustworthy
    Analysis of Online A/B Tests: Pitfalls, challenges and solutions. In *Proceedings
    of the Tenth ACM International Conference on Web Search and Data Mining* (Cambridge,
    United Kingdom) *(WSDM ’17)*. Association for Computing Machinery, New York, NY,
    USA, 641–649. [https://doi.org/10.1145/3018661.3018677](https://doi.org/10.1145/3018661.3018677)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deng 等 (2017) Alex Deng, Jiannan Lu, 和 Jonthan Litz. 2017. 可信赖的在线 A/B 测试分析：陷阱、挑战与解决方案.
    见 *第十届 ACM 国际网络搜索与数据挖掘会议论文集* (剑桥, 英国) *(WSDM ’17)*. 计算机协会, 纽约, NY, 美国, 641–649.
    [https://doi.org/10.1145/3018661.3018677](https://doi.org/10.1145/3018661.3018677)
- en: Gokaslan and Cohen (2019) Aaron Gokaslan and Vanya Cohen. 2019. OpenWebText
    Corpus. [http://Skylion007.github.io/OpenWebTextCorpus](http://Skylion007.github.io/OpenWebTextCorpus).
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gokaslan 和 Cohen (2019) Aaron Gokaslan 和 Vanya Cohen. 2019. OpenWebText 语料库.
    [http://Skylion007.github.io/OpenWebTextCorpus](http://Skylion007.github.io/OpenWebTextCorpus).
- en: 'Goyal et al. (2018) Priya Goyal, Piotr Dollár, Ross Girshick, Pieter Noordhuis,
    Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He.
    2018. Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour. arXiv:1706.02677 [cs.CV]'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goyal 等 (2018) Priya Goyal, Piotr Dollár, Ross Girshick, Pieter Noordhuis, Lukasz
    Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, 和 Kaiming He. 2018. 精确的大规模小批量
    SGD：在 1 小时内训练 ImageNet. arXiv:1706.02677 [cs.CV]
- en: Greene et al. (2022) Ryan Greene, Ted Sanders, Lilian Weng, and Arvind Neelakantan.
    2022. *New and improved embedding model*. [https://openai.com/blog/new-and-improved-embedding-model](https://openai.com/blog/new-and-improved-embedding-model)
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Greene 等 (2022) Ryan Greene, Ted Sanders, Lilian Weng, 和 Arvind Neelakantan.
    2022. *新改进的嵌入模型*. [https://openai.com/blog/new-and-improved-embedding-model](https://openai.com/blog/new-and-improved-embedding-model)
- en: Karpukhin et al. (2020) Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick
    Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020. Dense Passage
    Retrieval for Open-Domain Question Answering. In *Proceedings of the 2020 Conference
    on Empirical Methods in Natural Language Processing (EMNLP)*. 6769–6781.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Karpukhin 等 (2020) Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis,
    Ledell Wu, Sergey Edunov, Danqi Chen, 和 Wen-tau Yih. 2020. 开放域问答的密集检索. 见 *2020
    年自然语言处理实证方法会议论文集 (EMNLP)*. 6769–6781.
- en: 'Kwiatkowski et al. (2019) Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield,
    Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin,
    Jacob Devlin, Kenton Lee, et al. 2019. Natural questions: a benchmark for question
    answering research. *Transactions of the Association for Computational Linguistics*
    7 (2019), 453–466.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kwiatkowski 等人（2019）Tom Kwiatkowski、Jennimaria Palomaki、Olivia Redfield、Michael
    Collins、Ankur Parikh、Chris Alberti、Danielle Epstein、Illia Polosukhin、Jacob Devlin、Kenton
    Lee 等人。2019年。《自然问题：问题回答研究的基准》。*计算语言学协会会刊* 7（2019），453–466。
- en: 'Liu et al. (2023) Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape,
    Michele Bevilacqua, Fabio Petroni, and Percy Liang. 2023. Lost in the Middle:
    How Language Models Use Long Contexts. arXiv:2307.03172 [cs.CL]'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人（2023）Nelson F. Liu、Kevin Lin、John Hewitt、Ashwin Paranjape、Michele Bevilacqua、Fabio
    Petroni 和 Percy Liang。2023年。《迷失在中间：语言模型如何使用长上下文》。arXiv:2307.03172 [cs.CL]
- en: Paszke et al. (2017) Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan,
    Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam
    Lerer. 2017. Automatic differentiation in PyTorch. (2017).
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Paszke 等人（2017）Adam Paszke、Sam Gross、Soumith Chintala、Gregory Chanan、Edward
    Yang、Zachary DeVito、Zeming Lin、Alban Desmaison、Luca Antiga 和 Adam Lerer。2017年。《PyTorch
    中的自动微分》。 （2017年）。
- en: 'Pietsch et al. (2019) Malte Pietsch, Timo Möller, Bogdan Kostic, Julian Risch,
    Massimiliano Pippi, Mayank Jobanputra, Sara Zanzottera, Silvano Cerza, Vladimir
    Blagojevic, Thomas Stadelmann, Tanay Soni, and Sebastian Lee. 2019. Haystack:
    the end-to-end NLP framework for pragmatic builders. [https://github.com/deepset-ai/haystack](https://github.com/deepset-ai/haystack).'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pietsch 等人（2019）Malte Pietsch、Timo Möller、Bogdan Kostic、Julian Risch、Massimiliano
    Pippi、Mayank Jobanputra、Sara Zanzottera、Silvano Cerza、Vladimir Blagojevic、Thomas
    Stadelmann、Tanay Soni 和 Sebastian Lee。2019年。《Haystack：面向务实构建者的端到端 NLP 框架》。[https://github.com/deepset-ai/haystack](https://github.com/deepset-ai/haystack)。
- en: 'Rebedea et al. (2023) Traian Rebedea, Razvan Dinu, Makesh Sreedhar, Christopher
    Parisien, and Jonathan Cohen. 2023. NeMo Guardrails: A Toolkit for Controllable
    and Safe LLM Applications with Programmable Rails. arXiv:2310.10501 [cs.CL]'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rebedea 等人（2023）Traian Rebedea、Razvan Dinu、Makesh Sreedhar、Christopher Parisien
    和 Jonathan Cohen。2023年。《NeMo Guardrails：用于可控和安全的 LLM 应用的工具包与可编程 Rails》。arXiv:2310.10501
    [cs.CL]
- en: 'Reimers and Gurevych (2019) Nils Reimers and Iryna Gurevych. 2019. Sentence-BERT:
    Sentence Embeddings using Siamese BERT-Networks. In *Proceedings of the 2019 Conference
    on Empirical Methods in Natural Language Processing*. Association for Computational
    Linguistics. [http://arxiv.org/abs/1908.10084](http://arxiv.org/abs/1908.10084)'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Reimers 和 Gurevych（2019）Nils Reimers 和 Iryna Gurevych。2019年。《Sentence-BERT：使用
    Siamese BERT 网络的句子嵌入》。见 *2019年自然语言处理经验方法会议论文集*。计算语言学协会。[http://arxiv.org/abs/1908.10084](http://arxiv.org/abs/1908.10084)
- en: 'Robertson et al. (2009) Stephen Robertson, Hugo Zaragoza, et al. 2009. The
    probabilistic relevance framework: BM25 and beyond. *Foundations and Trends in
    Information Retrieval* 3, 4 (2009), 333–389.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Robertson 等人（2009）Stephen Robertson、Hugo Zaragoza 等人。2009年。《概率相关框架：BM25 及其他》。*信息检索基础与趋势*
    3, 4（2009），333–389。
- en: Sakai et al. (2004) Tetsuya Sakai, Yoshimi Saito, Yumi Ichimura, Tomoharu Kokubu,
    and Makoto Koyama. 2004. The effect of back-formulating questions in question
    answering evaluation. In *Proceedings of the 27th annual international ACM SIGIR
    conference on Research and development in information retrieval*. 474–475.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sakai 等人（2004）Tetsuya Sakai、Yoshimi Saito、Yumi Ichimura、Tomoharu Kokubu 和 Makoto
    Koyama。2004年。《在问题回答评估中反向构造问题的效果》。见 *第27届国际 ACM SIGIR 信息检索研究与发展年会论文集*。474–475。
- en: 'Song et al. (2020) Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu.
    2020. MPNet: Masked and Permuted Pre-training for Language Understanding. arXiv:2004.09297 [cs.CL]'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Song 等人（2020）Kaitao Song、Xu Tan、Tao Qin、Jianfeng Lu 和 Tie-Yan Liu。2020年。《MPNet：用于语言理解的掩码和排列预训练》。arXiv:2004.09297
    [cs.CL]
- en: 'Tang et al. (2010) Diane Tang, Ashish Agarwal, Deirdre O’Brien, and Mike Meyer.
    2010. Overlapping Experiment Infrastructure: More, Better, Faster Experimentation.
    In *Proceedings 16th Conference on Knowledge Discovery and Data Mining*. Washington,
    DC, 17–26.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tang 等人（2010）Diane Tang、Ashish Agarwal、Deirdre O’Brien 和 Mike Meyer。2010年。《重叠实验基础设施：更多、更好、更快的实验》。见
    *第16届知识发现与数据挖掘会议论文集*。华盛顿特区，17–26。
- en: Thomas et al. (2023) Paul Thomas, Seth Spielman, Nick Craswell, and Bhaskar
    Mitra. 2023. Large language models can accurately predict searcher preferences.
    arXiv:2309.10621 [cs.IR]
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Thomas 等人（2023）Paul Thomas、Seth Spielman、Nick Craswell 和 Bhaskar Mitra。2023年。《大型语言模型可以准确预测搜索者偏好》。arXiv:2309.10621
    [cs.IR]
- en: 'Wowak ([n. d.]) Kaitlin Wowak. [n. d.]. Humans vs. automation: Service center
    agents can outperform technology, study shows. [https://news.nd.edu/news/humans-vs-automation-service-center-agents-can-outperform-technology-study-shows/](https://news.nd.edu/news/humans-vs-automation-service-center-agents-can-outperform-technology-study-shows/)'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wowak ([n. d.]) Kaitlin Wowak。 [n. d.]。《人类与自动化：服务中心代理能够超越技术，研究表明》。 [https://news.nd.edu/news/humans-vs-automation-service-center-agents-can-outperform-technology-study-shows/](https://news.nd.edu/news/humans-vs-automation-service-center-agents-can-outperform-technology-study-shows/)
- en: 'Xiao et al. (2023) Shitao Xiao, Zheng Liu, Peitian Zhang, and Niklas Muennighoff.
    2023. C-Pack: Packaged Resources To Advance General Chinese Embedding. arXiv:2309.07597 [cs.CL]'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xiao 等人（2023）Shitao Xiao、Zheng Liu、Peitian Zhang 和 Niklas Muennighoff。2023。《C-Pack：推进通用中文嵌入的打包资源》。arXiv:2309.07597
    [cs.CL]
- en: 'Yang et al. (2019) Wei Yang, Kuang Lu, Peilin Yang, and Jimmy Lin. 2019. Critically
    examining the ”neural hype”: weak baselines and the additivity of effectiveness
    gains from neural ranking models. In *Proceedings of the 42nd international ACM
    SIGIR conference on research and development in information retrieval*. 1129–1132.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人（2019）Wei Yang、Kuang Lu、Peilin Yang 和 Jimmy Lin。2019。《批判性审视“神经炒作”：神经排名模型的弱基线和效果增益的可加性》。见于
    *第42届国际 ACM SIGIR 信息检索研究与发展会议论文集*。1129–1132。
- en: 'Yang et al. (2015) Yi Yang, Wen-tau Yih, and Christopher Meek. 2015. WikiQA:
    A challenge dataset for open-domain question answering. In *Proceedings of the
    2015 conference on empirical methods in natural language processing*. 2013–2018.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人（2015）Yi Yang、Wen-tau Yih 和 Christopher Meek。2015。《WikiQA：一个开放领域问答的挑战数据集》。见于
    *2015 年自然语言处理经验方法会议论文集*。2013–2018。
- en: 'Zhu et al. (2023) Lianghui Zhu, Xinggang Wang, and Xinlong Wang. 2023. JudgeLM:
    Fine-tuned Large Language Models are Scalable Judges. arXiv:2310.17631 [cs.CL]'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu 等人（2023）Lianghui Zhu、Xinggang Wang 和 Xinlong Wang。2023。《JudgeLM：微调的大型语言模型是可扩展的评审者》。arXiv:2310.17631
    [cs.CL]
- en: 'Zhu et al. (2015) Yukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov,
    Raquel Urtasun, Antonio Torralba, and Sanja Fidler. 2015. Aligning books and movies:
    Towards story-like visual explanations by watching movies and reading books. In
    *Proceedings of the IEEE international conference on computer vision*. 19–27.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu 等人（2015）Yukun Zhu、Ryan Kiros、Rich Zemel、Ruslan Salakhutdinov、Raquel Urtasun、Antonio
    Torralba 和 Sanja Fidler。2015。《对齐书籍与电影：通过观看电影和阅读书籍实现类故事的视觉解释》。见于 *IEEE 国际计算机视觉会议论文集*。19–27。
