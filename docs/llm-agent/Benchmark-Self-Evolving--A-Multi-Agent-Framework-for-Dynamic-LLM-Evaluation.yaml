- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:52:15'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:52:15
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Benchmark Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基准自我演化：动态 LLM 评估的多智能体框架
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2402.11443](https://ar5iv.labs.arxiv.org/html/2402.11443)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2402.11443](https://ar5iv.labs.arxiv.org/html/2402.11443)
- en: Siyuan Wang¹¹¹1Equal contribution., Zhuohan Long²¹¹1Equal contribution.,
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 王四元¹¹¹1同等贡献，龙卓涵²¹¹1同等贡献，
- en: Zhihao Fan³, Zhongyu Wei¹, Xuanjing Huang¹
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 范志浩³，魏中宇¹，黄轩靖¹
- en: ¹Fudan University, ²Tongji University, ³Alibaba Inc. wangsy18@fudan.edu.cn;
    loongnanshine@gmail.com
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ¹复旦大学，²同济大学，³阿里巴巴公司 wangsy18@fudan.edu.cn； loongnanshine@gmail.com
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: This paper presents a benchmark self-evolving framework to dynamically evaluate
    rapidly advancing Large Language Models (LLMs), aiming for a more accurate assessment
    of their capabilities and limitations. We utilize a multi-agent system to manipulate
    the context or question of original instances, reframing new evolving instances
    with high confidence that dynamically extend existing benchmarks. Towards a more
    scalable, robust and fine-grained evaluation, we implement six reframing operations
    to construct evolving instances testing LLMs against diverse queries, data noise
    and probing their problem-solving sub-abilities. With this framework, we extend
    benchmark datasets of four tasks. Experimental results show a general performance
    decline in most LLMs against their original results. This decline under our scalable
    and robust evaluations, alongside our fine-grained evaluation, more accurately
    reflect models’ capabilities. Besides, our framework widens performance discrepancies
    both between different models and within the same model across various tasks,
    facilitating more informed model selection for specific tasks ¹¹1Code and data
    are available at [https://github.com/NanshineLoong/Self-Evolving-Benchmark](https://github.com/NanshineLoong/Self-Evolving-Benchmark).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提出了一个基准自我演化框架，以动态评估快速发展的大型语言模型（LLMs），旨在更准确地评估其能力和局限性。我们利用多智能体系统操控原始实例的上下文或问题，通过高置信度重新构建新的演化实例，从而动态扩展现有的基准。为了实现更具可扩展性、鲁棒性和细粒度的评估，我们实施了六种重新构建操作，以构造演化实例，测试
    LLM 对各种查询、数据噪声的响应，并探测其问题解决的子能力。通过这个框架，我们扩展了四个任务的基准数据集。实验结果显示，在大多数 LLM 中，相对于其原始结果，性能普遍下降。这种在我们可扩展且鲁棒的评估下的下降，以及我们的细粒度评估，更准确地反映了模型的能力。此外，我们的框架扩大了不同模型之间以及同一模型在不同任务中的性能差异，帮助更明智地选择特定任务的模型
    ¹¹1代码和数据可在 [https://github.com/NanshineLoong/Self-Evolving-Benchmark](https://github.com/NanshineLoong/Self-Evolving-Benchmark)
    获得。
- en: 'Benchmark Self-Evolving:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 基准自我演化：
- en: A Multi-Agent Framework for Dynamic LLM Evaluation
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 动态 LLM 评估的多智能体框架
- en: Siyuan Wang¹¹¹1Equal contribution., Zhuohan Long²¹¹1Equal contribution., Zhihao
    Fan³, Zhongyu Wei¹, Xuanjing Huang¹ ¹Fudan University, ²Tongji University, ³Alibaba
    Inc. wangsy18@fudan.edu.cn; loongnanshine@gmail.com
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 王四元¹¹¹1同等贡献，龙卓涵²¹¹1同等贡献，范志浩³，魏中宇¹，黄轩靖¹ ¹复旦大学，²同济大学，³阿里巴巴公司 wangsy18@fudan.edu.cn；
    loongnanshine@gmail.com
- en: 1 Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Recent advancements in Large Language Models (LLMs) Touvron et al. ([2023](#bib.bib25));
    Chiang et al. ([2023](#bib.bib4)); OpenAI ([2023](#bib.bib19)); Jiang et al. ([2023](#bib.bib14))
    have demonstrated remarkable performance across various tasks, ranging from text
    generation to complex problem-solving. The evaluation of LLMs thus has emerged
    as a crucial area of research Chang et al. ([2023](#bib.bib3)); Espejel et al.
    ([2023](#bib.bib8)). It can provide a comprehensive understanding of the capabilities
    and limitations in these models, and guide the selection of the most applicable
    LLM for specific applications. Besides, a systematic assessment of LLMs would
    inspire further potential improvement.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，大型语言模型（LLMs）的进展 Touvron 等人 ([2023](#bib.bib25)); Chiang 等人 ([2023](#bib.bib4));
    OpenAI ([2023](#bib.bib19)); Jiang 等人 ([2023](#bib.bib14)) 展现了在各种任务中的卓越性能，从文本生成到复杂问题解决。因此，LLM
    的评估已成为一个关键研究领域 Chang 等人 ([2023](#bib.bib3)); Espejel 等人 ([2023](#bib.bib8))。这可以提供对这些模型能力和局限性的全面理解，并指导为特定应用选择最合适的
    LLM。此外，对 LLM 的系统评估将激发进一步的潜在改进。
- en: A multitude of benchmark datasets Hendrycks et al. ([2020](#bib.bib12)); Liang
    et al. ([2022](#bib.bib16)); bench authors ([2023](#bib.bib1)) have been proposed
    to evaluate LLMs. However, with the rapid development and emerging abilities of
    ever-evolving LLMs, these static datasets are increasingly inadequate for a thorough
    assessment. Besides, the extensive use of data for improving LLMs leads to data
    contamination issues Zhou et al. ([2023](#bib.bib34)); Shi et al. ([2023](#bib.bib23)),
    where in-domain training or even public test data may be inadvertently included
    during LLM training, resulting in skewed evaluations.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 许多基准数据集 Hendrycks et al. ([2020](#bib.bib12)); Liang et al. ([2022](#bib.bib16));
    bench authors ([2023](#bib.bib1)) 已被提出以评估LLMs。然而，随着LLMs的快速发展和不断涌现的能力，这些静态数据集越来越不足以进行全面评估。此外，广泛使用数据来改进LLMs导致数据污染问题 Zhou
    et al. ([2023](#bib.bib34)); Shi et al. ([2023](#bib.bib23))，其中领域内的训练数据或甚至公共测试数据可能在LLM训练过程中被无意包含，从而导致评估偏差。
- en: '![Refer to caption](img/abb79618a64f417275c04f866494529a.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/abb79618a64f417275c04f866494529a.png)'
- en: 'Figure 1: The evolution of LLMs necessitates benchmark self-evolving.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：LLMs的演变需要基准测试自我演化。
- en: These challenges necessitate continual updates of static benchmark datasets,
    enabling a more dynamic and accurate evaluation of LLMs. Since annotating new
    benchmarks from scratch is costly Kiela et al. ([2021](#bib.bib15)), Wei et al.
    ([2023](#bib.bib27)) evaluate LLMs using perplexity on re-sampled data. However,
    this over-reliance on perplexity may not fully reflect LLMs’ performance beyond
    predictive accuracy. Zhu et al. ([2023](#bib.bib35)) dynamically synthetize test
    samples based on directed acyclic graphs, but this method struggles in generalizing
    to tasks that cannot be graph-represented. In this work, we propose to flexibly
    update existing benchmark datasets instead of constructing entirely new ones.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这些挑战需要不断更新静态基准数据集，以实现对LLMs的更动态和准确的评估。由于从头开始注释新基准成本高 Kiela et al. ([2021](#bib.bib15));
    Wei et al. ([2023](#bib.bib27)) 使用困惑度在重新采样数据上评估LLMs。然而，这种过度依赖困惑度可能无法完全反映LLMs在预测准确度之外的表现。Zhu
    et al. ([2023](#bib.bib35)) 基于有向无环图动态合成测试样本，但这种方法在无法图示表示的任务上泛化困难。在这项工作中，我们提出灵活更新现有基准数据集的方案，而不是完全构建新的数据集。
- en: We introduce a benchmark self-evolving framework, which reframes existing benchmark
    instances into new variants for dynamic evaluation, by modifying their contexts
    or questions, and corresponding answers. This framework propels existing benchmarks
    towards self-evolution in three directions, providing a systematical dynamic evaluation
    of LLMs. First, to examine LLMs’ ability to generalize across diverse and increasingly
    challenging queries, we introduce scalable evaluation by creating alternative
    or more complex questions based on original contexts. Second, to counteract LLMs’
    tendency to exploit shortcut biases Gallegos et al. ([2023](#bib.bib9)); Yang
    et al. ([2023](#bib.bib28)) and their sensitivity to data noise Dong et al. ([2023](#bib.bib7));
    Pezeshkpour and Hruschka ([2023](#bib.bib21)), our framework implements robust
    evaluation. This involves incorporating various perturbations to the contexts
    of original instances, including paraphrasing, adding noise, and reversing polarity.
    Finally, to mitigate the impact that outdated data and bias susceptibility could
    skew capability assessments, we design fine-grained evaluation to probe LLMs’
    sub-abilities for solving different problems.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们引入了一个基准自我演化框架，通过修改现有基准实例的上下文或问题以及相应的答案，将其重新定义为新的变体进行动态评估。该框架推动现有基准在三个方向上进行自我演化，提供系统的动态评估LLMs。首先，为了检验LLMs在多样且越来越具有挑战性查询中的泛化能力，我们通过基于原始上下文创建替代或更复杂的问题引入可扩展评估。其次，为了对抗LLMs利用捷径偏差 Gallegos
    et al. ([2023](#bib.bib9)); Yang et al. ([2023](#bib.bib28)) 和对数据噪声的敏感性 Dong et al.
    ([2023](#bib.bib7)); Pezeshkpour and Hruschka ([2023](#bib.bib21))，我们的框架实施了稳健的评估。这包括对原始实例的上下文进行各种扰动，包括意译、添加噪声和反转极性。最后，为了减轻过时数据和偏差易感性对能力评估的影响，我们设计了细粒度评估，以探测LLMs解决不同问题的子能力。
- en: 'We design a multi-agent system to dynamically generate evolving instances from
    existing benchmarks while ensuring their accuracy. It comprises four key components:
    an instance pre-filter, an instance creator, an instance verifier and a candidate
    option formulator. The workflow begins with the pre-filter to select manageable
    instances from the original evaluation set. The instance creator crafts new instances
    by editing their contexts or questions with answers, which the verifier checks
    for correctness. To further enhance reliability, the candidate option formulator
    subsequently creates an incorrect answer option for each new context-question
    pair, which the verifier need to identify as inconsistent with the new context-question.
    These rigorously generated and double-verified instances will be used for dynamic
    evaluation. All these components are powered by GPT-4 to leverage its generative
    and verification strengths.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设计了一个多代理系统，以动态生成演变实例，同时确保其准确性。它包括四个关键组件：实例预筛选器、实例创建器、实例验证器和候选选项制定器。工作流程从预筛选器开始，从原始评估集选择可管理的实例。实例创建器通过编辑其背景或问题和答案来制作新的实例，验证器检查其正确性。为了进一步提高可靠性，候选选项制定器随后为每对新背景-问题对创建一个错误答案选项，验证器需要将其识别为与新背景-问题不一致。这些严格生成和双重验证的实例将用于动态评估。所有这些组件都由GPT-4提供支持，以利用其生成和验证的优势。
- en: Based on our framework, we dynamically extend benchmark datasets of four different
    tasks, including mathematical reasoning (GSM8K), logical reasoning (CLUTRR), commonsense
    reasoning (StrategyQA) and reading comprehension (BoolQ), and re-evaluate various
    closed-source and open-source LLMs. Results show that our scalable and robust
    evaluation are more challenging compared to original benchmarks, leading to a
    general performance decline for all models. It helps reveal the limited generalizability
    and robustness of models to diverse and complex queries. This along with sub-ability
    probing offers a more accurate reflection of LLMs’ true capabilities. Besides,
    our framework expands the performance gap between various models and also the
    differences of a single model across various tasks, which benefits the selection
    of the most suitable LLM for specific applications.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 基于我们的框架，我们动态扩展了四种不同任务的基准数据集，包括数学推理（GSM8K）、逻辑推理（CLUTRR）、常识推理（StrategyQA）和阅读理解（BoolQ），并重新评估了各种封闭源和开源LLM。结果表明，我们的可扩展和鲁棒评估比原始基准更具挑战性，导致所有模型的总体性能下降。这有助于揭示模型对多样和复杂查询的有限泛化能力和鲁棒性。这与子能力探测相结合，提供了对LLM真实能力的更准确反映。此外，我们的框架扩展了不同模型之间的性能差距以及单个模型在不同任务中的差异，这有助于选择最适合特定应用的LLM。
- en: 2 Benchmark Self-Evolving Framework
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 基准自演化框架
- en: '| Original Instance |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 原始实例 |'
- en: '| Context: Janet’s ducks lay 16 eggs per day. She eats three for breakfast
    every morning and bakes muffins for her friends every day with four. She sells
    the remainder at the farmers’ market daily for $2 per fresh duck egg. |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 背景：珍妮特的鸭子每天产16个鸡蛋。她每天早上吃三个做早餐，并用四个给朋友们烤松饼。她每天将剩余的鸭蛋以每个$2的价格在农贸市场上出售。 |'
- en: '| Original Question: How much in dollars does she make every day at the farmers’
    market? |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 原始问题：她每天在农贸市场上赚多少美元？ |'
- en: '| Original Answer: Janet sells 16 - 3 - 4 = <>9 duck eggs a day.
    She makes 9 * 2 = $<>18 every day at the farmer’s market. #### 18 |  |
    Directions | Operation Types | Changed Items | Examples |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 原始答案：珍妮特每天出售16 - 3 - 4 = <>9个鸭蛋。她每天在农贸市场上赚9 * 2 = $<>18。####
    18 |  | 说明 | 操作类型 | 改动项目 | 示例 |'
- en: '| Scalable | Question Alternating | context, answer | Alternative Question:
    If Janet decides to use 2 of her daily eggs to make a special omelette for dinner
    each day, how much will she earn at the farmers’ market in a week? Alternative
    Answer: $98 |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 可扩展 | 问题交替 | 背景，答案 | 替代问题：如果珍妮特决定每天用2个鸡蛋做特别的晚餐煎蛋饼，她在农贸市场一周能赚多少钱？替代答案：$98
    |'
- en: '| Question Complicating | context, answer | Complex Question: How many days
    will it take for Janet to save $100 from her earnings at the farmers’ market?
    Complex Answer: 6 days |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 复杂问题 | 背景，答案 | 复杂问题：珍妮特需要多少天才能从她在农贸市场的收入中存到$100？复杂答案：6天 |'
- en: '| Robust | Context Paraphrasing | context | Paraphrased Context: Janet’s daily
    egg production from her ducks is 16\. Each morning, she consumes three eggs for
    breakfast and uses four more to bake muffins for her friends. The remaining eggs
    are then sold at the farmers’ market for $2 each. |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 可靠 | 上下文释义 | 上下文 | 释义后的上下文：珍妮特的鸭子每天生产16个鸡蛋。她每天早晨吃三个鸡蛋做早餐，并用四个鸡蛋为她的朋友们烤松饼。剩余的鸡蛋在农贸市场以每个2美元的价格出售。'
- en: '| Context Noising | context | Noised Context: Janet’s ducks lay 16 eggs per
    day and *her cows product 4L milk* per day. She eats three eggs and 1L milk for
    breakfast every morning and bakes muffins for her friends every day with four
    eggs. She *keeps the remainder milk for herself* and only sells the remainder
    eggs at the farmers’ market daily for $2 per fresh duck egg. |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 上下文噪声 | 上下文 | 噪声上下文：珍妮特的鸭子每天产16个鸡蛋，*她的奶牛每天产4升牛奶*。她每天早晨吃三个鸡蛋和1升牛奶作为早餐，并且每天用四个鸡蛋为朋友们烤松饼。她*把剩余的牛奶留给自己*，只在农贸市场每天以2美元每个新鲜鸭蛋的价格出售剩余的鸡蛋。
    |'
- en: '| Polarity Reversing | context, answer | Reversed Context: Janet’s ducks lay
    *20 eggs* per day. She eats *five* for breakfast every morning and bakes muffins
    for her friends every day with four. She sells the remainder at the farmers’ market
    daily for *$2.5* per fresh duck egg. Reversed Answer: 27.5 |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 极性反转 | 上下文，答案 | 反转后的上下文：珍妮特的鸭子每天产*20个鸡蛋*。她每天早晨吃*五个*作为早餐，并且每天用四个鸡蛋为她的朋友烤松饼。她在农贸市场每天以*2.5美元*每个新鲜鸭蛋的价格出售剩余的鸡蛋。反转后的答案：27.5
    |'
- en: '| Fine-grained | Sub-ability Question Generation | context, answer | New Question:
    What are the detailed reasoning steps required to calculate how much in dollars
    Janet makes every day at the farmers’ market? New Answer: The solution involves
    2 reasoning steps. [Step 1] calculates the number of eggs can be sold. [Step 2]
    calculate the money she earns. |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 细粒度 | 子能力问题生成 | 上下文，答案 | 新问题：计算珍妮特每天在农贸市场赚多少钱的详细推理步骤是什么？新答案：解决方案涉及两个推理步骤。[步骤1]
    计算可出售的鸡蛋数量。[步骤2] 计算她赚到的钱。 |'
- en: 'Table 1: The reframing operations and examples for generating evolving instances.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：生成演变实例的重新框架操作和示例。
- en: 'The overall illustration of our framework is presented in Figure [1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ Benchmark Self-Evolving: A Multi-Agent Framework
    for Dynamic LLM Evaluation"). We first introduce different directions that we
    modify the contexts or questions of original instances along with their answers
    for newly evolving instances (see Section [2.1](#S2.SS1 "2.1 Evolving Instance
    Taxonomy ‣ 2 Benchmark Self-Evolving Framework ‣ Benchmark Self-Evolving: A Multi-Agent
    Framework for Dynamic LLM Evaluation")). We employ a multi-agent system to facilitate
    collaboration on evolving instance generation and double-verification. (see Section [2.2](#S2.SS2
    "2.2 Multi-Agent Evolving Instance Generator ‣ 2 Benchmark Self-Evolving Framework
    ‣ Benchmark Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation"))'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '我们框架的总体示意图见图 [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Benchmark Self-Evolving:
    A Multi-Agent Framework for Dynamic LLM Evaluation")。我们首先介绍了修改原始实例的上下文或问题及其答案的不同方向，以生成新的演变实例（见第[2.1](#S2.SS1
    "2.1 Evolving Instance Taxonomy ‣ 2 Benchmark Self-Evolving Framework ‣ Benchmark
    Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation")节）。我们使用多智能体系统来促进演变实例生成和双重验证的协作。（见第[2.2](#S2.SS2
    "2.2 Multi-Agent Evolving Instance Generator ‣ 2 Benchmark Self-Evolving Framework
    ‣ Benchmark Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation")节）'
- en: '![Refer to caption](img/ac3dd6817979a403728df68a35eec516.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/ac3dd6817979a403728df68a35eec516.png)'
- en: 'Figure 2: The workflow of our Multi-Agent Evolving Instance Generator system.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：我们的多智能体演变实例生成器系统的工作流程。
- en: 2.1 Evolving Instance Taxonomy
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 演变实例分类
- en: An instance can be formulated as a triplet consisting of a context ($C$, for
    scalable, robust and fine-grained evaluation.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 实例可以被表述为一个三元组，包括上下文（$C$），用于可扩展、可靠和细粒度的评估。
- en: Scalable Evaluation For scalable evaluation of evolving LLMs, we create various
    questions with their corresponding new answers based on the original instance
    to examine whether LLMs can generalize to diverse and increasingly challenging
    queries. Our approach includes the creation of alternative questions (Question
    Alternating) that examine different facets of the original context, as well as
    more complex questions requiring additional reasoning steps (Question Complicating).
    To maintain the accuracy of evolving instance, we conduct question generation
    without changing original contexts.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展的评估 为了对演变中的LLMs进行可扩展的评估，我们基于原始实例创建了各种问题及其对应的新答案，以检验LLMs是否能够推广到多样化和越来越具挑战性的查询。我们的方法包括创建替代问题（问题交替），以考察原始上下文的不同方面，以及需要额外推理步骤的更复杂问题（问题复杂化）。为了保持演变实例的准确性，我们在生成问题时不改变原始上下文。
- en: 'Robust Evaluation For more robust evaluation of LLMs, we introduce various
    perturbations to the contexts of original instances to generate evolving instances.
    Specifically, we apply three perturbation strategies on the contexts as follows.
    (1) Context Paraphrasing: paraphrasing the original context to obtain diverse
    formulations; (2) Context Noising: adding noise by introducing irrelevant or adversarial
    sentences into the original context; (3) Polarity Reversing: reversing the polarity
    or altering key details of the original context. The first two perturbations require
    maintaining the original answer labels while the third approach necessitates a
    corresponding answer change, offering a more rigorous test of the model’s adaptability.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 更强健的评估 为了对大型语言模型（LLMs）进行更强健的评估，我们在原始实例的上下文中引入了各种扰动，以生成演变实例。具体来说，我们对上下文应用了三种扰动策略如下：(1)
    上下文改写：对原始上下文进行改写，以获得多样化的表述；(2) 上下文噪声：通过在原始上下文中引入无关或对抗性的句子来添加噪声；(3) 极性反转：反转原始上下文的极性或改变关键细节。前两种扰动需要保持原始答案标签，而第三种方法需要相应地更改答案，从而提供了对模型适应性的更严格测试。
- en: 'Fine-grained Evaluation We design fine-grained evaluation by generating sub-ability
    questions to probe LLMs’ problem-solving capabilities. We focus on three explainability-related
    sub-abilities: (1) task planning capability that inquires about the details of
    planned reasoning steps, (2) implicit knowledge identification capability for
    recognizing underlying facts or rules, and (3) relevant context retrieval capability
    for extracting pertinent information from the given context to support its responses.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 细粒度评估 我们通过生成子能力问题来设计细粒度评估，以探查LLMs的解决问题能力。我们关注三种与解释性相关的子能力：(1) 任务规划能力，询问计划的推理步骤的细节；(2)
    隐性知识识别能力，用于识别潜在的事实或规则；(3) 相关上下文检索能力，从给定上下文中提取相关信息以支持其回应。
- en: 'The detailed operations to reframe evolving instances and corresponding examples
    are in Table [1](#S2.T1 "Table 1 ‣ 2 Benchmark Self-Evolving Framework ‣ Benchmark
    Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation").'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 重新构建演变实例的详细操作和对应的示例见表格 [1](#S2.T1 "表格 1 ‣ 2 基准自演变框架 ‣ 基准自演变：动态LLM评估的多智能体框架")。
- en: 2.2 Multi-Agent Evolving Instance Generator
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 多智能体演变实例生成器
- en: 'To generate evolving instances and ensure their correctness, we design a multi-agent
    instance creator system, incorporating four key agents including an instance pre-filter,
    an instance creator, an instance verifier and a candidate option formulator. All
    agents are built upon GPT-4 to fulfill their roles. The system’s workflow is presented
    in Figure [2](#S2.F2 "Figure 2 ‣ 2 Benchmark Self-Evolving Framework ‣ Benchmark
    Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation").'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为了生成演变实例并确保其正确性，我们设计了一个多智能体实例创建系统，包含四个关键智能体，包括实例预过滤器、实例创建器、实例验证器和候选选项制定者。所有智能体都建立在GPT-4的基础上，以履行其角色。系统的工作流程见图
    [2](#S2.F2 "图 2 ‣ 2 基准自演变框架 ‣ 基准自演变：动态LLM评估的多智能体框架")。
- en: Instance Pre-Filter The instance pre-filter is designed to go through the original
    dataset to identify manageable instances that fall within GPT-4’s capability to
    accurately answer. As the whole system is powered by GPT-4, this instance pre-filter
    can establish a correct foundation for subsequent operations and enhance the overall
    system’s reliability. It takes the context and question of the original instance
    as inputs, prompting GPT-4 to predict the answer and compare its prediction with
    the reference answer. A two-shot chain of thought Wei et al. ([2022](#bib.bib26))
    prompting setting is utilized to select manageable cases as $(C_{o},Q_{o},A_{o})$.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 实例预筛选 实例预筛选旨在通过原始数据集，以识别在GPT-4能力范围内能够准确回答的可管理实例。由于整个系统由GPT-4提供支持，这个实例预筛选可以为后续操作建立正确的基础，并提升整体系统的可靠性。它以原始实例的上下文和问题作为输入，提示GPT-4预测答案，并将其预测与参考答案进行比较。利用了魏等人（[2022](#bib.bib26)）的两步链式思考提示设置来选择可管理的案例作为$(C_{o},Q_{o},A_{o})$。
- en: 'Instance Creator The instance creator agent is pivotal in generating different
    types of newly evolving instances $(C_{e},Q_{e},A_{e})$), the instance creator
    is specifically prompted to maintain the original answer during the operation.
    For operations leading to new answers, the instance creator think step-by-step
    to infer its new answer after the reformulation of the context or question. This
    process adopts a one-shot prompting strategy for better understanding operation
    requirements. An example prompt for generating complex question is provided below.
    Prompts for other reframing operations are listed in Appendix [A.2](#A1.SS2 "A.2
    Prompts of Multi-Agent Evolving Instance Setter ‣ Appendix A Details of Framework
    ‣ Benchmark Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation").'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '实例创建器 实例创建器在生成不同类型的新兴实例$(C_{e},Q_{e},A_{e})$方面至关重要，实例创建器特别被提示在操作过程中保持原始答案。对于导致新答案的操作，实例创建器需要逐步思考，以推断在上下文或问题重新表述后的新答案。这个过程采用一次性提示策略以更好地理解操作要求。以下提供了生成复杂问题的示例提示。其他重新构建操作的提示请见附录 [A.2](#A1.SS2
    "A.2 Prompts of Multi-Agent Evolving Instance Setter ‣ Appendix A Details of Framework
    ‣ Benchmark Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation")。'
- en: 'Prompt
    on Question Complicating You are an expert Question
    Creator. You will receive an instance of {task description}, including a context,
    an original question and its answer. Your task is to generate a more complex question
    and its corresponding answer based on the given context, with the goal of incorporating
    additional reasoning steps beyond what is required by the original question and
    answer. Please do not change the context but just edit the question and the answer.
    Please first generate the question. Then think step-by-step in one line to give
    an brief analysis of the question, Finally, directly present a short answer omitting
    the intermediate steps, in a single line. Context: {context $C_{o}$} Alternative
    Question:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 问题复杂化提示
    你是一个专家问题创建者。你将收到一个包含上下文、原始问题及其答案的{任务描述}实例。你的任务是根据给定的上下文生成一个更复杂的问题及其相应的答案，目的是在原始问题和答案所需的基础上增加额外的推理步骤。请不要改变上下文，只需编辑问题和答案。请首先生成问题。然后逐步思考一行，对问题进行简要分析，最后直接给出简短的答案，省略中间步骤，一行呈现。上下文：{context
    $C_{o}$} 替代问题：
- en: 'Instance Verifier The primary function of the instance verifier agent is to
    validate the correctness of the newly evolving instance $(C_{e},Q_{e},A_{e})$,
    i.e., whether its answer can correctly support the corresponding context and question.
    Since these evolving instances are auto-generated through a GPT-4 based agent,
    the inclusion of this verifier is essential to control our data quality. The instance
    verifier directly takes the context, question and answer of the new instance as
    inputs, and adopts a two-shot CoT prompting strategy. It utilizes both a correct
    and an incorrect demonstrations to avoid potential biases. The specific prompt
    used for instance verifier can be found in Appendix [A.2](#A1.SS2 "A.2 Prompts
    of Multi-Agent Evolving Instance Setter ‣ Appendix A Details of Framework ‣ Benchmark
    Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation").'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '实例验证器 实例验证器代理的主要功能是验证新生成实例 $(C_{e},Q_{e},A_{e})$ 的正确性，即其答案是否能正确支持相应的上下文和问题。由于这些演变实例是通过基于GPT-4的代理自动生成的，因此包含此验证器对于控制我们的数据质量至关重要。实例验证器直接以新实例的上下文、问题和答案作为输入，采用双次
    CoT 提示策略。它利用正确和不正确的示例来避免潜在的偏见。用于实例验证器的具体提示可以在附录 [A.2](#A1.SS2 "A.2 Prompts of
    Multi-Agent Evolving Instance Setter ‣ Appendix A Details of Framework ‣ Benchmark
    Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation")中找到。'
- en: 'Candidate Option Formulator The candidate option formulator aims to generate
    an incorrect answer option $O_{w}$. (2) It additionally provides a standardized
    binary-choice assessment method for more accurate evaluation metrics. For new
    instances with fine-grained questions where their free-form answers are not easy
    to evaluate, we adopt this binary-choice evaluation. Specifically, it takes the
    context-question pair and the correct answer as inputs, and adopts a one-shot
    prompting strategy to output a wrong candidate option. The specific prompt is
    provided in Appendix [A.2](#A1.SS2 "A.2 Prompts of Multi-Agent Evolving Instance
    Setter ‣ Appendix A Details of Framework ‣ Benchmark Self-Evolving: A Multi-Agent
    Framework for Dynamic LLM Evaluation").'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '候选选项生成器旨在生成一个不正确的答案选项 $O_{w}$。 (2) 它还提供了一种标准化的二元选择评估方法，以获得更准确的评估指标。对于新实例中细化的问题，其自由形式的答案不容易评估时，我们采用这种二元选择评估方法。具体来说，它以上下文-问题对和正确答案作为输入，采用一次性提示策略生成一个错误的候选选项。具体的提示在附录 [A.2](#A1.SS2
    "A.2 Prompts of Multi-Agent Evolving Instance Setter ‣ Appendix A Details of Framework
    ‣ Benchmark Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation")中提供。'
- en: '| Dataset | Manageable | Scalable | Robust | Fine-Grained |  Total |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 可管理 | 可扩展 | 强健 | 细化 | 总计 |'
- en: '| Alternating | Complicating | Paraphrasing | Noising | Reversing | Planning
    | Knowledge | Retrieval |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 交替 | 复杂化 | 同义改写 | 加噪 | 反转 | 规划 | 知识 | 检索 |'
- en: '| GSM8K | 96/100 | 65 | 55 | 90 | 90 | 61 | 71 | / | / | 432 |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| GSM8K | 96/100 | 65 | 55 | 90 | 90 | 61 | 71 | / | / | 432 |'
- en: '| CLUTRR | 96/100 | 88 | 78 | 76 | 80 | 72 | 69 | 81 | 64 | 608 |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| CLUTRR | 96/100 | 88 | 78 | 76 | 80 | 72 | 69 | 81 | 64 | 608 |'
- en: '| StrategyQA | 83/100 | / | 57 | / | / | / | 78 | 65 | / | 200 |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| StrategyQA | 83/100 | / | 57 | / | / | / | 78 | 65 | / | 200 |'
- en: '| BoolQ | 90/100 | 88 | 68 | 90 | 86 | 50 | / | / | 67 | 382 |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| BoolQ | 90/100 | 88 | 68 | 90 | 86 | 50 | / | / | 67 | 382 |'
- en: 'Table 2: Statistics of our evolving instances from four original datasets.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '表 2: 我们从四个原始数据集中演变实例的统计数据。'
- en: 'System Workflow The systematic procedure of our system is delineated in the
    following steps. First, the instance pre-filter selects manageable instances $(C_{o},Q_{o},A_{o})$.
    Only those instances that pass this double-verification process, i.e., the generated
    instance is examined as correct while the alternative is incorrect, will be utilized
    for dynamic evaluation. For a detailed exposition of the underlying algorithms,
    refer to Appendix [A.1](#A1.SS1 "A.1 Algorithm Design ‣ Appendix A Details of
    Framework ‣ Benchmark Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation")'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '系统工作流程 我们系统的系统化过程如下所述。首先，实例预筛选器选择可管理的实例 $(C_{o},Q_{o},A_{o})$。只有那些通过双重验证过程的实例，即生成的实例被检查为正确，而备选实例为不正确的，才会用于动态评估。有关底层算法的详细说明，请参阅附录 [A.1](#A1.SS1
    "A.1 Algorithm Design ‣ Appendix A Details of Framework ‣ Benchmark Self-Evolving:
    A Multi-Agent Framework for Dynamic LLM Evaluation")。'
- en: 3 Experiments
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 个实验
- en: 3.1 Setup
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 设置
- en: 'Tasks and Datasets Using our benchmark self-evolving framework, we dynamically
    extend benchmark datasets of four different tasks, including mathematical reasoning,
    logical reasoning, commonsense reasoning and reading comprehension. Specifically,
    we utilize GSM8K Cobbe et al. ([2021](#bib.bib6)), CLUTRR Sinha et al. ([2019](#bib.bib24)),
    StrategyQA Geva et al. ([2021](#bib.bib10)), and BoolQ Clark et al. ([2019](#bib.bib5))
    respectively for these four tasks, all involving multi-step complex reasoning.
    Detailed dataset descriptions are provided in Appendix [B.1](#A2.SS1 "B.1 Dataset
    Descriptions ‣ Appendix B Experimental Analysis ‣ Benchmark Self-Evolving: A Multi-Agent
    Framework for Dynamic LLM Evaluation").'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '任务和数据集 使用我们的基准自演化框架，我们动态扩展了四种不同任务的基准数据集，包括数学推理、逻辑推理、常识推理和阅读理解。具体来说，我们分别利用了
    GSM8K Cobbe 等人 ([2021](#bib.bib6))、CLUTRR Sinha 等人 ([2019](#bib.bib24))、StrategyQA Geva
    等人 ([2021](#bib.bib10)) 和 BoolQ Clark 等人 ([2019](#bib.bib5)) 这四个数据集，所有数据集都涉及多步骤复杂推理。详细的数据集描述见附录 [B.1](#A2.SS1
    "B.1 Dataset Descriptions ‣ Appendix B Experimental Analysis ‣ Benchmark Self-Evolving:
    A Multi-Agent Framework for Dynamic LLM Evaluation")。'
- en: 'We randomly select 100 instances from publicly available dev/test sets of each
    dataset²²2The instances from CLUTRR are selected within the clauses of length
    $k\leq 3$., and feed each instance into our multi-agent system to generate new
    evaluation instances of various reframing types. For GSM8K, CLUTRR and BoolQ,
    we generate new instances across all six types as in Table [1](#S2.T1 "Table 1
    ‣ 2 Benchmark Self-Evolving Framework ‣ Benchmark Self-Evolving: A Multi-Agent
    Framework for Dynamic LLM Evaluation"). For StrategyQA without context, we only
    generate instances with complex and fine-grained questions. Specifically for fine-grained
    sub-abilities, we focus on the task planning ability for GSM8K and BoolQ, both
    task planning and implicit knowledge identification for StrategyQA, and all three
    sub-abilities for CLUTRR. Statistics of generated evolving datasets are summarized
    as Table [2](#S2.T2 "Table 2 ‣ 2.2 Multi-Agent Evolving Instance Generator ‣ 2
    Benchmark Self-Evolving Framework ‣ Benchmark Self-Evolving: A Multi-Agent Framework
    for Dynamic LLM Evaluation").'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '我们从每个数据集的公开开发/测试集随机选择了100个实例²²2CLUTRR中的实例选择在长度为$k\leq 3$的子句内，并将每个实例输入到我们的多智能体系统中，生成各种重构类型的新评估实例。对于
    GSM8K、CLUTRR 和 BoolQ，我们生成了如表 [1](#S2.T1 "Table 1 ‣ 2 Benchmark Self-Evolving Framework
    ‣ Benchmark Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation")所示的所有六种类型的新实例。对于没有上下文的
    StrategyQA，我们仅生成具有复杂且精细问题的实例。具体来说，对于精细的子能力，我们关注 GSM8K 和 BoolQ 的任务规划能力，StrategyQA
    的任务规划和隐性知识识别能力，以及 CLUTRR 的所有三种子能力。生成的演化数据集统计如表 [2](#S2.T2 "Table 2 ‣ 2.2 Multi-Agent
    Evolving Instance Generator ‣ 2 Benchmark Self-Evolving Framework ‣ Benchmark
    Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation")所示。'
- en: Examined LLMs We evaluate both closed-source models, ChatGPT and ChatGLM Zeng
    et al. ([2023](#bib.bib30)), and open-source models, LLama Touvron et al. ([2023](#bib.bib25))
    and Mistral Jiang et al. ([2023](#bib.bib14)), using our evolving evaluation datasets.
    We compare their performance against on original datasets to demonstrate the effectiveness
    of our framework. For closed-source models, we use gpt-3.5-turbo-1106 and chatglm-turbo
    versions, while for open-source models, we employ LLama2-70B-Chat and Mistral-7B-Instruct-v0.2\.
    We also evaluate GPT-4 despite its involvement in generating evolving instances,
    to test whether they can also provide more scalable and robust evaluation for
    GPT-4.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 检查的 LLM 我们使用自演化评估数据集评估了闭源模型 ChatGPT 和 ChatGLM Zeng 等人 ([2023](#bib.bib30)) 以及开源模型
    LLama Touvron 等人 ([2023](#bib.bib25)) 和 Mistral Jiang 等人 ([2023](#bib.bib14))。我们将它们的性能与原始数据集进行比较，以展示我们框架的有效性。对于闭源模型，我们使用
    gpt-3.5-turbo-1106 和 chatglm-turbo 版本，而对于开源模型，我们采用 LLama2-70B-Chat 和 Mistral-7B-Instruct-v0.2。尽管
    GPT-4 参与了生成演化实例，我们仍对其进行评估，以测试它是否也能为 GPT-4 提供更具规模性和鲁棒性的评估。
- en: Task Formats We adopt two task formats tailored to different evaluation directions.
    For scalable and robust evaluations, we adhere to the original datasets’ task
    types, and employ a two-shot CoT prompting strategy. For fine-grained evaluation,
    we create binary-choice questions featuring two options, A and B, among which
    one is randomly selected as the correct answer and the other, developed by our
    Candidate Option Formulator, is incorrect. We implement a zero-shot prompting
    approach for fine-grained evaluation.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 任务格式 我们采用两种任务格式，以适应不同的评估方向。对于可扩展和稳健的评估，我们遵循原始数据集的任务类型，并采用两次提示的 CoT 策略。对于细粒度评估，我们创建了两个选项的二元选择问题，其中一个是随机选择的正确答案，另一个由我们的候选选项制定者开发，为错误答案。我们为细粒度评估实施零次提示的方法。
- en: 3.2 Overall Comparison
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 总体比较
- en: 'We first provide an overall assessment of LLMs with scalable and robust evaluations,
    leaving the fine-grained evaluation in Section [3.4](#S3.SS4 "3.4 Further Analysis
    on Sub-Ability ‣ 3 Experiments ‣ Benchmark Self-Evolving: A Multi-Agent Framework
    for Dynamic LLM Evaluation"). We conduct scalable evaluation using instances with
    alternative and complex questions, while performing robust evaluation using instances
    with paraphrased, noised and reversed contexts, and compare their performance
    against on corresponding original instances. For fair comparison, the average
    performance of original instances involved in each evaluation type is reported
    as their original performance. Table [3](#S3.T3 "Table 3 ‣ 3.2 Overall Comparison
    ‣ 3 Experiments ‣ Benchmark Self-Evolving: A Multi-Agent Framework for Dynamic
    LLM Evaluation") presents the main comparisons, with arrows indicate shifts from
    original to evolving evaluation results. We have following findings.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '我们首先提供 LLMs 的可扩展和稳健评估的整体评估，将细粒度评估留在第 [3.4](#S3.SS4 "3.4 Further Analysis on
    Sub-Ability ‣ 3 Experiments ‣ Benchmark Self-Evolving: A Multi-Agent Framework
    for Dynamic LLM Evaluation") 节。我们使用具有替代和复杂问题的实例进行可扩展评估，同时使用具有释义、噪声和反转上下文的实例进行稳健评估，并将其表现与相应原始实例进行比较。为了公平比较，报告每种评估类型中原始实例的平均性能作为其原始表现。表
    [3](#S3.T3 "Table 3 ‣ 3.2 Overall Comparison ‣ 3 Experiments ‣ Benchmark Self-Evolving:
    A Multi-Agent Framework for Dynamic LLM Evaluation") 展示了主要的比较，箭头表示从原始到演变评估结果的变化。我们的发现如下。'
- en: '| Models | Scalable Evaluation | Robust Evaluation | Overall |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 可扩展评估 | 稳健评估 | 总体 |'
- en: '| (Evolving$\leftarrow$Original) |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| (演变$\leftarrow$原始) |'
- en: '| GSM8K |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| GSM8K |'
- en: '| GPT-4 | 85.00 $\leftarrow$ 100.0 (- 6.93) |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | 85.00 $\leftarrow$ 100.0 (- 6.93) |'
- en: '| ChatGPT | 60.83 $\leftarrow$ 91.97 (-18.84) |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| ChatGPT | 60.83 $\leftarrow$ 91.97 (-18.84) |'
- en: '| ChatGLM | 42.50 $\leftarrow$ 67.04 (-11.08) |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| ChatGLM | 42.50 $\leftarrow$ 67.04 (-11.08) |'
- en: '| LLama | 40.83 $\leftarrow$ 59.00 (- 4.98) |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| LLama | 40.83 $\leftarrow$ 59.00 (- 4.98) |'
- en: '| Mistral | 27.50 $\leftarrow$ 40.17 (- 7.48) |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| Mistral | 27.50 $\leftarrow$ 40.17 (- 7.48) |'
- en: '| CLUTRR |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| CLUTRR |'
- en: '| GPT-4 | 77.11 $\leftarrow$ 100.0 (-13.45) |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | 77.11 $\leftarrow$ 100.0 (-13.45) |'
- en: '| ChatGPT | 65.66 $\leftarrow$ 82.49 ( -9.39) |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| ChatGPT | 65.66 $\leftarrow$ 82.49 (-9.39) |'
- en: '| ChatGLM | 55.42 $\leftarrow$ 74.11 (-11.93) |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| ChatGLM | 55.42 $\leftarrow$ 74.11 (-11.93) |'
- en: '| LLama | 47.59 $\leftarrow$ 34.77 (+ 5.35) |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| LLama | 47.59 $\leftarrow$ 34.77 (+ 5.35) |'
- en: '| Mistral | 45.78 $\leftarrow$ 54.57 (- 6.35) |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| Mistral | 45.78 $\leftarrow$ 54.57 (- 6.35) |'
- en: '| StrategyQA |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| StrategyQA |'
- en: '| GPT-4 | 98.25 $\leftarrow$ 100.0 (- 1.75) |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | 98.25 $\leftarrow$ 100.0 (- 1.75) |'
- en: '| ChatGPT | 64.91 $\leftarrow$ 91.23 (-26.32) |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| ChatGPT | 64.91 $\leftarrow$ 91.23 (-26.32) |'
- en: '| ChatGLM | 66.67 $\leftarrow$ 73.68 (- 7.01) |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| ChatGLM | 66.67 $\leftarrow$ 73.68 (- 7.01) |'
- en: '| LLama | 78.95 $\leftarrow$ 75.44 (+ 3.51) |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| LLama | 78.95 $\leftarrow$ 75.44 (+ 3.51) |'
- en: '| Mistral | 77.19 $\leftarrow$ 73.68 (+ 3.51) |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| Mistral | 77.19 $\leftarrow$ 73.68 (+ 3.51) |'
- en: '| BoolQ |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| BoolQ |'
- en: '| GPT-4 | 99.36 $\leftarrow$ 100.0 (- 1.83) |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | 99.36 $\leftarrow$ 100.0 (- 1.83) |'
- en: '| ChatGPT | 92.31 $\leftarrow$ 90.58 (+ 1.04) |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| ChatGPT | 92.31 $\leftarrow$ 90.58 (+ 1.04) |'
- en: '| ChatGLM | 86.54 $\leftarrow$ 88.48 (+ 0.53) |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| ChatGLM | 86.54 $\leftarrow$ 88.48 (+ 0.53) |'
- en: '| LLama | 84.62 $\leftarrow$ 91.88 (- 3.14) |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| LLama | 84.62 $\leftarrow$ 91.88 (- 3.14) |'
- en: '| Mistral | 76.92 $\leftarrow$ 79.58 (+ 1.05) |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| Mistral | 76.92 $\leftarrow$ 79.58 (+ 1.05) |'
- en: 'Table 3: Comparison of evolving and original evaluation. Left-side values of
    the arrow are evolving results, while the right-side denotes original performance
    on respective instances. Values in parentheses are performance changes.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '表 3: 演变与原始评估的比较。箭头左侧的值为演变结果，右侧表示相应实例的原始表现。括号中的值为性能变化。'
- en: (1)
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: Overall, most models exhibit reduced performance in our scalable and robust
    evaluation compared to their original results across the first three tasks. This
    offers a more accurate measure of LLMs’ capabilities, highlighting that original
    results potential overestimate their proficiency. The decline of all models except
    LLama in robust evaluation on GSM8K and CLUTRR indicating their limited robustness.
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 总体而言，大多数模型在我们的可扩展和稳健评估中表现出相较于前三个任务的原始结果性能下降。这提供了对LLM能力更准确的衡量，突显了原始结果可能高估了它们的能力。所有模型在GSM8K和CLUTRR的稳健评估中表现下降，除了LLama，这表明它们的鲁棒性有限。
- en: (2)
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: GPT-4, though achieving 100% accuracy on manageable original instances, still
    experiences performance drops on our evolving instances. This is because these
    evolving instances are generated by GPT-4 given the original ones with correct
    answers, aiding model’s reasoning. Yet, directly evaluating GPT-4 with evolving
    instances would uncover their limitations.
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: GPT-4虽然在可管理的原始实例上达到了100%的准确率，但在我们的演变实例上仍然会出现性能下降。这是因为这些演变实例是GPT-4在给定原始实例和正确答案的情况下生成的，帮助模型进行推理。然而，直接用演变实例评估GPT-4会揭示其局限性。
- en: (3)
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3)
- en: Our scalable and robust evaluation effectively expand the performance gap between
    models. Initially, GPT-4 and ChatGPT exhibit less than a 10% accuracy difference
    on GSM8K, while this gap increased to 20% under our evolved evaluation. On the
    BoolQ dataset where all models consistently perform well, our scalable evaluation
    further highlights their disparities.
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们的可扩展和稳健评估有效地扩大了模型之间的性能差距。最初，GPT-4和ChatGPT在GSM8K上的准确率差距不到10%，而在我们的演变评估中，这一差距增加到了20%。在所有模型在BoolQ数据集上表现一致的情况下，我们的可扩展评估进一步突显了它们的差异。
- en: (4)
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (4)
- en: Our framework also widens performance discrepancies of the same model across
    various tasks. For example, while ChatGPT consistently achieves 80$\sim$90% accuracy
    on four tasks, its proficiency notably diverges following scalable evaluation,
    only maintaining stable performance on BoolQ. Similarly, GPT-4 shows performance
    disparities after our evaluation, maintaining effectiveness on most datasets while
    showing a decrease on CLUTRR.
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们的框架还扩大了相同模型在不同任务中的性能差异。例如，虽然ChatGPT在四个任务上的准确率始终保持在80$\sim$90%之间，但其能力在可扩展评估后显著出现差异，仅在BoolQ上保持稳定的性能。同样，GPT-4在我们的评估后表现出性能差异，在大多数数据集上维持有效性，但在CLUTRR上的表现有所下降。
- en: 3.3 Analysis of Varied Reframing Operations
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 多样化重构操作分析
- en: 'To further assess the impact of various reframing operations on model evaluation,
    we gather results of each operation across all datasets and compare them with
    corresponding original results. Our analysis as detailed in Figure [3](#S3.F3
    "Figure 3 ‣ 3.3 Analysis of Varied Reframing Operations ‣ 3 Experiments ‣ Benchmark
    Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation") shows that
    among five reframing operations, question complicating cause the most disruption
    to models, followed by polarity reversing and question alternating. In contrast,
    context paraphrasing and context noising have a limited impact on model performance.
    These findings suggest that our framework primarily enhances the original benchmarks
    by highlighting the limitations of these LLMs regarding question generalizability
    and their susceptibility to adversarial attacks.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 为进一步评估不同重构操作对模型评估的影响，我们收集了每个操作在所有数据集上的结果，并与相应的原始结果进行比较。我们的分析如图[3](#S3.F3 "图3
    ‣ 3.3 多样化重构操作分析 ‣ 3 实验 ‣ 基准自我演变：一种动态LLM评估的多智能体框架")所示，五种重构操作中，问题复杂化对模型的干扰最大，其次是极性反转和问题交替。相比之下，上下文释义和上下文噪声对模型性能的影响有限。这些发现表明，我们的框架主要通过突出这些LLM在问题泛化和对抗攻击的脆弱性来增强原始基准。
- en: '![Refer to caption](img/024b60e2a7cebb27d101cbce0a957b9d.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/024b60e2a7cebb27d101cbce0a957b9d.png)'
- en: 'Figure 3: Comparison of evolving results using various reframing operations
    versus original results. Darker bars show accuracy for each operation across all
    datasets, with lighter bars ahead representing original accuracy.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：使用不同重构操作与原始结果的比较。较深的条形图显示每个操作在所有数据集上的准确率，前面较浅的条形图代表原始准确率。
- en: 'We further offer a perplexity-based analysis in Appendix [B.4](#A2.SS4 "B.4
    Dataset Perplexity Analysis ‣ Appendix B Experimental Analysis ‣ Benchmark Self-Evolving:
    A Multi-Agent Framework for Dynamic LLM Evaluation") demonstrating that our generated
    instances exhibit greater complexity and diversity than the original instances
    for dynamic evaluation, along with an error analysis in Appendix [B.5](#A2.SS5
    "B.5 Error Analysis ‣ Appendix B Experimental Analysis ‣ Benchmark Self-Evolving:
    A Multi-Agent Framework for Dynamic LLM Evaluation").'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在附录 [B.4](#A2.SS4 "B.4 数据集困惑度分析 ‣ 附录 B 实验分析 ‣ 基准自演变：动态 LLM 评估的多智能体框架") 提供了基于困惑度的分析，展示了我们生成的实例比原始实例在动态评估中展现出更大的复杂性和多样性，同时附录
    [B.5](#A2.SS5 "B.5 错误分析 ‣ 附录 B 实验分析 ‣ 基准自演变：动态 LLM 评估的多智能体框架") 中包含了错误分析。
- en: 3.4 Further Analysis on Sub-Ability
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 子能力进一步分析
- en: 'The fine-grained evaluation in our framework paves a way to dissect the sub-abilities
    of models. We aggregate the results of each sub-ability across all datasets and
    compare the models’ rankings against their original ranking, as shown in Figure [4a](#S3.F4.sf1
    "In Figure 4 ‣ 3.4 Further Analysis on Sub-Ability ‣ 3 Experiments ‣ Benchmark
    Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation").'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们框架中的细粒度评估为剖析模型的子能力提供了方法。我们汇总了所有数据集中每个子能力的结果，并将模型的排名与其原始排名进行比较，如图 [4a](#S3.F4.sf1
    "在图 4 中 ‣ 3.4 子能力进一步分析 ‣ 3 实验 ‣ 基准自演变：动态 LLM 评估的多智能体框架") 所示。
- en: Substantial Discrepancy Between Original and Fine-grained Evaluations. Our findings
    reveal that ChatGLM, initially lagging behind ChatGPT in original evaluation,
    surprisingly outperforms ChatGPT in all sub-ability evaluations. Upon scrutinizing
    ChatGPT’s results, we observe a significant selection bias towards option ’A’.
    We hypothesize that such bias in certain LLMs impairs their decision-making, leading
    to poorer performance.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 原始评估与细粒度评估之间的显著差异。我们的发现表明，ChatGLM 在原始评估中起初落后于 ChatGPT，但在所有子能力评估中意外地超越了 ChatGPT。仔细审查
    ChatGPT 的结果后，我们观察到对选项 ‘A’ 存在显著的选择偏差。我们假设某些 LLM 的这种偏差会影响其决策，导致性能较差。
- en: 'Presence of Selection Bias in Certain LLMs. Following Zheng et al. ([2023a](#bib.bib32)),
    We estimate the prior prediction distribution of different LLMs on options ID
    ’A’ and ’B’. The result in Figure [4b](#S3.F4.sf2 "In Figure 4 ‣ 3.4 Further Analysis
    on Sub-Ability ‣ 3 Experiments ‣ Benchmark Self-Evolving: A Multi-Agent Framework
    for Dynamic LLM Evaluation") shows that ChatGPT, LLama, and Mistral exhibit a
    significant preference towards ’A’, in contrast to the neutral stance of GPT-4
    and ChatGLM. For a fair model evaluation, we utilize a bias calibrating method
    to obtain debiased results as shown in Figure [4c](#S3.F4.sf3 "In Figure 4 ‣ 3.4
    Further Analysis on Sub-Ability ‣ 3 Experiments ‣ Benchmark Self-Evolving: A Multi-Agent
    Framework for Dynamic LLM Evaluation"), with methodologies for bias calculation
    and mitigation detailed in Appendix [B.3](#A2.SS3 "B.3 Selection Bias Analysis
    ‣ Appendix B Experimental Analysis ‣ Benchmark Self-Evolving: A Multi-Agent Framework
    for Dynamic LLM Evaluation").'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 某些 LLM 的选择偏差。根据 Zheng 等人 ([2023a](#bib.bib32)) 的研究，我们估算了不同 LLM 对选项 ID ‘A’ 和
    ‘B’ 的预测分布。图 [4b](#S3.F4.sf2 "在图 4 中 ‣ 3.4 子能力进一步分析 ‣ 3 实验 ‣ 基准自演变：动态 LLM 评估的多智能体框架")
    显示，ChatGPT、LLama 和 Mistral 对 ‘A’ 表现出显著的偏好，与 GPT-4 和 ChatGLM 的中立立场形成对比。为了公平评估模型，我们采用了偏差校正方法，得到去偏差结果，如图
    [4c](#S3.F4.sf3 "在图 4 中 ‣ 3.4 子能力进一步分析 ‣ 3 实验 ‣ 基准自演变：动态 LLM 评估的多智能体框架") 所示，偏差计算和缓解的方法详见附录
    [B.3](#A2.SS3 "B.3 选择偏差分析 ‣ 附录 B 实验分析 ‣ 基准自演变：动态 LLM 评估的多智能体框架")。
- en: '![Refer to caption](img/65081a9401d2064082ad9529830ce819.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/65081a9401d2064082ad9529830ce819.png)'
- en: a Biased results.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: a 偏差结果。
- en: '![Refer to caption](img/4284edfc40bed02d717899e655b0dadd.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4284edfc40bed02d717899e655b0dadd.png)'
- en: b Selection Bias of Various LLMs.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: b 各种 LLM 的选择偏差。
- en: '![Refer to caption](img/6bd61ddc3bb940535b8ddfa8c2d419a7.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/6bd61ddc3bb940535b8ddfa8c2d419a7.png)'
- en: c Debiased results.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: c 去偏差结果。
- en: 'Figure 4: Results of fine-grained sub-ability evaluation.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：细粒度子能力评估结果。
- en: '![Refer to caption](img/4d8b027b37fe031ae0eb4d4ea5e68f82.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4d8b027b37fe031ae0eb4d4ea5e68f82.png)'
- en: 'Figure 5: Comparison of LLama-2-7B-Chat models under different contamination
    conditions. “Vanilla”, “In-domain Cont.” and “Direct Cont.” denotes the original
    model, the in-domain contaminated and direct contaminated models.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：在不同污染条件下的LLama-2-7B-Chat模型比较。“Vanilla”，“In-domain Cont.”和“Direct Cont.”分别表示原始模型、领域内污染模型和直接污染模型。
- en: 'Improvement Potential for Planning Ability As Figure [4c](#S3.F4.sf3 "In Figure
    4 ‣ 3.4 Further Analysis on Sub-Ability ‣ 3 Experiments ‣ Benchmark Self-Evolving:
    A Multi-Agent Framework for Dynamic LLM Evaluation"), GPT-4 consistently performs
    best across all three sub-abilities while Mistral showing the lowest performance.
    Among three sub-abilities, planning emerges as the weakest skill for all LLMs,
    highlighting a key area for further enhancements.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 计划能力的改进潜力 如图[4c](#S3.F4.sf3 "图4 ‣ 3.4 子能力的进一步分析 ‣ 3 实验 ‣ 基准自我演变：一种用于动态LLM评估的多智能体框架")，GPT-4在所有三个子能力中表现最佳，而Mistral表现最差。在这三种子能力中，计划能力是所有LLM中最弱的技能，突出显示了进一步改进的关键领域。
- en: 3.5 Quality of Evolving Instances
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.5 演变实例的质量
- en: Human Verification To demonstrate the reliability of our dynamic evaluation,
    we sample a subset of our generated instances and conduct a human annotation ³³3Manually
    verified by the authors. to assess their quality. Specifically, we randomly select
    five instances that are incorrectly answered by ChatGPT for each reframing operation
    across all datasets, with a total of 115 instances. Following human verification,
    110 out of 115 instances (95.7%) are deemed accurate, reinforcing the credibility
    of our evolving instances.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 人工验证 为了展示我们动态评估的可靠性，我们抽取了一部分生成实例进行人工标注³³由作者手动验证。以评估其质量。具体而言，我们从所有数据集中，每个重构操作中随机选择五个ChatGPT回答错误的实例，总计115个实例。经过人工验证，115个实例中的110个（95.7%）被认为准确，增强了我们演变实例的可信度。
- en: 'Instance Filter Rate Our system incorporates a pre-filter and a double-verification
    process to enhance the reliability of generated instances. The pre-filter discards
    nearly 9% of the original instances that exceed the capabilities of GPT-4\. Following
    this, the double-verification stage filters out approximately 24% which initially
    processed correctly by GPT-4 (Detailed statistics are in Appendix [B.2](#A2.SS2
    "B.2 Instance Filtering Statistics ‣ Appendix B Experimental Analysis ‣ Benchmark
    Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation")). This underscores
    the importance of our double-verification strategy on instance quality.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 实例过滤率 我们的系统包括预过滤和双重验证过程，以提高生成实例的可靠性。预过滤阶段丢弃了近9%超出GPT-4能力范围的原始实例。随后，双重验证阶段过滤掉了大约24%最初由GPT-4正确处理的实例（详细统计见附录[B.2](#A2.SS2
    "B.2 实例过滤统计 ‣ 附录B 实验分析 ‣ 基准自我演变：一种用于动态LLM评估的多智能体框架")）。这突显了我们的双重验证策略对实例质量的重要性。
- en: 3.6 Impact on Data Contamination
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.6 数据污染的影响
- en: 'To further analyze our framework’s ability to mitigate data contamination,
    we design controlled experiments to simulate data contamination. We construct
    two instruction-tuning datasets: one simulating in-domain contamination by including
    portions of our evaluation benchmark’s training set, and the other simulating
    direct contamination by incorporating both training and evaluation sets. We respectively
    use these two datasets to fine-tune LLama-2-7B-Chat (details in Appendix [B.6](#A2.SS6
    "B.6 Data Contamination Experiment Details ‣ Appendix B Experimental Analysis
    ‣ Benchmark Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation")).
    We assess the original model and two fine-tuned models using original evaluation
    instances and our generated evolving instances, with results shown in Figure [5](#S3.F5
    "Figure 5 ‣ 3.4 Further Analysis on Sub-Ability ‣ 3 Experiments ‣ Benchmark Self-Evolving:
    A Multi-Agent Framework for Dynamic LLM Evaluation").'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步分析我们框架减轻数据污染的能力，我们设计了受控实验来模拟数据污染。我们构建了两个指令调整数据集：一个通过包含我们评估基准的训练集的部分来模拟领域内污染，另一个通过包含训练集和评估集来模拟直接污染。我们分别使用这两个数据集对LLama-2-7B-Chat进行微调（详细信息见附录[B.6](#A2.SS6
    "B.6 数据污染实验详情 ‣ 附录B 实验分析 ‣ 基准自我演变：一种用于动态LLM评估的多智能体框架")）。我们使用原始评估实例和我们生成的演变实例来评估原始模型和两个微调模型，结果见图[5](#S3.F5
    "图5 ‣ 3.4 子能力的进一步分析 ‣ 3 实验 ‣ 基准自我演变：一种用于动态LLM评估的多智能体框架")。
- en: •
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Compared to the original model, both in-domain and direct contaminated models
    show notable improvement under original evaluation, revealing how data contamination
    can skew evaluations. In contrast, under our dynamic evaluation, the performance
    gap between contaminated models and the original model decreases, especially in
    scalable and fine-grained assessments. This indicates our framework’s resistance
    against data contamination.
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与原始模型相比，领域内和直接污染模型在原始评估下均显示出显著的改进，揭示了数据污染如何扭曲评估。相比之下，在我们的动态评估下，污染模型与原始模型之间的性能差距减少，特别是在可扩展和细粒度评估中。这表明我们的框架对数据污染具有抵抗力。
- en: •
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: In fine-grained evaluations, the in-domain contaminated model surpasses the
    original model, indicating that in-domain training can enhance task-related abilities.
    Yet, the direct contaminated model performs worse than the original, suggesting
    that memorizing original answers may hinder problem-solving in new contexts. This
    highlights the value of fine-grained evaluations in mitigating data contamination
    effects.
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在细粒度评估中，领域内污染模型优于原始模型，表明领域内训练可以提升与任务相关的能力。然而，直接污染模型表现不如原始模型，表明记忆原始答案可能会妨碍在新情境下的解决问题。这突显了细粒度评估在减轻数据污染影响方面的价值。
- en: 4 Related Work
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 相关工作
- en: LLMs Evaluation
  id: totrans-131
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: LLM 评估
- en: Recent advanced large language models OpenAI ([2023](#bib.bib19)); Jiang et al.
    ([2023](#bib.bib14)); Touvron et al. ([2023](#bib.bib25)), have shown remarkable
    performance across various tasks and sparked significant interest in their evaluation Chang
    et al. ([2023](#bib.bib3)); Liu et al. ([2023a](#bib.bib17)). The evaluation for
    LLMs encompass automatic evaluation, human evaluation and LLM-based evaluation
    that respectively utilizes automatic metrics Liang et al. ([2022](#bib.bib16)),
    human preference Zheng et al. ([2023b](#bib.bib33)) and LLM feedback Liu et al.
    ([2023b](#bib.bib18)); Zhang et al. ([2023](#bib.bib31)). Automatic evaluation
    offers a most cost-effective approach for extensive and comprehensive assessments,
    necessitating diverse benchmark datasets, including task-specific benchmarks Yu
    et al. ([2023](#bib.bib29)); Holmes et al. ([2023](#bib.bib13)) and general benchmarks Hendrycks
    et al. ([2020](#bib.bib12)); bench authors ([2023](#bib.bib1)). However, with
    the rapid evolution of LLMs and potential data contamination issue, these static
    benchmarks tend to be inadequate for a thorough assessment. To address this, our
    benchmark self-evolving framework dynamically updating instances via a multi-agent
    system, providing a dynamic solution for LLM evaluation.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的高级大型语言模型 OpenAI ([2023](#bib.bib19)); Jiang et al. ([2023](#bib.bib14));
    Touvron et al. ([2023](#bib.bib25))，在各种任务中表现出色，引发了对其评估的极大兴趣 Chang et al. ([2023](#bib.bib3));
    Liu et al. ([2023a](#bib.bib17))。LLM 的评估包括自动评估、人类评估和基于 LLM 的评估，这三者分别利用自动指标 Liang
    et al. ([2022](#bib.bib16))、人类偏好 Zheng et al. ([2023b](#bib.bib33)) 和 LLM 反馈 Liu
    et al. ([2023b](#bib.bib18)); Zhang et al. ([2023](#bib.bib31))。自动评估提供了一种最具成本效益的方法来进行广泛而全面的评估，需要多样化的基准数据集，包括任务特定的基准
    Yu et al. ([2023](#bib.bib29)); Holmes et al. ([2023](#bib.bib13)) 和一般基准 Hendrycks
    et al. ([2020](#bib.bib12)); bench authors ([2023](#bib.bib1))。然而，随着 LLM 的快速发展和潜在的数据污染问题，这些静态基准往往不足以进行全面评估。为了解决这一问题，我们的基准自我进化框架通过多代理系统动态更新实例，提供了一种动态解决方案用于
    LLM 评估。
- en: Data Contamination The expansion of training datasets for LLMs introduces a
    significant challenge of data contamination. This results in an in-domain distribution
    overlap with existing datasets, or even publicly available development and test
    sets, risking biased evaluation Sainz et al. ([2023](#bib.bib22)). Such contamination
    undermines the fairness and accuracy of benchmarks Zhou et al. ([2023](#bib.bib34)),
    casting doubt on whether high performance reflects true generalization or merely
    data memorization Biderman et al. ([2023](#bib.bib2)). Shi et al. ([2023](#bib.bib23))
    and Golchin and Surdeanu ([2023](#bib.bib11)) propose detecting contaminated data
    from benchmark for LLMs and use untainted data for evaluation. Besides, Wei et al.
    ([2023](#bib.bib27)) utilize perplexity as an evaluation metric on newly sampled
    data without additional annotations, yet this may not fully reflect models’ capabilities.
    Our benchmark self-evolving framework can mitigate evaluation bias caused by data
    contamination.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 数据污染：扩展大语言模型（LLM）的训练数据集带来了数据污染的重大挑战。这导致了与现有数据集或甚至公开开发和测试集的领域内分布重叠，存在偏见评估的风险 Sainz
    et al. ([2023](#bib.bib22))。这种污染削弱了基准测试的公平性和准确性 Zhou et al. ([2023](#bib.bib34))，使人们对高性能是否反映了真实的泛化能力还是仅仅是数据记忆产生怀疑 Biderman
    et al. ([2023](#bib.bib2))。Shi et al. ([2023](#bib.bib23)) 和 Golchin 和 Surdeanu
    ([2023](#bib.bib11)) 提出了从基准中检测污染数据并使用未受污染的数据进行评估的方法。此外，Wei et al. ([2023](#bib.bib27))
    通过对新采样数据使用困惑度作为评估指标，而没有额外的注释，但这可能不能完全反映模型的能力。我们的基准自演变框架可以减轻由数据污染引起的评估偏差。
- en: 5 Conclusion
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: In this study, we introduce a benchmark self-evolving framework that employs
    a multi-agent system to enhance existing benchmarks for a more scalable, robust
    and fine-grained evaluation on LLMs. Results indicate a general decline in LLM
    performance, alongside significant discrepancies in performance across various
    models and tasks. This highlights the effectiveness of our framework in providing
    a more accurate and comprehensive evaluation of LLMs, as well as distinguishing
    the capabilities of various models. Our study aids in selecting the most suitable
    LLMs for specific applications, and guide their further development.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们引入了一个基准自演变框架，该框架利用多智能体系统来增强现有基准，从而对LLM进行更具规模、强健和细粒度的评估。结果表明，LLM的性能普遍下降，同时不同模型和任务之间的性能差异显著。这突显了我们框架在提供更准确和全面的LLM评估方面的有效性，以及区分各种模型能力的能力。我们的研究有助于选择最适合特定应用的LLM，并指导其进一步发展。
- en: Limitations
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 限制
- en: Limitation on benchmark coverage
  id: totrans-137
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基准覆盖的限制
- en: Due to computational limit, our dynamic evaluation study only explores four
    datasets across various textual tasks and select 100 instances from each dataset
    to construct nearly 1600 evolving instances. Our framework can flexibly generalize
    to other tasks and even different modalities for a broader analysis.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 由于计算限制，我们的动态评估研究仅探索了四个数据集在各种文本任务中的表现，并从每个数据集中选择了100个实例来构建近1600个演变实例。我们的框架可以灵活地推广到其他任务甚至不同的模态，以进行更广泛的分析。
- en: Limitation on examine LLMs
  id: totrans-139
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 评估LLM的限制
- en: We evaluate three closed-source (GPT-4, ChatGPT, ChatGLM) and two open-sourec
    LLMs (LLama, Mistral) using our crafted evolving instances to illustrate our scalable,
    robust and fine-grained evaluation. We acknowledge the limitation in the scope
    of LLMs, and will later provide further experiments on more LLMs.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用我们制作的演变实例对三种闭源（GPT-4、ChatGPT、ChatGLM）和两种开源LLM（LLama、Mistral）进行了评估，以展示我们的规模化、强健和细粒度评估。我们承认LLM范围的限制，并将来提供对更多LLM的进一步实验。
- en: Limitation on instance accuracy
  id: totrans-141
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 实例准确性的限制
- en: Despite incorporating a pre-filtering and double-verification procedure, our
    system, which is entirely powered by GPT-4, may inevitably generate a small number
    of instances with inaccuracies, as evidenced by human verification. This might
    result in less accurate assessments of LLMs.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管包含了预过滤和双重验证程序，我们的系统完全由GPT-4驱动，可能不可避免地会生成少量不准确的实例，正如人工验证所证明的。这可能导致对LLM的评估不够准确。
- en: Risks
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 风险
- en: Introduction of Factual Errors
  id: totrans-144
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 事实错误的引入
- en: For benchmark datasets containing factual information, such as BoolQ, our framework
    may generate counterfactual information to alter the key details of the original
    context during the polarity reversing operation. Such inaccuracies, if inadvertently
    used as learning material by the models, could negatively impact their performance
    and reliability.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 对于包含事实信息的基准数据集，如BoolQ，我们的框架可能会生成反事实信息，以在极性反转操作期间更改原始上下文的关键细节。如果这些不准确的信息被模型作为学习材料不经意使用，可能会对其性能和可靠性产生负面影响。
- en: Environmental Impact
  id: totrans-146
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 环境影响
- en: A significant risk associated with our methodology is the potential increase
    in environmental impact due to the extensive use of OpenAI’s APIs for large language
    models. This is particularly concerning for benchmarks of substantial size, as
    the energy consumption and carbon footprint associated with generating evolving
    instances could be considerable.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的方法学的一个重大风险是，由于大量使用OpenAI的API，可能会增加环境影响。这在大规模基准测试中尤为令人担忧，因为生成演变实例所需的能量消耗和碳足迹可能会相当可观。
- en: Ethics Statement
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 伦理声明
- en: All data utilized in our benchmark self-evolving framework are sourced from
    publicly available datasets, including GSM8K, CLUTRR, StrategyQA and BoolQ. Our
    generated evolving instances for dynamic evaluation are also publicly released
    for usage and have been subjected to a thorough review by the authors. This setting
    guarantees transparency and reproducibility in our experiments, allowing other
    researchers to evaluate and expand upon our work. Our benchmark-evolving framework
    is strictly limited to be used for instance generation that follow the ethical
    guidelines of the community. The authors emphatically denounce the use of our
    framework for generating inaccurate or harmful instances.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们基准自我演变框架中使用的所有数据均来自公开可用的数据集，包括GSM8K、CLUTRR、StrategyQA和BoolQ。我们为动态评估生成的演变实例也已公开发布，并经过了作者的全面审查。此设置保证了我们实验的透明性和可重复性，使其他研究人员可以评估和扩展我们的工作。我们的基准演变框架严格限制用于生成遵循社区伦理指南的实例。作者强烈谴责使用我们的框架生成不准确或有害的实例。
- en: References
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'bench authors (2023) BIG bench authors. 2023. [Beyond the imitation game: Quantifying
    and extrapolating the capabilities of language models](https://openreview.net/forum?id=uyTL5Bvosj).
    *Transactions on Machine Learning Research*.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: bench authors (2023) BIG bench authors. 2023. [超越模仿游戏：量化和外推语言模型的能力](https://openreview.net/forum?id=uyTL5Bvosj)。*机器学习研究汇刊*。
- en: 'Biderman et al. (2023) Stella Biderman, Hailey Schoelkopf, Quentin Gregory
    Anthony, Herbie Bradley, Kyle O’Brien, Eric Hallahan, Mohammad Aflah Khan, Shivanshu
    Purohit, USVSN Sai Prashanth, Edward Raff, et al. 2023. Pythia: A suite for analyzing
    large language models across training and scaling. In *International Conference
    on Machine Learning*, pages 2397–2430\. PMLR.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Biderman et al. (2023) Stella Biderman, Hailey Schoelkopf, Quentin Gregory Anthony,
    Herbie Bradley, Kyle O’Brien, Eric Hallahan, Mohammad Aflah Khan, Shivanshu Purohit,
    USVSN Sai Prashanth, Edward Raff, 等. 2023. Pythia：一个用于分析大型语言模型的套件，涵盖训练和扩展。在*国际机器学习大会*，第2397–2430页。PMLR。
- en: Chang et al. (2023) Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Kaijie Zhu,
    Hao Chen, Linyi Yang, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, et al. 2023. A
    survey on evaluation of large language models. *arXiv preprint arXiv:2307.03109*.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chang et al. (2023) Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Kaijie Zhu,
    Hao Chen, Linyi Yang, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, 等. 2023. 大型语言模型评估调查。*arXiv
    预印本 arXiv:2307.03109*。
- en: 'Chiang et al. (2023) Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao
    Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez,
    Ion Stoica, and Eric P. Xing. 2023. [Vicuna: An open-source chatbot impressing
    gpt-4 with 90%* chatgpt quality](https://lmsys.org/blog/2023-03-30-vicuna/).'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chiang et al. (2023) Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao
    Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez,
    Ion Stoica, 和 Eric P. Xing. 2023. [Vicuna：一个开源聊天机器人，以90%* ChatGPT质量给GPT-4留下深刻印象](https://lmsys.org/blog/2023-03-30-vicuna/)。
- en: 'Clark et al. (2019) Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski,
    Michael Collins, and Kristina Toutanova. 2019. Boolq: Exploring the surprising
    difficulty of natural yes/no questions. *NAACL*.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Clark et al. (2019) Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski,
    Michael Collins, 和 Kristina Toutanova. 2019. Boolq：探索自然是/否问题的意外困难。*NAACL*。
- en: Cobbe et al. (2021) Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen,
    Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro
    Nakano, et al. 2021. Training verifiers to solve math word problems. *arXiv preprint
    arXiv:2110.14168*.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cobbe 等人（2021）**Karl Cobbe**, **Vineet Kosaraju**, **Mohammad Bavarian**, **Mark
    Chen**, **Heewoo Jun**, **Lukasz Kaiser**, **Matthias Plappert**, **Jerry Tworek**,
    **Jacob Hilton**, **Reiichiro Nakano** 等。2021年。训练验证者解决数学文字问题。*arXiv 预印本 arXiv:2110.14168*。
- en: 'Dong et al. (2023) Guanting Dong, Jinxu Zhao, Tingfeng Hui, Daichi Guo, Wenlong
    Wan, Boqi Feng, Yueyan Qiu, Zhuoma Gongque, Keqing He, Zechen Wang, and Weiran
    Xu. 2023. [Revisit input perturbation problems for llms: A unified robustness
    evaluation framework for noisy slot filling task](http://arxiv.org/abs/2310.06504).'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dong 等人（2023）**Guanting Dong**, **Jinxu Zhao**, **Tingfeng Hui**, **Daichi Guo**,
    **Wenlong Wan**, **Boqi Feng**, **Yueyan Qiu**, **Zhuoma Gongque**, **Keqing He**,
    **Zechen Wang**, 和 **Weiran Xu**。2023年。[重新审视LLMs的输入扰动问题：一种统一的噪声槽填充任务鲁棒性评估框架](http://arxiv.org/abs/2310.06504)。
- en: Espejel et al. (2023) Jessica López Espejel, El Hassane Ettifouri, Mahaman Sanoussi Yahaya
    Alassan, El Mehdi Chouham, and Walid Dahhane. 2023. Gpt-3.5, gpt-4, or bard? evaluating
    llms reasoning ability in zero-shot setting and performance boosting through prompts.
    *Natural Language Processing Journal*, 5:100032.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Espejel 等人（2023）**Jessica López Espejel**, **El Hassane Ettifouri**, **Mahaman
    Sanoussi Yahaya Alassan**, **El Mehdi Chouham**, 和 **Walid Dahhane**。2023年。**GPT-3.5**,
    **GPT-4**, 还是 **Bard**？评估LLMs在零样本设置中的推理能力以及通过提示提高的表现。*自然语言处理期刊*，5:100032。
- en: 'Gallegos et al. (2023) Isabel O Gallegos, Ryan A Rossi, Joe Barrow, Md Mehrab
    Tanjim, Sungchul Kim, Franck Dernoncourt, Tong Yu, Ruiyi Zhang, and Nesreen K
    Ahmed. 2023. Bias and fairness in large language models: A survey. *arXiv preprint
    arXiv:2309.00770*.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gallegos 等人（2023）**Isabel O Gallegos**, **Ryan A Rossi**, **Joe Barrow**, **Md
    Mehrab Tanjim**, **Sungchul Kim**, **Franck Dernoncourt**, **Tong Yu**, **Ruiyi
    Zhang**, 和 **Nesreen K Ahmed**。2023年。大型语言模型中的偏见与公平性：综述。*arXiv 预印本 arXiv:2309.00770*。
- en: Geva et al. (2021) Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth,
    and Jonathan Berant. 2021. Did aristotle use a laptop? a question answering benchmark
    with implicit reasoning strategies. *Transactions of the Association for Computational
    Linguistics*, 9:346–361.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Geva 等人（2021）**Mor Geva**, **Daniel Khashabi**, **Elad Segal**, **Tushar Khot**,
    **Dan Roth**, 和 **Jonathan Berant**。2021年。**亚里士多德**是否使用过笔记本电脑？一个带有隐含推理策略的问答基准。*计算语言学协会会刊*，9:346–361。
- en: 'Golchin and Surdeanu (2023) Shahriar Golchin and Mihai Surdeanu. 2023. Time
    travel in llms: Tracing data contamination in large language models. *arXiv preprint
    arXiv:2308.08493*.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Golchin 和 Surdeanu（2023）**Shahriar Golchin** 和 **Mihai Surdeanu**。2023年。LLMs中的时间旅行：追踪大型语言模型中的数据污染。*arXiv
    预印本 arXiv:2308.08493*。
- en: Hendrycks et al. (2020) Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou,
    Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2020. Measuring massive multitask
    language understanding. *arXiv preprint arXiv:2009.03300*.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hendrycks 等人（2020）**Dan Hendrycks**, **Collin Burns**, **Steven Basart**, **Andy
    Zou**, **Mantas Mazeika**, **Dawn Song**, 和 **Jacob Steinhardt**。2020年。测量大规模多任务语言理解。*arXiv
    预印本 arXiv:2009.03300*。
- en: Holmes et al. (2023) Jason Holmes, Zhengliang Liu, Lian Zhang, Yuzhen Ding,
    Terence T Sio, Lisa A McGee, Jonathan B Ashman, Xiang Li, Tianming Liu, Jiajian
    Shen, et al. 2023. Evaluating large language models on a highly-specialized topic,
    radiation oncology physics. *arXiv preprint arXiv:2304.01938*.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Holmes 等人（2023）**Jason Holmes**, **Zhengliang Liu**, **Lian Zhang**, **Yuzhen
    Ding**, **Terence T Sio**, **Lisa A McGee**, **Jonathan B Ashman**, **Xiang Li**,
    **Tianming Liu**, **Jiajian Shen** 等。2023年。在高度专业化的主题——放射肿瘤物理学上评估大型语言模型。*arXiv
    预印本 arXiv:2304.01938*。
- en: Jiang et al. (2023) Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris
    Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna
    Lengyel, Guillaume Lample, Lucile Saulnier, et al. 2023. Mistral 7b. *arXiv preprint
    arXiv:2310.06825*.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang 等人（2023）**Albert Q Jiang**, **Alexandre Sablayrolles**, **Arthur Mensch**,
    **Chris Bamford**, **Devendra Singh Chaplot**, **Diego de las Casas**, **Florian
    Bressand**, **Gianna Lengyel**, **Guillaume Lample**, **Lucile Saulnier** 等。2023年。**Mistral
    7b**。*arXiv 预印本 arXiv:2310.06825*。
- en: 'Kiela et al. (2021) Douwe Kiela, Max Bartolo, Yixin Nie, Divyansh Kaushik,
    Atticus Geiger, Zhengxuan Wu, Bertie Vidgen, Grusha Prasad, Amanpreet Singh, Pratik
    Ringshia, et al. 2021. Dynabench: Rethinking benchmarking in nlp. *arXiv preprint
    arXiv:2104.14337*.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kiela 等人（2021）**Douwe Kiela**, **Max Bartolo**, **Yixin Nie**, **Divyansh Kaushik**,
    **Atticus Geiger**, **Zhengxuan Wu**, **Bertie Vidgen**, **Grusha Prasad**, **Amanpreet
    Singh**, **Pratik Ringshia** 等。2021年。**Dynabench**：重新思考NLP中的基准测试。*arXiv 预印本 arXiv:2104.14337*。
- en: Liang et al. (2022) Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras,
    Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya
    Kumar, et al. 2022. Holistic evaluation of language models. *arXiv preprint arXiv:2211.09110*.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liang 等人（2022）**Percy Liang**, **Rishi Bommasani**, **Tony Lee**, **Dimitris
    Tsipras**, **Dilara Soylu**, **Michihiro Yasunaga**, **Yian Zhang**, **Deepak
    Narayanan**, **Yuhuai Wu**, **Ananya Kumar** 等。2022年。语言模型的整体评估。*arXiv 预印本 arXiv:2211.09110*。
- en: 'Liu et al. (2023a) Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu
    Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, et al. 2023a. Agentbench:
    Evaluating llms as agents. *arXiv preprint arXiv:2308.03688*.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu et al. (2023a) 萧刘, 浩宇·余, 汉臣·张, 逸凡·徐, 轩宇·雷, 汉宇·赖, 于·顾, 杭亮·丁, 凯文·门, 科娟·杨,
    等. 2023a. Agentbench: 评估大语言模型作为代理。*arXiv预印本 arXiv:2308.03688*。'
- en: 'Liu et al. (2023b) Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu,
    and Chenguang Zhu. 2023b. Gpteval: Nlg evaluation using gpt-4 with better human
    alignment. *arXiv preprint arXiv:2303.16634*.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu et al. (2023b) 杨刘, 丹·伊特尔, 依琼·徐, 朔航·王, 若辰·徐, 和成光·朱. 2023b. Gpteval: 使用gpt-4进行更好的人类对齐的nlg评估。*arXiv预印本
    arXiv:2303.16634*。'
- en: OpenAI (2023) OpenAI. 2023. [Gpt-4 technical report](http://arxiv.org/abs/2303.08774).
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI (2023) OpenAI. 2023. [Gpt-4技术报告](http://arxiv.org/abs/2303.08774)。
- en: Peng et al. (2023) Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and
    Jianfeng Gao. 2023. Instruction tuning with gpt-4. *arXiv preprint arXiv:2304.03277*.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Peng et al. (2023) 包林·彭, 春远·李, 彭成·何, 米歇尔·加利, 和建峰·高. 2023. 使用gpt-4进行指令调整。*arXiv预印本
    arXiv:2304.03277*。
- en: Pezeshkpour and Hruschka (2023) Pouya Pezeshkpour and Estevam Hruschka. 2023.
    [Large language models sensitivity to the order of options in multiple-choice
    questions](http://arxiv.org/abs/2308.11483).
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pezeshkpour and Hruschka (2023) Pouya Pezeshkpour 和 Estevam Hruschka. 2023.
    [大型语言模型对多项选择题选项顺序的敏感性](http://arxiv.org/abs/2308.11483)。
- en: 'Sainz et al. (2023) Oscar Sainz, Jon Ander Campos, Iker García-Ferrero, Julen
    Etxaniz, Oier Lopez de Lacalle, and Eneko Agirre. 2023. Nlp evaluation in trouble:
    On the need to measure llm data contamination for each benchmark. *arXiv preprint
    arXiv:2310.18018*.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sainz et al. (2023) 奥斯卡·赛因斯, 乔恩·安德·坎波斯, 伊克尔·加西亚-费雷罗, 胶伦·埃查尼兹, 奥耶尔·洛佩斯·德·拉卡尔,
    和埃内科·阿吉雷. 2023. 自然语言处理评估的困境：关于每个基准测量大语言模型数据污染的必要性。*arXiv预印本 arXiv:2310.18018*。
- en: Shi et al. (2023) Weijia Shi, Anirudh Ajith, Mengzhou Xia, Yangsibo Huang, Daogao
    Liu, Terra Blevins, Danqi Chen, and Luke Zettlemoyer. 2023. Detecting pretraining
    data from large language models. *arXiv preprint arXiv:2310.16789*.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi et al. (2023) 韦佳·史, 阿尼鲁德·阿吉斯, 孟洲·夏, 杨斯博·黄, 道高·刘, 泰拉·布莱文斯, 丹琪·陈, 和卢克·泽特勒莫耶.
    2023. 检测大语言模型的预训练数据。*arXiv预印本 arXiv:2310.16789*。
- en: 'Sinha et al. (2019) Koustuv Sinha, Shagun Sodhani, Jin Dong, Joelle Pineau,
    and William L Hamilton. 2019. Clutrr: A diagnostic benchmark for inductive reasoning
    from text. *arXiv preprint arXiv:1908.06177*.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Sinha et al. (2019) 库斯图夫·辛哈, 沙贡·索达尼, 金·董, 乔埃尔·皮诺, 和威廉·L·汉密尔顿. 2019. Clutrr:
    一个用于文本归纳推理的诊断基准。*arXiv预印本 arXiv:1908.06177*。'
- en: 'Touvron et al. (2023) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
    Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal,
    Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language
    models. *arXiv preprint arXiv:2302.13971*.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Touvron et al. (2023) 雨果·图弗龙, 提博·拉夫里尔, 戈特耶·伊扎卡德, 赛维尔·马提内特, 玛丽-安娜·拉肖, 蒂莫西·拉克鲁瓦,
    巴蒂斯特·罗齐耶尔, 纳曼·戈亚尔, 埃里克·汉布罗, 法伊萨尔·阿扎尔, 等. 2023. Llama: 开放而高效的基础语言模型。*arXiv预印本 arXiv:2302.13971*。'
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei
    Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits
    reasoning in large language models. *Advances in Neural Information Processing
    Systems*, 35:24824–24837.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei et al. (2022) 杰森·魏, 薛智·王, 戴尔·舒尔曼斯, 马尔滕·博斯玛, 费·夏, 艾德·池, 国伟·李, 丹尼·周, 等. 2022.
    思维链提示引发大语言模型的推理。*神经信息处理系统进展*, 35:24824–24837。
- en: 'Wei et al. (2023) Tianwen Wei, Liang Zhao, Lichang Zhang, Bo Zhu, Lijie Wang,
    Haihua Yang, Biye Li, Cheng Cheng, Weiwei Lü, Rui Hu, Chenxia Li, Liu Yang, Xilin
    Luo, Xuejie Wu, Lunan Liu, Wenjun Cheng, Peng Cheng, Jianhao Zhang, Xiaoyu Zhang,
    Lei Lin, Xiaokun Wang, Yutuan Ma, Chuanhai Dong, Yanqi Sun, Yifu Chen, Yongyi
    Peng, Xiaojuan Liang, Shuicheng Yan, Han Fang, and Yahui Zhou. 2023. [Skywork:
    A more open bilingual foundation model](http://arxiv.org/abs/2310.19341).'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wei et al. (2023) 天文·魏, 梁·赵, 力昌·张, 博·朱, 李杰·王, 海华·杨, 毕业·李, 成·程, 伟伟·吕, 瑞·胡, 陈霞·李,
    刘·杨, 西林·罗, 薛杰·吴, 伦安·刘, 文君·程, 彭·程, 建浩·张, 小宇·张, 雷·林, 小坤·王, 玉团·马, 川海·董, 晏琦·孙, 逸夫·陈,
    永益·彭, 小娟·梁, 水成·闫, 汉·方, 和雅辉·周. 2023. [Skywork: 一个更开放的双语基础模型](http://arxiv.org/abs/2310.19341)。'
- en: 'Yang et al. (2023) Jingfeng Yang, Hongye Jin, Ruixiang Tang, Xiaotian Han,
    Qizhang Feng, Haoming Jiang, Bing Yin, and Xia Hu. 2023. Harnessing the power
    of llms in practice: A survey on chatgpt and beyond. *arXiv preprint arXiv:2304.13712*.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang et al. (2023) 靖峰·杨, 红叶·金, 瑞翔·唐, 晓天·韩, 奇璋·冯, 浩铭·江, 冰·尹, 和霞·胡. 2023. 实践中利用大语言模型的力量：关于chatgpt及其扩展的调查。*arXiv预印本
    arXiv:2304.13712*。
- en: 'Yu et al. (2023) Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying
    Liu, Yu Zhang, James T Kwok, Zhenguo Li, Adrian Weller, and Weiyang Liu. 2023.
    Metamath: Bootstrap your own mathematical questions for large language models.
    *arXiv preprint arXiv:2309.12284*.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yu et al. (2023) Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying
    Liu, Yu Zhang, James T Kwok, Zhenguo Li, Adrian Weller, 和 Weiyang Liu. 2023. Metamath:
    为大型语言模型构建你自己的数学问题。*arXiv 预印本 arXiv:2309.12284*。'
- en: 'Zeng et al. (2023) Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai,
    Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan
    Ma, Yufei Xue, Jidong Zhai, Wenguang Chen, Zhiyuan Liu, Peng Zhang, Yuxiao Dong,
    and Jie Tang. 2023. [GLM-130b: An open bilingual pre-trained model](https://openreview.net/forum?id=-Aw0rrrPUF).
    In *The Eleventh International Conference on Learning Representations (ICLR)*.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zeng et al. (2023) Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai,
    Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan
    Ma, Yufei Xue, Jidong Zhai, Wenguang Chen, Zhiyuan Liu, Peng Zhang, Yuxiao Dong,
    和 Jie Tang. 2023. [GLM-130b: 一个开放的双语预训练模型](https://openreview.net/forum?id=-Aw0rrrPUF)。在
    *第十一届国际学习表征会议 (ICLR)* 上。'
- en: Zhang et al. (2023) Xinghua Zhang, Bowen Yu, Haiyang Yu, Yangyu Lv, Tingwen
    Liu, Fei Huang, Hongbo Xu, and Yongbin Li. 2023. Wider and deeper llm networks
    are fairer llm evaluators. *arXiv preprint arXiv:2308.01862*.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2023) Xinghua Zhang, Bowen Yu, Haiyang Yu, Yangyu Lv, Tingwen
    Liu, Fei Huang, Hongbo Xu, 和 Yongbin Li. 2023. 更宽广更深的 LLM 网络是更公平的 LLM 评估者。*arXiv
    预印本 arXiv:2308.01862*。
- en: Zheng et al. (2023a) Chujie Zheng, Hao Zhou, Fandong Meng, Jie Zhou, and Minlie
    Huang. 2023a. Large language models are not robust multiple choice selectors.
    *arXiv e-prints*, pages arXiv–2309.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng et al. (2023a) Chujie Zheng, Hao Zhou, Fandong Meng, Jie Zhou, 和 Minlie
    Huang. 2023a. 大型语言模型不是稳健的多项选择选择器。*arXiv e-prints*，页面 arXiv–2309。
- en: Zheng et al. (2023b) Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang,
    Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao
    Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023b. [Judging llm-as-a-judge with
    mt-bench and chatbot arena](http://arxiv.org/abs/2306.05685).
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng et al. (2023b) Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang,
    Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao
    Zhang, Joseph E. Gonzalez, 和 Ion Stoica. 2023b. [使用 mt-bench 和聊天机器人竞技场评估 LLM 作为评审者](http://arxiv.org/abs/2306.05685)。
- en: Zhou et al. (2023) Kun Zhou, Yutao Zhu, Zhipeng Chen, Wentong Chen, Wayne Xin
    Zhao, Xu Chen, Yankai Lin, Ji-Rong Wen, and Jiawei Han. 2023. Don’t make your
    llm an evaluation benchmark cheater. *arXiv preprint arXiv:2311.01964*.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou et al. (2023) Kun Zhou, Yutao Zhu, Zhipeng Chen, Wentong Chen, Wayne Xin
    Zhao, Xu Chen, Yankai Lin, Ji-Rong Wen, 和 Jiawei Han. 2023. 不要让你的 LLM 成为评估基准作弊者。*arXiv
    预印本 arXiv:2311.01964*。
- en: 'Zhu et al. (2023) Kaijie Zhu, Jiaao Chen, Jindong Wang, Neil Zhenqiang Gong,
    Diyi Yang, and Xing Xie. 2023. [Dyval: Graph-informed dynamic evaluation of large
    language models](http://arxiv.org/abs/2309.17167).'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhu et al. (2023) Kaijie Zhu, Jiaao Chen, Jindong Wang, Neil Zhenqiang Gong,
    Diyi Yang, 和 Xing Xie. 2023. [Dyval: 图信息驱动的大型语言模型动态评估](http://arxiv.org/abs/2309.17167)。'
- en: Appendix A Details of Framework
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 框架详细信息
- en: A.1 Algorithm Design
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 算法设计
- en: 'The pseudo-code for the algorithm of our multi-agent evolving instance setting
    system is presented in Algorithm [1](#alg1 "Algorithm 1 ‣ A.1 Algorithm Design
    ‣ Appendix A Details of Framework ‣ Benchmark Self-Evolving: A Multi-Agent Framework
    for Dynamic LLM Evaluation").'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的多智能体演变实例设置系统的伪代码在算法 [1](#alg1 "算法 1 ‣ A.1 算法设计 ‣ 附录 A 框架详细信息 ‣ 基准自演变：一种动态
    LLM 评估的多智能体框架") 中给出。
- en: Algorithm 1 Multi-Agent Evolving Instance Setter
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 1 多智能体演变实例设置器
- en: 0:  An original evaluation instance $(C_{o},Q_{o},A_{o})$6:  else7:     return
     *NULL*8:  end if
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '0: 原始评估实例 $(C_{o},Q_{o},A_{o})$ 6: 其他 7: 返回 *NULL* 8: 结束 如果'
- en: A.2 Prompts of Multi-Agent Evolving Instance Setter
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 多智能体演变实例设置器的提示
- en: 'Table [4](#A1.T4 "Table 4 ‣ A.2 Prompts of Multi-Agent Evolving Instance Setter
    ‣ Appendix A Details of Framework ‣ Benchmark Self-Evolving: A Multi-Agent Framework
    for Dynamic LLM Evaluation"),  [5](#A1.T5 "Table 5 ‣ A.2 Prompts of Multi-Agent
    Evolving Instance Setter ‣ Appendix A Details of Framework ‣ Benchmark Self-Evolving:
    A Multi-Agent Framework for Dynamic LLM Evaluation"),  [6](#A1.T6 "Table 6 ‣ A.2
    Prompts of Multi-Agent Evolving Instance Setter ‣ Appendix A Details of Framework
    ‣ Benchmark Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation"),
     [7](#A1.T7 "Table 7 ‣ A.2 Prompts of Multi-Agent Evolving Instance Setter ‣ Appendix
    A Details of Framework ‣ Benchmark Self-Evolving: A Multi-Agent Framework for
    Dynamic LLM Evaluation"),  [8](#A1.T8 "Table 8 ‣ A.2 Prompts of Multi-Agent Evolving
    Instance Setter ‣ Appendix A Details of Framework ‣ Benchmark Self-Evolving: A
    Multi-Agent Framework for Dynamic LLM Evaluation"),  [9](#A1.T9 "Table 9 ‣ A.2
    Prompts of Multi-Agent Evolving Instance Setter ‣ Appendix A Details of Framework
    ‣ Benchmark Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation")
    and [10](#A1.T10 "Table 10 ‣ A.2 Prompts of Multi-Agent Evolving Instance Setter
    ‣ Appendix A Details of Framework ‣ Benchmark Self-Evolving: A Multi-Agent Framework
    for Dynamic LLM Evaluation") present prompts for Instance Generator of different
    reframing operations. Table [11](#A1.T11 "Table 11 ‣ A.2 Prompts of Multi-Agent
    Evolving Instance Setter ‣ Appendix A Details of Framework ‣ Benchmark Self-Evolving:
    A Multi-Agent Framework for Dynamic LLM Evaluation") presents the prompt for Instance
    Verifier. Table [12](#A1.T12 "Table 12 ‣ A.2 Prompts of Multi-Agent Evolving Instance
    Setter ‣ Appendix A Details of Framework ‣ Benchmark Self-Evolving: A Multi-Agent
    Framework for Dynamic LLM Evaluation") presents the prompt for Candidate Option
    Formulator.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 表[4](#A1.T4 "表 4 ‣ A.2 多智能体演变实例设置器提示 ‣ 附录 A 框架详细信息 ‣ 基准自我演变：动态 LLM 评估的多智能体框架")、[5](#A1.T5
    "表 5 ‣ A.2 多智能体演变实例设置器提示 ‣ 附录 A 框架详细信息 ‣ 基准自我演变：动态 LLM 评估的多智能体框架")、[6](#A1.T6
    "表 6 ‣ A.2 多智能体演变实例设置器提示 ‣ 附录 A 框架详细信息 ‣ 基准自我演变：动态 LLM 评估的多智能体框架")、[7](#A1.T7
    "表 7 ‣ A.2 多智能体演变实例设置器提示 ‣ 附录 A 框架详细信息 ‣ 基准自我演变：动态 LLM 评估的多智能体框架")、[8](#A1.T8
    "表 8 ‣ A.2 多智能体演变实例设置器提示 ‣ 附录 A 框架详细信息 ‣ 基准自我演变：动态 LLM 评估的多智能体框架")、[9](#A1.T9
    "表 9 ‣ A.2 多智能体演变实例设置器提示 ‣ 附录 A 框架详细信息 ‣ 基准自我演变：动态 LLM 评估的多智能体框架") 和 [10](#A1.T10
    "表 10 ‣ A.2 多智能体演变实例设置器提示 ‣ 附录 A 框架详细信息 ‣ 基准自我演变：动态 LLM 评估的多智能体框架") 提供了不同重构操作的实例生成器提示。表[11](#A1.T11
    "表 11 ‣ A.2 多智能体演变实例设置器提示 ‣ 附录 A 框架详细信息 ‣ 基准自我演变：动态 LLM 评估的多智能体框架") 提供了实例验证器的提示。表[12](#A1.T12
    "表 12 ‣ A.2 多智能体演变实例设置器提示 ‣ 附录 A 框架详细信息 ‣ 基准自我演变：动态 LLM 评估的多智能体框架") 提供了候选选项制定者的提示。
- en: 'Table 4: Prompt on Question Alternating'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：问题交替的提示
- en: 'Prompt
    for Instance Generator on Question Alternating You
    are an expert Question Creator. You will receive an instance of {task description},
    including a context, a question and its answer. You are tasked with creating an
    alternative question to explore a different aspect of the original problem. Please
    do not change the context but just edit the question and the answer. Please first
    generate the question. Then think step-by-step in one line to give an brief analysis
    of the question, Finally, directly present a short answer omitting the intermediate
    steps, in a single line. Context: {context $C_{o}$} Alternative Question:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 针对问题替代的实例生成器提示
    你是一个专业的问题创建者。你将收到一个{任务描述}的实例，包括上下文、一个问题及其答案。你的任务是创建一个替代问题，以探讨原始问题的不同方面。请勿更改上下文，只需编辑问题和答案。请首先生成问题。然后一步一步地给出问题的简要分析，最后直接给出一个简短的答案，省略中间步骤，用单行表述。上下文：{context
    $C_{o}$} 替代问题：
- en: 'Table 5: Prompt on Context Paraphrasing'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：关于上下文释义的提示
- en: 'Prompt
    for Instance Generator on Context Paraphrasing You
    are an expert Question Creator.You will receive an instance of {task description},
    including a context, a question and its answer. Your task is to rephrase the given
    context in a short and easy-readable manner without summarizing or explaining.
    Confirm that the rephrased context do not change the answer to the original question.
    Simply output the rephrased context and do not output the original question. Context:
    {context $C_{o}$} Alternative Context:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 针对上下文释义的实例生成器提示
    你是一个专业的问题创建者。你将收到一个{任务描述}的实例，包括上下文、一个问题及其答案。你的任务是以简洁易读的方式重述给定的上下文，不进行总结或解释。确认重述后的上下文不会改变原始问题的答案。仅输出重述的上下文，不输出原始问题。上下文：{context
    $C_{o}$} 替代上下文：
- en: 'Table 6: Prompt on Context Noising'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6：关于上下文噪声的提示
- en: 'Prompt
    for Instance Generator on Context Noising You
    are an expert Question Creator. You will receive an instance of {task description},
    including a context, a question and its answer. You are tasked with creating a
    new context by inserting irrelevant facts within the critical sentences of the
    original context. Make sure these facts shouldn’t change the correct answer to
    the question. Simply output the rephrased context and do not output the original
    question. Context: {context $C_{o}$} Alternative Context:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '实例生成器的上下文噪声提示
    你是一个专业的问题创建者。你将收到一个包含上下文、问题及其答案的{task description}实例。你的任务是通过在原始上下文的关键句子中插入无关的事实来创建一个新的上下文。确保这些事实不会改变问题的正确答案。只需输出重新表述的上下文，不要输出原始问题。上下文:
    {context $C_{o}$} 替代上下文:'
- en: 'Table 7: Prompt on Polarity Reversing'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '表 7: 极性反转提示'
- en: 'Prompt
    for Instance Generator on Polarity Reversing You
    are an expert Question Creator. You will receive an instance of {task description},
    including a context, a question and its answer. Your task is to generate a new
    context by altering key details in the original context. Ensure that the rest
    of the original context remains unchanged. The altered details should change the
    answer to the question. Please first output the rephrased context. Then give an
    one-line step-by-step analysis of the original question based on the new context.
    Finally, generate the corresponding direct answer in a newline. Context: {context
    $C_{o}$} Alternative Context:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '实例生成器的极性反转提示
    你是一个专业的问题创建者。你将收到一个包含上下文、问题及其答案的{task description}实例。你的任务是通过改变原始上下文中的关键细节来生成一个新的上下文。确保其余的原始上下文保持不变。改变的细节应该改变问题的答案。请首先输出重新表述的上下文。然后根据新的上下文给出原始问题的一行逐步分析。最后，在新的一行生成相应的直接答案。上下文:
    {context $C_{o}$} 替代上下文:'
- en: 'Table 8: Prompt on Planning'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '表 8: 计划提示'
- en: 'Prompt
    for Instance Generator on Planning You are an expert Task Planner.
    You will receive an instance of {task description}, including a context, a question
    and its answer. Your task is to generate a new question and its corresponding
    answer, aiming to ask about the plan to solve the original question given the
    context. Your new question can either inquire about all reasoning steps required
    or ask for the specific details about a certain (e.g., first, second, or last)
    step. Please first generate the question. Then think step-by-step in one line
    to give an brief analysis of the question, Finally, directly present a short answer
    omitting the intermediate steps, in a single line. Context: {context $C_{o}$}
    Alternative Question:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '规划实例生成器提示
    你是一个专家级任务规划师。你将收到一个{task description}的实例，包括一个上下文，一个问题及其答案。你的任务是生成一个新问题及其对应答案，旨在询问关于解决原始问题的计划，给定上下文。你新的问题可以询问所有必要的推理步骤，或询问关于某个特定步骤（如第一个、第二个或最后一个步骤）的详细信息。请首先生成问题。然后一步步思考以简要分析问题，最后直接给出简短的答案，省略中间步骤，一行呈现。上下文:
    {context $C_{o}$} 备用问题:'
- en: 'Table 9: Prompt on Retrieval'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '表 9: 检索提示'
- en: 'Prompt
    for Instance Generator on Retrieval You
    are an expert Relevant Context Retriever. You will receive an instance of {task
    description}, including a context, a question and its answer. Your task is to
    generate a new question and its corresponding answer, aiming to identify the relevant
    information from the given context necessary to solve the original question with
    the original answer. Your answer must be exclusively from the given context, to
    contain all required information to solve the original question and cover the
    original answer. Please first generate the question. Then think step-by-step in
    one line to give an brief analysis of the question, Finally, directly present
    a short answer omitting the intermediate steps, in a single line. Context: {context
    $C_{o}$} Alternative Question:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '检索实例生成器提示
    你是一个专家级相关上下文检索者。你将收到一个{task description}的实例，包括一个上下文，一个问题及其答案。你的任务是生成一个新问题及其对应答案，旨在从给定的上下文中识别出解决原始问题和原始答案所需的相关信息。你的答案必须完全来自给定的上下文，包含解决原始问题所需的所有信息，并覆盖原始答案。请首先生成问题。然后一步步思考以简要分析问题，最后直接给出简短的答案，省略中间步骤，一行呈现。上下文:
    {context $C_{o}$} 备用问题:'
- en: 'Table 10: Prompt on Knowledge'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '表 10: 知识提示'
- en: 'Prompt
    for Instance Generator on Knowledge You
    are an expert Relevant Context Retriever. You will receive an instance of {task
    description}, including a context, a question and its answer. Your task is to
    generate a new question and its corresponding answer, aiming to ask about the
    implicit knowledge (e.g., facts, rules, commonsense, …) required to solve the
    original question. Your new answer should directly list all required implicit
    knowledge for the question. Please first generate the question. Then think step-by-step
    in one line to give an brief analysis of the question, Finally, directly present
    a short answer omitting the intermediate steps, in a single line. Context: {context
    $C_{o}$} Alternative Question:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 知识实例生成器提示
    你是一个专家相关背景检索员。你将接收一个包含上下文、问题及其答案的{任务描述}实例。你的任务是生成一个新的问题及其对应的答案，旨在询问解决原问题所需的隐性知识（例如，事实、规则、常识等）。你新的答案应直接列出问题所需的所有隐性知识。请首先生成问题。然后一步步思考，给出对问题的简要分析，最后直接用一行简短的答案呈现，省略中间步骤。上下文：{context
    $C_{o}$} 备用问题：
- en: 'Table 11: Prompt for Instance Verifier'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 表11：实例验证提示
- en: 'Prompt
    for Instance Verifier You are an expert Question-Answer
    Validator. You will receive an instance of {task description}, including a context,
    a question and its answer. Your task is to validate whether the answer is correct
    to solve the question given the context. Please think step-by-step in one line
    to analyze whether the answer is correct for the question and the context. Then
    give your final judgement with Yes or No in a newline. Context: {context $C$}
    Judgement:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 实例验证提示
    你是一个专家问答验证员。你将接收一个包含上下文、问题及其答案的{任务描述}实例。你的任务是验证答案是否正确，是否能够解决问题。请一步步思考，分析答案是否正确，然后用"Yes"或"No"给出最终判断，并另起一行。上下文：{context
    $C$} 判断：
- en: 'Table 12: Prompt for Candidate Option Formulator'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 表12：候选选项制定者提示
- en: 'Prompt
    for Candidate Option Formulator You are an expert Candidate
    Option Generator. You will receive an instance of {task description}, including
    a context, a question and its answer. Your task is to modify the provided answer
    to generate a candidate option that wrongly answer the question given the context.
    Context: {context $C$} Option:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 候选选项生成器提示
    你是一个专家候选选项生成器。你将接收到一个{任务描述}实例，包括一个上下文、一个问题及其答案。你的任务是修改提供的答案，生成一个错误回答问题的候选选项，基于给定的上下文。上下文：{context
    $C$} 选项：
- en: Appendix B Experimental Analysis
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 实验分析
- en: B.1 Dataset Descriptions
  id: totrans-212
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.1 数据集描述
- en: •
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'GSM8K: a collection of grade school math problems in a free-form QA format,
    featuring diverse arithmetic and algebraic problems.'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: GSM8K：一个包含自由形式问答格式的基础数学问题的集合，包含多样的算术和代数问题。
- en: •
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'CLUTRR: a synthesized free-form question answering dataset designed for evaluating
    logical reasoning over kinship relationships.'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: CLUTRR：一个合成的自由形式问答数据集，旨在评估关于亲属关系的逻辑推理。
- en: •
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'StrategyQA: consists of crowdsourced yes/no questions that require implicit
    reasoning steps and commonsense strategies. The instances in StrategyQA consist
    solely of questions and answers, with their contexts being null.'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: StrategyQA：包含众包的“是/否”问题，这些问题需要隐含的推理步骤和常识策略。StrategyQA中的实例仅包含问题和答案，上下文为空。
- en: •
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'BoolQ: a reading comprehension dataset sourced from Google’s Natural Questions,
    offers yes/no questions based on real Google searches paired with answers from
    Wikipedia articles.'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: BoolQ：一个阅读理解数据集，来源于谷歌的自然问题，提供基于真实谷歌搜索的“是/否”问题，答案来自维基百科文章。
- en: B.2 Instance Filtering Statistics
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.2 实例过滤统计
- en: 'Table [13](#A2.T13 "Table 13 ‣ B.2 Instance Filtering Statistics ‣ Appendix
    B Experimental Analysis ‣ Benchmark Self-Evolving: A Multi-Agent Framework for
    Dynamic LLM Evaluation") shows the percentage of instances filtered by double-verification.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 表[13](#A2.T13 "表 13 ‣ B.2 实例过滤统计 ‣ 附录 B 实验分析 ‣ 基准自我演变：动态LLM评估的多代理框架")显示了通过双重验证过滤的实例百分比。
- en: 'Table 13: Percentage (%) of instances filtered by double-verification.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 表13：通过双重验证过滤的实例百分比（%）。
- en: '| Dataset | Scalable | Robust | Fine-grained |  Average |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 可扩展 | 稳健 | 细粒度 | 平均 |'
- en: '| Alternating | Complicating | Paraphrasing | Noising | Reversing | Planning
    | Knowledge | Retrieval |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| 交替 | 复杂 | 释义 | 噪声 | 反转 | 规划 | 知识 | 检索 |'
- en: '| GSM8K | 32.29% | 42.71% | 6.25% | 6.25% | 36.46% | 26.04% | / | / | 25.00%
    |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| GSM8K | 32.29% | 42.71% | 6.25% | 6.25% | 36.46% | 26.04% | / | / | 25.00%
    |'
- en: '| CLUTRR | 8.33% | 18.75% | 20.83% | 16.67% | 25.00% | 28.13% | 15.63% | 33.33%
    | 20.83% |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| CLUTRR | 8.33% | 18.75% | 20.83% | 16.67% | 25.00% | 28.13% | 15.63% | 33.33%
    | 20.83% |'
- en: '| StrategyQA | / | 31.33% | / | / | / | 6.02% | 21.69% | / | 19.68% |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| StrategyQA | / | 31.33% | / | / | / | 6.02% | 21.69% | / | 19.68% |'
- en: '| BoolQ | 2.22% | 24.44% | 0.00% | 4.44% | 44.44% | / | / | 25.56% | 29.26%
    |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| BoolQ | 2.22% | 24.44% | 0.00% | 4.44% | 44.44% | / | / | 25.56% | 29.26%
    |'
- en: '| Average | 14.28% | 29.17% | 9.03% | 9.12% | 35.30% | 20.06% | 18.66% | 29.45%
    | 23.69% |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| 平均 | 14.28% | 29.17% | 9.03% | 9.12% | 35.30% | 20.06% | 18.66% | 29.45%
    | 23.69% |'
- en: B.3 Selection Bias Analysis
  id: totrans-231
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.3 选择偏差分析
- en: In our discussion, selection bias denotes the tendency that a model inherently
    assigns a higher probability to specific ID tokens, such as A or B, in multi-choice
    questions. The impact of selection bias varies across different models and tasks,
    influencing the models’ performance by reducing their robustness in handling multi-choice
    problems Zheng et al. ([2023a](#bib.bib32)). The permutation-based debiasing method,
    which averages the model’s prediction distributions across various option permutations,
    theoretically eliminates selection bias. However, due to limited access to the
    prediction distributions of closed-source models, we employ a sampling approximation
    approach to estimate and mitigate selection bias.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的讨论中，选择偏差表示模型在多选题中固有地赋予特定ID令牌（如A或B）更高概率的倾向。选择偏差的影响在不同模型和任务中有所不同，影响模型的性能，使其在处理多选问题时的鲁棒性降低Zheng等人（[2023a](#bib.bib32)）。基于置换的去偏差方法，通过对各种选项置换的模型预测分布进行平均，从理论上消除选择偏差。然而，由于无法访问封闭源模型的预测分布，我们采用采样近似方法来估计和缓解选择偏差。
- en: To formalize our discussion, we use $C$.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 为了形式化我们的讨论，我们使用 $C$。
- en: 'We assume that given $C$, which can be decomposed as:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设给定 $C$，可以分解为：
- en: '|  | $\displaystyle Z_{x^{I}}^{-1}P_{\text{prior}}\left(id_{i}\mid C\right)P_{\text{debiased}}\left(o_{f_{I}(i)}\mid
    C,x^{I}\right)$ |  | (1) |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle Z_{x^{I}}^{-1}P_{\text{prior}}\left(id_{i}\mid C\right)P_{\text{debiased}}\left(o_{f_{I}(i)}\mid
    C,x^{I}\right)$ |  | (1) |'
- en: where $Z_{x^{I}}^{-1}$.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $Z_{x^{I}}^{-1}$。
- en: 'We assume $P_{\text{debiased}}$ as:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设 $P_{\text{debiased}}$ 为：
- en: '|  | $\displaystyle\operatorname{softmax}\left(\frac{1}{&#124;\mathcal{I}&#124;}\sum_{I\in\mathcal{I}}\log
    P_{\text{biased }}\left(id_{i}\mid C,x^{I}\right)\right)$ |  | (2) |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\operatorname{softmax}\left(\frac{1}{&#124;\mathcal{I}&#124;}\sum_{I\in\mathcal{I}}\log
    P_{\text{biased }}\left(id_{i}\mid C,x^{I}\right)\right)$ |  | (2) |'
- en: Based on the estimated $P_{\text{prior }}\left(id_{i}\mid C\right)$.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 基于估计的 $P_{\text{prior }}\left(id_{i}\mid C\right)$。
- en: For our analysis, the $P_{\text{prior }}\left(id_{i}\mid C\right)$.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的分析，$P_{\text{prior }}\left(id_{i}\mid C\right)$。
- en: B.4 Dataset Perplexity Analysis
  id: totrans-241
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.4 数据集困惑度分析
- en: 'Perplexity is a metric that quantifies the complexity and the predictability
    of a dataset. By analyzing the perplexity of dataset, we can gain insights into
    the relative difficulty models may encounter during testing, as well as the diversity
    of information within the dataset. In this analysis, we calculate the perplexity
    of newly evolving datasets derived by reframing the original GSM8K dataset and
    compared them with their original counterparts. The comparison results are presented
    in Figure [6](#A2.F6 "Figure 6 ‣ B.4 Dataset Perplexity Analysis ‣ Appendix B
    Experimental Analysis ‣ Benchmark Self-Evolving: A Multi-Agent Framework for Dynamic
    LLM Evaluation").'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '困惑度是量化数据集复杂性和可预测性的指标。通过分析数据集的困惑度，我们可以洞察模型在测试过程中可能遇到的相对难度，以及数据集中的信息多样性。在本分析中，我们计算了通过重构原始GSM8K数据集得到的新数据集的困惑度，并与原始数据集进行了比较。比较结果见图[6](#A2.F6
    "Figure 6 ‣ B.4 Dataset Perplexity Analysis ‣ Appendix B Experimental Analysis
    ‣ Benchmark Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation")。'
- en: 'Our findings indicate that the datasets created through different reframing
    operations exhibit an increase in perplexity compared to the original instances.
    This indicates that the reframed instances are more complex and less predictable.
    These results, aligning with the experimental observations discussed in Section [3.3](#S3.SS3
    "3.3 Analysis of Varied Reframing Operations ‣ 3 Experiments ‣ Benchmark Self-Evolving:
    A Multi-Agent Framework for Dynamic LLM Evaluation"), suggest that our framework
    has the ability to generate instances with enhanced linguistic structure and diversity
    compared to the original instances.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '我们的研究发现，通过不同的重构操作创建的数据集相较于原始实例展现出更高的困惑度。这表明重构实例更加复杂且更难预测。这些结果与第[3.3](#S3.SS3
    "3.3 Analysis of Varied Reframing Operations ‣ 3 Experiments ‣ Benchmark Self-Evolving:
    A Multi-Agent Framework for Dynamic LLM Evaluation")节中讨论的实验观察结果一致，表明我们的框架能够生成具有更高语言结构和多样性的实例。'
- en: '![Refer to caption](img/c456e737b5f7babced19a34c45b73781.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/c456e737b5f7babced19a34c45b73781.png)'
- en: 'Figure 6: Perplexity comparison between original and reframed datasets.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：原始数据集与重构数据集的困惑度比较。
- en: B.5 Error Analysis
  id: totrans-246
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.5 错误分析
- en: 'Tables [14](#A2.T14 "Table 14 ‣ B.5 Error Analysis ‣ Appendix B Experimental
    Analysis ‣ Benchmark Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation"), [15](#A2.T15
    "Table 15 ‣ B.5 Error Analysis ‣ Appendix B Experimental Analysis ‣ Benchmark
    Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation")and [16](#A2.T16
    "Table 16 ‣ B.5 Error Analysis ‣ Appendix B Experimental Analysis ‣ Benchmark
    Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation") present cases
    from GSM8K where ChatGPT successfully responds to the original instance but fails
    to answer the evolved version. The case in Table [14](#A2.T14 "Table 14 ‣ B.5
    Error Analysis ‣ Appendix B Experimental Analysis ‣ Benchmark Self-Evolving: A
    Multi-Agent Framework for Dynamic LLM Evaluation") introduces an additional reasoning
    step to the original instance, which causes ChatGPT to misinterpret the context
    and perform an incorrect calculation. In Table [15](#A2.T15 "Table 15 ‣ B.5 Error
    Analysis ‣ Appendix B Experimental Analysis ‣ Benchmark Self-Evolving: A Multi-Agent
    Framework for Dynamic LLM Evaluation"), the evolved instance alters two data points
    from the original case, leading ChatGPT to neglect the critical information "4
    times a week," resulting in an inaccurate response. The example in Table [16](#A2.T16
    "Table 16 ‣ B.5 Error Analysis ‣ Appendix B Experimental Analysis ‣ Benchmark
    Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation") demonstrates
    that, although ChatGPT correctly calculates the total number of hours the candle
    will burn in the original instance, it fails to address a direct question about
    the first reasoning step in the new instance.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 [14](#A2.T14 "表 14 ‣ B.5 错误分析 ‣ 附录 B 实验分析 ‣ 基准自我进化：动态 LLM 评估的多智能体框架")、 [15](#A2.T15
    "表 15 ‣ B.5 错误分析 ‣ 附录 B 实验分析 ‣ 基准自我进化：动态 LLM 评估的多智能体框架")和 [16](#A2.T16 "表 16 ‣
    B.5 错误分析 ‣ 附录 B 实验分析 ‣ 基准自我进化：动态 LLM 评估的多智能体框架")展示了 ChatGPT 在原始实例中成功回应但在进化版本中未能回答的情况。表 [14](#A2.T14
    "表 14 ‣ B.5 错误分析 ‣ 附录 B 实验分析 ‣ 基准自我进化：动态 LLM 评估的多智能体框架") 的案例在原始实例中引入了额外的推理步骤，这导致
    ChatGPT 错误解读了背景并进行了不正确的计算。在表 [15](#A2.T15 "表 15 ‣ B.5 错误分析 ‣ 附录 B 实验分析 ‣ 基准自我进化：动态
    LLM 评估的多智能体框架") 中，进化实例更改了原始案例中的两个数据点，导致 ChatGPT 忽视了关键信息“每周 4 次”，从而产生了不准确的回复。表 [16](#A2.T16
    "表 16 ‣ B.5 错误分析 ‣ 附录 B 实验分析 ‣ 基准自我进化：动态 LLM 评估的多智能体框架") 的例子表明，尽管 ChatGPT 在原始实例中正确计算了蜡烛燃烧的总小时数，但在新实例中未能处理直接询问第一个推理步骤的问题。
- en: By utilizing instances from our evolving framework, we can expose model’s limitations
    more effectively, including its vulnerability to perturbations, diminished generalization
    capabilities on more complex problems, and inadequacies in addressing questions
    targeting specific sub-abilities.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用我们不断进化的框架中的实例，我们可以更有效地揭示模型的局限性，包括其对扰动的脆弱性、在更复杂问题上的泛化能力下降，以及在处理针对特定子能力的问题时的不足。
- en: 'Table 14: Instance Before and After Question Complicating'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '表 14: 问题复杂化前后的实例'
- en: '| Original Instance | New Instance |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| 原始实例 | 新实例 |'
- en: '| Context: A robe takes 2 bolts of blue fiber and half that much white fiber.
    | Context: A robe takes 2 bolts of blue fiber and half that much white fiber.
    |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| 背景: 一件长袍需要 2 卷蓝色纤维和一半量的白色纤维。 | 背景: 一件长袍需要 2 卷蓝色纤维和一半量的白色纤维。 |'
- en: '| Question: How many bolts in total does it take? | Question: If a merchant
    has 20 bolts of blue fiber and 10 bolts of white fiber, how many robes can he
    make using all the fibers without any leftovers? |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| 问题: 总共需要多少卷布？ | 问题: 如果商人有 20 卷蓝色纤维和 10 卷白色纤维，他可以使用所有纤维制作多少件长袍而没有剩余？ |'
- en: '| Answer: 3 | Answer: 10 |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| 答案: 3 | 答案: 10 |'
- en: '| Response: It takes 2 + 1 = 3 bolts in total. | Response: The merchant can
    make 20/2 = 10 robes using the blue fiber. He can make 10/2 = 5 robes using the
    white fiber. So, he can make a total of 5 robes using all the fibers without any
    leftovers. |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| 回复: 总共需要 2 + 1 = 3 卷布。 | 回复: 商人可以使用蓝色纤维制作 20/2 = 10 件长袍。他可以使用白色纤维制作 10/2
    = 5 件长袍。因此，他可以使用所有纤维制作总共 5 件长袍，没有剩余。 |'
- en: '| Judgement: ✓ | Judgement: $\times$ |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| 判断: ✓ | 判断: $\times$ |'
- en: 'Table 15: Instance Before and After Polarity Reversing'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '表 15: 极性反转前后的实例'
- en: '| Original Instance | New Instance |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| 原始实例 | 新实例 |'
- en: '| Context: Jim spends 2 hours watching TV and then decides to go to bed and
    reads for half as long. He does this 3 times a week. | Context: Jim spends 3 hours
    watching TV and then decides to go to bed and reads for a third as long. He does
    this 4 times a week. |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| 上下文：吉姆花2小时看电视，然后决定上床睡觉，并阅读一半时间。他每周这样做3次。 | 上下文：吉姆花3小时看电视，然后决定上床睡觉，并阅读三分之一的时间。他每周这样做4次。
    |'
- en: '| Question: How many hours does he spend on TV and reading in 4 weeks? | Question:
    How many hours does he spend on TV and reading in 4 weeks? |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| 问题：他在4周内花了多少小时看电视和阅读？ | 问题：他在4周内花了多少小时看电视和阅读？ |'
- en: '| Answer: 36 | Answer: 64 |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| 答案：36 | 答案：64 |'
- en: '| Response: Jim spends 2 + (2/2) = 3 hours on TV and reading each time. So,
    in 4 weeks, he spends 3 * 3 * 4 = 36 hours on TV and reading. The answer is 36.
    | Response: Jim spends 3 + (3/3) = 4 hours on TV and reading each time. In 4 weeks,
    he spends 4 * 4 = 16 hours on TV and reading. The answer is 16. |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| 回答：吉姆每次花费2 + (2/2) = 3小时看电视和阅读。因此，在4周内，他花费3 * 3 * 4 = 36小时看电视和阅读。答案是36。 |
    回答：吉姆每次花费3 + (3/3) = 4小时看电视和阅读。在4周内，他花费4 * 4 = 16小时看电视和阅读。答案是16。 |'
- en: '| Judgement: ✓ | Judgement: $\times$ |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| 判定：✓ | 判定：$\times$ |'
- en: 'Table 16: Instance Before and After Planning Operation'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 表16：规划操作前后的实例
- en: '| Original Instance | New Instance |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| 原始实例 | 新实例 |'
- en: '| Context: A candle melts by 2 centimeters every hour that it burns. | Context:
    A candle melts by 2 centimeters every hour that it burns. |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| 上下文：蜡烛每小时燃烧2厘米。 | 上下文：蜡烛每小时燃烧2厘米。 |'
- en: '| Question: How many centimeters shorter will a candle be after burning from
    1:00 PM to 5:00 PM? | Question: What is the first reasoning step to calculate
    how many centimeters shorter a candle will be after burning from 1:00 PM to 5:00
    PM? |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| 问题：蜡烛在下午1:00到下午5:00燃烧后会短多少厘米？ | 问题：计算蜡烛在下午1:00到下午5:00燃烧后会短多少厘米的第一步推理是什么？
    |'
- en: '|  | A. The first reasoning step is to measure the initial height of the candle.
    |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '|  | A. 第一步推理是测量蜡烛的初始高度。 |'
- en: '|  | B. The first reasoning step is to determine the total number of hours
    the candle will burn. |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '|  | B. 第一步推理是确定蜡烛燃烧的总小时数。 |'
- en: '| Answer: 8 | Answer: B |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| 答案：8 | 答案：B |'
- en: '| Response: The candle burns for 5-1=4 hours. So, it will be 2*4=8 centimeters
    shorter. The answer is 8. | Response: A |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| 回答：蜡烛燃烧了5-1=4小时。因此，它将短2*4=8厘米。答案是8。 | 回答：A |'
- en: '| Judgement: ✓ | Judgement: $\times$ |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| 判定：✓ | 判定：$\times$ |'
- en: B.6 Data Contamination Experiment Details
  id: totrans-272
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.6 数据污染实验细节
- en: We construct an instruction tuning dataset comprising 4,000 general instances
    from alpaca-gpt4-data Peng et al. ([2023](#bib.bib20)) and additional 4,000 instances,
    with 1,000 each from the training sets of GSM8K, CLUTRR, StrategyQA and BoolQ.
    This dataset is used to fine-tune a model to simulate in-domain contamination.
    Furthermore, we incorperate 400 instances from the original benchmark into the
    instruction tuning dataset to fine-tune another model to simulate the direct contamination.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建了一个包含4,000个通用实例的指令调整数据集，数据来源于alpaca-gpt4-data Peng等人（[2023](#bib.bib20)）以及另外4,000个实例，其中每个训练集来自GSM8K、CLUTRR、StrategyQA和BoolQ各1,000个。这些数据用于微调模型以模拟领域内污染。此外，我们将400个来自原始基准的实例并入指令调整数据集，以微调另一个模型以模拟直接污染。
