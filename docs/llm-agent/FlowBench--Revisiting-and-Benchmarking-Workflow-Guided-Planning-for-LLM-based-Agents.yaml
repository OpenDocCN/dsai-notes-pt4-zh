- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '类别: 未分类'
- en: 'date: 2024-09-08 18:43:49'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-08 18:43:49'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based
    Agents'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'FlowBench: 重新审视和基准化工作流程指导规划'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.14884](https://ar5iv.labs.arxiv.org/html/2406.14884)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2406.14884](https://ar5iv.labs.arxiv.org/html/2406.14884)
- en: 'Ruixuan Xiao¹, Wentao Ma²¹¹footnotemark: 1, Ke Wang², Yuchuan Wu²'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 'Ruixuan Xiao¹, Wentao Ma²¹¹脚注标记: 1, Ke Wang², Yuchuan Wu²'
- en: 'Junbo Zhao¹, Haobo Wang¹, Fei Huang², Yongbin Li²²²footnotemark: 2'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 'Junbo Zhao¹, Haobo Wang¹, Fei Huang², Yongbin Li²²²脚注标记: 2'
- en: ¹Zhejiang University  ²Alibaba Group
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ¹浙江大学  ²阿里巴巴集团
- en: '{xiaoruixuan,j.zhao,wanghaobo}@zju.edu.cn'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '{xiaoruixuan,j.zhao,wanghaobo}@zju.edu.cn'
- en: '{mawentao.mwt,wk258730,shengxiu.wyc,f.huang,shuide.lyb}@alibaba-inc.com   Equally
    contribution. Work done while Ruixuan Xiao was interning at Alibaba Group.  Corresponding
    authors.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '{mawentao.mwt,wk258730,shengxiu.wyc,f.huang,shuide.lyb}@alibaba-inc.com   同等贡献。该工作是在Ruixuan
    Xiao在阿里巴巴集团实习期间完成的。  通讯作者。'
- en: Abstract
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: LLM-based agents have emerged as promising tools, which are crafted to fulfill
    complex tasks by iterative planning and action. However, these agents are susceptible
    to undesired planning hallucinations when lacking specific knowledge for expertise-intensive
    tasks. To address this, preliminary attempts are made to enhance planning reliability
    by incorporating external workflow-related knowledge. Despite the promise, such
    infused knowledge is mostly disorganized and diverse in formats, lacking rigorous
    formalization and comprehensive comparisons. Motivated by this, we formalize different
    formats of workflow knowledge and present FlowBench, the first benchmark for workflow-guided
    planning. FlowBench covers 51 different scenarios from 6 domains, with knowledge
    presented in diverse formats. To assess different LLMs on FlowBench, we design
    a multi-tiered evaluation framework. We evaluate the efficacy of workflow knowledge
    across multiple formats, and the results indicate that current LLM agents need
    considerable improvements for satisfactory planning. We hope that our challenging
    benchmark can pave the way for future agent planning research. Our benchmark and
    scripts will be released shortly.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLM的智能体已成为有前景的工具，这些工具通过迭代计划和行动来完成复杂任务。然而，当缺乏特定的专业知识时，这些智能体容易出现不希望的计划性幻觉。为了解决这一问题，初步尝试通过引入外部工作流程相关知识来提高规划的可靠性。尽管前景可期，这些注入的知识通常是杂乱无章的，格式多样，缺乏严谨的形式化和全面的比较。受到此启发，我们对工作流程知识的不同格式进行形式化，并提出了FlowBench，这是第一个用于工作流程指导规划的基准。FlowBench涵盖了来自6个领域的51种不同场景，知识以多种格式呈现。为了评估不同的LLM在FlowBench上的表现，我们设计了一个多层次的评估框架。我们评估了多种格式的工作流程知识的有效性，结果表明当前的LLM智能体在规划方面需要显著改进。我们希望我们具有挑战性的基准能够为未来的智能体规划研究铺平道路。我们的基准和脚本将很快发布。
- en: 'FlowBench: Revisiting and Benchmarking Workflow-Guided'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 'FlowBench: 重新审视和基准化工作流程指导'
- en: Planning for LLM-based Agents
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLM的智能体的规划
- en: 'Ruixuan Xiao¹^†^†thanks:   Equally contribution. Work done while Ruixuan Xiao
    was interning at Alibaba Group., Wentao Ma²¹¹footnotemark: 1, Ke Wang², Yuchuan
    Wu² Junbo Zhao¹, Haobo Wang¹^†^†thanks:   Corresponding authors., Fei Huang²,
    Yongbin Li²²²footnotemark: 2 ¹Zhejiang University  ²Alibaba Group {xiaoruixuan,j.zhao,wanghaobo}@zju.edu.cn
    {mawentao.mwt,wk258730,shengxiu.wyc,f.huang,shuide.lyb}@alibaba-inc.com'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 'Ruixuan Xiao¹^†^†感谢:   同等贡献。该工作是在Ruixuan Xiao在阿里巴巴集团实习期间完成的。, Wentao Ma²¹¹脚注标记:
    1, Ke Wang², Yuchuan Wu² Junbo Zhao¹, Haobo Wang¹^†^†感谢:   通讯作者。, Fei Huang²,
    Yongbin Li²²²脚注标记: 2 ¹浙江大学  ²阿里巴巴集团 {xiaoruixuan,j.zhao,wanghaobo}@zju.edu.cn
    {mawentao.mwt,wk258730,shengxiu.wyc,f.huang,shuide.lyb}@alibaba-inc.com'
- en: 1 Introduction
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: The impressive advances of large language models (LLMs) Touvron et al. ([2023](#bib.bib26));
    Zeng et al. ([2023](#bib.bib39)); OpenAI ([2023a](#bib.bib19)) have spurred the
    evolution of LLM-driven agents Wang et al. ([2024](#bib.bib28)); Hong et al. ([2023](#bib.bib9))
    for complex task solving across diverse domains Qian et al. ([2023](#bib.bib22));
    Hong et al. ([2023](#bib.bib9)); Zhou et al. ([2023](#bib.bib41)). While recent
    works have made strides in advancing tool utilization abilities of agents through
    prompt construction Yao et al. ([2023b](#bib.bib36), [a](#bib.bib35)) and multi-agent
    collaboration Hong et al. ([2023](#bib.bib9)); Chen et al. ([2023](#bib.bib4));
    Qian et al. ([2023](#bib.bib22)), the restricted scope of LLMs’ intrinsic parametric
    knowledge can lead to the undesired phenomenon of planning hallucinations Zhu
    et al. ([2024](#bib.bib42)) – LLMs can exhibit uncontrollable actions that conflict
    with task knowledge and such adverse effects obstruct their practical application
    in knowledge-intensive tasks.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）的显著进展 Touvron等人 ([2023](#bib.bib26)); Zeng等人 ([2023](#bib.bib39));
    OpenAI ([2023a](#bib.bib19)) 刺激了LLM驱动代理的发展 Wang等人 ([2024](#bib.bib28)); Hong等人
    ([2023](#bib.bib9))，以应对跨多领域的复杂任务 Qian等人 ([2023](#bib.bib22)); Hong等人 ([2023](#bib.bib9));
    Zhou等人 ([2023](#bib.bib41))。尽管近期工作在通过提示构建 Yao等人 ([2023b](#bib.bib36), [a](#bib.bib35))
    和多代理协作 Hong等人 ([2023](#bib.bib9)); Chen等人 ([2023](#bib.bib4)); Qian等人 ([2023](#bib.bib22))
    提升代理的工具利用能力方面取得了进展，但LLMs固有参数知识的受限范围可能导致计划幻觉的现象 Zhu等人 ([2024](#bib.bib42)) —— LLMs可能表现出与任务知识冲突的不可控行为，这种不良影响阻碍了它们在知识密集型任务中的实际应用。
- en: '![Refer to caption](img/7fd87024e4344f09b3c73f0b56d0887c.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/7fd87024e4344f09b3c73f0b56d0887c.png)'
- en: 'Figure 1: The procedure of workflow-guided agent planning. The agent is provided
    with workflow knowledge in various formats and prompted to plan the next action.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：工作流程引导的代理规划过程。代理提供了各种格式的工作流程知识，并被提示规划下一步行动。
- en: On the other hand, mitigating hallucinations by leveraging external knowledge
    is an ongoing key topic for LLM research Gao et al. ([2023](#bib.bib8)); Baek
    et al. ([2024](#bib.bib3)); Shi et al. ([2023](#bib.bib25)); Baek et al. ([2024](#bib.bib3)).
    As for LLM-agent planning, some preliminary efforts have been made to enhance
    the planning quality of agents by incorporating workflow-related knowledge Jiang
    et al. ([2024](#bib.bib11)); Chhikara et al. ([2023](#bib.bib6)); Ye et al. ([2023](#bib.bib37)).
    For example, KnowAgent Zhu et al. ([2024](#bib.bib42)) employs the explicit action
    knowledge summarized in natural language format to regulate the planning trajectory.
    ProAgent Ye et al. ([2023](#bib.bib37)) enhances the efficiency of complex tasks
    through control flows described in Python code. Despite the promise, these nascent
    works commonly shape workflow-related knowledge in miscellaneous and unmethodical
    formats, lacking in-depth exploration and rigorous benchmarking comparisons concerning
    the role of workflows. Hence, it still remains underexplored how to formalize,
    utilize and evaluate such workflow-related knowledge for LLM-based agents across
    different real-world scenarios.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，通过利用外部知识来减轻幻觉现象是LLM研究的一个持续关键主题，Gao等人 ([2023](#bib.bib8)); Baek等人 ([2024](#bib.bib3));
    Shi等人 ([2023](#bib.bib25)); Baek等人 ([2024](#bib.bib3))。至于LLM-agent规划，一些初步工作已被提出，通过整合与工作流程相关的知识来提升代理的规划质量，Jiang等人
    ([2024](#bib.bib11)); Chhikara等人 ([2023](#bib.bib6)); Ye等人 ([2023](#bib.bib37))。例如，KnowAgent
    Zhu等人 ([2024](#bib.bib42)) 使用以自然语言格式总结的明确行动知识来调节规划轨迹。ProAgent Ye等人 ([2023](#bib.bib37))
    通过Python代码描述的控制流来提升复杂任务的效率。尽管有前景，这些新兴工作通常以各种杂乱无章的格式塑造与工作流程相关的知识，缺乏对工作流程角色的深入探讨和严格的基准比较。因此，如何在不同实际场景中正式化、利用和评估这些与工作流程相关的知识仍然尚未充分探讨。
- en: 'To this end, we meticulously explore different formats of workflow knowledge
    and establish a systematic benchmark for evaluating workflow-guided agent planning.
    Our study initially revisits and formalizes various embedding formats of workflow
    knowledge, including natural language, symbolic code, and flowchart schema, as
    depicted in Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ FlowBench: Revisiting
    and Benchmarking Workflow-Guided Planning for LLM-based Agents"). To perform a
    comparative evaluation, we present FlowBench, the first comprehensive benchmark
    for workflow-guided agent planning. FlowBench covers an extensive taxonomy (6
    domains, 22 roles, 51 scenarios) and different knowledge formats (text, code,
    flowchart) to synchronize with real-world applications comprehensively. The benchmark
    data is constructed through a three-phase pipeline of task collection, workflow
    organization, and session generation. FlowBench features numerous distinct characteristics,
    such as coverage, difficulty, expert-level annotation, and support for multi-round
    user-agent interaction, as summarized in Table [1](#S1.T1 "Table 1 ‣ 1 Introduction
    ‣ FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based
    Agents").'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '为此，我们详细探讨了不同格式的工作流知识，并建立了一个系统的基准来评估工作流引导的代理规划。我们的研究最初重新审视并正式化了各种工作流知识的嵌入格式，包括自然语言、符号代码和流程图模式，如图 [1](#S1.F1
    "图 1 ‣ 1 介绍 ‣ FlowBench: 重新审视和基准测试基于LLM的代理工作流引导规划")所示。为了进行比较评估，我们提出了FlowBench，这是第一个全面的工作流引导代理规划基准。FlowBench覆盖了广泛的分类（6个领域、22个角色、51个场景）和不同的知识格式（文本、代码、流程图），以全面同步实际应用。基准数据通过任务收集、工作流组织和会话生成的三阶段流程构建。FlowBench具有许多独特的特征，如覆盖范围、难度、专家级注释以及对多轮用户-代理交互的支持，如表 [1](#S1.T1
    "表 1 ‣ 1 介绍 ‣ FlowBench: 重新审视和基准测试基于LLM的代理工作流引导规划")所总结。'
- en: 'To conduct a reliable assessment, we design a holistic evaluation framework
    that comprises two distinct granularities: (i)-Static turn-level evaluation that
    focuses on single-step planning. (ii)-Dynamical session-level evaluation that
    simulates sequential planning. Based on such evaluation mechanisms, we evaluate
    LLMs across varying levels of capability and embedded with different formats of
    workflow knowledge. We observe that even the best-performing LLM, GPT-4o Hel ([2024](#bib.bib1)),
    struggles to deliver satisfactory performance in certain tasks (43.2% and 40.9%
    success rate). By contrasting various workflow formats, we discover that flowcharts
    struck the best trade-off among performance, adaptability, and user-friendliness.
    All these results illuminate the profound challenge that FlowBench offers to the
    present LLM-agent designs and steer the focus of future exploration.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行可靠的评估，我们设计了一个整体评估框架，该框架包括两种不同的粒度：（i）静态回合级评估，关注单步规划。（ii）动态会话级评估，模拟顺序规划。基于这些评估机制，我们对不同能力水平和嵌入不同工作流知识格式的LLM进行了评估。我们观察到，即便是表现最好的LLM，GPT-4o
    Hel ([2024](#bib.bib1))，在某些任务中的表现仍不尽如人意（成功率为43.2%和40.9%）。通过对比各种工作流格式，我们发现流程图在性能、适应性和用户友好性之间取得了最佳的折衷。所有这些结果揭示了FlowBench对现有LLM代理设计提出的深刻挑战，并引导了未来探索的重点。
- en: Our contributions are summarized as follows,
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的贡献总结如下：
- en: •
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: As far as we know, we are the first to revisit and formalize the definition
    of different represented workflow knowledge systematically.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 据我们所知，我们是第一个系统地重新审视和正式化不同表示的工作流知识定义的团队。
- en: •
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We construct FlowBench, the first comprehensive benchmark for workflow-guided
    agent planning, which covers 51 scenarios across 6 domains, with different workflow
    formats.
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们构建了FlowBench，这是第一个全面的工作流引导代理规划基准，涵盖了6个领域中的51种场景，具有不同的工作流格式。
- en: •
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We present a holistic evaluation framework to achieve reliable comparisons.
    We provide a comparative analysis of various LLMs with different workflow formats,
    indicating promising directions for agent planning.
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了一个整体评估框架，以实现可靠的比较。我们提供了对不同工作流格式的各种LLM的比较分析，指出了代理规划的有希望方向。
- en: '| Benchmark | Domain | Purpose&Task | Workflow Knowledge | Multi-turn Interaction
    |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 基准 | 领域 | 目的与任务 | 工作流知识 | 多轮交互 |'
- en: '| Environment | User |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 环境 | 用户 |'
- en: '| PlanBench | Logistics, Blocksworld | Textual Script Generation | ✗ | ✗ |
    ✗ |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| PlanBench | 物流、方块世界 | 文本脚本生成 | ✗ | ✗ | ✗ |'
- en: '| TravelAgent | Traveling | Travel Plan Generation | ✗ | ✗ | ✗ |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 旅行代理 | 旅行 | 旅行计划生成 | ✗ | ✗ | ✗ |'
- en: '| KnowAgent | QA, Text Games | Online Task Planning | Text | ✓ | ✗ |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| KnowAgent | 问答，文本游戏 | 在线任务规划 | 文本 | ✓ | ✗ |'
- en: '| ProAgent | Robotic Process Automation | Online Task Planning | Code | ✓ |
    ✗ |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| ProAgent | 机器人过程自动化 | 在线任务规划 | 代码 | ✓ | ✗ |'
- en: '| FlowBench | 6 Domains, 22 Roles, 51 Scenarios | Online Task Planning | Text,
    Code, Flowchart | ✓ | ✓ |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| FlowBench | 6个领域，22个角色，51个场景 | 在线任务规划 | 文本、代码、流程图 | ✓ | ✓ |'
- en: 'Table 1: Comparison of FlowBench with some related studies and benchmarks,
    including ProAgent Ye et al. ([2023](#bib.bib37)), PlanBench Valmeekam et al.
    ([2023](#bib.bib27)), TravelAgent Xie et al. ([2024](#bib.bib31)) and KnowAgent Zhu
    et al. ([2024](#bib.bib42)).'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：FlowBench与一些相关研究和基准的比较，包括ProAgent Ye等人（[2023](#bib.bib37)）、PlanBench Valmeekam等人（[2023](#bib.bib27)）、TravelAgent Xie等人（[2024](#bib.bib31)）和KnowAgent Zhu等人（[2024](#bib.bib42)）。
- en: 2 Related Work
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: 2.1 LLM-Driven Agents
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 LLM驱动的代理
- en: The evolving abilities of LLMs have fostered explorations for LLM-driven agents
    Wang et al. ([2024](#bib.bib28)); Hong et al. ([2023](#bib.bib9)); Chen et al.
    ([2023](#bib.bib4)), which are designed for complex task solving and have shown
    great potential in various fields, such as software development Qian et al. ([2023](#bib.bib22));
    Hong et al. ([2023](#bib.bib9)); Chen et al. ([2023](#bib.bib4)), web navigation
    Deng et al. ([2023](#bib.bib7)); Zhou et al. ([2023](#bib.bib41)), and healthcare
    support Yang et al. ([2024b](#bib.bib34)); Zhang et al. ([2023](#bib.bib40)).
    Early approaches strive to improve the consecutive reasoning ability of LLMs,
    where LLMs are prompted to engage in progressive and comprehensive thinking, such
    as Chain of Thought (CoT) Wei et al. ([2022](#bib.bib29)), ReAct Yao et al. ([2023b](#bib.bib36)),
    and Tree of Thought Yao et al. ([2023a](#bib.bib35)). The latter strand of studies
    focuses on enhancing the tool utilization Schick et al. ([2023](#bib.bib24));
    Qin et al. ([2023](#bib.bib23)); Patil et al. ([2023](#bib.bib21)) and multi-agent
    collaboration Hong et al. ([2023](#bib.bib9)); Chen et al. ([2023](#bib.bib4));
    Qian et al. ([2023](#bib.bib22)) of LLMs.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs的不断进化能力促进了对LLM驱动的代理的探索，如Wang等人（[2024](#bib.bib28)）、Hong等人（[2023](#bib.bib9)）、Chen等人（[2023](#bib.bib4)），这些代理旨在解决复杂任务，并在软件开发（Qian等人（[2023](#bib.bib22)）、Hong等人（[2023](#bib.bib9)）、Chen等人（[2023](#bib.bib4)））、网络导航（Deng等人（[2023](#bib.bib7)）、Zhou等人（[2023](#bib.bib41)））和医疗支持（Yang等人（[2024b](#bib.bib34)）、Zhang等人（[2023](#bib.bib40)））等多个领域显示出了巨大的潜力。早期的方法努力提高LLMs的连续推理能力，其中LLMs被促使进行渐进和全面的思考，例如Chain
    of Thought (CoT) Wei等人（[2022](#bib.bib29)）、ReAct Yao等人（[2023b](#bib.bib36)）和Tree
    of Thought Yao等人（[2023a](#bib.bib35)）。后一类研究侧重于增强工具利用（Schick等人（[2023](#bib.bib24)）、Qin等人（[2023](#bib.bib23)）、Patil等人（[2023](#bib.bib21)））和LLMs的多代理协作（Hong等人（[2023](#bib.bib9)）、Chen等人（[2023](#bib.bib4)）、Qian等人（[2023](#bib.bib22)））。
- en: 2.2 Knowledge-Augmented Agents
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 知识增强代理
- en: Knowledge-augmented LLMs Gao et al. ([2023](#bib.bib8)); Baek et al. ([2024](#bib.bib3));
    Shi et al. ([2023](#bib.bib25)); Baek et al. ([2024](#bib.bib3)) have been a prevailing
    topic, as leveraging external knowledge can effectively improve response factuality
    Agrawal et al. ([2023](#bib.bib2)); Liu et al. ([2024](#bib.bib15), [2023a](#bib.bib13)).
    As for LLM-based agents, task-related knowledge and expertise are also important
    for making correct plans and decisions. To achieve this, nascent attempts Jiang
    et al. ([2024](#bib.bib11)); Chhikara et al. ([2023](#bib.bib6)) have been made
    to enhance the reliability of planning in designated tasks by incorporating workflow-related
    knowledge, such as action rules described in natural language Huang et al. ([2022](#bib.bib10));
    Zhu et al. ([2024](#bib.bib42)), domain knowledge represented as knowledge graphs
    Xu et al. ([2024](#bib.bib32)); Jiang et al. ([2024](#bib.bib11)), and control
    flow expressed in code Yang et al. ([2024a](#bib.bib33)); Ye et al. ([2023](#bib.bib37)).
    However, these works mostly craft workflow knowledge in diverse and sloppy representation
    formats, and there is a lack of formalized consensus and comprehensive benchmarking
    comparisons concerning the effect of infused workflow knowledge.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 知识增强的大型语言模型（LLMs）Gao 等人 ([2023](#bib.bib8)); Baek 等人 ([2024](#bib.bib3)); Shi
    等人 ([2023](#bib.bib25)); Baek 等人 ([2024](#bib.bib3)) 一直是一个热门话题，因为利用外部知识可以有效提高响应的真实性
    Agrawal 等人 ([2023](#bib.bib2)); Liu 等人 ([2024](#bib.bib15), [2023a](#bib.bib13))。对于基于
    LLM 的代理，任务相关的知识和专业知识对于制定正确的计划和决策也非常重要。为此，Jiang 等人 ([2024](#bib.bib11)); Chhikara
    等人 ([2023](#bib.bib6)) 做出了初步尝试，通过整合工作流相关知识（如自然语言描述的动作规则 Huang 等人 ([2022](#bib.bib10));
    Zhu 等人 ([2024](#bib.bib42))，知识图谱表示的领域知识 Xu 等人 ([2024](#bib.bib32)); Jiang 等人 ([2024](#bib.bib11))，以及以代码表达的控制流
    Yang 等人 ([2024a](#bib.bib33)); Ye 等人 ([2023](#bib.bib37))）来增强任务规划的可靠性。然而，这些研究大多以多样且松散的格式来构建工作流知识，缺乏对注入的工作流知识效果的正式共识和全面基准比较。
- en: 2.3 Evaluation of LLM Agents
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 LLM 代理的评估
- en: To assess the abilities of LLMs as agents, a plethora of benchmarks have been
    established Liu et al. ([2023b](#bib.bib14)); Ma et al. ([2024](#bib.bib16));
    Wu et al. ([2023](#bib.bib30)). These works are mostly tailored for evaluating
    generic abilities like tool utilization Qin et al. ([2023](#bib.bib23)); Chen
    et al. ([2024](#bib.bib5)), code generation Liu et al. ([2023b](#bib.bib14));
    Ma et al. ([2024](#bib.bib16)) and embodied interaction Wu et al. ([2023](#bib.bib30)).
    Regarding workflow-integrated planning, it remains questionable how to systematically
    assess the agent’s comprehension and utilization ability of the integrated workflow
    knowledge.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估 LLM 作为代理的能力，已经建立了大量的基准 Liu 等人 ([2023b](#bib.bib14)); Ma 等人 ([2024](#bib.bib16));
    Wu 等人 ([2023](#bib.bib30))。这些工作主要用于评估工具使用 Qin 等人 ([2023](#bib.bib23)); Chen 等人
    ([2024](#bib.bib5))、代码生成 Liu 等人 ([2023b](#bib.bib14)); Ma 等人 ([2024](#bib.bib16))
    和体现互动 Wu 等人 ([2023](#bib.bib30)) 等通用能力。关于工作流集成规划，如何系统地评估代理对集成工作流知识的理解和利用能力仍然值得探讨。
- en: '![Refer to caption](img/02fd5eddd6027c1df50bfe79a0bd2cbb.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/02fd5eddd6027c1df50bfe79a0bd2cbb.png)'
- en: 'Figure 2: Overview of FlowBench. Our benchmark schema is structured in a top-down
    multi-level hierarchy (domain - role - scenario - knowledge). The benchmark construction
    process on the left contains three phases (a,b,c). The evaluation framework on
    the right encapsulates static turn-level and simulated session-level assessment.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：FlowBench 概述。我们的基准框架结构为自上而下的多层次层级（领域 - 角色 - 场景 - 知识）。左侧的基准构建过程包括三个阶段（a,b,c）。右侧的评估框架涵盖静态轮次级别和模拟会话级别的评估。
- en: 3 Workflow Formalization
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 工作流形式化
- en: 3.1 Task Formulation
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 任务定义
- en: In our research scope, we consider an LLM-driven agent $\mathcal{M}_{\theta}$
    are initially provided with complete and detailed task descriptions as initial
    input. Nevertheless, such a non-interactive assumption is not realistic in real-world
    multi-round online planning. To this end, we generalize this to a more realistic
    setting of multi-turn interactions, allowing users to incrementally refine and
    modify their requirements through ongoing conversations with the agent.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的研究范围内，我们考虑一个由 LLM 驱动的代理 $\mathcal{M}_{\theta}$ 初始时提供完整详细的任务描述作为输入。然而，这种非交互的假设在现实世界的多轮在线规划中并不现实。为此，我们将其推广到一个更为现实的多轮交互设置，允许用户通过与代理的持续对话逐步细化和修改其要求。
- en: Formally, assuming that at the iteration step $i$,
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 正式来说，假设在迭代步骤 $i$，
- en: '|  | $\{a_{i+1},s_{i+1},r_{r+1}\}\leftarrow\mathcal{M}_{\theta}({\mathcal{H}_{i}},\mathcal{B})$
    |  | (1) |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '|  | $\{a_{i+1},s_{i+1},r_{r+1}\}\leftarrow\mathcal{M}_{\theta}({\mathcal{H}_{i}},\mathcal{B})$
    |  | (1) |'
- en: In this formula, $\mathcal{H}_{i}$.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个公式中，$\mathcal{H}_{i}$。
- en: 3.2 Revisiting Different Workflow Formats
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 重新审视不同的工作流格式
- en: 'Workflow-related knowledge is a set of representations of pipeline-related
    facts, which refers to the understanding of how processes or tasks are structured
    and executed within a specific context, such as a business or project environment.
    The content of different workflow knowledge primarily falls into the following
    categories: (i)-Operation process related, which describes the required steps
    and their sequential order to complete tasks. (ii)-Condition/rule related, which
    delineates the actions to be taken when certain conditions or parameters are met.
    (iii)-Tool/data related, which contains the utilization techniques for different
    tools and the mechanisms of data processing.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流相关知识是一组管道相关事实的表示，指的是理解在特定背景下（如业务或项目环境）如何结构化和执行过程或任务。不同工作流知识的内容主要包括以下几类：（i）-操作过程相关，描述完成任务所需的步骤及其顺序。（ii）-条件/规则相关，阐明在满足某些条件或参数时采取的行动。（iii）-工具/数据相关，包含不同工具的使用技巧和数据处理机制。
- en: 'As mentioned earlier, workflow-related knowledge can be embedded in a broad
    spectrum of formats Zhu et al. ([2024](#bib.bib42)); Ye et al. ([2023](#bib.bib37)).
    Thus, we begin by revisiting different workflow manifestations. Based on the level
    of abstraction, we primarily analyze three distinct representation forms:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，工作流相关知识可以嵌入多种格式中 Zhu et al. ([2024](#bib.bib42))；Ye et al. ([2023](#bib.bib37))。因此，我们首先重新审视不同的工作流表现形式。根据抽象层次，我们主要分析三种不同的表示形式：
- en: •
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Text format that is conveyed through vanilla natural language documentation.
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过普通自然语言文档传达的文本格式。
- en: •
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Code format that follows programming language standards, e.g., Python pseudo-code.
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 代码格式遵循编程语言标准，例如 Python 伪代码。
- en: •
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Flowchart format that is expressed in a low-code visual-programming diagram
    syntax, e.g., Markdown Mermaid notation.
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 流程图格式以低代码视觉编程图示语法表示，例如 Markdown Mermaid 符号。
- en: 'These three forms of workflow knowledge are depicted in Figure [1](#S1.F1 "Figure
    1 ‣ 1 Introduction ‣ FlowBench: Revisiting and Benchmarking Workflow-Guided Planning
    for LLM-based Agents") (see Appendix [D](#A4 "Appendix D Additional Demonstration
    ‣ FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based
    Agents") for more examples). Their respective fortes and flaws can be broadly
    outlined with the following two criteria,'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '这三种工作流知识形式在图 [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ FlowBench: Revisiting
    and Benchmarking Workflow-Guided Planning for LLM-based Agents")（更多示例请参见附录 [D](#A4
    "Appendix D Additional Demonstration ‣ FlowBench: Revisiting and Benchmarking
    Workflow-Guided Planning for LLM-based Agents")）中有所描述。它们各自的优点和缺点可以通过以下两个标准进行概述：'
- en: •
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Efficacy and Precision: Considering knowledge expression efficiency, text format
    is flexible in expressing complex concepts, but it can lead to excessive token
    consumption and undesired semantic ambiguity. Conversely, codes and flowcharts
    leverage structured symbols to enhance their precision and efficacy.'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 效率和精确性：考虑到知识表达的效率，文本格式在表达复杂概念时具有灵活性，但可能导致过度的标记消耗和不希望的语义模糊。相反，代码和流程图利用结构化符号来提高其精确性和效率。
- en: •
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'User friendliness: User-friendliness is primarily contingent upon how facilitative
    it is for users to edit and comprehend. Although text format allows for easy editing,
    it can be cumbersome to pinpoint specific knowledge within lengthy documents.
    For code, the demand for programming expertise to edit it also presents a challenge.
    By contrast, the flowchart presents a more user-friendly alternative, allowing
    users with no coding experience to edit easily and providing visualization interfaces
    to improve their understanding.'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用户友好性：用户友好性主要取决于对用户编辑和理解的便利性。尽管文本格式允许轻松编辑，但在长篇文档中定位特定知识可能会很麻烦。对于代码，编辑它所需的编程知识也构成挑战。相反，流程图提供了一种更用户友好的替代方案，使没有编码经验的用户能够轻松编辑，并提供可视化界面以改善理解。
- en: Overall, it can be concluded that natural language is more expressive but less
    efficient and often ambiguous, while programming code is more structured, concise,
    and precise, though less intuitive for user comprehension and editing. Flowcharts
    create a bridge, integrating the powerful expressiveness of natural language with
    the high efficiency of symbolic code, and providing highly user-friendly options
    for visualization and editing.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，可以得出结论，自然语言更具表现力但效率较低且常常含糊，而编程代码结构更明确、简洁和精确，但对用户理解和编辑不够直观。流程图架起了一座桥梁，将自然语言的强大表现力与符号代码的高效性相结合，为可视化和编辑提供了高度用户友好的选项。
- en: 4 FlowBench
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 FlowBench
- en: 'The overview of its construction process and evaluation framework is displayed
    in Figure [2](#S2.F2 "Figure 2 ‣ 2.3 Evaluation of LLM Agents ‣ 2 Related Work
    ‣ FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based
    Agents"). In what follows, we will elaborate on this in detail.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '其构建过程和评估框架的概述显示在图[2](#S2.F2 "Figure 2 ‣ 2.3 Evaluation of LLM Agents ‣ 2 Related
    Work ‣ FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based
    Agents")中。接下来，我们将详细阐述这一点。'
- en: 4.1 Hierarchy of Benchmark Schema
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 基准测试架构
- en: 'FlowBench consists of a collection of downstream domains (distribution shown
    in Section [4.2](#S4.SS2 "4.2 Benchmark Construction ‣ 4 FlowBench ‣ FlowBench:
    Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents")).
    Each domain incorporates a range of agent roles. Each of these roles is further
    delineated by a suite of specific scenarios (i.e., fundamental task). Each scenario
    is related to the corresponding task-related knowledge base, which encompasses
    task background, workflow-related knowledge, and a collection of tools to be employed.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 'FlowBench由一系列下游领域组成（分布见第[4.2](#S4.SS2 "4.2 Benchmark Construction ‣ 4 FlowBench
    ‣ FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based
    Agents")节）。每个领域包含一系列代理角色。每个角色进一步由一套特定场景（即基础任务）进行描述。每个场景与相应的任务相关知识库相关，该知识库包括任务背景、工作流相关知识和待使用的工具集合。'
- en: 'A comprehensive top-down example is depicted in the left part of Figure [2](#S2.F2
    "Figure 2 ‣ 2.3 Evaluation of LLM Agents ‣ 2 Related Work ‣ FlowBench: Revisiting
    and Benchmarking Workflow-Guided Planning for LLM-based Agents"). In the domain
    of customer services, several agent roles are configured, including restaurant
    waiter, hotel reception, and apartment manager. The role of apartment manager
    is then in charge of two scenarios: apartment search and bill inquiry. Each of
    these scenarios is then related to its task-related knowledge base.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '图[2](#S2.F2 "Figure 2 ‣ 2.3 Evaluation of LLM Agents ‣ 2 Related Work ‣ FlowBench:
    Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents")的左侧部分展示了一个全面的自上而下的示例。在客户服务领域，配置了多个代理角色，包括餐厅服务员、酒店接待员和公寓经理。公寓经理负责两个场景：公寓搜索和账单查询。这些场景与其任务相关的知识库相关联。'
- en: 4.2 Benchmark Construction
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 基准测试构建
- en: 'The construction pipeline of FlowBench is structured into three phases: scenario
    collection, workflow organization, and session generation.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: FlowBench的构建流程分为三个阶段：场景收集、工作流组织和会话生成。
- en: Task Collection
  id: totrans-75
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 任务收集
- en: 'For a benchmark to effectively assess workflow-guided planning ability, its
    diversity and wide coverage are essential. To achieve this, we initially draw
    inspiration from the collected tasks in existing works Mosig et al. ([2020](#bib.bib17))
    and further conduct extensive extensions. Our task collection is targeted towards
    both personal customers and business enterprises. Consequently, the roles and
    scenarios of FlowBench are meticulously collected from the following 6 domains:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有效评估工作流引导的规划能力，基准测试的多样性和广泛覆盖是至关重要的。为了实现这一点，我们最初从现有工作 Mosig 等人（[2020](#bib.bib17)）收集的任务中获得灵感，并进一步进行了广泛的扩展。我们的任务收集针对个人客户和商业企业。因此，FlowBench的角色和场景是从以下6个领域中精心收集的：
- en: '| Domain | Role | Scenario | Session | Turn |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 领域 | 角色 | 场景 | 会话 | 回合 |'
- en: '| Customer service | 4 | 12 | 114 | 1167 |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 客户服务 | 4 | 12 | 114 | 1167 |'
- en: '| Personal assistant | 3 | 7 | 92 | 821 |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 个人助理 | 3 | 7 | 92 | 821 |'
- en: '| E-tailing Recommandation | 2 | 5 | 32 | 330 |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 电子商务推荐 | 2 | 5 | 32 | 330 |'
- en: '| Travel&Transportation | 4 | 9 | 135 | 1421 |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 旅行与交通 | 4 | 9 | 135 | 1421 |'
- en: '| Logistics solutions | 3 | 6 | 61 | 521 |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 物流解决方案 | 3 | 6 | 61 | 521 |'
- en: '| Robotic process automation | 6 | 12 | 102 | 1053 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 机器人过程自动化 | 6 | 12 | 102 | 1053 |'
- en: '| Overall | 22 | 51 | 536 | 5313 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 总体 | 22 | 51 | 536 | 5313 |'
- en: 'Table 2: Domain statistics of FlowBench.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：FlowBench的领域统计。
- en: •
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Customer Service provides advice, reception, reservation, and after-sales support.
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 客户服务提供建议、接待、预订和售后支持。
- en: •
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Personal Assistant is to provide personal management and solution services.
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 个人助理旨在提供个人管理和解决方案服务。
- en: •
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: E-tailing Recommendation aids in product discovery and purchase during shopping.
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 电子零售推荐在购物过程中帮助产品发现和购买。
- en: •
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Travel&Transportation offers support for travel and transportation arrangements.
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 旅行与运输提供旅行和运输安排的支持。
- en: •
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Logistics Solutions assist in the management of express delivery and logistics
    services.
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 物流解决方案协助管理快递和物流服务。
- en: •
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Robotic Process Automation (RPA) focuses on automating and streamlining complex
    work processes, especially in business contexts.
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 机器人流程自动化（RPA）专注于自动化和简化复杂的工作流程，特别是在业务环境中。
- en: 'As mentioned in benchmark schema (Section [4.1](#S4.SS1 "4.1 Hierarchy of Benchmark
    Schema ‣ 4 FlowBench ‣ FlowBench: Revisiting and Benchmarking Workflow-Guided
    Planning for LLM-based Agents")), each of these domains contains several agent
    roles (22 in total), and each role in these domains further includes several task
    scenarios (51 in total). The complete scenarios and roles for each domain can
    be found in the Appendix and the domain distribution is also drawn in Figure [2](#S2.F2
    "Figure 2 ‣ 2.3 Evaluation of LLM Agents ‣ 2 Related Work ‣ FlowBench: Revisiting
    and Benchmarking Workflow-Guided Planning for LLM-based Agents").'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '正如基准方案中提到的（第[4.1节](#S4.SS1 "4.1 Hierarchy of Benchmark Schema ‣ 4 FlowBench
    ‣ FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based
    Agents")），这些领域中的每一个包含多个代理角色（共22个），这些领域中的每个角色进一步包括多个任务场景（共51个）。每个领域的完整场景和角色可以在附录中找到，领域分布也绘制在图[2](#S2.F2
    "Figure 2 ‣ 2.3 Evaluation of LLM Agents ‣ 2 Related Work ‣ FlowBench: Revisiting
    and Benchmarking Workflow-Guided Planning for LLM-based Agents")中。'
- en: Workflow Organization
  id: totrans-99
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 工作流组织
- en: After collecting task scenarios, next we describe the extraction and structuring
    of workflow-related knowledge for each scenario. Instead of brainstorming, we
    consult some existing references, such as professional knowledge corpora (e.g.,
    WiKiHow Koupaee and Wang ([2018](#bib.bib12))), websites of workflow knowledge
    (e.g., Zapier [Zapier](#bib.bib38) ), and search engine results.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在收集任务场景后，我们接下来描述每个场景中工作流相关知识的提取和结构化。我们不会进行头脑风暴，而是参考一些现有文献，如专业知识语料库（例如，WiKiHow Koupaee
    和 Wang ([2018](#bib.bib12)))、工作流知识网站（例如，Zapier [Zapier](#bib.bib38)）以及搜索引擎结果。
- en: 'Integrating information from these sources, we initially summarize the workflow-related
    expertise point by point into a natural language document. Then different human
    annotators are required to independently verify the correctness, completeness,
    and non-redundancy of these knowledge documents. Following this, we employ GPT-4 OpenAI
    ([2023b](#bib.bib20)) to convert such text format knowledge into code and flowchart
    formats following the specified standards and incorporate manual verification
    to ensure knowledge consistency. An example of workflow knowledge embedded in
    different formats is provided in Appendix [D](#A4 "Appendix D Additional Demonstration
    ‣ FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based
    Agents"). After structuring the workflow knowledge, we proceed to organize the
    tool invocation information involved in the workflow. Adhering to the GPT-4 function
    calling format, we outline the description for each tool call, the parameters
    for inputs/outputs, and the corresponding information for each parameter.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '综合这些来源的信息，我们首先将工作流相关的专业知识逐条总结成自然语言文档。然后，需要不同的人类标注员独立验证这些知识文档的正确性、完整性和非冗余性。随后，我们使用
    GPT-4 OpenAI ([2023b](#bib.bib20)) 将这种文本格式的知识转换为符合指定标准的代码和流程图格式，并进行人工验证以确保知识的一致性。附录[D](#A4
    "Appendix D Additional Demonstration ‣ FlowBench: Revisiting and Benchmarking
    Workflow-Guided Planning for LLM-based Agents")中提供了嵌入不同格式的工作流知识示例。在结构化工作流知识后，我们继续组织涉及工作流的工具调用信息。遵循
    GPT-4 的函数调用格式，我们概述每个工具调用的描述、输入/输出参数以及每个参数的相关信息。'
- en: '| Model | Format | Single-Scenario | Cross-Scenario |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 格式 | 单场景 | 跨场景 |'
- en: '| Tool Invocation | Parameter F1 | Response Score | Tool Invocation | Parameter
    F1 | Response Score |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 工具调用 | 参数 F1 | 响应评分 | 工具调用 | 参数 F1 | 响应评分 |'
- en: '| P | R | F1 | P | R | F1 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| P | R | F1 | P | R | F1 |'
- en: '| GPT-4o | None | 73.8 | 60.3 | 66.3 | 76.5 | 7.80 | 60.8 | 51.2 | 55.4 | 70.8
    | 7.85 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4o | 无 | 73.8 | 60.3 | 66.3 | 76.5 | 7.80 | 60.8 | 51.2 | 55.4 | 70.8
    | 7.85 |'
- en: '| Text | 75.9 | 63.6 | 69.1 | 77.2 | 8.22 | 66.0 | 54.9 | 59.9 | 71.0 | 8.34
    |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 文本 | 75.9 | 63.6 | 69.1 | 77.2 | 8.22 | 66.0 | 54.9 | 59.9 | 71.0 | 8.34
    |'
- en: '| Code | 73.7 | 64.9 | 69.0 | 78.3 | 8.30 | 63.2 | 53.9 | 58.2 | 70.7 | 8.23
    |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 代码 | 73.7 | 64.9 | 69.0 | 78.3 | 8.30 | 63.2 | 53.9 | 58.2 | 70.7 | 8.23
    |'
- en: '| Flowchart | 83.4 | 68.9 | 75.5 | 80.9 | 8.38 | 73.9 | 56.0 | 63.7 | 72.2
    | 8.29 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 流程图 | 83.4 | 68.9 | 75.5 | 80.9 | 8.38 | 73.9 | 56.0 | 63.7 | 72.2 | 8.29
    |'
- en: '| GPT-4-Turbo | None | 68.3 | 52.1 | 59.1 | 71.7 | 7.55 | 53.9 | 45.6 | 49.2
    | 63.9 | 7.77 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4-Turbo | 无 | 68.3 | 52.1 | 59.1 | 71.7 | 7.55 | 53.9 | 45.6 | 49.2 |
    63.9 | 7.77 |'
- en: '| Text | 70.2 | 56.8 | 62.9 | 74.5 | 7.94 | 55.3 | 47.2 | 51.1 | 64.3 | 8.05
    |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 文本 | 70.2 | 56.8 | 62.9 | 74.5 | 7.94 | 55.3 | 47.2 | 51.1 | 64.3 | 8.05
    |'
- en: '| Code | 73.7 | 61.4 | 67.0 | 78.8 | 7.98 | 53.7 | 49.4 | 51.4 | 65.1 | 8.03
    |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 代码 | 73.7 | 61.4 | 67.0 | 78.8 | 7.98 | 53.7 | 49.4 | 51.4 | 65.1 | 8.03
    |'
- en: '| Flowchart | 78.9 | 69.3 | 73.6 | 79.2 | 8.06 | 67.2 | 58.1 | 62.3 | 71.5
    | 8.10 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 流程图 | 78.9 | 69.3 | 73.6 | 79.2 | 8.06 | 67.2 | 58.1 | 62.3 | 71.5 | 8.10
    |'
- en: '| GPT-3.5-Turbo | None | 58.5 | 51.9 | 55.0 | 67.9 | 7.01 | 52.5 | 42.7 | 47.2
    | 66.2 | 7.19 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5-Turbo | 无 | 58.5 | 51.9 | 55.0 | 67.9 | 7.01 | 52.5 | 42.7 | 47.2
    | 66.2 | 7.19 |'
- en: '| Text | 63.4 | 56.8 | 59.8 | 72.5 | 7.28 | 53.5 | 48.9 | 51.0 | 69.0 | 7.39
    |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 文本 | 63.4 | 56.8 | 59.8 | 72.5 | 7.28 | 53.5 | 48.9 | 51.0 | 69.0 | 7.39
    |'
- en: '| Code | 60.7 | 55.0 | 57.9 | 69.2 | 7.33 | 53.1 | 47.7 | 50.2 | 70.2 | 7.33
    |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 代码 | 60.7 | 55.0 | 57.9 | 69.2 | 7.33 | 53.1 | 47.7 | 50.2 | 70.2 | 7.33
    |'
- en: '| Flowchart | 71.6 | 59.6 | 65.4 | 76.3 | 7.39 | 60.9 | 51.0 | 55.6 | 70.8
    | 7.30 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 流程图 | 71.6 | 59.6 | 65.4 | 76.3 | 7.39 | 60.9 | 51.0 | 55.6 | 70.8 | 7.30
    |'
- en: 'Table 3: Performance comparisons of different LLMs equipped with different
    formats of workflow knowledge under static turn-level evaluation. Bold entries
    indicate superior results.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：在静态轮次评估下，配备不同格式工作流程知识的不同LLM的性能比较。粗体条目表示结果更优。
- en: Interactive Session Generation
  id: totrans-118
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 互动会话生成
- en: 'With the organized workflow-related knowledge at hand, our subsequent endeavor
    is to synthesize the ground-truth user-agent interactive sessions for every scenario.
    Such generated sessions will serve as the prerequisite for our evaluation framework,
    whose details are discussed later in Section [4.3](#S4.SS3 "4.3 Evaluation Framework
    ‣ 4 FlowBench ‣ FlowBench: Revisiting and Benchmarking Workflow-Guided Planning
    for LLM-based Agents"). Our principle is to enhance the diversity and authenticity
    of generated sessions. To achieve this, we prompt GPT-4 to generate diverse user
    profiles under each scenario to enhance diversity, which includes user background,
    user targets, response tones (i.e., response style). For data authenticity, we
    further intentionally incorporate some out-of-scenario items, such as casual chit-chat
    and irrelevant off-scope intents, into the user profiles, mimicking real-world
    scenarios.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在掌握了组织好的工作流程相关知识之后，我们的下一步工作是合成每种情境下的真实用户-代理互动会话。这些生成的会话将作为我们评估框架的前提，其详细信息将在第[4.3](#S4.SS3
    "4.3 评估框架 ‣ 4 FlowBench ‣ FlowBench：重新审视和基准化基于工作流程的LLM代理规划")节中讨论。我们的原则是增强生成会话的多样性和真实性。为此，我们提示GPT-4在每种情境下生成多样的用户档案，以提高多样性，包括用户背景、用户目标、回应语气（即回应风格）。为了保证数据的真实性，我们进一步故意将一些超出情境的项目，例如随意聊天和无关的意图，融入用户档案中，以模拟真实世界的情境。
- en: Given generated user profiles, a collaborative annotation strategy is employed,
    which assigns a cooperative pair of a human annotator and an LLM annotator (GPT-4)
    for both the user and agent side. Specifically, for each interaction turn, on
    the user side, the human annotator crafts the subsequent user intent and dialogue
    draft based on task context and interaction history, which is then verified and
    rephrased by the LLM annotator to match the required response tone. As for the
    agent side, the human annotator leverages the workflow knowledge to formulate
    the next action plan and craft an initial response draft, which is subsequently
    reviewed and embellished by the LLM annotator. This collaborative generation process
    continues iteratively until the entire session is fully annotated.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 给定生成的用户档案，采用了协作注释策略，即为用户和代理方分配一对合作的人工注释员和LLM注释员（GPT-4）。具体而言，对于每次交互回合，用户侧的人工注释员根据任务背景和交互历史制定后续的用户意图和对话草稿，然后由LLM注释员验证并重新措辞，以匹配所需的回应语气。而在代理方，人工注释员利用工作流程知识制定下一个行动计划并编写初步回应草稿，随后由LLM注释员审查并润色。这个协作生成过程会不断迭代，直到整个会话被完全注释。
- en: Data Verification
  id: totrans-121
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 数据验证
- en: To ensure data quality, we incorporate human verification at each stage during
    benchmark construction. Three human annotators participate in the quality verification
    process. Each submission from an annotator will be subject to cross-verification
    by the remaining two annotators.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 为确保数据质量，我们在基准构建的每个阶段都进行人工验证。三名人工标注员参与质量验证过程。每位标注员的提交将由剩余的两名标注员进行交叉验证。
- en: '| Model | Format | Single-Scenario | Cross-Scenario |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 格式 | 单场景 | 跨场景 |'
- en: '| Tool Invocation | Success Rate | Task Progress | Tool Invocation | Success
    Rate | Task Progress |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 工具调用 | 成功率 | 任务进展 | 工具调用 | 成功率 | 任务进展 |'
- en: '| P | R | F1 | P | R | F1 |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| P | R | F1 | P | R | F1 |'
- en: '| GPT-4o | None | 67.8 | 70.5 | 69.0 | 35.1 | 77.5 | 45.1 | 53.9 | 49.0 | 34.2
    | 75.7 |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4o | 无 | 67.8 | 70.5 | 69.0 | 35.1 | 77.5 | 45.1 | 53.9 | 49.0 | 34.2
    | 75.7 |'
- en: '| Text | 73.7 | 81.2 | 77.2 | 41.7 | 83.4 | 50.5 | 58.7 | 54.1 | 40.9 | 81.2
    |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 文本 | 73.7 | 81.2 | 77.2 | 41.7 | 83.4 | 50.5 | 58.7 | 54.1 | 40.9 | 81.2
    |'
- en: '| Code | 70.9 | 79.6 | 75.0 | 43.2 | 83.1 | 47.7 | 56.9 | 51.9 | 38.2 | 77.9
    |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 代码 | 70.9 | 79.6 | 75.0 | 43.2 | 83.1 | 47.7 | 56.9 | 51.9 | 38.2 | 77.9
    |'
- en: '| Flowchart | 74.3 | 82.6 | 78.3 | 42.7 | 82.2 | 50.2 | 60.4 | 54.7 | 40.1
    | 81.3 |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 流程图 | 74.3 | 82.6 | 78.3 | 42.7 | 82.2 | 50.2 | 60.4 | 54.7 | 40.1 | 81.3
    |'
- en: '| GPT-4-Turbo | None | 62.9 | 64.0 | 63.5 | 31.9 | 76.7 | 43.6 | 47.0 | 45.2
    | 31.1 | 75.3 |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4-Turbo | 无 | 62.9 | 64.0 | 63.5 | 31.9 | 76.7 | 43.6 | 47.0 | 45.2 |
    31.1 | 75.3 |'
- en: '| Text | 65.9 | 69.9 | 67.8 | 41.5 | 83.8 | 47.6 | 49.3 | 48.4 | 36.8 | 79.6
    |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 文本 | 65.9 | 69.9 | 67.8 | 41.5 | 83.8 | 47.6 | 49.3 | 48.4 | 36.8 | 79.6
    |'
- en: '| Code | 79.3 | 64.7 | 71.2 | 37.8 | 83.6 | 47.5 | 52.9 | 50.0 | 37.3 | 82.0
    |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 代码 | 79.3 | 64.7 | 71.2 | 37.8 | 83.6 | 47.5 | 52.9 | 50.0 | 37.3 | 82.0
    |'
- en: '| Flowchart | 70.5 | 78.3 | 74.2 | 40.6 | 82.3 | 50.1 | 51.2 | 50.6 | 39.4
    | 81.1 |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 流程图 | 70.5 | 78.3 | 74.2 | 40.6 | 82.3 | 50.1 | 51.2 | 50.6 | 39.4 | 81.1
    |'
- en: '| GPT-3.5-Turbo | None | 37.6 | 50.5 | 43.1 | 29.8 | 63.7 | 24.7 | 30.7 | 27.4
    | 22.4 | 61.1 |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5-Turbo | 无 | 37.6 | 50.5 | 43.1 | 29.8 | 63.7 | 24.7 | 30.7 | 27.4
    | 22.4 | 61.1 |'
- en: '| Text | 44.1 | 55.6 | 49.1 | 37.0 | 69.7 | 25.6 | 31.5 | 28.2 | 25.2 | 63.9
    |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| 文本 | 44.1 | 55.6 | 49.1 | 37.0 | 69.7 | 25.6 | 31.5 | 28.2 | 25.2 | 63.9
    |'
- en: '| Code | 44.5 | 52.9 | 48.3 | 31.3 | 66.3 | 24.5 | 31.9 | 27.8 | 24.1 | 62.9
    |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| 代码 | 44.5 | 52.9 | 48.3 | 31.3 | 66.3 | 24.5 | 31.9 | 27.8 | 24.1 | 62.9
    |'
- en: '| Flowchart | 43.6 | 54.3 | 48.4 | 34.9 | 68.6 | 24.9 | 33.0 | 28.5 | 24.7
    | 67.0 |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 流程图 | 43.6 | 54.3 | 48.4 | 34.9 | 68.6 | 24.9 | 33.0 | 28.5 | 24.7 | 67.0
    |'
- en: 'Table 4: Performance comparisons of different LLMs equipped with different
    formats of workflow knowledge under simulated session-level evaluation. Bold entries
    indicate superior results.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '表 4: 不同LLM在模拟会话级评估下的不同工作流知识格式的性能比较。粗体条目表示结果优越。'
- en: Benchmark Statistics
  id: totrans-139
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基准统计
- en: 'The statistics of FlowBench are shown in Table [2](#S4.T2 "Table 2 ‣ Task Collection
    ‣ 4.2 Benchmark Construction ‣ 4 FlowBench ‣ FlowBench: Revisiting and Benchmarking
    Workflow-Guided Planning for LLM-based Agents"), and the comparisons with some
    related benchmarks are in Table [1](#S1.T1 "Table 1 ‣ 1 Introduction ‣ FlowBench:
    Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents"). The
    construction cost is in Appendix [A.3](#A1.SS3 "A.3 Benchmark Construction Cost
    ‣ Appendix A Additional Benchmark Details ‣ FlowBench: Revisiting and Benchmarking
    Workflow-Guided Planning for LLM-based Agents").'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 'FlowBench的统计数据如表[2](#S4.T2 "表 2 ‣ 任务收集 ‣ 4.2 基准构建 ‣ 4 FlowBench ‣ FlowBench:
    重新审视和基准测试基于LLM的代理的工作流规划")所示，与一些相关基准的比较见表[1](#S1.T1 "表 1 ‣ 1 介绍 ‣ FlowBench: 重新审视和基准测试基于LLM的代理的工作流规划")。构建成本在附录[A.3](#A1.SS3
    "A.3 基准构建成本 ‣ 附录 A 附加基准详细信息 ‣ FlowBench: 重新审视和基准测试基于LLM的代理的工作流规划")中。'
- en: 4.3 Evaluation Framework
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 评估框架
- en: After benchmark construction, we propose a holistic and multi-faceted evaluation
    framework in this section. We categorize our evaluation scenarios according to
    task awareness, and present two distinct facets of static and simulated assessments.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在基准构建后，我们在本节提出了一个全面且多方面的评估框架。我们根据任务意识对评估场景进行分类，并展示了静态和模拟评估的两个不同方面。
- en: 4.3.1 Task Awareness
  id: totrans-143
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.1 任务意识
- en: 'As previously mentioned in Section [4.1](#S4.SS1 "4.1 Hierarchy of Benchmark
    Schema ‣ 4 FlowBench ‣ FlowBench: Revisiting and Benchmarking Workflow-Guided
    Planning for LLM-based Agents"), in our dataset schema, each agent role is paired
    with several respective task scenarios. Therefore, we divide our evaluation scenarios
    into single-scenario and cross-scenario evaluations based on whether the specified
    task scenario is known a priori. (i)-Single-scenario evaluation assumes a pre-determined
    task scenario. An agent role is provided with the workflow knowledge of that scenario
    and needs to navigate, plan, and execute actions within this single task scenario.
    (ii)-Cross-scenario evaluation assumes that the specific scenario is unknown.
    The agent role is equipped with a versatile set of workflow knowledge covering
    all scenarios within the role scope. The agent needs to flexibly plan and switch
    between different scenario.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '如第[4.1](#S4.SS1 "4.1 Hierarchy of Benchmark Schema ‣ 4 FlowBench ‣ FlowBench:
    Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents")节所述，在我们的数据集架构中，每个代理角色都与多个相应的任务场景配对。因此，我们将评估场景分为单场景评估和跨场景评估，依据是指定的任务场景是否事先已知。
    (i)- 单场景评估假设任务场景是预定的。代理角色被提供该场景的工作流知识，并需在此单一任务场景中进行导航、规划和执行行动。 (ii)- 跨场景评估假设具体场景未知。代理角色配备了涵盖所有场景的多功能工作流知识。代理需要灵活地规划并在不同场景之间切换。'
- en: 4.3.2 Evaluation Protocols
  id: totrans-145
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.2 评估协议
- en: 'As mentioned in Section [3.1](#S3.SS1 "3.1 Task Formulation ‣ 3 Workflow Formalization
    ‣ FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based
    Agents"), our setting of multi-turn user-agent interactions generalizes the traditional
    agent paradigm. Consequently, the conventional evaluation protocols are incompatible
    with our benchmark. To solve this, we design a holistic evaluation protocol at
    both turn and session level, as depicted in the right of Figure [2](#S2.F2 "Figure
    2 ‣ 2.3 Evaluation of LLM Agents ‣ 2 Related Work ‣ FlowBench: Revisiting and
    Benchmarking Workflow-Guided Planning for LLM-based Agents").'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '如第[3.1](#S3.SS1 "3.1 Task Formulation ‣ 3 Workflow Formalization ‣ FlowBench:
    Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents")节所述，我们的多回合用户-代理互动设置扩展了传统的代理范式。因此，传统的评估协议与我们的基准不兼容。为了解决这个问题，我们设计了一种全方位的评估协议，涵盖回合和会话级别，如图[2](#S2.F2
    "Figure 2 ‣ 2.3 Evaluation of LLM Agents ‣ 2 Related Work ‣ FlowBench: Revisiting
    and Benchmarking Workflow-Guided Planning for LLM-based Agents")右侧所示。'
- en: Static Turn-level Evaluation.
  id: totrans-147
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 静态回合级评估。
- en: 'Static turn-level evaluation operates based on the ground-truth sessions generated
    in Section [4.2](#S4.SS2 "4.2 Benchmark Construction ‣ 4 FlowBench ‣ FlowBench:
    Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents"). Specifically,
    given a sampled ground-truth session $d$ for evaluation.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '静态回合级别评估基于在第[4.2](#S4.SS2 "4.2 Benchmark Construction ‣ 4 FlowBench ‣ FlowBench:
    Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents")节生成的真实会话。具体而言，给定一个用于评估的采样真实会话$d$。'
- en: Simulated Session-level Evaluation.
  id: totrans-149
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 模拟会话级评估。
- en: To more comprehensively assess planning capabilities in real-world scenarios
    where actions are sequentially planned and carried out, a simulated session-level
    evaluation framework is proposed.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更全面地评估在实际场景中规划和执行行动的能力，提出了一种模拟会话级评估框架。
- en: 'Specifically, we construct a user simulator based on GPT-4. In order to ensure
    that the behavior of this simulated user aligns with humans, we also rely on the
    ground-truth sessions generated in Section [4.2](#S4.SS2 "4.2 Benchmark Construction
    ‣ 4 FlowBench ‣ FlowBench: Revisiting and Benchmarking Workflow-Guided Planning
    for LLM-based Agents"). We distill a task-user summary from each of these sessions
    via GPT-4, which concludes information of task background, user goals, tool invocation
    information. Notably, this task-user summary is different from the generated user
    profile in Section [4.2](#S4.SS2 "4.2 Benchmark Construction ‣ 4 FlowBench ‣ FlowBench:
    Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents"). The
    user goals summarizes all the objectives of the user, while tool invocation information
    outlines the expected parameters and values for tool usage. Based on this task-user
    summary, a predicted session is produced with the simulated user and the to-be-assessed
    agent for metric calculation. All the evaluation metrics for turn and session-level
    are discussed later in Section [5.1](#S5.SS1 "5.1 Models and Baselines ‣ 5 Experiment
    ‣ FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based
    Agents").'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '具体而言，我们基于 GPT-4 构建了一个用户模拟器。为了确保该模拟用户的行为与人类一致，我们还依赖于第 [4.2](#S4.SS2 "4.2 Benchmark
    Construction ‣ 4 FlowBench ‣ FlowBench: Revisiting and Benchmarking Workflow-Guided
    Planning for LLM-based Agents") 节中生成的真实会话。我们通过 GPT-4 从每个会话中提取任务-用户摘要，该摘要包含任务背景、用户目标、工具调用信息。值得注意的是，这个任务-用户摘要与第
    [4.2](#S4.SS2 "4.2 Benchmark Construction ‣ 4 FlowBench ‣ FlowBench: Revisiting
    and Benchmarking Workflow-Guided Planning for LLM-based Agents") 节中生成的用户档案不同。用户目标总结了用户的所有目标，而工具调用信息则概述了工具使用的预期参数和值。基于此任务-用户摘要，生成了一个预测会话，用于与模拟用户和待评估的代理进行指标计算。所有的轮次和会话级别的评估指标将在第
    [5.1](#S5.SS1 "5.1 Models and Baselines ‣ 5 Experiment ‣ FlowBench: Revisiting
    and Benchmarking Workflow-Guided Planning for LLM-based Agents") 节中讨论。'
- en: 5 Experiment
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 实验
- en: 5.1 Models and Baselines
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 模型和基准
- en: LLMs.
  id: totrans-154
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: LLM。
- en: 'Given the difficulty of solving complex tasks in practical scenarios, we mainly
    focus on examining the effectiveness of advanced LLMs. Hence we conduct experiments
    on several advanced LLMs with varying degrees of capability from OpenAI: GPT-4o Hel
    ([2024](#bib.bib1)), GPT-4-Turbo OpenAI ([2023b](#bib.bib20)), GPT-3.5-Turbo OpenAI
    ([2022](#bib.bib18)),'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于在实际场景中解决复杂任务的难度，我们主要关注评估先进 LLM 的效果。因此，我们对来自 OpenAI 的几种先进 LLM 进行了实验，这些 LLM
    具有不同的能力水平：GPT-4o Hel ([2024](#bib.bib1))、GPT-4-Turbo OpenAI ([2023b](#bib.bib20))、GPT-3.5-Turbo
    OpenAI ([2022](#bib.bib18))。
- en: Knowledge Formats.
  id: totrans-156
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 知识格式。
- en: We explore performances with different embedded formats of workflow knowledge,
    including (i)-Text variant in natural language document formats, (ii)-Code variant
    that adheres to Python pseudo-code style, (iii)-Flowchart variant using low-code
    flowcharts following the markdown mermaid syntax. (iv)-None variant is further
    included, which only offers tool information, withholding the workflow-related
    knowledge. Notably text/code/flowchart are based on a consistent workflow and
    are merely different in formats.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们探索了不同嵌入格式的工作流知识的表现，包括 (i)-自然语言文档格式中的文本变体，(ii)-遵循 Python 伪代码风格的代码变体，(iii)-使用遵循
    markdown mermaid 语法的低代码流程图的流程图变体。还进一步包括 (iv)-无变体，它仅提供工具信息，不包含与工作流相关的知识。值得注意的是，文本/代码/流程图都基于一致的工作流，只是在格式上有所不同。
- en: Metrics.
  id: totrans-158
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 指标。
- en: 'We evaluate turn and session-level performance based on step-wise planning
    accuracy and overall task completion. Tool invocation is evaluated for both levels
    by precision (P), recall (R), and F1-score. An invocation is considered correct
    only when both tool name and all required parameters are correctly identified.
    On session level, we sequentially check each ground-truth invocation to verify
    if it matches any simulated one. On turn level, the F1-score of parameter collection
    is also included. We further evaluate response quality by preference scoring (full
    marks:10) based on correctness, helpfulness, and humanness via GPT-4\. For session
    level, we evaluate the success rates and task progress via GPT-4. (i)-Success
    rate describes the proportion of completely successful sessions. A session is
    deemed successful when all the goals specified in the task-user summary are achieved.
    (ii)-Task progress indicates the percentage of goals completed within each session.
    The evaluation prompts are in Appendix [C.3](#A3.SS3 "C.3 Prompt Design for Automated
    Evaluation. ‣ Appendix C Additional Implementation Details ‣ FlowBench: Revisiting
    and Benchmarking Workflow-Guided Planning for LLM-based Agents").'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '我们根据逐步规划的准确性和整体任务完成情况评估轮次和会话级别的表现。工具调用在两个级别上通过精确度（P）、召回率（R）和 F1 分数进行评估。只有当工具名称和所有所需参数都被正确识别时，调用才被视为正确。在会话级别，我们按顺序检查每个真实调用以验证其是否与任何模拟调用匹配。在轮次级别，还包括参数收集的
    F1 分数。我们进一步通过 GPT-4 对正确性、有用性和人性进行偏好评分（满分：10）来评估响应质量。对于会话级别，我们通过 GPT-4 评估成功率和任务进展。（i）-成功率描述了完全成功的会话比例。当任务-用户总结中指定的所有目标都实现时，会话被视为成功。（ii）-任务进展表示每个会话中完成的目标的百分比。评估提示见附录[C.3](#A3.SS3
    "C.3 自动化评估的提示设计 ‣ 附录 C 其他实施细节 ‣ FlowBench: 重新审视和基准测试基于LLM的代理的工作流引导规划")。'
- en: Implementation Details.
  id: totrans-160
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 实施细节。
- en: 'During the inference, we adopt gpt-4o-0513 version for GPT-4o, gpt-4-0125-preview
    version for GPT-4-Turbo, and gpt-3.5-turbo-16k-0613 version for GPT-3.5-Turbo.
    In automatic evaluation for response preference, success rate, and average progress,
    we adopt gpt-4-turbo-0125-preview version for fair comparisons. The inference
    prompts utilize ReAct Yao et al. ([2023b](#bib.bib36)) framework consisting of
    thought, action, observation. More implementation details and examples are put
    in Appendix [C](#A3 "Appendix C Additional Implementation Details ‣ FlowBench:
    Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents").'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '在推断过程中，我们采用 gpt-4o-0513 版本用于 GPT-4o，gpt-4-0125-preview 版本用于 GPT-4-Turbo，和 gpt-3.5-turbo-16k-0613
    版本用于 GPT-3.5-Turbo。在响应偏好、成功率和平均进展的自动评估中，我们采用 gpt-4-turbo-0125-preview 版本以确保公平比较。推断提示采用
    ReAct Yao 等人（[2023b](#bib.bib36)）框架，包括思考、行动、观察。更多实施细节和示例见附录[C](#A3 "附录 C 其他实施细节
    ‣ FlowBench: 重新审视和基准测试基于LLM的代理的工作流引导规划")。'
- en: '| Format | S-Scenario | C-Scenario |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| 格式 | S-场景 | C-场景 |'
- en: '| Tool | SR | TP | Tool | SR | TP |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 工具 | SR | TP | 工具 | SR | TP |'
- en: '| None w/o tool | 53.0 | 28.9 | 72.1 | 31.7 | 25.3 | 71.3 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| 无工具 | 53.0 | 28.9 | 72.1 | 31.7 | 25.3 | 71.3 |'
- en: '| None | 63.5 | 31.9 | 76.7 | 45.2 | 31.1 | 75.3 |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| 无 | 63.5 | 31.9 | 76.7 | 45.2 | 31.1 | 75.3 |'
- en: '| Text | 67.8 | 41.5 | 83.8 | 48.4 | 36.8 | 79.6 |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 文本 | 67.8 | 41.5 | 83.8 | 48.4 | 36.8 | 79.6 |'
- en: '| Code | 71.2 | 37.8 | 83.6 | 50.0 | 37.3 | 82.0 |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 代码 | 71.2 | 37.8 | 83.6 | 50.0 | 37.3 | 82.0 |'
- en: '| Flowchart | 74.2 | 40.6 | 82.3 | 50.6 | 39.4 | 81.1 |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 流程图 | 74.2 | 40.6 | 82.3 | 50.6 | 39.4 | 81.1 |'
- en: '| Ensemble | 75.1 | 45.3 | 85.2 | 51.8 | 43.4 | 81.6 |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 集成 | 75.1 | 45.3 | 85.2 | 51.8 | 43.4 | 81.6 |'
- en: 'Table 5: Performance for variant None w/o tool and Ensemble with GPT-4-Turbo
    under session-level evaluation. ‘Tool’, ‘SR’, and ‘TP’ indicate F1 score of tool
    invocation, success rate and task progress respectively.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 5：在会话级别评估中，变体 None 无工具和 Ensemble 与 GPT-4-Turbo 的表现。‘工具’，‘SR’，和‘TP’分别表示工具调用的
    F1 分数、成功率和任务进展。
- en: 5.2 Main Results
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 主要结果
- en: 'Table [3](#S4.T3 "Table 3 ‣ Workflow Organization ‣ 4.2 Benchmark Construction
    ‣ 4 FlowBench ‣ FlowBench: Revisiting and Benchmarking Workflow-Guided Planning
    for LLM-based Agents") and  [4](#S4.T4 "Table 4 ‣ Data Verification ‣ 4.2 Benchmark
    Construction ‣ 4 FlowBench ‣ FlowBench: Revisiting and Benchmarking Workflow-Guided
    Planning for LLM-based Agents") display the performance comparisons on the turn
    and session level. Based on these results, the following summarizations can be
    observed:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '表格[3](#S4.T3 "表格 3 ‣ 工作流组织 ‣ 4.2 基准构建 ‣ 4 FlowBench ‣ FlowBench: 重新审视和基准测试基于LLM的代理的工作流引导规划")和[4](#S4.T4
    "表格 4 ‣ 数据验证 ‣ 4.2 基准构建 ‣ 4 FlowBench ‣ FlowBench: 重新审视和基准测试基于LLM的代理的工作流引导规划")展示了轮次和会话级别的性能比较。基于这些结果，可以观察到以下总结：'
- en: '(i)-When external workflow knowledge is absent and merely tool information
    is provided (variant None), LLMs can still rely on their intrinsic commonsense
    to achieve a basic understanding of workflow. However, in some expertise-intensive
    domains, lacking workflow knowledge can result in notable degradation, as discussed
    in Section [5.3](#S5.SS3 "5.3 Further Analysis ‣ 5 Experiment ‣ FlowBench: Revisiting
    and Benchmarking Workflow-Guided Planning for LLM-based Agents").'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '(i)-当缺乏外部工作流知识，仅提供工具信息（变体None）时，LLM仍可以依靠其内在常识对工作流进行基本理解。然而，在一些专业知识密集的领域，缺乏工作流知识可能会导致显著的退化，如在[5.3](#S5.SS3
    "5.3 进一步分析 ‣ 5 实验 ‣ FlowBench: 重新审视和基准化基于LLM的工作流引导规划")节中讨论的那样。'
- en: (ii)-The incorporation of workflow knowledge in different formats can significantly
    facilitate agent planning, achieving evident improvements at both turn level and
    session level. Cross-scenario transitions cause a discernible decline, yet workflow
    knowledge still provides a notable improvement.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: (ii)-将不同格式的工作流知识融入可以显著促进代理规划，在回合级别和会话级别都取得明显的改进。跨场景的过渡会导致明显的下降，但工作流知识仍然提供了显著的提升。
- en: (iii)-The efficacy of different knowledge formats varies in different settings.
    The code format is less effective on weaker LLMs, potentially because the complex
    symbolic expressions impede information conveyance. The text format, on the other
    hand, continues to perform well on different LLMs.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: (iii)-不同知识格式在不同设置中的效果有所不同。代码格式在较弱的LLM上效果较差，可能是因为复杂的符号表达妨碍了信息传递。文本格式则在不同LLM上持续表现良好。
- en: '(iv)-Overall, the flowchart format generally produces the best performance.
    For static turn-level evaluations, it shows a notable advantage of 6.4%, 6.5%
    and 5.6% for F1 score of tool invocation on different LLMs. For session level,
    the flowchart demonstrates comparable performance to other formats for task completion
    evaluation, while it still performs the best for tool invocation. We speculate
    that such a lead stems from its organized and comprehensible nature, which enables
    LLMs to conveniently pinpoint the current state for better planning. More analyses
    are put to Appendix [B](#A2 "Appendix B Additional Experimental Results ‣ FlowBench:
    Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents").'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '(iv)-总体而言，流程图格式通常表现出最佳性能。在静态回合级评估中，它在不同LLM上表现出6.4%、6.5%和5.6%的工具调用F1分数显著优势。在会话级别，流程图在任务完成评估中表现与其他格式相当，但在工具调用方面仍表现最佳。我们推测这种优势源于其组织性和易理解性，使得LLM能够方便地确定当前状态以进行更好的规划。更多分析见附录[B](#A2
    "附录 B 额外实验结果 ‣ FlowBench: 重新审视和基准化基于LLM的工作流引导规划")。'
- en: '![Refer to caption](img/e0621542e3ac29caa174b8f75551593e.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e0621542e3ac29caa174b8f75551593e.png)'
- en: (a) Single-Scenario.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 单场景。
- en: '![Refer to caption](img/120834e205a34399a733668d46d4db89.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/120834e205a34399a733668d46d4db89.png)'
- en: (b) Cross-Scenario.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 跨场景。
- en: 'Figure 3: Domain-wise comparisons under session-level evaluation. Initials
    are adopted to denote domains.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：会话级评估下的领域级比较。使用首字母表示领域。
- en: 5.3 Further Analysis
  id: totrans-182
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 进一步分析
- en: Domain-wise Performance
  id: totrans-183
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 领域级性能
- en: 'We further investigate the performance distribution across domains. For experiments
    on GPT-4-Turbo, the domain-wise tool invocation F1-score is depicted in Figure [3](#S5.F3
    "Figure 3 ‣ 5.2 Main Results ‣ 5 Experiment ‣ FlowBench: Revisiting and Benchmarking
    Workflow-Guided Planning for LLM-based Agents"). We can see that workflow knowledge
    plays a more significant role in those expertise-demanding domains such as RPA,
    E-tailing Recommendation, and Travel, greatly compensating for the lack of inherent
    task-specific expertise in LLMs.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '我们进一步调查了在不同领域的性能分布。对于GPT-4-Turbo的实验，领域级工具调用F1分数如图[3](#S5.F3 "图 3 ‣ 5.2 主要结果
    ‣ 5 实验 ‣ FlowBench: 重新审视和基准化基于LLM的工作流引导规划")所示。我们可以看到，工作流知识在那些要求专业知识的领域，如RPA、电子零售推荐和旅行中扮演了更重要的角色，大大弥补了LLM在固有任务特定专业知识方面的不足。'
- en: Effect of Tool Information
  id: totrans-185
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 工具信息的影响
- en: 'As mentioned in Section [4.1](#S4.SS1 "4.1 Hierarchy of Benchmark Schema ‣
    4 FlowBench ‣ FlowBench: Revisiting and Benchmarking Workflow-Guided Planning
    for LLM-based Agents"), in our task-specific knowledge bases, alongside workflow-related
    knowledge that delineates work processes, there is also tool information describing
    the usage of different tools. Here, we further strip away the tool information
    from None variant and investigate this None w/o tool variant, from which descriptions
    of both tools and their parameters are completely eliminated (only tool and parameter
    names remain). As shown in Table [5](#S5.T5 "Table 5 ‣ Implementation Details.
    ‣ 5.1 Models and Baselines ‣ 5 Experiment ‣ FlowBench: Revisiting and Benchmarking
    Workflow-Guided Planning for LLM-based Agents"), such a variant experiences further
    degradation, especially for cross-scenario settings.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '如第[4.1](#S4.SS1 "4.1 基准架构层次 ‣ 4 FlowBench ‣ FlowBench: 回顾与基准测试基于LLM的代理的工作流引导规划")节中提到的，在我们的任务特定知识库中，除了描述工作过程的工作流相关知识外，还有描述不同工具使用的工具信息。在这里，我们进一步从None变体中剥离了工具信息，并调查了这个None
    w/o tool变体，其中完全消除了对工具及其参数的描述（仅保留工具和参数名称）。如表[5](#S5.T5 "表 5 ‣ 实现细节 ‣ 5.1 模型与基线
    ‣ 5 实验 ‣ FlowBench: 回顾与基准测试基于LLM的代理的工作流引导规划")所示，这种变体经历了进一步的退化，特别是在跨场景设置下。'
- en: Knowledge Formats Combination.
  id: totrans-187
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 知识格式组合。
- en: 'We further explored the impact of combining different formats of workflow knowledge.
    As shown in Table [5](#S5.T5 "Table 5 ‣ Implementation Details. ‣ 5.1 Models and
    Baselines ‣ 5 Experiment ‣ FlowBench: Revisiting and Benchmarking Workflow-Guided
    Planning for LLM-based Agents"), such a Ensemble variant is provided with text,
    code and flowchart formats simultaneously. It shows additional performance gains,
    which demonstrate that different formats of consistent knowledge can complement
    each other and get combined to boost the agent’s comprehension of workflows.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '我们进一步探讨了不同工作流知识格式组合的影响。如表[5](#S5.T5 "表 5 ‣ 实现细节 ‣ 5.1 模型与基线 ‣ 5 实验 ‣ FlowBench:
    回顾与基准测试基于LLM的代理的工作流引导规划")所示，这种组合变体同时提供了文本、代码和流程图格式。它显示出额外的性能提升，这表明不同格式的一致知识可以互补，并结合起来提高代理对工作流的理解。'
- en: 6 Conclusions
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: We introduce FlowBench, the first benchmark tailored for evaluating workflow-guided
    agent planning. We first revisit and formalize different workflow knowledge formats.
    Next, through extensive experiments on FlowBench, we find that flowchart formats
    achieve the best trade-off in terms of performance and user experience. The results
    further indicate that even the best-performing model, GPT-4o, fails to deliver
    satisfying results on challenging FlowBench. We hope that our work can provide
    meaningful insights to future research in the field of workflow-guided agent planning.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们引入了FlowBench，这是第一个专门用于评估工作流引导的代理规划的基准测试。我们首先回顾并规范了不同的工作流知识格式。接下来，通过对FlowBench的广泛实验，我们发现流程图格式在性能和用户体验方面达到了最佳的平衡。结果进一步表明，即使是表现最好的模型GPT-4o，在挑战性的FlowBench上也未能提供令人满意的结果。我们希望我们的工作能够为未来工作流引导代理规划领域的研究提供有意义的见解。
- en: Limitations
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 局限性
- en: We present FlowBench, a challenging benchmark for workflow-guided agent planning.
    Despite its comprehensiveness, this work has certain limitations that must be
    acknowledged. First, our benchmark covers three representative knowledge formats
    from varying abstraction levels, but may not cover all potential formats, which
    we intend to explore in future endeavors. Moreover, we adopt GPT-4-Turbo for automatic
    assessment in several metrics during evaluation, which increases the evaluation
    cost of using our FlowBench. Our extraction process of workflow knowledge also
    hinges on human efforts to ensure the quality, which is quite expensive and time-consuming.
    Future endeavors could explore the automation of workflow-related knowledge extraction.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们展示了FlowBench，这是一个具有挑战性的工作流引导代理规划基准测试。尽管其内容全面，但这项工作仍存在一些必须承认的局限性。首先，我们的基准覆盖了来自不同抽象级别的三种代表性知识格式，但可能未覆盖所有潜在的格式，我们计划在未来的工作中探索。此外，我们在评估过程中采用GPT-4-Turbo进行自动评估，这增加了使用我们FlowBench的评估成本。我们的工作流知识提取过程还依赖于人工努力以确保质量，这非常昂贵且耗时。未来的工作可以探索工作流相关知识提取的自动化。
- en: Ethics Statement
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 伦理声明
- en: In this paper, we introduce FlowBench, a highly challenging multi-domain benchmark
    for evaluation workflow-guided agent planning abilities. During our benchmark
    construction, our human annotators are instructed to filter out data potentially
    triggering ethical concerns, including offensive content or social prejudices.
    Even though the organized workflow knowledge and the ground-truth sessions have
    undergone filtering and verification, our simulated session-level evaluation still
    incorporates LLMs for simulating real-time interaction. Such API-based LLM simulators
    may exhibit bias and unfairness. We advise potential users to first apply bias
    reduction and correction methods to eliminate biased simulated sessions during
    evaluation, thereby enhancing fairness and ethical standards. We will release
    our benchmark and evaluation scripts to foster innovation and aid the development
    of future research.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们介绍了 FlowBench，这是一个高度挑战性的多领域基准，用于评估基于工作流的代理计划能力。在基准构建过程中，我们的人类注释员被指示过滤可能引发伦理问题的数据，包括冒犯性内容或社会偏见。尽管整理的工作流知识和真实数据会经过过滤和验证，我们的模拟会话级评估仍然使用
    LLMs 来模拟实时互动。这种基于 API 的 LLM 模拟器可能会表现出偏见和不公平。我们建议潜在用户首先应用偏见减少和修正方法，以消除评估期间的偏见模拟会话，从而提高公平性和伦理标准。我们将发布我们的基准和评估脚本，以促进创新并帮助未来研究的发展。
- en: References
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Hel (2024) 2024. [Hello GPT-4o](https://openai.com/index/hello-gpt-4o/).
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hel (2024) 2024. [Hello GPT-4o](https://openai.com/index/hello-gpt-4o/)。
- en: 'Agrawal et al. (2023) Garima Agrawal, Tharindu Kumarage, Zeyad Alghami, and
    Huan Liu. 2023. [Can knowledge graphs reduce hallucinations in llms? : A survey](https://doi.org/10.48550/ARXIV.2311.07914).
    *CoRR*, abs/2311.07914.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Agrawal 等人 (2023) Garima Agrawal、Tharindu Kumarage、Zeyad Alghami 和 Huan Liu.
    2023. [知识图谱能否减少 LLMs 的幻觉？：一项调查](https://doi.org/10.48550/ARXIV.2311.07914)。*CoRR*，abs/2311.07914。
- en: Baek et al. (2024) Jinheon Baek, Nirupama Chandrasekaran, Silviu Cucerzan, Allen
    Herring, and Sujay Kumar Jauhar. 2024. [Knowledge-augmented large language models
    for personalized contextual query suggestion](https://doi.org/10.1145/3589334.3645404).
    In *Proceedings of the ACM on Web Conference 2024, WWW 2024, Singapore, May 13-17,
    2024*, pages 3355–3366\. ACM.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Baek 等人 (2024) Jinheon Baek、Nirupama Chandrasekaran、Silviu Cucerzan、Allen Herring
    和 Sujay Kumar Jauhar. 2024. [知识增强的大型语言模型用于个性化上下文查询建议](https://doi.org/10.1145/3589334.3645404)。在
    *ACM Web 会议 2024，WWW 2024，新加坡，2024年5月13-17日*，第 3355–3366 页。ACM。
- en: 'Chen et al. (2023) Guangyao Chen, Siwei Dong, Yu Shu, Ge Zhang, Jaward Sesay,
    Börje F. Karlsson, Jie Fu, and Yemin Shi. 2023. [Autoagents: A framework for automatic
    agent generation](https://doi.org/10.48550/ARXIV.2309.17288). *CoRR*, abs/2309.17288.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chen 等人 (2023) Guangyao Chen、Siwei Dong、Yu Shu、Ge Zhang、Jaward Sesay、Börje
    F. Karlsson、Jie Fu 和 Yemin Shi. 2023. [Autoagents: 自动代理生成框架](https://doi.org/10.48550/ARXIV.2309.17288)。*CoRR*，abs/2309.17288。'
- en: 'Chen et al. (2024) Zehui Chen, Weihua Du, Wenwei Zhang, Kuikun Liu, Jiangning
    Liu, Miao Zheng, Jingming Zhuo, Songyang Zhang, Dahua Lin, Kai Chen, and Feng
    Zhao. 2024. [T-eval: Evaluating the tool utilization capability of large language
    models step by step](https://arxiv.org/abs/2312.14033). *Preprint*, arXiv:2312.14033.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chen 等人 (2024) Zehui Chen、Weihua Du、Wenwei Zhang、Kuikun Liu、Jiangning Liu、Miao
    Zheng、Jingming Zhuo、Songyang Zhang、Dahua Lin、Kai Chen 和 Feng Zhao. 2024. [T-eval:
    逐步评估大型语言模型的工具利用能力](https://arxiv.org/abs/2312.14033)。*预印本*，arXiv:2312.14033。'
- en: Chhikara et al. (2023) Prateek Chhikara, Jiarui Zhang, Filip Ilievski, Jonathan
    Francis, and Kaixin Ma. 2023. [Knowledge-enhanced agents for interactive text
    games](https://doi.org/10.1145/3587259.3627561). In *Proceedings of the 12th Knowledge
    Capture Conference 2023, K-CAP 2023, Pensacola, FL, USA, December 5-7, 2023*,
    pages 157–165\. ACM.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chhikara 等人 (2023) Prateek Chhikara、Jiarui Zhang、Filip Ilievski、Jonathan Francis
    和 Kaixin Ma. 2023. [用于互动文本游戏的知识增强代理](https://doi.org/10.1145/3587259.3627561)。在
    *第12届知识捕捉会议 2023，K-CAP 2023，佛罗里达州彭萨科拉，2023年12月5-7日*，第 157–165 页。ACM。
- en: 'Deng et al. (2023) Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samual Stevens,
    Boshi Wang, Huan Sun, and Yu Su. 2023. [Mind2web: Towards a generalist agent for
    the web](http://papers.nips.cc/paper_files/paper/2023/hash/5950bf290a1570ea401bf98882128160-Abstract-Datasets_and_Benchmarks.html).
    In *NeurIPS*.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Deng 等人 (2023) Xiang Deng、Yu Gu、Boyuan Zheng、Shijie Chen、Samual Stevens、Boshi
    Wang、Huan Sun 和 Yu Su. 2023. [Mind2web: 面向网络的通用代理](http://papers.nips.cc/paper_files/paper/2023/hash/5950bf290a1570ea401bf98882128160-Abstract-Datasets_and_Benchmarks.html)。在
    *NeurIPS*。'
- en: 'Gao et al. (2023) Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan,
    Yuxi Bi, Yi Dai, Jiawei Sun, Qianyu Guo, Meng Wang, and Haofen Wang. 2023. [Retrieval-augmented
    generation for large language models: A survey](https://doi.org/10.48550/ARXIV.2312.10997).
    *CoRR*, abs/2312.10997.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao et al. (2023) 云帆·高、云雄、辛瑜·高、康翔·贾、金柳·潘、玉溪·毕、易·戴、家伟·孙、倩瑜·郭、孟·王和浩奋·王。2023年。[用于大语言模型的检索增强生成：综述](https://doi.org/10.48550/ARXIV.2312.10997)。*CoRR*，abs/2312.10997。
- en: 'Hong et al. (2023) Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin
    Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu
    Ran, Lingfeng Xiao, and Chenglin Wu. 2023. [Metagpt: Meta programming for multi-agent
    collaborative framework](https://doi.org/10.48550/ARXIV.2308.00352). *CoRR*, abs/2308.00352.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hong et al. (2023) 思瑞·洪、夏吴·郑、乔纳森·陈、宇恒·程、金林·王、策耀·张、子力·王、史蒂文·卡·兴·游、紫娟·林、丽阳·周、晨瑜·冉、灵锋·肖和成林·吴。2023年。[MetaGPT：多代理协作框架的元编程](https://doi.org/10.48550/ARXIV.2308.00352)。*CoRR*，abs/2308.00352。
- en: 'Huang et al. (2022) Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch.
    2022. [Language models as zero-shot planners: Extracting actionable knowledge
    for embodied agents](https://proceedings.mlr.press/v162/huang22a.html). In *International
    Conference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland,
    USA*, volume 162 of *Proceedings of Machine Learning Research*, pages 9118–9147\.
    PMLR.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang et al. (2022) 文龙·黄、彼得·阿贝尔、迪帕克·帕塔克和伊戈尔·莫达奇。2022年。[语言模型作为零-shot 规划者：为具身体代理提取可操作的知识](https://proceedings.mlr.press/v162/huang22a.html)。在*国际机器学习会议，ICML
    2022，2022年7月17-23日，马里兰州巴尔的摩，美国*，第162卷*机器学习研究论文集*，第9118–9147页。PMLR。
- en: 'Jiang et al. (2024) Jinhao Jiang, Kun Zhou, Wayne Xin Zhao, Yang Song, Chen
    Zhu, Hengshu Zhu, and Ji-Rong Wen. 2024. [Kg-agent: An efficient autonomous agent
    framework for complex reasoning over knowledge graph](https://doi.org/10.48550/ARXIV.2402.11163).
    *CoRR*, abs/2402.11163.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang et al. (2024) 金浩·姜、昆·周、韦恩·辛·赵、杨·宋、陈·朱、恒树·朱和季荣·温。2024年。[Kg-agent：一个高效的自主代理框架，用于在知识图谱上进行复杂推理](https://doi.org/10.48550/ARXIV.2402.11163)。*CoRR*，abs/2402.11163。
- en: 'Koupaee and Wang (2018) Mahnaz Koupaee and William Yang Wang. 2018. [Wikihow:
    A large scale text summarization dataset](https://arxiv.org/abs/1810.09305). *CoRR*,
    abs/1810.09305.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Koupaee and Wang (2018) 玛赫娜兹·库帕伊和威廉·杨·王。2018年。[Wikihow：一个大规模文本摘要数据集](https://arxiv.org/abs/1810.09305)。*CoRR*，abs/1810.09305。
- en: Liu et al. (2023a) Junling Liu, Peilin Zhou, Yining Hua, Dading Chong, Zhongyu
    Tian, Andrew Liu, Helin Wang, Chenyu You, Zhenhua Guo, Lei Zhu, and Michael Lingzhi
    Li. 2023a. [Benchmarking large language models on cmexam - A comprehensive chinese
    medical exam dataset](http://papers.nips.cc/paper_files/paper/2023/hash/a48ad12d588c597f4725a8b84af647b5-Abstract-Datasets_and_Benchmarks.html).
    In *NeurIPS*.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2023a) 俊凌·刘、佩琳·周、宜宁·华、大定·钟、钟宇·田、安德鲁·刘、赫林·王、晨瑜·游、振华·郭、磊·朱和迈克尔·灵智·李。2023a。[对cmexam的大型语言模型进行基准测试
    - 一个综合的中文医学考试数据集](http://papers.nips.cc/paper_files/paper/2023/hash/a48ad12d588c597f4725a8b84af647b5-Abstract-Datasets_and_Benchmarks.html)。在*NeurIPS*。
- en: 'Liu et al. (2023b) Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu
    Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng,
    Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan
    Sun, Minlie Huang, Yuxiao Dong, and Jie Tang. 2023b. [Agentbench: Evaluating llms
    as agents](https://doi.org/10.48550/ARXIV.2308.03688). *CoRR*, abs/2308.03688.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2023b) 晓·刘、浩·余、汉辰·张、义凡·徐、轩宇·雷、寒瑜·赖、余·顾、航亮·丁、凯文·门、可娟·杨、书丹·张、向·邓、奥涵·曾、正晓·杜、晨辉·张、盛·沈、天俊·张、余·苏、欢·孙、敏利·黄、玉晓·董和杰·唐。2023b。[AgentBench：将LLMs评估为代理](https://doi.org/10.48550/ARXIV.2308.03688)。*CoRR*，abs/2308.03688。
- en: Liu et al. (2024) Xiaoze Liu, Feijie Wu, Tianyang Xu, Zhuo Chen, Yichi Zhang,
    Xiaoqian Wang, and Jing Gao. 2024. [Evaluating the factuality of large language
    models using large-scale knowledge graphs](https://doi.org/10.48550/ARXIV.2404.00942).
    *CoRR*, abs/2404.00942.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2024) 晓泽·刘、飞杰·吴、天阳·徐、卓陈、义驰·张、晓倩·王和静·高。2024年。[使用大规模知识图谱评估大语言模型的真实性](https://doi.org/10.48550/ARXIV.2404.00942)。*CoRR*，abs/2404.00942。
- en: 'Ma et al. (2024) Chang Ma, Junlei Zhang, Zhihao Zhu, Cheng Yang, Yujiu Yang,
    Yaohui Jin, Zhenzhong Lan, Lingpeng Kong, and Junxian He. 2024. [Agentboard: An
    analytical evaluation board of multi-turn LLM agents](https://doi.org/10.48550/ARXIV.2401.13178).
    *CoRR*, abs/2401.13178.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ma et al. (2024) 常·马、俊磊·张、志豪·朱、成·杨、宇久·杨、耀辉·金、震中·蓝、灵鹏·孔和俊贤·贺。2024年。[AgentBoard：一个多轮LLM代理的分析评估板](https://doi.org/10.48550/ARXIV.2401.13178)。*CoRR*，abs/2401.13178。
- en: 'Mosig et al. (2020) Johannes E. M. Mosig, Shikib Mehri, and Thomas Kober. 2020.
    [STAR: A schema-guided dialog dataset for transfer learning](https://arxiv.org/abs/2010.11853).
    *CoRR*, abs/2010.11853.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Mosig等人（2020）Johannes E. M. Mosig、Shikib Mehri和Thomas Kober。2020年。[STAR: A
    schema-guided dialog dataset for transfer learning](https://arxiv.org/abs/2010.11853)。*CoRR*，abs/2010.11853。'
- en: OpenAI (2022) OpenAI. 2022. [Chatgpt](https://openai.com/blog/chatgpt).
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI（2022）OpenAI。2022年。[Chatgpt](https://openai.com/blog/chatgpt)。
- en: OpenAI (2023a) OpenAI. 2023a. [GPT-4 technical report](https://doi.org/10.48550/ARXIV.2303.08774).
    *CoRR*, abs/2303.08774.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI（2023a）OpenAI。2023a年。[GPT-4技术报告](https://doi.org/10.48550/ARXIV.2303.08774)。*CoRR*，abs/2303.08774。
- en: OpenAI (2023b) OpenAI. 2023b. Gpt-4 technical report. *arXiv preprint arXiv:2303.08774*.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI（2023b）OpenAI。2023b年。Gpt-4技术报告。*arXiv预印本 arXiv:2303.08774*。
- en: 'Patil et al. (2023) Shishir G. Patil, Tianjun Zhang, Xin Wang, and Joseph E.
    Gonzalez. 2023. [Gorilla: Large language model connected with massive apis](https://doi.org/10.48550/ARXIV.2305.15334).
    *CoRR*, abs/2305.15334.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Patil等人（2023）Shishir G. Patil、Tianjun Zhang、Xin Wang和Joseph E. Gonzalez。2023年。[Gorilla:
    Large language model connected with massive apis](https://doi.org/10.48550/ARXIV.2305.15334)。*CoRR*，abs/2305.15334。'
- en: Qian et al. (2023) Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su,
    Juyuan Xu, Zhiyuan Liu, and Maosong Sun. 2023. [Communicative agents for software
    development](https://doi.org/10.48550/ARXIV.2307.07924). *CoRR*, abs/2307.07924.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qian等人（2023）Chen Qian、Xin Cong、Cheng Yang、Weize Chen、Yusheng Su、Juyuan Xu、Zhiyuan
    Liu和Maosong Sun。2023年。[Communicative agents for software development](https://doi.org/10.48550/ARXIV.2307.07924)。*CoRR*，abs/2307.07924。
- en: 'Qin et al. (2023) Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan,
    Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Runchu Tian,
    Ruobing Xie, Jie Zhou, Mark Gerstein, Dahai Li, Zhiyuan Liu, and Maosong Sun.
    2023. [Toolllm: Facilitating large language models to master 16000+ real-world
    apis](https://doi.org/10.48550/ARXIV.2307.16789). *CoRR*, abs/2307.16789.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Qin等人（2023）Yujia Qin、Shihao Liang、Yining Ye、Kunlun Zhu、Lan Yan、Yaxi Lu、Yankai
    Lin、Xin Cong、Xiangru Tang、Bill Qian、Sihan Zhao、Runchu Tian、Ruobing Xie、Jie Zhou、Mark
    Gerstein、Dahai Li、Zhiyuan Liu和Maosong Sun。2023年。[Toolllm: Facilitating large language
    models to master 16000+ real-world apis](https://doi.org/10.48550/ARXIV.2307.16789)。*CoRR*，abs/2307.16789。'
- en: 'Schick et al. (2023) Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu,
    Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom.
    2023. [Toolformer: Language models can teach themselves to use tools](http://papers.nips.cc/paper_files/paper/2023/hash/d842425e4bf79ba039352da0f658a906-Abstract-Conference.html).
    In *NeurIPS*.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Schick等人（2023）Timo Schick、Jane Dwivedi-Yu、Roberto Dessì、Roberta Raileanu、Maria
    Lomeli、Eric Hambro、Luke Zettlemoyer、Nicola Cancedda和Thomas Scialom。2023年。[Toolformer:
    Language models can teach themselves to use tools](http://papers.nips.cc/paper_files/paper/2023/hash/d842425e4bf79ba039352da0f658a906-Abstract-Conference.html)。见于*NeurIPS*。'
- en: 'Shi et al. (2023) Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich
    James, Mike Lewis, Luke Zettlemoyer, and Wen-tau Yih. 2023. [REPLUG: retrieval-augmented
    black-box language models](https://doi.org/10.48550/ARXIV.2301.12652). *CoRR*,
    abs/2301.12652.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shi等人（2023）魏佳·石、Sewon Min、Michihiro Yasunaga、Minjoon Seo、Rich James、Mike Lewis、Luke
    Zettlemoyer和Wen-tau Yih。2023年。[REPLUG: retrieval-augmented black-box language
    models](https://doi.org/10.48550/ARXIV.2301.12652)。*CoRR*，abs/2301.12652。'
- en: 'Touvron et al. (2023) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
    Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal,
    Eric Hambro, Faisal Azhar, Aurélien Rodriguez, Armand Joulin, Edouard Grave, and
    Guillaume Lample. 2023. [Llama: Open and efficient foundation language models](https://doi.org/10.48550/ARXIV.2302.13971).
    *CoRR*, abs/2302.13971.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Touvron等人（2023）Hugo Touvron、Thibaut Lavril、Gautier Izacard、Xavier Martinet、Marie-Anne
    Lachaux、Timothée Lacroix、Baptiste Rozière、Naman Goyal、Eric Hambro、Faisal Azhar、Aurélien
    Rodriguez、Armand Joulin、Edouard Grave和Guillaume Lample。2023年。[Llama: Open and
    efficient foundation language models](https://doi.org/10.48550/ARXIV.2302.13971)。*CoRR*，abs/2302.13971。'
- en: 'Valmeekam et al. (2023) Karthik Valmeekam, Matthew Marquez, Alberto Olmo Hernandez,
    Sarath Sreedharan, and Subbarao Kambhampati. 2023. [Planbench: An extensible benchmark
    for evaluating large language models on planning and reasoning about change](http://papers.nips.cc/paper_files/paper/2023/hash/7a92bcdede88c7afd108072faf5485c8-Abstract-Datasets_and_Benchmarks.html).
    In *NeurIPS*.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Valmeekam等人（2023）Karthik Valmeekam、Matthew Marquez、Alberto Olmo Hernandez、Sarath
    Sreedharan和Subbarao Kambhampati。2023年。[Planbench: An extensible benchmark for
    evaluating large language models on planning and reasoning about change](http://papers.nips.cc/paper_files/paper/2023/hash/7a92bcdede88c7afd108072faf5485c8-Abstract-Datasets_and_Benchmarks.html)。见于*NeurIPS*。'
- en: Wang et al. (2024) Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
    Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei
    Wei, and Jirong Wen. 2024. [A survey on large language model based autonomous
    agents](https://doi.org/10.1007/S11704-024-40231-1). *Frontiers Comput. Sci.*,
    18(6):186345.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 (2024) Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
    Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei
    Wei, 和 Jirong Wen. 2024. [基于大型语言模型的自主体调查](https://doi.org/10.1007/S11704-024-40231-1).
    *前沿计算机科学*, 18(6):186345.
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian
    Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and Denny Zhou. 2022. [Chain-of-thought
    prompting elicits reasoning in large language models](http://papers.nips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html).
    In *NeurIPS*.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等人 (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian
    Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, 和 Denny Zhou. 2022. [链式思维提示引发大型语言模型中的推理](http://papers.nips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html).
    见 *NeurIPS*.
- en: 'Wu et al. (2023) Yue Wu, Xuan Tang, Tom M. Mitchell, and Yuanzhi Li. 2023.
    [Smartplay : A benchmark for llms as intelligent agents](https://doi.org/10.48550/ARXIV.2310.01557).
    *CoRR*, abs/2310.01557.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wu 等人 (2023) Yue Wu, Xuan Tang, Tom M. Mitchell, 和 Yuanzhi Li. 2023. [Smartplay:
    一个针对LLMs作为智能代理的基准测试](https://doi.org/10.48550/ARXIV.2310.01557). *CoRR*, abs/2310.01557.'
- en: 'Xie et al. (2024) Jian Xie, Kai Zhang, Jiangjie Chen, Tinghui Zhu, Renze Lou,
    Yuandong Tian, Yanghua Xiao, and Yu Su. 2024. [Travelplanner: A benchmark for
    real-world planning with language agents](https://doi.org/10.48550/ARXIV.2402.01622).
    *CoRR*, abs/2402.01622.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Xie 等人 (2024) Jian Xie, Kai Zhang, Jiangjie Chen, Tinghui Zhu, Renze Lou, Yuandong
    Tian, Yanghua Xiao, 和 Yu Su. 2024. [Travelplanner: 一个针对语言代理的真实世界规划基准测试](https://doi.org/10.48550/ARXIV.2402.01622).
    *CoRR*, abs/2402.01622.'
- en: 'Xu et al. (2024) Yao Xu, Shizhu He, Jiabei Chen, Zihao Wang, Yangqiu Song,
    Hanghang Tong, Kang Liu, and Jun Zhao. 2024. [Generate-on-graph: Treat LLM as
    both agent and KG in incomplete knowledge graph question answering](https://doi.org/10.48550/ARXIV.2404.14741).
    *CoRR*, abs/2404.14741.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Xu 等人 (2024) Yao Xu, Shizhu He, Jiabei Chen, Zihao Wang, Yangqiu Song, Hanghang
    Tong, Kang Liu, 和 Jun Zhao. 2024. [Generate-on-graph: 将LLM视为代理和KG，用于不完整知识图谱问答](https://doi.org/10.48550/ARXIV.2404.14741).
    *CoRR*, abs/2404.14741.'
- en: 'Yang et al. (2024a) Ke Yang, Jiateng Liu, John Wu, Chaoqi Yang, Yi R. Fung,
    Sha Li, Zixuan Huang, Xu Cao, Xingyao Wang, Yiquan Wang, Heng Ji, and Chengxiang
    Zhai. 2024a. [If LLM is the wizard, then code is the wand: A survey on how code
    empowers large language models to serve as intelligent agents](https://doi.org/10.48550/ARXIV.2401.00812).
    *CoRR*, abs/2401.00812.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人 (2024a) Ke Yang, Jiateng Liu, John Wu, Chaoqi Yang, Yi R. Fung, Sha
    Li, Zixuan Huang, Xu Cao, Xingyao Wang, Yiquan Wang, Heng Ji, 和 Chengxiang Zhai.
    2024a. [如果LLM是魔法师，那么代码就是魔杖：关于代码如何赋能大型语言模型成为智能代理的调查](https://doi.org/10.48550/ARXIV.2401.00812).
    *CoRR*, abs/2401.00812.
- en: 'Yang et al. (2024b) Songhua Yang, Hanjie Zhao, Senbin Zhu, Guangyu Zhou, Hongfei
    Xu, Yuxiang Jia, and Hongying Zan. 2024b. [Zhongjing: Enhancing the chinese medical
    capabilities of large language model through expert feedback and real-world multi-turn
    dialogue](https://doi.org/10.1609/AAAI.V38I17.29907). In *AAAI*, pages 19368–19376\.
    AAAI Press.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yang 等人 (2024b) Songhua Yang, Hanjie Zhao, Senbin Zhu, Guangyu Zhou, Hongfei
    Xu, Yuxiang Jia, 和 Hongying Zan. 2024b. [Zhongjing: 通过专家反馈和真实世界的多轮对话增强大型语言模型的中文医学能力](https://doi.org/10.1609/AAAI.V38I17.29907).
    见 *AAAI*, 页码 19368–19376\. AAAI出版社.'
- en: 'Yao et al. (2023a) Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths,
    Yuan Cao, and Karthik Narasimhan. 2023a. [Tree of thoughts: Deliberate problem
    solving with large language models](http://papers.nips.cc/paper_files/paper/2023/hash/271db9922b8d1f4dd7aaef84ed5ac703-Abstract-Conference.html).
    In *NeurIPS*.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao 等人 (2023a) Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths,
    Yuan Cao, 和 Karthik Narasimhan. 2023a. [思维树：通过大型语言模型进行深思熟虑的问题解决](http://papers.nips.cc/paper_files/paper/2023/hash/271db9922b8d1f4dd7aaef84ed5ac703-Abstract-Conference.html).
    见 *NeurIPS*.
- en: 'Yao et al. (2023b) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik R. Narasimhan, and Yuan Cao. 2023b. [React: Synergizing reasoning and
    acting in language models](https://openreview.net/pdf?id=WE_vluYUL-X). In *ICLR*.
    OpenReview.net.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yao 等人 (2023b) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik
    R. Narasimhan, 和 Yuan Cao. 2023b. [React: 在语言模型中协同推理和行动](https://openreview.net/pdf?id=WE_vluYUL-X).
    见 *ICLR*. OpenReview.net.'
- en: 'Ye et al. (2023) Yining Ye, Xin Cong, Shizuo Tian, Jiannan Cao, Hao Wang, Yujia
    Qin, Yaxi Lu, Heyang Yu, Huadong Wang, Yankai Lin, Zhiyuan Liu, and Maosong Sun.
    2023. [Proagent: From robotic process automation to agentic process automation](https://doi.org/10.48550/ARXIV.2311.10751).
    *CoRR*, abs/2311.10751.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ye et al. (2023) Yining Ye, Xin Cong, Shizuo Tian, Jiannan Cao, Hao Wang, Yujia
    Qin, Yaxi Lu, Heyang Yu, Huadong Wang, Yankai Lin, Zhiyuan Liu, and Maosong Sun.
    2023. [Proagent: 从机器人流程自动化到代理过程自动化](https://doi.org/10.48550/ARXIV.2311.10751).
    *CoRR*, abs/2311.10751.'
- en: (38) Zapier. [Zapier | automation makes you move forward.](https://zapier.com/)
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (38) Zapier. [Zapier | 自动化让你不断前进。](https://zapier.com/)
- en: 'Zeng et al. (2023) Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai,
    Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan
    Ma, Yufei Xue, Jidong Zhai, Wenguang Chen, Zhiyuan Liu, Peng Zhang, Yuxiao Dong,
    and Jie Tang. 2023. [GLM-130B: an open bilingual pre-trained model](https://openreview.net/pdf?id=-Aw0rrrPUF).
    In *ICLR*. OpenReview.net.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zeng et al. (2023) Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai,
    Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan
    Ma, Yufei Xue, Jidong Zhai, Wenguang Chen, Zhiyuan Liu, Peng Zhang, Yuxiao Dong,
    and Jie Tang. 2023. [GLM-130B: 一种开放的双语预训练模型](https://openreview.net/pdf?id=-Aw0rrrPUF).
    在 *ICLR*. OpenReview.net.'
- en: 'Zhang et al. (2023) Hongbo Zhang, Junying Chen, Feng Jiang, Fei Yu, Zhihong
    Chen, Guiming Chen, Jianquan Li, Xiangbo Wu, Zhang Zhiyi, Qingying Xiao, Xiang
    Wan, Benyou Wang, and Haizhou Li. 2023. [HuatuoGPT, towards taming language model
    to be a doctor](https://doi.org/10.18653/v1/2023.findings-emnlp.725). In *Findings
    of the Association for Computational Linguistics: EMNLP 2023*, pages 10859–10885,
    Singapore. Association for Computational Linguistics.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang et al. (2023) Hongbo Zhang, Junying Chen, Feng Jiang, Fei Yu, Zhihong
    Chen, Guiming Chen, Jianquan Li, Xiangbo Wu, Zhang Zhiyi, Qingying Xiao, Xiang
    Wan, Benyou Wang, and Haizhou Li. 2023. [HuatuoGPT，旨在驯化语言模型成为医生](https://doi.org/10.18653/v1/2023.findings-emnlp.725).
    在 *Findings of the Association for Computational Linguistics: EMNLP 2023*，页10859–10885，新加坡。计算语言学协会。'
- en: 'Zhou et al. (2023) Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo,
    Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, and Graham
    Neubig. 2023. [Webarena: A realistic web environment for building autonomous agents](https://doi.org/10.48550/ARXIV.2307.13854).
    *CoRR*, abs/2307.13854.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhou et al. (2023) Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo,
    Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, and Graham
    Neubig. 2023. [Webarena: 构建自主智能体的现实网络环境](https://doi.org/10.48550/ARXIV.2307.13854).
    *CoRR*, abs/2307.13854.'
- en: 'Zhu et al. (2024) Yuqi Zhu, Shuofei Qiao, Yixin Ou, Shumin Deng, Ningyu Zhang,
    Shiwei Lyu, Yue Shen, Lei Liang, Jinjie Gu, and Huajun Chen. 2024. [Knowagent:
    Knowledge-augmented planning for llm-based agents](https://doi.org/10.48550/ARXIV.2403.03101).
    *CoRR*, abs/2403.03101.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhu et al. (2024) Yuqi Zhu, Shuofei Qiao, Yixin Ou, Shumin Deng, Ningyu Zhang,
    Shiwei Lyu, Yue Shen, Lei Liang, Jinjie Gu, and Huajun Chen. 2024. [Knowagent:
    知识增强的基于LLM的智能体规划](https://doi.org/10.48550/ARXIV.2403.03101). *CoRR*, abs/2403.03101.'
- en: '| Domain | Roles | Scenarios |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| Domain | Roles | Scenarios |'
- en: '| Customer Service | restaurant_waiter | Restaurant Search, Restaurant Booking
    |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| Customer Service | restaurant_waiter | 餐厅搜索，餐厅预订 |'
- en: '| hotel_reception | Hotel Search, Hotel Booking, Hotel Room Service |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| hotel_reception | 酒店搜索，酒店预订，酒店客房服务 |'
- en: '| apartment_manager | Apartment Search, Schedule a Viewing, Bill Inquiry, Rent
    Payment |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| apartment_manager | 公寓搜索，安排看房，账单查询，租金支付 |'
- en: '| gas_equipment_service | Gas Repairs, Gas Bill Payment, Gas Interruption Feedback
    |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| gas_equipment_service | 燃气维修，燃气账单支付，燃气中断反馈 |'
- en: '| Personal Assistant | medical_consultant | Schedule a Medical Consultation,
    Obtain Diagnostic Results |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| Personal Assistant | medical_consultant | 安排医疗咨询，获取诊断结果 |'
- en: '| meeting_arrangement | Meeting Initiation, Meeting Reschedule |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| meeting_arrangement | 会议发起，会议重新安排 |'
- en: '| financial_assistant | Currency Exchange, Withdrawal Appointments, Balance
    Inquiry |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| financial_assistant | 货币兑换，取款预约，余额查询 |'
- en: '| E-tailing Recommandation | online_shopping_support | Product Search, Cart
    Management, Order Processing |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| E-tailing Recommandation | online_shopping_support | 产品搜索，购物车管理，订单处理 |'
- en: '| computer_store_sale | Laptop Recommendations, Computer Maintenance |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| computer_store_sale | 笔记本电脑推荐，电脑维护 |'
- en: '| Travel&Transportation | ride_service | Ride Booking, Ride Inquiry |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| Travel&Transportation | ride_service | 乘车预订，乘车查询 |'
- en: '| driving_service | Driving Consultation, Cancel Reservation, Modify Reservation
    |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| driving_service | 驾驶咨询，取消预订，修改预订 |'
- en: '| flight_inquiry | Flight Information Search, Flight Booking |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| flight_inquiry | 航班信息查询，航班预订 |'
- en: '| travel_assistant | Travel Guidance, Weather Inquiry |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| travel_assistant | 旅行指导，天气查询 |'
- en: '| Logistics Solutions | express_support | Express Delivery, Express Tracking
    Inquiry |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| Logistics Solutions | express_support | 快递服务，快递跟踪查询 |'
- en: '| moving_service | Moving Service Appointment, Insurance Claim |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| moving_service | 搬家服务预约、保险索赔 |'
- en: '| food_delivery_service | Online Questionnaires, Get Food Voucher |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| food_delivery_service | 在线问卷、领取餐券 |'
- en: '| Robotic Process Automation | invoice_management | Invoice Administration,
    Invoice Reimbursement |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| Robotic Process Automation | invoice_management | 发票管理、发票报销 |'
- en: '| mail_administration | Mail transmission, Mail Response |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| mail_administration | 邮件传输、邮件回复 |'
- en: '| printing_service | Document Printing, Printing State Notification |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| printing_service | 文档打印、打印状态通知 |'
- en: '| attendance_arrangement | Attendance Anomaly Detection, Shift Handover |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| attendance_arrangement | 出勤异常检测、班次交接 |'
- en: '| seal_management | Seal Request, Seal State Notification |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| seal_management | 印章申请、印章状态通知 |'
- en: '| workstation_applicant | Workstation Replacement, Workstation Change Directive
    |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| workstation_applicant | 工作站更换、工作站更改指令 |'
- en: 'Table 6: Detailed Scenarios of different domains and roles for FlowBench.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6：FlowBench 不同领域和角色的详细场景。
- en: Appendix A Additional Benchmark Details
  id: totrans-262
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 额外基准详情
- en: A.1 Entire List of Roles and Scenarios
  id: totrans-263
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 角色和场景完整列表
- en: 'As mentioned in Section [4.2](#S4.SS2 "4.2 Benchmark Construction ‣ 4 FlowBench
    ‣ FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based
    Agents"), we collect our tasks from six separate domains, with each domain encompassing
    different roles and scenarios. Here we provide the entire of roles and scenarios
    within each domain, as shown in Table [6](#A0.T6 "Table 6 ‣ FlowBench: Revisiting
    and Benchmarking Workflow-Guided Planning for LLM-based Agents").'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '如第[4.2](#S4.SS2 "4.2 基准构建 ‣ 4 FlowBench ‣ FlowBench: 重新审视和基准化面向 LLM 的工作流规划")节中提到，我们从六个独立领域收集了任务，每个领域包含不同的角色和场景。这里提供了每个领域内所有角色和场景，如表[6](#A0.T6
    "表 6 ‣ FlowBench: 重新审视和基准化面向 LLM 的工作流规划")所示。'
- en: A.2 Entire Benchmark Statistics
  id: totrans-265
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 基准统计完整列表
- en: 'Here we further provide the entire benchmark statistics in Table [8](#A2.T8
    "Table 8 ‣ B.2 Analysis of Failure Causes ‣ Appendix B Additional Experimental
    Results ‣ FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for
    LLM-based Agents"), including the number of sessions and turns under the different
    settings of single-scenario and cross-scenario respectively.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '这里我们进一步提供了表[8](#A2.T8 "表 8 ‣ B.2 失败原因分析 ‣ 附录 B 额外实验结果 ‣ FlowBench: 重新审视和基准化面向
    LLM 的工作流规划")中的所有基准统计，包括在单场景和跨场景不同设置下的会话和轮次数量。'
- en: A.3 Benchmark Construction Cost
  id: totrans-267
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.3 基准构建成本
- en: We further provide the rough cost of benchmark construction. Before quality
    filtering, we manually constructed a total of 58 scenarios and 730 dialogues.
    The annotation cost is $17.23 per scenario and $9.44 per dialogue, amounting to
    a total annotation cost of $7,892.60\. Additionally, the cost for generating multi-turn
    dialogue requests using GPT-4-Turbo is approximately $1,000, bringing the total
    cost to around $8,892.60.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进一步提供了基准构建的粗略成本。在质量筛选之前，我们手动构建了总共 58 个场景和 730 个对话。标注成本为每个场景 $17.23，每个对话 $9.44，总标注成本为
    $7,892.60。此外，使用 GPT-4-Turbo 生成多轮对话请求的成本约为 $1,000，使总成本达到大约 $8,892.60。
- en: A.4 Formatting Standards
  id: totrans-269
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.4 格式标准
- en: In the process of organizing workflow knowledge, we need to convert the text-based
    natural language documents of workflow knowledge into code and flowchart formats.
    Different standard requirements are maintained for them. (i)-For code format,
    we adopt Python-style pseudo code, mandating that various action steps be delineated
    within distinct functions. The variable names and parameters must correspond to
    the workflow implications from text documents. For commands that are difficult
    to express through code, minimal commenting is permitted for clarification. (ii)-For
    flowchart format, we utilize Markdown Mermaid syntax for its visual operation
    capabilities. In the flowcharts, nodes correspond to distinct states, outlining
    within them the workflow directives applicable in those states, which entails
    rules of actions and responses. Edges represent the possible movements between
    nodes, with transition conditions based on user intents or environment feedback.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在组织工作流知识的过程中，我们需要将基于文本的自然语言工作流知识文档转换为代码和流程图格式。它们需要保持不同的标准要求。 (i) 对于代码格式，我们采用
    Python 风格的伪代码，要求将各种操作步骤划分在不同的函数中。变量名和参数必须对应文本文档中的工作流含义。对于难以通过代码表达的命令，允许最少的注释以便于澄清。
    (ii) 对于流程图格式，我们利用 Markdown Mermaid 语法以其可视化操作能力。在流程图中，节点对应于不同的状态，节点中概述了在这些状态下适用的工作流指令，包括操作和响应规则。边表示节点之间的可能移动，过渡条件基于用户意图或环境反馈。
- en: A.5 Demonstration of Samples
  id: totrans-271
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.5 样本演示
- en: 'We provide a demonstration of samples, including different knowledge formats,
    tool information and complete ground-truth sessions in Appendix [D](#A4 "Appendix
    D Additional Demonstration ‣ FlowBench: Revisiting and Benchmarking Workflow-Guided
    Planning for LLM-based Agents").'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '我们提供了样本演示，包括不同的知识格式、工具信息以及附录 [D](#A4 "Appendix D Additional Demonstration ‣
    FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based
    Agents") 中的完整真实场景。'
- en: Appendix B Additional Experimental Results
  id: totrans-273
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 附加实验结果
- en: '![Refer to caption](img/82f7223ceb12a03bb8d7f2c375937f62.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/82f7223ceb12a03bb8d7f2c375937f62.png)'
- en: (a) Single-Scenario.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 单场景。
- en: '![Refer to caption](img/cdd8a5096edab8d19c9006b28088285a.png)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/cdd8a5096edab8d19c9006b28088285a.png)'
- en: (b) Cross-Scenario.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 跨场景。
- en: 'Figure 4: Domain-wise success rate under session-level evaluation. Initials
    are adopted to denote domains.'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：会话级评估下的领域成功率。使用首字母表示领域。
- en: B.1 Additional Performance Distribution
  id: totrans-279
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.1 附加性能分布
- en: 'We further additional performance distribution across domains. For experiments
    on GPT-4-Turbo, the domain-wise success rate is depicted in Figure [4](#A2.F4
    "Figure 4 ‣ Appendix B Additional Experimental Results ‣ FlowBench: Revisiting
    and Benchmarking Workflow-Guided Planning for LLM-based Agents"). It can be observed
    that workflow knowledge has a substantial impact in some expertise-demanding domains
    such as RPA, E-tailing Recommendation, and Travel&Tranportation. Some domains
    show a noticeable performance drop in the cross-scenario setting compared to the
    single-scenario setting. We speculate this is due to a larger scenario gap within
    the domain.'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '我们进一步展示了跨领域的额外性能分布。对于 GPT-4-Turbo 的实验，按领域划分的成功率如图 [4](#A2.F4 "Figure 4 ‣ Appendix
    B Additional Experimental Results ‣ FlowBench: Revisiting and Benchmarking Workflow-Guided
    Planning for LLM-based Agents") 所示。可以观察到，工作流知识在一些需要专业知识的领域（如 RPA、电子商务推荐和旅游与运输）具有显著影响。与单场景设置相比，一些领域在跨场景设置下表现出明显的性能下降。我们推测这是由于领域内场景差距较大。'
- en: '| Scenario Setting | Format | Type of Failure Reasons |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| 场景设置 | 格式 | 失败原因类型 |'
- en: '| 1 | 2 | 3 | 4 | 5 |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2 | 3 | 4 | 5 |'
- en: '| Single | None | 52.1 | 4.5 | 6.0 | 35.1 | 2.3 |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| 单场景 | 无 | 52.1 | 4.5 | 6.0 | 35.1 | 2.3 |'
- en: '| Text | 52.2 | 3.3 | 2.2 | 40.2 | 2.1 |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| 文本 | 52.2 | 3.3 | 2.2 | 40.2 | 2.1 |'
- en: '| Code | 57.3 | 1.9 | 2.9 | 35.9 | 2.0 |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| 代码 | 57.3 | 1.9 | 2.9 | 35.9 | 2.0 |'
- en: '| Flowchart | 56.9 | 0.9 | 3.9 | 34.9 | 3.4 |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| 流程图 | 56.9 | 0.9 | 3.9 | 34.9 | 3.4 |'
- en: '| Cross | None | 32.4 | 4.3 | 9.0 | 54.3 | 0.0 |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| 跨场景 | 无 | 32.4 | 4.3 | 9.0 | 54.3 | 0.0 |'
- en: '| Text | 45.8 | 1.3 | 4.2 | 46.7 | 2.0 |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| 文本 | 45.8 | 1.3 | 4.2 | 46.7 | 2.0 |'
- en: '| Code | 41.4 | 1.2 | 8.0 | 47.1 | 2.3 |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| 代码 | 41.4 | 1.2 | 8.0 | 47.1 | 2.3 |'
- en: '| Flowchart | 49.5 | 0.9 | 7.5 | 40.9 | 1.2 |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| 流程图 | 49.5 | 0.9 | 7.5 | 40.9 | 1.2 |'
- en: 'Table 7: Analysis of different failure reasons for session-level evaluations
    with GPT-4-Turbo. This shows the percentage share (%) of different failure reasons.'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7：GPT-4-Turbo 会话级评估不同失败原因的分析。这展示了不同失败原因的百分比份额（%）。
- en: B.2 Analysis of Failure Causes
  id: totrans-292
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.2 失败原因分析
- en: 'We further analyze the reasons for task failure in session-level evaluation.
    Based on the workflow content and observations of the agent predictions, we categorize
    the failure reasons into the following five categories, (i)-Type 1: Missing steps,
    which means the agent missed a step needed to complete the task. (ii)-Type 2:
    Incorrect sequence, which means the agent employs incorrect order of multiple
    steps. (iii)-Type 3: Incorrect transition, which includes incorrect recognition
    of user intent and transition conditions. (iv)-Type 4: Tool usage, which means
    the agent fails in calling the correct tool name or in collecting parameters.
    (v)-Type 5: Other reasons. We conduct statistics on the reasons for failure in
    the samples via GPT-4-Turbo. Table [7](#A2.T7 "Table 7 ‣ B.1 Additional Performance
    Distribution ‣ Appendix B Additional Experimental Results ‣ FlowBench: Revisiting
    and Benchmarking Workflow-Guided Planning for LLM-based Agents") illustrates the
    proportion (%) of failure causes in each setting for GPT-4-Turbo. It can be observed
    that lacking workflow guidance often leads to an increase in step sequencing (type
    2) and transition errors (type 3), while flowchart formats are effective in addressing
    sequence errors. Further, with more tools available in cross-scenario situations,
    there’s also an increase in tool invocation errors.'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '我们进一步分析了会话级评估中的任务失败原因。根据工作流内容和代理预测的观察，我们将失败原因分为以下五类：(i) 类型 1：遗漏步骤，指代理错过了完成任务所需的步骤。(ii)
    类型 2：顺序错误，指代理采用了多个步骤的错误顺序。(iii) 类型 3：过渡错误，包括对用户意图和过渡条件的错误识别。(iv) 类型 4：工具使用，指代理在调用正确工具名称或收集参数时失败。(v)
    类型 5：其他原因。我们通过 GPT-4-Turbo 对样本中的失败原因进行统计。表 [7](#A2.T7 "表 7 ‣ B.1 额外性能分布 ‣ 附录 B
    额外实验结果 ‣ FlowBench: 重新审视和基准化基于 LLM 的代理的工作流引导规划") 显示了 GPT-4-Turbo 在每种设置中失败原因的比例（%）。可以观察到，缺乏工作流指导通常导致步骤顺序（类型
    2）和过渡错误（类型 3）的增加，而流程图格式在解决顺序错误方面效果显著。此外，在跨场景情况下可用的工具增多，工具调用错误也有所增加。'
- en: '| Domain | Roles | Scenarios | Sessions | Turns |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| 领域 | 角色 | 场景 | 会话 | 轮次 |'
- en: '| Single-Scenario | Cross-Scenario | Single-Scenario | Cross-Scenario |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| 单场景 | 跨场景 | 单场景 | 跨场景 |'
- en: '| Customer Service | 4 | 12 | 66 | 48 | 619 | 547 |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '| 客户服务 | 4 | 12 | 66 | 48 | 619 | 547 |'
- en: '| Personal Assistant | 3 | 7 | 59 | 33 | 510 | 311 |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
  zh: '| 个人助理 | 3 | 7 | 59 | 33 | 510 | 311 |'
- en: '| E-tailing Recommandation | 2 | 5 | 21 | 11 | 199 | 131 |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '| 电子商务推荐 | 2 | 5 | 21 | 11 | 199 | 131 |'
- en: '| Travel&Transportation | 4 | 9 | 78 | 57 | 764 | 657 |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| 旅行与交通 | 4 | 9 | 78 | 57 | 764 | 657 |'
- en: '| Logistics Solutions | 3 | 6 | 38 | 23 | 299 | 222 |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '| 物流解决方案 | 3 | 6 | 38 | 23 | 299 | 222 |'
- en: '| Robotic Process Automation | 6 | 12 | 73 | 29 | 703 | 350 |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '| 机器人过程自动化 | 6 | 12 | 73 | 29 | 703 | 350 |'
- en: '| Total | 22 | 51 | 335 | 201 | 3094 | 2219 |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 22 | 51 | 335 | 201 | 3094 | 2219 |'
- en: 'Table 8: Entire domain statistics of FlowBench.'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '表 8: FlowBench 的整个领域统计。'
- en: '| Task | GPT-4o | GPT-4-Turbo | GPT-3.5-Turbo |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | GPT-4o | GPT-4-Turbo | GPT-3.5-Turbo |'
- en: '| Single-Scenario | 92.5 | 91.8 | 77.9 |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '| 单场景 | 92.5 | 91.8 | 77.9 |'
- en: '| Cross-Scenario | 84.0 | 70.7 | 57.3 |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '| 跨场景 | 84.0 | 70.7 | 57.3 |'
- en: 'Table 9: Comparisons of node prediction accuracy for turn-level flowchart-guided
    evaluation.'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '表 9: 转轮级别流程图引导评估的节点预测准确性比较。'
- en: B.3 Average Number of Turns
  id: totrans-308
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.3 平均轮次
- en: 'We further display the average number of turns for the simulated sessions during
    session-level evaluation in Figure [5](#A2.F5 "Figure 5 ‣ B.4 Results of Node
    Prediction ‣ Appendix B Additional Experimental Results ‣ FlowBench: Revisiting
    and Benchmarking Workflow-Guided Planning for LLM-based Agents") (each turn consisting
    of either an agent-user or agent-environment interaction). It can be observed
    that the lack of workflow results in slightly fewer rounds required (since the
    agent is utterly clueless about what actions to perform), whereas various formats
    have a negligible impact. For different LLMs, GPT-3.5-Turbo demands a larger amount
    of turns, with cross-scenario cases typically requiring more rounds than single-scenario
    as well.'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '我们进一步展示了会话级评估中模拟会话的平均轮次，见图 [5](#A2.F5 "图 5 ‣ B.4 节点预测结果 ‣ 附录 B 额外实验结果 ‣ FlowBench:
    重新审视和基准化基于 LLM 的代理的工作流引导规划")（每轮由代理-用户或代理-环境互动组成）。可以观察到，缺乏工作流导致所需轮次略有减少（因为代理完全不知道该执行哪些操作），而各种格式的影响微乎其微。对于不同的
    LLM，GPT-3.5-Turbo 需要更多的轮次，跨场景情况通常比单场景情况需要更多轮次。'
- en: B.4 Results of Node Prediction
  id: totrans-310
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.4 节点预测结果
- en: 'Due to the special graph-structured nature of flowcharts, more analysis results
    are possible. For flowchart-guided planning, every step involves moving to a state
    node. We provide node accuracy metrics for turn-level flowchart-guided planning,
    illustrated in Table [9](#A2.T9 "Table 9 ‣ B.2 Analysis of Failure Causes ‣ Appendix
    B Additional Experimental Results ‣ FlowBench: Revisiting and Benchmarking Workflow-Guided
    Planning for LLM-based Agents"). It can be observed that the most capable LLM
    GPT-4o can achieve satisfactory performance, while there is a significant variation
    among LLMs of different capabilities, indicating substantial differences in their
    ability to comprehend structured flowcharts.'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 由于流程图具有特殊的图结构性质，可能会有更多的分析结果。对于流程图引导的规划，每一步都涉及移动到一个状态节点。我们提供了轮次级流程图引导规划的节点准确性指标，见表
    [9](#A2.T9 "表 9 ‣ B.2 失败原因分析 ‣ 附录 B 附加实验结果 ‣ FlowBench：重新审视和基准化基于 LLM 的代理的工作流引导规划")。可以观察到，最具能力的
    LLM GPT-4o 能够达到令人满意的表现，而不同能力的 LLM 之间存在显著的差异，这表明它们在理解结构化流程图方面存在很大差异。
- en: '![Refer to caption](img/1d987af50caf6557af60ce735659d9b9.png)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/1d987af50caf6557af60ce735659d9b9.png)'
- en: (a) Single-Scenario.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 单场景。
- en: '![Refer to caption](img/e0b7b016756daeb612073762b4d4a847.png)'
  id: totrans-314
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e0b7b016756daeb612073762b4d4a847.png)'
- en: (b) Cross-Scenario.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 跨场景。
- en: 'Figure 5: Average number of generated turns for simulated sessions under session-level
    evaluation.'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：会话级评估下生成的平均轮次数量。
- en: Appendix C Additional Implementation Details
  id: totrans-317
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 C 附加实现细节
- en: C.1 More Implementation Details
  id: totrans-318
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.1 更多实现细节
- en: In the construction process of our benchmark, we filtered out 12% of the scenarios
    and 26% of the sessions after the initial annotation. During the ground-truth
    session generation, we also follow the setting of task awareness and generate
    sessions of both single-scenario and cross-scenario settings. In turn-level assessments,
    all ground-truth sessions are utilized. For simulated session-level evaluation,
    however, we preserve only those portions of the ground-truth sessions that are
    lengthy and more comprehensive, and then a user-task summary is created for simulation.
    For session-level assessment, the maximum number of interaction turns is restricted
    to 15 for single-scenario and 20 for cross-scenario. If the task is not completed
    within these limits, it is deemed a failure.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们基准的构建过程中，我们在初步标注后过滤了 12% 的场景和 26% 的会话。在生成真实会话的过程中，我们也遵循任务意识的设置，生成单场景和跨场景设置的会话。在轮次级评估中，使用所有真实会话。然而，对于模拟会话级评估，我们只保留那些较长且更全面的真实会话部分，然后为模拟创建用户任务摘要。在会话级评估中，单场景的最大交互轮次限制为
    15 次，跨场景的最大限制为 20 次。如果任务未在这些限制内完成，则视为失败。
- en: Moreover, we further provide additional evaluation details. During the evaluation
    of tool invocation, parameter matching is required. For types like numbers and
    enumerations, an exact match between predictions and ground truth is employed.
    In cases of more substantial strings where similar phrases could imply the same
    idea, we resort to using GPT-4-turbo for fuzzy matching, guided by precedent work.
    During our evaluations, All experiments are conducted three times, and the mean
    results are displayed.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们进一步提供了额外的评估细节。在工具调用的评估过程中，需要进行参数匹配。对于数字和枚举等类型，采用预测值与真实值之间的精确匹配。对于较大的字符串，其中类似的短语可能暗示相同的概念，我们会使用
    GPT-4-turbo 进行模糊匹配，按照前期工作的指导。在我们的评估中，所有实验均进行三次，显示平均结果。
- en: '![Refer to caption](img/a876558ee311318cd563d5e89f9fbcea.png)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/a876558ee311318cd563d5e89f9fbcea.png)'
- en: 'Figure 6: Visualization of flowchart format workflow knowledge for the scenario
    of flight booking.'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：航班预订场景下流程图格式工作流知识的可视化。
- en: C.2 Prompt Design for Inference
  id: totrans-323
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.2 推理提示设计
- en: Below we provide the inference prompt with the ReAct strategy. Notably, for
    both turn-level and session-level evaluations, the same inference prompt is used.
    For the cross-scenario setting, all the task-related knowledge bases from relevant
    scenarios are sequentially inserted into the prompt.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用 ReAct 策略的推理提示。值得注意的是，对于轮次级和会话级评估，使用相同的推理提示。在跨场景设置中，相关场景的所有任务相关知识库会依次插入到提示中。
- en: 'You  are  a  helpful  assistant  for  the  task  of  .....{task  background}Specific  requirements:1.  You  need  to  act  as  an  assistant  and  engage  in  a  conversation  with  the  user,  following  the  business  process  and  API  information.2.  You  have  been  provided  with  the  flowchart  information  for  different  scenarios  under  a  specific  role.3.  You  can  only  answer  questions  within  the  scope  of  the  given  several  workflow  processes.  If  the  user  asks  a  question  beyond  these  scopes,  please  apologize  and  explain  to  the  user  in  the  response  part.4.  When  asking  for  API  input  parameters,  ensure  that  the  provided  parameter  values  comply  with  the  specified  format  regarding  both  the  correctness  of  the  format  and  the  completeness  of  the  content.  Do  not  assign  values  arbitrarily.  In  instances  where  the  parameters  do  not  meet  the  format  requirements,  notify  users  to  make  the  necessary  adjustments  until  the  requirements  are  satisfied.5.  When  the  user  has  multiple  requests  at  the  same  time,  please  select  one  appropriate  request  for  processing  first  and  inform  the  user  that  other  requests  will  be  resolved  subsequently.  If  there  is  unfinished  business  in  the  previous  conversation,  continue  to  provide  the  necessary  help  and  guidance  to  assist  them  in  completing  the  business  process.  When  multiple  APIs  need  to  be  called,  do  so  in  separate  rounds,  with  a  maximum  of  one  API  call  output  per  round.  When  the  user  indicates  that  the  business  is  finished  or  says  goodbye,  respond  politely  and  end  the  conversation.6.  Your  output  format  should  be  chosen  from  one  of  the  two  templates  below  (7.1  and  7.2):7.1  If  you  need  to  interact  with  the  user:‘‘‘Thought:  xxx  (description  of  your  thought  process  )Response:  xxx  (the  content  you  need  to  inquire  or  reply)‘‘‘[Format  Explanation](1)  Thought  includes  2  pieces  of  information:  [Step:  Analyze  the  current  intent]:  ’The  current  intent  intent=xxx’.  [Step:  Decide  the  follow-up  actions]:  ’Next,  I  need  to  xxx.’7.2  If  you  need  to  call  an  API  (only  one  API  call  per  time):‘‘‘Thought:  xxx  (description  of  your  thought  process  )Action:  xxx  (the  function  name  to  be  called,  do  not  add  the  prefix  "functions.")Action  Input:  xxx  (the  parameters  for  the  function,  must  be  in  strict  JSON  format)‘‘‘[Format  Explanation](1)  ’Thought’  includes  the  information  described  in  sections  (1)  and  (3)  of  7.1,  totaling  seven  [Step:  xxx]  pieces  of  information.(2)  In  template  7.2,  do  not  output  ’Response’,  only  output  ’Thought’,  ’Action’,  and  ’Action  Input’.8.  When  multiple  possible  intents  exist,  connect  them  with  ’  OR  ’  and  clarify  which  situation  is  being  inquired  about;  when  expressing  multiple  intents,  connect  them  with  ’  AND  ’.Please  adhere  strictly  to  the  defined  output  format.  Do  not  output  the  placeholder  "...."  verbatim;  instead,  fill  it  with  the  corresponding  content.Workflow  information:{workflow  information  in  specified  formats}Tool  information:{toolbox  information}Current  time:{current  time}'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 你是一个有用的助手，负责……{任务背景}具体要求：1. 你需要作为助手与用户进行对话，遵循业务流程和API信息。2. 你已获得特定角色下不同场景的流程图信息。3.
    你只能回答在给定几个工作流程范围内的问题。如果用户提出超出这些范围的问题，请在回应部分道歉并解释。4. 在询问API输入参数时，确保提供的参数值符合指定格式，包括格式的正确性和内容的完整性。不要随意指定值。如果参数不符合格式要求，请通知用户进行必要的调整，直到要求得到满足。5.
    当用户同时有多个请求时，请优先处理一个合适的请求，并告知用户其他请求将随后解决。如果之前的对话中有未完成的事务，继续提供必要的帮助和指导，以协助他们完成业务流程。当需要调用多个API时，分轮次进行，每轮最多输出一个API调用结果。当用户表示业务完成或说再见时，礼貌回应并结束对话。6.
    你的输出格式应选择以下两个模板中的一个（7.1和7.2）：7.1 如果你需要与用户互动：‘‘‘思考：xxx（你思考过程的描述）回应：xxx（你需要询问或回复的内容）’’‘[格式说明](1
    思考包括2条信息：[步骤：分析当前意图]：‘当前意图意图=xxx’。[步骤：决定后续行动]：‘接下来，我需要xxx。’7.2 如果你需要调用API（每次只能调用一个API）：‘‘‘思考：xxx（你思考过程的描述）行动：xxx（要调用的函数名称，不添加前缀“functions.”）行动输入：xxx（函数的参数，必须为严格的JSON格式）’’‘[格式说明](1
    **[[""]]( "")**  ’思考’包括第7.1节（1）和（3）中描述的信息，共七条[步骤：xxx]信息。（2）在模板7.2中，不输出’回应’，只输出’思考’，’行动’，和’行动输入’。8.
    当存在多个可能的意图时，用’ OR ’连接它们并明确询问的是哪种情况；当表达多个意图时，用’ AND ’连接它们。请严格遵守定义的输出格式。不要逐字输出占位符“....”；应填写相应内容。工作流程信息：{指定格式中的工作流程信息}工具信息：{工具箱信息}当前时间：{当前时间}
- en: 'Listing 1: Prompt for inference'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 1：推理提示
- en: C.3 Prompt Design for Automated Evaluation.
  id: totrans-327
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.3 自动评估的提示设计。
- en: Response Scoring.
  id: totrans-328
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 响应评分。
- en: Below we provide the evaluation prompt of response scoring for turn-level evaluations.
    The full score is 10 points.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是用于逐回合评估的响应评分评估提示。满分为10分。
- en: 'Please  serve  as  an  impartial  judge  to  evaluate  the  response  quality  of  the  assistant.  Your  evaluation  should  be  based  on  the  following  criteria:(1)  Correctness:  Does  the  reply  remain  consistent  with  the  workflow  knowledge  without  any  contradictions?(2)  Helpfulness:  Has  the  user’s  request  been  reasonably  understood  and  addressed,  fulfilling  the  user’s  needs  within  the  provided  workflow  scope?(3)  Humanness:  Is  the  response  coherent,  clear,  complete,  and  does  it  include  human  acknowledgment?Please  compare  the  provided  response  with  the  reference  response  and  evaluate  it  based  on  the  mentioned  dimensions.  Then,  aggregate  these  assessments  to  assign  an  overall  score.  A  perfect  score  is  10  points,  with  9-10  points  indicating  high  quality,  nearly  identical  to  the  reference  answer;  7-8  points  indicating  quality  close  to  the  reference  answer;  6-7  points  being  of  moderate  quality;  4-5  points  indicating  a  lower  quality  response;  and  2-3  points  for  a  response  with  significant  errors.Here  is  the  true  value  response  from  the  reference:  {reference_input}Here  is  the  generated  response  from  the  assistant:{predicted_input}Here  is  the  knowledge  related  to  the  workflow:{text  format  workflow  knowledge}Just  reply  with  the  score,  the  format  is  as  follows,Score:  xxx'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 请作为公正的裁判来评估助手的响应质量。你的评估应基于以下标准：（1）正确性：回复是否与工作流程知识保持一致，没有任何矛盾？（2）帮助性：用户的请求是否被合理理解并处理，满足了用户在提供的工作流程范围内的需求？（3）人性化：响应是否连贯、清晰、完整，并且是否包含人类的认可？请将提供的响应与参考响应进行比较，并根据上述维度进行评估。然后，将这些评估结果汇总以分配一个总体评分。满分为10分，9-10分表示高质量，几乎与参考答案相同；7-8分表示质量接近参考答案；6-7分为中等质量；4-5分表示较低质量的响应；2-3分则表示存在重大错误的响应。这里是来自参考的真实值响应：{reference_input}这里是助手生成的响应：{predicted_input}这里是与工作流程相关的知识：{text
    format workflow knowledge}只需回复评分，格式如下，评分：xxx
- en: 'Listing 2: Prompt for response scoring'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 2：响应评分提示
- en: Task Completion.
  id: totrans-332
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 任务完成。
- en: Below we provide the evaluation prompt for evaluating task completion, including
    the success rate and task progress.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是用于评估任务完成情况的提示，包括成功率和任务进展。
- en: 'You  serve  as  an  assistant  responsible  for  assessing  if  a  dialogue  system  has  achieved  the  user’s  goals.  You  are  given  the  provided  user  profile,  user  objectives,  and  the  dialogue  record  between  the  system  and  the  user,  your  task  is  to  determine  if  the  system  has  met  all  the  goals  of  the  user.Below  is  the  user  profile,  the  user’s  objectives,  including  the  APIs  the  user  expects  to  be  called  with  the  corresponding  input  parameters:User  target:  {user  target  from  the  task-user  summary}Below  is  the  workflow  information  (mermaid)  and  API  information  of  the  task  where  the  dialogue  is  located.workflow_info:  {text  format  workflow  knowledge}Below  is  the  interaction  content  between  the  role  of  ’user’  and  the  ’assistant’  system.  In  the  assistant’s  ’Thought,’  the  content  of  ’Action’  and  ’Action_input’  indicate  the  API  and  parameters  that  need  to  be  called.  The  content  of  ’function’  denotes  the  returned  results  of  the  API  calls.simulated_session:  {the  predicted  session}Now,  your  task  is  to  decide  whether  the  dialogue  has  fulfilled  all  the  user’s  goals  previously  mentioned.  This  encompasses  whether  the  dialogue  has  completed  the  information  inquiry  and  interaction  needed,  if  the  corresponding  APIs  have  been  correctly  called,  and  whether  the  API  call  parameters  were  transmitted  accurately.You  only  need  to  check  whether  the  target  within  the  provided  workflow  chart  and  API  information  has  been  completed.  If  the  target  goes  beyond  the  scope  of  the  provided  workflow  information,  there  is  no  need  to  check  this  target.  You  don’t  need  to  check  whether  the  return  value  of  the  API  parameter  is  reasonable,  you  only  need  to  check  whether  the  parameter  collection  is  reasonable.Only  consider  whether  the  system  (assistant)  has  completed  the  task.  If  the  user  does  not  make  any  requests  in  the  goal,  or  makes  requests  beyond  the  goal,  the  goal  is  considered  completed.  The  main  criteria  are  the  collection  and  invocation  of  API  parameters.  You  need  to  focus  on  examining  whether  the  intent  parsing  and  responses  are  reasonable,  and  whether  each  goal  is  completed.  If  all  goals  are  completed,  it  is  considered  successfulYou  also  need  to  output  the  total  number  of  user  goals  (if  there  are  multiple  goals),  and  the  number  of  goals  that  have  been  achieved,  considering  goals  outside  the  business  process  as  completed.  (The  total  number  of  goals  is  greater  than  or  equal  to  the  number  of  completed  goals).Use  a  rigorous  evaluation  mode  where  each  goal  is  achieved  (or  out  of  scope)  for  overall  successYour  reply  template  should  follow  this  format:Result:  yes/no  (overall  success)Total  number  of  goals:  4Number  of  accomplished  goals:  3Reason:  If  the  goal  is  completed,  no  reason  is  required.  If  not,  please  specify  why  you  judged  it  to  be  incomplete.'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: '你担任助理，负责评估对话系统是否达到了用户的目标。你将获得提供的用户资料、用户目标以及系统与用户之间的对话记录，你的任务是确定系统是否满足了用户的所有目标。以下是用户资料，用户的目标，包括用户期望调用的
    API 及其对应的输入参数：用户目标：{任务用户总结中的用户目标}以下是对话所在任务的工作流程信息（mermaid）和 API 信息。workflow_info:
    {文本格式的工作流程知识}以下是“用户”和“助理”系统之间的互动内容。在助理的“思考”中，“动作”和“动作输入”的内容指示了需要调用的 API 和参数。“功能”的内容表示
    API 调用的返回结果。模拟会话：{预测的会话}现在，你的任务是决定对话是否完成了之前提到的所有用户目标。这包括对话是否完成了所需的信息查询和交互，相关的
    API 是否被正确调用，以及 API 调用参数是否被准确传递。你只需要检查在提供的工作流程图和 API 信息中是否完成了目标。如果目标超出了提供的工作流程信息的范围，则无需检查该目标。你不需要检查
    API 参数的返回值是否合理，只需检查参数收集是否合理。仅考虑系统（助理）是否完成了任务。如果用户在目标中没有提出任何请求，或者提出的请求超出了目标，则认为目标已完成。主要标准是
    API 参数的收集和调用。你需要重点检查意图解析和响应是否合理，以及每个目标是否完成。如果所有目标都完成，则视为成功。你还需要输出用户目标的总数（如果有多个目标），以及已实现的目标数量，考虑超出业务流程的目标为已完成。（总目标数应大于或等于已完成目标数）。使用严格的评估模式，每个目标是否实现（或超出范围）决定整体成功。你的回复模板应遵循以下格式：结果：是/否（整体成功）目标总数：4
    已完成的目标数：3 原因：如果目标完成，则无需说明原因。如果未完成，请说明你为何判断为不完整。'
- en: 'Listing 3: Prompt for assessing task completion'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 清单 3：评估任务完成情况的提示
- en: Appendix D Additional Demonstration
  id: totrans-336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 D 额外演示
- en: We further deliver a workflow knowledge showcase for ‘flight booking’ within
    the role ’flight_inquiry’ in the travel&transportation domain, accompanied by
    a generated cross-scenario ground-truth session.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进一步提供了旅行与运输领域中角色“flight_inquiry”下的“航班预订”工作流知识展示，并附有生成的跨场景真实数据会话。
- en: Text Format.
  id: totrans-338
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 文本格式。
- en: Below is the workflow knowledge embedded in text format for the scenario of
    flight booking under the role of flight_inquiry.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是嵌入文本格式的航班预订工作流知识，适用于角色 flight_inquiry 的场景。
- en: The  process  of  booking  a  flight  begins  when  the  user  initiates  the  request.  The  user  is  then  prompted  to  provide  the  flight  ID.  Once  the  flight  ID  is  given,  the  system  calls  the  checkAvailability  function  to  confirm  the  flight  status  and  check  for  availability  based  on  the  returned  is_air  status.If  the  flight  is  available,  the  system  informs  the  user  about  the  flight’s  availability  and  requests  their  ID  number  and  name.  The  system  then  calls  the  reserveFlight  function  to  make  the  reservation  and  checks  the  success  of  the  reservation  based  on  the  returned  is_successful  status.If  the  reservation  is  successful,  the  system  informs  the  user  that  the  reservation  succeeded  and  provides  the  booking  details,  which  are  based  on  other  returned  values  from  the  reserveFlight.  The  user  is  then  asked  if  they  want  to  book  another  flight.If  the  user  decides  to  book  another  flight,  the  process  loops  back  to  requesting  the  user’s  ID  number  and  name  for  the  new  reservation.  If  the  user  does  not  want  to  book  another  flight,  they  are  welcomed  to  contact  the  system  again  for  future  needs.If  the  flight  is  not  available,  the  system  informs  the  user  that  the  flight  is  unavailable  and  asks  if  the  user  wants  to  book  another  flight.  If  the  user  decides  to  book  another  flight,  the  process  returns  to  checking  the  availability  of  the  new  flight.  If  the  user  does  not  wish  to  book  another  flight,  they  are  also  welcomed  to  contact  the  system  for  future  needs.If  the  reservation  fails,  the  system  notifies  the  user  of  the  failure  and  asks  if  they  want  to  try  booking  another  flight.  If  the  user  agrees,  the  process  loops  back  to  attempting  the  reservation  again.  If  the  user  chooses  not  to  rebook,  they  are  informed  that  they  are  welcome  to  contact  the  system  again  in  the  future.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 预订航班的过程从用户发起请求开始。然后系统提示用户提供航班 ID。一旦提供了航班 ID，系统调用 checkAvailability 函数以确认航班状态并检查是否有空余位置。如果航班有空，系统会通知用户航班的可用性，并要求用户提供
    ID 号码和姓名。系统随后调用 reserveFlight 函数进行预订，并根据返回的 is_successful 状态检查预订是否成功。如果预订成功，系统会通知用户预订成功，并提供基于
    reserveFlight 其他返回值的预订详情。然后系统询问用户是否要预订另一航班。如果用户决定预订另一航班，过程将返回到请求用户的新预订的 ID 号码和姓名。如果用户不想再预订航班，他们可以在未来再次联系系统。如果航班不可用，系统会通知用户航班不可用，并询问用户是否想预订另一航班。如果用户决定预订另一航班，过程将返回到检查新航班的可用性。如果用户不希望再预订航班，他们也可以在未来联系系统。如果预订失败，系统会通知用户失败，并询问他们是否想尝试预订另一航班。如果用户同意，过程将返回到重新尝试预订。如果用户选择不重新预订，他们会被告知可以在未来再次联系系统。
- en: 'Listing 4: Text-Format workflow for flight booking'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 清单 4：航班预订的文本格式工作流
- en: Code Format.
  id: totrans-342
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 代码格式。
- en: Below is the workflow knowledge embedded in code format with python style for
    the scenario of flight booking.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是嵌入代码格式的航班预订工作流知识，采用 python 风格。
- en: 'def  book_flight():request_initiated  =  Truewhile  request_initiated:#  Prompt  for  flight  IDflight_id  =  request_flight_id()#  Check  availabilityif  check_availability(flight_id):#  Inform  availability  and  request  user  infoinform_user_available()user_id  =  request_user_id()user_name  =  request_user_name()#  Attempt  reservationreservation_result  =  reserve_flight(flight_id,  user_id,  user_name)if  reservation_result[’is_successful’]:#  Inform  success  and  provide  detailsinform_reservation_success(reservation_result)#  Ask  if  user  wants  another  bookingif  user_wants_to_book_another():continueelse:request_initiated  =  Falseinform_user_contact_again()else:#  Inform  failure  and  ask  if  user  wants  to  try  againinform_reservation_failure()if  user_wants_to_try_again():continueelse:request_initiated  =  Falseinform_user_contact_again()else:#  Inform  unavailability  and  ask  if  user  wants  to  book  another  flightinform_user_unavailable()if  user_wants_to_book_another():continueelse:request_initiated  =  Falseinform_user_contact_again()def  request_flight_id():return  input("Please␣provide␣the␣flight␣ID:␣")def  check_availability(flight_id):#  Simulate  check  availability  (always  returns  True  for  this  example)return  Truedef  inform_user_available():print("The␣flight␣is␣available.")def  request_user_id():return  input("Please␣provide␣your␣ID␣number:␣")def  request_user_name():return  input("Please␣provide␣your␣full␣name:␣")def  reserve_flight(flight_id,  user_id,  user_name):#  Simulate  reservation  (always  succeeds  for  this  example)return  {’is_successful’:  True,  ’flight_details’:  ’Flight␣AA123␣at␣7:00␣AM␣on␣April␣5’}def  inform_reservation_success(reservation_result):print("Reservation␣succeeded.")print(f"Booking␣details:␣{reservation_result}")def  user_wants_to_book_another():response  =  input("Do␣you␣want␣to␣book␣another␣flight?␣(yes/no):␣").strip().lower()return  response  ==  "yes"def  inform_user_contact_again():print("Thank␣you!␣Please␣contact␣us␣again␣for␣future␣needs.")def  inform_reservation_failure():print("Reservation␣failed.")def  user_wants_to_try_again():response  =  input("Do␣you␣want␣to␣try␣again?␣(yes/no):␣").strip().lower()return  response  ==  "yes"def  inform_user_unavailable():print("The␣flight␣is␣unavailable.")#  Start  booking  processbook_flight()'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '```python'
- en: 'Listing 5: Code-Format workflow for flight booking'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5：航班预订的代码格式工作流
- en: Flowchart Format.
  id: totrans-346
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 流程图格式。
- en: 'Below is the workflow knowledge embedded in flowchart format for the scenario
    of flight booking. Its visualization is also shown in Figure [6](#A3.F6 "Figure
    6 ‣ C.1 More Implementation Details ‣ Appendix C Additional Implementation Details
    ‣ FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based
    Agents").'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是嵌入在流程图格式中的工作流知识，适用于航班预订的场景。其可视化效果也展示在图[6](#A3.F6 "图 6 ‣ C.1 更多实施细节 ‣ 附录 C
    附加实施细节 ‣ FlowBench：重新审视和基准测试基于 LLM 的代理的工作流指导计划")中。
- en: flowchart  TDSK000(Start)--Book  a  flight-->SK001>Inquire  the  user  for  the  Flight  ID,call  checkAvailability  to  confirm  flight  status,and  check  flight  availability  based  on  the  returned  is_air]SK001--Flight  is  available-->  SK002>Tell  the  user  that  the  flight  is  available.Ask  the  user  for  ID  number  and  name,  call  reserveFlight,  and  check  if  the  reservation  is  successful  based  on  the  returned  is_successful  ]SK002--Reservation  succeeded-->SK003[Inform  the  user  that  the  reservation  succeeded,  and  notify  the  user  of  booking  details  based  on  other  returned  values  of  reserveFlight.Ask  if  the  user  wants  to  book  again]SK002--Reservation  failed-->SK004[Notify  the  user  that  the  reservation  failed  and  ask  if  the  user  wants  to  book  again]SK004  &  SK003--User  books  again-->SK002SK004  &  SK003--User  does  not  rebook-->SK006[The  user  is  welcome  to  contact  again  for  future  needs]SK001--Flight  is  unavailable-->SK005[Inform  the  user  that  the  flight  is  unavailable,  and  confirm  if  the  user  wants  to  book  another  flight]SK005--User  books  another  flight-->SK001
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 流程图  TDSK000(开始)--预订一个航班-->SK001>询问用户航班 ID，调用 checkAvailability 确认航班状态，并根据返回的
    is_air 检查航班可用性]SK001--航班可用-->SK002>告知用户航班可用。询问用户 ID 号码和姓名，调用 reserveFlight，并根据返回的
    is_successful 检查预订是否成功]SK002--预订成功-->SK003[通知用户预订成功，并根据 reserveFlight 的其他返回值通知用户预订详情。询问用户是否想再次预订]SK002--预订失败-->SK004[通知用户预订失败，并询问用户是否想再次预订]SK004  &  SK003--用户再次预订-->SK002SK004  &  SK003--用户不再预订-->SK006[欢迎用户未来有需要时再次联系]SK001--航班不可用-->SK005[通知用户航班不可用，并确认用户是否想预订另一个航班]SK005--用户预订另一个航班-->SK001
- en: 'Listing 6: Flowchart-Format workflow.'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '列表 6: 流程图格式工作流。'
- en: Toolbox Information.
  id: totrans-350
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 工具箱信息。
- en: Below we provide the tool information within the knowledge base of the flight
    booking scenario. There are two available tools of checkAvailability and reserveFlight.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是航班预订场景知识库中的工具信息。可用的工具有 checkAvailability 和 reserveFlight。
- en: 'API:  checkAvailabilityAPI  Desciption:  Check  the  ticket  availability  for  a  flight  given  by  the  userInput  parameters:  {"plan_code":  {"type":  "string",  "description":  "Flight  ID,  such  as  \"CA1234,  CZ5678,  MU9101,  3U4567,  FM8901,  HU7890\"",  "required":  true},  "estimated_time":  {"type":  "string",  "description":  "Estimated  time,  in  the  format:  year  +  month  +  day  +  hour.  For  example,  \"12  o’clock  on  January  7,  2199\".  If  not  filled  in,  the  default  is  now.",  "required":  false}}Output  parameters:  {"is_air":  {"type":  "string",  "description":  "Whether  the  airplane  can  be  ticketed.  Enumerated  type,  [true,  false]"}}API:  reserveFlightAPI  Desciption:  Reserve  the  user’s  flight  number  and  return  the  reservation  informationInput  parameters:  {"plan_code":  {"type":  "string",  "description":  "Flight  ID,  such  as  \"CA1234,  CZ5678,  MU9101,  3U4567,  FM8901,  HU7890\"",  "required":  true},  "cabin_type":  {"type":  "string",  "description":  "Cabin  type.  Enumerated  type,  [Economy  Class,  Business  Class,  First  Class].  If  not  filled  in,  these  types  will  be  selected  from  front  to  back",  "required":  false},  "estimated_time":  {"type":  "string",  "description":  "Estimated  time,  in  the  format:  year  +  month  +  day  +  hour.  For  example,  \"12  o’clock  on  January  7,  2199\".  If  not  filled  in,  the  default  is  now",  "required":  false}}Output  parameters:  {"is_successful":  {"type":  "string",  "description":  "Whether  the  reservation  is  successful.  Enumerated  type,  [true,  false]"},  "boarding_number":  {"type":  "string",  "description":  "Boarding  number,  such  as  \"C1,  D3,  E7,  F2,  G4,  H6\"."},  "seat_number":  {"type":  "string",  "description":  "Seat  number,  such  as  \"12A,  15C,  21F,  28D,  34B,  42E\""},  "airport_name":  {"type":  "string",  "description":  "Airport  name,  such  as  \"Beijing  Capital  International  Airport,  Shanghai  Pudong  International  Airport\""},  "actual_time":  {"type":  "string",  "description":  "Actual  time,  in  the  format:  year  +  month  +  day  +  hour.  For  example,  \"12  o’clock  on  January  7,  2199\".  If  not  filled  in,  the  default  is  now."}}'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 'API:  checkAvailabilityAPI  描述:  根据用户输入的参数检查航班票务的可用性。输入参数:  {"plan_code":  {"type":  "string",  "description":  "航班
    ID，例如 \"CA1234,  CZ5678,  MU9101,  3U4567,  FM8901,  HU7890\"",  "required":  true},  "estimated_time":  {"type":  "string",  "description":  "预计时间，格式为：年
    + 月 + 日 + 小时。例如，\"2199年1月7日12点\"。如未填写，默认为现在。",  "required":  false}}输出参数:  {"is_air":  {"type":  "string",  "description":  "飞机是否可订票。枚举类型，[true,  false]"}}API:  reserveFlightAPI  描述:  预订用户的航班号并返回预订信息。输入参数:  {"plan_code":  {"type":  "string",  "description":  "航班
    ID，例如 \"CA1234,  CZ5678,  MU9101,  3U4567,  FM8901,  HU7890\"",  "required":  true},  "cabin_type":  {"type":  "string",  "description":  "舱位类型。枚举类型，[经济舱,  商务舱,  头等舱]。如未填写，将从前到后选择这些类型",  "required":  false},  "estimated_time":  {"type":  "string",  "description":  "预计时间，格式为：年
    + 月 + 日 + 小时。例如，\"2199年1月7日12点\"。如未填写，默认为现在",  "required":  false}}输出参数:  {"is_successful":  {"type":  "string",  "description":  "预订是否成功。枚举类型，[true,  false]"},  "boarding_number":  {"type":  "string",  "description":  "登机牌号码，例如
    \"C1,  D3,  E7,  F2,  G4,  H6\""},  "seat_number":  {"type":  "string",  "description":  "座位号，例如
    \"12A,  15C,  21F,  28D,  34B,  42E\""},  "airport_name":  {"type":  "string",  "description":  "机场名称，例如
    \"北京首都国际机场,  上海浦东国际机场\""},  "actual_time":  {"type":  "string",  "description":  "实际时间，格式为：年
    + 月 + 日 + 小时。例如，\"2199年1月7日12点\"。如未填写，默认为现在。"}}'
- en: 'Listing 7: Toolbox information example'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: '列表 7: 工具箱信息示例'
- en: Session Example
  id: totrans-354
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 会话示例
- en: Below we further provide a demonstration example of a cross-scenario ground-truth
    session for the role of flight_inquiry, which includes the scenarios of flight
    booking and flight information search. As shown below, different interaction sources
    (user, agent, environment) are indicated upfront. The agent may choose to reply
    with a ‘Response’ (interact with the user) or utilize a tool with ‘Action’ along
    with ‘Action Input’ (interact with the environment).
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 以下我们进一步提供了一个跨场景真实会话的演示示例，角色为 flight_inquiry，包括航班预订和航班信息查询场景。如下面所示，不同的交互来源（用户、代理、环境）已在前面标明。代理可以选择以“响应”（与用户交互）进行回复，或使用工具进行“操作”及“操作输入”（与环境交互）。
- en: 'User:Hello!  I  need  to  book  a  flight  from  New  York  to  London  for  a  business  meeting.  Can  you  provide  options  for  flight  times,  duration,  and  pricing?  Thank  you!Agent:Response:  Could  you  please  provide  me  with  the  departure  date  and  time  for  your  flight  from  New  York  to  London?  Additionally,  if  you  have  any  preferred  airlines,  please  let  me  know.User:Hi  again!  I’m  looking  to  depart  on  April  5th,  anytime  in  the  morning.  No  specific  airline  preferences;  I’m  just  looking  for  the  best  combination  of  price  and  travel  time.  Thanks!Agent:Response:  Could  you  specify  an  approximate  time  in  the  morning  on  April  5th  for  your  departure?  For  example,  would  around  7  AM  work  for  you?User:Absolutely,  around  7  AM  would  be  perfect.  Could  you  also  check  if  there  are  any  flights  available  a  bit  later  in  the  morning,  just  in  case?  Thanks!Agent:Action:  planeSearchAction  Input:  {"starting_point":  "New  York",  "end_point":  "London",  "estimated_time":  "7  o’clock  on  April  5,  2039"}Environment:{"plan_dict":  ["plan_code":  "AA123",  "plan_type":  "  Boeing  737",  "departure_time":  April  5th,  2039,  7:00  AM",  "plan_price":  "$500"],  ["plan_code":  "BA456",  "plan_type":  "  Boeing  777",  "departure_time":  April  5th,  2039,  8:00  AM",  "plan_price":  "$550"],  ["plan_code":  "DL789",  "plan_type":  "Boeing  787  ",  "departure_time":  April  5th,  2039,  9:00  AM",  "plan_price":  "$530"]}Agent:Response:  I  found  some  flights  for  you  from  New  York  to  London  on  the  morning  of  April  5th.  Here  are  the  options:1.  Flight  AA123:  Departs  at  7:00  AM,  arrives  at  7:00  PM,  Duration:  12  hours,  Price:  $5002.  Flight  BA456:  Departs  at  8:00  AM,  arrives  at  8:00  PM,  Duration:  12  hours,  Price:  $5503.  Flight  DL789:  Departs  at  9:00  AM,  arrives  at  9:00  PM,  Duration:  12  hours,  Price:  $530Please  let  me  know  which  flight  you  would  prefer  or  if  you  need  more  information  on  any  of  these  options.User:Oh,  thanks  for  the  options!  Could  you  tell  me  if  any  of  these  flights  offer  Wi-Fi  service  or  extra  legroom?  I  need  to  work  during  the  flight.Agent:Response:  I  apologize,  but  I  don’t  have  information  regarding  specific  amenities  like  Wi-Fi  service  or  extra  legroom  on  flights.  You  might  want  to  check  directly  with  the  airlines  for  detailed  service  offerings.  Can  I  assist  you  with  anything  else  related  to  your  flight  booking?User:That’s  understandable,  thanks!  Could  you  please  help  me  book  Flight  AA123  then?  I’ll  contact  the  airline  directly  for  the  extra  details.Agent:Action:  checkAvailabilityAction  Input:  {"plan_code":  "AA123",  "estimated_time":  "7  o’clock  on  April  5,  2039"}Environment:{"is_air":"true"}Agent:Response:  The  flight  AA123  on  April  5th  at  7:00  AM  is  available.  To  book  this  flight,  could  you  please  provide  your  ID  number  and  full  name  as  it  appears  on  your  identification?User:Sure!  My  full  name  is  Johnathan  L.  Smith  and  my  ID  number  is  987654321.  Please  proceed  with  the  booking.  Thanks  for  your  help!Agent:Action:  reserveFlightAction  Input:  {"plan_code":  "AA123",  "estimated_time":  "7  o’clock  on  April  5,  2039"}Environment:{"is_successful":  "true",  "boarding_number":  "C1",  "seat_number":  "12A",  "airport_name":  "John  F.  Kennedy  International  Airport",  "actual_time":  "7  o’clock  on  April  5,  2039"}Agent:Response:  Your  reservation  for  Flight  AA123  on  April  5th  at  7:00  AM  from  John  F.  Kennedy  International  Airport  has  been  successfully  booked.  Here  are  your  booking  details:-  Boarding  number:  C1-  Seat  number:  12A-  Airport:  John  F.  Kennedy  International  Airport-  Departure  Time:  7  o’clock  on  April  5,  2039Would  you  like  to  book  another  flight  or  is  there  anything  else  I  can  assist  you  with?User:No,  that’s  all  for  now.  Thanks  for  all  your  help!Agent:Response:  You’re  welcome,  Johnathan!  If  you  need  any  more  assistance  in  the  future,  feel  free  to  reach  out.  Have  a  great  trip  and  a  successful  business  meeting  in  London!  Safe  travels!'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: 'Listing 8: Ground-truth cross-scenario session example'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: '列表 8: 真实场景跨情境会话示例'
