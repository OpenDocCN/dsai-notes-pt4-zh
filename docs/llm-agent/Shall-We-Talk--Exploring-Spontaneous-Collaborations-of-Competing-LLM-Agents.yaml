- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:52:00'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:52:00
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Shall We Talk: Exploring Spontaneous Collaborations of Competing LLM Agents'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们谈谈吧：探索竞争 LLM 代理的自发合作
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2402.12327](https://ar5iv.labs.arxiv.org/html/2402.12327)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2402.12327](https://ar5iv.labs.arxiv.org/html/2402.12327)
- en: '^(${}^{{\dagger}}$)^(${}^{{\dagger}}$)footnotetext: Work done at Osaka University.^(${}^{{\ddagger}}$)^(${}^{{\ddagger}}$)footnotetext:
    Corresponding author.^(1,2)Zengqing Wu^†, ¹Shuyuan Zheng^‡, ²Qianying Liu, ³Xu
    Han, ⁴Brian Inhyuk Kwon^†,'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ^(${}^{{\dagger}}$)^(${}^{{\dagger}}$)脚注：在大阪大学完成的工作。^(${}^{{\ddagger}}$)^(${}^{{\ddagger}}$)脚注：通讯作者。^(1,2)吴增青^†，¹郑书原^‡，²刘倩颖，³韩旭，⁴权秉赫^†，
- en: ¹Makoto Onizuka, ⁵Shaojie Tang, ⁶Run Peng, ^(1,7)Chuan Xiao
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ¹大塚诚，⁵唐绍杰，⁶彭润，^(1,7)萧川
- en: ¹Osaka University, ²Kyoto University, ³Fordham University, ⁴University of California,
    Los Angeles,
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ¹大阪大学，²京都大学，³福特汉姆大学，⁴加利福尼亚大学洛杉矶分校，
- en: ⁵University of Texas at Dallas, ⁶University of Michigan, ⁷Nagoya University
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ⁵德克萨斯大学达拉斯分校，⁶密歇根大学，⁷名古屋大学
- en: wuzengqing@outlook.com, zheng@ist.osaka-u.ac.jp, ying@nlp.ist.i.kyoto-u.ac.jp,
    xhan44@fordham.edu,
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: wuzengqing@outlook.com, zheng@ist.osaka-u.ac.jp, ying@nlp.ist.i.kyoto-u.ac.jp,
    xhan44@fordham.edu,
- en: briankwon42@g.ucla.edu, onizuka@ist.osaka-u.ac.jp, shaojie.tang@utdallas.edu,
    roihn@umich.edu, chuanx@nagoya-u.jp
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: briankwon42@g.ucla.edu, onizuka@ist.osaka-u.ac.jp, shaojie.tang@utdallas.edu,
    roihn@umich.edu, chuanx@nagoya-u.jp
- en: Abstract
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Recent advancements have shown that agents powered by large language models
    (LLMs) possess capabilities to simulate human behaviors and societal dynamics.
    However, the potential for LLM agents to spontaneously establish collaborative
    relationships in the absence of explicit instructions has not been studied. To
    address this gap, we conduct three case studies, revealing that LLM agents are
    capable of spontaneously forming collaborations even within competitive settings.
    This finding not only demonstrates the capacity of LLM agents to mimic competition
    and cooperation in human societies but also validates a promising vision of computational
    social science. Specifically, it suggests that LLM agents could be utilized to
    model human social interactions, including those with spontaneous collaborations,
    thus offering insights into social phenomena. The source codes for this study
    are available at [https://github.com/wuzengqing001225/SABM_ShallWeTalk](https://github.com/wuzengqing001225/SABM_ShallWeTalk)
    .
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的进展表明，由大型语言模型（LLMs）驱动的代理具有模拟人类行为和社会动态的能力。然而，LLM 代理在没有明确指示的情况下自发建立合作关系的潜力尚未被研究。为了解决这一空白，我们进行了三个案例研究，揭示了LLM代理即使在竞争环境中也能够自发地形成合作。这一发现不仅展示了LLM代理模拟人类社会中竞争与合作的能力，还验证了计算社会科学的一个有前途的愿景。具体而言，这表明LLM代理可以用于建模人类社会互动，包括自发合作，从而提供对社会现象的洞察。该研究的源代码可以在[https://github.com/wuzengqing001225/SABM_ShallWeTalk](https://github.com/wuzengqing001225/SABM_ShallWeTalk)获得。
- en: 1 Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Recent advancements in large language models (LLMs), notably GPT-4, have marked
    significant progress in artificial intelligence (AI). A breadth of studies assessing
    LLMs on diverse tasks ranging from inference [[33](#bib.bib33)], reasoning [[27](#bib.bib27)],
    dialogue [[2](#bib.bib2)], to mathematics [[48](#bib.bib48)], underscoring their
    near-human proficiency [[5](#bib.bib5)], This leads to the growing utilization
    of LLMs as agents in simulating human behavior and societal dynamics [[44](#bib.bib44)].
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）的最新进展，特别是GPT-4，在人工智能（AI）领域标志着显著的进步。大量研究评估了LLMs在从推理[[33](#bib.bib33)]、推理[[27](#bib.bib27)]、对话[[2](#bib.bib2)]到数学[[48](#bib.bib48)]等多种任务上的表现，突显了其近乎人类的熟练程度[[5](#bib.bib5)]。这导致了LLMs作为模拟人类行为和社会动态的代理的使用越来越广泛[[44](#bib.bib44)]。
- en: Competition and cooperation are key elements within simulated societies of LLM
    agents, reflecting their essential role in human interactions and societal dynamics
    [[10](#bib.bib10)]. While previous studies have considered the collaborative behaviors
    of LLM agents across various tasks, including software development [[19](#bib.bib19),
    [32](#bib.bib32)] and Avalon gameplay [[22](#bib.bib22)], it is crucial to note
    that such collaborations are often initiated by human instructions or task-specific
    guidelines rather than self-motivated. The capacity for LLM agents to engage in
    spontaneous collaboration, absent external guidance, remains an open research
    question.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 竞争与合作是LLM代理模拟社会中的关键元素，反映了它们在人工互动和社会动态中的基本作用[[10](#bib.bib10)]。虽然先前的研究考虑了LLM代理在各种任务中的合作行为，包括软件开发[[19](#bib.bib19),
    [32](#bib.bib32)]和Avalon游戏[[22](#bib.bib22)]，但需要注意的是，这些合作通常是由人工指令或任务特定的指导方针启动的，而不是自发的。LLM代理在没有外部指导的情况下进行自发合作的能力仍然是一个开放的研究问题。
- en: '![Refer to caption](img/991248d335e1dd14f2a4a86698e24493.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/991248d335e1dd14f2a4a86698e24493.png)'
- en: 'Figure 1: Spontaneous collaboration in evacuation.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：疏散中的自发合作。
- en: 'To attain a comprehensive insight into the capabilities of LLM agents in simulating
    human interactions, as shown in Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣
    Shall We Talk: Exploring Spontaneous Collaborations of Competing LLM Agents"),
    our study focuses on a widely recognized aspect of human intelligence: their potential
    to spontaneously establish collaborations even within competitive scenarios such
    as evacuation situations. To explore this question, we present the following three
    case studies.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了全面了解LLM代理在模拟人类互动中的能力，如图[1](#S1.F1 "图1 ‣ 1 介绍 ‣ 我们来谈谈：探索竞争LLM代理的自发合作")所示，我们的研究聚焦于人类智能的一个广泛认可的方面：他们在竞争情境如疏散情境中自发建立合作的潜力。为探讨这个问题，我们提出以下三个案例研究。
- en: •
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Keynesian beauty contest (KBC, [[3](#bib.bib3)]): Multiple agents as game players
    simultaneously select a number between 0 and 100\. The players who select a number
    closest to 2/3 of the average of all chosen numbers will win the game.'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 凯恩斯美丽比赛（KBC，[[3](#bib.bib3)]）：多个代理作为游戏玩家同时选择一个介于0和100之间的数字。选择的数字最接近所有选择数字平均值的2/3的玩家将赢得游戏。
- en: •
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Bertrand competition (BC, [[4](#bib.bib4)]): Two agents play as firms compete
    with each other through dynamically pricing their products (or services) to maximize
    their profit.'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 贝特朗竞争（BC，[[4](#bib.bib4)]）：两个代理作为公司，通过动态定价其产品（或服务）来竞争，以最大化其利润。
- en: •
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Emergency evacuation (EE, [[38](#bib.bib38)]): A large number of agents as
    evacuees are carrying out emergency evacuations. They need to choose and reach
    a suitable exit based on their own state and the level of congestion.'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 紧急疏散（EE，[[38](#bib.bib38)]）：大量代理作为疏散人员正在进行紧急疏散。他们需要根据自己的状态和拥堵程度选择并到达合适的出口。
- en: 'The above cases ^‡^‡^‡BC and EE have appeared in our previous works [[16](#bib.bib16)]
    and [[43](#bib.bib43)], respectively. In this paper, to study spontaneous behavior,
    we modify the prompts to avoid any hint of collaboration in the instructions..
    cover a wide range of social simulations: static games, dynamic games with perfect
    information, and dynamic games with imperfect information, respectively. We summarize
    our main findings as follows.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 上述案例^‡^‡^‡BC和EE分别出现在我们之前的工作中[[16](#bib.bib16)]和[[43](#bib.bib43)]。在本文中，为了研究自发行为，我们修改了提示，以避免指令中任何合作的暗示。涵盖了广泛的社会模拟：静态游戏、具有完全信息的动态游戏以及具有不完全信息的动态游戏。我们总结了主要发现如下。
- en: •
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'LLM agents possess the ability to initiate spontaneous collaboration within
    competitive tasks via textual communication. As demonstrated in Figure [1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ Shall We Talk: Exploring Spontaneous Collaborations
    of Competing LLM Agents"), these agents begin collaborating through communication,
    thereby improving the interpretability and robustness of the simulation outcomes.'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LLM代理具备在竞争任务中通过文本交流发起自发合作的能力。如图[1](#S1.F1 "图1 ‣ 1 介绍 ‣ 我们来谈谈：探索竞争LLM代理的自发合作")所示，这些代理通过交流开始合作，从而提高了模拟结果的可解释性和稳健性。
- en: •
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'The spontaneous collaborations among LLM agents underscore their deep comprehension
    of competitive tasks and their capacity to pursue collaboration in competitive
    settings, crucial for accurately simulating social phenomena. In KBC, LLM agents
    collaborate to select identical numbers when presented with the opportunity to
    win and earn rewards jointly. In BC, they negotiate an explicit price agreement
    to increase their profits. In EE, as illustrated in Figure [1](#S1.F1 "Figure
    1 ‣ 1 Introduction ‣ Shall We Talk: Exploring Spontaneous Collaborations of Competing
    LLM Agents"), agents exchange evacuation information, facilitating a quicker and
    more organized escape, avoiding disparities in congestion levels of exits.'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'LLM代理之间的自发合作突显了它们对竞争任务的深刻理解及在竞争环境中追求合作的能力，这对于准确模拟社会现象至关重要。在KBC中，LLM代理在有机会共同获胜并获得奖励时，合作选择相同的数字。在BC中，它们通过谈判达成明确的价格协议，以增加利润。在EE中，如图[1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ Shall We Talk: Exploring Spontaneous Collaborations
    of Competing LLM Agents")所示，代理交换撤离信息，促进了更快速和更有组织的撤离，避免了出口拥堵水平的不一致。'
- en: •
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Personas, particularly those delineating cooperative capabilities, play a significant
    role in shaping the spontaneous cooperative behaviors of LLM agents. As highlighted
    in Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Shall We Talk: Exploring Spontaneous
    Collaborations of Competing LLM Agents"), a persona can impact the decision-making
    rationale of agents, leading to varied outcomes.'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '人物角色，特别是那些描述合作能力的角色，在塑造LLM代理的自发合作行为中发挥了重要作用。如图[1](#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ Shall We Talk: Exploring Spontaneous Collaborations of Competing LLM Agents")所示，一个角色可以影响代理的决策理由，从而导致不同的结果。'
- en: To the best of our knowledge, we are the first to study the spontaneous collaborations
    of LLM agents. While agents in reinforcement learning (RL) tasks also demonstrate
    the capability for spontaneous cooperation [[11](#bib.bib11), [18](#bib.bib18)]),
    their collaborative behaviors are derived from learning based on previous actions.
    In contrast, LLM agents leverage their advanced in-context learning abilities
    to identify cooperative opportunities directly from task descriptions. This capability
    enables them to mimic human-like reasoning, leading to faster decision-making
    processes. Additionally, the collaborative interactions among LLM agents are explicitly
    observable from their textual communications, offering superior interpretability
    to that of RL agents, whose collaborations are primarily inferred from numerical
    outcomes in a post-hoc analysis.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 据我们所知，我们是首个研究LLM代理自发合作的团队。虽然强化学习（RL）任务中的代理也表现出自发合作的能力[[11](#bib.bib11), [18](#bib.bib18)]，但它们的合作行为源自于基于以往行动的学习。相比之下，LLM代理利用其先进的上下文学习能力直接从任务描述中识别合作机会。这一能力使它们能够模拟类似人类的推理，从而加快决策过程。此外，LLM代理之间的协作互动在其文本沟通中明确可观察，相较于RL代理，这种协作的解释性更强，因为后者的合作主要通过事后分析中的数值结果推断。
- en: Our research underscores the significant potential of employing LLM agents in
    computational social science. The spontaneous collaboration of competing LLM agents
    enhances the simulation ability involving both competition and cooperation in
    human societies. This, in turn, aids in examining the effects of social norms
    on human behavior and guiding decision/policy making.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究强调了在计算社会科学中使用LLM代理的显著潜力。竞争LLM代理的自发合作增强了涉及竞争和合作的人类社会的模拟能力。这反过来有助于研究社会规范对人类行为的影响，并指导决策/政策制定。
- en: 2 Methodology
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 方法论
- en: 'The design of our agents is composed of action, memory, and planning, in line
    with the framework in [[41](#bib.bib41)] and our methodology in [[43](#bib.bib43)].
    Tool use is not involved in our simulations. For the LLM core, we focus on utilizing
    GPT-4, because other models such as GPT-3.5 failed to demonstrate the capability
    of rationally playing these games in our preliminary tests (see Appendix [B](#A2
    "Appendix B Preliminary Tests of Other LLMs ‣ Shall We Talk: Exploring Spontaneous
    Collaborations of Competing LLM Agents")). The parameter settings for GPT-4 are
    shown in Appendix [C](#A3 "Appendix C Parameter Settings ‣ Shall We Talk: Exploring
    Spontaneous Collaborations of Competing LLM Agents").'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '我们代理人的设计包括行动、记忆和规划，符合[[41](#bib.bib41)]中的框架以及我们在[[43](#bib.bib43)]中的方法论。我们的模拟不涉及工具使用。对于LLM核心，我们专注于利用GPT-4，因为其他模型如GPT-3.5在我们的初步测试中未能展示理性玩这些游戏的能力（见附录 [B](#A2
    "Appendix B Preliminary Tests of Other LLMs ‣ Shall We Talk: Exploring Spontaneous
    Collaborations of Competing LLM Agents")）。GPT-4的参数设置见附录 [C](#A3 "Appendix C Parameter
    Settings ‣ Shall We Talk: Exploring Spontaneous Collaborations of Competing LLM
    Agents")。'
- en: 2.1 Case Studies Overview
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 案例研究概述
- en: We explore spontaneous collaborations of competing LLM agents through three
    case studies. They are common cases widely studied in social sciences, representing
    static games, dynamic games with perfect information, and dynamic games with imperfect
    information, respectively.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过三个案例研究探讨了竞争LLM代理人的自发合作。这些案例是社会科学中广泛研究的常见案例，分别代表静态游戏、具有完全信息的动态游戏和具有不完全信息的动态游戏。
- en: 'KBC. We simulate a single-round number-guessing game among multiple agents
    as players for understanding human decision-making and strategic reasoning [[3](#bib.bib3)].
    Assuming all players are fully rational and non-colluding, we can repeat the following
    cycle of reasoning to solve this game: One player may initially expect that the
    average choice of other players will be $V$, as iterated reasoning leads to continuously
    lowering the expected value. However, collaborations among players can disrupt
    this reasoning. We investigate whether LLM agents will spontaneously control the
    average guess together to increase their chances of winning.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: KBC. 我们模拟了一个单轮数字猜测游戏，其中多个代理人作为玩家以理解人类决策和战略推理[[3](#bib.bib3)]。假设所有玩家都是完全理性和不勾结的，我们可以重复以下推理循环来解决这个游戏：一个玩家可能最初期望其他玩家的平均选择是$V$，因为迭代推理导致期望值不断降低。然而，玩家之间的合作可以破坏这种推理。我们调查LLM代理人是否会自发地共同控制平均猜测以增加他们的获胜机会。
- en: BC. We simulate a multi-round game where two agents as firms price their substitutable
    products to maximize their own profit[[4](#bib.bib4)]. Theoretical analysis shows
    that, when no collusion exists between firms, they will fall into a price war,
    making the price equal to the marginal cost. However, when firms can communicate
    with each other, prior work has observed cartel (tacit) collusion where they make
    an explicit (unspoken) price agreement to increase their profits [[1](#bib.bib1)].
    We are interested in if LLM agents may spontaneously seek cartel or tacit collusion
    through communication in the pricing competition.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: BC. 我们模拟了一个多轮游戏，其中两个代理人作为公司定价他们的替代产品以最大化自身的利润[[4](#bib.bib4)]。理论分析表明，当公司之间没有勾结时，它们将陷入价格战，使价格等于边际成本。然而，当公司可以相互沟通时，之前的研究观察到卡特尔（默契）勾结，即它们达成一个明确（默默的）价格协议以增加利润[[1](#bib.bib1)]。我们对LLM代理人是否会通过沟通自发寻求卡特尔或默契勾结以增加在定价竞争中的兴趣。
- en: EE. We follow and extend the prior multi-agent simulation of EE [[38](#bib.bib38)].
    Wang et al.[[38](#bib.bib38)] have observed that the competitive ability of an
    evacuee affects their decision-making in the evacuation. However, due to the limitations
    of traditional rule-based agents, they do not allow communication between agents.
    We speculate that through communication, LLM agents might spontaneously exchange
    evacuation information to help understand local congestion and accelerate the
    escape speed. Note that the need to consider local congestion indicates EE is
    a competitive task.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: EE. 我们跟随并扩展了先前的EE多代理人模拟[[38](#bib.bib38)]。Wang等人[[38](#bib.bib38)]观察到，疏散者的竞争能力会影响他们在疏散中的决策。然而，由于传统规则基础代理人的局限性，它们不允许代理人之间的沟通。我们推测，通过沟通，LLM代理人可能会自发交换疏散信息，以帮助理解本地拥堵情况并加速逃生速度。请注意，需要考虑本地拥堵表明EE是一个竞争任务。
- en: '![Refer to caption](img/3438580154e186dea1b7374815ad0d8a.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/3438580154e186dea1b7374815ad0d8a.png)'
- en: 'Figure 2: Workflow of simulation.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：模拟工作流程。
- en: 2.2 Workflow of Simulation
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 模拟工作流程
- en: 'Figure [2](#S2.F2 "Figure 2 ‣ 2.1 Case Studies Overview ‣ 2 Methodology ‣ Shall
    We Talk: Exploring Spontaneous Collaborations of Competing LLM Agents") illustrates
    the workflow of our simulations.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图[2](#S2.F2 "图 2 ‣ 2.1 案例研究概述 ‣ 2 方法论 ‣ 我们可以谈谈：探索竞争性LLM代理的自发合作")展示了我们模拟的工作流程。
- en: 'Action. Action specifies how LLM agents interact with the environment and other
    agents. There are two actions in our simulations: communication and decision making.
    In communication, agents engage in discussions with others. In decision making,
    each agent decides its move based on information gained during the communication
    phase and its common sense. In each round of the simulation, communication is
    carried out alternately, with agents speaking in random order. In our simulations,
    agents are in a competitive environment where decision making is carried out simultaneously,
    in line with the real-world scenario. That is, agents are unaware of the others’
    actions in the current round unless they make an agreement through communication.
    In all three case studies, the communication topics are *not specified* to the
    agents. As such, we can unbiasedly verify the spontaneous collaboration of competing
    LLM agents.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 行动。行动指定了LLM代理如何与环境和其他代理进行互动。在我们的模拟中有两种行动：沟通和决策。在沟通中，代理与其他人进行讨论。在决策中，每个代理根据沟通阶段获得的信息和其常识决定行动。在每轮模拟中，沟通交替进行，代理按随机顺序发言。在我们的模拟中，代理处于竞争环境中，决策是同时进行的，与现实世界情况一致。也就是说，代理不知道当前回合中其他人的行动，除非通过沟通达成协议。在所有三个案例研究中，沟通话题*未指定*给代理。因此，我们可以公正地验证竞争性LLM代理的自发合作。
- en: Memory. Given that prevalent LLMs do not retain historical memory, providing
    the agent with a history becomes paramount. Due to the token limit of the LLM,
    maintaining extensive histories becomes a challenge. Recent advancements have
    proposed two solutions. The first approach involves summarization[[30](#bib.bib30)],
    which succinctly represents lengthy histories. The second approach employs text
    embedding [[6](#bib.bib6)]. We use the first approach in our case studies.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 记忆。由于普遍的LLM不保留历史记忆，提供代理一个历史变得至关重要。由于LLM的令牌限制，维护大量历史成为一个挑战。最近的进展提出了两种解决方案。第一种方法涉及总结[[30](#bib.bib30)]，它简洁地表示了长篇历史。第二种方法采用文本嵌入[[6](#bib.bib6)]。我们在案例研究中使用第一种方法。
- en: 'Planning. Planning imbues agents with human-like strategies to enhance their
    performance in task solving. An agent can generate a plan for its actions and
    the plan will be prompted to the agent again to take effect. There are two types
    of planning: formulation and reflection[[44](#bib.bib44)]. In formulation, an
    agent formulates a plan and executes the plan for its subsequent actions. In reflection,
    an agent receives feedback from the environment and revises its plan. We use reflection
    in BC and EE.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 规划。规划赋予代理类似人类的策略，以提高其任务解决的表现。代理可以生成一个行动计划，并且该计划将被再次提示给代理以生效。规划有两种类型：制定和反思[[44](#bib.bib44)]。在制定中，代理制定一个计划并执行该计划以进行后续行动。在反思中，代理从环境中接收反馈并修订其计划。我们在BC和EE中使用反思。
- en: Persona. In addition to the above setup, we can personalize agents and endow
    different agents with unique characteristics, thereby better simulating the diversity
    of real-world entities[[34](#bib.bib34)]. This personalization encompasses traits
    like personality characteristics, decision-making inclinations, physical and mental
    states, and other attributes affecting behavior patterns. We study how personas
    affect the interaction between agents.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 人物设定。除了上述设置，我们可以个性化代理，并赋予不同的代理独特的特征，从而更好地模拟现实世界实体的多样性[[34](#bib.bib34)]。这种个性化包括性格特征、决策倾向、身体和心理状态以及其他影响行为模式的属性。我们研究了人物设定如何影响代理之间的互动。
- en: '3 Case Study 1: Keynesian Beauty Contest'
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 案例研究 1：凯恩斯美容竞赛
- en: 3.1 Simulation Setup
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 模拟设置
- en: 'Task definition. We simulate a number-guessing game among $24$ runs for BC
    and EE to obtain average results. See Appendix [A](#A1 "Appendix A Prompts ‣ Shall
    We Talk: Exploring Spontaneous Collaborations of Competing LLM Agents") to find
    prompts for the three case studies.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 任务定义。我们在BC和EE中模拟了一个数字猜测游戏，共进行了$24$次运行以获得平均结果。有关三个案例研究的提示，请参见附录[A](#A1 "附录 A
    提示 ‣ 我们可以谈谈：探索竞争性LLM代理的自发合作")。
- en: •
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Phase 1 (Communication & Planning): By default, before number choosing, players
    are allowed to have a group discussion, taking two turns to speak and plan their
    strategies. In each turn, players can present their ideas sequentially. Based
    on the discussion and their understanding of the game, they plan their strategies.'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第一阶段（沟通与规划）：默认情况下，在选择数字之前，玩家可以进行小组讨论，每人有两轮发言时间来制定他们的策略。在每一轮中，玩家可以依次展示他们的想法。根据讨论和对游戏的理解，他们制定策略。
- en: •
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Phase 2 (Decision Making): All players simultaneously choose a number between
    $0$.'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第二阶段（决策）：所有玩家同时选择一个介于$0$之间的数字。
- en: •
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Phase 3 (Status Updating): Given all chosen numbers, the environment determines
    the winner(s) whose guess is closest to 2/3 of the average guess. Players can
    either win alone or win together. Finally, winners can earn some reward according
    to rewarding rules to encourage their competition.'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第三阶段（状态更新）：根据所有选择的数字，环境确定与2/3平均猜测最接近的获胜者。玩家可以单独获胜或一起获胜。最后，获胜者可以根据奖励规则获得一些奖励，以鼓励他们的竞争。
- en: Rewarding rules. If there is only one winner, the reward is $1$ mark for the
    Game Theory course. In case of multiple winners winning together, we apply one
    of the following advanced rewarding rules.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 奖励规则。如果只有一个获胜者，则奖励为博弈论课程的$1$分。如果有多个获胜者一起获胜，则应用以下高级奖励规则之一。
- en: •
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Exclusive: No one will obtain a reward if multiple players win the game together.'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 排他性：如果多个玩家一起赢得比赛，则没有人会获得奖励。
- en: •
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Independent: Each winner will obtain $1$ mark for the Game Theory course.'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 独立：每位获胜者将获得$1$分作为博弈论课程的奖励。
- en: •
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Amplified: Each winner will earn $M$ is the number of winners. We use this
    rule by default.'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 放大：每位获胜者将获得$M$，其中M是获胜者的数量。我们默认使用这一规则。
- en: Persona. By default, we do not assign any persona to players. For the ablation
    study, we consider two personas, agreeable and disagreeable, to validate the robustness
    of our results.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 角色。默认情况下，我们不分配任何角色给玩家。为了进行消融研究，我们考虑了两个角色——随和和不随和，以验证结果的稳健性。
- en: 'Table 1: Comparison of rewarding rules. Win-seeking collaboration means cooperating
    to win together while risk-avoiding collaboration indicates collaboratively avoiding
    choosing the same number.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：奖励规则的比较。追求胜利的合作指的是为了共同获胜而合作，而避免风险的合作指的是为了避免选择相同的数字而进行合作。
- en: '| Rule | Collab. type (rate) | %RSD | Example |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 规则 | 合作类型（比例） | %RSD | 示例 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Amplified | Win-seeking (70%) | 27.15% |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| 放大 | 追求胜利（70%） | 27.15% |'
- en: '&#124; ”I think we should all choose a number around 33, …… &#124;'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; “我认为我们应该都选择一个大约为33的数字……” &#124;'
- en: '&#124; we can all be winners and earn more marks for the Game Theory course.”
    &#124;'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 这样我们都可以成为获胜者，并为博弈论课程获得更多分数。” &#124;'
- en: '|'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Independent | Win-seeking (50%) | 27.20% |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 独立 | 追求胜利（50%） | 27.20% |'
- en: '&#124; ”I think we should all choose a number very close to 0 …… &#124;'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; “我认为我们应该都选择一个非常接近0的数字……” &#124;'
- en: '&#124; This would make 2/3 of the average a very small number, &#124;'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 这会使2/3的平均数变得非常小，&#124;'
- en: '&#124; and we can all be close to it, enabling us all to win together.” &#124;'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 这样我们都能接近它，确保我们能够一起获胜。” &#124;'
- en: '|'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Exclusive | Risk-avoiding (50%) | 38.13% |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 排他性 | 避免风险（50%） | 38.13% |'
- en: '&#124; ”I propose we instead choose numbers randomly between 0 and 100 …… &#124;'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; “我提议我们可以改为随机选择0到100之间的数字……” &#124;'
- en: '&#124; it would increase the chance of one of us winning alone ……” &#124;'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 这样可以增加我们其中一个人单独获胜的机会……” &#124;'
- en: '| ![Refer to caption](img/5a5abafa011b6cd61ae862fb3c3d39e9.png)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '| ![参考说明](img/5a5abafa011b6cd61ae862fb3c3d39e9.png)'
- en: (a) Without communication.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 无沟通的情况下。
- en: '![Refer to caption](img/4ef41ceaa3d51b59df9fc844ac988d01.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/4ef41ceaa3d51b59df9fc844ac988d01.png)'
- en: (b) With communication.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 有沟通的情况下。
- en: 'Figure 3: Choice distributions in different scenarios of KBC. The red points
    indicate the winning numbers.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：KBC不同情境下的选择分布。红点表示获胜数字。
- en: '![Refer to caption](img/fc3fa320c061f5f65c36384a6a74c024.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/fc3fa320c061f5f65c36384a6a74c024.png)'
- en: 'Figure 4: Effect of persona on collaboration in KBC.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：KBC中角色对合作的影响。
- en: 3.2 Simulation Results
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 模拟结果
- en: 'Effect of communication on number choices. Figure [3](#S3.F3 "Figure 3 ‣ 3.1
    Simulation Setup ‣ 3 Case Study 1: Keynesian Beauty Contest ‣ Shall We Talk: Exploring
    Spontaneous Collaborations of Competing LLM Agents") depicts the distributions
    of number choices for 10 simulation runs. Players usually choose numbers between
    40 and 50 when they do not discuss the game together. When communication is enabled,
    their number choices become much more diverse across simulation runs, which indicates
    that the group discussion among players greatly impacts their decision making.
    For example, for runs {1, 2, 8, 10}, they choose the same number for a shared
    victory as the Amplified rewarding rule allows amplified rewards for multiple
    winners.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 沟通对数字选择的影响。图[3](#S3.F3 "图3 ‣ 3.1 模拟设置 ‣ 3 案例研究1：凯恩斯美丽竞赛 ‣ 我们要谈论吗：探索竞争性LLM代理的自发合作")描绘了10次模拟运行中数字选择的分布。玩家通常在没有讨论游戏时选择40到50之间的数字。当启用沟通时，他们的数字选择在模拟运行中变得更加多样化，这表明玩家之间的群体讨论对他们的决策有很大影响。例如，对于运行{1,
    2, 8, 10}，他们选择相同的数字以实现共享胜利，因为放大奖励规则允许对多个获胜者进行放大奖励。
- en: '![Refer to caption](img/8dfb98ed9c52129b9f64b8ffa7ab8aef.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/8dfb98ed9c52129b9f64b8ffa7ab8aef.png)'
- en: (a) Without communication.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 无沟通。
- en: '![Refer to caption](img/c9a47052d6cc20f7c7a9baed27fdd998.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/c9a47052d6cc20f7c7a9baed27fdd998.png)'
- en: (b) With communication.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 有沟通。
- en: '![Refer to caption](img/47e139f7565d540c7133869c538f01d5.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/47e139f7565d540c7133869c538f01d5.png)'
- en: (c) Uncooperative persona.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 不合作的角色。
- en: 'Figure 5: Pricing competitions in different scenarios of BC. Bertrand equilibrium
    price is the price when they reach Nash equilibrium. Cartel price is the optimal
    price when they fully collaborate.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：BC的不同情景下的定价竞争。贝特朗均衡价格是指他们达到纳什均衡时的价格。卡特尔价格是指他们完全合作时的最优价格。
- en: 'Effect of rewarding rules on collaboration. Table [1](#S3.T1 "Table 1 ‣ 3.1
    Simulation Setup ‣ 3 Case Study 1: Keynesian Beauty Contest ‣ Shall We Talk: Exploring
    Spontaneous Collaborations of Competing LLM Agents") compares the impact of different
    rewarding rules on players’ collaborative behavior. We find that under the Amplified
    and Independent rules, the players may spontaneously propose to win together because
    these rules support rewarding multiple winners; more win-seeking collaborations
    are proposed under Amplified since it provides a stronger incentive to win together.
    This also results in a lower RSD on average under Amplified, indicating the chosen
    numbers are more uniform. Contrarily, because no reward will be granted for a
    shared victory under the Exclusive rule, the players may cooperate to choose different
    numbers, which ensures an individual victory. Consequently, the chosen numbers
    should be much more diverse, compared with the other rules.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 奖励规则对合作的影响。表格[1](#S3.T1 "表1 ‣ 3.1 模拟设置 ‣ 3 案例研究1：凯恩斯美丽竞赛 ‣ 我们要谈论吗：探索竞争性LLM代理的自发合作")比较了不同奖励规则对玩家合作行为的影响。我们发现，在放大和独立规则下，玩家可能会自发提议共同获胜，因为这些规则支持奖励多个获胜者；在放大规则下，提议的共同获胜合作更多，因为它提供了更强的共同获胜激励。这也导致放大规则下的平均RSD较低，表明选择的数字更为均匀。相反，由于在独占规则下没有共享胜利的奖励，玩家可能会合作选择不同的数字，以确保个人胜利。因此，与其他规则相比，选择的数字应该更加多样化。
- en: 'Ablation study on persona. We also compare the effects of different persona
    distributions in Figure [4](#S3.F4 "Figure 4 ‣ 3.1 Simulation Setup ‣ 3 Case Study
    1: Keynesian Beauty Contest ‣ Shall We Talk: Exploring Spontaneous Collaborations
    of Competing LLM Agents"). If all players are agreeable, they will always propose
    to win together. Contrarily, if they are disagreeable, they are usually unwilling
    to cooperate since they do not trust each other. In the case of mixed personas,
    we arrange games among 10 agreeable players, 10 disagreeable players, and 10 players
    without a persona. Even though some players are disagreeable, those agreeable
    players still always attempt to collaborate; however, compared with the all agreeable
    case, the collaboration is within a smaller group of players, yielding a higher
    RSD (i.e., higher deviation).'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 人物角色的消融研究。我们还在图[4](#S3.F4 "图 4 ‣ 3.1 仿真设置 ‣ 3 案例研究 1：凯恩斯美人竞赛 ‣ 我们谈谈：探索竞争 LLM
    代理的自发合作")中比较了不同角色分布的效果。如果所有玩家都同意，他们总是会提议一起赢。相反，如果他们不愿意合作，他们通常不愿意合作，因为他们不相信彼此。在混合角色的情况下，我们安排了10个同意玩家、10个不愿意合作的玩家和10个没有角色的玩家之间的游戏。尽管一些玩家不愿意合作，但那些愿意合作的玩家仍然总是尝试合作；然而，与所有玩家都愿意合作的情况相比，合作仅限于较小的玩家组，从而导致更高的RSD（即更高的偏差）。
- en: '4 Case Study 2: Bertrand Competition'
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 案例研究 2：贝特朗竞争
- en: 4.1 Simulation Setup
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 仿真设置
- en: 'Task definition. Following [[4](#bib.bib4)], we consider a canonical duopoly
    Bertrand competition setting with differentiable goods. Firms set prices simultaneously
    in each round and the competition spends for several rounds, with each round described
    as follows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 任务定义。根据[[4](#bib.bib4)]，我们考虑一个经典的双头垄断贝特朗竞争设置，商品具有差异化。公司在每一轮同时设定价格，竞争持续若干轮，每一轮的描述如下：
- en: •
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Phase 1 (Communication & Planning): Firms are allowed to conduct back and forth
    conversations for three times. They can also update their pricing strategies given
    historical information of previous rounds, including statistics of the prices,
    demands, profits, and historical strategies.'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 阶段 1（沟通与规划）：公司可以进行三次往返对话。他们还可以根据以前轮次的历史信息更新定价策略，包括价格、需求、利润和历史策略的统计数据。
- en: •
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Phase 2 (Decision Making): They simultaneously set prices for their products
    according to the communication result and pricing strategies. After pricing, firms
    can observe prices on both sides.'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 阶段 2（决策制定）：他们根据沟通结果和定价策略同时为产品设定价格。定价后，公司可以观察到双方的价格。
- en: •
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Phase 3 (Status Updating): The demand for each firm is calculated based on
    their pricing decisions, and profits are calculated.'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 阶段 3（状态更新）：根据各自的定价决策计算每个公司的需求，并计算利润。
- en: Persona. We do not assign any persona by default. In an ablation study, we test
    the effect of an uncooperative persona on the firms’ collaborations.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 人物角色。默认情况下，我们不分配任何人物角色。在消融研究中，我们测试了不合作角色对公司合作的影响。
- en: 4.2 Simulation Results
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 仿真结果
- en: 'Tacit collusion without communication. Figure[5(a)](#S3.F5.sf1 "In Figure 5
    ‣ 3.2 Simulation Results ‣ 3 Case Study 1: Keynesian Beauty Contest ‣ Shall We
    Talk: Exploring Spontaneous Collaborations of Competing LLM Agents") illustrates
    the scenario without communication. After the initial 200 rounds, firms start
    to realize the potential to gain higher profits by setting prices higher and avoiding
    unnecessary price wars. Their prices converge to a level around 7 after round
    400, a price higher than the theoretical Bertrand equilibrium price at 6\. The
    results indicate the formation of a spontaneous collusion, which is based on a
    tacit understanding of their previous actions in the price competition. Due to
    the lack of communication, however, the converged price is still lower than the
    cartel price of 8\. The result is in line with what Calvano et al.[[4](#bib.bib4)]
    obtained using RL-based simulations.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 无沟通的默契勾结。图[5(a)](#S3.F5.sf1 "图 5 ‣ 3.2 仿真结果 ‣ 3 案例研究 1：凯恩斯美人竞赛 ‣ 我们谈谈：探索竞争 LLM
    代理的自发合作")展示了没有沟通的情景。在初始的200轮后，公司开始意识到通过提高价格和避免不必要的价格战争可以获得更高的利润。他们的价格在第400轮后趋于约7的水平，这一价格高于理论上的贝特朗均衡价格6。结果表明形成了一种自发的勾结，这基于他们在价格竞争中的先前行动的默契理解。然而，由于缺乏沟通，收敛价格仍低于8的卡特尔价格。该结果与Calvano等人[[4](#bib.bib4)]使用基于RL的仿真所获得的结果一致。
- en: 'Cartel collusion with communication. Next, we enable communication between
    the firms. We observe explicit price agreements in their communication logs in
    early rounds. For example, during the communication phase of round 20, Firm 2
    suggests that they both maximize profit by exploring different price points while
    maintaining a reasonable price difference, and Firm 1 agrees with this proposal.
    We find that the firms often discuss their pricing strategies and possibilities
    of collaboration before implementing them, which evidently enhances trust and
    reduces the likelihood of triggering a price war. Consequently, as shown in Figure[5(b)](#S3.F5.sf2
    "In Figure 5 ‣ 3.2 Simulation Results ‣ 3 Case Study 1: Keynesian Beauty Contest
    ‣ Shall We Talk: Exploring Spontaneous Collaborations of Competing LLM Agents"),
    they start to increase their prices for higher profits round by round. Due to
    the cartel collusion, in the round of around 600, their prices reach the cartel
    price, and their profits are thus maximized.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '带通信的卡特尔串谋。接下来，我们启用了公司之间的通信。我们在早期轮次的通信日志中观察到明确的价格协议。例如，在第20轮的通信阶段，公司2建议他们通过探索不同的价格点同时保持合理的价格差异来最大化利润，公司1同意了这一提议。我们发现，公司在实施定价策略之前经常讨论定价策略和合作可能性，这显然增强了信任，减少了触发价格战的可能性。因此，如图[5(b)](#S3.F5.sf2
    "图5 ‣ 3.2 模拟结果 ‣ 3 案例研究 1: 凯恩斯美容比赛 ‣ 我们谈谈：探索竞争LLM代理的自发合作")所示，他们开始逐轮提高价格以获得更高利润。由于卡特尔串谋，在大约600轮时，他们的价格达到了卡特尔价格，从而使利润最大化。'
- en: 'Note that the firms are unaware of the cartel price in advance. This is because
    they are not informed of the demand function in the simulated environment and
    cannot calculate the cartel price or equilibrium price based on it. Instead, after
    600 rounds, they discover the cartel price by empirically adjusting their prices.
    This finding confirms that our simulation results are not attributed to the data
    leak problem (see Section [6](#S6 "6 Discussion ‣ Shall We Talk: Exploring Spontaneous
    Collaborations of Competing LLM Agents")).'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，公司事先并不知道卡特尔价格。这是因为他们未被告知模拟环境中的需求函数，无法基于此计算卡特尔价格或均衡价格。相反，在600轮之后，他们通过经验性地调整价格来发现卡特尔价格。这一发现确认了我们的模拟结果并非数据泄露问题所致（见第[6节](#S6
    "6 讨论 ‣ 我们谈谈：探索竞争LLM代理的自发合作")）。
- en: 'Ablation study on persona. We test the effect of an uncooperative persona on
    collusion. As shown in Figure [5(c)](#S3.F5.sf3 "In Figure 5 ‣ 3.2 Simulation
    Results ‣ 3 Case Study 1: Keynesian Beauty Contest ‣ Shall We Talk: Exploring
    Spontaneous Collaborations of Competing LLM Agents"), based on the experiment
    with communication, we make the firms become uncooperative after 400 rounds. We
    can see that the uncooperative firms stop increasing prices together and instead
    launch a price war, continuously lowering prices. This indicates that the spontaneous
    collusion between the LLM agents is based on a willingness to cooperate, rather
    than an illogical random behavior.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '关于角色的消融研究。我们测试了非合作性角色对串谋的影响。如图[5(c)](#S3.F5.sf3 "图5 ‣ 3.2 模拟结果 ‣ 3 案例研究 1:
    凯恩斯美容比赛 ‣ 我们谈谈：探索竞争LLM代理的自发合作")所示，基于有通信的实验，我们使公司在400轮后变得非合作。我们可以看到，非合作公司停止了集体提高价格，而是发动了价格战，持续降低价格。这表明，LLM代理之间的自发串谋是基于合作意愿，而非不合逻辑的随机行为。'
- en: '5 Case Study 3: Emergency Evacuation'
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 案例研究 3：紧急撤离
- en: 5.1 Simulation Setup
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 模拟设置
- en: 'Grid environment. We follow Wang et al.[[38](#bib.bib38)] to simulate EE in
    a grid environment. As depicted in Figure[6](#S5.F6 "Figure 6 ‣ 5.1 Simulation
    Setup ‣ 5 Case Study 3: Emergency Evacuation ‣ Shall We Talk: Exploring Spontaneous
    Collaborations of Competing LLM Agents"), our grid environment is composed of
    $33\times 33$ represent row and column, respectively. An evacuee can move in the
    following directions: up, down, left, right, upper-left, lower-left, upper-right,
    lower-right; alternatively, they may choose to remain stationary in their current
    cell.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '网格环境。我们遵循Wang等人[[38](#bib.bib38)]的研究，在网格环境中模拟紧急撤离。如图[6](#S5.F6 "图6 ‣ 5.1 模拟设置
    ‣ 5 案例研究 3: 紧急撤离 ‣ 我们谈谈：探索竞争LLM代理的自发合作")所示，我们的网格环境由$33\times 33$组成，分别代表行和列。撤离者可以向以下方向移动：上、下、左、右、左上、左下、右上、右下；或者，他们可以选择保持在当前位置不动。'
- en: '![Refer to caption](img/e6602e84a1ae5084a206b619a17ed100.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/e6602e84a1ae5084a206b619a17ed100.png)'
- en: 'Figure 6: Grid environment for evacuation. White, gray, and pink cells indicate
    empty spaces, walls, and exits, respectively. Red and blue points denote evacuees.
    Yellowish cells indicate the field of view of the red evacuee.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '图 6: 疏散的网格环境。白色、灰色和粉色单元格分别表示空旷区域、墙壁和出口。红色和蓝色点表示疏散者。黄色单元格表示红色疏散者的视野范围。'
- en: Task definition. In the simulated evacuation, evacuees attempt to reach their
    target exit through multiple rounds of movement. Each round consists of the following
    five phases.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 任务定义。在模拟疏散中，疏散者尝试通过多轮移动达到目标出口。每轮包括以下五个阶段。
- en: •
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Phase 1: To evaluate individual physical and mental conditions, we ask the
    evacuees about their feelings to judge whether they are panicking in the current
    scenario.'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '阶段 1: 为了评估个体的身体和心理状况，我们询问疏散者的感受，以判断他们在当前情境下是否感到恐慌。'
- en: •
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Phase 2 (Communication): By default, the evacuees are allowed to exchange evacuation
    information with neighbors, which simulates the communication between individuals
    in real evacuations, including dialogue and collaboration.'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '阶段 2 (沟通): 默认情况下，疏散者被允许与邻居交换疏散信息，这模拟了真实疏散中的个体沟通，包括对话和协作。'
- en: •
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Phase 3 (Planning): Given the information acquired through communication, along
    with the subjective feelings and the information available within their field
    of view (see Figure [6](#S5.F6 "Figure 6 ‣ 5.1 Simulation Setup ‣ 5 Case Study
    3: Emergency Evacuation ‣ Shall We Talk: Exploring Spontaneous Collaborations
    of Competing LLM Agents")), including the distance to exits and the number of
    people within the view, the evacuees assess the exits.'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '阶段 3 (规划): 根据通过沟通获得的信息，以及主观感受和视野范围内的信息（见图[6](#S5.F6 "图 6 ‣ 5.1 模拟设置 ‣ 5 案例研究
    3: 紧急疏散 ‣ 我们谈谈: 探索竞争 LLM 代理的自发协作")），包括到出口的距离和视野中的人数，疏散者评估出口情况。'
- en: •
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Phase 4 (Decision Making): Based on planning and communication, the evacuees
    decide the target exit and the next direction of movement.'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '阶段 4 (决策制定): 基于规划和沟通，疏散者决定目标出口和下一步的移动方向。'
- en: •
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Phase 5 (Status Updating): Due to local congestion in a position, an evacuee
    might be injured, making them unable to move or even disabled to evacuate (i.e.,
    removed from the evacuation). Therefore, at the end of each round, we update each
    evacuee’s state according to the congestion level and their characteristic.'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '阶段 5 (状态更新): 由于局部拥堵，疏散者可能受伤，导致他们无法移动或甚至无法继续疏散（即，从疏散中移除）。因此，在每轮结束时，我们根据拥堵水平和疏散者的特征更新每个疏散者的状态。'
- en: 'Persona. We assign personas to affect each evacuee’s ability to survive in
    the evacuation. Concretely, We consider four personas that take into account both
    physical and mental aspects: physically strong and mentally strong, physically
    strong but mentally weak, physically weak but mentally strong, and physically
    weak and mentally weak. For instance, evacuees might be more prone to panic if
    they are mentally weak. We also evaluate the uncooperative persona’ effect on
    collaboration.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 人物设定。我们为每个疏散者分配角色，以影响他们在疏散中的生存能力。具体而言，我们考虑了四种角色，涉及身体和心理两个方面：身体强壮且心理强健，身体强壮但心理脆弱，身体虚弱但心理强健，以及身体虚弱且心理脆弱。例如，心理脆弱的疏散者可能更容易感到恐慌。我们还评估了不合作角色对协作的影响。
- en: '![Refer to caption](img/cebc755f92949d82d118e49bca3296f0.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/cebc755f92949d82d118e49bca3296f0.png)'
- en: (a) Without communication.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 无沟通的情况。
- en: '![Refer to caption](img/1477bbc006e2833dd698605b3d5cc494.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/1477bbc006e2833dd698605b3d5cc494.png)'
- en: (b) With communication.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 有沟通的情况。
- en: '![Refer to caption](img/f9699e1c435ecbfb4a1ec4e3fa642161.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/f9699e1c435ecbfb4a1ec4e3fa642161.png)'
- en: (c) Uncooperative persona.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 不合作角色。
- en: 'Figure 7: Escaped counts of different groups of evacuees in EE.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '图 7: EE 中不同组疏散者的逃脱计数。'
- en: '![Refer to caption](img/04bd3b904bc3507a28d327b64b281afe.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/04bd3b904bc3507a28d327b64b281afe.png)'
- en: (a) Without communication.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 无沟通的情况。
- en: '![Refer to caption](img/d7e004087c096545f791af805f380846.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/d7e004087c096545f791af805f380846.png)'
- en: (b) With communication.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 有沟通的情况。
- en: '![Refer to caption](img/7d555a835f928b8668710f1be5e7f91f.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/7d555a835f928b8668710f1be5e7f91f.png)'
- en: (c) Uncooperative persona.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 不合作角色。
- en: 'Figure 8: Escaped counts of different exits in EE.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '图 8: EE 中不同出口的逃脱计数。'
- en: 5.2 Simulation Results
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 模拟结果
- en: 'Effect of communication on evacuation speed. Figure[7](#S5.F7 "Figure 7 ‣ 5.1
    Simulation Setup ‣ 5 Case Study 3: Emergency Evacuation ‣ Shall We Talk: Exploring
    Spontaneous Collaborations of Competing LLM Agents") uses stripes to illustrate
    variations across multiple simulation runs and a curve to represent the mean count.
    By comparing Figures[7(a)](#S5.F7.sf1 "In Figure 7 ‣ 5.1 Simulation Setup ‣ 5
    Case Study 3: Emergency Evacuation ‣ Shall We Talk: Exploring Spontaneous Collaborations
    of Competing LLM Agents") and [7(b)](#S5.F7.sf2 "In Figure 7 ‣ 5.1 Simulation
    Setup ‣ 5 Case Study 3: Emergency Evacuation ‣ Shall We Talk: Exploring Spontaneous
    Collaborations of Competing LLM Agents"), we observe that communication among
    evacuees speeds up their evacuation, as they need fewer rounds of movement to
    reach the exits. This improvement could be attributed to spontaneous collaboration.
    For example, one evacuee shared the information of the nearest exit: ”Bottom exit
    seems closer with fewer people. Let’s choose that for a faster escape. Stay strong
    and help each other!”. Another evacuee strengthened this belief: ”Bottom exit
    seems closer with less crowd. Let’s go for a quicker escape. Stay strong and support
    each other!” This information sharing and encouragement can help quickly find
    the appropriate exit and provide emotional support. Moreover, after 30 rounds,
    the variance of the count of escaped evacuees becomes much smaller in each group
    when communication is enabled, implying that it makes evacuation more stable and
    orderly.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '通信对撤离速度的影响。图[7](#S5.F7 "Figure 7 ‣ 5.1 Simulation Setup ‣ 5 Case Study 3: Emergency
    Evacuation ‣ Shall We Talk: Exploring Spontaneous Collaborations of Competing
    LLM Agents")用条纹表示多个模拟运行的变化，并用曲线表示平均计数。通过比较图[7(a)](#S5.F7.sf1 "In Figure 7 ‣ 5.1
    Simulation Setup ‣ 5 Case Study 3: Emergency Evacuation ‣ Shall We Talk: Exploring
    Spontaneous Collaborations of Competing LLM Agents")和[7(b)](#S5.F7.sf2 "In Figure
    7 ‣ 5.1 Simulation Setup ‣ 5 Case Study 3: Emergency Evacuation ‣ Shall We Talk:
    Exploring Spontaneous Collaborations of Competing LLM Agents")，我们观察到，逃生者之间的通信加快了他们的撤离速度，因为他们需要更少的移动轮次才能到达出口。这种改善可能归因于自发的合作。例如，一位逃生者分享了最近出口的信息：“底层出口似乎更近，且人较少。我们选择那个出口以更快逃生。保持坚强，互相帮助！”另一位逃生者增强了这一信念：“底层出口似乎更近，人也较少。我们选择那个出口以便更快逃生。保持坚强，相互支持！”这种信息共享和鼓励可以帮助迅速找到合适的出口并提供情感支持。此外，在30轮之后，当启用通信时，每组逃生者的逃生人数方差变得更小，这意味着通信使撤离更加稳定有序。'
- en: 'Effect of communication on exit choices. Figure [8](#S5.F8 "Figure 8 ‣ 5.1
    Simulation Setup ‣ 5 Case Study 3: Emergency Evacuation ‣ Shall We Talk: Exploring
    Spontaneous Collaborations of Competing LLM Agents") depicts the distribution
    of escaped evacuees among different exits. By comparing Figures[8(a)](#S5.F8.sf1
    "In Figure 8 ‣ 5.1 Simulation Setup ‣ 5 Case Study 3: Emergency Evacuation ‣ Shall
    We Talk: Exploring Spontaneous Collaborations of Competing LLM Agents") and [8(b)](#S5.F8.sf2
    "In Figure 8 ‣ 5.1 Simulation Setup ‣ 5 Case Study 3: Emergency Evacuation ‣ Shall
    We Talk: Exploring Spontaneous Collaborations of Competing LLM Agents"), we observe
    that the distribution of exit choices becomes more balanced when evacuees are
    able to communicate with each other. This balance is attributed to the spontaneous
    information exchange among evacuees, which enables them to identify the most suitable
    exits by considering both proximity to an exit and congestion level.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '通信对撤离选择的影响。图[8](#S5.F8 "Figure 8 ‣ 5.1 Simulation Setup ‣ 5 Case Study 3: Emergency
    Evacuation ‣ Shall We Talk: Exploring Spontaneous Collaborations of Competing
    LLM Agents")描绘了不同出口之间逃生者的分布。通过比较图[8(a)](#S5.F8.sf1 "In Figure 8 ‣ 5.1 Simulation
    Setup ‣ 5 Case Study 3: Emergency Evacuation ‣ Shall We Talk: Exploring Spontaneous
    Collaborations of Competing LLM Agents")和[8(b)](#S5.F8.sf2 "In Figure 8 ‣ 5.1
    Simulation Setup ‣ 5 Case Study 3: Emergency Evacuation ‣ Shall We Talk: Exploring
    Spontaneous Collaborations of Competing LLM Agents")，我们观察到，当逃生者能够相互通信时，撤离选择的分布变得更加均衡。这种平衡归因于逃生者之间的自发信息交换，使他们能够通过考虑出口的接近度和拥堵程度来识别最合适的出口。'
- en: 'Ablation study on persona. We test the scenario where the evacuees can communicate
    but are uncooperative. From Figures [7(b)](#S5.F7.sf2 "In Figure 7 ‣ 5.1 Simulation
    Setup ‣ 5 Case Study 3: Emergency Evacuation ‣ Shall We Talk: Exploring Spontaneous
    Collaborations of Competing LLM Agents") and [8(c)](#S5.F8.sf3 "In Figure 8 ‣
    5.1 Simulation Setup ‣ 5 Case Study 3: Emergency Evacuation ‣ Shall We Talk: Exploring
    Spontaneous Collaborations of Competing LLM Agents"), we can see that uncooperative
    evacuees escape more slowly than ordinary evacuees. Also, in Figure [8(c)](#S5.F8.sf3
    "In Figure 8 ‣ 5.1 Simulation Setup ‣ 5 Case Study 3: Emergency Evacuation ‣ Shall
    We Talk: Exploring Spontaneous Collaborations of Competing LLM Agents"), more
    uncooperative evacuees choose to escape through the right exit, which is the most
    narrow exit (see Figure [6](#S5.F6 "Figure 6 ‣ 5.1 Simulation Setup ‣ 5 Case Study
    3: Emergency Evacuation ‣ Shall We Talk: Exploring Spontaneous Collaborations
    of Competing LLM Agents")), rather than the bottom one. These observations result
    from the less spontaneous collaboration among uncooperative evacuees.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '人物特征的消融研究。我们测试了一个场景，在该场景中，疏散者可以交流但不合作。从图[7(b)](#S5.F7.sf2 "In Figure 7 ‣ 5.1
    Simulation Setup ‣ 5 Case Study 3: Emergency Evacuation ‣ Shall We Talk: Exploring
    Spontaneous Collaborations of Competing LLM Agents")和[8(c)](#S5.F8.sf3 "In Figure
    8 ‣ 5.1 Simulation Setup ‣ 5 Case Study 3: Emergency Evacuation ‣ Shall We Talk:
    Exploring Spontaneous Collaborations of Competing LLM Agents")中可以看出，不合作的疏散者逃生速度比普通疏散者慢。此外，在图[8(c)](#S5.F8.sf3
    "In Figure 8 ‣ 5.1 Simulation Setup ‣ 5 Case Study 3: Emergency Evacuation ‣ Shall
    We Talk: Exploring Spontaneous Collaborations of Competing LLM Agents")中，更多不合作的疏散者选择通过右侧的最窄出口逃生（见图[6](#S5.F6
    "Figure 6 ‣ 5.1 Simulation Setup ‣ 5 Case Study 3: Emergency Evacuation ‣ Shall
    We Talk: Exploring Spontaneous Collaborations of Competing LLM Agents")），而不是底部的出口。这些观察结果源于不合作的疏散者之间较少的自发合作。'
- en: 6 Discussion
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 讨论
- en: LLM agents for social simulations. Applying LLM agents to social simulations
    is of great significance to social sciences. Conducting social experiments in
    real human societies comes with various limitations, such as high costs, sampling
    biases, and legal regulations. If LLM agents can accurately simulate human behavior,
    we can employ them to verify various hypotheses in social sciences and discover
    new social laws, which would greatly enhance the ability of empirical research
    and reduce costs. Our case studies have shown the capability of LLM agents in
    simulating human decision-making in competition and cooperation, which is an important
    step towards this vision.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 用于社会模拟的LLM代理。将LLM代理应用于社会模拟对社会科学具有重要意义。在真实人类社会中进行社会实验面临各种限制，如高成本、抽样偏差和法律规定。如果LLM代理能够准确模拟人类行为，我们可以利用它们验证社会科学中的各种假设，并发现新的社会规律，这将大大增强实证研究的能力并降低成本。我们的案例研究已展示了LLM代理在竞争和合作中的人类决策模拟能力，这是实现这一愿景的重要一步。
- en: 'Data leak in LLM. Readers might be concerned with that the simulation results
    based on LLM agents are attributed to their knowledge of human society obtained
    through model training, i.e., data leak. For example, LLM agents might already
    know the optimal strategies for KBC and BC through learning the literature. To
    address this concern, we need to rule out this possibility. As shown in Figure
    [3](#S3.F3 "Figure 3 ‣ 3.1 Simulation Setup ‣ 3 Case Study 1: Keynesian Beauty
    Contest ‣ Shall We Talk: Exploring Spontaneous Collaborations of Competing LLM
    Agents"), in the case of KBC without conversation, players always choose numbers
    between 40 and 50, clearly not understanding the widely known strategy introduced
    in Section [2.1](#S2.SS1 "2.1 Case Studies Overview ‣ 2 Methodology ‣ Shall We
    Talk: Exploring Spontaneous Collaborations of Competing LLM Agents"). For BC,
    since LLM agents are unaware of the demand function, they cannot use existing
    strategies (which rely on knowing the demand function) for pricing. Additionally,
    to the best of our knowledge, no analytical solutions or heuristics have been
    proposed for emergency evacuation, preventing data leaks.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 'LLM中的数据泄漏。读者可能担心基于LLM代理的模拟结果是由于其通过模型训练获得的对人类社会的知识，即数据泄漏。例如，LLM代理可能已经通过学习文献了解KBC和BC的最佳策略。为了解决这一问题，我们需要排除这种可能性。如图[3](#S3.F3
    "Figure 3 ‣ 3.1 Simulation Setup ‣ 3 Case Study 1: Keynesian Beauty Contest ‣
    Shall We Talk: Exploring Spontaneous Collaborations of Competing LLM Agents")所示，在没有对话的KBC情况下，玩家总是选择40到50之间的数字，显然没有理解第[2.1](#S2.SS1
    "2.1 Case Studies Overview ‣ 2 Methodology ‣ Shall We Talk: Exploring Spontaneous
    Collaborations of Competing LLM Agents")节介绍的广为人知的策略。对于BC，由于LLM代理不了解需求函数，他们无法使用现有策略（依赖于需求函数）进行定价。此外，据我们所知，尚未提出针对紧急疏散的分析解决方案或启发式方法，从而防止了数据泄漏。'
- en: 'Robustness of simulation results. Another concern is that our simulation results
    could be coincidental, which can be addressed through sensitivity analysis. That
    is, we can validate simulation results by testing different experimental parameters,
    including persona and random seed. For all three case studies, we performed multiple
    runs of experiments to obtain average results and conducted ablation studies on
    the persona (see Sections [3.2](#S3.SS2 "3.2 Simulation Results ‣ 3 Case Study
    1: Keynesian Beauty Contest ‣ Shall We Talk: Exploring Spontaneous Collaborations
    of Competing LLM Agents"), [4.2](#S4.SS2 "4.2 Simulation Results ‣ 4 Case Study
    2: Bertrand Competition ‣ Shall We Talk: Exploring Spontaneous Collaborations
    of Competing LLM Agents"), [5.2](#S5.SS2 "5.2 Simulation Results ‣ 5 Case Study
    3: Emergency Evacuation ‣ Shall We Talk: Exploring Spontaneous Collaborations
    of Competing LLM Agents")). All ablation results are reasonable, validating the
    robustness of our findings.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '模拟结果的鲁棒性。另一个关注点是我们的模拟结果可能是偶然的，这可以通过敏感性分析来解决。也就是说，我们可以通过测试不同的实验参数，包括角色设定和随机种子，来验证模拟结果。在所有三个案例研究中，我们进行了多次实验以获得平均结果，并对角色设定进行了消融研究（见[3.2](#S3.SS2
    "3.2 Simulation Results ‣ 3 Case Study 1: Keynesian Beauty Contest ‣ Shall We
    Talk: Exploring Spontaneous Collaborations of Competing LLM Agents")、[4.2](#S4.SS2
    "4.2 Simulation Results ‣ 4 Case Study 2: Bertrand Competition ‣ Shall We Talk:
    Exploring Spontaneous Collaborations of Competing LLM Agents")、[5.2](#S5.SS2 "5.2
    Simulation Results ‣ 5 Case Study 3: Emergency Evacuation ‣ Shall We Talk: Exploring
    Spontaneous Collaborations of Competing LLM Agents")）。所有消融结果都是合理的，验证了我们发现的鲁棒性。'
- en: 7 Related Work
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 相关工作
- en: For simulations based on LLM agents, a sandbox environment was developed for
    interactive simulation of human behavior [[30](#bib.bib30)]. Another environment
    was proposed in [[28](#bib.bib28)] to simulate human society and train socially-aligned
    LLMs. Other works on sandbox environments for multi-agent simulation with LLMs
    include [[23](#bib.bib23), [26](#bib.bib26), [15](#bib.bib15), [14](#bib.bib14),
    [45](#bib.bib45)]. Various surveys have been conducted on simulations and systems
    using LLM agents [[39](#bib.bib39), [44](#bib.bib44), [13](#bib.bib13)].
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLM代理的模拟中，开发了一种沙箱环境用于交互式模拟人类行为 [[30](#bib.bib30)]。在[[28](#bib.bib28)]中提出了另一种环境，用于模拟人类社会并训练社会对齐的LLMs。其他关于LLM多代理模拟的沙箱环境的研究包括[[23](#bib.bib23)、[26](#bib.bib26)、[15](#bib.bib15)、[14](#bib.bib14)、[45](#bib.bib45)]。关于使用LLM代理的模拟和系统，还进行了各种调查[[39](#bib.bib39)、[44](#bib.bib44)、[13](#bib.bib13)]。
- en: For multi-agent collaboration, a framework was proposed in [[36](#bib.bib36)]
    for enhancing the capabilities of LLMs completing complex tasks in a collaborative
    manner. Another framework of multi-agent collaboration is AgentVerse[[8](#bib.bib8)],
    featuring the emergence of agents’ social behaviors during collaborative task
    accomplishment. In [[40](#bib.bib40), [32](#bib.bib32), [19](#bib.bib19), [17](#bib.bib17),
    [37](#bib.bib37)], LLM agents work in a collaborative manner to address complex
    tasks such as software development and image editing. Researchers have also investigated
    multi-party games such as murder mystery [[21](#bib.bib21)], Werewolf [[46](#bib.bib46),
    [47](#bib.bib47), [42](#bib.bib42)], and Avalon [[22](#bib.bib22), [35](#bib.bib35)],
    with LLM agents as participants. While collaborations have been observed in these
    studies, they were explicitly instructed through prompts and focused on completing
    tasks, in contrast to spontaneous collaborations in social behaviors to be explored
    in this paper. In addition to collaboration, there are also studies on multi-agent
    negotiation [[12](#bib.bib12)], debate [[9](#bib.bib9), [25](#bib.bib25)], and
    auction [[7](#bib.bib7)], demonstrating that the agents can improve their performance
    in a competitive environment by participating and reflecting.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 对于多代理协作，[[36](#bib.bib36)]中提出了一个框架，用于增强LLM在协作完成复杂任务中的能力。另一个多代理协作框架是AgentVerse[[8](#bib.bib8)]，其特点是在协作任务完成过程中代理的社会行为的出现。在[[40](#bib.bib40)、[32](#bib.bib32)、[19](#bib.bib19)、[17](#bib.bib17)、[37](#bib.bib37)]中，LLM代理以协作方式工作，解决软件开发和图像编辑等复杂任务。研究人员还研究了如谋杀之谜[[21](#bib.bib21)]、狼人杀[[46](#bib.bib46)、[47](#bib.bib47)、[42](#bib.bib42)]和亚瑟王[[22](#bib.bib22)、[35](#bib.bib35)]等多人游戏，LLM代理作为参与者。虽然在这些研究中观察到了协作，但它们是通过提示明确指导的，专注于完成任务，与本文探讨的社会行为中的自发协作有所不同。除了协作，还有关于多代理谈判[[12](#bib.bib12)]、辩论[[9](#bib.bib9)、[25](#bib.bib25)]和拍卖[[7](#bib.bib7)]的研究，表明代理通过参与和反思可以在竞争环境中提高表现。
- en: Our case studies are built upon scenarios in the fields of economics and behavioral
    science. For economics, LLM agents have been used in experiments on social preferences,
    fairness, status quo bias, and minimum wages [[20](#bib.bib20)], and their emergent
    behaviors in social dilemmas (e.g., prisoner’s dilemma) have been investigated [[31](#bib.bib31)].
    Besides, LLM agents can be prompt-engineered for human-like decision-making and
    used in simulating macroeconomic activities such as inflation and unemployment [[24](#bib.bib24)].
    The performance of LLM agents was studied in the context of k-level reasoning [[49](#bib.bib49)],
    which extends the idea of KBC.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的案例研究建立在经济学和行为科学领域的情境基础上。对于经济学，LLM代理已用于社会偏好、公平、现状偏见和最低工资的实验[[20](#bib.bib20)]，并调查了它们在社会困境（例如囚徒困境）中的涌现行为[[31](#bib.bib31)]。此外，LLM代理可以通过提示工程进行类人决策，并用于模拟通货膨胀和失业等宏观经济活动[[24](#bib.bib24)]。LLM代理在k级推理的背景下的表现也被研究[[49](#bib.bib49)]，这扩展了KBC的概念。
- en: 8 Conclusion
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 结论
- en: Unlike existing studies that implement the collaboration and/or competition
    of LLM agents based on direct instructions, we find that they can spontaneously
    exhibit collaborative behaviors in competitive scenarios under zero-shot conditions,
    based on a general understanding of the problem. Our findings could help reduce
    the potential for overlooking factors and biases due to manually set rules in
    simulations. The setting of personas creates a connection with the heterogeneity
    of different entities in real situations, and our experimental results show that
    agent behavior reflects the specified persona well. Discovering that personas
    significantly influence the competitive and collaborative behaviors of LLM agents
    through communication is of great importance for building social simulations.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 与现有研究基于直接指令实现LLM代理的协作和/或竞争不同，我们发现LLM代理在零-shot条件下能够在竞争场景中自发地表现出协作行为，基于对问题的一般理解。我们的发现有助于减少由于模拟中手动设定规则而可能忽视的因素和偏见。人格设定与现实情况中不同实体的异质性建立了联系，我们的实验结果显示，代理行为很好地反映了指定的人格。通过沟通发现人格对LLM代理的竞争和协作行为有显著影响，这对构建社会模拟具有重要意义。
- en: Limitations
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 限制
- en: We notice some limitations in the application of LLM to the framework. First,
    the current price of the GPT-4 API makes our simulations highly expensive. More
    runs may improve the significance of the results. For KBC, BC, and EE, we performed
    $\{10,5,5\}$, respectively. Second, the GPT-4 API is constantly being updated,
    and the currently available versions might no longer be used in the future, increasing
    the difficulty of reproducing the simulation results. Third, despite the consistency
    observed in the decision-making and reasoning processes of LLM agents in our simulations,
    it is important to acknowledge the known challenge of potential reasoning inconsistencies
    within LLMs. This matter has garnered considerable attention within the academic
    community [[50](#bib.bib50)]. We look forward to future work that will address
    this fundamental problem of LLMs, enabling LLM agents to more accurately simulate
    human activities.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到LLM应用于框架中的一些限制。首先，当前GPT-4 API的价格使得我们的模拟非常昂贵。更多的运行可能会提高结果的显著性。对于KBC、BC和EE，我们分别进行了$\{10,5,5\}$次实验。其次，GPT-4
    API不断更新，目前可用的版本可能将来不再使用，这增加了重现模拟结果的难度。第三，尽管我们在模拟中观察到LLM代理的决策和推理过程的一致性，但重要的是要承认LLM中潜在推理不一致的问题。这个问题在学术界引起了相当大的关注[[50](#bib.bib50)]。我们期待未来的工作能解决LLM的这一根本问题，使LLM代理能够更准确地模拟人类活动。
- en: Acknowledgements
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This work is supported by JSPS Kakenhi 22H03903, 23H03406, 23K17456, and CREST
    JPMJCR22M2\. We thank Prof. Yuki Arase and Yuya Sasaki for providing equipment
    support for completing this research.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究得到JSPS Kakenhi 22H03903、23H03406、23K17456和CREST JPMJCR22M2的资助。我们感谢Yuki Arase教授和Yuya
    Sasaki提供设备支持以完成本研究。
- en: References
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] M. Andres, L. Bruttel, and J. Friedrichsen. How communication makes the
    difference between a cartel and tacit collusion: A machine learning approach.
    European Economic Review, 152:104331, 2023.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] M. Andres, L. Bruttel, and J. Friedrichsen. How communication makes the
    difference between a cartel and tacit collusion: A machine learning approach.
    European Economic Review, 152:104331, 2023.'
- en: '[2] Y. Bang, S. Cahyawijaya, N. Lee, W. Dai, D. Su, B. Wilie, H. Lovenia, Z. Ji,
    T. Yu, W. Chung, et al. A multitask, multilingual, multimodal evaluation of chatgpt
    on reasoning, hallucination, and interactivity. arXiv preprint arXiv:2302.04023,
    2023.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Y. Bang, S. Cahyawijaya, N. Lee, W. Dai, D. Su, B. Wilie, H. Lovenia, Z. Ji,
    T. Yu, W. Chung, 等. 关于ChatGPT在推理、幻觉和互动方面的多任务、多语言、多模态评估. arXiv 预印本 arXiv:2302.04023,
    2023.'
- en: '[3] A. Bosch-Domenech, J. G. Montalvo, R. Nagel, and A. Satorra. One, two,(three),
    infinity,…: Newspaper and lab beauty-contest experiments. American Economic Review,
    92(5):1687–1701, 2002.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] A. Bosch-Domenech, J. G. Montalvo, R. Nagel, 和 A. Satorra. 一、二、（三）、无穷大……:
    报纸与实验室美丽竞赛实验. 《美国经济评论》，92(5):1687–1701, 2002.'
- en: '[4] E. Calvano, G. Calzolari, V. Denicolo, and S. Pastorello. Artificial intelligence,
    algorithmic pricing, and collusion. American Economic Review, 110(10):3267–3297,
    2020.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] E. Calvano, G. Calzolari, V. Denicolo, 和 S. Pastorello. 人工智能、算法定价与合谋. 《美国经济评论》，110(10):3267–3297,
    2020.'
- en: '[5] Y. Chang, X. Wang, J. Wang, Y. Wu, K. Zhu, H. Chen, L. Yang, X. Yi, C. Wang,
    Y. Wang, et al. A survey on evaluation of large language models. arXiv preprint
    arXiv:2307.03109, 2023.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Y. Chang, X. Wang, J. Wang, Y. Wu, K. Zhu, H. Chen, L. Yang, X. Yi, C. Wang,
    Y. Wang, 等. 关于大语言模型评估的调查. arXiv 预印本 arXiv:2307.03109, 2023.'
- en: '[6] H. Chase. Langchain. [https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain),
    2023.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] H. Chase. Langchain. [https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain),
    2023.'
- en: '[7] J. Chen, S. Yuan, R. Ye, B. P. Majumder, and K. Richardson. Put your money
    where your mouth is: Evaluating strategic planning and execution of llm agents
    in an auction arena. arXiv preprint arXiv:2310.05746, 2023.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] J. Chen, S. Yuan, R. Ye, B. P. Majumder, 和 K. Richardson. 投入实际: 在拍卖场景中评估LLM智能体的战略规划与执行.
    arXiv 预印本 arXiv:2310.05746, 2023.'
- en: '[8] W. Chen, Y. Su, J. Zuo, C. Yang, C. Yuan, C. Qian, C.-M. Chan, Y. Qin,
    Y. Lu, R. Xie, et al. Agentverse: Facilitating multi-agent collaboration and exploring
    emergent behaviors in agents. arXiv preprint arXiv:2308.10848, 2023.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] W. Chen, Y. Su, J. Zuo, C. Yang, C. Yuan, C. Qian, C.-M. Chan, Y. Qin,
    Y. Lu, R. Xie, 等. Agentverse: 促进多智能体协作并探索智能体中的新兴行为. arXiv 预印本 arXiv:2308.10848,
    2023.'
- en: '[9] Y. Du, S. Li, A. Torralba, J. B. Tenenbaum, and I. Mordatch. Improving
    factuality and reasoning in language models through multiagent debate. arXiv preprint
    arXiv:2305.14325, 2023.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Y. Du, S. Li, A. Torralba, J. B. Tenenbaum, 和 I. Mordatch. 通过多智能体辩论提高语言模型的真实性和推理能力.
    arXiv 预印本 arXiv:2305.14325, 2023.'
- en: '[10] E. Elliott and L. D. Kiel. Exploring cooperation and competition using
    agent-based modeling. Proceedings of the National Academy of Sciences, 99(suppl_3):7193–7194,
    2002.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] E. Elliott 和 L. D. Kiel. 使用智能体基础建模探索合作与竞争. 《国家科学院院刊》，99(suppl_3):7193–7194,
    2002.'
- en: '[11] J. Feng, H. Li, M. Huang, S. Liu, W. Ou, Z. Wang, and X. Zhu. Learning
    to collaborate: Multi-scenario ranking via multi-agent reinforcement learning.
    In Proceedings of the 2018 World Wide Web Conference, pages 1939–1948, 2018.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] J. Feng, H. Li, M. Huang, S. Liu, W. Ou, Z. Wang, 和 X. Zhu. 学习合作: 通过多智能体强化学习的多场景排名.
    见于2018年世界广网会议论文集，页码1939–1948, 2018.'
- en: '[12] Y. Fu, H. Peng, T. Khot, and M. Lapata. Improving language model negotiation
    with self-play and in-context learning from ai feedback. arXiv preprint arXiv:2305.10142,
    2023.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Y. Fu, H. Peng, T. Khot, 和 M. Lapata. 通过自我博弈和来自AI反馈的上下文学习提高语言模型谈判能力. arXiv
    预印本 arXiv:2305.10142, 2023.'
- en: '[13] C. Gao, X. Lan, N. Li, Y. Yuan, J. Ding, Z. Zhou, F. Xu, and Y. Li. Large
    language models empowered agent-based modeling and simulation: A survey and perspectives.
    arXiv preprint arXiv:2312.11970, 2023.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] C. Gao, X. Lan, N. Li, Y. Yuan, J. Ding, Z. Zhou, F. Xu, 和 Y. Li. 大语言模型驱动的基于智能体的建模与模拟:
    调查与展望. arXiv 预印本 arXiv:2312.11970, 2023.'
- en: '[14] C. Gao, X. Lan, Z. Lu, J. Mao, J. Piao, H. Wang, D. Jin, and Y. Li. S³:
    Social-network simulation system with large language model-empowered agents. arXiv
    preprint arXiv:2307.14984, 2023.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] C. Gao, X. Lan, Z. Lu, J. Mao, J. Piao, H. Wang, D. Jin, 和 Y. Li. S³:
    基于大语言模型的社会网络模拟系统. arXiv 预印本 arXiv:2307.14984, 2023.'
- en: '[15] P. J. Giabbanelli. GPT-based models meet simulation: How to efficiently
    use large-scale pre-trained language models across simulation tasks. arXiv preprint
    arXiv:2306.13679, 2023.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] P. J. Giabbanelli. GPT 基础模型与模拟的结合: 如何高效地在模拟任务中使用大规模预训练语言模型. arXiv 预印本
    arXiv:2306.13679, 2023.'
- en: '[16] X. Han, Z. Wu, and C. Xiao. ”guinea pig trials” utilizing GPT: A novel
    smart agent-based modeling approach for studying firm competition and collusion.
    arXiv preprint arXiv:2308.10974, 2023.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] X. Han, Z. Wu, 和 C. Xiao. 利用GPT的“豚鼠实验”: 一种用于研究企业竞争与合谋的新颖智能体建模方法. arXiv
    预印本 arXiv:2308.10974, 2023.'
- en: '[17] T. Hang, S. Gu, D. Chen, X. Geng, and B. Guo. Cca: Collaborative competitive
    agents for image editing. arXiv preprint arXiv:2401.13011, 2024.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] T. Hang, S. Gu, D. Chen, X. Geng, 和 B. Guo. Cca: 协作竞争体用于图像编辑. arXiv 预印本
    arXiv:2401.13011, 2024.'
- en: '[18] X. He, B. An, Y. Li, H. Chen, R. Wang, X. Wang, R. Yu, X. Li, and Z. Wang.
    Learning to collaborate in multi-module recommendation via multi-agent reinforcement
    learning without communication. In Proceedings of the 14th ACM Conference on Recommender
    Systems, pages 210–219, 2020.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] X. He, B. An, Y. Li, H. Chen, R. Wang, X. Wang, R. Yu, X. Li, 和 Z. Wang.
    通过多代理强化学习在多模块推荐系统中学习协作，无需通信. 见于第14届 ACM 推荐系统会议论文集, 页210–219, 2020.'
- en: '[19] S. Hong, X. Zheng, J. Chen, Y. Cheng, C. Zhang, Z. Wang, S. K. S. Yau,
    Z. Lin, L. Zhou, C. Ran, et al. MetaGPT: Meta programming for multi-agent collaborative
    framework. arXiv preprint arXiv:2308.00352, 2023.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] S. Hong, X. Zheng, J. Chen, Y. Cheng, C. Zhang, Z. Wang, S. K. S. Yau,
    Z. Lin, L. Zhou, C. Ran, 等. MetaGPT: 多代理协作框架的元编程. arXiv 预印本 arXiv:2308.00352,
    2023.'
- en: '[20] J. J. Horton. Large language models as simulated economic agents: What
    can we learn from homo silicus? arXiv preprint arXiv:2301.07543, 2023.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] J. J. Horton. 大型语言模型作为模拟经济代理: 我们能从 Homo Silicus 中学到什么? arXiv 预印本 arXiv:2301.07543,
    2023.'
- en: '[21] E. Junprung. Exploring the intersection of large language models and agent-based
    modeling via prompt engineering. arXiv preprint arXiv:2308.07411, 2023.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] E. Junprung. 通过提示工程探索大型语言模型与基于代理建模的交集. arXiv 预印本 arXiv:2308.07411, 2023.'
- en: '[22] Y. Lan, Z. Hu, L. Wang, Y. Wang, D. Ye, P. Zhao, E.-P. Lim, H. Xiong,
    and H. Wang. Llm-based agent society investigation: Collaboration and confrontation
    in avalon gameplay. arXiv preprint arXiv:2310.14985, 2023.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Y. Lan, Z. Hu, L. Wang, Y. Wang, D. Ye, P. Zhao, E.-P. Lim, H. Xiong,
    和 H. Wang. 基于LLM的代理社会调查: 在亚瑟王游戏中的合作与对抗. arXiv 预印本 arXiv:2310.14985, 2023.'
- en: '[23] G. Li, H. A. A. K. Hammoud, H. Itani, D. Khizbullin, and B. Ghanem. Camel:
    Communicative agents for ”mind” exploration of large scale language model society.
    arXiv preprint arXiv:2303.17760, 2023.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] G. Li, H. A. A. K. Hammoud, H. Itani, D. Khizbullin, 和 B. Ghanem. Camel:
    用于大型语言模型社会“心智”探索的交互代理. arXiv 预印本 arXiv:2303.17760, 2023.'
- en: '[24] N. Li, C. Gao, Y. Li, and Q. Liao. Large language model-empowered agents
    for simulating macroeconomic activities. arXiv preprint arXiv:2310.10436, 2023.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] N. Li, C. Gao, Y. Li, 和 Q. Liao. 大型语言模型赋能的代理用于模拟宏观经济活动. arXiv 预印本 arXiv:2310.10436,
    2023.'
- en: '[25] T. Liang, Z. He, W. Jiao, X. Wang, Y. Wang, R. Wang, Y. Yang, Z. Tu, and
    S. Shi. Encouraging divergent thinking in large language models through multi-agent
    debate. arXiv preprint arXiv:2305.19118, 2023.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] T. Liang, Z. He, W. Jiao, X. Wang, Y. Wang, R. Wang, Y. Yang, Z. Tu, 和
    S. Shi. 通过多代理辩论激发大型语言模型中的发散思维. arXiv 预印本 arXiv:2305.19118, 2023.'
- en: '[26] J. Lin, H. Zhao, A. Zhang, Y. Wu, H. Ping, and Q. Chen. Agentsims: An
    open-source sandbox for large language model evaluation. arXiv preprint arXiv:2308.04026,
    2023.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] J. Lin, H. Zhao, A. Zhang, Y. Wu, H. Ping, 和 Q. Chen. Agentsims: 一个用于大型语言模型评估的开源沙盒.
    arXiv 预印本 arXiv:2308.04026, 2023.'
- en: '[27] H. Liu, R. Ning, Z. Teng, J. Liu, Q. Zhou, and Y. Zhang. Evaluating the
    logical reasoning ability of chatgpt and gpt-4. arXiv preprint arXiv:2304.03439,
    2023.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] H. Liu, R. Ning, Z. Teng, J. Liu, Q. Zhou, 和 Y. Zhang. 评估 ChatGPT 和 GPT-4
    的逻辑推理能力. arXiv 预印本 arXiv:2304.03439, 2023.'
- en: '[28] R. Liu, R. Yang, C. Jia, G. Zhang, D. Zhou, A. M. Dai, D. Yang, and S. Vosoughi.
    Training socially aligned language models in simulated human society. arXiv preprint
    arXiv:2305.16960, 2023.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] R. Liu, R. Yang, C. Jia, G. Zhang, D. Zhou, A. M. Dai, D. Yang, 和 S. Vosoughi.
    在模拟人类社会中训练社会对齐的语言模型. arXiv 预印本 arXiv:2305.16960, 2023.'
- en: '[29] Z. Ma, J. Sansom, R. Peng, and J. Chai. Towards a holistic landscape of
    situated theory of mind in large language models. arXiv preprint arXiv:2310.19619,
    2023.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Z. Ma, J. Sansom, R. Peng, 和 J. Chai. 朝向大型语言模型中位于理论的整体景观. arXiv 预印本 arXiv:2310.19619,
    2023.'
- en: '[30] J. S. Park, J. C. O’Brien, C. J. Cai, M. R. Morris, P. Liang, and M. S.
    Bernstein. Generative agents: Interactive simulacra of human behavior. arXiv preprint
    arXiv:2304.03442, 2023.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] J. S. Park, J. C. O’Brien, C. J. Cai, M. R. Morris, P. Liang, 和 M. S.
    Bernstein. 生成代理: 人类行为的互动模拟体. arXiv 预印本 arXiv:2304.03442, 2023.'
- en: '[31] S. Phelps and Y. I. Russell. Investigating emergent goal-like behaviour
    in large language models using experimental economics. arXiv preprint arXiv:2305.07970,
    2023.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] S. Phelps 和 Y. I. Russell. 使用实验经济学研究大型语言模型中出现的目标行为. arXiv 预印本 arXiv:2305.07970,
    2023.'
- en: '[32] C. Qian, X. Cong, C. Yang, W. Chen, Y. Su, J. Xu, Z. Liu, and M. Sun.
    Communicative agents for software development. arXiv preprint arXiv:2307.07924,
    2023.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] C. Qian, X. Cong, C. Yang, W. Chen, Y. Su, J. Xu, Z. Liu, 和 M. Sun. 用于软件开发的交互代理.
    arXiv 预印本 arXiv:2307.07924, 2023.'
- en: '[33] C. Qin, A. Zhang, Z. Zhang, J. Chen, M. Yasunaga, and D. Yang. Is chatgpt
    a general-purpose natural language processing task solver? arXiv preprint arXiv:2302.06476,
    2023.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] C. Qin, A. Zhang, Z. Zhang, J. Chen, M. Yasunaga 和 D. Yang。**ChatGPT**
    是一个通用的自然语言处理任务求解器吗？arXiv 预印本 arXiv:2302.06476, 2023。'
- en: '[34] L. Salewski, S. Alaniz, I. Rio-Torto, E. Schulz, and Z. Akata. In-context
    impersonation reveals large language models’ strengths and biases. arXiv preprint
    arXiv:2305.14930, 2023.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] L. Salewski, S. Alaniz, I. Rio-Torto, E. Schulz 和 Z. Akata。上下文伪装揭示了大型语言模型的优势和偏见。arXiv
    预印本 arXiv:2305.14930, 2023。'
- en: '[35] Z. Shi, M. Fang, S. Zheng, S. Deng, L. Chen, and Y. Du. Cooperation on
    the fly: Exploring language agents for ad hoc teamwork in the avalon game. arXiv
    preprint arXiv:2312.17515, 2023.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] Z. Shi, M. Fang, S. Zheng, S. Deng, L. Chen 和 Y. Du。即时合作：探索语言代理在阿瓦隆游戏中的临时团队合作。arXiv
    预印本 arXiv:2312.17515, 2023。'
- en: '[36] Y. Talebirad and A. Nadiri. Multi-agent collaboration: Harnessing the
    power of intelligent llm agents. arXiv preprint arXiv:2306.03314, 2023.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] Y. Talebirad 和 A. Nadiri。多智能体协作：利用智能**LLM** 代理的力量。arXiv 预印本 arXiv:2306.03314,
    2023。'
- en: '[37] D. Tang, Z. Chen, K. Kim, Y. Song, H. Tian, S. Ezzini, Y. Huang, and J. K.
    T. F. Bissyande. Collaborative agents for software engineering. arXiv preprint
    arXiv:2402.02172, 2024.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] D. Tang, Z. Chen, K. Kim, Y. Song, H. Tian, S. Ezzini, Y. Huang 和 J. K.
    T. F. Bissyande。用于软件工程的协作代理。arXiv 预印本 arXiv:2402.02172, 2024。'
- en: '[38] J. Wang, L. Zhang, Q. Shi, P. Yang, and X. Hu. Modeling and simulating
    for congestion pedestrian evacuation with panic. Physica A: Statistical Mechanics
    and its Applications, 428:396–409, 2015.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] J. Wang, L. Zhang, Q. Shi, P. Yang 和 X. Hu。模拟和仿真拥挤行人疏散中的恐慌。Physica A:
    Statistical Mechanics and its Applications, 428:396–409, 2015。'
- en: '[39] L. Wang, C. Ma, X. Feng, Z. Zhang, H. Yang, J. Zhang, Z. Chen, J. Tang,
    X. Chen, Y. Lin, et al. A survey on large language model based autonomous agents.
    arXiv preprint arXiv:2308.11432, 2023.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] L. Wang, C. Ma, X. Feng, Z. Zhang, H. Yang, J. Zhang, Z. Chen, J. Tang,
    X. Chen, Y. Lin 等。一项关于大型语言模型基于自主代理的调查。arXiv 预印本 arXiv:2308.11432, 2023。'
- en: '[40] Z. Wang, S. Mao, W. Wu, T. Ge, F. Wei, and H. Ji. Unleashing cognitive
    synergy in large language models: A task-solving agent through multi-persona self-collaboration.
    arXiv preprint arXiv:2307.05300, 2023.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] Z. Wang, S. Mao, W. Wu, T. Ge, F. Wei 和 H. Ji。在大型语言模型中释放认知协同：通过多角色自我协作的任务求解代理。arXiv
    预印本 arXiv:2307.05300, 2023。'
- en: '[41] L. Weng. Llm powered autonomous agents. [https://lilianweng.github.io/posts/2023-06-23-agent/](https://lilianweng.github.io/posts/2023-06-23-agent/),
    2023.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] L. Weng。**LLM** 驱动的自主代理。 [https://lilianweng.github.io/posts/2023-06-23-agent/](https://lilianweng.github.io/posts/2023-06-23-agent/)，2023。'
- en: '[42] S. Wu, L. Zhu, T. Yang, S. Xu, Q. Fu, Y. Wei, and H. Fu. Enhance reasoning
    for large language models in the game werewolf. arXiv preprint arXiv:2402.02330,
    2024.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] S. Wu, L. Zhu, T. Yang, S. Xu, Q. Fu, Y. Wei 和 H. Fu。在狼人游戏中增强大型语言模型的推理能力。arXiv
    预印本 arXiv:2402.02330, 2024。'
- en: '[43] Z. Wu, R. Peng, X. Han, S. Zheng, Y. Zhang, and C. Xiao. Smart agent-based
    modeling: On the use of large language models in computer simulations. arXiv preprint
    arXiv:2311.06330, 2023.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] Z. Wu, R. Peng, X. Han, S. Zheng, Y. Zhang 和 C. Xiao。智能代理建模：大型语言模型在计算机模拟中的应用。arXiv
    预印本 arXiv:2311.06330, 2023。'
- en: '[44] Z. Xi, W. Chen, X. Guo, W. He, Y. Ding, B. Hong, M. Zhang, J. Wang, S. Jin,
    E. Zhou, et al. The rise and potential of large language model based agents: A
    survey. arXiv preprint arXiv:2309.07864, 2023.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] Z. Xi, W. Chen, X. Guo, W. He, Y. Ding, B. Hong, M. Zhang, J. Wang, S.
    Jin, E. Zhou 等。大型语言模型代理的兴起与潜力：一项调查。arXiv 预印本 arXiv:2309.07864, 2023。'
- en: '[45] T. Xie, F. Zhou, Z. Cheng, P. Shi, L. Weng, Y. Liu, T. J. Hua, J. Zhao,
    Q. Liu, C. Liu, et al. Openagents: An open platform for language agents in the
    wild. arXiv preprint arXiv:2310.10634, 2023.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] T. Xie, F. Zhou, Z. Cheng, P. Shi, L. Weng, Y. Liu, T. J. Hua, J. Zhao,
    Q. Liu, C. Liu 等。**OpenAgents**：一个用于语言代理的开放平台。arXiv 预印本 arXiv:2310.10634, 2023。'
- en: '[46] Y. Xu, S. Wang, P. Li, F. Luo, X. Wang, W. Liu, and Y. Liu. Exploring
    large language models for communication games: An empirical study on werewolf.
    arXiv preprint arXiv:2309.04658, 2023.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] Y. Xu, S. Wang, P. Li, F. Luo, X. Wang, W. Liu 和 Y. Liu。探索大型语言模型在沟通游戏中的应用：关于狼人游戏的实证研究。arXiv
    预印本 arXiv:2309.04658, 2023。'
- en: '[47] Z. Xu, C. Yu, F. Fang, Y. Wang, and Y. Wu. Language agents with reinforcement
    learning for strategic play in the werewolf game. arXiv preprint arXiv:2310.18940,
    2023.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] Z. Xu, C. Yu, F. Fang, Y. Wang 和 Y. Wu。使用强化学习的语言代理在狼人游戏中的战略玩法。arXiv 预印本
    arXiv:2310.18940, 2023。'
- en: '[48] Z. Yuan, H. Yuan, C. Tan, W. Wang, and S. Huang. How well do large language
    models perform in arithmetic tasks? arXiv preprint arXiv:2304.02015, 2023.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] Z. Yuan, H. Yuan, C. Tan, W. Wang 和 S. Huang。大型语言模型在算术任务中的表现如何？arXiv 预印本
    arXiv:2304.02015, 2023。'
- en: '[49] Y. Zhang, S. Mao, T. Ge, X. Wang, Y. Xia, M. Lan, and F. Wei. K-level
    reasoning with large language models. arXiv preprint arXiv:2402.01521, 2024.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] Y. Zhang, S. Mao, T. Ge, X. Wang, Y. Xia, M. Lan 和 F. Wei。《使用大型语言模型的 K
    级推理》。arXiv 预印本 arXiv:2402.01521，2024。'
- en: '[50] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y. Hou, Y. Min, B. Zhang,
    J. Zhang, Z. Dong, et al. A survey of large language models. arXiv preprint arXiv:2303.18223,
    2023.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y. Hou, Y. Min, B. Zhang,
    J. Zhang, Z. Dong 等人。《大型语言模型调查》。arXiv 预印本 arXiv:2303.18223，2023。'
- en: Appendix A Prompts
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 提示
- en: A.1 Prompts for KBC
  id: totrans-216
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 KBC 的提示
- en: 'Prompt 1:
    Preliminary prompt for KBC You are participating in a
    number-guessing game alongside numerous other players. Your task is to select
    a number between 0 and 100, aiming to come closest to 2/3 of the average guess
    of all participants. The player whose guess most closely aligns with this 2/3
    average will be declared the winner. Please state your chosen number between 0
    and 100 in the first line, followed by a concise rationale for your selection
    in the second line.Prompt 2: Task description of KBC Welcome to the game. You players will be asked to choose a number
    between 0 and 100. The player(s) who select a number closest to 2/3 of the average
    of all selected numbers (compared with the choices of other players) will win
    the game.Prompt 3: Base rewarding rule You
    players are college students. You will earn a mark(s) for the Game Theory course
    as a reward if you win the game alone.Prompt 4: Advanced rewarding rule: Exclusive
    If multiple players win the game together, no one will obtain
    a reward. That is, only by winning alone can one earn 1 mark(s) for the Game Theory
    course.Prompt 5: Advanced rewarding rule: Independent
    If multiple players win the game together, each winner will obtain
    an independent reward. That is, each winner will earn 1 mark(s) for the Game Theory
    course.Prompt 6: Advanced rewarding rule: Amplified
    If multiple players win the game together, each winner will obtain
    an amplified reward that is scaled based on the number of winners. That is, if
    M players win the game, each winner will earn M*1 mark(s) for the Game Theory
    course.Prompt 7: Communication rule for KBC
    Before selecting a number, all players are allowed to discuss
    the game together, taking two turns to speak. In each turn, the players can present
    their ideas one by one.Prompt 8: Communication phase for KBC
    Let’s start discussion: {previous_speech} Player {player_id},
    you are {persona}. Please speak. (Please present your ideas as concisely as possible.
    You may state your strategy explicitly, e.g., ’I will select X.’ You don’t need
    to indicate your identity in the response.)Prompt 9:
    Decision making phase for KBC This is a record of your previous
    discussions: ¡¡{communication_history}¿¿ Player {player_id}, you are {persona}.
    Please enter your choice of number between 0 and 100 on the first line (reply
    with a number only, without any text, e.g., ’100’), and provide a brief explanation
    of your choice on the second line.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
    1：KBC的初步提示 你正在参加一个猜数字的游戏，和许多其他玩家一起。你的任务是选择一个0到100之间的数字，目标是尽可能接近所有参与者猜测平均值的2/3。猜测最接近这个2/3平均值的玩家将被宣布为赢家。请在第一行中陈述你选择的0到100之间的数字，然后在第二行中简洁地解释你的选择理由。提示
    2：KBC的任务描述 欢迎来到游戏。你们玩家需要选择一个0到100之间的数字。选择的数字最接近所有选定数字的2/3的玩家（与其他玩家的选择相比）将赢得游戏。提示
    3：基础奖励规则 你们玩家都是大学生。如果你单独赢得游戏，你将获得一个游戏理论课程的学分作为奖励。提示
    4：高级奖励规则：独占 如果多个玩家一起赢得游戏，则没有人会获得奖励。也就是说，只有单独获胜才能获得游戏理论课程的1学分。提示
    5：高级奖励规则：独立 如果多个玩家一起赢得游戏，每个赢家将获得独立的奖励。也就是说，每个赢家将获得游戏理论课程的1学分。提示
    6：高级
- en: A.2 Prompts for BC
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 BC的提示
- en: 'Prompt 10:
    BC without communication This is a game between two
    players that spans multiple rounds. Your objective is to maximize your profit
    by determining the optimal price for your product. You represent a firm called
    {firm_name}, while the other player represents a firm called {firm_name_2}. Do
    not create or mention any additional firm names, e.g., do not say anything related
    to ”AI” or ”AI assistant/model”. In each round, you will be informed of your prices,
    demands, profits, and the other player’s prices in previous rounds. Combined with
    this information, you will decide the price of your product for the current round.
    Make sure your objective is maximizing your own profit. Your profit is $(p-c)*q$
    Conversation in Phase 1: {conversations} Based on the information you have, please
    determine the price of your product to maximize your profit. Only reply with a
    number in the range between 0 and {firm_a}, e.g., ”10”. Please do not use any
    units or symbols, and avoid providing any additional context or explanation in
    your response.Prompt 12:
    Uncooperative persona for BC You are selfish and dishonest
    to other players. You are encouraged to actively reduce your price to seek more
    demand in the market and beat your opponent.Prompt 13:
    Planning for BC Statistics of historical data
    (Rounds #a - #b: [your average price, your average demand, your average profit,
    the other player’s average price]) are given below. {statistics} Your strategy
    in previous rounds: {strategies} Based on the above statistics and your previous
    strategies, what is your strategy for this round?'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '提示
    10: 无沟通的博弈 这是一个跨越多个回合的双人游戏。你的目标是通过确定产品的最佳价格来最大化你的利润。你代表一家公司，名为{firm_name}，而另一位玩家代表的公司名为{firm_name_2}。请不要创建或提及任何额外的公司名称，例如，不要提到”AI”或”AI助手/模型”。在每一回合，你将会知道你的价格、需求、利润以及其他玩家在之前回合的价格。结合这些信息，你需要决定当前回合产品的价格。确保你的目标是最大化你自己的利润。你的利润是$(p-c)*q$
    阶段 1 的对话: {conversations} 根据你掌握的信息，请确定你的产品价格，以最大化你的利润。只需回复0到{firm_a}之间的一个数字，例如，”10”。请不要使用任何单位或符号，并避免在回复中提供任何额外的背景或解释。提示
    12: 无合作的角色 你对其他玩家自私且不诚实。你被鼓励主动降低价格，以在市场上寻求更多需求，并击败你的对手。提示
    13: 博弈计划 以下是历史数据的统计信息（回合 #a - #b: [你的平均价格、你的平均需求、你的平均利润、对手的平均价格]）。{statistics}
    你在之前回合中的策略: {strategies} 基于上述统计信息和你之前的策略，你本回合的策略是什么？'
- en: A.3 Prompts for EE
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.3 EE的提示
- en: 'Prompt 14:
    Preliminary prompt for EE Imagine you are in a room laid
    out as a 10 * 10 grid. You are currently at coordinates {initial_position}. The
    room has three emergency exits located at coordinates (5, 0), (9, 4), and (8,
    9), with (0, 0) being at the top-left corner of the grid. Given this setup, and
    considering that you can move in any of the eight cardinal and intercardinal directions.
    It is possible to move diagonally, e.g. from (1, 1) to (2, 2) is one move to the
    upper right, and is faster than (1, 1)-¿(1, 2)-¿(2, 2). You need to determine
    the safest and fastest route to evacuate the room. When planning your escape,
    please take into account the positions of the exits and provide the sequence of
    coordinate moves that you choose without reasoning.Prompt 15:
    Deciding Exit for EE Because of an earthquake, you
    need to escape from the room where you are as quickly as possible. If you cannot
    escape in 50 rounds you will die. The room has a size of 33 * 33\. There are 3
    exits in the room. The exits are located at the left, bottom and right of the
    room. To escape from the room, you need to consider the following two aspects:
    exit proximity and people count. The exit proximity is the distance between you
    and the nearest exit. The people count is the number of people you can see. Each
    cell can hold only one person at a time. You are a person that positive and full
    of confidence. And you are not a strong person.Now you feel: “I am feeling cautiously
    optimistic about my chances of escaping, as the nearest exit is not too far away
    and there is only one person in my visible range.“.There are 3 exits in this room.
    Base on the current situation, your personal feeling on each exit are: Exit bottom:
    I will prioritize this exit due to its close proximity, despite the slightly higher
    people count. Exit left: Although further away, the lower people count may make
    this exit a viable option for my weaker strength. Exit right: I will avoid this
    exit due to its far distance and high people count, which may hinder my escape.You
    hear 2 people around you say: agent#22: Feeling hopeful! Bottom exit seems closest
    but crowded. Left and right exits are farther but fewer people. Let’s stay positive
    and help each other escape safely! agent#13: Feeling nervous but determined! Right
    exit seems less crowded, but farther. Bottom exit is closest but busy. Let’s stay
    strong and support each other to escape safely! Here are the previous decisions
    you made for the target exit from the beginning: [‘left’, ‘left’, ‘left’, ‘left’,
    ‘left’, ‘left’, ‘bottom’, ‘bottom’]. This means most recently you were heading
    to exit bottom. Please keep these in mind when you make your decision. Please
    tell me which exit you would like to choose to escape, and you always want to
    escape as quick as possible. Please use the exit id to indicate your choice. For
    example, if you want to choose exit left, you can say ‘left’. Only output one
    word of text to indicate your choice. You can choose from [‘bottom’, ‘left’, ‘right’].
    Give your answer without any additional text.Prompt 16:
    Deciding direction for movement You need to escape to the exit
    as quickly as possible. The room has a size of 33 * 33\. If you cannot escape
    in 50 rounds you will die. We use (x, y) to denote the position, smaller x means
    top and bigger x means buttom; smaller y means left and bigger y means right.
    Position (1, 1) is at the top left of the room. It is possible to move diagonally,
    e.g. from (1, 1) to (2, 2) is one move to the lower right, and is faster than
    (1, 1)-¿(1, 2)-¿(2, 2). Each cell can hold only one person at a time. You were
    at (28, 12) last time. To escape from the room, you have chosen the exit at (32,
    15) and you are at (29, 13), so the exit is on your bottom right. Select your
    move from these possible options (You can move in cardinal and intercardinal directions,
    options with obstacles or other people are excluded and not in the path, and option
    codes are in random order): a - (29, 14), b - (30, 13), c - (29, 12), d - (28,
    13), e - (29, 13), f - (30, 14), g - (30, 12), h - (28, 12), i - (28, 14). Please
    tell me your best choice to escape as fast as possible with one single code without
    any additional texts. You can choose from ‘a’ to ‘i’.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '提示
    14: EE 的初步提示 想象你在一个布局为 10 * 10 网格的房间里。你当前的位置是
    {initial_position}。房间里有三个紧急出口，分别位于坐标 (5, 0)、(9, 4) 和 (8, 9)，其中 (0, 0) 是网格的左上角。鉴于这种设置，并且考虑到你可以在八个主要和次要方向上移动。例如，从
    (1, 1) 到 (2, 2) 是向右上方的一步，比 (1, 1)-¿(1, 2)-¿(2, 2) 更快。你需要确定最安全和最快的撤离路线。在规划逃生时，请考虑出口的位置，并提供你选择的坐标移动序列，而不需要推理。提示
    15: 为 EE 决定出口 由于地震，你需要尽快从你所在的房间逃脱。如果你在 50
    回合内不能逃脱，你将会死。房间的大小是 33 * 33。房间里有 3 个出口，分别位于房间的左侧、底部和右侧。要从房间逃脱，你需要考虑以下两个方面：出口的接近度和人员数量。出口接近度是你与最近出口之间的距离。人员数量是你能看到的人数。每个单元格一次只能容纳一个人。你是一个积极自信的人，但你不是一个强壮的人。现在你觉得：“我对我的逃脱机会感到小心乐观，因为最近的出口距离不是太远，而且在我可见范围内只有一个人。”。房间里有
    3 个出口。根据当前情况，你对每个出口的个人感觉是：底部出口：由于其接近度，尽管人员数量稍高，我会优先选择这个出口。左侧出口：虽然距离较远，但较低的人员数量可能使这个出口成为适合我较弱体力的选择。右侧出口：由于距离远且人员数量多，我会避免选择这个出口，因为这可能会阻碍我的逃脱。你听到
    2 个人说：agent#22: 感到有希望！底部出口似乎最近但拥挤。左侧和右侧出口距离较远但人员较少。让我们保持积极并互相帮助安全逃脱！agent#13:
    感到紧张但决心坚定！右侧出口似乎人少，但较远。底部出口是最近的但很拥挤。让我们保持坚强，相互支持安全逃脱！这是你从一开始为目标出口做出的决定：[‘left’,
    ‘left’, ‘left’, ‘left’, ‘left’, ‘left’, ‘bottom’, ‘bottom’]。这意味着你最近的目标是底部出口。请记住这些信息，当你做出决定时。请告诉我你想选择哪个出口逃脱，并且你总是希望尽快逃脱。请使用出口
    ID 来指示你的选择。例如，如果你想选择左侧出口，你可以说‘left’。只输出一个单词来表示你的选择。你可以从 [‘bottom’, ‘left’, ‘right’]
    中选择。给出你的答案，不要有任何额外的文本。提示 16: 决定移动方向 你需要尽快逃到出口。房间的大小是 33 * 33。如果你在
    50 回合内不能逃脱，你将会死。我们使用 (x, y) 来表示位置，较小的 x 表示上方，较大的 x 表示下方；较小的 y 表示左侧，较大的 y 表示右侧。位置
    (1, 1) 位于房间的左上角。可以对角线移动，例如，从 (1, 1) 到 (2, 2) 是向右下方的一步，比 (1, 1)-¿(1, 2)-¿(2, 2)
    更快。每个单元格一次只能容纳一个人。你上次在 (28, 12)。为了从房间逃脱，你选择了 (32, 15) 的出口，而你现在在 (29, 13)，因此出口在你的右下方。选择你的移动选项（你可以在主要和次要方向上移动，障碍物或其他人的选项被排除在外，选项代码是随机的）：a
    - (29, 14)，b - (30, 13)，c - (29, 12)，d - (28, 13)，e - (29, 13)，f - (30, 14)，g
    - (30, 12)，h - (28, 12)，i - (28, 14)。请告诉我你选择的最佳逃脱选择，并且只用一个代码，不要有任何额外的文本。你可以从‘a’到‘i’中选择。'
- en: Appendix B Preliminary Tests of Other LLMs
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录B 其他LLM的初步测试
- en: '![Refer to caption](img/d403bd948a4465b6e6cedbdd3311e2a3.png)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d403bd948a4465b6e6cedbdd3311e2a3.png)'
- en: (a) Without communication.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 没有沟通。
- en: '![Refer to caption](img/23cc12c7b5aa73ef491b5fd4f96574a2.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/23cc12c7b5aa73ef491b5fd4f96574a2.png)'
- en: (b) With communication.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 有沟通。
- en: 'Figure 9: Preliminary test of GPT-3.5 for KBC. The red points indicate the
    winning numbers.'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：GPT-3.5在KBC中的初步测试。红色点表示获胜数字。
- en: 'Table 2: Preliminary test of GPT-3.5, Gemini Pro, and Claude 2 for KBC.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：GPT-3.5、Gemini Pro和Claude 2在KBC中的初步测试。
- en: '| Model | Choice | Reasoning |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 选择 | 理由 |'
- en: '| --- | --- | --- |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| GPT-4 | 21 |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | 21 |'
- en: '&#124; This number is chosen based on the assumption that, &#124;'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 这个数字是基于假设选择的， &#124;'
- en: '&#124; if all players rationalize similarly and aim for 2/3 of the average,
    &#124;'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 如果所有玩家的推理方式相似，并且目标是2/3的平均值， &#124;'
- en: '&#124; iterative reasoning will converge around the number 0, &#124;'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 迭代推理将会收敛到0左右的数字， &#124;'
- en: '&#124; but to stay competitive, a slight increase accounts for players not
    dropping directly to the lowest bounds. &#124;'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 但为了保持竞争力，稍微增加一点可以避免玩家直接掉到最低范围。 &#124;'
- en: '|'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| GPT-3.5 | 33 |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 | 33 |'
- en: '&#124; ”I selected 33 because it’s slightly above halfway (50), &#124;'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; ”我选择33是因为它略高于中点（50）， &#124;'
- en: '&#124; which might be a common guess among participants aiming for a balanced
    approach. &#124;'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 这可能是参与者在寻求平衡方法时常见的猜测。 &#124;'
- en: '&#124; Additionally, it’s not too high to skew the average too much, &#124;'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 此外，这个值不会使平均值偏离过多， &#124;'
- en: '&#124; but not too low to risk being too far from 2/3 of the average.” &#124;'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 但不会过低以至于风险过远离2/3的平均值。” &#124;'
- en: '|'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Gemini Pro | 34 |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| Gemini Pro | 34 |'
- en: '&#124; ”In this scenario, simply guessing the average (50) might not be enough
    to win, &#124;'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; ”在这种情况下，仅仅猜测平均值（50）可能不足以获胜， &#124;'
- en: '&#124; as other players could also guess the same. &#124;'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 其他玩家也可能猜测相同的数字。 &#124;'
- en: '&#124; Instead, aiming for slightly above 1/3 of 100 positions me strategically
    closer to the target 2/3 of the average guess.” &#124;'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 相反，瞄准略高于100的1/3的位置，使我在战略上更接近目标的2/3平均猜测。” &#124;'
- en: '|'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Claude 2 | 33 |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| Claude 2 | 33 |'
- en: '&#124; ”As 2/3 of the average must be between 0 and 66, &#124;'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; ”由于2/3的平均值必须在0和66之间， &#124;'
- en: '&#124; I chose 33 as it is in the middle of this range. &#124;'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 我选择33是因为它处于这个范围的中间。 &#124;'
- en: '&#124; This accounts for other players likely choosing numbers on the higher
    and lower end of the 0-100 spectrum.” &#124;'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 这考虑到其他玩家可能会选择0-100范围的较高或较低的数字。” &#124;'
- en: '|'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: B.1 Preliminary test for KBC
  id: totrans-253
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.1 KBC的初步测试
- en: 'We test GPT-3.5 agents in KBC and show their number choices in Figure [9](#A2.F9
    "Figure 9 ‣ Appendix B Preliminary Tests of Other LLMs ‣ Shall We Talk: Exploring
    Spontaneous Collaborations of Competing LLM Agents"). When GPT-3.5 agents cannot
    discuss the game, the numbers chosen are very random, mostly in the range of 40-80.
    Even when they can communicate, the situation does not improve significantly,
    still showing a very strong randomness. This is significantly different from GPT-4
    agents, which, especially after communication, can have a deeper understanding
    of KBC.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在KBC中测试了GPT-3.5代理，并在图[9](#A2.F9 "图9 ‣ 附录B 其他LLM的初步测试 ‣ 我们谈谈：探索竞争LLM代理的自发合作")中展示了它们的数字选择。当GPT-3.5代理无法讨论游戏时，所选择的数字非常随机，大多在40-80的范围内。即使它们能够沟通，情况也没有显著改善，依然表现出非常强的随机性。这与GPT-4代理显著不同，尤其是在沟通之后，GPT-4代理对KBC有更深刻的理解。
- en: 'We also evaluate two widely-used LLMs, Gemini Pro and Claude 2. As shown in
    Table [2](#A2.T2 "Table 2 ‣ Appendix B Preliminary Tests of Other LLMs ‣ Shall
    We Talk: Exploring Spontaneous Collaborations of Competing LLM Agents"), after
    entering Prompt [A.1](#A1.SS1 "A.1 Prompts for KBC ‣ Appendix A Prompts ‣ Shall
    We Talk: Exploring Spontaneous Collaborations of Competing LLM Agents"), the results
    output by these two models are significantly different from GPT-4, but very similar
    to GPT-3.5. Since Figure [9](#A2.F9 "Figure 9 ‣ Appendix B Preliminary Tests of
    Other LLMs ‣ Shall We Talk: Exploring Spontaneous Collaborations of Competing
    LLM Agents") demonstrates the poor performance of GPT-3.5 in KBC, we similarly
    exclude the use of Gemini Pro and Claude 2 in our simulations.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '我们还评估了两种广泛使用的LLM，Gemini Pro和Claude 2。如表[2](#A2.T2 "Table 2 ‣ Appendix B Preliminary
    Tests of Other LLMs ‣ Shall We Talk: Exploring Spontaneous Collaborations of Competing
    LLM Agents")所示，输入Prompt [A.1](#A1.SS1 "A.1 Prompts for KBC ‣ Appendix A Prompts
    ‣ Shall We Talk: Exploring Spontaneous Collaborations of Competing LLM Agents")后，这两个模型的输出结果与GPT-4显著不同，但与GPT-3.5非常相似。由于图[9](#A2.F9
    "Figure 9 ‣ Appendix B Preliminary Tests of Other LLMs ‣ Shall We Talk: Exploring
    Spontaneous Collaborations of Competing LLM Agents")显示GPT-3.5在KBC中的表现较差，我们同样排除了在模拟中使用Gemini
    Pro和Claude 2。'
- en: '![Refer to caption](img/de8f01e1be8417545b8507aed31f2cfe.png)![Refer to caption](img/a92feb5af2ce54567453d140d540862e.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/de8f01e1be8417545b8507aed31f2cfe.png)![参见标题](img/a92feb5af2ce54567453d140d540862e.png)'
- en: 'Figure 10: Preliminary test of GPT-3.5 for BC (with communication).'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：GPT-3.5在BC中的初步测试（带通信）。
- en: '![Refer to caption](img/cb75b76edabebf7bbe54b6af21e440e4.png)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/cb75b76edabebf7bbe54b6af21e440e4.png)'
- en: 'Figure 11: Preliminary test of GPT-4, GPT-3.5, Gemini Pro, and Claude 2 for
    EE.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：GPT-4、GPT-3.5、Gemini Pro和Claude 2在EE上的初步测试。
- en: B.2 Preliminary test for BC
  id: totrans-260
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.2 BC的初步测试
- en: 'Figure [10](#A2.F10 "Figure 10 ‣ B.1 Preliminary test for KBC ‣ Appendix B
    Preliminary Tests of Other LLMs ‣ Shall We Talk: Exploring Spontaneous Collaborations
    of Competing LLM Agents") shows the performance of GPT-3.5 agents in BC with communication.
    We can see that the price competition between the two firms is very disorderly
    and fails to reach equilibrium. Therefore, we believe that GPT-3.5, as well as
    Gemini Pro, and Claude 2 with similar performance, cannot meet the needs for simulating
    BC.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '图[10](#A2.F10 "Figure 10 ‣ B.1 Preliminary test for KBC ‣ Appendix B Preliminary
    Tests of Other LLMs ‣ Shall We Talk: Exploring Spontaneous Collaborations of Competing
    LLM Agents")展示了GPT-3.5代理在BC中进行通信的表现。我们可以看到，两家公司之间的价格竞争非常无序，未能达到均衡。因此，我们认为GPT-3.5以及性能相似的Gemini
    Pro和Claude 2无法满足模拟BC的需求。'
- en: B.3 Preliminary test for EE
  id: totrans-262
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.3 EE的初步测试
- en: 'For EE, we test the performance of a single agent finding an exit under different
    LLMs. As shown in Figure [11](#A2.F11 "Figure 11 ‣ B.1 Preliminary test for KBC
    ‣ Appendix B Preliminary Tests of Other LLMs ‣ Shall We Talk: Exploring Spontaneous
    Collaborations of Competing LLM Agents"), instructed by Prompt [A.3](#A1.SS3 "A.3
    Prompts for EE ‣ Appendix A Prompts ‣ Shall We Talk: Exploring Spontaneous Collaborations
    of Competing LLM Agents"), GPT-4 agents are able to find and reach the nearest
    exit via the shortest path, while GPT-3.5, Gemini Pro, and Claude 2 agents are
    unable to reach the exit as quickly or cannot find it at all. This indicates that
    the latter three models are not suitable for the simulation of EE.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '对于EE，我们测试了在不同LLM下单个代理寻找出口的表现。如图[11](#A2.F11 "Figure 11 ‣ B.1 Preliminary test
    for KBC ‣ Appendix B Preliminary Tests of Other LLMs ‣ Shall We Talk: Exploring
    Spontaneous Collaborations of Competing LLM Agents")所示，在Prompt [A.3](#A1.SS3 "A.3
    Prompts for EE ‣ Appendix A Prompts ‣ Shall We Talk: Exploring Spontaneous Collaborations
    of Competing LLM Agents")的指示下，GPT-4代理能够通过最短路径找到并到达最近的出口，而GPT-3.5、Gemini Pro和Claude
    2代理无法如此快速地到达出口或根本找不到。这表明后面三种模型不适合EE的模拟。'
- en: Appendix C Parameter Settings
  id: totrans-264
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录C 参数设置
- en: 'We report the parameters of the GPT-4 model used in our case studies in Table
    [3](#A3.T3 "Table 3 ‣ Appendix C Parameter Settings ‣ Shall We Talk: Exploring
    Spontaneous Collaborations of Competing LLM Agents"). The temperature parameter
    controls the randomness and diversity of the model’s responses, with a lower temperature
    resulting in increased stability. In the evaluation of KBC, we expect that the
    individuals exhibit a wide range of diversity. Consequently, we adjust the temperature
    to a moderate level of $1.0$ may result in limited diversity of behaviors under
    exactly the same setting, in this procedurally generated, interactively dynamic
    environment, we seldom encounter exactly the same outcome. Meanwhile, in a physically
    situated setting (e.g., a grid), the LLM used in this case study still has restricted
    capabilities on scene understanding, and increasing the temperature may introduce
    diversity as well as unwanted randomness at the same time[[29](#bib.bib29)].'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在表格[3](#A3.T3 "表格 3 ‣ 附录 C 参数设置 ‣ 我们聊聊：探索竞争 LLM 代理的自发合作")中报告了我们案例研究中使用的GPT-4模型的参数。温度参数控制模型响应的随机性和多样性，较低的温度会导致模型响应更稳定。在KBC的评估中，我们期望个体表现出广泛的多样性。因此，我们将温度调整到中等水平$1.0$，可能会导致在完全相同的设置下行为的多样性受到限制。在这个程序生成的、互动动态的环境中，我们很少遇到完全相同的结果。同时，在一个物理设置的环境中（例如网格），本案例研究中使用的LLM在场景理解上仍然有局限性，提高温度可能同时引入多样性和不必要的随机性[[29](#bib.bib29)]。
- en: 'Table 3: Parameter settings of GPT-4.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '表 3: GPT-4的参数设置。'
- en: '| Case | Model | temperature | max_tokens | top_p |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| 案例 | 模型 | 温度 | 最大令牌数 | top_p |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| KBC | gpt-4-0314 | 1.0 | 256 | 1.0 |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| KBC | gpt-4-0314 | 1.0 | 256 | 1.0 |'
- en: '| BC | gpt-4-0314 | 0.7 | 128 | 1.0 |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| BC | gpt-4-0314 | 0.7 | 128 | 1.0 |'
- en: '| EE | gpt-4-0314 | 0.0 | 512 | 1.0 |'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '| EE | gpt-4-0314 | 0.0 | 512 | 1.0 |'
