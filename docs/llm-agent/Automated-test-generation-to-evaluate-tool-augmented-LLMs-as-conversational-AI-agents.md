<!--yml
category: 未分类
date: 2025-01-11 12:13:12
-->

# Automated test generation to evaluate tool-augmented LLMs as conversational AI agents

> 来源：[https://arxiv.org/html/2409.15934/](https://arxiv.org/html/2409.15934/)

Samuel Arcadinho
samuel.arcadinho@zendesk.com
&David Aparício
david.aparicio@zendesk.com
\ANDMariana S. C. Almeida
mariana.almeida@zendesk.com 

###### Abstract

Tool-augmented LLMs are a promising approach to create AI agents that can have realistic conversations, follow procedures, and call appropriate functions. However, evaluating them is challenging due to the diversity of possible conversations, and existing datasets focus only on single interactions and function-calling. We present a test generation pipeline to evaluate LLMs as conversational AI agents. Our framework uses LLMs to generate diverse tests grounded on user-defined procedures. For that, we use intermediate graphs to limit the LLM test generator’s tendency to hallucinate content that is not grounded on input procedures, and enforces high coverage of the possible conversations. Additionally, we put forward ALMITA, a manually curated dataset for evaluating AI agents in customer support, and use it to evaluate existing LLMs. Our results show that while tool-augmented LLMs perform well in single interactions, they often struggle to handle complete conversations. While our focus is on customer support, our method is general and capable of AI agents for different domains.

## 1 Introduction

Large language models (LLMs) are revolutionizing AI agents and have demonstrated remarkable generalization capabilities across various domains wu2023autogen; lan2024teachers; li2024personal. In particular, LLMs have made a profound impact as chatbots and as AI agents in customer support systems dam2024complete; katragadda2024leveraging.

Nevertheless, carelessly deploying an LLM as an AI agent, and allowing them to interact with real users and APIs, can lead to misinformation, reputational damage and costs to the company. Thus, it is critical to evaluate AI agents beforehand. Despite this need, evaluating the performance of LLMs in real-world scenarios remains a significant challenge. This is specially true in a conversational context, which is more complex than answering single-interaction requests. Most current approaches to evaluate LLMs focus primarily on specific tasks such as multi-QA zhuang2024toolqa; kamalloo2024towards or code generation liu2024your; liu2024exploring, which do not fully evaluate the broader set of capabilities that LLMs are expected to possess to truly function as an effective conversational AI agents.

Focusing on customer support, an effective AI agent is should be capable of interacting with tools and the customer in order to resolve customer issues, while stricly adhering to procedures described by customer support admins. In order to assess the AI agent’s performance, it is crucial to measure its ability to follow a given set of procedures and their resilience against potential customer manipulations. For that, it is key to have a comprehensive evaluation dataset, which can lead to valuable insights into the agent’s abilities and limitations.

![Refer to caption](img/e6cb03c0520866c3f7926030c3960526.png)

Figure 1: Automated test generation pipeline. For a given intent (e.g., cancel order) (1) we use an LLM to generate a corresponding procedure. Then, (2) an LLM extracts relevant APIs from the procedure, and (3) generates a flowgraph from the procedure and its APIs. Next, (4) an LLM generates a conversation graph from the flowgraph and (5) adds noise to the graph (e.g., users going out of the expected procedure), to make the graph more realistic. To obtain conversations from the graph, (6) we sample paths from it, which correspond to different interactions. Finally, (7) an LLM generates conversations from the paths and (8) we extract tests from the sampled conversations.

We propose a method to generate evaluation datasets for tool-augmented LLMs as conversational AI agents. Our method automates dataset generation using an LLM to create conversations based on procedures, which are then transformed into tests. We use intermediate graph structures to improve the quality of the generated dataset (i.e., tests follow user-defined procedures) and make it more comprehensive (i.e., tests cover most relevant cases). To assess the AI agent’s ability to handle attacks, we incorporate red teaming in our examples.

Our generation pipeline, illustrated in [Figure 1](https://arxiv.org/html/2409.15934v2#S1.F1 "In 1 Introduction ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents"), builds diverse datasets autonomously by using synthetically generated intents as seeds for procedures. Additionally, our pipeline also allows for the inclusion of real data where available, such as actual procedures or APIs used by a company to generate synthetic conversations. While datasets can be created fully automatically, we also put forward ALMITA (Automated benchmark of Language Models for Intelligent Tool-augmented Agents), a manually curated dataset. We use this high-quality dataset to benchmark LLMs as conversational tool-augmented AI agents.

Our main contributions are:

*   •

    A method that generates datasets to evaluate tool-augmented LLMs as AI conversational agents, reducing manual effort needed to obtain such datasets. Our method provides an holistic evaluation of AI agents, with realistic and diverse conversations, use of tools (e.g., functions/APIs), and grounded on user-defined procedures.

*   •

    ALMITA, the first conversational dataset that can be used to evaluate customer support AI agents, including both tooling (i.e., functions) and conversation reply to follow company user-defined procedures. ALMITA contains 1420 synthetic tests that were manually curated to ensure high-quality samples¹¹1ALMITA, along with all other datasets generated using our pipeline and referenced in the paper, are available in [https://github.com/zendesk/almita-dataset](https://github.com/zendesk/almita-dataset)..

*   •

    Benchmarking of multiple LLMs on the proposed dataset. Our results indicate that current LLMs have high performance regarding single message accuracy and in calling the correct functions, but have limited accuracy when the complete conversation is considered, which might indicate that they would not be successful if deployed as fully autonomous customer support AI agents.

We also note that, while our evaluation focuses on customer support, the same method could be applied, with some changes, to other domains.

## 2 Related work

With the increasing use of LLMs as AI agents, significant efforts have been made to develop benchmarks to evaluate their ability to correctly answer customer requests in conversational settings. GAIA proposes 466 human-annotated questions covering tasks like general knowledge, daily tasks, and data analysis Mialon2023GAIAAB. Recently, AgentInstruct introduced a framework for generating synthetic data from diverse sources, such as code, web articles, and textbook chapters, to help agents generate and refine instruction sets Mitra2024AgentInstructTG. Unlike our work, these datasets do not assess tool-augmented AI agents.

Datasets to evaluate tool-augmented LLMs have been proposed. Zeng2023AgentTuningEG propose AgentTuning and compile multiple agent datasets to create sequences of API calls. AgentBench features multi-step interactions between an agent and the environment, using various tools to solve user requests Liu2023AgentBenchEL. patil2023gorilla and qin2023toolllm build datasets of APIs from sources like TorchHub, TensorHub, and rapidAI, prompting an LLM to generate instructions solvable by these APIs. basu2024api combine multiple datasets to convert user instructions into API calls. APIGen introduced an automatic method to generate synthetic datasets for tool function calling liu2024apigen. Unlike our work, these datasets are not conversational and just focus on mapping utterances to API calls, and they do not use intermediate structures (i.e., graphs) to ensure coverage and reduce hallucinations in generated tests.

Other relevant work focuses on graph learning and on using different intermediate structures to reducing hallucinations. ye2023natural propose InstructGLM, which uses natural language to describe node features used to tune an LLM for inference on graphs. wang2024can introduce NLGraph, a benchmark for graph-based problems written in natural language, demonstrating that LLMs can perform structured operations on textual descriptions of graphs. Additionally, narayan2023conditional propose using question-answer blueprints as intermediate representations to reduce hallucinations. These works do not fully encompass our problem setting of generating conversations in dialog format, calling APIs, and extracting tests.

![Refer to caption](img/4900855e1644e154eaab8a895a1a6d6c.png)

Figure 2: Flowgraph for intent *Order not received* and procedure *"If the customer did not receive their order, allow the customer to cancel or refund their order given that they provide a correct order id"*. Blue nodes are message nodes, black nodes are API call nodes, orange nodes are end nodes. Edge labels are user messages or API outputs.

## 3 Method

Our automated test generation pipeline, illustrated in [Figure 1](https://arxiv.org/html/2409.15934v2#S1.F1 "In 1 Introduction ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents"), begins by generating textual procedures from input intents. While one could use an LLM to directly generate conversations from procedures, our approach converts the procedures into a flowgraph and then into a conversation graph. Our assumption is that using these intermediate structured representations makes the task of creating the conversations grounded on the procedures more accurate; see Section [4.2](https://arxiv.org/html/2409.15934v2#S4.SS2 "4.2 Ablation study: conversations from procedures ‣ 4 Results ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents") for supporting evidence. Additionally, the graphs allow us to introduce noise into the conversations, making conversations more realistic and challenging, and enable us to sample paths, ensuring path coverage and conversation diversity. We then generate conversations from the sampled paths. Finally, we extract tests from these conversations by breaking down the conversation at each user message, storing the context, and recording the generated response as the correct reply.

### 3.1 Intent generator

Intents (or *issues*, e.g., cancel order) serve as the seeds for our automated test generation method. Intents can be generated by an LLM (as is the case in this work), sourced from predefined domain-specific intents, or a mix of both. The prompt used to generate intents is shown in [Section A.1](https://arxiv.org/html/2409.15934v2#A1.SS1 "A.1 Intent generation ‣ Appendix A Prompts ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents").

### 3.2 Procedure generator

A procedure describes how a given issue/intent should be solved by an agent. We use an LLM to generate a procedure for each input intent by asking it to provide a list of instructions that helps an agent fulfill a given task. We enforce in the prompt to avoid outputting general statements (e.g., "cancelling policies might depend on the company" or "explain the company’s policy") since our goal is to generate specific and unambiguous procedures with precise and granular steps. We also enforce that conditionals are possible but that they need to have a clear solution in the steps of the procedure. Finally, steps might contain actions based on APIs (e.g., search a database, escalate an issue) but they cannot be browsing actions (e.g., click on the login page). The full prompt is shown in [Section A.2](https://arxiv.org/html/2409.15934v2#A1.SS2 "A.2 Procedure generation ‣ Appendix A Prompts ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents"). Similarly to what we described for intents, existing procedures (e.g., of a company) can be included as input for our method. Moreover, procedures can be generated based on existing knowledge, namely existing tickets or help center articles.

Consider the intent "order not received": a simple procedure could be "If the customer did not receive their order, allow the customer to cancel or refund their order given that they provide a correct order id". We use this procedure as an illustrative example throughout the paper (see [Figures 2](https://arxiv.org/html/2409.15934v2#S2.F2 "In 2 Related work ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents"), [3](https://arxiv.org/html/2409.15934v2#S3.F3 "Figure 3 ‣ 3.5 Conversation graph generator ‣ 3 Method ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents") and [4](https://arxiv.org/html/2409.15934v2#S3.F4 "Figure 4 ‣ 3.6 Noise generator ‣ 3 Method ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents").)

### 3.3 API extractor

Our target use-case is tool-augmented AI agents. We use an LLM to generate APIs that are useful for an input procedure. We enforce in the prompt that the extracted APIs are agent APIs and not customer facing APIs. Generated APIs include not only the API name, but also their input output parameters, as well as a small description. The full prompt is shown in [Section A.3](https://arxiv.org/html/2409.15934v2#A1.SS3 "A.3 API extraction ‣ Appendix A Prompts ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents"). These APIs should be explicitly called by the agent to fulfill the procedure. Similarly to intents and procedures, existing APIs can be easily included in our pipeline.

### 3.4 Flowgraph generator

The flowgraph generator receives as input a procedure and relevant APIs and generates a directed graph encapsulating the logic of the procedure from the agent’s perspective: nodes are agent actions and edges are customer replies or API outputs. Nodes are of 4 different types: (i) a single start_message node is the initial message sent by the agent to the customer, (ii) message nodes are additional messages sent by the agent to the customer, (iii) api nodes are API calls performed by the agent, and (iv) end_message nodes are messages by the agent that end the interaction. To reduce hallucinations and increase completeness, we enforce in the prompt ([Section A.4](https://arxiv.org/html/2409.15934v2#A1.SS4 "A.4 Flowgraph generation ‣ Appendix A Prompts ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents")) that every detail from the procedure needs to be in message nodes.

An example of a flowgraph is given in [Figure 2](https://arxiv.org/html/2409.15934v2#S2.F2 "In 2 Related work ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents"). Nodes in the flowgraph have a node_id (e.g., "N1"), a node_type (one of the four described above), and a node_description, which should be related to a step in the procedure (e.g., "Tell the user the order was not found") or an API call (e.g., "refund_order"). Edges in the graph are either the user interaction (e.g., "Gives order id and email") or the result of an API call (e.g., "Found order"). Edges in the flowgraph have an edge_id (e.g., "E1"), a tuple with the source node and the target node (e.g., "(N1, N2)"), and an edge description, as described previously. We do one-shot prompting, providing an example to the LLM; thus, a complete flowgraph can be seen in flowgraph prompt in [Section A.4](https://arxiv.org/html/2409.15934v2#A1.SS4 "A.4 Flowgraph generation ‣ Appendix A Prompts ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents").

To try to guarantee correct flowgraphs, we instruct the LLM to generate graphs with only one root node with type start_message, to always have concrete messages in the node and edge descriptions, and to provide API outputs in the outgoing edges of api nodes. To try to limit hallucinations and ensure that the graph encapsulates the entire procedure, we instruct the LLM to follow strictly what is in the procedure and to include all content from it. At the end of the generation step, we convert the graph into a networkx graph and, if parsing succeeds, we pragmatically verify if all the rules described previously are followed; if they are not followed, we discard the generated flowgraph.

### 3.5 Conversation graph generator

A flowgraph represents a sequence of agent steps to fulfill a procedure. The flowgraph’s structure does not directly map to a conversation, which can make the task of creating a conversation from a flowgraph hard. Thus, the goal of the conversation graph generator is to convert the flowgraph into a a conversation graph, which is a structure that is more akin to a dialogue. The generated conversation graph is a directed graph that is expected to have nodes of three different types: (i) agent nodes are messages sent by the agent, (ii) customer nodes are messages sent by the customer, and (iii) api nodes are API calls by the agent.

![Refer to caption](img/f8b5ddf790d8621a35ef9be87e9f6220.png)

Figure 3: Conversation graph for flowgraph from Fig. [2](https://arxiv.org/html/2409.15934v2#S2.F2 "Figure 2 ‣ 2 Related work ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents") for intent *Order not received*. Blue nodes are agent nodes, green are user nodes, and black are API nodes.

An example of a conversation graph is given in [Figure 3](https://arxiv.org/html/2409.15934v2#S3.F3 "In 3.5 Conversation graph generator ‣ 3 Method ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents"). Nodes in the conversation graph have a node_id (e.g., "N1"), a node_type (one of the three described above), and a node_description, which is a message for agent and customer nodes, and an API call for api nodes. Edges in the conversation graph connect consecutive messages/api calls. Some conversation paths have conditions, such as an API call returning that the order was found or not; in these cases, edges have an edge description, otherwise the edge description is empty. Edges in the flowgraph have an edge_id (e.g., "E1"), a tuple with the source node and the target node (e.g., "(N1, N2)"), and an edge description.

In an effort to mitigate incorrect conversation graphs, we provide the LLM with additional graph construction rules, e.g., customer nodes should be followed by either agent or api nodes, leaf nodes should be assistant nodes. We use one-shot prompting by giving the LLM as input an example of a flowgraph and the corresponding conversation graph, as shown in [Section A.5](https://arxiv.org/html/2409.15934v2#A1.SS5 "A.5 Conversation graph generation ‣ Appendix A Prompts ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents"). Similarly to flowgraphs, we load the generated graph into networkx and verify if the required conditions are met, otherwise the graph is discarded.

### 3.6 Noise generator

Conversation graphs are built from agent procedures, thus they are expected to only contain *good* behaviour by both the agent and the customer (i.e., happy paths). To make AI agents more resilient to unexpected customer behaviour, which might be malicious or not, we augment the conversation graphs with behaviour outside of the procedure.

The noise generator traverses the agent nodes in the conversation graph and, with a certain probability (e.g., 20%), inserts an edge to a new customer node with a node_description message which can either be an "out-of-procedure" message or an "attack" message. These messages are generated beforehand by an LLM. Additionally, we add an edge from the noisy customer node to a new agent node with node_description as "Say you’re only here to help with the original issue."

![Refer to caption](img/9e52187113df69fdb6838d45b2eec735.png)

Figure 4: Tests extracted from one conversation.

### 3.7 Path sampler

We extract conversations between a customer and an agent by sampling paths from the conversation graph. Given a conversation graph $\mathcal{G}$ with $N$ nodes and a desired number of conversations $M$, we employ a weighted random walks algorithm to sample paths, [Algorithm 1](https://arxiv.org/html/2409.15934v2#alg1 "In 3.7 Path sampler ‣ 3 Method ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents"), which is an enhanced version of vanilla random walks, designed to improve node coverage. For that, we use a weighting vector $\bf{w}$ with $N$ elements initialized with ones (line 3). Each path $p$ is built by iteratively sampling nodes using $sample\_node$ (line 7). A node $n$, which is a child of the last node in the current path $p$, is sampled with a probability inversely proportional to its weight $w_{i}$, where $w_{i}$ is the number of times node $n$ was visited plus one (line 9). The index $i$ of node $n$ in graph $\mathcal{G}$ is provided by $node\_index$ (line 8). Path construction terminates when a leaf node is reached (lines 11–13).

Algorithm 1 Conversation path sampling

1:Inputs: $\mathcal{G}$, $M$2:$\mathcal{P}\leftarrow\emptyset$3:$\bf{w}\leftarrow\bf{1}$[N]4:while $\lvert\mathcal{P}\rvert<M$ do5:     $p\leftarrow\emptyset$6:     while True do7:        $n\leftarrow\emph{sample\_node}(\mathcal{G},p,\bf{w})$8:        $i\leftarrow\emph{node\_index}(\mathcal{G},n)$9:        ${w_{i}}\leftarrow{w_{i}}+1$10:        $p\leftarrow p\mid n$11:        if $n$ is EndNode then12:            $\mathcal{P}\leftarrow\mathcal{P}\mid p$13:            break

### 3.8 Conversation generator

The conversation generator creates synthetic conversations from an input conversation graph, a sampled path, and relevant APIs. We provide the LLM with context about the conversation graph structure and the APIs. Using one-shot prompting, we present the LLM with an example triplet consisting of a conversation graph, a list of APIs, and a sampled path, as well as a possible conversation based on these conditions (see [Section A.6](https://arxiv.org/html/2409.15934v2#A1.SS6 "A.6 Conversations generation ‣ Appendix A Prompts ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents")). In an effort to generate valid conversations, we include conditions in the prompt, such as always generating a message with the API output following an API message, alternating customer and assistant messages, ensuring agents act on API output messages, and verifying API input and output types.

|  | Intents | Proc. | Proc. | Flowgraphs | Conv.Graphs | Conversations | Tests |
| --- | --- | --- | --- | --- | --- | --- | --- |
|  |  |  | w/ APIs |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- |
| Generated | 84 | 168 | 132 | 70 | 49 | 217 | 1,420 |
| + auto. filters | – | – | 98 | 55 | 33 | – | – |
| + man. filters | – | 132 | 70 | 49 | 33 | 192 | – |
| ALMITA | 14 | 18 | 18 | 18 | 18 | 192 | 1,420 |
| auto-ALMITA | 52 | 63 | 63 | 63 | 63 | 407 | 2,696 |

Table 1: Statistics while bootstrapping ALMITA’s dataset from 84 intents. We show the number of samples after (i) generation, (ii) automatic filtering, and (iii) human filtering annotations. "–" indicates no filtering. auto-ALMITA was created using the same 84 seed intents as ALMITA, but using the same pipeline without any human filtering, so that we can assess the capabilities of our test generation pipeline when no human annotators are available.

### 3.9 Test extractor

The test extractor converts a single conversation into one or more tests. It iteratively breaks down the conversation into sub-conversations (or contexts), each ending with a customer message (e.g., "Cancel my order") or an API output (e.g., "success" following a cancel function call). The rationale is that since the generated conversations exemplify correct flows, we can construct contexts using the preceding messages, with the expected output being the next non-customer message, whether it’s an agent response or an API call. [Figure 4](https://arxiv.org/html/2409.15934v2#S3.F4 "In 3.6 Noise generator ‣ 3 Method ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents") illustrates an example of three tests extracted from a generated conversation. Tests are used to evaluate an AI agent by providing it with the context and comparing its response with the expected output.

## 4 Results

| LLM | Reply | API | Test | Conversation |
| Recall | Correct | Recall | Correct | Correct params. | Correct | Correct |
| GPT-4o | 92.7 | 75.2 | 96.7 | 99.8 | 92.2 | 88.9 | 14.1 |
| Mistral-NeMo-I | 92.0 | 65.0 | 89.8 | 99.5 | 92.1 | 84.7 | 7.3 |
| Claude3-s | 88.0 | 60.3 | 96.2 | 99.8 | 90.5 | 83.3 | 10.4 |
| GPT-4 | 53.2 | 77.7 | 98.1 | 99.8 | 93.0 | 76.9 | 4.2 |
| Llama3.1-8b-I | 74.8 | 53.5 | 72.1 | 90.8 | 85.9 | 73.1 | 1.6 |
| GPT-4o w/ F | 92.9 | 74.8 | 97.2 | 99.0 | 86.6 | 88.0 | 15.6 |

Table 2: AI agents evaluated on their capacity to produce correct replies with correct API calls. We test different LLMs using the same prompt. Additionally, we evaluate LLMs using function calling (with the "w/ F" suffix). The versions of the closed source models are gpt-4-0613, gpt-4o-2024-05-13, anthropic.claude-3-sonnet-20240229-v1:0. The "-I" suffix indicates that it is an instruction model. All results are percentages, with the highest value in bold.

In Section [4.1](https://arxiv.org/html/2409.15934v2#S4.SS1 "4.1 Dataset generation: ALMITA ‣ 4 Results ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents") we detail the creation of ALMITA, a manually curated dataset for evaluating LLMs as AI customer support agents. Two annotators independently review each datapoint to identify incorrect instances, followed by a discussion to align their assessments and minimize disagreements. Any datapoint deemed incorrect by at least one annotator is then removed. GPT-4 is used for all generation steps (see Figure [1](https://arxiv.org/html/2409.15934v2#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents")). To assess the benefits of the graph intermediate structures, we conduct an ablation study comparing conversations generated directly from procedures to those using the intermediate structures, with manual curation for quality assessment (Section [4.2](https://arxiv.org/html/2409.15934v2#S4.SS2 "4.2 Ablation study: conversations from procedures ‣ 4 Results ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents")). In Section [4.3](https://arxiv.org/html/2409.15934v2#S4.SS3 "4.3 Evaluation of LLM AI agents ‣ 4 Results ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents"), we evaluate various AI agents on ALMITA. Finally, in Section [4.4](https://arxiv.org/html/2409.15934v2#S4.SS4 "4.4 Fully automated tests: auto-ALMITA ‣ 4 Results ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents"), we assess the effectiveness of our pipeline in generating high-quality test sets automatically. We do this by comparing the AI agents’ performance on ALMITA with those on its fully automated counterpart, auto-ALMITA.

### 4.1 Dataset generation: ALMITA

We begin by asking the LLM to generate intents using the prompt from [Section A.1](https://arxiv.org/html/2409.15934v2#A1.SS1 "A.1 Intent generation ‣ Appendix A Prompts ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents"), resulting in 84 intents. Using them as input, we prompt the model to generate two procedures per intent, for a total of 168 procedures. After manual annotation, we remove 36 procedures that did not comply with the rules from [Section 3.2](https://arxiv.org/html/2409.15934v2#S3.SS2 "3.2 Procedure generator ‣ 3 Method ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents"). The valid procedures average 315 words (ranging from 171 to 535) and 11 steps (ranging from 6 to 19). Next, we extract APIs for each procedure as outlined in [Section 3.3](https://arxiv.org/html/2409.15934v2#S3.SS3 "3.3 API extractor ‣ 3 Method ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents"). APIs not in the correct JSON format are automatically filtered out, along with procedures with invalid APIs, resulting in 70 valid procedures. Each of these procedures, on average, includes 4 APIs (ranging from 2 to 9). For each of the 70 procedures with APIs, we generate the corresponding flowgraph. We automatically filter out 15 flowgraphs and manually filter 6 more that do not adhere to the rules discussed in [Section 3.4](https://arxiv.org/html/2409.15934v2#S3.SS4 "3.4 Flowgraph generator ‣ 3 Method ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents"). The valid flowgraphs average 15 nodes (ranging from 10 to 20) and 17 edges (ranging from 10 to 25). For each of the remaining 49 valid flowgraphs, we generate the corresponding conversation graph. We automatically exclude 16 conversation graphs and manually exclude 7 more based on adherence to rules ([Section 3.5](https://arxiv.org/html/2409.15934v2#S3.SS5 "3.5 Conversation graph generator ‣ 3 Method ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents")). The valid conversation graphs average 23 nodes (ranging from 16 to 37) and 24 edges (ranging from 15 to 37). From these conversation graphs, we generate 217 conversations after path sampling ([Section 3.7](https://arxiv.org/html/2409.15934v2#S3.SS7 "3.7 Path sampler ‣ 3 Method ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents")). We manually filter out 25 conversations for not following the rules ([Section 3.8](https://arxiv.org/html/2409.15934v2#S3.SS8 "3.8 Conversation generator ‣ 3 Method ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents")). Thus, from the original 84 intents, we obtain 192 valid conversations. Each conversation traverses an average of 12 nodes (ranging from 3 to 24). Finally, tests are extracted from these conversations as detailed in Section [3.9](https://arxiv.org/html/2409.15934v2#S3.SS9 "3.9 Test extractor ‣ 3 Method ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents"), resulting in 1420 generated tests. Table [1](https://arxiv.org/html/2409.15934v2#S3.T1 "Table 1 ‣ 3.8 Conversation generator ‣ 3 Method ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents") summarizes the dataset statistics. In the end, the ALMITA dataset comprises 14 intents, 18 procedures, 18 flowgraphs, 18 conversations graphs, 192 conversations and 1420 tests.

### 4.2 Ablation study: conversations from procedures

We conduct an ablation study to validate the effectiveness of our intermediate graph representations in generating correct conversations. We remove the flowgraph generator, conversation graph generator, noise generator, and path sampler, and generate conversations directly from the procedures and APIs using the prompt from [Section A.7](https://arxiv.org/html/2409.15934v2#A1.SS7 "A.7 Conversations from procedures ‣ Appendix A Prompts ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents"). Annotating conversations directly generated from procedures showed to be a much more complex and time-consuming than annotating conversations generated from graphs. For this reason we only annotate 50 conversations. All 50 conversations are generated from the same 70 input procedures as ALMITA, and they are curated by the same two annotators, following the same annotation strategy. K The simplified pipeline results in $\approx 68\%$ ($34/50$) valid conversations, as evaluated by the same annotators that curated ALMITA. In contrast, the original pipeline with intermediate graph representations yields $\approx 88\%$ ($192/217$) valid conversations. This indicates that graph representations improve the validity of generated conversations. Even when considering the cumulative impact of curating flowgraphs, the original pipeline would automatically generate $\approx 78\%$ ($192/217\times 49/55$) valid conversations, which is above $\approx 68\%$.

Moreover, while the prompt used in the simplified pipeline could potentially be improved, the simplified pipeline intrinsically does not ensure that all branching paths from the procedure are explored. This highlights the benefit of intermediate graph representations in covering all possible conversation paths.

### 4.3 Evaluation of LLM AI agents

We use ALMITA to evaluate LLMs serving as customer support AI agents. The dataset allows us to evaluate the following dimensions, which we report in [Table 2](https://arxiv.org/html/2409.15934v2#S4.T2 "In 4 Results ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents"): (i) *reply recall*: when the correct action is to reply, the agent correctly sends a reply message instead of calling an unnecessary API, (ii) *correct reply*: when both the correct and the predicted action is to reply, the agent’s reply matches the expected reply (we use BERTScore with a similarity threshold of 0.55 after inspecting of some examples), (iii) *API recall*: when the correct action is to do an API call, the agent correctly detects that it needed to perform an API call instead of replying, (iv) *correct API*: when both the correct and the predicted action is to perform an API call, the agent calls the correct API; (v) *correct API parameters*: when both the correct and the predicted action are the same API call, the agents calls the API with the correct parameter values, (vi) *test correctness (or test accuracy)*: whether the test is fully correct (i.e., call the correct reply/API and, if the correct action is an API, call the correct API and use the correct parameters, or if the correct action is a reply, provide a correct reply), (vii) *conversation correctness (or conversation accuracy)*: whether the sequence of all tests from the conversation where all correct.

We evaluate 5 different LLMs: GPT4-o, GPT-4, Claude3-sonnet, Mistral-NeMo-Instruct, and Llama3.1-8b-Instruct. To ensure fairness, we use a uniform prompt for all models (details in [Section A.8](https://arxiv.org/html/2409.15934v2#A1.SS8 "A.8 Tool-augmented AI agent ‣ Appendix A Prompts ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents")). Our prompt aims to be general, avoiding any favoritism towards a specific model, although we acknowledge that different models may excel with different prompting styles. Since the dataset includes API calling, we also test GPT4-o with function calling, denoted as GPT-4o w/F.

We observe that all LLMs demonstrate high accuracy when responding with an API, achieving over 85% correctness in both the *correct API* and *correct API parameters* dimensions. With the exception of Llama3.1-8b-I, which performs considerably worse, the other models correctly determine when an API should be called, with an *API recall* exceeding 90%. However, performance in other dimensions is notably lower, suggesting that datasets focused solely on API calls do not comprehensively evaluate an AI agent’s capabilities.

Interestingly, GPT-4 tends to call APIs even when unnecessary, resulting in a lower *reply recall* compared to other models. In terms of *correct reply*, GPT models outperform the others, though this may be biased by the use of GPT-4 for test generation. For *test correctness*, GPT-4o, Claude3-s, and Mistral-NeMo-Instruct show the highest performance, while GPT-4 and Llama3.1-8b-Instruct rank among the lowest.

Most critically, we see that all models have very low performance regarding *correct conversation*. In practice, this would mean that these AI agents would very likely fail at some step of a conversation with a user. This showcases that current LLMs have some limitations that require either better models or very engineered prompts to suitably serve as fully autonomous customer support AI agents.

Our dataset could, potentially, be useful to evaluate future models and/or strategies on their AI agent capabilities. Furthermore, since the pipeline is automated, the dataset could be updated to include more (and harder) tests, as well as adapted to new or more specific domains.

### 4.4 Fully automated tests: auto-ALMITA

In this section, we analyze the results obtained by AI agents on auto-ALMITA, the fully automated version of the ALMITA dataset. This dataset was created using the same seed intents from the ALMITA dataset, described in [section 4.1](https://arxiv.org/html/2409.15934v2#S4.SS1 "4.1 Dataset generation: ALMITA ‣ 4 Results ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents"). Then we run the same pipeline without the manual filtering steps. Auto-ALMITA retains more data points and greater diversity (see Table [1](https://arxiv.org/html/2409.15934v2#S3.T1 "Table 1 ‣ 3.8 Conversation generator ‣ 3 Method ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents")), albeit with some reduction in quality. Being fully automatically generated, auto-ALMITA can also be easily extended without additional curation efforts.

We evaluate the same LLM agents from [Table 2](https://arxiv.org/html/2409.15934v2#S4.T2 "In 4 Results ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents") and compare the global metric test correct obtained by the AI agents both auto-ALMITA and ALMITA in [Figure 5](https://arxiv.org/html/2409.15934v2#S4.F5 "In 4.4 Fully automated tests: auto-ALMITA ‣ 4 Results ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents"). Both datasets rank the LLMs in the same order, with a high correlation value of 0.98 (detailed results are provided in Supplementary Table [1](https://arxiv.org/html/2409.15934v2#A2.T1 "Table 1 ‣ Appendix B auto-ALMITA: Detailed evaluation ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents")). These findings suggest that the proposed pipeline can generate evaluation datasets for AI agents entirely automatically, which lead to conclusions similar to those derived from curated datasets.

<svg class="ltx_picture" height="217.12" id="S4.F5.pic1" overflow="visible" version="1.1" width="580.46"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,217.12) matrix(1 0 0 -1 0 0) translate(42.45,0) translate(0,37.53) matrix(1.0 0.0 0.0 1.0 -42.45 -37.53)"><g class="ltx_nestedsvg" transform="matrix(1 0 0 1 0 0) translate(42.45,0) translate(0,37.53)"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"><g color="#000000" fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 13.76 -13.81)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$70$</foreignobject></g><g color="#000000" fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 96.49 -13.81)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$74$</foreignobject></g><g color="#000000" fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 179.22 -13.81)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$78$</foreignobject></g><g color="#000000" fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 261.95 -13.81)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$82$</foreignobject></g><g color="#000000" fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 344.68 -13.81)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$86$</foreignobject></g><g color="#000000" fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 427.4 -13.81)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$90$</foreignobject></g><g color="#000000" fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 510.13 -13.81)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$94$</foreignobject></g><g color="#000000" fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -18.73 2.23)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$70$</foreignobject></g><g color="#000000" fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -18.73 28.99)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$74$</foreignobject></g><g color="#000000" fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -18.73 55.76)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$78$</foreignobject></g><g color="#000000" fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -18.73 82.52)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$82$</foreignobject></g><g color="#000000" fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -18.73 109.28)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$86$</foreignobject></g><g color="#000000" fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -18.73 136.05)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$90$</foreignobject></g><g color="#000000" fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -18.73 162.81)"><foreignobject height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$94$</foreignobject></g><g clip-path="url(#pgfcp13)"><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 170.34 38.76)"><foreignobject height="8" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="12.61">![Refer to caption](img/343b5e0d6d552f2b843adbd222929686.png) GPT-4</foreignobject></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 97.96 25.3)"><foreignobject height="7" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="16.61">![Refer to caption](img/a9e167facd5937babcf68c4bd62df881.png) Llama3.1-8b-I</foreignobject></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 418.53 105.67)"><foreignobject height="8" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="12.61">![Refer to caption](img/343b5e0d6d552f2b843adbd222929686.png) GPT-4o</foreignobject></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 397.85 90.21)"><foreignobject height="8" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="12.61">![Refer to caption](img/343b5e0d6d552f2b843adbd222929686.png) GPT-4o w/ F</foreignobject></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 325.46 78.83)"><foreignobject height="9.46" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="24.68">![Refer to caption](img/0b78ec89143536bfb91dfe449724333c.png)Mistral-NeMo-I</foreignobject></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 304.78 58.76)"><foreignobject height="6" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="12.61">![Refer to caption](img/b22af2f2461a97a7b81df376088e2e3f.png) Claude3-sonnet</foreignobject></g></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 196.63 -32.92)"><foreignobject height="8.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="73.18">*test correct* @ ALMITA</foreignobject></g><g fill="#000000" stroke="#000000" transform="matrix(0.0 1.0 -1.0 0.0 -28.23 -1.02)"><foreignobject height="8.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="73.18">*test correct* @ auto-ALMITA</foreignobject></g></g></g></g></svg>

Figure 5: *test correct* value for different LLM Agents on the auto-ALMITA and ALMITA datasets.

## 5 Conclusions

LLMs are being used as customer support AI agents. However, existing evaluation datasets are limited in their scope. We propose an automated test generation pipeline to evaluate tool-augmented conversational AI agents. Our proposed method uses LLMs to generate intermediate graph structures that help limit hallucinations and improve diversity in the generated tests. We evaluate different LLMs to analyze the current capabilities of LLMs implemented as AI agents.

To facilitate this, we developed the ALMITA dataset, which we used to thoroughly evaluate these AI agents and identify their limitations. ALMITA allows for a multifaceted evaluation across several key dimensions, such as reply accuracy, API call correctness, and overall conversation integrity. Our findings highlighted significant limitations in current LLMs, particularly in maintaining correct conversations throughout a user interaction.

Importantly, the ALMITA dataset can be used by other researchers to evaluate AI agents, providing a comprehensive benchmark for assessing various aspects of their performance, possibly in other target domains. Additionally, since our test generation pipeline is fully automated, we have the capability to create new, more challenging versions of the dataset. This adaptability ensures that our framework can be continually updated to reflect more complex and realistic scenarios, further enhancing its utility for ongoing research and development of AI agents in customer support and beyond.

## 6 Limitations

Our evaluation has some limitations. Namely, we did not evaluate the diversity of the generated tests quantitatively. We performed human annotation, to verify correctness at each step, but the number of annotations and of annotators was small. Our test generation pipeline only used a single LLM as the generator, namely GPT4 and this might influence evaluation. A possible mitigation for this is to repeat the test generation pipeline for other LLMs and aggregate the tests. We evaluated multiple LLMs but only using a single prompt. Our goal was to test different models on the generated dataset, but more advanced AI agents could be considered.

Additionally, we acknowledge that some metrics may be too strict. As a future direction, we would like to consider the severity of the errors of an AI agent in a conversation. Conversations are relatively fluid and we may have other replies/actions that are somehow acceptable for a given procedure besides of the most obvious and direct one that was annotated in the dataset. There is still to be develop more advanced and more semantic conversational metrics allowing for some path variations, similarly to what has been happening for the comparison of two sentences where different words and order of words can lead to similar meanings.

## Appendix A Prompts

### A.1 Intent generation

<svg class="ltx_picture" height="127.17" id="A1.SS1.p1.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,127.17) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 109.11)"><foreignobject color="#FFFFFF" height="12.15" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">System prompt</foreignobject></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="77.62" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">You are <REDACTED>, a platform providing customer support. You serve clients from numerous different industries: internet providers, financial institutions, e-commerce platforms, entertainment websites, etc. All these clients have customer that can contact customer support to obtain information, complain about something, or other reasons to contact the customer support team.</foreignobject></g></g></svg><svg class="ltx_picture" height="1678.85" id="A1.SS1.p2.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,1678.85) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 1660.8)"><foreignobject color="#FFFFFF" height="12.15" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">User prompt</foreignobject></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="1629.31" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Your task is to generate a list of problems that can lead to a customer contacting support. Think of the type of client for which the issue is relevant, a description of the detailed issue, and a short name for the error. Generate {{ number_issues }} issues from a diverse pool of clients. Format your answer as a json with the following structure: [⬇](data:text/plain;base64,W3sKICAgImNsaWVudCI6IGUuZy4sIGEgYmFuaywgaW50ZXJuZXQgcHJvdmlkZXIsIGV0Yy4gRG8gbm90IGxpbWl0IHlvdXJzZWxmIHRvIHRoZXNlIGV4YW1wbGVzISwKICAgImlzc3VlIjogZGVzY3JpcHRpb24gb2YgdGhlIGVycm9yLCBiZSBzcGVjaWZpYyEsCiAgICJuYW1lIjogYSBzaG9ydCBuYW1lIGZvciB0aGUgaXNzdWUKfV0=) [{ "client":  e.g.,  a  bank,  internet  provider,  etc.  Do  not  limit  yourself  to  these  examples!, "issue":  description  of  the  error,  be  specific!, "name":  a  short  name  for  the  issue }]</foreignobject></g></g></svg>

### A.2 Procedure generation

<svg class="ltx_picture" height="374.64" id="A1.SS2.p1.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,374.64) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 356.59)"><foreignobject color="#FFFFFF" height="12.15" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">System prompt</foreignobject></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="325.09" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">You are <REDACTED>, a platform providing customer support. You serve clients from numerous different industries: internet providers, financial institutions, e-commerce platforms, entertainment websites, etc. All these clients have customer that can contact customer support to obtain information, complain about something, or other reasons to contact the customer support team. Your task is to generate a procedure that helps an agent to fulfil a task. The agent can take actions or they can ask the customer for data (e.g., email address). You can include branching in the procedure. Do not give general statements such as "Each system might have different processes". Instead, assume the role of a specific company that has very defined processes. Do not give general steps such as "Explain the company’s policy". The agent is following a procedure, so all steps need to be clearly stated, e.g., state precisely what is the policy. Do not leave room for ambiguity nor lack of information. Do not state conditionals that are not resolved in the procedures such as "If it is allowed by the policy". Every conditional has to be fully contained in the procedure, the agent should not have to read another document nor rely on other knowledge about the company’s procedures. Your role is to make up reasonable scenarios that are unambiguous. Steps should be precise and granular. Avoid giving examples, we want a concise procedure. Do not include actions that are unrelated to the interaction with the client (e.g., document the interaction, monitor the process). The procedure is solely on how to address the issue reported by the customer. Assume that you don’t have a browser. Do not include navigation steps, just the actions that the agent should take.</foreignobject></g></g></svg><svg class="ltx_picture" height="348.43" id="A1.SS2.p2.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,348.43) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 330.38)"><foreignobject color="#FFFFFF" height="12.15" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">User prompt</foreignobject></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="298.88" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">[⬇](data:text/plain;base64,IyBJc3N1ZQp7eyBpc3N1ZSB9fQ==) #  Issue {{  issue  }}</foreignobject></g></g></svg>

### A.3 API extraction

<svg class="ltx_picture" height="2142.39" id="A1.SS3.p1.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,2142.39) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 2124.34)"><foreignobject color="#FFFFFF" height="12.15" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">System prompt</foreignobject></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="2092.85" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">You are a programming assistant working for a customer experience company. Given a procedure an agent should follow to solve a customer problem, your job is to extract ALL possible APIs used by the agent. Never generate an API call that asks for passwords. The APIs should be as specific as possible to what is in the procedure and not general methods. All the API parameters should have type different than None. When representing structured output follow python convention like list[str] or dict[str, float]. Optional parameters should follow the python convetion of Optional[str]. If the procedure doesn’t have any action an agent should solve, return an empty JSON. [⬇](data:text/plain;base64,IyBPdXRwdXQKUmVzcG9uZCBvbmx5IGluIEpTT04gZm9ybWF0IHdpdGggdGhlIGZvbGxvd2luZyBzY2hlbWEuIFRoZSBuYW1lIG9mIHRoZSBhcGkgc2hvdWxkIGJlIHdyaXR0ZW4gaW4gc25ha2UgY2FzZS4KeyJhcGlzIjogW3sibmFtZSI6IHN0ciwgImRlc2MiOiBzdHIsICJwYXJhbXMiOiBbeyJuYW1lIjogc3RyfV0sICAib3V0cHV0IjogeyJuYW1lIjogc3RyLCAidHlwZSI6IHN0cn19XX0=) #  Output Respond  only  in  JSON  format  with  the  following  schema.  The  name  of  the  api  should  be  written  in  snake  case. {"apis":  [{"name":  str,  "desc":  str,  "params":  [{"name":  str}],  "output":  {"name":  str,  "type":  str}}]}</foreignobject></g></g></svg><svg class="ltx_picture" height="514.47" id="A1.SS3.p2.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,514.47) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 496.42)"><foreignobject color="#FFFFFF" height="12.15" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">User prompt</foreignobject></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="464.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">[⬇](data:text/plain;base64,IyBQcm9jZWR1cmUKYGBgCnt7IHByb2NlZHVyZSB9fQpgYGA=) #  Procedure ‘‘‘ {{  procedure  }} ‘‘‘</foreignobject></g></g></svg>

### A.4 Flowgraph generation

<svg class="ltx_picture" height="861.09" id="A1.SS4.p1.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,861.09) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 843.04)"><foreignobject color="#FFFFFF" height="12.15" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">System prompt</foreignobject></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="811.54" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">You are and experienced flowchart creator. You will be given a procedure enclosed by <procedure></procedure> and a list of apis that can used enclosed by <apis></apis>. Your job is to extract the flowchart used to solve the problem. Your flowchart will be used by an assistant to know how to solve the problem. The agent has no access to the procedure, so all the information has to be contained in this flowchart!! You are and experienced flowchart creator. You will be given a procedure enclosed by <procedure></procedure> and a list of apis that can used enclosed by <apis></apis>. Your job is to extract the flowchart used to solve the problem. Your flowchart will be used by an assistant to know how to solve the problem. The agent has no access to the procedure, so all the information has to be contained in this flowchart!! The flowchart is constituted by nodes and edges in the following format: [⬇](data:text/plain;base64,W25vZGVfaWRdKG5vZGVfdHlwZSl7bm9kZV9kZXNjcmlwdGlvbn0KW2VkZ2VfaWRdKHBhcmVudF9ub2RlX2lkLCBjaGlsZF9ub2RlX2lkKXtlZGdlX2Rlc2NyaXB0aW9ufQ==) [node_id](node_type){node_description} [edge_id](parent_node_id,  child_node_id){edge_description} Node ids should always be N followed by an integer. Edge ids should always be E followed by an integer. You can use nodes of the type start_message, message, api and end_message. - start_message: initial message sent by the assistant to the customer, taken from the procedure. It doesn’t have a parent node. - message: node with a message sent by an assistant to the customer. this message should have all the details found in the procedure. - api: api call the assistant should perform. - end_message: node to send a message and finish execution. Graph construction rules - The graph only have one root node of type ‘start_message‘. - An outgoing edge from a message node is the reply of the customer. Customer messages have to be specific. - An outgoing edge from an api node is the output of the api. - End nodes cannot have outgoing edges and should be of type end_message. - End nodes have the node type ‘end_message‘. - Never have an edge going back to the start node N0.</foreignobject></g></g></svg><svg class="ltx_picture" height="8199.77" id="A1.SS4.p2.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,8199.77) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="8172.21" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Details The messages by the agent and the customer should follow stricly what is in the procedure. ALL the details in the procedure need to be in the flowchat! Don’t assume that the agent will ever see the procedure, so it is critical that the details are here, such as reasons for something to fail, or information that needs to be collected. Make sure all steps are nodes. Some procedures might have branching paths. Always use the APIs when appropriate. The flowchart must be enclosed by <flow></flow>. [⬇](data:text/plain;base64,RXhhbXBsZSBvZiBhIGZsb3c6CjxmbG93PgpbTjBdKHN0YXJ0X21lc3NhZ2Upe0dyZWV0IHRoZSBjdXN0b21lcn0KW0UwXShOMCwgTjEpe0RpZG4ndCByZWNlaXZlIG15IG9yZGVyfQpbTjFdKG1lc3NhZ2Upe0FzayBjdXN0b21lciBmb3Igb3JkZXIgaWQsIHRoZSBlbWFpbCBvciBwaG9uZSBudW1iZXJ9CltFMl0oTjEsIE4yKXtHaXZlcyBvcmRlciBpZCBhbmQgZW1haWx9CltFM10oTjEsIE4zKXtHaXZlcyBvcmRlciBpZCBhbmQgcGhvbmUgbnVtYmVyfQpbTjJdKGFwaSl7Z2V0X29yZGVyX2RldGFpbHNfYnlfZW1haWx9CltOM10oYXBpKXtnZXRfb3JkZXJfZGV0YWlsc19ieV9waG9uZV9udW1iZXJ9CltONF0obWVzc2FnZSl7RG8geW91IHdhbnQgdG8gY2FuY2VsIG9yIHJlZnVuZCB0aGUgb3JkZXI/fQpbRTNdKE4yLCBONCl7Rm91bmQgb3JkZXJ9CltFNV0oTjMsIE40KXtGb3VuZCBvcmRlcn0KW041XShtZXNzYWdlKXtUZWxsIHRoZSB1c2VyIHRoZSBvcmRlciB3YXNuJ3QgZm91bmQgYW5kIGFzayBmb3IgY29ycmVjdCBpbmZvcm1hdGlvbn0KW0U1XShOMiwgTjUpe09yZGVyIG5vdCBGb3VuZH0KW0U2XShOMywgTjUpe09yZGVyIG5vdCBGb3VuZH0KW0U2XShONSwgTjIpe1VzZXIgcHJvdmlkZXMgYW5vdGhlciBlbWFpbCBvciBvcmRlciBpZH0KW0U3XShONSwgTjMpe1VzZXIgcHJvdmlkZXMgYW5vdGhlciBwaG9uZSBudW1iZXIgb3Igb3JkZXIgaWR9CltONl0oYXBpKXtjYW5jZWxfb3JkZXJ9CltFOF0oTjQsIE42KXtJIHdhbnQgdG8gY2FuY2VsIHRoZSBvcmRlcn0KW043XShlbmRfbWVzc2FnZSl7T3JkZXIgY2FuY2VsbGVkfQpbRTldKE42LCBONyl7U3VjY2Vzc30KW044XShhcGkpe3JlZnVuZF9vcmRlcn0KW0U5XShONCwgTjgpe0kgd2FudCBhIHJlZnVuZH0KW045XShlbmRfbWVzc2FnZSl7T3JkZXIgcmVmdW5kZWR9CltFMTBdKE44LCBOOSl7U3VjY2Vzc30KPC9mbG93PgoKPGFwaXM+Cnt7IGFwaXMgfX0KPC9hcGlzPg==) Example  of  a  flow: <flow> [N0](start_message){Greet  the  customer} [E0](N0,  N1){Didn’t  receive  my  order} [N1](message){Ask  customer  for  order  id,  the  email  or  phone  number} [E2](N1,  N2){Gives  order  id  and  email} [E3](N1,  N3){Gives  order  id  and  phone  number} [N2](api){get_order_details_by_email} [N3](api){get_order_details_by_phone_number} [N4](message){Do  you  want  to  cancel  or  refund  the  order?} [E3](N2,  N4){Found  order} [E5](N3,  N4){Found  order} [N5](message){Tell  the  user  the  order  wasn’t  found  and  ask  for  correct  information} [E5](N2,  N5){Order  not  Found} [E6](N3,  N5){Order  not  Found} [E6](N5,  N2){User  provides  another  email  or  order  id} [E7](N5,  N3){User  provides  another  phone  number  or  order  id} [N6](api){cancel_order} [E8](N4,  N6){I  want  to  cancel  the  order} [N7](end_message){Order  cancelled} [E9](N6,  N7){Success} [N8](api){refund_order} [E9](N4,  N8){I  want  a  refund} [N9](end_message){Order  refunded} [E10](N8,  N9){Success} </flow> <apis> {{  apis  }} </apis></foreignobject></g></g></svg><svg class="ltx_picture" height="448.05" id="A1.SS4.p3.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,448.05) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 430)"><foreignobject color="#FFFFFF" height="12.15" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">User prompt</foreignobject></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="398.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">[⬇](data:text/plain;base64,PHByb2NlZHVyZT4Ke3sgcHJvY2VkdXJlIH19CjwvcHJvY2VkdXJlPg==) <procedure> {{  procedure  }} </procedure></foreignobject></g></g></svg>

### A.5 Conversation graph generation

<svg class="ltx_picture" height="1175.8" id="A1.SS5.p1.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,1175.8) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 1157.75)"><foreignobject color="#FFFFFF" height="12.15" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">System prompt</foreignobject></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="1126.25" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Your task is to convert a flowchart into a conversation graph. The flowchart will be given in between <flowchart></flowchart>. The flowchart is constituted by nodes and edges in the following format: [⬇](data:text/plain;base64,W25vZGVfaWRdKG5vZGVfdHlwZSl7bm9kZV9kZXNjcmlwdGlvbn0KW2VkZ2VfaWRdKHBhcmVudF9ub2RlX2lkLCBjaGlsZF9ub2RlX2lkKXtlZGdlX2Rlc2NyaXB0aW9ufQ==) [node_id](node_type){node_description} [edge_id](parent_node_id,  child_node_id){edge_description} Nodes are of the following types: - start_message: initial message sent by the assistant to the customer, taken from the procedure. - message: node with a message sent by an assistant to the customer. - api: api call the assistant should perform. - end_message: node to send an assistant message and finish execution. You need to convert it into a conversation graph where: [⬇](data:text/plain;base64,W25vZGVfaWRdKG5vZGVfdHlwZSl7bm9kZV9kZXNjcmlwdGlvbn0KW2VkZ2VfaWRdKHBhcmVudF9ub2RlX2lkLCBjaGlsZF9ub2RlX2lkKXtlZGdlX2Rlc2NyaXB0aW9ufQ==) [node_id](node_type){node_description} [edge_id](parent_node_id,  child_node_id){edge_description} Nodes are of the following types: - assistant: message sent by the agent. - user: message sent by the user. - api: api call the agent should perform. Graph construction rules: - api nodes have outgoing edges with labels - api nodes are followed by api or assistant nodes - user nodes are followed by api or assistant nodes - assistant nodes **can be only followed by** user nodes - leaf nodes are assistant nodes</foreignobject></g></g></svg><svg class="ltx_picture" height="13031.2" id="A1.SS5.p2.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,13031.2) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="13003.64" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Edges connect user nodes to either assistant or api nodes. Only edges from API calls can have descriptions. The first node should start with an assistant node without any parent node. For instance, consider the following flow graph: [⬇](data:text/plain;base64,PGZsb3c+CltOMF0oc3RhcnRfbWVzc2FnZSl7R3JlZXQgdGhlIGN1c3RvbWVyfQpbRTBdKE4wLCBOMSl7RGlkbid0IHJlY2VpdmUgbXkgb3JkZXJ9CltOMV0obWVzc2FnZSl7QXNrIGN1c3RvbWVyIGZvciBvcmRlciBpZH0KW0UyXShOMSwgTjIpe0dpdmVzIG9yZGVyIGlkfQpbTjJdKGFwaSl7Z2V0X29yZGVyX2RldGFpbHN9CltOM10obWVzc2FnZSl7RG8geW91IHdhbnQgdG8gY2FuY2VsIG9yIHJlZnVuZCB0aGUgb3JkZXI/fQpbRTNdKE4yLCBOMyl7Rm91bmQgb3JkZXJ9CltONF0obWVzc2FnZSl7VGVsbCB0aGUgdXNlciB0aGUgb3JkZXIgd2Fzbid0IGZvdW5kfQpbRTRdKE4yLCBONCl7T3JkZXIgbm90IEZvdW5kfQpbRTVdKE40LCBOMil7VXNlciBnaXZlcyBhbm90aGVyIG9yZGVyIGlkfQpbTjVdKGFwaSl7Y2FuY2VsX29yZGVyfQpbRTZdKE4zLCBONSl7SSB3YW50IHRvIGNhbmNlbCB0aGUgb3JkZXJ9CltONl0oZW5kX21lc3NhZ2Upe09yZGVyIGNhbmNlbGxlZH0KW0U3XShONSwgTjYpe1N1Y2Nlc3N9CltON10oYXBpKXtyZWZ1bmRfb3JkZXJ9CltFOF0oTjMsIE43KXtJIHdhbnQgYSByZWZ1bmR9CltOOF0oZW5kX21lc3NhZ2Upe09yZGVyIHJlZnVuZGVkfQpbRTldKE43LCBOOCl7U3VjY2Vzc30KPC9mbG93Pg==) <flow> [N0](start_message){Greet  the  customer} [E0](N0,  N1){Didn’t  receive  my  order} [N1](message){Ask  customer  for  order  id} [E2](N1,  N2){Gives  order  id} [N2](api){get_order_details} [N3](message){Do  you  want  to  cancel  or  refund  the  order?} [E3](N2,  N3){Found  order} [N4](message){Tell  the  user  the  order  wasn’t  found} [E4](N2,  N4){Order  not  Found} [E5](N4,  N2){User  gives  another  order  id} [N5](api){cancel_order} [E6](N3,  N5){I  want  to  cancel  the  order} [N6](end_message){Order  cancelled} [E7](N5,  N6){Success} [N7](api){refund_order} [E8](N3,  N7){I  want  a  refund} [N8](end_message){Order  refunded} [E9](N7,  N8){Success} </flow> The correct output is: [⬇](data:text/plain;base64,PGZsb3c+CltOMF0oYXNzaXN0YW50KXtHcmVldCB0aGUgY3VzdG9tZXJ9CltOMV0odXNlcil7RGlkbid0IHJlY2VpdmUgbXkgb3JkZXJ9CltFMF0oTjAsIE4xKXt9CltOMl0oYXNzaXN0YW50KXtBc2sgY3VzdG9tZXIgZm9yIG9yZGVyIGlkfQpbRTFdKE4xLCBOMil7fQpbTjNdKHVzZXIpe0dpdmVzIG9yZGVyIGlkfQpbRTJdKE4yLCBOMyl7fQpbTjRdKGFwaSl7Z2V0X29yZGVyX2RldGFpbHN9CltFM10oTjMsIE40KXt9CltONV0oYXNzaXN0YW50KXtEbyB5b3Ugd2FudCB0byBjYW5jZWwgb3IgcmVmdW5kIHRoZSBvcmRlcj99CltFNF0oTjQsIE41KXtGb3VuZCBvcmRlcn0KW042XShhc3Npc3RhbnQpe1RlbGwgdGhlIHVzZXIgdGhlIG9yZGVyIHdhc24ndCBmb3VuZH0KW0U0XShONCwgTjYpe09yZGVyIG5vdCBGb3VuZH0KW043XSh1c2VyKXtVc2VyIGdpdmVzIGFub3RoZXIgb3JkZXIgaWR9CltFNV0oTjYsIE43KXt9CltFNl0oTjcsIE40KXt9CltOOF0odXNlcil7SSB3YW50IHRvIGNhbmNlbCB0aGUgb3JkZXJ9CltFN10oTjUsIE44KXt9CltOOV0oYXBpKXtjYW5jZWxfb3JkZXJ9CltFOF0oTjgsIE45KXt9CltOMTBdKGFzc2lzdGFudCl7T3JkZXIgY2FuY2VsbGVkfQpbRTldKE45LCBOMTApe1N1Y2Nlc3N9CltOMTFdKHVzZXIpe0kgd2FudCBhIHJlZnVuZH0KW0UxMF0oTjUsIE4xMSl7fQpbTjEyXShhcGkpe3JlZnVuZF9vcmRlcn0KW0UxMV0oTjExLCBOMTIpe30KW04xM10oYXNzaXN0YW50KXtZb3VyIG9yZGVyIGhhcyBiZWVuIHJlZnVuZGVkfQpbRTEyXShOMTIsIE4xMyl7U3VjY2Vzc30KPC9mbG93Pg==) <flow> [N0](assistant){Greet  the  customer} [N1](user){Didn’t  receive  my  order} [E0](N0,  N1){} [N2](assistant){Ask  customer  for  order  id} [E1](N1,  N2){} [N3](user){Gives  order  id} [E2](N2,  N3){} [N4](api){get_order_details} [E3](N3,  N4){} [N5](assistant){Do  you  want  to  cancel  or  refund  the  order?} [E4](N4,  N5){Found  order} [N6](assistant){Tell  the  user  the  order  wasn’t  found} [E4](N4,  N6){Order  not  Found} [N7](user){User  gives  another  order  id} [E5](N6,  N7){} [E6](N7,  N4){} [N8](user){I  want  to  cancel  the  order} [E7](N5,  N8){} [N9](api){cancel_order} [E8](N8,  N9){} [N10](assistant){Order  cancelled} [E9](N9,  N10){Success} [N11](user){I  want  a  refund} [E10](N5,  N11){} [N12](api){refund_order} [E11](N11,  N12){} [N13](assistant){Your  order  has  been  refunded} [E12](N12,  N13){Success} </flow></foreignobject></g></g></svg><svg class="ltx_picture" height="282.01" id="A1.SS5.p3.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,282.01) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 263.96)"><foreignobject color="#FFFFFF" height="12.15" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">User prompt</foreignobject></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="232.46" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">[⬇](data:text/plain;base64,e3sgZmxvd2dyYXBoIH19) {{  flowgraph  }}</foreignobject></g></g></svg>

### A.6 Conversations generation

<svg class="ltx_picture" height="196.22" id="A1.SS6.p1.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,196.22) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 178.17)"><foreignobject color="#FFFFFF" height="12.15" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">System prompt</foreignobject></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="146.67" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">You will receive a conversation graph with nodes and edges in the following format: -[Ni](assistant){message}: Agent nodes with the corresponding message. -[Nj](user){message}: User nodes with the corresponding message. -[Nk](api){message}: API nodes with the corresponding message. The graph also has edges with the following format: -[Ei](Ni,Nj){}: Message Ni happens before Nj. -[Ej](Ni,Nj){api_output}: Only applicable when Ni is an API node. Message Ni happens before Nj and has api outputs api_output. The flowchart is given inside <flow></flow>. The initial node is [N1]. The agent is guiding the user throughout the process. Our goal is to generate conversations based on the graph that follow the specified paths, given between <paths></paths>.</foreignobject></g></g></svg><svg class="ltx_picture" height="13862.48" id="A1.SS6.p2.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,13862.48) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="13834.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">For instance, consider the following flow graph: [⬇](data:text/plain;base64,PGZsb3c+CltOMV0oYXNzaXN0YW50KXtHcmVldCB0aGUgY3VzdG9tZXJ9CltOMl0odXNlcil7RGlkbid0IHJlY2VpdmUgbXkgb3JkZXJ9CltFMV0oTjEsIE4yKXt9CltOM10oYXNzaXN0YW50KXtBc2sgY3VzdG9tZXIgZm9yIG9yZGVyIGlkfQpbRTJdKE4yLCBOMyl7fQpbTjRdKHVzZXIpe0dpdmVzIG9yZGVyIGlkfQpbRTNdKE4zLCBONCl7fQpbTjVdKGFwaSl7Z2V0X29yZGVyX2RldGFpbHN9CltFNF0oTjQsIE41KXt9CltONl0oYXNzaXN0YW50KXtXYW50IHRvIGNhbmNlbCBvciByZWZ1bmQgdGhlIG9yZGVyP30KW0U1XShONSwgTjYpe0ZvdW5kIG9yZGVyfQpbTjddKGFzc2lzdGFudCl7VGVsbCB1c2VyIHRoZSBvcmRlciB3YXNuJ3QgZm91bmR9CltFNV0oTjUsIE43KXtPcmRlciBub3QgRm91bmR9CltOOF0odXNlcil7VXNlciBnaXZlcyBhbm90aGVyIG9yZGVyIGlkfQpbRTZdKE43LCBOOCl7fQpbRTddKE44LCBONSl7fQpbTjldKHVzZXIpe0kgd2FudCB0byBjYW5jZWwgdGhlIG9yZGVyfQpbRThdKE42LCBOOSl7fQpbTjEwXShhcGkpe2NhbmNlbF9vcmRlcn0KW0U5XShOOSwgTjEwKXt9CltOMTFdKGFzc2lzdGFudCl7T3JkZXIgY2FuY2VsbGVkfQpbRTEwXShOMTAsIE4xMSl7U3VjY2Vzc30KW04xMl0odXNlcil7SSB3YW50IGEgcmVmdW5kfQpbRTExXShONiwgTjEyKXt9CltOMTNdKGFwaSl7cmVmdW5kX29yZGVyfQpbRTEyXShOMTIsIE4xMyl7fQpbTjE0XShhc3Npc3RhbnQpe09yZGVyIHJlZnVuZGVkfQpbRTEzXShOMTMsIE4xNCl7U3VjY2Vzc30KPC9mbG93Pg==) <flow> [N1](assistant){Greet  the  customer} [N2](user){Didn’t  receive  my  order} [E1](N1,  N2){} [N3](assistant){Ask  customer  for  order  id} [E2](N2,  N3){} [N4](user){Gives  order  id} [E3](N3,  N4){} [N5](api){get_order_details} [E4](N4,  N5){} [N6](assistant){Want  to  cancel  or  refund  the  order?} [E5](N5,  N6){Found  order} [N7](assistant){Tell  user  the  order  wasn’t  found} [E5](N5,  N7){Order  not  Found} [N8](user){User  gives  another  order  id} [E6](N7,  N8){} [E7](N8,  N5){} [N9](user){I  want  to  cancel  the  order} [E8](N6,  N9){} [N10](api){cancel_order} [E9](N9,  N10){} [N11](assistant){Order  cancelled} [E10](N10,  N11){Success} [N12](user){I  want  a  refund} [E11](N6,  N12){} [N13](api){refund_order} [E12](N12,  N13){} [N14](assistant){Order  refunded} [E13](N13,  N14){Success} </flow> And the apis are: [⬇](data:text/plain;base64,PGFwaXM+ClsKICAgIHsKICAgICAgICAibmFtZSI6ICJnZXRfb3JkZXJfZGV0YWlscyIsCiAgICAgICAgInBhcmFtcyI6IFt7Im9yZGVyX2lkIjogImludCJ9XSwKICAgICAgICAib3V0cHV0IjogeyduYW1lJzogJ3NlbnRfc3RhdHVzJywgJ3R5cGUnOiAnbGlzdFtkaWN0W3N0ciwgc3RyXV0nfQogICAgfQpdCjwvYXBpcz4=) <apis> [ { "name":  "get_order_details", "params":  [{"order_id":  "int"}], "output":  {’name’:  ’sent_status’,  ’type’:  ’list[dict[str,  str]]’} } ] </apis> If the given path is: [N1, N2, N3, N4, N5, N7], one possible conversation is the following: [⬇](data:text/plain;base64,WwogICAgewogICAgICAgICJyb2xlIjogInVzZXIiLAogICAgICAgICJjb250ZW50IjogIkkgZGlkbid0IHJlY2VpdmUgbXkgb3JkZXIiCiAgICB9LAogICAgewogICAgICAgICJyb2xlIjogImFzc2lzdGFudCIsCiAgICAgICAgImNvbnRlbnQiOiAiQ2FuIHlvdSBnaXZlIG1lIHRoZSBvcmRlciBJRD8iCiAgICB9LAogICAgICAgIHsKICAgICAgICAicm9sZSI6ICJ1c2VyIiwKICAgICAgICAiY29udGVudCI6ICJUaGUgb3JkZXIgSUQgaXMgIzgxMiIKICAgIH0sCiAgICB7CiAgICAgICAgInJvbGUiOiAiYXBpIiwKICAgICAgICAiY29udGVudCI6ICJnZXRfb3JkZXJfZGV0YWlscyhvcmRlcl9pZD04MTIpIgogICAgfSwKICAgIHsKICAgICAgICAicm9sZSI6ICJhcGlfb3V0cHV0IiwKICAgICAgICAiY29udGVudCI6ICJ7InNlbnRfc3RhdHVzIjogW3siaXRlbSI6ICJQcm9kdWN0MSIsICJzdGF0dXMiOiAic2hpcHBlZCJ9XX0iCiAgICB9LAogICAgewogICAgICAgICJyb2xlIjogImFzc2lzdGFudCIsCiAgICAgICAgImNvbnRlbnQiOiAiSSBjb3VsZG4ndCBmaW5kIHlvdXIgb3JkZXIuIgogICAgfSwKXQ==) [ { "role":  "user", "content":  "I  didn’t  receive  my  order" }, { "role":  "assistant", "content":  "Can  you  give  me  the  order  ID?" }, { "role":  "user", "content":  "The  order  ID  is  #812" }, { "role":  "api", "content":  "get_order_details(order_id=812)" }, { "role":  "api_output", "content":  "{"sent_status":  [{"item":  "Product1",  "status":  "shipped"}]}" }, { "role":  "assistant", "content":  "I  couldn’t  find  your  order." }, ] Generate the conversation in the format specified above. When making information up, come up with reasonable names and never generic entities like Example1, ProductX, and similar. For example, if talking about products, mention existing products. Only use the given APIs and make sure all the parameters are defined. The conversations should follow the following rules: - After a message with api role always include a message with api_output role. - After a message with the assistant role always follow with a message with user role. - A message with the user role is followed by a message with assistant or api role. - After a message with a api_output role always include a message with assistant role. - The API output should be in the format specified in the API definition. That is always in JSON format. Note that, even if the node does not exist in the graph, the first message should be a message by the user explaining their problem.</foreignobject></g></g></svg><svg class="ltx_picture" height="746.93" id="A1.SS6.p3.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,746.93) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 728.88)"><foreignobject color="#FFFFFF" height="12.15" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">User prompt</foreignobject></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="697.38" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">[⬇](data:text/plain;base64,e3sgY29udmVyc2F0aW9uX2dyYXBoIH19CjxhcGlzPnt7IGFwaXMgfX08L2FwaXM+CnBhdGg6IHt7IHBhdGggfX0=) {{  conversation_graph  }} <apis>{{  apis  }}</apis> path:  {{  path  }}</foreignobject></g></g></svg>

### A.7 Conversations from procedures

<svg class="ltx_picture" height="17206.37" id="A1.SS7.p1.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,17206.37) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 17188.32)"><foreignobject color="#FFFFFF" height="12.15" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">System prompt</foreignobject></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="17156.82" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">You are an experienced customer service agent. You will be given a procedure enclosed by <procedure></procedure> and a list of apis that can used enclosed by <apis></apis>. Your goal is to generate conversations between an agent and a customer that could be solved used the given procedure and apis. For instance, consider the following procedure: [⬇](data:text/plain;base64,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) <procedure> #  Handling  a  Customer  Who  Didn’t  Receive  Their  Order Start  Interaction: 1.1.  Greet  the  customer  courteously. Identify  the  Issue: 2.1.  Confirm  the  customer  didn’t  receive  the  order. Obtain  Order  Information: 3.1.  Ask  the  customer  to  provide  their  order  ID  along  with  the  email  address  or  phone  number  associated  with  the  order. Retrieve  Order  Details: 4.1.  If  the  customer  provides  the  order  ID  and  email  address: -  Use  the  company’s  API  to  retrieve  order  details  by  email. 4.2.  If  the  customer  provides  the  order  ID  and  phone  number: -  Use  the  company’s  API  to  retrieve  order  details  by  phone  number. Check  if  Order  is  Found: 5.1.  If  the  order  is  found,  proceed  to  Step  6. 5.2.  If  the  order  is  not  found: -  Inform  the  customer  that  the  order  wasn’t  found. -  Ask  the  customer  to  provide  the  correct  email  or  phone  number  and  order  ID. -  Repeat  Step  3  based  on  the  new  information. Determine  Customer’s  Request: 6.1.  Ask  the  customer  if  they  would  like  to  cancel  the  order  or  request  a  refund. Processing  Customer’s  Request: 7.1.  Cancellation: -  If  the  customer  wants  to  cancel  the  order: -  Use  the  company’s  API  to  cancel  the  order. -  Upon  successful  cancellation,  inform  the  customer  that  the  order  has  been  cancelled. 7.2.  Refund: -  If  the  customer  wants  a  refund: -  Use  the  company’s  API  to  process  the  refund. -  Upon  successful  refund,  inform  the  customer  that  the  order  has  been  refunded. End  Interaction: 8.1.  Conclude  by  thanking  the  customer  for  their  patience  and  confirming  resolution. And the apis are: [⬇](data:text/plain;base64,PGFwaXM+ClsKICAgIHsKICAgICAgICAibmFtZSI6ICJnZXRfb3JkZXJfZGV0YWlscyIsCiAgICAgICAgInBhcmFtcyI6IFt7Im9yZGVyX2lkIjogImludCJ9XSwKICAgICAgICAib3V0cHV0IjogImJvb2wiCiAgICB9Cl0KPC9hcGlzPg==) <apis> [ { "name":  "get_order_details", "params":  [{"order_id":  "int"}], "output":  "bool" } ] </apis> One possible conversation is the following: [⬇](data:text/plain;base64,WwogICAgewogICAgICAgICJyb2xlIjogImFzc2lzdGFudCIsCiAgICAgICAgImNvbnRlbnQiOiAiSGVsbG8sIGhvdyBjYW4gSSBhc3Npc3QgeW91PyIKICAgIH0sCiAgICB7CiAgICAgICAgInJvbGUiOiAidXNlciIsCiAgICAgICAgImNvbnRlbnQiOiAiSSBkaWRuJ3QgcmVjZWl2ZSBteSBvcmRlciIKICAgIH0sCiAgICB7CiAgICAgICAgInJvbGUiOiAiYXNzaXN0YW50IiwKICAgICAgICAiY29udGVudCI6ICJDYW4geW91IGdpdmUgbWUgdGhlIG9yZGVyIElEPyIKICAgIH0sCiAgICB7CiAgICAgICAgInJvbGUiOiAidXNlciIsCiAgICAgICAgImNvbnRlbnQiOiAiVGhlIG9yZGVyIElEIGlzICM4MTIiCiAgICB9LAogICAgewogICAgICAgICJyb2xlIjogImFwaSIsCiAgICAgICAgImNvbnRlbnQiOiAiZ2V0X29yZGVyX2RldGFpbHMob3JkZXJfaWQ9ODEyKSIKICAgIH0sCiAgICB7CiAgICAgICAgInJvbGUiOiAiYXBpX291dHB1dCIsCiAgICAgICAgImNvbnRlbnQiOiAiRmFsc2UiCiAgICB9LAogICAgewogICAgICAgICJyb2xlIjogImFzc2lzdGFudCIsCiAgICAgICAgImNvbnRlbnQiOiAiSSdtIHNvcnJ5IGJ1dCBJIGNvdWxkbid0IGZpbmQgeW91ciBvcmRlci4iCiAgICB9LApd) [ { "role":  "assistant", "content":  "Hello,  how  can  I  assist  you?" }, { "role":  "user", "content":  "I  didn’t  receive  my  order" }, { "role":  "assistant", "content":  "Can  you  give  me  the  order  ID?" }, { "role":  "user", "content":  "The  order  ID  is  #812" }, { "role":  "api", "content":  "get_order_details(order_id=812)" }, { "role":  "api_output", "content":  "False" }, { "role":  "assistant", "content":  "I’m  sorry  but  I  couldn’t  find  your  order." }, ]</foreignobject></g></g></svg><svg class="ltx_picture" height="2449.57" id="A1.SS7.p2.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,2449.57) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="2422.01" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Generate the conversation in the format specified above. When making information up, come up with reasonable names and never generic entities like Example1, ProductX, and similar. For example, if talking about products, mention existing products. Only use the given APIs and make sure all the parameters are defined. The conversations should follow the following rules: [⬇](data:text/plain;base64,LSBBZnRlciBhIG1lc3NhZ2Ugd2l0aCBhcGkgcm9sZSBhbHdheXMgaW5jbHVkZSBhIG1lc3NhZ2Ugd2l0aCBhcGlcX291dHB1dCByb2xlLgotIEFmdGVyIGEgbWVzc2FnZSB3aXRoIHRoZSBhc3Npc3RhbnQgcm9sZSBhbHdheXMgZm9sbG93IHdpdGggYSBtZXNzYWdlIHdpdGggdXNlciByb2xlLgotIEEgbWVzc2FnZSB3aXRoIHRoZSB1c2VyIHJvbGUgaXMgZm9sbG93ZWQgYnkgYSBtZXNzYWdlIHdpdGggYXNzaXN0YW50IG9yIGFwaSByb2xlLgotIEFmdGVyIGEgbWVzc2FnZSB3aXRoIGEgYXBpXF9vdXRwdXQgcm9sZSBhbHdheXMgaW5jbHVkZSBhIG1lc3NhZ2Ugd2l0aCBhc3Npc3RhbnQgcm9sZS4=) -  After  a  message  with  api  role  always  include  a  message  with  api\_output  role. -  After  a  message  with  the  assistant  role  always  follow  with  a  message  with  user  role. -  A  message  with  the  user  role  is  followed  by  a  message  with  assistant  or  api  role. -  After  a  message  with  a  api\_output  role  always  include  a  message  with  assistant  role. Note that, even if the node does not exist in the graph, the first message should be a message by the user explaining their problem.</foreignobject></g></g></svg><svg class="ltx_picture" height="663.91" id="A1.SS7.p3.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,663.91) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 645.86)"><foreignobject color="#FFFFFF" height="12.15" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">User prompt</foreignobject></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="614.36" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">[⬇](data:text/plain;base64,PHByb2NlZHVyZT57eyBwcm9jZWR1cmUgfX08L3Byb2NlZHVyZT4KPGFwaXM+e3sgYXBpcyB9fTwvYXBpcz4=) <procedure>{{  procedure  }}</procedure> <apis>{{  apis  }}</apis></foreignobject></g></g></svg>

### A.8 Tool-augmented AI agent

<svg class="ltx_picture" height="2663.36" id="A1.SS8.p1.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,2663.36) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 2645.31)"><foreignobject color="#FFFFFF" height="12.15" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">System prompt</foreignobject></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="2613.81" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">You are a customer support agent with the goal of answering user requests. You will be given the following information: [⬇](data:text/plain;base64,LSBjb252ZXJzYXRpb246IE1lc3NhZ2VzIGV4Y2hhbmdlZCBiZXR3ZWVuIHRoZSBlbmQgdXNlciBhbmQgeW91LCBhbmQgdGhlIGV4ZWN1dGVkIGFjdGlvbnMgd2l0aCB0aGVpcgpvdXRwdXRzLg==) -  conversation:  Messages  exchanged  between  the  end  user  and  you,  and  the  executed  actions  with  their outputs. This is the procedure you know about: [⬇](data:text/plain;base64,PHByb2NlZHVyZT4Ke3sgcHJvY2VkdXJlIH19CjwvcHJvY2VkdXJlPg==) <procedure> {{  procedure  }} </procedure> You only know answers about this procedure! It is critical that you do not come up with any data nor instructions that are not contained in the procedure. This is the list of available actions. [⬇](data:text/plain;base64,PGFjdGlvbnM+Cnt7IGF2YWlsYWJsZV9hY3Rpb25zIH19CjwvYWN0aW9ucz4=) <actions> {{  available_actions  }} </actions> Sometimes your action might be simply to reply to an end user, other times you will need to call an action that performs an operation and/or retrieves necessary data. Some actions require information/parameters in order to be callable. If you do not have the necessary information available in the context, YOU MUST ASK FOR IT AND CANNOT SUGGEST THE ACTION. Make sure that you follow the directives in the procedure before suggesting a relevant action. For instance, some actions have consequences and might require user confirmation before being executed, if stated in the procedure. If this is the case, suggest a reply that asks confirmation from the end user. Make sure that the information that you are using properly matches the context (e.g., the user might give a phone number that does not match what is shown in the context, which contains the output of actions.) You MUST reply with a JSON object as follows: [⬇](data:text/plain;base64,ewogICAgJ3R5cGUnOiBuYW1lIG9mIHRoZSBmdW5jdGlvbiB0byBjYWxsLAogICAgJ3BhcmFtZXRlcnMnOiBwYXJhbWV0ZXJzIHRvIHBhc3MgdG8gdGhlIGZ1bmN0aW9uLAp9) { ’type’:  name  of  the  function  to  call, ’parameters’:  parameters  to  pass  to  the  function, }</foreignobject></g></g></svg><svg class="ltx_picture" height="464.66" id="A1.SS8.p2.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,464.66) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 446.61)"><foreignobject color="#FFFFFF" height="12.15" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">User prompt</foreignobject></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="415.11" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">[⬇](data:text/plain;base64,PGNvbnZlcnNhdGlvbj4Ke3sgY29udmVyc2F0aW9uIH19CjwvY29udmVyc2F0aW9uPg==) <conversation> {{  conversation  }} </conversation></foreignobject></g></g></svg>

## Appendix B auto-ALMITA: Detailed evaluation

Supplementary Table [1](https://arxiv.org/html/2409.15934v2#A2.T1 "Table 1 ‣ Appendix B auto-ALMITA: Detailed evaluation ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents") provides detailed results obtained with the auto-ALMITA dataset, considering the 6 LLM agents and all the evaluation metrics from [Section 4.3](https://arxiv.org/html/2409.15934v2#S4.SS3 "4.3 Evaluation of LLM AI agents ‣ 4 Results ‣ Automated test generation to evaluate tool-augmented LLMs as conversational AI agents").

| LLM | Reply | API | Test | Conversation |
| Recall | Correct | Recall | Correct | Correct params. | Correct | Correct |
| GPT-4o | 91.1 | 77.1 | 89.5 | 95.1 | 84,4 | 85.4 | 14.7 |
| Mistral-NeMo-I | 89.2 | 67.5 | 89.5 | 93.8 | 80.7 | 81.3 | 10.3 |
| Claude3-s | 79.9 | 67.1 | 92.9 | 95.9 | 84.1 | 78.9 | 6.9 |
| GPT-4 | 60.5 | 82.9 | 92.6 | 94.6 | 84.5 | 75.5 | 6.4 |
| Llama3.1-8b-I | 79.4 | 61.8 | 64.3 | 95.7 | 83.8 | 73.4 | 3.2 |
| GPT-4o w/ F | 89.6 | 75.3 | 93.0 | 93.8 | 72.2 | 82.9 | 11.5 |

Table 1: LLM AI agents evaluated on auto-ALMITA. For each LLM, the highest value in shown in bold. All results are percentages.