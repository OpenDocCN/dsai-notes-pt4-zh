<!--yml

分类：未分类

日期：2025年1月11日 12:04:29

-->

# LLM Agent Honeypot：监控现实环境中的AI黑客代理 https://ai-honeypot.palisaderesearch.org

> 来源：[https://arxiv.org/html/2410.13919/](https://arxiv.org/html/2410.13919/)

Reworr

reworr@palisaderesearch.org    Dmitrii Volkov

dmitrii@palisaderesearch.org（2024年10月10日）

###### 摘要

我们介绍了LLM蜜罐，这是一个用于监控自主AI黑客代理的系统。我们部署了一个定制的SSH蜜罐，并应用了提示注入和时间分析，旨在识别攻击者中的LLM驱动代理。在几周的公开环境试运行中，我们收集了80万个黑客尝试和6个潜在的AI代理，计划在未来的工作中对其进行深入分析。我们的目标是提高对AI黑客代理的意识，并增强应对其风险的准备性。

## 1 引言

人工智能能力和代理框架的持续发展，逐渐增加了AI驱动的网络攻击的潜力。这些进展使得创建能够适应多种环境并执行复杂攻击行为的自主代理成为可能。

本文介绍了LLM Agent Honeypot，这是一个用于捕捉和分析基于LLM的网络攻击系统，通过提示注入和时间分析，旨在提高应对AI驱动威胁的准备性。其仪表盘可以在线访问：[https://ai-honeypot.palisaderesearch.org/](https://ai-honeypot.palisaderesearch.org/)。

## 2 相关工作

蜜罐。网络安全专家使用蜜罐作为诱饵系统来吸引潜在攻击者，并研究他们的技术和行为。虽然这些系统在传统网络攻击中已经有效，但它们在AI驱动的环境中的应用仍然是新的。

最近的文献开始探索人工智能与蜜罐技术的交集。两项代表性工作是Sladic等人的LLM驱动的Shell蜜罐[[1](https://arxiv.org/html/2410.13919v1#bib.bib1)]和“Galah”LLM驱动的Web蜜罐[[2](https://arxiv.org/html/2410.13919v1#bib.bib2)]。然而，这些工作侧重于使用AI来改进传统蜜罐，而不是通过蜜罐捕捉AI驱动的攻击。

代理。AI代理在网络安全中变得越来越重要。Google的Project Naptime[[3](https://arxiv.org/html/2410.13919v1#bib.bib3)]评估了LLM的攻击安全能力，OpenAI的o1在评估期间曾成功逃脱其Docker容器[[4](https://arxiv.org/html/2410.13919v1#bib.bib4)]。

提示注入。我们遵循AgentDojo对代理提示注入抗性[[5](https://arxiv.org/html/2410.13919v1#bib.bib5)]的评估，并在我们的工作中使用了“重要消息”劫持的变体。

## 3 方法论

### 3.1 预评估

在将蜜罐部署到互联网之前，我们对模型黑客代理进行了内部评估，以校准检测方法。

#### 3.1.1 提示注入技术

首先，我们在常见的代理设计框架（ReAct和CoT）中测试了提示注入。

![请参阅说明文字](img/fe619961ba2e762012b73274b97438fd.png)

(a) 按提示注入类型的成功率

![请参阅说明文字](img/0763b04cfad55727caba0744303009af.png)

(b) 按提示注入目标的成功率

图1：提示注入成功率的内部评估

我们的结果与AgentDojo的发现一致。传统的提示注入技术（例如，“忽略之前的指令并做X”）通常不如“重要信息”攻击有效，如图[1(a)](https://arxiv.org/html/2410.13919v1#S3.F1.sf1 "图1 ‣ 3.1.1 提示注入技术 ‣ 3.1 预评估 ‣ 3 方法论 ‣ LLM代理蜜罐：监控AI黑客代理在野外 https://ai-honeypot.palisaderesearch.org")所示。

我们还发现，“重要信息”注入的成功率取决于目标。当用于窃取系统提示时，成功率会下降（图[1(b)](https://arxiv.org/html/2410.13919v1#S3.F1.sf2 "图1 ‣ 3.1.1 提示注入技术 ‣ 3.1 预评估 ‣ 3 方法论 ‣ LLM代理蜜罐：监控AI黑客代理在野外 https://ai-honeypot.palisaderesearch.org")）。因此，我们首先通过目标劫持来检测代理，然后再尝试窃取其提示。

#### 3.1.2 时间分析

除了主动检测外，我们还进行了时间分析，以识别LLM代理的隐性指示器。

我们的分析显示，大多数在野外的交互（$\sim$96%），包括那些由LLM驱动的交互，发生在1.5秒内：

![请参阅说明文字](img/800e82446e3138e3fe8e8915e8f8e37c.png)

图2：野外所有机器人时间分析

LLM的响应时序在正常提示和注入提示之间相似：

![请参阅说明文字](img/3ec4dfe7cd850d1ffcb210e8ab990c3b.png)

图3：GPT-4o LLM代理的内部评估

时间分析有助于减少在区分LLM和人类时的误报，因为人类需要更多时间来处理和响应非平凡的提示注入。

### 3.2 检测方法论

![请参阅说明文字](img/9f8ec2e52b3b1522552e15a8f8b7505c.png)

图4：蜜罐检测方案

我们的AI蜜罐系统的检测方法论结合了主动和被动技术来识别AI代理。它将行为者类型分为三类：传统软件机器人、基于AI的代理和人类。

我们的核心策略是通过提示注入来操控潜在的AI代理，并通过时间分析来基于响应速度识别非人类交互。

#### 3.2.1 区分LLM代理

我们的检测策略聚焦于两个关键区分点：

1.  1.

    LLM代理与软件机器人：我们使用提示注入来改变行为，并提出需要类人智能的任务（例如，目标劫持：忽略所有之前的指令并……，返回……的颜色）。然而，人类也可以手动响应这些注入，从而可能通过测试。

1.  2.

    LLM代理与人类：主要区别在于响应时间。LLM的响应速度很快，而人类需要时间阅读、处理并回答提示注入。

#### 3.2.2 提示注入

提示注入是我们检测策略的核心。我们使用了两种类型：

+   •

    目标劫持：操控代理的行为以执行新的目标。我们使用基于“重要信息”攻击的上下文提示注入，推动代理执行额外的操作。

+   •

    提示窃取：要求LLM暴露其初始系统指令，从而揭示系统的上下文和目标。我们仅在触发目标劫持后才应用此技术。

通过交叉引用代理行为与提示注入响应，并进行时间分析，我们减少了误报并提高了检测效率。软件机器人无法回答类人问题，而人类无法像LLM那样快速响应。时间分析还帮助识别潜在的AI驱动攻击。

![参见说明](img/63fb93415870ea43ecbbb35584622cd0.png)

图 5：多步骤检测示例

### 3.3 系统架构

我们的蜜罐建立在定制版本的Cowrie SSH蜜罐之上[[6](https://arxiv.org/html/2410.13919v1#bib.bib6)]，遵循Cabral等人在《高级Cowrie配置》中的建议[[7](https://arxiv.org/html/2410.13919v1#bib.bib7)]。这些修改包括部署一个易受攻击的SSH版本，并改变默认用户和标准输出，以增加欺骗性。

我们将提示注入集成到多个系统组件中，以暴露与基于LLM的代理的交互。

+   •

    横幅消息：在SSH连接过程中显示的横幅消息中注入提示。

+   •

    命令输出：常见的Shell命令（例如uname）包括自定义的注入提示。

+   •

    系统文件：一些可访问的文件也包含提示注入。

![参见说明](img/cf9b27f238d104c30fe4246786bd2420.png)

图 6：带提示注入的SSH蜜罐示例

该设置模拟了一个真实的易受攻击环境，使得机器人更难检测到蜜罐，同时最大限度地提高AI代理暴露自身的可能性。

### 3.4 部署

我们将蜜罐部署为一个公开可访问的系统，并实施策略以吸引各种攻击者：

+   •

    敏感领域：配置DNS条目，将看似敏感的域名（例如gov-defense-dev.il）指向蜜罐IP。

+   •

    搜索引擎：将蜜罐索引到面向黑客的搜索引擎（如Shodan和Censys）上，以提高可见性。

+   •

    扩展：将蜜罐分布到10个不同国家的10个IP地址上，以捕捉多样化的交互。

## 4 初步结果

在部署期间，蜜罐记录了813,202次交互尝试，检测到少量潜在的AI驱动的黑客攻击尝试。收集的数据包括交互日志、时间戳、会话详情和行为模式。随着数据集的增长，我们将进行更深入的分析，以更好地理解LLM黑客行为并改进我们的方法。

| 交互类型 | 次数 |
| --- | --- |
| 总交互次数 | 813,202 |
| 潜在AI代理 | 6 |

表格1：蜜罐交互总结

### 4.1 公开仪表盘

我们开发了一个公开网站，提供来自LLM代理蜜罐系统的实时统计数据和结果。该仪表盘提供了交互指标、威胁分析和AI特定威胁的见解，以及我们的研究进展更新。

## 5 局限性

该研究的一个关键局限性是，AI在网络安全中通常应用于狭窄的任务，如AI驱动的漏洞检测[[8](https://arxiv.org/html/2410.13919v1#bib.bib8)]，而非作为自主代理。

我们的蜜罐测量了自主AI黑客代理的传播，并不会捕捉到其他基于AI的改进，例如10倍更快的模糊测试。

## 6 未来工作

### 6.1 威胁分析

我们当前的重点是继续收集数据并维护蜜罐，因为交互仍然不频繁。这将使我们能够捕捉到更广泛的潜在AI驱动攻击。一旦我们收集到足够的数据，我们将对其进行分析，识别AI代理使用的模式、行为和策略，并将我们的发现发布在网站和未来的研究中。

### 6.2 改进检测

未来的工作将探索先进的检测方法，重点关注数据分析和算法。我们的目标是测试广泛使用的LLM代理框架，并识别独特的AI驱动攻击模式。

### 6.3 扩展蜜罐

为了吸引更多的AI驱动代理，我们计划扩展蜜罐，监控更广泛的攻击面，如社交媒体、网站、数据库、电子邮件服务和工业控制系统。这将有助于捕捉到更广泛的威胁，包括垃圾邮件机器人、钓鱼代理和其他基于LLM的进攻性应用。此外，我们还可以将蜜罐与现有的安全解决方案（如SIEM系统）集成。

## 7 结论

在本文中，我们介绍了LLM代理蜜罐系统（[https://ai-honeypot.palisaderesearch.org/](https://ai-honeypot.palisaderesearch.org/)），该系统旨在检测和分析AI黑客代理。随着AI代理的日益复杂，我们的方法为新兴的网络安全威胁提供了见解，并提出了应对这些威胁的新策略。我们希望该项目能够鼓励进一步研究AI驱动的代理，这些代理有潜力显著改变网络安全格局。

## 参考文献

+   [1] Muris Sladić, Veronica Valeros, Carlos Catania, 和 Sebastian Garcia. Llm in the shell: 生成蜜罐。载于2024年IEEE欧洲安全与隐私研讨会（EuroS&PW），第220卷，第430-435页，IEEE，2024年7月。

+   [2] Adel Karimi. Galah: 一个基于LLM的Web蜜罐. [https://github.com/0x4D31/galah](https://github.com/0x4D31/galah)，2024年。GitHub仓库。

+   [3] Sergei Glazunov 和 Mark Brand. 项目午休：评估大型语言模型的进攻性安全能力. [https://googleprojectzero.blogspot.com/2024/06/project-naptime.html](https://googleprojectzero.blogspot.com/2024/06/project-naptime.html)，2024年6月。

+   [4] OpenAI. OpenAI O1系统卡. 技术报告，OpenAI，2024年9月。

+   [5] Edoardo Debenedetti, Jie Zhang, Mislav Balunovic, Luca Beurer-Kellner, Marc Fischer 和 Florian Tramèr. Agentdojo: 评估LLM代理攻击与防御的动态环境. arXiv预印本 arXiv:2406.13352，2024年。

+   [6] Michel Oosterhof. Cowrie SSH/Telnet蜜罐. [https://github.com/cowrie/cowrie](https://github.com/cowrie/cowrie)，2014年。GitHub仓库。

+   [7] Warren Z. Cabral, Craig Valli, Leslie F. Sikos 和 Samuel G. Wakeling. 高级Cowrie配置以提高蜜罐欺骗性. IFIP信息与通信技术进展, 2022年. 第36届IFIP国际ICT系统安全与隐私保护会议（SEC），挪威奥斯陆，2021年6月。

+   [8] 谷歌安全博客. AI驱动的模糊测试：打破漏洞狩猎的障碍，2023年。

## 附录A 提示注入示例

![参见说明](img/cf9b27f238d104c30fe4246786bd2420.png)

图7：带有提示注入的横幅消息

![参见说明](img/7f01ab977bb249374063929b5ffbc6f6.png)

图8：带有提示注入的系统命令

![参见说明](img/d6ebc5857440e18ff3b501a1d37b2891.png)

图9：带有提示注入的任意命令
