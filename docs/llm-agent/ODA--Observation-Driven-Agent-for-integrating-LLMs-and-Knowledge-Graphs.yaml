- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:48:31'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:48:31
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'ODA: Observation-Driven Agent for integrating LLMs and Knowledge Graphs'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'ODA: 观察驱动代理，用于整合大语言模型（LLMs）和知识图谱'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2404.07677](https://ar5iv.labs.arxiv.org/html/2404.07677)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2404.07677](https://ar5iv.labs.arxiv.org/html/2404.07677)
- en: Lei Sun¹¹1Equal contribution²²2Corresponding author¹ Zhengwei Tao¹¹1Equal contribution
    ² Youdi Li ¹ Hiroshi Arakawa ¹
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**Lei Sun**¹¹1平等贡献²²2通讯作者¹ **Zhengwei Tao**¹¹1平等贡献 ² **Youdi Li** ¹ **Hiroshi
    Arakawa** ¹'
- en: ¹Panasonic Connect Co., Ltd., Japan
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ¹Panasonic Connect Co., Ltd., Japan
- en: ²Peking University
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ²北京大学
- en: tttzw@stu.pku.edu.cn
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: tttzw@stu.pku.edu.cn
- en: '{lei.sun, ri.yutei, arakawa.hrs}@jp.panasonic.com'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '{lei.sun, ri.yutei, arakawa.hrs}@jp.panasonic.com'
- en: Abstract
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: The integration of Large Language Models (LLMs) and knowledge graphs (KGs) has
    achieved remarkable success in various natural language processing tasks. However,
    existing methodologies that integrate LLMs and KGs often navigate the task-solving
    process solely based on the LLM’s analysis of the question, overlooking the rich
    cognitive potential inherent in the vast knowledge encapsulated in KGs. To address
    this, we introduce Observation-Driven Agent (ODA), a novel AI agent framework
    tailored for tasks involving KGs. ODA incorporates KG reasoning abilities via
    global observation that enhances reasoning capabilities through a cyclical paradigm
    of observation, action, and reflection. Confronting the exponential explosion
    of knowledge during observation, we innovatively design a recursive observation
    mechanism. Subsequently, we integrate the observed knowledge into the action and
    reflection modules. Through extensive experiments, ODA demonstrates state-of-the-art
    performance on several datasets, notably achieving accuracy improvements of 12.87%
    and 8.9%. Our code and data are available on [ODA](https://github.com/lanjiuqing64/KGdata).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 大语言模型（LLMs）和知识图谱（KGs）的整合在各种自然语言处理任务中取得了显著成功。然而，现有的将LLMs和KGs整合的方法通常仅基于LLM对问题的分析来导航任务解决过程，忽视了KG中蕴含的丰富认知潜力。为了解决这一问题，我们引入了观察驱动代理（ODA），这是一个专门为涉及KG的任务量身定制的新型AI代理框架。ODA通过全球观察融合KG推理能力，通过观察、行动和反思的循环范式增强推理能力。面对观察过程中的知识指数爆炸，我们创新性地设计了递归观察机制。随后，我们将观察到的知识整合到行动和反思模块中。通过大量实验，ODA在多个数据集上展示了最先进的性能，特别是在准确率上分别提高了12.87%和8.9%。我们的代码和数据可以在[ODA](https://github.com/lanjiuqing64/KGdata)上获取。
- en: 'ODA: Observation-Driven Agent for integrating LLMs and Knowledge Graphs'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 'ODA: 观察驱动代理，用于整合大语言模型（LLMs）和知识图谱'
- en: Lei Sun¹¹1Equal contribution²²2Corresponding author¹ Zhengwei Tao¹¹1Equal contribution
    ² Youdi Li ¹ Hiroshi Arakawa ¹ ¹Panasonic Connect Co., Ltd., Japan ²Peking University
    tttzw@stu.pku.edu.cn {lei.sun, ri.yutei, arakawa.hrs}@jp.panasonic.com
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**Lei Sun**¹¹1平等贡献²²2通讯作者¹ **Zhengwei Tao**¹¹1平等贡献 ² **Youdi Li** ¹ **Hiroshi
    Arakawa** ¹ ¹Panasonic Connect Co., Ltd., Japan ²北京大学 tttzw@stu.pku.edu.cn {lei.sun,
    ri.yutei, arakawa.hrs}@jp.panasonic.com'
- en: 1 Introduction
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Large language models (LLMs) Touvron et al. ([2023](#bib.bib22)); Scao et al.
    ([2022](#bib.bib18)); Muennighoff et al. ([2022](#bib.bib11)); Brown et al. ([2020](#bib.bib2))
    have exhibited extraordinary capabilities across a variety of natural language
    processing tasks. Despite their impressive accomplishments, LLMs often struggle
    to provide accurate responses to queries that necessitate specialized expertise
    beyond their pre-training content. In response to this limitation, a natural and
    promising approach involves the integration of external knowledge sources, such
    as knowledge graphs (KGs), to augment LLM reasoning abilities. KGs provide structured,
    explicit, and explainable knowledge representations, offering a synergistic method
    to overcome the intrinsic constraints of LLMs. The fusion of LLMs with KGs has
    garnered significant interest in recent research Pan et al. ([2024](#bib.bib14)),
    underlying a vast array of applications Zhang et al. ([2023](#bib.bib29)); Do
    et al. ([2024](#bib.bib4)); Sun et al. ([2023b](#bib.bib20)).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 大语言模型（LLMs）**Touvron et al.** ([2023](#bib.bib22)); **Scao et al.** ([2022](#bib.bib18));
    **Muennighoff et al.** ([2022](#bib.bib11)); **Brown et al.** ([2020](#bib.bib2))
    展示了在各种自然语言处理任务中的卓越能力。尽管取得了令人印象深刻的成就，LLMs常常难以对需要超出其预训练内容的专业知识的问题提供准确的回答。针对这一限制，一种自然且有前景的方法是整合外部知识来源，如知识图谱（KGs），以增强LLM的推理能力。KGs提供结构化、明确且可解释的知识表示，提供了一种协同的方法来克服LLMs的固有局限。LLMs与KGs的融合在近期研究中引起了广泛关注**Pan
    et al.** ([2024](#bib.bib14))，并支持了大量应用**Zhang et al.** ([2023](#bib.bib29)); **Do
    et al.** ([2024](#bib.bib4)); **Sun et al.** ([2023b](#bib.bib20))。
- en: '![Refer to caption](img/6414bb47c9995d34f21fcea33dfa3f46.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/6414bb47c9995d34f21fcea33dfa3f46.png)'
- en: 'Figure 1: An example of LLM integrating with KG. Observed entities are shown
    in white, while non-observed entities are displayed in gray. Entities selected
    by the agent to answer the question are highlighted in yellow.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：LLM 与 KG 集成的示例。观察到的实体以白色显示，而未观察到的实体则以灰色显示。由代理选择以回答问题的实体以黄色突出显示。
- en: 'Existing methodologies for solving tasks that integrate KGs with LLMs can be
    categorized into two groups. The first one involves retrieving relevant triples
    from KGs in response to specific questions Wang et al. ([2023b](#bib.bib24));
    Luo et al. ([2024](#bib.bib10)); Jiang et al. ([2023](#bib.bib8)). The second
    part adopts an explore-exploit strategy, directing the knowledge utilization process
    within the graph according to the question Sun et al. ([2023b](#bib.bib20)); Guo
    et al. ([2023](#bib.bib7)). However, both categories navigate the task-solving
    process by merely relying on the LLM’s analysis of the question, overlooking the
    rich cognitive potential inherent in the abundant knowledge encapsulated in KGs.
    KGs, which store a wealth of informative and symbolic facts, should deeply participate
    in the reasoning process together with LLM rather than being merely treated as
    a static repository of knowledge Pan et al. ([2024](#bib.bib14)). As the example
    in the upper panel of Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ ODA: Observation-Driven
    Agent for integrating LLMs and Knowledge Graphs"), LLM analyzes the question and
    navigates towards Narrative location relation of entity The Call of The Wild.
    However, this entity has many neighboring entities with that relation, leading
    LLM to incorrectly infer Canada as the answer. In contrast, the bottom panel demonstrates
    how KG provides key patterns that reveal both The Call of The Wild and White Fang
    share the location Yukon. If LLM could observe this information beforehand, it
    would precisely guide its reasoning process towards the correct answer (as shown
    in the bottom panel). Therefore, LLM should adopt an overall observation to incorporate
    the extensive knowledge and intricate patterns embedded within the KG. Achieving
    this objective presents two primary challenges: firstly, a global observation
    of the KG can result in an exponential growth in the number of triples. As shown
    in the upper panel of Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ ODA: Observation-Driven
    Agent for integrating LLMs and Knowledge Graphs"), fully processing all 3-hop
    connections for The Call of the Wild is impractical. Secondly, the integration
    of such comprehensive observation into the existing reasoning paradigms of LLMs
    presents another challenge. How to combine the observation with the reasoning
    process of LLM matters for solving the tasks.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '现有的将知识图谱（KG）与大型语言模型（LLM）集成以解决任务的方法可以分为两类。第一类涉及从KG中检索相关的三元组以回应特定的问题 Wang et al.
    ([2023b](#bib.bib24)); Luo et al. ([2024](#bib.bib10)); Jiang et al. ([2023](#bib.bib8))。第二类采用探索-利用策略，根据问题引导知识在图谱中的使用过程 Sun
    et al. ([2023b](#bib.bib20)); Guo et al. ([2023](#bib.bib7))。然而，这两类方法都仅依赖于LLM对问题的分析来导航任务解决过程，忽视了KG中蕴含的丰富认知潜力。KG储存了大量有用和符号性的事实，应该与LLM一起深入参与推理过程，而不仅仅被视为静态的知识库 Pan
    et al. ([2024](#bib.bib14))。如图 [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ ODA: Observation-Driven
    Agent for integrating LLMs and Knowledge Graphs")上面的示例所示，LLM分析问题并导航到实体《荒野之呼唤》的地点关系。然而，该实体有许多具有该关系的邻近实体，导致LLM错误地推断加拿大为答案。相比之下，下面的面板展示了KG如何提供关键模式，揭示《荒野之呼唤》和《白牙》都共享地点尤肯。如果LLM能够事先观察到这些信息，它将准确地指导其推理过程朝向正确的答案（如下面板所示）。因此，LLM应采取整体观察的方法，将KG中嵌入的大量知识和复杂模式整合进来。实现这一目标面临两个主要挑战：首先，对KG的全局观察可能导致三元组数量的指数增长。如图 [1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ ODA: Observation-Driven Agent for integrating LLMs
    and Knowledge Graphs")上面的面板所示，全面处理《荒野之呼唤》的所有三跳连接是不切实际的。其次，将如此全面的观察整合到现有的LLM推理范式中是另一个挑战。如何将观察与LLM的推理过程相结合对于解决任务至关重要。'
- en: 'Motivated by this, we introduce a novel framework, the Observation-Driven Agent
    (ODA), aimed at sufficiently and autonomously integrating the capabilities of
    both LLM and KG. ODA serves as an AI Agent specifically designed for KG-centric
    tasks. ODA engages in a cyclical paradigm of observation, action, and reflection.
    Within ODA, we design a novel observation module to efficiently draw autonomous
    reasoning patterns of KG. Our observation module avoids the problem of exponential
    growth of triples via recursive progress. This approach ensures ODA integrating
    abilities of KG and LLM while mitigating the challenges associated with excessive
    data in KG, improving the efficiency and accuracy. Following the observation phase,
    ODA takes action by autonomously amalgamating insights derived from LLM inferences
    with the observed KG patterns. ODA can perform actions of three distinct types:
    Neighbor Exploration, Path Discovery, and Answering. Subsequently, ODA reflects
    on its internal state, considering both the outcomes of its actions and the prior
    observations. This iterative process continues until ODA accomplishes the task
    at hand.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 受到此启发，我们引入了一种新颖的框架——观察驱动代理（ODA），旨在充分且自主地整合LLM和KG的能力。ODA作为一个专门设计用于KG相关任务的AI代理，参与一个观察、行动和反思的循环模式。在ODA中，我们设计了一个新颖的观察模块，以高效地提取KG的自主推理模式。我们的观察模块通过递归进展避免了三元组的指数增长问题。这种方法确保ODA整合KG和LLM的能力，同时减轻了KG中过多数据带来的挑战，提高了效率和准确性。在观察阶段之后，ODA通过自主整合从LLM推理中得出的见解与观察到的KG模式来采取行动。ODA可以执行三种不同类型的操作：邻居探索、路径发现和回答。随后，ODA对其内部状态进行反思，考虑其行动的结果和之前的观察。这一迭代过程将持续进行，直到ODA完成任务为止。
- en: 'We conduct extensive experiments to testify to the effectiveness of ODA on
    four datasets: QALD10-en, T-REx, Zero-Shot RE and Creak. Notably, our approach
    achieved state-of-the-art (SOTA) performance compared to competitive baselines.
    Specifically, on QALD10-en and T-REx datasets, we observed remarkable accuracy
    improvements of 12.87% and 8.9%, respectively. We conclude the contributions as
    follows:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了广泛的实验，以验证ODA在四个数据集上的有效性：QALD10-en、T-REx、Zero-Shot RE和Creak。值得注意的是，与竞争基线相比，我们的方法达到了最先进的（SOTA）性能。具体而言，在QALD10-en和T-REx数据集中，我们观察到准确性分别提高了12.87%和8.9%。我们总结了以下贡献：
- en: $\bullet$
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: We propose ODA, an AI Agent tailored for KG-centric tasks. ODA conducts observation
    to incorporate the reasoning ability of KG.
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了ODA，一个针对KG相关任务量身定制的AI代理。ODA进行观察以融入KG的推理能力。
- en: $\bullet$
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: We further design action and reflection modules that integrate the observation
    into LLM reasoning. This strategy leverages the synergy between the autonomous
    reasoning of KG and LLM.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们进一步设计了将观察整合到LLM推理中的行动和反思模块。这一策略利用了KG的自主推理与LLM之间的协同效应。
- en: $\bullet$
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: We conduct experiments on four datasets and achieve SOTA performances.
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们在四个数据集上进行实验，并取得了SOTA表现。
- en: '![Refer to caption](img/1de2640486dbda690f9dc685ad6d7406.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/1de2640486dbda690f9dc685ad6d7406.png)'
- en: 'Figure 2: The overall framework of ODA.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：ODA的整体框架。
- en: 2 Methods
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 方法
- en: 'In this work, we aim to solve tasks associated with KG. Let $q$ can be expressed
    as:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们旨在解决与KG相关的任务。令$q$可以表示为：
- en: '|  | $T:(q,E),G\rightarrow Y$ |  |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '|  | $T:(q,E),G\rightarrow Y$ |  |'
- en: '![Refer to caption](img/eb459b20c486f113520bb872d5b93cb5.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/eb459b20c486f113520bb872d5b93cb5.png)'
- en: 'Figure 3: An example workflow of ODA. In this case, ODA initiates the obervation
    with entity Johann Wolfgang von Goethe. During the first iteration on the left
    side, the Neighbor Exploration of Johann Wolfgang von Goethe is selected, and
    the reflected triple (Johann Wolfgang von Goethe, unmarried Partner, Lili Schöneman)
    is stored in memory. Subsequently, The observation of Lili Schöneman then guides
    ODA to choose Neighbor Exploration action, and leads to the retention of the triple
    (Lili Schöneman, place of birth, Offenbach am Main) in memory, as shown on the
    right side. Once sufficient knowledge has been accumulated, ODA triggers the Answer
    action, correctly identifying Offenbach am Main as the answer.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：ODA的一个示例工作流程。在这种情况下，ODA以实体Johann Wolfgang von Goethe开始观察。在左侧的第一次迭代中，选择了Johann
    Wolfgang von Goethe的邻居探索，并将反映的三元组（Johann Wolfgang von Goethe, unmarried Partner,
    Lili Schöneman）存储在内存中。随后，Lili Schöneman的观察引导ODA选择邻居探索动作，并导致三元组（Lili Schöneman,
    place of birth, Offenbach am Main）在内存中的保留，如右侧所示。一旦积累了足够的知识，ODA触发回答动作，正确地识别出Offenbach
    am Main作为答案。
- en: 'Employing an iterative approach, ODA tackles the challenges inherent in KG-centric
    tasks. In contrast to existing methods that couple LLMs and KGs and rely solely
    on analyzing the LLM’s query, ODA autonomously integrates observed knowledge from
    the KG into the entire reasoning process, resulting in more informed decisions.
    To achieve this objective, our ODA system, illustrated in Figure [2](#S1.F2 "Figure
    2 ‣ 1 Introduction ‣ ODA: Observation-Driven Agent for integrating LLMs and Knowledge
    Graphs"), primarily comprises three key modules for task resolution:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '通过迭代的方法，ODA 处理了 KG 相关任务中固有的挑战。与现有方法依赖于分析 LLM 的查询并将 LLM 与 KG 结合的方式不同，ODA 自主地将从
    KG 中观察到的知识整合到整个推理过程中，从而做出更为明智的决策。为实现这一目标，我们的 ODA 系统，如图 [2](#S1.F2 "Figure 2 ‣
    1 Introduction ‣ ODA: Observation-Driven Agent for integrating LLMs and Knowledge
    Graphs") 所示，主要包括三个关键模块用于任务解决：'
- en: •
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Observation: This module efficiently observes and processes relevant knowledge
    from the KG environment. In each iteration $i$). By leveraging insights and patterns
    gleaned from the KG, this subgraph is autonomously incorporated into a reasoning
    LLM. This synergistic integration equips ODA with enhanced capabilities from both
    the LLM and KG, allowing it to tackle tasks more effectively.'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 观察：该模块高效地观察和处理来自 KG 环境的相关知识。在每次迭代 $i$ 中，通过利用从 KG 中获取的见解和模式，此子图会被自主地融入到推理 LLM
    中。这种协同整合使 ODA 具备了 LLM 和 KG 的增强能力，使其能更有效地处理任务。
- en: •
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Action: Drawing upon both the observation subgraph $O_{i}$, strategically selects
    the most suitable action to execute on the KG, ensuring the accurate answering
    of the question.'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 行动：基于观察子图 $O_{i}$，策略性地选择最合适的动作来执行于 KG，确保问题的准确回答。
- en: •
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Reflection: Utilizing the observation subgraph $O_{i}$ for the next iteration,
    facilitating continuous reasoning.'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 反思：利用观察子图 $O_{i}$ 进行下一次迭代，促进持续推理。
- en: Through this iterative process, ODA dynamically updates its observation subgraph
    $O_{i}$. Each module is discussed in detail in the following sections.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这一迭代过程，ODA 动态更新其观察子图 $O_{i}$。每个模块将在以下部分详细讨论。
- en: 2.1 Observation
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 观察
- en: 'The observation module is specifically designed to inspect global KG knowledge
    and navigate the autonomous reasoning process with the KG environments. At each
    iteration $i$. This process can be formulated as:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 观察模块专门设计用于检查全局 KG 知识并在 KG 环境中导航自主推理过程。在每次迭代 $i$ 中。这个过程可以表示为：
- en: '|  | $O_{i}=\text{Observation}([E_{i},q])$ |  |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '|  | $O_{i}=\text{Observation}([E_{i},q])$ |  |'
- en: Initially, the task-relevant entities are populated with the entities embedded
    within the question $q$.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，任务相关的实体由嵌入在问题 $q$ 中的实体填充。
- en: 'For KG-centric tasks, the observation incurs the problem of an explosive number
    of nodes. To address the scalability challenge during observation subgraph updates,
    we propose a $D$ represents the maximum hop depth. Each turn has two steps: update
    and refine. The update step focuses on expanding the subgraph, while the refining
    step ensures its appropriate size without loss of important information.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 对于以 KG 为中心的任务，观察会导致节点数量爆炸的问题。为了应对观察子图更新期间的可扩展性挑战，我们提出了 $D$ 表示最大跳跃深度。每轮有两个步骤：更新和精炼。更新步骤专注于扩展子图，而精炼步骤则确保其适当的大小而不会丢失重要信息。
- en: 'For each entity $e\in E_{i}$ is reached. The specific details are described
    below:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个实体 $e\in E_{i}$ 的具体细节如下：
- en: Algorithm 1 Observation
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 1 观察
- en: 'Require: Question $q$'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 需要：问题 $q$
- en: Initialize task-relevant entities $E_{i}$     end whileend for
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化与任务相关的实体 $E_{i}$     end whileend for
- en: 'Update:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 更新：
- en: •
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: For each entity $e$ denotes the tail entity.
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于每个实体 $e$ 表示尾实体。
- en: •
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'The similarity score between the question and the combination of $r$, is computed
    by measuring the cosine similarity of their embeddings¹¹1We use the GPT text-embedding-ada-002
    model from OpenAI for encoding.:'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '通过计算问题与 $r$ 的组合之间的余弦相似度，来计算它们的相似度分数¹¹1我们使用 OpenAI 的 GPT text-embedding-ada-002
    模型进行编码。:'
- en: '|  | $\text{Cosine Similarity}(\mathbf{v}_{q},\mathbf{v}_{r+t})=\frac{\mathbf{v}_{q}\cdot\mathbf{v}_{r+t}}{\&#124;\mathbf{v}_{q}\&#124;\&#124;\mathbf{v}_{r+t}\&#124;}$
    |  |'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\text{Cosine Similarity}(\mathbf{v}_{q},\mathbf{v}_{r+t})=\frac{\mathbf{v}_{q}\cdot\mathbf{v}_{r+t}}{\&#124;\mathbf{v}_{q}\&#124;\&#124;\mathbf{v}_{r+t}\&#124;}$
    |  |'
- en: •
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: All triples associated with entities in $E$ are collectively sorted in descending
    order based on their similarity scores.
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 所有与 $E$ 中的实体相关的三元组按照它们的相似度分数按降序排序。
- en: •
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The Top-$N$.
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Top-$N$。
- en: 'Refine:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 精炼：
- en: •
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The Top-$N$ with the highest similarity scores.
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 具有最高相似度分数的前 $N$ 个。
- en: •
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The tail entities from the refined top $P\%$ for the next iteration.
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下一轮迭代的前 $P\%$ 的尾实体。
- en: 2.2 Action
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 动作
- en: Harnessing the power of an LLM, the action module crafts strategic prompts to
    generate optimal actions. Based on its memory $M_{ List[Tuple[str, str, str]]: |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '|  | GetNeighbor(entityID: str) -> List[Tuple[str, str, str]]: |'
- en: '|  | Description: Returns triplets containing the given entityID as the head
    and its corresponding entityID as the tail. |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '|  | 描述：返回包含给定实体ID作为主体和对应实体ID作为宾语的三元组。 |'
- en: '|  | GetPath(entityID1: str, entityID2: str) -> List[List[Tuple[str, str, str]]]:
    |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '|  | GetPath(entityID1: str, entityID2: str) -> List[List[Tuple[str, str, str]]]:
    |'
- en: '|  | Description: Returns all triplets linking the two given entityIDs. |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '|  | 描述：返回所有连接两个给定实体ID的三元组。 |'
- en: '|  | Example Usage:GetPath("Q30", "Q25231") returns all triplets connecting
    ’Q30’ and ’Q25231’. |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '|  | 示例用法：GetPath("Q30", "Q25231") 返回所有连接 ’Q30’ 和 ’Q25231’ 的三元组。 |'
- en: '|  | Data Provided to You: |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '|  | 提供给你的数据： |'
- en: '|  | Question:[Question] |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '|  | 问题：[Question] |'
- en: '|  | Memory: [Memory] |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '|  | 记忆：[Memory] |'
- en: '|  | Candidate EntityIDs: [Task-relevant EntityIDs] (Choose 1 or 2 based on
    the action) |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '|  | 候选实体ID：[Task-relevant EntityIDs]（根据操作选择1或2） |'
- en: '|  | Observation: [Observation] (These serve as a reference to assist you in
    selecting the appropriate entityID from the Candidate EntityIDs) |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '|  | 观察：[Observation]（这些作为参考，帮助你从候选实体ID中选择合适的实体ID） |'
- en: '|  | Labels: [Task-relevant entities labels] |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '|  | 标签：[Task-relevant entities labels] |'
- en: '|  | Action History: [historical action] (Avoid these actions) |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '|  | 动作历史：[historical action]（避免这些动作） |'
- en: '|  | Guidelines: |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '|  | 指导方针： |'
- en: '|  | Choose only one action at a time. |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '|  | 一次只选择一个动作。 |'
- en: '|  | For GetPath, select two entityIDs. For GetNeighbor, select one entityID.
    If there are less than 2 entityIDs available, only choose the GetNeighbor action.
    |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '|  | 对于GetPath，选择两个entityID。对于GetNeighbor，选择一个entityID。如果可用的entityID少于2个，只选择GetNeighbor动作。
    |'
- en: '| Answer | You are a agent that answer questions based on the reference memory
    and your knowledge. |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| 答案 | 你是一个基于参考记忆和你的知识回答问题的代理。 |'
- en: '|  | Here are the reference memory:[Memory]. You can use it to help you answer
    the quesiton. |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '|  | 这里是参考记忆：[Memory]。你可以使用它来帮助你回答问题。 |'
- en: '|  | Here is the question you are asked to answer the question:[Question].
    |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '|  | 这是你被要求回答的问题：[Question]。 |'
- en: '|  | Ensure that your answer contains one answer or a list of answer, and each
    answer should be only one or several words,a phrase, a number,true or false, or
    a date, no other information or descripation in answer. |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '|  | 确保你的答案包含一个答案或一个答案列表，每个答案应仅为一个或几个词、一个短语、一个数字、**真**或**假**，或一个日期，答案中不得包含其他信息或描述。
    |'
- en: 'Table 7: Action Prompt Description'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 表7：动作提示描述
- en: '| Field | Prompt |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| 领域 | 提示 |'
- en: '| --- | --- |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Reflection | You are an agent that provides answers based on a KG. |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| 反思 | 你是一个基于知识图谱（KG）提供答案的代理。 |'
- en: '|  | You queried some candidate triples [triples] from last action step and
    their corresponding labels:[entities labels] from the KB based on the question:
    [Question]. |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '|  | 你根据问题：[Question]，从上一个动作步骤中查询了一些候选三元组[triples]及其对应的标签：[entities labels]。
    |'
- en: '|  | Now you are asked to select related triples, so you can answer the question
    in the future by using them. |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '|  | 现在你被要求选择相关的三元组，以便你将来可以使用它们来回答问题。 |'
- en: '|  | Here are the observation: [Obervation] for guiding you to select the right
    triples from the candidate triples. |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '|  | 这里是观察结果：[Observation]，用于指导你从候选三元组中选择正确的三元组。 |'
- en: '|  | Also, here is the memory: [Memory]. You can use it to help you select
    the right triples from the candidate triples. |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '|  | 另外，这里是记忆：[Memory]。你可以使用它来帮助你从候选三元组中选择正确的三元组。 |'
- en: '|  | Guidelines: |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '|  | 指导方针： |'
- en: '|  | You can select less than 15 triples from the candidate triples. |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '|  | 你可以从候选三元组中选择少于15个三元组。 |'
- en: '|  | Your output triples must be in the format of entityID,relationID,entityID.
    |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '|  | 你的输出三元组必须采用entityID,relationID,entityID的格式。 |'
- en: 'Table 8: Reflection Prompt Description'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 表8：反思提示描述 |
