- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 18:52:34'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:52:34
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered
    Applications'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迈向更好的人与智能体对齐：评估 LLM 驱动应用中的任务效用
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2402.09015](https://ar5iv.labs.arxiv.org/html/2402.09015)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2402.09015](https://ar5iv.labs.arxiv.org/html/2402.09015)
- en: Negar Arabzadeh¹  Julia Kiseleva²  Qingyun Wu³  Chi Wang²
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Negar Arabzadeh¹  Julia Kiseleva²  Qingyun Wu³  Chi Wang²
- en: Ahmed Awadallah²  Victor Dibia²  Adam Fourney²  Charles Clarke¹
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Ahmed Awadallah²  Victor Dibia²  Adam Fourney²  Charles Clarke¹
- en: ¹Univerity of Waterloo
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ¹滑铁卢大学
- en: ²Microsoft Research
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ²微软研究院
- en: ³Pennsylvania State University __Work done during an internship at Microsoft
    Research
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ³宾夕法尼亚州立大学 __在微软研究院实习期间完成的工作
- en: Abstract
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: The rapid development in the field of Large Language Models (LLMs) has led to
    a surge in applications that facilitate collaboration among multiple agents to
    assist humans in their daily tasks. However, a significant gap remains in assessing
    whether LLM-powered applications genuinely enhance user experience and task execution
    efficiency. This highlights the pressing need for methods to verify utility of
    LLM-powered applications, particularly by ensuring alignment between the application’s
    functionality and end-user needs. We introduce AgentEval¹¹1[https://github.com/microsoft/autogen/blob/main/notebook/agenteval_cq_math.ipynb](https://github.com/microsoft/autogen/blob/main/notebook/agenteval_cq_math.ipynb)
    provides an implementation for the math problems, a novel framework designed to
    simplify the utility verification process by automatically proposing a set of
    criteria tailored to the unique purpose of any given application. This allows
    for a comprehensive assessment, quantifying the utility of an application against
    the suggested criteria. We present a comprehensive analysis of the robustness
    AgentEval for two open source datasets.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）领域的快速发展导致了促进多个智能体协作以帮助人类完成日常任务的应用激增。然而，仍然存在一个重要的差距，即评估 LLM 驱动的应用是否真正提升了用户体验和任务执行效率。这突显了验证
    LLM 驱动应用效用的迫切需求，特别是通过确保应用功能与最终用户需求的一致性。我们介绍了 AgentEval¹¹1[https://github.com/microsoft/autogen/blob/main/notebook/agenteval_cq_math.ipynb](https://github.com/microsoft/autogen/blob/main/notebook/agenteval_cq_math.ipynb)，它为数学问题提供了实现，是一个旨在简化效用验证过程的创新框架，通过自动提出一组符合任何特定应用唯一目的的标准。这样可以对应用程序进行全面评估，量化其相对于建议标准的效用。我们对
    AgentEval 在两个开源数据集上的稳健性进行了全面分析。
- en: 1 Introduction
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: The rapid development of open-source libraries Wu et al. ([2023](#bib.bib47));
    Li et al. ([2023a](#bib.bib23)) that aims to simplify the development of LLM-powered
    agentic solutions for various user-enteric tasks has led to the rapid growth of
    such applications Liang et al. ([2023b](#bib.bib28)); Hong et al. ([2023](#bib.bib14));
    Talebirad and Nadiri ([2023](#bib.bib39)). One of the long-lasting goals Winograd
    ([1972](#bib.bib46)) is the ability to seamlessly interact with humans in natural
    language to help end-users and to make their lives easier by assisting with their
    tasks from math tutoring to completing household tasks and so on. End users have
    expectations and requirements for a developed application that need to be met.
    This understanding is essential to assess the *utility* it brings and, consequently,
    to further improve and align the application towards end-users’ goals.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 开源库的快速发展 Wu et al. ([2023](#bib.bib47)); Li et al. ([2023a](#bib.bib23))，旨在简化
    LLM 驱动的智能体解决方案在各种用户任务中的开发，导致了此类应用的快速增长 Liang et al. ([2023b](#bib.bib28)); Hong
    et al. ([2023](#bib.bib14)); Talebirad and Nadiri ([2023](#bib.bib39))。一个持久的目标 Winograd
    ([1972](#bib.bib46)) 是能够与人类在自然语言中无缝互动，以帮助最终用户，并通过从数学辅导到完成家庭任务等任务来使他们的生活更轻松。最终用户对开发的应用程序有期望和要求，这些需求需要得到满足。这种理解对于评估它带来的*效用*至关重要，因此有助于进一步改进并将应用程序与最终用户的目标对齐。
- en: Directly evaluating agentic systems poses challenges as current approaches predominantly
    rely on end-to-end success metrics – essentially, whether the agent accomplishes
    tasks Shridhar et al. ([2020b](#bib.bib38), [2019](#bib.bib36)); Myers et al.
    ([2023](#bib.bib33)). However, comprehending user interaction with an application
    involves much more than success alone Kiseleva et al. ([2022a](#bib.bib19), [b](#bib.bib20));
    Zhang et al. ([2023](#bib.bib49)). Take math problems, for instance; it is not
    merely about the agent solving the problem. Equally significant is its ability
    to present solutions based on various criteria, including completeness, conciseness,
    and clarity of the explanation provided. In other words, in a code completion
    scenario, even an incomplete code suggestion can be useful when it provides substantial
    boilerplate code or proposes a framework to solve a task Dibia et al. ([2023](#bib.bib9)).
    Furthermore, success is not always clearly defined for every task. Knowing such
    criteria for an LLM-powered application and being able to quantify them is essential
    to verify whether user requirements are being satisfied, in other words, if the
    application brings utility to the end-users. Given the objective of verifying
    arbitrary applications, reliance on a benchmarking approach is untenable due to
    the expansive range of tasks requiring automation. A prerequisite is a scalable
    and flexible methodology capable of accommodating a diverse set of applications.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 直接评估自主系统存在挑战，因为当前的方法主要依赖于端到端的成功指标——即代理是否完成任务 Shridhar et al. ([2020b](#bib.bib38),
    [2019](#bib.bib36)); Myers et al. ([2023](#bib.bib33))。然而，理解用户与应用程序的互动不仅仅涉及成功本身 Kiseleva
    et al. ([2022a](#bib.bib19), [b](#bib.bib20)); Zhang et al. ([2023](#bib.bib49))。以数学问题为例，这不仅仅是代理解决问题。其能够基于各种标准提供解决方案，包括完整性、简洁性和解释的清晰度也同样重要。换句话说，在代码补全的场景中，即使是不完整的代码建议也可能有用，只要它提供了实质性的模板代码或提出了解决任务的框架 Dibia
    et al. ([2023](#bib.bib9))。此外，对于每个任务，成功并不总是明确定义的。了解这些标准并能够量化它们对于验证用户需求是否得到满足至关重要，即应用程序是否对最终用户有用。鉴于验证任意应用程序的目标，依赖基准测试方法是不切实际的，因为需要自动化的任务范围广泛。一个前提是需要一个可扩展和灵活的方法，能够适应多种应用。
- en: '![Refer to caption](img/b2a36eab2e1087b1d769cdcc5d576632.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/b2a36eab2e1087b1d769cdcc5d576632.png)'
- en: 'Figure 1: An overview of the *AgentEval* framework consists of two main components:
    (C) *CriticAgent*, which learns a list of $n$)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：*AgentEval* 框架概述包括两个主要组件：(C) *CriticAgent*，它学习一个 $n$)
- en: 'In this work, we aim to introduce the AgentEval framework, a tool crafted to
    swiftly gauge the utility of LLM-powered agentic applications designed to help
    end-users accomplish their desired tasks. The goal of AgentEval is to assess the
    current alignment between application behavior and user goals, providing application
    developers with insights into how and what aspects of the current flow can be
    improved. AgentEval takes into account recent discoveries that have shown LLMs
    to emerge as a scalable and cost-effective alternative to human evaluations for
    open-ended tasks Li et al. ([2023b](#bib.bib24)). The *AgentEval* is illustrated
    in Fig. [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Towards better Human-Agent Alignment:
    Assessing Task Utility in LLM-Powered Applications"), which consists of two main
    agents executed consecutively. These agents are customizable, conversable, and
    can operate in various modes that employ combinations of LLMs, human inputs, and
    tools Wu et al. ([2023](#bib.bib47))²²2[https://github.com/microsoft/autogen](https://github.com/microsoft/autogen):'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '在这项工作中，我们旨在介绍 AgentEval 框架，这是一个快速评估 LLM 驱动的自主应用程序对最终用户完成所需任务的工具。AgentEval 的目标是评估应用程序行为与用户目标之间的当前一致性，为应用程序开发人员提供有关当前流程可以如何以及哪些方面可以改进的见解。AgentEval
    考虑了最近的发现，这些发现表明 LLM 作为一种可扩展和具有成本效益的替代方案，可以替代人工评估开放性任务 Li et al. ([2023b](#bib.bib24))。*AgentEval*
    在图 [1](#S1.F1 "图 1 ‣ 1 引言 ‣ 朝着更好的 人类-代理 对齐: 评估 LLM 驱动应用程序的任务效用") 中进行了说明，其中包含两个主要代理顺序执行。这些代理是可定制的、可对话的，并且可以以各种模式操作，这些模式结合了
    LLM、人类输入和工具 Wu et al. ([2023](#bib.bib47))²²2[https://github.com/microsoft/autogen](https://github.com/microsoft/autogen)'
- en: •
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*CriticAgent* suggests the list of criteria based on the task description and
    the suggested solutions, e.g. for math problems can be *Efficiency* of the proposed
    solution and *Clarity* of the proposed solution;'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*CriticAgent* 根据任务描述和建议的解决方案建议标准列表，例如，对于数学问题，可以是建议解决方案的*效率*和建议解决方案的*清晰度*；'
- en: •
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*QuantifierAgent* verifies how well the solution $s$ are performing for each
    criterion and returns the utility function, e.g. what is the Clarity level of
    the solution, not clear, moderately clear or very clear.'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*QuantifierAgent* 验证解决方案 $s$ 在每个标准下的表现如何，并返回效用函数，例如，解决方案的清晰度水平是模糊的、中等清晰的还是非常清晰的。'
- en: We believe that the usage of *AgentEval* can extend beyond the immediate verification
    of the current performance of LLM-powered applications. The framework can be employed
    over time to uncover new capabilities of the system and potential changes in task
    utility for the end user. The discovered utility function can be utilized to optimize
    the system towards user needs or system developer requirements, and this optimization
    can occur over time.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们相信 *AgentEval* 的使用可以超越对基于LLM的应用程序当前性能的即时验证。该框架可以随着时间的推移被用来发现系统的新能力以及任务效用的潜在变化。发现的效用函数可以用于优化系统以满足用户需求或系统开发者要求，这种优化可以随着时间的推移进行。
- en: 'In summary, our main contributions are:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们的主要贡献包括：
- en: C1
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: C1
- en: A definition of task utility that enables access to the possible requirements
    an end-user may have regarding an LLM-powered application and how well the application
    satisfies this list of criteria;
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一个任务效用的定义，它允许访问最终用户可能对基于LLM的应用程序的要求以及该应用程序满足这些标准的程度；
- en: C2
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: C2
- en: 'An introduction of *AgentEval*, a novel framework that leverages LLM-powered
    agents as a scalable and cost-effective alternative to human evaluations to produce
    task utility through the collaboration of two agents: *CriticAgent* proposes a
    list of criteria based on the task description and the successful and failed execution
    of the agent, and *QuantifierAgent* assesses how well the list of criteria is
    supported by the current implementation of an application;'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 介绍了 *AgentEval*，这是一个新颖的框架，利用基于LLM的代理作为一种可扩展且具有成本效益的替代方案，用于通过两个代理的协作产生任务效用：*CriticAgent*
    根据任务描述以及代理的成功和失败执行提出一系列标准，*QuantifierAgent* 评估当前应用程序实现对这些标准的支持程度；
- en: C3
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: C3
- en: An in-depth analysis of the *AgentEval* robustness on various tasks and datasets
    across different solutions that can be replicated for a newly unseen domain.
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对 *AgentEval* 在各种任务和数据集上的鲁棒性进行深入分析，这些任务和数据集涉及不同的解决方案，并且可以被复制到新的未见领域。
- en: 'The remainder of this paper is organized as follows. Section [2](#S2 "2 Related
    Work ‣ Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered
    Applications") describes earlier work and background. We provide the motivation
    behind AgentEval and define the utility of the task in Section [3](#S3 "3 Defining
    Task Utility ‣ Towards better Human-Agent Alignment: Assessing Task Utility in
    LLM-Powered Applications"). Section [4](#S4 "4 Datasets and Solutions ‣ Towards
    better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications")
    gives an overview of the datasets, namely MATH Hendrycks et al. ([2021b](#bib.bib13))
    and ALFWorld Shridhar et al. ([2020b](#bib.bib38)), and the solutions for building
    applications powered by LLM utilized in our work. Section [5](#S5 "5 AgentEval
    Workflow ‣ Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered
    Applications") demonstrates our findings about applying AgentEval to assess the
    utility of the task for the selected datasets. Section [6](#S6 "6 AgentEval Robustness
    Analysis and In-depth Discussion ‣ Towards better Human-Agent Alignment: Assessing
    Task Utility in LLM-Powered Applications") presents an in-depth analysis of the
    robustness of AgentEval, namely *CriticAgent* robustness (Section [6.1](#S6.SS1
    "6.1 Task-based vs Solution-based criteria ‣ 6 AgentEval Robustness Analysis and
    In-depth Discussion ‣ Towards better Human-Agent Alignment: Assessing Task Utility
    in LLM-Powered Applications")), *QuantifierAgent* robustness (Section [6.2](#S6.SS2
    "6.2 Quantifier Agent Robustness ‣ 6 AgentEval Robustness Analysis and In-depth
    Discussion ‣ Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered
    Applications")) and an automatic verification of *QuantifierAgent* (Section [6.3](#S6.SS3
    "6.3 QuantifierAgent Verification ‣ 6 AgentEval Robustness Analysis and In-depth
    Discussion ‣ Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered
    Applications")).'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '本文的其余部分组织如下。第[2](#S2 "2 Related Work ‣ Towards better Human-Agent Alignment:
    Assessing Task Utility in LLM-Powered Applications")节描述了早期的工作和背景。我们在第[3](#S3 "3
    Defining Task Utility ‣ Towards better Human-Agent Alignment: Assessing Task Utility
    in LLM-Powered Applications")节提供了AgentEval的动机，并定义了任务的实用性。第[4](#S4 "4 Datasets
    and Solutions ‣ Towards better Human-Agent Alignment: Assessing Task Utility in
    LLM-Powered Applications")节概述了数据集，即MATH Hendrycks et al. ([2021b](#bib.bib13))和ALFWorld
    Shridhar et al. ([2020b](#bib.bib38))，以及在我们的工作中用于构建LLM驱动应用的解决方案。第[5](#S5 "5 AgentEval
    Workflow ‣ Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered
    Applications")节展示了我们关于应用AgentEval评估所选数据集任务实用性的发现。第[6](#S6 "6 AgentEval Robustness
    Analysis and In-depth Discussion ‣ Towards better Human-Agent Alignment: Assessing
    Task Utility in LLM-Powered Applications")节呈现了AgentEval的鲁棒性深入分析，即*CriticAgent*鲁棒性（第[6.1](#S6.SS1
    "6.1 Task-based vs Solution-based criteria ‣ 6 AgentEval Robustness Analysis and
    In-depth Discussion ‣ Towards better Human-Agent Alignment: Assessing Task Utility
    in LLM-Powered Applications")节）、*QuantifierAgent*鲁棒性（第[6.2](#S6.SS2 "6.2 Quantifier
    Agent Robustness ‣ 6 AgentEval Robustness Analysis and In-depth Discussion ‣ Towards
    better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications")节）以及*QuantifierAgent*的自动验证（第[6.3](#S6.SS3
    "6.3 QuantifierAgent Verification ‣ 6 AgentEval Robustness Analysis and In-depth
    Discussion ‣ Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered
    Applications")节）。'
- en: 2 Related Work
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: 'We build on the streams of prior work. First, we will discuss the list of benchmarks
    and approaches to evaluate general LLMs in general (Section [2.1](#S2.SS1 "2.1
    LLM evaluation ‣ 2 Related Work ‣ Towards better Human-Agent Alignment: Assessing
    Task Utility in LLM-Powered Applications")). Second, we will present approaches
    to understand and predict user utility functions (Section [2.2](#S2.SS2 "2.2 User
    satisfaction prediction ‣ 2 Related Work ‣ Towards better Human-Agent Alignment:
    Assessing Task Utility in LLM-Powered Applications")). Third, we will go over
    the current tendencies in using LLMs as evaluators in Section [2.3](#S2.SS3 "2.3
    Using LLMs as evaluators ‣ 2 Related Work ‣ Towards better Human-Agent Alignment:
    Assessing Task Utility in LLM-Powered Applications").'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '我们基于前期工作的成果。首先，我们将讨论评估一般LLM的基准和方法列表（第[2.1](#S2.SS1 "2.1 LLM evaluation ‣ 2
    Related Work ‣ Towards better Human-Agent Alignment: Assessing Task Utility in
    LLM-Powered Applications")节）。其次，我们将介绍理解和预测用户实用函数的方法（第[2.2](#S2.SS2 "2.2 User satisfaction
    prediction ‣ 2 Related Work ‣ Towards better Human-Agent Alignment: Assessing
    Task Utility in LLM-Powered Applications")节）。第三，我们将回顾当前将LLM作为评估者的趋势（第[2.3](#S2.SS3
    "2.3 Using LLMs as evaluators ‣ 2 Related Work ‣ Towards better Human-Agent Alignment:
    Assessing Task Utility in LLM-Powered Applications")节）。'
- en: 2.1 LLM evaluation
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 LLM 评估
- en: There exists a significant volume of literature dedicated to assessing Language
    Model Models (LLMs), as evidenced by extensive research efforts Guo et al. ([2023](#bib.bib11));
    Ziyu et al. ([2023](#bib.bib50)); Chang et al. ([2023](#bib.bib6)); Liang et al.
    ([2023a](#bib.bib27)). LLMs have been evaluated from various aspects including,
    but not limited to, specialized LLMs Jin et al. ([2019](#bib.bib16)), ethics and
    morality Hendrycks et al. ([2021a](#bib.bib12)), safety and robustness Wang et al.
    ([2023](#bib.bib42)), and knowledge and reasoning Bian et al. ([2023](#bib.bib5)).
    Additionally, recent developments include the introduction of intricate multi-modal
    benchmark datasets Mialon et al. ([2023](#bib.bib32)); Bang et al. ([2023](#bib.bib3)).
    Furthermore, there are attempts to evaluate LLMs as agents Liu et al. ([2023](#bib.bib30)).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 关于评估语言模型（LLMs）的文献量相当庞大，这从大量研究工作中可以看出 Guo et al. ([2023](#bib.bib11)); Ziyu et al.
    ([2023](#bib.bib50)); Chang et al. ([2023](#bib.bib6)); Liang et al. ([2023a](#bib.bib27))。LLMs
    从多个方面进行了评估，包括但不限于，专门的LLMs Jin et al. ([2019](#bib.bib16))，伦理与道德 Hendrycks et al.
    ([2021a](#bib.bib12))，安全性与稳健性 Wang et al. ([2023](#bib.bib42))，以及知识与推理 Bian et al.
    ([2023](#bib.bib5))。此外，最近的进展包括引入复杂的多模态基准数据集 Mialon et al. ([2023](#bib.bib32));
    Bang et al. ([2023](#bib.bib3))。此外，还有尝试将LLMs作为代理进行评估 Liu et al. ([2023](#bib.bib30))。
- en: However, there is a lack of literature that focuses on the holistic verification
    of the utility of LLMs for end-users in solving their tasks, which we tackle in
    this work.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，针对大规模验证大语言模型（LLMs）在解决最终用户任务中的实用性的文献仍然不足，这正是我们在本工作中要解决的问题。
- en: 2.2 User satisfaction prediction
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 用户满意度预测
- en: Recent studies suggest that users interacting with various systems operate with
    specific utility functions in mind Li et al. ([2020](#bib.bib25)); Azzopardi et al.
    ([2018](#bib.bib2)); Ahmadvand et al. ([2022](#bib.bib1)). Traditionally, metrics
    defining user satisfaction was built based on various at scale collected behavioral
    signals Kiseleva et al. ([2014](#bib.bib17)) and they were tailored to specific
    applications, such as intelligent assistants Kiseleva et al. ([2016a](#bib.bib21),
    [b](#bib.bib22)), web search engines Williams et al. ([2016a](#bib.bib43), [b](#bib.bib44));
    Williams and Zitouni ([2017](#bib.bib45)), dialogue systems See et al. ([2019](#bib.bib35)),
    multi-turn conversations Li et al. ([2021](#bib.bib26)) and general-purpose personal
    assistants Kiseleva and de Rijke ([2017](#bib.bib18)).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究表明，用户在与各种系统互动时，会以特定的实用功能为目标 Li et al. ([2020](#bib.bib25)); Azzopardi et al.
    ([2018](#bib.bib2)); Ahmadvand et al. ([2022](#bib.bib1))。传统上，定义用户满意度的度量标准是基于各种规模收集的行为信号构建的 Kiseleva
    et al. ([2014](#bib.bib17))，这些度量标准针对特定应用进行定制，例如智能助手 Kiseleva et al. ([2016a](#bib.bib21),
    [b](#bib.bib22))，网页搜索引擎 Williams et al. ([2016a](#bib.bib43), [b](#bib.bib44));
    Williams and Zitouni ([2017](#bib.bib45))，对话系统 See et al. ([2019](#bib.bib35))，多轮对话 Li
    et al. ([2021](#bib.bib26)) 和通用个人助理 Kiseleva and de Rijke ([2017](#bib.bib18))。
- en: 2.3 Using LLMs as evaluators
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 使用LLMs作为评估者
- en: Moreover, there is a growing trend in utilizing LLMs as evaluates Chiang and
    Lee ([2023](#bib.bib7)); Fu et al. ([2023](#bib.bib10)) for qualitative research Bano
    et al. ([2023](#bib.bib4)) and adopting LLMs as proxies for human behavior Tjuatja
    et al. ([2023](#bib.bib40)); Liu and Sun ([2023](#bib.bib29)). Jain et al. ([2023](#bib.bib15))
    studied efficacy of in-context learning based evaluators in evaluating zero-shot
    summaries written by LLMs. Notably, CoEval Li et al. ([2023b](#bib.bib24)) has
    recently demonstrated the synergy between human evaluation and LLMs in establishing
    evaluation criteria and conducting multi-dimensional evaluations for openended
    NLG tasks.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，越来越多地利用LLMs作为评估者的趋势正在增长 Chiang and Lee ([2023](#bib.bib7)); Fu et al. ([2023](#bib.bib10))，用于定性研究 Bano
    et al. ([2023](#bib.bib4)) 和采用LLMs作为人类行为的代理 Tjuatja et al. ([2023](#bib.bib40));
    Liu and Sun ([2023](#bib.bib29))。Jain et al. ([2023](#bib.bib15)) 研究了基于上下文学习的评估器在评估LLMs撰写的零样本总结中的有效性。值得注意的是，CoEval Li
    et al. ([2023b](#bib.bib24)) 最近展示了人类评估与LLMs之间的协同效应，用于建立评估标准并进行多维度的开放式自然语言生成（NLG）任务评估。
- en: Building on top of these works, we propose a framework capable of assessing
    the utility of various LLM-powered applications at scale. This framework aims
    to align agentic systems with human preferences.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些工作的基础上，我们提出了一个能够大规模评估各种LLM驱动应用程序实用性的框架。该框架旨在使代理系统与人类偏好对齐。
- en: 3 Defining Task Utility
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 定义任务实用性
- en: '![Refer to caption](img/7da368aaae702bce8086abd474004d88.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/7da368aaae702bce8086abd474004d88.png)'
- en: 'Figure 2: The taxonomy of task assessments based on optimal solutions existence'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：基于最优解存在的任务评估分类法
- en: 'It is important to begin by considering the categories of tasks around which
    we focus LLM-powered applications. Fig. [1](#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered
    Applications") outlines a taxonomy of target tasks for agentic systems in terms
    of success metrics. At the top level, tasks can be split into two main categories,
    where:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是首先考虑围绕我们关注的LLM驱动应用程序的任务类别。图[1](#S1.F1 "图 1 ‣ 1 引言 ‣ 朝着更好的人与代理对齐：评估LLM驱动应用程序中的任务效用")概述了代理系统目标任务的分类法，基于成功指标。在顶层，任务可以分为两大类，其中：
- en: •
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*Success is not clearly defined* — For these tasks, users utilize a system
    in an assistive manner, seeking suggestions rather than expecting the system to
    solve the task end-to-end. For example, a user might request the system to generate
    an email based on some user input. In many cases, this generated content serves
    as a template that the user will later edit. However, defining success precisely
    for such tasks is less well-defined. In case of online evaluation, while being
    expensive, we can ask users to what extend the the assistance was helpful. Although
    quantifying to what extent the help was useful is still challenging on its own,
    the problem becomes increasingly challenging when it comes to offline evaluation,
    or evaluation in novel scenarios before we have users.'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*成功定义不明确* — 对于这些任务，用户以辅助的方式使用系统，寻求建议而不是期待系统端到端地解决任务。例如，用户可能请求系统根据某些输入生成电子邮件。在许多情况下，这些生成的内容作为模板，用户会在之后进行编辑。然而，对于此类任务，精确地定义成功的标准较为困难。在在线评估中，虽然成本高昂，我们可以询问用户这种辅助的帮助程度。虽然量化帮助的有效程度本身仍具挑战，但在离线评估或在没有用户的全新场景中，这个问题变得更加复杂。'
- en: •
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*Success is clearly defined* — For these tasks, we can clearly determine whether
    a system solved the task or not. Consider agents that assist in accomplishing
    household tasks, where the definition of success is clear and measurable.'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*成功定义明确* — 对于这些任务，我们可以清晰地确定一个系统是否解决了任务。考虑那些协助完成家庭任务的代理，其中成功的定义是明确且可衡量的。'
- en: 'This second category can be further divided into two subcategories:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 第二类任务可以进一步分为两个子类别：
- en: •
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*Success is clearly defined and an optimal solution exits* — For these tasks,
    only one solution is possible. For example, if you ask your assistant to turn
    on the light, the success of this task is clearly defined, and there is only one
    way to accomplish it.'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*成功明确且存在最优解* — 对于这些任务，只有一种解决方案。例如，如果你要求助理打开灯，那么这个任务的成功定义是明确的，只有一种方式可以完成它。'
- en: •
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*Success is clearly defined and multiple solutions exist* — increasingly, we
    observe situations where multiple trajectories of agent behavior can lead to either
    success or failure. In such cases, it is crucial to differentiate between the
    various successful and unsuccessful outcomes. For example, when you ask the agent
    to suggest a food recipe or tell you a joke, you may define success as the food
    tasting good or the joke being funny, but perhaps the recipe should not be too
    expensive to prepare, and the joke should not be offensive.'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*成功明确且存在多种解决方案* — 我们越来越多地观察到，代理行为的多种轨迹可能导致成功或失败。在这种情况下，区分各种成功和失败的结果是至关重要的。例如，当你要求代理建议一个食谱或讲一个笑话时，你可能将成功定义为食物美味或笑话有趣，但也许食谱不应过于昂贵，笑话不应令人反感。'
- en: In our AgentEval framework, we are currently focused on tasks where success
    is clearly defined and multiple successful solutions may exist.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的AgentEval框架中，我们目前专注于成功定义明确且可能存在多种成功解决方案的任务。
- en: 'Our previous research on assistive agents suggested that the most optimal way
    to obtain human judgments is to present humans with two agents side by side and
    ask for preferences Kiseleva et al. ([2022b](#bib.bib20)). In this setup of pairwise
    comparison, humans can develop a list criteria to explain why they prefer the
    behavior of one agent over another. For instance, ‘the first agent was faster
    in execution’ or ‘the second agent moves more naturally’. Therefore, the comparative
    nature guided humans to come up with a list of criteria that helps to infer the
    utility of the task. With this idea in mind, we designed AgentEval (shown in Fig. [1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ Towards better Human-Agent Alignment: Assessing Task
    Utility in LLM-Powered Applications")), where we employ LLMs to help us understand,
    verify, and assess task utility for the multi-agent system. The AgentEval Framework
    employs two types of agents, namely:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '我们之前关于辅助代理的研究表明，获得人类判断的最优方法是将两个代理并排展示给人类，并询问他们的偏好 Kiseleva 等 ([2022b](#bib.bib20))。在这种成对比较的设置中，人类可以制定一份标准列表来解释他们为什么更喜欢一个代理的行为而不是另一个。例如，“第一个代理的执行速度更快”或“第二个代理的动作更自然”。因此，这种比较性质引导人类提出一份标准列表，以帮助推断任务的效用。考虑到这一点，我们设计了
    AgentEval（如图 [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Towards better Human-Agent
    Alignment: Assessing Task Utility in LLM-Powered Applications") 所示），在这里我们使用 LLMs
    来帮助我们理解、验证和评估多代理系统的任务效用。AgentEval 框架使用了两种类型的代理，即：'
- en: •
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'The goal of a *CriticAgent* is to suggest a list of criteria that can be used
    to assess task utility for end users. The critic is given a task description as
    well as a list of few successful and failed examples of the task execution; then
    it is able to return a list of criteria: $C=\{c_{1},\dots,c_{n}\}$. For example,
    The *CriticAgent* generated the criteria such as Clarity, Efficiency, and more
    as described in the Tab. [1](#S4.T1 "Table 1 ‣ 4 Datasets and Solutions ‣ Towards
    better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications")
    for solving math problems. Each of the Criterion would be accompanied with a set
    of accepted values as shown in this Table as an example.'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*CriticAgent* 的目标是建议一份可以用于评估最终用户任务效用的标准列表。批评者获得任务描述以及一些成功和失败的任务执行示例；然后它能够返回一个标准列表：$C=\{c_{1},\dots,c_{n}\}$。例如，*CriticAgent*
    生成了如清晰度、效率等标准，如表 [1](#S4.T1 "Table 1 ‣ 4 Datasets and Solutions ‣ Towards better
    Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications") 中所述，用于解决数学问题。每个标准将附带一组接受值，如此表所示为例。'
- en: •
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'The goal of *QuantifierAgent* is to quantify each of the suggested criteria
    to access the task utility $U_{t}$. For example, for one sample of math problem
    solving, and given the generated criteria shown in Tab. [1](#S4.T1 "Table 1 ‣
    4 Datasets and Solutions ‣ Towards better Human-Agent Alignment: Assessing Task
    Utility in LLM-Powered Applications") the solution’s Accuracy could be quantified
    as “Incorrect”, “partially correct” or “correct”. Eligible quantified values for
    quantification process are shown in “Accepted values” column in Tab. [1](#S4.T1
    "Table 1 ‣ 4 Datasets and Solutions ‣ Towards better Human-Agent Alignment: Assessing
    Task Utility in LLM-Powered Applications")'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*QuantifierAgent* 的目标是量化每个建议的标准以评估任务效用 $U_{t}$。例如，对于一个数学问题解决的样本，以及表 [1](#S4.T1
    "Table 1 ‣ 4 Datasets and Solutions ‣ Towards better Human-Agent Alignment: Assessing
    Task Utility in LLM-Powered Applications") 中展示的生成标准，解决方案的准确性可以被量化为“错误”、“部分正确”或“正确”。量化过程的合格值显示在表
    [1](#S4.T1 "Table 1 ‣ 4 Datasets and Solutions ‣ Towards better Human-Agent Alignment:
    Assessing Task Utility in LLM-Powered Applications") 中的“接受值”列。'
- en: Next we will discuss the datasets and baselines we use to test the work of AgentEval.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们将讨论我们用来测试 AgentEval 工作的数据集和基准。
- en: 4 Datasets and Solutions
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 数据集和解决方案
- en: 'Table 1: Verification Criteria for MathProblems'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：数学问题的验证标准
- en: '| Criteria | Description | Accepted Values |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 标准 | 描述 | 认可值 |'
- en: '| --- | --- | --- |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Clarity | The ease of understanding the steps, explanations, and language
    used in the solution. | – Not Clear (0) – Moderately Clear (1) – Very Clear (2)
    |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| 清晰度 | 理解解决方案中的步骤、解释和语言的难易程度。 | – 不清晰 (0) – 较清晰 (1) – 非常清晰 (2) |'
- en: '| Efficiency | The use of optimal methods or approaches to solve the math problem.
    | – Inefficient (0) – Moderately Efficient (1) – Efficient (2) |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| 效率 | 使用最佳方法或方法解决数学问题。 | – 低效 (0) – 较高效 (1) – 高效 (2) |'
- en: '| Error Analysis | The identification and description of possible errors or
    misconceptions in the math problem-solving process. | – Not Addressed (0) – Partially
    Addressed (1) – Well Addressed (2) |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 错误分析 | 在数学问题解决过程中识别和描述可能的错误或误解。 | – 未涉及 (0) – 部分涉及 (1) – 很好涉及 (2) |'
- en: '| Completeness | Quality of code in terms of efficiency and elegance | – Incomplete
    (0) – Mostly Complete (1) – Complete (2) |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 完整性 | 代码的效率和优雅性 | – 不完整 (0) – 大部分完整 (1) – 完整 (2) |'
- en: 'This section provides an overview of the datasets utilized in our study. Our
    selection encompasses a variety of datasets, from those based on real-world problems
    to their simulations and beyond. The Mathematics Dataset (Section [4.1](#S4.SS1
    "4.1 MATH Problem Solving ‣ 4 Datasets and Solutions ‣ Towards better Human-Agent
    Alignment: Assessing Task Utility in LLM-Powered Applications")) is chosen for
    its widespread usage and comprehensive understanding in the field. It represents
    complex problem-solving scenarios that are fundamental in evaluating the effectiveness
    of multi-agent systems. AlfWorld (Section [4.2](#S4.SS2 "4.2 ALFWorld Household
    Task ‣ 4 Datasets and Solutions ‣ Towards better Human-Agent Alignment: Assessing
    Task Utility in LLM-Powered Applications")) offers a scenario involving multi-turn
    interactions within a moderately approximated multi-modal environment. This dataset
    is instrumental in assessing agents’ performance in interactive and dynamic settings.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '本节概述了我们研究中使用的数据集。我们的选择涵盖了各种数据集，从基于现实世界问题的数据集到其模拟及其他。数学数据集（第 [4.1](#S4.SS1 "4.1
    MATH Problem Solving ‣ 4 Datasets and Solutions ‣ Towards better Human-Agent Alignment:
    Assessing Task Utility in LLM-Powered Applications")节）因其广泛使用和在该领域的全面理解而被选中。它代表了复杂的解决问题场景，这些场景在评估多智能体系统的有效性时至关重要。AlfWorld（第 [4.2](#S4.SS2
    "4.2 ALFWorld Household Task ‣ 4 Datasets and Solutions ‣ Towards better Human-Agent
    Alignment: Assessing Task Utility in LLM-Powered Applications")节）提供了一个涉及多轮交互的适度模拟的多模态环境场景。这个数据集对于评估智能体在互动和动态环境中的表现非常重要。'
- en: 'Each dataset plays a critical role in evaluating different aspects of AgentEval’s
    capabilities, from handling complex theoretical problems to navigating real-world
    scenarios. In both tasks, although success is clearly defined, multiple solutions
    exist for accomplishing the objectives. For example, when solving a math problem,
    there are various approaches one can take. Similarly, in the Alfworld dataset,
    which involves household tasks, there are multiple ways to complete them based
    on how you search for objects and the thinking strategies you employ, among other
    factors. An example of Math problem solving and AlfWorld task are shown in Appendix [A.1](#A1.SS1
    "A.1 Task Examples ‣ Appendix A Appendix ‣ Towards better Human-Agent Alignment:
    Assessing Task Utility in LLM-Powered Applications").'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '每个数据集在评估AgentEval的不同能力方面都发挥了关键作用，从处理复杂的理论问题到导航现实世界场景。在这两项任务中，虽然成功定义明确，但完成目标的方法有多种。例如，在解决数学问题时，可以采取多种方法。同样，在涉及家庭任务的Alfworld数据集中，有多种方式可以完成任务，具体取决于你如何搜索物体以及你所采用的思维策略等因素。数学问题解决和AlfWorld任务的示例见附录 [A.1](#A1.SS1
    "A.1 Task Examples ‣ Appendix A Appendix ‣ Towards better Human-Agent Alignment:
    Assessing Task Utility in LLM-Powered Applications")。'
- en: '![Refer to caption](img/b0ec45e4a6123d9f0a151d4bcb5bcf70.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/b0ec45e4a6123d9f0a151d4bcb5bcf70.png)'
- en: 'Figure 3: (a) AgentEval assessment of three different solutions on math problem
    solving task categorized (b) Same assessment categorized by success and failed
    cases'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '图3: (a) AgentEval对数学问题解决任务的三种不同解决方案的评估 (b) 按成功和失败情况分类的相同评估'
- en: 4.1 MATH Problem Solving
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 数学问题解决
- en: The MATH dataset, originally is a substantial collection of 12,500 challenging
    mathematics problems from high school competitions Hendrycks et al. ([2021b](#bib.bib13)).
    Each problem comes with a step-by-step solution, enabling models to learn how
    to generate both derivations and explanations. The dataset covers a wide range
    of mathematical subjects and is tagged by difficulty levels, offering a nuanced
    measure of model performance across various aspects of mathematical problem-solving.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: MATH数据集最初是一个由12,500个挑战性的数学问题组成的大型集合，来自高中竞赛 Hendrycks et al. ([2021b](#bib.bib13))。每个问题都附有逐步解决方案，使模型能够学习如何生成推导和解释。该数据集涵盖了广泛的数学科目，并按难度级别标记，提供了对模型在各种数学问题解决方面表现的细致衡量。
- en: 'This dataset is particularly suitable for testing multi-agent systems for several
    reason including: (i) The problems in the MATH dataset are not simple computations
    but require a deep understanding of mathematical concepts, heuristics, and problem-solving
    strategies. (ii) Since the dataset includes step-by-step solutions, it allows
    for the assessment of an agent’s ability to learn and reason through a problem,
    not just its ability to arrive at the correct answer. (iii) The variety of subjects
    and difficulty levels in the MATH dataset enables a comprehensive evaluation of
    a system’s versatility and adaptability in different mathematical domains which
    is crucial for multi-agent systems that are expected to operate across a range
    of scenarios.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集特别适合测试多智能体系统，原因包括：（i）MATH 数据集中的问题不仅仅是简单的计算，而是需要对数学概念、启发式方法和解决问题策略有深入理解。（ii）由于数据集包括逐步解决方案，因此可以评估智能体通过问题的能力，而不仅仅是其得出正确答案的能力。（iii）MATH
    数据集中的主题和难度等级的多样性使得可以全面评估系统在不同数学领域的多功能性和适应性，这对预期在各种场景下运行的多智能体系统至关重要。
- en: Similar to the math problem experimental setup as in Wu et al. ([2023](#bib.bib47)),
    we carry out two experimental evaluations which involves 120 problems from level-5,
    the most challenging category, and includes 20 problems each from six different
    categories, of number theory, counting and probability, prealgebra, algebra, intermediate
    algebra, and precalculus.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于 Wu 等人（[2023](#bib.bib47)）的数学问题实验设置，我们进行两项实验评估，涉及来自第 5 级（最具挑战性类别）的 120 个问题，每个类别包括
    20 个问题，这些类别包括数论、计数与概率、初等代数、代数、中级代数和预备微积分。
- en: 'Solutions: In establishing a solution for this task, we draw inspiration from
    the experiments showcased in Wu et al. ([2023](#bib.bib47)). We evaluate the proposed
    methodology by AutoGen Wu et al. ([2023](#bib.bib47)), as well as Langchain ReAct
    ³³3[https://python.langchain.com/en/latest/index.html](https://python.langchain.com/en/latest/index.html)
    and a Vanilla solver that employs gpt-4 to tackle the task. These solutions approaches
    have previously demonstrated promising performance in solving mathematical problems,
    particularly on the dataset at hand Wu et al. ([2023](#bib.bib47)). We assess
    and compare the performance of these three solutions using AgentEval. Fig. [9](#A1.F9
    "Figure 9 ‣ A.1 Task Examples ‣ Appendix A Appendix ‣ Towards better Human-Agent
    Alignment: Assessing Task Utility in LLM-Powered Applications") displays an example
    of one math problem from prealgebra category as well as the solution created by
    AutoGen. In Section [5.1](#S5.SS1 "5.1 AgentEval for Math Problems ‣ 5 AgentEval
    Workflow ‣ Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered
    Applications"), we delve into how AgentEval would perform on math problem solving
    tasks and how the measured performance with AgentEval correlates with the ground
    truths.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案：在建立此任务的解决方案时，我们从 Wu 等人（[2023](#bib.bib47)）展示的实验中获得灵感。我们评估了 AutoGen Wu 等人（[2023](#bib.bib47)）提出的方法，以及
    Langchain ReAct ³³3[https://python.langchain.com/en/latest/index.html](https://python.langchain.com/en/latest/index.html)
    和一个使用 gpt-4 解决该任务的 Vanilla 求解器。这些解决方案方法在解决数学问题方面已经展示了良好的表现，特别是在当前数据集上 Wu 等人（[2023](#bib.bib47)）。我们使用
    AgentEval 评估和比较这三种解决方案的表现。图 [9](#A1.F9 "图 9 ‣ A.1 任务示例 ‣ 附录 A ‣ 更好的人机对齐：评估 LLM
    驱动应用中的任务效用") 显示了一个来自预备微积分类别的数学问题及由 AutoGen 创建的解决方案。在第 [5.1](#S5.SS1 "5.1 AgentEval
    用于数学问题 ‣ 5 AgentEval 工作流程 ‣ 更好的人机对齐：评估 LLM 驱动应用中的任务效用") 节中，我们深入探讨了 AgentEval 在数学问题解决任务中的表现，以及使用
    AgentEval 测量的表现与实际情况的相关性。
- en: 4.2 ALFWorld Household Task
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 ALFWorld 家庭任务
- en: 'ALFWorld, presents a set of language-based interactive decision-making tasks
    within simulated household environments Shridhar et al. ([2020b](#bib.bib38)).
    This benchmark is distinguished by its diversity of tasks, offering a comprehensive
    platform for testing AI and multi-agent systems. This benchmark is particularly
    suited for such evaluations because first, ALFWorld is the first interactive parallel
    environment that aligns text descriptions and commands with physically embodied
    robotic simulation. It extends two prior works: TextWorld, an engine for interactive
    text-based games, and ALFRED, a large-scale dataset for vision-language instruction
    following in embodied environments Shridhar et al. ([2020a](#bib.bib37)); Côté
    et al. ([2019](#bib.bib8)). The cross-modality framework of this benchmark allows
    for a variety of embodied tasks with corresponding text-based counterparts, allowing
    agents to be trained and evaluated in both the language and embodied world. In
    addition, ALFWorld supports the development of agents that can reason both abstractly
    and execute actions concretely, mimicking human-like decision-making processes
    in varying contexts. Finally, the dataset’s inclusion of a wide range of tasks,
    from household chores to more intricate problem-solving scenarios, provides a
    comprehensive testbed for evaluating the adaptability and problem-solving capabilities
    of AI and multi-agent systems. In general, the dataset allows agents to explore,
    interact, and learn in an abstract language environment before dealing with the
    complexities of an embodied environment.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ALFWorld展示了一组基于语言的交互决策任务，在模拟家庭环境中进行测试Shirdar等（[2020b](#bib.bib38)）。这个基准测试以任务的多样性而著称，为测试AI和多智能体系统提供了一个全面的平台。这个基准测试特别适合这样的评估，因为首先，ALFWorld是第一个将文本描述和命令与物理体现的机器人模拟对齐的交互式并行环境。它扩展了两个先前的工作：TextWorld，一个用于交互式基于文本的游戏的引擎，以及ALFRED，一个用于在具体现实环境中跟随视觉-语言指令的大规模数据集Shridhar等（[2020a](#bib.bib37)）；Côté等（[2019](#bib.bib8)）。这个基准测试的跨模态框架允许进行各种具体现实任务，并提供相应的基于文本的对照，使得代理可以在语言和具体现实世界中进行训练和评估。此外，ALFWorld支持开发能够进行抽象推理和具体执行动作的代理，模拟人类在不同背景下的决策过程。最后，该数据集包含了从家庭琐事到更复杂问题解决场景的广泛任务，为评估AI和多智能体系统的适应能力和问题解决能力提供了一个全面的测试平台。总体而言，该数据集允许代理在处理具体现实环境的复杂性之前，在抽象语言环境中进行探索、互动和学习。
- en: 'Solutions: As for the solutions to solve ALFWorld Household tasks, similar
    to Wu et al. ([2023](#bib.bib47)), we consider ReAct Yao et al. ([2022](#bib.bib48))
    as well as AutoGen with two agents and AutoGen with three agents Wu et al. ([2023](#bib.bib47)).
    ReAct is an agent that operates within the ALFWorld environments and is responsible
    for suggesting plans and executing actions. On the other hand, AutoGen Two-Agent
    System consists of an LLM-backed assistant agent responsible for suggesting plans,
    and an executor agent responsible for executing actions in the ALFWorld environments.
    Both ReAct and this solution occasionally struggles with leveraging basic commonsense
    knowledge about the physical world, which can lead to repetitive errors and getting
    stuck in loops. In AutoGen with three agents, a grounding agent is provided just
    for the sake of critical common sense knowledge whenever the system exhibits early
    signs of recurring errors. We assess and compare the performance of these three
    solutions using AgentEval. Fig. [10](#A1.F10 "Figure 10 ‣ A.1 Task Examples ‣
    Appendix A Appendix ‣ Towards better Human-Agent Alignment: Assessing Task Utility
    in LLM-Powered Applications") displays a portion of an example of AlfWorld Householding
    task solved by AutoGen.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '解决方案：至于解决ALFWorld家庭任务的方案，类似于Wu等（[2023](#bib.bib47)），我们考虑了ReAct Yao等（[2022](#bib.bib48)）以及使用两个代理的AutoGen和使用三个代理的AutoGen
    Wu等（[2023](#bib.bib47)）。ReAct是一个在ALFWorld环境中运行的代理，负责建议计划和执行动作。另一方面，AutoGen两代理系统包括一个基于LLM的助理代理，负责建议计划，以及一个执行代理，负责在ALFWorld环境中执行动作。ReAct和这个解决方案有时在利用有关物理世界的基本常识方面遇到困难，这可能导致重复的错误和陷入循环。在使用三个代理的AutoGen中，提供了一个基础代理，仅用于在系统出现重复错误的早期迹象时提供关键的常识知识。我们使用AgentEval评估和比较这三种解决方案的性能。图[10](#A1.F10
    "Figure 10 ‣ A.1 Task Examples ‣ Appendix A Appendix ‣ Towards better Human-Agent
    Alignment: Assessing Task Utility in LLM-Powered Applications")展示了由AutoGen解决的AlfWorld家庭任务的一个示例。'
- en: 5 AgentEval Workflow
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 AgentEval 工作流程
- en: 'This Section outlines the workflow of the AgentEval illustrated in Fig. [1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ Towards better Human-Agent Alignment: Assessing Task
    Utility in LLM-Powered Applications"). Next, we will demonstrate how AgentEval
    works based on 3 different datasets: Math Problems (Sec. [4.1](#S4.SS1 "4.1 MATH
    Problem Solving ‣ 4 Datasets and Solutions ‣ Towards better Human-Agent Alignment:
    Assessing Task Utility in LLM-Powered Applications")) and AlfWorld (Sec. [4.2](#S4.SS2
    "4.2 ALFWorld Household Task ‣ 4 Datasets and Solutions ‣ Towards better Human-Agent
    Alignment: Assessing Task Utility in LLM-Powered Applications")).'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '本节概述了图[1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Towards better Human-Agent Alignment:
    Assessing Task Utility in LLM-Powered Applications")中所示的AgentEval工作流程。接下来，我们将展示基于3个不同数据集的AgentEval工作方式：数学问题（第[4.1](#S4.SS1
    "4.1 MATH Problem Solving ‣ 4 Datasets and Solutions ‣ Towards better Human-Agent
    Alignment: Assessing Task Utility in LLM-Powered Applications")节）和AlfWorld（第[4.2](#S4.SS2
    "4.2 ALFWorld Household Task ‣ 4 Datasets and Solutions ‣ Towards better Human-Agent
    Alignment: Assessing Task Utility in LLM-Powered Applications")节）。'
- en: 5.1 AgentEval for Math Problems
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 AgentEval在数学问题中的应用
- en: Critic and Quantifier Findings
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Critic和Quantifier的发现
- en: 'After executing the CriticAgent, we have obtained a set of criteria for validating
    the results of the mathematical problem presented in Table [1](#S4.T1 "Table 1
    ‣ 4 Datasets and Solutions ‣ Towards better Human-Agent Alignment: Assessing Task
    Utility in LLM-Powered Applications"). Subsequently, the *QuantifierAgent* is
    tasked with quantifying each criterion based on accepted values. In Figure [3](#S4.F3
    "Figure 3 ‣ 4 Datasets and Solutions ‣ Towards better Human-Agent Alignment: Assessing
    Task Utility in LLM-Powered Applications") (a), we present the outcome of *QuantifierAgent*
    i.e., the measured performance of three solutions on this task. This visual representation
    of the AgentEval output reveals some intriguing insights. Notably, it is evident
    that Agenteval do not quantify the three solutions as if they are equally performing
    well across different criteria. For instance, while all three solutions leverage
    GPT-4 as the underlying language model, Autogen outperforms ReAct and Vanilla
    GPT-4 in terms of accuracy. This observation extends to solution completeness
    and efficiency as well. Conversely, when considering the criterion of Clarity,
    all three approaches exhibit more competitive performance.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '执行CriticAgent后，我们获得了一套用于验证数学问题结果的标准，如表[1](#S4.T1 "Table 1 ‣ 4 Datasets and
    Solutions ‣ Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered
    Applications")所示。随后，*QuantifierAgent*的任务是根据接受的值量化每个标准。在图[3](#S4.F3 "Figure 3 ‣
    4 Datasets and Solutions ‣ Towards better Human-Agent Alignment: Assessing Task
    Utility in LLM-Powered Applications") (a)中，我们展示了*QuantifierAgent*的结果，即三种解决方案在此任务上的测量性能。这个AgentEval输出的可视化表示揭示了一些有趣的见解。显然，AgentEval没有将这三种解决方案在不同标准上量化为表现均等。例如，虽然这三种解决方案都使用了GPT-4作为底层语言模型，但在准确性方面，Autogen优于ReAct和Vanilla
    GPT-4。这一观察也扩展到解决方案的完整性和效率。然而，在考虑清晰度标准时，所有三种方法表现得更具竞争力。'
- en: 'As depicted in this figure, the error analysis range of quantified values differs
    from other metrics. To gain a better understanding of this criterion, we further
    scrutinize the results by categorizing them into successful and failed cases,
    as illustrated in Fig. [3](#S4.F3 "Figure 3 ‣ 4 Datasets and Solutions ‣ Towards
    better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications") (b).
    While AutoGen, Vanilla Solver and ReAct solution are each presented in orange,
    blue and green respectively, the darker bars represent the performance on successful
    cases and lighter bars represent the failed cases performance. The difference
    between the dark and light bar of each color, verify the AgentEval performance
    as we expect that each positive criteria should be quantifier higher for successful
    cases compared to their failed cases. We observe that in most cases, the successful
    and failed cases are distinguished even with 95% interval confidence on all the
    success and failed cases.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '如图所示，量化值的误差分析范围与其他指标不同。为了更好地理解这一标准，我们进一步通过将结果分类为成功和失败案例来进行审查，如图[3](#S4.F3 "Figure
    3 ‣ 4 Datasets and Solutions ‣ Towards better Human-Agent Alignment: Assessing
    Task Utility in LLM-Powered Applications") (b)所示。AutoGen、Vanilla Solver和ReAct解决方案分别用橙色、蓝色和绿色表示，较暗的条形表示成功案例的表现，较浅的条形表示失败案例的表现。每种颜色的深色和浅色条形之间的差异验证了AgentEval的表现，我们期望每个正面标准在成功案例中的量化值应高于失败案例。我们观察到，在大多数情况下，成功和失败案例即使在95%置信区间下也能被区分。'
- en: We delve further into the differences between successful cases among the three
    solutions and failed cases among the solutions. One interesting observation from
    this Figure is that not all successful cases are identical, and similarly, not
    all failed cases are the same. The difference between successful cases among the
    three solutions is smaller than the differences between their failed cases. For
    instance, Autogen’s failed cases exhibit higher efficiency and completeness compared
    to the Vanilla gpt-4 solver. This observation provides us with valuable additional
    insights.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进一步探讨了三种解决方案中成功案例与失败案例之间的差异。从图中可以得出一个有趣的观察结果，即并非所有成功案例都是相同的，同样地，失败案例也并非完全相同。三种解决方案中的成功案例之间的差异小于它们的失败案例之间的差异。例如，Autogen
    的失败案例在效率和完整性上表现出比 Vanilla gpt-4 解决方案更高的水平。这一观察为我们提供了宝贵的额外见解。
- en: 'Table 2: Verification Criteria for AlfWorld Housholding Tasks.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：AlfWorld 家务任务的验证标准。
- en: '| Criteria | Description | Accepted Values |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 标准 | 描述 | 接受值 |'
- en: '| --- | --- | --- |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Task Understanding | How well the participant was able to comprehend the
    problem set and follow the task instructions | – Excellent (4) – Good (3) – Average
    (2) – Poor (1) – Terrible (0) |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 任务理解 | 参与者对问题集的理解能力及其对任务指令的遵循程度 | – 优秀 (4) – 良好 (3) – 一般 (2) – 较差 (1) – 极差
    (0) |'
- en: '| Plan Making | The ability of the participant to strategize and make a plan
    for tackling the task. | – Excellent (4) – Good (3) – Average (2) – Poor (1) –
    Terrible (0) |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 计划制定 | 参与者制定策略和计划以完成任务的能力。 | – 优秀 (4) – 良好 (3) – 一般 (2) – 较差 (1) – 极差 (0)
    |'
- en: '| Action Decision | The participant’s decision-making skills in choosing the
    right action to perform. | – Excellent (4) – Good (3) – Average (2) – Poor (1)
    – Terrible (0) |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 行动决策 | 参与者在选择执行正确行动方面的决策能力。 | – 优秀 (4) – 良好 (3) – 一般 (2) – 较差 (1) – 极差 (0)
    |'
- en: '| Action Execution | How effectively the participant is able to execute the
    chosen action. | – Excellent (4) – Good (3) – Average (2) – Poor (1) – Terrible
    (0) |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 行动执行 | 参与者执行所选择行动的有效性。 | – 优秀 (4) – 良好 (3) – 一般 (2) – 较差 (1) – 极差 (0) |'
- en: '| Response to Feedback | How well the participant adapts his/her next steps
    based on the feedback from the environment | – Excellent (4) – Good (3) – Average
    (2) – Poor (1) – Terrible (0) |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 对反馈的响应 | 参与者根据环境反馈调整下一步行动的能力 | – 优秀 (4) – 良好 (3) – 一般 (2) – 较差 (1) – 极差 (0)
    |'
- en: '| Correctness of Action | The correctness of the action performed by the participant
    with respect to the available actions and the current context | – Correct (1)
    – Incorrect (0) |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 行动正确性 | 参与者执行的行动在现有行动和当前上下文中的正确性 | – 正确 (1) – 错误 (0) |'
- en: '| Use of Terminate | Whether the participant uses the ’TERMINATE’ command appropriately
    | – Appropriate (1) – Inappropriate (0) |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 使用终止命令 | 参与者是否适当地使用了’TERMINATE’命令 | – 适当 (1) – 不适当 (0) |'
- en: 5.2 AgentEval for AlfWorld
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 AlfWorld 的 AgentEval
- en: Critic and Quantifier Finding
  id: totrans-100
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 批评与量化发现
- en: 'In this section, we provide an example of AgentEval applied to the AlfWorld
    Householding task, as mentioned in Sec. [5.1](#S5.SS1 "5.1 AgentEval for Math
    Problems ‣ 5 AgentEval Workflow ‣ Towards better Human-Agent Alignment: Assessing
    Task Utility in LLM-Powered Applications") in which real-world household environments
    is emulated through textual interfaces Shridhar et al. ([2020b](#bib.bib38)).
    When running the *CriticAgent* on this task, it identified specific criteria such
    as “Task understanding”, “Plan making” and “Response to Feedback” as outlined
    in Tab. [2](#S5.T2 "Table 2 ‣ Critic and Quantifier Findings ‣ 5.1 AgentEval for
    Math Problems ‣ 5 AgentEval Workflow ‣ Towards better Human-Agent Alignment: Assessing
    Task Utility in LLM-Powered Applications"). We consulted researchers deeply involved
    with these tasks, and their expertise confirmed that these criteria are critically
    relevant and significant similar to Li et al. ([2023b](#bib.bib24)). For example,
    given that these tasks are language-based and require interactive decision-making,
    an agent in ALFWorld is tasked with high-level objectives, such as placing a hot
    apple in the fridge, and must navigate and interact with a simulated household
    environment to achieve these objectives. Therefore, criteria displayed in Tab. [2](#S5.T2
    "Table 2 ‣ Critic and Quantifier Findings ‣ 5.1 AgentEval for Math Problems ‣
    5 AgentEval Workflow ‣ Towards better Human-Agent Alignment: Assessing Task Utility
    in LLM-Powered Applications") satisfy the assessment of this task. While the criteria
    are pretty self-descriptive, about the criterion “Use of TERMINATE” We note that
    the agent is prompted to use the term “TERMINATE” upon task completion, which
    is closely correlated with task success.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们提供了一个将 AgentEval 应用于 AlfWorld Householding 任务的示例，如第 [5.1](#S5.SS1 "5.1
    AgentEval for Math Problems ‣ 5 AgentEval Workflow ‣ Towards better Human-Agent
    Alignment: Assessing Task Utility in LLM-Powered Applications")节所述，其中通过文本接口模拟了真实世界的家庭环境，Shridhar
    等人 ([2020b](#bib.bib38))。在这个任务上运行 *CriticAgent* 时，它识别了如“任务理解”、“计划制定”和“反馈响应”等特定标准，如表
    [2](#S5.T2 "Table 2 ‣ Critic and Quantifier Findings ‣ 5.1 AgentEval for Math
    Problems ‣ 5 AgentEval Workflow ‣ Towards better Human-Agent Alignment: Assessing
    Task Utility in LLM-Powered Applications")中所列。我们咨询了深度参与这些任务的研究人员，他们的专业知识证实了这些标准的关键相关性和重要性，与
    Li 等人 ([2023b](#bib.bib24)) 的结论类似。例如，考虑到这些任务基于语言并且需要互动决策，ALFWorld 中的代理被赋予了高层次的目标，比如将一个热苹果放入冰箱，并且必须在模拟的家庭环境中导航和互动以实现这些目标。因此，表
    [2](#S5.T2 "Table 2 ‣ Critic and Quantifier Findings ‣ 5.1 AgentEval for Math
    Problems ‣ 5 AgentEval Workflow ‣ Towards better Human-Agent Alignment: Assessing
    Task Utility in LLM-Powered Applications")中显示的标准符合对该任务的评估。虽然这些标准相当自描述，但关于标准“使用
    TERMINATE”我们注意到，代理在任务完成后会被提示使用“TERMINATE”这一术语，这与任务成功密切相关。'
- en: '![Refer to caption](img/a30ea06b98677d5872cf093cb316b687.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/a30ea06b98677d5872cf093cb316b687.png)'
- en: 'Figure 4: (a) AgentEval assessment of three different solutions on AlfWorld
    Householding Task (b) Same assessment categorized by success and failed cases.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '图 4: (a) AgentEval 对三种不同解决方案在 AlfWorld Householding 任务上的评估 (b) 根据成功和失败案例对相同评估的分类。'
- en: 'Following the extraction of a set of criteria as detailed in Tab [2](#S5.T2
    "Table 2 ‣ Critic and Quantifier Findings ‣ 5.1 AgentEval for Math Problems ‣
    5 AgentEval Workflow ‣ Towards better Human-Agent Alignment: Assessing Task Utility
    in LLM-Powered Applications"), these criteria are passed to the QuantifierAgent
    for quantification on each sample. Figure [4](#S5.F4 "Figure 4 ‣ Critic and Quantifier
    Finding ‣ 5.2 AgentEval for AlfWorld ‣ 5 AgentEval Workflow ‣ Towards better Human-Agent
    Alignment: Assessing Task Utility in LLM-Powered Applications") presents the results
    for three introduced solutions: AutoGen with 2 agents, AutoGen with 3 agents,
    and ReAct, on the 134-test set from Wu et al. ([2023](#bib.bib47)). On the left
    side of Fig. [4](#S5.F4 "Figure 4 ‣ Critic and Quantifier Finding ‣ 5.2 AgentEval
    for AlfWorld ‣ 5 AgentEval Workflow ‣ Towards better Human-Agent Alignment: Assessing
    Task Utility in LLM-Powered Applications"), a Spider Figure illustrates the performance
    of these three solutions across all criteria. It is important to note that all
    criteria, except “Use of TERMINATE” and “Correctness of Action” employ a five-level
    grading system, while these two criteria are binary. From this figure, it is evident
    that ReACT performs notably worse across all criteria, while AutoGen with 2 agents
    and 3 agents demonstrate competitive performance. Notably, AutoGen with an additional
    common-sense grounding agent slightly outperforms others, particularly in the
    areas of Response to Feedback and Action Execution. Additionally, the barplot
    on the right side of Fig. [4](#S5.F4 "Figure 4 ‣ Critic and Quantifier Finding
    ‣ 5.2 AgentEval for AlfWorld ‣ 5 AgentEval Workflow ‣ Towards better Human-Agent
    Alignment: Assessing Task Utility in LLM-Powered Applications") categorizes the
    134 games into two groups: failed and successful, displaying the quantifier performance
    for each subgroup. Similar to Fig. [3](#S4.F3 "Figure 3 ‣ 4 Datasets and Solutions
    ‣ Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered
    Applications"), darker colors represent performance in successful cases for each
    solution, while lighter colors represent performance in failed cases. AutoGen
    3-agent, AutoGen 2-agent, and ReAct are represented by blue, green, and orange,
    respectively. For most criteria, the distinction between failed and successful
    cases is clear, even within a 95% confidence interval. However, for certain criteria,
    such as “Task understanding” all solutions, whether they failed or succeeded,
    exhibit very similar performance. This could be interpreted as either (1) all
    solutions have a good understanding of the task, even if they fail to complete
    it, (2) this criterion may be redundant, as it does not provide additional information
    among these three solutions or (3) the *QuantifierAgent* is unable to score the
    criterion in a meaningful way. We refrain from concluding which criteria are most
    suitable for this specific task. Instead, we emphasize the importance of conducting
    a more in-depth analysis of performance beyond success rates, tailored to one’s
    goals and application requirements.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '根据表格 [2](#S5.T2 "Table 2 ‣ Critic and Quantifier Findings ‣ 5.1 AgentEval for
    Math Problems ‣ 5 AgentEval Workflow ‣ Towards better Human-Agent Alignment: Assessing
    Task Utility in LLM-Powered Applications") 中详细列出的标准，这些标准被传递给 QuantifierAgent 以对每个样本进行量化。图
    [4](#S5.F4 "Figure 4 ‣ Critic and Quantifier Finding ‣ 5.2 AgentEval for AlfWorld
    ‣ 5 AgentEval Workflow ‣ Towards better Human-Agent Alignment: Assessing Task
    Utility in LLM-Powered Applications") 展示了三种引入的解决方案的结果：具有 2 个代理的 AutoGen，具有 3 个代理的
    AutoGen，以及 ReAct，基于 Wu 等人的 134 测试集 ([2023](#bib.bib47))。在图 [4](#S5.F4 "Figure
    4 ‣ Critic and Quantifier Finding ‣ 5.2 AgentEval for AlfWorld ‣ 5 AgentEval Workflow
    ‣ Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered
    Applications") 的左侧，一张 Spider 图展示了这三种解决方案在所有标准下的表现。需要注意的是，除“使用 TERMINATE”和“行动的正确性”外，所有标准都使用五级评分系统，而这两个标准是二元的。从图中可以看出，ReACT
    在所有标准下的表现显著较差，而具有 2 个代理和 3 个代理的 AutoGen 展现了具有竞争力的表现。特别地，具有额外常识基础的 AutoGen 稍微优于其他方法，特别是在反馈响应和行动执行方面。此外，图
    [4](#S5.F4 "Figure 4 ‣ Critic and Quantifier Finding ‣ 5.2 AgentEval for AlfWorld
    ‣ 5 AgentEval Workflow ‣ Towards better Human-Agent Alignment: Assessing Task
    Utility in LLM-Powered Applications") 右侧的条形图将 134 个游戏分为两个组：失败和成功，展示了每个子组的量化器表现。与图
    [3](#S4.F3 "Figure 3 ‣ 4 Datasets and Solutions ‣ Towards better Human-Agent Alignment:
    Assessing Task Utility in LLM-Powered Applications") 类似，较暗的颜色表示每种解决方案在成功案例中的表现，而较浅的颜色表示在失败案例中的表现。AutoGen
    3 代理、AutoGen 2 代理和 ReAct 分别用蓝色、绿色和橙色表示。对于大多数标准，失败和成功案例之间的区别是明显的，即使在 95% 的置信区间内。然而，对于某些标准，如“任务理解”，所有解决方案，无论是失败还是成功，都表现得非常相似。这可以被解读为（1）所有解决方案都对任务有很好的理解，即使它们未能完成任务，（2）该标准可能是多余的，因为它没有提供这三种解决方案之间的额外信息，或（3）*QuantifierAgent*
    无法以有意义的方式对该标准进行评分。我们避免得出哪些标准最适合此特定任务的结论。相反，我们强调进行更深入的性能分析的重要性，超越成功率，根据目标和应用需求量身定制。'
- en: 6 AgentEval Robustness Analysis and In-depth Discussion
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 AgenEval 稳健性分析和深入讨论
- en: 'This section presents the results of the analysis of how robust AgenEval is.
    First, we inspect if the list of criteria can be solely extracted from the task
    description (task-based criteria), and how the list of criteria can be changed
    by adding failed and successful samples from the data. Where we played with varies
    sample size to check its effect of the final list of criteria (Section [6.1](#S6.SS1
    "6.1 Task-based vs Solution-based criteria ‣ 6 AgentEval Robustness Analysis and
    In-depth Discussion ‣ Towards better Human-Agent Alignment: Assessing Task Utility
    in LLM-Powered Applications")). Second, we focus on how can we estimate the robustness
    of the *QuantifierAgent* (Section [6.2](#S6.SS2 "6.2 Quantifier Agent Robustness
    ‣ 6 AgentEval Robustness Analysis and In-depth Discussion ‣ Towards better Human-Agent
    Alignment: Assessing Task Utility in LLM-Powered Applications")). We note that
    all the experiments reported in the paper are conducted with the temperature set
    at 0. Next, we will present our analysis using the MATH Problems dataset.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了AgenEval的稳健性分析结果。首先，我们检查是否可以仅从任务描述中提取标准列表（基于任务的标准），以及通过添加失败和成功的样本如何改变标准列表。我们尝试了不同的样本大小，以检查其对最终标准列表的影响（第[6.1](#S6.SS1
    "6.1 基于任务的标准与基于解决方案的标准 ‣ 6 AgenEval 稳健性分析和深入讨论 ‣ 更好的人工智能对齐：评估LLM驱动应用中的任务实用性")节）。其次，我们关注如何估计*QuantifierAgent*的稳健性（第[6.2](#S6.SS2
    "6.2 定量评估代理的稳健性 ‣ 6 AgenEval 稳健性分析和深入讨论 ‣ 更好的人工智能对齐：评估LLM驱动应用中的任务实用性")节）。我们注意到论文中报告的所有实验都是在温度设置为0的情况下进行的。接下来，我们将使用MATH问题数据集来展示我们的分析。
- en: '![Refer to caption](img/4bcaf71d32045961b7e5f23ef3c3eaf3.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4bcaf71d32045961b7e5f23ef3c3eaf3.png)'
- en: 'Figure 5: Task based criteria vs solution based criteria for Math problems.
    show the 95% interval at each step'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：数学问题的基于任务的标准与基于解决方案的标准。展示每一步的95%区间
- en: 6.1 Task-based vs Solution-based criteria
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 基于任务的标准与基于解决方案的标准
- en: General Hypothesis
  id: totrans-110
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 一般假设
- en: We execute the CriticAgent using two distinct methods. The first method involves
    the Agent generating criteria solely based on the provided task description, which
    we refer to as “task-based” criteria. On the other hand, the CriticAgent could
    potentially derives criteria not only from a task description but also from examples
    of task solutions so called as “solution-based” criteria. In this context, our
    objective is to examine whether this approach leads to variations in the criteria
    formulated by agents. We believe this investigation is important to have a more
    clear vision of what criteria necessitate for having a promising assessment.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用两种不同的方法执行CriticAgent。第一种方法涉及Agent仅基于提供的任务描述生成标准，我们称之为“基于任务的”标准。另一方面，CriticAgent可能不仅从任务描述中，还从任务解决方案示例中推导标准，称之为“基于解决方案的”标准。在这种情况下，我们的目标是检查这种方法是否会导致代理制定的标准发生变化。我们认为，这项调查对于更清晰地了解哪些标准对于具有前景的评估是必要的非常重要。
- en: A solution to a mathematical problem, might probably satisfy criteria such as
    accuracy and clarity in any case, independent of what the solution is. However,
    when additional tools are being utilized to solve the problems, such as coding
    to solve math problems, additional criteria like ‘Code Efficiency’ may be introduced
    to the set of criteria. If one never considered solving the problem with a specific
    solution method like coding, they might not initially include such criterion.
    In summary, depending on whether the *CriticAgent* receives only a task description
    or both a task description and examples of solutions, we classify the criteria
    as either “task-based” or “solution-based”. Additionally, it is important to analyze
    whether the solution-based criteria overlap across different solutions and to
    what extent different solutions share these criteria.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 一个数学问题的解决方案可能在任何情况下都可能满足如准确性和清晰度等标准，无论解决方案是什么。然而，当使用附加工具解决问题时，例如使用编码解决数学问题，可能会引入诸如“代码效率”等额外标准。如果一个人从未考虑过使用特定的解决方案方法如编码来解决问题，他们可能最初不会包含这样的标准。总之，根据*CriticAgent*是否仅接收到任务描述或同时接收到任务描述和解决方案示例，我们将标准分类为“基于任务的”或“基于解决方案的”。此外，分析解决方案标准是否在不同解决方案之间重叠以及不同解决方案在多大程度上共享这些标准也是重要的。
- en: 'To compare the differences between task-based and solution-based criteria,
    Fig. [5](#S6.F5 "Figure 5 ‣ 6 AgentEval Robustness Analysis and In-depth Discussion
    ‣ Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered
    Applications") displays the number of unique criteria extracted for mathematical
    problem solving in task-based mode and three different solution-based approaches
    i.e., when the solutions come from AutoGen, ReAct and Vanilla Solver. To keep
    the balance between computational costs and analyzing the robustness, we conducted
    50 runs of the CriticAgent with different seeds. Subsequently, for $N=50$.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较基于任务的标准和基于解决方案的标准之间的差异，图[5](#S6.F5 "图 5 ‣ 6 AgentEval 稳健性分析和深入讨论 ‣ 迈向更好的人工智能-代理对齐：评估
    LLM 驱动应用中的任务效用")显示了在基于任务的模式下和来自 AutoGen、ReAct 及 Vanilla Solver 的三种不同解决方案方法中提取的数学问题解决的唯一标准数量。为了平衡计算成本和分析稳健性，我们进行了
    50 次 CriticAgent 的运行，使用不同的种子。随后，对于 $N=50$。
- en: 'When examining the criteria, we have identified instances where certain criteria
    are quite similar but are expressed differently. These are essentially metrics
    that convey the same concept but are phrased with slight variations. In Table
    [3](#S6.T3 "Table 3 ‣ General Hypothesis ‣ 6.1 Task-based vs Solution-based criteria
    ‣ 6 AgentEval Robustness Analysis and In-depth Discussion ‣ Towards better Human-Agent
    Alignment: Assessing Task Utility in LLM-Powered Applications"), we provide examples
    of such similarities along with their descriptions. In order to gain a deeper
    insight into the results presented in Figure [5](#S6.F5 "Figure 5 ‣ 6 AgentEval
    Robustness Analysis and In-depth Discussion ‣ Towards better Human-Agent Alignment:
    Assessing Task Utility in LLM-Powered Applications"), we suggest consolidating
    these closely related criteria to determine the total number of unique criteria
    once again. This approach serves two purposes: 1\. It enhances our understanding
    of the actual number of unique criteria that have been extracted. 2\. It allows
    us to assess whether the repetitiveness and redundancy of criteria differ between
    solution-based and task-based criteria. By doing so, we can gain a better grasp
    of the data and draw more meaningful conclusions from our analysis.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在检查标准时，我们发现某些标准非常相似但表达方式不同。这些本质上是传达相同概念的指标，只是措辞上有细微差别。在表[3](#S6.T3 "表 3 ‣ 一般假设
    ‣ 6.1 基于任务与基于解决方案的标准 ‣ 6 AgentEval 稳健性分析和深入讨论 ‣ 迈向更好的人工智能-代理对齐：评估 LLM 驱动应用中的任务效用")中，我们提供了这些相似性的示例及其描述。为了更深入地了解图[5](#S6.F5
    "图 5 ‣ 6 AgentEval 稳健性分析和深入讨论 ‣ 迈向更好的人工智能-代理对齐：评估 LLM 驱动应用中的任务效用")中呈现的结果，我们建议整合这些密切相关的标准，以便重新确定唯一标准的总数。这种方法有两个目的：1.
    增强我们对提取出的唯一标准实际数量的理解。2. 评估标准的重复性和冗余性在基于解决方案的标准与基于任务的标准之间是否有所不同。通过这样做，我们可以更好地掌握数据，并从分析中得出更有意义的结论。
- en: 'Table 3: Pairs of similar criteria extracted for Math problem solving task.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：数学问题解决任务的相似标准对。
- en: '| - Problem Difficulty: The complexity of the math problem that has been solved.
    |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| - 问题难度：已解决数学问题的复杂性。 |'
- en: '| - Problem Complexity: The level of difficulty of the problem. |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| - 问题复杂性：问题的难度等级。 |'
- en: '| - Innovativeness: The novelty and creativity in the approach to solve the
    problem |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| - 创新性：解决问题的方法的新颖性和创造性 |'
- en: '| - Innovation: The ability to solve a problem using a unique or creative method
    not commonly known. |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| - 创新：使用不常见的独特或创造性方法解决问题的能力。 |'
- en: '| - Time Taken: The time taken to solve the problem. |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| - 所用时间：解决问题所花费的时间。 |'
- en: '| - Time to Completion: The amount of time taken to solve the problem completely
    |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| - 完成时间：解决问题所需的全部时间 |'
- en: '| - Understandability: The clarity and ease of comprehension of the solution
    provided. |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| - 理解度：所提供解决方案的清晰度和易理解性。 |'
- en: '| - Readability: How easy it is to comprehend the provided solution. |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| - 可读性：理解提供的解决方案的难易程度。 |'
- en: '![Refer to caption](img/8dbceb8bd50e5107979989a43f396d7f.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/8dbceb8bd50e5107979989a43f396d7f.png)'
- en: 'Figure 6: Quantifier Robustness on criteria of Math Problem Solving problem.
    Each bar represent the average performance of success (dark blue "//") and failed
    (light blue “\\”) cases and 95% interval on each set is shaded across the average
    point. The two plots are overlaid.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：数学问题解决问题标准的量化稳健性。每个条形图表示成功（深蓝色“//”）和失败（浅蓝色“\\”）情况的平均表现，每组的 95% 区间在平均点上进行了阴影处理。两个图形被叠加显示。
- en: In order to consolidate similar criteria, we draw inspiration from previous
    work Liu et al. ([2022](#bib.bib31)); Vahtola et al. ([2022](#bib.bib41)); Reimers
    and Gurevych ([2019](#bib.bib34)) which demonstrated that utilizing pre-trained
    language models fine-tuned for paraphrasing and semantic similarity can yield
    high performance in numerous downstream NLP tasks. Additionally, we employ a fine-tuned
    pre-trained language model specifically designed for paraphrasing, known as the
    Hugging Face Paraphrase MiniLM ⁴⁴4[https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 为了整合相似标准，我们借鉴了Liu等人（[2022](#bib.bib31)）、Vahtola等人（[2022](#bib.bib41)）和Reimers与Gurevych（[2019](#bib.bib34)）的研究，他们表明利用为同义词替换和语义相似性微调的预训练语言模型在众多下游NLP任务中表现良好。此外，我们使用了专门为同义词替换设计的微调预训练语言模型，即Hugging
    Face Paraphrase MiniLM ⁴⁴4[https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2)。
- en: Our approach begins by encoding each criterion’s title and its description,
    followed by measuring pairwise similarity between all available criteria within
    our experiments. Subsequently, by employing a specified threshold value denoted
    as $\tau$, we classify pairs with higher cosine similarity between the embedded
    representations of each criterion pair as one and select one of them as the representative
    for that pair. This strategy is commonly employed in various NLP downstream tasks.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的方法开始于对每个标准的标题和描述进行编码，然后测量我们实验中所有可用标准之间的成对相似性。随后，通过使用指定的阈值$\tau$，我们将嵌入表示中每对标准之间的余弦相似度较高的对分类为一，并选择其中一个作为该对的代表。这种策略通常应用于各种NLP下游任务中。
- en: 'In Fig. [5](#S6.F5 "Figure 5 ‣ 6 AgentEval Robustness Analysis and In-depth
    Discussion ‣ Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered
    Applications"), we illustrate the outcomes of the number of unique extracted criteria
    using different threshold values, namely 0.7, 0.85, and 1\. A threshold of 1 implies
    that no criteria are filtered out.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '在图[5](#S6.F5 "Figure 5 ‣ 6 AgentEval Robustness Analysis and In-depth Discussion
    ‣ Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered
    Applications")中，我们展示了使用不同阈值（0.7、0.85和1）提取到的唯一标准数量的结果。阈值为1意味着没有标准被筛选掉。'
- en: Summary
  id: totrans-129
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 总结
- en: In this section, we delved into various inputs and methods for extracting criteria.
    Our exploration compared the outcomes of task-based criteria, derived solely from
    task descriptions, with those of solution-based criteria, where the *CriticAgent*
    is exposed to both examples of solutions and the task description. We observed
    that solution-based methods produce a greater diversity of criteria compared to
    task-based methods. Furthermore, the diversity in the unique number of criteria
    varied even within solution-based methods, influenced by the model’s level of
    creativity. Additionally, we noticed a tendency for certain criteria to recur
    when running the *CriticAgent* multiple times. To address this, we suggest implementing
    consolidation techniques, such as merging synonymous terms, to eliminate redundant
    criteria."
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们*深入探讨*了用于提取标准的各种输入和方法。我们的探索比较了仅从任务描述中得出的基于任务的标准与基于解决方案的标准的结果，其中*CriticAgent*同时接触到解决方案示例和任务描述。我们观察到，基于解决方案的方法产生的标准多样性大于基于任务的方法。此外，即使在基于解决方案的方法中，唯一标准的多样性也有所不同，受到模型创造力水平的影响。此外，我们注意到某些标准在运行*CriticAgent*时可能会重复出现。为解决这一问题，我们建议实施整合技术，例如合并同义词，以消除冗余标准。
- en: 6.2 Quantifier Agent Robustness
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 量化器代理的稳健性
- en: General Hypothesis
  id: totrans-132
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 一般假设
- en: Here, we aim to investigate the robustness of the *QuantifierAgent* when applied
    repeatedly to the same set of criteria. Our goal is to assess the consistency
    of the results when quantifying the same set of criteria multiple times. This
    is of utmost importance as we expect the behavior of the quantifier to be stable
    and relatively free from noise when provided with a single sample and a fixed
    set of criteria. This stability is crucial for us to have confidence in the results.
    Additionally, this analysis can help us identify and filter out criteria that
    may not be sufficiently stable for reliable use.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们旨在调查*QuantifierAgent*在重复应用于相同标准集时的稳健性。我们的目标是评估在对相同标准集进行多次量化时结果的一致性。这一点至关重要，因为我们期望量化器在提供单一样本和固定标准集时行为稳定，且相对不受噪声影响。这种稳定性对于我们对结果的信心至关重要。此外，这一分析有助于我们识别和筛选出可能不够稳定的标准，以确保其可靠使用。
- en: 'To achieve this, we selected a specific subset of criteria related to mathematical
    problems, as detailed in Table [1](#S4.T1 "Table 1 ‣ 4 Datasets and Solutions
    ‣ Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered
    Applications"), and conducted 50 runs of the quantifier agent on the 120 problems
    described in Section [4.1](#S4.SS1 "4.1 MATH Problem Solving ‣ 4 Datasets and
    Solutions ‣ Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered
    Applications"). Our expectation is to observe consistent quantified performance
    for each of the criteria. In Fig.  [6](#S6.F6 "Figure 6 ‣ General Hypothesis ‣
    6.1 Task-based vs Solution-based criteria ‣ 6 AgentEval Robustness Analysis and
    In-depth Discussion ‣ Towards better Human-Agent Alignment: Assessing Task Utility
    in LLM-Powered Applications"), we present the distribution of quantified performance
    across 50 runs for both successful and failed cases, focusing on the five selected
    criteria. A consistently horizontal performance trend indicates greater robustness
    in the quantifier, whereas more fluctuations in the figure suggest less robustness
    and a noisier performance of the agent.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '为此，我们选择了与数学问题相关的特定标准子集，如表 [1](#S4.T1 "Table 1 ‣ 4 Datasets and Solutions ‣
    Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications")
    所详细说明，并对第 [4.1](#S4.SS1 "4.1 MATH Problem Solving ‣ 4 Datasets and Solutions ‣
    Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications")
    节中描述的 120 个问题进行了 50 次量化器代理运行。我们的期望是观察到每个标准的一致量化表现。在图 [6](#S6.F6 "Figure 6 ‣ General
    Hypothesis ‣ 6.1 Task-based vs Solution-based criteria ‣ 6 AgentEval Robustness
    Analysis and In-depth Discussion ‣ Towards better Human-Agent Alignment: Assessing
    Task Utility in LLM-Powered Applications") 中，我们展示了成功和失败案例在 50 次运行中的量化表现分布，重点关注五个选定标准。稳定的水平表现趋势表明量化器的稳健性较强，而图中的更多波动则表明稳健性较差，代理的表现更加噪声化。'
- en: As shown in the results, for four out of the five generated criteria, we consistently
    observe steady performance. Not only do the success cases consistently outperform
    the failed cases, but their performance also falls within a similar range across
    runs. However, when it comes to the “error analysis” criterion, we observe a more
    variable performance of the quantifier. It does not consistently predict one group
    (success or failed) to perform better than the other, and the quantifier’s performance
    varies across different runs. This suggests that the AgentEval tool may not exhibit
    promising robustness for this particular criterion. The underlying issues could
    be either the criterion itself lacks clarity and appropriateness for the task,
    or the *QuantifierAgent* struggles to quantify this criterion effectively. In
    either case, it is advisable to either modify or eliminate this criterion to enhance
    trustworthiness and reliability.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 如结果所示，对于五个生成标准中的四个，我们一致观察到稳定的表现。不仅成功的案例始终优于失败的案例，而且它们的表现也在各次运行中保持在类似范围内。然而，在“错误分析”标准上，我们观察到量化器的表现更加变化。量化器并未始终预测一个组（成功或失败）表现优于另一个组，并且量化器的表现随不同运行而变化。这表明，AgentEval
    工具在这个特定标准下可能不具备令人满意的稳健性。潜在的问题可能是标准本身缺乏明确性和适用性，或者*QuantifierAgent*在有效量化这一标准方面存在困难。在任何情况下，都建议修改或删除这一标准以提高可信度和可靠性。
- en: 'Furthermore, we present the distribution of quantified values in Fig. [7](#S6.F7
    "Figure 7 ‣ General Hypothesis ‣ 6.2 Quantifier Agent Robustness ‣ 6 AgentEval
    Robustness Analysis and In-depth Discussion ‣ Towards better Human-Agent Alignment:
    Assessing Task Utility in LLM-Powered Applications") using box plots, illustrating
    the distribution of quantifier values for both failed (dark blue) and successful
    cases (light blue) across all criteria. The box plots display the first and third
    quartiles of the distribution as well as the median. In this figure, robust criteria
    should exhibit a narrower range of quantifier performance (narrower box plots),
    and it should be easy to distinguish between the dark and light box plots for
    each criterion.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '此外，我们在图[7](#S6.F7 "Figure 7 ‣ General Hypothesis ‣ 6.2 Quantifier Agent Robustness
    ‣ 6 AgentEval Robustness Analysis and In-depth Discussion ‣ Towards better Human-Agent
    Alignment: Assessing Task Utility in LLM-Powered Applications")中展示了量化值的分布，使用箱形图展示了所有标准中失败（深蓝色）和成功案例（浅蓝色）的量词值分布。箱形图显示了分布的第一和第三四分位数以及中位数。在该图中，稳健的标准应表现出较窄的量词性能范围（箱形图更窄），并且应能轻松区分每个标准的深色和浅色箱形图。'
- en: Consistently with our previous observations, all four criteria, except “error
    analysis” allow for easy differentiation between successful and failed cases.
    Additionally, some criteria prove to be more robust compared to others. For example,
    accuracy displays a narrower range of distribution, while clarity in failed cases
    covers a wider range. We believe that such an analysis of the quantifier agent’s
    performance will yield valuable insights for enhancing reliability, trustworthiness,
    and explainability in performance evaluation.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们之前的观察一致，所有四个标准中，除了“错误分析”之外，其他标准都能够轻松区分成功与失败的案例。此外，一些标准比其他标准更为稳健。例如，准确性显示出较窄的分布范围，而失败案例中的清晰度涵盖了更广泛的范围。我们相信，这种对量词代理性能的分析将为提高性能评估中的可靠性、可信度和可解释性提供宝贵的见解。
- en: '![Refer to caption](img/ca5bd3aaa9c0fbcf88505b0a053484c9.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ca5bd3aaa9c0fbcf88505b0a053484c9.png)'
- en: 'Figure 7: Quantifier Robustness - Distribution of QuantifierAgent output on
    AutoGen results on 120 Math problems on Success (dark blue) and Failed (light
    blue) cases on terms of different criteria. The distributions demonstrates the
    same results as in Fig [6](#S6.F6 "Figure 6 ‣ General Hypothesis ‣ 6.1 Task-based
    vs Solution-based criteria ‣ 6 AgentEval Robustness Analysis and In-depth Discussion
    ‣ Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered
    Applications").'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '图 7：量词稳健性 - 在120个数学问题上对AutoGen结果进行的量词代理输出的分布，按照不同标准的成功（深蓝色）和失败（浅蓝色）案例进行展示。该分布与图[6](#S6.F6
    "Figure 6 ‣ General Hypothesis ‣ 6.1 Task-based vs Solution-based criteria ‣ 6
    AgentEval Robustness Analysis and In-depth Discussion ‣ Towards better Human-Agent
    Alignment: Assessing Task Utility in LLM-Powered Applications")中的结果相同。'
- en: Summary
  id: totrans-140
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 摘要
- en: We recognize the importance of thoroughly investigating the robustness of each
    criterion in quantification studies. This analysis is crucial as it sheds light
    on the stability of each criterion. Moreover, when ground truths are available,
    such as in cases of success versus failure, they provide a benchmark to validate
    our assessments. Additionally, it’s important to acknowledge that not all criteria
    exhibit the same level of robustness. This variability demands careful consideration
    during evaluations, especially given the non-deterministic nature of LLMs. Such
    awareness is essential to ensure the reliability and accuracy of our assessments
    in the dynamic field of LLMs.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们认识到在量化研究中彻底调查每个标准的稳健性的重要性。这一分析至关重要，因为它揭示了每个标准的稳定性。此外，当有真实数据可用时，例如成功与失败的案例，它们提供了验证我们评估的基准。此外，必须承认，并非所有标准都表现出相同程度的稳健性。这种变异性在评估过程中需要仔细考虑，特别是考虑到LLMs的非确定性特征。这种意识对于确保在LLMs动态领域中评估的可靠性和准确性至关重要。
- en: 6.3 *QuantifierAgent* Verification
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3 *量词代理* 验证
- en: To assess the accuracy of quantifying each criterion, it is essential to verify
    the quantification process. Ideally, we would like to validate this process by
    comparing it with known pairwise samples, where we have definitive knowledge that
    for a given criterion $C$. The correct quantification should align with this knowledge.
    However, as the use of LLM-powered applications continues to expand daily, obtaining
    annotated data for many tasks is often impractical, if not impossible. Therefore,
    we propose employing synthetically altered versions of the samples to obtain the
    knowledge required for this verification.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估每个标准的量化准确性，验证量化过程至关重要。理想情况下，我们希望通过与已知的成对样本进行比较来验证这一过程，其中我们对给定标准$C$有明确的知识。正确的量化应与这些知识保持一致。然而，由于LLM驱动的应用程序的使用不断扩展，获取许多任务的注释数据通常是不可行的，甚至是不可能的。因此，我们建议使用合成修改版本的样本来获得进行这种验证所需的知识。
- en: Let us assume that we have an alternative disturbed version of sample $A$, we
    anticipate that the criteria that assess sample quality will assign higher values
    to the original sample compared to the noisier variant in the same case. To carry
    out this validation, we conducted experiments involving mathematical problems.
    We introduce random noise into the solutions by removing a certain percentage
    of the solution sentences from Autogen’s results for the math problem solving
    dataset. For criteria such as “completeness” or “clarity”, we expect to observe
    greater completeness or clarity in the original solution as opposed to the one
    missing a portion of the solution.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个替代的扰动版本样本$A$，我们预期评估样本质量的标准会给原始样本分配比噪声较大的变体更高的值。为了进行这种验证，我们进行了涉及数学问题的实验。我们通过从Autogen的数学问题解决数据集中删除一定比例的解决方案句子来引入随机噪声。对于“完整性”或“清晰度”等标准，我们期望观察到原始解决方案比缺少部分解决方案的方案具有更高的完整性或清晰度。
- en: 'In our study, our goal is to assess the *QuantifierAgent’s* ability to capture
    these distinctions between a known better solution and a worse one. We generated
    disturbed versions of solutions by randomly removing 25% of the sentences and
    running the quantifier over the noisy solutions. The results of these experiments
    are presented in Fig. [8](#S6.F8 "Figure 8 ‣ 6.3 QuantifierAgent Verification
    ‣ 6 AgentEval Robustness Analysis and In-depth Discussion ‣ Towards better Human-Agent
    Alignment: Assessing Task Utility in LLM-Powered Applications"). As depicted in
    this figure, the criteria that captures the quality of the solutions such as “clarity”
    and “completeness” of the disturbed solutions decreased compared to the original
    ones. This observation helps establish confidence in the performance of *QuantifierAgent*.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的研究中，我们的目标是评估*QuantifierAgent*捕捉已知更好解决方案与较差解决方案之间差异的能力。我们通过随机移除25%的句子生成了扰动版本的解决方案，并在噪声解决方案上运行了量化器。这些实验的结果见图[8](#S6.F8
    "图 8 ‣ 6.3 QuantifierAgent 验证 ‣ 6 AgentEval 鲁棒性分析和深入讨论 ‣ 朝着更好的人工智能对齐：评估LLM驱动应用中的任务效用")。如图所示，捕捉解决方案质量的标准，例如扰动解决方案的“清晰度”和“完整性”，与原始解决方案相比有所下降。这一观察结果有助于建立对*QuantifierAgent*性能的信心。
- en: '![Refer to caption](img/1201dcfadff13e9233ebaf7d58082bca.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/1201dcfadff13e9233ebaf7d58082bca.png)'
- en: 'Figure 8: Quantifier Verification on original set of solutions as well as the
    disturbed solutions on Math Problem Solving dataset.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：在数学问题解决数据集中对原始解决方案及其扰动解决方案的量化验证。
- en: 7 Conclusions and Future Work
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 结论与未来工作
- en: The rapid development of open-source libraries aiming to simplify the creation
    of Language Model Models (LLM)-powered agentic solutions for various user-centric
    tasks has facilitated the rapid growth of such applications. However, meeting
    end-users’ expectations and requirements for these applications is paramount,
    underscoring the importance of assessing the utility they provide. Directly evaluating
    agentic systems presents challenges, as current approaches often rely on end-to-end
    success metrics alone. However, understanding user interaction with an application
    entails more than just task success. Given the diverse range of tasks requiring
    automation, a scalable and flexible methodology is essential for evaluating these
    applications effectively.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 旨在简化各种以用户为中心任务的语言模型（LLM）驱动解决方案创建的开源库的快速发展促进了此类应用程序的迅猛增长。然而，满足终端用户对这些应用程序的期望和要求至关重要，这突显了评估它们所提供效用的重要性。直接评估智能系统存在挑战，因为目前的方法往往仅依赖于端到端的成功指标。然而，理解用户与应用程序的互动不仅仅涉及任务的成功。考虑到需要自动化的任务范围广泛，一个可扩展且灵活的方法对于有效评估这些应用程序至关重要。
- en: 'In this work, we introduce the AgentEval framework, designed to swiftly gauge
    the utility of LLM-powered agentic applications for end-users. AgentEval aims
    to assess the alignment between application behavior and user goals, providing
    developers with insights into areas for improvement. The framework leverages recent
    findings suggesting LLMs as a scalable and cost-effective alternative to human
    evaluations for open-ended tasks. AgentEval consists of two agents: *CriticAgent*
    suggests criteria based on task descriptions and suggested solutions, while *QuantifierAgent*
    verifies how well the solutions align with these criteria. This framework is customizable,
    adaptable, and can operate in various modes, employing combinations of LLMs, human
    inputs, and tools. We believe that AgentEval’s utility extends beyond immediate
    performance verification. It can uncover new system capabilities over time and
    adapt to changes in user needs or developer requirements.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们介绍了 AgentEval 框架，旨在迅速衡量 LLM 驱动的智能应用程序对终端用户的效用。AgentEval 旨在评估应用程序行为与用户目标之间的一致性，为开发者提供改进的见解。该框架利用了近期研究结果，表明
    LLM 作为人类评估开放性任务的可扩展且成本效益高的替代方案。AgentEval 由两个代理组成：*CriticAgent* 根据任务描述和建议的解决方案提出标准，而
    *QuantifierAgent* 验证解决方案与这些标准的一致性。该框架具有可定制、适应性强的特点，并可以在各种模式下运行，结合 LLM、人类输入和工具。我们相信，AgentEval
    的效用超越了即时性能验证。它可以随着时间的推移揭示系统的新能力，并适应用户需求或开发者要求的变化。
- en: In summary, our contributions include defining task utility, introducing the
    AgentEval framework, and conducting a robust analysis of its performance across
    various datasets and solutions. AgentEval represents a significant step towards
    evaluating and optimizing LLM-powered applications to better serve end-users.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们的贡献包括定义任务效用、引入 AgentEval 框架，并对其在各种数据集和解决方案中的表现进行了深入分析。AgentEval 代表了评估和优化
    LLM 驱动应用程序以更好地服务终端用户的重要一步。
- en: Glossary
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 术语表
- en: References
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Ahmadvand et al. (2022) Ali Ahmadvand, Negar Arabzadeh, Julia Kiseleva, Patricio Figueroa
    Sanz, Xin Deng, Sujay Jauhar, Michael Gamon, Eugene Agichtein, Ned Friend, et al.
    2022. Supporting complex information-seeking tasks with implicit constraints.
    *arXiv preprint arXiv:2205.00584*.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ahmadvand 等 (2022) Ali Ahmadvand、Negar Arabzadeh、Julia Kiseleva、Patricio Figueroa
    Sanz、Xin Deng、Sujay Jauhar、Michael Gamon、Eugene Agichtein、Ned Friend 等。2022。支持带有隐性约束的复杂信息搜索任务。*arXiv
    预印本 arXiv:2205.00584*。
- en: 'Azzopardi et al. (2018) Leif Azzopardi, Paul Thomas, and Nick Craswell. 2018.
    Measuring the utility of search engine result pages: an information foraging based
    measure. In *The 41st International ACM SIGIR conference on research & development
    in information retrieval*, pages 605–614.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azzopardi 等 (2018) Leif Azzopardi、Paul Thomas 和 Nick Craswell。2018。测量搜索引擎结果页面的效用：一种基于信息觅食的度量。在
    *第41届国际 ACM SIGIR 信息检索研究与发展会议*，第 605–614 页。
- en: Bang et al. (2023) Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai,
    Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, Quyet V.
    Do, Yan Xu, and Pascale Fung. 2023. [A multitask, multilingual, multimodal evaluation
    of chatgpt on reasoning, hallucination, and interactivity](http://arxiv.org/abs/2302.04023).
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bang 等 (2023) 叶锦邦、Samuel Cahyawijaya、Nayeon Lee、Wenliang Dai、Dan Su、Bryan Wilie、Holy
    Lovenia、Ziwei Ji、Tiezheng Yu、Willy Chung、Quyet V. Do、Yan Xu 和 Pascale Fung。2023。[对
    ChatGPT 在推理、幻觉和互动方面的多任务、多语言、多模态评估](http://arxiv.org/abs/2302.04023)。
- en: Bano et al. (2023) Muneera Bano, Didar Zowghi, and Jon Whittle. 2023. Exploring
    qualitative research using llms. *arXiv preprint arXiv:2306.13298*.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bano等人 (2023) Muneera Bano, Didar Zowghi, 和 Jon Whittle. 2023. 使用大型语言模型进行定性研究探讨。*arXiv预印本
    arXiv:2306.13298*。
- en: 'Bian et al. (2023) Ning Bian, Xianpei Han, Le Sun, Hongyu Lin, Yaojie Lu, and
    Ben He. 2023. Chatgpt is a knowledgeable but inexperienced solver: An investigation
    of commonsense problem in large language models. *arXiv preprint arXiv:2303.16421*.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bian等人 (2023) Ning Bian, Xianpei Han, Le Sun, Hongyu Lin, Yaojie Lu, 和 Ben He.
    2023. Chatgpt是一个知识丰富但经验不足的解题者：对大型语言模型常识性问题的调查。*arXiv预印本 arXiv:2303.16421*。
- en: Chang et al. (2023) Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang,
    Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, et al. 2023. A
    survey on evaluation of large language models. *ACM Transactions on Intelligent
    Systems and Technology*.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chang等人 (2023) Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie
    Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, 等. 2023. 大型语言模型评估调查。*ACM智能系统与技术期刊*。
- en: Chiang and Lee (2023) Cheng-Han Chiang and Hung-yi Lee. 2023. Can large language
    models be an alternative to human evaluations? *arXiv preprint arXiv:2305.01937*.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chiang和Lee (2023) Cheng-Han Chiang 和 Hung-yi Lee. 2023. 大型语言模型能否成为人类评估的替代方案？*arXiv预印本
    arXiv:2305.01937*。
- en: 'Côté et al. (2019) Marc-Alexandre Côté, Akos Kádár, Xingdi Yuan, Ben Kybartas,
    Tavian Barnes, Emery Fine, James Moore, Matthew Hausknecht, Layla El Asri, Mahmoud
    Adada, et al. 2019. Textworld: A learning environment for text-based games. In
    *Computer Games: 7th Workshop, CGW 2018, Held in Conjunction with the 27th International
    Conference on Artificial Intelligence, IJCAI 2018, Stockholm, Sweden, July 13,
    2018, Revised Selected Papers 7*, pages 41–75\. Springer.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Côté等人 (2019) Marc-Alexandre Côté, Akos Kádár, Xingdi Yuan, Ben Kybartas, Tavian
    Barnes, Emery Fine, James Moore, Matthew Hausknecht, Layla El Asri, Mahmoud Adada,
    等. 2019. Textworld: 一种用于文本游戏的学习环境。见于*计算机游戏：第七届研讨会，CGW 2018，与第27届人工智能国际会议（IJCAI
    2018）联合举办，2018年7月13日，斯德哥尔摩，瑞典，修订选择论文集7*，第41–75页。施普林格。'
- en: Dibia et al. (2023) Victor Dibia, Adam Fourney, Gagan Bansal, Forough Poursabzi-Sangdeh,
    Han Liu, and Saleema Amershi. 2023. [Aligning offline metrics and human judgments
    of value for code generation models](http://arxiv.org/abs/2210.16494).
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dibia等人 (2023) Victor Dibia, Adam Fourney, Gagan Bansal, Forough Poursabzi-Sangdeh,
    Han Liu, 和 Saleema Amershi. 2023. [将离线指标与代码生成模型的价值判断对齐](http://arxiv.org/abs/2210.16494)。
- en: 'Fu et al. (2023) Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, and Pengfei Liu.
    2023. Gptscore: Evaluate as you desire. *arXiv preprint arXiv:2302.04166*.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Fu等人 (2023) Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, 和 Pengfei Liu. 2023. Gptscore:
    依你所愿的评估。*arXiv预印本 arXiv:2302.04166*。'
- en: 'Guo et al. (2023) Zishan Guo, Renren Jin, Chuang Liu, Yufei Huang, Dan Shi,
    Linhao Yu, Yan Liu, Jiaxuan Li, Bojian Xiong, Deyi Xiong, et al. 2023. Evaluating
    large language models: A comprehensive survey. *arXiv preprint arXiv:2310.19736*.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo等人 (2023) Zishan Guo, Renren Jin, Chuang Liu, Yufei Huang, Dan Shi, Linhao
    Yu, Yan Liu, Jiaxuan Li, Bojian Xiong, Deyi Xiong, 等. 2023. 大型语言模型评估：综合调查。*arXiv预印本
    arXiv:2310.19736*。
- en: Hendrycks et al. (2021a) Dan Hendrycks, Collin Burns, Steven Basart, Andrew
    Critch, Jerry Li, Dawn Song, and Jacob Steinhardt. 2021a. Aligning ai with shared
    human values. *Proceedings of the International Conference on Learning Representations
    (ICLR)*.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hendrycks等人 (2021a) Dan Hendrycks, Collin Burns, Steven Basart, Andrew Critch,
    Jerry Li, Dawn Song, 和 Jacob Steinhardt. 2021a. 使人工智能与共享的人类价值观一致。*国际学习表征会议（ICLR）会议论文集*。
- en: Hendrycks et al. (2021b) Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul
    Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. 2021b. Measuring
    mathematical problem solving with the math dataset. *arXiv preprint arXiv:2103.03874*.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hendrycks等人 (2021b) Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora,
    Steven Basart, Eric Tang, Dawn Song, 和 Jacob Steinhardt. 2021b. 使用数学数据集测量数学问题解决能力。*arXiv预印本
    arXiv:2103.03874*。
- en: 'Hong et al. (2023) Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin
    Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, et al.
    2023. Metagpt: Meta programming for multi-agent collaborative framework. *arXiv
    preprint arXiv:2308.00352*.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hong等人 (2023) Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin
    Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, 等.
    2023. Metagpt: 面向多智能体协作框架的元编程。*arXiv预印本 arXiv:2308.00352*。'
- en: Jain et al. (2023) Sameer Jain, Vaishakh Keshava, Swarnashree Mysore Sathyendra,
    Patrick Fernandes, Pengfei Liu, Graham Neubig, and Chunting Zhou. 2023. Multi-dimensional
    evaluation of text summarization with in-context learning. *arXiv preprint arXiv:2306.01200*.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jain等人 (2023) Sameer Jain, Vaishakh Keshava, Swarnashree Mysore Sathyendra,
    Patrick Fernandes, Pengfei Liu, Graham Neubig, 和 Chunting Zhou. 2023. 使用上下文学习的文本摘要多维评估。*arXiv预印本
    arXiv:2306.01200*。
- en: 'Jin et al. (2019) Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William W Cohen,
    and Xinghua Lu. 2019. Pubmedqa: A dataset for biomedical research question answering.
    *arXiv preprint arXiv:1909.06146*.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jin 等 (2019) Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William W Cohen, 和 Xinghua
    Lu. 2019. Pubmedqa: 一个用于生物医学研究问题回答的数据集。*arXiv 预印本 arXiv:1909.06146*。'
- en: Kiseleva et al. (2014) Julia Kiseleva, Eric Crestan, Riccardo Brigo, and Roland
    Dittel. 2014. Modelling and detecting changes in user satisfaction. In *Proceedings
    of the 23rd ACM International Conference on Conference on Information and Knowledge
    Management*, pages 1449–1458.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kiseleva 等 (2014) Julia Kiseleva, Eric Crestan, Riccardo Brigo, 和 Roland Dittel.
    2014. 建模和检测用户满意度的变化。见 *第 23 届 ACM 国际信息和知识管理会议论文集*，第 1449–1458 页。
- en: Kiseleva and de Rijke (2017) Julia Kiseleva and Maarten de Rijke. 2017. Evaluating
    personal assistants on mobile devices. *arXiv preprint arXiv:1706.04524*.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kiseleva 和 de Rijke (2017) Julia Kiseleva 和 Maarten de Rijke. 2017. 在移动设备上评估个人助手。*arXiv
    预印本 arXiv:1706.04524*。
- en: 'Kiseleva et al. (2022a) Julia Kiseleva, Ziming Li, Mohammad Aliannejadi, Shrestha
    Mohanty, Maartje ter Hoeve, Mikhail Burtsev, Alexey Skrynnik, Artem Zholus, Aleksandr
    Panov, Kavya Srinet, Arthur Szlam, Yuxuan Sun, Katja Hofmann, Marc-Alexandre Côté,
    Ahmed Awadallah, Linar Abdrazakov, Igor Churin, Putra Manggala, Kata Naszadi,
    Michiel van der Meer, and Taewoon Kim. 2022a. [Interactive grounded language understanding
    in a collaborative environment: Iglu 2021](https://proceedings.mlr.press/v176/kiseleva22a.html).
    In *Proceedings of the NeurIPS 2021 Competitions and Demonstrations Track*, volume
    176 of *Proceedings of Machine Learning Research*, pages 146–161\. PMLR.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kiseleva 等 (2022a) Julia Kiseleva, Ziming Li, Mohammad Aliannejadi, Shrestha
    Mohanty, Maartje ter Hoeve, Mikhail Burtsev, Alexey Skrynnik, Artem Zholus, Aleksandr
    Panov, Kavya Srinet, Arthur Szlam, Yuxuan Sun, Katja Hofmann, Marc-Alexandre Côté,
    Ahmed Awadallah, Linar Abdrazakov, Igor Churin, Putra Manggala, Kata Naszadi,
    Michiel van der Meer, 和 Taewoon Kim. 2022a. [协作环境中的互动性基础语言理解: Iglu 2021](https://proceedings.mlr.press/v176/kiseleva22a.html)。见
    *NeurIPS 2021 竞赛和演示跟踪会议论文集*，第 176 卷，*机器学习研究论文集*，第 146–161 页。PMLR。'
- en: 'Kiseleva et al. (2022b) Julia Kiseleva, Alexey Skrynnik, Artem Zholus, Shrestha
    Mohanty, Negar Arabzadeh, Marc-Alexandre Côté, Mohammad Aliannejadi, Milagro Teruel,
    Ziming Li, Mikhail Burtsev, Maartje ter Hoeve, Zoya Volovikova, Aleksandr Panov,
    Yuxuan Sun, Kavya Srinet, Arthur Szlam, Ahmed Awadallah, Seungeun Rho, Taehwan
    Kwon, Daniel Wontae Nam, Felipe Bivort Haiek, Edwin Zhang, Linar Abdrazakov, Guo
    Qingyam, Jason Zhang, and Zhibin Guo. 2022b. [Interactive grounded language understanding
    in a collaborative environment: Retrospective on iglu 2022 competition](https://proceedings.mlr.press/v220/kiseleva22a.html).
    In *Proceedings of the NeurIPS 2022 Competitions Track*, volume 220 of *Proceedings
    of Machine Learning Research*, pages 204–216\. PMLR.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kiseleva 等 (2022b) Julia Kiseleva, Alexey Skrynnik, Artem Zholus, Shrestha
    Mohanty, Negar Arabzadeh, Marc-Alexandre Côté, Mohammad Aliannejadi, Milagro Teruel,
    Ziming Li, Mikhail Burtsev, Maartje ter Hoeve, Zoya Volovikova, Aleksandr Panov,
    Yuxuan Sun, Kavya Srinet, Arthur Szlam, Ahmed Awadallah, Seungeun Rho, Taehwan
    Kwon, Daniel Wontae Nam, Felipe Bivort Haiek, Edwin Zhang, Linar Abdrazakov, Guo
    Qingyam, Jason Zhang, 和 Zhibin Guo. 2022b. [协作环境中的互动性基础语言理解: 对 iglu 2022 竞赛的回顾](https://proceedings.mlr.press/v220/kiseleva22a.html)。见
    *NeurIPS 2022 竞赛跟踪会议论文集*，第 220 卷，*机器学习研究论文集*，第 204–216 页。PMLR。'
- en: Kiseleva et al. (2016a) Julia Kiseleva, Kyle Williams, Ahmed Hassan Awadallah,
    Aidan C Crook, Imed Zitouni, and Tasos Anastasakos. 2016a. Predicting user satisfaction
    with intelligent assistants. In *Proceedings of the 39th International ACM SIGIR
    conference on Research and Development in Information Retrieval*, pages 45–54.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kiseleva 等 (2016a) Julia Kiseleva, Kyle Williams, Ahmed Hassan Awadallah, Aidan
    C Crook, Imed Zitouni, 和 Tasos Anastasakos. 2016a. 预测用户对智能助手的满意度。见 *第 39 届国际 ACM
    SIGIR 信息检索研究与开发会议论文集*，第 45–54 页。
- en: Kiseleva et al. (2016b) Julia Kiseleva, Kyle Williams, Jiepu Jiang, Ahmed Hassan Awadallah,
    Aidan C Crook, Imed Zitouni, and Tasos Anastasakos. 2016b. Understanding user
    satisfaction with intelligent assistants. In *Proceedings of the 2016 ACM on Conference
    on Human Information Interaction and Retrieval*, pages 121–130.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kiseleva 等 (2016b) Julia Kiseleva, Kyle Williams, Jiepu Jiang, Ahmed Hassan
    Awadallah, Aidan C Crook, Imed Zitouni, 和 Tasos Anastasakos. 2016b. 了解用户对智能助手的满意度。见
    *2016 年 ACM 人类信息交互与检索会议论文集*，第 121–130 页。
- en: 'Li et al. (2023a) Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii
    Khizbullin, and Bernard Ghanem. 2023a. Camel: Communicative agents for" mind"
    exploration of large scale language model society. *arXiv preprint arXiv:2303.17760*.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li 等 (2023a) Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin,
    和 Bernard Ghanem. 2023a. Camel: 用于“大规模语言模型社会”探索的交流代理。*arXiv 预印本 arXiv:2303.17760*。'
- en: 'Li et al. (2023b) Qintong Li, Leyang Cui, Lingpeng Kong, and Wei Bi. 2023b.
    Collaborative evaluation: Exploring the synergy of large language models and humans
    for open-ended generation evaluation. *arXiv preprint arXiv:2310.19740*.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. (2023b) Qintong Li, Leyang Cui, Lingpeng Kong, and Wei Bi. 2023b.
    协作评估：探索大型语言模型与人类在开放式生成评估中的协同效应。*arXiv 预印本 arXiv:2310.19740*。
- en: Li et al. (2020) Ziming Li, Julia Kiseleva, Alekh Agarwal, Maarten de Rijke,
    and Ryen W White. 2020. Optimizing interactive systems via data-driven objectives.
    *arXiv preprint arXiv:2006.12999*.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. (2020) Ziming Li, Julia Kiseleva, Alekh Agarwal, Maarten de Rijke,
    and Ryen W White. 2020. 通过数据驱动目标优化互动系统。*arXiv 预印本 arXiv:2006.12999*。
- en: 'Li et al. (2021) Ziming Li, Dookun Park, Julia Kiseleva, Young-Bum Kim, and
    Sungjin Lee. 2021. Deus: A data-driven approach to estimate user satisfaction
    in multi-turn dialogues. *arXiv preprint arXiv:2103.01287*.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li et al. (2021) Ziming Li, Dookun Park, Julia Kiseleva, Young-Bum Kim, and
    Sungjin Lee. 2021. Deus: 一种数据驱动的方法来估计多轮对话中的用户满意度。*arXiv 预印本 arXiv:2103.01287*。'
- en: Liang et al. (2023a) Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras,
    Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya
    Kumar, Benjamin Newman, Binhang Yuan, Bobby Yan, Ce Zhang, Christian Cosgrove,
    Christopher D. Manning, Christopher Ré, Diana Acosta-Navas, Drew A. Hudson, Eric
    Zelikman, Esin Durmus, Faisal Ladhak, Frieda Rong, Hongyu Ren, Huaxiu Yao, Jue
    Wang, Keshav Santhanam, Laurel Orr, Lucia Zheng, Mert Yuksekgonul, Mirac Suzgun,
    Nathan Kim, Neel Guha, Niladri Chatterji, Omar Khattab, Peter Henderson, Qian
    Huang, Ryan Chi, Sang Michael Xie, Shibani Santurkar, Surya Ganguli, Tatsunori
    Hashimoto, Thomas Icard, Tianyi Zhang, Vishrav Chaudhary, William Wang, Xuechen
    Li, Yifan Mai, Yuhui Zhang, and Yuta Koreeda. 2023a. [Holistic evaluation of language
    models](http://arxiv.org/abs/2211.09110).
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liang et al. (2023a) Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras,
    Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya
    Kumar, Benjamin Newman, Binhang Yuan, Bobby Yan, Ce Zhang, Christian Cosgrove,
    Christopher D. Manning, Christopher Ré, Diana Acosta-Navas, Drew A. Hudson, Eric
    Zelikman, Esin Durmus, Faisal Ladhak, Frieda Rong, Hongyu Ren, Huaxiu Yao, Jue
    Wang, Keshav Santhanam, Laurel Orr, Lucia Zheng, Mert Yuksekgonul, Mirac Suzgun,
    Nathan Kim, Neel Guha, Niladri Chatterji, Omar Khattab, Peter Henderson, Qian
    Huang, Ryan Chi, Sang Michael Xie, Shibani Santurkar, Surya Ganguli, Tatsunori
    Hashimoto, Thomas Icard, Tianyi Zhang, Vishrav Chaudhary, William Wang, Xuechen
    Li, Yifan Mai, Yuhui Zhang, and Yuta Koreeda. 2023a. [语言模型的整体评估](http://arxiv.org/abs/2211.09110)。
- en: Liang et al. (2023b) Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang,
    Rui Wang, Yujiu Yang, Zhaopeng Tu, and Shuming Shi. 2023b. [Encouraging divergent
    thinking in large language models through multi-agent debate](http://arxiv.org/abs/2305.19118).
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liang et al. (2023b) Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang,
    Rui Wang, Yujiu Yang, Zhaopeng Tu, and Shuming Shi. 2023b. [通过多智能体辩论鼓励大型语言模型的发散思维](http://arxiv.org/abs/2305.19118)。
- en: 'Liu and Sun (2023) Alex Liu and Min Sun. 2023. From voices to validity: Leveraging
    large language models (llms) for textual analysis of policy stakeholder interviews.
    *arXiv preprint arXiv:2312.01202*.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu and Sun (2023) Alex Liu and Min Sun. 2023. 从声音到有效性：利用大型语言模型（llms）进行政策利益相关者访谈的文本分析。*arXiv
    预印本 arXiv:2312.01202*。
- en: 'Liu et al. (2023) Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu
    Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, et al. 2023. Agentbench:
    Evaluating llms as agents. *arXiv preprint arXiv:2308.03688*.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu et al. (2023) Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu
    Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, et al. 2023. Agentbench:
    评估 llms 作为代理。*arXiv 预印本 arXiv:2308.03688*。'
- en: Liu et al. (2022) Yanchen Liu, Timo Schick, and Hinrich Schütze. 2022. Semantic-oriented
    unlabeled priming for large-scale language models. *arXiv preprint arXiv:2202.06133*.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2022) Yanchen Liu, Timo Schick, and Hinrich Schütze. 2022. 面向语义的未标记预训练用于大规模语言模型。*arXiv
    预印本 arXiv:2202.06133*。
- en: 'Mialon et al. (2023) Grégoire Mialon, Clémentine Fourrier, Craig Swift, Thomas
    Wolf, Yann LeCun, and Thomas Scialom. 2023. Gaia: a benchmark for general ai assistants.
    *arXiv preprint arXiv:2311.12983*.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Mialon et al. (2023) Grégoire Mialon, Clémentine Fourrier, Craig Swift, Thomas
    Wolf, Yann LeCun, and Thomas Scialom. 2023. Gaia: 一项用于通用人工智能助手的基准测试。*arXiv 预印本
    arXiv:2311.12983*。'
- en: 'Myers et al. (2023) Vivek Myers, Andre Wang He, Kuan Fang, Homer Rich Walke,
    Philippe Hansen-Estruch, Ching-An Cheng, Mihai Jalobeanu, Andrey Kolobov, Anca
    Dragan, and Sergey Levine. 2023. [Goal representations for instruction following:
    A semi-supervised language interface to control](https://proceedings.mlr.press/v229/myers23a.html).
    In *Proceedings of The 7th Conference on Robot Learning*, volume 229 of *Proceedings
    of Machine Learning Research*, pages 3894–3908\. PMLR.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Myers 等（2023）Vivek Myers, Andre Wang He, Kuan Fang, Homer Rich Walke, Philippe
    Hansen-Estruch, Ching-An Cheng, Mihai Jalobeanu, Andrey Kolobov, Anca Dragan,
    和 Sergey Levine. 2023. [指令跟随的目标表示：一个半监督语言接口来控制](https://proceedings.mlr.press/v229/myers23a.html)。在*第七届机器人学习会议论文集*，*机器学习研究*第229卷，第3894–3908页。PMLR。
- en: 'Reimers and Gurevych (2019) Nils Reimers and Iryna Gurevych. 2019. Sentence-bert:
    Sentence embeddings using siamese bert-networks. *arXiv preprint arXiv:1908.10084*.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Reimers 和 Gurevych（2019）Nils Reimers 和 Iryna Gurevych. 2019. Sentence-BERT：使用Siamese
    BERT网络的句子嵌入。*arXiv预印本 arXiv:1908.10084*。
- en: See et al. (2019) Abigail See, Stephen Roller, Douwe Kiela, and Jason Weston.
    2019. What makes a good conversation? how controllable attributes affect human
    judgments. *arXiv preprint arXiv:1902.08654*.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: See 等（2019）Abigail See, Stephen Roller, Douwe Kiela, 和 Jason Weston. 2019. 什么是好的对话？可控属性如何影响人类判断。*arXiv预印本
    arXiv:1902.08654*。
- en: 'Shridhar et al. (2019) Mohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan
    Bisk, Winson Han, Roozbeh Mottaghi, Luke Zettlemoyer, and Dieter Fox. 2019. [ALFRED:
    A benchmark for interpreting grounded instructions for everyday tasks](http://arxiv.org/abs/1912.01734).
    *CoRR*, abs/1912.01734.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shridhar 等（2019）Mohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk,
    Winson Han, Roozbeh Mottaghi, Luke Zettlemoyer, 和 Dieter Fox. 2019. [ALFRED：用于解释日常任务的基础指令的基准](http://arxiv.org/abs/1912.01734)。*CoRR*，abs/1912.01734。
- en: 'Shridhar et al. (2020a) Mohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan
    Bisk, Winson Han, Roozbeh Mottaghi, Luke Zettlemoyer, and Dieter Fox. 2020a. Alfred:
    A benchmark for interpreting grounded instructions for everyday tasks. In *Proceedings
    of the IEEE/CVF conference on computer vision and pattern recognition*, pages
    10740–10749.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shridhar 等（2020a）Mohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk,
    Winson Han, Roozbeh Mottaghi, Luke Zettlemoyer, 和 Dieter Fox. 2020a. Alfred：用于解释日常任务的基础指令的基准。在*IEEE/CVF计算机视觉与模式识别会议论文集*，第10740–10749页。
- en: 'Shridhar et al. (2020b) Mohit Shridhar, Xingdi Yuan, Marc-Alexandre Côté, Yonatan
    Bisk, Adam Trischler, and Matthew Hausknecht. 2020b. Alfworld: Aligning text and
    embodied environments for interactive learning. *arXiv preprint arXiv:2010.03768*.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shridhar 等（2020b）Mohit Shridhar, Xingdi Yuan, Marc-Alexandre Côté, Yonatan Bisk,
    Adam Trischler, 和 Matthew Hausknecht. 2020b. Alfworld：将文本与体现环境对齐以进行互动学习。*arXiv预印本
    arXiv:2010.03768*。
- en: 'Talebirad and Nadiri (2023) Yashar Talebirad and Amirhossein Nadiri. 2023.
    Multi-agent collaboration: Harnessing the power of intelligent llm agents. *arXiv
    preprint arXiv:2306.03314*.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Talebirad 和 Nadiri（2023）Yashar Talebirad 和 Amirhossein Nadiri. 2023. 多智能体协作：利用智能LLM代理的力量。*arXiv预印本
    arXiv:2306.03314*。
- en: Tjuatja et al. (2023) Lindia Tjuatja, Valerie Chen, Sherry Tongshuang Wu, Ameet
    Talwalkar, and Graham Neubig. 2023. Do llms exhibit human-like response biases?
    a case study in survey design. *arXiv preprint arXiv:2311.04076*.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tjuatja 等（2023）Lindia Tjuatja, Valerie Chen, Sherry Tongshuang Wu, Ameet Talwalkar,
    和 Graham Neubig. 2023. LLM是否表现出类似人类的反应偏差？调查设计中的案例研究。*arXiv预印本 arXiv:2311.04076*。
- en: 'Vahtola et al. (2022) Teemu Vahtola, Mathias Creutz, and Jörg Tiedemann. 2022.
    It is not easy to detect paraphrases: Analysing semantic similarity with antonyms
    and negation using the new semantoneg benchmark. In *Proceedings of the Fifth
    BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP*, pages
    249–262.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vahtola 等（2022）Teemu Vahtola, Mathias Creutz, 和 Jörg Tiedemann. 2022. 检测同义句并非易事：利用新的semantoneg基准分析带有反义词和否定的语义相似性。在*第五届BlackboxNLP研讨会：分析和解释NLP中的神经网络*，第249–262页。
- en: 'Wang et al. (2023) Jindong Wang, Xixu HU, Wenxin Hou, Hao Chen, Runkai Zheng,
    Yidong Wang, Linyi Yang, Wei Ye, Haojun Huang, Xiubo Geng, Binxing Jiao, Yue Zhang,
    and Xing Xie. 2023. [On the robustness of chatGPT: An adversarial and out-of-distribution
    perspective](https://openreview.net/forum?id=uw6HSkgoM29). In *ICLR 2023 Workshop
    on Trustworthy and Reliable Large-Scale Machine Learning Models*.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 王等（2023）Jindong Wang, Xixu HU, Wenxin Hou, Hao Chen, Runkai Zheng, Yidong Wang,
    Linyi Yang, Wei Ye, Haojun Huang, Xiubo Geng, Binxing Jiao, Yue Zhang, 和 Xing
    Xie. 2023. [ChatGPT的鲁棒性研究：对抗性和分布外视角](https://openreview.net/forum?id=uw6HSkgoM29)。在*ICLR
    2023可信赖和可靠的大规模机器学习模型研讨会*上。
- en: Williams et al. (2016a) Kyle Williams, Julia Kiseleva, Aidan C Crook, Imed Zitouni,
    Ahmed Hassan Awadallah, and Madian Khabsa. 2016a. Detecting good abandonment in
    mobile search. In *Proceedings of the 25th International Conference on World Wide
    Web*, pages 495–505.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Williams 等 (2016a) 凯尔·威廉姆斯、朱莉亚·基谢列瓦、艾丹·C·克鲁克、伊梅德·齐图尼、艾哈迈德·哈桑·阿瓦达拉赫 和 马迪安·卡布萨。2016a年。《在移动搜索中检测良好放弃》。在
    *第25届国际万维网会议论文集* 中，页码 495–505。
- en: Williams et al. (2016b) Kyle Williams, Julia Kiseleva, Aidan C Crook, Imed Zitouni,
    Ahmed Hassan Awadallah, and Madian Khabsa. 2016b. Is this your final answer? evaluating
    the effect of answers on good abandonment in mobile search. In *Proceedings of
    the 39th International ACM SIGIR conference on Research and Development in Information
    Retrieval*, pages 889–892.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Williams 等 (2016b) 凯尔·威廉姆斯、朱莉亚·基谢列瓦、艾丹·C·克鲁克、伊梅德·齐图尼、艾哈迈德·哈桑·阿瓦达拉赫 和 马迪安·卡布萨。2016b年。《这是你最终的答案吗？评估答案对移动搜索中良好放弃的影响》。在
    *第39届国际 ACM SIGIR 信息检索研究与发展会议论文集* 中，页码 889–892。
- en: Williams and Zitouni (2017) Kyle Williams and Imed Zitouni. 2017. Does that
    mean you’re happy? rnn-based modeling of user interaction sequences to detect
    good abandonment. In *Proceedings of the 2017 ACM on Conference on Information
    and Knowledge Management*, pages 727–736.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Williams 和 Zitouni (2017) 凯尔·威廉姆斯 和 伊梅德·齐图尼。2017年。《这意味着你很开心吗？基于 RNN 的用户互动序列建模以检测良好放弃》。在
    *2017 年 ACM 信息与知识管理大会论文集* 中，页码 727–736。
- en: Winograd (1972) Terry Winograd. 1972. Understanding natural language. *Cognitive
    psychology*, 3(1):1–191.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Winograd (1972) 特里·温诺格拉德。1972年。《理解自然语言》。*认知心理学*，3(1):1–191。
- en: 'Wu et al. (2023) Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang,
    Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. 2023. Autogen: Enabling
    next-gen llm applications via multi-agent conversation framework. *arXiv preprint
    arXiv:2308.08155*.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等 (2023) 吴青云、加根·班萨尔、张杰宇、吴怡然、张少坤、朱尔康、李北滨、李江、张晓云 和 王驰。2023年。《Autogen：通过多代理对话框架实现下一代
    LLM 应用》。*arXiv 预印本 arXiv:2308.08155*。
- en: 'Yao et al. (2022) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik Narasimhan, and Yuan Cao. 2022. React: Synergizing reasoning and acting
    in language models. *arXiv preprint arXiv:2210.03629*.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao 等 (2022) 邵昱、杰弗里·赵、缪滢、杜楠、伊扎克·沙弗兰、卡尔提克·纳拉西曼 和 袁操。2022年。《React：在语言模型中协同推理与行动》。*arXiv
    预印本 arXiv:2210.03629*。
- en: 'Zhang et al. (2023) Chi Zhang, Penglin Cai, Yuhui Fu, Haoqi Yuan, and Zongqing
    Lu. 2023. Creative agents: Empowering agents with imagination for creative tasks.
    *arXiv preprint arXiv:2312.02519*.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等 (2023) 张创、蔡鹏霖、傅宇辉、袁浩琪、陆宗庆。2023年。《创意代理：赋能代理以实现创造性任务》。*arXiv 预印本 arXiv:2312.02519*。
- en: 'Ziyu et al. (2023) Zhuang Ziyu, Chen Qiguang, Ma Longxuan, Li Mingda, Han Yi,
    Qian Yushan, Bai Haopeng, Zhang Weinan, and Ting Liu. 2023. [Through the lens
    of core competency: Survey on evaluation of large language models](https://aclanthology.org/2023.ccl-2.8).
    In *Proceedings of the 22nd Chinese National Conference on Computational Linguistics
    (Volume 2: Frontier Forum)*, pages 88–109, Harbin, China. Chinese Information
    Processing Society of China.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ziyu 等 (2023) 庄子煜、陈启光、马龙轩、李明达、韩逸、钱雨杉、白浩鹏、张伟楠、刘婷。2023年。[从核心能力的视角：大语言模型评估调查](https://aclanthology.org/2023.ccl-2.8)。在
    *第22届中国计算语言学国家会议（第2卷：前沿论坛）* 中，页码 88–109，哈尔滨，中国。中国信息处理学会。
- en: Appendix A Appendix
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 附录
- en: A.1 Task Examples
  id: totrans-205
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 任务示例
- en: 'In Figure [9](#A1.F9 "Figure 9 ‣ A.1 Task Examples ‣ Appendix A Appendix ‣
    Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications")
    and [10](#A1.F10 "Figure 10 ‣ A.1 Task Examples ‣ Appendix A Appendix ‣ Towards
    better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications"),
    we display an example of Math problems and AlfWorld Householding tasks with AutoGen’s
    solution for these problems.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '在图 [9](#A1.F9 "Figure 9 ‣ A.1 Task Examples ‣ Appendix A Appendix ‣ Towards
    better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications")
    和 [10](#A1.F10 "Figure 10 ‣ A.1 Task Examples ‣ Appendix A Appendix ‣ Towards
    better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications")
    中，我们展示了 Math 问题和 AlfWorld 家务任务的示例，以及 AutoGen 对这些问题的解决方案。'
- en: '"problem":
    "How many positive and negative integers is $12$ a multiple of?", "role": "user"
    }, { "content": "To determine how many positive and negative integers 12 is a
    multiple of, we need to find the divisors of 12\. Then we will double the number
    of divisors, as each positive divisor has a corresponding negative divisor. Let’s
    use a Python code snippet to find all the divisors of 12 and count them.", 1num  =  12
    2divisors  =  [i  for  i  in  range(1,  num  +  1)  if  num  \%  i  ==  0] 3positive_divisors_count  =  len(divisors)
    4negative_divisors_count  =  positive_divisors_count 5total_divisors_count  =  positive_divisors_count  +  negative_divisors_count
    6print(f"Positive  divisors  of  12:  {divisors}") 7divisors_negative  =  [-x  for  x  in  divisors]
    8print(f"Negative  divisors  of  12:  {divisors_negative}") 9print(f"Total  divisors  count:  {total_divisors_count}")
    Execute this code snippet to find the divisors of 12 and count how many positive
    and negative integers 12 is a multiple of. "role": "assistant" } ], "time": 17.360238790512085'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '"problem":
    "How many positive and negative integers is $12$ a multiple of?", "role": "user"
    }, { "content": "To determine how many positive and negative integers 12 is a
    multiple of, we need to find the divisors of 12\. Then we will double the number
    of divisors, as each positive divisor has a corresponding negative divisor. Let’s
    use a Python code snippet to find all the divisors of 12 and count them.", 1num  =  12
    2divisors  =  [i  for  i  in  range(1,  num  +  1)  if  num  \%  i  ==  0] 3positive_divisors_count  =  len(divisors)
    4negative_divisors_count  =  positive_divisors_count 5total_divisors_count  =  positive_divisors_count  +  negative_divisors_count
    6print(f"Positive  divisors  of  12:  {divisors}") 7divisors_negative  =  [-x  for  x  in  divisors]
    8print(f"Negative  divisors  of  12:  {divisors_negative}") 9print(f"Total  divisors  count:  {total_divisors_count}")
    Execute this code snippet to find the divisors of 12 and count how many positive
    and negative integers 12 is a multiple of. "role": "assistant" } ], "time": 17.360238790512085'
- en: 'Figure 9: An example of Math Problem solving sample with solution generated
    by AutoGen'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：一个由 AutoGen 生成解决方案的数学问题解决样本
- en: '{    { "content": "Perform actions and interact with a household to solve a task. At the beginning of your interactions, you will be given the detailed description of the current environment and your goal to accomplish. For each of your turn, you should choose from two actions: "think" or     "Action". If you choose "think", you should first think about the current condition and plan for your future actions, and then output your action in this turn. Your output must strictly follow this format:"think: your thoughts."    "Action: your next action\\n"; If you choose "ACTION", you should directly output the action in this turn. Your output must strictly follow this format:"ACTION: your next action".    After each of your turn, the environment will give you immediate feedback based on which you should plan your next few steps. if the envrionment output "Nothing happened", that means the previous action is invalid and you should try more options.    Reminder:    1. the action must be chosen from the given available actions. Any actions except provided available actions will be regarded as illegal.    2. Take the target household immediatly after you find it.    3. Reply ’TERMINATE’ only under two circumstances: a). The task has given you clear instructions to return ’TERMINATE’ b). The task seems insolvable.\\n Here are two examples.\nYou are in the middle of a room. Looking quickly around you, you see a cabinet 13, a cabinet 12, a cabinet 11, a cabinet 10, a cabinet 9, a cabinet 8, a cabinet 7, a cabinet 6, a cabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a coffeemachine 1, a countertop 1, a diningtable 1, a drawer 1, a fridge 1, a garbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin 1, a stoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster 1.\nYour task is to: put a hot apple in fridge.\n",        "role": "user"},    {   "content": "THOUGHT: The task is to put a hot apple in fridge. So i need to first find an apple and heat it. First I need to find an apple. An apple is more likely to appear in diningtable (1), coffeetable (1), fridge (1), drawer (1), cabinet (1-13), garbagecan (1). I can check one by one, starting with fridge 1.\n ACTION: go to diningtable 1\n",        "role": "assistant"},    {   "content": "On the diningtable 1, you see a apple 1, a bread 1, a fork 3, a fork 2, a fork 1, a mug 2, a peppershaker 3, a plate 2, a pot 1, a soapbottle 3, a spatula 1, a spoon 3, a spoon 2, a spoon 1, a winebottle 3, and a winebottle 2.\n",        "role": "user"},    {   "content": "ACTION: take apple 1 from diningtable 1\n",        "role": "assistant"},    {   "content": "You pick up the apple 1 from the diningtable 1.\n",        "role": "user"},    {   "content": "THOUGHT: I noticed that there is a microwave 1 in the room, i will use it to heat the apple.\n ACTION: go to microwave 1\n",        "role": "assistant"},    ...    ...    {   "content": "You open the microwave 1. The microwave 1 is open. In it, you see a egg 1.",        "role": "user"    },    {   "content": "ACTION: heat mug 2 with microwave 1",        "role": "assistant"},    {    "content": "You heat the mug 2 using the microwave 1.Task success, now reply TERMINATE\n",        "role": "user"},    {   "content": "TERMINATE",        "role": "assistant"},    {   "content": "TERMINATE",        "role": "user"}}'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '{    { "content": "执行操作并与家庭环境互动以解决任务。在互动开始时，您将获得当前环境的详细描述和要完成的目标。每回合，您应该从两个动作中选择一个：‘think’或‘Action’。如果选择‘think’，您应首先考虑当前条件并规划未来的行动，然后输出本回合的行动。您的输出必须严格按照以下格式：‘think: 您的想法。’‘Action: 您的下一个行动\\n’；如果选择‘ACTION’，您应直接输出本回合的行动。您的输出必须严格按照以下格式：‘ACTION: 您的下一个行动’。在每回合之后，环境将根据反馈给您即时反馈，您应根据反馈规划接下来的步骤。如果环境输出‘Nothing
    happened’，这意味着前一个行动无效，您应尝试更多选项。提醒：1. 行动必须从给定的可用行动中选择。任何不在可用行动范围内的行动将被视为非法。2. 发现目标家庭后立即处理。3.
    仅在以下两种情况下回复‘TERMINATE’：a). 任务明确指示您返回‘TERMINATE’ b). 任务似乎无法解决。\\n 这里有两个示例。\n您在房间的中间。快速环顾四周，您看到一个柜子13，一个柜子12，一个柜子11，一个柜子10，一个柜子9，一个柜子8，一个柜子7，一个柜子6，一个柜子5，一个柜子4，一个柜子3，一个柜子2，一个柜子1，一个咖啡机1，一个台面1，一个餐桌1，一个抽屉1，一个冰箱1，一个垃圾桶1，一个微波炉1，一个架子3，一个架子2，一个架子1，一个水槽1，一个炉子燃烧器4，一个炉子燃烧器3，一个炉子燃烧器2，一个炉子燃烧器1，以及一个烤面包机1。\n您的任务是：将一个热苹果放入冰箱。\n",        "role": "user"},    {   "content": "THOUGHT: 任务是将一个热苹果放入冰箱。所以我需要首先找到一个苹果并加热它。首先我需要找到一个苹果。苹果更可能出现在餐桌（1），咖啡桌（1），冰箱（1），抽屉（1），柜子（1-13），垃圾桶（1）。我可以一个一个检查，从冰箱1开始。\n
    ACTION: 去餐桌1\n",        "role": "assistant"},    {   "content": "在餐桌1上，您看到一个苹果1，一个面包1，三个叉子，两个杯子，三个调料瓶，两个盘子，一个锅，三个肥皂瓶，一个铲子，三个勺子，两瓶酒。\n",        "role": "user"},    {   "content": "ACTION: 从餐桌1上拿一个苹果1\n",        "role": "assistant"},    {   "content": "您从餐桌1上拿起了苹果1。\n",        "role": "user"},    {   "content": "THOUGHT: 我注意到房间里有一个微波炉1，我将用它来加热苹果。\n
    ACTION: 去微波炉1\n",        "role": "assistant"},    ...    ...    {   "content": "您打开了微波炉1。微波炉1是打开的。在里面，您看到一个鸡蛋1。",        "role": "user"    },    {   "content": "ACTION: 用微波炉1加热杯子2",        "role": "assistant"},    {    "content": "您使用微波炉1加热了杯子2。任务成功，现在回复‘TERMINATE’\n",        "role": "user"},    {   "content": "TERMINATE",        "role": "assistant"},    {   "content": "TERMINATE",        "role": "user"}'
- en: 'Figure 10: An example of AlfWorld Householding task from “Pick, Heat, then
    Place” category.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：来自“挑选、加热，然后放置”类别的 AlfWorld 家务任务示例。
