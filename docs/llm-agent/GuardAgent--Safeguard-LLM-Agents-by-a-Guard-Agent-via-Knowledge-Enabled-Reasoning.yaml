- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 18:44:49'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-09-08 18:44:49'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'GuardAgent: 通过知识驱动推理保护LLM代理的护栏代理'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.09187](https://ar5iv.labs.arxiv.org/html/2406.09187)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2406.09187](https://ar5iv.labs.arxiv.org/html/2406.09187)
- en: Zhen Xiang^(1∗)  Linzhi Zheng²  Yanjie Li³  Junyuan Hong⁴  Qinbin Li⁵  Han Xie⁶
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Zhen Xiang^(1∗)  Linzhi Zheng²  Yanjie Li³  Junyuan Hong⁴  Qinbin Li⁵  Han Xie⁶
- en: Jiawei Zhang¹  Zidi Xiong¹  Chulin Xie¹  Carl Yang⁶  Dawn Song⁵  Bo Li^(17)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Jiawei Zhang¹  Zidi Xiong¹  Chulin Xie¹  Carl Yang⁶  Dawn Song⁵  Bo Li^(17)
- en: ¹UIUC  ²Tsinghua University  ³Hong Kong Polytechnic University
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ¹UIUC  ²清华大学  ³香港理工大学
- en: ⁴UT Austin  ⁵UC Berkeley  ⁶Emory University  ⁷ University of Chicago Correspondence
    to Zhen Xiang ⟨zhen.xiang.lance@gmail.com⟩and Bo Li ⟨bol@uchicago.edu⟩.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ⁴UT Austin  ⁵UC Berkeley  ⁶Emory University  ⁷芝加哥大学 联系方式：Zhen Xiang ⟨zhen.xiang.lance@gmail.com⟩
    和 Bo Li ⟨bol@uchicago.edu⟩。
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'The rapid advancement of large language models (LLMs) has catalyzed the deployment
    of LLM-powered agents across numerous applications, raising new concerns regarding
    their safety and trustworthiness. In addition, existing methods for enhancing
    the safety of LLMs are not directly transferable to LLM-powered agents due to
    their diverse objectives and output modalities. In this paper, we propose GuardAgent,
    the first LLM agent as a guardrail to other LLM agents. Specifically, GuardAgent
    oversees a target LLM agent by checking whether its inputs/outputs satisfy a set
    of given guard requests (e.g., safety rules or privacy policies) defined by the
    users. GuardAgent comprises two steps: 1) creating a task plan by analyzing the
    provided guard requests, and 2) generating guardrail code based on the task plan
    and executing the code by calling APIs or using external engines. In both steps,
    an LLM is utilized as the core reasoning component, supplemented by in-context
    demonstrations retrieved from a memory module. Such knowledge-enabled reasoning
    allows GuardAgent to understand various textual guard requests and accurately
    “translate” them into executable code that provides reliable guardrails. Furthermore,
    GuardAgent is equipped with an extendable toolbox containing functions and APIs
    and requires no additional LLM training, which underscores its generalization
    capabilities and low operational overhead. In addition to GuardAgent , we propose
    two novel benchmarks: an EICU-AC benchmark for assessing privacy-related access
    control for healthcare agents and a Mind2Web-SC benchmark for safety evaluation
    for web agents. We show the effectiveness of GuardAgent on these two benchmarks
    with 98.7% and 90.0% guarding accuracy in moderating invalid inputs and outputs
    for the two types of agents, respectively. We also show that GuardAgent is able
    to define novel functions in adaption to emergent LLM agents and guard requests,
    which underscores its strong generalization capabilities.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）的快速进展催化了LLM驱动的代理在众多应用中的部署，提出了关于其安全性和可信性的新问题。此外，由于LLM驱动的代理目标和输出方式多样，现有的提升LLM安全性的方法不能直接转移到LLM驱动的代理上。本文提出了GuardAgent，这是第一个作为其他LLM代理护栏的LLM代理。具体来说，GuardAgent通过检查目标LLM代理的输入/输出是否满足用户定义的一组保护请求（例如安全规则或隐私政策）来进行监督。GuardAgent包括两个步骤：1)
    通过分析提供的保护请求来创建任务计划，2) 根据任务计划生成护栏代码并通过调用API或使用外部引擎执行代码。在这两个步骤中，LLM作为核心推理组件，辅以从记忆模块中检索的上下文示例。这种知识驱动的推理使GuardAgent能够理解各种文本保护请求，并准确地“翻译”成可执行代码，从而提供可靠的护栏。此外，GuardAgent配备了一个可扩展的工具箱，包含功能和API，并且不需要额外的LLM训练，这突出了其通用化能力和低操作开销。除了GuardAgent，我们还提出了两个新的基准：一个用于评估医疗代理隐私相关访问控制的EICU-AC基准和一个用于网络代理安全评估的Mind2Web-SC基准。我们展示了GuardAgent在这两个基准上的有效性，分别在调节无效输入和输出方面达到了98.7%和90.0%的护栏准确率。我们还展示了GuardAgent能够定义新功能以适应新兴的LLM代理和保护请求，这突显了其强大的通用化能力。
- en: '![Refer to caption](img/4d349704d11780c75335ac540ee875e5.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4d349704d11780c75335ac540ee875e5.png)'
- en: 'Figure 1: Illustration of GuardAgent as a guardrail to a target LLM agent.
    The inputs to GuardAgent include a) a set of guard requests informed by a specification
    of the target agent and b) the test-time inputs and outputs of the target agent.
    GuardAgent first generates an action plan following a few shots of demonstrations
    retrieved from the memory. Then, a guardrail code is generated following the action
    plan based on both demonstrations and a list of callable functions. The outputs/actions
    of the target agent will be denied if GuardAgent detects a violation of the guard
    requests.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：GuardAgent作为目标LLM代理的保护措施示意图。GuardAgent的输入包括：a) 一组根据目标代理的规格定义的保护请求，以及 b) 目标代理的测试时输入和输出。GuardAgent首先生成一个行动计划，该计划基于从记忆中检索到的几次示范。然后，生成一个保护代码，该代码根据行动计划、示范和可调用函数列表生成。如果GuardAgent检测到保护请求被违反，目标代理的输出/操作将被拒绝。
- en: 1 Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: AI agents empowered by large language models (LLMs) have showcased remarkable
    performance across diverse application domains, including finance [[24](#bib.bib24)],
    healthcare [[2](#bib.bib2), [17](#bib.bib17), [22](#bib.bib22), [18](#bib.bib18),
    [11](#bib.bib11)], daily work [[4](#bib.bib4), [5](#bib.bib5), [28](#bib.bib28),
    [27](#bib.bib27)], and autonomous driving [[3](#bib.bib3), [8](#bib.bib8), [12](#bib.bib12)].
    For each user query, these agents typically employ an LLM for task planning, leveraging
    the reasoning capability of the LLM with the optional support of long-term memory
    from previous use cases [[10](#bib.bib10)]. The proposed plan is then executed
    by calling external tools (e.g., through APIs) with potential interaction with
    the environment [[23](#bib.bib23)].
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 由大规模语言模型（LLM）赋能的人工智能代理在各种应用领域中展示了显著的性能，包括金融 [[24](#bib.bib24)]、医疗保健 [[2](#bib.bib2),
    [17](#bib.bib17), [22](#bib.bib22), [18](#bib.bib18), [11](#bib.bib11)]、日常工作 [[4](#bib.bib4),
    [5](#bib.bib5), [28](#bib.bib28), [27](#bib.bib27)]，以及自动驾驶 [[3](#bib.bib3), [8](#bib.bib8),
    [12](#bib.bib12)]。对于每一个用户查询，这些代理通常会使用LLM进行任务规划，利用LLM的推理能力，并可选择性地使用来自以往使用案例的长期记忆 [[10](#bib.bib10)]。然后，提出的计划通过调用外部工具（例如，通过API）并可能与环境交互 [[23](#bib.bib23)]。
- en: Unfortunately, the current development of LLM agents primarily focuses on their
    effectiveness in solving complex tasks while significantly overlooking their potential
    for misuse, which can lead to harmful consequences. For example, if misused by
    unauthorized personnel, a healthcare LLM agent could easily expose confidential
    patient information [[25](#bib.bib25)]. Indeed, some LLM agents, particularly
    those used in high-stakes applications like autonomous driving, are equipped with
    safety controls to prevent the execution of undesired dangerous actions [[12](#bib.bib12),
    [6](#bib.bib6)]. However, these task-specific guardrails are hardwired into the
    LLM agent and, therefore, cannot be generalized to other agents (e.g., for healthcare)
    with different guard requests (e.g., for privacy instead of safety).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，当前大规模语言模型（LLM）代理的发展主要关注其在解决复杂任务中的有效性，而显著忽视了其可能被滥用的潜力，这可能导致有害的后果。例如，如果被未经授权的人员滥用，医疗保健LLM代理可能轻易暴露机密的患者信息 [[25](#bib.bib25)]。确实，一些LLM代理，特别是那些用于高风险应用（如自动驾驶）的代理，配备了安全控制措施以防止执行不希望出现的危险操作 [[12](#bib.bib12),
    [6](#bib.bib6)]。然而，这些特定任务的保护措施是硬编码到LLM代理中的，因此不能推广到具有不同保护请求（例如，隐私而非安全）的其他代理（例如医疗保健）。
- en: On the other hand, guardrails for LLMs provide input and output moderation to
    detect and mitigate a wide range of potential harms [[13](#bib.bib13), [9](#bib.bib9),
    [16](#bib.bib16), [7](#bib.bib7), [26](#bib.bib26)]. This is typically achieved
    by building the guardrail upon another pre-trained LLM to contextually understand
    the input and output of the target LLM. More importantly, the ‘non-invasiveness’
    of guardrails, achieved through their parallel deployment alongside the target
    LLM, allows for their application to new models and harmfulness taxonomies with
    only minor modifications. However, LLM agents are significantly different from
    LLMs, as they involve a much broader range of output modalities and highly specific
    guard requests. For instance, a web agent empowered by LLM might generate actions
    like clicking a designated button on a webpage [[27](#bib.bib27)]. The guard requests
    here could involve safety rules that prohibit certain users (e.g., those under
    a certain age) from purchasing specific items (e.g., alcoholic beverages). Clearly,
    existing guardrails designed solely to moderate the textual inputs and outputs
    of LLMs cannot address such intricate guard requests.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，针对LLM的护栏提供输入和输出的管理，以检测和缓解广泛的潜在危害[[13](#bib.bib13), [9](#bib.bib9), [16](#bib.bib16),
    [7](#bib.bib7), [26](#bib.bib26)]。这通常通过在目标LLM的输入和输出上构建另一个预训练的LLM来实现。更重要的是，护栏的“非侵入性”，通过与目标LLM并行部署来实现，使其能够仅通过少量修改就适用于新模型和危害分类。然而，LLM代理与LLM有显著不同，因为LLM代理涉及更广泛的输出模式和高度具体的护栏请求。例如，一个由LLM赋能的网络代理可能会执行点击网页上指定按钮的操作[[27](#bib.bib27)]。这里的护栏请求可能涉及安全规则，如禁止某些用户（例如，特定年龄以下的用户）购买特定物品（例如，酒精饮料）。显然，现有的仅设计用于调节LLM的文本输入和输出的护栏无法处理如此复杂的护栏请求。
- en: In this paper, we present the first study on guardrails for LLM agents. We propose
    GuardAgent, the first generalizable framework that uses an LLM agent to safeguard
    other LLM agents (referred to as ‘target agents’ henceforth) by adhering to diverse
    real-world guard requests from users, such as safety rules or privacy policies.
    The deployment of GuardAgent requires the prescription of a set of textural guard
    requests informed by a specification of the target agent (e.g., the format of
    agent output and logs). During the inference, user inputs to the target agent,
    along with associated outputs and logs, will be provided to GuardAgent for examination
    to determine whether the guard requests are satisfied or not. Specifically, GuardAgent
    first uses an LLM to generate an action plan based on the guard requests and the
    inputs and outputs of the target agent. Subsequently, the LLM transforms the action
    plan into a guardrail code, which is then executed by calling an external engine.
    For both the action plan and the guardrail code generation, the LLM is provided
    with related demonstrations retrieved from a memory module, which archives inputs
    and outputs from prior use cases. Such knowledge-enabled reasoning is the foundation
    for GuardAgent to understand diverse guard requests for different types of LLM
    agents. The design of our GuardAgent offers three key advantages. Firstly, GuardAgent
    can be easily generalized to safeguard new target agents by simply uploading new
    functions to its toolbox. Secondly, GuardAgent provides guardrails by code generation
    and execution, which is more reliable than guardrails solely based on natural
    language. Thirdly, GuardAgent employs LLMs by in-context learning, enabling direct
    utilization of off-the-shelf LLMs without the need for additional training.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们提出了对LLM代理护栏的首次研究。我们提出了GuardAgent，这是一种可通用的框架，利用LLM代理通过遵守来自用户的各种现实世界护栏请求（如安全规则或隐私政策）来保护其他LLM代理（以下简称“目标代理”）。GuardAgent的部署需要规定一组基于目标代理规范的文本护栏请求（例如，代理输出和日志的格式）。在推理过程中，将目标代理的用户输入以及相关的输出和日志提供给GuardAgent进行检查，以确定护栏请求是否满足。具体来说，GuardAgent首先利用LLM根据护栏请求和目标代理的输入输出生成行动计划。随后，LLM将行动计划转换为护栏代码，然后通过调用外部引擎执行。对于行动计划和护栏代码生成，LLM会提供从记忆模块中检索到的相关示例，该模块存档了以前用例中的输入和输出。这种知识驱动的推理是GuardAgent理解不同类型LLM代理的各种护栏请求的基础。我们GuardAgent的设计提供了三个关键优势。首先，GuardAgent可以通过简单地将新功能上传到其工具箱中来轻松推广到保护新目标代理。其次，GuardAgent通过代码生成和执行提供护栏，这比仅基于自然语言的护栏更可靠。第三，GuardAgent通过上下文学习利用LLM，能够直接使用现成的LLM，而无需额外培训。
- en: 'Before introducing GuardAgent in Sec. [4](#S4 "4 GuardAgent Framework ‣ GuardAgent:
    Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning"), we investigate
    diverse guard requests for different types of LLM agents and propose two novel
    benchmarks in Sec. [3](#S3 "3 Safety Requests for Diverse LLM Agents ‣ GuardAgent:
    Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning"). The first
    benchmark, EICU-AC, is designed to assess the effectiveness of access control
    for LLM agents for healthcare. The second benchmark, Mind2Web-SC, evaluates safety
    control for LLM-powered web agents. These two benchmarks are used to evaluate
    our GuardAgent in our experiments in Sec. [5](#S5 "5 Experiments ‣ GuardAgent:
    Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning"). Note
    that the two types of guard requests considered here – access control and safety
    control – are closely related to privacy and safety, respectively, which are critical
    perspectives of AI trustworthiness [[19](#bib.bib19)]. Our technical contributions
    are summarized as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '在介绍GuardAgent之前，在第[4](#S4 "4 GuardAgent Framework ‣ GuardAgent: Safeguard LLM
    Agents by a Guard Agent via Knowledge-Enabled Reasoning)节中，我们调查了不同类型LLM代理的各种护栏请求，并在第[3](#S3
    "3 Safety Requests for Diverse LLM Agents ‣ GuardAgent: Safeguard LLM Agents by
    a Guard Agent via Knowledge-Enabled Reasoning)节中提出了两个新颖的基准测试。第一个基准测试EICU-AC旨在评估医疗LLM代理的访问控制效果。第二个基准测试Mind2Web-SC评估LLM驱动的网页代理的安全控制。这两个基准测试用于在第[5](#S5
    "5 Experiments ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning)节的实验中评估我们的GuardAgent。需要注意的是，这里考虑的两种护栏请求——访问控制和安全控制——分别与隐私和安全密切相关，这些都是AI可信度的关键视角[[19](#bib.bib19)]。我们的技术贡献总结如下：'
- en: •
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We propose GuardAgent, the first LLM agent framework providing guardrails to
    other LLM agents via knowledge-enabled reasoning in order to address diverse user
    guard requests.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了GuardAgent，这是第一个通过知识驱动推理为其他LLM代理提供护栏的LLM代理框架，以应对各种用户护栏请求。
- en: •
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We propose a novel design for GuardAgent, which comprises knowledge-enabled
    task planning using in-context demonstrations, followed by guardrail code generation
    involving an extendable array of functions. Such design endows GuardAgent with
    strong generalization capabilities, reliable guardrail generation, and no need
    for additional training.
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了一种新颖的GuardAgent设计，该设计包括使用上下文示例的知识驱动任务规划，随后是涉及可扩展功能数组的护栏代码生成。这种设计赋予GuardAgent强大的泛化能力、可靠的护栏生成能力，并且无需额外的训练。
- en: •
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We create two benchmarks, EICU-AC and Mind2Web-SC, for evaluating privacy-related
    access control for healthcare agents and safety control for web agents, respectively.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们创建了两个基准测试，EICU-AC和Mind2Web-SC，分别用于评估医疗代理的隐私相关访问控制和网页代理的安全控制。
- en: •
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We show that GuardAgent effectively provides guardrails to 1) an EHRAgent for
    healthcare with a 98.7% guarding accuracy in access control and 2) a SeeAct web
    agent with a 90.0% guarding accuracy in safety control. We also demonstrate the
    capabilities of GuardAgent in defining new functions during guardrail code generation
    and execution.
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们展示了GuardAgent有效地为1）医疗保健领域的EHRAgent提供了98.7%的访问控制护栏准确性和2）SeeAct网页代理提供了90.0%的安全控制护栏准确性。我们还展示了GuardAgent在护栏代码生成和执行过程中定义新功能的能力。
- en: 2 Related Work
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: LLM agents refer to AI agents that use LLMs as their central engine for task
    understanding and planning and then execute the plan by interacting with the environment
    (e.g., by calling third-party APIs) [[21](#bib.bib21)]. Such fundamental difference
    from LLMs (with purely textual outputs) enables LLM agents to be deployed in diverse
    applications, including finance [[24](#bib.bib24)], healthcare [[2](#bib.bib2),
    [17](#bib.bib17), [22](#bib.bib22), [18](#bib.bib18), [11](#bib.bib11)], daily
    work [[4](#bib.bib4), [5](#bib.bib5), [28](#bib.bib28), [27](#bib.bib27)], and
    autonomous driving [[3](#bib.bib3), [8](#bib.bib8), [12](#bib.bib12)]. LLM agents
    are also commonly equipped with a retrievable memory module, allowing them to
    perform knowledge-enabled reasoning to handle different tasks within its application
    domain [[10](#bib.bib10)]. Our GuardAgent is a typical LLM agent, but with different
    objectives from existing agents, as it is the first one to safeguard other LLM
    agents.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: LLM代理是指使用LLM作为其任务理解和规划的核心引擎的AI代理，然后通过与环境互动（例如，调用第三方API）来执行计划[[21](#bib.bib21)]。与纯文本输出的LLM的根本不同，使得LLM代理能够在金融[[24](#bib.bib24)]、医疗[[2](#bib.bib2),
    [17](#bib.bib17), [22](#bib.bib22), [18](#bib.bib18), [11](#bib.bib11)]、日常工作[[4](#bib.bib4),
    [5](#bib.bib5), [28](#bib.bib28), [27](#bib.bib27)]和自动驾驶[[3](#bib.bib3), [8](#bib.bib8),
    [12](#bib.bib12)]等各种应用中进行部署。LLM代理通常还配备了可检索的记忆模块，使其能够进行知识驱动的推理，以处理其应用领域内的不同任务[[10](#bib.bib10)]。我们的GuardAgent是一个典型的LLM代理，但其目标不同于现有代理，因为它是首个用于保护其他LLM代理的代理。
- en: LLM-based guardrails belong to a family of moderation approaches for harmfulness
    mitigation [[25](#bib.bib25), [15](#bib.bib15)]. Traditional guardrails were operated
    as classifiers trained on categorically labeled content [[13](#bib.bib13), [9](#bib.bib9)],
    while recently, guardrails based on LLMs with broader contextual understanding
    have been developed and shown strong generalization capabilities. However, existing
    guardrails for LLMs, either ‘model guarding models’ ([[16](#bib.bib16), [7](#bib.bib7),
    [26](#bib.bib26)]) or ‘agent guarding models’ ([[1](#bib.bib1)]), are designed
    for harmfulness defined on natural language. They cannot be directly used to safeguard
    LLM agents with diverse output modalities. In this paper, we propose GuardAgent,
    the first ‘agent guarding agents’ framework, and show its advantage over ‘model
    guarding agents’ approaches in our experiments.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLM的保护措施属于有害性减缓的调节方法的一种[[25](#bib.bib25), [15](#bib.bib15)]。传统的保护措施作为在分类标记内容上训练的分类器运行[[13](#bib.bib13),
    [9](#bib.bib9)]，而最近，基于LLM的保护措施以更广泛的上下文理解为基础，并展现了强大的泛化能力。然而，现有的LLM保护措施，无论是“模型保护模型”([[16](#bib.bib16),
    [7](#bib.bib7), [26](#bib.bib26)])还是“代理保护模型”([[1](#bib.bib1)])，都是针对自然语言定义的有害性设计的。它们不能直接用于保护具有多样化输出模式的LLM代理。在本文中，我们提出了GuardAgent，首个“代理保护代理”框架，并展示了其在实验中相较于“模型保护代理”方法的优势。
- en: 3 Safety Requests for Diverse LLM Agents
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 多样化LLM代理的安全请求
- en: 'Before introducing our GuardAgent, we investigate safety requests for different
    types of LLM agents in this section. We focus on two representative LLM agents:
    an EHRAgent for healthcare and a web agent SeeAct. In particular, EHRAgent represents
    LLM agents for high-stake tasks, while SeeAct represents generalist LLM agents
    for diverse tasks. We briefly review these two agents, their designated tasks,
    and their original evaluation benchmarks. More importantly, we propose two novel
    benchmarks for different safety requests: 1) EICU-AC, which assesses access control
    for healthcare agents like EHRAgent, and 2) Mind2Web-SC, which evaluates safety
    control for web agents like SeeAct. Then, we conduct a preliminary study to test
    ‘invasive’ approaches for access control and safety control, which are based on
    naive instructions injected into the system prompts of EHRAgent and SeeAct, respectively;
    their ineffectiveness and poor generalization motivate the need for our GuardAgent.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在介绍我们的GuardAgent之前，我们在本节中调查了不同类型LLM代理的安全请求。我们关注了两个具有代表性的LLM代理：一个用于医疗的EHRAgent和一个网络代理SeeAct。特别地，EHRAgent代表了用于高风险任务的LLM代理，而SeeAct代表了用于多样化任务的通用LLM代理。我们简要回顾了这两个代理，它们的指定任务和原始评估基准。更重要的是，我们提出了针对不同安全请求的两个新基准：1)
    EICU-AC，用于评估像EHRAgent这样的医疗代理的访问控制，以及2) Mind2Web-SC，用于评估像SeeAct这样的网络代理的安全控制。然后，我们进行了初步研究，测试了“侵入性”方法用于访问控制和安全控制，这些方法基于注入到EHRAgent和SeeAct系统提示中的简单指令；它们的无效性和较差的泛化能力激发了我们对GuardAgent的需求。
- en: '![Refer to caption](img/27ec2753e00c29f62b75c1eb06ca95a2.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/27ec2753e00c29f62b75c1eb06ca95a2.png)'
- en: 'Figure 2: An example from EICU-AC (left) and an example from Mind2Web-SC (right).'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：EICU-AC 的一个示例（左）和 Mind2Web-SC 的一个示例（右）。
- en: 3.1 EHRAgent and EICU-AC Benchmark
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 EHRAgent 和 EICU-AC 基准
- en: EHRAgent
  id: totrans-36
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: EHRAgent
- en: 'EHRAgent is designed to respond to healthcare-related queries by generating
    code to retrieve and analyze data from provided databases [[17](#bib.bib17)].
    EHRAgent has been evaluated and shown decent performance on several benchmarks,
    including an EICU dataset containing questions regarding the clinical care of
    ICU patients (see Fig. [2](#S3.F2 "Figure 2 ‣ 3 Safety Requests for Diverse LLM
    Agents ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning") for example) and 10 relevant databases [[14](#bib.bib14)]. Each database
    contains several types of patient information stored in different columns. In
    practical healthcare systems, it is crucial to restrict access to specific databases
    based on user identities. For example, personnel in general administration should
    not have access to patient diagnosis details. Thus, LLM agents for healthcare,
    such as EHRAgent, should be able to deny requests for information from the patient
    diagnosis database when the user is from the general administration. In essence,
    these LLM agents should incorporate access controls to safeguard patient privacy.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 'EHRAgent 旨在通过生成代码来从提供的数据库中检索和分析数据，以回应与医疗保健相关的查询[[17](#bib.bib17)]。EHRAgent
    已经过评估，并在多个基准测试中显示出良好的性能，包括一个包含关于 ICU 患者临床护理问题的 EICU 数据集（例如见图 [2](#S3.F2 "Figure
    2 ‣ 3 Safety Requests for Diverse LLM Agents ‣ GuardAgent: Safeguard LLM Agents
    by a Guard Agent via Knowledge-Enabled Reasoning)）和 10 个相关数据库[[14](#bib.bib14)]。每个数据库包含存储在不同列中的几种类型的患者信息。在实际的医疗保健系统中，基于用户身份限制对特定数据库的访问至关重要。例如，一般行政人员不应访问患者诊断详细信息。因此，医疗保健领域的
    LLM 代理，如 EHRAgent，应能够在用户来自一般行政部门时拒绝对患者诊断数据库的信息请求。实质上，这些 LLM 代理应包含访问控制来保护患者隐私。'
- en: Proposed EICU-AC benchmark
  id: totrans-38
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 提议的 EICU-AC 基准
- en: 'In this paper, we create an EICU-AC benchmark from EICU to evaluate Access
    Control approaches for EHRAgent (and potentially other healthcare agents that
    require database retrieval). We define three roles for the user of EHRAgent (and
    other similar target agents): ‘physician’, ‘nursing’, and ‘general administration’.
    The access control being evaluated is supposed to ensure that each identity has
    access to only a subset of databases and columns of the EICU benchmark. We generate
    the ground truth access permission for each role by querying ChatGPT (see App.
    [A.1](#A1.SS1 "A.1 Role-Based Access Permission ‣ Appendix A Details About the
    EICU-AC Benchmark ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning") for more details). While generic access control approaches should
    be invariant to the specific roles and their access permissions, we have made
    these choices to simulate practical healthcare scenarios. Then, each example in
    EICU-AC is designed to include the following information: 1) a healthcare-related
    question and the correct answer, 2) the databases and the columns required to
    answer the question, 3) a user identity/role, 4) a binary label ‘0’ if all required
    databases and columns are accessible to the given identity or ‘1’ otherwise, and
    5) the required databases and columns inaccessible to the identity if the label
    is ‘1’. An illustration of a generated EICU-AC example is shown in Fig. [2](#S3.F2
    "Figure 2 ‣ 3 Safety Requests for Diverse LLM Agents ‣ GuardAgent: Safeguard LLM
    Agents by a Guard Agent via Knowledge-Enabled Reasoning").'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '在本文中，我们创建了一个来自 EICU 的 EICU-AC 基准测试，用于评估 EHRAgent 的访问控制方法（以及其他需要数据库检索的医疗保健代理）。我们为
    EHRAgent（及其他类似目标代理）定义了三种角色：‘医生’，‘护理’和‘一般行政’。所评估的访问控制应确保每个身份只能访问 EICU 基准测试中的一部分数据库和列。我们通过查询
    ChatGPT 来生成每个角色的真实访问权限（更多细节见附录 [A.1](#A1.SS1 "A.1 Role-Based Access Permission
    ‣ Appendix A Details About the EICU-AC Benchmark ‣ GuardAgent: Safeguard LLM Agents
    by a Guard Agent via Knowledge-Enabled Reasoning)）。虽然通用访问控制方法应对特定角色及其访问权限保持不变，但我们做出这些选择以模拟实际的医疗保健场景。然后，EICU-AC
    中的每个示例设计为包含以下信息：1) 一个与医疗保健相关的问题及其正确答案，2) 回答问题所需的数据库和列，3) 用户身份/角色，4) 如果所有所需的数据库和列对给定身份可访问，则为二进制标签‘0’，否则为‘1’，5)
    如果标签为‘1’，则对身份不可访问的数据库和列。生成的 EICU-AC 示例的说明见图 [2](#S3.F2 "Figure 2 ‣ 3 Safety Requests
    for Diverse LLM Agents ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via
    Knowledge-Enabled Reasoning")。'
- en: 'In particular, all questions in EICU-AC are sampled or adapted from the EICU
    dataset. We keep questions from EICU that are correctly answered by EHRAgent using
    GPT-4 (at temperature zero) as the core LLM so that the evaluation using our benchmark
    will mainly focus on access control without much influence from the task performance.
    Initially, we generate three EICU-AC examples from each of these questions by
    assigning them the three roles respectively. After labeling each example based
    on the ground truth accessibility of its assigned role, we find for all three
    identities that the two labels are highly imbalanced. Thus, for each identity,
    we remove some of the generated examples while adding new ones to achieve a relative
    balance between the two labels (see more details in App. [A.2](#A1.SS2 "A.2 Sampling
    from EICU ‣ Appendix A Details About the EICU-AC Benchmark ‣ GuardAgent: Safeguard
    LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning")). Ultimately, our
    EICU-AC contains 52, 57, and 45 examples labeled to ‘0’ for ‘physician’, ‘nursing’,
    and ‘general administration’, respectively, and 46, 55, and 61 examples labeled
    to ‘1’ for the three roles, respectively. Moreover, among these 316 examples,
    there are 226 unique questions spanning 51 different ICU information categories,
    which underscores the diversity of our EICU-AC.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '特别是，EICU-AC 中的所有问题都来自或改编自 EICU 数据集。我们保留了那些由 GPT-4（温度为零）作为核心 LLM 正确回答的 EICU
    问题，以便使用我们的基准测试进行评估时主要关注访问控制，而不受任务性能的影响。最初，我们从这些问题中生成了三组 EICU-AC 示例，分别分配给三个角色。在根据分配角色的真实可访问性对每个示例进行标记后，我们发现所有三个身份的两个标签高度不平衡。因此，对于每个身份，我们移除了一些生成的示例，同时添加新的示例，以实现两个标签之间的相对平衡（更多细节请参见附录
    [A.2](#A1.SS2 "A.2 Sampling from EICU ‣ Appendix A Details About the EICU-AC Benchmark
    ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning")）。最终，我们的
    EICU-AC 包含了分别标记为‘0’的 52 个、57 个和 45 个示例，分别对应‘医生’、‘护理’和‘一般行政’，以及分别标记为‘1’的 46 个、55
    个和 61 个示例。此外，这 316 个示例中有 226 个独特的问题，涵盖了 51 个不同的 ICU 信息类别，这突显了我们 EICU-AC 的多样性。'
- en: 3.2 SeeAct and Mind2Web-SC Benchmark
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 SeeAct 和 Mind2Web-SC 基准测试
- en: SeeAct
  id: totrans-42
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: SeeAct
- en: 'SeeAct is a generalist web agent that follows natural language instructions
    to complete tasks on any given website by sequentially generating actions, including
    clicking on a button, typing specific texts, etc. (see Fig. [2](#S3.F2 "Figure
    2 ‣ 3 Safety Requests for Diverse LLM Agents ‣ GuardAgent: Safeguard LLM Agents
    by a Guard Agent via Knowledge-Enabled Reasoning") for example) [[27](#bib.bib27)].
    In the original paper, SeeAct is evaluated on the Mind2Web benchmark containing
    over 2,000 complex web tasks spanning 137 websites across 31 domains (e.g., car
    rental, shopping, entertainment, etc.) [[4](#bib.bib4)]. However, it is essential
    for practical web agents like SeeAct to integrate safety controls that restrict
    certain actions for specific users. For example, in most regions of the world,
    a driver’s license is required for car rental.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 'SeeAct 是一个通用的 web 代理，它通过顺序生成动作（如点击按钮、输入特定文本等）来按照自然语言指令完成任何给定网站上的任务（例如，见图 [2](#S3.F2
    "Figure 2 ‣ 3 Safety Requests for Diverse LLM Agents ‣ GuardAgent: Safeguard LLM
    Agents by a Guard Agent via Knowledge-Enabled Reasoning")）[[27](#bib.bib27)]。在原始论文中，SeeAct
    在包含超过 2,000 个复杂 web 任务的 Mind2Web 基准测试中进行了评估，这些任务跨越 137 个网站和 31 个领域（例如，汽车租赁、购物、娱乐等）[[4](#bib.bib4)]。然而，对于像
    SeeAct 这样的实际 web 代理，整合安全控制来限制特定用户的某些操作是至关重要的。例如，在世界大多数地区，汽车租赁需要驾照。'
- en: Proposed Mind2Web-SC benchmark
  id: totrans-44
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 提议的 Mind2Web-SC 基准测试
- en: 'We create a Mind2Web-SC benchmark to evaluate Safety Control applicable to
    SeeAct and other web agents that operate based on action generation. The objective
    of safety control is to ensure that the agent obeys six rules we created based
    on common web regulations and regional conventions: 1) user must be a member to
    shop, 2) unvaccinated user cannot book a flight, 3) user without a driver’s license
    cannot buy or rent a car, 4) user aged under 18 cannot book a hotel, 5) user must
    be in certain countries to search movies/music/video, 6) user under 15 cannot
    apply for jobs. Again, these rules are proposed solely for evaluation purposes
    and do not reflect the personal views or attitudes of the authors.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个 Mind2Web-SC 基准测试来评估适用于 SeeAct 和其他基于动作生成的 web 代理的安全控制。安全控制的目标是确保代理遵守我们根据常见的
    web 规定和区域惯例制定的六条规则：1）用户必须是会员才能购物，2）未接种疫苗的用户不能订购航班，3）没有驾照的用户不能购买或租用汽车，4）年龄在 18
    岁以下的用户不能预订酒店，5）用户必须在某些国家才能搜索电影/音乐/视频，6）15 岁以下的用户不能申请工作。再次说明，这些规则仅用于评估目的，不反映作者的个人观点或态度。
- en: 'The examples in Mind2Web-SC are created by the following steps. First, we obtain
    all tasks with correct action prediction by SeeAct (using LLaVA-1.5 as the core
    LLM) from the travel, shop, and entertainment domains of the test set of Mind2Web.
    Second, for each task, we randomly create a user profile containing ‘age’ in integer
    and ‘domestic’, ‘dr_license’, ‘vaccine’, and ‘membership’, all boolean (see the
    right of Fig. [2](#S3.F2 "Figure 2 ‣ 3 Safety Requests for Diverse LLM Agents
    ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning")).
    Note that each of these six user information categories is non-trivial, as it
    is related to at least one of the six safety rules we created. Third, we manually
    label each example based on the task and the user information. If the task itself
    is not related to any of the six rules, the example will be labeled to ‘0’ for
    ‘action permitted’. If the task is related to at least one of the rules (e.g.
    the one for car rental), we check the user information and will label the example
    to ‘1’ for ‘action denied’ if the rule is violated (e.g. ‘dr_license’ is ‘false’)
    and ‘0’ otherwise. For each example labeled to ‘1’, the violated rules are also
    included in our benchmark. Finally, we balance the two classes by creating additional
    examples (based on existing tasks but with different user information) while removing
    some examples with tasks irrelevant to any of the rules (see details in App. [B](#A2
    "Appendix B Details About the Mind2Web-SC Benchmark ‣ GuardAgent: Safeguard LLM
    Agents by a Guard Agent via Knowledge-Enabled Reasoning")). The created Mind2Web-SC
    benchmark contains 100 examples in each class with only unique tasks within the
    class.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 'Mind2Web-SC中的示例是通过以下步骤创建的。首先，我们通过SeeAct（使用LLaVA-1.5作为核心LLM）从Mind2Web测试集中的旅行、购物和娱乐领域获取所有正确的动作预测任务。其次，对于每个任务，我们随机创建一个用户档案，其中包含‘age’（整数）以及‘domestic’、‘dr_license’、‘vaccine’和‘membership’，这些都是布尔值（参见图[2](#S3.F2
    "Figure 2 ‣ 3 Safety Requests for Diverse LLM Agents ‣ GuardAgent: Safeguard LLM
    Agents by a Guard Agent via Knowledge-Enabled Reasoning")的右侧）。请注意，这六个用户信息类别中的每一个都是非平凡的，因为它们与我们创建的六条安全规则中的至少一条相关。第三，我们根据任务和用户信息手动标记每个示例。如果任务本身与六条规则中的任何一条无关，则示例将标记为‘0’，表示‘允许动作’。如果任务与至少一条规则相关（例如汽车租赁规则），我们会检查用户信息，并在规则被违反时将示例标记为‘1’，表示‘动作被拒绝’（例如‘dr_license’为‘false’），否则标记为‘0’。对于每个标记为‘1’的示例，被违反的规则也包含在我们的基准测试中。最后，我们通过创建额外的示例（基于现有任务但用户信息不同）来平衡两个类别，同时删除一些与任何规则无关的任务示例（详细信息见附录[B](#A2
    "Appendix B Details About the Mind2Web-SC Benchmark ‣ GuardAgent: Safeguard LLM
    Agents by a Guard Agent via Knowledge-Enabled Reasoning")）。创建的Mind2Web-SC基准包含每个类别中的100个示例，并且每个类别内的任务都是唯一的。'
- en: 'Table 1: Access control on EHRAgent and safety control on SeeAct based on system
    instructions are ineffective on EICU-AC and Mind2Web-SC; therefore, a new guardrail
    method is needed.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：基于系统指令对EHRAgent的访问控制和对SeeAct的安全控制在EICU-AC和Mind2Web-SC上效果不佳；因此，需要一种新的护栏方法。
- en: '|  | LPP $\uparrow$ |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '|  | LPP $\uparrow$ |'
- en: '| EHRAgent + EICU-AC | 76.6 | 90.7 | 50.0 | 3.2 |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| EHRAgent + EICU-AC | 76.6 | 90.7 | 50.0 | 3.2 |'
- en: '| SeeAct + Mind2Web-SC | 95.1 | 58.0 | 58.0 | 71.0 |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| SeeAct + Mind2Web-SC | 95.1 | 58.0 | 58.0 | 71.0 |'
- en: 3.3 Preliminary Guardrails on the Two Benchmarks
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 初步的两项基准测试护栏
- en: Naive ‘invasive’ baselines
  id: totrans-52
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 初步的‘侵入性’基线
- en: 'We use the EICU-AC benchmark to evaluate a naive approach that hardwires the
    access control into the system prompt of EHRAgent by specifying the three roles
    with their accessible databases and columns. During the evaluation, this modified
    EHRAgent will be provided with both the role and the query of the EICU-AC examples.
    Its system prompt will include instructions to display a ‘denial message’ along
    with the inaccessible databases and columns for the given role, if there are any.
    Similarly, we incorporate textual instructions for safety checks into the system
    prompt of SeeAct and evaluate it on Mind2Web-SC. If any of the rules are violated
    for the given user profile, the safety-enforced SeeAct is supposed to print a
    ‘denial message’ with the violated rules. Details about the system prompts for
    the two agents equipped with the naive ‘invasive’ guardrails are deferred to App.
    [C](#A3 "Appendix C Detailed System Prompts for Naive Access Control and Safety
    Control Based on Instructions ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent
    via Knowledge-Enabled Reasoning").'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 EICU-AC 基准测试来评估一种将访问控制硬编码到 EHRAgent 系统提示中的简单方法，通过指定三种角色及其可访问的数据库和列。在评估过程中，这种修改后的
    EHRAgent 将同时接收角色和 EICU-AC 示例的查询。其系统提示将包括指示，如果存在任何不可访问的数据库和列，则显示“拒绝消息”。类似地，我们将安全检查的文本指令融入
    SeeAct 的系统提示中，并在 Mind2Web-SC 上进行评估。如果给定用户配置文件违反了任何规则，安全强化的 SeeAct 应打印出带有违反规则的“拒绝消息”。关于这两种配备了简单“侵入式”保护措施的代理系统提示的详细信息，请参见
    App. [C](#A3 "附录 C：基于指令的简单访问控制和安全控制的详细系统提示 ‣ GuardAgent：通过知识驱动推理保护 LLM 代理")。
- en: Metrics
  id: totrans-54
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 指标
- en: 'We consider four evaluation metrics shared by both benchmarks: label prediction
    precision (LPP), label prediction recall (LPR), comprehensive control accuracy
    (CCA), and final response accuracy (FRA), all in percentage. Both LPP and LPR
    are calculated over all examples in each dataset to measure the overall label
    prediction efficacy, where a prediction of label ‘1’ is counted only if the ‘denial
    message’ appears. CCA considers all examples with ground truth labeled ‘1’. It
    is defined as the percentage of these examples being correctly predicted to ‘1’
    and with all inaccessible databases and columns (for EICU-AC) or all violated
    rules (for Mind2Web-SC) successfully detected. In contrast, FRA considers all
    examples with ground truth labeled ‘0’. It is defined as the percentage of these
    examples being correctly predicted to ‘0’ and with the agent responses correctly.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们考虑了两个基准共享的四个评估指标：标签预测精度（LPP）、标签预测召回率（LPR）、综合控制准确性（CCA）和最终响应准确性（FRA），均以百分比表示。LPP
    和 LPR 是在每个数据集中对所有示例进行计算的，以测量整体标签预测效果，其中仅当出现“拒绝消息”时，标签‘1’的预测才被计入。CCA 考虑所有标记为‘1’的示例。它定义为这些示例被正确预测为‘1’的百分比，并且所有不可访问的数据库和列（对于
    EICU-AC）或所有违反的规则（对于 Mind2Web-SC）都被成功检测到。相比之下，FRA 考虑所有标记为‘0’的示例。它定义为这些示例被正确预测为‘0’的百分比，以及代理响应的准确性。
- en: Results
  id: totrans-56
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 结果
- en: 'As shown in Tab. [1](#S3.T1 "Table 1 ‣ Proposed Mind2Web-SC benchmark ‣ 3.2
    SeeAct and Mind2Web-SC Benchmark ‣ 3 Safety Requests for Diverse LLM Agents ‣
    GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning"),
    the two naive baselines fail in their designated tasks, exhibiting either low
    precision or recall in label prediction. Specifically, the naive access control
    for EHRAgent is overly strict, resulting in an excessive number of false positives.
    Conversely, the naive safety control for SeeAct fails to reject many unsafe actions,
    leading to numerous false negatives. Moreover, the ‘invasion’ that introduces
    additional tasks imposes heavy burdens on both agents, significantly degrading
    the performance on their designated tasks, particularly for EHRAgent (which achieves
    only 3.2% end-to-end accuracy on negative examples as measured by FRA). Finally,
    despite their poor performance, both naive guardrail approaches are hardwired
    to the agent, making them non-transferable to other LLM agents with different
    designs. These shortcomings highlight the need for our GuardAgent, which is both
    effective and generalizable in safeguarding diverse LLM agents.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '如表 [1](#S3.T1 "Table 1 ‣ Proposed Mind2Web-SC benchmark ‣ 3.2 SeeAct and Mind2Web-SC
    Benchmark ‣ 3 Safety Requests for Diverse LLM Agents ‣ GuardAgent: Safeguard LLM
    Agents by a Guard Agent via Knowledge-Enabled Reasoning") 所示，两个简单的基准在指定任务中失败，表现出标签预测的低精度或召回率。具体来说，EHRAgent
    的简单访问控制过于严格，导致了过多的假阳性。相反，SeeAct 的简单安全控制未能拒绝许多不安全的操作，导致了大量的假阴性。此外，引入额外任务的“入侵”对两个代理都施加了沉重的负担，显著降低了它们在指定任务上的表现，特别是对于
    EHRAgent（在负面示例中仅达到 3.2% 的端到端准确率）。最后，尽管表现不佳，这两种简单的护栏方法都硬编码在代理中，使它们无法转移到其他设计不同的
    LLM 代理。这些缺点突显了我们 GuardAgent 的必要性，它在保护不同 LLM 代理方面既有效又具有广泛适用性。'
- en: 4 GuardAgent Framework
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 GuardAgent 框架
- en: 'In this section, we introduce GuardAgent with three key features: 1) generalizable
    – the memory and toolbox of GuardAgent can be easily extended to address new target
    agents with new guard requests; 2) reliable – outputs of GuardAgent are obtained
    by successful code execution; 3) training-free – GuardAgent is in-context-learning-based
    and does not need any LLM training.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们介绍了具有三个关键特性的 GuardAgent：1) 可推广性——GuardAgent 的记忆和工具箱可以轻松扩展以应对具有新护栏请求的新目标代理；2)
    可靠性——GuardAgent 的输出是通过成功的代码执行获得的；3) 无需训练——GuardAgent 基于上下文学习，不需要任何 LLM 训练。
- en: 4.1 Overview of GuardAgent
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 GuardAgent 概述
- en: The intended user of GuardAgent is the developer or administrator of a target
    LLM agent who seeks to implement guardrails on it. The mandatory inputs to GuardAgent
    are all textual, including a set of guard requests $I_{r}$ (e.g., by printing
    out the inaccessible databases and columns for EICU-AC) for potential further
    actions. For example, severe rule violations for some use cases may require judicial
    intervention.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: GuardAgent 的预期用户是希望在目标 LLM 代理上实施护栏的开发人员或管理员。GuardAgent 的强制输入都是文本，包括一组护栏请求 $I_{r}$（例如，通过打印出
    EICU-AC 的不可访问数据库和列）以供进一步的潜在操作。例如，对于某些用例，严重的规则违规可能需要司法干预。
- en: 'The key idea of GuardAgent is to leverage the logical reasoning capabilities
    of LLMs with knowledge retrieval to accurately ‘translate’ textual guard requests
    into executable code. Correspondingly, the pipeline of GuardAgent comprises two
    major steps (see Fig. [1](#S0.F1 "Figure 1 ‣ GuardAgent: Safeguard LLM Agents
    by a Guard Agent via Knowledge-Enabled Reasoning")). In the first step (Sec. [4.2](#S4.SS2
    "4.2 Task Planning ‣ 4 GuardAgent Framework ‣ GuardAgent: Safeguard LLM Agents
    by a Guard Agent via Knowledge-Enabled Reasoning")), a step-by-step action plan
    is generated by prompting an LLM with the above-mentioned inputs to GuardAgent.
    In the second step [4.3](#S4.SS3 "4.3 Guardrail Code Generation and Execution
    ‣ 4 GuardAgent Framework ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via
    Knowledge-Enabled Reasoning")), we prompt the LLM with the action plan and a set
    of callable functions to get a guardrail code, which is then executed by calling
    an external engine. A memory module is available in both steps to retrieve in-context
    demonstrations.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 'GuardAgent 的关键理念是利用 LLM 的逻辑推理能力和知识检索，将文本保护请求准确地“转换”为可执行的代码。因此，GuardAgent 的流程包括两个主要步骤（见图
    [1](#S0.F1 "Figure 1 ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning")）。在第一步（第 [4.2](#S4.SS2 "4.2 Task Planning ‣ 4 GuardAgent Framework
    ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning")
    节），通过向 LLM 提供上述输入生成逐步行动计划。在第二步 [4.3](#S4.SS3 "4.3 Guardrail Code Generation and
    Execution ‣ 4 GuardAgent Framework ‣ GuardAgent: Safeguard LLM Agents by a Guard
    Agent via Knowledge-Enabled Reasoning")，我们将行动计划和一组可调用的函数提供给 LLM，以获取保护代码，然后通过调用外部引擎执行该代码。在这两个步骤中都有一个内存模块用于检索上下文中的示例。'
- en: 4.2 Task Planning
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 任务规划
- en: 'The objective for task planning is to generate a step-by-step action plan $P$),
    and 3) guide the generation of action steps (see Fig. [8](#A4.F8 "Figure 8 ‣ Complete
    Inputs to GuardAgent ‣ Appendix D Complete Inputs and Output of GuardAgent ‣ GuardAgent:
    Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning") in App.
    [D](#A4 "Appendix D Complete Inputs and Output of GuardAgent ‣ GuardAgent: Safeguard
    LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning") for a concrete example).
    However, understanding the complex guard requests and incorporating them with
    the target agent remains a challenging task for existing LLMs.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '任务规划的目标是生成逐步行动计划 $P$)，以及 3) 指导行动步骤的生成（见图 [8](#A4.F8 "Figure 8 ‣ Complete Inputs
    to GuardAgent ‣ Appendix D Complete Inputs and Output of GuardAgent ‣ GuardAgent:
    Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning") 和附录 [D](#A4
    "Appendix D Complete Inputs and Output of GuardAgent ‣ GuardAgent: Safeguard LLM
    Agents by a Guard Agent via Knowledge-Enabled Reasoning") 中的具体示例）。然而，理解复杂的保护请求并将其与目标代理结合仍然是现有
    LLM 面临的挑战任务。'
- en: We address this challenge by allowing GuardAgent to retrieve demonstrations
    from a memory module that archives target agent inputs and outputs from past use
    cases. Here, an element $D$. Note that the guardrail code in each demonstration
    has been removed for the brevity of the prompt.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过允许 GuardAgent 从一个存档目标代理输入和输出的内存模块中检索示例来应对这一挑战。这里，元素 $D$。请注意，为了简洁起见，每个示例中的保护代码已被移除。
- en: 'In the cases where GuardAgent is applied to a new LLM agent for some specific
    guard requests, we also allow the user of GuardAgent to manually inject demonstrations
    into the memory module. In particular, we request the action plan in each demonstration
    provided by the user to contain four mandatory steps, denoted by $P_{D}=[p_{1,D},p_{2,D},p_{3,D},p_{4,D}]$,
    as well as the supposed execution engine. Example action plans are shown in Fig.
    [13](#A7.F13 "Figure 13 ‣ Appendix G Manually Created Demonstrations ‣ GuardAgent:
    Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning") of App.
    [G](#A7 "Appendix G Manually Created Demonstrations ‣ GuardAgent: Safeguard LLM
    Agents by a Guard Agent via Knowledge-Enabled Reasoning").'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '当 GuardAgent 应用于新的 LLM 代理以处理特定的保护请求时，我们还允许 GuardAgent 的用户手动将示例注入到内存模块中。特别是，我们要求用户提供的每个示例中的行动计划包含四个强制步骤，记作
    $P_{D}=[p_{1,D},p_{2,D},p_{3,D},p_{4,D}]$，以及假定的执行引擎。图 [13](#A7.F13 "Figure 13
    ‣ Appendix G Manually Created Demonstrations ‣ GuardAgent: Safeguard LLM Agents
    by a Guard Agent via Knowledge-Enabled Reasoning") 和附录 [G](#A7 "Appendix G Manually
    Created Demonstrations ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via
    Knowledge-Enabled Reasoning") 中显示了示例行动计划。'
- en: 4.3 Guardrail Code Generation and Execution
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 保护代码生成与执行
- en: The goal of this step is to generate a guardrail code $C$ of callable functions
    with specification of their input arguments. The definitions of these functions
    are stored in the toolbox of GuardAgent, which can be easily extended by users
    through code uploading to address new guard requests and target agents. The LLM
    is instructed to use only the provided functions for code generation; otherwise,
    it easily makes up non-existent functions during code generation.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 此步骤的目标是生成一个包含可调用函数及其输入参数规范的保护代码 $C$。这些函数的定义存储在 GuardAgent 的工具箱中，用户可以通过上传代码来轻松扩展，以应对新的保护请求和目标代理。LLM
    被指示仅使用提供的函数进行代码生成；否则，它在代码生成过程中容易编造不存在的函数。
- en: Furthermore, we utilize past examples retrieved from memory, employing the same
    approach used in task planning, to serve as demonstrations for code generation.
    Thus, we have $C={\rm LLM}(I_{c}(\mathcal{F}),D_{1},\cdots,D_{k},I_{i},I_{o},P)$.
    Finally, we adopt the debugging mechanism proposed by Shi et al. [[17](#bib.bib17)],
    which invokes an LLM to analyze any error messages that may arise during execution
    to enhance the reliability of the generated code.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们利用从记忆中检索到的过去示例，采用与任务规划中使用的相同方法，作为代码生成的示例。因此，我们有 $C={\rm LLM}(I_{c}(\mathcal{F}),D_{1},\cdots,D_{k},I_{i},I_{o},P)$。最后，我们采用了
    Shi 等人提出的调试机制[[17](#bib.bib17)]，该机制调用 LLM 来分析执行过程中可能出现的任何错误消息，以提高生成代码的可靠性。
- en: 5 Experiments
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 个实验
- en: 'In Sec. [5.2](#S5.SS2 "5.2 Guardrail Performance ‣ 5 Experiments ‣ GuardAgent:
    Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning"), we show
    the effectiveness of GuardAgent in safeguarding EHRAgent on EICU-AC and SeeAct
    on Mind2Web-SC with 98.7% and 90.0% label prediction accuracies, respectively.
    We illustrate through a case study that the advantage of GuardAgent over ‘model
    guarding agents’ approaches is attributed to the more reliable guardrail by code
    generation and execution. In Sec. [5.3](#S5.SS3 "5.3 Ablation Studies ‣ 5 Experiments
    ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning"),
    we conduct ablation studies to show 1) GuardAgent performs similarly well for
    most of the roles in EICU-AC and rules in Mind2Web-SC, allowing it to handle guard
    requests with high complexity, and 2) GuardAgent requires only a few shots of
    demonstrations. In Sec. [5.4](#S5.SS4 "5.4 Code-Based Guardrail is the Natural
    Preference of LLMs, but Tools are Needed ‣ 5 Experiments ‣ GuardAgent: Safeguard
    LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning"), we demonstrate
    that GuardAgent may define necessary functions based on guard requests, highlighting
    its ability to generalize to new guard requests. Additionally, we find that LLMs,
    such as GPT-4, tend to generate code-based guardrails (albeit mostly inexecutable)
    even when not provided with specific instructions for code generation and execution.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '在第[5.2节](#S5.SS2 "5.2 Guardrail Performance ‣ 5 Experiments ‣ GuardAgent: Safeguard
    LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning")中，我们展示了 GuardAgent
    在 EICU-AC 上保护 EHRAgent 和在 Mind2Web-SC 上保护 SeeAct 的效果，分别达到了 98.7% 和 90.0% 的标签预测准确率。我们通过案例研究说明，GuardAgent
    相对于‘模型保护代理’方法的优势在于通过代码生成和执行提供了更可靠的保护措施。在第[5.3节](#S5.SS3 "5.3 Ablation Studies
    ‣ 5 Experiments ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning")中，我们进行了消融研究，展示了 1) GuardAgent 对于 EICU-AC 中的大多数角色和 Mind2Web-SC 中的规则表现相似，能够处理复杂的保护请求，2)
    GuardAgent 仅需少量的示例。第[5.4节](#S5.SS4 "5.4 Code-Based Guardrail is the Natural Preference
    of LLMs, but Tools are Needed ‣ 5 Experiments ‣ GuardAgent: Safeguard LLM Agents
    by a Guard Agent via Knowledge-Enabled Reasoning")中，我们展示了 GuardAgent 可以根据保护请求定义必要的功能，突显了其对新保护请求的泛化能力。此外，我们发现，即使在没有提供具体的代码生成和执行指令的情况下，LLMs（如
    GPT-4）也倾向于生成基于代码的保护措施（尽管大多是不可执行的）。'
- en: 5.1 Setup
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 设置
- en: Datasets and agents
  id: totrans-73
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据集和代理
- en: 'We test GuardAgent on EICU-AC and Mind2Web-SC with EHRAgent and SeeAct (using
    their original settings) as the target agents, respectively. The role and question
    from each EICU-AC example are inputs to EHRAgent, and the output logs include
    the reasoning steps, the generated code, and the final answer produced by EHRAgent.
    The inputs to SeeAct contain the task and user information from each example in
    Mind2Web-SC, and the output logs include the predicted action and the reasoning
    by SeeAct. Example inputs ($I_{i}$), are also shown in App. [D](#A4 "Appendix
    D Complete Inputs and Output of GuardAgent ‣ GuardAgent: Safeguard LLM Agents
    by a Guard Agent via Knowledge-Enabled Reasoning") due to space limitations.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在EICU-AC和Mind2Web-SC上测试GuardAgent，以EHRAgent和SeeAct（使用其原始设置）作为目标代理。每个EICU-AC示例中的角色和问题作为EHRAgent的输入，输出日志包括推理步骤、生成的代码和EHRAgent产生的最终答案。SeeAct的输入包含每个Mind2Web-SC示例中的任务和用户信息，输出日志包括SeeAct的预测行动和推理。由于空间限制，示例输入($I_{i}$)也显示在附录
    [D](#A4 "Appendix D Complete Inputs and Output of GuardAgent ‣ GuardAgent: Safeguard
    LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning")。'
- en: Settings of GuardAgent
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: GuardAgent的设置
- en: 'In the main experiments, we set the number of demonstrations to $k=1$ manually
    created demonstrations (see App. [G](#A7 "Appendix G Manually Created Demonstrations
    ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning")
    for example). We use GPT-4 version 2024-02-01 with temperature zero as the core
    LLM of GuardAgent. We use Python as the default code execution engine, with two
    initial functions in the toolbox, ‘CheckAccess’ and ‘CheckRules’, which are defined
    in App. [E](#A5 "Appendix E Callable Functions ‣ GuardAgent: Safeguard LLM Agents
    by a Guard Agent via Knowledge-Enabled Reasoning"). Note that users of GuardAgent
    can easily upload new functions or engines into the toolbox. Finally, we allow
    three debugging iterations, though in most cases, the guardrail code generated
    by GuardAgent is directly executable.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '在主要实验中，我们将演示的数量设置为 $k=1$ 手动创建的演示（示例见附录 [G](#A7 "Appendix G Manually Created
    Demonstrations ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning")）。我们使用GPT-4 版本 2024-02-01 和温度为零作为GuardAgent的核心LLM。我们使用Python作为默认的代码执行引擎，工具箱中有两个初始函数，“CheckAccess”和“CheckRules”，这些函数在附录
    [E](#A5 "Appendix E Callable Functions ‣ GuardAgent: Safeguard LLM Agents by a
    Guard Agent via Knowledge-Enabled Reasoning")中定义。请注意，GuardAgent的用户可以轻松地将新的函数或引擎上传到工具箱中。最后，我们允许进行三次调试迭代，尽管在大多数情况下，GuardAgent生成的护栏代码是直接可执行的。'
- en: Baselines
  id: totrans-77
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基线
- en: Since GuardAgent is the first LLM agent designed to safeguard other agents,
    we compare it with baselines using models to safeguard agents. Here, we consider
    GPT-4 version 2024-02-01 and Llama3-70B as the guardrail models¹¹1Approaches for
    ‘model guarding models’, such as LlamaGuard designed to detect predefined unsafe
    categories [[7](#bib.bib7)], are not considered here due to their completely different
    objectives.. We create comprehensive prompts containing high-level instructions
    $I^{\prime}_{p}$.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 由于GuardAgent是第一个旨在保护其他代理的LLM代理，我们将其与使用模型来保护代理的基线进行比较。在这里，我们考虑GPT-4 版本 2024-02-01
    和Llama3-70B作为护栏模型¹¹1由于其目标完全不同，诸如LlamaGuard等“模型守护模型”的方法（例如，旨在检测预定义的危险类别[[7](#bib.bib7)]）在这里不被考虑。我们创建了包含高级指令
    $I^{\prime}_{p}$ 的综合提示。
- en: Evaluation metrics
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 评估指标
- en: 'We use the two label prediction metrics, LPP and LPR, and the CCA metric, all
    defined in Sec. [3.3](#S3.SS3 "3.3 Preliminary Guardrails on the Two Benchmarks
    ‣ 3 Safety Requests for Diverse LLM Agents ‣ GuardAgent: Safeguard LLM Agents
    by a Guard Agent via Knowledge-Enabled Reasoning"). The FRA metric is not considered
    here since all guardrails being evaluated will not affect the normal operation
    of the target agent when the alarm is not triggered. In addition, we report the
    label prediction accuracy (LPA, a.k.a. guarding accuracy), defined over all examples
    in each dataset, as the overall metric for the guardrail performance.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '我们使用了两个标签预测指标LPP和LPR，以及CCA指标，所有这些都在第 [3.3](#S3.SS3 "3.3 Preliminary Guardrails
    on the Two Benchmarks ‣ 3 Safety Requests for Diverse LLM Agents ‣ GuardAgent:
    Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning")节中定义。由于所有评估的护栏在未触发警报时不会影响目标代理的正常操作，因此不考虑FRA指标。此外，我们报告了标签预测准确率（LPA，也称为护栏准确率），这是在每个数据集中的所有示例上定义的，作为护栏性能的整体指标。'
- en: 'Table 2: Performance of GuardAgent in safeguarding EHRAgent on EICU-AC and
    SeeAct on Mind2Web-SC, compared with two model-based baselines with GPT-4 and
    Llama3, respectively.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：GuardAgent在保护EICU-AC上的EHRAgent和Mind2Web-SC上的SeeAct方面的表现，与基于GPT-4和Llama3的两个模型基线进行比较。
- en: '|  | EHRAgent on EICU-AC | SeeAct on Mind2Web-SC |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '|  | EHRAgent在EICU-AC上 | SeeAct在Mind2Web-SC上 |'
- en: '|  | LPA $\uparrow$ |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '|  | LPA $\uparrow$ |'
- en: '| Llama3 | 92.1 | 95.4 | 88.9 | 41.4 | 76.5 | 93.4 | 57.0 | 57.0 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| Llama3 | 92.1 | 95.4 | 88.9 | 41.4 | 76.5 | 93.4 | 57.0 | 57.0 |'
- en: '| GPT-4 | 97.5 | 95.3 | 100.0 | 67.9 | 82.5 | 100.0 | 65.0 | 65.0 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | 97.5 | 95.3 | 100.0 | 67.9 | 82.5 | 100.0 | 65.0 | 65.0 |'
- en: '| GuardAgent | 98.7 | 100.0 | 97.5 | 97.5 | 90.0 | 100.0 | 80.0 | 80.0 |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| GuardAgent | 98.7 | 100.0 | 97.5 | 97.5 | 90.0 | 100.0 | 80.0 | 80.0 |'
- en: '![Refer to caption](img/73c80dac04353c3caa3143ae56ef0d6d.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/73c80dac04353c3caa3143ae56ef0d6d.png)'
- en: 'Figure 3: Left: A failure case of the GPT-4 baseline where the same column
    name (‘patientunitstayid’) shared by different databases cannot be effectively
    distinguished. Right: A failure case of GuardAgent where a rule violation is not
    detected due to the overwhelming details in the query.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：左侧：GPT-4 基线的一个失败案例，其中不同数据库共享相同的列名（‘patientunitstayid’），无法有效区分。右侧：GuardAgent
    的一个失败案例，由于查询中的细节过多，未能检测到规则违规。
- en: 5.2 Guardrail Performance
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 Guardrail 性能
- en: 'In Tab. [2](#S5.T2 "Table 2 ‣ Evaluation metrics ‣ 5.1 Setup ‣ 5 Experiments
    ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning"),
    we show the performance of GuardAgent compared with the baselines using our comprehensive
    evaluation metrics. GuardAgent achieves better LPAs than the two baselines with
    also clear gaps in CCAs, showing the advantage of ‘agent guarding agents’ over
    ‘model guarding agents’. We attribute this advantage to our design of reasoning-based
    code generation and execution, which is clearly infeasible by guardrail models.
    In many failure cases of GPT-4 on EICU-AC, we found that guardrails based on natural
    language cannot effectively distinguish column names if they are shared by different
    databases. For example, in Fig. [3](#S5.F3 "Figure 3 ‣ Evaluation metrics ‣ 5.1
    Setup ‣ 5 Experiments ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via
    Knowledge-Enabled Reasoning"), the entire database ‘vitalperiodic’ that contains
    a column named ‘patientunitstayid’ is not accessible to ‘general administration’,
    while the column with the same name in the database ‘patient’ is accessible to
    the same role. In this case, the model-based guardrail using GPT-4 fails to determine
    the column ‘patientunitstayid’ in the database ‘vitalperiodic’ as ‘inaccessible’.
    In contrast, our GuardAgent based on code generation accurately converts each
    database and its columns into a dictionary, effectively avoiding such ambiguity
    in column names.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '在表 [2](#S5.T2 "Table 2 ‣ Evaluation metrics ‣ 5.1 Setup ‣ 5 Experiments ‣ GuardAgent:
    Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning") 中，我们展示了
    GuardAgent 与基线模型相比的性能。GuardAgent 在 LPA 上优于两个基线模型，并且在 CCA 上也有明显差距，显示出‘代理保护代理’相比于‘模型保护代理’的优势。我们将这一优势归因于我们基于推理的代码生成和执行设计，这在
    guardrail 模型中显然不可行。在 GPT-4 在 EICU-AC 上的许多失败案例中，我们发现基于自然语言的 guardrails 无法有效区分如果列名由不同数据库共享。例如，在图
    [3](#S5.F3 "Figure 3 ‣ Evaluation metrics ‣ 5.1 Setup ‣ 5 Experiments ‣ GuardAgent:
    Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning") 中，包含名为‘patientunitstayid’的列的整个数据库‘vitalperiodic’对于‘一般管理’不可访问，而在数据库‘patient’中具有相同名称的列对同一角色是可访问的。在这种情况下，使用
    GPT-4 的模型基础 guardrail 未能将数据库‘vitalperiodic’中的列‘patientunitstayid’确定为‘不可访问’。相比之下，我们基于代码生成的
    GuardAgent 能准确地将每个数据库及其列转换为字典，有效避免了列名的这种模糊性。'
- en: 'On the right of Fig. [3](#S5.F3 "Figure 3 ‣ Evaluation metrics ‣ 5.1 Setup
    ‣ 5 Experiments ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning"), we show a typical failure case of GuardAgent where the violated rule
    is undetected. We found that the query failed to be connected to the designated
    rule in the first step of the chain-of-thought reasoning during task planning,
    possibly due to the overwhelming details in the query. However, this issue can
    be mitigated by involving more demonstrations with better linguistic diversity,
    or using more powerful LLM as the core reasoning step.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '在图 [3](#S5.F3 "Figure 3 ‣ Evaluation metrics ‣ 5.1 Setup ‣ 5 Experiments ‣
    GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning")
    的右侧，我们展示了 GuardAgent 的一个典型失败案例，其中违规规则未被检测到。我们发现查询在任务规划过程中链式思维的第一步未能连接到指定规则，这可能是由于查询中的细节过多。然而，通过涉及更多具有更好语言多样性的示例，或使用更强大的
    LLM 作为核心推理步骤，可以缓解这一问题。'
- en: 'Table 3: Breakdown of GuardAgent results over the three roles in EICU-AC and
    the six rules in Mind2Web-SC. GuardAgent performs uniformly well for all roles
    and rules except for rule 5 related to movies, music, and videos.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：GuardAgent 在 EICU-AC 上的三种角色和 Mind2Web-SC 上的六条规则的结果分解。GuardAgent 在所有角色和规则上表现均匀良好，除了与电影、音乐和视频相关的规则
    5。
- en: '|  | EHRAgent on EICU-AC | SeeAct on Mind2Web-SC |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '|  | EHRAgent 在 EICU-AC 上 | SeeAct 在 Mind2Web-SC 上 |'
- en: '|  | physician | nursing | GA | rule 1 | rule 2 | rule 3 | rule 4 | rule 5
    | rule 6 |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '|  | 医生 | 护士 | GA | 规则 1 | 规则 2 | 规则 3 | 规则 4 | 规则 5 | 规则 6 |'
- en: '| LPA $\uparrow$ | 97.9 | 98.2 | 100.0 | 89.5 | 91.7 | 87.5 | 83.3 | 52.4 |
    83.3 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| LPA $\uparrow$ | 97.9 | 98.2 | 100.0 | 89.5 | 91.7 | 87.5 | 83.3 | 52.4 |
    83.3 |'
- en: '| CCA $\uparrow$ | 95.7 | 96.4 | 100.0 | 89.5 | 91.7 | 87.5 | 83.3 | 52.4 |
    83.3 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| CCA $\uparrow$ | 95.7 | 96.4 | 100.0 | 89.5 | 91.7 | 87.5 | 83.3 | 52.4 |
    83.3 |'
- en: 5.3 Ablation Studies
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 消融研究
- en: Breakdown results
  id: totrans-98
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 结果分析
- en: 'In Tab. [3](#S5.T3 "Table 3 ‣ 5.2 Guardrail Performance ‣ 5 Experiments ‣ GuardAgent:
    Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning"), we show
    LPA and CCA of GuardAgent for a) EHRAgent for each role of EICU-AC and b) SeeAct
    for each rule of EICU-AC (by only considering positive examples). In general,
    GuardAgent performances uniformly well for the three roles in EICU-AC and the
    six rules in Mind2Web-SC except for rule 5 related to movies, music, and videos.
    We find that all the failure cases for this rule are similar to the one illustrated
    in Fig. [3](#S5.F3 "Figure 3 ‣ Evaluation metrics ‣ 5.1 Setup ‣ 5 Experiments
    ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning")
    where the query cannot be related to the rule during reasoning. Still, GuardAgent
    demonstrates relatively strong capabilities in handling complex guard requests
    with high diversity.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在表 [3](#S5.T3 "表 3 ‣ 5.2 护栏性能 ‣ 5 实验 ‣ GuardAgent：通过知识驱动推理来保护 LLM 代理") 中，我们展示了
    GuardAgent 对 a) 每个 EICU-AC 角色的 EHRAgent 和 b) 每条 EICU-AC 规则的 SeeAct 的 LPA 和 CCA（仅考虑正面示例）。总体而言，GuardAgent
    在 EICU-AC 的三个角色和 Mind2Web-SC 的六条规则中表现均匀良好，除了与电影、音乐和视频相关的规则 5。我们发现该规则的所有失败案例类似于图
    [3](#S5.F3 "图 3 ‣ 评估指标 ‣ 5.1 设置 ‣ 5 实验 ‣ GuardAgent：通过知识驱动推理来保护 LLM 代理") 中所示的情况，即查询在推理过程中无法与规则相关联。然而，GuardAgent
    在处理多样化的复杂护栏请求方面仍展现出相对强大的能力。
- en: Influence of number of demonstrations
  id: totrans-100
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 演示数量的影响
- en: 'We vary the number of demonstrations used by GuardAgent and show the corresponding
    LPAs and CCAs in Fig. [4](#S5.F4 "Figure 4 ‣ Influence of number of demonstrations
    ‣ 5.3 Ablation Studies ‣ 5 Experiments ‣ GuardAgent: Safeguard LLM Agents by a
    Guard Agent via Knowledge-Enabled Reasoning"). The results show that GuardAgent
    can achieve descent guardrail performance with very few shots of demonstrations.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们改变了 GuardAgent 使用的演示数量，并在图 [4](#S5.F4 "图 4 ‣ 演示数量的影响 ‣ 5.3 消融研究 ‣ 5 实验 ‣ GuardAgent：通过知识驱动推理来保护
    LLM 代理") 中展示了相应的 LPA 和 CCA。结果表明，GuardAgent 在演示次数很少的情况下仍能取得不错的护栏性能。
- en: '![Refer to caption](img/2ac232c95eff0418bbddce0d0d4c89fa.png)![Refer to caption](img/5995145a9c8467921a1f4fd187ba095e.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/2ac232c95eff0418bbddce0d0d4c89fa.png)![参见标题](img/5995145a9c8467921a1f4fd187ba095e.png)'
- en: 'Figure 4: Performance of GuardAgent with different numbers of demonstrations
    on EICU-AC and Mind2Web-SC. GuardAgent is effective with very few demonstrations.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：GuardAgent 在 EICU-AC 和 Mind2Web-SC 上表现不同数量的演示。GuardAgent 在演示数量很少的情况下仍然有效。
- en: 5.4 Code-Based Guardrail is the Natural Preference of LLMs, but Tools are Needed
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 基于代码的护栏是 LLMs 的自然偏好，但仍需要工具
- en: 'We consider a challenging task where GuardAgent is instructed to generate guardrail
    code, but is provided with neither a) the functions needed for the guard requests
    nor b) demonstrations for guardrail code generation. Specifically, the guardrail
    code is now generated by $C^{\prime}={\rm LLM}(I_{c}(\mathcal{F}^{\prime}),I_{i},I_{o},P)$
    represents the toolbox without the required functions. In this case, GuardAgent
    either defines the required functions or produces procedural code towards the
    same goal (see App. [H](#A8 "Appendix H Function Defined by GuardAgent in Zero-Shot
    Setting ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning") for an example guardrail function generated by GuardAgent), and has
    achieved a 90.8% LPA with a 96.1% CCA on EICU-AC. These results support the need
    for the list of callable functions and the demonstrations as our key design for
    the code generation step. They also demonstrate a decent zero-shot generalization
    capability of GuardAgent to address new guard requests.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们考虑了一个具有挑战性的任务，其中 GuardAgent 被指示生成护栏代码，但没有提供 a) 生成护栏请求所需的函数，也没有 b) 生成护栏代码的示例。具体来说，护栏代码现在由
    $C^{\prime}={\rm LLM}(I_{c}(\mathcal{F}^{\prime}),I_{i},I_{o},P)$ 生成，表示没有所需函数的工具箱。在这种情况下，GuardAgent
    要么定义所需的函数，要么产生面向相同目标的过程性代码（请参见附录 [H](#A8 "附录 H GuardAgent 在零样本设置下定义的函数 ‣ GuardAgent：通过知识驱动推理保护
    LLM 代理的 Guard Agent") 中由 GuardAgent 生成的示例护栏函数），并且在 EICU-AC 上取得了 90.8% 的 LPA 和
    96.1% 的 CCA。这些结果支持我们设计代码生成步骤的关键需要，即可调用函数列表和示例。它们也展示了 GuardAgent 解决新护栏请求的良好零样本泛化能力。
- en: Moreover, we consider an even more challenging guardrail task. We use the GPT-4
    model to safeguard EHRAgent on EICU-AC, but remove all instructions related to
    code generation. In other words, the LLM has to figure out its way, either with
    or without code generation, to provide a guardrail. Interestingly, we find that
    for 68.0% examples in EICU-AC, the LLM chose to generate a code-based guardrail
    (though mostly inexecutable). This result shows the intrinsic tendency of LLMs
    to utilize code as a structured and precise method for guardrail, supporting our
    design of GuardAgent based on code generation.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们考虑了一个更具挑战性的护栏任务。我们使用 GPT-4 模型在 EICU-AC 上保护 EHRAgent，但移除了所有与代码生成相关的指令。换句话说，LLM
    必须在有无代码生成的情况下自行找到提供护栏的方法。有趣的是，我们发现 EICU-AC 中 68.0% 的示例中，LLM 选择生成基于代码的护栏（尽管大多数情况下无法执行）。这一结果表明
    LLM 本质上倾向于利用代码作为结构化且精确的护栏方法，支持我们基于代码生成的 GuardAgent 设计。
- en: 6 Conclusion
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: In this paper, we present the first study on guardrails for LLM agents to address
    diverse user safety requests. We propose GuardAgent, the first LLM agent framework
    designed to safeguard other LLM agents. GuardAgent leverages knowledge-enabled
    reasoning capabilities of LLMs to generate a task plan and convert it into a guardrail
    code. It is featured by the generalization capabilities to new guardrail requests,
    the reliability of the code-based guardrail, and the low computational overhead.
    In addition, we propose two benchmarks for evaluating privacy-related access control
    and safety control of LLM agents for healthcare and the web, respectively. We
    show that GuardAgent outperforms ‘model guarding agent’ baselines on these two
    benchmarks and the code generalization capabilities of GuardAgent under zero-shot
    settings.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们首次研究了 LLM 代理的护栏，以解决多样化的用户安全请求。我们提出了 GuardAgent，这是第一个旨在保护其他 LLM 代理的 LLM
    代理框架。GuardAgent 利用 LLM 的知识驱动推理能力生成任务计划并将其转化为护栏代码。其特点包括对新护栏请求的泛化能力、基于代码的护栏的可靠性以及较低的计算开销。此外，我们提出了两个基准，用于评估
    LLM 代理在医疗保健和网络中的隐私相关访问控制和安全控制。我们表明，GuardAgent 在这两个基准测试上优于“模型保护代理”基线，并且在零样本设置下，GuardAgent
    的代码泛化能力表现优异。
- en: References
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Guardrails AI. [https://www.guardrailsai.com/](https://www.guardrailsai.com/),
    2023.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Guardrails AI. [https://www.guardrailsai.com/](https://www.guardrailsai.com/),
    2023.'
- en: '[2] Mahyar Abbasian, Iman Azimi, Amir M. Rahmani, and Ramesh Jain. Conversational
    health agents: A personalized llm-powered agent framework, 2024.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Mahyar Abbasian, Iman Azimi, Amir M. Rahmani, 和 Ramesh Jain. 会话健康代理：一个个性化的
    LLM 驱动代理框架，2024。'
- en: '[3] Can Cui, Zichong Yang, Yupeng Zhou, Yunsheng Ma, Juanwu Lu, Lingxi Li,
    Yaobin Chen, Jitesh Panchal, and Ziran Wang. Personalized autonomous driving with
    large language models: Field experiments, 2024.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Can Cui, Zichong Yang, Yupeng Zhou, Yunsheng Ma, Juanwu Lu, Lingxi Li,
    Yaobin Chen, Jitesh Panchal, 和 Ziran Wang. 个性化自动驾驶与大语言模型：现场实验，2024。'
- en: '[4] Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang,
    Huan Sun, and Yu Su. Mind2web: Towards a generalist agent for the web, 2023.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang,
    Huan Sun, 和 Yu Su. Mind2web: 朝着面向网络的通用代理迈进，2023。'
- en: '[5] Izzeddin Gur, Hiroki Furuta, Austin V Huang, Mustafa Safdari, Yutaka Matsuo,
    Douglas Eck, and Aleksandra Faust. A real-world webagent with planning, long context
    understanding, and program synthesis. In The Twelfth International Conference
    on Learning Representations, 2024.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Izzeddin Gur, Hiroki Furuta, Austin V Huang, Mustafa Safdari, Yutaka Matsuo,
    Douglas Eck, 和 Aleksandra Faust. 一个具有规划、长期上下文理解和程序合成的现实世界 webagent。在第十二届国际学习表征会议，2024。'
- en: '[6] Wencheng Han, Dongqian Guo, Cheng-Zhong Xu, and Jianbing Shen. Dme-driver:
    Integrating human decision logic and 3d scene perception in autonomous driving,
    2024.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Wencheng Han, Dongqian Guo, Cheng-Zhong Xu, 和 Jianbing Shen. Dme-driver:
    将人类决策逻辑与 3D 场景感知相结合的自动驾驶系统，2024。'
- en: '[7] Hakan Inan, Kartikeya Upasani, Jianfeng Chi, Rashi Rungta, Krithika Iyer,
    Yuning Mao, Michael Tontchev, Qing Hu, Brian Fuller, Davide Testuggine, and Madian
    Khabsa. Llama guard: Llm-based input-output safeguard for human-ai conversations,
    2023.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Hakan Inan, Kartikeya Upasani, Jianfeng Chi, Rashi Rungta, Krithika Iyer,
    Yuning Mao, Michael Tontchev, Qing Hu, Brian Fuller, Davide Testuggine, 和 Madian
    Khabsa. Llama guard: 基于 Llm 的输入输出保护机制用于人类与 AI 对话，2023。'
- en: '[8] Ye Jin, Xiaoxi Shen, Huiling Peng, Xiaoan Liu, Jingli Qin, Jiayang Li,
    Jintao Xie, Peizhong Gao, Guyue Zhou, and Jiangtao Gong. Surrealdriver: Designing
    generative driver agent simulation framework in urban contexts based on large
    language model, 2023.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Ye Jin, Xiaoxi Shen, Huiling Peng, Xiaoan Liu, Jingli Qin, Jiayang Li,
    Jintao Xie, Peizhong Gao, Guyue Zhou, 和 Jiangtao Gong. Surrealdriver: 基于大语言模型设计的城市环境下生成型驾驶代理模拟框架，2023。'
- en: '[9] Alyssa Lees, Vinh Q. Tran, Yi Tay, Jeffrey Sorensen, Jai Gupta, Donald
    Metzler, and Lucy Vasserman. A new generation of perspective api: Efficient multilingual
    character-level transformers. In Proceedings of the 28th ACM SIGKDD Conference
    on Knowledge Discovery and Data Mining, 2022.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Alyssa Lees, Vinh Q. Tran, Yi Tay, Jeffrey Sorensen, Jai Gupta, Donald
    Metzler, 和 Lucy Vasserman. 新一代的 Perspective API：高效的多语言字符级变换器。在第28届 ACM SIGKDD
    知识发现与数据挖掘会议论文集，2022。'
- en: '[10] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir
    Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel,
    Sebastian Riedel, and Douwe Kiela. Retrieval-augmented generation for knowledge-intensive
    nlp tasks. In Proceedings of the 34th International Conference on Neural Information
    Processing Systems, 2020.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir
    Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel,
    Sebastian Riedel, 和 Douwe Kiela. 基于检索增强生成的知识密集型 NLP 任务。在第34届国际神经信息处理系统大会论文集，2020。'
- en: '[11] Junkai Li, Siyu Wang, Meng Zhang, Weitao Li, Yunghwei Lai, Xinhui Kang,
    Weizhi Ma, and Yang Liu. Agent hospital: A simulacrum of hospital with evolvable
    medical agents, 2024.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Junkai Li, Siyu Wang, Meng Zhang, Weitao Li, Yunghwei Lai, Xinhui Kang,
    Weizhi Ma, 和 Yang Liu. Agent hospital: 一个具有可进化医疗代理的医院模拟系统，2024。'
- en: '[12] Jiageng Mao, Junjie Ye, Yuxi Qian, Marco Pavone, and Yue Wang. A language
    agent for autonomous driving. 2023.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Jiageng Mao, Junjie Ye, Yuxi Qian, Marco Pavone, 和 Yue Wang. 用于自动驾驶的语言代理。2023。'
- en: '[13] Todor Markov, Chong Zhang, Sandhini Agarwal, Tyna Eloundou, Teddy Lee,
    Steven Adler, Angela Jiang, and Lilian Weng. A holistic approach to undesired
    content detection in the real world. In AAAI, 2023.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Todor Markov, Chong Zhang, Sandhini Agarwal, Tyna Eloundou, Teddy Lee,
    Steven Adler, Angela Jiang, 和 Lilian Weng. 针对现实世界中不良内容检测的整体方法。在 AAAI，2023。'
- en: '[14] Tom J Pollard, Alistair E W Johnson, Jesse D Raffa, Leo A Celi, Roger G
    Mark, and Omar Badawi. The eicu collaborative research database, a freely available
    multi-center database for critical care research. Scientific Data, 2018.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Tom J Pollard, Alistair E W Johnson, Jesse D Raffa, Leo A Celi, Roger
    G Mark, 和 Omar Badawi. eicu 协作研究数据库，一个免费提供的多中心重症护理研究数据库。Scientific Data，2018。'
- en: '[15] Xiangyu Qi, Yi Zeng, Tinghao Xie, Pin-Yu Chen, Ruoxi Jia, Prateek Mittal,
    and Peter Henderson. Fine-tuning aligned language models compromises safety, even
    when users do not intend to! In The Twelfth International Conference on Learning
    Representations, 2024.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Xiangyu Qi, Yi Zeng, Tinghao Xie, Pin-Yu Chen, Ruoxi Jia, Prateek Mittal,
    和 Peter Henderson. 微调对齐语言模型会妨碍安全，即使用户没有意图！ 在第十二届国际学习表征会议，2024。'
- en: '[16] Traian Rebedea, Razvan Dinu, Makesh Narsimhan Sreedhar, Christopher Parisien,
    and Jonathan Cohen. NeMo guardrails: A toolkit for controllable and safe LLM applications
    with programmable rails. In Proceedings of the 2023 Conference on Empirical Methods
    in Natural Language Processing: System Demonstrations, December 2023.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Traian Rebedea, Razvan Dinu, Makesh Narsimhan Sreedhar, Christopher Parisien,
    和 Jonathan Cohen。NeMo guardrails: 用于可控和安全LLM应用的可编程轨道工具包。在2023年自然语言处理实证方法会议：系统演示文稿论文集中，2023年12月。'
- en: '[17] Wenqi Shi, Ran Xu, Yuchen Zhuang, Yue Yu, Jieyu Zhang, Hang Wu, Yuanda
    Zhu, Joyce Ho, Carl Yang, and May D. Wang. Ehragent: Code empowers large language
    models for few-shot complex tabular reasoning on electronic health records, 2024.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Wenqi Shi, Ran Xu, Yuchen Zhuang, Yue Yu, Jieyu Zhang, Hang Wu, Yuanda
    Zhu, Joyce Ho, Carl Yang, 和 May D. Wang。Ehragent: 代码赋能大型语言模型在电子健康记录上的少量复杂表格推理，2024年。'
- en: '[18] Tao Tu, Anil Palepu, Mike Schaekermann, Khaled Saab, Jan Freyberg, Ryutaro
    Tanno, Amy Wang, Brenna Li, Mohamed Amin, Nenad Tomasev, Shekoofeh Azizi, Karan
    Singhal, Yong Cheng, Le Hou, Albert Webson, Kavita Kulkarni, S Sara Mahdavi, Christopher
    Semturs, Juraj Gottweis, Joelle Barral, Katherine Chou, Greg S Corrado, Yossi
    Matias, Alan Karthikesalingam, and Vivek Natarajan. Towards conversational diagnostic
    ai, 2024.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Tao Tu, Anil Palepu, Mike Schaekermann, Khaled Saab, Jan Freyberg, Ryutaro
    Tanno, Amy Wang, Brenna Li, Mohamed Amin, Nenad Tomasev, Shekoofeh Azizi, Karan
    Singhal, Yong Cheng, Le Hou, Albert Webson, Kavita Kulkarni, S Sara Mahdavi, Christopher
    Semturs, Juraj Gottweis, Joelle Barral, Katherine Chou, Greg S Corrado, Yossi
    Matias, Alan Karthikesalingam, 和 Vivek Natarajan。迈向对话式诊断AI，2024年。'
- en: '[19] Boxin Wang, Weixin Chen, Hengzhi Pei, Chulin Xie, Mintong Kang, Chenhui
    Zhang, Chejian Xu, Zidi Xiong, Ritik Dutta, Rylan Schaeffer, et al. Decodingtrust:
    A comprehensive assessment of trustworthiness in gpt models. 2023.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Boxin Wang, Weixin Chen, Hengzhi Pei, Chulin Xie, Mintong Kang, Chenhui
    Zhang, Chejian Xu, Zidi Xiong, Ritik Dutta, Rylan Schaeffer 等。Decodingtrust: 对GPT模型信任度的全面评估，2023年。'
- en: '[20] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter,
    Fei Xia, Ed H. Chi, Quoc V Le, and Denny Zhou. Chain of thought prompting elicits
    reasoning in large language models. In Advances in Neural Information Processing
    Systems, 2022.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter,
    Fei Xia, Ed H. Chi, Quoc V Le, 和 Denny Zhou。思维链提示在大型语言模型中的推理引发。在神经信息处理系统进展会议上，2022年。'
- en: '[21] Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming
    Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, Xiao Wang,
    Limao Xiong, Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou, Xiangyang Liu,
    Zhangyue Yin, Shihan Dou, Rongxiang Weng, Wensen Cheng, Qi Zhang, Wenjuan Qin,
    Yongyan Zheng, Xipeng Qiu, Xuanjing Huang, and Tao Gui. The rise and potential
    of large language model based agents: A survey, 2023.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming
    Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, Xiao Wang,
    Limao Xiong, Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou, Xiangyang Liu,
    Zhangyue Yin, Shihan Dou, Rongxiang Weng, Wensen Cheng, Qi Zhang, Wenjuan Qin,
    Yongyan Zheng, Xipeng Qiu, Xuanjing Huang, 和 Tao Gui。基于大型语言模型的代理的崛起与潜力：综述，2023年。'
- en: '[22] Qisen Yang, Zekun Wang, Honghui Chen, Shenzhi Wang, Yifan Pu, Xin Gao,
    Wenhao Huang, Shiji Song, and Gao Huang. Llm agents for psychology: A study on
    gamified assessments, 2024.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Qisen Yang, Zekun Wang, Honghui Chen, Shenzhi Wang, Yifan Pu, Xin Gao,
    Wenhao Huang, Shiji Song, 和 Gao Huang。心理学中的LLM代理：关于游戏化评估的研究，2024年。'
- en: '[23] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan,
    and Yuan Cao. ReAct: Synergizing reasoning and acting in language models. In International
    Conference on Learning Representations (ICLR), 2023.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan,
    和 Yuan Cao。ReAct: 语言模型中的推理与行动协同。在国际学习表征会议（ICLR），2023年。'
- en: '[24] Yangyang Yu, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Denghui Zhang,
    Rong Liu, Jordan W. Suchow, and Khaldoun Khashanah. Finmem: A performance-enhanced
    llm trading agent with layered memory and character design, 2023.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Yangyang Yu, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Denghui Zhang,
    Rong Liu, Jordan W. Suchow, 和 Khaldoun Khashanah。Finmem: 具有分层记忆和角色设计的性能增强LLM交易代理，2023年。'
- en: '[25] Tongxin Yuan, Zhiwei He, Lingzhong Dong, Yiming Wang, Ruijie Zhao, Tian
    Xia, Lizhen Xu, Binglin Zhou, Li Fangqi, Zhuosheng Zhang, Rui Wang, and Gongshen
    Liu. R-judge: Benchmarking safety risk awareness for LLM agents. In ICLR 2024
    Workshop on Large Language Model (LLM) Agents, 2024.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Tongxin Yuan, Zhiwei He, Lingzhong Dong, Yiming Wang, Ruijie Zhao, Tian
    Xia, Lizhen Xu, Binglin Zhou, Li Fangqi, Zhuosheng Zhang, Rui Wang, 和 Gongshen
    Liu。R-judge: 对LLM代理的安全风险意识基准测试。在ICLR 2024大型语言模型（LLM）代理研讨会上，2024年。'
- en: '[26] Zhuowen Yuan, Zidi Xiong, Yi Zeng, Ning Yu, Ruoxi Jia, Dawn Song, and
    Bo Li. Rigorllm: Resilient guardrails for large language models against undesired
    content. In ICML, 2024.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Zhuowen Yuan, Zidi Xiong, Yi Zeng, Ning Yu, Ruoxi Jia, Dawn Song, and
    Bo Li. Rigorllm: 对抗不期望内容的大型语言模型的弹性护栏。在ICML, 2024。'
- en: '[27] Boyuan Zheng, Boyu Gou, Jihyung Kil, Huan Sun, and Yu Su. Gpt-4v(ision)
    is a generalist web agent, if grounded. arXiv preprint arXiv:2401.01614, 2024.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Boyuan Zheng, Boyu Gou, Jihyung Kil, Huan Sun, and Yu Su. Gpt-4v(ision)是一个通用的网页代理，如果有实地验证的话。arXiv预印本arXiv:2401.01614,
    2024。'
- en: '[28] Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar,
    Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, et al. Webarena: A realistic
    web environment for building autonomous agents. arXiv preprint arXiv:2307.13854,
    2023.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar,
    Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon等人。Webarena: 用于构建自主代理的真实网页环境。arXiv预印本arXiv:2307.13854,
    2023。'
- en: Limitations
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 限制
- en: While GuardAgent performs well on the two benchmarks with also evidence of its
    generalization capabilities, it requires the core LLM to have descent reasoning
    capabilities. This limitation is due to the complexity of both the guardrail tasks
    and the target agent to be safeguarded. However, this limitation can be mitigated
    as current LLMs are becoming more and more powerful in reasoning.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管GuardAgent在这两个基准测试中表现良好，并且有证据表明其泛化能力，但它要求核心LLM具备合理的推理能力。这一限制由于护栏任务和目标代理的复杂性而产生。然而，随着当前LLM在推理能力上的不断提升，这一限制可以得到缓解。
- en: Broader Impacts
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更广泛的影响
- en: We propose GuardAgent with potentially positive social impacts. GuardAgent is
    the first LLM agent framework that safeguards other LLM agents. GuardAgent directly
    addresses the safety and trustworthiness concerns of LLM agents and will potentially
    inspire more advanced guardrail approaches for LLM agents.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出了GuardAgent，具有潜在的积极社会影响。GuardAgent是第一个保护其他LLM代理的LLM代理框架。GuardAgent直接解决了LLM代理的安全性和可信度问题，并可能激发更多先进的LLM代理保护方法。
- en: Appendix A Details About the EICU-AC Benchmark
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录A 关于EICU-AC基准的详细信息
- en: A.1 Role-Based Access Permission
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 基于角色的访问权限
- en: 'For the EICU-AC benchmark, we consider three roles: ‘physician’, ‘nursing’,
    and ‘general administration’. These roles are selected based on our understanding
    of the ICU environment. Although various other roles exist, we focus on these
    three roles due to their prevalence, ensuring sufficient queries relevant to each
    role when creating the benchmark.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 对于EICU-AC基准，我们考虑了三种角色：‘医生’，‘护理’，和‘总管理’。这些角色是基于我们对ICU环境的理解选择的。虽然存在其他各种角色，但我们专注于这三种角色，因为它们的普遍性，确保在创建基准时有足够与每个角色相关的查询。
- en: '![Refer to caption](img/8302923ed12a8631a183f737bb9ef269.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8302923ed12a8631a183f737bb9ef269.png)'
- en: (a) List of all databases and columns.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 所有数据库和列的列表。
- en: '![Refer to caption](img/dc6f3380f192041a3dd15613c3d9c167.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/dc6f3380f192041a3dd15613c3d9c167.png)'
- en: (b) Databases and columns accessible by ‘physician’.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: (b) ‘医生’可访问的数据库和列。
- en: '![Refer to caption](img/7545ecc90a0b980b94d3243f91923b37.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/7545ecc90a0b980b94d3243f91923b37.png)'
- en: (c) Databases and columns accessible by ‘nursing’.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: (c) ‘护理’可访问的数据库和列。
- en: empty space
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 空白
- en: '![Refer to caption](img/ee6c7d2ff9b1ee7baae9209d012c00d3.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ee6c7d2ff9b1ee7baae9209d012c00d3.png)'
- en: (d) Databases and columns accessible by ‘general administration’.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: (d) ‘总管理’可访问的数据库和列。
- en: 'Figure 5: Databases and columns accessible to the three roles defined for EICU-AC,
    and the complete list of databases and columns for reference. Accessible columns
    and inaccessible columns for each role are marked in green while inaccessible
    ones are shaded.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '图5: 访问EICU-AC定义的三种角色的数据库和列的列表，以及参考的完整数据库和列列表。每个角色可访问的列和不可访问的列用绿色标记，而不可访问的列用阴影标出。'
- en: 'For each role, we select a subset of accessible databases and columns from
    the EICU benchmark, as shown in Fig. [5](#A1.F5 "Figure 5 ‣ A.1 Role-Based Access
    Permission ‣ Appendix A Details About the EICU-AC Benchmark ‣ GuardAgent: Safeguard
    LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning"). Our selection rule
    is to query ChatGPT about the access permission for the three roles over each
    database. For example, for the ‘diagnosis’ database with four columns, ‘patientunitstayid’,
    ‘icd9code’, ‘diagnosisname’, and ‘diagnosistime’, we query ChatGPT using the prompt
    shown in Fig. [6](#A1.F6 "Figure 6 ‣ A.1 Role-Based Access Permission ‣ Appendix
    A Details About the EICU-AC Benchmark ‣ GuardAgent: Safeguard LLM Agents by a
    Guard Agent via Knowledge-Enabled Reasoning"). ChatGPT responds with the recommended
    access permission (‘full access’, ‘limited access’, or ‘no access’) for each role
    to each of the four columns. Here, we follow all ‘full access’ and ‘no access’
    recommendations by ChatGPT. For ‘limited access’, we set it to ‘no access’ if
    it is recommended for ‘physician’ or ‘nursing’; if it is recommended for ‘general
    administration’, we set it to ‘full access’. This is to ensure both ‘physician’
    and ‘nursing’ roles have sufficient inaccessible databases so that there will
    be sufficient queries that should be denied in the ground truth (to achieve relatively
    balanced labeling for both roles).'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '对于每个角色，我们从 EICU 基准中选择一个可访问的数据库和列子集，如图 [5](#A1.F5 "图 5 ‣ A.1 基于角色的访问权限 ‣ 附录
    A EICU-AC 基准的详细信息 ‣ GuardAgent: 通过知识启用推理保护 LLM 代理") 所示。我们的选择规则是查询 ChatGPT 关于每个数据库中三个角色的访问权限。例如，对于包含四列的‘diagnosis’数据库，‘patientunitstayid’，‘icd9code’，‘diagnosisname’，和‘diagnosistime’，我们使用图
    [6](#A1.F6 "图 6 ‣ A.1 基于角色的访问权限 ‣ 附录 A EICU-AC 基准的详细信息 ‣ GuardAgent: 通过知识启用推理保护
    LLM 代理") 中所示的提示查询 ChatGPT。ChatGPT 会回复每个角色对四列中每一列的推荐访问权限（‘完全访问’，‘有限访问’或‘无访问’）。在这里，我们遵循
    ChatGPT 的所有‘完全访问’和‘无访问’建议。对于‘有限访问’，如果推荐给‘医生’或‘护理’角色，我们将其设置为‘无访问’；如果推荐给‘一般管理’，我们将其设置为‘完全访问’。这样可以确保‘医生’和‘护理’角色都有足够的不可访问数据库，以便在真实情况下有足够的查询应被拒绝（以实现两个角色相对平衡的标记）。'
- en: '![Refer to caption](img/5352df1e474bdd18d66b5ca3bc00af93.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/5352df1e474bdd18d66b5ca3bc00af93.png)'
- en: 'Figure 6: Our prompt to ChatGPT for the access permission for the three roles
    to the ‘diagnosis’ database (with four columns, ‘patientunitstayid’, ‘icd9code’,
    ‘diagnosisname’, and ‘diagnosistime’), and the responses of ChatGPT.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：我们向 ChatGPT 提问关于三个角色对‘diagnosis’数据库（包含四列，‘patientunitstayid’，‘icd9code’，‘diagnosisname’，和‘diagnosistime’）的访问权限的提示，以及
    ChatGPT 的回应。
- en: A.2 Sampling from EICU
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 从 EICU 采样
- en: 'As mentioned in the main paper, each example in EICU-AC contains 1) a healthcare-related
    question and the correct answer, 2) the databases and the columns required to
    answer the question, 3) a user identity, 4) a binary label (either ‘0’ for ‘access
    granted’ and ‘1’ for ‘access denied’), and 5) databases and the columns required
    to answer the question but not accessible for the given role (if there are any).
    The examples in EICU-AC are created by sampling from the original EICU dataset
    following the steps below. First, from the 580 test examples in EICU, we obtain
    183 examples that are correctly responded to by EHRAgent with GPT-4 at temperature
    zero. For each of these examples, we manually check the code generated by EHRAgent
    to obtain the databases and columns required to answer the question. Second, we
    assign the three roles to each example, which gives 549 examples in total. We
    label these examples by checking if any of the required databases or columns are
    inaccessible to the given role (i.e., by comparing with the access permission
    for each role in Fig. [5](#A1.F5 "Figure 5 ‣ A.1 Role-Based Access Permission
    ‣ Appendix A Details About the EICU-AC Benchmark ‣ GuardAgent: Safeguard LLM Agents
    by a Guard Agent via Knowledge-Enabled Reasoning")). This will lead to a highly
    imbalanced dataset with 136, 110, and 48 examples labeled ‘0’ for ‘physician’,
    ‘nursing’, and ‘general administration’, respectively, and 47, 73, and 135 examples
    labeled ‘1’ for ‘physician’, ‘nursing’, and ‘general administration’, respectively.
    In the third step, we remove some of the 549 created examples to a) achieve a
    better balance between the labels and b) reduce the duplication of questions among
    these examples. We notice that for ‘general administration’, there are many more
    examples labeled ‘1’ than ‘0’, while for the other two roles, there are many more
    examples labeled ‘0’ than ‘1’. Thus, for each example with ‘general administration’
    and label ‘1’, we remove it if any of the two examples with the same question
    for the other two roles are labeled ‘1’. Then, for each example with ‘nursing’
    and label ‘1’, we remove it if any example with the same question for ‘physician’
    is labeled ‘1’. Similarly, we remove each example with ‘physician’ and label ‘0’
    if any of the two examples with the same question for the other two roles are
    also labeled ‘0’. Then for each example with ‘nursing’ and label ‘0’, we remove
    it if any example with the same question for ‘general administration’ is labeled
    ‘0’. After this step, we have 41, 78, and 48 examples labeled ‘0’ for ‘physician’,
    ‘nursing’, and ‘general administration’, respectively, and 47, 41, and 62 examples
    labeled ‘1’ for ‘physician’, ‘nursing’, and ‘general administration’, respectively.
    Finally, we randomly remove some examples for ‘nursing’ with label ‘0’ and ‘general
    administration’ with label ‘1’, and randomly add some examples for the other four
    categories (‘physician’ with label ‘0’, ‘general administration’ with label ‘0’,
    ‘physician’ with label ‘1’, and ‘nursing’ with label ‘1’) to achieve a better
    balance. The added examples are generated based on the questions from the training
    set²²2In the original EICU dataset, both the training set and the test set do
    not contain the ground truth answer for each question. The ground truth answers
    in the test set of EICU are provided by Shi et al. [[17](#bib.bib17)]. of the
    original EICU benchmark. The ultimate number of examples in our created EICU-AC
    benchmark is 316, with the distribution of examples across the three roles and
    two labels displayed in Tab [4](#A1.T4 "Table 4 ‣ A.2 Sampling from EICU ‣ Appendix
    A Details About the EICU-AC Benchmark ‣ GuardAgent: Safeguard LLM Agents by a
    Guard Agent via Knowledge-Enabled Reasoning").'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '如主论文中提到的，EICU-AC 中的每个示例包含 1) 一个与医疗保健相关的问题及其正确答案，2) 回答问题所需的数据库和列，3) 用户身份，4)
    一个二元标签（‘0’ 表示‘访问授权’，‘1’ 表示‘访问拒绝’），以及 5) 回答问题所需但该角色无法访问的数据库和列（如果有的话）。EICU-AC 中的示例是通过以下步骤从原始
    EICU 数据集中抽样创建的。首先，从 EICU 中的 580 个测试示例中，我们获得了 183 个由 EHRAgent 使用 GPT-4 在温度为零时正确响应的示例。对于这些示例中的每一个，我们手动检查
    EHRAgent 生成的代码，以获取回答问题所需的数据库和列。第二，我们将三个角色分配给每个示例，总共得到了 549 个示例。我们通过检查所需的数据库或列是否对给定角色不可访问来标记这些示例（即，通过与图
    [5](#A1.F5 "Figure 5 ‣ A.1 Role-Based Access Permission ‣ Appendix A Details About
    the EICU-AC Benchmark ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via
    Knowledge-Enabled Reasoning")中每个角色的访问权限进行比较）。这将导致一个高度不平衡的数据集，其中‘physician’、‘nursing’
    和‘general administration’的标签为‘0’的示例分别为 136、110 和 48，而标签为‘1’的示例分别为 47、73 和 135。在第三步中，我们移除了一些
    549 个创建的示例，以 a) 实现标签之间的更好平衡，b) 减少这些示例中问题的重复。我们注意到，对于‘general administration’，标签为‘1’的示例远多于标签为‘0’的示例，而对于其他两个角色，标签为‘0’的示例远多于标签为‘1’的示例。因此，对于每个带有‘general
    administration’和标签为‘1’的示例，如果其他两个角色中相同问题的两个示例都标记为‘1’，我们将其移除。然后，对于每个带有‘nursing’和标签为‘1’的示例，如果‘physician’中相同问题的示例标记为‘1’，我们将其移除。同样地，如果其他两个角色中相同问题的两个示例也标记为‘0’，我们将每个带有‘physician’和标签为‘0’的示例移除。然后，对于每个带有‘nursing’和标签为‘0’的示例，如果‘general
    administration’中相同问题的示例标记为‘0’，我们将其移除。经过这一步后，我们得到了 41、78 和 48 个标签为‘0’的示例分别对应于‘physician’、‘nursing’和‘general
    administration’，以及 47、41 和 62 个标签为‘1’的示例分别对应于‘physician’、‘nursing’和‘general administration’。最后，我们随机移除一些标签为‘0’的‘nursing’示例和标签为‘1’的‘general
    administration’示例，并随机添加一些其他四个类别（‘physician’标签为‘0’，‘general administration’标签为‘0’，‘physician’标签为‘1’，‘nursing’标签为‘1’）的示例，以实现更好的平衡。这些添加的示例是基于原始
    EICU 基准的训练集问题生成的。最终，我们创建的 EICU-AC 基准中的示例数量为 316，三个角色和两个标签的示例分布显示在表 [4](#A1.T4
    "Table 4 ‣ A.2 Sampling from EICU ‣ Appendix A Details About the EICU-AC Benchmark
    ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning")
    中。'
- en: 'Table 4: Number of examples in EICU-AC for each role and each label.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：EICU-AC 中每个角色和每个标签的示例数量。
- en: '|  | physician | nursing | general administration |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '|  | 医生 | 护理 | 一般管理 |'
- en: '| label ‘0’ (access denied) | 52 | 57 | 45 |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| 标签 ‘0’（访问拒绝） | 52 | 57 | 45 |'
- en: '| label ‘1’ (access granted) | 46 | 55 | 61 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 标签 ‘1’（访问授权） | 46 | 55 | 61 |'
- en: A.3 Healthcare Questions Involved in EICU-AC
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.3 涉及 EICU-AC 的医疗问题
- en: As mentioned in the main paper, our created EICU-AC dataset involves healthcare
    questions spanning 50 different ICU information categories, i.e., columns across
    all 10 databases of the EICU benchmark. We further categorize the questions in
    EICU-AC following the ‘template’ provided by EICU (extracted from the ‘q_tag’
    entry of each example [[17](#bib.bib17)]). This gives 70 different question templates,
    showing the high diversity of healthcare questions involved in our EICU-AC benchmark.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 如主文中所述，我们创建的 EICU-AC 数据集涉及 50 个不同的 ICU 信息类别，即 EICU 基准的所有 10 个数据库中的列。我们进一步根据
    EICU 提供的 ‘模板’ 对 EICU-AC 中的问题进行分类（从每个示例的 ‘q_tag’ 条目中提取 [[17](#bib.bib17)]）。这生成了
    70 种不同的问题模板，显示了我们 EICU-AC 基准中涉及的医疗问题的高度多样性。
- en: 'Table 5: Number of examples labeled ‘1’ in Mind2Web-SC for each rule violation.
    Note that examples labeled ‘0’ do not violate any rules.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：Mind2Web-SC 中标记为 ‘1’ 的示例数量，按每个规则违规情况分类。注意，标记为 ‘0’ 的示例不违反任何规则。
- en: '| Safety rules | No. examples |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 安全规则 | 示例数量 |'
- en: '| Rule 1: User must be a member to shop. | 19 |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 规则 1：用户必须是会员才能购物。 | 19 |'
- en: '| Rule 2: Unvaccinated user cannot book a flight | 12 |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 规则 2：未接种疫苗的用户不能预订航班 | 12 |'
- en: '| Rule 3: User without a driver’s license cannot buy or rent a car. | 24 |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 规则 3：没有驾驶执照的用户不能买车或租车。 | 24 |'
- en: '| Rule 4: User aged under 18 cannot book a hotel. | 18 |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| 规则 4：未满 18 岁的用户不能预订酒店。 | 18 |'
- en: '| Rule 5: User must be in certain countries to search movies/musics/video.
    | 21 |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 规则 5：用户必须在某些国家才能搜索电影/音乐/视频。 | 21 |'
- en: '| Rule 6: User under 15 cannot apply for jobs. | 6 |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 规则 6：未满 15 岁的用户不能申请工作。 | 6 |'
- en: Appendix B Details About the Mind2Web-SC Benchmark
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 关于 Mind2Web-SC 基准的详细信息
- en: 'In Sec. [3.2](#S3.SS2 "3.2 SeeAct and Mind2Web-SC Benchmark ‣ 3 Safety Requests
    for Diverse LLM Agents ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via
    Knowledge-Enabled Reasoning"), we have defined six safety rules for the Mind2Web-SC
    Benchmark. Rule 1 requires ‘membership’ in the user information to be ‘true’.
    Rule 2 requires ‘vaccine’ in the user information to be ‘true’. Rule 3 requires
    ‘dr_license’ in the user information to be ‘true’. Rule 4 requires ‘age’ in the
    user information to be no less than 18. Rule 5 requires ‘domestic’ in the user
    information to be ‘true’. Rule 6 requires ‘age’ in the user information to be
    no less than 15. In Tab. [5](#A1.T5 "Table 5 ‣ A.3 Healthcare Questions Involved
    in EICU-AC ‣ Appendix A Details About the EICU-AC Benchmark ‣ GuardAgent: Safeguard
    LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning"), we show the number
    of examples labeled ‘1’ in Mind2Web-SC for each rule violation. Note that examples
    labeled ‘0’ do not violate any rules.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 [3.2](#S3.SS2 "3.2 SeeAct 和 Mind2Web-SC 基准 ‣ 3 安全请求的多样化 LLM 代理 ‣ GuardAgent：通过知识驱动推理保护
    LLM 代理的守护代理") 节中，我们定义了 Mind2Web-SC 基准的六条安全规则。规则 1 要求用户信息中的 ‘membership’ 为 ‘true’。规则
    2 要求用户信息中的 ‘vaccine’ 为 ‘true’。规则 3 要求用户信息中的 ‘dr_license’ 为 ‘true’。规则 4 要求用户信息中的
    ‘age’ 不小于 18。规则 5 要求用户信息中的 ‘domestic’ 为 ‘true’。规则 6 要求用户信息中的 ‘age’ 不小于 15。在表 [5](#A1.T5
    "Table 5 ‣ A.3 涉及 EICU-AC 的医疗问题 ‣ 附录 A 关于 EICU-AC 基准的详细信息 ‣ GuardAgent：通过知识驱动推理保护
    LLM 代理的守护代理") 中，我们展示了 Mind2Web-SC 中标记为 ‘1’ 的示例数量，按每个规则违规情况分类。注意，标记为 ‘0’ 的示例不违反任何规则。
- en: 'During the construction of Mind2Web-SC, we added some examples with label ‘1’
    and removed some examples with label ‘0’ to balance the two classes. By only following
    the steps in Sec. [3.2](#S3.SS2 "3.2 SeeAct and Mind2Web-SC Benchmark ‣ 3 Safety
    Requests for Diverse LLM Agents ‣ GuardAgent: Safeguard LLM Agents by a Guard
    Agent via Knowledge-Enabled Reasoning") without any adding or removal of examples,
    we obtain a highly imbalanced dataset with 178 examples labeled ‘0’ and only 70
    examples labeled ‘1’. Among the 178 examples labeled ‘0’, there are 148 examples
    with the tasks irrelevant to any of the rules – we keep 50 of them and remove
    the other $(148-50=)$ 98 examples. All 30 examples labeled ‘0’ but related to
    at least one rule are also kept. Then, we create 30 examples labeled ‘1’ by reusing
    the tasks for these 30 examples labeled ‘0’. We keep generating random user profiles
    for these tasks until the task-related rule is violated, and the example is labeled
    to ‘1’. Note that the tasks are randomly selected but manually controlled to avoid
    duplicated tasks within one class. Similarly, we created 20 examples labeled ‘0’
    by reusing the tasks for examples labeled ‘1’, with randomly generated user information
    without any rule violation. Finally, we obtain the Mind2Web-SC dataset with 100
    examples in each class (200 examples in total). Among the 100 examples labeled
    ‘0’, 50 are related to at least one of the rules.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '在Mind2Web-SC的构建过程中，我们添加了一些标签为‘1’的示例，并移除了一些标签为‘0’的示例，以平衡这两个类别。仅按照第[3.2节](#S3.SS2
    "3.2 SeeAct 和 Mind2Web-SC 基准 ‣ 3 多样化LLM代理的安全请求 ‣ GuardAgent: 通过知识启用推理保护LLM代理")中的步骤，不添加或移除任何示例，我们获得了一个高度不平衡的数据集，其中178个示例标记为‘0’，仅70个示例标记为‘1’。在178个标记为‘0’的示例中，有148个示例的任务与任何规则无关——我们保留了其中50个，移除了其他$(148-50=)$
    98个示例。所有30个标记为‘0’但与至少一个规则相关的示例也被保留。然后，我们通过重用这些30个标记为‘0’的示例的任务，创建了30个标记为‘1’的示例。我们继续为这些任务生成随机用户配置文件，直到任务相关规则被违反，示例被标记为‘1’。请注意，这些任务是随机选择的，但经过手动控制以避免在一个类别内重复任务。类似地，我们通过重用标记为‘1’的示例的任务，创建了20个标记为‘0’的示例，生成的用户信息是随机的且没有规则违规。最终，我们获得了每个类别各100个示例的Mind2Web-SC数据集（共200个示例）。在100个标记为‘0’的示例中，有50个与至少一个规则相关。'
- en: Appendix C Detailed System Prompts for Naive Access Control and Safety Control
    Based on Instructions
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录C 基于指令的原始访问控制和安全控制的详细系统提示
- en: 'In our preliminary studies, We created a naive access control for EHRAgent
    and a naive safety control for SeeAct by directly modifying their system prompts
    for planning. These approaches are either ineffective in safeguarding the agents
    or degrade the benign performance of the agents. In Fig. [7](#A3.F7 "Figure 7
    ‣ Appendix C Detailed System Prompts for Naive Access Control and Safety Control
    Based on Instructions ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via
    Knowledge-Enabled Reasoning"), we show the instructions we injected into the system
    prompts of these two agents.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '在我们的初步研究中，我们通过直接修改EHRAgent和SeeAct的系统提示来创建了原始访问控制和原始安全控制。这些方法要么在保护代理方面无效，要么降低了代理的良性表现。在图[7](#A3.F7
    "图7 ‣ 附录C 基于指令的原始访问控制和安全控制的详细系统提示 ‣ GuardAgent: 通过知识启用推理保护LLM代理")中，我们展示了我们注入到这两个代理系统提示中的指令。'
- en: '![Refer to caption](img/491736f6b413fa6ed881a5a927591b9b.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/491736f6b413fa6ed881a5a927591b9b.png)'
- en: 'Figure 7: Instructions injected into the system prompt of EHRAgent for access
    control and SeeAct for safety control, as naive baselines that motivate our GuardAgent.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：注入到EHRAgent的系统提示中的指令用于访问控制，注入到SeeAct中的指令用于安全控制，作为激发我们GuardAgent的原始基线。
- en: Appendix D Complete Inputs and Output of GuardAgent
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录D GuardAgent的完整输入和输出
- en: Complete Inputs to GuardAgent
  id: totrans-182
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 完整输入到GuardAgent
- en: 'As described in Sec. [4.2](#S4.SS2 "4.2 Task Planning ‣ 4 GuardAgent Framework
    ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning"),
    the inputs to GuardAgent include a specification $I_{s}$ for both EHRAgent on
    EICU-AC and SeeAct on Mind2Web.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '如第[4.2节](#S4.SS2 "4.2 任务规划 ‣ 4 GuardAgent 框架 ‣ GuardAgent: 通过知识启用推理保护LLM代理")中所述，GuardAgent的输入包括EHRAgent在EICU-AC和SeeAct在Mind2Web上的规格$
    I_{s} $。'
- en: '![Refer to caption](img/4286078723f752ac6ca482a511f8e670.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/4286078723f752ac6ca482a511f8e670.png)'
- en: 'Figure 8: The actual planning instruction $I_{p}$ we used in our experiments
    for the two agents, EHRAgent and SeeAct, and the two benchmarks, EICU-AC and Mind2Web-SC.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：我们在实验中为两个代理EHRAgent和SeeAct，以及两个基准EICU-AC和Mind2Web-SC使用的实际规划指令$ I_{p} $。
- en: '![Refer to caption](img/8f6486fd8575b7b246f688b1ec5037dd.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8f6486fd8575b7b246f688b1ec5037dd.png)'
- en: 'Figure 9: Examples for target agent inputs $I_{i}$, as the inputs to GuardAgent,
    for the two agents, EHRAgent and SeeAct, and the two benchmarks, EICU-AC and Mind2Web-SC.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：作为 GuardAgent 输入的目标代理输入 $I_{i}$ 的示例，涉及两个代理 EHRAgent 和 SeeAct，以及两个基准 EICU-AC
    和 Mind2Web-SC。
- en: Outputs of GuardAgent
  id: totrans-188
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: GuardAgent 的输出
- en: 'The intermediate outputs of GuardAgent, including the generated action plan
    $P$ of GuardAgent for both benchmarks in Fig. [10](#A4.F10 "Figure 10 ‣ Outputs
    of GuardAgent ‣ Appendix D Complete Inputs and Output of GuardAgent ‣ GuardAgent:
    Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning").'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: GuardAgent 的中间输出，包括图 [10](#A4.F10 "图 10 ‣ GuardAgent 的输出 ‣ 附录 D GuardAgent 的完整输入和输出
    ‣ GuardAgent：通过知识启用推理的保护代理来保护 LLM 代理") 中的 GuardAgent 为两个基准生成的行动计划 $P$。
- en: '![Refer to caption](img/755e94f4c8e5a5c8e4711c2ea7b8ddde.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/755e94f4c8e5a5c8e4711c2ea7b8ddde.png)'
- en: 'Figure 10: Example outputs of GuardAgent, including the label prediction $O_{l}$,
    and the final answer/action of the target agent with guardrail, for the two agents,
    EHRAgent and SeeAct, and the two benchmarks, EICU-AC and Mind2Web-SC.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：GuardAgent 的示例输出，包括标签预测 $O_{l}$ 和目标代理的最终答案/行动及保护措施，涉及两个代理 EHRAgent 和 SeeAct，以及两个基准
    EICU-AC 和 Mind2Web-SC。
- en: Appendix E Callable Functions
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 E 可调用函数
- en: 'Our experiments involve two callable functions shown in Fig. [11](#A5.F11 "Figure
    11 ‣ Appendix E Callable Functions ‣ GuardAgent: Safeguard LLM Agents by a Guard
    Agent via Knowledge-Enabled Reasoning"). However, the user of GuardAgent can easily
    extend the toolbox by uploading more functions. The actual toolbox of GuardAgent
    in practice will contain much more callable functions than for our experiments.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实验涉及图 [11](#A5.F11 "图 11 ‣ 附录 E 可调用函数 ‣ GuardAgent：通过知识启用推理的保护代理来保护 LLM 代理")
    中展示的两个可调用函数。然而，GuardAgent 的用户可以通过上传更多函数轻松扩展工具箱。实际上，GuardAgent 的工具箱中将包含比我们实验中更多的可调用函数。
- en: '![Refer to caption](img/730def30ea05787e2c7ba5f00ba2bb30.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/730def30ea05787e2c7ba5f00ba2bb30.png)'
- en: 'Figure 11: Callable functions in the toolbox of GuardAgent involved in our
    experiments.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11：在我们实验中涉及的 GuardAgent 工具箱中的可调用函数。
- en: Appendix F Prompts for Baselines
  id: totrans-196
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 F 基线提示
- en: 'In the main experiments, we compare GuardAgent with two baselines using LLMs
    to safeguard LLM agents. The guardrail is created by prompting the LLM with a
    system instruction, the specification of the target agent, the guard requests,
    the user inputs to the target agent with the associated output logs, and a few
    show of examples. Here the system instruction is adapted from the one used by
    GuardAgent for task planning. However, we include additional instructions about
    the format of the guardrail outputs. The baselines do not involve any guardrail
    code generation, and this is reflected by the demonstrations we created that generate
    guardrails solely based on reasoning over the textual inputs to the LLM. In Fig.
    [12](#A6.F12 "Figure 12 ‣ Appendix F Prompts for Baselines ‣ GuardAgent: Safeguard
    LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning"), we show the modified
    system prompt template for the baselines, with two example demonstrations for
    the two benchmarks, respectively.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在主要实验中，我们将 GuardAgent 与两个基线进行比较，这些基线使用 LLMs 来保护 LLM 代理。保护措施通过提示 LLM 以系统指令、目标代理的规范、保护请求、用户对目标代理的输入及其相关输出日志、以及一些示例来创建。这里的系统指令是从
    GuardAgent 用于任务规划的指令中改编而来的。不过，我们包含了有关保护措施输出格式的额外指令。基线不涉及任何保护措施代码生成，这从我们创建的演示中可以看出，这些演示完全基于对
    LLM 的文本输入进行推理来生成保护措施。在图 [12](#A6.F12 "图 12 ‣ 附录 F 基线提示 ‣ GuardAgent：通过知识启用推理的保护代理来保护
    LLM 代理") 中，我们展示了基线的修改后的系统提示模板，并分别提供了两个基准的两个示例演示。
- en: '![Refer to caption](img/f75236610746d70ce5807685c27dc2f9.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/f75236610746d70ce5807685c27dc2f9.png)'
- en: 'Figure 12: System prompt template for the baselines and the two example demonstrations
    for EICU-AC and Mind2Web-SC, respectively.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12：基线的系统提示模板以及 EICU-AC 和 Mind2Web-SC 的两个示例演示。
- en: Appendix G Manually Created Demonstrations
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 G 手动创建的演示
- en: 'We manually created a set of demonstrations for each benchmark. In Fig. [13](#A7.F13
    "Figure 13 ‣ Appendix G Manually Created Demonstrations ‣ GuardAgent: Safeguard
    LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning"), we show two example
    demonstrations for EHRAgent on EICU-AC and SeeAct on Mind2Web-SC, respectively.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '我们为每个基准手动创建了一组演示。在图 [13](#A7.F13 "图 13 ‣ 附录 G 手动创建的演示 ‣ GuardAgent: 通过知识驱动推理保护
    LLM 代理") 中，我们展示了 EHRAgent 在 EICU-AC 上和 SeeAct 在 Mind2Web-SC 上的两个示例演示。'
- en: '![Refer to caption](img/970959359a48659be685094d2b204434.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/970959359a48659be685094d2b204434.png)'
- en: 'Figure 13: Example demonstrations for EHRAgent on EICU-AC and SeeAct on Mind2Web-SC.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13：EHRAgent 在 EICU-AC 和 SeeAct 在 Mind2Web-SC 上的示例演示。
- en: Appendix H Function Defined by GuardAgent in Zero-Shot Setting
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 H GuardAgent 在零样本设置中定义的函数
- en: 'In the zero-shot setting where GuardAgent is provided with neither the required
    functions nor demonstrations for guardrail code generation, GuardAgent can still
    generate guardrails by defining new functions. In Fig. [14](#A8.F14 "Figure 14
    ‣ Appendix H Function Defined by GuardAgent in Zero-Shot Setting ‣ GuardAgent:
    Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning"), we show
    a function defined by GuardAgent during guardrail code generation. The function
    differs from those we provided in Fig. [11](#A5.F11 "Figure 11 ‣ Appendix E Callable
    Functions ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning"), but it achieves the same guardrail goals.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '在零样本设置中，GuardAgent 没有提供所需函数或守护代码生成的示例，但仍可以通过定义新函数生成守护功能。在图 [14](#A8.F14 "图
    14 ‣ 附录 H GuardAgent 在零样本设置中定义的函数 ‣ GuardAgent: 通过知识驱动推理保护 LLM 代理") 中，我们展示了 GuardAgent
    在生成守护代码时定义的一个函数。该函数与图 [11](#A5.F11 "图 11 ‣ 附录 E 可调用函数 ‣ GuardAgent: 通过知识驱动推理保护
    LLM 代理") 中提供的函数不同，但实现了相同的守护目标。'
- en: '![Refer to caption](img/0d03957c47b492aafbe1cc589dbf291d.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/0d03957c47b492aafbe1cc589dbf291d.png)'
- en: 'Figure 14: A function defined by GuardAgent in zero-shot setting with neither
    demonstrations for code generation nor required functions'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14：在零样本设置中，GuardAgent 定义的一个函数，既没有代码生成的示例也没有所需函数
- en: Appendix I Execution Time of GuardAgent
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 I GuardAgent 的执行时间
- en: The average execution time for GuardAgent (with GPT-4) safeguarding EHRAgent
    on EICU-AC is 45.4 seconds per example, while the average execution time for EHRAgent
    (with GPT-4) is 31.9 seconds per example. The average execution time for GuardAgent
    (with GPT-4) safeguarding SeeAct on Mind2Web-SC is about 60 seconds per example,
    while the average execution time for EHRAgent (with LLaVA-1.5) is about 20 seconds
    per example. In general, the execution time for GuardAgent is comparable to the
    execution time of the target agent. Moreover, human inspectors will likely need
    much more time than our GuardAgent to read the guard requests and then moderate
    the inputs and outputs of the target agent correspondingly. Given the effectiveness
    of our GuardAgent as shown in the experiments, we believe that GuardAgent is the
    current best for safeguarding LLM agents.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: GuardAgent（使用 GPT-4）在 EICU-AC 上保护 EHRAgent 的平均执行时间为每个示例 45.4 秒，而 EHRAgent（使用
    GPT-4）的平均执行时间为每个示例 31.9 秒。GuardAgent（使用 GPT-4）在 Mind2Web-SC 上保护 SeeAct 的平均执行时间约为每个示例
    60 秒，而 EHRAgent（使用 LLaVA-1.5）的平均执行时间约为每个示例 20 秒。一般来说，GuardAgent 的执行时间与目标代理的执行时间相当。此外，人类检查员在阅读守护请求、然后相应地调整目标代理的输入和输出时，可能需要比我们的
    GuardAgent 更多的时间。鉴于实验显示我们 GuardAgent 的有效性，我们相信 GuardAgent 是当前保护 LLM 代理的最佳选择。
