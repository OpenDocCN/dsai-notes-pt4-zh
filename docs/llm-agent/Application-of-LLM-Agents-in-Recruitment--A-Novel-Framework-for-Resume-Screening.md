<!--yml
category: 未分类
date: 2025-01-11 12:57:35
-->

# Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening

> 来源：[https://arxiv.org/html/2401.08315/](https://arxiv.org/html/2401.08315/)

Chengguang Gan¹  Qinghao Zhang²  Tatsunori Mori¹
¹Yokohama National University, Japan
gan-chengguan-pw@ynu.jp, tmori@ynu.ac.jp
²Department of Information Convergence Engineering,
Pusan National University, South Korea
zhangqinghao@pusan.ac.kr

###### Abstract

The automation of resume screening is a crucial aspect of the recruitment process in organizations. Automated resume screening systems often encompass a range of natural language processing (NLP) tasks. This paper introduces a novel Large Language Models (LLMs) based agent framework for resume screening, aimed at enhancing efficiency and time management in recruitment processes. Our framework is distinct in its ability to efficiently summarize and grade each resume from a large dataset. Moreover, it utilizes LLM agents for decision-making. To evaluate our framework, we constructed a dataset from actual resumes and simulated a resume screening process. Subsequently, the outcomes of the simulation experiment were compared and subjected to detailed analysis. The results demonstrate that our automated resume screening framework is 11 times faster than traditional manual methods. Furthermore, by fine-tuning the LLMs, we observed a significant improvement in the F1 score, reaching 87.73%, during the resume sentence classification phase. In the resume summarization and grading phase, our fine-tuned model surpassed the baseline performance of the GPT-3.5 model Ouyang et al. ([2022](https://arxiv.org/html/2401.08315v2#bib.bib26)). Analysis of the decision-making efficacy of the LLM agents in the final offer stage further underscores the potential of LLM agents in transforming resume screening processes.

Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening

Chengguang Gan¹  Qinghao Zhang²  Tatsunori Mori¹ ¹Yokohama National University, Japan gan-chengguan-pw@ynu.jp, tmori@ynu.ac.jp ²Department of Information Convergence Engineering, Pusan National University, South Korea zhangqinghao@pusan.ac.kr

## 1 Introduction

![Refer to caption](img/65e1aec69da9900584df5357625188f1.png)

Figure 1: The Process of automated resume screening.

Resume screening is a crucial aspect of recruitment for all companies, particularly larger ones, where it becomes a labor-intensive and time-consuming endeavor. In contrast to smaller firms, a large corporation might receive thousands of resumes during a hiring phase, making efficient screening of these numerous applications a significant challenge. To reduce labor costs associated with resume screening, developing an automated framework is essential. Utilizing natural language processing (NLP) technology for this purpose is increasingly becoming the preferred approach.

The automated resume screening Singh et al. ([2010a](https://arxiv.org/html/2401.08315v2#bib.bib29)) process encompasses two primary components: information extraction Singhal et al. ([2001](https://arxiv.org/html/2401.08315v2#bib.bib31)) and evaluation. As illustrated in Figure [1](https://arxiv.org/html/2401.08315v2#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening"), resumes typically exist as unstructured or semi-structured text, varying in format. The initial step of the automated framework is to convert this unstructured text into a structured format. This process involves a key NLP task: text classification Bayer et al. ([2022](https://arxiv.org/html/2401.08315v2#bib.bib4)), specifically sentence classification Minaee et al. ([2021](https://arxiv.org/html/2401.08315v2#bib.bib23)). It entails extracting and classifying sentences related to personal information, education, and work experience, transforming them into structured data that is easily stored and manipulated.

Upon structuring the resume text, it must then be summarized and evaluated. The lower part of Figure [1](https://arxiv.org/html/2401.08315v2#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening") depicts this process, which includes both automatic and manual screening. Manual screening involves grading and summarizing extensive sections of the resume text, after which the graded and summarized resumes are presented to HR for review, leading to the selection of qualified candidates. This approach significantly reduces the time HR personnel spend perusing resumes and deliberating decisions by shortening the resume text and implementing a grading system for ranking. The aim is to enhance the efficiency of the screening process. NLP technology can also automate this process, culminating in the output of qualified resumes.

![Refer to caption](img/98bb9f9683f27fde900633e73b6462fa.png)

Figure 2: The illustration reprehsents the process of pre-training a language model and applying the pre-trained language model to a downstream task through fine-tuning method.

In the preceding discussion, we elucidated two NLP tasks pertinent to the automated extraction of information from resumes. Addressing these tasks necessitates the employment of Language Models (LMs) . Presently, the most prevalent infrastructure for LMs is the transformer architecture Vaswani et al. ([2017](https://arxiv.org/html/2401.08315v2#bib.bib37)), distinguished by its attention mechanism. These LMs are predominantly trained on extensive corpora, endowing them with a broad spectrum of knowledge. The seq2seq (sequence-to-sequence) Sutskever et al. ([2014](https://arxiv.org/html/2401.08315v2#bib.bib33)) structure is instrumental in this context, enabling the conversion of an input sequence into a predicted output sequence. This mechanism facilitates the adaptability of LMs to a diverse range of NLP tasks.

As illustrated in Figure [2](https://arxiv.org/html/2401.08315v2#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening"), the process of LMs spans from their training to their application in various downstream NLP tasks. The initial phase involves assembling a substantial corpus for unsupervised learning, encompassing a broad array of general knowledge. This corpus is typically derived from sources such as Wikipedia ¹¹1https://www.wikipedia.org/ and extensive web content. Subsequently, these voluminous, unlabeled corpora serve as the foundation for training LMs. Through this process, LMs acquire foundational linguistic competencies and general knowledge autonomously. Following the pre-training phase, Pre-trained Language Models (PLMs) Min et al. ([2023](https://arxiv.org/html/2401.08315v2#bib.bib22)) undergo fine-tuning Ding et al. ([2023](https://arxiv.org/html/2401.08315v2#bib.bib12)) with different datasets tailored to specific downstream tasks. The culmination of this process is the development of task-specific PLMs, capable of effectively predicting or processing relevant NLP tasks.

The initial PLMs, such as BERT Devlin et al. ([2018](https://arxiv.org/html/2401.08315v2#bib.bib11)), T5 Raffel et al. ([2020](https://arxiv.org/html/2401.08315v2#bib.bib28)), and GPT-2 Radford et al. ([2019](https://arxiv.org/html/2401.08315v2#bib.bib27)), were characterized by their relatively modest size, containing only several hundred million parameters. However, the advent of GPT-3 Brown et al. ([2020](https://arxiv.org/html/2401.08315v2#bib.bib6)) marked a significant leap in this field, boasting an impressive 135 billion parameters. This escalation was not merely quantitative but also qualitative, as evidenced by the subsequent development of ChatGPT Ouyang et al. ([2022](https://arxiv.org/html/2401.08315v2#bib.bib26)). ChatGPT underscored how expanding the pre-trained corpus and increasing the parameter count of PLMs could substantially enhance their capabilities, thereby heralding a new era in the development of Large Language Models (LLMs) Zhao et al. ([2023](https://arxiv.org/html/2401.08315v2#bib.bib41)).

Despite these advancements, concerns have arisen regarding the closed-source models developed by major corporations, particularly in terms of user security. The primary issue lies in the potential for private information leakage. Utilizing these LLMs typically requires users to upload their data, creating a risk of data compromise. This is especially pertinent in applications like resume screening, where sensitive personal information is involved. In contrast to closed-source models like GPT-3.5 and GPT-4 OpenAI et al. ([2023](https://arxiv.org/html/2401.08315v2#bib.bib25)), there are open-source LLMs available, such as LLaMA1/2 Touvron et al. ([2023a](https://arxiv.org/html/2401.08315v2#bib.bib35), [b](https://arxiv.org/html/2401.08315v2#bib.bib36)). While these open-source models may not yet match the capabilities of their closed-source counterparts, they offer a significant advantage: the ability to run locally on a user’s machine. This local execution ensures greater security for private data, making these models a more secure option for handling sensitive information.

The preceding overview delineates the particular NLP tasks essential for the automated resume screening framework. Additionally, it is highlighted that the tasks, as marked by the blue blocks in Figure [1](https://arxiv.org/html/2401.08315v2#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening"), are manageable through PLMs and LLMs. A succinct explanation of the fundamental principles of LMs is also provided. Subsequent paragraphs will offer a comprehensive exposition on the implementation of an automated resume screening system utilizing agents derived from LLMs.

![Refer to caption](img/dd5d81ee821e597f79de150e853af3e1.png)

Figure 3: The illustration depict LLM as the backbone of the agent system.

Figure [3](https://arxiv.org/html/2401.08315v2#S1.F3 "Figure 3 ‣ 1 Introduction ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening") presents a schematic representation of a fundamental agent system. This diagram illustrates the segmentation of Language Model (LLM) agents into four core components: Character, Memory, Planning, and Action. Initially, the LLM agent is assigned a distinct character, essentially defining its role or function. For instance, in this study, the LLM agent is designated as an adept Human Resources (HR) professional. This role encapsulates the responsibilities and duties expected of the LLM agent. Subsequently, ’Memory’ pertains to the requisite knowledge base necessary for the agent to execute its role effectively. In the context of an HR professional, this encompasses a comprehensive understanding of employee skill requirements, salary management, and relevant laws and regulations. This aspect is analogous to an LLM’s capability to access and utilize its internal knowledge database. The next phase involves ’Planning,’ where the LLM agent strategizes the execution of tasks. This process entails decomposing a complex task into smaller, manageable subtasks, thereby enhancing the efficiency in addressing intricate assignments. This stage is indicative of an LLM’s reasoning and problem-solving abilities. Finally, the ’Action’ component represents the implementation stage. In the context of an automated resume screening system, this would involve the LLM agent filtering and selecting resumes that align with specific job requirements. This final stage exemplifies the practical application of the LLM agent’s planning and reasoning in a real-world scenario.

In this study, we integrate a LLM agent into the process of automated resume screening. We propose an innovative framework that leverages the LLM agent for automated extraction and analysis of resumes. This framework streamlines the entire process, from initial resume screening to the final selection of qualified candidates, significantly enhancing the efficiency of this task. For our analysis, we utilized a publicly available IT industry-specific resume dataset²²2[https://huggingface.co/datasets/ganchengguang/resume_seven_class](https://huggingface.co/datasets/ganchengguang/resume_seven_class), optimized for sentence classification. Through fine-tuning of the LLM, we achieved an F1 score of 87.73 in sentence classification. This improvement is particularly notable in the model’s ability to identify and exclude personal information from resumes, thereby mitigating the risk of privacy breaches when employing models like GPT-3.5/4\. Additionally, we developed an HR Agent, designed to both grade and summarize resumes. We created a specialized Grade & Summarization Resume (GSR) dataset, derived from the initial dataset, using the GPT-4 model. This GSR dataset was instrumental in evaluating other LLMs. In these evaluations, the LLaMA2-13B model, once fine-tuned, achieved a ROUGE-1 score of 37.30 in summarization and a Grade accuracy of 81.35, significantly surpassing the baseline GPT-3.5-Turbo model. Finally, we deployed the HR Agent to select suitable candidates, further analyzing the decision-making outcomes.

In addition, we conducted experiments using GPT-4-Turbo and GPT-3.5-Turbo-16k to demonstrate that LLMs are capable of processing long-context resume information effectively. To further validate the effectiveness of our proposed LLM-based resume screening framework, we randomly selected 50 resumes for manual summarization and evaluation. The performance of the LLMs was benchmarked against this manually labeled dataset. Our analysis of the experiments and specific samples indicated that LLMs’ evaluations and decisions closely resemble those of human reviewers. Additionally, to assess the framework’s ability to meet complex recruitment requirements, we incorporated additional criteria beyond the basic requirements into the framework. The decision-making outcomes were then analyzed to determine the adaptability of the LLMs to these enhanced requirements.

Our comprehensive experiments and analysis demonstrate the LLM agent’s robust capability in resume screening. As an HR agent, it effectively facilitates the candidate selection process.

## 2 Related Work

### 2.1 Resume Information Extraction

Resume screening is a classic application of information extraction, evolving from rule-based methods Mooney ([1999](https://arxiv.org/html/2401.08315v2#bib.bib24)) to the use of toolkits for automating these rules Ciravegna and Lavelli ([2004](https://arxiv.org/html/2401.08315v2#bib.bib9)). Over time, techniques such as Hidden Markov Models (HMM) and Support Vector Machines (SVM) developed into Cascaded Hybrid Models for segment classification in resumes Yu et al. ([2005](https://arxiv.org/html/2401.08315v2#bib.bib40)). The adoption of deep learning, utilizing Convolutional Neural Networks (CNNs) and Long Short-Term Memory networks (LSTMs), further enhanced extraction methods Harsha et al. ([2022](https://arxiv.org/html/2401.08315v2#bib.bib17)); Sinha et al. ([2021](https://arxiv.org/html/2401.08315v2#bib.bib32)); Kinge et al. ([2022](https://arxiv.org/html/2401.08315v2#bib.bib19)); Ali et al. ([2022](https://arxiv.org/html/2401.08315v2#bib.bib1)); Bharadwaj et al. ([2022](https://arxiv.org/html/2401.08315v2#bib.bib5)); Zu and Wang ([2019](https://arxiv.org/html/2401.08315v2#bib.bib42)); Barducci et al. ([2022](https://arxiv.org/html/2401.08315v2#bib.bib3)), with Conditional Random Fields (CRFs) improving LSTM models by refining sequence labeling Ayishathahira et al. ([2018](https://arxiv.org/html/2401.08315v2#bib.bib2)).

Recent advances incorporate pre-trained language models like BERT, integrated with LSTMs and CRFs, significantly enhancing contextual understanding for resume information extraction Tallapragada et al. ([2023](https://arxiv.org/html/2401.08315v2#bib.bib34)). This has been applied in developing algorithms for automating recruitment, with applications in ranking candidates for specific jobs Erdem ([2023](https://arxiv.org/html/2401.08315v2#bib.bib14)).

Additionally, new tools such as PROSPECT have been developed to support resume screening by extracting and ranking candidate skills and experiences using CRFs Singh et al. ([2010b](https://arxiv.org/html/2401.08315v2#bib.bib30)). Another approach involves using NLP and similarity measures to improve the efficiency of job candidate selection through automated systems that match resumes with job descriptions Daryani et al. ([2020](https://arxiv.org/html/2401.08315v2#bib.bib10)).

### 2.2 Large Language Model in Recruit Application

After the advent of LLM, there were other jobs that used LLM in the recruitment process. The work Du et al. ([2024](https://arxiv.org/html/2401.08315v2#bib.bib13)) introduces an LLM-based GANs Interactive Recommendation (LGIR) method that enhances job recommendation systems by using Generative Adversarial Networks to refine resume representations, improving the accuracy of job matching by overcoming issues of fabricated content and insufficient data. JobRecoGPT Ghosh and Sadaphal ([2023](https://arxiv.org/html/2401.08315v2#bib.bib16)) explores four job recommendation methods using LLMs to analyze unstructured job and candidate data, highlighting advantages, limitations, and efficiency in IT domain job matching.

### 2.3 Decision Making with LLM Agent

In addition, the LLM agent is employed in decision-making processes across various applications. This paper Huang et al. ([2024](https://arxiv.org/html/2401.08315v2#bib.bib18)) evaluates the decision-making capabilities of LLMs in complex multi-agent environments using a novel framework. This paper Ma et al. ([2024](https://arxiv.org/html/2401.08315v2#bib.bib21)) introduces a novel framework, Human-AI Deliberation, designed to enhance AI-assisted decision-making by fostering a deliberative dialogue between humans and AI. Chen et al. ([2023](https://arxiv.org/html/2401.08315v2#bib.bib8)) introduces "Introspective Tips," a novel approach for enhancing the decision-making capabilities of LLMs without the need for fine-tuning. Wei et al. ([2022](https://arxiv.org/html/2401.08315v2#bib.bib38)) highlights that enhanced decision-making abilities can be achieved by incorporating a series of intermediate reasoning steps. Yao et al. ([2022](https://arxiv.org/html/2401.08315v2#bib.bib39)) presents ReAct, a novel method that integrates reasoning with action generation, enhancing the synergy between language comprehension and decision-making in interactive tasks.

![Refer to caption](img/9947b52953c5a71de692eec376ecdda4.png)

Figure 4: The illustration depict the workflow of LLM agent base Automated Resume Screening Framework.

### 2.4 Compare LLM-based Resume Screening and Traditional Methods

The application of LLMs to resume screening frameworks offers significant advantages over traditional methods. Firstly, unlike PLMs which are constrained to processing a maximum of 512 tokens, LLMs can manage considerably longer texts. This capability allows LLMs to effectively handle resumes of virtually any length, enhancing the comprehensiveness of the screening process. Secondly, LLMs possess a broader knowledge base, enabling their deployment across various industries for resume data processing without the need for specific fine-tuning. Furthermore, LLMs demonstrate enhanced performance compared to traditional PLMs, providing evaluations and judgments that are more aligned with human reasoning. This makes LLMs particularly valuable in contexts where nuanced understanding and decision-making are crucial.

## 3 Resume Screening Framework Based on LLM Agents

This section provides a comprehensive overview of the workflow within an novel automated resume screening framework that utilizes a LLM agent. It focuses on the application of the LLM agent in efficiently identifying and selecting qualified resumes from a substantial pool of candidates. To maintain clarity, this overview condenses some aspects, retaining only the essential steps. Detailed discussions of these steps are presented in the subsequent three subsections.

Figure [4](https://arxiv.org/html/2401.08315v2#S2.F4 "Figure 4 ‣ 2.3 Decision Making with LLM Agent ‣ 2 Related Work ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening") illustrates the architecture of our innovative automated resume screening system, which is underpinned by a LLM agent. The process begins with the transformation of a multitude of resumes, each in disparate formats like PDF, DOCX, and TXT, into a uniform JSON format. This is achieved through a rule-based algorithm designed to standardize the diverse formatting and file types into coherent, individual sentences. Such pre-processing is crucial for enabling consistent analysis in later stages. The next step involves segmenting these uniformly formatted resumes into distinct sentences, based on criteria like line breaks. This segmentation is vital for the effective functioning of the open-source LLM, which operates locally to classify each sentence. Critical to this process is the categorization of various sentence types, ranging from personal information, which is earmarked for removal to protect privacy, to other categories like work experience, education, and skills. This categorization is particularly significant because it allows for a tailored analysis based on the specific requirements of a job position. For instance, certain roles may prioritize a candidate’s skills over their educational background. By extracting and focusing on the segments of a resume that detail relevant skills, the system can more effectively screen candidates for such positions. While our framework currently focuses primarily on the basic functionality of removing personal information, it lays the groundwork for more nuanced and customized resume screening processes in the future.

Upon removed personal information from resumes, the next step involves utilizing the GPT-3.5 model for grading and summarizing these documents. This task primarily falls under the purview of the HR agent. The grading system serves as a mechanism to rank candidates, streamlining the process of identifying top applicants. Summarization, on the other hand, is aimed at conserving time for the decision-making agent, who must evaluate these summaries. The brevity of summarized content not only expedites the process but also benefits human HR professionals by reducing the time required for initial resume screening. Once resumes are assigned grades and summaries, the decision regarding the candidates’ progression can be made either by an HR agent or a human HR professional. Utilizing grades as a comprehensive metric allows for an efficient ranking of candidates. Depending on the specific requirements, a selection of the top 10 or 100 candidates can be made for the next stage of the screening process. This step, whether performed by an HR agent or a human, significantly reduces the time and effort involved in decision-making. The final stage involves choosing candidates for interviews or extending job offers directly, based on the refined pool of qualified resumes. This method optimizes the recruitment process, ensuring efficiency and effectiveness in candidate selection.

The preceding section outlined the comprehensive procedure for automated resume screening utilizing open source LLM and LLM agents. Subsequent subsections will elaborate on the implementation of the three pivotal steps: sentence classification, grade & summarization, and decision-making.

![Refer to caption](img/eb016699f43c58120a4019ac0b873871.png)

Figure 5: The illustration depict the process of instruction tuning and RLHF for the LLaMA2 model.

### 3.1 Sentence Classification

In our methodology, the LLaMA2 model serves as the foundational base for sentence classification. We enhanced this base model through fine-tuning, specifically targeting the classification of resume sentences. Unlike previous Pretrained Language Models (PLMs), the LLaMA2 model does not straightforwardly accept a sentence as input and produce a corresponding predicted label. This limitation stems from the model’s architecture, as depicted in Figure [5](https://arxiv.org/html/2401.08315v2#S3.F5 "Figure 5 ‣ 3 Resume Screening Framework Based on LLM Agents ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening"). The LLaMA2-chat variant, developed from the original LLaMA2 model, undergoes a specialized instruction tuning process using an instruction dataset, followed by further refinement through Reinforcement Learning from Human Feedback (RLHF). This approach presents a challenge: simply inputting a sentence into the model does not guarantee the generation of the appropriate prediction label, a phenomenon also evidenced in our subsequent experimental results.

![Refer to caption](img/a542246191aa4b4f5c3fc9102842f19d.png)

Figure 6: The illustration depict the components of the converted resume sentence instruction dataset.

The underlying reason for this is the model’s design to respond according to the instruction dataset’s guidelines. To elaborate, the input not only contains the query sentence but also incorporates specific textual instructions guiding the model’s response. As illustrated in Figure [6](https://arxiv.org/html/2401.08315v2#S3.F6 "Figure 6 ‣ 3.1 Sentence Classification ‣ 3 Resume Screening Framework Based on LLM Agents ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening"), to address this, we append a question to the resume sentence requiring classification. This question instructs the model to categorize the preceding sentence into one of seven predefined labels. Alongside this, we introduce the "Answer:" prompt as part of the input text sequence. Consequently, we utilize the LLaMA2 model, fine-tuned with a specially curated resume sentence instruction dataset, for the effective classification of resume sentences. This fine-tuned LLaMA2 model demonstrates enhanced performance in the task at hand.

### 3.2 Grade & Summarization

Upon extracting the resume text with personal details redacted, our objective is to assess and encapsulate each resume. This process involves a shared component: both evaluation and summarization require a comprehensive understanding of the resume’s content. Consequently, we amalgamated these two processes into a singular question and answer task. Figure [7](https://arxiv.org/html/2401.08315v2#S3.F7 "Figure 7 ‣ 3.2 Grade & Summarization ‣ 3 Resume Screening Framework Based on LLM Agents ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening") illustrates this integration, where the red block denotes the assigned role to the LLM agent, exemplified as an HR professional in an IT firm with over a decade of HR experience. This role-play empowers the HR agent to conduct an analysis with the insight of a seasoned HR expert.

![Refer to caption](img/b0967e44c74f7b41f6f87510039f39d2.png)

Figure 7: The illustration depict assignment of roles and tasks to the LLM agent.

The initial task involves the HR agent appraising the resume, striving for precision and variety in assessment. For guidance, a scoring example (e.g., Grade: XX/100) is provided, deliberately without a predetermined score to avoid biasing the agent’s evaluation. Following this, the agent is tasked with summarizing the resume in a concise paragraph, limited to 100 words. The culmination of this process is the agent presenting both the grade and a succinct summary of the resume.

![Refer to caption](img/171f682286593ef4d2b1eed1bf20fed2.png)

Figure 8: The illustration depict the HR agent making a final Decision to select a qualified candidate.

### 3.3 Decision Making

The concluding phase of the resume screening system involves evaluating candidates based on their assigned grades and summaries. In this study, we have bifurcated this stage into two distinct processes: automatic and manual. This bifurcation allows for flexibility to cater to various requirements. Even when the ultimate selection is executed manually by human HR personnel, the highly-rated resumes can be efficiently sifted through utilizing grade rankings. Additionally, the provided summaries facilitate a rapid comprehension of the key elements in each resume by the HR staff, thereby significantly reducing the time required for resume screening.

On the other hand, the process of automated decision-making can be further pursued through the use of a LLM agent. As depicted in Figure [8](https://arxiv.org/html/2401.08315v2#S3.F8 "Figure 8 ‣ 3.2 Grade & Summarization ‣ 3 Resume Screening Framework Based on LLM Agents ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening"), each resume is initially provided with a formatted identifier, grade, and summary. This procedure simulates the selection of final candidates. Consequently, the role assignments in the red block are altered, transitioning from an experienced HR professional to a CEO. The task involves selecting one candidate out of ten, based on the provided grades and summaries. Following this, the agent will identify the chosen resume by its ID and articulate the rationale behind this particular selection.

Consequently, a multitude of resumes undergo a series of evaluative processes to identify the most suitable candidates. The automated resume screening framework employed in this process is versatile, allowing customization to meet various requirements and real-world scenarios. For instance, this research replicates the resume evaluation criteria of IT companies, which prioritize candidates’ technical skills. Accordingly, the screening process emphasizes skill-related information in the resumes. This approach is adaptable to other sectors such as Marketing, Education, Finance, etc., by modifying the keywords and criteria. Furthermore, the system can be designed to mitigate educational bias by prioritizing skills and work experience, thus focusing on the candidates’ competencies. Additionally, the framework’s screening parameters are flexible; for example, it can be set to select the top 10% of candidates based on specific criteria. In summary, this adaptability enhances the overall effectiveness and applicability of the screening framework.

## 4 Experiment Setup

In this section, we will introduce how to simulate a resume screening process to verify the effectiveness of the automated resume screening framework based on LLM agent. This includes the preparation of the resume dataset and some settings for simulating the resume screening [4.1](https://arxiv.org/html/2401.08315v2#S4.SS1 "4.1 Resume Dataset and Screening Simulation ‣ 4 Experiment Setup ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening"). The selection of LLM for the backbone of the LLM agent, and the parameter settings for model inference and fine-tuning [4.2](https://arxiv.org/html/2401.08315v2#S4.SS2 "4.2 Prepare Backbone LLMs and Parameter Sets ‣ 4 Experiment Setup ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening"). And description of the evaluation method [4.3](https://arxiv.org/html/2401.08315v2#S4.SS3 "4.3 Evaluation ‣ 4 Experiment Setup ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening").

### 4.1 Resume Dataset and Screening Simulation

In the initial phase of our study, we opted for a classification dataset comprising sentences from resumes Gan and Mori ([2022](https://arxiv.org/html/2401.08315v2#bib.bib15)). This dataset encompasses seven categories: personal information, experience, summary, education, qualification certification, skill, and objectives. It includes a total of 1,000 resumes, amounting to 78,668 sentences, predominantly from the IT sector. Thus, the simulation of resume screening in this research is contextualized within an IT company recruitment framework. And we set that the person who is used to grade each resume is an experienced HR stuff. Then, we set that the top 10 resumes of grade go to the final round of decision making. Finally, the CEO is set to screen the resume grades and summaries of these 10 candidates in order to select a final qualified candidate.

Conversely, given the lack of grade and summarization annotations in the original resume dataset, the GPT-4 model, which currently exhibits superior performance, was employed for annotating these resumes. The annotations generated by GPT-4 served as a benchmark for evaluating the performance of other models, essentially treating GPT-4’s output as a gold standard (100% performance) against which to measure other LLMs. This approach facilitated the creation of a comprehensive dataset for simulating resume screening processes. Moreover, due to the token limit of 4096 in the LLaMA2 model, resumes exceeding this token count were excluded. Consequently, a refined dataset of 838 resumes remained, which was then utilized for the second phase of testing.

To enhance the validation of our proposed resume screening framework, we randomly selected 50 resumes, which were then summarized and evaluated manually. This process mirrored the previous method of labeling using GPT-4, where each resume was concisely summarized in approximately 100 words and assessed on a 100-point scale.

We enlisted three graduate students to annotate the resumes manually. Before beginning the annotation process, these evaluators received comprehensive training and were provided with several exemplars to standardize their markings. Specifically, the summaries required detailed inclusion of the candidate’s work experience, years in the field, educational achievements (including undergraduate and graduate degrees), skills, experience at major companies, and any other notable experiences, while adhering strictly to 100 word limit.

During the grading phase, we establish specific criteria for evaluation. For instance, we consider skills that may not be directly relevant to the needs of an IT company, such as marketing management. Candidates with limited work experience typically receive grades between 50 and 65\. Conversely, candidates who possess several years of IT experience along with undergraduate and graduate degrees in computer science are usually scored within the range of 80 to 95\. Due to the inherent imprecision of the scoring process, we adopt a scoring interval of 5 points. Ultimately, the grades are averaged across three evaluators. We then review three different summaries of each resume and select the one that most accurately reflects the original document as the final labeled result.

### 4.2 Prepare Backbone LLMs and Parameter Sets

In the initial phase of the sentence classification task, the LLaMA2-7B model was chosen for fine-tuning. The dataset, comprising 78,668 sentences, was partitioned into training, validation, and testing sets in a 7:1.5:1.5 ratio. A random seed of 42 was set to ensure reproducibility. This configuration aligns with the experimental setup described in the original paper pertaining to the resume dataset, enabling direct comparisons with other PLMs. For the training process, each GPU was assigned a batch size of 32, and the model underwent training for 2 epochs using 32-bit floating-point precision.

In the subsequent phase, specifically the second stage of grading and summarization, we selected LLaMA2-7B/13/70B and GPT-3.5-turbo-0614 as the backbone LLMs for the HR agent. Initially, we employed a zero-shot methodology to grade and summarize 838 resumes using four different LLMs, aiming to assess and compare their efficacy. During this process, we meticulously configured the parameters for model generation. The maximum number of new tokens was set at 200\. This parameter choice was informed by the requirement that each resume should be graded and summarized in over 100 words. Additionally, we incorporated the ’do sample’ and ’early stopping’ features to optimize the summarization process. Except for these specific adjustments, all other parameters were maintained at their default settings.

In additional, we involved enhancing LLaMA2-7B/13B’s capabilities by fine-tuning it with a specialized dataset focused on resume grading and summarization. Initially, this dataset was partitioned into two distinct subsets: a training set with 500 resumes and a test set comprising 383 resumes. Subsequently, the model underwent a training process where each GPU was allocated a batch size of eight. This training was conducted over 2 epochs, utilizing BF16 precision to optimize performance and computational efficiency.

In conclusion, our experimental setup involved conducting the inference tests for LLaMA2-7B/13B using a dual RTX 3090 24G GPU configuration with float16 precision. In contrast, both the fine-tuning procedures for LLaMA2-7B/13B and the inference tests for LLaMA2-70B were executed on an RTX A800 80G * 8 GPU server.

### 4.3 Evaluation

In the initial phase of resume sentence classification, we utilize the F1 score as the primary evaluation metric. This score comprehensively reflects the model’s performance by harmonizing precision and recall into a balanced mean. This approach offers a more accurate representation of the model’s effectiveness.

For the resume summarization segment, our evaluation employs two predominant metrics: ROUGE-1/2/L Lin and Och ([2004](https://arxiv.org/html/2401.08315v2#bib.bib20)) and BLEU. These metrics are extensively recognized in the automatic evaluation of summarization tasks. Although BLEU is traditionally associated with translation evaluations, its application in summarization tasks provides valuable insights. By incorporating BLEU, we aim to achieve a more holistic assessment of the summarization quality.

Regarding the evaluation of grade scores, our methodology focuses on accuracy. This is particularly crucial given the significant variance in grade distribution across different models. We adopt a tolerance range approach in calculating accuracy: a generated grade is deemed accurate if it falls within a margin of ±5 from the actual grade. The calculation adheres to the following principle: if the absolute difference between the predicted and the actual grade is 5 or less, the prediction is considered correct (recorded as 1, with 0 indicating an error). To derive the final grade accuracy, we divide the total count of correct predictions by the total number of actual grades (PG is denote Predict Grade, TG is denote True Grade).

|  | $\text{Accuracy}=\frac{\sum_{i=1}^{N}\mathbf{1}\left(\left&#124;\text{PG}_{i}-\text{% TG}_{i}\right&#124;\leq 5\right)}{N}$ |  |

Table 1: Results of resume sentence classification dataset.

Model F1 Score BERT Large 86.67 ALBERT Large 86.40 RoBERTa Large 87.00 T5 Large 87.35 LLaMA2-7B-chat 78.16 LLaMA2-7B-chat (Instruction Format) 87.73

Table 2: Results of resume grade and summarization dataset (ROUGE-1/2/L).

Model ROUGE-1 ROUGE-2 ROUGE-L LLaMA2-7B 26.35 6.22 24.00 LLaMA2-13B 25.31 5.83 22.99 LLaMA2-70B 28.12 7.70 25.68 GPT-3.5-Turbo 34.75 12.34 31.92

Table 3: Results of resume grade and summarization dataset (BLEU and Grade Accuracy).

Model BLEU Grade Accuracy LLaMA2-7B 2.66 47.49 LLaMA2-13B 2.56 59.31 LLaMA2-70B 3.73 23.27 GPT-3.5-Turbo 7.31 47.61

## 5 Results

In the results of sentence classification for resumes, we conducted comparative experiments on the performances of several large-scale models: BERT Large, ALBERT Large, RoBERTa Large, and T5 Large. The results, detailed in Table [1](https://arxiv.org/html/2401.08315v2#S4.T1 "Table 1 ‣ 4.3 Evaluation ‣ 4 Experiment Setup ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening"), reveal a notable enhancement in the F1 score of the LLaMA2-7B-chat model, which reaches 87.73, attributed to the implementation of the instruction format for both input and output. Interestingly, a direct fine-tuning of the LLaMA2-7B-chat model, using the conventional approach of inputting sentences and outputting labels as done with previous PLMs, resulted in a significant drop in the F1 score to 78.16\. This outcome undergrades the efficacy of the instruction format we proposed. Furthermore, it highlights a critical consideration for fine-tuning LLMs in sentence classification tasks: adhering to the instruction format used during the instruction learning phase is crucial for optimizing the models’ sentence classification capabilities.

In the evaluation of the grading and summarization component of the automated resume screening framework, we conducted tests using three different model sizes of LLaMA2 and GPT-3.5-Turbo. The results, as presented in Table [2](https://arxiv.org/html/2401.08315v2#S4.T2 "Table 2 ‣ 4.3 Evaluation ‣ 4 Experiment Setup ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening"), indicate that GPT-3.5-Turbo outperformed the others across all three ROUGE metrics: ROUGE-1 (34.75), ROUGE-2 (12.34), and ROUGE-L (31.92), significantly surpassing the LLaMA2-70B model. Furthermore, under the BLEU evaluation metric (Table [3](https://arxiv.org/html/2401.08315v2#S4.T3 "Table 3 ‣ 4.3 Evaluation ‣ 4 Experiment Setup ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening")), GPT-3.5-Turbo achieved a score of 7.31, nearly tripling the performance of its counterparts. This suggests that, if not using the fine-tuning method (0-shot inference). Utilizing closed-source models like GPT-3.5-Turbo and GPT-4 as the backbone for HR agents is crucial for enhanced performance. Interestingly, in the aspect of grading accuracy, LLaMA2-13B outshined the other models with a score of 59.31, notably exceeding the LLaMA2-70B model by 23.27\. This anomaly and its implications will be further analyzed and discussed in the following subsection.

Table 4: Results of fine-tuned LLaMA2-7B/13B in resume grade and summarization dataset (ROUGE-1/2/L).

Model ROUGE-1 ROUGE-2 ROUGE-L GPT-3.5-Turbo 34.61 12.18 31.83 LLaMA2-7B 36.50 13.32 33.48 LLaMA2-13B 37.30 13.90 33.93

Table 5: Results of fine-tuned LLaMA2-7B/13B in resume grade and summarization dataset (BLEU and Grade Accuracy).

Model BLEU Grade Accuracy GPT-3.5-Turbo 7.40 45.24 LLaMA2-7B 8.45 76.19 LLaMA2-13B 8.62 81.35

Finally, the LLaMA2-7B/13B model was subjected to fine-tuning, yielding notable improvements as documented in Table [4](https://arxiv.org/html/2401.08315v2#S5.T4 "Table 4 ‣ 5 Results ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening"). Specifically, the refined LLaMA2-13B model demonstrated remarkable grades of 37.30, 13.90, and 33.93 in ROUGE-1/2/L metrics, respectively. This performance notably surpassed that of the 0-shot GPT-3.5 Turbo model in the test set evaluations. Furthermore, Table [5](https://arxiv.org/html/2401.08315v2#S5.T5 "Table 5 ‣ 5 Results ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening") presents the enhancements in BLEU grades, where the LLaMA2-7B and LLaMA2-13B models recorded increments to 8.45 and 8.62, respectively. Correspondingly, there was a significant improvement in grade accuracy, reaching 76.19 and 81.35 for each model. These results clearly indicate that, with adequate resume datasets for fine-tuning, opting for open-source LLaMA2-7B/13B models as the foundation for HR agent systems is a more effective strategy.

![Refer to caption](img/09d0add64296c7b0b34080cb6ab32d1e.png)

(a) Grade Distribution of LLaMA2-7B

![Refer to caption](img/bdb554087f38131e75e6e77dd9e7bfe8.png)

(b) Grade Distribution of LLaMA2-13B

![Refer to caption](img/2c3ef6187d18877edfc5d4c5a33a8972.png)

(c) Grade Distribution of LLaMA2-70B

Figure 9: Compare the Grade Distribution of LLaMA2-7B/13B/70B models.

![Refer to caption](img/329b0b8dddc420f4bff66a64cf75d703.png)

(a) Grade Distribution of GPT-3.5-Turbo

![Refer to caption](img/25b4c220302e8722701ddc0d6cd71ae6.png)

(b) Grade Distribution of GPT-4

![Refer to caption](img/590a2d953a7525504d2216d407c5a7ce.png)

(c) Comparison of 6 LLMs in grade

Figure 10: Compare the Grade Distribution of GPT-3.5-Turbo/4 models. And comparison of 6 LLMs in grade.

### 5.1 Normal Distribution of Grade

Figure [9](https://arxiv.org/html/2401.08315v2#S5.F9 "Figure 9 ‣ 5 Results ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening") & [10](https://arxiv.org/html/2401.08315v2#S5.F10 "Figure 10 ‣ 5 Results ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening") presents the normal distribution plots for the evaluations assigned by five different LLMs. Notably, the GPT-4 model generally aligns with the normal distribution across all grades, with a marked preference for assigning grades within the 85-90 range. This skew towards higher grades may stem from GPT-4’s inclination to award more favorable ratings during fine-tuning processes, such as RLHF. Despite this, the impact on final resume screening remains minimal, as the system consistently prioritizes the top 10 resumes based on grades. While there may be some uncertainty regarding the extent to which these LLM-based HR agents accurately reflect the actual quality of each resume, the simulation experiment suggests that the grading patterns of all five LLMs largely adhere to a normal distribution. This indicates that the application of LLMs in resume evaluation is a successful experiment, with outcomes mirroring those expected in real-world scenarios.

Table 6: Number of grading errors (The grade is not a two-digit number) by different LLMs.

Model Total Number of Errors LLaMA2-7B 190 LLaMA2-13B 22 LLaMA2-70B 8 LLaMA2-7B FT 1 LLaMA2-13B FT 0

![Refer to caption](img/a696afa0c699be73377afe739c2055ff.png)

Figure 11: The answer text of Decision Making with HR agents (GPT4 and GPT-3.5-Turbo Models).

![Refer to caption](img/12529e2690eedfec073cbf661907f024.png)

Figure 12: The text of Decision Making with HR agents (GPT4-Turbo Models).

The data presented in Figure [9](https://arxiv.org/html/2401.08315v2#S5.F9 "Figure 9 ‣ 5 Results ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening") & [10](https://arxiv.org/html/2401.08315v2#S5.F10 "Figure 10 ‣ 5 Results ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening") and Table [6](https://arxiv.org/html/2401.08315v2#S5.T6 "Table 6 ‣ 5.1 Normal Distribution of Grade ‣ 5 Results ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening") reveals that the three LLaMA2 models exhibit instances of zero grading. This phenomenon occurs because these models assign grades that are not exclusively two-digit grades (such as ’A’, ’B+++’, etc.), leading to misclassification. Consequently, we have classified all such instances as zero grades. It is noteworthy that the incidence of grading errors in the LLaMA2 model is significantly reduced following fine-tuning. Additionally, the GPT-3.5-Turbo/4 model demonstrates an absence of grade errors, which can be attributed to the differences in the capabilities of various LLMs in terms of understanding and adherence to instructions.

### 5.2 Analysis of Decision Making

In our study, we utilized the GPT-3.5-Turbo and GPT-4 models as autonomous HR agents to evaluate the top 10 resumes based on their grades. The rationale behind their decisions is detailed. As illustrated in Figure [11](https://arxiv.org/html/2401.08315v2#S5.F11 "Figure 11 ‣ 5.1 Normal Distribution of Grade ‣ 5 Results ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening"), both models consistently identified resume ID 308 as the top candidate. The justification for this selection was not only the high grade of resume ID 308 but also its alignment with the specific needs of an IT company, including relevant work experience and managerial skills. This analysis demonstrates a remarkable congruence with the cognitive processes and judgment criteria typically employed by human HR professionals in decision-making. Furthermore, these findings underscore the potential of integrating LLM based HR agents into future automated resume screening systems.

To further investigate the decision-making capabilities of the HR agent, particularly in handling complex recruitment requirements, we refined the criteria within this stage and conducted an additional experiment. This experiment utilized a dataset of 50 manually annotated resumes, summarized and graded for relevance. We configured the hiring criteria to target three individuals with expertise in database development. This requirement was incorporated into the input prompt template as follows: "You are now recruiting three individuals for database development roles in your company."

As depicted in Figure [12](https://arxiv.org/html/2401.08315v2#S5.F12 "Figure 12 ‣ 5.1 Normal Distribution of Grade ‣ 5 Results ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening"), the HR agent successfully identified three candidates, providing detailed justifications for each selection. Notably, all candidates demonstrated relevant database development skills and substantial professional experience. The reasoning for their selection was well-articulated and convincing. Subsequent manual review of the candidates’ resumes confirmed that these individuals were indeed the most suitable for the positions.

This experiment underscores the adaptability of the LLM-based resume screening framework, highlighting its ability to accommodate a diverse array of job specifications. It demonstrates that the model can be effectively tailored to meet varying recruitment needs of different companies for various positions, thus proving its generalizability and utility in complex HR scenarios.

Table 7: Experimental results of LLMs evaluated based on manually annotated 50 sample datasets (ROUGE-1/2/L).

Model ROUGE-1 ROUGE-2 ROUGE-L LLaMA2-7B 27.03 7.11 24.28 LLaMA2-13B 24.96 5.96 22.62 LLaMA2-70B 27.27 7.69 25.00 GPT-3.5-Turbo 34.55 12.37 31.94 GPT-4 39.87 16.44 35.89

Table 8: Experimental results of LLMs evaluated based on manually annotated 50 sample datasets (BLEU and Grade Accuracy).

Model BLEU Grade Accuracy LLaMA2-7B 3.28 22.00 LLaMA2-13B 2.71 40.00 LLaMA2-70B 3.73 38.00 GPT-3.5-Turbo 7.16 58.00 GPT-4 11.06 50.00

![Refer to caption](img/fc043c2e6821a3c5945c6660d9bed649.png)

Figure 13: Ranking comparison of top 10 GPT-4 rated resumes and top 10 manually graded resumes. Underlining represents the portion where the two overlap (i.e., the grades are equivalent).

### 5.3 Comparison with Manual Resume Screening

We conducted a thorough evaluation of various LLMs by manually annotated 50 resumes to serve as a benchmark. The results of these tests are detailed in Tables [7](https://arxiv.org/html/2401.08315v2#S5.T7 "Table 7 ‣ 5.2 Analysis of Decision Making ‣ 5 Results ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening") and [8](https://arxiv.org/html/2401.08315v2#S5.T8 "Table 8 ‣ 5.2 Analysis of Decision Making ‣ 5 Results ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening"), with the GPT-3.5-Turbo and GPT-4 models demonstrating superior performance. Notably, while the accuracy of the grade assignments was not perfect, a subsequent analysis of the top ten resumes ranked by grades revealed significant insights. The resumes that received the highest grades from GPT-4 exhibited a striking resemblance to those scored manually, underscoring the effectiveness of the model in mimicking human evaluative patterns.

As depicted in Figure [13](https://arxiv.org/html/2401.08315v2#S5.F13 "Figure 13 ‣ 5.2 Analysis of Decision Making ‣ 5 Results ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening"), we compiled the IDs and grades of the top ten resumes according to the final grades from GPT-4 and manual scoring. In this figure, underlined text indicates where the two sets of rankings overlap, highlighting a strong correlation in the evaluation outcomes. Remarkably, both manually and by GPT-4, resumes ID 801 and ID 892 received the highest grades. Furthermore, 11 out of the 12 resumes that ranked highly in the manual assessment also featured prominently in the GPT-4 rankings, further validating the model’s evaluative consistency.

Finally, we selected a final qualified resume using both manual and GPT-4 methods. Both selected resume ID 801 as the hiring candidate. Detailed analysis of this candidate’s credentials revealed not only a robust six years of professional experience but also a comprehensive repertoire of IT-related skills. The individual is a versatile full-stack Java developer, proficient in a range of technologies spanning from front-end to back-end development, including networking. This skill set renders the candidate highly suitable for a developer role within an IT organization.

In conclusion, our findings affirm the efficacy of the proposed resume screening framework that leverages LLMs. This comparison with traditional manual methods substantiates the potential for LLMs to effectively replace manual resume screening processes in the future.

![Refer to caption](img/1b9f171ed8aeebc9bc5f0d57fd97f926.png)

Figure 14: The comparison of manual and GPT-4 in grades distributions (Base 50 samples dataset).

Table 9: GPT-3.5-Turbo-16k Model experiment results. Evaluated based on GPT-4-Turbo (Max input length 128K) annotated 162 over length resume datasets .

Model ROUGE-1 ROUGE-2 ROUGE-L GPT-3.5-Turbo-16k 36.05 12.62 32.61 Model BLEU Grade Accuracy GPT-3.5-Turbo-16k 6.78 72.22

Our analysis also included a comparison between the score distributions of the most advanced GPT-4 model and manual grading. Figure [14](https://arxiv.org/html/2401.08315v2#S5.F14 "Figure 14 ‣ 5.3 Comparison with Manual Resume Screening ‣ 5 Results ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening") illustrates this comparison, revealing a high degree of similarity between the two distributions. We quantified this similarity by calculating the cosine similarity, which yielded a value of 0.9944, approaching 1\. This high similarity score further supports the consistency between GPT-4-generated grades and manual grades. This consistency is likely attributable to the model’s use of instruction tuning and reinforcement learning with human feedback (RLHF). We also computed the correlation between the two rankings using Spearman’s rho ($\rho$) and Kendall’s tau ($\tau$). The values obtained were 0.7574 for Spearman’s $\rho$ and 0.6252 for Kendall’s $\tau$, indicating a strong positive correlation between the manual rankings and the predicted rankings produced by the LLM.

### 5.4 Analysis of Long Length Resume Screening

In addition, for resumes that exceed the LLaMA2 model’s processing limit of 4,096 tokens, we conducted further experiments using more advanced models from the GPT family. Specifically, we utilized the GPT-4-Turbo and GPT-3.5-Turbo-16k models, which are capable of processing up to 128,000 and 16,000 tokens, respectively. These models are well-suited to handle the length of most resumes. Due to resource limitations, our experiments were confined to 162 resumes that exceeded 4,000 tokens in length.

We used the results from the GPT-4-Turbo model as a benchmark for evaluating the performance of the GPT-3.5-Turbo-16k model. As indicated in Table [9](https://arxiv.org/html/2401.08315v2#S5.T9 "Table 9 ‣ 5.3 Comparison with Manual Resume Screening ‣ 5 Results ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening"), the GPT-3.5-Turbo-16k model demonstrated promising results, with a notable grade accuracy of 72.22%. This high level of accuracy can be attributed to the model’s ability to effectively analyze content-rich resumes, which typically contain extensive text detailing numerous skills and work experiences. Common sense suggests that resumes with more detailed information about a candidate’s skills and experiences are likely to score higher, indicating a potentially stronger candidate. This principle was affirmed by our findings, which showed a direct correlation between the depth of resume content and the accuracy of the model’s grading.

### 5.5 Time comparison between automated and human resume screening

Our study entailed a meticulous time comparison of three distinct resume screening methods: Automated, Semi-Automated, and Manual. To this end, we deconstructed the automated screening process into three discrete stages: Classification, Grading & Summarization, and Decision Making. We measured the time expenditure for each phase, culminating in an aggregate duration assessment. Notably, in the Classification stage, we accounted for the time span from initiation to conclusion of the inference process, excluding the fine-tuning duration. This approach mirrors the actual operational timeline of the automated screening framework. In the Decision Making stage, our focus was on the time required to evaluate the top ten resumes.

Additionally, we assessed the time investment for the semi-automated method, wherein human HR personnel undertake the final decision-making step, while preceding stages are managed by LLMs. For the manual screening conducted by Human HR, we based our calculations on the average adult reading speed of 238 words per minute, as indicated by survey literature Brysbaert ([2019](https://arxiv.org/html/2401.08315v2#bib.bib7)). Consequently, we deduced that reviewing all 838 resumes, encompassing a total of 442,047 words, would approximately take 31 hours (Please note that this is an estimated time, calculated based on the average human reading speed.).

Table 10: Follow each step to compare the time consumed by automated and manual resume screening.

Model Classification Grade & Summary Decision Making GPT-4 API 25 min (FT LLaMA2-7B) 2 h 30 min 0.4 min LLM with Estimated Human 25 min (FT LLaMA2-7B) 2 h 30 min (GPT-4) 22 min (Manual) Screening Time Estimated Human Screening — — — Time

Model Total Time Multiple Automatic or Manual GPT-4 API 2 h 55.4 min x 11 Automatic LLM with Estimated 3 h 17 min x 9 Semi-automatic Human Screening Time Estimated Human x 1 Manual Screening Time 31 h

Table [10](https://arxiv.org/html/2401.08315v2#S5.T10 "Table 10 ‣ 5.5 Time comparison between automated and human resume screening ‣ 5 Results ‣ Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening") illustrates that the fully automated resume screening framework, utilizing an LLM agent, completes the entire process set in approximately 2 hours and 55 minutes. This efficiency represents a speed 11 times faster than manual resume screening. Additionally, the semi-automatic approach is 9 times quicker than the manual method. While this comparison may lack rigorous precision, as it does not account for the possibility that human HR personnel might not read every word in a resume to reach a decision, the significant time reduction observed with the automated framework underscores its high efficiency.

## 6 Conclusion

In this study, we explore the feasibility of using an LLM agent for automated resume screening. We propose an innovative framework for this purpose and validate it using a real-world resume dataset, as well as through simulation of the resume screening process. Our results, derived from a series of comparative tests and analyses, demonstrate that the LLM agent can effectively perform the role of a human HR professional in resume screening. Notably, in terms of time efficiency, the LLM agent significantly surpasses traditional manual screening methods.

This work is subject to certain limitations. Primarily, it employs a controlled experimental design to maximize result accuracy, which restricts the scope of application to basic requirements of LLMs agent within IT companies. Consequently, this approach does not account for the varied requirements of other industries. Additionally, the collection of resume data is challenging due to privacy concerns. In future work, we aim to gather a broader array of resumes from diverse industries to enhance the representativeness of our study and further refine the LLM resume screening framework.

## References

*   Ali et al. (2022) Irfan Ali, Nimra Mughal, Zahid Hussain Khand, Javed Ahmed, and Ghulam Mujtaba. 2022. Resume classification system using natural language processing and machine learning techniques. *Mehran University Research Journal of Engineering & Technology*, 41(1):65–79.
*   Ayishathahira et al. (2018) CH Ayishathahira, C Sreejith, and C Raseek. 2018. Combination of neural networks and conditional random fields for efficient resume parsing. In *2018 International CET Conference on Control, Communication, and Computing (IC4)*, pages 388–393\. IEEE.
*   Barducci et al. (2022) Alessandro Barducci, Simone Iannaccone, Valerio La Gatta, Vincenzo Moscato, Giancarlo Sperlì, and Sergio Zavota. 2022. An end-to-end framework for information extraction from italian resumes. *Expert Systems with Applications*, 210:118487.
*   Bayer et al. (2022) Markus Bayer, Marc-André Kaufhold, and Christian Reuter. 2022. [A survey on data augmentation for text classification](https://doi.org/10.1145/3544558). *ACM Comput. Surv.*, 55(7).
*   Bharadwaj et al. (2022) S Bharadwaj, Rudra Varun, Potukuchi Sreeram Aditya, Macherla Nikhil, and G Charles Babu. 2022. Resume screening using nlp and lstm. In *2022 international conference on inventive computation technologies (ICICT)*, pages 238–241\. IEEE.
*   Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. *Advances in neural information processing systems*, 33:1877–1901.
*   Brysbaert (2019) Marc Brysbaert. 2019. How many words do we read per minute? a review and meta-analysis of reading rate. *Journal of memory and language*, 109:104047.
*   Chen et al. (2023) Liting Chen, Lu Wang, Hang Dong, Yali Du, Jie Yan, Fangkai Yang, Shuang Li, Pu Zhao, Si Qin, Saravan Rajmohan, et al. 2023. Introspective tips: Large language model for in-context decision making. *arXiv preprint arXiv:2305.11598*.
*   Ciravegna and Lavelli (2004) Fabio Ciravegna and Alberto Lavelli. 2004. Learningpinocchio: Adaptive information extraction for real world applications. *Natural Language Engineering*, 10(2):145–165.
*   Daryani et al. (2020) Chirag Daryani, Gurneet Singh Chhabra, Harsh Patel, Indrajeet Kaur Chhabra, and Ruchi Patel. 2020. An automated resume screening system using natural language processing and similarity. *ETHICS AND INFORMATION TECHNOLOGY [Internet]. VOLKSON PRESS*, pages 99–103.
*   Devlin et al. (2018) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. *arXiv preprint arXiv:1810.04805*.
*   Ding et al. (2023) Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, Yusheng Su, Shengding Hu, Yulin Chen, Chi-Min Chan, Weize Chen, et al. 2023. Parameter-efficient fine-tuning of large-scale pre-trained language models. *Nature Machine Intelligence*, 5(3):220–235.
*   Du et al. (2024) Yingpeng Du, Di Luo, Rui Yan, Xiaopei Wang, Hongzhi Liu, Hengshu Zhu, Yang Song, and Jie Zhang. 2024. Enhancing job recommendation through llm-based generative adversarial networks. In *Proceedings of the AAAI Conference on Artificial Intelligence*, volume 38, pages 8363–8371.
*   Erdem (2023) Merve Elmas Erdem. 2023. [Automatic resume screening with content matching](https://doi.org/10.1109/UBMK59864.2023.10286578). In *2023 8th International Conference on Computer Science and Engineering (UBMK)*, pages 554–558.
*   Gan and Mori (2022) Chengguang Gan and Tatsunori Mori. 2022. Construction of english resume corpus and test with pre-trained language models. *arXiv preprint arXiv:2208.03219*.
*   Ghosh and Sadaphal (2023) Preetam Ghosh and Vaishali Sadaphal. 2023. Jobrecogpt–explainable job recommendations using llms. *arXiv preprint arXiv:2309.11805*.
*   Harsha et al. (2022) Tumula Mani Harsha, Gangaraju Sai Moukthika, Dudipalli Siva Sai, Mannuru Naga Rajeswari Pravallika, Satish Anamalamudi, and MuraliKrishna Enduri. 2022. Automated resume screener using natural language processing (nlp). In *2022 6th international conference on trends in electronics and informatics (ICOEI)*, pages 1772–1777\. IEEE.
*   Huang et al. (2024) Jen-tse Huang, Eric John Li, Man Ho Lam, Tian Liang, Wenxuan Wang, Youliang Yuan, Wenxiang Jiao, Xing Wang, Zhaopeng Tu, and Michael R Lyu. 2024. How far are we on the decision-making of llms? evaluating llms’ gaming ability in multi-agent environments. *arXiv preprint arXiv:2403.11807*.
*   Kinge et al. (2022) Bhushan Kinge, Shrinivas Mandhare, Pranali Chavan, and SM Chaware. 2022. Resume screening using machine learning and nlp: A proposed system. *International Journal of Scientific Research in Computer Science, Engineering and Information Technology (IJSRCSEIT)*, 8(2):253–258.
*   Lin and Och (2004) Chin-Yew Lin and Franz Josef Och. 2004. Automatic evaluation of machine translation quality using longest common subsequence and skip-bigram statistics. In *Proceedings of the 42nd annual meeting of the association for computational linguistics (ACL-04)*, pages 605–612.
*   Ma et al. (2024) Shuai Ma, Qiaoyi Chen, Xinru Wang, Chengbo Zheng, Zhenhui Peng, Ming Yin, and Xiaojuan Ma. 2024. Towards human-ai deliberation: Design and evaluation of llm-empowered deliberative ai for ai-assisted decision-making. *arXiv preprint arXiv:2403.16812*.
*   Min et al. (2023) Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben Veyseh, Thien Huu Nguyen, Oscar Sainz, Eneko Agirre, Ilana Heintz, and Dan Roth. 2023. Recent advances in natural language processing via large pre-trained language models: A survey. *ACM Computing Surveys*, 56(2):1–40.
*   Minaee et al. (2021) Shervin Minaee, Nal Kalchbrenner, Erik Cambria, Narjes Nikzad, Meysam Chenaghlu, and Jianfeng Gao. 2021. [Deep learning–based text classification: A comprehensive review](https://doi.org/10.1145/3439726). *ACM Comput. Surv.*, 54(3).
*   Mooney (1999) R Mooney. 1999. Relational learning of pattern-match rules for information extraction. In *Proceedings of the sixteenth national conference on artificial intelligence*, volume 328, page 334.
*   OpenAI et al. (2023) OpenAI, :, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie Balcom, Paul Baltescu, Haiming Bao, Mo Bavarian, Jeff Belgum, Irwan Bello, Jake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman, Tim Brooks, Miles Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany Carey, Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek Chen, Sully Chen, Ruby Chen, Jason Chen, Mark Chen, Ben Chess, Chester Cho, Casey Chu, Hyung Won Chung, Dave Cummings, Jeremiah Currier, Yunxing Dai, Cory Decareaux, Thomas Degry, Noah Deutsch, Damien Deville, Arka Dhar, David Dohan, Steve Dowling, Sheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna Eloundou, David Farhi, Liam Fedus, Niko Felix, Simón Posada Fishman, Juston Forte, Isabella Fulford, Leo Gao, Elie Georges, Christian Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-Lopes, Jonathan Gordon, Morgan Grafstein, Scott Gray, Ryan Greene, Joshua Gross, Shixiang Shane Gu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris, Yuchen He, Mike Heaton, Johannes Heidecke, Chris Hesse, Alan Hickey, Wade Hickey, Peter Hoeschele, Brandon Houghton, Kenny Hsu, Shengli Hu, Xin Hu, Joost Huizinga, Shantanu Jain, Shawn Jain, Joanne Jang, Angela Jiang, Roger Jiang, Haozhun Jin, Denny Jin, Shino Jomoto, Billie Jonn, Heewoo Jun, Tomer Kaftan, Łukasz Kaiser, Ali Kamali, Ingmar Kanitscheider, Nitish Shirish Keskar, Tabarak Khan, Logan Kilpatrick, Jong Wook Kim, Christina Kim, Yongjik Kim, Hendrik Kirchner, Jamie Kiros, Matt Knight, Daniel Kokotajlo, Łukasz Kondraciuk, Andrew Kondrich, Aris Konstantinidis, Kyle Kosic, Gretchen Krueger, Vishal Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan Leike, Jade Leung, Daniel Levy, Chak Ming Li, Rachel Lim, Molly Lin, Stephanie Lin, Mateusz Litwin, Theresa Lopez, Ryan Lowe, Patricia Lue, Anna Makanju, Kim Malfacini, Sam Manning, Todor Markov, Yaniv Markovski, Bianca Martin, Katie Mayer, Andrew Mayne, Bob McGrew, Scott Mayer McKinney, Christine McLeavey, Paul McMillan, Jake McNeil, David Medina, Aalok Mehta, Jacob Menick, Luke Metz, Andrey Mishchenko, Pamela Mishkin, Vinnie Monaco, Evan Morikawa, Daniel Mossing, Tong Mu, Mira Murati, Oleg Murk, David Mély, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak, Arvind Neelakantan, Richard Ngo, Hyeonwoo Noh, Long Ouyang, Cullen O’Keefe, Jakub Pachocki, Alex Paino, Joe Palermo, Ashley Pantuliano, Giambattista Parascandolo, Joel Parish, Emy Parparita, Alex Passos, Mikhail Pavlov, Andrew Peng, Adam Perelman, Filipe de Avila Belbute Peres, Michael Petrov, Henrique Ponde de Oliveira Pinto, Michael, Pokorny, Michelle Pokrass, Vitchyr Pong, Tolly Powell, Alethea Power, Boris Power, Elizabeth Proehl, Raul Puri, Alec Radford, Jack Rae, Aditya Ramesh, Cameron Raymond, Francis Real, Kendra Rimbach, Carl Ross, Bob Rotsted, Henri Roussez, Nick Ryder, Mario Saltarelli, Ted Sanders, Shibani Santurkar, Girish Sastry, Heather Schmidt, David Schnurr, John Schulman, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah Shoker, Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin, Katarina Slama, Ian Sohl, Benjamin Sokolowsky, Yang Song, Natalie Staudacher, Felipe Petroski Such, Natalie Summers, Ilya Sutskever, Jie Tang, Nikolas Tezak, Madeleine Thompson, Phil Tillet, Amin Tootoonchian, Elizabeth Tseng, Preston Tuggle, Nick Turley, Jerry Tworek, Juan Felipe Cerón Uribe, Andrea Vallone, Arun Vijayvergiya, Chelsea Voss, Carroll Wainwright, Justin Jay Wang, Alvin Wang, Ben Wang, Jonathan Ward, Jason Wei, CJ Weinmann, Akila Welihinda, Peter Welinder, Jiayi Weng, Lilian Weng, Matt Wiethoff, Dave Willner, Clemens Winter, Samuel Wolrich, Hannah Wong, Lauren Workman, Sherwin Wu, Jeff Wu, Michael Wu, Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qiming Yuan, Wojciech Zaremba, Rowan Zellers, Chong Zhang, Marvin Zhang, Shengjia Zhao, Tianhao Zheng, Juntang Zhuang, William Zhuk, and Barret Zoph. 2023. [Gpt-4 technical report](http://arxiv.org/abs/2303.08774).
*   Ouyang et al. (2022) Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022. [Training language models to follow instructions with human feedback](http://arxiv.org/abs/2203.02155).
*   Radford et al. (2019) Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised multitask learners. *OpenAI blog*, 1(8):9.
*   Raffel et al. (2020) Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. *The Journal of Machine Learning Research*, 21(1):5485–5551.
*   Singh et al. (2010a) Amit Singh, Rose Catherine, Karthik Venkat Ramanan, Vijil Chenthamarakshan, and Nanda Kambhatla. 2010a. [Prospect: a system for screening candidates for recruitment](https://api.semanticscholar.org/CorpusID:5276445). *Proceedings of the 19th ACM international conference on Information and knowledge management*.
*   Singh et al. (2010b) Amit Singh, Catherine Rose, Karthik Visweswariah, Vijil Chenthamarakshan, and Nandakishore Kambhatla. 2010b. Prospect: a system for screening candidates for recruitment. In *Proceedings of the 19th ACM international conference on Information and knowledge management*, pages 659–668.
*   Singhal et al. (2001) Amit Singhal et al. 2001. Modern information retrieval: A brief overview. *IEEE Data Eng. Bull.*, 24(4):35–43.
*   Sinha et al. (2021) Arvind Kumar Sinha, Md Amir Khusru Akhtar, and Ashwani Kumar. 2021. Resume screening using natural language processing and machine learning: A systematic review. *Machine Learning and Information Processing: Proceedings of ICMLIP 2020*, pages 207–214.
*   Sutskever et al. (2014) Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014. Sequence to sequence learning with neural networks. *Advances in neural information processing systems*, 27.
*   Tallapragada et al. (2023) VV Satyanarayana Tallapragada, V Sushma Raj, U Deepak, P Divya Sai, and T Mallikarjuna. 2023. Improved resume parsing based on contextual meaning extraction using bert. In *2023 7th International Conference on Intelligent Computing and Control Systems (ICICCS)*, pages 1702–1708\. IEEE.
*   Touvron et al. (2023a) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023a. Llama: Open and efficient foundation language models. *arXiv preprint arXiv:2302.13971*.
*   Touvron et al. (2023b) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023b. Llama 2: Open foundation and fine-tuned chat models. *arXiv preprint arXiv:2307.09288*.
*   Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. *Advances in neural information processing systems*, 30.
*   Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reasoning in large language models. *Advances in neural information processing systems*, 35:24824–24837.
*   Yao et al. (2022) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2022. React: Synergizing reasoning and acting in language models. *arXiv preprint arXiv:2210.03629*.
*   Yu et al. (2005) Kun Yu, Gang Guan, and Ming Zhou. 2005. Resume information extraction with cascaded hybrid model. In *Proceedings of the 43rd annual meeting of the Association for Computational Linguistics (ACL’05)*, pages 499–506.
*   Zhao et al. (2023) Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023. A survey of large language models. *arXiv preprint arXiv:2303.18223*.
*   Zu and Wang (2019) Shicheng Zu and Xiulai Wang. 2019. Resume information extraction with a novel text block segmentation algorithm. *Int J Nat Lang Comput*, 8(2019):29–48.