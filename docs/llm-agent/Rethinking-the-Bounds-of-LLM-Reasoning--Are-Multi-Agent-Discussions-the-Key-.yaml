- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:51:19'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:51:19
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重新审视LLM推理的界限：多代理讨论是否是关键？
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2402.18272](https://ar5iv.labs.arxiv.org/html/2402.18272)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2402.18272](https://ar5iv.labs.arxiv.org/html/2402.18272)
- en: Qineng Wang^(1*)    Zihao Wang^(2*)    Ying Su²    Hanghang Tong³    Yangqiu
    Song²
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 秦能旺^(1*)    王子浩^(2*)    苏莹²    佟航航³    宋扬秋²
- en: ¹Zhejiang University    ²HKUST    ³UIUC
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ¹浙江大学    ²香港科技大学    ³伊利诺伊大学厄本那-香槟分校
- en: wongqineng73@zju.edu.cn, htong@illinois.edu
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: wongqineng73@zju.edu.cn, htong@illinois.edu
- en: '{zwanggc,ysuay,yqsong}@cse.ust.hk'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '{zwanggc,ysuay,yqsong}@cse.ust.hk'
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Recent progress in LLMs discussion suggests that multi-agent discussion improves
    the reasoning abilities of LLMs. In this work, we reevaluate this claim through
    systematic experiments, where we propose a novel group discussion framework to
    enrich the set of discussion mechanisms. Interestingly, our results show that
    a single-agent LLM with strong prompts can achieve almost the same performance
    as the best existing discussion approach on a wide range of reasoning tasks and
    backbone LLMs. We observe that the multi-agent discussion performs better than
    a single agent only when there is no demonstration in the prompt. Further study
    reveals the common interaction mechanisms of LLMs during the discussion.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 最近在LLM讨论方面的进展表明，多代理讨论可以提高LLM的推理能力。在这项工作中，我们通过系统实验重新评估了这一说法，我们提出了一种新颖的群体讨论框架，以丰富讨论机制的集合。有趣的是，我们的结果表明，具有强大提示的单代理LLM在广泛的推理任务和基础LLM上几乎可以达到与最佳现有讨论方法相同的性能。我们观察到，只有在提示中没有示范时，多代理讨论才比单代理讨论表现更好。进一步研究揭示了LLM在讨论过程中的常见互动机制。
- en: 'Rethinking the Bounds of LLM Reasoning:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 重新审视LLM推理的界限：
- en: Are Multi-Agent Discussions the Key?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 多代理讨论是否是关键？
- en: Qineng Wang^(1*)   Zihao Wang^(2*)   Ying Su²   Hanghang Tong³   Yangqiu Song²
    ¹Zhejiang University   ²HKUST   ³UIUC wongqineng73@zju.edu.cn, htong@illinois.edu
    {zwanggc,ysuay,yqsong}@cse.ust.hk
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 秦能旺^(1*)   王子浩^(2*)   苏莹²   佟航航³   宋扬秋² ¹浙江大学   ²香港科技大学   ³伊利诺伊大学厄本那-香槟分校 wongqineng73@zju.edu.cn,
    htong@illinois.edu {zwanggc,ysuay,yqsong}@cse.ust.hk
- en: '^*^*footnotetext: These authors contributed equally to this work.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ^*^*脚注：这些作者对本工作做出了同等贡献。
- en: 1 Introduction
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Large Language Models (LLMs) demonstrate strong abilities in language understanding
    and generation OpenAI ([2022](#bib.bib30), [2023](#bib.bib31)); Touvron et al.
    ([2023a](#bib.bib37)); Zhang et al. ([2022a](#bib.bib53)); Chowdhery et al. ([2022](#bib.bib9));
    Team et al. ([2023](#bib.bib36)). However, LLMs still fall short for reasoning
    tasks due to model deficiencies like hallucination and reasoning perspective mistakes
    Xu et al. ([2023a](#bib.bib45)). To overcome these issues, numerous works have
    been proposed by simulating human reasoning. Inspired by Society of Mind Minsky
    ([1988](#bib.bib29)), multi-agent discussion frameworks such as Debate Du et al.
    ([2023](#bib.bib13)), MAD Liang et al. ([2023](#bib.bib22)), and ReConcile Chen
    et al. ([2023a](#bib.bib7)) present a novel approach by involving multiple AI
    agents. Powered by LLMs, these agents autonomously engage in discussions on given
    topics, improving the reasoning abilities of LLMs by emulating the human discussion
    process. To further improve the performance, most of multi-agent discussion frameworks
    leverage task-specific examples, which are often termed as demonstrations Min
    et al. ([2022](#bib.bib28)). This is based on the insights that LLMs can learn
    from the context demonstrations Brown et al. ([2020](#bib.bib5)). We note that
    *all these discussion frameworks claim that they outperform the conventional methods
    with a single agent*, such as Chain-of-Thought Wei et al. ([2022](#bib.bib41)).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）在语言理解和生成方面表现出强大的能力 OpenAI ([2022](#bib.bib30), [2023](#bib.bib31));
    Touvron et al. ([2023a](#bib.bib37)); Zhang et al. ([2022a](#bib.bib53)); Chowdhery
    et al. ([2022](#bib.bib9)); Team et al. ([2023](#bib.bib36)). 然而，由于模型缺陷如幻觉和推理视角错误，LLMs
    在推理任务上仍然有所欠缺 Xu et al. ([2023a](#bib.bib45)). 为了克服这些问题，许多工作通过模拟人类推理提出了多种方法。受到心智社会
    Minsky ([1988](#bib.bib29)) 的启发，多代理讨论框架如 Debate Du et al. ([2023](#bib.bib13)),
    MAD Liang et al. ([2023](#bib.bib22)), 和 ReConcile Chen et al. ([2023a](#bib.bib7))
    提出了通过涉及多个AI代理的新颖方法。这些代理由LLM驱动，能够在给定的主题上自主进行讨论，通过模拟人类讨论过程来提高LLM的推理能力。为了进一步提高性能，大多数多代理讨论框架利用任务特定示例，这些示例通常被称为示范
    Min et al. ([2022](#bib.bib28)). 这是基于LLM可以从上下文示范中学习的见解 Brown et al. ([2020](#bib.bib5)).
    我们注意到*所有这些讨论框架声称它们比传统的单代理方法更出色*，例如Chain-of-Thought Wei et al. ([2022](#bib.bib41)).
- en: 'Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Rethinking the Bounds of LLM
    Reasoning: Are Multi-Agent Discussions the Key?") presents a comparison between
    single-agent settings and multi-agent discussion frameworks on FOLIO-wiki dataset
    Zhang et al. ([2023b](#bib.bib54)); Han et al. ([2022](#bib.bib16)). In this figure,
    ‘Demo’ means that the tested single agent is provided with a demonstration case,
    ‘Q-Desc.’ indicates that the single agent is provided with detailed question description,
    while ‘Direct’ refers to the single agent without demonstrations. We observe that
    the single agent ‘Demo’ tends to reach a performance upper bound similar to that
    of all discussion frameworks, which will be further elaborated on later. This
    result suggests that the previous *claim* is NOT fully established.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [1](#S1.F1 "图 1 ‣ 1 引言 ‣ 重新审视 LLM 推理的界限：多代理讨论是关键吗？") 展示了单代理设置与多代理讨论框架在 FOLIO-wiki
    数据集上的比较 Zhang et al. ([2023b](#bib.bib54)); Han et al. ([2022](#bib.bib16))。在此图中，“Demo”表示测试的单代理提供了一个示例案例，“Q-Desc.”
    表示单代理提供了详细的问题描述，而“Direct”则指单代理没有示例。我们观察到单代理“Demo”往往能达到类似所有讨论框架的性能上限，这将在后文进一步阐述。这一结果表明之前的
    *声明* 并未完全成立。
- en: '![Refer to caption](img/ee66e69f6863c24325d42e539785f233.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ee66e69f6863c24325d42e539785f233.png)'
- en: 'Figure 1: Comparative performance of single-agent settings and multi-agent
    discussion frameworks on FOLIO-wiki dataset.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：单代理设置与多代理讨论框架在 FOLIO-wiki 数据集上的比较性能。
- en: '![Refer to caption](img/08f80399a8ae8d73c3dab5674986fa49.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/08f80399a8ae8d73c3dab5674986fa49.png)'
- en: 'Figure 2: Our proposed design pipeline of multi-agent discussion frameworks.
    This pipeline operates by having agents starting with a kick-start prompt. Then,
    agents will start discussion by obeying the rules defined in the algorithm and
    come to a result in the end.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：我们提出的多代理讨论框架设计流程。此流程通过让代理从一个启动提示开始运行，然后代理将遵循算法中定义的规则进行讨论，最终得出结果。
- en: 'Based on the observation from Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?"),
    in this paper, we conduct systematic experiments to provide in-depth analysis.
    As a newly emergent topic, the number of available discussion frameworks still
    remains limited. To provide a more comprehensive and detailed comparison between
    the single-agent settings and discussion frameworks, as demonstrated in Figure
    [3](#S2.F3 "Figure 3 ‣ 2 Preliminary ‣ Rethinking the Bounds of LLM Reasoning:
    Are Multi-Agent Discussions the Key?"), we propose a new discussion framework
    named CMD, which is inspired by human group discussion process. Our discussion
    pipeline considers multiple design aspects shown in Figure [2](#S1.F2 "Figure
    2 ‣ 1 Introduction ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions
    the Key?") (see Section [2.1](#S2.SS1 "2.1 What is Multi-Agent Discussion? ‣ 2
    Preliminary ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions
    the Key?") for more details). We further carry out a range of experiments over
    standard reasoning benchmarks (ECQA Aggarwal et al. ([2021](#bib.bib1)), GSM8k
    Cobbe et al. ([2021](#bib.bib10)), and FOLIO-wiki Han et al. ([2022](#bib.bib16));
    Zhang et al. ([2023b](#bib.bib54))) using various configurations within different
    parts of this pipeline.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 基于图 [1](#S1.F1 "图 1 ‣ 1 引言 ‣ 重新审视 LLM 推理的界限：多代理讨论是关键吗？") 的观察，在本文中，我们进行系统实验以提供深入分析。作为一个新兴话题，现有的讨论框架数量仍然有限。为了在单代理设置与讨论框架之间提供更全面和详细的比较，如图
    [3](#S2.F3 "图 3 ‣ 2 初步 ‣ 重新审视 LLM 推理的界限：多代理讨论是关键吗？") 所示，我们提出了一种名为 CMD 的新讨论框架，灵感来自于人类小组讨论过程。我们的讨论流程考虑了图
    [2](#S1.F2 "图 2 ‣ 1 引言 ‣ 重新审视 LLM 推理的界限：多代理讨论是关键吗？") 中显示的多个设计方面（更多细节请参见第 [2.1](#S2.SS1
    "2.1 什么是多代理讨论？ ‣ 2 初步 ‣ 重新审视 LLM 推理的界限：多代理讨论是关键吗？") 节）。我们进一步在标准推理基准（ECQA Aggarwal
    et al. ([2021](#bib.bib1)), GSM8k Cobbe et al. ([2021](#bib.bib10)), 和 FOLIO-wiki
    Han et al. ([2022](#bib.bib16)); Zhang et al. ([2023b](#bib.bib54))) 上使用此流程的不同配置进行了一系列实验。
- en: 'We find that multi-agent discussion does not necessarily enhance reasoning
    when the prompt provided to an agent is sufficiently robust, which aligns with
    the observation from Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Rethinking
    the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?"). Additionally,
    our experimental results reveal that multi-agent discussion frameworks outperform
    single-agent setups when no demonstrations are provided. We also find that agents
    powered by weaker LLMs like Bard Anil et al. ([2023](#bib.bib3)) can improve its
    performance on reasoning with the assistance of the stronger LLMs like Gemini
    Pro Team et al. ([2023](#bib.bib36)) during interaction.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '我们发现，当提供给智能体的提示已经足够强大时，多智能体讨论不一定能增强推理能力，这与图 [1](#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?")
    的观察结果一致。此外，我们的实验结果表明，当没有提供演示时，多智能体讨论框架优于单个智能体设置。我们还发现，像 Bard Anil 等人（[2023](#bib.bib3)）这样的较弱LLMs驱动的智能体在与像
    Gemini Pro Team 等人（[2023](#bib.bib36)）这样的较强LLMs互动时，可以提升推理性能。'
- en: 'In summary, our analysis provides a new way of understanding when to use multi-agent
    discussion on reasoning. Our contributions are listed as follows: (1) We propose
    a new multi-agent discussion framework CMD, which simulates human group discussion
    process; (2) We observe that single agents with a strong prompt match the performance
    of a multi-agent discussion using equally robust prompts; (3) We identify two
    common types of discussion errors: judge mistake and wrong answer propagation;
    (4) We find that without demonstrations, multi-agent discussions surpass the single
    agent ; (5) In multi-LLMs multi-agent discussions, agents with stronger LLMs help
    improve performance of agents with weaker LLMs.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，我们的分析提供了一种新的理解方式，说明何时使用多智能体讨论来进行推理。我们的贡献如下： (1) 我们提出了一个新的多智能体讨论框架CMD，它模拟了人类小组讨论的过程；
    (2) 我们观察到，具有强大提示的单个智能体在性能上与使用同样强大提示的多智能体讨论相匹配； (3) 我们识别出两种常见的讨论错误：判断错误和错误答案传播；
    (4) 我们发现，在没有演示的情况下，多智能体讨论优于单个智能体； (5) 在多LLMs的多智能体讨论中，具有更强LLMs的智能体有助于提升具有较弱LLMs的智能体的性能。
- en: 2 Preliminary
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 初步概述
- en: '![Refer to caption](img/3e890fd323b25b5a293f5216f36f5c3a.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![参考图注](img/3e890fd323b25b5a293f5216f36f5c3a.png)'
- en: 'Figure 3: Overview of the Conquer-and-Merge Discussion (CMD) Framework.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：征服与合并讨论（CMD）框架概述。
- en: 2.1 What is Multi-Agent Discussion?
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 什么是多智能体讨论？
- en: Multi-agent discussion refers to an interactive setup where multiple agents,
    each powered by an LLM, engage in an autonomous dialogue. Each agent is given
    a prompt that outlines the necessary background knowledge and guides its behavior
    throughout the discussion. Once the topic is given, these agents can carry on
    the conversation independently.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 多智能体讨论指的是一种互动设置，其中多个由LLM驱动的智能体进行自主对话。每个智能体会收到一个提示，概述了必要的背景知识，并指导其在讨论中的行为。一旦主题给定，这些智能体可以独立进行对话。
- en: 'Figure [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Rethinking the Bounds of LLM
    Reasoning: Are Multi-Agent Discussions the Key?") illustrates a discussion design
    pipeline, which is structured into four main elements: the Kick-start prompt,
    agents, algorithm, and result. The Kick-start prompt supplies essential details
    such as background knowledge and the topic for discussion. This information is
    then fed to an agent, which operates based on various LLMs. Next, the algorithm
    lays out the specific rules of discussion, including the number of rounds, decision-making
    processes (whether by a judge or through voting), and the structure of the discussion
    (such as hierarchical). Lastly, ‘Result’ describes how the final decisions are
    rendered and presented. We further provide a view from symmetry for prompt-related
    mechanism (including discussion) in Appendix [A](#A1 "Appendix A Discussion Engineering
    and Agent Symmetry ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions
    the Key?").'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '图 [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Rethinking the Bounds of LLM Reasoning:
    Are Multi-Agent Discussions the Key?") 展示了一个讨论设计流程图，它分为四个主要元素：启动提示、智能体、算法和结果。启动提示提供了诸如背景知识和讨论主题等必要细节。然后，这些信息被传递给一个基于各种LLMs运作的智能体。接下来，算法规定了讨论的具体规则，包括回合数、决策过程（由判断者决定还是通过投票）以及讨论的结构（如分层结构）。最后，“结果”描述了最终决策如何做出并呈现。我们进一步在附录
    [A](#A1 "Appendix A Discussion Engineering and Agent Symmetry ‣ Rethinking the
    Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?") 提供了关于提示相关机制（包括讨论）的对称视角。'
- en: 2.2 Existing Discussion Frameworks
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 现有讨论框架
- en: 'Previous works on multi-agent discussion frameworks have already covered several
    common discussion paradigms. In this paper, we consider the following discussion
    frameworks for our experiments: Debate Du et al. ([2023](#bib.bib13)), MAD Liang
    et al. ([2023](#bib.bib22)) and ReConcile Chen et al. ([2023a](#bib.bib7)).'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 之前关于多智能体讨论框架的研究已经覆盖了几种常见的讨论范式。在本文中，我们考虑了以下讨论框架进行实验：Debate Du 等 ([2023](#bib.bib13))、MAD
    Liang 等 ([2023](#bib.bib22)) 和 ReConcile Chen 等 ([2023a](#bib.bib7))。
- en: Debate replicates a simple turn-based discussion among agents. Initially, all
    agents are prompted to address the assigned task, and their respective responses
    are then incorporated into each agent’s input for the subsequent round. Typically,
    this process consists of three rounds of discussion.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 辩论模拟了智能体之间的简单轮流讨论。最初，所有智能体被要求处理指定的任务，然后将各自的回应纳入每个智能体在下一轮中的输入中。通常，这个过程包括三轮讨论。
- en: MAD introduces divergent thinking by involving two participants to discuss a
    task from opposing perspectives. A judge then steps in to evaluate which viewpoint
    seems more plausible or if further discussion is needed. The discussion is repeated
    until a consensus is reached or the judge favors a particular solution.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: MAD 通过让两个参与者从对立的角度讨论一个任务来引入发散思维。然后，评判者介入，评估哪种观点更为合理或是否需要进一步讨论。讨论会重复进行，直到达成共识或评判者倾向于某个特定解决方案。
- en: ReConcile implements a round-table discussion with the agents powered by multiple
    LLMs. It reaches a decision through a weighted voting system. In this process,
    agents provide a confidence level for their answers, and agents in ReConcile utilize
    these confidence levels as weights to cast votes and arrive at a final decision.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ReConcile 实现了一个由多个 LLM 支持的圆桌讨论。它通过加权投票系统达成决定。在这个过程中，智能体为他们的答案提供一个置信水平，ReConcile
    中的智能体利用这些置信水平作为权重来投票并得出最终决定。
- en: 'Despite these advancements, the number of multi-agent frameworks is still limited,
    and none has yet to consider one of the most prevalent forms of discussion: group
    discussion.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管取得了这些进展，但多智能体框架的数量仍然有限，且目前还没有考虑到一种最普遍的讨论形式：小组讨论。
- en: '3 CMD: Conquer-and-Merge Discussion'
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 CMD：征服与合并讨论
- en: 'To provide a thorough comparison in following experiments, we identify and
    rectify the gap in previous research, which has not suggested a group-discussion-based
    framework. To address this, we introduce a novel framework for multi-agent group
    discussion, referred to as CMD. In CMD, suppose there are $n$ denotes the explanation.
    Detailed description can be seen in Appendix [B](#A2 "Appendix B CMD: Conquer
    and Merge Discussion Framework ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent
    Discussions the Key?").'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在后续实验中进行全面比较，我们识别并修正了之前研究中的缺口，即未提出基于小组讨论的框架。为了解决这个问题，我们引入了一个新的多智能体小组讨论框架，称为CMD。在CMD中，假设有$n$表示解释。详细描述请见附录
    [B](#A2 "附录 B CMD：征服与合并讨论框架 ‣ 重新思考 LLM 推理的界限：多智能体讨论是关键吗？")。
- en: 3.1 Message-Passing Algorithm
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 消息传递算法
- en: 'For the synchronization of agent communications, we propose a message-passing
    algorithm. Previous works on multi-agent discussion frameworks focus exclusively
    on specific scenarios without designing a universal algorithm to synchronize agent
    messages across various discussions. Moreover, discussion forms vary in architecture
    and agents can be powered by different LLMs, where each LLM usually possesses
    different calling protocols. Therefore, we design a message-passing algorithm
    using a multi-threaded way to overcome these issues. The algorithm establishes
    a receiving map $M$ to corresponding agents. Please refer to Appendix [B.4](#A2.SS4
    "B.4 Message-Passing Algorithm ‣ Appendix B CMD: Conquer and Merge Discussion
    Framework ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions
    the Key?") for more detailed pseudo code.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了同步智能体之间的通信，我们提出了一种消息传递算法。之前关于多智能体讨论框架的研究主要集中在特定场景上，而没有设计一种通用算法来同步各种讨论中的智能体消息。此外，讨论形式在架构上有所不同，智能体可能由不同的
    LLM 支持，每个 LLM 通常具有不同的调用协议。因此，我们设计了一种多线程方式的消息传递算法来克服这些问题。该算法建立了一个接收映射 $M$ 对应的智能体。更多详细的伪代码请参考附录
    [B.4](#A2.SS4 "B.4 消息传递算法 ‣ 附录 B CMD：征服与合并讨论框架 ‣ 重新思考 LLM 推理的界限：多智能体讨论是关键吗？")。
- en: 3.2 Three Stages of CMD
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 CMD 的三个阶段
- en: 'As illustrated in Figure [3](#S2.F3 "Figure 3 ‣ 2 Preliminary ‣ Rethinking
    the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?"), CMD consists
    of three stages: group discussion, voting and the final decision stage. Typically,
    the final decision stage is reserved for instances of a tie and is otherwise unnecessary.
    Below is a breakdown of each stage involved in the CMD framework, and detailed
    introduction can be seen in Appendix [B.3](#A2.SS3 "B.3 CMD Stages ‣ Appendix
    B CMD: Conquer and Merge Discussion Framework ‣ Rethinking the Bounds of LLM Reasoning:
    Are Multi-Agent Discussions the Key?").'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '如图 [3](#S2.F3 "Figure 3 ‣ 2 Preliminary ‣ Rethinking the Bounds of LLM Reasoning:
    Are Multi-Agent Discussions the Key?") 所示，CMD 包含三个阶段：小组讨论、投票和最终决策阶段。通常，最终决策阶段保留用于出现平局的情况，否则不必要。以下是
    CMD 框架中每个阶段的详细介绍，详细内容请见附录 [B.3](#A2.SS3 "B.3 CMD Stages ‣ Appendix B CMD: Conquer
    and Merge Discussion Framework ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent
    Discussions the Key?")。'
- en: 'Stage 1: Group Discussion. During this stage, agents $\mathcal{A}$ rounds of
    discussions, CMD moves to the voting stage.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 阶段 1：小组讨论。在此阶段，代理 $\mathcal{A}$ 进行多轮讨论，CMD 进入投票阶段。
- en: 'Stage 2: Voting. When discussion reaches the maximum number of rounds, all
    agents $\mathcal{A}$ start voting. Each vote of agent in this discussion is treated
    equally, therefore, the result is determined by the majority decision. In the
    event of a tie, CMD transitions to stage 3\. Otherwise, the discussion process
    concludes formally.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 阶段 2：投票。当讨论达到最大轮数时，所有代理 $\mathcal{A}$ 开始投票。每个代理的投票在此次讨论中被视为平等，因此结果由多数决策决定。如果出现平局，CMD
    过渡到阶段 3。否则，讨论过程正式结束。
- en: 'Stage 3: Final Decision. If a tie occurs, we introduce an extra agent $S$,
    representing a set of viewpoints and a set of explanations respectively.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 阶段 3：最终决策。如果出现平局，我们引入一个额外的代理 $S$，分别代表一组观点和一组解释。
- en: 4 Experimental Setups
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实验设置
- en: 'In the experiments, we contrast single-agent setup with four established multi-agent
    discussion frameworks: Debate, MAD, ReConcile, and CMD under various prompt conditions.
    These methods are introduced in previous Sections [2.2](#S2.SS2 "2.2 Existing
    Discussion Frameworks ‣ 2 Preliminary ‣ Rethinking the Bounds of LLM Reasoning:
    Are Multi-Agent Discussions the Key?") and [3](#S3 "3 CMD: Conquer-and-Merge Discussion
    ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?").'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '在实验中，我们将单代理设置与四种已建立的多代理讨论框架进行对比：Debate、MAD、ReConcile 和 CMD，比较各种提示条件下的表现。这些方法在前面的章节
    [2.2](#S2.SS2 "2.2 Existing Discussion Frameworks ‣ 2 Preliminary ‣ Rethinking
    the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?") 和 [3](#S3
    "3 CMD: Conquer-and-Merge Discussion ‣ Rethinking the Bounds of LLM Reasoning:
    Are Multi-Agent Discussions the Key?") 中有介绍。'
- en: 4.1 Implementation Details and Metrics
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 实现细节与指标
- en: Our experiments are primarily implemented with three advanced LLMs, including
    ChatGPT-3.5 OpenAI ([2022](#bib.bib30)), Gemini Pro Team et al. ([2023](#bib.bib36))
    and Bard Anil et al. ([2023](#bib.bib3)). In particular, we employ the gpt-35-turbo
    (0613) instance hosted on Azure OpenAI¹¹1https://oai.azure.com/ for ChatGPT-3.5,
    while the chat-bison-001 model represents Bard via PaLM2 architecture. Gemini
    Pro and Bard interfaces operate through Google MakerSuite API²²2https://ai.google.dev/.
    A uniform dialogue temperature of $0.25$ is configured across LLMs on CMD to ensure
    consistency. For all multi-agent discussion frameworks, we set the maximum discussion
    round number to 3\. Our evaluations use accuracy to measure performance across
    all tasks.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实验主要使用了三个先进的 LLM，包括 ChatGPT-3.5 OpenAI ([2022](#bib.bib30))、Gemini Pro Team
    等 ([2023](#bib.bib36)) 和 Bard Anil 等 ([2023](#bib.bib3))。特别是，我们使用了在 Azure OpenAI¹¹1https://oai.azure.com/
    上托管的 gpt-35-turbo (0613) 实例作为 ChatGPT-3.5，而 chat-bison-001 模型通过 PaLM2 架构代表 Bard。Gemini
    Pro 和 Bard 接口通过 Google MakerSuite API²²2https://ai.google.dev/ 操作。所有 LLM 在 CMD
    上配置了一致的对话温度 $0.25$ 以确保一致性。对于所有多代理讨论框架，我们将最大讨论轮数设置为 3。我们的评估使用准确性来衡量所有任务的表现。
- en: 4.2 Downstream Tasks
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 下游任务
- en: 'The frameworks are implemented on a suite of reasoning tasks, including a commonsense
    reasoning task and two deductive reasoning tasks: (1) ECQA Aggarwal et al. ([2021](#bib.bib1)):
    A QA dataset centered on commonsense knowledge, (2) GSM8K Cobbe et al. ([2021](#bib.bib10)):
    A benchmark consists of math word problems, (3) FOLIO-wiki Zhang et al. ([2023b](#bib.bib54)):
    A dataset adapted from FOLIO Han et al. ([2022](#bib.bib16)) for both symbolic
    and natural language deductive reasoning. In alignment with constraints imposed
    by computational resources and following precedents set by earlier research Du
    et al. ([2023](#bib.bib13)); Chen et al. ([2023a](#bib.bib7)); Liang et al. ([2023](#bib.bib22)),
    a subset of 100 instances from the test sets of both ECQA and GSM8K are selectively
    sampled. For an in-depth analysis, we choose to conduct a comprehensive experiments
    of all 460 cases within the curated version of the FOLIO-wiki dataset, which removes
    the flawed cases to ensure the result authenticity.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 框架在一系列推理任务上实现，包括常识推理任务和两个演绎推理任务：（1）ECQA Aggarwal 等（[2021](#bib.bib1)）：一个以常识知识为中心的
    QA 数据集，（2）GSM8K Cobbe 等（[2021](#bib.bib10)）：一个由数学词题组成的基准，（3）FOLIO-wiki Zhang 等（[2023b](#bib.bib54)）：一个从
    FOLIO Han 等（[2022](#bib.bib16)）改编的数据集，适用于符号和自然语言演绎推理。根据计算资源的限制以及先前研究 Du 等（[2023](#bib.bib13)）；Chen
    等（[2023a](#bib.bib7)）；Liang 等（[2023](#bib.bib22)）设定的先例，从 ECQA 和 GSM8K 的测试集中选择了
    100 个实例的子集。为了深入分析，我们选择对 FOLIO-wiki 数据集的 460 个案例进行全面实验，去除了有缺陷的案例，以确保结果的真实性。
- en: 5 Experiments on Single LLM
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 实验：单一 LLM
- en: 'In this section, we conduct our experiments using a single LLM, ChatGPT-3.5\.
    To gain the initial insights, we provide an in-depth analysis of the FOLIO-wiki
    dataset, examining both single-agent settings and multi-agent discussions as detailed
    in Section [5.1](#S5.SS1 "5.1 Analysis of FOLIO-wiki Dataset ‣ 5 Experiments on
    Single LLM ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions
    the Key?"). Afterward, we extend our experiments to two other datasets GSM8K and
    ECQA in Section [5.2](#S5.SS2 "5.2 Evaluation on All Tasks ‣ 5 Experiments on
    Single LLM ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions
    the Key?"). We also investigate common mistakes made by discussions through a
    case study in Section [5.3](#S5.SS3 "5.3 Two Discussion Error Types: A Case Study
    ‣ 5 Experiments on Single LLM ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent
    Discussions the Key?"). Finally, we summarize our findings in Section [5.4](#S5.SS4
    "5.4 Summary ‣ 5 Experiments on Single LLM ‣ Rethinking the Bounds of LLM Reasoning:
    Are Multi-Agent Discussions the Key?").'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '在这一部分，我们使用单一的 LLM，ChatGPT-3.5，进行实验。为了获得初步见解，我们对 FOLIO-wiki 数据集进行了深入分析，研究了单一代理设置和多代理讨论，如[5.1](#S5.SS1
    "5.1 Analysis of FOLIO-wiki Dataset ‣ 5 Experiments on Single LLM ‣ Rethinking
    the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?")节中详细说明的那样。随后，我们在[5.2](#S5.SS2
    "5.2 Evaluation on All Tasks ‣ 5 Experiments on Single LLM ‣ Rethinking the Bounds
    of LLM Reasoning: Are Multi-Agent Discussions the Key?")节中将实验扩展到另外两个数据集 GSM8K
    和 ECQA。我们还通过[5.3](#S5.SS3 "5.3 Two Discussion Error Types: A Case Study ‣ 5 Experiments
    on Single LLM ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions
    the Key?")节中的案例研究调查了讨论中常见的错误。最后，我们在[5.4](#S5.SS4 "5.4 Summary ‣ 5 Experiments
    on Single LLM ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions
    the Key?")节中总结了我们的发现。'
- en: '| Prompt Components | Multi-Agent Discussion (%) | Single Agent (%) |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 提示组件 | 多代理讨论（%） | 单一代理（%） |'
- en: '| Q-Desc. | A-Desc. | Demo. | MAD (3) | Debate (3) | Debate (6) | CMD (6) |  |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| Q-Desc. | A-Desc. | Demo. | MAD (3) | Debate (3) | Debate (6) | CMD (6) |  |'
- en: '| ${\color[rgb]{0.765625,0.19140625,0.28515625}\definecolor[named]{pgfstrokecolor}{rgb}{0.765625,0.19140625,0.28515625}\usym{2717}}$
    | 64.13 | 70.00 | 69.13 | 73.26 | 70.22 |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| ${\color[rgb]{0.765625,0.19140625,0.28515625}\definecolor[named]{pgfstrokecolor}{rgb}{0.765625,0.19140625,0.28515625}\usym{2717}}$
    | 64.13 | 70.00 | 69.13 | 73.26 | 70.22 |'
- en: '| ${\color[rgb]{0.05859375,0.44140625,0.44921875}\definecolor[named]{pgfstrokecolor}{rgb}{0.05859375,0.44140625,0.44921875}\usym{2713}}$
    | 74.13 | 75.65 | 76.30 | 74.13 | 73.26 |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| ${\color[rgb]{0.05859375,0.44140625,0.44921875}\definecolor[named]{pgfstrokecolor}{rgb}{0.05859375,0.44140625,0.44921875}\usym{2713}}$
    | 74.13 | 75.65 | 76.30 | 74.13 | 73.26 |'
- en: '| ${\color[rgb]{0.765625,0.19140625,0.28515625}\definecolor[named]{pgfstrokecolor}{rgb}{0.765625,0.19140625,0.28515625}\usym{2717}}$
    | 68.91 | 71.96 | 71.74 | 73.89 | 71.30 |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| ${\color[rgb]{0.765625,0.19140625,0.28515625}\definecolor[named]{pgfstrokecolor}{rgb}{0.765625,0.19140625,0.28515625}\usym{2717}}$
    | 68.91 | 71.96 | 71.74 | 73.89 | 71.30 |'
- en: '| ${\color[rgb]{0.05859375,0.44140625,0.44921875}\definecolor[named]{pgfstrokecolor}{rgb}{0.05859375,0.44140625,0.44921875}\usym{2713}}$
    | 71.96 | 70.22 | 70.00 | 71.09 | 73.91 |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| ${\color[rgb]{0.05859375,0.44140625,0.44921875}\definecolor[named]{pgfstrokecolor}{rgb}{0.05859375,0.44140625,0.44921875}\usym{2713}}$
    | 71.96 | 70.22 | 70.00 | 71.09 | 73.91 |'
- en: '| ${\color[rgb]{0.05859375,0.44140625,0.44921875}\definecolor[named]{pgfstrokecolor}{rgb}{0.05859375,0.44140625,0.44921875}\usym{2713}}$
    | 74.13 | 75.65 | 74.78 | 77.39 | 76.09 |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| ${\color[rgb]{0.05859375,0.44140625,0.44921875}\definecolor[named]{pgfstrokecolor}{rgb}{0.05859375,0.44140625,0.44921875}\usym{2713}}$
    | 74.13 | 75.65 | 74.78 | 77.39 | 76.09 |'
- en: 'Table 1: Comparative performance of single-agent settings and multi-agent discussions
    on FOLIO-wiki using ChatGPT-3.5\. Abbreviations are: detailed question descriptions
    (Q-Desc.), and answer format descriptions (A-Desc.), demonstrations (Demo.). Only
    the question itself is used as input when prompt components are disabled. The
    number next to the framework represents the number of agents.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 表格1：使用ChatGPT-3.5对FOLIO-wiki的单一智能体设置和多智能体讨论的比较表现。缩写为：详细问题描述（Q-Desc.）、答案格式描述（A-Desc.）、示例（Demo.）。当提示组件被禁用时，仅使用问题本身作为输入。框架旁边的数字表示智能体的数量。
- en: 5.1 Analysis of FOLIO-wiki Dataset
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 FOLIO-wiki数据集分析
- en: 'We begin by examining if multi-agent discussions are more effective than an
    agent using the strongest prompt on FOLIO-wiki dataset. Drawing from previous
    research Wei et al. ([2022](#bib.bib41)); Ling et al. ([2023](#bib.bib23)) on
    crafting prompts for reasoning tasks, we divide the prompt into three parts: a
    detailed question description, which provides an in-depth background of the task;
    an answer format description, which instructs how an agent should reply; and a
    task-specific demonstration, which shows an example of a question and answer pair.
    For this task, we meticulously craft a demonstration for input prompt. We start
    by labeling each premise. After that, we quote all the premises and relate them
    to every step in the reasoning process by using these labels, until the final
    step is reached. A labeled example is similar to the case in Table [5](#A3.T5
    "Table 5 ‣ C.2 Round 1 Answer ‣ Appendix C An CMD Example ‣ Rethinking the Bounds
    of LLM Reasoning: Are Multi-Agent Discussions the Key?"). We then test the performance
    of various combinations of these components for both single agents and discussions.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '我们首先检查多智能体讨论是否比使用最强提示的单一智能体在FOLIO-wiki数据集上更有效。借鉴了Wei等人（[2022](#bib.bib41)）和Ling等人（[2023](#bib.bib23)）关于推理任务提示的研究，我们将提示分为三部分：详细的问题描述，提供任务的深入背景；答案格式描述，指导智能体如何回应；以及特定任务的示例，展示问题和答案对的示例。对于这个任务，我们精心制作了输入提示的示例。我们首先标记每个前提。之后，我们引用所有前提，并通过使用这些标签将它们与推理过程中的每一步关联，直到达到最后一步。一个标记的示例类似于表格[5](#A3.T5
    "Table 5 ‣ C.2 Round 1 Answer ‣ Appendix C An CMD Example ‣ Rethinking the Bounds
    of LLM Reasoning: Are Multi-Agent Discussions the Key?")中的案例。然后我们测试这些组件的各种组合在单一智能体和讨论中的表现。'
- en: 'Single Agent. We conduct an evaluation of different prompt components with
    a single agent, and the results are outlined in Table [1](#S5.T1 "Table 1 ‣ 5
    Experiments on Single LLM ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent
    Discussions the Key?"). This table shows that for both single-agent settings and
    multi-agent discussions, the inclusion of a detailed question description or a
    task-specific demonstration enhances reasoning abilities on the FOLIO-wiki dataset.
    The detailed question description is helpful because the possible answers to judge
    the correctness of a given proposition—true, false, or unknown—require clarity.
    Without such clarity, agents often struggle to differentiate between what is ‘false’
    and what is ‘unknown’. Most notably, the addition of a demonstration contributes
    significantly to improved performance, highlighting its value as the most impactful
    component, in line with what prior studies have suggested Min et al. ([2022](#bib.bib28)).'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '单一智能体。我们对单一智能体的不同提示组件进行了评估，结果见表格[1](#S5.T1 "Table 1 ‣ 5 Experiments on Single
    LLM ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the
    Key?")。该表显示，对于单一智能体设置和多智能体讨论，包含详细的问题描述或特定任务的示例都能增强FOLIO-wiki数据集上的推理能力。详细的问题描述是有帮助的，因为判断给定命题的正确性（真、假或未知）的可能答案需要清晰度。如果没有这种清晰度，智能体往往难以区分‘假’和‘未知’。特别值得注意的是，添加示例显著提高了性能，突显了它作为最具影响力组件的价值，与先前研究Min等人（[2022](#bib.bib28)）的建议一致。'
- en: 'Multi-Agent Discussions. We assess the same prompt components within multi-agent
    discussion setups, and Table [1](#S5.T1 "Table 1 ‣ 5 Experiments on Single LLM
    ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?")
    reveals three key insights: (1) Demonstrations and detailed question description
    enhance multi-agent discussions. (2) Despite similar overall performance, most
    multi-agent discussions do not surpass the single agent when a demonstration is
    introduced. (3) CMD performs better than both single-agent setups and other multi-agent
    discussion frameworks on the FOLIO-wiki dataset. Below is further analysis of
    our findings.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 多代理讨论。我们在多代理讨论设置中评估相同的提示组件，表[1](#S5.T1 "表 1 ‣ 5 次单一 LLM 实验 ‣ 重新思考 LLM 推理的界限：多代理讨论是关键吗？")揭示了三个关键见解：（1）示例和详细问题描述增强了多代理讨论。（2）尽管总体表现相似，但大多数多代理讨论在引入示例时并未超越单一代理。（3）CMD在FOLIO-wiki数据集上的表现优于单一代理设置和其他多代理讨论框架。以下是我们发现的进一步分析。
- en: A Strong Single Agent is Comparable to Discussion Frameworks. Analyzing experiments
    with single-agent settings and multi-agent discussions on the FOLIO-wiki dataset,
    we find that task-specific demonstrations significantly enhance a single agent’s
    performance. Additionally, we establish that a well-supported agent can perform
    on par with discussion frameworks. Our analysis indicates that prompt engineering
    can boost reasoning performance in large language models, with demonstrations
    in both single-agent and multi-agent discussions pushing towards the upper bound
    of performance.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 强大的单一代理与讨论框架可比。通过分析在FOLIO-wiki数据集上进行的单一代理设置和多代理讨论实验，我们发现任务特定的示例显著提升了单一代理的表现。此外，我们确定了一个良好支持的代理可以与讨论框架相媲美。我们的分析表明，提示工程可以提升大语言模型的推理性能，单一代理和多代理讨论中的示例均推动了性能的上限。
- en: 5.2 Evaluation on All Tasks
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 所有任务的评估
- en: '| Method | ECQA | GSM8K | FOLIO-wiki | Average |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | ECQA | GSM8K | FOLIO-wiki | 平均值 |'
- en: '| Direct | Demo | Direct | Demo | Direct | Demo | Direct | Demo |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| 直接 | 示例 | 直接 | 示例 | 直接 | 示例 | 直接 | 示例 |'
- en: '| Single Agent | 63.00 | 67.00 | 69.00 | 83.00 | 70.22 | 76.09 | 67.41 | 75.63
    |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 单一代理 | 63.00 | 67.00 | 69.00 | 83.00 | 70.22 | 76.09 | 67.41 | 75.63 |'
- en: '| MAD (3 Agents) | 55.00 | 58.00 | 74.00 | 78.00 | 61.25 | 74.13 | 63.42 |
    70.04 |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| MAD（3个代理） | 55.00 | 58.00 | 74.00 | 78.00 | 61.25 | 74.13 | 63.42 | 70.04
    |'
- en: '| Debate (3 Agents) | 67.00 | 65.00 | 78.00 | 81.00 | 70.00 | 75.65 | 71.67
    | 73.88 |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 辩论（3个代理） | 67.00 | 65.00 | 78.00 | 81.00 | 70.00 | 75.65 | 71.67 | 73.88
    |'
- en: '| Debate (6 Agents) | 65.00 | 64.00 | 74.00 | 78.00 | 69.13 | 74.78 | 69.38
    | 72.26 |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 辩论（6个代理） | 65.00 | 64.00 | 74.00 | 78.00 | 69.13 | 74.78 | 69.38 | 72.26
    |'
- en: '| CMD (6 Agents) | 64.00 | 63.00 | 75.00 | 83.00 | 73.26 | 77.39 | 70.75 |
    74.46 |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| CMD（6个代理） | 64.00 | 63.00 | 75.00 | 83.00 | 73.26 | 77.39 | 70.75 | 74.46
    |'
- en: 'Table 2: Results for all tasks, with and without demonstration settings included.
    Using ChatGPT-3.5\.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：所有任务的结果，包括和不包括示例设置。使用 ChatGPT-3.5\。
- en: 'In Section [5.1](#S5.SS1 "5.1 Analysis of FOLIO-wiki Dataset ‣ 5 Experiments
    on Single LLM ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions
    the Key?"), we discover that demonstrations play a pivotal role in enhancing performance
    on FOLIO-wiki dataset. With this insight in mind, we simplify our evaluation to
    two prompt scenarios: with (referred as direct) and without demonstrations (referred
    as demo). The results presented in Table [2](#S5.T2 "Table 2 ‣ 5.2 Evaluation
    on All Tasks ‣ 5 Experiments on Single LLM ‣ Rethinking the Bounds of LLM Reasoning:
    Are Multi-Agent Discussions the Key?") cover all tested reasoning tasks. The findings
    show: (1) With demonstrations, discussion frameworks and single-agent settings
    have comparable performance on average. This is consistent with our earlier observations.
    (2) Without demonstrations, CMD tend to surpass single-agent settings, both on
    average and in most individual tasks.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在[5.1](#S5.SS1 "5.1 FOLIO-wiki 数据集分析 ‣ 5 次单一 LLM 实验 ‣ 重新思考 LLM 推理的界限：多代理讨论是关键吗？")节中，我们发现示例在提升FOLIO-wiki数据集上的表现中发挥了关键作用。鉴于此，我们将评估简化为两种提示场景：有（称为直接）和无示例（称为示例）。表[2](#S5.T2
    "表 2 ‣ 5.2 所有任务的评估 ‣ 5 次单一 LLM 实验 ‣ 重新思考 LLM 推理的界限：多代理讨论是关键吗？")中呈现的结果涵盖了所有测试的推理任务。结果显示：（1）有示例的情况下，讨论框架和单一代理设置在平均表现上可比。这与我们早期的观察一致。（2）没有示例时，CMD在平均值和大多数单独任务上通常优于单一代理设置。
- en: When Does Discussion Work Better? Most Multi-agent discussion frameworks, especially
    CMD, achieve better performance compared with single-agent settings when neither
    is supported by demonstrations. We believe this is because, during discussions,
    the input from other agents can introduce new perspectives, leading to a more
    thorough reasoning process. Therefore, this collaborative advantage makes multi-agent
    discussions a more effective option in scenarios lacking specific expert knowledge
    or detailed examples.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论何时效果更好？大多数多代理讨论框架，特别是CMD，在没有演示支持的情况下，相比单代理设置能取得更好的性能。我们认为这是因为在讨论过程中，其他代理的输入可以带来新的视角，从而引导更为全面的推理过程。因此，这种协作优势使得多代理讨论在缺乏特定专家知识或详细示例的情况下成为更有效的选择。
- en: 'Why Does Discussion Frameworks Perform Differently on Tested Tasks? Table [2](#S5.T2
    "Table 2 ‣ 5.2 Evaluation on All Tasks ‣ 5 Experiments on Single LLM ‣ Rethinking
    the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?") indicates
    that MAD is the least effective among the frameworks tested. We suspect that this
    is because MAD incorporates a divergent thinking way, which asks agents to disagree
    with each other. This can sometimes hinder reasoning by introducing irrelevant
    information that complicates decision-making. We explore this further with an
    error analysis in Section [5.3](#S5.SS3 "5.3 Two Discussion Error Types: A Case
    Study ‣ 5 Experiments on Single LLM ‣ Rethinking the Bounds of LLM Reasoning:
    Are Multi-Agent Discussions the Key?"). Additionally, we observed unexpected behaviors
    from other discussion frameworks under specific conditions or tasks. For example,
    Debate and CMD perform worse on ECQA dataset when demonstrations are introduced.
    We hypothesize that because ECQA demands more commonsense knowledge than purely
    analytical reasoning, the single-source interaction stemming from a single LLM
    might cause agents to overthink. Instead of clarifying misunderstandings, the
    increased dialogue may introduce complexity without addressing the underlying
    knowledge gaps. In contrast to ECQA, datasets like GSM8K and FOLIO-wiki place
    a greater emphasis on deductive reasoning abilities. In these cases, the discussion
    process between agents can be beneficial as it allows them to identify and address
    flaws in each other’s reasoning through interaction.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么讨论框架在测试任务上表现不同？表[2](#S5.T2 "表 2 ‣ 5.2 对所有任务的评估 ‣ 5 单一LLM实验 ‣ 重新思考LLM推理的界限：多代理讨论是否是关键？")显示，MAD在测试的框架中效果最差。我们怀疑这是因为MAD采用了一种发散性思维方式，要求代理之间互相不同意。这有时会通过引入无关信息来阻碍推理，从而使决策过程复杂化。我们在第[5.3](#S5.SS3
    "5.3 两种讨论错误类型：案例研究 ‣ 5 单一LLM实验 ‣ 重新思考LLM推理的界限：多代理讨论是否是关键？")节进一步探讨了这一点。此外，我们还观察到其他讨论框架在特定条件或任务下表现出意外行为。例如，当引入演示时，Debate和CMD在ECQA数据集上的表现更差。我们推测，这可能是因为ECQA比纯粹的分析推理更需要常识知识，单一LLM的单源互动可能导致代理过度思考。增加的对话可能引入复杂性，而没有解决潜在的知识差距。与ECQA不同，像GSM8K和FOLIO-wiki这样的数据集更强调演绎推理能力。在这些情况下，代理之间的讨论过程可能是有益的，因为它允许代理通过互动识别和解决彼此推理中的缺陷。
- en: '5.3 Two Discussion Error Types: A Case Study'
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 两种讨论错误类型：案例研究
- en: '![Refer to caption](img/38d4cf38115711f7f77d6328455cac4f.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/38d4cf38115711f7f77d6328455cac4f.png)'
- en: 'Figure 4: Two common types of errors that may occur in multi-agent discussions
    are judge mistake and wrong answer propagation. These issues can lead to circumstances
    where a multi-agent discussion reaches an incorrect conclusion, even if single
    agent can arrive at the correct one.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：多代理讨论中可能出现的两种常见错误类型是判断错误和错误答案传播。这些问题可能导致多代理讨论得出错误的结论，即使单一代理可以得出正确的结论。
- en: 'Our experiments show that multi-agent discussions can sometimes reach incorrect
    conclusions on questions that a single agent answers correctly. Figure [4](#S5.F4
    "Figure 4 ‣ 5.3 Two Discussion Error Types: A Case Study ‣ 5 Experiments on Single
    LLM ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the
    Key?") presents an example from the FOLIO-wiki dataset illustrating this point:
    a single agent provides the correct answer, but multi-agent discussions lead to
    an erroneous result. We identify two unique types of errors in multi-agent discussions:
    (1) Judge Mistake: This occurs in situations where an agent serves as a judge
    to decide on the final answer. If there are varying responses among agents, the
    judge might select the incorrect option as the final verdict. Frameworks like
    MAD and CMD  are susceptible to this error, particularly when decisions are made
    during a tie. (2) Wrong Answer Propagation: This type of error happens when an
    agent, influenced by the input from others, deviates from its initial correct
    answer and adopts an incorrect consensus, spreading the mistake further in the
    discussion. This is the most common mistake the multi-agent discussion can make,
    even when most of their initial answers are correct.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实验表明，多代理讨论有时可能会对单一代理正确回答的问题得出错误的结论。图 [4](#S5.F4 "图 4 ‣ 5.3 两种讨论错误类型：案例研究
    ‣ 5 个单一 LLM 实验 ‣ 重新思考 LLM 推理的界限：多代理讨论是关键吗？") 展示了来自 FOLIO-wiki 数据集的一个示例：单一代理提供了正确的答案，但多代理讨论得出了错误的结果。我们在多代理讨论中识别了两种独特的错误类型：（1）**判断错误**：这种错误发生在一个代理担任裁判决定最终答案的情况下。如果代理之间的回答不一致，裁判可能会选择错误的选项作为最终裁决。像
    MAD 和 CMD 这样的框架容易出现这种错误，特别是在决定平局时。（2）**错误答案传播**：这种错误发生在一个代理受到其他代理输入的影响，偏离了其初始正确答案并采纳了错误的共识，从而在讨论中进一步传播错误。这是多代理讨论最常见的错误，即使他们的大多数初始答案都是正确的。
- en: 5.4 Summary
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 总结
- en: '| Method Category | LLM | ECQA | GSM8K | FOLIO-wiki | Average |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 方法类别 | LLM | ECQA | GSM8K | FOLIO-wiki | 平均值 |'
- en: '| Direct | Demo | Direct | Demo | Direct | Demo | Direct | Demo |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 直接 | 演示 | 直接 | 演示 | 直接 | 演示 | 直接 | 演示 |'
- en: '| Single Agent | Bard | 66.00 | 65.00 | 47.00 | 54.00 | 70.00 | 71.96 | 61.00
    | 63.65 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 单一代理 | Bard | 66.00 | 65.00 | 47.00 | 54.00 | 70.00 | 71.96 | 61.00 | 63.65
    |'
- en: '| Gemini Pro | 74.00 | 75.00 | 75.00 | 81.00 | 74.13 | 79.78 | 74.38 | 78.59
    |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| Gemini Pro | 74.00 | 75.00 | 75.00 | 81.00 | 74.13 | 79.78 | 74.38 | 78.59
    |'
- en: '| ChatGPT-3.5 | 63.00 | 67.00 | 69.00 | 83.00 | 70.22 | 76.09 | 67.41 | 75.63
    |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| ChatGPT-3.5 | 63.00 | 67.00 | 69.00 | 83.00 | 70.22 | 76.09 | 67.41 | 75.63
    |'
- en: '| Discussion | ReConcile (Bard, Gemini, ChatGPT) | 70.00 | 71.00 | 78.00 |
    83.00 | 80.34 | 81.09 | 76.11 | 78.36 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 讨论 | ReConcile（Bard、Gemini、ChatGPT） | 70.00 | 71.00 | 78.00 | 83.00 | 80.34
    | 81.09 | 76.11 | 78.36 |'
- en: '| Group Discussion | CMD (Bard, Gemini, ChatGPT) | 73.00 | 72.00 | 78.00 |
    82.00 | 79.78 | 81.96 | 76.93 | 78.66 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 小组讨论 | CMD（Bard、Gemini、ChatGPT） | 73.00 | 72.00 | 78.00 | 82.00 | 79.78 |
    81.96 | 76.93 | 78.66 |'
- en: 'Table 3: Results from single-agent and CMD across multiple LLMs on all tasks
    evaluated with two types of prompts: with demonstrations and without.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：单一代理和 CMD 在多个 LLM 上的结果，评估了两种提示类型：有演示和无演示。
- en: 'In this section, we evaluate various prompt component combinations for both
    single-agent settings and multi-agent discussions. Our findings suggest that multi-agent
    discussions are on par with a single agent when both have access to demonstrations.
    However, in the absence of demonstrations, multi-agent discussions generally outperform
    a single agent, making them a better option in scenarios where expert knowledge
    or detailed examples are insufficient. We also highlight unusual outcomes and
    present a case study to identify two frequent errors in multi-agent discussions:
    Judge Mistake and Wrong Answer Propagation.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们评估了单一代理和多代理讨论的各种提示组件组合。我们的发现表明，当单一代理和多代理讨论都可以访问演示时，两者的表现相当。然而，在缺乏演示的情况下，多代理讨论通常优于单一代理，使其在专家知识或详细示例不足的情况下成为更好的选择。我们还突出了不寻常的结果，并通过案例研究识别了多代理讨论中的两个常见错误：**判断错误**和**错误答案传播**。
- en: 6 Experiments on Multiple LLMs
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 个多 LLM 实验
- en: 'In this section, we expand our experimental scope from a single LLM to multiple
    LLMs for both single-agent settings and multi-agent discussion frameworks, which
    allows us to test the validity of our previous findings in multi-LLM scenarios.
    Specifically, we assess the performance of agents powered by three advanced LLMs:
    ChatGPT-3.5, Gemini Pro, and Bard. In Section [6.1](#S6.SS1 "6.1 Validate Findings
    on Multiple LLMs Scenarios ‣ 6 Experiments on Multiple LLMs ‣ Rethinking the Bounds
    of LLM Reasoning: Are Multi-Agent Discussions the Key?"), we compare the performance
    of three single-agent configurations, each using a different LLM, against multi-agent
    discussions leveraging all three LLMs. Our round-level analysis in Section [6.2](#S6.SS2
    "6.2 Enhancing Agents in Weaker LLMs with Support from Stronger LLMs ‣ 6 Experiments
    on Multiple LLMs ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions
    the Key?") yields another insight: an agent powered by stronger LLM can enhance
    the performance of an agent powered by a less capable LLM.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们将实验范围从单一 LLM 扩展到多个 LLM，包括单一代理设置和多代理讨论框架，这使我们能够测试我们在多 LLM 场景中先前发现的有效性。具体来说，我们评估了由三种先进
    LLM 支持的代理的性能：ChatGPT-3.5、Gemini Pro 和 Bard。在第 [6.1](#S6.SS1 "6.1 Validate Findings
    on Multiple LLMs Scenarios ‣ 6 Experiments on Multiple LLMs ‣ Rethinking the Bounds
    of LLM Reasoning: Are Multi-Agent Discussions the Key?") 节中，我们比较了三种单一代理配置（每种使用不同的
    LLM）与利用这三种 LLM 的多代理讨论的性能。在第 [6.2](#S6.SS2 "6.2 Enhancing Agents in Weaker LLMs
    with Support from Stronger LLMs ‣ 6 Experiments on Multiple LLMs ‣ Rethinking
    the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?") 节的轮次级分析中，我们得出了另一个见解：由更强大
    LLM 支持的代理可以提升由能力较弱 LLM 支持的代理的性能。'
- en: 6.1 Validate Findings on Multiple LLMs Scenarios
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 在多个 LLM 场景中验证发现
- en: 'In this section, we evaluate the performance of three single-agent settings,
    each supported by a different LLM, and two multi-agent discussion frameworks,
    ReConcile and CMD, across all tasks. We utilize two types of prompt settings for
    each task: one with demonstrations and one without. For the CMD framework, we
    organize six agents into two groups of three, with each agent in a group powered
    by one of the LLMs: ChatGPT-3.5, Gemini Pro, or Bard. The results presented in
    Table [3](#S5.T3 "Table 3 ‣ 5.4 Summary ‣ 5 Experiments on Single LLM ‣ Rethinking
    the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?") support our
    previous findings from Section [5](#S5 "5 Experiments on Single LLM ‣ Rethinking
    the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?") with some
    slight modifications.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们评估了三种单一代理设置的性能，每种设置由不同的 LLM 支持，以及两个多代理讨论框架，ReConcile 和 CMD，涵盖所有任务。我们为每个任务使用两种提示设置：一种有示例，一种没有。对于
    CMD 框架，我们将六个代理组织成两组，每组三人，每个代理组由一个 LLM 提供支持：ChatGPT-3.5、Gemini Pro 或 Bard。表格 [3](#S5.T3
    "Table 3 ‣ 5.4 Summary ‣ 5 Experiments on Single LLM ‣ Rethinking the Bounds of
    LLM Reasoning: Are Multi-Agent Discussions the Key?") 中呈现的结果支持我们在第 [5](#S5 "5
    Experiments on Single LLM ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent
    Discussions the Key?") 节中的发现，只是做了一些轻微的修改。'
- en: 'A Strong Single Agent is Comparable to Discussion Frameworks. Based on experimental
    results from Table [3](#S5.T3 "Table 3 ‣ 5.4 Summary ‣ 5 Experiments on Single
    LLM ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the
    Key?"), we can find that discussion frameworks perform comparably to a single
    agent powered by Gemini Pro when both are provided with demonstrations. This consolidates
    our earlier conclusion that a ‘strong’ single agent—supported by both a well-designed
    prompt and a SOTA LLM—can rival the performance of a multi-agent discussion framework.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '强大的单一代理与讨论框架相当。根据表格 [3](#S5.T3 "Table 3 ‣ 5.4 Summary ‣ 5 Experiments on Single
    LLM ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the
    Key?") 的实验结果，我们发现讨论框架在提供示例时的表现与由 Gemini Pro 支持的单一代理相当。这巩固了我们之前的结论，即一个由设计良好的提示和
    SOTA LLM 支持的‘强大’单一代理可以与多代理讨论框架的表现相抗衡。'
- en: 'Discussion Frameworks Outperform Single Agents with No Demonstration. Table
    [3](#S5.T3 "Table 3 ‣ 5.4 Summary ‣ 5 Experiments on Single LLM ‣ Rethinking the
    Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?") reveals that,
    in multi-LLM scenarios, multi-agent discussions outperform single agents when
    demonstrations are not provided. This outcome aligns with our previous observations
    in single LLM settings. Furthermore, CMD and ReConcile demonstrate similar performance
    when they both have no access to demonstrations and they are both powered by same
    LLMs. This indicates that our findings are consistent on different multi-LLM multi-agent
    discussions frameworks.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论框架在没有演示的情况下优于单一智能体。表[3](#S5.T3 "表 3 ‣ 5.4 摘要 ‣ 5 单一 LLM 实验 ‣ 重新思考 LLM 推理的界限：多智能体讨论是否是关键？")揭示了在多LLM场景中，当没有提供演示时，多智能体讨论优于单一智能体。这一结果与我们在单一
    LLM 设置中的先前观察一致。此外，CMD 和 ReConcile 在没有演示且由相同 LLM 支持的情况下表现相似。这表明我们的发现适用于不同的多LLM多智能体讨论框架。
- en: 6.2 Enhancing Agents in Weaker LLMs with Support from Stronger LLMs
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 通过更强 LLM 的支持增强较弱 LLM 的智能体
- en: '![Refer to caption](img/fd4226922a1c0d4d8d8efd7e80ce38ea.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/fd4226922a1c0d4d8d8efd7e80ce38ea.png)'
- en: (a) ReConcile (Discussion)
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: (a) ReConcile（讨论）
- en: '![Refer to caption](img/b025bd88432244c0f17adbfcba770143.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/b025bd88432244c0f17adbfcba770143.png)'
- en: (b) CMD (Group Discussion)
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: (b) CMD（小组讨论）
- en: 'Figure 5: Round-level performance of each LLM in multi-agent discussions on
    FOLIO-wiki dataset.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：FOLIO-wiki 数据集中每个 LLM 在多智能体讨论中的逐轮表现。
- en: 'As shown in Table [3](#S5.T3 "Table 3 ‣ 5.4 Summary ‣ 5 Experiments on Single
    LLM ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the
    Key?"), single agents using Bard show the least effectiveness in reasoning tasks
    such as those in the FOLIO-wiki dataset. However, multi-LLM multi-agent frameworks
    remain competitive. To understand how a less advanced LLM like Bard performs during
    multi-agent discussions, we further study the round-by-round performance of each
    LLM engaged in the discussions. Figure [5](#S6.F5 "Figure 5 ‣ 6.2 Enhancing Agents
    in Weaker LLMs with Support from Stronger LLMs ‣ 6 Experiments on Multiple LLMs
    ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?")
    demonstrates that agents with less capable LLMs like Bard and ChatGPT-3.5 gradually
    enhance their performance over consecutive rounds with the support of the more
    robust LLM, Gemini Pro. We infer that throughout the discussion, Gemini Pro assists
    in bridging the gaps in knowledge and reasoning for the less advanced LLMs, guiding
    towards a stronger line of reasoning. Notably, although there is a slight drop
    in the performance of Gemini Pro during the second round, it demonstrates resilience
    and recovers swiftly, largely maintaining its superior performance. Again, this
    finding is applicable to different multi-LLM discussions, specifically for both
    ReConcile and CMD.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如表[3](#S5.T3 "表 3 ‣ 5.4 摘要 ‣ 5 单一 LLM 实验 ‣ 重新思考 LLM 推理的界限：多智能体讨论是否是关键？")所示，使用
    Bard 的单一智能体在如 FOLIO-wiki 数据集中的推理任务中效果最差。然而，多LLM多智能体框架依然具有竞争力。为了了解像 Bard 这样较不先进的
    LLM 在多智能体讨论中的表现，我们进一步研究了每个参与讨论的 LLM 的逐轮表现。图[5](#S6.F5 "图 5 ‣ 6.2 通过更强的 LLM 支持增强较弱
    LLM 的智能体 ‣ 6 多个 LLM 实验 ‣ 重新思考 LLM 推理的界限：多智能体讨论是否是关键？") 表明，像 Bard 和 ChatGPT-3.5
    这样的能力较弱的 LLM 在更强的 LLM Gemini Pro 的支持下，逐渐提高了其表现。我们推测，在讨论过程中，Gemini Pro 帮助弥补了较不先进
    LLM 的知识和推理差距，引导其更强的推理路线。值得注意的是，尽管 Gemini Pro 在第二轮中表现略有下降，但它表现出恢复的韧性，并迅速恢复，大体上维持了其优越的表现。再次，这一发现适用于不同的多LLM讨论，特别是对于
    ReConcile 和 CMD。
- en: 7 Related Work
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 相关工作
- en: 7.1 Prompting LLM for Reasoning
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1 提示 LLM 进行推理
- en: Recent researches have experienced great progresses in building powerful LLMs
    (Brown et al., [2020](#bib.bib5); OpenAI, [2022](#bib.bib30), [2023](#bib.bib31))
    or exploring the strategy of adopting LLMs over many downstream tasks via prompt
    enigineering.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究在构建强大的 LLM（Brown 等，[2020](#bib.bib5)；OpenAI，[2022](#bib.bib30)，[2023](#bib.bib31)）或通过提示工程在多个下游任务中采用
    LLM 的策略方面取得了重大进展。
- en: By training with different knowledge textual sources and parameter size, various
    LLMs equipped with different reasoning capabilities are constructed, such as OPT
    (Zhang et al., [2022a](#bib.bib53)), LLaMA (Touvron et al., [2023a](#bib.bib37),
    [b](#bib.bib38)), BLOOM Scao et al. ([2022](#bib.bib33)), and PaLM Chowdhery et al.
    ([2022](#bib.bib9)); Anil et al. ([2023](#bib.bib3)). Recently, Gemini Pro Team
    et al. ([2023](#bib.bib36)) extends the capabilities of LLMs to the field of multi-modality.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用不同的知识文本来源和参数规模进行训练，构建了具有不同推理能力的各种 LLM，例如 OPT（Zhang 等人，[2022a](#bib.bib53)），LLaMA（Touvron
    等人，[2023a](#bib.bib37)，[b](#bib.bib38)），BLOOM Scao 等人（[2022](#bib.bib33)），以及 PaLM
    Chowdhery 等人（[2022](#bib.bib9)）；Anil 等人（[2023](#bib.bib3)）。最近，Gemini Pro Team
    等人（[2023](#bib.bib36)）将 LLM 的能力扩展到多模态领域。
- en: Numerous advancements have been made in the field of improving reasoning abilities
    of LLMs with prompt engineering. Chain of Thought (CoT) (Wei et al., [2022](#bib.bib41);
    Kojima et al., [2022](#bib.bib19)) is a linear problem-solving approach where
    each step builds upon the previous one. Fu et al. ([2022](#bib.bib15)) propose
    to apply CoT to multi-step reasoning tasks. To automate the CoT, Auto-CoT (Zhang
    et al., [2022b](#bib.bib55)) constructs demonstrations by sampling diverse questions
    and generating reasoning chains. Active-Prompt (Diao et al., [2023](#bib.bib12))
    aims to select the most uncertain questions for task-specific annotations. Other
    prompt strategies designed to enhance reasoning in LLMs include the PS Prompt
    (Wang et al., [2023](#bib.bib39)), which breaks tasks into subtasks, ToT (Yao
    et al., [2023a](#bib.bib49)) which expands on the reasoning process by considering
    multiple paths of reasoning and self-evaluating choices, the effective GoT (Yao
    et al., [2023b](#bib.bib50)), which frames thoughts as graphs, Natural Program
    (Ling et al., [2023](#bib.bib23)) which helps to improve the deductive reasoning
    tasks, re-reading prompt (Xu et al., [2023b](#bib.bib46)) which revisits the question
    information embedded within input prompts.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在提升 LLM 推理能力的领域，已经取得了大量进展。Chain of Thought (CoT)（Wei 等人，[2022](#bib.bib41)；Kojima
    等人，[2022](#bib.bib19)）是一种线性问题解决方法，其中每一步都建立在前一步之上。Fu 等人（[2022](#bib.bib15)）提出将
    CoT 应用于多步骤推理任务。为了自动化 CoT，Auto-CoT（Zhang 等人，[2022b](#bib.bib55)）通过采样不同的问题并生成推理链来构建示例。Active-Prompt（Diao
    等人，[2023](#bib.bib12)）旨在选择最不确定的问题进行任务特定的标注。其他旨在增强 LLM 推理的提示策略包括 PS Prompt（Wang
    等人，[2023](#bib.bib39)），它将任务分解为子任务，ToT（Yao 等人，[2023a](#bib.bib49)）通过考虑多条推理路径和自我评估选择来扩展推理过程，有效的
    GoT（Yao 等人，[2023b](#bib.bib50)），它将思维框架化为图，Natural Program（Ling 等人，[2023](#bib.bib23)）帮助提高演绎推理任务，re-reading
    prompt（Xu 等人，[2023b](#bib.bib46)）重新审视嵌入在输入提示中的问题信息。
- en: 7.2 Multi-agent Discussion for Reasoning with LLMs
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2 多代理讨论在 LLM 推理中的应用
- en: Multi-agent discussion utilizes multiple LLMs as agents to collectively discuss
    and reason given problems in an interactive way. Abundant researches have explored
    how to improve the reasoning ability of single LLM, while multi-agent discussion
    among LLMs is still under exploration.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 多代理讨论利用多个 LLM 作为代理，以互动的方式共同讨论和推理给定的问题。大量研究探讨了如何提高单一 LLM 的推理能力，而 LLM 之间的多代理讨论仍在探索中。
- en: The Multi-Agent Debate framework, introduced by Du et al. ([2023](#bib.bib13)),
    establishes a mechanism for symmetric discussions among agents. During the same
    period, the MAD (Multi-Agent Debate) framework (Liang et al., [2023](#bib.bib22))
    introduces an asymmetric mechanism design. It assigns different roles (debater
    and judge) asymmetrically. Other similar works include Chan et al. ([2023](#bib.bib6)).
    Also, the ReConcile framework (Chen et al., [2023a](#bib.bib7)) exemplifies an
    asymmetric discussion mechanism by involving different LLMs and using a weighted
    voting mechanism. To understand discussion more deeply, Zhang et al. ([2023a](#bib.bib52))
    aim to explain such collaboration mechanism in a social psychology view.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Multi-Agent Debate 框架，由 Du 等人（[2023](#bib.bib13)）引入，建立了一种代理之间对称讨论的机制。在同一时期，MAD（Multi-Agent
    Debate）框架（Liang 等人，[2023](#bib.bib22)）引入了一个不对称的机制设计。它不对称地分配了不同的角色（辩手和裁判）。其他类似的工作包括
    Chan 等人（[2023](#bib.bib6)）。此外，ReConcile 框架（Chen 等人，[2023a](#bib.bib7)）通过涉及不同的
    LLMs 并使用加权投票机制，展示了不对称讨论机制。为了更深入地理解讨论，Zhang 等人（[2023a](#bib.bib52)）旨在从社会心理学的角度解释这种协作机制。
- en: Unlike these works, we aim to explore the potential effects of prompting contents
    over the discussion process by our defined multi-agent group discussion framework
    CMD.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 与这些工作不同，我们的目标是通过我们定义的多代理组讨论框架 CMD 探索提示内容对讨论过程的潜在影响。
- en: 8 Conclusion
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 结论
- en: In this paper, we re-examine the claim that multi-agent discussions are superior
    to a single agent in reasoning tasks by conducting systematic experiments. We
    introduce a novel framework CMD for a comprehensive and fair assessment. By conducting
    experiments over standard benchmarks, we find that (1) A single agent with a strong
    prompt and powered by a strong LLM achieves comparable performance with multi-LLM
    multi-agent discussions; (2) In the absence of demonstrations, multi-agent discussion
    frameworks outperform single agents on most tasks; (3) When multiple LLMs are
    involved in multi-agent discussions, agents with stronger LLMs can enhance the
    performance of agents with weaker LLMs as discussion progresses.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们通过进行系统的实验重新审视多代理讨论是否优于单一代理的推理任务。我们引入了一个新的框架CMD，以进行全面和公平的评估。通过在标准基准上进行实验，我们发现（1）一个强大的提示和强大的LLM驱动的单一代理与多LLM多代理讨论的表现相当；（2）在没有示范的情况下，多代理讨论框架在大多数任务上优于单一代理；（3）当多个LLM参与多代理讨论时，具有更强LLM的代理可以提升具有较弱LLM的代理的表现。
- en: 9 Ethical Considerations
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9 伦理考虑
- en: 'Our study employs publicly available datasets and LLMs accesses via official
    APIs, ensuring responsible and ethical use. Specifically, our ethical considerations
    can be summarized as follows:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究使用公开可用的数据集和通过官方API访问的LLM，确保负责任和伦理的使用。具体而言，我们的伦理考虑可以总结如下：
- en: Public Datasets. Datasets we use are designed for academic research. No personal
    data has been processed.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 公开数据集。我们使用的数据集是为学术研究设计的。未处理任何个人数据。
- en: Licensed API Usage. Our application of LLMs complies with the API usage policies,
    maintaining fair use standards and respecting intellectual property.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 授权API使用。我们对LLM的应用遵循API使用政策，保持公平使用标准并尊重知识产权。
- en: Transparency. We provide detailed experimentation methods to allow for result
    reproduction and encourage transparent scientific practices.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 透明性。我们提供详细的实验方法，以便于结果重现，并鼓励透明的科学实践。
- en: 10 Limitations
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10 限制
- en: Our research offers comprehensive experiments to study the performance of a
    strong single agent and multi-agent discussions. However, several aspects highlighted
    below can be further refined and explored in future work.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究提供了全面的实验，以研究强单一代理和多代理讨论的表现。然而，下述几个方面可以在未来的工作中进一步完善和探索。
- en: Enhancing Agent Complexity. Currently, all discussion frameworks including CMD considers
    an LLM session as an AI Agent. This perspective simplifies the the concept of
    LLM-based AI Agent defined in the literature Weng ([2023](#bib.bib42)). By integrating
    more sophisticated techniques such as Tree-of-Thought Yao et al. ([2023a](#bib.bib49))
    or Cumulative Reasoning Zhang et al. ([2023b](#bib.bib54)), or incorporating with
    external tools or knowledge bases, we could potentially improve the overall reasoning
    performance of multi-agent discussions.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 增强代理复杂性。目前，所有讨论框架，包括CMD，都将LLM会话视为AI代理。这种观点简化了文献中定义的基于LLM的AI代理的概念 Weng ([2023](#bib.bib42))。通过整合更复杂的技术，如Tree-of-Thought
    Yao et al. ([2023a](#bib.bib49)) 或 Cumulative Reasoning Zhang et al. ([2023b](#bib.bib54))，或结合外部工具或知识库，我们可以潜在地提高多代理讨论的整体推理性能。
- en: Expanding Task Diversity. While our study mainly focuses on reasoning tasks
    for assessing both single-agent settings and multi-agent discussions, the adaptive
    nature of discussions allows for a broader types of applications. Future research
    could explore the use of agent discussions in diverse scenarios such as real-world
    strategic planning or the integration of agents into interactive gaming environments.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 扩大任务多样性。虽然我们的研究主要集中在评估单代理设置和多代理讨论的推理任务上，但讨论的自适应性质允许更广泛的应用。未来的研究可以探索在各种场景下使用代理讨论，例如现实世界的战略规划或将代理整合到互动游戏环境中。
- en: Experimenting with Additional LLMs. Due to computational and financial constraints,
    our investigation is limited to testing three LLMs—Bard, Gemini Pro, and ChatGPT-3.5\.
    Expanding our analysis to include additional LLMs could provide a more extensive
    understanding of the capabilities and variances across different language models,
    offering valuable insights into the generalizability and scalability of our findings
    in multi-agent discussion frameworks.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 实验附加LLM。由于计算和财务限制，我们的研究仅限于测试三种LLM——Bard、Gemini Pro 和 ChatGPT-3.5。扩展分析以包括更多LLM可能会提供对不同语言模型能力和差异的更广泛理解，为多代理讨论框架的普遍性和可扩展性提供宝贵见解。
- en: References
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Aggarwal et al. (2021) Shourya Aggarwal, Divyanshu Mandowara, Vishwajeet Agrawal,
    Dinesh Khandelwal, Parag Singla, and Dinesh Garg. 2021. Explanations for commonsenseqa:
    New dataset and models. In *Proceedings of the 59th Annual Meeting of the Association
    for Computational Linguistics and the 11th International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)*, pages 3050–3065.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Aggarwal 等人 (2021) Shourya Aggarwal, Divyanshu Mandowara, Vishwajeet Agrawal,
    Dinesh Khandelwal, Parag Singla, 和 Dinesh Garg. 2021. Commonsenseqa 的解释：新的数据集和模型。在
    *第59届计算语言学协会年会暨第11届国际联合自然语言处理会议（第1卷：长篇论文）*，第3050–3065页。
- en: 'Anderson (1972) Philip W Anderson. 1972. More is different: Broken symmetry
    and the nature of the hierarchical structure of science. *Science*, 177(4047):393–396.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anderson (1972) Philip W Anderson. 1972. 多即不同：破缺对称性与科学层次结构的性质。*科学*，177(4047):393–396。
- en: Anil et al. (2023) Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry
    Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng
    Chen, et al. 2023. Palm 2 technical report. *arXiv preprint arXiv:2305.10403*.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anil 等人 (2023) Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry
    Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng
    Chen, 等. 2023. Palm 2 技术报告。*arXiv 预印本 arXiv:2305.10403*。
- en: 'Besta et al. (2023) Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger,
    Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski,
    Piotr Nyczyk, et al. 2023. Graph of thoughts: Solving elaborate problems with
    large language models. *arXiv preprint arXiv:2308.09687*.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Besta 等人 (2023) Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger,
    Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski,
    Piotr Nyczyk, 等. 2023. 思维图：使用大型语言模型解决复杂问题。*arXiv 预印本 arXiv:2308.09687*。
- en: Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D
    Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
    Askell, et al. 2020. Language models are few-shot learners. *Advances in neural
    information processing systems*, 33:1877–1901.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown 等人 (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared
    D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
    Amanda Askell, 等. 2020. 语言模型是少样本学习者。*神经信息处理系统进展*，33:1877–1901。
- en: 'Chan et al. (2023) Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue,
    Shanghang Zhang, Jie Fu, and Zhiyuan Liu. 2023. Chateval: Towards better llm-based
    evaluators through multi-agent debate. *arXiv preprint arXiv:2308.07201*.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chan 等人 (2023) Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang
    Zhang, Jie Fu, 和 Zhiyuan Liu. 2023. Chateval：通过多智能体辩论提升 llm 评估器。*arXiv 预印本 arXiv:2308.07201*。
- en: 'Chen et al. (2023a) Justin Chih-Yao Chen, Swarnadeep Saha, and Mohit Bansal.
    2023a. Reconcile: Round-table conference improves reasoning via consensus among
    diverse llms. *arXiv preprint arXiv:2309.13007*.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人 (2023a) Justin Chih-Yao Chen, Swarnadeep Saha, 和 Mohit Bansal. 2023a.
    Reconcile：圆桌会议通过多样化 llms 之间的共识提升推理。*arXiv 预印本 arXiv:2309.13007*。
- en: Chen et al. (2023b) Xinyun Chen, Maxwell Lin, Nathanael Schärli, and Denny Zhou.
    2023b. Teaching large language models to self-debug. *arXiv preprint arXiv:2304.05128*.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人 (2023b) Xinyun Chen, Maxwell Lin, Nathanael Schärli, 和 Denny Zhou. 2023b.
    教授大型语言模型自我调试。*arXiv 预印本 arXiv:2304.05128*。
- en: 'Chowdhery et al. (2022) Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten
    Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton,
    Sebastian Gehrmann, et al. 2022. Palm: Scaling language modeling with pathways.
    *arXiv preprint arXiv:2204.02311*.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chowdhery 等人 (2022) Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten
    Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton,
    Sebastian Gehrmann, 等. 2022. Palm：通过路径扩展语言建模。*arXiv 预印本 arXiv:2204.02311*。
- en: Cobbe et al. (2021) Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen,
    Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro
    Nakano, et al. 2021. Training verifiers to solve math word problems. *arXiv preprint
    arXiv:2110.14168*.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cobbe 等人 (2021) Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo
    Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano,
    等. 2021. 训练验证器解决数学应用题。*arXiv 预印本 arXiv:2110.14168*。
- en: Daskalakis and Weinberg (2012) Constantinos Daskalakis and Seth Matthew Weinberg.
    2012. Symmetries and optimal multi-dimensional mechanism design. In *Proceedings
    of the 13th ACM conference on Electronic commerce*, pages 370–387.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Daskalakis 和 Weinberg (2012) Constantinos Daskalakis 和 Seth Matthew Weinberg.
    2012. 对称性与最优多维机制设计。在 *第13届ACM电子商务会议论文集*，第370–387页。
- en: Diao et al. (2023) Shizhe Diao, Pengcheng Wang, Yong Lin, and Tong Zhang. 2023.
    Active prompting with chain-of-thought for large language models. *arXiv preprint
    arXiv:2302.12246*.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Diao 等人 (2023) Shizhe Diao, Pengcheng Wang, Yong Lin, 和 Tong Zhang. 2023. 利用链式思维对大型语言模型进行主动提示。*arXiv
    预印本 arXiv:2302.12246*。
- en: Du et al. (2023) Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum,
    and Igor Mordatch. 2023. Improving factuality and reasoning in language models
    through multiagent debate. *arXiv preprint arXiv:2305.14325*.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Du 等人（2023）Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum 和 Igor
    Mordatch. 2023. 通过多代理辩论提高语言模型的真实性和推理能力。*arXiv 预印本 arXiv:2305.14325*。
- en: Dua et al. (2022) Dheeru Dua, Shivanshu Gupta, Sameer Singh, and Matt Gardner.
    2022. Successive prompting for decomposing complex questions. *arXiv preprint
    arXiv:2212.04092*.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dua 等人（2022）Dheeru Dua, Shivanshu Gupta, Sameer Singh 和 Matt Gardner. 2022.
    逐步提示以分解复杂问题。*arXiv 预印本 arXiv:2212.04092*。
- en: Fu et al. (2022) Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and Tushar
    Khot. 2022. Complexity-based prompting for multi-step reasoning. *arXiv preprint
    arXiv:2210.00720*.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fu 等人（2022）Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark 和 Tushar Khot. 2022.
    基于复杂度的多步骤推理提示。*arXiv 预印本 arXiv:2210.00720*。
- en: 'Han et al. (2022) Simeng Han, Hailey Schoelkopf, Yilun Zhao, Zhenting Qi, Martin
    Riddell, Luke Benson, Lucy Sun, Ekaterina Zubova, Yujie Qiao, Matthew Burtell,
    et al. 2022. Folio: Natural language reasoning with first-order logic. *arXiv
    preprint arXiv:2209.00840*.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Han 等人（2022）Simeng Han, Hailey Schoelkopf, Yilun Zhao, Zhenting Qi, Martin
    Riddell, Luke Benson, Lucy Sun, Ekaterina Zubova, Yujie Qiao, Matthew Burtell
    等人。2022. Folio: 使用一阶逻辑的自然语言推理。*arXiv 预印本 arXiv:2209.00840*。'
- en: 'Imani et al. (2023) Shima Imani, Liang Du, and Harsh Shrivastava. 2023. Mathprompter:
    Mathematical reasoning using large language models. *arXiv preprint arXiv:2303.05398*.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Imani 等人（2023）Shima Imani, Liang Du 和 Harsh Shrivastava. 2023. Mathprompter:
    使用大语言模型的数学推理。*arXiv 预印本 arXiv:2303.05398*。'
- en: 'Khot et al. (2022) Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle
    Richardson, Peter Clark, and Ashish Sabharwal. 2022. Decomposed prompting: A modular
    approach for solving complex tasks. *arXiv preprint arXiv:2210.02406*.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khot 等人（2022）Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson,
    Peter Clark 和 Ashish Sabharwal. 2022. 分解提示：解决复杂任务的模块化方法。*arXiv 预印本 arXiv:2210.02406*。
- en: Kojima et al. (2022) Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka
    Matsuo, and Yusuke Iwasawa. 2022. Large language models are zero-shot reasoners.
    *Advances in neural information processing systems*, 35:22199–22213.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kojima 等人（2022）Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo
    和 Yusuke Iwasawa. 2022. 大语言模型是零-shot 推理者。*神经信息处理系统进展*, 35:22199–22213。
- en: Laffont and Martimort (2000) Jean-Jacques Laffont and David Martimort. 2000.
    Mechanism design with collusion and correlation. *Econometrica*, 68(2):309–342.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Laffont 和 Martimort（2000）Jean-Jacques Laffont 和 David Martimort. 2000. 带有共谋和相关性的机制设计。*Econometrica*,
    68(2):309–342。
- en: Li et al. (2022) Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang
    Lou, and Weizhu Chen. 2022. On the advance of making language models better reasoners.
    *arXiv preprint arXiv:2206.02336*.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人（2022）Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang
    Lou 和 Weizhu Chen. 2022. 使语言模型成为更好的推理者的进展。*arXiv 预印本 arXiv:2206.02336*。
- en: Liang et al. (2023) Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang,
    Rui Wang, Yujiu Yang, Zhaopeng Tu, and Shuming Shi. 2023. Encouraging divergent
    thinking in large language models through multi-agent debate. *arXiv preprint
    arXiv:2305.19118*.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liang 等人（2023）Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui
    Wang, Yujiu Yang, Zhaopeng Tu 和 Shuming Shi. 2023. 通过多代理辩论鼓励大语言模型的发散思维。*arXiv
    预印本 arXiv:2305.19118*。
- en: Ling et al. (2023) Zhan Ling, Yunhao Fang, Xuanlin Li, Zhiao Huang, Mingu Lee,
    Roland Memisevic, and Hao Su. 2023. Deductive verification of chain-of-thought
    reasoning. *arXiv preprint arXiv:2306.03872*.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ling 等人（2023）Zhan Ling, Yunhao Fang, Xuanlin Li, Zhiao Huang, Mingu Lee, Roland
    Memisevic 和 Hao Su. 2023. 推理链的演绎验证。*arXiv 预印本 arXiv:2306.03872*。
- en: 'Liu et al. (2022) Ruibo Liu, Jason Wei, Shixiang Shane Gu, Te-Yen Wu, Soroush
    Vosoughi, Claire Cui, Denny Zhou, and Andrew M Dai. 2022. Mind’s eye: Grounded
    language model reasoning through simulation. *arXiv preprint arXiv:2210.05359*.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu 等人（2022）Ruibo Liu, Jason Wei, Shixiang Shane Gu, Te-Yen Wu, Soroush Vosoughi,
    Claire Cui, Denny Zhou 和 Andrew M Dai. 2022. Mind’s eye: 通过模拟进行的有根语言模型推理。*arXiv
    预印本 arXiv:2210.05359*。'
- en: 'Lu et al. (2023) Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang,
    Ying Nian Wu, Song-Chun Zhu, and Jianfeng Gao. 2023. Chameleon: Plug-and-play
    compositional reasoning with large language models. *arXiv preprint arXiv:2304.09842*.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lu 等人（2023）Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang, Ying
    Nian Wu, Song-Chun Zhu 和 Jianfeng Gao. 2023. Chameleon: 与大语言模型的即插即用组合推理。*arXiv
    预印本 arXiv:2304.09842*。'
- en: Madaan et al. (2022) Aman Madaan, Niket Tandon, Peter Clark, and Yiming Yang.
    2022. Memory-assisted prompt editing to improve gpt-3 after deployment. *arXiv
    preprint arXiv:2201.06009*.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Madaan 等人（2022）Aman Madaan, Niket Tandon, Peter Clark 和 Yiming Yang. 2022. 记忆辅助的提示编辑以改善
    GPT-3 部署后的表现。*arXiv 预印本 arXiv:2201.06009*。
- en: 'Madaan et al. (2023) Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan,
    Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang,
    et al. 2023. Self-refine: Iterative refinement with self-feedback. *arXiv preprint
    arXiv:2303.17651*.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Madaan et al. (2023) Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan,
    Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang,
    等. 2023. Self-refine: 自我反馈的迭代改进。*arXiv 预印本 arXiv:2303.17651*。'
- en: 'Min et al. (2022) Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis,
    Hannaneh Hajishirzi, and Luke Zettlemoyer. 2022. Rethinking the role of demonstrations:
    What makes in-context learning work? *arXiv preprint arXiv:2202.12837*.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Min et al. (2022) Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis,
    Hannaneh Hajishirzi, 和 Luke Zettlemoyer. 2022. 重新思考示范的作用：是什么使得上下文学习有效？*arXiv 预印本
    arXiv:2202.12837*。
- en: Minsky (1988) Marvin Minsky. 1988. *Society of mind*. Simon and Schuster.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Minsky (1988) Marvin Minsky. 1988. *心智社会*。Simon and Schuster。
- en: OpenAI (2022) OpenAI. 2022. Chatgpt. [https://openai.com/blog/chatgpt](https://openai.com/blog/chatgpt).
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI (2022) OpenAI. 2022. Chatgpt. [https://openai.com/blog/chatgpt](https://openai.com/blog/chatgpt)。
- en: OpenAI (2023) OpenAI. 2023. [Gpt-4 technical report](http://arxiv.org/abs/2303.08774).
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI (2023) OpenAI. 2023. [Gpt-4 技术报告](http://arxiv.org/abs/2303.08774)。
- en: Press et al. (2022) Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A
    Smith, and Mike Lewis. 2022. Measuring and narrowing the compositionality gap
    in language models. *arXiv preprint arXiv:2210.03350*.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Press et al. (2022) Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah
    A Smith, 和 Mike Lewis. 2022. 测量和缩小语言模型中的组合性差距。*arXiv 预印本 arXiv:2210.03350*。
- en: 'Scao et al. (2022) Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick,
    Suzana Ilić, Daniel Hesslow, Roman Castagné, Alexandra Sasha Luccioni, François
    Yvon, Matthias Gallé, et al. 2022. Bloom: A 176b-parameter open-access multilingual
    language model. *arXiv preprint arXiv:2211.05100*.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Scao et al. (2022) Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick,
    Suzana Ilić, Daniel Hesslow, Roman Castagné, Alexandra Sasha Luccioni, François
    Yvon, Matthias Gallé, 等. 2022. Bloom: 一个具有1760亿参数的开放获取多语言模型。*arXiv 预印本 arXiv:2211.05100*。'
- en: 'Shinn et al. (2023) Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik R
    Narasimhan, and Shunyu Yao. 2023. Reflexion: Language agents with verbal reinforcement
    learning. In *Thirty-seventh Conference on Neural Information Processing Systems*.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shinn et al. (2023) Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik
    R Narasimhan, 和 Shunyu Yao. 2023. Reflexion: 具有语言增强学习的语言代理。发表于 *第三十七届神经信息处理系统会议*。'
- en: Tapp (2021) Kristopher Tapp. 2021. *Symmetry*. Springer.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tapp (2021) Kristopher Tapp. 2021. *对称性*。Springer。
- en: 'Team et al. (2023) Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu,
    Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai,
    Anja Hauth, et al. 2023. Gemini: a family of highly capable multimodal models.
    *arXiv preprint arXiv:2312.11805*.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Team et al. (2023) Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu,
    Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai,
    Anja Hauth, 等. 2023. Gemini: 一系列高能力的多模态模型。*arXiv 预印本 arXiv:2312.11805*。'
- en: 'Touvron et al. (2023a) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
    Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal,
    Eric Hambro, Faisal Azhar, et al. 2023a. Llama: Open and efficient foundation
    language models. *arXiv preprint arXiv:2302.13971*.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Touvron et al. (2023a) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
    Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal,
    Eric Hambro, Faisal Azhar, 等. 2023a. Llama: 开放和高效的基础语言模型。*arXiv 预印本 arXiv:2302.13971*。'
- en: 'Touvron et al. (2023b) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, et al. 2023b. Llama 2: Open foundation and fine-tuned chat models.
    *arXiv preprint arXiv:2307.09288*.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Touvron et al. (2023b) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, 等. 2023b. Llama 2: 开放基础和微调聊天模型。*arXiv 预印本 arXiv:2307.09288*。'
- en: 'Wang et al. (2023) Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan,
    Roy Ka-Wei Lee, and Ee-Peng Lim. 2023. Plan-and-solve prompting: Improving zero-shot
    chain-of-thought reasoning by large language models. *arXiv preprint arXiv:2305.04091*.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. (2023) Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan,
    Roy Ka-Wei Lee, 和 Ee-Peng Lim. 2023. 计划与解决提示：通过大型语言模型改进零样本思维链推理。*arXiv 预印本 arXiv:2305.04091*。
- en: Wang et al. (2022) Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi,
    Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2022. Self-consistency improves
    chain of thought reasoning in language models. *arXiv preprint arXiv:2203.11171*.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. (2022) Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi,
    Sharan Narang, Aakanksha Chowdhery, 和 Denny Zhou. 2022. 自我一致性改善语言模型中的思维链推理。*arXiv
    预印本 arXiv:2203.11171*。
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei
    Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits
    reasoning in large language models. *Advances in Neural Information Processing
    Systems*, 35:24824–24837.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei
    Xia, Ed Chi, Quoc V Le, Denny Zhou, 等. 2022. Chain-of-thought 提示在大型语言模型中引发推理。*神经信息处理系统进展*,
    35:24824–24837。
- en: Weng (2023) Lilian Weng. 2023. [Llm-powered autonomous agents](https://lilianweng.github.io/posts/2023-06-23-agent/).
    *lilianweng.github.io*.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Weng (2023) Lilian Weng. 2023. [Llm-powered autonomous agents](https://lilianweng.github.io/posts/2023-06-23-agent/)。*lilianweng.github.io*。
- en: Weng et al. (2022) Yixuan Weng, Minjun Zhu, Shizhu He, Kang Liu, and Jun Zhao.
    2022. Large language models are reasoners with self-verification. *arXiv preprint
    arXiv:2212.09561*.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Weng et al. (2022) Yixuan Weng, Minjun Zhu, Shizhu He, Kang Liu, 和 Jun Zhao.
    2022. 大型语言模型是具有自我验证的推理者。*arXiv 预印本 arXiv:2212.09561*。
- en: 'Xi et al. (2023) Zhiheng Xi, Senjie Jin, Yuhao Zhou, Rui Zheng, Songyang Gao,
    Tao Gui, Qi Zhang, and Xuanjing Huang. 2023. Self-polish: Enhance reasoning in
    large language models via problem refinement. *arXiv preprint arXiv:2305.14497*.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Xi et al. (2023) Zhiheng Xi, Senjie Jin, Yuhao Zhou, Rui Zheng, Songyang Gao,
    Tao Gui, Qi Zhang, 和 Xuanjing Huang. 2023. Self-polish: 通过问题细化增强大型语言模型中的推理。*arXiv
    预印本 arXiv:2305.14497*。'
- en: Xu et al. (2023a) Fangzhi Xu, Qika Lin, Jiawei Han, Tianzhe Zhao, Jun Liu, and
    Erik Cambria. 2023a. Are large language models really good logical reasoners?
    a comprehensive evaluation from deductive, inductive and abductive views. *arXiv
    preprint arXiv:2306.09841*.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu et al. (2023a) Fangzhi Xu, Qika Lin, Jiawei Han, Tianzhe Zhao, Jun Liu, 和
    Erik Cambria. 2023a. 大型语言模型真的擅长逻辑推理吗？从演绎、归纳和溯因视角的全面评估。*arXiv 预印本 arXiv:2306.09841*。
- en: Xu et al. (2023b) Xiaohan Xu, Chongyang Tao, Tao Shen, Can Xu, Hongbo Xu, Guodong
    Long, and Jian-guang Lou. 2023b. Re-reading improves reasoning in language models.
    *arXiv preprint arXiv:2309.06275*.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu et al. (2023b) Xiaohan Xu, Chongyang Tao, Tao Shen, Can Xu, Hongbo Xu, Guodong
    Long, 和 Jian-guang Lou. 2023b. 再读提高语言模型中的推理能力。*arXiv 预印本 arXiv:2309.06275*。
- en: 'Xue et al. (2023) Tianci Xue, Ziqi Wang, Zhenhailong Wang, Chi Han, Pengfei
    Yu, and Heng Ji. 2023. Rcot: Detecting and rectifying factual inconsistency in
    reasoning by reversing chain-of-thought. *arXiv preprint arXiv:2305.11499*.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Xue et al. (2023) Tianci Xue, Ziqi Wang, Zhenhailong Wang, Chi Han, Pengfei
    Yu, 和 Heng Ji. 2023. RCOT: 通过反转思维链检测和纠正事实不一致。*arXiv 预印本 arXiv:2305.11499*。'
- en: 'Yang et al. (2022) Zhicheng Yang, Jinghui Qin, Jiaqi Chen, Liang Lin, and Xiaodan
    Liang. 2022. Logicsolver: Towards interpretable math word problem solving with
    logical prompt-enhanced learning. *arXiv preprint arXiv:2205.08232*.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yang et al. (2022) Zhicheng Yang, Jinghui Qin, Jiaqi Chen, Liang Lin, 和 Xiaodan
    Liang. 2022. Logicsolver: 通过逻辑提示增强学习来实现可解释的数学问题解决。*arXiv 预印本 arXiv:2205.08232*。'
- en: 'Yao et al. (2023a) Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L
    Griffiths, Yuan Cao, and Karthik Narasimhan. 2023a. Tree of thoughts: Deliberate
    problem solving with large language models. *arXiv preprint arXiv:2305.10601*.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yao et al. (2023a) Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas
    L Griffiths, Yuan Cao, 和 Karthik Narasimhan. 2023a. Tree of thoughts: 使用大型语言模型进行深思熟虑的问题解决。*arXiv
    预印本 arXiv:2305.10601*。'
- en: Yao et al. (2023b) Yao Yao, Zuchao Li, and Hai Zhao. 2023b. Beyond chain-of-thought,
    effective graph-of-thought reasoning in large language models. *arXiv preprint
    arXiv:2305.16582*.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao et al. (2023b) Yao Yao, Zuchao Li, 和 Hai Zhao. 2023b. 超越链式思维，大型语言模型中的有效图式思维推理。*arXiv
    预印本 arXiv:2305.16582*。
- en: 'Zelikman et al. (2022) Eric Zelikman, Yuhuai Wu, Jesse Mu, and Noah Goodman.
    2022. Star: Bootstrapping reasoning with reasoning. *Advances in Neural Information
    Processing Systems*, 35:15476–15488.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zelikman et al. (2022) Eric Zelikman, Yuhuai Wu, Jesse Mu, 和 Noah Goodman.
    2022. Star: 用推理来引导推理。*神经信息处理系统进展*, 35:15476–15488。'
- en: 'Zhang et al. (2023a) Jintian Zhang, Xin Xu, and Shumin Deng. 2023a. Exploring
    collaboration mechanisms for llm agents: A social psychology view. *arXiv preprint
    arXiv:2310.02124*.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2023a) Jintian Zhang, Xin Xu, 和 Shumin Deng. 2023a. 探索 LLM 代理的协作机制：一种社会心理学视角。*arXiv
    预印本 arXiv:2310.02124*。
- en: 'Zhang et al. (2022a) Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe,
    Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin,
    et al. 2022a. Opt: Open pre-trained transformer language models. *arXiv e-prints*,
    pages arXiv–2205.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang et al. (2022a) Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe,
    Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin,
    等. 2022a. Opt: 开放预训练的变换器语言模型。*arXiv e-prints*, 页码 arXiv–2205。'
- en: Zhang et al. (2023b) Yifan Zhang, Jingqin Yang, Yang Yuan, and Andrew Chi-Chih
    Yao. 2023b. Cumulative reasoning with large language models. *arXiv preprint arXiv:2308.04371*.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2023b) Yifan Zhang, Jingqin Yang, Yang Yuan, 和 Andrew Chi-Chih
    Yao. 2023b. 使用大型语言模型的累积推理。*arXiv 预印本 arXiv:2308.04371*。
- en: Zhang et al. (2022b) Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola. 2022b.
    Automatic chain of thought prompting in large language models. *arXiv preprint
    arXiv:2210.03493*.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang等人（2022b）Zhuosheng Zhang, Aston Zhang, Mu Li, 和 Alex Smola. 2022b. 大型语言模型中的自动思维链提示。*arXiv预印本arXiv:2210.03493*。
- en: Appendix A Discussion Engineering and Agent Symmetry
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录A 讨论工程与代理对称性
- en: This section introduces a general framework to understand the discussion engineering
    of large language models. Let $\mathcal{L}$ be the input text, the forward inference
    generates a response of surprising quality, which is written as
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了一个通用框架，以理解大型语言模型的讨论工程。设$\mathcal{L}$为输入文本，前向推断生成了令人惊讶的高质量响应，其形式为
- en: '|  | $\displaystyle\hat{y}=\mathcal{L}(x).$ |  | (1) |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\hat{y}=\mathcal{L}(x).$ |  | (1) |'
- en: Given the high price of obtaining one large language model, one essential research
    question is to unlock the reasoning capability of large language models so that
    they can perform better on various tasks. One of the key directions is prompt
    engineering, where the format and content of the input texts are decorated to
    improve performances for downstream tasks. Specifically, for a task $\mathcal{T}$
    is generated by prompt engineering, which is written as
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于获得一个大型语言模型的高价格，一个重要的研究问题是如何解锁大型语言模型的推理能力，以使其在各种任务中表现更好。一个关键方向是提示工程，其中输入文本的格式和内容经过装饰，以提高下游任务的表现。具体来说，对于由提示工程生成的任务$\mathcal{T}$，其形式为
- en: '|  | $\displaystyle\hat{y}=\mathcal{L}(p(x;\mathcal{T},\mathcal{L})).$ |  |
    (2) |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\hat{y}=\mathcal{L}(p(x;\mathcal{T},\mathcal{L})).$ |  |
    (2) |'
- en: Another way to improve the reasoning capability of $\mathcal{L}(x)$ is considered
    as
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 提高$\mathcal{L}(x)$推理能力的另一种方式被认为是
- en: '|  | $\displaystyle\hat{y}=M\left(x;\{(\mathcal{L}_{i},p_{i}(\cdot,\mathcal{T},\mathcal{L}_{i}))\}_{i=1}^{n}\right),$
    |  | (3) |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\hat{y}=M\left(x;\{(\mathcal{L}_{i},p_{i}(\cdot,\mathcal{T},\mathcal{L}_{i}))\}_{i=1}^{n}\right),$
    |  | (3) |'
- en: where $M$.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$M$。
- en: The discussion engineering, characterized by the mechanism $\mathcal{M}=(M,\{(\mathcal{L}_{i},p_{i})\}_{i=1}^{n})$.
    Under our framework, several examples are discussed.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论工程的机制为$\mathcal{M}=(M,\{(\mathcal{L}_{i},p_{i})\}_{i=1}^{n})$。在我们的框架下，讨论了几个例子。
- en: A.1 Agent symmetry in discussion engineering
  id: totrans-193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 讨论工程中的代理对称性
- en: Symmetry and its breaking is a fundamental concept and widely investigated in
    science (Anderson, [1972](#bib.bib2)). Symmetry also plays an important role in
    the context of mechanism design of multiple agents (Laffont and Martimort, [2000](#bib.bib20);
    Daskalakis and Weinberg, [2012](#bib.bib11)). Here we introduce a formal description
    to justify the agent symmetry of the mechanism $\mathcal{M}$.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 对称性及其破坏是一个基本概念，并在科学中广泛研究（Anderson, [1972](#bib.bib2)）。在多个代理的机制设计中，对称性也发挥了重要作用（Laffont和Martimort,
    [2000](#bib.bib20); Daskalakis和Weinberg, [2012](#bib.bib11)）。在这里，我们引入一个正式的描述来证明机制$\mathcal{M}$的代理对称性。
- en: Definition 1  (Computational graph).
  id: totrans-195
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义1  （计算图）。
- en: Given the mechanism $\mathcal{M}=(M,\{(\mathcal{L}_{i},p_{i})\}_{i=1}^{n})$.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 给定机制$\mathcal{M}=(M,\{(\mathcal{L}_{i},p_{i})\}_{i=1}^{n})$。
- en: We note that the graph $G$.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到图$G$。
- en: Then we introduce how the LLM agents are associated with the computational graph.
    To make an LLM conversational session, the entire conversational history is always
    concatenated as part of the input of each inference call, resulting in many additional
    connections of the computational graph. The presence of agents allows us to conceptually
    assume the agents “know” the information in the conversation history, and then
    the complexity of the graph can be largely reduced. In this paper, we consider
    the computational graph with agents, so the connections that feed conversation
    history to the inference nodes are ignored for simplicity.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们介绍如何将LLM代理与计算图关联。为了进行LLM对话会话，整个对话历史总是作为每次推断调用输入的一部分，从而导致计算图中出现许多额外的连接。代理的存在使我们可以在概念上假设代理“知道”对话历史中的信息，从而大大降低图的复杂性。在本文中，我们考虑了带有代理的计算图，因此为了简化，忽略了将对话历史传递给推断节点的连接。
- en: Let $\mathcal{A}=\{A_{1},...,A_{m}\}$.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 设$\mathcal{A}=\{A_{1},...,A_{m}\}$。
- en: Definition 2  (Agent assignment).
  id: totrans-200
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义2  （代理分配）。
- en: Let $\mathcal{A}=\{A_{1},...,A_{m}\}$ be the agent-inference assignment matrix,
    such that
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 设$\mathcal{A}=\{A_{1},...,A_{m}\}$为代理推断分配矩阵，使得
- en: '|  | $\displaystyle P_{ij}=\left\{\begin{array}[]{cc}1&amp;j=\alpha(i),\\ 0&amp;j\neq\alpha(i)\end{array}\right..$
    |  | (6) |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle P_{ij}=\left\{\begin{array}[]{cc}1&amp;j=\alpha(i),\\ 0&amp;j\neq\alpha(i)\end{array}\right..$
    |  | (6) |'
- en: The assignment matrix $P$.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 分配矩阵$P$。
- en: Then a multi-agent discussion mechanism is defined by the triple $D=(\mathcal{M},\mathcal{A},\alpha)=(G,\mathcal{A},\alpha)$,
    which is the central object of discussion engineering. Then, we can further introduce
    the concept of the coloring of the computational graph.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 然后一个多代理讨论机制由三元组 $D=(\mathcal{M},\mathcal{A},\alpha)=(G,\mathcal{A},\alpha)$
    定义，这是讨论工程中的核心对象。然后，我们可以进一步引入计算图着色的概念。
- en: Definition 3  (Agent coloring of the computational graph).
  id: totrans-205
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 3（计算图的代理着色）。
- en: Given the the multi-agent discussion $D=(G,\mathcal{A},\alpha)$ be a colored
    computational graph.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 给定多代理讨论 $D=(G,\mathcal{A},\alpha)$ 为一个着色的计算图。
- en: Then the agent symmetry is established by the permutation operation over the
    agent set $\mathcal{A}$. Then we can discuss the symmetry by the agent permutation.
    We begin with the concept of mechanism invariance.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 然后通过对代理集 $\mathcal{A}$ 的置换操作建立代理对称性。然后我们可以通过代理置换来讨论对称性。我们从机制不变性的概念开始。
- en: Definition 4  (Mechanism invariance under the agent permutation).
  id: totrans-208
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 4（代理置换下的机制不变性）。
- en: Given the multi-agent discussion $D=(G,\mathcal{A},\alpha)$, such that
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 给定多代理讨论 $D=(G,\mathcal{A},\alpha)$，如此定义
- en: (1)
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: $\phi$ is a bijection,
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\phi$ 是一个双射，
- en: (2)
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: $\forall(v_{i},v_{j})\in E,(\phi(v_{i}),\phi(v_{j}))\in E$,
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\forall(v_{i},v_{j})\in E,(\phi(v_{i}),\phi(v_{j}))\in E$，
- en: (3)
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3)
- en: $\forall v\in V,C^{D}(v)=C^{D_{\pi}}(\phi(v))$.
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\forall v\in V,C^{D}(v)=C^{D_{\pi}}(\phi(v))$。
- en: We can also define the model invariance to justify the symmetry in the multi-model
    setting (Chen et al., [2023a](#bib.bib7)).
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以定义模型不变性来证明多模型设置中的对称性（Chen et al., [2023a](#bib.bib7)）。
- en: Definition 5  (Model invariance under the agent permutation).
  id: totrans-217
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 5（代理置换下的模型不变性）。
- en: Given the agent $\mathcal{A}=\{A_{1},...,A_{m}\}$.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 给定代理 $\mathcal{A}=\{A_{1},...,A_{m}\}$。
- en: Following the definition of invariance, the symmetry group of agents is naturally
    defined following the standard algebra (Tapp, [2021](#bib.bib35)). The largest
    possible symmetry group for a discussion of $m$, and that of condition (3) implies
    the asymmetry in prompt decorators.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 根据不变性的定义，代理的对称群自然地按照标准代数定义（Tapp, [2021](#bib.bib35)）。对于一个 $m$ 的讨论，最大的可能对称群是，条件
    (3) 暗示了提示装饰中的非对称性。
- en: 'Appendix B CMD: Conquer and Merge Discussion Framework'
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B CMD：征服与合并讨论框架
- en: B.1 Motivation
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.1 动机
- en: 'The Debate framework proposes that an increased number of agents and discussion
    rounds will result in improved performance in multi-agent discussions (Du et al.,
    [2023](#bib.bib13)). Also, the ReConcile framework asserts that a greater number
    of discussion rounds leads to a higher level of consensus among agents, and the
    higher the consensus among agents, the more accurate the discussion outcomes become
    (Chen et al., [2023a](#bib.bib7)). However, as the number of agents increases
    in a discussion, it leads to increased overhead in each round of discussion: 1\.
    Each agent has to read more viewpoints from others, resulting in a sharp rise
    in input tokens. 2\. The increase in input tokens puts significant pressure on
    language models with context token limitations. Inspired by real-life group discussions,
    we propose a variant framework for Debate called CMD. Fig [3](#S2.F3 "Figure 3
    ‣ 2 Preliminary ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions
    the Key?") shows the overview of our method.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 'Debate 框架提出，增加代理数量和讨论轮次会提高多代理讨论的表现（Du et al., [2023](#bib.bib13)）。此外，ReConcile
    框架声称，讨论轮次的增加会导致代理间达成更高水平的一致性，而代理间的一致性越高，讨论结果的准确性也就越高（Chen et al., [2023a](#bib.bib7)）。然而，随着讨论中代理数量的增加，每轮讨论的开销也会增加：1\.
    每个代理需要阅读更多其他代理的观点，导致输入令牌数量急剧增加。2\. 输入令牌的增加对有上下文令牌限制的语言模型施加了重大压力。受现实生活中小组讨论的启发，我们提出了一种名为
    CMD 的 Debate 框架变体。图 [3](#S2.F3 "Figure 3 ‣ 2 Preliminary ‣ Rethinking the Bounds
    of LLM Reasoning: Are Multi-Agent Discussions the Key?") 显示了我们方法的概览。'
- en: B.2 Problem Definition
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.2 问题定义
- en: Assume that there are $n$ is
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 假设有 $n$ 是
- en: '|  | $1$2 |  | (7) |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (7) |'
- en: This represents that $A_{i}$. For example, different agents may be asked to
    hold different views at first.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 这代表 $A_{i}$。例如，不同的代理可能会被要求首先持有不同的观点。
- en: 'Algorithm 1 CMD: A Conquer and Merge Style Multi-Agents Discussion Framework'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 1 CMD：一种征服与合并风格的多代理讨论框架
- en: 1:Debate Task $\mathcal{Q}$33:end function
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 1:Debate 任务 $\mathcal{Q}$33:结束 函数
- en: B.3 CMD Stages
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.3 CMD 阶段
- en: Generally, there are three stages in CMD. In stage 1, the group map and all
    states will be initialized, then all the participants will generate their initial
    answers. Then, in stage 2, the participants will continue the discussion during
    the remaining rounds in groups. When the discussion round reaches the maximum
    number, it moves to stage 3\. In this stage, all participants will vote to get
    the final answer.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，CMD 中有三个阶段。在阶段 1 中，将初始化小组图和所有状态，然后所有参与者将生成他们的初始回答。然后，在阶段 2 中，参与者将在剩余的轮次中继续以小组形式进行讨论。当讨论轮次达到最大数量时，进入阶段
    3。在此阶段，所有参与者将投票以获得最终答案。
- en: •
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: $\mathsf{Stage\ 1:\ Group\ Discussion\ Initialization.}$.
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\mathsf{Stage\ 1:\ Group\ Discussion\ Initialization.}$.
- en: •
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: $\mathsf{Stage\ 2:\ Multi\ Rounds\ Discussion.}$,
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\mathsf{Stage\ 2:\ Multi\ Rounds\ Discussion.}$,
- en: '1.'
  id: totrans-235
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '1.'
- en: The algorithm will start to update the opinions history $O_{i}^{(r-1)}$ will
    gather local group explanations based on group members opinions.
  id: totrans-236
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 算法将开始更新意见历史 $O_{i}^{(r-1)}$，并基于组成员的意见收集本地小组解释。
- en: '2.'
  id: totrans-237
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '2.'
- en: To save up tokens, last round history $H$ for the further use.
  id: totrans-238
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了节省令牌，保留上轮历史 $H$ 以供后续使用。
- en: '3.'
  id: totrans-239
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '3.'
- en: Repeat 1\. and 2\. until the maximum number of discussion rounds is reached.
  id: totrans-240
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重复 1\. 和 2\. 直到达到最大讨论轮次数。
- en: •
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: $\mathsf{Stage\ 3:\ Vote\ for\ the\ Final\ Result.}$ for further discussion.
    If there is still a tie, new representatives will be designated for further discussion,
    until either the tie is resolved or only one agent is activated for the discussion.
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\mathsf{Stage\ 3:\ Vote\ for\ the\ Final\ Result.}$ 以便进一步讨论。如果仍然存在平局，将指定新的代表进行进一步讨论，直到解决平局或只有一个代理被激活进行讨论。
- en: B.4 Message-Passing Algorithm
  id: totrans-243
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.4 消息传递算法
- en: Below is the detailed message-passing algorithm that synchronize all agents
    messages during the discussion process. This algorithm supports various discussion
    architectures.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是详细的消息传递算法，该算法在讨论过程中同步所有代理的消息。此算法支持各种讨论架构。
- en: 'Algorithm 2 MesSync: A Message-Passing Algorithm for Multi-Agents Communication'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '算法 2 MesSync: 一种用于多代理通信的消息传递算法'
- en: 1:Discussion Rule $\mathcal{R}$ then break38:         end if39:     end while40:end function
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 1:讨论规则 $\mathcal{R}$ 然后 break38:         end if39:     end while40:end function
- en: Appendix C An CMD Example
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 C 一个 CMD 示例
- en: In the upcoming demonstration, we’ll walk you through the CMD framework from
    the viewpoint of agent A among six agents using ChatGPT-3.5.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的演示中，我们将从六名代理中代理 A 的视角，使用 ChatGPT-3.5 带您了解 CMD 框架。
- en: C.1 Meta Prompt
  id: totrans-249
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.1 元提示
- en: '|   System |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '|   系统 |'
- en: '| You will be asked to answer a correctness verification task of a deductive
    reasoing proposition. |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| 你将被要求回答一个关于演绎推理命题的正确性验证任务。 |'
- en: '| Use knowledge only comes from the given premises. |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| 仅使用来自给定前提的知识。 |'
- en: '| The suffix of your answer should be the your opinion of one of these answer
    type: |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| 你回答的后缀应是你对这些回答类型的意见: |'
- en: '| 1\. [Correct], 2\. [Incorrect], 3\. [Unknown]. |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| 1\. [正确], 2\. [错误], 3\. [未知]. |'
- en: '| Do not omit the brackets. |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| 不要遗漏括号。 |'
- en: '|   |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '|   |'
- en: 'Table 4: Vanilla Prompt'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '表 4: 基础提示'
- en: C.2 Round 1 Answer
  id: totrans-258
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.2 第 1 轮回答
- en: '|  Assistant (ChatGPT-3.5) - Agent A |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '|  助手 (ChatGPT-3.5) - Agent A |'
- en: '| First let’s write down all the premises with labels: |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| 首先，让我们写下所有带标签的前提: |'
- en: '| #1\. Neocrepidodera Corpulentas are flea beetles or moths. |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| #1\. Neocrepidodera Corpulentas 是跳甲还是蛾。 |'
- en: '| #2\. The species Neocrepidodera Corpulenta is in the Chrysomelidae family.
    |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| #2\. Neocrepidodera Corpulenta 这个物种在 Chrysomelidae 科中。 |'
- en: '| #3\. There are no moths within the Chrysomelidae family. |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| #3\. Chrysomelidae 科中没有蛾类。 |'
- en: '| Next, let’s answer the question step by step with reference to the question
    and reasoning process: |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| 接下来，让我们参考问题和推理过程逐步回答问题: |'
- en: '| #4\. (by #1, #2) Neocrepidodera Corpulenta is either a flea beetle or a moth,
    and it is in the Chrysomelidae family. |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| #4\. (根据 #1, #2) Neocrepidodera Corpulenta 要么是跳甲，要么是蛾，而且它在 Chrysomelidae
    科中。 |'
- en: '| #5\. (by #3, #4) Since there are no moths within the Chrysomelidae family,
    Neocrepidodera Corpulenta must be a flea beetle. |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| #5\. (根据 #3, #4) 由于 Chrysomelidae 科中没有蛾类，Neocrepidodera Corpulenta 必须是跳甲。
    |'
- en: '| Final Step (by #5): Neocrepidodera Corpulenta is a flea beetle, so the proposition
    “There are no flea beetles within the Chrysomelidae family” is [Incorrect]. |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| 最终步骤 (根据 #5): Neocrepidodera Corpulenta 是跳甲，因此命题“Chrysomelidae 科中没有跳甲”是 [错误]。
    |'
- en: '|   |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '|   |'
- en: 'Table 5: The Answer of Agent A in Round 1'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '表 5: 第 1 轮 Agent A 的回答'
- en: C.3 Middle System and User Prompts in Round 1
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.3 系统与用户提示在第 1 轮
- en: '|  System |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '|  系统 |'
- en: '| There are 2 groups of people discussing on the same topic. I will provide
    you the detailed opinions and reasoning steps from your group member and opinions
    from other group members. Use these opinions and your previous opinion as additional
    advice, note that they maybe wrong. Do not copy other’s entire answer, modify
    the part you believe is wrong. |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| 有两个小组在讨论相同的话题。我将提供你组员的详细意见和其他组员的意见。请使用这些意见和你之前的意见作为附加建议，注意它们可能是错误的。不要复制他人的全部答案，修改你认为错误的部分。
    |'
- en: '| Other group members’ opinions: |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| 其他组员的意见： |'
- en: '| Three agents think the proposition is Incorrect. |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| 三位代理人认为该命题是不正确的。 |'
- en: '| Your group’s opinions: |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| 你们组的意见： |'
- en: '| One agent thinks the proposition is Correct. Below is his answer: |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| 一位代理人认为该命题是正确的。以下是他的回答： |'
- en: '| First let’s write down all the premises with labels: |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| 首先，让我们将所有前提列出并标注： |'
- en: '| $\cdots$ |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| $\cdots$ |'
- en: '| Next, let’s answer the question step by step with reference to the question
    and reasoning process: |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| 接下来，让我们参考问题和推理过程逐步回答问题： |'
- en: '| #4\. (by #1, #2) Neocrepidodera Corpulenta is either a flea beetle or a moth,
    and it is in the Chrysomelidae family. |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| #4\. （由 #1、#2 提出）Neocrepidodera Corpulenta 要么是跳甲，要么是蛾子，它属于叶甲科。 |'
- en: '| #5\. (by #3) There are no moths within the Chrysomelidae family. |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| #5\. （由 #3 提出）在叶甲科中没有蛾子。 |'
- en: '| #6\. (by #4, #5) Neocrepidodera Corpulenta cannot be a moth because there
    are no moths in the Chrysomelidae family. |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| #6\. （由 #4、#5 提出）Neocrepidodera Corpulenta 不能是蛾子，因为叶甲科中没有蛾子。 |'
- en: '| Final Step (by #6): The proposition “There are no flea beetles within the
    Chrysomelidae family” is [Correct] because Neocrepidodera Corpulenta, which is
    in the Chrysomelidae family, cannot be a moth according to premise #5. |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| 最后一步（由 #6 提出）：命题“叶甲科中没有跳甲”是 [Correct] 的，因为根据前提 #5，Neocrepidodera Corpulenta
    属于叶甲科，因此不能是蛾子。 |'
- en: '| One agent thinks the proposition is Incorrect. Below is his answer: |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| 一位代理人认为该命题是不正确的。以下是他的回答： |'
- en: '| $\cdots$ |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| $\cdots$ |'
- en: '| Next, let’s answer the question step by step with reference to the question
    and reasoning process: |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| 接下来，让我们参考问题和推理过程逐步回答问题： |'
- en: '| #4\. (by #1, #2) Neocrepidodera Corpulenta is a species of Neocrepidodera
    Corpulentas, so it is either a flea beetle or a moth. |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| #4\. （由 #1、#2 提出）Neocrepidodera Corpulenta 是 Neocrepidodera Corpulentas 的一个物种，因此它要么是跳甲，要么是蛾子。
    |'
- en: '| #5\. (by #3, #4) Since there are no moths within the Chrysomelidae family,
    Neocrepidodera Corpulenta must be a flea beetle. |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| #5\. （由 #3、#4 提出）由于叶甲科中没有蛾子，Neocrepidodera Corpulenta 必须是跳甲。 |'
- en: '| Final Step (by #5): The proposition states that there are no flea beetles
    within the Chrysomelidae family. However, from premise #2, we know that Neocrepidodera
    Corpulenta, which is a flea beetle, is in the Chrysomelidae family. Therefore,
    the proposition is [Incorrect]. |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| 最后一步（由 #5 提出）：该命题声称叶甲科中没有跳甲。然而，根据前提 #2，我们知道 Neocrepidodera Corpulenta 是一种跳甲，并且它在叶甲科中。因此，该命题是
    [Incorrect]。 |'
- en: '| User |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| 用户 |'
- en: '| Use the provided opinions and your previous answer as additional advice critically,
    please provide an updated answer. Make sure to state your opinion over proposition
    at the end of the response in the given format: [Correct], [Incorrect] or [Unknown],
    and such format should be only used to determine the correctness of the proposition.
    |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| 请批判性地使用提供的意见和你之前的回答作为附加建议，提供一个更新的回答。在回答的最后，确保用以下格式陈述你对命题的看法：[Correct]、[Incorrect]
    或 [Unknown]，该格式仅用于确定命题的正确性。 |'
- en: '|   |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '|   |'
- en: 'Table 6: Middle System Prompt at the End of Round 1'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '| 表 6：第一轮结束时的中间系统提示 |'
- en: C.4 Round 2 Answer
  id: totrans-294
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.4 第二轮回答 |
- en: '|  Assistant (ChatGPT-3.5) - Agent A |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| 助理（ChatGPT-3.5） - 代理人 A |'
- en: '| Based on the opinions provided by the other group members and my previous
    answer, I will critically evaluate the reasoning steps and provide an updated
    answer. |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '| 根据其他组员提供的意见和我之前的回答，我将批判性地评估推理步骤并提供更新的答案。 |'
- en: '| The first agent from my group argues that the proposition is correct. Their
    reasoning is as follows: |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
  zh: '| 我组的第一位代理人认为该命题是正确的。他们的推理如下： |'
- en: '| #4\. (by #1, #2) Neocrepidodera Corpulenta is either a flea beetle or a moth,
    and it is in the Chrysomelidae family. |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '| #4\. （由 #1、#2 提出）Neocrepidodera Corpulenta 是跳甲或蛾子，它属于叶甲科。 |'
- en: '| #5\. (by #3) There are no moths within the Chrysomelidae family. |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| #5\. （由 #3 提出）在叶甲科中没有蛾子。 |'
- en: '| #6\. (by #4, #5) Neocrepidodera Corpulenta cannot be a moth because there
    are no moths in the Chrysomelidae family. |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '| #6\.（由 #4, #5）Neocrepidodera Corpulenta 不能是蛾子，因为 Chrysomelidae 科中没有蛾子。 |'
- en: '| Final Step (by #6): The proposition “There are no flea beetles within the
    Chrysomelidae family” is [Correct] because Neocrepidodera Corpulenta, which is
    in the Chrysomelidae family, cannot be a moth according to premise #5. |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '| 最终步骤（由 #6）：命题“Chrysomelidae 科中没有跳蚤甲虫”是 [正确的]，因为根据前提 #5，Neocrepidodera Corpulenta
    在 Chrysomelidae 科中，不能是蛾子。 |'
- en: '| The second agent from my group argues that the proposition is incorrect.
    Their reasoning is as follows: |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '| 我们组的第二个代理认为命题是错误的。他们的推理如下： |'
- en: '| #4\. (by #1, #2) Neocrepidodera Corpulenta is a species of Neocrepidodera
    Corpulentas, so it is either a flea beetle or a moth. |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '| #4\.（由 #1, #2）Neocrepidodera Corpulenta 是 Neocrepidodera Corpulentas 的一个物种，所以它要么是跳蚤甲虫，要么是蛾子。
    |'
- en: '| #5\. (by #3, #4) Since there are no moths within the Chrysomelidae family,
    Neocrepidodera Corpulenta must be a flea beetle. |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
  zh: '| #5\.（由 #3, #4）由于 Chrysomelidae 科中没有蛾子，Neocrepidodera Corpulenta 必须是跳蚤甲虫。
    |'
- en: '| Final Step (by #5): The proposition states that there are no flea beetles
    within the Chrysomelidae family. However, from premise #2, we know that Neocrepidodera
    Corpulenta, which is a flea beetle, is in the Chrysomelidae family. Therefore,
    the proposition is [Incorrect]. |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '| 最终步骤（由 #5）：命题声明 Chrysomelidae 科中没有跳蚤甲虫。然而，根据前提 #2，我们知道 Neocrepidodera Corpulenta
    是一种跳蚤甲虫，属于 Chrysomelidae 科。因此，命题是 [错误的]。 |'
- en: '| After critically evaluating the reasoning steps, I agree with the second
    agent from my group that the proposition is incorrect. Neocrepidodera Corpulenta
    is a species of Neocrepidodera Corpulentas, which are either flea beetles or moths
    according to premise #1\. Since Neocrepidodera Corpulenta is in the Chrysomelidae
    family according to premise #2, it cannot be concluded that there are no flea
    beetles within the Chrysomelidae family. Therefore, the proposition is [Incorrect].
    |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '| 在批判性地评估推理步骤后，我同意我们组的第二个代理的意见，即命题是错误的。Neocrepidodera Corpulenta 是 Neocrepidodera
    Corpulentas 的一个物种，根据前提 #1，这些物种要么是跳蚤甲虫，要么是蛾子。由于根据前提 #2，Neocrepidodera Corpulenta
    在 Chrysomelidae 科中，因此不能得出 Chrysomelidae 科中没有跳蚤甲虫的结论。因此，命题是 [错误的]。 |'
- en: '|   |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
  zh: '|   |'
- en: 'Table 7: The Answer of Agent A in Round 2'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7：第 2 轮代理 A 的回答
- en: C.5 Middle System Prompt at the End of Round 2
  id: totrans-309
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.5 第 2 轮结束时的中间系统提示
- en: '|  System |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
  zh: '| 系统 |'
- en: '| There are 2 groups of people discussing on the same topic. I will provide
    you the detailed opinions and reasoning steps from your group member and opinions
    from other group members. Use these opinions and your previous opinion as additional
    advice, note that they maybe wrong. Do not copy other’s entire answer, modify
    the part you believe is wrong. |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
  zh: '| 有 2 组人正在讨论同一话题。我将提供你组成员的详细意见和其他组成员的意见。使用这些意见和你之前的意见作为额外建议，注意它们可能是错误的。不要完全复制其他人的回答，修改你认为错误的部分。
    |'
- en: '| Other group members’ opinions: |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '| 其他组成员的意见： |'
- en: '| Three agents think the proposition is Incorrect. |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
  zh: '| 三个代理认为命题是错误的。 |'
- en: '| Your group’s opinions: |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| 你们组的意见： |'
- en: '| Two agents think the proposition is Incorrect. Below are their answers: |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| 两个代理认为命题是错误的。以下是他们的回答： |'
- en: '| $\cdots$ |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| $\cdots$ |'
- en: '| User |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| 用户 |'
- en: '| This part is the same user part shown in table [6](#A3.T6 "Table 6 ‣ C.3
    Middle System and User Prompts in Round 1 ‣ Appendix C An CMD Example ‣ Rethinking
    the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?"). |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '| 这部分与表格 [6](#A3.T6 "表 6 ‣ C.3 第 1 轮的中间系统和用户提示 ‣ 附录 C 一个 CMD 示例 ‣ 重新思考 LLM
    推理的范围：多代理讨论是否是关键？") 中显示的用户部分相同。 |'
- en: '|   |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '|   |'
- en: 'Table 8: Middle System Prompt at the End of Round 2'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8：第 2 轮结束时的中间系统提示
- en: C.6 Round 3 Answer
  id: totrans-321
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.6 第 3 轮回答
- en: '|  Assistant (ChatGPT-3.5) - Agent A |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| 助手（ChatGPT-3.5）- 代理 A |'
- en: '| Based on the opinions provided by the other group members and my previous
    answer, here is an updated response: |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| 基于其他组成员提供的意见和我之前的回答，以下是更新后的回应： |'
- en: '| First, let’s write down all the premises with labels: |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '| 首先，让我们写下所有带有标签的前提： |'
- en: '| #1\. Neocrepidodera Corpulentas are flea beetles or moths. |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
  zh: '| #1\. Neocrepidodera Corpulentas 是跳蚤甲虫或蛾子。 |'
- en: '| #2\. The species Neocrepidodera Corpulenta is in the Chrysomelidae family.
    |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
  zh: '| #2\. 物种 Neocrepidodera Corpulenta 在 Chrysomelidae 科中。 |'
- en: '| #3\. There are no moths within the Chrysomelidae family. |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
  zh: '| #3\. Chrysomelidae 科中没有蛾子。 |'
- en: '| Next, let’s answer the question step by step with reference to the question
    and reasoning process: |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
  zh: '| 接下来，让我们一步步回答这个问题，参考问题和推理过程： |'
- en: '| #4\. (by #1, #2) Neocrepidodera Corpulenta is either a flea beetle or a moth,
    and it is in the Chrysomelidae family. |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
  zh: '| #4\.（由 #1、#2 提供）Neocrepidodera Corpulenta 要么是跳蚤甲虫，要么是蛾子，并且它属于 Chrysomelidae
    科。 |'
- en: '| #5\. (by #3) There are no moths within the Chrysomelidae family. |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '| #5\.（由 #3 提供）Chrysomelidae 科中没有蛾子。 |'
- en: '| #6\. (by #4, #5) Neocrepidodera Corpulenta cannot be a moth because there
    are no moths in the Chrysomelidae family. |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
  zh: '| #6\.（由 #4、#5 提供）Neocrepidodera Corpulenta 不能是蛾子，因为 Chrysomelidae 科中没有蛾子。
    |'
- en: '| Final Step (by #6): The proposition “There are no flea beetles within the
    Chrysomelidae family” contradicts the given premises, as Neocrepidodera Corpulenta,
    which is in the Chrysomelidae family, is a flea beetle. Therefore, the proposition
    is [Incorrect]. |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '| 最终步骤（由 #6 提供）：命题“Chrysomelidae 科中没有跳蚤甲虫”与给定前提矛盾，因为 Neocrepidodera Corpulenta，属于
    Chrysomelidae 科，是跳蚤甲虫。因此，该命题为 [Incorrect]。 |'
- en: '| After critically evaluating the reasoning steps and considering the opinions
    provided by the other group members, I agree that the proposition is [Incorrect].
    The given premises state that Neocrepidodera Corpulenta is in the Chrysomelidae
    family and that it is either a flea beetle or a moth. Since there are no moths
    within the Chrysomelidae family, it can be concluded that Neocrepidodera Corpulenta
    must be a flea beetle. Therefore, the proposition “There are no flea beetles within
    the Chrysomelidae family” contradicts the given premises. |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
  zh: '| 在批判性评估推理步骤并考虑其他组成员提供的意见后，我同意该命题为 [Incorrect]。给定的前提声明 Neocrepidodera Corpulenta
    属于 Chrysomelidae 科，并且它要么是跳蚤甲虫，要么是蛾子。由于 Chrysomelidae 科中没有蛾子，因此可以得出结论，Neocrepidodera
    Corpulenta 必须是跳蚤甲虫。因此，命题“Chrysomelidae 科中没有跳蚤甲虫”与给定前提矛盾。 |'
- en: '|   |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
  zh: '|   |'
- en: 'Table 9: The Answer of Agent A in Round 3'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 表 9：A 代理人在第 3 轮的回答
- en: Appendix D CMD Secretary - A Tie Case Solution
  id: totrans-336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 D CMD 秘书 - 平局解决方案
- en: 'In the event of a tie between two groups, we suggest employing a secretary
    to resolve such cases. The complete chat transcript below in table [10](#A4.T10
    "Table 10 ‣ Appendix D CMD Secretary - A Tie Case Solution ‣ Rethinking the Bounds
    of LLM Reasoning: Are Multi-Agent Discussions the Key?") illustrates a scenario
    where the secretary provides the ultimate resolution.'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 如果两个组之间出现平局，我们建议聘请秘书来解决此类情况。下面表格 [10](#A4.T10 "表 10 ‣ 附录 D CMD 秘书 - 平局解决方案 ‣
    重新思考 LLM 推理的界限：多代理讨论是关键吗？") 中的完整聊天记录展示了秘书提供最终解决方案的场景。
- en: '|  System |'
  id: totrans-338
  prefs: []
  type: TYPE_TB
  zh: '|  系统 |'
- en: '| 6 agents are discussing the correctness of a proposition based on the given
    premises. The given premises are: $\cdots$ The proposition is: “IBM has an office
    in London or Zurich.” |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '| 6 名代理人在讨论基于给定前提的命题的正确性。给定的前提是： $\cdots$ 该命题是：“IBM 在伦敦或苏黎世有办公室。” |'
- en: '| However, now there is a draw: |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
  zh: '| 然而，现在出现了平局： |'
- en: '| Three agents think the proposition is Correct. Below is one of their answers:
    $\cdots$ |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '| 三位代理人认为该命题为 Correct。以下是其中一个回答： $\cdots$ |'
- en: '| Three agents think the proposition is Unknown. Below is one of their answers:
    $\cdots$ |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| 三位代理人认为该命题为 Unknown。以下是其中一个回答： $\cdots$ |'
- en: '| User |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '| 用户 |'
- en: '| Your task is to carefully determine which opinion is more plausible. Answer
    opinion types are: [Correct], [Incorrect], [Unknown]. You should give your response
    in the required format. You are forbidden to copy others’ reasoning steps. You
    can only use the given premises and your reasoning steps to answer the question.
    |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '| 您的任务是仔细确定哪种意见更为可信。回答意见类型为： [Correct]， [Incorrect]， [Unknown]。您应按照要求的格式给出回答。禁止复制他人的推理步骤。您只能使用给定的前提和您的推理步骤来回答问题。
    |'
- en: '| Here are the instructions how you organize your answer format: |'
  id: totrans-345
  prefs: []
  type: TYPE_TB
  zh: '| 以下是如何组织您的回答格式的说明： |'
- en: '| First, let’s write down all the premises with labels. The labels look like
    “#{premise_number}.” |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '| 首先，让我们列出所有带有标签的前提。标签格式为“#{premise_number}。” |'
- en: '| Next, let’s answer the question step by step with reference to the question
    and reasoing process. There will be a prefix in your every reasoning step with
    the format “#{number} (by {list_of_premises_and_steps_used})”. In your final step,
    you should come to your conclusion with the format “Final Step (by {list_of_premises_and_steps_used}):”.
    |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '| 接下来，让我们参考问题和推理过程逐步回答问题。您的每一步推理应带有前缀，格式为 “#{number}（由 {list_of_premises_and_steps_used}
    提供）”。在最终步骤中，您应以 “最终步骤（由 {list_of_premises_and_steps_used} 提供）：” 的格式得出结论。 |'
- en: '| The suffix of your answer should be the answer type: [Correct], [Incorrect]
    or [Unknown]. |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '| 您的回答的后缀应为回答类型： [Correct]， [Incorrect] 或 [Unknown]。 |'
- en: '| Here are several hints to help you conclude the final answer: |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
  zh: '| 这里有几个提示帮助你得出最终答案： |'
- en: '| 1\. Pay attention to the logic of quantifiers and distinguish the meanings
    of quantifiers such as “all” and “some”. |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '| 1\. 注意量词的逻辑，区分“所有”和“一些”等量词的含义。 |'
- en: '| 2\. When two quantifiers are connected as the premise of existence, the conclusion
    may not be established, that is, it is unknown. |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
  zh: '| 2\. 当两个量词作为存在的前提连接时，结论可能无法确定，即为未知。 |'
- en: '| Assistant (ChatGPT-3.5) - Secretary |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '| 助理（ChatGPT-3.5） - 秘书 |'
- en: '| First, let’s write down all the premises with labels: |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '| 首先，写下所有带标签的前提： |'
- en: '| #1\. Evangelos Eleftheriou is a Greek electrical engineer. |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '| #1\. Evangelos Eleftheriou 是一位希腊电气工程师。 |'
- en: '| #2\. Evangelos Eleftheriou worked for IBM in Zurich. |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| #2\. Evangelos Eleftheriou 曾在 IBM 苏黎世工作。 |'
- en: '| #3\. If a company has employees working for them somewhere, then they have
    an office there. |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| #3\. 如果公司在某地有员工工作，那么他们那里就有办事处。 |'
- en: '| #4\. IBM is a company. |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '| #4\. IBM 是一家企业。 |'
- en: '| Next, let’s answer the question step by step with reference to the question
    and reasoning process: |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '| 接下来，让我们一步步回答问题，并参考问题和推理过程： |'
- en: '| #5 (by #4, #3) Since IBM is a company, and according to premise #3, if a
    company has employees working for them somewhere, then they have an office there.
    Therefore, IBM has an office in Zurich. |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '| #5（由 #4, #3 提供）由于 IBM 是一家公司，且根据前提 #3，如果公司在某地有员工工作，那么他们那里就有办事处。因此，IBM 在苏黎世有办事处。
    |'
- en: '| Now, let’s consider the opinions of the other group members: |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| 现在，让我们考虑其他小组成员的意见： |'
- en: '| - One agent thinks the proposition is Correct. |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| - 一位代理认为该命题是正确的。 |'
- en: '| - Two agents think the proposition is Unknown. |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| - 两位代理认为该命题是未知的。 |'
- en: '| Considering the opinions of the other group members, there is disagreement
    regarding the correctness of the proposition. However, based on the premises and
    the reasoning process, it can be concluded that IBM has an office in Zurich. |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| 考虑到其他小组成员的意见，对该命题的正确性存在分歧。然而，根据前提和推理过程，可以得出 IBM 在苏黎世有办事处的结论。 |'
- en: '| Final Step (by #5): Since IBM has an office in Zurich, the proposition “IBM
    has an office in London or Zurich” is [Correct]. |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| 最终步骤（由 #5 提供）：由于 IBM 在苏黎世设有办事处，命题“IBM 在伦敦或苏黎世有办事处”是 [正确的]。 |'
- en: '|   |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '|   |'
- en: 'Table 10: Secretary to solve a tie case.'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 表 10：秘书解决平局情况。
- en: Appendix E Extended Related Work
  id: totrans-367
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 E 扩展相关工作
- en: E.1 Large language models $\mathcal{L}$
  id: totrans-368
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: E.1 大型语言模型 $\mathcal{L}$
- en: With the advent of large language models (LLMs) like GPT-3 (Brown et al., [2020](#bib.bib5)),
    chatGPT (OpenAI, [2022](#bib.bib30)), GPT-4 (OpenAI, [2023](#bib.bib31)), Llama
    series (Touvron et al., [2023a](#bib.bib37), [b](#bib.bib38)) and PaLM 2 (Anil
    et al., [2023](#bib.bib3)), prompt engineering is a burgeoning field that focuses
    on optimizing the output of language models by crafting effective input prompts.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 随着像 GPT-3 (Brown et al., [2020](#bib.bib5))、chatGPT (OpenAI, [2022](#bib.bib30))、GPT-4
    (OpenAI, [2023](#bib.bib31))、Llama 系列 (Touvron et al., [2023a](#bib.bib37), [b](#bib.bib38))
    和 PaLM 2 (Anil et al., [2023](#bib.bib3)) 等大型语言模型（LLMs）的出现，提示工程成为一个新兴领域，专注于通过精心设计输入提示来优化语言模型的输出。
- en: E.2 Prompt decorator $p(\cdot;\mathcal{T},\mathcal{L})$ for reasoning
  id: totrans-370
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: E.2 推理用的提示装饰器 $p(\cdot;\mathcal{T},\mathcal{L})$
- en: Numerous advancements have been made in the field of improving reasoning abilities
    of LLMs with prompt engineering. Chain of Thought (CoT) (Wei et al., [2022](#bib.bib41);
    Kojima et al., [2022](#bib.bib19)) is a linear problem-solving approach where
    each step builds upon the previous one. Fu et al. ([2022](#bib.bib15)) propose
    to apply CoT to multi-step reasoning tasks. To automate the CoT, Auto-CoT (Zhang
    et al., [2022b](#bib.bib55)) constructs demonstrations by sampling diverse questions
    and generating reasoning chains. Active-Prompt (Diao et al., [2023](#bib.bib12))
    aims to select the most uncertain questions for task-specific annotations. Other
    prompt strategies include PS prompt (Wang et al., [2023](#bib.bib39)) which divides
    task into subtasks then solve them, effective GoT (Yao et al., [2023b](#bib.bib50))
    which models human thought processes as a graph rather than a chain, Natural Program
    (Ling et al., [2023](#bib.bib23)) which helps to improve the deductive reasoning
    tasks, re-reading prompt (Xu et al., [2023b](#bib.bib46)) which revisits the question
    information embedded within input prompts.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用提示工程提升LLMs推理能力的领域取得了许多进展。思维链（CoT）（Wei 等， [2022](#bib.bib41)；Kojima 等， [2022](#bib.bib19)）是一种线性问题解决方法，其中每一步都建立在前一步的基础上。Fu
    等（[2022](#bib.bib15)）建议将CoT应用于多步骤推理任务。为了自动化CoT，Auto-CoT（Zhang 等， [2022b](#bib.bib55)）通过采样多样的问题并生成推理链来构建示例。Active-Prompt（Diao
    等， [2023](#bib.bib12)）旨在选择最不确定的问题以进行任务特定的注释。其他提示策略包括PS提示（Wang 等， [2023](#bib.bib39)），将任务分解为子任务然后解决它们；有效的GoT（Yao
    等， [2023b](#bib.bib50)），将人类思维过程建模为图而非链；自然程序（Ling 等， [2023](#bib.bib23)），帮助改善演绎推理任务；重读提示（Xu
    等， [2023b](#bib.bib46)），重新审视嵌入在输入提示中的问题信息。
- en: E.3 Mechanism $\mathcal{M}$ for reasoning
  id: totrans-372
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: E.3 推理机制 $\mathcal{M}$
- en: In addition to focusing on the design of prompts themselves, some works incorporate
    different mechanisms to assist language models in reasoning.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 除了专注于提示设计本身，一些研究还结合了不同的机制来帮助语言模型进行推理。
- en: 'The design directions of these mechanisms include: 1\. Breaking down the reasoning
    process into multiple stages, with possible verification at each stage. 2\. Optimizing
    the reasoning process via ensemble methods. 3\. Iteratively prompting the model
    for reflection and correction. 4\. Utilizing external tools to aid in reasoning.
    These approaches aim to enhance the overall reasoning capabilities of language
    models by introducing additional support and guidance throughout the process.'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 这些机制的设计方向包括：1. 将推理过程分解为多个阶段，并在每个阶段进行可能的验证。2. 通过集成方法优化推理过程。3. 迭代地提示模型进行反思和修正。4.
    利用外部工具辅助推理。这些方法旨在通过引入额外的支持和指导来提升语言模型的整体推理能力。
- en: Break Down the Reasoning Process into Multiple Stages. Self-Polish (Xi et al.,
    [2023](#bib.bib44)) make models to progressively refine given problems with multiple
    stages of prompts. Additionally, some works (Khot et al., [2022](#bib.bib18);
    Press et al., [2022](#bib.bib32); Dua et al., [2022](#bib.bib14); Zhang et al.,
    [2023b](#bib.bib54)) study over decomposing the tasks into smaller tasks, and
    use an individual prompt to solve each subtask.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 将推理过程分解为多个阶段。自我修正（Xi 等， [2023](#bib.bib44)）使模型通过多个阶段的提示逐步完善给定问题。此外，一些研究（Khot
    等， [2022](#bib.bib18)；Press 等， [2022](#bib.bib32)；Dua 等， [2022](#bib.bib14)；Zhang
    等， [2023b](#bib.bib54)）研究了将任务分解为更小的任务，并使用单独的提示解决每个子任务。
- en: 'Optimize the Reasoning Process via Ensemble Methods. Tree of Thoughts (ToT)
    (Yao et al., [2023a](#bib.bib49)) expands on the reasoning process by considering
    multiple paths of reasoning and self-evaluating choices. Graph of Thoughts (GoT)
    (Besta et al., [2023](#bib.bib4)) further advances this by modeling information
    as an arbitrary graph, enabling complex networks of thoughts. And some works propose
    to first sample reasoning pathsvthen vote for the best one, including self-consistency
    (Wang et al., [2022](#bib.bib40)) and step-aware verifier (Li et al., [2022](#bib.bib21)).
    Discussion Engineering is also one category of ensemble methods. We leave it to
    section [7](#S7 "7 Related Work ‣ Rethinking the Bounds of LLM Reasoning: Are
    Multi-Agent Discussions the Key?") for further introduction.'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: '通过集成方法优化推理过程。思维树（ToT）（Yao 等，[2023a](#bib.bib49)）通过考虑多条推理路径和自我评估选择来扩展推理过程。思维图（GoT）（Besta
    等，[2023](#bib.bib4)）进一步推进了这一点，通过将信息建模为任意图，从而实现复杂的思维网络。一些工作提议首先对推理路径进行采样，然后投票选择最佳路径，包括自一致性（Wang
    等，[2022](#bib.bib40)）和步骤感知验证器（Li 等，[2022](#bib.bib21)）。讨论工程也是一种集成方法。我们将在第[7](#S7
    "7 Related Work ‣ Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions
    the Key?")节中进一步介绍。'
- en: Iteratively Prompt the Model for Reflection and Correction. These works (Zelikman
    et al., [2022](#bib.bib51); Weng et al., [2022](#bib.bib43); Shinn et al., [2023](#bib.bib34);
    Madaan et al., [2023](#bib.bib27); Chen et al., [2023b](#bib.bib8); Xue et al.,
    [2023](#bib.bib47)) are mainly based on iteratively asking model to find the mistakes
    or inconsistencies among previous reasoning steps or the knowledge, then solve
    them one by one.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代性地提示模型进行反思和修正。这些工作（Zelikman 等，[2022](#bib.bib51)；Weng 等，[2022](#bib.bib43)；Shinn
    等，[2023](#bib.bib34)；Madaan 等，[2023](#bib.bib27)；Chen 等，[2023b](#bib.bib8)；Xue
    等，[2023](#bib.bib47)）主要基于迭代地要求模型找到之前推理步骤或知识中的错误或不一致之处，然后逐一解决这些问题。
- en: Utilize External Tools or Knowledge to Aid in Reasoning. Mind’s Eye (Liu et al.,
    [2022](#bib.bib24)) proposes to use physical simulator to help models reason in
    the physical world. There are also other works Lu et al. ([2023](#bib.bib25));
    Imani et al. ([2023](#bib.bib17)) will equip models with tools to solve problems.
    Further more, some works like MemPrompt (Madaan et al., [2022](#bib.bib26)) and
    LogicSolver Yang et al. ([2022](#bib.bib48)) use external knowledge to assist
    LLMs with reasoning.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 利用外部工具或知识来辅助推理。Mind’s Eye（Liu 等，[2022](#bib.bib24)）提议使用物理模拟器来帮助模型在物理世界中进行推理。还有其他一些工作，如
    Lu 等（[2023](#bib.bib25)）；Imani 等（[2023](#bib.bib17)）将为模型配备工具来解决问题。此外，一些工作，如 MemPrompt（Madaan
    等，[2022](#bib.bib26)）和 LogicSolver（Yang 等，[2022](#bib.bib48)）使用外部知识来辅助 LLM 的推理。
