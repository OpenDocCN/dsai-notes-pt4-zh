<!--yml

分类：未分类

日期：2025-01-11 11:43:28

-->

# 通过LLM代理进行自然语言的可解释多模态数据探索

> 来源：[https://arxiv.org/html/2412.18428/](https://arxiv.org/html/2412.18428/)

Farhad Nooralahzadeh [noor@zhaw.ch](mailto:noor@zhaw.ch) 苏黎世应用科技大学 瑞士,  Yi Zhang [zhay@zhaw.ch](mailto:zhay@zhaw.ch) 苏黎世应用科技大学 瑞士,  Jonathan Fürst [fues@zhaw.ch](mailto:fues@zhaw.ch) 苏黎世应用科技大学 瑞士 以及 Kurt Stockinger [stog@zhaw.ch](mailto:stog@zhaw.ch) 苏黎世应用科技大学 瑞士

###### 摘要。

国际企业、组织或医院收集大量的多模态数据，这些数据存储在数据库、文本文档、图像和视频中。尽管在多模态数据探索的各个领域以及将自然语言问题自动转换为数据库查询语言的数据库系统方面，最近取得了一些进展，但将数据库系统与其他非结构化模态（如图像）结合在一起进行自然语言查询的研究挑战仍然广泛未被探索。

本文提出了XMODE¹¹1源代码、数据和/或其他相关资源已在[https://github.com/yizhang-unifr/XMODE](https://github.com/yizhang-unifr/XMODE)发布。- 这是一个支持用自然语言进行可解释的多模态数据探索的系统。我们的方法基于以下研究贡献：（1）我们的系统受一个现实世界用例的启发，允许用户探索多模态信息系统。（2）XMODE利用基于LLM的代理AI框架将自然语言问题分解为子任务，例如文本到SQL生成和图像分析。（3）在关系数据和图像上的多模态数据集的实验结果表明，我们的系统在精度上不仅超过了当前最先进的多模态探索系统，还在查询延迟、API成本、计划效率和解释质量等多项性能指标上表现优异，得益于更有效地利用LLM的推理能力。

## 1\. 引言

设想一个不久的将来，医院中的医生、护士和数据科学家可以自然地访问数字化病人数据。这些数据包括电子健康记录（EHR），通常存储在关系数据库中 ([sivasubramaniamsm3,](https://arxiv.org/html/2412.18428v1#bib.bib19) ），还包括如 CT 扫描或 X 光片的医学影像和医疗专家撰写的相应报告（非结构化数据）。每个参与者都希望以自然语言互动查询这些数据集。不同的参与者具有不同的技能和探索目标。此外，鉴于应用领域，每个用户都希望准确了解系统如何评估他们的查询。支持这种场景的系统将解锁大量应用，从这个医学示例到对共享科学数据库（也包含结构化数据、文本、图像和视频）的查询、公共数据集的查询等。然而，构建这样的系统面临着在理解用户意图方面的重大研究挑战，这通常依赖于复杂的查询、查询多媒体数据库以及确保可解释性。

![参见说明文字](img/c5d7e1e086dd8218ebe7dc0d1d093dc2.png)

(a) 医疗数据探索

![参见说明文字](img/2ca223d598a1d5bd21fd2242c152a9e6.png)

(b) 艺术作品数据探索

图 1\. 自然语言在异构数据源中的多模态数据探索示例工作流。一个复杂的自然语言问题被分解成多个子问题，以更好地支持答案的可解释性。每个子问题都被指定到一个特定的任务（例如文本到 SQL 翻译或图像分析）。这些任务可以扩展为利用各种工具和机器学习模型，以解决回答用户自然语言问题所需的特定下游需求。

为了理解这些挑战，这里概述了一个涉及关系数据库、文本文件和图像的多模态探索的具体场景。假设一个用户用自然语言提出以下问题：展示吸烟的肺癌患者在过去12个月中的癌症病灶进展。（参见图[1](https://arxiv.org/html/2412.18428v1#S1.F1 "Figure 1 ‣ 1\. Introduction ‣ Explainable Multi-Modal Data Exploration in Natural Language via LLM Agent") b）的上半部分）。这个看似简单的查询包含了多面数据探索中的几个基本挑战。首先，它需要将自然语言查询分解成语义准确的子查询，每个子查询针对不同的数据模态，同时保持原始意图。在这个过程中，优化工作流顺序至关重要——确定哪些查询应首先执行，以最小化计算开销并最大化效率。例如，在检索和分析医学图像之前，通过结构化数据库查询筛选患者，相比直接分析所有可用图像，能够显著减少计算负担。在图1的示例中，自然语言$NL1$是一个文本到SQL的任务，用于查询已诊断为肺癌患者的姓名和年龄。结果随后用于$NL2$——一个图像分析任务——查找这些患者图像中的癌症病灶。最后，$NL3$——一个可视化任务——展示每个患者的癌症进展。这一工作流顺序是经过故意优化的：先进行结构化数据筛选，再进行计算量更大的图像分析任务。当考虑到疾病进展的时间因素时，复杂性进一步增加，这要求在不同模态和时间戳之间仔细对齐数据。此外，在医疗环境中，结果验证和透明度至关重要。用户必须能够追溯任何结论的来源数据，理解中间结果是如何得出的，并验证每个分析步骤的准确性。这就需要一个工作流，允许用户在进行后续分析阶段之前验证中间结果，并在结果与临床预期不符时有能力细化查询。

现在，想象一下未来不久的博物馆或艺术画廊，在那里，策展人、研究人员和数据科学家可以自然地访问和探索数字艺术收藏。这些数据包括关于画作的结构化信息，例如艺术家、标题、媒介和主题，这些通常存储在关系数据库中。该收藏还包括非结构化数据，如艺术评论和描述的全文，以及艺术作品的数字图像。与前面提到的医学数据探索用例类似，艺术作品探索用例也是多模态的，且需要分析异构数据（例如表格数据和图像），如图[1](https://arxiv.org/html/2412.18428v1#S1.F1 "Figure 1 ‣ 1\. Introduction ‣ Explainable Multi-Modal Data Exploration in Natural Language via LLM Agent")(b)所示。

本文的目标是通过设计和实现一个系统，支持自然语言中的多模态数据探索场景，以解决以下挑战：

+   •

    异构数据探索：我们如何设计一个系统，准确解释用户的自然语言查询，以高精度探索异构数据源？

+   •

    协调多个专家模型和工具进行数据探索：我们如何自动地将用户问题分解为子问题，并将这些子问题组织成工作流计划？我们如何根据依赖关系和并行执行的可能性，将这些任务委派给来自可用工具箱的合适专家模型？

+   •

    可解释性：我们如何设计一个系统，促进多模态探索，使最终用户能够追溯结论的源数据，理解中间结果是如何生成的，并识别因数据缺失而导致问题无法回答的情况？

现有的自然语言多模态数据探索工作主要遵循两种范式：(1) 多模态嵌入到单一查询语言中，例如，NeuralSQL ([bae2024ehrxqa,](https://arxiv.org/html/2412.18428v1#bib.bib1)) 将视觉问答功能直接嵌入SQL中；(2) 代理工作流，其中不同的工具（如关系数据库操作符、视觉模型）被智能地结合，以回答用户问题，例如Caesura ([urban2023caesura,](https://arxiv.org/html/2412.18428v1#bib.bib20))。

本文提出了XMODE——一种多模态数据探索系统，采用基于大型语言模型的代理框架来应对这些挑战。基本思路是先将复杂的自然语言问题分解为更简单的子问题。然后，每个问题被转换为特定任务的工作流。通过应用智能规划，我们的方法能够推理出工作流中哪个任务失败，从而重新规划该特定任务，而不是重启整个工作流。与类似的系统（如Caesura）相比，我们方法的优势在于，它通过构建有向无环任务图来实现任务并行执行，并且需要较少的提示工程令牌，从而提高了查询执行时间和API调用成本的效率。本文的主要贡献如下：

+   •

    更高的准确性：XMODE基于代理AI框架，凭借对数据探索管道中不同任务的智能协调，表现出比传统方法更高的多模态数据探索准确性。

+   •

    性能提升：XMODE通过并行性、推理和智能重新规划，展示了与现有技术相比的性能改进。

+   •

    更好的可解释性：XMODE通过让用户检查每个步骤的决策和推理过程，增强了可解释性，可以追溯到所有前置步骤的结果，直至最终输出。

+   •

    泛化能力：XMODE在零-shot设置下进行设计和评估，展示了其无需依赖上下文学习（ICL）即可执行复杂任务的能力，从而提升了适应性和可访问性。

## 2\. 相关工作

##### 文本到SQL系统。

近年来，得益于大型语言模型的进步，文本到SQL系统的研究领域取得了巨大进展（[Floratou2024,](https://arxiv.org/html/2412.18428v1#bib.bib5)；[pourreza2024din,](https://arxiv.org/html/2412.18428v1#bib.bib18)）。最初的成功可归因于相对简单的数据集，这些数据集仅包含几个表的数据库，例如Spider（[yu2018spider,](https://arxiv.org/html/2412.18428v1#bib.bib24)）。特别是引入了新的基准，如ScienceBenchmark（[zhang2023sciencebenchmark,](https://arxiv.org/html/2412.18428v1#bib.bib27)）或BIRD（[li2024can,](https://arxiv.org/html/2412.18428v1#bib.bib13)），进一步推动了这些系统的极限。大多数研究努力一直局限于用英语查询数据库，少数例外如Statbot.Swiss（[noor2024,](https://arxiv.org/html/2412.18428v1#bib.bib17)）。

##### 可解释性。

可解释性旨在通过阐明机器学习模型的决策过程，提供对这些模型如何做出预测的更深入理解。它努力提供透明度，使利益相关者能够理解、信任并有效管理这些模型产生的结果（[lundberg2017unified,](https://arxiv.org/html/2412.18428v1#bib.bib16) ; [kim2018interpretability,](https://arxiv.org/html/2412.18428v1#bib.bib10) ）。尽管人工智能领域最近取得了一些进展，但在自然语言数据探索任务中，可解释性仍然是一个未解的问题。最近，在多代理协作框架中（[wang2023towards,](https://arxiv.org/html/2412.18428v1#bib.bib23) ），可解释性已经被设计用来模仿人类式的自上而下推理，通过利用大语言模型（LLMs）广泛的知识。对于文本到SQL的任务，可解释性基本上是一个未被深入研究的课题，除了自动生成SQL语句并将其反向翻译为自然语言的研究（[bandyopadhyay2020natural,](https://arxiv.org/html/2412.18428v1#bib.bib2) ; [von2022improving,](https://arxiv.org/html/2412.18428v1#bib.bib22) ; [zhang2023sciencebenchmark,](https://arxiv.org/html/2412.18428v1#bib.bib27) ）之外。然而，反向翻译通常不足以完全解释一个系统如何得出答案，以及如何解释结果。

##### 多模态系统。

视频数据库管理系统（VDBMSs）支持对视频数据进行高效且复杂的查询，但通常仅限于视频数据（例如，([zhang2023equi,](https://arxiv.org/html/2412.18428v1#bib.bib25) ; [DBLP:journals/pvldb/KangBZ19,](https://arxiv.org/html/2412.18428v1#bib.bib7) ; [DBLP:conf/deem/KakkarCCXVDPBS023,](https://arxiv.org/html/2412.18428v1#bib.bib4) )）。ThalamusDB ([jo2024,](https://arxiv.org/html/2412.18428v1#bib.bib6) ) 支持多模态数据的查询，但需要使用SQL作为输入，并明确标识应应用于与视频或音频数据相关的属性的谓词。同样，MindsDB²²2https://docs.mindsdb.com 和 VIVA ([DBLP:conf/cidr/KangRBKZ22,](https://arxiv.org/html/2412.18428v1#bib.bib8) )要求用户编写SQL，并手动将来自关系表和模型的数据进行组合。视觉语言模型提供视频数据的文本描述（[zhang2024vision,](https://arxiv.org/html/2412.18428v1#bib.bib26)），但并非专门设计来支持精确的结构化查询。

与我们的方法最相关的是CAESURA（[urbanB24,](https://arxiv.org/html/2412.18428v1#bib.bib21)），它支持对多模态数据湖的自然语言查询，以及PALIMPZEST（[liu2024declarative,](https://arxiv.org/html/2412.18428v1#bib.bib15)），它可以优化AI工作负载。我们系统XMODE的关键区别在于它专注于高效协调各种模型调用及其依赖关系。这种方法不仅提高了延迟和成本效率，还通过最小化中间函数调用输出的干扰，提升了准确性。

此外，相关系统支持跨结构化和非结构化数据的多模态查询，并侧重于查询规划。然而，这些系统没有解决如何增强底层模型在自然语言数据探索任务中的准确性和可解释性的问题。在医学数据科学等领域，可解释性和答案合理性至关重要，因为医疗设备法规要求系统提供详细的解释，说明特定结果是如何得出的，以确保不会推荐可能致命的医疗治疗。

![参见说明](img/9f492ce48538d932e33f486400e98312.png)

图2\. XMODE系统架构。

## 3\. 系统设计

我们现在描述我们的系统设计，称为XMODE，它使得多模态数据探索可以通过自然语言进行解释。

### 3.1\. XMODE系统架构

![参见说明](img/40f30ca11596dfdba8e2c9c6e9d28dc7.png)

图3\. XMODE系统架构在ArtWork中的应用（[urban2023caesura,](https://arxiv.org/html/2412.18428v1#bib.bib20)），展示了处理多模态查询的示例。查询被自动分解成多个组件，例如text2SQL和图像分析，用户可以检查这些组件以确保可解释性。

![参见说明](img/68f020d417e303039f59ab7b0a0ac52f.png)

图4\. XMODE系统架构在EHRXQA中的应用（[bae2024ehrxqa,](https://arxiv.org/html/2412.18428v1#bib.bib1)），展示了处理多模态查询的示例。查询被自动分解成多个组件，用户可以检查这些组件以确保可解释性。

我们系统XMODE的架构如图[2](https://arxiv.org/html/2412.18428v1#S2.F2 "Figure 2 ‣ Multi-modal systems. ‣ 2\. Related Work ‣ Explainable Multi-Modal Data Exploration in Natural Language via LLM Agent")所示。我们通过一个应用于艺术品数据的示例查询来描述XMODE的五个主要组件，该查询涉及关系表格和图像：绘制每个世纪描绘战争的画作数量。系统的操作如图[3](https://arxiv.org/html/2412.18428v1#S3.F3 "Figure 3 ‣ 3.1\. System Architecture of XMODE ‣ 3\. System Design ‣ Explainable Multi-Modal Data Exploration in Natural Language via LLM Agent")所示。

XMODE是一个代理系统（[kapoor2024ai,](https://arxiv.org/html/2412.18428v1#bib.bib9)），由基于LLM的动态规划模式驱动（[kim2023llm,](https://arxiv.org/html/2412.18428v1#bib.bib11)），配备了一个包含所有必要模型的全面工具包，用于将用户的问题（例如多模态自然语言问题）分解成工作流（即子问题的图）。工作流表示为一个有向无环图（DAG），其中每个节点对应一个简单的子问题，且由规划器分配了特定的工具。规划器确定可以并行执行的子任务，并管理它们之间的依赖关系。XMODE设计上具有适应性，能够在必要时进行动态调试和计划修改（重新规划），例如在执行text-to-SQL子任务时发生失败的情况下。正如图[1](https://arxiv.org/html/2412.18428v1#S1.F1 "Figure 1 ‣ 1\. Introduction ‣ Explainable Multi-Modal Data Exploration in Natural Language via LLM Agent")所示，XMODE的设计包含了多个组件：

1.  (1)

    规划与专家模型分配。系统分析用户的问题，然后构建一个任务序列，考虑到任务之间的依赖关系。它从可用工具包中为每个任务确定所需的专家模型，以及它们的输入参数和相互依赖关系，从而将它们合成一个工作流。为此，它利用了大型语言模型（LLMs）的推理能力。此阶段的输出是一个形式为DAG的工作流，正式化了任务依赖关系。正如我们在图[3](https://arxiv.org/html/2412.18428v1#S3.F3 "Figure 3 ‣ 3.1\. System Architecture of XMODE ‣ 3\. System Design ‣ Explainable Multi-Modal Data Exploration in Natural Language via LLM Agent")中看到的，原始的自然语言问题被分解为四个任务$t_{1}$到$t_{4}$，分别是text2SQL、image_analysis、data_preparation和data_plotting。我们利用LLMs的推理能力，通过提供工具包中每个专家模型的详细规范，从自然语言问题生成工作流。

1.  (2)

    执行与自我调试。系统根据生成的工作流执行任务，通过调用工具包中的分配专家模型来实现。系统使用一个状态对象来存储工作流执行过程中的所有中间交互。独立的任务并行执行，在每个任务完成后，结果作为输入传递给依赖于它们的任务，按照工作流进行。每个专家模型都有一个内部自我调试组件，用于处理执行过程中可能出现的错误。正如我们在图[3](https://arxiv.org/html/2412.18428v1#S3.F3 "Figure 3 ‣ 3.1\. System Architecture of XMODE ‣ 3\. System Design ‣ Explainable Multi-Modal Data Exploration in Natural Language via LLM Agent")的中间部分看到的，XMODE为每个任务提供了自然语言推理，易于人类理解。

1.  (3)

    决策制定。在这一部分，XMODE合成来自状态对象的结果，并检查它们以作出最终决策。如果任务结果足够满足用户请求，它将准备最终结果以响应用户；否则，它将请求规划组件重新规划一个新工作流，并提供中间结果和重新规划的原因。这个过程会重复，直到决策组件对最终结果满意并呈现给用户，或者达到最大循环限制。该组件受益于大语言模型（LLM）在决策制定过程中的推理能力。

1.  (4)

    专家模型与工具。该组件包含专家模型，如执行特定下游任务的机器学习模型，包括文本到SQL、图像分析和文本分析。它还包含特定工具，如数据格式化和绘图工具。考虑到各种使用场景，XMODE的工具包部分提供了对这些模型和工具的访问。每个专家模型或工具应包括描述和参数规范，它们将提供给规划模块。

1.  (5)

    数据湖。一个包含结构化和非结构化数据的库，如表格数据、图像和文本。每个模型专家和工具可以直接访问该库，以执行指定的任务。

我们当前的XMODE实现提供了一系列功能，包括查询调试、查询重新规划、优化和可解释性，以便更好地理解自然语言问题是如何被拆解成多个子任务的。我们系统的每个功能都在不同的复杂度级别下可用。

## 4\. 实验

在本节中，我们评估系统XMODE的性能。具体来说，我们希望解决以下研究问题：

+   •

    XMODE在两个不同数据集上的多模态自然语言问题处理效果如何，这些数据集包含表格数据和图像？

+   •

    与诸如CAESURA（[urbanB24,](https://arxiv.org/html/2412.18428v1#bib.bib21)）和NeuralSQL（[bae2024ehrxqa,](https://arxiv.org/html/2412.18428v1#bib.bib1)）等最先进系统相比，该系统的表现如何？

+   •

    系统提供了哪些解释来证明答案的正确性？

### 4.1\. 实验设置

#### 4.1.1\. 数据集

在我们的实验中，我们使用了两个不同的数据集，分别是关于艺术品的信息以及电子健康记录。

数据集1：艺术作品。我们使用由([urbanB24,](https://arxiv.org/html/2412.18428v1#bib.bib21)）介绍的艺术作品数据集。该数据集包含以表格形式呈现的绘画信息，以及包含100幅艺术作品图像的图像集。数据来源于Wikipedia。表格数据包含有关绘画的元数据，如标题、创作时间、艺术流派等，以及对相应绘画的引用。该数据集的一个典型示例问题是：绘制每个世纪描绘战争的绘画数量（如图[3](https://arxiv.org/html/2412.18428v1#S3.F3 "Figure 3 ‣ 3.1\. System Architecture of XMODE ‣ 3\. System Design ‣ Explainable Multi-Modal Data Exploration in Natural Language via LLM Agent")中所示）。除了艺术作品数据集中的24个现有问题外，我们提出了六个新问题，旨在评估并行任务规划与执行，促进对两种架构特点的比较。这六个问题涉及单一和多模态的数据。此外，六个问题中的四个要求以不同格式回答：两个问题要求绘制两张图表，另外两个问题涉及绘图并以特定数据结构展示结果，即以表格格式或JSON格式展示。最终的测试数据集包含从艺术作品数据集中的24个问题派生出的30个自然语言问题。这些问题包括8个要求单一结果值的查询，11个要求结构化数据输出的查询，以及11个请求绘图的查询。其中，18个查询涉及多模态数据，剩余的12个仅基于关系数据。

我们选择了这个数据集，直接将我们的系统与CAESURA进行比较（[urbanB24,](https://arxiv.org/html/2412.18428v1#bib.bib21)），这是一个用于自然语言中的多模态数据探索的最先进系统之一。

数据集 2：电子健康记录（EHR）。我们还使用了 EHRXQA ([bae2024ehrxqa,](https://arxiv.org/html/2412.18428v1#bib.bib1)) 数据集，这是一个多模态问答数据集，结合了结构化电子健康记录（EHR）和胸部X光图像。该数据集由18个表格和432张图像组成，特别需要进行跨模态推理。EHRXQA的问题根据其模态范围和患者相关性进行了分类。在基于模态的分类中，问题分为三种类型：与表格相关、与图像相关以及与表格-图像相关，具体取决于所需的数据模态。在基于患者的分类中，问题根据其与单一患者、一组患者或无关（即与特定患者无关）的相关性进行分类。我们选择了这个数据集，因为它曾用于评估NeuralSQL，这也是另一个多模态数据探索的先进系统。为了管理API调用的成本，我们随机提取了100个问题。选择过程受到了EHRXQA数据集中测试集内三个预定义类别的指导：图像单项-1、图像单项-2以及图像+表格单项。

以下是来自每个类别的示例，摘自原始论文 ([bae2024ehrxqa,](https://arxiv.org/html/2412.18428v1#bib.bib1))。这些类别中的所有问题都需要多模态数据探索来进行推理。

+   •

    图像单项-1：根据患者15439的最后一次检查，右下肺区的解剖学发现与气胸还是血管重分布相关？

+   •

    图像单项-2：列举患者19290在2103年的最后一次检查中与之前的检查相比，新检测到的所有疾病。

+   •

    图像+表格单项：对于患者15110，在2021年开始使用 hydralazine 后的2个月内，胸部X光检查是否发现任何解剖学异常？

#### 4.1.2\. 基准系统与设置

我们将 XMODE 与 CAESURA ([urbanB24,](https://arxiv.org/html/2412.18428v1#bib.bib21)) 和 NeuralSQL ([bae2024ehrxqa,](https://arxiv.org/html/2412.18428v1#bib.bib1)) 的基准实现进行了比较——这两个是多模态数据探索领域的先进系统。

CAESURA 支持通过多模态数据湖的自然语言查询，利用 BLIP-2 ([li2023blip,](https://arxiv.org/html/2412.18428v1#bib.bib14)) 进行视觉问答，利用 BART ([lewis2020bart,](https://arxiv.org/html/2412.18428v1#bib.bib12)) 进行文本问答。我们使用 GPT4o 在 Artwork 数据集上重现了 CAESURA 的结果。为了与我们的系统进行比较，我们将 GPT4o 作为大语言模型（LLM），并在 XMODE 中使用相同的视觉问答模型（即 BLIP-2）。

在NeuralSQL中，集成了一个外部视觉问答系统M3AE模型（[10.1007/978-3-031-16443-9_65,](https://arxiv.org/html/2412.18428v1#bib.bib3)），通过将用户问题一步转换为SQL，处理包含图像的结构化数据库中的多模态问题。为了确保我们使用了最优的超参数设置和提示结构，我们联系了EHRXQA的作者（[bae2024ehrxqa,](https://arxiv.org/html/2412.18428v1#bib.bib1)），他们提供了使用GPT-4o在100个随机选择的问题上进行NeuralSQL实验的结果。

对于XMODE，我们采用M3AE模型，并使用任务特定的微调权重，权重由([bae2024ehrxqa,](https://arxiv.org/html/2412.18428v1#bib.bib1)）提供，用于图像分析任务。定制的M3AE模型被封装为Web服务，并部署在与第[4.1.4](https://arxiv.org/html/2412.18428v1#S4.SS1.SSS4 "4.1.4\. Hardware Setup ‣ 4.1\. Experimental Setup ‣ 4\. Experiments ‣ Explainable Multi-Modal Data Exploration in Natural Language via LLM Agent")节中描述的相同计算节点上。

#### 4.1.3\. Evaluation Metrics

为了评估XMODE相对于最先进系统的表现，我们使用以下指标：

+   •

    Accuracy: 衡量生成的结果集与黄金标准结果集或与人类专家的准确度（即，完全匹配）。

+   •

    Steps: 各系统得出最终结果所需的步骤数。这些步骤包括推理、规划、重新规划等。

+   •

    Tokens: 用于提示工程的令牌数量。

+   •

    Latency: 系统得出最终结果的端到端执行时间。

+   •

    API costs: 调用LLM的成本，例如调用GPT4o的费用。

我们在不同的问题和系统类别下应用上述评估指标：

+   •

    Modality: 问题可以是单一模态，即仅查询关系数据或图像数据，或是多模态，即同时查询关系和图像数据。

+   •

    Output Type: 问题的输出类型可以是单个值，例如true或false，一个数据结构，例如表格或JSON格式，图表，或图表与数据结构的组合。

+   •

    Workflow: 生成的工作流计划可以是顺序的或并行的。

最后，我们评估一个系统是否生成了正确的（多模态）查询计划（即生成的计划），以及它是否支持重新规划。

#### 4.1.4\. Hardware Setup

我们使用一个CUDA加速的计算节点进行以下实验，该节点位于OpenStack虚拟主机上。该节点配备了16核CPU、16GB主内存和240GB的SSD存储。此外，它还配备了一块具有16GB专用显存的NVIDIA T4 GPU。

### 4.2\. Results on the Artwork Dataset

我们首先在艺术品数据集上评估结果，然后在EHR数据集上评估。

#### 4.2.1\. Performance Results

| System | Category | Accuracy | Steps | Tokens | Latency [s] | API Cost [USD] | Generated Plan | Re-planning |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| CAESURA | 模态 | 单一 (15) | 60.00% | 152 | 214,014 | 973.28 | 1.33 | 80% | 否 |
| 多模态 (15) | 6.67% | 164 | 268,918 | 4,847.95 | 1.65 |
| 输出类型 | 单一值 (8) | 37.50% | 88 | 135,077 | 1,047.24 | 0.82 |
| 数据结构 (10) | 50.00% | 116 | 183,454 | 2,683.03 | 1.14 |
| 图表 (8) | 25.00% | 79 | 112,732 | 1,856.66 | 0.69 |
| 少样本 ($n=4$) | 图表-图表 (2) | 0% | 16 | 21,508 | 108.87 | 0.14 |
| 规划中 | 图表-数据结构 (2) | 0% | 17 | 30,161 | 125.42 | 0.19 |
|  | 工作流 | 顺序 (24) | 41.67% | 261 | 399,045 | 5,330.12 | 2.45 |
|  | 并行 (6) | 0% | 55 | 83,887 | 491.11 | 0.52 |
|  | 总体 (30) | 33.33% | 316 | 482,932 | 5,821.23 | 2.98 |
| XMODE | 模态 | 单一 (15) | 100.00% | 96 | 159,212 | 525.09 | 0.61 |  |  |
| 多模态 (15) | 26.67% | 107 | 326,400 | 2,515.03 | 1.49 | 100% | 是 |
| 输出类型 | 单一值 (8) | 50.00% | 56 | 71,575 | 494.78 | 0.39 |
| 数据结构 (10) | 50.00% | 67 | 223,528 | 1,330.40 | 0.89 |
| 图表 (8) | 75.00% | 52 | 118,431 | 798.97 | 0.48 |
| 零样本 | 图表-图表 (2) | 100.00% | 14 | 50,108 | 308.92 | 0.22 |
|  | 图表-数据结构 (2) | 100.00% | 14 | 21,970 | 107.05 | 0.10 |
|  | 工作流 | 顺序 (24) | 62.50% | 163 | 338,766 | 2,131.11 | 1.51 |
|  | 并行 (6) | 66.67% | 40 | 146,846 | 909.01 | 0.59 |
|  | 总体 (30) | 63.33% | 203 | 485,612 | 3,040.12 | 2.10 |

表 1\. Caesura ([urban2023caesura,](https://arxiv.org/html/2412.18428v1#bib.bib20)) 和 XMODE 在艺术作品数据集上的性能指标。

表 [1](https://arxiv.org/html/2412.18428v1#S4.T1 "Table 1 ‣ 4.2.1\. Performance Results ‣ 4.2\. Results on the Artwork Dataset ‣ 4\. Experiments ‣ Explainable Multi-Modal Data Exploration in Natural Language via LLM Agent") 展示了 XMODE 和 CAESURA 在艺术作品数据集上多个方面的比较。每个方面的性能指标是通过我们团队四位研究人员进行的手动评估得出的。XMODE 和 CAESURA 在艺术作品数据集的多个方面表现出显著差异。首先是评估不同模态查询的准确度：XMODE 在单模态和多模态问题上的表现均优于 CAESURA。在单一情况中，XMODE 达到 100.00% 的输出准确度，而 CAESURA 的准确度为 60.00%。在更具挑战性的多模态场景中，XMODE 展现出明显的优势，准确度为 26.67%，而 CAESURA 仅为 6.67%。

基于输出类型的准确度表明，对于单一值输出，CAESURA 的准确度为 37.5%，而 XMODE 为 50%。XMODE 在复杂任务中的优势更加明显，其中输出为图表、图表-图表或图表-数据结构时，XMODE 分别达到了 75%、100% 和 100% 的准确度，而 CAESURA 分别为 25%、0% 和 0%。

此外，CAESURA 需要对每个自然语言问题进行顺序推理和行动，这可能导致高延迟、高成本，并且有时会产生不准确的行为。XMODE 在工作流规划过程中识别任务之间的依赖关系，从而支持并发和并行任务执行。在六个需要并行任务规划和执行的新问题上，CAESURA 完全失败，而 XMODE 成功生成了正确的计划，并实现了 66.67% 的准确性。

总体而言，XMODE 作为更强大的系统脱颖而出，整体输出准确率为 63.33%，而 CAESURA 为 33.33%。XMODE 的优势在于能够提供更好的解释、支持重规划和并发执行，而这些功能在 CAESURA 中是缺失的。

从效率角度来看，XMODE 在多个领域显示出相较于 CAESURA 的显著优势。它所需的步骤更少（203 步对比 316 步），并且延迟显著更低（3,040.12 毫秒对比 5,821.23 毫秒），响应时间更快。最后，XMODE 的 API 成本（2.10）也低于 CAESURA 的 2.98，表明在 API 使用方面，XMODE 更具成本效益。

总结来说，使用艺术作品基准测试的实验结果表明，XMODE 在准确性、效率和功能支持方面始终优于 CAESURA，展示了它在艺术作品数据集上的多任务鲁棒性。它处理复杂输出、提供解释以及通过重规划进行适应的能力，使其在这个基准测试中成为更好的选择。

#### 4.2.2\. 通过示例解释 XMODE 的优化

为了更好地展示 XMODE 的优势，我们提供了若干示例（见图 [3](https://arxiv.org/html/2412.18428v1#S3.F3 "图 3 ‣ 3.1\. XMODE 系统架构 ‣ 3\. 系统设计 ‣ 通过 LLM Agent 进行可解释的多模态数据探索") 和 [5](https://arxiv.org/html/2412.18428v1#S4.F5 "图 5 ‣ 4.2.2\. 通过示例解释 XMODE 的优化 ‣ 4.2\. 艺术作品数据集上的结果 ‣ 4\. 实验 ‣ 通过 LLM Agent 进行可解释的多模态数据探索"))，涵盖三个关键方面：解释、智能重规划和并行规划。以下示例详细说明了这三个方面。

{mdframed}

[hidealllines=true,backgroundcolor=cyan!20,innerleftmargin=3pt,innerrightmargin=3pt,leftmargin=-1pt,rightmargin=-1pt]

示例 1：绘制每个世纪描绘战争的绘画数量（见图 [3](https://arxiv.org/html/2412.18428v1#S3.F3 "图 3 ‣ 3.1\. XMODE 系统架构 ‣ 3\. 系统设计 ‣ 通过 LLM Agent 进行可解释的多模态数据探索"))。

![参见标题](img/20b1a87b464f59f228001f8c716266b9.png)

图 5\. XMODE 优化：智能重规划。

通过一系列精心计划和系统执行的步骤，模型不仅展示了它是如何处理查询的，还展示了它如何在每个阶段提供透明度和推理，确保用户理解整个过程和结果。图示展示了一个工作流，涉及（1）计划与专家模型分配，（2）执行与自我调试，以及（3）决策过程。以下是每个步骤的详细分解：

1) 计划与专家模型分配：过程从将查询分解为一系列子任务开始：任务 1：从数据库中检索画作元数据，包括它们的创作年份和相关的世纪。任务 2：分析图像，确定它们是否描绘战争。任务 3：准备数据，通过统计每个世纪的战争相关画作数量来整理数据。任务 4：在柱状图中可视化这些数量。

每个任务都分配给专门的工具或模型，例如使用 text2SQL 将自然语言问题转换为 SQL 语句并进行数据库检索，使用图像分析工具进行视觉解读，使用编码工具来组织数据，以及使用可视化库如 matplotlib。这个阶段建立了一个清晰的计划，展示了如何通过逻辑步骤解决整体查询。

2) 执行与自我调试：模型开始执行任务，在每个阶段提供解释和输出，以确保清晰性。任务 1 - 检索数据：模型构建 SQL 查询，从数据库中检索所需的信息。它解释了其推理：为了确定每幅画作的世纪，它将创作年份转换为世纪值。结果是一个画作列表，每幅画作都关联了其图像路径和所属世纪。任务 2 - 图像分析：使用检索到的数据，模型分析每幅画作，确定其是否描绘战争。它应用图像分析工具来解读画作的视觉内容。这里的推理很明确——必须识别战争相关的图像内容，如战斗或士兵，以回答查询。输出结果是一个数据集，指示每幅画作是否描绘战争。任务 3 - 数据准备：模型筛选并聚合数据，统计每个世纪描绘战争的画作数量。它解释说，通过按世纪分组画作，可以轻松比较不同时期的趋势。结果是一个简明的总结：16世纪有1幅画作，18世纪有2幅画作被确定为描绘战争。任务 4 - 数据可视化：最后，模型准备了一个柱状图来可视化结果。它解释了选择这种可视化方式的推理：柱状图能有效地比较各类别的数量，在本例中是各个世纪的数量。提供了一段 Python 脚本，展示了图表的生成过程，输出结果以图像形式保存，以供用户参考。

3) 决策：当任务完成后，模型会反思自己的工作，并根据其思路提供最终输出，摘要：“描绘战争的画作数量已被绘制于 16 世纪和 18 世纪的图表中。”， “详细信息”： “分析确定了 1 幅来自 16 世纪的画作和 2 幅来自 18 世纪的画作描绘了战争。该图表可视化了这些发现。[..]”。在整个工作流程中，模型展现了对透明度的承诺。

在每个阶段，XMODE 都提供推理来证明其行动的合理性，从选择 SQL 检索到选择条形图进行可视化。中间输出，例如战争画作的数据集和 Python 绘图代码，将会被显示，确保用户可以追溯所采取的步骤。决策阶段通过总结发现、阐明方法并分享最终的可视化结果来结束整个过程。这表明 XMODE 不仅有效地回答了问题，还确保其步骤是可以理解、合逻辑且文档化的，从而建立了对其分析的信任。

![参见标题说明](img/4c1baf2d72b379c504c97b853e809367.png)

图 6\. XMODE 的优化：并行规划。

{mdframed}

[hidealllines=true,backgroundcolor=cyan!20,innerleftmargin=2pt,innerrightmargin=3pt,leftmargin=-1pt,rightmargin=-1pt] 示例 2 - 智能重规划：数据库中最古老的文艺复兴画作描绘了什么？（参见图 [5](https://arxiv.org/html/2412.18428v1#S4.F5 "图 5 ‣ 4.2.2\. 通过示例解释 XMODE 的优化 ‣ 4.2\. 在艺术作品数据集上的结果 ‣ 4\. 实验 ‣ 通过 LLM 代理进行可解释的多模态数据探索")）。与前一个例子不同，这里 XMODE 涉及智能重规划——这是 XMODE 的一项主要优化技术。其主要思想是，在某些任务失败或未产生任何结果的情况下，动态地调整规划。以下是每个步骤的详细说明：

1) 规划与专家模型分配：XMODE 输出包含 2 个任务的初步工作流程计划。第一个任务涉及使用“text2SQL”专家模型从数据库中检索图像路径和最古老文艺复兴时期画作的年份。第二个任务涉及“image_analysis”专家模型，旨在确定图像中所描绘的内容。

2) 执行与自我调试：XMODE 将关于计划工作流程的信息以及任务依赖关系付诸实践。在任务 1 中，它提供了一条推理声明，以生成 SQL 查询：SELECT img_path, strftime(’%Y’, inception) AS year FROM paintings WHERE movement = ’Renaissance’ ORDER BY inception ASC LIMIT 1。然后，它在 Artwork 数据库中执行该查询，并检索最古老文艺复兴时期画作的图像路径和年份，结果为 [’img_path’: ’images/img_0.jpg’, ’year’: ’1438’]。这使得模型能够在后续任务中访问实际的画作数据。

在任务2中，XMODE利用“image_analysis”专家模型（即基于BLIP的视觉问答）来检查img_0.jpg的内容，以回答问题：“图像中描绘的是什么？”此任务的输出结果作为最终答案传递给决策组件。此时，模型在该组件中的“思考”过程变得显而易见。它推理出，尽管它知道img_0.jpg是一幅画作，但关于画作中描绘内容的细节尚未提供。因此，模型决定不向用户提供最终答案，并进行重新规划。

重新规划能力是XMODE方法中的一个关键方面。模型不会盲目接受最终答案，如果该答案不能产生令人满意或正确的结果，模型会识别到需要重新规划，并再次调用“image_analysis”模块。由于模型已经知道数据库中哪张图像包含最古老的文艺复兴画作，它巧妙地将“image_analysis”任务规划为任务3，通过将问题重新表述为“画作中具体描绘的是什么？”来执行。XMODE然后执行该任务，并收到更具体的答案“雨伞”。

接下来，决策组件确认了画作的细节。此时，它验证已收集的信息是否与自然语言问题一致，并且作为对最古老文艺复兴画作的全面理解是有意义的。关键在于模型能够有效地重新规划，并战略性地利用现有信息避免重复任务。{mdframed}[hidealllines=true,backgroundcolor=cyan!20,innerleftmargin=3pt,innerrightmargin=3pt,leftmargin=-1pt,rightmargin=-1pt] 示例3 - 并行规划：在文艺复兴时期，找出描绘战争的画作总数以及描绘剑的画作数量（见图[6](https://arxiv.org/html/2412.18428v1#S4.F6 "图6 ‣ 4.2.2\. XMODE优化通过示例解释 ‣ 4.2\. 艺术作品数据集的实验结果 ‣ 4\. 通过LLM代理的可解释多模态数据探索")）。该图展示了XMODE如何处理有关文艺复兴画作的复杂查询，重点是识别有多少画作描绘战争，有多少描绘剑。管道结构旨在将并行任务执行与逐步解释相结合，确保整个过程的清晰和高效。

该过程从规划与专家模型分配阶段开始，在这一阶段，模型将用户的查询分解为不同的子任务。这些子任务被分配给专门的模块：任务1 "text2SQL"：此任务使用SQL查询从数据库中检索文艺复兴时期画作的图像路径和相关元数据；任务2 "image_analysis"：此任务检查每幅画是否描绘了战争；任务3 "image_analysis"：同时，另一个模块分析每幅画是否描绘了剑；任务4 "data_preparation"：此任务将任务2和任务3的结果汇总，用于统计和总结画作。

执行阶段从任务1开始，模型生成并运行SQL查询。提供的推理解释了如何理解数据库模式以及查询如何确保仅检索到文艺复兴时期的画作。任务1的输出包括图像路径和元数据，这些数据随后被传送到下一个阶段。

在这一阶段，模型展示了其并行规划的能力。任务2和任务3是并行执行的：对于任务2，系统使用图像分析来判断每幅画是否描绘了战争；对于任务3，类似的图像分析过程用于识别描绘剑的画作。并行运行这些任务显著加快了工作流程，因为它们相互独立。一旦图像分析任务完成，模型将过渡到任务4，在这一阶段它会汇总结果。推理过程详细说明了系统如何编译两个列表——一个是描绘战争的画作列表，另一个是描绘剑的画作列表。之后，XMODE会计算每个列表中的条目数量。最终结果将为决策模块准备。

在决策阶段，模型回顾其发现。它确认已经处理了足够的数据来回答查询，并提供总结：“有1幅画描绘了战争，38幅画描绘了剑。”

XMODE提供了详细信息，解释了分析是如何进行的，并突出了两类画作之间的差异。系统还进一步解释了其方法论，强调了它是如何系统地工作以回答查询的。这展示了XMODE通过并行执行有效管理任务的能力，并通过每一步的推理解释确保了透明度。通过结合这些能力，系统为用户的查询提供了清晰、准确且有力的支持响应。

需要注意的是，我们没有将XMODE与NeuralSQL在ArtWork的问题上进行比较，因为这样的比较是不公平的，原因在于NeuralSQL无法支持绘图功能。

### 4.3\. 在EHRXQA数据集上的结果

在本节中，我们评估了 NeuralSQL 和 XMODE 在 EHRXQA 数据集上的表现。此比较排除了步骤、标记和延迟等指标，因为在这些方面评估 XMODE 的表现与 NeuralSQL 进行比较没有意义。NeuralSQL 在单个步骤中生成最终答案，不提供计划或中间步骤，而我们的方法专注于分解自然语言问题、规划工作流程，并进行透明的响应。

我们还将 CAESURA 从 EHRXQA 实验中排除。虽然 CAESURA 被设计为一个通用的多模态系统，但它通过多个步骤处理关系型数据库，依次检查每个表和关系。这一限制在处理 EHRXQA 数据集（有 18 张表）复杂数据模式时，在发现阶段引入了显著的开销。因此，在 EHRXQA 问题上重现 CAESURA 时，未能在规划阶段的早期进行推理，最终在超过允许的最大尝试次数后终止。

| 系统 | 范围 | 输出类型 | 总体（100） | 生成 | 重新规划 |
| --- | --- | --- | --- | --- | --- |
| Image Single-1 | Image Single-2 | Image+Table Single | 二元 | 分类 | 计划 |
| (30) | (30) | (40) | (50) | (50) |
| NeuralSQL | zero-shot | 0.00% | 0.00% | 0.00% | 0.00% | 0.00% | 0.00% | N/A | No |
| few-shot ($n=10$) | 26.67% | 20.00% | 47.50% | 48.00% | 18.00% | 33.00% |
| XMODE | zero-shot | 23.33% | 43.33% | 77.50% | 74.00% | 28.00% | 51.00% | 98% | Yes |

表 2\. NeuralSQL（零样本和少样本）和 XMODE（零样本）在 EHRXQA 数据集上的性能指标。

![请参见说明](img/7d1d002d97d6a9d0e249420b38caa012.png)

(a) CAESURA

![请参见说明](img/6916832f02e8365308d5fa8794a20789.png)

(b) XMODE

图 7\. CAESURA ([urban2023caesura,](https://arxiv.org/html/2412.18428v1#bib.bib20) ) (a) 和 XMODE (b) 在 ArtWork 数据集上不同步骤的错误分析。

表 [2](https://arxiv.org/html/2412.18428v1#S4.T2 "Table 2 ‣ 4.3\. Results on the EHRXQA Dataset ‣ 4\. Experiments ‣ Explainable Multi-Modal Data Exploration in Natural Language via LLM Agent") 展示了 XMODE 相对于 NeuralSQL 在 EHRXQA 数据集上的实验结果。我们的评估涵盖了三个范围类别：单表查询带一张图片（Image Single-1）、单表查询带两张图片（Image Single-2）和多表查询带单张图片（Image+Table Single）。XMODE 在所有评估指标上都展现了强大的性能，整体准确率为 51.00%。特别地，XMODE 在处理多表场景时表现突出，达到了 77.50% 的准确率，显著优于 NeuralSQL 在 10-shot 设置下的 47.50%。对于单表查询，XMODE 在两张图片查询上表现强劲，准确率为 43.33%，尽管与 NeuralSQL 在单图查询中的 10-shot 表现（26.67%）相比，得分略低（23.33%）。

在检查输出类型时，XMODE在二元问题上的表现特别强，准确率为74.00%，而NeuralSQL为48.00%。对于类别问题，两个系统的表现都较低，在10-shot设置下，XMODE达到了28.00%，NeuralSQL为18.00%。

XMODE的一个关键区分特点是它超越原始准确性的全面功能。与NeuralSQL不同，XMODE生成具有98%覆盖率的可执行计划，提供最终输出的可追溯性解释，并支持动态重新规划能力。相比之下，即使在10-shot配置下，NeuralSQL也缺乏这些附加功能，并且在零-shot设置下在所有指标上没有表现。这些结果突显了XMODE作为EHRXQA任务更完整解决方案的有效性，特别是在涉及多个表和二元决策的复杂场景中，同时也为实际部署提供了重要的辅助功能。

### 4.4\. 错误分析

本节中，我们对评估过程中遇到的错误进行全面分析。这些错误被系统地分类为以下几类：

+   •

    规划错误：这些错误源于不正确或不完整的任务规划，例如任务分解、完全错误的自然语言问题生成等。

+   •

    文本到SQL错误：生成的SQL无法准确检索到预期的数据。

+   •

    图像分析不准确：即使底层任务计划正确，图像分析模型的输出不准确也会导致错误。

+   •

    绘图生成错误：图表未完全生成、部分生成或生成错误，未能达到预期的结果。

为了系统地分析关键问题，我们根据任务执行过程中各类别之间的相互依赖关系优先排序。各类别的优先级顺序定义如下：任务规划 → 文本到SQL生成 → 图像分析 → 绘图生成。如果在任何阶段发生错误，只考虑第一个受影响的类别，这可能涉及多个类别的问题。例如，如果在规划阶段检测到错误，但随后的任务成功，且在后期的绘图生成阶段再次发生错误，则只计算规划阶段的错误。在这种情况下，样本被归类为规划错误类别。

这种错误分析方法基于任务的逻辑依赖结构。由于每个任务是下一个任务的前提，早期任务的失败会使后续任务的成功对于整体推理过程无关紧要。因此，错误会归因于最早的失败点，以更好地反映任务依赖的层次性，从而促进有针对性的优化。

#### 4.4.1\. 艺术作品数据集的错误分析。

如图[7](https://arxiv.org/html/2412.18428v1#S4.F7 "Figure 7 ‣ 4.3\. Results on the EHRXQA Dataset ‣ 4\. Experiments ‣ Explainable Multi-Modal Data Exploration in Natural Language via LLM Agent")（a）所示，在CAESURA的30个推理任务中，共识别出20个错误。其中，14个错误发生在CAESURA的顺序工作流中。这些错误包括三个单模态问题和11个多模态问题。在三个单模态问题中，其中一个任务由于数据池中数据不足未能解决。在这个失败之后，CAESURA尝试重新规划两次，但最终生成了一个不正确的计划，导致错误的响应。其余两个单模态任务的错误被归类为图表生成错误，原因是图表输出的时间轴单位不一致。

在多模态问题中，共有11个错误，其中五个与单值输出相关，四个与图表相关，三个与数据结构相关。所有这些错误都归因于图像分析模型生成的不正确输出。经过进一步研究，我们发现分类错误类别时存在两个模糊的任务：（1）绘制每年描绘战争的画作数量，和（2）数据库中最古老的宗教艺术作品上描绘了什么？这两个任务失败的原因是图像分析任务中的子问题解析不正确，特别是“战争”这一过于简化的术语。虽然该术语在语义上与正确的自然语言问题“图像是否描绘了战争？”相关，但它并未完全捕捉任务的意图。因此，它不能被归类为完全错误的问题。值得注意的是，XMODE模型对这些任务生成了正确的结果，突显了CAESURA方法在处理细微语义差异时的局限性。

在需要并行工作流的问题中——包括两种数据结构、两种图—图，以及两种图—数据结构输出——在早期规划阶段观察到错误。我们的分析揭示，CAESURA 在生成准确的计划方面遇到了重大挑战，尤其是在处理令人尴尬的并行任务时。对于这两项任务，系统根本未能生成任何计划。对于其余四项任务，CAESURA 能为一些子任务提供部分结果，但其他子任务未得到解答，反映出其在并行规划管理方面的更广泛问题。我们的 XMODE 系统成功地为所有任务生成了适当的计划。此外，所有的文本到 SQL 步骤、数据准备管道以及所需的图表输出都已验证为正确。如图 [7](https://arxiv.org/html/2412.18428v1#S4.F7 "Figure 7 ‣ 4.3\. Results on the EHRXQA Dataset ‣ 4\. Experiments ‣ Explainable Multi-Modal Data Exploration in Natural Language via LLM Agent")(b) 所示，唯一的错误来源是图像分析模型输出的不准确，导致了 11 个错误。文本到 SQL 任务、图表生成或任务规划方面没有发现其他错误。此分析突出了图像分析模型作为系统性能瓶颈，强调了进一步提高其预测准确性的必要性。

#### 4.4.2\. EHRXQA 数据集上的错误分析

由于 NeuralSQL 是一种缺乏任务规划和可解释性的一步法，因此我们无法像在 XMODE 或 CAESURA 系统中那样系统地定位错误来源。因此，我们将错误分析的重点仅放在使用 EHRXQA 数据集的 XMODE 系统上。

图 [8](https://arxiv.org/html/2412.18428v1#S4.F8 "图 8 ‣ 4.4.2\. EHRXQA 数据集的错误分析 ‣ 4.4\. 错误分析 ‣ 4\. 实验 ‣ 通过 LLM Agent 在自然语言中可解释的多模态数据探索") 展示了49个错误在不同步骤中的分布，并按各自的范围进行了分类：图像单一-1（23个错误）、图像单一-2（17个错误）和图像+表格单一（9个错误）。其中，36个错误与类别范围相关，其中20个归因于图像单一-1，16个归因于图像单一-2。相反，与二元输出类型相关的错误主要出现在图像+表格单一范围内。具体来说，图像单一-1贡献了三个二元错误，图像单一-2贡献了一个，图像+表格单一包括九个，合计49个错误中的13个是二元错误。考虑到错误在不同输出类型和范围之间的分布不均，我们认为图像分析不准确——主要由M3AE模型（[10.1007/978-3-031-16443-9_65,](https://arxiv.org/html/2412.18428v1#bib.bib3) ）驱动——是错误的主要来源。我们的分析显示，和二元输出类型相关的错误（13个）仅为类别输出类型错误（36个）的三分之一，表明错误模式与不同范围内的任务难度关系较小，更多地受输出类型的影响，因为二元问题相比于类别问题表现出统计学上更高的成功率。值得注意的是，图像+表格单一范围仅使用二元输出类型。

为了更深入地了解，逐步的错误分析显示，在图像单一-1范围内的23个错误中，有22个是由于图像分析的不准确，只有一个与文本到SQL过程中的误操作有关。该案例的具体问题文本是：“根据11801290号患者第一次就诊时的首个检查，列出图像中所有可见的解剖学发现。”生成的SQL查询未能包括指定首个检查的条件，导致输出错误。在图像单一-2类别中，总共17个错误中有16个是由于图像分析不准确，1个归因于文本到SQL步骤。问题的具体查询是：“16345504号患者今年的倒数第二次检查是否显示右肺存在仍然存在的液体超负荷/心力衰竭，相较于今年的第一次检查？”文本到SQL任务未能正确检索今年的第一次和最后一次检查，反而错误地返回了今年的多个检查。在图像+表格单一范围内，所有九个错误都涉及二进制输出类型。在这些错误中，六个是由于图像分析不准确，1个是由于计划不完整，2个是由于文本到SQL步骤错误。由计划不完整导致的错误出现在问题：“19055351号患者是否在胸部X光显示任何解剖学发现后，与右心和左心联合心导管检查程序是否在2104年内同一月份进行？”在这种情况下，计划中遗漏了必要的图像分析步骤，导致最终输出错误。在推理阶段，发现了一些空输出的情况，这些情况巧合地与真实结果对齐。但XMODE的可解释性指出这是一个误分类，因为输出的缺失并非由于正确的推理。

图像+表格单一类别中的两个错误归因于文本到SQL的错误行为。导致这些错误的具体问题是：“12724975号患者是否在1年前被诊断为缺氧症，并且在同一期间胸部X光是否显示腹部有任何管子/导管？”以及“10762986号患者是否在胸部X光显示主动脉弓有任何异常后，在同一月内被诊断为吸烟史，且此诊断是在1年前？”在这两种情况下，SQL查询未能正确应用“直到1年前”这一条件（基于当前时间），而是将1年前当作一个固定的时间点。

这些发现突显了准确图像分析在多模态数据探索系统中的关键作用。特别地，它们强调了与分类输出相关的巨大挑战。此外，研究结果还强调了强有力的规划和高效SQL查询生成的必要性，以实现最佳系统性能。解决这些挑战需要在视觉推理、时序逻辑理解和SQL生成方面的进展，这些都是减少错误并提升系统准确性所必需的。

![请参见标题说明](img/ee9828cd85be6d93b2161e94a2dc216f.png)

图8\. XMODE在EHRXQA（[bae2024ehrxqa,](https://arxiv.org/html/2412.18428v1#bib.bib1)）数据集上不同步骤的错误分析。

## 5\. 结论

我们证明了使用大型语言模型（如GPT-4）进行的多代理协作提供了一种有前景的方法，用于自然语言中可解释的多模态数据探索。我们在两个不同数据集上，分别使用表格数据和图像数据，对比了XMODE与两个最先进系统的实验评估，结果表明XMODE不仅在多模态数据探索任务中具有更高的准确性，而且由于智能重新规划和并行执行，还能更快地完成任务。此外，XMODE还提供了详细的解释和推理，使其具有透明性，并帮助最终用户更好地理解和验证结果。我们的实验主要发现，文本到SQL任务表现出高准确性，而图像分析任务的准确性则有限。因此，未来的多模态数据探索工作应集中于提高图像解读和理解模型的准确性。未来研究的潜在方向包括表格数据与图像数据之间的更好对齐方法，或通过自然语言问题重写进行的迭代提示工程，以更好地探测图像搜索空间。另一个有前景的方法是聚焦于“人机协作”方法，在这种方法中，系统与人类共同完成任务。

## 6\. 致谢

我们要感谢华盛顿大学的Magda Balazinska教授对XMODE系统初步构想的富有成效的讨论。我们还要感谢CAESURA（[urban2023caesura,](https://arxiv.org/html/2412.18428v1#bib.bib20)）和EHRXQA（[bae2024ehrxqa,](https://arxiv.org/html/2412.18428v1#bib.bib1)）团队提供的专业支持，帮助运行各自的系统。

## 参考文献

+   [1] Seongsu Bae, Daeun Kyung, Jaehee Ryu, Eunbyeol Cho, Gyubok Lee, Sunjun Kweon, Jungwoo Oh, Lei Ji, Eric Chang, Tackeun Kim 等人。EHRXQA：一个用于电子健康记录与胸部X射线图像的多模态问答数据集。神经信息处理系统进展，36，2024。

+   [2] Saptarashmi Bandyopadhyay 和 Tianyang Zhao。基于SQL的自然语言响应生成，具有泛化能力和回译机制。发表于2020年互动与可执行语义解析研讨会。

+   [3] Zhihong Chen, Yuhao Du, Jinpeng Hu, Yang Liu, Guanbin Li, Xiang Wan 和 Tsung-Hui Chang。用于医学视觉与语言预训练的多模态掩码自编码器。在医学图像计算与计算机辅助介入国际会议（MICCAI 2022），新加坡，2022年9月18-22日，第V部分，页面679–689，柏林，海德堡，2022年。Springer-Verlag出版。

+   [4] Gaurav Tarlok Kakkar 等。EVA：一个端到端的探索性视频分析系统。在数据管理与端到端机器学习工作坊（DEEM），2023年。

+   [5] Avrilia Floratou, Fotis Psallidas, Fuheng Zhao, Shaleen Deep, Gunther Hagleither, Wangda Tan, Joyce Cahoon, Rana Alotaibi, Jordan Henkel, Abhik Singla, Alex van Grootel, Brandon Chow, Kai Deng, Katherine Lin, Marcos Campos, Venkatesh Emani, Vivek Pandit, Victor Shnayder, Wenjing Wang 和 Carlo Curino。NL2SQL已解决问题……并非如此！在CIDR，2024年。

+   [6] Saehan Jo 和 Immanuel Trummer。Thalamusdb：多模态数据上的近似查询处理。《ACM数据管理会议论文集》，2(3)，2024年。

+   [7] Daniel Kang, Peter Bailis 和 Matei Zaharia。Blazeit：优化基于神经网络的视频分析中的声明性聚合和限制查询。《VLDB会议论文集》，13(4):533–546，2019年。

+   [8] Daniel Kang, Francisco Romero, Peter D. Bailis, Christos Kozyrakis 和 Matei Zaharia。VIVA：一个端到端的互动视频分析系统。在CIDR，2022年。

+   [9] Sayash Kapoor, Benedikt Stroebl, Zachary S Siegel, Nitya Nadgir 和 Arvind Narayanan。重要的AI代理。arXiv预印本 arXiv:2407.01502，2024年。

+   [10] Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler, Fernanda Viegas 等。超越特征归因的可解释性：使用概念激活向量（TCAV）进行定量测试。在ICML，2018年。

+   [11] Sehoon Kim, Suhong Moon, Ryan Tabrizi, Nicholas Lee, Michael W Mahoney, Kurt Keutzer 和 Amir Gholami。一个用于并行函数调用的LLM编译器。arXiv预印本 arXiv:2312.04511，2023年。

+   [12] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov 和 Luke Zettlemoyer。Bart：用于自然语言生成、翻译和理解的去噪序列到序列预训练。在第58届计算语言学会年会（ACL）论文集，第7871页。计算语言学会，2020年。

+   [13] Jinyang Li, Binyuan Hui, Ge Qu, Jiaxi Yang, Binhua Li, Bowen Li, Bailin Wang, Bowen Qin, Ruiying Geng, Nan Huo 等。大型语言模型（LLM）是否已经能够作为数据库接口？一个针对大规模数据库的文本到 SQL 的大基准测试。NeurIPS, 2024。

+   [14] Junnan Li, Dongxu Li, Silvio Savarese 和 Steven Hoi。Blip-2：使用冻结的图像编码器和大型语言模型引导语言-图像预训练。在国际机器学习大会，页面19730–19742。PMLR，2023年。

+   [15] Chunwei Liu, Matthew Russo, Michael Cafarella, Lei Cao, Peter Baille Chen, Zui Chen, Michael Franklin, Tim Kraska, Samuel Madden, 和 Gerardo Vitagliano。用于优化AI工作负载的声明式系统。arXiv电子预印本，页面arXiv–2405，2024年。

+   [16] Scott M Lundberg 和 Su-In Lee。统一的模型预测解释方法。NeurIPS，2017年。

+   [17] Farhad Nooralahzadeh, Yi Zhang, Ellery Smith, Sabine Maennel, Cyril Matthey-Doret, Raphaël de Fondville, 和 Kurt Stockinger。StatBot.Swiss：自然语言中的双语开放数据探索。在ACL发现，2024年。

+   [18] Mohammadreza Pourreza 和 Davood Rafiei。Din-sql：带自我修正的文本到sql的分解式上下文学习。NeurIPS，2024年。

+   [19] Sithursan Sivasubramaniam, Cedric Osei-Akoto, Yi Zhang, Kurt Stockinger, 和 Jonathan Fuerst。Sm3-text-to-query：合成多模态医学文本到查询基准。发表于《第三十八届神经信息处理系统大会 数据集与基准 Track》。

+   [20] Matthias Urban 和 Carsten Binnig。Caesura：作为多模态查询规划器的语言模型。arXiv预印本arXiv:2308.03424，2023年。

+   [21] Matthias Urban 和 Carsten Binnig。CAESURA：作为多模态查询规划器的语言模型。在CIDR，2024年。

+   [22] Pius Von Däniken, Jan Milan Deriu, Eneko Agirre, Ursin Brunner, Mark Cieliebak, 和 Kurt Stockinger。通过重新排序语义假设来改进nl-to-query系统。在ICNLSP，2022年。

+   [23] Zeqing Wang, Wentao Wan, Runmeng Chen, Qiqing Lao, Minjie Lang, 和 Keze Wang。迈向自上而下推理：一种可解释的多代理视觉问答方法。arXiv预印本arXiv:2311.17331，2023年。

+   [24] Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingning Yao, Shanelle Roman 等。Spider：一个大型人工标注数据集，用于复杂跨领域语义解析和文本到sql任务。发表于EMNLP，2018年。

+   [25] Enhao Zhang, Maureen Daum, Dong He, Brandon Haynes, Ranjay Krishna, 和 Magdalena Balazinska。Equi-vocal：从有限的用户交互中合成复合视频事件的查询。发表于《VLDB基金会会议》，16(11)：2714-2727，2023年。

+   [26] Jingyi Zhang, Jiaxing Huang, Sheng Jin, 和 Shijian Lu。用于视觉任务的视觉-语言模型：一项调查。IEEE《模式分析与机器智能学报》，2024年。

+   [27] Yi Zhang, Jan Deriu, George Katsogiannis-Meimarakis, Catherine Kosten, Georgia Koutrika, 和 Kurt Stockinger。Sciencebenchmark：用于评估自然语言到sql系统的复杂现实世界基准。发表于《VLDB基金会会议》，17(4)：685-698，2024年。
