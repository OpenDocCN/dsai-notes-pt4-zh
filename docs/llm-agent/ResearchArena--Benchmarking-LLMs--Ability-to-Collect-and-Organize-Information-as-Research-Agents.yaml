- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:44:40'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:44:40
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'ResearchArena: Benchmarking LLMs’ Ability to Collect and Organize Information
    as Research Agents'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ResearchArena：基准测试LLM作为研究代理的收集和组织信息能力
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.10291](https://ar5iv.labs.arxiv.org/html/2406.10291)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2406.10291](https://ar5iv.labs.arxiv.org/html/2406.10291)
- en: Hao Kang
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Hao Kang
- en: haok@andrew.cmu.edu School of Computer Science
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: haok@andrew.cmu.edu 计算机科学学院
- en: Carnegie Mellon University
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 卡内基梅隆大学
- en: Pittsburgh, PA, 15213 &Chenyan Xiong
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 皮兹堡，PA，15213 &Chenyan Xiong
- en: cx@cs.cmu.edu Language Technologies Institute
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: cx@cs.cmu.edu 语言技术研究所
- en: Carnegie Mellon University
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 卡内基梅隆大学
- en: Pittsburgh, PA, 15213
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 皮兹堡，PA，15213
- en: Abstract
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Large language models (LLMs) have exhibited remarkable performance across various
    tasks in natural language processing. Nevertheless, challenges still arise when
    these tasks demand domain-specific expertise and advanced analytical skills, such
    as conducting research surveys on a designated topic. In this research, we develop
    ResearchArena, a benchmark that measures LLM agents’ ability to conduct academic
    surveys, an initial step of academic research process. Specifically, we deconstructs
    the surveying process into three stages 1) information discovery: locating relevant
    papers, 2) information selection: assessing papers’ importance to the topic, and
    3) information organization: organizing papers into meaningful structures. In
    particular, we establish an offline environment comprising 12.0M full-text academic
    papers and 7.9K survey papers, which evaluates agents’ ability to locate supporting
    materials for composing the survey on a topic, rank the located papers based on
    their impact, and organize these into a hierarchical knowledge mind-map. With
    this benchmark, we conduct preliminary evaluations of existing techniques and
    find that all LLM-based methods under-performing when compared to basic keyword-based
    retrieval techniques, highlighting substantial opportunities for future research.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）在自然语言处理的各类任务中表现出了显著的性能。然而，当这些任务需要领域特定的专业知识和高级分析技能时，挑战依然存在，比如在指定主题上进行研究调查。在这项研究中，我们开发了ResearchArena，一个衡量LLM代理进行学术调查能力的基准，这是一项学术研究过程的初步步骤。具体而言，我们将调查过程分解为三个阶段：1）信息发现：定位相关论文，2）信息选择：评估论文对主题的重要性，3）信息组织：将论文组织成有意义的结构。特别地，我们建立了一个离线环境，包括12.0M篇完整的学术论文和7.9K篇调查论文，评估代理在为某一主题撰写调查时定位支持材料的能力，根据其影响力对定位的论文进行排名，并将这些论文组织成分层的知识思维导图。通过这个基准，我们对现有技术进行了初步评估，发现所有基于LLM的方法在与基本的基于关键词的检索技术相比时表现不佳，突显了未来研究的巨大机会。
- en: 1 Introduction
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Large language models (LLMs) have demonstrated exceptional performance across
    tasks related to natural language understanding, generation, and various other
    domains [[1](#bib.bib1), [2](#bib.bib2), [3](#bib.bib3), [4](#bib.bib4)]. The
    capabilities of LLMs can be significantly augmented through integration with external
    tools such as code interpreters, gaming simulators, and search engines. This integration
    facilitates the development of sophisticated autonomous agents capable of receiving
    feedback and executing tasks in a manner akin to human behavior [[5](#bib.bib5),
    [6](#bib.bib6), [7](#bib.bib7), [8](#bib.bib8)]. Nevertheless, there remains uncertainty
    regarding the extent to which LLMs can perform tasks necessitating domain-specific
    expertise and advanced analytical skills, particularly in the context of conducting
    research on designated topics.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）在自然语言理解、生成以及各个领域的任务中展示了卓越的表现[[1](#bib.bib1)、[2](#bib.bib2)、[3](#bib.bib3)、[4](#bib.bib4)]。通过与外部工具如代码解释器、游戏模拟器和搜索引擎的集成，LLMs的能力可以显著增强。这种集成促进了复杂自主代理的发展，使其能够接收反馈并以类似人类行为的方式执行任务[[5](#bib.bib5)、[6](#bib.bib6)、[7](#bib.bib7)、[8](#bib.bib8)]。然而，关于LLMs在执行需要领域特定专业知识和高级分析技能的任务时的表现，尤其是在指定主题上的研究，仍然存在不确定性。
- en: The potential of LLMs to conduct research would be profoundly impactful, particularly
    in light of the rapid development of numerous fields and the accompanying information
    explosion. In these contexts, learning a topic and composing an academic survey
    report often necessitates several months of effort by multiple researchers. On
    the LLM side, it is imperative to acquire the capability to conduct independent
    research on topics not encompassed within their pre-training datasets. Possessing
    such an ability would eliminate the necessity for continuous updates and re-training
    of the entire model, thereby significantly enhancing its practical utility across
    diverse domains.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 进行研究的潜力将产生深远的影响，特别是考虑到众多领域的快速发展和随之而来的信息爆炸。在这些背景下，学习一个主题并撰写学术调查报告通常需要多个研究人员几个月的努力。在
    LLM 方面，获得对其预训练数据集未涵盖的主题进行独立研究的能力是至关重要的。具备这种能力将消除对整个模型进行持续更新和再训练的必要，从而显著提升其在各个领域的实际应用价值。
- en: Previous research involving autonomous agents in tasks that are relatively straightforward
    and executable by the general public, such as online shopping or playing card
    games, has demonstrated notable success, particularly when utilizing models like
    GPT-4 [[6](#bib.bib6), [9](#bib.bib9)]. However, more challenging categories,
    such as research tasks that require domain-specific expertise, represent the next
    frontier for potential advancements by LLM agents. Admittedly, there is a paucity
    of research in this area, and one of the primary challenges is the absence of
    standardized benchmarks.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 以往涉及自主代理的研究，诸如在线购物或玩纸牌游戏等相对简单且可由公众执行的任务，已取得显著成功，特别是当利用像 GPT-4 这样的模型时 [[6](#bib.bib6),
    [9](#bib.bib9)]。然而，更具挑战性的类别，如需要领域特定专业知识的研究任务，代表了 LLM 代理潜在进步的下一前沿。诚然，该领域的研究还很稀缺，其中一个主要挑战是缺乏标准化的基准测试。
- en: 'To advance the development of research agents capable of conducting comprehensive
    surveys, we introduce the ResearchArena benchmark, which is rooted in rigorous
    scholarly content. This benchmark specifically leverages academic papers due to
    their depth of research, peer-reviewed accuracy, and formal structure—attributes
    often lacking in other sources such as web pages. The ResearchArena provides an
    offline environment where autonomous agents can collect and organize information
    to conduct research across various topics. It comprises three sub-tasks for evaluation:
    Information Discovery, Information Selection, and Information Organization. These
    three sub-tasks emulate the general methodology employed by human researchers
    during literature surveys, which are discussed further below.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了推动能够进行全面调查的研究代理的发展，我们引入了基于严谨学术内容的 ResearchArena 基准测试。该基准测试特别利用学术论文，因为它们具有深入的研究、同行评审的准确性和正式的结构——这些特征在其他来源如网页中往往缺失。ResearchArena
    提供了一个离线环境，允许自主代理收集和组织信息，以在各种主题上进行研究。它包含三个评估子任务：信息发现、信息选择和信息组织。这三个子任务模拟了人类研究人员在文献调查中使用的一般方法，下面将进一步讨论。
- en: 'Researchers typically conduct literature surveys by defining the scope of their
    inquiry, developing a search protocol, and iteratively reading and organizing
    papers into an evolving schema. This process culminates in a synthesis of findings
    to draw conclusions and highlight future research directions [[10](#bib.bib10)].
    Based on this methodology, our benchmark delineates the surveying process into
    three specific tasks: Information Discovery, Information Selection, and Information
    Organization. Notably, we do not include the generation of text as part of the
    evaluation. This exclusion stems from the premise that a comprehensive understanding
    of the topic, established during the pre-writing stage through research, should
    already provide a robust foundation for composing a full-length article [[11](#bib.bib11)].
    Furthermore, evaluating a complete article is inherently challenging due to variations
    in individual writing styles. Consequently, we reserve such assessments for future
    investigations and potentially other benchmarks targeting long-text natural language
    generation.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员通常通过定义调查范围、制定搜索协议以及迭代地阅读和组织论文到一个不断发展的框架中来进行文献调查。这个过程 culminates 在综合发现以得出结论并突出未来的研究方向[[10](#bib.bib10)]。基于这一方法论，我们的基准将调查过程划分为三个具体任务：信息发现、信息选择和信息组织。值得注意的是，我们不包括生成文本作为评估的一部分。这一排除的前提是，在研究阶段通过研究建立对主题的全面理解，应该已经为撰写完整文章提供了坚实的基础[[11](#bib.bib11)]。此外，评估完整文章本质上具有挑战性，因为个体写作风格的差异。因此，我们将此类评估保留给未来的研究，并可能留给其他针对长文本自然语言生成的基准。
- en: The Information Discovery task requires LLMs to identify and retrieve relevant
    academic papers that are foundational to the survey topic, leveraging their ability
    to navigate and understand vast scholarly corpus. The Information Selection task
    then challenges the LLMs to critically evaluate these papers based on their scholarly
    impact and relevance, mimicking the peer review process to ensure only the most
    significant studies are considered. Lastly, the Information Organization task
    assesses the LLMs’ ability to synthesize the selected research into a coherent
    narrative, offering a structured and insightful overview of the topic, through
    the use of knowledge mind-maps.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 信息发现任务要求 LLMs 识别和检索与调查主题相关的基础学术论文，利用其在广泛学术语料库中导航和理解的能力。信息选择任务则挑战 LLMs 基于学术影响力和相关性来批判性地评估这些论文，模拟同行评审过程以确保只考虑最重要的研究。最后，信息组织任务评估
    LLMs 将选定的研究综合成连贯叙述的能力，通过使用知识思维导图提供主题的结构化和有洞察力的概述。
- en: 'Our assessments indicate that LLMs frequently underperform when compared to
    simpler keyword-based search methods, particularly in tasks requiring deep analytical
    skills. For example, traditional techniques such as utilizing a survey title as
    a retrieval query consistently outperform LLMs in both Information Discovery and
    Information Selection, as demonstrated by superior recall and precision metrics.
    Furthermore, during the Information Organization phase, particularly in the absence
    of oracle guidance¹¹1The term ”oracle” refers to the distinction between intermediate
    and end-to-end versions in the task of Information Organization, as discussed
    in Section [5](#S5 "5 Benchmark Tasks ‣ ResearchArena: Benchmarking LLMs’ Ability
    to Collect and Organize Information as Research Agents")., LLMs encounter significant
    challenges in constructing coherent and accurate knowledge structures. This underscores
    a critical need for enhancements in their ability to manage complex organizational
    tasks independently.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '我们的评估表明，与简单的基于关键词的搜索方法相比，LLMs 在某些任务中表现往往较差，特别是在需要深度分析技能的任务中。例如，传统技术如使用调查标题作为检索查询在信息发现和信息选择方面的一贯表现优于
    LLMs，如通过优越的召回率和精确度指标所示。此外，在信息组织阶段，尤其是在缺乏 oracle 指导的情况下¹¹1术语“oracle”指的是在信息组织任务中中间版本与端到端版本之间的区别，如第
    [5](#S5 "5 Benchmark Tasks ‣ ResearchArena: Benchmarking LLMs’ Ability to Collect
    and Organize Information as Research Agents")节讨论的那样，LLMs 在构建连贯且准确的知识结构方面遇到重大挑战。这突显了在独立管理复杂组织任务能力上的重要提升需求。'
- en: The constructed environment includes 12.0M full-text academic papers and 7.9K
    survey papers, meticulously curated from the Semantic Scholar Open Research Corpus
    (S2ORC) [[12](#bib.bib12)]. This rigorous selection process ensures a high standard
    of reliability and scholarly relevance, rendering the dataset ideal for evaluating
    LLMs designed to execute complex, domain-specific research. By focusing on such
    a rich and diverse academic base, the dataset supports a robust analysis of LLM
    capabilities across multiple scientific domains, providing a realistic and challenging
    environment for benchmarking. Furthermore, the S2ORC is updated on a weekly basis,
    allowing for the inclusion and evaluation of newer content that extends beyond
    the LLMs’ knowledge cutoff.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 构建的环境包括 12.0M 的全文学术论文和 7.9K 的调查论文，精心筛选自 Semantic Scholar Open Research Corpus
    (S2ORC) [[12](#bib.bib12)]。这一严格的筛选过程确保了高标准的可靠性和学术相关性，使得该数据集非常适合评估旨在执行复杂领域特定研究的
    LLMs。通过专注于如此丰富多样的学术基础，该数据集支持对 LLM 能力在多个科学领域的全面分析，提供了一个现实而具有挑战性的基准环境。此外，S2ORC 每周更新一次，允许纳入和评估超出
    LLM 知识截止点的新内容。
- en: 'The remainder of this paper is structured as follows: After reviewing related
    work in Section [2](#S2 "2 Related Work ‣ ResearchArena: Benchmarking LLMs’ Ability
    to Collect and Organize Information as Research Agents"), Section [3](#S3 "3 Collection
    Methodology ‣ ResearchArena: Benchmarking LLMs’ Ability to Collect and Organize
    Information as Research Agents") details our dataset collection process. Subsequently,
    Section [4](#S4 "4 Dataset Composition ‣ ResearchArena: Benchmarking LLMs’ Ability
    to Collect and Organize Information as Research Agents") provides a thorough analysis
    of the dataset composition and its various statistical properties. Each task within
    the benchmark, along with their corresponding metrics, is introduced in Section
    [5](#S5 "5 Benchmark Tasks ‣ ResearchArena: Benchmarking LLMs’ Ability to Collect
    and Organize Information as Research Agents"). Finally, the evaluations across
    various baselines are presented in Section [6](#S6 "6 Experiments ‣ ResearchArena:
    Benchmarking LLMs’ Ability to Collect and Organize Information as Research Agents").'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '本论文的其余部分结构如下：在第 [2](#S2 "2 Related Work ‣ ResearchArena: Benchmarking LLMs’
    Ability to Collect and Organize Information as Research Agents") 节回顾相关工作后，第 [3](#S3
    "3 Collection Methodology ‣ ResearchArena: Benchmarking LLMs’ Ability to Collect
    and Organize Information as Research Agents") 节详细介绍了我们的数据集收集过程。随后，第 [4](#S4 "4
    Dataset Composition ‣ ResearchArena: Benchmarking LLMs’ Ability to Collect and
    Organize Information as Research Agents") 节提供了数据集组成及其各种统计属性的详细分析。基准中的每个任务及其对应的指标在第
    [5](#S5 "5 Benchmark Tasks ‣ ResearchArena: Benchmarking LLMs’ Ability to Collect
    and Organize Information as Research Agents") 节中介绍。最后，各种基线的评估结果在第 [6](#S6 "6 Experiments
    ‣ ResearchArena: Benchmarking LLMs’ Ability to Collect and Organize Information
    as Research Agents") 节中呈现。'
- en: 2 Related Work
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: Previous research has employed diverse methodologies to compile datasets featuring
    academic survey papers. For instance, BigSurvey dataset [[13](#bib.bib13)] aggregates
    over 7K survey papers from arXiv and includes approximately 434K eferences from
    Microsoft Academic Service and Semantic Scholar. This dataset underwent rigorous
    preprocessing by removing duplicates, unprocessable files, and normalizing text.
    On the other hand, Surfer100 dataset [[14](#bib.bib14)] includes 100 surveys emulating
    Wikipedia page structures, compiled by eight annotators who summarized content
    from web pages. Each survey contains predefined sections such as Introduction,
    History, Key Ideas, Variations, and Applications, summarized concisely in 50 to
    150 words.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 以往的研究采用了多种方法来编制包含学术调查论文的数据集。例如，BigSurvey 数据集 [[13](#bib.bib13)] 汇总了来自 arXiv
    的 7K 多篇调查论文，并包括了约 434K 条来自 Microsoft Academic Service 和 Semantic Scholar 的参考文献。该数据集经过严格的预处理，包括删除重复项、不可处理的文件以及文本规范化。另一方面，Surfer100
    数据集 [[14](#bib.bib14)] 包含 100 份模仿 Wikipedia 页面结构的调查，由八名注释员编写，他们总结了网页内容。每份调查包含预定义的部分，如引言、历史、关键思想、变体和应用，并在
    50 到 150 字内进行简洁总结。
- en: BigSurvey dataset provides references in an abstract-only format, offering a
    concise overview of documents. Surfer100 utilizes Google search results to compile
    references for each survey topic, reflecting a broad spectrum of web-based information.
    In contrast, our dataset emphasizes full-text academic papers for a deeper understanding
    and leverages bibliographic references from original survey papers for enhanced
    authority and accuracy.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: BigSurvey 数据集以仅包含摘要的格式提供参考文献，提供了文献的简要概述。Surfer100 利用 Google 搜索结果为每个调查主题汇编参考文献，反映了广泛的网络信息。相比之下，我们的数据集强调完整的学术论文，以获得更深入的理解，并利用原始调查论文中的书目参考文献，以提高权威性和准确性。
- en: The most related LLM agents task in previous research focuses on generating
    Wikipedia articles. Liu et al. proposed a method for generating English Wikipedia
    articles by framing the task as a multi-document summarization challenge [[15](#bib.bib15)].
    Their approach employs a combination of extractive and abstractive summarization
    techniques. It involves identifying salient information using methods such as
    TF-IDF and TextRank [[16](#bib.bib16)]. In another study, Shao et al. introduced
    the STORM system [[17](#bib.bib17)], which addresses pre-writing challenges such
    as research and outline preparation. STORM enhances the article generation process
    by simulating multi-perspective conversations, wherein an LLM poses questions
    and aggregates responses from reliable sources to develop detailed outlines.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 之前研究中最相关的 LLM 代理任务集中在生成维基百科文章。刘等人提出了一种通过将任务框架化为多文档摘要挑战来生成英语维基百科文章的方法[[15](#bib.bib15)]。他们的方法结合了提取式和抽象式摘要技术，涉及使用
    TF-IDF 和 TextRank 等方法识别重要信息[[16](#bib.bib16)]。在另一项研究中，邵等人介绍了 STORM 系统[[17](#bib.bib17)]，该系统解决了如研究和大纲准备等写作前的挑战。STORM
    通过模拟多角度对话来增强文章生成过程，其中 LLM 提问并汇总来自可靠来源的回答，以制定详细的大纲。
- en: While Wikipedia is a valuable resource for obtaining an introductory understanding
    of a subject, it is inherently limited by the user-authored nature of its content,
    which does not always guarantee expert oversight. In contrast, rigorous academic
    research requires a more in-depth and systematic investigation of a topic, often
    peer-reviewed by experts within the same domain.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然维基百科是获取某个主题入门理解的宝贵资源，但由于其内容由用户撰写，缺乏专家监督，存在固有的局限性。相比之下，严格的学术研究需要对主题进行更深入和系统的调查，通常由该领域的专家进行同行评审。
- en: 3 Collection Methodology
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 收集方法
- en: 'This section delineates our methodology for assembling the dataset, which contains
    three primary stages: survey selection, reference linking, and mind-map extraction.
    Each stage is indispensable for ensuring the the relevance and accuracy of the
    dataset, thereby facilitating its application across various benchmark tasks.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 本节描述了我们组装数据集的方法，包括三个主要阶段：调查选择、参考文献链接和思维导图提取。每个阶段对于确保数据集的相关性和准确性都是不可或缺的，从而促进其在各种基准任务中的应用。
- en: We begin with the survey selection stage, which concentrates on identifying
    relevant survey papers. Following this, we proceed to the reference linking stage,
    where we incorporate bibliographic references from each selected survey. Finally,
    we address the mind-map extraction stage, detailing the criteria employed to identify
    knowledge mind-maps from the surveys. Each of these stages and their respective
    methodologies are presented in the corresponding subsections. At the very end,
    we provide a quick overview of the dataset.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从调查选择阶段开始，该阶段专注于识别相关的调查论文。接下来，我们进入参考文献链接阶段，在此阶段中，我们从每个选定的调查中纳入书目参考文献。最后，我们处理思维导图提取阶段，详细说明了用于从调查中识别知识思维导图的标准。这些阶段及其各自的方法将在相应的子节中呈现。最后，我们提供了数据集的简要概述。
- en: 3.1 Survey Selection
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 调查选择
- en: To evaluate the research capabilities on designated topics, it is essential
    first to identify these topics. This was achieved by extracting every survey paper
    from the S2ORC dataset, based on a combination of keyword-based filtration and
    rigorous textual analysis. In general, the titles of survey papers encapsulate
    the topics discussed therein.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估指定主题上的研究能力，首先需要确定这些主题。我们通过从 S2ORC 数据集中提取每篇调查论文，结合基于关键词的过滤和严格的文本分析来实现这一点。一般来说，调查论文的标题概括了其中讨论的主题。
- en: To compile all relevant survey topics, we first need to identify research surveys
    from the corpus. We assume that titles of all the topic-specific survey papers
    contain the term “survey”, but not every paper satisfying this criteria is an
    actual survey pertaining to our research theme. In particular, some papers, despite
    incorporating the keyword, rely heavily on information outside the corpus. This
    includes population-based survey questionnaires from Medical domains or Redshift
    surveys using telescope observations in the field of Physics.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了汇总所有相关的调查主题，我们首先需要从语料库中识别研究调查。我们假设所有主题特定的调查论文的标题中都包含“survey”一词，但并非所有符合这一标准的论文都是与我们的研究主题相关的实际调查。特别是，一些论文尽管包含关键字，但在很大程度上依赖于语料库之外的信息。这包括来自医学领域的人口调查问卷或在物理学领域使用望远镜观测的红移调查。
- en: 'As a result, the identification was accomplished by a combination of keyword-based
    filtration and rigorous textual analysis. We first excluded those papers whose
    titles did not contain “survey” as a keyword. Afterwards, we instructed GPT-4
    ²²2GPT-4 refers to gpt-4-0613 as documented in [https://platform.openai.com/docs/models](https://platform.openai.com/docs/models).
    to discern the scope and content of each document based on its title and abstract.
    We included only those papers that provide an organized view on the current state
    of field concerning a specific topic. The exact wording of the prompts can be
    found in Figure [1](#S3.F1 "Figure 1 ‣ 3.1 Survey Selection ‣ 3 Collection Methodology
    ‣ ResearchArena: Benchmarking LLMs’ Ability to Collect and Organize Information
    as Research Agents"), where approximately 85% of the papers identified through
    the initial keyword search were discarded.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '结果是通过关键字过滤和严格的文本分析相结合来完成识别的。我们首先排除了标题中不包含“survey”这一关键字的论文。之后，我们指导GPT-4²²GPT-4
    指的是[https://platform.openai.com/docs/models](https://platform.openai.com/docs/models)中记录的
    gpt-4-0613，来根据每篇文献的标题和摘要识别其范围和内容。我们仅包括那些提供特定主题当前领域有组织视角的论文。提示的准确措辞见图[1](#S3.F1
    "图 1 ‣ 3.1 调查选择 ‣ 3 收集方法 ‣ ResearchArena: 基准测试 LLMs 收集和组织信息作为研究代理的能力")，其中大约85%的通过初步关键字搜索识别的论文被丢弃了。'
- en: 'As presented in Appendix [B](#A2 "Appendix B Quality of Collection Methodology
    ‣ ResearchArena: Benchmarking LLMs’ Ability to Collect and Organize Information
    as Research Agents"), a manual inspection of 25 samples from the final collection
    of survey papers revealed that our selection method yielded a 92% accuracy rate.
    The selection process is certainly not a perfect recall since survey papers may
    not explicitly include the term “survey” in their title. However, we believe that
    the selected papers are sufficiently representative of the broader distribution
    of survey literature in the field.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '如附录[B](#A2 "附录 B 收集方法的质量 ‣ ResearchArena: 基准测试 LLMs 收集和组织信息作为研究代理的能力")中所示，对最终收集的调查论文中的
    25 个样本进行的人工检查显示，我们的选择方法达到了 92% 的准确率。选择过程显然不是完美的回忆，因为调查论文可能在标题中没有明确包含“survey”一词。然而，我们认为所选论文足够代表该领域调查文献的广泛分布。'
- en: The  point  of  a  survey  paper  is  to  provide  an  organized  view  on  the  current  state  of  the  field.  If  it  relies  heavily  on  external  information,  such  as  the  results  of  a  population  questionnaire,  do  not  include  it.  Using  the  above  criteria,  is  the  following  article  a  survey  paper?  Respond  either  "True"  or  "False".
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 调查论文的要点是提供对当前领域状态的有组织视角。如果它过度依赖外部信息，如人口问卷的结果，则不包括在内。根据上述标准，以下文章是否是调查论文？请回答“True”或“False”。
- en: 'Figure 1: Instruction with GPT-4 on survey selection.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：关于调查选择的 GPT-4 指导。
- en: The corpus for conducting these research surveys is limited to papers with full-text
    access in S2ORC. Unlike previous works, we believe relying solely on abstract
    might omit crucial details present in the full text which could contribute to
    a deeper understanding of the topic. Enforcing this accessibility constraint reduced
    the number of papers in S2ORC to 12.0 million.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 进行这些研究调查的语料库仅限于 S2ORC 中具有全文访问权限的论文。与以往的工作不同，我们认为仅依靠摘要可能会遗漏存在于全文中的重要细节，这些细节可能有助于对主题的更深理解。施加这一可访问性限制将
    S2ORC 中的论文数量减少到 1200 万篇。
- en: 3.2 Reference Linking
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 参考文献链接
- en: To evaluate performance in Information Discovery, it is essential to identify
    the fundamental sources for these surveys. These sources are derived from the
    bibliographic references cited within each survey paper. We relied on S2ORC for
    the extracted bibliographies and enforced additional post-processing to discard
    any papers unsuitable for evaluations.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估信息发现的性能，识别这些调查的基本来源是至关重要的。这些来源来自每篇调查论文中引用的书目参考文献。我们依赖S2ORC来提取书目，并进行额外的后处理，以丢弃任何不适合评估的论文。
- en: Following the selection of relevant survey papers, we proceeded to compile their
    bibliographic references. Despite the general reliability of the S2ORC bibliographic
    resolution system, we encountered discrepancies, such as missing references. These
    issues were particularly prevalent in documents where the reference header was
    indistinguishable from the main body text. To address these problems, we excluded
    any survey papers without references, totaling 406, deeming them unsuitable due
    to the failure of bibliography extraction. Furthermore, survey papers with no
    accessible citations were filtered out, amounting to 1,635, as such papers offer
    no evaluative utility.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择了相关的调查论文后，我们继续编纂它们的书目参考文献。尽管S2ORC书目解析系统通常可靠，但我们遇到了一些不一致的问题，例如缺少参考文献。这些问题在参考文献标题与正文难以区分的文档中尤为普遍。为了解决这些问题，我们排除了所有没有参考文献的调查论文，共计406篇，认为这些论文因书目提取失败而不适用。此外，没有可访问引文的调查论文也被筛选掉，共计1,635篇，因为这些论文没有评估价值。
- en: 'For references that were successfully extracted, we documented the publication
    dates for each one. In cases where a reference listed only the year, we assigned
    the last day of that year as its date to mitigate the risk of information leakage,
    as discussed in Section [5](#S5 "5 Benchmark Tasks ‣ ResearchArena: Benchmarking
    LLMs’ Ability to Collect and Organize Information as Research Agents"). Furthermore,
    citations from S2ORC were categorized based on their contribution to the topic,
    as outlined by Valenzuela et al. [[18](#bib.bib18)] with a supervised classification
    approach. This categorization involved distinguishing between influential and
    non-influential references, which is a prerequisite for evaluating the task of
    Information Selection.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '对于成功提取的参考文献，我们记录了每个文献的出版日期。如果参考文献只列出了年份，我们将该年份的最后一天作为其日期，以降低信息泄露的风险，如第[5](#S5
    "5 Benchmark Tasks ‣ ResearchArena: Benchmarking LLMs’ Ability to Collect and
    Organize Information as Research Agents")节中所讨论。此外，来自S2ORC的引文根据它们对主题的贡献进行了分类，参照Valenzuela等人的[[18](#bib.bib18)]监督分类方法。该分类涉及区分具有影响力和无影响力的参考文献，这是评估信息选择任务的前提。'
- en: 3.3 Mind-Map Extraction
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 思维导图提取
- en: A common method for organizing information in academic surveys is the utilization
    of mind-map style typologies, which promote a systematic understanding of the
    subject under review. Due to the exclusive text-based nature of the S2ORC corpus,
    we employed an approach to extract such typologies by collecting every figure-caption
    pair directly from the Semantic Scholar website. Through the analysis of these
    captions using GPT-4, we identified relevant mind-map figures and transformed
    the graphical representations into JSON-encoded trees that preserve their hierarchical
    structure.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在学术调查中组织信息的一个常见方法是利用思维导图风格的分类方法，这有助于系统化地理解所评审的主题。由于S2ORC语料库完全基于文本，我们采用了一种通过直接从Semantic
    Scholar网站收集每对图形-说明文字的方式来提取此类分类方法。通过使用GPT-4分析这些说明文字，我们识别了相关的思维导图图形，并将图形表示转换为保留其层次结构的JSON编码树。
- en: 'This process is illustrated in Figure [2](#S3.F2 "Figure 2 ‣ 3.3 Mind-Map Extraction
    ‣ 3 Collection Methodology ‣ ResearchArena: Benchmarking LLMs’ Ability to Collect
    and Organize Information as Research Agents"), with the prompt provided in Figure
    [3](#S3.F3 "Figure 3 ‣ 3.3 Mind-Map Extraction ‣ 3 Collection Methodology ‣ ResearchArena:
    Benchmarking LLMs’ Ability to Collect and Organize Information as Research Agents").
    The extraction performed by GPT-4 is deemed accurate if the hierarchical structure
    of the figure is adequately represented by the JSON-encoded tree. Furthermore,
    relevance is determined if the figure authentically represents a knowledge mind-map
    pertinent to the survey topic. As detailed in Appendix [B](#A2 "Appendix B Quality
    of Collection Methodology ‣ ResearchArena: Benchmarking LLMs’ Ability to Collect
    and Organize Information as Research Agents"), a manual inspection of 25 samples
    from the final collection of mind-maps revealed that our extraction method achieved
    an accuracy score of 80% and a relevance score of 60%.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这一过程在图 [2](#S3.F2 "图 2 ‣ 3.3 思维导图提取 ‣ 3 数据收集方法 ‣ ResearchArena：基准测试 LLM 收集和组织信息的能力")
    中进行了说明，提示信息见图 [3](#S3.F3 "图 3 ‣ 3.3 思维导图提取 ‣ 3 数据收集方法 ‣ ResearchArena：基准测试 LLM
    收集和组织信息的能力")。如果图的层次结构被 JSON 编码的树充分表示，则 GPT-4 执行的提取被认为是准确的。此外，如果该图真实地代表了与调查主题相关的知识思维导图，则其相关性被确定。如附录
    [B](#A2 "附录 B 数据收集方法的质量 ‣ ResearchArena：基准测试 LLM 收集和组织信息的能力") 中详细说明，从最终收集的思维导图中手动检查的
    25 个样本显示，我们的提取方法达到了 80% 的准确率和 60% 的相关性分数。
- en: '![Refer to caption](img/477ba97940f1202ba1842363269c47d2.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/477ba97940f1202ba1842363269c47d2.png)'
- en: '[PRE0]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Figure 2: Mind-map extraction from a figure [[19](#bib.bib19)] to its JSON
    representation.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：从图 [[19](#bib.bib19)] 到其 JSON 表示的思维导图提取。
- en: Identify  the  figure  that  most  likely  illustrates  a  taxonomy  or  overview.  Your  response  should  be  limited  to  the  filename,  or  NULL  if  not  found.  The  provided  figure  presents  a  hierarchy.  Extract  as  JSON-encoded  tree  whose  children  are  NULL-terminated.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 确定最有可能展示分类法或概述的图表。您的回答应仅限于文件名，或者如果未找到，则为 NULL。提供的图表展示了一个层次结构。提取为 JSON 编码的树，其子节点以
    NULL 结束。
- en: 'Figure 3: Instruction with GPT-4 on mind-map extraction.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：关于思维导图提取的 GPT-4 指令。
- en: 3.4 ResearchArena Dataset
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 ResearchArena 数据集
- en: To ensure the reproducibility of our work and compliance with copyright standards,
    we developed the dataset from S2ORC, which provides access to 81.1 million academic
    papers in English from various disciplines. These documents are meticulously structured
    in a machine-readable format with resolved bibliographic references and annotated
    inline citations. We used the February 06, 2024 release of S2ORC, which was the
    most recent version at the start of our project.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保我们工作的可重复性和符合版权标准，我们从 S2ORC 开发了数据集，S2ORC 提供了来自各个学科的 8,110 万篇英文学术论文。这些文档被精确地结构化为机器可读格式，解决了书目引用和注释内联引用。我们使用了
    2024 年 2 月 06 日发布的 S2ORC，这是项目开始时最新的版本。
- en: For a concise summary of our dataset, it consists of approximately 12 million
    academic papers, each with full-text access, sourced from the Semantic Scholar
    Open Research Corpus. From this vast repository, we have successfully identified
    7,952 survey papers. These surveys have been meticulously analyzed to derive 1,884
    mind-maps, which provide structured summaries of the topics covered.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们数据集的简要总结，它包含大约 1200 万篇学术论文，每篇都有全文访问权限，来源于 Semantic Scholar Open Research
    Corpus。在这个庞大的存储库中，我们成功识别了 7,952 篇调查论文。这些调查论文已被仔细分析，以提取 1,884 个思维导图，提供了覆盖主题的结构化总结。
- en: 4 Dataset Composition
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 数据集组成
- en: Understanding the composition of our dataset is essential for ensuring the reliability
    and comprehensiveness of the benchmark used to evaluate LLMs in academic survey
    tasks. This section details the makeup of our dataset in terms of disciplinary
    diversity, reference coverage, and the structural complexity of derived typologies,
    reflecting on how these factors contribute to the robustness and applicability
    across various domains.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 理解我们数据集的组成对于确保用于评估 LLM 在学术调查任务中的基准的可靠性和全面性至关重要。本节详细描述了我们数据集的组成，包括学科多样性、参考文献覆盖范围以及衍生类型学的结构复杂性，并反映这些因素如何有助于跨领域的稳健性和适用性。
- en: 'Disciplinary Distribution. We classified each of the 12.0M papers in our public
    corpus and 7.9K survey papers by the top-5 most popular academic disciplines.
    This classification was based on the indexing information provided by S2ORC. Frequencies
    of papers per discipline were then aggregated and visualized to identify trends
    and imbalances. Figure [4(a)](#S4.F4.sf1 "In Figure 4 ‣ 4 Dataset Composition
    ‣ ResearchArena: Benchmarking LLMs’ Ability to Collect and Organize Information
    as Research Agents") and [4(b)](#S4.F4.sf2 "In Figure 4 ‣ 4 Dataset Composition
    ‣ ResearchArena: Benchmarking LLMs’ Ability to Collect and Organize Information
    as Research Agents") revealed significant disparities in the frequency of disciplines
    between the public corpus and the survey subset. Notably, Computer Science is
    the most prevalent discipline within surveys but less common in the broader corpus.
    This could reflect the dynamic nature of the CS field, which often necessitates
    comprehensive reviews to synthesize rapid advancements and emerging trends.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '学科分布。我们将我们公共语料库中的1200万篇论文和7900篇调查论文按前五大最受欢迎的学科进行了分类。这一分类基于S2ORC提供的索引信息。每个学科的论文频率随后被汇总并可视化，以识别趋势和不平衡情况。图
    [4(a)](#S4.F4.sf1 "在图4 ‣ 4 数据集组成 ‣ ResearchArena: 基准测试LLMs收集和组织信息作为研究代理的能力") 和
    [4(b)](#S4.F4.sf2 "在图4 ‣ 4 数据集组成 ‣ ResearchArena: 基准测试LLMs收集和组织信息作为研究代理的能力") 揭示了公共语料库与调查子集之间在学科频率上的显著差异。特别是，计算机科学在调查中是最常见的学科，但在更广泛的语料库中则较为罕见。这可能反映了计算机科学领域的动态特性，该领域常常需要全面的综述来综合快速发展的技术和新兴趋势。'
- en: 'Reference Coverage. For each survey paper, we calculated the coverage ratio
    as the proportion of its references that were also available within our full-text
    corpus. We plotted cumulative density functions for each discipline to analyze
    how extensively the surveys’ references are represented in the broader corpus.
    As illustrated with Figure [4(c)](#S4.F4.sf3 "In Figure 4 ‣ 4 Dataset Composition
    ‣ ResearchArena: Benchmarking LLMs’ Ability to Collect and Organize Information
    as Research Agents"), similar patterns were observed across all disciplines, where
    the density experienced exponential decay as the coverage increases. Approximately
    17.18% of the survey subset (i.e., 1.3K survey papers) have at least 50% of their
    references available. This limitation is mainly attributed to copyright restrictions,
    where full-text is not permitted by the publisher.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '参考覆盖率。对于每篇调查论文，我们计算了其参考文献在我们全文语料库中可用的比例，即覆盖率。我们绘制了每个学科的累积分布函数，以分析调查文献参考在更广泛语料库中的代表程度。正如图
    [4(c)](#S4.F4.sf3 "在图4 ‣ 4 数据集组成 ‣ ResearchArena: 基准测试LLMs收集和组织信息作为研究代理的能力") 所示，所有学科中都观察到了类似的模式，即随着覆盖率的增加，密度呈指数衰减。约17.18%的调查子集（即1300篇调查论文）有至少50%的参考文献可用。这一限制主要归因于版权限制，出版商不允许提供全文。'
- en: 'Mind-Map Complexity. We analyzed the structural complexity of the mind-maps
    extracted from survey papers by counting the number of nodes and measuring the
    maximal depth. These measures provide insights into the conceptual breadth and
    hierarchical depth of the topics covered. The scatter plot from Figure [4(d)](#S4.F4.sf4
    "In Figure 4 ‣ 4 Dataset Composition ‣ ResearchArena: Benchmarking LLMs’ Ability
    to Collect and Organize Information as Research Agents") showed that typologies
    in general have shallow depths but a broad range of nodes, suggesting that while
    survey topics are extensively branched, they do not delve deeply into sub-topics.
    In particular, most typologies have a maximum depth ranging from 3 to 7 levels,
    where the coefficient of the regression line in the scatter plot is approximately
    2.04.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '思维导图复杂性。我们通过计算节点数量和测量最大深度来分析从调查论文中提取的思维导图的结构复杂性。这些度量提供了对所涵盖主题的概念广度和层次深度的洞察。图
    [4(d)](#S4.F4.sf4 "在图4 ‣ 4 数据集组成 ‣ ResearchArena: 基准测试LLMs收集和组织信息作为研究代理的能力") 的散点图显示，典型的思维导图一般具有较浅的深度，但节点范围较广，表明虽然调查主题有广泛的分支，但并未深入探讨子主题。特别是，大多数典型的思维导图具有3到7层的最大深度，其中散点图中的回归线系数约为2.04。'
- en: '![Refer to caption](img/8751fe8044d6abdf1d656d1d0b34726a.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8751fe8044d6abdf1d656d1d0b34726a.png)'
- en: (a) Disciplinary distribution of the public corpus.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 公共语料库的学科分布。
- en: '![Refer to caption](img/f1121bd96427dad05be3fd6f072f76c5.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/f1121bd96427dad05be3fd6f072f76c5.png)'
- en: (b) Disciplinary distribution of the survey subset.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 调查子集的学科分布。
- en: '![Refer to caption](img/93c0b86b504db751860600eb75663941.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/93c0b86b504db751860600eb75663941.png)'
- en: (c) Reference coverage of the survey subset.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 调查子集的参考覆盖范围。
- en: '![Refer to caption](img/b725d8e8df1c1cef707780df2f0203a5.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/b725d8e8df1c1cef707780df2f0203a5.png)'
- en: (d) Complexity with the extracted mind-maps.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: (d) 提取的思维导图的复杂性。
- en: 'Figure 4: Dataset composition analysis with disciplinary distribution, reference
    coverage, and mind-map complexity. Each of these aspects is critical for benchmark
    evaluation. Fields of studies like Medicine (Med), Biology (Bio), Physics (Phy),
    Environmental Science (ES), Computer Science (CS), Engineering (Eng), and Mathematics
    (Math) are denoted with their abbreviations in the figures.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：数据集组成分析，包括学科分布、参考覆盖率和思维导图复杂性。这些方面对基准评估至关重要。医学 (Med)、生物学 (Bio)、物理学 (Phy)、环境科学
    (ES)、计算机科学 (CS)、工程 (Eng) 和数学 (Math) 等研究领域在图中用其缩写表示。
- en: 5 Benchmark Tasks
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 个基准任务
- en: This section presents a comprehensive overview of the benchmark tasks designed
    to evaluate the capabilities of research agents in discovering, selecting, and
    organizing information. Each task targets a specific aspect of research proficiency,
    with rigorous constraints and evaluation metrics to ensure thorough and unbiased
    assessment.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提供了一个全面的基准任务概述，旨在评估研究代理在发现、选择和组织信息方面的能力。每个任务针对研究能力的特定方面，设有严格的约束和评估指标，以确保彻底和公正的评估。
- en: Information Discovery. Provided a topic extracted from survey title, the task
    of information discovery requires research agents to identify a subset of documents
    $R$.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 信息发现。提供从调查标题中提取的主题，信息发现的任务要求研究代理识别文献子集 $R$。
- en: However, within the collection $D$.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在集合 $D$ 中。
- en: To evaluate performance, we employ standard information retrieval metrics, Recall
    and Precision, to measure the proportion of relevant documents successfully retrieved
    and the proportion of retrieved documents that are relevant. Together, these metrics
    determine the effectiveness and accuracy of the discovery process. For this task,
    the cutoff parameter $K$ is set at 10 and 100.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估性能，我们使用标准的信息检索指标，召回率和精准度，来测量成功检索到的相关文献的比例以及检索到的文献中相关文献的比例。这些指标共同决定了发现过程的有效性和准确性。对于这项任务，截止参数
    $K$ 设置为 10 和 100。
- en: 'Information Selection. The task of information selection requires research
    agents to rank the discovered documents based on their importance to the topic.
    The labels are distinctions between influential and non-influential citations,
    as elaborated in Section [3](#S3 "3 Collection Methodology ‣ ResearchArena: Benchmarking
    LLMs’ Ability to Collect and Organize Information as Research Agents"). Normalized
    Discounted Cumulative Gain (nDCG) [[20](#bib.bib20)] and Mean Reciprocal Rank
    (MRR) [[21](#bib.bib21)] are used for evaluation.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '信息选择。信息选择的任务要求研究代理根据文献与主题的相关性对发现的文献进行排序。标签是区分有影响力和无影响力的引用，如[3](#S3 "3 Collection
    Methodology ‣ ResearchArena: Benchmarking LLMs’ Ability to Collect and Organize
    Information as Research Agents")节中详细说明。使用归一化折扣累计增益 (nDCG) [[20](#bib.bib20)] 和平均倒数排名
    (MRR) [[21](#bib.bib21)] 进行评估。'
- en: These measures are crucial because conducting research involves more than merely
    summarizing retrieved documents; it requires the presentation of key insights
    from the most significant sources. Furthermore, both human researchers and autonomous
    agents are limited by their processing capacities. Therefore, it is essential
    to prioritize and focus on the most critical information first.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这些措施至关重要，因为进行研究不仅仅是总结检索到的文献；还需要呈现最重要来源的关键见解。此外，人类研究者和自主代理都受到处理能力的限制。因此，优先关注和聚焦最关键的信息是必不可少的。
- en: Information Organization. For information organization, research agents are
    required to construct a hierarchical knowledge mind-map $M$ is the set of discovered
    documents from the previous task.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 信息组织。在信息组织方面，研究代理需要构建一个分层的知识思维导图，$M$ 是来自前一个任务的发现文献集合。
- en: 'For evaluation, two primary metrics are employed: Heading Soft Recall [[22](#bib.bib22)]
    and Heading Entity Recall [[17](#bib.bib17)]. These metrics compare the set of
    node labels from the original and the constructed knowledge mind-maps, referred
    to as $A$ is the set of labels extracted from the mind-maps.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 评估中采用了两个主要指标：标题软召回 [[22](#bib.bib22)] 和标题实体召回 [[17](#bib.bib17)]。这些指标比较原始和构建的知识思维导图中的节点标签集合，称为
    $A$ 是从思维导图中提取的标签集合。
- en: '|  | $\displaystyle\text{Cardinality}(S)$ |  |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\text{基数}(S)$ |  |'
- en: '|  | $\displaystyle\text{Heading Soft Recall}(A,B)$ |  |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\text{标题软召回}(A,B)$ |  |'
- en: '|  | $\displaystyle\text{Heading Entity Recall}(A,B)$ |  |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\text{标题实体召回}(A,B)$ |  |'
- en: While these metrics provide a measure of content similarity, they do not account
    for structural alignment. Tree Editing Distance [[25](#bib.bib25)] solves this
    concern by calculating the minimal number of operations (i.e., relabeling, deleting,
    and inserting nodes) required to transform one tree into another. Nonetheless,
    relying on Tree Editing Distance alone might overlook the potential for non-exact
    label matches. To address this, we propose Tree Semantic Distance, which assigns
    no cost to editing operations involving nodes whose cosine similarity exceeds
    $0.8$.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些指标提供了内容相似性的度量，但它们并未考虑结构对齐。树编辑距离 [[25](#bib.bib25)] 通过计算将一棵树转变为另一棵树所需的最少操作（即重新标记、删除和插入节点）来解决此问题。然而，仅依赖树编辑距离可能会忽略非精确标签匹配的潜在可能性。为此，我们提出了树语义距离，该距离对涉及余弦相似度超过
    $0.8$ 的节点的编辑操作不收取成本。
- en: 6 Experiments
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 实验
- en: 'In this section, we present preliminary evaluations of existing techniques,
    describing their configurations and performance metrics. These techniques encompass
    both naive keyword-based methods, such as Title, and advanced LLM-based methods,
    including STORM. The exact wording of the prompts used in each baseline can be
    found in Appendix [C](#A3 "Appendix C Prompts with Experiments ‣ ResearchArena:
    Benchmarking LLMs’ Ability to Collect and Organize Information as Research Agents").'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们介绍现有技术的初步评估，描述其配置和性能指标。这些技术包括简单的基于关键词的方法，如标题方法，以及高级的基于 LLM 的方法，如 STORM。每个基准使用的提示的具体措辞可以在附录
    [C](#A3 "附录 C 实验提示 ‣ ResearchArena: 评估 LLM 收集和组织信息作为研究代理的能力") 中找到。'
- en: 6.1 Baselines
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 基准
- en: Information Discovery. For information discovery, research agents are equipped
    with retrieval tools that enable interaction with the public corpus by submitting
    queries to retrievers such as BM25 and BGE [[26](#bib.bib26)]. These agents are
    evaluated based on their ability to effectively leverage these tools by generating
    relevant queries. Since exploration is limited to previously published non-survey
    literature, retrievers retry with exponential back-off until the cutoff parameter
    $K$ is satisfied.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 信息发现。在信息发现方面，研究代理配备了检索工具，使其能够通过向 BM25 和 BGE 等检索器提交查询，与公共语料库进行交互[[26](#bib.bib26)]。这些代理根据有效利用这些工具生成相关查询的能力进行评估。由于探索仅限于先前发布的非调查文献，检索器会使用指数退避重新尝试，直到满足截止参数
    $K$。
- en: •
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Title: Assuming that research topics are encapsulated within survey titles,
    this method directly employs the title from each survey paper as a query to retrieve
    relevant materials that support research on the topic. It is important to note
    that title extraction using S2ORC exhibits variable capitalization across different
    documents. As a result, we normalize by converting titles to lowercase.'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '标题: 假设研究主题被封装在调查标题中，此方法直接将每篇调查论文的标题用作查询，以检索支持该主题研究的相关材料。需要注意的是，使用 S2ORC 提取标题时，不同文档中的大写字母表现不一致。因此，我们通过将标题转换为小写来进行标准化。'
- en: •
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Zero-Shot: Assuming that existing LLMs possess prior knowledge relevant to
    a survey topic, this method extends the Title method by instructing GPT-4 to derive
    a query from the survey title. This approach leverages the inherent capabilities
    of LLMs to generate more sophisticated and contextually appropriate queries.'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'Zero-Shot: 假设现有的 LLM 具备与调查主题相关的先验知识，此方法通过指导 GPT-4 从调查标题中提取查询，从而扩展了标题方法。此方法利用了
    LLM 的固有能力，以生成更复杂且上下文相关的查询。'
- en: •
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Decomposer: As discovered by Tushar et al. [[27](#bib.bib27)], decomposed prompting
    is more effective when individual reasoning steps of a task are difficult to learn.
    This principle is applicable to our case, as a survey topic may consist of multiple
    sub-topics, making it challenging to directly generate a single query that retrieves
    all relevant papers. Consequently, we instruct GPT-4 to first deconstruct the
    research topic into several sub-questions. Each sub-question then generates a
    corresponding sub-query. These sub-queries are retrieved in batches, and the results
    are amalgamated using reciprocal rank fusion [[28](#bib.bib28)].'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 分解器：正如 Tushar 等人所发现的 [[27](#bib.bib27)]，当任务的各个推理步骤难以学习时，分解提示更为有效。这个原则适用于我们的情况，因为调查主题可能包含多个子主题，使得直接生成一个检索所有相关论文的单一查询变得具有挑战性。因此，我们指示
    GPT-4 首先将研究主题分解为几个子问题。每个子问题随后生成一个相应的子查询。这些子查询按批次检索，结果通过互惠排序融合 [[28](#bib.bib28)]
    进行汇总。
- en: •
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Self-RAG: As proposed by Asai et al. [[29](#bib.bib29)], Self-RAG adaptively
    retrieves passages on demand and utilizes reflection tokens to determine which
    retrieved documents are relevant to the instruction, thus continuing the generation
    based on the pertinent information. It serves as an enhanced version of Zero-Shot,
    where the model is instructed to generate a query from the topic. Because the
    model refines its final query generation based on the discovered information from
    intermediate retrievals, it operates as a research agent.'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自适应 RAG：正如 Asai 等人提出的 [[29](#bib.bib29)]，自适应 RAG 根据需求自适应检索段落，并利用反射标记确定哪些检索到的文档与指令相关，从而基于相关信息继续生成。它作为
    Zero-Shot 的增强版本，其中模型被指示从主题生成查询。由于模型基于中间检索发现的信息来完善最终查询生成，因此它作为一个研究代理进行操作。
- en: •
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'STORM: As presented in Section [2](#S2 "2 Related Work ‣ ResearchArena: Benchmarking
    LLMs’ Ability to Collect and Organize Information as Research Agents"), STORM
    conducts research through multi-perspective conversations to compose Wikipedia
    articles on particular topics from scratch. It closely resembles our scenario,
    except that the environment involves more rigorous academic papers. We record
    the retrieval history as STORM continues to probe for additional papers. Upon
    concluding the final round of conversations, every article within the retrieval
    history is considered part of the discovered information.'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'STORM：正如第 [2](#S2 "2 Related Work ‣ ResearchArena: Benchmarking LLMs’ Ability
    to Collect and Organize Information as Research Agents") 节中所述，STORM 通过多角度对话进行研究，从头开始撰写关于特定主题的
    Wikipedia 文章。这与我们的情况非常相似，只是环境涉及更为严格的学术论文。我们记录检索历史，因为 STORM 继续探查更多论文。在结束最后一轮对话时，检索历史中的每一篇文章都被视为发现的信息的一部分。'
- en: Information Selection. For information selection, documents are ranked based
    on the similarity scores obtained during the discovery phase. For BGE retriever,
    we rely on FAISS [[30](#bib.bib30)] to retrieve based on L2 distance in the embedding
    space, which is negated to determine similarity. On the other hand, STORM does
    not explicitly rank the retrieved documents. It is assumed that documents discovered
    earlier in the conversations are of higher relevance.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 信息选择。在信息选择方面，文档根据发现阶段获得的相似性评分进行排名。对于 BGE 检索器，我们依赖 FAISS [[30](#bib.bib30)] 根据嵌入空间中的
    L2 距离进行检索，距离被取反以确定相似性。另一方面，STORM 不明确地对检索到的文档进行排序。假设在对话中较早发现的文档相关性更高。
- en: Information Organization. For information organization, the Clustering approach
    employs Ward’s method for hierarchical clustering on the BGE embedding of every
    reference article, and the final dendrogram is extracted as typology. The label
    in each node is computed as the most important TF-IDF word, with ngrams ranging
    from 1 to 3\. Few-Shot is achieved by providing a few random examples of extracted
    typologies and instructing GPT-4 to generate another topic-oriented mind-map.
    Lastly, the article outline generated by STORM is converted to typology, with
    headings and their nested sub-headings representing the hierarchy.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 信息组织。在信息组织方面，聚类方法采用 Ward 方法对每篇参考文章的 BGE 嵌入进行层次聚类，最终的树状图作为分类提取。每个节点中的标签被计算为最重要的
    TF-IDF 词，ngram 范围从 1 到 3。通过提供一些随机的提取分类示例并指示 GPT-4 生成另一个主题导向的思维导图，实现了少量样本。最后，STORM
    生成的文章大纲被转换为分类，其中标题及其嵌套子标题代表层次结构。
- en: 6.2 Evaluation Results
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 评估结果
- en: The baseline experiments were conducted on a single machine equipped with 8
    NVIDIA RTX A6000 GPUs, 96 CPU cores, and 128GB RAM. Discussion on the performance
    metrics is presented below.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 基准实验在一台配备 8 个 NVIDIA RTX A6000 GPU、96 个 CPU 核心和 128GB RAM 的单一机器上进行。下文讨论了性能指标。
- en: 'Information Discovery. As demonstrated in Table [1](#S6.T1 "Table 1 ‣ 6.2 Evaluation
    Results ‣ 6 Experiments ‣ ResearchArena: Benchmarking LLMs’ Ability to Collect
    and Organize Information as Research Agents"), the task of information discovery
    remains challenging for all baseline models. This is illustrated by the Recall@100
    metric, which falls below 0.15 for BM25 and 0.27 for BGE. Moreover, agent baselines
    such as Self-RAG and STORM consistently achieve the lowest rankings, irrespective
    of the retrievers employed. This limitation highlights the critical need for more
    advanced retrieval mechanisms to manage large volumes of documents effectively
    during information discovery.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '信息发现。如表 [1](#S6.T1 "Table 1 ‣ 6.2 Evaluation Results ‣ 6 Experiments ‣ ResearchArena:
    Benchmarking LLMs’ Ability to Collect and Organize Information as Research Agents")
    所示，信息发现任务对所有基准模型仍然具有挑战性。这从 Recall@100 指标中可以看出，BM25 的 Recall@100 低于 0.15，而 BGE
    的 Recall@100 为 0.27。此外，像 Self-RAG 和 STORM 这样的代理基准在使用的检索器无论如何，都始终取得最低排名。这一局限性突显了在信息发现过程中需要更先进的检索机制来有效管理大量文档的关键需求。'
- en: 'Table 1: Baseline performance on discovery task, evaluated with Recall@10,
    Recall@100, Precision@10, and Precision@100, where the retrievers include BM25
    and BGE.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：基准性能在发现任务上进行评估，使用 Recall@10、Recall@100、Precision@10 和 Precision@100，其中检索器包括
    BM25 和 BGE。
- en: '|  | Recall@10 | Recall@100 | Precision@10 | Precision@100 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '|  | Recall@10 | Recall@100 | Precision@10 | Precision@100 |'
- en: '| Baseline | BM25 | BGE | BM25 | BGE | BM25 | BGE | BM25 | BGE |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 基准 | BM25 | BGE | BM25 | BGE | BM25 | BGE | BM25 | BGE |'
- en: '| Title | 0.0424 | 0.1012 | 0.1338 | 0.2697 | 0.0669 | 0.1541 | 0.0286 | 0.0586
    |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| Title | 0.0424 | 0.1012 | 0.1338 | 0.2697 | 0.0669 | 0.1541 | 0.0286 | 0.0586
    |'
- en: '| Zero-Shot | 0.0382 | 0.0832 | 0.1253 | 0.2287 | 0.0602 | 0.1232 | 0.0256
    | 0.0464 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| Zero-Shot | 0.0382 | 0.0832 | 0.1253 | 0.2287 | 0.0602 | 0.1232 | 0.0256
    | 0.0464 |'
- en: '| Decomposer | 0.0434 | 0.0879 | 0.1431 | 0.2554 | 0.0717 | 0.1304 | 0.0312
    | 0.0536 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| Decomposer | 0.0434 | 0.0879 | 0.1431 | 0.2554 | 0.0717 | 0.1304 | 0.0312
    | 0.0536 |'
- en: '| Self-RAG | 0.0380 | 0.0815 | 0.1210 | 0.2260 | 0.0595 | 0.1215 | 0.0256 |
    0.0461 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| Self-RAG | 0.0380 | 0.0815 | 0.1210 | 0.2260 | 0.0595 | 0.1215 | 0.0256 |
    0.0461 |'
- en: '| STORM | 0.0281 | 0.0979 | 0.0693 | 0.1441 | 0.0446 | 0.1041 | 0.0130 | 0.0208
    |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| STORM | 0.0281 | 0.0979 | 0.0693 | 0.1441 | 0.0446 | 0.1041 | 0.0130 | 0.0208
    |'
- en: 'Information Selection. The performance with information selection is presented
    in Table [2](#S6.T2 "Table 2 ‣ 6.2 Evaluation Results ‣ 6 Experiments ‣ ResearchArena:
    Benchmarking LLMs’ Ability to Collect and Organize Information as Research Agents").
    The results indicate a consistent trend wherein agent baselines underperform compared
    to keyword-based methods. The evaluation of nDCG at various levels of document
    retrieval, such as nDCG@10, nDCG@30, and nDCG@100, provides a quantitative assessment
    of the ranking performance. Notably, for the Title method using the BGE retriever,
    the nDCG@100 score is 0.2019, which significantly surpasses the score of STORM,
    which stands at 0.1267\. Improvements during the information discovery phase have
    the potential to enhance overall performance in the selection phase, as evidenced
    by Decomposer, which ranks the second behind Title in discovery and selection
    tasks.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '信息选择。信息选择的性能如表 [2](#S6.T2 "Table 2 ‣ 6.2 Evaluation Results ‣ 6 Experiments
    ‣ ResearchArena: Benchmarking LLMs’ Ability to Collect and Organize Information
    as Research Agents") 所示。结果表明，代理基准相比于基于关键词的方法表现始终较差。对文档检索的不同级别进行的 nDCG 评估，例如 nDCG@10、nDCG@30
    和 nDCG@100，提供了排名性能的定量评估。值得注意的是，对于使用 BGE 检索器的标题方法，nDCG@100 的得分为 0.2019，这显著超过了 STORM
    的得分 0.1267。信息发现阶段的改进有可能提升选择阶段的整体表现，正如 Decomposer 所示，在发现和选择任务中排名第二。'
- en: 'Table 2: Baseline performance on selection task, evaluated with nDCG@10, nDCG@30,
    nDCG@100, and Precision@100, where the retrievers include BM25 and BGE.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：基准性能在选择任务上进行评估，使用 nDCG@10、nDCG@30、nDCG@100 和 Precision@100，其中检索器包括 BM25
    和 BGE。
- en: '|  | nDCG@10 | nDCG@30 | nDCG@100 | MRR |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '|  | nDCG@10 | nDCG@30 | nDCG@100 | MRR |'
- en: '| Baseline | BM25 | BGE | BM25 | BGE | BM25 | BGE | BM25 | BGE |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 基准 | BM25 | BGE | BM25 | BGE | BM25 | BGE | BM25 | BGE |'
- en: '| Title | 0.0711 | 0.1678 | 0.0775 | 0.1754 | 0.0941 | 0.2019 | 0.1903 | 0.3816
    |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| Title | 0.0711 | 0.1678 | 0.0775 | 0.1754 | 0.0941 | 0.2019 | 0.1903 | 0.3816
    |'
- en: '| Zero-Shot | 0.0634 | 0.1346 | 0.0692 | 0.1417 | 0.0856 | 0.1657 | 0.1743
    | 0.3246 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| Zero-Shot | 0.0634 | 0.1346 | 0.0692 | 0.1417 | 0.0856 | 0.1657 | 0.1743
    | 0.3246 |'
- en: '| Decomposer | 0.0735 | 0.1445 | 0.0803 | 0.1554 | 0.0986 | 0.1838 | 0.1959
    | 0.3510 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| Decomposer | 0.0735 | 0.1445 | 0.0803 | 0.1554 | 0.0986 | 0.1838 | 0.1959
    | 0.3510 |'
- en: '| Self-RAG | 0.0627 | 0.1341 | 0.0679 | 0.1415 | 0.0837 | 0.1646 | 0.1705 |
    0.3233 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| Self-RAG | 0.0627 | 0.1341 | 0.0679 | 0.1415 | 0.0837 | 0.1646 | 0.1705 |
    0.3233 |'
- en: '| STORM | 0.0445 | 0.1275 | 0.0507 | 0.1322 | 0.0524 | 0.1267 | 0.1271 | 0.3206
    |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| STORM | 0.0445 | 0.1275 | 0.0507 | 0.1322 | 0.0524 | 0.1267 | 0.1271 | 0.3206
    |'
- en: 'Information Organization. The evaluation on task of information organization
    under intermediate (i.e., with oracle) and end-to-end (i.e., without oracle) conditions
    are documented in Table [3](#S6.T3 "Table 3 ‣ 6.2 Evaluation Results ‣ 6 Experiments
    ‣ ResearchArena: Benchmarking LLMs’ Ability to Collect and Organize Information
    as Research Agents"). Notably, the metrics exhibit discrepancies across each other,
    which contrasts with the uniformity observed in previous discovery and selection
    tasks. This divergence is expected due to the distinct nature of the metrics:
    Heading Soft Recall and Heading Entity Recall assess content similarity, whereas
    Tree Semantic Distance evaluates structural alignment.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '信息组织。在表格[3](#S6.T3 "Table 3 ‣ 6.2 Evaluation Results ‣ 6 Experiments ‣ ResearchArena:
    Benchmarking LLMs’ Ability to Collect and Organize Information as Research Agents")中记录了在中级（即有oracle）和端到端（即没有oracle）条件下信息组织任务的评估。值得注意的是，各个指标之间存在差异，这与先前发现和选择任务中观察到的统一性形成对比。这种分歧是可以预期的，因为这些指标的性质不同：Heading
    Soft Recall和Heading Entity Recall评估内容相似性，而Tree Semantic Distance评估结构对齐。'
- en: In the intermediate version, where references are provided to LLMs, the proportion
    of correctly included entities, as measured by Heading Entity Recall, is slightly
    higher. Specifically, STORM achieved a recall rate of 0.3098, outperforming the
    end-to-end condition. Conversely, when it comes to constructing the hierarchy,
    Clustering outperforms advanced LLM-based agents, as evidenced by its attainment
    of the lowest Tree Semantic Distance of 45.69 among all baseline methods.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在中级版本中，当提供了对LLMs的参考时，Heading Entity Recall测量的正确包含实体的比例略高。具体而言，STORM的召回率达到了0.3098，优于端到端条件。相反，在构建层级时，Clustering优于先进的基于LLM的代理，其在所有基线方法中获得了最低的Tree
    Semantic Distance 45.69。
- en: 'Table 3: Baseline performance on organization task, evaluated with Heading
    Soft Recall, Heading Entity Recall, and Tree Semantic Distance, across intermediate
    and end-to-end conditions.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 表格3：在中级和端到端条件下，基于Heading Soft Recall、Heading Entity Recall和Tree Semantic Distance对组织任务的基线性能评估。
- en: '| Oracle | Baseline | Heading Soft Recall ($\uparrow$) |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| Oracle | Baseline | Heading Soft Recall ($\uparrow$) |'
- en: '| Yes | Clustering | 0.6074 | 0.2104 | 45.69 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| Yes | Clustering | 0.6074 | 0.2104 | 45.69 |'
- en: '| STORM | 0.7325 | 0.3098 | 60.04 |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| STORM | 0.7325 | 0.3098 | 60.04 |'
- en: '| No | Few-Shot | 0.8408 | 0.2446 | 49.83 |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| No | Few-Shot | 0.8408 | 0.2446 | 49.83 |'
- en: '| STORM.BM25 | 0.7940 | 0.2938 | 66.65 |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| STORM.BM25 | 0.7940 | 0.2938 | 66.65 |'
- en: '| STORM.BGE | 0.7842 | 0.2693 | 65.93 |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| STORM.BGE | 0.7842 | 0.2693 | 65.93 |'
- en: 7 Limitation
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 限制
- en: Despite the robust framework and extensive dataset provided by ResearchArena,
    this study has several limitations. Firstly, the offline environment, though comprehensive,
    may not accurately represent the dynamic and interconnected nature of live databases
    and the internet. This discrepancy could potentially limit the applicability of
    the findings in real-world research settings. Additionally, due to copyright constraints,
    not every full-text reference of the survey papers could be included. This omission
    could affect the comprehensive understanding of the survey topics under investigation.
    Finally, there is no evaluation on text generation but mostly the surveying process.
    However, even if this is just the first step of conducting research, LLM agents
    have already shown deficiencies. Future iterations of ResearchArena should address
    this issue, particularly as these agents improve.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管ResearchArena提供了强大的框架和广泛的数据集，但本研究仍有若干限制。首先，尽管离线环境非常全面，但可能无法准确代表实时数据库和互联网的动态和互联特性。这种差异可能会限制研究结果在实际研究环境中的适用性。此外，由于版权限制，并未能包含调查论文的每一篇完整参考文献。这一遗漏可能会影响对调查主题的全面理解。最后，本研究未对文本生成进行评估，而主要集中在调查过程中。然而，即使这是研究的第一步，LLM代理已经显示出不足之处。Future
    ResearchArena iterations 应该解决这一问题，特别是当这些代理逐步改进时。
- en: 8 Conclusion
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 结论
- en: In conclusion, ResearchArena introduces a rigorous benchmark designed to evaluate
    LLMs in conducting research surveys on designated topics. By systematically decomposing
    the survey process into distinct tasks like information discovery, selection,
    and organization, this benchmark provides a detailed framework for evaluating
    autonomus research agents. Our findings underscore the potential of LLMs to revolutionize
    academic research, provided that future advancements can bridge the existing performance
    gaps. Grounded in Semantic Scholar Open Research Corpus, this work establishes
    a robust foundation for the future, aiming to improve the ability of LLMs to autonomously
    conduct expertise-level, domain-specific research.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，ResearchArena 引入了一种严格的基准，旨在评估LLMs在进行指定主题的研究调查时的表现。通过系统地将调查过程分解为信息发现、选择和组织等不同任务，这一基准提供了一个详细的框架，用于评估自主研究代理。我们的研究结果强调了LLMs在学术研究中可能带来的变革潜力，前提是未来的进展能够弥补现有的性能差距。基于
    Semantic Scholar Open Research Corpus，这项工作为未来奠定了坚实的基础，旨在提高LLMs在自主进行专家级、领域特定研究的能力。
- en: References
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu,
    Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, et al.
    Holistic evaluation of language models. arXiv preprint arXiv:2211.09110, 2022.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu,
    Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar等。《语言模型的全面评估》。arXiv预印本
    arXiv:2211.09110, 2022。'
- en: '[2] Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan
    Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, et al. A multitask, multilingual,
    multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity.
    arXiv preprint arXiv:2302.04023, 2023.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan
    Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung等。《对chatgpt在推理、幻觉和互动方面的多任务、多语言、多模态评估》。arXiv预印本
    arXiv:2302.04023, 2023。'
- en: '[3] Chengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao Chen, Michihiro Yasunaga,
    and Diyi Yang. Is chatgpt a general-purpose natural language processing task solver?
    arXiv preprint arXiv:2302.06476, 2023.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Chengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao Chen, Michihiro Yasunaga,
    和 Diyi Yang。《chatgpt是否是通用的自然语言处理任务解决者？》。arXiv预印本 arXiv:2302.06476, 2023。'
- en: '[4] Md Tahmid Rahman Laskar, M Saiful Bari, Mizanur Rahman, Md Amran Hossen
    Bhuiyan, Shafiq Joty, and Jimmy Xiangji Huang. A systematic study and comprehensive
    evaluation of chatgpt on benchmark datasets. arXiv preprint arXiv:2305.18486,
    2023.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Md Tahmid Rahman Laskar, M Saiful Bari, Mizanur Rahman, Md Amran Hossen
    Bhuiyan, Shafiq Joty, 和 Jimmy Xiangji Huang。《对chatgpt在基准数据集上的系统性研究和综合评估》。arXiv预印本
    arXiv:2305.18486, 2023。'
- en: '[5] Opendevin: Code less, make more. [https://github.com/OpenDevin/OpenDevin](https://github.com/OpenDevin/OpenDevin),
    2024.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Opendevin: Code less, make more. [https://github.com/OpenDevin/OpenDevin](https://github.com/OpenDevin/OpenDevin),
    2024。'
- en: '[6] Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar,
    Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, et al. Webarena: A realistic
    web environment for building autonomous agents. arXiv preprint arXiv:2307.13854,
    2023.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar,
    Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon等。《Webarena：构建自主代理的现实网络环境》。arXiv预印本
    arXiv:2307.13854, 2023。'
- en: '[7] Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai
    Lin, Xin Cong, Xiangru Tang, Bill Qian, et al. Toolllm: Facilitating large language
    models to master 16000+ real-world apis. arXiv preprint arXiv:2307.16789, 2023.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai
    Lin, Xin Cong, Xiangru Tang, Bill Qian等。《Toolllm：助力大型语言模型掌握16000+现实世界API》。arXiv预印本
    arXiv:2307.16789, 2023。'
- en: '[8] Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan
    Liu, and Maosong Sun. Communicative agents for software development. arXiv preprint
    arXiv:2307.07924, 2023.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan
    Liu, 和 Maosong Sun。《用于软件开发的沟通型代理》。arXiv预印本 arXiv:2307.07924, 2023。'
- en: '[9] Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu,
    Hangliang Ding, Kaiwen Men, Kejuan Yang, et al. Agentbench: Evaluating llms as
    agents. arXiv preprint arXiv:2308.03688, 2023.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu,
    Hangliang Ding, Kaiwen Men, Kejuan Yang等。《Agentbench：评估LLMs作为代理》。arXiv预印本 arXiv:2308.03688,
    2023。'
- en: '[10] literature review - how to write a survey paper? - academia stack exchange.
    [https://academia.stackexchange.com/questions/43371/how-to-write-a-survey-paper](https://academia.stackexchange.com/questions/43371/how-to-write-a-survey-paper),
    2015.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] 文献综述 - 如何撰写调查论文？ - academia stack exchange。 [https://academia.stackexchange.com/questions/43371/how-to-write-a-survey-paper](https://academia.stackexchange.com/questions/43371/how-to-write-a-survey-paper),
    2015。'
- en: '[11] Laura Dietz and John Foley. Trec car y3: Complex answer retrieval overview.
    In Proceedings of Text REtrieval Conference (TREC), 2019.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Laura Dietz 和 John Foley. Trec car y3：复杂答案检索概述。在文本检索会议（TREC）论文集，2019年。'
- en: '[12] Kyle Lo, Lucy Lu Wang, Mark Neumann, Rodney Kinney, and Dan S Weld. S2orc:
    The semantic scholar open research corpus. arXiv preprint arXiv:1911.02782, 2019.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Kyle Lo、Lucy Lu Wang、Mark Neumann、Rodney Kinney 和 Dan S Weld. S2orc：语义学者开放研究语料库。arXiv
    预印本 arXiv:1911.02782，2019年。'
- en: '[13] Shuaiqi Liu, Jiannong Cao, Ruosong Yang, and Zhiyuan Wen. Generating a
    structured summary of numerous academic papers: Dataset and method. arXiv preprint
    arXiv:2302.04580, 2023.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Shuaiqi Liu、Jiannong Cao、Ruosong Yang 和 Zhiyuan Wen. 生成众多学术论文的结构化摘要：数据集和方法。arXiv
    预印本 arXiv:2302.04580，2023年。'
- en: '[14] Irene Li, Alexander Fabbri, Rina Kawamura, Yixin Liu, Xiangru Tang, Jaesung
    Tae, Chang Shen, Sally Ma, Tomoe Mizutani, and Dragomir Radev. Surfer100: Generating
    surveys from web resources, wikipedia-style. arXiv preprint arXiv:2112.06377,
    2021.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Irene Li、Alexander Fabbri、Rina Kawamura、Yixin Liu、Xiangru Tang、Jaesung
    Tae、Chang Shen、Sally Ma、Tomoe Mizutani 和 Dragomir Radev. Surfer100：从网络资源生成维基百科风格的调查。arXiv
    预印本 arXiv:2112.06377，2021年。'
- en: '[15] Peter J Liu, Mohammad Saleh, Etienne Pot, Ben Goodrich, Ryan Sepassi,
    Lukasz Kaiser, and Noam Shazeer. Generating wikipedia by summarizing long sequences.
    arXiv preprint arXiv:1801.10198, 2018.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Peter J Liu、Mohammad Saleh、Etienne Pot、Ben Goodrich、Ryan Sepassi、Lukasz
    Kaiser 和 Noam Shazeer. 通过总结长序列生成维基百科。arXiv 预印本 arXiv:1801.10198，2018年。'
- en: '[16] Rada Mihalcea and Paul Tarau. Textrank: Bringing order into text. In Proceedings
    of the 2004 conference on empirical methods in natural language processing, pages
    404–411, 2004.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Rada Mihalcea 和 Paul Tarau. Textrank：将秩序带入文本。在《2004年自然语言处理实证方法会议论文集》，第404–411页，2004年。'
- en: '[17] Yijia Shao, Yucheng Jiang, Theodore A Kanell, Peter Xu, Omar Khattab,
    and Monica S Lam. Assisting in writing wikipedia-like articles from scratch with
    large language models. arXiv preprint arXiv:2402.14207, 2024.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Yijia Shao、Yucheng Jiang、Theodore A Kanell、Peter Xu、Omar Khattab 和 Monica
    S Lam. 使用大型语言模型从头开始撰写维基百科风格的文章。arXiv 预印本 arXiv:2402.14207，2024年。'
- en: '[18] Marco Valenzuela, Vu Ha, and Oren Etzioni. Identifying meaningful citations.
    In Workshops at the twenty-ninth AAAI conference on artificial intelligence, 2015.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Marco Valenzuela、Vu Ha 和 Oren Etzioni. 识别有意义的引用。在第二十九届 AAAI 人工智能大会的工作坊，2015年。'
- en: '[19] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi,
    and Graham Neubig. Pre-train, prompt, and predict: A systematic survey of prompting
    methods in natural language processing. ACM Computing Surveys, 55(9):1–35, 2023.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Pengfei Liu、Weizhe Yuan、Jinlan Fu、Zhengbao Jiang、Hiroaki Hayashi 和 Graham
    Neubig. 预训练、提示和预测：自然语言处理中的提示方法系统综述。ACM 计算调查，55(9):1–35，2023年。'
- en: '[20] Kalervo Järvelin and Jaana Kekäläinen. Cumulated gain-based evaluation
    of ir techniques. ACM Transactions on Information Systems (TOIS), 20(4):422–446,
    2002.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Kalervo Järvelin 和 Jaana Kekäläinen. 基于累积增益的 IR 技术评估。ACM 信息系统交易（TOIS），20(4):422–446，2002年。'
- en: '[21] EM Voorhees. Proceedings of the 8th text retrieval conference. TREC-8
    Question Answering Track Report, pages 77–82, 1999.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] EM Voorhees. 第八届文本检索会议论文集。TREC-8 问答轨迹报告，第77–82页，1999年。'
- en: '[22] Pasi Fränti and Radu Mariescu-Istodor. Soft precision and recall. Pattern
    Recognition Letters, 167:115–121, 2023.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Pasi Fränti 和 Radu Mariescu-Istodor. 软精确率和召回率。模式识别快报，167:115–121，2023年。'
- en: '[23] Nils Reimers and Iryna Gurevych. Sentence-BERT: Sentence embeddings using
    Siamese BERT-networks. In Kentaro Inui, Jing Jiang, Vincent Ng, and Xiaojun Wan,
    editors, Proceedings of the 2019 Conference on Empirical Methods in Natural Language
    Processing and the 9th International Joint Conference on Natural Language Processing
    (EMNLP-IJCNLP), pages 3982–3992, Hong Kong, China, November 2019\. Association
    for Computational Linguistics.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] Nils Reimers 和 Iryna Gurevych. Sentence-BERT：使用 Siamese BERT 网络的句子嵌入。在
    Kentaro Inui、Jing Jiang、Vincent Ng 和 Xiaojun Wan 编辑的《2019年自然语言处理实证方法大会与第九届国际联合自然语言处理会议（EMNLP-IJCNLP）论文集》，第3982–3992页，中国香港，2019年11月。计算语言学协会。'
- en: '[24] Alan Akbik, Tanja Bergmann, Duncan Blythe, Kashif Rasul, Stefan Schweter,
    and Roland Vollgraf. FLAIR: An easy-to-use framework for state-of-the-art NLP.
    In Waleed Ammar, Annie Louis, and Nasrin Mostafazadeh, editors, Proceedings of
    the 2019 Conference of the North American Chapter of the Association for Computational
    Linguistics (Demonstrations), pages 54–59, Minneapolis, Minnesota, June 2019\.
    Association for Computational Linguistics.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Alan Akbik, Tanja Bergmann, Duncan Blythe, Kashif Rasul, Stefan Schweter
    和 Roland Vollgraf. FLAIR: 一种易于使用的前沿 NLP 框架。见 Waleed Ammar, Annie Louis 和 Nasrin
    Mostafazadeh 主编，《2019 年北美计算语言学协会年会论文集（演示）》，第 54–59 页, 明尼阿波利斯, 明尼苏达州, 2019年6月。计算语言学协会。'
- en: '[25] Kaizhong Zhang and Dennis Shasha. Simple fast algorithms for the editing
    distance between trees and related problems. SIAM journal on computing, 18(6):1245–1262,
    1989.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Kaizhong Zhang 和 Dennis Shasha. 编辑距离的简单快速算法以及相关问题。SIAM 计算期刊, 18(6):1245–1262,
    1989。'
- en: '[26] Shitao Xiao, Zheng Liu, Peitian Zhang, and Niklas Muennighof. C-pack:
    Packaged resources to advance general chinese embedding. arXiv preprint arXiv:2309.07597,
    2023.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Shitao Xiao, Zheng Liu, Peitian Zhang 和 Niklas Muennighof. C-pack: 打包资源以推进通用中文嵌入。arXiv
    预印本 arXiv:2309.07597, 2023。'
- en: '[27] Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson,
    Peter Clark, and Ashish Sabharwal. Decomposed prompting: A modular approach for
    solving complex tasks. arXiv preprint arXiv:2210.02406, 2022.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson,
    Peter Clark 和 Ashish Sabharwal. 解构提示：解决复杂任务的模块化方法。arXiv 预印本 arXiv:2210.02406,
    2022。'
- en: '[28] Gordon V Cormack, Charles LA Clarke, and Stefan Buettcher. Reciprocal
    rank fusion outperforms condorcet and individual rank learning methods. In Proceedings
    of the 32nd international ACM SIGIR conference on Research and development in
    information retrieval, pages 758–759, 2009.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] Gordon V Cormack, Charles LA Clarke 和 Stefan Buettcher. 递归排名融合优于 Condorcet
    和个体排名学习方法。见《第 32 届国际 ACM SIGIR 信息检索研究与开发会议论文集》，第 758–759 页, 2009。'
- en: '[29] Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and Hannaneh Hajishirzi.
    Self-rag: Learning to retrieve, generate, and critique through self-reflection.
    arXiv preprint arXiv:2310.11511, 2023.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil 和 Hannaneh Hajishirzi.
    Self-rag: 通过自我反思学习检索、生成和批判。arXiv 预印本 arXiv:2310.11511, 2023。'
- en: '[30] Jeff Johnson, Matthijs Douze, and Hervé Jégou. Billion-scale similarity
    search with GPUs. IEEE Transactions on Big Data, 7(3):535–547, 2019.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Jeff Johnson, Matthijs Douze 和 Hervé Jégou. 亿级规模的相似性搜索与 GPU。IEEE 大数据学报,
    7(3):535–547, 2019。'
- en: '[31] Corby Rosset, Ho-Lam Chung, Guanghui Qin, Ethan C Chau, Zhuo Feng, Ahmed
    Awadallah, Jennifer Neville, and Nikhil Rao. Researchy questions: A dataset of
    multi-perspective, decompositional questions for llm web agents. arXiv preprint
    arXiv:2402.17896, 2024.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Corby Rosset, Ho-Lam Chung, Guanghui Qin, Ethan C Chau, Zhuo Feng, Ahmed
    Awadallah, Jennifer Neville 和 Nikhil Rao. Researchy questions: 多视角、分解性问题的数据集用于
    LLM 网页代理。arXiv 预印本 arXiv:2402.17896, 2024。'
- en: Appendix A Parameters with Collection Methodology
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 收集方法学参数
- en: In order to ensure deterministic behavior during dataset construction, the temperature
    is set to 0, and the seed is fixed at 42 when utilizing GPT-4 for chat completions.
    The choice of the number 42 is arbitrary; other numbers could be equally effective,
    provided that the seed remains constant throughout the dataset collection process
    to maintain reproducibility.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保数据集构建期间的确定性行为，使用 GPT-4 进行聊天补全时，将温度设置为 0，种子固定为 42。选择数字 42 是任意的；其他数字也可能同样有效，只要在数据集收集过程中种子保持不变，以确保可重复性。
- en: Appendix B Quality of Collection Methodology
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 收集方法学质量
- en: 'Records of manual inspection over 25 samples from surveys and typologies are
    presented in Table [4](#A2.T4 "Table 4 ‣ Appendix B Quality of Collection Methodology
    ‣ ResearchArena: Benchmarking LLMs’ Ability to Collect and Organize Information
    as Research Agents").'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '手动检查 25 个调查和类型样本的记录见表 [4](#A2.T4 "Table 4 ‣ Appendix B Quality of Collection
    Methodology ‣ ResearchArena: Benchmarking LLMs’ Ability to Collect and Organize
    Information as Research Agents")。'
- en: 'Table 4: Evaluation on the quality of survey selection and mind-map extraction.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '表 4: 调查选择和思维导图提取质量评估。'
- en: '| Corpus ID | Accurate Selection | Corpus ID | Object ID | Accurate Extraction
    | Relevant Extraction |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 语料库 ID | 精确选择 | 语料库 ID | 对象 ID | 精确提取 | 相关提取 |'
- en: '| 1359411 | Yes | 3373610 | 2-Figure1-1.png | Yes | Yes |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 1359411 | 是 | 3373610 | 2-Figure1-1.png | 是 | 是 |'
- en: '| 2197301 | No | 10837932 | 6-TableII-1.png | Yes | Yes |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| 2197301 | 否 | 10837932 | 6-TableII-1.png | 是 | 是 |'
- en: '| 3638888 | Yes | 20774863 | 2-Figure1-1.png | Yes | No |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 3638888 | 是 | 20774863 | 2-Figure1-1.png | 是 | 否 |'
- en: '| 3799929 | Yes | 21265344 | 4-Figure3-1.png | No | No |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 3799929 | 是 | 21265344 | 4-Figure3-1.png | 否 | 否 |'
- en: '| 4470807 | Yes | 52986472 | 4-Figure1-1.png | Yes | Yes |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| 4470807 | 是 | 52986472 | 4-Figure1-1.png | 是 | 是 |'
- en: '| 7972041 | Yes | 54437297 | 6-Figure1-1.png | No | Yes |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| 7972041 | 是 | 54437297 | 6-Figure1-1.png | 否 | 是 |'
- en: '| 44951320 | Yes | 59407515 | 4-Figure1-1.png | Yes | No |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| 44951320 | 是 | 59407515 | 4-Figure1-1.png | 是 | 否 |'
- en: '| 56895486 | Yes | 67855323 | 3-Figure1-1.png | Yes | No |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 56895486 | 是 | 67855323 | 3-Figure1-1.png | 是 | 否 |'
- en: '| 115156611 | Yes | 201532876 | 6-Figure1-1.png | Yes | No |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| 115156611 | 是 | 201532876 | 6-Figure1-1.png | 是 | 否 |'
- en: '| 126187216 | Yes | 204080064 | 5-Figure1-1.png | No | No |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| 126187216 | 是 | 204080064 | 5-Figure1-1.png | 否 | 否 |'
- en: '| 134642625 | Yes | 218487045 | 7-Figure4-1.png | Yes | Yes |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 134642625 | 是 | 218487045 | 7-Figure4-1.png | 是 | 是 |'
- en: '| 209386804 | Yes | 221938634 | 6-Figure1-1.png | Yes | Yes |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 209386804 | 是 | 221938634 | 6-Figure1-1.png | 是 | 是 |'
- en: '| 214566304 | Yes | 226300094 | 2-Figure2-1.png | Yes | Yes |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 214566304 | 是 | 226300094 | 2-Figure2-1.png | 是 | 是 |'
- en: '| 229474407 | Yes | 227259882 | 6-Figure2-1.png | No | Yes |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| 229474407 | 是 | 227259882 | 6-Figure2-1.png | 否 | 是 |'
- en: '| 233241600 | No | 232126642 | 3-Figure1-1.png | Yes | No |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 233241600 | 否 | 232126642 | 3-Figure1-1.png | 是 | 否 |'
- en: '| 234790465 | Yes | 233677020 | 6-Figure2-1.png | No | No |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| 234790465 | 是 | 233677020 | 6-Figure2-1.png | 否 | 否 |'
- en: '| 235794880 | Yes | 237291802 | 2-Figure1-1.png | Yes | Yes |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| 235794880 | 是 | 237291802 | 2-Figure1-1.png | 是 | 是 |'
- en: '| 245433612 | Yes | 237327839 | 6-Figure1-1.png | Yes | No |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| 245433612 | 是 | 237327839 | 6-Figure1-1.png | 是 | 否 |'
- en: '| 253735066 | Yes | 240011970 | 5-Figure4-1.png | Yes | Yes |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| 253735066 | 是 | 240011970 | 5-Figure4-1.png | 是 | 是 |'
- en: '| 254563889 | Yes | 246599122 | 2-Figure1-1.png | Yes | No |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| 254563889 | 是 | 246599122 | 2-Figure1-1.png | 是 | 否 |'
- en: '| 258060212 | Yes | 248227736 | 2-Figure1-1.png | Yes | Yes |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| 258060212 | 是 | 248227736 | 2-Figure1-1.png | 是 | 是 |'
- en: '| 258541526 | Yes | 248717714 | 4-Figure2-1.png | Yes | Yes |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| 258541526 | 是 | 248717714 | 4-Figure2-1.png | 是 | 是 |'
- en: '| 258841314 | Yes | 252089272 | 4-Figure1-1.png | Yes | Yes |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| 258841314 | 是 | 252089272 | 4-Figure1-1.png | 是 | 是 |'
- en: '| 259855591 | Yes | 258212628 | 6-Figure1-1.png | Yes | Yes |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| 259855591 | 是 | 258212628 | 6-Figure1-1.png | 是 | 是 |'
- en: '| 262464721 | Yes | 260887757 | 4-Figure2-1.png | Yes | Yes |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| 262464721 | 是 | 260887757 | 4-Figure2-1.png | 是 | 是 |'
- en: Appendix C Prompts with Experiments
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 C 实验提示
- en: C.1 Prompt to Decomposer for Information Discovery
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.1 信息发现的分解器提示
- en: Adopted from the Researchy Questions by Rosset et al. [[31](#bib.bib31)].
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 摘自 Rosset 等人的研究问题 [[31](#bib.bib31)]。
- en: '"""###  Below  is  an  example  on  how  to  decompose  a  complex  question  into  sub-questions  and  search  queries.Question:  should  the  death  penalty  be  legalized?-  What  are  the  arguments  in  favor  of  the  death  penalty?-  Does  the  death  penalty  serve  as  a  deterrent  to  crime?-  Is  the  death  penalty  a  just  punishment  for  certain  crimes?-  How  does  the  death  penalty  compare  to  other  forms  of  punishment  in  terms  of  cost  and  effectiveness?-  What  are  the  arguments  against  the  death  penalty?-  What  is  the  risk  of  executing  innocent  people  with  a  death  penalty?-  Are  there  any  ethical  concerns  surrounding  the  death  penalty?-  To  what  extent  is  the  death  penalty  applied  fairly  and  without  bias?-  In  practice,  how  expensive  is  the  death  penalty?-  What  is  the  current  legal  status  of  the  death  penalty  in  various  jurisdictions?-  In  which  countries  or  states  is  the  death  penalty  currently  legal?-  What  are  the  trends  in  death  penalty  legislation  and  public  opinion?-  What  are  the  alternatives  to  the  death  penalty?-  How  effective  are  alternative  punishments  to  the  death  penalty,  e.g.  life  imprisonment?-  What  are  the  costs  and  benefits  of  alternatives  to  the  death  penalty?-  How  do  the  pros  and  cons  of  the  death  penalty  compare  to  its  alternatives?-  arguments  in  favor  of  the  death  penalty-  death  penalty  as  a  deterrent  to  crime-  death  penalty  as  a  just  punishment-  death  penalty  cost  and  effectiveness  comparison-  arguments  against  the  death  penalty-  risk  of  executing  innocent  people  with  death  penalty-  ethical  concerns  surrounding  the  death  penalty-  fairness  and  bias  in  death  penalty  application-  current  legal  status  of  the  death  penalty  worldwide-  trends  in  death  penalty  legislation  and  public  opinion-  alternatives  to  the  death  penalty-  effectiveness  of  life  imprisonment  without  parole-  costs  and  benefits  of  death  penalty  alternativesQuestion:  {x}###  Instructions:1.  What  sub-questions  do  I  need  to  know  in  order  to  fully  understand  and  answer  the  above  Question.-  Format  your  response  as  a  bullet-point  style  outline  of  questions  and  sub-questions  in  the    tag.-  Order  your  sub-questions  such  that  one  question  comes  after  another  if  it  needs  to  use  the  answer  to  the  previous  one.-  Do  not  ask  unnecessary  or  tangential  sub-questions,  only  those  that  are  critical  to  finding  important  information.2)  Next,  write  a  list  of  search  queries  that  would  likely  lead  to  results  addressing  all  the  sub-questions.-  Enumerate  your  queries  in  a  bullet-point  style  list  inside  the    tag.You  may  refer  to  the  example  above  for  guidance."""'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '"""### 以下是如何将复杂问题分解为子问题和搜索查询的示例。问题：死刑是否应该合法化？-  支持死刑的论点是什么？-  死刑是否能有效威慑犯罪？-  死刑是否是对某些罪行的公正惩罚？-  就成本和效果而言，死刑与其他惩罚形式相比如何？-  反对死刑的论点是什么？-  死刑执行无辜者的风险有多大？-  死刑是否存在伦理问题？-  死刑的实施是否公平且无偏见？-  实际上，死刑的成本有多高？-  各个司法管辖区对死刑的当前法律状态如何？-  哪些国家或州目前合法化了死刑？-  死刑立法和公众舆论的趋势是什么？-  死刑的替代方案有哪些？-  替代惩罚（如无期徒刑）的效果如何？-  死刑替代方案的成本和收益如何？-  死刑的利弊与其替代方案相比如何？-  支持死刑的论点-  死刑是否能有效威慑犯罪-  死刑是否是公正惩罚-  死刑的成本和效果比较-  反对死刑的论点-  死刑执行无辜者的风险-  死刑的伦理问题-  死刑实施的公平性和偏见-  死刑的当前法律状态-  死刑立法和公众舆论的趋势-  死刑的替代方案-  无期徒刑的效果-  死刑替代方案的成本和收益问题：{x}###
    指示：1. 我需要了解哪些子问题才能充分理解和回答上述问题。-  将您的回答格式化为标签中的项目符号样式大纲。-  按顺序排列您的子问题，以便一个问题在需要使用前一个问题的答案时出现在另一个问题之后。-  不要提出不必要或偏离主题的子问题，只提出对找到重要信息至关重要的子问题。2)
    接下来，写一个搜索查询列表，这些查询可能会导致解决所有子问题的结果。-  在标签中以项目符号样式列出您的查询。您可以参考上述示例进行指导。"""'
- en: C.2 Prompt to Zero-Shot / Self-RAG for Information Discovery
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.2 从零示例 / 自我RAG生成信息发现提示
- en: 'Create  a  search  query  that  gathers  supporting  materials  for  writing  a  survey  paper  on  the  following  topic:  {x}.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个搜索查询，以收集撰写关于以下主题的调查论文所需的支持材料：{x}。
- en: C.3 Prompt to Few-Shot for Information Organization
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.3 从少量示例生成信息组织提示
- en: '"""###  ExamplesA  Survey  on  LiDAR  Scanning  Mechanisms{"Opto-Mechanical  Beam  Deflection  Mechanisms":  {"Line  Scanner":  {"Slanted  Plain  Mirror":  null,  "Off-axis  Parabolic  Mirror":  null,  "Polygon  Mirror":  null},  "Area  Scanner":  {"Single  Galvanometer  Scanning  Mirror":  null,  "Double  Galvanometer  Scanning  Mirror":  null,  "Gyroscopic  Mirror":  null,  "Risley  Scanner":  null}}}A  Survey  on  Large  Language  Models  for  Recommendation{"LLM4Rec":  {"Discriminative  LLM4Rec":  {"Fine-tuning":  {"Prompt  Tuning":  null}},  "Generative  LLM4Rec":  {"Non-tuning":  {"Prompting":  null,  "In-context  Learning":  null},  "Tuning":  {"Fine-tuning":  null,  "Prompt  Tuning":  null,  "Instruction  Tuning":  null}}}}###  Instructions-  Provided  a  topic,  your  task  is  to  construct  a  mind-map  style  typology  that  presents  a  systematic  understanding  of  the  topic.-  Put  your  JSON-encoded  response  in  the  tag  ‘...‘.  You  may  refer  to  the  examples  above  for  guidance.{x}"""'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '"""###  示例关于LiDAR扫描机制的调查{"光学-机械束偏转机制":  {"线扫描仪":  {"倾斜平面镜":  null,  "离轴抛物面镜":  null,  "多面镜":  null},  "区域扫描仪":  {"单光圈扫描镜":  null,  "双光圈扫描镜":  null,  "陀螺镜":  null,  "Risley扫描仪":  null}}}关于用于推荐的大型语言模型的调查{"LLM4Rec":  {"区分性LLM4Rec":  {"微调":  {"提示微调":  null}},  "生成性LLM4Rec":  {"非微调":  {"提示":  null,  "上下文学习":  null},  "微调":  {"微调":  null,  "提示微调":  null,  "指令微调":  null}}}}###  说明-  给定一个主题，你的任务是构建一个思维导图风格的类别结构，以呈现对该主题的系统理解。-  将你的JSON编码响应放在标签‘...’中。你可以参考上述示例以获得指导。{x}"""'
