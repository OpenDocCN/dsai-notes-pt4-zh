- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 18:42:42'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:42:42
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'CAMON: Cooperative Agents for Multi-Object Navigation with LLM-based Conversations'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'CAMON: 基于大语言模型对话的多目标导航合作代理'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2407.00632](https://ar5iv.labs.arxiv.org/html/2407.00632)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2407.00632](https://ar5iv.labs.arxiv.org/html/2407.00632)
- en: Pengying Wu, Yao Mu, Kangjie Zhou, Ji Ma, Junting Chen, Chang Liu
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 吴鹏英，穆瑶，周康杰，马骥，陈俊廷，刘畅
- en: Abstract
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Visual navigation tasks are critical for household service robots. As these
    tasks become increasingly complex, effective communication and collaboration among
    multiple robots become imperative to ensure successful completion. In recent years,
    large language models (LLMs) have exhibited remarkable comprehension and planning
    abilities in the context of embodied agents. However, their application in household
    scenarios, specifically in the use of multiple agents collaborating to complete
    complex navigation tasks through communication, remains unexplored. Therefore,
    this paper proposes a framework for decentralized multi-agent navigation, leveraging
    LLM-enabled communication and collaboration. By designing the communication-triggered
    dynamic leadership organization structure, we achieve faster team consensus with
    fewer communication instances, leading to better navigation effectiveness and
    collaborative exploration efficiency. With the proposed novel communication scheme,
    our framework promises to be conflict-free and robust in multi-object navigation
    tasks, even when there is a surge in team size.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉导航任务对家庭服务机器人至关重要。随着这些任务变得越来越复杂，多机器人之间的有效沟通和协作变得至关重要，以确保任务的成功完成。近年来，大语言模型（LLMs）在具身代理的上下文中表现出了显著的理解和规划能力。然而，它们在家庭场景中的应用，特别是多个代理通过沟通协作完成复杂导航任务的应用，仍未被探索。因此，本文提出了一种去中心化的多代理导航框架，利用
    LLM 启用的沟通和协作。通过设计沟通触发的动态领导组织结构，我们在减少沟通实例的情况下实现了更快的团队共识，从而提高了导航效果和协作探索效率。凭借提出的新颖沟通方案，我们的框架在多目标导航任务中承诺无冲突且具有强大的鲁棒性，即使团队规模激增。
- en: I Introduction
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I 引言
- en: '![Refer to caption](img/1fcc5a9422cc4124d48cb97778ee0ee0.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/1fcc5a9422cc4124d48cb97778ee0ee0.png)'
- en: 'Figure 1: We contribute CAMON: a framework for Cooperative Multi-Object Navigation
    in indoor Environments. This figure shows three agents collaborating to find some
    objects, and the dialog box represents the agents’ conversation contents. In CAMON,
    the agents make decisions that do not conflict with other robots and maximize
    team collaboration benefits by asking their current leaders.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：我们贡献了 CAMON：一个用于室内环境中的多目标导航合作框架。此图展示了三个代理协作寻找一些物体，且对话框表示代理之间的对话内容。在 CAMON
    中，代理通过询问当前的领导者来做出不会与其他机器人冲突的决策，并最大化团队合作的利益。
- en: In recent years, household visual navigation utilizing the large language model
    (LLM) has advanced rapidly. Previous methods [[41](#bib.bib41), [12](#bib.bib12),
    [27](#bib.bib27), [4](#bib.bib4), [8](#bib.bib8)] have leveraged LLMs as scene-understanding
    tools and planners, yielding promising application results. However, these approaches
    are constrained to single-agent navigation and do not offer viable solutions for
    effective communication and collaborative planning among multiple agents [[34](#bib.bib34)].
    When tasked with searching for and locating various objects within a household
    environment, such complex tasks pose significant challenges for a single robot,
    leading to low efficiency and high failure rates. In multi-object navigation scenarios
    [[30](#bib.bib30), [22](#bib.bib22), [14](#bib.bib14)], it is essential for multiple
    robots to collaborate to accomplish these tasks effectively.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，利用大语言模型（LLM）的家庭视觉导航迅速发展。以前的方法 [[41](#bib.bib41)，[12](#bib.bib12)，[27](#bib.bib27)，[4](#bib.bib4)，[8](#bib.bib8)]
    利用 LLM 作为场景理解工具和规划器，取得了有前景的应用结果。然而，这些方法局限于单代理导航，未能提供多代理之间有效沟通和协作规划的可行解决方案 [[34](#bib.bib34)]。当任务是搜索和定位家庭环境中的各种物体时，这些复杂任务对单个机器人提出了重大挑战，导致效率低下和失败率高。在多目标导航场景
    [[30](#bib.bib30)，[22](#bib.bib22)，[14](#bib.bib14)] 中，多台机器人协作完成这些任务是至关重要的。
- en: 'Successfully completing multi-agent tasks necessitates a team possessing three
    key abilities: (1) extracting useful information from observations, i.e., determining
    the content of communication, (2) a conflict-free communication mechanism, i.e.,
    identifying with whom to communicate, (3) a global planning capability, i.e.,
    planning after communication. To achieve these abilities, we have designed a novel
    framework specifically designed for multi-agent navigation, and the effect is
    shown in Figure [1](#S1.F1 "Figure 1 ‣ I Introduction ‣ CAMON: Cooperative Agents
    for Multi-Object Navigation with LLM-based Conversations"). This method achieves
    cooperative multi-target tasks through structured scene descriptions and ordered
    communication mechanisms.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '成功完成多智能体任务需要团队具备三个关键能力：(1) 从观察中提取有用信息，即确定沟通内容，(2) 无冲突的沟通机制，即确定与谁沟通，(3) 全局规划能力，即在沟通后进行规划。为了实现这些能力，我们设计了一个专门针对多智能体导航的创新框架，效果如图[1](#S1.F1
    "Figure 1 ‣ I Introduction ‣ CAMON: Cooperative Agents for Multi-Object Navigation
    with LLM-based Conversations")所示。这种方法通过结构化场景描述和有序的沟通机制实现了协作多目标任务。'
- en: To logically organize and summarize observations, we focus on the layout patterns
    of indoor scenes, where the placement of objects in household environments is
    often related to the properties of the room [[28](#bib.bib28)]. For example, a
    room with a bed is typically a bedroom, where pillows, televisions, and similar
    items are commonly found, while toilets and microwaves are not. Therefore, we
    advocate this motivation of object-room relationships in navigation representations,
    dividing the observed scene into individual rooms and generating descriptions
    of each room for subsequent communication for task division. For instance, upon
    entering a room and identifying it as a living area based on its layout, a robot
    should promptly locate and exclusively find all potential targets within that
    space. To ensure efficient team collaboration, other robots should avoid entering
    rooms identified as living areas upon detection.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了逻辑地组织和总结观察结果，我们重点关注室内场景的布局模式，其中家庭环境中物体的摆放通常与房间的属性相关[[28](#bib.bib28)]。例如，配有床的房间通常是卧室，常见枕头、电视等物品，而厕所和微波炉则不常见。因此，我们主张在导航表示中考虑物体-房间关系，将观察到的场景划分为单独的房间，并为每个房间生成描述，以便后续任务分配时进行沟通。例如，进入一个房间并根据其布局将其识别为生活区后，机器人应迅速在该空间内定位并仅寻找所有潜在目标。为了确保团队协作的高效性，其他机器人在检测到生活区后应避免进入这些房间。
- en: 'In multi-agent embodied tasks, the organizational structure of the team is
    crucial [[7](#bib.bib7), [15](#bib.bib15)]. Prior research [[10](#bib.bib10)]
    indicates that leadership-based communication patterns expedite consensus achievement,
    whereas dynamic leadership allocation further enhances team coordination and effectiveness
    [[15](#bib.bib15)]. To establish an efficient and stable communication system,
    we designed a comm-triggered¹¹1”comm” is short for ”communication” in this paper.
    dynamic leadership model as an advanced form of decentralized communication. Our
    contributions can be summarized as follows ²²2This work is in progress.:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在多智能体具身任务中，团队的组织结构至关重要[[7](#bib.bib7), [15](#bib.bib15)]。先前的研究[[10](#bib.bib10)]表明，基于领导的沟通模式加快了共识的达成，而动态领导分配进一步提高了团队的协调性和有效性[[15](#bib.bib15)]。为了建立一个高效而稳定的沟通系统，我们设计了一个以沟通触发为基础的动态领导模型，作为去中心化沟通的高级形式。我们的贡献可以总结如下²²2此项工作正在进行中。
- en: •
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We have designed a comprehensive framework for multi-agent navigation tasks
    utilizing LLMs, encompassing modules for perception, communication, and cooperative
    planning.
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们设计了一个综合框架，用于利用LLM进行多智能体导航任务，涵盖了感知、沟通和协作规划模块。
- en: •
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Our proposed multi-agent communication mechanism facilitates adaptive task division
    and planning for complex navigation tasks.
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出的多智能体沟通机制有助于适应性任务分配和复杂导航任务的规划。
- en: •
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We have developed a dynamic leadership mechanism, activated by agents’ communication
    requests, that facilitates the distribution of information exchange workload in
    distributed systems.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们开发了一个动态领导机制，由智能体的沟通请求激活，以促进分布式系统中信息交换工作负荷的分配。
- en: II Related Work
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 相关工作
- en: II-A Visual Object Navigation
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-A 视觉对象导航
- en: 'Target object navigation necessitates that robots swiftly locate and approach
    the target object in an unfamiliar environment. Recent research in this field
    has primarily branched into two mainstream approaches: end-to-end network model-based
    frameworks [[3](#bib.bib3), [20](#bib.bib20), [23](#bib.bib23), [39](#bib.bib39),
    [6](#bib.bib6), [13](#bib.bib13), [4](#bib.bib4)] and modular map-based frameworks
    [[24](#bib.bib24), [5](#bib.bib5), [9](#bib.bib9), [41](#bib.bib41), [35](#bib.bib35),
    [27](#bib.bib27), [32](#bib.bib32), [28](#bib.bib28), [19](#bib.bib19)]. End-to-end
    model-based methods exhibit good transferability but are relatively ineffective
    in navigation efficiency and task success rates [[5](#bib.bib5)]. Conversely,
    the modular approach, guided by hierarchical maps, requires meticulously designed
    modules, enabling highly effective navigation. With the increasing complexity
    of object-finding tasks, multi-object navigation (MultiON) tasks [[30](#bib.bib30)]
    and methods [[25](#bib.bib25), [22](#bib.bib22), [36](#bib.bib36)] have emerged
    as advanced versions of single-target object navigation. However, existing methods
    for MultiON predominantly address pre-sequenced MultiON, where the robot receives
    a predefined sequence for exploring target object classes. To demonstrate the
    flexibility of the task and the adaptive planning capability of the proposed framework,
    we adopt the Sequence Agnostic MultiON (SAM) [[14](#bib.bib14)] task for evaluation.
    In this approach, the robot neither receives nor is required to follow a global
    order for locating and navigating to instances of target object classes. Instead,
    the robot explores probable locations of the target objects and dynamically adapts
    its exploration based on observations.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 目标物体导航要求机器人在陌生环境中迅速定位并接近目标物体。该领域的最新研究主要分为两种主流方法：基于端到端网络模型的框架[[3](#bib.bib3),
    [20](#bib.bib20), [23](#bib.bib23), [39](#bib.bib39), [6](#bib.bib6), [13](#bib.bib13),
    [4](#bib.bib4)]和基于模块化地图的框架[[24](#bib.bib24), [5](#bib.bib5), [9](#bib.bib9), [41](#bib.bib41),
    [35](#bib.bib35), [27](#bib.bib27), [32](#bib.bib32), [28](#bib.bib28), [19](#bib.bib19)]。基于端到端模型的方法表现出良好的迁移性，但在导航效率和任务成功率方面相对较低[[5](#bib.bib5)]。相反，基于层次地图的模块化方法需要精心设计的模块，能够实现高度有效的导航。随着物体查找任务复杂性的增加，多物体导航（MultiON）任务[[30](#bib.bib30)]和方法[[25](#bib.bib25),
    [22](#bib.bib22), [36](#bib.bib36)]已经成为单一目标物体导航的高级版本。然而，现有的MultiON方法主要处理预先排序的MultiON，其中机器人接收一个预定义的顺序来探索目标物体类别。为了展示任务的灵活性和所提框架的适应性规划能力，我们采用了序列无关MultiON（SAM）[[14](#bib.bib14)]任务进行评估。在这种方法中，机器人既不接收也不需要遵循一个全局顺序来定位和导航到目标物体类别的实例。相反，机器人探索目标物体的可能位置，并根据观察动态调整其探索策略。
- en: II-B LLM-Based Cooperative Embodied Agents
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-B 基于LLM的协作体现智能体
- en: 'Recent work [[21](#bib.bib21), [38](#bib.bib38), [37](#bib.bib37)] has demonstrated
    the feasibility of inputting observation in linguistic form into large language
    models for communication and decision-making in Multi-Agent Systems (MAS). Most
    of the work is structured in a hierarchical manner to ensure the proper functioning
    of MAS. The mainstream LLM-based multi-agent planning frameworks are divided into
    two major branches: centralized [[40](#bib.bib40), [2](#bib.bib2), [34](#bib.bib34),
    [10](#bib.bib10)] and decentralized [[10](#bib.bib10), [18](#bib.bib18), [38](#bib.bib38),
    [33](#bib.bib33), [29](#bib.bib29)].'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究[[21](#bib.bib21), [38](#bib.bib38), [37](#bib.bib37)]已经展示了将观察以语言形式输入大语言模型以进行多智能体系统（MAS）的通信和决策的可行性。这些研究大多以层次结构的方式进行，以确保MAS的正常运作。主流的基于LLM的多智能体规划框架分为两个主要分支：集中式[[40](#bib.bib40),
    [2](#bib.bib2), [34](#bib.bib34), [10](#bib.bib10)]和分散式[[10](#bib.bib10), [18](#bib.bib18),
    [38](#bib.bib38), [33](#bib.bib33), [29](#bib.bib29)]。
- en: In the centralized organization, the LLMs comprehend the observations, history,
    and task progress of multiple agents, and collaboratively allocate tasks to each
    robot group [[40](#bib.bib40)] or individual [[2](#bib.bib2), [34](#bib.bib34)].
    Specifically, Yu et al. [[34](#bib.bib34)] implement a centralized multi-agent
    navigation framework, extracting frontier information and semantic information
    from the map, and utilizing LLMs to allocate exploratory areas for each robot.
    Such frameworks achieve good coordination and planning performance in small-scale
    groups. However, as the team size scales up, the communication and information
    processing burden of centralized leadership increases, posing challenges to reasonable
    and seasonable planning [[10](#bib.bib10)].
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在集中式组织中，LLMs 理解多个代理的观察结果、历史记录和任务进展，并协同分配任务给每个机器人组 [[40](#bib.bib40)] 或个人 [[2](#bib.bib2),
    [34](#bib.bib34)]。具体而言，Yu 等 [[34](#bib.bib34)] 实现了一个集中式的多代理导航框架，从地图中提取前沿信息和语义信息，并利用
    LLMs 为每个机器人分配探索区域。这些框架在小规模组中取得了良好的协调和规划表现。然而，随着团队规模的扩大，集中领导的沟通和信息处理负担增加，这对合理和及时的规划提出了挑战
    [[10](#bib.bib10)]。
- en: 'In decentralized systems, each robot acts as an independent entity with self-autonomy,
    exchanging historical observations through human-like verbal communication and
    making adaptive decisions [[33](#bib.bib33)]. In particular, Zhang et al. [[38](#bib.bib38)]
    provide a systematic template for decentralized communication and collaboration.
    This method categorizes each agent’s execution in the MAS into five modules: observation,
    belief, communication, reasoning, and planning, with the LLMs facilitating inter-agent
    communication and reasoning.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在去中心化系统中，每个机器人作为一个独立实体具有自我自治，通过类人语言交流历史观察结果，并做出适应性决策 [[33](#bib.bib33)]。特别是，Zhang
    等 [[38](#bib.bib38)] 提供了一种去中心化沟通和协作的系统模板。该方法将每个代理在 MAS 中的执行分为五个模块：观察、信念、沟通、推理和规划，并由
    LLMs 促进代理之间的沟通和推理。
- en: II-C Multi-Agent Organizational Structures
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-C 多代理组织结构
- en: Recent studies have delved into the impact of organizational structures among
    multiple agents on task division, planning conflicts, and communication costs
    in embodied tasks. Through experiments, Chen et al. [[10](#bib.bib10)] demonstrate
    that a hierarchical organizational structure with leadership significantly outperforms
    the original decentralized and centralized structures in terms of effectiveness.
    Chen et al. [[7](#bib.bib7)] also analyze the communication patterns among multiple
    agents and have validated that a leader-organized framework achieves faster task
    convergence through a simple task of multiple agents moving to a common point.
    Guo et al. [[15](#bib.bib15)] further investigate the organizational forms of
    leaders and have concluded that dynamic leaders are the most effective in multi-agent
    collaboration. However, the scheme proposed by [[15](#bib.bib15)] assigns leaders
    based on the importance of the tasks performed by each robot, which does not work
    well when tasks are equally important. Here, we propose a comm-triggered dynamic
    leader strategy that can perform well in MultiON tasks.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究已经*深入探讨*了多代理之间的组织结构对任务分配、规划冲突和沟通成本的影响。通过实验，Chen 等 [[10](#bib.bib10)] 证明了具有领导的层级组织结构在效果上显著优于原始的去中心化和集中式结构。Chen
    等 [[7](#bib.bib7)] 还分析了多个代理之间的沟通模式，并验证了一个领导组织的框架通过多个代理移动到共同点的简单任务实现了更快的任务收敛。Guo
    等 [[15](#bib.bib15)] 进一步调查了领导者的组织形式，并得出结论，动态领导者在多代理协作中最为有效。然而，[[15](#bib.bib15)]
    提出的方案是基于每个机器人执行任务的重要性来分配领导者，当任务同样重要时，这种方案效果不佳。在这里，我们提出了一种基于通信触发的动态领导者策略，它可以在 MultiON
    任务中表现良好。
- en: III Problem Setup
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III 问题设置
- en: We consider having multiple collaborative robots participate in MultiON tasks,
    where they jointly explore and approach target objects in indoor environments.
    At the beginning of each episode, two or more robots are randomly placed in an
    unfamiliar environment and tasked with searching for a common set of target objects
    $G=\{g_{1},g_{2},\ldots,g_{m}\}$. The robots have neither been trained to find
    these objects nor have prior information about similar scenes. They must coordinate
    their exploration and locate the targets as quickly as possible using general
    knowledge and common sense. Through communication, the robots can collaborate
    to understand the scene, divide tasks, and navigate to the target objects’ locations
    efficiently.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们考虑让多个协作机器人参与MultiON任务，它们在室内环境中共同探索和接近目标物体。在每个回合开始时，两个或更多机器人会被随机放置在一个陌生的环境中，并被分配寻找一组共同的目标物体$G=\{g_{1},g_{2},\ldots,g_{m}\}$。这些机器人既没有接受过寻找这些物体的训练，也没有类似场景的先验信息。它们必须协调探索，利用一般知识和常识尽快定位目标。通过通信，机器人可以协作理解场景，分配任务，并有效地导航到目标物体的位置。
- en: When a robot correctly recognizes and approaches a target object $g_{t}\in G$,
    the sub-task is considered successful. Conversely, if a robot navigates to the
    wrong object, the sub-task is considered a failure. Regardless of success or failure,
    the robot will continue searching for the remaining objects. Additionally, the
    episode ends if all robots reach the maximum step limit to avoid endless movement.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当机器人正确识别并接近目标物体$g_{t}\in G$时，该子任务被视为成功。相反，如果机器人导航到错误的物体，则该子任务被视为失败。无论成功还是失败，机器人将继续寻找剩余的物体。此外，如果所有机器人达到最大步数限制，回合将结束，以避免无限移动。
- en: '![Refer to caption](img/0ec39810d68294879b3fcb636a146aa1.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/0ec39810d68294879b3fcb636a146aa1.png)'
- en: 'Figure 2: Components of CAMON. Our framework comprises three modules: perception,
    communication, and control. The perception module generates a real-time semantic
    map using robot RGB-D and pose inputs, from which the agent extracts topology
    maps, and segments and describes rooms. Agent_1 makes global decisions by querying
    the current leader, Agent_2, to obtain the target room. Leadership and global
    information are then conveyed from Agent_2 to Agent_1\. Finally, the control module
    generates a sequence of actions for the Agent_1 to navigate from its current position
    to the target room.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：CAMON的组件。我们的框架包含三个模块：感知、通信和控制。感知模块利用机器人RGB-D和姿态输入生成实时语义地图，从中提取拓扑地图，并对房间进行分割和描述。Agent_1通过查询当前领导者Agent_2来做出全局决策，获取目标房间。领导权和全局信息从Agent_2传递给Agent_1。最后，控制模块为Agent_1生成一系列动作，以便其从当前位置导航到目标房间。
- en: IV CAMON Approach
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV CAMON方法
- en: 'The key concept of CAMON is to present a comprehensive framework for completing
    multi-agent navigation tasks through LLM communication and planning. As shown
    in Figure [2](#S3.F2 "Figure 2 ‣ III Problem Setup ‣ CAMON: Cooperative Agents
    for Multi-Object Navigation with LLM-based Conversations"), the central technical
    approach is as follows: (1) In the perception module that understands and describes
    observed scenes ([IV-A](#S4.SS1 "IV-A Perception Module ‣ IV CAMON Approach ‣
    CAMON: Cooperative Agents for Multi-Object Navigation with LLM-based Conversations")),
    each robot maintains a local map ([IV-A1](#S4.SS1.SSS1 "IV-A1 Map Construction
    ‣ IV-A Perception Module ‣ IV CAMON Approach ‣ CAMON: Cooperative Agents for Multi-Object
    Navigation with LLM-based Conversations")), divides the map into room levels,
    extracts the most relevant historical image frames for each room, uses large multimodal
    models (GPT-4o) to interpret these image frames, and generates language descriptions
    of the observed scenes ([IV-A2](#S4.SS1.SSS2 "IV-A2 Room Description ‣ IV-A Perception
    Module ‣ IV CAMON Approach ‣ CAMON: Cooperative Agents for Multi-Object Navigation
    with LLM-based Conversations")). (2) In the comm module that undertakes communication
    and decision-making ([IV-B](#S4.SS2 "IV-B Planning Module ‣ IV CAMON Approach
    ‣ CAMON: Cooperative Agents for Multi-Object Navigation with LLM-based Conversations")),
    we employ a sequential and dynamic leader-member communication structure, where
    the leader adjusts the decision-making proposals ([IV-B2](#S4.SS2.SSS2 "IV-B2
    Agent Asks for Help ‣ IV-B Planning Module ‣ IV CAMON Approach ‣ CAMON: Cooperative
    Agents for Multi-Object Navigation with LLM-based Conversations")) of the agent
    and ensures team coordination ([IV-B3](#S4.SS2.SSS3 "IV-B3 Leader’s Coordination
    of Teamwork ‣ IV-B Planning Module ‣ IV CAMON Approach ‣ CAMON: Cooperative Agents
    for Multi-Object Navigation with LLM-based Conversations")). By making decisions
    during communication, the member will be assigned the responsibility of finding
    specific objects and will select the next referenced target room from the leader.
    (3) At the path planning level ([IV-C](#S4.SS3 "IV-C Motion Planning ‣ IV CAMON
    Approach ‣ CAMON: Cooperative Agents for Multi-Object Navigation with LLM-based
    Conversations")), we plan a sequence of waypoints on the map based on the current
    location and target room, generating discrete actions.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 'CAMON的关键概念是通过LLM通信和规划提供一个完整的框架来完成多智能体导航任务。如图[2](#S3.F2 "Figure 2 ‣ III Problem
    Setup ‣ CAMON: Cooperative Agents for Multi-Object Navigation with LLM-based Conversations")所示，中心技术方法如下：（1）在理解和描述观察场景的感知模块([IV-A](#S4.SS1
    "IV-A Perception Module ‣ IV CAMON Approach ‣ CAMON: Cooperative Agents for Multi-Object
    Navigation with LLM-based Conversations"))中，每个机器人维护一个本地地图([IV-A1](#S4.SS1.SSS1
    "IV-A1 Map Construction ‣ IV-A Perception Module ‣ IV CAMON Approach ‣ CAMON:
    Cooperative Agents for Multi-Object Navigation with LLM-based Conversations"))，将地图划分为房间层次，为每个房间提取最相关的历史图像帧，使用大型多模态模型（GPT-4o）来解释这些图像帧，并生成观察场景的语言描述([IV-A2](#S4.SS1.SSS2
    "IV-A2 Room Description ‣ IV-A Perception Module ‣ IV CAMON Approach ‣ CAMON:
    Cooperative Agents for Multi-Object Navigation with LLM-based Conversations"))。（2）在承担通信和决策的通信模块([IV-B](#S4.SS2
    "IV-B Planning Module ‣ IV CAMON Approach ‣ CAMON: Cooperative Agents for Multi-Object
    Navigation with LLM-based Conversations"))中，我们采用顺序和动态的领导-成员沟通结构，领导者调整代理的决策建议([IV-B2](#S4.SS2.SSS2
    "IV-B2 Agent Asks for Help ‣ IV-B Planning Module ‣ IV CAMON Approach ‣ CAMON:
    Cooperative Agents for Multi-Object Navigation with LLM-based Conversations"))并确保团队协调([IV-B3](#S4.SS2.SSS3
    "IV-B3 Leader’s Coordination of Teamwork ‣ IV-B Planning Module ‣ IV CAMON Approach
    ‣ CAMON: Cooperative Agents for Multi-Object Navigation with LLM-based Conversations"))。在沟通过程中做出决策时，成员将被分配寻找特定物体的责任，并从领导者那里选择下一个参考目标房间。（3）在路径规划层面([IV-C](#S4.SS3
    "IV-C Motion Planning ‣ IV CAMON Approach ‣ CAMON: Cooperative Agents for Multi-Object
    Navigation with LLM-based Conversations"))，我们基于当前位置和目标房间在地图上规划了一系列航点，生成离散动作。'
- en: IV-A Perception Module
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A 感知模块
- en: IV-A1 Map Construction
  id: totrans-39
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-A1 地图构建
- en: To record historical semantic information, each robot constructs and updates
    a local semantic map in real-time using its poses and RGB-D images. The map records
    the occupancy of obstacle areas, accessible areas, and semantic information. Inspired
    by the methodology in [[42](#bib.bib42), [17](#bib.bib17), [32](#bib.bib32)],
    we extracted the waypoints and topological map from the accessible area map channels
    to optimize the point-to-point movement.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 为了记录历史语义信息，每个机器人通过实时使用其位姿和RGB-D图像来构建和更新本地语义地图。该地图记录了障碍区、可达区和语义信息的占用情况。受到[[42](#bib.bib42),
    [17](#bib.bib17), [32](#bib.bib32)]方法论的启发，我们从可达区域地图通道中提取了航点和拓扑图，以优化点对点的移动。
- en: IV-A2 Room Description
  id: totrans-41
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-A2 房间描述
- en: Following the principle of 3D room segmentation [[31](#bib.bib31), [16](#bib.bib16)],
    the observed rooms are segmented to obtain masks for each room on the map. To
    obtain a description of each room, we aim to use an LMM to read the holistic image
    of the entire room and generate the corresponding description. To capture such
    a comprehensive image, we take advantage of the robot’s manner of moving between
    nodes on the topology map. The robot will rotate itself to collect $12$ frames
    of images each time it passes through waypoints. For each segmented room, we select
    the image from the recorded frames that best captures the view of the room. Next,
    we use GPT-4o [[1](#bib.bib1)] to generate descriptions of the scenes in these
    images.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 3D 房间分割的原则 [[31](#bib.bib31), [16](#bib.bib16)]，观察到的房间被分割以获得地图上每个房间的掩码。为了获得每个房间的描述，我们的目标是使用
    LMM 来读取整个房间的全景图像并生成相应的描述。为了捕捉这种全面的图像，我们利用机器人在拓扑地图上节点之间移动的方式。每当机器人经过一个路标时，它会旋转自身以收集
    $12$ 帧图像。对于每个分割的房间，我们从录制的帧中选择最佳捕捉房间视角的图像。接下来，我们使用 GPT-4o [[1](#bib.bib1)] 生成这些图像场景的描述。
- en: IV-B Planning Module
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-B 规划模块
- en: During navigation, each embodied agent carefully observes the current room and
    updates the semantic map of the room each time it enters a new one. When remaining
    and previously unsearched objects are detected, the agent sequentially navigates
    to the locations of the target objects. When the entire room has been explored
    and no remaining target objects are present in the room, the robot considers which
    room to explore next and what objects to take responsibility for by communicating
    with the current leader through a communication module to make a reasonable decision.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在导航过程中，每个具身代理仔细观察当前房间，并在进入新房间时更新房间的语义地图。当检测到剩余和之前未搜索的物体时，代理会依次导航到目标物体的位置。当整个房间被探索完毕且房间中不再存在剩余的目标物体时，机器人会通过沟通模块与当前领导者沟通，以决定下一步探索哪个房间以及对哪些物体负责。
- en: IV-B1 Communication and Leadership Appointment
  id: totrans-45
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B1 沟通与领导任命
- en: In team collaboration, the presence of leaders greatly affects communication
    efficiency and task completion. An orderly organization needs to address the question
    of who the leader is and what role the leader plays. In this framework, we adopt
    a comm-triggered dynamic leadership mechanism to answer the question of who is
    the leader, while addressing the issues of imbalanced information flow and poor
    robustness in fixed leadership. As the episode starts, one of the robots, $agent\_a$
    inherits the leader. In the subsequent process, robots continuously send communication
    requests, and global information and leadership are conveyed sequentially within
    the robots. We answer the question of the role played by leaders by endowing dynamic
    leaders with temporary access to the authority to command any robot and the latest
    global information. This collaborative approach can share the communication load
    between robots, and even if a robot crashes (or even the temp leader), the remaining
    robots can maintain system stability by asking the previous leader.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在团队协作中，领导者的存在极大地影响了沟通效率和任务完成。一个有序的组织需要解决领导者是谁以及领导者扮演什么角色的问题。在这个框架下，我们采用了一个由沟通触发的动态领导机制来回答谁是领导者的问题，同时解决固定领导下信息流不平衡和鲁棒性差的问题。随着情节的开始，其中一个机器人，$agent\_a$
    继承了领导者。在随后的过程中，机器人不断发送沟通请求，全球信息和领导权在机器人之间依次传递。我们通过赋予动态领导者暂时指挥任何机器人和获取最新全球信息的权力来回答领导者所扮演的角色的问题。这种协作方式可以分担机器人之间的沟通负担，即使一个机器人（或临时领导者）崩溃，剩下的机器人也可以通过向之前的领导者请求来保持系统稳定。
- en: IV-B2 Agent Asks for Help
  id: totrans-47
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B2 代理请求帮助
- en: 'Due to the complexity of multi-agent task planning, LLM needs clear historical
    observations and team conditions to enhance understanding and planning performance.
    Before any robot team member sends a communication request to the current leader,
    a robot makes an initial decision using the LLM based on the recorded historical
    information. This decision focuses on the benefit of the robot itself, which is
    subsequently conveyed to the leader to help determine whether the decision will
    cause conflicts with other robots. When the robot receives the response from the
    leader containing the target room and locked objects to prevent others from finding
    them, it then moves to the target room. We use templates $Pr$. The process can
    be formulated as:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 由于多代理任务规划的复杂性，LLM 需要清晰的历史观测和团队状况来增强理解和规划性能。在任何机器人团队成员向当前领导者发送通信请求之前，一台机器人会基于记录的历史信息使用LLM做出初步决策。这个决策关注于机器人自身的利益，然后传达给领导者，以帮助确定该决策是否会与其他机器人产生冲突。当机器人收到领导者的回应，其中包含目标房间和锁定的物体以防止其他机器人找到它们时，机器人将移动到目标房间。我们使用模板
    $Pr$。这个过程可以表示为：
- en: '|  | $Ps_{i}=\text{LLM}(Pr(i,P_{i},S_{i},G,H_{i}))$ |  | (1) |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '|  | $Ps_{i}=\text{LLM}(Pr(i,P_{i},S_{i},G,H_{i}))$ |  | (1) |'
- en: IV-B3 Leader’s Coordination of Teamwork
  id: totrans-50
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B3 领导者的团队协调
- en: 'When receiving requests from team members, the leader undertakes to evaluate
    the initial proposals $Ps_{i}$ of all agents and task progress. Similarly, We
    employ the LLM to handle this process, as demonstrated in Formula [2](#S4.E2 "In
    IV-B3 Leader’s Coordination of Teamwork ‣ IV-B Planning Module ‣ IV CAMON Approach
    ‣ CAMON: Cooperative Agents for Multi-Object Navigation with LLM-based Conversations").'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '当接收到团队成员的请求时，领导者承诺评估所有代理的初始提议 $Ps_{i}$ 和任务进展。类似地，我们使用LLM来处理这个过程，如公式[2](#S4.E2
    "在 IV-B3 领导者的团队协调 ‣ IV-B 规划模块 ‣ IV CAMON 方法 ‣ CAMON: 基于LLM对话的多目标导航的合作代理")所示。'
- en: '|  | $Re^{*}=\text{LLM}(Pr^{*}(Ps_{i},P_{g},S_{g},G))$ |  | (2) |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '|  | $Re^{*}=\text{LLM}(Pr^{*}(Ps_{i},P_{g},S_{g},G))$ |  | (2) |'
- en: where $Pr^{*}$-th agent, as well as actions assigned to it (if interrupted).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $Pr^{*}$-th 代理及其分配的动作（如果被中断）。
- en: IV-C Motion Planning
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-C 运动规划
- en: Given the current position of the robot and the target room, the robot selects
    the Voronoi point closest to its current position within the target room. Subsequently,
    it uses the Dijkstra [[11](#bib.bib11)] method to plan the next waypoint along
    the topological edges as a mid-term goal. Then, the Fast Marching Method [[26](#bib.bib26)]
    is employed to plan the shortest point sequence and the next discrete action in
    real-time, from the current position to the mid-term target point. Whenever the
    robot passes through a topological waypoint, it rotates once to collect surrounding
    images.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 给定机器人的当前位置和目标房间，机器人选择目标房间内最接近当前位置的Voronoi点。随后，它使用Dijkstra [[11](#bib.bib11)]
    方法沿拓扑边规划下一个中期目标点。然后，采用快速行进方法 [[26](#bib.bib26)] 实时规划从当前位置到中期目标点的最短点序列和下一个离散动作。每当机器人通过一个拓扑目标点时，它会旋转一次以收集周围的图像。
- en: V Conclusion
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V 结论
- en: In this work, we propose a fully decentralized, LLM-based multi-agent collaborative
    navigation framework. The agents can effectively communicate, efficiently divide
    tasks and collaborate through a dynamic leadership organization. Our method can
    achieve task division and team planning consensus with minimal communication overhead,
    resulting in optimal navigation performance and robustness in the multi-agent
    system. We believe that our approach holds promising applications for future team
    collaboration of household mobile agents.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们提出了一种完全去中心化、基于LLM的多代理协作导航框架。这些代理可以通过动态的领导组织进行有效的沟通、高效的任务分配和协作。我们的方法可以在最小的通信开销下实现任务分配和团队规划的共识，从而在多代理系统中实现最佳的导航性能和鲁棒性。我们相信，我们的方法在未来家庭移动代理的团队协作中具有广阔的应用前景。
- en: Limitations & Future Work. Several limitations remain in the current approach.
    First, while our mapping perception module can effectively map all observed objects,
    it may struggle with dynamic objects, such as humans or pets, in household scenarios.
    This could adversely affect the robot’s mapping and room segmentation capabilities.
    Additionally, our current framework is restricted to single-floor navigation and
    does not account for cross-floor cooperative navigation. However, we believe these
    limitations are not central to the issues addressed in this article and can be
    mitigated by incorporating additional strategy modules. Our work demonstrates
    promising application prospects and offers feasible ideas for future multi-robot
    systems. Future research will focus on the collaboration of multi-robot system
    movement and manipulation, aiming to complete the framework for communication,
    navigation, and manipulation integration. These important topics will be left
    for future exploration.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 限制与未来工作。当前方法存在一些限制。首先，虽然我们的映射感知模块可以有效地映射所有观察到的物体，但它可能在处理家庭场景中的动态物体（如人或宠物）时遇到困难。这可能会对机器人的映射和房间分割能力产生不利影响。此外，我们当前的框架仅限于单层楼导航，并且未考虑跨楼层协作导航。然而，我们认为这些限制并非本文讨论的核心问题，可以通过纳入额外的策略模块来缓解。我们的工作展示了有希望的应用前景，并为未来的多机器人系统提供了可行的思路。未来的研究将专注于多机器人系统的运动与操作协作，旨在完善通信、导航和操作整合的框架。这些重要话题将留待未来探讨。
- en: References
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] GPT-4o. [https://openai.com/index/hello-gpt-4o/](https://openai.com/index/hello-gpt-4o/).'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] GPT-4o. [https://openai.com/index/hello-gpt-4o/](https://openai.com/index/hello-gpt-4o/)。'
- en: Agashe et al. [2023] Saaket Agashe, Yue Fan, and Xin Eric Wang. Evaluating multi-agent
    coordination abilities in large language models. *arXiv preprint arXiv:2310.03903*,
    2023.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Agashe et al. [2023] Saaket Agashe, Yue Fan, 和 Xin Eric Wang. 评估大型语言模型中的多智能体协调能力。*arXiv
    预印本 arXiv:2310.03903*，2023。
- en: 'Anderson et al. [2018] Peter Anderson, Qi Wu, Damien Teney, Jake Bruce, Mark
    Johnson, Niko Sünderhauf, Ian Reid, Stephen Gould, and Anton Van Den Hengel. Vision-and-language
    navigation: Interpreting visually-grounded navigation instructions in real environments.
    In *Proceedings of the IEEE conference on computer vision and pattern recognition*,
    pages 3674–3683, 2018.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anderson et al. [2018] Peter Anderson, Qi Wu, Damien Teney, Jake Bruce, Mark
    Johnson, Niko Sünderhauf, Ian Reid, Stephen Gould, 和 Anton Van Den Hengel. 视觉与语言导航：解释在真实环境中的视觉基础导航指令。在*IEEE计算机视觉与模式识别会议论文集*，页码
    3674–3683，2018。
- en: Cai et al. [2023] Wenzhe Cai, Siyuan Huang, Guangran Cheng, Yuxing Long, Peng
    Gao, Changyin Sun, and Hao Dong. Bridging zero-shot object navigation and foundation
    models through pixel-guided navigation skill. *arXiv preprint arXiv:2309.10309*,
    2023.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cai et al. [2023] Wenzhe Cai, Siyuan Huang, Guangran Cheng, Yuxing Long, Peng
    Gao, Changyin Sun, 和 Hao Dong. 通过像素引导导航技能桥接零样本物体导航和基础模型。*arXiv 预印本 arXiv:2309.10309*，2023。
- en: Chaplot et al. [2020] Devendra Singh Chaplot, Dhiraj Prakashchand Gandhi, Abhinav
    Gupta, and Russ R Salakhutdinov. Object goal navigation using goal-oriented semantic
    exploration. *Advances in Neural Information Processing Systems*, 33:4247–4258,
    2020.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chaplot et al. [2020] Devendra Singh Chaplot, Dhiraj Prakashchand Gandhi, Abhinav
    Gupta, 和 Russ R Salakhutdinov. 使用目标导向的语义探索进行物体目标导航。*神经信息处理系统进展*，33:4247–4258，2020。
- en: Chen et al. [2023a] Hongyi Chen, Ruinian Xu, Shuo Cheng, Patricio A Vela, and
    Danfei Xu. Zero-shot object searching using large-scale object relationship prior.
    *arXiv preprint arXiv:2303.06228*, 2023a.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. [2023a] Hongyi Chen, Ruinian Xu, Shuo Cheng, Patricio A Vela, 和
    Danfei Xu. 使用大规模物体关系先验进行零样本物体搜索。*arXiv 预印本 arXiv:2303.06228*，2023a。
- en: Chen et al. [2023b] Huaben Chen, Wenkang Ji, Lufeng Xu, and Shiyu Zhao. Multi-agent
    consensus seeking via large language models. *arXiv preprint arXiv:2310.20151*,
    2023b.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. [2023b] Huaben Chen, Wenkang Ji, Lufeng Xu, 和 Shiyu Zhao. 通过大型语言模型进行多智能体共识寻求。*arXiv
    预印本 arXiv:2310.20151*，2023b。
- en: 'Chen et al. [2024] Jiaqi Chen, Bingqian Lin, Ran Xu, Zhenhua Chai, Xiaodan
    Liang, and Kwan-Yee K Wong. Mapgpt: Map-guided prompting for unified vision-and-language
    navigation. *arXiv preprint arXiv:2401.07314*, 2024.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. [2024] Jiaqi Chen, Bingqian Lin, Ran Xu, Zhenhua Chai, Xiaodan Liang,
    和 Kwan-Yee K Wong. Mapgpt：用于统一视觉与语言导航的地图引导提示。*arXiv 预印本 arXiv:2401.07314*，2024。
- en: 'Chen et al. [2023c] Junting Chen, Guohao Li, Suryansh Kumar, Bernard Ghanem,
    and Fisher Yu. How to not train your dragon: Training-free embodied object goal
    navigation with semantic frontiers. In *Robotics: Science and Systems (RSS)*,
    2023c.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. [2023c] Junting Chen, Guohao Li, Suryansh Kumar, Bernard Ghanem,
    和 Fisher Yu. 如何不训练你的龙：无训练的具身物体目标导航与语义前沿。在*机器人学：科学与系统 (RSS)*，2023c。
- en: 'Chen et al. [2023d] Yongchao Chen, Jacob Arkin, Yang Zhang, Nicholas Roy, and
    Chuchu Fan. Scalable multi-robot collaboration with large language models: Centralized
    or decentralized systems? *arXiv preprint arXiv:2309.15943*, 2023d.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 [2023d] Yongchao Chen, Jacob Arkin, Yang Zhang, Nicholas Roy 和 Chuchu
    Fan. 大型语言模型的可扩展多机器人协作：集中式还是分散式系统？*arXiv 预印本 arXiv:2309.15943*, 2023d。
- en: DIJKSTRA [1959] EW DIJKSTRA. A note on two problems in connexion with graphs.
    *Numerische Mathematik*, 1:269–271, 1959.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DIJKSTRA [1959] EW DIJKSTRA. 关于图的两个问题的说明。*Numerische Mathematik*, 1:269–271,
    1959。
- en: 'Dorbala et al. [2024] Vishnu Sashank Dorbala, James F. Mullen, and Dinesh Manocha.
    Can an embodied agent find your “cat-shaped mug”? llm-based zero-shot object navigation.
    *IEEE Robotics and Automation Letters*, 9(5):4083–4090, 2024. doi: 10.1109/LRA.2023.3346800.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Dorbala 等 [2024] Vishnu Sashank Dorbala, James F. Mullen 和 Dinesh Manocha.
    一个具身智能体能找到你的“猫形杯”吗？基于 llm 的零样本目标导航。*IEEE Robotics and Automation Letters*, 9(5):4083–4090,
    2024. doi: 10.1109/LRA.2023.3346800。'
- en: 'Gadre et al. [2023] Samir Yitzhak Gadre, Mitchell Wortsman, Gabriel Ilharco,
    Ludwig Schmidt, and Shuran Song. Cows on pasture: Baselines and benchmarks for
    language-driven zero-shot object navigation. In *Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition*, pages 23171–23181, 2023.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gadre 等 [2023] Samir Yitzhak Gadre, Mitchell Wortsman, Gabriel Ilharco, Ludwig
    Schmidt 和 Shuran Song. 牧场上的奶牛：语言驱动的零样本目标导航的基准和标准。在 *IEEE/CVF 计算机视觉与模式识别会议论文集*
    中，页码 23171–23181，2023。
- en: Gireesh et al. [2023] Nandiraju Gireesh, Ayush Agrawal, Ahana Datta, Snehasis
    Banerjee, Mohan Sridharan, Brojeshwar Bhowmick, and Madhava Krishna. Sequence-agnostic
    multi-object navigation. In *2023 IEEE International Conference on Robotics and
    Automation (ICRA)*, pages 9573–9579\. IEEE, 2023.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gireesh 等 [2023] Nandiraju Gireesh, Ayush Agrawal, Ahana Datta, Snehasis Banerjee,
    Mohan Sridharan, Brojeshwar Bhowmick 和 Madhava Krishna. 序列无关的多目标导航。在 *2023 IEEE
    国际机器人与自动化会议 (ICRA)* 中，页码 9573–9579。IEEE，2023。
- en: Guo et al. [2024] Xudong Guo, Kaixuan Huang, Jiale Liu, Wenhui Fan, Natalia
    Vélez, Qingyun Wu, Huazheng Wang, Thomas L Griffiths, and Mengdi Wang. Embodied
    llm agents learn to cooperate in organized teams. *arXiv preprint arXiv:2403.12482*,
    2024.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo 等 [2024] Xudong Guo, Kaixuan Huang, Jiale Liu, Wenhui Fan, Natalia Vélez,
    Qingyun Wu, Huazheng Wang, Thomas L Griffiths 和 Mengdi Wang. 具身 llm 智能体学习在组织化团队中的合作。*arXiv
    预印本 arXiv:2403.12482*, 2024。
- en: 'Hughes et al. [2022] Nathan Hughes, Yun Chang, and Luca Carlone. Hydra: A real-time
    spatial perception system for 3d scene graph construction and optimization. *arXiv
    preprint arXiv:2201.13360*, 2022.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hughes 等 [2022] Nathan Hughes, Yun Chang 和 Luca Carlone. Hydra: 用于 3d 场景图构建和优化的实时空间感知系统。*arXiv
    预印本 arXiv:2201.13360*, 2022。'
- en: Kwon et al. [2023] Obin Kwon, Jeongho Park, and Songhwai Oh. Renderable neural
    radiance map for visual navigation. In *Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition*, pages 9099–9108, 2023.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kwon 等 [2023] Obin Kwon, Jeongho Park 和 Songhwai Oh. 可渲染神经辐射图用于视觉导航。在 *IEEE/CVF
    计算机视觉与模式识别会议论文集* 中，页码 9099–9108，2023。
- en: Liu et al. [2023] Jijia Liu, Chao Yu, Jiaxuan Gao, Yuqing Xie, Qingmin Liao,
    Yi Wu, and Yu Wang. Llm-powered hierarchical language agent for real-time human-ai
    coordination. *arXiv preprint arXiv:2312.15224*, 2023.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等 [2023] Jijia Liu, Chao Yu, Jiaxuan Gao, Yuqing Xie, Qingmin Liao, Yi Wu
    和 Yu Wang. llm 驱动的分层语言智能体用于实时人类-ai 协作。*arXiv 预印本 arXiv:2312.15224*, 2023。
- en: 'Ma et al. [2024] Ji Ma, Hongming Dai, Yao Mu, Pengying Wu, Hao Wang, Xiaowei
    Chi, Yang Fei, Shanghang Zhang, and Chang Liu. Doze: A dataset for open-vocabulary
    zero-shot object navigation in dynamic environments. *arXiv preprint arXiv:2402.19007*,
    2024.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ma 等 [2024] Ji Ma, Hongming Dai, Yao Mu, Pengying Wu, Hao Wang, Xiaowei Chi,
    Yang Fei, Shanghang Zhang 和 Chang Liu. Doze: 动态环境下开放词汇的零样本目标导航数据集。*arXiv 预印本 arXiv:2402.19007*,
    2024。'
- en: 'Majumdar et al. [2022] Arjun Majumdar, Gunjan Aggarwal, Bhavika Suresh Devnani,
    Judy Hoffman, and Dhruv Batra. ZSON: Zero-shot object-goal navigation using multimodal
    goal embeddings. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun
    Cho, editors, *Advances in Neural Information Processing Systems*, 2022. URL [https://openreview.net/forum?id=VY1dqOF2RjC](https://openreview.net/forum?id=VY1dqOF2RjC).'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Majumdar 等 [2022] Arjun Majumdar, Gunjan Aggarwal, Bhavika Suresh Devnani,
    Judy Hoffman 和 Dhruv Batra. ZSON: 使用多模态目标嵌入的零样本目标导航。在 Alice H. Oh, Alekh Agarwal,
    Danielle Belgrave 和 Kyunghyun Cho 编者的 *Advances in Neural Information Processing
    Systems* 中，2022。网址 [https://openreview.net/forum?id=VY1dqOF2RjC](https://openreview.net/forum?id=VY1dqOF2RjC)。'
- en: 'Mandi et al. [2023] Zhao Mandi, Shreeya Jain, and Shuran Song. Roco: Dialectic
    multi-robot collaboration with large language models. *arXiv preprint arXiv:2307.04738*,
    2023.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Mandi 等 [2023] Zhao Mandi, Shreeya Jain 和 Shuran Song. Roco: 利用大语言模型的辩证多机器人协作。*arXiv
    预印本 arXiv:2307.04738*, 2023。'
- en: Marza et al. [2023] Pierre Marza, Laetitia Matignon, Olivier Simonin, and Christian
    Wolf. Multi-object navigation with dynamically learned neural implicit representations.
    In *Proceedings of the IEEE/CVF International Conference on Computer Vision*,
    pages 11004–11015, 2023.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Marza 等 [2023] Pierre Marza、Laetitia Matignon、Olivier Simonin 和 Christian Wolf。使用动态学习的神经隐式表示进行多目标导航。在
    *IEEE/CVF 国际计算机视觉会议论文集*，第 11004–11015 页，2023。
- en: 'Park et al. [2023] Jeongeun Park, Taerim Yoon, Jejoon Hong, Youngjae Yu, Matthew
    Pan, and Sungjoon Choi. Zero-shot active visual search (zavis): Intelligent object
    search for robotic assistants. In *2023 IEEE International Conference on Robotics
    and Automation (ICRA)*, pages 2004–2010, 2023. doi: 10.1109/ICRA48891.2023.10161345.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Park 等 [2023] Jeongeun Park、Taerim Yoon、Jejoon Hong、Youngjae Yu、Matthew Pan
    和 Sungjoon Choi。零样本主动视觉搜索 (zavis)：为机器人助手提供智能物体搜索。在 *2023 IEEE 国际机器人与自动化会议（ICRA）*，第
    2004–2010 页，2023。doi: 10.1109/ICRA48891.2023.10161345。'
- en: 'Ramakrishnan et al. [2022] Santhosh Kumar Ramakrishnan, Devendra Singh Chaplot,
    Ziad Al-Halah, Jitendra Malik, and Kristen Grauman. Poni: Potential functions
    for objectgoal navigation with interaction-free learning. In *Proceedings of the
    IEEE/CVF Conference on Computer Vision and Pattern Recognition*, pages 18890–18900,
    2022.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ramakrishnan 等 [2022] Santhosh Kumar Ramakrishnan、Devendra Singh Chaplot、Ziad
    Al-Halah、Jitendra Malik 和 Kristen Grauman。Poni：用于无交互学习的对象目标导航的潜在函数。在 *IEEE/CVF
    计算机视觉与模式识别会议论文集*，第 18890–18900 页，2022。
- en: 'Sadek et al. [2023] Assem Sadek, Guillaume Bono, Boris Chidlovskii, Atilla
    Baskurt, and Christian Wolf. Multi-object navigation in real environments using
    hybrid policies. In *2023 IEEE International Conference on Robotics and Automation
    (ICRA)*, pages 4085–4091, 2023. doi: 10.1109/ICRA48891.2023.10161030.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Sadek 等 [2023] Assem Sadek、Guillaume Bono、Boris Chidlovskii、Atilla Baskurt
    和 Christian Wolf。在真实环境中使用混合策略进行多目标导航。在 *2023 IEEE 国际机器人与自动化会议（ICRA）*，第 4085–4091
    页，2023。doi: 10.1109/ICRA48891.2023.10161030。'
- en: Sethian [1996] James A Sethian. A fast marching level set method for monotonically
    advancing fronts. *proceedings of the National Academy of Sciences*, 93(4):1591–1595,
    1996.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sethian [1996] James A Sethian。用于单调推进前沿的快速行进水平集方法。*美国国家科学院院刊*，93(4)：1591–1595，1996。
- en: 'Shah et al. [2023] Dhruv Shah, Michael Equi, Blazej Osinski, Fei Xia, Brian
    Ichter, and Sergey Levine. Navigation with large language models: Semantic guesswork
    as a heuristic for planning. In *7th Annual Conference on Robot Learning*, 2023.
    URL [https://openreview.net/forum?id=PsV65r0itpo](https://openreview.net/forum?id=PsV65r0itpo).'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shah 等 [2023] Dhruv Shah、Michael Equi、Blazej Osinski、Fei Xia、Brian Ichter 和
    Sergey Levine。使用大语言模型的导航：作为规划启发式的语义猜测。在 *第七届机器人学习年会*，2023。网址 [https://openreview.net/forum?id=PsV65r0itpo](https://openreview.net/forum?id=PsV65r0itpo)。
- en: Sun et al. [2024] Leyuan Sun, Asako Kanezaki, Guillaume Caron, and Yusuke Yoshiyasu.
    Leveraging large language model-based room-object relationships knowledge for
    enhancing multimodal-input object goal navigation. *arXiv preprint arXiv:2403.14163*,
    2024.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun 等 [2024] Leyuan Sun、Asako Kanezaki、Guillaume Caron 和 Yusuke Yoshiyasu。利用基于大语言模型的房间-物体关系知识来增强多模态输入目标导航。*arXiv
    预印本 arXiv:2403.14163*，2024。
- en: Wang et al. [2024] Jun Wang, Guocheng He, and Yiannis Kantaros. Safe task planning
    for language-instructed multi-robot systems using conformal prediction. *arXiv
    preprint arXiv:2402.15368*, 2024.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等 [2024] Jun Wang、Guocheng He 和 Yiannis Kantaros。基于语言指令的多机器人系统的安全任务规划，使用符合预测。*arXiv
    预印本 arXiv:2402.15368*，2024。
- en: 'Wani et al. [2020] Saim Wani, Shivansh Patel, Unnat Jain, Angel X. Chang, and
    Manolis Savva. Multion: Benchmarking semantic map memory using multi-object navigation.
    In *NeurIPS*, 2020.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wani 等 [2020] Saim Wani、Shivansh Patel、Unnat Jain、Angel X. Chang 和 Manolis Savva。Multion：使用多目标导航对语义地图记忆进行基准测试。在
    *NeurIPS*，2020。
- en: Werby et al. [2024] Abdelrhman Werby, Chenguang Huang, Martin Büchner, Abhinav
    Valada, and Wolfram Burgard. Hierarchical open-vocabulary 3d scene graphs for
    language-grounded robot navigation. In *First Workshop on Vision-Language Models
    for Navigation and Manipulation at ICRA 2024*, 2024.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Werby 等 [2024] Abdelrhman Werby、Chenguang Huang、Martin Büchner、Abhinav Valada
    和 Wolfram Burgard。基于语言的机器人导航的分层开放词汇 3D 场景图。在 *2024 ICRA 首届视觉-语言模型导航与操作研讨会*，2024。
- en: 'Wu et al. [2024] Pengying Wu, Yao Mu, Bingxian Wu, Yi Hou, Ji Ma, Shanghang
    Zhang, and Chang Liu. Voronav: Voronoi-based zero-shot object navigation with
    large language model. *arXiv preprint arXiv:2401.02695*, 2024.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等 [2024] Pengying Wu、Yao Mu、Bingxian Wu、Yi Hou、Ji Ma、Shanghang Zhang 和 Chang
    Liu。Voronav：基于 Voronoi 的零样本对象导航与大语言模型。*arXiv 预印本 arXiv:2401.02695*，2024。
- en: 'Ying et al. [2024] Lance Ying, Kunal Jha, Shivam Aarya, Joshua B Tenenbaum,
    Antonio Torralba, and Tianmin Shu. Goma: Proactive embodied cooperative communication
    via goal-oriented mental alignment. *arXiv preprint arXiv:2403.11075*, 2024.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ying 等人 [2024] 兰斯·英、库纳尔·贾、希瓦姆·阿利亚、约书亚·B·特能堡、安东尼奥·托拉尔巴 和 天敏·舒。GOMA：通过以目标为导向的心理对齐进行主动的具身合作通信。*arXiv
    预印本 arXiv:2403.11075*，2024。
- en: 'Yu et al. [2023a] Bangguo Yu, Hamidreza Kasaei, and Ming Cao. Co-navgpt: Multi-robot
    cooperative visual semantic navigation using large language models. *arXiv preprint
    arXiv:2310.07937*, 2023a.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu 等人 [2023a] 邦国·余、哈米德雷扎·卡萨伊 和 明·曹。Co-NAVGPT：使用大型语言模型的多机器人合作视觉语义导航。*arXiv 预印本
    arXiv:2310.07937*，2023a。
- en: 'Yu et al. [2023b] Bangguo Yu, Hamidreza Kasaei, and Ming Cao. L3mvn: Leveraging
    large language models for visual target navigation. *arXiv preprint arXiv:2304.05501*,
    2023b.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu 等人 [2023b] 邦国·余、哈米德雷扎·卡萨伊 和 明·曹。L3MVN：利用大型语言模型进行视觉目标导航。*arXiv 预印本 arXiv:2304.05501*，2023b。
- en: 'Zeng et al. [2023] Haitao Zeng, Xinhang Song, and Shuqiang Jiang. Multi-object
    navigation using potential target position policy function. *IEEE Transactions
    on Image Processing*, 32:2608–2619, 2023. doi: 10.1109/TIP.2023.3263110.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zeng 等人 [2023] 海涛·曾、鑫航·宋 和 舒强·姜。使用潜在目标位置策略函数进行多目标导航。*IEEE 图像处理汇刊*，32:2608–2619，2023。doi:
    10.1109/TIP.2023.3263110。'
- en: 'Zhang et al. [2023a] Bin Zhang, Hangyu Mao, Jingqing Ruan, Ying Wen, Yang Li,
    Shao Zhang, Zhiwei Xu, Dapeng Li, Ziyue Li, Rui Zhao, et al. Controlling large
    language model-based agents for large-scale decision-making: An actor-critic approach.
    *arXiv preprint arXiv:2311.13884*, 2023a.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人 [2023a] 宾·张、杭宇·毛、晶清·阮、英·温、杨·李、邵·张、智伟·徐、大鹏·李、紫月·李、瑞·赵 等人。控制大型语言模型基础的代理进行大规模决策：一种演员-评论家方法。*arXiv
    预印本 arXiv:2311.13884*，2023a。
- en: Zhang et al. [2023b] Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun
    Du, Joshua B Tenenbaum, Tianmin Shu, and Chuang Gan. Building cooperative embodied
    agents modularly with large language models. *arXiv preprint arXiv:2307.02485*,
    2023b.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人 [2023b] 洪鑫·张、韦华·杜、佳明·单、秦洪·周、亿伦·杜、约书亚·B·特能堡、天敏·舒 和 庄阔·甘。通过大型语言模型模块化构建合作的具身代理。*arXiv
    预印本 arXiv:2307.02485*，2023b。
- en: 'Zhao et al. [2023] Qianfan Zhao, Lu Zhang, Bin He, Hong Qiao, and Zhiyong Liu.
    Zero-shot object goal visual navigation. In *2023 IEEE International Conference
    on Robotics and Automation (ICRA)*, pages 2025–2031, 2023. doi: 10.1109/ICRA48891.2023.10161289.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhao 等人 [2023] 钱凡·赵、陆·张、宾·赫、洪·乔 和 智勇·刘。零样本目标视觉导航。在 *2023 IEEE 国际机器人与自动化会议 (ICRA)*，页码
    2025–2031，2023。doi: 10.1109/ICRA48891.2023.10161289。'
- en: Zhao et al. [2024] Zhonghan Zhao, Kewei Chen, Dongxu Guo, Wenhao Chai, Tian
    Ye, Yanting Zhang, and Gaoang Wang. Hierarchical auto-organizing system for open-ended
    multi-agent navigation. *arXiv preprint arXiv:2403.08282*, 2024.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao 等人 [2024] 钟瀚·赵、可为·陈、东旭·郭、文浩·柴、天·叶、燕婷·张 和 高昂·王。用于开放式多智能体导航的层次自动组织系统。*arXiv
    预印本 arXiv:2403.08282*，2024。
- en: 'Zhou et al. [2023] Kaiwen Zhou, Kaizhi Zheng, Connor Pryor, Yilin Shen, Hongxia
    Jin, Lise Getoor, and Xin Eric Wang. Esc: Exploration with soft commonsense constraints
    for zero-shot object navigation. *arXiv preprint arXiv:2301.13166*, 2023.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou 等人 [2023] 凯文·周、凯志·郑、康纳·普赖尔、伊琳·沈、洪霞·金、丽丝·格图尔 和 辛·埃里克·王。ESC：使用软常识约束进行零样本对象导航。*arXiv
    预印本 arXiv:2301.13166*，2023。
- en: Zuo et al. [2020] Xinkai Zuo, Fan Yang, Yifan Liang, Zhou Gang, Fei Su, Haihong
    Zhu, and Lin Li. An improved autonomous exploration framework for indoor mobile
    robotics using reduced approximated generalized voronoi graphs. *ISPRS Annals
    of the Photogrammetry, Remote Sensing and Spatial Information Sciences*, 1:351–359,
    2020.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zuo 等人 [2020] 新凯·左、范洋、依凡·梁、周刚、费苏、海洪·朱 和 林立。使用简化的近似广义 Voronoi 图的室内移动机器人改进的自主探索框架。*ISPRS
    摄影测量、遥感与空间信息科学年鉴*，1:351–359，2020。
