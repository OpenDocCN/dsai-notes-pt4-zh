- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:40:44'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:40:44
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents for
    Rich Tabletop Game Applications'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI-Gadget Kit：将集群用户界面与基于 LLM 的代理整合以丰富桌面游戏应用
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2407.17086](https://ar5iv.labs.arxiv.org/html/2407.17086)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2407.17086](https://ar5iv.labs.arxiv.org/html/2407.17086)
- en: Yijie Guo Tsinghua UniversityBeijingChina [guoyijie.sh@gmail.com](mailto:guoyijie.sh@gmail.com)
    ,  Zhenhan Huang University of TsukubaTsukubaJapan [zhenhan.email.jp@gmail.com](mailto:zhenhan.email.jp@gmail.com)
    ,  Ruhan Wang Tsinghua UniversityBeijingChina [wangrh22@mails.tsinghua.edu.cn](mailto:wangrh22@mails.tsinghua.edu.cn)
    ,  Zhihao Yao Tsinghua University30 Shuangqing RdBeijingChina [yaozh˙h@outlook.com](mailto:yaozh%CB%99h@outlook.com)
    ,  Tianyu Yu Tsinghua UniversityBeijingChina [yty21@mails.tsinghua.edu.cn](mailto:yty21@mails.tsinghua.edu.cn)
    ,  Zhiling Xu Tsinghua UniversityBeijingChina [xzl23@mails.tsinghua.edu.cn](mailto:xzl23@mails.tsinghua.edu.cn)
    ,  Xinyu Zhao Tsinghua UniversityBeijingChina [xyzhao23@mails.tsinghua.edu.cn](mailto:xyzhao23@mails.tsinghua.edu.cn)
    ,  Xueqing Li Tsinghua UniversityBeijingChina [li-xq23@mails.tsinghua.edu.cn](mailto:li-xq23@mails.tsinghua.edu.cn)
     and  Haipeng Mi Tsinghua UniversityBeijingChina [mhp@tsinghua.edu.cn](mailto:mhp@tsinghua.edu.cn)(2018;
    20 February 2007; 12 March 2009; 5 June 2009)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Yijie Guo 清华大学 北京 中国 [guoyijie.sh@gmail.com](mailto:guoyijie.sh@gmail.com)，
    Zhenhan Huang 筑波大学 筑波 日本 [zhenhan.email.jp@gmail.com](mailto:zhenhan.email.jp@gmail.com)，
    Ruhan Wang 清华大学 北京 中国 [wangrh22@mails.tsinghua.edu.cn](mailto:wangrh22@mails.tsinghua.edu.cn)，
    Zhihao Yao 清华大学 30 双清路 北京 中国 [yaozh˙h@outlook.com](mailto:yaozh%CB%99h@outlook.com)，
    Tianyu Yu 清华大学 北京 中国 [yty21@mails.tsinghua.edu.cn](mailto:yty21@mails.tsinghua.edu.cn)，
    Zhiling Xu 清华大学 北京 中国 [xzl23@mails.tsinghua.edu.cn](mailto:xzl23@mails.tsinghua.edu.cn)，
    Xinyu Zhao 清华大学 北京 中国 [xyzhao23@mails.tsinghua.edu.cn](mailto:xyzhao23@mails.tsinghua.edu.cn)，
    Xueqing Li 清华大学 北京 中国 [li-xq23@mails.tsinghua.edu.cn](mailto:li-xq23@mails.tsinghua.edu.cn)
    和 Haipeng Mi 清华大学 北京 中国 [mhp@tsinghua.edu.cn](mailto:mhp@tsinghua.edu.cn)（2018；2007
    年 2 月 20 日；2009 年 3 月 12 日；2009 年 6 月 5 日）
- en: Abstract.
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: While Swarm User Interfaces (SUIs) have succeeded in enriching tangible interaction
    experiences, their limitations in autonomous action planning have hindered the
    potential for personalized and dynamic interaction generation in tabletop games.
    Based on the AI-Gadget Kit we developed, this paper explores how to integrate
    LLM-driven agents within tabletop games to enable SUIs to execute complex interaction
    tasks. After defining the design space of this kit, we elucidate the method for
    designing agents that can extend the meta-actions of SUIs to complex motion planning.
    Furthermore, we introduce an add-on prompt method that simplifies the design process
    for four interaction behaviors and four interaction relationships in tabletop
    games. Lastly, we present several application scenarios that illustrate the potential
    of AI-Gadget Kit to construct personalized interaction in SUI tabletop games.
    We expect to use our work as a case study to inspire research on multi-agent-driven
    SUI for other scenarios with complex interaction tasks.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管集群用户界面（SUIs）在丰富有形交互体验方面取得了成功，但其在自主行动规划方面的局限性阻碍了桌面游戏中个性化和动态交互生成的潜力。基于我们开发的
    AI-Gadget Kit，本文探讨了如何在桌面游戏中集成基于 LLM 的代理，以使 SUIs 能够执行复杂的交互任务。在定义了该工具包的设计空间之后，我们阐明了设计能够扩展
    SUIs 元操作到复杂运动规划的代理的方法。此外，我们介绍了一种附加提示方法，它简化了桌面游戏中四种交互行为和四种交互关系的设计过程。最后，我们展示了几个应用场景，说明了
    AI-Gadget Kit 在 SUI 桌面游戏中构建个性化交互的潜力。我们希望利用我们的工作作为案例研究，激发对其他具有复杂交互任务场景的多代理驱动 SUI
    的研究。
- en: 'Personalization; Tangible UIs; LLM-Based Agent; Tabletop Game; Swarm User Interface^†^†copyright:
    acmcopyright^†^†journalyear: 2018^†^†doi: XXXXXXX.XXXXXXX^†^†conference: Make
    sure to enter the correct conference title from your rights confirmation emai;
    June 03–05, 2018; Woodstock, NY^†^†price: 15.00^†^†isbn: 978-1-4503-XXXX-X/18/06^†^†ccs:
    Human-centered computing Interaction devices![Refer to caption](img/6e1b6d0564cb53324b804cf0b8463959.png)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 个性化；有形用户界面；基于 LLM 的代理；桌面游戏；集群用户界面^†^†版权：acmcopyright^†^†期刊年份：2018^†^†doi：XXXXXXX.XXXXXXX^†^†会议：确保从您的权利确认电子邮件中输入正确的会议标题；2018
    年 6 月 03–05 日；纽约伍德斯托克^†^†价格：15.00^†^†isbn：978-1-4503-XXXX-X/18/06^†^†ccs：以人为本的计算
    交互设备![参见标题](img/6e1b6d0564cb53324b804cf0b8463959.png)
- en: Figure 1\. Building a tabletop game with a multi-agent system enabled by AI-Gaget
    Kit. a) Extend the meta actions of SUIs to gadgets’ complex motion planning, b)
    interaction behavior generation, c) interaction relationship management. d) Robotic
    gadget plays a turn-based strategy game with a human player.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图1\. 使用AI-Gaget Kit构建一个桌面游戏。a) 将SUI的元动作扩展到小工具的复杂运动规划，b) 交互行为生成，c) 交互关系管理。d)
    机器人小工具与人类玩家进行回合制策略游戏。
- en: \Description
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: \Description
- en: Building a tabletop game with a multi-agent system enabled by AI-Gaget Kit.
    a) Extend the meta actions of SUIs to gadgets’ complex motion planning, b) interaction
    behavior generation, c) interaction relationship management. d) Robotic gadget
    plays a turn-based strategy game with a human player.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 使用AI-Gaget Kit构建一个桌面游戏。a) 将SUI的元动作扩展到小工具的复杂运动规划，b) 交互行为生成，c) 交互关系管理。d) 机器人小工具与人类玩家进行回合制策略游戏。
- en: 1\. Introduction
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 引言
- en: Swarm User Interface (SUI) as an emerging interface has garnered significant
    attention from researchers. Researchers have explored multiple application scenarios
    of SUI, such as data physicalization(Suzuki et al., [2019](#bib.bib29)), remote
    collaboration(Ihara et al., [2023](#bib.bib10)), and educational purposes(Kaimoto
    et al., [2022](#bib.bib13)), based on the unique tangible interaction behaviors
    of SUI, such as collaborative motion, objects actuation, or self-shape changes.
    However, most existing SUIs utilize a pre-programmed set of action planning rules
    to execute different interaction tasks during use, i.e., users need to program
    the action each time they face a new interaction task. This approach struggles
    to adapt to real-world tasks that are usually more complex, dynamic, and possibly
    changeable beyond the pre-programmed scope.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 群体用户界面（SUI）作为一种新兴界面，已引起研究人员的广泛关注。研究人员探索了SUI的多种应用场景，如数据物化（Suzuki et al., [2019](#bib.bib29)）、远程协作（Ihara
    et al., [2023](#bib.bib10)）和教育目的（Kaimoto et al., [2022](#bib.bib13)），这些应用基于SUI的独特物理交互行为，如协作运动、物体驱动或自我形状变化。然而，大多数现有SUI利用预编程的动作规划规则来执行不同的交互任务，即用户在面对新的交互任务时需要每次编程。这种方法难以适应通常更复杂、动态且可能超出预编程范围的现实世界任务。
- en: In recent years, Large Language Models (LLM) have shown benefits for robotic
    motion control and planning. Based on the embedded knowledge of LLMs, they are
    capable of understanding and reasoning about the complex contexts in different
    tasks, thus dynamically generating responses, e.g., motion planning, based on
    the contexts in the tasks. Traditional methods for robotic motion planning included
    using one-decision models, which relied on the prediction of every step of the
    robot’s movement(Gan et al., [2020](#bib.bib5); Wang et al., [2020](#bib.bib32)).
    Recent research has explored using LLMs, particularly LLM-driven agents, to conduct
    robotic motion planning for more complex interaction tasks. For instance, DiscussNav(Long
    et al., [2023](#bib.bib18)) has used multiple LLM agents with different expertise
    to make decisions for robotic navigation in a complex interior scenario. Nevertheless,
    most of these works focused on single-robot systems. Research on multiple-robot
    systems, e.g., SUI, and how to use LLMs to assist the motion planning of these
    systems for complex interaction tasks still remains unexplored.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，大型语言模型（LLM）在机器人运动控制和规划方面显示了其优势。基于LLM的嵌入知识，它们能够理解和推理不同任务中的复杂背景，从而根据任务中的背景动态生成响应，例如运动规划。传统的机器人运动规划方法包括使用一决策模型，这些模型依赖于预测机器人每一步的运动（Gan
    et al., [2020](#bib.bib5); Wang et al., [2020](#bib.bib32)）。近期研究探讨了使用LLM，特别是LLM驱动的代理，来进行更复杂交互任务的机器人运动规划。例如，DiscussNav（Long
    et al., [2023](#bib.bib18)）使用了多种具备不同专业知识的LLM代理来决策机器人在复杂内部场景中的导航。然而，这些工作大多集中在单机器人系统上。对多机器人系统（如SUI）的研究，以及如何利用LLM辅助这些系统的运动规划以处理复杂的交互任务仍然未被探讨。
- en: Among the various applications of SUI, the tabletop game is a typical scenario
    that contains versatile complex interaction tasks. Existing research has explored
    the application of tangible and swarm user interfaces in tabletop games to enhance
    interactivity and enjoyment, such as using robots to facilitate embodied AI players(Matuszek
    et al., [2011](#bib.bib19); van Breemen et al., [2005](#bib.bib30)), robotic game
    masters (Gillet et al., [2020](#bib.bib6)), and automated gadgets(Brock et al.,
    [2021](#bib.bib2); Jariyavajee et al., [2018](#bib.bib11)). However, the action
    planning for robots in these studies still relies on pre-programmed rules, which
    makes it challenging to execute the complex interaction tasks in tabletop games,
    such as understanding and reacting to complex game narratives, improvised decisions
    of players, or emotional expressions from players.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在SUI的各种应用中，桌面游戏是一个典型的场景，包含多样的复杂交互任务。现有研究已探索了在桌面游戏中应用有形和群体用户界面，以增强互动性和趣味性，例如使用机器人促进具身AI玩家（Matuszek
    et al., [2011](#bib.bib19); van Breemen et al., [2005](#bib.bib30)）、机器人游戏主持人（Gillet
    et al., [2020](#bib.bib6)）和自动化小工具（Brock et al., [2021](#bib.bib2); Jariyavajee
    et al., [2018](#bib.bib11)）。然而，这些研究中的机器人行动规划仍然依赖于预编程规则，这使得在桌面游戏中执行复杂交互任务变得具有挑战性，例如理解和反应复杂的游戏叙事、玩家的即兴决策或玩家的情感表达。
- en: In this paper, we aimed to use the tabletop game as a case study to explore
    the application of LLMs on action planning of SUI in scenarios with complex interaction
    tasks. We proposed AI-gadget Kit, a multi-agent SUI tabletop gaming system, which
    is designed to facilitate dynamic and complex interaction tasks in tabletop games.
    We first introduced the system architecture of the AI-gadget Kit, which includes
    a set of swarm robots based on existing platforms to perform the gadget behaviors,
    and a multi-agent system responsible for executing the game and generating action
    plans for the swarm robots. We then elaborated the design of the multi-agent system,
    comprising a series of meta-motions for individual robots, two LLM-based agents
    for complex action planning, and a set of add-on prompts aimed at reinforcing
    the understanding and reacting capabilities of the agents. At last, we demonstrate
    four application examples using AI-gadget Kit to showcase the effect of the multi-agent-driven
    SUI on executing complex interaction tasks in tabletop games. Through this work,
    we aim to inspire the research of multi-agent-driven SUI on other scenarios with
    complex interaction tasks.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们旨在使用桌面游戏作为案例研究，探讨LLM在复杂交互任务场景中的SUI行动规划应用。我们提出了AI-gadget Kit，这是一个多智能体SUI桌面游戏系统，旨在促进桌面游戏中的动态和复杂交互任务。我们首先介绍了AI-gadget
    Kit的系统架构，包括一组基于现有平台的群体机器人来执行小工具行为，以及一个负责执行游戏和为群体机器人生成行动计划的多智能体系统。接着，我们详细阐述了多智能体系统的设计，其中包括个体机器人的一系列元动作、两个基于LLM的复杂行动规划智能体，以及一组旨在强化智能体理解和反应能力的附加提示。最后，我们展示了四个使用AI-gadget
    Kit的应用示例，以展示多智能体驱动的SUI在桌面游戏中执行复杂交互任务的效果。通过这项工作，我们旨在激发对其他复杂交互任务场景中多智能体驱动SUI的研究。
- en: 'In summary, the contribution of this paper includes:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 总结而言，本文的贡献包括：
- en: (1)
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: AI-gadget Kit, a multi-agent SUI tabletop gaming system, which consists of a
    series of meta-motions for individual robots, two LLM-based agents for complex
    action planning, and a series of add-on prompts tailored to the tabletop gaming
    scenario to enhance the understanding capability of the multi-agent system.
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: AI-gadget Kit是一个多智能体SUI桌面游戏系统，包括一系列个体机器人的元动作、两个基于LLM的复杂行动规划智能体，以及一系列为桌面游戏场景量身定制的附加提示，以增强多智能体系统的理解能力。
- en: (2)
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: A set of application examples using AI-gadget Kit on tabletop games, which demonstrates
    the effect of agent-driven swarm robots as gadgets in tabletop games for complex
    interaction tasks.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用AI-gadget Kit在桌面游戏中的一组应用示例，展示了作为小工具的智能体驱动群体机器人在桌面游戏中的复杂交互任务的效果。
- en: 2\. Related work
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 相关工作
- en: 2.1\. Swarm User Interface
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1\. 群体用户界面
- en: Compared to traditional Tangible User Interfaces (TUI), Swarm User Interfaces
    (SUI) introduce multiple moving robots that enable collaborative motion, providing
    a flexible and extensive physical interaction space and multi-modal interaction
    experiences.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统的有形用户界面（TUI）相比，群体用户界面（SUI）引入了多个移动机器人，实现了协作运动，提供了灵活且广泛的物理交互空间和多模态交互体验。
- en: Researchers in Human-Computer Interaction (HCI) have explored various applications
    of SUI. For instance, SwarmHaptic(Kim and Follmer, [2019](#bib.bib14)) utilized
    small wheeled swarm robots moving on a flat surface to construct a novel tactile
    interface. Rovables(Dementyev et al., [2016](#bib.bib3)) provided a series of
    robots that were capable of autonomous movement on wearable clothing, proposing
    an interaction space for sensing and actuation on wearables. ShapeBots(Suzuki
    et al., [2019](#bib.bib29)) enabled a group of self-deforming robots to individually
    or collectively change their configuration to display information in physical
    space. Additionally, Holobots(Ihara et al., [2023](#bib.bib10)) proposed a mixed-reality
    remote collaboration system augmenting holographic telepresence with synchronized
    mobile robots. Out of academia, SUIs have also demonstrated extensive application
    prospects in education and entertainment scenarios. Sony employs programmable
    small robots called Toio¹¹1https://toio.io/ to engage learners from elementary
    to adult in logical thinking and learning programming Thymo²²2https://www.thymio.org/
    robots provide STEM education for learners of all ages.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 人机交互（HCI）领域的研究者们探索了 SUI 的各种应用。例如，SwarmHaptic（Kim 和 Follmer，[2019](#bib.bib14)）利用在平面上移动的小型轮式群体机器人构建了一种新颖的触觉界面。Rovables（Dementyev
    等，[2016](#bib.bib3)）提供了一系列能够在可穿戴衣物上自主移动的机器人，提出了一种用于可穿戴设备上的感知和驱动的交互空间。ShapeBots（Suzuki
    等，[2019](#bib.bib29)）使一组自我变形的机器人能够单独或集体地改变其配置，以在物理空间中显示信息。此外，Holobots（Ihara 等，[2023](#bib.bib10)）提出了一种混合现实远程协作系统，通过与同步移动机器人增强全息远程呈现。在学术界之外，SUIs
    在教育和娱乐场景中也展示了广泛的应用前景。索尼使用名为 Toio¹¹1https://toio.io/ 的可编程小型机器人来吸引从小学到成人的学习者进行逻辑思维和编程学习，而
    Thymo²²2https://www.thymio.org/ 机器人则为各个年龄段的学习者提供 STEM 教育。
- en: However, most existing SUIs utilize a pre-programmed set of action planning
    rules to execute different interaction tasks during use. For example, although
    Holobots creatively proposed six interaction types for remote collaboration, constrained
    by predetermined programming, they struggled to dynamically generate personalized
    tactile feedback based on users’ flexible needs during actual usage. Thus, a system
    that is capable of understanding and reacting to complex interaction tasks will
    significantly improve the generalizability of interaction behaviors of SUIs in
    these works.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，大多数现有的 SUIs 利用预设的动作规划规则来执行不同的交互任务。例如，尽管 Holobots 创新性地提出了六种远程协作的交互类型，但由于受到预定编程的限制，它们在实际使用中很难根据用户灵活的需求动态生成个性化的触觉反馈。因此，一个能够理解和应对复杂交互任务的系统将显著提高这些工作中
    SUIs 的交互行为的通用性。
- en: 2.2\. Agents for Action Planning
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2\. 动作规划的代理
- en: In the domain of robotics, researchers aim to issue high-level instructions
    to robotic agents. These agents automatically translate the instructions into
    low-level actions for execution by robots, eliminating the need for humans to
    manually program. The Skill Transformer(Huang et al., [2023a](#bib.bib9)), leveraging
    a neural network model based on the Transformer architecture(Vaswani et al., [2017](#bib.bib31)),
    predicts low-level actions for robots, enabling them to accomplish embodied tasks
    of moving objects to specified targets and locations in complex environments.
    With the advent of Large Language Models (LLMs), researchers have sought to harness
    LLMs’ robust natural language understanding capabilities to process generalized,
    natural language-based embodied instructions. For example, March in Chat(Qiao
    et al., [2023](#bib.bib22)) interacts with agents, LLMs, and VLMs to navigate
    daily activity scenes based on vague natural language instructions. VoxPoser(Huang
    et al., [2023b](#bib.bib8)) estimates the potential benefits and losses of objects
    in a scene towards fulfilling an instruction using LLMs, generating a 3D value
    map of the scene to derive the robot’s trajectory.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器人领域，研究人员旨在向机器人代理发出高级指令。这些代理会自动将指令转化为低级动作，以供机器人执行，消除了人工编程的需求。Skill Transformer(Huang
    et al., [2023a](#bib.bib9)) 利用基于Transformer架构的神经网络模型(Vaswani et al., [2017](#bib.bib31))，预测机器人的低级动作，使其能够在复杂环境中完成移动物体到指定目标和位置的任务。随着大型语言模型(LLMs)的出现，研究人员希望利用LLMs强大的自然语言理解能力来处理基于自然语言的广义指令。例如，March
    in Chat(Qiao et al., [2023](#bib.bib22))与代理、LLMs和VLMs互动，根据模糊的自然语言指令导航日常活动场景。VoxPoser(Huang
    et al., [2023b](#bib.bib8)) 使用LLMs估计场景中对象的潜在收益和损失，以完成指令，生成场景的3D价值图，以推导机器人的轨迹。
- en: Researchers have also recognized that collaborative decision-making among multiple
    agents for a robot’s actions can enable adaptation to more complex scenarios compared
    to decisions made by a single agent alone. DiscussNav(Long et al., [2023](#bib.bib18))
    is used to address navigation problems in complex scenes, where robots take each
    step with the involvement of multiple LLM/VLM agents with different specialties,
    enhancing the robots’ generalization ability in navigation.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员还认识到，多个代理的协作决策对于机器人的行动，可以使其适应比单一代理决策更复杂的情境。DiscussNav(Long et al., [2023](#bib.bib18))
    用于解决复杂场景中的导航问题，其中机器人每一步都涉及多个具有不同专长的LLM/VLM代理，增强了机器人在导航中的泛化能力。
- en: Despite existing research has shown feasible performance in action planning
    and robotic control for embodied agents, their validation of task planning for
    embodied tasks has been primarily confined to operational tasks in daily routine
    scenes (Huang et al., [2023a](#bib.bib9), [b](#bib.bib8)) and navigation tasks(Long
    et al., [2023](#bib.bib18)) with less emphasis on other certain genres of task
    scenarios, e.g., fictional narrative settings. Moreover, its interaction planning
    capabilities in user interfaces driven by multiple robots also require validation.
    Exploring the integration of LLM-based agents with SUI will broaden the application
    scenarios and interaction cases for related work in robotics.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管现有研究已显示出在具身任务的动作规划和机器人控制方面的可行性，但其对具身任务的任务规划的验证主要局限于日常例行场景中的操作任务(Huang et al.,
    [2023a](#bib.bib9), [b](#bib.bib8))和导航任务(Long et al., [2023](#bib.bib18))，对其他某些任务场景类型，例如虚构叙事设置，关注较少。此外，多机器人驱动的用户界面中的交互规划能力也需要验证。探索LLM基础的代理与SUI的结合将拓宽相关机器人工作的应用场景和互动案例。
- en: 2.3\. Robots in Tabletop Game
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3\. 桌面游戏中的机器人
- en: In recent years, researchers have explored the application of tangible and swarm
    user interfaces in tabletop games to enhance interactivity and enjoyment.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，研究人员探索了在桌面游戏中应用有形和集群用户界面，以增强互动性和趣味性。
- en: With the emerging trend of robots being small and versatile, more and more robots
    are used as embodied AI players or gadgets in tabletop games. For example, Brock
    et al.(Brock et al., [2021](#bib.bib2)) utilized the robot Haru to simulate the
    behavior of remote human players. Researchers also used robots to serve as robotic
    gadgets in the game, such as creating chess that can move automatically to enable
    novel and compelling interaction experiences(Jariyavajee et al., [2018](#bib.bib11)).
    Sparkybot(Guo et al., [2023](#bib.bib7)) allowed children to use mobile robots
    as different actors in storytelling games to enhance children’s creativity.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 随着机器人日益趋向小型化和多功能化，越来越多的机器人被用作桌面游戏中的具身AI玩家或小工具。例如，Brock等人（Brock et al., [2021](#bib.bib2)）利用机器人Haru模拟远程人类玩家的行为。研究人员还利用机器人作为游戏中的机器人小工具，例如创建可以自动移动的棋盘，以实现新颖且引人入胜的交互体验（Jariyavajee
    et al., [2018](#bib.bib11)）。Sparkybot（Guo et al., [2023](#bib.bib7)）允许儿童在讲故事游戏中使用移动机器人作为不同的角色，从而提升儿童的创造力。
- en: These works, that use SUI for tabletop games, provide rich user interaction
    spaces. However, the action planning for robots in these studies still relies
    on pre-programmed rules, which makes it challenging to execute the complex interaction
    tasks in tabletop games, such as understanding and reacting to complex game narratives,
    improvised decisions of players, or emotional expressions from players. In this
    work, we aimed to leverage LLM-based agents to assist action planning for SUI,
    in order to execute complex interaction behaviors of the gadgets in tabletop games.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 使用SUI进行桌面游戏的这些工作提供了丰富的用户交互空间。然而，这些研究中的机器人行动规划仍然依赖于预编程的规则，这使得执行桌面游戏中的复杂交互任务变得具有挑战性，例如理解和反应复杂的游戏叙事、玩家的即兴决策或玩家的情感表达。在这项工作中，我们旨在利用基于LLM的智能体来辅助SUI的行动规划，以执行桌面游戏中小工具的复杂交互行为。
- en: 3\. System Architecture of AI-Gaget Kit
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. AI-Gadget Kit的系统架构
- en: 'The system architecture of AI-Gadget Kit, shown in Figure[2](#S3.F2 "Figure
    2 ‣ 3\. System Architecture of AI-Gaget Kit ‣ AI-Gadget Kit: Integrating Swarm
    User Interfaces with LLM-driven Agents for Rich Tabletop Game Applications"),
    consists of an SUI platform, a localization system, a server, and a LLM-based
    multi-agent system. The SUI platform includes multiple independent robots, which
    are used to actuate various gadget behaviors in tabletop games. The localization
    system comprises a camera and multiple on-robot markers, used to obtain the position
    and orientation of each robot. The server obtains users’ text or verbal input
    commands, as well as robots’ position and orientation data, and then sends them
    to the LLM-based multi-agent system for information processing. The server also
    receives the actuations generated by the multi-agent system, playing sound effects,
    or sending action sequences to the robots in the SUI platform. The LLM-based multi-agent
    system is responsible for the execution of the core game interactions. Based on
    the game’s rules and knowledge, the multi-agent system responds to user commands,
    reasons the gadget behaviors in the game, and then generates the action sequences
    to control the SUI robots.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 'AI-Gadget Kit的系统架构如图[2](#S3.F2 "Figure 2 ‣ 3\. System Architecture of AI-Gaget
    Kit ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents
    for Rich Tabletop Game Applications")所示，包括一个SUI平台、一个定位系统、一个服务器和一个基于LLM的多智能体系统。SUI平台包含多个独立的机器人，用于在桌面游戏中驱动各种小工具行为。定位系统包括一个摄像头和多个机器人上的标记，用于获取每个机器人的位置和方向。服务器接收用户的文本或语音输入命令，以及机器人的位置和方向数据，然后将这些信息发送到基于LLM的多智能体系统进行处理。服务器还接收多智能体系统生成的执行指令，播放声音效果，或将动作序列发送到SUI平台中的机器人。基于LLM的多智能体系统负责核心游戏交互的执行。根据游戏规则和知识，多智能体系统响应用户命令，推理游戏中的小工具行为，然后生成控制SUI机器人的动作序列。'
- en: In this project, we utilized a 1m*1m tabletop as the interaction space. The
    space was divided into a 30*30 coordinate system, with the east and north directions
    serving as the positive directions of x and y axes, respectively. We used Sony’s
    Toio robots as the SUI platform. Each individual robot has dimensions of 3.2*3.2*2.5cm.
    We used a PC as the server, which communicates with Toio robots via Bluetooth
    and communicates with the LLM via WiFi. In our localization system, we employed
    an imx415 network IP camera, positioned 1m above the tabletop, and we used ArUco
    codes as the localization markers on the robots. The server retrieves the video
    stream from the camera using the RTSP protocol and uses the Python OpenCV to track
    the position and orientation of each robot. We developed the multi-agent system
    based on GPT4 LLM. The design of the multi-agent system is introduced as follows.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我们利用了一个 1m*1m 的桌面作为交互空间。该空间被划分为 30*30 的坐标系统，其中东向和北向分别作为 x 和 y 轴的正方向。我们使用了索尼的
    Toio 机器人作为 SUI 平台。每个单独的机器人尺寸为 3.2*3.2*2.5cm。我们使用了一台 PC 作为服务器，通过蓝牙与 Toio 机器人通信，并通过
    WiFi 与 LLM 进行通信。在我们的定位系统中，我们使用了一个 imx415 网络 IP 摄像头，摄像头位置在桌面上方 1 米处，我们使用 ArUco
    码作为机器人上的定位标记。服务器使用 RTSP 协议从摄像头获取视频流，并使用 Python OpenCV 跟踪每个机器人的位置和方向。我们基于 GPT4
    LLM 开发了多智能体系统。多智能体系统的设计如下介绍。
- en: '![Refer to caption](img/78a4871fae79948792920f1a2fedff80.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/78a4871fae79948792920f1a2fedff80.png)'
- en: Figure 2\. System Architecture of AI-Gadget Kit.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2\. AI-Gadget Kit 的系统架构。
- en: 4\. Multi-agent system
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 多智能体系统
- en: In the AI-Gadget Kit, we utilized a multi-agent system to compute the core interaction
    of the game. Based on the rules, and knowledge of the game, the system responds
    to the user’s command, reasons the gadget behaviors within the game, and then
    generates the action sequences to control the SUI robots.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在 AI-Gadget Kit 中，我们利用了多智能体系统来计算游戏的核心交互。根据规则和游戏知识，该系统响应用户的命令，推理游戏中的设备行为，然后生成控制
    SUI 机器人的动作序列。
- en: To build the multi-agent system, we first defined a set of meta-actions for
    each single robot, and then designed a two-agent system, including a Coordinator
    agent and a Controller agent, to learn and use those meta-actions for complex
    motion planning. We also designed a set of add-on prompts, including prompts for
    Interaction behavior planning and Interaction relationship planning, to enhance
    the agents to understand and react to complex interactions during the game.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了建立多智能体系统，我们首先为每个单独的机器人定义了一组元动作，然后设计了一个包括协调员智能体和控制器智能体的双智能体系统，以学习和使用这些元动作进行复杂的运动规划。我们还设计了一组附加提示，包括用于交互行为规划和交互关系规划的提示，以增强智能体在游戏过程中理解和响应复杂交互的能力。
- en: '![Refer to caption](img/e7a626717ec12a88e880af8a3749fe5d.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e7a626717ec12a88e880af8a3749fe5d.png)'
- en: Figure 3\. Design space for SUI action planning in tabletop game scenarios through
    our kit. The kit includes a two-agent system(d) that can generate action sequences
    for gadgets to complete interaction tasks based on eight meta-actions (a), four
    types of interaction behaviors (b), and four types of interaction relationships
    (c).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3\. 通过我们的工具包在桌面游戏场景中进行 SUI 动作规划的设计空间。该工具包包括一个双智能体系统（d），可以基于八个元动作（a）、四种交互行为类型（b）和四种交互关系类型（c）生成完成交互任务的设备动作序列。
- en: 4.1\. Meta-action for Individual Robot
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1\. 单个机器人的元动作
- en: 'To leverage the LLM-based agents for planning and generating complex actions
    for our SUI, we first defined the primitive movement patterns of an individual
    robot, i.e., meta-actions (Figure [3](#S4.F3 "Figure 3 ‣ 4\. Multi-agent system
    ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents for
    Rich Tabletop Game Applications")a). An individual Toio robot moves by controlling
    the motors of the two wheels. Thus, in this work, we controlled the robot’s meta-action
    by controlling the rotation direction (clockwise by default or anti-clockwise),
    speed (three levels - 10, 20, or 30³³3Speed values in Toio platform), and the
    duration (x seconds) of each motor.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为了利用基于 LLM 的智能体进行规划和生成复杂动作，我们首先定义了单个机器人原始运动模式，即元动作（图 [3](#S4.F3 "图 3 ‣ 4. 多智能体系统
    ‣ AI-Gadget Kit：将群体用户界面与 LLM 驱动的智能体集成以实现丰富的桌面游戏应用")a）。单个 Toio 机器人通过控制两个轮子的电机来移动。因此，在这项工作中，我们通过控制旋转方向（默认顺时针或逆时针）、速度（三级
    - 10、20 或 30³³3 速度值在 Toio 平台上）和每个电机的持续时间（x 秒）来控制机器人的元动作。
- en: 'We categorized the robot’s meta-actions into two types of movements: translation
    and rotation, defined as follows:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将机器人的元动作分为两种类型的运动：平移和旋转，定义如下：
- en: •
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Rotation:'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 旋转：
- en: –
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: 'Rotation A: The robot rotates around its center, by spinning its wheels in
    opposite directions at the same speed for a specified seconds, achieving a precise
    angle of rotation.'
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 旋转 A：机器人围绕其中心旋转，通过以相同速度相反方向旋转轮子指定的秒数，实现精确的旋转角度。
- en: –
  id: totrans-53
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: 'Rotation B: The robot rotates around one side of itself, by spinning only one
    wheel for a specified seconds, achieving a specific angle of rotation.'
  id: totrans-54
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 旋转 B：机器人围绕自身的一侧旋转，通过仅旋转一个轮子指定的秒数，实现特定的旋转角度。
- en: •
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Translation: The robot adjusts its orientation to the desired direction through
    Rotation A, followed by spinning both wheels in the same direction and speed for
    a few seconds to achieve linear translation over a specific distance.'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 平移：机器人通过旋转 A 调整其朝向，然后在几秒钟内以相同方向和速度旋转两个轮子，实现特定距离的线性平移。
- en: During each movement, the server determines the duration based on a simple calculation
    of expected translation or rotation displacement and official kinematic data⁴⁴4https://toio.github.io/toio-spec/en/docs/hardware_components.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在每次运动中，服务器根据预期的平移或旋转位移和官方运动学数据⁴⁴4https://toio.github.io/toio-spec/en/docs/hardware_components进行简单计算来确定持续时间。
- en: 'Furthermore, considering interactions between multiple robots, we designed
    another type of meta-action to adjust their relative orientations, including face-to-face,
    back-to-back, face-to-back, parallel, and counter-parallel, defined and illustrated
    in Figure [3](#S4.F3 "Figure 3 ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating
    Swarm User Interfaces with LLM-driven Agents for Rich Tabletop Game Applications")a.
    The two robots conducting one of these meta-actions adjust their orientations
    by executing Rotation A for a time.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '此外，考虑到多个机器人之间的交互，我们设计了另一种类型的元动作来调整它们的相对方向，包括面对面、背对背、面对背、平行和反向平行，这些都在图 [3](#S4.F3
    "Figure 3 ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces
    with LLM-driven Agents for Rich Tabletop Game Applications")a 中定义和说明。这两台机器人通过执行旋转
    A 一段时间来调整其方向。'
- en: By repeatedly calling and combining these three types of meta-actions with custom
    parameters, the agents in the AI-Gadget kit could generate multiple actions in
    sequences to facilitate the complex motion planning of these robots in SUI.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 通过反复调用和结合这三种类型的元动作与自定义参数，AI-Gadget 套件中的代理能够生成多个动作序列，以便于这些机器人在 SUI 中进行复杂的运动规划。
- en: 4.2\. Complex Motion Planning
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2\. 复杂运动规划
- en: 'To facilitate the complex motion planning for SUI to execute the gadget behaviors
    in tabletop games, we developed an LLM-based two-agent system, that aims to understand
    and react to the game contexts and then generate the action sequences for the
    robots (Figure [3](#S4.F3 "Figure 3 ‣ 4\. Multi-agent system ‣ AI-Gadget Kit:
    Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop Game
    Applications")d). Specifically, we proposed two agents in the system with expert
    prompts: Coordinator and Controller:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '为了简化 SUI 执行桌面游戏中小玩意儿行为的复杂运动规划，我们开发了一个基于 LLM 的双代理系统，旨在理解和响应游戏环境，然后生成机器人的动作序列（见图
    [3](#S4.F3 "Figure 3 ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm
    User Interfaces with LLM-driven Agents for Rich Tabletop Game Applications")d）。具体而言，我们在系统中提出了两个专家提示的代理：协调者和控制器：'
- en: (1) Coordinator Agent. The operation in a tabletop game typically involves the
    user’s commands and the processing of context information. Taking chess as an
    example, if the user inputs a command of ”move the queen to A1”, the execution
    of this command involves the actual movement of the queen, and processing of context
    information such as the dimensions of the chessboard, the queen’s movement rules,
    and whether an opponent’s piece can be captured. Hence, we designed a Coordinator
    agent to respond by processing the players’ commands and the game context information,
    then reasoning the commands for each gadget within this interaction step. In the
    prompts for Coordinator, we asked the agent to act as administrator, coordinator,
    and referee in the game. We added the description of a series of duties to the
    prompts, such as explaining rules, coordinating actions, and updating game states.
    We also inputted the game’s environmental settings to the prompts, including the
    size of the map and the coordinate system.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: (1) 协调员代理。桌面游戏的操作通常涉及用户的命令和上下文信息的处理。以国际象棋为例，如果用户输入“将皇后移动到A1”的命令，该命令的执行涉及皇后的实际移动，以及棋盘的尺寸、皇后的移动规则和是否可以吃掉对方棋子的上下文信息的处理。因此，我们设计了一个协调员代理，通过处理玩家的命令和游戏上下文信息来响应，然后推理每个小工具在这一交互步骤中的命令。在协调员的提示中，我们要求代理在游戏中担任管理员、协调员和裁判。我们在提示中添加了一系列职责的描述，如解释规则、协调行动和更新游戏状态。我们还将游戏的环境设置输入到提示中，包括地图的大小和坐标系统。
- en: Note that, to allow the Coordinator agent to focus on game operations, we employed
    a ”reality-agnostic” approach. Specifically, the Coordinator only facilitates
    the execution of the game, without dealing with the physical parameters of the
    SUI robots, such as their locations or next movements. We aim to use this method
    to enhance the Coordinator’s understanding and reaction capabilities through efficient
    prompting of LLM. The prompts of the Coordinator are detailed in Supplementary
    Material.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，为了使协调员代理能够专注于游戏操作，我们采用了一种“与现实无关”的方法。具体而言，协调员仅仅促进游戏的执行，而不涉及SUI机器人的物理参数，如它们的位置或下一步动作。我们旨在通过高效提示LLM来提高协调员的理解和反应能力。协调员的提示详细信息见补充材料。
- en: '(2) Controller Agent. To use SUI in tabletop games, we require the robots to
    plan their motion according to the gadget behaviors in the game. To this end,
    we proposed a Controller agent in our system, which is responsible for embodying
    characters and generating the action sequence of each robot that represents these
    characters. The Controller agent is designed to gather information from two sources:
    the gadget commands outputted by the Coordinator agent, along with the physical
    location data of the robots at the given time. Next, we asked the Controller to
    generate the action sequences for the robots using the meta-actions, while simultaneously
    considering the logical flow of the game and the gameplay experience.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: (2) 控制器代理。为了在桌面游戏中使用SUI，我们要求机器人根据游戏中的小工具行为来规划它们的运动。为此，我们在系统中提出了一个控制器代理，它负责体现角色并生成每个代表这些角色的机器人的动作序列。控制器代理被设计为从两个来源获取信息：协调员代理输出的小工具命令，以及给定时间的机器人物理位置数据。接下来，我们要求控制器使用元动作生成机器人的动作序列，同时考虑游戏的逻辑流程和游戏体验。
- en: 'To ensure these action sequences are properly formatted for the robot actuation,
    we designed a Chain-of-Thought (CoT) prompting (Wei et al., [2022](#bib.bib33))
    for the Controller. The CoT prompting of the Controller unfolds as follows: (1)
    Output a textual description of the action sequence of the robots that will move,
    along with the current location information of these robots; (2) Generate an action
    sequence based on the aforementioned textural description in the form of a Python
    dictionary. This Python dictionary encompasses ID for the robots, as well as details
    for each subsequent meta-action, including destination locations/angles, speeds,
    types of movement, etc. Furthermore, we utilized in-context learning and few-shot
    learning approaches(Liu et al., [2021](#bib.bib17)), which provide specific examples
    in the prompts to demonstrate the process of the aforementioned CoT prompting,
    to assist the agent in effectively learning how to generate and plan the motion
    sequences.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为确保这些动作序列正确格式化以便机器人执行，我们为控制器设计了链式思维（Chain-of-Thought, CoT）提示（Wei et al., [2022](#bib.bib33)）。控制器的CoT提示展开如下：（1）输出将要移动的机器人的动作序列的文本描述，以及这些机器人的当前位置；（2）基于上述文本描述生成一个动作序列，形式为Python字典。这个Python字典包括机器人的ID，以及每个后续元动作的详细信息，包括目的地位置/角度、速度、运动类型等。此外，我们利用了上下文学习和少量样本学习方法（Liu
    et al., [2021](#bib.bib17)），通过在提示中提供具体示例来展示上述CoT提示的过程，以帮助代理有效地学习如何生成和规划运动序列。
- en: During use, users first input the game’s description and rules to the system,
    in order to declare the game to play. The system then understands and initiates
    the game based on the inherent knowledge of LLMs. Then, users continuously input
    the game commands to the system to engage with the game. The two agents in the
    system analyze these commands and the ongoing contextual information of the game,
    reasoning the gadget behaviors in the game, and then generating the action sequences
    to actuate the motion of SUI robots, embodying the interactions of the gadgets
    with users.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用过程中，用户首先将游戏的描述和规则输入系统，以便声明要玩的游戏。系统随后根据大型语言模型（LLM）的固有知识理解并启动游戏。然后，用户不断向系统输入游戏指令以参与游戏。系统中的两个代理分析这些指令以及游戏的持续上下文信息，推理游戏中设备的行为，然后生成动作序列以驱动SUI机器人，体现设备与用户的交互。
- en: '![Refer to caption](img/b95d3e75026b66e3e7fd855d573f8093.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/b95d3e75026b66e3e7fd855d573f8093.png)'
- en: 'Figure 4\. An example using our kit: (a) Users can declare the game they are
    playing through an introduction and rules entry. (b) Then, they input game commands
    based on the scenario to interact with the gadget. The gadget generates corresponding
    action sequences based on a two-agent system within the kit.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图4\. 使用我们工具包的示例：（a）用户可以通过介绍和规则输入来声明他们正在玩的游戏。（b）然后，他们根据场景输入游戏指令与设备进行交互。设备基于工具包中的双代理系统生成相应的动作序列。
- en: 'Here we presented a specific case of using the two-agent system to play a chess
    game. The comprehensive process of the interaction was illustrated in Figure [4](#S4.F4
    "Figure 4 ‣ 4.2\. Complex Motion Planning ‣ 4\. Multi-agent system ‣ AI-Gadget
    Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop
    Game Applications"), including the initiation step of the game and a typical step
    during one round of the game. In the initiation step, the user first inputted
    the game name and a piece of introduction to the system (see Supplementary Material).
    The Coordinator then initialized the game based on the user’s input and outputted
    the response as shown in Figure [4](#S4.F4 "Figure 4 ‣ 4.2\. Complex Motion Planning
    ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with
    LLM-driven Agents for Rich Tabletop Game Applications")a. Note that in this step,
    since the user did not input any specific game commands, the Controller agent
    did not generate specific action sequences, either. Subsequently, as the game
    started, the user continuously gave commands to the system. For instance, in the
    first round, the user inputted a command: ”Move the pawn from d2 to d4”. Next,
    the Coordinator responded to the command and informed the Controller of the gadget
    behavior of the pawn actuated by the user, as shown in the middle block in [4](#S4.F4
    "Figure 4 ‣ 4.2\. Complex Motion Planning ‣ 4\. Multi-agent system ‣ AI-Gadget
    Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop
    Game Applications")b. The Controlled then received the gadget behavior of the
    pawn, along with the actual location data (shown in [4](#S4.F4 "Figure 4 ‣ 4.2\.
    Complex Motion Planning ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating
    Swarm User Interfaces with LLM-driven Agents for Rich Tabletop Game Applications")c)
    of the robot that represented the pawn gadget, proceeding to generate the corresponding
    action sequence for the pawn robot through the CoT process. The output action
    sequence of the pawn robot is shown in the right block in [4](#S4.F4 "Figure 4
    ‣ 4.2\. Complex Motion Planning ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating
    Swarm User Interfaces with LLM-driven Agents for Rich Tabletop Game Applications")b.
    The server in the system then decoded the action sequence from the Controller,
    sent the motion commands to the pawn gadget, and then actuated the movement of
    the pawn gadget, shown in [4](#S4.F4 "Figure 4 ‣ 4.2\. Complex Motion Planning
    ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with
    LLM-driven Agents for Rich Tabletop Game Applications")d.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '在这里，我们展示了一个使用双代理系统下棋的具体案例。互动的全过程如图[4](#S4.F4 "Figure 4 ‣ 4.2\. Complex Motion
    Planning ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces
    with LLM-driven Agents for Rich Tabletop Game Applications")所示，包括游戏的启动步骤和游戏中一轮的典型步骤。在启动步骤中，用户首先输入了游戏名称和系统介绍（见补充材料）。然后，协调器根据用户输入初始化游戏，并输出如图[4](#S4.F4
    "Figure 4 ‣ 4.2\. Complex Motion Planning ‣ 4\. Multi-agent system ‣ AI-Gadget
    Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop
    Game Applications")a所示的响应。请注意，在此步骤中，由于用户没有输入任何具体的游戏指令，控制器代理也没有生成具体的动作序列。随后，随着游戏的开始，用户不断向系统发出指令。例如，在第一轮中，用户输入了一个指令：“将兵从d2移动到d4”。接下来，协调器响应了该指令，并通知控制器用户驱动的兵的设备行为，如图[4](#S4.F4
    "Figure 4 ‣ 4.2\. Complex Motion Planning ‣ 4\. Multi-agent system ‣ AI-Gadget
    Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop
    Game Applications")b中间块所示。控制器接收了兵的设备行为，以及实际位置数据（如图[4](#S4.F4 "Figure 4 ‣ 4.2\.
    Complex Motion Planning ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating
    Swarm User Interfaces with LLM-driven Agents for Rich Tabletop Game Applications")c所示）的机器人，随后通过CoT过程生成了相应的兵机器人动作序列。兵机器人输出的动作序列如图[4](#S4.F4
    "Figure 4 ‣ 4.2\. Complex Motion Planning ‣ 4\. Multi-agent system ‣ AI-Gadget
    Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop
    Game Applications")b右块所示。系统中的服务器随后解码了控制器的动作序列，向兵设备发送了运动指令，然后驱动兵设备的移动，如图[4](#S4.F4
    "Figure 4 ‣ 4.2\. Complex Motion Planning ‣ 4\. Multi-agent system ‣ AI-Gadget
    Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop
    Game Applications")d所示。'
- en: 4.3\. Interactive Behavior Planning
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3\. 互动行为规划
- en: Generally, in the context of utilizing SUI for tabletop games, depending on
    the specific game scenario, SUI often needs to control the movements of robots
    and translate various game operations into tangible interactive behaviors(Nakagaki
    et al., [2020](#bib.bib20)). However, in practice, we have found that due to the
    complexity and specificity of various interactive behaviors, the agents in our
    system, particularly the Controller, may not be able to rely solely on the generic
    prompts to realize all of these tangible interactive behaviors. To address this
    challenge, we have enhanced the Controller’s capability by incorporating several
    sets of additional prompts (add-on prompts) following a one/few-shot learning
    scheme. This approach aids the Controller in comprehending certain specific robotic
    operations (abilities) applied to different contexts. We anticipate that these
    add-on prompts will optimize the system’s ability to generate action sequences
    for Gadgets across various game scenarios.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，在利用SUI进行桌面游戏的背景下，根据具体的游戏场景，SUI通常需要控制机器人的运动，并将各种游戏操作转化为具体的互动行为（Nakagaki等人，[2020](#bib.bib20)）。然而，实际上，我们发现由于各种互动行为的复杂性和特异性，我们系统中的代理，特别是控制器，可能无法仅凭通用提示实现所有这些具体的互动行为。为应对这一挑战，我们通过引入多个额外提示（附加提示），采用一/少样本学习方案，增强了控制器的能力。这种方法帮助控制器理解应用于不同背景的特定机器人操作（能力）。我们预期这些附加提示将优化系统在各种游戏场景中为Gadgets生成动作序列的能力。
- en: To determine which interactive behaviors required the design of additional prompts,
    we referenced past work in SUI (Nakagaki et al., [2020](#bib.bib20); Suzuki et al.,
    [2019](#bib.bib29); Ihara et al., [2023](#bib.bib10); Guo et al., [2023](#bib.bib7);
    Peng et al., [2020](#bib.bib21); Yu et al., [2023](#bib.bib35); Li et al., [2022](#bib.bib16))
    and recruited five designers with a background in Human-Computer Interaction (HCI)
    and experience in tabletop games for an informal interview and brainstorming session.
    During this process, we identified four common types of interaction behavior related
    to Gadget operations in tabletop games, including Objective Actuation, Symbol
    Visualization, Non-verbal Expression, and Scene Interaction. After that, we designed
    additional prompts for the Controller based on each type of interaction behavior,
    as detailed below.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 为确定需要设计额外提示的互动行为，我们参考了过去在SUI领域的工作（Nakagaki等人，[2020](#bib.bib20)；Suzuki等人，[2019](#bib.bib29)；Ihara等人，[2023](#bib.bib10)；Guo等人，[2023](#bib.bib7)；Peng等人，[2020](#bib.bib21)；Yu等人，[2023](#bib.bib35)；Li等人，[2022](#bib.bib16)），并招募了五名具有人机交互（HCI）背景和桌面游戏经验的设计师进行非正式访谈和头脑风暴。在此过程中，我们确定了与Gadget操作相关的四种常见互动行为类型，包括目标驱动、符号可视化、非语言表达和场景互动。之后，我们基于每种互动行为类型为控制器设计了额外的提示，具体如下。
- en: 4.3.1\. Object Actuation
  id: totrans-73
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.1\. 物体驱动
- en: In tabletop games based on SUI, the ability of the system to automatically manipulate
    objects on the table using robotic gadgets (Ihara et al., [2023](#bib.bib10))
    enables the automation of game prop operations or simulates interactions between
    players and AI opponents or remote players. To this end, we added a set of additional
    prompts for the controller to assist in generating action sequences for our Gadgets
    to ”actuate objects”. In these prompts, we specify that the Controller should
    focus on the speed and trajectory of robot movement to achieve object movement
    along a prescribed path and simulate the properties of objects, such as weight.
    We also included a specific example in the prompts, which involves the task of
    pushing a heavy box to a designated location and the expected action sequence
    generated by the Controller.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于SUI的桌面游戏中，系统使用机器人设备（Ihara等人，[2023](#bib.bib10)）自动操控桌面上的物体，这使得游戏道具操作的自动化成为可能，或模拟玩家与AI对手或远程玩家之间的互动。为此，我们为控制器增加了一组额外的提示，以协助生成Gadgets的动作序列来“驱动物体”。在这些提示中，我们指定控制器应关注机器人运动的速度和轨迹，以实现物体沿着规定路径的移动，并模拟物体的属性，如重量。我们还在提示中包含了一个具体示例，涉及将重物推送到指定位置的任务以及控制器生成的预期动作序列。
- en: 'After incorporating the add-on prompt for object actuation into the Controller’s
    original prompt, we test the after-modified effectiveness by using the Controller
    to actuate the Gadgets in scenarios involving pushing heavy objects. We tested
    the effectiveness of using the controller to actuate the Gadgets in pushing light
    objects. For instance, it was stipulated that the Gadgets start at a position
    (1, 1) and need to kick a light plastic soccer ball located at (3, 3). The outcome
    of the Gadget’s movement and the action sequences generated by the controller
    are depicted in Figure [5](#S4.F5 "Figure 5 ‣ 4.3.1\. Object Actuation ‣ 4.3\.
    Interactive Behavior Planning ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating
    Swarm User Interfaces with LLM-driven Agents for Rich Tabletop Game Applications")a-b.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在将附加提示集成到控制器的原始提示后，我们通过使用控制器在推动重物的场景中驱动小工具来测试修改后的效果。我们还测试了使用控制器驱动小工具推动轻物体的效果。例如，规定小工具从位置
    (1, 1) 开始，需要踢一个位于 (3, 3) 的轻质塑料足球。小工具的移动结果和控制器生成的动作序列如图 [5](#S4.F5 "图 5 ‣ 4.3.1\.
    物体驱动 ‣ 4.3\. 互动行为规划 ‣ 4\. 多智能体系统 ‣ AI-Gadget 套件：将集群用户界面与基于 LLM 的代理整合应用于丰富的桌面游戏")a-b
    所示。
- en: 'Also, in another example, two gadgets are initially located at (1, 1) and (3,
    1), and we require the gadgets to push the two very heavy doors to (1, 4) (3,
    4) from (1, 3) and (3, 3). The demonstration of the movements of the Gadgets and
    the action sequence generated by the Controller is shown in Figure [5](#S4.F5
    "Figure 5 ‣ 4.3.1\. Object Actuation ‣ 4.3\. Interactive Behavior Planning ‣ 4\.
    Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven
    Agents for Rich Tabletop Game Applications")c-d.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，在另一个示例中，两个小工具最初位于 (1, 1) 和 (3, 1)，我们要求这些小工具将两个非常重的门从 (1, 3) 和 (3, 3) 推到 (1,
    4) 和 (3, 4)。小工具的运动演示和控制器生成的动作序列如图 [5](#S4.F5 "图 5 ‣ 4.3.1\. 物体驱动 ‣ 4.3\. 互动行为规划
    ‣ 4\. 多智能体系统 ‣ AI-Gadget 套件：将集群用户界面与基于 LLM 的代理整合应用于丰富的桌面游戏")c-d 所示。
- en: '![Refer to caption](img/ea718382e3920a7aac8a36a3d2db1a96.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/ea718382e3920a7aac8a36a3d2db1a96.png)'
- en: 'Figure 5\. The gadget starts at position (1,1) and needs to kick a light plastic
    soccer ball located at (3,3). a) Gadget: Moves northeast at speed 3 to approach
    the soccer ball’s location b)Kicks the soccer ball, simulating the action by moving
    east to (3,3). c-d) Two gadgets open a door together by moving towards it.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5\. 小工具从位置 (1,1) 开始，需要踢一个位于 (3,3) 的轻质塑料足球。 a) 小工具：以速度 3 向东北移动接近足球的位置 b) 踢足球，通过向东移动到
    (3,3) 来模拟动作。 c-d) 两个小工具通过移动到门前一起开门。
- en: 4.3.2\. Symbol Visualization
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.2\. 符号可视化
- en: 'In SUI-based tabletop games, the system’s ability to use robotic gadgets to
    visualize certain graphic symbols can enhance the presentation of textual or graphical
    information in the game [74]. For this purpose, we added a set of add-on prompts
    for the Controller to assist in generating action sequences for swarm robots (the
    Gadgets) for Symbol Visualization. Specifically, we designed two methods for visualizing
    graphic symbols: ”trajectory tracing” and ”robotic formation,” along with corresponding
    prompts for each method. To make this visualization function more consistent,
    we also added certain rules, such as ”not inverting the symbols vertically” and
    ”using uppercase letters for English alphabets”. We also provided an example for
    each visualization method in the add-on prompt, including a description of a natural
    language task for visualizing the letters ”HCI,” along with the expected action
    sequence the Controller should generate. Detailed prompts are provided in the
    Supplementary Material.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于 SUI 的桌面游戏中，系统使用机器人小工具可视化某些图形符号的能力可以增强游戏中文本或图形信息的呈现 [74]。为此，我们为控制器添加了一组附加提示，帮助生成集群机器人（小工具）的动作序列以进行符号可视化。具体而言，我们设计了两种可视化图形符号的方法：“轨迹追踪”和“机器人队形”，并为每种方法提供了相应的提示。为了使这种可视化功能更一致，我们还添加了一些规则，例如“不要垂直翻转符号”和“对英文字母使用大写字母”。我们还为每种可视化方法提供了一个示例，包含可视化字母“HCI”的自然语言任务描述，以及控制器应生成的预期动作序列。详细提示请参见补充材料。
- en: 'After incorporating the add-on prompt for symbol visualization into the Controller,
    we tested its effectiveness by using the Controller to drive certain Gadgets in
    visualizing ”UIST.” For the ”tracing” method, the Controller successfully determined
    to utilize four Gadgets and generated appropriate trajectories of movement for
    each Gadget. The trajectory patterns and the action sequences that formed these
    trajectories are illustrated in Figure [6](#S4.F6 "Figure 6 ‣ 4.3.2\. Symbol Visualization
    ‣ 4.3\. Interactive Behavior Planning ‣ 4\. Multi-agent system ‣ AI-Gadget Kit:
    Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop Game
    Applications")a-g.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '在将符号可视化的附加提示整合到控制器后，我们通过使用控制器驱动某些小工具来测试其有效性，以可视化“UIST”。对于“跟踪”方法，控制器成功决定使用四个小工具，并为每个小工具生成了适当的运动轨迹。这些轨迹模式及形成这些轨迹的动作序列在图
    [6](#S4.F6 "Figure 6 ‣ 4.3.2\. Symbol Visualization ‣ 4.3\. Interactive Behavior
    Planning ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces
    with LLM-driven Agents for Rich Tabletop Game Applications")a-g 中进行了说明。'
- en: 'For the ”formation” method, the Controller determined to utilize multiple robots
    to separately form the shapes of the letters ”H” and ”I.” The effectiveness of
    the robotic forming these letters and the action sequences used are illustrated
    in Figure [6](#S4.F6 "Figure 6 ‣ 4.3.2\. Symbol Visualization ‣ 4.3\. Interactive
    Behavior Planning ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm
    User Interfaces with LLM-driven Agents for Rich Tabletop Game Applications")h-i.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '对于“形成”方法，控制器决定使用多个机器人分别形成字母“H”和“I”的形状。这些机器人形成字母的效果及使用的动作序列在图 [6](#S4.F6 "Figure
    6 ‣ 4.3.2\. Symbol Visualization ‣ 4.3\. Interactive Behavior Planning ‣ 4\. Multi-agent
    system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents
    for Rich Tabletop Game Applications")h-i 中进行了说明。'
- en: '![Refer to caption](img/70d8fcb8dabab63f3a0562bb8b0c0219.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/70d8fcb8dabab63f3a0562bb8b0c0219.png)'
- en: Figure 6\. The gadgets were asked to present the word ’UIST’ or ’HI’. a-d) Agents
    generated trajectories of four gadgets, which were arranged to form ’U’, ’I’,
    ’S’. e-f) A detailed demonstration of how one of the gadgets presents the letter
    ”T” through its movement trajectory. h-i) Agents make each letter composed of
    multiple gadgets, using 7 and 3 gadgets to form the letters ’H’ and ’I’ respectively.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6\. 小工具被要求呈现单词“UIST”或“HI”。a-d) 代理生成了四个小工具的轨迹，这些小工具被排列成“U”、“I”、“S”。e-f) 详细演示了其中一个小工具通过其运动轨迹呈现字母“T”的过程。h-i)
    代理通过多个小工具组成每个字母，使用 7 个和 3 个小工具分别形成字母“H”和“I”。
- en: 4.3.3\. Non-Verbal Expression
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.3\. 非语言表达
- en: 'In SUI-based tabletop games, the ability of the system to use robotic gadgets
    for non-verbal expressions, such as displaying characters’ emotions, can significantly
    enhance the narrative expressiveness of tabletop games (Peng et al., [2020](#bib.bib21)).
    To this end, we incorporate a set of add-on prompts for the Controller to assist
    in generating action sequences for swarm robots for ”non-verbal expression.” Specifically,
    we designed two methods of non-verbal expression: ”mood expression” and ”social
    expression,” along with corresponding prompts for each method. We also provided
    an example for each method in the prompts, along with the expected action sequences
    the Controller should generate. The examples include asking the Gadget to express
    sadness and a greeting between two Gadgets. Related prompts are detailed in the
    Supplementary Material.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于 SUI 的桌面游戏中，系统利用机器人小工具进行非语言表达的能力，例如展示角色的情感，可以显著增强桌面游戏的叙事表现力（Peng et al.,
    [2020](#bib.bib21)）。为此，我们为控制器整合了一组附加提示，以协助生成用于“非语言表达”的群体机器人动作序列。具体来说，我们设计了两种非语言表达的方法：“情绪表达”和“社交表达”，并为每种方法提供了相应的提示。我们还在提示中提供了每种方法的示例，以及控制器应生成的预期动作序列。这些示例包括要求小工具表达悲伤和两个小工具之间的问候。相关提示详见补充材料。
- en: 'After incorporating the add-on prompt for non-verbal expression into the Controller,
    we first tested the effectiveness of using the controller to drive a single Gadget
    to express excitement. The demonstration of this expression and the corresponding
    action sequences are illustrated in the Figure [7](#S4.F7 "Figure 7 ‣ 4.3.3\.
    Non-Verbal Expression ‣ 4.3\. Interactive Behavior Planning ‣ 4\. Multi-agent
    system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents
    for Rich Tabletop Game Applications")a-b.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '在将非语言表达的附加提示融入控制器后，我们首先测试了使用控制器驱动单个设备表现兴奋的效果。这种表现的演示及其对应的行动序列在图[7](#S4.F7 "Figure
    7 ‣ 4.3.3\. Non-Verbal Expression ‣ 4.3\. Interactive Behavior Planning ‣ 4\.
    Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven
    Agents for Rich Tabletop Game Applications")a-b中说明。'
- en: 'Next, we tested the effectiveness of using the controller to drive two Gadgets
    to express a disputing social behavior. The demonstration of this expression and
    the corresponding action sequences are illustrated in the Figure [7](#S4.F7 "Figure
    7 ‣ 4.3.3\. Non-Verbal Expression ‣ 4.3\. Interactive Behavior Planning ‣ 4\.
    Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven
    Agents for Rich Tabletop Game Applications")c-e.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '接下来，我们测试了使用控制器驱动两个设备表现争论社交行为的效果。这种表现的演示及其对应的行动序列在图[7](#S4.F7 "Figure 7 ‣ 4.3.3\.
    Non-Verbal Expression ‣ 4.3\. Interactive Behavior Planning ‣ 4\. Multi-agent
    system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents
    for Rich Tabletop Game Applications")c-e中说明。'
- en: '![Refer to caption](img/784fe69c67f56f3238b1d0a896e25c5d.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/784fe69c67f56f3238b1d0a896e25c5d.png)'
- en: Figure 7\. a-b) A single gadget expresses excitement, the gadgets move upward
    a little and rotate for a circle. c-e) Two gadgets express an argument, they move
    toward each other, each rotates for a circle during the argument, and each retreats
    when the argument is over.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图7\. a-b) 一个设备表现出兴奋，设备稍微向上移动并旋转一个圆圈。c-e) 两个设备表现出争论，它们互相靠近，在争论过程中各自旋转一个圆圈，争论结束时各自后退。
- en: 4.3.4\. Scene Interaction
  id: totrans-91
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.4\. 场景互动
- en: In SUI-based tabletop games, as it is expected that a robotic gadget should
    be able to perform actions such as storytelling within a scene, the gadget’s behavior
    may need to interact with the settings of map environment (Guo et al., [2023](#bib.bib7)).
    To this end, we incorporate a set of add-on prompts for the Controller to assist
    in generating action sequences for swarm robots for ”scene interaction.” Specifically,
    we proposed that the Controller possesses a ”global perspective” in the Gadget’s
    action planning, taking into account additional map information, scene props,
    and even the positions or statuses of other Gadgets among other factors. We also
    provided an example for each method in the prompts, along with the expected action
    sequences the Controller should generate. The add-on prompt includes an example
    demonstrating a Gadget navigating around an obstacle of a certain length to reach
    the other side of the obstacle. Related prompts are specified in the Supplementary
    Material.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于SUI的桌面游戏中，由于期望机器人设备能够在场景中执行讲故事等操作，设备的行为可能需要与地图环境的设置进行交互（Guo et al., [2023](#bib.bib7)）。为此，我们为控制器加入了一组附加提示，以帮助生成“场景互动”的集群机器人行动序列。具体而言，我们建议控制器在设备的行动规划中具备“全球视角”，考虑额外的地图信息、场景道具，甚至其他设备的位置或状态等因素。我们还为每种方法提供了一个示例，并说明了控制器应生成的预期行动序列。附加提示包括一个示例，演示了设备如何绕过一定长度的障碍物以到达障碍物的另一侧。相关提示在附加材料中指定。
- en: 'After incorporating the add-on prompt for scene interaction into the Controller,
    we tested it with an example of navigating a Gadget around an obstacle formed
    by three other Gadgets. The demonstration of this expression and the corresponding
    action sequences are illustrated in Figure [8](#S4.F8 "Figure 8 ‣ 4.3.4\. Scene
    Interaction ‣ 4.3\. Interactive Behavior Planning ‣ 4\. Multi-agent system ‣ AI-Gadget
    Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop
    Game Applications").'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '在将场景互动的附加提示融入控制器后，我们以设备绕过由其他三个设备形成的障碍物的示例进行测试。这种表现的演示及其对应的行动序列在图[8](#S4.F8
    "Figure 8 ‣ 4.3.4\. Scene Interaction ‣ 4.3\. Interactive Behavior Planning ‣
    4\. Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with
    LLM-driven Agents for Rich Tabletop Game Applications")中说明。'
- en: '![Refer to caption](img/8174c79b2fc75625ca7de8fa6b2bea06.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/8174c79b2fc75625ca7de8fa6b2bea06.png)'
- en: Figure 8\. The gadget goes around a wall consisting of three other gadgets,
    approaching the obstacle before moving to the south side of the obstacle and moving
    east to get over the obstacle.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8\. 小工具绕过由另外三个小工具组成的墙壁，接近障碍物后，移动到障碍物的南侧，然后向东移动以越过障碍物。
- en: 4.4\. Interaction Relationship Planning
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4\. 互动关系规划
- en: 'Within the multiple interaction rounds in a game, it is crucial for agents
    to reflect upon the relational structure underpinning their engagements with players.
    This encompasses scenarios where agents may either confront or collaborate with
    players, or independently modulate their responses in alignment with the unfolding
    narrative, thereby contributing to the thematic ambiance. Drawing from this premise,
    researchers’ investigations have distilled the potential stances an agent might
    assume into four distinct categories: Apprentice, Competitor, Teammate, or Designer
    (Zhu et al., [2021](#bib.bib36)). To enable agents to grasp the relationship between
    human-computer interaction relationships and the generation of interactive behaviors
    within the game, we have augmented the Controller with the additional prompt (add-on
    prompt) to understand the varying interaction relationships.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在游戏中的多轮互动中，代理需要反思支撑其与玩家互动的关系结构。这包括代理可能与玩家对抗或合作，或独立调整其回应以符合展开的叙事，从而有助于主题氛围。基于这一前提，研究者们将代理可能采取的潜在立场提炼为四个不同的类别：学徒、竞争者、队友或设计者（Zhu
    et al., [2021](#bib.bib36)）。为了使代理理解人机互动关系与游戏内互动行为生成之间的关系，我们为控制器增加了额外的提示（附加提示），以便理解各种互动关系。
- en: 4.4.1\. Apprentice
  id: totrans-98
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.4.1\. 学徒
- en: Within the context of most tabletop gaming environments, Gadgets in our system
    typically embody the player’s avatar or operate as player-controlled entities
    ⁵⁵5http://scruffygrognard.com/. We believe that the ability of the system to act
    as an ”apprentice,” autonomously and precisely modifying the actions of robotic
    gadgets in response to users’ suggestions, would significantly enhance personalized
    interactive behaviors. To achieve this, we established a set of additional prompts
    for the Controller, enabling it to refer to and adjust its action planning as
    much as possible according to the user’s guidance. The specific prompts are detailed
    in the Supplementary Material.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数桌面游戏环境中，我们系统中的小工具通常体现了玩家的化身或作为玩家控制的实体⁵⁵5http://scruffygrognard.com/。我们相信，系统能够作为一个“学徒”，自主而准确地根据用户的建议调整机器人小工具的动作，将显著提升个性化的互动行为。为此，我们为控制器建立了一组额外的提示，使其能够根据用户的指导尽可能多地参考和调整其动作计划。具体提示在补充材料中有详细说明。
- en: After incorporating the add-on prompt for ”apprentice” into the Controller,
    we tested it with an example of requesting to ”speed up Gadgets”. The following
    is an example of an action sequence generated by the Controller controlling a
    Gadget to move from (5,5) to (10,10) on the grid map. The translation (movement)
    speed is set to 2.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在将“学徒”附加提示整合到控制器后，我们用请求“小工具加速”的例子进行了测试。以下是控制器生成的动作序列的示例，该序列控制小工具在网格地图上从 (5,5)
    移动到 (10,10)，移动速度设置为 2。
- en: 'Following this, if we then request the Gadget to move faster, the Controller
    updates and generates the following sequence of actions as Figure [9](#S4.F9 "Figure
    9 ‣ 4.4.1\. Apprentice ‣ 4.4\. Interaction Relationship Planning ‣ 4\. Multi-agent
    system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents
    for Rich Tabletop Game Applications")'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '如果我们要求小工具移动得更快，控制器会更新并生成如下动作序列，如图 [9](#S4.F9 "Figure 9 ‣ 4.4.1\. Apprentice
    ‣ 4.4\. Interaction Relationship Planning ‣ 4\. Multi-agent system ‣ AI-Gadget
    Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop
    Game Applications") 所示。'
- en: '![Refer to caption](img/eaf504308ac4a5160b8ec19ee70c0617.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/eaf504308ac4a5160b8ec19ee70c0617.png)'
- en: Figure 9\. The gadget was asked to move from (5, 5) to (10, 10), and after being
    asked to speed up, the gadget moved faster.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9\. 小工具被要求从 (5, 5) 移动到 (10, 10)，在被要求加速后，小工具移动得更快。
- en: 4.4.2\. Opponent
  id: totrans-104
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.4.2\. 对手
- en: Many tabletop games feature the roles of opponents not controlled by players,
    engaging in competitive activities with the players. We believe it can enrich
    the gaming experience of tabletop games if our system comprehends the concept
    of ”opponent”, establishes non-player-controlled opponent roles, and uses the
    Gadgets to materialize their interactions. To facilitate this, we have established
    a set of additional prompts for the Controller, helping it generate and enact
    the roles of single or multiple opponents for competition or matches in games.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 许多桌面游戏中包含玩家未控制的对手角色，与玩家进行竞争活动。我们相信，如果我们的系统理解“对手”的概念，建立非玩家控制的对手角色，并使用小工具实现它们的互动，将能丰富桌面游戏的体验。为此，我们为控制器建立了一套额外的提示，帮助它生成和执行单个或多个对手角色以进行游戏中的竞争或比赛。
- en: We specify in the prompt the planning about the principles and duties that the
    Controller should adhere to when generating ”Opponent” roles (Raman et al., [2022](#bib.bib23)).
    For example, we set the goal of the opponent ”… to challenge the opponent characters
    through strategy and decision-making while keeping the game fair and enjoyable.”
    Furthermore, we have defined a mechanism for the Controller how to analyze player
    behavior and dynamically formulate challenging interaction strategies. For example,
    we specify in the prompt that the Controller ”… formulate challenging strategies
    based on the current state of the game and the behaviors of opponent characters.”
    The prompts are specified in the Supplementary Material.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在提示中明确了生成“对手”角色时，控制器应遵循的原则和职责（Raman et al., [2022](#bib.bib23)）。例如，我们设定了对手的目标是“…通过策略和决策挑战对手角色，同时保持游戏公平和愉快。”此外，我们为控制器定义了一种机制，用于分析玩家行为并动态制定具有挑战性的互动策略。例如，我们在提示中规定控制器“…根据游戏的当前状态和对手角色的行为制定具有挑战性的策略。”这些提示在补充材料中进行了说明。
- en: 'After incorporating the add-on prompt for ”opponent” into the Controller, we
    tested it with an example of using Gadgets for combat behavior. In this example,
    one gadget embodies the role of a Monster1 commanded by the user (with action
    sequences generated by the Controller), while another gadget was controlled by
    the system, acting as an opponent Monster2. After the Monster1 is commanded to
    use Thunderbolt to attack, the Controller generates the action sequence of their
    battle as Figure [10](#S4.F10 "Figure 10 ‣ 4.4.2\. Opponent ‣ 4.4\. Interaction
    Relationship Planning ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm
    User Interfaces with LLM-driven Agents for Rich Tabletop Game Applications").'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在将“对手”的附加提示整合到控制器中后，我们用一个使用小工具进行战斗行为的示例进行了测试。在这个示例中，一个小工具体现了由用户指挥的Monster1角色（由控制器生成动作序列），而另一个小工具则由系统控制，充当对手Monster2。在Monster1被指示使用雷电攻击后，控制器生成了它们战斗的动作序列，如图
    [10](#S4.F10 "图 10 ‣ 4.4.2\. 对手 ‣ 4.4\. 互动关系规划 ‣ 4\. 多代理系统 ‣ AI-小工具套件：将集群用户界面与基于LLM的代理整合到丰富的桌面游戏应用中")。
- en: '![Refer to caption](img/02fcc02463c3a8d292f1185f71a508b3.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/02fcc02463c3a8d292f1185f71a508b3.png)'
- en: Figure 10\. Monster1 is asked to attack Monster2, and Monster2 responds being
    attacked.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10\. Monster1 被要求攻击 Monster2，Monster2 对攻击作出回应。
- en: 4.4.3\. Teammate
  id: totrans-110
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.4.3\. 队友
- en: Similar to opponents, in tabletop gaming, there exist numerous non-player controlled
    characters that support the player by collaborating to accomplish tasks or combat
    adversaries. Enriching the gaming experience becomes more feasible if our system
    can comprehend the ”teammate (ally)” relationship, autonomously establish these
    non-player controlled teammate roles, and materialize interactions using the Gadgets.
    To achieve this, we have also developed a set of add-on prompts for the Controller,
    fostering it in generating and embodying one or multiple teammate roles. We specify
    in the prompt the planning about the principles and duties that the Controller
    should adhere to when generating ”Teammate” roles (Raman et al., [2022](#bib.bib23)).
    For example, we set a goal for the teammate ”… is to support teammate characters
    through effective collaboration and strategy, ensuring the success of the entire
    team and the enjoyment of the game…” Furthermore, we have established guidelines
    in the prompts for how Controllers can support teammate roles through effective
    collaboration and strategic planning, such as ”providing necessary support to
    help teammate characters overcome challenges while ensuring not to overshadow
    them, maintaining the game’s balance and interest.”, to ensure the success of
    the entire team and enhance the enjoyment of the game. The prompts are specified
    in the Supplementary Material.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于对手，在桌面游戏中，存在许多非玩家控制的角色，这些角色通过合作来支持玩家以完成任务或与对手作战。如果我们的系统能够理解“队友（盟友）”关系，自动建立这些非玩家控制的队友角色，并利用Gadgets实现互动，那么丰富游戏体验将变得更加可行。为此，我们还为Controller开发了一套附加提示，帮助其生成和体现一个或多个队友角色。我们在提示中明确了Controller在生成“队友”角色时应遵循的原则和职责（Raman等，[2022](#bib.bib23)）。例如，我们为队友设定了目标：“...通过有效的合作和策略支持队友角色，确保整个团队的成功和游戏的乐趣...”。此外，我们在提示中为Controller如何通过有效的合作和战略规划支持队友角色制定了指导方针，如“提供必要的支持以帮助队友角色克服挑战，同时确保不抢风头，保持游戏的平衡和趣味性。”，以确保整个团队的成功并提升游戏的乐趣。提示详见附录材料。
- en: 'After incorporating the add-on prompt for ”teammate” into the Controller, we
    tested it with an example of using Gadgets for collaborative combat behavior as
    Figure [11](#S4.F11 "Figure 11 ‣ 4.4.3\. Teammate ‣ 4.4\. Interaction Relationship
    Planning ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces
    with LLM-driven Agents for Rich Tabletop Game Applications"). In this scenario,
    one Gadget embodies the role of a Monster1 commanded by the user (with action
    sequences generated by the Controller), while two other Gadgets, generated and
    governed by the Controller, take on the roles of a teammate Monster2 and an opponent
    Monster3, respectively.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在将“队友”附加提示整合到Controller中后，我们用Gadgets进行协作战斗行为的示例进行了测试，如图[11](#S4.F11 "图 11 ‣
    4.4.3\. 队友 ‣ 4.4\. 互动关系规划 ‣ 4\. 多智能体系统 ‣ AI-Gadget工具包：将Swarm用户界面与LLM驱动的代理集成用于丰富的桌面游戏应用")所示。在此场景中，一个Gadget扮演由用户指挥的Monster1角色（由Controller生成动作序列），而两个其他Gadgets，由Controller生成和控制，分别扮演队友Monster2和对手Monster3的角色。
- en: '![Refer to caption](img/1ff985d576f6cbb6398f5a2c5c402b8d.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/1ff985d576f6cbb6398f5a2c5c402b8d.png)'
- en: Figure 11\. Gadgets that can generate collaborative behavior act as a teammate
    of the user and attack the enemy together.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图11\. 能生成协作行为的Gadgets作为用户的队友一起攻击敌人。
- en: 4.4.4\. Designer
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.4.4\. 设计师
- en: In tabletop games, more roles that serve to enhance the narrative, such as NPCs
    (Non-Player Characters) or props, may also be present. For instance, upon the
    players and their teammates defeating adversaries, villager NPCs can be configured
    to celebrate players’ victory. If the Controller can act as a ”designer,” generating
    these roles based on the game’s narrative and materializing their actions through
    gadgets, then it would elevate the dramatic effect and overall experience of the
    game. To facilitate this, we have developed a set of add-on prompts for the Controller,
    enabling it to ”… spontaneously generate new characters, NPCs, items, or plots,
    as well as the corresponding robotic action sequences, to advance the game storyline.”
    Related prompts are detailed in the Supplementary Material.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在桌面游戏中，还可能存在更多旨在增强叙事的角色，如NPC（非玩家角色）或道具。例如，当玩家和队友击败对手时，村民NPC可以被配置为庆祝玩家的胜利。如果控制器能够充当“设计师”，根据游戏的叙事生成这些角色，并通过小工具实现他们的动作，那么它将提升游戏的戏剧效果和整体体验。为此，我们为控制器开发了一套附加提示，使其能够“……自发生成新角色、NPC、物品或情节，以及相应的机器人动作序列，以推进游戏情节。”相关提示详见补充材料。
- en: 'After incorporating the add-on prompt for ”designer” into the Controller, we
    tested it with an example focusing on a pivotal narrative moment following a battle
    victory. Specifically, when the user-controlled Monster1 and the teammate Monster2
    defeated Monster3, the Controller generated a storyline in which villager NPCs
    appeared to celebrate the victory. To bring this celebratory behavior to life,
    the Controller then invoked three new Gadgets designed for this purpose as Figure
    [12](#S4.F12 "Figure 12 ‣ 4.4.4\. Designer ‣ 4.4\. Interaction Relationship Planning
    ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with
    LLM-driven Agents for Rich Tabletop Game Applications").'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '在将“设计师”附加提示集成到控制器后，我们用一个例子进行了测试，重点关注战斗胜利后的关键叙事时刻。具体来说，当用户控制的Monster1和队友Monster2击败了Monster3时，控制器生成了一个故事情节，其中村民NPC出现庆祝胜利。为了实现这种庆祝行为，控制器随后调用了为此目的设计的三个新小工具，如图[12](#S4.F12
    "Figure 12 ‣ 4.4.4\. Designer ‣ 4.4\. Interaction Relationship Planning ‣ 4\.
    Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven
    Agents for Rich Tabletop Game Applications")所示。'
- en: '![Refer to caption](img/5f231f0d77403a035b48b13d81ef29c4.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/5f231f0d77403a035b48b13d81ef29c4.png)'
- en: Figure 12\. Three new NPCs generated by the agent celebrate the user’s victory
    together, they surround the player, each taking a step forward and expressing
    excitement by spinning.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12\. 三个由代理生成的新NPC一起庆祝用户的胜利，它们围绕玩家，逐步向前并通过旋转表达兴奋。
- en: 5\. Example Application
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 示例应用
- en: 'We designed several different tabletop games using the AI-Gadget Kit to demonstrate
    its capabilities with a two-agent system and the effectiveness of the eight add-on
    prompts (comprising four Interaction Behaviors and four Interaction Relationships).
    For each game played, we followed the procedure outlined in Figure [4](#S4.F4
    "Figure 4 ‣ 4.2\. Complex Motion Planning ‣ 4\. Multi-agent system ‣ AI-Gadget
    Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop
    Game Applications"), beginning with giving the game’s introduction and rules to
    the AI-Gadget Kit (details provided in the Supplementary Material). This initial
    step involved declaring the game being played. Subsequently, based on the game
    scenario, we provide game commands to interact with the Gadgets, engaging in an
    interactive gameplay experience.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '我们使用AI-Gadget Kit设计了几种不同的桌面游戏，以展示其在双代理系统中的能力和八个附加提示的有效性（包括四种互动行为和四种互动关系）。每次游戏开始时，我们都按照图[4](#S4.F4
    "Figure 4 ‣ 4.2\. Complex Motion Planning ‣ 4\. Multi-agent system ‣ AI-Gadget
    Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop
    Game Applications")中的程序进行，首先向AI-Gadget Kit介绍游戏和规则（详细信息见补充材料）。这个初步步骤包括声明正在进行的游戏。随后，根据游戏场景，我们提供游戏命令以与小工具进行互动，进行互动游戏体验。'
- en: 5.1\. Soccer-Ball-Shooting Game
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1\. 足球射门游戏
- en: 'Using the AI-Gadget Kit, we implemented a soccer-ball-shooting game, as illustrated
    in the Figure [13](#S5.F13 "Figure 13 ‣ 5.1\. Soccer-Ball-Shooting Game ‣ 5\.
    Example Application ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven
    Agents for Rich Tabletop Game Applications"). The setup includes a stationary
    goal on the tabletop, with players and a Gadget taking turns to shoot the ball.
    Players propel the ball using two fingers, while the Gadget executes its shots
    by striking the ball. We began by providing the game rules into the system (details
    in the Supplementary Material). Once the Coordinator comprehended the rules, it
    assumed the roles of both host and referee within the game. It then tasked the
    Controller with deploying an opponent role to control the action sequences of
    the Gadget. The Kit shall leverage the capability through the ”object actuation”
    add-on prompt of the Controller to simulate and execute collision planning based
    on the position of the goal and the ball. When it is the Gadget turn to take a
    shot, Controller generates the opponent’s direction and speed by considering factors
    such as the distance of the ball from the goal, the ball’s orientation relative
    to the goal, and the speed required to propel the ball.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 AI-小工具包，我们实现了一个足球射门游戏，如图 [13](#S5.F13 "图 13 ‣ 5.1\. 足球射门游戏 ‣ 5\. 示例应用 ‣ AI-小工具包：将集群用户界面与LLM驱动的代理集成，用于丰富的桌面游戏应用")
    所示。设置包括一个固定在桌面上的球门，玩家和小工具轮流射门。玩家使用两根手指推动球，而小工具则通过击打球来进行射门。我们首先将游戏规则输入系统（详细信息见补充材料）。一旦协调器理解了规则，它就会在游戏中担任主机和裁判的角色。然后，它指派控制器部署对手角色以控制小工具的动作序列。该工具包将通过控制器的“物体驱动”附加提示，利用目标和球的位置进行碰撞规划和执行。当轮到小工具射门时，控制器会考虑球离球门的距离、球相对于球门的方向以及推动球所需的速度，生成对手的方向和速度。
- en: 'Figure [13](#S5.F13 "Figure 13 ‣ 5.1\. Soccer-Ball-Shooting Game ‣ 5\. Example
    Application ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven
    Agents for Rich Tabletop Game Applications") demonstrates the performance of the
    system in this gaming scenario, highlighting the Gadget acting as the opponent.
    After the player takes a shot, the Gadget autonomously aims for the kickoff spot,
    moves towards the ball, and pushes it towards the goal.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [13](#S5.F13 "图 13 ‣ 5.1\. 足球射门游戏 ‣ 5\. 示例应用 ‣ AI-小工具包：将集群用户界面与LLM驱动的代理集成，用于丰富的桌面游戏应用")
    展示了系统在这种游戏场景下的表现，突出了小工具作为对手的作用。在玩家射门后，小工具会自动瞄准开球点，移动到球的位置，并将其推向球门。
- en: '![Refer to caption](img/e3c6f0c63b75329f75acac7d5808772e.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/e3c6f0c63b75329f75acac7d5808772e.png)'
- en: Figure 13\. Human player and AI player play soccer games together.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13\. 人类玩家与 AI 玩家一起踢足球。
- en: Additionally, the Controller monitors past scores to adjust strategies to enhance
    gameplay and competitiveness. For instance, in a single game session, if the player
    fails to score consecutively over multiple attempts, the opponent’s accuracy will
    be dynamically lowered in subsequent rounds. This adjustment is designed to enrich
    the users’ gaming experience by maintaining a competitive balance and ensuring
    that the game remains engaging and challenging without becoming discouragingly
    difficult.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，控制器监控过去的得分情况，以调整策略以提升游戏体验和竞争性。例如，在单场游戏会话中，如果玩家连续多次未能得分，对手的准确性将在后续回合中动态降低。此调整旨在通过保持竞争平衡，确保游戏保持有趣且具有挑战性，而不会变得过于困难，从而丰富用户的游戏体验。
- en: 5.2\. Turn-Based Strategy Game
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2\. 回合制策略游戏
- en: 'Within the Turn-Based Strategy (TBS) game scenarios, the system is designed
    to support battles between players whose commands are embodied through Gadget
    controlling (Player vs. Player, or PVP) as well as battles where the Gadget itself
    acts as the opponent (Player vs. Environment, or PVE). During gameplay, robotic
    gadgets assume roles as combatants, generating robotic action commands based on
    the attack targets and skills released as designated by the players. Following
    the game rules outlined, the Coordinator updates and transmits game information
    during interactions, such as the status and capabilities of the gadgets. The Controller
    then synthesizes this information to produce corresponding sequences of actions.
    In combat scenarios, our Kit primarily relies on an apprentice, opponent, and
    non-verbal expression add-on prompts. It adheres to the players’ interaction commands
    (such as attack/defense, skill deployment, etc.) to generate corresponding interactive
    behaviors. As illustrated in the figure[14](#S5.F14 "Figure 14 ‣ 5.2\. Turn-Based
    Strategy Game ‣ 5\. Example Application ‣ AI-Gadget Kit: Integrating Swarm User
    Interfaces with LLM-driven Agents for Rich Tabletop Game Applications"), when
    a player commands their character to ”attack the enemy with the power of thunderbolt,”
    the kit generates an attack action directed at the opposing Gadget. Considering
    the characteristics of ”thunderbolt,” the kit is designed with actions for the
    attacking gadget that simulate the buildup of electrical charge followed by a
    swift charge forward, and for the opponent gadget, it simulates the motion of
    being electrocuted with on-the-spot swaying movements. Moreover, through the add-on
    prompts of teammates and designers within our kit, TBS games can accommodate a
    larger number of gadgets for combat or interaction. This can complement the combat
    theater in existing Dungeons and Dragons (D&D) type games.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在回合制策略（TBS）游戏场景中，系统设计支持玩家之间的战斗，其指令通过设备控制体现（玩家对玩家，或 PVP），以及设备本身作为对手的战斗（玩家对环境，或
    PVE）。在游戏过程中，机器人设备作为战斗者，基于玩家指定的攻击目标和释放的技能生成机器人动作指令。根据游戏规则，协调员在互动过程中更新和传输游戏信息，如设备的状态和能力。然后，控制器综合这些信息，生成相应的动作序列。在战斗场景中，我们的套件主要依赖于学徒、对手和非语言表达附加提示。它遵循玩家的互动指令（如攻击/防御、技能部署等），生成相应的互动行为。如图[14](#S5.F14
    "图 14 ‣ 5.2\. 回合制策略游戏 ‣ 5\. 示例应用 ‣ AI-Gadget 套件：将群体用户界面与 LLM 驱动的代理集成，用于丰富的桌面游戏应用")所示，当玩家指挥他们的角色“用雷霆的力量攻击敌人”时，套件会生成针对对手设备的攻击动作。考虑到“雷霆”的特点，套件为攻击设备设计了模拟电荷积累并随即冲刺的动作，而对手设备则模拟被电击的动作，伴随现场的摇摆动作。此外，通过我们套件中的队友和设计师附加提示，TBS
    游戏可以容纳更多的设备进行战斗或互动。这可以补充现有的《龙与地下城》（D&D）类型游戏中的战斗场景。
- en: '![Refer to caption](img/bef59b971e1e8f281602697cc42c274a.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/bef59b971e1e8f281602697cc42c274a.png)'
- en: Figure 14\. Robotic gadget plays turn-based strategy games with human players.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14\. 机器人设备与人类玩家进行回合制策略游戏。
- en: 5.3\. Yes Or No?
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3\. 是还是不是？
- en: In many games, there are moments where a system provides Yes or No responses,
    such as ability checks and answering questions within the narrative in Dungeons
    and Dragons (D&D) games. Our kit enhances the presentation of Yes and No answers
    in these instances, making them more engaging.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多游戏中，系统会提供“是”或“不是”的回答，如能力检查和在《龙与地下城》（D&D）游戏的叙事中回答问题。我们的套件增强了这些情况下“是”和“不是”回答的呈现，使其更具吸引力。
- en: 'For instance, we have designed a quiz game[15](#S5.F15 "Figure 15 ‣ 5.3\. Yes
    Or No? ‣ 5\. Example Application ‣ AI-Gadget Kit: Integrating Swarm User Interfaces
    with LLM-driven Agents for Rich Tabletop Game Applications") (its rules are detailed
    in the Supplementary Material) where the Coordinator accepts questions raised
    by users and provides corresponding answers.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们设计了一个问答游戏[15](#S5.F15 "图 15 ‣ 5.3\. 是还是不是？ ‣ 5\. 示例应用 ‣ AI-Gadget 套件：将群体用户界面与
    LLM 驱动的代理集成，用于丰富的桌面游戏应用")（其规则详见补充材料），在该游戏中，协调员接受用户提出的问题并提供相应的答案。
- en: The Controller, equipped with designer capabilities, utilizes add-on prompts
    for symbol visualization to control a Gadget. This Gadget writes out Y (Yes) or
    N (No) on paper, responding affirmatively or negatively to the users’ queries.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 配备设计师功能的控制器，利用附加提示进行符号可视化，以控制设备。该设备在纸上写出 Y（是）或 N（不是），对用户的查询作出肯定或否定的回答。
- en: To mitigate the impact of friction between the pen tip and paper on the robotic
    gadget’s movement, we employed two gadgets to hold a pen jointly for drawing.
    This design is intended to offer users a more suspenseful and immersive gaming
    experience.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减轻笔尖与纸张之间的摩擦对机器人小工具运动的影响，我们采用了两个小工具共同持笔绘画的设计。这一设计旨在为用户提供更具悬念和沉浸感的游戏体验。
- en: '![Refer to caption](img/d5c01bc55d2ab1c715545f60190eb44c.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/d5c01bc55d2ab1c715545f60190eb44c.png)'
- en: Figure 15\. Robotic gadgets answer ’Yes’ or ’No’ to user questions by driving
    a pen to write on paper.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15\. 机器人小工具通过驱动笔在纸上书写来回答用户的问题，“是”或“否”。
- en: 5.4\. Improvisational Theater
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4\. 即兴戏剧
- en: Improvisational theater is a form of group drama without a fixed script, where
    most of the content is spontaneously created by the performers during the performance(Johnstone,
    [2012](#bib.bib12)). Integrating AI-Gadget Kit, we have designed an application
    for users to perform improvisational theater in collaboration with the Gadgets.
    In this setup, Gadgets act as performers, with one of the Gadgets representing
    the user. We require the Gadgets to adhere to the core principle of improvisational
    theater, ”Yes, and,” which means freely generating subsequent performance content,
    including voice and action sequences, based on the previous performer’s contribution
    and randomly selecting the next performer from among the users and other Gadgets.
    The Coordinator is responsible for assigning roles to all parties, recording and
    transmitting the content of the performance, and coordinating the turns of the
    performance.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 即兴戏剧是一种没有固定剧本的集体戏剧形式，大部分内容是由表演者在表演过程中即兴创作的（Johnstone，[2012](#bib.bib12)）。通过整合AI-Gadget
    Kit，我们设计了一个应用，允许用户与小工具合作进行即兴戏剧。在这个设置中，小工具充当表演者，其中一个小工具代表用户。我们要求小工具遵守即兴戏剧的核心原则，“是的，并且”，即基于前一位表演者的贡献自由生成后续表演内容，包括声音和动作序列，并从用户和其他小工具中随机选择下一位表演者。协调员负责为各方分配角色，记录并传输表演内容，以及协调表演的轮次。
- en: 'After integrating non-verbal expression add-on prompts, the Controller is capable
    of generating dialogue that fits the characters’ identities and the plot development,
    while also endowing robots with non-verbal ”mood” expressions to convey the characters’
    emotional states. Moreover, by assigning specific scene information to different
    areas of the venue, the scene interaction capability add-on prompt enables the
    Controller to consider information such as the performance location when generating
    action sequences. In one of our improvisational theater tests set in the world
    of ”Hamlet” (detailed game rules can be found in the Supplementary Material),
    our Kit initially assigns identities to a cluster of Gadgets(Figure [16](#S5.F16
    "Figure 16 ‣ 5.4\. Improvisational Theater ‣ 5\. Example Application ‣ AI-Gadget
    Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop
    Game Applications")), several following the original characters of the drama and
    others being original characters based on user commands.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '在整合了非语言表达附加提示后，控制器能够生成符合角色身份和情节发展的对话，同时赋予机器人非语言的“情绪”表达以传达角色的情感状态。此外，通过将特定的场景信息分配到场地的不同区域，场景互动能力附加提示使得控制器在生成动作序列时能够考虑诸如表演位置等信息。在我们的一次设定在《哈姆雷特》世界中的即兴戏剧测试中（详细的游戏规则可以在补充材料中找到），我们的Kit最初为一群小工具分配身份（图
    [16](#S5.F16 "Figure 16 ‣ 5.4\. Improvisational Theater ‣ 5\. Example Application
    ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents for
    Rich Tabletop Game Applications")），其中几个角色沿用戏剧中的原始角色，而其他则是根据用户指令创建的原创角色。'
- en: Once the performance starts, the Controller coordinates with the user, taking
    into account the pre-set information of the performance site, to continue the
    act. For example, when the robot playing Hamlet utters ”To be or not to be, that
    is the question,” in complete contrast to the original story, the user, who is
    consoled by a robot as Hamlet’s friend (an original character), expresses his
    comfort and informs Hamlet that Ophelia is waiting on the terrace. Based on the
    lines entered by the user for the performance, the Controller Agent directs the
    user’s robot to express emotion through a non-verbal sequence of actions. Hamlet
    then moved to the area representing the terrace based on the venue information
    and engaged in a dialog and performance with Ophelia.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦表演开始，控制器会与用户协调，考虑到演出现场的预设信息，以继续表演。例如，当扮演哈姆雷特的机器人说出“生存还是毁灭，这是个问题”时，与原故事完全不同，用户则由一个作为哈姆雷特朋友的机器人安慰，并告诉哈姆雷特奥菲莉亚正在露台上等待。根据用户为演出输入的台词，控制器代理将引导用户的机器人通过非语言动作序列来表达情感。哈姆雷特随后根据场地信息移动到代表露台的区域，并与奥菲莉亚进行对话和表演。
- en: It is not difficult to see that AI-Gadget has the ability to respond to high
    degree-of-freedom user input in performance scenarios. We also tested completely
    original story contexts in which AI-Gadget similarly demonstrated the ability
    to receive feedback on improvised content. As the art form of improvisational
    theater is gaining traction in the areas of imagination and creativity stimulation,
    mental health, and social-emotional education (Sawyer, [2000](#bib.bib26))(Schwenke
    et al., [2021](#bib.bib27))(Felsman et al., [2019](#bib.bib4)), combined with
    a more specialized Emergent Story Generation strategy, AI-Gadget has the potential
    to provide users with a richer interactive and emotional experience.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 不难看出，AI-Gadget 在性能场景中能够响应高自由度的用户输入。我们还测试了完全原创的故事情境，其中 AI-Gadget 同样表现出了对即兴内容的反馈能力。由于即兴戏剧在想象力与创造力刺激、心理健康和社会情感教育领域逐渐受到关注（Sawyer,
    [2000](#bib.bib26)）（Schwenke et al., [2021](#bib.bib27)）（Felsman et al., [2019](#bib.bib4)），结合更专业的紧急故事生成策略，AI-Gadget
    具有为用户提供更丰富互动和情感体验的潜力。
- en: '![Refer to caption](img/bd90b8f00fa575ee76a456e49ae07b82.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/bd90b8f00fa575ee76a456e49ae07b82.png)'
- en: Figure 16\. In Hamlet-themed improvisational theater, the gadget playing Hamlet
    flexibly reacts to the user’s words outside of the script.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图16\. 在以《哈姆雷特》为主题的即兴戏剧中，扮演哈姆雷特的装置灵活地对用户的台词作出反应。
- en: 6\. Discussion
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 讨论
- en: 6.1\. Limitation and Future Works
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1\. 限制与未来工作
- en: In this study, we employed the Sony Toio robots as our Robotic Gadget. However,
    due to the Toio robots’ movement being reliant on motor differential speed control,
    the performance of the motors themselves can impact the robots’ action performance.
    This imposes limitations on the AI-Gadget Kit’s functionality. For instance, in
    practice, the Toio robots exhibited random deviations when executing users’ movement
    commands, a situation exacerbated by a shift in the center of gravity due to additional
    attachments to the casing.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们使用了 Sony Toio 机器人作为我们的机器人装置。然而，由于 Toio 机器人的运动依赖于电机差速控制，电机本身的性能可能会影响机器人的动作表现。这对
    AI-Gadget 套件的功能造成了限制。例如，在实际操作中，Toio 机器人在执行用户的运动指令时出现了随机偏差，这种情况由于机壳上附加部件导致重心移动而加剧。
- en: To mitigate the challenges faced by the Gadget due to the aforementioned factors,
    we are considering several optimizations to the system architecture. Firstly,
    a more precise movement correction algorithm on the robot side could support the
    robots’ movement performance. With the anticipated action sequences of the Gadget,
    coupled with real-time positioning information based on ArUCo from cameras, the
    robots are capable of precise closed-loop control during action, enabling real-time
    adjustments. Furthermore, inspired by works such as Swarm Haptics(Kim and Follmer,
    [2019](#bib.bib14)) and Hermits(Nakagaki et al., [2020](#bib.bib20)), mechanical
    modifications to the robots (like increasing tire friction) could address the
    limitations in the Gadget’s linear driving capability and performance due to the
    mass and speed of swarm robots in scenarios such as object propulsion.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 为了缓解Gadget因上述因素面临的挑战，我们正在考虑对系统架构进行多项优化。首先，机器人端更精确的运动修正算法可以支持机器人的运动性能。结合Gadget预期的动作序列和基于摄像头ArUCo的实时定位信息，机器人能够在动作过程中进行精确的闭环控制，实现实时调整。此外，受到Swarm
    Haptics（Kim和Follmer，[2019](#bib.bib14)）和Hermits（Nakagaki等，[2020](#bib.bib20)）等工作的启发，对机器人进行机械改造（如增加轮胎摩擦力）可以解决由于集群机器人质量和速度造成的Gadget线性驱动能力和性能的限制，特别是在物体推动等场景中。
- en: Beyond optimizing the robots’ movement capabilities, we also recognize that
    the current provision of meta-actions by the robot side is insufficient to meet
    the demand for a broader range of complex movements. For the Gadget, diverse movement
    modes (such as curved motion) are expected to improve the robots’ interactive
    experience and expressiveness. Therefore, the encapsulation and provision of more
    movement modes will assist the Robotic Gadget in achieving interactions with complex
    and rich semantics in tabletop games.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 除了优化机器人的运动能力外，我们还认识到当前机器人端提供的元动作不足以满足更广泛复杂运动的需求。对于Gadget来说，多样化的运动模式（如弯曲运动）有望提升机器人的互动体验和表现力。因此，封装和提供更多运动模式将帮助Robotic
    Gadget在桌面游戏中实现复杂且丰富语义的交互。
- en: On the other hand, in this study, when confronted with complex board game scenarios,
    such as ”Improvisational Theater,” the LLM (i.e., GPT-4) which the agents rely
    on, may encounter performance bottlenecks due to the utilization of multiple add-ons
    prompts and numerous game rounds, leading to complications in processing lengthy
    contexts. This can result in inaccuracies and errors or the so-called ”hallucination”
    phenomenon of LLM, where the model generates content with inaccuracies related
    to the game’s rules and scenario descriptions. In such cases, the model’s output
    may require additional testing (e.g., The Needle In a Haystack Test) to verify
    its accuracy and reliability.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，在本研究中，当面对复杂的棋盘游戏场景时，如“即兴剧场”，代理所依赖的LLM（即GPT-4）可能会因为使用了多个附加提示和大量游戏回合而遇到性能瓶颈，导致处理长上下文时出现复杂情况。这可能导致不准确和错误，或者所谓的LLM“幻觉”现象，即模型生成与游戏规则和场景描述相关的不准确内容。在这种情况下，模型的输出可能需要额外的测试（如“针在干草堆中的测试”）来验证其准确性和可靠性。
- en: To address this challenge and enhance the agents’ performance in complex scenarios,
    several strategies can be considered for the future. Firstly, introducing a more
    powerful LLM represents a direct solution. By enhancing the model’s capability
    to understand and retrieve long contexts, we can directly improve agents’ performance
    in complex interaction scenarios. However, this approach depends on external technological
    advancements.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这一挑战并提升代理在复杂场景中的表现，可以考虑未来的几种策略。首先，引入更强大的LLM代表了一个直接的解决方案。通过增强模型理解和检索长上下文的能力，我们可以直接改善代理在复杂交互场景中的表现。然而，这种方法依赖于外部技术进步。
- en: Furthermore, drawing inspiration from AutoGen(Wu et al., [2023](#bib.bib34)),
    we can introduce multiple specialized agents to handle specific contextual challenges.
    These specialized agents could be designed to perform distinct functions, such
    as generating game rules and action sequences and analyzing the consequences of
    players’ moves. By isolating specific contexts, these specialized agents facilitate
    interaction among the main agents. They can work together to provide more accurate,
    efficient, and coherent content generation. For example, by distributing specific
    parts of the context and isolating the others, a certain agent can specialize
    in tracking the logical relationship between game states and player actions, while
    other agents may focus on generating descriptions and reactions that align with
    the specific game environment or scenario and action sequences of the Gadgets.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，借鉴自AutoGen（Wu等人，[2023](#bib.bib34)），我们可以引入多个专门化的代理来处理特定的上下文挑战。这些专门化代理可以设计为执行不同的功能，例如生成游戏规则和行动序列，以及分析玩家动作的后果。通过隔离特定的上下文，这些专门化代理可以促进主要代理之间的互动。它们可以协同工作，提供更准确、高效和连贯的内容生成。例如，通过分配上下文的特定部分并隔离其他部分，某些代理可以专注于跟踪游戏状态和玩家行动之间的逻辑关系，而其他代理则可以专注于生成与特定游戏环境或场景和行动序列相一致的描述和反应。
- en: Through such a two-agent collaboration system, we can not only enhance the agents’
    performance in complex game scenarios, improve content generation speed, and reduce
    token consumption to lower inference costs but also allow each agent to provide
    deep and precise processing within their areas of expertise. This enables the
    entire SUI system to better understand and reflect the complex logic of games
    and player interactions.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样的双代理协作系统，我们不仅可以提高代理在复杂游戏场景中的表现，提升内容生成速度，减少令牌消耗以降低推理成本，还可以让每个代理在其专业领域内提供深度和精确的处理。这使得整个SUI系统能够更好地理解和反映游戏和玩家互动的复杂逻辑。
- en: 6.2\. Beyond Action Planning
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2\. 超越行动规划
- en: This paper primarily focuses on the integration of SUI (Spatial User Interface)
    with LLM-based (Large Language Model-based) agents in tabletop game scenarios.
    However, the HCI (Human-Computer Interaction) field has already introduced many
    instances where SUI is combined with other interactive scenarios, including AR
    (Augmented Reality) games (Kaimoto et al., [2022](#bib.bib13)), serious games
    (Peng et al., [2020](#bib.bib21)), and remote interactions (Ihara et al., [2023](#bib.bib10)).
    This reveals the potential for our AI-Gadget Kit to inspire further research and
    applications of SUI in scenarios with complex interaction tasks. In this paper,
    we take the first step by incorporating LLM-based agents for automated action
    planning in SUI. Future expansions of our kit could enhance understanding and
    generation of SUI’s other interactive modalities. For instance, by integrating
    Add-ons like the Mechanical Shell (Nakagaki et al., [2020](#bib.bib20)), our kit
    could transform SUI action planning into planning for other interactivities (e.g.,
    Multi-DoF, Aggregation). Similarly, by generating virtual information, our kit
    could extend SUI action planning into dynamic interactions that blend virtual
    and real elements (Suzuki et al., [2020](#bib.bib28)). Moving forward, we aim
    to explore more LLM-generated SUI interaction modalities, advancing research and
    application of SUI in scenarios with complex interaction tasks.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 本文主要关注将SUI（空间用户界面）与基于LLM（大型语言模型）的代理在桌面游戏场景中的集成。然而，人机交互（HCI）领域已经引入了许多SUI与其他互动场景结合的实例，包括增强现实（AR）游戏（Kaimoto等人，[2022](#bib.bib13)）、严肃游戏（Peng等人，[2020](#bib.bib21)）和远程互动（Ihara等人，[2023](#bib.bib10)）。这揭示了我们的AI-Gadget
    Kit在复杂互动任务的场景中激发SUI进一步研究和应用的潜力。本文通过在SUI中引入基于LLM的代理来自动化行动规划，迈出了第一步。未来我们可以通过扩展我们的工具包来增强对SUI其他互动模式的理解和生成。例如，通过集成像机械外壳（Nakagaki等人，[2020](#bib.bib20)）这样的附加组件，我们的工具包可以将SUI行动规划转化为其他互动活动的规划（例如，多自由度，聚合）。类似地，通过生成虚拟信息，我们的工具包可以将SUI行动规划扩展到融合虚拟和真实元素的动态互动中（Suzuki等人，[2020](#bib.bib28)）。未来，我们旨在探索更多基于LLM生成的SUI互动模式，推动SUI在复杂互动任务场景中的研究和应用。
- en: 6.3\. Availability and Applicability
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3\. 可用性与适用性
- en: Our proposed AI-Gadget Kit aims to assist researchers, board game designers,
    and players in creatively designing interactive experiences with automated gadgets
    using natural language. By leveraging the two-agent system and various add-on
    prompts included in the kit, users can easily modify the rules for generating
    sequences of interactive actions (for example, testing can be conducted directly
    on the OpenAI GPT-4 web client).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出的 AI-Gadget Kit 旨在帮助研究人员、桌游设计师和玩家使用自然语言创造性地设计与自动化设备的互动体验。通过利用套件中的双代理系统和各种附加提示，用户可以轻松修改生成互动动作序列的规则（例如，可以直接在
    OpenAI GPT-4 网页客户端上进行测试）。
- en: However, we have identified obstacles encountered when attempting to rapidly
    debug the dynamic effects of action sequences generated by the Kit. Users must
    either conduct live tests with a corresponding number of gadgets for different
    scenarios or plot the trajectories on a coordinate system based on the content
    of the action sequences to evaluate the agent-generated content. This impedes
    the visualization of creative interactive ideas of the users.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们发现当尝试快速调试 Kit 生成的动作序列的动态效果时会遇到障碍。用户必须要么通过对应数量的设备进行实时测试以适应不同场景，要么根据动作序列的内容在坐标系统上绘制轨迹，以评估代理生成的内容。这阻碍了用户创意互动想法的可视化。
- en: Recently, WRLKits(Saberpour Abadian et al., [2023](#bib.bib24)) demonstrated
    a tool based on the interactive computational design approach, which visually
    assists designers in rapidly building personalized prototypes. Similarly, works
    like Habitat-Sim(Savva et al., [2019](#bib.bib25)) and AI2-THOR(Kolve et al.,
    [2022](#bib.bib15)) have proven the viability of simulation platforms for robot
    interaction design. In the future, we plan to develop simulation and design tools
    for the AI-Gadget Kit, enabling visualizations on web or client platforms for
    designing personalized interactions, thus making it more accessible and usable
    by many.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，WRLKits（Saberpour Abadian 等，[2023](#bib.bib24)）展示了一种基于互动计算设计方法的工具，能直观地帮助设计师快速构建个性化原型。同样，像
    Habitat-Sim（Savva 等，[2019](#bib.bib25)）和 AI2-THOR（Kolve 等，[2022](#bib.bib15)）这样的工作也证明了用于机器人互动设计的仿真平台的可行性。未来，我们计划为
    AI-Gadget Kit 开发仿真和设计工具，使其在网页或客户端平台上进行可视化，以便设计个性化的互动，从而让更多人能更方便、更易用。
- en: In addition, we have noted that the hardware costs associated with SUI capable
    of driving gadgets for interaction may hinder the widespread adoption of this
    work in board game scenarios. This is because most board game café may find it
    challenging to afford the costs of bulk purchasing expensive hardware platforms,
    such as the Sony Toio platform. To further promote our work, we will explore the
    development of lower-cost hardware platforms for the AI-Gadget Kit in the future.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们注意到，能够驱动设备进行互动的 SUI 硬件成本可能会阻碍该工作在桌游场景中的广泛应用。这是因为大多数桌游咖啡馆可能难以承担批量购买昂贵硬件平台（如
    Sony Toio 平台）的成本。为了进一步推动我们的工作，我们将探索未来为 AI-Gadget Kit 开发更低成本的硬件平台。
- en: 7\. Conclusion
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 结论
- en: While Swarm User Interfaces (SUIs) have succeeded in enriching tangible interaction
    experiences, their limitations in autonomous action planning have hindered the
    potential for personalized and dynamic interaction generation in tabletop games.
    In this paper, We proposed an AI-Gadget Kit, a multi-agent SUI tabletop gaming
    system, which is designed to facilitate dynamic and complex interaction tasks
    in tabletop games. We first introduced the system architecture of the AI-gadget
    Kit, which includes a set of swarm robots to perform the gadget behaviors, and
    a multi-agent system responsible for executing the game and generating action
    plans for the swarm robots. We then elaborated the design of the multi-agent system,
    comprising a series of meta-motions for individual robots, two LLM-based agents
    for complex action planning, and a set of add-on prompts aimed at reinforcing
    the understanding and reacting capabilities of the agents. At last, we demonstrate
    four application examples using AI-gadget Kit to showcase the effect of the multi-agent-driven
    SUI on executing complex interaction tasks in tabletop games. We aimed to use
    our work as a case study to explore and inspire the application of LLMs on action
    planning of SUI in multiple scenarios with complex interaction tasks.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然集群用户界面（SUIs）在丰富有形交互体验方面取得了成功，但它们在自主行动规划方面的局限性阻碍了个性化和动态交互生成的潜力。本文提出了一个AI-Gadget
    Kit，一个多智能体SUI桌面游戏系统，旨在促进桌面游戏中的动态和复杂交互任务。我们首先介绍了AI-gadget Kit的系统架构，其中包括一组用于执行小工具行为的集群机器人，以及一个负责执行游戏和生成集群机器人行动计划的多智能体系统。然后，我们详细阐述了多智能体系统的设计，包括针对单个机器人的一系列元运动、两个基于LLM的智能体用于复杂的行动规划，以及一组旨在强化智能体理解和反应能力的附加提示。最后，我们展示了四个应用示例，使用AI-gadget
    Kit来展示多智能体驱动的SUI在执行桌面游戏中的复杂交互任务方面的效果。我们旨在将我们的工作作为案例研究，以探索和激发LLMs在多种复杂交互任务场景中对SUI行动规划的应用。
- en: References
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: 'Brock et al. (2021) Heike Brock, Selma Šabanović, and Randy Gomez. 2021. Remote
    You, Haru and Me: Exploring Social Interaction in Telepresence Gaming With a Robotic
    Agent. In *Companion of the 2021 ACM/IEEE International Conference on Human-Robot
    Interaction* (Boulder, CO, USA) *(HRI ’21 Companion)*. Association for Computing
    Machinery, New York, NY, USA, 283–287. [https://doi.org/10.1145/3434074.3447177](https://doi.org/10.1145/3434074.3447177)'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brock 等人（2021）Heike Brock、Selma Šabanović 和 Randy Gomez。2021年。远程的你、Haru 和我：通过机器人智能体探索远程存在游戏中的社会互动。在
    *2021 ACM/IEEE International Conference on Human-Robot Interaction*（Boulder, CO,
    USA） *（HRI ’21 Companion）*。计算机协会，美国纽约，283–287。 [https://doi.org/10.1145/3434074.3447177](https://doi.org/10.1145/3434074.3447177)
- en: 'Dementyev et al. (2016) Artem Dementyev, Hsin-Liu (Cindy) Kao, Inrak Choi,
    Deborah Ajilo, Maggie Xu, Joseph A. Paradiso, Chris Schmandt, and Sean Follmer.
    2016. Rovables: Miniature On-Body Robots as Mobile Wearables. In *Proceedings
    of the 29th Annual Symposium on User Interface Software and Technology* (Tokyo,
    Japan) *(UIST ’16)*. Association for Computing Machinery, New York, NY, USA, 111–120.
    [https://doi.org/10.1145/2984511.2984531](https://doi.org/10.1145/2984511.2984531)'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dementyev 等人（2016）Artem Dementyev、Hsin-Liu（Cindy）Kao、Inrak Choi、Deborah Ajilo、Maggie
    Xu、Joseph A. Paradiso、Chris Schmandt 和 Sean Follmer。2016年。Rovables：作为移动穿戴设备的迷你身体机器人。在
    *Proceedings of the 29th Annual Symposium on User Interface Software and Technology*（东京，日本）
    *（UIST ’16）*。计算机协会，美国纽约，111–120。 [https://doi.org/10.1145/2984511.2984531](https://doi.org/10.1145/2984511.2984531)
- en: Felsman et al. (2019) Peter Felsman, Colleen M. Seifert, and Joseph A. Himle.
    2019. The use of improvisational theater training to reduce social anxiety in
    adolescents. *The Arts in Psychotherapy* 63 (2019), 111–117. [https://doi.org/10.1016/j.aip.2018.12.001](https://doi.org/10.1016/j.aip.2018.12.001)
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Felsman 等人（2019）Peter Felsman、Colleen M. Seifert 和 Joseph A. Himle。2019年。使用即兴戏剧训练来减少青少年的社交焦虑。*The
    Arts in Psychotherapy* 63（2019），111–117。 [https://doi.org/10.1016/j.aip.2018.12.001](https://doi.org/10.1016/j.aip.2018.12.001)
- en: 'Gan et al. (2020) Chuang Gan, Yiwei Zhang, Jiajun Wu, Boqing Gong, and Joshua B
    Tenenbaum. 2020. Look, listen, and act: Towards audio-visual embodied navigation.
    In *2020 IEEE International Conference on Robotics and Automation (ICRA)*. IEEE,
    9701–9707.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gan 等人（2020）Chuang Gan、Yiwei Zhang、Jiajun Wu、Boqing Gong 和 Joshua B Tenenbaum。2020年。看、听、行动：朝着视听化的具身导航迈进。在
    *2020 IEEE International Conference on Robotics and Automation (ICRA)*。IEEE，9701–9707。
- en: 'Gillet et al. (2020) Sarah Gillet, Wouter van den Bos, Iolanda Leite, et al.
    2020. A social robot mediator to foster collaboration and inclusion among children..
    In *Robotics: Science and Systems*.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gillet 等人（2020）Sarah Gillet、Wouter van den Bos、Iolanda Leite 等人。2020年。一个社会机器人调解员以促进儿童之间的合作和包容。在
    *Robotics: Science and Systems*。'
- en: Guo et al. (2023) Yijie Guo, Zhenhan Huang, Ruhan Wang, Chih-Heng Li, Ruoyu
    Wu, Qirui Sun, Zhihao Yao, Haipeng Mi, and Yu Peng. 2023. Sparkybot:An Embodied
    AI Agent-Powered Robot with Customizable Characters andInteraction Behavior for
    Children. In *Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface
    Software and Technology* (¡conf-loc¿, ¡city¿San Francisco¡/city¿, ¡state¿CA¡/state¿,
    ¡country¿USA¡/country¿, ¡/conf-loc¿) *(UIST ’23 Adjunct)*. Association for Computing
    Machinery, New York, NY, USA, Article 90, 3 pages. [https://doi.org/10.1145/3586182.3615804](https://doi.org/10.1145/3586182.3615804)
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Guo 等 (2023) Yijie Guo, Zhenhan Huang, Ruhan Wang, Chih-Heng Li, Ruoyu Wu,
    Qirui Sun, Zhihao Yao, Haipeng Mi 和 Yu Peng. 2023. Sparkybot: 一个具备可定制角色和交互行为的具身AI代理驱动的儿童机器人。发表于
    *第36届年度ACM用户界面软件与技术研讨会附录论文集*（¡conf-loc¿, ¡city¿旧金山¡/city¿, ¡state¿CA¡/state¿,
    ¡country¿美国¡/country¿, ¡/conf-loc¿）*(UIST ’23 Adjunct)*。计算机协会，美国纽约，文章90，第3页。 [https://doi.org/10.1145/3586182.3615804](https://doi.org/10.1145/3586182.3615804)'
- en: 'Huang et al. (2023b) Wenlong Huang, Chen Wang, Ruohan Zhang, Yunzhu Li, Jiajun
    Wu, and Li Fei-Fei. 2023b. Voxposer: Composable 3d value maps for robotic manipulation
    with language models. *arXiv preprint arXiv:2307.05973* (2023).'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Huang 等 (2023b) Wenlong Huang, Chen Wang, Ruohan Zhang, Yunzhu Li, Jiajun Wu
    和 Li Fei-Fei. 2023b. Voxposer: 用于机器人操控的可组合三维价值图与语言模型。*arXiv预印本 arXiv:2307.05973*
    (2023)。'
- en: 'Huang et al. (2023a) Xiaoyu Huang, Dhruv Batra, Akshara Rai, and Andrew Szot.
    2023a. Skill transformer: A monolithic policy for mobile manipulation. In *Proceedings
    of the IEEE/CVF International Conference on Computer Vision*. 10852–10862.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Huang 等 (2023a) Xiaoyu Huang, Dhruv Batra, Akshara Rai 和 Andrew Szot. 2023a.
    Skill transformer: 移动操控的整体策略。发表于 *IEEE/CVF国际计算机视觉会议论文集*。第10852–10862页。'
- en: 'Ihara et al. (2023) Keiichi Ihara, Mehrad Faridan, Ayumi Ichikawa, Ikkaku Kawaguchi,
    and Ryo Suzuki. 2023. HoloBots: Augmenting Holographic Telepresence with Mobile
    Robots for Tangible Remote Collaboration in Mixed Reality. In *Proceedings of
    the 36th Annual ACM Symposium on User Interface Software and Technology* (¡conf-loc¿,
    ¡city¿San Francisco¡/city¿, ¡state¿CA¡/state¿, ¡country¿USA¡/country¿, ¡/conf-loc¿)
    *(UIST ’23)*. Association for Computing Machinery, New York, NY, USA, Article
    119, 12 pages. [https://doi.org/10.1145/3586183.3606727](https://doi.org/10.1145/3586183.3606727)'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ihara 等 (2023) Keiichi Ihara, Mehrad Faridan, Ayumi Ichikawa, Ikkaku Kawaguchi
    和 Ryo Suzuki. 2023. HoloBots: 通过移动机器人增强全息远程协作，以实现混合现实中的有形远程协作。发表于 *第36届年度ACM用户界面软件与技术研讨会论文集*（¡conf-loc¿,
    ¡city¿旧金山¡/city¿, ¡state¿CA¡/state¿, ¡country¿美国¡/country¿, ¡/conf-loc¿）*(UIST
    ’23)*。计算机协会，美国纽约，文章119，第12页。 [https://doi.org/10.1145/3586183.3606727](https://doi.org/10.1145/3586183.3606727)'
- en: Jariyavajee et al. (2018) Chattriya Jariyavajee, Arnon Visavakitcharoen, Preeyaphond
    Sirimaha, Booncharoen Sirinaovakul, and Jumpol Polvichai. 2018. A Practical interactive
    chess board with automatic movement control. In *2018 Global Wireless Summit (GWS)*.
    IEEE, 246–250.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jariyavajee 等 (2018) Chattriya Jariyavajee, Arnon Visavakitcharoen, Preeyaphond
    Sirimaha, Booncharoen Sirinaovakul 和 Jumpol Polvichai. 2018. 一种实用的交互式棋盘，具有自动运动控制。发表于
    *2018全球无线峰会 (GWS)*。IEEE，第246–250页。
- en: 'Johnstone (2012) Keith Johnstone. 2012. *Impro: Improvisation and the theatre*.
    Routledge.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Johnstone (2012) Keith Johnstone. 2012. *即兴：即兴创作与戏剧*。劳特利奇。
- en: 'Kaimoto et al. (2022) Hiroki Kaimoto, Kyzyl Monteiro, Mehrad Faridan, Jiatong
    Li, Samin Farajian, Yasuaki Kakehi, Ken Nakagaki, and Ryo Suzuki. 2022. Sketched
    reality: Sketching bi-directional interactions between virtual and physical worlds
    with ar and actuated tangible ui. In *Proceedings of the 35th Annual ACM Symposium
    on User Interface Software and Technology*. 1–12.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kaimoto 等 (2022) Hiroki Kaimoto, Kyzyl Monteiro, Mehrad Faridan, Jiatong Li,
    Samin Farajian, Yasuaki Kakehi, Ken Nakagaki 和 Ryo Suzuki. 2022. 速写现实：利用增强现实和驱动型有形用户界面绘制虚拟与物理世界之间的双向交互。发表于
    *第35届年度ACM用户界面软件与技术研讨会论文集*。第1–12页。
- en: 'Kim and Follmer (2019) Lawrence H. Kim and Sean Follmer. 2019. SwarmHaptics:
    Haptic Display with Swarm Robots. In *Proceedings of the 2019 CHI Conference on
    Human Factors in Computing Systems* (Glasgow, Scotland Uk) *(CHI ’19)*. Association
    for Computing Machinery, New York, NY, USA, 1–13. [https://doi.org/10.1145/3290605.3300918](https://doi.org/10.1145/3290605.3300918)'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kim 和 Follmer (2019) Lawrence H. Kim 和 Sean Follmer. 2019. SwarmHaptics: 具有群体机器人触觉显示。发表于
    *2019年CHI计算机系统人因会议论文集*（苏格兰格拉斯哥，英国）*(CHI ’19)*。计算机协会，美国纽约，第1–13页。 [https://doi.org/10.1145/3290605.3300918](https://doi.org/10.1145/3290605.3300918)'
- en: 'Kolve et al. (2022) Eric Kolve, Roozbeh Mottaghi, Winson Han, Eli VanderBilt,
    Luca Weihs, Alvaro Herrasti, Matt Deitke, Kiana Ehsani, Daniel Gordon, Yuke Zhu,
    Aniruddha Kembhavi, Abhinav Gupta, and Ali Farhadi. 2022. AI2-THOR: An Interactive
    3D Environment for Visual AI. arXiv:1712.05474 [cs.CV]'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kolve等（2022）Eric Kolve、Roozbeh Mottaghi、Winson Han、Eli VanderBilt、Luca Weihs、Alvaro
    Herrasti、Matt Deitke、Kiana Ehsani、Daniel Gordon、Yuke Zhu、Aniruddha Kembhavi、Abhinav
    Gupta和Ali Farhadi。2022年。AI2-THOR：一个用于视觉AI的互动3D环境。arXiv:1712.05474 [cs.CV]
- en: 'Li et al. (2022) Jiannan Li, Maurício Sousa, Chu Li, Jessie Liu, Yan Chen,
    Ravin Balakrishnan, and Tovi Grossman. 2022. ASTEROIDS: Exploring Swarms of Mini-Telepresence
    Robots for Physical Skill Demonstration. In *Proceedings of the 2022 CHI Conference
    on Human Factors in Computing Systems* (¡conf-loc¿, ¡city¿New Orleans¡/city¿,
    ¡state¿LA¡/state¿, ¡country¿USA¡/country¿, ¡/conf-loc¿) *(CHI ’22)*. Association
    for Computing Machinery, New York, NY, USA, Article 111, 14 pages. [https://doi.org/10.1145/3491102.3501927](https://doi.org/10.1145/3491102.3501927)'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li等（2022）Jiannan Li、Maurício Sousa、Chu Li、Jessie Liu、Yan Chen、Ravin Balakrishnan和Tovi
    Grossman。2022年。ASTEROIDS：探索用于物理技能展示的迷你远程机器人群。在*2022年CHI计算机系统人因会议*的会议记录中（¡conf-loc¿，¡city¿新奥尔良¡/city¿，¡state¿LA¡/state¿，¡country¿美国¡/country¿，¡/conf-loc¿）*(CHI
    ’22)*。计算机协会，纽约，NY，美国，第111篇，14页。 [https://doi.org/10.1145/3491102.3501927](https://doi.org/10.1145/3491102.3501927)
- en: Liu et al. (2021) Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence
    Carin, and Weizhu Chen. 2021. What Makes Good In-Context Examples for GPT-$3$?
    *arXiv preprint arXiv:2101.06804* (2021).
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu等（2021）Jiachang Liu、Dinghan Shen、Yizhe Zhang、Bill Dolan、Lawrence Carin和Weizhu
    Chen。2021年。什么样的上下文示例对GPT-$3$效果好？*arXiv预印本 arXiv:2101.06804*（2021年）。
- en: 'Long et al. (2023) Yuxing Long, Xiaoqi Li, Wenzhe Cai, and Hao Dong. 2023.
    Discuss before moving: Visual language navigation via multi-expert discussions.
    *arXiv preprint arXiv:2309.11382* (2023).'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Long等（2023）Yuxing Long、Xiaoqi Li、Wenzhe Cai和Hao Dong。2023年。讨论后再移动：通过多专家讨论进行视觉语言导航。*arXiv预印本
    arXiv:2309.11382*（2023年）。
- en: 'Matuszek et al. (2011) Cynthia Matuszek, Brian Mayton, Roberto Aimi, Marc Peter
    Deisenroth, Liefeng Bo, Robert Chu, Mike Kung, Louis LeGrand, Joshua R Smith,
    and Dieter Fox. 2011. Gambit: An autonomous chess-playing robotic system. In *2011
    IEEE international conference on robotics and automation*. IEEE, 4291–4297.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matuszek等（2011）Cynthia Matuszek、Brian Mayton、Roberto Aimi、Marc Peter Deisenroth、Liefeng
    Bo、Robert Chu、Mike Kung、Louis LeGrand、Joshua R Smith和Dieter Fox。2011年。Gambit：一个自主象棋机器人系统。在*2011
    IEEE国际机器人与自动化会议*上。IEEE，4291–4297。
- en: 'Nakagaki et al. (2020) Ken Nakagaki, Joanne Leong, Jordan L. Tappa, João Wilbert,
    and Hiroshi Ishii. 2020. HERMITS: Dynamically Reconfiguring the Interactivity
    of Self-propelled TUIs with Mechanical Shell Add-ons. In *Proceedings of the 33rd
    Annual ACM Symposium on User Interface Software and Technology* (Virtual Event,
    USA) *(UIST ’20)*. Association for Computing Machinery, New York, NY, USA, 882–896.
    [https://doi.org/10.1145/3379337.3415831](https://doi.org/10.1145/3379337.3415831)'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nakagaki等（2020）Ken Nakagaki、Joanne Leong、Jordan L. Tappa、João Wilbert和Hiroshi
    Ishii。2020年。HERMITS：通过机械外壳附加件动态重新配置自驱动TUI的互动性。在*第33届ACM用户界面软件与技术年会*（虚拟会议，美国）*(UIST
    ’20)*中。计算机协会，纽约，NY，美国，882–896。 [https://doi.org/10.1145/3379337.3415831](https://doi.org/10.1145/3379337.3415831)
- en: 'Peng et al. (2020) Yu Peng, Yuan-Ling Feng, Nan Wang, and Haipeng Mi. 2020.
    How children interpret robots’ contextual behaviors in live theatre: Gaining insights
    for multi-robot theatre design. In *2020 29th IEEE International Conference on
    Robot and Human Interactive Communication (RO-MAN)*. IEEE, 327–334.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Peng等（2020）Yu Peng、Yuan-Ling Feng、Nan Wang和Haipeng Mi。2020年。儿童如何在现场剧场中解读机器人上下文行为：为多机器人剧场设计获取见解。在*2020年第29届IEEE国际机器人与人机互动通信会议（RO-MAN）*上。IEEE，327–334。
- en: 'Qiao et al. (2023) Yanyuan Qiao, Yuankai Qi, Zheng Yu, Jing Liu, and Qi Wu.
    2023. March in chat: Interactive prompting for remote embodied referring expression.
    In *Proceedings of the IEEE/CVF International Conference on Computer Vision*.
    15758–15767.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qiao等（2023）Yanyuan Qiao、Yuankai Qi、Zheng Yu、Jing Liu和Qi Wu。2023年。在聊天中行动：用于远程体现参照表达的互动提示。在*IEEE/CVF国际计算机视觉大会*的会议记录中。15758–15767。
- en: Raman et al. (2022) Shreyas Sundara Raman, Vanya Cohen, Eric Rosen, Ifrah Idrees,
    David Paulius, and Stefanie Tellex. 2022. Planning with large language models
    via corrective re-prompting. In *NeurIPS 2022 Foundation Models for Decision Making
    Workshop*.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raman等（2022）Shreyas Sundara Raman、Vanya Cohen、Eric Rosen、Ifrah Idrees、David
    Paulius和Stefanie Tellex。2022年。通过纠正重提示进行大语言模型的规划。在*NeurIPS 2022基础模型决策制定研讨会*中。
- en: Saberpour Abadian et al. (2023) Artin Saberpour Abadian, Ata Otaran, Martin
    Schmitz, Marie Muehlhaus, Rishabh Dabral, Diogo Luvizon, Azumi Maekawa, Masahiko
    Inami, Christian Theobalt, and Jürgen Steimle. 2023. Computational Design of Personalized
    Wearable Robotic Limbs. In *Proceedings of the 36th Annual ACM Symposium on User
    Interface Software and Technology* (¡conf-loc¿, ¡city¿San Francisco¡/city¿, ¡state¿CA¡/state¿,
    ¡country¿USA¡/country¿, ¡/conf-loc¿) *(UIST ’23)*. Association for Computing Machinery,
    New York, NY, USA, Article 68, 13 pages. [https://doi.org/10.1145/3586183.3606748](https://doi.org/10.1145/3586183.3606748)
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Saberpour Abadian 等（2023）Artin Saberpour Abadian, Ata Otaran, Martin Schmitz,
    Marie Muehlhaus, Rishabh Dabral, Diogo Luvizon, Azumi Maekawa, Masahiko Inami,
    Christian Theobalt, 和 Jürgen Steimle。2023年。个性化可穿戴机器人肢体的计算设计。发表于 *第36届年度ACM用户界面软件与技术研讨会论文集*（¡conf-loc¿，¡city¿旧金山¡/city¿，¡state¿CA¡/state¿，¡country¿美国¡/country¿，¡/conf-loc¿）
    *(UIST ’23)*。计算机协会，纽约，NY，美国，文章68，13页。[https://doi.org/10.1145/3586183.3606748](https://doi.org/10.1145/3586183.3606748)
- en: 'Savva et al. (2019) Manolis Savva, Abhishek Kadian, Oleksandr Maksymets, Yili
    Zhao, Erik Wijmans, Bhavana Jain, Julian Straub, Jia Liu, Vladlen Koltun, Jitendra
    Malik, et al. 2019. Habitat: A platform for embodied ai research. In *Proceedings
    of the IEEE/CVF international conference on computer vision*. 9339–9347.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Savva 等（2019）Manolis Savva, Abhishek Kadian, Oleksandr Maksymets, Yili Zhao,
    Erik Wijmans, Bhavana Jain, Julian Straub, Jia Liu, Vladlen Koltun, Jitendra Malik
    等。2019年。Habitat: 一个用于体现AI研究的平台。发表于 *IEEE/CVF国际计算机视觉会议论文集*。9339–9347。'
- en: 'Sawyer (2000) R. Keith Sawyer. 2000. Improvisational Cultures: Collaborative
    Emergence and Creativity in Improvisation. *Mind, Culture, and Activity* 7, 3
    (2000), 180–185. [https://doi.org/10.1207/S15327884MCA0703_05](https://doi.org/10.1207/S15327884MCA0703_05)
    arXiv:https://doi.org/10.1207/S15327884MCA0703_05'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sawyer（2000）R. Keith Sawyer。2000年。即兴文化：即兴创作中的协作涌现与创造力。*思维、文化与活动* 7，3（2000），180–185。[https://doi.org/10.1207/S15327884MCA0703_05](https://doi.org/10.1207/S15327884MCA0703_05)
    arXiv:[https://doi.org/10.1207/S15327884MCA0703_05](https://doi.org/10.1207/S15327884MCA0703_05)
- en: 'Schwenke et al. (2021) Diana Schwenke, Maja Dshemuchadse, Lisa Rasehorn, Dominik
    Klarholter, and Stefan Scherbaum. 2021. Improv to Improve: The Impact of Improvisational
    Theater on Creativity, Acceptance, and Psychological Well-Being. *Journal of Creativity
    in Mental Health* 16, 1 (2021), 31–48. [https://doi.org/10.1080/15401383.2020.1754987](https://doi.org/10.1080/15401383.2020.1754987)
    arXiv:https://doi.org/10.1080/15401383.2020.1754987'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schwenke 等（2021）Diana Schwenke, Maja Dshemuchadse, Lisa Rasehorn, Dominik Klarholter,
    和 Stefan Scherbaum。2021年。即兴演出以提升：即兴剧对创造力、接受度和心理健康的影响。*心理健康创造力杂志* 16，1（2021），31–48。[https://doi.org/10.1080/15401383.2020.1754987](https://doi.org/10.1080/15401383.2020.1754987)
    arXiv:[https://doi.org/10.1080/15401383.2020.1754987](https://doi.org/10.1080/15401383.2020.1754987)
- en: 'Suzuki et al. (2020) Ryo Suzuki, Rubaiat Habib Kazi, Li-yi Wei, Stephen DiVerdi,
    Wilmot Li, and Daniel Leithinger. 2020. RealitySketch: Embedding Responsive Graphics
    and Visualizations in AR through Dynamic Sketching. In *Proceedings of the 33rd
    Annual ACM Symposium on User Interface Software and Technology* (Virtual Event,
    USA) *(UIST ’20)*. Association for Computing Machinery, New York, NY, USA, 166–181.
    [https://doi.org/10.1145/3379337.3415892](https://doi.org/10.1145/3379337.3415892)'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Suzuki 等（2020）Ryo Suzuki, Rubaiat Habib Kazi, Li-yi Wei, Stephen DiVerdi, Wilmot
    Li, 和 Daniel Leithinger。2020年。RealitySketch：通过动态草图在AR中嵌入响应性图形和可视化。发表于 *第33届年度ACM用户界面软件与技术研讨会论文集*（虚拟会议，美国）
    *(UIST ’20)*。计算机协会，纽约，NY，美国，166–181。[https://doi.org/10.1145/3379337.3415892](https://doi.org/10.1145/3379337.3415892)
- en: 'Suzuki et al. (2019) Ryo Suzuki, Clement Zheng, Yasuaki Kakehi, Tom Yeh, Ellen
    Yi-Luen Do, Mark D. Gross, and Daniel Leithinger. 2019. ShapeBots: Shape-changing
    Swarm Robots. In *Proceedings of the 32nd Annual ACM Symposium on User Interface
    Software and Technology* (New Orleans, LA, USA) *(UIST ’19)*. Association for
    Computing Machinery, New York, NY, USA, 493–505. [https://doi.org/10.1145/3332165.3347911](https://doi.org/10.1145/3332165.3347911)'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Suzuki 等（2019）Ryo Suzuki, Clement Zheng, Yasuaki Kakehi, Tom Yeh, Ellen Yi-Luen
    Do, Mark D. Gross, 和 Daniel Leithinger。2019年。ShapeBots：形状变化的群体机器人。发表于 *第32届年度ACM用户界面软件与技术研讨会论文集*（新奥尔良，LA，美国）
    *(UIST ’19)*。计算机协会，纽约，NY，美国，493–505。[https://doi.org/10.1145/3332165.3347911](https://doi.org/10.1145/3332165.3347911)
- en: 'van Breemen et al. (2005) Albert van Breemen, Xue Yan, and Bernt Meerbeek.
    2005. iCat: an animated user-interface robot with personality. In *Proceedings
    of the Fourth International Joint Conference on Autonomous Agents and Multiagent
    Systems* (The Netherlands) *(AAMAS ’05)*. Association for Computing Machinery,
    New York, NY, USA, 143–144. [https://doi.org/10.1145/1082473.1082823](https://doi.org/10.1145/1082473.1082823)'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: van Breemen 等（2005）Albert van Breemen, Xue Yan, 和 Bernt Meerbeek。2005。iCat：一个具有个性的动画用户界面机器人。发表于
    *第四届国际自主智能体与多智能体系统联合会议论文集*（荷兰） *(AAMAS ’05)*。计算机协会，美国纽约，143–144。 [https://doi.org/10.1145/1082473.1082823](https://doi.org/10.1145/1082473.1082823)
- en: Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit,
    Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention
    is all you need. *Advances in neural information processing systems* 30 (2017).
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vaswani 等（2017）Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion
    Jones, Aidan N Gomez, Łukasz Kaiser, 和 Illia Polosukhin。2017。注意力机制是你所需的一切。*神经信息处理系统进展*
    30（2017）。
- en: 'Wang et al. (2020) Xin Eric Wang, Vihan Jain, Eugene Ie, William Yang Wang,
    Zornitsa Kozareva, and Sujith Ravi. 2020. Environment-agnostic multitask learning
    for natural language grounded navigation. In *Computer Vision–ECCV 2020: 16th
    European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XXIV 16*.
    Springer, 413–430.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等（2020）Xin Eric Wang, Vihan Jain, Eugene Ie, William Yang Wang, Zornitsa
    Kozareva, 和 Sujith Ravi。2020。面向环境无关的多任务学习用于自然语言基础导航。发表于 *计算机视觉–ECCV 2020：第16届欧洲会议，英国格拉斯哥，2020年8月23–28日，论文集，第XXIV卷第16篇*。Springer，413–430。
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei
    Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits
    reasoning in large language models. *Advances in neural information processing
    systems* 35 (2022), 24824–24837.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等（2022）Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia,
    Ed Chi, Quoc V Le, Denny Zhou 等。2022。链式思维提示引发大型语言模型的推理。*神经信息处理系统进展* 35（2022），24824–24837。
- en: 'Wu et al. (2023) Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang,
    Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. 2023. Autogen: Enabling
    next-gen llm applications via multi-agent conversation framework. *arXiv preprint
    arXiv:2308.08155* (2023).'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等（2023）Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang
    Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, 和 Chi Wang。2023。Autogen：通过多智能体对话框架实现下一代大型语言模型应用。*arXiv预印本
    arXiv:2308.08155*（2023）。
- en: 'Yu et al. (2023) Lilith Yu, Chenfeng Gao, David Wu, and Ken Nakagaki. 2023.
    AeroRigUI: Actuated TUIs for Spatial Interaction using Rigging Swarm Robots on
    Ceilings in Everyday Space. In *Proceedings of the 2023 CHI Conference on Human
    Factors in Computing Systems*. 1–18.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu 等（2023）Lilith Yu, Chenfeng Gao, David Wu, 和 Ken Nakagaki。2023。AeroRigUI：利用悬挂在天花板上的装配群体机器人进行空间交互的驱动式触控界面。发表于
    *2023年CHI计算机系统人因会议论文集*。1–18。
- en: 'Zhu et al. (2021) Jichen Zhu, Jennifer Villareale, Nithesh Javvaji, Sebastian
    Risi, Mathias Löwe, Rush Weigelt, and Casper Harteveld. 2021. Player-AI interaction:
    What neural network games reveal about AI as play. In *Proceedings of the 2021
    CHI Conference on Human Factors in Computing Systems*. 1–17.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu 等（2021）Jichen Zhu, Jennifer Villareale, Nithesh Javvaji, Sebastian Risi,
    Mathias Löwe, Rush Weigelt, 和 Casper Harteveld。2021。玩家-AI 互动：神经网络游戏揭示了AI作为游戏的表现。发表于
    *2021年CHI计算机系统人因会议论文集*。1–17。
