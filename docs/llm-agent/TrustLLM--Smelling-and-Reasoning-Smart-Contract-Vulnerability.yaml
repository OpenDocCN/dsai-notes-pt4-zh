- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 18:49:38'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:49:38
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'TrustLLM: Smelling and Reasoning Smart Contract Vulnerability'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'TrustLLM: 智能合约漏洞的嗅探与推理'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2403.16073](https://ar5iv.labs.arxiv.org/html/2403.16073)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2403.16073](https://ar5iv.labs.arxiv.org/html/2403.16073)
- en: 'Wei Ma1, Daoyuan Wu1, Yuqiang Sun1, Tianwen Wang2, Shangqing Liu1, Jian Zhang1,
    Yue Xue3, and Yang Liu1 Corresponding author: Daoyuan Wu. 1Nanyang Technological
    University, Singapore 2National University of Singapore, Singapore 3MetaTrust
    Labs, Singapore'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 魏玛1，吴道元1，孙宇强1，王天文2，刘尚青1，张健1，薛越3，刘洋1  论文通讯作者：吴道元。1南洋理工大学，新加坡 2新加坡国立大学，新加坡 3MetaTrust实验室，新加坡
- en: 'TrustLLM: Unified Fine-Tuning and LLM Agents for Smart Contract Auditing with
    Justifications'
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'TrustLLM: 统一微调和LLM代理的智能合约审计及其理由'
- en: 'Wei Ma1, Daoyuan Wu1, Yuqiang Sun1, Tianwen Wang2, Shangqing Liu1, Jian Zhang1,
    Yue Xue3, and Yang Liu1 Corresponding author: Daoyuan Wu. 1Nanyang Technological
    University, Singapore 2National University of Singapore, Singapore 3MetaTrust
    Labs, Singapore'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 魏玛1，吴道元1，孙宇强1，王天文2，刘尚青1，张健1，薛越3，刘洋1  论文通讯作者：吴道元。1南洋理工大学，新加坡 2新加坡国立大学，新加坡 3MetaTrust实验室，新加坡
- en: Combining Fine-Tuning and LLM-based Agents for Intuitive Smart Contract Auditing
    with Justifications
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结合微调和基于LLM的智能合约审计代理及其理由
- en: 'Wei Ma1, Daoyuan Wu1, Yuqiang Sun1, Tianwen Wang2, Shangqing Liu1, Jian Zhang1,
    Yue Xue3, and Yang Liu1 Corresponding author: Daoyuan Wu. 1Nanyang Technological
    University, Singapore 2National University of Singapore, Singapore 3MetaTrust
    Labs, Singapore'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 魏玛1，吴道元1，孙宇强1，王天文2，刘尚青1，张健1，薛越3，刘洋1  论文通讯作者：吴道元。1南洋理工大学，新加坡 2新加坡国立大学，新加坡 3MetaTrust实验室，新加坡
- en: Abstract
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Smart contracts are decentralized applications built atop blockchains like Ethereum.
    Recent research has shown that large language models (LLMs) have potential in
    auditing smart contracts, but the state-of-the-art indicates that even GPT-4 can
    achieve only 30% precision (when both decision and justification are correct).
    This is likely because off-the-shelf LLMs were primarily pre-trained on a general
    text/code corpus and not fine-tuned on the specific domain of Solidity smart contract
    auditing.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 智能合约是建立在区块链（如以太坊）上的去中心化应用程序。近期研究表明，大型语言模型（LLMs）在审计智能合约方面具有潜力，但最新研究表明，即便是GPT-4也只能达到30%的精确度（当决策和理由都正确时）。这可能是因为现成的LLM主要在通用文本/代码语料库上进行预训练，而不是在特定的Solidity智能合约审计领域上进行微调。
- en: 'In this paper, we propose TrustLLM, a general framework that combines fine-tuning
    and LLM-based agents for intuitive smart contract auditing with justifications.
    Specifically, TrustLLM is inspired by the observation that expert human auditors
    first perceive what could be wrong and then perform a detailed analysis of the
    code to identify the cause. As such, TrustLLM employs a two-stage fine-tuning
    approach: it first tunes a Detector model to make decisions and then tunes a Reasoner
    model to generate causes of vulnerabilities. However, fine-tuning alone faces
    challenges in accurately identifying the optimal cause of a vulnerability. Therefore,
    we introduce two LLM-based agents, the Ranker and Critic, to iteratively select
    and debate the most suitable cause of vulnerability based on the output of the
    fine-tuned Reasoner model. To evaluate TrustLLM, we collected a balanced dataset
    with 1,734 positive and 1,810 negative samples to fine-tune TrustLLM. We then
    compared it with traditional fine-tuned models (CodeBERT, GraphCodeBERT, CodeT5,
    and UnixCoder) as well as prompt learning-based LLMs (GPT4, GPT-3.5, and CodeLlama-13b/34b).
    On a dataset of 263 real smart contract vulnerabilities, TrustLLM achieves an
    F1 score of 91.21% and an accuracy of 91.11%. The causes generated by TrustLLM
    achieved a consistency of about 38% compared to the ground truth causes.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提出了TrustLLM，这是一个结合了微调和基于LLM的代理的通用框架，用于直观的智能合约审计和解释。具体来说，TrustLLM的灵感来源于观察到的专业人工审计师的行为，他们首先感知可能出现的问题，然后对代码进行详细分析以识别原因。因此，TrustLLM采用了两阶段微调方法：首先微调一个Detector模型以做出决策，然后微调一个Reasoner模型以生成漏洞原因。然而，仅凭微调在准确识别漏洞的最佳原因上面临挑战。因此，我们引入了两个基于LLM的代理——Ranker和Critic，基于微调后的Reasoner模型输出，迭代选择和辩论最合适的漏洞原因。为了评估TrustLLM，我们收集了一个平衡的数据集，包括1,734个正样本和1,810个负样本来微调TrustLLM。然后，我们将其与传统的微调模型（CodeBERT、GraphCodeBERT、CodeT5和UnixCoder）以及基于提示学习的LLM（GPT4、GPT-3.5和CodeLlama-13b/34b）进行比较。在263个真实智能合约漏洞的数据集上，TrustLLM达到了91.21%的F1分数和91.11%的准确率。TrustLLM生成的漏洞原因与真实原因的一致性约为38%。
- en: “One of the big skills in bug
    bounties that’s really difficult to teach is intuition. Everything I do I am following
    my intuition. It’s what looks interesting and what doesn’t look right.” — Katie
    Paxton-Fear One of the million-dollar-earning hackers [[1](#bib.bib1)].
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: “One of the big skills in bug
    bounties that’s really difficult to teach is intuition. Everything I do I am following
    my intuition. It’s what looks interesting and what doesn’t look right.” — Katie
    Paxton-Fear One of the million-dollar-earning hackers [[1](#bib.bib1)].
- en: I Introduction
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I 引言
- en: Smart contracts have emerged as a key application based on blockchain technology
    since the advent of Ethereum. Due to their openness, transparency, and irreversibility,
    smart contracts have become the foundation of decentralized financial applications
    (DeFi). However, since DeFi manages a significant amount of digital assets, identifying
    and fixing vulnerabilities in smart contracts is crucial. Currently, the real
    vulnerabilities exploited by hackers in smart contracts are mainly due to logical
    flaws [[2](#bib.bib2)], which render traditional pattern-based program analysis [[3](#bib.bib3),
    [4](#bib.bib4), [5](#bib.bib5), [6](#bib.bib6), [7](#bib.bib7), [8](#bib.bib8),
    [9](#bib.bib9), [10](#bib.bib10)] less effective. According to Defillama Hacks [[11](#bib.bib11)],
    vulnerability attacks have caused losses of around $7.69 billion as of March 2024.
    Hence, there is an urgent need for innovative methods to combat these emerging
    threats.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 智能合约自以太坊出现以来，已成为基于区块链技术的关键应用。由于其开放性、透明性和不可逆性，智能合约已成为去中心化金融应用（DeFi）的基础。然而，由于DeFi管理大量数字资产，识别和修复智能合约中的漏洞至关重要。目前，黑客利用的智能合约实际漏洞主要由于逻辑缺陷 [[2](#bib.bib2)]，这使得传统基于模式的程序分析 [[3](#bib.bib3),
    [4](#bib.bib4), [5](#bib.bib5), [6](#bib.bib6), [7](#bib.bib7), [8](#bib.bib8),
    [9](#bib.bib9), [10](#bib.bib10)] 效果不佳。根据Defillama Hacks [[11](#bib.bib11)]，截至2024年3月，漏洞攻击已造成约76.9亿美元的损失。因此，迫切需要创新方法来应对这些新兴威胁。
- en: Recent research [[12](#bib.bib12), [13](#bib.bib13), [14](#bib.bib14), [15](#bib.bib15)]
    has shown that large language models (LLMs) have potential in auditing smart contracts,
    especially in demonstrating superior performance in detecting logic vulnerabilities [[2](#bib.bib2),
    [13](#bib.bib13)]. However, a recent systematic evaluation study [[15](#bib.bib15)]
    shows that even when equipping the LLM-based vulnerability detection paradigm
    with a state-of-the-art approach, namely enhancing GPT-4 with summarized vulnerability
    knowledge in a Retrieval Augmented Generation (RAG) [[16](#bib.bib16)] fashion,
    it still achieves only $\sim$30% precision when both the decision (i.e., whether
    the subject code is vulnerable) and justification (i.e., pinpointing the correct
    vulnerability type) are correct. This can be attributed to the fact that off-the-shelf
    LLMs (e.g., GPT-4), which were primarily pre-trained on a general text/code corpus,
    were not fine-tuned for the specific domain of Solidity¹¹1Solidity is a mainstream
    language for smart contract development. smart contract auditing.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究[[12](#bib.bib12), [13](#bib.bib13), [14](#bib.bib14), [15](#bib.bib15)]表明，大型语言模型（LLMs）在审计智能合约方面具有潜力，特别是在检测逻辑漏洞方面表现优异[[2](#bib.bib2),
    [13](#bib.bib13)]。然而，最近的一项系统评估研究[[15](#bib.bib15)]显示，即使将基于LLM的漏洞检测范式装备上最先进的方法，即在检索增强生成（RAG）[[16](#bib.bib16)]的方式下增强GPT-4，仍然只有约30%的精确度，同时决策（即代码是否存在漏洞）和理由（即准确定位漏洞类型）都正确。这可以归因于现成的LLM（例如GPT-4），这些模型主要是在通用文本/代码语料库上进行预训练的，并未针对Solidity¹¹1Solidity是智能合约开发的主流语言。智能合约审计这一特定领域进行微调。
- en: Fine-tuning [[17](#bib.bib17), [18](#bib.bib18)] could be a promising approach
    to embed Solidity-specific vulnerability data into the model itself, compared
    to RAG [[19](#bib.bib19)], and thus address the problem mentioned above. In particular,
    by fine-tuning an LLM with vulnerable and non-vulnerable code, it could effectively
    perceive whether a new piece of code is vulnerable or not. According to insights
    from a million-dollar-earning hacker mentioned in the prologue, such intuition
    is quite important for vulnerability auditing. As such, instead of fine-tuning
    a single model to generate both vulnerability decisions (i.e., Yes or No) and
    the causes of vulnerabilities (i.e., the type or reason) simultaneously, we propose
    a novel two-stage fine-tuning approach. This approach first tunes a Detector model
    to make decisions only, and then tunes a Reasoner model to generate the causes
    of vulnerabilities. In this way, the fine-tuned LLMs could could mimic human hackers
    by first making intuitive judgments and then performing follow-up analysis of
    the code to identify the reasons for vulnerabilities.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 微调[[17](#bib.bib17), [18](#bib.bib18)]可能是一种有前景的方法，将Solidity特定的漏洞数据嵌入到模型中，相比于RAG[[19](#bib.bib19)]，从而解决上述问题。特别是，通过对LLM进行漏洞和非漏洞代码的微调，它能够有效地感知新的代码是否存在漏洞。根据前言中提到的一位百万美元收入的黑客的见解，这种直觉在漏洞审计中非常重要。因此，我们提出了一种新颖的两阶段微调方法，而不是微调单一模型以同时生成漏洞决策（即“是”或“否”）和漏洞原因（即类型或原因）。该方法首先微调一个仅用于做决策的Detector模型，然后微调一个用于生成漏洞原因的Reasoner模型。通过这种方式，微调后的LLM可以通过首先进行直觉判断，然后进行代码的后续分析来模拟人类黑客，以识别漏洞的原因。
- en: We implement this “perception-then-analysis” fune-tuning into a general framework
    called TrustLLM for intuitive smart contract auditing. In this implementation,
    TrustLLM allows Detector to make multiple intuitive judgments, each representing
    one perception. To achieve this, TrustLLM generates multiple variant prompts for
    the same vulnerability label to tune Detector and similarly employs multiple variant
    prompts for the same vulnerability reason to tune Reasoner. While it is possible
    to determine the optimal decision based on majority voting, fine-tuning alone
    cannot identify the optimal cause for a vulnerability during the inference phase.
    To address this new problem, we introduce the concept of LLM-based agents to the
    paradigm of fine-tuning in TrustLLM. Specifically, we introduce two dedicated
    LLM-based agents, the Ranker and Critic agents, to iteratively select and debate
    the most appropriate cause of vulnerability based on the output of the fine-tuned
    Reasoner model.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这种“感知-然后分析”的微调方法实现为一个名为 TrustLLM 的通用框架，用于直观的智能合约审计。在这一实现中，TrustLLM 允许 Detector
    进行多次直观判断，每次判断代表一种感知。为了实现这一点，TrustLLM 为同一漏洞标签生成多个变体提示来调整 Detector，并类似地为同一漏洞原因生成多个变体提示来调整
    Reasoner。虽然可以根据多数投票来确定最佳决策，但仅靠微调无法在推理阶段识别漏洞的最佳原因。为了解决这个新问题，我们向 TrustLLM 的微调范式中引入了基于
    LLM 的代理概念。具体而言，我们引入了两个专用的基于 LLM 的代理，Ranker 和 Critic 代理，来迭代选择和辩论最合适的漏洞原因，基于微调后的
    Reasoner 模型的输出。
- en: To obtain high-quality data for training and testing TrustLLM, we propose leveraging
    reputable auditing reports to collect positive samples and employing our own data
    enhancement method to derive negative samples. Eventually, we collected a balanced
    dataset consisting of 1,734 positive samples, i.e., vulnerable functions with
    reasons from 263 smart contract auditing reports, and 1,810 negative samples,
    i.e., non-vulnerable benign code. We then compared TrustLLM with traditional full-model
    fine-tuning methods, including CodeBERT, GraphCodeBERT, CodeT5, and UnixCoder,
    as well as with prompt learning-based LLMs, such as GPT-4/GPT-3.5 and CodeLlama-13b/34b.
    Our experimental results show that TrustLLM achieved an F1 score of 91.21%, significantly
    outperforming prompt learning-based LLMs (which are in the range of 60%+) and
    also notably beating other fine-tuned models (which are in the range of 80%+)
    that used the same training data as ours. Furthermore, in terms of alignment with
    ground-truth explanations, TrustLLM’s output is clearly superior to that of other
    models, reaching a consistency rate of 37.99%. In contrast, the second-ranked
    GPT-4 achieves only 24%.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得高质量的数据来训练和测试 TrustLLM，我们提议利用有信誉的审计报告来收集正样本，并采用我们自己的数据增强方法来推导负样本。最终，我们收集了一个平衡的数据集，包括
    1,734 个正样本，即来自 263 个智能合约审计报告的漏洞函数及其原因，以及 1,810 个负样本，即非漏洞的良性代码。然后，我们将 TrustLLM
    与传统的全模型微调方法（如 CodeBERT、GraphCodeBERT、CodeT5 和 UnixCoder）以及基于提示学习的 LLM（如 GPT-4/GPT-3.5
    和 CodeLlama-13b/34b）进行了比较。我们的实验结果显示，TrustLLM 达到了 91.21% 的 F1 分数，显著优于基于提示学习的 LLM（这些模型的范围在
    60%+）以及使用与我们相同训练数据的其他微调模型（这些模型的范围在 80%+）。此外，在与真实解释的一致性方面，TrustLLM 的输出明显优于其他模型，达到了
    37.99% 的一致性率。而排名第二的 GPT-4 仅达到 24%。
- en: 'Besides the evaluation results, we also conducted three ablation studies to
    further justify TrustLLM’s two-stage fine-tuning and majority voting strategies,
    as well as to measure the impact of additional call graph information on the model’s
    performance. We summarize the key findings as follows:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 除了评估结果，我们还进行了三项消融研究，以进一步验证 TrustLLM 的两阶段微调和多数投票策略，并测量额外调用图信息对模型性能的影响。我们总结了以下关键发现：
- en: •
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: TrustLLM’s two-stage approach achieved better detection performance than the
    integration model, which outputs labels and reasons simultaneously. We also experimentally
    confirmed that the model struggles to focus on the labels when required to output
    both types of information.
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: TrustLLM 的两阶段方法在检测性能上优于集成模型，该模型同时输出标签和原因。我们还实验性地确认，当需要同时输出这两种信息时，模型很难集中注意力在标签上。
- en: •
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Majority voting enhances the detection performance and stability. Using multiple
    prompts also allows the model to perform better than when using a single prompt.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 多数投票增强了检测性能和稳定性。使用多个提示还使模型的表现优于使用单一提示时的表现。
- en: •
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Call graph information may enable the model to make better judgments in some
    cases, but we also observed situations where this additional information could
    potentially confuse the model, thereby reducing its performance.
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 调用图信息在某些情况下可能使模型做出更好的判断，但我们也观察到这种额外的信息有可能让模型感到困惑，从而降低其性能。
- en: 'Roadmap. The rest of this paper is organized as follows. We first introduce
    the relevant background in §[II](#S2 "II Background ‣ TrustLLM: Smelling and Reasoning
    Smart Contract Vulnerability"), followed by the design of TrustLLM in §[III](#S3
    "III Design of TrustLLM ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability").
    We then present our experimental setup and the results in §[IV](#S4 "IV Evaluation
    ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability"). After that,
    we discuss related work and the limitations in §[V](#S5 "V Related Work ‣ TrustLLM:
    Smelling and Reasoning Smart Contract Vulnerability") and §[VI](#S6 "VI Threats
    to Validity ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability"),
    respectively. Finally, §[VII](#S7 "VII Conclusion ‣ TrustLLM: Smelling and Reasoning
    Smart Contract Vulnerability") concludes this paper.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '路线图。本文的其余部分组织如下。我们首先在§[II](#S2 "II Background ‣ TrustLLM: Smelling and Reasoning
    Smart Contract Vulnerability")介绍相关背景，接着在§[III](#S3 "III Design of TrustLLM ‣ TrustLLM:
    Smelling and Reasoning Smart Contract Vulnerability")介绍TrustLLM的设计。然后，我们在§[IV](#S4
    "IV Evaluation ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability")展示我们的实验设置和结果。之后，我们在§[V](#S5
    "V Related Work ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability")和§[VI](#S6
    "VI Threats to Validity ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability")讨论相关工作和局限性。最后，§[VII](#S7
    "VII Conclusion ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability")总结了本文。'
- en: Availability. To facilitate future research and comparison, we have made the
    inference code and dataset available at [[20](#bib.bib20)].
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 可用性。为了促进未来的研究和比较，我们已将推理代码和数据集提供在[[20](#bib.bib20)]。
- en: II Background
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 背景
- en: II-A Pre-trained Models and Large Language Models
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-A 预训练模型和大型语言模型
- en: Pre-trained models are models that have been initially trained on large datasets.
    These models can be quickly adapted to various specific tasks with minimal adjustments,
    avoiding the complex training process from scratch. Currently, most pre-trained
    models adopt an architecture based on transformers [[21](#bib.bib21)]. The innovation
    of this approach is that pre-trained models leverage large data and well-designed
    tasks for effective feature learning, which has been proven effective in multiple
    fields, such as text processing, image recognition, and software engineering.
    The standard transformer structure consists of one encoder and one decoder, which
    are structurally similar but function differently. Pre-trained models can be classified
    into encoder-based, decoder-based, or encoder-decoder combined types depending
    on the transformer structure used. For example, encoder-based models are represented
    by BERT [[22](#bib.bib22)] and CodeBERT [[23](#bib.bib23)], decoder models by
    the GPT series [[24](#bib.bib24), [25](#bib.bib25)], and encoder-decoder models
    by BART [[26](#bib.bib26)], T5 [[27](#bib.bib27)], and CodeT5 [[28](#bib.bib28)].
    Compared with general pre-trained models, Large Language Models (LLMs) [[29](#bib.bib29),
    [30](#bib.bib30)] differ significantly in their used larger data and model scales.
    These models are trained by learning world-wide knowledge bases, typically reaching
    billions in scale. As the model size, data volume, and computational capacity
    increase, performance also improves, as revealed by the Scaling Laws [[31](#bib.bib31)].
    Closed-source LLMs like GPT-3.5, GPT-4, and Gemini [[32](#bib.bib32)] offer their
    services externally through APIs, while open-source models like Llama2 [[33](#bib.bib33)]
    can achieve performance comparable or better to closed-source models after fine-tuning.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练模型是指那些最初在大型数据集上进行训练的模型。这些模型可以通过最小的调整快速适应各种特定任务，避免了从头开始的复杂训练过程。目前，大多数预训练模型采用基于transformers的架构[[21](#bib.bib21)]。这种方法的创新在于预训练模型利用大量数据和精心设计的任务进行有效的特征学习，这在多个领域如文本处理、图像识别和软件工程中已被证明有效。标准的transformer结构由一个编码器和一个解码器组成，这两者在结构上相似但功能不同。预训练模型可以根据使用的transformer结构分为基于编码器、基于解码器或编码器-解码器组合类型。例如，基于编码器的模型有BERT[[22](#bib.bib22)]和CodeBERT[[23](#bib.bib23)]，解码器模型有GPT系列[[24](#bib.bib24),
    [25](#bib.bib25)]，而编码器-解码器模型有BART[[26](#bib.bib26)]、T5[[27](#bib.bib27)]和CodeT5[[28](#bib.bib28)]。与一般的预训练模型相比，大型语言模型（LLMs）[[29](#bib.bib29),
    [30](#bib.bib30)]在使用更大数据和模型规模方面有显著不同。这些模型通过学习全球知识库进行训练，规模通常达到数十亿。随着模型大小、数据量和计算能力的增加，性能也有所提升，这由Scaling
    Laws[[31](#bib.bib31)]揭示。像GPT-3.5、GPT-4和Gemini[[32](#bib.bib32)]这样的闭源LLMs通过API提供服务，而像Llama2[[33](#bib.bib33)]这样的开源模型在微调后可以达到或超越闭源模型的性能。
- en: II-B Parameter-Efficient Fine-Tuning
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-B 参数高效微调
- en: 'LLMs have extremely large parameters. Fully fine-tuning a large language model
    requires significant hardware resources and is very costly. Therefore, lightweight
    parameter fine-tuning [[34](#bib.bib34), [35](#bib.bib35)] is currently the main
    method of using LLMs compared to fully fine-tuning them. Although LLMs can be
    used without task-specific fine-tuning through in-context learning [[36](#bib.bib36)],
    this usually requires carefully prepared prompts. Furthermore, research has found
    that partial fine-tuning of LLMs with smaller parameters can achieve or even surpass
    the effects of huge models [[37](#bib.bib37), [38](#bib.bib38)]. These fine-tuning
    methods differ from full-model fine-tuning by focusing only on fine-tuning additional
    parameters while keeping the large model weights fixed, known collectively as
    parameter-efficient fine-tuning [[34](#bib.bib34), [35](#bib.bib35)]. They can
    be generally categorized into four types: Adapter [[37](#bib.bib37)], Low-Rank
    Adaptation (LoRA) [[39](#bib.bib39)], prefix tuning [[40](#bib.bib40)], and prompt
    tuning [[41](#bib.bib41)].'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs具有极其庞大的参数。完全微调一个大型语言模型需要显著的硬件资源，并且非常昂贵。因此，相对于完全微调，轻量级参数微调[[34](#bib.bib34),
    [35](#bib.bib35)]目前是使用LLMs的主要方法。尽管LLMs可以通过上下文学习[[36](#bib.bib36)]在不进行任务特定微调的情况下使用，但这通常需要精心准备的提示。此外，研究发现，具有较小参数的LLMs的部分微调可以实现甚至超过大模型的效果[[37](#bib.bib37),
    [38](#bib.bib38)]。这些微调方法与全模型微调不同，专注于仅微调附加参数，同时保持大型模型权重不变，这被统称为参数高效微调[[34](#bib.bib34),
    [35](#bib.bib35)]。这些方法一般可以分为四类：Adapter[[37](#bib.bib37)]，低秩适配（LoRA）[[39](#bib.bib39)]，前缀调整[[40](#bib.bib40)]和提示调整[[41](#bib.bib41)]。
- en: Adapter [[37](#bib.bib37)] adds a lightweight additional module to each layer
    of the model to capture information specific to downstream tasks. During optimization,
    only the parameters of the additional module are optimized. Since the number of
    parameters in the Adapter is much smaller than that of the model itself, it significantly
    reduces the overall parameter count and computational complexity of the model.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 适配器[[37](#bib.bib37)]在模型的每一层添加一个轻量级的附加模块，以捕捉特定下游任务的信息。在优化过程中，仅优化附加模块的参数。由于适配器的参数数量远小于模型本身的参数数量，它显著减少了模型的总体参数数量和计算复杂性。
- en: Low-Rank Adaptation (LoRA) [[39](#bib.bib39)] is a parameter-efficient adaptation
    method for LLMs, which adjusts LLMs for downstream tasks at a lower parameter
    cost. The core idea of LoRA is to introduce additional, low-rank adaptation parameters
    into the self-attention mechanism, effectively adjusting the model to suit new
    tasks with minimal addition of extra parameters.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 低秩适应（LoRA）[[39](#bib.bib39)]是一种参数高效的适应方法，用于对 LLM 进行下游任务调整，参数成本较低。LoRA 的核心思想是在自注意力机制中引入额外的低秩适应参数，有效地调整模型以适应新任务，同时最小化额外参数的增加。
- en: Prefix tuning [[40](#bib.bib40)] adds a “prefix” sequence to each layer of the
    model, serving as additional context input. This method allows the model to adapt
    to specific tasks while retaining most of the knowledge acquired during pre-training.
    Unlike prefix tuning, prompt tuning [[41](#bib.bib41)] adds prompt tokens to the
    input, which can be placed at any position.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 前缀调优[[40](#bib.bib40)]在模型的每一层添加一个“前缀”序列，作为额外的上下文输入。这种方法使模型能够适应特定任务，同时保留大部分在预训练过程中获得的知识。与前缀调优不同，提示调优[[41](#bib.bib41)]将提示标记添加到输入中，这些标记可以放置在任何位置。
- en: To sum up, using adapters can increase inference latency [[39](#bib.bib39),
    [42](#bib.bib42)]. Prefix or prompt tuning is subject to structural constraints
    that inhibit the learning of new attention patterns [[43](#bib.bib43)]. LoRA is
    an efficient method with low cost and can have a performance close to the full
    fine-tuning approach [[39](#bib.bib39)].
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，使用适配器可能会增加推理延迟[[39](#bib.bib39), [42](#bib.bib42)]。前缀或提示调优受到结构性约束，抑制了新注意力模式的学习[[43](#bib.bib43)]。LoRA
    是一种高效且成本低的方法，其性能接近全面微调的方法[[39](#bib.bib39)]。
- en: II-C Smart Contracts and Their Vulnerabilities
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-C 智能合约及其漏洞
- en: Smart contracts are essential for realizing decentralized finance [[44](#bib.bib44)]
    as an application layer of blockchain technology. According to data from DeFiLlama [[45](#bib.bib45)],
    as of March 2024, the total value locked in the top three blockchain platforms
    (Ethereum, Tron, and BSC) has reached $73 billions. Given the close relationship
    between smart contracts and economic interests, their security has attracted widespread
    attention. Vulnerabilities in smart contracts can lead to significant losses,
    such reentrancy attacks and access-control attacks [[46](#bib.bib46)].
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 智能合约对于实现去中心化金融[[44](#bib.bib44)]是至关重要的，它是区块链技术的应用层。根据 DeFiLlama 的数据[[45](#bib.bib45)]，截至2024年3月，前两大区块链平台（以太坊、Tron
    和 BSC）的总锁仓价值已达到730亿美元。鉴于智能合约与经济利益的密切关系，它们的安全性引起了广泛关注。智能合约中的漏洞可能导致重大损失，例如重入攻击和访问控制攻击[[46](#bib.bib46)]。
- en: In the real world, hackers employ even more complex tactics. Currently, to address
    vulnerabilities in smart contracts, various static and dynamic detection tools [[3](#bib.bib3),
    [4](#bib.bib4), [5](#bib.bib5), [6](#bib.bib6), [7](#bib.bib7), [8](#bib.bib8),
    [9](#bib.bib9), [10](#bib.bib10)] are used to test contract security. Unfortunately,
    some complex vulnerabilities are hard to be found by these detection tools. For
    example, in a sandwich attack [[47](#bib.bib47)], attackers monitor other pending
    transactions and execute their transactions first upon spotting a high-value yet
    uncompleted transaction. Due to this preemptive action, the attack transaction
    will be executed at a higher price, allowing the attacker to immediately sell
    the acquired excess profit for profit. Many well-funded project teams also invite
    third parties to audit their smart contracts before public release to ensure their
    safety.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中，黑客使用的战术更加复杂。目前，为了应对智能合约中的漏洞，使用了各种静态和动态检测工具 [[3](#bib.bib3), [4](#bib.bib4),
    [5](#bib.bib5), [6](#bib.bib6), [7](#bib.bib7), [8](#bib.bib8), [9](#bib.bib9),
    [10](#bib.bib10)] 来测试合约的安全性。不幸的是，一些复杂的漏洞很难被这些检测工具发现。例如，在夹心攻击 [[47](#bib.bib47)]
    中，攻击者监控其他待处理交易，并在发现高价值但尚未完成的交易时首先执行他们的交易。由于这种先发制人的行为，攻击交易将以更高的价格执行，使攻击者能够立即出售获得的超额利润。许多资金雄厚的项目团队还会邀请第三方在公开发布前审计他们的智能合约，以确保其安全。
- en: '![Refer to caption](img/e33450b9ba21d958b50e17e006caebc6.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/e33450b9ba21d958b50e17e006caebc6.png)'
- en: 'Figure 1: An overview of TrustLLM, featuring its four roles: Detector, Reasoner,
    Ranker, and Critic.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '图 1: TrustLLM 的概述，展示其四个角色：Detector、Reasoner、Ranker 和 Critic。'
- en: III Design of TrustLLM
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III TrustLLM 设计
- en: 'As motivated in §[I](#S1 "I Introduction ‣ TrustLLM: Smelling and Reasoning
    Smart Contract Vulnerability"), TrustLLM employs a novel two-stage fine-tuning
    approach and combines it with LLM-based agents for intuitive smart contract auditing
    with justifications. As shown in Fig. [1](#S2.F1 "Figure 1 ‣ II-C Smart Contracts
    and Their Vulnerabilities ‣ II Background ‣ TrustLLM: Smelling and Reasoning Smart
    Contract Vulnerability"), TrustLLM has the following four roles:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '如 §[I](#S1 "I 引言 ‣ TrustLLM: 发现和推理智能合约漏洞") 中所述，TrustLLM 采用了新颖的两阶段微调方法，并结合了基于
    LLM 的智能合约审计代理进行直观审计和理由说明。如图 [1](#S2.F1 "图 1 ‣ II-C 智能合约及其漏洞 ‣ II 背景 ‣ TrustLLM:
    发现和推理智能合约漏洞") 所示，TrustLLM 具有以下四个角色：'
- en: •
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Detector is the key component for achieving intuitive smart contract auditing.
    By fine-tuning an LLM with vulnerable and non-vulnerable code, Detector can discern
    whether a piece of code is vulnerable, much like how a human hacker perceives
    a potential vulnerability.
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Detector 是实现直观智能合约审计的关键组件。通过用易受攻击和非易受攻击的代码对 LLM 进行微调，Detector 能够判断一段代码是否存在漏洞，类似于人类黑客识别潜在漏洞的方式。
- en: •
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Reasoner takes Detector’s initial vulnerability perception to further investigate
    problematic code locations. By connecting Detector’s output with Reasoner’s reasoning
    during both training and inference, TrustLLM achieves two-stage fine-tuning.
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Reasoner 依据 Detector 的初步漏洞感知进一步调查问题代码的位置。通过在训练和推理过程中将 Detector 的输出与 Reasoner
    的推理连接，TrustLLM 实现了两阶段的微调。
- en: •
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: To identify the optimal cause of a vulnerability during the inference phase,
    we further introduce the concept of LLM-based agents into the fine-tuning paradigm
    in TrustLLM. Specifically, Ranker evaluates the reasons for each potential vulnerability,
    selecting a top explanation, while Critic further assesses Ranker’s output to
    debate and determine the most appropriate cause of the vulnerability.
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了在推理阶段确定漏洞的最佳原因，我们进一步将基于 LLM 的代理概念引入到 TrustLLM 的微调范式中。具体来说，Ranker 评估每个潜在漏洞的原因，选择一个最佳解释，而
    Critic 进一步评估 Ranker 的输出，以辩论和确定漏洞的最合适原因。
- en: 'Challenges. While TrustLLM’s four roles in Fig. [1](#S2.F1 "Figure 1 ‣ II-C
    Smart Contracts and Their Vulnerabilities ‣ II Background ‣ TrustLLM: Smelling
    and Reasoning Smart Contract Vulnerability") are intuitive, training and coordinating
    them well for effective smart contract auditing with reasonable justifications
    is difficult. More specifically, we encountered the following four challenges
    during the design and implementation of TrustLLM:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '挑战。虽然图 [1](#S2.F1 "图 1 ‣ II-C 智能合约及其漏洞 ‣ II 背景 ‣ TrustLLM: 发现和推理智能合约漏洞") 中的
    TrustLLM 四个角色直观易懂，但为了有效进行智能合约审计并提供合理的理由，对它们进行训练和协调是困难的。更具体来说，我们在 TrustLLM 的设计和实施过程中遇到了以下四个挑战：'
- en: 'C1:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 'C1:'
- en: 'How to collect and derive high-quality training data? For a fine-tuned model
    like TrustLLM, obtaining high-quality training data is always crucial. We propose
    leveraging reputable auditing reports to collect positive samples and employing
    our own data enhancement method to derive negative samples. Since this part is
    independent of TrustLLM’s design, we defer its presentation to the end of this
    section in §[III-D](#S3.SS4 "III-D High-quality Training Data Collection and Enhancement
    ‣ III Design of TrustLLM ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability").'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '如何收集和获取高质量的训练数据？对于像TrustLLM这样的微调模型，获取高质量的训练数据始终至关重要。我们建议利用可靠的审计报告来收集正样本，并采用我们自己的数据增强方法来获取负样本。由于这部分独立于TrustLLM的设计，我们将其介绍推迟到本节末尾的§[III-D](#S3.SS4
    "III-D High-quality Training Data Collection and Enhancement ‣ III Design of TrustLLM
    ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability")。'
- en: 'C2:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 'C2:'
- en: 'How to make effective vulnerability judgements? While fine-tuning a model with
    vulnerable and non-vulnerable code is straightforward, tuning it to be effective
    with limited data presents a challenge. We make an effort towards addressing this
    problem in §[III-A](#S3.SS1 "III-A Using Multi-prompt Tuning and Majority Voting
    for Effective Vulnerability Judgements in the Detector ‣ III Design of TrustLLM
    ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability") by opting to
    use multiple prompts for fine-tuning rather than a single prompt. The advantages
    of this approach are twofold: (i) it enriches the training dataset by increasing
    the volume of data, and (ii) it diminishes the bias associated with a single prompt,
    thereby enhancing the reliability of the results [[48](#bib.bib48)]. Optimal vulnerability
    perception could thus be achieved through majority voting.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '如何做出有效的漏洞判断？虽然用有漏洞和无漏洞的代码对模型进行微调是直接的，但在有限数据下使其有效仍然是一个挑战。我们在§[III-A](#S3.SS1
    "III-A Using Multi-prompt Tuning and Majority Voting for Effective Vulnerability
    Judgements in the Detector ‣ III Design of TrustLLM ‣ TrustLLM: Smelling and Reasoning
    Smart Contract Vulnerability")中努力解决这个问题，选择使用多个提示进行微调而不是单一提示。这种方法有两个优点：（i）通过增加数据量来丰富训练数据集，
    (ii) 减少单一提示带来的偏差，从而提高结果的可靠性[[48](#bib.bib48)]。因此，可以通过多数投票实现最佳的漏洞感知。'
- en: 'C3:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 'C3:'
- en: 'How to effectively connect Detector’s vulnerability sensing with Reasoner’s
    vulnerability reasoning? The fine-tuning of TrustLLM is unique because it employs
    a two-stage fine-tuning approach with the Detector and Reasoner models. Therefore,
    how to effectively connect these two models becomes a new issue not encountered
    in traditional fine-tuning. We present this aspect of TrustLLM’s design in §[III-B](#S3.SS2
    "III-B Connecting Detector for Reasoner’s Tuning & Inference ‣ III Design of TrustLLM
    ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability").'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '如何有效地将探测器的漏洞感知与推理器的漏洞推理连接起来？TrustLLM的微调独特之处在于它采用了一个两阶段的微调方法，涉及探测器和推理器模型。因此，如何有效地连接这两个模型成为一个在传统微调中未曾遇到的新问题。我们在§[III-B](#S3.SS2
    "III-B Connecting Detector for Reasoner’s Tuning & Inference ‣ III Design of TrustLLM
    ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability")中展示了TrustLLM设计的这一方面。'
- en: 'C4:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 'C4:'
- en: 'How to obtain the optimal vulnerability cause from Reasoner’s output? Since
    Reasoner also employs multi-prompt fine-tuning, it is necessary to identify the
    optimal cause of vulnerability among the multiple causes output by Reasoner. We
    introduce two LLM-based agents, namely the Ranker and Critic components, in §[III-C](#S3.SS3
    "III-C Ranking and Debating the Optimal Vulnerability Cause ‣ III Design of TrustLLM
    ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability"), to iteratively
    select and debate the most appropriate cause of vulnerability.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '如何从推理器的输出中获取最佳漏洞原因？由于推理器还采用了多提示微调，因此需要从推理器输出的多个原因中识别出最佳的漏洞原因。我们在§[III-C](#S3.SS3
    "III-C Ranking and Debating the Optimal Vulnerability Cause ‣ III Design of TrustLLM
    ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability")中介绍了两个基于LLM的代理，即排名器和评论器组件，用于迭代选择和辩论最合适的漏洞原因。'
- en: 'An Example of Workflow. To wrap up, Fig. [1](#S2.F1 "Figure 1 ‣ II-C Smart
    Contracts and Their Vulnerabilities ‣ II Background ‣ TrustLLM: Smelling and Reasoning
    Smart Contract Vulnerability") also illustrates an example of TrustLLM’s workflow.
    Initially, Detector perceives code vulnerabilities using five different inference
    paths (prompts). The perceived results are then subjected to majority voting to
    determine a consensus label. Based on the voting result, Reasoner interprets this
    outcome according to different inference paths, resulting in ten answers (each
    considering the context of the code location or not). Next, Ranker selects Reason
    1 with a confidence score 9/10 and explains this choice. Critic challenges this
    choice and advises Ranker to re-evaluate. Taking Critic’s feedback into account,
    Ranker re-ranks the ten reasons and selects Reason 3 with a confidence score of
    10/10. Critic reviews Ranker’s choice again and agrees with this decision. The
    loop is completed, and the final reason is returned to the user.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '工作流程示例。总而言之，图 [1](#S2.F1 "Figure 1 ‣ II-C Smart Contracts and Their Vulnerabilities
    ‣ II Background ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability")
    还展示了 TrustLLM 工作流程的示例。最初，Detector 使用五条不同的推理路径（提示）感知代码漏洞。感知结果随后进行多数投票，以确定共识标签。根据投票结果，Reasoner
    根据不同的推理路径解释这一结果，产生十个答案（每个考虑代码位置的上下文与否）。接下来，Ranker 选择置信度分数为 9/10 的 Reason 1，并解释这个选择。Critic
    挑战这个选择，并建议 Ranker 重新评估。考虑 Critic 的反馈后，Ranker 重新排序这十个理由，并选择置信度分数为 10/10 的 Reason
    3。Critic 再次审查 Ranker 的选择，并同意这个决定。循环完成，最终理由返回给用户。'
- en: III-A Using Multi-prompt Tuning and Majority Voting for Effective Vulnerability
    Judgements in the Detector
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-A 使用多提示调整和多数投票进行有效漏洞判断
- en: 'Detector is a fine-tuned expert model responsible for assessing whether code
    poses any risk. It mimics human intuitive judgment upon seeing a piece of code,
    assessing whether there are any issues. We employed LoRA [[39](#bib.bib39)] to
    fine-tune CodeLlama-13b [[49](#bib.bib49)] in the instruction manner [[50](#bib.bib50)]
    based on a high quality of dataset. During training, for the same input code,
    we wrap it with multiple prompts. These prompts, with different instruction formats,
    represent the different inference paths, as illustrated in Fig. [1](#S2.F1 "Figure
    1 ‣ II-C Smart Contracts and Their Vulnerabilities ‣ II Background ‣ TrustLLM:
    Smelling and Reasoning Smart Contract Vulnerability"). In the inference phase
    of Detector, based on the output results of each prompt, we adopt a majority voting
    approach to determine the input label and use the voting ratio as the confidence
    score. Based on Detector’s majority voting result, Reasoner in §[III-B](#S3.SS2
    "III-B Connecting Detector for Reasoner’s Tuning & Inference ‣ III Design of TrustLLM
    ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability") then generates
    different reasons according to different inference paths.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 'Detector 是一个经过精细调整的专家模型，负责评估代码是否存在任何风险。它模拟人类在看到一段代码时的直观判断，评估是否存在问题。我们采用了 LoRA
    [[39](#bib.bib39)] 来基于高质量数据集以指令方式 [[50](#bib.bib50)] 微调 CodeLlama-13b [[49](#bib.bib49)]。在训练过程中，对于相同的输入代码，我们使用多个提示进行包装。这些提示具有不同的指令格式，代表了不同的推理路径，如图
    [1](#S2.F1 "Figure 1 ‣ II-C Smart Contracts and Their Vulnerabilities ‣ II Background
    ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability") 所示。在 Detector
    的推理阶段，根据每个提示的输出结果，我们采用多数投票的方法来确定输入标签，并使用投票比例作为置信度分数。根据 Detector 的多数投票结果，§[III-B](#S3.SS2
    "III-B Connecting Detector for Reasoner’s Tuning & Inference ‣ III Design of TrustLLM
    ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability") 中的 Reasoner
    根据不同的推理路径生成不同的理由。'
- en: 'Detector’s
    Prompt Template Below is an instruction that
    describes a classification task. [Task Description] ### Instruction: [Task Instruction]
    ### Input: [Input Description]:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '探测器的提示模板
    以下是描述分类任务的指令。 [任务描述] ### 指令: [任务指令] ### 输入: [输入描述]:'
- en: “‘Solidiy
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: “‘Solidiy
- en: '{code}'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '{code}'
- en: ”’
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ”’
- en: Response: The label is {Label Name}.
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Response: 标签是 {Label Name}。
- en: 'Figure 2: The Prompt Template Used by Detector.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：探测器使用的提示模板。
- en: 'The prompt template used by Detector is demonstrated in Fig. [2](#S3.F2 "Figure
    2 ‣ III-A Using Multi-prompt Tuning and Majority Voting for Effective Vulnerability
    Judgements in the Detector ‣ III Design of TrustLLM ‣ TrustLLM: Smelling and Reasoning
    Smart Contract Vulnerability"). Above the dashed line is the input $x$, with “{Label
    Name}” being the label placeholder, which can be either “safe” and “vulnerable.”
    The left table (Detector’s Multiple Prompts) in Fig. [4](#S3.F4 "Figure 4 ‣ III-B
    Connecting Detector for Reasoner’s Tuning & Inference ‣ III Design of TrustLLM
    ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability") details the
    [Task Description], [Task Instruction], and [Input Description], listed as notations
    a, b, and c, respectively. We fine-tune CodeLlama-13b using LoRA in a generative
    manner, as shown in Eq. [1](#S3.E1 "In III-A Using Multi-prompt Tuning and Majority
    Voting for Effective Vulnerability Judgements in the Detector ‣ III Design of
    TrustLLM ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability"),'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '探测器使用的提示模板如图 [2](#S3.F2 "图 2 ‣ III-A 使用多提示调优和多数投票来有效判断探测器中的漏洞 ‣ III TrustLLM
    设计 ‣ TrustLLM: 智能合约漏洞的嗅探与推理") 所示。虚线以上是输入$x$，“{Label Name}”是标签占位符，可以是“safe”或“vulnerable”。图 [4](#S3.F4
    "图 4 ‣ III-B 连接探测器用于推理器的调优与推断 ‣ III TrustLLM 设计 ‣ TrustLLM: 智能合约漏洞的嗅探与推理") 中的左侧表格（探测器的多个提示）详细说明了[任务描述]、[任务指令]和[输入描述]，分别列为符号a、b和c。我们使用LoRA以生成方式微调CodeLlama-13b，如方程 [1](#S3.E1
    "在 III-A 使用多提示调优和多数投票来有效判断探测器中的漏洞 ‣ III TrustLLM 设计 ‣ TrustLLM: 智能合约漏洞的嗅探与推理")
    所示，'
- en: '|  | $L(\theta)=-\sum_{t=1}^{T}\log P_{\theta}(y_{t}&#124;x,y_{Reasoner’s
    Prompt Template Below is an instruction that
    describes a reasoning task. [Task Description] ### Instruction: [Task Instruction]
    ### Input: [Input Description]:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 'Reasoner
    的提示模板 下面是描述推理任务的指令。[任务描述] ### 指令：[任务指令]
    ### 输入：[输入描述]：'
- en: “‘Solidiy
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: “‘Solidiy
- en: '{code}'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '{code}'
- en: “‘
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: “‘
- en: 'As a Caller: (Optional) [Caller Description] “‘'
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 作为调用者：（可选）[调用者描述] “‘
- en: '{caller info}'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '{caller info}'
- en: “‘
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: “‘
- en: 'As a Callee: (Optional) [Callee Description] “‘'
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 作为被调用者：（可选）[被调用者描述] “‘
- en: '{callee info}'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '{callee info}'
- en: “‘
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: “‘
- en: 'Response: [Label Information + Zero-shot-CoT Tip] {Target
    Reason}'
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 响应：[标签信息 + 零样本链式思维提示] {目标推理}
- en: 'Figure 3: The Prompt Template Used by Reasoner.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：Reasoner 使用的提示模板。
- en: 'The prompt template used by the Reasoner is shown in Fig. [3](#S3.F3 "Figure
    3 ‣ III-B Connecting Detector for Reasoner’s Tuning & Inference ‣ III Design of
    TrustLLM ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability"). “code”,
    “caller info”, “callee info”, and “Target Reason” are placeholders for the input
    code, caller context, callee context, and the target output, respectively. The
    right table (Reasoner’s Multiple Prompts) in Fig. [4](#S3.F4 "Figure 4 ‣ III-B
    Connecting Detector for Reasoner’s Tuning & Inference ‣ III Design of TrustLLM
    ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability") details the
    first prompt type with calling context, including [Task Description] denoted as
    a, [Task Instruction] denoted as b, [Input Description] denoted as c, [Caller
    Description] denoted as d, [Callee Description] denoted as e, and [Label Information
    + Zero-shot-CoT Tip] denoted as f. For the second prompt type, the calling context
    is omitted. Reasoner employed the same fine-tuning method as Detector, as shown
    by Eq. [1](#S3.E1 "In III-A Using Multi-prompt Tuning and Majority Voting for
    Effective Vulnerability Judgements in the Detector ‣ III Design of TrustLLM ‣
    TrustLLM: Smelling and Reasoning Smart Contract Vulnerability"). During inference,
    the proposed input prompt follows the training format, and Reasoner generates
    ten answers to interpret Detector’s assessment.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Reasoner 使用的提示模板如图[3](#S3.F3 "图 3 ‣ III-B 连接检测器以进行 Reasoner 的调整和推理 ‣ III TrustLLM
    的设计 ‣ TrustLLM：检测和推理智能合约漏洞")所示。 “code”，“caller info”，“callee info”和“Target Reason”分别是输入代码、调用者上下文、被调用者上下文和目标输出的占位符。图[4](#S3.F4
    "图 4 ‣ III-B 连接检测器以进行 Reasoner 的调整和推理 ‣ III TrustLLM 的设计 ‣ TrustLLM：检测和推理智能合约漏洞")中的右侧表格（Reasoner
    的多个提示）详细说明了第一种提示类型，包括 [任务描述] 记为 a，[任务指令] 记为 b，[输入描述] 记为 c，[调用者描述] 记为 d，[被调用者描述]
    记为 e，以及 [标签信息 + 零样本-CoT 提示] 记为 f。对于第二种提示类型，调用上下文被省略。Reasoner 使用了与 Detector 相同的微调方法，如
    Eq. [1](#S3.E1 "在 III-A 中使用多提示调整和多数投票进行有效漏洞判断 ‣ III TrustLLM 的设计 ‣ TrustLLM：检测和推理智能合约漏洞")
    所示。在推理过程中，所提议的输入提示遵循训练格式，Reasoner 生成十个答案来解释 Detector 的评估。
- en: '![Refer to caption](img/daef5834d6b98e2e60c7e0e886060833.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/daef5834d6b98e2e60c7e0e886060833.png)'
- en: 'Figure 4: Detailed Multiple Prompts for Detector and Reasoner.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：检测器和 Reasoner 的详细多个提示。
- en: III-C Ranking and Debating the Optimal Vulnerability Cause
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-C 排名和争论最佳漏洞原因
- en: 'Ranker and Critic are two LLM-based agents collaborating to select the most
    appropriate cause of vulnerability from multiple explanations returned by Reasoner
    for a given code function. Ranker performs two actions: “rank” and “merge”. “Rank”
    involves selecting the best explanation from the ones provided, while “merge”
    involves integrating multiple selected explanations. We define 10 constraints
    for Ranker to select the top explanation. Critic evaluates Ranker’s answer in
    conjunction with the code function, providing three next-step action instructions:
    “agree”, “rerank”, and “merge”. “Agree” means the current answer is reasonable
    and can be returned to the user. “Rerank” indicates that Ranker needs to re-select,
    considering Critic’s feedback and previous answers. “Merge” suggests that the
    top reasons provided must be integrated.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Ranker 和 Critic 是两个基于 LLM 的代理，合作从 Reasoner 返回的多个解释中选择最合适的漏洞原因以应用于给定的代码函数。Ranker
    执行两个操作：“rank”和“merge”。“Rank”涉及从提供的解释中选择最佳解释，而“merge”则涉及整合多个选中的解释。我们为 Ranker 定义了
    10 个约束条件以选择最佳解释。Critic 根据代码函数评估 Ranker 的答案，并提供三种后续操作指令：“agree”，“rerank”和“merge”。“Agree”表示当前答案是合理的，可以返回给用户。“Rerank”表明
    Ranker 需要重新选择，考虑 Critic 的反馈和之前的答案。“Merge”则建议必须整合提供的最佳原因。
- en: 'More specifically, Ranker employs the following 10 constraints in the prompt
    as its selection criteria:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，Ranker 在提示中采用以下 10 个约束作为选择标准：
- en: '1.'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: If one reason describes code that does not exist in the provided input, it is
    not valid.
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果一个理由描述了在提供的输入中不存在的代码，它就是无效的。
- en: '2.'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: If one reason is not related to the code, the reason is not valid.
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果一个理由与代码无关，那么这个理由就是无效的。
- en: '3.'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: If this reason violates the facts, the reason is unreasonable.
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果这个理由违背了事实，那么这个理由是不合理的。
- en: '4.'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: If one reason is not related to the decision, the reason is not valid.
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果一个理由与决策无关，那么这个理由就是无效的。
- en: '5.'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: If one reason assume any information that is not provided, the reason is not
    valid.
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果一个理由假设了任何未提供的信息，那么这个理由就是无效的。
- en: '6.'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '6.'
- en: If the code is safe and one reason supports the decision, please check if the
    code has other potential vulnerabilities. If the code has other potential vulnerabilities,
    the reason is not valid.
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果代码是安全的且一个理由支持该决定，请检查代码是否存在其他潜在漏洞。如果代码存在其他潜在漏洞，则该理由无效。
- en: '7.'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '7.'
- en: The selected reason should be the most relevant to the decision.
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 选择的理由应与决定最相关。
- en: '8.'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '8.'
- en: The selected reason must be the most reasonable and accurate one.
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 选择的理由必须是最合理和准确的。
- en: '9.'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '9.'
- en: The selected reason must be factual, logical and convincing.
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 选择的理由必须是事实性的、逻辑性的和有说服力的。
- en: '10.'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '10.'
- en: Do not make any assumption out of the given code.
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 不要对给定的代码做出任何假设。
- en: Both Ranker and Critic are LLMs agents implemented based on the Mixtral 8x7B-Instruct [[52](#bib.bib52)]
    model, the capability of which is close to that of larger LLMs [[52](#bib.bib52),
    [53](#bib.bib53), [54](#bib.bib54)]. Moreover, we have observed that the Mixture
    of Experts (MoE) [[52](#bib.bib52)] model can more effectively output data in
    the predetermined format than other models, making it easier for us to handle
    the output.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Ranker和Critic都是基于Mixtral 8x7B-Instruct[[52](#bib.bib52)]模型实现的LLMs代理，其能力接近于更大的LLMs[[52](#bib.bib52)，[53](#bib.bib53)，[54](#bib.bib54)]。此外，我们观察到Mixture
    of Experts（MoE）[[52](#bib.bib52)]模型比其他模型更有效地输出预定格式的数据，使我们更容易处理输出。
- en: III-D High-quality Training Data Collection and Enhancement
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-D 高质量训练数据收集与增强
- en: The quality of training data is crucial for fine-tuning LLMs. To collect positive
    samples, namely risky vulnerability code, we can employ auditing reports from
    reputable industry companies, such as Trail of Bits, Code4rena, and Immunefi.
    Specifically, we crawled and parsed 1,734 vulnerable functions with reasons from
    263 smart contract auditing reports, which were assembled by a popular auditing
    website called Solodit [[55](#bib.bib55)].
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据的质量对微调LLMs至关重要。为了收集正样本，即有风险的漏洞代码，我们可以利用来自知名行业公司的审计报告，如Trail of Bits、Code4rena和Immunefi。具体而言，我们从263份智能合约审计报告中爬取并解析了1,734个漏洞函数及其原因，这些报告由一个叫做Solodit的热门审计网站汇编[[55](#bib.bib55)]。
- en: However, to train our model, we also need non-vulnerable benign code (i.e.,
    negative samples), but this type of data is missing in the audit reports. Therefore,
    we propose our own data enhancement method to derive high-quality negative samples.
    Specifically, we adopt the GPT-4-based approach described in LLM4Vuln [[15](#bib.bib15)]
    to extract vulnerability knowledge from vulnerability reports on Code4rena. This
    includes the functionality descriptions of vulnerable functions and the code-level
    reasons why the vulnerabilities occur. We then cluster this raw vulnerability
    knowledge based on the functionality descriptions into groups and use GPT-4 to
    summarize a functionality description for each group. With the hierarchical information
    of group functionality, individual functionality, and vulnerability negligence,
    we employ the hierarchical GPT-based matching (i.e., matching the group first,
    then matching functionality and negligence) in GPTScan [[13](#bib.bib13)] to obtain
    the label information for tested code. A function is labeled as a negative sample
    if no vulnerability information matches. All prompts used are from LLM4Vuln and
    GPTScan.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，为了训练我们的模型，我们还需要非易受攻击的良性代码（即负样本），但这种数据在审计报告中缺失。因此，我们提出了自己的数据增强方法以获取高质量的负样本。具体而言，我们采用了LLM4Vuln中描述的基于GPT-4的方法[[15](#bib.bib15)]，从Code4rena的漏洞报告中提取漏洞知识。这包括易受攻击函数的功能描述以及漏洞发生的代码级原因。然后，我们根据功能描述将这些原始漏洞知识进行聚类，并使用GPT-4为每个组总结功能描述。通过分组功能、单独功能和漏洞忽略的层级信息，我们在GPTScan[[13](#bib.bib13)]中采用层级GPT匹配（即先匹配组，然后匹配功能和忽略）来获得被测代码的标签信息。如果没有漏洞信息匹配，则该函数被标记为负样本。所有使用的提示都来自LLM4Vuln和GPTScan。
- en: Eventually, we collected a balanced dataset with 1,734 positive samples and
    1,810 negative samples. This dataset was divided into training, validation, and
    test subsets, containing 2,268, 567, and 709 entries, respectively. During training,
    we use the training and validation sets. During testing, we use the test set.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们收集了一个平衡的数据集，其中包括1,734个正样本和1,810个负样本。该数据集被分为训练集、验证集和测试集，分别包含2,268、567和709条记录。在训练过程中，我们使用训练集和验证集。在测试过程中，我们使用测试集。
- en: '![Refer to caption](img/fc30f39a05141308c8e9e9370bfa38d0.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/fc30f39a05141308c8e9e9370bfa38d0.png)'
- en: 'Figure 5: Data Enhancement for Expanding Vulnerability Explanations based on
    GPT-3.5.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：基于GPT-3.5的漏洞解释扩展的数据增强。
- en: 'After collecting the labeled and unlabeled data, we also obtained corresponding
    explanations for the vulnerabilities. However, the quality of these vulnerability
    justifications varies considerably. Furthermore, some data contain external links,
    which may cause the model to hallucinate and output non-existent links. To improve
    the interpretability of the reasons behind the vulnerabilities in the dataset,
    we used GPT-3.5 to enhance the existing explanations, expanding on the explanations
    of the vulnerabilities, proofs of concept (PoC), and recommended fixes. Fig. [5](#S3.F5
    "Figure 5 ‣ III-D High-quality Training Data Collection and Enhancement ‣ III
    Design of TrustLLM ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability")
    shows an example, where the left part presents the original reasons for the vulnerability,
    which are short and lack detail. We thus use them as prompts, along with the code
    context, to instruct GPT-3.5 to generate more detailed descriptions, including
    the PoC and the mitigation recommendation.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在收集了标注和未标注的数据后，我们还获得了相应的漏洞解释。然而，这些漏洞解释的质量差异很大。此外，一些数据包含外部链接，这可能导致模型产生幻觉并输出不存在的链接。为了提高数据集中漏洞解释的可解释性，我们使用GPT-3.5来增强现有的解释，扩展漏洞的解释、概念验证（PoC）和推荐修复。图[5](#S3.F5
    "图5 ‣ III-D 高质量训练数据收集与增强 ‣ III TrustLLM设计 ‣ TrustLLM：智能合约漏洞的嗅探与推理")展示了一个例子，其中左侧部分展示了漏洞的原始原因，这些原因简短且缺乏细节。因此，我们将这些原因作为提示，与代码上下文一起，用来指导GPT-3.5生成更详细的描述，包括PoC和缓解建议。
- en: IV Evaluation
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 评估
- en: IV-A Experimental Setup
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A 实验设置
- en: 'In our study, we carefully selected a series of benchmark models, categorized
    into two groups: LLMs for zero-shot learning and pre-trained code models based
    on fine-tuning, to ensure a comprehensive and sound comparative analysis. For
    zero-shot learning LLMs, we chose CodeLlama-13b-Instruct, CodeLlama-34b-Instruct [[49](#bib.bib49)],
    GPT-3.5, and GPT-4 as benchmarks, representing the current state-of-the-art. Additionally,
    we selected CodeBERT [[23](#bib.bib23)], GraphCodeBERT [[56](#bib.bib56)], CodeT5 [[28](#bib.bib28)],
    UnixCoder [[57](#bib.bib57)], and CodeLlama-13b [[49](#bib.bib49)] to train classifiers.
    Among these, CodeBERT, GraphCodeBERT, CodeT5, and UnixCoder underwent a complete
    model fine-tuning process to adapt to the specific code classification task. In
    particular, CodeLlama-13b employs LoRA for lightweight tuning and uses the last
    token representation for classification. Note that that our method is different;
    TrustLLM’s Detector achieves classification by generating label names as task
    outputs.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的研究中，我们仔细选择了一系列基准模型，分为两组：零样本学习的LLM和基于微调的预训练代码模型，以确保全面和可靠的比较分析。对于零样本学习LLM，我们选择了CodeLlama-13b-Instruct、CodeLlama-34b-Instruct [[49](#bib.bib49)]、GPT-3.5和GPT-4作为基准，代表当前的最先进技术。此外，我们选择了CodeBERT [[23](#bib.bib23)]、GraphCodeBERT [[56](#bib.bib56)]、CodeT5 [[28](#bib.bib28)]、UnixCoder [[57](#bib.bib57)]和CodeLlama-13b [[49](#bib.bib49)]来训练分类器。其中，CodeBERT、GraphCodeBERT、CodeT5和UnixCoder经过了完整的模型微调过程，以适应特定的代码分类任务。特别地，CodeLlama-13b采用LoRA进行轻量级调优，并使用最后的token表示进行分类。请注意，我们的方法不同；TrustLLM的Detector通过生成标签名称作为任务输出实现分类。
- en: IV-B Research Questions (RQs)
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-B 研究问题（RQs）
- en: 'Since our proposed method comprises two core functions: vulnerability detection
    and reason explanation, we designed a series of experiments to evaluate and demonstrate
    the performance and effectiveness of both tasks. These experiments aim to answer
    the following research questions (RQs):'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们提出的方法包含两个核心功能：漏洞检测和原因解释，我们设计了一系列实验来评估和展示这两个任务的性能和有效性。这些实验旨在回答以下研究问题（RQs）：
- en: RQ1 - Performance Comparison
  id: totrans-127
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: RQ1 - 性能比较
- en: How does the performance of TrustLLM in detecting vulnerabilities compare to
    other models? This question aims to understand how the effectiveness of Detector
    in detecting vulnerabilities compares to that of other existing models. The focus
    is on comparative analysis, involving metrics accuracy, precision, recall, and
    F1 score, to evaluate and contrast the performance.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: TrustLLM在检测漏洞方面的性能与其他模型相比如何？这个问题旨在了解Detector在检测漏洞方面的效果如何与其他现有模型进行比较。重点在于比较分析，涉及准确率、精确度、召回率和F1分数等指标，以评估和对比性能。
- en: RQ2 - Explanation Alignment
  id: totrans-129
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: RQ2 - 解释对齐
- en: To what extent do the explanations generated by TrustLLM’s Reasoner align with
    the real reasons? RQ2 concerns the quality of the explanations the Reasoner provided
    for the decision of the Detector. It questions whether the reasons given by TrustLLM
    correspond to the actual reasons behind the vulnerabilities, emphasizing the interpretability
    and trustworthiness of the model.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: TrustLLM 的 Reasoner 生成的解释在多大程度上与实际原因一致？RQ2 关注 Reasoner 为 Detector 决策提供的解释的质量。它质疑
    TrustLLM 提供的理由是否与漏洞背后的实际原因相符，强调模型的可解释性和可信度。
- en: RQ3 - Two-stage Approach vs. An Integration Model
  id: totrans-131
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: RQ3 - 两阶段方法与集成模型
- en: How does TrustLLM compare with an integration model that performs detection
    and reasoning simultaneously? Our method is based on a generative model, with
    two models trained on the generated labels and reasons, respectively. Another
    approach uses a single model to generate both reasons and labels. This question
    explores the effectiveness and impact of integrating the Detector and Reasoner
    components into one.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: TrustLLM 如何与同时进行检测和推理的集成模型相比？我们的方法基于生成模型，有两个模型分别在生成的标签和理由上进行训练。另一种方法使用单一模型生成理由和标签。这个问题探讨了将
    Detector 和 Reasoner 组件集成到一个模型中的有效性和影响。
- en: RQ4 - Effectiveness of Majority Voting
  id: totrans-133
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: RQ4 - 多数投票的有效性
- en: Can majority voting improve the effectiveness of the Detector? RQ4 investigates
    whether the effectiveness of the Detector can be improved by adopting a majority
    voting mechanism. Majority voting, a technique that makes the final decision based
    on the majority output of multiple models, may improve the robustness and accuracy
    of the method.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 多数投票能否提高 Detector 的有效性？RQ4 研究了通过采用多数投票机制是否能提高 Detector 的有效性。多数投票是一种根据多个模型的多数输出做出最终决策的技术，可能会提高方法的鲁棒性和准确性。
- en: RQ5 - Impact of Additional Information
  id: totrans-135
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: RQ5 - 附加信息的影响
- en: 'The call graph illustrates the interaction of code with other components within
    the project, which is expected to be advantageous for our task. We address two
    specific research sub-questions:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 调用图展示了代码与项目中其他组件的互动，预计这对我们的任务有利。我们探讨了两个具体的研究子问题：
- en: •
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: RQ5.1\. Can the call graph enhance the Detector performance?
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: RQ5.1. 调用图能否提升 Detector 的性能？
- en: •
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: RQ5.2\. In what way does the call graph influence our explanation generation
    process, specifically within the Reasoner-Ranker-Critic pipeline?
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: RQ5.2. 调用图如何影响我们的解释生成过程，特别是在 Reasoner-Ranker-Critic 流水线中？
- en: Besides the RQs above, we also used our model to audit two bounty projects (currently
    anonymous) on Code4rena. We invited audit experts to verify our findings. In the
    end, we found 6 critical vulnerabilities, which were recognized by the project
    team or audit experts. In particular, one vulnerability was not discovered by
    any tools, marked as a great finding. This demonstrates the real-world value of
    TrustLLM. Due to page limitations, we have included these case studies in the
    supplementary materials for interested readers.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 除了上述 RQs，我们还使用我们的模型对 Code4rena 上的两个赏金项目（目前匿名）进行了审计。我们邀请了审计专家验证我们的发现。最终，我们发现了
    6 个关键漏洞，这些漏洞被项目团队或审计专家认可。特别是，一个漏洞没有被任何工具发现，被标记为重大发现。这展示了 TrustLLM 的现实价值。由于篇幅限制，我们将这些案例研究包含在附录材料中，供感兴趣的读者查阅。
- en: IV-C RQ1 - Performance Comparison
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-C RQ1 - 性能比较
- en: 'Firstly, we compared TrustLLM with LLMs based on zero-shot learning, as shown
    in Table [I](#S4.T1 "TABLE I ‣ IV-C RQ1 - Performance Comparison ‣ IV Evaluation
    ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability"). Our method
    also uses a zero-shot approach during the inference phase. We considered two proprietary
    models (GPT-4 and GPT-3.5) and three open-source models (CodeLlama-13b and CodeLlama-34b).
    For the open-source models, we strictly adhered to their prompt formats. Huggingface
    Transformer [[58](#bib.bib58)] has integrated these prompt formats into its framework.
    The format conversion is completed by calling apply_chat_template. CodeLlama requires
    adding [INST] and [/INST] as well as special tags <> and <>. As shown
    in Table [I](#S4.T1 "TABLE I ‣ IV-C RQ1 - Performance Comparison ‣ IV Evaluation
    ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability"), after fine-tuning,
    our proposed strategy significantly outperforms the baseline models in the zero-shot
    scenario in terms of F1, accuracy, and precision, achieving high scores of $0.9121$.
    We checked the confusing matrix and found that all test data are labelled by the
    vulnerability. For GPT-4 and GPT-3.5, we adopted the prompts which are provided
    by our industrial partner, a Web3 security company.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '首先，我们将TrustLLM与基于零-shot学习的LLMs进行了比较，如表[I](#S4.T1 "TABLE I ‣ IV-C RQ1 - Performance
    Comparison ‣ IV Evaluation ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability")所示。我们的方法在推理阶段也使用了零-shot方法。我们考虑了两个专有模型（GPT-4和GPT-3.5）和三个开源模型（CodeLlama-13b和CodeLlama-34b）。对于开源模型，我们严格遵守其提示格式。Huggingface
    Transformer [[58](#bib.bib58)] 已将这些提示格式集成到其框架中。格式转换通过调用apply_chat_template完成。CodeLlama需要添加[INST]和[/INST]以及特殊标签<>和<>。如表[I](#S4.T1
    "TABLE I ‣ IV-C RQ1 - Performance Comparison ‣ IV Evaluation ‣ TrustLLM: Smelling
    and Reasoning Smart Contract Vulnerability")所示，经过微调后，我们提出的策略在零-shot场景中的F1、准确率和精确度方面显著优于基线模型，取得了高达$0.9121$的分数。我们检查了混淆矩阵，发现所有测试数据都被标记为漏洞。对于GPT-4和GPT-3.5，我们采用了由我们的行业合作伙伴——一家Web3安全公司提供的提示。'
- en: 'TABLE I: Performance comparison between TrustLLM’s Detector and zero-shot LLMs.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 表 I：TrustLLM的检测器与零-shot LLMs的性能比较。
- en: '|  | F1 | Recall | Precision | Accuracy |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '|  | F1 | 召回率 | 精确度 | 准确率 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| GPT-4 | 0.6809 | 1 | 0.5162 | 0.5162 |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | 0.6809 | 1 | 0.5162 | 0.5162 |'
- en: '| GPT-3.5 | 0.6809 | 1 | 0.5162 | 0.5162 |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 | 0.6809 | 1 | 0.5162 | 0.5162 |'
- en: '| CodeLlama-13b | 0.6767 | 0.9781 | 0.5173 | 0.5176 |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| CodeLlama-13b | 0.6767 | 0.9781 | 0.5173 | 0.5176 |'
- en: '| CodeLlama-34b | 0.6725 | 0.9454 | 0.5219 | 0.5247 |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| CodeLlama-34b | 0.6725 | 0.9454 | 0.5219 | 0.5247 |'
- en: '| TrustLLM | 0.9121 | 0.8934 | 0.9316 | 0.9111 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| TrustLLM | 0.9121 | 0.8934 | 0.9316 | 0.9111 |'
- en: 'TABLE II: Performance comparison between TrustLLM’s Detector and other fine-tuned
    models.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 表 II：TrustLLM的检测器与其他微调模型的性能比较。
- en: '|  | F1 | Recall | Precision | Accuracy |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '|  | F1 | 召回率 | 精确度 | 准确率 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| CodeBERT | 0.8221 | 0.7322 | 0.9371 | 0.8364 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| CodeBERT | 0.8221 | 0.7322 | 0.9371 | 0.8364 |'
- en: '| GraphCodeBERT | 0.8841 | 0.8333 | 0.9414 | 0.8872 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| GraphCodeBERT | 0.8841 | 0.8333 | 0.9414 | 0.8872 |'
- en: '| CodeT5 | 0.8481 | 0.7705 | 0.9431 | 0.8575 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| CodeT5 | 0.8481 | 0.7705 | 0.9431 | 0.8575 |'
- en: '| UnixCoder | 0.8791 | 0.8443 | 0.9169 | 0.8801 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| UnixCoder | 0.8791 | 0.8443 | 0.9169 | 0.8801 |'
- en: '| CodeLlama-13b-class | 0.8936 | 0.8716 | 0.9167 | 0.8928 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| CodeLlama-13b-class | 0.8936 | 0.8716 | 0.9167 | 0.8928 |'
- en: '| TrustLLM | 0.9121 | 0.8934 | 0.9316 | 0.9111 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| TrustLLM | 0.9121 | 0.8934 | 0.9316 | 0.9111 |'
- en: 'Secondly, we compared Detector with fine-tuned models in detecting vulnerabilities,
    using F1, recall, precision, and accuracy as evaluation metrics, as shown in Table [II](#S4.T2
    "TABLE II ‣ IV-C RQ1 - Performance Comparison ‣ IV Evaluation ‣ TrustLLM: Smelling
    and Reasoning Smart Contract Vulnerability"). We compared our method with CodeBERT,
    GraphCodeBERT, CodeT5, UnixCoder, and CodeLlama-13b-class. CodeBERT, GraphCodeBERT,
    CodeT5, and UnixCoder underwent full model fine-tuning. These traditional pre-trained
    models use the first token of the input sequence as the feature input for the
    classifier. CodeBERT is based on the transformer encoder. GraphCodeBERT has the
    same architecture as CodeBERT but includes additional pre-training on data dependency
    relations. CodeT5 utilizes the transformer encoder and decoder, adopting an architecture
    similar to T5 [[27](#bib.bib27)]. UnixCoder unifies the encoder and decoder architecture,
    controlling the model behaviour through a masked attention matrix with prefix
    adapters. CodeLlama-13b-class performs classification based on LoRA. We fine-tuned
    CodeLlama-13b-class for LoRA classification using the PEFT framework. CodeLlama-13b-class
    uses the representation of the last token of the input sequence as the feature
    input for the classifier.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '其次，我们将Detector与经过微调的模型在检测漏洞方面进行了比较，使用F1、召回率、精确度和准确率作为评估指标，如表[II](#S4.T2 "TABLE
    II ‣ IV-C RQ1 - Performance Comparison ‣ IV Evaluation ‣ TrustLLM: Smelling and
    Reasoning Smart Contract Vulnerability")所示。我们将我们的方法与CodeBERT、GraphCodeBERT、CodeT5、UnixCoder和CodeLlama-13b-class进行了比较。CodeBERT、GraphCodeBERT、CodeT5和UnixCoder经历了完整的模型微调。这些传统的预训练模型使用输入序列的第一个标记作为分类器的特征输入。CodeBERT基于transformer编码器。GraphCodeBERT与CodeBERT具有相同的架构，但在数据依赖关系上进行了额外的预训练。CodeT5利用transformer编码器和解码器，采用了类似于T5的架构[[27](#bib.bib27)]。UnixCoder统一了编码器和解码器架构，通过带有前缀适配器的掩码注意力矩阵控制模型行为。CodeLlama-13b-class基于LoRA进行分类。我们使用PEFT框架对CodeLlama-13b-class进行了LoRA分类微调。CodeLlama-13b-class使用输入序列的最后一个标记的表示作为分类器的特征输入。'
- en: 'As shown in Table [II](#S4.T2 "TABLE II ‣ IV-C RQ1 - Performance Comparison
    ‣ IV Evaluation ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability"),
    TrustLLM achieves the highest scores of F1, Recall, and Accuracy among all methods,
    $0.9121$), indicating that many of the predicted risky vulnerabilities are indeed
    risky.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '如表[II](#S4.T2 "TABLE II ‣ IV-C RQ1 - Performance Comparison ‣ IV Evaluation
    ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability")所示，TrustLLM在所有方法中获得了最高的F1、召回率和准确率得分（$0.9121$），这表明许多预测的风险漏洞确实是有风险的。'
- en: 'Answer
    for RQ1: The performance of TrustLLM’s Detector exceeds that of traditional full-model
    fine-tuning, LoRA fine-tuning in a classification manner, and LLMs based on in-context
    learning. The performance of fine-tuned models is also better than that of zero-shot
    learning.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 'Answer
    for RQ1: The performance of TrustLLM’s Detector exceeds that of traditional full-model
    fine-tuning, LoRA fine-tuning in a classification manner, and LLMs based on in-context
    learning. The performance of fine-tuned models is also better than that of zero-shot
    learning.'
- en: IV-D RQ2 - Explanation Alignment
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-D RQ2 - 解释对齐
- en: '![Refer to caption](img/7868563ff5efd6f0889aae04867c714e.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/7868563ff5efd6f0889aae04867c714e.png)'
- en: 'Figure 6: Comparing the alignment with ground-truth reasons.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：比较与真实原因的一致性。
- en: 'To measure the effectiveness of Reasoner in explaining vulnerabilities, we
    compared the consistency between the explanations we generated and the root causes.
    Given the LLM’s outstanding performance in interpreting textual meaning, we used
    GPT-4 to verify whether our generated explanations align with the root causes.
    For this consistency assessment, we employed automated annotation prompts from
    Y. Sun et al. [[15](#bib.bib15)]. The results of our consistency test are depicted
    in Fig. [6](#S4.F6 "Figure 6 ‣ IV-D RQ2 - Explanation Alignment ‣ IV Evaluation
    ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability"), where the y-axis
    represents the percentage of our explanations in the test set that match the root
    causes. Our method significantly outperformed the baseline methods, achieving
    a consistency rate of 37.99%, while no baseline method exceeded 25%. Among these
    baselines, GPT-4 performed the second best with 24.13% consistency. Additionally,
    the results also indicated that CodeLlama-13b had the weakest performance.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '为了衡量Reasoner在解释漏洞方面的有效性，我们比较了我们生成的解释与根本原因之间的一致性。鉴于LLM在解释文本含义方面的出色表现，我们使用GPT-4来验证我们生成的解释是否与根本原因对齐。为了进行一致性评估，我们使用了Y.
    Sun等人提出的自动注释提示[[15](#bib.bib15)]。我们的一致性测试结果如图[6](#S4.F6 "Figure 6 ‣ IV-D RQ2 -
    Explanation Alignment ‣ IV Evaluation ‣ TrustLLM: Smelling and Reasoning Smart
    Contract Vulnerability")所示，其中y轴表示测试集中与根本原因匹配的解释的百分比。我们的方法显著优于基线方法，达到了37.99%的一致性率，而没有任何基线方法超过25%。在这些基线方法中，GPT-4的表现次佳，一致性为24.13%。此外，结果还表明CodeLlama-13b的表现最差。'
- en: 'Answer
    for RQ2: The rationality of Reasoner’s output is clearly superior to that of other
    models. On the test set, its consistency with real reasons reaches 37.99%, which
    is over 10% higher than the second-ranked GPT-4.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 'Answer
    for RQ2: The rationality of Reasoner’s output is clearly superior to that of other
    models. On the test set, its consistency with real reasons reaches 37.99%, which
    is over 10% higher than the second-ranked GPT-4.'
- en: IV-E RQ3 - Two-stage Approach vs. An Integration Model
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-E RQ3 - 两阶段方法与集成模型
- en: '![Refer to caption](img/96b86510b936bfde6c8679e8adb998dd.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/96b86510b936bfde6c8679e8adb998dd.png)'
- en: 'Figure 7: Comparing TrustLLM with the integration models that make decisions
    and explain the vulnerabilities simultaneously.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：比较 TrustLLM 与同时做出决策并解释漏洞的集成模型。
- en: 'Our research methodology involves vulnerability detection and explanation,
    executed in two stages. We trained two models, i.e., Detector and Reasoner, based
    on a generative approach to perform these tasks on their respective high-quality
    datasets. A question arises whether these two tasks can be merged and trained
    simultaneously in a single model. In response, we developed an integration model
    that generates labels and explanations for the vulnerabilities, comparing it to
    our two-stage approach. The integration model uses prompts similar to those of
    Reasoner, with additional requirements to output the label. We explored two integration
    training approaches: 1) generating labels first, then explaining the reasons;
    2) explaining the reasons first, then generating labels.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究方法包括漏洞检测和解释，分为两个阶段进行。我们基于生成方法训练了两个模型，即检测器和推理器，在各自的高质量数据集上执行这些任务。一个问题是这两个任务是否可以合并并在单一模型中同时训练。为此，我们开发了一个集成模型，用于生成漏洞的标签和解释，并将其与我们的两阶段方法进行比较。集成模型使用类似于推理器的提示，并附加要求输出标签。我们探讨了两种集成训练方法：1）首先生成标签，然后解释原因；2）首先解释原因，然后生成标签。
- en: 'The results, as shown in Fig. [7](#S4.F7 "Figure 7 ‣ IV-E RQ3 - Two-stage Approach
    vs. An Integration Model ‣ IV Evaluation ‣ TrustLLM: Smelling and Reasoning Smart
    Contract Vulnerability"), indicate that our step-wise approach outperforms the
    integration models across four key performance metrics. While the three methods
    are similar in precision, the differences in other metrics are notable. Analyzing
    these results, we found that the integration methods have higher accuracy for
    negative samples but a lower detection rate for positive samples (i.e., lower
    recall). This may be attributed to the generative loss optimization, where the
    output sequence is longer, making the label-related loss occupy a smaller proportion
    of the total loss, thus preventing the model from adequately focusing on the label.
    To test this hypothesis, we added data that includes only label generation to
    the dataset during the integration training process, guiding the model to focus
    more on the label. In the evaluation phase, we still required the model to output
    both labels and explanations simultaneously. Through this mixed training approach,
    we observed a significant improvement in the model’s vulnerability detection performance,
    with an F1 score of $0.8433$.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '结果如图[7](#S4.F7 "Figure 7 ‣ IV-E RQ3 - Two-stage Approach vs. An Integration
    Model ‣ IV Evaluation ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability")所示，表明我们的逐步方法在四个关键性能指标上优于集成模型。尽管三种方法在精确度上相似，但其他指标的差异显著。分析这些结果，我们发现集成方法在负样本上的准确率较高，但正样本的检测率较低（即召回率较低）。这可能归因于生成损失优化，其中输出序列较长，使得与标签相关的损失占总损失的比例较小，从而阻碍了模型对标签的充分关注。为了验证这一假设，我们在集成训练过程中添加了仅包含标签生成的数据，指导模型更多地关注标签。在评估阶段，我们仍要求模型同时输出标签和解释。通过这种混合训练方法，我们观察到模型的漏洞检测性能显著提高，F1
    分数为 $0.8433$。'
- en: 'Answer
    for RQ3: TrustLLM achieved better detection performance than the integration model
    that outputs labels and reasons simultaneously. We confirmed that the model struggles
    to focus on the labels when required to output both types of information, as evidenced
    by our inclusion of label-only data in the verification process.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 'Answer
    for RQ3: TrustLLM achieved better detection performance than the integration model
    that outputs labels and reasons simultaneously. We confirmed that the model struggles
    to focus on the labels when required to output both types of information, as evidenced
    by our inclusion of label-only data in the verification process.'
- en: 'TABLE III: Majority Voting vs. Single Prompt.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 表 III：多数投票与单一提示的比较。
- en: '|  | F1 | Recall | Precision | Accuracy |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '|  | F1 | 召回率 | 精确度 | 准确率 |'
- en: '| Single-prompt | 0.8278 | 0.8005 | 0.8567 | 0.8279 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 单一提示 | 0.8278 | 0.8005 | 0.8567 | 0.8279 |'
- en: '| Prompt-1 | 0.8988 | 0.8852 | 0.9127 | 0.8970 |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| 提示-1 | 0.8988 | 0.8852 | 0.9127 | 0.8970 |'
- en: '| Prompt-2 | 0.9027 | 0.8743 | 0.9329 | 0.9027 |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| 提示-2 | 0.9027 | 0.8743 | 0.9329 | 0.9027 |'
- en: '| Prompt-3 | 0.9063 | 0.8852 | 0.9284 | 0.9055 |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 提示-3 | 0.9063 | 0.8852 | 0.9284 | 0.9055 |'
- en: '| Prompt-4 | 0.9098 | 0.8962 | 0.9239 | 0.9083 |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 提示-4 | 0.9098 | 0.8962 | 0.9239 | 0.9083 |'
- en: '| Prompt-5 | 0.9096 | 0.8934 | 0.9263 | 0.9083 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 提示-5 | 0.9096 | 0.8934 | 0.9263 | 0.9083 |'
- en: '| TrustLLM | 0.9121 | 0.8934 | 0.9316 | 0.9111 |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| TrustLLM | 0.9121 | 0.8934 | 0.9316 | 0.9111 |'
- en: IV-F RQ4 - Effectiveness of Majority Voting
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-F RQ4 - 多数投票的有效性
- en: 'Our research explored a method using multiple prompts and a voting mechanism
    for Detector to determine the final label. This method aims to enhance the model’s
    precision and credibility. During the evaluation process, we continued to use
    metrics such as the F1 score, recall, precision, and accuracy. We calculated these
    metrics for each prompt individually for comparative analysis, as shown in Table [III](#S4.T3
    "TABLE III ‣ IV-E RQ3 - Two-stage Approach vs. An Integration Model ‣ IV Evaluation
    ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability"). It should be
    noted that the first row Single-prompt indicates that we used only one prompt
    format to train Detector. Prompt-1, Prompt-2, Prompt-3, Prompt-4, and Prompt-5
    represent the results for each prompt after multiple-prompt training. The last
    row shows the results after majority voting, indicating that majority voting can
    improve the overall performance of TrustLLM, with both the F1 score and accuracy
    being the highest. At the same time, except for Single-prompt, we noticed minimal
    performance differences among multiple prompts. Single-prompt performed much worse
    than the others. Training with multiple prompts can improve model performance
    compared to using only one prompt during training.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '我们的研究探讨了一种使用多个提示和投票机制来确定Detector最终标签的方法。该方法旨在提高模型的精度和可信度。在评估过程中，我们继续使用F1分数、召回率、精确度和准确率等指标。我们对每个提示单独计算这些指标以进行比较分析，如表[III](#S4.T3
    "TABLE III ‣ IV-E RQ3 - Two-stage Approach vs. An Integration Model ‣ IV Evaluation
    ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability")所示。需要注意的是，第一行Single-prompt表示我们仅使用一种提示格式来训练Detector。Prompt-1、Prompt-2、Prompt-3、Prompt-4和Prompt-5代表了多提示训练后每个提示的结果。最后一行显示了经过多数投票后的结果，表明多数投票可以提高TrustLLM的整体性能，其中F1分数和准确率均为最高。同时，除了Single-prompt之外，我们注意到多个提示之间的性能差异最小。Single-prompt的表现远逊于其他提示。与仅使用一个提示进行训练相比，使用多个提示可以提高模型性能。'
- en: 'Additionally, we divided the test set into two groups based on whether the
    predictions were correct or incorrect, named “correct prediction" and “incorrect
    prediction" groups, respectively, and analyzed the distribution of confidence
    scores within these two groups. We found that in the incorrect prediction group,
    the proportion of confidence scores within the range of $0.6$ is significantly
    higher than in the correct prediction group (11% vs 2%, 10% vs 3%, respectively),
    as shown in Fig. [8](#S4.F8 "Figure 8 ‣ IV-F RQ4 - Effectiveness of Majority Voting
    ‣ IV Evaluation ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability").
    The confidence score can reflect the reliability of the prediction results to
    a certain extent. When the confidence score is low, the prediction results are
    less credible.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '此外，我们将测试集根据预测结果的正确与否分为两个组，分别命名为“正确预测”和“错误预测”组，并分析了这两个组内的置信度得分分布。我们发现，在错误预测组中，置信度得分在$0.6$范围内的比例显著高于正确预测组（分别为11%
    vs 2%，10% vs 3%），如图[8](#S4.F8 "Figure 8 ‣ IV-F RQ4 - Effectiveness of Majority
    Voting ‣ IV Evaluation ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability")所示。置信度得分在一定程度上可以反映预测结果的可靠性。当置信度得分较低时，预测结果的可信度较低。'
- en: 'Answer
    for RQ4: Majority voting enhances the detection performance and stability. Additionally,
    using multiple prompts allows the model to perform better and be more reliable
    than when using a single prompt.![Refer to caption](img/7394abe3d47287314f25c68ffc90e5ce.png)'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: RQ4的答案：多数投票提高了检测性能和稳定性。此外，使用多个提示使模型比使用单个提示时表现更好，可靠性更高。![参见说明](img/7394abe3d47287314f25c68ffc90e5ce.png)
- en: 'Figure 8: The Distribution of Voting Scores for Correct Predictions and Wrong
    Predictions.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：正确预测与错误预测的投票得分分布。
- en: IV-G RQ5 - Impact of Additional Information
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-G RQ5 - 额外信息的影响
- en: We explored whether introducing additional call graph information into the model
    could enhance its performance. We added function call relationships to the prompts
    as contextual information.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们探讨了引入额外调用图信息是否能够提升模型的性能。我们将函数调用关系作为上下文信息添加到提示中。
- en: RQ5.1
  id: totrans-191
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: RQ5.1
- en: 'Through comparative experiments as shown in Table [IV](#S4.T4 "TABLE IV ‣ RQ5.2
    ‣ IV-G RQ5 - Impact of Additional Information ‣ IV Evaluation ‣ TrustLLM: Smelling
    and Reasoning Smart Contract Vulnerability"), we found that this calling contextual
    information did not improve the model’s overall performance. In the second row,
    Call, we used the prompts with the calling information and then employed majority
    voting to decide the prediction result. For the third row, Call-OutCall, we used
    prompts both with and without calling information and also used majority voting.
    Compared with TrustLLM’s Detector, they exhibited lower precision, accuracy, and
    f1, with almost the same recall.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '通过如表[IV](#S4.T4 "TABLE IV ‣ RQ5.2 ‣ IV-G RQ5 - Impact of Additional Information
    ‣ IV Evaluation ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability")所示的比较实验，我们发现调用上下文信息并未提升模型的整体性能。在第二行，Call，我们使用了包含调用信息的提示，并采用了多数投票决定预测结果。在第三行，Call-OutCall，我们使用了包含和不包含调用信息的提示，并同样使用了多数投票。与TrustLLM的检测器相比，它们展示了较低的精度、准确率和f1，召回率几乎相同。'
- en: RQ5.2
  id: totrans-193
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: RQ5.2
- en: 'Fig. [9](#S4.F9 "Figure 9 ‣ RQ5.2 ‣ IV-G RQ5 - Impact of Additional Information
    ‣ IV Evaluation ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability")
    demonstrates the selected reason distribution from Ranker-Critic. We can see that
    the majority (65%) of the selected reasons are from the prompts with calling information,
    while there is still a high ratio (35%) of selected reasons from the prompts without
    calling information.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '图[9](#S4.F9 "Figure 9 ‣ RQ5.2 ‣ IV-G RQ5 - Impact of Additional Information
    ‣ IV Evaluation ‣ TrustLLM: Smelling and Reasoning Smart Contract Vulnerability")展示了Ranker-Critic选择的原因分布。我们可以看到，绝大多数（65%）的选择原因来自于包含调用信息的提示，而仍有较高比例（35%）的选择原因来自于不包含调用信息的提示。'
- en: Although function call relationships provide more information, this information
    does not always help the model better complete the current task. In some cases,
    this information may cause interference, making it difficult for the model to
    identify critical information, thereby resulting in more false positives and affecting
    performance. Furthermore, not all function call relationships are practically
    valuable. If these additional pieces of information are not closely related to
    the problem the model is trying to solve, they may not help enhance the model’s
    performance. Our research indicates that merely adding function call information
    does not directly facilitate the model’s effectiveness in detecting vulnerabilities.
    In the field of vulnerability detection, exploring how to construct effective
    contextual information remains a challenging and worthy research question.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管函数调用关系提供了更多信息，但这些信息并不总是有助于模型更好地完成当前任务。在某些情况下，这些信息可能会造成干扰，使得模型难以识别关键性信息，从而导致更多的假阳性并影响性能。此外，并非所有的函数调用关系都是实际有价值的。如果这些额外的信息与模型试图解决的问题不紧密相关，它们可能不会帮助提升模型的性能。我们的研究表明，仅仅添加函数调用信息并不能直接提高模型在漏洞检测中的效果。在漏洞检测领域，探索如何构建有效的上下文信息仍然是一个具有挑战性且值得研究的问题。
- en: 'Answer
    for RQ5: Additional call graph information may enable the model to make better
    judgments in some cases. However, we also observed situations where this additional
    information could potentially confuse the model, thereby reducing its performance.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 'Answer
    for RQ5: Additional call graph information may enable the model to make better
    judgments in some cases. However, we also observed situations where this additional
    information could potentially confuse the model, thereby reducing its performance.'
- en: 'TABLE IV: Impact with or without Additional Information.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 表IV：有无额外信息的影响。
- en: '|  | F1 | Recall | Precision | Accuracy |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '|  | F1 | 召回率 | 精度 | 准确率 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Call | 0.9011 | 0.8962 | 0.9061 | 0.8984 |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| Call | 0.9011 | 0.8962 | 0.9061 | 0.8984 |'
- en: '| Call-OutCall | 0.9083 | 0.8934 | 0.9237 | 0.9069 |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| Call-OutCall | 0.9083 | 0.8934 | 0.9237 | 0.9069 |'
- en: '| TrustLLM | 0.9121 | 0.8934 | 0.9316 | 0.9111 | ![Refer to caption](img/96e354c44aa85fd3c805f96096703961.png)'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '| TrustLLM | 0.9121 | 0.8934 | 0.9316 | 0.9111 | ![参见说明](img/96e354c44aa85fd3c805f96096703961.png)'
- en: 'Figure 9: Final Reason Distribution of Ranker-Critic.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：Ranker-Critic最终原因分布。
- en: V Related Work
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V 相关工作
- en: Vulnerability detection has been critical problems for the healthy and sustainable
    development of the software ecosystem, especially on blockchain and smart contracts.
    Traditional vulnerability detection methods, such as those based on predefined
    static analysis rules [[3](#bib.bib3)], often lack good generalization capabilities
    and are difficult to extend to new types of vulnerabilities. In addition, some
    logic-related vulnerabilities [[2](#bib.bib2)] are also difficult to abstract
    into static analysis rules. Researchers have employed a deep learning-based approach
    to address this issue. For example, Zhuang et al. [[59](#bib.bib59)] used graph
    neural networks to detect vulnerabilities in smart contracts. Liu et al. [[60](#bib.bib60)]
    fused the interpretable graph features with expert patterns to achieve better
    results and interpretable weights. Wu et al. [[61](#bib.bib61)] utilized pre-training
    technique and crucial data flow graphs for the detection of smart contract vulnerabilities.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 漏洞检测对于软件生态系统的健康和可持续发展至关重要，特别是在区块链和智能合约方面。传统的漏洞检测方法，例如基于预定义静态分析规则[[3](#bib.bib3)]的方法，通常缺乏良好的泛化能力，难以扩展到新类型的漏洞。此外，一些与逻辑相关的漏洞[[2](#bib.bib2)]也很难抽象为静态分析规则。研究人员采用了基于深度学习的方法来解决这个问题。例如，Zhuang等人[[59](#bib.bib59)]使用图神经网络来检测智能合约中的漏洞。Liu等人[[60](#bib.bib60)]将可解释的图特征与专家模式融合，以获得更好的结果和可解释的权重。Wu等人[[61](#bib.bib61)]利用预训练技术和关键数据流图来检测智能合约漏洞。
- en: With the advent of large language models (LLMs), researchers are utilizing not
    only traditional deep learning models but also LLMs for vulnerability detection.
    For example, Ullah et al. [[62](#bib.bib62)] evaluated LLMs on vulnerability detection
    tasks and found that they may not perform well. Fu et al. [[63](#bib.bib63)] further
    analyzed the gap for LLMs in detecting vulnerabilities. Thapa et al. [[64](#bib.bib64)]
    leveraged LLMs for software vulnerability detection, and David et al. [[12](#bib.bib12)]
    used LLMs for smart contract vulnerability tasks. Alqarni et al. [[65](#bib.bib65)]
    fine-tuned the BERT model [[66](#bib.bib66)] for source code vulnerability detection.
    Sun et al. [[15](#bib.bib15)] conducted an empirical study to find out how to
    enhance the ability of LLMs to detect vulnerabilities. In addition, Mathews et
    al. [[67](#bib.bib67)], Hu et al. [[14](#bib.bib14)], and Purba et al. [[68](#bib.bib68)]
    made efforts to utilize LLMs for detecting vulnerabilities. Some research also
    fused large language models with tradition program analysis methods. Sun et al. [[13](#bib.bib13)]
    proposed GPTScan for smart contracts, leveraging static program analysis to reduce
    the false positives of LLMs. Li et al. [[69](#bib.bib69)] proposed LLift for integrating
    LLMs with static analysis tools.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大型语言模型（LLMs）的出现，研究人员不仅使用传统的深度学习模型，还使用LLMs进行漏洞检测。例如，Ullah等人[[62](#bib.bib62)]评估了LLMs在漏洞检测任务中的表现，发现它们可能效果不佳。Fu等人[[63](#bib.bib63)]进一步分析了LLMs在检测漏洞方面的差距。Thapa等人[[64](#bib.bib64)]利用LLMs进行软件漏洞检测，David等人[[12](#bib.bib12)]使用LLMs进行智能合约漏洞任务。Alqarni等人[[65](#bib.bib65)]对BERT模型[[66](#bib.bib66)]进行了微调以进行源代码漏洞检测。Sun等人[[15](#bib.bib15)]进行了实证研究，以发现如何提高LLMs检测漏洞的能力。此外，Mathews等人[[67](#bib.bib67)]、Hu等人[[14](#bib.bib14)]和Purba等人[[68](#bib.bib68)]也努力利用LLMs进行漏洞检测。一些研究还将大型语言模型与传统程序分析方法结合。Sun等人[[13](#bib.bib13)]提出了GPTScan用于智能合约，利用静态程序分析来减少LLMs的误报。Li等人[[69](#bib.bib69)]提出了LLift，将LLMs与静态分析工具结合。
- en: However, all these studies have not tuned domain-specific knowledge into the
    models themselves, focusing only on the knowledge from the pre-training dataset
    or the vulnerable code segment itself, which could not effectively detect logic
    bugs.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，所有这些研究并未将领域特定知识融入到模型中，只关注预训练数据集或脆弱代码段本身的知识，这无法有效检测逻辑错误。
- en: VI Threats to Validity
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VI 有效性威胁
- en: In the data collection process, there is a risk of data bias, which might prevent
    models trained and tested on these data from generalizing accurately. Moreover,
    the precision of data labelling significantly impacts model performance. To mitigate
    these issues, we collected verified data from real and public audit reports and
    utilized the latest tools, such as GPTScan [[13](#bib.bib13)] and LLM4Vuln [[15](#bib.bib15)],
    to assist in cleaning and annotating the data. It is important to note that external
    links in the data could induce LLM to produce incorrect information; therefore,
    we performed data cleaning to remove these links. Considering LLMs’ sensitivity
    to input data, we standardized the code data, including removing unnecessary spaces
    without changing code semantics, to enhance the model robustness and reliability.
    To maximize the performance of the zero-shot learning of GPT-3.5 and GPT-4, we
    adopted and optimized the prompts from our partner, a Web3 security company. These
    prompts have been integrated into their working pipeline. For open-source models,
    we collaborated with an auditing expert to adapt their prompts for these models.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据收集过程中，存在数据偏差的风险，这可能会阻止在这些数据上训练和测试的模型准确地进行泛化。此外，数据标注的精确度对模型性能有显著影响。为了减轻这些问题，我们收集了来自真实和公开审计报告的经过验证的数据，并利用了最新工具，如GPTScan [[13](#bib.bib13)]和LLM4Vuln [[15](#bib.bib15)]，来帮助清理和标注数据。需要注意的是，数据中的外部链接可能会导致LLM生成不正确的信息；因此，我们进行了数据清理以去除这些链接。考虑到LLM对输入数据的敏感性，我们对代码数据进行了标准化处理，包括去除不必要的空格而不改变代码语义，以增强模型的稳健性和可靠性。为了最大化GPT-3.5和GPT-4的零-shot学习性能，我们采用并优化了来自我们的合作伙伴——一家Web3安全公司的提示。这些提示已被整合到他们的工作流程中。对于开源模型，我们与审计专家合作，为这些模型调整了提示。
- en: Overfitting is a common issue during model training, which we addressed by implementing
    an early stopping strategy. The choice of different models might affect the ranker-critic
    architecture’s effectiveness. We tested multiple cutting-edge open-source models,
    including MoE [[52](#bib.bib52)], CodeLlama-70b [[49](#bib.bib49)], Llama2-70b [[33](#bib.bib33)],
    and the recently introduced Gemma [[70](#bib.bib70)], and compared their performance
    on inference benchmark tests. Based on factors like the strictness of the model
    output format and operational speed, we chose MoE [[52](#bib.bib52)]. Our research
    also showed that the consistency between the selected reasons from the MoE and
    the real reasons reached about 38%. To control costs, we limited the maximum iterations
    in the ranker-critic loop to five and adopted four-decimal precision handling.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 过拟合是模型训练中的一个常见问题，我们通过实施早停策略来解决。不同模型的选择可能会影响ranker-critic架构的有效性。我们测试了多个前沿开源模型，包括MoE [[52](#bib.bib52)]、CodeLlama-70b [[49](#bib.bib49)]、Llama2-70b [[33](#bib.bib33)]和最近推出的Gemma [[70](#bib.bib70)]，并比较了它们在推理基准测试中的表现。基于模型输出格式的严格性和操作速度等因素，我们选择了MoE [[52](#bib.bib52)]。我们的研究还表明，MoE所选理由与实际理由的一致性达到了约38%。为了控制成本，我们将ranker-critic循环的最大迭代次数限制为五次，并采用了四位小数精度处理。
- en: VII Conclusion
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VII 结论
- en: In this paper, we proposed TrustLLM, the first smart contract auditing framework
    that combines fine-tuning and LLM-based agents to detect vulnerabilities and explain
    the results. We adopted a multiple-prompt-based strategy and applied LoRA-based
    fine-tuning to train the Detector and Reasoner. The former generates results based
    on a majority voting mechanism, while the latter provides multiple alternative
    explanations based on different inference paths. Furthermore, we introduced two
    LLM agents, Ranker and Critic, to collaborate in selecting the most appropriate
    explanation. Our approach demonstrated superior performance in zero-shot scenarios
    compared to zero-shot LLM learning and traditional full-model fine-tuning methods.
    We studied the performance improvement brought by the majority voting strategy
    and compared different LoRA training methods, providing the rationality of our
    choice. We also explored how additional calling context affects our model’s performance.
    For future work, we will focus on enhancing the model’s stability and its alignment
    with human preferences.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们提出了TrustLLM，这是第一个将微调和基于LLM的代理结合起来检测漏洞并解释结果的智能合约审计框架。我们采用了基于多提示的策略，并应用了LoRA-based微调来训练检测器和推理器。前者基于多数投票机制生成结果，而后者则基于不同的推理路径提供多种替代解释。此外，我们引入了两个LLM代理，Ranker和Critic，协作选择最合适的解释。我们的研究方法在零样本场景下展示了优越的性能，相较于零样本LLM学习和传统全模型微调方法。我们研究了多数投票策略带来的性能提升，并比较了不同的LoRA训练方法，提供了我们选择的合理性。我们还探讨了额外调用上下文如何影响我们模型的性能。未来的工作将集中于提升模型的稳定性及其与人类偏好的对齐。
- en: References
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] L. Whitney, “Google paid out $10 million in bug bounties to security researchers
    in 2023,” https://www.zdnet.com/article/google-paid-out-10-million-in-bug-bounties-to-security-researchers-in-2023/,
    Mar. 2024.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] L. Whitney, “谷歌在2023年向安全研究人员支付了1000万美元的漏洞奖励，” https://www.zdnet.com/article/google-paid-out-10-million-in-bug-bounties-to-security-researchers-in-2023/,
    2024年3月。'
- en: '[2] Z. Zhang, B. Zhang, W. Xu, and Z. Lin, “Demystifying Exploitable Bugs in
    Smart Contracts,” in *2023 IEEE/ACM 45th International Conference on Software
    Engineering (ICSE)*, May 2023, pp. 615–627.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Z. Zhang, B. Zhang, W. Xu, 和 Z. Lin, “揭示智能合约中的可利用漏洞，” 在 *2023年IEEE/ACM第45届国际软件工程会议（ICSE）*
    中，2023年5月，第615–627页。'
- en: '[3] J. Feist, G. Grieco, and A. Groce, “Slither: A static analysis framework
    for smart contracts,” in *2019 IEEE/ACM 2nd International Workshop on Emerging
    Trends in Software Engineering for Blockchain (WETSEB)*, May 2019, pp. 8–15.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] J. Feist, G. Grieco, 和 A. Groce, “Slither：智能合约的静态分析框架，” 在 *2019年IEEE/ACM第二届区块链软件工程新兴趋势国际研讨会（WETSEB）*
    中，2019年5月，第8–15页。'
- en: '[4] Y. Fang, D. Wu, X. Yi, S. Wang, Y. Chen, M. Chen, Y. Liu, and L. Jiang,
    “Beyond “protected” and “private”: An empirical security analysis of custom function
    modifiers in smart contracts,” in *Proceedings of the 32nd ACM SIGSOFT International
    Symposium on Software Testing and Analysis*, ser. ISSTA 2023.   New York, NY,
    USA: Association for Computing Machinery, 2023, p. 1157–1168\. [Online]. Available:
    [https://doi.org/10.1145/3597926.3598125](https://doi.org/10.1145/3597926.3598125)'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Y. Fang, D. Wu, X. Yi, S. Wang, Y. Chen, M. Chen, Y. Liu, 和 L. Jiang, “超越“保护”和“私有”：智能合约中自定义函数修饰符的实证安全分析，”
    在 *第32届ACM SIGSOFT国际软件测试与分析研讨会论文集* 中，ISSTA 2023系列。纽约，NY，美国：计算机协会，2023年，第1157–1168页。[在线].
    可用：[https://doi.org/10.1145/3597926.3598125](https://doi.org/10.1145/3597926.3598125)'
- en: '[5] L. Brent, N. Grech, S. Lagouvardos, B. Scholz, and Y. Smaragdakis, “Ethainter:
    a smart contract security analyzer for composite vulnerabilities,” in *Proceedings
    of the 41st ACM SIGPLAN Conference on Programming Language Design and Implementation*,
    ser. PLDI 2020.   New York, NY, USA: Association for Computing Machinery, 2020,
    p. 454–469\. [Online]. Available: [https://doi.org/10.1145/3385412.3385990](https://doi.org/10.1145/3385412.3385990)'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] L. Brent, N. Grech, S. Lagouvardos, B. Scholz, 和 Y. Smaragdakis, “Ethainter：一种用于复合漏洞的智能合约安全分析器，”
    在 *第41届ACM SIGPLAN编程语言设计与实现会议论文集* 中，PLDI 2020系列。纽约，NY，美国：计算机协会，2020年，第454–469页。[在线].
    可用：[https://doi.org/10.1145/3385412.3385990](https://doi.org/10.1145/3385412.3385990)'
- en: '[6] J. Chen, X. Xia, D. Lo, J. Grundy, X. Luo, and T. Chen, “Defectchecker:
    Automated smart contract defect detection by analyzing evm bytecode,” *IEEE Transactions
    on Software Engineering*, vol. 48, no. 7, p. 2189–2207, Jul. 2022.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] J. Chen, X. Xia, D. Lo, J. Grundy, X. Luo, 和 T. Chen, “Defectchecker：通过分析EVM字节码自动检测智能合约缺陷，”
    *IEEE软件工程学报*，第48卷，第7期，第2189–2207页，2022年7月。'
- en: '[7] L. Brent, A. Jurisevic, M. Kong, E. Liu, F. Gauthier, V. Gramoli, R. Holz,
    and B. Scholz, “Vandal: A scalable security analysis framework for smart contracts,”
    no. arXiv:1809.03981, Sep. 2018, arXiv:1809.03981 [cs]. [Online]. Available: [http://arxiv.org/abs/1809.03981](http://arxiv.org/abs/1809.03981)'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] L. Brent, A. Jurisevic, M. Kong, E. Liu, F. Gauthier, V. Gramoli, R. Holz,
    和 B. Scholz, “Vandal：一个可扩展的智能合约安全分析框架，” no. arXiv:1809.03981，2018年9月，arXiv:1809.03981
    [cs]。 [在线]. 可用: [http://arxiv.org/abs/1809.03981](http://arxiv.org/abs/1809.03981)'
- en: '[8] S. Kalra, S. Goel, M. Dhawan, and S. Sharma, “ZEUS: Analyzing safety of
    smart contracts,” in *Proc. ISOC NDSS*, 2018.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] S. Kalra, S. Goel, M. Dhawan, 和 S. Sharma, “ZEUS：智能合约的安全性分析，” 见于 *ISOC
    NDSS 会议论文集*，2018年。'
- en: '[9] P. Tsankov, A. Dan, D. Drachsler-Cohen, A. Gervais, F. Bünzli, and M. Vechev,
    “Securify: Practical security analysis of smart contracts,” in *Proc. ACM CCS*,
    2018.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] P. Tsankov, A. Dan, D. Drachsler-Cohen, A. Gervais, F. Bünzli, 和 M. Vechev,
    “Securify：智能合约的实用安全分析，” 见于 *ACM CCS 会议论文集*，2018年。'
- en: '[10] M. Mossberg, F. Manzano, E. Hennenfent, A. Groce, G. Grieco, J. Feist,
    T. Brunson, and A. Dinaburg, “Manticore: A user-friendly symbolic execution framework
    for binaries and smart contracts,” in *2019 34th IEEE/ACM International Conference
    on Automated Software Engineering (ASE)*, Nov. 2019, p. 1186–1189\. [Online].
    Available: [https://ieeexplore.ieee.org/document/8952204](https://ieeexplore.ieee.org/document/8952204)'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] M. Mossberg, F. Manzano, E. Hennenfent, A. Groce, G. Grieco, J. Feist,
    T. Brunson, 和 A. Dinaburg, “Manticore：一个用户友好的二进制和智能合约符号执行框架，” 见于 *2019年第34届 IEEE/ACM
    自动化软件工程国际会议（ASE）*，2019年11月，第1186–1189页。 [在线]. 可用: [https://ieeexplore.ieee.org/document/8952204](https://ieeexplore.ieee.org/document/8952204)'
- en: '[11] Defillama, “Defillama hacks,” 2024\. [Online]. Available: [https://defillama.com/hacks](https://defillama.com/hacks)'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Defillama, “Defillama 黑客事件，” 2024年。 [在线]. 可用: [https://defillama.com/hacks](https://defillama.com/hacks)'
- en: '[12] I. David, L. Zhou, K. Qin, D. Song, L. Cavallaro, and A. Gervais, “Do
    you still need a manual smart contract audit?” no. arXiv:2306.12338, Jun. 2023,
    arXiv:2306.12338 [cs]. [Online]. Available: [http://arxiv.org/abs/2306.12338](http://arxiv.org/abs/2306.12338)'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] I. David, L. Zhou, K. Qin, D. Song, L. Cavallaro, 和 A. Gervais, “你还需要手动智能合约审计吗？”
    no. arXiv:2306.12338，2023年6月，arXiv:2306.12338 [cs]。 [在线]. 可用: [http://arxiv.org/abs/2306.12338](http://arxiv.org/abs/2306.12338)'
- en: '[13] Y. Sun, D. Wu, Y. Xue, H. Liu, H. Wang, Z. Xu, X. Xie, and Y. Liu, “GPTScan:
    Detecting Logic Vulnerabilities in Smart Contracts by Combining GPT with Program
    Analysis,” in *Proceedings of the 46th IEEE/ACM International Conference on Software
    Engineering*, 2024.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Y. Sun, D. Wu, Y. Xue, H. Liu, H. Wang, Z. Xu, X. Xie, 和 Y. Liu, “GPTScan:
    通过将 GPT 与程序分析相结合检测智能合约中的逻辑漏洞，” 见于 *第46届 IEEE/ACM 国际软件工程大会论文集*，2024年。'
- en: '[14] S. Hu, T. Huang, F. Ilhan, S. Tekin, and L. Liu, “Large language model-powered
    smart contract vulnerability detection: New perspectives,” in *2023 5th IEEE International
    Conference on Trust, Privacy and Security in Intelligent Systems and Applications
    (TPS-ISA)*.   Los Alamitos, CA, USA: IEEE Computer Society, nov 2023, pp. 297–306\.
    [Online]. Available: [https://doi.ieeecomputersociety.org/10.1109/TPS-ISA58951.2023.00044](https://doi.ieeecomputersociety.org/10.1109/TPS-ISA58951.2023.00044)'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] S. Hu, T. Huang, F. Ilhan, S. Tekin, 和 L. Liu, “大语言模型驱动的智能合约漏洞检测：新视角，”
    见于 *2023年第五届 IEEE 智能系统与应用中的信任、隐私和安全国际会议（TPS-ISA）*。洛杉矶，加利福尼亚，美国：IEEE 计算机协会，2023年11月，第297–306页。
    [在线]. 可用: [https://doi.ieeecomputersociety.org/10.1109/TPS-ISA58951.2023.00044](https://doi.ieeecomputersociety.org/10.1109/TPS-ISA58951.2023.00044)'
- en: '[15] Y. Sun, D. Wu, Y. Xue, H. Liu, W. Ma, L. Zhang, M. Shi, and Y. Liu, “LLM4Vuln:
    A Unified Evaluation Framework for Decoupling and Enhancing LLMs’ Vulnerability
    Reasoning,” no. arXiv:2401.16185, Jan. 2024.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Y. Sun, D. Wu, Y. Xue, H. Liu, W. Ma, L. Zhang, M. Shi, 和 Y. Liu, “LLM4Vuln：一种用于解耦和增强
    LLM 漏洞推理的统一评估框架，” no. arXiv:2401.16185，2024年1月。'
- en: '[16] P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler,
    M. Lewis, W.-t. Yih, T. Rocktäschel, S. Riedel, and D. Kiela, “Retrieval-augmented
    generation for knowledge-intensive NLP tasks,” in *Proceedings of the 34th International
    Conference on Neural Information Processing Systems*, ser. NIPS’20.   Red Hook,
    NY, USA: Curran Associates Inc., Dec. 2020, pp. 9459–9474.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H.
    Küttler, M. Lewis, W.-t. Yih, T. Rocktäschel, S. Riedel, 和 D. Kiela, “增强检索生成用于知识密集型自然语言处理任务，”
    见于 *第34届国际神经信息处理系统会议论文集*，NIPS’20系列。纽约，纽约，美国：Curran Associates Inc.，2020年12月，第9459–9474页。'
- en: '[17] K. Tian, E. Mitchell, H. Yao, C. D. Manning, and C. Finn, “Fine-tuning
    Language Models for Factuality,” no. arXiv:2311.08401, Nov. 2023.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] K. Tian, E. Mitchell, H. Yao, C. D. Manning, 和 C. Finn, “对语言模型进行事实性微调，”
    no. arXiv:2311.08401，2023年11月。'
- en: '[18] K. Lv, Y. Yang, T. Liu, Q. Gao, Q. Guo, and X. Qiu, “Full Parameter Fine-tuning
    for Large Language Models with Limited Resources,” no. arXiv:2306.09782, Jun.
    2023.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] K. Lv, Y. Yang, T. Liu, Q. Gao, Q. Guo, 和 X. Qiu, “资源有限的大型语言模型的全参数微调，”
    无. arXiv:2306.09782, 2023年6月。'
- en: '[19] A. Balaguer, V. Benara, R. L. d. F. Cunha, R. d. M. E. Filho, T. Hendry,
    D. Holstein, J. Marsman, N. Mecklenburg, S. Malvar, L. O. Nunes, R. Padilha, M. Sharp,
    B. Silva, S. Sharma, V. Aski, and R. Chandra, “RAG vs Fine-tuning: Pipelines,
    Tradeoffs, and a Case Study on Agriculture,” no. arXiv:2401.08406, Jan. 2024.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] A. Balaguer, V. Benara, R. L. d. F. Cunha, R. d. M. E. Filho, T. Hendry,
    D. Holstein, J. Marsman, N. Mecklenburg, S. Malvar, L. O. Nunes, R. Padilha, M.
    Sharp, B. Silva, S. Sharma, V. Aski, 和 R. Chandra, “RAG vs 微调：管道、权衡及农业案例研究，” 无.
    arXiv:2401.08406, 2024年1月。'
- en: '[20] TrustLLM, “Trustllm inference code and dataset,” 2024\. [Online]. Available:
    [https://sites.google.com/view/trustllm/home](https://sites.google.com/view/trustllm/home)'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] TrustLLM, “Trustllm 推理代码和数据集，” 2024年。 [在线]. 可用: [https://sites.google.com/view/trustllm/home](https://sites.google.com/view/trustllm/home)'
- en: '[21] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” *Advances in neural
    information processing systems*, vol. 30, 2017.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    Ł. Kaiser, 和 I. Polosukhin, “注意力机制就是你所需的一切，” *神经信息处理系统进展*，第30卷，2017年。'
- en: '[22] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training
    of deep bidirectional transformers for language understanding,” in *Proceedings
    of the 2019 Conference of the North American Chapter of the Association for Computational
    Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)*, J. Burstein,
    C. Doran, and T. Solorio, Eds.   Minneapolis, Minnesota: Association for Computational
    Linguistics, Jun. 2019, p. 4171–4186\. [Online]. Available: [https://aclanthology.org/N19-1423](https://aclanthology.org/N19-1423)'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] J. Devlin, M.-W. Chang, K. Lee, 和 K. Toutanova, “Bert：用于语言理解的深度双向变换器预训练，”
    收录于 *2019年北美计算语言学协会会议：人类语言技术，第1卷（长短论文集）*，J. Burstein, C. Doran, 和 T. Solorio 编.
    明尼阿波利斯，明尼苏达州：计算语言学协会，2019年6月，第4171–4186页。 [在线]. 可用: [https://aclanthology.org/N19-1423](https://aclanthology.org/N19-1423)'
- en: '[23] Z. Feng, D. Guo, D. Tang, N. Duan, X. Feng, M. Gong, L. Shou, B. Qin,
    T. Liu, D. Jiang, and M. Zhou, “CodeBERT: A pre-trained model for programming
    and natural languages,” in *Findings of the Association for Computational Linguistics:
    EMNLP 2020*, T. Cohn, Y. He, and Y. Liu, Eds.   Online: Association for Computational
    Linguistics, Nov. 2020, pp. 1536–1547\. [Online]. Available: [https://aclanthology.org/2020.findings-emnlp.139](https://aclanthology.org/2020.findings-emnlp.139)'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] Z. Feng, D. Guo, D. Tang, N. Duan, X. Feng, M. Gong, L. Shou, B. Qin,
    T. Liu, D. Jiang, 和 M. Zhou, “CodeBERT：一种用于编程和自然语言的预训练模型，” 收录于 *计算语言学协会：EMNLP
    2020年会议论文集*，T. Cohn, Y. He, 和 Y. Liu 编. 在线：计算语言学协会，2020年11月，第1536–1547页。 [在线].
    可用: [https://aclanthology.org/2020.findings-emnlp.139](https://aclanthology.org/2020.findings-emnlp.139)'
- en: '[24] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever, “Language
    models are unsupervised multitask learners,” 2019.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, 和 I. Sutskever, “语言模型是无监督的多任务学习者，”
    2019年。'
- en: '[25] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan,
    P. Shyam, G. Sastry, A. Askell *et al.*, “Language models are few-shot learners,”
    *Advances in neural information processing systems*, vol. 33, pp. 1877–1901, 2020.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A.
    Neelakantan, P. Shyam, G. Sastry, A. Askell *等*，“语言模型是少样本学习者，” *神经信息处理系统进展*，第33卷，第1877–1901页，2020年。'
- en: '[26] M. Lewis, Y. Liu, N. Goyal, M. Ghazvininejad, A. Mohamed, O. Levy, V. Stoyanov,
    and L. Zettlemoyer, “Bart: Denoising sequence-to-sequence pre-training for natural
    language generation, translation, and comprehension,” no. arXiv:1910.13461, Oct.
    2019, arXiv:1910.13461 [cs, stat]. [Online]. Available: [http://arxiv.org/abs/1910.13461](http://arxiv.org/abs/1910.13461)'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] M. Lewis, Y. Liu, N. Goyal, M. Ghazvininejad, A. Mohamed, O. Levy, V.
    Stoyanov, 和 L. Zettlemoyer, “Bart：用于自然语言生成、翻译和理解的去噪序列到序列预训练，” 无. arXiv:1910.13461,
    2019年10月，arXiv:1910.13461 [cs, stat]. [在线]. 可用: [http://arxiv.org/abs/1910.13461](http://arxiv.org/abs/1910.13461)'
- en: '[27] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou,
    W. Li, and P. J. Liu, “Exploring the limits of transfer learning with a unified
    text-to-text transformer,” *J. Mach. Learn. Res.*, vol. 21, no. 1, jan 2020.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou,
    W. Li, 和 P. J. Liu, “探索统一文本到文本变换器的迁移学习极限，” *机器学习研究期刊*，第21卷，第1期，2020年1月。'
- en: '[28] Y. Wang, W. Wang, S. Joty, and S. C. Hoi, “Codet5: Identifier-aware unified
    pre-trained encoder-decoder models for code understanding and generation,” in
    *Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing*,
    2021, pp. 8696–8708.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] Y. Wang, W. Wang, S. Joty 和 S. C. Hoi, “Codet5: 识别符感知的统一预训练编码器-解码器模型用于代码理解和生成，”收录于
    *2021年自然语言处理经验方法大会论文集*，2021年，第8696–8708页。'
- en: '[29] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang *et al.*, “A survey of large
    language models,” no. arXiv:2303.18223, Nov. 2023, arXiv:2303.18223 [cs]. [Online].
    Available: [http://arxiv.org/abs/2303.18223](http://arxiv.org/abs/2303.18223)'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang *等*，“大规模语言模型综述，” no. arXiv:2303.18223，2023年11月，arXiv:2303.18223
    [cs]。[在线]. 可用： [http://arxiv.org/abs/2303.18223](http://arxiv.org/abs/2303.18223)'
- en: '[30] Y. Chang, X. Wang, J. Wang, Y. Wu, L. Yang, K. Zhu, H. Chen, X. Yi, C. Wang,
    Y. Wang, W. Ye, Y. Zhang, Y. Chang, P. S. Yu, Q. Yang, and X. Xie, “A survey on
    evaluation of large language models,” *ACM Trans. Intell. Syst. Technol.*, jan
    2024, just Accepted. [Online]. Available: [https://doi.org/10.1145/3641289](https://doi.org/10.1145/3641289)'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Y. Chang, X. Wang, J. Wang, Y. Wu, L. Yang, K. Zhu, H. Chen, X. Yi, C.
    Wang, Y. Wang, W. Ye, Y. Zhang, Y. Chang, P. S. Yu, Q. Yang 和 X. Xie, “大规模语言模型评估综述，”
    *ACM 智能系统技术杂志*，2024年1月，已接受。[在线]. 可用： [https://doi.org/10.1145/3641289](https://doi.org/10.1145/3641289)'
- en: '[31] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,
    S. Gray, A. Radford, J. Wu, and D. Amodei, “Scaling laws for neural language models,”
    no. arXiv:2001.08361, Jan. 2020, arXiv:2001.08361 [cs, stat]. [Online]. Available:
    [http://arxiv.org/abs/2001.08361](http://arxiv.org/abs/2001.08361)'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,
    S. Gray, A. Radford, J. Wu 和 D. Amodei, “神经语言模型的扩展定律，” no. arXiv:2001.08361，2020年1月，arXiv:2001.08361
    [cs, stat]。[在线]. 可用： [http://arxiv.org/abs/2001.08361](http://arxiv.org/abs/2001.08361)'
- en: '[32] Google, “Google gemini ai,” 2024\. [Online]. Available: [https://blog.google/technology/ai/google-gemini-ai](https://blog.google/technology/ai/google-gemini-ai)'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] Google, “Google Gemini AI，” 2024年。[在线]. 可用： [https://blog.google/technology/ai/google-gemini-ai](https://blog.google/technology/ai/google-gemini-ai)'
- en: '[33] H. Touvron, L. Martin, K. Stone *et al.*, “Llama 2: Open foundation and
    fine-tuned chat models,” no. arXiv:2307.09288, Jul. 2023, arXiv:2307.09288 [cs].'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] H. Touvron, L. Martin, K. Stone *等*，“Llama 2: 开放基础和微调聊天模型，” no. arXiv:2307.09288，2023年7月，arXiv:2307.09288
    [cs]。'
- en: '[34] L. Xu, H. Xie, S.-Z. J. Qin, X. Tao, and F. L. Wang, “Parameter-efficient
    fine-tuning methods for pretrained language models: A critical review and assessment,”
    no. arXiv:2312.12148, Dec. 2023, arXiv:2312.12148 [cs]. [Online]. Available: [http://arxiv.org/abs/2312.12148](http://arxiv.org/abs/2312.12148)'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] L. Xu, H. Xie, S.-Z. J. Qin, X. Tao, 和 F. L. Wang, “预训练语言模型的参数高效微调方法：一项关键性回顾与评估，”
    no. arXiv:2312.12148，2023年12月，arXiv:2312.12148 [cs]。[在线]. 可用： [http://arxiv.org/abs/2312.12148](http://arxiv.org/abs/2312.12148)'
- en: '[35] Z. Wan, X. Wang, C. Liu, S. Alam, Y. Zheng, J. Liu, Z. Qu, S. Yan, Y. Zhu,
    Q. Zhang, M. Chowdhury, and M. Zhang, “Efficient large language models: A survey,”
    no. arXiv:2312.03863, Jan. 2024, arXiv:2312.03863 [cs]. [Online]. Available: [http://arxiv.org/abs/2312.03863](http://arxiv.org/abs/2312.03863)'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] Z. Wan, X. Wang, C. Liu, S. Alam, Y. Zheng, J. Liu, Z. Qu, S. Yan, Y.
    Zhu, Q. Zhang, M. Chowdhury 和 M. Zhang, “高效的大规模语言模型：一项调查，” no. arXiv:2312.03863，2024年1月，arXiv:2312.03863
    [cs]。[在线]. 可用： [http://arxiv.org/abs/2312.03863](http://arxiv.org/abs/2312.03863)'
- en: '[36] Q. Dong, L. Li, D. Dai, C. Zheng, Z. Wu, B. Chang, X. Sun, J. Xu, L. Li,
    and Z. Sui, “A survey on in-context learning,” no. arXiv:2301.00234, Jun. 2023,
    arXiv:2301.00234 [cs]. [Online]. Available: [http://arxiv.org/abs/2301.00234](http://arxiv.org/abs/2301.00234)'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] Q. Dong, L. Li, D. Dai, C. Zheng, Z. Wu, B. Chang, X. Sun, J. Xu, L. Li
    和 Z. Sui, “上下文学习综述，” no. arXiv:2301.00234，2023年6月，arXiv:2301.00234 [cs]。[在线].
    可用： [http://arxiv.org/abs/2301.00234](http://arxiv.org/abs/2301.00234)'
- en: '[37] Z. Hu, L. Wang, Y. Lan, W. Xu, E.-P. Lim, L. Bing, X. Xu, S. Poria, and
    R. Lee, “LLM-adapters: An adapter family for parameter-efficient fine-tuning of
    large language models,” in *Proceedings of the 2023 Conference on Empirical Methods
    in Natural Language Processing*, H. Bouamor, J. Pino, and K. Bali, Eds.   Singapore:
    Association for Computational Linguistics, Dec. 2023, pp. 5254–5276\. [Online].
    Available: [https://aclanthology.org/2023.emnlp-main.319](https://aclanthology.org/2023.emnlp-main.319)'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] Z. Hu, L. Wang, Y. Lan, W. Xu, E.-P. Lim, L. Bing, X. Xu, S. Poria, 和
    R. Lee, “LLM-adapters: 一种用于大规模语言模型参数高效微调的适配器家族，”收录于 *2023年自然语言处理经验方法大会论文集*，H.
    Bouamor, J. Pino 和 K. Bali 主编。 新加坡：计算语言学协会，2023年12月，第5254–5276页。[在线]. 可用： [https://aclanthology.org/2023.emnlp-main.319](https://aclanthology.org/2023.emnlp-main.319)'
- en: '[38] W. Song, Z. Li, L. Zhang, H. Zhao, and B. Du, “Sparse is enough in fine-tuning
    pre-trained large language model,” no. arXiv:2312.11875, Dec. 2023, arXiv:2312.11875
    [cs]. [Online]. Available: [http://arxiv.org/abs/2312.11875](http://arxiv.org/abs/2312.11875)'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] W. Song, Z. Li, L. Zhang, H. Zhao, 和 B. Du，“在微调预训练大型语言模型时稀疏就足够了”，编号 arXiv:2312.11875，2023年12月，arXiv:2312.11875
    [cs]。[在线]。可用： [http://arxiv.org/abs/2312.11875](http://arxiv.org/abs/2312.11875)'
- en: '[39] E. J. Hu, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, W. Chen *et al.*,
    “Lora: Low-rank adaptation of large language models,” in *International Conference
    on Learning Representations*, 2021.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] E. J. Hu, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, W. Chen *等人*，“Lora：大型语言模型的低秩适配”，*国际学习表示会议*，2021年。'
- en: '[40] X. L. Li and P. Liang, “Prefix-tuning: Optimizing continuous prompts for
    generation,” in *Proceedings of the 59th Annual Meeting of the Association for
    Computational Linguistics and the 11th International Joint Conference on Natural
    Language Processing (Volume 1: Long Papers)*, 2021, pp. 4582–4597.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] X. L. Li 和 P. Liang，“前缀调优：优化生成的连续提示”，在*第59届计算语言学协会年会及第11届国际自然语言处理联合会议（第1卷：长篇论文）*中，2021年，第4582–4597页。'
- en: '[41] B. Lester, R. Al-Rfou, and N. Constant, “The power of scale for parameter-efficient
    prompt tuning,” in *Proceedings of the 2021 Conference on Empirical Methods in
    Natural Language Processing*, M.-F. Moens, X. Huang, L. Specia, and S. W.-t. Yih,
    Eds.   Online and Punta Cana, Dominican Republic: Association for Computational
    Linguistics, Nov. 2021, pp. 3045–3059\. [Online]. Available: [https://aclanthology.org/2021.emnlp-main.243](https://aclanthology.org/2021.emnlp-main.243)'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] B. Lester, R. Al-Rfou, 和 N. Constant，“参数高效的提示调优的规模效应”，在*2021年自然语言处理实证方法会议论文集*中，由
    M.-F. Moens, X. Huang, L. Specia, 和 S. W.-t. Yih 主编。线上和多米尼加共和国蓬塔卡纳：计算语言学协会，2021年11月，第3045–3059页。[在线]。可用：
    [https://aclanthology.org/2021.emnlp-main.243](https://aclanthology.org/2021.emnlp-main.243)'
- en: '[42] N. Mundra, S. Doddapaneni, R. Dabre, A. Kunchukuttan, R. Puduppully, and
    M. M. Khapra, “A comprehensive analysis of adapter efficiency,” in *Proceedings
    of the 7th Joint International Conference on Data Science & Management of Data
    (11th ACM IKDD CODS and 29th COMAD)*, 2024, pp. 136–154.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] N. Mundra, S. Doddapaneni, R. Dabre, A. Kunchukuttan, R. Puduppully, 和
    M. M. Khapra，“适配器效率的全面分析”，在*第7届数据科学与数据管理联合国际会议（第11届ACM IKDD CODS和第29届COMAD）*中，2024年，第136–154页。'
- en: '[43] A. Petrov, P. Torr, and A. Bibi, “When do prompting and prefix-tuning
    work? a theory of capabilities and limitations,” in *The Twelfth International
    Conference on Learning Representations*, 2024\. [Online]. Available: [https://openreview.net/forum?id=JewzobRhay](https://openreview.net/forum?id=JewzobRhay)'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] A. Petrov, P. Torr, 和 A. Bibi，“何时提示和前缀调优有效？能力和限制理论”，在*第十二届国际学习表示会议*中，2024年。[在线]。可用：
    [https://openreview.net/forum?id=JewzobRhay](https://openreview.net/forum?id=JewzobRhay)'
- en: '[44] D. A. Zetzsche, D. W. Arner, and R. P. Buckley, “Decentralized finance
    (defi),” *Journal of Financial Regulation*, vol. 6, pp. 172–203, 2020.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] D. A. Zetzsche, D. W. Arner, 和 R. P. Buckley，“去中心化金融（defi）”，*金融监管期刊*，第6卷，第172–203页，2020年。'
- en: '[45] Defillama, “Defillama chain,” 2024\. [Online]. Available: [https://defillama.com/chains](https://defillama.com/chains)'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] Defillama，“Defillama 链”，2024年。[在线]。可用： [https://defillama.com/chains](https://defillama.com/chains)'
- en: '[46] P. Praitheeshan, L. Pan, J. Yu, J. Liu, and R. Doss, “Security analysis
    methods on ethereum smart contract vulnerabilities: A survey,” no. arXiv:1908.08605,
    Sep. 2020, arXiv:1908.08605 [cs]. [Online]. Available: [http://arxiv.org/abs/1908.08605](http://arxiv.org/abs/1908.08605)'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] P. Praitheeshan, L. Pan, J. Yu, J. Liu, 和 R. Doss，“以太坊智能合约漏洞的安全分析方法：综述”，编号
    arXiv:1908.08605，2020年9月，arXiv:1908.08605 [cs]。[在线]。可用： [http://arxiv.org/abs/1908.08605](http://arxiv.org/abs/1908.08605)'
- en: '[47] P. Züst, T. Nadahalli, and Y. W. R. Wattenhofer, “Analyzing and preventing
    sandwich attacks in ethereum,” *ETH Zürich*, 2021.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] P. Züst, T. Nadahalli, 和 Y. W. R. Wattenhofer，“分析和防止以太坊中的三明治攻击”，*ETH Zürich*，2021年。'
- en: '[48] C. Zhou, J. He, X. Ma, T. Berg-Kirkpatrick, and G. Neubig, “Prompt consistency
    for zero-shot task generalization,” in *Findings of the Association for Computational
    Linguistics: EMNLP 2022*, Y. Goldberg, Z. Kozareva, and Y. Zhang, Eds.   Abu Dhabi,
    United Arab Emirates: Association for Computational Linguistics, Dec. 2022, pp.
    2613–2626\. [Online]. Available: [https://aclanthology.org/2022.findings-emnlp.192](https://aclanthology.org/2022.findings-emnlp.192)'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] C. Zhou, J. He, X. Ma, T. Berg-Kirkpatrick 和 G. Neubig，“零样本任务泛化的提示一致性”，发表于*计算语言学协会的发现:
    EMNLP 2022*，Y. Goldberg, Z. Kozareva 和 Y. Zhang 编辑。 阿布扎比，阿联酋: 计算语言学协会，2022年12月，第2613–2626页。
    [在线]. 可用: [https://aclanthology.org/2022.findings-emnlp.192](https://aclanthology.org/2022.findings-emnlp.192)'
- en: '[49] B. Rozière, J. Gehring, F. Gloeckle, S. Sootla *et al.*, “Code llama:
    Open foundation models for code,” no. arXiv:2308.12950, Jan. 2024, arXiv:2308.12950
    [cs]. [Online]. Available: [http://arxiv.org/abs/2308.12950](http://arxiv.org/abs/2308.12950)'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] B. Rozière, J. Gehring, F. Gloeckle, S. Sootla *等人*，“Code llama: 开放基础模型用于代码”，无.
    arXiv:2308.12950，2024年1月，arXiv:2308.12950 [cs]。 [在线]. 可用: [http://arxiv.org/abs/2308.12950](http://arxiv.org/abs/2308.12950)'
- en: '[50] R. Taori, I. Gulrajani, T. Zhang, Y. Dubois, X. Li, C. Guestrin, P. Liang,
    and T. B. Hashimoto, “Stanford alpaca: An instruction-following llama model,”
    [https://github.com/tatsu-lab/stanford_alpaca](https://github.com/tatsu-lab/stanford_alpaca),
    2023.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] R. Taori, I. Gulrajani, T. Zhang, Y. Dubois, X. Li, C. Guestrin, P. Liang
    和 T. B. Hashimoto，“斯坦福alpaca: 一种遵循指令的llama模型”， [https://github.com/tatsu-lab/stanford_alpaca](https://github.com/tatsu-lab/stanford_alpaca)，2023年。'
- en: '[51] T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and Y. Iwasawa, “Large language
    models are zero-shot reasoners,” *Advances in neural information processing systems*,
    vol. 35, pp. 22 199–22 213, 2022.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] T. Kojima, S. S. Gu, M. Reid, Y. Matsuo 和 Y. Iwasawa，“大型语言模型是零样本推理器”，*神经信息处理系统进展*，第35卷，第22,199–22,213页，2022年。'
- en: '[52] A. Q. Jiang, A. Sablayrolles, A. Roux, A. Mensch, and et al., “Mixtral
    of experts,” no. arXiv:2401.04088, Jan. 2024, arXiv:2401.04088 [cs]. [Online].
    Available: [http://arxiv.org/abs/2401.04088](http://arxiv.org/abs/2401.04088)'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] A. Q. Jiang, A. Sablayrolles, A. Roux, A. Mensch 等人，“Mixtral of experts”，无.
    arXiv:2401.04088，2024年1月，arXiv:2401.04088 [cs]。 [在线]. 可用: [http://arxiv.org/abs/2401.04088](http://arxiv.org/abs/2401.04088)'
- en: '[53] A. Q. Jiang, A. Sablayrolles, A. Mensch, and et al., “Mistral 7b,” no.
    arXiv:2310.06825, Oct. 2023, arXiv:2310.06825 [cs]. [Online]. Available: [http://arxiv.org/abs/2310.06825](http://arxiv.org/abs/2310.06825)'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] A. Q. Jiang, A. Sablayrolles, A. Mensch 等人，“Mistral 7b”，无. arXiv:2310.06825，2023年10月，arXiv:2310.06825
    [cs]。 [在线]. 可用: [http://arxiv.org/abs/2310.06825](http://arxiv.org/abs/2310.06825)'
- en: '[54] F. Xue, Z. Zheng, Y. Fu, J. Ni, Z. Zheng, W. Zhou, and Y. You, “Openmoe:
    An early effort on open mixture-of-experts language models,” no. arXiv:2402.01739,
    Jan. 2024, arXiv:2402.01739 [cs]. [Online]. Available: [http://arxiv.org/abs/2402.01739](http://arxiv.org/abs/2402.01739)'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] F. Xue, Z. Zheng, Y. Fu, J. Ni, Z. Zheng, W. Zhou 和 Y. You，“Openmoe: 对开放混合专家语言模型的早期尝试”，无.
    arXiv:2402.01739，2024年1月，arXiv:2402.01739 [cs]。 [在线]. 可用: [http://arxiv.org/abs/2402.01739](http://arxiv.org/abs/2402.01739)'
- en: '[55] Solodit, “Solodit,” 2024\. [Online]. Available: [https://solodit.xyz/](https://solodit.xyz/)'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] Solodit，“Solodit”，2024年。 [在线]. 可用: [https://solodit.xyz/](https://solodit.xyz/)'
- en: '[56] D. Guo, S. Ren, S. Lu, Z. Feng, D. Tang, L. Shujie, L. Zhou, N. Duan,
    A. Svyatkovskiy, S. Fu *et al.*, “Graphcodebert: Pre-training code representations
    with data flow,” in *International Conference on Learning Representations*, 2020.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] D. Guo, S. Ren, S. Lu, Z. Feng, D. Tang, L. Shujie, L. Zhou, N. Duan,
    A. Svyatkovskiy, S. Fu *等人*，“Graphcodebert: 使用数据流预训练代码表示”，发表于*国际学习表示大会*，2020年。'
- en: '[57] D. Guo, S. Lu, N. Duan, Y. Wang, M. Zhou, and J. Yin, “Unixcoder: Unified
    cross-modal pre-training for code representation,” in *Proceedings of the 60th
    Annual Meeting of the Association for Computational Linguistics (Volume 1: Long
    Papers)*, 2022, pp. 7212–7225.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] D. Guo, S. Lu, N. Duan, Y. Wang, M. Zhou 和 J. Yin，“Unixcoder: 统一跨模态预训练以进行代码表示”，发表于*第60届计算语言学协会年会（卷1:
    长篇论文）*，2022年，第7212–7225页。'
- en: '[58] Huggingface, “Huggingface transformer,” 2024\. [Online]. Available: [https://huggingface.co/docs/transformers/](https://huggingface.co/docs/transformers/)'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] Huggingface，“Huggingface transformer”，2024年。 [在线]. 可用: [https://huggingface.co/docs/transformers/](https://huggingface.co/docs/transformers/)'
- en: '[59] Y. Zhuang, Z. Liu, P. Qian, Q. Liu, X. Wang, and Q. He, “Smart Contract
    Vulnerability Detection using Graph Neural Network,” in *Twenty-Ninth International
    Joint Conference on Artificial Intelligence*, vol. 3, Jul. 2020, pp. 3283–3290.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] Y. Zhuang, Z. Liu, P. Qian, Q. Liu, X. Wang, 和 Q. He，“使用图神经网络检测智能合约漏洞”，发表于*第二十九届国际人工智能联合会议*，第3卷，2020年7月，第3283–3290页。'
- en: '[60] Z. Liu, P. Qian, X. Wang, L. Zhu, Q. He, and S. Ji, “Smart Contract Vulnerability
    Detection: From Pure Neural Network to Interpretable Graph Feature and Expert
    Pattern Fusion,” in *Twenty-Ninth International Joint Conference on Artificial
    Intelligence*, vol. 3, Aug. 2021, pp. 2751–2759.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] Z. Liu, P. Qian, X. Wang, L. Zhu, Q. He, 和 S. Ji, “智能合约漏洞检测：从纯神经网络到可解释的图特征和专家模式融合，”
    *第二十九届国际联合人工智能会议*，卷. 3, 2021年8月, 页码2751–2759。'
- en: '[61] H. Wu, Z. Zhang, S. Wang, Y. Lei, B. Lin, Y. Qin, H. Zhang, and X. Mao,
    “Peculiar: Smart Contract Vulnerability Detection Based on Crucial Data Flow Graph
    and Pre-training Techniques,” in *2021 IEEE 32nd International Symposium on Software
    Reliability Engineering (ISSRE)*, Oct. 2021, pp. 378–389.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] H. Wu, Z. Zhang, S. Wang, Y. Lei, B. Lin, Y. Qin, H. Zhang, 和 X. Mao,
    “Peculiar: 基于关键数据流图和预训练技术的智能合约漏洞检测，” *2021 IEEE第32届国际软件可靠性工程研讨会 (ISSRE)*, 2021年10月,
    页码378–389。'
- en: '[62] S. Ullah, M. Han, S. Pujar, H. Pearce, A. Coskun, and G. Stringhini, “Can
    Large Language Models Identify And Reason About Security Vulnerabilities? Not
    Yet,” no. arXiv:2312.12575, Dec. 2023.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] S. Ullah, M. Han, S. Pujar, H. Pearce, A. Coskun, 和 G. Stringhini, “大型语言模型能识别并推理安全漏洞吗？还不能，”
    no. arXiv:2312.12575, 2023年12月。'
- en: '[63] M. Fu, C. Tantithamthavorn, V. Nguyen, and T. Le, “ChatGPT for Vulnerability
    Detection, Classification, and Repair: How Far Are We?” no. arXiv:2310.09810,
    Oct. 2023.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] M. Fu, C. Tantithamthavorn, V. Nguyen, 和 T. Le, “ChatGPT在漏洞检测、分类和修复中的应用：我们还差多远？”
    no. arXiv:2310.09810, 2023年10月。'
- en: '[64] C. Thapa, S. I. Jang, M. E. Ahmed, S. Camtepe, J. Pieprzyk, and S. Nepal,
    “Transformer-Based Language Models for Software Vulnerability Detection,” in *Proceedings
    of the 38th Annual Computer Security Applications Conference*, ser. ACSAC ’22.   New
    York, NY, USA: Association for Computing Machinery, Dec. 2022, pp. 481–496.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] C. Thapa, S. I. Jang, M. E. Ahmed, S. Camtepe, J. Pieprzyk, 和 S. Nepal,
    “基于变换器的语言模型用于软件漏洞检测，” *第38届年度计算机安全应用会议论文集*，系列 ACSAC ’22。   纽约, NY, 美国: 计算机协会,
    2022年12月, 页码481–496。'
- en: '[65] M. Alqarni and A. Azim, “Low Level Source Code Vulnerability Detection
    Using Advanced BERT Language Model,” in *Proceedings of the Canadian Conference
    on Artificial Intelligence*.   Canadian Artificial Intelligence Association (CAIAC),
    May 2022.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] M. Alqarni 和 A. Azim, “使用先进的BERT语言模型进行低级源代码漏洞检测，” *加拿大人工智能会议论文集*。   加拿大人工智能协会
    (CAIAC), 2022年5月。'
- en: '[66] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “BERT: Pre-training
    of Deep Bidirectional Transformers for Language Understanding,” in *Proceedings
    of the 2019 Conference of the North American Chapter of the Association for Computational
    Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)*, J. Burstein,
    C. Doran, and T. Solorio, Eds.   Minneapolis, Minnesota: Association for Computational
    Linguistics, Jun. 2019, pp. 4171–4186.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] J. Devlin, M.-W. Chang, K. Lee, 和 K. Toutanova, “BERT：用于语言理解的深度双向变换器的预训练，”
    *2019年北美计算语言学协会会议论文集：人类语言技术，第1卷（长文和短文）*，J. Burstein, C. Doran, 和 T. Solorio, 编辑。   明尼阿波利斯,
    明尼苏达州: 计算语言学协会, 2019年6月, 页码4171–4186。'
- en: '[67] N. S. Mathews, Y. Brus, Y. Aafer, M. Nagappan, and S. McIntosh, “LLbezpeky:
    Leveraging Large Language Models for Vulnerability Detection,” no. arXiv:2401.01269,
    Feb. 2024.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] N. S. Mathews, Y. Brus, Y. Aafer, M. Nagappan, 和 S. McIntosh, “LLbezpeky：利用大型语言模型进行漏洞检测，”
    no. arXiv:2401.01269, 2024年2月。'
- en: '[68] M. D. Purba, A. Ghosh, B. J. Radford, and B. Chu, “Software Vulnerability
    Detection using Large Language Models,” in *2023 IEEE 34th International Symposium
    on Software Reliability Engineering Workshops (ISSREW)*.   IEEE Computer Society,
    Oct. 2023, pp. 112–119.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] M. D. Purba, A. Ghosh, B. J. Radford, 和 B. Chu, “使用大型语言模型进行软件漏洞检测，” *2023
    IEEE第34届国际软件可靠性工程研讨会 (ISSREW)*。   IEEE计算机协会, 2023年10月, 页码112–119。'
- en: '[69] H. Li, Y. Hao, Y. Zhai, and Z. Qian, “The Hitchhiker’s Guide to Program
    Analysis: A Journey with Large Language Models,” no. arXiv:2308.00245, Nov. 2023.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] H. Li, Y. Hao, Y. Zhai, 和 Z. Qian, “程序分析的指南：与大型语言模型的旅程，” no. arXiv:2308.00245,
    2023年11月。'
- en: '[70] G. Team, T. Mesnard, C. Hardin, R. Dadashi, S. Bhupatiraju, S. Pathak
    *et al.*, “Gemma: Open models based on gemini research and technology,” no. arXiv:2403.08295,
    Mar. 2024, arXiv:2403.08295 [cs]. [Online]. Available: [http://arxiv.org/abs/2403.08295](http://arxiv.org/abs/2403.08295)'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] G. Team, T. Mesnard, C. Hardin, R. Dadashi, S. Bhupatiraju, S. Pathak
    *等*, “Gemma: 基于双子研究和技术的开放模型，” no. arXiv:2403.08295, 2024年3月, arXiv:2403.08295
    [cs]. [在线]. 可用: [http://arxiv.org/abs/2403.08295](http://arxiv.org/abs/2403.08295)'
