- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 18:44:34'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:44:34
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM介导的领域特定语音代理：以TextileBot为例
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.10590](https://ar5iv.labs.arxiv.org/html/2406.10590)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2406.10590](https://ar5iv.labs.arxiv.org/html/2406.10590)
- en: Shu Zhong Department of Computer Science, University College London Elia Gatti
    Department of Computer Science, University College London James Hardwick Department
    of Computer Science, University College London Miriam Ribul Materials Science
    Research Centre, Royal College of Art Youngjun Cho Department of Computer Science,
    University College London Marianna Obrist Department of Computer Science, University
    College London
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Shu Zhong 计算机科学系，伦敦大学学院 Elia Gatti 计算机科学系，伦敦大学学院 James Hardwick 计算机科学系，伦敦大学学院
    Miriam Ribul 材料科学研究中心，皇家艺术学院 Youngjun Cho 计算机科学系，伦敦大学学院 Marianna Obrist 计算机科学系，伦敦大学学院
- en: Abstract
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Developing domain-specific conversational agents (CAs) has been challenged by
    the need for extensive domain-focused data. Recent advancements in Large Language
    Models (LLMs) make them a viable option as a knowledge backbone. LLMs behaviour
    can be enhanced through prompting, instructing them to perform downstream tasks
    in a zero-shot fashion (i.e. without training). To this end, we incorporated structural
    knowledge into prompts and used prompted LLMs to build domain-specific voice-based
    CAs. We demonstrate this approach for the specific domain of textile circularity
    in form of the design, development, and evaluation of TextileBot. We present the
    design and development of the voice agent TextileBot and also the insights from
    an in-person user study (N=30) evaluating three variations of TextileBots. We
    analyse the human-agent interactions, combining quantitative and qualitative methods.
    Our results suggest that participants engaged in multi-turn conversations, and
    their perceptions of the three variation agents and respective interactions varied
    demonstrating the effectiveness of our prompt-based LLM approach. We discuss the
    dynamics of these interactions and their implications for designing future voice-based
    CAs.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 开发领域特定的对话代理（CAs）面临着对大量领域专注数据的需求。最近在大型语言模型（LLMs）上的进展使其成为一个可行的知识支撑选择。通过提示可以增强LLMs的行为，指导它们以零样本的方式（即无需训练）执行下游任务。为此，我们将结构化知识融入提示中，并利用提示的LLMs构建领域特定的语音对话代理。我们展示了这一方法在纺织品循环利用领域的应用，包括设计、开发和评估TextileBot。我们介绍了语音代理TextileBot的设计和开发，并且提供了从一次面对面的用户研究（N=30）中获得的见解，评估了三种不同的TextileBots。我们分析了人机互动，结合了定量和定性方法。我们的结果表明，参与者参与了多轮对话，他们对三种不同语音代理及其互动的感知有所不同，展示了我们基于提示的LLM方法的有效性。我们讨论了这些互动的动态及其对未来语音对话代理设计的影响。
- en: The results show that our method’s potential for building domain-specific CAs.
    Furthermore, most participants engaged in multi-turn conversations, and their
    perceptions of the three voice agents and respective interactions varied demonstrating
    the effectiveness of our prompt-based LLM approach. We discuss the dynamics of
    these interactions and their implications for designing future voice-based CAs.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示了我们方法在构建领域特定CAs中的潜力。此外，大多数参与者进行了多轮对话，他们对三种语音代理及其互动的感知有所不同，展示了我们基于提示的LLM方法的有效性。我们讨论了这些互动的动态及其对未来语音对话代理设计的影响。
- en: 1 Introduction
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: The potential for designing conversational interfaces through the use of pre-trained
    large language models (LLMs) has gained substantial attention [[106](#bib.bib106),
    [48](#bib.bib48), [56](#bib.bib56)]. These LLMs possess remarkable capabilities
    to comprehend human language, generate text in a human-like way, and execute various
    tasks with only a few text *prompts* at run time, even without any additional
    training [[28](#bib.bib28), [64](#bib.bib64), [79](#bib.bib79), [14](#bib.bib14),
    [72](#bib.bib72)]. A prompt is a piece of text input to the LLM to elicit a response.
    For instance, a prompt can be *“What is sustainable fashion? Please explain it
    to a 10-year-old kid.”*. This has significantly lowered the entry barriers for
    artificial intelligence (AI) access, allowing non-experts to interact with LLMs
    through text. However, designing such prompts manually poses a particular challenge,
    as accurate and concise encapsulation of the complex, domain-specific knowledge
    is needed to guide the model towards a specific domain. This is due to the inherent
    task-agnostic nature of vanilla LLMs ¹¹1Vanilla model refers to an LLM without
    fine-tuning or prompting., which are not fine-tuned for specific domains. Additionally,
    another drawback of pre-trained vanilla LLMs is their lack of conversational memory,
    which restricts interactions to a ‘single turn’ manner²²2A one-time exchange between
    a user and an AI system or another person in a conversation counts as one turn..
    This limitation affects the continuity and depth of user interactions, as these
    models cannot recall their previous inputs and outputs.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用预训练的大型语言模型（LLMs）来设计对话界面的潜力已经引起了广泛关注[[106](#bib.bib106), [48](#bib.bib48),
    [56](#bib.bib56)]。这些LLMs具有显著的能力，能够理解人类语言、以类似人类的方式生成文本，并且仅通过几个文本*提示*就能执行各种任务，即使没有额外的训练[[28](#bib.bib28),
    [64](#bib.bib64), [79](#bib.bib79), [14](#bib.bib14), [72](#bib.bib72)]。提示是输入到LLM中的一段文本，用于引发回应。例如，一个提示可以是*“什么是可持续时尚？请向一个10岁的小孩解释一下。”*这显著降低了人工智能（AI）访问的入门门槛，使非专家可以通过文本与LLMs进行互动。然而，手动设计这些提示面临特定挑战，因为需要准确而简明地概括复杂的、领域特定的知识，以引导模型进入特定领域。这是由于普通LLMs的固有任务无关特性¹¹1普通模型指的是未经过微调或提示的LLM。，这些模型没有针对特定领域进行微调。此外，预训练普通LLMs的另一个缺点是缺乏对话记忆，这限制了互动为“单轮”方式²²2用户与AI系统或其他人之间的对话中一次交换称为一个轮次。这个限制影响了用户互动的连续性和深度，因为这些模型无法回忆之前的输入和输出。
- en: The human-computer interaction (HCI) community is seeing a rising emphasis on
    the development of voice-based conversational agents [[95](#bib.bib95), [9](#bib.bib9),
    [94](#bib.bib94), [40](#bib.bib40)]. Seaborn et al. found that only 13% of studies
    in voice-based human-agent interaction (vHAI) used an autonomous setup, fully
    controlled by participants [[84](#bib.bib84)]. This limited adoption is primarily
    due to the complexity of creating voice agents. The advent of LLMs now enables
    real-time conversational interactions with humans, eliminating the necessity for
    constructing intricate heuristic-based conversation rules from scratch. In addition,
    the development of domain-specific conversational agents has long been hindered
    by data scarcity [[7](#bib.bib7), [51](#bib.bib51)]. Collecting and annotating
    the data for these agents is an expensive and labour-intensive process that requires
    considerable resources [[27](#bib.bib27), [105](#bib.bib105), [37](#bib.bib37)].
    This has then necessitated exploring cost-effective approaches for developing
    domain-specific conversational agents. In essence, we are interested in how to
    efficiently combine the knowledge in general-purpose LLMs together with the structural
    domain knowledge from human experts.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 人机交互（HCI）社区正在越来越重视语音对话代理的开发[[95](#bib.bib95), [9](#bib.bib9), [94](#bib.bib94),
    [40](#bib.bib40)]。Seaborn等人发现，在语音基础的人机交互（vHAI）研究中，只有13%的研究使用了完全由参与者控制的自主设置[[84](#bib.bib84)]。这种有限的采用主要是由于创建语音代理的复杂性。LLMs的出现现在使得与人类进行实时对话互动成为可能，消除了从头构建复杂启发式对话规则的必要性。此外，领域特定对话代理的发展长期以来受到数据稀缺的阻碍[[7](#bib.bib7),
    [51](#bib.bib51)]。为这些代理收集和标注数据是一个昂贵且劳动密集的过程，需要大量资源[[27](#bib.bib27), [105](#bib.bib105),
    [37](#bib.bib37)]。这迫使我们探索开发领域特定对话代理的成本效益方法。实质上，我们关心的是如何高效地将通用LLMs中的知识与人类专家的结构化领域知识结合起来。
- en: 'To this end, we introduce an approach that uses LLMs in a zero-shot manner
    (i.e. without training), coupled with the knowledge from domain human experts.
    This approach also facilitates researchers, who may not be AI experts, in prototyping
    domain-specific conversational agents. We propose a novel three-phase method designed
    to transfer LLMs from task-agnostic to domain-specific voice-based CAs and offer
    personalized interactions. The first phase involves the creation of a Taxonomy-based
    Knowledge Structure Chain, a novel prompt generation method. We prompted LLMs
    as a knowledge foundation model instead of traditional method in building a dialogue
    system (see Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ LLM-Mediated Domain-Specific
    Voice Agents: The Case of TextileBot")). It eliminates the need for domain-specific
    data collection while allowing human experts to inject their structural knowledge
    into the LLM. The second phase involves a Prompt Refinement strategy that enables
    LLMs to interact with users with varying breadth and freedom, providing LLMs with
    different levels of domain-focusness and varying conversational styles. Finally,
    a System Optimization is introduced to facilitate LLMs engaging with users in
    continuous interactions, allowing the LLM to retain statefulness with memory,
    enabling long-last “multi-turn” conversations. Notably, these phases can be applied
    individually or in conjunction to boost CA’s design.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '为此，我们引入了一种利用LLMs以零-shot方式（即无需训练）结合领域人类专家知识的方法。这种方法也有助于那些可能不是AI专家的研究人员进行领域特定对话体的原型设计。我们提出了一种新颖的三阶段方法，旨在将LLMs从任务无关的状态转变为领域特定的语音对话体，并提供个性化互动。第一阶段涉及创建基于分类法的知识结构链，这是一种新颖的提示生成方法。我们将LLMs作为知识基础模型进行提示，而不是传统的对话系统构建方法（见图
    [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot")）。这消除了对领域特定数据收集的需求，同时允许专家将其结构化知识注入LLM。第二阶段涉及提示优化策略，使LLMs能够与具有不同广度和自由度的用户互动，提供不同层次的领域专注性和多样的对话风格。最后，引入了系统优化，以促进LLMs在持续互动中与用户交互，使LLM能够保留状态性并具有记忆，从而实现长期的“多轮”对话。值得注意的是，这些阶段可以单独应用或结合使用，以提升对话体的设计。'
- en: '![Refer to caption](img/6f0b5d45bd6f82b565238ab08d7024ce.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/6f0b5d45bd6f82b565238ab08d7024ce.png)'
- en: (a) Traditional
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 传统的
- en: '![Refer to caption](img/a2856a03daa3b05a64ddab0add89d65a.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/a2856a03daa3b05a64ddab0add89d65a.png)'
- en: (b) LLM-based
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 基于LLM的
- en: 'Figure 1: (a) Traditional and (b) LLM-based conversational agents with voice
    inputs and outputs. The traditional agent has various components such as NLU,
    NLG and Dialogue database searching. In contrast, the LLM-based agent simply uses
    the database to generate prompts for the LLM, enabling a much simpler and easy-to-develop
    pipeline.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：（a）传统的和（b）基于LLM的语音输入和输出对话体。传统对话体具有诸如NLU、NLG和对话数据库搜索等多个组件。相比之下，基于LLM的对话体仅使用数据库生成LLM提示，从而实现了更简单且易于开发的流程。
- en: 'To showcase our approach, we present TextileBot, a voice interface that conveys
    the topic of *textiles circularity* developed on a Raspberry Pi. We evaluate TextileBot’s
    effectiveness through a subjective user study, focusing on a human-in-the-loop
    strategy to foster human-centered AI design. Success will be measured by the participants’
    ability to discern the unique CA characteristics crafted through our approach
    and the system’s proficiency in maintaining domain-specific, multi-turn conversations.
    This evaluation integrates both quantitative data and qualitative insights. Additionally,
    we uncovered the complex dynamics of these human-agent interactions and explored
    various facets of human behaviour, engagement, and responses. Our research address
    two timely questions: First, while LLMs as foundation models for general-purpose
    conversational agents have been studied [[106](#bib.bib106), [48](#bib.bib48),
    [56](#bib.bib56)], their application in creating domain-specific voice agents
    is less understood. Second, there is limited understanding of how humans perceive
    and interact domain-specific voiced-based CAs powered by prompted LLMs. These
    knowledge gaps stem from various intertwined factors including the inherent complexity
    of natural languages, technical challenges associated with text-to-speech integration,
    the ability to handle ambiguity and context in human speech, and the imperative
    need for effective user experience design to facilitate seamless and meaningful
    user interactions with the system [[9](#bib.bib9), [84](#bib.bib84)]. In summary,
    the main contributions of this paper are three-fold:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为展示我们的方法，我们介绍了TextileBot，一个基于Raspberry Pi开发的语音接口，传达*纺织品循环性*的主题。我们通过主观用户研究评估TextileBot的有效性，重点关注一种人机交互的策略，以促进以人为本的人工智能设计。成功将通过参与者辨别我们方法所创造的独特CA特征的能力以及系统在维持特定领域的多轮对话中的表现来衡量。该评估结合了定量数据和定性见解。此外，我们揭示了这些人机互动的复杂动态，并探索了人类行为、参与度和反应的各个方面。我们的研究解决了两个当前问题：首先，虽然LLMs作为通用对话代理的基础模型已被研究[[106](#bib.bib106),
    [48](#bib.bib48), [56](#bib.bib56)]，但在创建特定领域语音代理中的应用理解较少。其次，对如何感知和互动基于提示LLMs的特定领域语音CA的了解有限。这些知识空白源于多种交织的因素，包括自然语言固有的复杂性、文本到语音集成的技术挑战、处理人类语言中的模糊性和上下文的能力，以及有效的用户体验设计以促进系统与用户的无缝和有意义的互动[[9](#bib.bib9),
    [84](#bib.bib84)]。总之，本文的主要贡献有三方面：
- en: •
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We develop a novel three-phase method that enables LLMs to transform from task-agnostic
    to domain-specific, adapting different conversational styles and incorporating
    memory for continues conversation. These phases can be used individually or in
    combination, depending on the task at hand.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们开发了一种新颖的三阶段方法，使大型语言模型（LLMs）能够从任务无关转变为特定领域，适应不同的对话风格并融入记忆以实现持续对话。这些阶段可以单独使用，也可以结合使用，具体取决于当前的任务。
- en: •
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We integrate the three-phase method into a design of a domain-specific voice-based
    device, i.e., TextileBot. This voice-based agent is custom-designed for the textile
    circularity domain, facilitating tailored conversations with consumers regarding
    circular economy practices within the textile industry.
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将三阶段方法整合到一个特定领域的基于语音的设备设计中，即TextileBot。这个语音代理是专门为纺织品循环性领域定制的，旨在促进与消费者关于纺织行业循环经济实践的量身定制的对话。
- en: •
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We evaluated three variations of TextileBot through in-person interactions to
    assess our approach’s effectiveness and to better understand user interactions.
    We analyzed these human-agent interactions, providing qualitative descriptions
    and quantitative insights. This analysis aims to inform potential design improvements
    in the wider domain of AI-enabled voice interfaces.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们通过面对面的互动评估了TextileBot的三种变体，以评估我们方法的有效性，并更好地理解用户互动。我们分析了这些人机互动，提供了定性描述和定量见解。此分析旨在为AI驱动的语音接口的更广泛领域的潜在设计改进提供信息。
- en: 2 Background and Related Work
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 背景和相关工作
- en: In this section, we explain our rationale for choosing textiles circularity
    as our applied domain. Following this, we give an overview of voice-based CAs
    and related literature focusing on human interaction with traditional heuristics-guided
    voice-based CAs. Subsequently, we introduce recent advancements in pre-trained
    LLMs and HCI research related to LLMs-mediated interfaces.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们解释了选择纺织品循环性作为应用领域的理由。接下来，我们概述了基于语音的对话代理及相关文献，重点关注与传统启发式指导的基于语音的对话代理的互动。随后，我们介绍了在预训练大语言模型和与大语言模型介导接口相关的HCI研究方面的最新进展。
- en: '2.1 The Domain of Textiles Circularity: A Case for Voice Agents Design'
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 纺织品循环性的领域：语音代理设计的案例
- en: We choose to develop a conversational agent specifically for the *textiles circularity*
    domain to demonstrate our method effectively. Textiles circularity is circular
    economy for textiles, and it refers to the sustainable practice in the textile
    industry where materials are reused, recycled, or biodegraded to minimize waste
    and reduce environmental impact [[31](#bib.bib31)]. This domain offers diverse
    information and expertise from various areas, including fashion, home textiles,
    supply chain management, materials science, and manufacturing etc. The complexity
    and diversity of conversations within this domain make it an ideal choice for
    showcasing the capabilities of our CA.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择开发一个专门针对*纺织品循环性*领域的对话代理，以有效展示我们的方法。纺织品循环性是纺织品的循环经济，指的是在纺织行业中，通过重新使用、回收或生物降解材料来最小化废物和减少环境影响的可持续实践[[31](#bib.bib31)]。该领域提供了来自时尚、家用纺织品、供应链管理、材料科学和制造等多个领域的多样信息和专业知识。这个领域内对话的复杂性和多样性使其成为展示我们对话代理能力的理想选择。
- en: Another main reason behind our focus on the textile industry is its significant
    contribution to global carbon emissions. In fact, the textile industry alone accounts
    for 10% of global carbon emissions, which is as much as the combined emissions
    from international flights and maritime shipping [[74](#bib.bib74)]. This alarming
    environmental impact highlights the urgent need for sustainable practices within
    the sector. The challenge of incorporating circularity, particularly in recycling
    of textile fibres into new textile fibres, is complex due to the broad spectrum
    of knowledge required. We anticipate that conversational agents, integrated with
    expert knowledge, will provide a more accessible mean of understanding and communicating
    the concept of textile circularity with the general public. We anticipate that
    this approach could also be adapted for educational purposes.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们关注纺织行业的另一个主要原因是其对全球碳排放的显著贡献。实际上，纺织行业单独占全球碳排放的10%，与国际航班和海运的总排放量相当[[74](#bib.bib74)]。这一令人担忧的环境影响突显了该行业对可持续实践的迫切需求。由于涉及到广泛的知识，纺织纤维回收成新纺织纤维的循环性挑战复杂。我们预计，结合专家知识的对话代理将提供一种更易于理解和沟通纺织品循环性概念的手段，也可以适应教育用途。
- en: Furthermore, CAs are increasingly being utilized in the fashion retail sector
    for a variety of purposes [[5](#bib.bib5), [10](#bib.bib10)], offering significant
    opportunities to foster socially responsible behaviours. Among these, promoting
    sustainability communication as an integral component of business strategies stands
    out as a notable application [[23](#bib.bib23)]. We believe that our approach
    can bring social and economic benefits to the textiles circularity domain. For
    example, the conversational agent could be situated in a store, offering valuable
    insights into how consumer clothing choices might affect their well-being and
    the environment.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，对话代理在时尚零售行业中的应用越来越广泛[[5](#bib.bib5), [10](#bib.bib10)]，提供了促进社会责任行为的重大机会。在这些应用中，推动可持续性沟通作为商业战略的一个重要组成部分尤为突出[[23](#bib.bib23)]。我们相信，我们的方法可以为纺织品循环性领域带来社会和经济效益。例如，对话代理可以设置在商店中，提供有关消费者服装选择如何影响他们的健康和环境的有价值见解。
- en: 2.2 Domain Specific Conversational Agents
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 领域特定对话代理
- en: Classic CAs typically comprise Natural Language Understanding (NLU) and Natural
    Language Generation (NLG) components, along with a database-driven dialogue management
    system [[5](#bib.bib5), [51](#bib.bib51)]. This dialogue system design can be
    broken down into various building blocks, namely dialogue database, dialogue searching
    and dialogue management. Building a dialogue system is a complex task requiring
    extensive domain knowledge and data. Alternatively, an end-to-end model can be
    trained using collected data, although this usually necessitates a large amount
    of training data to cover the different possible dialogues when deployed. In these
    approaches, the development of CAs is normally impeded by the lack of available
    data and the cost of annotating it [[65](#bib.bib65), [32](#bib.bib32), [7](#bib.bib7)].
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 经典对话代理通常包括自然语言理解（NLU）和自然语言生成（NLG）组件，以及一个基于数据库的对话管理系统 [[5](#bib.bib5), [51](#bib.bib51)]。这种对话系统设计可以拆分为多个构建块，即对话数据库、对话搜索和对话管理。构建一个对话系统是一项复杂的任务，需要广泛的领域知识和数据。另一种选择是使用收集的数据训练端到端模型，尽管这通常需要大量的训练数据，以覆盖不同的可能对话。在这些方法中，对话代理的发展通常受到可用数据缺乏和标注成本的阻碍
    [[65](#bib.bib65), [32](#bib.bib32), [7](#bib.bib7)]。
- en: 'This complexity can also hamper research in voice-based human-agent interaction
    (vHAI). While CA user interface is a popular topic in the HCI community, studies
    on domain focused CAs are relatively rare. Thus, this section focuses on a broader
    range of voice agents. Seaborn et al. [[84](#bib.bib84)] conducted a survey that
    identified four main methods for carrying out human voice interaction studies:
    autonomous setup, semi-autonomous setup, “Wizard of Oz” setup [[26](#bib.bib26)],
    and conversations under given scenarios - with respective usage rates of 13%,
    24%, 27%, and 33%. Notably, just 13% used an autonomous setup – a design where
    the system can operate without the involvement of an experimenter and the participants
    control the interactions. As mentioned earlier, creating fully automated CAs presents
    technical challenges (e.g. data scarcity and high monetary cost). These difficulties
    impede the comprehension of the human-agent interactions, thereby obstructing
    the design of effective autonomous CAs [[104](#bib.bib104), [106](#bib.bib106)].
    In addition, the evaluation of conversational agents is largely performed using
    crowdworkers [[51](#bib.bib51)]. These evaluations are also mostly conducted in
    non-goal-oriented conversations (a.k.a task-agnostic) [[92](#bib.bib92), [86](#bib.bib86)].
    In our work, we conducted an in-person study where participants directly controlled
    the voice agent interaction without mediation from experimenters. Moreover, our
    evaluation includes both non-goal-oriented tasks and goal-oriented tasks.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这种复杂性也可能阻碍基于语音的人机交互（vHAI）的研究。虽然对话代理用户界面在HCI社区中是一个热门话题，但对专注于特定领域的对话代理的研究相对较少。因此，本节关注于更广泛的语音代理。Seaborn
    等人 [[84](#bib.bib84)] 进行了一项调查，确定了四种主要的人声交互研究方法：自主设置、半自主设置、"奥兹魔法师"设置 [[26](#bib.bib26)]
    和给定场景下的对话 —— 各自的使用率为13%、24%、27% 和33%。值得注意的是，只有13%使用了自主设置 —— 这种设计下系统可以在没有实验者参与的情况下操作，参与者控制互动。如前所述，创建完全自动化的对话代理存在技术挑战（例如数据稀缺和高昂的费用）。这些困难妨碍了对人机交互的理解，从而阻碍了有效自主对话代理的设计
    [[104](#bib.bib104), [106](#bib.bib106)]。此外，对话代理的评估通常由众包工人完成 [[51](#bib.bib51)]。这些评估大多在非目标导向的对话中进行（即任务无关）
    [[92](#bib.bib92), [86](#bib.bib86)]。在我们的研究中，我们进行了面对面的研究，参与者直接控制语音代理的互动，没有实验者的介入。此外，我们的评估包括非目标导向任务和目标导向任务。
- en: 2.2.1 Voice-Based Human-Agent Interaction
  id: totrans-35
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.1 基于语音的人机交互
- en: This work presents an LLM-mediated voice agent specialized in textiles circularity,
    designed to operate via a device designed by ourselves. It’s important to note
    that this agent differs from conventional voice-based devices such as Alexa and
    Google Home, which are categorized as voice assistants (VAs). These voice assistants
    are not domain-specific in terms of their scope and functionality [[80](#bib.bib80),
    [84](#bib.bib84)], domain-specific agents focus on specific areas with detailed,
    context-aware responses, while VAs provide a wide array of services such as weather
    updates. Multiple studies suggest that voice assistants often fail to meet user
    expectations due to limited understanding or response [[24](#bib.bib24), [42](#bib.bib42),
    [9](#bib.bib9)].
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究介绍了一种通过我们自己设计的设备操作的、专注于纺织品循环利用的LLM中介语音代理。需要注意的是，这种代理与传统的语音设备如Alexa和Google
    Home不同，后者被归类为语音助手（VAs）。这些语音助手在其范围和功能上并不具有领域特定性[[80](#bib.bib80), [84](#bib.bib84)]，而领域特定的代理则专注于特定领域，提供详细的、具有上下文感知的回应，而VAs则提供诸如天气更新等各种服务。多项研究表明，由于理解或回应的局限性，语音助手往往未能满足用户期望[[24](#bib.bib24),
    [42](#bib.bib42), [9](#bib.bib9)]。
- en: Researchers have studied voiced-based human-agent interaction (vHAI) [[94](#bib.bib94),
    [58](#bib.bib58), [9](#bib.bib9), [95](#bib.bib95), [40](#bib.bib40)]. Some studies
    have explored factors that affected users’ preference between voice and text inputs
    [[94](#bib.bib94), [69](#bib.bib69)], while others discussed how user experience
    might be improved through enriching the personalities of the conversational agent
    [[96](#bib.bib96), [22](#bib.bib22), [12](#bib.bib12), [25](#bib.bib25)]. Hoegen
    et al. [[41](#bib.bib41)] found that voice agents that can conduct naturalistic
    multi-turn dialogue and are aligned with the participants’ conversational style
    will increase user trust. Baughan et al. [[9](#bib.bib9)] used interviews and
    surveys to understand how voice assistant failures impact user trust and willingness
    to rely on them for future tasks. Haas et al. discovered that users prefer voice
    assistants to “keep it short” in their responses [[38](#bib.bib38)]. Also, Völkel
    et al. [[95](#bib.bib95)] presented a rule-based dialogue design to give voice
    assistants distinct personalities and asked users to rate their preferences. They
    found that there is a connection between user personality traits and their voice
    assistant preferences. The voice-based agents used in these studies have primarily
    followed canonical approaches that are mostly in a “Wizard of Oz” manner, or are
    manipulated by human. However, our work stands out as the first endeavour to explore
    how humans interact with LLM-mediated voice agents and utilizes prompting techniques
    to design agents with distinct personas, response manners, and conversational
    freedom. We also offer novel insights into LLM-mediated voice agents’ design and
    interaction possibilities.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员研究了基于语音的人机交互（vHAI）[[94](#bib.bib94), [58](#bib.bib58), [9](#bib.bib9), [95](#bib.bib95),
    [40](#bib.bib40)]。一些研究探讨了影响用户在语音和文本输入之间选择的因素[[94](#bib.bib94), [69](#bib.bib69)]，而其他研究则讨论了通过丰富对话代理的个性来改善用户体验的方式[[96](#bib.bib96),
    [22](#bib.bib22), [12](#bib.bib12), [25](#bib.bib25)]。Hoegen等人[[41](#bib.bib41)]发现，能够进行自然多轮对话并与参与者的对话风格一致的语音代理将增加用户的信任。Baughan等人[[9](#bib.bib9)]通过访谈和调查了解了语音助手故障如何影响用户的信任和未来任务的依赖性。Haas等人发现用户更喜欢语音助手在回应中“简明扼要”[[38](#bib.bib38)]。此外，Völkel等人[[95](#bib.bib95)]提出了一种基于规则的对话设计，以赋予语音助手独特的个性，并要求用户对其偏好进行评分。他们发现用户的个性特征与其语音助手偏好之间存在联系。这些研究中使用的基于语音的代理主要遵循经典的方法，大多处于“奥兹巫师”的方式，或由人为操控。然而，我们的工作作为首个探索人类如何与LLM中介语音代理互动的尝试，利用了提示技术来设计具有独特个性、回应方式和对话自由度的代理。我们还提供了关于LLM中介语音代理设计和互动可能性的创新见解。
- en: 2.3 Large Language Models
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 大型语言模型
- en: Historically, NLP models have gone through a shift from a *fully supervised
    learning* paradigm, focusing on *feature engineering* (e.g. word identity [[52](#bib.bib52)])
    and *architecture engineering* (e.g. self-attention [[91](#bib.bib91)]), to a
    pre-train and fine-tune approach [[63](#bib.bib63)] with neural networks. Recently,
    the advent of pre-trained LLMs like GPT-3 has catalyzed a new *”pre-train and
    prompt”* paradigm [[72](#bib.bib72), [85](#bib.bib85), [63](#bib.bib63)].
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 历史上，自然语言处理（NLP）模型经历了从*完全监督学习*范式的转变，专注于*特征工程*（例如，单词身份 [[52](#bib.bib52)]）和*架构工程*（例如，自注意力
    [[91](#bib.bib91)]），到使用神经网络的预训练和微调方法 [[63](#bib.bib63)]。最近，像 GPT-3 这样的预训练 LLM
    的出现催化了新的*“预训练和提示”*范式 [[72](#bib.bib72), [85](#bib.bib85), [63](#bib.bib63)]。
- en: In the *pre-train and fine-tune* paradigm, fixed architecture models are trained
    with a large corpus of text data, typically several billion words or more, such
    as books, articles, or conversations, to learn general-purpose features of a language,
    e.g. BART [[57](#bib.bib57)] and UniLM [[29](#bib.bib29)]. The *pre-trained* LLMs
    can then be adapted (e.g. fine-tuned) to a broad range of downstream tasks (such
    as machine translation, text entailment, sentiment analysis, etc.) with a task-specific
    loss function. Large Language Models (LLMs), such as BERT (Bidirectional Encoder
    Representations from Transformers) [[28](#bib.bib28)], RoBERTa [[64](#bib.bib64)],
    T5 [[79](#bib.bib79)], and GPT-3 (Generative Pre-training Transformer 3) [[14](#bib.bib14)],
    are now used as *foundation models* ³³3A model trained on a large corpus of data
    that can be adapted to a wide range of downstream tasks [[13](#bib.bib13)]. for
    downstream tasks in NLP, paving the way toward task-agnostic machine learning
    [[13](#bib.bib13)].
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在*预训练和微调*范式中，固定架构的模型使用大量文本数据（通常是数十亿字或更多），例如书籍、文章或对话，进行训练，以学习语言的一般特征，例如 BART
    [[57](#bib.bib57)] 和 UniLM [[29](#bib.bib29)]。然后，可以将*预训练*的 LLM 适配（例如，微调）到各种下游任务（如机器翻译、文本蕴涵、情感分析等），使用特定任务的损失函数。大型语言模型（LLMs），如
    BERT（双向编码器表示来自 Transformers） [[28](#bib.bib28)]、RoBERTa [[64](#bib.bib64)]、T5
    [[79](#bib.bib79)] 和 GPT-3（生成预训练 Transformer 3） [[14](#bib.bib14)]，现在被用作*基础模型*
    ³³ 一个在大量数据语料库上训练的模型，可以适配到各种下游任务 [[13](#bib.bib13)]，为 NLP 的下游任务铺平了道路，迈向任务无关的机器学习
    [[13](#bib.bib13)]。
- en: LLMs have experienced significant breakthroughs recently in terms of their ability
    to understand and generate human-like text [[63](#bib.bib63)]. GPT-3 [[14](#bib.bib14)],
    with 175 billion parameters, stands out with its ability to execute various text-related
    tasks with only a few text *prompts* at run time, even without any additional
    training. This is known as the (*zero-shot*) capability, as its paper title *“Language
    Models are Few-Shot Learners”* suggests [[14](#bib.bib14)]. This capability highlights
    an evolution in model application, moving towards a *“pre-train and prompt”* paradigm
    [[72](#bib.bib72), [85](#bib.bib85), [63](#bib.bib63)]. Consequently, considerable
    effort has been invested in the research of *prompt engineering*, which aims to
    design efficient prompts to guide LLMs to perform various downstream tasks [[14](#bib.bib14),
    [85](#bib.bib85)]. For instance, prompts such as *“What is material fibre? Explain
    to a fashion designer.”* and *“What is material fibre? Explain to a chemist.”*
    will generate different outputs. This also implies a substantial step toward lowering
    the barriers for AI non-experts to interact with LLMs for various tasks by using
    only prompts [[45](#bib.bib45)].
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 最近在理解和生成类人文本的能力上取得了显著突破 [[63](#bib.bib63)]。GPT-3 [[14](#bib.bib14)]，拥有 1750
    亿个参数，以其仅需几个文本*提示*就能执行各种文本相关任务的能力而突出，即使没有任何额外训练。这被称为（*零样本*）能力，如其论文标题*“语言模型是少样本学习者”*所示
    [[14](#bib.bib14)]。这一能力突显了模型应用的演变，向*“预训练和提示”*范式 [[72](#bib.bib72), [85](#bib.bib85),
    [63](#bib.bib63)] 迈进。因此，已投入大量精力研究*提示工程*，旨在设计高效的提示以指导 LLM 执行各种下游任务 [[14](#bib.bib14),
    [85](#bib.bib85)]。例如，提示*“什么是材料纤维？给时尚设计师解释一下。”* 和*“什么是材料纤维？给化学家解释一下。”* 会生成不同的输出。这也意味着，通过仅使用提示，AI
    非专家与 LLM 进行各种任务交互的门槛显著降低 [[45](#bib.bib45)]。
- en: 2.3.1 Human-LLM Interaction
  id: totrans-42
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.1 人类-LLM 交互
- en: The rise of prompting LLMs presents a promising alternative for CA design [[106](#bib.bib106),
    [48](#bib.bib48), [56](#bib.bib56), [13](#bib.bib13)]. HCI researchers have been
    increasingly interested in harnessing the power of LLMs and enabling a plethora
    of language-based interactive applications. Examples of such applications include
    creative writing [[54](#bib.bib54), [21](#bib.bib21), [17](#bib.bib17), [43](#bib.bib43),
    [16](#bib.bib16)], iterative query reformulation (e.g., question answering) [[98](#bib.bib98),
    [4](#bib.bib4)], writing code [[90](#bib.bib90), [8](#bib.bib8)], and creating
    novel user interfaces [[98](#bib.bib98), [100](#bib.bib100)].
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 提示大型语言模型（LLMs）的兴起为CA设计提供了一种有前景的替代方案[[106](#bib.bib106), [48](#bib.bib48), [56](#bib.bib56),
    [13](#bib.bib13)]。人机交互（HCI）研究人员越来越关注利用LLMs的能力，并使大量基于语言的互动应用成为可能。这些应用的例子包括创意写作[[54](#bib.bib54),
    [21](#bib.bib21), [17](#bib.bib17), [43](#bib.bib43), [16](#bib.bib16)]，迭代查询改写（如问答）[[98](#bib.bib98),
    [4](#bib.bib4)]，编写代码[[90](#bib.bib90), [8](#bib.bib8)]，以及创建新颖的用户界面[[98](#bib.bib98),
    [100](#bib.bib100)]。
- en: However, most of the existing interaction frameworks focus on “single-turn”
    interaction, where a “turn” means one back-and-forth interaction on a specific
    topic; this can be either the user speaks, then the bot follows or vice-versa.
    In our work, we focus on a “multi-turn” and “continuous” interaction (dyadic),
    where the agent would need to react coherently and be able to memorise previous
    interaction rounds. One particular relevant literature to our work is from Zamfirescu-Pereira
    et al. [[106](#bib.bib106)]. They explored the use of prompting for fast CA design,
    specifically for text-based chatbots, and suggested that this method can achieve
    ”80%” of the user experience (UX) goal. However, the actual user perception and
    interactions with such CAs were not explored. In our work, we carefully designed
    our prompt templates and further carefully investigated the users’ perception
    and interaction using both qualitative and quantitative methods.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，大多数现有的互动框架关注于“单轮”互动，其中“轮次”指的是在特定主题上的一次往返互动；这可以是用户先发言，接着机器人回应，或反之。在我们的工作中，我们关注于“多轮”和“连续”互动（双向），其中代理需要连贯地反应，并能够记住之前的互动轮次。与我们工作特别相关的文献来自Zamfirescu-Pereira等人[[106](#bib.bib106)]。他们探讨了在快速CA设计中使用提示的方法，特别是针对基于文本的聊天机器人，并建议这种方法可以实现“80%”的用户体验（UX）目标。然而，实际用户对这种CA的感知和互动并未被探讨。在我们的工作中，我们仔细设计了提示模板，并进一步使用定性和定量方法仔细调查了用户的感知和互动。
- en: 'Currently, the performance of LLMs has been widely evaluated using numerical
    metrics without incorporating human participants [[72](#bib.bib72), [60](#bib.bib60),
    [14](#bib.bib14)]. For instance, metrics, such as perplexity and BLEU (bilingual
    evaluation understudy) score [[73](#bib.bib73)], are popular for evaluating LLMs
    performance on downstream tasks. These evaluations lack human-in-the-loop. To
    better understand the quality of human-LLM interactions, Lee et al. [[55](#bib.bib55)]
    proposed the Human-AI Language-based Interaction Evaluation (HALIE) framework,
    utilizing interaction traces, and suggested novel metrics related to user experience
    and interaction quality for assessing the LLM’s capabilities. In our design, we
    adopted several important metrics (including Ease, Change, Enjoyment, Reuse and
    Accuracy, fully described in Section [5.1](#S5.SS1 "5.1 Study design and methods
    ‣ 5 Evaluation of TextileBot ‣ LLM-Mediated Domain-Specific Voice Agents: The
    Case of TextileBot")) from Lee et al. to facilitate human-in-the-loop evaluation
    for our LLM-mediated voice agent.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '目前，LLMs的性能主要通过数值指标进行评估，而没有纳入人类参与者[[72](#bib.bib72), [60](#bib.bib60), [14](#bib.bib14)]。例如，困惑度和BLEU（双语评估补充）得分[[73](#bib.bib73)]等指标，在评估LLMs在下游任务中的表现时非常流行。这些评估缺乏人类参与。为了更好地理解人类与LLMs的互动质量，Lee等人[[55](#bib.bib55)]提出了基于人类-AI语言互动评估（HALIE）框架，利用互动痕迹，并建议了与用户体验和互动质量相关的新指标，以评估LLM的能力。在我们的设计中，我们采纳了Lee等人提出的几个重要指标（包括易用性、变化、享受、重用和准确性，在第[5.1节](#S5.SS1
    "5.1 Study design and methods ‣ 5 Evaluation of TextileBot ‣ LLM-Mediated Domain-Specific
    Voice Agents: The Case of TextileBot")中完全描述）来促进我们LLM介导的语音代理的人工评估。'
- en: 3 Prototyping Domain-Specific Voice Agents
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 领域特定语音代理的原型设计
- en: 'In this section, we present a zero-shot prototyping framework designed to enable
    a wider spectrum of users to prototype conversational agents (CAs) across various
    domains. Our novel method encompasses three distinct phases: (1) a Taxonomy-based
    Knowledge Structure Chain for effectively injecting domain knowledge, (2) a prompt
    refinement strategy *from task agnostic to domain specific*, and (3) a system
    optimization to equip LLMs with conversational memory enabling *continuous (multi-turn)*
    human-LLM interactions. Figure [1(b)](#S1.F1.sf2 "In Figure 1 ‣ 1 Introduction
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot") illustrates
    how our prompt-based LLM approach is different from the traditional conversational
    agent design. To demonstrate the practical application of this method, we present
    two implementations of our prompting approach within the context of textiles circularity,
    namely TextileBot-Expert and TextileBot-Assistant.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们展示了一个零-shot 原型框架，旨在使更多用户能够在不同领域原型对话代理（CAs）。我们新颖的方法包括三个不同阶段：（1）一个基于分类法的知识结构链，用于有效注入领域知识，（2）一个提示精炼策略*从任务无关到领域特定*，以及（3）一个系统优化，以使
    LLMs 具备对话记忆，实现*持续（多轮）*的人机互动。图 [1(b)](#S1.F1.sf2 "在图 1 ‣ 1 引言 ‣ LLM 介导的领域特定语音代理：以
    TextileBot 为例") 说明了我们基于提示的 LLM 方法与传统对话代理设计的不同。为了展示此方法的实际应用，我们在纺织品循环利用的背景下展示了我们提示方法的两个实现，即
    TextileBot-Expert 和 TextileBot-Assistant。
- en: '3.1 Phase 1: Taxonomy-based Knowledge Structure Chain'
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 阶段 1：基于分类法的知识结构链
- en: '![Refer to caption](img/3e8f3d03f071cc376948b5d83b5bf83c.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/3e8f3d03f071cc376948b5d83b5bf83c.png)'
- en: 'Figure 2: Taxonomy-Based Knowledge Structure Chain. This process requires domain-specific
    expertise to construct or utilize pre-existing structured knowledge frameworks,
    eg. taxonomies. To craft the Taxonomy-bind prompts, in every single prompt (eg.
    Prompt 1, 2, 3…) the entity types are connected by a relationship. In each prompt,
    we define the entity and hierarchical relationship to structure the knowledge,
    and finally, all prompts are chained together.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：基于分类法的知识结构链。这个过程需要领域特定的专业知识来构建或利用现有的结构化知识框架，例如分类法。为了制作基于分类法的提示，在每一个提示中（例如，提示
    1、2、3……）实体类型通过关系连接。在每个提示中，我们定义实体和层级关系来构建知识，最后将所有提示链在一起。
- en: A key challenge of using LLMs as foundation models is that they can return false
    answers in situations where they are unsure how to respond to a query from a user,
    producing both “plausible-sounding and incorrect or nonsensical answers” [[70](#bib.bib70)].
    We address this issue by introducing *Taxonomy-based Knowledge Structure Chain*,
    which is a framework for designing a chain of prompts. Typically, a prompt consists
    of two parts - a template and a set of label words [[19](#bib.bib19)]. Taxonomies,
    as relational systems, efficiently organize knowledge by logically interconnecting
    entities, representing relationships [[53](#bib.bib53)]. While prompting LLMs
    only rely on plain sentences, taxonomies excel in generating precise keywords,
    thereby enhancing the relevance and accuracy of LLM responses. This method organizes
    prompts to align with the taxonomy’s structure using label words, enhancing the
    relevance and accuracy of LLM responses.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 LLMs 作为基础模型的一个关键挑战是，它们在不确定如何回应用户查询的情况下，可能会返回错误答案，产生既“看似合理又不正确或荒谬的答案” [[70](#bib.bib70)]。我们通过引入*基于分类法的知识结构链*来解决这个问题，这是一种设计提示链的框架。通常，提示由两部分组成
    - 一个模板和一组标签词 [[19](#bib.bib19)]。分类法作为关系系统，通过逻辑上连接实体，表示关系，从而高效地组织知识 [[53](#bib.bib53)]。尽管提示
    LLMs 仅依赖普通句子，但分类法在生成精确关键词方面表现出色，从而提高了 LLM 响应的相关性和准确性。此方法通过使用标签词将提示组织与分类法的结构对齐，从而提高了
    LLM 响应的相关性和准确性。
- en: 'We exemplify this approach using the TextileNet taxonomy [[108](#bib.bib108)].
    TextileNet’s hierarchy captures the relationships between general textile fibre
    categories, their subcategories, and specific fibre types, aiding in the creation
    of a *knowledge prompt*. For example, “cotton fibre” falls under “plant fibres”,
    which is a subset of “natural fibres”. This hierarchical organization of the taxonomy
    forms the basis of our *Taxonomy-based Knowledge Structure Chain*, systematically
    capturing the relationship (eg. subcategories, macro-types) among different entity
    types as illustrated in Figure [2](#S3.F2 "Figure 2 ‣ 3.1 Phase 1: Taxonomy-based
    Knowledge Structure Chain ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot").'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '我们使用 TextileNet 分类法 [[108](#bib.bib108)] 来举例说明这种方法。TextileNet 的层级结构捕捉了一般纺织纤维类别、它们的子类别以及特定纤维类型之间的关系，帮助创建一个
    *知识提示*。例如，“棉纤维”属于“植物纤维”，这是“天然纤维”的一个子集。这种分类法的层级组织形成了我们的 *基于分类法的知识结构链*，系统地捕捉了不同实体类型之间的关系（例如子类别、宏观类型），如图
    [2](#S3.F2 "Figure 2 ‣ 3.1 Phase 1: Taxonomy-based Knowledge Structure Chain ‣
    3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot") 所示。'
- en: 'The dialogues in our user study demonstrate the effectiveness of this approach
    as illustrated in Figure [3](#S3.F3 "Figure 3 ‣ 3.2 Phase 2: From General to Domain
    Specific through Prompt Refinements ‣ 3 Prototyping Domain-Specific Voice Agents
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot"). Participants
    talked with three CAs: Vanilla GPT-3.5 model, TextileBot-Expert and TextileBot-Assistant.
    Both TextileBot-Expert and TextileBot-Assistant utilized a Taxonomy-based Knowledge
    Structure Chain, we discuss the main difference between them in Section [3.2](#S3.SS2
    "3.2 Phase 2: From General to Domain Specific through Prompt Refinements ‣ 3 Prototyping
    Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The
    Case of TextileBot"), but focus on how their domain expertise got improved.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '我们的用户研究对话展示了这种方法的有效性，如图 [3](#S3.F3 "Figure 3 ‣ 3.2 Phase 2: From General to
    Domain Specific through Prompt Refinements ‣ 3 Prototyping Domain-Specific Voice
    Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot") 所示。参与者与三种
    CAs 进行了对话：Vanilla GPT-3.5 模型、TextileBot-Expert 和 TextileBot-Assistant。TextileBot-Expert
    和 TextileBot-Assistant 都使用了基于分类法的知识结构链，我们在第 [3.2](#S3.SS2 "3.2 Phase 2: From General
    to Domain Specific through Prompt Refinements ‣ 3 Prototyping Domain-Specific
    Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")
    节中讨论了它们之间的主要区别，但重点关注它们的领域专业知识如何得到提升。'
- en: 'In Figure [3](#S3.F3 "Figure 3 ‣ 3.2 Phase 2: From General to Domain Specific
    through Prompt Refinements ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot"), “viscose” (a bio-derived
    fibre) was incorrectly categorized as a synthetic fibre and suggested as an unsustainable
    material by the Vanilla GPT-3.5 model. In contrast, our Taxonomy-bind approach,
    as shown through TextileBot Assistant and Expert, provides more accurate and contextually
    relevant information. For instance, TextileBot Expert accurately distinguishes
    between natural, synthetic, and regenerated fibres, demonstrating the LLM’s improved
    ability to recognize logical structures in taxonomy-based prompts. Our method
    significantly enhances the LLM’s capability to provide precise, consistent, and
    contextually relevant answers, particularly in the realms of fibres, textiles,
    and textile circularity.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '在图 [3](#S3.F3 "Figure 3 ‣ 3.2 Phase 2: From General to Domain Specific through
    Prompt Refinements ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot") 中，“粘胶纤维”（一种生物衍生纤维）被 Vanilla
    GPT-3.5 模型错误地归类为合成纤维，并建议其为不可持续的材料。相比之下，我们的基于分类法的方法，如 TextileBot Assistant 和 Expert
    所示，提供了更准确和上下文相关的信息。例如，TextileBot Expert 准确地区分了天然、合成和再生纤维，展示了 LLM 在基于分类法的提示中识别逻辑结构的能力提升。我们的方法显著提高了
    LLM 提供精准、一致且上下文相关答案的能力，特别是在纤维、纺织品和纺织循环性领域。'
- en: 'Taxonomy-based prompts provide “ground truth” when enhancing domain awareness
    for LLMs. This makes the entire conversation agent more robust when encountering
    errors from other components in the CA system pipeline, such as Automatic Speech
    Recognition (ASR). For instance, the term *‘viscous’* in Figure [3](#S3.F3 "Figure
    3 ‣ 3.2 Phase 2: From General to Domain Specific through Prompt Refinements ‣
    3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot") is a typical example of the errors that can arise
    from the ASR. By integrating taxonomy-based prompts within the CA pipeline, LLMs
    gain improved accuracy in understanding and responding to domain-specific content.
    This integration significantly mitigates ASR errors in conversation agents. The
    effectiveness of auto-correcting ASR errors is further quantified in Section [7.3.2](#S7.SS3.SSS2
    "7.3.2 Lessons Learned for design LLM-mediated voice agent ‣ 7.3 Optimizing LLM-mediated
    voice agent design for specific domains ‣ 7 Discussion & Future Directions ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot").'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 基于分类法的提示在增强大型语言模型（LLMs）的领域意识时提供了“基础真相”。这使得整个对话代理在遇到来自CA系统管道中其他组件的错误时变得更加稳健，例如自动语音识别（ASR）。例如，图[3](#S3.F3
    "图 3 ‣ 3.2 阶段 2：通过提示细化从一般到特定领域 ‣ 3 领域特定语音代理的原型 ‣ LLM介导的领域特定语音代理：以TextileBot为例")中的术语*‘viscous’*就是ASR可能出现错误的典型例子。通过在CA管道中集成基于分类法的提示，LLMs可以提高对领域特定内容的理解和响应准确性。这种集成显著减少了对话代理中的ASR错误。自动纠正ASR错误的有效性在第[7.3.2节](#S7.SS3.SSS2
    "7.3.2 针对LLM介导语音代理的设计经验教训 ‣ 7.3 针对特定领域优化LLM介导的语音代理设计 ‣ 7 讨论与未来方向 ‣ LLM介导的领域特定语音代理：以TextileBot为例")中有进一步量化。
- en: '3.2 Phase 2: From General to Domain Specific through Prompt Refinements'
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 阶段 2：通过提示细化从一般到特定领域
- en: '{dialogue} Setup Vanilla GPT-3.5 model Human Is viscose material sustainable?
    Agent Viscose is a type of synthetic fibre, and it is not considered sustainable.
    Instead, opt for natural fibres such as cotton, linen and hemp. Setup TextileBot
    Expert Human Hi, so I need to know what kind of textile materials are most selling?
    Agent Hello! That is an interesting question. It really depends on what type of
    textile you are looking for and what your application is. Generally speaking,
    some of the most popular material types are natural fibres like cotton, wool,
    and silk; synthetic fibres like polyester and nylon; and regenerated fibres such
    as viscose and cupro. Knowing the properties of each of these materials is important
    in order to find the best one for your application. However, you should also consider
    textile circularity in your selection process. Textile circularity is a concept
    that ensures a closed-loop life cycle for textiles, from fibre sourcing to manufacturing
    to end-of-life. This approach is important for creating a sustainable solution
    for the textiles industry. Setup TextileBot Assistant Human What is viscous? Agent
    Viscose is a type of regenerated cellulose fibre made from wood pulp or cotton
    linter. It is often used to make clothing, linens, bedding, towels and other fabrics
    that require a soft, silky handfeel.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '{对话} 设置香草GPT-3.5模型 人类 粘胶材料是否可持续？ 代理 粘胶是一种合成纤维，不被认为是可持续的。相反，选择如棉花、亚麻和麻等天然纤维。
    设置TextileBot专家 人类 你好，我想知道哪种纺织材料销售最火？ 代理 你好！这是个有趣的问题。实际上，这取决于你所寻找的纺织品类型以及你的应用需求。一般来说，一些最受欢迎的材料类型包括天然纤维如棉花、羊毛和丝绸；合成纤维如涤纶和尼龙；以及再生纤维如粘胶和铜氨纤维。了解每种材料的特性对于找到最适合你应用的材料非常重要。然而，你在选择过程中还应考虑纺织品的循环性。纺织品循环性是一个确保纺织品从纤维来源到生产再到使用寿命结束的闭环生命周期的概念。这种方法对于创建可持续的纺织行业解决方案至关重要。
    设置TextileBot助手 人类 粘胶是什么？ 代理 粘胶是一种由木浆或棉短绒制成的再生纤维素纤维。它通常用于制作需要柔软、丝滑手感的衣物、床单、被褥、毛巾和其他面料。'
- en: 'Figure 3: Three prompt-based LLM-mediated agents (Vanilla GPT-3.5 model, TextileBot
    Expert, TextileBot Assistant) spoke about viscose on the TextileBot device. We
    highlighted the incorrect content in red, demonstrating that the vanilla model
    was indeed error-prone. Both TextileBot Expert and Assistant utilize the TextileNet
    taxonomy-based prompts (as explained in Section [3.1](#S3.SS1 "3.1 Phase 1: Taxonomy-based
    Knowledge Structure Chain ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot")) to improve accuracy. TextileBot
    Expert replies in more detail and is generally considered to be more ‘obsessed’
    with this topic by our participants. We further explain this difference in Section
    [3.2](#S3.SS2 "3.2 Phase 2: From General to Domain Specific through Prompt Refinements
    ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot").'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '图 3：三个基于提示的 LLM 介导的代理（香草 GPT-3.5 模型、TextileBot 专家、TextileBot 助手）在 TextileBot
    设备上讨论了粘胶纤维。我们将不正确的内容用红色突出显示，表明香草模型确实存在错误。TextileBot 专家和助手都使用基于 TextileNet 分类法的提示（如第
    [3.1](#S3.SS1 "3.1 Phase 1: Taxonomy-based Knowledge Structure Chain ‣ 3 Prototyping
    Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The
    Case of TextileBot") 节中所述）来提高准确性。TextileBot 专家的回复更为详细，并且通常被我们的参与者认为对这个话题更加‘执着’。我们在第
    [3.2](#S3.SS2 "3.2 Phase 2: From General to Domain Specific through Prompt Refinements
    ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot") 节中进一步解释了这种差异。'
- en: '{dialogue} Setup Vanilla GPT-3.5 model Human So what would you recommend me
    to eat today because it’s almost lunchtime? Agent That depends on your dietary
    preferences. What kind of foods do you usually like to eat for lunch? Setup TextileBot
    Expert Human Well, I’m hungry. Um, what should I have for my lunch? Agent I’m
    sorry but I’m not the best person to help you with that. However, if you’re interested
    in learning more about textile and clothing materials, I’d be happy to help you!
    Setup TextileBot Assistant Human It’s almost lunchtime. What should I have for
    lunch today? Agent That sounds like an exciting decision! Are you looking for
    some textile-inspired lunch ideas? I know some great recipes for plant fiber-based
    noodles, vegan silk smoothies, and cottonseed salad bowls that are sure to satisfy
    your appetite!'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '{对话} 设置 香草 GPT-3.5 模型 人类 那你今天推荐我吃什么，因为快到午餐时间了？ 代理 这取决于你的饮食偏好。你通常喜欢吃什么类型的午餐？
    设置 TextileBot 专家 人类 嗯，我饿了。我该吃什么午餐呢？ 代理 对不起，我可能不是帮助你解决这个问题的最佳人选。不过，如果你有兴趣了解更多关于纺织品和服装材料的知识，我很乐意帮助你！
    设置 TextileBot 助手 人类 快到午餐时间了。我今天午餐该吃什么？ 代理 听起来这是个激动人心的决定！你是在寻找一些受纺织启发的午餐创意吗？我知道一些很棒的食谱，比如植物纤维面条、纯素丝绸奶昔和棉籽沙拉碗，这些一定能满足你的胃口！'
- en: 'Figure 4: Three prompt-based LLM-mediated agents on the topic of lunch (Vanilla
    GPT-3.5 model, TextileBot Expert, TextileBot Assistant).'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：关于午餐主题的三个基于提示的 LLM 介导的代理（香草 GPT-3.5 模型、TextileBot 专家、TextileBot 助手）。
- en: 'As the process of designing prompt templates is empirical, various ad-hoc prompt
    refinement techniques such as “Let’s think step by step” [[49](#bib.bib49)] have
    been employed in prompt design. However, there is yet no specific systematic approach
    for optimizing performance. To bridge this gap, we introduce a human-centred iterative
    prototyping process to personalize a desired CA. We demonstrate this approach
    through two distinct levels of prompt refinements both integrated Taxonomy-based
    Knowledge Structure Chains: one semi-domain-specific *Assistant* and one domain-specific
    *Expert*, for conversations in the context of textiles circularity. The process
    involves a series of prompt refinement steps:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 由于设计提示模板的过程是经验性的，因此在提示设计中采用了各种临时提示改进技术，例如“我们一步一步来”[[49](#bib.bib49)]。然而，目前尚无具体的系统方法来优化性能。为了填补这一空白，我们引入了一种以人为本的迭代原型设计过程，以个性化所需的
    CA。我们通过两个不同级别的提示改进演示了这种方法，这两个级别都整合了基于分类法的知识结构链：一个是半领域特定的*助手*，一个是领域特定的*专家*，用于纺织品循环性的对话。该过程包括一系列提示改进步骤：
- en: $\blacksquare$
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: $\blacksquare$
- en: '*Give the model an identity*: Start by giving the model a clear identity so
    it can identify its role and understand what kind of behaviour is expected of
    it. This helps to establish a consistent personality for the model’s responses.'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*赋予模型身份*：首先为模型赋予一个明确的身份，以便它能够确定自己的角色，并理解期望的行为。这有助于为模型的回应建立一致的个性。'
- en: $\blacksquare$
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: $\blacksquare$
- en: '*Tell the model how to behave*: Next, you can also instruct it on how to behave,
    for example, by telling it to be creative and helpful. These instructions help
    to further define the model’s personality with the desired tone.'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*告诉模型如何行为* ：接下来，你还可以指示它如何表现，例如，告诉它要富有创意和有帮助。这些指示有助于进一步定义模型的个性和期望的语气。'
- en: $\blacksquare$
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: $\blacksquare$
- en: '*“Let’s think step by step”* : Occasionally, GPTs fails on completing complex
    tasks [[3](#bib.bib3)]. To ensure the successful completion of the task, the model
    needs to be given clear instructions step-by-step to help it understand what is
    required. Break the complex tasks into simpler subtasks with a clear separation
    between each task. In addition, using the “Let’s think step by step” [[49](#bib.bib49)]
    trick in the prompt can help the model to think logically.'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*“一步一步来思考”* ：有时，GPT 在完成复杂任务时会失败 [[3](#bib.bib3)]。为了确保任务的成功完成，需要逐步给予模型明确的指示，帮助它理解要求。将复杂任务分解为更简单的子任务，并在每个任务之间保持清晰的分隔。此外，在提示中使用
    “一步一步来思考” [[49](#bib.bib49)] 的技巧可以帮助模型进行逻辑思考。'
- en: $\blacksquare$
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: $\blacksquare$
- en: '*Format the prompts*: Structure the prompt template format with delimiters
    and line breaks. This helps the model to disambiguate different sections and determine
    when the prompt ends and when it should start generating a response.'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*格式化提示* ：用分隔符和换行符结构化提示模板格式。这有助于模型区分不同的部分，并确定提示何时结束以及何时开始生成响应。'
- en: $\blacksquare$
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: $\blacksquare$
- en: '*Fine-tune prompts*: Fine-tune it with the desired behaviour the model needs
    to take. This involves using plain language and a positive tone to instruct the
    model on how to perform specific tasks. For example, we might instruct the model
    to “provide a sustainable clothing suggestion regardless of gender.”'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*微调提示* ：用模型需要采取的期望行为来微调它。这涉及使用简单的语言和积极的语气来指示模型如何执行特定任务。例如，我们可能会指示模型 “提供一个无论性别如何的可持续服装建议”。'
- en: 'These refinement techniques can be utilized individually or in combination,
    depending on the specific task. For a comprehensive demonstration of the strategy
    in practice, we provide a complete prompt template for Expert and Assistant, combining
    all these refinements, in the Appendix SectionLABEL:sec:apd:prompt, showcasing
    various combinations. Table [1](#S3.T1 "Table 1 ‣ 3.2 Phase 2: From General to
    Domain Specific through Prompt Refinements ‣ 3 Prototyping Domain-Specific Voice
    Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot") highlights
    the prompts used in the template.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '这些改进技术可以单独使用，也可以组合使用，具体取决于任务的要求。为了全面展示这些策略在实践中的应用，我们在附录 SectionLABEL:sec:apd:prompt
    提供了一个完整的专家与助手的提示模板，结合了所有这些改进，并展示了各种组合。表格 [1](#S3.T1 "Table 1 ‣ 3.2 Phase 2: From
    General to Domain Specific through Prompt Refinements ‣ 3 Prototyping Domain-Specific
    Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")
    突出了模板中使用的提示。'
- en: 'Table 1: Prompts used for three agents’ role and response manner. The conversational
    freedom is predefined as the design guideline for prompt template.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '表格 1: 三个代理角色及其响应方式的提示。对话自由度被预先定义为提示模板的设计指南。'
- en: '|  | Prompts used for characteristic | Response manner | Conversational freedom
    |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '|  | 特征提示 | 响应方式 | 对话自由度 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Vanilla | N/A | N/A | non-goal oriented |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| Vanilla | N/A | N/A | 非目标导向 |'
- en: '| Assistant |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 助手 |'
- en: '&#124; A helpful, creative, clever, and very friendly AI assistant, &#124;'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 一个有帮助、富有创意、聪明且非常友好的 AI 助手， &#124;'
- en: '&#124; specialized in textile circularity. &#124;'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 专注于纺织品循环性。 &#124;'
- en: '| Conscious in response | semi-domain-specific |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 反应时的意识 | 半领域特定 |'
- en: '| Expert |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 专家 |'
- en: '&#124; A textile circularity expert, response query around the concept of &#124;'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 纺织品循环性专家，围绕这一概念回应查询 &#124;'
- en: '&#124; textile circularity and guide the conversation towards textile circularity
    &#124;'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 纺织品循环性，并引导对话向纺织品循环性方向发展 &#124;'
- en: '| In a detailed manner | domain-specific |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 详细方式 | 领域特定 |'
- en: '*Expert* is designed to promote the idea of textile circularity and facilitate
    discussions on the topic. The Expert excels in providing detailed information
    on textiles and textile circularity, often including additional information. In
    Expert mode, as a domain-specific Ca, control the degree of freedom in the topic
    becomes the fundamental step. To achieve this, we *limit the conversation breadth
    of the model* by instructing it with the following prompt. We show the effectiveness
    of this in Appendix Section LABEL:sec:apd:prompt showing that participants failed
    to ”jail break” the prompt.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '*Expert*旨在推动纺织品循环的理念并促进相关讨论。Expert在提供纺织品及其循环的详细信息方面表现出色，通常会包括额外的信息。在Expert模式下，作为领域特定的Ca，控制话题的自由度成为基本步骤。为此，我们*限制模型的对话广度*，通过以下提示进行指导。我们在附录部分LABEL:sec:apd:prompt中展示了这一点的有效性，参与者未能“突破”提示。'
- en: On the other hand, *Assistant* is designed to engage in broader conversations
    and can act as an intermediary between non-goal-oriented conversation (task-agnostic)
    [[92](#bib.bib92)] and domain-specific conversation. We increase the breadth of
    topics and freedom of conversation in Assistant mode. For instance, the Assistant
    can provide suggestions on various scenarios such as dining or dressing, and even
    tell jokes without losing its focus on textiles.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，*Assistant*旨在进行更广泛的对话，并可以作为非目标导向对话（任务无关）[[92](#bib.bib92)]和领域特定对话之间的中介。在Assistant模式下，我们增加了话题的广度和对话的自由度。例如，Assistant可以在用餐或穿衣等各种场景下提供建议，甚至可以讲笑话，同时不失去对纺织品的关注。
- en: 'To better understand the distinctions between these agents, Figure [3](#S3.F3
    "Figure 3 ‣ 3.2 Phase 2: From General to Domain Specific through Prompt Refinements
    ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot") demonstrates how Expert is more “obsessed” with
    textile circularity compared to the Assistant. Figures [4](#S3.F4 "Figure 4 ‣
    3.2 Phase 2: From General to Domain Specific through Prompt Refinements ‣ 3 Prototyping
    Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The
    Case of TextileBot") provide an example from our user study, which shows different
    participants having real conversations regarding providing a lunch idea. The Vanilla
    model typically engages in free conversations in such cases, while the Expert
    refuses to engage unless it senses the topic is related to textiles. On the other
    hand, Assistant provides a textile-favoured lunch suggestion, thereby preserving
    the domain-specific feature while still allowing for open conversations. The Vanilla,
    Expert and Assistant agents show distinguishable response styles as follows:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '为了更好地理解这些代理之间的区别，图[3](#S3.F3 "Figure 3 ‣ 3.2 Phase 2: From General to Domain
    Specific through Prompt Refinements ‣ 3 Prototyping Domain-Specific Voice Agents
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")展示了Expert相比于Assistant在纺织品循环方面更为“执着”。图[4](#S3.F4
    "Figure 4 ‣ 3.2 Phase 2: From General to Domain Specific through Prompt Refinements
    ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot")提供了我们用户研究的一个示例，展示了不同参与者就提供午餐建议进行真实对话的情况。在这种情况下，Vanilla模型通常参与自由对话，而Expert则拒绝参与，除非它感知到话题与纺织品相关。另一方面，Assistant提供了一个偏向纺织品的午餐建议，从而保持了领域特定的特征，同时仍允许开放对话。Vanilla、Expert和Assistant代理展示了不同的响应风格，如下所示：'
- en: •
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Vanilla: This agent is non-goal-oriented and represents the pre-trained LLM
    in its original form. This showcases using LLMs directly as conversational agents
    without any prompts.'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'Vanilla: 该代理不以目标为导向，代表了原始形式的预训练LLM。这展示了直接将LLM用作对话代理的方式，而无需任何提示。'
- en: •
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Expert: Positioned as a goal-oriented (domain specific) voice agent, it embodies
    a domain expert, with a focus on specialized knowledge, but limited in making
    social conversations. The Expert excels in providing detailed explanations, often
    including additional information.'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'Expert: 被定位为以目标为导向（领域特定）的语音代理，体现了领域专家的角色，专注于专业知识，但在进行社交对话方面有限。Expert在提供详细解释方面表现出色，通常会包括额外的信息。'
- en: •
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Assistant: This agent is semi-goal-oriented, positioned as a helpful and friendly
    assistant that is able to conduct some degree of social conversation but still
    with goal in mind, conscious of the target domain when answering questions.'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'Assistant: 该代理是半目标导向的，被定位为一个友好的助手，能够进行一定程度的社交对话，但仍以目标为导向，在回答问题时意识到目标领域。'
- en: '3.3 Phase 3: Enable continuous LLM interaction with memory through System Optimization'
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 第三阶段：通过系统优化实现具有记忆的持续LLM互动
- en: '{dialogue} Human Which materials make the concept of textile circularity difficult
    to implement? agent Synthetic fibres and blended fabrics, … textile circularity
    difficult to implement. Human Repeat. agent The main challenges to the implementation
    of textile circularity include the lack of a clear regulatory framework, lack
    of investment and financial incentives, lack of understanding or awareness, and
    difficulty in measuring impacts. Human Please repeat my last question. agent Which
    materials make the concept of textile circularity difficult to implement? Human
    What was your last response? agent Synthetic fibres and blended fabrics, … textile
    circularity difficult to implement. Human Repeat your last response. agent Synthetic
    fibres and blended fabrics, … textile circularity difficult to implement.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '{对话} 人类：哪些材料使得纺织品循环概念难以实现？ 代理：合成纤维和混合面料……使得纺织品循环概念难以实现。 人类：重复一遍。 代理：实现纺织品循环的主要挑战包括缺乏明确的监管框架、缺乏投资和财务激励、缺乏理解或意识，以及难以衡量影响。
    人类：请重复我的最后一个问题。 代理：哪些材料使得纺织品循环概念难以实现？ 人类：你刚才的回答是什么？ 代理：合成纤维和混合面料……使得纺织品循环概念难以实现。
    人类：重复你的最后一个回答。 代理：合成纤维和混合面料……使得纺织品循环概念难以实现。'
- en: 'Figure 5: Transcript history for TextileBot Assistant. In Figure [3](#S3.F3
    "Figure 3 ‣ 3.2 Phase 2: From General to Domain Specific through Prompt Refinements
    ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot") and [4](#S3.F4 "Figure 4 ‣ 3.2 Phase 2: From
    General to Domain Specific through Prompt Refinements ‣ 3 Prototyping Domain-Specific
    Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot"),
    we both take the unmodified transcript history to demonstrate the agents’ capabilities.
    Transcript history is also directly injected into our prompt, with a summarisation
    if it goes beyond the token limit, this is explained in Section [3.3](#S3.SS3
    "3.3 Phase 3: Enable continuous LLM interaction with memory through System Optimization
    ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot"). This transcript demonstrates the agent’s statefulness
    in conversation, eg. its ability to recall and refer back to previously asked
    questions.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '图 5：TextileBot 助手的对话历史。在图 [3](#S3.F3 "Figure 3 ‣ 3.2 Phase 2: From General
    to Domain Specific through Prompt Refinements ‣ 3 Prototyping Domain-Specific
    Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")
    和 [4](#S3.F4 "Figure 4 ‣ 3.2 Phase 2: From General to Domain Specific through
    Prompt Refinements ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot") 中，我们都使用了未经修改的对话历史来展示代理的能力。对话历史也会直接注入到我们的提示中，如果超出令牌限制，会进行摘要，这在第
    [3.3](#S3.SS3 "3.3 Phase 3: Enable continuous LLM interaction with memory through
    System Optimization ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot") 节中进行了说明。这段对话展示了代理在对话中的状态性，例如它回忆和引用之前提问的能力。'
- en: Previous sections discussed how our prompt design helps the model identify its
    task. In this section, we first introduce some challenges using LLMs directly
    as CAs to conduct continuous conversation, and then provide corresponding System
    Optimization for these challenges.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的部分讨论了我们的提示设计如何帮助模型识别其任务。在本节中，我们首先介绍了直接使用大型语言模型（LLMs）作为对话代理进行持续对话的一些挑战，然后提供了针对这些挑战的系统优化方案。
- en: '1.'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: 'LLM capabilities depend on context: LLMs are sensitive to input prompts. Minor
    alterations to the prompt can result in significant differences in the model’s
    prediction [[63](#bib.bib63), [14](#bib.bib14)]. They may exhibit a preference
    for specific prompt formats, paraphrases, or particular information contained
    in the input [[6](#bib.bib6), [39](#bib.bib39)]. For instance, the *”Let’s think
    step by step”* trick [[49](#bib.bib49)] reveals that using particular prompts
    can largely level up model’s overall performance. Additionally, nouns and verbs
    tend to carry more weight than adjectives and function words [[103](#bib.bib103),
    [68](#bib.bib68)]. In short, the quality of response will be altered by the context.'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LLM的能力依赖于上下文：LLM对输入提示非常敏感。提示的微小变化可能会导致模型预测结果的显著差异[[63](#bib.bib63), [14](#bib.bib14)]。它们可能会对特定的提示格式、释义或输入中包含的特定信息表现出偏好[[6](#bib.bib6),
    [39](#bib.bib39)]。例如，*“一步步思考”*技巧[[49](#bib.bib49)]表明，使用特定的提示可以显著提升模型的整体表现。此外，名词和动词通常比形容词和功能词更具权重[[103](#bib.bib103),
    [68](#bib.bib68)]。简而言之，响应的质量将会受到上下文的影响。
- en: '2.'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: 'Transformer-based LLMs are memory-less: Transformer-based LLMs do not have
    an explicit memory of their previous outputs, including ChatGPT [[70](#bib.bib70)].'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于Transformer的LLM是无记忆的：基于Transformer的LLM没有对其先前输出的明确记忆，包括ChatGPT [[70](#bib.bib70)]。
- en: 'Although raw LLMs are usually memory-less, their ability to *learn in context*
    provides us with a way to enable them to remember previous conversations. This
    is done by *incorporating past human input and model output pairs* into the prompt
    in a clear format (as shown in Figure [6](#S4.F6 "Figure 6 ‣ 4 The Case of TextileBot:
    Design and Implementation ‣ LLM-Mediated Domain-Specific Voice Agents: The Case
    of TextileBot")) and allowing the model to use its capacity for learning in context
    to build a “Dialogue Memory” that is constantly updated with each interaction
    round between the human and the model. This ensures the model remains up-to-date
    with conversations, thus providing it with a form of memory that would otherwise
    not be possible. Interestingly, from the transcripts in Figure [5](#S3.F5 "Figure
    5 ‣ 3.3 Phase 3: Enable continuous LLM interaction with memory through System
    Optimization ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific
    Voice Agents: The Case of TextileBot"), we can observe that when using simple
    terms such as “repeat”, the model can repeat certain parts of the conversation;
    however, it requires *clear prompts* in order to understand what exactly should
    be repeated.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管原始LLM通常是无记忆的，但它们在*上下文中学习*的能力为我们提供了一种使其记住先前对话的方法。这是通过将*过去的人工输入和模型输出对*以清晰的格式纳入提示中（如图
    [6](#S4.F6 "图 6 ‣ 4 TextileBot的案例：设计与实施 ‣ LLM介导的领域特定语音代理：TextileBot的案例")）来实现的，并允许模型利用其在上下文中学习的能力建立一个“对话记忆”，该记忆会随着人类和模型之间每次交互轮次的更新而不断更新。这确保了模型与对话保持同步，从而提供了本来不可能实现的记忆形式。有趣的是，从图
    [5](#S3.F5 "图 5 ‣ 3.3 第三阶段：通过系统优化实现具有记忆的连续LLM交互 ‣ 3 领域特定语音代理的原型设计 ‣ LLM介导的领域特定语音代理：TextileBot的案例")
    的转录中，我们可以观察到，当使用“重复”等简单术语时，模型可以重复对话的某些部分；然而，它需要*明确的提示*才能理解具体应该重复什么。
- en: 'Since the transcript history is constantly being updated, the issue of the
    token limit arises, which can lead to a system crash if we exceed this limit.
    To tackle this, System Optimization have used a token counter to keep track of
    the total token count in our prompt. Once the overall text length reaches almost
    $3000$ characters), we use the text-davinci-003 model as a summarizer (Figure
    [5](#S3.F5 "Figure 5 ‣ 3.3 Phase 3: Enable continuous LLM interaction with memory
    through System Optimization ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot")) to summarize transcripts
    between the user and the model. The summarized text is then combined with other
    more recent dialogues to make up the Dialogue Memory, this memory is pure text
    and is then added to the initial CA prompt that we have generated from Phase 1
    and 2, in this way, we enable multi-turn interaction to continue.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 由于转录历史不断更新，令牌限制的问题随之出现，如果超出此限制可能会导致系统崩溃。为了解决这个问题，系统优化使用了令牌计数器来跟踪我们提示中的总令牌数量。一旦整体文本长度接近$3000$字符，我们就使用text-davinci-003模型作为总结器（见图
    [5](#S3.F5 "图 5 ‣ 3.3 第三阶段：通过系统优化实现具有记忆的连续LLM交互 ‣ 3 领域特定语音代理的原型设计 ‣ LLM介导的领域特定语音代理：TextileBot的案例")）对用户与模型之间的对话进行总结。总结后的文本然后与其他更近期的对话结合，形成对话记忆，这些记忆是纯文本形式，并与我们从第1阶段和第2阶段生成的初始CA提示一起添加，这样我们就可以继续进行多轮交互。
- en: '4 The Case of TextileBot: Design and Implementation'
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 《TextileBot的案例：设计与实施》
- en: '![Refer to caption](img/da5e79ac954050c201621b231eb11b9f.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/da5e79ac954050c201621b231eb11b9f.png)'
- en: 'Figure 6: System optimization (phase 3) with integrated memory. This optimization
    includes a token counter for monitoring the dialogue length. Once the token limit
    is reached, an automatic summarizer is triggered to condense the past dialogue.
    The CA prompt is pre-set always at the start, where these past-dialogue are inserted
    after it, to maintain the CA’s functionality.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：集成记忆的系统优化（第三阶段）。该优化包括用于监控对话长度的令牌计数器。一旦达到令牌限制，自动总结器将被触发以浓缩过去的对话。CA提示始终在开始时预设，这些过去的对话在其之后插入，以保持CA的功能。
- en: 'In this section, we provide our prompt-based conversational voice agents’ software
    and hardware designs. Notably, our system design exhibits great adaptability.
    The design building blocks (illustrated in Figure [7](#S4.F7 "Figure 7 ‣ 4.1 Software
    System Design - Multi-Model Stitching ‣ 4 The Case of TextileBot: Design and Implementation
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")) can be
    seamlessly integrated with various platforms and input/output methods. These include
    smart devices, smartphones, computers, VR interfaces, and diverse user input/output
    methods. The TextileBot voice interface, featured in this study, serves as an
    exemplary implementation of our domain-specific prompt-based voice agent approach
    within the context of textile circularity. We built a device with a voice interface
    for several reasons. Firstly, in line with the current textile circularity agenda,
    a key objective is to raise consumers’ awareness and engagement with this concept
    [[75](#bib.bib75), [83](#bib.bib83)]. Utilizing physical artifacts to enhance
    user engagement has been a significant pursuit in human-agent interaction [[69](#bib.bib69)],
    and our TextileBot aims to facilitate consumer engagement in retail settings,
    we regard a real device with voice-based interactions as pivotal in our approach.
    Secondly, it is well-established that people employ distinct language styles when
    speaking compared to writing, as articulated in the literature [[81](#bib.bib81)].
    To our knowledge, no prior research has delved into natural spoken dialogue with
    LLMs, leaving a substantial gap in understanding how humans perceive and interact
    with prompt LLM-based voice agents. Finally, a voice interface can create better
    accessibility for users.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们提供了基于提示的对话语音助手的软件和硬件设计。值得注意的是，我们的系统设计表现出很好的适应性。设计的构建模块（如图[7](#S4.F7
    "Figure 7 ‣ 4.1 Software System Design - Multi-Model Stitching ‣ 4 The Case of
    TextileBot: Design and Implementation ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot")所示）可以与各种平台和输入/输出方法无缝集成。这些包括智能设备、智能手机、计算机、VR界面和多种用户输入/输出方法。本文中展示的TextileBot语音接口，作为我们领域特定的基于提示的语音助手方法的一个典型实现，专注于纺织品循环利用的背景。我们构建了一个带有语音接口的设备有几个原因。首先，符合当前纺织品循环利用的议程，一个关键目标是提升消费者对这一概念的认知和参与[[75](#bib.bib75)、[83](#bib.bib83)]。利用实物增强用户参与感一直是人机交互中的一个重要追求[[69](#bib.bib69)]，我们的TextileBot旨在促进零售环境中的消费者参与，我们认为一个具有语音互动的真实设备在我们的方法中是至关重要的。其次，文献中指出，人们在说话时使用的语言风格与写作时有所不同[[81](#bib.bib81)]。据我们了解，目前尚无研究探讨与LLMs的自然语言对话，这留下了一个关于人类如何感知和与基于提示的LLM语音助手互动的重大空白。最后，语音接口可以为用户提供更好的可访问性。'
- en: 4.1 Software System Design - Multi-Model Stitching
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 软件系统设计 - 多模型融合
- en: 'The TextileBot software system stitches together three models - an Automated
    Speech Recognition (ASR) model, a Large language model (LLM) and a Text-to-Speech
    (TTS) model. We explain each of them in detail in the following subsections, and
    an overview of this system is in Figure [7](#S4.F7 "Figure 7 ‣ 4.1 Software System
    Design - Multi-Model Stitching ‣ 4 The Case of TextileBot: Design and Implementation
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot").'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 'TextileBot软件系统将三个模型融合在一起——一个自动语音识别（ASR）模型，一个大型语言模型（LLM）和一个文本到语音（TTS）模型。我们将在以下子节中详细解释每个模型，系统的概述见图[7](#S4.F7
    "Figure 7 ‣ 4.1 Software System Design - Multi-Model Stitching ‣ 4 The Case of
    TextileBot: Design and Implementation ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot")。'
- en: '![Refer to caption](img/71d3f7aeb5ed3895a2ec3461a560aa54.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/71d3f7aeb5ed3895a2ec3461a560aa54.png)'
- en: 'Figure 7: Software System Design for TextileBot - Multi-Model Stitching. For
    the complete CA design, we utilized an ASR model, a LLM and a TTS model. It is
    worth mentioning that our ASR model is Whisper, deep learning based ASR model.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：TextileBot的软件系统设计 - 多模型融合。为了完整的CA设计，我们使用了ASR模型、LLM和TTS模型。值得一提的是，我们的ASR模型是Whisper，一种基于深度学习的ASR模型。
- en: 4.1.1 Automatic Speech Recognition (ASR)
  id: totrans-112
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.1 自动语音识别（ASR）
- en: We tested two speech recognition models, Google speech-to-text and OpenAI’s
    Whisper [[78](#bib.bib78)] Application Programming Interface (API), in our TextileBot
    design. Initially, we used Google’s API, which is popular, but we experienced
    unexpected latency issues on our Raspberry Pi device due to heavy preprocessing
    on recorded audio files. To evaluate latency, we randomly sampled recording lengths
    between $1$ seconds on these samples. In a pilot study with four participants
    (including one native English speaker), two non-native English speakers, we found
    that participants had to speak slowly and repeat their words when using Google
    ASR.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在我们的TextileBot设计中测试了两个语音识别模型：Google语音转文本和OpenAI的Whisper [[78](#bib.bib78)]
    应用程序编程接口（API）。最初，我们使用了Google的API，这是一款受欢迎的工具，但由于录音文件的预处理繁重，我们在Raspberry Pi设备上遇到了意外的延迟问题。为了评估延迟，我们对这些样本的录音长度进行了随机采样，长度在$1$秒之间。在一项包含一位母语英语使用者和两位非母语英语使用者的四人试点研究中，我们发现参与者在使用Google
    ASR时必须说得慢一些，并且需要重复他们的话。
- en: We chose OpenAI’s Whisper as our ASR due to its faster latency and robustness
    in recognition [[77](#bib.bib77)]. While we did not conduct a thorough accuracy
    comparison study between the two APIs, and to our knowledge, no related literature
    compares them as Whisper was officially released in March 2023, we observed that
    Whisper recognized most non-native English-speaking participants significantly
    better. Conversely, with Google speech-to-text ASR, key terms in our dialogue
    such as ”textile circularity” were consistently recognized as ”textile security”
    or even ”Texas a Coronavirus”.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了OpenAI的Whisper作为我们的自动语音识别（ASR），因为它在识别中的延迟更快且更具鲁棒性 [[77](#bib.bib77)]。虽然我们没有对这两个API进行彻底的准确性比较研究，并且据我们所知，没有相关文献比较它们，因为Whisper是在2023年3月正式发布的，但我们观察到Whisper对大多数非母语英语参与者的识别显著更好。相对而言，使用Google语音转文本ASR时，我们对话中的关键术语如“textile
    circularity”经常被识别为“textile security”或甚至“Texas a Coronavirus”。
- en: 4.1.2 Language model as foundation model
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.2 语言模型作为基础模型
- en: In our study, we chose GPT-3.5 (text-davinci-003) API which was known for its
    outstanding performance and trained with the largest parameters at the time of
    testing. Currently, there is a lot of discussion within the community about the
    differences between OpenAI’s GPT models, including GPT-3, GPT-3.5, ChatGPT, and
    the newly released GPT-4. Our work focuses on the pre-trained OpenAI GPT model⁴⁴4OpenAI’s
    GPT-3 is a pre-trained LLM with 175 billion parameters [[14](#bib.bib14)] rather
    than any other published sources or third-party models trained from scratch. One
    drawback of LLMs is the generation of plausible-sounding but incorrect or nonsensical
    responses [[70](#bib.bib70)]. To address this issue, LLMs like InstructGPT and
    ChatGPT have incorporated human efforts using Reinforcement Learning from Human
    Feedback (RLHF), resulting in fewer false responses and less toxicity [[72](#bib.bib72)].
    Although ChatGPT’s advanced language processing capabilities allow it to engage
    in natural, human-like conversations with users, it has a tendency to be verbose
    due to biases in the training data. Trainers in the RLHF prefer longer answers
    that appear more comprehensive [[87](#bib.bib87), [34](#bib.bib34)].
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的研究中，我们选择了以其卓越性能著称并且在测试时拥有最大参数的GPT-3.5（text-davinci-003）API。目前，社区内对OpenAI的GPT模型之间的差异，包括GPT-3、GPT-3.5、ChatGPT以及新发布的GPT-4，讨论颇多。我们的工作集中在预训练的OpenAI
    GPT模型⁴⁴4OpenAI的GPT-3是一个具有1750亿参数的预训练LLM [[14](#bib.bib14)]，而非任何其他已发布的来源或从头训练的第三方模型。LLM的一个缺点是生成看似合理但不正确或无意义的回应
    [[70](#bib.bib70)]。为了应对这个问题，像InstructGPT和ChatGPT这样的LLM已经结合了人类的努力，通过人类反馈强化学习（RLHF）来减少错误回应和降低毒性
    [[72](#bib.bib72)]。尽管ChatGPT的高级语言处理能力使其能够与用户进行自然且类似人类的对话，但由于训练数据中的偏差，它往往倾向于冗长。RLHF的训练者更喜欢看起来更全面的长答案
    [[87](#bib.bib87), [34](#bib.bib34)]。
- en: We cannot determine the parameters used in the RLHF for ChatGPT, limiting our
    freedom in using these LLMs. Furthermore, the long-text style response of ChatGPT
    is unsuitable for voice interfaces. In contrast, GPT-3 and GPT-3.5 are more “organic”
    and provide more freedom in designing arbitrary prompts, making them useful for
    customizable content generation and language translation. Therefore, we focus
    on exploiting these large foundation models directly, such as GPT-3.5, for controlled,
    high-quality content generation instead of using the patched ChatGPT.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们无法确定 ChatGPT 的 RLHF 使用的参数，这限制了我们使用这些 LLM 的自由。此外，ChatGPT 的长文本风格响应不适合语音接口。相比之下，GPT-3
    和 GPT-3.5 更加“自然”，在设计任意提示时提供了更多自由，使其在定制内容生成和语言翻译方面更有用。因此，我们专注于直接利用这些大型基础模型，如 GPT-3.5，以实现受控的高质量内容生成，而不是使用修补过的
    ChatGPT。
- en: At the time of writing this paper, OpenAI had just announced GPT-4 - an enhanced
    language model with improved mathematical abilities and the capacity to take visual
    inputs. However, it can be difficult to distinguish GPT-3.5 from GPT-4 in a casual
    conversation, as noted on GPT-4’s website. Interestingly, OpenAI has also reported
    that there is almost no improvement in generating factual content when questions
    related to environmental science are posed [[71](#bib.bib71)]. In this paper,
    our focus is on designing a domain-specific conversation agent related to textile
    circularity, a key topic in material and environmental science.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，OpenAI 刚刚宣布了 GPT-4 —— 一个增强的语言模型，具有改进的数学能力和处理视觉输入的能力。然而，正如 GPT-4 的网站上所指出的那样，在随意对话中区分
    GPT-3.5 和 GPT-4 可能很困难。有趣的是，OpenAI 还报告称，当提出与环境科学相关的问题时，生成事实内容几乎没有改进 [[71](#bib.bib71)]。在本文中，我们的重点是设计一个与纺织品循环性相关的领域特定对话代理，这是材料和环境科学中的一个关键话题。
- en: 4.1.3 Text-to-speech
  id: totrans-119
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.3 语音合成
- en: 'We use the gTTS (Google Text-to-Speech) library in Python to read out text
    with a female British English voice. However, we received feedback during the
    pilot study that the speech speed felt slow for natural conversation. To address
    this issue, we will discuss our solution in Section [4.2](#S4.SS2 "4.2 Hardware
    System Design: The TextileBot Voice Device ‣ 4 The Case of TextileBot: Design
    and Implementation ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot").'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 Python 中使用 gTTS（Google 语音合成）库来以女性英国英语的声音朗读文本。然而，在试点研究期间，我们收到反馈，认为语音速度在自然对话中显得较慢。为了解决这个问题，我们将在第
    [4.2](#S4.SS2 "4.2 硬件系统设计：TextileBot 语音设备 ‣ 4 TextileBot 案例：设计与实施 ‣ LLM 媒介领域特定语音代理：TextileBot
    案例") 节讨论我们的解决方案。
- en: '4.2 Hardware System Design: The TextileBot Voice Device'
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 硬件系统设计：TextileBot 语音设备
- en: '![Refer to caption](img/4b13287d7fdabbf80b633206b65230fa.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4b13287d7fdabbf80b633206b65230fa.png)'
- en: (a) The physical TextileBot interface.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 物理 TextileBot 界面。
- en: '![Refer to caption](img/bbcf22b6460d37a88e5f13f9a679968c.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/bbcf22b6460d37a88e5f13f9a679968c.png)'
- en: (b) A participant interacts with the TextileBot.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 一位参与者与 TextileBot 互动。
- en: 'Figure 8: Left: TextileBot - The physical agent interface is composed of a
    3D printed box (6), a speaker (5), a microphone (4), and a button (3), all integrated
    into the Google AIY board (2) mounted on the Raspberry Pi 3 Model B (1) presented
    in (a). Right: A participant interacting with the TextileBot used across all three
    voice-based agents (b).'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：左：TextileBot - 物理代理接口由一个 3D 打印的盒子（6）、一个扬声器（5）、一个麦克风（4）和一个按钮（3）组成，全部集成到装在
    Raspberry Pi 3 Model B（1）上的 Google AIY 板（2）中，如（a）所示。右：一个参与者与在所有三个语音代理中使用的 TextileBot
    互动（b）。
- en: 'We built the hardware device around a Raspberry Pi device. The device is housed
    in a 3D printed box (6), which includes a speaker (5), a microphone (4), and a
    button (3), all integrated on the AIY board (2) mounted on the Raspberry Pi 3B
    (1) as shown in Figure [8(a)](#S4.F8.sf1 "In Figure 8 ‣ 4.2 Hardware System Design:
    The TextileBot Voice Device ‣ 4 The Case of TextileBot: Design and Implementation
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot"). The hardware
    system includes a Raspberry Pi 3B with a Quad Core 1.2GHz Broadcom BCM2837 64bit
    CPU and 1GB RAM (1). We use the Voice HAT configuration [[1](#bib.bib1)], which
    contains a Voice AIY accessory board (2) that provides physical connectivity from
    the GPIO pins and is mounted on the Raspberry Pi 3 board. The Voice HAT set also
    provides us with an arcade-style button with an LED light (3), a microphone board
    with the 5-wire daughter board cable (4) and a microphone (5).'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们围绕一个 Raspberry Pi 设备构建了硬件装置。该设备装在一个 3D 打印的盒子里（6），盒子包括一个扬声器（5）、一个麦克风（4）和一个按钮（3），这些都集成在安装在
    Raspberry Pi 3B（1）上的 AIY 板（2）中，如图 [8(a)](#S4.F8.sf1 "图 8 ‣ 4.2 硬件系统设计：TextileBot
    语音设备 ‣ 4 TextileBot 案例：设计与实现 ‣ LLM 媒介的领域特定语音代理：TextileBot 案例") 所示。硬件系统包括一个配备 Quad
    Core 1.2GHz Broadcom BCM2837 64 位 CPU 和 1GB RAM 的 Raspberry Pi 3B（1）。我们使用了 Voice
    HAT 配置 [[1](#bib.bib1)]，其中包含一个 Voice AIY 附件板（2），提供来自 GPIO 引脚的物理连接，并安装在 Raspberry
    Pi 3 板上。Voice HAT 套件还为我们提供了一个带 LED 灯的街机风格按钮（3）、一个带有 5 根线的麦克风板（4）和一个麦克风（5）。
- en: The housing was created from an open source CAD model in the Thingiverse model
    library. It was 3D printed on a Prusa I3 MK3S+ using the readily available polylactic
    acid (PLA) material. The front facing side contains holes to allow sound from
    the speaker to leave the enclosure, while the inside contains various shelves
    for the control electronics to be mounted to. The top of the box has a hole for
    the activation button. The firmware to control this hardware was designed by Google
    and deeply integrated with the Google Assistant service ⁵⁵5The Google AIY has
    stopped updating their service, and the repository has been archived by the owner
    on Feb 9, 2023 [[2](#bib.bib2)]. [[2](#bib.bib2), [35](#bib.bib35)]. However,
    this did not meet our needs, so we conducted the development of our own firmware
    code that enables flexible audio recording, audio playback and push button control.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 外壳是从 Thingiverse 模型库中的开源 CAD 模型创建的。它使用现成的聚乳酸（PLA）材料在 Prusa I3 MK3S+ 上进行 3D 打印。前面朝向的侧面有孔，以便扬声器的声音可以离开外壳，而内部则包含各种架子用于安装控制电子设备。盒子的顶部有一个用于激活按钮的孔。控制该硬件的固件由
    Google 设计，并与 Google Assistant 服务深度集成 ⁵⁵5Google AIY 已停止更新其服务，且仓库已于 2023 年 2 月 9
    日由所有者存档 [[2](#bib.bib2)]。[[2](#bib.bib2), [35](#bib.bib35)]。然而，这并未满足我们的需求，因此我们开发了自己的固件代码，实现灵活的音频录制、音频播放和按钮控制。
- en: Users interface with TextileBot via a button with an LED light. A predefined
    user guide is played when the device is booted. To speak to the TextileBot, users
    press and then release the button, and do it again when they finish their sentence.
    The LED light will be lit while recording and playing audio. We use mpg123 library
    with command “mpg123 -d 4 -h 3” to manually speed up the playback rate to $1.33\times$.
    This is because participants in our pilot studies have reported the original speaking
    speed from gTTS is too slow.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 用户通过带 LED 灯的按钮与 TextileBot 进行交互。设备启动时播放预定义的用户指南。要与 TextileBot 对话，用户按下并释放按钮，然后在完成句子后再按一次。LED
    灯在录音和播放音频时会亮起。我们使用 mpg123 库和命令 “mpg123 -d 4 -h 3” 手动加快播放速率至 $1.33\times$。这是因为我们试点研究中的参与者报告说，gTTS
    的原始讲话速度太慢。
- en: 5 Evaluation of TextileBot
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 TextileBot 的评估
- en: In the user study, we aimed (1) to evaluate whether our prompt strategy remained
    effective while preserving domain specificity across various spoken dialogues,
    and to assess if interactions with three variations of TextileBot differed significantly—indicating
    that users perceived each as a distinct entity and validating phase 2 of our approach,
    (2) to investigate if TextileBot could retain memory and conduct continuous conversations
    as designed in phase 3, and (3) to explore the nature of user interactions with
    each bot variant to understand the nuances of user engagement. As the language
    used in spoken dialogue is different from written text [[81](#bib.bib81)], an
    in-person study was chosen to allow participants to interact with the TextileBot
    smart device and evoke natural language conversations. We used a mixed-method
    approach, combining traditional machine learning ablation study analysis with
    HIC analysis - questionnaires and qualitative feedback from participants with
    a conversational analysis of the human-agent dialogue. We recruited a total of
    30 participants to interact with each of the three voice agents on textiles and
    textile circularity, as outlined in the Introduction. In the following sections,
    we first describe the within-subject study design, measures, and procedure.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在用户研究中，我们旨在（1）评估我们的提示策略在各种口头对话中是否仍然有效，并保持领域特异性，并评估与三种不同 TextileBot 变体的互动是否有显著差异——这表明用户将每个代理视为独特的实体，并验证我们方法的阶段
    2，（2）调查 TextileBot 是否能够保持记忆并进行连续对话，如阶段 3 设计，并（3）探索用户与每个 bot 变体的互动性质，以了解用户参与的细微差别。由于口头对话中使用的语言不同于书面文本[[81](#bib.bib81)]，我们选择了面对面的研究，让参与者与
    TextileBot 智能设备进行互动，激发自然语言对话。我们采用了混合方法，将传统的机器学习消融研究分析与 HIC 分析结合——包括问卷调查和参与者的定性反馈，并结合对人机对话的对话分析。我们招募了总共
    30 名参与者，与三位语音代理进行纺织品和纺织品循环利用方面的互动，如引言中所述。在接下来的部分中，我们首先描述被试内研究设计、测量和程序。
- en: 5.1 Study design and methods
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 研究设计和方法
- en: 'We utilized a mixed within/between-subjects design, where each of the participants
    ($N=30$) was asked to speak with the three CAs (Vanilla, Assistant, Expert) embodied
    in the same smart device TextileBots. The order in which participants interacted
    with each of the agents was randomised to avoid order effects. For each agent
    interaction, participants followed the same four phases: Free chatting, Information
    gathering, Questionnaires, and Overall user feedback. Each of the four phases
    is detailed below:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们采用了混合的被试内/被试间设计，其中每位参与者（$N=30$）被要求与三位 CAs（Vanilla、Assistant、Expert）在同一个智能设备
    TextileBots 上进行交流。参与者与每个代理互动的顺序是随机的，以避免顺序效应。对于每次代理互动，参与者遵循相同的四个阶段：自由聊天、信息收集、问卷调查和总体用户反馈。以下是四个阶段的详细描述：
- en: Phase 1 - Free chatting
  id: totrans-134
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 阶段 1 - 自由聊天
- en: The human-agent interaction started with an open conversation with no topical
    restrictions. Participants could freely engage with the agents on any topic of
    their choice. This approach was designed to facilitate a broad exploration of
    potential conversation topics relevant to textiles contexts and to gain insights
    into the personality and characteristics of three conversational agents. A minimum
    of 5 minutes to a maximum of 10 minutes was allocated to this phase. Free exploration
    is particularly beneficial for domains that have not yet implemented conversational
    agents, such as textile circularity. Engaging in freeform conversations during
    the prototyping phase provides valuable insights into user needs and the scope
    of topic coverage required in these domains.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 人机互动以没有话题限制的开放对话开始。参与者可以自由地与代理讨论任何他们选择的话题。这种方法旨在促进对与纺织品相关的潜在对话话题的广泛探索，并获取对三位对话代理的个性和特点的见解。此阶段分配了至少
    5 分钟至最多 10 分钟。自由探索对尚未实施对话代理的领域特别有益，如纺织品循环利用。在原型阶段进行自由形式对话为用户需求和这些领域所需的话题覆盖范围提供了有价值的见解。
- en: Phase 2 - Information gathering
  id: totrans-136
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 阶段 2 - 信息收集
- en: To ensure consistency in the topics discussed, the second part focused on textile
    circularity, the main conversational topic that has guided the TextileBot implementations.
    In collaboration with domain experts in materials science and textile circularity,
    we developed ten information gathering tasks for participants. To ensure a structured
    approach, we arranged these tasks in a progression from general to specific, transitioning
    from high-level concepts to more detailed aspects. Subsequently, we divided the
    tasks into three distinct groups, and applied the three TextileBots to these groups
    in a round-robin fashion [[33](#bib.bib33)] to ensure coverage of different task-agent
    combinations.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保讨论主题的一致性，第二部分集中于纺织品循环利用，这是指导 TextileBot 实施的主要对话话题。在与材料科学和纺织品循环利用领域的专家合作下，我们为参与者开发了十个信息收集任务。为了确保结构化的方法，我们将这些任务按从一般到具体的顺序安排，从高层次概念过渡到更详细的方面。随后，我们将任务分为三个不同的组，并采用循环方式将三个
    TextileBot 应用于这些组中[[33](#bib.bib33)]，以确保涵盖不同的任务-代理组合。
- en: 'Table 2: Questionnaire used after each of the three TextileBots to assess the
    human-bot interaction experience.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：每个 TextileBot 之后用于评估人机交互体验的问卷。
- en: '| Evaluation Category | Metric | Question type |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| 评估类别 | 度量指标 | 问题类型 |'
- en: '| --- | --- | --- |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Usability | Ease to use | 5 likert scale |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| 可用性 | 使用难易度 | 5 点量表 |'
- en: '| Engagement | E-I: Interest in responses | 5 likert scale |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 参与度 | E-I：对回答的兴趣 | 5 点量表 |'
- en: '| E-E: Engagement in conversation | 5 likert scale |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| E-E：对话中的参与度 | 5 点量表 |'
- en: '| E-W: Willingness to use in the future | 5 likert scale |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| E-W：未来使用意愿 | 5 点量表 |'
- en: '| Coherence | C-I: Input comprehensibility | 5 likert scale |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 连贯性 | C-I：输入的可理解性 | 5 点量表 |'
- en: '| C-C: Clarity in responses | 5 likert scale |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| C-C：回答的清晰度 | 5 点量表 |'
- en: '| C-A: Accuracy in responses | 5 likert scale |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| C-A：回答的准确性 | 5 点量表 |'
- en: '| Changes over time | The level of engagement over time | Multiple-choice:
    Increase, Decrease, Dynamic |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| 随时间变化 | 随时间变化的参与度 | 选择题：增加，减少，动态 |'
- en: '| Follow-up on changes over time | Open-ended question to capture the reason
    |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 随时间变化的跟进 | 开放式问题以捕捉原因 |'
- en: Phase 3 - Questionnaire
  id: totrans-150
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 第三阶段 - 问卷
- en: 'We developed a questionnaire that contains an evaluation matrix to assess the
    human-LLM agent interaction. The evaluation matrix employs a wide range of existing
    metrics, combining metrics from conventional heuristics-based conversational agents,
    for both non goal-oriented/task-agnostic and domain-specific/goal-oriented agents
    [[51](#bib.bib51), [86](#bib.bib86), [65](#bib.bib65), [92](#bib.bib92)]. We also
    incorporated human-LM interaction metrics [[55](#bib.bib55), [99](#bib.bib99)].
    Since our study involves three TextileBots, we treated each as a separate model
    and employed the pairwise per-dialogue (PW-dialogue) method [[86](#bib.bib86)]
    to evaluate the human-LLM interaction. This method compares two entire conversations
    with two different agents, and has been shown to outperform evaluations of single
    models. Each participant was asked to conduct three conversations with the three
    different TextileBots. Table [2](#S5.T2 "Table 2 ‣ Phase 2 - Information gathering
    ‣ 5.1 Study design and methods ‣ 5 Evaluation of TextileBot ‣ LLM-Mediated Domain-Specific
    Voice Agents: The Case of TextileBot") summarises the key focus of the questionnaire,
    the metrics used and the question types.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '我们开发了一个包含评估矩阵的问卷，以评估人类与 LLM 代理的交互。该评估矩阵使用了广泛的现有度量指标，结合了传统基于启发式对话代理的度量指标，适用于非目标导向/任务无关和领域特定/目标导向的代理[[51](#bib.bib51)，[86](#bib.bib86)，[65](#bib.bib65)，[92](#bib.bib92)]。我们还结合了人类-LM
    交互的度量指标[[55](#bib.bib55)，[99](#bib.bib99)]。由于我们的研究涉及三个 TextileBot，我们将每个视为一个单独的模型，并采用对话对比（PW-dialogue）方法[[86](#bib.bib86)]来评估人类与
    LLM 的交互。这种方法比较两个不同代理的两次完整对话，并已被证明优于单一模型的评估。每个参与者被要求与三个不同的 TextileBot 进行三次对话。表
    [2](#S5.T2 "Table 2 ‣ Phase 2 - Information gathering ‣ 5.1 Study design and methods
    ‣ 5 Evaluation of TextileBot ‣ LLM-Mediated Domain-Specific Voice Agents: The
    Case of TextileBot") 总结了问卷的重点，所使用的度量指标和问题类型。'
- en: Phase 4 - Overall user feedback
  id: totrans-152
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 第四阶段 - 整体用户反馈
- en: 'At the end of the study, we collected participants overall feedback on their
    experience with the TextileBots, capturing participants’ subjective experiences
    engaging with the voice agents, their preferences, observations about the interaction
    and changes over time, as well as any suggestions for improvements and insights
    they gained on the domain-specific conversation. Please see an overview of the
    focus and question types in Table [3](#S5.T3 "Table 3 ‣ Phase 4 - Overall user
    feedback ‣ 5.1 Study design and methods ‣ 5 Evaluation of TextileBot ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot").'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '在研究结束时，我们收集了参与者对 TextileBots 体验的整体反馈，记录了参与者与语音代理互动的主观体验、他们的偏好、对互动的观察以及随时间的变化，还包括对改进的建议和他们在领域特定对话中获得的见解。请参见表
    [3](#S5.T3 "表 3 ‣ 第 4 阶段 - 整体用户反馈 ‣ 5.1 研究设计与方法 ‣ 5 评价 TextileBot ‣ LLM 介导的领域特定语音代理:
    TextileBot 案例") 的焦点和问题类型概述。'
- en: 'Table 3: Overall user feedback and participants preferences between the three
    TextileBots, captured at the end of the study.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：研究结束时对三个 TextileBot 的整体用户反馈和参与者偏好。
- en: '| Feedback category | Question type |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 反馈类别 | 问题类型 |'
- en: '| --- | --- |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Overall feedback on each of the TextileBots | Open-ended questions |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 对每个 TextileBot 的整体反馈 | 开放性问题 |'
- en: '| Preference between the three TextileBot | Ranking and open-ended questions
    |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 三个 TextileBot 之间的偏好 | 排名和开放性问题 |'
- en: '| Experience of the TextileBots interaction, changes over time | Open-ended
    question |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| TextileBots 互动体验、随时间变化 | 开放性问题 |'
- en: '| Suggestions on TextileBot | Open-ended questions |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 对 TextileBot 的建议 | 开放性问题 |'
- en: '| Understanding of the domain (textiles circularity) | 5 likert scale and open-ended
    questions |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| 对领域（纺织品循环性）的理解 | 5 点李克特量表和开放性问题 |'
- en: 5.2 Study setup and procedure
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 研究设置和程序
- en: 'The study was conducted in a controlled laboratory environment, with each participant
    attending individually in-person. Participants were briefed with instructions
    to imagine a scenario wherein they were talking with three distinct voice agents
    (each with different personalities and capabilities) in a retail environment,
    such as a clothing store. A TextileBot device was placed was positioned on a table
    in front of a participant, allowing them to control it (see Figure [8(b)](#S4.F8.sf2
    "In Figure 8 ‣ 4.2 Hardware System Design: The TextileBot Voice Device ‣ 4 The
    Case of TextileBot: Design and Implementation ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot")). The tasks involved identifying and ranking
    their preferred agent based on its suitability for use in a retail environment
    as TextileBot, and their subject experience to the overall user feedback. Every
    interaction session began with an introduction from the respective agent (Vanilla,
    Expert and Assistant):'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '该研究在一个受控的实验室环境中进行，每位参与者都需亲自单独参加。参与者被简要说明了一个情景，即他们正在与三个不同的语音代理（每个代理具有不同的个性和能力）进行对话，情境设定在零售环境中，例如服装店。一个
    TextileBot 设备被放置在参与者面前的桌子上，让他们可以控制它（参见图 [8(b)](#S4.F8.sf2 "在图 8 ‣ 4.2 硬件系统设计:
    TextileBot 语音设备 ‣ 4 TextileBot 案例: 设计与实施 ‣ LLM 介导的领域特定语音代理: TextileBot 案例")）。任务包括根据
    TextileBot 在零售环境中的适用性识别和排序他们喜欢的代理，并对他们的体验进行整体反馈。每次互动会话都以相应代理（Vanilla、Expert 和
    Assistant）的介绍开始：'
- en: '"Hi there, I’m TextileBot. I’m here to assist you with any questions or discussions
    you may have regarding textiles. To speak with me, simply click the button and
    start talking. When you’re finished, click the button again to let me know that
    you’re done. How can I assist you today?"'
  id: totrans-164
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “你好，我是 TextileBot。我在这里协助你解答任何关于纺织品的问题或进行讨论。要与我交谈，只需点击按钮并开始说话。当你完成时，再次点击按钮以告诉我你已经完成。今天我怎么帮助你呢？”
- en: 'After the agent’s welcome message, participants were given 5-10 minutes to
    interact freely with the TextileBot, choosing their own conversational topics
    (Phase 1). When satisfied with the interaction or the time limit was reached,
    participants proceeded to the information gathering phase (Phase 2). Upon completion
    of both phases, participants were then asked to fill out a questionnaire to assess
    their experience with that particular agent (Phase 3). This three-phase procedure
    was repeated for all three TextileBots. Participants were also offered the opportunity
    to extend their interaction with any TextileBot of their choice or all of them,
    if they prefer, before proceeding to Phase 4\. Once all interaction sessions were
    completed, participants were asked to provide final overall feedback (Phase 4)
    on their experience using the voice-based TextileBots, as outlined in Section
    [5.1](#S5.SS1 "5.1 Study design and methods ‣ 5 Evaluation of TextileBot ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot").'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在代理的欢迎消息后，参与者有 5-10 分钟时间与 TextileBot 自由互动，选择他们自己的对话主题（阶段 1）。当对互动感到满意或时间限制到达时，参与者进入信息收集阶段（阶段
    2）。完成这两个阶段后，参与者被要求填写问卷，以评估他们与该代理的体验（阶段 3）。这一三阶段程序对所有三种 TextileBots 都进行了重复。参与者还可以选择延长与任何
    TextileBot 的互动，或者与所有 TextileBot 进行互动，如果他们愿意，然后进入阶段 4。一旦所有互动环节完成，参与者将被要求提供最终的总体反馈（阶段
    4），以评估他们使用基于语音的 TextileBots 的体验，详细信息见第 [5.1](#S5.SS1 "5.1 研究设计与方法 ‣ 5 TextileBot
    的评估 ‣ 基于 LLM 的领域特定语音代理：以 TextileBot 为例") 节。
- en: 5.3 Analysis approach
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 分析方法
- en: Our primary focus is to explore the efficient development of LLM-based voice
    CAs that are domain-specific and offer personalized interactions that is capable
    of conducting continuous (multi-turn) conversations. We started by analyzing questionnaire
    responses with each agent to understand each vHAI (Vallina, Expert and Assistant).
    Following this, we conducted a qualitative analysis of the overall user feedback
    to gain insights into participants’ overall perceptions of three agents. The evaluation
    also examines the effectiveness of our approach.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的主要关注点是探索基于 LLM 的语音 CAs 的高效开发，这些 CAs 是特定领域的，提供个性化的互动，能够进行连续的（多轮）对话。我们首先通过分析每个代理的问卷回答来理解每个
    vHAI（Vallina、Expert 和 Assistant）。随后，我们进行了对整体用户反馈的定性分析，以获取参与者对三种代理的总体看法。评估还检查了我们方法的有效性。
- en: In addition, a key aspect of our research is exploring how people perceive and
    engage with different prompted LLM-based CAs. Hence, as a first step in the analysis,
    the dialogue contents were stored in a text format and imported into NVivo 14,
    a qualitative analysis software. A dialogue refers to a whole recorded exchange
    of conversation between a participant and a CA [[89](#bib.bib89)]. We then applied
    a data-driven inductive thematic analysis approach to identify recurring themes
    and patterns within the dialogue transcripts and to gain qualitative insights
    into the vHAI.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们研究的一个关键方面是探索人们如何感知和参与不同的提示 LLM 基础 CAs。因此，作为分析的第一步，对话内容被存储为文本格式并导入 NVivo
    14，这是一个定性分析软件。对话指的是参与者与 CA 之间的整个录音交换[[89](#bib.bib89)]。然后，我们应用了基于数据的归纳主题分析方法，以识别对话记录中的重复主题和模式，并获得对
    vHAI 的定性洞察。
- en: 'The first author applied an open-coding approach to the dialogues, and created
    a first coding scheme that was discussed and refined with the co-authors. After
    several discussions and iterations, all authors reached the consensus that the
    vHAI can’t be easily shoehorned into a set of themes. However, it was agreed that
    the changes in the interaction patterns over time should be further explored to
    understand variations in the dialogue and participant behaviours. Hence, we decided
    to employ a combined inductive/deductive hybrid approach focused on:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 第一作者对对话应用了开放编码方法，并创建了第一个编码方案，该方案与合著者进行了讨论和改进。经过多次讨论和迭代，所有作者达成共识，即 vHAI 不能轻易被强行归入一组主题。然而，大家同意应进一步探索互动模式随时间变化的情况，以理解对话和参与者行为的变化。因此，我们决定采用结合了归纳/演绎的混合方法，重点关注：
- en: '1.'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: An analysis of the dialogues based on conversational turns,
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于对话轮次的对话分析，
- en: '2.'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: An analysis of the conversational styles,
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对对话风格的分析，
- en: '3.'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: An analysis of the human behaviour in the interaction with the TextileBots.
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对人类行为在与 TextileBots 互动中的分析。
- en: 'In Section [6.3](#S6.SS3 "6.3 Dialogue analysis of the voice-based human-agent
    interaction ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case
    of TextileBot"), we present the results for each of those three points, starting
    from the “conversational turns” and “turn-taking patterns” observed within and
    across the three voice agents. We then further explored differences between single
    vs. multi-turn conversations and calculated the number of words used by participants
    in each turn, as a possible indicator for their engagement over time and across
    the agents. This dialogue analysis was extended with a deep dive into the conversational
    styles enriched and exemplified with representative quotes from participants’
    interaction with the agents, and a particular emphasis on the changes over time,
    drawing on existing language concepts such as code-switching and social protocols.
    We conclude with a reflection on specific human behaviours and strategies when
    engaging with the three different agents. All taken together form a rich, multi-faceted
    foundation for our discussion on the effectiveness of our approach and how humans
    perceive, interact, and engage with prompt-based voice agents.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在[6.3](#S6.SS3 "6.3 基于语音的人机交互对话分析 ‣ 6 结果 ‣ LLM介导的领域特定语音代理：以TextileBot为例")部分中，我们展示了三个点的结果，从观察到的“对话轮次”和“轮次交替模式”开始，涵盖了三个语音代理中的情况。然后，我们进一步探讨了单轮对话与多轮对话之间的差异，并计算了参与者每轮使用的词汇数量，作为他们参与度的可能指标。这一对话分析扩展为深入探讨对话风格，并通过参与者与代理的互动中具有代表性的引用进行了丰富和示例化，特别强调了随时间变化的情况，借鉴了现有的语言概念，如代码转换和社会协议。我们以对与三种不同代理互动时的特定人类行为和策略的反思作为结尾。所有这些内容共同构成了我们对方法有效性以及人类如何感知、互动和参与基于提示的语音代理的讨论的丰富多面的基础。
- en: All participants quotes are included with original spelling and emphasis.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 所有参与者的引用均保留了原始拼写和强调。
- en: 5.4 Participants
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 参与者
- en: We recruited 30 participants aged between 22 to 44 years of age (mean age =
    30, SD = 5.33), out of which fourteen were male, sixteen female. Participants
    had a diverse range of backgrounds, including computer scientists, UX designers,
    artists, healthcare consultants, researchers, university lecturers, and university
    students. All participants were either native English speakers or highly proficient
    in English. Furthermore, the participants came from 15 countries across five continents.
    The study was approved by the local University Research Ethics Committee . All
    participants provided written informed consent before taking part in the study.
    The study lasted between 45 to 60 minutes, and all participants were compensated
    with a gift voucher for their time.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们招募了30名年龄在22到44岁之间的参与者（平均年龄 = 30，标准差 = 5.33），其中十四名为男性，十六名为女性。参与者背景多样，包括计算机科学家、用户体验设计师、艺术家、医疗顾问、研究人员、大学讲师和大学生。所有参与者均为英语母语者或英语水平非常高。此外，参与者来自五大洲的15个国家。该研究已获得当地大学研究伦理委员会的批准。所有参与者在参与研究前均提供了书面知情同意。研究持续了45到60分钟，所有参与者都获得了礼品券作为补偿。
- en: 6 Results
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结果
- en: 'We present our findings in three main sections: analysis of questionnaire responses
    (Section [6.1](#S6.SS1 "6.1 Questionnaire results ‣ 6 Results ‣ LLM-Mediated Domain-Specific
    Voice Agents: The Case of TextileBot")), overall participant feedback (Section
    [6.2](#S6.SS2 "6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated Domain-Specific
    Voice Agents: The Case of TextileBot")), and dialogue data from our user study
    (Section [6.4](#S6.SS4 "6.4 Conversational styles ‣ 6 Results ‣ LLM-Mediated Domain-Specific
    Voice Agents: The Case of TextileBot")). The questionnaire responses and dialogue
    data explore whether participants perceived three variations of TextileBot as
    distinct entities and their engagement with each prompted version. Additionally,
    these sections assess whether TextileBot maintained memory and facilitated continuous
    conversations. Together, these results provide insights into the nuances of user
    engagement with different LLM-powered voice agents.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '我们的发现分为三个主要部分：问卷反馈分析（第[6.1节](#S6.SS1 "6.1 Questionnaire results ‣ 6 Results
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")）、总体参与者反馈（第[6.2节](#S6.SS2
    "6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot")）和我们用户研究中的对话数据（第[6.4节](#S6.SS4 "6.4 Conversational styles
    ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")）。问卷反馈和对话数据探讨了参与者是否将三种不同的TextileBot视为不同的实体，以及他们对每个版本的互动情况。此外，这些部分评估了TextileBot是否保持了记忆并促进了连续对话。这些结果综合起来提供了对用户与不同LLM驱动语音助手互动细节的洞察。'
- en: 6.1 Questionnaire results
  id: totrans-182
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 问卷结果
- en: 'To determine if participants perceived three variations of TextileBot as distinct
    entities, we analyzed questionnaire data from our study. We obtained a total of
    120 questionnaires, 90 from the interaction sessions (three per participant, for
    each agent they tried), and 30 from the overall user feedback. This section mainly
    discusses the results we have with respect to an analysis using the metrics in
    Table [2](#S5.T2 "Table 2 ‣ Phase 2 - Information gathering ‣ 5.1 Study design
    and methods ‣ 5 Evaluation of TextileBot ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot"). We also aimed to understand participants’ perceptions
    of voice agents when presented with different prompts.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '为了确定参与者是否将三种不同的TextileBot视为不同的实体，我们分析了我们研究中的问卷数据。我们共获得了120份问卷，其中90份来自互动环节（每个参与者尝试每个代理时填写三份），30份来自总体用户反馈。本节主要讨论了我们使用[2](#S5.T2
    "Table 2 ‣ Phase 2 - Information gathering ‣ 5.1 Study design and methods ‣ 5
    Evaluation of TextileBot ‣ LLM-Mediated Domain-Specific Voice Agents: The Case
    of TextileBot")表中的指标进行分析的结果。我们还旨在了解参与者在面对不同提示时对语音助手的看法。'
- en: Engagement and coherence metrics
  id: totrans-184
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 参与度和连贯性指标
- en: 'We first obtained participants’ scores for both Engagement and Coherence metrics,
    averaged them, and presented them in a radar plot (Figure [9(a)](#S6.F9.sf1 "In
    Figure 9 ‣ Cross-metrics interactions ‣ 6.1 Questionnaire results ‣ 6 Results
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")). All responses
    were coded from $1$. Figure [9(a)](#S6.F9.sf1 "In Figure 9 ‣ Cross-metrics interactions
    ‣ 6.1 Questionnaire results ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot") shows the questionnaire’s overall results regarding the
    evaluation of engagement and coherence. The results in Figure [9(a)](#S6.F9.sf1
    "In Figure 9 ‣ Cross-metrics interactions ‣ 6.1 Questionnaire results ‣ 6 Results
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot") demonstrate
    that Assistant is generally the best across all these evaluation metrics.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '我们首先获得了参与者对参与度和连贯性指标的评分，计算了平均值，并以雷达图的形式呈现（图[9(a)](#S6.F9.sf1 "In Figure 9 ‣
    Cross-metrics interactions ‣ 6.1 Questionnaire results ‣ 6 Results ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot")）。所有回应的评分从$1$开始。图[9(a)](#S6.F9.sf1
    "In Figure 9 ‣ Cross-metrics interactions ‣ 6.1 Questionnaire results ‣ 6 Results
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")展示了问卷在参与度和连贯性评价方面的整体结果。图[9(a)](#S6.F9.sf1
    "In Figure 9 ‣ Cross-metrics interactions ‣ 6.1 Questionnaire results ‣ 6 Results
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")的结果显示，Assistant在所有这些评估指标中通常表现最好。'
- en: Cross-metrics interactions
  id: totrans-186
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 跨指标互动
- en: 'We then used mixed cumulative link regression models with participants and
    interaction topics/questions as random effects. This allowed us to account for
    the nested nature of the experimental design [[50](#bib.bib50)] and the ordinal
    characteristics of the survey’s responses [[109](#bib.bib109)]. Data was analysed
    using the “ordinal” package in R [[20](#bib.bib20)]. No difference was found when
    comparing models on their Ease of use and Coherence (C-I, C-C, C-A) metrics. As
    we have also seen in Figure [9(a)](#S6.F9.sf1 "In Figure 9 ‣ Cross-metrics interactions
    ‣ 6.1 Questionnaire results ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot"), the variations in C-I, C-C and C-A are relatively small,
    we turn the focus of the analysis to the remaining Engagement metrics (E-I, E-E
    and E-W).'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们随后使用了混合累积链接回归模型，将参与者和互动主题/问题作为随机效应。这使我们能够考虑实验设计的嵌套性质 [[50](#bib.bib50)] 和调查回应的序数特征
    [[109](#bib.bib109)]。数据使用R中的“ordinal”包进行了分析 [[20](#bib.bib20)]。在易用性和连贯性（C-I、C-C、C-A）指标上比较模型时未发现差异。正如我们在图
    [9(a)](#S6.F9.sf1 "在图9 ‣ 跨指标交互 ‣ 6.1 问卷结果 ‣ 6 结果 ‣ 基于LLM的特定领域语音助手：以TextileBot为例")
    中所见，C-I、C-C和C-A的变化相对较小，我们将分析重点转向剩余的吸引力指标（E-I、E-E和E-W）。
- en: '![Refer to caption](img/2a9d8cf090030121d5d9584704f93eee.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/2a9d8cf090030121d5d9584704f93eee.png)'
- en: (a) Engagement and Coherence metrics.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 吸引力和连贯性指标。
- en: '![Refer to caption](img/389a23655b18e74f48615e398b9bd6e1.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/389a23655b18e74f48615e398b9bd6e1.png)'
- en: (b) Participant preference ranking.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 参与者偏好排名。
- en: 'Figure 9: Left: this includes Interestingness in responses (Engagement, E-I),
    Engagement in conversations (Engagement, E-E) and Willingness to use in the future
    (Engagement, E-W), Input comprehensibility (Coherence, C-I), Clarity in responses
    (Coherence, C-C), Accuracy in responses (Coherence, C-A). Right: Participant preference
    ranking of the three TextileBots in light of textile circularity.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：左侧：包括回应中的趣味性（吸引力，E-I）、对话中的互动（吸引力，E-E）以及未来使用的意愿（吸引力，E-W），输入的可理解性（连贯性，C-I），回应的清晰度（连贯性，C-C），回应的准确性（连贯性，C-A）。右侧：参与者对三个TextileBot在纺织品循环利用方面的偏好排名。
- en: 'As depicted in Figure [9(a)](#S6.F9.sf1 "In Figure 9 ‣ Cross-metrics interactions
    ‣ 6.1 Questionnaire results ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot"), the TextileBot Assistant was found consistently more
    engaging at the single response than its Expert and Vanilla counterparts (E-I),
    although results were not statistically significant (“marginally” significant
    $p=0.06$, post-hoc tests, Bonferroni corrected).'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 [9(a)](#S6.F9.sf1 "在图9 ‣ 跨指标交互 ‣ 6.1 问卷结果 ‣ 6 结果 ‣ 基于LLM的特定领域语音助手：以TextileBot为例")
    所示，TextileBot助手在单次回应中的吸引力持续高于其专家和普通对照组（E-I），尽管结果在统计上并不显著（“边际”显著 $p=0.06$，事后检验，Bonferroni校正）。
- en: Ease to use and Interest change over time
  id: totrans-194
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 易用性和兴趣的变化情况
- en: Overall, the ease of use was rated from 2 to 5 with an average score of 4. Regarding
    the change in interest levels over time, 83.8% of the sessions showed that there
    is a variation in interest levels. 53.8% reported an increase, 20% reported a
    decrease, 10% were dynamic. The rest reported no change. Participants emphasized
    the significant influence of response content on their level of interest. For
    example, P5 pointed out that their interest “depended on the specific question
    and corresponding answers”. Similar statements were echoed by P18 and P28, who
    noted that their interest heightened when the agent delivered intriguing responses.
    The other factor is the length of the response. Both P15 and P16 expressed annoyance
    due to the vast, long-winded response from Expert. As P15 put it, ”It sometimes
    provided too much information which made me lose interest somewhat”. P16 went
    into further detail, stating, ”Sometimes the responses were a bit long. The information
    provided was interesting, but the agent essentially answered my question within
    the first few seconds and then kept talking.” However, not all participants were
    thrilled with shorter responses. P17 commented on Vanilla as “It was too brief
    with little prompt but it remembers previous questions and provided context based
    answers”.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，易用性评分从2到5不等，平均分为4。关于兴趣水平的变化，83.8%的会话显示兴趣水平存在波动。53.8%报告了兴趣的增加，20%报告了兴趣的减少，10%表示动态变化，其余报告没有变化。参与者强调了回答内容对兴趣水平的重大影响。例如，P5指出他们的兴趣“取决于具体问题和对应的回答”。类似的观点也出现在P18和P28，他们提到当代理人提供有趣的回答时，他们的兴趣增加。另一个因素是回答的长度。P15和P16都对Expert的冗长回答表示烦恼。正如P15所说，“有时提供的信息过多，让我有些失去兴趣”。P16进一步指出，“有时回答有点长。提供的信息很有趣，但代理人在前几秒内基本回答了我的问题，然后继续讲述。”然而，并不是所有参与者都对较短的回答感到满意。P17对Vanilla的评价是“它过于简短，几乎没有提示，但它记住了之前的问题并提供了有上下文的回答”。
- en: 6.2 Overall feedback
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 总体反馈
- en: In this section, we present the overall user feedback on the participants’ subjective
    experiences with the agents, their preferences, feedback on how they perceived
    the interactions over time and any suggestions for improvements.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们展示了参与者对代理人的主观体验的总体反馈，包括他们的偏好、对互动感知的反馈以及任何改进建议。
- en: 'Overall, participants enjoyed the interaction because “it felt really natural”
    (P7) and “The levels of answers were good throughout but I really liked the memory
    function and the agent answers were not generic, especially compared to my other
    voice agent experiences” (P13). Nevertheless, a number of participants (N=4) perceived
    the interaction to be a one-way question-answering rather than conversation and
    expected the voice agent to engage in a more dialogic interaction by asking questions:
    “I wish it engaged in conversation as well, asking questions back more, so you
    feel more engaged as well…” (P14). Participants (N=5) suggested that the voice
    agents would benefit from adopting “emotion embedded” and “more interesting” responses
    to achieve a human-like “real conversation”. Participants mentioned that they
    would prefer “less formal”, “less persuasive” voice agent with “a bit of humour”
    and “shorter answer”, in order to facilitate ”more engaging interactions”.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，参与者喜欢这种互动，因为“感觉非常自然”（P7）和“回答的层次一直很好，但我特别喜欢记忆功能，代理人的回答不是通用的，尤其是与我其他语音代理的经历相比”（P13）。然而，许多参与者（N=4）认为这种互动更像是一种单向的问答，而不是对话，期望语音代理能通过提问来进行更多的对话式互动：“我希望它也能进行对话，多提问一些，这样你会觉得更加参与……”（P14）。参与者（N=5）建议语音代理采用“嵌入情感的”和“更有趣的”回答，以实现类人的“真实对话”。参与者提到，他们更喜欢“少正式”、“少说服”的语音代理，带有“一点幽默”和“更短的回答”，以促进“更具吸引力的互动”。
- en: 'Moreover, participants (N=6) commented on the clarity and quality of the content
    provided by the voice agents. The majority of the feedback on the information
    seeking phase (i.e. information provided by the voice agent) was positive, with
    comments praising the levels of answers and clarity, such as P13 noted “agent
    answers were not generic especially compared to my other voice agent experiences”.
    On the other hand, some participants pointed out redundancy and vagueness, such
    as highlighted by P22: “Sometimes the answers provided in the conversations were
    a bit redundant, but I found the answers very clear, although sometimes a bit
    vague or broad.” . However, there was a general feeling that more concise, in-depth
    content delivery by the voice agents would be desirable.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，参与者（N=6）对语音助手提供的内容的清晰度和质量进行了评价。大多数关于信息获取阶段（即语音助手提供的信息）的反馈是积极的，评论称赞了回答的水平和清晰度，例如P13指出“与我其他语音助手的体验相比，代理的回答不泛泛而谈”。另一方面，一些参与者指出了冗余和模糊性，例如P22强调：“有时对话中的回答有点冗余，但我发现回答非常清晰，尽管有时稍显模糊或宽泛。”然而，普遍感觉语音助手提供更简洁、深入的内容传递会更为理想。
- en: In summary, participants anticipated voice agents that engage proactively, exhibit
    personality, deliver interactive communication (memory function), and provide
    varied, interesting yet concise content. Furthermore, the incorporation of human-like
    qualities in both content and voice is desirable. These insights are further reflected
    in participants’ feedback on their agent preferences.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，参与者期待语音助手能够积极互动，展现个性，进行互动沟通（记忆功能），并提供多样、有趣但简洁的内容。此外，内容和语音中融入类似人类的特质也是理想的。这些见解在参与者对其代理偏好的反馈中得到了进一步体现。
- en: 6.2.1 Preferences and experiences across voice agents
  id: totrans-201
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.1 语音助手的偏好和体验
- en: 'Participants were asked to express their preference towards the three TextileBots
    by ranking them. We used the chi-square test to assess whether any of the agents
    was selected significantly more (or less) often as a favourite agent. Results
    showed no statistically significant differences although, as mentioned before
    based on the conversational analysis and questionnaire feedback, we can see a
    preference for the Assisstant agent, followed by Vanilla and the Expert as shown
    in Figure [9(b)](#S6.F9.sf2 "In Figure 9 ‣ Cross-metrics interactions ‣ 6.1 Questionnaire
    results ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot").
    The Assistant agent was selected more often (14 selections) than Vanilla (12 selections)
    than the Expert agent (only 4 selections). On the other hand, the Expert agent
    reached “second place” (14 selections) more often than both the Vanilla (7 selections)
    and Assistant (9 selections) agents.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者被要求通过排名表达对三款TextileBots的偏好。我们使用卡方检验来评估是否有任何代理被显著更频繁（或更少）地选择为最喜欢的代理。结果显示没有统计学上显著的差异，尽管如前所述，根据对话分析和问卷反馈，我们可以看到对Assistant代理的偏好，其次是Vanilla和Expert，如图[9(b)](#S6.F9.sf2
    "在图9 ‣ 跨指标互动 ‣ 6.1 问卷结果 ‣ 6 结果 ‣ LLM介导的领域特定语音助手：以TextileBot为例")所示。Assistant代理被选择的次数（14次）多于Vanilla（12次），而Expert代理（仅4次）则较少。另一方面，Expert代理（14次）更频繁地获得“第二名”，相比于Vanilla（7次）和Assistant（9次）代理。
- en: 'Most participants (N=18) expressed a preference for an agent that can communicate
    in a concise and clear manner with them. P17 stated, “the 2nd agent (Assistant)
    gave just the right amount of detail.” However, it is worth noting that the length
    of the agent responses was not universally appreciated, as discussed in Section
    [6.1](#S6.SS1.SSS0.Px3 "Ease to use and Interest change over time ‣ 6.1 Questionnaire
    results ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot").
    Moreover, some participants (N=13) distinguished the agents based on their interactive
    capability. The Assistant agent was preferred by many for its interaction level,
    as P29 stated“Assistant agent has the best understanding of my question and explained
    in a most interesting way”. In contrast, the Expert agent was criticized for being
    a repetitive information source lacking meaningful interaction. P1 mentioned that
    Expert agent ”feels like a repetitive of the textile circularity concept.” Whereas
    P30 point out on the conversational breath that Expert “is too restrictive up
    to a point where it stops responding to questions asked”.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '大多数参与者（N=18）表达了对能以简洁明了的方式与他们沟通的代理人的偏好。P17 说道，“第二个代理人（Assistant）提供了恰到好处的细节。”然而，值得注意的是，代理人回应的长度并未得到普遍认可，如[6.1](#S6.SS1.SSS0.Px3
    "Ease to use and Interest change over time ‣ 6.1 Questionnaire results ‣ 6 Results
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")章节中所讨论。此外，一些参与者（N=13）根据互动能力区分代理人。Assistant
    代理人因其互动水平受到许多人的青睐，P29 说道：“Assistant 代理人对我的问题理解最好，并以最有趣的方式解释。”相比之下，Expert 代理人因缺乏有意义的互动而受到批评。P1
    提到 Expert 代理人“感觉像是对纺织品循环概念的重复。”而 P30 则指出 Expert 代理人的对话范围“过于限制，以至于它停止回应所提出的问题”。'
- en: Finally, the agent’s perceived personality also played a role in preferences.
    A number of participants (N=8) appreciated agents that showed human-like responses.
    P5 noted that the 2nd agent (Vanilla) “sounds more like a human… and gives me
    some interesting answers and makes me laugh.” In contrast, the Expert agent received
    criticism for its formal tonality, with P25 noting that it was more like a “text-book”
    and P10 referring to it as “speaking with a smart microwave.”
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，代理人的感知个性也在偏好中发挥了作用。一些参与者（N=8）欣赏那些展现类人回应的代理人。P5 指出，第二个代理人（Vanilla）“听起来更像人类……给出了一些有趣的回答，让我笑了。”相反，Expert
    代理人因其正式的语调受到批评，P25 认为它更像是“教科书”，而 P10 形容它为“像智能微波炉一样说话”。
- en: 6.2.2 Perceived changes over time
  id: totrans-205
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.2 随时间感知的变化
- en: 'Most participants (N=24) in our study described a change in their overall interaction
    with the agents. Several participants (N=13) commented that their engagement and
    the nature of interaction evolved as they became familiar with the agent. Some
    participants even noted an increase in confidence and comfort in their interaction
    towards the later stages, as described by P5: “the more time I spent on the agent,
    the more open I am”. Several participants (N=9) even mentioned adapting their
    communication styles, such as the language and the clarity of their questions
    to better communicate with the agent. P15 stated: “The way I asked it questions
    so that they were clear enough, avoided using too much colloquial language”. Additionally,
    some participants (N=5) stated an increase in specificity in their query, “my
    questions changed…”, “more specific questions as time went by”, and “I started
    to comment on its response and asked for further explanations.”. There was a general
    trend towards asking more specific and deeper questions as the dialogues progressed.
    Possibly as a result of a better understanding of the agent’s capacities or due
    to a growing interest in the topic.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究中的大多数参与者（N=24）描述了与代理人总体互动的变化。一些参与者（N=13）评论说，随着他们对代理人的熟悉，他们的参与和互动性质发生了变化。一些参与者甚至指出，在后期阶段，他们对互动的信心和舒适感有所增加，P5
    说道：“我花在代理人上的时间越多，我就越开放。”一些参与者（N=9）甚至提到，他们调整了沟通风格，比如语言和问题的清晰度，以更好地与代理人沟通。P15 表示：“我提问的方式更清晰，避免使用过多的口语。”此外，一些参与者（N=5）表示，他们的查询变得更加具体，“我的问题发生了变化……”，“随着时间的推移，问题变得更加具体”，“我开始对其回答进行评论，并要求进一步解释。”。随着对话的进行，问更具体和深入的问题成为一种普遍趋势，这可能是由于对代理人能力的更好理解或对话题的兴趣增加所致。
- en: 6.2.3 Suggestions for improvements
  id: totrans-207
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.3 改进建议
- en: 'Participants provided valuable suggestions for improving the agents, including
    one common suggestion to use a more natural and human-like voice. Suggestions
    such as “more natural voice” (P5) and “smoother voice, more dynamic” (P6) indicated
    a preference for a less robotic tone. Participants also mentioned the need for
    the agent to be maybe more empathetic, as P20 stated, “add some emotions”. Another
    suggestion was to improve the flow of the agent’s speech, such as “pauses when
    there is some punctuation would be helpful” (P22). In addition to the voice suggestions,
    participants wanted the agent to be concise, encouraging, and human-like. Suggestions
    included making the agent more engaging and insightful with personalised responses.
    Participants emphasised the importance of personalization, acknowledging that
    different users may have different knowledge levels, needs, and interests. They
    felt that the current agents need to reduce the “teacher-like” (P1) and “uncanny
    valley” (P7) effects in their responses. Another suggestion was related to the
    ability to interrupt the agent’s responses, as one could in a human-human interaction.
    P15 put it as follows: “Could be useful to be able to interrupt the agent’s response
    if the answer is not in line or maybe too long”. This again hints to the suggestion
    for a more natural and human-like interaction.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者提供了宝贵的改进建议，包括一个共同的建议是使用更自然、更类似人类的声音。诸如“更自然的声音”（P5）和“更流畅的声音，更有动感”（P6）的建议表明了对减少机器人声音的偏好。参与者还提到需要代理可能更加富有同理心，例如P20表示，“添加一些情感”。另一个建议是改善代理语音的流畅性，例如“有标点符号时暂停会很有帮助”（P22）。除了声音方面的建议外，参与者还希望代理简洁、鼓励并且更像人类。建议包括使代理更加引人入胜和具有洞察力，提供个性化的回应。参与者强调了个性化的重要性，承认不同用户可能有不同的知识水平、需求和兴趣。他们认为当前的代理需要减少“教师般的”（P1）和“恐怖谷”（P7）效应。另一个建议与能够打断代理回应有关，就像人际互动中一样。P15
    表示：“如果回答不符合预期或可能太长，能够打断代理的回应会很有用”。这再次暗示了对更自然、更类似人类的交互的建议。
- en: 6.2.4 Understanding of the domain (textiles circularity)
  id: totrans-209
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.4 领域理解（纺织品循环性）
- en: With regard to the specific conversation topic, textile circularity, most participants
    (N=21) reported that they had not previously encountered the concept of textile
    circularity. Despite this, an almost equal majority (N=27) were able to furnish
    a definition falling within the standard understanding of textile circularity
    by the end of the study. This concept of textile circularity is admittedly abstract
    and complex, a factor which led to many of our participants finding the subject
    matter somewhat tedious. Regardless, they remained engaged throughout the study
    and demonstrated the ability to articulate the concept in their own words. We
    believe these observations underscore potential avenues for future research, particularly
    exploring our prompt-based voice agents in other subject domains.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 关于特定的对话主题——纺织品循环性，大多数参与者（N=21）报告称他们之前没有遇到过纺织品循环性的概念。尽管如此，研究结束时几乎同样数量的大多数参与者（N=27）能够提供符合纺织品循环性标准理解的定义。纺织品循环性概念确实抽象且复杂，这使得许多参与者觉得这个话题有些乏味。尽管如此，他们在整个研究过程中保持了参与，并展示了用自己的话表达该概念的能力。我们认为这些观察结果突出了未来研究的潜在方向，特别是探索我们基于提示的语音代理在其他学科领域的应用。
- en: 6.3 Dialogue analysis of the voice-based human-agent interaction
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3 基于语音的人机交互对话分析
- en: We collected a total of 93 dialogues from 30 participants (3 agent interactions
    per participant), where 3 additional dialogues resulted from the “further interactions”
    that 2 participants had with the Vanilla (1x) and Assistant (2x) agents.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从30名参与者处收集了总共93个对话（每位参与者进行3次代理交互），其中3个额外对话源自2位参与者与Vanilla（1次）和Assistant（2次）代理进行的“进一步交互”。
- en: 'Table 4: Analysis of Interaction Turns and Word Count in TextileBots: The Assistant
    TextileBot displayed the highest frequency of interaction turns but the lowest
    word counts per turn both by the participants and Assistant TextileBot itself,
    as compared to others. In contrast, the Expert TextileBot exhibited the reverse
    behaviour. *In our study, each participant gathers one-third of the information
    using a bot, totaling 30 Info gathering sessions. The average number of turns
    is calculated from 10 complete sessions for each bot.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '表 4: 《TextileBots》的互动轮次和词数分析：助理 TextileBot 显示出最高的互动轮次频率，但在每轮的词数上，无论是参与者还是助理
    TextileBot 本身，都低于其他 Bot。相比之下，专家 TextileBot 展现了相反的行为。*在我们的研究中，每位参与者使用一个 Bot 收集三分之一的信息，总计
    30 次信息收集会话。平均轮次是从每个 Bot 的 10 次完整会话中计算得出的。*'
- en: '|  | Number of turns | Word counts per turn |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '|  | 轮次数 | 每轮词数 |'
- en: '|  | Overall | Free-chatting | Info gathering* | Participants utterances |
    Bot utterances |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '|  | 总体 | 自由聊天 | 信息收集* | 参与者发言 | Bot 发言 |'
- en: '| Vanilla | 13.77 ± 6.29 | 12.6 | 11.7 | 11.78 ± 8.06 | 44.53 ± 22.69 |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| Vanilla | 13.77 ± 6.29 | 12.6 | 11.7 | 11.78 ± 8.06 | 44.53 ± 22.69 |'
- en: '| Expert | 11.03 ± 3.7 | 7.6 | 11.2 | 12.11 ± 8.45 | 61.52 ± 23.74 |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| 专家 | 11.03 ± 3.7 | 7.6 | 11.2 | 12.11 ± 8.45 | 61.52 ± 23.74 |'
- en: '| Assistant | 17.6 ± 10.19 | 9.5 | 14 | 11.43 ± 9.20 | 37.29 ± 37.29 |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| 助理 | 17.6 ± 10.19 | 9.5 | 14 | 11.43 ± 9.20 | 37.29 ± 37.29 |'
- en: 6.3.1 Conversation turns
  id: totrans-219
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.3.1 对话轮次
- en: The dialogues contained a total of 1272 conversational turns. Each turn denotes
    an exchange of utterances, representing a pairwise dialogue between a participant
    and the agent. On average, a dialogue comprised 799.40 words (SD=317.53) and 14.13
    turns (SD=7.95). As we discussed earlier, tracking the number of conversation
    turns between the participant and the conversational agent can provide insights
    into the depth and length of interactions. Higher turn counts indicate more engaged
    participants [[67](#bib.bib67), [66](#bib.bib66)].
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 对话总共有 1272 个对话轮次。每轮表示一次发言的交换，代表参与者和智能体之间的对话。平均而言，每次对话包含 799.40 个词（标准差=317.53）和
    14.13 轮（标准差=7.95）。正如我们之前讨论的那样，跟踪参与者和对话智能体之间的对话轮次可以提供有关互动深度和长度的见解。更高的轮次数表明参与者更加投入
    [[67](#bib.bib67), [66](#bib.bib66)]。
- en: Turn-taking comparison across agents
  id: totrans-221
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 轮次对比各智能体
- en: 'As illustrated in Table [4](#S6.T4 "Table 4 ‣ 6.3 Dialogue analysis of the
    voice-based human-agent interaction ‣ 6 Results ‣ LLM-Mediated Domain-Specific
    Voice Agents: The Case of TextileBot") and Figure [10(a)](#S6.F10.sf1 "In Figure
    10 ‣ 6.3.2 Word count in each turn ‣ 6.3 Dialogue analysis of the voice-based
    human-agent interaction ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot"), it is evident that the Assistant agent garners the highest
    level of participant engagement, whereas participants tend to exhibit lower levels
    of engagement with the Vanilla agent. These results indicate that there are statistically
    significant differences in the number of turns between the Assistant agent and
    the other two agents, but not between the Vanilla and Expert agents.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 如表 [4](#S6.T4 "表 4 ‣ 6.3 语音基础人机交互对话分析 ‣ 6 结果 ‣ 基于 LLM 的特定领域语音代理：以 TextileBot
    为例") 和图 [10(a)](#S6.F10.sf1 "图 10 ‣ 6.3.2 每轮词数 ‣ 6.3 语音基础人机交互对话分析 ‣ 6 结果 ‣ 基于
    LLM 的特定领域语音代理：以 TextileBot 为例") 所示，显然助理智能体获得了最高的参与者参与度，而参与者对 Vanilla 智能体的参与度则较低。这些结果表明，助理智能体与其他两个智能体之间的轮次数存在统计学上显著的差异，但
    Vanilla 智能体和专家智能体之间则没有。
- en: Single vs Multi-turn conversations
  id: totrans-223
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 单轮对比多轮对话
- en: 'Smart voice assistants, such as Alexa and Google Assistant, are generally limited
    to single-turn conversations due to their lack of memory. In contrast, our design
    incorporates a memory function, prompting an investigation into whether participants
    can engage naturally in this novel interaction pattern. Multi-turn conversation
    refers to an interaction style whereby multiple rounds of queries and responses
    revolve around the same topic, while single-turn conversation pertains to a scenario
    where only a single query and response take place regarding a specific topic.
    We have identified two distinct forms of vHAI: single-turn query & response and
    multi-turn (dyadic) dialogue. Among the 30 participants, 29 were naturally engaged
    in multi-turn dialogues to varying extents.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 智能语音助手，如Alexa和Google Assistant，由于缺乏记忆功能，通常限制于单轮对话。相比之下，我们的设计融入了记忆功能，促使我们探究参与者是否能自然地参与这种新颖的交互模式。多轮对话指的是一种交互风格，其中多个回合的询问和回应围绕同一主题进行，而单轮对话则指的是仅就特定主题进行一次询问和回应的情境。我们识别出了两种不同形式的虚拟人类-代理交互（vHAI）：单轮询问与回应以及多轮（双向）对话。在30名参与者中，有29人自然地参与了不同程度的多轮对话。
- en: 6.3.2 Word count in each turn
  id: totrans-225
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.3.2 每回合的单词数
- en: 'We further investigated the number of words in both participants’ and agents’
    utterances in each turn, shown in Table [4](#S6.T4 "Table 4 ‣ 6.3 Dialogue analysis
    of the voice-based human-agent interaction ‣ 6 Results ‣ LLM-Mediated Domain-Specific
    Voice Agents: The Case of TextileBot"). The Vanilla agent has an average of 11.78
    words (SD=8.06), the Expert has 12.11 (SD=8.45), and the Assistant has 11.43 words
    (SD=9.20). The maximum words participants spent were 78, 61, and 111 respectively
    on these three agents. Regarding the responses from TextileBot. The Vanilla agent
    has an average of 44.53 words (SD=22.69), the Expert has 61.52 (SD=23.74), and
    the Assistant has an average of 37.29 words (SD=18.31).'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进一步调查了每回合中参与者和代理的发言单词数，如表[4](#S6.T4 "表4 ‣ 6.3 基于语音的人类-代理交互对话分析 ‣ 6 结果 ‣ LLM-中介领域特定语音代理：以TextileBot为例")所示。Vanilla代理的平均单词数为11.78（SD=8.06），Expert为12.11（SD=8.45），Assistant为11.43（SD=9.20）。参与者在这三个代理上的单词数最多分别为78、61和111。关于TextileBot的回应，Vanilla代理的平均单词数为44.53（SD=22.69），Expert为61.52（SD=23.74），Assistant的平均单词数为37.29（SD=18.31）。
- en: '![Refer to caption](img/676dabc5912cf391a0652a65c6a9296c.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/676dabc5912cf391a0652a65c6a9296c.png)'
- en: (a) Numbers of turns per participant across three agents.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 三个代理中每个参与者的回合数。
- en: '![Refer to caption](img/ea5b776c57635783782127af787153d3.png)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/ea5b776c57635783782127af787153d3.png)'
- en: (b) overall trends for lengths of turns
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 回合长度的总体趋势
- en: 'Figure 10: Left: Figure (a) shows the number of turns per participant across
    three agents. Right: Figure (b) illustrates the word count per turn, smoothed
    using a moving average for each agent, against different turn numbers.'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：左图：图(a)显示了每个参与者在三个代理中的回合数。右图：图(b)展示了每个回合的单词数，使用移动平均法对每个代理的数据进行了平滑处理，并对不同的回合数进行了对比。
- en: 'The trend for participant’s word usage across agents involves calculating a
    moving average with a window size of four, and this smoothed data is depicted
    in Figure [10(b)](#S6.F10.sf2 "In Figure 10 ‣ 6.3.2 Word count in each turn ‣
    6.3 Dialogue analysis of the voice-based human-agent interaction ‣ 6 Results ‣
    LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot"). Observing
    the data, a noticeable pattern emerges: participants’ initial utterances with
    fewer words gradually increased their words in the early turns. The duration peak,
    or hold time, represents the duration for which the agents can sustain participant
    engagement. Towards the end, the curve shows a decline, suggesting a decrease
    in participant engagement as they gradually speak fewer words.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者在不同代理中的单词使用趋势涉及到计算窗口大小为四的移动平均，这些平滑的数据在图[10(b)](#S6.F10.sf2 "图10 ‣ 6.3.2 每回合的单词数
    ‣ 6.3 基于语音的人类-代理交互对话分析 ‣ 6 结果 ‣ LLM-中介领域特定语音代理：以TextileBot为例")中显示。观察这些数据，可以看出一个显著的模式：参与者在早期回合中使用的单词逐渐增加。持续时间峰值或保持时间，表示代理可以维持参与者参与的时间。到最后，曲线显示出下降，表明随着参与者逐渐减少单词，参与度下降。
- en: 6.4 Conversational styles
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.4 对话风格
- en: Beyond the overview of dialogues, we explore the conversational styles in the
    dialogues and conversational turns over time. Deborah Tannen [[88](#bib.bib88)]
    describes conversational styles “is comprised of the habitual use of specific
    linguistic devices, chosen by reference to broad operating principles or conversational
    strategies”.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 除了对对话的概述，我们还探讨了对话中的交际风格和对话轮次的变化。Deborah Tannen [[88](#bib.bib88)] 描述了交际风格，“由特定语言手段的习惯性使用组成，这些手段是根据广泛的操作原则或对话策略选择的”。
- en: 6.4.1 Conversational styles change over time
  id: totrans-235
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.4.1 交际风格随着时间的推移而变化
- en: Across all agents, we noticed a similar trend of changes over time. The complexity
    of participants’ queries increased over time. In other words, participants began
    with straightforward queries and progressed to more complex ones. Initially, participants
    prefer using straightforward queries that are concise, direct, and easy to understand
    and respond to. These queries seek simple and concise answers without requiring
    elaborations [[82](#bib.bib82)], the phrases commonly start with “What is”, “What
    are”, e.g., “What fiber is cotton made from?” .
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有代理中，我们注意到随着时间的推移出现了类似的变化趋势。参与者的提问复杂度随着时间的推移而增加。换句话说，参与者从简单的提问开始，逐渐过渡到更复杂的问题。一开始，参与者更倾向于使用简单、直接且易于理解和回答的提问。这些提问寻求简洁明了的答案，不需要详细阐述
    [[82](#bib.bib82)]，短语通常以“What is”，“What are”开头，例如，“棉花是由什么纤维制成的？”。
- en: 'As the conversation progressed, we observed a shift towards more complex queries,
    such as posing chained queries (P28-Expert: “So what if I want to help you to
    persuade the whole community to use in textile circularity? What would be the
    strategy? How should I get involved into the community to try to persuade more
    people be aware of this issue?”) and lengthy information (P10-Assistant: “what
    is the advantage over organic material over other types of material is it more
    sustainable or is more healthy or is more I don’t know like is there any other
    properties that you can mention I can actually make it the top trending material
    that’s used during this generation”).'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '随着对话的进行，我们观察到对更复杂的提问的倾斜，例如提出链式问题（P28-Expert: “那么如果我想帮助你说服整个社区在纺织品循环利用方面采取行动呢？那策略是什么？我应该如何参与社区以尝试说服更多人关注这个问题？”）和详细的信息（P10-Assistant:
    “与其他类型的材料相比，有机材料有什么优势？它更可持续，还是更健康，或者还有其他属性可以提及？我实际上可以让它成为当代最受欢迎的材料”）。'
- en: '{dialogue} First bot Vanilla GPT-3.5 model Bot Hi there, I’m TextileBot … How
    can I assist you today? Human Hello, I would like to learn more about the circular
    economy in the textile industry. … Human What is the percentage between, the ratio
    between production and recycling in India in relation to cotton? Second bot Expert
    Bot Hi there, I’m TextileBot … How can I assist you today? Human How do you think
    AI can be used to support and improve the textile systemarity?'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '{dialogue} 第一个机器人 Vanilla GPT-3.5模型 机器人 你好，我是TextileBot … 今天我能帮你做什么？ 人类 你好，我想了解更多关于纺织行业中的循环经济。
    … 人类 印度在棉花生产和回收之间的比例是多少？ 第二个机器人 Expert 机器人 你好，我是TextileBot … 今天我能帮你做什么？ 人类 你认为人工智能如何能用来支持和改善纺织系统？'
- en: … Human Do you know what is the percentage of clothes from big brands like the
    fast fashion industry like Zara and H&M that are actually sold in the same production
    here? Third bot Assistant Bot Hi there, I’m TextileBot … How can I assist you
    today? Human Can you name some fashion companies that are big players in the fashion
    society? … Human So it was introduced in 2015 and it’s still something that’s
    available.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: … 人类 你知道像Zara和H&M这样的快时尚行业中的大品牌的衣物中，有多少实际在同一生产地销售吗？ 第三个机器人 Assistant 机器人 你好，我是TextileBot
    … 今天我能帮你做什么？ 人类 你能说出一些在时尚界中的大玩家吗？ … 人类 所以它是在2015年推出的，至今仍然可用。
- en: 'Figure 11: The three dialogues of P22 demonstrate a progression from the starting
    point to a later stage with Vanilla, Expert, Assistant, respectively.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：P22的三个对话展示了从起始点到后期阶段的进展，分别是Vanilla、Expert、Assistant。
- en: 'Regarding the content, the example in Figure [11](#S6.F11 "Figure 11 ‣ 6.4.1
    Conversational styles change over time ‣ 6.4 Conversational styles ‣ 6 Results
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot") illustrates
    how participants’ queries progressed with each agent. Participants moved from
    general ( P27-Assistant: “Tell me the basics about textiles.”) to specific (P27-Assistant:
    “Can you still make nylon or polyester without petrol?”) and from factual (P23-Assistant:
    “How to wash my clothes with the oil on it.”) to subjective queries (P23-Assistant:
    “What’s your opinion on Uniqlo?”), which aligned with the findings in Section
    [6.2](#S6.SS2 "6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated Domain-Specific
    Voice Agents: The Case of TextileBot"). These progressions in query complexity
    echoed Wilson’s information seeking model [[102](#bib.bib102)].'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '关于内容，图示[11](#S6.F11 "Figure 11 ‣ 6.4.1 Conversational styles change over time
    ‣ 6.4 Conversational styles ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot")展示了参与者查询随着每个代理人的变化。参与者的查询从一般性（P27-Assistant: “告诉我关于纺织品的基础知识。”）转向具体性（P27-Assistant:
    “你还能在不使用石油的情况下制作尼龙或聚酯吗？”），从事实性（P23-Assistant: “如何洗掉衣服上的油。”）转向主观性查询（P23-Assistant:
    “你对优衣库有什么看法？”），这与第[6.2](#S6.SS2 "6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot")节的发现一致。这些查询复杂性的进展反映了Wilson的信息寻求模型[[102](#bib.bib102)]。'
- en: 6.4.2 Code-switching
  id: totrans-242
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.4.2 语言转换
- en: 'Code-switching, also known as language alternation, is a phenomenon that frequently
    occurs in multilingual individuals and is formally referred to as changing the
    language used in conversation. As sociolinguists have defined [[44](#bib.bib44)],
    it is now widely acknowledged as the way people select their “linguistic repertoire”
    [[15](#bib.bib15), [40](#bib.bib40)] based on situational demands. We here refer
    to code-switching as the language alternation of the participants, which includes
    the formulation of queries and variations in tone. Participants tend to use code-switching
    to elicit their desired response. For example, in Figure [5](#S3.F5 "Figure 5
    ‣ 3.3 Phase 3: Enable continuous LLM interaction with memory through System Optimization
    ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot") it is evident that participants applied code-switching
    to assess the agent’s capabilities. In computer science terms, this behaviour
    can be likened to participants testing with various prompts to evaluate the LLMs.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '语言转换，也称为语言交替，是一种在多语言个体中经常发生的现象，正式称为对话中语言的变化。正如社会语言学家定义的[[44](#bib.bib44)]，它现在被广泛认可为人们根据情境需求选择其“语言
    repertory”的方式[[15](#bib.bib15), [40](#bib.bib40)]。我们在这里将语言转换指参与者的语言交替，包括查询的形成和语调的变化。参与者倾向于使用语言转换来引出他们期望的回应。例如，在图示[5](#S3.F5
    "Figure 5 ‣ 3.3 Phase 3: Enable continuous LLM interaction with memory through
    System Optimization ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot")中，可以明显看出参与者使用语言转换来评估代理人的能力。在计算机科学术语中，这种行为可以类似于参与者使用各种提示来评估LLM。'
- en: 6.4.3 Social protocol
  id: totrans-244
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.4.3 社交礼仪
- en: Following Völkel et al. [[94](#bib.bib94)], social protocol as an exchange of
    polite conventions or obligations, such as saying “hi”, “thank you”, “please”,
    a form of general information (e.g., “Nice”). 76.7% of participants (N=23) had
    at least one social protocol with the agent, 56.7% participants (N=17) used “thank
    you” or “please”, 50% participant (N=15) greeted the agent at the beginning of
    their conversation, e.g. “Hello, what is your name?” (P13), but most of them did
    not do so in all interactions with every agent. 23.3% participant (N=7) appreciated
    or affirmed agent’s answer, most of them occurred with Assistant, such as “that’s
    good to know” (P20-Assistant/Vanilla), “You’re a good guy.” (P5-Assistant), “Wow,
    sounds amazing.” (P37-Assistant). Unfortunately, none of those acknowledgements
    were given to Expert.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 根据Völkel等人的研究[[94](#bib.bib94)]，社交礼仪作为礼貌习惯或义务的交换，如说“你好”、“谢谢”、“请”，是一种一般信息的形式（例如，“很高兴”）。76.7%的参与者（N=23）在与代理人互动时至少使用过一种社交礼仪，56.7%的参与者（N=17）使用了“谢谢”或“请”，50%的参与者（N=15）在对话开始时向代理人打招呼，例如“你好，你叫什么名字？”（P13），但他们大多数并未在所有与每个代理人的互动中都这样做。23.3%的参与者（N=7）对代理人的回答表示赞赏或肯定，大多数发生在助理（Assistant）中，如“知道这些很好”（P20-Assistant/Vanilla），“你是个好人。”（P5-Assistant），“哇，听起来很棒。”（P37-Assistant）。不幸的是，这些确认没有给予专家（Expert）。
- en: 6.4.4 Variations of utterances across agents
  id: totrans-246
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.4.4 话语在不同代理人之间的变异
- en: 'We further investigate if the conversational styles are varied across agents.
    We found that participants tend to pose detailed queries with clear instructions
    and relatively formal language with Expert, for instance P12 stated “Can you tell
    me more about what’s going on in one of those countries with a lot of textile
    waste from northern countries? Can you tell me more about how a specific country
    deals with the textile they receive?”. This may indicate the reason for the average
    word spend is slightly more with Expert in (refer to Section [6.3.2](#S6.SS3.SSS2
    "6.3.2 Word count in each turn ‣ 6.3 Dialogue analysis of the voice-based human-agent
    interaction ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case
    of TextileBot")).'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进一步调查了对话风格是否在不同代理间有所变化。我们发现，参与者倾向于对 Expert 提出详细的查询，并使用清晰的指示和相对正式的语言。例如，P12
    说“你能详细讲讲那些来自北方国家的纺织废料在某些国家的情况吗？你能多讲讲某个特定国家如何处理它们收到的纺织品吗？”这可能表明 Expert 平均用词量略高的原因（参见第
    [6.3.2](#S6.SS3.SSS2 "6.3.2 每轮的字数 ‣ 6.3 基于语音的人机对话分析 ‣ 6 结果 ‣ LLM 媒介的领域特定语音代理：以
    TextileBot 为例")）。
- en: In the dialogue with Assistant, the conversational style people phrased their
    queries ranged from formal, complete sentences, to more conversation-like utterances.
    This reflects varying social protocols for interacting with agents, but it also
    shows the Assistant agent’s effectiveness in engaging participants in a more natural
    and less formalistic dialogue.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在与 Assistant 的对话中，人们提出查询的风格从正式的完整句子到更具对话性质的表达不一。这反映了与代理互动的社会协议的多样性，但也展示了 Assistant
    代理在更自然和少正式对话中吸引参与者的效果。
- en: Similarly, participants’ queries with the Vanilla agent were less formal compared
    to the Expert. It is worth noting that two multi-turn dialogues led to arguments
    with rude utterances. P21 even went as far as to state “That is absolutely bullshit.
    Who told you that? Why do you believe him?” when Vanilla claimed it is programmed
    by experienced programmers and “My programmer believes that having an English
    accent gives me a more sophisticated, knowledgeable and intelligent persona.”.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，参与者对 Vanilla 代理的查询比对 Expert 的查询不那么正式。值得注意的是，两次多轮对话导致了争论和粗鲁的言辞。P21 甚至表示“那完全是胡说八道。是谁告诉你的？你为什么相信他？”当
    Vanilla 声称它由经验丰富的程序员编程，并且“我的程序员相信拥有英国口音让我显得更有文化、更有知识和智慧”的时候。
- en: 6.5 Human behaviour and reactions
  id: totrans-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.5 人类行为和反应
- en: 'Diving further into participants’ engagement with the agents in the dialogues,
    our data shows that one-third of participants (N=10) used the phrase, “tell me
    more …” at least once. All participants (N=30) were seeking clarifications in
    the free chatting phase (e.g. P14-Vanilla: “What do you mean by promote sustainability?”
    P28-Assistant: “Please tell me more about it”). These instances suggest a demand
    for additional detailed explanations. The Assistant, Expert, and Vanilla agents
    received such requests in 6.1%, 4.7%, and 4.5% of interactions, respectively.
    Whereas only 63.3% participants (N=19) sought clarification in the information
    seeking phase. For instance, P25-Vanilla “I think the example you gave is very
    high level. Is there any more detailed example you can give me?”. The information-seeking
    phase witnessed an increased number of clarifications, as the name suggests, totalling
    32.1% with the Assistant, 24.1% with the Expert, 17.9% with the Vanilla. This
    could be because the Assistant tends to respond in a concise style, where participants
    desire more elaboration.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '深入探讨参与者与对话代理的互动，我们的数据表明，三分之一的参与者（N=10）至少使用过一次“tell me more …”这个短语。所有参与者（N=30）在自由聊天阶段都在寻求澄清（例如
    P14-Vanilla: “你所说的推动可持续性是什么意思？” P28-Assistant: “请详细说明一下”）。这些实例表明对详细解释的需求。Assistant、Expert
    和 Vanilla 代理分别在 6.1%、4.7% 和 4.5% 的互动中接到了这样的请求。而在信息寻求阶段，仅有 63.3% 的参与者（N=19）寻求澄清。例如，P25-Vanilla
    说“我认为你给出的例子很高层次。你能给我一个更详细的例子吗？”。信息寻求阶段的澄清次数有所增加，总体达到 32.1%（Assistant）、24.1%（Expert）、17.9%（Vanilla）。这可能是因为
    Assistant 倾向于以简洁的风格回应，参与者希望获得更多的详细解释。'
- en: Moreover, it was interesting to observe how participants reacted to agent errors.
    This was captured by the main experimenter through note-taking during the study
    and dialogue between the participants and agents. 30% participants (N=9) encountered
    agent errors such as failures in Automatic Speech Recognition (ASR) or a lack
    of understanding in response to participant queries. Out of those participants,
    77.8% (N=7) participants actively corrected the agent by explicitly stating the
    misunderstanding, repeating or rephrasing their queries, e.g. P15 stating “No,
    I meant - what materials are you made of?”. Other strategies encompassed terminating
    the conversation, shifting to a different topic, or progressing with the agent.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，观察参与者如何对代理错误做出反应也很有趣。这通过主要实验者在研究期间的记笔记和参与者与代理之间的对话得以记录。30%的参与者（N=9）遇到了代理错误，如自动语音识别（ASR）失败或对参与者查询缺乏理解。在这些参与者中，77.8%（N=7）的参与者通过明确指出误解、重复或重新表述他们的查询来积极纠正代理，例如P15表示“不是，我的意思是——你是由什么材料做的？”。其他策略包括结束对话、转移话题或继续与代理互动。
- en: Since LLMs can produce both plausible-sounding and incorrect or nonsensical
    answers [[106](#bib.bib106)], participants encountered such situations. Some participants
    (N=5) contested the agents, and tried to convince or educate the agent to correct
    its answer. On one occasion, a participant expressed discontent when the Assistant
    agent was repetitive about sustainable suggestions. The participant pointed out,
    “Yeah, but if you repeat yourself, sometimes people think that you’re talking
    down to them.”. The agent then acknowledged the feedback and apologized.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 由于LLM可以产生看似合理但实际上不正确或无意义的回答[[106](#bib.bib106)]，参与者遇到了这样的情况。一些参与者（N=5）对代理提出了质疑，尝试说服或教育代理纠正其答案。在一次情况下，当助手代理在关于可持续建议方面重复时，参与者表示不满。参与者指出，“是的，但如果你重复自己，有时人们会觉得你在指责他们。”。代理随后承认了反馈并表示歉意。
- en: 'Participants also challenged some of the agents’ responses and 40% participants
    (N=12) explicitly expressed their skepticism and mistrust towards LLM-mediated
    agents. Some participants (N=5) addressed their concern by asking “Are you sure
    …?” and continued to ask for more evidence from the agent on the topic of the
    conversation. P15 even went as far as to state “That is where you’re wrong, my
    friend.”, when the participant was unhappy with the responses and decided to finish
    the conversation in the free chatting phase and move to the information seeking
    part. It was interesting to observe, that arguments and skepticism were more prevalent
    in the conversation with the Expert agent. This may be due to the lengthy response
    style, where participants mentioned losing interest. We observed that a strategy
    participants used to verify if the agent was making up their answer or not was
    by asking some facts they knew. Below is an example:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者还对一些代理的回应提出了质疑，40%的参与者（N=12）明确表达了他们对LLM媒介代理的怀疑和不信任。一些参与者（N=5）通过询问“你确定吗……？”来表达他们的担忧，并继续要求代理提供更多证据。P15甚至进一步表示“这就是你错的地方，我的朋友。”，当参与者对回应不满意并决定在自由聊天阶段结束对话并转到信息寻求阶段时。这种情况特别在与专家代理的对话中更为常见，可能是由于回应风格较长，参与者提到他们失去了兴趣。我们观察到，参与者用来验证代理是否在编造答案的策略是通过询问他们知道的一些事实。以下是一个例子：
- en: 'p11: Are real numbers countable? Assistant: I’m sorry, I’m not familiar with
    real numbers. Could you help me understand what they are? I can help you find
    sustainable clothing options, if you’d like. p11: Do you know what rational numbers
    are? Assistant: Yes, rational numbers are numbers that can be expressed as a fraction
    or ratio, such as 1/2 or 3:4\. Would you like to know more about sustainable clothing?
    p11: back to your previous question, real numbers are the completion of the rational
    numbers.'
  id: totrans-255
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'p11: 实数是可数的吗？助手：对不起，我不熟悉实数。您能帮助我理解它们是什么吗？如果你愿意，我可以帮助你找到可持续的服装选项。p11: 你知道什么是有理数吗？助手：是的，有理数是可以表示为分数或比率的数字，如1/2或3:4。你想了解更多关于可持续服装的信息吗？p11:
    回到你之前的问题，实数是有理数的完备。'
- en: 7 Discussion & Future Directions
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 讨论与未来方向
- en: This work introduces a novel three-phase approach to prototyping domain-specific
    voice agents using LLMs. We assessed our method by implementing a voice agent
    on an actual device, TextileBot, specifically focusing on textiles circularity,
    and conducted an in-depth user study. In this discussion, we first analyze the
    effectiveness of our approach, drawing upon evaluation metrics and dialogue analysis.
    We then explore comprehensive insights derived from the dialogue analysis, questionnaire
    responses, and overall participant feedback. This exploration aims to deepen our
    understanding of human perceptions, engagement, and interactions with LLM-mediated,
    prompt-based voice agents. Finally, we reflect on the key lessons learned from
    this design process and discuss their broader implications for the HCI community.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究提出了一种新颖的三阶段方法，用于使用 LLM 原型设计特定领域的语音代理。我们通过在实际设备 TextileBot 上实施语音代理来评估我们的方法，特别关注纺织品的循环性，并进行了深入的用户研究。在此讨论中，我们首先分析我们方法的有效性，依托评估指标和对话分析。然后，我们探讨从对话分析、问卷反馈和整体参与者反馈中获得的全面见解。这一探索旨在加深我们对人类感知、参与和与
    LLM 介导的基于提示的语音代理互动的理解。最后，我们反思这一设计过程中的关键经验教训，并讨论其对 HCI 社区的更广泛影响。
- en: 7.1 The effectiveness of the method
  id: totrans-258
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1 方法的有效性
- en: The effectiveness of prompting LLMs has been widely studied [[49](#bib.bib49),
    [60](#bib.bib60), [14](#bib.bib14)], using standard metrics, such as perplexity
    and the BLEU score [[73](#bib.bib73)]. However, all of these metrics are objective
    evaluations that fail to capture the nuanced human-LLM interactions. In our research,
    we adopt a human-centred AI design approach with human-in-the-loop to evaluate
    prompt-based LLM-mediated voice agents. We conducted a subjective user study that
    combined both heuristics conversational agents evaluation metrics [[51](#bib.bib51),
    [86](#bib.bib86), [65](#bib.bib65), [92](#bib.bib92)] and human-LM interaction
    metrics [[55](#bib.bib55), [99](#bib.bib99)]. This approach allowed us to integrate
    quantitative data and qualitative insights, offering a more holistic understanding
    of the voice agent’s effectiveness. We are interested in whether participants
    can identify the conversational agents’ characteristics as intended in our design,
    particularly in terms of restricting the agent’s conversational domain and personality.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 提示 LLM 的有效性已经被广泛研究[[49](#bib.bib49), [60](#bib.bib60), [14](#bib.bib14)]，使用了诸如困惑度和
    BLEU 分数[[73](#bib.bib73)]等标准指标。然而，所有这些指标都是客观评估，未能捕捉到细微的人机 LLM 互动。在我们的研究中，我们采用了以人为中心的
    AI 设计方法，并结合了人的参与来评估基于提示的 LLM 介导的语音代理。我们进行了主观用户研究，结合了启发式对话代理评估指标[[51](#bib.bib51),
    [86](#bib.bib86), [65](#bib.bib65), [92](#bib.bib92)]和人机互动指标[[55](#bib.bib55),
    [99](#bib.bib99)]。这种方法使我们能够整合定量数据和定性见解，从而提供对语音代理有效性的更全面理解。我们关注参与者是否能识别出我们设计中预期的对话代理特征，特别是在限制代理的对话领域和个性方面。
- en: 'Our results showed no statistically significant differences across three agent
    ratings for their Coherence, Ease to use and Change over time metrics (Section
    [6.1](#S6.SS1.SSS0.Px2 "Cross-metrics interactions ‣ 6.1 Questionnaire results
    ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")).
    The results indicate that prompting does not have a significant impact on the
    Ease of Use, Coherence, and Change over Time in the interaction between TextileBots
    and users. We found that all three agents are nearly equal in these comparison
    dimensions. This is an encouraging result, as it demonstrates that prompting does
    not have a detrimental effect on these dimensions for the type and level of prompting
    tested in this experiment.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的结果显示，三个代理在其连贯性、易用性和随时间变化指标上的评分之间没有统计学上显著的差异（详见第[6.1](#S6.SS1.SSS0.Px2 "跨指标交互
    ‣ 6.1 问卷结果 ‣ 6 结果 ‣ LLM-介导的特定领域语音代理：以 TextileBot 为例")节）。结果表明，提示对 TextileBots 与用户之间的易用性、连贯性和随时间变化的互动没有显著影响。我们发现这三种代理在这些比较维度上几乎相等。这是一个令人鼓舞的结果，因为它表明，在本实验中测试的提示类型和水平对这些维度没有不利影响。
- en: 'On the other hand, the prompts design significantly influenced user engagement
    and perception (Figure [9(a)](#S6.F9.sf1 "In Figure 9 ‣ Cross-metrics interactions
    ‣ 6.1 Questionnaire results ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot")). The Expert, despite its design for detailed and domain-specific
    responses in textiles circularity, faced criticism for its lengthy and persuasive
    replies, hindering user engagement. Yet, this critique aligns with our intention
    for the Expert to provide “response in a detailed manner”, validating the effectiveness
    of our Taxonomy-based Knowledge Structure Chain. Interestingly, while the Expert
    had a negative impact on engagement levels, it was not considered particularly
    bad (in terms of preferences). We noted that participants recognized its utility
    in textiles circularity domain, aligning with its intended role as a domain-specific
    “TextileBot”.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，提示设计显著影响了用户的参与度和感知（图[9(a)](#S6.F9.sf1 "图9 ‣ 交叉度量互动 ‣ 6.1 问卷结果 ‣ 6 结果 ‣
    LLM驱动的领域特定语音代理：以TextileBot为例")）。尽管Expert的设计旨在提供详细和领域特定的纺织品循环回复，但其冗长且说服力强的回复受到了批评，阻碍了用户参与。然而，这一批评与我们对Expert“以详细方式回复”的意图一致，验证了我们基于分类法的知识结构链的有效性。有趣的是，尽管Expert对参与水平有负面影响，但在偏好方面并未被认为特别糟糕。我们注意到参与者认识到它在纺织品循环领域的实用性，与其作为领域特定“TextileBot”的预期角色一致。
- en: 'The results also highlight the participants’ nuanced perception of the differences
    between the Vanilla, Expert and Assistant, recognizing their distinct characteristics
    and domain-specific utilities as discussed in Section [6.2.1](#S6.SS2.SSS1 "6.2.1
    Preferences and experiences across voice agents ‣ 6.2 Overall feedback ‣ 6 Results
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot"). This indicates
    a successful differentiation in their roles and conversational styles. Overall,
    our findings demonstrate the potential of our three-phase method in transforming
    LLMs from generalist to domain-specific roles. This approach effectively manages
    the domain focus, personalities, response styles, and conversational freedom of
    voice-based conversational agents.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 结果还突显了参与者对Vanilla、Expert和Assistant之间差异的细致感知，认识到它们各自的特征和领域特定的用途，如第[6.2.1](#S6.SS2.SSS1
    "6.2.1 语音代理的偏好和经验 ‣ 6.2 总体反馈 ‣ 6 结果 ‣ LLM驱动的领域特定语音代理：以TextileBot为例")节所讨论。这表明它们在角色和对话风格上的成功区分。总体而言，我们的发现展示了我们三阶段方法在将LLMs从通用角色转变为领域特定角色方面的潜力。这种方法有效地管理了领域焦点、个性、回应风格和语音对话代理的对话自由度。
- en: 7.2 Insights into human-agent interactions and AI-powered dialogues
  id: totrans-263
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2 人类-代理互动和AI驱动对话的洞察
- en: 'This work distinguishes itself from text-based human-agent interaction because
    people behave differently when speaking and writing, as the language used for
    spoken dialogue is distinct from that in written text [[81](#bib.bib81)]. While
    voice-based interactions share some commonalities with text-based interactions,
    they differ significantly in various aspects as discussed in Section [7.3](#S7.SS3
    "7.3 Optimizing LLM-mediated voice agent design for specific domains ‣ 7 Discussion
    & Future Directions ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot").
    Our findings not only align with but also extend existing research in voice-based
    human-agent interaction (vHAI) [[38](#bib.bib38), [88](#bib.bib88), [15](#bib.bib15),
    [40](#bib.bib40), [94](#bib.bib94)], offering fresh insights into fully automated
    AI-powered conversations.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 这项工作与基于文本的人类-代理互动有所不同，因为说话和写作时人们的行为不同，口语对话使用的语言与书面文本中的语言不同[[81](#bib.bib81)]。虽然基于语音的互动与基于文本的互动有一些共性，但在各个方面的差异显著，如第[7.3](#S7.SS3
    "7.3 优化LLM驱动的语音代理设计以适应特定领域 ‣ 7 讨论与未来方向 ‣ LLM驱动的领域特定语音代理：以TextileBot为例")节所讨论。我们的发现不仅与现有的基于语音的人类-代理互动（vHAI）研究[[38](#bib.bib38),
    [88](#bib.bib88), [15](#bib.bib15), [40](#bib.bib40), [94](#bib.bib94)]相符，而且还扩展了这些研究，提供了对完全自动化AI驱动对话的新见解。
- en: The TextileBot represents a significant advancement in this realm. It achieves
    multi-turn conversations, allowing for more natural and ongoing contact compared
    to typical voice agents like Alexa, which only have single-turn memoryless interactions.
    Also, unlike domain-specific agents, which offer detailed, context-aware responses
    in particular areas, general voice assistants like Alexa answer common queries,
    providing a broader range of services, e.g. weather updating, but with less specialization.
    In our study, nearly all participants (N=29) quickly adapted to this new form
    of interaction, underscoring the inherent and instinctive nature of human communication
    as continuous multi-turn dialogue. Current voice-based agents lack the capacity
    to retain knowledge for ongoing conversations. TextileBot’s design effectively
    addresses these shortcomings, demonstrating a more realistic interaction model.
    This advancement is particularly beneficial for the HCI community, as it facilitates
    the prototyping of voice agents for more sophisticated interactions beyond simple
    single-turn exchanges. Future developments in voice agents should aim at enabling
    conscious and continuous interactions that mimic natural human dialogue.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: TextileBot 代表了这一领域的重大进展。与典型的语音助手如 Alexa 只具有单轮无记忆互动不同，它实现了多轮对话，允许更自然且持续的联系。此外，与特定领域的助手不同，后者在特定领域提供详细的、上下文感知的回应，一般语音助手如
    Alexa 回答常见问题，提供更广泛的服务，例如天气更新，但专业性较差。在我们的研究中，几乎所有参与者（N=29）都迅速适应了这种新的互动形式，这突显了人类交流本质上和直观上是连续的多轮对话。当前的语音助手缺乏保留知识以进行持续对话的能力。TextileBot
    的设计有效地解决了这些不足，展示了一个更现实的互动模型。这一进展对 HCI 社区尤为重要，因为它促进了语音助手原型的开发，以实现比简单的单轮交换更复杂的互动。未来语音助手的发展应致力于实现有意识和持续的互动，以模拟自然的人类对话。
- en: 'In conversational analysis, we noticed a significant shift in the participants’
    conversational styles [[88](#bib.bib88)] over time. They gradually began to pose
    more sophisticated queries (Section [6.4.1](#S6.SS4.SSS1 "6.4.1 Conversational
    styles change over time ‣ 6.4 Conversational styles ‣ 6 Results ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot")) and even applied code-switching
    (Section [6.4.2](#S6.SS4.SSS2 "6.4.2 Code-switching ‣ 6.4 Conversational styles
    ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot"))
    [[15](#bib.bib15), [40](#bib.bib40)] to alter their language for desired responses.
    This change is also reflected in their overall feedback, as they reported a shift
    in engagement and interaction dynamics as they became more familiar with the prompt-based
    voice agents. These findings indicate a growing confidence of participants in
    their interactions as they developed a better understanding of the agents (Section
    [6.2.2](#S6.SS2.SSS2 "6.2.2 Perceived changes over time ‣ 6.2 Overall feedback
    ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")).
    These complex changes in behaviour and interaction patterns pose a central challenge
    for autonomous voice agents, which aim to operate without the involvement of an
    experimenter. However, our study shows that LLM-mediated voice agents demonstrate
    a level of capability and flexibility in handling these dynamics. This emphasizes
    the potential of utilizing LLMs for conversational agents to effectively address
    complex human inquiries.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '在对话分析中，我们注意到参与者的对话风格 [[88](#bib.bib88)] 随时间发生了显著变化。他们逐渐开始提出更复杂的问题（第 [6.4.1](#S6.SS4.SSS1
    "6.4.1 Conversational styles change over time ‣ 6.4 Conversational styles ‣ 6
    Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")
    节），甚至应用了代码切换（第 [6.4.2](#S6.SS4.SSS2 "6.4.2 Code-switching ‣ 6.4 Conversational
    styles ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")
    节）[[15](#bib.bib15), [40](#bib.bib40)] 来改变他们的语言以获得所需的回应。这一变化也反映在他们的总体反馈中，因为他们报告了在对语音助手的提示越来越熟悉的过程中，参与度和互动动态发生了变化。这些发现表明，参与者在互动中逐渐建立了信心，因为他们对助手的理解有所提高（第
    [6.2.2](#S6.SS2.SSS2 "6.2.2 Perceived changes over time ‣ 6.2 Overall feedback
    ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")
    节）。这些复杂的行为和互动模式的变化对自主语音助手构成了核心挑战，而这些助手旨在无需实验者的参与进行操作。然而，我们的研究表明，LLM 介导的语音助手在处理这些动态方面展示了一定的能力和灵活性。这强调了利用
    LLMs 为对话代理有效应对复杂人类询问的潜力。'
- en: 'Furthermore, we observed that participants consistently employed social protocols
    [[94](#bib.bib94)] with an informal tone when interacting with the Vanilla and
    Assistant agents, but such occurrences were rare with the Expert (Section [6.4.3](#S6.SS4.SSS3
    "6.4.3 Social protocol ‣ 6.4 Conversational styles ‣ 6 Results ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot")). Additionally, there was
    a notable difference in the length of utterances and turn-taking behaviour (Section
    [6.3](#S6.SS3 "6.3 Dialogue analysis of the voice-based human-agent interaction
    ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")).
    Participants had shorter utterances and engaged in more turn-taking with the Assistant
    agent, while the Expert agent exhibited the opposite pattern. These changes in
    participant social protocols, utterance length, and turn-taking behaviour suggest
    that the level of engagement varies across these three agents. It is worth noting
    that all three TextileBots are mediated by the same LLM, with the only distinction
    being the prompts provided. This further confirmed the effectiveness of our three-phase
    prompt design as illustrated in Section [6.2.1](#S6.SS2.SSS1 "6.2.1 Preferences
    and experiences across voice agents ‣ 6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot"), and highlights that prompting
    strategies can effectively shape the personalities and capabilities of voice agents,
    thereby directly influencing user engagement.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们观察到参与者在与Vanilla和Assistant代理互动时，始终使用了带有非正式语调的社交协议[[94](#bib.bib94)]，但与Expert代理的这种情况则较为少见（见[6.4.3](#S6.SS4.SSS3
    "6.4.3 社交协议 ‣ 6.4 对话风格 ‣ 6 结果 ‣ LLM中介特定领域语音代理：以TextileBot为例")）。另外，在话语长度和轮流发言行为方面（见[6.3](#S6.SS3
    "6.3 基于语音的人机互动对话分析 ‣ 6 结果 ‣ LLM中介特定领域语音代理：以TextileBot为例")）也存在显著差异。参与者在与Assistant代理互动时话语较短且轮流发言较多，而Expert代理则表现出相反的模式。这些参与者社交协议、话语长度和轮流发言行为的变化表明，这三种代理的参与度有所不同。值得注意的是，这三种TextileBots都由相同的LLM中介，唯一的区别在于所提供的提示。这进一步确认了我们三阶段提示设计的有效性，如在[6.2.1](#S6.SS2.SSS1
    "6.2.1 各语音代理的偏好和体验 ‣ 6.2 总体反馈 ‣ 6 结果 ‣ LLM中介特定领域语音代理：以TextileBot为例")中所示，并强调了提示策略可以有效地塑造语音代理的个性和能力，从而直接影响用户参与度。
- en: 7.3 Optimizing LLM-mediated voice agent design for specific domains
  id: totrans-268
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3 为特定领域优化LLM中介语音代理设计
- en: In the previous two sections, we elaborated on the feasibility of prompting
    LLM to develop domain specific voice agents. We also noted that the prompt design
    of these voice agents critically influences user interaction. This section first
    focuses on key aspects that enhance voice agent design, specifically aiming to
    improve user engagement and the overall experience. Then summarize the lessons
    learned in using LLM for conversational agent design.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在前两节中，我们详细阐述了促使大型语言模型（LLM）开发特定领域语音代理的可行性。我们还注意到，这些语音代理的提示设计对用户互动具有关键影响。本节首先集中于增强语音代理设计的关键方面，特别是旨在提升用户参与度和整体体验。然后，总结在使用LLM进行对话代理设计时所获得的经验教训。
- en: 7.3.1 Enhancing the voice agent design
  id: totrans-270
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.3.1 提升语音代理设计
- en: Agent characteristic and user preference
  id: totrans-271
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 代理特征和用户偏好
- en: 'Participants’ preferences and interaction styles were notably influenced by
    the perceived personality and characteristics of the agents. Our results indicate
    that a greater number of participants showed increased interest in the Assistant
    agent (56.7% for Assistant, 53.3% for Vallina and 36.7% for Expert), as illustrated
    in Section [6.1](#S6.SS1.SSS0.Px3 "Ease to use and Interest change over time ‣
    6.1 Questionnaire results ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot"). This preference was further evidenced by more user interactions
    with the Assistant agent and fewer with the Expert, as detailed in Section [6.3.1](#S6.SS3.SSS1
    "6.3.1 Conversation turns ‣ 6.3 Dialogue analysis of the voice-based human-agent
    interaction ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case
    of TextileBot"). A primary factor for this preference was the agents’ conversational
    styles, with participants favouring the “human-like” response from the Assistant
    and Vanilla agents. In contrast, the Expert, characterized by a more “expert”
    tone, was less favourably received, with participants likening it to a “text-book”
    (P25) or a “smart microwave” (P10) in their feedback (Section [6.2.1](#S6.SS2.SSS1
    "6.2.1 Preferences and experiences across voice agents ‣ 6.2 Overall feedback
    ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")).
    Vanilla, while popular for its conversational freedom, faced criticism for occasional
    microaggressions and off-topic remarks, making it less suitable for specific applications
    like TextileBot, as discussed in Section [7.3.2](#S7.SS3.SSS2 "7.3.2 Lessons Learned
    for design LLM-mediated voice agent ‣ 7.3 Optimizing LLM-mediated voice agent
    design for specific domains ‣ 7 Discussion & Future Directions ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot"). Furthermore, participants
    expressed a desire for more “emotions embedded” within agent conversations (e.g.
    humour, jokes) [[61](#bib.bib61), [62](#bib.bib62), [101](#bib.bib101)] in Section
    [6.2.3](#S6.SS2.SSS3 "6.2.3 Suggestions for improvements ‣ 6.2 Overall feedback
    ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot"),
    implying a stronger preference for human-agent interactions that emulate human-like
    communication. Overall, we noticed that an appropriate level of prompting, e.g.
    add more social ability, can enhance user engagement, as seen with the Assistant
    (Section [6.2](#S6.SS2 "6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated Domain-Specific
    Voice Agents: The Case of TextileBot")). However, it is crucial to strike a balance,
    overemphasis on domain-specific details, as seen in the Expert, can detract from
    user engagement.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者的偏好和互动风格受到代理人的感知个性和特征的显著影响。我们的结果表明，更多的参与者对Assistant代理表现出更大的兴趣（Assistant为56.7%，Vanilla为53.3%，Expert为36.7%），如第[6.1节](#S6.SS1.SSS0.Px3
    "使用便捷性与兴趣变化 ‣ 6.1 问卷结果 ‣ 6 结果 ‣ LLM中介领域特定语音代理：以TextileBot为例")所示。这种偏好进一步通过与Assistant代理的更多用户互动和与Expert代理的较少互动得到证实，如第[6.3.1节](#S6.SS3.SSS1
    "6.3.1 对话轮次 ‣ 6.3 基于语音的人机互动对话分析 ‣ 6 结果 ‣ LLM中介领域特定语音代理：以TextileBot为例")所述。这种偏好的主要因素是代理人的对话风格，参与者更喜欢Assistant和Vanilla代理的“类人”响应。相反，具有更多“专家”语气的Expert反响不佳，参与者在反馈中将其比作“教科书”（P25）或“智能微波炉”（P10）（第[6.2.1节](#S6.SS2.SSS1
    "6.2.1 语音代理的偏好和体验 ‣ 6.2 总体反馈 ‣ 6 结果 ‣ LLM中介领域特定语音代理：以TextileBot为例")）。Vanilla虽然因对话自由受到欢迎，但因偶尔的微侵害和离题评论而受到批评，使其不适合像TextileBot这样的特定应用，如第[7.3.2节](#S7.SS3.SSS2
    "7.3.2 设计LLM中介语音代理的经验教训 ‣ 7.3 针对特定领域优化LLM中介语音代理设计 ‣ 7 讨论与未来方向 ‣ LLM中介领域特定语音代理：以TextileBot为例")中所讨论的。此外，参与者希望代理人的对话中能嵌入更多的“情感”（例如幽默、笑话）[[61](#bib.bib61),
    [62](#bib.bib62), [101](#bib.bib101)]，如第[6.2.3节](#S6.SS2.SSS3 "6.2.3 改进建议 ‣ 6.2
    总体反馈 ‣ 6 结果 ‣ LLM中介领域特定语音代理：以TextileBot为例")所示，这暗示了对模拟类人沟通的人机互动的更强偏好。总体而言，我们注意到适当的提示水平，例如增加更多社交能力，可以增强用户参与度，正如Assistant所展示的（第[6.2节](#S6.SS2
    "6.2 总体反馈 ‣ 6 结果 ‣ LLM中介领域特定语音代理：以TextileBot为例")）。然而，必须保持平衡，过度强调领域特定细节，如Expert所示，可能会削弱用户参与度。
- en: Short answers in a conversation
  id: totrans-273
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 对话中的简短回答
- en: We had this feedback during the pilot study, to further investigate this issue,
    we prompted Assistant to respond in limited words (short answer) to distinguish
    from others. Participants frequently commented on the verbosity of responses from
    the Expert with some expressing a desire for a feature to speed up or stop lengthy
    replies *“I wish there is a speed up and stop button.”*. This suggests that while
    detailed responses can be informative, they may overwhelm users in conversational
    contexts. Moreover, the use of ChatGPT as a foundational model for voice agents
    should be approached cautiously due to its tendency for verbosity, a result of
    training biases favouring more comprehensive answers [[87](#bib.bib87), [34](#bib.bib34)].
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在试点研究中我们收到了这一反馈，为了进一步调查此问题，我们要求助手用有限的字数（简短回答）进行回应，以便与其他助手区分开来。参与者经常评论专家回答的冗长，有些人表达了希望能有一个加速或停止冗长回复的功能的愿望*“我希望有一个加速和停止按钮。”*。这表明虽然详细的回答可以提供信息，但在对话场景中可能会让用户感到不适。此外，由于
    ChatGPT 在训练过程中倾向于冗长的回答，因此作为语音助手的基础模型使用时应谨慎 [[87](#bib.bib87), [34](#bib.bib34)]。
- en: Avoid repeating and being persuasive
  id: totrans-275
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 避免重复并进行说服
- en: 'Some participants expressed that when the agent repeatedly states the same
    domain specific content or attempts to be overly persuasive (Section [6.2](#S6.SS2
    "6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot")), their engagement with the conversation decreases. This
    issue, though sometimes inevitable in educational or specialized domains, highlights
    the need for designing voice agents with diverse and balanced responses to sustain
    user interest and trust.'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '一些参与者表示，当代理重复陈述相同领域的内容或试图过于说服时（第 [6.2](#S6.SS2 "6.2 Overall feedback ‣ 6 Results
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot") 节），他们对话的参与度会降低。这一问题虽然在教育或专业领域中有时难以避免，但突显了设计具有多样化和平衡响应的语音助手的必要性，以维持用户的兴趣和信任。'
- en: Interactive dialogue - ask back and interrupt
  id: totrans-277
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 互动对话 - 回问和打断
- en: 'Based on feedback from participants (Section LABEL:), we found that they felt
    most engaged when the agent actively asked questions, indicating a preference
    for interactive dialogue. Our participants found the conversation with TextileBot
    Expert and Assistant to be more intelligent than Google Assistant or Alexa, in
    part due to its memory function, which is achieved through our System Optimization
    (Section [3.3](#S3.SS3 "3.3 Phase 3: Enable continuous LLM interaction with memory
    through System Optimization ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot")). Moreover, a critical
    aspect of natural conversation is the ability to interrupt and interact fluidly
    [[46](#bib.bib46)]. Participants emphasized that voice agents lacking this feature
    fail to provide a truly conversational experience (Section [6.2.3](#S6.SS2.SSS3
    "6.2.3 Suggestions for improvements ‣ 6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot")). Therefore, integrating
    the ability for interactive dialogue is desired for enhancing user engagement.'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '根据参与者的反馈（第 LABEL 节），我们发现当代理主动提问时，参与者感到最为投入，这表明他们偏好互动对话。我们的参与者认为与 TextileBot
    专家和助手的对话比 Google Assistant 或 Alexa 更智能，这部分归功于其记忆功能，这一功能通过我们的系统优化实现（第 [3.3](#S3.SS3
    "3.3 Phase 3: Enable continuous LLM interaction with memory through System Optimization
    ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot") 节）。此外，自然对话的一个关键方面是能够流畅地打断和互动 [[46](#bib.bib46)]。参与者强调，缺乏此功能的语音助手无法提供真正的对话体验（第
    [6.2.3](#S6.SS2.SSS3 "6.2.3 Suggestions for improvements ‣ 6.2 Overall feedback
    ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")
    节）。因此，集成互动对话功能是提升用户参与度的关键。'
- en: 7.3.2 Lessons Learned for design LLM-mediated voice agent
  id: totrans-279
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.3.2 设计 LLM 驱动的语音助手的经验教训
- en: We distil key lessons from our experiences in employing LLMs for developing
    voice agents, highlighting their benefits and limitations.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从使用 LLM 开发语音助手的经验中提炼出关键教训，突出其优点和局限性。
- en: Fault tolerance
  id: totrans-281
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 容错性
- en: 'A significant advantage of utilizing prompted LLMs in CAs is their capacity
    for fault tolerance, particularly in correcting errors from other components like
    Automatic Speech Recognition (ASR). Our case study in textile circularity exemplifies
    this. Prompt-based agents, such as Expert and Assistant, successfully corrected
    a considerable number of ASR misrecognitions. For instance, the term ‘textile
    circularity’ was often misheard as ‘texas secularity’, ‘textile/test security’,
    or ‘regularity’, with such errors present in 62% of ASR error instances (Section
    LABEL:). Nevertheless, our Expert and Assistant reliably redirected the conversation
    back to relevant topics related to textile circularity. In contrast, the Vanilla
    showed limitations, often leading to irrelevant content and disappointing participants.
    This highlights the benefit of domain-specific awareness in LLMs, which not only
    enhances their understanding of the intended subject matter but also significantly
    improves the fault tolerance of voice agent architectures. For a more in-depth
    analysis of participant encounters with ASR errors, we discussed it in Section
    [6.5](#S6.SS5 "6.5 Human behaviour and reactions ‣ 6 Results ‣ LLM-Mediated Domain-Specific
    Voice Agents: The Case of TextileBot").'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在CA中使用提示的LLM的一个显著优势是它们的容错能力，特别是在纠正其他组件如自动语音识别（ASR）中的错误方面。我们的纺织品循环性案例研究证明了这一点。基于提示的代理，如Expert和Assistant，成功纠正了大量的ASR误识。例如，术语“纺织品循环性”常被误听为“德克萨斯州世俗性”、“纺织品/测试安全性”或“规律性”，这种错误出现在62%的ASR错误实例中（第LABEL节）。然而，我们的Expert和Assistant可靠地将对话引导回与纺织品循环性相关的话题。相比之下，Vanilla显示出局限性，常常导致无关内容，并让参与者感到失望。这突显了LLM中领域特定意识的好处，它不仅增强了对预期主题的理解，而且显著提高了语音代理架构的容错能力。关于参与者与ASR错误的互动的更深入分析，我们在第[6.5节](#S6.SS5
    "6.5 人类行为与反应 ‣ 6 结果 ‣ LLM介导的领域特定语音代理：以TextileBot为例")进行了讨论。
- en: Neutrality
  id: totrans-283
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 中立性
- en: Although recent advances in LLMs have opened up many new possibilities; however,
    they have also raised significant worries and concerns. Not only is there a fear
    of the potential harmful contents these models could produce, but the model’s
    outputs are potentially biased [[11](#bib.bib11), [55](#bib.bib55), [18](#bib.bib18),
    [36](#bib.bib36)]. For example, in our case, we must instruct the model to “provide
    a sustainable clothing suggestion regardless of gender”. This is because, based
    on our pilot study, we found that when giving dressing suggestions, the model
    is not gender-neutral and has an obvious bias. The model always gives dressing
    suggestions with a female outlook. We also observed that LLMs are not politically
    neutral; one of our participants asked a question “Who has a more fashionable
    leader, China or Russia?” The agent consistently condemned the outfit of Putin.
    Drawing from our experience, we found that prompting may help mitigate the generation
    of biased content (e.g. gender-neutrality) from the LLM. However, it is difficult
    to completely restrict all forms of biases, as bias can manifest in many different
    ways.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管最近LLM的进展开辟了许多新可能性，但它们也引发了重大担忧。不仅担心这些模型可能生成有害内容，还可能存在模型输出的潜在偏见[[11](#bib.bib11),
    [55](#bib.bib55), [18](#bib.bib18), [36](#bib.bib36)]。例如，在我们的案例中，我们必须指示模型“无论性别如何，都提供可持续的服装建议”。这是因为，根据我们的初步研究，我们发现当给出穿衣建议时，模型并不是性别中立的，而是具有明显的偏见。模型总是给出带有女性视角的穿衣建议。我们还观察到LLM在政治上并不中立；我们的一个参与者问了一个问题：“中国还是俄罗斯的领导者更有时尚感？”该代理始终谴责普京的着装。根据我们的经验，我们发现提示可能有助于减轻LLM生成偏见内容（例如性别中立性）。然而，完全限制所有形式的偏见是困难的，因为偏见可以以多种不同方式表现出来。
- en: Micro-aggression
  id: totrans-285
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 微侵害
- en: Another concern is the LLM’s propensity to generate content with micro-aggression,
    as reported by three participants who found the Vanilla somewhat aggressive or
    mean. Previous research in this area has revealed that the content generated by
    LLMs can contain micro-aggression [[47](#bib.bib47), [13](#bib.bib13)]. Properly
    crafted prompts can significantly reduce such negative occurrences, as seen in
    Assistant and Expert; thus, a strict prompting protocol is almost essential to
    prevent such issues.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是LLM生成微侵害内容的倾向，三位参与者报告称Vanilla有些具有攻击性或恶意。以往的研究显示，LLM生成的内容可能包含微侵害[[47](#bib.bib47),
    [13](#bib.bib13)]。精心设计的提示可以显著减少这些负面情况，如在Assistant和Expert中所见，因此严格的提示协议几乎是防止此类问题的必要条件。
- en: 7.4 Limitations and future work
  id: totrans-287
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4 限制与未来工作
- en: As our study is a first study in LLM-based voice agent, we highlighted a few
    limitations in our data, method and findings.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的研究是基于LLM的语音代理的首次研究，我们在数据、方法和发现中突显了一些局限性。
- en: Firstly, our findings uncovered the existence of variations in participant preferences
    with respect to the voice agents. A small group of participants exhibited a preference
    for the responses of the Expert agent due to its perceived level of detail. However,
    we also intuitively suspect that factors such as participant backgrounds, their
    professions and past experiences may have influenced this preference. To obtain
    a clearer understanding of this relationship, it could be beneficial to implement
    a larger-scale study involving a diverse participant pool. In relation to this,
    we see considerable potential in incorporating participants’ psychological traits,
    such as extroversion and introversion, along with their demographic attributes
    [[30](#bib.bib30), [97](#bib.bib97)] in future studies. We did not explore this
    research dimension, but it could offer critical insights into the correlations
    between a user’s conversational habits and their engagement with voice agents.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们的发现揭示了参与者对语音代理的偏好存在差异。一小部分参与者由于认为专家代理的回答更为详尽，表现出了对其的偏好。然而，我们也直观地怀疑，如参与者背景、职业和过去经历等因素可能影响了这种偏好。为了更清晰地理解这种关系，实施一个涉及多样化参与者群体的大规模研究可能会有所帮助。与此相关，我们看到在未来的研究中将参与者的心理特征，如外向性和内向性，以及他们的人口统计特征[[30](#bib.bib30)、[97](#bib.bib97)]纳入研究中具有相当大的潜力。我们没有探索这一研究维度，但它可能为用户的对话习惯与他们与语音代理的互动之间的相关性提供关键见解。
- en: Secondly, we excluded voice data due to ethical considerations. However, that
    is inevitably limiting our ability to tap into the wealth of insights offered
    by non-verbal cues (e.g. pitch, tone), particularly when it comes to analysing
    emotional facets (e.g. frustration, anger) as part of conversational styles [[84](#bib.bib84),
    [76](#bib.bib76)]. Despite this limitation, our work aligns with existing HCI
    research methods in CAs, encompassing both text and voice-based interactions.
    Accordingly, this limitation can be seen as an opportunity for future research
    to consider both verbal and non-verbal data for a more comprehensive understanding
    of voice-based conversations and interactions.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们由于伦理考虑排除了语音数据。然而，这不可避免地限制了我们利用非语言线索（如音调、语调）所提供的丰富见解的能力，特别是在分析情感方面（如挫折、愤怒）作为对话风格的一部分[[84](#bib.bib84)、[76](#bib.bib76)]。尽管存在这一限制，我们的工作仍然符合现有的CA领域人机交互研究方法，包括文本和语音互动。因此，这一限制可以被视为未来研究的一个机会，考虑同时使用语言和非语言数据，以更全面地理解基于语音的对话和互动。
- en: Thirdly, a subset of participants (N=4) have reported that the text-to-speech
    (TTS) voice adopted by TextileBot was too robotic, leading to less engagement.
    In general, the optimization of speech naturalness and accuracy emerged as key
    expectations from voice agents [[107](#bib.bib107)]. This feedback serves as useful
    design guidance for voice agents aiming for improved engagement and user satisfaction.
    Future research could then delve into advanced neural speech synthesis (neural
    TTS) [[59](#bib.bib59)] with varied genders and accents for personalizing the
    voice agent.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，部分参与者（N=4）报告称，TextileBot采用的文本转语音（TTS）声音过于机械，导致参与度降低。总的来说，语音自然性和准确性的优化成为语音代理的重要期望[[107](#bib.bib107)]。这些反馈为旨在提升参与度和用户满意度的语音代理提供了有用的设计指导。未来的研究可以深入探索具有多种性别和口音的先进神经语音合成（神经TTS）[[59](#bib.bib59)]，以实现语音代理的个性化。
- en: Fourthly, the agent interactions are based on a lab-based, single session. Although
    our study gave us already a richness of data and insights, an extended and repeated
    interaction with the different agents, both inside and outside laboratory environments
    would be desirable. This could provide a more nuanced understanding of the observed
    changes over time and user experiences [[93](#bib.bib93)]. Participants’ feedback
    further underlines this, as they suggested an initial increase in both engagement
    and interaction as the familiarity with the agent grew; however, this engagement
    was noted to decline towards the end of the study.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 第四，代理交互基于实验室的单次会话。虽然我们的研究已经提供了丰富的数据和见解，但与不同代理进行的扩展和重复互动，既包括实验室环境内的，也包括外部环境的，将是有益的。这可以提供对观察到的时间变化和用户体验的更细致的理解[[93](#bib.bib93)]。参与者的反馈进一步强调了这一点，因为他们建议随着对代理的熟悉度增加，最初的参与和互动都有所上升；然而，这种参与在研究的最后阶段有所下降。
- en: Lastly, three participants reported that the Vanilla TextileBot was slightly
    aggressive or potentially disrespectful. Previous research in this area has revealed
    that the content generated by LLMs can contain micro-aggression [[47](#bib.bib47),
    [13](#bib.bib13)]. Our other participants did not report this when the LLM is
    prompted appropriately; thus, a strict prompting protocol is almost essential
    to prevent such issues. Further exploration is needed to develop robust mechanisms
    that can reliably identify and prevent such offensive outputs, ensuring a safer
    and more respectful user experience.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，三位参与者报告说，Vanilla TextileBot 有些稍显激进或可能不尊重。以往的研究已经揭示，LLM 生成的内容可能包含微侵犯[[47](#bib.bib47),
    [13](#bib.bib13)]。当 LLM 得到适当提示时，我们的其他参与者没有报告这种情况；因此，严格的提示协议几乎是避免此类问题的必需。还需要进一步探索，以开发可靠的机制，能够可靠地识别和防止这些冒犯性输出，从而确保更安全、更尊重的用户体验。
- en: 8 Conclusion
  id: totrans-294
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 结论
- en: 'In this paper, we introduce a novel three-phase method to prototype domain-specific
    voice agents using prompted LLMs. Our method is structured into three phases:
    (1) imbuing LLM with domain-specific knowledge by using Taxonomy-based Knowledge
    Structure Chain; (2) transitioning the LLM from task-agnostic to domain-specific
    focused including altering the conversational style, through prompting refinements,
    and (3) integrating system optimization to allow dialogue memorization. These
    phases are flexible and can be used independently or collectively to customize
    the LLM for particular tasks. We showcase our method with TextileBot, a voice
    agent designed for discussions on textile circularity, developed in three versions:
    Vanilla, Assistant, and Expert, each providing unique conversational features.
    To evaluate the effectiveness of these LLM-powered voice agents, we conducted
    an in-person user study. Our results showed that most participants engaged in
    multi-turn conversations with the agents, with their perceptions and behaviours
    significantly differing across the three versions. The descriptive user feedback
    with three agents aligned with our design intentions, confirming the efficacy
    of our approach in developing prompt-based voice agents. Key findings from the
    study highlight a preference for voice agents that offer concise, non-repetitive,
    and interactive dialogues. This includes the ability to ask questions, interrupt,
    and remember past conversations. Additionally, participants expressed a preference
    for agents that exhibit human-like qualities, such as humour. In the subsequent
    discussion in the paper, we shared insights and experiences related to enhancing
    voice agent design, along with a discussion of the challenges and lessons learned
    when utilizing LLMs in designing voice-based CAs. We delve into the nuances of
    these interactions and their implications for the future development of voice-based
    CAs in HCI to offer a broader scope of voice interfaces across various domains.'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们介绍了一种新颖的三阶段方法，通过提示的 LLM 原型领域特定语音代理。我们的方法分为三个阶段：（1）通过使用基于分类法的知识结构链赋予 LLM
    领域特定知识；（2）将 LLM 从任务无关转换为领域特定关注，包括通过提示的改进来改变对话风格；（3）整合系统优化以实现对话记忆。这些阶段是灵活的，可以独立或集体使用，以定制
    LLM 以适应特定任务。我们通过 TextileBot 展示了我们的方法，这是一种旨在讨论纺织品循环性的语音代理，开发了三个版本：Vanilla、Assistant
    和 Expert，每个版本提供独特的对话功能。为了评估这些 LLM 驱动的语音代理的有效性，我们进行了面对面的用户研究。我们的结果表明，大多数参与者与代理进行了多轮对话，并且他们的感知和行为在三个版本之间存在显著差异。三个代理的描述性用户反馈与我们的设计意图一致，确认了我们在开发基于提示的语音代理方面方法的有效性。研究的关键发现突出了对提供简洁、不重复和互动对话的语音代理的偏好。这包括提问、打断和记住过去对话的能力。此外，参与者表达了对具有幽默等人类特质的代理的偏好。在本文随后的讨论中，我们分享了与增强语音代理设计相关的见解和经验，以及在利用
    LLM 设计基于语音的 CAs 时遇到的挑战和经验教训。我们深入探讨了这些互动的细微差别及其对未来 HCI 语音基础 CAs 发展的影响，以提供在各种领域内语音界面的更广泛视角。
- en: Acknowledgments and Disclosure of Funding
  id: totrans-296
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢与资助披露
- en: This work was supported by the UK Research and Innovation (UKRI) National Interdisciplinary
    Circular Economy Centres Research programme, as part of the Textiles Circularity
    Centre (TCC) [grant number EP/V011766/1]. For the purpose of open access, the
    author has applied a Creative Commons Attribution (CC BY) licence to any Author
    Accepted Manuscript version arising.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作得到了英国研究与创新（UKRI）国家跨学科循环经济中心研究项目的支持，作为纺织品循环中心（TCC）[资助编号 EP/V011766/1]的一部分。为了开放获取，作者对任何作者接受的手稿版本应用了创作共用署名（CC
    BY）许可证。
- en: References
  id: totrans-298
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Google aiy voice kit V1. https://aiyprojects.withgoogle.com/, 2017.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Google aiy voice kit V1. https://aiyprojects.withgoogle.com/, 2017.'
- en: '[2] Google/aiyprojects-raspbian. https://github.com/google/aiyprojects-raspbian/releases,
    2021.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Google/aiyprojects-raspbian. https://github.com/google/aiyprojects-raspbian/releases,
    2021.'
- en: '[3] OpenAI Cookbook - Techniques to improve reliability. OpenAI, 2023.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] OpenAI Cookbook - 提高可靠性的技术。OpenAI, 2023.'
- en: '[4] M. Ahn, A. Brohan, N. Brown, Y. Chebotar, O. Cortes, B. David, C. Finn,
    K. Gopalakrishnan, K. Hausman, A. Herzog, et al. Do as i can, not as i say: Grounding
    language in robotic affordances. arXiv preprint arXiv:2204.01691, 2022.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] M. Ahn, A. Brohan, N. Brown, Y. Chebotar, O. Cortes, B. David, C. Finn,
    K. Gopalakrishnan, K. Hausman, A. Herzog, 等。行事如我能，不如我说：将语言与机器人可操作性结合。arXiv 预印本
    arXiv:2204.01691, 2022.'
- en: '[5] M. Allouch, A. Azaria, and R. Azoulay. Conversational agents: Goals, technologies,
    vision and challenges. Sensors, 21(24):8448, 2021.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] M. Allouch, A. Azaria, 和 R. Azoulay. 对话代理：目标、技术、愿景与挑战。《传感器》，21(24)：8448，2021。'
- en: '[6] S. Arora, A. Narayan, M. F. Chen, L. Orr, N. Guha, K. Bhatia, I. Chami,
    F. Sala, and C. Ré. Ask Me Anything: A simple strategy for prompting language
    models, 2022.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] S. Arora, A. Narayan, M. F. Chen, L. Orr, N. Guha, K. Bhatia, I. Chami,
    F. Sala, 和 C. Ré. 任何问题问我：一种简单的语言模型提示策略，2022。'
- en: '[7] M. A. Bansal, D. R. Sharma, and D. M. Kathuria. A systematic review on
    data scarcity problem in deep learning: solution and applications. ACM Computing
    Surveys (CSUR), 54(10s):1–29, 2022.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] M. A. Bansal, D. R. Sharma, 和 D. M. Kathuria. 深度学习中的数据稀缺问题：解决方案与应用的系统评审。《ACM计算调查》（CSUR），54(10s)：1–29，2022。'
- en: '[8] S. Barke, M. B. James, and N. Polikarpova. Grounded copilot: How programmers
    interact with code-generating models. arXiv preprint arXiv:2206.15000, 2022.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] S. Barke, M. B. James, 和 N. Polikarpova. 基于场景的副驾驶：程序员如何与代码生成模型互动。arXiv
    预印本 arXiv:2206.15000，2022。'
- en: '[9] A. Baughan, X. Wang, A. Liu, A. Mercurio, J. Chen, and X. Ma. A mixed-methods
    approach to understanding user trust after voice assistant failures. In Proceedings
    of the 2023 CHI Conference on Human Factors in Computing Systems, pages 1–16,
    2023.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] A. Baughan, X. Wang, A. Liu, A. Mercurio, J. Chen, 和 X. Ma. 理解语音助手失败后用户信任的混合方法。在《2023年CHI计算机系统人因会议论文集》中，第1–16页，2023。'
- en: '[10] R. Bavaresco, D. Silveira, E. Reis, J. Barbosa, R. Righi, C. Costa, R. Antunes,
    M. Gomes, C. Gatti, M. Vanzin, et al. Conversational agents in business: A systematic
    literature review and future research directions. Computer Science Review, 36:100239,
    2020.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] R. Bavaresco, D. Silveira, E. Reis, J. Barbosa, R. Righi, C. Costa, R.
    Antunes, M. Gomes, C. Gatti, M. Vanzin 等. 商业中的对话代理：系统文献综述及未来研究方向。《计算机科学评论》，36：100239，2020。'
- en: '[11] E. M. Bender, T. Gebru, A. McMillan-Major, and S. Shmitchell. On the dangers
    of stochastic parrots: Can language models be too big? In Proceedings of the 2021
    ACM Conference on Fairness, Accountability, and Transparency, pages 610–623, 2021.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] E. M. Bender, T. Gebru, A. McMillan-Major, 和 S. Shmitchell. 随机鹦鹉的危险：语言模型是否可能过大？《2021年ACM公平性、问责制与透明度会议论文集》，第610–623页，2021。'
- en: '[12] T. Bickmore and J. Cassell. Social dialongue with embodied conversational
    agents. Advances in natural multimodal dialogue systems, pages 23–54, 2005.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] T. Bickmore 和 J. Cassell. 与具身对话代理的社交对话。《自然多模态对话系统进展》，第23–54页，2005。'
- en: '[13] R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. Arora, S. von Arx,
    M. S. Bernstein, J. Bohg, A. Bosselut, E. Brunskill, et al. On the opportunities
    and risks of foundation models. arXiv preprint arXiv:2108.07258, 2021.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. Arora, S. von Arx,
    M. S. Bernstein, J. Bohg, A. Bosselut, E. Brunskill 等. 基础模型的机会与风险。arXiv 预印本 arXiv:2108.07258，2021。'
- en: '[14] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan,
    P. Shyam, G. Sastry, A. Askell, et al. Language models are few-shot learners.
    Advances in neural information processing systems, 33:1877–1901, 2020.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A.
    Neelakantan, P. Shyam, G. Sastry, A. Askell 等. 语言模型是少量示例学习者。《神经信息处理系统进展》，33：1877–1901，2020。'
- en: '[15] B. E. Bullock and A. J. Toribio. Themes in the study of code-switching.
    The Cambridge handbook of linguistic code-switching, 117, 2009.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] B. E. Bullock 和 A. J. Toribio. 语言切换研究中的主题。《剑桥语言切换手册》，117，2009。'
- en: '[16] D. Buschek, M. Zürn, and M. Eiband. The impact of multiple parallel phrase
    suggestions on email input and composition behaviour of native and non-native
    english writers. In Proceedings of the 2021 CHI Conference on Human Factors in
    Computing Systems, pages 1–13, 2021.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] D. Buschek, M. Zürn, 和 M. Eiband. 多个平行短语建议对电子邮件输入和作文行为的影响：母语和非母语英语写作者。在《2021年CHI计算机系统人因会议论文集》中，第1–13页，2021。'
- en: '[17] T. Chakrabarty, V. Padmakumar, and H. He. Help me write a poem: Instruction
    tuning as a vehicle for collaborative poetry writing. arXiv preprint arXiv:2210.13669,
    2022.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] T. Chakrabarty, V. Padmakumar, 和 H. He. 帮我写首诗：指令调整作为协作诗歌创作的工具。arXiv 预印本
    arXiv:2210.13669，2022。'
- en: '[18] K. Chen, A. Shao, J. Burapacheep, and Y. Li. A critical appraisal of equity
    in conversational AI: Evidence from auditing GPT-3’s dialogues with different
    publics on climate change and Black Lives Matter, 2022.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] K. Chen, A. Shao, J. Burapacheep, 和 Y. Li. 对会话AI公平性的批判性评估：审计GPT-3与不同公众在气候变化和黑人的命也是命对话中的证据，2022。'
- en: '[19] X. Chen, N. Zhang, X. Xie, S. Deng, Y. Yao, C. Tan, F. Huang, L. Si, and
    H. Chen. Knowprompt: Knowledge-aware prompt-tuning with synergistic optimization
    for relation extraction. In Proceedings of the ACM Web Conference 2022, pages
    2778–2788, 2022.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] X. Chen, N. Zhang, X. Xie, S. Deng, Y. Yao, C. Tan, F. Huang, L. Si, 和
    H. Chen. Knowprompt: 知识感知提示调优与协同优化在关系提取中的应用。在 2022 年 ACM Web 会议录中，第 2778–2788
    页，2022。'
- en: '[20] R. H. B. Christensen. ordinal—regression models for ordinal data. R package
    version, 28:2015, 2015.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] R. H. B. Christensen. ordinal—用于有序数据的回归模型。R 包版本，28:2015，2015。'
- en: '[21] E. Clark, A. S. Ross, C. Tan, Y. Ji, and N. A. Smith. Creative writing
    with a machine in the loop: Case studies on slogans and stories. In 23rd International
    Conference on Intelligent User Interfaces, pages 329–340, 2018.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] E. Clark, A. S. Ross, C. Tan, Y. Ji, 和 N. A. Smith. 与机器协作的创意写作：口号和故事的案例研究。在第
    23 届国际智能用户界面会议录中，第 329–340 页，2018。'
- en: '[22] L. Clark, N. Pantidi, O. Cooney, P. Doyle, D. Garaialde, J. Edwards, B. Spillane,
    E. Gilmartin, C. Murad, C. Munteanu, et al. What makes a good conversation? challenges
    in designing truly conversational agents. In Proceedings of the 2019 CHI conference
    on human factors in computing systems, pages 1–12, 2019.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] L. Clark, N. Pantidi, O. Cooney, P. Doyle, D. Garaialde, J. Edwards, B.
    Spillane, E. Gilmartin, C. Murad, C. Munteanu, 等。什么才算是一次好的对话？设计真正会话代理的挑战。在 2019
    年 CHI 计算系统人因会议录中，第 1–12 页，2019。'
- en: '[23] M. Colucci, A. Tuan, and M. Visentin. An empirical investigation of the
    drivers of csr talk and walk in the fashion industry. Journal of Cleaner Production,
    248:119200, 2020.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] M. Colucci, A. Tuan, 和 M. Visentin. 对时尚行业中企业社会责任（CSR）话语与实践驱动因素的实证研究。清洁生产杂志，248:119200，2020。'
- en: '[24] J. Condliffe. Ai voice assistant apps are proliferating, but people don’t
    use them. Technology Review, 2017.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] J. Condliffe. AI 语音助手应用正在激增，但人们却不常使用它们。技术评论，2017。'
- en: '[25] B. R. Cowan, N. Pantidi, D. Coyle, K. Morrissey, P. Clarke, S. Al-Shehri,
    D. Earley, and N. Bandeira. ” what can i help you with?” infrequent users’ experiences
    of intelligent personal assistants. In Proceedings of the 19th international conference
    on human-computer interaction with mobile devices and services, pages 1–12, 2017.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] B. R. Cowan, N. Pantidi, D. Coyle, K. Morrissey, P. Clarke, S. Al-Shehri,
    D. Earley, 和 N. Bandeira. “我能帮你做什么？”不频繁用户对智能个人助手的体验。在第 19 届国际人机交互与移动设备服务会议录中，第
    1–12 页，2017。'
- en: '[26] N. Dahlbäck, A. Jönsson, and L. Ahrenberg. Wizard of oz studies—why and
    how. Knowledge-based systems, 6(4):258–266, 1993.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] N. Dahlbäck, A. Jönsson, 和 L. Ahrenberg. 奥兹巫师研究——为何及如何。知识基础系统，6(4):258–266，1993。'
- en: '[27] A. R. de Lacerda and C. S. Aguiar. Floss faq chatbot project reuse: how
    to allow nonexperts to develop a chatbot. In Proceedings of the 15th International
    Symposium on Open Collaboration, pages 1–8, 2019.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] A. R. de Lacerda 和 C. S. Aguiar. Floss faq 聊天机器人项目重用：如何让非专家开发聊天机器人。在第
    15 届开放协作国际研讨会录中，第 1–8 页，2019。'
- en: '[28] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. Bert: Pre-training of
    deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805,
    2018.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] J. Devlin, M.-W. Chang, K. Lee, 和 K. Toutanova. Bert: 深度双向变换器的语言理解预训练。arXiv
    预印本 arXiv:1810.04805，2018。'
- en: '[29] L. Dong, N. Yang, W. Wang, F. Wei, X. Liu, Y. Wang, J. Gao, M. Zhou, and
    H.-W. Hon. Unified language model pre-training for natural language understanding
    and generation. Advances in Neural Information Processing Systems, 32, 2019.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] L. Dong, N. Yang, W. Wang, F. Wei, X. Liu, Y. Wang, J. Gao, M. Zhou, 和
    H.-W. Hon. 统一语言模型预训练用于自然语言理解与生成。神经信息处理系统进展，32，2019。'
- en: '[30] P. R. Doyle, J. Edwards, O. Dumbleton, L. Clark, and B. R. Cowan. Mapping
    perceptions of humanness in intelligent personal assistant interaction. In Proceedings
    of the 21st international conference on human-computer interaction with mobile
    devices and services, pages 1–12, 2019.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] P. R. Doyle, J. Edwards, O. Dumbleton, L. Clark, 和 B. R. Cowan. 映射智能个人助手互动中的人性感知。在第
    21 届国际人机交互与移动设备服务会议录中，第 1–12 页，2019。'
- en: '[31] T. E. M. Foundation. Fashion and a circular economy — ellen macarthur
    foundation.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] T. E. M. Foundation. 时尚与循环经济——艾伦·麦克阿瑟基金会。'
- en: '[32] A. Frummet, D. Elsweiler, and B. Ludwig. “what can i cook with these ingredients?”-understanding
    cooking-related information needs in conversational search. ACM Transactions on
    Information Systems (TOIS), 40(4):1–32, 2022.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] A. Frummet, D. Elsweiler, 和 B. Ludwig. “我可以用这些材料做什么？”——理解会话搜索中的烹饪相关信息需求。ACM
    信息系统学报（TOIS），40(4):1–32，2022。'
- en: '[33] J. Fürnkranz. Round robin classification. The Journal of Machine Learning
    Research, 2:721–747, 2002.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] J. Fürnkranz. 轮流分类。机器学习研究杂志，2:721–747，2002。'
- en: '[34] L. Gao, J. Schulman, and J. Hilton. Scaling laws for reward model overoptimization.
    arXiv preprint arXiv:2210.10760, 2022.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] L. Gao, J. Schulman, 和 J. Hilton. 奖励模型过度优化的缩放规律. arXiv 预印本 arXiv:2210.10760,
    2022.'
- en: '[35] Google. Google Assistant, your own personal Google default. https://assistant.google.com/.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] Google. Google Assistant，你的个人 Google 默认助手. https://assistant.google.com/.'
- en: '[36] N. Goyal, I. D. Kivlichan, R. Rosen, and L. Vasserman. Is Your Toxicity
    My Toxicity? Exploring the Impact of Rater Identity on Toxicity Annotation. Proceedings
    of the ACM on Human-Computer Interaction, 6(CSCW2):363:1–363:28, 2022.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] N. Goyal, I. D. Kivlichan, R. Rosen, 和 L. Vasserman. 你的毒性是我的毒性吗？探讨评估者身份对毒性标注的影响.
    《ACM 人机交互会议论文集》，6(CSCW2):363:1–363:28, 2022.'
- en: '[37] I. Gupta, B. Di Eugenio, B. Ziebart, A. Baiju, B. Liu, B. Gerber, L. Sharp,
    N. Nabulsi, and M. Smart. Human-human health coaching via text messages: Corpus,
    annotation, and analysis. In Proceedings of the 21th Annual Meeting of the Special
    Interest Group on Discourse and Dialogue, pages 246–256, 2020.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] I. Gupta, B. Di Eugenio, B. Ziebart, A. Baiju, B. Liu, B. Gerber, L. Sharp,
    N. Nabulsi, 和 M. Smart. 通过短信进行人际健康辅导：语料库、标注和分析. 在第21届年会特殊兴趣组话语与对话会议论文集，页码246–256,
    2020.'
- en: '[38] G. Haas, M. Rietzler, M. Jones, and E. Rukzio. Keep it short: A comparison
    of voice assistants’ response behavior. In Proceedings of the 2022 CHI Conference
    on Human Factors in Computing Systems, pages 1–12, 2022.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] G. Haas, M. Rietzler, M. Jones, 和 E. Rukzio. 保持简短：语音助手响应行为的比较. 在2022年CHI人机交互大会论文集，页码1–12,
    2022.'
- en: '[39] X. Han, W. Zhao, N. Ding, Z. Liu, and M. Sun. Ptr: Prompt tuning with
    rules for text classification. AI Open, 3:182–192, 2022.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] X. Han, W. Zhao, N. Ding, Z. Liu, 和 M. Sun. Ptr：规则驱动的文本分类提示调优. AI Open,
    3:182–192, 2022.'
- en: '[40] C. N. Harrington, R. Garg, A. Woodward, and D. Williams. “it’s kind of
    like code-switching”: Black older adults’ experiences with a voice assistant for
    health information seeking. In Proceedings of the 2022 CHI Conference on Human
    Factors in Computing Systems, pages 1–15, 2022.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] C. N. Harrington, R. Garg, A. Woodward, 和 D. Williams. “这有点像代码切换”：黑人老年人与语音助手在健康信息寻求中的经历.
    在2022年CHI人机交互大会论文集，页码1–15, 2022.'
- en: '[41] R. Hoegen, D. Aneja, D. McDuff, and M. Czerwinski. An end-to-end conversational
    style matching agent. In Proceedings of the 19th ACM International Conference
    on Intelligent Virtual Agents, pages 111–118, 2019.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] R. Hoegen, D. Aneja, D. McDuff, 和 M. Czerwinski. 一种端到端对话风格匹配代理. 在第19届ACM国际智能虚拟代理会议论文集，页码111–118,
    2019.'
- en: '[42] T. Hunter. Siri and alexa are getting on their owners’ last nerves. the
    washington post, 2022.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] T. Hunter. Siri 和 Alexa 让他们的主人烦透了. 《华盛顿邮报》，2022.'
- en: '[43] D. Ippolito, A. Yuan, A. Coenen, and S. Burnam. Creative writing with
    an ai-powered writing assistant: Perspectives from professional writers. arXiv
    preprint arXiv:2211.05030, 2022.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] D. Ippolito, A. Yuan, A. Coenen, 和 S. Burnam. 利用 AI 助手进行创意写作：来自专业作家的观点.
    arXiv 预印本 arXiv:2211.05030, 2022.'
- en: '[44] B. Jan-Petter and J. J. Gumperz. Social meaning in linguistic structure:
    Code-switching in norway. In The bilingualism reader, pages 75–96\. Routledge,
    2020.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] B. Jan-Petter 和 J. J. Gumperz. 语言结构中的社会意义：挪威的代码切换. 在《双语主义读本》中，页码75–96\.
    Routledge, 2020.'
- en: '[45] E. Jiang, K. Olson, E. Toh, A. Molina, A. Donsbach, M. Terry, and C. J.
    Cai. PromptMaker: Prompt-based Prototyping with Large Language Models. In Extended
    Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems, CHI
    EA ’22, pages 1–8, New York, NY, USA, 2022\. Association for Computing Machinery.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] E. Jiang, K. Olson, E. Toh, A. Molina, A. Donsbach, M. Terry, 和 C. J.
    Cai. PromptMaker：基于提示的大型语言模型原型设计. 在2022年CHI人机交互大会扩展摘要，CHI EA ’22，页码1–8, 纽约，NY，美国，2022\.
    计算机协会.'
- en: '[46] B. Jordan and A. Henderson. Interaction analysis: Foundations and practice.
    The journal of the learning sciences, 4(1):39–103, 1995.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] B. Jordan 和 A. Henderson. 互动分析：基础与实践. 《学习科学期刊》，4(1):39–103, 1995.'
- en: '[47] D. Jurgens, E. Chandrasekharan, and L. Hemphill. A just and comprehensive
    strategy for using nlp to address online abuse. arXiv preprint arXiv:1906.01738,
    2019.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] D. Jurgens, E. Chandrasekharan, 和 L. Hemphill. 使用NLP应对在线虐待的公正全面策略. arXiv
    预印本 arXiv:1906.01738, 2019.'
- en: '[48] J. Kaddour, J. Harris, M. Mozes, H. Bradley, R. Raileanu, and R. McHardy.
    Challenges and applications of large language models. arXiv preprint arXiv:2307.10169,
    2023.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] J. Kaddour, J. Harris, M. Mozes, H. Bradley, R. Raileanu, 和 R. McHardy.
    大型语言模型的挑战与应用. arXiv 预印本 arXiv:2307.10169, 2023.'
- en: '[49] T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and Y. Iwasawa. Large language
    models are zero-shot reasoners. arXiv preprint arXiv:2205.11916, 2022.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] T. Kojima, S. S. Gu, M. Reid, Y. Matsuo 和 Y. Iwasawa。大型语言模型是零样本推理者。arXiv
    预印本 arXiv:2205.11916，2022年。'
- en: '[50] M. Krzywinski, N. Altman, and P. Blainey. Nested designs. Nature Methods,
    11(10):977–979, 2014.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] M. Krzywinski, N. Altman 和 P. Blainey。嵌套设计。Nature Methods，11(10)：977–979，2014年。'
- en: '[51] S. Kusal, S. Patil, J. Choudrie, K. Kotecha, S. Mishra, and A. Abraham.
    Ai-based conversational agents: A scoping review from technologies to future directions.
    IEEE Access, 2022.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] S. Kusal, S. Patil, J. Choudrie, K. Kotecha, S. Mishra 和 A. Abraham。基于人工智能的对话代理：从技术到未来方向的范围评估。IEEE
    Access，2022年。'
- en: '[52] J. Lafferty, A. McCallum, and F. C. Pereira. Conditional random fields:
    Probabilistic models for segmenting and labeling sequence data. 2001.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] J. Lafferty, A. McCallum 和 F. C. Pereira。条件随机场：用于分割和标注序列数据的概率模型。2001年。'
- en: '[53] P. Lambe. Organising knowledge: taxonomies, knowledge and organisational
    effectiveness. Elsevier, 2014.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] P. Lambe。组织知识：分类法、知识与组织效率。Elsevier，2014年。'
- en: '[54] M. Lee, P. Liang, and Q. Yang. Coauthor: Designing a human-ai collaborative
    writing dataset for exploring language model capabilities. In CHI Conference on
    Human Factors in Computing Systems, pages 1–19, 2022.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] M. Lee, P. Liang 和 Q. Yang。Coauthor：设计一个人类与人工智能协作的写作数据集，以探索语言模型能力。在CHI计算机系统人因会议论文集中，第1–19页，2022年。'
- en: '[55] M. Lee, M. Srivastava, A. Hardy, J. Thickstun, E. Durmus, A. Paranjape,
    I. Gerard-Ursin, X. L. Li, F. Ladhak, F. Rong, et al. Evaluating human-language
    model interaction. arXiv preprint arXiv:2212.09746, 2022.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] M. Lee, M. Srivastava, A. Hardy, J. Thickstun, E. Durmus, A. Paranjape,
    I. Gerard-Ursin, X. L. Li, F. Ladhak, F. Rong 等。评估人类语言模型互动。arXiv 预印本 arXiv:2212.09746，2022年。'
- en: '[56] P. Lee, S. Bubeck, and J. Petro. Benefits, limits, and risks of gpt-4
    as an ai chatbot for medicine. New England Journal of Medicine, 388(13):1233–1239,
    2023.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] P. Lee, S. Bubeck 和 J. Petro。GPT-4作为医学AI聊天机器人的好处、限制和风险。新英格兰医学杂志，388(13)：1233–1239，2023年。'
- en: '[57] M. Lewis, Y. Liu, N. Goyal, M. Ghazvininejad, A. Mohamed, O. Levy, V. Stoyanov,
    and L. Zettlemoyer. Bart: Denoising sequence-to-sequence pre-training for natural
    language generation, translation, and comprehension. arXiv preprint arXiv:1910.13461,
    2019.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] M. Lewis, Y. Liu, N. Goyal, M. Ghazvininejad, A. Mohamed, O. Levy, V.
    Stoyanov 和 L. Zettlemoyer。Bart：用于自然语言生成、翻译和理解的去噪序列到序列预训练。arXiv 预印本 arXiv:1910.13461，2019年。'
- en: '[58] C.-H. Li, S.-F. Yeh, T.-J. Chang, M.-H. Tsai, K. Chen, and Y.-J. Chang.
    A conversation analysis of non-progress and coping strategies with a banking task-oriented
    chatbot. In Proceedings of the 2020 CHI Conference on Human Factors in Computing
    Systems, pages 1–12, 2020.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] C.-H. Li, S.-F. Yeh, T.-J. Chang, M.-H. Tsai, K. Chen 和 Y.-J. Chang。银行任务导向聊天机器人的非进展对话分析及应对策略。在2020年CHI计算机系统人因会议论文集中，第1–12页，2020年。'
- en: '[59] N. Li, S. Liu, Y. Liu, S. Zhao, and M. Liu. Neural speech synthesis with
    transformer network. In Proceedings of the AAAI conference on artificial intelligence,
    volume 33, pages 6706–6713, 2019.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] N. Li, S. Liu, Y. Liu, S. Zhao 和 M. Liu。基于变换器网络的神经语音合成。在AAAI人工智能会议论文集中，第33卷，第6706–6713页，2019年。'
- en: '[60] P. Liang, R. Bommasani, T. Lee, D. Tsipras, D. Soylu, M. Yasunaga, Y. Zhang,
    D. Narayanan, Y. Wu, A. Kumar, et al. Holistic evaluation of language models.
    arXiv preprint arXiv:2211.09110, 2022.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] P. Liang, R. Bommasani, T. Lee, D. Tsipras, D. Soylu, M. Yasunaga, Y.
    Zhang, D. Narayanan, Y. Wu, A. Kumar 等。语言模型的全面评估。arXiv 预印本 arXiv:2211.09110，2022年。'
- en: '[61] Q. V. Liao, M. Davis, W. Geyer, M. Muller, and N. S. Shami. What can you
    do? studying social-agent orientation and agent proactive interactions with an
    agent for employees. In Proceedings of the 2016 acm conference on designing interactive
    systems, pages 264–275, 2016.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] Q. V. Liao, M. Davis, W. Geyer, M. Muller 和 N. S. Shami。你能做什么？研究社会代理导向及其与员工的主动互动。在2016年ACM交互系统设计会议论文集中，第264–275页，2016年。'
- en: '[62] Q. V. Liao, M. Mas-ud Hussain, P. Chandar, M. Davis, Y. Khazaeni, M. P.
    Crasso, D. Wang, M. Muller, N. S. Shami, and W. Geyer. All work and no play? In
    Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems,
    pages 1–13, 2018.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] Q. V. Liao, M. Mas-ud Hussain, P. Chandar, M. Davis, Y. Khazaeni, M. P.
    Crasso, D. Wang, M. Muller, N. S. Shami 和 W. Geyer。工作与玩乐？在2018年CHI计算机系统人因会议论文集中，第1–13页，2018年。'
- en: '[63] P. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, and G. Neubig. Pre-train,
    prompt, and predict: A systematic survey of prompting methods in natural language
    processing. arXiv preprint arXiv:2107.13586, 2021.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] P. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi 和 G. Neubig。预训练、提示和预测：自然语言处理中的提示方法系统综述。arXiv
    预印本 arXiv:2107.13586，2021年。'
- en: '[64] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis,
    L. Zettlemoyer, and V. Stoyanov. Roberta: A robustly optimized bert pretraining
    approach. arXiv preprint arXiv:1907.11692, 2019.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis,
    L. Zettlemoyer 和 V. Stoyanov. Roberta：一种鲁棒优化的 BERT 预训练方法。arXiv 预印本 arXiv:1907.11692，2019年。'
- en: '[65] S. Meyer, D. Elsweiler, B. Ludwig, M. Fernandez-Pichel, and D. E. Losada.
    Do we still need human assessors? prompt-based gpt-3 user simulation in conversational
    ai. In Proceedings of the 4th Conference on Conversational User Interfaces, pages
    1–6, 2022.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] S. Meyer, D. Elsweiler, B. Ludwig, M. Fernandez-Pichel 和 D. E. Losada.
    我们还需要人工评估者吗？基于提示的 GPT-3 用户模拟在对话 AI 中。发表于第4届对话用户界面会议论文集，页码 1–6，2022年。'
- en: '[66] S. H. Ng, D. Bell, and M. Brooke. Gaining turns and achieving high influence
    ranking in small conversational groups. British Journal of Social Psychology,
    32(3):265–275, 1993.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] S. H. Ng, D. Bell 和 M. Brooke. 在小型对话组中获得轮次并实现高影响力排名。英国社会心理学杂志，32(3):265–275，1993年。'
- en: '[67] C. O’Connor, S. Michaels, S. Chapin, and A. G. Harbaugh. The silent and
    the vocal: Participation and learning in whole-class discussion. Learning and
    instruction, 48:5–13, 2017.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] C. O’Connor, S. Michaels, S. Chapin 和 A. G. Harbaugh. 沉默与发言：全班讨论中的参与与学习。学习与教学，48:5–13，2017年。'
- en: '[68] J. O’Connor and J. Andreas. What context features can transformer language
    models use? arXiv preprint arXiv:2106.08367, 2021.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] J. O’Connor 和 J. Andreas. 转换器语言模型可以使用什么上下文特征？arXiv 预印本 arXiv:2106.08367，2021年。'
- en: '[69] C. Oertel, G. Castellano, M. Chetouani, J. Nasir, M. Obaid, C. Pelachaud,
    and C. Peters. Engagement in human-agent interaction: An overview. Frontiers in
    Robotics and AI, 7:92, 2020.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] C. Oertel, G. Castellano, M. Chetouani, J. Nasir, M. Obaid, C. Pelachaud
    和 C. Peters. 人机交互中的参与：概述。机器人与人工智能前沿，7:92，2020年。'
- en: '[70] OpenAI. ChatGPT: Optimizing Language Models for Dialogue. OpenAI, 2022.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] OpenAI. ChatGPT：优化对话语言模型。OpenAI，2022年。'
- en: '[71] OpenAI. Gpt-4 technical report. (arXiv:2303.08774), Mar 2023. arXiv:2303.08774
    [cs].'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] OpenAI. Gpt-4 技术报告。（arXiv:2303.08774），2023年3月。arXiv:2303.08774 [cs]。'
- en: '[72] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wainwright, P. Mishkin,
    C. Zhang, S. Agarwal, K. Slama, A. Ray, et al. Training language models to follow
    instructions with human feedback. arXiv preprint arXiv:2203.02155, 2022.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wainwright, P. Mishkin,
    C. Zhang, S. Agarwal, K. Slama, A. Ray 等。通过人类反馈训练语言模型以遵循指令。arXiv 预印本 arXiv:2203.02155，2022年。'
- en: '[73] K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. Bleu: a method for automatic
    evaluation of machine translation. In Proceedings of the 40th annual meeting of
    the Association for Computational Linguistics, pages 311–318, 2002.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] K. Papineni, S. Roukos, T. Ward 和 W.-J. Zhu. Bleu：一种自动评估机器翻译的方法。发表于第40届计算语言学协会年会论文集，页码
    311–318，2002年。'
- en: '[74] E. Parliament. The impact of textile production and waste on the environment
    (infographic), 2020.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] E. Parliament. 纺织品生产和废料对环境的影响（信息图），2020年。'
- en: '[75] B. Petreca, S. Baurley, K. Hesseldahl, A. Pollmann, and M. Obrist. The
    compositor tool: Investigating consumer experiences in the circular economy. Multimodal
    Technologies and Interaction, 6(4):24, 2022.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[75] B. Petreca, S. Baurley, K. Hesseldahl, A. Pollmann 和 M. Obrist. 组合工具：调查消费者在循环经济中的体验。多模态技术与互动，6(4):24，2022年。'
- en: '[76] D. Phutela. The importance of non-verbal communication. IUP Journal of
    Soft Skills, 9(4):43, 2015.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[76] D. Phutela. 非语言交流的重要性。IUP软技能杂志，9(4):43，2015年。'
- en: '[77] A. Radford, J. W. Kim, T. Xu, G. Brockman, C. McLeavey, and I. Sutskever.
    Robust speech recognition via large-scale weak supervision. arXiv preprint arXiv:2212.04356,
    2022.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[77] A. Radford, J. W. Kim, T. Xu, G. Brockman, C. McLeavey 和 I. Sutskever.
    通过大规模弱监督进行鲁棒语音识别。arXiv 预印本 arXiv:2212.04356，2022年。'
- en: '[78] A. Radford, J. W. Kim, T. Xu, G. Brockman, C. McLeavey, and I. Sutskever.
    Robust speech recognition via large-scale weak supervision. In International Conference
    on Machine Learning, pages 28492–28518\. PMLR, 2023.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] A. Radford, J. W. Kim, T. Xu, G. Brockman, C. McLeavey 和 I. Sutskever.
    通过大规模弱监督进行鲁棒语音识别。发表于国际机器学习大会，页码 28492–28518。PMLR，2023年。'
- en: '[79] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou,
    W. Li, P. J. Liu, et al. Exploring the limits of transfer learning with a unified
    text-to-text transformer. J. Mach. Learn. Res., 21(140):1–67, 2020.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[79] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou,
    W. Li, P. J. Liu 等。通过统一的文本到文本变换器探索迁移学习的极限。J. Mach. Learn. Res., 21(140):1–67，2020年。'
- en: '[80] A. Rastogi, X. Zang, S. Sunkara, R. Gupta, and P. Khaitan. Towards scalable
    multi-domain conversational agents: The schema-guided dialogue dataset. In Proceedings
    of the AAAI conference on artificial intelligence, volume 34, pages 8689–8696,
    2020.'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[80] A. Rastogi, X. Zang, S. Sunkara, R. Gupta, 和 P. Khaitan. 朝向可扩展的多领域对话代理：模式引导对话数据集。发表于《人工智能AAAI会议论文集》，第34卷，页8689–8696，2020年。'
- en: '[81] G. Redeker. On differences between spoken and written language. Discourse
    processes, 7(1):43–55, 1984.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[81] G. Redeker. 关于口语和书面语言之间的差异。《话语过程》，7(1):43–55，1984年。'
- en: '[82] C. K. Riessman. Analysis of personal narratives. Inside interviewing:
    New lenses, new concerns, pages 331–346, 2003.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[82] C. K. Riessman. 个人叙事分析。《访谈内：新视角，新关切》，页331–346，2003年。'
- en: '[83] K. A. Schumacher and A. L. Forster. Textiles in a circular economy: An
    assessment of the current landscape, challenges, and opportunities in the united
    states. Frontiers in Sustainability, 3:146, 2022.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[83] K. A. Schumacher 和 A. L. Forster. 循环经济中的纺织品：对美国当前形势、挑战和机遇的评估。《可持续性前沿》，3:146，2022年。'
- en: '[84] K. Seaborn, N. P. Miyake, P. Pennefather, and M. Otake-Matsuura. Voice
    in human–agent interaction: A survey. ACM Computing Surveys (CSUR), 54(4):1–43,
    2021.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[84] K. Seaborn, N. P. Miyake, P. Pennefather, 和 M. Otake-Matsuura. 人类-代理交互中的语音：一项调查。《ACM计算调查》（CSUR），54(4):1–43，2021年。'
- en: '[85] T. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. Autoprompt:
    Eliciting knowledge from language models with automatically generated prompts.
    arXiv preprint arXiv:2010.15980, 2020.'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[85] T. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, 和 S. Singh. Autoprompt：通过自动生成的提示从语言模型中引导知识。arXiv预印本
    arXiv:2010.15980，2020年。'
- en: '[86] E. M. Smith, O. Hsu, R. Qian, S. Roller, Y.-L. Boureau, and J. Weston.
    Human evaluation of conversations is an open problem: comparing the sensitivity
    of various methods for evaluating dialogue agents. arXiv preprint arXiv:2201.04723,
    2022.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[86] E. M. Smith, O. Hsu, R. Qian, S. Roller, Y.-L. Boureau, 和 J. Weston. 人类对话评估是一个未解问题：比较评估对话代理的各种方法的敏感性。arXiv预印本
    arXiv:2201.04723，2022年。'
- en: '[87] N. Stiennon, L. Ouyang, J. Wu, D. Ziegler, R. Lowe, C. Voss, A. Radford,
    D. Amodei, and P. F. Christiano. Learning to summarize with human feedback. Advances
    in Neural Information Processing Systems, 33:3008–3021, 2020.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[87] N. Stiennon, L. Ouyang, J. Wu, D. Ziegler, R. Lowe, C. Voss, A. Radford,
    D. Amodei, 和 P. F. Christiano. 学习通过人工反馈进行总结。《神经信息处理系统进展》，33:3008–3021，2020年。'
- en: '[88] D. Tannen. Conversational style: Analyzing talk among friends. Oxford
    University Press, 2005.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[88] D. Tannen. 对话风格：分析朋友间的交谈。牛津大学出版社，2005年。'
- en: '[89] P. Ten Have. Doing conversation analysis. Sage, 2007.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[89] P. Ten Have. 进行对话分析。Sage，2007年。'
- en: '[90] P. Vaithilingam, T. Zhang, and E. L. Glassman. Expectation vs. experience:
    Evaluating the usability of code generation tools powered by large language models.
    In CHI Conference on Human Factors in Computing Systems Extended Abstracts, pages
    1–7, 2022.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90] P. Vaithilingam, T. Zhang, 和 E. L. Glassman. 期望与经验：评估由大型语言模型驱动的代码生成工具的可用性。发表于《CHI人机交互会议扩展摘要》，页1–7，2022年。'
- en: '[91] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    Ł. Kaiser, and I. Polosukhin. Attention is all you need. Advances in neural information
    processing systems, 30, 2017.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[91] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    Ł. Kaiser, 和 I. Polosukhin. 注意力即是你所需。《神经信息处理系统进展》，30，2017年。'
- en: '[92] A. Venkatesh, C. Khatri, A. Ram, F. Guo, R. Gabriel, A. Nagar, R. Prasad,
    M. Cheng, B. Hedayatnia, A. Metallinou, et al. On evaluating and comparing conversational
    agents. 2017.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[92] A. Venkatesh, C. Khatri, A. Ram, F. Guo, R. Gabriel, A. Nagar, R. Prasad,
    M. Cheng, B. Hedayatnia, A. Metallinou, 等. 关于评估和比较对话代理。2017年。'
- en: '[93] A. P. Vermeeren, E. L.-C. Law, V. Roto, M. Obrist, J. Hoonhout, and K. Väänänen-Vainio-Mattila.
    User experience evaluation methods: current state and development needs. In Proceedings
    of the 6th Nordic conference on human-computer interaction: Extending boundaries,
    pages 521–530, 2010.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[93] A. P. Vermeeren, E. L.-C. Law, V. Roto, M. Obrist, J. Hoonhout, 和 K. Väänänen-Vainio-Mattila.
    用户体验评估方法：现状与发展需求。发表于《第6届北欧人机交互会议：扩展边界》，页521–530，2010年。'
- en: '[94] S. T. Völkel, D. Buschek, M. Eiband, B. R. Cowan, and H. Hussmann. Eliciting
    and analysing users’ envisioned dialogues with perfect voice assistants. In Proceedings
    of the 2021 CHI Conference on Human Factors in Computing Systems, pages 1–15,
    2021.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[94] S. T. Völkel, D. Buschek, M. Eiband, B. R. Cowan, 和 H. Hussmann. 引导和分析用户设想中的对话与完美的语音助手。发表于《2021年CHI人机交互会议论文集》，页1–15，2021年。'
- en: '[95] S. T. Völkel, S. Meindl, and H. Hussmann. Manipulating and evaluating
    levels of personality perceptions of voice assistants through enactment-based
    dialogue design. In Proceedings of the 3rd Conference on Conversational User Interfaces,
    pages 1–12, 2021.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[95] S. T. Völkel, S. Meindl, 和 H. Hussmann. 通过基于表演的对话设计操控和评估语音助手的个性感知层次。发表于第3届对话用户界面会议，页码
    1–12, 2021。'
- en: '[96] S. T. Völkel, R. Schödel, D. Buschek, C. Stachl, V. Winterhalter, M. Bühner,
    and H. Hussmann. Developing a personality model for speech-based conversational
    agents using the psycholexical approach. In Proceedings of the 2020 CHI Conference
    on Human Factors in Computing Systems, pages 1–14, 2020.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[96] S. T. Völkel, R. Schödel, D. Buschek, C. Stachl, V. Winterhalter, M. Bühner,
    和 H. Hussmann. 使用心理词汇方法开发语音基础对话代理的个性模型。发表于 2020 年 CHI 人机因素会议，页码 1–14, 2020。'
- en: '[97] S. T. Völkel, R. Schoedel, L. Kaya, and S. Mayer. User perceptions of
    extraversion in chatbots after repeated use. In Proceedings of the 2022 CHI Conference
    on Human Factors in Computing Systems, pages 1–18, 2022.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[97] S. T. Völkel, R. Schoedel, L. Kaya, 和 S. Mayer. 聊天机器人在重复使用后的外向性用户感知。发表于
    2022 年 CHI 人机因素会议，页码 1–18, 2022。'
- en: '[98] B. Wang, G. Li, and Y. Li. Enabling conversational interaction with mobile
    ui using large language models. arXiv preprint arXiv:2209.08655, 2022.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[98] B. Wang, G. Li, 和 Y. Li. 利用大型语言模型实现移动用户界面的对话交互。arXiv 预印本 arXiv:2209.08655,
    2022。'
- en: '[99] B. Wang, G. Li, and Y. Li. Enabling conversational interaction with mobile
    ui using large language models. In Proceedings of the 2023 CHI Conference on Human
    Factors in Computing Systems, pages 1–17, 2023.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[99] B. Wang, G. Li, 和 Y. Li. 利用大型语言模型实现移动用户界面的对话交互。发表于 2023 年 CHI 人机因素会议，页码
    1–17, 2023。'
- en: '[100] B. Wang, G. Li, X. Zhou, Z. Chen, T. Grossman, and Y. Li. Screen2words:
    Automatic mobile ui summarization with multimodal learning. In The 34th Annual
    ACM Symposium on User Interface Software and Technology, pages 498–510, 2021.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[100] B. Wang, G. Li, X. Zhou, Z. Chen, T. Grossman, 和 Y. Li. Screen2words：基于多模态学习的自动移动用户界面总结。发表于第34届
    ACM 用户界面软件与技术年会，页码 498–510, 2021。'
- en: '[101] Y.-C. Wang, A. Papangelis, R. Wang, Z. Feizollahi, G. Tur, and R. Kraut.
    Can you be more social? injecting politeness and positivity into task-oriented
    conversational agents. arXiv preprint arXiv:2012.14653, 2020.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[101] Y.-C. Wang, A. Papangelis, R. Wang, Z. Feizollahi, G. Tur, 和 R. Kraut.
    你能更社交一点吗？在任务导向对话代理中注入礼貌和积极性。arXiv 预印本 arXiv:2012.14653, 2020。'
- en: '[102] T. D. Wilson. Models in information behaviour research. Journal of documentation,
    55(3):249–270, 1999.'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[102] T. D. Wilson. 信息行为研究中的模型。文献学期刊，55(3):249–270, 1999。'
- en: '[103] T. Wu, M. Terry, and C. J. Cai. Ai chains: Transparent and controllable
    human-ai interaction by chaining large language model prompts. In CHI Conference
    on Human Factors in Computing Systems, pages 1–22, 2022.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[103] T. Wu, M. Terry, 和 C. J. Cai. AI 链：通过链接大型语言模型提示实现透明且可控的人机交互。发表于 CHI 人机因素会议，页码
    1–22, 2022。'
- en: '[104] Q. Yang, J. Cranshaw, S. Amershi, S. T. Iqbal, and J. Teevan. Sketching
    nlp: A case study of exploring the right things to design with language intelligence.
    In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems,
    pages 1–12, 2019.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[104] Q. Yang, J. Cranshaw, S. Amershi, S. T. Iqbal, 和 J. Teevan. 设计 NLP：探索与语言智能设计的正确方式的案例研究。发表于
    2019 年 CHI 人机因素会议，页码 1–12, 2019。'
- en: '[105] M. Zaib, Q. Z. Sheng, and W. Emma Zhang. A short survey of pre-trained
    language models for conversational ai-a new age in nlp. In Proceedings of the
    Australasian computer science week multiconference, pages 1–4, 2020.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[105] M. Zaib, Q. Z. Sheng, 和 W. Emma Zhang. 对话 AI 的预训练语言模型短评——自然语言处理的新纪元。发表于澳大利亚计算机科学周多会议，页码
    1–4, 2020。'
- en: '[106] J. Zamfirescu-Pereira, H. Wei, A. Xiao, K. Gu, G. Jung, M. G. Lee, B. Hartmann,
    and Q. Yang. Herding ai cats: Lessons from designing a chatbot by prompting gpt-3.
    2023.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[106] J. Zamfirescu-Pereira, H. Wei, A. Xiao, K. Gu, G. Jung, M. G. Lee, B.
    Hartmann, 和 Q. Yang. 驯化人工智能猫：从设计基于 GPT-3 的聊天机器人中得到的经验教训。2023。'
- en: '[107] L. Zhang, L. Jiang, N. Washington, A. A. Liu, J. Shao, A. Fourney, M. R.
    Morris, and L. Findlater. Social media through voice: Synthesized voice qualities
    and self-presentation. Proceedings of the ACM on Human-Computer Interaction, 5(CSCW1):1–21,
    2021.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[107] L. Zhang, L. Jiang, N. Washington, A. A. Liu, J. Shao, A. Fourney, M.
    R. Morris, 和 L. Findlater. 通过声音的社交媒体：合成语音质量和自我呈现。ACM 人机交互学报，5(CSCW1):1–21, 2021。'
- en: '[108] S. Zhong, M. Ribul, Y. Cho, and M. Obrist. Textilenet: A material taxonomy-based
    fashion textile dataset. arXiv preprint arXiv:2301.06160, 2023.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[108] S. Zhong, M. Ribul, Y. Cho, 和 M. Obrist. Textilenet：基于材料分类的时尚纺织品数据集。arXiv
    预印本 arXiv:2301.06160, 2023。'
- en: '[109] A. F. Zuur, E. N. Ieno, N. J. Walker, A. A. Saveliev, G. M. Smith, et al.
    Mixed effects models and extensions in ecology with R, volume 574. Springer, 2009.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[109] A. F. Zuur, E. N. Ieno, N. J. Walker, A. A. Saveliev, G. M. Smith 等。《生态学中的混合效应模型及其扩展》，第
    574 卷。Springer，2009年。'
