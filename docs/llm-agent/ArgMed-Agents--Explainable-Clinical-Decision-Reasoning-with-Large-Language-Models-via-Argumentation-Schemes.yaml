- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 18:50:30'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-08 18:50:30'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'ArgMed-Agents: Explainable Clinical Decision Reasoning with Large Language
    Models via Argumentation Schemes'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'ArgMed-Agents: 通过论证方案实现大型语言模型的可解释临床决策推理'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2403.06294](https://ar5iv.labs.arxiv.org/html/2403.06294)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2403.06294](https://ar5iv.labs.arxiv.org/html/2403.06294)
- en: Shengxin Hong¹ Liang Xiao²    Xin Zhang¹&Jianxia Chen²
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 胜鑫·洪¹ 梁晓²    辛·张¹&建霞·陈²
- en: ¹Detroit Green Technology Institute, Hubei University of Technology, China
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ¹湖北工业大学底特律绿色技术研究所，中国
- en: ²School of Computer Science, Hubei University of Technology, China seikin.shengxinhong@gmail.com,
    lx@mail.hbut.edu.cn
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ²湖北工业大学计算机科学学院，中国 seikin.shengxinhong@gmail.com, lx@mail.hbut.edu.cn
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: There are two main barriers to using large language models (LLMs) in clinical
    reasoning. Firstly, while LLMs exhibit significant promise in Natural Language
    Processing (NLP) tasks, their performance in complex reasoning and planning falls
    short of expectations. Secondly, LLMs use uninterpretable methods to make clinical
    decisions that are fundamentally different from the clinician’s cognitive processes.
    This leads to user distrust. In this paper, we present a multi-agent framework
    called ArgMed-Agents, which aims to enable LLM-based agents to make explainable
    clinical decision reasoning through interaction. ArgMed-Agents performs self-argumentation
    iterations via Argumentation Scheme for Clinical Decision (a reasoning mechanism
    for modeling cognitive processes in clinical reasoning), and then constructs the
    argumentation process as a directed graph representing conflicting relationships.
    Ultimately, Reasoner(a symbolic solver) identify a series of rational and coherent
    arguments to support decision. ArgMed-Agents enables LLMs to mimic the process
    of clinical argumentative reasoning by generating explanations of reasoning in
    a self-directed manner. The setup experiments show that ArgMed-Agents not only
    improves accuracy in complex clinical decision reasoning problems compared to
    other prompt methods, but more importantly, it provides users with decision explanations
    that increase their confidence.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在临床推理中使用大型语言模型（LLMs）面临两个主要障碍。首先，虽然LLMs在自然语言处理（NLP）任务中表现出显著的潜力，但它们在复杂推理和规划中的表现却未达预期。其次，LLMs使用不可解释的方法来做出临床决策，这与临床医生的认知过程根本不同，从而导致用户的不信任。本文提出了一个多智能体框架，称为ArgMed-Agents，旨在通过互动使LLM-based
    agents能够进行可解释的临床决策推理。ArgMed-Agents通过临床决策论证方案（用于建模临床推理中的认知过程的推理机制）执行自我论证迭代，然后将论证过程构建为一个有向图，表示冲突关系。最终，Reasoner（一个符号求解器）识别出一系列合理且连贯的论据以支持决策。ArgMed-Agents使LLMs能够通过生成自我导向的推理解释来模拟临床论证推理过程。设置实验表明，与其他提示方法相比，ArgMed-Agents不仅提高了复杂临床决策推理问题的准确性，更重要的是，它为用户提供了增强信心的决策解释。
- en: 1 Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: 'Large Language Models (LLMs) OpenAI ([2023](#bib.bib25)) have received a lot
    of attention for their human-like performance in a variety of domains. In the
    medical field especially, preliminary studies have shown that LLMs can be used
    as clinical assistants for tasks such as writing clinical texts Nayak et al. ([2023](#bib.bib22)),
    providing biomedical knowledge Singhal et al. ([2022](#bib.bib33)) and drafting
    responses to patients’ questions Ayers et al. ([2023](#bib.bib1)). However, the
    following barriers to building an LLM-based clinical decision-making system still
    exist: (i) LLMs still struggle to provide secure, stable answers when faced with
    highly complex clinical reasoning tasks Pal et al. ([2023](#bib.bib26)). (ii)
    There is a perception that LLMs use unexplainable methods to arrive at clinical
    decisions (known as black boxes), which may have led to user distrust Eigner and
    Händler ([2024](#bib.bib11)).'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）OpenAI ([2023](#bib.bib25))因其在人类表现中的多种领域中引起了广泛关注。尤其在医学领域，初步研究显示LLMs可以用作临床助理，用于撰写临床文本
    Nayak et al. ([2023](#bib.bib22))、提供生物医学知识 Singhal et al. ([2022](#bib.bib33))
    和草拟对患者问题的回答 Ayers et al. ([2023](#bib.bib1))。然而，构建基于LLM的临床决策系统仍存在以下障碍：（i）LLMs在面对高度复杂的临床推理任务时仍然难以提供安全、稳定的答案
    Pal et al. ([2023](#bib.bib26))。（ii）存在一种看法，即LLMs使用不可解释的方法得出临床决策（称为黑箱），这可能导致用户的不信任
    Eigner and Händler ([2024](#bib.bib11))。
- en: To address these barriers, exploring the capabilities of LLMs in argumentative
    reasoning is a promising direction. Argumentation is a means of conveying a compelling
    point of view that can increase user acceptance of a position. Its considered
    a fundamental requirement for building Human-Centric AI Dietz et al. ([2022](#bib.bib9)).
    As computational argumentation has become a growing area of research in Natural
    Language Processing (NLP) Dietz et al. ([2021](#bib.bib8)), researchers have begun
    to apply argumentation to a wide range of clinical reasoning applications, including
    analysis of clinical discussions Qassas et al. ([2015](#bib.bib29)), clinical
    decision making Hong et al. ([2023](#bib.bib14)); Zeng et al. ([2020](#bib.bib43));
    Sassoon et al. ([2021](#bib.bib30)), address clinical conflicting Čyras et al.
    ([2018](#bib.bib6)). In the recent past, some work has assessed the ability of
    LLMs in argumentation reasoning Chen et al. ([2023](#bib.bib4)); Castagna et al.
    ([2024](#bib.bib3)) or non-monotonic reasoning Xiu et al. ([2022](#bib.bib42)).
    Although LLMs show some potential for computational argumentation, more results
    show that LLMs perform poorly in logical reasoning tasks Xie et al. ([2024](#bib.bib41)),
    and better ways to utilise LLMs for non-monotonic reasoning tasks need to be explored.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些障碍，探索 LLM 在论证推理中的能力是一个有前景的方向。论证是一种传达令人信服观点的手段，可以增加用户对某一立场的接受度。它被认为是构建以人为本的
    AI 的基本要求 Dietz 等人 ([2022](#bib.bib9))。随着计算论证成为自然语言处理（NLP）领域的一个增长研究方向 Dietz 等人
    ([2021](#bib.bib8))，研究人员已开始将论证应用于广泛的临床推理应用中，包括临床讨论分析 Qassas 等人 ([2015](#bib.bib29))，临床决策制定
    Hong 等人 ([2023](#bib.bib14))；Zeng 等人 ([2020](#bib.bib43))；Sassoon 等人 ([2021](#bib.bib30))，解决临床冲突
    Čyras 等人 ([2018](#bib.bib6))。近期，一些工作评估了 LLM 在论证推理中的能力 Chen 等人 ([2023](#bib.bib4))；Castagna
    等人 ([2024](#bib.bib3)) 或非单调推理 Xiu 等人 ([2022](#bib.bib42))。虽然 LLM 显示出在计算论证方面的一些潜力，但更多的结果表明
    LLM 在逻辑推理任务中表现不佳 Xie 等人 ([2024](#bib.bib41))，需要探索更好的方法来利用 LLM 进行非单调推理任务。
- en: Meanwhile, LLM as agent studies have been surprisingly successful Zhang et al.
    ([2023](#bib.bib44)); Wang et al. ([2023](#bib.bib38)); Shi et al. ([2024](#bib.bib32)).
    These methods use LLMs as computational engines for autonomous agents, and optimise
    the reasoning, planning capabilities of LLMs through external tools (e.g. symbolic
    solvers, APIs, retrieval tools, etc.) Pan et al. ([2023](#bib.bib27)); Shi et
    al. ([2024](#bib.bib32)), multi-agent interactions Tang et al. ([2024](#bib.bib35))
    and novel algorithmic frameworks Gandhi et al. ([2023](#bib.bib13)). Through this
    design, LLMs agents can interact with the environment and generate action plans
    through intermediate reasoning steps that can be executed sequentially to obtain
    an effective solution.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，LLM 作为智能体的研究取得了令人惊讶的成功 Zhang 等人 ([2023](#bib.bib44))；Wang 等人 ([2023](#bib.bib38))；Shi
    等人 ([2024](#bib.bib32))。这些方法将 LLM 作为自主智能体的计算引擎，并通过外部工具（例如符号求解器、API、检索工具等）优化 LLM
    的推理和规划能力 Pan 等人 ([2023](#bib.bib27))；Shi 等人 ([2024](#bib.bib32))，多智能体互动 Tang 等人
    ([2024](#bib.bib35)) 和新颖的算法框架 Gandhi 等人 ([2023](#bib.bib13))。通过这种设计，LLM 智能体可以与环境互动，并通过中间推理步骤生成可以顺序执行的行动计划，从而获得有效的解决方案。
- en: 'Motivated by these concepts, we present ArgMed-Agents, a multi-agent framework
    designed for explainable clinical decision reasoning. We formalised the cognitive
    process of clinical reasoning using an argumentation scheme for clinical decision
    (ASCD) as a prompt strategy for interactive reasoning by LLM agents. There are
    three types of agents in ArgMed-Agents: the Generator, the Verifier, and the Reasoner.
    the Generator generates arguments to support clinical decisions based on the argumentation
    scheme; the Verifier checks the arguments for legitimacy based on the critical
    question, and if not legitimate, it asks the Generator to generate attack arguments;
    Reasoner is a symbolic solver that identifies reasonable, non-contradictory arguments
    in the resulting directed argumentation graph as decision support.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 受这些概念的启发，我们提出了 ArgMed-Agents，一个用于可解释临床决策推理的多智能体框架。我们使用临床决策的论证方案（ASCD）作为 LLM
    智能体进行互动推理的提示策略，形式化了临床推理的认知过程。ArgMed-Agents 中有三种类型的智能体：生成器、验证器和推理器。生成器基于论证方案生成支持临床决策的论据；验证器根据关键问题检查论据的合法性，如果不合法，则要求生成器生成攻击论据；推理器是一个符号求解器，在生成的定向论证图中识别合理的、不矛盾的论据作为决策支持。
- en: In our method, we do not expect every proposed argument or detection of Generator
    or Verifier to be correct, instead we consider their generation as a assumption.
    The LLM agents are induced to recursively iterate in a self-argumentative manner
    through the prompt strategy , while the newly proposed assumptions always contradict
    the old ones, and eventually the Reasoner eliminates unreasonable assumptions
    and identifies coherent arguments, leading to consistent reasoning results. ArgMed-Agents
    enables LLMs to explain its own outputs in terms of self-cognitive profiling by
    modelling their own generation as a prompt for question recursion. The generative
    process derives the attack relations of the arguments are determined based on
    the ASCD prompt strategy. For example, when there exist two decisions as arguments
    $a$, they attack each other based on the decision exclusivity defined in ASCD.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的方法中，我们并不期望每个提出的论点或生成器或验证器的检测都是正确的，而是将其生成视为一种假设。LLM 代理通过提示策略以自我论证的方式递归迭代，而新提出的假设总是与旧的假设相矛盾，最终推理者会消除不合理的假设并识别一致的论点，从而得出一致的推理结果。ArgMed-Agents
    使 LLM 能够通过将其自身生成建模为问题递归的提示，解释其自身的输出。生成过程根据 ASCD 提示策略确定论点的攻击关系。例如，当存在两个作为论点 $a$
    的决策时，它们根据 ASCD 中定义的决策排他性互相攻击。
- en: Our experiment was divided into two parts, evaluating accuracy and explainability
    of ArgMed-Agents clinical reasoning, respectively. First, we conducted experiments
    on two datasets, including MedQA Jin et al. ([2020](#bib.bib17)) and PubMedQA
    Jin et al. ([2019](#bib.bib16)). To better align with real-world application scenarios,
    our study focused on a zero-shot setting. Second, we used predictability and traceability
    as measures of explainability by manually assessing whether the clinical reasoning
    process of ArgMed-Agents is meaningful in terms of explanation for users. The
    results show that ArgMed-Agents achieves better performance in both accuracy and
    explainability compared to direct generation and Chain of Thought (CoT).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实验分为两部分，分别评估 ArgMed-Agents 临床推理的准确性和可解释性。首先，我们在两个数据集上进行了实验，包括 MedQA Jin 等人
    ([2020](#bib.bib17)) 和 PubMedQA Jin 等人 ([2019](#bib.bib16))。为了更好地与现实应用场景对齐，我们的研究集中在零样本设置上。其次，我们通过手动评估
    ArgMed-Agents 的临床推理过程是否在解释方面对用户有意义，使用可预测性和可追溯性作为可解释性的衡量标准。结果显示，ArgMed-Agents 在准确性和可解释性方面都比直接生成和思维链（CoT）表现更佳。
- en: 2 Preliminaries
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 前言
- en: 2.1 Abstract Argumentation Framework
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 抽象论证框架
- en: 'Abstract Argumentation (AA) frameworks Dung ([1995](#bib.bib10)) are pair $\langle\mathcal{A},\mathcal{R}\rangle$.
    On top of that, Dung defines some notions:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 抽象论证（AA）框架 Dung ([1995](#bib.bib10)) 是一对 $\langle\mathcal{A},\mathcal{R}\rangle$。在此基础上，Dung
    定义了一些概念：
- en: •
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: $\exists a\in\mathcal{A}$.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\exists a\in\mathcal{A}$。
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: A set of arguments is conflict-free if there is no attack between its arguments.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果论点之间没有攻击，则一组论点是无冲突的。
- en: In order to decide whether a single parameter can be accepted or whether multiple
    parameters can be accepted at the same time, the argumentation system allows for
    the use of various semantics to compute the set of parameters (called extensions).
    For example, Given an AA framework $\langle\mathcal{A},\mathcal{R}\rangle$.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了决定单个参数是否可以被接受，或者是否可以同时接受多个参数，论证系统允许使用各种语义来计算参数集（称为扩展）。例如，给定一个 AA 框架 $\langle\mathcal{A},\mathcal{R}\rangle$。
- en: 2.2 Argumentation Scheme
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 论证方案
- en: 'The concept of Argumentation Scheme (AS) originated within the domain of informal
    logic, stemming from the seminal works of Walton et al. ([2008](#bib.bib36));
    Walton ([1996](#bib.bib37)). Argumentation Scheme serves as a semi-formalized
    framework for capturing and analyzing human reasoning patterns. Formally defined
    as $AS=\langle P,c,V\rangle$). A pivotal aspect of the argumentation scheme is
    the delineation of Critical Questions (CQs) pertinent to AS. Failure to address
    them prompts a challenge to both the premises and the conclusion posited by the
    scheme. Consequently, the role of CQs is to instigate argument generation; when
    an AS is contested, it engenders the formulation of a counter-argument in response
    to the initial AS. This iterative process culminates in the construction of an
    attack argument graph, facilitating a nuanced understanding of argumentative dynamics.
    Figure [1](#S3.F1 "Figure 1 ‣ 3 Argumentation Scheme for Clinial Decision ‣ ArgMed-Agents:
    Explainable Clinical Decision Reasoning with Large Language Models via Argumentation
    Schemes") illustrates three templates of argumentation schemes.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '论证方案（AS）的概念源于非正式逻辑领域，起源于 Walton 等人 ([2008](#bib.bib36))；Walton ([1996](#bib.bib37))
    的开创性工作。论证方案作为一个半正式化的框架，用于捕捉和分析人类推理模式。形式上定义为 $AS=\langle P,c,V\rangle$。论证方案的一个关键方面是明确与
    AS 相关的关键问题（CQs）。未能回答这些问题会对方案提出的前提和结论构成挑战。因此，CQs 的作用是引发论证生成；当 AS 被质疑时，它会导致对初始 AS
    的反驳论证的形成。这个迭代过程最终形成一个攻击论证图，促进对论证动态的深入理解。图 [1](#S3.F1 "Figure 1 ‣ 3 Argumentation
    Scheme for Clinial Decision ‣ ArgMed-Agents: Explainable Clinical Decision Reasoning
    with Large Language Models via Argumentation Schemes") 展示了三种论证方案模板。'
- en: 3 Argumentation Scheme for Clinial Decision
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 临床决策的论证方案
- en: 'In the past, numerous studies Oliveira et al. ([2018](#bib.bib24)); Sassoon
    et al. ([2021](#bib.bib30)); Qassas et al. ([2015](#bib.bib29)) have explored
    the application of argumentation in the clinical domain. In this section, we provide
    a summary of these endeavors, focusing on the development of Argumentation Schemes
    for Clinical Decision (ASCD). ASCD encapsulate various argumentation scheme tailored
    for clinical decision-making processes and the reasoning process. Additionally,
    we propose to refine and adapt these schemes to enhance their suitability for
    LLM. ASCD consists of three argumentation schemes which are Argumentation Scheme
    for Decision (ASD), Argumentation Scheme for Side Effect (ASSE) and Argumentation
    Scheme for Better Decision (ASBD). Figure [1](#S3.F1 "Figure 1 ‣ 3 Argumentation
    Scheme for Clinial Decision ‣ ArgMed-Agents: Explainable Clinical Decision Reasoning
    with Large Language Models via Argumentation Schemes") includes the components
    of the three argumentation schemes and the derivations between them.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '过去，Oliveira 等人 ([2018](#bib.bib24))；Sassoon 等人 ([2021](#bib.bib30))；Qassas
    等人 ([2015](#bib.bib29)) 的大量研究探讨了论证在临床领域中的应用。在本节中，我们总结了这些努力，重点介绍临床决策论证方案（ASCD）的发展。ASCD
    包含各种针对临床决策过程和推理过程的论证方案。此外，我们建议对这些方案进行改进和调整，以提高其对 LLM 的适用性。ASCD 由三种论证方案组成：决策论证方案（ASD）、副作用论证方案（ASSE）和更好决策论证方案（ASBD）。图
    [1](#S3.F1 "Figure 1 ‣ 3 Argumentation Scheme for Clinial Decision ‣ ArgMed-Agents:
    Explainable Clinical Decision Reasoning with Large Language Models via Argumentation
    Schemes") 包括了这三种论证方案的组件及其之间的推导关系。'
- en: '![Refer to caption](img/bdec46be281a957e88faa4649cb70708.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/bdec46be281a957e88faa4649cb70708.png)'
- en: 'Figure 1: The derivation rules between the argumentation schemes in ASCD.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：ASCD 中论证方案之间的推导规则。
- en: 'ASCD formalizes the decision-making process for clinicians. Clinical decision
    reasoning begins with ASD, where decisions are related to clinical goals. Formally,
    in Figure [1](#S3.F1 "Figure 1 ‣ 3 Argumentation Scheme for Clinial Decision ‣
    ArgMed-Agents: Explainable Clinical Decision Reasoning with Large Language Models
    via Argumentation Schemes") we model the derivation of CQs. When the CQs are rejected,
    new ASs are generated as arguments to refute the first proposed AS based on the
    derivation relation. It is worth noting that when a CQ without a derivation relationship
    (e.g., ASD.CQ1, ASSE.CQ1) is rejected, the AS will be refuted by itself (on the
    grounds of the CQ’s answer). We illustrate how to reason using ASCD with an example:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ASCD形式化了临床决策过程。临床决策推理始于ASD，其中决策与临床目标相关。正式地，在图[1](#S3.F1 "图1 ‣ 3 临床决策的论证方案 ‣
    ArgMed-Agents：通过论证方案进行可解释的临床决策推理")中，我们建模了CQ的推导。当CQ被拒绝时，新AS将作为论据生成以反驳最初提出的AS。值得注意的是，当一个没有推导关系的CQ（例如ASD.CQ1,
    ASSE.CQ1）被拒绝时，AS将会被自身反驳（基于CQ的答案）。我们通过一个示例来说明如何使用ASCD进行推理：
- en: •
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Joey is a 50 year old male patient who has suffered a stroke and has high blood
    pressure. For Joey, the goal is to control his blood pressure;
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Joey是一位50岁的男性患者，曾中风并且血压较高。对Joey来说，目标是控制他的血压；
- en: First, we represent the initial ASD reasoning result as $ASD_{1}(joey,control\_blood\_pressure,ACEI)\rightarrow
    ACEI$. Notably, since we set exclusivity between ASD, in order for ASD.CQ1 and
    ASD.CQ3 to be valid, when these two CQs are rejected, that ASD first refutes itself
    (forming a closed loop) and then generates a new ASD.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将初始ASD推理结果表示为 $ASD_{1}(joey,control\_blood\_pressure,ACEI)\rightarrow ACEI$。值得注意的是，由于我们设定了ASD之间的排他性，为了使ASD.CQ1和ASD.CQ3有效，当这两个CQ被拒绝时，ASD首先自我否定（形成闭环），然后生成一个新的ASD。
- en: '![Refer to caption](img/f669a371d121b588b822a291d8c84bea.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/f669a371d121b588b822a291d8c84bea.png)'
- en: 'Figure 2: An example from the MedQA USMLE dataset, with the entire process
    of ArgMed-Agents reasoning about the clinical problem. Notably, the letters in
    the argumentation framework correspond to the serial numbers of the four generators
    on the right, representing the premises and conclusion generated by that generator.
    In the argumentation framework, the red nodes ($A$) represent arguments in support
    of the beliefs.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：来自MedQA USMLE数据集的一个示例，展示了ArgMed-Agents对临床问题的完整推理过程。值得注意的是，论证框架中的字母对应右侧四个生成器的序列号，表示由该生成器生成的前提和结论。在论证框架中，红色节点（$A$）表示支持这些信念的论据。
- en: '4 ArgMed-Agents: a Multi-LLM-Agents Framework'
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 ArgMed-Agents：一个多LLM智能体框架
- en: 'In Section [3](#S3 "3 Argumentation Scheme for Clinial Decision ‣ ArgMed-Agents:
    Explainable Clinical Decision Reasoning with Large Language Models via Argumentation
    Schemes"), we discussed Argumentation Schemes for clinical decision(ASCD). ASCD
    is a semi-formal reasoning template for clinical decision making by defining the
    logical structure and the reasoning mechanism in the clinical reasoning process.
    However, the clinical decision support systems based on argumentation scheme in
    the past Sassoon et al. ([2021](#bib.bib30)); Qassas et al. ([2015](#bib.bib29))
    have often been implemented through knowledge-based approaches, which rely on
    expert knowledge to build knowledge bases and rule. In this section, we propose
    a multi-agent framework called ArgMed-Agents, which supports the seamless integration
    of prompt strategy designed based on ASCD into agent interactions. Our approach
    enhances LLMs to be able to perform explainable clinical decision reasoning without
    the need for expert involvement in knowledge encoding.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在章节[3](#S3 "3 临床决策的论证方案 ‣ ArgMed-Agents：通过论证方案进行可解释的临床决策推理")中，我们讨论了临床决策的论证方案（ASCD）。ASCD是一个半正式的临床决策推理模板，通过定义临床推理过程中的逻辑结构和推理机制来进行临床决策。然而，以前基于论证方案的临床决策支持系统，如Sassoon等人（[2021](#bib.bib30)）；Qassas等人（[2015](#bib.bib29)）往往通过基于知识的方法来实现，这些方法依赖于专家知识来构建知识库和规则。在本节中，我们提出了一种名为ArgMed-Agents的多智能体框架，它支持将基于ASCD设计的提示策略无缝集成到智能体互动中。我们的方法增强了LLMs，使其能够进行可解释的临床决策推理，而无需专家参与知识编码。
- en: 4.1 ASCD-based Multi-agent Interaction
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 基于ASCD的多智能体互动
- en: 'ArgMed-Agents framework includes three distinct types of LLMs agent:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ArgMed-Agents框架包括三种不同类型的LLM智能体：
- en: •
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Generator(s): Instantiate the AS according to the current situation.'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 生成器：根据当前情况实例化AS。
- en: •
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Verifier: Whenever Generator generates an instantiation of an AS, Verifier
    checks the accuracy of the instantiation of that AS via CQ. When the CQ validation
    is rejected, return to the generator the reason why the CQ rejected, so that the
    generator generates a new AS based on the derivation rules of that CQ. The process
    iterates until no more new AS are generated.'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 验证者：每当生成器生成一个AS的实例时，验证者通过CQ检查该AS实例的准确性。当CQ验证被拒绝时，将拒绝的原因返回给生成器，以便生成器根据CQ的推导规则生成新的AS。该过程迭代，直到不再生成新的AS。
- en: •
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Reasoner: A symbolic solver for computational argumentation. At the end of
    the iteration, the arguments presented by the generator constitute a complete
    argumentation framework, and it identifies a subset of coherent and reasonable
    arguments within that argumentation framework.'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 推理者：一种用于计算论证的符号求解器。在迭代结束时，生成器提出的论证构成了一个完整的论证框架，并在该框架内识别出一组连贯且合理的论证。
- en: 'We convert ASCD into a step-by-step reasoning interaction protocol as a prompt
    strategy and define the interaction behavior between LLM agents based on ASCD
    prompt strategy, which describes the specification of the interaction behavior
    between different types of agents under the ASCD reasoning mechanism. Figure [2](#S3.F2
    "Figure 2 ‣ 3 Argumentation Scheme for Clinial Decision ‣ ArgMed-Agents: Explainable
    Clinical Decision Reasoning with Large Language Models via Argumentation Schemes")
    depicts how ArgMed-Agents interacts. In this example, $Generator_{A}$ would attack
    itself. The Verifier facilitates an iterative process of mutual debate between
    Generators, which forms an argumentation framework that can be solved by the symbolic
    Reasonner. We provide a formal description of the interaction process in Appendix
    A.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '我们将ASCD转化为逐步推理交互协议作为提示策略，并基于ASCD提示策略定义LLM代理之间的交互行为，该策略描述了在ASCD推理机制下，不同类型代理之间交互行为的规范。图[2](#S3.F2
    "Figure 2 ‣ 3 Argumentation Scheme for Clinial Decision ‣ ArgMed-Agents: Explainable
    Clinical Decision Reasoning with Large Language Models via Argumentation Schemes")展示了ArgMed-Agents如何进行交互。在这个例子中，$Generator_{A}$将会攻击自己。验证者促进生成器之间的互辩的迭代过程，形成一个由符号推理者解决的论证框架。我们在附录A中提供了交互过程的正式描述。'
- en: In ArgMed-Agents, we do not expect single generation or single verification
    to be correct. ArgMed-Agents uses generation as a assumption to recursively prompt
    the model with critical questions, identifying conflicting and erroneous arguments
    in an iterative process. Ultimately, such mutually attacking arguments are converted
    into a formal framework that solves for a subset of reasonably coherent arguments
    via Reasoner.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在ArgMed-Agents中，我们不期望单次生成或单次验证是正确的。ArgMed-Agents利用生成作为假设，通过递归性地向模型提出关键问题，识别迭代过程中出现的冲突和错误论证。最终，这些互相攻击的论证被转化为一个正式框架，通过推理者解决出一组合理连贯的论证。
- en: The theoretical motivation for our method stems from non-monotonic logic, logical
    intuition and cognitive clinical. Studies have shown that LLM performs reasonably
    well for simple reasoning, single-step reasoning problems, however, as the number
    of reasoning steps rises, the rate of correct reasoning decreases in a catastrophic
    manner Creswell et al. ([2022](#bib.bib5)). Thus, we consider that LLM is primed
    with rational intuition, but lacks true logical reasoning ability. In light of
    this, ASCD Prompt Stratygy guides LLM in a recursive form to generate a series
    of casual reasoning steps as a tentative conclusion, with any further evidence
    withdrawing their conclusion. The process ultimately leads to a directed graph
    representing the disputed relationships. In addition this, agents with different
    LLMs roles within ArgMed-Agents interact collaboratively with each other in a
    formalized process consistent with clinical reasoning (i.e., following the ASCD
    prompt strategy). This design not only facilitates LLMs to engage in clinical
    reasoning in a critical-thinking manner, which in turn maintains a cognitive processes
    consistent with clinicians to improve the explainability of decisions, but also
    allows for the effective highlighting of some implicit knowledge in LLMs that
    cannot be readily accessed through traditional prompts.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们方法的理论动机来源于非单调逻辑、逻辑直觉和认知临床。研究表明，LLM 在简单推理和单步推理问题上表现合理，但随着推理步骤的增加，正确推理的比率以灾难性的方式下降（Creswell
    et al. ([2022](#bib.bib5))）。因此，我们认为 LLM 具有理性直觉，但缺乏真正的逻辑推理能力。鉴于此，ASCD 提示策略以递归形式指导
    LLM 生成一系列因果推理步骤作为初步结论，并通过进一步证据撤回其结论。该过程最终导致一个表示争议关系的有向图。此外，ArgMed-Agents 中具有不同
    LLM 角色的代理在与临床推理一致的正式化过程（即遵循 ASCD 提示策略）中协作互动。这一设计不仅有助于 LLM 以批判性思维方式参与临床推理，从而保持与临床医生一致的认知过程，提高决策的可解释性，而且还能够有效突出一些通过传统提示无法轻易获得的隐性知识。
- en: 4.2 Explainable Argumentative Reasoning
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 可解释的论证推理
- en: ArgMed-Agent obtains a complete argument graph by iterating through the ASCD
    Prompt Strategy. In this section, we describe how Reasoner reasons and explains
    decisions through these arguments. First, we map the reasoning results of ASCD
    to the AA framework.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ArgMed-Agent 通过迭代 ASCD 提示策略来获得完整的论证图。在这一部分，我们描述了推理器如何通过这些论证进行推理和解释决策。首先，我们将
    ASCD 的推理结果映射到 AA 框架中。
- en: Definition 1.
  id: totrans-53
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 1.
- en: 'An AA framework for ASCD is a pair $\langle\mathcal{A},\mathcal{R}\rangle$
    such that:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ASCD 的 AA 框架是一个对 $\langle\mathcal{A},\mathcal{R}\rangle$ 的配对，其中：
- en: •
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: $\exists arg=\langle P,c,V\rangle\in\mathcal{A}$ is constituted by the argumentation
    schemes.
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\exists arg=\langle P,c,V\rangle\in\mathcal{A}$ 是由论证方案构成的。
- en: •
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: $\mathcal{A}=Args_{d}(\mathcal{A})\cup Args_{b}(\mathcal{A})$.
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\mathcal{A}=Args_{d}(\mathcal{A})\cup Args_{b}(\mathcal{A})$。
- en: 'In Definition [1](#Thmdefinition1 "Definition 1\. ‣ 4.2 Explainable Argumentative
    Reasoning ‣ 4 ArgMed-Agents: a Multi-LLM-Agents Framework ‣ ArgMed-Agents: Explainable
    Clinical Decision Reasoning with Large Language Models via Argumentation Schemes"),
    arguments in support of decisions $Args_{d}(\mathcal{A})$ correspond to ASSE and
    ASBD in the argumentation scheme. These two types of arguments play different
    roles; arguments in support of decisions build on beliefs and goals and try to
    justify choices, while arguments in support of beliefs always try to undermine
    decision arguments. Therefore, based on the modeling of ASCD, we make the following
    setup for the attack relation between these two types of arguments: first, arguments
    in support of different decisions are in conflict with each other, which is consistent
    with our previous description of decisions being exclusive in ASCD. Second, arguments
    in support of decisions are not allowed to attack arguments in support of beliefs,
    which is dictated by the modeling of ASCD, as can be seen in Figure [1](#S3.F1
    "Figure 1 ‣ 3 Argumentation Scheme for Clinial Decision ‣ ArgMed-Agents: Explainable
    Clinical Decision Reasoning with Large Language Models via Argumentation Schemes"),
    where ASSE and ASBD are always trying to disprove ASD, while the converse does
    not work. Formalized as:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '在定义 [1](#Thmdefinition1 "定义 1\. ‣ 4.2 可解释的论证推理 ‣ 4 ArgMed-Agents: 一个多LLM代理框架
    ‣ ArgMed-Agents: 通过论证方案使用大型语言模型的可解释临床决策推理") 中，支持决策的论点 $Args_{d}(\mathcal{A})$
    对应于论证方案中的ASSE和ASBD。这两种类型的论点扮演着不同的角色；支持决策的论点基于信念和目标并尝试为选择提供理由，而支持信念的论点则总是试图削弱决策论点。因此，根据ASCD的建模，我们对这两种论点之间的攻击关系做出如下设置：首先，支持不同决策的论点相互冲突，这与我们之前描述的ASCD中决策的排他性是一致的。其次，支持决策的论点不允许攻击支持信念的论点，这由ASCD的建模决定，如图
    [1](#S3.F1 "图 1 ‣ 3 临床决策的论证方案 ‣ ArgMed-Agents: 通过论证方案使用大型语言模型的可解释临床决策推理") 所示，其中ASSE和ASBD总是试图驳斥ASD，而反之则不起作用。形式化为：'
- en: Definition 2.
  id: totrans-60
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 2。
- en: 'Given an AA framework for ASCD $\langle\mathcal{A},\mathcal{R}\rangle$ such
    that:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个用于ASCD的AA框架 $\langle\mathcal{A},\mathcal{R}\rangle$，其中：
- en: •
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: $\forall arg_{1},arg_{2}$
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\forall arg_{1},arg_{2}$
- en: •
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: $\nexists(arg_{1},arg_{2})$.
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\nexists(arg_{1},arg_{2})$。
- en: Next, we use the preferred semantics in the AA framework to illustrate how the
    Reasoner Agent selects the set of possible admissible arguments to support clinical
    decision.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用AA框架中的首选语义来说明推理代理如何选择一组可能的可接受论点以支持临床决策。
- en: Definition 3.
  id: totrans-67
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 3。
- en: Given an AA framework for ASCD $\langle\mathcal{A},\mathcal{R}\rangle$.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个用于ASCD的AA框架 $\langle\mathcal{A},\mathcal{R}\rangle$。
- en: Example 1.
  id: totrans-69
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 示例 1。
- en: An AA framework for ASCD is given below such that $Args_{d}(\mathcal{A})=\{A,B,C\}$
    are optional because they are supported by preferred extension.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 一个用于ASCD的AA框架如下所示，其中 $Args_{d}(\mathcal{A})=\{A,B,C\}$ 是可选的，因为它们由首选扩展所支持。
- en: 'A
    B
    C
    E D Admissible Sets: $\displaystyle\{B,D,E\},$'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: A
    B
    C
    E D 可接受的集合：$\displaystyle\{B,D,E\},$
- en: In this regard, we present a proposition to justify the Reasoner agent’s use
    of preferred semantics for decision making.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在这方面，我们提出了一个命题，以证明 Reasoner agent 使用优选语义进行决策的合理性。
- en: Proposition 1.
  id: totrans-73
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 命题 1。
- en: Given an AA framework for ASCD $\langle\mathcal{A},\mathcal{R}\rangle$ where,
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个用于 ASCD 的 AA 框架 $\langle\mathcal{A},\mathcal{R}\rangle$ 其中，
- en: •
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: $\exists a\in Args_{d}(\mathcal{A})$
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\exists a\in Args_{d}(\mathcal{A})$
- en: •
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: $\exists a\in Args_{d}(\mathcal{E})$.
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\exists a\in Args_{d}(\mathcal{E})$。
- en: 'Proposition [1](#Thmproposition1 "Proposition 1\. ‣ 4.2 Explainable Argumentative
    Reasoning ‣ 4 ArgMed-Agents: a Multi-LLM-Agents Framework ‣ ArgMed-Agents: Explainable
    Clinical Decision Reasoning with Large Language Models via Argumentation Schemes")
    states that using preferred semantics on the AA framework for ASCD always selects
    extensions that contain the only acceptable decision, which is consistent with
    our expected reasoning. Meanwhile, arguments from $Args_{b}(\mathcal{E})$ Fan
    and Toni ([2015](#bib.bib12)). The proof of the proposition proceeds as follows:
    We first prove that there will be only one decision in the preferred extension.
    According to Definition [2](#Thmdefinition2 "Definition 2\. ‣ 4.2 Explainable
    Argumentative Reasoning ‣ 4 ArgMed-Agents: a Multi-LLM-Agents Framework ‣ ArgMed-Agents:
    Explainable Clinical Decision Reasoning with Large Language Models via Argumentation
    Schemes"), we know that decisions are exclusive, so different decisions do not
    appear in the same admissible set. Secondly, we prove that the preferred extension
    will always contain a argument in support of decision. According to the modeling
    of ASCD as well as Definition [2](#Thmdefinition2 "Definition 2\. ‣ 4.2 Explainable
    Argumentative Reasoning ‣ 4 ArgMed-Agents: a Multi-LLM-Agents Framework ‣ ArgMed-Agents:
    Explainable Clinical Decision Reasoning with Large Language Models via Argumentation
    Schemes"), it can be seen that arguments in support of decision (ASD) are built
    on top of arguments in support of beliefs (ASSE and ASBD), i.e., the inclusion
    of ASD arguments does not lead to the ASSE and ASBD arguments becoming unacceptable.
    Therefore, the set is maximized when the acceptable set includes pro-decision
    arguments.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '命题 [1](#Thmproposition1 "命题 1\. ‣ 4.2 可解释的论证推理 ‣ 4 ArgMed-Agents: 多LLM-Agents框架
    ‣ ArgMed-Agents: 通过论证方案的可解释临床决策推理") 说明在 AA 框架下使用优选语义进行 ASCD 时，总是选择包含唯一可接受决策的扩展，这与我们预期的推理一致。同时，来自
    $Args_{b}(\mathcal{E})$ 的论点 Fan 和 Toni ([2015](#bib.bib12))。该命题的证明如下：我们首先证明在优选扩展中将只有一个决策。根据定义
    [2](#Thmdefinition2 "定义 2\. ‣ 4.2 可解释的论证推理 ‣ 4 ArgMed-Agents: 多LLM-Agents框架 ‣
    ArgMed-Agents: 通过论证方案的可解释临床决策推理")，我们知道决策是排他的，因此不同的决策不会出现在同一个可接受集合中。其次，我们证明优选扩展总是会包含支持决策的论点。根据
    ASCD 的建模以及定义 [2](#Thmdefinition2 "定义 2\. ‣ 4.2 可解释的论证推理 ‣ 4 ArgMed-Agents: 多LLM-Agents框架
    ‣ ArgMed-Agents: 通过论证方案的可解释临床决策推理")，可以看出，支持决策的论点（ASD）是建立在支持信念的论点（ASSE 和 ASBD）之上的，即包含
    ASD 论点不会导致 ASSE 和 ASBD 论点变得不可接受。因此，当可接受集合包括支持决策的论点时，集合是最大化的。'
- en: Definition 4.
  id: totrans-80
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 4。
- en: Given an AA framework for ASCD $\langle\mathcal{A},\mathcal{R}\rangle$.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个用于 ASCD 的 AA 框架 $\langle\mathcal{A},\mathcal{R}\rangle$。
- en: 'Clinical reasoning errors are discussed in Tang et al. ([2024](#bib.bib35)).
    They consider that most clinical reasoning errors in LLMs are due to confusion
    about domain knowledge. On the other hand, research by Singhal et al. ([2022](#bib.bib33))
    points out that LLMs may produce compelling misinformation about medical treatment,
    so it is crucial to recognize this illusion, which is difficult for humans to
    detect. For this purpose, we define the relevant mechanisms for identifying clinical
    reasoning errors in Reasoner as follows: When any decision in the AA framework
    is not accepted, we consider there are errors in the reasoning by ArgMed-Agents.
    This mechanism assists ArgMed-Agents in identifying the capability boundaries
    of LLMs when their knowledge reserves are insufficient to address certain issues.This
    helps ArgMed-Agents avoid the risks associated with adopting erroneous decisions
    and achieving more robust and safe clinical reasoning.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 临床推理错误在 Tang 等人 ([2024](#bib.bib35)) 中进行了讨论。他们认为，LLMs 中的大多数临床推理错误是由于对领域知识的混淆。另一方面，Singhal
    等人 ([2022](#bib.bib33)) 的研究指出，LLMs 可能会产生有关医疗治疗的令人信服的错误信息，因此识别这种错觉至关重要，这对人类而言很难检测。为此，我们在
    Reasoner 中定义了识别临床推理错误的相关机制：当 AA 框架中的任何决策未被接受时，我们认为 ArgMed-Agents 的推理存在错误。该机制帮助
    ArgMed-Agents 识别 LLMs 的能力边界，当其知识储备不足以解决某些问题时。这有助于 ArgMed-Agents 避免采纳错误决策的风险，实现更稳健和安全的临床推理。
- en: 5 Experiments
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 实验
- en: In this section, we demonstrate the potential of ArgMed-Agents in clinical decision
    reasoning by evaluating the accuracy and explainability.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们通过评估准确性和可解释性展示了 ArgMed-Agents 在临床决策推理中的潜力。
- en: 'We implemented Generator and Verifier in ArgMed-Agents using the APIs GPT-3.5-turbo
    and GPT-4 provided by OpenAI OpenAI ([2023](#bib.bib25)), and according to our
    setup, the LLM Agents are implemented with the same LLM and different few-shot
    prompts. Each agent is configured with specific parameters: the temperature is
    set to 0.0, as well as a dialogue limit of 4, indicating the maximum number of
    decisions allowed for ArgMed-Agents to generate, which is to prevent the agents
    from getting into loops with each other. On the other hand, we using python3 to
    implemente a symbolic solver of abstract argumentation framework as Reasoner.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 ArgMed-Agents 中实现了 Generator 和 Verifier，使用了 OpenAI 提供的 GPT-3.5-turbo 和 GPT-4
    APIs ([2023](#bib.bib25))，根据我们的设置，LLM Agents 采用相同的 LLM 和不同的少量示例提示。每个 agent 都配置了特定的参数：温度设置为
    0.0，并且对话限制为 4，表示 ArgMed-Agents 生成的决策的最大数量，这旨在防止 agent 之间产生循环。另一方面，我们使用 python3
    实现了一个符号推理器作为 Reasoner。
- en: 5.1 Accuracy
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 准确性
- en: 'The following two datasets were used to assess the accuracy of ArgMed-Agents
    clinical reasoning:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 以下两个数据集用于评估 ArgMed-Agents 临床推理的准确性：
- en: •
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: MedQA Jin et al. ([2020](#bib.bib17)):Answering multiple-choice questions derived
    from the United States Medical License Exams (USMLE). This dataset is sourced
    from official medical board exams and encompasses questions in English, simplified
    Chinese, and traditional Chinese. The total question counts for each language
    are 12,723, 34,251, and 14,123, respectively.
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: MedQA Jin 等人 ([2020](#bib.bib17))：回答来源于美国医学执照考试（USMLE）的多项选择题。该数据集来源于官方医学考试，包括英文、简体中文和繁体中文的问题。每种语言的问题总数分别为
    12,723、34,251 和 14,123。
- en: •
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'PubMedQA Jin et al. ([2019](#bib.bib16)): A biomedical question and answer
    (QA) dataset collected from PubMed abstracts. The task of PubMedQA is to answer
    yes/no/maybe research questions using the corresponding abstracts (e.g., Do preoperative
    statins reduce atrial fibrillation after coronary artery bypass graft surgery?).'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: PubMedQA Jin 等人 ([2019](#bib.bib16))：一个从 PubMed 摘要中收集的生物医学问答（QA）数据集。PubMedQA
    的任务是使用相应的摘要回答是/否/也许的研究问题（例如，术前使用他汀类药物是否减少了冠状动脉旁路移植术后的房颤？）。
- en: We randomly selected 300 examples in each dataset for our experiments. We set
    the baseline in our experiments to compare with gpt direct generation and Chain
    of Thought(CoT) Wei et al. ([2023](#bib.bib39)). It is worth noting that we focussed
    on evaluating the performance of ArgMed-Agents on clinical decision reasoning,
    however, there were some biomedical general knowledge quiz-type questions in MedQA
    and PubMedQA, and so we intentionally excluded this part of the questioning in
    selecting the example.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在每个数据集中随机选择了 300 个示例进行实验。我们设置了基线，以便与 GPT 直接生成和 Chain of Thought (CoT) Wei
    et al. ([2023](#bib.bib39)) 进行比较。值得注意的是，我们专注于评估 ArgMed-Agents 在临床决策推理中的表现，但在 MedQA
    和 PubMedQA 中确实有一些生物医学常识问答类型的问题，因此我们在选择示例时有意排除了这一部分的问题。
- en: '| Model | Method | MedQA | PubMedQA |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| Model | Method | MedQA | PubMedQA |'
- en: '|  | Direct | 52.7 | 68.4 |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '|  | Direct | 52.7 | 68.4 |'
- en: '| GPT-3.5-turbo | CoT | 48.0 | 71.5 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5-turbo | CoT | 48.0 | 71.5 |'
- en: '|  | ArgMed-Agents | 62.1 | 78.3 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '|  | ArgMed-Agents | 62.1 | 78.3 |'
- en: '|  | Direct | 67.8 | 72.9 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '|  | Direct | 67.8 | 72.9 |'
- en: '| GPT-4 | CoT | 71.4 | 77.2 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | CoT | 71.4 | 77.2 |'
- en: '|  | ArgMed-Agents | 83.3 | 81.6 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '|  | ArgMed-Agents | 83.3 | 81.6 |'
- en: 'Table 1: Results of the accuracy of various clinical decision reasoning methods
    on MedQA and PubMedQA datasets.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：各种临床决策推理方法在 MedQA 和 PubMedQA 数据集上的准确性结果。
- en: 'Table [1](#S5.T1 "Table 1 ‣ 5.1 Accuracy ‣ 5 Experiments ‣ ArgMed-Agents: Explainable
    Clinical Decision Reasoning with Large Language Models via Argumentation Schemes")
    shows the accuracy results of MedQA and PubMedQA. We compared ArgMed-Agents to
    several baselines in direct generation and CoT settings. Notably, both GPT-3.5-turbo
    and GPT4 models showed that our proposed ArgMed-Agents improved accuracy on a
    clinical decision reasoning task compared to a baseline such as CoT. This result
    demonstrates the effectiveness of ArgMed-Agents to enhance the clinical reasoning
    performance of LLMs. Interestingly, after we repeated the experiment several times,
    we found that the introduction of CoT sometimes leads to a surprising drop in
    performance. The reason for this may be that when LLMs experience hallucinatory
    phenomena, the use of CoT will amplify such hallucinations indefinitely. In contrast,
    our approach of using mutual argumentation iterations between multiple agents
    effectively mitigates this problem. We analysed the data from our experiments
    and found that each AS’s CQ1 (i.e., asking the Verifier whether there is evidence
    to support the argument made by the Generator) acts as a hallucination detector
    in the reasoning process. On the other hand, we analysed the examples in which
    both Direct Generation, CoT and ArgMed-Agents reasoned wrongly. We found that
    ArgMed-Agents can report 76% of errors in these examples according to Reasoner’s
    definition [4](#Thmdefinition4 "Definition 4\. ‣ 4.2 Explainable Argumentative
    Reasoning ‣ 4 ArgMed-Agents: a Multi-LLM-Agents Framework ‣ ArgMed-Agents: Explainable
    Clinical Decision Reasoning with Large Language Models via Argumentation Schemes").
    This provides initial evidence that ArgMed-Agents not only has higher accuracy
    compared to baseline, but also that it is safer for clinical decision reasoning.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '表 [1](#S5.T1 "Table 1 ‣ 5.1 Accuracy ‣ 5 Experiments ‣ ArgMed-Agents: Explainable
    Clinical Decision Reasoning with Large Language Models via Argumentation Schemes")
    显示了 MedQA 和 PubMedQA 的准确性结果。我们将 ArgMed-Agents 与直接生成和 CoT 设置中的几个基线进行了比较。值得注意的是，GPT-3.5-turbo
    和 GPT4 模型都显示出我们提出的 ArgMed-Agents 在临床决策推理任务中的准确性优于 CoT 等基线。这一结果证明了 ArgMed-Agents
    提高 LLMs 临床推理表现的有效性。有趣的是，在我们重复实验几次后，我们发现 CoT 的引入有时会导致性能意外下降。这可能是因为当 LLMs 发生幻觉现象时，使用
    CoT 会无限放大这种幻觉。相比之下，我们的多代理人之间的相互论证迭代方法有效地缓解了这个问题。我们分析了实验数据，发现每个 AS 的 CQ1（即询问验证者是否有证据支持生成者提出的论点）在推理过程中充当了幻觉检测器。另一方面，我们分析了
    Direct Generation、CoT 和 ArgMed-Agents 都错误推理的示例。我们发现，按照 Reasoner 的定义 [4](#Thmdefinition4
    "Definition 4\. ‣ 4.2 Explainable Argumentative Reasoning ‣ 4 ArgMed-Agents: a
    Multi-LLM-Agents Framework ‣ ArgMed-Agents: Explainable Clinical Decision Reasoning
    with Large Language Models via Argumentation Schemes")，ArgMed-Agents 能报告这些示例中的
    76% 错误。这提供了初步证据，表明 ArgMed-Agents 不仅比基线具有更高的准确性，而且在临床决策推理中更安全。'
- en: 5.2 Human Evaluation for Explainability
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 解释性的人类评估
- en: 'The main focus of Explainable AI (XAI) is usually the reasoning behind decisions
    or predictions made by AI that become more understandable and transparent. In
    the context of artificial intelligence, Explainability is defined as follows ISO
    ([2020](#bib.bib15)):'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释人工智能（XAI）的主要关注点通常是 AI 做出的决策或预测背后的推理，使其变得更易理解和透明。在人工智能的背景下，可解释性定义如下 ISO ([2020](#bib.bib15))：
- en: …level of understanding how the AI-based system came up with a given result.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: …了解基于 AI 的系统如何得出给定结果的程度。
- en: 'Based on this criterion, we define two measures of LLMs’ explanability:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这一标准，我们定义了 LLM 可解释性的两个度量：
- en: •
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'predictability(Pre.): Can the explanations given by LLMs help users predict
    LLM decisions?'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可预测性（Pre.）：LLM 提供的解释是否有助于用户预测 LLM 的决策？
- en: •
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'proof-based traceability(Tra.): Can the model reason about the correct decision
    based on the correct path of inference (i.e. does the path of inference as an
    explanation have relevance to the LLM’s decision)?'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 证明基础的可追溯性（Tra.）：模型是否可以基于正确的推理路径对正确的决策进行推理（即，推理路径作为解释是否与 LLM 的决策相关）？
- en: '| Method | Pre. | Tra. | $\%$ Arg. |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | Pre. | Tra. | $\%$ Arg. |'
- en: '| CoT | 0.63 | 2.8 | 59.5$\%$ |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| CoT | 0.63 | 2.8 | 59.5$\%$ |'
- en: '| ArgMed-Agents | 0.91 | 4.2 | 87.5$\%$ |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| ArgMed-Agents | 0.91 | 4.2 | 87.5$\%$ |'
- en: 'Table 2: Human evaluation result on 20 examples.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：对 20 个示例的人类评估结果。
- en: 'For the evaluation of predictability, our experimental setup is as follows:
    we recorded the inputs and the reasoning process (e.g., the complete dialogue
    between Generator and Verifier in ArgMed-Agents and the corresponding argumentation
    framework). We invited 50 undergraduate and graduate students in medical-related
    disciplines to answer questions given only the inputs to the LLMs as well as the
    explanations (four questions were distributed to each individual), and counted
    to what extent they were able to predict the decisions of the LLMs.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 对于可预测性的评估，我们的实验设置如下：我们记录了输入和推理过程（例如，ArgMed-Agents 中生成器和验证器之间的完整对话以及相应的论证框架）。我们邀请了
    50 名医学相关学科的本科生和研究生，仅根据输入和解释回答问题（每人分发四个问题），并统计他们在多大程度上能够预测 LLM 的决策。
- en: 'Our team has produced a fully functional knowledge-based clinical decision
    support system at an early stage that can be used to assist in treatment decisions
    for complex diseases such as cancer, neurological disorders, and infectious diseases.
    Figure [3](#S5.F3 "Figure 3 ‣ 5.2 Human Evaluation for Explainability ‣ 5 Experiments
    ‣ ArgMed-Agents: Explainable Clinical Decision Reasoning with Large Language Models
    via Argumentation Schemes") illustrates this knowledge-based CDSS, consisting
    of computer-interpretable guidelines in the form of Resource Description Framework
    (RDF) Klyne and Carroll ([2004](#bib.bib20)) and the corresponding inference engine.
    We use the knowledge-based CDSS’s process of performing reasoning on the 20 examples
    in MedQA as a logical criterion for measuring the proof-based traceability of
    LLMs. We manually evaluated the consistency of ArgMed-Agents’ reasoning paths
    with logical criteria and the relevance of explanations to decision making, scoring
    each example on a scale of one to five. CoT performance was also used as a comparison.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的团队在早期阶段开发了一个功能齐全的知识基础临床决策支持系统，能够用于辅助治疗复杂疾病的决策，如癌症、神经系统疾病和传染病。图 [3](#S5.F3
    "图 3 ‣ 5.2 人工评估可解释性 ‣ 5 实验 ‣ ArgMed-Agents：通过论证方案实现的大型语言模型的可解释临床决策推理") 展示了这一知识基础
    CDSS，它由以资源描述框架（RDF）Klyne 和 Carroll ([2004](#bib.bib20)) 形式呈现的计算机可解释的指南以及相应的推理引擎组成。我们使用知识基础
    CDSS 在 MedQA 中对 20 个示例进行推理的过程作为衡量 LLM 证明基础可追溯性的逻辑标准。我们手动评估了 ArgMed-Agents 推理路径与逻辑标准的一致性以及解释与决策的相关性，对每个示例进行了
    1 到 5 的评分。同时也将 CoT 性能作为对比。
- en: '![Refer to caption](img/f0056aa6c5c303ca1364daad6e45389f.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/f0056aa6c5c303ca1364daad6e45389f.png)'
- en: 'Figure 3: A screenshot of the knowledge-based CDSS for diagnosing depression,
    where prismatic nodes represent enquiry, circular nodes represent decision, and
    square nodes represent action.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：用于诊断抑郁症的知识基础临床决策支持系统的截图，其中棱柱形节点表示查询，圆形节点表示决策，方形节点表示行动。
- en: 'In Table [2](#S5.T2 "Table 2 ‣ 5.2 Human Evaluation for Explainability ‣ 5
    Experiments ‣ ArgMed-Agents: Explainable Clinical Decision Reasoning with Large
    Language Models via Argumentation Schemes"), it is shown that ArgMed-Agents outperforms
    CoT in both measures of explainability. Specifically, in the experiment evaluating
    predictability, 50 participants answered the question a total of 200 times, of
    which participants succeeded 91 out of 100 times in predicting ArgMed-Agents decisions,
    compared to 63/100 times in predicting the CoT. On the other hand, most of the
    reasoning nodes of the knowledge-based CDSS can be found to correspond in the
    reasoning process of ArgMed-Agents, whereas the reasoning process of the CoT method
    to arrive at an answer is often logically incomplete. Interestingly, we found
    that the reasoning of the knowledge-based CDSS on many examples can be regarded
    as a reasoning subgraph of ArgMed-Agents, probably because ArgMed-Agents traverses
    all the reasoning paths in a randomly generated manner, and thus the reasoning
    graph includes not only the reasoning paths of the correct decisions, but also
    the explanations of the incorrect decisions.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '在表格[2](#S5.T2 "Table 2 ‣ 5.2 Human Evaluation for Explainability ‣ 5 Experiments
    ‣ ArgMed-Agents: Explainable Clinical Decision Reasoning with Large Language Models
    via Argumentation Schemes")中，显示ArgMed-Agents在解释性两个指标上均优于CoT。具体而言，在评估预测能力的实验中，50名参与者共回答了200次问题，其中参与者成功预测ArgMed-Agents决策的次数为91/100次，而预测CoT决策的次数为63/100次。另一方面，大多数基于知识的CDSS的推理节点可以在ArgMed-Agents的推理过程中找到对应，而CoT方法的推理过程往往在逻辑上不完整。有趣的是，我们发现知识型CDSS在许多示例上的推理可以视为ArgMed-Agents的推理子图，可能是因为ArgMed-Agents以随机生成的方式遍历所有推理路径，因此推理图不仅包含正确决策的推理路径，还包含错误决策的解释。'
- en: 6 Related Work
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 相关工作
- en: 6.1 LLM-based Clinical Decision Support System
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 基于LLM的临床决策支持系统
- en: Extensive research highlights the potential for LLMs to be used in medicine
    Bao et al. ([2023](#bib.bib2)); Nori et al. ([2023](#bib.bib23)); Jin et al. ([2023](#bib.bib18)).
    However, LLMs still struggle to make safe and trustworthy decisions when they
    encounter clinical decisions that require complex medical expertise and good reasoning
    skills Singhal et al. ([2022](#bib.bib33)). Therefore, much work has begun to
    focus on ways to enhance clinical reasoning in LLMs. Tang et al. ([2024](#bib.bib35))
    proposes a Multi-disciplinary Collaboration (MC) framework that utilises LLM-based
    agents in a role-playing environment that engages in collaborative multi-round
    discussions until consensus is reached. Despite the results achieved, the method
    is unable to formalise the iterative results in such a way as to enhance the inference
    performance of the LLM using inference tools. Savage et al. ([2024](#bib.bib31))
    proposes a method that uses diagnostic reasoning prompts to improve clinical reasoning
    abilities and interpretability in LLM. However, their approach does not focus
    on critical reasoning in clinical decision-making, which allows LLM to generate
    explanations of why one decision is ”good” but not why others were not chosen.
    In addition to this, the work such as Singhal et al. ([2023](#bib.bib34)); Li
    et al. ([2023](#bib.bib21)) fine-tuned LLMs using extensive datasets collected
    from the medical and biomedical literature. Unlike our approach, ours focuses
    more on exploiting the latent medical knowledge inherent in LLMs to improve their
    reasoning ability in a training-free environment.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 大量研究突显了LLM在医学领域的潜力 Bao et al. ([2023](#bib.bib2))；Nori et al. ([2023](#bib.bib23))；Jin
    et al. ([2023](#bib.bib18))。然而，LLM在遇到需要复杂医学专业知识和良好推理技能的临床决策时，仍然难以做出安全和可靠的决策 Singhal
    et al. ([2022](#bib.bib33))。因此，许多工作已开始集中于如何增强LLM的临床推理能力。Tang et al. ([2024](#bib.bib35))
    提出了一个多学科合作（MC）框架，该框架利用基于LLM的代理在角色扮演环境中进行协作性多轮讨论，直到达成共识。尽管取得了成果，但该方法无法将迭代结果形式化，从而利用推理工具提升LLM的推理性能。Savage
    et al. ([2024](#bib.bib31)) 提出了一个使用诊断推理提示来提高LLM临床推理能力和解释性的方案。然而，他们的方法并未关注临床决策中的关键推理，使得LLM能够生成一个决策“好”的解释，却无法说明其他未选择的理由。此外，Singhal
    et al. ([2023](#bib.bib34))；Li et al. ([2023](#bib.bib21)) 等工作通过使用从医学和生物医学文献中收集的大量数据集对LLM进行了微调。与我们的方案不同，我们的方法更关注利用LLM固有的潜在医学知识，在无训练环境中提升其推理能力。
- en: 6.2 Logical Reasoning with LLMs
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 基于LLM的逻辑推理
- en: An extensive body of research has been dedicated to utilizing symbolic systems
    to augment reasoning, which includes code environments, knowledge graphs, and
    formal theorem provers Pan et al. ([2023](#bib.bib27), [2024](#bib.bib28)); Wu
    et al. ([2023](#bib.bib40)). In the study by Jung et al. Jung et al. ([2022](#bib.bib19)),
    reasoning is constructed as a satisfiability problem of its logical relations
    through inverse causal reasoning, with consistent reasoning enhanced using SAT
    solvers to improve the reasoning abilities of Large Language Models (LLMs). Zhang
    et al.’s work Zhang et al. ([2023](#bib.bib44)) employs cumulative reasoning to
    decompose tasks into smaller components, thereby simplifying the problem-solving
    process and enhancing efficiency. Xiu et al. Xiu et al. ([2022](#bib.bib42)) delve
    into the non-monotonic reasoning capabilities of LLMs. However, despite the initial
    promise exhibited by LLMs, their performance falls short in terms of generalization
    and proof-based traceability, with a significant decline in performance observed
    with increasing depth of reasoning. In line with our study, some recent works
    have started to explore the potential for argumentative reasoning in LLMs Chen
    et al. ([2023](#bib.bib4)), aiming to enhance LLMs argumentative reasoning abilities
    de Wynter and Yuan ([2023](#bib.bib7)); Castagna et al. ([2024](#bib.bib3)).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 大量研究致力于利用符号系统来增强推理，这包括代码环境、知识图谱和形式化定理证明工具 Pan et al. ([2023](#bib.bib27), [2024](#bib.bib28));
    Wu et al. ([2023](#bib.bib40))。在Jung et al.的研究中 Jung et al. ([2022](#bib.bib19))，推理被构建为其逻辑关系的可满足性问题，通过逆因果推理来进行，使用SAT求解器增强一致性推理，以提高大型语言模型（LLMs）的推理能力。Zhang
    et al.的工作 Zhang et al. ([2023](#bib.bib44)) 使用累积推理将任务分解为更小的组件，从而简化问题解决过程并提高效率。Xiu
    et al. Xiu et al. ([2022](#bib.bib42)) 探讨了LLMs的非单调推理能力。然而，尽管LLMs展示了初步的前景，但它们在泛化和基于证据的可追溯性方面的表现仍不尽如人意，推理深度的增加导致性能显著下降。与我们的研究一致，一些近期的工作开始探索LLMs中论证推理的潜力
    Chen et al. ([2023](#bib.bib4))，旨在提升LLMs的论证推理能力 de Wynter 和 Yuan ([2023](#bib.bib7));
    Castagna et al. ([2024](#bib.bib3))。
- en: 7 Conclusion
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: In this work, We propose a novel medical multi-agent interaction framework called
    ArgMed-Agents, which inspires agents of different roles to iterate through argumentation
    and critical questioning, systematically generating an abstract argumentation
    framework. Then, using a Reasoner agent to identify a set of reasonable and coherent
    arguments in this framework as decision support. The experimental results indicate
    that, compared to different baselines, using ArgMed-Agent for clinical decision-making
    reasoning achieves greater accuracy and provides inherent explanations for its
    inferences.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们提出了一个新颖的医疗多代理互动框架，称为**ArgMed-Agents**，该框架激发了不同角色的代理通过论证和批判性提问进行迭代，系统地生成一个抽象论证框架。然后，使用Reasoner代理在该框架中识别出一组合理且连贯的论证作为决策支持。实验结果表明，与不同的基线相比，使用**ArgMed-Agent**进行临床决策推理能够实现更高的准确性，并为其推理提供内在的解释。
- en: Despite the success of ArgMed-Agents, there are still some limitations. In particular,
    abstract arguments alone may struggle with clinical reasoning tasks that numerical
    calculations or probabilistic reasoning. Therefore, future research will focus
    on enhancing the capabilities of ArgMed-Agents to address these challenges. One
    promising avenue involves exploring the integration of value-based argumentation
    or probabilistic argumentation techniques. Our goal is to provide healthcare professionals
    with powerful tools to enhance their decision-making process and ultimately improve
    patient outcomes.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管**ArgMed-Agents**取得了成功，但仍存在一些局限性。特别是，单靠抽象论证可能在处理需要数值计算或概率推理的临床推理任务时面临困难。因此，未来的研究将重点提升**ArgMed-Agents**的能力，以应对这些挑战。一个有前景的方向是探索基于价值的论证或概率论证技术的整合。我们的目标是为医疗专业人员提供强大的工具，以增强他们的决策过程，并*最终改善患者结果*。
- en: Ethical Statement
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 伦理声明
- en: There are no ethical issues.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 没有伦理问题。
- en: References
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Ayers et al. [2023] John W. Ayers, Adam Poliak, Mark Dredze, Eric C. Leas, Zechariah
    Zhu, Jessica B. Kelley, Dennis J. Faix, Aaron M. Goodman, Christopher A. Longhurst,
    Michael Hogarth, and Davey M. Smith. Comparing Physician and Artificial Intelligence
    Chatbot Responses to Patient Questions Posted to a Public Social Media Forum.
    JAMA Internal Medicine, 183(6):589–596, 06 2023.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ayers et al. [2023] John W. Ayers、Adam Poliak、Mark Dredze、Eric C. Leas、Zechariah
    Zhu、Jessica B. Kelley、Dennis J. Faix、Aaron M. Goodman、Christopher A. Longhurst、Michael
    Hogarth 和 Davey M. Smith。比较医生与人工智能聊天机器人对公开社交媒体论坛上患者问题的回应。JAMA 内科医学，183(6):589–596，2023年6月。
- en: 'Bao et al. [2023] Zhijie Bao, Wei Chen, Shengze Xiao, Kuang Ren, Jiaao Wu,
    Cheng Zhong, Jiajie Peng, Xuanjing Huang, and Zhongyu Wei. Disc-medllm: Bridging
    general large language models and real-world medical consultation, 2023.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bao et al. [2023] Zhijie Bao、Wei Chen、Shengze Xiao、Kuang Ren、Jiaao Wu、Cheng
    Zhong、Jiajie Peng、Xuanjing Huang 和 Zhongyu Wei。Disc-medllm：桥接通用大语言模型与现实世界医疗咨询，2023年。
- en: 'Castagna et al. [2024] Federico Castagna, Nadin Kokciyan, Isabel Sassoon, Simon
    Parsons, and Elizabeth Sklar. Computational argumentation-based chatbots: a survey,
    2024.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Castagna et al. [2024] Federico Castagna、Nadin Kokciyan、Isabel Sassoon、Simon
    Parsons 和 Elizabeth Sklar。基于计算论证的聊天机器人：一项调查，2024年。
- en: Chen et al. [2023] Guizhen Chen, Liying Cheng, Luu Anh Tuan, and Lidong Bing.
    Exploring the potential of large language models in computational argumentation,
    2023.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. [2023] Guizhen Chen、Liying Cheng、Luu Anh Tuan 和 Lidong Bing。探索大语言模型在计算论证中的潜力，2023年。
- en: 'Creswell et al. [2022] Antonia Creswell, Murray Shanahan, and Irina Higgins.
    Selection-inference: Exploiting large language models for interpretable logical
    reasoning, 2022.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Creswell et al. [2022] Antonia Creswell、Murray Shanahan 和 Irina Higgins。选择推断：利用大语言模型进行可解释的逻辑推理，2022年。
- en: 'Čyras et al. [2018] Kristijonas Čyras, Brendan Delaney, Denys Prociuk, Francesca
    Toni, Martin Chapman, Jesús Domínguez, and Vasa Curcin. Argumentation for explainable
    reasoning with conflicting medical recommendations. CEUR Workshop Proceedings,
    2237, January 2018. 2018 Joint Reasoning with Ambiguous and Conflicting Evidence
    and Recommendations in Medicine and the 3rd International Workshop on Ontology
    Modularity, Contextuality, and Evolution, MedRACER + WOMoCoE 2018 ; Conference
    date: 29-10-2018.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Čyras et al. [2018] Kristijonas Čyras、Brendan Delaney、Denys Prociuk、Francesca
    Toni、Martin Chapman、Jesús Domínguez 和 Vasa Curcin。关于带有冲突医疗建议的可解释推理的论证。CEUR工作坊论文集，2237，2018年1月。2018年在模棱两可和冲突证据与建议的联合推理会议和第三届本体模块化、上下文和演变国际研讨会（MedRACER
    + WOMoCoE 2018）；会议日期：2018年10月29日。
- en: 'de Wynter and Yuan [2023] Adrian de Wynter and Tommy Yuan. I wish to have an
    argument: Argumentative reasoning in large language models, 2023.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: de Wynter and Yuan [2023] Adrian de Wynter 和 Tommy Yuan。我希望有一个论证：大语言模型中的论证推理，2023年。
- en: Dietz et al. [2021] Emmanuelle Dietz, Antonis Kakas, and Loizos Michael. Computational
    argumentation and cognition, 2021.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dietz et al. [2021] Emmanuelle Dietz、Antonis Kakas 和 Loizos Michael。计算论证与认知，2021年。
- en: 'Dietz et al. [2022] Emmanuelle Dietz, Antonis Kakas, and Loizos Michael. Argumentation:
    A calculus for human-centric ai. Frontiers in Artificial Intelligence, 5, 2022.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dietz et al. [2022] Emmanuelle Dietz、Antonis Kakas 和 Loizos Michael。论证：面向以人为中心的人工智能的微积分。前沿人工智能，5，2022年。
- en: Dung [1995] Phan Minh Dung. On the acceptability of arguments and its fundamental
    role in nonmonotonic reasoning, logic programming and n-person games. Artificial
    Intelligence, 77(2):321–357, 1995.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dung [1995] Phan Minh Dung。论证的可接受性及其在非单调推理、逻辑编程和多人游戏中的基本作用。人工智能，77(2):321–357，1995年。
- en: Eigner and Händler [2024] Eva Eigner and Thorsten Händler. Determinants of llm-assisted
    decision-making, 2024.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eigner and Händler [2024] Eva Eigner 和 Thorsten Händler。大语言模型辅助决策的决定因素，2024年。
- en: Fan and Toni [2015] Xiuyi Fan and Francesca Toni. On computing explanations
    in argumentation. In Proceedings of the Twenty-Ninth AAAI Conference on Artificial
    Intelligence, AAAI’15, page 1496–1492\. AAAI Press, 2015.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fan and Toni [2015] Xiuyi Fan 和 Francesca Toni。计算论证中的解释。在第二十九届AAAI人工智能会议论文集中，AAAI’15，页面1496–1492。AAAI出版社，2015年。
- en: Gandhi et al. [2023] Kanishk Gandhi, Dorsa Sadigh, and Noah D. Goodman. Strategic
    reasoning with language models, 2023.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gandhi et al. [2023] Kanishk Gandhi、Dorsa Sadigh 和 Noah D. Goodman。使用语言模型的战略推理，2023年。
- en: Hong et al. [2023] Shengxin Hong, Liang Xiao, and Jianxia Chen. An interaction
    model for merging multi-agent argumentation in shared clinical decision making.
    In 2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),
    pages 4304–4311, 2023.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hong et al. [2023] Shengxin Hong、Liang Xiao 和 Jianxia Chen。一个用于整合多智能体论证的交互模型，在2023年IEEE国际生物信息学与生物医学会议（BIBM）上，页面4304–4311，2023年。
- en: 'ISO [2020] ISO, IEC: AWI TS 29119-11: Software and systems engineering - software
    testing - part 11: Testing of AI systems. Technical report, 2020.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'ISO [2020] ISO, IEC: AWI TS 29119-11: 软件和系统工程 - 软件测试 - 第11部分: AI系统的测试。技术报告，2020年。'
- en: 'Jin et al. [2019] Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William W. Cohen,
    and Xinghua Lu. Pubmedqa: A dataset for biomedical research question answering,
    2019.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jin 等人 [2019] Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William W. Cohen 和 Xinghua
    Lu。Pubmedqa: 一个用于生物医学研究问题回答的数据集，2019年。'
- en: Jin et al. [2020] Di Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng, Hanyi
    Fang, and Peter Szolovits. What disease does this patient have? a large-scale
    open domain question answering dataset from medical exams, 2020.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jin 等人 [2020] Di Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng, Hanyi Fang
    和 Peter Szolovits。这个病人得了什么病？一个来自医学考试的大规模开放领域问答数据集，2020年。
- en: 'Jin et al. [2023] Qiao Jin, Yifan Yang, Qingyu Chen, and Zhiyong Lu. Genegpt:
    Augmenting large language models with domain tools for improved access to biomedical
    information, 2023.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jin 等人 [2023] Qiao Jin, Yifan Yang, Qingyu Chen 和 Zhiyong Lu。Genegpt: 用领域工具增强大型语言模型以改善生物医学信息的获取，2023年。'
- en: 'Jung et al. [2022] Jaehun Jung, Lianhui Qin, Sean Welleck, Faeze Brahman, Chandra
    Bhagavatula, Ronan Le Bras, and Yejin Choi. Maieutic prompting: Logically consistent
    reasoning with recursive explanations, 2022.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jung 等人 [2022] Jaehun Jung, Lianhui Qin, Sean Welleck, Faeze Brahman, Chandra
    Bhagavatula, Ronan Le Bras 和 Yejin Choi。孕育性提示: 通过递归解释进行逻辑一致的推理，2022年。'
- en: 'Klyne and Carroll [2004] Graham Klyne and Jeremy J. Carroll. Resource description
    framework (rdf): Concepts and abstract syntax. W3C Recommendation, 2004.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Klyne 和 Carroll [2004] Graham Klyne 和 Jeremy J. Carroll。资源描述框架（RDF）：概念和抽象语法。W3C
    推荐，2004年。
- en: 'Li et al. [2023] Chunyuan Li, Cliff Wong, Sheng Zhang, Naoto Usuyama, Haotian
    Liu, Jianwei Yang, Tristan Naumann, Hoifung Poon, and Jianfeng Gao. Llava-med:
    Training a large language-and-vision assistant for biomedicine in one day, 2023.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li 等人 [2023] Chunyuan Li, Cliff Wong, Sheng Zhang, Naoto Usuyama, Haotian Liu,
    Jianwei Yang, Tristan Naumann, Hoifung Poon 和 Jianfeng Gao。Llava-med: 在一天内训练一个用于生物医学的大型语言-视觉助手，2023年。'
- en: Nayak et al. [2023] Anupama Nayak, Michael S Alkaitis, Karthik Nayak, Martin
    Nikolov, Kevin P Weinfurt, and Kevin Schulman. Comparison of history of present
    illness summaries generated by a chatbot and senior internal medicine residents.
    JAMA Intern Med, 183(9):1026–1027, Sep 2023.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nayak 等人 [2023] Anupama Nayak, Michael S Alkaitis, Karthik Nayak, Martin Nikolov,
    Kevin P Weinfurt 和 Kevin Schulman。由聊天机器人和高级内科医生生成的现病史总结的比较。JAMA Intern Med, 183(9):1026–1027,
    2023年9月。
- en: Nori et al. [2023] Harsha Nori, Yin Tat Lee, Sheng Zhang, Dean Carignan, Richard
    Edgar, Nicolo Fusi, Nicholas King, Jonathan Larson, Yuanzhi Li, Weishung Liu,
    Renqian Luo, Scott Mayer McKinney, Robert Osazuwa Ness, Hoifung Poon, Tao Qin,
    Naoto Usuyama, Chris White, and Eric Horvitz. Can generalist foundation models
    outcompete special-purpose tuning? case study in medicine, 2023.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nori 等人 [2023] Harsha Nori, Yin Tat Lee, Sheng Zhang, Dean Carignan, Richard
    Edgar, Nicolo Fusi, Nicholas King, Jonathan Larson, Yuanzhi Li, Weishung Liu,
    Renqian Luo, Scott Mayer McKinney, Robert Osazuwa Ness, Hoifung Poon, Tao Qin,
    Naoto Usuyama, Chris White 和 Eric Horvitz。通用基础模型能否超越特定用途的调优？医学领域的案例研究，2023年。
- en: Oliveira et al. [2018] Tiago Oliveira, Jérémie Dauphin, Ken Satoh, Shusaku Tsumoto,
    and Paulo Novais. Argumentation with goals for clinical decision support in multimorbidity.
    In Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent
    Systems, 2018. 2031–2033.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Oliveira 等人 [2018] Tiago Oliveira, Jérémie Dauphin, Ken Satoh, Shusaku Tsumoto
    和 Paulo Novais。针对多重疾病的临床决策支持的目标论证。在第17届国际自主代理和多代理系统会议论文集中，2018年。2031–2033。
- en: OpenAI [2023] OpenAI. Gpt-4 technical report, 2023.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI [2023] OpenAI。GPT-4 技术报告，2023年。
- en: 'Pal et al. [2023] Ankit Pal, Logesh Kumar Umapathi, and Malaikannan Sankarasubbu.
    Med-halt: Medical domain hallucination test for large language models, 2023.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Pal 等人 [2023] Ankit Pal, Logesh Kumar Umapathi 和 Malaikannan Sankarasubbu。Med-halt:
    大型语言模型的医学领域幻觉测试，2023年。'
- en: 'Pan et al. [2023] Liangming Pan, Alon Albalak, Xinyi Wang, and William Yang
    Wang. Logic-lm: Empowering large language models with symbolic solvers for faithful
    logical reasoning, 2023.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Pan 等人 [2023] Liangming Pan, Alon Albalak, Xinyi Wang 和 William Yang Wang。Logic-lm:
    用符号求解器增强大型语言模型以实现忠实的逻辑推理，2023年。'
- en: 'Pan et al. [2024] Shirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang,
    and Xindong Wu. Unifying large language models and knowledge graphs: A roadmap.
    IEEE Transactions on Knowledge and Data Engineering, page 1–20, 2024.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Pan 等人 [2024] Shirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang 和 Xindong
    Wu。统一大型语言模型和知识图谱: 一条路线图。IEEE知识与数据工程学报，第1–20页，2024年。'
- en: Qassas et al. [2015] Malik Al Qassas, Daniela Fogli, Massimiliano Giacomin,
    and Giovanni Guida. Analysis of clinical discussions based on argumentation schemes.
    Procedia Computer Science, 64:282–289, 2015. Conference on ENTERprise Information
    Systems/International Conference on Project MANagement/Conference on Health and
    Social Care Information Systems and Technologies, CENTERIS/ProjMAN / HCist 2015
    October 7-9, 2015.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qassas et al. [2015] 马利克·阿尔·卡萨斯、达尼埃拉·福戈利、马西米利亚诺·贾科敏和乔瓦尼·吉达。基于论证模式的临床讨论分析。计算机科学学报，64:282–289，2015年。ENTERprise信息系统国际会议/项目管理国际会议/健康与社会护理信息系统与技术会议，CENTERIS/ProjMAN/HCist
    2015年10月7-9日。
- en: Sassoon et al. [2021] Isabel Sassoon, Nadin Kökciyan, Sanjay Modgil, and Simon
    Parsons. Argumentation schemes for clinical decision support. Argument and Computation,
    12(3):329–355, November 2021.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sassoon et al. [2021] 伊莎贝尔·萨索恩、纳丁·科克基扬、桑贾伊·莫吉尔和西蒙·帕森斯。临床决策支持的论证模式。论证与计算，12(3):329–355，2021年11月。
- en: Savage et al. [2024] Thomas Savage, Abhishek Nayak, Robert Gallo, and et al.
    Diagnostic reasoning prompts reveal the potential for large language model interpretability
    in medicine. npj Digital Medicine, 7:20, 2024.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Savage et al. [2024] 托马斯·萨维奇、阿比谢克·纳亚克、罗伯特·加洛等。诊断推理提示揭示了大型语言模型在医学中可解释性的潜力。npj数字医学，7:20，2024年。
- en: 'Shi et al. [2024] Wenqi Shi, Ran Xu, Yuchen Zhuang, Yue Yu, Jieyu Zhang, Hang
    Wu, Yuanda Zhu, Joyce Ho, Carl Yang, and May D. Wang. Ehragent: Code empowers
    large language models for few-shot complex tabular reasoning on electronic health
    records, 2024.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi et al. [2024] 温祺·石、阮旭、卓宇晨、余悦、张杰宇、吴航、朱远达、霍乔伊斯、杨卡尔和梅·D·王。Ehragent：代码赋能大型语言模型进行电子健康记录上的少样本复杂表格推理，2024年。
- en: Singhal et al. [2022] Karan Singhal, Shekoofeh Azizi, Tao Tu, S. Sara Mahdavi,
    Jason Wei, Hyung Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen
    Pfohl, Perry Payne, Martin Seneviratne, Paul Gamble, Chris Kelly, Nathaneal Scharli,
    Aakanksha Chowdhery, Philip Mansfield, Blaise Aguera y Arcas, Dale Webster, Greg S.
    Corrado, Yossi Matias, Katherine Chou, Juraj Gottweis, Nenad Tomasev, Yun Liu,
    Alvin Rajkomar, Joelle Barral, Christopher Semturs, Alan Karthikesalingam, and
    Vivek Natarajan. Large language models encode clinical knowledge, 2022.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Singhal et al. [2022] 卡兰·辛格哈尔、谢库费·阿齐齐、陶图、S·萨拉·马赫达维、贾森·魏、洪元重、内森·斯凯尔斯、阿贾伊·坦瓦尼、海瑟·科尔-刘易斯、斯蒂芬·福尔、佩里·佩恩、马丁·塞尼维拉特、保罗·甘布尔、克里斯·凯利、纳撒尼尔·沙利、阿坎莎·乔杜赫里、菲利普·曼斯菲尔德、布莱斯·阿圭拉·亚·阿尔卡斯、戴尔·韦伯斯特、格雷格·S·科拉多、约西·马蒂亚斯、凯瑟琳·周、尤拉伊·戈特维斯、尼纳德·托马塞夫、刘云、阿尔文·拉杰科马、乔埃尔·巴拉尔、克里斯托弗·塞姆图斯、艾伦·卡尔基萨林甘和维韦克·纳塔拉詹。大型语言模型编码临床知识，2022年。
- en: Singhal et al. [2023] Karan Singhal, Tao Tu, Juraj Gottweis, Rory Sayres, Ellery
    Wulczyn, Le Hou, Kevin Clark, Stephen Pfohl, Heather Cole-Lewis, Darlene Neal,
    Mike Schaekermann, Amy Wang, Mohamed Amin, Sami Lachgar, Philip Mansfield, Sushant
    Prakash, Bradley Green, Ewa Dominowska, Blaise Aguera y Arcas, Nenad Tomasev,
    Yun Liu, Renee Wong, Christopher Semturs, S. Sara Mahdavi, Joelle Barral, Dale
    Webster, Greg S. Corrado, Yossi Matias, Shekoofeh Azizi, Alan Karthikesalingam,
    and Vivek Natarajan. Towards expert-level medical question answering with large
    language models, 2023.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Singhal et al. [2023] 卡兰·辛格哈尔、陶图、尤拉伊·戈特维斯、罗里·塞耶斯、埃勒里·伍尔钦、勒·侯、凯文·克拉克、斯蒂芬·福尔、海瑟·科尔-刘易斯、达琳·尼尔、迈克·谢克曼、艾米·王、穆罕默德·阿明、萨米·拉赫贾、菲利普·曼斯菲尔德、苏尚特·普拉卡什、布拉德利·格林、埃娃·多米诺夫斯卡、布莱斯·阿圭拉·亚·阿尔卡斯、尼纳德·托马塞夫、刘云、雷妮·黄、克里斯托弗·塞姆图斯、S·萨拉·马赫达维、乔埃尔·巴拉尔、戴尔·韦伯斯特、格雷格·S·科拉多、约西·马蒂亚斯、谢库费·阿齐齐、艾伦·卡尔基萨林甘和维韦克·纳塔拉詹。朝着专家级医疗问答迈进，使用大型语言模型，2023年。
- en: 'Tang et al. [2024] Xiangru Tang, Anni Zou, Zhuosheng Zhang, Ziming Li, Yilun
    Zhao, Xingyao Zhang, Arman Cohan, and Mark Gerstein. Medagents: Large language
    models as collaborators for zero-shot medical reasoning, 2024.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tang et al. [2024] 唐翔如、邹安妮、张卓胜、李子铭、赵伊伦、张兴耀、阿尔曼·科汉和马克·格斯坦。Medagents：大型语言模型作为零样本医学推理的合作者，2024年。
- en: Walton et al. [2008] Douglas Walton, Chris Reed, and Fabrizio Macagno. Argumentation
    Schemes. Cambridge University Press, New York, 2008.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Walton et al. [2008] 道格拉斯·沃尔顿、克里斯·里德和法布里齐奥·马卡尼奥。论证模式。剑桥大学出版社，纽约，2008年。
- en: Walton [1996] Douglas Walton. Argumentation Schemes for Presumptive Reasoning.
    Routledge, 1st edition, 1996.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Walton [1996] 道格拉斯·沃尔顿。预设推理的论证模式。劳特利奇，第一版，1996年。
- en: Wang et al. [2023] Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
    Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei
    Wei, and Ji-Rong Wen. A survey on large language model based autonomous agents,
    2023.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. [2023] 王磊、马晨、冯雪扬、张泽宇、杨浩、张景森、陈智远、唐佳凯、陈旭、林彦凯、魏伟、乔容文。基于大型语言模型的自主智能体调查，2023年。
- en: Wei et al. [2023] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian
    Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. Chain-of-thought prompting elicits
    reasoning in large language models, 2023.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等人 [2023] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian
    Ichter, Fei Xia, Ed Chi, Quoc Le, 和 Denny Zhou. 链式思维提示引发大语言模型的推理能力，2023。
- en: 'Wu et al. [2023] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li,
    Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, Ahmed Hassan Awadallah,
    Ryen W White, Doug Burger, and Chi Wang. Autogen: Enabling next-gen llm applications
    via multi-agent conversation, 2023.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等人 [2023] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang
    Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, Ahmed Hassan Awadallah,
    Ryen W White, Doug Burger, 和 Chi Wang. Autogen：通过多智能体对话启用下一代 LLM 应用，2023。
- en: 'Xie et al. [2024] Jian Xie, Kai Zhang, Jiangjie Chen, Tinghui Zhu, Renze Lou,
    Yuandong Tian, Yanghua Xiao, and Yu Su. Travelplanner: A benchmark for real-world
    planning with language agents, 2024.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie 等人 [2024] Jian Xie, Kai Zhang, Jiangjie Chen, Tinghui Zhu, Renze Lou, Yuandong
    Tian, Yanghua Xiao, 和 Yu Su. Travelplanner：一个用于语言智能体实际规划的基准，2024。
- en: 'Xiu et al. [2022] Yeliang Xiu, Zhanhao Xiao, and Yongmei Liu. LogicNMR: Probing
    the non-monotonic reasoning ability of pre-trained language models. In Yoav Goldberg,
    Zornitsa Kozareva, and Yue Zhang, editors, Findings of the Association for Computational
    Linguistics: EMNLP 2022, pages 3616–3626, Abu Dhabi, United Arab Emirates, December
    2022\. Association for Computational Linguistics.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xiu 等人 [2022] Yeliang Xiu, Zhanhao Xiao, 和 Yongmei Liu. LogicNMR：探究预训练语言模型的非单调推理能力。见
    Yoav Goldberg, Zornitsa Kozareva, 和 Yue Zhang 编，《计算语言学协会会议论文集：EMNLP 2022》，第 3616–3626
    页，阿布扎比，阿联酋，2022年12月。计算语言学协会。
- en: Zeng et al. [2020] Zhiwei Zeng, Zhiqi Shen, Benny Toh Hsiang Tan, Jing Jih Chin,
    Cyril Leung, Yu Wang, Ying Chi, and Chunyan Miao. Explainable and Argumentation-based
    Decision Making with Qualitative Preferences for Diagnostics and Prognostics of
    Alzheimer’s Disease. In Proceedings of the 17th International Conference on Principles
    of Knowledge Representation and Reasoning, pages 816–826, 9 2020.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zeng 等人 [2020] Zhiwei Zeng, Zhiqi Shen, Benny Toh Hsiang Tan, Jing Jih Chin,
    Cyril Leung, Yu Wang, Ying Chi, 和 Chunyan Miao. 可解释和基于论证的决策制定：用于阿尔茨海默病诊断和预后分析的定性偏好。见《第17届知识表示与推理原则国际会议论文集》，第
    816–826 页，2020年9月。
- en: Zhang et al. [2023] Yifan Zhang, Jingqin Yang, Yang Yuan, and Andrew Chi-Chih
    Yao. Cumulative reasoning with large language models, 2023.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人 [2023] Yifan Zhang, Jingqin Yang, Yang Yuan, 和 Andrew Chi-Chih Yao.
    大语言模型的累积推理，2023。
- en: Appendix A Formal Description of ArgMed-Agents
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A ArgMed-Agents 的形式描述
- en: Algorithm 1 ArgMed-Agents Interaction Reasoning
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 1 ArgMed-Agents 交互推理
- en: 1:Question $Q$)24:end function
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '1: 问题 $Q$)24:end 函数'
- en: Appendix B ASCD Reasoning Mechanisms
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B ASCD 推理机制
- en: '| Argumentation Scheme | Critical Questions | Reject Rule | Derive Role | Attack
    Rule |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| 论证方案 | 关键问题 | 驳回规则 | 导出角色 | 攻击规则 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Argumentation Scheme |  |  |  |  |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 论证方案 |  |  |  |  |'
- en: '| for Decision(ASD) | ASD.CQ1 | NO (no evidence to support the argument) |
    none | self-attack |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 对决策（ASD） | ASD.CQ1 | NO（没有证据支持该论点） | 无 | 自我攻击 |'
- en: '|  | ASD.CQ2 | YES (there are side effects of decision-making) | ASSE | ASSE
    attack ASD |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '|  | ASD.CQ2 | YES（存在决策副作用） | ASSE | ASSE 攻击 ASD |'
- en: '|  | ASD.CQ3 | NO (incomplete decisions to fulfil goals) | none | self-attack
    |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '|  | ASD.CQ3 | NO（不完整的决策以实现目标） | 无 | 自我攻击 |'
- en: '|  | ASD.CQ4 | YES (existence of alternative decisions) | ASD | ASBD attack
    the worse decision |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '|  | ASD.CQ4 | YES（存在替代决策） | ASD | ASBD 攻击较差决策 |'
- en: '| in ASD_1 and ASD_2 |  |  |  |  |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| 在 ASD_1 和 ASD_2 中 |  |  |  |  |'
- en: '| Argumentation Scheme |  |  |  |  |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| 论证方案 |  |  |  |  |'
- en: '| for Side Effect(ASSE) | ASSE.CQ1 | NO (no evidence to support the argument)
    | none | self-attack |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| 对副作用（ASSE） | ASSE.CQ1 | NO（没有证据支持该论点） | 无 | 自我攻击 |'
- en: '|  | ASSE.CQ2 | NO (the side-effect is acceptable) | none | self-attack |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '|  | ASSE.CQ2 | NO（副作用是可以接受的） | 无 | 自我攻击 |'
- en: '|  | ASSE.CQ3 | YES (there are ways to ameliorate side effects) | ASD | none
    |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '|  | ASSE.CQ3 | YES（有改善副作用的方法） | ASD | 无 |'
- en: '| Argumentation Scheme |  |  |  |  |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| 论证方案 |  |  |  |  |'
- en: '| for Better Decision(ASBD) | ASBD.CQ1 | NO (no evidence to support the argument)
    | none | self-attack |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| 对更好决策（ASBD） | ASBD.CQ1 | NO（没有证据支持该论点） | 无 | 自我攻击 |'
- en: 'Table 3: List of specialized schemes, CQs, when CQs will be rejected and their
    derived roles and attack rules between derived roles and initial schemes. Notably,
    every ASD is attacking each other by default, so it is not shown in the attack
    rules.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：专用方案、CQ 列表，CQ 何时会被拒绝及其衍生角色和衍生角色与初始方案之间的攻击规则。值得注意的是，每个 ASD 默认会相互攻击，因此攻击规则中未显示。
- en: Appendix C More Case Details in Experiment
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 C 实验中的更多案例细节
- en: '![Refer to caption](img/a82eff4588abaf8dd2da648b816fe126.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/a82eff4588abaf8dd2da648b816fe126.png)'
- en: 'Figure 4: Example of correct reasoning by ArgMed-Agents. We show the flow of
    the multi-agent dialogue and the resulting formal AA framework.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：ArgMed-Agents 正确推理的示例。我们展示了多智能体对话的流程以及最终的正式 AA 框架。
- en: '![Refer to caption](img/e8d0b933be92c11e95ff772dd88fde0b.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e8d0b933be92c11e95ff772dd88fde0b.png)'
- en: 'Figure 5: (continued) Example of correct reasoning by ArgMed-Agents. We provide
    runnable demo files with available GPT-4 API Keys in the code that include these
    cases.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：（续）ArgMed-Agents 正确推理的示例。我们提供了包含这些案例的可运行演示文件，配有有效的 GPT-4 API 密钥。
