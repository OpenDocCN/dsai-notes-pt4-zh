<!--yml

类别：未分类

日期：2025-01-11 12:10:02

-->

# 6G LLM 代理：一种面向任务的物理层自动化新范式

> 来源：[https://arxiv.org/html/2410.03688/](https://arxiv.org/html/2410.03688/)

Zhuoran Xiao, Chenhui Ye${2}$, Yunbo Hu, Honggang Yuan, Yihang Huang, Yijia Feng, Liyu Cai, 和 Jiang Chang，诺基亚贝尔实验室，中国上海

电子邮件：{zhuoran.xiao, chenhui.a.ye${2}$, yunbo.hu, honggang.yuan, yihang.huang, yijia.feng, liyu.cai, jiang.chang}

@nokia-sbell.com

###### 摘要

生成式预训练模型的快速发展推动了技术进步的范式转变，从简单的应用如聊天机器人向更复杂的基于代理的系统发展。6G系统与大型语言模型（LLM）代理的副驾驶结合，管理具有新兴特性的复杂通信系统，如原生AI服务和感知，是具有巨大潜力和必要性的。通过6G定向代理，基站可以理解各种动态上层任务的传输需求，自动协调最优的系统工作流程，并相应提高性能。与现有为一般应用设计的LLM代理不同，6G定向代理旨在利用大量额外的专家知识进行高度严谨和精确的规划，这不可避免地需要从模型训练到实现的特定系统设计。本文提出了一种构建面向任务的6G LLM代理的新综合方法。我们首先提出了一个两阶段的持续预训练和微调方案，以构建领域基础模型以及满足各种任务要求的多样化专家模型。此外，本文还提出了一种新颖的基于检索的代理推理框架，用于利用现有的通信相关功能。实验结果表明，诸如3GPP协议问答和物理层任务分解等典型任务的实验表明，所提出的范式具有可行性和有效性。

###### 索引词：

6G 网络，AI 代理，大型语言模型，物理层，无线通信。

## I 引言

无线通信系统正处于一个新时代，正在从传统的仅为符号传输设计的系统，发展为一个更具功能性和复杂性的系统。将人工智能（AI）方法引入空中接口，使得该系统能够在各种场景下实现增强的性能[[1](https://arxiv.org/html/2410.03688v1#bib.bib1)]，而像JCAS（联合通信与感知）这样的新特性极大地扩展了系统的功能[[2](https://arxiv.org/html/2410.03688v1#bib.bib2)]。此外，新的应用场景也应运而生，如自动驾驶[[3](https://arxiv.org/html/2410.03688v1#bib.bib3)]和增强现实[[4](https://arxiv.org/html/2410.03688v1#bib.bib4)]，这些场景带来了超越传统使用案例的多样化需求。此外，随着针对特定下游任务优化系统的目标，面向任务的通信被认为是一种有前景的方法，可以最大化系统的整体效率[[5](https://arxiv.org/html/2410.03688v1#bib.bib5), [6](https://arxiv.org/html/2410.03688v1#bib.bib6)]。相关研究表明，通过专业化的系统设计，系统性能可以显著提升。显然，所有上述需求都要求系统具备自动适应多种通信场景并响应各种UE任务的能力。在现有的通信系统中，基站只能在预定义的工作流程下运行，缺乏全面的任务理解，导致系统效率低下。这种低效不仅浪费了频谱资源和能源，还对用户体验产生了负面影响。

![参见标题](img/39e225d7b75ceac52073eb2e436f16a4.png)

图 1：所提议的 6G LLM 代理的系统框架。

通过利用大型语言模型（LLM）的强大学习能力，AI代理在协调复杂系统、制定连续计划和决策方面展现了巨大的潜力[[7](https://arxiv.org/html/2410.03688v1#bib.bib7), [8](https://arxiv.org/html/2410.03688v1#bib.bib8)]。对于一个全面的AI代理，有几个必不可少的功能，包括观察环境、制定计划和做出决策、利用工具以及通过强化学习自我提升。显然，未来无线通信系统的愿景与开发LLM代理的前提条件完美契合。首先，通信系统具备通过多模态感知（包括信道估计、传感和电磁波成像，以及通过摄像头进行的视觉捕捉）观察散射环境的强大能力。其次，存在一个庞大的特定领域数据仓库，其中包括协议文档、软件代码库和错误日志，可以用于训练LLM。这样的训练将使系统能够进行规划和决策，例如设计系统工作流和配置系统设置。第三，通信系统中已经存在大量功能性的API（应用程序编程接口），这些可以视为代理的工具包，促进各种操作的执行。最后，性能指标，如服务质量（QoS）和任务质量（QoT），可以作为强化奖励来优化代理的行为。

由于6G导向的大型语言模型（LLM）代理具有独特的特点，它与通用型LLM存在显著的差异。例如，一个先进的6G LLM代理需要从大量特定领域的知识库中进行广泛学习。此外，由于现有代理系统中可用的工具种类有限，使用这些工具变得相对简单。相比之下，对于复杂的无线通信系统，存在许多具有复杂调用逻辑的API工具，这为有效实施和管理带来了巨大挑战。

为了解决上述问题，我们提出了一种创新的系统范式，用于任务导向型6G LLM代理的训练和推理过程。具体来说，我们提出了一种两阶段的持续训练方法。在第一阶段，我们旨在将领域特定的知识注入到一个预训练的通用LLM中，增强其理解通信任务和协调系统的能力。通过这一阶段的训练得到的模型被称为领域基础模型，因为它可以进一步微调，以适应特定的通信场景或任务。在第二阶段，我们使用少量高质量数据对第$1$层模型进行微调。这一精炼过程确保了模型的规划和决策能力最优化地与宿主系统的固有功能相匹配。这一微调阶段的适应性使得该方法能够轻松适应各种场景和应用。此外，我们设计了一种通信系统特定的检索方法，拓宽了代理使用工具的能力。与现有方法相比，这种方法显著提高了调用专业功能的准确性。

本文的其余部分组织结构如下。系统框架在[II](https://arxiv.org/html/2410.03688v1#S2 "II System Framework ‣ 6G LLM Agents: A Novel Paradigm for Task-Oriented Physical-Layer Automation")节中进行了描述。两阶段LLM训练方法在[III](https://arxiv.org/html/2410.03688v1#S3 "III Two-Stage Model training ‣ 6G LLM Agents: A Novel Paradigm for Task-Oriented Physical-Layer Automation")节中给出。[IV](https://arxiv.org/html/2410.03688v1#S4 "IV Workflow Design for Task-Oriented Physical-Layer Automation ‣ 6G LLM Agents: A Novel Paradigm for Task-Oriented Physical-Layer Automation")节介绍了所提议的LLM代理工作流。[V](https://arxiv.org/html/2410.03688v1#S5 "V Experiments ‣ 6G LLM Agents: A Novel Paradigm for Task-Oriented Physical-Layer Automation")节介绍了我们的实验设置及相应结果，从不同角度评估了我们提出的方法的性能。[VI](https://arxiv.org/html/2410.03688v1#S6 "VI Conclusions ‣ 6G LLM Agents: A Novel Paradigm for Task-Oriented Physical-Layer Automation")节总结了我们的主要结论。

![参见说明文字](img/e7e7b50ae406bb1933b6593a0453987e.png)

图2：提出的三种模型层级及其对应功能。L1模型是从预训练的L0模型中训练得到的，并作为领域基础模型。L2模型则是基于L1模型进一步微调，针对特定目标场景或代理角色进行定制。

## II 系统框架

我们考虑一个典型场景，其中LLM智能体被部署在基站，用于协调一个小区内的整个无线接入网络（RAN）。如图[1](https://arxiv.org/html/2410.03688v1#S1.F1 "图 1 ‣ I 引言 ‣ 6G LLM智能体：任务导向物理层自动化的新范式")所示，6G LLM智能体系统主要由三个部分组成：LLM、多源感知和工具。LLM作为系统的大脑，首先将上层任务描述和环境感知作为输入，从而理解传输需求。然后，通过思维链（CoT）或思维树（ToT）输出推理和规划，从而动态调整系统的配置和工作流程。

6G智能体与其他应用的区别在于其先进的感知能力，能够有效感知散射环境并熟练运用工具。这种感知能力通过整合多模态功能，如信道估计、传感、视觉和数字双胞胎等，得到了显著增强。通过对环境的日益精确的理解，系统能够进行有效的调整。此外，未来的通信系统预计将集成更多的综合工具集，具有前沿的功能，如大规模多输入多输出（MIMO）技术和人工智能驱动的物理层功能，从而提升其整体性能和多功能性。总的来说，这些相互连接的模块共同构成了高度复杂的6G智能体架构。

## III 两阶段模型训练

由于自然环境的复杂性以及应用设备的多样化角色，部署通用模型以适应所有环境是不现实的。因此，我们提出了一个三层模型架构，如图[2](https://arxiv.org/html/2410.03688v1#S1.F2 "图 2 ‣ I 引言 ‣ 6G LLM智能体：任务导向物理层自动化的新范式")所示。该框架从一个基础的预训练模型开始，称为L0模型，旨在处理如理解自然语言和格式化输出等通用任务。在此基础模型之上，我们通过知识注入开发了L1模型。L1模型，即领域基础模型，包含了大量常见的领域特定知识，并具备解决领域相关问题的专家能力。随后，通过将L1模型中体现的通用知识与特定部署设备所遇到的独特情况相结合，我们得出了L2模型，该模型有助于推理和规划，并可以直接部署在实际的6G系统中。

![参考标题](img/63bc2a10ad9cca8638c516448d038e3c.png)

(a) 阶段 1：持续训练

![参考标题](img/65aaffe0fed333d616da5dfc272e9f17.png)

(b) 阶段 2：LoRA微调

图3：两阶段训练过程的学习结构。

![参考标题](img/0521799e6437c085d90230cd54375acd.png)

图4：LLM代理协调的通信系统工作流示例。LLM代理在系统的不同部分扮演不同角色。代理可以理解用户设备（UE）上层任务的要求，并根据需要逐步优化系统操作。

### III-A 第一阶段：通过持续学习注入知识

在第一阶段的训练过程中，我们提出了一种通过利用预训练通用大型语言模型（LLM）进行持续训练的方案。使用预训练模型的原因在于其能够直接利用语言的固有理解能力。此外，我们建议仅训练预训练模型顶部$K$个变换器块中的全连接层的参数，而不是进行全面的参数训练。这个想法基于几个关键考虑。首先，尽管可用的训练数据集规模庞大，但仍不足以有效训练一个包含数十亿参数的完整模型，而不引发显著的过拟合问题。其次，灾难性遗忘是训练大型语言模型时常见的挑战。当使用高度结构化且简化的语料库进行训练时，这种现象尤为突出，而这种语料库在电信领域尤为常见，例如协议文档和功能说明。LLM中的注意力层用于保持自然语言层面上隐含的词汇关联，这些关联容易被这些数据破坏。因此，通过选择性地仅训练最上层的前馈层，并冻结底层的注意力层，我们显著提高了模型的鲁棒性，并减少了灾难性遗忘的风险。

训练任务设定为无监督自回归与有监督指令跟随的结合。无监督自回归方法在LLM的训练过程中广泛应用，并且无需标注数据。然而，这种学习方法可能导致学习过程中的潜在低效，并且难以将模型的注意力集中在关键信息上。因此，我们提出利用通用LLM提取提示文档中的关键信息，并生成高质量的标注数据，采用问答对格式。这种方式可以使模型更加关注重要信息，例如技术术语。通过这种方式，我们大大增强了模型的专业知识，同时保持了鲁棒性。

### III-B 第二阶段：角色特定的微调

第二阶段训练计划的目标是优化模型在做出决策时能够根据目标代理的特定角色和功能量身定制。例如，通常应该存在一个环境观察代理，持续监控传输环境的变化，以及一个系统配置代理，根据变化调整系统配置。不同代理之间的一个重要特征是它们各自的API数据库。因此，本步骤数据预处理的第一步是创建全面的API数据库文档，其中包含功能、参数定义和输出规范的详细描述。接下来，这使得查询和任务分解语料库的获取成为可能。该语料库中的查询可以以多种格式呈现，从直接的任务描述到具体的传输需求。语料库中的每个复合步骤对应着已建立数据库中的一个潜在API。

我们建议采用LoRA方法对L1模型进行监督微调。这涉及在原始变压器架构中的每个参数矩阵上附加一个低秩适配器，从而使得模型能够迅速根据其独特的工具包调整规划和决策能力。采用这种训练配置具有几个显著的好处。首先，LoRA适配器的小巧尺寸使得它们能够轻松地在云服务器上更新，并随后被基站（BS）或用户设备（UE）下载，从而保证了操作的灵活性。此外，LoRA技术在处理有限大小的数据集时，表现出较低的灾难性遗忘或过拟合的倾向，从而确保了整个系统的整体鲁棒性。值得一提的是，训练语料库中的每个查询都与一个固定的提示拼接，描述了代理的角色，这将有助于增强训练过程的收敛性。

## IV 面向任务的物理层自动化工作流设计

### IV-A 代理的角色扮演与协作

关于明确界定LLM代理在系统中不同角色的两大主要关注点。首先，从LLM实际使用的角度来看，清晰的角色定义有助于优化提示设计，从而提高模型输出的准确性，并减少模型幻觉的可能性。其次，明确的角色定义将有助于简化系统流程并提高系统效率，因为每个角色都有明确的触发逻辑。

如图[4](https://arxiv.org/html/2410.03688v1#S3.F4 "Figure 4 ‣ III Two-Stage Model training ‣ 6G LLM Agents: A Novel Paradigm for Task-Oriented Physical-Layer Automation")所示的提议系统工作流中，我们定义了四个LLM代理角色来完成系统工作流。对于每个即将到来的UE任务，任务感知代理首先会将上层任务描述翻译为精确的传输需求。观察者代理将持续监控散射环境并总结系统状态。每当有新的UE任务或环境变化时，系统配置代理会给出完整的推理和规划思路。在API检索之后，API调用代理将帮助正确执行这些API。在所有上述过程完成后，报告代理将总结执行结果以便捕获潜在错误并进行修正。

### IV-B 基于向量语义相似性搜索的API检索

在现有的工作中，工具的使用依赖于将所有的API描述放入提示中。这种方法在任务简单且涉及的API数量有限时是实用的。然而，复杂的通信系统中有成千上万的API，由于上下文长度的限制，将所有API包含在提示中并不现实。为了解决这个问题，我们提出了一种新颖的解决方案，通过在扩展的向量数据库中进行API指令的语义向量化，并利用相似性搜索进行检索。

首先，我们使用预训练的语义句子到向量模型将所有的API指令编码为固定长度的向量。然后，对于LLM的每个输出步骤，我们应用相同的模型生成语义表示向量。接着，我们计算生成的步骤向量与存储在数据库中的每个API嵌入之间的GCS（广义余弦相似度），可以表示为

|  | $GCS=\frac{\mathbf{D}\cdot\mathbf{S}}{\left\&#124;\mathbf{D}\right\&#124;\cdot\left\&#124;% \mathbf{S}\right\&#124;},$ |  | (1) |
| --- | --- | --- | --- |

其中，$\mathbf{D}$是API数据库中项目的嵌入向量，$\mathbf{S}$表示LLM规划步骤的嵌入向量。然后，选择相似度得分最高的API作为最相关的匹配。该策略即使在API库庞大且多样时，也能高效、可扩展地进行API检索。

### IV-C 基于自组织的工具执行

如何准确规划工具的调用，并通过找到每个API的适当实际参数成功执行它们，一直是一个具有挑战性的问题。在现有的工作中，常见的方法是严格约束API的参数格式，并在程序中实现参数过滤。因此，所有工具应在初始阶段专门开发，或者需要额外的努力来完善它们以满足格式要求。然而，存在着大量为不同协议标准开发的API函数，转向统一格式是不可行的。因此，我们提出采用LLM作为中介，架起这些不同API之间的桥梁，并有效识别所需的参数。

如图[4](https://arxiv.org/html/2410.03688v1#S3.F4 "图 4 ‣ III 两阶段模型训练 ‣ 6G LLM 代理：任务导向物理层自动化的新范式")所示，API调用代理将在每次执行API之前介入，并查找相应的输入参数。参数输入有三个来源：任务描述中的值、之前执行的API的结果以及当前执行API固有的默认值。因此，我们将所有来源集成到提示中，并要求LLM通过物理含义自动找到值。例如，如果前一个API指令提到估计的信道状态信息矩阵将存储在一个名为‘CSI_matrix’的临时变量中，而正在执行的API指令提到它需要将估计的CSI作为名为‘estimated_channel’的参数值，则LLM将自动意识到‘estimated_channel = CSI_matrix’。值得一提的是，这种方法并非易事，因为它要求LLM识别这些术语并将它们与描述联系起来，这在很大程度上依赖于专家知识的注入。因此，API调用代理需要由我们的L1模型驱动，这确保了系统动作的流畅性和连续性。

## V 实验

### V-A 参数设置和数据集生成

我们使用两种不同规模的开源LLM模型，分别是LLaMA2-13B和LLaMA2-70B，作为我们的基础预训练L0模型。在第一阶段的持续训练中，我们训练最高变换块中的前馈层参数，13B和70B模型的总可训练参数大约为35亿。在第二阶段训练中，我们进一步采用LoRA方法处理整个变换网络中注意力块（查询、键和值）中的所有矩阵。适配器的秩设置为$16$，因此与原始模型相比，引入了大约额外$0.6\%$的可训练参数。

#### V-A1 数据集生成

对于第一阶段的训练，数据集包含了多种文本资源，包括3GPP文档、与电信相关的ArXiv论文以及开源数据集如Telecom Q&A [[9](https://arxiv.org/html/2410.03688v1#bib.bib9)]。为了确保数据集的质量，所有原始文本都经过严格的预处理程序，涉及全面的数据清理和结构化格式化。此外，我们还使用了**Tongyi-Max**来帮助清理和重述部分语料。因此，信息密集的部分将被突出显示。

对于第二阶段的微调，我们最初构建了一个包含约$200$个API的工具库。随后，我们手动创建了约$20000$的语料，内容包括UE任务、传输要求及其相应的分解步骤。每个动作步骤对应工具库中的一个现有API。

### V-B 实验结果

![参考说明](img/e20171ebc379fa2efbcdded739c931d3.png)

图5：三种大型语言模型（LLM）在回答与通信相关问题时的胜率比较。

![参考说明](img/64e01306f3fc20df41432a230f2cbb3d.png)

图6：通过计算$35$个示例步骤描述的嵌入向量与数据库中API指令的嵌入向量之间的余弦相似度来进行度量。

![参考说明](img/bc77f307dfd84a9799b41aae18944c60.png)

图7：比较模型之间任务分解的修正率比较。

![参考说明](img/eb5018732fb88c87808b5d89f2b8ca65.png)

图8：采用LLM代理来协调一个实际通信系统的概念演示。

首先，我们将L1模型与LLaMA2和Claude进行比较，验证领域特定知识注入的效果，特别是在回答电信相关问题时。我们收集了一个测试数据集，包含$4000$个与3GPP协议相关的问题，并附上正确答案及其相应的解释。这些问题通过相同的提示呈现给三种比较模型。一个第三方的LLM，**Tongyi-max**，接收到所有问题以及相应的答案和解释。分配给Tongyi-max的任务是评估哪些提供的答案与正确答案更为接近。图[5](https://arxiv.org/html/2410.03688v1#S5.F5 "图5 ‣ V-B 实验结果 ‣ V 实验 ‣ 6G LLM代理：一种用于任务导向的物理层自动化的新范式")展示了三种模型的整体胜率。显然，通过知识注入的实施，L1模型在13B和70B模型上均表现优于其对手，证明了训练的有效性。

其次，为了说明所提出的基于语义相似度搜索的API检索方法的可行性，我们随机选择了L2模型输出的$35$个示例步骤实例，这些实例应当对应于库中的前$50$个API，并获取它们的语义嵌入向量。然后，我们计算步骤描述嵌入向量与API指令嵌入向量之间的GCS。结果如图[6](https://arxiv.org/html/2410.03688v1#S5.F6 "Figure 6 ‣ V-B Experimental Results ‣ V Experiments ‣ 6G LLM Agents: A Novel Paradigm for Task-Oriented Physical-Layer Automation")所示。从结果中可以观察到，对于每个实例，正确的API总是具有最高的相似度，显著超过其他错误的API，这确保了我们始终能够为每个规划步骤找到正确的API。

第三，为了进一步验证二阶段训练的有效性，我们收集了一个验证数据集，其中包含$1000$个查询实例，涵盖了不同的风格，以及它们对应的最优分解步骤。然后，我们将L2模型的响应与图[7](https://arxiv.org/html/2410.03688v1#S5.F7 "Figure 7 ‣ V-B Experimental Results ‣ V Experiments ‣ 6G LLM Agents: A Novel Paradigm for Task-Oriented Physical-Layer Automation")中展示的三种对比模型进行了比较，包括原始的LLaMA2模型、L1模型以及没有知识注入持续训练的直接微调模型。为了确保公平比较，我们采用了相同的提示，并使用上述方法调用每个步骤的相应API，并将结果与实际结果进行比较。这样，我们可以计算每个模型的纠正率。如图[7](https://arxiv.org/html/2410.03688v1#S5.F7 "Figure 7 ‣ V-B Experimental Results ‣ V Experiments ‣ 6G LLM Agents: A Novel Paradigm for Task-Oriented Physical-Layer Automation")所示，所提出的L2模型展示了最高的准确率，并大大超过了其他模型，这证明了二阶段训练过程的有效性。此外，一个值得注意的观察是，在第一阶段训练后，L2模型显著优于没有任何知识注入的直接微调模型。这一结果进一步凸显了我们所提训练方法的可行性。

最后，为了直观地展示在无线通信系统中应用LLM的优势，我们制作了一个概念性演示，展示了采用LLM代理自动编排DeepTx和DeepRx的调用[[10](https://arxiv.org/html/2410.03688v1#bib.bib10)]，以增强系统吞吐量并解决由设备温度升高引起的PA非线性问题。详细的视频演示可以通过‘https://github.com/hongan-nokia/bell_labs_6G_llm’获取，供进一步参考。

## VI 结论

本文提出了一种用于任务导向的6G物理层自动化的LLM代理训练和应用的新范式。通过采用专门设计的两阶段持续训练方法，训练后的领域适配LLM有效地帮助理解用户的高层次需求，并相应地推荐工作流和最优系统配置。此外，结合所提出的自动化系统构建工作流，这些LLM代理的响应可以映射到实际调用相应的API，最终协调系统以实现更高的性能。实验结果验证了所提方法的可行性和有效性，并展示了其在未来无线通信系统设计中应对实际挑战的潜力。

## 参考文献

+   [1] N. A. Khan 和 S. Schmid, “6G网络中的Ai-ran：现状与挑战,” *IEEE开放通信学会期刊*, 第5卷，第294–311页, 2024年。

+   [2] Z. Wei, H. Qu, Y. Wang, X. Yuan, H. Wu, Y. Du, K. Han, N. Zhang, 和 Z. Feng, “面向5G-A和6G的集成感知与通信信号：综述,” *IEEE物联网期刊*, 第10卷，第13期，第11 068–11 092页, 2023年。

+   [3] Y. Tao, J. Wu, X. Lin, S. Mumtaz, 和 S. Cherkaoui, “数字双胞胎与基于DRL的语义传播用于6G自动驾驶服务,” 在*GLOBECOM 2023 - 2023 IEEE全球通信大会*, 2023年，第2075–2080页。

+   [4] S. I. Loutfi, U. Tureli, 和 I. Shayea, “在6G网络上通过移动边缘计算增强的现实与移动性感知：综述,” 在*2023年第10届无线网络与移动通信国际会议 (WINCOM)*, 2023年，第1–6页。

+   [5] S. Wan, Q. Yang, Z. Shi, Z. Yang, 和 Z. Zhang, “面向多模态数据的合作任务导向通信与传输控制,” 在*2023 IEEE国际通信研讨会 (ICC研讨会)*, 2023年，第1635–1640页。

+   [6] J. Shao, Y. Mao, 和 J. Zhang, “面向边缘推理的任务导向通信学习：信息瓶颈方法,” *IEEE通信领域精选杂志*, 第40卷，第1期，第197–211页, 2022年。

+   [7] A. K, S. Sudarshan G S, 和 S. J U, “自动驾驶中的LLM：一种教机器驾驶的新方法,” 在*2023年第3届国际移动网络与无线通信大会 (ICMNWC)*, 2023年，第1–6页。

+   [8] C. H. Song, B. M. Sadler, J. Wu, W.-L. Chao, C. Washington, 和 Y. Su, “LLM规划器：基于大型语言模型的具身智能体少量实例规划,” 在*2023 IEEE/CVF计算机视觉国际会议 (ICCV)*, 2023年，第2986–2997页。

+   [9] L. Bariah, H. Zou, Q. Zhao, B. Mouhouche, F. Bader, 和 M. Debbah, “通过大型语言模型理解电信语言,” 在*GLOBECOM 2023 - 2023 IEEE全球通信大会*, 2023年，第6542–6547页。

+   [10] M. Honkala, D. Korpi 和 J. M. J. Huttunen，“Deeprx：全卷积深度学习接收器，” *IEEE无线通信学报*，第20卷，第6期，页码3925–3940，2021年。
