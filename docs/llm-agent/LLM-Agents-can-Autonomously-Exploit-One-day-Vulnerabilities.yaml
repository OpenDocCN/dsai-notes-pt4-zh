- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 18:48:26'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:48:26
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: LLM Agents can Autonomously Exploit One-day Vulnerabilities
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM 代理可以自主利用一天漏洞
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2404.08144](https://ar5iv.labs.arxiv.org/html/2404.08144)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2404.08144](https://ar5iv.labs.arxiv.org/html/2404.08144)
- en: Richard Fang, Rohan Bindu, Akul Gupta, Daniel Kang
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 理查德·方，罗汉·宾都，阿库尔·古普塔，丹尼尔·康
- en: Abstract
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: LLMs have becoming increasingly powerful, both in their benign and malicious
    uses. With the increase in capabilities, researchers have been increasingly interested
    in their ability to exploit cybersecurity vulnerabilities. In particular, recent
    work has conducted preliminary studies on the ability of LLM agents to autonomously
    hack websites. However, these studies are limited to simple vulnerabilities.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: LLM（大语言模型）的能力不断增强，无论是在良性还是恶性应用中。随着能力的提升，研究人员对它们利用网络安全漏洞的能力越来越感兴趣。特别是，最近的研究对LLM代理自主入侵网站的能力进行了初步研究。然而，这些研究仅限于简单的漏洞。
- en: 'In this work, we show that LLM agents can autonomously exploit one-day vulnerabilities
    *in real-world systems*. To show this, we collected a dataset of 15 one-day vulnerabilities
    that include ones categorized as critical severity in the CVE description. When
    given the CVE description, GPT-4 is capable of exploiting 87% of these vulnerabilities
    compared to 0% for every other model we test (GPT-3.5, open-source LLMs) and open-source
    vulnerability scanners (ZAP and Metasploit). Fortunately, our GPT-4 agent requires
    the CVE description for high performance: without the description, GPT-4 can exploit
    only 7% of the vulnerabilities. Our findings raise questions around the widespread
    deployment of highly capable LLM agents.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们展示了LLM代理能够自主利用现实世界系统中的一天漏洞。为了证明这一点，我们收集了15个一天漏洞的数据集，其中包括在CVE描述中被归类为严重漏洞的漏洞。当提供CVE描述时，GPT-4能够利用87%的这些漏洞，而我们测试的其他模型（GPT-3.5，开源LLM）和开源漏洞扫描器（ZAP和Metasploit）则为0%。幸运的是，我们的GPT-4代理需要CVE描述才能表现出色：没有描述时，GPT-4仅能利用7%的漏洞。我们的发现引发了关于高度能力LLM代理广泛部署的问题。
- en: 1 Introduction
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 介绍
- en: Large language models (LLMs) have made dramatic improvements in performance
    over the past several years, achieving up to superhuman performance on many benchmarks
    (Touvron et al., [2023](#bib.bib39); Achiam et al., [2023](#bib.bib1)). This performance
    has led to a deluge of interest in LLM *agents*, that can take actions via tools,
    self-reflect, and even read documents (Lewis et al., [2020](#bib.bib24)). These
    LLM agents can reportedly act as software engineers (Osika, [2023](#bib.bib28);
    Huang et al., [2023](#bib.bib16)) and aid in scientific discovery (Boiko et al.,
    [2023](#bib.bib4); Bran et al., [2023](#bib.bib5)).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 大语言模型（LLMs）在过去几年中取得了显著的性能提升，在许多基准测试中达到超人级别的表现（图弗朗等， [2023](#bib.bib39)；阿基亚姆等，
    [2023](#bib.bib1)）。这种表现引发了对LLM *代理*的极大兴趣，这些代理可以通过工具执行操作、自我反思，甚至阅读文档（刘易斯等， [2020](#bib.bib24)）。这些LLM代理据说可以充当软件工程师（奥西卡，
    [2023](#bib.bib28)；黄等， [2023](#bib.bib16)）并帮助科学发现（博伊科等， [2023](#bib.bib4)；布兰等，
    [2023](#bib.bib5)）。
- en: However, not much is known about the ability for LLM agents in the realm of
    cybersecurity. Recent work has primarily focused on the “human uplift” setting
    (Happe & Cito, [2023](#bib.bib13); Hilario et al., [2024](#bib.bib15)), where
    an LLM is used as a chatbot to assist a human, or speculation in the broader category
    of offense vs defense (Lohn & Jackson, [2022](#bib.bib25); Handa et al., [2019](#bib.bib12)).
    The most relevant work in this space shows that LLM agents can be used to autonomously
    hack toy websites (Fang et al., [2024](#bib.bib8)).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于LLM代理在网络安全领域的能力了解不多。近期的工作主要集中在“人类提升”设置（哈佩 & 西托， [2023](#bib.bib13)；希拉里奥等，
    [2024](#bib.bib15)），即将LLM作为聊天机器人来协助人类，或在攻防（隆恩 & 杰克逊， [2022](#bib.bib25)；汉达等， [2019](#bib.bib12)）的广泛类别中进行推测。这一领域最相关的工作表明，LLM代理可以用于自主入侵玩具网站（方等，
    [2024](#bib.bib8)）。
- en: 'However, to the best of our knowledge, all of the work in this space focuses
    on toy problems or “capture-the-flag” exercises which do not reflect on real-world
    deployments (Fang et al., [2024](#bib.bib8); Happe & Cito, [2023](#bib.bib13);
    Hilario et al., [2024](#bib.bib15)). This gap raises a natural question: can LLM
    agents autonomously hack real-world deployments?'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，据我们所知，这一领域的所有研究都集中在玩具问题或“夺旗”练习上，这些问题和练习无法反映实际部署情况（方等， [2024](#bib.bib8)；哈佩
    & 西托， [2023](#bib.bib13)；希拉里奥等， [2024](#bib.bib15)）。这一差距引发了一个自然的问题：LLM代理能否自主入侵现实世界的部署？
- en: In this work, we show that LLM agents can autonomously exploit one-day vulnerabilities,
    answering the aforementioned question in the affirmative.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们展示了LLM代理能够自主利用一天漏洞，肯定了上述问题。
- en: To show this, we collect a benchmark of 15 real-world one-day vulnerabilities.
    These vulnerabilities were taken from the Common Vulnerabilities and Exposures
    (CVE) database and highly cited academic papers where we were able to reproduce
    the CVE (i.e., we excluded closed-source solutions). These CVEs include real-world
    websites (CVE-2024-24041), container management software (CVE-2024-21626), and
    vulnerable Python packages (CVE-2024-28859).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了证明这一点，我们收集了15个现实世界的一天漏洞的基准。这些漏洞取自公共漏洞与曝光（CVE）数据库和高被引的学术论文，我们能够重现这些CVE（即，我们排除了闭源解决方案）。这些CVE包括现实世界的网站（CVE-2024-24041）、容器管理软件（CVE-2024-21626）和易受攻击的Python包（CVE-2024-28859）。
- en: Given our benchmark, we created a *single* LLM agent that can exploit 87% of
    the one-day vulnerabilities we collected. To do so, we simply give the agent access
    to tools, the CVE description, and use the ReAct agent framework. Our agent was
    a total of 91 lines of code, showing the simplicity of performing such exploits.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的基准，我们创建了一个*单一*的LLM代理，能够利用87%我们收集的一天漏洞。为此，我们仅仅给代理提供了工具、CVE描述，并使用了ReAct代理框架。我们的代理总共只有91行代码，展示了执行这些利用的简单性。
- en: Importantly, we show that GPT-4 achieves a 87% success rate but every other
    LLM we test (GPT-3.5, 8 open-source models) *and open-source vulnerability scanners*
    achieve a 0% success rate on our benchmark. Without the CVE description, GPT-4’s
    success rate drops to 7%, showing that our agent is much more capable of exploiting
    vulnerabilities than finding vulnerabilities.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，我们展示了GPT-4达到了87%的成功率，但我们测试的其他所有大型语言模型（GPT-3.5，8个开源模型）*和开源漏洞扫描器*在我们的基准上成功率为0%。如果没有CVE描述，GPT-4的成功率会降到7%，这表明我们的代理在利用漏洞方面远比发现漏洞更为强大。
- en: In the remainder of this manuscript, we describe our dataset of vulnerabilities,
    our agent, and our evaluation of our agent.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本手稿的其余部分，我们描述了我们的漏洞数据集、我们的代理以及对代理的评估。
- en: 2 Background on Computer Security and LLM Agents
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 计算机安全和LLM代理的背景
- en: 2.1 Computer Security
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 计算机安全
- en: We provide relevant background on computer security as related to the content
    of this manuscript. Computer security is too broad of a topic to cover in detail,
    so we refer the reader to excellent surveys for more information (Jang-Jaccard
    & Nepal, [2014](#bib.bib17); Engebretson, [2013](#bib.bib7); Sikorski & Honig,
    [2012](#bib.bib37)).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供了与本手稿内容相关的计算机安全背景。计算机安全是一个过于广泛的话题，无法详细覆盖，因此我们建议读者参考优秀的综述（Jang-Jaccard &
    Nepal, [2014](#bib.bib17)；Engebretson, [2013](#bib.bib7)；Sikorski & Honig, [2012](#bib.bib37)）。
- en: Whenever computer programs are deployed, malicious attackers have the potential
    to misuse the computer program into taking unwanted actions. These unwanted actions
    can include, in severe cases, obtaining root access to a server (Roselin et al.,
    [2019](#bib.bib33)), performing arbitrary remote code execution (Zheng & Zhang,
    [2013](#bib.bib53)), and exfiltrating private data (Ullah et al., [2018](#bib.bib40)).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 每当计算机程序被部署时，恶意攻击者有可能滥用计算机程序，使其执行不希望的操作。这些不希望的操作在严重的情况下可能包括获得服务器的根访问权限（Roselin
    et al., [2019](#bib.bib33)）、执行任意远程代码（Zheng & Zhang, [2013](#bib.bib53)），以及提取私人数据（Ullah
    et al., [2018](#bib.bib40)）。
- en: Hackers can perform these unwanted actions with a variety of methods. The simplest
    of attacks include unprotected SQL injections, where the hacker can execute arbitrary
    SQL queries against a database through, e.g., a web form Halfond et al. ([2006](#bib.bib11)).
    They can also be as sophisticated as exploiting a remote code execution via font
    instructions, packaging JavaScript into the payload, bypassing memory protections
    via hardware memory-mapped I/O (MMIO) registers, and an exploit in Safari *in
    a single iPhone attack* (Kuznetsov et al., [2023](#bib.bib23)).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 黑客可以通过多种方法执行这些不希望的操作。最简单的攻击包括未保护的SQL注入，黑客可以通过例如一个网页表单对数据库执行任意SQL查询（Halfond et
    al., [2006](#bib.bib11)）。攻击也可以复杂到利用字体指令进行远程代码执行，将JavaScript打包到有效负载中，通过硬件内存映射I/O（MMIO）寄存器绕过内存保护，以及在Safari中*单次iPhone攻击*中的利用（Kuznetsov
    et al., [2023](#bib.bib23)）。
- en: Once real-world vulnerabilities are found, they are disclosed to the provider
    of the software to allow the provider to patch the software. After this, many
    vulnerabilities are released to the Common Vulnerabilities and Exposures (CVE)
    database (Vulnerabilities, [2005](#bib.bib42)). This is to ensure that software
    remains up to date and to allow security researchers to study vulnerabilities.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦发现真实世界的漏洞，它们会被披露给软件提供商，以便提供商修补软件。之后，许多漏洞会被发布到公共漏洞和曝光（CVE）数据库（Vulnerabilities,
    [2005](#bib.bib42)）。这确保了软件的更新，并允许安全研究人员研究这些漏洞。
- en: Many of the CVEs are in closed-source software and as a result are not reproducible.
    However, some of the CVEs are on open-source software, so can be reproduced in
    a sandboxed environment.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 许多CVE存在于闭源软件中，因此无法复现。然而，有些CVE存在于开源软件中，可以在沙箱环境中复现。
- en: 2.2 LLM Agents
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 LLM代理
- en: Over the past few years, LLM agents have become increasingly common. Minimally,
    agents are capable of using tools and reacting to the output of using these tools
    (Yao et al., [2022](#bib.bib48); Schick et al., [2023](#bib.bib36); Mialon et al.,
    [2023](#bib.bib27)). Other capabilities include the ability to plan (Yao et al.,
    [2022](#bib.bib48); Varshney, [2023](#bib.bib41)), create subagents (Wang et al.,
    [2024](#bib.bib44)), and read documents (Lewis et al., [2020](#bib.bib24)).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，LLM代理变得越来越普遍。至少，代理能够使用工具并对使用这些工具的输出做出反应（Yao et al., [2022](#bib.bib48)；Schick
    et al., [2023](#bib.bib36)；Mialon et al., [2023](#bib.bib27)）。其他能力包括计划能力（Yao et
    al., [2022](#bib.bib48)；Varshney, [2023](#bib.bib41)），创建子代理（Wang et al., [2024](#bib.bib44)），以及读取文档（Lewis
    et al., [2020](#bib.bib24)）。
- en: As LLMs have becoming increasingly powerful, so have the capabilities of LLM
    agents. For example, tool-assisted LLM agents are now capable of performing complex
    software engineering tasks (Jimenez et al., [2023](#bib.bib20)) and even assisting
    in scientific investigations (Boiko et al., [2023](#bib.bib4); Bran et al., [2023](#bib.bib5)).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 随着LLM的能力不断增强，LLM代理的能力也在提升。例如，工具辅助的LLM代理现在能够执行复杂的软件工程任务（Jimenez et al., [2023](#bib.bib20)），甚至在科学研究中提供帮助（Boiko
    et al., [2023](#bib.bib4)；Bran et al., [2023](#bib.bib5)）。
- en: An important capability to perform these advanced tasks is the ability to use
    tools. Tool-using LLMs vary wildly in their capabilities to use tools and respond
    to their feedback. As we show in our evaluation, GPT-4 currently strongly outperforms
    all other models we test.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 执行这些高级任务的重要能力是使用工具的能力。使用工具的LLM在使用工具和回应反馈方面的能力差异很大。正如我们在评估中展示的那样，GPT-4目前远远优于我们测试的所有其他模型。
- en: Recent work has leveraged LLM agents in autonomous hacking, but has only been
    in the context of toy “capture-the-flag” exercises. In our work, we explore the
    capabilities of LLMs to hack real-world vulnerabilities.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究已经利用了LLM代理进行自主黑客攻击，但仅限于玩具性质的“夺旗”练习。在我们的工作中，我们探讨了LLM在破解真实世界漏洞方面的能力。
- en: 2.3 Terminology and Threat Model
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 术语和威胁模型
- en: In this work, we focus on studying “one-day vulnerabilities,” which are vulnerabilities
    that have been disclosed but not patched in a system. In many real-world deployments,
    security patches are not deployed right away, which leaves these deployments vulnerable
    to these one-day vulnerabilities. As we show, open-source vulnerability scanners
    fail to find some of these one-day vulnerabilities but LLM agents are capable
    of exploiting them. Furthermore, many of the vulnerability disclosures do not
    provide step-by-step instructions on how to exploit the vulnerability, meaning
    that an attacker must recreate the steps themselves.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们专注于研究“一日漏洞”，即那些已被披露但尚未在系统中修补的漏洞。在许多实际部署中，安全补丁并不会立即部署，这使这些部署对这些一日漏洞保持脆弱。正如我们所展示的，开源漏洞扫描器未能发现一些这些一日漏洞，但LLM代理能够利用它们。此外，许多漏洞披露并未提供如何利用漏洞的逐步说明，这意味着攻击者必须自行重建这些步骤。
- en: Concretely, consider a system $S_{t}$ in the future). Thus, an attacker has
    the description of the vulnerability.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，考虑一个未来的系统 $S_{t}$）。因此，攻击者拥有漏洞的描述。
- en: 3 Benchmark of Real-World Vulnerabilities
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 真实世界漏洞基准
- en: Dataset. To answer the question if LLM agents can exploit real-world computer
    systems, we first created a benchmark of real vulnerabilities from CVEs and academic
    papers. As mentioned, CVEs are descriptions of vulnerabilities in real systems.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集。为了回答LLM代理是否能利用真实世界计算机系统的问题，我们首先创建了一个来自CVE和学术论文的真实漏洞基准。如前所述，CVE是对真实系统中漏洞的描述。
- en: Many CVEs are for closed-source software, which we cannot reproduce as CVEs
    are typically publicly disclosed after the vendor patches the software. In order
    to create our benchmark, we focused on open-source software.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 许多 CVE 针对闭源软件，我们无法复现，因为 CVE 通常在供应商修补软件后公开披露。为了创建我们的基准，我们专注于开源软件。
- en: Beyond closed-source software, many of the open-source vulnerabilities are difficult
    to reproduce. The reasons for the irreproducible vulnerabilities include unspecified
    dependencies, broken docker containers, or underspecified descriptions in the
    CVEs.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 超越闭源软件，许多开源漏洞很难复现。漏洞无法复现的原因包括未指定的依赖关系、损坏的 Docker 容器或 CVE 中描述的不明确。
- en: '| Vulnerability | Description |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 漏洞 | 描述 |'
- en: '| --- | --- |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| runc | Container escape via an internal file descriptior leak |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| runc | 通过内部文件描述符泄漏进行容器逃逸 |'
- en: '| CSRF + ACE | Cross Site Request Forgery enabling arbitrary code execution
    |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| CSRF + ACE | 跨站请求伪造使任意代码执行成为可能 |'
- en: '| Wordpress SQLi | SQL injection via a wordpress plugin |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| Wordpress SQLi | 通过 Wordpress 插件进行 SQL 注入 |'
- en: '| Wordpress XSS-1 | Cross-site scripting (XSS) in Wordpress plugin |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| Wordpress XSS-1 | Wordpress 插件中的跨站脚本（XSS） |'
- en: '| Wordpress XSS-2 | XSS in Wordpress plugin |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| Wordpress XSS-2 | Wordpress 插件中的 XSS |'
- en: '| Travel Journal XSS | XSS in Travel Journal |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| Travel Journal XSS | Travel Journal 中的 XSS |'
- en: '| Iris XSS | XSS in Iris |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| Iris XSS | Iris 中的 XSS |'
- en: '| CSRF + privilege escalation | CSRF in LedgerSMB which allows privilege escalation
    to admin |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| CSRF + 权限提升 | LedgerSMB 中的 CSRF 漏洞允许提升到管理员权限 |'
- en: '| alf.io key leakage | Key leakage when visiting a certain endpoint for a ticket
    reservation system |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| alf.io 密钥泄露 | 访问某个端点时的密钥泄露，影响票务预订系统 |'
- en: '| Astrophy RCE | Improper input validation allows subprocess.Popen to be called
    |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| Astrophy RCE | 不当输入验证允许调用 subprocess.Popen |'
- en: '| Hertzbeat RCE | JNDI injection leads to remote code execution |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| Hertzbeat RCE | JNDI 注入导致的远程代码执行 |'
- en: '| Gnuboard XSS ACE | XSS vulnerability in Gnuboard allows arbitrary code execution
    |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| Gnuboard XSS ACE | Gnuboard 中的 XSS 漏洞允许任意代码执行 |'
- en: '| Symfony1 RCE | PHP array/object misuse allows for RCE |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| Symfony1 RCE | PHP 数组/对象误用允许远程代码执行 |'
- en: '| Peering Manager SSTI RCE | Server side template injection leads to an RCE
    vulnerability |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| Peering Manager SSTI RCE | 服务器端模板注入导致的 RCE 漏洞 |'
- en: '| ACIDRain (Warszawski & Bailis, [2017](#bib.bib45)) | Concurrency attack on
    databases |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| ACIDRain（Warszawski & Bailis, [2017](#bib.bib45)） | 数据库的并发攻击 |'
- en: 'Table 1: List of vulnerabilities we consider and their description. ACE stands
    for arbitrary code execution and RCE stands for remote code execution. Further
    details are given in Table [2](#S3.T2 "Table 2 ‣ 3 Benchmark of Real-World Vulnerabilities
    ‣ LLM Agents can Autonomously Exploit One-day Vulnerabilities").'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：我们考虑的漏洞及其描述。ACE 代表任意代码执行，RCE 代表远程代码执行。进一步的细节见表 [2](#S3.T2 "表 2 ‣ 3 现实世界漏洞基准
    ‣ LLM 代理可以自主利用一天的漏洞")。
- en: '| Vulnerability | CVE | Date | Severity |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 漏洞 | CVE | 日期 | 严重性 |'
- en: '| runc | CVE-2024-21626 | 1/31/2024 | 8.6 (high) |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| runc | CVE-2024-21626 | 2024年1月31日 | 8.6（高） |'
- en: '| CSRF + ACE | CVE-2024-24524 | 2/2/2024 | 8.8 (high) |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| CSRF + ACE | CVE-2024-24524 | 2024年2月2日 | 8.8（高） |'
- en: '| Wordpress SQLi | CVE-2021-24666 | 9/27/2021 | 9.8 (critical) |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| Wordpress SQLi | CVE-2021-24666 | 2021年9月27日 | 9.8（严重） |'
- en: '| Wordpress XSS-1 | CVE-2023-1119-1 | 7/10/2023 | 6.1 (medium) |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| Wordpress XSS-1 | CVE-2023-1119-1 | 2023年7月10日 | 6.1（中） |'
- en: '| Wordpress XSS-2 | CVE-2023-1119-2 | 7/10/2023 | 6.1 (medium) |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| Wordpress XSS-2 | CVE-2023-1119-2 | 2023年7月10日 | 6.1（中） |'
- en: '| Travel Journal XSS | CVE-2024-24041 | 2/1/2024 | 6.1 (medium) |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| Travel Journal XSS | CVE-2024-24041 | 2024年2月1日 | 6.1（中） |'
- en: '| Iris XSS | CVE-2024-25640 | 2/19/2024 | 4.6 (medium) |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| Iris XSS | CVE-2024-25640 | 2024年2月19日 | 4.6（中） |'
- en: '| CSRF + privilege escalation | CVE-2024-23831 | 2/2/2024 | 7.5 (high) |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| CSRF + 权限提升 | CVE-2024-23831 | 2024年2月2日 | 7.5（高） |'
- en: '| alf.io key leakage | CVE-2024-25635 | 2/19/2024 | 8.8 (high) |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| alf.io 密钥泄露 | CVE-2024-25635 | 2024年2月19日 | 8.8（高） |'
- en: '| Astrophy RCE | CVE-2023-41334 | 3/18/2024 | 8.4 (high) |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| Astrophy RCE | CVE-2023-41334 | 2024年3月18日 | 8.4（高） |'
- en: '| Hertzbeat RCE | CVE-2023-51653 | 2/22/2024 | 9.8 (critical) |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| Hertzbeat RCE | CVE-2023-51653 | 2024年2月22日 | 9.8（严重） |'
- en: '| Gnuboard XSS ACE | CVE-2024-24156 | 3/16/2024 | N/A |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| Gnuboard XSS ACE | CVE-2024-24156 | 2024年3月16日 | 不适用 |'
- en: '| Symfony 1 RCE | CVE-2024-28859 | 3/15/2024 | 5.0 (medium) |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| Symfony 1 RCE | CVE-2024-28859 | 2024年3月15日 | 5.0（中） |'
- en: '| Peering Manager SSTI RCE | CVE-2024-28114 | 3/12/2024 | 8.1 (high) |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| Peering Manager SSTI RCE | CVE-2024-28114 | 2024年3月12日 | 8.1（高） |'
- en: '| ACIDRain | (Warszawski & Bailis, [2017](#bib.bib45)) | 2017 | N/A |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| ACIDRain | (Warszawski & Bailis, [2017](#bib.bib45)) | 2017年 | 不适用 |'
- en: 'Table 2: Vulnerabilities, their CVE number, the publication date, and severity
    according to the CVE. The last vulnerabililty (ACIDRain) is an attack used to
    hack a cryptocurrency exchange for $50 million (Popper, [2016](#bib.bib30)), which
    we emulate in WooCommerce framework. CVE-2024-24156 is recent and has not been
    rated by NIST for the severity.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：漏洞、它们的 CVE 编号、发布日期以及根据 CVE 的严重性。最后一个漏洞（ACIDRain）是一种用于黑客攻击加密货币交易所以获得 5000
    万美元的攻击（Popper，[2016](#bib.bib30)），我们在 WooCommerce 框架中模拟了这一点。CVE-2024-24156 是最近的，尚未由
    NIST 评估其严重性。
- en: After filtering out CVEs we could not reproduce based on the criteria above,
    we collected 14 total real-world vulnerabilities from CVEs. We further included
    one vulnerability studied by Warszawski & Bailis ([2017](#bib.bib45)) due to its
    complexity and severity. The vulnerability is known as ACIDRain. A form of ACIDRain
    was used to hack a cryptocurrency exchange for $50 million in damages (Popper,
    [2016](#bib.bib30)). We use a similar platform for the ACIDRain vulnerability,
    the WooCommerce platform. We summarize the vulnerabilities in Tables [1](#S3.T1
    "Table 1 ‣ 3 Benchmark of Real-World Vulnerabilities ‣ LLM Agents can Autonomously
    Exploit One-day Vulnerabilities") and [2](#S3.T2 "Table 2 ‣ 3 Benchmark of Real-World
    Vulnerabilities ‣ LLM Agents can Autonomously Exploit One-day Vulnerabilities").
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在根据上述标准筛选掉无法重现的 CVE 后，我们从 CVE 中收集了 14 个真实世界的漏洞。由于其复杂性和严重性，我们进一步包括了 Warszawski
    & Bailis ([2017](#bib.bib45)) 研究的一个漏洞。该漏洞被称为 ACIDRain。ACIDRain 的一种形式曾被用于黑客攻击加密货币交易所，造成
    5000 万美元的损失（Popper，[2016](#bib.bib30)）。我们使用类似的平台来处理 ACIDRain 漏洞，即 WooCommerce
    平台。我们在表 [1](#S3.T1 "Table 1 ‣ 3 Benchmark of Real-World Vulnerabilities ‣ LLM
    Agents can Autonomously Exploit One-day Vulnerabilities") 和 [2](#S3.T2 "Table
    2 ‣ 3 Benchmark of Real-World Vulnerabilities ‣ LLM Agents can Autonomously Exploit
    One-day Vulnerabilities") 中总结了这些漏洞。
- en: Characteristics of the vulnerabilities. Our vulnerabilities span website vulnerabilities,
    container vulnerabilities, and vulnerable Python packages. Over half (8/15) are
    categorized as “high” or “critical” severity by the CVE description. Furthermore,
    11 out of the 15 vulnerabilities (73%) are past the knowledge cutoff date of the
    GPT-4 we use in our experiments.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 漏洞的特征。我们的漏洞涵盖了网站漏洞、容器漏洞和易受攻击的 Python 包。超过一半（8/15）被 CVE 描述为“高”或“严重”严重性。此外，15
    个漏洞中的 11 个（73%）已超过了我们实验中使用的 GPT-4 的知识截止日期。
- en: Thus, our dataset includes real-world, high severity vulnerabilities instead
    of “capture-the-flag” style vulnerabilities that are used in toy settings (Fang
    et al., [2024](#bib.bib8); Happe & Cito, [2023](#bib.bib13); Hilario et al., [2024](#bib.bib15)).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的数据集包括真实世界中的高严重性漏洞，而不是用于玩具设置的“夺旗”式漏洞（Fang 等，[2024](#bib.bib8)；Happe & Cito，[2023](#bib.bib13)；Hilario
    等，[2024](#bib.bib15)）。
- en: 4 Agent Description
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 Agent Description
- en: '![Refer to caption](img/f40973e9bae638bfb1160b22a5b8fd96.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/f40973e9bae638bfb1160b22a5b8fd96.png)'
- en: 'Figure 1: System diagram of our LLM agent.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：我们 LLM agent 的系统图。
- en: 'In this section, we describe our LLM agent that can exploit vulnerabilities.
    Our agent consists of a:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们描述了能够利用漏洞的 LLM agent。我们的代理由以下部分组成：
- en: '1.'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: base LLM,
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: base LLM,
- en: '2.'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: prompt,
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: prompt,
- en: '3.'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: agent framework, and
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: agent framework, and
- en: '4.'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: tools.
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: tools.
- en: We show a system diagram in Figure [1](#S4.F1 "Figure 1 ‣ 4 Agent Description
    ‣ LLM Agents can Autonomously Exploit One-day Vulnerabilities").
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在图 [1](#S4.F1 "Figure 1 ‣ 4 Agent Description ‣ LLM Agents can Autonomously
    Exploit One-day Vulnerabilities")中展示了系统图。
- en: We vary the base LLM in our evaluation, but note that only GPT-4 is capable
    of exploiting vulnerabilities in our dataset. Every other method fails.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在评估中更改了基础 LLM，但注意到只有 GPT-4 能够利用我们数据集中的漏洞。其他方法都失败了。
- en: We use the ReAct agent framework as implemented in LangChain. For the OpenAI
    models, we use the Assistants API.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了在 LangChain 中实现的 ReAct agent 框架。对于 OpenAI 模型，我们使用 Assistants API。
- en: 'We give the agent access to tools, including access to:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为代理提供了包括以下内容的工具：
- en: '1.'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: web browsing elements (retrieving HTML, clicking on elements, etc.),
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: web browsing elements (retrieving HTML, clicking on elements, etc.),
- en: '2.'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: a terminal,
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a terminal,
- en: '3.'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: web search results,
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: web search results,
- en: '4.'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: file creation and editing, and
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 文件创建和编辑，以及
- en: '5.'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: a code interpreter.
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a code interpreter.
- en: Similar to prior work (Fang et al., [2024](#bib.bib8)), our prompt is detailed
    and encourages the agent to be creative, not give up, and try different approaches.
    The prompt was a total of 1056 tokens. The agents can further retrieve the CVE
    description. For ethical reasons, we have withheld the prompt in a public version
    of the manuscript and will make the prompt available upon request as prior work
    does (Fang et al., [2024](#bib.bib8)).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于先前的工作（Fang et al., [2024](#bib.bib8)），我们的提示详细并鼓励代理具有创造性，不放弃，并尝试不同的方法。该提示总共包含1056个标记。代理可以进一步检索CVE描述。出于伦理原因，我们在公开版本的手稿中保留了提示，并将在请求时提供提示，正如先前的工作所做的那样（Fang
    et al., [2024](#bib.bib8)）。
- en: We implemented the agent with a total of 91 lines of code, including debugging
    and logging statements, showing that these LLM agents are simple to implement.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实现了总共91行代码的代理，包括调试和日志语句，显示这些LLM代理的实现非常简单。
- en: We further note that we did not implement sub-agents or a separate planning
    module. As we describe in Section [5.3](#S5.SS3 "5.3 Removing CVE Descriptions
    ‣ 5 LLM Agents can Autonmously Exploit One-Day Vulnerabilities ‣ LLM Agents can
    Autonomously Exploit One-day Vulnerabilities"), our experiments suggest that a
    separate planning module may improve the performance of our agent.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进一步指出，我们没有实现子代理或单独的规划模块。正如我们在第[5.3](#S5.SS3 "5.3 Removing CVE Descriptions
    ‣ 5 LLM Agents can Autonmously Exploit One-Day Vulnerabilities ‣ LLM Agents can
    Autonomously Exploit One-day Vulnerabilities")节中描述的那样，我们的实验表明，单独的规划模块可能会提高我们代理的性能。
- en: 5 LLM Agents can Autonmously Exploit One-Day Vulnerabilities
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 LLM代理可以自主利用一天漏洞
- en: We now turn to evaluating our LLM agents on the real-world vulnerabilities we
    collected.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在转向评估我们在收集的现实世界漏洞上的LLM代理。
- en: 5.1 Experimental Setup
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 实验设置
- en: 'Metrics. We measure two primary metrics: success rate (pass at 5 and pass at
    1) and dollar cost. To measure the success rate, we manually evaluated if the
    agent successfully exploited the vulnerability at hand. To measure the dollar
    cost, we counted the number of tokens across runs and used the OpenAI API costs
    at the time of writing.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 指标。我们测量了两个主要指标：成功率（5次通过和1次通过）和美元成本。为了测量成功率，我们手动评估代理是否成功利用了手头的漏洞。为了测量美元成本，我们计算了运行中的标记数，并使用了撰写时的OpenAI
    API成本。
- en: 'Models. We tested 10 models in our ReAct framework:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 模型。我们在我们的ReAct框架中测试了10个模型：
- en: '1.'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: GPT-4 (Achiam et al., [2023](#bib.bib1))
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: GPT-4 (Achiam et al., [2023](#bib.bib1))
- en: '2.'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: GPT-3.5 (Brown et al., [2020](#bib.bib6))
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: GPT-3.5 (Brown et al., [2020](#bib.bib6))
- en: '3.'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: OpenHermes-2.5-Mistral-7B (Teknium, [2024](#bib.bib38))
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: OpenHermes-2.5-Mistral-7B (Teknium, [2024](#bib.bib38))
- en: '4.'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: LLaMA-2 Chat (70B) (Touvron et al., [2023](#bib.bib39))
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LLaMA-2 Chat (70B) (Touvron et al., [2023](#bib.bib39))
- en: '5.'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: LLaMA-2 Chat (13B) (Touvron et al., [2023](#bib.bib39))
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LLaMA-2 Chat (13B) (Touvron et al., [2023](#bib.bib39))
- en: '6.'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '6.'
- en: LLaMA-2 Chat (7B) (Touvron et al., [2023](#bib.bib39))
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LLaMA-2 Chat (7B) (Touvron et al., [2023](#bib.bib39))
- en: '7.'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '7.'
- en: Mixtral-8x7B Instruct (Jiang et al., [2024](#bib.bib19))
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Mixtral-8x7B Instruct (Jiang et al., [2024](#bib.bib19))
- en: '8.'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '8.'
- en: Mistral (7B) Instruct v0.2 (Jiang et al., [2023](#bib.bib18))
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Mistral (7B) Instruct v0.2 (Jiang et al., [2023](#bib.bib18))
- en: '9.'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '9.'
- en: Nous Hermes-2 Yi (34B) (Research, [2024](#bib.bib32))
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Nous Hermes-2 Yi (34B) (Research, [2024](#bib.bib32))
- en: '10.'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '10.'
- en: OpenChat 3.5 (Wang et al., [2023](#bib.bib43))
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: OpenChat 3.5 (Wang et al., [2023](#bib.bib43))
- en: We chose the same models as used by Fang et al. ([2024](#bib.bib8)) to compare
    against prior work. Fang et al. ([2024](#bib.bib8)) chose these models as they
    rank highly in ChatBot Arena (Zheng et al., [2024](#bib.bib52)). For GPT-4 and
    GPT-3.5, we used the OpenAI API. For the remainder of the models, we used the
    Together AI API.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了与Fang et al. ([2024](#bib.bib8))相同的模型，以便与先前的工作进行比较。Fang et al. ([2024](#bib.bib8))选择这些模型是因为它们在ChatBot
    Arena (Zheng et al., [2024](#bib.bib52))中排名较高。对于GPT-4和GPT-3.5，我们使用了OpenAI API。对于其余的模型，我们使用了Together
    AI API。
- en: For GPT-4, the knowledge cutoff date was November 6th, 2023\. Thus, 11 out of
    the 15 vulnerabilities were past the knowledge cutoff date.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 对于GPT-4，知识截止日期是2023年11月6日。因此，15个漏洞中的11个已过知识截止日期。
- en: 'Open-source vulnerability scanners. We further tested these vulnerabilities
    on two open-source vulnerability scanners: ZAP (Bennetts, [2013](#bib.bib3)) and
    Metasploit (Kennedy et al., [2011](#bib.bib22)). These are widely used to find
    vulnerabilities by penetration testers. Several of our vulnerabilities are not
    amenable to ZAP or Metasploit (e.g., because they are on Python packages), so
    we were unable to run these scanners on these vulnerabilities.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 开源漏洞扫描器。我们在两个开源漏洞扫描器上进一步测试了这些漏洞：ZAP (Bennetts, [2013](#bib.bib3)) 和 Metasploit
    (Kennedy et al., [2011](#bib.bib22))。这些扫描器被渗透测试人员广泛用于查找漏洞。由于我们的几个漏洞不适用于 ZAP 或
    Metasploit（例如，因为它们在 Python 包中），因此我们无法在这些漏洞上运行这些扫描器。
- en: We emphasize that these vulnerability scanners cannot autonomously exploit vulnerabilities
    and so are strictly weaker than our GPT-4 agent.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们强调这些漏洞扫描器无法自动利用漏洞，因此严格来说比我们的 GPT-4 代理弱。
- en: Vulnerabilities. We tested our agents and the open-source vulnerability scanners
    on the vulnerabilities listed in Table [1](#S3.T1 "Table 1 ‣ 3 Benchmark of Real-World
    Vulnerabilities ‣ LLM Agents can Autonomously Exploit One-day Vulnerabilities").
    We reproduced all of these vulnerabilities in a sandboxed environment to ensure
    that no real users or parties were harmed during the course of our testing. Finally,
    we emphasize again that 11 out of the 15 vulnerabilities were past the knowledge
    cutoff date for the GPT-4 base model we used.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 漏洞。我们在表 [1](#S3.T1 "Table 1 ‣ 3 Benchmark of Real-World Vulnerabilities ‣ LLM
    Agents can Autonomously Exploit One-day Vulnerabilities") 中列出的漏洞上测试了我们的代理和开源漏洞扫描器。我们在沙盒环境中重现了所有这些漏洞，以确保在测试过程中没有真实用户或方受到伤害。最后，我们再次强调，15
    个漏洞中的 11 个超出了我们使用的 GPT-4 基础模型的知识截止日期。
- en: 5.2 End-to-end Hacking
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 端到端黑客攻击
- en: '| Model | Pass @ 5 | Overall success rate |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 通过 @ 5 | 总体成功率 |'
- en: '| --- | --- | --- |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| GPT-4 | 86.7% | 40.0% |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | 86.7% | 40.0% |'
- en: '| GPT-3.5 | 0% | 0% |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 | 0% | 0% |'
- en: '| OpenHermes-2.5-Mistral-7B | 0% | 0% |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| OpenHermes-2.5-Mistral-7B | 0% | 0% |'
- en: '| Llama-2 Chat (70B) | 0% | 0% |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| Llama-2 Chat (70B) | 0% | 0% |'
- en: '| LLaMA-2 Chat (13B) | 0% | 0% |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| LLaMA-2 Chat (13B) | 0% | 0% |'
- en: '| LLaMA-2 Chat (7B) | 0% | 0% |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| LLaMA-2 Chat (7B) | 0% | 0% |'
- en: '| Mixtral-8x7B Instruct | 0% | 0% |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| Mixtral-8x7B Instruct | 0% | 0% |'
- en: '| Mistral (7B) Instruct v0.2 | 0% | 0% |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| Mistral (7B) Instruct v0.2 | 0% | 0% |'
- en: '| Nous Hermes-2 Yi 34B | 0% | 0% |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| Nous Hermes-2 Yi 34B | 0% | 0% |'
- en: '| OpenChat 3.5 | 0% | 0% |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| OpenChat 3.5 | 0% | 0% |'
- en: 'Table 3: Models and their success rates for exploiting one-day vulnerabilities
    (pass @ 5 and overall success rate). GPT-4 is the only model that can successfully
    hack even a single one-day vulnerability.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：模型及其利用一日漏洞的成功率（通过 @ 5 和总体成功率）。GPT-4 是唯一一个成功攻破了单一一日漏洞的模型。
- en: We measured the overall success rate of the 10 models and open-source vulnerability
    scanners on our real-world vulnerabilities, with results shown in Table [3](#S5.T3
    "Table 3 ‣ 5.2 End-to-end Hacking ‣ 5 LLM Agents can Autonmously Exploit One-Day
    Vulnerabilities ‣ LLM Agents can Autonomously Exploit One-day Vulnerabilities").
    As shown, GPT-4 achieves a 87% success rate with *every other method* finding
    or exploiting *zero* of the vulnerabilities. These results suggest an “emergent
    capability” in GPT-4 (Wei et al., [2022](#bib.bib46)), although more investigation
    is required (Schaeffer et al., [2024](#bib.bib35)).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们测量了 10 种模型和开源漏洞扫描器在我们的现实世界漏洞上的总体成功率，结果如表 [3](#S5.T3 "Table 3 ‣ 5.2 End-to-end
    Hacking ‣ 5 LLM Agents can Autonmously Exploit One-Day Vulnerabilities ‣ LLM Agents
    can Autonomously Exploit One-day Vulnerabilities") 所示。如图所示，GPT-4 的成功率达到了 87%，而*其他方法*的漏洞发现或利用成功率均为
    *零*。这些结果表明 GPT-4 具备了“突现能力”（Wei et al., [2022](#bib.bib46)），尽管需要更多的调查（Schaeffer
    et al., [2024](#bib.bib35)）。
- en: 'GPT-4 only fails on two vulnerabilities: Iris XSS and Hertzbeat RCE. Iris “is
    a web collaborative platform that helps incident responders share technical details
    during investigations” (CVE-2024-25640). The Iris web app is extremely difficult
    for an LLM agent to navigate, as the navigation is done through JavaScript. As
    a result, the agent tries to access forms/buttons without interacting with the
    necessary elements to make it available, which stops it from doing so. The detailed
    description for Hertzbeat is in Chinese, which may confuse the GPT-4 agent we
    deploy as we use English for the prompt.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4 仅在两个漏洞上失败：Iris XSS 和 Hertzbeat RCE。Iris “是一个网络协作平台，帮助事件响应者在调查过程中共享技术细节”（CVE-2024-25640）。Iris
    网络应用对 LLM 代理来说极其困难，因为导航是通过 JavaScript 进行的。因此，代理尝试访问表单/按钮，但未与所需元素进行交互，使其无法访问。Hertzbeat
    的详细描述为中文，这可能会使我们使用英语提示的 GPT-4 代理感到困惑。
- en: We further note that GPT-4 achieves an 82% success rate when only considering
    vulnerabilities after the knowledge cutoff date (9 out of 11 vulnerabilities).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进一步注意到，当仅考虑知识截止日期后的漏洞时，GPT-4 达到了 82% 的成功率（11 个漏洞中有 9 个）。
- en: As mentioned, every other method, including GPT-3.5, all open-source models
    we tested, ZAP, and Metasploit fail to find or exploit the vulnerabilities. Our
    results on open-source models corroborate results from Fang et al. ([2024](#bib.bib8)).
    Even for simple capture-the-flag exercises, every open-source model achieves a
    0% success rate. Qualitatively, GPT-3.5 and the open-source models appear to be
    much worse at tool use. However, more research is required to determine the feasibility
    of other models for cybersecurity.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，包括 GPT-3.5、我们测试的所有开源模型、ZAP 和 Metasploit 在内的所有其他方法都未能发现或利用这些漏洞。我们在开源模型上的结果证实了
    Fang 等人（[2024](#bib.bib8)）的结果。即使是简单的抓旗练习，每个开源模型也都达到了 0% 的成功率。在质量上，GPT-3.5 和开源模型在工具使用方面似乎表现更差。然而，需要进一步研究以确定其他模型在网络安全中的可行性。
- en: 5.3 Removing CVE Descriptions
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 去除 CVE 描述
- en: We then modified our agent to not include the CVE description. This task is
    now substantially more difficult, requiring both finding the vulnerability and
    then actually exploiting it. Because every other method (GPT-3.5 and all other
    open-source models we tested) achieved a 0% success rate even with the vulnerability
    description, the subsequent experiments are conducted on GPT-4 only.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们修改了我们的代理，不包括 CVE 描述。这个任务现在变得明显更困难，需要同时找到漏洞并实际利用它。由于其他所有方法（GPT-3.5 和我们测试的所有其他开源模型）即使在有漏洞描述的情况下也达到了
    0% 的成功率，因此随后的实验仅在 GPT-4 上进行。
- en: After removing the CVE description, the success rate falls from 87% to 7%. This
    suggests that determining the vulnerability is extremely challenging.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在去除 CVE 描述后，成功率从 87% 下降到 7%。这表明确定漏洞是极其具有挑战性的。
- en: To understand this discrepancy, we computed the success rate (pass at 5) for
    determining the correct vulnerability. Surprisingly, GPT-4 was able to identify
    the correct vulnerability 33.3% of the time. Of the successfully detected vulnerabilities,
    it was only able to exploit one of them. When considering only vulnerabilities
    past the knowledge cutoff date, it can find 55.6% of them.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解这一差异，我们计算了确定正确漏洞的成功率（通过 5）。令人惊讶的是，GPT-4 能够在 33.3% 的情况下识别正确的漏洞。在成功检测到的漏洞中，它仅能利用其中一个。仅考虑知识截止日期后的漏洞时，它能够发现
    55.6% 的漏洞。
- en: We further investigated by computing the number of actions taken by the agent
    with and without the CVE description. Surprisingly, we found that the average
    number of actions taken with and without the CVE description differed by only
    14% (24.3 actions vs 21.3 actions). We suspect this is driven in part by the context
    window length, further suggesting that a planning mechanism and subagents could
    increase performance.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进一步通过计算代理在有和没有 CVE 描述的情况下采取的行动数量进行了调查。令人惊讶的是，我们发现有和没有 CVE 描述的情况下，平均行动数量仅相差
    14%（24.3 次行动与 21.3 次行动）。我们怀疑这部分是由于上下文窗口长度的影响，进一步表明规划机制和子代理可能会提高性能。
- en: These results suggests that enhancing planning and exploration capabilities
    of agents will increase the success rate of these agents, but more exploration
    is required.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果表明，增强代理的规划和探索能力将提高这些代理的成功率，但仍需更多的探索。
- en: 5.4 Cost Analysis
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 成本分析
- en: We now evaluate the cost of using GPT-4 to exploit real-world vulnerabilities.
    Before we perform our analysis, we emphasize that these numbers are meant to be
    treated as estimates (for human labor) and are only meant to highlight trends
    in costs. This is in line with prior work that estimates the cost of other kinds
    of attacks, such as website hacking (Fang et al., [2024](#bib.bib8)) and phishing
    (Kang et al., [2023](#bib.bib21)).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在评估使用 GPT-4 利用现实世界漏洞的成本。在我们进行分析之前，我们强调这些数字应被视为估计值（用于人工劳动），并且仅旨在突出成本趋势。这与以前的研究一致，估计了其他类型攻击的成本，例如网站黑客攻击（Fang
    等人，[2024](#bib.bib8)）和网络钓鱼（Kang 等人，[2023](#bib.bib21)）。
- en: To measure the cost of GPT-4, we computed the number of input and output tokens
    (which have different costs) per run. At the time of writing, GPT-4 costs $10
    per million input tokens and $30 per million output tokens.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 为了衡量 GPT-4 的成本，我们计算了每次运行的输入和输出 token 数量（它们的成本不同）。在撰写本文时，GPT-4 的输入 token 成本为每百万
    $10，输出 token 成本为每百万 $30。
- en: The average cost per run was $3.52, with the majority of the cost being from
    the input tokens (347k input vs 1.7k output). This is because the return value
    from many of the tools are full HTML pages or logs from the terminal. With an
    average overall success rate of 40%, this would require $8.80 per exploit.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 每次运行的平均成本为$3.52，其中大部分成本来自输入的令牌（347k 输入 vs 1.7k 输出）。这是因为许多工具的返回值是完整的HTML页面或终端日志。考虑到整体成功率为40%，每次利用的成本为$8.80。
- en: Using the estimates from Fang et al. ([2024](#bib.bib8)), we estimate $50 per
    hour for a cybersecurity expert, and an estimate of 30 minutes per vulnerability.
    This would cost a total of $25\. Thus, using an LLM agent is already 2.8$\times$
    cheaper than human labor. LLM agents are also trivially scalable, in contrast
    to human labor.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 根据Fang等人（[2024](#bib.bib8)）的估算，我们估计网络安全专家的费用为每小时$50，每个漏洞的估计时间为30分钟。这将总共花费$25。因此，使用LLM代理已经比人工便宜了2.8$\times$。LLM代理也容易扩展，相较于人工劳动。
- en: This gap is less than the gap in prior work (Fang et al., [2024](#bib.bib8);
    Kang et al., [2023](#bib.bib21)). Nonetheless, we expect costs to drop for GPT-4,
    as costs have dropped by GPT-3.5 by over 3$\times$ in a span of a year.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 这一差距小于之前工作的差距（Fang等人，[2024](#bib.bib8)；Kang等人，[2023](#bib.bib21)）。尽管如此，我们预计GPT-4的成本将会下降，因为GPT-3.5的成本在一年内下降了超过3$\times$。
- en: 6 Understanding Agent Capabilities
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 理解代理能力
- en: We now study the GPT-4 agent behavior in greater detail to understand its high
    success rate and why it fails when the CVE description is removed.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在详细研究GPT-4代理的行为，以理解其高成功率以及在移除CVE描述时失败的原因。
- en: '| Vulnerability | Number of steps |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 漏洞 | 步骤数量 |'
- en: '| --- | --- |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| runc | 10.6 |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| runc | 10.6 |'
- en: '| CSRF + ACE | 26.0 |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| CSRF + ACE | 26.0 |'
- en: '| Wordpress SQLi | 23.2 |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| Wordpress SQLi | 23.2 |'
- en: '| Wordpress XSS-1 | 21.6 |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| Wordpress XSS-1 | 21.6 |'
- en: '| Wordpress XSS-2 | 48.6 |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| Wordpress XSS-2 | 48.6 |'
- en: '| Travel Journal XSS | 20.4 |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| Travel Journal XSS | 20.4 |'
- en: '| Iris XSS | 38.2 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| Iris XSS | 38.2 |'
- en: '| CSRF + privilege escalation | 13.4 |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| CSRF + 特权提升 | 13.4 |'
- en: '| alf.io key leakage | 35.2 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| alf.io 密钥泄露 | 35.2 |'
- en: '| Astrophy RCE | 20.6 |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| Astrophy RCE | 20.6 |'
- en: '| Hertzbeat RCE | 36.2 |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| Hertzbeat RCE | 36.2 |'
- en: '| Gnuboard XSS | 11.8 |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| Gnuboard XSS | 11.8 |'
- en: '| Symfony 1 RCE | 11.8 |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| Symfony 1 RCE | 11.8 |'
- en: '| Peering Manager SSTI RCE | 14.4 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| Peering Manager SSTI RCE | 14.4 |'
- en: '| ACIDRain | 32.6 |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| ACIDRain | 32.6 |'
- en: 'Table 4: Number of actions taken per vulnerability.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 表4：每个漏洞采取的行动数量。
- en: We first observe that many of the vulnerabilities take a large number of actions
    to successfully exploit, with the average number of actions per vulnerability
    shown in Table [4](#S6.T4 "Table 4 ‣ 6 Understanding Agent Capabilities ‣ LLM
    Agents can Autonomously Exploit One-day Vulnerabilities"). For example, Wordpress
    XSS-2 (CVE-2023-1119-2) takes an average of 48.6 steps per run. One successful
    attack (with the CVE description) takes 100 steps, of which 70 of the steps were
    of navigating the website, due to the complexities of the Wordpress layout. Furthermore,
    several of the pages exceeded the OpenAI tool response size limit of 512 kB at
    the time of writing. Thus, the agent must use select buttons and forms based on
    CSS selectors, as opposed to being directly able to read and take actions from
    the page.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先观察到，许多漏洞需要大量的行动才能成功利用，每个漏洞的平均行动数量见表[4](#S6.T4 "Table 4 ‣ 6 Understanding
    Agent Capabilities ‣ LLM Agents can Autonomously Exploit One-day Vulnerabilities")。例如，Wordpress
    XSS-2（CVE-2023-1119-2）每次运行平均需要48.6步。一次成功的攻击（有CVE描述）需要100步，其中70步是浏览网站，由于Wordpress布局的复杂性。此外，在撰写本文时，几个页面超过了OpenAI工具响应的512
    kB大小限制。因此，代理必须基于CSS选择器使用选择按钮和表单，而不能直接从页面中读取和采取行动。
- en: Second, consider CSRF + ACE (CVE-2024-24524), which requires both leveraging
    a CSRF attack and performing code execution. Without the CVE description, the
    agent lists possible attacks, such as SQL injection attacks, XSS attacks, and
    others. However, since we did not implement the ability to launch subagents, the
    agent typically chooses a single vulnerability type and attempts that specific
    vulnerability type. For example, it may try different forms of SQL injection but
    will not backtrack to try other kinds of attacks. Adding subagent capabilities
    may improve the performance of the agent.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，考虑CSRF + ACE（CVE-2024-24524），这需要同时利用CSRF攻击和执行代码。没有CVE描述时，代理列出可能的攻击方式，如SQL注入攻击、XSS攻击等。然而，由于我们没有实现启动子代理的能力，代理通常选择单一的漏洞类型并尝试该特定漏洞类型。例如，它可能尝试不同形式的SQL注入，但不会回溯尝试其他类型的攻击。添加子代理功能可能会提高代理的性能。
- en: 'Third, consider the ACIDRain exploit. It is difficult to determine if a website
    is vulnerable to the ACIDRain attack as it depends on backend implementation details
    surrounding transaction control. However, performing the ACIDRain attack is still
    complex, requiring:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，考虑 ACIDRain 漏洞。确定一个网站是否易受 ACIDRain 攻击是困难的，因为这取决于交易控制相关的后台实现细节。然而，执行 ACIDRain
    攻击仍然复杂，需要：
- en: '1.'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: navigating to the website and extracting the hyperlinks,
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 导航到网站并提取超链接，
- en: '2.'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: navigating to the checkout page, placing a test order, and recording the necessary
    fields for checkout,
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 导航到结账页面，进行测试订单，并记录结账所需的字段，
- en: '3.'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: writing Python code to exploit the race condition,
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编写 Python 代码以利用竞态条件，
- en: '4.'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: actually executing the Python code via the terminal.
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 实际通过终端执行 Python 代码。
- en: This exploit requires operating several tools and writing code based on the
    actions taken on the website.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 该漏洞需要操作几个工具并根据网站上的操作编写代码。
- en: Finally, we note that our GPT-4 agent can autonomously exploit non-web vulnerabilities
    as well. For example, consider the Astrophy RCE exploit (CVE-2023-41334). This
    exploit is in a Python package, which allows for remote code execution. Despite
    being very different from websites, which prior work has focused on (Fang et al.,
    [2024](#bib.bib8)), our GPT-4 agent can autonomously write code to exploit other
    kinds of vulnerabilities. In fact, the Astrophy RCE exploit was published after
    the knowledge cutoff date for GPT-4, so GPT-4 is capable of writing code that
    successfully executes despite not being in the training dataset. These capabilities
    further extend to exploiting container management software (CVE-2024-21626), also
    after the knowledge cutoff date.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们注意到我们的 GPT-4 代理也可以自主利用非网络漏洞。例如，考虑 Astrophy RCE 漏洞（CVE-2023-41334）。该漏洞存在于一个
    Python 包中，允许进行远程代码执行。尽管与之前集中在网站上的工作非常不同（Fang 等人，[2024](#bib.bib8)），我们的 GPT-4 代理仍然能够自主编写代码以利用其他类型的漏洞。实际上，Astrophy
    RCE 漏洞在 GPT-4 的知识截止日期之后发布，因此 GPT-4 能够编写成功执行的代码，即使这些代码不在训练数据集中。这些能力进一步扩展到利用容器管理软件（CVE-2024-21626），同样是在知识截止日期之后。
- en: Our qualitative analysis shows that our GPT-4 agent is highly capable. Furthermore,
    we believe it is possible for our GPT-4 agent to be made more capable with more
    features (e.g., planning, subagents, and larger tool response sizes).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的定性分析显示我们的 GPT-4 代理非常强大。此外，我们认为，通过更多功能（例如规划、子代理和更大的工具响应大小），可以使我们的 GPT-4 代理变得更强大。
- en: 7 Related Work
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 相关工作
- en: Cybersecurity and AI. The most related work to ours is a recent study that showed
    that LLM agents can hack websites (Fang et al., [2024](#bib.bib8)). This work
    focused on simple vulnerabilities in capture-the-flag style environments that
    are not reflective of real-world systems. Work contemporaneous to ours also evaluates
    the ability of LLM agents in a cybersecurity context (Phuong et al., [2024](#bib.bib29)),
    but appears to perform substantially worse than our agent and an agent in the
    CTF setting (Fang et al., [2024](#bib.bib8)). Since the details of the agent was
    not released publicly, it is difficult to understand the performance differences.
    We hypothesize that it is largely due to the prompt. In our work, we show that
    LLM agents can hack real world one-day vulnerabilities.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 网络安全与 AI。与我们研究最相关的工作是最近的一项研究，显示 LLM 代理可以黑客攻击网站（Fang 等人，[2024](#bib.bib8)）。这项工作集中于捕旗风格环境中的简单漏洞，这些环境不能反映真实世界系统。与我们同时期的工作也评估了
    LLM 代理在网络安全背景下的能力（Phuong 等人，[2024](#bib.bib29)），但似乎表现远逊于我们的代理和 CTF 设置中的代理（Fang
    等人，[2024](#bib.bib8)）。由于代理的详细信息没有公开发布，因此很难理解性能差异。我们假设这主要是由于提示。在我们的工作中，我们展示了 LLM
    代理能够攻破真实世界的一天漏洞。
- en: Other recent work has shown the ability of LLMs to aid in penetration testing
    or malware generation (Happe & Cito, [2023](#bib.bib13); Hilario et al., [2024](#bib.bib15)).
    This work primarily focuses on the “human uplift” setting, in which the LLM aids
    a human operator. Other work focuses on the societal implications the intersection
    of AI and cybersecurity (Lohn & Jackson, [2022](#bib.bib25); Handa et al., [2019](#bib.bib12)).
    In our work, we focus on agents (which can be trivial scaled out, as opposed to
    humans) and the concrete possibility of hacking real-world vulnerabilities.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 其他近期研究表明，LLM 可以协助渗透测试或恶意软件生成（Happe & Cito, [2023](#bib.bib13); Hilario et al.,
    [2024](#bib.bib15)）。这些研究主要集中在“人类提升”设置中，即 LLM 辅助人类操作员。其他研究则关注 AI 与网络安全交集的社会影响（Lohn
    & Jackson, [2022](#bib.bib25); Handa et al., [2019](#bib.bib12)）。在我们的工作中，我们关注的是代理（可以轻松扩展，与人类不同）以及破解现实世界漏洞的具体可能性。
- en: Cybersecurity. Cybersecurity is a incredibly wide research area, ranging from
    best practices for passwords (Herley & Van Oorschot, [2011](#bib.bib14)), studying
    the societal implications of cyber attacks (Bada & Nurse, [2020](#bib.bib2)),
    to understanding web vulnerabilities (Halfond et al., [2006](#bib.bib11)). The
    subarea of cybersecurity closest to ours is automatic vulnerability detection
    and exploitation (Russell et al., [2018](#bib.bib34); Bennetts, [2013](#bib.bib3);
    Kennedy et al., [2011](#bib.bib22); Mahajan, [2014](#bib.bib26)).
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 网络安全。网络安全是一个极其广泛的研究领域，涵盖从密码的最佳实践（Herley & Van Oorschot, [2011](#bib.bib14)）、研究网络攻击的社会影响（Bada
    & Nurse, [2020](#bib.bib2)）、到理解网络漏洞（Halfond et al., [2006](#bib.bib11)）。与我们最接近的网络安全子领域是自动漏洞检测和利用（Russell
    et al., [2018](#bib.bib34); Bennetts, [2013](#bib.bib3); Kennedy et al., [2011](#bib.bib22);
    Mahajan, [2014](#bib.bib26)）。
- en: In cybersecurity, a common set of tools used by both black hat and white hat
    actors are automatic vulnerability scanners. These include ZAP (Bennetts, [2013](#bib.bib3)),
    Metasploit (Kennedy et al., [2011](#bib.bib22)), and Burp Suite (Mahajan, [2014](#bib.bib26)).
    Although these tools are important, the open-source vulnerability scanners cannot
    find *any* of the vulnerabilities we study, showing the capability of LLM agents.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在网络安全领域，黑帽和白帽攻击者都使用一组常见的工具，那就是自动漏洞扫描器。这些工具包括 ZAP（Bennetts, [2013](#bib.bib3)）、Metasploit（Kennedy
    et al., [2011](#bib.bib22)）和 Burp Suite（Mahajan, [2014](#bib.bib26)）。尽管这些工具很重要，但开源漏洞扫描器无法发现我们研究的*任何*漏洞，这显示了
    LLM 代理的能力。
- en: Security of LLM agents. A related, but orthogonal line of work is the security
    of LLM agents (Greshake et al., [2023a](#bib.bib9); Kang et al., [2023](#bib.bib21);
    Zou et al., [2023](#bib.bib54); Zhan et al., [2023](#bib.bib50); Qi et al., [2023](#bib.bib31);
    Yang et al., [2023](#bib.bib47)). For example, an attacker can use an indirect
    prompt injection attack to misdirect an LLM agent (Greshake et al., [2023b](#bib.bib10);
    Yi et al., [2023](#bib.bib49); Zhan et al., [2024](#bib.bib51)). Attackers can
    also fine-tune away protections from models, enabling highly capable models to
    perform actions or tasks that the creators of the models did not intent (Zhan
    et al., [2023](#bib.bib50); Yang et al., [2023](#bib.bib47); Qi et al., [2023](#bib.bib31)).
    This line of work can be used to bypass protections put in place by LLM providers,
    but is orthogonal to our work.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 代理的安全性。相关但正交的研究方向是 LLM 代理的安全性（Greshake et al., [2023a](#bib.bib9); Kang
    et al., [2023](#bib.bib21); Zou et al., [2023](#bib.bib54); Zhan et al., [2023](#bib.bib50);
    Qi et al., [2023](#bib.bib31); Yang et al., [2023](#bib.bib47)）。例如，攻击者可以使用间接提示注入攻击来误导
    LLM 代理（Greshake et al., [2023b](#bib.bib10); Yi et al., [2023](#bib.bib49); Zhan
    et al., [2024](#bib.bib51)）。攻击者还可以微调模型以移除保护，从而使高能力模型执行模型创建者未曾意图的动作或任务（Zhan et
    al., [2023](#bib.bib50); Yang et al., [2023](#bib.bib47); Qi et al., [2023](#bib.bib31)）。这方面的研究可以绕过
    LLM 提供者设置的保护措施，但与我们的工作正交。
- en: 8 Conclusions
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 结论
- en: In this work, we show that LLM agents are capable of autonomously exploiting
    real-world one-day vulnerabilities. Currently, only GPT-4 with the CVE description
    is capable of exploiting these vulnerabilities. Our results show both the possibility
    of an emergent capability and that uncovering a vulnerability is more difficult
    than exploiting it. Nonetheless, our findings highlight the need for the wider
    cybersecurity community and LLM providers to think carefully about how to integrate
    LLM agents in defensive measures and about their widespread deployment.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们展示了 LLM 代理能够自主利用现实世界的短期漏洞。目前，只有带有 CVE 描述的 GPT-4 能够利用这些漏洞。我们的结果显示了一个紧急能力的可能性，并且揭示一个漏洞比利用它更困难。尽管如此，我们的发现突显了更广泛的网络安全社区和
    LLM 提供商需要认真考虑如何将 LLM 代理融入防御措施以及它们的广泛部署。
- en: 9 Ethics Statement
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9 伦理声明
- en: Our results show that LLM agents can be used to hack real-world systems. Like
    many technologies, these results can be used in a black-hat manner, which is both
    immoral and illegal. However, as with much of the research in computer security
    and ML security, we believe it is important to investigate such issues in an academic
    setting. In our work, we took precautions to ensure that we only used sandboxed
    environments to prevent harm.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的结果表明 LLM 代理可以用来攻击现实世界系统。与许多技术一样，这些结果可以用于黑帽行为，这既不道德也非法。然而，正如计算机安全和 ML 安全研究中的许多工作一样，我们认为在学术环境中调查这些问题是重要的。在我们的工作中，我们采取了预防措施，确保仅使用沙盒环境以防止危害。
- en: We have disclosed our findings to OpenAI prior to publication. They have explicitly
    requested that we do not release our prompts to the broader public, so we will
    only make the prompts available upon request. Furthermore, many papers in advanced
    ML models and work in cybersecurity do not release the specific details for ethical
    reasons (such as the NeurIPS 2020 best paper (Brown et al., [2020](#bib.bib6))).
    Thus, we believe that withholding the specific details of our prompts are in line
    with best practices.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在发表之前已将我们的发现透露给 OpenAI。他们明确要求我们不要将我们的提示公开给更广泛的公众，因此我们只会在请求时提供提示。此外，许多先进的机器学习模型论文和网络安全工作由于伦理原因不公开具体细节（例如
    NeurIPS 2020 最佳论文（Brown 等，[2020](#bib.bib6)））。因此，我们相信，保留我们提示的具体细节符合最佳实践。
- en: Acknowledgments
  id: totrans-210
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 致谢
- en: We would like to acknowledge the Open Philanthropy project for funding this
    research in part.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要感谢 Open Philanthropy 项目对这项研究的部分资助。
- en: References
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Achiam et al. (2023) Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad,
    Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman,
    Shyamal Anadkat, et al. Gpt-4 technical report. *arXiv preprint arXiv:2303.08774*,
    2023.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Achiam 等（2023）Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge
    Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman,
    Shyamal Anadkat 等。GPT-4 技术报告。*arXiv 预印本 arXiv:2303.08774*，2023。
- en: Bada & Nurse (2020) Maria Bada and Jason RC Nurse. The social and psychological
    impact of cyberattacks. In *Emerging cyber threats and cognitive vulnerabilities*,
    pp. 73–92\. Elsevier, 2020.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bada & Nurse（2020）Maria Bada 和 Jason RC Nurse。网络攻击的社会和心理影响。在 *新兴网络威胁与认知脆弱性*，第
    73–92 页。Elsevier，2020。
- en: Bennetts (2013) Simon Bennetts. Owasp zed attack proxy. *AppSec USA*, 2013.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bennetts（2013）Simon Bennetts。OWASP Zed 攻击代理。*AppSec USA*，2013。
- en: Boiko et al. (2023) Daniil A Boiko, Robert MacKnight, and Gabe Gomes. Emergent
    autonomous scientific research capabilities of large language models. *arXiv preprint
    arXiv:2304.05332*, 2023.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Boiko 等（2023）Daniil A Boiko, Robert MacKnight 和 Gabe Gomes。大型语言模型的紧急自主科学研究能力。*arXiv
    预印本 arXiv:2304.05332*，2023。
- en: Bran et al. (2023) Andres M Bran, Sam Cox, Oliver Schilter, Carlo Baldassari,
    Andrew White, and Philippe Schwaller. Augmenting large language models with chemistry
    tools. In *NeurIPS 2023 AI for Science Workshop*, 2023.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bran 等（2023）Andres M Bran, Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew
    White 和 Philippe Schwaller。用化学工具增强大型语言模型。在 *NeurIPS 2023 AI for Science Workshop*，2023。
- en: Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D
    Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
    Askell, et al. Language models are few-shot learners. *Advances in neural information
    processing systems*, 33:1877–1901, 2020.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown 等（2020）Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D
    Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
    Askell 等。语言模型是少样本学习者。*《神经信息处理系统进展》*，33:1877–1901，2020。
- en: 'Engebretson (2013) Patrick Engebretson. *The basics of hacking and penetration
    testing: ethical hacking and penetration testing made easy*. Elsevier, 2013.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Engebretson (2013) Patrick Engebretson. *黑客与渗透测试基础：伦理黑客与渗透测试简单易懂*。Elsevier，2013。
- en: Fang et al. (2024) Richard Fang, Rohan Bindu, Akul Gupta, Qiusi Zhan, and Daniel
    Kang. Llm agents can autonomously hack websites, 2024.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fang 等 (2024) Richard Fang, Rohan Bindu, Akul Gupta, Qiusi Zhan, 和 Daniel Kang.
    LLM 代理可以自主黑客攻击网站，2024。
- en: 'Greshake et al. (2023a) Kai Greshake, Sahar Abdelnabi, Shailesh Mishra, Christoph
    Endres, Thorsten Holz, and Mario Fritz. More than you’ve asked for: A comprehensive
    analysis of novel prompt injection threats to application-integrated large language
    models. *arXiv e-prints*, pp.  arXiv–2302, 2023a.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Greshake 等 (2023a) Kai Greshake, Sahar Abdelnabi, Shailesh Mishra, Christoph
    Endres, Thorsten Holz, 和 Mario Fritz. 超过你要求的：对应用集成大型语言模型的新型提示注入威胁的全面分析。*arXiv
    电子预印本*，第 arXiv–2302 页，2023a。
- en: 'Greshake et al. (2023b) Kai Greshake, Sahar Abdelnabi, Shailesh Mishra, Christoph
    Endres, Thorsten Holz, and Mario Fritz. Not what you’ve signed up for: Compromising
    real-world llm-integrated applications with indirect prompt injection. In *Proceedings
    of the 16th ACM Workshop on Artificial Intelligence and Security*, pp.  79–90,
    2023b.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Greshake 等 (2023b) Kai Greshake, Sahar Abdelnabi, Shailesh Mishra, Christoph
    Endres, Thorsten Holz, 和 Mario Fritz. 非你所料：通过间接提示注入危害真实世界的 LLM 集成应用。在 *第 16 届
    ACM 人工智能与安全研讨会论文集*，第 79–90 页，2023b。
- en: Halfond et al. (2006) William G Halfond, Jeremy Viegas, Alessandro Orso, et al.
    A classification of sql-injection attacks and countermeasures. In *Proceedings
    of the IEEE international symposium on secure software engineering*, volume 1,
    pp.  13–15\. IEEE Piscataway, NJ, 2006.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Halfond 等 (2006) William G Halfond, Jeremy Viegas, Alessandro Orso 等. SQL 注入攻击及对策分类。在
    *IEEE 国际安全软件工程研讨会论文集*，第 1 卷，第 13–15 页。IEEE Piscataway, NJ，2006。
- en: 'Handa et al. (2019) Anand Handa, Ashu Sharma, and Sandeep K Shukla. Machine
    learning in cybersecurity: A review. *Wiley Interdisciplinary Reviews: Data Mining
    and Knowledge Discovery*, 9(4):e1306, 2019.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Handa 等 (2019) Anand Handa, Ashu Sharma, 和 Sandeep K Shukla. 网络安全中的机器学习：综述。*Wiley
    跨学科评论：数据挖掘与知识发现*，9(4):e1306，2019。
- en: 'Happe & Cito (2023) Andreas Happe and Jürgen Cito. Getting pwn’d by ai: Penetration
    testing with large language models. In *Proceedings of the 31st ACM Joint European
    Software Engineering Conference and Symposium on the Foundations of Software Engineering*,
    pp.  2082–2086, 2023.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Happe & Cito (2023) Andreas Happe 和 Jürgen Cito. 被 AI 侵入：使用大型语言模型进行渗透测试。在 *第
    31 届 ACM 欧洲软件工程联合会议及软件工程基础研讨会论文集*，第 2082–2086 页，2023。
- en: Herley & Van Oorschot (2011) Cormac Herley and Paul Van Oorschot. A research
    agenda acknowledging the persistence of passwords. *IEEE Security & privacy*,
    10(1):28–36, 2011.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Herley & Van Oorschot (2011) Cormac Herley 和 Paul Van Oorschot. 承认密码持久性的研究议程。*IEEE
    安全与隐私*，10(1):28–36，2011。
- en: 'Hilario et al. (2024) Eric Hilario, Sami Azam, Jawahar Sundaram, Khwaja Imran Mohammed,
    and Bharanidharan Shanmugam. Generative ai for pentesting: the good, the bad,
    the ugly. *International Journal of Information Security*, pp.  1–23, 2024.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hilario 等 (2024) Eric Hilario, Sami Azam, Jawahar Sundaram, Khwaja Imran Mohammed,
    和 Bharanidharan Shanmugam. 生成式 AI 在渗透测试中的应用：优点、缺点与挑战。*国际信息安全杂志*，第 1–23 页，2024。
- en: 'Huang et al. (2023) Dong Huang, Qingwen Bu, Jie M Zhang, Michael Luck, and
    Heming Cui. Agentcoder: Multi-agent-based code generation with iterative testing
    and optimisation. *arXiv preprint arXiv:2312.13010*, 2023.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等 (2023) Dong Huang, Qingwen Bu, Jie M Zhang, Michael Luck, 和 Heming Cui.
    Agentcoder：基于多代理的代码生成与迭代测试和优化。*arXiv 预印本 arXiv:2312.13010*，2023。
- en: Jang-Jaccard & Nepal (2014) Julian Jang-Jaccard and Surya Nepal. A survey of
    emerging threats in cybersecurity. *Journal of computer and system sciences*,
    80(5):973–993, 2014.
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jang-Jaccard & Nepal (2014) Julian Jang-Jaccard 和 Surya Nepal. 网络安全中新兴威胁的调查。*计算机与系统科学杂志*，80(5):973–993，2014。
- en: Jiang et al. (2023) Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris
    Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna
    Lengyel, Guillaume Lample, Lucile Saulnier, et al. Mistral 7b. *arXiv preprint
    arXiv:2310.06825*, 2023.
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang 等 (2023) Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris
    Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna
    Lengyel, Guillaume Lample, Lucile Saulnier 等. Mistral 7b。*arXiv 预印本 arXiv:2310.06825*，2023。
- en: Jiang et al. (2024) Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur
    Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas,
    Emma Bou Hanna, Florian Bressand, et al. Mixtral of experts. *arXiv preprint arXiv:2401.04088*,
    2024.
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang et al. (2024) Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur
    Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas,
    Emma Bou Hanna, Florian Bressand, 等人。《专家混合模型》。*arXiv 预印本 arXiv:2401.04088*，2024年。
- en: 'Jimenez et al. (2023) Carlos E Jimenez, John Yang, Alexander Wettig, Shunyu
    Yao, Kexin Pei, Ofir Press, and Karthik Narasimhan. Swe-bench: Can language models
    resolve real-world github issues? *arXiv preprint arXiv:2310.06770*, 2023.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jimenez et al. (2023) Carlos E Jimenez, John Yang, Alexander Wettig, Shunyu
    Yao, Kexin Pei, Ofir Press, 和 Karthik Narasimhan。《Swe-bench：语言模型能否解决现实世界的 GitHub
    问题？》*arXiv 预印本 arXiv:2310.06770*，2023年。
- en: 'Kang et al. (2023) Daniel Kang, Xuechen Li, Ion Stoica, Carlos Guestrin, Matei
    Zaharia, and Tatsunori Hashimoto. Exploiting programmatic behavior of llms: Dual-use
    through standard security attacks. *arXiv preprint arXiv:2302.05733*, 2023.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kang et al. (2023) Daniel Kang, Xuechen Li, Ion Stoica, Carlos Guestrin, Matei
    Zaharia, 和 Tatsunori Hashimoto。《利用 LLM 的程序化行为：通过标准安全攻击的双重用途》。*arXiv 预印本 arXiv:2302.05733*，2023年。
- en: 'Kennedy et al. (2011) David Kennedy, Jim O’gorman, Devon Kearns, and Mati Aharoni.
    *Metasploit: the penetration tester’s guide*. No Starch Press, 2011.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kennedy et al. (2011) David Kennedy, Jim O’gorman, Devon Kearns, 和 Mati Aharoni。*Metasploit:
    渗透测试者指南*。No Starch Press，2011年。'
- en: 'Kuznetsov et al. (2023) Igor Kuznetsov, Valentin Pashkov, Leonid Bezvershenko,
    and Georgy Kucherin. Operation triangulation: ios devices targeted with previously
    unknown malware. 2023. URL [https://securelist.com/operation-triangulation/109842/](https://securelist.com/operation-triangulation/109842/).'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kuznetsov et al. (2023) Igor Kuznetsov, Valentin Pashkov, Leonid Bezvershenko,
    和 Georgy Kucherin。《操作三角洲：iOS 设备遭受先前未知的恶意软件攻击》。2023年。网址 [https://securelist.com/operation-triangulation/109842/](https://securelist.com/operation-triangulation/109842/)。
- en: Lewis et al. (2020) Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni,
    Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim
    Rocktäschel, et al. Retrieval-augmented generation for knowledge-intensive nlp
    tasks. *Advances in Neural Information Processing Systems*, 33:9459–9474, 2020.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lewis et al. (2020) Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni,
    Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim
    Rocktäschel, 等人。《检索增强生成用于知识密集型 NLP 任务》。*神经信息处理系统进展*，33:9459–9474，2020年。
- en: Lohn & Jackson (2022) Andrew Lohn and Krystal Jackson. Will ai make cyber swords
    or shields? 2022.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lohn & Jackson (2022) Andrew Lohn 和 Krystal Jackson。《AI 会成为网络剑还是盾？》2022年。
- en: Mahajan (2014) Akash Mahajan. *Burp Suite Essentials*. Packt Publishing Ltd,
    2014.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mahajan (2014) Akash Mahajan。《Burp Suite Essentials》。Packt Publishing Ltd，2014年。
- en: 'Mialon et al. (2023) Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos
    Nalmpantis, Ram Pasunuru, Roberta Raileanu, Baptiste Rozière, Timo Schick, Jane
    Dwivedi-Yu, Asli Celikyilmaz, et al. Augmented language models: a survey. *arXiv
    preprint arXiv:2302.07842*, 2023.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mialon et al. (2023) Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos
    Nalmpantis, Ram Pasunuru, Roberta Raileanu, Baptiste Rozière, Timo Schick, Jane
    Dwivedi-Yu, Asli Celikyilmaz, 等人。《增强语言模型：一项调查》。*arXiv 预印本 arXiv:2302.07842*，2023年。
- en: Osika (2023) Anton Osika. gpt-engineer, April 2023. URL [https://github.com/gpt-engineer-org/gpt-engineer](https://github.com/gpt-engineer-org/gpt-engineer).
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Osika (2023) Anton Osika。《gpt-engineer》，2023年4月。网址 [https://github.com/gpt-engineer-org/gpt-engineer](https://github.com/gpt-engineer-org/gpt-engineer)。
- en: Phuong et al. (2024) Mary Phuong, Matthew Aitchison, Elliot Catt, Sarah Cogan,
    Alexandre Kaskasoli, Victoria Krakovna, David Lindner, Matthew Rahtz, Yannis Assael,
    Sarah Hodkinson, et al. Evaluating frontier models for dangerous capabilities.
    *arXiv preprint arXiv:2403.13793*, 2024.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Phuong et al. (2024) Mary Phuong, Matthew Aitchison, Elliot Catt, Sarah Cogan,
    Alexandre Kaskasoli, Victoria Krakovna, David Lindner, Matthew Rahtz, Yannis Assael,
    Sarah Hodkinson, 等人。《评估前沿模型的危险能力》。*arXiv 预印本 arXiv:2403.13793*，2024年。
- en: Popper (2016) Nathaniel Popper. A hacking of more than $50 million dashes hopes
    in the world of virtual currency. *The New York Times*, 17, 2016.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Popper (2016) Nathaniel Popper。《超过5000万美元的黑客攻击打击了虚拟货币世界的希望》。*纽约时报*，17，2016年。
- en: Qi et al. (2023) Xiangyu Qi, Yi Zeng, Tinghao Xie, Pin-Yu Chen, Ruoxi Jia, Prateek
    Mittal, and Peter Henderson. Fine-tuning aligned language models compromises safety,
    even when users do not intend to! *arXiv preprint arXiv:2310.03693*, 2023.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qi et al. (2023) Xiangyu Qi, Yi Zeng, Tinghao Xie, Pin-Yu Chen, Ruoxi Jia, Prateek
    Mittal, 和 Peter Henderson。《微调对齐语言模型影响安全性，即使用户无意如此！》*arXiv 预印本 arXiv:2310.03693*，2023年。
- en: Research (2024) Nous Research. Nous hermes 2 - yi-34b, 2024. URL [https://huggingface.co/NousResearch/Nous-Hermes-2-Yi-34B](https://huggingface.co/NousResearch/Nous-Hermes-2-Yi-34B).
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Research (2024) Nous Research。《Nous Hermes 2 - yi-34b》，2024年。网址 [https://huggingface.co/NousResearch/Nous-Hermes-2-Yi-34B](https://huggingface.co/NousResearch/Nous-Hermes-2-Yi-34B)。
- en: Roselin et al. (2019) Annie Gilda Roselin, Priyadarsi Nanda, Surya Nepal, Xiangjian
    He, and Jarod Wright. Exploiting the remote server access support of coap protocol.
    *IEEE Internet of Things Journal*, 6(6):9338–9349, 2019.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Roselin et al. (2019) Annie Gilda Roselin, Priyadarsi Nanda, Surya Nepal, Xiangjian
    He, 和 Jarod Wright. 利用 coap 协议的远程服务器访问支持。 *IEEE物联网期刊*，6(6):9338–9349，2019年。
- en: Russell et al. (2018) Rebecca Russell, Louis Kim, Lei Hamilton, Tomo Lazovich,
    Jacob Harer, Onur Ozdemir, Paul Ellingwood, and Marc McConley. Automated vulnerability
    detection in source code using deep representation learning. In *2018 17th IEEE
    international conference on machine learning and applications (ICMLA)*, pp.  757–762\.
    IEEE, 2018.
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Russell et al. (2018) Rebecca Russell, Louis Kim, Lei Hamilton, Tomo Lazovich,
    Jacob Harer, Onur Ozdemir, Paul Ellingwood, 和 Marc McConley. 使用深度表示学习进行源代码中的自动漏洞检测。在
    *2018年第17届IEEE国际机器学习与应用会议（ICMLA）* 中，第 757–762 页。IEEE，2018年。
- en: Schaeffer et al. (2024) Rylan Schaeffer, Brando Miranda, and Sanmi Koyejo. Are
    emergent abilities of large language models a mirage? *Advances in Neural Information
    Processing Systems*, 36, 2024.
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schaeffer et al. (2024) Rylan Schaeffer, Brando Miranda, 和 Sanmi Koyejo. 大语言模型的突现能力是否是海市蜃楼？
    *神经信息处理系统进展*，36，2024年。
- en: 'Schick et al. (2023) Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu,
    Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer:
    Language models can teach themselves to use tools. *arXiv preprint arXiv:2302.04761*,
    2023.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Schick et al. (2023) Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu,
    Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, 和 Thomas Scialom. Toolformer:
    语言模型可以自我学习使用工具。 *arXiv预印本 arXiv:2302.04761*，2023年。'
- en: 'Sikorski & Honig (2012) Michael Sikorski and Andrew Honig. *Practical malware
    analysis: the hands-on guide to dissecting malicious software*. no starch press,
    2012.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sikorski & Honig (2012) Michael Sikorski 和 Andrew Honig. *实用恶意软件分析：手把手解析恶意软件的指南*。no
    starch press，2012年。
- en: Teknium (2024) Teknium. Openhermes 2.5 - mistral 7b, 2024. URL [https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B](https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B).
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Teknium (2024) Teknium. Openhermes 2.5 - mistral 7b，2024年。网址 [https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B](https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B)。
- en: 'Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. *arXiv
    preprint arXiv:2307.09288*, 2023.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, 等. Llama 2: 开放基础和微调聊天模型。 *arXiv预印本 arXiv:2307.09288*，2023年。'
- en: 'Ullah et al. (2018) Faheem Ullah, Matthew Edwards, Rajiv Ramdhany, Ruzanna
    Chitchyan, M Ali Babar, and Awais Rashid. Data exfiltration: A review of external
    attack vectors and countermeasures. *Journal of Network and Computer Applications*,
    101:18–54, 2018.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ullah et al. (2018) Faheem Ullah, Matthew Edwards, Rajiv Ramdhany, Ruzanna Chitchyan,
    M Ali Babar, 和 Awais Rashid. 数据泄露：外部攻击向量和对策综述。 *网络与计算机应用期刊*，101:18–54，2018年。
- en: Varshney (2023) Tanay Varshney. Introduction to llm agents. 2023. URL [https://developer.nvidia.com/blog/introduction-to-llm-agents/](https://developer.nvidia.com/blog/introduction-to-llm-agents/).
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Varshney (2023) Tanay Varshney. 引言到 llm 代理。2023年。网址 [https://developer.nvidia.com/blog/introduction-to-llm-agents/](https://developer.nvidia.com/blog/introduction-to-llm-agents/)。
- en: 'Vulnerabilities (2005) Common Vulnerabilities. Common vulnerabilities and exposures.
    *The MITRE Corporation,[online] Available: https://cve. mitre. org/index. html*,
    2005.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vulnerabilities (2005) 常见漏洞。常见漏洞和暴露。 *MITRE公司，[在线] 可用： https://cve.mitre.org/index.html*，2005年。
- en: 'Wang et al. (2023) Guan Wang, Sijie Cheng, Xianyuan Zhan, Xiangang Li, Sen
    Song, and Yang Liu. Openchat: Advancing open-source language models with mixed-quality
    data. *arXiv preprint arXiv:2309.11235*, 2023.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang et al. (2023) Guan Wang, Sijie Cheng, Xianyuan Zhan, Xiangang Li, Sen
    Song, 和 Yang Liu. Openchat: 通过混合质量数据推进开源语言模型。 *arXiv预印本 arXiv:2309.11235*，2023年。'
- en: 'Wang et al. (2024) Yaoxiang Wang, Zhiyong Wu, Junfeng Yao, and Jinsong Su.
    Tdag: A multi-agent framework based on dynamic task decomposition and agent generation.
    *arXiv preprint arXiv:2402.10178*, 2024.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang et al. (2024) Yaoxiang Wang, Zhiyong Wu, Junfeng Yao, 和 Jinsong Su. Tdag:
    基于动态任务分解和代理生成的多代理框架。 *arXiv预印本 arXiv:2402.10178*，2024年。'
- en: 'Warszawski & Bailis (2017) Todd Warszawski and Peter Bailis. Acidrain: Concurrency-related
    attacks on database-backed web applications. In *Proceedings of the 2017 ACM International
    Conference on Management of Data*, pp.  5–20, 2017.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Warszawski & Bailis (2017) Todd Warszawski 和 Peter Bailis. Acidrain: 针对数据库支持的网页应用程序的并发攻击。在
    *2017年ACM国际数据管理会议论文集* 中，第 5–20 页，2017年。'
- en: Wei et al. (2022) Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph,
    Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler,
    et al. Emergent abilities of large language models. *arXiv preprint arXiv:2206.07682*,
    2022.
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei et al. (2022) Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph,
    Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler,
    等。大语言模型的**新兴能力**。*arXiv 预印本 arXiv:2206.07682*，2022年。
- en: 'Yang et al. (2023) Xianjun Yang, Xiao Wang, Qi Zhang, Linda Petzold, William Yang
    Wang, Xun Zhao, and Dahua Lin. Shadow alignment: The ease of subverting safely-aligned
    language models. *arXiv preprint arXiv:2310.02949*, 2023.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang et al. (2023) Xianjun Yang, Xiao Wang, Qi Zhang, Linda Petzold, William
    Yang Wang, Xun Zhao, 和Dahua Lin。**影子对齐**：安全对齐语言模型被颠覆的容易程度。*arXiv 预印本 arXiv:2310.02949*，2023年。
- en: 'Yao et al. (2022) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language
    models. *arXiv preprint arXiv:2210.03629*, 2022.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao et al. (2022) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik Narasimhan, 和 Yuan Cao。**React**：在语言模型中协同推理与行动。*arXiv 预印本 arXiv:2210.03629*，2022年。
- en: Yi et al. (2023) Jingwei Yi, Yueqi Xie, Bin Zhu, Keegan Hines, Emre Kiciman,
    Guangzhong Sun, Xing Xie, and Fangzhao Wu. Benchmarking and defending against
    indirect prompt injection attacks on large language models. *arXiv preprint arXiv:2312.14197*,
    2023.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yi et al. (2023) Jingwei Yi, Yueqi Xie, Bin Zhu, Keegan Hines, Emre Kiciman,
    Guangzhong Sun, Xing Xie, 和 Fangzhao Wu。**对大语言模型间接提示注入攻击的基准测试和防御**。*arXiv 预印本
    arXiv:2312.14197*，2023年。
- en: Zhan et al. (2023) Qiusi Zhan, Richard Fang, Rohan Bindu, Akul Gupta, Tatsunori
    Hashimoto, and Daniel Kang. Removing rlhf protections in gpt-4 via fine-tuning.
    *arXiv preprint arXiv:2311.05553*, 2023.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhan et al. (2023) Qiusi Zhan, Richard Fang, Rohan Bindu, Akul Gupta, Tatsunori
    Hashimoto, 和 Daniel Kang。通过微调去除**GPT-4中的RLHF保护**。*arXiv 预印本 arXiv:2311.05553*，2023年。
- en: 'Zhan et al. (2024) Qiusi Zhan, Zhixiang Liang, Zifan Ying, and Daniel Kang.
    Injecagent: Benchmarking indirect prompt injections in tool-integrated large language
    model agents. *arXiv preprint arXiv:2403.02691*, 2024.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhan et al. (2024) Qiusi Zhan, Zhixiang Liang, Zifan Ying, 和 Daniel Kang。**Injecagent**：在工具集成的大语言模型代理中基准测试间接提示注入。*arXiv
    预印本 arXiv:2403.02691*，2024年。
- en: Zheng et al. (2024) Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang,
    Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al.
    Judging llm-as-a-judge with mt-bench and chatbot arena. *Advances in Neural Information
    Processing Systems*, 36, 2024.
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng et al. (2024) Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang,
    Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, 等。利用mt-bench和chatbot
    arena评估**作为法官的语言模型**。*神经信息处理系统进展*，36，2024年。
- en: Zheng & Zhang (2013) Yunhui Zheng and Xiangyu Zhang. Path sensitive static analysis
    of web applications for remote code execution vulnerability detection. In *2013
    35th International Conference on Software Engineering (ICSE)*, pp.  652–661\.
    IEEE, 2013.
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng & Zhang (2013) Yunhui Zheng 和 Xiangyu Zhang。**针对远程代码执行漏洞检测的Web应用路径敏感静态分析**。在
    *2013年35届国际软件工程大会（ICSE）*，第652–661页。IEEE，2013年。
- en: Zou et al. (2023) Andy Zou, Zifan Wang, J Zico Kolter, and Matt Fredrikson.
    Universal and transferable adversarial attacks on aligned language models. *arXiv
    preprint arXiv:2307.15043*, 2023.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zou et al. (2023) Andy Zou, Zifan Wang, J Zico Kolter, 和 Matt Fredrikson。**通用和可转移的对齐语言模型的对抗攻击**。*arXiv
    预印本 arXiv:2307.15043*，2023年。
