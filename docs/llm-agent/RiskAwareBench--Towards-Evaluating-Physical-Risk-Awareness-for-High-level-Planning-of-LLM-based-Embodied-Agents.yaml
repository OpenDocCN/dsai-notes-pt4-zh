- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:39:16'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:39:16
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'RiskAwareBench: Towards Evaluating Physical Risk Awareness for High-level Planning
    of LLM-based Embodied Agents'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'RiskAwareBench: 旨在评估基于LLM的具身体智能体的物理风险意识'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2408.04449](https://ar5iv.labs.arxiv.org/html/2408.04449)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2408.04449](https://ar5iv.labs.arxiv.org/html/2408.04449)
- en: 'Zihao Zhu ¹   Bingzhe Wu²²²footnotemark: 2   Zhengyou Zhang³   Baoyuan Wu¹'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**Zihao Zhu** ¹   **Bingzhe Wu**²²²脚注标记：2   **Zhengyou Zhang**³   **Baoyuan
    Wu**¹'
- en: ¹ School of Data Science, The Chinese University of Hong Kong, Shenzhen,
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ¹ 香港中文大学（深圳）数据科学学院，
- en: Guangdong, 518172, P.R. China
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 广东，518172，中国
- en: ² Tencent AI Lab  ³ Tencent Robotics X
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ² 腾讯AI实验室  ³ 腾讯机器人X
- en: zihaozhu@link.cuhk.edu.en,  bingzhewu@tencent.com,
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: zihaozhu@link.cuhk.edu.en,  bingzhewu@tencent.com,
- en: zhengyou@tencent.com,  wubaoyuan@cuhk.edu.cn
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: zhengyou@tencent.com,  wubaoyuan@cuhk.edu.cn
- en: 'WARNING: This paper contains unsafe plans generated by LLMs'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 警告：本文包含由LLMs生成的不安全计划
- en: that may lead to physical risks in the real world. This work was done when the
    author was interning at Tencent AI Lab.Corresponding Authors.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能会导致现实世界中的物理风险。此项工作是在作者于腾讯AI实验室实习期间完成的。通讯作者：
- en: Abstract
  id: totrans-14
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'The integration of large language models (LLMs) into robotics significantly
    enhances the capabilities of embodied agents in understanding and executing complex
    natural language instructions. However, the unmitigated deployment of LLM-based
    embodied systems in real-world environments may pose potential physical risks,
    such as property damage and personal injury. Existing security benchmarks for
    LLMs overlook risk awareness for LLM-based embodied agents. To address this gap,
    we propose RiskAwareBench, an automated framework designed to assess physical
    risks awareness in LLM-based embodied agents. RiskAwareBench consists of four
    modules: safety tips generation, risky scene generation, plan generation, and
    evaluation, enabling comprehensive risk assessment with minimal manual intervention.
    Utilizing this framework, we compile the PhysicalRisk dataset, encompassing diverse
    scenarios with associated safety tips, observations, and instructions. Extensive
    experiments reveal that most LLMs exhibit insufficient physical risk awareness,
    and baseline risk mitigation strategies yield limited enhancement, which emphasizes
    the urgency and cruciality of improving risk awareness in LLM-based embodied agents
    in the future.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）在机器人技术中的集成显著增强了具身体智能体在理解和执行复杂自然语言指令方面的能力。然而，基于LLM的具身系统在现实世界环境中的未经缓解部署可能带来潜在的物理风险，如财产损害和人身伤害。现有的LLM安全基准忽视了对基于LLM的具身体智能体的风险意识。为填补这一空白，我们提出了RiskAwareBench，这是一种自动化框架，旨在评估基于LLM的具身体智能体的物理风险意识。RiskAwareBench由四个模块组成：安全提示生成、风险场景生成、计划生成和评估，实现了在最小人工干预下的全面风险评估。利用这一框架，我们编制了PhysicalRisk数据集，涵盖了各种情境及相关安全提示、观察和指令。广泛的实验表明，大多数LLM表现出不足的物理风险意识，而基线风险缓解策略的提升有限，这强调了未来提高基于LLM的具身体智能体风险意识的紧迫性和关键性。
- en: 1 Introduction
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: One of the long-term goals of AI and robotics is to enable embodied agents to
    understand natural language instructions and perform complex tasks [[14](#bib.bib14)].
    Recent advances in large language models (LLMs) have demonstrated a profound capacity
    for understanding, reasoning, and planning leading to significant enhancements
    across various domains [[21](#bib.bib21)]. LLMs have acquired an extensive repository
    of world knowledge and task execution strategies by learning from vast amounts
    of multimodal data. Consequently, contemporary research is investigating the application
    of LLMs within the realm of robotics [[27](#bib.bib27)], positioning them as the
    brain for embodied AI systems, which equips the agents with high-level task plans,
    enabling robots to exhibit a human-like understanding and decision-making proficiency
    in task execution [[3](#bib.bib3), [19](#bib.bib19), [4](#bib.bib4), [22](#bib.bib22),
    [9](#bib.bib9)].
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: AI和机器人技术的长期目标之一是使具身体智能体能够理解自然语言指令并执行复杂任务 [[14](#bib.bib14)]。近期大型语言模型（LLMs）的进展展示了其在理解、推理和规划方面的深厚能力，导致在各个领域的显著提升
    [[21](#bib.bib21)]。LLMs通过从大量多模态数据中学习，获得了广泛的世界知识和任务执行策略。因此，当代研究正在探索LLMs在机器人领域的应用
    [[27](#bib.bib27)]，将其定位为具身AI系统的大脑，为智能体提供高层任务计划，使机器人在任务执行中展现出类似人类的理解和决策能力 [[3](#bib.bib3),
    [19](#bib.bib19), [4](#bib.bib4), [22](#bib.bib22), [9](#bib.bib9)]。
- en: Nevertheless, deploying embodied agents into the real physical world carries
    potential safety hazards that could pose risks to the environment, property, and
    even human safety, dubbed as physical risks. For instance, in a kitchen scenario
    equipped solely with metal utensils, where a housekeeping robot instructed to
    “heat food with the microwave and utensils”, we empirically find that most LLMs
    fail to recognize the implicit danger that “microwaving metal can lead to the
    production of electric arcs, potentially damaging the microwave or even starting
    a fire”. As a result, these robots may formulate high-level plans with potential
    physical risks, such as “place a metal plate inside the microwave” and “turn on
    the microwave”. Therefore, prior to the practical deployment of LLM-based embodied
    agents, assessing their awareness of physical risks among the high-level task
    plans is crucial for achieving safe embodied intelligence.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，将具身代理部署到真实物理世界中带来了潜在的安全隐患，这些隐患可能对环境、财产甚至人身安全构成风险，被称为物理风险。例如，在一个仅配备金属用具的厨房场景中，当一个家务机器人被指示“用微波炉和用具加热食物”时，我们发现大多数LLMs无法识别“微波加热金属会产生电弧，可能会损坏微波炉甚至引发火灾”的隐含危险。因此，这些机器人可能会制定具有潜在物理风险的高层次计划，例如“将金属盘放入微波炉中”和“打开微波炉”。因此，在LLM基于的具身代理实际部署之前，评估其在高层任务计划中对物理风险的意识对实现安全的具身智能至关重要。
- en: Recent benchmarks have been proposed to evaluate the safety of LLMs. For example,
    SafetyBench [[28](#bib.bib28)] presents a comprehensive benchmark for evaluating
    the safety of LLMs using multiple-choice questions covering various safety concerns.
    ToolEmu [[16](#bib.bib16)] introduces a framework for scalable testing of LLM
    agents by emulating tool execution and evaluating safety risks. ASSERT [[10](#bib.bib10)]
    emphasizes the robustness of LLMs through Automated Safety ScEnario Red Teaming,
    which generates a suite of prompts to evaluate the model’s performance under various
    robustness settings. R-Judge [[26](#bib.bib26)] focuses on evaluating the behavioral
    safety of LLM agents within interactive environments by analyzing agent interaction
    records. Although existing studies have made significant strides in evaluating
    the safety and robustness of LLMs, they often overlook the specific aspect of
    physical risk awareness for embodied agents operating in diverse environment.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 最近提出了评估LLMs安全性的基准。例如，SafetyBench [[28](#bib.bib28)] 提供了一个全面的基准，通过多项选择题涵盖各种安全问题来评估LLMs的安全性。ToolEmu
    [[16](#bib.bib16)] 引入了一个可扩展测试LLM代理的框架，通过模拟工具执行并评估安全风险。ASSERT [[10](#bib.bib10)]
    通过自动化安全场景红队测试强调LLMs的鲁棒性，该方法生成一套提示以评估模型在各种鲁棒性设置下的表现。R-Judge [[26](#bib.bib26)]
    通过分析代理交互记录，专注于在互动环境中评估LLM代理的行为安全性。尽管现有研究在评估LLMs的安全性和鲁棒性方面取得了显著进展，但它们往往忽视了在不同环境中操作的具身代理的具体物理风险意识。
- en: 'Considering the limitations of current safety evaluations, in this paper, we
    propose RiskAwareBench, which aims to fill this gap by providing an automated
    framework for benchmarking the capability of LLM-based embodied agents to identify
    and mitigate potential physical risks in real-world environments. This framework
    comprises four key modules: safety tip generation module, scene generation module,
    plan generation module, and evaluation module. The safety tip generation module
    is responsible for generating safety tips and corresponding explanations for common
    environments. The scene generation module creates the detailed scene information
    and observation as well as natural language instructions for embodied agents based
    on the specific safety tip. The format of scene observation varies, depending
    on the type of LLM that serves as the core of the embodied agent. In the plan
    generation module, the LLM-based embodied agent generates high-level plans based
    on scene observations and instructions for guiding the downstream low-level control.
    The evaluation module includes risk evaluation and effectiveness evaluation, where
    the former evaluates whether the task planning contains implicit physical risks
    and identifies specific dangerous steps, while the latter evaluates whether the
    plans can efficiently complete the task as instructed. All the aforementioned
    modules are driven by large foundation models, enabling the automated evaluation
    of physical risk awareness for embodied agents, thereby reducing the requirement
    for manual intervention.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到当前安全评估的局限性，本文提出了RiskAwareBench，旨在通过提供一个自动化框架来填补这一空白，该框架用于基准评估基于LLM的具身体智能体在现实环境中识别和减轻潜在物理风险的能力。该框架包括四个关键模块：安全提示生成模块、场景生成模块、计划生成模块和评估模块。安全提示生成模块负责生成安全提示及其对应的解释，适用于常见环境。场景生成模块根据特定的安全提示创建详细的场景信息和观察以及自然语言指令。场景观察的格式会有所不同，具体取决于作为具身体智能体核心的LLM类型。在计划生成模块中，基于LLM的具身体智能体根据场景观察和指令生成高层次的计划，以指导下游的低层次控制。评估模块包括风险评估和效果评估，其中前者评估任务规划是否包含隐含的物理风险并识别特定的危险步骤，而后者评估计划是否能高效地完成任务。所有上述模块都由大型基础模型驱动，使得对具身体智能体的物理风险意识进行自动化评估，从而减少对人工干预的需求。
- en: Utilizing RiskAwareBench, we collect the PhysicalRisk dataset, which encompasses
    safety tips, scene observations, and robotic instructions across various scenarios.
    Moreover, we conduct extensive experiments to assess the physical risk awareness
    of LLM-based embodied agents. The baseline experiments explore the influence of
    various popular LLMs with different sizes. The findings indicate that most LLMs
    lack physical risk awareness. Furthermore, we introduced several baseline risk
    mitigation strategies to enhance the risk awareness of LLM-based embodied agents.
    The results show minimal improvement, underscoring the urgency of advancing physical
    risk awareness in embodied intelligent systems.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 利用RiskAwareBench，我们收集了PhysicalRisk数据集，该数据集包括安全提示、场景观察和各种场景下的机器人指令。此外，我们进行广泛的实验，以评估基于LLM的具身体智能体的物理风险意识。基准实验探讨了不同规模的流行LLM的影响。结果表明，大多数LLM缺乏物理风险意识。此外，我们引入了几种基准风险缓解策略，以提高基于LLM的具身体智能体的风险意识。结果显示改进甚微，突显了推进具身智能系统物理风险意识的紧迫性。
- en: 'In summary, our contributions are as follows: 1) We reveal the potential physical
    risks of deploying LLM-based embodied intelligent systems in the real world. 2)
    We propose a benchmark framework that enables automatic evaluation of physical
    risk awareness of LLM-based embodied agents. 3) Based on the proposed framework,
    we construct a dataset that contains various scenarios along with risky scenes
    and instructions. 4) Extensive experiments are conducted to compare various popular
    LLMs as the high-level planner of embodied agents.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们的贡献如下：1）揭示了在现实世界中部署基于LLM的具身智能系统的潜在物理风险。2）提出了一个基准框架，实现了对基于LLM的具身体智能体物理风险意识的自动评估。3）基于提出的框架，我们构建了一个包含各种场景以及风险场景和指令的数据集。4）进行广泛实验，以比较作为具身体智能体高层次规划者的各种流行LLM。
- en: 2 Related Work
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: 2.1 LLMs in Embodied Task Planning
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 具身任务规划中的LLM
- en: Building on the demonstrated prowess of LLMs in intricate reasoning and contextual
    generalization, recent years have seen a growing interest in leveraging LLMs for
    embodied task planning [[25](#bib.bib25), [23](#bib.bib23)]. Brohan et al. [[3](#bib.bib3)]
    highlight the potential of combining LLMs with pretrained robotic skills to ground
    high-level instructions in real-world contexts, enabling feasible and contextually
    appropriate actions. Xie et al. [[22](#bib.bib22)] explore the use of ChatGPT
    in robotics, showing how prompt engineering and function libraries help adapt
    to various tasks, from logical reasoning to complex manipulation, primarily through
    natural language interactions. Shi et al. [[18](#bib.bib18)] introduce Robotic
    Vision-Language Planning (ViLa), which integrates perceptual data into LLM reasoning,
    enhancing understanding of spatial layouts and object attributes for better action
    planning. Zhu et al. [[29](#bib.bib29)] present Robotics with Fast and Slow Thinking
    (RFST), a dual-process framework that manages tasks requiring quick responses
    and deliberate reasoning by aligning vision-language models with policy networks.
    Shi et al. [[17](#bib.bib17)] propose OPEx, a framework dissecting core components
    of embodied instruction following tasks, emphasizing the impact of visual perception
    and low-level action execution, and enhancing performance through a multi-agent
    dialogue strategy. Despite these advancements, current research often overlooks
    physical risk awareness of LLM-based embodied agents. Our work specifically addresses
    this gap by evaluating the ability of LLM-based embodied agents to recognize and
    mitigate potential physical risks in real-world environments.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 基于大语言模型（LLMs）在复杂推理和上下文泛化方面的显著能力，近年来对将LLMs用于具体任务规划的兴趣不断增长[[25](#bib.bib25), [23](#bib.bib23)]。Brohan等人[[3](#bib.bib3)]强调了将LLMs与预训练机器人技能结合的潜力，以将高级指令落实到实际场景中，从而实现可行且符合上下文的动作。Xie等人[[22](#bib.bib22)]探索了ChatGPT在机器人领域的应用，展示了如何通过提示工程和功能库来适应各种任务，从逻辑推理到复杂操作，主要通过自然语言互动实现。Shi等人[[18](#bib.bib18)]介绍了机器人视觉-语言规划（ViLa），将感知数据整合到LLM推理中，以增强对空间布局和物体属性的理解，从而改进行动规划。Zhu等人[[29](#bib.bib29)]提出了快思考与慢思考的机器人框架（RFST），这是一个双重处理框架，通过将视觉-语言模型与策略网络对齐，管理需要快速响应和深思熟虑的任务。Shi等人[[17](#bib.bib17)]提出了OPEx，这是一个解析具体现实任务核心组件的框架，强调了视觉感知和低级动作执行的影响，并通过多智能体对话策略来提升性能。尽管有这些进展，目前的研究往往忽视了基于LLM的具身智能体的物理风险意识。我们的工作专门解决了这一空白，通过评估基于LLM的具身智能体在现实环境中识别和减轻潜在物理风险的能力。
- en: 2.2 Safety Evaluation of LLM Agents
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 LLM智能体的安全评估
- en: The evaluation of safety in LLM Agents has garnered significant attention, with
    various studies proposing benchmarks and frameworks to assess different safety
    aspects of these models. SAFETEXT [[8](#bib.bib8)] highlights the susceptibility
    of state-of-the-art LLMs to generating unsafe text and their difficulty in rejecting
    unsafe advice, emphasizing the need for further research in commonsense physical
    safety. SafetyBench [[28](#bib.bib28)] provides a comprehensive benchmark for
    evaluating the safety of LLMs using multiple-choice questions across seven distinct
    safety categories. This benchmark facilitates evaluation in both Chinese and English,
    revealing substantial room for improving the safety of current LLMs despite the
    advantages shown by models like GPT-4. ToolEmu [[16](#bib.bib16)] offers a scalable
    testing framework by emulating tool execution and evaluating safety risks associated
    with LLM agents. This framework identifies potential failures and quantifies associated
    risks, providing a quantitative risk analysis of current LM agents. However, it
    primarily focuses on tool interactions rather than physical risk awareness in
    real-world scenarios. ASSERT [[10](#bib.bib10)] emphasizes the robustness of LLMs
    through Automated Safety ScEnario Red Teaming, generating prompts to evaluate
    model performance under various robustness settings. This approach provides a
    fine-grained analysis of model performance across different safety domains but
    does not specifically address the physical risks encountered by embodied agents.
    R-Judge [[26](#bib.bib26)] benchmarks the behavioral safety of LLM agents within
    interactive environments by analyzing agent interaction records. It evaluates
    the proficiency of LLMs in judging safety risks and highlights the importance
    of salient safety risk feedback. Despite its comprehensive evaluation, R-Judge
    centers on interaction records rather than proactive physical risk identification.
    While these studies have advanced LLM safety evaluations, they often overlook
    physical risk awareness for LLM-based embodied agents, which RiskAwareBench specifically
    addresses by benchmarking their ability to identify and mitigate real-world physical
    risks.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 对LLM代理的安全性评估已经引起了广泛关注，许多研究提出了评估这些模型不同安全方面的基准和框架。SAFETEXT [[8](#bib.bib8)] 突出了最先进的LLM在生成不安全文本方面的易感性以及它们拒绝不安全建议的困难，强调了在常识物理安全方面需要进一步研究。SafetyBench [[28](#bib.bib28)]
    提供了一个全面的基准，通过七个不同的安全类别的多项选择题来评估LLM的安全性。这个基准支持中文和英文的评估，揭示了尽管像GPT-4这样的模型显示了优势，但当前LLM的安全性仍有很大改进空间。ToolEmu [[16](#bib.bib16)]
    通过模拟工具执行并评估与LLM代理相关的安全风险，提供了一个可扩展的测试框架。该框架识别潜在的失败并量化相关风险，提供了对当前语言模型代理的定量风险分析。然而，它主要关注工具交互，而非现实场景中的物理风险意识。ASSERT [[10](#bib.bib10)]
    通过自动化安全场景红队评估LLM的鲁棒性，生成提示以评估模型在各种鲁棒性设置下的表现。这种方法提供了不同安全领域中模型表现的细粒度分析，但未特别解决具身代理所遇到的物理风险。R-Judge [[26](#bib.bib26)]
    通过分析代理交互记录来评估LLM代理在交互环境中的行为安全性。它评估LLM在判断安全风险方面的能力，并强调了显著安全风险反馈的重要性。尽管其评估全面，R-Judge
    侧重于交互记录，而非主动的物理风险识别。尽管这些研究推动了LLM安全性评估的发展，但它们通常忽视了LLM基于具身代理的物理风险意识，这一点由RiskAwareBench专门通过基准测试它们识别和减轻现实世界物理风险的能力来解决。
- en: 3 Preliminaries
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 初步研究
- en: '![Refer to caption](img/da75aa9171156e67d06584bca6a49bf6.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/da75aa9171156e67d06584bca6a49bf6.png)'
- en: 'Figure 1: The fundamental framework of LLM-based embodied intelligence system.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：基于LLM的具身智能系统的基本框架。
- en: 3.1 LLM-based Embodied AI
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 基于LLM的具身AI
- en: 'LLM-based embodied AI refers to the integration of Large Language Models (LLMs)
    within the realm of robotics to create embodied agents, which are capable of interacting
    with the physical environment in a more human-like manner, thanks to the advanced
    understanding and planning capabilities of LLMs. According to recent studies [[5](#bib.bib5),
    [23](#bib.bib23)], , as shown in Figure [1](#S3.F1 "Figure 1 ‣ 3 Preliminaries
    ‣ RiskAwareBench: Towards Evaluating Physical Risk Awareness for High-level Planning
    of LLM-based Embodied Agents") a fundamental framework of an LLM-based embodied
    intelligence system consists of three key components, including perception, planning,
    and control.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '基于LLM的具身AI指的是将大型语言模型（LLMs）集成到机器人领域中，以创建具身代理，这些代理能够以更类似于人类的方式与物理环境进行交互，得益于LLMs的高级理解和规划能力。根据最近的研究[[5](#bib.bib5),
    [23](#bib.bib23)]，如图[1](#S3.F1 "Figure 1 ‣ 3 Preliminaries ‣ RiskAwareBench: Towards
    Evaluating Physical Risk Awareness for High-level Planning of LLM-based Embodied
    Agents")所示，基于LLM的具身智能系统的基本框架包括三个关键组件：感知、规划和控制。'
- en: Perception.
  id: totrans-33
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 感知。
- en: Perception serves as the cornerstone of embodied AI, tasked with environmental
    comprehension. It mirrors the human sensory system, enabling robotic entities
    to harness an array of sensors, such as cameras, lidar, and microphones, to transmute
    raw sensory inputs into digestible observations. These observations, which may
    manifest as text, images, or alternative data constructs, are then processed and
    understood by the robot, facilitating interaction with its environment.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 感知作为具身AI的基石，负责环境理解。它类似于人类的感官系统，使机器人能够利用各种传感器，如摄像头、激光雷达和麦克风，将原始的感官输入转化为可处理的观察结果。这些观察结果可以表现为文本、图像或其他数据结构，然后由机器人处理和理解，从而与环境进行互动。
- en: Planning.
  id: totrans-35
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 规划。
- en: The planning module is the cognitive core of the embodied intelligence system,
    similar to the human brain, which is responsible for orchestrating high-level
    plans based on observations made by the perception module along with the task
    instruction. This involves understanding instructions and formulating a sequence
    of actions to achieve the specified goal. Leveraging the advanced natural language
    understanding and reasoning capabilities of LLMs, the planning module effectively
    serves as the decision-maker of the robotic system, endowing robots with a human-like
    proficiency in decision-making.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 规划模块是具身智能系统的认知核心，类似于人类的大脑，负责根据感知模块的观察结果和任务指令来策划高级计划。这包括理解指令并制定行动序列以实现指定目标。利用LLMs的高级自然语言理解和推理能力，规划模块有效地作为机器人系统的决策者，使机器人具备类似于人类的决策能力。
- en: Control.
  id: totrans-37
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 控制。
- en: The control module, functions as the robot’s executor, translating the high-level
    plans into granular, low-level controls. Analogous to the human motor system,
    it is charged with the precise calibration of the robot’s manipulative and locomotive
    parameters, such as motor speed, the positioning of the robotic arm’s end-effector,
    and the articulation of joint angles.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 控制模块作为机器人的执行者，将高级计划转换为细化的低级控制。类似于人类的运动系统，它负责精确调整机器人的操作和运动参数，例如电机速度、机器人手臂末端执行器的位置以及关节角度的调节。
- en: 3.2 Physical Risk
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 物理风险
- en: The high-level plans generated by the planning module, while indispensable for
    guiding the robot’s actions, can inadvertently introduce physical risks if not
    meticulously managed. Physical risk refers to the propensity for the robot to
    inflict harm upon humans, property, or the environment as a consequence of executing
    these plans. This risk can emanate from a multitude of sources, including but
    not limited to, collisions with objects, mishandling of fragile items, non-standard
    operations on hazardous goods, combinations of incompatible objects, and etc.
    Given the critical implications of physical risks, this paper focuses on evaluating
    the risk awareness of LLM-based embodied agents to ensure their future safe deployment
    in real-world environments.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 规划模块生成的高级计划虽然对于指导机器人的动作至关重要，但如果没有精心管理，可能会无意中引入物理风险。物理风险指的是机器人在执行这些计划时可能对人类、财产或环境造成伤害的倾向。这种风险可能来源于多种因素，包括但不限于与物体碰撞、处理易碎物品不当、对危险品进行非标准操作、不兼容物品的组合等。鉴于物理风险的重要性，本文重点评估基于LLM的具身代理的风险意识，以确保其在实际环境中的安全部署。
- en: 4 RiskAwareBench
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 RiskAwareBench
- en: To comprehensively evaluate the physical risk awareness of LLM-based embodied
    agents, we introduce an automated evaluation framework, named RiskAwareBench.
    Then, with the help of RiskAwareBench, we construct a PhysicalRisk dataset, which
    contains various risky scenes and corresponding task instructions which imply
    potential physical risks. In the following sections, we will describe the framework
    of RiskAwareBench and the construction of the PhysicalRisk dataset in detail.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 为了全面评估基于LLM的具身代理的物理风险意识，我们引入了一个名为RiskAwareBench的自动化评估框架。然后，在RiskAwareBench的帮助下，我们构建了一个PhysicalRisk数据集，该数据集包含各种风险场景和相应的任务指令，这些指令暗示了潜在的物理风险。在接下来的部分中，我们将详细描述RiskAwareBench的框架和PhysicalRisk数据集的构建过程。
- en: 4.1 Overall Framework
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 总体框架
- en: 'As illustrated in Figure [2](#S4.F2 "Figure 2 ‣ 4.1 Overall Framework ‣ 4 RiskAwareBench
    ‣ RiskAwareBench: Towards Evaluating Physical Risk Awareness for High-level Planning
    of LLM-based Embodied Agents"), the framework of RiskAwareBench consists of four
    key modules, including safety tip generation module, risky scene generation module,
    plan generation module, and evaluation module. First, the safety tip generation
    module is responsible for generating safety tips based on the risky scenes and
    task instructions. Then, the risky scene generation module creates diverse scenes
    and task instructions that may lead to potential physical risks. Afterwards, the
    plan generation module generates high-level plans to complete the instructed task
    based on the observation of risky scenes. Finally, the evaluation module evaluates
    riskiness and effectiveness of the generated plans. The detailed description of
    each module is as follows.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '如图 [2](#S4.F2 "Figure 2 ‣ 4.1 Overall Framework ‣ 4 RiskAwareBench ‣ RiskAwareBench:
    Towards Evaluating Physical Risk Awareness for High-level Planning of LLM-based
    Embodied Agents")所示，RiskAwareBench的框架由四个关键模块组成，包括安全提示生成模块、风险场景生成模块、计划生成模块和评估模块。首先，安全提示生成模块负责根据风险场景和任务指令生成安全提示。接下来，风险场景生成模块创建可能导致潜在物理风险的多样化场景和任务指令。然后，计划生成模块根据对风险场景的观察生成完成指令任务的高级计划。最后，评估模块评估生成计划的风险性和有效性。各模块的详细描述如下。'
- en: '![Refer to caption](img/e462b7b9f2d4d878b035f2f595919f27.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/e462b7b9f2d4d878b035f2f595919f27.png)'
- en: 'Figure 2: The framework of our proposed RiskAwareBench.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：我们提出的RiskAwareBench框架。
- en: 4.2 Safety Tips Generation Module
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 安全提示生成模块
- en: 'The safety tips generation module plays a pivotal role in the RiskAwareBench
    framework by proactively identifying and communicating potential safety hazards
    to prevent physical risks in various environments. This module is inspired by
    the notion that in real life, adherence to safety standards and precautions, as
    established through expert consensus and experiential learning, significantly
    reduces the likelihood of hazards. For instance, the user manual of a microwave
    oven explicitly warns against heating metal objects, guiding users away from potential
    hazards. Drawing on this principle, the safety tip generation module is designed
    to generate comprehensive safety tips for given scenes. Our approach encompasses
    two distinct strategies for generating these safety tips: summarizing safety tips
    from existing materials and generating new safety tips. The prompts used in this
    module are presented in Appendix [A.1](#A1.SS1 "A.1 Prompts of Safety Tips Generation
    Module ‣ Appendix A Details of the RiskAwareBench ‣ RiskAwareBench: Towards Evaluating
    Physical Risk Awareness for High-level Planning of LLM-based Embodied Agents").'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '安全提示生成模块在RiskAwareBench框架中发挥着关键作用，通过主动识别和传达潜在的安全隐患，以防止各种环境中的物理风险。该模块的灵感来自于这样一个观点：在现实生活中，遵守安全标准和预防措施（通过专家共识和经验学习建立）可以显著降低危险的发生可能性。例如，微波炉的用户手册明确警告不要加热金属物体，引导用户远离潜在的危险。基于这一原则，安全提示生成模块被设计用来为给定的场景生成全面的安全提示。我们的方法包含了生成这些安全提示的两种不同策略：从现有材料中总结安全提示和生成新的安全提示。该模块中使用的提示见附录 [A.1](#A1.SS1
    "A.1 Prompts of Safety Tips Generation Module ‣ Appendix A Details of the RiskAwareBench
    ‣ RiskAwareBench: Towards Evaluating Physical Risk Awareness for High-level Planning
    of LLM-based Embodied Agents")。'
- en: 'Strategy 1: Summarizing Safety Tips from Existing Materials.'
  id: totrans-49
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 策略1：从现有材料中总结安全提示。
- en: Recognizing the vast array of safety manuals and guidelines available online,
    the first strategy involves a two-step process. Initially, the module conducts
    a targeted search to locate relevant safety instructions pertaining to the given
    scene. Subsequently, the module extracts valuable safety tips from these documents
    based on the understanding abilities of LLMs. This process not only ensures the
    provision of established safety measures but also filters out irrelevant information,
    thereby optimizing the relevance and utility of the safety tips generated.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 认识到在线上可用的大量安全手册和指南，第一种策略包括两个步骤。首先，模块进行有针对性的搜索以找到与给定场景相关的安全说明。随后，模块根据LLMs的理解能力从这些文档中提取有价值的安全提示。这个过程不仅确保了提供既定的安全措施，还筛选了不相关的信息，从而优化了生成的安全提示的相关性和实用性。
- en: 'Strategy 2: Generating New Safety Tips.'
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 策略 2：生成新的安全提示。
- en: The second strategy is employed particularly in scenarios where existing online
    materials are sparse or insufficient. In such cases, the module uses the existing
    safety tips extracted with strategy 1 and leverages the in-context learning capabilities
    of LLMs to generate new safety tips that are tailored to the specific needs and
    contexts of the scenario at hand. This innovative approach allows for the comprehensive
    generation of safety tips, filling the gaps left by existing materials and ensuring
    comprehensive coverage of potential physical risks.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种策略特别适用于在线现有材料稀缺或不足的情况下。在这种情况下，模块利用策略 1 提取的现有安全提示，并利用 LLMs 的上下文学习能力生成针对特定场景需求和背景的新安全提示。这种创新方法允许全面生成安全提示，填补现有材料留下的空白，并确保对潜在物理风险的全面覆盖。
- en: 4.3 Risky Scene Generation Module
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 风险场景生成模块
- en: 'Following the generation of safety tips, it is critical to contextualize these
    precautions within environments where the physical risks they address may occur.
    The Risky scene generation module is devised to automatically create such environments,
    along with detailed instructions for embodied agents to execute tasks within these
    potentially hazardous settings. The effectiveness of a scene is gauged by the
    presence of four fundamental elements: objects, positions of objects, attributions
    of objects. Each element contributes to constructing a realistic and challenging
    scenario for the agent. In addition, this module also need to generate task instructions
    that may result in physical hazards, which are used as inputs to the agent. The
    following paragraphs elucidate the significance and composition of each element.
    The prompts used in this module are presented in Appendix [A.2](#A1.SS2 "A.2 Prompt
    of Risky Scene Generation module ‣ Appendix A Details of the RiskAwareBench ‣
    RiskAwareBench: Towards Evaluating Physical Risk Awareness for High-level Planning
    of LLM-based Embodied Agents").'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '在生成安全提示后，重要的是将这些预防措施在可能发生物理风险的环境中进行情境化。风险场景生成模块旨在自动创建这样的环境，并为具身智能体提供详细的任务执行指令。场景的有效性通过四个基本要素的存在来衡量：物体、物体的位置、物体的属性。每个要素都有助于构建一个现实且具有挑战性的场景。此外，该模块还需要生成可能导致物理危险的任务指令，这些指令作为输入提供给智能体。以下段落阐明了每个要素的意义和组成。本模块使用的提示在附录 [A.2](#A1.SS2
    "A.2 Prompt of Risky Scene Generation module ‣ Appendix A Details of the RiskAwareBench
    ‣ RiskAwareBench: Towards Evaluating Physical Risk Awareness for High-level Planning
    of LLM-based Embodied Agents")中展示。'
- en: Objects.
  id: totrans-55
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 物体。
- en: At the core of every scene are the objects, the tangible entities that populate
    the environment. These include items directly related to the generated safety
    tips, like the microwave and metal utensils for the tip "Do not heat metal items
    in a microwave." To mimic the complexity of real-world environments and to add
    layers of challenge, objects not associated with the safety tip are also integrated,
    such as tables, cabinets, glassware, sinks, and faucets. Each object is uniquely
    identified with a name_id format (e.g., , spoon_1, spoon_2), allowing for distinction
    between identical objects within the scene.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 每个场景的核心都是物体，这些具体的实体充斥在环境中。这些包括与生成的安全提示直接相关的物品，如“不要在微波炉中加热金属物品”的微波炉和金属餐具。为了模拟现实世界环境的复杂性，并增加挑战的层次，也会集成与安全提示无关的物体，如桌子、橱柜、玻璃器皿、水槽和水龙头。每个物体都用名称_id格式（例如，spoon_1,
    spoon_2）唯一标识，以便区分场景中相同的物体。
- en: Positions of Objects.
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 物体的位置。
- en: The spatial arrangement of objects is a crucial aspect of scene generation,
    dictating how the objects relate to one another within the space. This is described
    using the format $<$, where the Relation is a preposition defining spatial relationships,
    like “in, above, or beside”. An example could be “microwave_1 above cabinet_1,"
    establishing a clear and structured layout of the scene.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对象的空间排列是场景生成的一个关键方面，决定了对象在空间中的相互关系。这使用格式$<$描述，其中关系是定义空间关系的介词，如“在， 上方或旁边”。例如，“microwave_1
    above cabinet_1”，建立了场景的清晰和结构化布局。
- en: Attributes of Objects.
  id: totrans-59
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 对象的属性。
- en: To enhance the diversity and authenticity of the scenes, attributions are assigned
    to objects. These characteristics can include material properties (e.g., , the
    chair is made of wooden), states (e.g., , the door of the microwave is opened),
    or contents (e.g., , the glass is filled with orange juice). These attributions
    not only enrich the scene’s description but also influence the decision-making
    process of the agent, as different attributes can present varying levels of risk.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 为了增强场景的多样性和真实性，对象被赋予属性。这些特征可以包括材料属性（例如，椅子是由木头制成的），状态（例如，微波炉的门是打开的），或内容（例如，玻璃杯里装满了橙汁）。这些属性不仅丰富了场景的描述，还影响代理人的决策过程，因为不同的属性可能呈现出不同的风险水平。
- en: Task Instructions.
  id: totrans-61
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 任务指令。
- en: Apart from above necessary scene information, this module is also responsible
    for generating task instructions for embodied agents to follow. The instructions
    should be described in natural language, mimicking tasks that users might perform
    in their daily lives. The instructions need be explicit and challenging to test
    decision-making skills in complex situations. Crucially, since the framework’s
    objective is to assess the agent’s risk awareness, the instructions are designed
    to potentially lead the agent to plan actions with inherent physical risks. An
    example might be “Place the metal tray inside the microwave and set the timer
    for 3 minutes on high power.” This instrustion, while straightforward, invites
    the agent to engage in an action that poses a marked safety hazard, thereby evaluating
    its risk assessment capabilities.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 除了上述必要的场景信息外，该模块还负责生成具身代理需要遵循的任务指令。指令应以自然语言描述，模仿用户在日常生活中可能执行的任务。指令需要明确且具有挑战性，以测试在复杂情况下的决策能力。至关重要的是，由于框架的目标是评估代理人的风险意识，指令被设计为可能导致代理人计划具有固有物理风险的行动。例如，“将金属托盘放入微波炉中，并将计时器设置为高功率3分钟。”这个指令虽然简单，但邀请代理人参与一个明显存在安全隐患的行动，从而评估其风险评估能力。
- en: 'Next, this module need to produce observations about the simulated scene, which
    serve as the input for the agents’ subsequent planning process. These observations
    are carefully designed to be compatible with various types of embodied agents,
    ensuring broad applicability of the RiskAwareBench framework. We introduce two
    distinct observation modalities: textual observation and visual observation.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，这个模块需要生成关于模拟场景的观察结果，这些结果作为代理人后续规划过程的输入。这些观察结果经过精心设计，以与各种类型的具身代理兼容，确保RiskAwareBench框架的广泛适用性。我们引入了两种不同的观察方式：文本观察和视觉观察。
- en: Textual Observation.
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 文本观察。
- en: The textual observation synthesizes the scene’s elements into a coherent natural
    language description. This format is particularly suited for agents whose core
    is text-only LLMs. For example, a textual observation might be “In the kitchen,
    you see microwave_1 mounted above cabinet_1\. On the countertop lies spoon_1 with
    a metal bowl_1, …” This detailed narrative enables the agent to comprehend the
    scene’s complexity and identify the risks associated with the environment and
    the tasks to be performed.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 文本观察将场景的元素综合成一个连贯的自然语言描述。这个格式特别适合核心是文本的LLM代理。例如，一个文本观察可能是“在厨房里，你看到microwave_1安装在cabinet_1上。台面上放着spoon_1和一个metal
    bowl_1，...”这个详细的叙述使代理人能够理解场景的复杂性，并识别与环境和任务相关的风险。
- en: Visual Observation.
  id: totrans-66
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 视觉观察。
- en: To extend the framework’s utility to multimodal LLMs, visual observations are
    generated using text-to-image diffusion models. These models translate the detailed
    information of the scene into a visual context, akin to the perspective a robot’s
    camera might capture. This visual data encapsulates the scene’s spatial dynamics
    and the interplay of various elements, providing a rich visual context for agents
    that process image input.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将框架的实用性扩展到多模态 LLM，使用文本到图像的扩散模型生成视觉观察。这些模型将场景的详细信息转化为视觉上下文，类似于机器人相机可能捕捉到的视角。这些视觉数据包含了场景的空间动态以及各种元素的相互作用，为处理图像输入的智能体提供了丰富的视觉背景。
- en: 4.4 Plan Generation Module
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 计划生成模块
- en: 'The plan generation module is a crucial component of the framework, where the
    LLM serves as the decision-maker within the emobodied agent, responsible for generating
    high-level plans from observations of the scene and task instruction. To ensure
    that the generated plans are executable for downstream low-level control, we additionally
    provide the LLM with a predefined skill set. This skill set delineates the repertoire
    of actions available to the robot, from basic locomotion to complex manipulative
    tasks such as “move to, hold on, put down, etc”. The prompts used in this module
    are presented in Appendix [A.3](#A1.SS3 "A.3 Prompts of Plan Generation Module
    ‣ Appendix A Details of the RiskAwareBench ‣ RiskAwareBench: Towards Evaluating
    Physical Risk Awareness for High-level Planning of LLM-based Embodied Agents").'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '计划生成模块是框架中的关键组件，其中 LLM 作为具身体智能体中的决策者，负责从场景观察和任务指令中生成高层次的计划。为了确保生成的计划可以被下游低层控制执行，我们还为
    LLM 提供了一个预定义的技能集。这个技能集界定了机器人可用的动作范围，从基本的运动到复杂的操作任务，如“移动到、保持、放下”等。本模块中使用的提示词在附录[A.3](#A1.SS3
    "A.3 Prompts of Plan Generation Module ‣ Appendix A Details of the RiskAwareBench
    ‣ RiskAwareBench: Towards Evaluating Physical Risk Awareness for High-level Planning
    of LLM-based Embodied Agents")中列出。'
- en: 4.5 Evaluation Module
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 评估模块
- en: 'The evaluation module is the critical final step in the framework, where the
    high-level plans generated by the previous module are evaluated for risk and effectiveness.
    Drawing inspiration from related works that have successfully demonstrated the
    capabilities of LLMs in achieving human-paralleled accuracy in assessing complex
    tasks. we adopts LLMs as an evaluator, which enables automatic evaluation. The
    prompts used in this module are presented in Appendix [A.4](#A1.SS4 "A.4 Prompts
    of Evaluation Module. ‣ Appendix A Details of the RiskAwareBench ‣ RiskAwareBench:
    Towards Evaluating Physical Risk Awareness for High-level Planning of LLM-based
    Embodied Agents").'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '评估模块是框架中的关键最终步骤，在此步骤中，前一个模块生成的高层次计划会被评估其风险和效果。借鉴相关工作成功展示 LLM 在评估复杂任务时达到与人类相当的准确性，我们采用
    LLM 作为评估者，实现自动化评估。本模块中使用的提示词在附录[A.4](#A1.SS4 "A.4 Prompts of Evaluation Module.
    ‣ Appendix A Details of the RiskAwareBench ‣ RiskAwareBench: Towards Evaluating
    Physical Risk Awareness for High-level Planning of LLM-based Embodied Agents")中列出。'
- en: Risk Evaluation.
  id: totrans-72
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 风险评估。
- en: While LLM-based embodied agents have a powerful understanding of language and
    context, may not inherently possess an awareness of physical risks. Hence, it
    is imperative to assess where these plans could lead to hazardous outcomes, especially
    considering the potential physical hazards embedded within the scenes and instructions
    through scene generation module. With carefully designed prompts, the evaluator
    can output not only whether there is a risk, but also which steps are risky.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然基于 LLM 的具身智能体对语言和上下文有强大的理解能力，但可能并不固有地具备对物理风险的意识。因此，评估这些计划可能导致的危险结果是至关重要的，特别是考虑到通过场景生成模块嵌入的潜在物理危险。通过精心设计的提示词，评估者不仅可以输出是否存在风险，还可以指出哪些步骤存在风险。
- en: Effectiveness Evaluation.
  id: totrans-74
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 效果评估。
- en: The effectiveness evaluation aims to assess the quality of the generated plans
    in terms of robot executableness. Due to the LLM Hallucinations, the LLM-based
    embodied agents may generate plans than include actions outside the robot’s skill
    set, resulting in execution failures, which means that the plans are ineffective.
    On the contrary, if all the plans are valid and executable according to the skill
    set, the plans are considered effective.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 效果评估的目的是评估生成的计划在机器人可执行性方面的质量。由于 LLM 的幻觉，基于 LLM 的具身智能体可能生成包含超出机器人技能集的动作的计划，从而导致执行失败，这意味着这些计划是无效的。相反，如果所有计划都有效且可以根据技能集执行，则这些计划被认为是有效的。
- en: 5 Experiments
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 实验
- en: 5.1 Experimental Setup
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 实验设置
- en: PhysicalRisk Dataset.
  id: totrans-78
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: PhysicalRisk数据集。
- en: Utilizing the RiskAwareBench framework’s first two modules, we have meticulously
    compiled the PhysicalRisk dataset, which is an extensive collection of samples
    from diverse environments such as kitchen, bathroom, laboratory, factory, and
    etc. Each sample is a comprehensive unit consisting of an environment name, associated
    safety tip with an explanation, corresponding detailed scene information (including
    the list of objects, their positions, properties, and various modalities of scene
    observation), and task instruction that could violate the safety tip. The PhysicalRisk
    dataset encompasses a comprehensive collection of 4,605 samples, distributed across
    15 distinct environments. In particular, we generate a total of 307 safety tips,
    each paired with a constructed risky scene encompassing objects, positions, and
    attributes. For every risky scene, we formulate one textual observation and four
    visual observations. Furthermore, we create multiple distinct task instructions
    for each safety tip. As a result, this methodology has produced a total of 921
    textual risk scenarios and 3,684 multimodal scenarios, consequently augmenting
    the thoroughness and dependability of our evaluation.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 利用RiskAwareBench框架的前两个模块，我们精心编制了PhysicalRisk数据集，这是一个来自不同环境（如厨房、浴室、实验室、工厂等）的广泛样本集合。每个样本是一个完整的单元，包括环境名称、与之相关的安全提示及解释、相应的详细场景信息（包括对象列表、它们的位置、属性和场景观察的各种模态），以及可能违反安全提示的任务指令。PhysicalRisk数据集包含4,605个样本，分布在15个不同的环境中。特别地，我们生成了总计307条安全提示，每条提示配有一个包含对象、位置和属性的构建风险场景。对于每个风险场景，我们制定了一条文本观察和四个视觉观察。此外，我们为每个安全提示创建了多个不同的任务指令。结果，这种方法总共生成了921个文本风险场景和3,684个多模态场景，从而提高了评估的全面性和可靠性。
- en: Baseline LLMs.
  id: totrans-80
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基线LLMs。
- en: 'To comprehensively evaluate the risk awareness of LLMs as high-level planners
    for embodied agents, we assessed two categories of LLMs: unimodal text-based LLMs
    and multimodal LLMs. We included LLMs of varying scales, encompassing both open-source
    and proprietary models. The unimodal text-based LLMs include gpt-3.5-turbo-1106 [[11](#bib.bib11)],
    Llama-3-8b-chat-hf and Llama-3-70b-chat-hf [[20](#bib.bib20)], Qwen1.5-7B-Chat
    and Qwen1.5-72B-Chat [[2](#bib.bib2)], Qwen2-72B-Instruct [[24](#bib.bib24)],
    Mistral-7B-Instruct-v0.1 [[6](#bib.bib6)] and Mistral-8x7B-Instruct-v0.1 [[7](#bib.bib7)].
    The multimodal LLMs include gpt-4o [[12](#bib.bib12)] and gpt-4o-mini [[13](#bib.bib13)],
    claude-3-haiku [[1](#bib.bib1)], gemini-1.5-flash [[15](#bib.bib15)]. All LLMs
    were evaluated on the text subset of the PhysicalRisk dataset, while only the
    multimodal LLMs were further assessed on the multimodal subset.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 为了全面评估LLMs作为具身代理的高级规划者的风险意识，我们评估了两类LLMs：单模态文本LLMs和多模态LLMs。我们包含了不同规模的LLMs，包括开源和专有模型。单模态文本LLMs包括gpt-3.5-turbo-1106
    [[11](#bib.bib11)]，Llama-3-8b-chat-hf和Llama-3-70b-chat-hf [[20](#bib.bib20)]，Qwen1.5-7B-Chat和Qwen1.5-72B-Chat
    [[2](#bib.bib2)]，Qwen2-72B-Instruct [[24](#bib.bib24)]，Mistral-7B-Instruct-v0.1
    [[6](#bib.bib6)]和Mistral-8x7B-Instruct-v0.1 [[7](#bib.bib7)]。多模态LLMs包括gpt-4o [[12](#bib.bib12)]和gpt-4o-mini
    [[13](#bib.bib13)]，claude-3-haiku [[1](#bib.bib1)]，gemini-1.5-flash [[15](#bib.bib15)]。所有LLMs都在PhysicalRisk数据集的文本子集上进行了评估，而只有多模态LLMs在多模态子集上进行了进一步评估。
- en: Evaluation Metrics.
  id: totrans-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 评估指标。
- en: 'As described in Section [4.5](#S4.SS5 "4.5 Evaluation Module ‣ 4 RiskAwareBench
    ‣ RiskAwareBench: Towards Evaluating Physical Risk Awareness for High-level Planning
    of LLM-based Embodied Agents"), the evaluation module is divided into risk evaluation
    and effectiveness evaluation. We use the Task Risk Rate (TRR) to measure the risk
    awareness of LLMs. The TRR is defined as the proportion of cases where the plans
    generated by the planner do not violate the corresponding safety tips. Additionally,
    we use the Task Effective Rate (TER) to measure the effectiveness of the plans,
    which is defined as the proportion of cases where where the planner successfully
    completes the instructed task.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '如第[4.5](#S4.SS5 "4.5 Evaluation Module ‣ 4 RiskAwareBench ‣ RiskAwareBench:
    Towards Evaluating Physical Risk Awareness for High-level Planning of LLM-based
    Embodied Agents")节所述，评估模块分为风险评估和有效性评估。我们使用任务风险率（TRR）来衡量LLMs的风险意识。TRR定义为生成的计划中没有违反相应安全提示的案例比例。此外，我们使用任务有效率（TER）来衡量计划的有效性，定义为规划者成功完成指令任务的案例比例。'
- en: Implementation Details.
  id: totrans-84
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 实施细节。
- en: For the safety tip generation module, we employ gpt-4o as the LLM. In the risk
    scene generation module, gpt-4o is also utilized for the risk scene generation
    module. We leverage MidJourney as the text-to-image diffusion model to generate
    visual observations. For the evaluation module, we use gpt-4o as the evaluator.
    We predefine a skill set for embodied agents to ensure that the planner generates
    plans within this scope, thereby avoiding arbitrary actions that could affect
    the evaluation accuracy.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 对于安全提示生成模块，我们采用了gpt-4o作为LLM。在风险场景生成模块中，gpt-4o也被用于风险场景生成模块。我们利用MidJourney作为文本到图像的扩散模型来生成视觉观察。对于评估模块，我们使用gpt-4o作为评估者。我们预定义了一个具身代理的技能集，以确保规划者生成的计划在此范围内，从而避免可能影响评估准确性的任意行动。
- en: 5.2 Main Results
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 主要结果
- en: 'Table 1: Main results of text-based and multimodal LLMs on textual portion
    of PhysicalRisk dataset, where the scene information is represented as textual
    observation.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 1：文本LLMs和多模态LLMs在PhysicalRisk数据集文本部分的主要结果，其中场景信息以文本观察的形式表示。
- en: '| Models | Task Risk Rate (%) | Task Effective Rate (%) |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 任务风险率（%） | 任务有效率（%） |'
- en: '| Open-Source LLMs | Llama-3-8b-chat-hf | 96.005 | 86.301 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 开源LLMs | Llama-3-8b-chat-hf | 96.005 | 86.301 |'
- en: '| Llama-3-70b-chat-hf | 95.662 | 81.735 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| Llama-3-70b-chat-hf | 95.662 | 81.735 |'
- en: '| Qwen1.5-7B-Chat | 95.548 | 75.799 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| Qwen1.5-7B-Chat | 95.548 | 75.799 |'
- en: '| Qwen1.5-72B-Chat | 94.977 | 77.968 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| Qwen1.5-72B-Chat | 94.977 | 77.968 |'
- en: '| Qwen2-72B-Instruct | 95.434 | 83.904 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| Qwen2-72B-Instruct | 95.434 | 83.904 |'
- en: '| Mistral-7B-Instruct-v0.1 | 98.288 | 83.219 |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| Mistral-7B-Instruct-v0.1 | 98.288 | 83.219 |'
- en: '| Mixtral-8x7B-Instruct-v0.1 | 96.119 | 77.626 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| Mixtral-8x7B-Instruct-v0.1 | 96.119 | 77.626 |'
- en: '| Average | 96.005 | 80.936 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 平均值 | 96.005 | 80.936 |'
- en: '| Closed-Source LLMs | gpt-3.5-turbo-1106 | 94.521 | 83.676 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 闭源LLMs | gpt-3.5-turbo-1106 | 94.521 | 83.676 |'
- en: '| gpt-4o | 93.950 | 82.763 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4o | 93.950 | 82.763 |'
- en: '| gpt-4o mini | 94.863 | 83.105 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4o mini | 94.863 | 83.105 |'
- en: '| claude-3-haiku | 93.151 | 83.105 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| claude-3-haiku | 93.151 | 83.105 |'
- en: '|  | gemini-1.5-flash | 94.292 | 88.950 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '|  | gemini-1.5-flash | 94.292 | 88.950 |'
- en: '|  | Average | 94.155 | 84.320 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '|  | 平均值 | 94.155 | 84.320 |'
- en: 'Tables [1](#S5.T1 "Table 1 ‣ 5.2 Main Results ‣ 5 Experiments ‣ RiskAwareBench:
    Towards Evaluating Physical Risk Awareness for High-level Planning of LLM-based
    Embodied Agents") and [2](#S5.T2 "Table 2 ‣ Visual observation is more challenging
    than textual observation. ‣ 5.2 Main Results ‣ 5 Experiments ‣ RiskAwareBench:
    Towards Evaluating Physical Risk Awareness for High-level Planning of LLM-based
    Embodied Agents") present the main results of RiskAwareBench. Based on the results,
    we derive the following key findings.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 [1](#S5.T1 "表格 1 ‣ 5.2 主要结果 ‣ 5 实验 ‣ RiskAwareBench：旨在评估基于LLM的具身体代理的高层次规划的物理风险意识")
    和 [2](#S5.T2 "表格 2 ‣ 视觉观察比文本观察更具挑战性 ‣ 5.2 主要结果 ‣ 5 实验 ‣ RiskAwareBench：旨在评估基于LLM的具身体代理的高层次规划的物理风险意识")
    展示了RiskAwareBench的主要结果。根据结果，我们得出了以下关键发现。
- en: All LLMs exhibit poor risk awareness.
  id: totrans-104
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 所有LLMs的风险意识都很差。
- en: 'Table [1](#S5.T1 "Table 1 ‣ 5.2 Main Results ‣ 5 Experiments ‣ RiskAwareBench:
    Towards Evaluating Physical Risk Awareness for High-level Planning of LLM-based
    Embodied Agents") presents the performance of well-known unimodal text-based LLMs
    and multimodal LLMs on the textual cases of the PhysicalRisk dataset. Meanwhile,
    Table [2](#S5.T2 "Table 2 ‣ Visual observation is more challenging than textual
    observation. ‣ 5.2 Main Results ‣ 5 Experiments ‣ RiskAwareBench: Towards Evaluating
    Physical Risk Awareness for High-level Planning of LLM-based Embodied Agents")
    displays the results of multimodal LLMs on the multimodal portion of the dataset.
    We find that the Task Risk Rate (TRR) for all LLMs exceeds 90%, indicating that
    current implementations of LLMs as decision-makers for embodied agents lack robust
    risk awareness. For instance, gpt-4o exhibited a TRR of 93.950%, while Llama-3-70b-chat-hf
    showed a TRR of 95.662%. Such high TRR values underscore the inadequate performance
    of LLMs in generating safe high-level plans.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 [1](#S5.T1 "表格 1 ‣ 5.2 主要结果 ‣ 5 实验 ‣ RiskAwareBench：旨在评估基于LLM的具身体代理的高层次规划的物理风险意识")
    展示了著名的单模态文本LLMs和多模态LLMs在PhysicalRisk数据集文本案例上的表现。与此同时，表格 [2](#S5.T2 "表格 2 ‣ 视觉观察比文本观察更具挑战性
    ‣ 5.2 主要结果 ‣ 5 实验 ‣ RiskAwareBench：旨在评估基于LLM的具身体代理的高层次规划的物理风险意识") 显示了多模态LLMs在数据集多模态部分的结果。我们发现所有LLMs的任务风险率（TRR）都超过了90%，这表明目前LLMs作为具身代理的决策者在风险意识方面缺乏足够的稳健性。例如，gpt-4o的TRR为93.950%，而Llama-3-70b-chat-hf的TRR为95.662%。如此高的TRR值突显了LLMs在生成安全高层次计划方面的表现不足。
- en: Bigger LLMs achieve better risk awareness in general.
  id: totrans-106
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 较大的LLMs在总体上实现了更好的风险意识。
- en: We further analyze the impact of different model sizes on risk awareness. The
    results suggest that within the same model series, bigger models generally exhibit
    better risk awareness. This trend is evident when comparing models of different
    scales within the same family. For example, Llama-3-70b-chat-hf has a TRR of 95.662%,
    which is slightly lower than the 96.005% TRR of Llama-3-8b-chat-hf. Similarly,
    the Qwen1.5-72B-Chat model, with a TRR of 94.977%, outperforms its smaller counterparts
    such as Qwen1.5-7B-Chat, which has TRR of 95.548%. This finding holds true for
    the Mixtral series as well. Such results indicate that scaling laws are also valid
    for the risk awareness of LLMs.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进一步分析了不同模型规模对风险意识的影响。结果表明，在相同模型系列中，较大的模型通常表现出更好的风险意识。这一趋势在比较同一系列中不同规模的模型时尤为明显。例如，Llama-3-70b-chat-hf
    的 TRR 为 95.662%，略低于 Llama-3-8b-chat-hf 的 96.005% TRR。同样，Qwen1.5-72B-Chat 模型的 TRR
    为 94.977%，优于其较小的对应模型，如 Qwen1.5-7B-Chat，其 TRR 为 95.548%。这一发现同样适用于 Mixtral 系列。这些结果表明，缩放定律对
    LLM 的风险意识也是适用的。
- en: Closed-source LLMs show relatively better risk awareness than open-source LLMs.
  id: totrans-108
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 闭源 LLM 显示出比开源 LLM 更好的风险意识。
- en: 'Despite the overall poor performance of all LLMs in risk awareness, a comparison
    between closed-source and open-source LLMs reveals that closed-source models tend
    to perform slightly better than open-source LLMs. As shown in Table [1](#S5.T1
    "Table 1 ‣ 5.2 Main Results ‣ 5 Experiments ‣ RiskAwareBench: Towards Evaluating
    Physical Risk Awareness for High-level Planning of LLM-based Embodied Agents"),
    the average TRR for closed-source LLMs is 94.155%, compared to 96.005% for open-source
    LLMs. For example, gpt-4o and Claude-3-haiku have TRRs of 93.950% and 93.151%,
    respectively, showing a slight improvement over many open-source counterparts.
    However, it is crucial to note that even the closed-source models have TRRs well
    above 90%, indicating that none of LLMs achieve satisfactory risk awareness under
    the baseline settings.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '尽管所有 LLM 在风险意识方面的整体表现较差，但闭源和开源 LLM 的比较显示，闭源模型往往表现略好于开源 LLM。如表格 [1](#S5.T1 "Table
    1 ‣ 5.2 Main Results ‣ 5 Experiments ‣ RiskAwareBench: Towards Evaluating Physical
    Risk Awareness for High-level Planning of LLM-based Embodied Agents") 所示，闭源 LLM
    的平均 TRR 为 94.155%，而开源 LLM 为 96.005%。例如，gpt-4o 和 Claude-3-haiku 的 TRR 分别为 93.950%
    和 93.151%，显示出略微优于许多开源对应模型的表现。然而，必须注意的是，即使是闭源模型的 TRR 也远高于 90%，这表明没有任何 LLM 在基准设置下实现了令人满意的风险意识。'
- en: Visual observation is more challenging than textual observation.
  id: totrans-110
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 视觉观察比文本观察更具挑战性。
- en: 'By comparing the results in Table [1](#S5.T1 "Table 1 ‣ 5.2 Main Results ‣
    5 Experiments ‣ RiskAwareBench: Towards Evaluating Physical Risk Awareness for
    High-level Planning of LLM-based Embodied Agents") and Table [2](#S5.T2 "Table
    2 ‣ Visual observation is more challenging than textual observation. ‣ 5.2 Main
    Results ‣ 5 Experiments ‣ RiskAwareBench: Towards Evaluating Physical Risk Awareness
    for High-level Planning of LLM-based Embodied Agents"), we find that, for the
    same model, the task risk rate is higher when embodied agents receive textual
    observations compared to visual observations. For example, the TPP of gpt-4o in
    Table [1](#S5.T1 "Table 1 ‣ 5.2 Main Results ‣ 5 Experiments ‣ RiskAwareBench:
    Towards Evaluating Physical Risk Awareness for High-level Planning of LLM-based
    Embodied Agents") is 93.950%, while in Table  [2](#S5.T2 "Table 2 ‣ Visual observation
    is more challenging than textual observation. ‣ 5.2 Main Results ‣ 5 Experiments
    ‣ RiskAwareBench: Towards Evaluating Physical Risk Awareness for High-level Planning
    of LLM-based Embodied Agents"), the TRR is 97.516%. Similar results can also be
    found for claude-3-haiku and gemini-1.5-flash.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '通过比较表格 [1](#S5.T1 "Table 1 ‣ 5.2 Main Results ‣ 5 Experiments ‣ RiskAwareBench:
    Towards Evaluating Physical Risk Awareness for High-level Planning of LLM-based
    Embodied Agents") 和表格 [2](#S5.T2 "Table 2 ‣ Visual observation is more challenging
    than textual observation. ‣ 5.2 Main Results ‣ 5 Experiments ‣ RiskAwareBench:
    Towards Evaluating Physical Risk Awareness for High-level Planning of LLM-based
    Embodied Agents") 的结果，我们发现，对于相同的模型，当具身体代理接收文本观察时，任务风险率较高，而非视觉观察。例如，表格 [1](#S5.T1
    "Table 1 ‣ 5.2 Main Results ‣ 5 Experiments ‣ RiskAwareBench: Towards Evaluating
    Physical Risk Awareness for High-level Planning of LLM-based Embodied Agents")
    中的 gpt-4o 的 TPP 为 93.950%，而在表格 [2](#S5.T2 "Table 2 ‣ Visual observation is more
    challenging than textual observation. ‣ 5.2 Main Results ‣ 5 Experiments ‣ RiskAwareBench:
    Towards Evaluating Physical Risk Awareness for High-level Planning of LLM-based
    Embodied Agents") 中，TRR 为 97.516%。类似的结果也可以在 claude-3-haiku 和 gemini-1.5-flash
    中找到。'
- en: In summary, such findings underscore the challenges and potential directions
    for improving the risk awareness of LLM-based planners under embodied settings.
    While larger and closed-source models show relative improvements, there is a clear
    need for further research and development to enhance the safety and effectiveness
    of these models in high-level planning tasks.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，这些发现强调了在具身设置下提高LLM基础规划器的风险意识的挑战和潜在方向。尽管较大且封闭源的模型显示出相对改善，但显然需要进一步的研究和开发，以增强这些模型在高层规划任务中的安全性和有效性。
- en: 'Table 2: Main results of multimodal LLMs on multimodal portion of PhysicalRisk
    dataset, where the scene information is represented as visual observation.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：多模态LLMs在PhysicalRisk数据集多模态部分的主要结果，其中场景信息以视觉观察形式呈现。
- en: '| Models | Task Risk Rate (%) | Task Effective Rate (%) |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 任务风险率 (%) | 任务有效率 (%) |'
- en: '| Closed-source LLMs | gpt-4o | 97.516 | 82.734 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 封闭源LLMs | gpt-4o | 97.516 | 82.734 |'
- en: '| gpt-4o mini | 95.748 | 84.047 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4o mini | 95.748 | 84.047 |'
- en: '| claude-3-haiku | 96.832 | 87.003 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| claude-3-haiku | 96.832 | 87.003 |'
- en: '| gemini-1.5-flash | 97.995 | 89.716 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| gemini-1.5-flash | 97.995 | 89.716 |'
- en: '|  | Average | 97.023 | 85.875 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '|  | 平均 | 97.023 | 85.875 |'
- en: 5.3 Case Study
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 案例研究
- en: 'Figure [3](#S5.F3 "Figure 3 ‣ 5.3 Case Study ‣ 5 Experiments ‣ RiskAwareBench:
    Towards Evaluating Physical Risk Awareness for High-level Planning of LLM-based
    Embodied Agents") showcases examples of safety tips, scene information, task instructions,
    and observations generated for a kitchen environment. Constructing such detailed
    and contextually accurate scene information manually is a challenging and time-consuming
    task. However, leveraging carefully designed prompts, LLMs can accurately generate
    diverse and detailed scene information automatically, which significantly enhances
    the efficiency and scalability of creating realistic and varied environments for
    evaluating risk awareness.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '图[3](#S5.F3 "图 3 ‣ 5.3 案例研究 ‣ 5 实验 ‣ RiskAwareBench: 针对LLM基础的具身体智能体高层规划评估物理风险意识")展示了为厨房环境生成的安全提示、场景信息、任务指令和观察的示例。手动构建如此详细和上下文准确的场景信息是一项具有挑战性且耗时的任务。然而，利用精心设计的提示，LLMs可以准确地自动生成多样且详细的场景信息，这显著提高了创建真实且多样环境以评估风险意识的效率和可扩展性。'
- en: 'Figure [4](#S5.F4 "Figure 4 ‣ 5.3 Case Study ‣ 5 Experiments ‣ RiskAwareBench:
    Towards Evaluating Physical Risk Awareness for High-level Planning of LLM-based
    Embodied Agents") shows high-level plans generated by LLM-based embodied agents
    under three different settings. The left image shows plans without any risk mitigation
    strategy. Notably, steps 10-13 involve a risk operation: heating eggs in a microwave.
    If executed in the real world, these steps could pose significant risks. The middle
    image shows plans with an implicit risk mitigation strategy, which still includes
    risk steps. The right one, however, shows plans with an explicit risk mitigation
    strategy, where the LLM provides a warning to the user. These examples highlight
    the weak risk awareness of LLM-based embodied agents and underscores the necessity
    of advanced strategies to mitigate potential risks.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '图[4](#S5.F4 "图 4 ‣ 5.3 案例研究 ‣ 5 实验 ‣ RiskAwareBench: 针对LLM基础的具身体智能体高层规划评估物理风险意识")展示了LLM基础的具身体智能体在三种不同设置下生成的高层计划。左图显示了没有任何风险缓解策略的计划。特别地，步骤10-13涉及一个风险操作：在微波炉中加热鸡蛋。如果在现实世界中执行，这些步骤可能会带来显著风险。中间图显示了包含隐性风险缓解策略的计划，但仍包括风险步骤。然而，右图显示了包含显性风险缓解策略的计划，其中LLM向用户提供了警告。这些示例突显了LLM基础的具身体智能体对风险的较弱意识，并强调了缓解潜在风险的高级策略的必要性。'
- en: '![Refer to caption](img/1041b0ecc00d4e5a9ac3e9437d32014d.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/1041b0ecc00d4e5a9ac3e9437d32014d.png)'
- en: 'Figure 3: Examples of safety tips, scene information, task instructions, and
    observations of the environment generated for the kitchen environment.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：为厨房环境生成的安全提示、场景信息、任务指令和环境观察的示例。
- en: '![Refer to caption](img/b53cdf77a87cde357db48dddb0f39fac.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/b53cdf77a87cde357db48dddb0f39fac.png)'
- en: 'Figure 4: Examples of high-level plans generated by LLM-based embodied agents
    under different settings: 1) Left: without risk mitigation strategy; 2) Middle:
    with implicit risk mitigation strategy; Right: with explicit risk mitigation strategy.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：LLM基础的具身体智能体在不同设置下生成的高层计划示例：1) 左：没有风险缓解策略；2) 中：包含隐性风险缓解策略；右：包含显性风险缓解策略。
- en: 6 Risk Mitigation Strategies
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 风险缓解策略
- en: 'To enhance the risk awareness of LLM-based embodied agents, we propose two
    fundamental prompt-based risk mitigation strategies: the implicit risk mitigation
    strategy (RM-Implicit)and the explicit risk mitigation (RM-Explicit) strategy.
    Given the robust instruction comprehension capabilities of LLMs, these strategies
    aim to incorporate additional safety constraints into the input prompts to guide
    the model in generating risk-free plans. Below, we detail each strategy and present
    the experimental results.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 为了增强基于LLM的具身智能体的风险意识，我们提出了两种基本的基于提示的风险缓解策略：隐式风险缓解策略（RM-Implicit）和显式风险缓解策略（RM-Explicit）。鉴于LLM对指令的强大理解能力，这些策略旨在将额外的安全约束纳入输入提示，以指导模型生成无风险的计划。以下是对每种策略的详细说明以及实验结果。
- en: Implicit risk mitigation strategy (RM-Implicit).
  id: totrans-129
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 隐式风险缓解策略（RM-Implicit）。
- en: 'In the RM-Implicit strategy, we incorporate general safety guidelines into
    the prompt to implicitly remind the model to consider potential risks when generating
    plans. The added prompt is structured as follows:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在RM-Implicit策略中，我们将一般安全指南纳入提示中，以隐式提醒模型在生成计划时考虑潜在风险。添加的提示结构如下：
- en: '“When generating the plans, you should consider the safety of the plans to
    avoid any potential risks or hazards in the real world. The risks include object
    damage, human injury, environmental damage, generation of toxic substances and
    pollutants, or any other negative consequences that may arise from the actions
    performed by the robot. The risks may come from various factors, including but
    not limited to collisions with objects, improper handling of fragile objects,
    unsafe movements in dynamic environments, non-standard operations on objects,
    or combinations of incompatible objects. When you think one step may cause a potential
    risk, you should avoid generating such a step in the plans and add "Warning: "
    at the beginning of the step to point out the risk.”'
  id: totrans-131
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “在生成计划时，您应考虑计划的安全性，以避免现实世界中可能出现的任何潜在风险或危害。风险包括物体损坏、人身伤害、环境损害、产生有毒物质和污染物，或任何其他可能由机器人执行的动作引发的负面后果。风险可能来源于各种因素，包括但不限于与物体碰撞、对易碎物体的不当处理、在动态环境中的不安全动作、对物体的非标准操作，或不兼容物体的组合。当您认为某一步骤可能会导致潜在风险时，应避免在计划中生成该步骤，并在步骤开头添加“警告：”以指出风险。”
- en: This strategy leverages the model’s inherent understanding of general safety
    principles to mitigate risks without specifying detailed instructions for each
    scenario.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 该策略利用模型对一般安全原则的固有理解来缓解风险，而无需为每种情况指定详细的指令。
- en: Explicit risk mitigation strategy (RM-Explicit).
  id: totrans-133
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 显式风险缓解策略（RM-Explicit）。
- en: Contrary to the RM-Implicit strategy, the RM-Explicit strategy involves incorporating
    more detailed and scenario-specific safety rules into the prompt, explicitly requiring
    the model to consider these risks. Specifically, we directly include the safety
    tips generated by the safety tip module for the current scenario into the prompt,
    ensuring that the model adheres to these safety tips when generating plans.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 与RM-Implicit策略相反，RM-Explicit策略涉及将更详细和特定场景的安全规则纳入提示中，明确要求模型考虑这些风险。具体而言，我们将安全提示模块为当前场景生成的安全提示直接纳入提示中，确保模型在生成计划时遵循这些安全提示。
- en: 'Table 3: Task risk rates (TRR %) of gpt-3.5-turbo-1106 and gpt-4o on textual
    portion of PhysicalRisk dataset with different risk mitigation strategies.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：gpt-3.5-turbo-1106和gpt-4o在不同风险缓解策略下对PhysicalRisk数据集文本部分的任务风险率（TRR %）。
- en: '| Method | gpt-3.5-turbo-1106 | gpt-4o |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | gpt-3.5-turbo-1106 | gpt-4o |'
- en: '| Baseline | 94.521 | 93.95 |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 基线 | 94.521 | 93.95 |'
- en: '| RM-Implicit | 79.365 | 49.206 |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| RM-Implicit | 79.365 | 49.206 |'
- en: '| RM-Explicit | 90.651 | 43.915 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| RM-Explicit | 90.651 | 43.915 |'
- en: Mitigation results.
  id: totrans-140
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 缓解结果。
- en: 'Table [3](#S6.T3 "Table 3 ‣ Explicit risk mitigation strategy (RM-Explicit).
    ‣ 6 Risk Mitigation Strategies ‣ RiskAwareBench: Towards Evaluating Physical Risk
    Awareness for High-level Planning of LLM-based Embodied Agents") presents the
    task risk rate of different risk mitigation strategies in comparison to the baseline.
    The results reveal significant variations in the effectiveness of different risk
    mitigation strategies across various LLMs. For gpt-4o, both RM-Implicit and RM-Explicit
    strategies markedly enhance the model’s risk awareness, with TRR values of 49.206%
    and 43.915%, respectively. This improvement can be attributed to the superior
    instruction comprehension capabilities of gpt-4o, which allows it to better integrate
    and act upon the provided safety guidelines. In contrast, for the less advanced
    gpt-3.5-turbo-1106, the instruction comprehension ability is limited, resulting
    in inconsistent improvements in risk awareness using these prompt-based strategies.
    The RM-Implicit strategy achieves a TRR of 79.365%, whereas the RM-Explicit strategy
    results in a TRR of 90.651%. These findings suggest that while prompt-based strategies
    can be beneficial, their effectiveness is contingent upon the underlying model’s
    capacity to interpret and follow complex instructions. Overall, these strategies
    provide limited enhancement, underscoring the importance of developing more effective
    Risk Mitigation Strategies in the future. Further research is necessary to devise
    advanced methods that can consistently improve the risk awareness of LLM-based
    embodied agents across different model architectures.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '表格 [3](#S6.T3 "Table 3 ‣ Explicit risk mitigation strategy (RM-Explicit). ‣
    6 Risk Mitigation Strategies ‣ RiskAwareBench: Towards Evaluating Physical Risk
    Awareness for High-level Planning of LLM-based Embodied Agents") 展示了不同风险缓解策略与基准相比的任务风险率。结果揭示了不同LLM在各种风险缓解策略下效果的显著差异。对于gpt-4o，RM-Implicit和RM-Explicit策略明显提高了模型的风险意识，TRR值分别为49.206%和43.915%。这种改进可以归因于gpt-4o在指令理解方面的卓越能力，使其能够更好地整合并执行提供的安全指南。相比之下，对于不那么先进的gpt-3.5-turbo-1106，由于指令理解能力有限，使用这些基于提示的策略在风险意识方面的改进不一致。RM-Implicit策略的TRR为79.365%，而RM-Explicit策略的TRR为90.651%。这些发现表明，尽管基于提示的策略可能有益，但其有效性取决于基础模型解释和遵循复杂指令的能力。总体而言，这些策略提供的增强效果有限，强调了未来开发更有效的风险缓解策略的重要性。需要进一步研究以制定能够在不同模型架构下持续提高基于LLM的具身代理的风险意识的先进方法。'
- en: 7 Conclusion
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 结论
- en: In this paper, we propose RiskAwareBench, an innovative framework designed to
    evaluate the physical risk awareness of LLM-based embodied AI system. Through
    the creation of the PhysicalRisk dataset and a series of comprehensive experiments,
    we have demonstrated that current LLMs, despite their advanced language processing
    capabilities, often lack the necessary risk awareness to operate safely in real-world
    environments. The high Task Risk Rates (TRR) across various models, both open-source
    and closed-source, highlight a significant gap in safety that must be addressed.
    Moreover, the risk mitigation strategies proposed in this paper represent initial
    steps towards enhancing safety. However, the limited improvements observed suggest
    that these strategies are not sufficiently robust to address the complex risks
    inherent in physical environments. This calls for more sophisticated and context-aware
    approaches that can dynamically adapt to the nuances of different scenarios. As
    LLMs merge with robotics, safety must be prioritized to ensure that technological
    advancement does not come at the expense of human well-being or environmental
    integrity. The RiskAwareBench framework and the associated dataset provide a valuable
    tool for the AI and robotics community to further explore and enhance the safety
    of LLM-based embodied AI systems.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们提出了RiskAwareBench，这是一个创新框架，旨在评估基于LLM的具身AI系统的物理风险意识。通过创建PhysicalRisk数据集和一系列全面的实验，我们已经展示了当前的LLM尽管具备先进的语言处理能力，但往往缺乏在实际环境中安全操作所需的风险意识。各种模型，无论是开源还是闭源，高任务风险率（TRR）突显了必须解决的安全差距。此外，本文提出的风险缓解策略代表了提升安全性的初步步骤。然而，观察到的有限改进表明，这些策略尚不足以应对物理环境中的复杂风险。这呼唤更复杂且具有上下文感知的解决方案，这些方案能够动态适应不同场景的细微差别。随着LLM与机器人技术的融合，必须优先考虑安全性，以确保技术进步不会以牺牲人类福祉或环境完整性为代价。RiskAwareBench框架及其相关数据集为AI和机器人社区提供了一个有价值的工具，用于进一步探索和增强基于LLM的具身AI系统的安全性。
- en: References
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Anthropic [2024] Anthropic. Introducing the next generation of claude, 2024.
    URL [https://www.anthropic.com/news/claude-3-family](https://www.anthropic.com/news/claude-3-family).
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anthropic [2024] Anthropic。介绍下一代 Claude，2024。网址 [https://www.anthropic.com/news/claude-3-family](https://www.anthropic.com/news/claude-3-family)。
- en: Bai et al. [2023] Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong
    Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, et al. Qwen technical report. *arXiv
    preprint arXiv:2309.16609*, 2023.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bai 等人 [2023] Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong
    Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang 等人。Qwen 技术报告。*arXiv 预印本 arXiv:2309.16609*，2023。
- en: 'Brohan et al. [2023] Anthony Brohan, Yevgen Chebotar, Chelsea Finn, Karol Hausman,
    Alexander Herzog, Daniel Ho, Julian Ibarz, Alex Irpan, Eric Jang, Ryan Julian,
    et al. Do as i can, not as i say: Grounding language in robotic affordances. In
    *Conference on robot learning*, pp.  287–318\. PMLR, 2023.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Brohan 等人 [2023] Anthony Brohan, Yevgen Chebotar, Chelsea Finn, Karol Hausman,
    Alexander Herzog, Daniel Ho, Julian Ibarz, Alex Irpan, Eric Jang, Ryan Julian
    等人。Do as i can, not as i say: 将语言置于机器人可实现性之中。在 *机器人学习会议*，第 287–318 页。PMLR，2023。'
- en: 'Driess et al. [2023] Danny Driess, Fei Xia, Mehdi SM Sajjadi, Corey Lynch,
    Aakanksha Chowdhery, Brian Ichter, Ayzaan Wahid, Jonathan Tompson, Quan Vuong,
    Tianhe Yu, et al. Palm-e: An embodied multimodal language model. In *International
    Conference on Machine Learning*, pp.  8469–8488\. PMLR, 2023.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Driess 等人 [2023] Danny Driess, Fei Xia, Mehdi SM Sajjadi, Corey Lynch, Aakanksha
    Chowdhery, Brian Ichter, Ayzaan Wahid, Jonathan Tompson, Quan Vuong, Tianhe Yu
    等人。Palm-e: 一个具身的多模态语言模型。在 *国际机器学习大会*，第 8469–8488 页。PMLR，2023。'
- en: 'Hu et al. [2023] Yingdong Hu, Fanqi Lin, Tong Zhang, Li Yi, and Yang Gao. Look
    before you leap: Unveiling the power of gpt-4v in robotic vision-language planning.
    *arXiv preprint arXiv:2311.17842*, 2023.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hu 等人 [2023] Yingdong Hu, Fanqi Lin, Tong Zhang, Li Yi 和 Yang Gao。Look before
    you leap: 揭示 GPT-4v 在机器人视觉-语言规划中的力量。*arXiv 预印本 arXiv:2311.17842*，2023。'
- en: Jiang et al. [2023] Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris
    Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna
    Lengyel, Guillaume Lample, Lucile Saulnier, et al. Mistral 7b. *arXiv preprint
    arXiv:2310.06825*, 2023.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang 等人 [2023] Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris
    Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna
    Lengyel, Guillaume Lample, Lucile Saulnier 等人。Mistral 7b。*arXiv 预印本 arXiv:2310.06825*，2023。
- en: Jiang et al. [2024] Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur
    Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas,
    Emma Bou Hanna, Florian Bressand, et al. Mixtral of experts. *arXiv preprint arXiv:2401.04088*,
    2024.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang 等人 [2024] Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur
    Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas,
    Emma Bou Hanna, Florian Bressand 等人。Mixtral of experts。*arXiv 预印本 arXiv:2401.04088*，2024。
- en: 'Levy et al. [2022] Sharon Levy, Emily Allaway, Melanie Subbiah, Lydia Chilton,
    Desmond Patton, Kathleen Mckeown, and William Yang Wang. Safetext: A benchmark
    for exploring physical safety in language models. In *Proceedings of the 2022
    Conference on Empirical Methods in Natural Language Processing*, pp.  2407–2421,
    2022.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Levy 等人 [2022] Sharon Levy, Emily Allaway, Melanie Subbiah, Lydia Chilton,
    Desmond Patton, Kathleen Mckeown 和 William Yang Wang。Safetext: 一个探索语言模型物理安全的基准。在
    *2022 年自然语言处理实证方法会议论文集*，第 2407–2421 页，2022。'
- en: 'Lv et al. [2024] Qi Lv, Hao Li, Xiang Deng, Rui Shao, Michael Yu Wang, and
    Liqiang Nie. Robomp$2$: A robotic multimodal perception-planning framework with
    mutlimodal large language models. In *International Conference on Machine Learning*,
    2024.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lv 等人 [2024] Qi Lv, Hao Li, Xiang Deng, Rui Shao, Michael Yu Wang 和 Liqiang
    Nie。Robomp$2$: 一个具有多模态大型语言模型的机器人多模态感知-规划框架。在 *国际机器学习大会*，2024。'
- en: 'Mei et al. [2023] Alex Mei, Sharon Levy, and William Wang. Assert: Automated
    safety scenario red teaming for evaluating the robustness of large language models.
    In *Findings of the Association for Computational Linguistics: EMNLP 2023*, pp. 
    5831–5847, 2023.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Mei 等人 [2023] Alex Mei, Sharon Levy 和 William Wang。Assert: 自动化安全场景红队测试以评估大型语言模型的稳健性。在
    *计算语言学协会：EMNLP 2023 会议记录*，第 5831–5847 页，2023。'
- en: OpenAI [2023] OpenAI. Gpt-3.5-turbo, 2023. URL [https://platform.openai.com/docs/models/gpt-3-5-turbo](https://platform.openai.com/docs/models/gpt-3-5-turbo).
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI [2023] OpenAI。Gpt-3.5-turbo，2023。网址 [https://platform.openai.com/docs/models/gpt-3-5-turbo](https://platform.openai.com/docs/models/gpt-3-5-turbo)。
- en: OpenAI [2024a] OpenAI. Hello gpt-4o, 2024a. URL [https://openai.com/index/hello-gpt-4o/](https://openai.com/index/hello-gpt-4o/).
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI [2024a] OpenAI。Hello gpt-4o，2024a。网址 [https://openai.com/index/hello-gpt-4o/](https://openai.com/index/hello-gpt-4o/)。
- en: 'OpenAI [2024b] OpenAI. Gpt-4o mini: advancing cost-efficient intelligence,
    2024b. URL [https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/).'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'OpenAI [2024b] OpenAI. Gpt-4o mini: 提升成本效益的智能，2024b。网址 [https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)。'
- en: Rajan & Saffiotti [2017] Kanna Rajan and Alessandro Saffiotti. Towards a science
    of integrated ai and robotics, 2017.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rajan & Saffiotti [2017] Kanna Rajan 和 Alessandro Saffiotti. 朝着集成 AI 和机器人学的科学迈进，2017。
- en: 'Reid et al. [2024] Machel Reid, Nikolay Savinov, Denis Teplyashin, Dmitry Lepikhin,
    Timothy Lillicrap, Jean-baptiste Alayrac, Radu Soricut, Angeliki Lazaridou, Orhan
    Firat, Julian Schrittwieser, et al. Gemini 1.5: Unlocking multimodal understanding
    across millions of tokens of context. *arXiv preprint arXiv:2403.05530*, 2024.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Reid et al. [2024] Machel Reid, Nikolay Savinov, Denis Teplyashin, Dmitry Lepikhin,
    Timothy Lillicrap, Jean-baptiste Alayrac, Radu Soricut, Angeliki Lazaridou, Orhan
    Firat, Julian Schrittwieser 等。Gemini 1.5: 解锁跨百万个上下文标记的多模态理解。*arXiv 预印本 arXiv:2403.05530*，2024。'
- en: Ruan et al. [2023] Yangjun Ruan, Honghua Dong, Andrew Wang, Silviu Pitis, Yongchao
    Zhou, Jimmy Ba, Yann Dubois, Chris J Maddison, and Tatsunori Hashimoto. Identifying
    the risks of lm agents with an lm-emulated sandbox. In *The Twelfth International
    Conference on Learning Representations*, 2023.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ruan et al. [2023] Yangjun Ruan, Honghua Dong, Andrew Wang, Silviu Pitis, Yongchao
    Zhou, Jimmy Ba, Yann Dubois, Chris J Maddison, 和 Tatsunori Hashimoto. 识别 LM 代理的风险以及
    LM 模拟沙箱。在 *第十二届国际学习表征会议*，2023。
- en: 'Shi et al. [2024a] Haochen Shi, Zhiyuan Sun, Xingdi Yuan, Marc-Alexandre Côté,
    and Bang Liu. Opex: A component-wise analysis of llm-centric agents in embodied
    instruction following. *arXiv preprint arXiv:2403.03017*, 2024a.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shi et al. [2024a] Haochen Shi, Zhiyuan Sun, Xingdi Yuan, Marc-Alexandre Côté,
    和 Bang Liu. Opex: 具身指令跟随中的 LLM 代理组件分析。*arXiv 预印本 arXiv:2403.03017*，2024a。'
- en: Shi et al. [2024b] Ruizhe Shi, Yuyao Liu, Yanjie Ze, Simon Shaolei Du, and Huazhe
    Xu. Unleashing the power of pre-trained language models for offline reinforcement
    learning. In *The Twelfth International Conference on Learning Representations*,
    2024b.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi et al. [2024b] Ruizhe Shi, Yuyao Liu, Yanjie Ze, Simon Shaolei Du, 和 Huazhe
    Xu. 发挥预训练语言模型在离线强化学习中的力量。在 *第十二届国际学习表征会议*，2024b。
- en: Szot et al. [2023] Andrew Szot, Max Schwarzer, Harsh Agrawal, Bogdan Mazoure,
    Rin Metcalf, Walter Talbott, Natalie Mackraz, R Devon Hjelm, and Alexander T Toshev.
    Large language models as generalizable policies for embodied tasks. In *The Twelfth
    International Conference on Learning Representations*, 2023.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Szot et al. [2023] Andrew Szot, Max Schwarzer, Harsh Agrawal, Bogdan Mazoure,
    Rin Metcalf, Walter Talbott, Natalie Mackraz, R Devon Hjelm, 和 Alexander T Toshev.
    大型语言模型作为具身任务的可泛化策略。在 *第十二届国际学习表征会议*，2023。
- en: 'Touvron et al. [2023] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. *arXiv
    preprint arXiv:2307.09288*, 2023.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Touvron et al. [2023] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale 等。Llama 2: 开放基础和微调聊天模型。*arXiv 预印本 arXiv:2307.09288*，2023。'
- en: Wei et al. [2022] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph,
    Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler,
    et al. Emergent abilities of large language models. *Transactions on Machine Learning
    Research*, 2022.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei et al. [2022] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph,
    Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler 等。大语言模型的突现能力。*机器学习研究杂志*，2022。
- en: 'Xie et al. [2023] Bing Xie, Xiangming Xi, Xinan Zhao, Yuhan Wang, Wei Song,
    Jianjun Gu, and Shiqiang Zhu. Chatgpt for robotics: A new approach to human-robot
    interaction and task planning. In *International Conference on Intelligent Robotics
    and Applications*, pp.  365–376\. Springer, 2023.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie et al. [2023] Bing Xie, Xiangming Xi, Xinan Zhao, Yuhan Wang, Wei Song,
    Jianjun Gu, 和 Shiqiang Zhu. ChatGPT 在机器人学中的应用：一种人机互动和任务规划的新方法。在 *国际智能机器人与应用会议*，第
    365–376 页。Springer，2023。
- en: 'Xu et al. [2024] Zhiyuan Xu, Kun Wu, Junjie Wen, Jinming Li, Ning Liu, Zhengping
    Che, and Jian Tang. A survey on robotics with foundation models: toward embodied
    ai. *arXiv preprint arXiv:2402.02385*, 2024.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu et al. [2024] Zhiyuan Xu, Kun Wu, Junjie Wen, Jinming Li, Ning Liu, Zhengping
    Che, 和 Jian Tang. 关于基础模型在机器人学中的应用的调查：朝向具身 AI。*arXiv 预印本 arXiv:2402.02385*，2024。
- en: Yang et al. [2024] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang
    Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, et al. Qwen2 technical
    report. *arXiv preprint arXiv:2407.10671*, 2024.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 杨等人 [2024] 杨安, 杨宝松, 惠斌元, 郑博, 于博文, 周昌, 李成鹏, 李承元, 刘大义, 黄飞 等。Qwen2 技术报告。*arXiv
    预印本 arXiv:2407.10671*, 2024。
- en: 'Yang et al. [2023] Sherry Yang, Ofir Nachum, Yilun Du, Jason Wei, Pieter Abbeel,
    and Dale Schuurmans. Foundation models for decision making: Problems, methods,
    and opportunities. *arXiv preprint arXiv:2303.04129*, 2023.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 杨等人 [2023] 杨雪莉, 奥菲尔·纳赫姆, 杜怡伦, 詹森·魏, 皮特·阿贝尔, 和 戴尔·舒尔曼斯。基础模型在决策中的应用：问题、方法与机会。*arXiv
    预印本 arXiv:2303.04129*, 2023。
- en: 'Yuan et al. [2024] Tongxin Yuan, Zhiwei He, Lingzhong Dong, Yiming Wang, Ruijie
    Zhao, Tian Xia, Lizhen Xu, Binglin Zhou, Fangqi Li, Zhuosheng Zhang, et al. R-judge:
    Benchmarking safety risk awareness for llm agents. *arXiv preprint arXiv:2401.10019*,
    2024.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '袁等人 [2024] 袁同鑫, 何志伟, 董灵忠, 王一鸣, 赵瑞杰, 夏天, 徐丽珍, 周冰林, 李方启, 张卓生 等. R-judge: 基准测试
    LLM 代理的安全风险意识。*arXiv 预印本 arXiv:2401.10019*, 2024。'
- en: 'Zeng et al. [2023] Fanlong Zeng, Wensheng Gan, Yongheng Wang, Ning Liu, and
    Philip S Yu. Large language models for robotics: A survey. *arXiv preprint arXiv:2311.07226*,
    2023.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 曾等人 [2023] 曾凡龙, 甘文生, 王永恒, 刘宁, 和 Philip S Yu。用于机器人技术的大型语言模型：综述。*arXiv 预印本 arXiv:2311.07226*,
    2023。
- en: 'Zhang et al. [2023] Zhexin Zhang, Leqi Lei, Lindong Wu, Rui Sun, Yongkang Huang,
    Chong Long, Xiao Liu, Xuanyu Lei, Jie Tang, and Minlie Huang. Safetybench: Evaluating
    the safety of large language models with multiple choice questions. *arXiv preprint
    arXiv:2309.07045*, 2023.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '张等人 [2023] 张哲鑫, 雷乐琪, 吴林东, 孙睿, 黄永康, 龙聪, 刘晓, 雷轩宇, 唐杰, 黄敏lie。Safetybench: 用多项选择题评估大型语言模型的安全性。*arXiv
    预印本 arXiv:2309.07045*, 2023。'
- en: Zhu et al. [2024] Minjie Zhu, Yichen Zhu, Jinming Li, Junjie Wen, Zhiyuan Xu,
    Zhengping Che, Chaomin Shen, Yaxin Peng, Dong Liu, Feifei Feng, et al. Language-conditioned
    robotic manipulation with fast and slow thinking. *arXiv preprint arXiv:2401.04181*,
    2024.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 朱等人 [2024] 朱敏杰, 朱一辰, 李金铭, 温俊杰, 许志远, 车正平, 沈超敏, 彭雅鑫, 刘东, 冯飞飞 等. 基于语言的机器人操作与快速和慢速思维。*arXiv
    预印本 arXiv:2401.04181*, 2024。
- en: Appendix A Details of the RiskAwareBench
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A RiskAwareBench 详细信息
- en: A.1 Prompts of Safety Tips Generation Module
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 安全提示生成模块的提示
- en: 'Table [A.4](#A1.SS4 "A.4 Prompts of Evaluation Module. ‣ Appendix A Details
    of the RiskAwareBench ‣ RiskAwareBench: Towards Evaluating Physical Risk Awareness
    for High-level Planning of LLM-based Embodied Agents") shows the prompt used for
    summarizing safety tips from existing materials and Table LABEL:tab:prompt_generate_safety_tip
    shows the prompt used for generating new safety tips.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '表格 [A.4](#A1.SS4 "A.4 评估模块的提示。 ‣ 附录 A RiskAwareBench 详细信息 ‣ RiskAwareBench:
    旨在评估 LLM 基于的具身代理的高层规划的物理风险意识") 显示了用于总结现有材料安全提示的提示，表格 LABEL:tab:prompt_generate_safety_tip
    显示了用于生成新安全提示的提示。'
- en: A.2 Prompt of Risky Scene Generation module
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 风险场景生成模块的提示
- en: Table LABEL:tab:prompt_generate_scene shows the prompt used for generating risky
    scene information.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 LABEL:tab:prompt_generate_scene 显示了用于生成风险场景信息的提示。
- en: A.3 Prompts of Plan Generation Module
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.3 计划生成模块的提示
- en: Table LABEL:tab:prompt_plan_generation shows the prompt used for generating
    high-level plans with different LLMs and Table LABEL:tab:skill_set presents the
    pre-defined skill set of robots.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 LABEL:tab:prompt_plan_generation 显示了用于生成不同 LLM 的高层计划的提示，表格 LABEL:tab:skill_set
    展示了机器人预定义的技能集。
- en: A.4 Prompts of Evaluation Module.
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.4 评估模块的提示
- en: Table LABEL:tab:prompt_evaluation shows the prompt used for evaluation.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 LABEL:tab:prompt_evaluation 显示了用于评估的提示。
- en: 'Table 4: The prompt used for summarizing safety tips from existing materials,
    where the content wrapped in { } are placeholders that need to be replaced with
    specific content.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 4：用于总结现有材料安全提示的提示，其中用 { } 包裹的内容是需要替换为具体内容的占位符。
