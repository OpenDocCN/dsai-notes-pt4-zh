- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 18:38:47'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:38:47
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Audit-LLM: Multi-Agent Collaboration for Log-based Insider Threat Detection'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Audit-LLM：基于日志的多代理协作内部威胁检测
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2408.08902](https://ar5iv.labs.arxiv.org/html/2408.08902)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2408.08902](https://ar5iv.labs.arxiv.org/html/2408.08902)
- en: Chengyu Song Systems Engineering Institute
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 程序宋系统工程研究所
- en: Academy of Military Sciences Beijing, China
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 军事科学院 北京，中国
- en: songchengyu@alumni.nudt.edu.cn    Linru Ma Systems Engineering Institute
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: songchengyu@alumni.nudt.edu.cn    马林如 系统工程研究所
- en: Academy of Military Sciences Beijing, China
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 军事科学院 北京，中国
- en: malinru@163.com    Jianming Zheng^⋆ State Key Laboratory of
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: malinru@163.com    郑建明^⋆ 国家重点实验室
- en: Mathematical Engineering
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 数学工程
- en: and Advanced Computing Wuxi, China
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 及先进计算 无锡，中国
- en: zhengjianming12@nudt.edu.cn    Jinzhi Liao National University of Defense Technology
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: zhengjianming12@nudt.edu.cn    廖金智 国防科技大学
- en: National Key Laboratory of
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 国家重点实验室
- en: Information Systems Engineering Changsha, China
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 信息系统工程 长沙，中国
- en: liaojinzhi12@nudt.edu.cn    Hongyu Kuang Systems Engineering Institute
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: liaojinzhi12@nudt.edu.cn    邝红宇 系统工程研究所
- en: Academy of Military Sciences Beijing, China
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 军事科学院 北京，中国
- en: khy_y@qq.com    Lin Yang Systems Engineering Institute
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: khy_y@qq.com    杨林 系统工程研究所
- en: Academy of Military Sciences Beijing, China
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 军事科学院 北京，中国
- en: yanglin61s@126.com
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: yanglin61s@126.com
- en: Abstract
  id: totrans-21
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Log-based insider threat detection (ITD) detects malicious user activities
    by auditing log entries. Recently, Large Language Models (LLMs) with strong common
    sense knowledge are emerging in the domain of ITD. Nevertheless, diverse activity
    types and overlong log files pose a significant challenge for LLMs to directly
    discern malicious ones within myriads of normal activities. Furthermore, the faithfulness
    hallucination issue from LLMs aggravates its application difficulty in ITD, as
    the generated conclusion may not align with user commands and activity context.
    In response to these challenges, we introduce Audit-LLM, a multi-agent log-based
    insider threat detection framework comprising three collaborative agents: (i)
    the Decomposer agent, breaking down the complex ITD task into manageable sub-tasks
    using Chain-of-Thought (COT) reasoning; (ii) the Tool Builder agent, creating
    reusable tools for sub-tasks to overcome context length limitations in LLMs; and
    (iii) the Executor agent, generating the final detection conclusion by invoking
    constructed tools. To enhance conclusion accuracy, we propose a pair-wise Evidence-based
    Multi-agent Debate (EMAD) mechanism, where two independent Executors iteratively
    refine their conclusions through reasoning exchange to reach a consensus. Comprehensive
    experiments conducted on three publicly available ITD datasets—CERT r4.2, CERT
    r5.2, and PicoDomain—demonstrate the superiority of our method over existing baselines
    and show that the proposed EMAD significantly improves the faithfulness of explanations
    generated by LLMs. ¹¹1* Corresponding author ²²2^⋆ Equal contribution'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 基于日志的内部威胁检测（ITD）通过审计日志条目来检测恶意用户活动。近期，具备强大常识知识的大型语言模型（LLMs）在ITD领域中逐渐兴起。然而，多样的活动类型和过长的日志文件对LLMs直接辨别恶意活动提出了重大挑战。此外，LLMs的真实性幻觉问题加剧了其在ITD中的应用难度，因为生成的结论可能与用户命令和活动上下文不一致。为应对这些挑战，我们引入了Audit-LLM，这是一种由三个协作代理组成的多代理基于日志的内部威胁检测框架：（i）分解器代理，通过思维链（COT）推理将复杂的ITD任务分解为可管理的子任务；（ii）工具构建器代理，为子任务创建可重用的工具，以克服LLMs的上下文长度限制；（iii）执行器代理，通过调用构建的工具生成最终检测结论。为了提高结论准确性，我们提出了一种对证据进行配对的多代理辩论（EMAD）机制，其中两个独立的执行器通过推理交换迭代地完善其结论以达成共识。在三个公开可用的ITD数据集—CERT
    r4.2、CERT r5.2和PicoDomain—上进行的全面实验表明，我们的方法优于现有基准，并且所提出的EMAD显著提高了LLMs生成解释的真实性。¹¹1*
    通讯作者 ²²2^⋆ 等同贡献
- en: 'Index Terms:'
  id: totrans-23
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 索引词：
- en: Insider threat, Large language models, Chain of Thought, Cybersecurity
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 内部威胁、大型语言模型、思维链、网络安全
- en: I Introduction
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引言
- en: Insider threats are one of the most challenging attack patterns in practice
    as they are usually carried out by authorized users who have legitimate access
    to sensitive and confidential materials (Homoliak et al., [2019](#bib.bib1)).
    To address the task, Insider Threat Detection (ITD) is coined to detect malicious
    activities by insiders, involving monitoring and analyzing logs. These logs contain
    critical records of various user behaviors essential for troubleshooting and security
    analysis.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 内部威胁是实践中最具挑战性的攻击模式之一，因为这些威胁通常由授权用户实施，这些用户合法访问敏感和机密材料（Homoliak 等，[2019](#bib.bib1)）。为应对这一任务，提出了内部威胁检测（ITD），其涉及监控和分析日志，以检测内部的恶意活动。这些日志包含了各种用户行为的关键记录，对于故障排除和安全分析至关重要。
- en: Conventional ITD models (Du et al., [2017](#bib.bib2); Le et al., [2021](#bib.bib3);
    Li et al., [2023](#bib.bib4)) utilize Deep Learning for capturing diverse user
    behavioral characteristics (Yuan and Wu, [2021](#bib.bib5)). However, the inherent
    problems in this line of approaches, i.e., overfitting and opacity, hinder the
    further enhancement of their performance. The emergence of overfitting is caused
    by the scarcity of insider threats in comparison to benign activities, resulting
    in a bias towards benign behavior while neglecting critical malicious activities.
    Opacity limits practical log auditing by delivering results in an opaque format,
    lacking the interpretability necessary for credible and actionable insights in
    security auditing.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的 ITD 模型（Du 等，[2017](#bib.bib2)；Le 等，[2021](#bib.bib3)；Li 等，[2023](#bib.bib4)）利用深度学习捕捉多样的用户行为特征（Yuan
    和 Wu，[2021](#bib.bib5)）。然而，这类方法固有的问题，即过拟合和不透明，阻碍了其性能的进一步提升。过拟合的出现是由于内部威胁相较于良性活动稀缺，导致对良性行为的偏向，同时忽视了关键的恶意活动。不透明性通过以不透明的格式呈现结果，限制了实际日志审计的可操作性，缺乏在安全审计中提供可靠和可操作洞察的必要解释性。
- en: In response, there is a booming trend of applying LLMs in the domain of ITD (Le
    and Zhang, [2023](#bib.bib6); Qi et al., [2023](#bib.bib7); Jin et al., [2024](#bib.bib8)).
    Leveraging LLMs’ extensive commonsense knowledge and capacity for intricate multi-step
    reasoning, existing methods require them to either justify each decision, thereby
    implicitly constructing logical chains of reasoning (Liu et al., [2024](#bib.bib9)),
    manually define intermediate steps for log auditing (Qi et al., [2023](#bib.bib7)),
    or use a few annotated log samples to provide context and guide predictions (Liu
    et al., [2024](#bib.bib9)). These abilities empower them to conduct log auditing
    in a zero-shot manner without the need for training or fine-tuning, thereby fundamentally
    mitigating the risks of overfitting caused by highly imbalanced categories. Additionally,
    auditing results can be delivered in a pre-defined human-readable format, thereby
    avoiding issues of non-interpretable outcomes.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 针对这一问题，LLM 在 ITD 领域的应用趋势迅猛（Le 和 Zhang，[2023](#bib.bib6)；Qi 等，[2023](#bib.bib7)；Jin
    等，[2024](#bib.bib8)）。利用 LLM 广泛的常识知识和复杂的多步骤推理能力，现有方法要求它们要么为每个决策提供理由，从而隐式地构建推理逻辑链（Liu
    等，[2024](#bib.bib9)），要么手动定义日志审计的中间步骤（Qi 等，[2023](#bib.bib7)），或使用少量标注日志样本提供上下文并指导预测（Liu
    等，[2024](#bib.bib9)）。这些能力使它们能够以零-shot 方式进行日志审计，无需训练或微调，从而从根本上减轻了由高度不平衡类别引起的过拟合风险。此外，审计结果可以以预定义的人类可读格式呈现，从而避免了不可解释结果的问题。
- en: 'Despite the promising applications of LLMs in ITD, current studies merely transfer
    them in a straightforward input-output way. This direct transformation fails to
    approach the specific features of ITD. Specifically, we identify challenges as
    follows: (1) Malicious behaviors exhibited by users are intrinsically manifold.
    Insiders may leak confidential data through the network, mobile storage devices,
    or email (Glasser and Lindauer, [2013](#bib.bib10)), requiring a multidimensional
    examination of user behaviors. (2) The input length constrained by LLMs might
    result in inadequate detection. Online APIs for LLMs commonly restrict the size
    of input windows (e.g., approximately 128K tokens for GPT-4), which proves inadequate
    for incorporating entire overlong logs, thereby disregarding crucial contextual
    details such as typical user behaviors. (3) The faithfulness hallucination brought
    by LLMs leads to the divergence of generated content from user instructions. For
    example, even if some sub-tasks’ results are identified as malicious, there remains
    a possibility for LLMs to categorize the whole log set as benign.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 LLM 在 ITD 中有着令人期待的应用，但目前的研究仅仅以简单的输入输出方式转移它们。这种直接转化未能涉及 ITD 的具体特征。具体来说，我们识别出以下挑战：（1）用户表现出的恶意行为本质上是多样的。内部人员可能通过网络、移动存储设备或电子邮件泄露机密数据（Glasser
    和 Lindauer，[2013](#bib.bib10)），这需要对用户行为进行多维度的检查。（2）LLM 受限于输入长度可能导致检测不足。LLM 的在线
    API 通常限制输入窗口的大小（例如，GPT-4 的输入窗口大约为 128K 令牌），这对于包含整个过长日志显得不够充分，从而忽略了诸如典型用户行为等关键的上下文细节。（3）LLM
    带来的可信度幻觉导致生成内容与用户指令的偏离。例如，即使某些子任务的结果被识别为恶意，LLM 仍有可能将整个日志集分类为良性。
- en: '![Refer to caption](img/b45cb671520167459c87cc8d5eca27f2.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/b45cb671520167459c87cc8d5eca27f2.png)'
- en: 'Figure 1: An example of the three agents included in Audit-LLM, along with
    their interaction and workflow.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：Audit-LLM 中包含的三个代理示例，以及它们的互动和工作流程。
- en: 'Considering the multiple perspectives involved in identified challenges, distinct
    capabilities are required to collaboratively handle ITD, i.e., decomposing log
    auditing into sub-tasks, accessing information beyond the input window, and possessing
    mechanisms to mitigate hallucinations. The requirement is in line with the main
    idea of multi-agent systems (Yu et al., [2024](#bib.bib11); Deng et al., [2024](#bib.bib12)),
    where several specialized agents are played as specific roles to achieve a shared
    goal collectively. Thus, we draw upon the workflows of human log auditors to develop
    a multi-agent insider threat detection framework Audit-LLM. Enhanced by multi-agent
    collaboration, the Audit-LLM framework focuses on task decomposition, tool creation,
    and hallucination elimination, as depicted in Fig. [1](#S1.F1 "Figure 1 ‣ I Introduction
    ‣ Audit-LLM: Multi-Agent Collaboration for Log-based Insider Threat Detection").'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到识别出的挑战涉及的多个视角，需要不同的能力来协作处理 ITD，即将日志审计分解为子任务，访问超出输入窗口的信息，并具备减轻幻觉的机制。这一要求与多代理系统的主要思想一致（Yu
    等，[2024](#bib.bib11)；Deng 等，[2024](#bib.bib12)），其中多个专门的代理扮演特定角色，共同实现一个共享目标。因此，我们借鉴了人类日志审计员的工作流程，开发了一个多代理内部威胁检测框架
    Audit-LLM。通过多代理协作，Audit-LLM 框架专注于任务分解、工具创建和幻觉消除，如图[1](#S1.F1 "图 1 ‣ I 引言 ‣ Audit-LLM：基于日志的多代理协作内部威胁检测")所示。
- en: Specifically, instead of achieving the final result in a single step, we instruct
    a Chain-of-Thought (Ji et al., [2024](#bib.bib13)) (CoT)-oriented agent, referred
    to as the Decomposer, to tailor the complex ITD task into a series of sub-tasks.
    This agent facilitates a comprehensive evaluation of user behavior from multiple
    perspectives. Expanding on this analogy, we guide the next agent, known as the
    Tool Builder, to develop a suite of sub-task-specific tools to extract global
    characteristics for detection. These tools are engineered to derive insights from
    the log set, such as a user’s historical login frequency and the verification
    of website legitimacy, thereby improving the final conclusion. Lastly, we develop
    a third agent named Executor, tasked with systematically accomplishing sub-tasks
    by invoking constructed tools to realize threat detection. Drawing inspiration
    from the human “peer review” process, which improves the quality and reliability
    of work through mutual evaluations and feedback, we propose a pair-wise Evidence-Based
    Multi-Agent Debate (EMAD) mechanism to mitigate the faithfulness hallucination
    issue encountered in LLMs employed for ITD.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，我们没有在一步中完成最终结果，而是指导一个以链式思维（Ji et al., [2024](#bib.bib13)）（CoT）为导向的代理，称为“解构者”，将复杂的ITD任务分解成一系列子任务。这个代理有助于从多个角度对用户行为进行全面评估。基于这个类比，我们指导下一个代理，即“工具构建者”，开发一套特定子任务的工具来提取检测的全局特征。这些工具旨在从日志集中提取洞察，例如用户的历史登录频率和网站合法性验证，从而改善最终结论。最后，我们开发了一个名为“执行者”的第三个代理，负责通过调用构建的工具来系统地完成子任务以实现威胁检测。受到人类“同行评审”过程的启发，该过程通过相互评估和反馈来提高工作质量和可靠性，我们提出了一种成对的基于证据的多代理辩论（EMAD）机制，以减轻在ITD中使用LLMs时遇到的可信度幻觉问题。
- en: 'In this paper, we introduce Audit-LLM (a multi-agent log-based insider threat
    detection framework) that integrates the aforementioned ideas. Our contributions
    are three-fold:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们介绍了Audit-LLM（一个基于多代理的日志内部威胁检测框架），该框架集成了上述思想。我们的贡献有三方面：
- en: •
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: To the best of our knowledge, we are the first to employ multi-agent collaboration
    for ITD and propose Audit-LLM, a multi-agent log-based insider threat detection
    framework.
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 据我们所知，我们是首个将多代理协作应用于ITD并提出Audit-LLM这一基于多代理的日志内部威胁检测框架的研究团队。
- en: •
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We counter faithfulness hallucination issues by introducing a pair-wise Evidence-based
    Multi-agent Debate mechanism. This enables agents to engage in an iterative refining
    process, thus bolstering the reliability of our ITD system.
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们通过引入成对的基于证据的多代理辩论机制来应对可信度幻觉问题。这使得代理可以参与一个迭代的优化过程，从而增强我们ITD系统的可靠性。
- en: •
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We evaluate the proposed Audit-LLM alongside state-of-the-art baselines for
    the ITD task using three publicly accessible datasets. Our findings demonstrate
    the superiority of Audit-LLM compared to the competitive baselines.
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们使用三个公开可用的数据集对提出的Audit-LLM与最先进的基线进行评估。我们的发现显示，与竞争性基线相比，Audit-LLM具有优越性。
- en: II Related Work
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 相关工作
- en: 'In this section, we first review related works of traditional ITD methods and
    deep learning-based ITD methods in Sec. [II-A](#S2.SS1 "II-A Log-based insider
    threat detection ‣ II Related Work ‣ Audit-LLM: Multi-Agent Collaboration for
    Log-based Insider Threat Detection"). Then, in Sec. [II-B](#S2.SS2 "II-B LLM for
    cybersecurity ‣ II Related Work ‣ Audit-LLM: Multi-Agent Collaboration for Log-based
    Insider Threat Detection"), we provide a detailed discussion of various approaches
    for applying LLMs in the field of cybersecurity.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们首先回顾传统ITD方法和基于深度学习的ITD方法的相关工作，详见第[II-A](#S2.SS1 "II-A Log-based insider
    threat detection ‣ II Related Work ‣ Audit-LLM: Multi-Agent Collaboration for
    Log-based Insider Threat Detection")节。然后，在第[II-B](#S2.SS2 "II-B LLM for cybersecurity
    ‣ II Related Work ‣ Audit-LLM: Multi-Agent Collaboration for Log-based Insider
    Threat Detection")节，我们详细讨论了在网络安全领域应用LLMs的各种方法。'
- en: II-A Log-based insider threat detection
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-A 基于日志的内部威胁检测
- en: 'Insider threat detection has attracted considerable research interest over
    the last decade as an important task in cybersecurity. Over the years, extensive
    research has been conducted to develop effective approaches for detecting insider
    threats. Broadly, these approaches can be categorized into two main streams: traditional
    methods and deep learning methods.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 内部威胁检测在过去十年中作为网络安全中的一项重要任务，吸引了大量的研究兴趣。多年来，已经进行了广泛的研究以开发有效的内部威胁检测方法。广泛而言，这些方法可以分为两大类：传统方法和深度学习方法。
- en: 'Traditional ITD methods can further be classified into two types: anomaly-based
    and misuse-based approaches. Anomaly-based detection is the prevalent approach.
    For instance, Brdiczka et al. ([2012](#bib.bib14)) propose a traitor assessment
    using Bayesian techniques that combined structural anomaly detection from information
    and social networks with psychological profiling. Additionally, Camiña et al.
    ([2016](#bib.bib15)) propose detection systems for masqueraders utilizing SVM
    and KNN as one-class techniques. In contrast, misuse-based methods incorporate
    softer forms of matching through similarity measurement. For instance, Agrafiotis
    et al. ([2016](#bib.bib16)) propose tripwire grammar capable of capturing abstraction
    of policies that organizations adopted, as well as signatures of insider misbehaviors.
    Moreover, Magklaras and Furnell ([2012](#bib.bib17)) design an insider threat
    prediction and specification language (ITPSL), which has markup features and utilizes
    logical operators.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的 ITD 方法进一步可以分为两种类型：基于异常的方法和基于滥用的方法。基于异常的检测是主要的方法。例如，Brdiczka 等人 ([2012](#bib.bib14))
    提出了使用贝叶斯技术的背叛者评估，将信息和社交网络中的结构异常检测与心理档案结合在一起。此外，Camiña 等人 ([2016](#bib.bib15))
    提出了利用 SVM 和 KNN 作为单类技术的伪装者检测系统。相对而言，基于滥用的方法通过相似性测量进行更柔和的匹配。例如，Agrafiotis 等人 ([2016](#bib.bib16))
    提出了能够捕捉组织采用的政策抽象以及内部不当行为签名的 tripwire 语法。此外，Magklaras 和 Furnell ([2012](#bib.bib17))
    设计了一种内部威胁预测和规范语言（ITPSL），具有标记特性并利用逻辑运算符。
- en: With the development of deep learning methods, there is a departure from traditional
    approaches, as practitioners increasingly turn to neural networks to distinguish
    between benign and malicious behaviors. For instance, Yuan et al. ([2019](#bib.bib18))
    employ hierarchical neural temporal point processes to capture activity types
    and time information within user sessions. Further, Liu et al. ([2019](#bib.bib19))
    introduce a network security threat detection method based on heterogeneous graph
    embedding. It achieves user behavior detection by constructing a heterogeneous
    graph, conducting graph embedding learning, and employing detection algorithms.
    Moreover, Fang et al. ([2022](#bib.bib20)) present LMTracker for lateral movement
    path detection based on heterogeneous graphs and propose a representation method
    for lateral movement paths and devise an unsupervised detection algorithm utilizing
    reconstruction error.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 随着深度学习方法的发展，传统方法逐渐被取代，实践者越来越倾向于使用神经网络来区分良性和恶意行为。例如，Yuan 等人 ([2019](#bib.bib18))
    使用层次神经时间点过程捕捉用户会话中的活动类型和时间信息。此外，Liu 等人 ([2019](#bib.bib19)) 引入了一种基于异构图嵌入的网络安全威胁检测方法。该方法通过构建异构图、进行图嵌入学习和应用检测算法实现用户行为检测。此外，Fang
    等人 ([2022](#bib.bib20)) 提出了基于异构图的横向移动路径检测工具 LMTracker，并提出了一种横向移动路径的表示方法，并设计了一种利用重建误差的无监督检测算法。
- en: However, in real-world scenarios, malicious insider threat behaviors are extremely
    rare compared to benign behaviors. This rarity can lead deep learning models to
    exhibit bias, often favouring predictions of benign activity. Furthermore, deep
    learning typically outputs log classification results in an end-to-end manner,
    lacking interpretable intermediate results that are crucial for end-users such
    as auditors to trust. Instead, Audit-LLM leverages the extensive knowledge and
    zero-shot generation abilities of LLMs to accurately detect malicious behaviors
    and provide an interpretable analysis process.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在实际场景中，恶意内部威胁行为与良性行为相比极其罕见。这种稀有性可能导致深度学习模型出现偏差，通常倾向于预测良性活动。此外，深度学习通常以端到端的方式输出日志分类结果，缺乏对最终用户如审计员而言至关重要的可解释中间结果。相反，Audit-LLM
    利用 LLM 的广泛知识和零样本生成能力，准确检测恶意行为并提供可解释的分析过程。
- en: II-B LLM for cybersecurity
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-B LLM 在网络安全中的应用
- en: The constantly changing landscape of modern cybersecurity poses significant
    challenges, with adversaries adapting tactics to exploit vulnerabilities and avoid
    detection. However, AI advancements, especially Large Language Models (LLMs),
    offer promising avenues for strengthening cybersecurity, serving not only as defensive
    measures but also as offensive tools. For instance, Xu et al. ([2024](#bib.bib21))
    present a system named AutoAttacker, which leverages Large Language Models for
    automated network attacks, utilizing language models for planning, summarization,
    navigation, and experience management. The paper proposes a system for automated
    penetration testing. Moreover, Fang et al. ([2024](#bib.bib22)) investigate the
    capability of LLMs to automatically exploit cybersecurity vulnerabilities. Employing
    the GPT-4 model in conjunction with CVE vulnerability descriptions, they were
    able to successfully exploit 87% of real-world software vulnerabilities. Concurrently,
    LLMs can serve as potent instruments for the defensive side, aiding in the detection
    and identification of potential security threats. For instance, Jin et al. ([2024](#bib.bib8))
    leverage large language models to enhance strategic reasoning capabilities in
    cybersecurity, realizing a comprehensive human-machine interactive data synthesis
    workflow for developing CVE to ATT&CK mapping datasets. It employs retrieval-aware
    training techniques to enhance the strategic reasoning capabilities of large language
    models in generating precise policies. Similarly, Fayyazi et al. ([2024](#bib.bib23))
    comply a dataset of 639 descriptions by extracting tactics, techniques, and sub-techniques
    from the MITRE ATT&CK framework and evaluated different models’ abilities to interpret
    process descriptions and map them to corresponding ATT&CK tactics.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现代网络安全领域不断变化的格局带来了重大挑战，对手不断调整策略以利用漏洞并避免检测。然而，人工智能的进步，特别是大型语言模型（LLMs），为加强网络安全提供了有前景的途径，不仅作为防御措施，还作为进攻工具。例如，Xu
    等人（[2024](#bib.bib21)）提出了一个名为 AutoAttacker 的系统，该系统利用大型语言模型进行自动化网络攻击，利用语言模型进行规划、总结、导航和经验管理。该论文提出了一种自动化渗透测试的系统。此外，Fang
    等人（[2024](#bib.bib22)）研究了大型语言模型自动利用网络安全漏洞的能力。通过将 GPT-4 模型与 CVE 漏洞描述结合，他们成功利用了
    87% 的真实世界软件漏洞。同时，大型语言模型还可以作为强大的防御工具，帮助检测和识别潜在的安全威胁。例如，Jin 等人（[2024](#bib.bib8)）利用大型语言模型增强了网络安全中的战略推理能力，实现了一个全面的人机互动数据合成工作流程，用于开发
    CVE 到 ATT&CK 的映射数据集。该方法采用了检索感知训练技术，以增强大型语言模型在生成精准策略方面的战略推理能力。类似地，Fayyazi 等人（[2024](#bib.bib23)）通过从
    MITRE ATT&CK 框架中提取战术、技术和子技术，编制了一个包含 639 个描述的数据集，并评估了不同模型解释过程描述并将其映射到相应 ATT&CK
    战术的能力。
- en: When focusing on log analysis, LLMs also demonstrate strong parsing and analytical
    capabilities. For instance, Le and Zhang ([2023](#bib.bib6)) assess the capability
    of ChatGPT in log parsing. They devised appropriate prompts to guide ChatGPT in
    understanding log parsing tasks and extracting log events/templates from input
    log messages. Besides, Qi et al. ([2023](#bib.bib7)) introduce LogGPT, a log anomaly
    detection framework based on ChatGPT. Leveraging ChatGPT’s natural language understanding
    capabilities, it explores the potential of transferring knowledge from large-scale
    corpora to the task of log anomaly detection. Moreover, Karlsen et al. ([2023](#bib.bib24))
    explore methodologies for log file analysis using Large Language Models (LLMs)
    and evaluates the performance of various LLM architectures in the context of application
    and system log security analysis.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在日志分析方面，大型语言模型也展示了强大的解析和分析能力。例如，Le 和 Zhang（[2023](#bib.bib6)）评估了 ChatGPT 在日志解析中的能力。他们设计了适当的提示以引导
    ChatGPT 理解日志解析任务，并从输入的日志消息中提取日志事件/模板。此外，Qi 等人（[2023](#bib.bib7)）介绍了 LogGPT，一个基于
    ChatGPT 的日志异常检测框架。利用 ChatGPT 的自然语言理解能力，它探索了将大规模语料库中的知识转移到日志异常检测任务中的潜力。此外，Karlsen
    等人（[2023](#bib.bib24)）探索了使用大型语言模型（LLMs）进行日志文件分析的方法，并评估了各种 LLM 架构在应用和系统日志安全分析中的表现。
- en: However, the abundance of overlong log files presents a significant hurdle for
    LLMs, potentially concealing anomalous behavior within truncated logs due to the
    constrained context length of LLMs. Moreover, methods that segment and analyze
    logs fail to provide LLMs with the historical context of logs. In contrast, we
    propose the utilization of automated tools to effectively extract user behavior
    characteristics from extensive log datasets and input them as contextual information
    into LLMs for assessment.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，过长的日志文件数量繁多，对 LLMs 形成了重大障碍，可能由于 LLMs 的上下文长度限制而隐藏了截断日志中的异常行为。此外，将日志分段并分析的方法无法为
    LLMs 提供日志的历史上下文。相反，我们建议利用自动化工具从广泛的日志数据集中有效提取用户行为特征，并将其作为上下文信息输入 LLMs 进行评估。
- en: III APPROACH
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III 方法
- en: '![Refer to caption](img/a195eb353dfa542b78b1bcfd384bca16.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/a195eb353dfa542b78b1bcfd384bca16.png)'
- en: 'Figure 2: The framework of Audit-LLM comprises three agents:(i) the Decomposer,
    tasked with breaking down complex tasks into more manageable sub-tasks via the
    COT reasoning, (ii) the Tool builder, responsible for creating a suite of task-specific,
    callable tools; and (iii) two Executors, dedicated to independently accomplishing
    the sub-tasks and reach the conclusion consensus by the pair-wise Evidence-based
    Multi-agent Debate mechanism.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '图 2: Audit-LLM 的框架包括三个主体：（i）分解器，负责通过 COT 推理将复杂任务分解为更易管理的子任务；（ii）工具构建器，负责创建一套任务特定的、可调用的工具；以及（iii）两个执行者，致力于独立完成子任务，并通过成对的基于证据的多智能体辩论机制达成结论一致。'
- en: This section formalizes the task and presents the proposed model, including
    the framework and module details.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 本节对任务进行形式化定义，并展示了提出的模型，包括框架和模块的详细信息。
- en: III-A Framework
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-A 框架
- en: 'We first overview the Audit-LLM framework, as illustrated in Fig. [2](#S3.F2
    "Figure 2 ‣ III APPROACH ‣ Audit-LLM: Multi-Agent Collaboration for Log-based
    Insider Threat Detection"). It is a multi-agent collaboration framework, consisting
    of three core agents: the Decomposer, the Tool Builder, and the Executor. Particularly,
    the Decomposer reformulates the log auditing task into a sequence of more manageable
    sub-tasks via the CoT reasoning (Sec. [III-B](#S3.SS2 "III-B Task definition and
    decomposition ‣ III APPROACH ‣ Audit-LLM: Multi-Agent Collaboration for Log-based
    Insider Threat Detection")). Then, the Tool Builder constructs a set of reusable
    tools tailored for each sub-task (Sec. [III-C](#S3.SS3 "III-C Tool development
    and optimization ‣ III APPROACH ‣ Audit-LLM: Multi-Agent Collaboration for Log-based
    Insider Threat Detection")). Ultimately, two independent Executors dynamically
    invoke tools to accomplish sub-tasks, generating respective results, which are
    further refined by the pair-wise Evidence-based Multi-agent debate mechanism to
    culminate in a consensus on the final conclusion (Sec. [III-D](#S3.SS4 "III-D
    Task execution ‣ III APPROACH ‣ Audit-LLM: Multi-Agent Collaboration for Log-based
    Insider Threat Detection")).'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '我们首先概述了如图 [2](#S3.F2 "图 2 ‣ III 方法 ‣ Audit-LLM: 基于日志的内部威胁检测的多智能体协作") 所示的 Audit-LLM
    框架。它是一个多智能体协作框架，由三个核心主体组成：分解器、工具构建器和执行者。特别地，分解器通过 CoT 推理将日志审计任务重新表述为一系列更易管理的子任务（参见
    [III-B](#S3.SS2 "III-B 任务定义与分解 ‣ III 方法 ‣ Audit-LLM: 基于日志的内部威胁检测的多智能体协作")）。然后，工具构建器为每个子任务构建一套可重用的工具（参见
    [III-C](#S3.SS3 "III-C 工具开发与优化 ‣ III 方法 ‣ Audit-LLM: 基于日志的内部威胁检测的多智能体协作")）。最终，两个独立的执行者动态调用工具完成子任务，生成各自的结果，这些结果通过成对的基于证据的多智能体辩论机制进一步精炼，最终达成结论一致（参见
    [III-D](#S3.SS4 "III-D 任务执行 ‣ III 方法 ‣ Audit-LLM: 基于日志的内部威胁检测的多智能体协作")）。'
- en: III-B Task definition and decomposition
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-B 任务定义与分解
- en: III-B1 ITD
  id: totrans-59
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B1 ITD
- en: 'Formally, consider an information system that accesses a time-ordered log set,
    $\mathcal{L}=\{a^{u_{i}}_{j}\in\mathcal{R}\mid 1\leq i\leq N,1\leq j\leq|u_{i}|\}$
    are defined as:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 从形式上考虑，考虑一个访问时间排序日志集的信息系统，$\mathcal{L}=\{a^{u_{i}}_{j}\in\mathcal{R}\mid 1\leq
    i\leq N,1\leq j\leq|u_{i}|\}$ 定义为：
- en: '|  | $1$2 |  | (1) |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (1) |'
- en: III-B2 CoT for ITD
  id: totrans-62
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B2 CoT 在 ITD 中的应用
- en: 'The Chain-of-Thought (CoT) is a reasoning mechanism where the Large Language
    Model (LLM) produces intermediate steps or justifications to reach the final conclusion,
    thereby improving interpretability and the model’s proficiency in tackling intricate
    tasks. For an LLM $\mathcal{M}$ can be expressed as:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Chain-of-Thought (CoT) 是一种推理机制，其中大型语言模型（LLM）生成中间步骤或理由以得出最终结论，从而提高可解释性和模型在处理复杂任务时的能力。对于
    LLM $\mathcal{M}$ 可以表示为：
- en: '|  | $1$2 |  | (2) |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (2) |'
- en: Here, $\mathcal{V}$.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，$\mathcal{V}$。
- en: 'However, as previously noted, the log set $\mathcal{L}$, enabling Audit-LLM
    to address ITD through a CoT paradigm as:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如前所述，日志集 $\mathcal{L}$ 使 Audit-LLM 能够通过 CoT 模式来处理 ITD，如下所示：
- en: '|  | $z^{i}_{ta}\leftarrow\mathcal{M}(Sample(\mathcal{R}),p_{Deco}),\quad\text{for}\
    i=1,\ldots,N_{t},$ |  | (3) |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '|  | $z^{i}_{ta}\leftarrow\mathcal{M}(Sample(\mathcal{R}),p_{Deco}),\quad\text{for}\
    i=1,\ldots,N_{t},$ |  | (3) |'
- en: where $p_{Deco}$.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $p_{Deco}$。
- en: To ensure thorough coverage of all potential malicious behavior patterns, we
    drew inspiration from the field of psychology’s concept of “meta-cognitive dialogues”—a
    process of self-reflection and iterative improvement (Conway-Smith and West, [2024](#bib.bib25)).
    Specifically, we present the Decomposer with slicing of log activities and guided
    its iterative exploration of sub-tasks by continually asking, “What additional
    information do you need to detect threat behaviors?” This strategy allows the
    Decomposer to progressively advance until barely surpassing the task’s boundaries,
    i.e., the requirements of detecting the whole log set.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保全面覆盖所有潜在的恶意行为模式，我们借鉴了心理学领域的“元认知对话”概念——一种自我反思和迭代改进的过程 (Conway-Smith 和 West,
    [2024](#bib.bib25))。具体来说，我们向 Decomposer 提供了日志活动的切片，并通过不断提问“你需要什么额外信息来检测威胁行为？”来指导其对子任务的迭代探索。这一策略使
    Decomposer 能够逐步推进，直到仅仅超出任务的边界，即检测整个日志集的要求。
- en: 'In practice, these sub-tasks guide the Tool Builder agent to construct sub-task-specific
    tools, which further help the Executor agent to think logically, generating corresponding
    intermediate results to facilitate the CoT process for ITD (see Eq.([2](#S3.E2
    "In III-B2 CoT for ITD ‣ III-B Task definition and decomposition ‣ III APPROACH
    ‣ Audit-LLM: Multi-Agent Collaboration for Log-based Insider Threat Detection"))).'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际操作中，这些子任务指导 Tool Builder 代理构建子任务特定的工具，这进一步帮助 Executor 代理进行逻辑思考，生成相应的中间结果，以促进
    ITD 的 CoT 过程（参见 Eq.([2](#S3.E2 "在 III-B2 CoT for ITD ‣ III-B 任务定义与分解 ‣ III 方法
    ‣ Audit-LLM：基于日志的内部威胁检测的多代理协作"))）。
- en: III-C Tool development and optimization
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-C 工具开发与优化
- en: 'The objective of the Tool Builder agent is to construct a collection of sub-task-specific
    and reusable tools $\{z_{to}^{i}\}_{i=1}^{N_{t}}$. The creation process can be
    formalized as:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Tool Builder 代理的目标是构建一系列子任务特定且可重用的工具 $\{z_{to}^{i}\}_{i=1}^{N_{t}}$。创建过程可以形式化为：
- en: '|  | $z_{to}^{i}\leftarrow\mathcal{M}(z_{ta}^{i},p_{\text{Tool}}),\quad\text{for}\
    i=1,\ldots,N_{t},$ |  | (4) |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '|  | $z_{to}^{i}\leftarrow\mathcal{M}(z_{ta}^{i},p_{\text{Tool}}),\quad\text{for}\
    i=1,\ldots,N_{t},$ |  | (4) |'
- en: 'where $p_{\text{Tool}}$ denotes the prompt for the Tool Builder. This process
    is further delineated into three stages:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $p_{\text{Tool}}$ 表示 Tool Builder 的提示。该过程进一步划分为三个阶段：
- en: III-C1 Intent recognition
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-C1 意图识别
- en: In this stage, we applied the “Programming by Example” (PbE) paradigm (Bauer,
    [1979](#bib.bib26)), which streamlines the programming process and reduces complexity
    by guiding program writing through concrete demonstrations. Specifically, the
    demonstrations consist of two components, namely log examples and result examples.
    Log examples serve to acquaint the Tool Builder with accessible inputs and enable
    them to determine the necessary input parameters for the tools. Result examples
    aim to align the generated tool with the objectives of the sub-tasks.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一阶段，我们应用了“示例编程”（PbE）范式 (Bauer, [1979](#bib.bib26))，通过具体演示来简化编程过程并减少复杂性。具体而言，演示包括两个组件，即日志示例和结果示例。日志示例旨在使
    Tool Builder 熟悉可访问的输入，并确定工具所需的输入参数。结果示例旨在使生成的工具与子任务的目标对齐。
- en: III-C2 Unit test
  id: totrans-77
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-C2 单元测试
- en: In the next stage, we verify the functionality and accuracy of the generated
    tools through unit testing, ensuring that the agent can seamlessly invoke these
    tools and obtain accurate results. We begin by manually entering the necessary
    parameters for the tools to validate their functionality. Subsequently, each tool
    undergoes three invocation tests by the LLM for every sub-task. Upon successful
    extraction of parameters from the logs and their placement in the intended positions
    by the LLM, the tool is incorporated into the toolkit for subsequent utilization.
    While any tool triggers errors during this process, we document the error details
    and utilize this information to guide the LLM in reconstructing the faulty tool.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一阶段，我们通过单元测试验证生成工具的功能和准确性，确保智能体可以无缝调用这些工具并获得准确的结果。我们首先手动输入工具所需的参数以验证其功能。随后，每个工具都会由LLM进行三次调用测试。成功从日志中提取参数并由LLM将其放置在预期位置后，该工具将被纳入工具包中以供后续使用。如果在此过程中任何工具触发错误，我们会记录错误细节，并利用这些信息指导LLM重建有缺陷的工具。
- en: III-C3 Tool decoration
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-C3 工具装饰
- en: 'Although unit testing has demonstrated the reliability of an agent’s invocation
    of individual tools, the presence of multiple tools can still potentially lead
    to error invocation. Thus, the final stage involves enhancing the validated tools
    with decoration. The decoration process includes two main aspects: code documentation
    and output restructuring. Code documentation provides contextual information at
    the beginning of each tool, accurately describing its functionality to prevent
    missteps during agent calls. Additionally, we refine the output formats to ensure
    that the agent can better understand the meaning of the results obtained from
    using the tools in natural language terms.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管单元测试已经证明了智能体调用单个工具的可靠性，但多个工具的存在仍可能导致错误调用。因此，最后阶段涉及用装饰增强经过验证的工具。装饰过程包括两个主要方面：代码文档和输出重组。代码文档在每个工具的开头提供上下文信息，准确描述其功能，以防止在智能体调用过程中出现误操作。此外，我们还优化输出格式，以确保智能体能够更好地理解使用工具后获得结果的自然语言含义。
- en: In practice, the Tool Builder completes the process of tool development and
    optimization, and only needs to be performed once for each sub-task. The resulting
    tools $\{z_{to}^{i}\}_{i=1}^{N_{t}}$ can be reused for all instances of ITD, thereby
    reducing the usage costs of Audit-LLM.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，工具构建者完成工具开发和优化过程，并且每个子任务只需执行一次。生成的工具 $\{z_{to}^{i}\}_{i=1}^{N_{t}}$ 可以在所有
    ITD 实例中重复使用，从而降低审计-LLM 的使用成本。
- en: '![Refer to caption](img/900abb6ef9b3eed97d17f5260c019490.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/900abb6ef9b3eed97d17f5260c019490.png)'
- en: 'Figure 3: An example of building different agents via prompts. The specific
    details are omitted for the sake of brevity.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：通过提示构建不同智能体的示例。为了简洁起见，具体细节已被省略。
- en: 'Input: Given a task set comprising $n$'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：给定一个包含 $n$ 的任务集
- en: Algorithm 1 The procedure of pair-wise Evidence-based Multi-agent debate.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 1 成对的基于证据的多智能体辩论过程。
- en: III-D Task execution
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-D 任务执行
- en: 'The principal role of the Executor is to complete the sub-tasks generated by
    the Decomposer by invoking tools in a CoT manner. Hence, the intermediate results
    can be formulated as:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 执行者的主要角色是通过以 CoT 方式调用工具来完成由分解器生成的子任务。因此，中间结果可以表示为：
- en: '|  | $1$2 |  | (5) |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (5) |'
- en: 'where the invoke function $Invoke(\cdot)$. We illustrate the collaborative
    process of all agents in Fig. [3](#S3.F3 "Figure 3 ‣ III-C3 Tool decoration ‣
    III-C Tool development and optimization ‣ III APPROACH ‣ Audit-LLM: Multi-Agent
    Collaboration for Log-based Insider Threat Detection"). To manage output diversity,
    we instruct the Executor to categorize responses into predefined formats, e.g.,
    sub-task results, anomalous behaviors, and final conclusions.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 其中调用函数为 $Invoke(\cdot)$。我们在图 [3](#S3.F3 "图 3 ‣ III-C3 工具装饰 ‣ III-C 工具开发与优化 ‣
    III 方法 ‣ 审计-LLM：基于日志的内部威胁检测的多智能体协作") 中展示了所有智能体的协作过程。为了管理输出的多样性，我们指示执行者将响应分类为预定义格式，例如子任务结果、异常行为和最终结论。
- en: Although generally effective, the Executor occasionally generates final conclusions
    that may contradict the results of sub-tasks. For instance, consider the scenario
    where the Executor correctly invokes the website legitimacy verification tool
    and identifies some malicious activities, e.g., accessing suspicious sites or
    downloading malicious payloads. Nevertheless, the final conclusion synthesized
    by LLM may still categorize this log set as benign, resulting in what is known
    as faithfulness hallucination in LLM (Huang et al., [2023](#bib.bib27)). This
    phenomenon can be attributed to the intrinsic event error from LLM (Kim et al.,
    [2024](#bib.bib28)), wherein the generated explanations misrepresent source events.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管通常有效，执行者偶尔会得出可能与子任务结果相矛盾的最终结论。例如，考虑以下情景：执行者正确调用了网站合法性验证工具并识别出一些恶意活动，如访问可疑网站或下载恶意负载。然而，LLM
    综合得出的最终结论仍可能将该日志集分类为良性，导致在 LLM 中出现所谓的忠实性幻觉（Huang et al., [2023](#bib.bib27)）。这一现象可归因于
    LLM 的内在事件错误（Kim et al., [2024](#bib.bib28)），即生成的解释误述了源事件。
- en: To address this issue, we propose a pair-wise Evidence-based Multi-Agent Debate
    (EMAD) mechanism, mimicking the human debate process to help LLM review each reasoning
    step. Particularly, two Executors are designated as the proponent and opponent,
    with their respective reasoning processes forming the basis of their claims. During
    each debate round, these claims are presented to the opposing Executor for scrutiny,
    which helps each Executor to update their respective conclusion. Through multiple
    rounds of debate, a comprehensive and accurate conclusion consensus can be achieved.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们提出了一种成对证据基础的多智能体辩论（EMAD）机制，模拟人类辩论过程，帮助 LLM 审查每一步推理。特别是，指定两个执行者分别为支持者和反对者，他们的各自推理过程构成他们主张的基础。在每轮辩论中，这些主张会被提交给对方执行者进行审查，这帮助每个执行者更新他们的结论。通过多轮辩论，可以达成一个全面且准确的结论共识。
- en: 'Formally, the process of EMAD is outlined in Algorithm [1](#alg1 "In III-C3
    Tool decoration ‣ III-C Tool development and optimization ‣ III APPROACH ‣ Audit-LLM:
    Multi-Agent Collaboration for Log-based Insider Threat Detection"). Given a sub-task
    set $\{z_{ta}^{i}\}_{i=1}^{N_{t}}$) to update their respective conclusions in
    lines 5-12. To ensure the most accurate feedback, the two Executors continue their
    discussion until they reach a mutual agreement on the result set. Finally, merging
    the final results from both Executors formulates the ultimate conclusion, as indicated
    in line 13. To prevent endless debates, we also set a fixed number of iterations
    in line 4.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '正式来说，EMAD 的过程在算法 [1](#alg1 "在 III-C3 工具装饰 ‣ III-C 工具开发与优化 ‣ III 方法 ‣ Audit-LLM:
    基于日志的内部威胁检测的多智能体协作") 中概述。给定一个子任务集 $\{z_{ta}^{i}\}_{i=1}^{N_{t}}$) 更新它们各自的结论，见第
    5-12 行。为了确保最准确的反馈，两个执行者继续讨论，直到他们在结果集上达成一致。最后，将两个执行者的最终结果合并，形成*最终结论*，如第 13 行所示。为了防止无休止的辩论，我们还在第
    4 行设置了固定的迭代次数。'
- en: IV Experimental Setup
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 实验设置
- en: 'Within this section, we present a comprehensive overview of the experimental
    configuration, encompassing details about the experimental environment, datasets,
    and baselines. First, we present detailed information about the experimental configuration
    and discuss the research questions in Sec. [IV-A](#S4.SS1 "IV-A Research questions
    and experimental configuration ‣ IV Experimental Setup ‣ Audit-LLM: Multi-Agent
    Collaboration for Log-based Insider Threat Detection"). Second, we provide an
    in-depth description of the datasets used in our study in Sec. [IV-B](#S4.SS2
    "IV-B Datasets ‣ IV Experimental Setup ‣ Audit-LLM: Multi-Agent Collaboration
    for Log-based Insider Threat Detection"). Finally, we summarize the baseline models
    in Sec. [IV-C](#S4.SS3 "IV-C Baseline methods ‣ IV Experimental Setup ‣ Audit-LLM:
    Multi-Agent Collaboration for Log-based Insider Threat Detection")'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们提供了实验配置的全面概述，包括实验环境、数据集和基准的详细信息。首先，我们提供有关实验配置的详细信息，并在 Sec. [IV-A](#S4.SS1
    "IV-A 研究问题与实验配置 ‣ IV 实验设置 ‣ Audit-LLM: 基于日志的内部威胁检测的多智能体协作") 中讨论研究问题。其次，我们在 Sec. [IV-B](#S4.SS2
    "IV-B 数据集 ‣ IV 实验设置 ‣ Audit-LLM: 基于日志的内部威胁检测的多智能体协作") 中对我们研究中使用的数据集进行深入描述。最后，我们在
    Sec. [IV-C](#S4.SS3 "IV-C 基准方法 ‣ IV 实验设置 ‣ Audit-LLM: 基于日志的内部威胁检测的多智能体协作") 中总结了基准模型。'
- en: IV-A Research questions and experimental configuration
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A 研究问题与实验配置
- en: IV-A1 Research questions
  id: totrans-96
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-A1 研究问题
- en: We list several research questions to guide the experiments and verify the effectiveness
    of our proposal.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们列出了几个研究问题来指导实验并验证我们提案的有效性。
- en: 'RQ1:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'RQ1:'
- en: Can the proposed Audit-LLM achieve better performance than state-of-the-art
    baselines for log-based ITD?
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提出的 Audit-LLM 是否能比最新的基准方法在基于日志的 ITD 中取得更好的性能？
- en: 'RQ2:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'RQ2:'
- en: Which component contributes more to improving model performance?
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 哪个组件对提升模型性能的贡献更大？
- en: 'RQ3:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'RQ3:'
- en: When employing diverse LLMs as the base models, how does the performance of
    Audit-LLM vary?
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当使用多种 LLM 作为基础模型时，Audit-LLM 的性能如何变化？
- en: 'RQ4:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'RQ4:'
- en: What do the responses generated by Audit-LLM look like? How interpretable are
    they?
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Audit-LLM 生成的响应是什么样的？它们的可解释性如何？
- en: 'RQ5:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'RQ5:'
- en: How does Audit-LLM perform in real-world system environments?
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Audit-LLM 在真实世界系统环境中的表现如何？
- en: 'RQ6:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'RQ6:'
- en: What are the time and economic implications of using online LLM APIs like ChatGPT
    and ZhipuAI?
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用在线 LLM API，如 ChatGPT 和 ZhipuAI，时间和经济上的影响是什么？
- en: IV-A2 Experimental configuration
  id: totrans-110
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-A2 实验配置
- en: The experiments are conducted with an Intel Xeon(R) Gold 5218R CPU, 256 GB of
    RAM, and four Nvidia RTX A6000 (48 GB) GPUs. The agent in Audit-LLM is developed
    based on LangChain (LangChain, [a](#bib.bib29)), and we conduct our method in
    the Python 3.10.14 environment. We build our Audit-LLM framework based on multiple
    large language models, including a snapshot of gpt-3.5-turbo-0125 released by
    Openai ([OpenAI,](#bib.bib30) ), To facilitate the reproduction of the results
    in this paper, we share the code and data used to obtain these results on https://anonymous.address/.
    Additionally, we have shared the prompt we developed in the LangChain prompt hub
    under the identifier “anonymous-id”.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 实验在 Intel Xeon(R) Gold 5218R CPU、256 GB RAM 和四个 Nvidia RTX A6000 (48 GB) GPU
    上进行。Audit-LLM 中的代理基于 LangChain（LangChain, [a](#bib.bib29)）开发，我们在 Python 3.10.14
    环境中进行方法实验。我们基于多个大型语言模型构建了 Audit-LLM 框架，包括由 OpenAI 发布的 gpt-3.5-turbo-0125 快照（[OpenAI,](#bib.bib30)）。为了方便重现本文中的结果，我们将用于获得这些结果的代码和数据分享在
    https://anonymous.address/ 上。此外，我们已将我们在 LangChain 提示中心开发的提示以“anonymous-id”为标识符进行了共享。
- en: IV-B Datasets
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-B 数据集
- en: 'TABLE I: Statistics of the datasets used in our experiments.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '表 I: 我们实验中使用的数据集统计。'
- en: '| Dataset | CERT r4.2 | CERT r5.2 | PicoDomain |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | CERT r4.2 | CERT r5.2 | PicoDomain |'
- en: '| --- | --- | --- | --- |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Duration | 18 months | 3 days |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 持续时间 | 18 个月 | 3 天 |'
- en: '| --- | --- | --- |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| # employees | 930 | 1,901 | 15 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| # 员工 | 930 | 1,901 | 15 |'
- en: '| # insiders | 70 | 99 | 1 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| # 内部人员 | 70 | 99 | 1 |'
- en: '| # benign entries | 32,762,906 | 79,846,358 | 537,840 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| # 良性条目 | 32,762,906 | 79,846,358 | 537,840 |'
- en: '| # malicious entries | 7,316 | 10,306 | 80 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| # 恶意条目 | 7,316 | 10,306 | 80 |'
- en: '| Data sources |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 数据来源 |'
- en: '&#124; logon, email, &#124;'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 登录, 电子邮件, &#124;'
- en: '&#124; device, http, file, &#124;'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 设备, http, 文件, &#124;'
- en: '&#124; psychometric &#124;'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 心理测量学 &#124;'
- en: '|'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; file, system, &#124;'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 文件, 系统, &#124;'
- en: '&#124; network, auth, &#124;'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 网络, 认证, &#124;'
- en: '&#124; anomalies &#124;'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 异常 &#124;'
- en: '|'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 'To conduct robust and convincing experiments, we utilize three publicly accessible
    insider threat datasets, namely, CERT r4.2, CERT 5.2 (University, [2020](#bib.bib31)),
    and PicoDomain (Laprade et al., [2020](#bib.bib32)). The data statistics are summarized
    in Table [I](#S4.T1 "TABLE I ‣ IV-B Datasets ‣ IV Experimental Setup ‣ Audit-LLM:
    Multi-Agent Collaboration for Log-based Insider Threat Detection").'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '为了进行稳健且具有说服力的实验，我们利用了三个公开可访问的内部威胁数据集，即 CERT r4.2、CERT 5.2（University, [2020](#bib.bib31)）和
    PicoDomain（Laprade et al., [2020](#bib.bib32)）。数据统计汇总在表格[I](#S4.T1 "TABLE I ‣
    IV-B Datasets ‣ IV Experimental Setup ‣ Audit-LLM: Multi-Agent Collaboration for
    Log-based Insider Threat Detection")中。'
- en: 'The CERT datasets, provided by Carnegie Mellon University (Glasser and Lindauer,
    [2013](#bib.bib10)) in this work, are widely recognized in log-based insider threat
    detection (Xiao et al., [2024](#bib.bib33); Sun and Yang, [2022](#bib.bib34);
    Liu et al., [2019](#bib.bib19); Cai et al., [2024](#bib.bib35); Gonçalves and
    Zanchettin, [2024](#bib.bib36)). On one hand, CERT r4.2 includes activity logs
    from 1,000 users and 1,003 computers, while CERT r5.2 simulates an organization
    with 2,000 employees over 18 months. Both datasets encompass diverse multi-source
    activity logs, including user login/logoff events, emails, file access, website
    visits, device usage, and organizational structure data. Each malicious insider
    in the CERT dataset is categorized into one of four prevalent insider threat scenarios:
    data exfiltration, intellectual property theft, and IT sabotage.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: CERT 数据集由卡内基梅隆大学（Glasser 和 Lindauer, [2013](#bib.bib10)）提供，在基于日志的内部威胁检测中得到广泛认可（Xiao
    et al., [2024](#bib.bib33); Sun 和 Yang, [2022](#bib.bib34); Liu et al., [2019](#bib.bib19);
    Cai et al., [2024](#bib.bib35); Gonçalves 和 Zanchettin, [2024](#bib.bib36)）。一方面，CERT
    r4.2 包含来自 1,000 名用户和 1,003 台计算机的活动日志，而 CERT r5.2 模拟了一个拥有 2,000 名员工的组织，时间跨度为 18
    个月。这两个数据集涵盖了多种来源的活动日志，包括用户登录/注销事件、电子邮件、文件访问、网站访问、设备使用和组织结构数据。CERT 数据集中的每个恶意内部人员都被归类为四种流行的内部威胁场景之一：数据外泄、知识产权盗窃和
    IT 破坏。
- en: 'On the other hand, PicoDomain consists of detailed Zeek logs spanning 3 days,
    collected from a simulated small-scale network where APT attacks occurred during
    the last two days. The data sources within PicoDomain can be broadly classified
    into 5 groups: file logs (files, smb_files), system logs (dhcp, hosts, services),
    authentication logs (kerberos, ntlm), and anomaly detection logs (weird).'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，PicoDomain 包含详细的 Zeek 日志，跨度为 3 天，数据来源于一个模拟的小规模网络，在最后两天发生了 APT 攻击。PicoDomain
    中的数据来源大致可分为 5 类：文件日志（files，smb_files），系统日志（dhcp，hosts，services），认证日志（kerberos，ntlm）和异常检测日志（weird）。
- en: IV-C Baseline methods
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-C 基线方法
- en: IV-C1 Baseline methods
  id: totrans-135
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C1 基线方法
- en: 'For all LLM-based models discussed, we employ the same base LLM, i.e., the
    snapshot of gpt-3.5-turbo-0125, to fairly compare their performance. Due to severe
    class imbalance in the CERT dataset, which impedes DL-based methods from effectively
    capturing features of minority classes, we implemented an under-sampling approach
    following Xiao et al. ([2024](#bib.bib33)), restricting the number of benign class
    samples to below 20,000. Here, we list a series of state-of-the-art baselines
    for comparisons with our proposal in this paper:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有讨论的基于 LLM 的模型，我们使用相同的基础 LLM，即 gpt-3.5-turbo-0125 的快照，以公平比较它们的性能。由于 CERT
    数据集中的严重类别不平衡，阻碍了基于深度学习的方法有效捕捉少数类特征，我们实现了一个下采样方法，参考了 Xiao et al. ([2024](#bib.bib33))，将良性类别样本的数量限制在
    20,000 以下。在这里，我们列出了一系列最先进的基线方法，以便与本文中的提议进行比较：
- en: 'LogGPT (Qi et al., [2023](#bib.bib7)):'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LogGPT (Qi et al., [2023](#bib.bib7))：
- en: LogGPT utilizes LLMs for log auditing, extracting structured data from raw logs
    audited by ChatGPT.
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LogGPT 利用大型语言模型（LLMs）进行日志审计，从 ChatGPT 审计的原始日志中提取结构化数据。
- en: 'LogPrompt (Liu et al., [2024](#bib.bib9)):'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LogPrompt (Liu et al., [2024](#bib.bib9))：
- en: LogPrompt enhances zero-shot log auditing using LLMs and advanced prompting
    techniques, employing their top-performing CoT prompt.
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LogPrompt 利用大型语言模型（LLMs）和先进的提示技术增强零-shot日志审计，采用其表现最佳的 CoT 提示。
- en: 'LAN (Cai et al., [2024](#bib.bib35)):'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LAN (Cai et al., [2024](#bib.bib35))：
- en: LAN employs graph structure learning to adaptively construct user activity graphs,
    addressing data imbalance with a hybrid predictive loss.
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LAN 采用图结构学习自适应构建用户活动图，并通过混合预测损失解决数据不平衡问题。
- en: 'DeepLog (Du et al., [2017](#bib.bib2)):'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DeepLog (Du et al., [2017](#bib.bib2))：
- en: DeepLog treats log entries as sequential natural language, utilizing Long Short-Term
    Memory to detect anomalies.
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: DeepLog 将日志条目视为序列自然语言，利用长短期记忆（LSTM）检测异常。
- en: 'LMTracker (Fang et al., [2022](#bib.bib20)):'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LMTracker (Fang et al., [2022](#bib.bib20))：
- en: LMTracker uses event logs to construct heterogeneous graphs and apply unsupervised
    algorithms to detect malicious behavior.
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LMTracker 使用事件日志构建异质图，并应用无监督算法检测恶意行为。
- en: 'CATE (Xiao et al., [2024](#bib.bib33)):'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: CATE (Xiao et al., [2024](#bib.bib33))：
- en: CATE uses convolutional attention and a transformer encoder for log statistical
    and sequential analysis.
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: CATE 使用卷积注意力和变换器编码器进行日志统计和序列分析。
- en: In our comprehensive model performance evaluation, we covered baselines using
    LLMs, LSTM for sequential data, GNNs for graph structures, and pre-trained Transformers
    for insider threat detection.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们全面的模型性能评估中，我们涵盖了使用LLM的基线、用于顺序数据的LSTM、用于图结构的GNN和用于内部威胁检测的预训练Transformer。
- en: V Results and analysis
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V 结果与分析
- en: V-A Overall performance
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-A 总体性能
- en: 'TABLE II: Performance comparison of Audit-LLM with six baselines for insider
    threat detection. The best and second-best results are boldfaced and underlined,
    respectively. An upward arrow ($\uparrow$) indicates the lower the better.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 表II：Audit-LLM与六个基线模型在内部威胁检测中的性能比较。最佳和第二最佳结果分别用粗体和下划线标记。向上的箭头（$\uparrow$）表示越低越好。
- en: '| Model | CERT r4.2 | CERT r5.2 | PicoDomain |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | CERT r4.2 | CERT r5.2 | PicoDomain |'
- en: '| Prec $\uparrow$ |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 精确度 $\uparrow$ |'
- en: '| DeepLog | 0.684 | 0.715 | 0.335 | 0.743 | 0.728 | 0.776 | 0.264 | 0.801 |
    0.728 | 0.746 | 0.752 | 0.754 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| DeepLog | 0.684 | 0.715 | 0.335 | 0.743 | 0.728 | 0.776 | 0.264 | 0.801 |
    0.728 | 0.746 | 0.752 | 0.754 |'
- en: '| LMTracker | 0.782 | 0.829 | 0.217 | 0.856 | 0.765 | 0.794 | 0.216 | 0.821
    | 0.902 | 0.918 | 0.095 | 0.897 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| LMTracker | 0.782 | 0.829 | 0.217 | 0.856 | 0.765 | 0.794 | 0.216 | 0.821
    | 0.902 | 0.918 | 0.095 | 0.897 |'
- en: '| CATE | 0.885 | 0.892 | 0.289 | 0.928 | 0.893 | 0.906 | 0.324 | 0.932 | -
    | - | - | - |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| CATE | 0.885 | 0.892 | 0.289 | 0.928 | 0.893 | 0.906 | 0.324 | 0.932 | -
    | - | - | - |'
- en: '| LAN | 0.876 | 0.886 | 0.142 | 0.934 | 0.883 | 0.891 | 0.099 | 0.902 | 0.874
    | 0.886 | 0.122 | 0.862 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| LAN | 0.876 | 0.886 | 0.142 | 0.934 | 0.883 | 0.891 | 0.099 | 0.902 | 0.874
    | 0.886 | 0.122 | 0.862 |'
- en: '| LogPrompt | 0.861 | 0.875 | 0.324 | 0.841 | 0.852 | 0.862 | 0.328 | 0.873
    | 0.771 | 0.804 | 0.293 | 0.795 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| LogPrompt | 0.861 | 0.875 | 0.324 | 0.841 | 0.852 | 0.862 | 0.328 | 0.873
    | 0.771 | 0.804 | 0.293 | 0.795 |'
- en: '| LogGPT | 0.911 | 0.914 | 0.184 | 0.926 | 0.905 | 0.907 | 0.116 | 0.918 |
    0.802 | 0.824 | 0.196 | 0.834 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| LogGPT | 0.911 | 0.914 | 0.184 | 0.926 | 0.905 | 0.907 | 0.116 | 0.918 |
    0.802 | 0.824 | 0.196 | 0.834 |'
- en: '| Audit-LLM | 0.943 | 0.958 | 0.037 | 0.961 | 0.941 | 0.956 | 0.039 | 0.959
    | 0.914 | 0.927 | 0.067 | 0.931 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| Audit-LLM | 0.943 | 0.958 | 0.037 | 0.961 | 0.941 | 0.956 | 0.039 | 0.959
    | 0.914 | 0.927 | 0.067 | 0.931 |'
- en: 'To answer RQ1, we evaluate the performance of our proposed Audit-LLM and six
    competitive baselines for the insider threat detection task on three public datasets.
    We present the results of the involved models in Table [II](#S5.T2 "TABLE II ‣
    V-A Overall performance ‣ V Results and analysis ‣ Audit-LLM: Multi-Agent Collaboration
    for Log-based Insider Threat Detection"). Among these metrics, the higher the
    precision, detection rate, and accuracy, the better overall performance. Contrarily,
    the lower the False Positive Rate (FPR), the fewer false positives that cause
    false alarms.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '为回答RQ1，我们评估了我们提出的Audit-LLM和六个竞争基线模型在三个公共数据集上的内部威胁检测任务的性能。我们在表[II](#S5.T2 "TABLE
    II ‣ V-A Overall performance ‣ V Results and analysis ‣ Audit-LLM: Multi-Agent
    Collaboration for Log-based Insider Threat Detection")中展示了涉及模型的结果。在这些指标中，精确度、检测率和准确度越高，整体性能越好。相反，假阳性率（FPR）越低，假警报造成的假阳性就越少。'
- en: Generally, comparing the model performance on CERT r4.2 against that on CERT
    r5.2, we can observe that the model mostly performs relatively better on the former
    than on the latter dataset. It could be explained by the fact that the r4.2 version
    of CERT is a “dense needle” dataset that contains more insiders and malicious
    activities than the r5.2 version. The more severe category imbalance problem results
    in difficulties for the model to classify the activities correctly. In particular,
    our proposed Audit-LLM performs the best among the models, with a noticeable performance
    improvement over the other six baselines. For instance, on the CERT r4.2 dataset,
    Audit-LLM presents an improvement of 21.8%, 10.5%, 3.3%, 2.7%, 12%, and 3.5% in
    terms of accuracy against the DeepLog, LMTracker, CATE, LAN, LogPrompt, and LogGPT
    models, respectively. These overwhelming results indicate that our Audit-LLM leads
    to consistent gains across different datasets.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，将模型在CERT r4.2上的性能与在CERT r5.2上的性能进行比较，我们可以观察到模型在前者的数据集上表现普遍较好。这可以解释为r4.2版本的CERT是一个“密集针”数据集，比r5.2版本包含更多的内部人员和恶意活动。更严重的类别不平衡问题导致模型难以正确分类活动。特别地，我们提出的Audit-LLM在所有模型中表现最佳，相较于其他六个基线模型有显著的性能提升。例如，在CERT
    r4.2数据集上，Audit-LLM在准确度方面相较于DeepLog、LMTracker、CATE、LAN、LogPrompt和LogGPT模型分别提高了21.8%、10.5%、3.3%、2.7%、12%和3.5%。这些压倒性的结果表明我们的Audit-LLM在不同数据集上都带来了持续的收益。
- en: For all LLM-based methods, namely LogPrompt, LogGPT, and Audit-LLM, their performance
    on the CERT dataset is significantly better than on the PicoDomain dataset. A
    similar trend is observed with Audit-LLM, where the accuracy decreases by up to
    3% compared to its performance on the CERT dataset. The reason is that, compared
    to CERT which includes more user behavior logs such as email communications and
    accessed website content, PicoDomain comprises more traffic and system activity
    logs. LLM inherently possesses strong natural language understanding capabilities,
    thus enabling it to effectively leverage email content or website content summaries
    for insider threat detection on the CERT dataset. Note that CATE (Xiao et al.,
    [2024](#bib.bib33)) integrates organizational structure information and psychological
    data (user profile data) for each user into a unified table, which is an integral
    part of the model and therefore not reproducible in terms of performance within
    PicoDomain.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有基于 LLM 的方法，即 LogPrompt、LogGPT 和 Audit-LLM，它们在 CERT 数据集上的表现明显优于在 PicoDomain
    数据集上的表现。Audit-LLM 也观察到了类似的趋势，在 CERT 数据集上的准确率比 PicoDomain 数据集下降了最多 3%。原因是，相比包含更多用户行为日志（如电子邮件通讯和访问的网站内容）的
    CERT，PicoDomain 包含更多的流量和系统活动日志。LLM 天生具有强大的自然语言理解能力，因此能有效利用电子邮件内容或网站内容摘要来检测 CERT
    数据集中的内部威胁。注意，CATE (Xiao et al., [2024](#bib.bib33)) 将组织结构信息和每个用户的心理数据（用户档案数据）整合到一个统一的表格中，这是模型的一个
    integral 部分，因此在 PicoDomain 中的性能无法复现。
- en: When zooming in on the False Positive Rate (FPR), it can be observed that the
    FPRs of Audit-LLM are 3.7%, 3.9%, and 6.7% on CERT r4.2, r5.2, and Picodomain,
    respectively, lower than all the baselines by at least 1.47%, 0.8%, and 2.8% on
    three datasets. These results indicate that Audit-LLM can well reduce the number
    of false positives, which has great value when the investigation budget is finite.
    In addition, LMTracker demonstrates the best performance in the baseline on PicoDomain,
    achieving 90.2% precision, 91.8% detection rate, 9.5% false positive rate, and
    89.7% accuracy. This could be attributed to LMTracker’s use of heterogeneous graphs
    to model relationships between computers and users, specifically focusing on designing
    models for lateral movement.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 当放大查看假阳性率（FPR）时，可以观察到 Audit-LLM 在 CERT r4.2、r5.2 和 Picodomain 上的 FPR 分别为 3.7%、3.9%
    和 6.7%，比所有基准低至少 1.47%、0.8% 和 2.8%。这些结果表明，Audit-LLM 能够有效减少假阳性数量，对于调查预算有限的情况具有极大的价值。此外，LMTracker
    在 PicoDomain 基准上表现最佳，精度达到 90.2%、检测率 91.8%、假阳性率 9.5% 和准确率 89.7%。这可能归因于 LMTracker
    利用异构图来建模计算机和用户之间的关系，特别是专注于设计用于横向移动的模型。
- en: V-B Ablation study in Audit-LLM
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-B 消融研究在 Audit-LLM 中
- en: 'TABLE III: Ablation study results of Audit-LLM on CERT r4.2, r5.2, and Picodomain.
    The biggest drop in each column is appended with $\downharpoonright$.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 表 III：Audit-LLM 在 CERT r4.2、r5.2 和 Picodomain 上的消融研究结果。每列的最大下降值后附有 $\downharpoonright$。
- en: '| Model Variants | CERT r4.2 | CERT r5.2 | PicoDomain |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 模型变体 | CERT r4.2 | CERT r5.2 | PicoDomain |'
- en: '| Prec | DR | FPR | Acc | Prec | DR | FPR | Acc | Prec | DR | FPR | Acc |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 精度 | 召回率 | 假阳性率 | 准确率 | 精度 | 召回率 | 假阳性率 | 准确率 | 精度 | 召回率 | 假阳性率 | 准确率 |'
- en: '| Vanilla (GPT-3.5-turbo) | 0.659 | 0.673 | 0.342 | 0.662 | 0.629 | 0.631 |
    0.264 | 0.621 | 0.608 | 0.616 | 0.402 | 0.610 |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| Vanilla (GPT-3.5-turbo) | 0.659 | 0.673 | 0.342 | 0.662 | 0.629 | 0.631 |
    0.264 | 0.621 | 0.608 | 0.616 | 0.402 | 0.610 |'
- en: '| Audit-LLM w/o CoT | 0.693$\downharpoonright$ |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| Audit-LLM 无 CoT | 0.693$\downharpoonright$ |'
- en: '| Audit-LLM w/o Decomp | 0.846 | 0.856 | 0.172 | 0.834 | 0.823 | 0.821 | 0.189
    | 0.812 | 0.824 | 0.834 | 0.192 | 0.821 |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| Audit-LLM 无 Decomp | 0.846 | 0.856 | 0.172 | 0.834 | 0.823 | 0.821 | 0.189
    | 0.812 | 0.824 | 0.834 | 0.192 | 0.821 |'
- en: '| Audit-LLM w/o tools | 0.876 | 0.883 | 0.137 | 0.871 | 0.867 | 0.877 | 0.128
    | 0.863 | 0.841 | 0.852 | 0.313 | 0.835 |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| Audit-LLM 无工具 | 0.876 | 0.883 | 0.137 | 0.871 | 0.867 | 0.877 | 0.128 | 0.863
    | 0.841 | 0.852 | 0.313 | 0.835 |'
- en: '| Audit-LLM w/o EMAD | 0.921 | 0.935 | 0.069 | 0.946 | 0.932 | 0.941 | 0.054
    | 0.948 | 0.904 | 0.924 | 0.072 | 0.923 |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| Audit-LLM 无 EMAD | 0.921 | 0.935 | 0.069 | 0.946 | 0.932 | 0.941 | 0.054
    | 0.948 | 0.904 | 0.924 | 0.072 | 0.923 |'
- en: '| Audit-LLM (original) | 0.943 | 0.958 | 0.037 | 0.961 | 0.941 | 0.956 | 0.039
    | 0.959 | 0.914 | 0.927 | 0.067 | 0.931 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| Audit-LLM（原始） | 0.943 | 0.958 | 0.037 | 0.961 | 0.941 | 0.956 | 0.039 | 0.959
    | 0.914 | 0.927 | 0.067 | 0.931 |'
- en: 'For RQ2, we perform an ablation study by comparing Audit-LLM with its variants
    to analyze the effectiveness of each component. Specifically, we produce five
    variants for comparison: (1) “Vanilla” that removes all agent involvement, providing
    only the most basic task prompts to the LLM, (2) “Audit-LLM w/o CoT” that allows
    the LLM to make one-step decisions without employing reasoning through CoT, (3)
    “Audit-LLM w/o Decomp” that removes the Decomposer, thereby not delineating the
    subtasks that need to be accomplished, and relies solely on tools to assist the
    Executor in making decisions, (4) “Audit-LLM w/o tools” that removes the use of
    tools and allows the Executor to make decisions based on the log entries within
    the current input, (5) “Audit-LLM w/o EMAD” that removes the evidence-based multi-agent
    debate process, adopting the initial decision made by the Executor. The results
    are presented in Table [III](#S5.T3 "TABLE III ‣ V-B Ablation study in Audit-LLM
    ‣ V Results and analysis ‣ Audit-LLM: Multi-Agent Collaboration for Log-based
    Insider Threat Detection").'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '对于 RQ2，我们通过将 Audit-LLM 与其变体进行比较，进行了一项消融研究，以分析每个组件的有效性。具体而言，我们产生了五种变体进行比较：（1）“Vanilla”去除所有代理参与，仅向
    LLM 提供最基本的任务提示，（2）“Audit-LLM w/o CoT”允许 LLM 在不通过 CoT 进行推理的情况下做出一步决策，（3）“Audit-LLM
    w/o Decomp”去除 Decomposer，从而不划分需要完成的子任务，仅依赖工具协助 Executor 做决策，（4）“Audit-LLM w/o
    tools”去除工具的使用，并允许 Executor 基于当前输入中的日志条目做决策，（5）“Audit-LLM w/o EMAD”去除基于证据的多代理辩论过程，采用
    Executor 所做的初步决策。结果见表格 [III](#S5.T3 "TABLE III ‣ V-B Ablation study in Audit-LLM
    ‣ V Results and analysis ‣ Audit-LLM: Multi-Agent Collaboration for Log-based
    Insider Threat Detection")。'
- en: 'From Table [III](#S5.T3 "TABLE III ‣ V-B Ablation study in Audit-LLM ‣ V Results
    and analysis ‣ Audit-LLM: Multi-Agent Collaboration for Log-based Insider Threat
    Detection"), we can observe that removing any component in Audit-LLM leads to
    a decrease in the performance, indicating that all components in Audit-LLM contribute
    to the model performance. Besides “Vanilla”, the largest impact on model performance
    comes from removing the CoT process, indicating that conducting log auditing in
    a single step may overlook malicious behaviors, whereas decomposing it into sub-tasks
    allows for a more comprehensive log auditing. Moreover, the “Audit-LLM w/o EMAD”
    shows minimal impact on model performance degradation. This may be attributed
    to the assistance of CoT, which mitigates the complexity of the ITD task, consequently
    diminishing the potential for LLM hallucinations. Thus, EMAD corrects only a small
    amount of unfaithful hallucinations.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '从表格 [III](#S5.T3 "TABLE III ‣ V-B Ablation study in Audit-LLM ‣ V Results and
    analysis ‣ Audit-LLM: Multi-Agent Collaboration for Log-based Insider Threat Detection")
    可以观察到，移除 Audit-LLM 中的任何组件都会导致性能下降，这表明 Audit-LLM 中的所有组件都对模型性能有贡献。除了“Vanilla”之外，对模型性能影响最大的来自移除
    CoT 过程，这表明在单一步骤中进行日志审计可能会忽视恶意行为，而将其分解为子任务则可以进行更全面的日志审计。此外，“Audit-LLM w/o EMAD”对模型性能降级的影响最小。这可能归因于
    CoT 的帮助，它减轻了 ITD 任务的复杂性，从而降低了 LLM 错觉的潜力。因此，EMAD 仅纠正了少量的不真实错觉。'
- en: By comparing “Audit-LLM w/o Decomp” with “Audit-LLM (original)”, we observe
    a notable decline in model performance. Specifically, “Audit-LLM w/o Decomp” shows
    a decrease in accuracy by 12.7%, 14.7%, and 11% on CERT r4.2, r5.2, and PicoDomain,
    respectively. These results suggest that the Decomposer can break down ITD into
    more manageable sub-tasks based on multiple log data sources. By generating a
    series of intermediate steps before reaching the final result, this approach enhances
    the LLM’s reasoning capabilities. In addition, “Audit-LLM w/o tools” loses the
    performance competition to the original Audt-LLM on three datasets. For example,
    ”Audit-LLM w/o tools” exhibits increased false positive rates compared to ”Audit-LLM
    (original)” on CERT r4.2, r5.2, and PicoDomain, with increases of 28.7%, 28.9%,
    and 22.6%, respectively. This phenomenon demonstrates that the contextual information
    provided by tools helps the Executor to eliminate some anomalies within the input
    window that appear suspicious but are actually benign behaviors.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将“Audit-LLM w/o Decomp”与“Audit-LLM (original)”进行比较，我们观察到模型性能显著下降。具体而言，“Audit-LLM
    w/o Decomp”在 CERT r4.2、r5.2 和 PicoDomain 上的准确率分别下降了 12.7%、14.7% 和 11%。这些结果表明，Decomposer
    可以根据多个日志数据源将 ITD 拆分为更易于管理的子任务。通过在达到最终结果之前生成一系列中间步骤，这种方法增强了 LLM 的推理能力。此外，“Audit-LLM
    w/o tools”在三个数据集上输给了原始的 Audit-LLM。例如，与“Audit-LLM (original)”相比，“Audit-LLM w/o
    tools”在 CERT r4.2、r5.2 和 PicoDomain 上的假阳性率分别增加了 28.7%、28.9% 和 22.6%。这一现象表明，工具提供的上下文信息帮助
    Executor 消除输入窗口内看似可疑但实际上是良性行为的异常。
- en: V-C Impact of base LLMs
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-C 基础 LLM 的影响
- en: '![Refer to caption](img/82882aed01f0028a890fab713cc4c128.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/82882aed01f0028a890fab713cc4c128.png)'
- en: (a) Performance on CERT r4.2s.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 在 CERT r4.2 上的表现。
- en: '![Refer to caption](img/da9e53ed08b61d4743e8f6af4b2b1a02.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/da9e53ed08b61d4743e8f6af4b2b1a02.png)'
- en: (b) Performance on CERT r5.2.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 在 CERT r5.2 上的表现。
- en: 'Figure 4: Performance of Audit-LLM with different base LLMs.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：不同基础 LLM 下 Audit-LLM 的表现。
- en: 'Due to Audit-LLM’s significant dependence on the natural language understanding
    and reasoning abilities of the base LLM, it is of interest to investigate the
    impact of various base LLMs on model performance. To answer RQ3, we employed GPT-3.5-turbo,
    Llama2-7B, Llama3-8B-instruct, ChatGLM3-6B, and ChatGLM4 (Zhipuai) ([zhipuai,](#bib.bib37)
    ) for evaluation. For simplicity, we focus our examination solely on the performance
    of these LLMs on CERT r4.2 and r5.2. The results are shown in Fig. [V-C](#S5.SS3
    "V-C Impact of base LLMs ‣ V Results and analysis ‣ Audit-LLM: Multi-Agent Collaboration
    for Log-based Insider Threat Detection").'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '由于 Audit-LLM 对基础 LLM 的自然语言理解和推理能力有显著依赖，因此有必要研究不同基础 LLM 对模型性能的影响。为了解答 RQ3，我们采用了
    GPT-3.5-turbo、Llama2-7B、Llama3-8B-instruct、ChatGLM3-6B 和 ChatGLM4 (Zhipuai) ([zhipuai,](#bib.bib37))
    进行评估。为简化起见，我们仅关注这些 LLM 在 CERT r4.2 和 r5.2 上的表现。结果如图 [V-C](#S5.SS3 "V-C Impact
    of base LLMs ‣ V Results and analysis ‣ Audit-LLM: Multi-Agent Collaboration for
    Log-based Insider Threat Detection") 所示。'
- en: 'Overall, we find that the performance of Audit-LLM maintains robust performance
    across various base LLMs, indicating that the proposed Audit-LLM does not impose
    stringent requirements on the language comprehension skills of the base LLMs.
    The best performance was obtained with GPT-3.5-turbo-0125 on CERT r4.2. Particularly,
    GPT-3.5-turbo-0125 shows a maximum accuracy gap of 5.8% compared to other base
    language models on the CERT r4.2 dataset, with a minimum gap of 0.08%. This phenomenon
    may be attributed to several factors: Firstly, GPT-3.5-Turbo-0125 utilized through
    API calls incorporates significantly higher parameter counts compared to locally
    executable base language models such as LLama2-7B and ChatGLM3-6B. This implies
    that GPT-3.5-Turbo possesses enhanced learning and inference capabilities when
    handling large-scale datasets, as it can leverage more parameters to capture complex
    patterns and features within the dataset. Secondly, as mentioned, our CoT process
    is implemented using the LangChain Python library, which was originally tailored
    for adaptations to the GPT series. Such optimizations encompass model invocation
    methods, data processing, and task-specific adaptations, thereby enhancing the
    precision of GPT-3.5-Turbo-based agents during the execution of the Chain of Thought
    (CoT) process and the invocation of tools.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 总体来看，我们发现 Audit-LLM 在各种基础 LLM 上表现稳健，这表明所提出的 Audit-LLM 对基础 LLM 的语言理解能力没有严格要求。在
    CERT r4.2 数据集上，GPT-3.5-turbo-0125 的性能最佳。特别是，GPT-3.5-turbo-0125 与其他基础语言模型在 CERT
    r4.2 数据集上的最大准确率差距为 5.8%，最小差距为 0.08%。这一现象可能归因于几个因素：首先，通过 API 调用的 GPT-3.5-Turbo-0125
    相比于本地可执行的基础语言模型，如 LLama2-7B 和 ChatGLM3-6B，具有显著更高的参数量。这意味着，GPT-3.5-Turbo 在处理大规模数据集时具有更强的学习和推理能力，因为它可以利用更多的参数来捕捉数据集中的复杂模式和特征。其次，正如前面提到的，我们的
    CoT 过程是使用 LangChain Python 库实现的，该库最初是为 GPT 系列的适配而量身定制的。这些优化包括模型调用方法、数据处理和任务特定的适配，从而在执行思维链（CoT）过程和调用工具时，提高了基于
    GPT-3.5-Turbo 的代理的精确度。 |
- en: V-D Analysis of generated responses
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-D 生成响应分析
- en: 'TABLE IV: The responses generated by Audit-LLM across three scenarios.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 表 IV：Audit-LLM 在三种情景下生成的响应。 |
- en: '| scenario: Benign |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| 情景：良性 |'
- en: '| Logon: Logon frequency is within normal range. |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| 登录：登录频率在正常范围内。 |'
- en: '| Website: Websites visited are trusted. |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| 网站：访问的网站是可信的。 |'
- en: '| Drive: Driver usage within normal range. |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| 驱动器：驱动器使用量在正常范围内。 |'
- en: '| Suspicious: No suspicious behavior detected. |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| 可疑：未检测到可疑行为。 |'
- en: '| Basis of Judgment: Logon, website, and driver. |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| 判断依据：登录、网站和驱动器。 |'
- en: '| Decision: Benign |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| 决策：良性 |'
- en: '| scenario: Data leakage |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| 情景：数据泄露 |'
- en: '| Logon: Logs in 4 times, above average. |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| 登录：登录次数 4 次，超过平均水平。 |'
- en: '| Website: Visited untrusted website ”http://wikileaks.org/xxx.php”. |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| 网站：访问了不可信的网站 ”http://wikileaks.org/xxx.php”。 |'
- en: '| Drive: Drive usage within normal range. |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| 驱动器：驱动器使用量在正常范围内。 |'
- en: '| Suspicious: Visiting ”http://wikileaks.org/xxx.php” is suspicious. |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| 可疑：访问 ”http://wikileaks.org/xxx.php” 是可疑的。 |'
- en: '| Basis of judgment: Legitimacy of website visits. |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| 判断依据：网站访问的合法性。 |'
- en: '| Decision: Malicious |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| 决策：恶意 |'
- en: '| scenario: Insider keylogging |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| 情景：内部键盘记录 |'
- en: '| Logon: Logs in 3 times, above average. |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| 登录：登录次数 3 次，超过平均水平。 |'
- en: '| Website: Visited websites related to keylogging and downloaded suspicious
    payloads. |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| 网站：访问了与键盘记录相关的网站并下载了可疑的负载。 |'
- en: '| Device: The user has a device usage frequency of 2.0 per day, which is within
    the average range. |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| 设备：用户的设备使用频率为每天 2.0 次，属于平均范围内。'
- en: '| Email: The content expresses dissatisfaction, claiming it’s irreplaceability.
    |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| 电子邮件：内容表达不满，声称无法替代。 |'
- en: '| Download: Executable file downloaded. |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| 下载：可执行文件已下载。 |'
- en: '| Suspicious: The high logon frequency, the content of the email, and the executable
    file downloaded. |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| 可疑：高频率的登录、电子邮件内容和下载的可执行文件。 |'
- en: '| Basis of judgment: The combination of logon, job dissatisfaction, and download
    of executable file. |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| 判断依据：登录、工作不满和下载可执行文件的组合。 |'
- en: '| Decision: Malicious |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| 决策：恶意 |'
- en: 'Improving explanations for the model’s detection of insider threats has been
    challenging because deep learning methods are often viewed as black boxes with
    opaque decision-making processes. This complicates the task for log auditors who
    need to quickly identify and prevent insider threats. To address RQ4, we present
    responses generated by Audit-LLM in three scenarios of insider threats from the
    CERT dataset, specifically the final responses generated by the Executor. These
    three scenarios are concurrently present in both CERT r4.2 and r5.2 datasets,
    namely, benign, data leakage and insider keylogging. Note that due to space constraints,
    we have made some simplifications to the response generated by Audit-LLM, removing
    redundant words while preserving the original meaning. The results are presented
    in Table [IV](#S5.T4 "TABLE IV ‣ V-D Analysis of generated responses ‣ V Results
    and analysis ‣ Audit-LLM: Multi-Agent Collaboration for Log-based Insider Threat
    Detection").'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '改善模型对内部威胁的检测解释一直是一个挑战，因为深度学习方法通常被视为黑箱，决策过程不透明。这使得日志审计员在快速识别和防止内部威胁时面临困难。为了回应RQ4，我们展示了Audit-LLM在CERT数据集的三个内部威胁场景中生成的响应，特别是Executor生成的最终响应。这三个场景同时存在于CERT
    r4.2和r5.2数据集中，即，良性、数据泄露和内部键盘记录。注意，由于空间限制，我们对Audit-LLM生成的响应进行了简化，删除了冗余词汇，同时保留了原意。结果见表[IV](#S5.T4
    "TABLE IV ‣ V-D Analysis of generated responses ‣ V Results and analysis ‣ Audit-LLM:
    Multi-Agent Collaboration for Log-based Insider Threat Detection")。'
- en: 'As shown in Table [IV](#S5.T4 "TABLE IV ‣ V-D Analysis of generated responses
    ‣ V Results and analysis ‣ Audit-LLM: Multi-Agent Collaboration for Log-based
    Insider Threat Detection"), Audit-LLM is capable of providing accurate responses
    for various subtasks and accurately identifying decisive factors based on the
    outcomes of these sub-tasks. For example, in the scenario of insider keylogging,
    Audit-LLM identified three results: above-normal login frequency, abnormal email
    content, and suspicious executable file downloads. It combines these findings
    to conclude that the user exhibited anomalous behavior. Relatively, when there
    is no email correspondence or file downloads recorded in the logs, Audit-LLM refrains
    from conducting corresponding checks, thereby reducing computational overhead.
    Further, when all sub-tasks do not exhibit anomaly results, Audit-LLM arrives
    at a benign conclusion. In summary, Audit-LLM can provide auditors with audit
    opinions that are comprehensible to humans. Research has shown that automated
    auditing methods based on LLM can offer certain remediation suggestions (Qi et al.,
    [2023](#bib.bib7)). However, in our pilot experiments, we find that without the
    assistance of a specialized knowledge base, these suggestions are often not applicable.
    Therefore, we do not discuss them in this section.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '如表[IV](#S5.T4 "TABLE IV ‣ V-D Analysis of generated responses ‣ V Results and
    analysis ‣ Audit-LLM: Multi-Agent Collaboration for Log-based Insider Threat Detection")所示，Audit-LLM能够为各种子任务提供准确的响应，并根据这些子任务的结果准确识别决定性因素。例如，在内部键盘记录的场景中，Audit-LLM识别出三种结果：高于正常的登录频率、异常的电子邮件内容和可疑的可执行文件下载。它将这些发现结合起来，得出用户表现出异常行为的结论。相对地，当日志中没有记录电子邮件通信或文件下载时，Audit-LLM会避免进行相应的检查，从而减少计算开销。此外，当所有子任务都没有表现出异常结果时，Audit-LLM会得出良性的结论。总之，Audit-LLM可以为审计员提供易于理解的审计意见。研究表明，基于LLM的自动化审计方法可以提供一定的修正建议（Qi等人，[2023](#bib.bib7)）。然而，在我们的初步实验中，我们发现没有专业知识库的协助，这些建议通常不适用。因此，我们在本节中未对此进行讨论。'
- en: V-E Case study
  id: totrans-214
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-E 案例研究
- en: 'To answer RQ5, we deploy Audit-LLM in an actual operational system environment
    and conduct simulated penetration tests to evaluate its performance in real-world
    scenarios. We gather logs exclusively from the native logging systems of the Linux
    hosts, mainly authorization logs, HTTP logs, network traffic, and other sources.
    In total, we monitored 21 hosts for 5 days which were used daily for product development.
    During this period, we simulated four types of penetration test activities including
    MITRE ATT&CK framework’s Forge Web Credentials (T1606), Content Injection (T1586),
    Network sniffing (T1040), and Compromise Accounts (T1133). A short description
    of each attack is shown in Table [V](#S5.T5 "TABLE V ‣ V-E Case study ‣ V Results
    and analysis ‣ Audit-LLM: Multi-Agent Collaboration for Log-based Insider Threat
    Detection").'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '为了回答 RQ5，我们在实际操作系统环境中部署了 Audit-LLM，并进行了模拟渗透测试以评估其在实际场景中的性能。我们仅从 Linux 主机的原生日志系统中收集日志，主要包括授权日志、HTTP
    日志、网络流量以及其他来源。总共，我们监控了 21 台主机，持续 5 天，这些主机每日用于产品开发。在此期间，我们模拟了四种类型的渗透测试活动，包括 MITRE
    ATT&CK 框架的伪造 Web 凭证（T1606）、内容注入（T1586）、网络嗅探（T1040）和账户泄露（T1133）。每种攻击的简要描述见表格 [V](#S5.T5
    "TABLE V ‣ V-E Case study ‣ V Results and analysis ‣ Audit-LLM: Multi-Agent Collaboration
    for Log-based Insider Threat Detection")。'
- en: Audit-LLM can effectively detect all four types of penetration testing activities.
    Specifically, for Compromise Accounts, Audit-LLM identifies numerous failed login
    attempts within a short timeframe in authorization logs, triggered by testers
    attempting brute-force login attacks on target hosts. For Content Injection, Audit-LLM
    performs a thorough analysis of HTTP logs to detect content injection attacks.
    It examines both the payload transmitted in requests and the content retrieved
    in responses, pinpointing suspicious and potentially malicious activities indicative
    of content injection attempts. Furthermore, for Forge Web Credentials, Audit-LLM
    ensures comprehensive detection capabilities by meticulously analyzing header
    information, cookies, session tokens, and authentication parameters to identify
    Forge web credentials attacks. Moreover, for Network sniffing, Audit-LLM can identify
    explicit network sniffing behaviors by analyzing network traffic logs. For example,
    this occurs when a host sends numerous requests using different protocols to various
    target hosts but fails to receive responses for all of them.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: Audit-LLM 能够有效检测所有四种渗透测试活动。具体而言，对于账户泄露，Audit-LLM 通过在授权日志中识别短时间内大量的登录失败尝试来检测这种活动，这些尝试由测试人员对目标主机进行暴力破解攻击引发。对于内容注入，Audit-LLM
    对 HTTP 日志进行彻底分析，以检测内容注入攻击。它检查请求中传输的有效负载和响应中检索的内容，准确定位出具有内容注入尝试的可疑和潜在恶意活动。此外，对于伪造
    Web 凭证，Audit-LLM 通过详细分析头信息、cookies、会话令牌和认证参数来确保全面检测能力，从而识别伪造 Web 凭证攻击。而对于网络嗅探，Audit-LLM
    可以通过分析网络流量日志来识别明确的网络嗅探行为。例如，当主机使用不同协议向多个目标主机发送大量请求，但没有收到所有请求的响应时，就会发生这种情况。
- en: 'TABLE V: Real-world attack scenarios with short descriptions.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '表 V: 带有简短描述的真实世界攻击场景。'
- en: '| Technique | ID | Description |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| 技术 | ID | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '|'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Compromise &#124;'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 泄露 &#124;'
- en: '&#124; accounts &#124;'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 账户 &#124;'
- en: '| T1586 | Adversaries infiltrate existing accounts through various means, such
    as brute-force attacks, to obtain account credentials. |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| T1586 | 对手通过各种手段，如暴力破解攻击，渗透现有账户以获取账户凭证。 |'
- en: '|'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Content &#124;'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 内容 &#124;'
- en: '&#124; injection &#124;'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 注入 &#124;'
- en: '| T1659 | Adversaries inject malicious content into network traffic to gain
    system access and communicate with victims. |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| T1659 | 对手将恶意内容注入网络流量中，以获得系统访问权限并与受害者通信。 |'
- en: '|'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Forge web &#124;'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 伪造 Web &#124;'
- en: '&#124; credentials &#124;'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 凭证 &#124;'
- en: '| T1606 | Adversaries may forge web cookies that can be used to gain access
    to web applications or Internet services. |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| T1606 | 对手可能伪造网络 cookies，这些 cookies 可以用于访问 web 应用程序或互联网服务。 |'
- en: '|'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Network &#124;'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 网络 &#124;'
- en: '&#124; sniffing &#124;'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 嗅探 &#124;'
- en: '| T1040 | Network sniffing refers to using the network interface on a system
    to monitor or capture information sent over a wired or wireless connection. |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| T1040 | 网络嗅探指的是使用系统上的网络接口来监控或捕获通过有线或无线连接发送的信息。 |'
- en: V-F Cost analysis
  id: totrans-236
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-F 成本分析
- en: 'Thanks to online APIs, researchers can employ LLMs with extensive parameters
    even without having access to substantial GPU memory. However, the time and economic
    costs incurred by invoking these APIs remain a significant concern. To answer
    RQ6, we present in Figure [5](#S5.F5 "Figure 5 ‣ V-F Cost analysis ‣ V Results
    and analysis ‣ Audit-LLM: Multi-Agent Collaboration for Log-based Insider Threat
    Detection") the average latency, token usage, and economic cost of the two online
    LLM APIs used in our experiment: GPT-3.5 from OpenAI and GLM-4 from ZhipuAI, across
    four scenarios, namely, Benign behavior, Data leakage via drive, Data theft via
    Website, and Insider keylogging. All data in the experiment was recorded by Langsmith (LangChain,
    [b](#bib.bib38)).'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢在线API，研究人员即使没有大量GPU内存也可以使用具有广泛参数的LLM。然而，调用这些API所产生的时间和经济成本仍然是一个重大问题。为了回答RQ6，我们在图[5](#S5.F5
    "图5 ‣ V-F 成本分析 ‣ V 结果与分析 ‣ Audit-LLM：基于日志的内部威胁检测的多代理协作")中展示了在我们的实验中使用的两个在线LLM
    API：OpenAI的GPT-3.5和ZhipuAI的GLM-4，在四种场景下的平均延迟、令牌使用量和经济成本，即良性行为、通过驱动器的数据泄露、通过网站的数据盗窃和内部密钥记录。实验中的所有数据由Langsmith
    (LangChain, [b](#bib.bib38))记录。
- en: Overall, the cost of using LLM APIs for log analysis is substantial. Specifically,
    in the Insider Keylogging scenario, GPT-3.5 and GLM-4 consumed an average of 6,903
    and 20,313 tokens per single CoT process, respectively, costing 0.004$ and 0.21$
    per transaction. Comparatively, Insider keylogging and Data theft via website
    scenarios incur the highest token usage. This is because internal threats often
    involve extensive web browsing, necessitating Audit-LLM to validate the legitimacy
    of each website accessed. From the perspective of the base LLM, GPT-3.5 consumes
    fewer tokens compared to GLM-4. This is because the Langchain framework is more
    compatible with GPT-3.5, providing readily available interfaces for direct invocation.
    In contrast, the adaptation for GLM-4 is less developed, requiring indirect tool
    invocation through JSON formats.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，使用LLM API进行日志分析的成本是相当高的。特别是在内部密钥记录的场景中，GPT-3.5和GLM-4分别在单次CoT处理过程中平均消耗了6,903和20,313个令牌，分别花费了0.004$和0.21$每次交易。相比之下，内部密钥记录和通过网站的数据盗窃场景的令牌使用量最高。这是因为内部威胁通常涉及广泛的网页浏览，要求Audit-LLM验证每个访问网站的合法性。从基础LLM的角度来看，GPT-3.5消耗的令牌比GLM-4少。这是因为Langchain框架与GPT-3.5的兼容性更好，提供了直接调用的现成接口。相对而言，GLM-4的适配发展较少，需要通过JSON格式间接调用工具。
- en: '![Refer to caption](img/33060986f82869ed0adb9f960f00b92d.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/33060986f82869ed0adb9f960f00b92d.png)'
- en: 'Figure 5: The average latency, token usage, and economic costs of two online
    LLM APIs across four scenarios.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：两个在线LLM API在四种场景下的平均延迟、令牌使用量和经济成本。
- en: VI Conclusion and future work
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VI 结论与未来工作
- en: 'In this study, we have proposed a multi-agent log-based insider threat detection
    framework called Audit-LLM. Audit-LLM consists of three agents: the Decomposer,
    the Tool Builder, and the Executor. The Decomposer agent breaks down ITD into
    sub-tasks based on user activity types to construct a Chain-of-Thought (CoT) for
    auditing. The Tool Builder agent creates a set of task-specific, reusable tools
    for extracting contextual information beyond the input window. The Executor agent
    uses the generated tools to complete sub-tasks, classify user behavior, and provide
    human-readable justifications. Based on experimental results, Audit-LLM effectively
    leverages the inherent knowledge repository and natural language comprehension
    abilities of LLM to tackle log-based insider threat detection issues, while avoiding
    overfitting problems caused by class imbalance. Additionally, tools generated
    by the Tool Builder can efficiently extract statistical log information beyond
    the input window, thereby assisting the Executor in decision-making. Furthermore,
    to address the faithfulness hallucination issue, we propose pair-wise Evidence-based
    multi-agent debate. This approach involves two independent Executors to exchange
    results obtained from sub-tasks, and iteratively refine their results to improve
    outcome fidelity.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们提出了一个基于多代理的日志内部威胁检测框架，称为 Audit-LLM。Audit-LLM 包括三个代理：Decomposer、Tool
    Builder 和 Executor。Decomposer 代理根据用户活动类型将 ITD 分解为子任务，以构建审计的 Chain-of-Thought (CoT)。Tool
    Builder 代理创建一组任务特定的、可重复使用的工具，以提取超出输入窗口的上下文信息。Executor 代理使用生成的工具完成子任务、分类用户行为，并提供可读性强的解释。根据实验结果，Audit-LLM
    有效利用了 LLM 的内在知识库和自然语言理解能力来处理基于日志的内部威胁检测问题，同时避免了由类别不平衡引起的过拟合问题。此外，Tool Builder
    生成的工具可以有效提取超出输入窗口的统计日志信息，从而帮助 Executor 进行决策。此外，为了解决可信度幻觉问题，我们提出了基于证据的成对多代理辩论。这种方法涉及两个独立的
    Executors 交换从子任务中获得的结果，并迭代地完善结果，以提高结果的可靠性。
- en: In our future work, we aim to refine agent design to enhance the accuracy of
    internal threat detection, minimize false positives, and reduce token usage. Additionally,
    we intend to integrate a network threat knowledge base akin to MITRE ATT&CK ([MITRE,](#bib.bib39)
    ). Our goal is to explore the application of Retrieval Augmented Generation (RAG)
    to provide network security auditors with effective mitigation recommendations
    for addressing insider threats.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在未来的工作中，我们旨在完善代理设计，以提高内部威胁检测的准确性，减少假阳性，并降低令牌使用。此外，我们打算集成类似于 MITRE ATT&CK 的网络威胁知识库（[MITRE,](#bib.bib39)）。我们的目标是探索检索增强生成（RAG）的应用，为网络安全审计员提供有效的缓解建议，以应对内部威胁。
- en: References
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Homoliak et al. (2019) I. Homoliak, F. Toffalini, J. Guarnizo *et al.*, “Insight
    into insiders and IT: A survey of insider threat taxonomies, analysis, modeling,
    and countermeasures,” *ACM Comput. Surv.*, vol. 52, no. 2, pp. 30:1–30:40, 2019.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Homoliak et al. (2019) I. Homoliak, F. Toffalini, J. Guarnizo *等*，“内部人员与 IT
    的洞察：内部威胁分类、分析、建模和对策的调查，” *ACM Comput. Surv.*, 第 52 卷, 第 2 期, 第 30:1–30:40 页, 2019
    年。
- en: 'Du et al. (2017) M. Du, F. Li, G. Zheng, and V. Srikumar, “Deeplog: Anomaly
    detection and diagnosis from system logs through deep learning,” in *CCS*.   ACM,
    2017, pp. 1285–1298.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Du et al. (2017) M. Du, F. Li, G. Zheng, 和 V. Srikumar，“Deeplog: 从系统日志中通过深度学习进行异常检测和诊断，”
    *CCS*。 ACM, 2017, 第 1285–1298 页。'
- en: Le et al. (2021) D. C. Le, N. Zincir-Heywood, and M. I. Heywood, “Training regime
    influences to semi-supervised learning for insider threat detection,” in *IEEE
    Security and Privacy Workshops, SP Workshops 2021, San Francisco, CA, USA, May
    27, 2021*.   IEEE, 2021, pp. 13–18.
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Le et al. (2021) D. C. Le, N. Zincir-Heywood, 和 M. I. Heywood，“训练方案对半监督学习用于内部威胁检测的影响，”在
    *IEEE Security and Privacy Workshops, SP Workshops 2021, San Francisco, CA, USA,
    May 27, 2021*。 IEEE, 2021, 第 13–18 页。
- en: Li et al. (2023) X. Li, X. Li, J. Jia, and ohers, “A high accuracy and adaptive
    anomaly detection model with dual-domain graph convolutional network for insider
    threat detection,” *IEEE Trans. Inf. Forensics Secur.*, vol. 18, pp. 1638–1652,
    2023.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. (2023) X. Li, X. Li, J. Jia, 和其他人，“一种高精度和自适应的异常检测模型，基于双领域图卷积网络用于内部威胁检测，”
    *IEEE Trans. Inf. Forensics Secur.*, 第 18 卷, 第 1638–1652 页, 2023 年。
- en: 'Yuan and Wu (2021) S. Yuan and X. Wu, “Deep learning for insider threat detection:
    Review, challenges and opportunities,” *Comput. Secur.*, vol. 104, p. 102221,
    2021.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yuan 和 Wu (2021) S. Yuan 和 X. Wu，“深度学习在内部威胁检测中的应用：回顾、挑战与机遇，” *Comput. Secur.*,
    第 104 卷, 第 102221 页, 2021 年。
- en: Le and Zhang (2023) V. Le and H. Zhang, “An evaluation of log parsing with chatgpt,”
    *CoRR*, vol. abs/2306.01590, 2023.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Le 和 Zhang（2023）V. Le 和 H. Zhang，“使用 ChatGPT 进行日志解析的评估，”*CoRR*，卷 abs/2306.01590,
    2023。
- en: 'Qi et al. (2023) J. Qi, S. Huang, Z. Luan *et al.*, “Loggpt: Exploring chatgpt
    for log-based anomaly detection,” in *IEEE International Conference on High Performance
    Computing & Communications, Data Science & Systems, Smart City & Dependability
    in Sensor, Cloud & Big Data Systems & Application, HPCC/DSS/SmartCity/DependSys
    2023, Melbourne, Australia, December 17-21, 2023*.   IEEE, 2023, pp. 273–280.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qi 等（2023）J. Qi, S. Huang, Z. Luan *等*，“Loggpt：探索 ChatGPT 在基于日志的异常检测中的应用，”发表于
    *IEEE International Conference on High Performance Computing & Communications,
    Data Science & Systems, Smart City & Dependability in Sensor, Cloud & Big Data
    Systems & Application, HPCC/DSS/SmartCity/DependSys 2023, Melbourne, Australia,
    December 17-21, 2023*。   IEEE, 2023, 页码 273–280。
- en: 'Jin et al. (2024) J. Jin, B. Tang, M. Ma *et al.*, “Crimson: Empowering strategic
    reasoning in cybersecurity through large language models,” *CoRR*, vol. abs/2403.00878,
    2024.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jin 等（2024）J. Jin, B. Tang, M. Ma *等*，“Crimson：通过大语言模型增强网络安全中的战略推理，”*CoRR*，卷
    abs/2403.00878, 2024。
- en: 'Liu et al. (2024) Y. Liu, S. Tao, W. Meng *et al.*, “Logprompt: Prompt engineering
    towards zero-shot and interpretable log analysis,” in *ICSE*.   ACM, 2024, pp.
    364–365.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等（2024）Y. Liu, S. Tao, W. Meng *等*，“Logprompt：面向零样本和可解释日志分析的提示工程，”发表于 *ICSE*。   ACM,
    2024, 页码 364–365。
- en: 'Glasser and Lindauer (2013) J. Glasser and B. Lindauer, “Bridging the gap:
    A pragmatic approach to generating insider threat data,” in *2013 IEEE Symposium
    on Security and Privacy Workshops, San Francisco, CA, USA, May 23-24, 2013*.   IEEE
    Computer Society, 2013, pp. 98–104.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Glasser 和 Lindauer（2013）J. Glasser 和 B. Lindauer，“弥合差距：生成内部威胁数据的务实方法，”发表于 *2013
    IEEE Symposium on Security and Privacy Workshops, San Francisco, CA, USA, May
    23-24, 2013*。   IEEE Computer Society, 2013, 页码 98–104。
- en: Yu et al. (2024) X. Yu, R. Shi, P. Feng *et al.*, “Leveraging partial symmetry
    for multi-agent reinforcement learning,” in *AAAI*.   AAAI Press, 2024, pp. 17 583–17 590.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu 等（2024）X. Yu, R. Shi, P. Feng *等*，“利用部分对称性进行多智能体强化学习，”发表于 *AAAI*。   AAAI
    Press, 2024, 页码 17 583–17 590。
- en: Deng et al. (2024) X. Deng, L. Zhou, D. Dong *et al.*, “Enhancing multi-agent
    communication collaboration through gpt-based semantic information extraction
    and prediction,” in *ACM-TURC*.   ACM, 2024.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deng 等（2024）X. Deng, L. Zhou, D. Dong *等*，“通过基于 GPT 的语义信息提取和预测增强多智能体通信协作，”发表于
    *ACM-TURC*。   ACM, 2024。
- en: Ji et al. (2024) B. Ji, H. Liu, M. Du *et al.*, “Chain-of-thought improves text
    generation with citations in large language models,” in *AAAI*.   AAAI Press,
    2024, pp. 18 345–18 353.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ji 等（2024）B. Ji, H. Liu, M. Du *等*，“Chain-of-thought 改进了大语言模型中的文本生成与引用，”发表于
    *AAAI*。   AAAI Press, 2024, 页码 18 345–18 353。
- en: Brdiczka et al. (2012) O. Brdiczka, J. Liu, B. Price *et al.*, “Proactive insider
    threat detection through graph learning and psychological context,” in *2012 IEEE
    Symposium on Security and Privacy Workshops, San Francisco, CA, USA, May 24-25,
    2012*.   IEEE Computer Society, 2012, pp. 142–149.
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brdiczka 等（2012）O. Brdiczka, J. Liu, B. Price *等*，“通过图学习和心理背景主动检测内部威胁，”发表于 *2012
    IEEE Symposium on Security and Privacy Workshops, San Francisco, CA, USA, May
    24-25, 2012*。   IEEE Computer Society, 2012, 页码 142–149。
- en: 'Camiña et al. (2016) J. B. Camiña, R. Monroy, L. A. Trejo, and M. A. Medina-Pérez,
    “Temporal and spatial locality: An abstraction for masquerade detection,” *IEEE
    Trans. Inf. Forensics Secur.*, vol. 11, no. 9, pp. 2036–2051, 2016.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Camiña 等（2016）J. B. Camiña, R. Monroy, L. A. Trejo, 和 M. A. Medina-Pérez，“时间和空间局部性：伪装检测的抽象，”*IEEE
    Trans. Inf. Forensics Secur.*，卷 11, 期 9, 页码 2036–2051, 2016。
- en: Agrafiotis et al. (2016) I. Agrafiotis, A. Erola, M. Goldsmith, and S. Creese,
    “A tripwire grammar for insider threat detection,” in *Proceedings of the 8th
    ACM CCS International Workshop on Managing Insider Security Threats, MIST@CCS
    2016, Vienna, Austria, October 28, 2016*.   ACM, 2016, pp. 105–108.
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Agrafiotis 等（2016）I. Agrafiotis, A. Erola, M. Goldsmith, 和 S. Creese，“内部威胁检测的触发器语法，”发表于
    *第八届 ACM CCS 国际工作坊，内部安全威胁管理（MIST@CCS 2016），奥地利维也纳，2016年10月28日*。   ACM, 2016, 页码
    105–108。
- en: Magklaras and Furnell (2012) G. Magklaras and S. Furnell, “The insider threat
    prediction and specification language,” in *Ninth International Network Conference
    (INC 2012), Port Elizabeth, South Africa, July 11-12, 2012\. Proceedings*.   University
    of Plymouth, 2012, pp. 51–61.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Magklaras 和 Furnell（2012）G. Magklaras 和 S. Furnell，“内部威胁预测和规范语言，”发表于 *第九届国际网络会议（INC
    2012），南非开普敦，2012年7月11-12日. 会议论文集*。   University of Plymouth, 2012, 页码 51–61。
- en: Yuan et al. (2019) S. Yuan, P. Zheng, X. Wu, and Q. Li, “Insider threat detection
    via hierarchical neural temporal point processes,” in *2019 IEEE International
    Conference on Big Data (IEEE BigData), Los Angeles, CA, USA, December 9-12, 2019*.   IEEE,
    2019, pp. 1343–1350.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yuan et al. (2019) S. Yuan, P. Zheng, X. Wu 和 Q. Li，“通过层次神经时间点过程检测内部威胁，” 2019年
    IEEE 国际大数据会议（IEEE BigData），洛杉矶，加州，美国，2019年12月9-12日。   IEEE，2019，页 1343–1350。
- en: 'Liu et al. (2019) F. Liu, Y. Wen, D. Zhang *et al.*, “Log2vec: A heterogeneous
    graph embedding based approach for detecting cyber threats within enterprise,”
    in *Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications
    Security, CCS 2019, London, UK, November 11-15, 2019*, L. Cavallaro, J. Kinder,
    X. Wang, and J. Katz, Eds.   ACM, 2019, pp. 1777–1794.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2019) F. Liu, Y. Wen, D. Zhang *等人*，“Log2vec：一种基于异质图嵌入的企业网络威胁检测方法，”
    收录于 *2019 ACM SIGSAC 计算机与通信安全会议，CCS 2019，伦敦，英国，2019年11月11-15日*，L. Cavallaro, J.
    Kinder, X. Wang 和 J. Katz 主编。   ACM，2019，页 1777–1794。
- en: 'Fang et al. (2022) Y. Fang, C. Wang, Z. Fang, and C. Huang, “Lmtracker: Lateral
    movement path detection based on heterogeneous graph embedding,” *Neurocomputing*,
    vol. 474, pp. 37–47, 2022.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fang et al. (2022) Y. Fang, C. Wang, Z. Fang 和 C. Huang，“Lmtracker：基于异质图嵌入的横向移动路径检测，”
    *Neurocomputing*，卷 474，页 37–47，2022。
- en: 'Xu et al. (2024) J. Xu, J. W. Stokes, G. McDonald *et al.*, “Autoattacker:
    A large language model guided system to implement automatic cyber-attacks,” *CoRR*,
    vol. abs/2403.01038, 2024.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu et al. (2024) J. Xu, J. W. Stokes, G. McDonald *等人*，“Autoattacker：一个由大型语言模型指导的自动化网络攻击系统，”
    *CoRR*，卷 abs/2403.01038，2024。
- en: Fang et al. (2024) R. Fang, R. Bindu, A. Gupta, and D. Kang, “LLM agents can
    autonomously exploit one-day vulnerabilities,” *CoRR*, vol. abs/2404.08144, 2024.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fang et al. (2024) R. Fang, R. Bindu, A. Gupta 和 D. Kang，“LLM 代理可以自主利用一天漏洞，”
    *CoRR*，卷 abs/2404.08144，2024。
- en: 'Fayyazi et al. (2024) R. Fayyazi, R. Taghdimi, and S. J. Yang, “Advancing TTP
    analysis: Harnessing the power of encoder-only and decoder-only language models
    with retrieval augmented generation,” *CoRR*, vol. abs/2401.00280, 2024.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fayyazi et al. (2024) R. Fayyazi, R. Taghdimi 和 S. J. Yang，“推进 TTP 分析：利用仅编码器和仅解码器语言模型与检索增强生成的力量，”
    *CoRR*，卷 abs/2401.00280，2024。
- en: Karlsen et al. (2023) E. Karlsen, X. Luo, N. Zincir-Heywood, and M. I. Heywood,
    “Benchmarking large language models for log analysis, security, and interpretation,”
    *CoRR*, vol. abs/2311.14519, 2023.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Karlsen et al. (2023) E. Karlsen, X. Luo, N. Zincir-Heywood 和 M. I. Heywood，“大型语言模型在日志分析、安全性和解释方面的基准测试，”
    *CoRR*，卷 abs/2311.14519，2023。
- en: 'Conway-Smith and West (2024) B. Conway-Smith and R. L. West, “Toward autonomy:
    Metacognitive learning for enhanced AI performance,” in *AAAI*.   AAAI Press,
    2024, pp. 545–546.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Conway-Smith 和 West (2024) B. Conway-Smith 和 R. L. West，“走向自主：元认知学习以提升 AI 性能，”
    收录于 *AAAI*。   AAAI Press，2024，页 545–546。
- en: Bauer (1979) M. A. Bauer, “Programming by examples,” *Artif. Intell.*, vol. 12,
    no. 1, pp. 1–21, 1979.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bauer (1979) M. A. Bauer，“通过示例编程，” *Artif. Intell.*，卷 12，第 1 期，页 1–21，1979。
- en: 'Huang et al. (2023) L. Huang, W. Yu, W. Ma *et al.*, “A survey on hallucination
    in large language models: Principles, taxonomy, challenges, and open questions,”
    *CoRR*, vol. abs/2311.05232, 2023.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang et al. (2023) L. Huang, W. Yu, W. Ma *等人*，“对大型语言模型中的幻觉现象的调查：原理、分类、挑战及未解问题，”
    *CoRR*，卷 abs/2311.05232，2023。
- en: Kim et al. (2024) K. Kim, S. Lee, K. Huang *et al.*, “Can llms produce faithful
    explanations for fact-checking? towards faithful explainable fact-checking via
    multi-agent debate,” *CoRR*, vol. abs/2402.07401, 2024.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim et al. (2024) K. Kim, S. Lee, K. Huang *等人*，“大型语言模型能否为事实检查提供可靠解释？通过多智能体辩论实现*可靠的可解释性事实检查*，”
    *CoRR*，卷 abs/2402.07401，2024。
- en: 'LangChain (a) LangChain, “Langchain.” [Online]. Available: https://python.langchain.com/v0.2/docs/introduction/'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LangChain (a) LangChain，“Langchain。” [在线]。可用网址： https://python.langchain.com/v0.2/docs/introduction/
- en: '(30) OpenAI, “Gpt-3.5 turbo.” [Online]. Available: https://platform.openai.com/docs/models/gpt-3-5-turbo'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (30) OpenAI，“Gpt-3.5 turbo。” [在线]。可用网址： https://platform.openai.com/docs/models/gpt-3-5-turbo
- en: 'University (2020) C. M. University, “Insider threat test dataset,” Sep 2020\.
    [Online]. Available: https://kilthub.cmu.edu/articles/dataset/Insider_Threat_Test_Dataset/12841247'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: University (2020) C. M. University，“内部威胁测试数据集，” 2020年9月。[在线]。可用网址： https://kilthub.cmu.edu/articles/dataset/Insider_Threat_Test_Dataset/12841247
- en: 'Laprade et al. (2020) C. Laprade, B. Bowman, and H. H. Huang, “Picodomain:
    A compact high-fidelity cybersecurity dataset,” *CoRR*, vol. abs/2008.09192, 2020.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Laprade et al. (2020) C. Laprade, B. Bowman 和 H. H. Huang，“Picodomain：一个紧凑的高保真网络安全数据集，”
    *CoRR*，卷 abs/2008.09192，2020。
- en: 'Xiao et al. (2024) H. Xiao, Y. Zhu, B. Zhang *et al.*, “Unveiling shadows:
    A comprehensive framework for insider threat detection based on statistical and
    sequential analysis,” *Comput. Secur.*, vol. 138, p. 103665, 2024.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xiao 等 (2024) H. Xiao, Y. Zhu, B. Zhang *等*, “揭示阴影：基于统计和序列分析的内部威胁检测综合框架，” *Comput.
    Secur.*, 卷 138, 页 103665, 2024年。
- en: 'Sun and Yang (2022) X. Sun and J. Yang, “Hetglm: Lateral movement detection
    by discovering anomalous links with heterogeneous graph neural network,” in *IEEE
    International Performance, Computing, and Communications Conference, IPCCC 2022,
    Austin, TX, USA, November 11-13, 2022*.   IEEE, 2022, pp. 404–411.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun 和 Yang (2022) X. Sun 和 J. Yang, “Hetglm：通过异质图神经网络发现异常链接以检测横向移动，” 见于 *IEEE国际性能、计算和通信会议,
    IPCCC 2022, 奥斯汀, TX, 美国, 2022年11月11-13日*。 IEEE, 2022年, 页 404–411。
- en: 'Cai et al. (2024) X. Cai, Y. Wang, S. Xu *et al.*, “LAN: learning adaptive
    neighbors for real-time insider threat detection,” *CoRR*, vol. abs/2403.09209,
    2024.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cai 等 (2024) X. Cai, Y. Wang, S. Xu *等*, “LAN：学习适应邻居以实现实时内部威胁检测，” *CoRR*, 卷
    abs/2403.09209, 2024年。
- en: Gonçalves and Zanchettin (2024) L. Gonçalves and C. Zanchettin, “Detecting abnormal
    logins by discovering anomalous links via graph transformers,” *Computers & Security*,
    vol. 144, p. 103944, 2024.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gonçalves 和 Zanchettin (2024) L. Gonçalves 和 C. Zanchettin, “通过图变换器发现异常链接以检测异常登录，”
    *Computers & Security*, 卷 144, 页 103944, 2024年。
- en: '(37) zhipuai, “Zhipuai glm-4.” [Online]. Available: https://open.bigmodel.cn/dev/api#language'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(37) zhipuai, “Zhipuai glm-4.” [在线]. 可用链接: https://open.bigmodel.cn/dev/api#language'
- en: 'LangChain (b) LangChain, “Langsmith.” [Online]. Available: https://www.langchain.com/langsmith'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'LangChain (b) LangChain, “Langsmith.” [在线]. 可用链接: https://www.langchain.com/langsmith'
- en: '(39) MITRE, “Mitre att&ck.” [Online]. Available: https://attack.mitre.org/'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(39) MITRE, “Mitre att&ck.” [在线]. 可用链接: https://attack.mitre.org/'
