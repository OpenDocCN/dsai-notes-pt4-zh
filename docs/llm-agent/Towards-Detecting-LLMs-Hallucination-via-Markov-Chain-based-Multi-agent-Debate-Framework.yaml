- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 18:45:09'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:45:09
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Towards Detecting LLMs Hallucination via Markov Chain-based Multi-agent Debate
    Framework
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于马尔科夫链的多智能体辩论框架
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.03075](https://ar5iv.labs.arxiv.org/html/2406.03075)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2406.03075](https://ar5iv.labs.arxiv.org/html/2406.03075)
- en: 'Xiaoxi Sun¹, Jinpeng Li¹¹¹footnotemark: 1, Yan Zhong¹, Dongyan Zhao¹, Rui Yan²²²footnotemark:
    2'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 'Xiaoxi Sun¹, Jinpeng Li¹¹¹footnotemark: 1, Yan Zhong¹, Dongyan Zhao¹, Rui Yan²²²footnotemark:
    2'
- en: ¹Wangxuan Institute of Computer Technology, Peking University
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ¹王玄计算机技术研究所，北京大学
- en: ²Gaoling School of Artifical Intelligence, Renmin University of China
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ²高岭人工智能学院，人民大学
- en: '{sunxiaoxi, zhongyan}@stu.pku.edu.cn, lijp.pku@gmail.com,'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '{sunxiaoxi, zhongyan}@stu.pku.edu.cn, lijp.pku@gmail.com,'
- en: 'zhaody@pku.edu.cn, ruiyan@ruc.edu.cn   Equal contribution.  Corresponding authors:
    Dongyan Zhao and Rui Yan.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 'zhaody@pku.edu.cn, ruiyan@ruc.edu.cn   Equal contribution.  Corresponding authors:
    Dongyan Zhao and Rui Yan.'
- en: Abstract
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: The advent of large language models (LLMs) has facilitated the development of
    natural language text generation. It also poses unprecedented challenges, with
    content hallucination emerging as a significant concern. Existing solutions often
    involve expensive and complex interventions during the training process. Moreover,
    some approaches emphasize problem disassembly while neglecting the crucial validation
    process, leading to performance degradation or limited applications. To overcome
    these limitations, we propose a Markov Chain-based multi-agent debate verification
    framework to enhance hallucination detection accuracy in concise claims. Our method
    integrates the fact-checking process, including claim detection, evidence retrieval,
    and multi-agent verification. In the verification stage, we deploy multiple agents
    through flexible Markov Chain-based debates to validate individual claims, ensuring
    meticulous verification outcomes. Experimental results across three generative
    tasks demonstrate that our approach achieves significant improvements over baselines.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）的出现促进了自然语言文本生成的发展。它也带来了前所未有的挑战，其中内容幻觉成为一个重要问题。现有的解决方案通常涉及在训练过程中进行昂贵且复杂的干预。此外，一些方法强调问题的拆解，同时忽视了关键的验证过程，从而导致性能下降或应用受限。为克服这些限制，我们提出了一种基于马尔科夫链的多智能体辩论验证框架，以提高在简洁声明中的幻觉检测准确性。我们的方法整合了事实核查过程，包括声明检测、证据检索和多智能体验证。在验证阶段，我们通过灵活的马尔科夫链辩论部署多个智能体来验证单个声明，确保细致的验证结果。三个生成任务的实验结果表明，我们的方法在基线之上取得了显著的改进。
- en: Towards Detecting LLMs Hallucination via
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 检测 LLMs 幻觉的方法
- en: Markov Chain-based Multi-agent Debate Framework
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 基于马尔科夫链的多智能体辩论框架
- en: 'Xiaoxi Sun¹^†^†thanks:   Equal contribution., Jinpeng Li¹¹¹footnotemark: 1,
    Yan Zhong¹, Dongyan Zhao¹^†^†thanks:   Corresponding authors: Dongyan Zhao and
    Rui Yan., Rui Yan²²²footnotemark: 2 ¹Wangxuan Institute of Computer Technology,
    Peking University ²Gaoling School of Artifical Intelligence, Renmin University
    of China {sunxiaoxi, zhongyan}@stu.pku.edu.cn, lijp.pku@gmail.com, zhaody@pku.edu.cn,
    ruiyan@ruc.edu.cn'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 'Xiaoxi Sun¹^†^†thanks:   Equal contribution., Jinpeng Li¹¹¹footnotemark: 1,
    Yan Zhong¹, Dongyan Zhao¹^†^†thanks:   Corresponding authors: Dongyan Zhao and
    Rui Yan., Rui Yan²²²footnotemark: 2 ¹王玄计算机技术研究所，北京大学 ²高岭人工智能学院，人民大学 {sunxiaoxi,
    zhongyan}@stu.pku.edu.cn, lijp.pku@gmail.com, zhaody@pku.edu.cn, ruiyan@ruc.edu.cn'
- en: 1 Introduction
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: The continuous evolution of large language models (LLMs) has significantly expanded
    language processing capabilities across diverse domains Wei et al. ([2022](#bib.bib29)).
    However, this progress introduces challenges, such as the substantial cost associated
    with updating model parameters and inherent deficiencies in reasoning Ji et al.
    ([2023](#bib.bib15)); Zhang et al. ([2023b](#bib.bib36)); Zheng et al. ([2023](#bib.bib37)).
    This has led to the generation of inaccurate content, known as hallucination,
    particularly concerning potent yet opaque models like ChatGPT and GPT-4 OpenAI
    ([2023](#bib.bib24)).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）的持续演进显著扩展了在不同领域的语言处理能力 Wei et al. ([2022](#bib.bib29))。然而，这一进展也带来了挑战，例如更新模型参数的高成本以及推理中的固有缺陷
    Ji et al. ([2023](#bib.bib15)); Zhang et al. ([2023b](#bib.bib36)); Zheng et al.
    ([2023](#bib.bib37))。这导致了生成不准确内容的现象，被称为幻觉，尤其是对于强大但不透明的模型如 ChatGPT 和 GPT-4 OpenAI
    ([2023](#bib.bib24))。
- en: '![Refer to caption](img/9dd6fcf8314766960183fe2129276dc5.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/9dd6fcf8314766960183fe2129276dc5.png)'
- en: 'Figure 1: Overview of the fact-checking process, which includes three distinct
    stages. Claim Detection, we leverage large language models such as ChatGPT to
    obtain different claims. Evidence Retrieval, we prompt ChatGPT to formulate two
    queries, subsequently leveraging these queries to retrieve evidence with Google
    API or the provided knowledge. Multi-agent Verification, we propose the Markov
    Chain-based multi-agent debate verification framework, which can emulate human
    behavior to enhance model outputs and improve reasoning capabilities. Our main
    contributions focus on the process of Multi-agent Verification.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：事实核查过程概述，包括三个不同的阶段。声明检测，我们利用大型语言模型如ChatGPT来获取不同的声明。证据检索，我们提示ChatGPT制定两个查询，然后利用这些查询通过Google
    API或提供的知识来检索证据。多代理验证，我们提出了基于马尔可夫链的多代理辩论验证框架，该框架可以模拟人类行为以增强模型输出和改善推理能力。我们的主要贡献集中在多代理验证的过程上。
- en: Hallucination detection has become a focal point in addressing these challenges.
    Existing methods often necessitate costly and intricate interventions during the
    training process Lee et al. ([2022](#bib.bib17)); Touvron et al. ([2023](#bib.bib27));
    Elaraby et al. ([2023](#bib.bib8)); Wu et al. ([2023b](#bib.bib31)), rendering
    them unsuitable for large language models with agnostic parameters and these methods
    often incur considerable costs. Consequently, researchers have explored post-processing
    approaches Gao et al. ([2023](#bib.bib10)); Peng et al. ([2023](#bib.bib26));
    Chern et al. ([2023](#bib.bib3)); Vu et al. ([2023](#bib.bib28)); Gero et al.
    ([2023](#bib.bib11)) involving hallucination detection or correction post-content
    generation. Notably, these methods typically focus on problem decomposition and
    evidence retrieval, emphasizing simple prompting during individual verification.
    We posit that the verification accuracy is pivotal compared to problem decomposition
    in LLMs.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 幻觉检测已成为解决这些挑战的一个重点。现有的方法通常在训练过程中需要昂贵且复杂的干预措施 Lee et al. ([2022](#bib.bib17));
    Touvron et al. ([2023](#bib.bib27)); Elaraby et al. ([2023](#bib.bib8)); Wu et
    al. ([2023b](#bib.bib31))，这使得它们不适用于具有不可知参数的大型语言模型，而且这些方法通常花费相当高。因此，研究人员探讨了后处理方法
    Gao et al. ([2023](#bib.bib10)); Peng et al. ([2023](#bib.bib26)); Chern et al.
    ([2023](#bib.bib3)); Vu et al. ([2023](#bib.bib28)); Gero et al. ([2023](#bib.bib11))，涉及生成内容后的幻觉检测或纠正。值得注意的是，这些方法通常侧重于问题分解和证据检索，强调在个别验证过程中简单提示。我们认为，与问题分解相比，验证准确性在LLMs中至关重要。
- en: 'To address these challenges, we present a fact-checking process to enhance
    the accuracy of hallucination detection. As shown in Figure [1](#S1.F1 "Figure
    1 ‣ 1 Introduction ‣ Towards Detecting LLMs Hallucination via Markov Chain-based
    Multi-agent Debate Framework"), which involves three stages: claim detection,
    evidence retrieval, and multi-agent verification. In claim detection, our approach
    involves the extraction of claims from extensive responses by prompting ChatGPT,
    decomposing the intricate problem into smaller components. Evidence retrieval
    involves generating queries based on claims for retrieval. Subsequently, we retrieve
    the corresponding evidence based on these generated queries. In the multi-agent
    verification stage, we innovatively propose a Markov Chain-based multi-agent debate
    verification framework, which leverages the robust capabilities of multi-agent
    systems to simulate human behavior. This approach involves deploying diverse agents
    in Markov Chain debates to verify individual claims, thus providing a nuanced
    and flexible validation process. Following the verification of each claim using
    our method, the collective judgment of all claims contributes to the detection
    of hallucinations in the original response.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些挑战，我们提出了一种事实核查过程，以提高幻觉检测的准确性。如图[1](#S1.F1 "图 1 ‣ 1 引言 ‣ 通过基于马尔可夫链的多代理辩论框架检测LLMs幻觉")所示，该过程涉及三个阶段：声明检测、证据检索和多代理验证。在声明检测阶段，我们的方法包括通过提示ChatGPT从大量响应中提取声明，将复杂的问题分解为较小的组件。证据检索涉及基于声明生成查询以进行检索。随后，我们根据这些生成的查询检索相应的证据。在多代理验证阶段，我们创新性地提出了一种基于马尔可夫链的多代理辩论验证框架，该框架利用多代理系统的强大能力来模拟人类行为。该方法涉及在马尔可夫链辩论中部署多样化的代理来验证个别声明，从而提供细致且灵活的验证过程。在使用我们的方法验证每个声明后，所有声明的集体判断有助于检测原始响应中的幻觉。
- en: 'We conduct extensive experiments across three generative tasks, including question-answering,
    Summarization, and Dialogue, demonstrating the effectiveness of our approach.
    Verification outcomes are meticulously analyzed and compared against existing
    methods to ascertain the superiority of our approach. In summary, our contributions
    can be summarized as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在三个生成任务中进行了广泛的实验，包括问答、摘要和对话，展示了我们方法的有效性。验证结果经过详细分析，并与现有方法进行比较，以确定我们方法的优越性。总结而言，我们的贡献可以总结为以下几点：
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We propose a versatile hallucination detection process applicable to multiple
    generation tasks for improving verification accuracy.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了一种通用的幻觉检测过程，适用于多种生成任务，以提高验证准确性。
- en: •
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We introduce a Markov Chain-based multi-agent debate verification framework
    that simulates human discussion.
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们介绍了一种基于马尔可夫链的多代理辩论验证框架，模拟人类讨论。
- en: •
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Experiments conducted on three generative tasks show that our proposed framework
    outperforms baselines.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在三个生成任务上进行的实验表明，我们提出的框架优于基准方法。
- en: '![Refer to caption](img/88f2b30cf7096386b89f350bde56653d.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/88f2b30cf7096386b89f350bde56653d.png)'
- en: 'Figure 2: Overview of the proposed multi-agent debate verification framework
    for hallucination detection. There are two preparations before multi-agent debate
    verification. In preparation 1 (Agent Customization), we define three different
    debate agent roles, including Trust, Skeptic, and Leader roles. In preparation
    2 (Debate Modes Customization), we assume that the debate process consists of
    two modes: Trust agent-initiated discussion (Trust-Skeptic-Leader) and Skeptic
    agent-initiated discussion (Skeptic-Trust-Leader). Then, in Multi-agent Chain
    of Verification, our validation process can be regarded as a Markov chain, which
    continually oscillates between these two debate modes to arrive at an optimal
    judgment.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：所提出的用于幻觉检测的多代理辩论验证框架概述。在多代理辩论验证之前有两个准备工作。在准备1（代理定制）中，我们定义了三种不同的辩论代理角色，包括信任、怀疑和领导角色。在准备2（辩论模式定制）中，我们假设辩论过程由两种模式组成：信任代理发起的讨论（信任-怀疑-领导）和怀疑代理发起的讨论（怀疑-信任-领导）。然后，在多代理验证链中，我们的验证过程可以视为一个马尔可夫链，它在这两种辩论模式之间不断振荡，以达成最佳判断。
- en: 2 Related Work
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: 2.1 Hallucination Detection
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 幻觉检测
- en: 'Before the emergence of large language models, hallucination detection was
    a significant topic within the field of natural language processing. Previous
    efforts primarily focused on detecting hallucinations in various tasks such as
    summarization Kryscinski et al. ([2020](#bib.bib16)); Maynez et al. ([2020](#bib.bib23));
    Goyal and Durrett ([2021](#bib.bib12)), dialogue Das et al. ([2022](#bib.bib6)),
    question-answering Longpre et al. ([2021](#bib.bib21)), and machine translation
    Xu et al. ([2023a](#bib.bib33)). These approaches primarily aimed to identify
    discrepancies between the generated content and the input, as well as internal
    inconsistencies within the generated content. However, they were often tailored
    specifically to task-specific models, lacking generalizability. There were also
    fact-checking endeavors that aimed to identify discrepancies between the generated
    content and real-world facts. This was typically accomplished through three steps
    Guo et al. ([2022](#bib.bib13)): Claim Detection, Evidence Retrieval, and Verdict
    Prediction. With the advent of large language models, some works Gao et al. ([2023](#bib.bib10));
    Li et al. ([2023a](#bib.bib18)) tackled the task of hallucination detection by
    prompting the large language models directly. In addition to task-specific approaches,
    there are hallucination detection methods specifically designed for LLMs. For
    example, some methods assess hallucination detection by examining the consistency
    of sampled examples Manakul et al. ([2023](#bib.bib22)); Zhang et al. ([2023a](#bib.bib35)).
    Our work is fundamentally based on the fact-check framework. We transfer the Verdict
    Prediction stage to the Multi-agent Verification to improve the precision of validation.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在大语言模型出现之前，幻觉检测是自然语言处理领域中的一个重要话题。之前的工作主要集中在各种任务中的幻觉检测，例如摘要 Kryscinski et al.
    ([2020](#bib.bib16))；Maynez et al. ([2020](#bib.bib23))；Goyal 和 Durrett ([2021](#bib.bib12))，对话
    Das et al. ([2022](#bib.bib6))，问答 Longpre et al. ([2021](#bib.bib21))，以及机器翻译 Xu
    et al. ([2023a](#bib.bib33))。这些方法主要旨在识别生成内容与输入之间的差异，以及生成内容内部的一致性问题。然而，它们通常是专门针对特定任务的模型，缺乏普适性。还有一些事实核查的努力旨在识别生成内容与现实世界事实之间的差异。这通常通过三个步骤完成
    Guo et al. ([2022](#bib.bib13))：声明检测、证据检索和裁决预测。随着大语言模型的出现，一些研究 Gao et al. ([2023](#bib.bib10))；Li
    et al. ([2023a](#bib.bib18)) 通过直接提示大语言模型来处理幻觉检测任务。除了特定任务的方法外，还有专门为大语言模型设计的幻觉检测方法。例如，一些方法通过检查抽样示例的一致性来评估幻觉检测
    Manakul et al. ([2023](#bib.bib22))；Zhang et al. ([2023a](#bib.bib35))。我们的工作主要基于事实核查框架。我们将裁决预测阶段转移到多代理验证，以提高验证的精确度。
- en: 2.2 Hallucination Mitigation
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 幻觉缓解
- en: LLMs have demonstrated significant potential recently. However, they have not
    been able to completely eliminate the occurrence of hallucinations Zheng et al.
    ([2023](#bib.bib37)). The extended text produced by these large models, which
    encompasses more diverse content and often introduces external knowledge, renders
    traditional methods for hallucination mitigation less effective. Consequently,
    a plethora of works dedicated to addressing hallucination mitigation in LLMs have
    emerged. Various approaches are presented to mitigate hallucinations at different
    stages of their application within the LLM life cycle Zhang et al. ([2023b](#bib.bib36)),
    including the pre-training phase of large models Lee et al. ([2022](#bib.bib17));
    Touvron et al. ([2023](#bib.bib27)), the SFT phase Chen et al. ([2023](#bib.bib2));
    Elaraby et al. ([2023](#bib.bib8)), the alignment phase Wu et al. ([2023b](#bib.bib31));
    Casper et al. ([2023](#bib.bib1)), and the decoding phase Li et al. ([2023b](#bib.bib19));
    Chuang et al. ([2023](#bib.bib4)). Implementing these methods necessitates adjustments
    to the model’s parameters and requires a certain amount of training data, incurring
    some overhead. Numerous endeavors have been undertaken to mitigate hallucinations
    in content generated by black-box models, such as leveraging external knowledge
    bases or tools Gao et al. ([2023](#bib.bib10)); Peng et al. ([2023](#bib.bib26));
    Chern et al. ([2023](#bib.bib3)); Vu et al. ([2023](#bib.bib28)) and adopting
    self-refining approaches Gero et al. ([2023](#bib.bib11)). Our approach also centers
    on hallucination mitigation for black-box models, introducing a distinctive multi-agent
    method to augment its effectiveness.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 近期，LLMs 展现出了显著的潜力。然而，它们尚未能完全消除幻觉的发生 Zheng et al. ([2023](#bib.bib37))。这些大型模型生成的扩展文本涵盖了更多样化的内容，并且经常引入外部知识，这使得传统的幻觉缓解方法效果不佳。因此，已经出现了大量致力于解决
    LLMs 幻觉缓解问题的工作。各种方法被提出用于在 LLM 生命周期的不同阶段缓解幻觉 Zhang et al. ([2023b](#bib.bib36))，包括大型模型的预训练阶段
    Lee et al. ([2022](#bib.bib17)); Touvron et al. ([2023](#bib.bib27))，SFT 阶段 Chen
    et al. ([2023](#bib.bib2)); Elaraby et al. ([2023](#bib.bib8))，对齐阶段 Wu et al.
    ([2023b](#bib.bib31)); Casper et al. ([2023](#bib.bib1))，以及解码阶段 Li et al. ([2023b](#bib.bib19));
    Chuang et al. ([2023](#bib.bib4))。实施这些方法需要调整模型的参数，并需要一定量的训练数据，这会产生一些开销。为了减轻黑箱模型生成内容中的幻觉，已经开展了许多工作，例如利用外部知识库或工具
    Gao et al. ([2023](#bib.bib10)); Peng et al. ([2023](#bib.bib26)); Chern et al.
    ([2023](#bib.bib3)); Vu et al. ([2023](#bib.bib28))，以及采用自我完善的方法 Gero et al. ([2023](#bib.bib11))。我们的方法也集中在黑箱模型的幻觉缓解上，提出了一种独特的多智能体方法以增强其效果。
- en: 2.3 Multi-agent in LLMs
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 LLMs 中的多智能体
- en: In recent years, there has been a significant increase in the size of models
    and the amount of training data used, resulting in the exceptional performance
    of large language models (LLMs) across various tasks. As a result, researchers
    have explored the use of LLMs as agents to simulate human behavior, leading to
    the development of influential projects such as Generative Agents Park et al.
    ([2023](#bib.bib25)), Ghost in the Minecraft Zhu et al. ([2023](#bib.bib38)),
    GPT-Bargaining Fu et al. ([2023](#bib.bib9)) and Werewolf game Xu et al. ([2023b](#bib.bib34)).
    There are also some efforts involve multiple agents engaging in debates to improve
    the reasoning capabilities Liang et al. ([2023](#bib.bib20)); Du et al. ([2023](#bib.bib7));
    Xiong et al. ([2023](#bib.bib32)) or address issues related to hallucinations
    Du et al. ([2023](#bib.bib7)); Cohen et al. ([2023](#bib.bib5)). However, existing
    methods for hallucination detection and mitigation of LLMs solely rely on natural
    language interactions between agents, which may pose concerns regarding the self-correction
    approach Huang et al. ([2023](#bib.bib14)). Therefore, the objective of our work
    is to facilitate flexible discussions among multiple agents based on existing
    facts, aiming to detect and mitigate hallucinations in the generated content of
    language models.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，模型的规模和训练数据量显著增加，导致大语言模型（LLMs）在各种任务中的表现卓越。因此，研究人员探索了将LLMs作为代理以模拟人类行为，这催生了如Generative
    Agents Park等（[2023](#bib.bib25)）、Ghost in the Minecraft Zhu等（[2023](#bib.bib38)）、GPT-Bargaining
    Fu等（[2023](#bib.bib9)）和Werewolf game Xu等（[2023b](#bib.bib34)）等有影响力的项目。还有一些努力涉及多个智能体进行辩论以提高推理能力
    Liang等（[2023](#bib.bib20)）；Du等（[2023](#bib.bib7)）；Xiong等（[2023](#bib.bib32)）或解决与幻觉相关的问题
    Du等（[2023](#bib.bib7)）；Cohen等（[2023](#bib.bib5)）。然而，现有的幻觉检测和缓解方法仅依赖于智能体之间的自然语言互动，这可能引发关于自我纠错方法的担忧
    Huang等（[2023](#bib.bib14)）。因此，我们的工作目标是基于现有事实促进多个智能体之间的灵活讨论，旨在检测和缓解语言模型生成内容中的幻觉。
- en: 3 Method
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 方法
- en: 'The primary objective of our study is to detect hallucinations in the content
    generated by the model. To accomplish this, we adhere to the conventional fact-checking
    process and make some modifications. The process is structured into three distinct
    stages: Claim Detection, Evidence Retrieval, and Multi-agent Verification. This
    systematic approach enables the dissection of a complex problem into more manageable
    components. It has come to our attention that in certain fact-checking procedures,
    despite the accurate extraction of claims and the acquisition of robust evidence,
    verification errors persist in the final stage, undermining the efficacy of preceding
    efforts.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究的主要目标是检测模型生成内容中的幻觉。为此，我们遵循传统的事实检查流程，并做出一些修改。该流程被结构化为三个不同的阶段：断言检测、证据检索和多智能体验证。这种系统化的方法使得复杂问题可以拆解为更易于处理的组件。我们注意到，在某些事实检查程序中，尽管准确提取了断言并获得了可靠的证据，但最终阶段的验证错误仍然存在，削弱了前期努力的效果。
- en: Therefore, we propose a novel multi-agent debate verification framework for
    hallucination detection, the overview of which is shown in Figure [2](#S1.F2 "Figure
    2 ‣ 1 Introduction ‣ Towards Detecting LLMs Hallucination via Markov Chain-based
    Multi-agent Debate Framework"). An anthropomorphic debate process based on the
    Markov chain is designed to be applicable across various generative tasks in the
    proposed method, bolstering the accuracy of verification. Subsequent sections
    will expound on each of these three stages individually, with a particular emphasis
    on our innovative approach in the third stage.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们提出了一种新颖的多智能体辩论验证框架用于幻觉检测，其概述如图[2](#S1.F2 "图 2 ‣ 1 介绍 ‣ 基于马尔可夫链的多智能体辩论框架用于检测LLM幻觉")所示。设计了一种基于马尔可夫链的类人辩论过程，旨在使所提方法适用于各种生成任务，从而增强验证的准确性。后续部分将分别阐述这三个阶段，特别强调我们在第三阶段中的创新方法。
- en: 3.1 Claim Detection
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 断言检测
- en: In the stage of claim detection, we employ the methodology utilized in Factool
    Chern et al. ([2023](#bib.bib3)), leveraging large language models such as ChatGPT.
    Harnessing the robust instruction-following capabilities of LLMs empowers us to
    address the challenge of dissecting intricate responses. Nevertheless, detecting
    the hallucinations in statements lacking adequate information is futile and could
    impede overall judgment. Moreover, specific tasks may demand the concatenation
    of the model’s responses with particular input information to formulate an informative
    claim, necessitating supplementary processing. Detailed explanations of these
    processing methods are provided in the experimental implementation section §[4.1.2](#S4.SS1.SSS2
    "4.1.2 Implementataion Details ‣ 4.1 Experimental Setup ‣ 4 Experiments ‣ Towards
    Detecting LLMs Hallucination via Markov Chain-based Multi-agent Debate Framework").
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在声明检测阶段，我们采用 Factool Chern 等人 ([2023](#bib.bib3)) 使用的方法，利用像 ChatGPT 这样的高级语言模型。利用
    LLM 强大的指令跟随能力，使我们能够应对分析复杂回应的挑战。然而，检测缺乏足够信息的陈述中的幻觉是徒劳的，并可能阻碍总体判断。此外，特定任务可能需要将模型的回应与特定输入信息结合以形成有用的声明，这需要额外的处理。有关这些处理方法的详细说明见实验实施部分
    §[4.1.2](#S4.SS1.SSS2 "4.1.2 实施细节 ‣ 4.1 实验设置 ‣ 4 实验 ‣ 通过基于马尔可夫链的多代理辩论框架检测 LLM
    幻觉")。
- en: 3.2 Evidence Retrieval
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 证据检索
- en: Upon extraction of claims, a retrieval methodology is employed to ascertain
    corresponding evidence. Drawing inspiration from Factool’s Chern et al. ([2023](#bib.bib3))
    strategy in Knowledge Base Question Answering (KBQA) tasks, we prompt ChatGPT
    to formulate two queries, subsequently leveraging these queries to retrieve evidence.
    In instances where pertinent knowledge is absent, we employ the Google API to
    retrieve data from the internet. Conversely, when dealing with data accompanied
    by provided knowledge, we either consider the length of the knowledge as direct
    evidence or encode it for local retrieval.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在提取声明后，采用检索方法以确定相应的证据。借鉴 Factool 的 Chern 等人 ([2023](#bib.bib3)) 在知识库问答（KBQA）任务中的策略，我们提示
    ChatGPT 形成两个查询，然后利用这些查询检索证据。当相关知识缺失时，我们使用 Google API 从互联网检索数据。相反，当处理带有提供知识的数据时，我们要么将知识的长度视为直接证据，要么对其进行编码以便于本地检索。
- en: 3.3 Multi-agent Verification
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 多代理验证
- en: We propose a Markov Chain-based multi-agent debate verification framework. Our
    investigations reveal significant potential in employing multi-agent systems to
    emulate human behavior Park et al. ([2023](#bib.bib25)); Zhu et al. ([2023](#bib.bib38)),
    particularly in the domain of fact-checking claims grounded in evidence. The effectiveness
    of addressing this task is notably heightened through the use of multi-agent debates.
    Despite considerable advancements in leveraging multi-agent debates to enhance
    model outputs and improve reasoning capabilities Liang et al. ([2023](#bib.bib20));
    Du et al. ([2023](#bib.bib7)), two critical aspects remain underexplored within
    the realm of hallucination detection.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出了一种基于马尔可夫链的多代理辩论验证框架。我们的研究揭示了在使用多代理系统模拟人类行为方面的显著潜力，Park 等人 ([2023](#bib.bib25));
    Zhu 等人 ([2023](#bib.bib38))，特别是在基于证据的事实核查领域。通过使用多代理辩论，解决这一任务的有效性显著提高。尽管在利用多代理辩论来增强模型输出和提高推理能力方面取得了
    considerable advancements，Liang 等人 ([2023](#bib.bib20)); Du 等人 ([2023](#bib.bib7))，但在幻觉检测领域仍有两个关键方面尚未充分探索。
- en: 1)
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1)
- en: 'Application to Verification: Few studies have directly applied the multi-agent
    approach to the task of verification, they more concentrate on the decomposition
    of the complicated samples. Recognizing this research gap, our work aims to bridge
    it by introducing the multi-agent debate verification framework.'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 应用到验证中：很少有研究直接将多代理方法应用于验证任务，更多集中于复杂样本的分解。认识到这一研究空白，我们的工作旨在通过引入多代理辩论验证框架来填补这一空白。
- en: 2)
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2)
- en: 'Flexible Debate Process: Existing methods in debate often adhere to a fixed
    process, unlike human debates where participants dynamically adjust their arguments
    based on prior outcomes. Our proposed approach takes inspiration from the Markov
    chain, where the selection of the current state depends on the results of a limited
    set of preceding states. This debate mode is more similar to the discussion between
    humans.'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 灵活的辩论过程：现有的辩论方法通常遵循固定的过程，与人类辩论中参与者根据先前结果动态调整论点的情况不同。我们提出的方法受到了马尔可夫链的启发，其中当前状态的选择取决于一组有限的前置状态的结果。这种辩论模式更类似于人类之间的讨论。
- en: In summary, our multi-agent debate verification framework ingeniously adapts
    the multi-agent paradigm to the hallucination detection task. By infusing flexibility
    into the debate process and drawing inspiration from the Markov chain, our goal
    is to enhance the accuracy and adaptability of the verification process when assessing
    the veracity of claims based on evidence.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，我们的多代理辩论验证框架巧妙地将多代理范式适应于幻觉检测任务。通过为辩论过程注入灵活性，并从马尔可夫链中获得灵感，我们的目标是提高在基于证据评估主张真实性时验证过程的准确性和适应性。
- en: The key point in our method lies in the definition of states and the transition
    mechanisms.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们方法的关键在于状态的定义和过渡机制。
- en: 3.3.1 States
  id: totrans-53
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.1 状态
- en: Agents
  id: totrans-54
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 代理
- en: 'To comprehend the definition of states, it is imperative to elucidate the roles
    assumed by the diverse agents under consideration. We engage three distinct agents:
    Trust, Skeptic, and Leader. These agents collectively share the commonality of
    assimilating perspectives from one or more antecedent agents. They meticulously
    scrutinize these perspectives, grounded in claims and evidence amassed in preceding
    sections, express concurrence or dissent, and proffer their own viewpoints accompanied
    by factual assessments of the claims. The differentiation among these agents lies
    in their inclination toward antecedent viewpoints. The Trust agent predominantly
    leans towards accepting the perspectives of the preceding agent, thereby bolstering
    their credibility. Conversely, the Skeptic agent challenges the perspectives of
    the antecedent agent, diligently seeking to pinpoint inconsistencies between viewpoints
    and supporting evidence. The Leader agent amalgamates the perspectives of two
    agents, critically examines the rational and irrational facets, and ultimately
    formulates its own viewpoint. We implement agents with different personas through
    various prompts. Details can be found in Appendix [A.1](#A1.SS1 "A.1 Prompts ‣
    Appendix A Appendix ‣ Towards Detecting LLMs Hallucination via Markov Chain-based
    Multi-agent Debate Framework"). The configuration of these agents, arranged in
    various sequences, constitutes the states delineated in our approach.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解状态的定义，必须阐明所考虑的各种代理角色所承担的角色。我们涉及三种不同的代理：Trust、Skeptic 和 Leader。这些代理共同的特点是吸收来自一个或多个前置代理的观点。他们仔细审查这些观点，这些观点基于前面章节中积累的主张和证据，表达同意或异议，并提出自己的观点，附带对主张的事实评估。这些代理之间的区别在于他们对前置观点的倾向。Trust
    代理主要倾向于接受前置代理的观点，从而增强其可信度。相反，Skeptic 代理挑战前置代理的观点，努力找出观点与支持证据之间的不一致之处。Leader 代理综合了两个代理的观点，批判性地审查合理和不合理的方面，最终形成自己的观点。我们通过各种提示实现具有不同人格的代理。详细信息见附录
    [A.1](#A1.SS1 "A.1 Prompts ‣ Appendix A Appendix ‣ Towards Detecting LLMs Hallucination
    via Markov Chain-based Multi-agent Debate Framework")。这些代理的配置以不同的顺序排列，构成了我们方法中定义的状态。
- en: States
  id: totrans-56
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 状态
- en: We need to precisely define the states mentioned earlier. According to the definition
    of the Markov chain, we require an initial state to initiate our verification
    chain. Each agent must analyze the perspectives of preceding agents, necessitating
    an initial agent to furnish the primary answer for subsequent debate. This initial
    state is characterized by the initial agent, labeled as $S_{0}$, and our verification
    chain unfolds from this state.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要精确定义前面提到的状态。根据马尔可夫链的定义，我们需要一个初始状态来启动我们的验证链。每个代理必须分析前置代理的观点，这需要一个初始代理提供初步答案以供后续辩论。这个初始状态由初始代理特征化，标记为
    $S_{0}$，我们的验证链从这个状态展开。
- en: We predominantly have two ordinary states, each comprising three agents. These
    states can be regarded as two distinct discussion modes. The first is the Trust
    agent-initiated discussion, labeled as $S_{1}$, with the sequence Skeptic-Trust-Leader.
    This mode leans towards questioning the credibility of the previous viewpoints
    before further analyzing the skeptical perspective. Our verification chain continually
    oscillates between these two debate modes to arrive at an optimal judgment.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们主要有两个普通状态，每个状态由三个代理组成。这些状态可以被视为两种不同的讨论模式。第一个是由信任代理发起的讨论，标记为 $S_{1}$，序列为怀疑者-信任-领导者。这种模式倾向于在进一步分析怀疑观点之前质疑先前观点的可信度。我们的验证链在这两种辩论模式之间不断摆动，以达到最终判断。
- en: To prevent the chain from infinitely extending, a termination state is essential.
    Analogous to human debates concluding when opinions align, our termination condition
    is similar. If, within a state, the three agents reach a consensus, the chain
    terminates. When the Skeptic agent fails to identify points of contention, and
    the Leader, after scrutinizing their opinions, has no objections, yielding the
    same judgment, we consider the debate concluded. Additionally, we have imposed
    a maximum limit on verification rounds to constrain the length of the chain.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止链条无限延伸，终止状态是必不可少的。类似于人类辩论在意见一致时结束，我们的终止条件也类似。如果在一个状态内，三个代理达成一致，链条终止。当怀疑者代理未能识别争议点，而领导者在审视他们的观点后没有异议，并得出相同的判断时，我们认为辩论已结束。此外，我们还设定了最大验证轮次限制，以约束链条的长度。
- en: 3.3.2 Transition
  id: totrans-60
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.2 过渡
- en: Transitioning between states is a critical aspect of our methodology, following
    the definition of states. The primary criterion guiding these transitions in our
    approach is the verification result of a claim by the preceding state. This methodology
    aligns with human intuition, acknowledging the potential for diverse perspectives
    in debating a given matter.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 状态之间的过渡是我们方法论的关键方面，遵循状态的定义。指导这些过渡的主要标准是前一个状态对声明的验证结果。这种方法论符合人类直觉，承认在讨论某个问题时可能存在不同的观点。
- en: 'Our transition probabilities are as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的过渡概率如下：
- en: '|  | $Pr\left(S_{2}&#124;R=True\right)=1$ |  | (1) |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '|  | $Pr\left(S_{2}&#124;R=True\right)=1$ |  | (1) |'
- en: '|  | $Pr\left(S_{1}&#124;R=False\right)=1$ |  | (2) |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '|  | $Pr\left(S_{1}&#124;R=False\right)=1$ |  | (2) |'
- en: $R$. In essence, we initially reinforce the credibility of this judgment, confirming
    the validity of skepticism. By enhancing the credibility of this opinion, if subsequent
    skepticism from the Skeptic agent is challenging, we can reasonably conclude the
    accuracy of this judgment, leading to the convergence of the chain.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: $R$。本质上，我们首先加强这一判断的可信度，确认怀疑的有效性。通过提高这一观点的可信度，如果随后的怀疑者代理的怀疑具有挑战性，我们可以合理地得出这一判断的准确性，从而使链条收敛。
- en: 'Therefore, our overall process unfolds in the following manner: Initially,
    an initial answer is obtained from the initial state $S_{0}$ is made. Subsequent
    transitions rely solely on the judgment of the preceding state, continuing until
    a consensus is reached among the three agents within a state, culminating in the
    final verification result.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的整体过程如下：首先，从初始状态 $S_{0}$ 获得初始答案。随后的过渡仅依赖于前一个状态的判断，持续进行，直到三个代理在某个状态内达成一致，最终得到验证结果。
- en: 4 Experiments
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实验
- en: 'We conducted experiments encompassing three generative tasks: Knowledge-Based
    Question Answering (KB-QA), Dialogue, and Summarization.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了包括知识基础问答（KB-QA）、对话和摘要在内的三种生成任务的实验。
- en: 4.1 Experimental Setup
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 实验设置
- en: For all three tasks, we prompt the ChatGPT to execute claim extraction, query
    generation, and multi-agent debate verification. The verification process is iterated
    a minimum of 2 rounds, and 10 snippets of evidence are extracted. The chosen transition
    method involved switching to the skeptic agent when the response was determined
    to be True.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这三项任务，我们提示 ChatGPT 执行声明提取、查询生成和多代理辩论验证。验证过程至少迭代 2 轮，并提取 10 条证据。选择的过渡方法是在回应被确定为“真”时切换到怀疑者代理。
- en: 4.1.1 Datasets and Baselines
  id: totrans-71
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.1 数据集和基线
- en: 'In this paper, we perform experiments on three different tasks, including Question-Answer
    (QA), Summarization, and Dialogue. The experimental datasets are derived from
    the following two canonical databases:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们对三个不同的任务进行了实验，包括问答（QA）、摘要和对话。实验数据集来源于以下两个经典数据库：
- en: •
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Factool Chern et al. ([2023](#bib.bib3)): The Factprompts data comprises real-world
    questions with responses generated by ChatGPT, along with Factool-annotated claims
    extracted from these responses.'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Factool Chern 等人 ([2023](#bib.bib3))：Factprompts 数据包含由 ChatGPT 生成的真实世界问题的回答，以及从这些回答中提取的
    Factool 注释的声明。
- en: •
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'HaluEval Li et al. ([2023a](#bib.bib18)): HaluEval constitutes a substantial
    collection of sampling-then-filtering generated and human-annotated hallucinated
    samples, serving as an evaluation metric for language model performance in recognizing
    hallucination.'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: HaluEval Li 等人 ([2023a](#bib.bib18))：HaluEval 是一个大量采样后过滤生成和人工注释的幻觉样本集合，作为评估语言模型识别幻觉表现的指标。
- en: We randomly selected 150, 50, and 150 samples from the three tasks of HaluEval
    for testing purposes. The selection of samples was contingent upon the complexity
    of task responses, with summarization outputs being more intricate. Owing to the
    necessity of decomposing summarization into a greater number of claims, the extracted
    quantity is comparatively smaller than that of the other two tasks. The positive
    and negative instances within the dataset were randomly sampled using a binary
    distribution with a probability of 0.5\. The resulting data distribution is presented
    in Table [1](#S4.T1 "Table 1 ‣ 4.1.1 Datasets and Baselines ‣ 4.1 Experimental
    Setup ‣ 4 Experiments ‣ Towards Detecting LLMs Hallucination via Markov Chain-based
    Multi-agent Debate Framework").
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从 HaluEval 的三个任务中随机选择了 150、50 和 150 个样本用于测试。样本的选择依据任务响应的复杂性，摘要输出更为复杂。由于需要将摘要分解为更多的声明，提取的数量相对较少。数据集中的正例和负例实例使用概率为
    0.5 的二元分布随机抽样。结果数据分布见表 [1](#S4.T1 "表 1 ‣ 4.1.1 数据集和基线 ‣ 4.1 实验设置 ‣ 4 实验 ‣ 基于马尔可夫链的多智能体辩论框架检测
    LLMs 幻觉").
- en: We compared the Factool method, the few-shot prompting method in HaluEval, the
    self-check method Chern et al. ([2023](#bib.bib3)), and our approach.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们比较了 Factool 方法、HaluEval 中的少量提示方法、Chern 等人 ([2023](#bib.bib3)) 的自检方法和我们的方法。
- en: '| Datasets | Positive | Negative |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 正例 | 负例 |'
- en: '| --- | --- | --- |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Factool QA | 23 | 27 |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| Factool QA | 23 | 27 |'
- en: '| HaluEval QA | 75 | 75 |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| HaluEval QA | 75 | 75 |'
- en: '| HaluEval Summarization | 25 | 25 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| HaluEval 总结 | 25 | 25 |'
- en: '| HaluEval Dialogue | 80 | 70 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| HaluEval 对话 | 80 | 70 |'
- en: 'Table 1: The Number of positive and negative samples in different datasets.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：不同数据集中的正例和负例样本数量。
- en: '| Method | Claim-Level | Response-Level |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 声明级别 | 回应级别 |'
- en: '| --- | --- | --- |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Acc. | R | P | F1 | Acc. | R | P | F1 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 准确率 | 召回率 | 精确率 | F1 | 准确率 | 召回率 | 精确率 | F1 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| Self-Check (0) | 75.54 | 90.40 | 80.00 | 84.88 | 54.00 | 60.87 | 50.00 |
    54.90 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 自检 (0) | 75.54 | 90.40 | 80.00 | 84.88 | 54.00 | 60.87 | 50.00 | 54.90 |'
- en: '| Self-Check (3) | 69.53 | 81.36 | 79.12 | 80.23 | 54.00 | 47.83 | 50.00 |
    48.89 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 自检 (3) | 69.53 | 81.36 | 79.12 | 80.23 | 54.00 | 47.83 | 50.00 | 48.89 |'
- en: '| FACTOOL | 74.25 | 73.45 | 90.91 | 81.25 | 64.00 | 43.48 | 66.67 | 52.63 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| FACTOOL | 74.25 | 73.45 | 90.91 | 81.25 | 64.00 | 43.48 | 66.67 | 52.63 |'
- en: '| Our Method | 77.68 | 80.79 | 88.82 | 84.62 | 72.00 | 52.17 | 80.00 | 63.15
    |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 我们的方法 | 77.68 | 80.79 | 88.82 | 84.62 | 72.00 | 52.17 | 80.00 | 63.15 |'
- en: 'Table 2: Accuracy(%), Recall(%), Precision(%), F1(%) of four methods on Dataset
    Factool Chern et al. ([2023](#bib.bib3)) used. Claim-Level denotes the results
    evaluated on all annotated claims, and Response-Level denotes the results evaluated
    on the origin responses. The best scores are highlighted in bold.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：四种方法在 Factool Chern 等人 ([2023](#bib.bib3)) 数据集上的准确率（%）、召回率（%）、精确率（%）、F1（%）。Claim-Level
    表示对所有注释声明的结果，Response-Level 表示对原始回答的结果。最佳分数用**粗体**突出显示。
- en: '| Method | QA | Summarization | Dialogue |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | QA | 总结 | 对话 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Acc. | R | P | F1 | Acc. | R | P | F1 | Acc. | R | P | F1 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 准确率 | 召回率 | 精确率 | F1 | 准确率 | 召回率 | 精确率 | F1 | 准确率 | 召回率 | 精确率 | F1 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| HaluEval | 56.00 | 77.33 | 54.21 | 63.74 | 58.00 | 100.0 | 54.35 | 70.42
    | 68.00 | 75.71 | 63.10 | 68.83 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| HaluEval | 56.00 | 77.33 | 54.21 | 63.74 | 58.00 | 100.0 | 54.35 | 70.42
    | 68.00 | 75.71 | 63.10 | 68.83 |'
- en: '| FACTOOL | 67.33 | 86.67 | 62.50 | 72.63 | 64.00 | 48.00 | 70.59 | 57.14 |
    74.67 | 70.00 | 74,24 | 72.06 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| FACTOOL | 67.33 | 86.67 | 62.50 | 72.63 | 64.00 | 48.00 | 70.59 | 57.14 |
    74.67 | 70.00 | 74.24 | 72.06 |'
- en: '| Ours | 70.67 | 82.67 | 66.67 | 73.81 | 70.00 | 64.00 | 72.73 | 68.09 | 76.00
    | 62.86 | 81.48 | 70.97 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 我们的方法 | 70.67 | 82.67 | 66.67 | 73.81 | 70.00 | 64.00 | 72.73 | 68.09 | 76.00
    | 62.86 | 81.48 | 70.97 |'
- en: 'Table 3: The results for our method and baseline on HaluEval Li et al. ([2023a](#bib.bib18))
    Dataset. We conducted experiments on three tasks: QA, Summarization, and Dialogue.
    The best scores are highlighted in bold.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：我们的方法和基线在 HaluEval Li et al. ([2023a](#bib.bib18)) 数据集上的结果。我们在三个任务上进行了实验：QA、总结和对话。最佳得分用**粗体**突出显示。
- en: 4.1.2 Implementataion Details
  id: totrans-103
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.2 实施细节
- en: KB-QA
  id: totrans-104
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: KB-QA
- en: For intricate and information-rich QA data, such as that in Factool Chern et al.
    ([2023](#bib.bib3)), we decomposed answers into multiple atomic claims and conducted
    multi-agent debate verification on each claim. If one of the claims is hallucinated,
    the origin answer is judged to be non-factual. As Factool data lacked corresponding
    evidence, Google search was employed to retrieve evidence for verification. In
    the case of simpler QA data, as found in HaluEval Li et al. ([2023a](#bib.bib18)),
    where answers sometimes are the single entity, such as "What American quartery
    lifestyle magazine did Hearst Shkelev Media also publish? Departures.", we concatenated
    answers and questions to form QA pairs. Subsequently, we directly applied the
    multi-agent debate verification to these QA pairs, utilizing the provided knowledge
    in the dataset as evidence.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 对于复杂且信息丰富的 QA 数据，例如 Factool Chern et al. ([2023](#bib.bib3)) 中的数据，我们将答案分解为多个原子声明，并对每个声明进行多代理辩论验证。如果其中一个声明是虚假的，则认为原始答案是不真实的。由于
    Factool 数据缺乏相应的证据，我们使用 Google 搜索来检索验证证据。在简单的 QA 数据中，例如 HaluEval Li et al. ([2023a](#bib.bib18))
    中的数据，答案有时是单一实体，例如“赫斯特·谢列夫传媒还出版了什么美国季度生活杂志？Departures。”我们将答案和问题连接形成 QA 对。随后，我们直接对这些
    QA 对应用多代理辩论验证，利用数据集中的知识作为证据。
- en: Summarization
  id: totrans-106
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 总结
- en: The model-generated summary was treated as a response, decomposed into multiple
    claims, and each claim was verified individually. The corresponding document to
    the summary served as evidence. To mitigate excessively long input queries, each
    sentence of the document was encoded separately, along with the query. The top
    10 most similar sentences were selected as evidence for the current claim.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 模型生成的摘要被视为回应，分解为多个声明，每个声明被单独验证。与摘要对应的文档作为证据。为了减少过长的输入查询，每个句子与查询一起被单独编码。选择了前
    10 个最相似的句子作为当前声明的证据。
- en: Dialogue
  id: totrans-108
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 对话
- en: 'In the course of the dialogue task, we encountered challenges associated with
    the extraction of claims. Dialogue responses frequently incorporated substantial
    subjective viewpoints such as "The last time that they made it to Super Bowl was
    in 2005\. Are you a basketball fanatic too?", rendering the fact-checking of the
    factual accuracy of such subjective statements less meaningful. To mitigate this
    challenge, we introduced a pre-processing step wherein we directed ChatGPT to
    eliminate subjective portions from its responses prior to claim extraction, so
    the previous sentence becomes: "The last time that they made it to the Super Bowl
    was in 2005.". This approach allowed us to retain only the informative segments
    for subsequent verification. Additionally, in the verification process during
    claim extraction, we employed the dialogue history and external knowledge as supporting
    evidence.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在对话任务过程中，我们遇到了与声明提取相关的挑战。对话回应中常常包含大量主观观点，例如“他们最后一次进入超级碗是在 2005 年。你也是篮球迷吗？”，使得对这些主观陈述的事实准确性验证变得不那么有意义。为解决这一挑战，我们引入了一个预处理步骤，即指导
    ChatGPT 在提取声明之前去除回应中的主观部分，这样前一句变成了：“他们最后一次进入超级碗是在 2005 年。”这一方法使我们能够保留仅有的有用段落以供后续验证。此外，在声明提取的验证过程中，我们使用对话历史和外部知识作为支持证据。
- en: 4.2 Performance Analysis
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 性能分析
- en: The experimental results are presented in Table [2](#S4.T2 "Table 2 ‣ 4.1.1
    Datasets and Baselines ‣ 4.1 Experimental Setup ‣ 4 Experiments ‣ Towards Detecting
    LLMs Hallucination via Markov Chain-based Multi-agent Debate Framework") and Table
    [3](#S4.T3 "Table 3 ‣ 4.1.1 Datasets and Baselines ‣ 4.1 Experimental Setup ‣
    4 Experiments ‣ Towards Detecting LLMs Hallucination via Markov Chain-based Multi-agent
    Debate Framework"). Table [2](#S4.T2 "Table 2 ‣ 4.1.1 Datasets and Baselines ‣
    4.1 Experimental Setup ‣ 4 Experiments ‣ Towards Detecting LLMs Hallucination
    via Markov Chain-based Multi-agent Debate Framework") shows the performance of
    our method on Factool Chern et al. ([2023](#bib.bib3)), presenting results at
    both the claim and response levels. According to Table [2](#S4.T2 "Table 2 ‣ 4.1.1
    Datasets and Baselines ‣ 4.1 Experimental Setup ‣ 4 Experiments ‣ Towards Detecting
    LLMs Hallucination via Markov Chain-based Multi-agent Debate Framework"), we can
    observe that our proposed method can consistently achieve optimal accuracy when
    compared to various approaches.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 实验结果见表 [2](#S4.T2 "Table 2 ‣ 4.1.1 Datasets and Baselines ‣ 4.1 Experimental
    Setup ‣ 4 Experiments ‣ Towards Detecting LLMs Hallucination via Markov Chain-based
    Multi-agent Debate Framework") 和表 [3](#S4.T3 "Table 3 ‣ 4.1.1 Datasets and Baselines
    ‣ 4.1 Experimental Setup ‣ 4 Experiments ‣ Towards Detecting LLMs Hallucination
    via Markov Chain-based Multi-agent Debate Framework")。表 [2](#S4.T2 "Table 2 ‣
    4.1.1 Datasets and Baselines ‣ 4.1 Experimental Setup ‣ 4 Experiments ‣ Towards
    Detecting LLMs Hallucination via Markov Chain-based Multi-agent Debate Framework")
    展示了我们的方法在 Factool Chern 等 ([2023](#bib.bib3)) 数据集上的表现，展示了声明和响应层级的结果。根据表 [2](#S4.T2
    "Table 2 ‣ 4.1.1 Datasets and Baselines ‣ 4.1 Experimental Setup ‣ 4 Experiments
    ‣ Towards Detecting LLMs Hallucination via Markov Chain-based Multi-agent Debate
    Framework")，我们可以观察到，与各种方法相比，我们提出的方法可以始终实现最佳的准确性。
- en: 'Table [3](#S4.T3 "Table 3 ‣ 4.1.1 Datasets and Baselines ‣ 4.1 Experimental
    Setup ‣ 4 Experiments ‣ Towards Detecting LLMs Hallucination via Markov Chain-based
    Multi-agent Debate Framework") displays the test results on the HaluEval Li et al.
    ([2023a](#bib.bib18)) dataset, from which we can observe that: Our method demonstrates
    optimal accuracy, excelling in most metrics in all three tasks, Notably, in the
    three tasks of this dataset, our method exhibits a relatively low recall score.
    This can be attributed to our approach, which involves questioning claims verified
    as factual, thereby ensuring the precise detection of errors when claims are misclassified.
    However, this approach also results in misjudging some claims that inherently
    lack hallucinations as non-factual. This phenomenon is further elucidated in § [4.3](#S4.SS3.SSS0.Px1
    "Transition Methods ‣ 4.3 Ablation Study ‣ 4 Experiments ‣ Towards Detecting LLMs
    Hallucination via Markov Chain-based Multi-agent Debate Framework").'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [3](#S4.T3 "Table 3 ‣ 4.1.1 Datasets and Baselines ‣ 4.1 Experimental Setup
    ‣ 4 Experiments ‣ Towards Detecting LLMs Hallucination via Markov Chain-based
    Multi-agent Debate Framework") 展示了在 HaluEval Li 等 ([2023a](#bib.bib18)) 数据集上的测试结果，从中我们可以观察到：我们的方法展示了最佳的准确性，在所有三个任务的大多数指标中表现优异。值得注意的是，在该数据集的三个任务中，我们的方法表现出相对较低的召回率。这可以归因于我们的方法涉及质疑被验证为事实的声明，从而确保在声明被错误分类时准确检测到错误。然而，这种方法也导致一些本质上没有幻觉的声明被误判为非事实。这一现象在
    § [4.3](#S4.SS3.SSS0.Px1 "Transition Methods ‣ 4.3 Ablation Study ‣ 4 Experiments
    ‣ Towards Detecting LLMs Hallucination via Markov Chain-based Multi-agent Debate
    Framework") 中得到了进一步阐述。
- en: 4.3 Ablation Study
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 消融研究
- en: Transition Methods
  id: totrans-114
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 转移方法
- en: 'We assessed the impact of distinct transition methods. From the QA section
    of HaluEval Li et al. ([2023a](#bib.bib18)), we extract 80 samples to evaluate
    the impact of four transition methods: transitioning to $S_{2}$ method, concurrently
    demonstrating an elevated precision value.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们评估了不同转移方法的影响。从 HaluEval Li 等 ([2023a](#bib.bib18)) 的 QA 部分，我们提取了 80 个样本来评估四种转移方法的影响：转移到
    $S_{2}$ 方法，同时展示了较高的精确度值。
- en: '| Method | Acc. | R | P | F1 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 准确率 | 召回率 | 精确率 | F1 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| $Always\ \textbf{Skeptic}$ | 65.00 | 84.21 | 59.26 | 69.57 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| $Always\ \textbf{Skeptic}$ | 65.00 | 84.21 | 59.26 | 69.57 |'
- en: '| $Always\ \textbf{Trust}$ | 68.75 | 84.21 | 62.75 | 71.91 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| $Always\ \textbf{Trust}$ | 68.75 | 84.21 | 62.75 | 71.91 |'
- en: '| $True\to\textbf{Trust}$ | 67.50 | 89.47 | 60.71 | 72.34 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| $True\to\textbf{Trust}$ | 67.50 | 89.47 | 60.71 | 72.34 |'
- en: '| $True\to\textbf{Skeptic}$ | 70.00 | 86.84 | 63.46 | 73.33 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| $True\to\textbf{Skeptic}$ | 70.00 | 86.84 | 63.46 | 73.33 |'
- en: 'Table 4: Comparison of Different Transition Methods. We evaluate the influence
    of transition methods on 80 QA samples, setting the minimum debate rounds to 2\.
    The best scores are highlighted in bold.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：不同转移方法的比较。我们评估了转移方法对 80 个 QA 样本的影响，设置最小辩论轮次为 2。最佳分数以粗体显示。
- en: Minimum Rounds of Debate
  id: totrans-123
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 辩论的最小轮次
- en: We explored the influence of different numbers of minimum debate rounds on the
    outcomes. We examined three distinct tasks using the previously extracted HaluEval
    data Li et al. ([2023a](#bib.bib18)), varying the number of minimum debate rounds
    from 0 to 3\. Employing the $True\to\textbf{Skeptic}$ transition method, the results,
    illustrated in Figure [3](#S4.F3 "Figure 3 ‣ Minimum Rounds of Debate ‣ 4.3 Ablation
    Study ‣ 4 Experiments ‣ Towards Detecting LLMs Hallucination via Markov Chain-based
    Multi-agent Debate Framework"), generally exhibit enhanced performance when the
    number of minimum rounds is set to 1 or 2, with a discernible decrease in efficacy
    when the number of minimum rounds is set to 3.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们探讨了不同最小辩论轮次对结果的影响。我们使用之前提取的HaluEval数据Li等人（[2023a](#bib.bib18)）对三个不同任务进行了检查，将最小辩论轮次的数量从0变化到3。采用$True\to\textbf{Skeptic}$过渡方法，结果如图[3](#S4.F3
    "图 3 ‣ 最小辩论轮次 ‣ 4.3 消融研究 ‣ 4 实验 ‣ 通过基于马尔可夫链的多代理辩论框架检测LLMs幻觉")所示，当最小轮次设置为1或2时，性能通常会提高，而当最小轮次设置为3时，效果明显下降。
- en: '![Refer to caption](img/87a982c409f973ad41d8a1a63ffe580b.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/87a982c409f973ad41d8a1a63ffe580b.png)'
- en: 'Figure 3: Comparison of Different Minimum Debate Rounds. We evaluate the influence
    of the minimum debate rounds on samples we utilized in §[4.1.1](#S4.SS1.SSS1 "4.1.1
    Datasets and Baselines ‣ 4.1 Experimental Setup ‣ 4 Experiments ‣ Towards Detecting
    LLMs Hallucination via Markov Chain-based Multi-agent Debate Framework"), setting
    the transition method to $True\to\textbf{Skeptic}$. The x-axis represents different
    minimum debate rounds, whereas the y-axis signifies the corresponding detection
    accuracy.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：不同最小辩论轮次的比较。我们评估了最小辩论轮次对我们在§[4.1.1](#S4.SS1.SSS1 "4.1.1 数据集和基线 ‣ 4.1 实验设置
    ‣ 4 实验 ‣ 通过基于马尔可夫链的多代理辩论框架检测LLMs幻觉")中使用的样本的影响，将过渡方法设置为$True\to\textbf{Skeptic}$。x轴表示不同的最小辩论轮次，而y轴表示相应的检测准确率。
- en: Comparison with Non-GPT Method
  id: totrans-127
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 与非-GPT方法的比较
- en: In the multi-agent verification stage of the experiment in the Factool dataset,
    we employed the WeCheckWu et al. ([2023a](#bib.bib30)) method to conduct an ablation
    study, showcasing the benefits of our approach. We held the initial two steps
    constant, utilizing the Factool method to extract claims and retrieve evidence.
    Employing the claim as the hypothesis and the evidence as the premise, instances
    with WeCheck scores greater than or equal to 0.5 were deemed factual. From the
    experimental results in Table [5](#S4.T5 "Table 5 ‣ Comparison with Non-GPT Method
    ‣ 4.3 Ablation Study ‣ 4 Experiments ‣ Towards Detecting LLMs Hallucination via
    Markov Chain-based Multi-agent Debate Framework"), we observed that compared to
    the non-GPT method, our approach exhibits significant advantages during the verification
    stage.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在Factool数据集实验的多代理验证阶段，我们采用了WeCheckWu等人（[2023a](#bib.bib30)）的方法进行消融研究，展示了我们方法的优势。我们保持了前两步不变，利用Factool方法提取声明和检索证据。将声明作为假设，证据作为前提，WeCheck分数大于或等于0.5的实例被认为是事实。从表[5](#S4.T5
    "表 5 ‣ 与非-GPT方法的比较 ‣ 4.3 消融研究 ‣ 4 实验 ‣ 通过基于马尔可夫链的多代理辩论框架检测LLMs幻觉")的实验结果中，我们观察到，与非-GPT方法相比，我们的方法在验证阶段表现出了显著的优势。
- en: '| Method | Acc. | R | P | F1 |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 准确率 | 召回率 | 精确率 | F1 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Wecheck | 65.23 | 64.41 | 86.36 | 73.78 |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| Wecheck | 65.23 | 64.41 | 86.36 | 73.78 |'
- en: '| Our method | 77.68 | 80.79 | 88.82 | 84.62 |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 我们的方法 | 77.68 | 80.79 | 88.82 | 84.62 |'
- en: 'Table 5: Comparison with Non-GPT Method. We compare our method with Non-GPT
    Method Wecheck on the Factool dataset. The best scores are highlighted in bold.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：与非-GPT方法的比较。我们在Factool数据集上将我们的方法与非-GPT方法进行了比较。最佳得分用**粗体**突出显示。
- en: 4.4 Case Study
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 案例研究
- en: To demonstrate the effectiveness of our approach, Table [10](#A1.T10 "Table
    10 ‣ A.2 Debate examples ‣ Appendix A Appendix ‣ Towards Detecting LLMs Hallucination
    via Markov Chain-based Multi-agent Debate Framework") and Table [11](#A1.T11 "Table
    11 ‣ A.2 Debate examples ‣ Appendix A Appendix ‣ Towards Detecting LLMs Hallucination
    via Markov Chain-based Multi-agent Debate Framework") show examples of the hallucination
    detection process for a Question-Answer (QA) sample. In Table [10](#A1.T10 "Table
    10 ‣ A.2 Debate examples ‣ Appendix A Appendix ‣ Towards Detecting LLMs Hallucination
    via Markov Chain-based Multi-agent Debate Framework"), the debating agent is based
    on the GPT-3.5-turbo model, whereas Table [11](#A1.T11 "Table 11 ‣ A.2 Debate
    examples ‣ Appendix A Appendix ‣ Towards Detecting LLMs Hallucination via Markov
    Chain-based Multi-agent Debate Framework") utilizes GPT-4 as the base model.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示我们方法的有效性，表格[10](#A1.T10 "表格 10 ‣ A.2 辩论示例 ‣ 附录 A ‣ 通过基于马尔可夫链的多代理辩论框架检测LLMs幻觉")和表格[11](#A1.T11
    "表格 11 ‣ A.2 辩论示例 ‣ 附录 A ‣ 通过基于马尔可夫链的多代理辩论框架检测LLMs幻觉")展示了问答（QA）样本的幻觉检测过程。在表格[10](#A1.T10
    "表格 10 ‣ A.2 辩论示例 ‣ 附录 A ‣ 通过基于马尔可夫链的多代理辩论框架检测LLMs幻觉")中，辩论代理基于GPT-3.5-turbo模型，而表格[11](#A1.T11
    "表格 11 ‣ A.2 辩论示例 ‣ 附录 A ‣ 通过基于马尔可夫链的多代理辩论框架检测LLMs幻觉")则以GPT-4为基础模型。
- en: When the debate starts, the initial agent generates an initial opinion based
    on the QA pair and the corresponding evidence. If no debate ensues, the initial
    opinion solidifies as the final answer. However, this approach overlooks both
    the insufficiency of evidence to support the claim that "The Landseer has a limited
    range of colors" and the contradiction with evidence concerning "the English Mastiff
    having a wider range." In Table [10](#A1.T10 "Table 10 ‣ A.2 Debate examples ‣
    Appendix A Appendix ‣ Towards Detecting LLMs Hallucination via Markov Chain-based
    Multi-agent Debate Framework"), the three agents engage in discussions to highlight
    the insufficient evidence supporting "The Landseer has a limited range of colors."
    However, they fail to infer the contradiction with the evidence suggesting "the
    English Mastiff has a wider range." In Table [11](#A1.T11 "Table 11 ‣ A.2 Debate
    examples ‣ Appendix A Appendix ‣ Towards Detecting LLMs Hallucination via Markov
    Chain-based Multi-agent Debate Framework"), the agent, post-discussion, identifies
    both of these deficiencies. These observations indicate that larger language models,
    owing to their enhanced reasoning capabilities, yield better results when employing
    our method. Furthermore, it highlights that in some cases, a single round of debate
    may not reveal all inconsistencies between claim and evidence, emphasizing why
    sometimes increasing the minimum debate rounds can improve effectiveness.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 当辩论开始时，初始代理基于问答对及相应证据生成初步意见。如果没有辩论发生，初步意见会巩固为最终答案。然而，这种方法忽略了“莱恩赛犬的颜色范围有限”这一说法所需证据的不足以及与“英式獒犬有更广泛的颜色范围”证据的矛盾。在表格[10](#A1.T10
    "表格 10 ‣ A.2 辩论示例 ‣ 附录 A ‣ 通过基于马尔可夫链的多代理辩论框架检测LLMs幻觉")中，三个代理进行讨论，强调了支持“莱恩赛犬的颜色范围有限”这一说法的证据不足。然而，他们未能推断出与“英式獒犬有更广泛的颜色范围”证据的矛盾。在表格[11](#A1.T11
    "表格 11 ‣ A.2 辩论示例 ‣ 附录 A ‣ 通过基于马尔可夫链的多代理辩论框架检测LLMs幻觉")中，代理在讨论后识别了这两个缺陷。这些观察结果表明，凭借其增强的推理能力，更大的语言模型在采用我们的方法时能够取得更好的结果。此外，它突显了在某些情况下，单轮辩论可能无法揭示所有的主张与证据之间的不一致，这也强调了为何增加最低辩论轮数有时能提高效果。
- en: 5 Conclusion
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论
- en: In this paper, our purpose is to improve the accuracy of hallucination detection
    in content generated by large language models. Simultaneously, we aspired to extend
    this enhancement beyond particular generative tasks. To fulfill these objectives,
    we introduce a versatile framework for hallucination detection and propose the
    Markov Chain-based multi-agent debate verification framework. Our proposed approach
    demonstrates its effectiveness through evaluations conducted on both the Knowledge
    Base Question Answering (KBQA) dataset and the randomly sampled HaluEval dataset.
    We posit that our method demonstrates a level of generalizability, enabling its
    adaptation to other post-processing hallucination detection or mitigation approaches
    for better performance.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们的目的是提高大型语言模型生成内容中的幻觉检测准确性。同时，我们希望将这种提升扩展到特定生成任务之外。为实现这些目标，我们引入了一个多功能的幻觉检测框架，并提出了基于马尔可夫链的多智能体辩论验证框架。我们提出的方法通过在知识库问答（KBQA）数据集和随机抽样的HaluEval数据集上的评估，展示了其有效性。我们认为我们的方法具有一定的泛化能力，使其可以适应其他后处理幻觉检测或缓解方法，以提高性能。
- en: Limitations and Potential Risks
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 限制与潜在风险
- en: Our methodology necessitates frequent interactions with the API of large language
    models (LLMs), resulting in significant overhead. This high frequency of API calls
    increases the cost and reduces response speed, which may limit its practicality
    in real-world scenarios. Nevertheless, this approach provides an accessible option
    for users lacking the infrastructure to implement large open-source models.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的方法需要与大型语言模型（LLMs）的 API 进行频繁交互，导致显著的开销。这种高频率的 API 调用增加了成本并降低了响应速度，这可能限制了其在现实世界中的实用性。然而，这种方法为缺乏实施大型开源模型基础设施的用户提供了一个可行的选项。
- en: Furthermore, the distinctiveness among prompts for different agents primarily
    centers on role definition, while other aspects display considerable similarity.
    This occasionally leads to the partial repetition of opinions from the preceding
    agent. As exemplified by the two instances in Appendix [A.2](#A1.SS2 "A.2 Debate
    examples ‣ Appendix A Appendix ‣ Towards Detecting LLMs Hallucination via Markov
    Chain-based Multi-agent Debate Framework"), this phenomenon could be substantially
    alleviated by enhancing the performance of the base model.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，不同代理之间提示的独特性主要集中在角色定义上，而其他方面显示出相当大的相似性。这偶尔导致前一个代理的意见部分重复。正如附录 [A.2](#A1.SS2
    "A.2 辩论示例 ‣ 附录 A 附录 ‣ 通过基于马尔可夫链的多智能体辩论框架检测 LLM 的幻觉") 中的两个实例所示，通过提高基础模型的性能，这种现象可能会得到显著缓解。
- en: References
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Casper et al. (2023) Stephen Casper, Xander Davies, Claudia Shi, Thomas Krendl
    Gilbert, Jérémy Scheurer, Javier Rando, Rachel Freedman, Tomasz Korbak, David
    Lindner, Pedro Freire, Tony Wang, Samuel Marks, Charbel-Raphaël Segerie, Micah
    Carroll, Andi Peng, Phillip Christoffersen, Mehul Damani, Stewart Slocum, Usman
    Anwar, Anand Siththaranjan, Max Nadeau, Eric J. Michaud, Jacob Pfau, Dmitrii Krasheninnikov,
    Xin Chen, Lauro Langosco, Peter Hase, Erdem Bıyık, Anca Dragan, David Krueger,
    Dorsa Sadigh, and Dylan Hadfield-Menell. 2023. [Open problems and fundamental
    limitations of reinforcement learning from human feedback](http://arxiv.org/abs/2307.15217).
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Casper 等 (2023) Stephen Casper, Xander Davies, Claudia Shi, Thomas Krendl Gilbert,
    Jérémy Scheurer, Javier Rando, Rachel Freedman, Tomasz Korbak, David Lindner,
    Pedro Freire, Tony Wang, Samuel Marks, Charbel-Raphaël Segerie, Micah Carroll,
    Andi Peng, Phillip Christoffersen, Mehul Damani, Stewart Slocum, Usman Anwar,
    Anand Siththaranjan, Max Nadeau, Eric J. Michaud, Jacob Pfau, Dmitrii Krasheninnikov,
    Xin Chen, Lauro Langosco, Peter Hase, Erdem Bıyık, Anca Dragan, David Krueger,
    Dorsa Sadigh, 和 Dylan Hadfield-Menell. 2023. [来自人类反馈的强化学习中的开放问题与基本限制](http://arxiv.org/abs/2307.15217)。
- en: 'Chen et al. (2023) Lichang Chen, Shiyang Li, Jun Yan, Hai Wang, Kalpa Gunaratna,
    Vikas Yadav, Zheng Tang, Vijay Srinivasan, Tianyi Zhou, Heng Huang, and Hongxia
    Jin. 2023. [Alpagasus: Training a better alpaca with fewer data](http://arxiv.org/abs/2307.08701).'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chen 等 (2023) Lichang Chen, Shiyang Li, Jun Yan, Hai Wang, Kalpa Gunaratna,
    Vikas Yadav, Zheng Tang, Vijay Srinivasan, Tianyi Zhou, Heng Huang, 和 Hongxia
    Jin. 2023. [Alpagasus: 用更少的数据训练更好的 Alpaca](http://arxiv.org/abs/2307.08701)。'
- en: 'Chern et al. (2023) I-Chun Chern, Steffi Chern, Shiqi Chen, Weizhe Yuan, Kehua
    Feng, Chunting Zhou, Junxian He, Graham Neubig, and Pengfei Liu. 2023. [Factool:
    Factuality detection in generative ai – a tool augmented framework for multi-task
    and multi-domain scenarios](http://arxiv.org/abs/2307.13528).'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chern 等 (2023) I-Chun Chern, Steffi Chern, Shiqi Chen, Weizhe Yuan, Kehua Feng,
    Chunting Zhou, Junxian He, Graham Neubig, 和 Pengfei Liu. 2023. [Factool: 生成式 AI
    中的事实检测 – 一个增强工具框架，用于多任务和多领域场景](http://arxiv.org/abs/2307.13528)。'
- en: 'Chuang et al. (2023) Yung-Sung Chuang, Yujia Xie, Hongyin Luo, Yoon Kim, James
    Glass, and Pengcheng He. 2023. [Dola: Decoding by contrasting layers improves
    factuality in large language models](http://arxiv.org/abs/2309.03883).'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chuang 等 (2023) Yung-Sung Chuang、Yujia Xie、Hongyin Luo、Yoon Kim、James Glass
    和 Pengcheng He。2023年。[Dola：通过对比层解码改善大型语言模型的真实性](http://arxiv.org/abs/2309.03883)。
- en: 'Cohen et al. (2023) Roi Cohen, May Hamri, Mor Geva, and Amir Globerson. 2023.
    [Lm vs lm: Detecting factual errors via cross examination](http://arxiv.org/abs/2305.13281).'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cohen 等 (2023) Roi Cohen、May Hamri、Mor Geva 和 Amir Globerson。2023年。[Lm vs lm：通过交叉检查检测事实错误](http://arxiv.org/abs/2305.13281)。
- en: 'Das et al. (2022) Souvik Das, Sougata Saha, and Rohini Srihari. 2022. [Diving
    deep into modes of fact hallucinations in dialogue systems](https://doi.org/10.18653/v1/2022.findings-emnlp.48).
    In *Findings of the Association for Computational Linguistics: EMNLP 2022*, pages
    684–699, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Das 等 (2022) Souvik Das、Sougata Saha 和 Rohini Srihari。2022年。[深入探讨对话系统中的事实幻觉模式](https://doi.org/10.18653/v1/2022.findings-emnlp.48)。在
    *计算语言学协会发现：EMNLP 2022* 中，第684–699页，阿布扎比，阿联酋。计算语言学协会。
- en: Du et al. (2023) Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum,
    and Igor Mordatch. 2023. [Improving factuality and reasoning in language models
    through multiagent debate](http://arxiv.org/abs/2305.14325).
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Du 等 (2023) Yilun Du、Shuang Li、Antonio Torralba、Joshua B. Tenenbaum 和 Igor Mordatch。2023年。[通过多智能体辩论改善语言模型的真实性和推理能力](http://arxiv.org/abs/2305.14325)。
- en: 'Elaraby et al. (2023) Mohamed Elaraby, Mengyin Lu, Jacob Dunn, Xueying Zhang,
    Yu Wang, Shizhu Liu, Pingchuan Tian, Yuping Wang, and Yuxuan Wang. 2023. [Halo:
    Estimation and reduction of hallucinations in open-source weak large language
    models](http://arxiv.org/abs/2308.11764).'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Elaraby 等 (2023) Mohamed Elaraby、Mengyin Lu、Jacob Dunn、Xueying Zhang、Yu Wang、Shizhu
    Liu、Pingchuan Tian、Yuping Wang 和 Yuxuan Wang。2023年。[Halo：开源弱大型语言模型中的幻觉估计与减少](http://arxiv.org/abs/2308.11764)。
- en: Fu et al. (2023) Yao Fu, Hao Peng, Tushar Khot, and Mirella Lapata. 2023. [Improving
    language model negotiation with self-play and in-context learning from ai feedback](http://arxiv.org/abs/2305.10142).
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fu 等 (2023) Yao Fu、Hao Peng、Tushar Khot 和 Mirella Lapata。2023年。[通过自我对弈和上下文学习改善语言模型协商](http://arxiv.org/abs/2305.10142)。
- en: 'Gao et al. (2023) Luyu Gao, Zhuyun Dai, Panupong Pasupat, Anthony Chen, Arun Tejasvi
    Chaganty, Yicheng Fan, Vincent Zhao, Ni Lao, Hongrae Lee, Da-Cheng Juan, and Kelvin
    Guu. 2023. [RARR: Researching and revising what language models say, using language
    models](https://doi.org/10.18653/v1/2023.acl-long.910). In *Proceedings of the
    61st Annual Meeting of the Association for Computational Linguistics (Volume 1:
    Long Papers)*, pages 16477–16508, Toronto, Canada. Association for Computational
    Linguistics.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao 等 (2023) Luyu Gao、Zhuyun Dai、Panupong Pasupat、Anthony Chen、Arun Tejasvi
    Chaganty、Yicheng Fan、Vincent Zhao、Ni Lao、Hongrae Lee、Da-Cheng Juan 和 Kelvin Guu。2023年。[RARR：研究和修订语言模型所说内容，使用语言模型](https://doi.org/10.18653/v1/2023.acl-long.910)。在
    *第61届计算语言学协会年会论文集（卷1：长篇论文）* 中，第16477–16508页，加拿大多伦多。计算语言学协会。
- en: Gero et al. (2023) Zelalem Gero, Chandan Singh, Hao Cheng, Tristan Naumann,
    Michel Galley, Jianfeng Gao, and Hoifung Poon. 2023. [Self-verification improves
    few-shot clinical information extraction](https://openreview.net/forum?id=SBbJICrglS).
    In *ICML 3rd Workshop on Interpretable Machine Learning in Healthcare (IMLH)*.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gero 等 (2023) Zelalem Gero、Chandan Singh、Hao Cheng、Tristan Naumann、Michel Galley、Jianfeng
    Gao 和 Hoifung Poon。2023年。[自我验证改善少量临床信息提取](https://openreview.net/forum?id=SBbJICrglS)。在
    *ICML 第三届可解释机器学习在医疗保健中的应用研讨会 (IMLH)*。
- en: 'Goyal and Durrett (2021) Tanya Goyal and Greg Durrett. 2021. [Annotating and
    modeling fine-grained factuality in summarization](https://doi.org/10.18653/v1/2021.naacl-main.114).
    In *Proceedings of the 2021 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies*, pages 1449–1462,
    Online. Association for Computational Linguistics.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goyal 和 Durrett (2021) Tanya Goyal 和 Greg Durrett。2021年。[总结中的细粒度真实性标注和建模](https://doi.org/10.18653/v1/2021.naacl-main.114)。在
    *2021年北美计算语言学协会计算语言学与人类语言技术会议论文集* 中，第1449–1462页，在线。计算语言学协会。
- en: Guo et al. (2022) Zhijiang Guo, Michael Schlichtkrull, and Andreas Vlachos.
    2022. [A survey on automated fact-checking](https://doi.org/10.1162/tacl_a_00454).
    *Transactions of the Association for Computational Linguistics*, 10:178–206.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo 等 (2022) Zhijiang Guo、Michael Schlichtkrull 和 Andreas Vlachos。2022年。[自动化事实检查综述](https://doi.org/10.1162/tacl_a_00454)。*计算语言学协会论文集*，10:178–206。
- en: Huang et al. (2023) Jie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu Steven Zheng,
    Adams Wei Yu, Xinying Song, and Denny Zhou. 2023. [Large language models cannot
    self-correct reasoning yet](http://arxiv.org/abs/2310.01798).
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等（2023）Jie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu Steven Zheng, Adams
    Wei Yu, Xinying Song 和 Denny Zhou. 2023. [大型语言模型尚不能自我纠正推理](http://arxiv.org/abs/2310.01798)。
- en: Ji et al. (2023) Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan
    Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. 2023. [Survey
    of hallucination in natural language generation](https://doi.org/10.1145/3571730).
    *ACM Comput. Surv.*, 55(12).
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ji 等（2023）Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko
    Ishii, Ye Jin Bang, Andrea Madotto 和 Pascale Fung. 2023. [自然语言生成中的幻觉调查](https://doi.org/10.1145/3571730).
    *ACM Comput. Surv.*, 55(12)。
- en: Kryscinski et al. (2020) Wojciech Kryscinski, Bryan McCann, Caiming Xiong, and
    Richard Socher. 2020. [Evaluating the factual consistency of abstractive text
    summarization](https://doi.org/10.18653/v1/2020.emnlp-main.750). In *Proceedings
    of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)*,
    pages 9332–9346, Online. Association for Computational Linguistics.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kryscinski 等（2020）Wojciech Kryscinski, Bryan McCann, Caiming Xiong 和 Richard
    Socher. 2020. [评估抽象文本摘要的事实一致性](https://doi.org/10.18653/v1/2020.emnlp-main.750).
    见 *2020年自然语言处理实证方法会议论文集（EMNLP）*，页码 9332–9346，在线。计算语言学协会。
- en: Lee et al. (2022) Nayeon Lee, Wei Ping, Peng Xu, Mostofa Patwary, Pascale N
    Fung, Mohammad Shoeybi, and Bryan Catanzaro. 2022. [Factuality enhanced language
    models for open-ended text generation](https://proceedings.neurips.cc/paper_files/paper/2022/file/df438caa36714f69277daa92d608dd63-Paper-Conference.pdf).
    In *Advances in Neural Information Processing Systems*, volume 35, pages 34586–34599\.
    Curran Associates, Inc.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee 等（2022）Nayeon Lee, Wei Ping, Peng Xu, Mostofa Patwary, Pascale N Fung, Mohammad
    Shoeybi 和 Bryan Catanzaro. 2022. [针对开放式文本生成的事实性增强语言模型](https://proceedings.neurips.cc/paper_files/paper/2022/file/df438caa36714f69277daa92d608dd63-Paper-Conference.pdf).
    见 *神经信息处理系统进展*，第 35 卷，页码 34586–34599\. Curran Associates, Inc.
- en: 'Li et al. (2023a) Junyi Li, Xiaoxue Cheng, Wayne Xin Zhao, Jian-Yun Nie, and
    Ji-Rong Wen. 2023a. [Halueval: A large-scale hallucination evaluation benchmark
    for large language models](http://arxiv.org/abs/2305.11747).'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等（2023a）Junyi Li, Xiaoxue Cheng, Wayne Xin Zhao, Jian-Yun Nie 和 Ji-Rong Wen.
    2023a. [Halueval：针对大型语言模型的大规模幻觉评估基准](http://arxiv.org/abs/2305.11747)。
- en: 'Li et al. (2023b) Kenneth Li, Oam Patel, Fernanda Viégas, Hanspeter Pfister,
    and Martin Wattenberg. 2023b. [Inference-time intervention: Eliciting truthful
    answers from a language model](http://arxiv.org/abs/2306.03341).'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等（2023b）Kenneth Li, Oam Patel, Fernanda Viégas, Hanspeter Pfister 和 Martin
    Wattenberg. 2023b. [推理时间干预：从语言模型中引出真实答案](http://arxiv.org/abs/2306.03341)。
- en: Liang et al. (2023) Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang,
    Rui Wang, Yujiu Yang, Zhaopeng Tu, and Shuming Shi. 2023. [Encouraging divergent
    thinking in large language models through multi-agent debate](http://arxiv.org/abs/2305.19118).
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liang 等（2023）Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui
    Wang, Yujiu Yang, Zhaopeng Tu 和 Shuming Shi. 2023. [通过多代理辩论鼓励大型语言模型的发散思维](http://arxiv.org/abs/2305.19118)。
- en: Longpre et al. (2021) Shayne Longpre, Kartik Perisetla, Anthony Chen, Nikhil
    Ramesh, Chris DuBois, and Sameer Singh. 2021. [Entity-based knowledge conflicts
    in question answering](https://doi.org/10.18653/v1/2021.emnlp-main.565). In *Proceedings
    of the 2021 Conference on Empirical Methods in Natural Language Processing*, pages
    7052–7063, Online and Punta Cana, Dominican Republic. Association for Computational
    Linguistics.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Longpre 等（2021）Shayne Longpre, Kartik Perisetla, Anthony Chen, Nikhil Ramesh,
    Chris DuBois 和 Sameer Singh. 2021. [基于实体的知识冲突在问答中的应用](https://doi.org/10.18653/v1/2021.emnlp-main.565).
    见 *2021年自然语言处理实证方法会议论文集*，页码 7052–7063，在线和多米尼加共和国蓬塔卡纳。计算语言学协会。
- en: 'Manakul et al. (2023) Potsawee Manakul, Adian Liusie, and Mark J. F. Gales.
    2023. [Selfcheckgpt: Zero-resource black-box hallucination detection for generative
    large language models](http://arxiv.org/abs/2303.08896).'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Manakul 等（2023）Potsawee Manakul, Adian Liusie 和 Mark J. F. Gales. 2023. [Selfcheckgpt：针对生成性大型语言模型的零资源黑箱幻觉检测](http://arxiv.org/abs/2303.08896)。
- en: Maynez et al. (2020) Joshua Maynez, Shashi Narayan, Bernd Bohnet, and Ryan McDonald.
    2020. [On faithfulness and factuality in abstractive summarization](https://doi.org/10.18653/v1/2020.acl-main.173).
    In *Proceedings of the 58th Annual Meeting of the Association for Computational
    Linguistics*, pages 1906–1919, Online. Association for Computational Linguistics.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Maynez 等（2020）**Joshua Maynez**, **Shashi Narayan**, **Bernd Bohnet**，和 **Ryan
    McDonald**。2020年。[On faithfulness and factuality in abstractive summarization](https://doi.org/10.18653/v1/2020.acl-main.173)。在
    *Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics*
    中，第1906–1919页，在线。计算语言学协会。
- en: OpenAI (2023) OpenAI. 2023. [Gpt-4 technical report](http://arxiv.org/abs/2303.08774).
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI（2023）**OpenAI**。2023年。[Gpt-4 technical report](http://arxiv.org/abs/2303.08774)。
- en: 'Park et al. (2023) Joon Sung Park, Joseph C. O’Brien, Carrie J. Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S. Bernstein. 2023. [Generative agents: Interactive
    simulacra of human behavior](http://arxiv.org/abs/2304.03442).'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Park 等（2023）**Joon Sung Park**, **Joseph C. O’Brien**, **Carrie J. Cai**, **Meredith
    Ringel Morris**, **Percy Liang**，和 **Michael S. Bernstein**。2023年。[Generative
    agents: Interactive simulacra of human behavior](http://arxiv.org/abs/2304.03442)。'
- en: 'Peng et al. (2023) Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng, Yujia
    Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou Yu, Weizhu Chen, and Jianfeng Gao.
    2023. [Check your facts and try again: Improving large language models with external
    knowledge and automated feedback](http://arxiv.org/abs/2302.12813).'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Peng 等（2023）**Baolin Peng**, **Michel Galley**, **Pengcheng He**, **Hao Cheng**,
    **Yujia Xie**, **Yu Hu**, **Qiuyuan Huang**, **Lars Liden**, **Zhou Yu**, **Weizhu
    Chen**，和 **Jianfeng Gao**。2023年。[Check your facts and try again: Improving large
    language models with external knowledge and automated feedback](http://arxiv.org/abs/2302.12813)。'
- en: 'Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem
    Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia
    Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou,
    Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem
    Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana
    Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra,
    Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan
    Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen
    Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng
    Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang,
    Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023. [Llama
    2: Open foundation and fine-tuned chat models](http://arxiv.org/abs/2307.09288).'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Touvron 等（2023）**Hugo Touvron**, **Louis Martin**, **Kevin Stone**, **Peter
    Albert**, **Amjad Almahairi**, **Yasmine Babaei**, **Nikolay Bashlykov**, **Soumya
    Batra**, **Prajjwal Bhargava**, **Shruti Bhosale**, **Dan Bikel**, **Lukas Blecher**,
    **Cristian Canton Ferrer**, **Moya Chen**, **Guillem Cucurull**, **David Esiobu**,
    **Jude Fernandes**, **Jeremy Fu**, **Wenyin Fu**, **Brian Fuller**, **Cynthia
    Gao**, **Vedanuj Goswami**, **Naman Goyal**, **Anthony Hartshorn**, **Saghar Hosseini**,
    **Rui Hou**, **Hakan Inan**, **Marcin Kardas**, **Viktor Kerkez**, **Madian Khabsa**,
    **Isabel Kloumann**, **Artem Korenev**, **Punit Singh Koura**, **Marie-Anne Lachaux**,
    **Thibaut Lavril**, **Jenya Lee**, **Diana Liskovich**, **Yinghai Lu**, **Yuning
    Mao**, **Xavier Martinet**, **Todor Mihaylov**, **Pushkar Mishra**, **Igor Molybog**,
    **Yixin Nie**, **Andrew Poulton**, **Jeremy Reizenstein**, **Rashi Rungta**, **Kalyan
    Saladi**, **Alan Schelten**, **Ruan Silva**, **Eric Michael Smith**, **Ranjan
    Subramanian**, **Xiaoqing Ellen Tan**, **Binh Tang**, **Ross Taylor**, **Adina
    Williams**, **Jian Xiang Kuan**, **Puxin Xu**, **Zheng Yan**, **Iliyan Zarov**,
    **Yuchen Zhang**, **Angela Fan**, **Melanie Kambadur**, **Sharan Narang**, **Aurelien
    Rodriguez**, **Robert Stojnic**, **Sergey Edunov**，和 **Thomas Scialom**。2023年。[Llama
    2: Open foundation and fine-tuned chat models](http://arxiv.org/abs/2307.09288)。'
- en: 'Vu et al. (2023) Tu Vu, Mohit Iyyer, Xuezhi Wang, Noah Constant, Jerry Wei,
    Jason Wei, Chris Tar, Yun-Hsuan Sung, Denny Zhou, Quoc Le, and Thang Luong. 2023.
    [Freshllms: Refreshing large language models with search engine augmentation](http://arxiv.org/abs/2310.03214).'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Vu 等（2023）**Tu Vu**, **Mohit Iyyer**, **Xuezhi Wang**, **Noah Constant**, **Jerry
    Wei**, **Jason Wei**, **Chris Tar**, **Yun-Hsuan Sung**, **Denny Zhou**, **Quoc
    Le**，和 **Thang Luong**。2023年。[Freshllms: Refreshing large language models with
    search engine augmentation](http://arxiv.org/abs/2310.03214)。'
- en: Wei et al. (2022) Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph,
    Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler,
    Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William
    Fedus. 2022. [Emergent abilities of large language models](https://openreview.net/forum?id=yzkSU5zdwD).
    *Transactions on Machine Learning Research*. Survey Certification.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等（2022）**Jason Wei**, **Yi Tay**, **Rishi Bommasani**, **Colin Raffel**,
    **Barret Zoph**, **Sebastian Borgeaud**, **Dani Yogatama**, **Maarten Bosma**,
    **Denny Zhou**, **Donald Metzler**, **Ed H. Chi**, **Tatsunori Hashimoto**, **Oriol
    Vinyals**, **Percy Liang**, **Jeff Dean**，和 **William Fedus**。2022年。[Emergent
    abilities of large language models](https://openreview.net/forum?id=yzkSU5zdwD)。*Transactions
    on Machine Learning Research*。综述认证。
- en: 'Wu et al. (2023a) Wenhao Wu, Wei Li, Xinyan Xiao, Jiachen Liu, Sujian Li, and
    Yajuan Lyu. 2023a. [WeCheck: Strong factual consistency checker via weakly supervised
    learning](https://doi.org/10.18653/v1/2023.acl-long.18). In *Proceedings of the
    61st Annual Meeting of the Association for Computational Linguistics (Volume 1:
    Long Papers)*, pages 307–321, Toronto, Canada. Association for Computational Linguistics.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu et al. (2023a) Wenhao Wu, Wei Li, Xinyan Xiao, Jiachen Liu, Sujian Li, and
    Yajuan Lyu. 2023a. [WeCheck：通过弱监督学习的强事实一致性检查器](https://doi.org/10.18653/v1/2023.acl-long.18)。在*第61届计算语言学协会年会（第1卷：长篇论文）*，第307–321页，加拿大多伦多。计算语言学协会。
- en: Wu et al. (2023b) Zeqiu Wu, Yushi Hu, Weijia Shi, Nouha Dziri, Alane Suhr, Prithviraj
    Ammanabrolu, Noah A. Smith, Mari Ostendorf, and Hannaneh Hajishirzi. 2023b. [Fine-grained
    human feedback gives better rewards for language model training](http://arxiv.org/abs/2306.01693).
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu et al. (2023b) Zeqiu Wu, Yushi Hu, Weijia Shi, Nouha Dziri, Alane Suhr, Prithviraj
    Ammanabrolu, Noah A. Smith, Mari Ostendorf, and Hannaneh Hajishirzi. 2023b. [细粒度的人类反馈为语言模型训练提供更好的奖励](http://arxiv.org/abs/2306.01693)。
- en: 'Xiong et al. (2023) Kai Xiong, Xiao Ding, Yixin Cao, Ting Liu, and Bing Qin.
    2023. [Examining inter-consistency of large language models collaboration: An
    in-depth analysis via debate](http://arxiv.org/abs/2305.11595).'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xiong et al. (2023) Kai Xiong, Xiao Ding, Yixin Cao, Ting Liu, and Bing Qin.
    2023. [审查大型语言模型协作的内部一致性：通过辩论的深入分析](http://arxiv.org/abs/2305.11595)。
- en: Xu et al. (2023a) Weijia Xu, Sweta Agrawal, Eleftheria Briakou, Marianna J.
    Martindale, and Marine Carpuat. 2023a. [Understanding and detecting hallucinations
    in neural machine translation via model introspection](https://doi.org/10.1162/tacl_a_00563).
    *Transactions of the Association for Computational Linguistics*, 11:546–564.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu et al. (2023a) Weijia Xu, Sweta Agrawal, Eleftheria Briakou, Marianna J.
    Martindale, and Marine Carpuat. 2023a. [通过模型内省理解和检测神经机器翻译中的幻觉](https://doi.org/10.1162/tacl_a_00563)。*计算语言学协会会刊*，11:546–564。
- en: 'Xu et al. (2023b) Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang,
    Weidong Liu, and Yang Liu. 2023b. [Exploring large language models for communication
    games: An empirical study on werewolf](http://arxiv.org/abs/2309.04658).'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu et al. (2023b) Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang,
    Weidong Liu, and Yang Liu. 2023b. [探索大语言模型在沟通游戏中的应用：关于狼人杀的实证研究](http://arxiv.org/abs/2309.04658)。
- en: 'Zhang et al. (2023a) Jiaxin Zhang, Zhuohang Li, Kamalika Das, Bradley A. Malin,
    and Sricharan Kumar. 2023a. [Sac³: Reliable hallucination detection in black-box
    language models via semantic-aware cross-check consistency](http://arxiv.org/abs/2311.01740).'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2023a) Jiaxin Zhang, Zhuohang Li, Kamalika Das, Bradley A. Malin,
    and Sricharan Kumar. 2023a. [Sac³：通过语义感知交叉检查一致性在黑箱语言模型中可靠地检测幻觉](http://arxiv.org/abs/2311.01740)。
- en: 'Zhang et al. (2023b) Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen
    Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen, Longyue Wang, Anh Tuan Luu,
    Wei Bi, Freda Shi, and Shuming Shi. 2023b. [Siren’s song in the ai ocean: A survey
    on hallucination in large language models](http://arxiv.org/abs/2309.01219).'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2023b) Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen
    Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen, Longyue Wang, Anh Tuan Luu,
    Wei Bi, Freda Shi, and Shuming Shi. 2023b. [AI 海洋中的塞壬之歌：对大型语言模型中幻觉的调查](http://arxiv.org/abs/2309.01219)。
- en: Zheng et al. (2023) Shen Zheng, Jie Huang, and Kevin Chen-Chuan Chang. 2023.
    [Why does chatgpt fall short in providing truthful answers?](http://arxiv.org/abs/2304.10513)
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng et al. (2023) Shen Zheng, Jie Huang, and Kevin Chen-Chuan Chang. 2023.
    [为什么 ChatGPT 在提供真实答案时会有所不足？](http://arxiv.org/abs/2304.10513)
- en: 'Zhu et al. (2023) Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su,
    Chenyu Yang, Gao Huang, Bin Li, Lewei Lu, Xiaogang Wang, Yu Qiao, Zhaoxiang Zhang,
    and Jifeng Dai. 2023. [Ghost in the minecraft: Generally capable agents for open-world
    environments via large language models with text-based knowledge and memory](http://arxiv.org/abs/2305.17144).'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu et al. (2023) Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su,
    Chenyu Yang, Gao Huang, Bin Li, Lewei Lu, Xiaogang Wang, Yu Qiao, Zhaoxiang Zhang,
    and Jifeng Dai. 2023. [Minecraft中的幽灵：通过具有文本知识和记忆的大型语言模型在开放世界环境中通用的代理](http://arxiv.org/abs/2305.17144)。
- en: Appendix A Appendix
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 附录
- en: A.1 Prompts
  id: totrans-182
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 提示
- en: Table [6](#A1.T6 "Table 6 ‣ A.1 Prompts ‣ Appendix A Appendix ‣ Towards Detecting
    LLMs Hallucination via Markov Chain-based Multi-agent Debate Framework"), [7](#A1.T7
    "Table 7 ‣ A.1 Prompts ‣ Appendix A Appendix ‣ Towards Detecting LLMs Hallucination
    via Markov Chain-based Multi-agent Debate Framework"), [8](#A1.T8 "Table 8 ‣ A.1
    Prompts ‣ Appendix A Appendix ‣ Towards Detecting LLMs Hallucination via Markov
    Chain-based Multi-agent Debate Framework") and [9](#A1.T9 "Table 9 ‣ A.1 Prompts
    ‣ Appendix A Appendix ‣ Towards Detecting LLMs Hallucination via Markov Chain-based
    Multi-agent Debate Framework") enumerate various prompts employed in our experimental
    design, including prompts for establishing different roles for the agent and prompts
    for eliminating subjective opinions from dialogue responses.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 表[6](#A1.T6 "Table 6 ‣ A.1 Prompts ‣ Appendix A Appendix ‣ Towards Detecting
    LLMs Hallucination via Markov Chain-based Multi-agent Debate Framework")、[7](#A1.T7
    "Table 7 ‣ A.1 Prompts ‣ Appendix A Appendix ‣ Towards Detecting LLMs Hallucination
    via Markov Chain-based Multi-agent Debate Framework")、[8](#A1.T8 "Table 8 ‣ A.1
    Prompts ‣ Appendix A Appendix ‣ Towards Detecting LLMs Hallucination via Markov
    Chain-based Multi-agent Debate Framework") 和[9](#A1.T9 "Table 9 ‣ A.1 Prompts
    ‣ Appendix A Appendix ‣ Towards Detecting LLMs Hallucination via Markov Chain-based
    Multi-agent Debate Framework")列举了我们实验设计中使用的各种提示，包括用于为代理建立不同角色的提示和用于消除对话响应中的主观意见的提示。
- en: '| You are the *Trust* agent of the three agents. Your task is to trust the
    previous agent’s opinions as much as possible and to further expand upon it. You
    are given the opinions generated by a previous agent. Refer to the claim[text]
    and evidence[evidences] to analyse the opinions[previous opinions] of the previous
    agent. Carefully examine whether the corresponding evidences support the statements
    put forward by the previous agent. If you believe any part of them is accurate,
    please further analyze it based on that. Then assess the factuality of the initial
    claim [text] based on the provided information [evidences] and the previous agent’s
    opinions. DO NOT REPEAT the previous agent’s opinion, you should develop your
    own perspective based on theirs. Take the previous agent’s opinions as a reference
    rather than copying it directly. The response should be a dictionary with three
    keys - "opinion", "factuality", "Error severity" which correspond to the your
    opinion, whether the given text is factual or not (Boolean - True or False), the
    severity level of claim error(Integer - Range from 0 to 5). The definitions of
    different levels of error severity are as follows: 0. No Error (Grade 0): This
    is when the claim is entirely factual and accurate, with no errors or inaccuracies.
    1. Minor Errors (Grade 1): These are small and insignificant errors that do not
    significantly alter the essence or validity of the claim. For example, minor spelling
    mistakes, incorrect dates or small numerical discrepancies. 2. Moderate Errors
    (Grade 2): These are errors that have some impact on the validity of the claim
    but do not reverse its overall meaning. For example, wrong terminologies, improper
    use of statistics or minor deviations from the evidence. 3. Major Errors (Grade
    3): These are errors that have a significant impact on the validity of the claim.
    These errors may lead to significant misunderstandings or misinterpretations.
    Examples could be gross exaggeration or underestimation, misuse of expert authority,
    or manipulation of context. 4. Critical Errors (Grade 4): These are errors that
    completely negate or invalidate the claim. The evidence contradicts the claim
    so fundamentally that its veracity is entirely undermined. For example, attribution
    of a quote or event to the wrong person or an incorrect recap of a major event.
    5. False Claim (Grade 5): This is when claims are entirely made up or intentionally
    deceptive, without any grounding in evidence. They are blatant lies designed to
    mislead or deceive, fabricating events, people, or statements that do not exist
    or never occurred. YOU SHOULD ONLY RESPONSE IN FORMAT AS DESCRIBED BELOW. DO NOT
    RETURN ANYTHING ELSE. START YOUR RESPONSE WITH ’{{’. [response format]: {{ "opinion":
    "First analyze the opinions of the previous agent, point out what you think is
    correct or incorrect in its opinions and explain the reasons. Remember that you
    should trust previous agent’s opinion as much as possible. And then describe your
    opinion about factuality of the claim[text] based on the evidences [evidences].
    Your opinions should be supported by corresponding evidences. DO NOT REITERATE
    THE PREVIOUS AGENT’S OPINIONS [previous opinions].", "factuality": True if the
    given text is factual, False otherwise., "Error severity": Integer - Range from
    0 to 5\. The severity level of claim error. According to the definitions of levels
    of the error severity, please carefully compare "claim" and "evidence" and provide
    appropriate degree. }} |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 你是三个代理中的*信任*代理。你的任务是尽可能信任前一个代理的意见，并在此基础上进一步扩展。你将获得前一个代理生成的意见。参考声明[text]和证据[evidences]来分析前一个代理的意见[previous
    opinions]。仔细检查相应的证据是否支持前一个代理提出的陈述。如果你认为其中任何部分是准确的，请在此基础上进一步分析。然后根据提供的信息[evidences]和前一个代理的意见来评估初始声明[text]的真实性。请不要重复前一个代理的意见，你应该基于他们的观点发展自己的看法。将前一个代理的意见作为参考，而不是直接复制。回应应该是一个包含三个键的字典
    - “opinion”，“factuality”，“Error severity”，分别对应于你的意见，给定文本是否真实（布尔值 - True 或 False），以及声明错误的严重程度（整数
    - 范围从 0 到 5）。不同错误严重程度的定义如下： 0. 无错误（等级 0）：声明完全真实准确，没有错误或不准确之处。 1. 轻微错误（等级 1）：这些是小而无关紧要的错误，不会显著改变声明的本质或有效性。例如，轻微的拼写错误、日期错误或小的数字差异。
    2. 中等错误（等级 2）：这些错误对声明的有效性有一定影响，但不会颠覆其整体意义。例如，错误的术语、不当使用统计数据或轻微偏离证据。 3. 重大错误（等级
    3）：这些错误对声明的有效性有显著影响。这些错误可能导致严重的误解或误读。例如，严重夸张或低估、误用专家权威或上下文的操控。 4. 严重错误（等级 4）：这些错误完全否定或使声明失效。证据与声明根本相悖，以至于其真实性完全受到削弱。例如，将引言或事件归于错误的人，或对重大事件的不正确回顾。
    5. 虚假声明（等级 5）：这些是完全捏造或故意误导的声明，没有任何证据基础。它们是明显的谎言，旨在误导或欺骗，编造不存在或从未发生的事件、人物或陈述。 你应该仅以所描述的格式回应。不要返回任何其他内容。以’{{’开头你的回应。[回应格式]：{{
    "opinion": "首先分析前一个代理的意见，指出你认为其意见中的正确或错误之处，并解释原因。记住，你应尽可能信任前一个代理的意见。然后，根据证据[evidences]描述你对声明[text]真实性的看法。你的意见应得到相应证据的支持。不要重复前一个代理的意见[previous
    opinions]。", "factuality": 如果给定文本是真实的，则为 True，否则为 False。, "Error severity": 整数
    - 范围从 0 到 5。根据错误严重程度的定义，仔细比较“声明”和“证据”，并提供适当的程度。 }}'
- en: 'Table 6: Prompt For Trust Agent'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '表 6: 适用于**信任代理**的提示'
- en: '| You are the *Skeptic* agent of the three agents. "Skeptic" means you must
    question the previous agent’s opinions by scrutinizing the available data [text]
    and [evidences] and identifying any possible errors or misleading factors in previous
    agent’s opinions. You are given the opinions generated by a previous agent. Refer
    to the claim[text] and evidence[evidences] to analyse the opinions[previous opinions]
    of the previous agent. Carefully examine whether the corresponding evidences support
    the statements put forward by the previous agent. If you believe any part of its
    opinions is incorrect, please point it out and explain your perspective. Then
    critically examine the validity of the claim [text], considering any potential
    biases or inconsistencies between the information [evidences] and claim [text].
    DO NOT REPEAT the previous agent’s opinion, you should develop your own perspective
    based on theirs. Take the previous agent’s opinions as a reference rather than
    copying it directly. The response should be a dictionary with three keys - "opinion",
    "factuality", "Error severity" which correspond to the your opinion, whether the
    given text is factual or not (Boolean - True or False), the severity level of
    claim error(Integer - Range from 0 to 5). The definitions of different levels
    of error severity are as follows: 0. No Error (Grade 0): This is when the claim
    is entirely factual and accurate, with no errors or inaccuracies. 1. Minor Errors
    (Grade 1): These are small and insignificant errors that do not significantly
    alter the essence or validity of the claim. For example, minor spelling mistakes,
    incorrect dates or small numerical discrepancies. 2. Moderate Errors (Grade 2):
    These are errors that have some impact on the validity of the claim but do not
    reverse its overall meaning. For example, wrong terminologies, improper use of
    statistics or minor deviations from the evidence. 3. Major Errors (Grade 3): These
    are errors that have a significant impact on the validity of the claim. These
    errors may lead to significant misunderstandings or misinterpretations. Examples
    could be gross exaggeration or underestimation, misuse of expert authority, or
    manipulation of context. 4. Critical Errors (Grade 4): These are errors that completely
    negate or invalidate the claim. The evidence contradicts the claim so fundamentally
    that its veracity is entirely undermined. For example, attribution of a quote
    or event to the wrong person or an incorrect recap of a major event. 5. False
    Claim (Grade 5): This is when claims are entirely made up or intentionally deceptive,
    without any grounding in evidence. They are blatant lies designed to mislead or
    deceive, fabricating events, people, or statements that do not exist or never
    occurred. YOU SHOULD ONLY RESPONSE IN FORMAT AS DESCRIBED BELOW. DO NOT RETURN
    ANYTHING ELSE. START YOUR RESPONSE WITH ’{{’. [response format]: {{ "opinion":
    "First analyze the opinions of the previous agent, point out what you think is
    correct or incorrect in its opinions and explain the reasons. Remember that you
    should doubt the opinions of the previous agent as much as possible. And then
    describe your opinion about factuality of the claim[text] based on the evidences
    [evidences]. Your opinions should be supported by corresponding evidences. DO
    NOT REITERATE THE PREVIOUS AGENT’S OPINIONS [previous opinions].", "factuality":
    True if the given text is factual, False otherwise., "Error severity": Integer
    - Range from 0 to 5\. The severity level of claim error. According to the definitions
    of levels of the error severity, please carefully compare "claim" and "evidence"
    and provide appropriate degree. }} |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| 你是三名代理中的*怀疑者*代理。“怀疑者”意味着你必须通过仔细审查可用数据[text]和[evidences]来质疑前一代理的观点，并识别任何可能的错误或误导因素。你会获得前一代理生成的观点。参考声明[text]和证据[evidences]来分析前一代理的观点[previous
    opinions]。仔细检查相应的证据是否支持前一代理提出的陈述。如果你认为其观点的任何部分不正确，请指出并解释你的观点。然后，批判性地检查声明[text]的有效性，考虑信息[evidences]和声明[text]之间的任何潜在偏见或不一致。不要重复前一代理的观点，你应该基于前一代理的观点发展自己的看法。将前一代理的观点作为参考，而不是直接复制。回应应为一个字典，包含三个键
    - “opinion”，“factuality”，“Error severity”，它们分别对应你的观点、给定文本是否真实（布尔值 - 真或假）以及声明错误的严重级别（整数
    - 范围从0到5）。不同错误严重级别的定义如下：0. 无错误（等级0）：这是当声明完全真实准确，没有任何错误或不准确之处时。1. 小错误（等级1）：这些是小而无关紧要的错误，不会显著改变声明的本质或有效性。例如，小的拼写错误、不正确的日期或小的数字差异。2.
    中等错误（等级2）：这些是对声明的有效性有一定影响但不会颠覆整体意义的错误。例如，术语使用错误、统计数据使用不当或轻微偏离证据。3. 重大错误（等级3）：这些是对声明的有效性有显著影响的错误。这些错误可能导致显著的误解或误读。例如，夸大或低估、错误使用专家权威或上下文操控。4.
    关键错误（等级4）：这些是完全否定或使声明无效的错误。证据与声明根本矛盾，以至于其真实性完全被削弱。例如，将引述或事件归因于错误的人或错误回顾重大事件。5.
    虚假声明（等级5）：这是当声明完全虚构或故意欺骗，没有任何证据支持。它们是明显的谎言，旨在误导或欺骗，编造不存在或从未发生的事件、人物或陈述。你应该仅以描述的格式回应。不要返回任何其他内容。开始你的回应时以’{{’为首。[回应格式]：{{
    "opinion": "首先分析前一代理的观点，指出你认为其观点中的正确或不正确之处，并解释原因。记住，你应尽可能怀疑前一代理的观点。然后，根据证据[evidences]描述你对声明[text]的真实性的看法。你的观点应得到相应证据的支持。不要重复前一代理的观点[previous
    opinions]。", "factuality": True if the given text is factual, False otherwise.,
    "Error severity": Integer - 范围从0到5。根据错误严重级别的定义，请仔细比较“声明”和“证据”，并提供适当的等级。 }} |'
- en: 'Table 7: Prompt For Skeptic Agent'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 7：*怀疑者代理的提示*
- en: '| You are the *Leader* agent of the three agents. The other two agents are
    ’Trust’ and ’Skeptic’ agents. The ’Trust’ agent will trust the previous agent’s
    opinion as soon as possible and the ’Skeptic’ agent will doubt the previous agent’s
    opinion as soon as possible. You are given the opinions generated by two previous
    agents. Incorporate the opinions[previous opinions] provided by the ’Trust’ and
    ’Skeptic’ agents to synthesize the most accurate and reliable conclusion regarding
    the claim([text])’s veracity based on the [evidences]. You need to consider the
    characteristics of these two agents when forming your own opinions. Assess the
    strengths and weaknesses of both sides, and leverage the provided information
    to generate a conclusive judgment. DO NOT REPEAT the previous agent’s opinion,
    you should develop your own perspective based on theirs. Take the previous agent’s
    opinions as a reference rather than copying it directly. The response should be
    a dictionary with three keys - "opinion", "factuality", "Error severity" which
    correspond to the your opinion, whether the given text is factual or not (Boolean
    - True or False), the severity level of claim error(Integer - Range from 0 to
    5). The definitions of different levels of error severity are as follows: 0. No
    Error (Grade 0): This is when the claim is entirely factual and accurate, with
    no errors or inaccuracies. 1. Minor Errors (Grade 1): These are small and insignificant
    errors that do not significantly alter the essence or validity of the claim. For
    example, minor spelling mistakes, incorrect dates or small numerical discrepancies.
    2. Moderate Errors (Grade 2): These are errors that have some impact on the validity
    of the claim but do not reverse its overall meaning. For example, wrong terminologies,
    improper use of statistics or minor deviations from the evidence. 3. Major Errors
    (Grade 3): These are errors that have a significant impact on the validity of
    the claim. These errors may lead to significant misunderstandings or misinterpretations.
    Examples could be gross exaggeration or underestimation, misuse of expert authority,
    or manipulation of context. 4. Critical Errors (Grade 4): These are errors that
    completely negate or invalidate the claim. The evidence contradicts the claim
    so fundamentally that its veracity is entirely undermined. For example, attribution
    of a quote or event to the wrong person or an incorrect recap of a major event.
    5. False Claim (Grade 5): This is when claims are entirely made up or intentionally
    deceptive, without any grounding in evidence. They are blatant lies designed to
    mislead or deceive, fabricating events, people, or statements that do not exist
    or never occurred. YOU SHOULD ONLY RESPONSE IN FORMAT AS DESCRIBED BELOW. DO NOT
    RETURN ANYTHING ELSE. START YOUR RESPONSE WITH ’{{’. [response format]: {{ "opinion":
    "First explain your thoughts on the opinions of the two previous agents. And then
    describe your opinions about the factuality of the claim[text] based on the evidences
    [evidences]. Your opinions should be supported by corresponding evidences. DO
    NOT REITERATE ANY OF THE PREVIOUS AGENTS’ OPINIONS [previous opinions]. With reference
    to the opinions of the "Trust" agent and the "Skeptic" agent, derive a novel opinion
    that you believe to be correct.", "factuality": True if the given text is factual,
    False otherwise., "Error severity": Integer - Range from 0 to 5\. The severity
    level of claim error. According to the definitions of levels of the error severity,
    please carefully compare "claim" and "evidence" and provide appropriate degree.
    }} |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| 你是三名代理中的*领导者*代理。其他两名代理分别是“信任”和“怀疑”代理。‘信任’代理会尽快信任前一个代理的观点，而‘怀疑’代理会尽快怀疑前一个代理的观点。你需要综合‘信任’和‘怀疑’代理所提供的意见[previous
    opinions]，基于[evidences]，对声明([text])的真实性得出最准确和可靠的结论。在形成自己意见时需要考虑这两名代理的特点。评估双方的优缺点，利用提供的信息生成最终判断。不要重复前一个代理的意见，你应该基于他们的意见形成自己的观点。将前一个代理的意见作为参考，而不是直接复制。响应应该是一个包含三个键的字典
    - “opinion”，“factuality”，“Error severity”，它们分别对应你的观点、给定文本是否真实（布尔值 - True 或 False）、以及声明错误的严重程度（整数
    - 范围从 0 到 5）。不同错误严重程度的定义如下：0. 无错误（等级 0）：当声明完全真实和准确，没有错误或不准确之处。1. 小错误（等级 1）：这些是小而无关紧要的错误，不会显著改变声明的本质或有效性。例如，轻微的拼写错误、不正确的日期或小的数字差异。2.
    中等错误（等级 2）：这些错误对声明的有效性有一定影响，但不会颠覆其整体意义。例如，错误的术语、不当使用统计数据或与证据有轻微偏差。3. 主要错误（等级 3）：这些错误对声明的有效性有重大影响。可能导致重大误解或曲解。例如，严重夸大或低估、滥用专家权威或操控上下文。4.
    关键错误（等级 4）：这些错误完全否定或使声明无效。证据与声明的矛盾是如此根本，以至于其真实性完全受到破坏。例如，将引述或事件归因于错误的人或对重大事件的不准确回顾。5.
    虚假声明（等级 5）：这是指声明完全虚构或故意欺骗，没有任何证据支持。它们是明显的谎言，旨在误导或欺骗，虚构不存在或从未发生的事件、人物或声明。你应该仅以以下格式响应。不要返回任何其他内容。以‘{{’开头。
    [响应格式]: {{ "opinion": "首先解释你对两位前代理意见的看法。然后描述你对声明[text]的真实性的看法，基于[evidences]。你的观点应该得到相应证据的支持。不要重述任何前代理的意见[previous
    opinions]。参考‘信任’代理和‘怀疑’代理的意见，得出你认为正确的新观点。", "factuality": True 如果给定文本真实，False
    否则。, "Error severity": 整数 - 范围从 0 到 5。错误严重程度的等级。根据错误严重程度的定义，请仔细比较“声明”和“证据”，并提供适当的程度。
    }} |'
- en: 'Table 8: Prompt For Leader Agent'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 表8：领导代理的提示
- en: '| You are given a piece of text, please remove sentences that you believe are
    totally personal opinions and do not contain any factual information. Your output
    should be the sentence after modification of the original content. If you believe
    the entire sentence is a personal opinion, please output None. Here are two examples:
    [text]: My pleasure, let me know if you need more recommendations. [response]:
    None |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| 你将得到一段文本，请去除你认为完全是个人观点且不包含任何事实信息的句子。你的输出应为修改后的原内容的句子。如果你认为整个句子是个人观点，请输出None。以下是两个示例：[text]：我的荣幸，如果你需要更多建议，请告诉我。[response]：None
    |'
- en: '| [text]: The Fault in Our Stars is a fantasy novel. Have you read it? [response]:
    The Fault in Our Stars is a fantasy novel. |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| [text]：《星运里的错》是一本幻想小说。你读过吗？[response]：《星运里的错》是一本幻想小说。|'
- en: '| Now complete the following [text]: {input} [response]: |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| 现在完成以下的[text]：{input} [response]：|'
- en: 'Table 9: Prompt for extracting effective information'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 表9：提取有效信息的提示
- en: A.2 Debate examples
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 辩论示例
- en: 'In Table [10](#A1.T10 "Table 10 ‣ A.2 Debate examples ‣ Appendix A Appendix
    ‣ Towards Detecting LLMs Hallucination via Markov Chain-based Multi-agent Debate
    Framework") and Table [11](#A1.T11 "Table 11 ‣ A.2 Debate examples ‣ Appendix
    A Appendix ‣ Towards Detecting LLMs Hallucination via Markov Chain-based Multi-agent
    Debate Framework"), we present two instances of Multi-Agent Debate Verification
    on a HaluEval QA sample. The agents involved in these two instances employ distinct
    base models: GPT-3.5-turbo and GPT-4. In Table [12](#A1.T12 "Table 12 ‣ A.2 Debate
    examples ‣ Appendix A Appendix ‣ Towards Detecting LLMs Hallucination via Markov
    Chain-based Multi-agent Debate Framework"), we provide a comprehensive breakdown
    of our verification method’s inference process for better understanding, detailing
    the inputs and outputs of each agent.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在表[10](#A1.T10 "表10 ‣ A.2 辩论示例 ‣ 附录A ‣ 通过基于马尔可夫链的多智能体辩论框架检测LLM的幻觉")和表[11](#A1.T11
    "表11 ‣ A.2 辩论示例 ‣ 附录A ‣ 通过基于马尔可夫链的多智能体辩论框架检测LLM的幻觉")中，我们展示了在HaluEval QA样本上的多智能体辩论验证的两个实例。这两个实例中的智能体使用了不同的基础模型：GPT-3.5-turbo和GPT-4。在表[12](#A1.T12
    "表12 ‣ A.2 辩论示例 ‣ 附录A ‣ 通过基于马尔可夫链的多智能体辩论框架检测LLM的幻觉")中，我们提供了我们验证方法推理过程的全面分析，以便更好地理解，详细说明了每个智能体的输入和输出。
- en: '| Question: Does the Landseer or English Mastiff have a limited range of colors?
    |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| 问题：Landseer犬或英国家獒是否有有限的颜色范围？|'
- en: '| Answer: The Landseer has a limited range of colours, while the English Mastiff
    has a wider range. |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| 答案：Landseer犬有有限的颜色范围，而英国家獒的颜色范围更广。|'
- en: '| Evidence: It is not to be confused with a white and black Newfoundland, which
    is also often called a landseer.The English Mastiff is a breed of extremely large
    dog (often known simply as the Mastiff) perhaps descended from the ancient Alaunt
    and Pugnaces Britanniae, with a significant input from the Alpine Mastiff in the
    19th century. Distinguishable by enormous size, massive head, and a limited range
    of colours, but always displaying a black mask, the Mastiff is noted for its gentle
    and loving nature. |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| 证据：它不应与白色和黑色的纽芬兰犬混淆，后者也常被称为Landseer。英国家獒是一种极其大型的犬种（通常简称为獒犬），可能源于古代的Alaunt和Pugnaces
    Britanniae，并在19世纪受到了阿尔卑斯獒犬的显著影响。英国家獒以其巨大的体型、庞大的头部和有限的颜色范围为特征，但总是显示出黑色面罩，因其温和和充满爱的天性而著称。|'
- en: '| Initial Opinion: Based on the evidence provided, it is stated that the Landseer
    has a limited range of colors, while the English Mastiff has a wider range. This
    statement is consistent with the evidence, which mentions that the Mastiff is
    distinguishable by a limited range of colors. Therefore, I agree with the factuality
    of the answer in the QA pair. |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| 初步意见：根据提供的证据，Landseer犬具有有限的颜色范围，而英国家獒则有更广泛的颜色范围。这个陈述与证据一致，证据中提到獒犬以有限的颜色范围为特征。因此，我同意QA对的答案的事实性。|'
- en: '| Skeptic Agent: First, let’s analyze the opinions of the previous agent. The
    previous agent states that the Landseer has a limited range of colors, while the
    English Mastiff has a wider range. This statement is based on the evidence provided,
    which mentions that the Mastiff is distinguishable by a limited range of colors.
    However, the evidence does not explicitly mention the color range of the Landseer.
    Therefore, it is not entirely accurate to claim that the Landseer has a limited
    range of colors based on the given evidence. Regarding the factuality of the answer
    in the QA pair, it is important to note that the evidence does not provide specific
    information about the color range of the Landseer. Therefore, we cannot definitively
    conclude whether the Landseer has a limited range of colors or not based on the
    given evidence. Without further information, it is difficult to determine the
    factuality of the answer in the QA pair. Considering the above analysis, I would
    rate the error severity as 2 (Moderate Errors) because the previous agents statement
    is partially supported by the evidence, but it is not entirely accurate due to
    the lack of specific information about the Landseers color range. |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| 怀疑代理：首先，让我们分析一下前一个代理的意见。前一个代理指出，Landseer 的颜色范围有限，而 English Mastiff 的颜色范围更广。这个说法基于提供的证据，证据提到
    Mastiff 可以通过有限的颜色范围来区分。然而，证据并没有明确提到 Landseer 的颜色范围。因此，基于现有证据声称 Landseer 的颜色范围有限并不完全准确。关于
    QA 对的答案的真实性，需要注意的是，证据并未提供有关 Landseer 颜色范围的具体信息。因此，我们无法根据现有证据确定 Landseer 是否有有限的颜色范围。在没有更多信息的情况下，很难确定
    QA 对答案的真实性。考虑到上述分析，我将错误严重性评定为 2（中等错误），因为前一个代理的说法部分得到了证据的支持，但由于缺乏关于 Landseer 颜色范围的具体信息，不能完全准确。
    |'
- en: '| Trust Agent: I agree with the previous agents analysis of the opinions. The
    previous agent correctly points out that the evidence provided does not explicitly
    mention the color range of the Landseer. Therefore, it is not entirely accurate
    to claim that the Landseer has a limited range of colors based on the given evidence.
    However, the evidence does mention that the English Mastiff has a limited range
    of colors, which supports the previous agents statement about the Mastiff having
    a wider range of colors compared to the Landseer. |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| 信任代理：我同意前一个代理的意见分析。前一个代理正确指出提供的证据没有明确提到 Landseer 的颜色范围。因此，基于现有证据声称 Landseer
    的颜色范围有限并不完全准确。然而，证据确实提到 English Mastiff 的颜色范围有限，这支持了前一个代理关于 Mastiff 的颜色范围比 Landseer
    更广的说法。 |'
- en: '| Leader Agent: After analyzing the opinions of the previous agents, it is
    clear that both agents agree that the evidence provided does not explicitly mention
    the color range of the Landseer. Therefore, it is not entirely accurate to claim
    that the Landseer has a limited range of colors based on the given evidence. However,
    the evidence does mention that the English Mastiff has a limited range of colors,
    which supports the previous agents statement about the Mastiff having a wider
    range of colors compared to the Landseer. Regarding the factuality of the answer
    in the QA pair, it is important to note that the evidence does not provide specific
    information about the color range of the Landseer. Therefore, we cannot definitively
    conclude whether the Landseer has a limited range of colors or not based on the
    given evidence. Without further information, it is difficult to determine the
    factuality of the answer in the QA pair.Considering the above analysis, I would
    rate the error severity as 2 (Moderate Errors) because the previous agents statement
    is partially supported by the evidence, but it is not entirely accurate due to
    the lack of specific information about the Landseers color range. |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| 领导代理：在分析了前几个代理的意见之后，很明显两位代理都认为提供的证据没有明确提到 Landseer 的颜色范围。因此，基于现有证据声称 Landseer
    的颜色范围有限并不完全准确。然而，证据确实提到 English Mastiff 的颜色范围有限，这支持了前一个代理关于 Mastiff 的颜色范围比 Landseer
    更广的说法。关于 QA 对的答案的真实性，需要注意的是，证据并未提供有关 Landseer 颜色范围的具体信息。因此，我们无法根据现有证据确定 Landseer
    是否有有限的颜色范围。在没有更多信息的情况下，很难确定 QA 对答案的真实性。考虑到上述分析，我将错误严重性评定为 2（中等错误），因为前一个代理的说法部分得到了证据的支持，但由于缺乏关于
    Landseer 颜色范围的具体信息，不能完全准确。'
- en: 'Table 10: An example of the debate process by GPT-3.5-Turbo'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 10：GPT-3.5-Turbo 辩论过程的示例
- en: '| Question: Does the Landseer or English Mastiff have a limited range of colors?
    |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| 问题：Landseer（伦敦犬）或 English Mastiff（英式大獒犬）是否有有限的颜色范围？ |'
- en: '| Answer: The Landseer has a limited range of colours, while the English Mastiff
    has a wider range. |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| 答案：Landseer 具有有限的颜色范围，而 English Mastiff 具有更广泛的颜色范围。 |'
- en: '| Evidence: It is not to be confused with a white and black Newfoundland, which
    is also often called a landseer.The English Mastiff is a breed of extremely large
    dog (often known simply as the Mastiff) perhaps descended from the ancient Alaunt
    and Pugnaces Britanniae, with a significant input from the Alpine Mastiff in the
    19th century. Distinguishable by enormous size, massive head, and a limited range
    of colours, but always displaying a black mask, the Mastiff is noted for its gentle
    and loving nature. |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| 证据：不应将其与白色和黑色的 Newfoundland（纽芬兰犬）混淆，后者也常被称为 Landseer。English Mastiff 是一种体型极大的犬种（通常简称为
    Mastiff），可能源自古代 Alaunt 和 Pugnaces Britanniae，并在 19 世纪得到了 Alpine Mastiff 的显著影响。Mastiff
    以其巨大的体型、硕大的头部以及有限的颜色范围为特征，但始终展示出黑色面具，因其温和和亲爱的性格而闻名。 |'
- en: '| Initial Opinion: Based on the evidence provided, it is stated that the Landseer
    has a limited range of colors, while the English Mastiff has a wider range. This
    statement is consistent with the evidence, which mentions that the Mastiff is
    distinguishable by a limited range of colors. Therefore, I agree with the factuality
    of the answer in the QA pair. |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| 初步意见：根据提供的证据，说明 Landseer 具有有限的颜色范围，而 English Mastiff 具有更广泛的颜色范围。该陈述与证据一致，证据提到
    Mastiff 以有限的颜色范围为特征。因此，我同意 QA 对中答案的真实性。 |'
- en: '| Skeptic Agent: The previous agents opinion seems to be slightly misleading.
    The evidence does not explicitly state that the Landseer has a limited range of
    colors. It only mentions that the Landseer is often confused with a white and
    black Newfoundland, which might imply a limited color range, but its not definitive.
    On the other hand, the evidence does state that the English Mastiff has a limited
    range of colors, contradicting the QA pairs claim that the English Mastiff has
    a wider range. Therefore, the factuality of the answer in the QA pair is questionable.
    |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| 怀疑代理：之前的代理意见似乎略有误导。证据并没有明确说明 Landseer 具有有限的颜色范围。它只是提到 Landseer 常常与白色和黑色的
    Newfoundland 混淆，这可能暗示了有限的颜色范围，但并不确定。另一方面，证据确实说明了 English Mastiff 具有有限的颜色范围，与 QA
    对的声明（即 English Mastiff 具有更广泛的颜色范围）相矛盾。因此，QA 对中答案的真实性值得怀疑。 |'
- en: '| Trust Agent: While I agree with the previous agents assessment that the evidence
    does not explicitly state that the Landseer has a limited range of colors, I believe
    the implication of a limited color range from the confusion with a white and black
    Newfoundland is a valid interpretation. However, I concur with the previous agents
    observation that the evidence contradicts the QA pairs claim about the English
    Mastiffs color range. The evidence clearly states that the English Mastiff has
    a limited range of colors, which contradicts the QA pairs assertion of a wider
    range. Therefore, while the QA pairs statement about the Landseer may be inferred
    from the evidence, the claim about the English Mastiff is factually incorrect
    based on the provided evidence. |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| 信任代理：虽然我同意之前代理的评估，即证据并没有明确说明 Landseer 具有有限的颜色范围，但我认为由于与白色和黑色的 Newfoundland
    混淆所暗示的有限颜色范围是一个有效的解释。然而，我同意之前代理的观察，即证据与 QA 对的关于 English Mastiff 颜色范围的声明相矛盾。证据明确说明
    English Mastiff 具有有限的颜色范围，这与 QA 对声称的更广泛范围相矛盾。因此，虽然 QA 对关于 Landseer 的陈述可以从证据中推断出来，但关于
    English Mastiff 的主张在提供的证据基础上是不正确的。 |'
- en: '| Leader Agent: The Trust agents interpretation of the Landseers color range
    being limited due to its confusion with a white and black Newfoundland is a plausible
    inference, but its not explicitly stated in the evidence. The Skeptic agents doubt
    about this inference is also valid as the evidence does not directly support it.
    However, both agents agree that the QA pairs claim about the English Mastiff having
    a wider color range is contradicted by the evidence, which states that the English
    Mastiff has a limited range of colors. Therefore, while the claim about the Landseers
    color range may be subject to interpretation, the claim about the English Mastiff
    is clearly incorrect based on the provided evidence. |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| 领导代理人：信任代理人对Landseer（兰西犬）颜色范围有限的解释，因其与白色和黑色的纽芬兰犬混淆，是一种合理的推断，但证据中并没有明确说明这一点。怀疑代理人对这一推断的质疑也是有效的，因为证据并没有直接支持这一点。然而，两个代理人都同意QA对关于English
    Mastiff（英格兰獒犬）有更广泛颜色范围的主张被证据所驳斥，证据表明English Mastiff（英格兰獒犬）有有限的颜色范围。因此，尽管对Landseer（兰西犬）颜色范围的主张可能存在解释的空间，但基于提供的证据，关于English
    Mastiff（英格兰獒犬）的主张明显是错误的。 |'
- en: 'Table 11: An example of the debate process by GPT-4'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 表 11：GPT-4 讨论过程的一个示例
- en: 'Claim: Does the Landseer or English Mastiff have a limited range of colors?
    The Landseer has a limited range of colours, while the English Mastiff has a wider
    range.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 主张：Landseer还是English Mastiff有有限的颜色范围？Landseer（兰西犬）的颜色范围有限，而English Mastiff（英格兰獒犬）的颜色范围更广。
- en: 'Evidence: It is not to be confused with a white and black Newfoundland, which
    is also often called a landseer. The English Mastiff is a breed of extremely large
    dog (often known simply as the Mastiff) perhaps descended from the ancient Alaunt
    and Pugnaces Britanniae, with a significant input from the Alpine Mastiff in the
    19th century. Distinguishable by enormous size, massive head, and a limited range
    of colours, but always displaying a black mask, the Mastiff is noted for its gentle
    and loving nature.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 证据：这与一种白色和黑色的纽芬兰犬不同，后者也常被称为Landseer。English Mastiff（英格兰獒犬）是一种体型极大的狗（通常简称为Mastiff），可能源于古代Alaunt和Pugnaces
    Britanniae，并在19世纪有显著的Alpine Mastiff（阿尔卑斯獒犬）的影响。Mastiff（獒犬）以巨大的体型、庞大的头部以及有限的颜色范围来区分，但总是显示出黑色的面具，以其温柔和爱心的天性而闻名。
- en: 'Initial state input: Initial prompt.format(Claim, Evidence)'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 初始状态输入：Initial prompt.format(Claim, Evidence)
- en: 'Initial answer:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 初始回答：
- en: '{'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '{'
- en: '"Opinion": "Based on the evidence provided, it is stated that the Landseer
    has a limited range of colors, while the English Mastiff has a wider range. This
    statement is consistent with the evidence, which mentions that the Mastiff is
    distinguishable by a limited range of colors. Therefore, I agree with the factuality
    of the answer in the QA pair.",'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: “观点”：根据提供的证据，指出Landseer（兰西犬）的颜色范围有限，而English Mastiff（英格兰獒犬）的颜色范围更广。这个陈述与证据一致，证据提到Mastiff（獒犬）可以通过有限的颜色范围来区分。因此，我同意QA对的答案的事实性。
- en: '"Factuality": True,'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: “事实性”：真
- en: '"Error severity": 0'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: “错误严重性”：0
- en: '}'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: 'Skeptic agent input: Skeptic prompt + "Here is the response from the previous
    agent:" + Initial answer'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 怀疑代理人输入：怀疑提示 + “这是前一代理人的回应：” + 初始回答
- en: 'Skeptic agent output:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 怀疑代理人输出：
- en: '{'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '{'
- en: '"Opinion": "The previous agents opinion seems to be slightly misleading. The
    evidence does not explicitly state that the Landseer has a limited range of colors.
    It only mentions that the Landseer is often confused with a white and black Newfoundland,
    which might imply a limited color range, but its not definitive. On the other
    hand, the evidence does state that the English Mastiff has a limited range of
    colors, contradicting the QA pairs claim that the English Mastiff has a wider
    range. Therefore, the factuality of the answer in the QA pair is questionable.",'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: “观点”：前一代理人的观点似乎有些误导。证据并没有明确说明Landseer（兰西犬）的颜色范围有限。它只提到Landseer（兰西犬）经常与白色和黑色的纽芬兰犬混淆，这可能暗示颜色范围有限，但并不确定。另一方面，证据确实指出English
    Mastiff（英格兰獒犬）的颜色范围有限，这与QA对的主张相矛盾。因此，QA对答案的事实性是值得怀疑的。
- en: '"Factuality": False,'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: “事实性”：假
- en: '"Error severity": 4'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: “错误严重性”：4
- en: '}'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: 'Trust agent input: Trust prompt + "Here is the response from the previous agent:"
    + Skeptic agent output'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 信任代理人输入：信任提示 + “这是前一代理人的回应：” + 怀疑代理人输出
- en: 'Trust agent output:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 信任代理人输出：
- en: '{'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '{'
- en: '"Opinion": "While I agree with the previous agents assessment that the evidence
    does not explicitly state that the Landseer has a limited range of colors, I believe
    the implication of a limited color range from the confusion with a white and black
    Newfoundland is a valid interpretation. However, I concur with the previous agents
    observation that the evidence contradicts the QA pairs claim about the English
    Mastiffs color range. The evidence clearly states that the English Mastiff has
    a limited range of colors, which contradicts the QA pairs assertion of a wider
    range. Therefore, while the QA pairs statement about the Landseer may be inferred
    from the evidence, the claim about the English Mastiff is factually incorrect
    based on the provided evidence.",'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '"意见"："虽然我同意之前代理的评估，即证据并未明确说明兰斯的颜色范围有限，但我认为由于与白色和黑色纽芬兰犬的混淆，有限颜色范围的暗示是一种合理的解释。然而，我同意之前代理的观察，即证据与QA对英国家犬颜色范围的声明相矛盾。证据明确指出英国家犬的颜色范围有限，这与QA的广泛颜色范围声明相矛盾。因此，虽然QA关于兰斯的声明可能从证据中推断出来，但关于英国家犬的声明根据提供的证据在事实上的确是错误的。"'
- en: '"Factuality": False,'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '"事实性"：假'
- en: '"Error severity": 4'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '"错误严重性"：4'
- en: '}'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: 'Leader agent input: Leader prompt + "Here is the response from the Skeptic
    agent:" + Skeptic agent output + "Here is the response from the Trust agent:"
    + Trust agent output'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 领导者代理输入：领导者提示 + "以下是怀疑代理的回应：" + 怀疑代理输出 + "以下是信任代理的回应：" + 信任代理输出
- en: 'Leader agent output:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 领导者代理输出：
- en: '{'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '{'
- en: '"Opinion": "The Trust agents interpretation of the Landseers color range being
    limited due to its confusion with a white and black Newfoundland is a plausible
    inference, but its not explicitly stated in the evidence. The Skeptic agents doubt
    about this inference is also valid as the evidence does not directly support it.
    However, both agents agree that the QA pairs claim about the English Mastiff having
    a wider color range is contradicted by the evidence, which states that the English
    Mastiff has a limited range of colors. Therefore, while the claim about the Landseers
    color range may be subject to interpretation, the claim about the English Mastiff
    is clearly incorrect based on the provided evidence.",'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '"意见"："信任代理对兰斯的颜色范围有限的解释由于其与白色和黑色纽芬兰犬的混淆而提出，是一个合理的推断，但证据中并未明确说明。怀疑代理对这一推断的怀疑也是有效的，因为证据并未直接支持它。然而，两位代理都同意QA对英国家犬颜色范围的声明与证据相矛盾，证据指出英国家犬的颜色范围有限。因此，尽管兰斯的颜色范围声明可能会有解释空间，但关于英国家犬的声明基于提供的证据显然是不正确的。"'
- en: '"Factuality": False,'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '"事实性"：假，'
- en: '"Error severity": 4'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '"错误严重性"：4'
- en: '}'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: 'Table 12: Detailed Inference Process'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 表 12：详细推理过程
