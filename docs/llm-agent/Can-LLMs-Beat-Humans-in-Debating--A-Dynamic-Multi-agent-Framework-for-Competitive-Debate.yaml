- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:39:10'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:39:10
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive
    Debate
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLMs能否超越人类进行辩论？一个动态多代理框架用于竞技辩论
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2408.04472](https://ar5iv.labs.arxiv.org/html/2408.04472)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2408.04472](https://ar5iv.labs.arxiv.org/html/2408.04472)
- en: Yiqun Zhang¹, Xiaocui Yang¹, Shi Feng¹, Daling Wang¹, Yifei Zhang¹, Kaisong Song²
    Corresponding author.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 张一群¹、杨晓翠¹、石峰¹、王达林¹、张逸飞¹、宋凯松² 通讯作者。
- en: Abstract
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Competitive debate is a complex task of computational argumentation. Large Language
    Models (LLMs) suffer from hallucinations and lack competitiveness in this field.
    To address these challenges, we introduce Agent for Debate (Agent4Debate), a dynamic
    multi-agent framework based on LLMs designed to enhance their capabilities in
    competitive debate. Drawing inspiration from human behavior in debate preparation
    and execution, Agent4Debate employs a collaborative architecture where four specialized
    agents, involving Searcher, Analyzer, Writer, and Reviewer, dynamically interact
    and cooperate. These agents work throughout the debate process, covering multiple
    stages from initial research and argument formulation to rebuttal and summary.
    To comprehensively evaluate framework performance, we construct the Competitive
    Debate Arena, comprising 66 carefully selected Chinese debate motions. We recruit
    ten experienced human debaters and collect records of 200 debates involving Agent4Debate,
    baseline models, and humans. The evaluation employs the Debatrix automatic scoring
    system and professional human reviewers based on the established Debatrix-Elo
    and Human-Elo ranking. Experimental results indicate that the state-of-the-art
    Agent4Debate exhibits capabilities comparable to those of humans. Furthermore,
    ablation studies demonstrate the effectiveness of each component in the agent
    structure.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 竞技辩论是一个复杂的计算论证任务。大型语言模型（LLMs）在这个领域中容易出现幻觉，并且竞争力不足。为了应对这些挑战，我们引入了辩论代理（Agent4Debate），这是一个基于LLMs的动态多代理框架，旨在增强其在竞技辩论中的能力。受人类在辩论准备和执行中的行为启发，Agent4Debate采用了一个协作架构，其中包括四个专业代理：搜索者、分析者、写作员和评审员，这些代理动态互动与合作。这些代理贯穿整个辩论过程，涵盖了从初步研究和论点形成到反驳和总结的多个阶段。为了全面评估框架的性能，我们构建了竞技辩论竞技场，包含66个精心挑选的中文辩论主题。我们招募了十位经验丰富的辩手，收集了200场涉及Agent4Debate、基线模型和人类的辩论记录。评估采用Debatrix自动评分系统和基于已建立的Debatrix-Elo及Human-Elo排名的专业人类评审。实验结果表明，最先进的Agent4Debate展示了与人类相当的能力。此外，消融研究证明了代理结构中每个组件的有效性。
- en: Code — https://github.com/ZhangYiqun018/agent-for-debate
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 代码 — https://github.com/ZhangYiqun018/agent-for-debate
- en: Introduction
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: Competitive debate, as a structured and competitive form of communication (Nichols
    [1936](#bib.bib21); Thueblood [1926](#bib.bib30)), plays a crucial role in fields
    such as education, law, and politics. It challenges the comprehensive ability
    of participants, including logical thinking, expression skills, rapid analysis,
    argument construction, and rebuttal techniques, ultimately aiming to persuade
    a third party. With the advancement of artificial intelligence technologies, computational
    argumentation has emerged, and it is dedicated to simulating and understanding
    human argumentation processes through computational methods (Atkinson et al. [2017](#bib.bib3);
    Eger, Daxenberger, and Gurevych [2017](#bib.bib10)). However, existing research
    is largely confined to specific tasks on particular datasets, such as argument
    mining (Lawrence and Reed [2019](#bib.bib16)), argument quality assessment (Wachsmuth
    et al. [2017a](#bib.bib35)), and argument generation (Li, Ji, and Han [2021](#bib.bib18)).
    While these methods excel at specific tasks, they struggle to handle the complexity
    of competitive debate characterized by its openness, intense competition, and
    the need for decision-making and comprehensive skills.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 竞争性辩论作为一种结构化和竞争性的沟通形式（Nichols [1936](#bib.bib21); Thueblood [1926](#bib.bib30)），在教育、法律和政治等领域中扮演着重要角色。它挑战参与者的综合能力，包括逻辑思维、表达技巧、快速分析、论证构建和反驳技巧，最终目的是说服第三方。随着人工智能技术的进步，计算论证应运而生，致力于通过计算方法模拟和理解人类论证过程（Atkinson
    et al. [2017](#bib.bib3); Eger, Daxenberger, and Gurevych [2017](#bib.bib10)）。然而，现有研究大多局限于特定数据集上的具体任务，例如论证挖掘（Lawrence
    and Reed [2019](#bib.bib16)）、论证质量评估（Wachsmuth et al. [2017a](#bib.bib35)）和论证生成（Li,
    Ji, and Han [2021](#bib.bib18)）。虽然这些方法在特定任务中表现出色，但它们在处理竞争性辩论的复杂性时仍然存在困难，尤其是在其开放性、激烈的竞争以及决策和综合技能需求方面。
- en: In recent years, Large Language Models (LLMs) (OpenAI [2023](#bib.bib22); Touvron
    et al. [2023b](#bib.bib32)) have demonstrated remarkable capabilities in various
    natural language processing tasks, offering new possibilities for constructing
    high-performance debate systems. Competitive debate, characterized by multi-turn
    document-level text generation with inter-turn logical dependencies, presents
    a unique challenge for LLMs, particularly in two significant areas. First, LLMs
    often face hallucination problems (Ji et al. [2023](#bib.bib14)), where models
    may generate plausible information that is inaccurate or fabricated. Second, due
    to limitations in safety alignment during training (Ouyang et al. [2022](#bib.bib23))
    and constraints in handling long contexts (Liu et al. [2024](#bib.bib20)), models
    often need to improve in adversarial and sustained debate scenarios (shown in
    Figure [1](#Sx1.F1 "Figure 1 ‣ Introduction ‣ Can LLMs Beat Humans in Debating?
    A Dynamic Multi-agent Framework for Competitive Debate")), struggling to maintain
    competitiveness and argumentative consistency.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，大型语言模型（LLMs）（OpenAI [2023](#bib.bib22); Touvron et al. [2023b](#bib.bib32)）在各种自然语言处理任务中展现了卓越的能力，为构建高性能辩论系统提供了新的可能性。竞争性辩论以多轮文档级文本生成和轮间逻辑依赖为特点，对LLMs提出了独特的挑战，特别是在两个重要领域。首先，LLMs经常面临幻觉问题（Ji
    et al. [2023](#bib.bib14)），即模型可能生成看似准确但实际上不正确或虚假的信息。其次，由于训练过程中安全对齐的局限性（Ouyang
    et al. [2022](#bib.bib23)）和处理长上下文的限制（Liu et al. [2024](#bib.bib20)），模型在对抗性和持续性辩论场景中常常需要改进（如图
    [1](#Sx1.F1 "图1 ‣ 引言 ‣ LLMs能否战胜人类？一种动态多代理框架用于竞争性辩论") 所示），难以保持竞争力和论证的一致性。
- en: '![Refer to caption](img/c32326df1fa54e3a2dda4cbfc142e67f.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c32326df1fa54e3a2dda4cbfc142e67f.png)'
- en: 'Figure 1: Before and After: Agent4Debate’s impact on LLMs competitive debating
    skills.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：前后对比：Agent4Debate对LLMs竞争性辩论技能的影响。
- en: To address these challenges, we propose a multi-agent framework based on LLMs,
    Agent for Debate (Agent4Debate). Agent4Debate features a dynamic, multi-agent
    collaborative architecture, leveraging the cooperation of multiple specialized
    LLMs to enable the framework to participate in multi-stage competitive debates.
    Inspired by human debate preparation processes, our framework incorporates four
    key agents, including Searcher, Analyzer, Writer, and Reviewer. To comprehensively
    evaluate the competitive debate capabilities of Agent4Debate, we establish the
    Competitive Debate Arena, employing an Elo ranking system widely used in competitive
    sports, ensuring fairness and scalability. This arena comprises 66 carefully selected
    Chinese debate motions, covering three categories (Abell [2018](#bib.bib1)), such
    as Policy, Value, and Fact, thoroughly testing the performance of participants
    across different types of debates. Participants include Agent4Debate with different
    foundation models, two baselines, and ten experienced human debaters. All participants
    engage in pairwise matches, with each debate assessed through two independent
    evaluation methods, including an automatic debate judging system based on the
    Debatrix (Liang et al. [2024](#bib.bib19)) metrics, and an expert judging system
    consisting of three professional human reviewers. Based on these two sets of independent
    evaluation results, we construct two separate Elo (Elo [1967](#bib.bib11); Zheng
    et al. [2023](#bib.bib44)) ranking lists, providing a multi-faceted quantitative
    assessment of participants’ performance across various debate motions. The experimental
    results from the arena demonstrate that Agent4Debate can achieve human-level performance
    in various types of competitive debates.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些挑战，我们提出了一种基于LLMs的多智能体框架——Agent for Debate（Agent4Debate）。Agent4Debate具有动态的多智能体协作架构，利用多个专业化LLMs的合作，使框架能够参与多阶段的竞争性辩论。受到人类辩论准备过程的启发，我们的框架包含四个关键智能体，包括Searcher、Analyzer、Writer和Reviewer。为了全面评估Agent4Debate的竞争性辩论能力，我们建立了竞争性辩论竞技场，采用广泛用于竞技体育的Elo排名系统，确保公平性和可扩展性。这个竞技场包含66个精心挑选的中文辩论议题，涵盖三类（Abell
    [2018](#bib.bib1)），例如政策、价值和事实，全面测试参与者在不同类型辩论中的表现。参与者包括使用不同基础模型的Agent4Debate、两个基线模型以及十名经验丰富的人类辩手。所有参与者进行配对比赛，每场辩论通过两种独立的评估方法进行评估，包括基于Debatrix（Liang
    et al. [2024](#bib.bib19)）指标的自动辩论判断系统，以及由三名专业人类评审组成的专家评审系统。根据这两组独立的评估结果，我们构建了两个独立的Elo（Elo
    [1967](#bib.bib11); Zheng et al. [2023](#bib.bib44)）排名列表，从多个角度定量评估参与者在各种辩论议题中的表现。竞技场的实验结果表明，Agent4Debate能够在各种类型的竞争性辩论中达到人类水平的表现。
- en: 'In conclusion, the main contributions of this work are as follows:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，这项工作的主要贡献如下：
- en: •
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We propose the Agent4Debate, which enhances the performance of LLMs in competitive
    debates through dynamic multi-agent collaboration. This framework mimics human
    debate team interactions, with agents adapting roles and strategies. Specifically,
    it employs the Searcher for information gathering, the Analyzer for strategic
    assessment, the Writer for argument formulation, and the Reviewer for critical
    evaluation.
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了Agent4Debate，它通过动态的多智能体协作提升了大语言模型（LLMs）在竞争性辩论中的表现。该框架模拟了人类辩论团队的互动，智能体在其中适应角色和策略。具体来说，它利用Searcher进行信息收集，Analyzer进行战略评估，Writer进行论点制定，以及Reviewer进行批判性评价。
- en: •
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We construct the Competitive Debate Arena, a public resource comprising 66 Chinese
    debate motions and 200 debate matches across Policy, Value, and Fact categories.
    Human debaters are incorporated, and we establish Debatrix-Elo and Human-Elo rankings
    using Debatrix metrics and professional human judges, respectively.
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们构建了竞争性辩论竞技场，这是一个公共资源，包含66个中文辩论议题和200场辩论比赛，涵盖政策、价值和事实三类。包含了人类辩手，并利用Debatrix指标和专业人类评审分别建立了Debatrix-Elo和Human-Elo排名。
- en: •
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Our experimental results indicate that Agent4Debate’s performance in competitive
    debates is comparable to that of humans. Ablation studies validate the effectiveness
    of each component.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们的实验结果表明，Agent4Debate在竞争性辩论中的表现与人类相当。消融研究验证了每个组件的有效性。
- en: Related Work
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关工作
- en: Computational Argumentation
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算性辩论
- en: Argumentation research has deep historical roots (Walton, Reed, and Macagno
    [2008](#bib.bib37)), with its core objective being to achieve persuasion through
    logical reasoning and promote consensus among parties. In recent years, computational
    argumentation has emerged as an increasingly important field in natural language
    processing, with its main research directions encompassing argument mining (Lawrence
    and Reed [2019](#bib.bib16); Chen et al. [2024](#bib.bib8)), argument generation
    (Hua, Hu, and Wang [2019](#bib.bib12)), argument persuasiveness (Carlile et al.
    [2018](#bib.bib6)), and argument quality assessment (Wachsmuth et al. [2017b](#bib.bib36);
    Liang et al. [2024](#bib.bib19); Wachsmuth et al. [2024](#bib.bib34)). Project
    Debater (Slonim et al. [2021](#bib.bib29)), a debate system that integrates multiple
    modules, relies on retrieval-based methods rather than generative approaches for
    its argumentation. With the rise of Large Language Models research utilizing adversarial
    methods such as debate to enhance model capabilities (Du et al. [2023](#bib.bib9);
    Chang [2024](#bib.bib7)) has gradually attracted academic attention. Against this
    backdrop, our study focuses on competitive debate, a complex computational argumentation
    task that integrates multiple sub-tasks.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 争论研究具有深厚的历史根基（Walton, Reed, 和 Macagno [2008](#bib.bib37)），其核心目标是通过逻辑推理实现说服，并促进各方达成共识。近年来，计算争论作为自然语言处理中的一个重要领域逐渐兴起，其主要研究方向包括争论挖掘（Lawrence
    和 Reed [2019](#bib.bib16)；Chen 等 [2024](#bib.bib8)），争论生成（Hua, Hu, 和 Wang [2019](#bib.bib12)），争论说服力（Carlile
    等 [2018](#bib.bib6)），以及争论质量评估（Wachsmuth 等 [2017b](#bib.bib36)；Liang 等 [2024](#bib.bib19)；Wachsmuth
    等 [2024](#bib.bib34)）。Project Debater（Slonim 等 [2021](#bib.bib29)），一个集成了多个模块的辩论系统，依赖于基于检索的方法，而非生成方法进行争论。随着利用对抗性方法（如辩论）来增强模型能力的大语言模型研究的兴起（Du
    等 [2023](#bib.bib9)；Chang [2024](#bib.bib7)）逐渐引起了学术界的关注。在这一背景下，我们的研究集中于竞争辩论，这是一项复杂的计算争论任务，涉及多个子任务。
- en: LLM-based Agents
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于大语言模型的智能体
- en: LLMs, such as ChatGPT (OpenAI [2023](#bib.bib22)), LLaMA (Touvron et al. [2023b](#bib.bib32),
    [a](#bib.bib31)), demonstrate powerful capabilities in instruction following and
    reasoning tasks. Harnessing these advanced capabilities, researchers have developed
    LLM-based agents, which mark a significant step forward in the field. These agents
    leverage the language understanding and generation abilities of models for more
    sophisticated tasks like multi-step reasoning and interactive problem-solving,
    as shown in recent studies (Wang et al. [2023b](#bib.bib39); Li et al. [2023](#bib.bib17)).
    They have various uses across different domains, such as software engineering
    (Qian et al. [2023](#bib.bib25)) and scientific inquiry (Boiko, MacKnight, and
    Gomes [2023](#bib.bib5)), highlighting their versatility. These agents can imitate
    complex human actions, partake in social interactions (Park et al. [2023](#bib.bib24);
    Tu et al. [2023](#bib.bib33)), and replicate intricate scenarios like elections
    (Argyle et al. [2022](#bib.bib2)), debates (Wang et al. [2023a](#bib.bib38); Du
    et al. [2023](#bib.bib9)), and consumer patterns (Wang et al. [2023c](#bib.bib40)),
    illustrating their capacity to emulate human social dynamics. While these agents
    demonstrate impressive capabilities in emulating human social dynamics, current
    research predominantly explores collaborative scenarios. However, competitive
    settings, though equally crucial in human interactions, remain comparatively underexplored.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 诸如 ChatGPT（OpenAI [2023](#bib.bib22)）和 LLaMA（Touvron 等 [2023b](#bib.bib32),
    [a](#bib.bib31)）等大语言模型展现了在指令跟随和推理任务中的强大能力。利用这些先进的能力，研究人员开发了基于大语言模型的智能体，这标志着该领域的重要进步。这些智能体利用模型的语言理解和生成能力，执行更复杂的任务，如多步骤推理和互动问题解决，正如近期研究所示（Wang
    等 [2023b](#bib.bib39)；Li 等 [2023](#bib.bib17)）。它们在软件工程（Qian 等 [2023](#bib.bib25)）和科学探究（Boiko,
    MacKnight, 和 Gomes [2023](#bib.bib5)）等不同领域具有广泛的应用，突显了它们的多样性。这些智能体能够模仿复杂的人类行为，参与社会互动（Park
    等 [2023](#bib.bib24)；Tu 等 [2023](#bib.bib33)），并重现复杂场景如选举（Argyle 等 [2022](#bib.bib2)），辩论（Wang
    等 [2023a](#bib.bib38)；Du 等 [2023](#bib.bib9)），和消费模式（Wang 等 [2023c](#bib.bib40)），展现了它们模拟人类社会动态的能力。虽然这些智能体在模拟人类社会动态方面表现出色，但目前的研究主要探索了合作场景。然而，竞争环境虽然在人际互动中同样重要，却仍然相对未被充分探索。
- en: Task Definition
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 任务定义
- en: 'Competitive debate is a structured multi-turn interactive task. Each turn of
    statement can be regarded as a document-level text generation task, with a temporal
    and logical progression relationship between multiple turns. A typical debate
    has two opposing sides: the Pro side and the Con side. We represent the competitive
    debate as a sequence:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 竞争性辩论是一个结构化的多回合互动任务。每一回合的陈述可以看作是一个文档级文本生成任务，多个回合之间具有时间和逻辑的进展关系。典型的辩论有两个对立的方面：正方和反方。我们将竞争性辩论表示为一个序列：
- en: '|  | $D=\{(s_{1},r_{1}),(s_{2},r_{2}),\cdots,(s_{n},r_{n})\}$ |  | (1) |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '|  | $D=\{(s_{1},r_{1}),(s_{2},r_{2}),\cdots,(s_{n},r_{n})\}$ |  | (1) |'
- en: 'where $(s_{i},r_{i})$ represents the role of speaker. Each statement can be
    defined as:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $(s_{i},r_{i})$ 代表发言者的角色。每个陈述可以定义为：
- en: '|  | $s_{i}=\mathcal{G}(m,r_{i},D_{i-1})$ |  | (2) |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '|  | $s_{i}=\mathcal{G}(m,r_{i},D_{i-1})$ |  | (2) |'
- en: where $m$ is the generation function that produces each statement.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $m$ 是生成每个陈述的生成函数。
- en: 'Typical competitive debate structure usually comprises three distinct stages,
    namely constructive arguments, rebuttals, and summary statements. To ensure fairness
    and simulate actual competitive debate conditions (Whitman [2005](#bib.bib41)),
    we establish specific rules for each stage:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的竞争性辩论结构通常包括三个不同的阶段，即构建性论点、反驳和总结陈述。为了确保公平并模拟实际的竞争性辩论条件（Whitman [2005](#bib.bib41)），我们为每个阶段制定了具体规则：
- en: '![Refer to caption](img/cdf4a4857a4f3140c37d835accc92932.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/cdf4a4857a4f3140c37d835accc92932.png)'
- en: 'Figure 2: Agent for Debate (Agent4Debate) Workflow: A dynamic framework simulating
    human debate team collaboration. From searching to reviewing, it showcases how
    four key roles (Searcher, Analyzer, Writer, Reviewer) interact and work iteratively.
    The right side illustrates the cyclical process from information gathering to
    argument formation using Stage 1 as an example, highlighting the framework’s multi-steps
    progression and recursive refinement.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：辩论代理（Agent4Debate）工作流程：一个模拟人类辩论团队协作的动态框架。从搜索到审阅，展示了四个关键角色（搜索员、分析员、撰写员、审阅员）如何互动和迭代工作。右侧展示了从信息收集到论点形成的循环过程，以阶段1为例，突出框架的多步骤进展和递归优化。
- en: •
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: In Stage 1 (Constructive Arguments), both sides work independently, with the
    Con side unable to view the Pro’s constructive argument, ensuring initial viewpoints
    are uninfluenced.
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在阶段1（构建性论点）中，双方独立工作，反方无法查看正方的构建性论点，确保初始观点不受影响。
- en: •
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Stages 2 and 3 (Rebuttal and Summary) employ a progressive disclosure mechanism,
    where participants access all previous content to construct targeted statements.
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 阶段2和3（反驳和总结）采用逐步披露机制，参与者可以访问所有先前内容以构建有针对性的陈述。
- en: •
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We alternate the sequence across stages to balance the advantages of speaking
    order. The Pro side speaks first in Stage 2, while the Con side leads in Stage
    3.
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们在各阶段之间交替序列，以平衡发言顺序的优势。正方在阶段2中首先发言，而反方在阶段3中主导。
- en: Agent for Debate
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 辩论代理
- en: To address the challenges of hallucination and the difficulties in maintaining
    competitiveness and argumentative consistency in sustained debate scenarios, we
    propose the Agent for Debate (Agent4Debate) framework to enable LLMs to participate
    in competitive debates, as shown in Figure [2](#Sx3.F2 "Figure 2 ‣ Task Definition
    ‣ Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive
    Debate"). This framework dynamically simulates human debate preparation through
    dialogue-based collaboration (Wu et al. [2023](#bib.bib42)) among four LLM-based
    agents, each mirroring key roles in a human debate team. The Searcher acts as
    a research assistant, gathering relevant information, while the Analyzer functions
    like an executive coach, strategizing and analyzing arguments. The Writer performs
    as a debater, crafting and articulating arguments, and the Reviewer serves as
    a debate coach, providing feedback and quality control. These agents interact
    flexibly throughout the debate process, adapting their roles and contributions
    based on the current stage and needs, much like a well-coordinated human debate
    team.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对幻觉问题以及在持续辩论场景中保持竞争力和论点一致性的困难，我们提出了辩论代理（Agent4Debate）框架，使得大规模语言模型（LLMs）能够参与竞争性辩论，如图
    [2](#Sx3.F2 "Figure 2 ‣ Task Definition ‣ Can LLMs Beat Humans in Debating? A
    Dynamic Multi-agent Framework for Competitive Debate") 所示。该框架通过基于对话的协作（Wu et al.
    [2023](#bib.bib42)）动态模拟人类辩论准备，包含四个基于LLM的代理，每个代理反映了人类辩论团队中的关键角色。搜索者作为研究助手，负责收集相关信息，而分析师则像执行教练一样，负责制定策略和分析论点。撰稿者充当辩手，撰写和阐述论点，审阅者则作为辩论教练，提供反馈和质量控制。这些代理在整个辩论过程中灵活互动，根据当前阶段和需求调整角色和贡献，就像一个协调良好的人工辩论团队一样。
- en: The collaboration in Agent4Debate is not just a simple sequence of steps, but
    rather a dynamic interaction between multiple agents, based on the debate stage
    and context. All the agents are equipped with customized prompts for different
    debate stages, enabling them to better adapt to and execute the specific tasks
    of the current stage. In the following sections, we introduce the functions of
    each agent in detail.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Agent4Debate中的协作不仅仅是简单的步骤序列，而是基于辩论阶段和上下文的多个代理之间的动态互动。所有代理都配备了不同辩论阶段的定制提示，使其能够更好地适应和执行当前阶段的具体任务。在接下来的章节中，我们将详细介绍每个代理的功能。
- en: Searcher Agent
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 搜索者代理
- en: The Searcher is a tool agent in the Agent4Debate framework, designed to effectively
    mitigate hallucination issues and address information timeliness problems that
    LLMs may encounter during debates. It achieves this by accessing and organizing
    information from external knowledge bases. The workflow of Searcher primarily
    involves decomposing search questions into more refined queries, then utilizing
    external tools (such as search engines or specialized knowledge bases) to retrieve
    relevant information, and finally systematically compiling and organizing the
    obtained answers. The information compiled by the Searcher forms a motion knowledge
    base, which is fixed and accessible to all agents for reference throughout the
    entire debate process. This approach ensures consistency and reliability of the
    information used in the debate. Note that, the Searcher plays different roles
    at various stages of the debate. In Stage 1, the Searcher uses the motion as the
    search question for information gathering. However, in Stage 2 and Stage 3, the
    Searcher switches to a passive mode, waiting for specific instructions from the
    Writer before conducting targeted searches.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索者是Agent4Debate框架中的一个工具代理，旨在有效减轻幻觉问题，并解决LLMs在辩论过程中可能遇到的信息时效性问题。它通过访问和组织来自外部知识库的信息来实现这一目标。搜索者的工作流程主要包括将搜索问题细分为更精炼的查询，然后利用外部工具（如搜索引擎或专门的知识库）检索相关信息，最后系统地编译和整理获得的答案。搜索者编译的信息形成了一个固定的运动知识库，所有代理在整个辩论过程中均可参考。此方法确保了辩论中使用的信息的一致性和可靠性。注意，搜索者在辩论的不同阶段扮演不同的角色。在阶段1中，搜索者使用运动作为信息收集的搜索问题。然而，在阶段2和阶段3中，搜索者切换到被动模式，等待撰稿者的具体指示后再进行针对性搜索。
- en: Analyzer Agent
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分析师代理
- en: 'The Analyzer is a core agent in the Agent4Debate framework, integrating real-time
    information from the debate and providing structured guidance for subsequent content
    output. Its primary function is to systematically analyze and plan the debate
    content based on the given motion, current stage, and historical context, thus
    bridging different phases of the debate. The workflow of Analyzer primarily involves
    breaking down the debate content step-by-step, drafting detailed outlines, and
    providing targeted strategic advice to other agents. This approach ensures coherence
    in debate reasoning and comprehensiveness in argumentation. Notably, the Analyzer
    plays different roles at various stages:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 分析员是Agent4Debate框架中的核心角色，整合辩论中的实时信息，并为后续内容输出提供结构化的指导。其主要功能是根据给定的动议、当前阶段和历史背景，系统地分析和规划辩论内容，从而连接辩论的不同阶段。分析员的工作流程主要涉及逐步拆解辩论内容，起草详细的大纲，并向其他代理提供有针对性的战略建议。这种方法确保了辩论推理的连贯性和论证的全面性。值得注意的是，分析员在不同阶段扮演不同的角色：
- en: •
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: In Stage 1, the Analyzer receives the debate topic and compiled materials from
    the Searcher. It then summarizes the motion and formulates definitions, judgment
    criteria, main arguments, and supporting evidence from its own perspective.
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在第1阶段，分析员接收来自搜索员的辩论主题和整理材料。然后，分析员总结动议并从自身的角度制定定义、判断标准、主要论点和支持证据。
- en: •
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: In Stage 2, the Analyzer analyzes all content from previous phases, summarizing
    the differences in viewpoints between both sides, such as the opponent’s definitions
    and judgment criteria. It then suggests rebuttal techniques that can be used to
    address these differences.
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在第2阶段，分析员分析之前阶段的所有内容，总结双方观点的差异，如对手的定义和判断标准。然后建议可以用来解决这些差异的反驳技巧。
- en: •
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: In Stage 3, in addition to continuing to summarize points of disagreement and
    provide rebuttal techniques, the Analyzer also offers suggestions from a value-based
    perspective, further enhancing the depth and persuasiveness of the debate.
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在第3阶段，除了继续总结分歧点和提供反驳技巧外，分析员还从价值观的角度提出建议，进一步增强辩论的深度和说服力。
- en: Writer Agent
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 撰稿人代理
- en: 'The Writer is the executive agent in the Agent4Debate framework, responsible
    for transforming analysis and planning into actual debate content. Its primary
    function is to compose complete debate drafts based on the instructions and outlines
    provided by the Analyzer and to revise these drafts according to feedback from
    the Reviewer, ensuring the quality and persuasiveness of the debate. Workflow
    of the Writer primarily encompasses the following aspects:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 撰稿人是Agent4Debate框架中的执行代理，负责将分析和规划转化为实际的辩论内容。其主要功能是根据分析员提供的指示和大纲撰写完整的辩论草稿，并根据审阅员的反馈修订这些草稿，以确保辩论的质量和说服力。撰稿人的工作流程主要包括以下方面：
- en: •
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Content Creation: Based on the outline provided by the Analyzer, the Writer
    expands it into a detailed debate script, ensuring the logic of arguments and
    the sufficiency of supporting evidence.'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 内容创作：根据分析员提供的大纲，撰稿人将其扩展为详细的辩论脚本，确保论点逻辑严谨，证据充分。
- en: •
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Revision and Refinement: Upon receiving modification suggestions from the Reviewer,
    the Writer makes corresponding adjustments and optimizations to the script to
    enhance its overall quality.'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 修订与完善：在接收到审阅员的修改建议后，撰稿人对脚本进行相应的调整和优化，以提高整体质量。
- en: •
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Resource Assessment: The Writer evaluates whether the information in the current
    knowledge base is sufficient to support the requirements of the outline and script
    revisions. If information is found to need to be improved, the Writer proactively
    initiates requests to the Searcher, clearly specifying the additional materials
    needed.'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 资源评估：撰稿人评估当前知识库中的信息是否足够支持大纲和脚本的要求。如果发现信息需要补充，撰稿人会主动向搜索员发起请求，明确说明所需的额外材料。
- en: Reviewer Agent
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 审阅员代理
- en: 'The Reviewer is the quality control agent in the Agent4Debate framework, responsible
    for reviewing and evaluating debate scripts generated by the Writer. Its primary
    function is to provide targeted modification suggestions based on the current
    debate stage and historical context, ensuring the debate content’s quality, logic,
    and persuasiveness. The Reviewer’s workflow focuses on different aspects at various
    stages of the debate:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Reviewer 是 Agent4Debate 框架中的质量控制代理，负责审查和评估 Writer 生成的辩论稿。其主要功能是根据当前辩论阶段和历史背景提供有针对性的修改建议，以确保辩论内容的质量、逻辑性和说服力。Reviewer
    的工作流程在辩论的不同阶段关注不同方面：
- en: •
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: In Stage 1, the Reviewer primarily concentrates on the completeness of the argument
    structure, the comprehensiveness of content (including definitions, criteria,
    and main points), the sufficiency of supporting evidence, and the fluency of expression.
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在阶段 1 中，Reviewer 主要关注论证结构的完整性、内容的全面性（包括定义、标准和要点）、支持证据的充分性以及表达的流畅性。
- en: •
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: In Stage 2, building upon the previous stage, the Reviewer additionally focuses
    on the appropriate application of rebuttal techniques and ensures that rebuttals
    to the opponent’s arguments do not lead to self-contradiction in one’s stance.
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在阶段 2 中，基于前一个阶段的内容，Reviewer 还特别关注反驳技巧的恰当应用，并确保对对手论点的反驳不会导致自己立场的自我矛盾。
- en: •
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: In Stage 3, besides addressing the content from the previous two stages, the
    Reviewer also assesses the depth of the debate content and makes a judgment based
    on the context, providing detailed reasons for this assessment.
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在阶段 3 中，除了处理前两个阶段的内容外，Reviewer 还评估辩论内容的深度，并根据上下文做出判断，提供详细的评估理由。
- en: The Reviewer maintains argumentative coherence by continuously assessing consistency
    with previously presented information across all debate stages. This process involves
    providing feedback and modification suggestions to the Writer, and facilitating
    targeted revisions. The review-revision cycle persists iteratively until the script
    meets the Reviewer’s quality standards.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Reviewer 通过不断评估辩论各阶段与之前信息的一致性来保持论证的连贯性。这个过程涉及向 Writer 提供反馈和修改建议，并促进有针对性的修订。审查-修订周期会反复进行，直到稿件符合
    Reviewer 的质量标准。
- en: Experimental Setup
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实验设置
- en: Experimental Subjects
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实验对象
- en: Our experimental design involves three types of participants, including the
    baseline framework, Agent4Debate based on different LLMs, and human participants.
    For all models, we set temperature to 0.2 and Top P to 0.75, with no other parameters
    adjusted.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实验设计涉及三种类型的参与者，包括基线框架、基于不同 LLM 的 Agent4Debate 和人工参与者。对于所有模型，我们将温度设置为 0.2，Top
    P 设置为 0.75，其他参数保持不变。
- en: Baseline
  id: totrans-76
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基线
- en: We adopt the benchmark framework of AI-Debater 2024 competition¹¹1http://www.fudan-disc.com/sharedtask/AIDebater24,
    incorporating Tavily²²2https://tavily.com as the search engine and stage-specific
    prompts. We uses Claude-3.5-sonnet and Deepseek-Chat (Bi et al. [2024](#bib.bib4))
    as the foundation models.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们采用了 AI-Debater 2024 竞赛¹¹1http://www.fudan-disc.com/sharedtask/AIDebater24
    的基准框架，并结合 Tavily²²2https://tavily.com 作为搜索引擎和特定阶段提示。我们使用 Claude-3.5-sonnet 和 Deepseek-Chat（Bi
    等人 [2024](#bib.bib4)）作为基础模型。
- en: Agent4Debate
  id: totrans-78
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Agent4Debate
- en: To comprehensively evaluate the generalization capability of Agent4Debate and
    conduct more in-depth comparative experiments, we select a variety of advanced
    LLMs as the foundation for Agent4Debate. These models include Claude-3.5-sonnet,
    GPT-4o (OpenAI [2023](#bib.bib22)), and Gemini-1.5-Pro/Flash (Reid et al. [2024](#bib.bib28)),
    all of which have demonstrated excellent performance in various evaluations (Zheng
    et al. [2023](#bib.bib44)). Considering that our study focuses on Chinese competitive
    debate, we specifically incorporate several LLMs that excel in Chinese language
    processing, including Qwen2-72b-Instruct (Yang et al. [2024](#bib.bib43)), Deepseek-Chat
    , and GLM-4-Air. Switching models in Agent4Debate experiments updates all components
    accordingly. In all experiments, the Searcher used Tavily as the search engine.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 为了全面评估 Agent4Debate 的泛化能力并进行更深入的比较实验，我们选择了多种先进的 LLM 作为 Agent4Debate 的基础。这些模型包括
    Claude-3.5-sonnet、GPT-4o（OpenAI [2023](#bib.bib22)）和 Gemini-1.5-Pro/Flash（Reid
    等人 [2024](#bib.bib28)），它们在各种评估中均表现出色（Zheng 等人 [2023](#bib.bib44)）。考虑到我们的研究重点是中文竞争性辩论，我们特别纳入了几种在中文语言处理方面表现突出的
    LLM，包括 Qwen2-72b-Instruct（Yang 等人 [2024](#bib.bib43)）、Deepseek-Chat 和 GLM-4-Air。在
    Agent4Debate 实验中切换模型时，所有组件也会相应更新。在所有实验中，Searcher 使用 Tavily 作为搜索引擎。
- en: Humans
  id: totrans-80
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 人工
- en: We recruit ten experienced debaters for our experiment to validate the performance
    of Agent4Debate against humans in competitive debate. Each debater has with 2-4
    years of debate team training and at least one year of Chinese competitive debate
    experience. They are informed that they will be debating against artificial intelligence
    and are given 2 days of preparation time for each motion. To ensure effective
    communication, we use the Whisper model (Radford et al. [2023](#bib.bib26)) to
    transcribe human speeches into text while the human debaters read the model’s
    output directly. This design ensures accurate information transfer and provides
    human debaters ample time for reflection and response. These debaters participate
    only in the debates, not in other research activities.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们招募了十位经验丰富的辩手来进行实验，以验证Agent4Debate在竞争性辩论中对比人类的表现。每位辩手都有2-4年的辩论团队培训经验，并且至少有一年的中文竞争性辩论经验。他们被告知将与人工智能进行辩论，并且每个辩题都有2天的准备时间。为了确保有效沟通，我们使用Whisper模型（Radford
    et al. [2023](#bib.bib26)）将人类的演讲转录成文本，而人类辩手直接阅读模型的输出。这种设计确保了信息的准确传递，并为人类辩手提供了充足的反思和回应时间。这些辩手仅参与辩论，不参与其他研究活动。
- en: Metrics
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估指标
- en: Debatrix
  id: totrans-83
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 辩论评分员
- en: 'Debatrix (Liang et al. [2024](#bib.bib19)) is a multi-turn debate evaluation
    method based on LLMs. It comprehensively assesses debates by considering the chronological
    order of statements and evaluating them along three dimensions, each described
    in natural language: Argument (A), Source (S), and Language (L). These natural
    language evaluations are then integrated to form an Overall (O) assessment, ultimately
    determining the winner. In our implementation, we convert each dimension’s descriptive
    result into a ternary outcome (win, lose, or tie). This evaluation approach is
    particularly well-suited for our multi-turn, document-level competitive debate
    scenarios. In our experiments, we employ GPT-4o-mini as the foundational model
    for Debatrix. To ensure the reliability of the assessment, we conduct three independent
    evaluations using Debatrix for each debate, ultimately deriving the final scores.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: Debatrix（Liang et al. [2024](#bib.bib19)）是一种基于大型语言模型（LLMs）的多轮辩论评估方法。它通过考虑陈述的时间顺序并在三个维度上进行评估来全面评估辩论，每个维度用自然语言描述：论点（A）、来源（S）和语言（L）。这些自然语言评估随后整合形成一个总体（O）评估，最终确定获胜者。在我们的实施中，我们将每个维度的描述结果转换为三元结果（胜、负或平局）。这种评估方法特别适合我们的多轮、文档级竞争性辩论场景。在我们的实验中，我们使用GPT-4o-mini作为Debatrix的基础模型。为了确保评估的可靠性，我们对每场辩论进行三次独立评估，最终得出最终分数。
- en: Human
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 人类
- en: We invite three experienced Chinese competitive debate judges to participate
    in this study. Each judge possesses 3-5 years of experience in Chinese competitive
    debates and has coached university debate teams. The judges independently assess
    each debate, casting a vote for win, lose, or tie, with the outcome determined
    by majority rule. To maintain impartiality, judges are only informed that both
    sides have an equal burden of proof without receiving any additional context.
    It is important to note that all judges are external to the research development
    process and do not have backgrounds in computer science, thereby minimizing potential
    biases.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们邀请了三位经验丰富的中文竞争性辩论裁判参与这项研究。每位裁判都有3-5年的中文竞争性辩论经验，并且曾指导过大学辩论队。裁判们独立评估每场辩论，为胜、负或平局投票，结果由多数决定。为了保持公正，裁判们仅被告知双方有相等的举证责任，而没有提供任何额外的背景信息。值得注意的是，所有裁判均与研究开发过程无关，并且没有计算机科学背景，从而最大限度地减少潜在的偏见。
- en: Competitive Debate Arena
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 竞争性辩论领域
- en: To comprehensively assess the abilities of Agent4Debate, Baseline, and Humans
    in competitive debate, we establish the Competitive Debate Arena. This arena is
    designed to provide a fair and extensible evaluation environment, covering various
    types of debate motions and assessment methods. We carefully select 66 debate
    motions from major Chinese debate competitions over the past decade, including
    Chinese Debate World Cup, The World Mandarin Debating Championship, and International
    Chinese Debating Competition. These motions cover three main categories (Abell
    [2018](#bib.bib1)), including Value, Fact, and Policy. Fact makes statements or
    comparisons about testable aspects of the natural world, Value assigns value or
    judgment to certain things or concepts, while Policy typically suggests action
    plans through proposed changes.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 为了全面评估 Agent4Debate、Baseline 和 Humans 在竞争辩论中的能力，我们建立了竞争辩论竞技场。这个竞技场旨在提供一个公平且可扩展的评估环境，涵盖各种类型的辩论议题和评估方法。我们从过去十年主要的中国辩论比赛中精心挑选了
    66 个辩论议题，包括中国辩论世界杯、世界普通话辩论锦标赛和国际中文辩论比赛。这些议题涵盖了三个主要类别 (Abell [2018](#bib.bib1))，包括价值、事实和政策。事实对自然世界中可测试的方面做出陈述或比较，价值对某些事物或概念进行评判或赋予价值，而政策则通常通过提出变更建议来建议行动计划。
- en: 'In terms of evaluation methods, we adopt two independent review approaches,
    where one uses the Debatrix based on LLMs for assessment, and the other involves
    judgments by experienced human reviewers. These review methods are completely
    independent, each producing separate results. Based on these review methods, we
    construct two ranking systems, including Debatrix-Elo and Human-Elo. To build
    these ranking systems, we draw inspiration from the Chatbot Arena (Zheng et al.
    [2023](#bib.bib44)) approach and adopt an improved version of the Bradley-Terry
    (BT) model (Hunter [2004](#bib.bib13); Rafailov et al. [2024](#bib.bib27)) to
    calculate Elo scores. The traditional BT model uses the following formula to calculate
    the probability of Participant A winning over Participant B:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估方法方面，我们采用了两种独立的审查方式，其中一种使用基于 LLM 的 Debatrix 进行评估，另一种则由经验丰富的人工评审员进行判断。这些评审方法完全独立，每种方法产生单独的结果。基于这些评审方法，我们构建了两个排名系统，包括
    Debatrix-Elo 和 Human-Elo。为了构建这些排名系统，我们从 Chatbot Arena (Zheng et al. [2023](#bib.bib44))
    的方法中获得灵感，并采用了改进版的 Bradley-Terry (BT) 模型 (Hunter [2004](#bib.bib13); Rafailov et
    al. [2024](#bib.bib27)) 来计算 Elo 分数。传统的 BT 模型使用以下公式计算参与者 A 战胜参与者 B 的概率：
- en: '|  | $$P(A> |  | (3) |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '|  | $$P(A> |  | (3) |'
- en: where $\gamma_{A}$ represent the ability parameters of A and B, respectively.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$\gamma_{A}$ 分别表示 A 和 B 的能力参数。
- en: 'However, considering that our review system (whether Debatrix or human reviewers)
    independently provides three scores, we improve the traditional model by introducing
    a weight function based on score differences:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，考虑到我们的评审系统（无论是 Debatrix 还是人工评审）独立提供三个分数，我们通过引入基于分数差异的权重函数来改进传统模型：
- en: '|  | $w_{i}=\frac{1}{1+e^{-&#124;\text{score}_{A_{i}}-\text{score}_{B_{i}}&#124;}}$
    |  | (4) |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '|  | $w_{i}=\frac{1}{1+e^{-&#124;\text{score}_{A_{i}}-\text{score}_{B_{i}}&#124;}}$
    |  | (4) |'
- en: 'where $\text{score}\in[0,3]$. This weight function adjusts the importance of
    each match in the final ranking, making the ranking calculation more precise.
    Based on this weight function, our likelihood function becomes:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\text{score}\in[0,3]$。该权重函数调整了每场比赛在最终排名中的重要性，使得排名计算更为精确。基于这一权重函数，我们的似然函数变为：
- en: '|  | <math id=$$ |  | (5) |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '|  | <math id=$$ |  | (5) |'
- en: By maximizing this likelihood function, we can obtain more accurate ability
    parameter estimates, thus constructing a more precise ranking system.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 通过最大化这一似然函数，我们可以获得更准确的能力参数估计，从而构建一个更精确的排名系统。
- en: Our improved Elo system not only effectively reflects participants’ overall
    performance in multiple matchups but also allows for more nuanced adjustments
    based on the specifics of each match. Using two independent review methods and
    ranking systems, we can better understand the performance of participants and
    compare potential differences between Debatrix and human reviews. Furthermore,
    this Elo system is scalable, efficiently incorporating new frameworks or models
    for ongoing comparative analysis.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们改进后的 Elo 系统不仅有效反映了参与者在多个对决中的整体表现，还允许根据每场比赛的具体情况进行更细致的调整。通过使用两种独立的评审方法和排名系统，我们可以更好地了解参与者的表现，并比较
    Debatrix 和人工评审之间的潜在差异。此外，该 Elo 系统具有可扩展性，能够高效地融入新的框架或模型，以进行持续的比较分析。
- en: Experimental Results
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实验结果
- en: Agent4Debate vs. Baseline
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Agent4Debate vs. Baseline
- en: We conduct a comparative performance evaluation of Agent4Debate against the
    baselines. Each framework participates in 20 debate matches, including five different
    motions. To ensure fairness, the number of times each framework argued for the
    Pro and Con sides is balanced. Debatrix is employed as the evaluation criteria.
    Debatrix scoring is applied three times for each debate, with 1 point awarded
    for each win in the dimensions of Argument (A), Language (L), Source (S), and
    Overall (O) performance. In the case of a tie, both sides are awarded 0.5 points.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对Agent4Debate与基线进行比较性能评估。每个框架参与20场辩论比赛，包括五种不同的辩题。为确保公平，每个框架支持正方和反方的次数是平衡的。Debatrix被用作评估标准。每场辩论应用Debatrix评分三次，每个维度的胜利（论点（A）、语言（L）、来源（S）和总体（O））均获得1分。在平局情况下，双方均获得0.5分。
- en: '| Model | Framework | Debatrix |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 框架 | Debatrix |'
- en: '| --- | --- | --- |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| S | L | A | O |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| S | L | A | O |'
- en: '| --- | --- | --- | --- |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Claude-3.5-sonnet | Agent4Debate | 2.83 | 1.76 | 2.52 | 2.62 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| Claude-3.5-sonnet | Agent4Debate | 2.83 | 1.76 | 2.52 | 2.62 |'
- en: '| Baseline | 0.17 | 1.24 | 0.48 | 0.38 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 基线 | 0.17 | 1.24 | 0.48 | 0.38 |'
- en: '| Deepseek-Chat | Agent4Debate | 2.73 | 1.88 | 2.31 | 2.77 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| Deepseek-Chat | Agent4Debate | 2.73 | 1.88 | 2.31 | 2.77 |'
- en: '| Baseline | 0.27 | 1.12 | 0.69 | 0.23 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 基线 | 0.27 | 1.12 | 0.69 | 0.23 |'
- en: 'Table 1: Comparison of Agent4Debate and Baseline.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：Agent4Debate与基线的比较。
- en: As shown in Table [1](#Sx6.T1 "Table 1 ‣ Agent4Debate vs. Baseline ‣ Experimental
    Results ‣ Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for
    Competitive Debate"), Agent4Debate enhances the competitive debating performance
    across both models. For Claude-3.5-sonnet, the Overall score improves from 0.38
    to 2.62, while for Deepseek-Chat, it increases from 0.23 to 2.77\. These results
    demonstrate that the Agent4Debate framework effectively enhances the performance
    of language models of varying scales and types in competitive debate tasks. Among
    all metrics, Source shows improvement. This can be attributed to the Searcher
    Agent and Analyzer Agent within Agent4Debate, which conducts an in-depth analysis
    of debate motions and systematic organization of materials, utilizing external
    knowledge more effectively than the simple search approach from baseline. The
    Language shows relatively modest improvement, reflecting robust generation capabilities
    of LLMs, leaving limited room for enhancement.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如表[1](#Sx6.T1 "Table 1 ‣ Agent4Debate vs. Baseline ‣ Experimental Results ‣
    Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive
    Debate")所示，Agent4Debate在两个模型中的竞争辩论性能都有所提升。对于Claude-3.5-sonnet，总体评分从0.38提升到2.62，而Deepseek-Chat则从0.23提升到2.77。这些结果表明，Agent4Debate框架有效提升了各种规模和类型的语言模型在竞争辩论任务中的表现。在所有指标中，来源表现出改进。这归因于Agent4Debate中的Searcher
    Agent和Analyzer Agent，它们对辩题进行深入分析和系统组织材料，比基线中的简单搜索方法更有效地利用了外部知识。语言方面的改进相对较小，反映了LLMs的生成能力强，提升空间有限。
- en: Comparing the results between Claude-3.5-sonnet and Deepseek-Chat, it is observed
    that Agent4Debate yields more pronounced performance improvements for the more
    powerful model, particularly in the Argument and Overall metrics. This may be
    due to more advanced models possessing stronger reasoning abilities and better
    instruction-following capabilities (Kaplan et al. [2020](#bib.bib15)), thus exhibiting
    superior adaptability to complex frameworks.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 比较Claude-3.5-sonnet和Deepseek-Chat的结果，观察到Agent4Debate在更强大的模型中表现出更明显的性能提升，特别是在论点和总体指标方面。这可能是由于更先进的模型拥有更强的推理能力和更好的指令跟随能力（Kaplan
    et al. [2020](#bib.bib15)），因此对复杂框架的适应性更强。
- en: Ablation Study
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 消融研究
- en: To evaluate the contribution of each agent within Agent4Debate, we conduct a
    series of ablation studies. The experimental setup remains consistent with the
    previous comparative experiments. Each ablation configuration engages in 20 debates
    across five motions, with a balanced distribution of the Pro and Con sides. The
    evaluation continues to employ Debatrix, with the scoring method identical to
    that of the comparative experiments. We do not perform an ablation experiment
    on the Writer Agent, as it is responsible for the text generation at every stage.
    The foundation model for the ablation study is Claude-3.5-sonnet.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 为评估 Agent4Debate 中每个代理的贡献，我们进行了一系列消融研究。实验设置与之前的对比实验保持一致。每个消融配置进行 20 次辩论，涉及五个论题，Pro
    和 Con 方面分布均衡。评估继续使用 Debatrix，评分方法与对比实验相同。我们没有对 Writer Agent 进行消融实验，因为它负责每个阶段的文本生成。消融研究的基础模型是
    Claude-3.5-sonnet。
- en: '| Framework | Debatrix |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 框架 | Debatrix |'
- en: '| --- | --- |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| S | L | A | O |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| S | L | A | O |'
- en: '| --- | --- | --- | --- |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Agent4Debate | 2.79 | 1.54 | 2.01 | 2.12 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| Agent4Debate | 2.79 | 1.54 | 2.01 | 2.12 |'
- en: '| w/o Searcher | 0.21 | 1.46 | 0.99 | 0.88 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 无 Searcher | 0.21 | 1.46 | 0.99 | 0.88 |'
- en: '| Agent4Debate | 1.83 | 1.50 | 1.79 | 1.76 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| Agent4Debate | 1.83 | 1.50 | 1.79 | 1.76 |'
- en: '| w/o Analyzer | 1.17 | 1.50 | 1.21 | 1.24 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 无 Analyzer | 1.17 | 1.50 | 1.21 | 1.24 |'
- en: '| Agent4Debate | 1.74 | 1.67 | 2.13 | 1.93 |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| Agent4Debate | 1.74 | 1.67 | 2.13 | 1.93 |'
- en: '| w/o Reviewer | 1.26 | 1.33 | 0.87 | 1.07 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 无 Reviewer | 1.26 | 1.33 | 0.87 | 1.07 |'
- en: 'Table 2: The results of ablation study. The foundation model for the ablation
    study is Claude-3.5-sonnet.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：消融研究的结果。消融研究的基础模型是 Claude-3.5-sonnet。
- en: Table [2](#Sx6.T2 "Table 2 ‣ Ablation Study ‣ Experimental Results ‣ Can LLMs
    Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive Debate")
    presents the detailed results of our ablation study, clearly illustrating the
    impact of removing each agent. The experimental results demonstrate that each
    agent in the Agent4Debate framework contributes to the overall performance. When
    we remove any agent, the Overall score decreases, confirming the necessity of
    each component. Specifically, removing the Analyzer reduces the Overall score
    from 2.12 to 1.76\. Its impact on the Source and Argument metrics is particularly
    notable, with the Source score dropping from 2.79 to 1.83 and the Argument score
    from 2.01 to 1.79\. This indicates the Analyzer’s crucial role in the formulation
    of material analysis, argument refinement, and rebuttal strategy. The absence
    of the Searcher results in a dramatic drop in the Source score from 2.79 to 0.21,
    while the Overall score falls from 2.12 to 0.88\. This highlights the importance
    of appropriately searching and organizing external knowledge to enhance debate
    performance. The removal of the Reviewer has a smaller impact on overall performance
    (Overall score decreases from 2.12 to 1.93). However, its primary function of
    reviewing drafts, suggesting revisions, and improving the output quality of Agent4Debate
    aligns with the framework’s design expectations.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [2](#Sx6.T2 "Table 2 ‣ Ablation Study ‣ Experimental Results ‣ Can LLMs Beat
    Humans in Debating? A Dynamic Multi-agent Framework for Competitive Debate") 展示了我们消融研究的详细结果，清楚地说明了移除每个代理的影响。实验结果表明，Agent4Debate
    框架中的每个代理都对整体表现有贡献。当我们移除任何一个代理时，整体评分都会下降，确认了每个组件的必要性。具体而言，移除 Analyzer 将整体评分从 2.12
    降至 1.76。它对 Source 和 Argument 指标的影响尤为显著，Source 评分从 2.79 降至 1.83，Argument 评分从 2.01
    降至 1.79。这表明 Analyzer 在材料分析、论证精炼和反驳策略的制定中扮演着关键角色。缺少 Searcher 会导致 Source 评分从 2.79
    降至 0.21，同时整体评分从 2.12 降至 0.88。这突显了适当搜索和组织外部知识以提升辩论表现的重要性。移除 Reviewer 对整体表现的影响较小（整体评分从
    2.12 降至 1.93）。然而，其主要功能是审查草稿、建议修订和提高 Agent4Debate 输出质量，与框架的设计期望相符。
- en: Results of Competitive Debate Arena
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 竞争辩论场的结果
- en: We collect records of 200 debate matches (excluding those from comparison experiments
    and ablation studies), covering 66 debate motions across three categories, including
    Fact, Value, and Policy. Participants included in Agent4Debate using different
    foundation models, two baselines, and ten human debaters, all of which are engaged
    in randomly paired competitions. Each debate is independently assessed using both
    the Debatrix and human judges. Utilizing the improved BT model in Eq. [5](#Sx5.E5
    "In Competitive Debate Arena ‣ Experimental Setup ‣ Can LLMs Beat Humans in Debating?
    A Dynamic Multi-agent Framework for Competitive Debate"), we calculate Elo scores
    for all 200 matches and sub-Elo scores for each of the three debate categories.
    The experimental results are presented in two independent ranking systems, consisting
    of Debatrix-Elo (Table [3](#Sx6.T3 "Table 3 ‣ Results of Competitive Debate Arena
    ‣ Experimental Results ‣ Can LLMs Beat Humans in Debating? A Dynamic Multi-agent
    Framework for Competitive Debate")) and Human-Elo (Table [4](#Sx6.T4 "Table 4
    ‣ Results of Competitive Debate Arena ‣ Experimental Results ‣ Can LLMs Beat Humans
    in Debating? A Dynamic Multi-agent Framework for Competitive Debate")).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们收集了 200 场辩论比赛的记录（排除了比较实验和消融研究的数据），涵盖了三个类别的 66 个辩论议题，包括事实、价值和政策。参与的模型包括使用不同基础模型的
    Agent4Debate、两个基线模型和十位人类辩手，所有辩论都在随机配对的情况下进行。每场辩论都由 Debatrix 和人类裁判独立评估。利用改进的 BT
    模型（见公式 [5](#Sx5.E5 "在竞争辩论领域 ‣ 实验设置 ‣ 大型语言模型能否击败人类？一种动态多智能体框架")），我们计算了所有 200 场比赛的
    Elo 分数以及三个辩论类别的子 Elo 分数。实验结果以两种独立的排名系统呈现，分别是 Debatrix-Elo（表 [3](#Sx6.T3 "表 3 ‣
    竞争辩论领域的结果 ‣ 实验结果 ‣ 大型语言模型能否击败人类？一种动态多智能体框架")）和人类-Elo（表 [4](#Sx6.T4 "表 4 ‣ 竞争辩论领域的结果
    ‣ 实验结果 ‣ 大型语言模型能否击败人类？一种动态多智能体框架")）。
- en: '| Model | Full | Fact | Policy | Value |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 完整 | 事实 | 政策 | 价值 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Gemini-1.5-Pro | 1034.15 | 1154.93 | 1231.98 | 1075.30 |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| Gemini-1.5-Pro | 1034.15 | 1154.93 | 1231.98 | 1075.30 |'
- en: '| Claude-3.5-sonnet | 1032.51 | 1159.18 | 1224.19 | 1074.33 |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| Claude-3.5-sonnet | 1032.51 | 1159.18 | 1224.19 | 1074.33 |'
- en: '| Qwen2-72b-Instruct | 1023.31 | 1130.83 | 1179.62 | 1081.75 |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| Qwen2-72b-Instruct | 1023.31 | 1130.83 | 1179.62 | 1081.75 |'
- en: '| GPT-4o | 1022.21 | 1150.14 | 1137.49 | 1069.55 |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4o | 1022.21 | 1150.14 | 1137.49 | 1069.55 |'
- en: '| Gemini-1.5-Flash | 1012.45 | 1136.21 | 1156.50 | 1057.73 |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| Gemini-1.5-Flash | 1012.45 | 1136.21 | 1156.50 | 1057.73 |'
- en: '| GLM-4-Air | 1011.72 | 1155.07 | 1148.53 | 1048.42 |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| GLM-4-Air | 1011.72 | 1155.07 | 1148.53 | 1048.42 |'
- en: '| Deepseek-chat | 1004.00 | 1118.98 | 1131.16 | 1054.89 |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| Deepseek-chat | 1004.00 | 1118.98 | 1131.16 | 1054.89 |'
- en: '| Claude-3.5-sonnet^∗ | 982.07 | 479.50 | 956.21 | 1021.44 |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| Claude-3.5-sonnet^∗ | 982.07 | 479.50 | 956.21 | 1021.44 |'
- en: '| Human | 978.35 | 1109.73 | 515.57 | 953.05 |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 人类 | 978.35 | 1109.73 | 515.57 | 953.05 |'
- en: '| Deepseek-Chat^∗ | 954.34 | 491.13 | 478.78 | 983.99 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| Deepseek-Chat^∗ | 954.34 | 491.13 | 478.78 | 983.99 |'
- en: 'Table 3: Debatrix-Elo Ranking. ^∗ denotes baseline models, unmarked models
    are Agent4Debate foundation models.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：Debatrix-Elo 排名。^∗ 表示基线模型，未标记的模型为 Agent4Debate 基础模型。
- en: '| Model | Full | Fact | Policy | Value |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 完整 | 事实 | 政策 | 价值 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Gemini-1.5-Pro | 1040.64 | 1110.23 | 1104.79 | 1048.10 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| Gemini-1.5-Pro | 1040.64 | 1110.23 | 1104.79 | 1048.10 |'
- en: '| Claude-3.5-sonnet | 1031.15 | 1093.87 | 1104.44 | 1020.05 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| Claude-3.5-sonnet | 1031.15 | 1093.87 | 1104.44 | 1020.05 |'
- en: '| GPT-4o | 1028.84 | 1086.78 | 1099.63 | 1033.09 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4o | 1028.84 | 1086.78 | 1099.63 | 1033.09 |'
- en: '| Human | 1006.46 | 1055.82 | 1030.32 | 1006.57 |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| 人类 | 1006.46 | 1055.82 | 1030.32 | 1006.57 |'
- en: '| Gemini-1.5-Flash | 1000.00 | 1037.45 | 997.66 | 1003.29 |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| Gemini-1.5-Flash | 1000.00 | 1037.45 | 997.66 | 1003.29 |'
- en: '| Qwen2-72b-Instruct | 999.70 | 1041.10 | 976.16 | 1005.56 |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| Qwen2-72b-Instruct | 999.70 | 1041.10 | 976.16 | 1005.56 |'
- en: '| Claude-3.5-sonnet^∗ | 991.38 | 1023.29 | 968.34 | 997.47 |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| Claude-3.5-sonnet^∗ | 991.38 | 1023.29 | 968.34 | 997.47 |'
- en: '| GLM-4-Air | 972.48 | 940.00 | 948.31 | 996.67 |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| GLM-4-Air | 972.48 | 940.00 | 948.31 | 996.67 |'
- en: '| Deepseek-chat | 971.94 | 963.05 | 946.30 | 986.79 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| Deepseek-chat | 971.94 | 963.05 | 946.30 | 986.79 |'
- en: '| Deepseek-Chat^∗ | 962.61 | 786.44 | 911.33 | 979.29 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| Deepseek-Chat^∗ | 962.61 | 786.44 | 911.33 | 979.29 |'
- en: 'Table 4: Human-Elo Ranking. ^∗ denotes baseline models, unmarked models are
    Agent4Debate foundation models.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：人类-Elo 排名。^∗ 表示基线模型，未标记的模型为 Agent4Debate 基础模型。
- en: 'Drawing from the experimental results presented in Tables [3](#Sx6.T3 "Table
    3 ‣ Results of Competitive Debate Arena ‣ Experimental Results ‣ Can LLMs Beat
    Humans in Debating? A Dynamic Multi-agent Framework for Competitive Debate") and
    [4](#Sx6.T4 "Table 4 ‣ Results of Competitive Debate Arena ‣ Experimental Results
    ‣ Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive
    Debate"), we can derive the following insights. (1) Agent4Debate, especially those
    using advanced foundation models such as Gemini-1.5-Pro and Claude-3.5-sonnet,
    demonstrate performance comparable to or surpassing human debaters in Debatrix-Elo
    and Human-Elo rankings. The top-performing Agent4Debate (Gemini-1.5-Pro) consistently
    ranks first, scoring 1044.18 in Debatrix-Elo and 1040.64 in Human-Elo. Experimental
    results indicate that models with more robust reasoning and instruction-following
    capabilities perform better within the Agent4Debate framework. (2) In Debatrix-Elo,
    most models show score variations across the Fact, Policy, and Value categories.
    In contrast, Human-Elo displays more consistent scores for each model across categories.
    This disparity may arise because Debatrix considers Source, Language, and Argument
    dimensions, while human judges likely focus more on logic and rebuttal techniques.
    Debatrix-Elo and Human-Elo show high consistency in model rankings, particularly
    for top-performing models. However, human performance is ranked differently in
    the two rankings. In Debatrix-Elo, humans rank 8th with a score of 978.35, while
    in Human-Elo, they rank 4th with a score of 1006.46\. This suggests that Debatrix-Elo
    may underestimate human performance. This underestimation is partly due to the
    different evaluation tendencies between Debatrix and human judges, and partly
    because human speech quality deteriorates when transcribed to text. (3) In Debatrix-Elo,
    certain models excel in specific categories. This is due to differences in the
    argumentation processes for the three types of debate motions: Policy debates
    typically require extensive evidence to demonstrate policy necessity and effectiveness;
    Value debates often demand more substantial logical reasoning and expressive skills;
    Fact debates combine characteristics of both. These distinctions, reflected in
    Debatrix’s multi-dimensional evaluation, yield varying results.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 根据表格[3](#Sx6.T3 "Table 3 ‣ 竞争性辩论竞技场结果 ‣ 实验结果 ‣ 大型语言模型能否击败人类辩手？一个动态的多智能体框架")和[4](#Sx6.T4
    "Table 4 ‣ 竞争性辩论竞技场结果 ‣ 实验结果 ‣ 大型语言模型能否击败人类辩手？一个动态的多智能体框架")中展示的实验结果，我们可以得出以下见解。(1)
    Agent4Debate，特别是那些使用先进基础模型如Gemini-1.5-Pro和Claude-3.5-sonnet的模型，在Debatrix-Elo和Human-Elo排名中表现与人类辩手相当或更优。表现最好的Agent4Debate（Gemini-1.5-Pro）始终排名第一，在Debatrix-Elo中的得分为1044.18，在Human-Elo中的得分为1040.64。实验结果表明，具有更强推理和指令跟随能力的模型在Agent4Debate框架内表现更佳。(2)
    在Debatrix-Elo中，大多数模型在Fact、Policy和Value类别中得分有所波动。相比之下，Human-Elo显示出每个模型在各类别中的得分更加一致。这种差异可能是因为Debatrix考虑了Source、Language和Argument维度，而人类评审可能更侧重于逻辑和反驳技巧。Debatrix-Elo和Human-Elo在模型排名上显示出较高的一致性，特别是对于表现最好的模型。然而，人类的表现排名在两者中有所不同。在Debatrix-Elo中，人类排名第8，得分为978.35，而在Human-Elo中排名第4，得分为1006.46。这表明Debatrix-Elo可能低估了人类的表现。这种低估部分是由于Debatrix和人类评审之间的不同评估倾向，部分原因是人类的口头表现转录为文本时质量下降。(3)
    在Debatrix-Elo中，某些模型在特定类别中表现优异。这是由于三种辩论主题的论证过程存在差异：政策辩论通常需要大量证据来证明政策的必要性和有效性；价值辩论通常要求更多的逻辑推理和表达技巧；事实辩论则结合了两者的特点。这些区别反映在Debatrix的多维评估中，导致了不同的结果。
- en: Agent4Debate vs. Humans
  id: totrans-155
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Agent4Debate与人类对比
- en: '| Model | Debatrix | Human |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | Debatrix | 人类 |'
- en: '| --- | --- | --- |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| S | L | A | O |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| S | L | A | O |'
- en: '| --- | --- | --- | --- |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Human | 0.52 | 0.30 | 0.6 | 0.42 | 1.22 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 人类 | 0.52 | 0.30 | 0.6 | 0.42 | 1.22 |'
- en: '| Agent4Debate | 2.48 | 2.70 | 2.40 | 2.58 | 1.78 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| Agent4Debate | 2.48 | 2.70 | 2.40 | 2.58 | 1.78 |'
- en: 'Table 5: Comparison of Human and Agent4Debate'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 表格5：人类与Agent4Debate的比较
- en: We conduct a separate analysis of 30 debates between Agent4Debate and human
    debaters. In these debates, to ensure comprehensive experimentation, all foundation
    models of Agent4Debate participate. The scoring results from the Debatrix system
    and human judges are presented in Table [5](#Sx6.T5 "Table 5 ‣ Agent4Debate vs.
    Humans ‣ Results of Competitive Debate Arena ‣ Experimental Results ‣ Can LLMs
    Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive Debate").
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对 Agent4Debate 和人工辩手之间的 30 场辩论进行了单独分析。在这些辩论中，为确保实验的全面性，所有的 Agent4Debate 基础模型均参与其中。Debatrix
    系统和人工评审的评分结果见表 [5](#Sx6.T5 "表 5 ‣ Agent4Debate vs. 人工 ‣ 竞争辩论平台的结果 ‣ 实验结果 ‣ LLM
    能否击败人类辩手？一个动态多代理框架用于竞争辩论")。
- en: Debatrix for human performance is lower than human judges across three dimensions.
    This discrepancy may stem from several factors. Regarding Source, human debaters
    use voice input, which is then transcribed into text. People typically do not
    directly cite references in oral debates, leading to lower scores. The Language
    score is the lowest, possibly due to oral expressions often containing verbal
    tics and informal language, coupled with imperfect voice-to-text transcription
    accuracy, affecting language quality assessment. The low Argument score may be
    a cascading effect of the previous two low scores, thus impacting Debatrix’s overall
    understanding and evaluation of human input. In contrast, human judges employ
    different criteria when evaluating competitive debates. They usually prioritize
    core factors such as logical reasoning and debating skills, only considering other
    aspects when these primary elements are challenging to distinguish. This approach
    to judgment differs from the Debatrix.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在三个维度上，Debatrix 对人类表现的评分低于人工评审。这种差异可能源于几个因素。关于来源，人类辩手使用语音输入，然后将其转录为文本。人们在口头辩论中通常不会直接引用参考资料，从而导致较低的分数。语言评分最低，这可能是因为口头表达通常包含语言习惯和非正式语言，加上语音转文本的准确性不完美，影响了语言质量的评估。低的论点评分可能是前两项低分的连锁效应，从而影响了
    Debatrix 对人类输入的整体理解和评估。相比之下，人工评审在评估竞争辩论时采用不同的标准。他们通常优先考虑核心因素，如逻辑推理和辩论技巧，只有在这些主要因素难以区分时才考虑其他方面。这种判断方式与
    Debatrix 不同。
- en: Consistency
  id: totrans-165
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 一致性
- en: To analyze the differences between Debatrix and human evaluations, we conduct
    a consistency analysis. Consistency is calculated by comparing the result between
    human and Debatrix, with tie considered consistent outcomes. Table [6](#Sx6.T6
    "Table 6 ‣ Consistency ‣ Results of Competitive Debate Arena ‣ Experimental Results
    ‣ Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive
    Debate") presents the results, showing that internal consistency among human reviewers
    remains stable across all matches, while the consistency between Debatrix and
    human reviewers varies when including or excluding human debaters. These findings
    further corroborate the above observations. These findings suggest that while
    Debatrix shows differences from human reviewers in evaluating debates between
    humans and models, it still provides valuable insights, particularly in assessing
    model-to-model debates. In these cases, Debatrix offers multi-faceted analytical
    results that contribute to our understanding of models’ comprehensive capabilities
    in competitive debates.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 为了分析 Debatrix 和人工评估之间的差异，我们进行了一个一致性分析。一致性是通过比较人类和 Debatrix 的结果来计算的，平局被认为是一致的结果。表
    [6](#Sx6.T6 "表 6 ‣ 一致性 ‣ 竞争辩论平台的结果 ‣ 实验结果 ‣ LLM 能否击败人类辩手？一个动态多代理框架用于竞争辩论") 展示了结果，显示人类评审之间的内部一致性在所有比赛中保持稳定，而
    Debatrix 和人工评审之间的一致性在包括或排除人类辩手时有所变化。这些发现进一步证实了上述观察。这些发现表明，虽然 Debatrix 在评估人类与模型之间的辩论时与人工评审存在差异，但在评估模型间辩论时仍提供了有价值的见解。在这些情况下，Debatrix
    提供了多方面的分析结果，有助于我们理解模型在竞争辩论中的综合能力。
- en: '| Consistency | Excluding Human Debates | All Debates |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 一致性 | 排除人工辩论 | 所有辩论 |'
- en: '| --- | --- | --- |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Debatrix vs. Human | 0.66 | 0.56 |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| Debatrix 与人工 | 0.66 | 0.56 |'
- en: '| Among Human | 0.74 | 0.73 |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 人类之间 | 0.74 | 0.73 |'
- en: 'Table 6: Consistency between Debatrix and Human Judges'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '表 6: Debatrix 与人工评审的一致性'
- en: We further analyze the Elo rankings and Agent4Debate in the Appendix.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在附录中进一步分析了 Elo 排名和 Agent4Debate。
- en: Conclusion
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: We propose a dynamic multi-agent framework, Agent for Debate (Agent4Debate),
    to enable LLMs to participate in competitive debates. To evaluate the performance
    of Agent4Debate, we construct the Competitive Debate Arena, comprising 66 classic
    Chinese debate motions. We recruit ten human debaters and collect 200 debate matches
    involving Agent4Debate, baselines, and human debaters. Using the Debatrix and
    human judges for evaluation, we propose Debatrix-Elo and Human-Elo rankings. Experimental
    results show that our state-of-the-art Agent4Debate exhibits capabilities comparable
    to those of humans in competitive debates. Ablation studies prove the effectiveness
    of each component in the agent structure.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出了一种动态多智能体框架——辩论代理（Agent4Debate），以使LLMs能够参与竞争性辩论。为了评估Agent4Debate的性能，我们构建了竞争辩论竞技场，包括66个经典的中文辩论议题。我们招募了十名人类辩手，并收集了200场涉及Agent4Debate、基线模型和人类辩手的辩论比赛。使用Debatrix和人类评审进行评估，我们提出了Debatrix-Elo和Human-Elo排名。实验结果表明，我们的最先进的Agent4Debate在竞争性辩论中展现出的能力可与人类相媲美。消融研究证明了代理结构中每个组件的有效性。
- en: References
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Abell (2018) Abell, J. 2018. Value, Fact, and Policy Resolutions.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abell (2018) Abell, J. 2018. 价值、事实和政策决议。
- en: 'Argyle et al. (2022) Argyle, L. P.; Busby, E. C.; Fulda, N.; Gubler, J.; Rytting,
    C.; and Wingate, D. 2022. Out of One, Many: Using Language Models to Simulate
    Human Samples. In *Proceedings of the 60th Annual Meeting of the Association for
    Computational Linguistics (Volume 1: Long Papers)*, 819–862.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Argyle 等人 (2022) Argyle, L. P.; Busby, E. C.; Fulda, N.; Gubler, J.; Rytting,
    C.; 和 Wingate, D. 2022. 从一而多：使用语言模型模拟人类样本。见 *第60届计算语言学协会年会论文集（第1卷：长篇论文）*，819–862。
- en: 'Atkinson et al. (2017) Atkinson, K.; Baroni, P.; Giacomin, M.; Hunter, A.;
    Prakken, H.; Reed, C.; Simari, G. R.; Thimm, M.; and Villata, S. 2017. Towards
    Artificial Argumentation. *AI Mag.*, 38: 25–36.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Atkinson 等人 (2017) Atkinson, K.; Baroni, P.; Giacomin, M.; Hunter, A.; Prakken,
    H.; Reed, C.; Simari, G. R.; Thimm, M.; 和 Villata, S. 2017. 朝向人工论证。*AI Mag.*,
    38: 25–36。'
- en: 'Bi et al. (2024) Bi, X.; Chen, D.; Chen, G.; Chen, S.; Dai, D.; Deng, C.; Ding,
    H.; Dong, K.; Du, Q.; Fu, Z.; et al. 2024. Deepseek llm: Scaling open-source language
    models with longtermism. *arXiv preprint arXiv:2401.02954*.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bi 等人 (2024) Bi, X.; Chen, D.; Chen, G.; Chen, S.; Dai, D.; Deng, C.; Ding,
    H.; Dong, K.; Du, Q.; Fu, Z.; 等人. 2024. Deepseek llm：以长期主义扩展开源语言模型。*arXiv 预印本
    arXiv:2401.02954*。
- en: Boiko, MacKnight, and Gomes (2023) Boiko, D. A.; MacKnight, R.; and Gomes, G.
    2023. Emergent Autonomous Scientific Research Capabilities of Large Language Models.
    *arXiv preprint arXiv:2304.05332*.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Boiko, MacKnight, 和 Gomes (2023) Boiko, D. A.; MacKnight, R.; 和 Gomes, G. 2023.
    大型语言模型的自发性科学研究能力。*arXiv 预印本 arXiv:2304.05332*。
- en: 'Carlile et al. (2018) Carlile, W.; Gurrapadi, N.; Ke, Z.; and Ng, V. 2018.
    Give Me More Feedback: Annotating Argument Persuasiveness and Related Attributes
    in Student Essays. In Gurevych, I.; and Miyao, Y., eds., *Proceedings of the 56th
    Annual Meeting of the Association for Computational Linguistics (Volume 1: Long
    Papers)*, 621–631\. Melbourne, Australia: Association for Computational Linguistics.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Carlile 等人 (2018) Carlile, W.; Gurrapadi, N.; Ke, Z.; 和 Ng, V. 2018. 给我更多反馈：标注学生论文中的论证说服力及相关属性。见
    Gurevych, I.; 和 Miyao, Y., 编，《第56届计算语言学协会年会论文集（第1卷：长篇论文）》，621–631\. 澳大利亚墨尔本：计算语言学协会。
- en: 'Chang (2024) Chang, E. Y. 2024. SocraSynth: Multi-LLM Reasoning with Conditional
    Statistics. arXiv:2402.06634.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chang (2024) Chang, E. Y. 2024. SocraSynth：具有条件统计的多LLM推理。arXiv:2402.06634。
- en: Chen et al. (2024) Chen, G.; Cheng, L.; Tuan, L. A.; and Bing, L. 2024. Exploring
    the Potential of Large Language Models in Computational Argumentation. arXiv:2311.09022.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人 (2024) Chen, G.; Cheng, L.; Tuan, L. A.; 和 Bing, L. 2024. 探索大型语言模型在计算性论证中的潜力。arXiv:2311.09022。
- en: Du et al. (2023) Du, Y.; Li, S.; Torralba, A.; Tenenbaum, J. B.; and Mordatch,
    I. 2023. Improving Factuality and Reasoning in Language Models through Multiagent
    Debate. arXiv:2305.14325.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Du 等人 (2023) Du, Y.; Li, S.; Torralba, A.; Tenenbaum, J. B.; 和 Mordatch, I.
    2023. 通过多智能体辩论提高语言模型的真实性和推理能力。arXiv:2305.14325。
- en: Eger, Daxenberger, and Gurevych (2017) Eger, S.; Daxenberger, J.; and Gurevych,
    I. 2017. Neural end-to-end learning for computational argumentation mining. *arXiv
    preprint arXiv:1704.06104*.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eger, Daxenberger, 和 Gurevych (2017) Eger, S.; Daxenberger, J.; 和 Gurevych,
    I. 2017. 用于计算性论证挖掘的神经端到端学习。*arXiv 预印本 arXiv:1704.06104*。
- en: 'Elo (1967) Elo, A. E. 1967. The proposed uscf rating system, its development,
    theory, and applications. *Chess life*, 22(8): 242–247.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Elo (1967) Elo, A. E. 1967. 提议的USCF等级系统及其发展、理论和应用。*棋类生活*, 22(8): 242–247。'
- en: Hua, Hu, and Wang (2019) Hua, X.; Hu, Z.; and Wang, L. 2019. Argument Generation
    with Retrieval, Planning, and Realization. arXiv:1906.03717.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 花、胡和王（2019）花晓、胡志、王磊。2019年。《基于检索、规划和实现的论证生成》。arXiv:1906.03717。
- en: 'Hunter (2004) Hunter, D. R. 2004. MM algorithms for generalized Bradley-Terry
    models. *The annals of statistics*, 32(1): 384–406.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '汉特（2004）汉特，D. R. 2004年。《广义布拉德利-特里模型的MM算法》。*统计年鉴*，32(1): 384–406。'
- en: 'Ji et al. (2023) Ji, Z.; Lee, N.; Frieske, R.; Yu, T.; Su, D.; Xu, Y.; Ishii,
    E.; Bang, Y. J.; Madotto, A.; and Fung, P. 2023. Survey of hallucination in natural
    language generation. *ACM Computing Surveys*, 55(12): 1–38.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '姜等（2023）姜震、李宁、弗里斯克、余涛、苏丹、徐云、石井英、邦英杰、马多托、冯鹏。2023年。《自然语言生成中的幻觉调查》。*ACM 计算调查*，55(12):
    1–38。'
- en: Kaplan et al. (2020) Kaplan, J.; McCandlish, S.; Henighan, T.; Brown, T. B.;
    Chess, B.; Child, R.; Gray, S.; Radford, A.; Wu, J.; and Amodei, D. 2020. Scaling
    Laws for Neural Language Models. arXiv:2001.08361.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卡普兰等（2020）卡普兰、麦坎德利什、亨尼根、布朗、切斯、查尔德、格雷、拉德福、吴杰、阿莫代。2020年。《神经语言模型的缩放定律》。arXiv:2001.08361。
- en: 'Lawrence and Reed (2019) Lawrence, J.; and Reed, C. 2019. Argument Mining:
    A Survey. *Computational Linguistics*, 45(4): 765–818.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '劳伦斯和里德（2019）劳伦斯、里德。2019年。《论证挖掘：综述》。*计算语言学*，45(4): 765–818。'
- en: 'Li et al. (2023) Li, G.; Hammoud, H. A. A. K.; Itani, H.; Khizbullin, D.; and
    Ghanem, B. 2023. CAMEL: Communicative Agents for ”Mind” Exploration of Large Scale
    Language Model Society. *arXiv preprint arXiv:2303.17760*.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 李等（2023）李光、哈穆德、伊塔尼、赫兹布林、加内姆。2023年。《CAMEL：用于“大规模语言模型社会”的交流代理》。*arXiv 预印本 arXiv:2303.17760*。
- en: Li, Ji, and Han (2021) Li, S.; Ji, H.; and Han, J. 2021. Document-level event
    argument extraction by conditional generation. *arXiv preprint arXiv:2104.05919*.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 李、季和韩（2021）李晟、季浩、韩俊。2021年。《基于条件生成的文档级事件论证提取》。*arXiv 预印本 arXiv:2104.05919*。
- en: 'Liang et al. (2024) Liang, J.; Ye, R.; Han, M.; Lai, R.; Zhang, X.; Huang,
    X.; and Wei, Z. 2024. Debatrix: Multi-dimensinal Debate Judge with Iterative Chronological
    Analysis Based on LLM. *arXiv preprint arXiv:2403.08010*.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '梁等（2024）梁俊、叶锐、韩敏、赖瑞、张旭、黄旭、魏智。2024年。《Debatrix: 基于大语言模型的多维度辩论评判与迭代时间序列分析》。*arXiv
    预印本 arXiv:2403.08010*。'
- en: 'Liu et al. (2024) Liu, N. F.; Lin, K.; Hewitt, J.; Paranjape, A.; Bevilacqua,
    M.; Petroni, F.; and Liang, P. 2024. Lost in the middle: How language models use
    long contexts. *Transactions of the Association for Computational Linguistics*,
    12: 157–173.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '刘等（2024）刘宁飞、林凯、休伊特、帕兰贾佩、贝维拉夸、佩特罗尼、梁佩。2024年。《迷失在中间：语言模型如何使用长上下文》。*计算语言学协会会刊*，12:
    157–173。'
- en: 'Nichols (1936) Nichols, E. R. 1936. A historical sketch of intercollegiate
    debating: I. *Quarterly Journal of Speech*, 22(2): 213–220.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '尼科尔斯（1936）尼科尔斯，E. R. 1936年。《大学辩论的历史概述：I》。*言语季刊*，22(2): 213–220。'
- en: OpenAI (2023) OpenAI, R. 2023. GPT-4 technical report. *arXiv*, arXiv preprint
    arXiv:2303.08774.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI（2023）OpenAI，R. 2023年。《GPT-4 技术报告》。*arXiv*，arXiv 预印本 arXiv:2303.08774。
- en: 'Ouyang et al. (2022) Ouyang, L.; Wu, J.; Jiang, X.; Almeida, D.; Wainwright,
    C.; Mishkin, P.; Zhang, C.; Agarwal, S.; Slama, K.; Ray, A.; et al. 2022. Training
    language models to follow instructions with human feedback. *Advances in neural
    information processing systems*, 35: 27730–27744.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '欧阳等（2022）欧阳乐、吴俊、姜新、阿尔梅达、温赖特、米什金、张晨、阿加瓦尔、斯拉马、雷阿、等。2022年。《通过人类反馈训练语言模型以遵循指令》。*神经信息处理系统进展*，35:
    27730–27744。'
- en: 'Park et al. (2023) Park, J. S.; O’Brien, J. C.; Cai, C. J.; Morris, M. R.;
    Liang, P.; and Bernstein, M. S. 2023. Generative Agents: Interactive Simulacra
    of Human Behavior. *arXiv preprint arXiv:2304.03442*.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 帕克等（2023）帕克、奥布莱恩、蔡超、莫里斯、梁佩、伯恩斯坦。2023年。《生成代理：人类行为的互动仿真》。*arXiv 预印本 arXiv:2304.03442*。
- en: Qian et al. (2023) Qian, C.; Cong, X.; Yang, C.; Chen, W.; Su, Y.; Xu, J.; Liu,
    Z.; and Sun, M. 2023. Communicative Agents for Software Development. *arXiv preprint
    arXiv:2207.07924*.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 钱等（2023）钱超、丛晓、杨超、陈伟、苏阳、徐静、刘正、孙美。2023年。《软件开发中的交流代理》。*arXiv 预印本 arXiv:2207.07924*。
- en: Radford et al. (2023) Radford, A.; Kim, J. W.; Xu, T.; Brockman, G.; McLeavey,
    C.; and Sutskever, I. 2023. Robust speech recognition via large-scale weak supervision.
    In *International conference on machine learning*, 28492–28518\. PMLR.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拉德福等（2023）拉德福、金俊伟、徐天、布罗克曼、麦克利维、苏茨克弗。2023年。《通过大规模弱监督的鲁棒语音识别》。在*国际机器学习会议*上，28492–28518。PMLR。
- en: 'Rafailov et al. (2024) Rafailov, R.; Sharma, A.; Mitchell, E.; Ermon, S.; Manning,
    C. D.; and Finn, C. 2024. Direct Preference Optimization: Your Language Model
    is Secretly a Reward Model. arXiv:2305.18290.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rafailov 等（2024）Rafailov, R.; Sharma, A.; Mitchell, E.; Ermon, S.; Manning,
    C. D.; 和 Finn, C. 2024. 直接偏好优化：你的语言模型实际上是一个奖励模型。arXiv:2305.18290。
- en: 'Reid et al. (2024) Reid, M.; Savinov, N.; Teplyashin, D.; Lepikhin, D.; Lillicrap,
    T.; Alayrac, J.-b.; Soricut, R.; Lazaridou, A.; Firat, O.; Schrittwieser, J.;
    et al. 2024. Gemini 1.5: Unlocking multimodal understanding across millions of
    tokens of context. *arXiv preprint arXiv:2403.05530*.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Reid 等（2024）Reid, M.; Savinov, N.; Teplyashin, D.; Lepikhin, D.; Lillicrap,
    T.; Alayrac, J.-b.; Soricut, R.; Lazaridou, A.; Firat, O.; Schrittwieser, J.;
    等. 2024. Gemini 1.5：在数百万个上下文标记中解锁多模态理解。*arXiv 预印本 arXiv:2403.05530*。
- en: 'Slonim et al. (2021) Slonim, N.; Bilu, Y.; Alzate, C.; Bar-Haim, R.; Bogin,
    B.; Bonin, F.; Choshen, L.; Cohen-Karlik, E.; Dankin, L.; Edelstein, L.; et al.
    2021. An autonomous debating system. *Nature*, 591(7850): 379–384.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Slonim 等（2021）Slonim, N.; Bilu, Y.; Alzate, C.; Bar-Haim, R.; Bogin, B.; Bonin,
    F.; Choshen, L.; Cohen-Karlik, E.; Dankin, L.; Edelstein, L.; 等. 2021. 一个自主辩论系统。*自然*，591(7850)：379–384。
- en: 'Thueblood (1926) Thueblood, T. C. 1926. A chapter on the organization of college
    courses in public speaking. *Quarterly Journal of Speech*, 12(1): 1–11.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Thueblood (1926) Thueblood, T. C. 1926. 关于大学公共演讲课程组织的一章。*演讲季刊*，12(1)：1–11。
- en: 'Touvron et al. (2023a) Touvron, H.; Martin, L.; Stone, K.; Albert, P.; Almahairi,
    A.; Babaei, Y.; Bashlykov, N.; Batra, S.; Bhargava, P.; Bhosale, S.; Bikel, D.;
    Blecher, L.; Ferrer, C. C.; Chen, M.; Cucurull, G.; Esiobu, D.; Fernandes, J.;
    Fu, J.; Fu, W.; Fuller, B.; Gao, C.; Goswami, V.; Goyal, N.; Hartshorn, A.; Hosseini,
    S.; Hou, R.; Inan, H.; Kardas, M.; Kerkez, V.; Khabsa, M.; Kloumann, I.; Korenev,
    A.; Koura, P. S.; Lachaux, M.-A.; Lavril, T.; Lee, J.; Liskovich, D.; Lu, Y.;
    Mao, Y.; Martinet, X.; Mihaylov, T.; Mishra, P.; Molybog, I.; Nie, Y.; Poulton,
    A.; Reizenstein, J.; Rungta, R.; Saladi, K.; Schelten, A.; Silva, R.; Smith, E. M.;
    Subramanian, R.; Tan, X. E.; Tang, B.; Taylor, R.; Williams, A.; Kuan, J. X.;
    Xu, P.; Yan, Z.; Zarov, I.; Zhang, Y.; Fan, A.; Kambadur, M.; Narang, S.; Rodriguez,
    A.; Stojnic, R.; Edunov, S.; and Scialom, T. 2023a. Llama 2: Open Foundation and
    Fine-Tuned Chat Models. arXiv:2307.09288.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Touvron 等（2023a）Touvron, H.; Martin, L.; Stone, K.; Albert, P.; Almahairi, A.;
    Babaei, Y.; Bashlykov, N.; Batra, S.; Bhargava, P.; Bhosale, S.; Bikel, D.; Blecher,
    L.; Ferrer, C. C.; Chen, M.; Cucurull, G.; Esiobu, D.; Fernandes, J.; Fu, J.;
    Fu, W.; Fuller, B.; Gao, C.; Goswami, V.; Goyal, N.; Hartshorn, A.; Hosseini,
    S.; Hou, R.; Inan, H.; Kardas, M.; Kerkez, V.; Khabsa, M.; Kloumann, I.; Korenev,
    A.; Koura, P. S.; Lachaux, M.-A.; Lavril, T.; Lee, J.; Liskovich, D.; Lu, Y.;
    Mao, Y.; Martinet, X.; Mihaylov, T.; Mishra, P.; Molybog, I.; Nie, Y.; Poulton,
    A.; Reizenstein, J.; Rungta, R.; Saladi, K.; Schelten, A.; Silva, R.; Smith, E.
    M.; Subramanian, R.; Tan, X. E.; Tang, B.; Taylor, R.; Williams, A.; Kuan, J.
    X.; Xu, P.; Yan, Z.; Zarov, I.; Zhang, Y.; Fan, A.; Kambadur, M.; Narang, S.;
    Rodriguez, A.; Stojnic, R.; Edunov, S.; 和 Scialom, T. 2023a. Llama 2：开放基础和微调聊天模型。arXiv:2307.09288。
- en: 'Touvron et al. (2023b) Touvron, H.; Martin, L.; Stone, K.; Albert, P.; Almahairi,
    A.; Babaei, Y.; Bashlykov, N.; Batra, S.; Bhargava, P.; Bhosale, S.; et al. 2023b.
    Llama 2: Open foundation and fine-tuned chat models. *arXiv preprint arXiv:2307.09288*.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Touvron 等（2023b）Touvron, H.; Martin, L.; Stone, K.; Albert, P.; Almahairi, A.;
    Babaei, Y.; Bashlykov, N.; Batra, S.; Bhargava, P.; Bhosale, S.; 等. 2023b. Llama
    2：开放基础和微调聊天模型。*arXiv 预印本 arXiv:2307.09288*。
- en: 'Tu et al. (2023) Tu, Q.; Chen, C.; Li, J.; Li, Y.; Shang, S.; Zhao, D.; Wang,
    R.; and Yan, R. 2023. CharacterChat: Learning towards Conversational AI with Personalized
    Social Support. *arXiv preprint arXiv:2308.10278*.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tu 等（2023）Tu, Q.; Chen, C.; Li, J.; Li, Y.; Shang, S.; Zhao, D.; Wang, R.; 和
    Yan, R. 2023. CharacterChat：向具有人性化社会支持的对话 AI 学习。*arXiv 预印本 arXiv:2308.10278*。
- en: Wachsmuth et al. (2024) Wachsmuth, H.; Lapesa, G.; Cabrio, E.; Lauscher, A.;
    Park, J.; Vecchi, E. M.; Villata, S.; and Ziegenbein, T. 2024. Argument Quality
    Assessment in the Age of Instruction-Following Large Language Models. arXiv:2403.16084.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wachsmuth 等（2024）Wachsmuth, H.; Lapesa, G.; Cabrio, E.; Lauscher, A.; Park,
    J.; Vecchi, E. M.; Villata, S.; 和 Ziegenbein, T. 2024. 在指令跟随大型语言模型时代的论证质量评估。arXiv:2403.16084。
- en: 'Wachsmuth et al. (2017a) Wachsmuth, H.; Naderi, N.; Hou, Y.; Bilu, Y.; Prabhakaran,
    V.; Thijm, T. A.; Hirst, G.; and Stein, B. 2017a. Computational argumentation
    quality assessment in natural language. In *Proceedings of the 15th Conference
    of the European Chapter of the Association for Computational Linguistics: Volume
    1, Long Papers*, 176–187.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wachsmuth 等（2017a）Wachsmuth, H.; Naderi, N.; Hou, Y.; Bilu, Y.; Prabhakaran,
    V.; Thijm, T. A.; Hirst, G.; 和 Stein, B. 2017a. 自然语言中的计算性论证质量评估。见 *第十五届欧洲计算语言学协会年会：第一卷，长篇论文*，176–187。
- en: 'Wachsmuth et al. (2017b) Wachsmuth, H.; Naderi, N.; Hou, Y.; Bilu, Y.; Prabhakaran,
    V.; Thijm, T. A.; Hirst, G.; and Stein, B. 2017b. Computational Argumentation
    Quality Assessment in Natural Language. In Lapata, M.; Blunsom, P.; and Koller,
    A., eds., *Proceedings of the 15th Conference of the European Chapter of the Association
    for Computational Linguistics: Volume 1, Long Papers*, 176–187\. Valencia, Spain:
    Association for Computational Linguistics.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wachsmuth 等人 (2017b) Wachsmuth, H.; Naderi, N.; Hou, Y.; Bilu, Y.; Prabhakaran,
    V.; Thijm, T. A.; Hirst, G.; 和 Stein, B. 2017b. 《自然语言中的计算论证质量评估》。收录于 Lapata, M.;
    Blunsom, P.; 和 Koller, A. 编，*第十五届欧洲计算语言学协会会议论文集：第一卷，长篇论文*，176–187。西班牙瓦伦西亚：计算语言学协会。
- en: Walton, Reed, and Macagno (2008) Walton, D.; Reed, C.; and Macagno, F. 2008.
    Argumentation Schemes. In *Computer Science, Psychology*.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Walton, Reed 和 Macagno (2008) Walton, D.; Reed, C.; 和 Macagno, F. 2008. 《论证方案》。收录于
    *计算机科学，心理学*。
- en: 'Wang et al. (2023a) Wang, H.; Du, X.; Yu, W.; Chen, Q.; Zhu, K.; Chu, Z.; Yan,
    L.; and Guan, Y. 2023a. Apollo’s Oracle: Retrieval-Augmented Reasoning in Multi-Agent
    Debates. *arXiv preprint arXiv:2312.04854*.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 (2023a) Wang, H.; Du, X.; Yu, W.; Chen, Q.; Zhu, K.; Chu, Z.; Yan, L.;
    和 Guan, Y. 2023a. 《阿波罗的神谕：多智能体辩论中的检索增强推理》。*arXiv 预印本 arXiv:2312.04854*。
- en: Wang et al. (2023b) Wang, L.; Ma, C.; Feng, X.; Zhang, Z.; Yang, H.; Zhang,
    J.; Chen, Z.; Tang, J.; Chen, X.; Lin, Y.; Zhao, W. X.; Wei, Z.; and Wen, J.-R.
    2023b. A Survey on Large Language Model Based Autonomous Agents. *arXiv preprint
    arXiv:2308.11432*.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 (2023b) Wang, L.; Ma, C.; Feng, X.; Zhang, Z.; Yang, H.; Zhang, J.;
    Chen, Z.; Tang, J.; Chen, X.; Lin, Y.; Zhao, W. X.; Wei, Z.; 和 Wen, J.-R. 2023b.
    《基于大型语言模型的自主智能体调查》。*arXiv 预印本 arXiv:2308.11432*。
- en: 'Wang et al. (2023c) Wang, L.; Zhang, J.; Yang, H.; Chen, Z.; Tang, J.; Zhang,
    Z.; Chen, X.; Lin, Y.; Song, R.; Zhao, W. X.; Xu, J.; Dou, Z.; Wang, J.; and Wen,
    J.-R. 2023c. When Large Language Model Based Agent Meets User Behavior Analysis:
    A Novel User Simulation Paradigm. *arXiv preprint arXiv:2306.02552*.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 (2023c) Wang, L.; Zhang, J.; Yang, H.; Chen, Z.; Tang, J.; Zhang, Z.;
    Chen, X.; Lin, Y.; Song, R.; Zhao, W. X.; Xu, J.; Dou, Z.; Wang, J.; 和 Wen, J.-R.
    2023c. 《当大型语言模型基础智能体遇到用户行为分析：一种新颖的用户模拟范式》。*arXiv 预印本 arXiv:2306.02552*。
- en: Whitman (2005) Whitman, G. 2005. Formats of Debate. https://www.csun.edu/~dgw61315/debformats.html.
    Accessed on August 04, 2024.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Whitman (2005) Whitman, G. 2005. 《辩论的格式》。https://www.csun.edu/~dgw61315/debformats.html。访问日期：2024年8月4日。
- en: 'Wu et al. (2023) Wu, Q.; Bansal, G.; Zhang, J.; Wu, Y.; Li, B.; Zhu, E.; Jiang,
    L.; Zhang, X.; Zhang, S.; Liu, J.; Awadallah, A. H.; White, R. W.; Burger, D.;
    and Wang, C. 2023. AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent
    Conversation. arXiv:2308.08155.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等人 (2023) Wu, Q.; Bansal, G.; Zhang, J.; Wu, Y.; Li, B.; Zhu, E.; Jiang,
    L.; Zhang, X.; Zhang, S.; Liu, J.; Awadallah, A. H.; White, R. W.; Burger, D.;
    和 Wang, C. 2023. 《AutoGen：通过多智能体对话实现下一代 LLM 应用》。arXiv:2308.08155。
- en: Yang et al. (2024) Yang, A.; Yang, B.; Hui, B.; Zheng, B.; Yu, B.; Zhou, C.;
    Li, C.; Li, C.; Liu, D.; Huang, F.; et al. 2024. Qwen2 technical report. *arXiv
    preprint arXiv:2407.10671*.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人 (2024) Yang, A.; Yang, B.; Hui, B.; Zheng, B.; Yu, B.; Zhou, C.; Li,
    C.; Li, C.; Liu, D.; Huang, F.; 等人. 2024. 《Qwen2 技术报告》。*arXiv 预印本 arXiv:2407.10671*。
- en: Zheng et al. (2023) Zheng, L.; Chiang, W.-L.; Sheng, Y.; Zhuang, S.; Wu, Z.;
    Zhuang, Y.; Lin, Z.; Li, Z.; Li, D.; Xing, E. P.; Zhang, H.; Gonzalez, J. E.;
    and Stoica, I. 2023. Judging LLM-as-a-judge with MT-Bench and Chatbot Arena. arXiv:2306.05685.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng 等人 (2023) Zheng, L.; Chiang, W.-L.; Sheng, Y.; Zhuang, S.; Wu, Z.; Zhuang,
    Y.; Lin, Z.; Li, Z.; Li, D.; Xing, E. P.; Zhang, H.; Gonzalez, J. E.; 和 Stoica,
    I. 2023. 《使用 MT-Bench 和 Chatbot Arena 评估 LLM 作为裁判的能力》。arXiv:2306.05685。
- en: Appendix
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录
- en: Further Analysis of Elo Rankings
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 进一步分析 Elo 排名
- en: Competitive Debate Arena currently includes only Chinese debate records. This
    choice is based on the availability of professional Chinese debate judges, ensuring
    the reliability of our Elo ranking system. However, Agent4Debate is designed to
    support competitive debates in other languages, including English, using the same
    structural framework. Expanding to multilingual debates would require only minor
    adjustments to the language constraints in the prompts. Future research may explore
    the implementation of debates in various languages.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的竞争辩论场仅包含中文辩论记录。这个选择基于专业中文辩论裁判的可用性，确保了我们的 Elo 排名系统的可靠性。然而，Agent4Debate 旨在支持其他语言的竞争辩论，包括英语，使用相同的结构框架。扩展到多语言辩论只需对提示中的语言约束进行少量调整。未来的研究可能会探索在各种语言中实施辩论。
- en: '| Model | Debatrix-CI | Human-CI |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | Debatrix-CI | 人类-CI |'
- en: '| --- | --- | --- |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Gemini-1.5-Pro | + 69/- 18 | + 57/- 14 |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| Gemini-1.5-Pro | + 69/- 18 | + 57/- 14 |'
- en: '| Claude-3.5-sonnet | + 67/- 18 | + 54/- 14 |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| Claude-3.5-sonnet | + 67/- 18 | + 54/- 14 |'
- en: '| Qwen2-72b-instruct | + 66/- 20 | + 54/- 15 |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| Qwen2-72b-instruct | + 66/- 20 | + 54/- 15 |'
- en: '| GPT-4o | + 66/- 20 | + 58/- 14 |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4o | + 66/- 20 | + 58/- 14 |'
- en: '| Gemini-1.5-flash | + 66/- 18 | + 53/- 15 |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| Gemini-1.5-flash | + 66/- 18 | + 53/- 15 |'
- en: '| GLM-4-Air | + 67/- 16 | + 48/- 19 |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| GLM-4-Air | + 67/- 16 | + 48/- 19 |'
- en: '| Deepseek-chat | + 64/- 22 | + 44/- 19 |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| Deepseek-chat | + 64/- 22 | + 44/- 19 |'
- en: '| baseline (Claude-3.5-sonnet) | + 69/- 36 | + 51/- 31 |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| 基线 (Claude-3.5-sonnet) | + 69/- 36 | + 51/- 31 |'
- en: '| Human | + 64/- 550 | + 50/- 22 |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| 人类 | + 64/- 550 | + 50/- 22 |'
- en: '| baseline (Deepseek-chat) | + 62/- 530 | + 32/- 520 |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| 基线 (Deepseek-chat) | + 62/- 530 | + 32/- 520 |'
- en: 'Table 7: 95% Confidence Intervals'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '表 7: 95% 置信区间'
- en: Table [7](#Ax1.T7 "Table 7 ‣ Further Analysis of Elo Rankings ‣ Appendix ‣ Can
    LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive
    Debate") presents the 95% confidence intervals (CI) for various models and human
    performance, as evaluated by both the Debatrix-Elo and Human-Elo rankings. The
    CIs are expressed as upper and lower bounds relative to the median scores. Based
    on experimental results, we estimate that new debate models or frameworks can
    achieve a relatively stable ranking after about 15 debates. This allows for quick
    assessment of their competitive debate performance. Models with lower win rates
    show wider CIs (like baseline (Deepseek-Chat)), especially in the lower bound.
    However, this does not significantly affect the evaluation of their debate performance.
    The wider CIs mainly reflect the increased uncertainty in precise ranking for
    these models.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [7](#Ax1.T7 "Table 7 ‣ Further Analysis of Elo Rankings ‣ Appendix ‣ Can LLMs
    Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive Debate")
    显示了各种模型和人类表现的95%置信区间（CI），这些评估是通过 Debatrix-Elo 和 Human-Elo 排名进行的。CI 表示为相对于中位数得分的上限和下限。根据实验结果，我们估计新的辩论模型或框架在大约15场辩论后可以达到相对稳定的排名。这使得对它们的竞争辩论表现能够进行快速评估。胜率较低的模型表现出更广泛的CI（如基线
    (Deepseek-Chat)），尤其是在下限方面。然而，这并不会显著影响对其辩论表现的评估。更宽的CI 主要反映了这些模型在精确排名方面的不确定性增加。
- en: The Elo system can be used to estimate the winning rate of competitive debates
    between models. Figure [3](#Ax1.F3 "Figure 3 ‣ Further Analysis of Elo Rankings
    ‣ Appendix ‣ Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework
    for Competitive Debate") presents the win rate calculated using the Debatrix-elo
    and Human-elo rankings, respectively.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: Elo 系统可用于估算模型之间竞争辩论的胜率。图 [3](#Ax1.F3 "Figure 3 ‣ Further Analysis of Elo Rankings
    ‣ Appendix ‣ Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework
    for Competitive Debate") 显示了分别使用 Debatrix-elo 和 Human-elo 排名计算的胜率。
- en: '![Refer to caption](img/a258143610574b525511d403e7a46e76.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/a258143610574b525511d403e7a46e76.png)'
- en: 'Figure 3: Predicted Win Rates Using Elo Rankings for Model A in A vs. B Battles.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '图 3: 使用 Elo 排名预测 A 模型在 A vs. B 战斗中的胜率。'
- en: Further Analysis of Agent4Debate
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 进一步分析 Agent4Debate
- en: As shown in Table [8](#Ax1.T8 "Table 8 ‣ Further Analysis of Agent4Debate ‣
    Appendix ‣ Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for
    Competitive Debate"), the interaction frequency data reveals distinct patterns
    across debate stages. The Searcher role shows peak activity during the Argument
    stage (3.4431), while the Writer’s interactions are highest in the Summary stage
    (3.0932). The Reviewer maintains consistently high engagement throughout all stages.
    In contrast, the Analyzer exhibits a stable, low interaction frequency (approximately
    1.0) across all phases. Notably, the Searcher’s high activity in the Stage 1 is
    due to its proactive information-seeking role, whereas in subsequent stages (Rebuttal
    and Summary), it assumes a more passive stance, resulting in lower interaction
    frequencies. These patterns suggest varied role importance and engagement levels
    at different debate stages, with the Analyzer serving as an efficient, low-interaction
    information processor throughout the process.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 如表 [8](#Ax1.T8 "Table 8 ‣ Further Analysis of Agent4Debate ‣ Appendix ‣ Can
    LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive
    Debate") 所示，交互频率数据揭示了辩论阶段的不同模式。Searcher 角色在 Argument 阶段表现出最高的活动量（3.4431），而 Writer
    的互动在 Summary 阶段最高（3.0932）。Reviewer 在所有阶段保持一致的高参与度。相比之下，Analyzer 在所有阶段的互动频率稳定且较低（约1.0）。值得注意的是，Searcher
    在阶段 1 的高活动是由于其主动的信息搜索角色，而在后续阶段（Rebuttal 和 Summary），它采取了更被动的立场，导致互动频率较低。这些模式表明在不同辩论阶段角色的重要性和参与水平有所不同，Analyzer
    在整个过程中作为高效、低互动的信息处理者。
- en: '| Stage | Searcher | Analyzer | Writer | Reviewer |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| 阶段 | Searcher | Analyzer | Writer | Reviewer |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Overall | 2.1862 | 1.0015 | 2.7243 | 2.4888 |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| 总体 | 2.1862 | 1.0015 | 2.7243 | 2.4888 |'
- en: '| Stage 1 | 3.4431 | 1.0036 | 2.4313 | 2.1682 |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| 阶段 1 | 3.4431 | 1.0036 | 2.4313 | 2.1682 |'
- en: '| Stage 2 | 1.3435 | 1.0000 | 2.7939 | 2.5817 |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| 阶段2 | 1.3435 | 1.0000 | 2.7939 | 2.5817 |'
- en: '| Stage 3 | 1.2559 | 1.0000 | 3.0932 | 2.8720 |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| 阶段3 | 1.2559 | 1.0000 | 3.0932 | 2.8720 |'
- en: 'Table 8: Interaction Frequencies of Roles Across Debate Stages in the Agent4Debate'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 表8：Agent4Debate中各角色在辩论阶段的互动频率
- en: Table [9](#Ax1.T9 "Table 9 ‣ Further Analysis of Agent4Debate ‣ Appendix ‣ Can
    LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive
    Debate") illustrates the average token usage (only calculated completion token)
    per utterance for each agent. The Searcher, responsible for collecting and organizing
    information, shows the highest token consumption (2182.90). The Analyzer and Writer
    exhibit similar token usage (795.06 and 811.94 respectively). The Reviewer, tasked
    with providing feedback, has the lowest token consumption (415.57), consistent
    with its role in offering concise critiques. These token consumption patterns
    align well with the intended functions of each role in our multi-agent framework
    design, with the Searcher’s high token usage emphasizing its critical role in
    information processing.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 表[9](#Ax1.T9 "表9 ‣ Agent4Debate进一步分析 ‣ 附录 ‣ LLM能否战胜人类辩论？一个动态多智能体框架用于竞争性辩论")展示了每个智能体每次发言的平均令牌使用量（仅计算完成令牌）。负责收集和组织信息的搜索者显示了最高的令牌消耗（2182.90）。分析师和撰写者的令牌使用量相似（分别为795.06和811.94）。负责提供反馈的审阅者具有最低的令牌消耗（415.57），与其提供简明批评的角色一致。这些令牌消耗模式与我们多智能体框架设计中每个角色的预期功能很好地对齐，搜索者的高令牌使用突显了其在信息处理中的关键作用。
- en: '| Token | Searcher | Analyzer | Writer | Reviewer |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| 令牌 | 搜索者 | 分析师 | 撰写者 | 审阅者 |'
- en: '| Completion | 2182.90 | 795.06 | 811.94 | 415.57 |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| 完成度 | 2182.90 | 795.06 | 811.94 | 415.57 |'
- en: 'Table 9: Token completion counts for different agents'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 表9：不同智能体的令牌完成计数
- en: Prompts
  id: totrans-253
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: This section outlines the prompt design principles for Agent4Debate. Due to
    space constraints, we provide only key examples here, with the complete set of
    prompts available in the Github Repository³³3https://github.com/ZhangYiqun018/agent-for-debate.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 本节概述了Agent4Debate的提示设计原则。由于篇幅限制，我们仅提供了关键示例，完整的提示集可以在Github Repository³³3https://github.com/ZhangYiqun018/agent-for-debate中找到。
- en: 'Agent4Debate employs a conversational multi-agent collaborative structure without
    implicit long-term memory. All information is stored within the dialogue context,
    accessible to each agent during their turn. The prompt design for each agent consists
    of five components: profile, knowledge, workflow, rules, and output format.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: Agent4Debate采用对话式多智能体协作结构，不具备隐式长期记忆。所有信息都存储在对话上下文中，各智能体在其回合时可以访问。每个智能体的提示设计包含五个组件：档案、知识、工作流程、规则和输出格式。
- en: 'The profile contains basic agent information. For instance, the Analyzer’s
    profile might state: ”You are an experienced debate coach tasked with analyzing
    debate motions, stances, and relevant materials.” The knowledge component stores
    debate-related information and techniques specific to the task of agent. For example,
    the Writer agent for the constructive argument (Stage 1) would have prompts on
    proof techniques, while Stage 2 Writer would have prompts on logical fallacies
    and rebuttal strategies. The workflow component outlines the specific steps for
    task completion, ensuring each agent follows a chain-of-thought (CoT) process.
    The rules component lists guidelines to prevent low-quality responses. Finally,
    the output format defines the structure of the response of agent.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 档案包含基本的智能体信息。例如，分析师的档案可能会说明：“你是一个经验丰富的辩论教练，负责分析辩论动议、立场和相关材料。”知识组件存储与辩论相关的信息和技术，针对智能体的任务。例如，建设性论证的撰写者（阶段1）会有有关证明技术的提示，而阶段2的撰写者则会有有关逻辑谬误和反驳策略的提示。工作流程组件概述了完成任务的具体步骤，确保每个智能体遵循链式思维（CoT）过程。规则组件列出了防止低质量响应的指导方针。最后，输出格式定义了智能体响应的结构。
- en: Each agent is guided by prompts with similar structures but varying content
    across different debate stages, ensuring task completion at each stage.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 每个智能体都由具有类似结构但内容不同的提示指导，以确保每个阶段的任务完成。
- en: Case Study
  id: totrans-258
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 案例研究
- en: 'Figures [4](#Ax1.F4 "Figure 4 ‣ Case Study ‣ Appendix ‣ Can LLMs Beat Humans
    in Debating? A Dynamic Multi-agent Framework for Competitive Debate") to [7](#Ax1.F7
    "Figure 7 ‣ Case Study ‣ Appendix ‣ Can LLMs Beat Humans in Debating? A Dynamic
    Multi-agent Framework for Competitive Debate") show case studies of two debate
    motions: one on the correlation between justice and interest and another on implementing
    a fat tax in developed countries. Each motion is shown in English and Chinese,
    with the English versions translated from Chinese using Claude-3.5-sonnet. These
    case studies demonstrate the application of Agent4Debate using different foundation
    models, including GPT-4o, Claude-3.5-sonnet, and Gemini-1.5-Pro. Due to space
    limitations, references for the case studies have been omitted.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 图[4](#Ax1.F4 "图4 ‣ 案例研究 ‣ 附录 ‣ LLM能否击败人类辩论？一个动态的多代理竞争辩论框架")至[7](#Ax1.F7 "图7
    ‣ 案例研究 ‣ 附录 ‣ LLM能否击败人类辩论？一个动态的多代理竞争辩论框架")展示了两个辩题的案例研究：一个是正义与利益之间的关系，另一个是发达国家是否应实施肥胖税。每个辩题都有英语和中文版本，英语版本由Claude-3.5-sonnet从中文翻译。这些案例研究展示了使用不同基础模型的Agent4Debate的应用，包括GPT-4o、Claude-3.5-sonnet和Gemini-1.5-Pro。由于空间限制，案例研究的参考文献已被省略。
- en: '![Refer to caption](img/c555b51c532184c2e5c9c0488db187a5.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/c555b51c532184c2e5c9c0488db187a5.png)'
- en: 'Figure 4: English (translated by Claude-3.5-sonnet from Chinese) case study
    of the debate motion ”Justice is nothing but interest. (Pro side) / Justice is
    nothing more than interest (Con side)”. Pro side is Agent4Debate (GPT-4o), Con
    side is Agent4Debate (Claude-3.5-sonnet).'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：英语（由Claude-3.5-sonnet从中文翻译）关于辩题“正义只是利益。 （正方）/ 正义不过是利益 （反方）”的案例研究。正方是Agent4Debate（GPT-4o），反方是Agent4Debate（Claude-3.5-sonnet）。
- en: '![Refer to caption](img/fd305d9534ce1ed44891018844b63788.png)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/fd305d9534ce1ed44891018844b63788.png)'
- en: 'Figure 5: Chinese case study of the debate motion ”Justice is nothing but interest.
    (Pro side) / Justice is nothing more than interest (Con side)”. Pro side is Agent4Debate
    (GPT-4o), Con side is Agent4Debate (Claude-3.5-sonnet).'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：关于辩题“正义只是利益。 （正方）/ 正义不过是利益 （反方）”的中文案例研究。正方是Agent4Debate（GPT-4o），反方是Agent4Debate（Claude-3.5-sonnet）。
- en: '![Refer to caption](img/9c746af89c6e5caa8929aec83adcd342.png)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/9c746af89c6e5caa8929aec83adcd342.png)'
- en: 'Figure 6: English (translated by Claude-3.5-sonnet from Chinese) case study
    of the debate motion ”Developed countries should (Pro side) / should not (Con
    side) impose a fat tax.”. Pro side is Agent4Debate (Gemini-1.5-Pro), Con side
    is Agent4Debate (Claude-3.5-sonnet).'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：英语（由Claude-3.5-sonnet从中文翻译）关于辩题“发达国家应该（正方）/ 不应该（反方）征收肥胖税”的案例研究。正方是Agent4Debate（Gemini-1.5-Pro），反方是Agent4Debate（Claude-3.5-sonnet）。
- en: '![Refer to caption](img/e899c6c175dff082236d03cc75f9db86.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/e899c6c175dff082236d03cc75f9db86.png)'
- en: 'Figure 7: Chinese case study of the debate motion ”Developed countries should
    (Pro side) / should not (Con side) impose a fat tax.”. Pro side is Agent4Debate
    (Gemini-1.5-Pro), Con side is Agent4Debate (Claude-3.5-sonnet).'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：关于辩题“发达国家应该（正方）/ 不应该（反方）征收肥胖税”的中文案例研究。正方是Agent4Debate（Gemini-1.5-Pro），反方是Agent4Debate（Claude-3.5-sonnet）。
