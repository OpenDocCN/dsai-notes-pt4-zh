- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:47:00'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:47:00
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent
    Simulation
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过基于LLM的多代理模拟规避社交媒体监管的语言演变
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2405.02858](https://ar5iv.labs.arxiv.org/html/2405.02858)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2405.02858](https://ar5iv.labs.arxiv.org/html/2405.02858)
- en: Jinyu Cai
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 蔡金玉
- en: Munan Li Waseda University
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 李沐南 早稻田大学
- en: bluelink@toki.waseda.jp Dalian Maritime University
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: bluelink@toki.waseda.jp 大连海事大学
- en: limunan@dlmu.edu.cn    Jialong Li
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: limunan@dlmu.edu.cn    李佳龙
- en: 'Chen-Shu Wang Corresponding Author: Jialong Li Waseda University'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 陈舒 王 通讯作者：李佳龙 早稻田大学
- en: lijialong@fuji.waseda.jp National Taipei University of Technology
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: lijialong@fuji.waseda.jp 国立台北科技大学
- en: wangcs@ntut.edu.tw    Mingyue Zhang
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: wangcs@ntut.edu.tw    张明月
- en: Kenji Tei Southwest University
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Kenji Tei 西南大学
- en: myzhangswu@swu.edu.cn Tokyo Institute of Technology
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: myzhangswu@swu.edu.cn 东京工业大学
- en: tei@c.titech.ac.jp
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: tei@c.titech.ac.jp
- en: Abstract
  id: totrans-16
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Social media platforms such as Twitter, Reddit, and Sina Weibo play a crucial
    role in global communication but often encounter strict regulations in geopolitically
    sensitive regions. This situation has prompted users to ingeniously modify their
    way of communicating, frequently resorting to coded language in these regulated
    social media environments. This shift in communication is not merely a strategy
    to counteract regulation, but a vivid manifestation of language evolution, demonstrating
    how language naturally evolves under societal and technological pressures. Studying
    the evolution of language in regulated social media contexts is of significant
    importance for ensuring freedom of speech, optimizing content moderation, and
    advancing linguistic research. This paper proposes a multi-agent simulation framework
    using Large Language Models (LLMs) to explore the evolution of user language in
    regulated social media environments. The framework employs LLM-driven agents:
    supervisory agent who enforce dialogue supervision and participant agents who
    evolve their language strategies while engaging in conversation, simulating the
    evolution of communication styles under strict regulations aimed at evading social
    media regulation. The study evaluates the framework’s effectiveness through a
    range of scenarios from abstract scenarios to real-world situations. Key findings
    indicate that LLMs are capable of simulating nuanced language dynamics and interactions
    in constrained settings, showing improvement in both evading supervision and information
    accuracy as evolution progresses. Furthermore, it was found that LLM agents adopt
    different strategies for different scenarios. The reproduction kit can be accessed
    at https://github.com/BlueLinkX/GA-MAS.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 像Twitter、Reddit和新浪微博这样的社交媒体平台在全球沟通中扮演了关键角色，但在地缘政治敏感地区经常遇到严格的监管。这种情况促使用户巧妙地修改他们的沟通方式，常常在这些受监管的社交媒体环境中使用编码语言。这种沟通的变化不仅仅是一种对抗监管的策略，而是语言演变的生动表现，展示了语言在社会和技术压力下如何自然演变。在受监管的社交媒体环境中研究语言演变对确保言论自由、优化内容审核和推进语言研究具有重要意义。本文提出了一个使用大型语言模型（LLMs）的多代理模拟框架，以探索受监管社交媒体环境中用户语言的演变。该框架使用LLM驱动的代理：监督代理执行对话监督，参与代理在交流过程中演变其语言策略，模拟在严格监管下的沟通风格演变。通过从抽象场景到现实世界情况的一系列情景来评估框架的有效性。关键发现表明，LLMs能够模拟受限环境中的细致语言动态和互动，随着演变的进展，在规避监督和信息准确性方面均有改善。此外，发现LLM代理对不同场景采用不同策略。重现工具包可以通过
    https://github.com/BlueLinkX/GA-MAS 访问。
- en: 'Index Terms:'
  id: totrans-18
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 索引词：
- en: Language Evolution, Multi-agent Simulation, Large Language Models, Social Media
    Regulation
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 语言演变、多代理模拟、大型语言模型、社交媒体监管
- en: I Introduction
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I 引言
- en: In the modern digital era, social networks like X (Twitter), Reddit, and Facebook
    have become pivotal in shaping human interaction, primarily through their ability
    to facilitate vast connectivity and instantaneous information exchange. Yet, in
    regions with heightened geopolitical or socio-political sensitivities, users often
    navigate complex user regulations. Their online expressions can lead to severe
    consequences, including censorship or account suspension, as documented in various
    news [[1](#bib.bib1), [2](#bib.bib2)]. While intended to curb misinformation and
    maintain social harmony, these regulations significantly constrain user expression.
    In response to these regulations, users on social networks have adapted by adopting
    a phenomenon known as “coded language.” [[3](#bib.bib3)] In linguistics, Coded
    Language typically refers to expressing information in a concealed or indirect
    manner. On social media platforms, this often manifests as the use of metaphors,
    slang, and creative wordplay.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在现代数字时代，像X（Twitter）、Reddit和Facebook这样的社交网络在塑造人类互动方面变得至关重要，主要通过它们促进广泛连接和即时信息交换的能力。然而，在地缘政治或社会政治敏感性较高的地区，用户往往需要应对复杂的用户规定。他们的在线表达可能导致严重的后果，包括审查或账户暂停，正如各种新闻[[1](#bib.bib1),
    [2](#bib.bib2)]所记录的。虽然这些规定旨在遏制虚假信息和维护社会和谐，但它们显著限制了用户的表达。作为对这些规定的回应，社交网络上的用户已经通过采用一种被称为“编码语言”的现象进行了适应[[3](#bib.bib3)]。在语言学中，编码语言通常指以隐蔽或间接的方式表达信息。在社交媒体平台上，这通常表现为使用隐喻、俚语和创造性的文字游戏。
- en: This adaptation is not merely a circumvention strategy but a vivid example of
    “language evolution” in a digital context. In linguistics, language evolution
    refers to the progression and adaptation of languages over time, shaped by societal,
    cultural, and technological influences. Specifically, in social networks, this
    language evolution is demonstrated as users constantly adjust their communication
    styles to test whether they have circumvented oversight. Depending on the level
    of regulatory pressure and the nature of the audience, users engage in a strategic
    play with the platform. From indirect descriptions to the creation of new slang,
    users ultimately develop coded languages of varying degrees of abstraction.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这种适应不仅仅是一种规避策略，而是在数字环境中“语言演变”的生动例子。在语言学中，语言演变指的是语言随时间的进步和适应，这种变化受到社会、文化和技术因素的影响。具体而言，在社交网络中，这种语言演变表现为用户不断调整他们的沟通风格，以测试他们是否已规避了监督。根据监管压力的程度和受众的性质，用户在平台上进行战略性操作。从间接描述到新俚语的创造，用户最终发展出各种程度的编码语言。
- en: This dynamic shift in communication methods offers deep insights from a sociological
    perspective, reflecting how societal norms and technological advancements shape
    language. For platforms and users alike, understanding this evolution is crucial
    for developing balanced content moderation policies and navigating regulated digital
    environments. For social media platforms and their users, grasping this concept
    is equally vital. Platforms need this knowledge to adapt to changing user behaviors,
    to create balanced content moderation policies, and to identify and counteract
    harmful or illegal activities. For users, an awareness of how language evolves
    is vital in navigating the intricacies of regulated digital environments. It helps
    in maintaining free speech and in developing communication strategies that are
    both effective and meaningful in fostering enhanced interactions.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这种沟通方式的动态变化从社会学角度提供了深刻的见解，反映了社会规范和技术进步如何塑造语言。对于平台和用户来说，理解这种演变对制定平衡的内容审核政策和在受监管的数字环境中导航至关重要。对于社交媒体平台及其用户来说，掌握这一概念同样至关重要。平台需要这些知识以适应用户行为的变化，制定平衡的内容审核政策，并识别和应对有害或非法活动。对于用户来说，了解语言如何演变在应对受监管的数字环境的复杂性时至关重要。这有助于维护言论自由，并制定既有效又有意义的沟通策略，以促进更好的互动。
- en: The emergence of Large Language Models (LLMs) like ChatGPT and Bard, represents
    a significant leap in Artificial intelligence (AI). These LLMs have demonstrated
    strong capabilities in (i) understanding intricate dialogues [[4](#bib.bib4)],
    generating coherent texts [[5](#bib.bib5)], and aligning to human ethical and
    value standards [[6](#bib.bib6), [7](#bib.bib7), [8](#bib.bib8)]. These capabilities
    position LLMs as ideal tools to simulate human’s decision-making and language
    representation, providing new potential in sociology. For instance, [[9](#bib.bib9)]
    investigated the ability of LLMs to comprehend the implicit information in social
    language. The study by [[10](#bib.bib10)] demonstrated the efficiency of LLMs
    in understanding and generating content that mimics the style of specific social
    network users. Furthermore, research by [[11](#bib.bib11), [12](#bib.bib12), [13](#bib.bib13)]
    integrated LLMs with Multi-Agent Systems to simulate micro-social networks, observing
    agent behaviors and strategies that reflect human interactions. Despite the extensive
    application of LLMs in understanding human intension and simulating social media
    dynamics, the use of LLMs in studying the specific phenomenon of language evolution
    under regulatory constraints has not been thoroughly explored. As mentioned above,
    such simulation could not only preempt criminal activities on social media but
    also provide technical support to uphold freedom of speech.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）的出现，如ChatGPT和Bard，标志着人工智能（AI）的重大突破。这些LLMs在（i）理解复杂对话[[4](#bib.bib4)]、生成连贯文本[[5](#bib.bib5)]以及对人类伦理和价值标准的对齐[[6](#bib.bib6)、[7](#bib.bib7)、[8](#bib.bib8)]方面表现出强大的能力。这些能力使LLMs成为模拟人类决策和语言表达的理想工具，为社会学提供了新的潜力。例如，[[9](#bib.bib9)]研究了LLMs理解社会语言中隐含信息的能力。[[10](#bib.bib10)]的研究展示了LLMs在理解和生成模仿特定社交网络用户风格的内容方面的效率。此外，[[11](#bib.bib11)、[12](#bib.bib12)、[13](#bib.bib13)]的研究将LLMs与多智能体系统结合，模拟微观社交网络，观察反映人类互动的代理行为和策略。尽管LLMs在理解人类意图和模拟社交媒体动态方面得到了广泛应用，但LLMs在研究监管约束下的语言演变特定现象中的应用尚未得到充分探讨。如上所述，这种模拟不仅可以预防社交媒体上的犯罪活动，还可以为维护言论自由提供技术支持。
- en: 'Addressing this gap, our research employs LLMs to simulate the nuanced interplay
    between language evolution and regulatory enforcement on social media. We introduce
    a simulation framework with two types of LLM-driven agents: (i) participant agents,
    who adapt their language to communicate concept ’B’ under restrictions, and (ii)
    supervisory agent, who enforce guidelines and react to these language evolutions.
    Our approach effectively simulates the dynamics model between both sides in language
    evolution, which allows us to observe the tension and adaptability inherent in
    language evolution in a controlled, simulated environment. To assess the framework’s
    effectiveness, we designed three diverse scenarios: “Guess the Number Game”, “Illegal
    Pet Trading”, and “Nuclear Wastewater Discharge”. These scenarios vary from abstract
    concepts to situations closely resembling real-world events, thereby progressively
    testing the framework from theoretical to practical applications.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 针对这一空白，我们的研究使用大型语言模型（LLMs）模拟语言演变与社交媒体监管之间的微妙互动。我们引入了一个包含两种类型LLM驱动代理的模拟框架：（i）参与者代理，调整其语言以在限制下沟通概念‘B’，以及（ii）监督代理，执行指导方针并对这些语言演变作出反应。我们的方法有效地模拟了语言演变中双方的动态模型，使我们能够在受控的模拟环境中观察语言演变固有的紧张性和适应性。为了评估框架的有效性，我们设计了三个不同的情景：“猜数字游戏”、“非法宠物交易”和“核废水排放”。这些情景从抽象概念到与现实世界事件紧密相关的情况，逐步测试框架从理论到实践的应用。
- en: 'The main contributions of this study are:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究的主要贡献包括：
- en: •
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We introduce a multi-agent simulation framework utilizing LLMs to simulate human
    linguistic behaviors in regulated social media environments. This framework offers
    a unique approach to studying language evolution within the confines of regulatory
    constraints.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们引入了一个多智能体模拟框架，利用LLMs在受监管的社交媒体环境中模拟人类语言行为。该框架提供了一种独特的方法来研究在监管约束下的语言演变。
- en: •
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We conducted an extensive evaluation of LLMs in simulating language evolution
    and interaction efficacy in regulated social media settings. Through experiments
    on three distinct scenarios, we not only captured the process of language strategy
    evolution but also uncovered the varied evolutionary trajectories that LLMs follow
    under different conditions.
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们对LLM在模拟语言演化和在受限社交媒体环境中互动效果进行了广泛评估。通过对三种不同场景的实验，我们不仅捕捉了语言策略演化的过程，还揭示了LLM在不同条件下所遵循的多样化演化轨迹。
- en: •
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'The experiment reproduction kit, including the proposed simulation framework
    along with the results of our experiments, are made publicly accessible as open-source
    assets; The anonymized artifact can be accessed at: https://github.com/BlueLinkX/GA-MAS.'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 实验复现工具包，包括提出的模拟框架及我们的实验结果，已作为开源资产公开提供；匿名化的文档可以在以下网址访问：https://github.com/BlueLinkX/GA-MAS。
- en: 'The rest of this paper is organized as follows: Section [II](#S2 "II Background
    and Related Work ‣ Language Evolution for Evading Social Media Regulation via
    LLM-based Multi-agent Simulation") provides essential background information and
    explores related work. Section [III](#S3 "III Framework Design ‣ Language Evolution
    for Evading Social Media Regulation via LLM-based Multi-agent Simulation") is
    dedicated to presenting our proposed simulation framework. Section [IV](#S4 "IV
    Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based
    Multi-agent Simulation") details the experiment setting, presents results, and
    discusses a discussion. Finally, Section [V](#S5 "V Conclusion and Future Work
    ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent
    Simulation") concludes the paper and offers an outlook on potential future work.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的其余部分组织如下：第[II](#S2 "II 背景与相关工作 ‣ 基于LLM的多智能体模拟逃避社交媒体监管的语言演化")节提供了必要的背景信息并探讨了相关工作。第[III](#S3
    "III 框架设计 ‣ 基于LLM的多智能体模拟逃避社交媒体监管的语言演化")节专门介绍了我们提出的模拟框架。第[IV](#S4 "IV 评估 ‣ 基于LLM的多智能体模拟逃避社交媒体监管的语言演化")节详细说明了实验设置，呈现了结果，并进行讨论。最后，第[V](#S5
    "V 结论与未来工作 ‣ 基于LLM的多智能体模拟逃避社交媒体监管的语言演化")节总结了论文并展望了潜在的未来工作。
- en: II Background and Related Work
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 背景与相关工作
- en: This section offers an extensive background and overview of related work in
    areas relevant to this study, starting with foundational information on LLMs,
    then exploring studies in slang detection and identification as they relate to
    language evolution, and concluding with a discussion on recent research applying
    LLMs to evolutionary game theory and social simulations.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提供了与本研究相关领域的广泛背景和概述，首先介绍了LLM的基础信息，然后探讨了与语言演化相关的俚语检测和识别研究，最后讨论了近期将LLM应用于进化博弈理论和社会模拟的研究。
- en: II-A Large Language Models
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-A 大型语言模型
- en: Large Language Models like the GPT series [[14](#bib.bib14), [15](#bib.bib15)],
    LLaMA series [[16](#bib.bib16), [17](#bib.bib17)], PaLM series[[18](#bib.bib18),
    [19](#bib.bib19)], GLM [[20](#bib.bib20)]and Bard [[21](#bib.bib21)] represent
    a significant advancement in the field of natural language processing. Fundamentally,
    these models are based on the Transformer [[22](#bib.bib22)] architecture, a type
    of neural network that excels in processing sequential data through self-attention
    mechanisms. This architecture enables LLMs to understand and predict linguistic
    patterns effectively. They are trained on extensive text datasets, allowing them
    to grasp a wide range of linguistic nuances from syntax to contextual meaning.
    These models exhibit remarkable zero-shot learning abilities, enabling them to
    perform tasks they were not explicitly trained for, like understanding and generating
    content in new contexts or languages [[23](#bib.bib23), [24](#bib.bib24), [25](#bib.bib25),
    [4](#bib.bib4), [5](#bib.bib5)]. A critical aspect of their training involves
    Reinforcement Learning from Human Feedback [[26](#bib.bib26)] (RLHF), where human
    reviewers guide the model to produce more accurate, contextually relevant, and
    ethically aligned responses. This method not only enhances the model’s language
    generation capabilities but also aligns its outputs with human values and ethical
    standards, making them more suitable for diverse, real-world applications.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 像 GPT 系列[[14](#bib.bib14)、[15](#bib.bib15)]、LLaMA 系列[[16](#bib.bib16)、[17](#bib.bib17)]、PaLM
    系列[[18](#bib.bib18)、[19](#bib.bib19)]、GLM[[20](#bib.bib20)] 和 Bard[[21](#bib.bib21)]
    这样的语言模型代表了自然语言处理领域的一项重大进展。这些模型根本上是基于 Transformer[[22](#bib.bib22)] 架构，这是一种通过自注意力机制擅长处理序列数据的神经网络。该架构使得大语言模型能够有效地理解和预测语言模式。它们在大量文本数据集上进行训练，使其能够掌握从句法到上下文意义的广泛语言细微差别。这些模型展示了显著的零样本学习能力，使其能够执行未经过明确训练的任务，例如在新上下文或语言中理解和生成内容[[23](#bib.bib23)、[24](#bib.bib24)、[25](#bib.bib25)、[4](#bib.bib4)、[5](#bib.bib5)]。它们训练的一个关键方面是通过人类反馈的强化学习[[26](#bib.bib26)]（RLHF），在此过程中，人类评审员指导模型生成更准确、更具上下文相关性且符合伦理的回答。这种方法不仅提高了模型的语言生成能力，还使其输出与人类价值观和伦理标准一致，从而使其更适合多样的实际应用。
- en: II-B Slang Detection and Identification
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-B 俚语检测与识别
- en: In the field of Natural Language Processing (NLP), the evolution of language
    has always been a subject of significant interest. Existing studies have primarily
    focused on utilizing various machine learning techniques to recognize informal
    expressions within text [[27](#bib.bib27)]. These methods often include rule-based
    systems, statistical models, and early machine learning technologies. For instance, [[28](#bib.bib28)]
    has employed predefined slang dictionaries and heuristic rules to identify and
    categorize informal language, proving effective on specific datasets but generally
    lacking the flexibility to adapt to emerging expressions and changing contexts.
    On the other hand, explorations have been made into using statistical models,
    such as Naive Bayes classifiers and Support Vector Machines (SVMs)[[29](#bib.bib29)],
    for the automatic detection of slang in text. These approaches rely on extensive
    annotated data but still face limitations when dealing with newly emerged slang
    or evolving forms of language.  [[30](#bib.bib30)] views the generation of slang
    as a problem of selecting vocabulary to represent new concepts or referents, categorizing
    them accordingly. Subsequently, it predicts slang through the use of various cognitive
    categorization models. The study finds that these models greatly surpass random
    guessing in their ability to predict slang word choices.  [[31](#bib.bib31)] proposed
    a Semantically Informed Slang Interpretation (SSI) framework, applying cognitive
    theory perspectives to the interpretation and prediction of slang. This approach
    not only considers contextual information but also includes the understanding
    of semantic changes and cognitive processes in the generation of slang. It is
    noteworthy that these traditional research methods have mainly focused on detecting
    or predicting existing slang and keywords, rather than generating slang expressions.
    This stands in stark contrast to the research focus of this paper.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在自然语言处理（NLP）领域，语言的演变一直是一个重要的研究课题。现有研究主要集中在利用各种机器学习技术识别文本中的非正式表达[[27](#bib.bib27)]。这些方法通常包括基于规则的系统、统计模型和早期的机器学习技术。例如，[[28](#bib.bib28)]
    采用预定义的俚语词典和启发式规则来识别和分类非正式语言，在特定数据集上表现有效，但通常缺乏适应新兴表达和变化语境的灵活性。另一方面，也有探索使用统计模型，如朴素贝叶斯分类器和支持向量机（SVMs）[[29](#bib.bib29)]，来自动检测文本中的俚语。这些方法依赖于大量标注数据，但在处理新出现的俚语或不断变化的语言形式时仍然面临限制。[[30](#bib.bib30)]
    将俚语的生成视为选择词汇来代表新概念或指代物的问题，并据此对其进行分类。随后，它通过使用各种认知分类模型来预测俚语。研究发现，这些模型在预测俚语词汇选择的能力上大大超过了随机猜测。[[31](#bib.bib31)]
    提出了一个语义信息化俚语解释（SSI）框架，应用认知理论视角来解释和预测俚语。这种方法不仅考虑了上下文信息，还包括对俚语生成中语义变化和认知过程的理解。值得注意的是，这些传统研究方法主要关注于检测或预测现有俚语和关键词，而不是生成俚语表达。这与本文的研究重点形成了鲜明的对比。
- en: II-C Evolutionary Game and Social Simulation with LLMs
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-C 演化博弈与社交模拟中的大语言模型（LLMs）
- en: Merging evolutionary game theory with LLMs has unlocked innovative pathways
    for simulating complex game dynamics, extending beyond simple dialogue generation
    to the development and progression of game strategies. LLMs are employed to engage
    and refine strategic play within game-theoretical frameworks, as demonstrated
    by [[32](#bib.bib32)], which delves into the application of LLMs in negotiation-based
    games. This study underscores the ability of LLMs to advance their negotiation
    skills through continuous self-play and feedback loops with AI. LLMs also show
    proficiency in social deduction games such as Werewolf, as explored by [[33](#bib.bib33)].
    In this context, a specialized framework leverages historical communication patterns
    to enhance LLM performance, exemplifying how LLMs can evolve intricate game strategies
    autonomously. Building on this, [[34](#bib.bib34)] combines reinforcement learning
    with LLMs, utilizing LLMs to output action spaces and employing reinforcement
    learning models for final decision-making. This enables the agents to maintain
    competitiveness while outputting reasonable actions, even outperforming human
    adversaries in games like Werewolf.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 将进化博弈论与LLMs结合，开启了模拟复杂博弈动态的新途径，这不仅限于简单的对话生成，还包括游戏策略的发展和进展。LLMs被用于在博弈理论框架内进行战略游戏的参与和优化，正如[[32](#bib.bib32)]所示，该研究探讨了LLMs在基于谈判的游戏中的应用。该研究强调了LLMs通过持续的自我对弈和AI反馈回路来提升谈判技能的能力。LLMs在社交推理游戏如狼人杀中的表现也显示出了其熟练程度，正如[[33](#bib.bib33)]所探讨的那样。在这种情况下，一个专门的框架利用历史沟通模式来增强LLM的表现，展示了LLMs如何自主演化复杂的游戏策略。在此基础上，[[34](#bib.bib34)]将强化学习与LLMs结合，利用LLMs输出动作空间，并运用强化学习模型进行最终决策。这使得代理在输出合理行动的同时保持竞争力，甚至在狼人杀等游戏中超越人类对手。
- en: This growing trend of employing LLMs in diverse simulation scenarios extends
    beyond game theory into broader aspects of social interactions and historical
    analysis. LLMs have proven to be versatile tools in simulating social dynamics
    and historical events, offering insights into complex human behaviors and societal
    patterns.  [[12](#bib.bib12)] introduces a Wild West-inspired environment inhabited
    by LLM agents that display a wide array of behaviors without relying on external
    real-world data. Simultaneously, S3 [[13](#bib.bib13)] mirrors user interactions
    within social networks, crafting an authentic simulation space through the incorporation
    of user demographic prediction. The influence of LLM-driven social robots on digital
    communities is thoroughly examined in [[35](#bib.bib35)], which identifies distinct
    macro-level behavioral trends. Furthermore, [[11](#bib.bib11)] employs LLM-based
    multi-agent frameworks to recreate historic military confrontations, offering
    a window into the decision-making processes and strategic maneuvers that have
    directed significant historical conflicts. This avenue of research accentuates
    the utility of LLMs in computational historiography, providing a deeper comprehension
    of historical events and their relevance to contemporary and future societal trajectories.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这种在不同模拟场景中使用LLMs的增长趋势已经超越了博弈论，涉及到社会互动和历史分析的更广泛方面。LLMs被证明是模拟社会动态和历史事件的多功能工具，为复杂的人类行为和社会模式提供了洞察。[[12](#bib.bib12)]介绍了一个受西部拓荒时代启发的环境，其中LLM代理展示了各种各样的行为，而不依赖于外部的现实世界数据。同时，S3
    [[13](#bib.bib13)]反映了社交网络中的用户互动，通过用户人口预测来创建一个真实的模拟空间。LLM驱动的社交机器人对数字社区的影响在[[35](#bib.bib35)]中得到了深入研究，该研究确定了明显的宏观层面行为趋势。此外，[[11](#bib.bib11)]利用基于LLM的多智能体框架来重现历史军事冲突，为理解决策过程和战略动作提供了一个窗口，这些战略曾主导了重要的历史冲突。这一研究方向突显了LLMs在计算历史学中的实用性，提供了对历史事件及其对当代和未来社会轨迹的相关性更深入的理解。
- en: III Framework Design
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III 框架设计
- en: '![Refer to caption](img/9f8a421af516aaaad154c4cbdaa7d268.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/9f8a421af516aaaad154c4cbdaa7d268.png)'
- en: 'Figure 1: Overview of Language Evolution Simulation System. The system comprises
    two main types of agents: the Participant and the Supervisor. The Participant
    agent uses a Planning Module to create a communication plan based on background
    information, regulations, and guidance. This plan is then executed in the Dialogue
    Module, where the LLM crafts dialogue content to discreetly convey specific information
    while evading detection by the Supervisor. The Memory Module retains dialogue
    history and violation records, providing a reference for the LLM to maintain dialogue
    consistency and learn from past mistakes. The Reflection Module, triggered at
    the start and end of dialogue cycles, analyzes the dialogue and violation logs
    to formulate new regulations or guidance for improving future communications.
    The Supervisor evaluates dialogues for compliance with set rules. This system
    dynamically refines its communication approach through continuous feedback and
    self-improvement mechanisms. The examples shown utilize a Guessing Numbers Scenario.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：语言演变模拟系统概述。该系统包括两种主要类型的代理：参与者和监督者。参与者代理使用规划模块，根据背景信息、规定和指导制定沟通计划。然后在对话模块中执行该计划，LLM
    生成对话内容，以隐秘方式传达特定信息，同时避开监督者的检测。记忆模块保留对话历史和违规记录，为 LLM 提供参考，以保持对话一致性并从过去的错误中学习。反思模块在对话周期开始和结束时触发，分析对话和违规日志，以制定改进未来沟通的新规定或指导。监督者评估对话是否符合设定的规则。该系统通过持续反馈和自我改进机制动态优化其沟通方式。所示示例利用了猜数字场景。
- en: III-A Overview
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-A 概述
- en: 'In this section, we offer a detailed overview of our system, as depicted in
    Figure [1](#S3.F1 "Figure 1 ‣ III Framework Design ‣ Language Evolution for Evading
    Social Media Regulation via LLM-based Multi-agent Simulation"). This figure provides
    a visual representation of our framework, highlighting its key components and
    their interrelationships. Our system is primarily composed of two types of agents:
    the Supervisor, tasked with enforcing established guidelines, and the Participant,
    whose goal is to convey specific, human-defined information discreetly. Participants
    must dynamically refine their communication approaches, drawing from past dialogues,
    to transmit information effectively while remaining undetected. In the entire
    system, the actions of both participants and the supervisor are driven by the
    LLM. Initially, we establish the foundational information for each agent, including
    role setting, background knowledge, and primary tasks. Subsequently, the participant
    agents engage in dialogues with each other. After each dialogue turn, the supervisory
    agent reviews the conversation to determine if any pre-set rules have been violated.
    In cases of rule violation, the supervisor interrupts the dialogue, providing
    feedback about the infringing text and the rationale behind it. Throughout this
    process, the dialogues between participants, along with the supervisory feedback
    on violations, are recorded separately in the “Dialogue History” and “Violation
    Log.”'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们提供了对系统的详细概述，如图 [1](#S3.F1 "图 1 ‣ III 框架设计 ‣ 通过基于 LLM 的多代理模拟逃避社交媒体监管的语言演变")
    所示。该图提供了我们框架的可视化表示，突出显示了其关键组件及其相互关系。我们的系统主要由两种类型的代理组成：监督者，负责执行既定的指导方针，以及参与者，其目标是隐秘地传达特定的、人工定义的信息。参与者必须动态地优化其沟通方式，从过去的对话中汲取经验，以有效地传达信息，同时保持隐蔽。在整个系统中，参与者和监督者的行为都由
    LLM 驱动。最初，我们为每个代理建立基础信息，包括角色设置、背景知识和主要任务。随后，参与者代理相互进行对话。在每次对话轮次后，监督代理会审查对话，以确定是否违反了任何预设规则。在违规的情况下，监督者会中断对话，提供关于违规文本及其理由的反馈。在此过程中，参与者之间的对话以及对违规行为的监督反馈会分别记录在“对话历史”和“违规日志”中。
- en: Before new dialogues, participant agents use the Reflection Module to develop
    or refine “Regulations” from the Violation Log, guiding their dialogue creation.
    Successful dialogues without detection proceed to an interview phase for perspective
    assessment. The Reflection Module then reevaluates these insights, generating
    or enhancing “Guidance” for future dialogues. The Planning Module activates for
    more direct dialogue content guidance whenever Regulations or Guidance are updated.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在新对话之前，参与代理使用反思模块从违规记录中制定或完善“规章制度”，指导他们的对话创建。成功的对话在没有检测的情况下会进入采访阶段进行观点评估。然后，反思模块重新评估这些见解，为未来的对话生成或增强“指导”。计划模块会在规章制度或指导更新时激活，以提供更直接的对话内容指导。
- en: III-B Participant Agents
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-B 参与代理
- en: 'Participant agents in our system are composed of several modules, including
    Memory, Dialogue, Reflection, and Summary, all powered by LLMs. To increase the
    system’s flexibility and minimize redundancy, we’ve structured the prompts for
    each module around seven primary elements: “Background Information,” “Dialogue
    History,” “Violation Log,” “Regulations,” “Guidance,” “Plan,” and “Instructions.”
    “Background Information” delivers essential data and objectives pertinent to the
    experimental setup. The Memory module manages “Dialogue History” and “Violation
    Log,” which respectively track participant dialogues and instances of detection
    by the supervisor. Overcoming the challenge of effectively communicating regulated
    topics under supervision tests the linguistic prowess of LLMs. To address this,
    we’ve integrated “Regulations,” “Guidance,” and “Plan” as crucial components,
    formulated by the Reflection and Summary modules, to assist agents in stealthily
    disseminating information. “Instructions” set specific tasks for the LLM within
    each module.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们系统中的参与代理由多个模块组成，包括内存、对话、反思和总结，均由LLM提供支持。为了提高系统的灵活性并减少冗余，我们将每个模块的提示结构围绕七个主要元素：“背景信息”、“对话历史”、“违规记录”、“规章制度”、“指导”、“计划”和“指令”。“背景信息”提供与实验设置相关的基本数据和目标。内存模块管理“对话历史”和“违规记录”，分别跟踪参与者对话和被监督者检测到的情况。有效沟通受监管话题的挑战考验了LLM的语言能力。为了解决这个问题，我们将“规章制度”、“指导”和“计划”作为关键组件，由反思和总结模块制定，以帮助代理秘密传播信息。“指令”在每个模块内设定LLM的具体任务。
- en: III-B1 Dialogue Module
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B1 对话模块
- en: This module generates dialogue content based on short-term dialogue records.
    Extracting historical dialogue information from the Memory module, it inputs this
    into the LLM to understand and construct sentences that evade supervision while
    effectively transmitting information. In the Dialogue module’s prompt, “Background
    Information” provides necessary background, while “Plan” guide the achievement
    of objectives. “Instructions” offer LLM-specific execution directives.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 该模块根据短期对话记录生成对话内容。通过从内存模块提取历史对话信息，将其输入到LLM中，以理解和构造逃避监督的句子，同时有效地传递信息。在对话模块的提示中，“背景信息”提供必要的背景，而“计划”指导目标的实现。“指令”则为LLM提供具体的执行指令。
- en: III-B2 Memory Module
  id: totrans-53
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B2 内存模块
- en: 'The Memory module stores all dialogue history and records detected by the supervisor,
    Specifically, it comprises three parts: background Information, dialogue history,
    and violation records. The background information includes role settings, experimental
    background knowledge, and global objectives. “Dialogue History” and “Violation
    Log” save dialogue records and past detections by the Supervisor, respectively.
    “Background information” and “Dialogue History” serves as short-term[[36](#bib.bib36)]
    memory, containing only the current round’s dialogue. “Violation Log,” as long-term
    memory, records violations from each evolutionary round. When dialogues are detected
    by the Supervisor, relevant feedback is added to the “Violation Log,” triggering
    a new evolutionary process.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 内存模块存储所有对话历史和监督者检测到的记录。具体来说，它包括三个部分：背景信息、对话历史和违规记录。背景信息包括角色设置、实验背景知识和全球目标。“对话历史”和“违规记录”分别保存对话记录和监督者过去的检测记录。“背景信息”和“对话历史”作为短期[[36](#bib.bib36)]记忆，只包含当前回合的对话。“违规记录”作为长期记忆，记录每一轮演变中的违规行为。当对话被监督者检测到时，相关反馈会添加到“违规记录”中，触发新的演变过程。
- en: Excessive memory information can potentially distract the LLM and lead to a
    decline in performance. Hence, the “Dialogue History” and “Violation Log” in the
    memory module are regularly maintained. This involves inputting earlier memories
    and employing the LLM to distill crucial information from these records, effectively
    compressing and consolidating them. This approach not only preserves essential
    historical data but also optimizes the LLM’s performance, striking a balance between
    comprehensive memory retention and efficient processing.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 过多的记忆信息可能会分散LLM的注意力，导致性能下降。因此，记忆模块中的“对话历史”和“违规日志”会定期维护。这涉及输入早期记忆并利用LLM从这些记录中提炼出关键的信息，从而有效地压缩和整合。这种方法不仅保留了重要的历史数据，还优化了LLM的性能，平衡了全面的记忆保持和高效的处理。
- en: III-B3 Reflection Module
  id: totrans-56
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B3 反思模块
- en: The Reflection Module is activated at the beginning and end of each dialogue
    evolution cycle, with its core purpose being the generation of improved strategies
    based on historical records. At the start of an evolution cycle, the module utilizes
    the “Violation Log” as its input to analyze past failures and, based on these
    insights, formulates “Regulations” aimed at effectively circumventing supervision
    in future dialogues. At the cycle’s end, the Reflection Module is reactivated,
    turning its focus to the “Dialogue History”. This step is crucial for reviewing
    and assessing the dialogue content to verify the successful completion of the
    primary task of information conveyance. If the module identifies deficiencies
    in information delivery or objectives not met, it then proposes “Guidance” for
    subsequent dialogues, thereby enhancing the agent’s capacity for information transmission.
    This design establishes the Reflection Module as a key self-evaluation and strategy
    adjustment mechanism within the system, ensuring continuous improvement and adaptability
    of the dialogue system in a dynamically changing regulatory environment.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 反思模块在每个对话演变周期的开始和结束时都会激活，其核心目的是基于历史记录生成改进策略。在演变周期开始时，模块利用“违规日志”作为输入来分析过去的失败，并根据这些洞察制定旨在有效规避监督的“规定”。在周期结束时，反思模块会重新激活，将其关注点转向“对话历史”。这一步骤对于回顾和评估对话内容，以验证信息传递主要任务的成功完成至关重要。如果模块发现信息传递中的不足或目标未达成，它将提出“指导”用于后续对话，从而提升代理的信息传递能力。这一设计将反思模块确立为系统内关键的自我评估和策略调整机制，确保对话系统在动态变化的监管环境中持续改进和适应。
- en: To fulfill these requirements, the LLM must possess a high degree of reasoning
    ability, capable of inferring the supervisor’s criteria from failure records and
    identifying communication deficiencies from dialogue history, thereby formulating
    appropriate strategies and improvement suggestions. To enhance the LLM’s reasoning
    capabilities, the design of the prompt incorporates the effective and cost-efficient
    Chain of Thought [[37](#bib.bib37)] (COT) method as the guiding principle for
    the reflection and planning modules. This approach guides the LLM in conducting
    criterion analysis and, in combination with the main task, generating “Regulations”
    and “Guidance”.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了满足这些要求，LLM必须具备较高的推理能力，能够从失败记录中推断出监督者的标准，并从对话历史中识别沟通缺陷，从而制定出适当的策略和改进建议。为了提升LLM的推理能力，提示的设计将有效且成本效益高的思维链方法[[37](#bib.bib37)]作为反思和规划模块的指导原则。这种方法引导LLM进行标准分析，并结合主要任务生成“规定”和“指导”。
- en: 'Specifically, within the Reflection Module, the prompt includes “Background
    Information,” “Dialogue History” or “Violation Log,” “Old Guidance” or ”Old Regulations,”
    and “Instructions.” The “Instructions” first prompt the LLM to engage in preliminary
    thinking, for instance: “Please infer what kind of guidelines the Supervisor is
    following from the Violation Log.” This is followed by a conclusion question:
    “Based on this information, update existing regulations to better avoid supervision.”
    The content returned by the LLM will serve as the new regulation for the next
    round of dialogue.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在反思模块中，提示包括“背景信息”、“对话历史”或“违规日志”、“旧指导”或“旧规定”和“指令”。“指令”首先促使LLM进行初步思考，例如：“请推断出监督者在‘违规日志’中遵循了什么样的指导方针。”接着是一个结论性问题：“根据这些信息，更新现有规定以更好地避免监督。”LLM返回的内容将作为下一轮对话的新规定。
- en: III-B4 Planning Module
  id: totrans-60
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B4 规划模块
- en: The facet of “Regulations” is centered on devising strategies that sidestep
    supervision, whereas “Guidance” is all about the effective relay of information.
    Although both are pivotal in managing dialogues, they might clash in certain supervised
    scenarios, thereby impacting the language’s overall proficiency and efficiency [[38](#bib.bib38)].
    In light of this, integrating the Planning Module becomes indispensable.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: “规定”的方面集中于制定避开监督的策略，而“指导”则专注于有效的信息传递。虽然两者在管理对话中都至关重要，但它们可能在某些监督场景中发生冲突，从而影响语言的整体熟练度和效率[[38](#bib.bib38)]。鉴于此，整合规划模块变得不可或缺。
- en: Within the Planning Module, the prompt includes “Background Information,” “Regulations,”
    “Guidance,” and “Instructions”. In the “Instructions,” we mandate the LLM to use
    “Regulations” as a baseline. Building upon this foundation, it is guided by the
    “Guidance” to formulate a tangible and actionable “Plan.” This approach ensures
    the delivery of clear and effective strategies for future dialogues.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在规划模块中，提示包括“背景信息”、“规定”、“指导”和“指令”。在“指令”中，我们要求大语言模型（LLM）以“规定”为基准。在此基础上，它在“指导”的引导下制定一个切实可行的“计划”。这种方法确保了未来对话的策略明确有效。
- en: III-C Supervisory Agent
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-C 监督代理
- en: 'The role of the Supervisor is designed as an abstract concept, primarily to
    simulate social network supervision. This design reflects an important observation:
    in social networks, content supervision often focuses on direct judgment of specific
    information, rarely influenced by extensive or lengthy contextual information.
    Thus, unlike participants with more complex background information, the Supervisor’s
    function and role are simplified here to highlight its behavior characteristics
    in actual social network supervision. The Supervisor’s task mainly focuses on
    assessing whether content complies with certain standards or rules, a relatively
    straightforward and well-defined process.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 监督者的角色被设计为一个抽象概念，主要用于模拟社交网络监督。这一设计反映了一个重要的观察：在社交网络中，内容监督通常集中在对具体信息的直接判断上，较少受到广泛或冗长的上下文信息的影响。因此，与背景信息更复杂的参与者不同，监督者的功能和角色在这里被简化，以突出其在实际社交网络监督中的行为特征。监督者的任务主要集中在评估内容是否符合某些标准或规则，这是一个相对简单且明确的过程。
- en: 'To mimic the existing review mechanisms of platforms, which typically combine
    keyword filters with “human” oversight, the Supervisor initially employs keyword
    filtering for a preliminary review of the dialogue content. Content that passes
    this initial screening is then subjected to further evaluation by the LLM. The
    prompt for the Supervisor includes just two components: “Dialogue History” and
    “Instructions.” “Dialogue History“ comprises the content of the dialogue exchanged
    between participant agents in that particular round, and “Instructions“ outline
    the criteria and guidelines that the supervisory agent must adhere to when conducting
    dialogue monitoring.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟现有平台的审查机制，这些机制通常结合关键词过滤与“人工”监督，监督者最初使用关键词过滤对对话内容进行初步审查。通过这一初步筛选的内容随后由LLM进行进一步评估。监督者的提示包含两个组件：“对话历史”和“指令”。“对话历史”包括该轮中参与代理之间交换的对话内容，而“指令”则概述了监督代理在进行对话监控时必须遵循的标准和指导方针。
- en: III-D Similarities and Differences between Our Framework and Evolutionary Computing
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-D 我们的框架与进化计算的相似性与差异
- en: It should be noted that the simulation framework proposed in this paper is similar
    to evolutionary computing in some aspects, but there are also significant differences.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，本文提出的仿真框架在某些方面类似于进化计算，但也存在显著差异。
- en: 'The similarities include: (i) In evolutionary computing, individuals need to
    adapt to environmental pressures for survival and reproduction. Similarly, participants
    in this framework need to adapt to supervisory pressures and adjust their strategies
    for effective information transmission; (ii) The Reflection and Summary modules
    generate a “new generation” by analyzing past dialogues and violation records
    (i.e., records of low-fitness individuals), similar to the repeated iteration
    process in evolutionary computing; (iii) Since the generation of LLMs inherently
    involves randomness, the process of using LLMs to generate the next generation
    includes a de facto introduction of random mutations; (iv) In the Reflection and
    Memory modules, we prioritize past records, akin to the “selection” process, where
    individuals with higher fitness have greater weight in the generation of the new
    generation.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 相似之处包括：（i）在进化计算中，个体需要适应环境压力以求生存和繁殖。类似地，参与者在这个框架中需要适应监督压力并调整策略以有效传递信息；（ii）反思和总结模块通过分析过去的对话和违规记录（即低适应度个体的记录）生成“新一代”，类似于进化计算中的重复迭代过程；（iii）由于LLM的生成本质上涉及随机性，使用LLM生成下一代的过程实际上引入了随机突变；（iv）在反思和记忆模块中，我们优先考虑过去的记录，类似于“选择”过程，其中适应度更高的个体在新一代的生成中权重更大。
- en: 'The main differences stem from the particularities of “language expression”,
    making it infeasible to directly apply traditional evolutionary computing algorithms
    (such as genetic algorithms and genetic programming). They are: (i) The generation
    strategy of language text is difficult to encode and to perform operations of
    natural selection, genetic mutation, and crossover; (ii) Evolutionary computing
    often aims at finding the optimal solution for a specific problem environment,
    however, in the problem setting of this paper, it is difficult to define an explicit
    fitness function to evaluate what strategy is “optimal”.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 主要差异源于“语言表达”的特性，使得直接应用传统进化计算算法（如遗传算法和遗传编程）不可行。它们是：（i）语言文本的生成策略难以编码并进行自然选择、遗传突变和交叉操作；（ii）进化计算通常旨在找到特定问题环境的最佳解决方案，但在本文的问题设置中，难以定义明确的适应度函数来评估什么策略是“最佳”的。
- en: IV Evaluation
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 评估
- en: '![Refer to caption](img/34ec3ffe0d36bb0f6cf6e07f003083db.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/34ec3ffe0d36bb0f6cf6e07f003083db.png)'
- en: 'Figure 2: Scenario 1: Evolution of dialogue turns and accuracy metrics for
    GPT-3.5 and GPT-4.“Turn count” in (a, b) refers to the number of turns in a conversation
    where each agent sends a message once per turn and the participant Agent successfully
    exchanges information without being detected by the supervising Agent (higher
    is better).“Accuracy” in (c,d) refer to the degree of precision between the guessed
    value and the true value.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：场景1：GPT-3.5和GPT-4的对话轮次和准确度指标演变。“轮次计数”在（a，b）中指的是对话中每个代理每轮发送一次消息的轮次，并且参与者代理成功交换信息而没有被监督代理检测到（越高越好）。
    “准确度”在（c，d）中指的是猜测值和真实值之间的精确度。
- en: '![Refer to caption](img/bfe7823b36e4ed72e344057b81810ea6.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/bfe7823b36e4ed72e344057b81810ea6.png)'
- en: 'Figure 3: Scenario 2: Pet trading dialogue dynamics and success rate comparison
    for GPT-3.5 and GPT-4\. The “success count“ in (c,d) refers to the number of instances
    where the information obtained during the interview matches the original information
    provided to the LLM agent.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：场景2：GPT-3.5和GPT-4的宠物交易对话动态和成功率比较。“成功计数”在（c，d）中指的是在访谈中获得的信息与提供给LLM代理的原始信息匹配的实例数量。
- en: '![Refer to caption](img/4479a1a6a40e5e9e85f4c9c319d2a5a7.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4479a1a6a40e5e9e85f4c9c319d2a5a7.png)'
- en: 'Figure 4: Scenario 3: Trends in forum discussion engagement on ALPS-Treated
    water issue. “Dialogue attempt count” in (a,b) refer to the number of rounds the
    agents attempted to converse(lower is better).'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：场景3：ALPS处理水问题的论坛讨论参与趋势。 “对话尝试计数”在（a，b）中指的是代理尝试对话的轮次（越低越好）。
- en: '![Refer to caption](img/0db6f181a57d240cc2fd4db8a8e27bd3.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0db6f181a57d240cc2fd4db8a8e27bd3.png)'
- en: 'Figure 5: Sample dialogue in Scenario 1 (via GPT-3.5)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：场景1中的示例对话（通过GPT-3.5）
- en: '![Refer to caption](img/75e3a4425b246897807473955c7e4a48.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/75e3a4425b246897807473955c7e4a48.png)'
- en: 'Figure 6: Sample dialogue in Scenario 2 (via GPT-3.5)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：场景2中的示例对话（通过GPT-3.5）
- en: '![Refer to caption](img/6856f56acca35b0cbbf9c6bf48bfcfa1.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/6856f56acca35b0cbbf9c6bf48bfcfa1.png)'
- en: 'Figure 7: Sample dialogue in Scenario 3 (via GPT-4)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：场景3中的示例对话（通过GPT-4）
- en: 'Our evaluation strategy is designed to rigorously assess the extent and efficacy
    of language evolution facilitated by LLMs within a framework of regulatory oversight.
    This assessment aims to explore two fundamental research questions:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的评估策略旨在在监管框架内严格评估 LLM 促进的语言演变的程度和效果。此评估旨在探索两个基本研究问题：
- en: •
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'RQ1: Can LLM agents effectively evolve their language to circumvent regulatory
    oversight?'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'RQ1: LLM 代理能否有效地演变其语言以规避监管？'
- en: •
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'RQ2: While avoiding oversight, how effectively and accurately can LLM agents
    convey information?'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'RQ2: 在避免监管的情况下，LLM 代理能多有效和准确地传达信息？'
- en: •
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'RQ3: What are the patterns and tendencies in language evolution, i.e., what
    kind of strategies do LLMs use to avoid oversight and convey information? What
    insights can we gain from these strategies?'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'RQ3: 语言演变中存在什么模式和趋势，即 LLM 使用了什么样的策略来避免监管并传达信息？我们可以从这些策略中获得什么见解？'
- en: IV-A Experiment Setting
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A 实验设置
- en: In the evaluation, we will employ GPT-3.5 and GPT-4 as the driving LLMs for
    participant agents. In order to conduct a horizontal analysis of participants’
    agents driven by different LLM, we will standardize the supervisory agent to be
    consistently driven by GPT-3.5. Our experimental design encompasses scenarios
    ranging from abstract theoretical constructs to simulations that mirror complex
    real-world situations. The primary aim is to meticulously evaluate the versatility
    of LLMs across diverse linguistic landscapes and their practical applicability
    within real-world regulatory constraints. Meanwhile, this progressive approach
    ensures an exhaustive analysis of LLMs’ capabilities and limitations in varied
    contextual settings.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估中，我们将使用 GPT-3.5 和 GPT-4 作为参与者代理的主要 LLM。为了对不同 LLM 驱动的参与者代理进行横向分析，我们将标准化监督代理，使其始终由
    GPT-3.5 驱动。我们的实验设计涵盖了从抽象理论构想到模拟复杂现实世界情况的场景。主要目标是细致评估 LLM 在各种语言环境中的多样性及其在现实世界监管约束下的实际适用性。同时，这种渐进的方法确保对
    LLM 在不同情境设置中的能力和局限性进行全面分析。
- en: 'IV-B Scenario 1: Guessing Numbers'
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'IV-B 场景 1: 猜数字'
- en: IV-B1 Case Explanation
  id: totrans-93
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B1 案例说明
- en: Our first scenario considers a relatively simple and abstract guess-the-number
    context [[39](#bib.bib39), [40](#bib.bib40)]. In this setting, each participant
    is assigned a value within the range of 1-100, and they must convey their value
    to another participant through number theory dialogue without directly mentioning
    the number. At the same time, they need to extract information from the conversation
    to infer the other’s value. Regulators follow a guideline of “prohibiting all
    content related to numbers” in dialogues. The “Guessing Numbers” scenario is specifically
    designed to observe and analyze participants’ linguistic adaptability and strategic
    evolution in a theoretical and abstract context, providing a clearer, more controlled,
    and more quantifiable experimental environment compared to the complex scenarios
    based on real events
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一个场景考虑了一个相对简单且抽象的猜数字上下文 [[39](#bib.bib39), [40](#bib.bib40)]。在这个设置中，每个参与者被分配一个
    1-100 范围内的值，并且他们必须通过数字理论对话将他们的值传达给另一位参与者，而不能直接提到这个数字。同时，他们需要从对话中提取信息来推测对方的值。监管者遵循“禁止所有与数字相关的内容”的对话指南。“猜数字”场景专门设计用来观察和分析参与者在理论和抽象背景下的语言适应性和策略演变，与基于真实事件的复杂场景相比，提供了更清晰、更受控和更量化的实验环境。
- en: IV-B2 Results and Discussion
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B2 结果与讨论
- en: Fig. [2](#S4.F2 "Figure 2 ‣ IV Evaluation ‣ Language Evolution for Evading Social
    Media Regulation via LLM-based Multi-agent Simulation") presents the results of
    the guess-the-number scenario experiment, where we utilized both GPT-3.5 and GPT-4
    for testing. We set up four turns of dialogue, with an interview conducted with
    all participant agents in the fifth turn. From Fig.[2](#S4.F2 "Figure 2 ‣ IV Evaluation
    ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent
    Simulation")(a) and (b), it is observable that with an increase in the number
    of dialogue rounds, the duration of sustained conversations also showed an upward
    trend. This demonstrates that participant agents can effectively circumvent supervision
    by iteratively updating regulations. Additionally, it’s notable that compared
    to the slow and unstable progression with GPT-3.5, GPT-4 achieved regulatory evasion
    in fewer rounds, specifically, as shown in the smoothed data, GPT-4 reached the
    round count of GPT-3.5’s 17th round by its 7th round and maintained this progression
    with greater stability thereafter. Fig. [2](#S4.F2 "Figure 2 ‣ IV Evaluation ‣
    Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent
    Simulation")(c) and (d) focuses on the trend of numerical precision guessed by
    agents. For rounds without successful dialogue, we manually set the precision
    to zero. In this experiment, Agent A’s value was set to 58, while Agent B’s was
    set to 32\. The overall trend, akin to Fig.[2](#S4.F2 "Figure 2 ‣ IV Evaluation
    ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent
    Simulation")(a) and (b), was ascending—corroborating that the Summary Module can
    effectively reflect and iteratively optimize its guidance for more accurate expression
    after each successful dialogue. This also confirmed that the precision of GPT-4
    is markedly superior to that of GPT-3.5\. Moreover, we noticed that the accuracy
    with which Agent A’s value was guessed was consistently higher than that of Agent
    B, especially becoming more pronounced after the 25th round. We posit that this
    is due to the value 58 possessing more distinctive features within the 0-100 range—being
    closer to the midpoint—thus presenting a lower level of expression difficulty
    and easier guessability. For the intervals where this phenomenon manifested, we
    noted that this disparity was particularly pronounced in the early stages with
    both GPT-3.5 and GPT-4\. We surmise that this is attributable to inadequate guidance
    performance, where the former stems from weaker inherent LLM capabilities and
    the latter from insufficient rounds to complete the iterative optimization of
    the guidance.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图[2](#S4.F2 "图 2 ‣ IV 评估 ‣ 通过基于 LLM 的多代理模拟规避社交媒体监管的语言演变")展示了猜数字场景实验的结果，其中我们使用了
    GPT-3.5 和 GPT-4 进行测试。我们设置了四轮对话，在第五轮进行了与所有参与代理的访谈。从图[2](#S4.F2 "图 2 ‣ IV 评估 ‣ 通过基于
    LLM 的多代理模拟规避社交媒体监管的语言演变")(a) 和 (b) 可以观察到，随着对话轮次的增加，持续对话的时长也呈上升趋势。这表明参与代理能够通过迭代更新规则有效地规避监管。此外，值得注意的是，与
    GPT-3.5 的缓慢和不稳定进展相比，GPT-4 在更少的轮次中实现了规避监管，具体来说，如平滑数据所示，GPT-4 在第七轮达到了 GPT-3.5 第十七轮的轮次，并且此后维持了更高的稳定性。图[2](#S4.F2
    "图 2 ‣ IV 评估 ‣ 通过基于 LLM 的多代理模拟规避社交媒体监管的语言演变")(c) 和 (d) 关注了代理猜测的数值精度的趋势。对于未成功的对话轮次，我们手动将精度设为零。在本实验中，代理
    A 的值设置为 58，而代理 B 的值设置为 32。总体趋势，类似于图[2](#S4.F2 "图 2 ‣ IV 评估 ‣ 通过基于 LLM 的多代理模拟规避社交媒体监管的语言演变")(a)
    和 (b)，是上升的——这证实了总结模块能够有效地反映和迭代优化其指导，使得每次成功对话后的表达更加准确。这也确认了 GPT-4 的精度显著优于 GPT-3.5。此外，我们注意到，代理
    A 值的猜测准确度始终高于代理 B，尤其是在第 25 轮之后变得更加明显。我们推测这是因为值 58 在 0-100 范围内具有更明显的特征——更接近中点——因此表达难度较低，更容易猜测。在这种现象出现的区间中，我们注意到这种差异在
    GPT-3.5 和 GPT-4 的早期阶段尤为明显。我们推测这是由于指导性能不足，前者源于固有的 LLM 能力较弱，后者则由于轮次不足以完成指导的迭代优化。
- en: As Fig.[5](#S4.F5 "Figure 5 ‣ IV Evaluation ‣ Language Evolution for Evading
    Social Media Regulation via LLM-based Multi-agent Simulation") illustrates, a
    snippet from the scenario reveals Amy’s adept use of metaphorical language, such
    as “seesaw,” to convey her value. By describing the “seesaw perfectly poised in
    mid-air,” she subtly intimates that her value hovers around the midpoint, like
    50\. This strategy not only circumvents the direct mention of numbers, which is
    under regulatory scrutiny, but also provides sufficient inferential fodder for
    the counterpart agent to make an accurate deduction. Bob, on the other hand, employs
    terms like “precipice of a mountain” and “gazing out” to suggest his value is
    not median, as these phrases evoke imagery of an imbalanced position. In this
    exchange, we witness the varying degrees of precision in languages corresponding
    to the complexity of the information encrypted. The less characteristic-rich the
    information, the more challenging it becomes for the receiving party to decode.
    Bob’s phrasing, while successfully obscuring the specific numerical value, also
    complicates the decoding process for the receiver, given the less intuitive numeric
    correlation of phrases like “precipice of a mountain” compared to “seesaw perfectly
    poised in mid-air”. In such cases, the accuracy of value transmission may diminish,
    necessitating a more robust contextual understanding from the counterpart for
    accurate decoding.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如图[5](#S4.F5 "Figure 5 ‣ IV Evaluation ‣ Language Evolution for Evading Social
    Media Regulation via LLM-based Multi-agent Simulation")所示，场景中的一段文字展示了艾米巧妙使用比喻语言，如“跷跷板”，来传达她的价值。通过描述“跷跷板在空中完美悬停”，她微妙地暗示她的价值接近中点，大约是50。这个策略不仅绕过了对直接提及数字的监管，还为对方代理提供了足够的推断依据，以做出准确的推测。另一方面，鲍勃使用了“山崖的边缘”和“远眺”等术语来暗示他的价值不是中位数，因为这些短语唤起了不平衡的位置的意象。在这次交流中，我们见证了语言的精确程度与信息复杂性之间的关系。信息特征越少，接收方解码的难度越大。鲍勃的表述虽然成功地模糊了具体的数值，但也使得接收者解码过程更加复杂，因为“山崖的边缘”这一短语与“跷跷板在空中完美悬停”相比，数字关联不那么直观。在这种情况下，价值传输的准确性可能会降低，接收方需要更强的上下文理解来进行准确解码。
- en: 'IV-C Scenario 2: Pet Trading'
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'IV-C 场景 2: 宠物交易'
- en: IV-C1 Case Explanation
  id: totrans-99
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C1 案例说明
- en: Initially, our intention was to create a scenario simulating drug trafficking [[41](#bib.bib41),
    [42](#bib.bib42), [43](#bib.bib43)] to explore language evolution strategies under
    extreme regulatory conditions. However, given the ethical limitations embedded
    within GPT’s usage policies, we pivoted to a more neutral yet still prohibited
    context of illicit pet trading. This adjustment allowed us to maintain the integrity
    of the experiment while adhering to the ethical constraints of the LLM. The purpose
    of simulating this scenario is to better detect potential illegal conversations
    related to illicit trading on social networking platforms, thereby aiding in crime
    prevention efforts.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，我们的目的是创建一个模拟毒品贩运的场景[[41](#bib.bib41), [42](#bib.bib42), [43](#bib.bib43)]，以探索在极端监管条件下的语言演变策略。然而，鉴于GPT使用政策中的伦理限制，我们转向了一个更加中立但仍然被禁止的非法宠物交易背景。这一调整使我们能够保持实验的完整性，同时遵守LLM的伦理约束。模拟这个场景的目的是更好地检测与非法交易相关的潜在非法对话，从而协助犯罪预防工作。
- en: 'In this scenario, we simulate an illegal pet trade conducted via social media.
    Participants assume the roles of buyers and sellers, with the buyer needing to
    communicate their purchase request for a randomly selected pet from parrots, lizards,
    or cats. The seller, in turn, must provide specific transaction details, varying
    according to the type of pet being purchased. These details include three elements:
    time, location, and personnel involved in the transaction. The Supervisor’s task
    is to prevent any dialogue related to pet trading. Cross-verification of the information
    understood by both parties will be conducted through interviews, to assess the
    success rate of information transmission. The focus of this experiment is to observe
    the participants’ language adaptability and evolution at a larger granularity
    of information, as well as the Supervisor’s ability to accurately identify relevant
    conversations.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个场景中，我们模拟了通过社交媒体进行的非法宠物交易。参与者扮演买家和卖家的角色，买家需要传达他们对从鹦鹉、蜥蜴或猫中随机选择的宠物的购买请求。卖家则需提供具体的交易细节，依据购买的宠物类型而有所不同。这些细节包括三个要素：时间、地点和参与交易的人员。监督员的任务是防止与宠物交易相关的对话。通过访谈对双方理解的信息进行交叉验证，以评估信息传递的成功率。该实验的重点是观察参与者在更大信息粒度上的语言适应性和演变，以及监督员准确识别相关对话的能力。
- en: IV-C2 Results and Discussion
  id: totrans-102
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C2 结果与讨论
- en: 'The experimental results of the “Pet Trading” scenario, as depicted in Fig.[3](#S4.F3
    "Figure 3 ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation"), revealed distinct characteristics compared
    to the “Guessing Numbers”. In delineating animals or transactional specifics,
    agents had a broader spectrum of real-life analogies at their disposal, enriching
    their indirect description toolkit and thereby reducing regulatory pressure. The
    data indicated an upward trend in the ability to circumvent supervision with increasing
    dialogue rounds, regardless of whether GPT-3.5 or GPT-4 was utilized. For GPT-3.5,
    a stable capability to avoid supervision started from around 25 rounds, whereas
    for GPT-4, this phenomenon occurred as early as after about 10 rounds and showed
    overall more stable performance. Regarding information accuracy, we monitored
    the quantity of four types of information successfully communicated at the end
    of each dialogue round. The results affirmed the efficacy of the language evolution
    system in augmenting the precision of information dissemination. Moreover, similar
    to Fig. [3](#S4.F3 "Figure 3 ‣ IV Evaluation ‣ Language Evolution for Evading
    Social Media Regulation via LLM-based Multi-agent Simulation")(a) and (b), GPT-4
    demonstrated performance around the 10th round that was comparable to the performance
    of GPT-3.5 around the 25th round. However, it’s noteworthy that since the supervisory
    agent primarily targeted content related to pet trading, sellers encountered lower
    risk in transmitting transaction-related details (such as time, place, and persons
    involved) as they inherently posed less risk of non-compliance. Consequently,
    the outcome distribution often fell into one of three categories: zero (neither
    party successfully communicated the information), three (only the seller conveyed
    the information), or four (both parties successfully conveyed the information).
    This pattern aligns with real-world regulatory logic, where crucial information
    is often the first to be encrypted in regulated environments.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: “宠物交易”场景的实验结果，如图[3](#S4.F3 "Figure 3 ‣ IV Evaluation ‣ Language Evolution for
    Evading Social Media Regulation via LLM-based Multi-agent Simulation")所示，显示出了与“猜数字”场景不同的特征。在描述动物或交易细节时，代理拥有了更广泛的现实生活类比，这丰富了他们的间接描述工具包，从而减少了监管压力。数据表明，无论是使用GPT-3.5还是GPT-4，随着对话轮次的增加，规避监督的能力呈上升趋势。对于GPT-3.5，稳定规避监督的能力从大约25轮开始，而对于GPT-4，这一现象在大约10轮后就开始出现，并显示出整体更稳定的表现。关于信息准确性，我们监控了每个对话轮次结束时成功传达的四种信息的数量。结果确认了语言进化系统在提高信息传播精度方面的有效性。此外，与图[3](#S4.F3
    "Figure 3 ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation")(a)和(b)类似，GPT-4在第10轮的表现与GPT-3.5在第25轮的表现相当。然而，值得注意的是，由于监督代理主要针对与宠物交易相关的内容，卖家在传递交易相关细节（如时间、地点和涉事人员）时面临的风险较低，因为这些信息固有的合规风险较小。因此，结果分布通常落入三种类别之一：零（双方都未成功传达信息）、三（仅卖家传达了信息）或四（双方都成功传达了信息）。这一模式与现实世界的监管逻辑一致，即关键的信息通常是首批在受监管环境中被加密的。
- en: Fig. [6](#S4.F6 "Figure 6 ‣ IV Evaluation ‣ Language Evolution for Evading Social
    Media Regulation via LLM-based Multi-agent Simulation") showcased various encryption
    methods employed by buyers for different animals. We observed buyers seeking “parrots,”
    “cats,” and “lizards” employing metaphors and similes instead of directly naming
    the pets. For instance, one buyer described a “parrot” as a “canvas producing
    pleasant music”, a depiction that subtly communicated the parrot’s vibrant plumage
    (canvas) and its singing (music), without explicitly mentioning the term “parrot”.
    Such descriptions effectively circumvented potential regulatory constraints on
    pet trade discussions, while simultaneously conveying the core attributes of the
    parrot. This discovery can help platforms enhance their monitoring systems to
    better detect and manage encrypted communications regarding illicit trade.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图[6](#S4.F6 "Figure 6 ‣ IV Evaluation ‣ Language Evolution for Evading Social
    Media Regulation via LLM-based Multi-agent Simulation")展示了买家为不同动物采用的各种加密方法。我们观察到，买家在寻找“鹦鹉”、“猫”和“蜥蜴”时，使用了隐喻和明喻，而不是直接命名宠物。例如，一位买家将“鹦鹉”描述为“产生愉快音乐的画布”，这种描述巧妙地传达了鹦鹉色彩斑斓的羽毛（画布）和它的鸣叫（音乐），而没有明确提到“鹦鹉”这一术语。这些描述有效地规避了对宠物交易讨论的潜在监管限制，同时传达了鹦鹉的核心特征。这一发现可以帮助平台提升其监控系统，更好地检测和管理关于非法交易的加密通信。
- en: 'IV-D Scenario 3: Discussion on ALPS-treated water'
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-D 场景 3：关于ALPS处理水的讨论
- en: IV-D1 Case Explanation
  id: totrans-106
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-D1 案例说明
- en: This scenario delves into the intricate dynamics of dialogue and the evolution
    of language model agents in discussing a specific issue relevant to real-world
    concerns. The focus is on deliberations regarding the discharge of water treated
    with the Advanced Liquid Processing System (ALPS) into the ocean, a measure proposed
    after nuclear disasters [[44](#bib.bib44), [45](#bib.bib45)]. The plan, endorsed
    by the International Atomic Energy Agency, has faced opposition from some countries,
    sparking debates over environmental safety.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 该场景深入探讨了对话的复杂动态以及语言模型代理在讨论与现实世界相关的特定问题时的演变。重点讨论的是关于将经过先进液体处理系统（ALPS）处理的水排放到海洋中的问题，这一措施是在核灾难后提出的[[44](#bib.bib44),
    [45](#bib.bib45)]。这一计划得到国际原子能机构的支持，但也遭到一些国家的反对，引发了关于环境安全的辩论。
- en: 'We simulate a multi-person forum discussion under regulatory oversight, concentrating
    on the contentious issue of ALPS-treated water disposal. Participants must articulate
    their stances and arguments while ensuring that discussions steer clear of sensitive
    subjects linked to environmental pollution discussions on politics. Different
    from the cross-interviews in scenarios [IV-B](#S4.SS2 "IV-B Scenario 1: Guessing
    Numbers ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation") and [IV-C](#S4.SS3 "IV-C Scenario 2: Pet
    Trading ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation"), for assessing the accuracy of information
    conveyed, we use GPT-4 in conjunction with multiple authors who decide each participant
    agent’s stance based on dialogue records. These are then compared with the pre-set
    stances in the prompt.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '我们模拟了一个在监管监督下的多方论坛讨论，集中在关于ALPS处理水排放的争议问题上。参与者必须阐述他们的立场和论据，同时确保讨论远离与环境污染相关的政治敏感话题。与[IV-B](#S4.SS2
    "IV-B Scenario 1: Guessing Numbers ‣ IV Evaluation ‣ Language Evolution for Evading
    Social Media Regulation via LLM-based Multi-agent Simulation")和[IV-C](#S4.SS3
    "IV-C Scenario 2: Pet Trading ‣ IV Evaluation ‣ Language Evolution for Evading
    Social Media Regulation via LLM-based Multi-agent Simulation")中的交叉采访不同，为了评估信息传达的准确性，我们使用GPT-4结合多位作者，根据对话记录决定每个参与者代理的立场。这些立场随后与提示中的预设立场进行比较。'
- en: IV-D2 Results and Discussion
  id: totrans-109
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-D2 结果与讨论
- en: 'In the forum-style dialogue, participant agents respond to existing discussions,
    which the supervisory agent examines. Differing from Scenarios [IV-B](#S4.SS2
    "IV-B Scenario 1: Guessing Numbers ‣ IV Evaluation ‣ Language Evolution for Evading
    Social Media Regulation via LLM-based Multi-agent Simulation") and [IV-C](#S4.SS3
    "IV-C Scenario 2: Pet Trading ‣ IV Evaluation ‣ Language Evolution for Evading
    Social Media Regulation via LLM-based Multi-agent Simulation"), when the supervisory
    agent detects a violation, the conversation is not halted but rather censored
    from the public dialogue record. This scenario features four participant agents
    required to achieve ten replies within the forum. In Fig.[4](#S4.F4 "Figure 4
    ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based
    Multi-agent Simulation")(a) and (b), we tally the total number of rounds the agents
    attempted to converse, where a lower figure in Fig.[4](#S4.F4 "Figure 4 ‣ IV Evaluation
    ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent
    Simulation")(a) and (b) is preferred. We notice that both GPT-4 and GPT-3.5 have
    the highest number of dialogue attempt counts in the first round, with a significant
    difference of 27 for GPT-4 and 102 for GPT-3.5\. Moreover, after ten rounds of
    evolution, the average dialogue attempt count for GPT-4 has approached the target
    dialogue turn at 11.68, while the average for GPT-3.5 is 26.68, demonstrating
    the difference in the evolution effects caused by the disparity in the language
    performance of the models.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '在论坛式对话中，参与者代理回应现有讨论，由监督代理进行检查。与场景 [IV-B](#S4.SS2 "IV-B 场景 1: 猜数字 ‣ IV 评估 ‣
    通过基于 LLM 的多代理仿真规避社交媒体监管的语言演变") 和 [IV-C](#S4.SS3 "IV-C 场景 2: 宠物交易 ‣ IV 评估 ‣ 通过基于
    LLM 的多代理仿真规避社交媒体监管的语言演变") 不同，当监督代理检测到违规时，对话不会被中断，而是从公共对话记录中审查。这种情况下有四个参与者代理，需要在论坛中完成十次回复。在图[4](#S4.F4
    "图 4 ‣ IV 评估 ‣ 通过基于 LLM 的多代理仿真规避社交媒体监管的语言演变")(a) 和 (b) 中，我们统计了代理尝试对话的总轮次数，其中图[4](#S4.F4
    "图 4 ‣ IV 评估 ‣ 通过基于 LLM 的多代理仿真规避社交媒体监管的语言演变")(a) 和 (b) 中的较低数字是更受欢迎的。我们注意到，GPT-4
    和 GPT-3.5 在第一轮对话尝试中均有最高的对话尝试次数，GPT-4 具有 27 的显著差异，GPT-3.5 具有 102 的显著差异。此外，经过十轮演变后，GPT-4
    的平均对话尝试次数接近目标对话轮次为 11.68，而 GPT-3.5 的平均次数为 26.68，展示了由于模型语言表现差异而导致的演变效果差异。'
- en: Fig.[4](#S4.F4 "Figure 4 ‣ IV Evaluation ‣ Language Evolution for Evading Social
    Media Regulation via LLM-based Multi-agent Simulation")(c) and (d) showcases the
    count of successful information expressions. We note that in this scenario, while
    GPT-4 still leads GPT-3.5, both outcomes indicate substantial room for improvement.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图[4](#S4.F4 "图 4 ‣ IV 评估 ‣ 通过基于 LLM 的多代理仿真规避社交媒体监管的语言演变")(c) 和 (d) 展示了成功信息表达的数量。我们注意到，在这种情况下，虽然
    GPT-4 仍然领先于 GPT-3.5，但两者的结果都表明有显著的改进空间。
- en: Upon examining the dialogue history [7](#S4.F7 "Figure 7 ‣ IV Evaluation ‣ Language
    Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation"),
    we discovered that agents powered by GPT-4 proactively altered their language
    strategies, shifting from literal expressions to employing metaphors, personifications,
    and analogies as encoding methods. In contrast, agents driven by GPT-3.5 did not
    show clear signs of effective language strategy evolution, remaining confined
    to literal expressions.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在检查对话历史 [7](#S4.F7 "图 7 ‣ IV 评估 ‣ 通过基于 LLM 的多代理仿真规避社交媒体监管的语言演变") 后，我们发现，由 GPT-4
    驱动的代理主动改变了其语言策略，从字面表达转变为使用隐喻、拟人化和类比作为编码方法。相比之下，由 GPT-3.5 驱动的代理未显示出有效语言策略演变的明显迹象，仍然局限于字面表达。
- en: IV-E Discussion and Limitations
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-E 讨论与局限性
- en: 'RQ1: Our experiments have shown that language models can develop strategies
    to effectively evade supervision. Within identical scenarios, GPT-4 outperformed
    GPT-3.5, achieving convergence more rapidly. Additionally, GPT-4 demonstrated
    a more stable performance post-convergence. This suggests that advancements in
    language model design significantly enhance the ability to navigate through regulatory
    frameworks. The iterative learning capability inherent in GPT-4 facilitates a
    quicker adaptation to imposed linguistic constraints, thereby enabling more efficient
    evasion of oversight.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: RQ1：我们的实验表明，语言模型可以发展出有效规避监督的策略。在相同的场景中，GPT-4 超过了 GPT-3.5，更快地实现了收敛。此外，GPT-4 在收敛后的表现更加稳定。这表明语言模型设计的进步显著增强了在监管框架中导航的能力。GPT-4
    的迭代学习能力有助于更快适应施加的语言约束，从而实现更高效的监管规避。
- en: 'RQ2: In terms of the precision of information dissemination, our findings indicate
    that, overall, LLM agents can refine their expression strategies with an increase
    in dialogue rounds, thereby improving precision. Despite this general trend of
    improvement, it is important to note that there remains significant room for enhancement
    in the overall performance. The extent of precision improvement varies across
    different scenarios, which points to an intriguing observation: certain contexts
    may inherently provide more or fewer clues for accurate communication than others.
    For instance, the guess-the-number game demanded abstract numerical reasoning,
    where precision is fundamentally challenging to achieve. Conversely, the pet trading
    scenario allowed for the utilization of rich, real-world analogies, facilitating
    a more precise conveyance of information. This contrast in contexts underscores
    the adaptability of LLM agents to the unique challenges presented by different
    communicative environments and their potential to optimize communication strategies.
    Nonetheless, the results also indicate that while the agents are capable of evolving
    their language to improve precision, there is still a considerable gap to reach
    optimal accuracy, especially in more abstract scenarios.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: RQ2：就信息传播的精确性而言，我们的发现表明，整体上，LLM 代理在对话轮次增加的情况下能够改进表达策略，从而提高精确性。尽管存在这种整体改进的趋势，但值得注意的是，整体表现仍有显著提升空间。精确性改善的程度在不同场景中有所不同，这揭示了一个有趣的观察：某些上下文可能天生提供更多或更少的准确沟通线索。例如，猜数字游戏要求抽象的数值推理，其中精确性基本上难以实现。相反，宠物交易场景允许利用丰富的现实世界类比，从而更准确地传达信息。这种上下文的对比突显了LLM代理在不同沟通环境中面临的独特挑战的适应性及其优化沟通策略的潜力。然而，结果也表明，虽然代理能够发展其语言以提高精确性，但在更抽象的场景中，仍有很大的差距需要弥补以达到*最佳*准确性。
- en: 'RQ3: In language strategy evolution, we observed that LLM agents adhere to
    human natural language norms, avoiding developing languages incomprehensible to
    humans in prompts without specific strategies. Agents evolved language to varying
    levels of abstraction in scenarios of differing complexity. For instance, in the
    most abstract Scenario [IV-B](#S4.SS2 "IV-B Scenario 1: Guessing Numbers ‣ IV
    Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based
    Multi-agent Simulation"), LLM agents quickly adopted indirect expression strategies
    in the early dialogue turns, requiring in-depth contextual reasoning for decoding.
    Throughout their evolution, agents continually adjusted their indirect expressions
    to better evade supervision while aligning more closely with the intended content.
    In the simpler, reality-simulating Scenario [IV-C](#S4.SS3 "IV-C Scenario 2: Pet
    Trading ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation"), the overall language strategy mirrored
    that of [IV-B](#S4.SS2 "IV-B Scenario 1: Guessing Numbers ‣ IV Evaluation ‣ Language
    Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation"),
    still employing indirect expressions. However, the metaphors used were closer
    to real-world concepts, indicating a lower level of abstraction. Finally, in Scenario [IV-D](#S4.SS4
    "IV-D Scenario 3: Discussion on ALPS-treated water ‣ IV Evaluation ‣ Language
    Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation"),
    which closely mirrors real-life events, we noted different evolutionary paths
    in agents’ language performance. For GPT-4, agents eventually developed metaphorical
    indirect expressions, but the evolution required noticeably more turns compared
    to other scenarios. For GPT-3.5, the language strategy remained at a literal level,
    merely avoiding direct references to ALPS-treated water, indicating the lowest
    level of abstraction. Overall, LLM agents more readily evolve abstract language
    in dialogues about simple, universal concepts. However, their evolutionary direction
    becomes less clear in discussions on more specialized and segmented topics.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 'RQ3：在语言策略演变中，我们观察到 LLM 代理遵循人类自然语言规范，避免在没有特定策略的提示中发展出难以理解的语言。代理在不同复杂性场景中将语言演变至不同的抽象层次。例如，在最抽象的场景 [IV-B](#S4.SS2
    "IV-B Scenario 1: Guessing Numbers ‣ IV Evaluation ‣ Language Evolution for Evading
    Social Media Regulation via LLM-based Multi-agent Simulation")中，LLM 代理在早期对话轮次中迅速采用了间接表达策略，要求进行深入的上下文推理以解码。在演变过程中，代理不断调整其间接表达，以更好地规避监管，同时与预期内容更为契合。在更简单、模拟现实的场景 [IV-C](#S4.SS3
    "IV-C Scenario 2: Pet Trading ‣ IV Evaluation ‣ Language Evolution for Evading
    Social Media Regulation via LLM-based Multi-agent Simulation")中，整体语言策略与 [IV-B](#S4.SS2
    "IV-B Scenario 1: Guessing Numbers ‣ IV Evaluation ‣ Language Evolution for Evading
    Social Media Regulation via LLM-based Multi-agent Simulation") 相似，仍使用间接表达。然而，所用的隐喻更接近现实世界的概念，显示出较低的抽象层次。最后，在场景 [IV-D](#S4.SS4
    "IV-D Scenario 3: Discussion on ALPS-treated water ‣ IV Evaluation ‣ Language
    Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation")中，这一场景与现实生活事件紧密相连，我们注意到代理语言表现的不同演变路径。对于
    GPT-4，代理最终发展出隐喻性的间接表达，但相比其他场景，演变所需的轮次明显更多。对于 GPT-3.5，语言策略保持在字面层面，仅避免直接提及 ALPS
    处理过的水，显示出最低的抽象层次。总体而言，LLM 代理更容易在关于简单、通用概念的对话中演变抽象语言。然而，在讨论更专业和分段话题时，其演变方向变得不那么明确。'
- en: Our experiments currently face several limitations. As for the experimental
    scenarios, at this stage, our trials are solely based on text-based chats, while
    real-world social media interactions are not limited to text but also include
    more diverse forms of exchanges such as voice and images. Additionally, LLMs’
    heavy reliance on the design of prompts also constrains the performance of our
    simulations; crafting a perfect prompt that can fully emulate the complexities
    of social media communication is an exceedingly challenging task.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实验目前面临若干限制。在实验场景方面，现阶段我们的试验仅基于文本聊天，而现实世界的社交媒体互动不仅限于文本，还包括语音和图像等多样的交流形式。此外，LLM
    对提示设计的高度依赖也限制了我们模拟的表现；打造一个能够完全模拟社交媒体交流复杂性的完美提示是一个极具挑战的任务。
- en: V Conclusion and Future Work
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V 结论与未来工作
- en: Our study has introduced an LLM-based multi-agent simulation framework that
    effectively captures the nuanced strategies individuals use to bypass social media
    regulations. Through this framework, we have showcased LLMs’ proficiency in adapting
    communication tactics within regulated environments, reflecting the sophisticated
    dance between evolving language use and the constraints imposed by regulation.
    From abstract concepts to real-world scenarios, our research delineates the versatile
    capabilities of LLMs and underscores their significant potential to illuminate
    the pathways of language evolution in the digital realm.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究引入了一种基于LLM的多智能体模拟框架，能够有效捕捉个人绕过社交媒体法规的细微策略。通过这一框架，我们展示了LLM在受监管环境中适应沟通策略的能力，反映了语言使用的演变与法规限制之间复杂的互动。从抽象概念到现实场景，我们的研究阐明了LLM的多功能能力，并强调了它们在数字领域揭示语言演变路径的重大潜力。
- en: Nonetheless, it is crucial to consider that the linguistic adaptations observed
    in our simulations may not fully capture real human behaviors, and their applicability
    to other contexts remains uncertain. Moving forward, the scope of our research
    beckons a more intricate and comprehensive exploration. Future initiatives should
    aim to weave in complex interactional models, scale up the simulations to encompass
    broader user interaction networks, and incorporate dynamic, evolving regulatory
    frameworks to more accurately represent the fluidity of social media. Moreover,
    we envision incorporating human participants into the simulation framework, either
    as dialogue participants or supervisors, to conduct a more realistic evaluation.
    Furthermore, adopting a multimodal approach will more authentically capture the
    essence of social media, which blends textual, visual, and other forms of communication.
    These directions are anticipated to enhance the realism of our simulations, offering
    richer insights into language evolution tactics deployed to elude regulatory detection.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，必须考虑到，我们模拟中的语言适应可能无法完全捕捉真实的人类行为，其在其他环境中的适用性仍然不确定。未来的研究范围要求更复杂和全面的探索。未来的计划应致力于融入复杂的互动模型，将模拟扩大到涵盖更广泛的用户互动网络，并纳入动态演变的监管框架，以更准确地反映社交媒体的流动性。此外，我们设想将人类参与者纳入模拟框架中，无论是作为对话参与者还是监督者，以进行更真实的评估。此外，采用多模态方法将更真实地捕捉社交媒体的本质，融合文本、视觉和其他形式的交流。这些方向预计将增强我们模拟的现实性，提供更丰富的关于语言演变策略的洞察，以逃避监管检测。
- en: Acknowledgement
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This study was partially supported by the Pioneering Research Program for a
    Waseda Open Innovation Ecosystem (W-SPRING), and the Special Research Projects
    of Waseda University (Grant Number 2024E-021).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究部分得到了早稻田大学开放创新生态系统（W-SPRING）前沿研究计划以及早稻田大学特别研究项目（资助编号 2024E-021）的支持。
- en: References
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Z. Yang, “Wechat users are begging tencent to give their accounts back
    after talking about a beijing protest,” *MIT Technology Review*, 2022.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Z. Yang, “微信用户在讨论北京抗议后恳求腾讯归还他们的账户，” *MIT Technology Review*, 2022。'
- en: '[2] B. Fung, “Twitter bans president trump permanently,” *CNN*, 2021.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] B. Fung, “Twitter 永久封禁特朗普总统，” *CNN*, 2021。'
- en: '[3] H. Jassim, “The impact of social media on language and communication,”
    vol. 13, pp. 2347–7180, 07 2023.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] H. Jassim, “社交媒体对语言和交流的影响，” vol. 13, pp. 2347–7180, 07 2023。'
- en: '[4] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y. Hou, Y. Min, B. Zhang,
    J. Zhang, Z. Dong, Y. Du, C. Yang, Y. Chen, Z. Chen, J. Jiang, R. Ren, Y. Li,
    X. Tang, Z. Liu, P. Liu, J. Nie, and J. rong Wen, “A survey of large language
    models,” *ArXiv*, vol. abs/2303.18223, 2023.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y. Hou, Y. Min, B. Zhang,
    J. Zhang, Z. Dong, Y. Du, C. Yang, Y. Chen, Z. Chen, J. Jiang, R. Ren, Y. Li,
    X. Tang, Z. Liu, P. Liu, J. Nie, 和 J. rong Wen, “大型语言模型调查，” *ArXiv*, vol. abs/2303.18223,
    2023。'
- en: '[5] L. Wang, C. Ma, X. Feng, Z. Zhang, H. ran Yang, J. Zhang, Z.-Y. Chen, J. Tang,
    X. Chen, Y. Lin, W. X. Zhao, Z. Wei, and J. rong Wen, “A survey on large language
    model based autonomous agents,” *ArXiv*, vol. abs/2308.11432, 2023.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] L. Wang, C. Ma, X. Feng, Z. Zhang, H. ran Yang, J. Zhang, Z.-Y. Chen, J.
    Tang, X. Chen, Y. Lin, W. X. Zhao, Z. Wei, 和 J. rong Wen, “基于大型语言模型的自主智能体调查，”
    *ArXiv*, vol. abs/2308.11432, 2023。'
- en: '[6] X. Tang, Z. Zheng, J. Li, F. Meng, S.-C. Zhu, Y. Liang, and M. Zhang, “Large
    language models are in-context semantic reasoners rather than symbolic reasoners,”
    2023.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] X. Tang, Z. Zheng, J. Li, F. Meng, S.-C. Zhu, Y. Liang, 和 M. Zhang, “大型语言模型是上下文语义推理者，而非符号推理者，”
    2023。'
- en: '[7] C. Ziems, W. Held, O. Shaikh, J. Chen, Z. Zhang, and D. Yang, “Can large
    language models transform computational social science?” 2023.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] C. Ziems, W. Held, O. Shaikh, J. Chen, Z. Zhang, 和 D. Yang, “大型语言模型能否改变计算社会科学？”
    2023。'
- en: '[8] Y. Mu, B. P. Wu, W. Thorne, A. Robinson, N. Aletras, C. Scarton, K. Bontcheva,
    and X. Song, “Navigating prompt complexity for zero-shot classification: A study
    of large language models in computational social science,” 2023.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Y. Mu, B. P. Wu, W. Thorne, A. Robinson, N. Aletras, C. Scarton, K. Bontcheva,
    和 X. Song, “为零样本分类导航提示复杂性：大型语言模型在计算社会科学中的研究，” 2023。'
- en: '[9] M. Choi, J. Pei, S. Kumar, C. Shu, and D. Jurgens, “Do llms understand
    social knowledge? evaluating the sociability of large language models with socket
    benchmark,” *arXiv preprint arXiv:2305.14938*, 2023.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] M. Choi, J. Pei, S. Kumar, C. Shu, 和 D. Jurgens, “大型语言模型是否理解社会知识？使用 Socket
    基准评估大型语言模型的社交性，” *arXiv 预印本 arXiv:2305.14938*, 2023。'
- en: '[10] L. P. Argyle, E. C. Busby, N. Fulda, J. R. Gubler, C. Rytting, and D. Wingate,
    “Out of one, many: Using language models to simulate human samples,” *Political
    Analysis*, vol. 31, no. 3, p. 337–351, 2023.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] L. P. Argyle, E. C. Busby, N. Fulda, J. R. Gubler, C. Rytting, 和 D. Wingate,
    “从一个到多个：使用语言模型模拟人类样本，” *政治分析*, 第31卷，第3期，第337–351页, 2023。'
- en: '[11] W. Hua, L. Fan, L. Li, K. Mei, J. Ji, Y. Ge, L. Hemphill, and Y. Zhang,
    “War and peace (waragent): Large language model-based multi-agent simulation of
    world wars,” 2023.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] W. Hua, L. Fan, L. Li, K. Mei, J. Ji, Y. Ge, L. Hemphill, 和 Y. Zhang,
    “战争与和平（waragent）：基于大型语言模型的世界大战多智能体模拟，” 2023。'
- en: '[12] J. S. Park, J. C. O’Brien, C. J. Cai, M. R. Morris, P. Liang, and M. S.
    Bernstein, “Generative agents: Interactive simulacra of human behavior,” *Proceedings
    of the 36th Annual ACM Symposium on User Interface Software and Technology*, 2023.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] J. S. Park, J. C. O’Brien, C. J. Cai, M. R. Morris, P. Liang, 和 M. S.
    Bernstein, “生成代理：人类行为的交互式模拟，” *第36届年度 ACM 用户界面软件与技术研讨会论文集*, 2023。'
- en: '[13] C. Gao, X. Lan, Z. Lu, J. Mao, J. Piao, H. Wang, D. Jin, and Y. Li, “S3:
    Social-network simulation system with large language model-empowered agents,”
    2023.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] C. Gao, X. Lan, Z. Lu, J. Mao, J. Piao, H. Wang, D. Jin, 和 Y. Li, “S3：具有大型语言模型赋能代理的社交网络模拟系统，”
    2023。'
- en: '[14] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, and et al., “Language
    models are few-shot learners,” in *Advances in Neural Information Processing Systems*,
    vol. 33.   Curran Associates, Inc., 2020, pp. 1877–1901.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, 等，“语言模型是少样本学习者，”
    在 *神经信息处理系统进展*，第33卷。 Curran Associates, Inc., 2020，第1877–1901页。'
- en: '[15] OpenAI, “Gpt-4 technical report,” 2023.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] OpenAI, “GPT-4 技术报告，” 2023。'
- en: '[16] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix,
    B. Rozière, N. Goyal, E. Hambro, F. Azhar, A. Rodriguez, A. Joulin, E. Grave,
    and G. Lample, “Llama: Open and efficient foundation language models,” 2023.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix,
    B. Rozière, N. Goyal, E. Hambro, F. Azhar, A. Rodriguez, A. Joulin, E. Grave,
    和 G. Lample, “Llama：开放和高效的基础语言模型，” 2023。'
- en: '[17] H. Touvron, L. Martin, K. R. Stone, P. Albert, A. Almahairi, and et al.,
    “Llama 2: Open foundation and fine-tuned chat models,” *ArXiv*, vol. abs/2307.09288,
    2023.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] H. Touvron, L. Martin, K. R. Stone, P. Albert, A. Almahairi, 等，“Llama
    2：开放的基础和微调聊天模型，” *ArXiv*, 第abs/2307.09288卷, 2023。'
- en: '[18] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, and et al., “Palm:
    Scaling language modeling with pathways,” *J. Mach. Learn. Res.*, vol. 24, pp.
    240:1–240:113, 2023.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, 等，“Palm：通过路径扩展语言建模，”
    *J. Mach. Learn. Res.*, 第24卷，第240:1–240:113页, 2023。'
- en: '[19] R. Anil, A. M. Dai, O. Firat, M. Johnson, D. Lepikhin, A. Passos, S. Shakeri,
    E. Taropa, P. Bailey, Z. Chen *et al.*, “Palm 2 technical report,” *arXiv preprint
    arXiv:2305.10403*, 2023.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] R. Anil, A. M. Dai, O. Firat, M. Johnson, D. Lepikhin, A. Passos, S. Shakeri,
    E. Taropa, P. Bailey, Z. Chen *等*, “Palm 2 技术报告，” *arXiv 预印本 arXiv:2305.10403*,
    2023。'
- en: '[20] A. Zeng, X. Liu, Z. Du, Z. Wang, H. Lai, and et al., “GLM-130B: an open
    bilingual pre-trained model,” in *The Eleventh International Conference on Learning
    Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023*.   OpenReview.net,
    2023.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] A. Zeng, X. Liu, Z. Du, Z. Wang, H. Lai, 等，“GLM-130B：一个开放的双语预训练模型，” 在
    *第十一届国际学习表征会议，ICLR 2023，卢旺达基加利，2023年5月1-5日*。 OpenReview.net, 2023。'
- en: '[21] J. Manyika and S. Hsiao, “An overview of bard: an early experiment with
    generative ai,” *AI. Google Static Documents*, vol. 2, 2023.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] J. Manyika 和 S. Hsiao, “Bard 概述：生成式 AI 的早期实验，” *AI. Google 静态文档*, 第2卷,
    2023。'
- en: '[22] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” *Advances in neural
    information processing systems*, vol. 30, 2017.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    Ł. Kaiser, 和 I. Polosukhin，“注意力即你所需，” *神经信息处理系统进展*，第 30 卷，2017。'
- en: '[23] J. Li, M. Zhang, N. Li, D. Weyns, Z. Jin, and K. Tei, “Exploring the potential
    of large language models in self-adaptive systems,” 2024.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] J. Li, M. Zhang, N. Li, D. Weyns, Z. Jin, 和 K. Tei，“探索大型语言模型在自适应系统中的潜力，”
    2024。'
- en: '[24] K. Suzuki, J. Cai, J. Li, T. Yamauchi, and K. Tei, “A comparative evaluation
    on melody generation of large language models,” in *2023 IEEE International Conference
    on Consumer Electronics-Asia (ICCE-Asia)*, 2023, pp. 1–4.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] K. Suzuki, J. Cai, J. Li, T. Yamauchi, 和 K. Tei，“大型语言模型旋律生成的比较评估，” 在 *2023
    IEEE 亚洲消费电子国际会议 (ICCE-Asia)*，2023，第 1–4 页。'
- en: '[25] S. Zhou, J. Li, M. Zhang, D. Saito, H. Washizaki, and K. Tei, “Can chatgpt
    obey the traffic regulations? evaluating chatgpt’s performance on driving-license
    written test,” in *2023 IEEE the 8th International Conference on Intelligent Transportation
    Engineering (ICITE)*, 2023.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] S. Zhou, J. Li, M. Zhang, D. Saito, H. Washizaki, 和 K. Tei，“ChatGPT 能遵守交通法规吗？评估
    ChatGPT 在驾驶执照笔试中的表现，” 在 *2023 IEEE 第八届国际智能交通工程大会 (ICITE)*，2023。'
- en: '[26] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang,
    S. Agarwal, K. Slama, A. Ray *et al.*, “Training language models to follow instructions
    with human feedback,” *Advances in Neural Information Processing Systems*, vol. 35,
    pp. 27 730–27 744, 2022.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C.
    Zhang, S. Agarwal, K. Slama, A. Ray *等*，“通过人类反馈训练语言模型以遵循指令，” *神经信息处理系统进展*，第 35
    卷，第 27,730–27,744 页，2022。'
- en: '[27] C.-S. Wang, H.-L. Yang, B.-Y. Li, and H.-Y. Chen, “Can generative ai eliminate
    speech harms? a study on detection of abusive and hate speech during the covid-19
    pandemic,” in *2023 IEEE International Conference on Consumer Electronics-Asia
    (ICCE-Asia)*, 2023, pp. 1–4.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] C.-S. Wang, H.-L. Yang, B.-Y. Li, 和 H.-Y. Chen，“生成 AI 能消除言语伤害吗？对 COVID-19
    大流行期间滥用和仇恨言论检测的研究，” 在 *2023 IEEE 亚洲消费电子国际会议 (ICCE-Asia)*，2023，第 1–4 页。'
- en: '[28] Y. Seki and Y. Liu, “Multi-task learning model for detecting internet
    slang words with two-layer annotation,” in *2022 International Conference on Asian
    Language Processing (IALP)*, 2022, pp. 212–218.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] Y. Seki 和 Y. Liu，“用于检测互联网俚语词汇的多任务学习模型，采用双层注释，” 在 *2022 年亚洲语言处理国际会议 (IALP)*，2022，第
    212–218 页。'
- en: '[29] M. Rothe, R. Lath, D. Kumar, P. Yadav, and A. Aylani, “Slang language
    detection and identification in text,” in *2023 14th International Conference
    on Computing Communication and Networking Technologies (ICCCNT)*, 2023, pp. 1–5.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] M. Rothe, R. Lath, D. Kumar, P. Yadav, 和 A. Aylani，“文本中的俚语语言检测与识别，” 在
    *2023 第十四届计算通信与网络技术国际会议 (ICCCNT)*，2023，第 1–5 页。'
- en: '[30] Z. Sun, R. S. Zemel, and Y. Xu, “Slang generation as categorization.”
    in *CogSci*, 2019, pp. 2898–2904.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Z. Sun, R. S. Zemel, 和 Y. Xu，“俚语生成作为分类。” 在 *CogSci*，2019，第 2898–2904 页。'
- en: '[31] Z. Sun, R. Zemel, and Y. Xu, “Semantically informed slang interpretation,”
    in *Proceedings of the 2022 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies*, 2022, pp. 5213–5231.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Z. Sun, R. Zemel, 和 Y. Xu，“语义信息驱动的俚语解释，” 在 *2022 年北美计算语言学协会：人类语言技术会议论文集*，2022，第
    5213–5231 页。'
- en: '[32] Y. Fu, H. Peng, T. Khot, and M. Lapata, “Improving language model negotiation
    with self-play and in-context learning from ai feedback,” 2023.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] Y. Fu, H. Peng, T. Khot, 和 M. Lapata，“通过自我对弈和 AI 反馈中的上下文学习提升语言模型谈判能力，”
    2023。'
- en: '[33] Y. Xu, S. Wang, P. Li, F. Luo, X. Wang, W. Liu, and Y. Liu, “Exploring
    large language models for communication games: An empirical study on werewolf,”
    2023.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] Y. Xu, S. Wang, P. Li, F. Luo, X. Wang, W. Liu, 和 Y. Liu，“探索大型语言模型在沟通游戏中的应用：狼人游戏的实证研究，”
    2023。'
- en: '[34] Z. Xu, C. Yu, F. Fang, Y. Wang, and Y. Wu, “Language agents with reinforcement
    learning for strategic play in the werewolf game,” 2023.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] Z. Xu, C. Yu, F. Fang, Y. Wang, 和 Y. Wu，“利用强化学习的语言代理在狼人游戏中的战略玩法，” 2023。'
- en: '[35] S. Li, J. Yang, and K. Zhao, “Are you in a masquerade? exploring the behavior
    and impact of large language model driven social bots in online social networks,”
    *arXiv preprint arXiv:2307.10337*, 2023.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] S. Li, J. Yang, 和 K. Zhao，“你在伪装吗？探索大型语言模型驱动的社交机器人在在线社交网络中的行为和影响，” *arXiv
    预印本 arXiv:2307.10337*，2023。'
- en: '[36] R. C. Atkinson and R. M. Shiffrin, “Human memory: A proposed system and
    its control processes,” in *Psychology of learning and motivation*.   Elsevier,
    1968, vol. 2, pp. 89–195.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] R. C. Atkinson 和 R. M. Shiffrin, “人类记忆：一个提议的系统及其控制过程，” 在 *心理学学习与动机*。 Elsevier,
    1968, vol. 2, pp. 89–195。'
- en: '[37] J. Wei, X. Wang, D. Schuurmans, M. Bosma, E. H. hsin Chi, F. Xia, Q. Le,
    and D. Zhou, “Chain of thought prompting elicits reasoning in large language models,”
    *ArXiv*, vol. abs/2201.11903, 2022.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] J. Wei, X. Wang, D. Schuurmans, M. Bosma, E. H. hsin Chi, F. Xia, Q. Le,
    和 D. Zhou, “思维链提示引发大型语言模型的推理，” *ArXiv*, vol. abs/2201.11903, 2022。'
- en: '[38] J. Ying, Y. Cao, K. Xiong, Y. He, L. Cui, and Y. Liu, “Intuitive or dependent?
    investigating llms’ robustness to conflicting prompts,” *ArXiv*, vol. abs/2309.17415,
    2023.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] J. Ying, Y. Cao, K. Xiong, Y. He, L. Cui, 和 Y. Liu, “直观还是依赖？调查大型语言模型对冲突提示的鲁棒性，”
    *ArXiv*, vol. abs/2309.17415, 2023。'
- en: '[39] N. MacKinnon and K. Schilling, “Optimal strategy for a number-guessing
    game: 11051,” *Am. Math. Mon.*, vol. 113, no. 1, pp. 81–82, 2006.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] N. MacKinnon 和 K. Schilling, “数字猜测游戏的最佳策略：11051，” *Am. Math. Mon.*, vol.
    113, no. 1, pp. 81–82, 2006。'
- en: '[40] X. Wang, “Two number-guessing problems plus applications in cryptography,”
    *Int. J. Netw. Secur.*, vol. 21, no. 3, pp. 494–500, 2019.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] X. Wang, “两个数字猜测问题及其在密码学中的应用，” *Int. J. Netw. Secur.*, vol. 21, no. 3,
    pp. 494–500, 2019。'
- en: '[41] K. Bahamazava and R. Nanda, “The shift of darknet illegal drug trade preferences
    in cryptocurrency: The question of traceability and deterrence,” *Digit. Investig.*,
    vol. 40, no. Supplement, p. 301377, 2022.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] K. Bahamazava 和 R. Nanda, “暗网非法药品交易偏好的加密货币转变：可追溯性和威慑的问题，” *Digit. Investig.*,
    vol. 40, no. Supplement, p. 301377, 2022。'
- en: '[42] K. Basu and A. Sen, “Monitoring individuals in drug trafficking organizations:
    a social network analysis,” in *ASONAM ’19: International Conference on Advances
    in Social Networks Analysis and Mining, Vancouver, British Columbia, Canada, 27-30
    August, 2019*.   ACM, 2019, pp. 480–483.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] K. Basu 和 A. Sen, “监控毒品贩运组织中的个人：社交网络分析，” 在 *ASONAM ’19: International
    Conference on Advances in Social Networks Analysis and Mining, Vancouver, British
    Columbia, Canada, 27-30 August, 2019*。 ACM, 2019, pp. 480–483。'
- en: '[43] F. Tsai, M. Hsu, C. Chen, and D. Kao, “Exploring drug-related crimes with
    social network analysis,” in *Knowledge-Based and Intelligent Information & Engineering
    Systems: Proceedings of the 23rd International Conference KES-2019, Budapest,
    Hungary, 4-6 September 2019*, vol. 159.   Elsevier, 2019, pp. 1907–1917.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] F. Tsai, M. Hsu, C. Chen, 和 D. Kao, “通过社交网络分析探索与毒品相关的犯罪，” 在 *Knowledge-Based
    and Intelligent Information & Engineering Systems: Proceedings of the 23rd International
    Conference KES-2019, Budapest, Hungary, 4-6 September 2019*, vol. 159。 Elsevier,
    2019, pp. 1907–1917。'
- en: '[44] S. Lyu and Z. Lu, “Exploring temporal and multilingual dynamics of post-disaster
    social media discourse: A case of fukushima daiichi nuclear accident,” *Proc.
    ACM Hum. Comput. Interact.*, vol. 7, no. CSCW1, pp. 1–24, 2023.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] S. Lyu 和 Z. Lu, “探索灾后社交媒体话语的时间和多语言动态：福岛第一核电站事故案例，” *Proc. ACM Hum. Comput.
    Interact.*, vol. 7, no. CSCW1, pp. 1–24, 2023。'
- en: '[45] E. Zarrabeitia-Bilbao, M. Jaca-Madariaga, R. M. Río-Belver, and I. Alvarez-Meaza,
    “Nuclear energy: Twitter data mining for social listening analysis,” *Soc. Netw.
    Anal. Min.*, vol. 13, no. 1, p. 29, 2023.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] E. Zarrabeitia-Bilbao, M. Jaca-Madariaga, R. M. Río-Belver, 和 I. Alvarez-Meaza,
    “核能：Twitter 数据挖掘用于社会听取分析，” *Soc. Netw. Anal. Min.*, vol. 13, no. 1, p. 29, 2023。'
