- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 18:51:35'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:51:35
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: LLM Based Multi-Agent Generation of Semi-structured Documents from Semantic
    Templates in the Public Administration Domain
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于LLM的多智能体生成公共行政领域的半结构化文档
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2402.14871](https://ar5iv.labs.arxiv.org/html/2402.14871)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2402.14871](https://ar5iv.labs.arxiv.org/html/2402.14871)
- en: '¹¹institutetext: Dept. of Computer, Control, and Management Engineering'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ¹¹机构文本：计算机、控制与管理工程系
- en: 'Sapienza University of Rome, Rome (Italy), ¹¹email: {lastname}@diag.uniroma1.it
    ²²institutetext: UNINT Univeristy, Via Cristoforo Colombo, 200 - 00147 Rome (Italy),
    ²²email: domenico.bloisi@unint.euEmanuele Musumeci [0009-0004-2359-5032](https://orcid.org/0009-0004-2359-5032
    "ORCID identifier") 11    Michele Brienza 11 [0009-0000-1549-9500](https://orcid.org/0009-0000-1549-9500
    "ORCID identifier")    Vincenzo Suriani 11 [0000−0003−1199−8358](https://orcid.org/0000%E2%88%920003%E2%88%921199%E2%88%928358
    "ORCID identifier")    Daniele Nardi 11 [0000-0001-6606-200X](https://orcid.org/0000-0001-6606-200X
    "ORCID identifier")    Domenico Daniele Bloisi 22 [0000−0003−0339−8651](https://orcid.org/0000%E2%88%920003%E2%88%920339%E2%88%928651
    "ORCID identifier")'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 罗马萨比恩扎大学，意大利罗马，¹¹电子邮件：{lastname}@diag.uniroma1.it ²²机构文本：UNINT大学，克里斯托福罗·哥伦布街200号，00147罗马（意大利），²²电子邮件：domenico.bloisi@unint.eu
    Emanuele Musumeci [0009-0004-2359-5032](https://orcid.org/0009-0004-2359-5032
    "ORCID identifier") 11    Michele Brienza 11 [0009-0000-1549-9500](https://orcid.org/0009-0000-1549-9500
    "ORCID identifier")    Vincenzo Suriani 11 [0000−0003−1199−8358](https://orcid.org/0000%E2%88%920003%E2%88%921199%E2%88%928358
    "ORCID identifier")    Daniele Nardi 11 [0000-0001-6606-200X](https://orcid.org/0000-0001-6606-200X
    "ORCID identifier")    Domenico Daniele Bloisi 22 [0000−0003−0339−8651](https://orcid.org/0000%E2%88%920003%E2%88%920339%E2%88%928651
    "ORCID identifier")
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: In the last years’ digitalization process, the creation and management of documents
    in various domains, particularly in Public Administration (PA), have become increasingly
    complex and diverse. This complexity arises from the need to handle a wide range
    of document types, often characterized by semi-structured forms. Semi-structured
    documents present a fixed set of data without a fixed format. As a consequence,
    a template-based solution cannot be used, as understanding a document requires
    the extraction of the data structure. The recent introduction of Large Language
    Models (LLMs) has enabled the creation of customized text output satisfying user
    requests. In this work, we propose a novel approach that combines the LLMs with
    prompt engineering and multi-agent systems for generating new documents compliant
    with a desired structure.The main contribution of this work concerns replacing
    the commonly used manual prompting with a task description generated by semantic
    retrieval from an LLM. The potential of this approach is demonstrated through
    a series of experiments and case studies, showcasing its effectiveness in real-world
    PA scenarios.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年的数字化过程中，各个领域，特别是公共行政（PA）中的文档创建和管理变得越来越复杂和多样化。这种复杂性源于需要处理各种类型的文档，通常以半结构化的形式存在。半结构化文档呈现固定的数据集，但没有固定的格式。因此，不能使用基于模板的解决方案，因为理解文档需要提取数据结构。最近引入的大型语言模型（LLMs）使得创建满足用户请求的定制化文本输出成为可能。在这项工作中，我们提出了一种新方法，将LLMs与提示工程和多智能体系统相结合，用于生成符合所需结构的新文档。这项工作的主要贡献在于用从LLM中通过语义检索生成的任务描述取代常用的手动提示。这种方法的潜力通过一系列实验和案例研究得到了验证，展示了其在实际公共行政场景中的有效性。
- en: 'Keywords:'
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Human-Centered AI Public Administration Task optimization
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 人本中心的人工智能公共行政任务优化
- en: 1 Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: '![Refer to caption](img/8adf03105dfa35542cd982d35d403e52.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/8adf03105dfa35542cd982d35d403e52.png)'
- en: 'Figure 1: The presented multi-agent architecture with the LLMs used in prompt
    engineering and multi-agent fashion for generating new documents.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：展示的多智能体架构与用于提示工程和多智能体模式生成新文档的LLMs。
- en: Document creation is a typical task in the Public Administration (PA) setting,
    requiring repetitive sub-tasks that offer the potential for automation. For instance,
    when writing official certificates required in public offices, the required personal
    information from the requesting user is often very schematic and constitutes only
    a small percentage of the text present in the document.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 文档创建是公共行政（PA）环境中的典型任务，需要重复的子任务，具有自动化的潜力。例如，在编写公共办公室所需的官方证书时，来自请求用户的个人信息通常是非常简化的，并且仅占文档中文本的一小部分。
- en: The use of pre-made document templates manages only marginally to reduce the
    effort spent and applies only to rigidly structured documents, where the semantics
    of missing information can be perfectly defined in the templates themselves. Automation
    of the writing of this kind of document, which amounts to field-filling, is straightforward.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 使用预制文档模板只能在一定程度上减少所花费的努力，并且仅适用于结构严格的文档，在这些文档中，缺失信息的语义可以在模板中被完美定义。这种文档的写作自动化，即填充字段，是直接的。
- en: Instead, semi-structured documents offer a flexible format, in which missing
    information cannot be clearly tagged and is usually determined by the semantics
    of the surrounding context. For instance, standard fields like the current date
    can appear in different positions in the document with no pre-defined criteria.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，半结构化文档提供了一种灵活的格式，其中缺失的信息不能被清晰标记，通常由周围上下文的语义决定。例如，像当前日期这样的标准字段可以出现在文档中的不同位置，没有预定义的标准。
- en: 'Producing this kind of document requires additional effort to adapt their flexible
    structure to the current use case and the available and required information,
    with additional effort to recover missing information. The semantics associated
    with the necessary information require some contextual knowledge, which can be
    gained by the surrounding context and sometimes the overall semantics of the whole
    document. For instance, different terms can be used for the qualification of the
    same field: e.g. "Invoice," "Invoice No." "Bill" and "Purchase Order" can all
    label the same information (the invoice number). For this reason, structure and
    semantics in a semi-structured document are usually intertwined, and developing
    an efficient document generation pipeline that can run for a wide variety of documents
    is a very challenging task.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 生成这种类型的文档需要额外的努力，以将其灵活的结构适应当前的使用案例以及可用和所需的信息，同时需要额外的努力来恢复缺失的信息。与所需信息相关的语义需要一些上下文知识，这可以通过周围的上下文以及有时整个文档的总体语义来获得。例如，相同领域的资格认证可以使用不同的术语：例如，“发票”，“发票号”，“账单”和“采购订单”都可以标记相同的信息（发票号码）。因此，半结构化文档中的结构和语义通常是交织在一起的，开发一个可以运行各种文档的高效文档生成管道是一个非常具有挑战性的任务。
- en: On these premises, the specific task of adapting semi-structured document templates
    can be supported by the use of Artificial Intelligence and in particular Language
    Models, to reduce the time spent automating the process and as a means to improve
    the generality of the automatic approach.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些前提下，适应半结构化文档模板的特定任务可以通过使用人工智能，特别是语言模型来支持，以减少自动化过程中的时间消耗，并作为提高自动化方法通用性的手段。
- en: A straightforward solution could be to generate and therefore refine a document
    in several incremental steps, with a separate prompt for each one, but this could
    hinder the quality of the result due to the potential dependencies between data
    in different parts of the same document, that might be located in structurally
    unrelated sections. A fully unsupervised approach would therefore run the risk
    of incurring in hallucination due to the limited effectiveness of long context
    windows for long document structures.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 一种简单的解决方案是生成并因此在多个增量步骤中完善文档，每个步骤有一个单独的提示，但这可能会影响结果的质量，因为不同部分的数据之间可能存在潜在的依赖关系，这些数据可能位于结构上不相关的部分。因此，完全无监督的方法可能会因长文档结构中长上下文窗口的有限效果而冒险产生虚假内容。
- en: Prompt engineering guidelines usually require providing preliminary and accurate
    context to the role of the LLM agent in the required task. Therefore it is possible
    to alter and improve the result on the same user request by prepending an accurate
    description of the role of the LLM agent to the actual user prompt.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程指南通常要求提供准确的上下文，以明确LLM代理在所需任务中的角色。因此，通过在实际用户提示之前附加准确的LLM代理角色描述，可以在相同的用户请求上改变和改进结果。
- en: Under these assumptions, it is possible to improve the incremental trial-and-error
    document generation by introducing several agents, each with a defined fine-grained
    role in the generation process. In this framework, the capabilities of each agent
    can be tuned by providing it with an accurate description of its role. Moreover,
    each agent can be augmented with a memory component local to the agent, sampled
    and applied specifically for its role, and with additional capabilities that compensate
    for the lacks of Language Models, such as interaction with the World Wide Web
    in real-time, access to private custom knowledge bases and information feeds to
    enhance agents with domain-specific knowledge, or the execution of specialized
    code as in a Function-as-a-Service framework. This kind of architecture is perfectly
    compatible with the emergent AI-as-a-Service (AIaaS) paradigm[[3](#bib.bib3)].
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些假设下，通过引入多个代理，每个代理在生成过程中具有定义明确的细粒度角色，可以改进逐步试错的文档生成。在这个框架中，可以通过提供准确的角色描述来调整每个代理的能力。此外，每个代理可以配备特定于其角色的内存组件，进行采样和应用，并具备弥补语言模型不足的额外能力，如实时与万维网互动、访问私人定制知识库和信息源，以增强代理的领域特定知识，或在Function-as-a-Service框架中执行专门的代码。这种架构与新兴的AI-as-a-Service（AIaaS）范式完全兼容[[3](#bib.bib3)]。
- en: The multi-agent process assists the user by iteratively refining the prompt
    with the guidance of a pre-existing structure extracted from similar documents.
    Then, context-specific prompts are provided to the various agents during the process,
    depending on their specific role and the original document structure, with little
    to no human supervision. Interaction between the agents, which is conversational
    in nature, can include direct interaction with the user in cases in which intervention
    is needed.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 多代理过程通过迭代地优化提示，并参考从类似文档中提取的预先存在的结构来协助用户。然后，根据代理的具体角色和原始文档结构，在过程中提供上下文特定的提示，几乎无需人类监督。代理之间的互动具有对话性质，在需要干预的情况下，可以包括与用户的直接互动。
- en: We present a workflow and interaction framework for the LLM-assisted multi-agent
    generation of a semi-structured document in the PA domain, with limited human
    supervision. We then show the prompt refinement process necessary to obtain the
    required results for each specific agent role in the current workflow.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们展示了一个工作流和交互框架，用于LLM辅助的多代理半结构化文档生成，涉及有限的人类监督。然后，我们展示了为了获得当前工作流中每个特定代理角色所需结果的提示优化过程。
- en: The code and the additional results obtained from this work can be found at
    the following webpage [https://sites.google.com/uniroma1.it/multi-agent-documentgeneration/home-page](https://sites.google.com/uniroma1.it/multi-agent-documentgeneration/home-page).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 该工作的代码和额外结果可以在以下网页找到 [https://sites.google.com/uniroma1.it/multi-agent-documentgeneration/home-page](https://sites.google.com/uniroma1.it/multi-agent-documentgeneration/home-page)。
- en: The remainder of the paper is organized as follows. Section [2](#S2 "2 Related
    Work ‣ LLM Based Multi-Agent Generation of Semi-structured Documents from Semantic
    Templates in the Public Administration Domain") contains a description of the
    state of the art. Section [3](#S3 "3 Proposed Approach ‣ LLM Based Multi-Agent
    Generation of Semi-structured Documents from Semantic Templates in the Public
    Administration Domain") presents the description of the workflow and interaction
    framework. The prompt refinement process is then shown in Section [4](#S4 "4 Experimental
    Evaluation ‣ LLM Based Multi-Agent Generation of Semi-structured Documents from
    Semantic Templates in the Public Administration Domain"). Finally, conclusions
    are drawn in Section [5](#S5 "5 Conclusions ‣ 4.4 Prompt-engineered results ‣
    4.3 Content Generation Agent ‣ 4.1 Semantics Identification Agent ‣ 4 Experimental
    Evaluation ‣ LLM Based Multi-Agent Generation of Semi-structured Documents from
    Semantic Templates in the Public Administration Domain").
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 论文的其余部分组织如下。第[2](#S2 "2 Related Work ‣ LLM Based Multi-Agent Generation of Semi-structured
    Documents from Semantic Templates in the Public Administration Domain")节包含最新技术的描述。第[3](#S3
    "3 Proposed Approach ‣ LLM Based Multi-Agent Generation of Semi-structured Documents
    from Semantic Templates in the Public Administration Domain")节展示了工作流和交互框架的描述。第[4](#S4
    "4 Experimental Evaluation ‣ LLM Based Multi-Agent Generation of Semi-structured
    Documents from Semantic Templates in the Public Administration Domain")节展示了提示优化过程。最后，第[5](#S5
    "5 Conclusions ‣ 4.4 Prompt-engineered results ‣ 4.3 Content Generation Agent
    ‣ 4.1 Semantics Identification Agent ‣ 4 Experimental Evaluation ‣ LLM Based Multi-Agent
    Generation of Semi-structured Documents from Semantic Templates in the Public
    Administration Domain")节总结了结论。
- en: 2 Related Work
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: Since their release to the public, Large Language Models (LLMs) have shown great
    potential for a wide range of daily tasks [[10](#bib.bib10)]. In particular, their
    capabilities in document editing and generation use-cases offer great potential
    for their successful application to the PA domain. Most LLMs have shown greater
    performance in zero-shot [[5](#bib.bib5)] and in particular few-shot[[4](#bib.bib4)]
    tasks, where examples of acceptable results are provided along with the instructions
    for the task to be executed.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 自公开发布以来，大型语言模型（LLMs）在广泛的日常任务中展示了巨大潜力[[10](#bib.bib10)]。特别是，它们在文档编辑和生成用例中的能力，为它们在PA领域的成功应用提供了巨大潜力。大多数LLMs在零样本[[5](#bib.bib5)]，特别是少样本[[4](#bib.bib4)]任务中表现出了更高的性能，其中提供了可接受结果的示例以及执行任务的指令。
- en: It has been shown that better results can be obtained by applying guidelines
    for prompt engineering [[16](#bib.bib16)]. Usually, when a human is involved,
    the prompt refinement becomes a trial-and-error process, by improving the final
    result by incremental changes to the initial prompt, based on the generated output.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 已经证明，通过应用提示工程的指导原则，可以获得更好的结果[[16](#bib.bib16)]。通常，当有人参与时，提示的改进变成了一个反复试验的过程，通过对初始提示进行逐步改进来提升最终结果，基于生成的输出。
- en: Prompt engineering proved to be a crucial step both for the average and advanced
    users in applications of LLMs to the production of semi-structured documents,
    where the original structure requires subsequent adaptations through a trial-and-error
    process. Through prompt engineering, it is possible to improve the quality of
    the output obtained and especially its compliance with contextual specifications
    regarding the required content and style. For this reason, the main challenge
    of allowing PA entities to successfully integrate LLMs in their workflows is to
    enable the inexperienced user to create efficient prompts and to minimize the
    time spent improving the task description provided as a prompt to the Large Language
    Model.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程被证明是LLMs在生产半结构化文档中的应用中，平均用户和高级用户都需要的重要步骤，其中原始结构需要通过反复试验过程进行后续调整。通过提示工程，可以提高输出结果的质量，特别是其与要求的内容和风格的上下文规范的符合度。因此，允许PA实体成功将LLMs整合到其工作流程中的主要挑战是使缺乏经验的用户能够创建有效的提示，并减少改进提供给大型语言模型的任务描述所花费的时间。
- en: As a trade-off for their versatility, LLMs incur in the problem of hallucination,
    causing results to be skewed and inaccurate or biased with respect to the original
    requests, especially with longer context windows. In the document generation task,
    especially for the generation of longer documents, prompts might tend to be long
    and rich in information, with the risk of causing hallucinations.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 作为其多功能性的权衡，LLMs会出现幻觉问题，导致结果偏差、不准确或相对于原始请求有偏见，特别是在较长的上下文窗口中。在文档生成任务中，特别是在生成较长文档时，提示可能趋向于长且信息丰富，有引发幻觉的风险。
- en: 2.1 LLMs in the PA Domain
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 PA领域中的LLMs
- en: The integration of Large Language Models (LLMs) in automating document generation
    processes, particularly in the domain of PA, has seen significant interest due
    to the amount of document manipulation required in this domain. Some works are
    helping in information extraction from those documents, for example, when dealing
    with extracting and classifying relations from tenders of the PA [[12](#bib.bib12)].
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）在自动化文档生成过程中的整合，特别是在PA领域，由于该领域对文档处理的需求量大，已引起了显著的关注。一些研究正在帮助从这些文档中提取信息，例如，在处理从PA招标中提取和分类关系时[[12](#bib.bib12)]。
- en: Prior studies are nowadays predominantly focused on leveraging LLMs for structured
    data extraction, text summarization, and content customization [[7](#bib.bib7)]
    to enhance administrative efficiency and user engagement. Prompt engineering has
    shown relevant results in improving the LLM’s generation capabilities[[16](#bib.bib16)],
    and, with guiding principles, LLMs can meet requirements and allow for enhanced
    quality in response [[1](#bib.bib1)].
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 目前的研究主要集中在利用LLMs进行结构化数据提取、文本总结和内容定制[[7](#bib.bib7)]，以提高行政效率和用户参与度。提示工程在提升LLM的生成能力方面显示了相关结果[[16](#bib.bib16)]，并且，通过指导原则，LLMs可以满足要求，并提高响应质量[[1](#bib.bib1)]。
- en: An approach for information extraction for unstructured documents is presented
    in [[9](#bib.bib9)], where an embedding-based retrieval system with LLM is used
    for effective agriculture information extraction from unstructured data. The system
    features an embedding-based retrieval system along with LLM question-answering
    to automatically extract entities and attributes from the documents, and transform
    them into structured data.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[[9](#bib.bib9)] 中提出了一种用于非结构化文档的信息提取方法，其中使用基于嵌入的检索系统与 LLM 结合，以有效地从非结构化数据中提取农业信息。该系统结合了基于嵌入的检索系统和
    LLM 问答，自动提取文档中的实体和属性，并将其转换为结构化数据。'
- en: When dealing with novel documents, also Retrieval-augmented generation (RAG)
    approaches allow large language models (LLM) to retrieve relevant knowledge, showing
    promising potential in mitigating LLM hallucinations and enhancing response quality,
    and, chance, facilitating the adoption of LLMs in practice [[2](#bib.bib2)]. However,
    existing RAG systems are often inadequate in answering multi-hop queries, which
    require retrieving and reasoning over iteratively. An improvement of this technology
    has been proposed in [[14](#bib.bib14)] where multi-hop reasoning steps are introduced
    in the RAG system.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理新文档时，检索增强生成 (RAG) 方法也允许大语言模型 (LLM) 检索相关知识，展示了在减轻 LLM 幻觉和提高响应质量方面的良好潜力，并有可能促进
    LLM 在实践中的采用 [[2](#bib.bib2)]。然而，现有的 RAG 系统在回答需要多次检索和推理的多跳查询时通常不够充分。 [[14](#bib.bib14)]
    提出了这一技术的改进，其中在 RAG 系统中引入了多跳推理步骤。
- en: The difficulties are even more common when dealing with the application of LLMs
    in generating semi-structured documents from semantically similar examples. This
    remains relatively unsolved and they still struggle with tasks that require generating
    complex, structured outputs [[13](#bib.bib13)]. This gap is primarily due to the
    inherent complexity of semi-structured documents, which defy conventional template-based
    approaches. Several approaches have been proposed to handle them. A notable example
    is represented by [[15](#bib.bib15)], where Chain-Of-Thought is presented as a
    series of intermediate reasoning steps that significantly improve the ability
    of large language models to perform complex reasoning. In particular, it is shown
    how such reasoning abilities emerge naturally in sufficiently large language models.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理从语义相似示例生成半结构化文档的 LLM 应用时，这些困难变得更加普遍。这一问题仍未得到解决，它们在生成复杂、结构化输出的任务上仍然存在困难 [[13](#bib.bib13)]。这种差距主要是由于半结构化文档的固有复杂性，这些文档挑战了传统的基于模板的方法。已提出几种处理这些文档的方法。一个显著的例子是
    [[15](#bib.bib15)]，其中链式思维被呈现为一系列中间推理步骤，显著提高了大语言模型执行复杂推理的能力。特别是，这种推理能力如何在足够大的语言模型中自然地出现也得到了展示。
- en: A closer step in the generation of semi-structured documents is represented
    by the Directional Stimulus Prompting Technology [[8](#bib.bib8)], where the LLM
    output is conditioned to generate desired outcomes, such as including specific
    keywords. The research on semantic understanding and context-aware generation
    provides foundational insights but stops short of addressing the specific challenges
    posed by semi-structured documents in PA.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 半结构化文档生成的一个更近的步骤是由方向性刺激提示技术 [[8](#bib.bib8)] 代表的，其中 LLM 输出经过条件化以生成期望的结果，例如包括特定的关键词。关于语义理解和上下文感知生成的研究提供了基础性的见解，但未能解决
    PA 中半结构化文档所带来的具体挑战。
- en: Furthermore, the Artificial Intelligence as a Service (’AIaaS’) trend [[3](#bib.bib3)]
    is going to play a growing role in society’s technological infrastructure, enabling,
    facilitating, and underpinning functionality in many applications. AIaaS providers
    therefore hold significant power at this infrastructural level and with the upcoming
    legislations in Europe, their role can easily be diffused in the workflow of the
    public offices. The AIaaS approach aligns also with our proposed multi-agent approach
    in document generation tasks. The multi-agent approach has been demonstrated to
    improve problem-solving in overcoming the limitations of individual models [[11](#bib.bib11)].
    In the PA domain, this distributed approach offers modularity and scalability,
    potentially suitable for handling various document types and complexities within
    PA settings.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，人工智能即服务（’AIaaS’）趋势[[3](#bib.bib3)]将在社会的技术基础设施中发挥越来越重要的作用，启用、促进并支撑许多应用的功能。因此，AIaaS提供商在这一基础设施层面上拥有重要权力，并且随着欧洲即将出台的立法，其角色可以很容易地渗透到公共办公室的工作流程中。AIaaS方法也与我们提出的文档生成任务中的多智能体方法一致。多智能体方法已被证明能改善解决问题，克服单个模型的局限性[[11](#bib.bib11)]。在PA领域，这种分布式方法提供了模块化和可扩展性，可能适合处理PA环境中的各种文档类型和复杂性。
- en: In summary, while the literature provides valuable perspectives on the capabilities
    and applications of LLMs in various contexts, our work contributes a novel methodology
    and interaction framework for the LLM-assisted semi-structured document generation
    in PA, including multi-agent assistance in document generation and paving the
    way for further innovation and exploration in this domain.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，虽然文献提供了关于LLM在不同背景下能力和应用的宝贵观点，我们的工作贡献了一种新颖的方法论和交互框架，用于LLM辅助的半结构化文档生成，包括多智能体协助文档生成，并为这一领域的进一步创新和探索铺平了道路。
- en: 3 Proposed Approach
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 提议的方法
- en: The usual interaction model between an LLM and an inexperienced user for document
    generation features a trial-and-error process, aimed at refining the prompt until
    a satisfying result is reached. Longer prompts are required for longer documents,
    making it even more difficult to obtain a satisfying result. Moreover, in detail-rich
    documents, the performance of LLM agents is bound to decrease when document generation
    requires many tasks to be completed.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: LLM与缺乏经验的用户之间用于文档生成的通常交互模型采用试错过程，旨在细化提示直到达到令人满意的结果。较长的文档需要更长的提示，这使得获得令人满意的结果变得更加困难。此外，在详细信息丰富的文档中，当文档生成需要完成许多任务时，LLM代理的性能必然会下降。
- en: Given the requirement for user supervision in a trial-and-error process, we
    propose a different workflow aimed at minimizing user intervention. The proposed
    process, iterative in nature, follows the overall structure of a document template,
    which can be extracted from a pre-existing template document provided by the user
    as input.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于试错过程对用户监督的要求，我们提出了一种不同的工作流程，旨在最小化用户干预。所提议的过程具有迭代性质，遵循文档模板的整体结构，该模板可以从用户提供的预先存在的模板文档中提取。
- en: The user is allowed to provide an initial prompt to describe the overall expected
    result. The initial prompt is then refined throughout iterations, to hold all
    the missing data required to generate the document, accumulating in the original
    prompt the outcomes of user interventions whenever requested by the agents. The
    *accumulated prompt* will serve as a data source throughout the document generation
    steps. Following the structure of the template document, the output document is
    then generated section-by-section, in reading order.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 用户可以提供初始提示以描述总体预期结果。初始提示随后在迭代过程中被细化，以包含生成文档所需的所有缺失数据，累积在原始提示中，以便在智能体请求时包含用户干预的结果。*累积提示*将作为文档生成步骤中的数据来源。根据模板文档的结构，输出文档随后按顺序生成各个部分。
- en: During the generic generation step, LLM agents are interrogated to solve fine-grained
    tasks depending on the availability of the information required to generate semantically
    suitable content for the current section, according to the semantics provided
    in the corresponding section in the template document. Each agent is instructed
    with a previously engineered prompt, describing its task, which is then completed
    by context-dependent information, depending on the semantics of the current section
    and the data extracted from the *accumulated prompt*.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在通用生成步骤中，LLM 智能体被询问以解决细粒度任务，这取决于生成当前部分的语义上合适的内容所需的信息的可用性，依据模板文档中相应部分提供的语义。每个智能体都被指示以先前设计的提示，描述其任务，然后由上下文相关的信息补充，具体取决于当前部分的语义和从*累积提示*中提取的数据。
- en: The multi-agent framework allows specializing agents as much as necessary to
    prevent hallucinations, in sections where available contextual pieces of information
    are prone to provide undesired results (like what could happen in case the provided
    context is very short or the text is very schematic). Post-processing may be applied
    to improve the results, especially if a schematic output is expected, by explicitly
    asking the LLM agents to return specific tokens in case some conditions are met,
    as a way to force them to not hallucinate and comply with their role in the workflow.
    Detecting these tokens in the output may help in managing limit cases that would
    otherwise disrupt the workflow, improving the overall system robustness.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 多智能体框架允许对智能体进行必要的专业化，以防止在可用的上下文信息容易产生不希望结果的部分（如在提供的上下文非常简短或文本非常概括的情况下）出现幻觉。可以应用后处理以改进结果，特别是在期望得到概括性输出的情况下，通过明确要求
    LLM 智能体在满足某些条件时返回特定的标记，以迫使它们不产生幻觉并遵守其在工作流程中的角色。检测这些标记可能有助于管理那些会干扰工作流程的极限情况，从而提高系统的整体鲁棒性。
- en: 'User intervention is required only in case the pieces of information retrievable
    from the *accumulated prompt* are not enough to comply with the semantics of the
    current document section, so the frequency of user intervention depends on the
    quality of the initial prompt. The advantage of this approach is that the *accumulated
    prompt* is used only as a data source: in this way, the agent tasked with extracting
    data from the prompt is less prone to hallucinate when the user prompt is not
    complete or clear. After user intervention, the new data provided by the user
    is added to the *accumulated prompt*, to be stored for future retrievals.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 只有在从*累积提示*中检索到的信息不足以符合当前文档部分的语义时才需要用户干预，因此用户干预的频率取决于初始提示的质量。这种方法的优点是*累积提示*仅作为数据源使用：这样，当用户提示不完整或不明确时，负责从提示中提取数据的智能体不容易产生幻觉。在用户干预后，新提供的数据将被添加到*累积提示*中，以便将来检索。
- en: '![Refer to caption](img/ac51bac73c79953074d26de10ee9e766.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/ac51bac73c79953074d26de10ee9e766.png)'
- en: 'Figure 2: Representation of our multi-agent architecture. The workflow for
    the generic generation step is highlighted by the bold black arrows.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：我们多智能体架构的表示。通用生成步骤的工作流程由粗体黑色箭头突出显示。
- en: To ensure flexibility in the emulation of the original document template, the
    user is allowed to optionally skip the generation of a document section at any
    time, leaving the accumulated prompt unaltered. A representation of the workflow
    obtained according to this interaction model is shown in Fig. [2](#S3.F2 "Figure
    2 ‣ 3 Proposed Approach ‣ LLM Based Multi-Agent Generation of Semi-structured
    Documents from Semantic Templates in the Public Administration Domain").
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保在模拟原始文档模板时的灵活性，用户可以选择在任何时候跳过生成文档部分，从而保持累积提示不变。根据这种交互模型获得的工作流程表示如图 [2](#S3.F2
    "图 2 ‣ 3 提议的方法 ‣ 基于 LLM 的多智能体从公共管理领域的语义模板生成半结构化文档") 所示。
- en: Although our work focuses on the components atomically necessary to generate
    a document section-by-section, the presented interaction model allows the integration
    of additional agents to manage different aspects of document editing, depending
    on the level of structuring of the document and the level of expertise required
    by the specific task assigned to the agent.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们的工作专注于生成文档部分所需的基本组件，但所呈现的交互模型允许集成额外的智能体来管理文档编辑的不同方面，具体取决于文档的结构化程度以及分配给智能体的任务所需的专业知识水平。
- en: 3.1 Template Pre-processing
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 模板预处理
- en: The document structure can be extracted on a format-dependent basis, using pre-existing
    tools. In our case, we used a REST API interface for cloud-based processing using
    the Adobe Extraction API¹¹1[https://developer.adobe.com/document-services/docs/overview/pdf-extract-api/](https://developer.adobe.com/document-services/docs/overview/pdf-extract-api/),
    to extract bounding boxes and contents from figures, text blocks, and tables in
    the document. It is not important to deduce the field semantics at this stage
    as we only need structural cues for the next steps.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 文档结构可以根据格式依赖提取，使用现有工具。在我们的案例中，我们使用了Adobe Extraction API¹¹1[https://developer.adobe.com/document-services/docs/overview/pdf-extract-api/](https://developer.adobe.com/document-services/docs/overview/pdf-extract-api/)
    的REST API接口进行基于云的处理，以提取文档中的图形、文本块和表格的边界框和内容。在这个阶段，推断字段语义并不重要，因为我们只需要结构线索用于下一步。
- en: 3.2 Multi-agent Interaction
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 多代理交互
- en: The user is invited to provide an initial prompt giving an overall description
    and directives for the generated document, such as more general qualities like
    style or tone of the text or more specific information and data necessary for
    document generation. It is possible to leave the initial prompt empty, in which
    case the maximum level of user intervention will be required throughout the generation
    process.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 用户被邀请提供一个初始提示，给出生成文档的总体描述和指示，例如文本的风格或语调等更一般的特征，或生成文档所需的更具体的信息和数据。可以将初始提示留空，在这种情况下，生成过程将需要最大程度的用户干预。
- en: 'The current workflow features a set of three LLM-based agents, each corresponding
    to a phase of the generic content generation step for a single document section,
    in order: *Section Semantics Identification*, *Information Retrieval*, *Content
    Generation*.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的工作流程包含一组三个基于LLM的代理，每个代理对应于单个文档章节的一阶段内容生成步骤，依次是：*章节语义识别*、*信息检索*、*内容生成*。
- en: The *Section Semantics Identification* step is aimed at identifying the semantics
    of the current section from the document template. In case the template section
    contains tokens that need to be replaced in the current document section, which
    can appear as placeholders, such as "Name", "Surname", "Birthday", "City" or explicitly
    already populated with data, such as "John", "Doe", "01/01/1970", "Washington",
    the usual Natural Language Processing pipeline to perform Entity recognition and
    Semantic parsing on a sentence would generally require performing several preliminary
    tasks such as Part-of-Speech tagging, Named Entity Recognition, Relationship Extraction,
    before the actual semantic tagging of tokens, to build a semantic representation
    of the sentence good enough to extract the tokens of interest correctly. Using
    LLMs for this task allows instead exploiting their Commonsense Knowledge [[6](#bib.bib6)].
    This step is therefore managed by the first LLM agent, the *Semantics Identification
    agent*, which autonomously identifies the semantics of the current section from
    the template document, identifying replaceable data in the provided template section.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '*章节语义识别* 步骤旨在从文档模板中识别当前章节的语义。如果模板章节包含需要在当前文档章节中替换的标记，这些标记可能以占位符的形式出现，例如“姓名”、“姓氏”、“生日”、“城市”或已明确填充的数据，例如“约翰”、“杜”、“01/01/1970”、“华盛顿”，那么通常的自然语言处理流程会涉及多个预处理任务，例如词性标注、命名实体识别、关系提取，然后才是实际的标记语义，以构建一个足够好的语义表示，从而正确提取感兴趣的标记。使用大型语言模型（LLMs）来完成这项任务，则可以利用它们的常识知识[[6](#bib.bib6)]。因此，这一步由第一个LLM代理，即*语义识别代理*来管理，该代理能够自主地从模板文档中识别当前章节的语义，识别提供的模板章节中可替换的数据。'
- en: The agent output is a list of directives and instructions on how to reproduce
    the semantics of the corresponding template, whenever the text allows deducing
    it, serving as instructions for the *Content Generation* phase, along with a list
    of identified replaceable data. In case the semantics of any of such data are
    identified, the list of instructions will contain directives on how to add them
    to the text generated for the corresponding section in the output document. Using
    only a schematic representation of the semantics as an output causes a degradation
    in the quality of the generated content downstream, therefore the instructions
    provided by the agent are discursive and verbose. The output of this phase will
    be provided to the *Information Retrieval agent*, to identify data required in
    the current section, and the *Content Generation agent*, enabling it to reconstruct
    the semantics of this template section in the output document.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 代理输出是一系列指令和说明，告知如何重现相应模板的语义，只要文本允许推断出这些语义，这些指令将作为*内容生成*阶段的指导，以及识别出的可替代数据列表。如果识别出这些数据的语义，指令列表将包含如何将它们添加到生成的输出文档中相应部分的指令。仅使用语义的示意表示作为输出会导致下游生成内容质量的下降，因此代理提供的指令是详尽而冗长的。此阶段的输出将提供给*信息检索代理*，以识别当前部分所需的数据，并提供给*内容生成代理*，使其能够在输出文档中重建该模板部分的语义。
- en: It should be noted that the list of replaceable data might contain data that
    is already available in the accumulated user prompt as well as missing data. For
    this reason, the second phase, destined to *Information Retrieval*, is aimed at
    using the available information to retrieve the data specifically required by
    the current document section, according to the semantic cues previously extracted.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 应当注意，替代数据列表可能包含已经在累积用户提示中存在的数据以及缺失的数据。因此，第二阶段，即*信息检索*阶段，旨在使用现有的信息来检索当前文档部分所需的数据，根据之前提取的语义线索。
- en: The second agent, the *Information Retrieval agent*, is specialized in extracting
    the required information from the accumulated prompt, which at the first step
    coincides with the initial prompt, and determining which data could not be retrieved.
    In case it is not possible to find all the required data (according to the instructions
    from the *Semantics Identification agent*), user intervention is required, to
    specify through a textual prompt the actual replacement values for the missing
    data. The result of this interaction is added to the *accumulated prompt*, to
    be used by the *Content Generation agent* as a data source, or to be stored for
    the *Information Retrieval* phase of later iterations. Therefore, if the user
    decides not to specify some information, they will not be integrated into the
    result and will be ignored in the output content.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个代理，即*信息检索代理*，专门负责从累积提示中提取所需信息，这在第一步与初始提示相符，并确定哪些数据无法检索。如果无法找到所有所需的数据（根据*语义识别代理*的指示），则需要用户介入，通过文本提示指定缺失数据的实际替代值。这次交互的结果会被添加到*累积提示*中，供*内容生成代理*作为数据源使用，或者存储用于后续迭代的*信息检索*阶段。因此，如果用户决定不指定某些信息，它们将不会被整合到结果中，并在输出内容中被忽略。
- en: As a last step, during the *Content Generation* phase, the *Content Generation
    agent* is therefore instructed to generate the textual content for the current
    document section, using the *accumulated prompt*, now enriched with the required
    information, and the instructions coming from the *Semantics Identification agent*.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后一步，在*内容生成*阶段，*内容生成代理*将被指示生成当前文档部分的文本内容，使用已经丰富了所需信息的*累积提示*，以及来自*语义识别代理*的指示。
- en: '![Refer to caption](img/61742cc25996b8138b38032f4cd9d0dc.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/61742cc25996b8138b38032f4cd9d0dc.png)'
- en: 'Figure 3: Representation of a generation step instance. Notice how the *accumulated
    prompt* is enriched with the missing data provided by the user.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：生成步骤实例的表示。请注意，*累积提示*如何被用户提供的缺失数据所丰富。
- en: At the end, both an output document and a refined prompt are obtained. In particular,
    the refined prompt will contain all the missing data identified throughout the
    generation process. An example of a workflow instance is shown in Fig. [3](#S3.F3
    "Figure 3 ‣ 3.2 Multi-agent Interaction ‣ 3 Proposed Approach ‣ LLM Based Multi-Agent
    Generation of Semi-structured Documents from Semantic Templates in the Public
    Administration Domain").
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，将获得一个输出文档和一个精细化的提示。特别是，精细化的提示将包含在生成过程中识别出的所有缺失数据。一个工作流实例的示例见图 [3](#S3.F3
    "图 3 ‣ 3.2 多代理交互 ‣ 3 提议的方法 ‣ 基于 LLM 的多代理半结构化文档生成（公共行政领域）")。
- en: 3.3 Document Post-processing
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 文档后处理
- en: During the document generation, only text content is processed, while the same
    structure of the original template document is used, including figures and other
    graphical elements, which can be skipped by the user during the generation process
    to avoid including them. Thanks to the modularity of this framework, additional
    agents can be added to improve the graphical appearance and improve its dependence
    on the context and the semantics of the user requirements, and additional processing
    steps can be added downstream to improve the graphical appearance of the result
    (for example by generating context-dependent images) but this is outside of the
    scope of the current work.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在文档生成过程中，只处理文本内容，同时使用原始模板文档的相同结构，包括图形和其他图形元素，这些图形和图形元素可以在生成过程中由用户跳过以避免包括它们。由于这个框架的模块化，可以添加额外的代理来改善图形外观，并改善其对上下文和用户需求语义的依赖，此外，还可以在下游添加额外的处理步骤以改善结果的图形外观（例如通过生成上下文相关的图像），但这超出了当前工作的范围。
- en: 4 Experimental Evaluation
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实验评估
- en: Agents were built using the latest OpenAI *GPT 3.5 Turbo* model (*gpt-3.5-turbo-1106*)
    with a context window of 16,385 tokens and a maximum of 4,096 output tokens.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 代理是使用最新的 OpenAI *GPT 3.5 Turbo* 模型 (*gpt-3.5-turbo-1106*) 构建的，具有 16,385 个 tokens
    的上下文窗口和最多 4,096 个输出 tokens。
- en: '| Prompt engineering for the Semantics Identification Agent |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 语义识别代理的提示工程 |'
- en: '| --- |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| Template text: *Your Name* |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 模板文本: *你的名字* |'
- en: '| Agent task | Agent answer |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 代理任务 | 代理回答 |'
- en: '| You are an assistant helping to understand the structure content of a template
    document. Respond with the content that might be written in the document. | [Your
    Name] [Your Address]'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '| 你是一个助手，帮助理解模板文档的结构内容。回应文档中可能写入的内容。 | [你的名字] [你的地址]'
- en: '[City, State, Zip Code]'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[城市, 州, 邮政编码]'
- en: '[Email Address]'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[电子邮件地址]'
- en: '[Phone Number] |'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[电话号码] |'
- en: '| You are an assistant helping to understand the structure content of a template
    document. Respond with the content that might be written in the document. Give
    just the action to do. | Fill in your full legal name. |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 你是一个助手，帮助理解模板文档的结构内容。回应文档中可能写入的内容。仅给出要执行的操作。 | 填写你的全名。 |'
- en: '| You are an assistant helping to understand the structure content of a template
    document. Respond with the content that might be written in the document. Give
    just the action to do. For example, if you read "Location", the output will be
    "Add the location"; if you read "Dear Someone", the output will be "Add salutation".
    | Add your full name |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 你是一个助手，帮助理解模板文档的结构内容。回应文档中可能写入的内容。仅给出要执行的操作。例如，如果你看到“地点”，则输出为“添加地点”；如果你看到“亲爱的某人”，则输出为“添加称呼”。
    | 添加你的全名 |'
- en: 'Table 1: Agent task prompt refinement for Semantics Identification Agent, with
    template text "*Your name*"'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '表 1: 语义识别代理的任务提示细化，模板文本 "*你的名字*"'
- en: .
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: Experiments are aimed at designing an effective prompt for each agent, by performing
    a trial-and-error process to obtain a correct and contextually appropriate response
    from the LLMs.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 实验旨在为每个代理设计一个有效的提示，通过进行试错过程来获得 LLMs 的正确且符合上下文的回应。
- en: The evaluation process tests the agents’ ability to understand the assigned
    tasks, fine-tuning each agent’s ability to conform to the expected outputs, given
    their specific role in the generation workflow.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 评估过程测试了代理的理解分配任务的能力，微调每个代理在生成工作流中的特定角色下符合预期输出的能力。
- en: The process of crafting an effective prompt that maximizes conformity of the
    output of a Large Language Model to the original requirements has the potential
    to dramatically improve the quality of the generated output, especially when this
    output is used in an intermediate step of a processing pipeline. The baseline
    version of the prompt point is obtained by following general prompt engineering
    guidelines [[16](#bib.bib16)], the most important one consisting of writing in
    a clear and imperative tone the task assignment for the LLM. Starting from the
    baseline and analyzing the response, it is then possible to refine the prompt
    in incremental steps, by adding instructions to force the model toward a more
    desirable output.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 制作有效提示的过程，可以最大程度地使大型语言模型的输出符合原始要求，从而显著提升生成输出的质量，尤其是当这些输出用于处理管道的中间步骤时。提示点的基准版本是通过遵循一般的提示工程指南[[16](#bib.bib16)]获得的，其中最重要的一条是以清晰而命令式的语气写出LLM的任务分配。基于基准版本并分析响应后，可以逐步细化提示，通过添加指令来迫使模型朝着更理想的输出方向发展。
- en: The most important undesirable behavior to keep under control is the chance
    for hallucination, which in this case can alter the data in the generated content
    and therefore provide false and unsatisfying textual content for the document
    section being generated.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 最需要控制的不良行为是产生幻觉的可能性，这种情况会改变生成内容中的数据，从而为正在生成的文档部分提供虚假且不令人满意的文本内容。
- en: 'Each prompt consists of two components: a "*system prompt*" containing the
    pre-assigned instructions used to inform the agent of its specific task, instructing
    it with its role and the guidelines for the generation of its output, and a "*context-specific
    prompt*", which contains the actual context-specific text for the current instance
    of the agent’s task.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 每个提示由两个组成部分构成：一个包含预分配指令的"*系统提示*"，用于告知代理其具体任务，指导其角色及生成输出的指南，以及一个"*上下文特定提示*"，其中包含当前代理任务实例的实际上下文特定文本。
- en: Obtaining a robustly engineered prompt requires careful tuning, considering
    the variety of possible inputs in a semi-structured document. On one hand, very
    schematic text consisting of single entities (such as "First name", "Last name"
    and other specific data) poses a challenge and requires more carefully engineered
    prompts. On the other hand, output should still be desirable in the case of less
    schematic, more discursive sections. The generic input for the generation step,
    which will be forwarded to the *Semantics identification agent*, is the textual
    content of the currently processed template document section, which is necessary
    to obtain semantic cues about the desired output text.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 获得一个稳健工程化的提示需要仔细调整，考虑到半结构化文档中可能出现的各种输入。一方面，非常图示化的文本（例如"名字"、"姓氏"和其他具体数据）会带来挑战，需要更仔细地设计提示。另一方面，对于不那么图示化、更具讨论性的部分，输出仍应令人满意。生成步骤的通用输入，即将转发给*语义识别代理*的内容，是当前处理的模板文档部分的文本内容，这对于获取有关期望输出文本的语义线索是必要的。
- en: The output of the generation step coincides with the output from the *Content
    generation agent*.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 生成步骤的输出与*内容生成代理*的输出一致。
- en: 4.1 Semantics Identification Agent
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 语义识别代理
- en: The *Semantics Identification agent* is tasked with producing a discursive and
    fluent explanation of the semantics of the current document section and most importantly
    of the instructions and directives for the generation of the content to be included
    in the output document, based on the expected semantics. To avoid hallucinations
    it is extremely important to have a non-schematic and unspecific description of
    the semantics of the current document section.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*语义识别代理*的任务是基于期望的语义，生成当前文档部分的语义以及生成输出文档中所包含内容的指令和指导方针的详细且流畅的解释。为了避免产生幻觉，必须对当前文档部分的语义进行非图示化和不具体的描述。'
- en: We show the prompt engineering process based on the answers of the same agent
    to different *system prompts*, progressively refined in incremental steps, for
    different template texts, in order of increasing verbosity of the *context-specific
    prompt* (therefore in decreasing order of schematism).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们展示了基于同一代理对不同*系统提示*的回答的提示工程过程，这些提示经过逐步细化，适用于不同的模板文本，按照*上下文特定提示*的逐步详细化顺序（因此是图示化的递减顺序）。
- en: The first more schematic template text is "*Your name*", as could be found in
    any template document for a generic letter, in a field where the name of the user
    is required. The relevant results for this refinement process are provided in
    Tables [1](#S4.T1 "Table 1 ‣ 4 Experimental Evaluation ‣ LLM Based Multi-Agent
    Generation of Semi-structured Documents from Semantic Templates in the Public
    Administration Domain").
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个更具示意性的模板文本是"*你的名字*"，可以在任何通用信件的模板文档中找到，这个字段用于填写用户的名字。有关此优化过程的相关结果见表[1](#S4.T1
    "表1 ‣ 4 实验评估 ‣ 基于LLM的多代理生成半结构化文档的语义模板在公共行政领域的应用")。
- en: '| Prompt engineering for the Semantics Identification Agent |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 语义识别代理的提示工程 |'
- en: '| --- |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| Template text: *Dear Mr./Ms. (Lastname):* |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 模板文本：*尊敬的先生/女士（姓氏）：* |'
- en: '| Agent task | Agent answer |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 代理任务 | 代理回答 |'
- en: '| You are an assistant helping to understand the structure content of a template
    document. Respond with the content that might be written in the document. | I
    hope this message finds you well. I am writing to inform you about the upcoming
    meeting scheduled for (date) at (time) in (location). The purpose of this meeting
    is to discuss (agenda items). Your presence and input at this meeting are crucial,
    so please make every effort to attend. If you are unable to attend, please notify
    me as soon as possible. Thank you for your attention to this matter, and I look
    forward to seeing you at the meeting. |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 你是一个助手，帮助理解模板文档的结构内容。请回复文档中可能写入的内容。| 希望这条信息能够找到你。 我写信是为了通知你即将于（日期）在（时间）于（地点）召开的会议。
    会议的目的是讨论（议程项目）。 你在这次会议上的出席和意见至关重要，因此请尽量参加。如果你无法参加，请尽快通知我。感谢你对此事的关注，我期待在会议上见到你。
    |'
- en: '| You are an assistant helping to understand the structure content of a template
    document. Respond with the content that might be written in the document. Give
    just the action to do. | Insert the recipient’s last name in the salutation. |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 你是一个助手，帮助理解模板文档的结构内容。请回复文档中可能写入的内容。只给出需要做的操作。| 在称呼中插入收件人的姓氏。 |'
- en: '| You are an assistant helping to understand the structure content of a template
    document. Respond with the content that might be written in the document. Give
    just the action to do. For example, if you read "Location", the output will be
    "Add the location"; if you read "Dear Someone", the output will be "Add salutation".
    | Add salutation |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 你是一个助手，帮助理解模板文档的结构内容。请回复文档中可能写入的内容。只给出需要做的操作。例如，如果你读到"地点"，输出将是"添加地点"；如果你读到"亲爱的某人"，输出将是"添加称呼"。|
    添加称呼 |'
- en: 'Table 2: Agent task prompt refinement for Semantics Identification Agent, with
    template text "*Dear Mr./Ms. (Lastname):*".'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：语义识别代理的任务提示优化，模板文本为"*尊敬的先生/女士（姓氏）：*"。
- en: The initial baseline version of the prompt describes the agent’s task without
    specifying that the output should contain instructions on how to reproduce the
    semantics of the provided template text. The agent response is heavily affected
    by hallucinations, answering with plausible text for a generic letter, without
    giving a generic description of its semantics, clearly missing its objective.
    From the analysis of the answer, it can be assumed that the agent misinterprets
    the request "*Respond with the content that could be written*" as a request to
    provide the actual content of the generated document.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '提示的初始基线版本描述了代理的任务，但没有指定输出应包含如何再现提供的模板文本语义的说明。代理的回答受到幻觉的严重影响，给出了适用于通用信件的合理文本，但没有给出其语义的通用描述，明显未达到目标。通过对回答的分析，可以推测代理误解了"*回应可能写入的内容*"的请求，将其理解为提供生成文档的实际内容。 '
- en: '| Prompt engineering for the Semantics Identification Agent |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 语义识别代理的提示工程 |'
- en: '| --- |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| Template text: *First paragraphs : In your opening paragraph, concisely convey
    your enthusiasm for the role and the organization, while emphasizing your pertinent
    educational background. Aim to engage the reader’s interest, prompting them to
    delve deeper into your resume. This section serves as a preview, showcasing your
    qualifications and setting the stage for the detailed skills and experiences outlined
    in your resume. Highlight your top skills that align with the job requirements,
    and showcase your familiarity with the organization by mentioning specific aspects
    such as their mission, ongoing projects, or strategic objectives, linking them
    to how your abilities and interests can add value to their team.* |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 模板文本：*第一段：在开场段落中，简洁地传达你对这个角色和组织的热情，同时强调你相关的教育背景。旨在吸引读者的兴趣，促使他们深入查看你的简历。此部分作为预览，展示你的资格，为简历中详细列出的技能和经历奠定基础。突出与职位要求对接的顶尖技能，并通过提及组织的特定方面，如其使命、进行中的项目或战略目标，展示你对该组织的熟悉程度，将这些与自己的能力和兴趣如何为团队增值联系起来。*
    |'
- en: '| Agent task | Agent answer |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 代理任务 | 代理回答 |'
- en: '| You are an assistant helping to understand the structure content of a template
    document. Respond with the content that might be written in the document. | Dear
    [Hiring Manager’s Name], I am writing to express my genuine enthusiasm for the
    [Job Title] position at [Organization Name]. With a strong educational background
    in [relevant field], I am confident in my ability to contribute to the success
    of your team. The innovative projects and strategic objectives of [Organization
    Name] resonate with my professional interests, and I am eager to bring my skills
    and expertise to support your mission. My top skills in [specific skills] and
    [specific skills] align closely |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 你是一个助手，帮助理解模板文档的结构内容。请响应可能会在文档中写入的内容。 | 亲爱的[招聘经理的名字]，我写信表达我对[职位名称]在[组织名称]的职位的真诚热情。凭借在[相关领域]的坚实教育背景，我相信自己能够为你们的团队成功做出贡献。[组织名称]的创新项目和战略目标与我的专业兴趣相契合，我渴望将我的技能和专业知识用于支持你们的使命。我的顶尖技能包括[具体技能]和[具体技能]，与职位要求紧密对接。
    |'
- en: '| You are an assistant helping to understand the structure content of a template
    document. Respond with the content that might be written in the document. Give
    just the action to do. | Express enthusiasm for the role and the organization,
    emphasizing your educational background and top skills that align with the job
    requirements. Showcase your familiarity with the organization by mentioning specific
    aspects such as their mission, ongoing projects, or strategic objectives, and
    link them to how your abilities and interests can add value to their team. |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 你是一个助手，帮助理解模板文档的结构内容。请响应可能会在文档中写入的内容。只给出要做的动作。 | 表达对这个角色和组织的热情，强调你的教育背景和与职位要求对接的顶尖技能。通过提及组织的特定方面，如其使命、进行中的项目或战略目标，展示你对该组织的熟悉程度，并将这些与自己的能力和兴趣如何为团队增值联系起来。
    |'
- en: '| You are an assistant helping to understand the structure content of a template
    document. Respond with the content that might be written in the document. Give
    just the action to do. For example, if you read "Location", the output will be
    "Add the location"; if you read "Dear Someone", the output will be "Add salutation".
    | Write an enthusiastic opening paragraph that emphasizes your relevant educational
    background and showcases your qualifications and skills that align with the job
    requirements. Mention specific aspects of the organization such as their mission,
    ongoing projects, or strategic objectives, and link them to how your abilities
    and interests can add value to their team. |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 你是一个助手，帮助理解模板文档的结构内容。请响应可能会在文档中写入的内容。只给出要做的动作。例如，如果你看到“Location”，输出将是“添加位置”；如果你看到“Dear
    Someone”，输出将是“添加称呼”。 | 写一个充满热情的开场段落，强调你相关的教育背景，并展示与职位要求对接的资格和技能。提及组织的特定方面，如其使命、进行中的项目或战略目标，并将这些与自己的能力和兴趣如何为团队增值联系起来。
    |'
- en: 'Table 3: Agent task prompt refinement for Semantics Identification Agent, with
    a long and very discursive template text.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：语义识别代理的任务提示优化，包含长篇且非常冗长的模板文本。
- en: '| Prompt Engineering for the Information retrieval Agent |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 信息检索代理的提示工程 |'
- en: '| Accumulated prompt: "My name is John Doe, i want write a letter for Random
    University, i am a student in Computer Science" |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 累积提示：“我的名字是约翰·多伊，我想为随机大学写一封信，我是计算机科学的学生” |'
- en: The addition of a clear instruction "*Give just the action to do*" in the second
    version of the system prompt definition gives the agent a clear explanation on
    how to perform its task. This sentence is crucial to improve the conformity of
    the agent’s response to its original task, instructing it to provide a description
    of the action to perform to reproduce the semantics of the template section.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二版系统提示定义中添加了明确指令 "*仅提供要执行的操作*"，为代理提供了如何执行其任务的清晰说明。这句话对于提高代理响应与原始任务的一致性至关重要，指示其提供执行操作的描述，以重现模板部分的语义。
- en: The relevant results for template text "*Dear Mr./Ms.(Lastname)*" are provided
    in Table [2](#S4.T2 "Table 2 ‣ 4.1 Semantics Identification Agent ‣ 4 Experimental
    Evaluation ‣ LLM Based Multi-Agent Generation of Semi-structured Documents from
    Semantic Templates in the Public Administration Domain"). Here, the output to
    the second version of the prompt could be considered correct but it could be even
    more synthetic, considering that the optimal response would just be and instruction
    to "*Add a salutation*".
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 模板文本 "*亲爱的先生/女士（姓氏）*" 的相关结果见表 [2](#S4.T2 "表2 ‣ 4.1 语义识别代理 ‣ 4 实验评估 ‣ 基于LLM的多代理生成半结构化文档的语义模板在公共管理领域")。在这里，第二版提示的输出可以视为正确，但考虑到最优响应应该只是一个指令
    "*添加称谓*"，它可以更简洁。
- en: 'A particularly interesting study case consists of using the engineered prompt
    and providing a text without a semantic value, such as a placeholder text: Template
    text: *Lorem ipsum dolor sit amet, consectetur adipiscing elit…* The template
    text is the placeholder text ("*Lorem Ipsum …*") typically used to test graphical
    templates. The agent answer perfectly conforms to the prescribed task as this
    placeholder is usually found in the discursive sections of document templates:
    Agent Answer: *The missing information to satisfy the request is the content of
    the main body of the document.*'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 一个特别有趣的案例是使用工程化提示并提供没有语义价值的文本，例如占位符文本：模板文本：*Lorem ipsum dolor sit amet, consectetur
    adipiscing elit…* 模板文本是通常用于测试图形模板的占位符文本（"*Lorem Ipsum …*"）。该代理的回答完全符合规定的任务，因为这种占位符通常出现在文档模板的叙述性部分：代理回答：*满足请求所需的缺失信息是文档主体的内容。*
- en: 4.3 Content Generation Agent
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 内容生成代理
- en: 'The *Content Generation Agent* is tasked with generating the text in the output
    document following the instructions of the other agents and using the information
    contained in the *accumulated prompt*. The *system prompt* for this agent, as
    in the cases of the previous agents, contains clear instructions and constraints
    to obtain a desirable output. The baseline prompt is: Agent task:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '*内容生成代理* 负责根据其他代理的指示生成输出文档中的文本，并使用 *累计提示* 中包含的信息。对于该代理的 *系统提示*，与以前的代理情况类似，包含明确的指示和约束，以获得期望的输出。基线提示是：代理任务：'
- en: '*You are an assistant with the purpose of generating a document with the available
    information. You have the following information:* `{Accumulated prompt}`'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '*你是一个助手，目的是用现有信息生成文档。你有以下信息：* `{Accumulated prompt}`'
- en: '*For example, if you read "Add salutation name", write the salutation only.*
    where `{Accumulated prompt}` is the currently *accumulated prompt*. With this
    baseline, the model tends to add initial greetings and a conclusion. This deviation
    from the original task could be solved by forbidding the addition of out-of-context
    information, by adding the following sentence *Remember that in an opening paragraph,
    it is absolutely forbidden to write "dear someone", or "sincerely" at the end
    of the document.* As for the previous agents, adding examples of the desired result
    drives the agent’s output to the desired format.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '*例如，如果你读到“添加称谓名称”，只需写下称谓即可。* 其中 `{Accumulated prompt}` 是当前的 *累计提示*。基于这一基准，模型往往会添加初始问候和结尾。这种偏离原始任务的方法可以通过禁止添加无关信息来解决，通过添加以下句子
    *请记住，在开头段落中，绝对禁止在文档末尾写“亲爱的某人”或“诚挚的”*。至于以前的代理，通过添加期望结果的示例来推动代理的输出符合期望格式。'
- en: '![Refer to caption](img/72ab4828519f5f0c53f069adbd8b4a4c.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/72ab4828519f5f0c53f069adbd8b4a4c.png)'
- en: 'Figure 4: Agent responses throughout a single generation step, starting from
    the template text: "*Your name*". The figure represents a single generation step
    for a section of the document, showing an example of successful generation using
    the engineered prompt. In this case all information is retrieved in the original
    user prompt, so no information is asked to the user.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：代理在单次生成步骤中的响应，起始模板文本为："*您的名字*"。该图表示文档某一部分的单次生成步骤，展示了使用工程化提示成功生成的示例。在这种情况下，所有信息都在原始用户提示中检索，因此无需向用户询问信息。
- en: 4.4 Prompt-engineered results
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 提示工程化结果
- en: Examples of a full processing iteration of template sections with the refined
    prompts are shown in Figures [4](#S4.F4 "Figure 4 ‣ 4.3 Content Generation Agent
    ‣ 4.1 Semantics Identification Agent ‣ 4 Experimental Evaluation ‣ LLM Based Multi-Agent
    Generation of Semi-structured Documents from Semantic Templates in the Public
    Administration Domain") and [5](#S4.F5 "Figure 5 ‣ 4.4 Prompt-engineered results
    ‣ 4.3 Content Generation Agent ‣ 4.1 Semantics Identification Agent ‣ 4 Experimental
    Evaluation ‣ LLM Based Multi-Agent Generation of Semi-structured Documents from
    Semantic Templates in the Public Administration Domain").
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 带有精细化提示的模板部分的完整处理迭代示例如图[4](#S4.F4 "图 4 ‣ 4.3 内容生成代理 ‣ 4.1 语义识别代理 ‣ 4 实验评估 ‣
    基于LLM的多代理生成公共行政领域的半结构化文档")和图[5](#S4.F5 "图 5 ‣ 4.4 提示工程化结果 ‣ 4.3 内容生成代理 ‣ 4.1 语义识别代理
    ‣ 4 实验评估 ‣ 基于LLM的多代理生成公共行政领域的半结构化文档")中有所展示。
- en: Fig. [4](#S4.F4 "Figure 4 ‣ 4.3 Content Generation Agent ‣ 4.1 Semantics Identification
    Agent ‣ 4 Experimental Evaluation ‣ LLM Based Multi-Agent Generation of Semi-structured
    Documents from Semantic Templates in the Public Administration Domain") in particular
    presents a case in which, thanks to the prompt engineering process, the *Content
    Generation agent* is able to retrieve the necessary data from the *accumulated
    prompt* without asking for user intervention, then using the instructions for
    the reproduction of the semantics of the document section, provided by the *Semantics
    Identification agent*, to generate a desirable result.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图[4](#S4.F4 "图 4 ‣ 4.3 内容生成代理 ‣ 4.1 语义识别代理 ‣ 4 实验评估 ‣ 基于LLM的多代理生成公共行政领域的半结构化文档")特别展示了一个案例，其中，由于提示工程过程，*内容生成代理*能够从*累积提示*中检索必要的数据而无需用户干预，然后利用*语义识别代理*提供的文档部分语义再现指令，生成出期望的结果。
- en: Fig. [5](#S4.F5 "Figure 5 ‣ 4.4 Prompt-engineered results ‣ 4.3 Content Generation
    Agent ‣ 4.1 Semantics Identification Agent ‣ 4 Experimental Evaluation ‣ LLM Based
    Multi-Agent Generation of Semi-structured Documents from Semantic Templates in
    the Public Administration Domain") instead presents a case in which some missing
    information is detected, which requires user intervention to provide such missing
    data, which is then added to the *accumulated prompt*.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图[5](#S4.F5 "图 5 ‣ 4.4 提示工程化结果 ‣ 4.3 内容生成代理 ‣ 4.1 语义识别代理 ‣ 4 实验评估 ‣ 基于LLM的多代理生成公共行政领域的半结构化文档")则展示了一个检测到某些缺失信息的案例，这需要用户干预以提供这些缺失的数据，然后将其添加到*累积提示*中。
- en: In both cases, a dramatic improvement in the quality of the agents’ responses
    was obtained by adding examples for the structure of the expected result.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，通过为期望结果的结构添加示例，显著提高了代理响应的质量。
- en: '![Refer to caption](img/17644939c2ece661d2f324833162633c.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/17644939c2ece661d2f324833162633c.png)'
- en: 'Figure 5: Agent responses throughout a single generation step, starting from
    the template text: "*Dear Mr./Ms.(Lastname)*". In this case, user intervention
    is required to add missing information.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：代理在单次生成步骤中的响应，起始模板文本为："*尊敬的先生/女士（姓氏）*"。在这种情况下，需要用户干预以添加缺失的信息。
- en: 5 Conclusions
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论
- en: This work presents a workflow and an interaction framework for the LLM-assisted
    multi-agent generation of a semi-structured document in the PA domain, with limited
    human supervision.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作展示了一个工作流程和互动框架，用于在公共行政领域内，利用LLM辅助的多代理生成半结构化文档，且在有限的人类监督下进行。
- en: We exploited the capabilities of a Large Language Model, taking advantage of
    a multi-agent architecture, involving three roles, namely, a Semantics Identification
    Agent, an Information Retrieval Agent, and, a Content Generation Agent. With the
    resulting architecture, we highlighted the necessary prompt refinement process
    to obtain desirable results for each specific agent role in the presented workflow.
    The approach is successful in both schematic and verbose document sections providing
    enough cues about their semantics.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们利用了大型语言模型的能力，采用了一个多代理架构，涉及三个角色，即语义识别代理、信息检索代理和内容生成代理。通过这种架构，我们突出了必要的提示优化过程，以获得在呈现的工作流程中每个特定代理角色的理想结果。该方法在图示和详细文档部分均取得了成功，提供了足够的语义提示。
- en: Example-based document generation proves to be perfectly adaptable to the PA
    scenario, where a progressive transition to Artificial Intelligence tools is expected
    in the next years.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 基于示例的文档生成证明在PA场景中完全可适应，在未来几年中，预计将逐步过渡到人工智能工具。
- en: The paradigm shown in the present work could easily be adapted to a plethora
    of contexts, reducing the workload for human experts who can act as supervisors
    of the job that a pool of synthetic agents can carry out. This pushes forward
    the boundaries of the contribution that a large language model can provide in
    an office context and also represents a notable starting point for research in
    the field of multi-role architecture for everyday tasks.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究所展示的范式可以轻松适应众多上下文，减少了人类专家的工作量，这些专家可以作为合成代理池的工作监督者。这推动了大型语言模型在办公室环境中所能提供的贡献的边界，并且也代表了多角色架构在日常任务领域研究的一个显著起点。
- en: References
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Bsharat, S.M., Myrzakhan, A., Shen, Z.: Principled instructions are all
    you need for questioning llama-1/2, gpt-3.5/4 (2024)'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Bsharat, S.M., Myrzakhan, A., Shen, Z.：原则性指令就是你所需的，用于质疑llama-1/2，gpt-3.5/4（2024）'
- en: '[2] Chen, J., Lin, H., Han, X., Sun, L.: Benchmarking large language models
    in retrieval-augmented generation. arXiv preprint arXiv:2309.01431 (2023)'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Chen, J., Lin, H., Han, X., Sun, L.：在检索增强生成中对大型语言模型进行基准测试。arXiv预印本 arXiv:2309.01431（2023）'
- en: '[3] Cobbe, J., Singh, J.: Artificial intelligence as a service: Legal responsibilities,
    liabilities, and policy challenges. Computer Law & Security Review 42, 105573
    (2021)'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Cobbe, J., Singh, J.：作为服务的人工智能：法律责任、义务和政策挑战。计算机法律与安全评论 42，105573（2021）'
- en: '[4] Hegselmann, S., Buendia, A., Lang, H., Agrawal, M., Jiang, X., Sontag,
    D.: Tabllm: Few-shot classification of tabular data with large language models.
    In: Ruiz, F., Dy, J., van de Meent, J.W. (eds.) Proceedings of The 26th International
    Conference on Artificial Intelligence and Statistics. Proceedings of Machine Learning
    Research, vol. 206, pp. 5549–5581\. PMLR (25–27 Apr 2023), [https://proceedings.mlr.press/v206/hegselmann23a.html](https://proceedings.mlr.press/v206/hegselmann23a.html)'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Hegselmann, S., Buendia, A., Lang, H., Agrawal, M., Jiang, X., Sontag,
    D.：Tabllm：通过大型语言模型对表格数据进行少量样本分类。收录于：Ruiz, F., Dy, J., van de Meent, J.W.（编）《第26届国际人工智能与统计会议论文集》。机器学习研究论文集，第206卷，第5549–5581页。PMLR（2023年4月25–27日），[https://proceedings.mlr.press/v206/hegselmann23a.html](https://proceedings.mlr.press/v206/hegselmann23a.html)'
- en: '[5] Kojima, T., Gu, S.S., Reid, M., Matsuo, Y., Iwasawa, Y.: Large language
    models are zero-shot reasoners. In: Koyejo, S., Mohamed, S., Agarwal, A., Belgrave,
    D., Cho, K., Oh, A. (eds.) Advances in Neural Information Processing Systems.
    vol. 35, pp. 22199–22213\. Curran Associates, Inc. (2022)'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Kojima, T., Gu, S.S., Reid, M., Matsuo, Y., Iwasawa, Y.：大型语言模型是零-shot 推理器。收录于：Koyejo,
    S., Mohamed, S., Agarwal, A., Belgrave, D., Cho, K., Oh, A.（编）《神经信息处理系统进展》。第35卷，第22199–22213页。Curran
    Associates, Inc.（2022）'
- en: '[6] Krause, S., Stolzenburg, F.: Commonsense reasoning and explainable artificial
    intelligence using large language models. In: European Conference on Artificial
    Intelligence. pp. 302–319\. Springer (2023)'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Krause, S., Stolzenburg, F.：常识推理与使用大型语言模型的可解释人工智能。收录于：欧洲人工智能会议。第302–319页。Springer（2023）'
- en: '[7] Li, J., Tang, T., Zhao, W.X., Nie, J.Y., Wen, J.R.: Pretrained language
    models for text generation: A survey. arXiv preprint arXiv:2201.05273 (2022)'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Li, J., Tang, T., Zhao, W.X., Nie, J.Y., Wen, J.R.：用于文本生成的预训练语言模型：综述。arXiv预印本
    arXiv:2201.05273（2022）'
- en: '[8] Li, Z., Peng, B., He, P., Galley, M., Gao, J., Yan, X.: Guiding large language
    models via directional stimulus prompting. arXiv preprint arXiv:2302.11520 (2023)'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Li, Z., Peng, B., He, P., Galley, M., Gao, J., Yan, X.：通过方向性刺激提示引导大型语言模型。arXiv预印本
    arXiv:2302.11520（2023）'
- en: '[9] Peng, R., Liu, K., Yang, P., Yuan, Z., Li, S.: Embedding-based retrieval
    with llm for effective agriculture information extracting from unstructured data.
    arXiv preprint arXiv:2308.03107 (2023)'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] 彭瑞、刘凯、杨平、袁泽、李晟：基于嵌入的检索与大语言模型结合，针对非结构化数据中的农业信息提取。arXiv 预印本 arXiv:2308.03107
    (2023)'
- en: '[10] Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et al.:
    Language models are unsupervised multitask learners. OpenAI blog 1(8),  9 (2019)'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] 拉德福德、吴俊、查尔德、吕安、阿莫迪、苏茨克弗、等：语言模型是无监督的多任务学习者。OpenAI 博客 1(8)，9 (2019)'
- en: '[11] Rasal, S.: Llm harmony: Multi-agent communication for problem solving.
    arXiv preprint arXiv:2401.01312 (2024)'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] 拉萨尔：Llm harmony：多代理通信解决问题。arXiv 预印本 arXiv:2401.01312 (2024)'
- en: '[12] Siciliani, L., Ghizzota, E., Basile, P., Lops, P.: Oie4pa: open information
    extraction for the public administration. Journal of Intelligent Information Systems
    pp. 1–22 (2023)'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] 西西利亚尼、吉佐塔、巴西莱、洛普斯：Oie4pa：面向公共管理的信息提取。智能信息系统杂志，第1–22页 (2023)'
- en: '[13] Tang, X., Zong, Y., Zhao, Y., Cohan, A., Gerstein, M.: Struc-bench: Are
    large language models really good at generating complex structured data? arXiv
    preprint arXiv:2309.08963 (2023)'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] 唐晓、宗岩、赵一、科汉、杰斯坦：Struc-bench：大型语言模型在生成复杂结构化数据方面真的好吗？arXiv 预印本 arXiv:2309.08963
    (2023)'
- en: '[14] Tang, Y., Yang, Y.: Multihop-rag: Benchmarking retrieval-augmented generation
    for multi-hop queries. arXiv preprint arXiv:2401.15391 (2024)'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] 唐宇、杨洋：Multihop-rag：基准测试检索增强生成用于多跳查询。arXiv 预印本 arXiv:2401.15391 (2024)'
- en: '[15] Wei, J., Wang, X., Schuurmans, D., Bosma, M., ichter, b., Xia, F., Chi,
    E., Le, Q.V., Zhou, D.: Chain-of-thought prompting elicits reasoning in large
    language models. In: Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho,
    K., Oh, A. (eds.) Advances in Neural Information Processing Systems. vol. 35,
    pp. 24824–24837\. Curran Associates, Inc. (2022)'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] 魏杰、王鑫、舒尔曼、博斯玛、伊赫特、夏飞、池峰、乐权伟、周达：思维链提示引发大型语言模型的推理。在：科耶乔、穆罕默德、阿加瓦尔、贝尔格雷夫、乔恩、哦安（编）《神经信息处理系统进展》。第35卷，第24824–24837页。Curran
    Associates, Inc. (2022)'
- en: '[16] White, J., Fu, Q., Hays, S., Sandborn, M., Olea, C., Gilbert, H., Elnashar,
    A., Spencer-Smith, J., Schmidt, D.C.: A prompt pattern catalog to enhance prompt
    engineering with chatgpt. arXiv preprint arXiv:2302.11382 (2023)'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] 怀特、傅强、海斯、桑博恩、奥利亚、吉尔伯特、埃尔纳沙、斯宾塞-史密斯、施密特：一个提示模式目录，用于增强与 ChatGPT 的提示工程。arXiv
    预印本 arXiv:2302.11382 (2023)'
