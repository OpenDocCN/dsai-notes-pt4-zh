- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:42:13'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:42:13
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement
    for Enhanced Financial Decision Making'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'FinCon: 一种具有概念性语言强化的综合LLM多智能体系统，以提高金融决策能力'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2407.06567](https://ar5iv.labs.arxiv.org/html/2407.06567)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2407.06567](https://ar5iv.labs.arxiv.org/html/2407.06567)
- en: Yangyang Yu^(1,⋆),   Zhiyuan Yao^(1,⋆),  Haohang Li^(1,⋆),  Zhiyang Deng^(1,⋆), 
    Yupeng Cao^(1,⋆),  Zhi Chen^(1,⋆)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Yangyang Yu^(1,⋆),   Zhiyuan Yao^(1,⋆),  Haohang Li^(1,⋆),  Zhiyang Deng^(1,⋆), 
    Yupeng Cao^(1,⋆),  Zhi Chen^(1,⋆)
- en: Jordan W. Suchow¹,  Rong Liu¹,  Zhenyu Cui¹, Denghui Zhang¹  Koduvayur Subbalakshmi¹
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Jordan W. Suchow¹,  Rong Liu¹,  Zhenyu Cui¹,  Denghui Zhang¹  Koduvayur Subbalakshmi¹
- en: Guojun Xiong²,  Yueru He³,  Jimin Huang ³,  Dong Li³,  Qianqian Xie^(3,†)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Guojun Xiong²,  Yueru He³,  Jimin Huang ³,  Dong Li³,  Qianqian Xie^(3,†)
- en: ¹Stevens Institute of Technology ²Stony Brook University ³The Fin AI
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ¹斯蒂文斯理工学院 ²石溪大学 ³The Fin AI
- en: '^⋆These authors contributed equally ^† Corresponding author: qianqian.xie@yale.edu'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ^⋆这些作者贡献相等 ^† 通讯作者：qianqian.xie@yale.edu
- en: Abstract
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Large language models (LLMs) have demonstrated notable potential in conducting
    complex tasks and are increasingly utilized in various financial applications.
    However, high-quality sequential financial investment decision-making remains
    challenging. These tasks require multiple interactions with a volatile environment
    for every decision, demanding sufficient intelligence to maximize returns and
    manage risks. Although LLMs have been used to develop agent systems that surpass
    human teams and yield impressive investment returns, opportunities to enhance
    multi-sourced information synthesis and optimize decision-making outcomes through
    timely experience refinement remain unexplored. Here, we introduce the FinCon,
    an LLM-based multi-agent framework with conceptual verbal reinforcement tailored
    for diverse financial tasks. Inspired by effective real-world investment firm
    organizational structures, FinCon utilizes a manager-analyst communication hierarchy.
    This structure allows for synchronized cross-functional agent collaboration towards
    unified goals through natural language interactions and equips each agent with
    greater memory capacity than humans. Additionally, a risk-control component in
    FinCon enhances decision quality by episodically initiating a self-critiquing
    mechanism to update systematic investment beliefs. The conceptualized beliefs
    serve as verbal reinforcement for the future agent’s behavior and can be selectively
    propagated to the appropriate node that requires knowledge updates. This feature
    significantly improves performance while reducing unnecessary peer-to-peer communication
    costs. Moreover, FinCon demonstrates strong generalization capabilities in various
    financial tasks, including single stock trading and portfolio management.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）在执行复杂任务方面展示了显著的潜力，并在各种金融应用中得到了越来越广泛的使用。然而，高质量的连续金融投资决策仍然具有挑战性。这些任务要求每次决策都与波动的环境进行多次互动，要求足够的智能以最大化回报并管理风险。尽管LLMs已被用于开发超越人类团队的智能体系统，并获得了令人印象深刻的投资回报，但通过及时的经验优化来增强多源信息的综合和优化决策结果的机会仍未被探索。在这里，我们介绍了FinCon，一种基于LLM的多智能体框架，结合了适用于各种金融任务的概念性语言强化。受到现实世界投资公司组织结构的启发，FinCon利用了经理-分析师沟通层级。这种结构通过自然语言互动实现跨职能智能体的同步协作，以实现统一目标，并赋予每个智能体比人类更大的记忆容量。此外，FinCon中的风险控制组件通过定期启动自我批评机制来更新系统投资信念，从而提高决策质量。这些概念化的信念作为未来智能体行为的语言强化，并可以选择性地传播到需要知识更新的适当节点。这一特性显著提高了性能，同时降低了不必要的点对点沟通成本。此外，FinCon在包括单一股票交易和投资组合管理在内的各种金融任务中表现出强大的泛化能力。
- en: 1 Introduction
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: The intricacies and fluctuations of financial markets present substantial challenges
    for making high-quality, sequential investment decisions. In tasks such as single
    stock trading and portfolio management, each intelligent decision is informed
    by multiple market interactions and integrated information characterized by different
    levels of timeliness and modalities [[1](#bib.bib1), [2](#bib.bib2)]. These tasks
    aim to maximize profit while managing current market risks in an open-end environment.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 金融市场的复杂性和波动性对高质量的连续投资决策提出了重大挑战。在如单一股票交易和投资组合管理等任务中，每一个智能决策都基于多个市场互动和不同时间性和模态的信息
    [[1](#bib.bib1), [2](#bib.bib2)]。这些任务旨在最大化利润，同时在开放环境中管理当前市场风险。
- en: In practice, trading firms often rely on synthesized human teamwork, with an
    organizational structure that typically involves hierarchical communication among
    various functional roles such as data analysts, risk analysts, portfolio managers,
    etc., and careful integration of various resources [[3](#bib.bib3), [4](#bib.bib4)].
    However, the cognitive limitations of human team members can restrict their ability
    to quickly process market signals and achieve optimal investment results [[5](#bib.bib5)].
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，交易公司通常依赖于合成的人类团队合作，组织结构通常涉及不同职能角色如数据分析师、风险分析师、投资组合经理等之间的层级沟通，并对各种资源进行细致整合
    [[3](#bib.bib3), [4](#bib.bib4)]。然而，人类团队成员的认知局限性可能限制他们快速处理市场信号和实现最佳投资结果的能力 [[5](#bib.bib5)]。
- en: 'To improve investment returns and overcome human limitations, studies have
    employed methods such as deep reinforcement learning (DRL) to develop agent systems
    that simulate market environments and automate investment strategies [[6](#bib.bib6),
    [7](#bib.bib7), [8](#bib.bib8)]. Meanwhile, advancements in large language models
    (LLMs) demonstrate potential in complex tasks such as reasoning, tool-using, planning,
    and decision-making [[9](#bib.bib9), [10](#bib.bib10)], promising to surpass existing
    agent architectures. Language agents are known for human-like communication and
    adaptable prompt-based structures tailored for diverse decision-making settings
    [[11](#bib.bib11), [12](#bib.bib12), [13](#bib.bib13), [14](#bib.bib14)]. For
    optimal decision-making performance, two key elements need to be considered: 1)
    Organizing agents to promote effective teamwork and efficient communication, and
    2) Enabling agents to continually learn and refine their actions. Studies indicate
    that imitating human organizational structures can effectively coordinate language
    agents for specific tasks [[15](#bib.bib15), [16](#bib.bib16), [17](#bib.bib17)].
    Additionally, recent developments in textual gradient-based prompt optimization
    [[18](#bib.bib18), [19](#bib.bib19)] and verbal reinforcement [[20](#bib.bib20),
    [21](#bib.bib21)] have proven to be practical for enhancing the reasoning and
    decision-making abilities of language agents iteratively.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高投资回报率并克服人类局限性，研究采用了深度强化学习（DRL）等方法来开发模拟市场环境并自动化投资策略的代理系统 [[6](#bib.bib6),
    [7](#bib.bib7), [8](#bib.bib8)]。与此同时，大型语言模型（LLMs）的进展在复杂任务如推理、工具使用、规划和决策方面展示了潜力
    [[9](#bib.bib9), [10](#bib.bib10)]，有望超越现有的代理架构。语言代理以类似人类的沟通方式和适应性强的基于提示的结构而闻名，适用于多样的决策环境
    [[11](#bib.bib11), [12](#bib.bib12), [13](#bib.bib13), [14](#bib.bib14)]。为了实现最佳决策性能，需要考虑两个关键因素：1）组织代理以促进有效的团队合作和高效的沟通，2）使代理能够持续学习和优化其行动。研究表明，模仿人类组织结构可以有效协调语言代理以完成特定任务
    [[15](#bib.bib15), [16](#bib.bib16), [17](#bib.bib17)]。此外，近期文本梯度优化 [[18](#bib.bib18),
    [19](#bib.bib19)] 和语言强化 [[20](#bib.bib20), [21](#bib.bib21)] 的发展已证明对于迭代增强语言代理的推理和决策能力非常实用。
- en: Language agent systems adapted for financial decision-making, such as FinGPT
    [[22](#bib.bib22)], FinMem [[23](#bib.bib23)] and FinAgent [[24](#bib.bib24)],
    have demonstrated impressive performance. However, these systems exhibit several
    limitations. Firstly, their reliance on the risk preferences of agents based on
    short-term market fluctuations fails to control overall risk exposures over long-term
    trading periods. This oversight can lead to potential losses due to the dismissal
    of fundamental factors driving investment profits. A more effective strategy is
    to quantify investment risks using measures of risk from quantitative finance
    [[25](#bib.bib25), [26](#bib.bib26)]. Secondly, most existing systems are designed
    for single-asset trading tasks and show limited adaptability to other financial
    applications involving multiple assets, such as portfolio management. Thirdly,
    these systems depend on the information understanding and extraction ability of
    a single agent, placing heavy pressure on the language model to comprehend and
    process information within a limited context window. This likely degrades decision
    quality. A multi-agent system that allocates tasks based on data source and modality
    could enhance performance. Even though approaches like StockAgent [[27](#bib.bib27)]
    utilize a multi-agent system for individual stock trading tasks. However, their
    decision-making processes heavily depend on extensive discussions among numerous
    LLM agents, leading to high communication costs and extended processing times.
    Besides, the lack of a clear optimization goal in such systems can compromise
    the effectiveness of the outcomes.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 适用于金融决策的语言代理系统，如 FinGPT [[22](#bib.bib22)]、FinMem [[23](#bib.bib23)] 和 FinAgent
    [[24](#bib.bib24)]，已展示出令人印象深刻的性能。然而，这些系统存在一些局限性。首先，它们依赖于基于短期市场波动的代理风险偏好，这无法控制长期交易期间的整体风险暴露。这种忽视可能导致由于忽略推动投资利润的基本因素而造成潜在损失。更有效的策略是使用定量金融中的风险度量来量化投资风险
    [[25](#bib.bib25), [26](#bib.bib26)]。其次，大多数现有系统设计用于单一资产交易任务，对于涉及多个资产的其他金融应用（如投资组合管理）适应性有限。第三，这些系统依赖于单一代理的信息理解和提取能力，给语言模型在有限上下文窗口内理解和处理信息施加了很大的压力，这可能会降低决策质量。基于数据源和模态分配任务的多代理系统可能会提升性能。尽管像
    StockAgent [[27](#bib.bib27)] 这样的方式利用多代理系统进行个股交易任务，但它们的决策过程严重依赖于众多 LLM 代理之间的广泛讨论，导致高昂的通信成本和较长的处理时间。此外，此类系统缺乏明确的优化目标，可能会影响结果的有效性。
- en: 'In response to these unaddressed issues, we propose FinCon, an LLM-based multi-agent
    framework for critical financial decision-making tasks such as single stock trading
    and portfolio management. Our main contributions are as follows: 1) Inspired by
    real-world investment roles, we designed an innovative Synthesized Manager-Analyst
    hierarchical communication structure and a risk control component. This communication
    structure distributes financial data from various sources and modalities to corresponding
    functional analyst agents, allowing them to focus on distilling essential investment
    insights and indicators from a single source of information. The manager then
    makes trading decisions by consolidating these insights and interacting with the
    risk-control component. The manager and analyst in a synchronous hierarchy to
    effectively enhance overall comprehension and reasoning capabilities. In this
    communication network, messages are conveyed only to the workers who need to be
    informed, eliminating redundant peer-to-peer communication and saving communication
    costs. 2) It is a generalized framework that can conduct not only stock trading
    but also portfolio management. The latter has not been claimed to be tackled by
    other financial language agent frameworks. 3) We innovatively crafted the agents’
    persona using a dual-level risk control component, enabling comprehensive risk
    updates both within and across episodes. Within episodes, risk supervision is
    conducted using a quantile-based risk measure from quantitative finance, the Conditional
    Value at Risk (CVaR) [[28](#bib.bib28)]. For across-episode risk control, we designed
    a unique verbal reinforcement method to update the decision maker’s investment
    beliefs with conceptualized investment insights to guide future decisions. These
    investment beliefs are distilled from underlying reasoning trajectory-level profit
    and loss (PnL) changes and summarized as conceptual perspectives based on the
    functionality of all analyst agents. Investment beliefs can then be selectively
    back-propagated from the manager to the corresponding functional analyst agent.
    Ablation study results illustrate the significant effectiveness of our risk control
    design in managing market risk and improving trading performance.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 针对这些未解决的问题，我们提出了 FinCon，一个基于 LLM 的多智能体框架，用于关键的金融决策任务，如单只股票交易和投资组合管理。我们的主要贡献如下：1）受到现实世界投资角色的启发，我们设计了创新的综合经理-分析师层级通信结构和风险控制组件。这个通信结构将来自各种来源和模态的金融数据分发给相应的功能分析师智能体，使他们能够集中精力从单一信息源中提炼出关键的投资洞察和指标。然后，经理通过整合这些洞察和与风险控制组件互动来做出交易决策。经理和分析师在同步层级中有效地增强了整体理解和推理能力。在这个通信网络中，信息只传递给需要了解的工作者，消除了冗余的点对点通信，节省了通信成本。2）这是一个通用框架，不仅可以进行股票交易，还可以进行投资组合管理。后者未被其他金融语言智能体框架声称处理过。3）我们创新性地使用双层风险控制组件设计了智能体的人物特征，能够在集集和跨集集期间进行全面的风险更新。在集集内，使用基于量化金融的条件风险价值（CVaR）进行风险监督[[28](#bib.bib28)]。对于跨集集风险控制，我们设计了一种独特的语言强化方法，通过概念化的投资洞察更新决策者的投资信念，以指导未来的决策。这些投资信念是从潜在推理轨迹级的盈亏（PnL）变化中提炼出的，并根据所有分析师智能体的功能总结为概念视角。投资信念然后可以从经理处选择性地反向传播到相应的功能分析师智能体。消融研究结果表明，我们的风险控制设计在管理市场风险和提高交易性能方面具有显著效果。
- en: 2 Related Work
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: LLM Agents for Financial Decision Making. There are considerable efforts directed
    towards developing general-purpose LLM agent for sequential decision-making [[29](#bib.bib29),
    [30](#bib.bib30)], and such type of tasks often involve episodic interactions
    with environment and verbal reflections for action refinement, such as coding
    competition [[31](#bib.bib31), [32](#bib.bib32)], software development [[33](#bib.bib33),
    [14](#bib.bib14)], game-playing [[34](#bib.bib34), [35](#bib.bib35)]. Furthermore,
    researchers have started to exploit how LLM agents can perform better in harder
    decision-making tasks from finance [[36](#bib.bib36), [37](#bib.bib37), [38](#bib.bib38)],
    in which there are more volatile environments, leading to that the numerous unpredictable
    elements can obscure an agent’s ability to reflect accurately on the reasons for
    poor decision outcomes. FinMem [[23](#bib.bib23)] enhances single stock trading
    performance by embedding memory modules with LLM agent for reflection-refinement,
    and FinAgent [[24](#bib.bib24)] improved trading profits via using external quantitative
    tool to fight against volatile environment.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: LLM代理在金融决策中的应用。大量工作致力于开发通用的LLM代理以进行顺序决策[[29](#bib.bib29), [30](#bib.bib30)]，此类任务通常涉及与环境的情景互动以及对行动的口头反思，如编程竞赛[[31](#bib.bib31),
    [32](#bib.bib32)]、软件开发[[33](#bib.bib33), [14](#bib.bib14)]、游戏玩法[[34](#bib.bib34),
    [35](#bib.bib35)]。此外，研究人员已经开始探索LLM代理在更困难的金融决策任务中的表现[[36](#bib.bib36), [37](#bib.bib37),
    [38](#bib.bib38)]，这些任务中环境更为波动，导致许多不可预测的因素可能掩盖代理准确反思决策结果原因的能力。FinMem[[23](#bib.bib23)]通过将记忆模块嵌入LLM代理以进行反思改进，从而提升了单股交易表现，而FinAgent[[24](#bib.bib24)]通过使用外部定量工具应对波动环境，提高了交易利润。
- en: Multi-Agent System and Communication Structures. In traditional multi-agent
    systems [[39](#bib.bib39), [40](#bib.bib40)], the way for agents’ communication
    is pre-determined, like sharing data or state observations [[41](#bib.bib41),
    [42](#bib.bib42), [43](#bib.bib43), [44](#bib.bib44), [45](#bib.bib45)]. The emergence
    of large language model brings flexibility for human-understandable communications
    [[46](#bib.bib46), [11](#bib.bib11), [14](#bib.bib14), [47](#bib.bib47)], so some
    work tries to elevate decision-making ability of LLM-based multi-agent system
    by letting agents engage in discussions [[48](#bib.bib48), [12](#bib.bib12)] or
    debates [[49](#bib.bib49), [50](#bib.bib50)]. The similar peer-communication strategy
    was as well utilized by the multi-agent system for financial tasks [[51](#bib.bib51),
    [52](#bib.bib52), [53](#bib.bib53)]. However, such approach are not optimal for
    unified-goal financial tasks that prioritize profits [[54](#bib.bib54)], because
    they suffer from potentially ambiguous optimization objectives and are unable
    to control the unnecessary communication costs [[55](#bib.bib55)].
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 多代理系统与通信结构。在传统的多代理系统[[39](#bib.bib39), [40](#bib.bib40)]中，代理的通信方式是预先确定的，例如共享数据或状态观察[[41](#bib.bib41),
    [42](#bib.bib42), [43](#bib.bib43), [44](#bib.bib44), [45](#bib.bib45)]。大型语言模型的出现为人类可理解的通信带来了灵活性[[46](#bib.bib46),
    [11](#bib.bib11), [14](#bib.bib14), [47](#bib.bib47)]，因此有些工作尝试通过让代理参与讨论[[48](#bib.bib48),
    [12](#bib.bib12)]或辩论[[49](#bib.bib49), [50](#bib.bib50)]来提升基于LLM的多代理系统的决策能力。类似的对等通信策略也被用于金融任务的多代理系统[[51](#bib.bib51),
    [52](#bib.bib52), [53](#bib.bib53)]。然而，这种方法对于以利润为优先的统一目标金融任务并不理想[[54](#bib.bib54)]，因为它们可能面临模糊的优化目标，且无法控制不必要的通信成本[[55](#bib.bib55)]。
- en: Prompt Optimization and Verbal Reinforcement. To enhance the reasoning or decision-making
    of LLM agents, many prompt optimization techniques have been proposed, like ReAct
    [[56](#bib.bib56)], Chain of Thought (CoT) [[57](#bib.bib57)], Tree of Thoughts
    (ToT) [[58](#bib.bib58)], ART [[10](#bib.bib10)], intended for that LLM agents
    can automatically generate intermediate reasoning steps as an iterative program.
    In addition, to make LLM agent make decisions like humans and generate more understandable
    reasoning texts, some researchers recommend incorporating cognitive structures
    [[59](#bib.bib59), [60](#bib.bib60), [61](#bib.bib61), [62](#bib.bib62)]. Inspired
    by these previous work and DRL algorithms [[63](#bib.bib63)], verbal reinforcement
    [[20](#bib.bib20), [21](#bib.bib21), [64](#bib.bib64), [15](#bib.bib15)] was developed
    for LLM agents such that they can update actions based on iterative self-reflection
    while integrating additional LLM as a prompt optimizer [[18](#bib.bib18), [19](#bib.bib19)].
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 提示优化和语言强化。为了增强LLM代理的推理或决策能力，提出了许多提示优化技术，如ReAct [[56](#bib.bib56)]、思维链（CoT）[[57](#bib.bib57)]、思维树（ToT）[[58](#bib.bib58)]、ART
    [[10](#bib.bib10)]，这些技术旨在使LLM代理能够像迭代程序一样自动生成中间推理步骤。此外，为了使LLM代理能够像人类一样做出决策并生成更易理解的推理文本，一些研究者建议结合认知结构
    [[59](#bib.bib59)、[60](#bib.bib60)、[61](#bib.bib61)、[62](#bib.bib62)]。受这些先前工作的启发以及DRL算法
    [[63](#bib.bib63)] 的影响，语言强化 [[20](#bib.bib20)、[21](#bib.bib21)、[64](#bib.bib64)、[15](#bib.bib15)]
    被开发用于LLM代理，以便它们能够根据迭代自我反思更新动作，同时将额外的LLM作为提示优化器 [[18](#bib.bib18)、[19](#bib.bib19)]。
- en: 3 Preliminaries
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 前言
- en: Here, we outline the mathematical notations for the two major financial decision-making
    tasks that will be explicitly discussed in our work. We also formally present
    the generalized modeling formulation using a Partially Observable Markov Decision
    Process (POMDP) [[65](#bib.bib65)] for financial decision-making tasks.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们概述了将要在我们的工作中明确讨论的两个主要财务决策任务的数学符号。我们还正式呈现了使用部分可观察马尔可夫决策过程（POMDP）[[65](#bib.bib65)]
    的广义建模公式。
- en: 3.1 Financial Decision-making Tasks Formulation
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 财务决策任务的公式化
- en: Single Stock Trading Tasks. FinCon uses analyst agents group $\{M_{pr}^{i}\}_{i=1}^{I}$.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 单只股票交易任务。FinCon使用分析师代理组 $\{M_{pr}^{i}\}_{i=1}^{I}$。
- en: 'Portfolio Trading Tasks. In addition to processing multi-modal market information,
    the analyst agents also establish stocks’ pool for portfolio management, regarding
    statistical correlation between stocks’ returns. Then, the manager agent makes
    trading decisions on each stock in the pool. Lastly, the manager agent determines
    the portfolio weights for all stocks through a computational tool, which leverages
    the following mean-variance optimization [[66](#bib.bib66)]:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 投资组合交易任务。除了处理多模态市场信息外，分析师代理还会建立股票池以进行投资组合管理，考虑股票收益之间的统计相关性。然后，经理代理对股票池中的每只股票做出交易决策。最后，经理代理通过计算工具确定所有股票的投资组合权重，该工具利用以下均值-方差优化
    [[66](#bib.bib66)]：
- en: '|  | $$\max_{\textbf{w}}\langle\textbf{w},\mu\rangle-\langle\textbf{w},\Sigma\textbf{w}\rangle\quad\text{s.t.}~{}w_{n}=\begin{cases}\in[0,1],&amp;\text{``long''''}\\
    \in[-1,0],&amp;\text{``short''''}\\'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | $$\max_{\textbf{w}}\langle\textbf{w},\mu\rangle-\langle\textbf{w},\Sigma\textbf{w}\rangle\quad\text{s.t.}~{}w_{n}=\begin{cases}\in[0,1],&amp;\text{``多头''''}\\
    \in[-1,0],&amp;\text{``空头''''}\\'
- en: =0,&amp;\text{``neutral''}\end{cases},~{}~{}\forall n\in\{1,\cdots,N\}$$ |  |
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: =0,&amp;\text{``中立''}\end{cases},~{}~{}\forall n\in\{1,\cdots,N\}$$ |  |
- en: where $\textbf{w}=(w_{1}\cdots,w_{N})\in\mathbb{R}^{N}$ sample covariance matrix
    of chosen stocks’ daily return sequences respectively [[26](#bib.bib26)]. We note
    that portfolio weights are rebalanced on daily basis. In our implementation, we
    first calculate the portfolio weights by solving the above optimization problem.
    Then, the target position is calculated by linearly scaling the portfolio weights
    from the prior step.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\textbf{w}=(w_{1}\cdots,w_{N})\in\mathbb{R}^{N}$ 是选定股票的日收益序列的样本协方差矩阵 [[26](#bib.bib26)]。我们注意到，投资组合权重是每天重新平衡的。在我们的实现中，我们首先通过解决上述优化问题来计算投资组合权重。然后，通过将先前步骤中的投资组合权重线性缩放来计算目标位置。
- en: 3.2 Modeling Quantitative Trading as POMDP
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 将量化交易建模为POMDP
- en: Formally, we model quantitative trading task as an infinite horizon POMDP [[67](#bib.bib67),
    [68](#bib.bib68)] with time index $\mathbb{T}=\{0,1,2,\cdots\}$, which represents
    the information processing outputs from analyst agents group.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 正式地，我们将量化交易任务建模为一个无限期POMDP [[67](#bib.bib67)、[68](#bib.bib68)]，时间索引为 $\mathbb{T}=\{0,1,2,\cdots\}$，该时间索引表示来自分析师代理组的信息处理输出。
- en: 'Then, our multi-agent system is supposed to learn the policies of all agents:
    the policies of analyst agents $\pi_{\theta^{i}}^{i}:\mathcal{X}\to\mathcal{A}^{i},i\in\{1,\cdots,I\}$)
    such that the system maximizes cumulative trading reward while controlling risk
    [[70](#bib.bib70)].'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们的多代理系统应该学习所有代理的策略：分析代理的策略 $\pi_{\theta^{i}}^{i}:\mathcal{X}\to\mathcal{A}^{i},i\in\{1,\cdots,I\}$，使得系统在控制风险的同时最大化累计交易奖励[[70](#bib.bib70)]。
- en: 'All policies $\Pi_{\bm{\theta}}=(\{\pi_{\theta^{i}}^{i}\}_{i=1}^{I},\pi_{\theta^{a}})$,
    the optimization objective for the whole system can be written as:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 所有策略 $\Pi_{\bm{\theta}}=(\{\pi_{\theta^{i}}^{i}\}_{i=1}^{I},\pi_{\theta^{a}})$，整个系统的优化目标可以写作：
- en: '|  | $\max_{\bm{\theta}}\mathbb{E}\Big{[}\sum\limits_{t\in\mathbb{T}}\alpha^{t}R^{\Pi^{\bm{\theta}}}_{t}\Big{]}$
    |  | (1) |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '|  | $\max_{\bm{\theta}}\mathbb{E}\Big{[}\sum\limits_{t\in\mathbb{T}}\alpha^{t}R^{\Pi^{\bm{\theta}}}_{t}\Big{]}$
    |  | (1) |'
- en: which is a risk-sensitive optimization problem with respect to textual gradient
    descent, being essentially different from DRL algorithms for POMDP.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种相对于文本梯度下降的风险敏感优化问题，本质上不同于DRL算法用于POMDP。
- en: 3.3 Textual Gradient-Descent
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 文本梯度下降
- en: In an LLM-based prompt optimizer, a meta-prompt [[18](#bib.bib18), [19](#bib.bib19)]
    is used to refine the task prompt for better performance. For example, for a mathematical
    reasoning task, the task prompt might be "Let’s solve the problem," while the
    meta-prompt could be "Improve the prompt to help a model better perform mathematical
    reasoning."
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于LLM的提示优化器中，使用了一个元提示[[18](#bib.bib18), [19](#bib.bib19)]来优化任务提示，以获得更好的性能。例如，对于一个数学推理任务，任务提示可能是“让我们解决这个问题”，而元提示可能是“改进提示以帮助模型更好地进行数学推理”。
- en: Although prompt optimization lacks explicit gradients to control the update
    direction, we can simulate “textual gradient” by using LLMs’ reflection capabilities.
    By generating feedback from past successes and failures on trading decisions,
    LLMs can produce "semantic" gradient signals that guide the optimization process.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管提示优化缺乏明确的梯度来控制更新方向，我们可以通过使用LLM的反射能力来模拟“文本梯度”。通过生成过去在交易决策中成功和失败的反馈，LLM可以产生“语义”梯度信号，以指导优化过程。
- en: Adjusting the optimization process’s direction is crucial, similar to tuning
    the learning rate in traditional parameter optimization. An inappropriate learning
    rate can cause the process to oscillate or converge too slowly. Similarly, without
    proper control, the LLM-based optimizer might overshoot or oscillate during prompt
    optimization.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 调整优化过程的方向至关重要，这类似于传统参数优化中的学习率调整。不合适的学习率可能导致过程振荡或收敛过慢。同样，如果没有适当的控制，基于LLM的优化器可能在提示优化过程中发生过度调整或振荡。
- en: To mimic learning rate effects, we measure the overlapping percentage between
    trading decision sequences from consecutive iterations. We then directly edit
    the previous task prompt to enhance performance. The meta-prompt instructs the
    LLM to modify the current prompt based on feedback, ensuring a stable and incremental
    improvement process. This method allows for effective exploitation of existing
    prompts, leading to gradual performance enhancement.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟学习率效果，我们测量连续迭代中交易决策序列的重叠百分比。然后，我们直接编辑之前的任务提示以提高性能。元提示指导LLM根据反馈修改当前提示，确保一个稳定且渐进的改进过程。这种方法允许有效利用现有提示，从而逐步提升性能。
- en: Factor Gradient-based model optimizer LLM-based prompt optimizer Upgrade direction
    Model value gradient momentum Prompt reflection trajectory Update method Learning
    rate descent Overlapping percentage of trading decisions
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 因子 基于梯度的模型优化器 基于LLM的提示优化器 升级方向 模型值梯度动量 提示反射轨迹 更新方法 学习率下降 交易决策的重叠百分比
- en: 'Table 1: Analogy between glossaries in model optimizer and prompt optimizer.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：模型优化器和提示优化器术语的类比。
- en: 4 General framework of FinCon
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 FinCon的一般框架
- en: '![Refer to caption](img/ac04c2bd6d54be23282b93f7ff50bc74.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ac04c2bd6d54be23282b93f7ff50bc74.png)'
- en: 'Figure 1: The general framework of FinCon.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：FinCon的一般框架。
- en: In this section, we present the architecture of FinCon using a two-level hierarchy.
    First, we describe the hierarchical framework for coordinating the agents’ synchronous
    work and communication. Then, we elaborate on the functionalities of each module
    that constitutes each agent in FinCon.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们使用两级层次结构展示了FinCon的架构。首先，我们描述了协调代理的同步工作和通信的层次框架。接着，我们详细说明了构成FinCon中每个代理的每个模块的功能。
- en: 4.1 Synthesized Multi-agent Hierarchical Structure Design
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 合成的多代理层次结构设计
- en: 'The agent system of FinCon consists of two main components: the Manager-Analyst
    Agent Group component and the Risk-Control component.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: FinCon的智能体系统由两个主要组成部分组成：经理-分析师智能体组和风险控制组件。
- en: 4.1.1 Manager-Analyst Agent Group
  id: totrans-50
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.1 经理-分析师智能体组
- en: 'Analogous to human investment teamwork, FinCon establishes a unique hierarchy
    to organize the multi-agent system, synthesizing their efforts to achieve superior
    decision returns. The primary objective is to improve information presentation
    and comprehension while reducing unnecessary communication costs. The detailed
    working mechanism of each agent is explained and illustrated in Figure [2](#S4.F2.1
    "Figure 2 ‣ 4.1.1 Manager-Analyst Agent Group ‣ 4.1 Synthesized Multi-agent Hierarchical
    Structure Design ‣ 4 General framework of FinCon ‣ FinCon: A Synthesized LLM Multi-Agent
    System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making"):'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '类似于人类投资团队，FinCon 建立了一个独特的层级结构来组织多智能体系统，综合他们的努力以实现优越的决策回报。主要目标是提高信息呈现和理解，同时减少不必要的沟通成本。每个智能体的详细工作机制在图[2](#S4.F2.1
    "Figure 2 ‣ 4.1.1 Manager-Analyst Agent Group ‣ 4.1 Synthesized Multi-agent Hierarchical
    Structure Design ‣ 4 General framework of FinCon ‣ FinCon: A Synthesized LLM Multi-Agent
    System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making")中进行了说明和展示。'
- en: '![Refer to caption](img/24cab6a4eaa23471cee8d5af292a939b.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/24cab6a4eaa23471cee8d5af292a939b.png)'
- en: 'Figure 2: The detailed architecture of FinCon contains two key components:
    Manager-Analyst agent group and Risk Control. It also presents the between-component
    interaction of FinCon and decision-making flow.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：FinCon的详细架构包含两个关键组成部分：经理-分析师智能体组和风险控制。它还展示了FinCon之间的组件交互和决策流程。
- en: 'Analyst Agents. In FinCon, analyst agents distill concise investment insights
    from large volumes of multi-source market information for one specific trading
    target. To ensure high reasoning quality by reducing task load and enhancing analysis
    focus, each agent processes a single information source in a uni-modal manner,
    delivering pre-specified outputs based on prompts. This setup mirrors an effective
    human team structure, where each analyst specializes in a specific function and
    synchronously filters market noise to extract essential insights. These agents
    support the manager agent in making informed decisions by consolidating denoised
    investment information from multiple perspectives. We design seven distinct types
    of analyst agents using LLMs, each producing diverse investment insights, as shown
    in the upper part of Figure [2](#S4.F2.1 "Figure 2 ‣ 4.1.1 Manager-Analyst Agent
    Group ‣ 4.1 Synthesized Multi-agent Hierarchical Structure Design ‣ 4 General
    framework of FinCon ‣ FinCon: A Synthesized LLM Multi-Agent System with Conceptual
    Verbal Reinforcement for Enhanced Financial Decision Making"). Differentiated
    by input modalities, three textual data processing agents distill insights and
    sentiments from daily news and financial reports. An audio agent extracts investment
    tendencies from earnings call recordings using the Whisper API. Additionally,
    a data analysis agent and a stock selection agent compute key financial metrics,
    such as momentum and CVaR, based on tabular time series data. The stock selection
    agent also manages portfolio selection following the classic risk diversification
    method in quantitative finance [[1](#bib.bib1)], as detailed in Appendix. [7.5](#S7.SS5
    "7.5 Portfolio Management ‣ 7 Appendix ‣ FinCon: A Synthesized LLM Multi-Agent
    System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making").'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '分析师智能体。在FinCon中，分析师智能体从大量多源市场信息中提取简明的投资见解，针对一个特定的交易目标。为了确保高推理质量，减少任务负荷并提高分析重点，每个智能体以单一信息源的方式进行处理，根据提示生成预设的输出。这种设置类似于有效的人类团队结构，每个分析师专注于特定功能，并同步过滤市场噪声以提取关键见解。这些智能体通过整合来自多个角度的去噪投资信息，帮助经理智能体做出明智的决策。我们设计了七种不同类型的分析师智能体，使用LLM，每种智能体产生多样的投资见解，如图[2](#S4.F2.1
    "Figure 2 ‣ 4.1.1 Manager-Analyst Agent Group ‣ 4.1 Synthesized Multi-agent Hierarchical
    Structure Design ‣ 4 General framework of FinCon ‣ FinCon: A Synthesized LLM Multi-Agent
    System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making")的上部所示。根据输入模式的不同，三个文本数据处理智能体从每日新闻和财务报告中提取见解和情绪。一个音频智能体使用Whisper
    API从财报电话录音中提取投资趋势。此外，一个数据分析智能体和一个股票选择智能体基于表格时间序列数据计算关键财务指标，如动量和CVaR。股票选择智能体还根据经典的量化金融风险分散方法管理投资组合，详细信息见附录[7.5](#S7.SS5
    "7.5 Portfolio Management ‣ 7 Appendix ‣ FinCon: A Synthesized LLM Multi-Agent
    System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making")。'
- en: 'Manager Agent. In the FinCon system, the manager agent is the sole decision
    maker, generating trading actions for sequential financial tasks. For portfolio
    management, it computes portfolio weights using convex optimization techniques
    constrained by the direction of actions (see Equation. ([3.1](#S3.Ex1 "3.1 Financial
    Decision-making Tasks Formulation ‣ 3 Preliminaries ‣ FinCon: A Synthesized LLM
    Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial
    Decision Making"))). Four mechanisms support each decision: 1) Consolidating distilled
    investment insights from multiple analyst agents. 2) Receiving timely risk alerts
    and conceptual investment updates from the risk control component. 3) Refining
    investment beliefs about the impact of various information sources on the manager’s
    decisions regarding a specific trading target. 4) Retrieving self-reflections
    based on the reasoning outcomes of previous trading actions.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '经理代理。在FinCon系统中，经理代理是唯一的决策者，为顺序金融任务生成交易行动。对于投资组合管理，它使用约束在行动方向上的凸优化技术计算投资组合权重（见公式。
    ([3.1](#S3.Ex1 "3.1 Financial Decision-making Tasks Formulation ‣ 3 Preliminaries
    ‣ FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement
    for Enhanced Financial Decision Making"))）。每个决策由四个机制支持：1) 汇总来自多个分析师代理的提炼投资见解。2)
    从风险控制组件接收及时的风险警报和概念投资更新。3) 精炼关于各种信息源对经理决策特定交易目标影响的投资信念。4) 基于先前交易行动的推理结果检索自我反思。'
- en: 4.1.2 Risk-Control Component
  id: totrans-56
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.2 风险控制组件
- en: We innovatively design a dual-level risk-control mechanism comprising within-episode
    and over-episode risk management. The within-episode risk control mechanism detects
    market risk within a single training episode, enabling the manager agent to adjust
    trading actions promptly to prevent potential losses, which takes account of short-term
    trading performance and market fluctuations. Additionally, the within-episode
    risk control mechanism also operates during the testing stage. In contrast, the
    over-episode risk control mechanism only functions during the training stage,
    and it provides updating directions for prompt optimization by comparing the trading
    performance of the current episode with the previous one. This reflection helps
    the manager agent update its investment beliefs based on the differences in performance.
    Informed by prior observations of market risk and profitability patterns, these
    two mechanisms can potentially avoid repetitive investment mistakes, thereby enhancing
    gains for future investments.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创新性地设计了一个双层风险控制机制，包括单集和跨集风险管理。单集风险控制机制在一个训练集内检测市场风险，使经理代理能够迅速调整交易行动以防止潜在损失，考虑到短期交易表现和市场波动。此外，单集风险控制机制在测试阶段也会操作。相比之下，跨集风险控制机制仅在训练阶段运行，并通过比较当前集与之前集的交易表现提供更新方向以进行及时优化。这种反思帮助经理代理基于表现差异更新其投资信念。通过对市场风险和盈利模式的先前观察，这两个机制可以潜在地避免重复的投资错误，从而提高未来投资的收益。
- en: 'Within-Episode Risk Control: . The within-episode risk alert is triggered by
    an instant drop in CVaR value. The rationale of this setting is that Conditional
    Value at Risk (CVaR) typically represents the average of the bottom 1% of past
    daily trading Profits and Losses (PnLs). When the CVaR value decreases on a given
    day, it often means that the PnLs from our trading decisions on the previous day
    (or days) are in the bottom 1%, indicating a potentially high-risk market condition.
    Once the within-episode risk is initiated, the manager agent is instructed to
    adopt a risk-averse attitude for the current day’s trading actions, regardless
    of the prior risk status.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 单集风险控制：单集风险警报由CVaR值的瞬时下降触发。这个设置的原理是，条件风险价值（CVaR）通常表示过去每日交易的损益（PnLs）中最底层1%的平均值。当CVaR值在某一天下降时，通常意味着我们在前一天（或前几天）的交易决策产生的PnLs处于底层1%，这表明市场条件可能具有较高的风险。一旦启动单集风险控制，经理代理将被指示对当前日的交易采取风险厌恶的态度，而不考虑之前的风险状态。
- en: 'Over-Episode Risk Control: The over-episode investment belief updates facilitate
    timely adjustments in the emphasis placed on the analyst’s information distillation
    and the manager’s action generation. Through the Actor-Critic mechanism, FinCon episodically
    optimizes its investment strategy for a given trading target by deeply reflecting
    on continuous winning and losing actions. The episodic reflection of investment
    beliefs is generated by a unique Conceptual Verbal Reinforcement (CVRF). CVRF
    evaluates the performance of every two adjacent training episodes based on the
    information perspectives provided by analysts and available in the manager’s trading
    reasoning. It then conceptualizes and attributes the evaluation outcomes to these
    aspects. By comparing the conceptualized aspects of investment insights from both
    more profitable and less profitable episodes, the system informs the manager and
    analyst agents about the necessary belief adjustments for each market information
    aspect to prioritize for greater profit, following the steps of Algorithm [1](#alg1
    "Algorithm 1 ‣ 4.1.2 Risk-Control Component ‣ 4.1 Synthesized Multi-agent Hierarchical
    Structure Design ‣ 4 General framework of FinCon ‣ FinCon: A Synthesized LLM Multi-Agent
    System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making").
    CVRF utilizes text-based gradient descent to provide optimal conceptual investment
    guidance on a given target asset, substantially refining prompts with the latest
    investment beliefs for the manager agent. The obtained guidance is also meticulously
    organized from perspectives corresponding to insights from specific analyst agents,
    key financial indicators such as historical momentum, or other necessary perspectives.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '超剧集风险控制：超剧集投资信念更新有助于及时调整对分析师信息提炼和经理行动生成的重视程度。通过 Actor-Critic 机制，FinCon 在特定交易目标上通过深度反思持续的盈亏动作来周期性地优化其投资策略。投资信念的周期性反思由独特的概念性语言强化（CVRF）生成。CVRF
    根据分析师提供的信息视角和在经理的交易推理中可用的信息，评估每两个相邻训练剧集的表现。然后将评估结果概念化，并将其归因于这些方面。通过比较来自盈利和非盈利剧集的投资见解的概念化方面，系统通知经理和分析师代理有关每个市场信息方面的必要信念调整，以优先考虑更大的利润，遵循算法
    [1](#alg1 "Algorithm 1 ‣ 4.1.2 Risk-Control Component ‣ 4.1 Synthesized Multi-agent
    Hierarchical Structure Design ‣ 4 General framework of FinCon ‣ FinCon: A Synthesized
    LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial
    Decision Making") 的步骤。CVRF 利用基于文本的梯度下降提供对给定目标资产的最佳概念性投资指导，实质性地细化经理代理的最新投资信念提示。所获得的指导也从相应的分析师代理的见解、历史动量等关键金融指标或其他必要视角中仔细整理。'
- en: These investment belief updates are initially received by the manager agent
    and selectively propagated to relevant agent nodes, thereby minimizing over-communication.
    Additionally, unlike the text-based gradient descent proposed by Tang et al.[[19](#bib.bib19)],
    which uses prompt editing distance as the learning rate, we obtain investment
    belief prompt updates by measuring the overlapping percentage of trading actions
    between two adjacent training trajectories achieved at each investment belief
    update. This approach has proven effective in enhancing the performance of a synthesized
    agent system, where each worker has a clearly defined and specialized responsibility.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这些投资信念更新最初由经理代理接收，并选择性地传播到相关代理节点，从而减少过度通信。此外，与 Tang 等人提出的基于文本的梯度下降方法[[19](#bib.bib19)]不同，该方法使用提示编辑距离作为学习率，我们通过测量在每次投资信念更新时，相邻训练轨迹之间的交易动作重叠百分比来获得投资信念提示更新。这种方法在增强合成代理系统的性能方面已被证明是有效的，其中每个工人都有明确和专业的职责。
- en: 'Algorithm 1 Training Stage Algorithm of FinCon: Conceptual Verbal Reinforcement
    using Textual-based Gradient Descent'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 1 FinCon 训练阶段算法：基于文本的梯度下降的概念性语言强化
- en: Initialize manager-analysts component $\{M_{pr}^{i}\}^{I}_{i=1}\&amp;M_{a}$  end while
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化经理-分析师组件 $\{M_{pr}^{i}\}^{I}_{i=1}\&amp;M_{a}$ 结束时
- en: 4.1.3 FinCon Test Stage Workflow
  id: totrans-63
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.3 FinCon 测试阶段工作流程
- en: During the testing stage, FinCon will utilize the investment beliefs learned
    from the training stage, and the over-episode risk control mechanism will no longer
    operate. However, the within-episode risk control mechanism will still function,
    allowing the manager agent to adjust trading actions in real-time based on short-term
    trading performance and market fluctuations. This ensures that even during testing,
    FinCon can promptly respond to market risks and potentially prevent losses while
    leveraging the knowledge gained during training.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试阶段，FinCon 将利用从训练阶段学到的投资信念，过期风险控制机制将不再运行。然而，剧中风险控制机制仍将起作用，允许管理代理根据短期交易表现和市场波动实时调整交易行动。这确保了即使在测试期间，FinCon
    也能及时响应市场风险，并在利用训练期间获得的知识的同时可能防止损失。
- en: Algorithm 2 Testing Stage Algorithm of FinCon
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 算法2 FinCon 测试阶段算法
- en: Initialize trading start date $s$.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化交易开始日期$s$。
- en: 4.2 Modular Design of FinCon Agents
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 FinCon 代理的模块化设计
- en: 'Here, we explain the modular design of FinCon agents. Inspired by the recent
    works of Park et al. [[61](#bib.bib61)] and Sumers et al. [[71](#bib.bib71)] on
    developing the cognitive structure of language agents for human-like behavior,
    agents in FinCon integrate four modules to support their necessary functionalities,
    along with a shared general configuration, as detailed in Figure [3](#S4.F3 "Figure
    3 ‣ 4.2 Modular Design of FinCon Agents ‣ 4 General framework of FinCon ‣ FinCon:
    A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for
    Enhanced Financial Decision Making"):'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '在这里，我们解释了 FinCon 代理的模块化设计。受到 Park 等人 [[61](#bib.bib61)] 和 Sumers 等人 [[71](#bib.bib71)]
    最近研究的启发，这些研究集中于开发具有人类行为的语言代理的认知结构，FinCon 的代理集成了四个模块以支持其必要的功能，并具有一个共享的通用配置，详细信息见图[3](#S4.F3
    "Figure 3 ‣ 4.2 Modular Design of FinCon Agents ‣ 4 General framework of FinCon
    ‣ FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement
    for Enhanced Financial Decision Making")。'
- en: General Configuration and Profiling Module. The general configuration defines
    the task types (e.g., stock trading, portfolio management) and specifies the trading
    targets, including background information like trading sectors and performance
    overviews. The profiling module outlines the roles and responsibilities of each
    agent in text. The textual content from these two parts is concatenated and used
    to query investment-related events stored in the agents’ memory databases.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 通用配置和分析模块。通用配置定义任务类型（例如，股票交易、投资组合管理），并指定交易目标，包括如交易部门和绩效概览等背景信息。分析模块概述了每个代理在文本中的角色和职责。这两个部分的文本内容被连接并用于查询存储在代理内存数据库中的投资相关事件。
- en: 'Perception Module. This module defines how an agent interacts with the market,
    specifying what they perceive, receive, and send. These aspects of information
    vary among different functional agents, as illustrated in Figure [3](#S4.F3 "Figure
    3 ‣ 4.2 Modular Design of FinCon Agents ‣ 4 General framework of FinCon ‣ FinCon:
    A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for
    Enhanced Financial Decision Making").'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '感知模块。该模块定义了代理如何与市场互动，指定他们感知、接收和发送的内容。这些信息方面在不同功能的代理之间有所不同，如图[3](#S4.F3 "Figure
    3 ‣ 4.2 Modular Design of FinCon Agents ‣ 4 General framework of FinCon ‣ FinCon:
    A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for
    Enhanced Financial Decision Making")所示。'
- en: 'General Configuration 1\. Investment
    task introduction    2\. Trading target background 3\. Trading sectors          4\.
    Historical financial performance overviewAction Module Manager Agent: 1\. Conduct:
    Trading actions. 2\. Reflect: Trading reasons and analyst agents’ contribution
    assessment.Profiling
    Module Manager Agent: 1\. Role assignment:
    You are an experienced trading manager in the investment firm … 2\. Role description:
    Your responsibilities are to consolidate investment insights from analysts and
    make trading actions on {asset symbols} … Analyst Agents: 1\. Role assignment:
    You are the investment analysts for news/ market data/ Form 10-K (Q)/ ECC audio
    recording … 2\. Role duty description: Your responsibilities are to distill investment
    insights and other indicators like financial sentiment for {asset symbols} …Perception Module Manager Agent: 1\. Perceive:
    Investment insights from analyst agents & Risk signal and trajectory-level investment
    belief updates from the risk control component. 2\. Send: Feedback to analyst
    agents about their contribution to significant investment earnings & losses. Analyst
    Agents: 1\. Perceive: Market information from certain information sources. 2\.
    Receive: Feedback from the manager agent.Memory Module Manager Agent: 1\. Working:
          - Consolidation          -Refinement 2\. Procedural:    - Trading action
    records    - Reflection records 3\. Episodic:       - Trajectory history Analyst
    Agents: 1\. Working:        - Observation    - Retrieval    - Distillation 2\.
    Procedural:     - Distilled Investment-related insights    - Financial sentiment
    - Investment report recommended actions'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '通用配置 1\. 投资任务介绍    2\. 交易目标背景 3\.
    交易领域          4\. 历史财务表现概览行动模块 经理代理人: 1\. 执行: 交易操作。 2\. 反馈: 交易原因及分析师代理人贡献评估。概况模块 经理代理人: 1\. 角色分配: 你是投资公司中经验丰富的交易经理…
    2\. 角色描述: 你的职责是整合分析师的投资见解，并对{资产符号}进行交易操作… 分析师代理人: 1\. 角色分配: 你是负责新闻/市场数据/Form 10-K
    (Q)/ECC音频记录的投资分析师… 2\. 角色职责描述: 你的职责是提炼投资见解和其他指标，如{资产符号}的财务情绪…感知模块 经理代理人: 1\. 感知: 从分析师代理人处获取投资见解及从风险控制组件获取风险信号和轨迹级投资信念更新。
    2\. 发送: 向分析师代理人反馈其对重大投资收益和损失的贡献。 分析师代理人: 1\. 感知: 从某些信息源获取市场信息。 2\. 接收: 从经理代理人处获得反馈。记忆模块 经理代理人: 1\. 工作:       - 整合         
    - 精炼 2\. 程序:    - 交易操作记录    - 反思记录 3\. 事件:       - 轨迹历史 分析师代理人: 1\. 工作:        -
    观察    - 检索    - 提炼 2\. 程序:     - 提炼的投资相关见解    - 财务情绪 - 投资报告推荐行动'
- en: 'Figure 3: The detailed modular design of the manager and analyst agents. The
    general configuration and profiling modules generate text-based queries to retrieve
    investment-related information from the agents’ memory databases. The perceptual
    and memory modules interact with LLMs via prompts to extract key investment insights.
    The action module of the manager agent consolidates these insights to facilitate
    informed trading decisions.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：经理和分析师代理的详细模块化设计。一般配置和概况模块生成基于文本的查询，以从代理的记忆数据库中检索投资相关信息。感知和记忆模块通过提示与LLMs互动，以提取关键投资见解。经理代理的行动模块整合这些见解，以促进知情的交易决策。
- en: 'Memory Module. The memory module contains three key components: working memory,
    procedural memory, and episodic memory. Similar to how humans process events in
    their working memory [[72](#bib.bib72)], FinCon agents utilize a working memory
    component to perform a series of operations, including observation, distillation,
    and refinement on available memory events, tailored to the agents’ specific roles.
    Procedural memory and episodic memory are essential for recording historical actions,
    outcomes, and reflections during sequential decision-making. Procedural memory
    is created after each decision step within an episode, storing data as memory
    events. For a trading inquiry, top events are retrieved from procedural memory,
    which are ranked based on recency, relevancy, and importance, which is the simplified
    version based on Yu et al. [[23](#bib.bib23)] and detailed in Appendix [7.6](#S7.SS6
    "7.6 Ranking Metrics for Procedural Memory in FinCon ‣ 7 Appendix ‣ FinCon: A
    Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced
    Financial Decision Making"). Different functional analyst agents possesses distinct
    procedural memory decay rates, reflecting the timeliness of various financial
    data sources, which is crucial for aligning multi-type data impacting a specific
    time point and facilitating informed decision-making. The manager agent augments
    the procedural memory of analyst agents by providing feedback through access counter.
    Procedural memory is maintained by both analyst and manager agents, each keeping
    different records, as shown in Figure [3](#S4.F3 "Figure 3 ‣ 4.2 Modular Design
    of FinCon Agents ‣ 4 General framework of FinCon ‣ FinCon: A Synthesized LLM Multi-Agent
    System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making").
    The episodic memory, exclusive to the manager agent, retains actions, PnL series
    of the previous episodes and conceptualized updated investment beliefs from the
    risk control component.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '内存模块。内存模块包含三个关键组件：工作记忆、程序记忆和情节记忆。类似于人类如何在工作记忆中处理事件[[72](#bib.bib72)]，FinCon 代理利用工作记忆组件执行一系列操作，包括对可用的记忆事件进行观察、提炼和优化，以适应代理的特定角色。程序记忆和情节记忆对于记录历史行动、结果和在序列决策过程中反思至关重要。程序记忆是在每个决策步骤后创建的，将数据存储为记忆事件。对于交易查询，从程序记忆中检索出的重要事件根据最近性、相关性和重要性进行排序，这是基于Yu等人的简化版本[[23](#bib.bib23)]，并在附录[7.6](#S7.SS6
    "7.6 Ranking Metrics for Procedural Memory in FinCon ‣ 7 Appendix ‣ FinCon: A
    Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced
    Financial Decision Making")中详细说明。不同功能分析师代理具有不同的程序记忆衰减率，反映了各种金融数据源的时效性，这对于对齐影响特定时间点的多类型数据并促进知情决策至关重要。经理代理通过访问计数器提供反馈，增强分析师代理的程序记忆。程序记忆由分析师和经理代理共同维护，各自保存不同的记录，如图[3](#S4.F3
    "Figure 3 ‣ 4.2 Modular Design of FinCon Agents ‣ 4 General framework of FinCon
    ‣ FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement
    for Enhanced Financial Decision Making")所示。情节记忆专属于经理代理，保留了之前情节的行动、PnL系列和风险控制组件中更新的投资信念。'
- en: 5 Experiments
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 实验
- en: 'Reasearch Questions (RQs). Our experiment addresses three major research questions:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 研究问题（RQs）。我们的实验涉及三个主要研究问题：
- en: $\diamond$
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\diamond$
- en: 'RQ1: Does FinCon demonstrate robustness across multiple financial decision-making
    tasks? We evaluate its performance on two challenging tasks: single-asset trading
    and portfolio management.'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: RQ1：FinCon是否在多种金融决策任务中表现出鲁棒性？我们在两个具有挑战性的任务上评估其性能：单资产交易和投资组合管理。
- en: $\diamond$
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\diamond$
- en: 'RQ2: Is the within-trajectory risk control mechanism in FinCon’s risk control
    component effective in maintaining superior decision-making performance?'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: RQ2：FinCon的风险控制组件中的轨迹内风险控制机制是否有效保持优越的决策性能？
- en: $\diamond$
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\diamond$
- en: 'RQ3: Is the over-trajectory risk control mechanism in FinCon’s risk control
    component effective for timely updating a manager agent’s beliefs and enhancing
    trading performance?'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: RQ3：FinCon风险控制组件中的超轨迹风险控制机制是否有效地更新经理代理的信念并提高交易表现？
- en: 5.1 Experimental Setup
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 实验设置
- en: 'Multi-Modal Datasets. We collect a multi-modal dataset from real-world financial
    information to construct a representation of the market environment. It is composed
    of stock price information, daily financial news, company filing reports, and
    ECC audio recordings ranging from August 1, 2020, to August 14, 2023, as detailed
    in Appendix. [7.1](#S7.SS1 "7.1 Raw Data Sources ‣ 7 Appendix ‣ FinCon: A Synthesized
    LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial
    Decision Making"). Each data source features distinct timeliness and is assigned
    to separate analyst agents to process. Typically, the time-sensitivity of annual
    filing reports (Form 10K’s) is more persistent, that of quarterly filing reports
    (Form 10Q’s) and ECC are secondary, and the daily financial news is the most instantaneous.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 多模态数据集。我们从现实世界的金融信息中收集了一个多模态数据集，以构建市场环境的表示。数据集包括股票价格信息、每日金融新闻、公司备案报告和ECC音频记录，时间范围为2020年8月1日到2023年8月14日，详细信息见附录[7.1](#S7.SS1
    "7.1 原始数据源 ‣ 7 附录 ‣ FinCon：一个综合LLM多智能体系统，通过概念性语言强化提升金融决策能力")。每个数据源具有不同的时效性，并分配给不同的分析代理进行处理。通常，年度备案报告（Form
    10K）的时间敏感性较持久，季度备案报告（Form 10Q）和ECC的时间敏感性次之，而每日金融新闻的时间敏感性最强。
- en: 'Evaluation Metrics. We evaluate the performance of FinCon and compare it with
    other state-of-the-art (SOTA) LLM-based and DRL-based agent systems using three
    standard financial performance metrics: Cumulative Return (CR%) [[73](#bib.bib73)],
    the Sharpe Ratio (SR) [[74](#bib.bib74)] and Max Drawdown (MDD%) [[75](#bib.bib75)].
    Detailed definitions can be found in Appendix [7.3](#S7.SS3 "7.3 Formula of Classic
    Financial Metrics for Risk Estimator ‣ 7 Appendix ‣ FinCon: A Synthesized LLM
    Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial
    Decision Making").'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 评价指标。我们评估了FinCon的表现，并将其与其他最先进（SOTA）的基于LLM和DRL的代理系统进行比较，使用了三个标准的金融绩效指标：累积回报率（CR%）[[73](#bib.bib73)]、夏普比率（SR）[[74](#bib.bib74)]和最大回撤（MDD%）[[75](#bib.bib75)]。详细定义可以在附录[7.3](#S7.SS3
    "7.3 经典金融指标的公式 ‣ 7 附录 ‣ FinCon：一个综合LLM多智能体系统，通过概念性语言强化提升金融决策能力")中找到。
- en: 'Comparative Methods. For the single stock trading task, we assess FinCon’s
    performance against seven algorithmic agents and the Buy-and-Hold (B & H) strategy,
    a widely accepted baseline. These include three DRL-based agents from the FinRL
    framework [[76](#bib.bib76)]: A2C, PPO, and DQN, and four SOTA LLM-based agents:
    Generative Agent by Park et al. [[11](#bib.bib11)], FinGPT [[77](#bib.bib77)],
    FinMem [[23](#bib.bib23)], and FinAgent [[24](#bib.bib24)]. For the portfolio
    management task, FinCon competes against the classical Markowitz MV portfolio
    selection strategy [[1](#bib.bib1)], the RL-based FinRL-A2C agent [[76](#bib.bib76)]
    and the B & H strategy that is to hold an equal-weighted position in all trading
    assets (so-called equal-weighted ETF). Our focus on classical portfolio strategy,
    RL methods and B & H methods is due to the limited availability of mature LLM
    agents for portfolio management. The detailed experiment parameter configuration
    is detailed articulated in Appendix. [7.7](#S7.SS7 "7.7 Detailed Configurations
    in Experiments ‣ 7 Appendix ‣ FinCon: A Synthesized LLM Multi-Agent System with
    Conceptual Verbal Reinforcement for Enhanced Financial Decision Making").'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 比较方法。对于单一股票交易任务，我们将FinCon的表现与七种算法代理和广泛接受的基准——买入并持有（B & H）策略进行比较。这些算法包括FinRL框架中的三种基于DRL的代理[[76](#bib.bib76)]：A2C、PPO和DQN，以及四种SOTA
    LLM-based 代理：Park等人的生成代理[[11](#bib.bib11)]、FinGPT [[77](#bib.bib77)]、FinMem [[23](#bib.bib23)]
    和FinAgent [[24](#bib.bib24)]。对于组合管理任务，FinCon与经典的Markowitz MV组合选择策略[[1](#bib.bib1)]、基于RL的FinRL-A2C代理[[76](#bib.bib76)]和B
    & H策略竞争，后者是在所有交易资产中持有等权重（即所谓的等权重ETF）。我们关注经典组合策略、RL方法和B & H方法，是由于成熟LLM代理在组合管理中的可用性有限。实验参数配置的详细信息在附录[7.7](#S7.SS7
    "7.7 实验中的详细配置 ‣ 7 附录 ‣ FinCon：一个综合LLM多智能体系统，通过概念性语言强化提升金融决策能力")中详细阐述。
- en: Implementation Details. In our experiments, all large language model (LLM)-based
    agent systems employ GPT-4-Turbo as their backbone algorithm, with the temperature
    parameter set at 0.3 to balance response consistency and reasoning creativity.
    FinCon is trained on financial data from January 3, 2022, to October 4, 2022,
    and is tested with data from October 5, 2022, to June 10, 2023\. Given that deep
    reinforcement learning (DRL) algorithms require extensive training data for convergence,
    we extend the DRL agents’ training period to approximately five years, from January
    1, 2018, to October 14, 2022, ensuring a fair comparison. The testing period remains
    consistent across all models. The performance metrics are reported for the test
    trajectory with the median CR and SR from five repeated epochs. (If the median
    CR and SR do not belong to the same epoch, the performance is based on the trajectory
    with the median CR.)
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 实施细节。在我们的实验中，所有基于大型语言模型（LLM）的代理系统都采用 GPT-4-Turbo 作为其核心算法，温度参数设置为0.3，以平衡响应一致性和推理创造力。FinCon
    以2022年1月3日到2022年10月4日的金融数据进行训练，并使用2022年10月5日到2023年6月10日的数据进行测试。考虑到深度强化学习（DRL）算法需要大量的训练数据来实现收敛，我们将DRL代理的训练期扩展至大约五年，从2018年1月1日到2022年10月14日，以确保公平比较。测试期在所有模型中保持一致。性能指标是针对测试轨迹报告的，其中包含来自五次重复周期的中位CR和SR。（如果中位CR和SR不属于同一周期，则性能基于具有中位CR的轨迹。）
- en: 5.2 Main Results
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 主要结果
- en: 'In response to RQ1, we conduct analyses on two types of financial decision-making
    tasks: single-asset trading and portfolio management. The capability of FinCon
    to handle such sequentially complex decisions is thoroughly evaluated in the subsequent
    sections.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 针对RQ1，我们对两种类型的金融决策任务进行了分析：单一资产交易和投资组合管理。FinCon 处理这些顺序复杂决策的能力在随后的部分中得到了全面评估。
- en: 5.2.1 Single Asset Trading Task
  id: totrans-89
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.1 单一资产交易任务
- en: In the first task, we evaluate the performance of FinCon against other leading
    algorithmic trading models by trading six different stocks. As shown in two tables
    above, FinCon significantly outperforms all the LLM-based and DRL-based approaches
    in terms of two primary metrics – cumulative returns and Sharpe Ratios. The FinCon’s
    Max Drawdown are also mostly among one of the lowest across all the trading assets,
    indicating a well-managed level of investment risk while still achieving the highest
    investment returns.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个任务中，我们通过交易六种不同的股票来评估FinCon与其他领先算法交易模型的表现。如上面两个表格所示，FinCon 在两个主要指标——累计回报和夏普比率上显著优于所有基于LLM和基于DRL的方法。FinCon的最大回撤也大多是所有交易资产中最低的之一，表明在实现最高投资回报的同时，投资风险管理水平良好。
- en: Overall, even with extended training periods, DRL-based models generally underperform.
    Specifically, the A2C algorithm significantly trails behind other algorithmic
    trading agents. Here, the training periods for Nio Inc (NIO) and Coinbase Global
    Inc (COIN) needs to be clarified. NIO completed its IPOs in September, 2018, so
    its training period is slightly shorter than other tickers. But the DRL algorithms
    for NIO still achieved convergence.The IPO for Coinbase Global, Inc (COIN) was
    completed in April 2021\. With such limited trading data available, DRL algorithms
    struggle to converge, highlighting a significant limitation for DRL agents in
    automated trading of recent IPOs. Consequently, our analysis for COIN includes
    comparisons among FinCon, LLM-based trading agents, and the buy-and-hold strategy.
    In this analysis, FinCon demonstrates substantial performance advantages, achieving
    a cumulative return of over $57\%$. We also note that LLM-based agents, capable
    of utilizing diverse data types and requiring minimal training, effectively address
    the challenges that DRL algorithms face.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，即使在扩展的训练期下，基于DRL的模型通常表现不佳。特别是，A2C算法显著落后于其他算法交易代理。在这里，需要澄清Nio Inc (NIO)和Coinbase
    Global Inc (COIN)的训练期。NIO于2018年9月完成了首次公开募股（IPO），因此其训练期略短于其他股票。但NIO的DRL算法仍然实现了收敛。Coinbase
    Global, Inc (COIN)的IPO于2021年4月完成。由于交易数据有限，DRL算法难以收敛，这突显了DRL代理在近期IPO自动交易中的一个重大限制。因此，我们对COIN的分析包括了FinCon、基于LLM的交易代理和买入持有策略的比较。在这项分析中，FinCon显示出显著的性能优势，累计回报超过**57%**。我们还注意到，能够利用多种数据类型并且训练要求较少的LLM-based代理有效地解决了DRL算法面临的挑战。
- en: '| Categories | Models | TSLA |  | AMZN |  | NIO |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 类别 | 模型 | TSLA |  | AMZN |  | NIO |'
- en: '| CR$\%\uparrow$ |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| CR$\%\uparrow$ |'
- en: '| Market | B&H | 6.425 | 0.145 | 58.150 |  | 1.914 | 0.067 | 34.317 |  | -77.210
    | -1.449 | 63.975 |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 市场 | B&H | 6.425 | 0.145 | 58.150 |  | 1.914 | 0.067 | 34.317 |  | -77.210
    | -1.449 | 63.975 |'
- en: '| Our Model | FinCon | 82.871 | 1.972 | 29.727 |  | 24.964 | 0.906 | 25.889
    |  | 17.461 | 0.335 | 40.647 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 我们的模型 | FinCon | 82.871 | 1.972 | 29.727 |  | 24.964 | 0.906 | 25.889 |  |
    17.461 | 0.335 | 40.647 |'
- en: '| LLM-based | GA | 16.535 | 0.391 | 54.131 |  | -5.515 | -0.195 | 37.213 |  |
    -3.176 | -1.574 | 3.155 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 基于LLM | GA | 16.535 | 0.391 | 54.131 |  | -5.515 | -0.195 | 37.213 |  | -3.176
    | -1.574 | 3.155 |'
- en: '| FinGPT | 1.549 | 0.044 | 42.400 |  | -29.811 | -1.805 | -29.671 |  | -4.959
    | -0.121 | 37.344 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| FinGPT | 1.549 | 0.044 | 42.400 |  | -29.811 | -1.805 | -29.671 |  | -4.959
    | -0.121 | 37.344 |'
- en: '| FinMem | 34.624 | 1.552 | 15.674 |  | -18.126 | -0.776 | 36.825 |  | -48.437
    | -1.180 | 64.144 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| FinMem | 34.624 | 1.552 | 15.674 |  | -18.126 | -0.776 | 36.825 |  | -48.437
    | -1.180 | 64.144 |'
- en: '| FinAgent | 11.960 | 0.271 | 55.734 |  | -24.704 | -1.496 | 33.151 |  | 0.933
    | 0.051 | 19.181 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| FinAgent | 11.960 | 0.271 | 55.734 |  | -24.704 | -1.496 | 33.151 |  | 0.933
    | 0.051 | 19.181 |'
- en: '| DRL-based | A2C | -35.644 | -0.805 | 61.502 |  | -12.676 | -0.447 | 37.179
    |  | -91.910 | -1.728 | 68.911 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 基于DRL | A2C | -35.644 | -0.805 | 61.502 |  | -12.676 | -0.447 | 37.179 |  |
    -91.910 | -1.728 | 68.911 |'
- en: '| PPO | 1.409 | 0.032 | 49.740 |  | 3.863 | 0.137 | 28.085 |  | -72.119 | -1.352
    | 62.093 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| PPO | 1.409 | 0.032 | 49.740 |  | 3.863 | 0.137 | 28.085 |  | -72.119 | -1.352
    | 62.093 |'
- en: '| DQN | -1.296 | -0.029 | 58.150 |  | 11.171 | 0.398 | 31.174 |  | -35.419
    | -0.662 | 56.905 |  | Categories | Models | APPL |  | GOOG |  | COIN |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| DQN | -1.296 | -0.029 | 58.150 |  | 11.171 | 0.398 | 31.174 |  | -35.419
    | -0.662 | 56.905 |  | 类别 | 模型 | APPL |  | GOOG |  | COIN |'
- en: '| CR$\%\uparrow$ |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| CR$\%\uparrow$ |'
- en: '| Market | B&H | 22.315 | 1.107 | 20.659 |  | 22.420 | 0.891 | 21.191 |  |
    -21.756 | -0.311 | 60.187 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 市场 | B&H | 22.315 | 1.107 | 20.659 |  | 22.420 | 0.891 | 21.191 |  | -21.756
    | -0.311 | 60.187 |'
- en: '| Our Model | FinCon | 27.352 | 1.597 | 15.266 |  | 25.077 | 1.0521 | 17.5299
    |  | 57.045 | 0.825 | 42.679 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 我们的模型 | FinCon | 27.352 | 1.597 | 15.266 |  | 25.077 | 1.0521 | 17.5299 |  |
    57.045 | 0.825 | 42.679 |'
- en: '| LLM-based | GA | 5.694 | 0.372 | 14.161 |  | -0.0151 | -0.192 | 8.210 |  |
    19.271 | 0.277 | 67.532 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 基于LLM | GA | 5.694 | 0.372 | 14.161 |  | -0.0151 | -0.192 | 8.210 |  | 19.271
    | 0.277 | 67.532 |'
- en: '| FinGPT | 20.321 | 1.161 | 16.759 |  | 0.207 | 0.822 | 21.191 |  | -99.553
    | -1.807 | 74.967 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| FinGPT | 20.321 | 1.161 | 16.759 |  | 0.207 | 0.822 | 21.191 |  | -99.553
    | -1.807 | 74.967 |'
- en: '| FinMem | 12.396 | 0.994 | 11.268 |  | 0.311 | 0.018 | 21.503 |  | 0.811 |
    0.017 | 50.390 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| FinMem | 12.396 | 0.994 | 11.268 |  | 0.311 | 0.018 | 21.503 |  | 0.811 |
    0.017 | 50.390 |'
- en: '| FinAgent | 20.757 | 1.041 | 19.896 |  | -7.440 | -1.024 | 10.360 |  | -5.971
    | -0.106 | 56.882 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| FinAgent | 20.757 | 1.041 | 19.896 |  | -7.440 | -1.024 | 10.360 |  | -5.971
    | -0.106 | 56.882 |'
- en: '| DRL-based | A2C | 13.781 | 0.683 | 14.226 |  | 8.562 | 0.340 | 21.191 |  |
    - | - | - |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 基于DRL | A2C | 13.781 | 0.683 | 14.226 |  | 8.562 | 0.340 | 21.191 |  | -
    | - | - |'
- en: '| PPO | 14.041 | 0.704 | 22.785 |  | 2.434 | -0.097 | 25.202 |  | - | - | -
    |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| PPO | 14.041 | 0.704 | 22.785 |  | 2.434 | -0.097 | 25.202 |  | - | - | -
    |'
- en: '| DQN | 21.125 | 1.048 | 16.131 |  | 20.690 | 0.822 | 21.191 |  | - | - | -
    |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| DQN | 21.125 | 1.048 | 16.131 |  | 20.690 | 0.822 | 21.191 |  | - | - | -
    |'
- en: 'Table 2: Comparison of key performance metrics during the testing period for
    the single-asset trading tasks involving six stocks, between FinCon and other
    algorithmic agents. Note that the highest and second highest CRs and SRs have
    been tested and found statistically significant using the Wilcoxon signed-rank
    test. The highest CRs and SRs are highlighted in red, while the second highest
    are marked in blue.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：比较了涉及六只股票的单资产交易任务中，FinCon与其他算法代理的关键性能指标。注意，最高和第二高的CRs和SRs经过Wilcoxon符号秩检验，并被认为具有统计学意义。最高的CRs和SRs以红色突出显示，第二高的以蓝色标记。
- en: 'Moreover, in alignment with market trends, FinCon consistently exhibits superior
    sequential decision-making quality compared to other LLM-based financial agents,
    irrespective of whether the market conditions are bullish (e.g., GOOG), bearish
    (e.g., NIO), or mixed (e.g., TSLA). We attribute this performance to its high-quality
    distillation process through a synthesized multi-agent collaboration mechanism
    and its dual-functional risk control design, which collectively position FinCon
    as a leader in this space. Compared to FinCon, FinGPT primarily bases its trading
    decisions on the LLMs’ ability to interpret sentiment in financial information.
    This approach does not fully capitalize on the LLMs’ capacity to synthesize nuanced
    investment-related textual insights with numerical financial indicators. GA and
    FinMem, on the other hand, utilize single-agent frameworks that do not incorporate
    sophisticated information distillation processes or a diverse set of tools. This
    lack of complexity places considerable demand on the agent to process and reason
    through multi-sourced information, particularly when faced with large and varied
    data modalities. Additionally, they employ a static or minimal investment belief
    system. As a result, their ability to filter noise from mixed market data is relatively
    weak. As illustrated in Figure [7](#S5.F7 "Figure 7 ‣ 5.3.2 The Efficacy of Over-Episode
    Belief Updates Using CVRF ‣ 5.3 Ablation Studies ‣ 5 Experiments ‣ FinCon: A Synthesized
    LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial
    Decision Making") (a) & (b), this limitation leads them to consistently maintain
    a lower position and exhibit hesitation regarding ‘buy’ or ‘sell’ decisions, ultimately
    resulting in suboptimal performance. FinCon overcomes these limitations through
    its innovative multi-agent synthesis, enabling it to deliver better outcomes.
    While FinAgent positions itself as a foundational framework capable of utilizing
    multi-modal data, its performance is robust with images and tabular data but does
    not exhibit a competitive edge when integrating audio data, such as ECC audio,
    which is crucial in real-world trading. Additionally, its decision-relevant memory
    retrieval process is based on similarity, leading the agent to make current decisions
    based on outdated memories, often resulting in errors. In contrast, the memory
    structure of FinCon is designed to account for the varying timeliness of multi-sourced
    financial data, ultimately delivering significantly superior decision quality.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，与市场趋势保持一致，FinCon在连续决策质量方面始终优于其他基于LLM的金融代理，无论市场条件是看涨（例如GOOG）、看跌（例如NIO）还是混合（例如TSLA）。我们将这种表现归因于其通过综合多代理协作机制进行的高质量提炼过程和双重功能的风险控制设计，这些因素共同使FinCon在这一领域中处于领先地位。与FinCon相比，FinGPT主要基于LLM在金融信息中的情感解读能力来做出交易决策。这种方法未能充分利用LLM在综合细致的投资相关文本见解与数值金融指标方面的能力。另一方面，GA和FinMem采用的是单代理框架，这些框架未融入复杂的信息提炼过程或多样化的工具。这种缺乏复杂性的设计使得代理在处理和推理多源信息时面临较大挑战，尤其是在面对大量和多样化的数据模式时。此外，它们采用静态或最小化的投资信念系统。因此，它们在过滤混合市场数据中的噪声能力相对较弱。如图[7](#S5.F7
    "图 7 ‣ 5.3.2 使用CVRF的跨阶段信念更新的有效性 ‣ 5.3 消融研究 ‣ 5 实验 ‣ FinCon：一种综合LLM多代理系统，通过概念性语言强化提高金融决策质量")
    (a) & (b)所示，这种局限性导致它们始终保持较低的状态，并对“买入”或“卖出”决策表现出犹豫，最终导致表现不佳。FinCon通过其创新的多代理综合克服了这些局限性，能够提供更好的结果。尽管FinAgent将自己定位为能够利用多模态数据的基础框架，其在图像和表格数据上的表现稳健，但在集成音频数据（如ECC音频）时未显示出竞争优势，而这些音频数据在实际交易中至关重要。此外，它的决策相关记忆检索过程基于相似性，使得代理在当前决策时依赖过时的记忆，常常导致错误。相比之下，FinCon的记忆结构设计考虑了多源金融数据的时效性差异，最终提供了显著优越的决策质量。
- en: '![Refer to caption](img/8e9d56beb232a243b6034550ac7b99ef.png)![Refer to caption](img/1a6777659900384ffa9b525ee3779b68.png)![Refer
    to caption](img/909bc411364430ddffcf2197ad25b2b3.png)![Refer to caption](img/1050c68bf689227beabed36208f8067f.png)![Refer
    to caption](img/42598960cd06797d8e3c91e082a718e5.png)![Refer to caption](img/962953bac0ce93b5a4727bb252d65a1d.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/8e9d56beb232a243b6034550ac7b99ef.png)![参见标题](img/1a6777659900384ffa9b525ee3779b68.png)![参见标题](img/909bc411364430ddffcf2197ad25b2b3.png)![参见标题](img/1050c68bf689227beabed36208f8067f.png)![参见标题](img/42598960cd06797d8e3c91e082a718e5.png)![参见标题](img/962953bac0ce93b5a4727bb252d65a1d.png)'
- en: 'Figure 4: CRs over time for single-asset trading tasks. FinCon outperformed
    other comparative strategies, achieving the highest CRs across all six stocks
    by the end of the testing period, regardless of market conditions.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：单资产交易任务中的 CR 随时间变化。FinCon 超越了其他比较策略，在测试期结束时，无论市场条件如何，六只股票中都达到了最高的 CR。
- en: 5.2.2 Portfolio Management Task
  id: totrans-117
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.2 投资组合管理任务
- en: 'To address the first research question, we compare FinCon’s performance with
    the Markowitz Mean-Variance (MV) portfolio [[78](#bib.bib78)] and FinRL [[76](#bib.bib76)]
    in managing a small portfolio of TSLA, MSFT, and PFE. Those assets are chosen
    by the stock selection agent from 42 stocks with sufficient amount of news data
    (over $800$ new messages in the training and test periods together), referring
    to Figure [9](#S7.F9 "Figure 9 ‣ 7.2 Distribution of Data ‣ 7 Appendix ‣ FinCon:
    A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for
    Enhanced Financial Decision Making") in Appendix [7.2](#S7.SS2 "7.2 Distribution
    of Data ‣ 7 Appendix ‣ FinCon: A Synthesized LLM Multi-Agent System with Conceptual
    Verbal Reinforcement for Enhanced Financial Decision Making"). The training &
    testing periods and backbone algorithm are consistent with those used in the single-asset
    trading task. For the Markowitz MV portfolio, we estimate the covariance matrix
    and expected returns using the same training data. For FinRL, we use 5-year training
    data before the test period. Our results, detailed in Table [3](#S5.T3 "Table
    3 ‣ Figure 5 ‣ 5.2.2 Portfolio Management Task ‣ 5.2 Main Results ‣ 5 Experiments
    ‣ FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement
    for Enhanced Financial Decision Making"), show that FinCon outperforms both the
    Markowitz MV portfolio and FinRL, achieving significantly higher cumulative returns
    and Sharpe Ratio, and lower Maximum Drawdown (MDD).'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '为了回答第一个研究问题，我们将 FinCon 的表现与 Markowitz 均值-方差 (MV) 投资组合 [[78](#bib.bib78)] 和
    FinRL [[76](#bib.bib76)] 在管理小型投资组合（包括 TSLA、MSFT 和 PFE）方面进行比较。这些资产由股票选择代理从 42 支具有足够新闻数据（在训练和测试期间共超过
    $800$ 条新消息）的股票中挑选，参见附录 [7.2](#S7.SS2 "7.2 数据分布 ‣ 7 附录 ‣ FinCon: 一种综合的 LLM 多代理系统，结合概念性语言强化以增强金融决策")
    中的图 [9](#S7.F9 "图 9 ‣ 7.2 数据分布 ‣ 7 附录 ‣ FinCon: 一种综合的 LLM 多代理系统，结合概念性语言强化以增强金融决策")。训练和测试周期以及基础算法与单资产交易任务中使用的保持一致。对于
    Markowitz MV 投资组合，我们使用相同的训练数据来估计协方差矩阵和预期收益。对于 FinRL，我们在测试期之前使用了 5 年的训练数据。我们的结果，如表
    [3](#S5.T3 "表 3 ‣ 图 5 ‣ 5.2.2 投资组合管理任务 ‣ 5.2 主要结果 ‣ 5 实验 ‣ FinCon: 一种综合的 LLM 多代理系统，结合概念性语言强化以增强金融决策")
    中详细说明，表明 FinCon 的表现优于 Markowitz MV 投资组合和 FinRL，取得了显著更高的累计回报和 Sharpe 比率，并且最大回撤
    (MDD) 更低。'
- en: However, there are stronger indications of hallucination in the multi-asset
    decision-making task compared to single-asset trading due to increased complexity
    and input length. Although FinCon reduces the workload of individual agents by
    distributing tasks and focusing on essential investment insights, it can still
    occasionally produce incorrect information, such as generating non-existent memory
    IDs and misclassifying action types (e.g., outputting ‘buy’ and ‘sell’ instead
    of ‘long’ and ‘short’). Handling multi-asset decision-making tasks requires intricate
    logic and substantial market information, posing a significant challenge for LLMs
    to comprehend extended contexts. This challenge has left portfolio management
    an untapped field for previous language agent studies. However, FinCon demonstrates
    the potential of constructing agent systems that can address complex financial
    problems through resource optimization, even when managing a relatively compact
    portfolio.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，与单资产交易任务相比，由于复杂性和输入长度的增加，多资产决策任务中的幻觉迹象更为明显。尽管 FinCon 通过分配任务和专注于关键投资见解来减轻了单个代理的工作负担，但它仍然偶尔会产生不正确的信息，如生成不存在的内存
    ID 和错误分类行动类型（例如，输出‘买入’和‘卖出’而不是‘多头’和‘空头’）。处理多资产决策任务需要复杂的逻辑和大量的市场信息，这对 LLM 理解扩展上下文提出了重大挑战。这一挑战使得投资组合管理成为以前语言代理研究中未曾涉足的领域。然而，FinCon
    展示了通过资源优化构建能够解决复杂金融问题的代理系统的潜力，即使是在管理相对紧凑的投资组合时。
- en: Models CR % $\uparrow$ FinCon 121.018 3.435 16.288 Markowitz MV 32.521 1.423
    20.658 FinRL-A2C 33.479 1.352 27.124 Equal-Weighted ETF 19.983 1.003 22.807
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 模型 CR % $\uparrow$ FinCon 121.018 3.435 16.288 Markowitz MV 32.521 1.423 20.658
    FinRL-A2C 33.479 1.352 27.124 等权重 ETF 19.983 1.003 22.807
- en: 'Table 3: Key performance metrics comparison among all portfolio management
    strategies. FinCon leads all performance metrics.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '表 3: 所有投资组合管理策略的关键性能指标比较。FinCon在所有性能指标中领先。'
- en: '![Refer to caption](img/cfb78d995cc88a7a23f75c56634026b2.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/cfb78d995cc88a7a23f75c56634026b2.png)'
- en: 'Figure 5: Portfolio value (CR for portfolio) changes over time for all the
    strategies.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '图 5: 所有策略的投资组合价值（投资组合的 CR）随时间变化。'
- en: 5.3 Ablation Studies
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 消融研究
- en: In this section, we comprehensively evaluate our unique risk control component
    through two ablation studies. The first study assesses its ability to control
    risk within episodes using conditional value at risk (CVaR). The second study
    highlights the importance of the over-episode risk control mechanism in updating
    the trading manager agent’s beliefs for a holistic understanding of current trading
    circumstances. Consistency in training and testing periods is maintained with
    the main experiments for both single stock trading and portfolio management tasks.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们通过两个消融研究全面评估了我们独特的风险控制组件。第一个研究评估其使用条件风险价值（CVaR）在期内控制风险的能力。第二个研究突出了期间风险控制机制在更新交易管理代理的信念以全面理解当前交易情况中的重要性。单一股票交易和投资组合管理任务的训练和测试周期与主要实验保持一致。
- en: 5.3.1 The Effectiveness of Within-Episode Risk Control mechanism via CVaR
  id: totrans-126
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.1 通过CVaR的期内风险控制机制的有效性
- en: 'To answer the RQ2, we conduct the first ablation study. We assess the efficacy
    of FinCon’s within-episode risk control mechanisms by monitoring system risk changes
    through CVaR. To demonstrate the robustness of FinCon, we compare the performance
    of FinCon with versus without CVaR implementation across two task types: single-asset
    trading and portfolio management. Furthermore, in single-asset trading tasks,
    we consider assets in both general bullish and bearish market conditions in the
    testing phase for comprehensive consideration.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 为回答RQ2，我们进行第一次消融研究。我们通过CVaR监控系统风险变化来评估FinCon的期内风险控制机制的有效性。为了展示FinCon的鲁棒性，我们比较了实施与未实施CVaR的FinCon在两种任务类型下的表现：单一资产交易和投资组合管理。此外，在单一资产交易任务中，我们在测试阶段考虑了普通牛市和熊市条件下的资产，以便进行全面的考虑。
- en: 'Our results demonstrate that implementing CVaR in FinCon is highly effective
    across all financial metrics for both task types, as shown in Table [4](#S5.T4
    "Table 4 ‣ 5.3.1 The Effectiveness of Within-Episode Risk Control mechanism via
    CVaR ‣ 5.3 Ablation Studies ‣ 5 Experiments ‣ FinCon: A Synthesized LLM Multi-Agent
    System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making")
    and Fig [6](#S5.F6 "Figure 6 ‣ 5.3.1 The Effectiveness of Within-Episode Risk
    Control mechanism via CVaR ‣ 5.3 Ablation Studies ‣ 5 Experiments ‣ FinCon: A
    Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced
    Financial Decision Making"). For single-asset trading tasks, FinCon without within-episode
    risk control yields negative CRs and significantly higher MDDs, underperforming
    compared to the Buy-and-Hold strategy (CR of GOOG: $22.42\%$ with within-episode
    risk control, demonstrating its effectiveness in risk supervision even amid non-uniform
    market trends.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '我们的结果表明，在FinCon中实施CVaR在所有金融指标上都非常有效，如表[4](#S5.T4 "Table 4 ‣ 5.3.1 The Effectiveness
    of Within-Episode Risk Control mechanism via CVaR ‣ 5.3 Ablation Studies ‣ 5 Experiments
    ‣ FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement
    for Enhanced Financial Decision Making")和图[6](#S5.F6 "Figure 6 ‣ 5.3.1 The Effectiveness
    of Within-Episode Risk Control mechanism via CVaR ‣ 5.3 Ablation Studies ‣ 5 Experiments
    ‣ FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement
    for Enhanced Financial Decision Making")所示。对于单一资产交易任务，未进行期内风险控制的FinCon产生了负的CR和显著更高的MDD，相比于买入持有策略表现较差（GOOG的CR:
    $22.42\%$，实施期内风险控制，证明了其在非均匀市场趋势中的风险监督效果）。'
- en: Task Assets Market Trend Models CR %$\uparrow$ w/ CVaR 7.981 0.157 40.647 w/o
    CVaR -70.791 -1.383 70.243 Portfolio Management (TSLA, MSFT, PFE) Mixed w/ CVaR
    121.018 3.435 16.288 w/o CVaR 16.994 1.303 17.646
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 任务 资产 市场趋势 模型 CR %$\uparrow$ 有CVaR 7.981 0.157 40.647 无CVaR -70.791 -1.383 70.243
    投资组合管理 (TSLA, MSFT, PFE) 混合 有CVaR 121.018 3.435 16.288 无CVaR 16.994 1.303 17.646
- en: 'Table 4: Key metrics FinCon with vs. without implementing CVaR for within-episode
    risk control. The performance of FinCon with the implementation of CVaR won a
    leading performance in both single-asset trading and portfolio management tasks.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '表 4: FinCon在实施与未实施CVaR的期内风险控制方面的关键指标比较。实施CVaR的FinCon在单一资产交易和投资组合管理任务中表现领先。'
- en: '![Refer to caption](img/00f4935630b3b3e59fb46a5825f239b8.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/00f4935630b3b3e59fb46a5825f239b8.png)'
- en: '(a) [1] Single Stock: General Bullish'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: (a) [1] 单一股票：总体看涨
- en: '![Refer to caption](img/ac47a018e2261fd74e53370b93f12294.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ac47a018e2261fd74e53370b93f12294.png)'
- en: '(b) [2] Single Stock: General Bearlish'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: (b) [2] 单一股票：总体看跌
- en: '![Refer to caption](img/57a14282ce4d244bcb6541b27d345fbf.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/57a14282ce4d244bcb6541b27d345fbf.png)'
- en: (c) Multi-Assets
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 多资产
- en: 'Figure 6: CRs of FinCon with vs. without implementing CVaR for within-episode
    risk control show that the CVaR mechanism significantly improves FinCon’s performance.
    This is evident from two metrics: (a) cumulative returns over time for single
    stocks in both bullish and bearish market conditions, and (b) portfolio value
    over time for a multi-asset portfolio. In both cases, FinCon with CVaR demonstrates
    substantially higher cumulative returns.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：实施 CVaR 与不实施 CVaR 进行期内风险控制的 FinCon 的 CR 值显示，CVaR 机制显著提高了 FinCon 的表现。这从两个指标可以看出：（a）在看涨和看跌市场条件下单一股票的累计收益，和（b）多资产投资组合的累计价值。在这两种情况下，采用
    CVaR 的 FinCon 显示出显著更高的累计收益。
- en: Specifically, the success of utilizing CVaR for within-episode risk control
    is evident in both bullish and bearish market environments, as shown in the single
    asset trading case. In bullish markets, CVaR sharply captures immediate market
    shocks and timely informs FinCon to exercise caution, even amidst general optimism.
    Conversely, in bearish markets, CVaR consistently alerts FinCon to significant
    price drops, ensuring awareness of market risks. Moreover, in portfolio trading
    with mixed price trends, our within-episode risk control mechanism performs robustly
    by monitoring the entire portfolio’s value fluctuations, enabling the trading
    manager agent to adjust potentially aggressive operations for each asset promptly.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 具体而言，CVaR 在期内风险控制中的成功在看涨和看跌市场环境中都很明显，如单一资产交易案例所示。在看涨市场中，CVaR 迅速捕捉到市场的即时冲击，并及时通知
    FinCon 在普遍乐观的情况下保持谨慎。相反，在看跌市场中，CVaR 一致地提醒 FinCon 关注重大价格下跌，确保对市场风险的警觉。此外，在具有混合价格趋势的投资组合交易中，我们的期内风险控制机制通过监控整个投资组合的价值波动表现稳健，使交易经理代理能够及时调整每个资产的潜在激进操作。
- en: 5.3.2 The Efficacy of Over-Episode Belief Updates Using CVRF
  id: totrans-139
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.2 CVRF 的跨阶段信念更新效果
- en: In the second ablation study, to answer RQ3, we use the same assets to examine
    the effectiveness of FinCon’s over-episode risk control mechanisms. This is achieved
    by consistently improving FinCon’s beliefs about market conditions for the targeted
    assets. To ensure consistent belief output for each training episode, we set the
    temperature parameter to 0 specifically for belief generation.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二次消融研究中，为了回答 RQ3，我们使用相同的资产来检验 FinCon 的跨阶段风险控制机制的有效性。这是通过持续改进 FinCon 对目标资产市场条件的信念来实现的。为了确保每个训练阶段的一致信念输出，我们专门将温度参数设置为
    0 以生成信念。
- en: 'We collect third-time belief updates over four training episodes using our
    innovative CVRF mechanism. The overlap of trading actions between the last two
    adjacent episodes increases to over $80\%$, and the updated investment beliefs
    are mostly aligned. To illustrate FinCon’s evolving investment beliefs through
    iterative training, we use the GOOG investment belief update as an example, as
    shown in Figure [8](#S5.F8 "Figure 8 ‣ 5.3.2 The Efficacy of Over-Episode Belief
    Updates Using CVRF ‣ 5.3 Ablation Studies ‣ 5 Experiments ‣ FinCon: A Synthesized
    LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial
    Decision Making"). Compared to the initial and final belief updates, each conceptual
    aspect, such as historical momentum and news insights, is enriched with executable
    information through our CRVF mechanism, leading to more profitable actions.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过创新的 CVRF 机制收集了四个训练阶段的第三次信念更新。最后两个相邻阶段之间的交易行为重叠度增加到超过 $80\%$，且更新后的投资信念大多一致。为了说明
    FinCon 通过迭代训练的投资信念演变，我们以 GOOG 投资信念更新为例，如图 [8](#S5.F8 "图 8 ‣ 5.3.2 CVRF 的跨阶段信念更新效果
    ‣ 5.3 消融研究 ‣ 5 实验 ‣ FinCon：结合概念性语言强化的合成 LLM 多智能体系统，提升金融决策能力") 所示。与初始和最终信念更新相比，每个概念方面，如历史动量和新闻见解，通过我们的
    CRVF 机制得到了可执行的信息丰富，从而导致更有利可图的操作。
- en: 'The results in Table [5](#S5.T5 "Table 5 ‣ 5.3.2 The Efficacy of Over-Episode
    Belief Updates Using CVRF ‣ 5.3 Ablation Studies ‣ 5 Experiments ‣ FinCon: A Synthesized
    LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial
    Decision Making") and Figure [7](#S5.F7 "Figure 7 ‣ 5.3.2 The Efficacy of Over-Episode
    Belief Updates Using CVRF ‣ 5.3 Ablation Studies ‣ 5 Experiments ‣ FinCon: A Synthesized
    LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial
    Decision Making") indicate that the over-episode belief update mechanism is more
    critical than within-episode risk control in enhancing FinCon’s decision-making.
    Without this functionality, key metrics like CR, SR, and MDD are lower than without
    the within-episode risk control in single asset trading. Although the CR of $20.677\%$.
    These results demonstrate that using CVRF to update investment beliefs over episodes
    efficiently steers the agent’s investment beliefs towards more profitable directions.
    FinCon achieves superior performance on multiple tasks, with learning gains evident
    after just four training episodes, requiring far fewer episodes than traditional
    RL algorithmic trading agents.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [5](#S5.T5 "表 5 ‣ 5.3.2 使用 CVRF 的超轨迹信念更新的效果 ‣ 5.3 消融研究 ‣ 5 实验 ‣ FinCon：一个合成的
    LLM 多智能体系统，通过概念性语言强化提高金融决策") 和图 [7](#S5.F7 "图 7 ‣ 5.3.2 使用 CVRF 的超轨迹信念更新的效果 ‣
    5.3 消融研究 ‣ 5 实验 ‣ FinCon：一个合成的 LLM 多智能体系统，通过概念性语言强化提高金融决策") 表明，超剧集信念更新机制在提升 FinCon
    的决策能力方面比剧集内风险控制更为关键。没有这个功能，CR、SR 和 MDD 等关键指标低于没有剧集内风险控制的单一资产交易。尽管 CR 为 $20.677\%$。这些结果表明，使用
    CVRF 更新投资信念能够有效引导代理人的投资信念朝向更盈利的方向。FinCon 在多个任务上表现优异，学习增益在仅经过四个训练剧集后即显现，相较于传统的
    RL 算法交易代理人需要的剧集显著较少。
- en: Task Assets Market Trend Models CR %$\uparrow$ w/ belief 7.981 0.157 40.647
    w/o belief -17.956 -0.356 55.688 Portfolio Management (TSLA, MSFT, PFE) Mixed
    w/ belief 121.018 3.435 16.288 w/o belief 20.677 0.987 23.975
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 任务 资产 市场趋势 模型 CR %$\uparrow$ 有信念 7.981 0.157 40.647 无信念 -17.956 -0.356 55.688
    投资组合管理 (TSLA, MSFT, PFE) 混合 有信念 121.018 3.435 16.288 无信念 20.677 0.987 23.975
- en: 'Table 5: Key metrics FinCon with vs. without implementing belief updates for
    over-trajectory risk control. The performance of FinCon with the implementation
    of CVaR won a leading performance in both single-asset trading and portfolio management
    tasks.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：FinCon 在实施与不实施信念更新的超轨迹风险控制下的关键指标。实施 CVaR 的 FinCon 在单一资产交易和投资组合管理任务中均表现出领先性能。
- en: '![Refer to caption](img/cc82eb6b272820b149d212f95da4b459.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/cc82eb6b272820b149d212f95da4b459.png)'
- en: '(a) [1] Single Stock: General Bullish'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: (a) [1] 单一股票：总体看涨
- en: '![Refer to caption](img/28198ac7164b3a33fe17ba3152bee47c.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/28198ac7164b3a33fe17ba3152bee47c.png)'
- en: '(b) [2] Single Stock: General Bearlish'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: (b) [2] 单一股票：总体看跌
- en: '![Refer to caption](img/19129b6932e7b32ad9e513e629f4bd36.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/19129b6932e7b32ad9e513e629f4bd36.png)'
- en: (c) Multi-Assets
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 多资产
- en: 'Figure 7: CRs of FinCon with vs. without belief updates for over-trajectory
    risk control. (a) The CRs over time for single stocks. The performance of FinCon
    with belief updates consistently leads in both bullish and bearish market conditions.
    (b) The CRs over time for multi-asset portfolio. FinCon’s performance with belief
    updates also won a substantially higher CR.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：FinCon 在实施与不实施信念更新的超轨迹风险控制下的 CR。 (a) 单一股票的 CR 随时间变化。FinCon 在信念更新下的表现始终领先于看涨和看跌市场条件。
    (b) 多资产投资组合的 CR 随时间变化。FinCon 在信念更新下的表现也显著提高了 CR。
- en: 'Updated Investment Belief Contents First Update:
    {’historical momentum’: ’Enhance the use of momentum indicators by establishing
    systematic rules for entry and exit based on momentum values to improve consistency
    and predictability in trading actions.’, ’news insights’: ’Integrate advanced
    real-time news sentiment analysis to better understand immediate market reactions
    and adjust trading strategies accordingly…’, ’Form 10-Q’: ’Incorporating annual
    report insights (10-K) could provide a comprehensive view of the company’s long-term
    performance and strategic direction, aiding in more informed decision-making.’…,
    ’other aspects’: [’sector trends’, ’technological advancements’], …} Last Update:
    {’historical momentum’: ’The more profitable strategy effectively utilizes negative
    momentum values to make timely sell decisions, avoiding potential losses during
    downward trends, and effectively utilizes positive momentum values to make timely
    buy decisions, facilitating potential gains during upward trends. It is suggested
    to refine the use of momentum indicators, possibly by adjusting thresholds or
    incorporating additional short-term momentum metrics to enhance the timing and
    accuracy of buy/sell decisions.’, ’news insights’: ’It is recommended to further
    develop a systematic approach to quantify the impact of news, especially the sentiment
    scores and regulatory changes, to refine trading decisions.’, ’Form 10-Q’: ’It
    is suggested that even if there is a strong financial performance present 10-Q
    reports, it is better to prioritize immediate market signals. For future strategies,
    it is suggested to balance these aspects more evenly, especially in stable or
    bullish market conditions, to avoid premature exits from potentially profitable
    positions.’,…, ’other aspects’: [’sector trends’, ’technological advancements’,
    ’macroeconomic factors’, ’regulatory risks’], …}Tradng Action Overlapping Percentages 1\. Second
    vs. First Training Episode:   $46.939\%$'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '更新的投资信念内容 第一次更新：{’历史动量’: ’通过建立基于动量值的系统化入场和出场规则来增强动量指标的使用，以提高交易行为的一致性和可预测性。’，’新闻洞察’:
    ’整合先进的实时新闻情绪分析，以更好地理解即时市场反应，并据此调整交易策略……’，’Form 10-Q’: ’纳入年度报告见解（10-K）可以提供公司长期业绩和战略方向的全面视角，有助于做出更明智的决策。’……，’其他方面’:
    [’行业趋势’，’技术进步’]，……} 最新更新：{’历史动量’: ’更有利可图的策略有效利用负动量值来做出及时的卖出决策，避免在下跌趋势期间可能的损失，并有效利用正动量值来做出及时的买入决策，促进在上涨趋势期间的潜在收益。建议改进动量指标的使用，可能通过调整阈值或结合额外的短期动量指标来提高买入/卖出的时机和准确性。’，’新闻洞察’:
    ’建议进一步发展系统化的方法来量化新闻的影响，特别是情绪评分和监管变化，以细化交易决策。’，’Form 10-Q’: ’建议即使10-Q报告显示出强劲的财务表现，也应优先考虑即时市场信号。对于未来的策略，建议在这些方面更均衡，特别是在稳定或牛市市场条件下，以避免过早退出潜在的盈利位置。’……，’其他方面’:
    [’行业趋势’，’技术进步’，’宏观经济因素’，’监管风险’]，……}交易行动重叠百分比 1\. 第二次与第一次训练情节：  $46.939\%$'
- en: 'Figure 8: The first time and last time LLM generated investment belief updates
    by CVRF for GOOG.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：CVRF生成的GOOG投资信念更新的首次和最后一次时间。
- en: 6 Conclusion
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: In this paper, we present FinCon, a novel LLM-based multi-agent framework for
    financial decision-making tasks, including single stock trading and portfolio
    management. Central to FinCon is the Synthesized Manager-Analyst hierarchical
    communication structure and a dual-level risk control component. This communication
    method channels financial data from multiple sources to specialized analyst agents,
    who distill it into key investment insights. The manager agent then synthesizes
    these insights for decision-making. Our experimental evaluations demonstrate the
    efficacy of our risk control mechanism in mitigating investment risks and enhancing
    trading performance. Additionally, the streamlined communication structure reduces
    overhead. The dual-layered risk control component introduces a novel approach
    to defining agent personas, enabling dynamic updates of systematic risk and market
    beliefs within agent communication. A valuable future research direction would
    be to scale FinCon’s framework to manage large-sized portfolios comprising tens
    of assets, while maintaining the impressive decision-making quality demonstrated
    with smaller portfolios. Given the LLM’s input length constraint, a critical challenge
    lies in striking an optimal balance between information conciseness through agent
    distillation and potential performance deterioration when extending the current
    context window. Addressing this will be essential for ensuring quality-assured
    outcomes.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们介绍了FinCon，一种基于LLM的多代理框架用于金融决策任务，包括单股交易和投资组合管理。FinCon的核心是合成的经理-分析师层次化通信结构和双层风险控制组件。这种通信方法将来自多个来源的金融数据引导到专业的分析师代理中，这些分析师将数据提炼成关键的投资见解。经理代理随后综合这些见解进行决策。我们的实验评估展示了我们风险控制机制在减轻投资风险和提升交易表现方面的有效性。此外，精简的通信结构减少了开销。双层风险控制组件引入了一种新颖的代理角色定义方法，允许在代理通信中动态更新系统性风险和市场信念。一个有价值的未来研究方向是将FinCon框架扩展到管理包含数十种资产的大型投资组合，同时保持在较小投资组合中展示出的卓越决策质量。鉴于LLM的输入长度限制，关键挑战在于在代理提炼信息的简洁性与扩展当前上下文窗口可能导致的性能下降之间取得最佳平衡。解决这个问题对于确保结果的质量至关重要。
- en: References
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Harry Markowitz. Portfolio selection. The Journal of Finance, 7(1):77–91,
    1952.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] 哈里·马科维茨。投资组合选择。《金融杂志》，7(1):77–91，1952年。'
- en: '[2] Xuan-Hong Dang, Syed Yousaf Shah, and Petros Zerfos. " the squawk bot":
    Joint learning of time series and text data modalities for automated financial
    information filtering. arXiv preprint arXiv:1912.10858, 2019.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] 邓玄洪、赛义德·尤萨夫·沙赫、彼得罗斯·泽尔福斯。“啄木鸟机器人”：联合学习时间序列和文本数据模态以进行自动化金融信息筛选。arXiv预印本
    arXiv:1912.10858，2019年。'
- en: '[3] John L Maginn, Donald L Tuttle, Dennis W McLeavey, and Jerald E Pinto.
    Managing investment portfolios: a dynamic process, volume 3. John Wiley & Sons,
    2007.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] 约翰·L·马金、唐纳德·L·塔特尔、丹尼斯·W·麦克利维、杰拉尔德·E·平托。管理投资组合：一个动态过程，第3卷。约翰·威利与儿子出版社，2007年。'
- en: '[4] Roy Radner. The organization of decentralized information processing. Econometrica:
    Journal of the Econometric Society, pages 1109–1146, 1993.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] 罗伊·拉德纳。去中心化信息处理的组织。《计量经济学杂志》，第1109–1146页，1993年。'
- en: '[5] George A Miller. The magical number seven, plus or minus two: Some limits
    on our capacity for processing information. Psychological review, 63(2):81, 1956.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] 乔治·A·米勒。神奇的七，加减二：我们处理信息能力的一些限制。《心理学评论》，63(2):81，1956年。'
- en: '[6] Rundong Wang, Hongxin Wei, Bo An, Zhouyan Feng, and Jun Yao. Commission
    fee is not enough: A hierarchical reinforced framework for portfolio management.
    In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages
    626–633, 2021.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] 王润东、魏洪新、博安、冯周燕、姚军。佣金费用不够：一种层次化的强化框架用于投资组合管理。发表于《AAAI人工智能会议论文集》，第35卷，第626–633页，2021年。'
- en: '[7] Weiguang Han, Boyi Zhang, Qianqian Xie, Min Peng, Yanzhao Lai, and Jimin
    Huang. Select and trade: Towards unified pair trading with hierarchical reinforcement
    learning. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery
    and Data Mining, pages 4123–4134, 2023.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] 韩伟光、张博义、谢倩倩、彭敏、赖燕昭、黄季敏。选择和交易：基于层次化强化学习的统一配对交易。发表于《第29届ACM SIGKDD知识发现与数据挖掘会议论文集》，第4123–4134页，2023年。'
- en: '[8] Molei Qin, Shuo Sun, Wentao Zhang, Haochong Xia, Xinrun Wang, and Bo An.
    Earnhft: Efficient hierarchical reinforcement learning for high frequency trading.
    In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages
    14669–14676, 2024.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Molei Qin, Shuo Sun, Wentao Zhang, Haochong Xia, Xinrun Wang, 和 Bo An.
    Earnhft：高频交易的高效层次强化学习。见《美国人工智能协会会议论文集》，第38卷，第14669–14676页，2024。'
- en: '[9] Chan Hee Song, Jiaman Wu, Clayton Washington, Brian M Sadler, Wei-Lun Chao,
    and Yu Su. Llm-planner: Few-shot grounded planning for embodied agents with large
    language models. In Proceedings of the IEEE/CVF International Conference on Computer
    Vision, pages 2998–3009, 2023.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Chan Hee Song, Jiaman Wu, Clayton Washington, Brian M Sadler, Wei-Lun Chao,
    和 Yu Su. Llm-planner：针对具身代理的少样本基础规划与大型语言模型。见《IEEE/CVF计算机视觉国际会议论文集》，第2998–3009页，2023。'
- en: '[10] Bhargavi Paranjape, Scott Lundberg, Sameer Singh, Hannaneh Hajishirzi,
    Luke Zettlemoyer, and Marco Tulio Ribeiro. Art: Automatic multi-step reasoning
    and tool-use for large language models. arXiv preprint arXiv:2303.09014, 2023.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Bhargavi Paranjape, Scott Lundberg, Sameer Singh, Hannaneh Hajishirzi,
    Luke Zettlemoyer, 和 Marco Tulio Ribeiro. Art：大型语言模型的自动多步骤推理和工具使用。arXiv 预印本 arXiv:2303.09014,
    2023。'
- en: '[11] Joon Sung Park, Joseph C O’Brien, Carrie J Cai, Meredith Ringel Morris,
    Percy Liang, and Michael S Bernstein. Generative agents: Interactive simulacra
    of human behavior. arXiv preprint arXiv:2304.03442, 2023.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Joon Sung Park, Joseph C O’Brien, Carrie J Cai, Meredith Ringel Morris,
    Percy Liang, 和 Michael S Bernstein. 生成代理：人类行为的交互式模拟体。arXiv 预印本 arXiv:2304.03442,
    2023。'
- en: '[12] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang
    Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. Autogen: Enabling next-gen
    llm applications via multi-agent conversation framework. arXiv preprint arXiv:2308.08155,
    2023.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang
    Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, 和 Chi Wang. Autogen：通过多代理对话框架启用下一代llm应用。arXiv
    预印本 arXiv:2308.08155, 2023。'
- en: '[13] Shuofei Qiao, Ningyu Zhang, Runnan Fang, Yujie Luo, Wangchunshu Zhou,
    Yuchen Eleanor Jiang, Chengfei Lv, and Huajun Chen. Autoact: Automatic agent learning
    from scratch via self-planning. arXiv preprint arXiv:2401.05268, 2024.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Shuofei Qiao, Ningyu Zhang, Runnan Fang, Yujie Luo, Wangchunshu Zhou,
    Yuchen Eleanor Jiang, Chengfei Lv, 和 Huajun Chen. Autoact：通过自我规划从零开始的自动化代理学习。arXiv
    预印本 arXiv:2401.05268, 2024。'
- en: '[14] Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao
    Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, et al. Metagpt:
    Meta programming for multi-agent collaborative framework. arXiv preprint arXiv:2308.00352,
    2023.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao
    Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, 等。Metagpt：多代理协作框架的元编程。arXiv
    预印本 arXiv:2308.00352, 2023。'
- en: '[15] Xudong Guo, Kaixuan Huang, Jiale Liu, Wenhui Fan, Natalia Vélez, Qingyun
    Wu, Huazheng Wang, Thomas L Griffiths, and Mengdi Wang. Embodied llm agents learn
    to cooperate in organized teams. arXiv preprint arXiv:2403.12482, 2024.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Xudong Guo, Kaixuan Huang, Jiale Liu, Wenhui Fan, Natalia Vélez, Qingyun
    Wu, Huazheng Wang, Thomas L Griffiths, 和 Mengdi Wang. 具身的llm代理学会在有组织的团队中合作。arXiv
    预印本 arXiv:2403.12482, 2024。'
- en: '[16] Junkai Li, Siyu Wang, Meng Zhang, Weitao Li, Yunghwei Lai, Xinhui Kang,
    Weizhi Ma, and Yang Liu. Agent hospital: A simulacrum of hospital with evolvable
    medical agents. arXiv preprint arXiv:2405.02957, 2024.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Junkai Li, Siyu Wang, Meng Zhang, Weitao Li, Yunghwei Lai, Xinhui Kang,
    Weizhi Ma, 和 Yang Liu. Agent hospital：具有可进化医疗代理的医院模拟体。arXiv 预印本 arXiv:2405.02957,
    2024。'
- en: '[17] Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min
    Chan, Heyang Yu, Yaxi Lu, Yi-Hsin Hung, Chen Qian, et al. Agentverse: Facilitating
    multi-agent collaboration and exploring emergent behaviors. In The Twelfth International
    Conference on Learning Representations, 2023.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min
    Chan, Heyang Yu, Yaxi Lu, Yi-Hsin Hung, Chen Qian, 等。Agentverse：促进多代理合作和探索新兴行为。在第十二届国际学习表示会议上,
    2023。'
- en: '[18] Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang Zhu, and Michael
    Zeng. Automatic prompt optimization with" gradient descent" and beam search. arXiv
    preprint arXiv:2305.03495, 2023.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang Zhu, 和 Michael
    Zeng. 自动提示优化与“梯度下降”及束搜索。arXiv 预印本 arXiv:2305.03495, 2023。'
- en: '[19] Xinyu Tang, Xiaolei Wang, Wayne Xin Zhao, Siyuan Lu, Yaliang Li, and Ji-Rong
    Wen. Unleashing the potential of large language models as prompt optimizers: An
    analogical analysis with gradient-based model optimizers. arXiv preprint arXiv:2402.17564,
    2024.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Xinyu Tang, Xiaolei Wang, Wayne Xin Zhao, Siyuan Lu, Yaliang Li, 和 Ji-Rong
    Wen. 释放大型语言模型作为提示优化器的潜力：与基于梯度的模型优化器的类比分析。arXiv 预印本 arXiv:2402.17564, 2024。'
- en: '[20] Weiran Yao, Shelby Heinecke, Juan Carlos Niebles, Zhiwei Liu, Yihao Feng,
    Le Xue, Rithesh Murthy, Zeyuan Chen, Jianguo Zhang, Devansh Arpit, et al. Retroformer:
    Retrospective large language agents with policy gradient optimization. arXiv preprint
    arXiv:2308.02151, 2023.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] 伟然姚、谢尔比·海内克、胡安·卡洛斯·尼布莱斯、智伟刘、伊浩·冯、乐雪、里特什·穆尔蒂、泽源陈、建国张、德万什·阿尔皮特等。Retroformer:
    具有策略梯度优化的回顾性大语言代理。arXiv预印本 arXiv:2308.02151, 2023。'
- en: '[21] Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and
    Shunyu Yao. Reflexion: Language agents with verbal reinforcement learning. Advances
    in Neural Information Processing Systems, 36, 2024.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] 诺亚·申、费德里科·卡萨诺、阿什温·戈皮纳斯、卡尔提克·纳拉辛汉和舜宇·姚。Reflexion: 具有语言强化学习的语言代理。神经信息处理系统进展，36，2024。'
- en: '[22] Hongyang Yang, Xiao-Yang Liu, and Christina Dan Wang. Fingpt: Open-source
    financial large language models. arXiv preprint arXiv:2306.06031, 2023.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] 宏洋·杨、小杨·刘和克里斯蒂娜·丹·王。Fingpt: 开源金融大语言模型。arXiv预印本 arXiv:2306.06031, 2023。'
- en: '[23] Yangyang Yu, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Denghui Zhang,
    Rong Liu, Jordan W Suchow, and Khaldoun Khashanah. Finmem: A performance-enhanced
    llm trading agent with layered memory and character design. arXiv preprint arXiv:2311.13743,
    2023.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] 杨洋余、浩航李、智辰陈、悦辰姜、杨李、邓辉张、荣刘、乔丹·W·苏乔和哈勒顿·卡什纳。Finmem: 一种具有分层记忆和角色设计的性能增强LLM交易代理。arXiv预印本
    arXiv:2311.13743, 2023。'
- en: '[24] Wentao Zhang, Lingxuan Zhao, Haochong Xia, Shuo Sun, Jiaze Sun, Molei
    Qin, Xinyi Li, Yuqing Zhao, Yilei Zhao, Xinyu Cai, et al. Finagent: A multimodal
    foundation agent for financial trading: Tool-augmented, diversified, and generalist.
    arXiv preprint arXiv:2402.18485, 2024.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] 闻涛·张、灵轩·赵、浩冲·夏、硕·孙、佳泽·孙、莫雷·秦、欣怡·李、玉青·赵、一雷·赵、新宇·蔡等。Finagent: 一种用于金融交易的多模态基础代理：工具增强、多样化和通用型。arXiv预印本
    arXiv:2402.18485, 2024。'
- en: '[25] Freddy Delbaen and Sara Biagini. Coherent risk measures. Springer, 2000.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] 弗雷迪·德尔班和萨拉·比阿尼尼。连贯风险度量。施普林格出版社，2000。'
- en: '[26] Frank J Fabozzi, Sergio M Focardi, and Petter N Kolm. Quantitative equity
    investing: Techniques and strategies. John Wiley & Sons, 2010.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] 弗兰克·J·法博兹齐、塞尔吉奥·M·福卡尔迪和佩特尔·N·科尔姆。定量股票投资：技术与策略。约翰·威利父子公司，2010。'
- en: '[27] Xinyi Liu, Chong Zhang, Mingyu Jin, Zhongmou Zhang, Zhenting Wang, Dong
    Shu, Suiyuan Zhu, Sujian Li, Mengnan Du, and Yongfeng Zhang. When ai meets finance
    (stockagent): Large language model-based stock trading in simulated real-world
    environments. 2024.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] 欣怡·刘、冲·张、明玉·金、钟谋·张、镇庭·王、董舒、隋元·朱、苏建·李、梦楠·杜和永丰·张。当AI遇见金融（Stockagent）：基于大语言模型的股票交易在模拟现实环境中的应用。2024。'
- en: '[28] Keith Kuester, Stefan Mittnik, and Marc S Paolella. Value-at-risk prediction:
    A comparison of alternative strategies. Journal of Financial Econometrics, 4(1):53–89,
    2006.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] 基思·库斯特、斯特凡·米特尼克和马克·S·保利拉。风险价值预测：替代策略的比较。金融计量经济学杂志，4(1)：53–89, 2006。'
- en: '[29] Noah Shinn, Beck Labash, and Ashwin Gopinath. Reflexion: an autonomous
    agent with dynamic memory and self-reflection. arXiv preprint arXiv:2303.11366,
    2023.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] 诺亚·申、贝克·拉巴什和阿什温·戈皮纳斯。Reflexion: 一种具有动态记忆和自我反思的自主代理。arXiv预印本 arXiv:2303.11366,
    2023。'
- en: '[30] Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin, Yong-Jin Liu, and
    Gao Huang. Expel: Llm agents are experiential learners. In Proceedings of the
    AAAI Conference on Artificial Intelligence, volume 38, pages 19632–19642, 2024.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] 安德鲁·赵、丹尼尔·黄、昆汀·徐、马修·林、永金·刘和高黄。Expel: LLM代理是经验学习者。在AAAI人工智能会议论文集中，第38卷，19632–19642页，2024。'
- en: '[31] Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser,
    Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al.
    Competition-level code generation with alphacode. Science, 378(6624):1092–1097,
    2022.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] 余佳李、大卫·崔、俊勇·钟、内特·库什曼、朱利安·施里特维塞尔、雷米·勒布朗、汤姆·埃克尔斯、詹姆斯·基林、费利克斯·吉梅诺、奥古斯丁·达·拉戈等。使用AlphaCode的竞赛级代码生成。科学，378(6624)：1092–1097,
    2022。'
- en: '[32] Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang
    Lou, and Weizhu Chen. Codet: Code generation with generated tests. arXiv preprint
    arXiv:2207.10397, 2022.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] 贝·陈、冯基·张、安·阮、道广·赞、泽奇·林、简光·楼和韦朱·陈。Codet: 具有生成测试的代码生成。arXiv预印本 arXiv:2207.10397,
    2022。'
- en: '[33] Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan
    Liu, and Maosong Sun. Communicative agents for software development. arXiv preprint
    arXiv:2307.07924, 2023.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] 陈乾、辛聪、程阳、伟泽·陈、宇生·苏、居源·徐、志远·刘和茅松·孙。用于软件开发的沟通型代理。arXiv预印本 arXiv:2307.07924,
    2023。'
- en: '[34] Zelai Xu, Chao Yu, Fei Fang, Yu Wang, and Yi Wu. Language agents with
    reinforcement learning for strategic play in the werewolf game. arXiv preprint
    arXiv:2310.18940, 2023.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] Zelai Xu、Chao Yu、Fei Fang、Yu Wang 和 Yi Wu。用于狼人游戏战略玩法的语言代理与强化学习。arXiv 预印本
    arXiv:2310.18940，2023年。'
- en: '[35] Weiyu Ma, Qirui Mi, Xue Yan, Yuqiao Wu, Runji Lin, Haifeng Zhang, and
    Jun Wang. Large language models play starcraft ii: Benchmarks and a chain of summarization
    approach. arXiv preprint arXiv:2312.11865, 2023.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] Weiyu Ma、Qirui Mi、Xue Yan、Yuqiao Wu、Runji Lin、Haifeng Zhang 和 Jun Wang。大型语言模型在星际争霸
    II 中的表现：基准测试与总结链方法。arXiv 预印本 arXiv:2312.11865，2023年。'
- en: '[36] J de Curtò, I de Zarzà, Gemma Roig, Juan Carlos Cano, Pietro Manzoni,
    and Carlos T Calafate. Llm-informed multi-armed bandit strategies for non-stationary
    environments. Electronics, 12(13):2814, 2023.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] J de Curtò、I de Zarzà、Gemma Roig、Juan Carlos Cano、Pietro Manzoni 和 Carlos
    T Calafate。针对非平稳环境的基于大型语言模型的多臂赌博机策略。《电子学》，12(13)：2814，2023年。'
- en: '[37] Huaqin Zhao, Zhengliang Liu, Zihao Wu, Yiwei Li, Tianze Yang, Peng Shu,
    Shaochen Xu, Haixing Dai, Lin Zhao, Gengchen Mai, et al. Revolutionizing finance
    with llms: An overview of applications and insights. arXiv preprint arXiv:2401.11641,
    2024.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] Huaqin Zhao、Zhengliang Liu、Zihao Wu、Yiwei Li、Tianze Yang、Peng Shu、Shaochen
    Xu、Haixing Dai、Lin Zhao、Gengchen Mai 等。利用大型语言模型革新金融：应用与见解概述。arXiv 预印本 arXiv:2401.11641，2024年。'
- en: '[38] Yupeng Cao, Zhi Chen, Qingyun Pei, Fabrizio Dimino, Lorenzo Ausiello,
    Prashant Kumar, KP Subbalakshmi, and Papa Momar Ndiaye. Risklabs: Predicting financial
    risk using large language model based on multi-sources data. arXiv preprint arXiv:2404.07452,
    2024.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] Yupeng Cao、Zhi Chen、Qingyun Pei、Fabrizio Dimino、Lorenzo Ausiello、Prashant
    Kumar、KP Subbalakshmi 和 Papa Momar Ndiaye。Risklabs：基于多源数据的大型语言模型金融风险预测。arXiv 预印本
    arXiv:2404.07452，2024年。'
- en: '[39] Lorenzo Canese, Gian Carlo Cardarilli, Luca Di Nunzio, Rocco Fazzolari,
    Daniele Giardino, Marco Re, and Sergio Spanò. Multi-agent reinforcement learning:
    A review of challenges and applications. Applied Sciences, 11(11):4948, 2021.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] Lorenzo Canese、Gian Carlo Cardarilli、Luca Di Nunzio、Rocco Fazzolari、Daniele
    Giardino、Marco Re 和 Sergio Spanò。多智能体强化学习：挑战与应用综述。《应用科学》，11(11)：4948，2021年。'
- en: '[40] Kaiqing Zhang, Zhuoran Yang, and Tamer Başar. Multi-agent reinforcement
    learning: A selective overview of theories and algorithms. Handbook of reinforcement
    learning and control, pages 321–384, 2021.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] Kaiqing Zhang、Zhuoran Yang 和 Tamer Başar。多智能体强化学习：理论与算法的选择性概述。《强化学习与控制手册》，第321–384页，2021年。'
- en: '[41] Jakob Foerster, Ioannis Alexandros Assael, Nando De Freitas, and Shimon
    Whiteson. Learning to communicate with deep multi-agent reinforcement learning.
    Advances in neural information processing systems, 29, 2016.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] Jakob Foerster、Ioannis Alexandros Assael、Nando De Freitas 和 Shimon Whiteson。通过深度多智能体强化学习学习沟通。《神经信息处理系统进展》，29，2016年。'
- en: '[42] Toru Lin, Jacob Huh, Christopher Stauffer, Ser Nam Lim, and Phillip Isola.
    Learning to ground multi-agent communication with autoencoders. Advances in Neural
    Information Processing Systems, 34:15230–15242, 2021.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] Toru Lin、Jacob Huh、Christopher Stauffer、Ser Nam Lim 和 Phillip Isola。利用自编码器学习多智能体沟通的基础。《神经信息处理系统进展》，34：15230–15242，2021年。'
- en: '[43] Woojun Kim, Jongeui Park, and Youngchul Sung. Communication in multi-agent
    reinforcement learning: Intention sharing. In International Conference on Learning
    Representations, 2020.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] Woojun Kim、Jongeui Park 和 Youngchul Sung。在多智能体强化学习中的沟通：意图共享。2020年国际学习表示会议。'
- en: '[44] Changxi Zhu, Mehdi Dastani, and Shihan Wang. A survey of multi-agent reinforcement
    learning with communication. arXiv preprint arXiv:2203.08975, 2022.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] Changxi Zhu、Mehdi Dastani 和 Shihan Wang。带有沟通的多智能体强化学习综述。arXiv 预印本 arXiv:2203.08975，2022年。'
- en: '[45] Zhiyuan Yao, Zheng Li, Matthew Thomas, and Ionut Florescu. Reinforcement
    learning in agent-based market simulation: Unveiling realistic stylized facts
    and behavior. arXiv preprint arXiv:2403.19781, 2024.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] Zhiyuan Yao、Zheng Li、Matthew Thomas 和 Ionut Florescu。在基于代理的市场模拟中的强化学习：揭示现实的风格化事实和行为。arXiv
    预印本 arXiv:2403.19781，2024年。'
- en: '[46] Kuan Wang, Yadong Lu, Michael Santacroce, Yeyun Gong, Chao Zhang, and
    Yelong Shen. Adapting llm agents through communication. arXiv preprint arXiv:2310.01444,
    2023.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] Kuan Wang、Yadong Lu、Michael Santacroce、Yeyun Gong、Chao Zhang 和 Yelong
    Shen。通过沟通适应大型语言模型代理。arXiv 预印本 arXiv:2310.01444，2023年。'
- en: '[47] Zhao Mandi, Shreeya Jain, and Shuran Song. Roco: Dialectic multi-robot
    collaboration with large language models. arXiv preprint arXiv:2307.04738, 2023.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] Zhao Mandi、Shreeya Jain 和 Shuran Song。Roco：基于大型语言模型的辩证多机器人协作。arXiv 预印本
    arXiv:2307.04738，2023年。'
- en: '[48] Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B
    Tenenbaum, Tianmin Shu, and Chuang Gan. Building cooperative embodied agents modularly
    with large language models. arXiv preprint arXiv:2307.02485, 2023.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua
    B Tenenbaum, Tianmin Shu, 和 Chuang Gan. 使用大型语言模型模块化构建合作体代理. arXiv预印本 arXiv:2307.02485,
    2023.'
- en: '[49] Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch.
    Improving factuality and reasoning in language models through multiagent debate.
    arXiv preprint arXiv:2305.14325, 2023.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, 和 Igor Mordatch.
    通过多代理辩论改进语言模型的真实性和推理能力. arXiv预印本 arXiv:2305.14325, 2023.'
- en: '[50] Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang
    Zhang, Jie Fu, and Zhiyuan Liu. Chateval: Towards better llm-based evaluators
    through multi-agent debate. arXiv preprint arXiv:2308.07201, 2023.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang
    Zhang, Jie Fu, 和 Zhiyuan Liu. Chateval: 通过多代理辩论改进基于llm的评估器. arXiv预印本 arXiv:2308.07201,
    2023.'
- en: '[51] Frank Xing. Designing heterogeneous llm agents for financial sentiment
    analysis. arXiv preprint arXiv:2401.05799, 2024.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] Frank Xing. 设计用于金融情感分析的异构llm代理. arXiv预印本 arXiv:2401.05799, 2024.'
- en: '[52] Irene de Zarzà i Cubero, Joaquim de Curtò i Díaz, Gemma Roig, and Carlos T
    Calafate. Optimized financial planning: Integrating individual and cooperative
    budgeting models with llm recommendations. 2024.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] Irene de Zarzà i Cubero, Joaquim de Curtò i Díaz, Gemma Roig, 和 Carlos
    T Calafate. 优化金融规划：将个体和合作预算模型与llm推荐整合. 2024.'
- en: '[53] Xiangpeng Wan, Haicheng Deng, Kai Zou, and Shiqi Xu. Enhancing the efficiency
    and accuracy of underlying asset reviews in structured finance: The application
    of multi-agent framework. arXiv preprint arXiv:2405.04294, 2024.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] Xiangpeng Wan, Haicheng Deng, Kai Zou, 和 Shiqi Xu. 提升结构化金融中基础资产审查的效率和准确性：多代理框架的应用.
    arXiv预印本 arXiv:2405.04294, 2024.'
- en: '[54] Xinyi Liu, Chong Zhang, Mingyu Jin, Zhongmou Zhang, Zhenting Wang, Dong
    Shu, Suiyuan Zhu, Sujian Li, Mengnan Du, and Yongfeng Zhang. When ai meets finance
    (stockagent): Large language model-based stock trading in simulated real-world
    environments. 2024.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] Xinyi Liu, Chong Zhang, Mingyu Jin, Zhongmou Zhang, Zhenting Wang, Dong
    Shu, Suiyuan Zhu, Sujian Li, Mengnan Du, 和 Yongfeng Zhang. 当AI遇到金融（stockagent）：基于大型语言模型的股票交易在模拟现实世界环境中的应用.
    2024.'
- en: '[55] Patrick Bolton and Mathias Dewatripont. The firm as a communication network.
    The Quarterly Journal of Economics, 109(4):809–839, 1994.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] Patrick Bolton 和 Mathias Dewatripont. 公司作为一个通信网络. 《季刊经济学杂志》, 109(4):809–839,
    1994.'
- en: '[56] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan,
    and Yuan Cao. React: Synergizing reasoning and acting in language models. arXiv
    preprint arXiv:2210.03629, 2022.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan,
    和 Yuan Cao. React: 在语言模型中协同推理和行动. arXiv预印本 arXiv:2210.03629, 2022.'
- en: '[57] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi,
    Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in
    large language models. Advances in neural information processing systems, 35:24824–24837,
    2022.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi,
    Quoc V Le, Denny Zhou 等. 思维链提示引发大型语言模型的推理. 神经信息处理系统进展, 35:24824–24837, 2022.'
- en: '[58] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan
    Cao, and Karthik Narasimhan. Tree of thoughts: Deliberate problem solving with
    large language models. Advances in Neural Information Processing Systems, 36,
    2024.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan
    Cao, 和 Karthik Narasimhan. 思维树：使用大型语言模型进行深思熟虑的问题解决. 神经信息处理系统进展, 36, 2024.'
- en: '[59] Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang,
    and Zhiting Hu. Reasoning with language model is planning with world model. arXiv
    preprint arXiv:2305.14992, 2023.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang,
    和 Zhiting Hu. 使用语言模型进行推理即使用世界模型进行规划. arXiv预印本 arXiv:2305.14992, 2023.'
- en: '[60] Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu Yang,
    Gao Huang, Bin Li, Lewei Lu, Xiaogang Wang, et al. Ghost in the minecraft: Generally
    capable agents for open-world enviroments via large language models with text-based
    knowledge and memory. arXiv preprint arXiv:2305.17144, 2023.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu Yang,
    Gao Huang, Bin Li, Lewei Lu, Xiaogang Wang 等. Minecraft中的幽灵：通过大型语言模型与文本知识和记忆构建通用能力代理.
    arXiv预印本 arXiv:2305.17144, 2023.'
- en: '[61] Theodore Sumers, Shunyu Yao, Karthik Narasimhan, and Thomas L. Griffiths.
    Cognitive architectures for language agents, 2023.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] Theodore Sumers, Shunyu Yao, Karthik Narasimhan, 和 Thomas L. Griffiths.
    语言代理的认知架构, 2023.'
- en: '[62] Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang,
    Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al. A survey on large language
    model based autonomous agents. Frontiers of Computer Science, 18(6):1–26, 2024.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] Lei Wang、Chen Ma、Xueyang Feng、Zeyu Zhang、Hao Yang、Jingsen Zhang、Zhiyuan
    Chen、Jiakai Tang、Xu Chen、Yankai Lin 等人。基于大语言模型的自主代理综述。《计算机科学前沿》，18(6):1–26，2024年。'
- en: '[63] Leslie Pack Kaelbling, Michael L Littman, and Andrew W Moore. Reinforcement
    learning: A survey. Journal of artificial intelligence research, 4:237–285, 1996.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] Leslie Pack Kaelbling、Michael L Littman 和 Andrew W Moore。强化学习：综述。《人工智能研究期刊》，4:237–285，1996年。'
- en: '[64] Bin Zhang, Hangyu Mao, Jingqing Ruan, Ying Wen, Yang Li, Shao Zhang, Zhiwei
    Xu, Dapeng Li, Ziyue Li, Rui Zhao, et al. Controlling large language model-based
    agents for large-scale decision-making: An actor-critic approach. arXiv preprint
    arXiv:2311.13884, 2023.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] Bin Zhang、Hangyu Mao、Jingqing Ruan、Ying Wen、Yang Li、Shao Zhang、Zhiwei
    Xu、Dapeng Li、Ziyue Li、Rui Zhao 等人。控制基于大语言模型的代理进行大规模决策：一种演员-评论员方法。arXiv 预印本 arXiv:2311.13884，2023年。'
- en: '[65] Matthijs TJ Spaan. Partially observable markov decision processes. In
    Reinforcement learning: State-of-the-art, pages 387–414\. Springer, 2012.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] Matthijs TJ Spaan。部分可观测的马尔可夫决策过程。在《强化学习：现状》一书中，第387–414页。Springer，2012年。'
- en: '[66] Frank J Fabozzi, Harry M Markowitz, and Francis Gupta. Portfolio selection.
    Handbook of finance, 2, 2008.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] Frank J Fabozzi、Harry M Markowitz 和 Francis Gupta。投资组合选择。《金融手册》，2，2008年。'
- en: '[67] Yang Liu, Qi Liu, Hongke Zhao, Zhen Pan, and Chuanren Liu. Adaptive quantitative
    trading: An imitative deep reinforcement learning approach. In Proceedings of
    the AAAI conference on artificial intelligence, volume 34, pages 2128–2135, 2020.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] Yang Liu、Qi Liu、Hongke Zhao、Zhen Pan 和 Chuanren Liu。自适应定量交易：一种模仿的深度强化学习方法。在《AAAI
    人工智能会议论文集》上，第34卷，第2128–2135页，2020年。'
- en: '[68] Taylan Kabbani and Ekrem Duman. Deep reinforcement learning approach for
    trading automation in the stock market. IEEE Access, 10:93564–93574, 2022.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] Taylan Kabbani 和 Ekrem Duman。股票市场交易自动化的深度强化学习方法。《IEEE Access》，10:93564–93574，2022年。'
- en: '[69] Thomas L Griffiths, Jian-Qiao Zhu, Erin Grant, and R Thomas McCoy. Bayes
    in the age of intelligent machines. arXiv preprint arXiv:2311.10206, 2023.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] Thomas L Griffiths、Jian-Qiao Zhu、Erin Grant 和 R Thomas McCoy。智能机器时代的贝叶斯。arXiv
    预印本 arXiv:2311.10206，2023年。'
- en: '[70] Ashwin Rao and Tikhon Jelvis. Foundations of reinforcement learning with
    applications in finance. Chapman and Hall/CRC, 2022.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] Ashwin Rao 和 Tikhon Jelvis。《金融应用中的强化学习基础》。Chapman and Hall/CRC，2022年。'
- en: '[71] Jintian Zhang, Xin Xu, and Shumin Deng. Exploring collaboration mechanisms
    for llm agents: A social psychology view. arXiv preprint arXiv:2310.02124, 2023.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] Jintian Zhang、Xin Xu 和 Shumin Deng。探索 LLM 代理的协作机制：一种社会心理学视角。arXiv 预印本
    arXiv:2310.02124，2023年。'
- en: '[72] Anthony D Wagner. Working memory contributions to human learning and remembering.
    Neuron, 22(1):19–22, 1999.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] Anthony D Wagner。工作记忆对人类学习和记忆的贡献。《神经元》，22(1):19–22，1999年。'
- en: '[73] John Hull. Risk Management and Financial Institutions. John Wiley & Sons,
    2007.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] John Hull。《风险管理与金融机构》。John Wiley & Sons，2007年。'
- en: '[74] William F. Sharpe. The sharpe ratio. The Journal of Portfolio Management,
    21(1):49–58, 1994.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] William F. Sharpe。夏普比率。《投资组合管理期刊》，21(1):49–58，1994年。'
- en: '[75] Andrew Ang and Joseph Chen. Downside risk. Journal of Portfolio Management,
    29(4):103–112, 2003.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[75] Andrew Ang 和 Joseph Chen。下行风险。《投资组合管理期刊》，29(4):103–112，2003年。'
- en: '[76] Xiao-Yang Liu, Hongyang Yang, Qian Chen, Runjia Zhang, Liuqing Yang, Bowen
    Xiao, and Christina Dan Wang. Finrl: A deep reinforcement learning library for
    automated stock trading in quantitative finance. arXiv preprint arXiv:2011.09607,
    2020.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[76] Xiao-Yang Liu、Hongyang Yang、Qian Chen、Runjia Zhang、Liuqing Yang、Bowen
    Xiao 和 Christina Dan Wang。Finrl: 用于定量金融中自动化股票交易的深度强化学习库。arXiv 预印本 arXiv:2011.09607，2020年。'
- en: '[77] Xiao-Yang Liu, Guoxuan Wang, and Daochen Zha. Fingpt: Democratizing internet-scale
    data for financial large language models. arXiv preprint arXiv:2307.10485, 2023.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[77] Xiao-Yang Liu、Guoxuan Wang 和 Daochen Zha。Fingpt: 使互联网规模数据对金融大语言模型民主化。arXiv
    预印本 arXiv:2307.10485，2023年。'
- en: '[78] Harry M Markowitz and G Peter Todd. Mean-variance analysis in portfolio
    choice and capital markets, volume 66. John Wiley & Sons, 2000.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] Harry M Markowitz 和 G Peter Todd。投资组合选择与资本市场中的均值-方差分析，第66卷。John Wiley
    & Sons，2000年。'
- en: '[79] Yu Qin and Yi Yang. What you say and how you say it matters: Predicting
    stock volatility using verbal and vocal cues. In Proceedings of the 57th Annual
    Meeting of the Association for Computational Linguistics, pages 390–401, 2019.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[79] Yu Qin 和 Yi Yang。你说什么以及你怎么说很重要：利用语言和声音线索预测股票波动性。在《第57届计算语言学协会年会论文集》上，第390–401页，2019年。'
- en: '[80] Linyi Yang, Tin Lok James Ng, Barry Smyth, and Riuhai Dong. Html: Hierarchical
    transformer-based multi-task learning for volatility prediction. In Proceedings
    of The Web Conference 2020, pages 441–451, 2020.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[80] 杨林毅, 丁乐·詹姆斯·吴, 巴里·斯密斯, 和董瑞海. Html: 基于层次的变压器多任务学习用于波动性预测. 《2020年网络会议论文集》，页面441–451，2020年。'
- en: '[81] John C Hull. Options, Futures, and Other Derivatives. Pearson Education,
    2017.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[81] 约翰·C·赫尔. 《期权、期货及其他衍生品》。皮尔森教育，2017年。'
- en: '[82] Xiao-Yang Liu, Hongyang Yang, Jiechao Gao, and Christina Dan Wang. FinRL:
    Deep reinforcement learning framework to automate trading in quantitative finance.
    ACM International Conference on AI in Finance (ICAIF), 2021.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[82] 刘晓阳, 杨鸿洋, 焦杰超, 和丹·王. FinRL: 深度强化学习框架用于量化金融中的自动交易. ACM国际金融人工智能会议（ICAIF），2021年。'
- en: '[83] Xiao-Yang Liu, Ziyi Xia, Jingyang Rui, Jiechao Gao, Hongyang Yang, Ming
    Zhu, Christina Wang, Zhaoran Wang, and Jian Guo. Finrl-meta: Market environments
    and benchmarks for data-driven financial reinforcement learning. Advances in Neural
    Information Processing Systems, 35:1835–1849, 2022.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[83] 刘晓阳, 夏子怡, 锦阳瑞, 焦杰超, 杨鸿洋, 朱铭, 王克里斯蒂娜, 王召然, 和郭剑. Finrl-meta: 面向数据驱动金融强化学习的市场环境与基准.
    《神经信息处理系统进展》，35:1835–1849，2022年。'
- en: '[84] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg
    Klimov. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347,
    2017.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[84] 约翰·舒尔曼, 菲利普·沃尔斯基, 普拉夫拉·达里瓦尔, 亚历克斯·拉德福德, 和奥列格·克里莫夫. 近端策略优化算法. arXiv预印本
    arXiv:1707.06347, 2017年。'
- en: '[85] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis
    Antonoglou, Daan Wierstra, and Martin Riedmiller. Playing atari with deep reinforcement
    learning. arXiv preprint arXiv:1312.5602, 2013.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[85] 沃洛迪米尔·米赫, 科雷·卡武克朱奥卢, 大卫·西尔弗, 亚历克斯·格雷夫斯, 伊奥尼斯·安东诺格鲁, 丹·维尔斯特拉, 和马丁·里德米勒.
    使用深度强化学习玩Atari游戏. arXiv预印本 arXiv:1312.5602, 2013年。'
- en: '[86] Jaap MJ Murre and Joeri Dros. Replication and analysis of ebbinghaus’
    forgetting curve. PloS one, 10(7):e0120644, 2015.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[86] 雅普·MJ·穆雷 和 乔里·德罗斯. 埃宾豪斯遗忘曲线的复制与分析. 《PLoS ONE》，10(7):e0120644，2015年。'
- en: '[87] Guardrails ai. [https://docs.guardrailsai.com](https://docs.guardrailsai.com).
    Open source library for interacting with Large Language Models.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[87] Guardrails ai. [https://docs.guardrailsai.com](https://docs.guardrailsai.com).
    用于与大型语言模型互动的开源库。'
- en: 7 Appendix
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 附录
- en: 7.1 Raw Data Sources
  id: totrans-245
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1 原始数据来源
- en: We assessed the performance of FinCon using multi-modal financial data from
    August 15, 2020, to August 15, 2023, sourced from reputable databases and APIs
    including Yahoo Finance (via yfinance), Alpaca News API, and Capital IQ, detailed
    explained in Table. These data, initially stored in the Raw Financial Data Warehouse
    as available observations of the financial market environment, are diverged into
    the corresponding FinCon’s Analysts’ Procedural Memory Databases based on timeliness
    through working memory’s summarization operation.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用2020年8月15日至2023年8月15日的多模态金融数据评估了FinCon的性能，这些数据来自于包括Yahoo Finance（通过yfinance）、Alpaca
    News API和Capital IQ在内的权威数据库和API，详细说明见表格。这些数据最初存储在原始金融数据仓库中，作为金融市场环境的可用观测值，通过工作记忆的总结操作，根据时效性被分流到相应的FinCon分析师程序记忆数据库中。
- en: 'Data Sources News data associated with ticker: News data is sourced from REFINITIV
    REAL-TIME NEWS mainly contains news from Reuters. Form 10-Q, Part 1 Item 2 (Management’s
    Discussion and Analysis of Financial Condition and Results of Operations): Quarterly
    reports (Form 10-Q) are required by the U.S. Securities and Exchange Commission
    (SEC). Form 10-k, Section 7 (Management’s Discussion and Analysis of Financial
    Condition and Results of Operations): Annual reports (Form 10-K) are required
    by the U.S. Securities and Exchange Commission (SEC), sourced from EDGAR, and
    downloaded via SEC API. Historical stock price: Daily open price, high price,
    close price, adjusted close price, and volume data from Yahoo Finance. Zacks Equity
    Research: Zacks Rank: The Zacks Rank is a short-term rating system that is most
    effective over the one- to three-month holding horizon. The underlying driver
    for the quantitatively-determined Zacks Rank is the same as the Zacks Recommendation
    and reflects trends in earnings estimate revisions. Zacks Analyst: Reason to Sell,
    Reason to Buy, and potential risks. Earning Conference Calls (ECC): ECC is a type
    of unstructured financial data (audio) that is crucial for understanding market
    dynamics and investor sentiment. The company executive board delivers ECC about
    recent financial outcomes, future projections, and strategic directions. Recent
    studies have underscored the importance of not only the textual content of these
    calls but also the audio feature. Analyses have revealed that the audio elements—such
    as tone, pace, and inflections—offer significant predictive value regarding company
    performance and stock movements [[79](#bib.bib79), [80](#bib.bib80)].'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 数据来源 新闻数据与股票代码关联：新闻数据来自 REFINITIV 实时新闻，主要包含路透社的新闻。Form 10-Q，第 1 部分第 2 项（管理层对财务状况和运营结果的讨论与分析）：季度报告（Form
    10-Q）由美国证券交易委员会（SEC）要求。Form 10-K，第 7 节（管理层对财务状况和运营结果的讨论与分析）：年度报告（Form 10-K）由美国证券交易委员会（SEC）要求，数据来自
    EDGAR，并通过 SEC API 下载。历史股票价格：来自 Yahoo Finance 的每日开盘价、高价、收盘价、调整后收盘价和成交量数据。Zacks
    股票研究：Zacks 排名：Zacks 排名是一个短期评级系统，在一至三个月的持有期内效果最好。量化确定的 Zacks 排名的基本驱动因素与 Zacks 推荐相同，反映了盈利预期修订的趋势。Zacks
    分析师：卖出理由、买入理由和潜在风险。盈利电话会议（ECC）：ECC 是一种非结构化金融数据（音频），对理解市场动态和投资者情绪至关重要。公司执行董事会就近期财务结果、未来预测和战略方向提供
    ECC。近期研究强调了这些电话会议的文本内容和音频特征的重要性。分析揭示了音频元素——如语调、语速和语调变化——在公司业绩和股票走势预测方面具有显著的预测价值[[79](#bib.bib79),
    [80](#bib.bib80)]。
- en: 'Table 6: Raw data and memory warehouses of FinCon'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6：FinCon 的原始数据和记忆库
- en: 7.2 Distribution of Data
  id: totrans-249
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2 数据分布
- en: '![Refer to caption](img/1d951e17316978f1069db7ec6b2542a2.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/1d951e17316978f1069db7ec6b2542a2.png)'
- en: 'Figure 9: The distribution of news from REFINITIV REAL-TIME NEWS for the 42
    stocks in the experiments'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：实验中 42 只股票的 REFINITIV 实时新闻分布
- en: '![Refer to caption](img/68c91771a83639e3b1bd77478effe6e3.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/68c91771a83639e3b1bd77478effe6e3.png)'
- en: 'Figure 10: The distribution of 10k10q from Securities and Exchange Commission
    (SEC) for the 42 stocks in the experiments'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：实验中 42 只股票的证券交易委员会（SEC）10k10q 分布
- en: '![Refer to caption](img/b3ff465ef0c4674e7ce0c04e76008b53.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/b3ff465ef0c4674e7ce0c04e76008b53.png)'
- en: 'Figure 11: The distribution of Analyst Report from Zacks Equity Research for
    the 42 stocks in the experiments'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11：实验中 42 只股票的 Zacks 股票研究分析师报告分布
- en: 7.3 Formula of Classic Financial Metrics for Risk Estimator
  id: totrans-256
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3 风险估算器经典金融指标公式
- en: 'Profit and Loss (PnL)[[81](#bib.bib81)]: PnL quantifies the net outcome of
    trading activities over a specified period by accounting for the realized gains
    and losses from financial instruments like stocks and derivatives.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 盈亏（PnL）[[81](#bib.bib81)]：PnL 通过计算股票和衍生品等金融工具的实现收益和损失，量化在特定时期内的交易活动的净结果。
- en: 'Value at Risk (VaR) of PnL[[81](#bib.bib81)]: VaR is a statistical tool used
    to estimate the potential loss in a portfolio, within a defined confidence interval.
    Mathematically, it is defined as Equation [2](#S7.E2 "In 7.3 Formula of Classic
    Financial Metrics for Risk Estimator ‣ 7 Appendix ‣ FinCon: A Synthesized LLM
    Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial
    Decision Making"):'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 盈亏（PnL）的风险值（VaR）[[81](#bib.bib81)]：VaR 是一种统计工具，用于估计在定义的置信区间内，投资组合的潜在损失。在数学上，它被定义为公式[2](#S7.E2
    "在 7.3 风险估算器经典金融指标公式 ‣ 7 附录 ‣ FinCon：一个综合的 LLM 多代理系统，通过概念性语言强化提高金融决策能力")：
- en: '|  | $\text{VaR}_{\alpha}(PnL)=\inf\left\{l\in\mathbb{R}:\mathbb{P}(PnL\leq
    l)\geq\alpha\right\}$ |  | (2) |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '|  | $\text{VaR}_{\alpha}(PnL)=\inf\left\{l\in\mathbb{R}:\mathbb{P}(PnL\leq
    l)\geq\alpha\right\}$ |  | (2) |'
- en: where $\alpha$ is the confidence level.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\alpha$ 是置信水平。
- en: 'Conditional Value at Risk (CVaR) of PnL[[81](#bib.bib81)]: CVaR is a statistical
    tool used to estimate the expected potential loss worse than the VaR value in
    a portfolio, within a defined confidence interval. Mathematically, it is defined
    as Equation [3](#S7.E3 "In 7.3 Formula of Classic Financial Metrics for Risk Estimator
    ‣ 7 Appendix ‣ FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal
    Reinforcement for Enhanced Financial Decision Making"):'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 'PnL 的条件价值风险 (CVaR) [[81](#bib.bib81)]: CVaR 是一个统计工具，用于估计在定义的置信区间内，超出 VaR 值的潜在损失的期望。数学上，它定义为方程
    [3](#S7.E3 "In 7.3 Formula of Classic Financial Metrics for Risk Estimator ‣ 7
    Appendix ‣ FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal
    Reinforcement for Enhanced Financial Decision Making")：'
- en: '|  | $\text{CVaR}_{\alpha}(PnL)=\mathbb{E}\Big{\{}PnL&#124;PnL\leq\text{VaR}_{\alpha}(PnL)\Big{\}}$
    |  | (3) |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '|  | $\text{CVaR}_{\alpha}(PnL)=\mathbb{E}\Big{\{}PnL\mid PnL\leq\text{VaR}_{\alpha}(PnL)\Big{\}}$
    |  | (3) |'
- en: where $\alpha$ is the confidence level.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\alpha$ 是置信水平。
- en: 'Cumulative Return of PnL [[73](#bib.bib73)]: Cumulative Return is a key trading
    performance metric because it provides a comprehensive insight into investment
    performance, especially for strategies that emphasize long-term growth and reinvestment.
    The effectiveness of different investment strategies is evaluated based on their
    Cumulative Returns, which reflect the total change in value over time. In this
    study, we compute Cumulative Returns over the specified period by summing daily
    logarithmic returns, as outlined in Equation [4](#S7.E4 "In 7.3 Formula of Classic
    Financial Metrics for Risk Estimator ‣ 7 Appendix ‣ FinCon: A Synthesized LLM
    Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial
    Decision Making"). This method is widely accepted in the finance area due to its
    ability to precisely capture minor price fluctuations and symmetrically address
    gains and losses. In essence, a higher Cumulative Return typically indicates a
    more effective strategy.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 'PnL 的累积收益 [[73](#bib.bib73)]: 累积收益是一个关键的交易绩效指标，因为它提供了对投资绩效的全面洞察，特别是对于那些强调长期增长和再投资的策略。不同投资策略的有效性是通过它们的累积收益来评估的，累积收益反映了随着时间的推移的总价值变化。在本研究中，我们通过将每日对数收益相加来计算指定时期的累积收益，如方程
    [4](#S7.E4 "In 7.3 Formula of Classic Financial Metrics for Risk Estimator ‣ 7
    Appendix ‣ FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal
    Reinforcement for Enhanced Financial Decision Making") 所述。这种方法在金融领域被广泛接受，因为它能够精确捕捉微小的价格波动，并对收益和损失进行对称处理。从本质上讲，较高的累积收益通常表示策略更为有效。'
- en: '|  | Cumulative Return | $\displaystyle=\sum_{t=1}^{n}r_{i}$ |  |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '|  | 累积收益 | $\displaystyle=\sum_{t=1}^{n}r_{i}$ |  |'
- en: '|  |  | $\displaystyle=\sum_{t=1}^{n}\left[\ln\left(\frac{p_{t+1}}{p_{t}}\right)\cdot\text{action}_{t}\right],$
    |  | (4) |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=\sum_{t=1}^{n}\left[\ln\left(\frac{p_{t+1}}{p_{t}}\right)\cdot\text{action}_{t}\right],$
    |  | (4) |'
- en: where $r_{i}$ denotes the trading decision made by the model for that day.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $r_{i}$ 表示模型在那一天做出的交易决策。
- en: 'Sharpe Ratio of PnL [[74](#bib.bib74)]: Sharpe Ratio is another core metric
    for evaluating investment performance and adjusting returns for risk. It is calculated
    by dividing the portfolio’s average PnL ($R_{p}$), as shown in Equation [5](#S7.E5
    "In 7.3 Formula of Classic Financial Metrics for Risk Estimator ‣ 7 Appendix ‣
    FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement
    for Enhanced Financial Decision Making"). This metric adjusts returns for risk,
    with a higher ratio indicating better risk-adjusted performance. Essential in
    comparing different portfolios or strategies, it contextualizes performance against
    similar investments. Although a Sharpe Ratio above 1 is typically considered favorable
    and above 2 as excellent, these benchmarks can vary depending on the context of
    comparison.'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 'PnL 的夏普比率 [[74](#bib.bib74)]: 夏普比率是另一个评估投资绩效并调整风险回报的核心指标。它通过将投资组合的平均 PnL ($R_{p}$)
    除以投资组合的标准差 $\sigma_{p}$ 来计算，如方程 [5](#S7.E5 "In 7.3 Formula of Classic Financial
    Metrics for Risk Estimator ‣ 7 Appendix ‣ FinCon: A Synthesized LLM Multi-Agent
    System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making")
    所示。这个指标调整了风险的回报，较高的比率表示更好的风险调整绩效。它在比较不同投资组合或策略时至关重要，因为它将绩效置于类似投资的背景中。虽然通常认为夏普比率高于1为有利，高于2为优秀，但这些基准可能会根据比较的背景而有所不同。'
- en: '|  | $\textbf{Sharpe Ratio}=\frac{R_{p}-R_{f}}{\sigma_{p}}$ |  | (5) |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '|  | $\textbf{Sharpe Ratio}=\frac{R_{p}-R_{f}}{\sigma_{p}}$ |  | (5) |'
- en: 'Max Drawdown of PnL [[75](#bib.bib75)]: Max Drawdown is a metric for assessing
    risk. It represents the most significant decrease in a portfolio’s value, from
    its highest ($P_{\text{peak}}$) until a new peak emerges, detailed in Equation [6](#S7.E6
    "In 7.3 Formula of Classic Financial Metrics for Risk Estimator ‣ 7 Appendix ‣
    FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement
    for Enhanced Financial Decision Making"). Indicative of investment strategy robustness,
    a smaller Max Drawdown suggests reduced risk.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '最大回撤（Max Drawdown）[[75](#bib.bib75)]: 最大回撤是评估风险的指标。它表示从组合价值的最高点（$P_{\text{peak}}$）到新的高点出现之间的最大下降，详细见方程[6](#S7.E6
    "In 7.3 Formula of Classic Financial Metrics for Risk Estimator ‣ 7 Appendix ‣
    FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement
    for Enhanced Financial Decision Making")。作为投资策略稳健性的指标，较小的最大回撤表明风险较低。'
- en: '|  | $\displaystyle\textbf{Max Drawdown}=\text{max}(\frac{P_{\text{peak}}-P_{\text{trough}}}{P_{\text{peak}}})$
    |  | (6) |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\textbf{最大回撤}=\text{max}(\frac{P_{\text{peak}}-P_{\text{trough}}}{P_{\text{peak}}})$
    |  | (6) |'
- en: 7.4 Baseline and Comparative Models on Single Stock Trading Task
  id: totrans-272
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4 单股票交易任务的基线和比较模型
- en: 'Buy-and-Hold strategy (B&H):'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 买入并持有策略（B&H）：
- en: A passive investment approach, where an investor purchases stocks and holds
    onto them for an extended period regardless of market fluctuations, is commonly
    used as a baseline for comparison of stock trading strategies.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 被动投资方法，即投资者购买股票并长时间持有，不论市场波动如何，通常作为股票交易策略比较的基线。
- en: 'DRL trading agents:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: DRL交易代理：
- en: As the FinMem is practiced and examined on the basis of single stock trading
    and discrete trading actions, we choose three advanced DRL algorithms fitting
    into the same scenarios according to the previous and shown expressive performance
    in the work of Liu et al [[82](#bib.bib82), [83](#bib.bib83)]. The DRL training
    agents only take numeric features as inputs.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 由于FinMem在单股票交易和离散交易行为的基础上进行实践和检查，我们选择了三种适合相同场景的先进DRL算法，根据Liu等人的研究[[82](#bib.bib82),
    [83](#bib.bib83)]显示出的优异性能。DRL训练代理仅接受数值特征作为输入。
- en: •
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Proximal Policy Optimization (PPO): PPO ([[84](#bib.bib84)]) is employed in
    stock trading due to its stability and efficiency. One salient advantage of PPO
    is that it maintains a balance between exploration and exploitation by bounding
    the policy update, preventing drastic policy changes.'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'Proximal Policy Optimization (PPO): PPO ([[84](#bib.bib84)]) 被用于股票交易，因为它的稳定性和效率。PPO的一个显著优势是通过限制策略更新，维持探索与利用之间的平衡，防止策略发生剧烈变化。'
- en: •
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Deep Q-Network (DQN): DQN ([[85](#bib.bib85)]) is an adaptation of Q-learning,
    that can be used to optimize investment strategies. Unlike traditional Q-learning
    that relies on a tabular approach for storing Q-values, DQN generalizes Q-value
    estimation across states using deep learning, making it more scalable for complex
    trading environments.'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'Deep Q-Network (DQN): DQN ([[85](#bib.bib85)]) 是Q-learning的一个改进版本，可用于优化投资策略。与传统的依赖于表格方法存储Q值的Q-learning不同，DQN使用深度学习对状态进行Q值估计，使其在复杂交易环境中更具可扩展性。'
- en: 'LLM trading agents:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: LLM交易代理：
- en: We evaluate FinCon against four LLM agents in the context of stock trading.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在股票交易的背景下对四种LLM代理进行了FinCon的评估。
- en: •
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: General-purpose Generative Agents – GA:The generative AI agent by Park et al.
    [[11](#bib.bib11)], originally intended to simulate realistic human behavior and
    make everyday decisions, has been adapted here for specific stock trading tasks.
    This agent’s architecture includes a memory module that employs recency, relevance,
    and importance metrics to extract pivotal memory events for informed decision-making.
    However, it does not provide a layered memory module to effectively differentiate
    the time sensitivities unique to various types of financial data. Additionally,
    although it features a profiling module to define agent attributes like professional
    background, the model does not specify the agent’s persona. In our experiments,
    we modified the original prompt template created by Park et al., which was intended
    for general daily tasks, to suit financial investment tasks.
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '通用生成代理 – GA: 由Park等人[[11](#bib.bib11)]开发的生成AI代理，最初旨在模拟真实的人类行为和日常决策，现已调整用于特定股票交易任务。该代理的架构包括一个内存模块，利用时效性、相关性和重要性指标来提取关键记忆事件，以便做出明智的决策。然而，它没有提供分层内存模块来有效区分各种金融数据的时间敏感性。此外，尽管它具有定义代理属性（如职业背景）的配置文件模块，但模型没有指定代理的个人特征。在我们的实验中，我们修改了Park等人创建的原始提示模板，以适应金融投资任务。'
- en: •
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'FinGPT: A novel open-source LLM framework specialized for converting incoming
    textual and numeric information into informed financial decision-making, introduced
    by Yang et al[[22](#bib.bib22)]. It claims superiority over the traditional buy-and-hold
    strategy.'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: FinGPT：一个新颖的开源LLM框架，专门用于将传入的文本和数值信息转换为明智的金融决策，由Yang等人介绍[[22](#bib.bib22)]。它声称优于传统的买入并持有策略。
- en: •
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: FinMem:FinMem employs a specialized profiling module and self-adaptive risk
    settings for enhanced market robustness. Its memory module integrates working
    memory and layered long-term memory, enabling effective data processing. This
    allows FinMem to leverage market insights and improve trading decisions [[23](#bib.bib23)].
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: FinMem：FinMem采用了专业的分析模块和自适应风险设置，以增强市场的稳健性。其内存模块集成了工作记忆和分层长期记忆，实现了有效的数据处理。这使得FinMem能够利用市场洞察力，改善交易决策[[23](#bib.bib23)]。
- en: •
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: FinAgent:FinAgent developed upon FinMem, which leverages the use of tool-using
    capabilities of LLMs to incorporate multi-modal financial data [[24](#bib.bib24)].
    It claims an further improved trading performance on single asset trading (stocks
    and cryptocurrencies).
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: FinAgent：FinAgent在FinMem基础上开发，利用LLM的工具使用能力来整合多模态金融数据[[24](#bib.bib24)]。它声称在单一资产交易（股票和加密货币）上进一步提升了交易性能。
- en: 7.5 Portfolio Management
  id: totrans-291
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.5 投资组合管理
- en: 'Markowitz Portfolio Selection: introduced by Harry Markowitz in 1952 [[1](#bib.bib1)],
    is a framework for constructing portfolios that optimize expected return for a
    given level of risk or minimize risk for a given level of expected return. This
    method uses expected returns, variances, and covariances of asset returns to determine
    the optimal asset allocation, thereby balancing risk and return through diversification.'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 马科维茨投资组合选择：由哈里·马科维茨于1952年提出[[1](#bib.bib1)]，是一种构建投资组合的框架，旨在优化给定风险水平下的预期回报，或在给定预期回报水平下最小化风险。这种方法使用资产回报的预期回报、方差和协方差来确定最佳资产配置，从而通过多样化实现风险与回报的平衡。
- en: 'FinRL-A2C: is an RL algorithm proposed to address single stock trading and
    portfolio optimization problems in [[76](#bib.bib76)]. The RL models makes trading
    decisions (i.e., portfolio weights) based on the observation of previous market
    conditions and the brokerage information of the RL-agent. The implementation of
    this algorithm ¹¹1[https://github.com/AI4Finance-Foundation/FinRL-Meta](https://github.com/AI4Finance-Foundation/FinRL-Meta)
    is provided and is used as baselines in our study.'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: FinRL-A2C：是一种RL算法，提出用于解决单一股票交易和投资组合优化问题[[76](#bib.bib76)]。RL模型基于对先前市场条件和RL代理的经纪信息的观察，做出交易决策（即投资组合权重）。该算法的实现¹¹1[https://github.com/AI4Finance-Foundation/FinRL-Meta](https://github.com/AI4Finance-Foundation/FinRL-Meta)已提供，并作为我们研究中的基线。
- en: 7.6 Ranking Metrics for Procedural Memory in FinCon
  id: totrans-294
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.6 FinCon中的程序性记忆排名指标
- en: Upon receiving an investment inquiry, each agent in FinCon retrieves the top-$K$
    is defined by
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 收到投资询问后，FinCon中的每个代理会检索前$K$定义的内容
- en: '|  | $\gamma^{E}=S_{\text{Relevancy}}^{E}+S_{\text{Importance}}^{E}$ |  | (7)
    |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '|  | $\gamma^{E}=S_{\text{Relevancy}}^{E}+S_{\text{Importance}}^{E}$ |  | (7)
    |'
- en: 'which is adpated from Park et al [[11](#bib.bib11)] but with modified relevancy
    and importance computations, and is scaled to $[0,1]$, which is defined as follows:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 该指标改编自Park等人[[11](#bib.bib11)]，但对相关性和重要性计算进行了修改，并且缩放至$[0,1]$，定义如下：
- en: '|  | $S_{\text{Relevancy}}^{E}=\frac{\mathbf{m_{E}}\cdot\mathbf{m_{P}}}{\&#124;\mathbf{m_{E}}\&#124;_{2}\times\&#124;\mathbf{m_{P}}\&#124;_{2}}$
    |  | (8) |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '|  | $S_{\text{Relevancy}}^{E}=\frac{\mathbf{m_{E}}\cdot\mathbf{m_{P}}}{\&#124;\mathbf{m_{E}}\&#124;_{2}\times\&#124;\mathbf{m_{P}}\&#124;_{2}}$
    |  | (8) |'
- en: Note that the LLM prompt query inputs trading inquiry and trader characteristics.
    On the other hand, the importance score $S_{\text{Importance}}^{E}$, then the
    importance score is computed via
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 注意LLM提示查询输入交易询问和交易者特征。另一方面，重要性得分$S_{\text{Importance}}^{E}$，然后通过以下公式计算重要性得分
- en: '|  | $S_{\text{Importance}}^{E}=v^{E}\times\theta^{\delta t}$ |  | (9) |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '|  | $S_{\text{Importance}}^{E}=v^{E}\times\theta^{\delta t}$ |  | (9) |'
- en: Note that the ratio $\theta$.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 注意比例$\theta$。
- en: Additionally, an access counter function facilitates memory event augmentation,
    so that critical events impacting trading decisions can be augmented by FinCon,
    while trivial events are gradually faded. This is achieved by using the LLM validation
    tool Guardrails AI [[87](#bib.bib87)] to track critical memory ID. A memory ID
    deemed critical to investment gains receives $+5$. This access counter implementation
    enables FinCon to capture and prioritize crucial events based on type and retrieval
    frequency.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，访问计数器功能有助于记忆事件的增强，使得影响交易决策的关键事件可以被 FinCon 增强，而琐碎事件则逐渐消退。这通过使用 LLM 验证工具 Guardrails
    AI [[87](#bib.bib87)] 来跟踪关键记忆 ID 实现。被认为对投资收益关键的记忆 ID 获得 $+5$。此访问计数器实现使 FinCon
    能够根据类型和检索频率捕捉和优先考虑关键事件。
- en: 7.7 Detailed Configurations in Experiments
  id: totrans-303
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.7 实验中的详细配置
- en: The training period was chosen to account for the seasonal nature of corporate
    financial reporting and the duration of data retention in FinCon’s memory module.
    The selected training duration ensures the inclusion of at least one publication
    cycle of either Form 10-Q, ECC, or Form 10-K. This strategy ensures that the learned
    conceptualized investment guidance considers a more comprehensive scope of factors.
    Additionally, the training duration allowed FinCon sufficient time to establish
    inferential links between financial news, market indicators, and stock market
    trends, thereby accumulating substantial experience. Furthermore, we set the number
    of top memory events retrieved for each agent at 5\. We ran FinCon. The reported
    performance outcomes are based on the setting that achieved the highest cumulative
    return during the testing phase.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 训练期间的选择考虑了公司财务报告的季节性特点以及 FinCon 内存模块中的数据保留时间。所选的训练时长确保至少包含一个 Form 10-Q、ECC 或
    Form 10-K 的发布周期。这一策略确保了学习到的概念化投资指导考虑了更全面的因素。此外，训练时长使 FinCon 有足够的时间在财务新闻、市场指标和股市趋势之间建立推断联系，从而积累了大量经验。此外，我们将每个代理检索的顶级记忆事件数量设置为
    5。我们运行了 FinCon。报告的性能结果基于测试阶段取得的最高累计收益率的设置。
- en: To maintain consistency in the comparison, the training and testing phases for
    the other two LLM-based agents were aligned with those of FinMem. For parameters
    of other LLM-based agents that are not encompassed by FinMem’s configuration,
    they were kept in accordance with their original settings as specified in their
    respective source codes.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 为保持比较的一致性，其它两个基于 LLM 的代理的训练和测试阶段与 FinMem 对齐。对于 FinMem 配置中未涵盖的其它 LLM 基于代理的参数，它们保持在各自源代码中指定的原始设置。
- en: FinCon’s performance was benchmarked against that of the most effective comparative
    model, using Cumulative Return and Sharpe Ratio as the primary evaluation metrics.
    The statistical significance of FinCon’s superior performance was ascertained
    through the non-parametric Wilcoxon signed-rank test, which is particularly apt
    for the non-Gaussian distributed data.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: FinCon 的表现与最有效的比较模型进行了基准比较，使用累计收益率和夏普比率作为主要评估指标。通过非参数的 Wilcoxon 符号秩检验确定了 FinCon
    优越表现的统计显著性，这种检验特别适用于非高斯分布的数据。
