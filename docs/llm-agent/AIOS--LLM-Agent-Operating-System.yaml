- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:49:14'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:49:14
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'AIOS: LLM Agent Operating System'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AIOS：基于大语言模型的智能代理操作系统
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2403.16971](https://ar5iv.labs.arxiv.org/html/2403.16971)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2403.16971](https://ar5iv.labs.arxiv.org/html/2403.16971)
- en: Kai Mei
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 梅凯
- en: Rutgers University
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 罗格斯大学
- en: Zelong Li
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 李泽龙
- en: Rutgers University
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 罗格斯大学
- en: Shuyuan Xu
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 徐淑媛
- en: Rutgers University
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 罗格斯大学
- en: Ruosong Ye
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 叶若松
- en: Rutgers University
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 罗格斯大学
- en: Yingqiang Ge
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 葛英强
- en: Rutgers University
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 罗格斯大学
- en: Yongfeng Zhang
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 张永锋
- en: 'Rutgers University ^∗Author Affiliations: Department of Computer Science, Rutgers
    University, New Brunswick, NJ 08854; Author Emails: kai.mei, zelong.li, shuyuan.xu,
    ruosong.ye, yingqiang.ge, yongfeng.zhang@rutgers.edu'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 罗格斯大学 ^∗作者隶属：计算机科学系，罗格斯大学，新布伦瑞克，NJ 08854；作者邮箱：kai.mei, zelong.li, shuyuan.xu,
    ruosong.ye, yingqiang.ge, yongfeng.zhang@rutgers.edu
- en: Abstract
  id: totrans-18
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: The integration and deployment of large language model (LLM)-based intelligent
    agents have been fraught with challenges that compromise their efficiency and
    efficacy. Among these issues are sub-optimal scheduling and resource allocation
    of agent requests over the LLM, the difficulties in maintaining context during
    interactions between agent and LLM, and the complexities inherent in integrating
    heterogeneous agents with different capabilities and specializations. The rapid
    increase of agent quantity and complexity further exacerbates these issues, often
    leading to bottlenecks and sub-optimal utilization of resources. Inspired by these
    challenges, this paper presents AIOS, an LLM agent operating system, which embeds
    large language model into operating systems (OS) as the brain of the OS, enabling
    an operating system “with soul”—an important step towards AGI. Specifically, AIOS
    is designed to optimize resource allocation, facilitate context switch across
    agents, enable concurrent execution of agents, provide tool service for agents,
    and maintain access control for agents. We present the architecture of such an
    operating system, outline the core challenges it aims to resolve, and provide
    the basic design and implementation of the AIOS. Our experiments on concurrent
    execution of multiple agents demonstrate the reliability and efficiency of our
    AIOS modules. Through this, we aim to not only improve the performance and efficiency
    of LLM agents but also to pioneer for better development and deployment of the
    AIOS ecosystem in the future. The project is open-source at [https://github.com/agiresearch/AIOS](https://github.com/agiresearch/AIOS).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 基于大语言模型（LLM）的智能代理的集成和部署面临诸多挑战，这些挑战影响了它们的效率和有效性。这些问题包括对LLM代理请求的次优调度和资源分配、在代理和LLM之间交互过程中保持上下文的困难，以及集成具有不同能力和专业化的异质代理的复杂性。代理数量和复杂性的快速增加进一步加剧了这些问题，通常导致瓶颈和资源利用不佳。受到这些挑战的启发，本文提出了AIOS，一个将大语言模型嵌入操作系统（OS）作为OS“大脑”的LLM代理操作系统，赋予操作系统“灵魂”——这是向通用人工智能（AGI）迈出的重要一步。具体而言，AIOS旨在优化资源分配、促进代理之间的上下文切换、实现代理的并发执行、为代理提供工具服务，并维护代理的访问控制。我们展示了这种操作系统的架构，概述了它旨在解决的核心挑战，并提供了AIOS的基本设计和实现。我们在多个代理的并发执行实验中展示了AIOS模块的可靠性和效率。通过这一点，我们旨在不仅提高LLM代理的性能和效率，还为未来AIOS生态系统的更好发展和部署开创先河。该项目在[https://github.com/agiresearch/AIOS](https://github.com/agiresearch/AIOS)上开源。
- en: 1 Introduction
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: In the field of autonomous agents, research endeavors [[1](#bib.bib1), [2](#bib.bib2),
    [3](#bib.bib3)] are directed towards systems that can operate independently, make
    decisions, and perform tasks with no or minimal human intervention. These agents
    are designed to understand instructions, process information, make decisions and
    take action to achieve a state of autonomy. The advent of large language models
    (LLMs) [[4](#bib.bib4), [5](#bib.bib5), [6](#bib.bib6)] has brought new possibilities
    to the agent development [[7](#bib.bib7)]. Current LLMs have shown great power
    in understanding instructions [[8](#bib.bib8), [9](#bib.bib9), [10](#bib.bib10),
    [11](#bib.bib11)], reasoning and solving problems [[12](#bib.bib12), [13](#bib.bib13),
    [14](#bib.bib14), [15](#bib.bib15), [16](#bib.bib16)], and interacting with human
    users [[17](#bib.bib17)] as well as external environments [[18](#bib.bib18), [19](#bib.bib19)].
    Built upon these powerful LLMs, emergent LLM-based agents [[7](#bib.bib7), [20](#bib.bib20),
    [21](#bib.bib21), [22](#bib.bib22)] can present strong task fulfillment abilities
    in diverse environments, ranging from virtual assistants to more sophisticated
    systems involving complex and creative problem solving, planning and reasoning.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在自主智能体领域，研究工作[[1](#bib.bib1), [2](#bib.bib2), [3](#bib.bib3)]致力于开发可以独立操作、做出决策并执行任务的系统，这些系统不需要或只需最少的人类干预。这些智能体被设计成能够理解指令、处理信息、做出决策并采取行动以实现自主状态。大型语言模型（LLMs）的出现[[4](#bib.bib4),
    [5](#bib.bib5), [6](#bib.bib6)]为智能体的发展带来了新的可能性[[7](#bib.bib7)]。当前的LLMs在理解指令[[8](#bib.bib8),
    [9](#bib.bib9), [10](#bib.bib10), [11](#bib.bib11)]、推理和解决问题[[12](#bib.bib12),
    [13](#bib.bib13), [14](#bib.bib14), [15](#bib.bib15), [16](#bib.bib16)]以及与人类用户[[17](#bib.bib17)]和外部环境[[18](#bib.bib18),
    [19](#bib.bib19)]互动方面展现了强大的能力。基于这些强大的LLMs，涌现出的LLM智能体[[7](#bib.bib7), [20](#bib.bib20),
    [21](#bib.bib21), [22](#bib.bib22)]在各种环境中展现了强大的任务完成能力，从虚拟助手到涉及复杂和创造性问题解决、规划和推理的更复杂系统。
- en: 'One compelling example of how an LLM-based agent solves real-world tasks can
    be seen from [Figure 1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ AIOS: LLM Agent Operating
    System"). Given the trip organization request from the user, the travel agent
    decomposes the task into executable steps. Then, it follows the steps sequentially
    to book flights, reserve hotels, process payments, and update calendars based
    on the user’s preferences. During the plan execution, agents show the reasoning
    and decision-making abilities, which sets it apart from the traditional software
    applications that are constrained to a pre-defined set of functions or workflow.
    To realize this travel scenario, the agent needs to interact with both LLM services
    (e.g, retrieving and understanding user preferences, deciding which tool API to
    call, generating reviews and responses) and traditional operating system (OS)
    services (e.g., accessing disk driver and executing software).'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '一个引人注目的例子是基于LLM的智能体如何解决现实世界任务，这可以从[图1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣
    AIOS: LLM Agent Operating System")中看到。根据用户的旅行组织请求，旅行代理将任务分解成可执行的步骤。然后，它按照这些步骤顺序进行，包括预订航班、预订酒店、处理支付和根据用户的偏好更新日历。在计划执行过程中，智能体展示了推理和决策能力，这使其区别于受限于预定义功能或工作流程的传统软件应用。要实现这一旅行场景，智能体需要与LLM服务（例如，检索和理解用户偏好、决定调用哪个工具API、生成评论和响应）和传统操作系统（OS）服务（例如，访问磁盘驱动程序和执行软件）进行交互。'
- en: '![Refer to caption](img/004ae1e187f5d160d7851080b3d1f342.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/004ae1e187f5d160d7851080b3d1f342.png)'
- en: 'Figure 1: A motivating example of how an agent (i.e., Travel Agent) requires
    both LLM level and OS level resources and functions to complete a task.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：一个激励性例子，展示了一个智能体（即旅行代理）如何需要LLM级别和OS级别的资源和功能来完成任务。
- en: Accompanied by the exponential growth in the agent quantity and complexity,
    there is an increasing strain on the functionalities of LLM and OS. For example,
    scheduling and prioritizing agent requests in limited LLM resources poses a significant
    challenge. Moreover, the LLM’s generation process can become time-intensive when
    dealing with lengthy contexts, occasionally resulting in the generation being
    suspended by the scheduler. This raises the problem of devising a mechanism to
    snapshot the LLM’s current generation result, thereby enabling pause/resume behavior
    even when the LLM has not finalized the response generation for the current request.
    Furthermore, once an agent has obtained the list of available calling tools, determining
    the optimal sequence for invoking these tools presents yet another challenge since
    multiple agents may need to call the same tool. Additionally, the concurrent operation
    of multiple agents necessitates a robust system for memory management across different
    agents, while also ensuring stringent enforcement of privacy and access control
    measures.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 随着代理数量和复杂性的指数增长，对LLM和操作系统功能的压力也在增加。例如，在有限的LLM资源下调度和优先排序代理请求是一项重大挑战。此外，当处理较长的上下文时，LLM的生成过程可能会变得耗时，偶尔导致生成被调度器挂起。这就提出了制定机制快照LLM当前生成结果的问题，从而在LLM尚未完成当前请求的响应生成时实现暂停/恢复行为。此外，一旦代理获得了可用调用工具的列表，确定调用这些工具的最佳顺序也是一个挑战，因为多个代理可能需要调用相同的工具。此外，多个代理的并发操作需要一个强大的系统来进行不同代理之间的内存管理，同时还要确保严格执行隐私和访问控制措施。
- en: 'To address the above mentioned challenges, we propose AIOS, an LLM agent operating
    system ([Figure 2](#S2.F2 "Figure 2 ‣ LLM-based Multi-Agent Systems. ‣ 2.2 Large
    Language Model Agents ‣ 2 Related Work ‣ AIOS: LLM Agent Operating System")) to
    provide module isolation and aggregations of LLM and OS functionalities. To address
    the potential conflicts arising between tasks associated with LLM and those unrelated
    to LLM, we propose the design of an LLM-specific kernel. This kernel segregates
    the OS-like duties, particularly those related to the oversight of LLM agents,
    their corresponding resources, and development tool-kits. Through this segregation,
    the LLM kernel aims to enhance the management and coordination of LLM-related
    activities. Within the proposed LLM kernel, we have devised a suite of modules,
    each dedicated to addressing the distinct functions pertinent to LLM operations.
    An overview of these modules and their respective functionalities is presented
    in the following, with the comprehensive discussion of their underlying mechanisms
    detailed in Section [4](#S4 "4 AIOS Implementation ‣ AIOS: LLM Agent Operating
    System").'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '为了应对上述挑战，我们提出了AIOS，一个LLM代理操作系统（[图 2](#S2.F2 "Figure 2 ‣ LLM-based Multi-Agent
    Systems. ‣ 2.2 Large Language Model Agents ‣ 2 Related Work ‣ AIOS: LLM Agent
    Operating System")），以提供模块隔离和LLM与操作系统功能的整合。为了应对LLM相关任务和与LLM无关任务之间可能出现的冲突，我们提出了设计一个专门的LLM内核。这个内核将操作系统类似的职责，特别是与LLM代理、其相应资源和开发工具包的监督相关的职责进行隔离。通过这种隔离，LLM内核旨在提升LLM相关活动的管理和协调。在提议的LLM内核中，我们设计了一套模块，每个模块都专注于解决与LLM操作相关的不同功能。以下将介绍这些模块及其各自的功能，详细的机制讨论将在第[4](#S4
    "4 AIOS Implementation ‣ AIOS: LLM Agent Operating System")节中进行。'
- en: •
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Agent Scheduler: Prioritizes and schedules agent requests to optimize LLM utilization.'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 代理调度器：优先排序和调度代理请求，以优化LLM的使用。
- en: •
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Context Manager: Supports snapshot and restore the intermediate generation
    status in LLM and context window management of LLM.'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上下文管理器：支持快照和恢复LLM中的中间生成状态以及LLM的上下文窗口管理。
- en: •
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Memory Manager: Provides short-term memory for each agent’s interaction logs.'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 内存管理器：为每个代理的交互日志提供短期内存。
- en: •
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Storage Manager: Persists agent interaction logs to long-term storage for future
    retrieval.'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 存储管理器：将代理交互日志持久化到长期存储中，以便将来检索。
- en: •
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Tool Manager: Manages agent’s calling of external API tools (e.g., search,
    scientific computing).'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 工具管理器：管理代理对外部API工具（如搜索、科学计算）的调用。
- en: •
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Access Manager: Enforces privacy and access control policies between agents.'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 访问管理器：执行代理之间的隐私和访问控制策略。
- en: Aside from the modules, the kernel exposes an LLM system call interface through
    which agents can transparently leverage these services. Moreover, we design the
    AIOS SDK to further encapsulate the LLM system calls, providing more convenient
    agent library functions for agent developers. With the AIOS architecture, an agent
    like the travel planner can break down its task into steps that fluidly combine
    LLM reasoning (e.g., plan generation and tool calling decision) and OS-level actions
    (e.g., accessing storage and executing software services). This synergistic combination
    of capabilities equips multiple LLM agents to tackle increasingly complex, multi-modal
    tasks that require reasoning, execution, and interaction with the physical world.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 除了模块之外，内核还提供了LLM系统调用接口，代理可以通过该接口透明地利用这些服务。此外，我们设计了AIOS SDK以进一步封装LLM系统调用，为代理开发者提供更便捷的代理库函数。借助AIOS架构，像旅行规划器这样的代理可以将任务分解为流畅结合LLM推理（例如，计划生成和工具调用决策）与操作系统级操作（例如，访问存储和执行软件服务）的步骤。这种能力的协同组合使多个LLM代理能够处理越来越复杂的多模态任务，这些任务需要推理、执行以及与物理世界的互动。
- en: Looking ahead, we envision extending the AIOS to support even tighter agent-world
    integration (e.g., through robotic control), more intelligent resource management,
    and safer multi-agent collaboration. Ultimately, AIOS serves as the crucial platform
    to facilitate the development, deployment and usage of various complex LLM agents.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 展望未来，我们设想将AIOS扩展以支持更紧密的代理-世界集成（例如，通过机器人控制）、更智能的资源管理以及更安全的多代理协作。**最终**，AIOS作为促进各种复杂LLM代理开发、部署和使用的关键平台。
- en: 2 Related Work
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: 2.1 Evolution of Operating Systems
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 操作系统的演变
- en: The evolution of operating systems (OS) has unfolded in a progressive way, evolving
    from rudimentary systems to the complex and interactive OS of today. Initially,
    operating systems served to bridge the gap between the user-level tasks and the
    binary functionality of computer hardware, such as electron and gate manipulation.
    Their evolution saw a transition from simple batch job processing [[23](#bib.bib23)]
    to more advanced process management techniques like time-sharing [[24](#bib.bib24)]
    and multi-task processing [[25](#bib.bib25), [26](#bib.bib26)], which facilitated
    the handling of increasingly complex tasks. The progress moved toward modularization
    within the OS, delineating specific responsibilities such as process scheduling [[27](#bib.bib27),
    [28](#bib.bib28)], memory management [[29](#bib.bib29), [30](#bib.bib30)], and
    filesystem management [[31](#bib.bib31), [32](#bib.bib32)], enhancing efficiency
    and manageability. The further advent of graphical user interfaces (GUIs), e.g.,
    Macintosh¹¹1[http://apple-history.com/128k](http://apple-history.com/128k), Windows²²2[https://winworldpc.com/product/windows-3/31](https://winworldpc.com/product/windows-3/31)
    and GNOME³³3[https://www.gnome.org/](https://www.gnome.org/), makes operating
    systems more interactive and user-centric. Meanwhile, the operating system ecosystem
    has also expanded, offering a comprehensive suite of developer tools (OS SDKs)
    and runtime libraries. These tools enable application developers to design, implement,
    and run their applications efficiently within the OS environment [[33](#bib.bib33)].
    Notable examples of OS ecosystems include Android Studio⁴⁴4[https://developer.android.com/studio](https://developer.android.com/studio),
    XCode⁵⁵5[https://developer.apple.com/xcode/](https://developer.apple.com/xcode/)
    and Cloud SDK⁶⁶6[https://cloud.google.com/sdk](https://cloud.google.com/sdk).
    In these ecosystems, the OS provides numerous resources to facilitate software
    development and serves as a platform for deploying and hosting software applications,
    leading to a thriving OS-application ecosystem. Nowadays, we stand at the transformative
    phase to see the potential of intelligent operating systems. With the incorporation
    of large language models (LLMs), These advanced systems promise to further narrow
    the communication gap between humans and machines, forwarding a new era of user-computer
    interaction.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统（OS）的演变经历了一个渐进的过程，从原始系统发展到今天复杂且互动的操作系统。最初，操作系统用于弥合用户级任务与计算机硬件的二进制功能之间的差距，如电子和门控操作。它们的演变经历了从简单的批处理作业处理
    [[23](#bib.bib23)] 到更先进的进程管理技术，如时间共享 [[24](#bib.bib24)] 和多任务处理 [[25](#bib.bib25),
    [26](#bib.bib26)]，这些技术促成了越来越复杂任务的处理。进步趋向于操作系统内的模块化，明确了诸如进程调度 [[27](#bib.bib27),
    [28](#bib.bib28)]、内存管理 [[29](#bib.bib29), [30](#bib.bib30)] 和文件系统管理 [[31](#bib.bib31),
    [32](#bib.bib32)] 等特定职责，从而提高了效率和可管理性。图形用户界面（GUI）的进一步发展，例如 Macintosh¹¹1[http://apple-history.com/128k](http://apple-history.com/128k)、Windows²²2[https://winworldpc.com/product/windows-3/31](https://winworldpc.com/product/windows-3/31)
    和 GNOME³³3[https://www.gnome.org/](https://www.gnome.org/)，使操作系统变得更加互动和以用户为中心。同时，操作系统生态系统也得到了扩展，提供了一整套开发者工具（OS
    SDK）和运行时库。这些工具使应用程序开发者能够在操作系统环境中高效地设计、实现和运行应用程序 [[33](#bib.bib33)]。操作系统生态系统的著名例子包括
    Android Studio⁴⁴4[https://developer.android.com/studio](https://developer.android.com/studio)、XCode⁵⁵5[https://developer.apple.com/xcode/](https://developer.apple.com/xcode/)
    和 Cloud SDK⁶⁶6[https://cloud.google.com/sdk](https://cloud.google.com/sdk)。在这些生态系统中，操作系统提供了大量资源来促进软件开发，并作为软件应用程序的部署和托管平台，从而促成了蓬勃发展的操作系统-应用程序生态系统。如今，我们正处于智能操作系统的变革阶段，看到其潜力。通过大语言模型（LLMs）的融合，这些先进系统有望进一步缩小人类与机器之间的沟通差距，开启用户与计算机互动的新纪元。
- en: 2.2 Large Language Model Agents
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 大语言模型智能体
- en: Large language model (LLM) based autonomous agents take natural language instructions
    as input for complex task solving. The research on LLM-based agents can be generally
    classified into single-agent systems and multi-agent systems [[33](#bib.bib33)].
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 基于大语言模型（LLM）的自主智能体以自然语言指令作为输入来解决复杂任务。对LLM基础智能体的研究通常可以分为单智能体系统和多智能体系统 [[33](#bib.bib33)]。
- en: LLM-based Single-Agent Systems.
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基于LLM的单智能体系统。
- en: LLM-based single-agent systems (SAS) use a single LLM agent for complex task
    solving, such as travel planning, personalized recommendation, and artistic design
    [[7](#bib.bib7)]. The agent takes natural language instruction from users as input
    and decomposes the task into a multistep plan for task solving, where each step
    may call external tools to be completed, such as collecting information, executing
    specialized models, or interacting with the external world. Single-agent applications
    may engage with either digital environment or physical environment or both, depending
    on the task to solve. For example, agents in virtual or digital environment may
    invoke APIs [[7](#bib.bib7), [34](#bib.bib34), [35](#bib.bib35), [36](#bib.bib36),
    [37](#bib.bib37)], browse websites [[38](#bib.bib38), [22](#bib.bib22)], or execute
    codes [[39](#bib.bib39)], while agents in the physical environment may manipulate
    objects [[19](#bib.bib19), [40](#bib.bib40), [41](#bib.bib41)], carry out lab
    experiments [[42](#bib.bib42), [43](#bib.bib43)], or make actionable decisions
    [[44](#bib.bib44), [45](#bib.bib45)].
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLM的单智能体系统（SAS）使用单一的LLM智能体来解决复杂任务，如旅行规划、个性化推荐和艺术设计[[7](#bib.bib7)]。该智能体从用户那里接受自然语言指令作为输入，并将任务分解为多步骤计划来解决任务，其中每一步可能需要调用外部工具完成，如收集信息、执行专业模型或与外部世界互动。单智能体应用可以涉及数字环境或物理环境，或者两者兼顾，具体取决于要解决的任务。例如，虚拟或数字环境中的智能体可以调用API[[7](#bib.bib7),
    [34](#bib.bib34), [35](#bib.bib35), [36](#bib.bib36), [37](#bib.bib37)]、浏览网站[[38](#bib.bib38),
    [22](#bib.bib22)]或执行代码[[39](#bib.bib39)]，而物理环境中的智能体可能会操作物体[[19](#bib.bib19), [40](#bib.bib40),
    [41](#bib.bib41)]、进行实验室实验[[42](#bib.bib42), [43](#bib.bib43)]或做出可行决策[[44](#bib.bib44),
    [45](#bib.bib45)]。
- en: LLM-based Multi-Agent Systems.
  id: totrans-48
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基于LLM的多智能体系统。
- en: LLM-based multi-agent systems (MAS) leverage the interaction among multiple
    agents for problem solving. The relationship among the multiple agents could be
    cooperative, competitive, or a mixture of cooperation and competition [[33](#bib.bib33)].
    In cooperative multi-agent systems, each agent takes and assesses the information
    provided by other agents, thereby working together to solve complex tasks, such
    as role playing [[46](#bib.bib46)], social simulation [[47](#bib.bib47)] and software
    development [[48](#bib.bib48), [49](#bib.bib49), [50](#bib.bib50), [51](#bib.bib51)].
    In competitive multi-agent systems, agents may detabe, negotiate and compete with
    each other in a game environment to achieve their goals, such as improving negotiation
    skills [[52](#bib.bib52)] and debating about the correct answer [[53](#bib.bib53),
    [54](#bib.bib54), [55](#bib.bib55)]. Some multi-agent systems may exhibit both
    cooperation and competition among agents. For example, WarAgent [[56](#bib.bib56)]
    models each country as an LLM-based agent to study how the interaction between
    countries can lead to international conflicts, where countries may cooperate with
    each other, such as establishing alliances and making peace agreements, or compete
    with each other, such as arms race, mobilization, and declaring wars.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLM的多智能体系统（MAS）利用多个智能体之间的互动来解决问题。这些智能体之间的关系可以是合作的、竞争的，或者是合作与竞争的混合形式[[33](#bib.bib33)]。在合作的多智能体系统中，每个智能体会接收并评估其他智能体提供的信息，从而共同完成复杂的任务，如角色扮演[[46](#bib.bib46)]、社会模拟[[47](#bib.bib47)]和软件开发[[48](#bib.bib48),
    [49](#bib.bib49), [50](#bib.bib50), [51](#bib.bib51)]。在竞争的多智能体系统中，智能体可能会在游戏环境中进行辩论、谈判和竞争，以实现其目标，如提高谈判技能[[52](#bib.bib52)]和讨论正确答案[[53](#bib.bib53),
    [54](#bib.bib54), [55](#bib.bib55)]。一些多智能体系统可能会在智能体之间展现出合作与竞争。例如，WarAgent [[56](#bib.bib56)]
    将每个国家建模为基于LLM的智能体，以研究国家间的互动如何导致国际冲突，其中国家可能会合作，如建立联盟和签订和平协议，或者竞争，如军备竞赛、动员和宣战。
- en: '![Refer to caption](img/bf49a4180ea8ea50fd878115ed57976c.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/bf49a4180ea8ea50fd878115ed57976c.png)'
- en: 'Figure 2: An overview of the AIOS architecture.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：AIOS 架构概述。
- en: 3 AIOS Layers
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 AIOS 层
- en: 'As depicted in [Figure 2](#S2.F2 "Figure 2 ‣ LLM-based Multi-Agent Systems.
    ‣ 2.2 Large Language Model Agents ‣ 2 Related Work ‣ AIOS: LLM Agent Operating
    System"), the architecture of our AIOS is organized into three distinct layers:
    the application layer, the kernel layer, and the hardware layer. This layered
    architecture ensures a clear delineation of responsibilities across the system.
    Each higher layer abstracts the complexities of the layers below it, facilitating
    interaction through interfaces or specific modules, thereby enhancing modularity
    and simplifying system interactions across different layers.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '如[图2](#S2.F2 "Figure 2 ‣ LLM-based Multi-Agent Systems. ‣ 2.2 Large Language
    Model Agents ‣ 2 Related Work ‣ AIOS: LLM Agent Operating System")所示，我们的AIOS架构组织为三个不同的层次：应用层、内核层和硬件层。这种分层架构确保了系统职责的清晰划分。每一层都抽象化了其下层的复杂性，通过接口或特定模块促进交互，从而增强模块化，简化了不同层次之间的系统交互。'
- en: Application Layer.
  id: totrans-54
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 应用层。
- en: At the application layer, agent applications, such as travel agent or math agent,
    are developed and deployed. In this layer, AIOS provides the AIOS SDK, with a
    higher abstraction of system calls that simplifies the development process for
    agent developers. This SDK allows for development of agent applications by offering
    a rich toolkit that abstract away the complexities of lower-level system functions.
    This enables developers to dedicate their focus to the essential logic and functionalities
    of their agents, facilitating a more efficient development process.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用层，代理应用程序，如旅行代理或数学代理，得以开发和部署。在这一层，AIOS提供了AIOS SDK，提供了更高抽象的系统调用，简化了代理开发者的开发过程。这个SDK通过提供一个丰富的工具包，将底层系统函数的复杂性抽象化，从而使开发者能够将精力集中在代理的核心逻辑和功能上，促进了更高效的开发过程。
- en: Kernel Layer.
  id: totrans-56
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 内核层。
- en: 'The kernel layer is divided into two primary components: the OS Kernel and
    the LLM Kernel, each serving the unique requirements of non-LLM and LLM-specific
    operations, respectively. This distinction allows the LLM kernel to focus on LLM
    specific tasks such as context management and agent scheduling, which are essential
    for handling LLM-related activities and are not typically within the purview of
    standard OS kernel functions. Our work primarily concentrates on enhancing the
    LLM kernel without making significant alterations to the existing OS kernel structure.
    The LLM kernel is equipped with several key modules, including the LLM system
    call interface, agent scheduler, context manager, memory manager, storage manager,
    tool manager, and access manager. These components are designed to address the
    diverse execution needs of agent applications, ensuring efficient management and
    execution within the AIOS framework. The specifics of these modules will be further
    detailed in Section [4](#S4 "4 AIOS Implementation ‣ AIOS: LLM Agent Operating
    System").'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '内核层分为两个主要组件：操作系统内核和LLM内核，每个组件分别服务于非LLM和LLM特定操作的独特需求。这一区分使得LLM内核可以专注于LLM特定任务，如上下文管理和代理调度，这些任务对处理LLM相关活动至关重要，而通常不在标准操作系统内核功能的范围内。我们的工作主要集中在增强LLM内核，而不对现有操作系统内核结构进行重大修改。LLM内核配备了多个关键模块，包括LLM系统调用接口、代理调度器、上下文管理器、内存管理器、存储管理器、工具管理器和访问管理器。这些组件旨在满足代理应用程序的多样化执行需求，确保在AIOS框架内高效管理和执行。这些模块的具体细节将在第[4](#S4
    "4 AIOS Implementation ‣ AIOS: LLM Agent Operating System")节中进一步阐述。'
- en: Hardware Layer.
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 硬件层。
- en: The hardware layer comprises the physical components of the system, including
    the CPU, GPU, memory, disk, and peripheral devices. It is crucial to note that
    the LLM kernel’s system calls cannot directly interact with the hardware. Instead,
    these calls interface with the OS’s system calls, which in turn manage the hardware
    resources. This indirect interaction ensures a layer of abstraction and security,
    allowing the LLM kernel to leverage hardware capabilities without requiring direct
    hardware management, thus maintaining the system’s integrity and efficiency.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 硬件层包括系统的物理组件，如CPU、GPU、内存、磁盘和外设。值得注意的是，LLM内核的系统调用不能直接与硬件交互。相反，这些调用与操作系统的系统调用接口，后者管理硬件资源。这种间接交互确保了抽象层和安全性，使LLM内核能够利用硬件能力而无需直接管理硬件，从而保持系统的完整性和效率。
- en: 4 AIOS Implementation
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 AIOS实现
- en: In this section, we begin with an overview of the fundamental design and implementation
    of each module within the LLM kernel. Subsequently, we present the LLM system
    calls, which encompass essential functions for each module. At last, we discuss
    the exploration of the AIOS SDK, aiming to facilitate the development process
    for agent developers.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们首先概述了 LLM 核心中每个模块的基本设计和实现。随后，我们介绍了 LLM 系统调用，其中包含每个模块的基本功能。最后，我们讨论了 AIOS
    SDK 的探索，旨在促进代理开发者的开发过程。
- en: 4.1 Agent Scheduler
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 代理调度器
- en: '![Refer to caption](img/83a35c78c5066e25ef338d8401411efd.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/83a35c78c5066e25ef338d8401411efd.png)'
- en: 'Figure 3: An illustration of the agent scheduler.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：代理调度器的示意图。
- en: 'Agent scheduler is designed to manage the agent requests in an efficient way.
    Consider the various agents (denoted as A, B, and C) in [Figure 3](#S4.F3 "Figure
    3 ‣ 4.1 Agent Scheduler ‣ 4 AIOS Implementation ‣ AIOS: LLM Agent Operating System"),
    each of which has several execution steps. In the sequential execution paradigm,
    the agent tasks are processed in a linear order, where steps from a same agent
    will be processed first. This can lead to potential increased waiting times for
    tasks queued later in the sequence.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '代理调度器旨在以高效的方式管理代理请求。考虑[图3](#S4.F3 "Figure 3 ‣ 4.1 Agent Scheduler ‣ 4 AIOS
    Implementation ‣ AIOS: LLM Agent Operating System")中的各种代理（记作 A、B 和 C），每个代理都有几个执行步骤。在顺序执行范式中，代理任务按线性顺序处理，其中同一代理的步骤将优先处理。这可能导致队列中稍后的任务等待时间增加。'
- en: The agent scheduler employs strategies such as First-In-First-Out (FIFO)⁷⁷7[https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)](https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)),
    Round Robin (RR)⁸⁸8[https://en.wikipedia.org/wiki/Round-robin_scheduling](https://en.wikipedia.org/wiki/Round-robin_scheduling),
    and other scheduling algorithms to optimize this process. Through concurrent execution,
    the scheduler significantly balances waiting time and turnaround time of each
    agent, as tasks from different agents are interleaved and executed in parallel.
    This concurrent approach is visualized through a timeline where tasks from different
    agents are processed in an interleaved manner (e.g., A1, B1, C1, B2, A2, A3, C2,
    C3), ensuring that no single agent monopolizes the processing resources and that
    idle times are minimized. Apart from implementing the traditional scheduling algorithms,
    more complex scheduling algorithms considering the dependency relationships between
    agent requests can also be incorporated, which can be considered in the future.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 代理调度器采用诸如先进先出（FIFO）⁷⁷7[https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)](https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics))、轮询（RR）⁸⁸8[https://en.wikipedia.org/wiki/Round-robin_scheduling](https://en.wikipedia.org/wiki/Round-robin_scheduling)等策略来优化这一过程。通过并发执行，调度器显著平衡了每个代理的等待时间和周转时间，因为来自不同代理的任务交错执行。这种并发方法通过时间线可视化，其中来自不同代理的任务以交错的方式处理（例如，A1、B1、C1、B2、A2、A3、C2、C3），确保没有单一代理垄断处理资源，并且最小化空闲时间。除了实施传统调度算法外，还可以考虑更复杂的调度算法，这些算法考虑了代理请求之间的依赖关系，这可以在未来进行考虑。
- en: 4.2 Context Manager
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 上下文管理器
- en: '![Refer to caption](img/678cd58596a629cfb06388fcfa565e87.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/678cd58596a629cfb06388fcfa565e87.png)'
- en: 'Figure 4: Context snapshot and restoration, where we use beam search (beam
    width = 1) as an example search algorithm to illustrate this generative decoding
    process.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：上下文快照和恢复，其中我们使用束搜索（束宽度 = 1）作为示例搜索算法来说明这一生成解码过程。
- en: 'The context manager is responsible for managing the context provided to LLM
    and the generation process given certain context. It primarily involves two crucial
    functions: context snapshot and restoration, and context window management.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文管理器负责管理提供给 LLM 的上下文以及在特定上下文下的生成过程。它主要涉及两个关键功能：上下文快照和恢复，以及上下文窗口管理。
- en: '![Refer to caption](img/28fc33432b34a0afd0e82bd190c2c581.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/28fc33432b34a0afd0e82bd190c2c581.png)'
- en: 'Figure 5: Storage of interaction history with memory manager and storage manager.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：与内存管理器和存储管理器的交互历史存储。
- en: Context Snapshot and Restoration. Consider that the scheduler algorithms may
    involve time quantum operations (e.g., Round-Robin) and agent requests may be
    suspended by the scheduler. This suspension happens even if the response has not
    been fully generated yet by the LLM. Therefore, it necessitates a mechanism to
    preserve the state of the LLM’s generation process, ensuring that it can be accurately
    resumed once resources are available again.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文快照与恢复。考虑到调度算法可能涉及时间量子操作（例如，轮询），而且调度器可能会暂停代理请求，即使LLM的响应尚未完全生成。因此，需要一个机制来保存LLM生成过程的状态，确保在资源再次可用时可以准确恢复。
- en: 'AIOS provides the snapshot and restoration mechanisms in the context manager
    to address this issue, which can be seen from [Figure 4](#S4.F4 "Figure 4 ‣ 4.2
    Context Manager ‣ 4 AIOS Implementation ‣ AIOS: LLM Agent Operating System").
    We use the beam search process⁹⁹9[https://en.wikipedia.org/wiki/Beam_search](https://en.wikipedia.org/wiki/Beam_search),
    a typical practice in LLMs [[10](#bib.bib10), [57](#bib.bib57), [58](#bib.bib58)],
    to illustrate the generative decoding process. For simplicity of illustration,
    we set beam width as 1. Specifically, consider the agent request as: Determine
    whether there will be a rain in the destination of flight UA057. At each step,
    the LLM evaluates multiple potential candidates, with the most promising paths
    kept for further expansion based on the predefined beam width.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 'AIOS在上下文管理器中提供了快照和恢复机制来解决这个问题，从[图4](#S4.F4 "Figure 4 ‣ 4.2 Context Manager
    ‣ 4 AIOS Implementation ‣ AIOS: LLM Agent Operating System")中可以看到。我们使用束搜索过程⁹⁹9[https://en.wikipedia.org/wiki/Beam_search](https://en.wikipedia.org/wiki/Beam_search)，这是LLM中的一种典型实践[[10](#bib.bib10),
    [57](#bib.bib57), [58](#bib.bib58)]，来说明生成解码过程。为了简化说明，我们将束宽设置为1。具体地，考虑代理请求为：确定UA057航班目的地是否会下雨。在每一步中，LLM评估多个潜在候选路径，并根据预定义的束宽保留最有前途的路径以进行进一步扩展。'
- en: 'When such generation process has been suspended by the scheduler at an intermediate
    step, the context manager uses the snapshot function to capture and store the
    current state of the LLM’s beam search tree, including all intermediate probabilities
    and paths being explored for generating the response. Upon resumption, the restoration
    function is employed to reload the saved state from the snapshot, allowing the
    LLM to continue its generation process exactly from the point of suspension to
    reach the final answer: Search weather in Paris. In this way, the context manager
    ensures that the temporary suspension of one agent’s request does not lead to
    a loss of progress, thereby optimizing resource use without compromising the quality
    and efficiency of response generation.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 当这种生成过程在中间步骤被调度器暂停时，上下文管理器使用快照功能捕获并存储LLM束搜索树的当前状态，包括生成响应的所有中间概率和路径。在恢复时，恢复功能用于从快照中重新加载保存的状态，允许LLM从暂停点精确继续其生成过程，最终得到答案：搜索巴黎的天气。通过这种方式，上下文管理器确保一个代理请求的临时暂停不会导致进度丧失，从而优化资源使用，而不影响响应生成的质量和效率。
- en: Context Window Management. To address challenges posed by long contexts that
    surpass the context window limit of LLMs, context manager also needs to manage
    potential expansion of context window. Specifically, context manager in AIOS supports
    basic text summarization and incorporates other expansion techniques [[59](#bib.bib59),
    [60](#bib.bib60)] to manage the context window. In this way, it can help enhance
    the LLM’s ability to process and understand extensive contexts without compromising
    the integrity or relevance of the information.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文窗口管理。为了应对超出LLM上下文窗口限制的长上下文所带来的挑战，上下文管理器还需要管理上下文窗口的潜在扩展。具体来说，AIOS中的上下文管理器支持基本的文本摘要，并结合其他扩展技术[[59](#bib.bib59),
    [60](#bib.bib60)]来管理上下文窗口。这样可以提高LLM处理和理解广泛上下文的能力，而不影响信息的完整性或相关性。
- en: 4.3 Memory Manager
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 内存管理器
- en: 'As shown in [Figure 5](#S4.F5 "Figure 5 ‣ 4.2 Context Manager ‣ 4 AIOS Implementation
    ‣ AIOS: LLM Agent Operating System"), memory manager manages short-term memory
    within an agent’s lifecycle, ensuring that data is stored and accessible only
    while the agent is active, either waiting for execution or during runtime. The
    current AIOS supports storing each agent’s memory independently, each of which
    other agents have no direct access to, unless it is authorized by the access manager.
    More complicated memory mechanisms such as shared memory pools among agents or
    hierarchical caches can be considered and integrated into AIOS in the future.
    Compared with the storage manager introduced in the following, the memory manager
    enables rapid data retrieval and processing, facilitating swift responses to user
    queries and interactions without overburdening the storage of AIOS.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '如[图 5](#S4.F5 "Figure 5 ‣ 4.2 Context Manager ‣ 4 AIOS Implementation ‣ AIOS:
    LLM Agent Operating System")所示，内存管理器在智能体的生命周期内管理短期记忆，确保数据仅在智能体处于活跃状态时存储和可访问，无论是在等待执行还是在运行时。当前的
    AIOS 支持独立存储每个智能体的内存，其他智能体无法直接访问，除非获得访问管理器的授权。更复杂的内存机制，如智能体之间的共享内存池或分层缓存，可以考虑并在未来集成到
    AIOS 中。与后续介绍的存储管理器相比，内存管理器能够快速检索和处理数据，从而在不增加 AIOS 存储负担的情况下，快速响应用户查询和交互。'
- en: 'Table 1: Managed tools in AIOS. The last column shows each tool’s required
    input and output format.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：AIOS 中管理的工具。最后一列显示了每个工具所需的输入和输出格式。
- en: Category Tool Name Description Input $\rightarrow$ Text
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 类别 工具名称 描述 输入 $\rightarrow$ 文本
- en: 4.4 Storage Manager
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 存储管理器
- en: In constrast, the storage manager is responsible for the long-term preservation
    of data, overseeing the storage of information that needs to be retained indefinitely,
    beyond the active lifespan of any single agent. This permanent storage in AIOS
    is achieved through a variety of durable mediums such as local files, databases,
    or cloud-based solutions, ensuring data integrity and availability for future
    reference or analysis. The storage manager supports retrieval augmentation [[61](#bib.bib61)].
    Through storing user preferences and maintaining historical interaction logs,
    the storage manager can enrich the agent knowledge update and enhancing the long-term
    user experience.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，存储管理器负责数据的长期保存，监督需要无限期保留的信息的存储，超出任何单一智能体的活跃生命周期。AIOS 中的这种永久存储是通过各种耐用介质实现的，如本地文件、数据库或基于云的解决方案，确保数据的完整性和未来的参考或分析的可用性。存储管理器支持检索增强[[61](#bib.bib61)]。通过存储用户偏好和维护历史交互日志，存储管理器可以丰富智能体的知识更新，并提升长期用户体验。
- en: 4.5 Tool Manager
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 工具管理器
- en: 'The tool manager in the AIOS system manages a diverse array of API tools that
    enhance the functionality of LLMs. As shown in [Table 1](#S4.T1 "Table 1 ‣ 4.3
    Memory Manager ‣ 4 AIOS Implementation ‣ AIOS: LLM Agent Operating System"), the
    tool manager integrates commonly-used tools from various sources [[7](#bib.bib7),
    [62](#bib.bib62), [63](#bib.bib63)] and classify them into different categories,
    which covers web search, scientific computing, database retrieval, image processing,
    etc. In this way, the managed tools can cover different modalities of input and
    output (image and text), thus facilitating agent development within the AIOS ecosystem.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 'AIOS 系统中的工具管理器管理着多种 API 工具，这些工具增强了 LLM 的功能。如[表 1](#S4.T1 "Table 1 ‣ 4.3 Memory
    Manager ‣ 4 AIOS Implementation ‣ AIOS: LLM Agent Operating System")所示，工具管理器整合了来自不同来源的常用工具[[7](#bib.bib7),
    [62](#bib.bib62), [63](#bib.bib63)]，并将它们分类为不同类别，包括网页搜索、科学计算、数据库检索、图像处理等。通过这种方式，管理的工具可以涵盖不同的输入和输出模式（图像和文本），从而促进了
    AIOS 生态系统中的智能体开发。'
- en: 'Table 2: Instances of LLM system calls.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：LLM 系统调用实例。
- en: Category Name Description Arguments Agent syscall get_aid get ID of an agent
    - set_aid set ID of an agent int aid get_status get status of an agent int aid
    set_status get status of an agent int aid, string status get_priority get priority
    of an agent int aid set_priority set priority of an agent int aid, int priority
    suspend_agent suspend an agent’s operation int aid resume_agent resume an agent’s
    operation int aid Context syscall gen_snapshot snapshot intermediate LLM generation
    status - gen_restore restore intermediate LLM generation status - get_context
    get context window length - exp_context expand context window length - clr_context
    clear current context window - set_context set a specific context window context
    c Memory syscall mem_write write the interaction record into memory int aid, memory
    m mem_read read the interaction record from memory int aid, memory m mem_clear
    clear specific memory record int aid, memory m mem_alloc allocate memory for an
    agent int aid, size s Storage syscall sto_write write the interaction record into
    storage int aid, storage s sto_read load the interaction record from storage int
    aid, storage s sto_delete delete the interaction record from storage int aid,
    storage s sto_alloc allocate storage for an agent int aid, size s
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 类别 名称 描述 参数 代理系统调用 get_aid 获取代理的ID - set_aid 设置代理的ID int aid get_status 获取代理的状态
    int aid set_status 设置代理的状态 int aid, string status get_priority 获取代理的优先级 int aid
    set_priority 设置代理的优先级 int aid, int priority suspend_agent 挂起代理的操作 int aid resume_agent
    恢复代理的操作 int aid 上下文系统调用 gen_snapshot 快照中间LLM生成状态 - gen_restore 恢复中间LLM生成状态 - get_context
    获取上下文窗口长度 - exp_context 扩展上下文窗口长度 - clr_context 清除当前上下文窗口 - set_context 设置特定上下文窗口
    context c 内存系统调用 mem_write 将交互记录写入内存 int aid, memory m mem_read 从内存中读取交互记录 int
    aid, memory m mem_clear 清除特定内存记录 int aid, memory m mem_alloc 为代理分配内存 int aid,
    size s 存储系统调用 sto_write 将交互记录写入存储 int aid, storage s sto_read 从存储中加载交互记录 int aid,
    storage s sto_delete 从存储中删除交互记录 int aid, storage s sto_alloc 为代理分配存储 int aid,
    size s
- en: 4.6 Access Manager
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.6 访问管理器
- en: The access manager orchestrates access control operations among distinct agents
    by administering a dedicated privilege group for each agent. Those other agents
    that are excluded from an agent’s privilege group are denied access to its resources,
    such as the interaction history. To further enhance system transparency, the access
    manager compiles and maintains auditing logs. These logs capture detailed information
    about access requests, agent activities, and any modifications to the access control
    parameters, which help to safeguard against potential privilege attacks [[64](#bib.bib64),
    [65](#bib.bib65)].
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 访问管理器通过为每个代理管理专用的权限组来协调不同代理之间的访问控制操作。那些未被包括在代理权限组中的其他代理将被拒绝访问其资源，如交互历史。为了进一步提升系统透明度，访问管理器编制并维护审计日志。这些日志捕捉关于访问请求、代理活动和任何对访问控制参数的修改的详细信息，有助于防范潜在的权限攻击 [[64](#bib.bib64),
    [65](#bib.bib65)]。
- en: 4.7 LLM System Call
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.7 LLM系统调用
- en: 'LLM system call interface within the LLM kernel is designed to offer basic
    LLM call operation functions. This interface acts as a bridge between complex
    agent requests and the execution of different kernel’s modules. As is shown in [Table 2](#S4.T2
    "Table 2 ‣ 4.5 Tool Manager ‣ 4 AIOS Implementation ‣ AIOS: LLM Agent Operating
    System"), analogous to OS system calls, LLM system calls offers a suite of basic
    functions that span across the kernel’s modules, including agent management, context
    handling, memory and storage operations, and access control. The LLM system call
    list can be further expanded in the future to support more operations.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 'LLM内核中的LLM系统调用接口旨在提供基本的LLM调用操作功能。该接口作为复杂代理请求与不同内核模块执行之间的桥梁。如[表2](#S4.T2 "Table
    2 ‣ 4.5 Tool Manager ‣ 4 AIOS Implementation ‣ AIOS: LLM Agent Operating System")所示，类似于操作系统调用，LLM系统调用提供了一套基本功能，涵盖内核的模块，包括代理管理、上下文处理、内存和存储操作以及访问控制。未来可以进一步扩展LLM系统调用列表，以支持更多操作。'
- en: 4.8 AIOS SDK
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.8 AIOS SDK
- en: 'The AIOS SDK is designed to equip developers with a versatile toolkit for crafting
    sophisticated agent applications within the AIOS. This SDK encompasses a broad
    spectrum of functionalities, from initializing agents and managing agent lifecycles
    to facilitating complex operations like resource monitoring, and generation plan
    for an agent task. Like any operating system, enriching the SDK to be comprehensive
    and developer-friendly is a long-term and never-ending endeavor. The current SDK
    functions supported in AIOS are shown in [Table 3](#S4.T3 "Table 3 ‣ 4.8 AIOS
    SDK ‣ 4 AIOS Implementation ‣ AIOS: LLM Agent Operating System"), which will be
    continuously updated and expanded to fulfill the needs of evolving agent applications.
    This development effort aims to provide developers with the tools they need to
    harness the full potential of their agent applications within the AIOS framework.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 'AIOS SDK 旨在为开发人员提供一个多功能工具包，以在 AIOS 内创建复杂的代理应用程序。该 SDK 涵盖了广泛的功能，从初始化代理和管理代理生命周期，到执行复杂的操作，如资源监控和生成代理任务的计划。与任何操作系统一样，使
    SDK 变得全面且对开发者友好是一个长期且永无止境的工作。当前在 AIOS 中支持的 SDK 功能见 [表 3](#S4.T3 "Table 3 ‣ 4.8
    AIOS SDK ‣ 4 AIOS Implementation ‣ AIOS: LLM Agent Operating System")，这些功能将持续更新和扩展，以满足不断发展的代理应用程序的需求。这一开发工作旨在为开发者提供所需工具，以充分发挥其代理应用程序在
    AIOS 框架内的潜力。'
- en: 'Table 3: The list of SDK functions in AIOS SDK'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：AIOS SDK 中的 SDK 函数列表
- en: SDK Function Name Description Return Type initializeAgent() set up environment
    for agent execution, including resource allocation Void registerAgent() register
    a new agent to the system, providing it with ID and permissions Boolean queueForExecution()
    enqueue the agent for execution Void generatePlan() generate a plan of a given
    agent task Object terminateAgent() terminate an agent’s execution with cleanup
    Void createAgentSnapshot() Create a snapshot of the agent’s current state for
    rollback Object rollbackAgentState() Rollback the agent’s state to a previous
    snapshot Void updateAgentConfig() update the configuration settings for an agent
    Boolean authenticateAgent() authenticate an agent’s credentials before execution
    Boolean monitorResourceUsage() track and report the usage of system resources
    by agents Object logEvent() provide logging of agent-specific events for debugging
    and auditing Void listActiveAgents() list all currently active agents within the
    system List queryAgentHistory() query the historical operations of an agent Object
    encryptData() encrypt sensitive data generated by an agent Object decryptData()
    decrypt sensitive data for an agent’s consumption Object
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: SDK 功能名称 描述 返回类型 initializeAgent() 设置代理执行环境，包括资源分配 Void registerAgent() 注册一个新的代理到系统中，为其提供
    ID 和权限 Boolean queueForExecution() 将代理加入执行队列 Void generatePlan() 为给定的代理任务生成计划
    Object terminateAgent() 终止代理的执行并进行清理 Void createAgentSnapshot() 创建代理当前状态的快照以便回滚
    Object rollbackAgentState() 将代理状态回滚到先前的快照 Void updateAgentConfig() 更新代理的配置设置 Boolean
    authenticateAgent() 在执行前验证代理的凭据 Boolean monitorResourceUsage() 跟踪并报告系统资源的使用情况
    Object logEvent() 提供代理特定事件的日志记录，用于调试和审计 Void listActiveAgents() 列出系统内所有当前活动的代理
    List queryAgentHistory() 查询代理的历史操作 Object encryptData() 加密代理生成的敏感数据 Object decryptData()
    解密代理消费的敏感数据 Object
- en: 5 Evaluation
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 评估
- en: 'In this section, we evaluate both the correctness and the performance of AIOS
    modules when multiple agents are running in parallel in AIOS. Our investigation
    is guided by two research questions: firstly, whether the LLM responses to agent
    requests are consistent after agent suspension and transition to another agent,
    and secondly, how is the performance of AIOS scheduling in improving balance of
    waiting and turnaround time relative to non-scheduled (sequential) execution.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们评估了 AIOS 模块在多个代理并行运行时的正确性和性能。我们的调查由两个研究问题指导：首先，LLM 对代理请求的响应在代理挂起后及转移到另一个代理后是否一致；其次，AIOS
    调度在提高等待和周转时间的平衡相对于未调度（顺序）执行的性能如何。
- en: 5.1 Setup
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 设置
- en: 'Our experiments are conducted in Python 3.9 with PyTorch 2.0.1 and CUDA 11.8
    on an Ubuntu 22.04 machine equipped with 8 NVIDIA RTX A5000 GPUs. We employ the
    publicly available LLMs (i.e., Gemma-2b-it and Gemma-7b-it [[66](#bib.bib66)],
    LLaMA-2-13b-chat-hf [[10](#bib.bib10)]) as the backbone of AIOS. This selection
    is driven by the advantage of local deployment of open-sourced models, which aids
    in the accurate measurement of time latency. For the evaluation, we configure
    three specialized agents: a Math Agent for solving mathematical challenges, a
    Narrative Agent for generating novel narratives, and a Rec Agent tasked with providing
    restaurant recommendations. Each agent is designed to send 2 to 3 requests to
    the backbone LLM during running.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实验在配备8个NVIDIA RTX A5000 GPU的Ubuntu 22.04机器上，使用Python 3.9、PyTorch 2.0.1和CUDA
    11.8进行。我们采用公开可用的LLM（即Gemma-2b-it和Gemma-7b-it[[66](#bib.bib66)]，LLaMA-2-13b-chat-hf[[10](#bib.bib10)]）作为AIOS的骨干。这一选择是基于本地部署开源模型的优势，有助于准确测量时间延迟。为了评估，我们配置了三个专用代理：一个用于解决数学问题的数学代理，一个用于生成新叙事的叙事代理，以及一个负责提供餐馆推荐的推荐代理。每个代理在运行期间设计为向骨干LLM发送2到3个请求。
- en: 5.2 Experimental Results
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 实验结果
- en: 'Table 4: Consistency of LLM generated responses when running multiple agents
    in parallel compared with LLM generated responses when running a single agent
    one by one.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 表4：在并行运行多个代理与逐个运行单个代理时，LLM生成的响应的一致性。
- en: LLM-backbone Math Agent Narrative Agent Rec Agent BLEU Score BERT Score BLEU
    Score BERT Score BLEU Score BERT Score Gemma-2b-it 1.0 1.0 1.0 1.0 1.0 1.0 Gemma-7b-it
    1.0 1.0 1.0 1.0 1.0 1.0 LLaMA-2-13b-chat-hf 1.0 1.0 1.0 1.0 1.0 1.0
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: LLM-backbone 数学代理 叙事代理 推荐代理 BLEU分数 BERT分数 BLEU分数 BERT分数 BLEU分数 BERT分数 Gemma-2b-it
    1.0 1.0 1.0 1.0 1.0 1.0 Gemma-7b-it 1.0 1.0 1.0 1.0 1.0 1.0 LLaMA-2-13b-chat-hf
    1.0 1.0 1.0 1.0 1.0 1.0
- en: Consistency Analysis.
  id: totrans-102
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 一致性分析。
- en: 'To answer the consistency question, we first run each of the three constructed
    agents individually to generate results. Subsequently, we execute these agents
    in parallel, capturing their outputs at each step. To assess the consistency of
    outputs under the running of multiple agents in parallel and under the running
    of single agents one by one, we utilize the BLEU score [[67](#bib.bib67)] and
    BERT score [[68](#bib.bib68)] as evaluative metrics. Both metrics span from 0.0
    to 1.0, with outputs produced in a single-agent context serving as the reference
    standard and we set the temperature parameter as 0 to eliminate the impact of
    randomness. As demonstrated in Table [4](#S5.T4 "Table 4 ‣ 5.2 Experimental Results
    ‣ 5 Evaluation ‣ AIOS: LLM Agent Operating System"), BLEU and BERT scores all
    achieve the value of 1.0, indicating a perfect alignment between outputs generated
    in multi-agent and single-agent configurations. This result affirms the consistency
    of our design in effectively facilitating concurrent multi-agent operations.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '为了解答一致性问题，我们首先分别运行三个构建的代理以生成结果。随后，我们并行执行这些代理，捕捉它们在每一步的输出。为了评估在多个代理并行运行和单个代理逐个运行下输出的一致性，我们利用BLEU分数[[67](#bib.bib67)]和BERT分数[[68](#bib.bib68)]作为评估指标。这两个指标的范围为0.0到1.0，单代理上下文中生成的输出作为参考标准，我们将温度参数设为0，以消除随机性的影响。如表[4](#S5.T4
    "Table 4 ‣ 5.2 Experimental Results ‣ 5 Evaluation ‣ AIOS: LLM Agent Operating
    System")所示，BLEU和BERT分数均达到了1.0，表明在多代理和单代理配置中生成的输出完全一致。该结果确认了我们的设计在有效促进并发多代理操作中的一致性。'
- en: Performance Analysis.
  id: totrans-104
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 性能分析。
- en: 'To answer the efficiency question, we conduct a comparative analysis between
    AIOS employing FIFO scheduling and a non-scheduled approach, wherein the aforementioned
    three agents run concurrently. In the non-scheduled setting, the three agents
    are executed following a predefined sequential order: Math Agent, Narrative Agent,
    and Rec Agent. We employ two metrics for assessing temporal efficiency: waiting
    time (the interval from agent request submission to commencement) and turnaround
    time (the duration from agent request submission to completion). As each agent
    will send multiple requests to the LLM, the waiting time and turnaround time of
    each agent are calculated as the average of waiting time and turnaround time of
    all its sent requests, respectively. To mitigate randomness, we execute these
    three agents, both with and without scheduling, in five separate trials to report
    the results. As shown in  [Table 5](#S5.T5 "Table 5 ‣ Performance Analysis. ‣
    5.2 Experimental Results ‣ 5 Evaluation ‣ AIOS: LLM Agent Operating System"),
    the non-scheduled approach exhibits good performance for agents earlier in the
    sequence, but at the expense of extended waiting time and turnaround time for
    agents later in the sequence. Conversely, AIOS’s scheduling mechanism efficiently
    regulates both waiting time and turnaround time, a benefit that becomes particularly
    evident for agent requests submitted later by agents, especially when LLM is large.
    This suggests the importance of our scheduling to accommodate parallel operations
    of multiple agents.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '为了解决效率问题，我们对使用FIFO调度的AIOS与非调度方法进行了比较分析，其中上述三种代理同时运行。在非调度设置中，三种代理按照预定义的顺序执行：数学代理、叙事代理和推荐代理。我们使用两种指标来评估时间效率：等待时间（从代理请求提交到开始的间隔）和周转时间（从代理请求提交到完成的持续时间）。由于每个代理会向LLM发送多个请求，因此每个代理的等待时间和周转时间分别计算为其发送的所有请求的等待时间和周转时间的平均值。为了减少随机性，我们对这三种代理进行了五次独立试验，无论是有调度还是无调度。结果显示在[表5](#S5.T5
    "Table 5 ‣ Performance Analysis. ‣ 5.2 Experimental Results ‣ 5 Evaluation ‣ AIOS:
    LLM Agent Operating System")中，未调度的方法对于序列中的早期代理表现良好，但牺牲了序列中后期代理的等待时间和周转时间。相反，AIOS的调度机制有效地调节了等待时间和周转时间，这一优势在代理请求较晚提交时尤为明显，特别是在LLM较大的情况下。这表明我们的调度机制在适应多个代理的并行操作方面的重要性。'
- en: 'Table 5: Effectiveness of agent scheduling, compared with non-scheduled (sequential)
    execution.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 表5：代理调度的有效性，与未调度（顺序）执行相比。
- en: LLM backbone Agent Sequential execution (non-scheduled) Concurrent execution
    (scheduled) Waiting time (s) Turnaround time (s) Waiting time (s) Turnaround time
    (s) Gemma-2b-it Math Agent 0.002$\pm$2.43
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: LLM主干代理 顺序执行（未调度） 并发执行（调度） 等待时间（秒） 周转时间（秒） 等待时间（秒） 周转时间（秒） Gemma-2b-it 数学代理
    0.002$\pm$2.43
- en: 6 Conclusions
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: This paper proposes the AIOS architecture, demonstrating the potential to facilitate
    the development and deployment of LLM-based agents, fostering a more cohesive,
    effective and efficient AIOS-Agent ecosystem. The insights and methodologies presented
    herein contribute to the ongoing discourse in both AI and system research, offering
    a viable solution to the integration challenges posed by the diverse landscape
    of AI Agents. Diverse future work can be built upon this foundation, exploring
    innovative ways to refine and expand the AIOS architecture to meet the evolving
    needs of developing and deploying LLM agents.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提出了AIOS架构，展示了促进基于LLM的代理开发和部署的潜力，促进了一个更具凝聚力、高效和有效的AIOS-代理生态系统。本文提出的见解和方法为AI和系统研究的持续讨论做出了贡献，提供了一种解决多样化AI代理领域整合挑战的可行解决方案。在此基础上，可以开展多样化的未来工作，探索创新的方法来改进和扩展AIOS架构，以满足开发和部署LLM代理的不断变化的需求。
- en: 7 Future Work
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 未来工作
- en: Beginning with AIOS, there are many directions for future research to pursue.
    This section outlines potential areas of study that expand upon the foundational
    features of AIOS.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 从AIOS开始，未来的研究方向有很多。本节概述了可能的研究领域，这些领域扩展了AIOS的基础功能。
- en: Advanced Scheduling Algorithms.
  id: totrans-112
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 高级调度算法。
- en: The scheduling function of AIOS lays the groundwork for the development of more
    advanced algorithms. Future research could focus on algorithms that perform dependency
    analysis among agent requests, optimizing the allocation of computational resources.
    Additionally, some of the tool resources are locally deployed models, which can
    also be incorporated into the scheduling paradigm. This includes the management
    of tool status and snapshots, suggesting a move towards a unified scheduling framework
    that encompasses both agents and their tools.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: AIOS的调度功能为更高级算法的发展奠定了基础。未来的研究可以专注于执行代理请求之间依赖分析的算法，以优化计算资源的分配。此外，一些工具资源是本地部署的模型，也可以纳入调度范式中。这包括工具状态和快照的管理，建议转向一个统一的调度框架，涵盖代理及其工具。
- en: Efficiency of Context Management.
  id: totrans-114
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 上下文管理效率。
- en: More efficient mechanisms can be devised to assist context management. For example,
    the pursuit of time-efficient context management techniques could significantly
    augment user experience by expediting the processes of context snapshotting and
    restoration. Also, context compression techniques can also be leveraged prior
    to snapshotting, which can yield a more space-efficient solution.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 可以设计更高效的机制来协助上下文管理。例如，追求时间高效的上下文管理技术可以通过加速上下文快照和恢复过程显著提升用户体验。此外，还可以在快照前利用上下文压缩技术，以获得更节省空间的解决方案。
- en: Optimization of Memory and Storage Architecture.
  id: totrans-116
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 内存和存储架构优化。
- en: In the context of agent collaboration and communication, the future design of
    memory and storage systems can adopt a shared approach, enabling the sharing of
    memory and storage between agents. Such an architecture would enable agents to
    access a communal pool of memory and storage, thereby improving the agents’ decision-making
    ability since one agent can benefit from other agents’ memory or storage. Moreover,
    future work can explore hierarchical storage solutions, designed to optimize data
    retrieval and storage efficiency. This could involve prioritizing quicker access
    and reduced storage allocation for frequently accessed data, and vice versa for
    less frequently accessed information.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在代理协作和通信的背景下，未来内存和存储系统的设计可以采用共享方法，允许代理之间共享内存和存储。这样的架构将使代理能够访问共享的内存和存储池，从而提高代理的决策能力，因为一个代理可以受益于其他代理的内存或存储。此外，未来的工作可以探讨分层存储解决方案，旨在优化数据检索和存储效率。这可能涉及优先处理快速访问和减少存储分配给经常访问的数据，反之亦然。
- en: Safety and Privacy Enhancements.
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 安全性和隐私增强。
- en: The aspect of safety in AIOS necessitates protective measures against various
    attacks, ensuring the system’s resilience against malicious attacks, such as jailbreaking
    of LLM or unauthorized access of other agents’ memory. In the realm of privacy,
    the exploration of advanced encryption techniques is vital for safeguarding data
    transmission within AIOS, thus maintaining the confidentiality of agent communications.
    Furthermore, the implementation of watermarking techniques could serve to protect
    the intellectual property of agent developers by embedding unique identifiers
    in outputs, facilitating the tracing of data lineage.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: AIOS中的安全性方面需要针对各种攻击采取保护措施，确保系统对恶意攻击的抵御能力，如LLM的越狱或其他代理内存的未经授权访问。在隐私领域，探索先进的加密技术对于保护AIOS中的数据传输至关重要，从而保持代理通信的机密性。此外，实施水印技术可以通过在输出中嵌入唯一标识符来保护代理开发者的知识产权，便于追踪数据来源。
- en: In a netshell, AIOS stands as a motivating body of work that brings a broad
    spectrum of research opportunities. Each outlined direction can not only build
    upon the foundational elements of AIOS but also contribute to the advancement
    of the field at large.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，AIOS作为一个激励性的工作，带来了广泛的研究机会。每个列出的方向不仅可以建立在AIOS的基础元素上，还能为该领域的整体进步做出贡献。
- en: Acknowledgement
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: We thank Jian Zhang, Zhenting Wang, and Wenyue Hua for their valuable discussions
    and suggestions during the project.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢Jian Zhang、Zhenting Wang和Wenyue Hua在项目过程中提供的宝贵讨论和建议。
- en: References
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Michael Wooldridge and Nicholas R Jennings. Intelligent agents: Theory
    and practice. The knowledge engineering review, 10(2):115–152, 1995.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Michael Wooldridge 和 Nicholas R Jennings. 智能代理：理论与实践。《知识工程评论》，10(2):115–152，1995年。'
- en: '[2] Nicholas R Jennings, Katia Sycara, and Michael Wooldridge. A roadmap of
    agent research and development. Autonomous agents and multi-agent systems, 1:7–38,
    1998.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Nicholas R Jennings, Katia Sycara, 和 Michael Wooldridge. 代理研究与发展的路线图. 自主代理与多代理系统,
    1:7–38, 1998.'
- en: '[3] Paolo Bresciani, Anna Perini, Paolo Giorgini, Fausto Giunchiglia, and John
    Mylopoulos. Tropos: An agent-oriented software development methodology. Autonomous
    Agents and Multi-Agent Systems, 8:203–236, 2004.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Paolo Bresciani, Anna Perini, Paolo Giorgini, Fausto Giunchiglia, 和 John
    Mylopoulos. Tropos: 一种面向代理的软件开发方法论. 自主代理与多代理系统, 8:203–236, 2004.'
- en: '[4] OpenAI. Gpt-4. [https://openai.com/research/gpt-4](https://openai.com/research/gpt-4),
    2023.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] OpenAI. Gpt-4. [https://openai.com/research/gpt-4](https://openai.com/research/gpt-4),
    2023.'
- en: '[5] Facebook. Meta. introducing llama: A foundational, 65-billion-parameter
    large language model. [https://ai.facebook.com/blog/largelanguage-model-llama-meta-ai](https://ai.facebook.com/blog/largelanguage-model-llama-meta-ai),
    2022.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Facebook. Meta. 介绍 llama: 一种基础的、65亿参数的大型语言模型. [https://ai.facebook.com/blog/largelanguage-model-llama-meta-ai](https://ai.facebook.com/blog/largelanguage-model-llama-meta-ai),
    2022.'
- en: '[6] Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste
    Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al.
    Gemini: a family of highly capable multimodal models. arXiv preprint arXiv:2312.11805,
    2023.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste
    Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, 等.
    Gemini: 一系列高度能力的多模态模型. arXiv 预印本 arXiv:2312.11805, 2023.'
- en: '[7] Yingqiang Ge, Wenyue Hua, Kai Mei, Juntao Tan, Shuyuan Xu, Zelong Li, and
    Yongfeng Zhang. OpenAGI: When LLM Meets Domain Experts. Advances in Neural Information
    Processing Systems, 36, 2023.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Yingqiang Ge, Wenyue Hua, Kai Mei, Juntao Tan, Shuyuan Xu, Zelong Li, 和
    Yongfeng Zhang. OpenAGI: 当 LLM 遇见领域专家. 神经信息处理系统进展, 36, 2023.'
- en: '[8] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela
    Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training
    language models to follow instructions with human feedback. Advances in Neural
    Information Processing Systems, 35:27730–27744, 2022.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela
    Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, 等. 训练语言模型以遵循人类反馈的指令.
    神经信息处理系统进展, 35:27730–27744, 2022.'
- en: '[9] Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus,
    Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-finetuned
    language models. arXiv preprint arXiv:2210.11416, 2022.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus,
    Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, 等. 扩展指令微调语言模型. arXiv
    预印本 arXiv:2210.11416, 2022.'
- en: '[10] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi,
    Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale,
    et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288,
    2023.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi,
    Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale,
    等. Llama 2: 开放基础和微调聊天模型. arXiv 预印本 arXiv:2307.09288, 2023.'
- en: '[11] Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang.
    Recommendation as language processing (rlp): A unified pretrain, personalized
    prompt & predict paradigm (p5). In Proceedings of the 16th ACM Conference on Recommender
    Systems, page 299–315, 2022.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, 和 Yongfeng Zhang.
    推荐系统作为语言处理 (RLP): 统一的预训练、个性化提示与预测范式 (P5). 在第16届 ACM 推荐系统会议论文集中, 第 299–315 页, 2022.'
- en: '[12] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke
    Iwasawa. Large language models are zero-shot reasoners. Advances in neural information
    processing systems, 35:22199–22213, 2022.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, 和 Yusuke
    Iwasawa. 大型语言模型是零样本推理器. 神经信息处理系统进展, 35:22199–22213, 2022.'
- en: '[13] Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou,
    Silvio Savarese, and Caiming Xiong. Codegen: An open large language model for
    code with multi-turn program synthesis. arXiv preprint arXiv:2203.13474, 2022.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou,
    Silvio Savarese, 和 Caiming Xiong. Codegen: 一种开放的大型代码语言模型，支持多轮程序合成. arXiv 预印本 arXiv:2203.13474,
    2022.'
- en: '[14] Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony
    Hartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, and Robert Stojnic. Galactica:
    A large language model for science. arXiv preprint arXiv:2211.09085, 2022.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony
    Hartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, 和 Robert Stojnic. Galactica:
    一种用于科学的大型语言模型. arXiv 预印本 arXiv:2211.09085, 2022.'
- en: '[15] Shibo Hao, Yi Gu, Haodi Ma, Joshua Hong, Zhen Wang, Daisy Wang, and Zhiting
    Hu. Reasoning with language model is planning with world model. In Proceedings
    of the 2023 Conference on Empirical Methods in Natural Language Processing, pages
    8154–8173, 2023.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Shibo Hao, Yi Gu, Haodi Ma, Joshua Hong, Zhen Wang, Daisy Wang 和 Zhiting
    Hu. 使用语言模型进行推理即是在使用世界模型进行规划。在2023年自然语言处理实证方法会议论文集中, 页8154–8173, 2023.'
- en: '[16] Geunwoo Kim, Pierre Baldi, and Stephen McAleer. Language models can solve
    computer tasks. Advances in Neural Information Processing Systems, 36, 2023.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Geunwoo Kim, Pierre Baldi 和 Stephen McAleer. 语言模型可以解决计算机任务。神经信息处理系统进展,
    36, 2023.'
- en: '[17] Steven I Ross, Fernando Martinez, Stephanie Houde, Michael Muller, and
    Justin D Weisz. The programmer’s assistant: Conversational interaction with a
    large language model for software development. In Proceedings of the 28th International
    Conference on Intelligent User Interfaces, pages 491–514, 2023.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Steven I Ross, Fernando Martinez, Stephanie Houde, Michael Muller 和 Justin
    D Weisz. 程序员助手: 与大型语言模型的对话互动以进行软件开发。在第28届国际智能用户界面会议论文集中, 页491–514, 2023.'
- en: '[18] Danny Driess, Fei Xia, Mehdi SM Sajjadi, Corey Lynch, Aakanksha Chowdhery,
    Brian Ichter, Ayzaan Wahid, Jonathan Tompson, Quan Vuong, Tianhe Yu, et al. Palm-e:
    an embodied multimodal language model. In Proceedings of the 40th International
    Conference on Machine Learning, pages 8469–8488, 2023.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Danny Driess, Fei Xia, Mehdi SM Sajjadi, Corey Lynch, Aakanksha Chowdhery,
    Brian Ichter, Ayzaan Wahid, Jonathan Tompson, Quan Vuong, Tianhe Yu 等. Palm-e:
    一种具身的多模态语言模型。在第40届国际机器学习大会论文集中, 页8469–8488, 2023.'
- en: '[19] Anthony Brohan, Yevgen Chebotar, Chelsea Finn, Karol Hausman, Alexander
    Herzog, Daniel Ho, Julian Ibarz, Alex Irpan, Eric Jang, Ryan Julian, et al. Do
    as i can, not as i say: Grounding language in robotic affordances. In Conference
    on robot learning, pages 287–318\. PMLR, 2023.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Anthony Brohan, Yevgen Chebotar, Chelsea Finn, Karol Hausman, Alexander
    Herzog, Daniel Ho, Julian Ibarz, Alex Irpan, Eric Jang, Ryan Julian 等. 以我所能，而非我所说:
    将语言扎根于机器人能力中。在机器人学习大会上, 页287–318\. PMLR, 2023.'
- en: '[20] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan,
    and Yuan Cao. ReAct: Synergizing reasoning and acting in language models. International
    Conference on Learning Representations, 2023.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan
    和 Yuan Cao. ReAct: 在语言模型中协同推理与行动。国际表示学习大会, 2023.'
- en: '[21] Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and
    Shunyu Yao. Reflexion: Language agents with verbal reinforcement learning. Advances
    in Neural Information Processing Systems, 36, 2023.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan 和 Shunyu
    Yao. Reflexion: 通过言语强化学习的语言代理。神经信息处理系统进展, 36, 2023.'
- en: '[22] Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang,
    Huan Sun, and Yu Su. Mind2web: Towards a generalist agent for the web. Advances
    in Neural Information Processing Systems, 36, 2023.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang,
    Huan Sun 和 Yu Su. Mind2web: 迈向通用型网络代理。神经信息处理系统进展, 36, 2023.'
- en: '[23] UW:CSE451. History of Operating Systems, 2023. [https://courses.cs.washington.edu/courses/cse451/16wi/readings/lecture_readings/LCM_OperatingSystemsTimeline_Color_acd_newsize.pdf](https://courses.cs.washington.edu/courses/cse451/16wi/readings/lecture_readings/LCM_OperatingSystemsTimeline_Color_acd_newsize.pdf).'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] UW:CSE451. 操作系统历史, 2023. [https://courses.cs.washington.edu/courses/cse451/16wi/readings/lecture_readings/LCM_OperatingSystemsTimeline_Color_acd_newsize.pdf](https://courses.cs.washington.edu/courses/cse451/16wi/readings/lecture_readings/LCM_OperatingSystemsTimeline_Color_acd_newsize.pdf).'
- en: '[24] Dennis M. Ritchie and Ken Thompson. The unix time-sharing system. Commun.
    ACM, 17(7):365–375, jul 1974.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Dennis M. Ritchie 和 Ken Thompson. Unix 时间共享系统。Commun. ACM, 17(7):365–375,
    1974年7月.'
- en: '[25] Charles Antony Richard Hoare. Monitors: An operating system structuring
    concept. Communications of the ACM, 17(10):549–557, 1974.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Charles Antony Richard Hoare. 监视器: 一种操作系统结构化概念。ACM通讯, 17(10):549–557,
    1974.'
- en: '[26] Dawson R Engler, M Frans Kaashoek, and James O’Toole Jr. Exokernel: An
    operating system architecture for application-level resource management. ACM SIGOPS
    Operating Systems Review, 29(5):251–266, 1995.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Dawson R Engler, M Frans Kaashoek 和 James O’Toole Jr. Exokernel: 一种用于应用级资源管理的操作系统架构。ACM
    SIGOPS 操作系统评论, 29(5):251–266, 1995.'
- en: '[27] Chung Laung Liu and James W Layland. Scheduling algorithms for multiprogramming
    in a hard-real-time environment. Journal of the ACM (JACM), 20(1):46–61, 1973.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Chung Laung Liu 和 James W Layland. 硬实时环境中的多程序调度算法。ACM期刊(JACM), 20(1):46–61,
    1973.'
- en: '[28] Edsger W Dijkstra. Cooperating sequential processes. In The origin of
    concurrent programming: from semaphores to remote procedure calls, pages 65–138\.
    Springer, 2002.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] Edsger W Dijkstra. 协作的顺序进程。在《并发编程的起源：从信号量到远程过程调用》，第65–138页。Springer, 2002年。'
- en: '[29] Peter J Denning. The working set model for program behavior. Communications
    of the ACM, 11(5):323–333, 1968.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Peter J Denning. 程序行为的工作集模型。ACM 通讯，11(5):323–333, 1968年。'
- en: '[30] Robert C Daley and Jack B Dennis. Virtual memory, processes, and sharing
    in multics. Communications of the ACM, 11(5):306–312, 1968.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Robert C Daley 和 Jack B Dennis. Multics 中的虚拟内存、进程和共享。ACM 通讯，11(5):306–312,
    1968年。'
- en: '[31] Mendel Rosenblum and John K Ousterhout. The design and implementation
    of a log-structured file system. ACM Transactions on Computer Systems (TOCS),
    10(1):26–52, 1992.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Mendel Rosenblum 和 John K Ousterhout. 日志结构文件系统的设计与实现。ACM 计算机系统学报（TOCS），10(1):26–52,
    1992年。'
- en: '[32] Marshall K McKusick, William N Joy, Samuel J Leffler, and Robert S Fabry.
    A fast file system for unix. ACM Transactions on Computer Systems (TOCS), 2(3):181–197,
    1984.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] Marshall K McKusick, William N Joy, Samuel J Leffler 和 Robert S Fabry.
    一个快速的 UNIX 文件系统。ACM 计算机系统学报（TOCS），2(3):181–197, 1984年。'
- en: '[33] Yingqiang Ge, Yujie Ren, Wenyue Hua, Shuyuan Xu, Juntao Tan, and Yongfeng
    Zhang. LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent
    Ecosystem. arXiv:2312.03815, 2023.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] Yingqiang Ge, Yujie Ren, Wenyue Hua, Shuyuan Xu, Juntao Tan 和 Yongfeng
    Zhang. LLM 作为操作系统，代理作为应用：设想 AIOS、代理和 AIOS-代理生态系统。arXiv:2312.03815, 2023年。'
- en: '[34] Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli,
    Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models
    can teach themselves to use tools. arXiv preprint arXiv:2302.04761, 2023.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli,
    Luke Zettlemoyer, Nicola Cancedda 和 Thomas Scialom. Toolformer：语言模型可以自学使用工具。arXiv
    预印本 arXiv:2302.04761, 2023年。'
- en: '[35] Shunyu Yao and Karthik Narasimhan. Language agents in the digital world:
    Opportunities and risks. princeton-nlp.github.io, Jul 2023.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] Shunyu Yao 和 Karthik Narasimhan. 数字世界中的语言代理：机遇与风险。princeton-nlp.github.io,
    2023年7月。'
- en: '[36] Aaron Parisi, Yao Zhao, and Noah Fiedel. Talm: Tool augmented language
    models. arXiv preprint arXiv:2205.12255, 2022.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] Aaron Parisi, Yao Zhao 和 Noah Fiedel. Talm：工具增强语言模型。arXiv 预印本 arXiv:2205.12255,
    2022年。'
- en: '[37] Qiaoyu Tang, Ziliang Deng, Hongyu Lin, Xianpei Han, Qiao Liang, and Le Sun.
    Toolalpaca: Generalized tool learning for language models with 3000 simulated
    cases. arXiv preprint arXiv:2306.05301, 2023.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] Qiaoyu Tang, Ziliang Deng, Hongyu Lin, Xianpei Han, Qiao Liang 和 Le Sun.
    Toolalpaca：针对语言模型的 3000 个模拟案例的广义工具学习。arXiv 预印本 arXiv:2306.05301, 2023年。'
- en: '[38] Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina
    Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang,
    Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin
    Chess, and John Schulman. Webgpt: Browser-assisted question-answering with human
    feedback, 2022.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina
    Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang,
    Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin
    Chess 和 John Schulman. Webgpt：浏览器辅助的问答系统与人类反馈，2022年。'
- en: '[39] Kechi Zhang, Ge Li, Jia Li, Zhuo Li, and Zhi Jin. Toolcoder: Teach code
    generation models to use apis with search tools. arXiv preprint arXiv:2305.04032,
    2023.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] Kechi Zhang, Ge Li, Jia Li, Zhuo Li 和 Zhi Jin. Toolcoder：教代码生成模型使用带搜索工具的
    API。arXiv 预印本 arXiv:2305.04032, 2023年。'
- en: '[40] Linxi Fan, Guanzhi Wang, Yunfan Jiang, Ajay Mandlekar, Yuncong Yang, Haoyi
    Zhu, Andrew Tang, De-An Huang, Yuke Zhu, and Anima Anandkumar. Minedojo: Building
    open-ended embodied agents with internet-scale knowledge. Advances in Neural Information
    Processing Systems, 35:18343–18362, 2022.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] Linxi Fan, Guanzhi Wang, Yunfan Jiang, Ajay Mandlekar, Yuncong Yang, Haoyi
    Zhu, Andrew Tang, De-An Huang, Yuke Zhu 和 Anima Anandkumar. Minedojo：构建具有互联网规模知识的开放式具身代理。神经信息处理系统进展，35:18343–18362,
    2022年。'
- en: '[41] Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke
    Zhu, Linxi Fan, and Anima Anandkumar. Voyager: An open-ended embodied agent with
    large language models. In Intrinsically-Motivated and Open-Ended Learning Workshop@
    NeurIPS2023, 2023.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke
    Zhu, Linxi Fan 和 Anima Anandkumar. Voyager：一个开放式的具身代理，结合大型语言模型。在 Intrinsically-Motivated
    and Open-Ended Learning Workshop@ NeurIPS2023, 2023年。'
- en: '[42] Daniil A Boiko, Robert MacKnight, and Gabe Gomes. Emergent autonomous
    scientific research capabilities of large language models. arXiv preprint arXiv:2304.05332,
    2023.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] Daniil A Boiko, Robert MacKnight 和 Gabe Gomes. 大型语言模型的自主科学研究能力的出现。arXiv
    预印本 arXiv:2304.05332, 2023年。'
- en: '[43] Andres M Bran, Sam Cox, Andrew D White, and Philippe Schwaller. Chemcrow:
    Augmenting large-language models with chemistry tools. arXiv preprint arXiv:2304.05376,
    2023.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] Andres M Bran, Sam Cox, Andrew D White 和 Philippe Schwaller. Chemcrow：用化学工具增强大型语言模型。arXiv
    预印本 arXiv:2304.05376，2023。'
- en: '[44] Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch. Language
    models as zero-shot planners: Extracting actionable knowledge for embodied agents.
    In International Conference on Machine Learning, pages 9118–9147\. PMLR, 2022.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] Wenlong Huang, Pieter Abbeel, Deepak Pathak 和 Igor Mordatch. 语言模型作为零样本规划者：为具身代理提取可操作知识。在国际机器学习会议上，第
    9118–9147 页。PMLR，2022。'
- en: '[45] Jiannan Xiang, Tianhua Tao, Yi Gu, Tianmin Shu, Zirui Wang, Zichao Yang,
    and Zhiting Hu. Language models meet world models: Embodied experiences enhance
    language models. Advances in neural information processing systems, 36, 2023.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] Jiannan Xiang, Tianhua Tao, Yi Gu, Tianmin Shu, Zirui Wang, Zichao Yang
    和 Zhiting Hu. 语言模型遇见世界模型：具身经验提升语言模型。神经信息处理系统进展，36，2023。'
- en: '[46] Guohao Li, Hasan Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard
    Ghanem. Camel: Communicative agents for "mind" exploration of large language model
    society. Advances in Neural Information Processing Systems, 36, 2023.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] Guohao Li, Hasan Hammoud, Hani Itani, Dmitrii Khizbullin 和 Bernard Ghanem.
    Camel：用于“大型语言模型社会”心理探索的沟通代理。神经信息处理系统进展，36，2023。'
- en: '[47] Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel Morris,
    Percy Liang, and Michael S Bernstein. Generative agents: Interactive simulacra
    of human behavior. In Proceedings of the 36th Annual ACM Symposium on User Interface
    Software and Technology, pages 1–22, 2023.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel Morris,
    Percy Liang 和 Michael S Bernstein. 生成代理：人类行为的交互式仿真体。在第 36 届 ACM 用户界面软件和技术年会论文集中，第
    1–22 页，2023。'
- en: '[48] Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng,
    Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, et al. Metagpt:
    Meta programming for multi-agent collaborative framework. In The Twelfth International
    Conference on Learning Representations, 2023.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng,
    Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin 等。Metagpt：用于多智能体协作框架的元编程。第十二届国际学习表征会议，2023。'
- en: '[49] Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan
    Liu, and Maosong Sun. Communicative agents for software development. arXiv preprint
    arXiv:2307.07924, 2023.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan
    Liu 和 Maosong Sun. 用于软件开发的沟通代理。arXiv 预印本 arXiv:2307.07924，2023。'
- en: '[50] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang
    Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. Autogen: Enabling next-gen
    llm applications via multi-agent conversation framework. arXiv preprint arXiv:2308.08155,
    2023.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang
    Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang 和 Chi Wang. Autogen：通过多智能体对话框架实现下一代 LLM
    应用。arXiv 预印本 arXiv:2308.08155，2023。'
- en: '[51] Martin Josifoski, Lars Klein, Maxime Peyrard, Yifei Li, Saibo Geng, Julian Paul
    Schnitzler, Yuxing Yao, Jiheng Wei, Debjit Paul, and Robert West. Flows: Building
    blocks of reasoning and collaborating ai. arXiv preprint arXiv:2308.01285, 2023.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] Martin Josifoski, Lars Klein, Maxime Peyrard, Yifei Li, Saibo Geng, Julian
    Paul Schnitzler, Yuxing Yao, Jiheng Wei, Debjit Paul 和 Robert West. Flows：推理和协作
    AI 的构建模块。arXiv 预印本 arXiv:2308.01285，2023。'
- en: '[52] Yao Fu, Hao Peng, Tushar Khot, and Mirella Lapata. Improving language
    model negotiation with self-play and in-context learning from ai feedback. arXiv
    preprint arXiv:2305.10142, 2023.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] Yao Fu, Hao Peng, Tushar Khot 和 Mirella Lapata. 通过自我对弈和从 AI 反馈中进行上下文学习来改进语言模型谈判。arXiv
    预印本 arXiv:2305.10142，2023。'
- en: '[53] Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch.
    Improving factuality and reasoning in language models through multiagent debate.
    arXiv preprint arXiv:2305.14325, 2023.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum 和 Igor Mordatch.
    通过多智能体辩论提高语言模型的真实性和推理能力。arXiv 预印本 arXiv:2305.14325，2023。'
- en: '[54] Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang
    Zhang, Jie Fu, and Zhiyuan Liu. Chateval: Towards better llm-based evaluators
    through multi-agent debate. In The Twelfth International Conference on Learning
    Representations, 2023.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang
    Zhang, Jie Fu 和 Zhiyuan Liu. Chateval：通过多智能体辩论提升基于 LLM 的评估器。第十二届国际学习表征会议，2023。'
- en: '[55] Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu
    Yang, Zhaopeng Tu, and Shuming Shi. Encouraging divergent thinking in large language
    models through multi-agent debate. arXiv preprint arXiv:2305.19118, 2023.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu
    Yang, Zhaopeng Tu, 和 Shuming Shi. 通过多智能体辩论鼓励大型语言模型中的发散思维。arXiv 预印本 arXiv:2305.19118,
    2023。'
- en: '[56] Wenyue Hua, Lizhou Fan, Lingyao Li, Kai Mei, Jianchao Ji, Yingqiang Ge,
    Libby Hemphill, and Yongfeng Zhang. War and peace (waragent): Large language model-based
    multi-agent simulation of world wars. arXiv preprint arXiv:2311.17227, 2023.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] Wenyue Hua, Lizhou Fan, Lingyao Li, Kai Mei, Jianchao Ji, Yingqiang Ge,
    Libby Hemphill, 和 Yongfeng Zhang. 战争与和平（waragent）：基于大型语言模型的世界大战多智能体模拟。arXiv 预印本
    arXiv:2311.17227, 2023。'
- en: '[57] Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford,
    Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel,
    Guillaume Lample, Lucile Saulnier, et al. Mistral 7b. arXiv preprint arXiv:2310.06825,
    2023.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford,
    Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel,
    Guillaume Lample, Lucile Saulnier 等. Mistral 7b。arXiv 预印本 arXiv:2310.06825, 2023。'
- en: '[58] Stella Biderman, Hailey Schoelkopf, Quentin Gregory Anthony, Herbie Bradley,
    Kyle O’Brien, Eric Hallahan, Mohammad Aflah Khan, Shivanshu Purohit, USVSN Sai
    Prashanth, Edward Raff, et al. Pythia: A suite for analyzing large language models
    across training and scaling. In International Conference on Machine Learning,
    pages 2397–2430\. PMLR, 2023.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] Stella Biderman, Hailey Schoelkopf, Quentin Gregory Anthony, Herbie Bradley,
    Kyle O’Brien, Eric Hallahan, Mohammad Aflah Khan, Shivanshu Purohit, USVSN Sai
    Prashanth, Edward Raff 等. Pythia：一个用于分析大型语言模型的训练和扩展的套件。国际机器学习会议, 页 2397–2430\.
    PMLR, 2023。'
- en: '[59] Shouyuan Chen, Sherman Wong, Liangjian Chen, and Yuandong Tian. Extending
    context window of large language models via positional interpolation. arXiv preprint
    arXiv:2306.15595, 2023.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] Shouyuan Chen, Sherman Wong, Liangjian Chen, 和 Yuandong Tian. 通过位置插值扩展大型语言模型的上下文窗口。arXiv
    预印本 arXiv:2306.15595, 2023。'
- en: '[60] Bowen Peng, Jeffrey Quesnelle, Honglu Fan, and Enrico Shippole. Yarn:
    Efficient context window extension of large language models. arXiv preprint arXiv:2309.00071,
    2023.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] Bowen Peng, Jeffrey Quesnelle, Honglu Fan, 和 Enrico Shippole. Yarn：大型语言模型的高效上下文窗口扩展。arXiv
    预印本 arXiv:2309.00071, 2023。'
- en: '[61] Grégoire Mialon, Roberto Dessi, Maria Lomeli, Christoforos Nalmpantis,
    Ramakanth Pasunuru, Roberta Raileanu, Baptiste Roziere, Timo Schick, Jane Dwivedi-Yu,
    Asli Celikyilmaz, et al. Augmented language models: a survey. Transactions on
    Machine Learning Research, 2023.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] Grégoire Mialon, Roberto Dessi, Maria Lomeli, Christoforos Nalmpantis,
    Ramakanth Pasunuru, Roberta Raileanu, Baptiste Roziere, Timo Schick, Jane Dwivedi-Yu,
    Asli Celikyilmaz 等. 增强语言模型：综述。机器学习研究交易, 2023。'
- en: '[62] LangChain. Langchain. [https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain),
    2024.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] LangChain. Langchain. [https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain),
    2024。'
- en: '[63] Rapid. Rapid api hub. [https://rapidapi.com/hub](https://rapidapi.com/hub),
    2024.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] Rapid. Rapid api hub. [https://rapidapi.com/hub](https://rapidapi.com/hub),
    2024。'
- en: '[64] Ken Thompson. Reflections on trusting trust. Communications of the ACM,
    27(8):761–763, 1984.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] Ken Thompson. 《信任的反思》。ACM 通讯, 27(8):761–763, 1984。'
- en: '[65] Sven Bugiel, Lucas Davi, Alexandra Dmitrienko, Thomas Fischer, Ahmad-Reza
    Sadeghi, and Bhargava Shastry. Towards taming privilege-escalation attacks on
    android. In NDSS, volume 17, page 19, 2012.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] Sven Bugiel, Lucas Davi, Alexandra Dmitrienko, Thomas Fischer, Ahmad-Reza
    Sadeghi, 和 Bhargava Shastry. 朝着驯服 Android 上特权提升攻击的方向迈进。收录于 NDSS, 第 17 卷，第 19 页,
    2012。'
- en: '[66] Tris Warkentin Jeanine Banks. Gemma: Introducing new state-of-the-art
    open models. [https://blog.google/technology/developers/gemma-open-models/](https://blog.google/technology/developers/gemma-open-models/),
    2024.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] Tris Warkentin Jeanine Banks. Gemma：介绍新的最先进开放模型。 [https://blog.google/technology/developers/gemma-open-models/](https://blog.google/technology/developers/gemma-open-models/),
    2024。'
- en: '[67] Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: a method
    for automatic evaluation of machine translation. In Proceedings of the 40th annual
    meeting of the Association for Computational Linguistics, pages 311–318, 2002.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] Kishore Papineni, Salim Roukos, Todd Ward, 和 Wei-Jing Zhu. Bleu：一种用于自动评估机器翻译的方法。第
    40 届计算语言学协会年会论文集, 页 311–318, 2002。'
- en: '[68] Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, and Yoav
    Artzi. Bertscore: Evaluating text generation with bert. arXiv preprint arXiv:1904.09675,
    2019.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, 和 Yoav Artzi.
    Bertscore：用 Bert 评估文本生成。arXiv 预印本 arXiv:1904.09675, 2019。'
