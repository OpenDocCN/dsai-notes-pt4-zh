- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 18:51:31'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:51:31
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Navigating Complexity: Orchestrated Problem Solving with Multi-Agent LLMs'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导航复杂性：使用多智能体LLMs的协同问题解决
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2402.16713](https://ar5iv.labs.arxiv.org/html/2402.16713)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2402.16713](https://ar5iv.labs.arxiv.org/html/2402.16713)
- en: Sumedh Rasal
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Sumedh Rasal
- en: Georgia Institute of Technology
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 乔治亚理工学院
- en: Chicago, IL
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 芝加哥，IL
- en: srasal3@gatech.edu
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: srasal3@gatech.edu
- en: \AndE. J. Hauer
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: \AndE. J. Hauer
- en: EJ@ThoughtCrafters.com
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: EJ@ThoughtCrafters.com
- en: Abstract
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Large Language Models (LLMs) have demonstrated remarkable capabilities in solving
    various tasks, yet they often struggle with comprehensively addressing complex
    and vague problems. Existing approaches, including multi-agent LLM systems, offer
    solutions to certain challenges but still require manual setup and lack scalability.
    To address this gap, we propose a novel approach leveraging decomposition to enable
    LLMs to tackle vague problems effectively.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）在解决各种任务方面表现出了卓越的能力，但它们在全面解决复杂和模糊问题时常常遇到困难。现有的方法，包括多智能体LLM系统，提供了一些挑战的解决方案，但仍然需要手动设置且缺乏可扩展性。为了填补这一空白，我们提出了一种利用分解的创新方法，使LLMs能够有效地解决模糊问题。
- en: Our approach involves an orchestrating LLM that interacts with users to understand
    the problem and then decomposes it into tangible sub-problems. Instead of expecting
    the LLM to solve the entire problem in one go, we train it to ask follow-up questions
    to gain a deeper understanding of the user’s requirements. Once the problem is
    adequately understood, the orchestrating LLM divides it into smaller, manageable
    sub-problems. Each sub-problem is then assigned to specialized LLM agents or non-LLM
    functions for resolution. These agents work in parallel to solve their respective
    sub-problems, with the orchestrating LLM overseeing the process and compiling
    the solutions into a comprehensive answer for the user. By adopting this decomposition
    approach, we alleviate the constraints imposed by token limitations on LLM outputs
    and empower them to provide nuanced solutions to complex and ambiguous problems.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的方法涉及一个协调LLM，它与用户互动以理解问题，然后将其分解成具体的子问题。我们并不期望LLM一次性解决整个问题，而是训练它提出后续问题，以深入了解用户的需求。一旦问题被充分理解，协调LLM会将其分解成较小、可管理的子问题。每个子问题随后被分配给专业LLM代理或非LLM功能进行解决。这些代理并行工作，以解决各自的子问题，协调LLM则监督整个过程，并将解决方案整合成一个全面的答案提供给用户。通过采用这种分解方法，我们缓解了LLM输出中的令牌限制所带来的约束，赋予它们提供对复杂和模糊问题的细致解决方案的能力。
- en: Through our approach, we aim to enable LLMs to think and operate more like humans,
    breaking down complex problems into manageable parts and collaboratively solving
    them. This not only enhances the problem-solving capabilities of LLMs but also
    offers a scalable and efficient method for addressing a wide range of real-world
    challenges.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 通过我们的方法，我们旨在使大型语言模型（LLMs）能够更像人类一样思考和操作，将复杂问题分解成可管理的部分并协作解决。这不仅增强了LLMs的解决问题能力，还提供了一种可扩展和高效的方法来应对广泛的现实世界挑战。
- en: '*K*eywords Decomposition  $\cdot$ Multi-Agents'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*关键词* 分解  $\cdot$ 多智能体'
- en: 1 Introduction
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: In recent years, the proliferation of Large Language Models (LLMs) has revolutionized
    problem-solving across various domains [[Devlin et al., 2018](#bib.bibx11)] [[Patil
    et al., 2023](#bib.bibx25)] [[Touvron et al., 2023](#bib.bibx32)]. These models
    possess the ability to comprehend user queries and generate responses, often providing
    novel insights and solutions [[Wei et al., 2022a](#bib.bibx33)]. Notably, LLMs
    exhibit exceptional performance in tasks that can be tackled through zero-shot
    or few-shot training techniques [[Brown et al., 2020](#bib.bibx2)], such as transforming
    questions into familiar formats or solving coding problems based on analogous
    examples [[Chen et al., 2021](#bib.bibx5)] [[Sanh et al., 2021](#bib.bibx29)].
    As such, they hold immense potential for automating numerous tasks and streamlining
    workflows across diverse professional domains [[Liu et al., 2023b](#bib.bibx22)]
    [[Chiang and Lee, 2023](#bib.bibx6)] [[Gao et al., 2023](#bib.bibx13)] [[Shen
    et al., 2023](#bib.bibx31)] [[Zheng et al., 2023](#bib.bibx37)].
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，大型语言模型（LLMs）的普及彻底改变了各个领域的问题解决方式[[Devlin et al., 2018](#bib.bibx11)] [[Patil
    et al., 2023](#bib.bibx25)] [[Touvron et al., 2023](#bib.bibx32)]。这些模型能够理解用户查询并生成回应，通常提供新颖的见解和解决方案[[Wei
    et al., 2022a](#bib.bibx33)]。特别是，LLMs在可以通过零-shot或少-shot训练技术解决的任务中表现出色[[Brown et
    al., 2020](#bib.bibx2)]，例如将问题转化为熟悉的格式或基于类比示例解决编码问题[[Chen et al., 2021](#bib.bibx5)]
    [[Sanh et al., 2021](#bib.bibx29)]。因此，它们在自动化众多任务和简化各类专业领域的工作流程方面具有巨大潜力[[Liu et
    al., 2023b](#bib.bibx22)] [[Chiang and Lee, 2023](#bib.bibx6)] [[Gao et al., 2023](#bib.bibx13)]
    [[Shen et al., 2023](#bib.bibx31)] [[Zheng et al., 2023](#bib.bibx37)]。
- en: However, despite their remarkable capabilities, LLMs are not immune to limitations.
    Instances of hallucination, contradictory responses, or misinterpretation of user
    queries highlight the challenges inherent in relying solely on these models for
    problem-solving [[Azamfirei et al., 2023](#bib.bibx1)]. Existing frameworks designed
    to aid users in systematically addressing novel problems are constrained by token
    limits imposed by LLM models [[Gur et al., 2023](#bib.bibx15)]. These limits restrict
    the number of words or tokens that an LLM can process in a single message or query,
    often hindering the comprehensiveness of responses and impeding the continuity
    of conversations. While approaches such as chaining previous conversations or
    employing semantic search techniques mitigate some of these challenges, they are
    susceptible to errors, including redundancy or irrelevance in retrieved information
    [[Ouyang et al., 2022](#bib.bibx24)] [[Saunders et al., 2022](#bib.bibx30)] [[Liu
    et al., 2023a](#bib.bibx21)].
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，尽管LLMs具备显著能力，但它们并非没有局限。幻觉、矛盾的回应或对用户查询的误解都突显了单独依赖这些模型进行问题解决的挑战[[Azamfirei
    et al., 2023](#bib.bibx1)]。现有旨在帮助用户系统性地解决新问题的框架受到LLM模型所施加的令牌限制的制约[[Gur et al.,
    2023](#bib.bibx15)]。这些限制限制了LLM在单个消息或查询中可以处理的单词或令牌的数量，通常妨碍回应的全面性并阻碍对话的连续性。虽然如链式对话或采用语义搜索技术等方法能缓解部分这些挑战，但它们也容易出现错误，包括检索信息中的冗余或不相关性[[Ouyang
    et al., 2022](#bib.bibx24)] [[Saunders et al., 2022](#bib.bibx30)] [[Liu et al.,
    2023a](#bib.bibx21)]。
- en: To address these limitations, a promising avenue lies in leveraging multi-agent
    frameworks to tackle lengthy or complex problems [[Du et al., 2023](#bib.bibx12)]
    [[Cohen et al., 2023](#bib.bibx8)] [[Dafoe et al., 2021](#bib.bibx9)] [[Dafoe
    et al., 2020](#bib.bibx10)] [[Kramár et al., 2022](#bib.bibx16)] [[Yao et al.,
    2022](#bib.bibx36)]. Such frameworks distribute problem-solving tasks among multiple
    LLM agents, offering a more robust approach compared to heuristic methods [[Li
    et al., 2023](#bib.bibx19)] [[Liang et al., 2023](#bib.bibx20)] [[Qian et al.,
    2023](#bib.bibx26)] [[Lazaridou et al., 2020](#bib.bibx17)] [[Graesser et al.,
    2020](#bib.bibx14)] [[Lee et al., 2018](#bib.bibx18)] [[Wu et al., 2023](#bib.bibx35)].
    However, the manual assignment of personas or roles to each LLM agent presents
    a bottleneck, particularly when dealing with novel problems lacking predefined
    roles [[Rasal, 2024](#bib.bibx28)].
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些局限性，一个有前途的方向是利用多代理框架来处理冗长或复杂的问题[[Du et al., 2023](#bib.bibx12)] [[Cohen
    et al., 2023](#bib.bibx8)] [[Dafoe et al., 2021](#bib.bibx9)] [[Dafoe et al.,
    2020](#bib.bibx10)] [[Kramár et al., 2022](#bib.bibx16)] [[Yao et al., 2022](#bib.bibx36)]。这种框架将问题解决任务分配给多个LLM代理，与启发式方法相比，提供了更为强健的方法[[Li
    et al., 2023](#bib.bibx19)] [[Liang et al., 2023](#bib.bibx20)] [[Qian et al.,
    2023](#bib.bibx26)] [[Lazaridou et al., 2020](#bib.bibx17)] [[Graesser et al.,
    2020](#bib.bibx14)] [[Lee et al., 2018](#bib.bibx18)] [[Wu et al., 2023](#bib.bibx35)]。然而，给每个LLM代理分配角色或任务的手动方式成为了瓶颈，尤其是在处理缺乏预定义角色的新问题时[[Rasal,
    2024](#bib.bibx28)]。
- en: In this paper, we propose a novel solution that integrates the strengths of
    existing approaches while addressing their limitations. Our approach centers on
    an orchestration strategy that employs problem decomposition to facilitate the
    seamless resolution of lengthy or complex problems. Inspired by human problem-solving
    approaches, our framework involves an orchestration LLM that engages in iterative
    conversations with users to ascertain problem requirements. Once the requirements
    are elucidated, the orchestration LLM decomposes the problem into manageable subproblems
    and assigns them to specialized agents, each tailored to address specific aspects
    of the problem. Notably, our approach incorporates non-LLM functionalities where
    necessary, enhancing robustness and adaptability to real-world tasks [[Qin et al.,
    2023](#bib.bibx27)]. By leveraging problem decomposition and distributed task
    assignment, our framework offers a comprehensive and scalable solution for problem-solving
    with LLMs.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们提出了一种新颖的解决方案，它结合了现有方法的优点，同时解决了它们的局限性。我们的方法集中于一个协调策略，该策略利用问题分解来促进对冗长或复杂问题的无缝解决。受人类问题解决方法的启发，我们的框架涉及一个协调LLM，该LLM与用户进行迭代对话以确定问题要求。一旦需求阐明，协调LLM将问题分解为可管理的子问题，并将其分配给专业化的代理，每个代理都针对问题的特定方面量身定制。值得注意的是，我们的方法在必要时还结合了非LLM功能，提高了对现实世界任务的鲁棒性和适应性
    [[Qin et al., 2023](#bib.bibx27)]。通过利用问题分解和分布式任务分配，我们的框架提供了一个全面且可扩展的解决方案，用于与LLM一起解决问题。
- en: 'This is what we propose:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们提出的：
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Our proposed solution integrates problem decomposition and multi-agent orchestration,
    inspired by human problem-solving approaches, to address the limitations of existing
    frameworks.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出的解决方案结合了问题分解和多代理协调，灵感来源于人类的问题解决方法，以应对现有框架的局限性。
- en: •
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: By leveraging problem decomposition and distributed task assignment, our framework
    offers a comprehensive and scalable solution for problem-solving with LLMs, enhancing
    adaptability to real-world tasks.
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过利用问题分解和分布式任务分配，我们的框架提供了一个全面且可扩展的解决方案，用于与LLM一起解决问题，提高对现实世界任务的适应性。
- en: 2 Methodology
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 方法论
- en: In response to these challenges, our methodology adopts a novel approach that
    seeks to address the token limit issue through algorithmic enhancements rather
    than relying solely on memory expansion. At the core of our methodology lies the
    development of an Orchestration LLM, tasked with the responsibility of comprehending
    user problem statements, decomposing them into manageable subproblems, and orchestrating
    interactions among specialized LLM agents.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 针对这些挑战，我们的方法论采用了一种新颖的方式，试图通过算法增强来解决令牌限制问题，而不仅仅依赖于内存扩展。我们的方法论的核心是开发一个协调LLM，负责理解用户问题陈述，将其分解为可管理的子问题，并协调各专业LLM代理之间的互动。
- en: Inspired by human problem-solving strategies, our methodology mirrors the process
    of breaking down complex tasks into smaller, more digestible components. We employ
    advanced natural language processing (NLP) techniques to analyze and dissect complex
    queries, identifying distinct subproblems across various domains. These subproblems
    are then mapped to specialized LLM agents, each pre-trained on specific tasks
    such as data analysis, creative writing, or technical problem-solving, to ensure
    precision and relevance in their responses.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 受人类问题解决策略的启发，我们的方法论模拟了将复杂任务分解为更小、更易处理的组件的过程。我们采用先进的自然语言处理（NLP）技术来分析和解剖复杂的查询，识别出不同领域的子问题。这些子问题随后被映射到专业化的LLM代理，每个代理都经过特定任务的预训练，如数据分析、创意写作或技术问题解决，以确保其响应的精确性和相关性。
- en: Analogous to seeking expertise in real-life scenarios, our methodology leverages
    collaboration with domain experts to optimize problem-solving outcomes. For instance,
    just as individuals seek tax experts for efficient tax filing, our approach integrates
    specialized agents to tackle domain-specific challenges effectively.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于在现实生活中寻求专业知识，我们的方法论利用与领域专家的合作来优化问题解决的结果。例如，就像个人寻找税务专家以高效报税一样，我们的方法将专业化的代理整合进来，以有效应对领域特定的挑战。
- en: Furthermore, we develop an algorithmic framework that enables the Orchestration
    LLM to decompose complex problems based on predefined criteria such as problem
    domain, required expertise, and task complexity. Finally, we implement a task
    assignment system to allocate subproblems among selected specialized agents, considering
    factors such as availability, expertise, and workload to streamline the problem-solving
    process and optimize resource utilization.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们开发了一个算法框架，使 Orchestration LLM 能够根据预定义的标准（如问题领域、所需专业知识和任务复杂性）对复杂问题进行分解。
    最后，我们实施了任务分配系统，以在所选的专业代理之间分配子问题，考虑到可用性、专业知识和工作负载等因素，以简化问题解决过程并优化资源利用。
- en: 'The high-level algorithm to our framework can be found [1](#alg1 "Algorithm
    1 ‣ 2 Methodology ‣ Navigating Complexity: Orchestrated Problem Solving with Multi-Agent
    LLMs")'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们框架的高级算法可以在 [1](#alg1 "算法 1 ‣ 2 方法论 ‣ 导航复杂性：使用多代理 LLMs 进行编排问题解决") 中找到
- en: Algorithm 1 Orchestration of Problem Solving with LLMs
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 1 使用 LLMs 进行问题解决的编排
- en: 0:  A complex problem statement0:  A comprehensive solution to the problem1:  Begin2:  Input
    the complex problem statement3:  Decompose the problem into subproblems4:  for each
    subproblem do5:     Select a specialized LLM agent based on the subproblem’s domain
    and requirements6:     Assign the subproblem to the selected agent7:     Agent
    solves the subproblem and stores the solution8:  end for9:  Aggregate the solutions
    of subproblems into a coherent overall solution10:  Output the comprehensive solution11:  End
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '0:  复杂问题陈述0:  问题的全面解决方案1:  开始2:  输入复杂问题陈述3:  将问题分解为子问题4:  对于每个子问题5:     根据子问题的领域和需求选择一个专业的
    LLM 代理6:     将子问题分配给选定的代理7:     代理解决子问题并存储解决方案8:  结束循环9:  将子问题的解决方案汇总成一致的整体解决方案10:  输出全面解决方案11:  结束'
- en: 2.1 Decomposition Approach
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 分解方法
- en: The implementation of our framework initiates with the user’s submission of
    a complex problem statement, facilitated through a conversational interface within
    the LangChain framework [[Chase, 2022](#bib.bibx4)]. Within the Orchestration
    LLM, this input undergoes meticulous processing, wherein key information and requirements
    are extracted and analyzed with precision. Subsequently, the Orchestration LLM
    seamlessly applies a sophisticated decomposition algorithm, systematically breaking
    down the problem into manageable subproblems, thereby ensuring clarity and precision
    throughout the process.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的框架的实现从用户提交复杂问题陈述开始，通过 LangChain 框架中的对话界面进行。 在 Orchestration LLM 中，这些输入经过细致处理，关键的信息和需求被精确提取和分析。
    随后，Orchestration LLM 无缝地应用复杂的分解算法，将问题系统地分解为可管理的子问题，从而确保整个过程的清晰和准确。
- en: The decomposition approach was crafted through a series of few-shot training
    iterations employing the GPT4 model [[OpenAI, 2023](#bib.bibx23)] [[Bubeck et al.,
    2023](#bib.bibx3)]. Initially, the LLM model decomposed the main problem into
    vague subproblems, which necessitated further refinement to ensure alignment with
    the expected decomposition format. Utilizing few-shot training, we provided the
    model with chain-of-thought type reasoning to guide its decomposition process
    effectively.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 分解方法是通过一系列少量训练迭代使用 GPT4 模型制定的。最初，LLM 模型将主要问题分解为模糊的子问题，这需要进一步细化以确保与预期的分解格式对齐。
    利用少量训练，我们为模型提供了链式思维类型的推理，以有效指导其分解过程。
- en: Upon successful decomposition, the Orchestration LLM assumes the pivotal role
    of assigning these subproblems to the most suitable specialized LLM agents. This
    assignment process is meticulously orchestrated to ensure that each subproblem
    is delegated to an agent possessing the requisite expertise and capabilities to
    effectively address it.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在成功分解后，Orchestration LLM 扮演了将这些子问题分配给最合适的专业 LLM 代理的关键角色。 这一分配过程被精心编排，以确保每个子问题都分配给具有必要专业知识和能力的代理，以有效解决问题。
- en: Central to the framework’s efficacy is the decomposition phase, which serves
    as its cornerstone. We deliberately crafted the initial design to be adaptable
    and generalizable across diverse problem domains, prioritizing the demonstration
    of decomposition capabilities over specialized use-case system development.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 框架有效性的核心是分解阶段，它作为其基石。 我们故意将初始设计制作得具有适应性和普遍适用性，优先展示分解能力，而不是专注于特定用例系统的开发。
- en: 3 Experiments
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 实验
- en: Our experiments center around the utilization of an orchestration LLM agent,
    employing OpenAI’s gpt-4 model [[OpenAI, 2023](#bib.bibx23)], which adeptly engages
    with users to elucidate requirements and subsequently decomposes problems into
    manageable subproblems. This orchestration LLM also determines the most suitable
    specialized LLM agent to address each subproblem. Each specialized LLM agent employed
    in our experiments is based on OpenAI’s gpt3.5-turbo model, configured with a
    temperature parameter set to 0.0, reflecting the balance between coherence and
    creativity in responses. Facilitating communication among LLM agents is the LangChain
    framework, enabling seamless multi-agent interaction and facilitating focus on
    problem-solving.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实验围绕着使用协调 LLM 代理，运用 OpenAI 的 gpt-4 模型 [[OpenAI, 2023](#bib.bibx23)]，该模型巧妙地与用户互动，以阐明需求，并随后将问题分解为可管理的子问题。这个协调
    LLM 还确定最适合解决每个子问题的专业 LLM 代理。我们实验中使用的每个专业 LLM 代理都基于 OpenAI 的 gpt3.5-turbo 模型，温度参数设置为
    0.0，反映了响应中的连贯性与创造性之间的平衡。促进 LLM 代理之间的沟通的是 LangChain 框架，允许无缝的多代理互动，并有助于专注于问题解决。
- en: '3.1 Experiment 1: Travel Planning with LLM Agents'
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 实验 1：使用 LLM 代理进行旅行规划
- en: In this experiment, users present their travel plans to the framework, initiating
    a dialogue with the orchestration LLM to refine requirements and subsequently
    decompose the problem into subproblems. The orchestration LLM allocates tasks
    to specialized agents, which upon completion, contribute their findings for collation
    into a final course of action. Before execution, the orchestration LLM verifies
    details with the user to ensure accuracy.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实验中，用户将旅行计划提交给框架，启动与协调 LLM 的对话，以精炼需求，并随后将问题分解为子问题。协调 LLM 将任务分配给专业代理，这些代理在完成任务后，将其结果提供以进行最终汇总。在执行前，协调
    LLM 会与用户核实细节以确保准确性。
- en: Here’s the conversational output of the framework.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这是框架的对话输出。
- en: 'Initial Interaction: Gathering Requirements'
  id: totrans-45
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 初步互动：收集需求
- en: ''
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'User: I need to book a return flight from Chicago Airport to Newark Airport
    from 3/22/24 to 3/26/24\. I want to fly in luxury and travel between the hours
    of 10 am and 4 pm.'
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 用户：我需要从芝加哥机场到纽瓦克机场的往返航班，从 3/22/24 到 3/26/24。我想要豪华旅行，出发时间在上午 10 点至下午 4 点之间。
- en: ''
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Orchestration LLM Agent: Got it. To ensure I find the best options for you,
    could you specify your preferences for seating class and any additional services
    you might require during your flight?'
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 协调 LLM 代理：明白了。为了确保找到最佳选项，您能否具体说明您对座位等级和机上服务的偏好？
- en: ''
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'User: I prefer business class and would like access to in-flight Wi-Fi and
    a window seat.'
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 用户：我偏好商务舱，并希望能够使用机上 Wi-Fi 和窗座。
- en: ''
  id: totrans-52
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Orchestration LLM Agent Decomposes the Problem
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 协调 LLM 代理分解问题
- en: ''
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The Orchestration LLM Agent processes the user’s request and decomposes it
    into subproblems to be handled by specialized agents:'
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 协调 LLM 代理处理用户的请求并将其分解为由专业代理处理的子问题：
- en: ''
  id: totrans-56
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Flight Search Agent: Find business class flights from Chicago to Newark that
    depart between 10 am and 4 pm on 3/22/24 and return flights on 3/26/24.'
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 航班搜索代理：找到从芝加哥到纽瓦克的商务舱航班，出发时间在 3/22/24 的上午 10 点至下午 4 点之间，回程航班在 3/26/24。
- en: ''
  id: totrans-58
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Amenity Preferences Agent: Identify airlines offering in-flight Wi-Fi and window
    seat availability in business class.'
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 设施偏好代理：识别提供机上 Wi-Fi 和商务舱窗座的航空公司。
- en: ''
  id: totrans-60
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Booking Agent: Handle the booking process once the flight options are selected.'
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 预订代理：在选择航班选项后处理预订过程。
- en: ''
  id: totrans-62
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Interaction with Specialized Agents
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 与专业代理的互动
- en: ''
  id: totrans-64
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Orchestration LLM Agent to Flight Search Agent: Find business class flights
    from Chicago to Newark departing between 10 am and 4 pm on 3/22/24 and returning
    on 3/26/24.'
  id: totrans-65
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 协调 LLM 代理对航班搜索代理：找到从芝加哥到纽瓦克的商务舱航班，出发时间在 3/22/24 的上午 10 点至下午 4 点之间，回程时间在 3/26/24。
- en: ''
  id: totrans-66
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Flight Search Agent: Found several options.'
  id: totrans-67
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 航班搜索代理：找到几个选项。
- en: ''
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Orchestration LLM Agent to Amenity Preferences Agent: Which of these options
    offers in-flight Wi-Fi and window seats in business class?'
  id: totrans-69
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 协调 LLM 代理对设施偏好代理：这些选项中哪一项提供机上 Wi-Fi 和商务舱窗座？
- en: ''
  id: totrans-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Amenity Preferences Agent: [Lists airlines that meet the criteria] Finalizing
    the Option'
  id: totrans-71
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 设施偏好代理：[列出符合标准的航空公司] 确定选项
- en: ''
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Orchestration LLM Agent to User: Based on your preferences, here are the best
    flight options that offer business class, in-flight Wi-Fi, and window seats. [Presents
    options]'
  id: totrans-73
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 协调 LLM 代理对用户：根据您的偏好，这里是提供商务舱、机上 Wi-Fi 和窗座的最佳航班选项。[展示选项]
- en: ''
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'User: I’ll take the option with Airline X on the 3/22 at 2 pm.'
  id: totrans-75
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 用户：我选择 Airline X 的 3/22 下午 2 点的选项。
- en: ''
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Orchestration LLM Agent to Booking Agent: Please book the flight with Airline
    X for 3/22, departing at 2 pm in business class, with a window seat and in-flight
    Wi-Fi.'
  id: totrans-77
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 协调 LLM 代理到预订代理：请为 3/22 预订 Airline X 的航班，出发时间为下午 2 点，商务舱，靠窗座位，并提供机上 Wi-Fi。
- en: ''
  id: totrans-78
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Booking Agent: Your flight is booked. Here are your confirmation details.'
  id: totrans-79
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 预订代理：您的航班已预订。以下是确认详情。
- en: '3.2 Experiment 2: Exploratory Research and Summarization'
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 实验 2：探索性研究与总结
- en: Users pose exploratory research queries to the framework, prompting the orchestration
    LLM to segment the problem into subproblems and assign tasks to specialized agents.
    Following the completion of tasks, the specialized agents provide their outputs,
    which are synthesized by the orchestration LLM into a comprehensive summary. Feedback
    from the user is sought to refine the final output as necessary.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 用户向框架提出探索性研究查询，促使协调 LLM 将问题分解为子问题并分配任务给专业代理。任务完成后，专业代理提供输出，这些输出由协调 LLM 综合成一个全面的总结。用户反馈被用于根据需要优化最终输出。
- en: Here’s the conversational output of the framework.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这是框架的对话输出。
- en: 'Initial Interaction: Gathering Requirements'
  id: totrans-83
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 初始互动：收集需求
- en: ''
  id: totrans-84
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'User: I need to research topics about long-term memory management in LLMs,
    focusing on what’s currently possible and what’s not. Then, I’d like a 5-page
    article summarizing these findings and suggesting future research directions.'
  id: totrans-85
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 用户：我需要研究关于 LLM 中长期记忆管理的主题，关注当前可能的内容和尚未解决的问题。然后，我需要一篇 5 页的文章总结这些发现并提出未来研究方向。
- en: ''
  id: totrans-86
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Orchestration LLM Agent Decomposes the Problem
  id: totrans-87
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 协调 LLM 代理将问题分解
- en: ''
  id: totrans-88
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The Orchestration LLM Agent analyzes the request and identifies several key
    tasks:'
  id: totrans-89
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 协调 LLM 代理分析请求并识别出几个关键任务：
- en: ''
  id: totrans-90
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Literature Review Agent: Conduct a comprehensive review of existing research
    on long-term memory management in LLMs.'
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 文献综述代理：对 LLM 中长期记忆管理的现有研究进行全面评审。
- en: ''
  id: totrans-92
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Analysis Agent: Analyze the collected research to distinguish between solved
    problems, ongoing challenges, and unexplored areas.'
  id: totrans-93
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 分析代理：分析收集的研究，以区分已解决的问题、持续的挑战和未探索的领域。
- en: ''
  id: totrans-94
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Writing Agent: Synthesize the findings into a coherent 5-page article, highlighting
    current capabilities, and limitations, and suggesting future research directions.'
  id: totrans-95
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 写作代理：将发现综合成一篇连贯的 5 页文章，突出当前能力和局限性，并提出未来研究方向。
- en: ''
  id: totrans-96
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Interaction with Specialized Agents
  id: totrans-97
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 与专业代理的互动
- en: ''
  id: totrans-98
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Task 1: Conduct Literature Review'
  id: totrans-99
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 任务 1：进行文献综述
- en: ''
  id: totrans-100
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Orchestration LLM Agent to Literature Review Agent: Identify and summarize
    key research articles on long-term memory management in LLMs, focusing on methodologies,
    findings, and limitations.'
  id: totrans-101
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 协调 LLM 代理到文献综述代理：识别并总结关于 LLM 中长期记忆管理的关键研究文章，重点关注方法论、发现和局限性。
- en: ''
  id: totrans-102
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Literature Review Agent: [Returns a summary of articles, including key methodologies,
    findings, challenges, and limitations related to long-term memory management.]'
  id: totrans-103
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 文献综述代理：[返回文章摘要，包括与长期记忆管理相关的关键方法论、发现、挑战和局限性。]
- en: ''
  id: totrans-104
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Task 2: Analyze Research'
  id: totrans-105
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 任务 2：分析研究
- en: ''
  id: totrans-106
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Orchestration LLM Agent to Analysis Agent: Based on the literature review,
    analyze the current state of long-term memory management in LLMs, identifying
    what is possible, what remains challenging, and potential areas for future research.'
  id: totrans-107
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 协调 LLM 代理到分析代理：根据文献综述，分析 LLM 中长期记忆管理的现状，识别可能的内容、挑战以及未来研究的潜在领域。
- en: ''
  id: totrans-108
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Analysis Agent: [Provides an analysis distinguishing between the current capabilities
    and limitations of long-term memory management in LLMs, along with suggestions
    for future research directions.]'
  id: totrans-109
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 分析代理：[提供分析，区分 LLM 中长期记忆管理的当前能力和局限性，并提出未来研究方向的建议。]
- en: ''
  id: totrans-110
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Task 3: Write Article'
  id: totrans-111
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 任务 3：撰写文章
- en: ''
  id: totrans-112
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Orchestration LLM Agent to Writing Agent: Using the information collected and
    analyzed, write a 5-page article summarizing the findings on long-term memory
    management in LLMs. Highlight what is currently possible, and the limitations,
    and suggest ideas for future research.'
  id: totrans-113
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 协调 LLM 代理到写作代理：使用收集和分析的信息，撰写一篇 5 页的文章，总结 LLM 中长期记忆管理的发现。突出当前的可能性、局限性，并提出未来研究的想法。
- en: ''
  id: totrans-114
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Writing Agent: [Drafts a 5-page article that summarizes the state of long-term
    memory management in LLMs, including an overview of existing research, current
    limitations, and proposed future directions.]'
  id: totrans-115
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 写作代理：[撰写一篇5页的文章，总结LLMs中的长期记忆管理状态，包括现有研究概述、当前局限性和提出的未来方向。]
- en: ''
  id: totrans-116
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Finalizing the Article
  id: totrans-117
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 完成文章
- en: ''
  id: totrans-118
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Orchestration LLM Agent to User: Based on the comprehensive research and analysis
    conducted by specialized agents, we have compiled a 5-page article summarizing
    the current state of long-term memory management in LLMs. The article discusses
    what is currently possible, outlines the main challenges and limitations, and
    suggests potential areas for future research.'
  id: totrans-119
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 协调LLM代理到用户：基于专门代理进行的全面研究和分析，我们编写了一篇5页的文章，总结了LLMs中长期记忆管理的当前状态。文章讨论了目前的可能性，概述了主要挑战和局限性，并建议了未来研究的潜在领域。
- en: ''
  id: totrans-120
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'User: Reviews the article and provides feedback or requests revisions if necessary.'
  id: totrans-121
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 用户：审阅文章并提供反馈或如有必要请求修订。
- en: 4 Results
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 结果
- en: 'Rather than relying solely on conventional datasets typically utilized in research,
    we opted to assess the efficacy of our framework using the GSM8K dataset, chosen
    to specifically demonstrate the capabilities of our approach. We employed four
    distinct types of agents in our experimentation: a single LLM agent powered by
    the GPT3.5-turbo model, two LLM agents supported by GPT3.5-turbo models, two LLM
    agents utilizing the GPT3.5-turbo model combined with the chain-of-thought and
    persona approach [[Wei et al., 2022b](#bib.bibx34)] [[Rasal, 2024](#bib.bibx28)],
    and finally, two LLM agents operating with the GPT4 model [[OpenAI, 2023](#bib.bibx23)]
    for orchestration and decomposition methodology and GPT3.5-turbo model for the
    specialized LLM agents, which involves breaking down the primary problem into
    subproblems. Our orchestration framework represents a notable advancement over
    existing methodologies, with detailed results presented in Table [1](#S4.T1 "Table
    1 ‣ 4 Results ‣ Navigating Complexity: Orchestrated Problem Solving with Multi-Agent
    LLMs").'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '我们选择使用GSM8K数据集来评估我们框架的有效性，而不是仅依赖于通常在研究中使用的传统数据集，目的是特别展示我们方法的能力。我们在实验中使用了四种不同类型的代理：一个由GPT3.5-turbo模型驱动的单一LLM代理、两个由GPT3.5-turbo模型支持的LLM代理、两个结合了链式思维和角色扮演方法的GPT3.5-turbo模型的LLM代理[[Wei
    et al., 2022b](#bib.bibx34)] [[Rasal, 2024](#bib.bibx28)]，以及两个使用GPT4模型[[OpenAI,
    2023](#bib.bibx23)]的LLM代理，用于协调和分解方法，GPT3.5-turbo模型用于专门的LLM代理，涉及将主要问题分解为子问题。我们的协调框架代表了现有方法的一项显著进步，详细结果见表[1](#S4.T1
    "Table 1 ‣ 4 Results ‣ Navigating Complexity: Orchestrated Problem Solving with
    Multi-Agent LLMs")。'
- en: '"GSM8K consists of 8.5K high-quality grade school math problems created by
    human problem writers. We segmented these into 7.5K training problems and 1K test
    problems. These problems take between 2 and 8 steps to solve, and solutions primarily
    involve performing a sequence of elementary calculations using basic arithmetic
    operations (+ - / *) to reach the final answer. A bright middle school student
    should be able to solve every problem."[[Cobbe et al., 2021](#bib.bibx7)]'
  id: totrans-124
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '"GSM8K由人类问题编写者创建的8.5K高质量小学数学问题组成。我们将这些问题分为7.5K训练问题和1K测试问题。这些问题的解决步骤在2到8步之间，解决方案主要涉及使用基本算术运算（+
    - / *）进行一系列初等计算，以得到最终答案。一个聪明的中学生应该能够解决每个问题。"[[Cobbe et al., 2021](#bib.bibx7)]'
- en: Furthermore, our observations indicated a significant enhancement in accuracy
    when employing a calculator function as opposed to a math-specialized LLM agent.
    This improvement stems from the inherent limitations of LLMs in executing mathematical
    operations, despite their versatility across various domains. We contend that
    rather than training LLMs for math operations, our framework facilitates the orchestration
    LLM in discerning whether a subproblem necessitates an LLM agent or an alternative
    non-LLM approach.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们的观察表明，使用计算器功能时准确性显著提高，相比于数学专用的LLM代理。这种改进源于LLM在执行数学运算方面的固有限制，尽管它们在各种领域中表现出色。我们认为，与其训练LLM进行数学运算，不如让我们的框架帮助协调LLM，以判断子问题是否需要LLM代理或其他非LLM方法。
- en: 'Table 1: GSM8K Data set Evaluation'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：GSM8K数据集评估
- en: '| Agent | Solve Rate |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 代理 | 解题率 |'
- en: '| --- | --- |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Single GPT3.5-turbo | 50% |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 单一GPT3.5-turbo | 50% |'
- en: '| Multi-Agent GPT3.5-turbo | 55% |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 多代理GPT3.5-turbo | 55% |'
- en: '| Multi-Agent GPT3.5-turbo (LLM-Harmony) | 65% |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 多代理GPT3.5-turbo (LLM-Harmony) | 65% |'
- en: '| Multi-Agent GPT4 (Our Approach) | 73% |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 多代理GPT4（我们的方法） | 73% |'
- en: 5 Limitations
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 限制
- en: While our decomposition framework represents a significant advancement, it possesses
    inherent limitations that warrant consideration. Foremost among these limitations
    is the framework’s lack of generalization to address all conceivable problem scenarios,
    both novel and otherwise. We recognize the necessity of further training the orchestration
    model, essentially serving as a foundational Large Language Model (LLM), to acquire
    a comprehensive understanding of diverse problem-solving approaches. Presently,
    the model exhibits proficiency in decomposing various problems, yet its scope
    may not extend to accommodate the complexities of future challenges.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们的分解框架代表了重要的进步，但它也具有固有的局限性，值得考虑。其中最主要的限制是框架缺乏对所有可能问题情境的泛化能力，无论是新颖的还是其他的。我们认识到进一步训练协调模型的必要性，该模型本质上作为基础的大型语言模型（LLM），以获得对多样问题解决方法的全面理解。目前，该模型在分解各种问题方面表现出色，但其范围可能无法涵盖未来挑战的复杂性。
- en: For instance, consider a user’s request for transportation. While the current
    model adeptly decomposes the problem into a specialized agent capable of booking
    a ride, scenarios may arise where multiple specialized agents possess this capability.
    In such instances, the orchestration LLM faces the challenge of determining the
    most appropriate course of action. Additionally, the framework lacks a mechanism
    to assimilate information about new specialized agents, highlighting the need
    for a retraining mechanism to continually update the orchestration LLM’s knowledge
    base.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑用户对交通的请求。虽然当前模型能够熟练地将问题分解为一个能够预约交通的专门代理，但可能出现多个人工智能代理具备这种能力的情况。在这种情况下，协调
    LLM 面临确定最合适行动方案的挑战。此外，该框架缺乏吸收新专门代理信息的机制，突显了需要一个重新训练机制来持续更新协调 LLM 的知识库。
- en: Furthermore, while the current model effectively decomposes problems, it lacks
    the capability to iteratively learn and refine its problem-solving strategies
    based on the outcomes of decomposition steps. Addressing this limitation represents
    a key focus of our future research endeavors. Nonetheless, the primary objective
    of this paper is to disseminate our decomposition approach to the readership,
    offering insights into its application in problem-solving contexts.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，虽然当前模型有效地分解了问题，但缺乏基于分解步骤结果的迭代学习和改进其问题解决策略的能力。解决这一限制是我们未来研究工作的重点之一。尽管如此，本文的主要目的是向读者传播我们的分解方法，提供其在问题解决情境中的应用见解。
- en: 6 Conclusion
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: In conclusion, our paper introduces a novel approach to problem-solving using
    a decomposition framework orchestrated by Large Language Models (LLMs). Through
    meticulous decomposition of complex problem statements into manageable subproblems,
    our framework demonstrates the potential to streamline problem-solving processes
    and mitigate the limitations inherent in current LLM-based solutions. By leveraging
    the inherent capabilities of LLMs to understand user queries and decompose problems,
    our approach offers a promising avenue for addressing a wide range of challenges
    across various domains.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，本文介绍了一种使用大型语言模型（LLMs）协调的分解框架来解决问题的新方法。通过将复杂的问题陈述细致地分解为可管理的子问题，我们的框架展示了简化问题解决过程和缓解当前基于
    LLM 解决方案固有局限性的潜力。通过利用 LLM 本身理解用户查询和分解问题的能力，我们的方法为解决各种领域的广泛挑战提供了一个有前景的途径。
- en: Our implementation of the framework highlights its efficacy in breaking down
    intricate problem statements and assigning tasks to specialized LLM agents, resulting
    in coherent and comprehensive solutions. Moreover, our experiments underscore
    the versatility of the framework in facilitating tasks such as travel planning
    and research summary generation, showcasing its applicability in real-world scenarios.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对框架的实施凸显了其在分解复杂问题陈述并将任务分配给专门 LLM 代理方面的有效性，从而产生连贯且全面的解决方案。此外，我们的实验强调了框架在处理如旅行规划和研究总结生成等任务方面的多功能性，展示了其在现实场景中的适用性。
- en: However, our work also reveals several limitations that necessitate further
    research and development. While the decomposition framework represents a significant
    advancement, its generalization to novel problem scenarios remains an ongoing
    challenge. Additionally, the framework lacks mechanisms for adaptive learning
    and integration of new specialized agents, indicating avenues for future improvement.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们的工作也揭示了若干限制，需要进一步的研究和开发。尽管分解框架代表了一个重要的进展，但其对新问题场景的推广仍然是一个持续的挑战。此外，该框架缺乏适应性学习和整合新专门代理的机制，这表明了未来改进的方向。
- en: Despite these limitations, our paper contributes to the growing body of literature
    on LLM-based problem-solving approaches by introducing a systematic and scalable
    framework. By sharing our approach and insights, we aim to stimulate further research
    and innovation in this domain, paving the way for enhanced problem-solving capabilities
    and the realization of artificial general intelligence.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在这些限制，我们的论文通过引入一个系统化和可扩展的框架，为基于 LLM 的问题解决方法贡献了日益增长的文献。通过分享我们的方法和见解，我们旨在激发这一领域的进一步研究和创新，为增强问题解决能力和实现人工通用智能铺平道路。
- en: References
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[Azamfirei et al., 2023] Azamfirei, R., Kudchadkar, S. R., and Fackler, J.
    (2023). Large language models and the perils of their hallucinations. Critical
    Care, 27(1):1–2.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Azamfirei 等, 2023] Azamfirei, R., Kudchadkar, S. R., 和 Fackler, J. (2023).
    大型语言模型及其幻觉的危险。*重症监护*，27(1):1–2。'
- en: '[Brown et al., 2020] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D.,
    Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. (2020).
    Language models are few-shot learners. Advances in neural information processing
    systems, 33:1877–1901.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Brown 等, 2020] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D.,
    Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., 等. (2020). 语言模型是少样本学习者。*神经信息处理系统进展*，33:1877–1901。'
- en: '[Bubeck et al., 2023] Bubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J.,
    Horvitz, E., Kamar, E., Lee, P., Lee, Y. T., Li, Y., Lundberg, S., et al. (2023).
    Sparks of artificial general intelligence: Early experiments with gpt-4. arXiv
    preprint arXiv:2303.12712.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Bubeck 等, 2023] Bubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz,
    E., Kamar, E., Lee, P., Lee, Y. T., Li, Y., Lundberg, S., 等. (2023). 人工通用智能的火花：与
    GPT-4 的早期实验。*arXiv 预印本* arXiv:2303.12712。'
- en: '[Chase, 2022] Chase, H. (2022). Langchain, october 2022. URL https://github.
    com/langchain-ai/langchain.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Chase, 2022] Chase, H. (2022). Langchain, 2022 年 10 月。URL https://github.com/langchain-ai/langchain。'
- en: '[Chen et al., 2021] Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. d. O.,
    Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., et al. (2021). Evaluating
    large language models trained on code. arXiv preprint arXiv:2107.03374.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Chen 等, 2021] Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. d. O.,
    Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., 等. (2021). 评估在代码上训练的大型语言模型。*arXiv
    预印本* arXiv:2107.03374。'
- en: '[Chiang and Lee, 2023] Chiang, C.-H. and Lee, H.-y. (2023). Can large language
    models be an alternative to human evaluations? arXiv preprint arXiv:2305.01937.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Chiang 和 Lee, 2023] Chiang, C.-H. 和 Lee, H.-y. (2023). 大型语言模型能否替代人工评估？*arXiv
    预印本* arXiv:2305.01937。'
- en: '[Cobbe et al., 2021] Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun,
    H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., Hesse, C., and
    Schulman, J. (2021). Training verifiers to solve math word problems. arXiv preprint
    arXiv:2110.14168.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Cobbe 等, 2021] Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser,
    L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., Hesse, C., 和 Schulman, J.
    (2021). 训练验证者解决数学词题。*arXiv 预印本* arXiv:2110.14168。'
- en: '[Cohen et al., 2023] Cohen, R., Hamri, M., Geva, M., and Globerson, A. (2023).
    Lm vs lm: Detecting factual errors via cross examination. arXiv preprint arXiv:2305.13281.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Cohen 等, 2023] Cohen, R., Hamri, M., Geva, M., 和 Globerson, A. (2023). Lm
    与 lm：通过交叉检查检测事实错误。*arXiv 预印本* arXiv:2305.13281。'
- en: '[Dafoe et al., 2021] Dafoe, A., Bachrach, Y., Hadfield, G., Horvitz, E., Larson,
    K., and Graepel, T. (2021). Cooperative ai: machines must learn to find common
    ground. Nature, 593(7857):33–36.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Dafoe 等, 2021] Dafoe, A., Bachrach, Y., Hadfield, G., Horvitz, E., Larson,
    K., 和 Graepel, T. (2021). 合作人工智能：机器必须学会找到共同点。*自然*，593(7857):33–36。'
- en: '[Dafoe et al., 2020] Dafoe, A., Hughes, E., Bachrach, Y., Collins, T., McKee,
    K. R., Leibo, J. Z., Larson, K., and Graepel, T. (2020). Open problems in cooperative
    ai. arXiv preprint arXiv:2012.08630.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Dafoe 等, 2020] Dafoe, A., Hughes, E., Bachrach, Y., Collins, T., McKee, K.
    R., Leibo, J. Z., Larson, K., 和 Graepel, T. (2020). 合作人工智能中的开放问题。*arXiv 预印本* arXiv:2012.08630。'
- en: '[Devlin et al., 2018] Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
    (2018). Bert: Pre-training of deep bidirectional transformers for language understanding.
    arXiv preprint arXiv:1810.04805.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Devlin 等人, 2018] Devlin, J., Chang, M.-W., Lee, K., 和 Toutanova, K. (2018).
    BERT: 用于语言理解的深度双向变换器预训练。arXiv 预印本 arXiv:1810.04805。'
- en: '[Du et al., 2023] Du, Y., Li, S., Torralba, A., Tenenbaum, J. B., and Mordatch,
    I. (2023). Improving factuality and reasoning in language models through multiagent
    debate. arXiv preprint arXiv:2305.14325.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Du 等人, 2023] Du, Y., Li, S., Torralba, A., Tenenbaum, J. B., 和 Mordatch, I.
    (2023). 通过多智能体辩论提高语言模型的事实性和推理能力。arXiv 预印本 arXiv:2305.14325。'
- en: '[Gao et al., 2023] Gao, M., Ruan, J., Sun, R., Yin, X., Yang, S., and Wan,
    X. (2023). Human-like summarization evaluation with chatgpt. arXiv preprint arXiv:2304.02554.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Gao 等人, 2023] Gao, M., Ruan, J., Sun, R., Yin, X., Yang, S., 和 Wan, X. (2023).
    使用 ChatGPT 的类人摘要评估。arXiv 预印本 arXiv:2304.02554。'
- en: '[Graesser et al., 2020] Graesser, L., Cho, K., and Kiela, D. (2020). Emergent
    linguistic phenomena in multi-agent communication games.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Graesser 等人, 2020] Graesser, L., Cho, K., 和 Kiela, D. (2020). 多智能体通信游戏中的语言现象涌现。'
- en: '[Gur et al., 2023] Gur, I., Furuta, H., Huang, A., Safdari, M., Matsuo, Y.,
    Eck, D., and Faust, A. (2023). A real-world webagent with planning, long context
    understanding, and program synthesis. arXiv preprint arXiv:2307.12856.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Gur 等人, 2023] Gur, I., Furuta, H., Huang, A., Safdari, M., Matsuo, Y., Eck,
    D., 和 Faust, A. (2023). 具有规划、长上下文理解和程序合成的真实世界 Web 代理。arXiv 预印本 arXiv:2307.12856。'
- en: '[Kramár et al., 2022] Kramár, J., Eccles, T., Gemp, I., Tacchetti, A., McKee,
    K. R., Malinowski, M., Graepel, T., and Bachrach, Y. (2022). Negotiation and honesty
    in artificial intelligence methods for the board game of diplomacy. Nature Communications,
    13(1):7214.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Kramár 等人, 2022] Kramár, J., Eccles, T., Gemp, I., Tacchetti, A., McKee, K.
    R., Malinowski, M., Graepel, T., 和 Bachrach, Y. (2022). 用于外交棋盘游戏的人工智能方法中的谈判与诚实。自然通讯,
    13(1):7214。'
- en: '[Lazaridou et al., 2020] Lazaridou, A., Potapenko, A., and Tieleman, O. (2020).
    Multi-agent communication meets natural language: Synergies between functional
    and structural language learning.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Lazaridou 等人, 2020] Lazaridou, A., Potapenko, A., 和 Tieleman, O. (2020). 多智能体通信与自然语言：功能和结构语言学习的协同效应。'
- en: '[Lee et al., 2018] Lee, J., Cho, K., Weston, J., and Kiela, D. (2018). Emergent
    translation in multi-agent communication.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Lee 等人, 2018] Lee, J., Cho, K., Weston, J., 和 Kiela, D. (2018). 多智能体通信中的涌现翻译。'
- en: '[Li et al., 2023] Li, G., Hammoud, H. A. A. K., Itani, H., Khizbullin, D.,
    and Ghanem, B. (2023). Camel: Communicative agents for" mind" exploration of large
    scale language model society. arXiv preprint arXiv:2303.17760.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Li 等人, 2023] Li, G., Hammoud, H. A. A. K., Itani, H., Khizbullin, D., 和 Ghanem,
    B. (2023). Camel: 用于大规模语言模型社会的“心智”探索的交流代理。arXiv 预印本 arXiv:2303.17760。'
- en: '[Liang et al., 2023] Liang, T., He, Z., Jiao, W., Wang, X., Wang, Y., Wang,
    R., Yang, Y., Tu, Z., and Shi, S. (2023). Encouraging divergent thinking in large
    language models through multi-agent debate. arXiv preprint arXiv:2305.19118.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Liang 等人, 2023] Liang, T., He, Z., Jiao, W., Wang, X., Wang, Y., Wang, R.,
    Yang, Y., Tu, Z., 和 Shi, S. (2023). 通过多智能体辩论鼓励大型语言模型中的发散思维。arXiv 预印本 arXiv:2305.19118。'
- en: '[Liu et al., 2023a] Liu, J., Xia, C. S., Wang, Y., and Zhang, L. (2023a). Is
    your code generated by chatgpt really correct? rigorous evaluation of large language
    models for code generation. arXiv preprint arXiv:2305.01210.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Liu 等人, 2023a] Liu, J., Xia, C. S., Wang, Y., 和 Zhang, L. (2023a). 你的代码是由
    ChatGPT 生成的，真的正确吗？对大型语言模型进行严格评估以生成代码。arXiv 预印本 arXiv:2305.01210。'
- en: '[Liu et al., 2023b] Liu, Y., Iter, D., Xu, Y., Wang, S., Xu, R., and Zhu, C.
    (2023b). Gpteval: Nlg evaluation using gpt-4 with better human alignment. arXiv
    preprint arXiv:2303.16634.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Liu 等人, 2023b] Liu, Y., Iter, D., Xu, Y., Wang, S., Xu, R., 和 Zhu, C. (2023b).
    GPTEval: 使用 GPT-4 进行更好的人类对齐的 NLG 评估。arXiv 预印本 arXiv:2303.16634。'
- en: '[OpenAI, 2023] OpenAI (2023). Gpt-4 technical report. arxiv 2303.08774. View
    in Article, 2:13.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenAI, 2023] OpenAI (2023). GPT-4 技术报告。arxiv 2303.08774。文章查看，2:13。'
- en: '[Ouyang et al., 2022] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright,
    C. L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et al. (2022).
    Training language models to follow instructions with human feedback, 2022. URL
    https://arxiv. org/abs/2203.02155, 13.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Ouyang 等人, 2022] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C.
    L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., 等人. (2022). 通过人类反馈训练语言模型以遵循指令，2022。网址
    https://arxiv. org/abs/2203.02155, 13。'
- en: '[Patil et al., 2023] Patil, S. G., Zhang, T., Wang, X., and Gonzalez, J. E.
    (2023). Gorilla: Large language model connected with massive apis. arXiv preprint
    arXiv:2305.15334.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Patil 等人, 2023] Patil, S. G., Zhang, T., Wang, X., 和 Gonzalez, J. E. (2023).
    Gorilla: 大型语言模型与海量 API 连接。arXiv 预印本 arXiv:2305.15334。'
- en: '[Qian et al., 2023] Qian, C., Cong, X., Yang, C., Chen, W., Su, Y., Xu, J.,
    Liu, Z., and Sun, M. (2023). Communicative agents for software development. arXiv
    preprint arXiv:2307.07924.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[钱等，2023] 钱程、丛鑫、杨超、陈伟、苏扬、徐骏、刘哲、孙敏。（2023）。软件开发中的交流代理。arXiv 预印本 arXiv:2307.07924。'
- en: '[Qin et al., 2023] Qin, Y., Liang, S., Ye, Y., Zhu, K., Yan, L., Lu, Y., Lin,
    Y., Cong, X., Tang, X., Qian, B., et al. (2023). Toolllm: Facilitating large language
    models to master 16000+ real-world apis. arXiv preprint arXiv:2307.16789.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[秦等，2023] 秦跃、梁胜、叶颖、朱凯、严磊、陆洋、林跃、丛鑫、唐晓、钱璧等。（2023）。ToolLLM：帮助大语言模型掌握16000+现实世界API。arXiv
    预印本 arXiv:2307.16789。'
- en: '[Rasal, 2024] Rasal, S. (2024). Llm harmony: Multi-agent communication for
    problem solving. arXiv preprint arXiv:2401.01312.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[拉萨尔，2024] 拉萨尔。（2024）。LLM 和谐：多代理通信解决问题。arXiv 预印本 arXiv:2401.01312。'
- en: '[Sanh et al., 2021] Sanh, V., Webson, A., Raffel, C., Bach, S. H., Sutawika,
    L., Alyafeai, Z., Chaffin, A., Stiegler, A., Scao, T. L., Raja, A., et al. (2021).
    Multitask prompted training enables zero-shot task generalization. arXiv preprint
    arXiv:2110.08207.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Sanh et al., 2021] Sanh, V., Webson, A., Raffel, C., Bach, S. H., Sutawika,
    L., Alyafeai, Z., Chaffin, A., Stiegler, A., Scao, T. L., Raja, A., 等。（2021）。多任务提示训练实现零样本任务泛化。arXiv
    预印本 arXiv:2110.08207。'
- en: '[Saunders et al., 2022] Saunders, W., Yeh, C., Wu, J., Bills, S., Ouyang, L.,
    Ward, J., and Leike, J. (2022). Self-critiquing models for assisting human evaluators.
    arXiv preprint arXiv:2206.05802.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[桑德斯等，2022] 桑德斯、叶晨、吴俊、比尔斯、欧阳龙、沃德、莱克。（2022）。自我批评模型辅助人工评估者。arXiv 预印本 arXiv:2206.05802。'
- en: '[Shen et al., 2023] Shen, C., Cheng, L., You, Y., and Bing, L. (2023). Are
    large language models good evaluators for abstractive summarization? arXiv preprint
    arXiv:2305.13091.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[沈等，2023] 沈程、程立、游洋、丁炳。（2023）。大语言模型是否适合评估抽象总结？arXiv 预印本 arXiv:2305.13091。'
- en: '[Touvron et al., 2023] Touvron, H., Lavril, T., Izacard, G., Martinet, X.,
    Lachaux, M.-A., Lacroix, T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., et al.
    (2023). Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[图夫隆等，2023] 图夫隆、拉夫里尔、伊扎卡德、马提奈、拉肖、拉克鲁瓦、罗济埃、戈亚尔、汉布罗、阿扎尔等。（2023）。Llama：开放高效的基础语言模型。arXiv
    预印本 arXiv:2302.13971。'
- en: '[Wei et al., 2022a] Wei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B.,
    Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D., Metzler, D., et al. (2022a).
    Emergent abilities of large language models. arXiv preprint arXiv:2206.07682.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[魏等，2022a] 魏佳、戴义、博马萨尼、拉费尔、佐普、博尔戈德、瑜伽塔马、博斯马、周东、梅茨勒等。（2022a）。大语言模型的涌现能力。arXiv
    预印本 arXiv:2206.07682。'
- en: '[Wei et al., 2022b] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F.,
    Chi, E., Le, Q. V., Zhou, D., et al. (2022b). Chain-of-thought prompting elicits
    reasoning in large language models. Advances in Neural Information Processing
    Systems, 35:24824–24837.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[魏等，2022b] 魏佳、王鑫、舒尔曼斯、博斯马、夏飞、池逸、乐强·V、周东等。（2022b）。链式思维提示激发大语言模型的推理能力。《神经信息处理系统进展》，35:24824–24837。'
- en: '[Wu et al., 2023] Wu, N., Gong, M., Shou, L., Liang, S., and Jiang, D. (2023).
    Large language models are diverse role-players for summarization evaluation. arXiv
    preprint arXiv:2303.15078.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[吴等，2023] 吴南、龚敏、邵磊、梁胜、江东。（2023）。大语言模型在总结评估中的多样角色扮演。arXiv 预印本 arXiv:2303.15078。'
- en: '[Yao et al., 2022] Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan,
    K., and Cao, Y. (2022). React: Synergizing reasoning and acting in language models.
    arXiv preprint arXiv:2210.03629.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[姚等，2022] 姚晟、赵俊、余丹、杜宁、沙夫兰、纳拉辛汉、曹阳。（2022）。React：在语言模型中协同推理和行动。arXiv 预印本 arXiv:2210.03629。'
- en: '[Zheng et al., 2023] Zheng, L., Chiang, W.-L., Sheng, Y., Zhuang, S., Wu, Z.,
    Zhuang, Y., Lin, Z., Li, Z., Li, D., Xing, E., et al. (2023). Judging llm-as-a-judge
    with mt-bench and chatbot arena. arXiv preprint arXiv:2306.05685.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[郑等，2023] 郑利、蒋文龙、盛毅、庄尚、吴泽、庄宇、林志、李志、李东、邢恩等。（2023）。使用 mt-bench 和聊天机器人竞技场评判 llm-as-a-judge。arXiv
    预印本 arXiv:2306.05685。'
