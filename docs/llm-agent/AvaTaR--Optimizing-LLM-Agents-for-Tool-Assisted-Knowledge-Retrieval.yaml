- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:44:12'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:44:12
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'AvaTaR: Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AvaTaR：优化用于工具辅助知识检索的 LLM 代理
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.11200](https://ar5iv.labs.arxiv.org/html/2406.11200)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2406.11200](https://ar5iv.labs.arxiv.org/html/2406.11200)
- en: Shirley Wu^§, Shiyu Zhao^§, Qian Huang^§, Kexin Huang^§, Michihiro Yasunaga^§,
    Kaidi Cao^§
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Shirley Wu^§, Shiyu Zhao^§, Qian Huang^§, Kexin Huang^§, Michihiro Yasunaga^§,
    Kaidi Cao^§
- en: Vassilis N. Ioannidis^†, Karthik Subbian^†, Jure Leskovec^(∗§), James Zou^(∗§)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Vassilis N. Ioannidis^†, Karthik Subbian^†, Jure Leskovec^(∗§), James Zou^(∗§)
- en: ^∗Equal senior authorship.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ^∗平等高级作者。
- en: ^§Department of Computer Science, Stanford University   ^†Amazon
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ^§斯坦福大学计算机科学系   ^†亚马逊
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Large language model (LLM) agents have demonstrated impressive capability in
    utilizing external tools and knowledge to boost accuracy and reduce hallucinations.
    However, developing the prompting techniques that make LLM agents able to effectively
    use external tools and knowledge is a heuristic and laborious task. Here, we introduce
    AvaTaR, a novel and automatic framework that optimizes an LLM agent to effectively
    use the provided tools and improve its performance on a given task/domain. During
    optimization, we design a comparator module to iteratively provide insightful
    and holistic prompts to the LLM agent via reasoning between positive and negative
    examples sampled from training data. We demonstrate AvaTaR on four complex multimodal
    retrieval datasets featuring textual, visual, and relational information. We find
    AvaTaR consistently outperforms state-of-the-art approaches across all four challenging
    tasks and exhibits strong generalization ability when applied to novel cases,
    achieving an average relative improvement of 14% on the Hit@1 metric. Code and
    dataset are available at [https://github.com/zou-group/avatar.](https://github.com/zou-group/avatar)
    ^†^†footnotetext: Correspondence: {shirwu, jure, jamesz}@cs.stanford.edu'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 大规模语言模型（LLM）代理在利用外部工具和知识来提高准确性和减少幻觉方面表现出色。然而，开发使 LLM 代理能够有效使用外部工具和知识的提示技术是一个启发性且劳动密集的任务。在这里，我们介绍了
    AvaTaR，一个新颖的自动化框架，旨在优化 LLM 代理，以有效使用提供的工具并提高其在给定任务/领域上的表现。在优化过程中，我们设计了一个比较模块，通过对来自训练数据的正负例进行推理，迭代地为
    LLM 代理提供有见地和全面的提示。我们在四个复杂的多模态检索数据集上展示了 AvaTaR，这些数据集包含文本、视觉和关系信息。我们发现 AvaTaR 在所有四个具有挑战性的任务中始终优于最新的方法，并且在应用于新案例时表现出强大的泛化能力，Hit@1
    指标的平均相对提升为 14%。代码和数据集可以在 [https://github.com/zou-group/avatar](https://github.com/zou-group/avatar)
    获取。^†^†脚注：通信作者：{shirwu, jure, jamesz}@cs.stanford.edu
- en: 1 Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Autonomous agents powered by large language models (LLMs) offer substantial
    promise for complex problem-solving [[37](#bib.bib37), [48](#bib.bib48), [56](#bib.bib56),
    [35](#bib.bib35), [7](#bib.bib7)]. These agents demonstrate remarkable capabilities
    in reasoning [[42](#bib.bib42), [41](#bib.bib41), [48](#bib.bib48), [47](#bib.bib47)]
    and planning [[13](#bib.bib13), [53](#bib.bib53), [14](#bib.bib14), [8](#bib.bib8)].
    Moreover, their functionality is extended by employing external tools that provide
    access to external/private data and specialized operations, such as APIs for interacting
    with knowledge bases and search engines. These tools empower agents to perform
    complex tasks like multi-step problem-solving and retrieving diverse information,
    which is essential for complex question-answering and retrieval [[36](#bib.bib36),
    [34](#bib.bib34), [43](#bib.bib43), [22](#bib.bib22), [13](#bib.bib13), [19](#bib.bib19),
    [29](#bib.bib29)].
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 由大规模语言模型（LLMs）驱动的自主代理在复杂问题解决方面展示了巨大的潜力[[37](#bib.bib37), [48](#bib.bib48), [56](#bib.bib56),
    [35](#bib.bib35), [7](#bib.bib7)]。这些代理在推理[[42](#bib.bib42), [41](#bib.bib41),
    [48](#bib.bib48), [47](#bib.bib47)]和规划[[13](#bib.bib13), [53](#bib.bib53), [14](#bib.bib14),
    [8](#bib.bib8)]方面表现出色。此外，通过使用提供对外部/私有数据和专业操作（如与知识库和搜索引擎交互的 API）的访问的外部工具，进一步扩展了其功能。这些工具使得代理能够执行复杂的任务，如多步骤问题解决和检索多样化的信息，这对于复杂的问答和检索[[36](#bib.bib36),
    [34](#bib.bib34), [43](#bib.bib43), [22](#bib.bib22), [13](#bib.bib13), [19](#bib.bib19),
    [29](#bib.bib29)]至关重要。
- en: Despite the promising capabilities of LLM agents, it remains challenging to
    engineer effective prompts that guide these agents through a multi-stage procedure
    for real-world problem-solving. This procedure includes (1) decomposing a complex
    question into an actionable plan with simpler steps, (2) strategically utilizing
    provided tools to gather relevant information, and, finally, (3) synthesize the
    intermediate results to produce a coherent and accurate response. Each step requires
    extensive manual effort and numerous iterations of trial and error to perfect
    the prompts.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管LLM代理具有很大的潜力，但设计有效的提示来引导这些代理通过多阶段程序解决现实问题仍然具有挑战性。该程序包括（1）将复杂问题分解为可操作的简单步骤，（2）策略性地利用提供的工具收集相关信息，以及（3）综合中间结果以生成连贯且准确的响应。每一步都需要大量的手动工作和多次试错以完善提示。
- en: 'Current approaches have primarily focused on directly deploying agents using
    complex human-designed “mega-prompts” [[20](#bib.bib20), [48](#bib.bib48), [16](#bib.bib16)],
    which requires lots of manual trial-and-error. Nevertheless, such hand-engineered
    mega-prompts may also result in brittle implementations with suboptimal accuracy
    (see Figure [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ AvaTaR: Optimizing LLM Agents
    for Tool-Assisted Knowledge Retrieval") (a)), where the ReAct agent [[48](#bib.bib48)]
    easily produces trivial and misleading answers to customers’ queries about specific
    products. Furthermore, existing research [[45](#bib.bib45), [40](#bib.bib40),
    [5](#bib.bib5), [6](#bib.bib6), [55](#bib.bib55), [49](#bib.bib49), [52](#bib.bib52)]
    on employing LLMs as optimizers often fails to adequately refine the complex strategies
    for enhancing tool integration and usage. This lack of strategic optimization
    can lead to less effective, non-generalizable agent applications in complex real-world
    scenarios.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '当前的方法主要集中在使用复杂的人为设计的“巨型提示”直接部署代理[[20](#bib.bib20), [48](#bib.bib48), [16](#bib.bib16)]，这需要大量的手动试错。然而，这些手工设计的巨型提示也可能导致脆弱的实现，准确性不佳（见图[2](#S1.F2
    "Figure 2 ‣ 1 Introduction ‣ AvaTaR: Optimizing LLM Agents for Tool-Assisted Knowledge
    Retrieval") (a)），例如，ReAct代理[[48](#bib.bib48)]可能会轻易地对客户关于特定产品的查询产生琐碎且误导的回答。此外，现有研究[[45](#bib.bib45),
    [40](#bib.bib40), [5](#bib.bib5), [6](#bib.bib6), [55](#bib.bib55), [49](#bib.bib49),
    [52](#bib.bib52)]关于使用LLM作为优化器的工作，往往未能充分完善增强工具集成和使用的复杂策略。这种缺乏战略优化可能导致在复杂的现实场景中，代理应用效果不佳且不可泛化。'
- en: 'Present work: AvaTaR. To address these challenges, we introduce AvaTaR, an
    automated framework that optimizes Agents for effective Tool utilization and excellent
    task performance. We demonstrate our framework on challenging and common tasks
    of knowledge base Retrieval, which involves the complex multi-stage procedure
    and extensive tool usage. To highlight, we leverage the key insights from contrastive
    learning and build a comparator module (“trainer”) to generate holistic instructions/prompts
    (i.e., compute robust “gradient”) to optimize an actor LLM. Specifically, AvaTaR
    includes two phases:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 当前工作：AvaTaR。为了解决这些挑战，我们引入了AvaTaR，一个优化代理以实现有效工具利用和优秀任务表现的自动化框架。我们在知识库检索这一具有挑战性且常见的任务上展示了我们的框架，该任务涉及复杂的多阶段程序和广泛的工具使用。值得强调的是，我们利用对比学习的关键见解，构建了一个比较器模块（“训练师”），生成整体指令/提示（即计算稳健的“梯度”）以优化演员LLM。具体而言，AvaTaR包括两个阶段：
- en: '![Refer to caption](img/1781230d4db98a5648bdb9f01076ef1d.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/1781230d4db98a5648bdb9f01076ef1d.png)'
- en: 'Figure 1: Overview of AvaTaR. AvaTaR consists of an actor LLM and a comparator
    LLM. (a) During optimization, the actor generates actions to answer queries leveraging
    the provided tools. Then the comparator contrasts a set of well-performing (positive)
    and poorly-performing (negative) queries, and automatically generates holistic
    prompts to teach the actor more effective retrieval strategies and tool usage
    (cf. Section [4](#S4 "4 Our Method: Optimizing Agents for Tool-Assisted Multi-Step
    Tasks ‣ AvaTaR: Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval")).
    (b) At deployment, the optimized actor can be effectively utilized to answer new
    queries.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '图1：AvaTaR概述。AvaTaR包括一个演员LLM和一个比较器LLM。（a）在优化过程中，演员生成利用提供工具回答查询的动作。然后，比较器对一组表现良好（正面）和表现不佳（负面）的查询进行对比，并自动生成整体提示，以教导演员更有效的检索策略和工具使用（参见第[4](#S4
    "4 Our Method: Optimizing Agents for Tool-Assisted Multi-Step Tasks ‣ AvaTaR:
    Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval")节）。(b) 在部署阶段，优化后的演员可以有效地用于回答新查询。'
- en: •
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Optimization phase. The core of our optimization framework (Figure [1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ AvaTaR: Optimizing LLM Agents for Tool-Assisted Knowledge
    Retrieval")) is a comparator LLM that automatically generates holistic prompts
    to teach an actor LLM to differentiate between best-performing and poor-performing
    tool usage. The comparator takes positive and negative data samples on which the
    current agent performs well and poorly, respectively, to identify the overall
    gap and systematic errors exhibited by the agent. Unlike per-sample instructions
    which easily lead to overfitting on individual data point, by constructing multiple
    samples as a “batch”, comparator can extract a more robust “gradient” to “backpropagate”
    to the actor. In other words, the comparator can provide more effective and adaptive
    prompts through such batch-wise contrastive reasoning, promoting the agent to
    identify flaws in solving the challenging multi-stage problem. Following previous
    methods [[37](#bib.bib37), [26](#bib.bib26), [54](#bib.bib54), [49](#bib.bib49)],
    we also maintain a memory bank with selected past instructions to prevent the
    actor LLM from repeating previous mistakes.'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '优化阶段。我们优化框架的核心 (图 [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ AvaTaR: Optimizing
    LLM Agents for Tool-Assisted Knowledge Retrieval")) 是一个比较器 LLM，自动生成全面的提示来教导演员
    LLM 区分最佳工具使用和表现差的工具使用。比较器接受当前代理在表现良好和表现差的正负数据样本，以识别代理所展示的总体差距和系统性错误。与容易导致对单个数据点过拟合的逐样本指令不同，通过将多个样本构建为“批次”，比较器可以提取出更稳健的“梯度”以“反向传播”到演员模型。换句话说，比较器可以通过这种批次对比推理提供更有效和适应性的提示，促使代理识别解决复杂多阶段问题中的缺陷。遵循以往的方法[[37](#bib.bib37),
    [26](#bib.bib26), [54](#bib.bib54), [49](#bib.bib49)]，我们还保持了一个包含选定过去指令的记忆库，以防止演员
    LLM 重复之前的错误。'
- en: •
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Deployment phase. The iterative optimization through our AvaTaR framework updates
    actor for more effective and generalizable knowledge extraction, allowing direct
    generalization to novel user inquiries in the deployment time. In Figure [2](#S1.F2
    "Figure 2 ‣ 1 Introduction ‣ AvaTaR: Optimizing LLM Agents for Tool-Assisted Knowledge
    Retrieval") (b), the optimized actor creates three novel strategies 1) the precise
    decomposition of problems via extracting multifaceted attributes, 2) effective
    tool usage via a sophisticated and robust scoring system, and 3) The strategic
    combination of different scores, determined by the learned coefficients, ensures
    accurate and comprehensive retrieval.'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '部署阶段。通过我们的 AvaTaR 框架进行的迭代优化更新了演员模型，使其能够更有效和更具普适性地提取知识，允许在部署时直接对新用户询问进行泛化。在图
    [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ AvaTaR: Optimizing LLM Agents for Tool-Assisted
    Knowledge Retrieval") (b) 中，优化后的演员模型创建了三种新策略：1）通过提取多方面的属性来精确分解问题，2）通过复杂且稳健的评分系统有效使用工具，3）不同评分的战略性组合，由学习到的系数确定，确保了准确而全面的检索。'
- en: Experimental evaluation. We conduct extensive experiments on four retrieval
    datasets. The retrieval tasks are of high complexity with multimodal data, including
    textual, visual, and relational information. AvaTaR consistently outperforms state-of-the-art
    methods, showing a substantial 14% improvement in the Hit@1 metric. Impressively,
    with only 25 iterations, AvaTaR boosts the Hit@1 metric from an initial 5.1% to
    28.6% on Flickr30K-Entities[[31](#bib.bib31)] and the Recall@20 metric from 30.3%
    to 39.3% on STaRK-Prime[[44](#bib.bib44)]. These improvements, achieved through
    iterative updates to the prompts, underscore AvaTaR ’s ability to optimize agents
    for complex task and tool usage.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 实验评估。我们在四个检索数据集上进行了广泛的实验。这些检索任务复杂度高，包含文本、视觉和关系信息等多模态数据。AvaTaR 在 Hit@1 指标上表现持续优于最先进的方法，显示出显著的
    14% 提升。令人印象深刻的是，仅用 25 次迭代，AvaTaR 将 Flickr30K-Entities[[31](#bib.bib31)] 的 Hit@1
    指标从初始的 5.1% 提升到 28.6%，并将 STaRK-Prime[[44](#bib.bib44)] 的 Recall@20 指标从 30.3% 提升到
    39.3%。这些通过对提示的迭代更新实现的改进，突显了 AvaTaR 在优化代理用于复杂任务和工具使用方面的能力。
- en: 'Our key contributions are:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的关键贡献包括：
- en: •
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We introduce AvaTaR, a novel framework that optimizes an actor for effective
    tool utilization through a comparator module that automatically generate holistic
    prompts.
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们介绍了 AvaTaR，一个新颖的框架，通过比较模块自动生成全面的提示，从而优化演员模型的有效工具使用。
- en: •
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We demonstrate that AvaTaR on four challenging retrieval tasks, which significantly
    outperforms existing agent methods in terms of the task performance and generalization
    ability.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们展示了 AvaTaR 在四个具有挑战性的检索任务上显著优于现有的代理方法，在任务性能和泛化能力方面具有显著提升。
- en: •
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We provide a comprehensive analysis on the actor’s evolution during optimization,
    highlighting how comparator automatically provides targeted instructions that
    improve and generalize the actor.
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提供了对优化过程中演员演变的全面分析，突出展示了比较器如何自动提供针对性的指令，从而改进和推广演员。
- en: '![Refer to caption](img/4f8072563ea71a5308d3f710e70104c8.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/4f8072563ea71a5308d3f710e70104c8.png)'
- en: 'Figure 2: Comparison between AvaTaR and ReAct. (a) The ReAct agent exhibits
    incomplete task decomposition and employs suboptimal tool combinations like lengthy
    string matching, leading to poor task performance. (b) AvaTaR decomposes the task
    into multiple steps such as type filtering and flexible token matching. Moreover,
    it implements robust tool usage and precise synthesis with learned parameters
    from the optimization phase to achieve excellent performance on new queries.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：AvaTaR和ReAct的比较。 (a) ReAct代理展示了不完整的任务分解，并采用了次优的工具组合，如冗长的字符串匹配，导致任务表现不佳。 (b)
    AvaTaR将任务分解为多个步骤，如类型过滤和灵活的标记匹配。此外，它通过在优化阶段学习到的参数来实现稳健的工具使用和精确的综合，以在新查询上取得优异的表现。
- en: 2 Related Work
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: LLM Agents. Recent research has been leveraging the remarkable language understanding
    and reasoning abilities of LLMs [[42](#bib.bib42), [47](#bib.bib47), [2](#bib.bib2),
    [37](#bib.bib37), [48](#bib.bib48)] to complete downstream tasks. For complex
    tasks that require more capabilities, previous works regard LLMs as agents that
    can interact with the environments [[7](#bib.bib7), [36](#bib.bib36), [22](#bib.bib22),
    [43](#bib.bib43), [13](#bib.bib13), [19](#bib.bib19), [16](#bib.bib16), [48](#bib.bib48),
    [5](#bib.bib5), [23](#bib.bib23)] and leverage external tools [[35](#bib.bib35),
    [29](#bib.bib29), [57](#bib.bib57), [34](#bib.bib34), [58](#bib.bib58), [7](#bib.bib7),
    [27](#bib.bib27), [32](#bib.bib32), [24](#bib.bib24)]. For example, ReAct [[48](#bib.bib48)]
    conducts reasoning and action in an interleaved way, which retrieves information
    from Wikipedia to support reasoning.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: LLM代理。近期的研究已经利用了LLM的卓越语言理解和推理能力[[42](#bib.bib42), [47](#bib.bib47), [2](#bib.bib2),
    [37](#bib.bib37), [48](#bib.bib48)]来完成下游任务。对于需要更多能力的复杂任务，之前的工作将LLM视为可以与环境互动的代理[[7](#bib.bib7),
    [36](#bib.bib36), [22](#bib.bib22), [43](#bib.bib43), [13](#bib.bib13), [19](#bib.bib19),
    [16](#bib.bib16), [48](#bib.bib48), [5](#bib.bib5), [23](#bib.bib23)]，并利用外部工具[[35](#bib.bib35),
    [29](#bib.bib29), [57](#bib.bib57), [34](#bib.bib34), [58](#bib.bib58), [7](#bib.bib7),
    [27](#bib.bib27), [32](#bib.bib32), [24](#bib.bib24)]。例如，ReAct[[48](#bib.bib48)]以交替的方式进行推理和行动，它从维基百科中检索信息以支持推理。
- en: LLM Agents for Retrieval. Previous research has applied LLM agents for Information
    Retrieval (IR) systems, through pretraining [[9](#bib.bib9), [50](#bib.bib50),
    [3](#bib.bib3), [15](#bib.bib15)], reranking [[12](#bib.bib12), [38](#bib.bib38)],
    and prompting techniques [[16](#bib.bib16), [11](#bib.bib11)]. In the IR systems,
    retriever module directly influences the performance of downstream tasks, such
    as retrieval-augmented generation [[18](#bib.bib18), [25](#bib.bib25), [26](#bib.bib26)]
    and knowledge-intensive question answering [[30](#bib.bib30), [46](#bib.bib46)].
    For example, EHRAgent [[36](#bib.bib36)] is designed for EHR question-answering,
    capable of retrieving relevant clinical knowledge through a structured tool-use
    planning process and an interactive coding mechanism. However, these LLM agents
    usually take heuristic (zero-shot) prompts or rely on few-shot examples [[21](#bib.bib21),
    [48](#bib.bib48), [16](#bib.bib16), [36](#bib.bib36)] to apply to downstream tasks,
    which lack more informed guidance on generating effective retrieval strategies
    and tool-assisted actions.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: LLM代理在检索中的应用。之前的研究已将LLM代理应用于信息检索（IR）系统，通过预训练[[9](#bib.bib9), [50](#bib.bib50),
    [3](#bib.bib3), [15](#bib.bib15)]、重排序[[12](#bib.bib12), [38](#bib.bib38)]和提示技术[[16](#bib.bib16),
    [11](#bib.bib11)]。在IR系统中，检索模块直接影响下游任务的表现，如检索增强生成[[18](#bib.bib18), [25](#bib.bib25),
    [26](#bib.bib26)]和知识密集型问答[[30](#bib.bib30), [46](#bib.bib46)]。例如，EHRAgent[[36](#bib.bib36)]是为电子健康记录问答设计的，能够通过结构化的工具使用规划过程和交互式编码机制检索相关的临床知识。然而，这些LLM代理通常采用启发式（零样本）提示或依赖少量示例[[21](#bib.bib21),
    [48](#bib.bib48), [16](#bib.bib16), [36](#bib.bib36)]来应用于下游任务，这缺乏对生成有效检索策略和工具辅助行动的更多指导。
- en: Agent Optimization. In the field of improving LLM agents, previous works have
    modified the parameters of LLM backbones through finetuning or instruction tuning
    to enhance agent capability [[29](#bib.bib29), [51](#bib.bib51), [33](#bib.bib33),
    [4](#bib.bib4), [17](#bib.bib17), [28](#bib.bib28)] or generated better prompts
    through iterative prompt tuning [[45](#bib.bib45), [49](#bib.bib49), [40](#bib.bib40),
    [16](#bib.bib16), [11](#bib.bib11)]. Recently, Zhang et al. [[52](#bib.bib52)]
    conducted agent training by iteratively updating the agents’ functions according
    to the execution history. However, these methods do not explicitly consider targeted
    optimization on tool usage and the impact on complex multi-stage tasks. Moreover,
    improving the generalization ability of agents [[10](#bib.bib10), [39](#bib.bib39),
    [27](#bib.bib27)], which is essential for real-world applications, has received
    less attention. In our work, we focus on automatically generating holistic instructions
    via a novel contrastive reasoning mechanism, targeting effective tool usage and
    agents’ generalization ability.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 代理优化。在提升 LLM 代理的领域，之前的研究通过微调或指令调整修改了 LLM 主干的参数，以增强代理能力 [[29](#bib.bib29), [51](#bib.bib51),
    [33](#bib.bib33), [4](#bib.bib4), [17](#bib.bib17), [28](#bib.bib28)]，或者通过迭代提示调整生成更好的提示
    [[45](#bib.bib45), [49](#bib.bib49), [40](#bib.bib40), [16](#bib.bib16), [11](#bib.bib11)]。最近，Zhang
    等人 [[52](#bib.bib52)] 通过根据执行历史迭代更新代理的功能进行了代理训练。然而，这些方法没有明确考虑针对工具使用的优化和对复杂多阶段任务的影响。此外，提升代理的泛化能力
    [[10](#bib.bib10), [39](#bib.bib39), [27](#bib.bib27)]，这对于现实世界应用至关重要，受到的关注较少。在我们的工作中，我们通过一种新颖的对比推理机制，专注于自动生成整体指令，旨在有效使用工具和提升代理的泛化能力。
- en: 3 Problem Formulation
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 问题制定
- en: 'Definition 1: Tools. We define tools or APIs as a set of implemented functions
    with specified input and output variables. We denote the abstract tool space as
    $\mathcal{T}=\{f_{k}:\mathcal{I}_{f_{k}}\rightarrow\mathcal{O}_{f_{k}}\mid k=1,2,\ldots\}$.
    For example, the tools can be APIs used for accessing external knowledge given
    a search index, an encoder model that generates vector representations from text
    or image data, or a task-specific classifier that outputs probabilities over a
    list of classes.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 1：工具。我们将工具或 API 定义为一组具有特定输入和输出变量的实现函数。我们将抽象工具空间表示为 $\mathcal{T}=\{f_{k}:\mathcal{I}_{f_{k}}\rightarrow\mathcal{O}_{f_{k}}\mid
    k=1,2,\ldots\}$。例如，这些工具可以是用于访问外部知识的 API，给定一个搜索索引；也可以是一个将文本或图像数据生成向量表示的编码模型，或者是一个对一系列类别输出概率的任务特定分类器。
- en: 'Definition 2: Agents. An LLM agent, defined as $\mathcal{A}:\mathcal{P}\rightarrow\alpha$
    renders the results for the task.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 2：代理。LLM 代理定义为 $\mathcal{A}:\mathcal{P}\rightarrow\alpha$，为任务提供结果。
- en: 'Multi-step problem-solving. Real-world problems are inherently complex and
    cannot be effectively addressed with straightforward solution or simple tool usage
    alone. Using LLM agents for solving real-world problems can be structured into
    a multi-stage procedure:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 多步骤问题解决。现实世界的问题本质上是复杂的，不能仅靠简单的解决方案或工具使用来有效处理。使用 LLM 代理解决现实世界的问题可以被结构化为多阶段程序：
- en: •
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Decomposition of the problem: The procedure begins by breaking down a complex
    question into an actionable plan characterized by simpler steps. This decomposition
    is crucial for setting clear objectives and facilitating focused problem-solving.'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 问题分解：该过程始于将复杂的问题分解为由简单步骤构成的可操作计划。这一分解对于设定明确目标和促进有针对性的问题解决至关重要。
- en: •
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Tool-assisted subproblem solving: In the subsequent phase, agents strategically
    utilize tools from the established tool space $\mathcal{T}$ to gather solutions
    for each step. This stage is essential for acquiring the necessary information
    required to address each subproblem of the decomposed problem effectively.'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 工具辅助子问题求解：在随后的阶段，代理系统策略性地利用从已建立的工具空间 $\mathcal{T}$ 中获取的工具来收集每个步骤的解决方案。此阶段对于获取解决每个子问题所需的必要信息至关重要。
- en: •
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Synthesis and response formulation: The final stage involves synthesizing the
    intermediate results to construct a precise response. This synthesis not only
    combines the data but may also refine the response through trials and adjustments,
    ensuring the solution’s accuracy and relevancy.'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 综合与响应制定：最后阶段涉及综合中间结果以构建精确的响应。这一综合不仅结合了数据，还可能通过试验和调整来细化响应，确保解决方案的准确性和相关性。
- en: For example, retrieval tasks are inherently complex and demanding. Given a user
    query $q$, which are used to compute the quality of the prediction. Specifically,
    the LLM agent is required to 1) comprehend a user’s request, followed by 2) using
    the provided tools to identify and analyze relevant information in the large knowledge
    space, which may contain multi-modal data source. Finally, it requires 3) the
    integration of all gathered information to reason and generate an accurate response.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，检索任务本质上复杂且要求高。给定用户查询$q$，这些查询用于计算预测质量。具体来说，LLM代理需要1）理解用户的请求，随后2）使用提供的工具在大型知识空间中识别和分析相关信息，这些信息可能包含多模态数据源。最后，需要3）整合所有收集的信息进行推理并生成准确的回应。
- en: '4 Our Method: Optimizing Agents for Tool-Assisted Multi-Step Tasks'
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 我们的方法：优化用于工具辅助的多步骤任务的代理
- en: 'Table 1: Key differences between AvaTaR and prevailing agent methods. AvaTaR
    demonstrates the capabilities to: 1) self-improve on specific tasks, 2) retain
    memory throughout the optimization process, 3) enhance the agent’s ability to
    generalize, and 4) autonomously generate holistic, high-quality prompts for better
    tool usage. Please refer to Section [4](#S4 "4 Our Method: Optimizing Agents for
    Tool-Assisted Multi-Step Tasks ‣ AvaTaR: Optimizing LLM Agents for Tool-Assisted
    Knowledge Retrieval") for details.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '表1：AvaTaR与现有代理方法的关键区别。AvaTaR展示了以下能力：1）在特定任务上的自我改进，2）在优化过程中保留记忆，3）增强代理的泛化能力，4）自主生成整体的、高质量的提示以更好地使用工具。详细信息请参见第[4](#S4
    "4 Our Method: Optimizing Agents for Tool-Assisted Multi-Step Tasks ‣ AvaTaR:
    Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval")节。'
- en: '|  | Self-Improvement | Memory | Generalization | Holistic Prompt Generation
    |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '|  | 自我改进 | 记忆 | 泛化 | 整体提示生成 |'
- en: '|  | (on Tool Usage) |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '|  | （工具使用） |'
- en: '| ReAct [[48](#bib.bib48)] | ✗ | ✗ | ✗ | ✗ |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| ReAct [[48](#bib.bib48)] | ✗ | ✗ | ✗ | ✗ |'
- en: '| Self-refine [[23](#bib.bib23)] | ✔ | ✗ | ✗ | ✗ |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 自我优化 [[23](#bib.bib23)] | ✔ | ✗ | ✗ | ✗ |'
- en: '| Reflexion [[37](#bib.bib37)] | ✔ | ✔ | ✗ | ✗ |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| Reflexion [[37](#bib.bib37)] | ✔ | ✔ | ✗ | ✗ |'
- en: '| AvaTaR (Ours) | ✔ | ✔ | ✔ | ✔ |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| AvaTaR（我们的） | ✔ | ✔ | ✔ | ✔ |'
- en: 'Each step in the multi-stage problem-solving process (formulated in Section [3](#S3
    "3 Problem Formulation ‣ AvaTaR: Optimizing LLM Agents for Tool-Assisted Knowledge
    Retrieval")) requires effective prompts to identify key flaws and improve task
    performance. However, perfecting the agents’ prompts requires extensive manual
    effort and numerous iterations of trial and error.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '多阶段问题解决过程中的每一步（详见第[3](#S3 "3 Problem Formulation ‣ AvaTaR: Optimizing LLM Agents
    for Tool-Assisted Knowledge Retrieval")节）都需要有效的提示来识别关键缺陷和提升任务表现。然而，完善代理的提示需要大量的手动努力和无数次的反复试验。'
- en: 'Therefore, we offer an automatic and novel optimization framework, AvaTaR,
    to generate prompts to improve agents’ tool usage and task performance. In Table [1](#S4.T1
    "Table 1 ‣ 4 Our Method: Optimizing Agents for Tool-Assisted Multi-Step Tasks
    ‣ AvaTaR: Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval"), we highlight
    four critical aspects of our approach compared with the prevailing agent frameworks [[48](#bib.bib48),
    [37](#bib.bib37), [23](#bib.bib23)]. Here we introduce two main LLM components
    in AvaTaR, an actor LLM (Section [4.1](#S4.SS1 "4.1 Actor Construction and Challenges
    ‣ 4 Our Method: Optimizing Agents for Tool-Assisted Multi-Step Tasks ‣ AvaTaR:
    Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval")) and a comparator
    LLM (Section [4.2](#S4.SS2 "4.2 Automate Holistic Instruction Generation with
    Comparator ‣ 4 Our Method: Optimizing Agents for Tool-Assisted Multi-Step Tasks
    ‣ AvaTaR: Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval")).'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '因此，我们提供了一个自动化和新颖的优化框架AvaTaR，以生成提示来提升代理的工具使用和任务表现。在表[1](#S4.T1 "Table 1 ‣ 4
    Our Method: Optimizing Agents for Tool-Assisted Multi-Step Tasks ‣ AvaTaR: Optimizing
    LLM Agents for Tool-Assisted Knowledge Retrieval")中，我们突出显示了与现有代理框架[[48](#bib.bib48),
    [37](#bib.bib37), [23](#bib.bib23)]相比的四个关键方面。在这里，我们介绍了AvaTaR中的两个主要LLM组件，一个是代理LLM（第[4.1](#S4.SS1
    "4.1 Actor Construction and Challenges ‣ 4 Our Method: Optimizing Agents for Tool-Assisted
    Multi-Step Tasks ‣ AvaTaR: Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval")节），另一个是比较器LLM（第[4.2](#S4.SS2
    "4.2 Automate Holistic Instruction Generation with Comparator ‣ 4 Our Method:
    Optimizing Agents for Tool-Assisted Multi-Step Tasks ‣ AvaTaR: Optimizing LLM
    Agents for Tool-Assisted Knowledge Retrieval")节）。'
- en: 4.1 Actor Construction and Challenges
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 代理构建及挑战
- en: 'Actor. The actor agent follows the definition in Section [3](#S3 "3 Problem
    Formulation ‣ AvaTaR: Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval"),
    which is responsible for generating initial actions given the initial instructions/prompts
    and modifying actions given other instructions. Specifically, the initial instructions
    provide details about the task and the existing tools, where the tools can be
    introduced in programming languages such as Python. During optimization, the prompts
    further incorporate the previous action sequence and updated instructions to modify
    these actions. The actor then generates revised actions, which could be a blend
    of tool usage through the programming language (code generation), along with natural
    language explanations of how the tools are used.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '演员。演员代理遵循第 [3](#S3 "3 问题定义 ‣ AvaTaR: 优化 LLM 代理以支持工具辅助知识检索") 节中的定义，负责根据初始指令/提示生成初始行动，并根据其他指令修改行动。具体而言，初始指令提供有关任务和现有工具的详细信息，其中工具可以通过编程语言（如
    Python）引入。在优化过程中，提示进一步整合先前的行动序列和更新的指令以修改这些行动。然后，演员生成修订后的行动，这可能是通过编程语言（代码生成）使用工具的组合，以及工具使用的自然语言解释。'
- en: Challenges on multi-step complex tasks. A common approach to updating instructions
    uses execution results or performance data from a specific instance, often through
    techniques like self-explanation [[23](#bib.bib23), [5](#bib.bib5)] or self-reflection [[37](#bib.bib37),
    [49](#bib.bib49)]. However, this may not be suitable for complex tasks involving
    tool usage. As complex multi-step tasks include several interacting factors that
    influence overall performance, such as problem decomposition and tool selections,
    these per-sample instructions tend to be narrow and fail to identify flaws across
    all components of a complex solution. Additionally, while certain tool combinations
    may be effective for one type of input, their effectiveness can vary with others,
    leading to decreased performance when applied across different scenarios.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 多步骤复杂任务的挑战。更新指令的常见方法使用来自特定实例的执行结果或性能数据，通常通过自我解释 [[23](#bib.bib23), [5](#bib.bib5)]
    或自我反思 [[37](#bib.bib37), [49](#bib.bib49)] 等技术。然而，这可能不适用于涉及工具使用的复杂任务。由于复杂的多步骤任务包括多个相互作用的因素，这些因素影响整体性能，例如问题分解和工具选择，这些每样本的指令往往较窄，未能识别复杂解决方案中所有组件的缺陷。此外，虽然某些工具组合可能对一种类型的输入有效，但它们的有效性可能会因其他输入而有所不同，从而在应用于不同场景时导致性能下降。
- en: 4.2 Automate Holistic Instruction Generation with Comparator
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 使用比较器自动生成整体指令
- en: To address the challenges, we construct a comparator LLM to update the instructions
    for the actor. Instead of optimizing on a sampled instance, comparator aims to
    identify systematic flaws throughout the structured actions/solutions.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些挑战，我们构建了一个比较器 LLM 来更新演员的指令。与其在一个样本实例上进行优化，比较器旨在识别结构化行动/解决方案中的系统性缺陷。
- en: 'Step 1: Constructing positive and negative queries. To realize this goal, in
    Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ AvaTaR: Optimizing LLM Agents for
    Tool-Assisted Knowledge Retrieval"), the comparator samples a group of data samples
    (question-answer pairs), executes the current actions for each question, and constructs
    well-performing (positive) and poorly-performing (negative) queries based on their
    execution results. Specifically, we define two thresholds, $\ell$ as a hyperparameter.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '步骤 1：构建正面和负面查询。为了实现这一目标，在图 [1](#S1.F1 "图 1 ‣ 1 引言 ‣ AvaTaR: 优化 LLM 代理以支持工具辅助知识检索")
    中，比较器采样一组数据样本（问题-答案对），对每个问题执行当前的行动，并根据其执行结果构建表现良好（正面）和表现差（负面）的查询。具体而言，我们定义了两个阈值，$\ell$
    作为超参数。'
- en: 'Step 2: Generating instruction by contrastive reasoning. After that, the comparator
    is asked to contrast the two groups of queries based on their key characteristics,
    attribute the performance gap to particular tool usage in the complex solution,
    and finally suggest general modifications that can lead to overall improvement
    on task performance. The instructions generated by the comparator will then be
    appended to the initial prompts to update the actor.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 2：通过对比推理生成指令。之后，比较器会根据关键特征对两组查询进行对比，将性能差距归因于复杂解决方案中特定工具的使用，并最终建议可以整体提升任务性能的一般性修改。由比较器生成的指令将附加到初始提示中，以更新演员。
- en: Insights/Justification for the comparator. To illustrate the insights, we draw
    an analogy from deep neural network training, where extremely small batch sizes
    can introduce significant noise in gradient estimates and high variance in model
    updates. By adopting a batched training strategy and sampling positive and negative
    queries as two “mini-batches”, comparator is able to extract a robust “gradient”
    to update the actor. This approach motivates comparator to generate more general
    and comprehensive instructions on the complex action sequence, including problem
    decomposition, solutions to subproblems, and the final synthesis. Moreover, as
    contrastive reasoning directly targets disentangling the performance gap related
    to input patterns and how they are handled differently by the tools, it is particularly
    effective in helping comparator differentiate and select tools for use. Finally,
    by identifying systemic flaws across a wide array of negative queries, comparator
    generates modifications that are not only tailored to individual samples but also
    to diverse data samples, offering benefits for better generalization to novel
    samples.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对比较器的见解/理由。为了说明这些见解，我们借用深度神经网络训练中的类比，其中极小的批量大小可能会在梯度估计中引入显著噪声，并导致模型更新中的高方差。通过采用批量训练策略，并将正面和负面查询作为两个“迷你批次”进行采样，比较器能够提取稳健的“梯度”来更新演员。这种方法促使比较器生成更为通用和全面的复杂操作序列指令，包括问题分解、子问题的解决方案以及最终的综合。此外，由于对比推理直接针对与输入模式相关的性能差距及其如何被工具不同处理，因此在帮助比较器区分和选择工具方面特别有效。最后，通过识别广泛负面查询中的系统性缺陷，比较器生成的修改不仅适用于单个样本，也适用于多样的数据样本，从而有助于更好地推广到新样本。
- en: '![Refer to caption](img/8ad3aa1bc1e1028d30398fab59918b35.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8ad3aa1bc1e1028d30398fab59918b35.png)'
- en: 'Figure 3: Demonstration example during optimization. Best viewed in color.
    The task of the comparator is to automatically generate instructions based on
    sampled positive and negative queries. Then comparator provides holistic instructions
    that guide the actor to improve query decomposition, utilize better tools, and
    incorporate more comprehensive information.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：优化过程中的演示示例。最佳以彩色查看。比较器的任务是基于采样的正面和负面查询自动生成指令。然后比较器提供全面的指令，指导演员改进查询分解，利用更好的工具，并整合更多全面的信息。
- en: 'Demonstration example. Figure [3](#S4.F3 "Figure 3 ‣ 4.2 Automate Holistic
    Instruction Generation with Comparator ‣ 4 Our Method: Optimizing Agents for Tool-Assisted
    Multi-Step Tasks ‣ AvaTaR: Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval")
    shows an example where comparator contrasts the patterns of positive and negative
    queries, identifying discrepancies in tool usage within the action sequence. It
    reveals that compared to positive queries, negative queries feature more complex
    product descriptions, more subtle brand mentions, and additional relevant product
    mentions. These observations suggest: 1) an incomplete problem decomposition involving
    query attributes like detailed product features, 2) a potentially imprecise brand
    match using embedding similarity, and 3) a lack of consideration for related products
    in the results. Informed by these insights, actor updates its action sequence
    to include the additional sbuproblems and use the tools more effectively for the
    task, such as replacing the embedding tool with an LLM verification tool.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '演示示例。图 [3](#S4.F3 "Figure 3 ‣ 4.2 Automate Holistic Instruction Generation
    with Comparator ‣ 4 Our Method: Optimizing Agents for Tool-Assisted Multi-Step
    Tasks ‣ AvaTaR: Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval")
    展示了一个示例，其中比较器对比了正面和负面查询的模式，识别了操作序列中工具使用的差异。结果显示，与正面查询相比，负面查询包含了更复杂的产品描述、更微妙的品牌提及和更多相关产品的提及。这些观察表明：1)
    涉及详细产品特征的查询属性存在问题分解不完整，2) 使用嵌入相似度进行品牌匹配可能不精确，3) 结果中未考虑相关产品。根据这些见解，演员更新其操作序列，以包括额外的子问题，并更有效地使用工具，例如将嵌入工具替换为LLM验证工具。'
- en: 4.3 Logistic Instructions and Memory Construction
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 物流指令和记忆构建
- en: Logistic instructions. While instructions from the comparator are designed to
    improve task performance, we incorporate two types of orthogonal instructions
    to ensure the actions are valid and can be executed efficiently.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 物流指令。虽然来自比较器的指令旨在提高任务性能，我们还纳入了两种正交指令，以确保操作是有效的并且可以高效执行。
- en: •
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Validity check: This instruction is triggered internally during the execution
    of each action. It ensures the validity of the actor’s actions, such as verifying
    the proper use of function calls.'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有效性检查：该指令在每个动作执行期间内部触发。它确保 actor 的动作的有效性，例如验证函数调用的正确使用。
- en: •
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Timeout Error: To preclude inefficient action sequences that may stall the
    actor, we implement a timeout mechanism that triggers an error when processing
    exceeds a threshold. This error prompt the actor to use more efficient strategies,
    such as eliminating redundant operations.'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 超时错误：为了防止可能使 actor 停滞的低效动作序列，我们实施了一个超时机制，当处理超出阈值时触发错误。此错误提示 actor 使用更有效的策略，例如消除冗余操作。
- en: Memory Bank. During optimization, we utilize a memory bank inspired by human
    decision-making processes, where humans typically address current problems by
    analyzing the current situation and referencing past experiences. The memory bank
    stores tuples of action sequences, instructions from comparator, and the performance
    of these action sequences on a small QA set (conducted during sampling positive
    and negative queries). To manage the context size input to actor , we take only
    the top-$5$ action sequences with the best performance. This memory bank enables
    actor to learn from both immediate instructions and historical results.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 内存库。在优化过程中，我们利用了一个受人类决策过程启发的内存库，人类通常通过分析当前情况和参考过去的经验来解决当前问题。内存库存储了动作序列的元组、比较器的指令以及这些动作序列在小型
    QA 集上的表现（在采样正负查询时进行）。为了管理传递给 actor 的上下文大小输入，我们仅保留表现最佳的前 $5$ 个动作序列。这个内存库使 actor
    能够从即时指令和历史结果中学习。
- en: 'Deployment. At deployment (see Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ AvaTaR: Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval")), we apply
    the optimized actor /action sequence, which includes effective tool usage and
    problem-solving strategies, to directly answer user queries.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '部署。在部署时（见图 [1](#S1.F1 "图 1 ‣ 1 介绍 ‣ AvaTaR: 优化 LLM 代理以辅助知识检索")），我们应用优化后的 actor
    / 动作序列，包括有效的工具使用和问题解决策略，以直接回答用户查询。'
- en: 5 Experiments
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 个实验
- en: 'Tasks and Evaluation. We conduct experiments on four challenging retrieval
    datasets (Appendix [A](#A1 "Appendix A Retrieval Tasks ‣ AvaTaR: Optimizing LLM
    Agents for Tool-Assisted Knowledge Retrieval")) from STaRK [[44](#bib.bib44)]
    and Flickr30K-Entities [[31](#bib.bib31)] to demonstrate AvaTaR in handling complex
    real-world task. For each query, the task is to retrieve relevant entities such
    as nodes in the knowledge graph or images in the knowledge bases. We assess task
    performance by comparing the consistency of the results with the ground truth
    answers in the datasets, where we use Hit@1, Hit@5, Recall@20, and Mean Reciprocal
    Rank (MRR) as the metrics.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '任务和评估。我们在四个具有挑战性的检索数据集上进行实验（附录 [A](#A1 "附录 A 检索任务 ‣ AvaTaR: 优化 LLM 代理以辅助知识检索")）来自
    STaRK [[44](#bib.bib44)] 和 Flickr30K-Entities [[31](#bib.bib31)]，以展示 AvaTaR 处理复杂真实世界任务的能力。对于每个查询，任务是检索相关实体，如知识图谱中的节点或知识库中的图像。我们通过比较结果与数据集中的真实答案的一致性来评估任务性能，其中我们使用
    Hit@1、Hit@5、Recall@20 和 Mean Reciprocal Rank (MRR) 作为指标。'
- en: 'Baselines. Following Wu et al. [[44](#bib.bib44)], we employ several embedding-based
    retriever models for our evaluation: Vector Similarity Search (VSS) and Multi-Vector
    Similarity Search (Multi-VSS) using text-embedding-ada-002 from OpenAI; a relation-aware
    model, QAGNN [[50](#bib.bib50)], for the STaRK benchmark. Moreover, we include
    two prevailing agent frameworks to further enrich our evaluation.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 基线。根据 Wu 等人 [[44](#bib.bib44)] 的方法，我们使用几种基于嵌入的检索模型进行评估：使用 OpenAI 的 text-embedding-ada-002
    的向量相似性搜索（VSS）和多向量相似性搜索（Multi-VSS）；一个关系感知模型 QAGNN [[50](#bib.bib50)]，用于 STaRK 基准测试。此外，我们还包括两个流行的代理框架，以进一步丰富我们的评估。
- en: •
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: ReAct [[48](#bib.bib48)] conducts reasoning and action in an in-context and
    interleaved manner to enhance LLMs with the capability to interactively analyze
    observed information and perform actions.
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ReAct [[48](#bib.bib48)] 以上下文内和交错的方式进行推理和行动，以增强 LLM 具备互动分析观察到的信息并执行操作的能力。
- en: •
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Reflexion [[37](#bib.bib37)] utilizes self-reflection on the current task completion
    and store these reflections in an episodic memory buffer to enhance decision-making
    in subsequent trials.
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Reflexion [[37](#bib.bib37)] 利用对当前任务完成的自我反思，并将这些反思存储在情节记忆缓冲区中，以增强后续试验中的决策能力。
- en: 'We also include an ablation model, AvaTaR-C, which removes the comparator in
    our optimization pipeline. By default, we use Claude 3 Opus as the backbone LLM
    for all agent approaches in the main paper and report part of results using GPT-4
    Turbo (0125) in Appendix [B](#A2 "Appendix B Additional Experimental Results ‣
    AvaTaR: Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval").'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '我们还包括了一个消融模型 AvaTaR-C，该模型在我们的优化管道中去除了比较器。默认情况下，我们在主文中对所有代理方法使用 Claude 3 Opus
    作为基础 LLM，并在附录 [B](#A2 "Appendix B Additional Experimental Results ‣ AvaTaR: Optimizing
    LLM Agents for Tool-Assisted Knowledge Retrieval") 中报告了一部分使用 GPT-4 Turbo (0125)
    的结果。'
- en: 'Function library. Our function library (Appendix [D](#A4 "Appendix D Function
    library ‣ AvaTaR: Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval"))
    consists of twenty-eight functions that facilitate access to, operation on, and
    reasoning over the knowledge information by LLM agents. We used the same function
    library for ReAct, Reflexion, and AvaTaR agents.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '功能库。我们的功能库（附录 [D](#A4 "Appendix D Function library ‣ AvaTaR: Optimizing LLM
    Agents for Tool-Assisted Knowledge Retrieval")）包括二十八个功能，方便 LLM 代理访问、操作和推理知识信息。我们为
    ReAct、Reflexion 和 AvaTaR 代理使用了相同的功能库。'
- en: General pipeline. For AvaTaR, we leverage the same implementation, including
    the same structure of the initial prompts, the metric Recall@20 for constructing
    positive and negative queries, and hyperparameters ($\ell=h=0.5$), for all four
    datasets. Initially developed for STaRK-Amazon , this pipeline was then directly
    applied to the other datasets.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 一般管道。对于 AvaTaR，我们利用相同的实现，包括初始提示的相同结构、用于构建正负查询的指标 Recall@20 和超参数（$\ell=h=0.5$），适用于所有四个数据集。最初为
    STaRK-Amazon 开发的管道随后被直接应用于其他数据集。
- en: 5.1 Textual and Relational Retrieval Tasks
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 文本和关系检索任务
- en: 'We employ the Amazon, MAG, and Prime datasets from the STaRK benchmark [[44](#bib.bib44)],
    a large-scale semi-structured retrieval benchmark that integrates textual and
    relational knowledge (cf. detailed description in Appendix [A](#A1 "Appendix A
    Retrieval Tasks ‣ AvaTaR: Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval")).
    Here, the entities to be retrieved are defined as nodes in a graph structure,
    the knowledge associated with each entity includes both textual descriptions and
    relational data about the entities. We used the official splits in STaRK benchmark.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '我们使用 STaRK 基准测试中的 Amazon、MAG 和 Prime 数据集 [[44](#bib.bib44)]，这是一个大规模半结构化检索基准，集成了文本和关系知识（详见附录
    [A](#A1 "Appendix A Retrieval Tasks ‣ AvaTaR: Optimizing LLM Agents for Tool-Assisted
    Knowledge Retrieval")）。在这里，待检索的实体被定义为图结构中的节点，每个实体关联的知识包括文本描述和有关实体的关系数据。我们使用了 STaRK
    基准测试中的官方分割。'
- en: 'Takeaway 1: AvaTaR outperforms the state-of-the-art models. Table [2](#S5.T2
    "Table 2 ‣ 5.1 Textual and Relational Retrieval Tasks ‣ 5 Experiments ‣ AvaTaR:
    Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval") shows that AvaTaR
    substantially outperforms leading models such as Reflexion across all metrics
    on the STaRK benchmark. To highlight, the average improvement of AvaTaR is 15.6%
    on Hit@1 and 9.5% on MRR. ReAct agents, however, can not optimized from instructions
    on better tool usage and tend to select tools based on the LLM’s prior knowledge,
    which may not be optimal for the given task. We observe that ReAct agents applied
    highly similar tools across various queries and are hard to “jump out of the box”
    for better tool usage even with extensive in-context reasoning. In Appendix [B](#A2
    "Appendix B Additional Experimental Results ‣ AvaTaR: Optimizing LLM Agents for
    Tool-Assisted Knowledge Retrieval"), we provide results of the agent methods using
    GPT-4 Turbo, which has similar conclusions discussed here.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '关键点 1：AvaTaR 优于最先进的模型。表格 [2](#S5.T2 "Table 2 ‣ 5.1 Textual and Relational Retrieval
    Tasks ‣ 5 Experiments ‣ AvaTaR: Optimizing LLM Agents for Tool-Assisted Knowledge
    Retrieval") 显示，AvaTaR 在 STaRK 基准测试中的所有指标上大幅超越了领先模型如 Reflexion。特别是，AvaTaR 在 Hit@1
    上的平均提升为 15.6%，在 MRR 上为 9.5%。然而，ReAct 代理无法通过指令优化工具使用，通常根据 LLM 的先前知识选择工具，这可能对给定任务并不最优。我们观察到
    ReAct 代理在各种查询中使用了高度相似的工具，即使在广泛的上下文推理下也难以“跳出框框”以实现更好的工具使用。在附录 [B](#A2 "Appendix
    B Additional Experimental Results ‣ AvaTaR: Optimizing LLM Agents for Tool-Assisted
    Knowledge Retrieval") 中，我们提供了使用 GPT-4 Turbo 的代理方法的结果，与这里讨论的结论类似。'
- en: 'Takeaway 2: Comparator greatly impacts the actor’s performance. The comparison
    of AvaTaR with its ablation variant, AvaTaR-C, highlights the significant advantages
    of the comparator module. Although AvaTaR-C conducts validity and timeout checks,
    integrating Comparator into AvaTaR adds a comprehensive instruction mechanism
    that is crucial for identify clear directions to improve the agents, underlining
    comparator’s key role in optimizing actor.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '重点 2: 比较器对代理的表现影响巨大。将 AvaTaR 与其消融变体 AvaTaR-C 进行比较，突显了比较器模块的显著优势。尽管 AvaTaR-C
    进行了有效性和超时检查，但将比较器集成到 AvaTaR 中，添加了一个全面的指令机制，这对于确定改善代理的明确方向至关重要，强调了比较器在优化代理中的关键作用。'
- en: 'Table 2: Retrieval performance (%) on STaRK benchmark. Last row shows the relative
    improvements over the best metric value in each column.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '表 2: STaRK 基准上的检索性能（%）。最后一行显示了每列中最佳指标值的相对提升。'
- en: '|  | Amazon | MAG | Prime |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '|  | Amazon | MAG | Prime |'
- en: '|  | Hit@1 | Hit@5 | R@20 | MRR | Hit@1 | Hit@5 | R@20 | MRR | Hit@1 | Hit@5
    | R@20 | MRR |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '|  | Hit@1 | Hit@5 | R@20 | MRR | Hit@1 | Hit@5 | R@20 | MRR | Hit@1 | Hit@5
    | R@20 | MRR |'
- en: '| Dense Retr. | 15.29 | 47.93 | 44.49 | 30.20 | 10.51 | 35.23 | 42.11 | 21.34
    | 4.46 | 21.85 | 30.13 | 12.38 |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| Dense Retr. | 15.29 | 47.93 | 44.49 | 30.20 | 10.51 | 35.23 | 42.11 | 21.34
    | 4.46 | 21.85 | 30.13 | 12.38 |'
- en: '| QAGNN | 26.56 | 50.01 | 52.05 | 37.75 | 12.88 | 39.01 | 46.97 | 29.12 | 8.85
    | 21.35 | 29.63 | 14.73 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| QAGNN | 26.56 | 50.01 | 52.05 | 37.75 | 12.88 | 39.01 | 46.97 | 29.12 | 8.85
    | 21.35 | 29.63 | 14.73 |'
- en: '| VSS | 39.16 | 62.73 | 53.29 | 50.35 | 29.08 | 49.61 | 48.36 | 38.62 | 12.63
    | 31.49 | 36.00 | 21.41 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| VSS | 39.16 | 62.73 | 53.29 | 50.35 | 29.08 | 49.61 | 48.36 | 38.62 | 12.63
    | 31.49 | 36.00 | 21.41 |'
- en: '| Multi-VSS | 40.07 | 64.98 | 55.12 | 51.55 | 25.92 | 50.43 | 50.80 | 36.94
    | 15.10 | 33.56 | 38.05 | 23.49 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| Multi-VSS | 40.07 | 64.98 | 55.12 | 51.55 | 25.92 | 50.43 | 50.80 | 36.94
    | 15.10 | 33.56 | 38.05 | 23.49 |'
- en: '| ReAct | 42.14 | 64.56 | 50.81 | 52.30 | 31.07 | 49.49 | 47.03 | 39.25 | 15.28
    | 31.95 | 33.63 | 22.76 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| ReAct | 42.14 | 64.56 | 50.81 | 52.30 | 31.07 | 49.49 | 47.03 | 39.25 | 15.28
    | 31.95 | 33.63 | 22.76 |'
- en: '| Reflexion | 42.79 | 65.05 | 54.70 | 52.91 | 40.71 | 54.44 | 49.55 | 47.06
    | 14.28 | 34.99 | 38.52 | 24.82 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| Reflexion | 42.79 | 65.05 | 54.70 | 52.91 | 40.71 | 54.44 | 49.55 | 47.06
    | 14.28 | 34.99 | 38.52 | 24.82 |'
- en: '| AvaTaR-C | 40.92 | 63.63 | 53.68 | 51.73 | 33.25 | 52.17 | 47.88 | 41.34
    | 8.82 | 23.82 | 30.32 | 16.20 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| AvaTaR-C | 40.92 | 63.63 | 53.68 | 51.73 | 33.25 | 52.17 | 47.88 | 41.34
    | 8.82 | 23.82 | 30.32 | 16.20 |'
- en: '| AvaTaR | 49.87 | 69.16 | 60.57 | 58.70 | 44.36 | 59.66 | 50.63 | 51.15 |
    18.44 | 36.73 | 39.31 | 26.73 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| AvaTaR | 49.87 | 69.16 | 60.57 | 58.70 | 44.36 | 59.66 | 50.63 | 51.15 |
    18.44 | 36.73 | 39.31 | 26.73 |'
- en: '| Relative | 16.6% | 6.3% | 9.9% | 12.2% | 9.6% | 2.1% | -0.3% | 8.7% | 20.7%
    | 5.0% | 2.1% | 7.7% |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| Relative | 16.6% | 6.3% | 9.9% | 12.2% | 9.6% | 2.1% | -0.3% | 8.7% | 20.7%
    | 5.0% | 2.1% | 7.7% |'
- en: '| Improvement | ![Refer to caption](img/38cc352de7f161f974ca07996f71a23f.png)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '| Improvement | ![Refer to caption](img/38cc352de7f161f974ca07996f71a23f.png)'
- en: 'Figure 4: Optimization dynamics of AvaTaR agents on STaRK. The figures show
    the validation performance (solid line) and their moving average (dash line) during
    the optimization of AvaTaR.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '图 4: AvaTaR 代理在 STaRK 上的优化动态。图中展示了在 AvaTaR 优化过程中的验证性能（实线）及其移动平均（虚线）。'
- en: 'Takeaway 3: AvaTaR effectively improves the agents during optimization. Figure [4](#S5.F4
    "Figure 4 ‣ 5.1 Textual and Relational Retrieval Tasks ‣ 5 Experiments ‣ AvaTaR:
    Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval") illustrates the
    agents’ performance on the validation set during optimization. Impressively, we
    found that AvaTaR agents can significantly enhance performance, e.g., improving
    from 35% to 75% on Amazon and from 20% to 78% on MAG. This evidence strongly supports
    the effectiveness of the instructions generated by our comparator. Moreover, our
    memory bank, which stores past best-performing actions, encourages AvaTaR agents
    to gradually converge by the end of the optimization process.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '重点 3: AvaTaR 在优化过程中有效提升了代理的性能。图 [4](#S5.F4 "Figure 4 ‣ 5.1 Textual and Relational
    Retrieval Tasks ‣ 5 Experiments ‣ AvaTaR: Optimizing LLM Agents for Tool-Assisted
    Knowledge Retrieval") 说明了代理在优化过程中的验证集表现。令人印象深刻的是，我们发现 AvaTaR 代理可以显著提升性能，例如，在 Amazon
    上从 35% 提升至 75%，在 MAG 上从 20% 提升至 78%。这一证据强烈支持我们比较器生成的指令的有效性。此外，我们的记忆库存储了过去表现最佳的操作，鼓励
    AvaTaR 代理在优化过程结束时逐渐收敛。'
- en: 'Takeaway 4: AvaTaR can generalize to real-world tasks. Comparator suggests
    instructions tailored to a group of queries, which encourages agents to make more
    general modifications and generalize to novel queries. We validate this improved
    generalization capability by directly applying the optimized actions to the leave-out
    queries generated by humans from STaRK benchmark. These human-generated queries
    exhibit a more distinct distribution than the question-answering pairs used to
    optimize the agents in our framework. We report the results in Table [4](#A2.T4
    "Table 4 ‣ Appendix B Additional Experimental Results ‣ AvaTaR: Optimizing LLM
    Agents for Tool-Assisted Knowledge Retrieval") (Appendix [B](#A2 "Appendix B Additional
    Experimental Results ‣ AvaTaR: Optimizing LLM Agents for Tool-Assisted Knowledge
    Retrieval")) which shows that AvaTaR significantly outperforms other models, achieving
    an average improvement of 20.9% on Hit@1, demonstrating strong generalization
    across diverse human-generated queries.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 收获 4：AvaTaR可以推广到现实世界任务。比较器建议针对一组查询量身定制的指令，这鼓励代理进行更一般性的修改，并推广到新的查询。我们通过直接将优化后的动作应用于STaRK基准中由人类生成的留出查询来验证这种改进的泛化能力。这些人类生成的查询表现出比用来优化我们框架中的代理的问答对更为显著的分布差异。我们在表 [4](#A2.T4
    "表 4 ‣ 附录 B 额外实验结果 ‣ AvaTaR：优化LLM代理以支持工具辅助知识检索")（附录 [B](#A2 "附录 B 额外实验结果 ‣ AvaTaR：优化LLM代理以支持工具辅助知识检索")）中报告了结果，显示AvaTaR在Hit@1上的平均改进达20.9%，显著优于其他模型，表现出对多样化人类生成查询的强大泛化能力。
- en: 5.2 Image Retrieval Task
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 图像检索任务
- en: 'We further experiment on Flickr30K Entities [[31](#bib.bib31)], which focuses
    on image retrieval with 30k images representing the entity set. This dataset (Appendix [A](#A1
    "Appendix A Retrieval Tasks ‣ AvaTaR: Optimizing LLM Agents for Tool-Assisted
    Knowledge Retrieval")) enriches the entity information with pixel values and annotated
    bounding boxes along with their descriptive phrases. In Table [2](#S5.T2 "Table
    2 ‣ 5.1 Textual and Relational Retrieval Tasks ‣ 5 Experiments ‣ AvaTaR: Optimizing
    LLM Agents for Tool-Assisted Knowledge Retrieval"), AvaTaR again presents significant
    improvements. Particularly, the Reflexion agents struggle with this task due to
    “overfitting” where they are easily misled by specific image data, leading to
    inappropriate actions. For example, they might attempt to “extract the color of
    a hat” from images that do not contain a hat. In contrast, AvaTaR effectively
    avoids such pitfalls by employing the batch-wise contrastive reasoning that incorporates
    a more global perspective.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进一步在Flickr30K Entities [[31](#bib.bib31)]上进行实验，该数据集专注于图像检索，包含30k张代表实体集的图像。该数据集（附录 [A](#A1
    "附录 A 检索任务 ‣ AvaTaR：优化LLM代理以支持工具辅助知识检索")）通过像素值和注释边界框以及描述性短语丰富了实体信息。在表 [2](#S5.T2
    "表 2 ‣ 5.1 文本和关系检索任务 ‣ 5 实验 ‣ AvaTaR：优化LLM代理以支持工具辅助知识检索")中，AvaTaR再次展示了显著的改进。特别是，Reflexion代理在这个任务中表现不佳，原因是“过拟合”，它们容易被特定的图像数据误导，从而导致不适当的行为。例如，它们可能会试图从不包含帽子的图像中“提取帽子的颜色”。相比之下，AvaTaR通过采用批量对比推理，从更全球的角度有效地避免了这些陷阱。
- en: 'Takeaway 5: AvaTaR generates impressive and generalizable actions. The final
    actions of the AvaTaR agent achieve the advanced performance reported in Figure [5](#S5.F5
    "Figure 5 ‣ 5.2 Image Retrieval Task ‣ 5 Experiments ‣ AvaTaR: Optimizing LLM
    Agents for Tool-Assisted Knowledge Retrieval") (left). We present these actions
    in Figure [8](#A3.F8 "Figure 8 ‣ Appendix C Prompts ‣ AvaTaR: Optimizing LLM Agents
    for Tool-Assisted Knowledge Retrieval") (Appendix [B](#A2 "Appendix B Additional
    Experimental Results ‣ AvaTaR: Optimizing LLM Agents for Tool-Assisted Knowledge
    Retrieval")) due to space constraints. Notably, AvaTaR effectively handles the
    input query and impressively performs actions that leverage Inverse Document Frequency
    (IDF) scores to reweight phrase matching scores, ultimately synthesizing the final
    answers. Besides utilizing existing tools, AvaTaR agents can also develop high-level
    tools based on existing ones, such as the tool for reweighting phrase match scores
    by IDF scores. This capability suggests a future direction to maintain a dynamic
    tool library and generate instructions to enhance tool generation.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 关键点5：AvaTaR生成了令人印象深刻且具有普遍适用性的动作。AvaTaR代理的最终动作在图[5](#S5.F5 "图5 ‣ 5.2 图像检索任务 ‣
    5 实验 ‣ AvaTaR：优化用于工具辅助知识检索的LLM代理")（左）中实现了先进的性能。由于空间限制，我们在图[8](#A3.F8 "图8 ‣ 附录C
    提示 ‣ AvaTaR：优化用于工具辅助知识检索的LLM代理")（附录[B](#A2 "附录B 额外实验结果 ‣ AvaTaR：优化用于工具辅助知识检索的LLM代理")中展示了这些动作。值得注意的是，AvaTaR有效处理输入查询，并通过利用逆文档频率（IDF）分数来重新加权短语匹配分数，最终合成最终答案。除了利用现有工具外，AvaTaR代理还可以基于现有工具开发高级工具，例如通过IDF分数重新加权短语匹配分数的工具。这一能力暗示了未来的方向，即维持一个动态工具库，并生成指令以增强工具生成。
- en: '|  | Hit@1 | Hit@5 | R@20 | MRR |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '|  | Hit@1 | Hit@5 | R@20 | MRR |'
- en: '| VSS (clip-vit-large-patch14) | 37.2 | 56.4 | 72.8 | 46.3 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| VSS (clip-vit-large-patch14) | 37.2 | 56.4 | 72.8 | 46.3 |'
- en: '| ReAct (claude3) | 38.8 | 54.8 | 71.6 | 46.1 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| ReAct (claude3) | 38.8 | 54.8 | 71.6 | 46.1 |'
- en: '| Reflexion (claude3) | 28.4 | 53.2 | 75.2 | 41.2 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| Reflexion (claude3) | 28.4 | 53.2 | 75.2 | 41.2 |'
- en: '| AvaTaR-C (claude3) | 28.8 | 53.2 | 78.4 | 40.0 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| AvaTaR-C (claude3) | 28.8 | 53.2 | 78.4 | 40.0 |'
- en: '| AvaTaR (claude3) | 42.4 | 63.0 | 79.2 | 52.3 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| AvaTaR (claude3) | 42.4 | 63.0 | 79.2 | 52.3 |'
- en: '| Relative Improvement | 9.2% | 11.7% | 5.3% | 13.0% | ![Refer to caption](img/e2da32c7a288e84d408e37bcd01f8dbd.png)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '| 相对提升 | 9.2% | 11.7% | 5.3% | 13.0% | ![参考图注](img/e2da32c7a288e84d408e37bcd01f8dbd.png)'
- en: 'Figure 5: Performance (left) and AvaTaR’s optimization dynamics (right) on
    Flickr30K-Entities.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：在Flickr30K-Entities上的性能（左）和AvaTaR的优化动态（右）。
- en: '![Refer to caption](img/c86b117bdfef93e5a5ae576ae9de7858.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![参考图注](img/c86b117bdfef93e5a5ae576ae9de7858.png)'
- en: 'Figure 6: Representative instruction types from the comparator. We provide
    three cases where the comparator guides the actor towards (1) better divide-and-conquer
    strategies for multi-step problem-solving, (2) more sensible differentiation between
    good and bad tool usage/combinations, and (3) adjustments in the weights to generate
    the final answers. We record the number of occurrences $X$/25).'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：来自比较器的代表性指令类型。我们提供了三个案例，其中比较器引导行为者实现（1）更好的多步骤问题解决的分而治之策略，（2）更合理地区分优质和劣质工具使用/组合，以及（3）调整权重以生成最终答案。我们记录了出现的次数
    $X$/25。
- en: 'Takeaway 6: Emerging Behaviors during Optimization. In Figure [6](#S5.F6 "Figure
    6 ‣ 5.2 Image Retrieval Task ‣ 5 Experiments ‣ AvaTaR: Optimizing LLM Agents for
    Tool-Assisted Knowledge Retrieval"), we present concrete cases illustrating key
    interactions between actor and comparator . In each instance, comparator identifies
    critical flaws, including information omission, ineffective tool usage, and suboptimal
    synthesis of varying scores. The instructions subsequently prompt actor to enhance
    retrieval strategies, tool selection, and precise score combinations. Furthermore,
    the frequent references to tool usage underscore comparator ’s dedicated examination
    of tool utilization during optimization.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 关键点6：优化过程中的新兴行为。在图[6](#S5.F6 "图6 ‣ 5.2 图像检索任务 ‣ 5 实验 ‣ AvaTaR：优化用于工具辅助知识检索的LLM代理")中，我们展示了具体的案例，说明了行为者和比较器之间的关键互动。在每个实例中，比较器识别出关键缺陷，包括信息遗漏、工具使用无效以及分数合成不佳。随后，指令促使行为者改进检索策略、工具选择和精确的分数组合。此外，频繁提及工具使用强调了比较器在优化过程中对工具使用的专门检查。
- en: 6 Conclusion
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: In this study, we introduce AvaTaR, a novel framework that automates the optimization
    of LLM agents for enhanced tool utilization in multi-step problems with a focus
    on complex retrieval tasks. AvaTaR demonstrates remarkable improvements across
    four diverse datasets. This success can largely be attributed to the comparator
    module, which effectively refines agent performance through the iterative generation
    of holistic and strategic prompts. A key innovation of comparator is its use of
    contrastive reasoning with batch-wise sampling, enabling it to identify systemic
    flaws and extract robust "gradients" for comprehensive agent improvement across
    diverse scenarios. Future work can explore extending this methodology to other
    agent tasks and more dynamic environments.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项研究中，我们介绍了AvaTaR，这是一种新颖的框架，自动优化LLM代理以提高在多步骤问题中工具的使用，特别关注复杂的检索任务。AvaTaR在四个不同的数据集上显示了显著的改进。这一成功主要归功于比较器模块，该模块通过迭代生成全面而有策略的提示，有效地提升了代理的性能。比较器的一个关键创新是其使用对比推理和批量采样，使其能够识别系统性缺陷，并提取强健的“梯度”以全面提升代理在不同场景中的表现。未来的工作可以探索将这种方法扩展到其他代理任务和更动态的环境中。
- en: Acknowledgement
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: We thank lab members in Zou and Leskovec’s labs for discussions and for providing
    feedback on our manuscript. We also gratefully acknowledge the support of DARPA
    under Nos. N660011924033 (MCS); NSF under Nos. OAC-1835598 (CINES), CCF-1918940
    (Expeditions), DMS-2327709 (IHBEM); Stanford Data Applications Initiative, Wu
    Tsai Neurosciences Institute, Stanford Institute for Human-Centered AI, Chan Zuckerberg
    Initiative, Amazon, Genentech, GSK, Hitachi, SAP, and UCB. The content is solely
    the responsibility of the authors and does not necessarily represent the official
    views of the funding entities.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢Zou和Leskovec实验室的成员进行讨论并提供对我们手稿的反馈。我们也衷心感谢DARPA（编号N660011924033 (MCS)）、NSF（编号OAC-1835598
    (CINES)、CCF-1918940 (Expeditions)、DMS-2327709 (IHBEM)）、斯坦福数据应用倡议、吴蔡神经科学研究所、斯坦福人类中心AI研究所、Chan
    Zuckerberg Initiative、亚马逊、Genentech、GSK、日立、SAP 和 UCB的支持。内容仅代表作者的观点，并不一定代表资助机构的官方观点。
- en: REFERENCES
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1]'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1]'
- en: 'Besta et al. [[n. d.]] Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger,
    Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski,
    Piotr Nyczyk, and Torsten Hoefler. [n. d.]. Graph of Thoughts: Solving Elaborate
    Problems with Large Language Models. ([n. d.]). arXiv:2308.09687'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Besta et al. [[n. d.]] Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger,
    Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski,
    Piotr Nyczyk, 和 Torsten Hoefler. [n. d.]. 思维图谱：使用大型语言模型解决复杂问题. ([n. d.]). arXiv:2308.09687
- en: Borgeaud et al. [2022] Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor
    Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste
    Lespiau, Bogdan Damoc, Aidan Clark, Diego de Las Casas, Aurelia Guy, Jacob Menick,
    Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer,
    Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero,
    Karen Simonyan, Jack W. Rae, Erich Elsen, and Laurent Sifre. 2022. Improving Language
    Models by Retrieving from Trillions of Tokens. In *ICML*.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Borgeaud et al. [2022] Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor
    Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste
    Lespiau, Bogdan Damoc, Aidan Clark, Diego de Las Casas, Aurelia Guy, Jacob Menick,
    Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer,
    Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero,
    Karen Simonyan, Jack W. Rae, Erich Elsen, 和 Laurent Sifre. 2022. 通过从万亿标记中检索来改进语言模型.
    在 *ICML* 中.
- en: 'Chen et al. [2023b] Baian Chen, Chang Shu, Ehsan Shareghi, Nigel Collier, Karthik
    Narasimhan, and Shunyu Yao. 2023b. FireAct: Toward Language Agent Fine-tuning.
    arXiv:2310.05915'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chen et al. [2023b] Baian Chen, Chang Shu, Ehsan Shareghi, Nigel Collier, Karthik
    Narasimhan, 和 Shunyu Yao. 2023b. FireAct: 朝向语言代理的微调. arXiv:2310.05915'
- en: Chen et al. [2023a] Xinyun Chen, Maxwell Lin, Nathanael Schärli, and Denny Zhou.
    2023a. Teaching Large Language Models to Self-Debug. (2023).
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. [2023a] Xinyun Chen, Maxwell Lin, Nathanael Schärli, 和 Denny Zhou.
    2023a. 教授大型语言模型自我调试. (2023).
- en: 'Deng et al. [2022] Mingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan Wang,
    Han Guo, Tianmin Shu, Meng Song, Eric P. Xing, and Zhiting Hu. 2022. RLPrompt:
    Optimizing Discrete Text Prompts with Reinforcement Learning. In *EMNLP*. ACL.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Deng et al. [2022] Mingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan Wang,
    Han Guo, Tianmin Shu, Meng Song, Eric P. Xing, 和 Zhiting Hu. 2022. RLPrompt: 使用强化学习优化离散文本提示.
    在 *EMNLP* 中. ACL.'
- en: 'Durante et al. [[n. d.]] Zane Durante, Qiuyuan Huang, Naoki Wake, Ran Gong,
    Jae Sung Park, Bidipta Sarkar, Rohan Taori, Yusuke Noda, Demetri Terzopoulos,
    Yejin Choi, Katsushi Ikeuchi, Hoi Vo, Li Fei-Fei, and Jianfeng Gao. [n. d.]. Agent
    AI: Surveying the Horizons of Multimodal Interaction. ([n. d.]). arXiv:2401.03568'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Durante 等人 [[n. d.]] Zane Durante, Qiuyuan Huang, Naoki Wake, Ran Gong, Jae
    Sung Park, Bidipta Sarkar, Rohan Taori, Yusuke Noda, Demetri Terzopoulos, Yejin
    Choi, Katsushi Ikeuchi, Hoi Vo, Li Fei-Fei, 和 Jianfeng Gao. [n. d.]. Agent AI:
    调查多模态交互的前景。 ([n. d.]). arXiv:2401.03568'
- en: 'Gong et al. [[n. d.]] Ran Gong, Qiuyuan Huang, Xiaojian Ma, Hoi Vo, Zane Durante,
    Yusuke Noda, Zilong Zheng, Song-Chun Zhu, Demetri Terzopoulos, Li Fei-Fei, and
    Jianfeng Gao. [n. d.]. MindAgent: Emergent Gaming Interaction. ([n. d.]). arXiv:2309.09971'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gong 等人 [[n. d.]] Ran Gong, Qiuyuan Huang, Xiaojian Ma, Hoi Vo, Zane Durante,
    Yusuke Noda, Zilong Zheng, Song-Chun Zhu, Demetri Terzopoulos, Li Fei-Fei, 和 Jianfeng
    Gao. [n. d.]. MindAgent: 新兴游戏交互。 ([n. d.]). arXiv:2309.09971'
- en: Guu et al. [2020] Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Mingwei
    Chang. 2020. Retrieval augmented language model pre-training. In *ICML*. PMLR.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guu 等人 [2020] Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, 和 Mingwei
    Chang. 2020. 检索增强语言模型预训练。在 *ICML* 中。PMLR。
- en: Han et al. [2024] Simon Jerome Han, Keith J. Ransom, Andrew Perfors, and Charles
    Kemp. 2024. Inductive reasoning in humans and large language models. *Cogn. Syst.
    Res.* (2024).
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Han 等人 [2024] Simon Jerome Han, Keith J. Ransom, Andrew Perfors, 和 Charles Kemp.
    2024. 人类和大型语言模型中的归纳推理。 *Cogn. Syst. Res.* (2024).
- en: 'He et al. [2024] Xiaoxin He, Yijun Tian, Yifei Sun, Nitesh V. Chawla, Thomas
    Laurent, Yann LeCun, Xavier Bresson, and Bryan Hooi. 2024. G-Retriever: Retrieval-Augmented
    Generation for Textual Graph Understanding and Question Answering. (2024). arXiv:2402.07630'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'He 等人 [2024] Xiaoxin He, Yijun Tian, Yifei Sun, Nitesh V. Chawla, Thomas Laurent,
    Yann LeCun, Xavier Bresson, 和 Bryan Hooi. 2024. G-Retriever: 用于文本图理解和问答的检索增强生成。
    (2024). arXiv:2402.07630'
- en: Hou et al. [2023] Yupeng Hou, Junjie Zhang, Zihan Lin, Hongyu Lu, Ruobing Xie,
    Julian McAuley, and Wayne Xin Zhao. 2023. Large language models are zero-shot
    rankers for recommender systems. *arXiv:2305.08845* (2023).
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hou 等人 [2023] Yupeng Hou, Junjie Zhang, Zihan Lin, Hongyu Lu, Ruobing Xie, Julian
    McAuley, 和 Wayne Xin Zhao. 2023. 大型语言模型是推荐系统的零-shot 排序器。 *arXiv:2305.08845* (2023).
- en: 'Huang et al. [2022a] Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor
    Mordatch. 2022a. Language Models as Zero-Shot Planners: Extracting Actionable
    Knowledge for Embodied Agents. In *ICML*.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等人 [2022a] Wenlong Huang, Pieter Abbeel, Deepak Pathak, 和 Igor Mordatch.
    2022a. 语言模型作为零-shot 规划器：为具身代理提取可操作的知识。在 *ICML* 中。
- en: 'Huang et al. [2022b] Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang,
    Pete Florence, Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, Pierre
    Sermanet, Tomas Jackson, Noah Brown, Linda Luu, Sergey Levine, Karol Hausman,
    and Brian Ichter. 2022b. Inner Monologue: Embodied Reasoning through Planning
    with Language Models. In *CoRL*.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等人 [2022b] Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang,
    Pete Florence, Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, Pierre
    Sermanet, Tomas Jackson, Noah Brown, Linda Luu, Sergey Levine, Karol Hausman,
    和 Brian Ichter. 2022b. 内在对话：通过语言模型进行具身推理。在 *CoRL* 中。
- en: Ioannidis et al. [2022] Vassilis N Ioannidis, Xiang Song, Da Zheng, Houyu Zhang,
    Jun Ma, Yi Xu, Belinda Zeng, Trishul Chilimbi, and George Karypis. 2022. Efficient
    and effective training of language and graph neural network models. *arXiv preprint
    arXiv:2206.10781* (2022).
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ioannidis 等人 [2022] Vassilis N Ioannidis, Xiang Song, Da Zheng, Houyu Zhang,
    Jun Ma, Yi Xu, Belinda Zeng, Trishul Chilimbi, 和 George Karypis. 2022. 高效且有效的语言和图神经网络模型训练。
    *arXiv 预印本 arXiv:2206.10781* (2022).
- en: 'Khattab et al. [2023] Omar Khattab, Keshav Santhanam, Xiang Lisa Li, David
    Hall, Percy Liang, Christopher Potts, and Matei Zaharia. 2023. Demonstrate-Search-Predict:
    Composing retrieval and language models for knowledge-intensive NLP. arXiv:2212.14024 [cs.CL]'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Khattab 等人 [2023] Omar Khattab, Keshav Santhanam, Xiang Lisa Li, David Hall,
    Percy Liang, Christopher Potts, 和 Matei Zaharia. 2023. Demonstrate-Search-Predict:
    组合检索和语言模型以应对知识密集型 NLP。 arXiv:2212.14024 [cs.CL]'
- en: 'Le et al. [2022] Hung Le, Yue Wang, Akhilesh Deepak Gotmare, Silvio Savarese,
    and Steven Chu-Hong Hoi. 2022. CodeRL: Mastering Code Generation through Pretrained
    Models and Deep Reinforcement Learning. In *NeurIPS*.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Le 等人 [2022] Hung Le, Yue Wang, Akhilesh Deepak Gotmare, Silvio Savarese, 和
    Steven Chu-Hong Hoi. 2022. CodeRL: 通过预训练模型和深度强化学习掌握代码生成。在 *NeurIPS* 中。'
- en: Lewis et al. [2021] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni,
    Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen tau Yih, Tim
    Rocktäschel, Sebastian Riedel, and Douwe Kiela. 2021. Retrieval-Augmented Generation
    for Knowledge-Intensive NLP Tasks. arXiv:2005.11401 [cs.CL]
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lewis 等人 [2021] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni,
    Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen tau Yih, Tim
    Rocktäschel, Sebastian Riedel, 和 Douwe Kiela. 2021. Retrieval-Augmented Generation
    for Knowledge-Intensive NLP Tasks. arXiv:2005.11401 [cs.CL]
- en: 'Li et al. [2023] Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii
    Khizbullin, and Bernard Ghanem. 2023. CAMEL: Communicative Agents for "Mind" Exploration
    of Large Scale Language Model Society. abs/2303.17760 (2023). arXiv:2303.17760'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li 等 [2023] Guohao Li、Hasan Abed Al Kader Hammoud、Hani Itani、Dmitrii Khizbullin
    和 Bernard Ghanem。2023年。《CAMEL: 大规模语言模型社会的“心智”探索的沟通代理》。abs/2303.17760（2023）。arXiv:2303.17760'
- en: 'Liu et al. [2023] Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu
    Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng,
    Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan
    Sun, Minlie Huang, Yuxiao Dong, and Jie Tang. 2023. AgentBench: Evaluating LLMs
    as Agents. (2023). arXiv:2308.03688'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu 等 [2023] Xiao Liu、Hao Yu、Hanchen Zhang、Yifan Xu、Xuanyu Lei、Hanyu Lai、Yu
    Gu、Hangliang Ding、Kaiwen Men、Kejuan Yang、Shudan Zhang、Xiang Deng、Aohan Zeng、Zhengxiao
    Du、Chenhui Zhang、Sheng Shen、Tianjun Zhang、Yu Su、Huan Sun、Minlie Huang、Yuxiao Dong
    和 Jie Tang。2023年。《AgentBench: 评估 LLM 作为代理》。 （2023）。arXiv:2308.03688'
- en: 'Lo et al. [2023] Robert Lo, Abishek Sridhar, Frank Xu, Hao Zhu, and Shuyan
    Zhou. 2023. Hierarchical Prompting Assists Large Language Model on Web Navigation.
    In *Findings of the Association for Computational Linguistics: EMNLP 2023*.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lo 等 [2023] Robert Lo、Abishek Sridhar、Frank Xu、Hao Zhu 和 Shuyan Zhou。2023年。《分层提示助力大语言模型进行网页导航》。见于
    *Findings of the Association for Computational Linguistics: EMNLP 2023*。'
- en: 'Lu et al. [2023] Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang,
    Ying Nian Wu, Song-Chun Zhu, and Jianfeng Gao. 2023. Chameleon: Plug-and-Play
    Compositional Reasoning with Large Language Models. In *NeurIPS*.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lu 等 [2023] Pan Lu、Baolin Peng、Hao Cheng、Michel Galley、Kai-Wei Chang、Ying Nian
    Wu、Song-Chun Zhu 和 Jianfeng Gao。2023年。《Chameleon: 插拔式组合推理与大语言模型》。见于 *NeurIPS*。'
- en: 'Madaan et al. [2023] Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan,
    Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang,
    Shashank Gupta, Bodhisattwa Prasad Majumder, Katherine Hermann, Sean Welleck,
    Amir Yazdanbakhsh, and Peter Clark. 2023. Self-Refine: Iterative Refinement with
    Self-Feedback. In *NeurIPS*.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Madaan 等 [2023] Aman Madaan、Niket Tandon、Prakhar Gupta、Skyler Hallinan、Luyu
    Gao、Sarah Wiegreffe、Uri Alon、Nouha Dziri、Shrimai Prabhumoye、Yiming Yang、Shashank
    Gupta、Bodhisattwa Prasad Majumder、Katherine Hermann、Sean Welleck、Amir Yazdanbakhsh
    和 Peter Clark。2023年。《Self-Refine: 通过自我反馈进行迭代改进》。见于 *NeurIPS*。'
- en: 'Nakano et al. [2021] Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu,
    Ouyang Long, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju,
    William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin
    Button, Matthew Knight, Benjamin Chess, and John Schulman. 2021. WebGPT: Browser-assisted
    question-answering with human feedback. *ArXiv* (2021).'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Nakano 等 [2021] Reiichiro Nakano、Jacob Hilton、Suchir Balaji、Jeff Wu、Ouyang
    Long、Christina Kim、Christopher Hesse、Shantanu Jain、Vineet Kosaraju、William Saunders、Xu
    Jiang、Karl Cobbe、Tyna Eloundou、Gretchen Krueger、Kevin Button、Matthew Knight、Benjamin
    Chess 和 John Schulman。2021年。《WebGPT: 通过浏览器辅助的问答与人工反馈》。*ArXiv*（2021）。'
- en: 'Nakano et al. [[n. d.]] Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff
    Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju,
    William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin
    Button, Matthew Knight, Benjamin Chess, and John Schulman. [n. d.]. WebGPT: Browser-assisted
    question-answering with human feedback. ([n. d.]). arXiv:2112.09332'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Nakano 等 [[n. d.]] Reiichiro Nakano、Jacob Hilton、Suchir Balaji、Jeff Wu、Long
    Ouyang、Christina Kim、Christopher Hesse、Shantanu Jain、Vineet Kosaraju、William Saunders、Xu
    Jiang、Karl Cobbe、Tyna Eloundou、Gretchen Krueger、Kevin Button、Matthew Knight、Benjamin
    Chess 和 John Schulman。 [n. d.]。《WebGPT: 通过浏览器辅助的问答与人工反馈》。([n. d.])。arXiv:2112.09332'
- en: 'Packer et al. [2023] Charles Packer, Vivian Fang, Shishir G. Patil, Kevin Lin,
    Sarah Wooders, and Joseph E. Gonzalez. 2023. MemGPT: Towards LLMs as Operating
    Systems. 2310.08560 (2023).'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Packer 等 [2023] Charles Packer、Vivian Fang、Shishir G. Patil、Kevin Lin、Sarah
    Wooders 和 Joseph E. Gonzalez。2023年。《MemGPT: 朝着将 LLM 作为操作系统迈进》。2310.08560（2023）。'
- en: 'Paranjape et al. [2023] Bhargavi Paranjape, Scott Lundberg, Sameer Singh, Hannaneh
    Hajishirzi, Luke Zettlemoyer, and Marco Tulio Ribeiro. 2023. ART: Automatic multi-step
    reasoning and tool-use for large language models. *arXiv:2303.09014* (2023).'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Paranjape 等 [2023] Bhargavi Paranjape、Scott Lundberg、Sameer Singh、Hannaneh
    Hajishirzi、Luke Zettlemoyer 和 Marco Tulio Ribeiro。2023年。《ART: 大语言模型的自动化多步骤推理和工具使用》。*arXiv:2303.09014*（2023）。'
- en: 'Parisi et al. [2022] Aaron Parisi, Yao Zhao, and Noah Fiedel. 2022. TALM: Tool
    Augmented Language Models. arXiv:2205.12255'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Parisi 等 [2022] Aaron Parisi、Yao Zhao 和 Noah Fiedel。2022年。《TALM: 工具增强语言模型》。arXiv:2205.12255'
- en: 'Patil et al. [2023] Shishir G. Patil, Tianjun Zhang, Xin Wang, and Joseph E.
    Gonzalez. 2023. Gorilla: Large Language Model Connected with Massive APIs. *CoRR*
    (2023). arXiv:2305.15334'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Patil 等 [2023] Shishir G. Patil、Tianjun Zhang、Xin Wang 和 Joseph E. Gonzalez。2023年。《Gorilla:
    连接大量 API 的大语言模型》。*CoRR*（2023）。arXiv:2305.15334'
- en: 'Peng et al. [2023] Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng, Yujia
    Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou Yu, Weizhu Chen, and Jianfeng Gao.
    2023. Check Your Facts and Try Again: Improving Large Language Models with External
    Knowledge and Automated Feedback. *arxiv* 2302.12813 (2023).'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Peng 等 [2023] Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng, Yujia Xie,
    Yu Hu, Qiuyuan Huang, Lars Liden, Zhou Yu, Weizhu Chen, 和 Jianfeng Gao. 2023.
    检查你的事实并重试: 用外部知识和自动化反馈改进大型语言模型。 *arxiv* 2302.12813 (2023)。'
- en: 'Plummer et al. [2017] Bryan A. Plummer, Liwei Wang, Chris M. Cervantes, Juan C.
    Caicedo, Julia Hockenmaier, and Svetlana Lazebnik. 2017. Flickr30k Entities: Collecting
    Region-to-Phrase Correspondences for Richer Image-to-Sentence Models. *Int. J.
    Comput. Vis.* (2017).'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Plummer 等 [2017] Bryan A. Plummer, Liwei Wang, Chris M. Cervantes, Juan C.
    Caicedo, Julia Hockenmaier, 和 Svetlana Lazebnik. 2017. Flickr30k Entities: 收集区域到短语的对应关系以增强图像到句子的模型。
    *Int. J. Comput. Vis.* (2017)。'
- en: 'Qin et al. [2023a] Yujia Qin, Zihan Cai, Dian Jin, Lan Yan, Shihao Liang, Kunlun
    Zhu, Yankai Lin, Xu Han, Ning Ding, Huadong Wang, Ruobing Xie, Fanchao Qi, Zhiyuan
    Liu, Maosong Sun, and Jie Zhou. 2023a. WebCPM: Interactive Web Search for Chinese
    Long-form Question Answering. In *Proceedings of ACL 2023*. Association for Computational
    Linguistics.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Qin 等 [2023a] Yujia Qin, Zihan Cai, Dian Jin, Lan Yan, Shihao Liang, Kunlun
    Zhu, Yankai Lin, Xu Han, Ning Ding, Huadong Wang, Ruobing Xie, Fanchao Qi, Zhiyuan
    Liu, Maosong Sun, 和 Jie Zhou. 2023a. WebCPM: 用于中文长篇问答的互动网络搜索。发表于 *Proceedings
    of ACL 2023*。计算语言学协会。'
- en: 'Qin et al. [2023b] Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan,
    Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Runchu Tian,
    Ruobing Xie, Jie Zhou, Mark Gerstein, Dahai Li, Zhiyuan Liu, and Maosong Sun.
    2023b. ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world
    APIs. *arxiv* 2307.16789 (2023).'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Qin 等 [2023b] Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi
    Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Runchu Tian, Ruobing
    Xie, Jie Zhou, Mark Gerstein, Dahai Li, Zhiyuan Liu, 和 Maosong Sun. 2023b. ToolLLM:
    促进大型语言模型掌握 16000+ 实际 API。 *arxiv* 2307.16789 (2023)。'
- en: 'Schick et al. [2023] Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu,
    Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom.
    2023. Toolformer: Language Models Can Teach Themselves to Use Tools. In *NeurIPS*.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Schick 等 [2023] Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu,
    Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, 和 Thomas Scialom.
    2023. Toolformer: 语言模型可以自学使用工具。发表于 *NeurIPS*。'
- en: 'Shen et al. [2023] Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming
    Lu, and Yueting Zhuang. 2023. HuggingGPT: Solving AI Tasks with ChatGPT and its
    Friends in Hugging Face. In *NeurIPS*.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shen 等 [2023] Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu,
    和 Yueting Zhuang. 2023. HuggingGPT: 使用 ChatGPT 和其在 Hugging Face 的伙伴解决 AI 任务。发表于
    *NeurIPS*。'
- en: 'Shi et al. [2024] Wenqi Shi, Ran Xu, Yuchen Zhuang, Yue Yu, Jieyu Zhang, Hang
    Wu, Yuanda Zhu, Joyce Ho, Carl Yang, and May D Wang. 2024. EHRAgent: Code Empowers
    Large Language Models for Complex Tabular Reasoning on Electronic Health Records.
    *arXiv:2401.07128* (2024).'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shi 等 [2024] Wenqi Shi, Ran Xu, Yuchen Zhuang, Yue Yu, Jieyu Zhang, Hang Wu,
    Yuanda Zhu, Joyce Ho, Carl Yang, 和 May D Wang. 2024. EHRAgent: 代码增强大语言模型在电子健康记录中的复杂表格推理能力。
    *arXiv:2401.07128* (2024)。'
- en: 'Shinn et al. [2023] Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik
    Narasimhan, and Shunyu Yao. 2023. Reflexion: language agents with verbal reinforcement
    learning. In *NeurIPS*.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shinn 等 [2023] Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan,
    和 Shunyu Yao. 2023. Reflexion: 带有语言强化学习的语言代理。发表于 *NeurIPS*。'
- en: Sun et al. [[n. d.]] Weiwei Sun, Lingyong Yan, Xinyu Ma, Shuaiqiang Wang, Pengjie
    Ren, Zhumin Chen, Dawei Yin, and Zhaochun Ren. [n. d.]. Is ChatGPT Good at Search?
    Investigating Large Language Models as Re-Ranking Agents. In *EMNLP, year = 2023*.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun 等 [[n. d.]] Weiwei Sun, Lingyong Yan, Xinyu Ma, Shuaiqiang Wang, Pengjie
    Ren, Zhumin Chen, Dawei Yin, 和 Zhaochun Ren. [n. d.]. ChatGPT 擅长搜索吗？调查大型语言模型作为重新排序代理的表现。发表于
    *EMNLP, year = 2023*。
- en: 'Wang et al. [2024] Ruocheng Wang, Eric Zelikman, Gabriel Poesia, Yewen Pu,
    Nick Haber, and Noah D. Goodman. 2024. Hypothesis Search: Inductive Reasoning
    with Language Models. *ICLR* (2024).'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang 等 [2024] Ruocheng Wang, Eric Zelikman, Gabriel Poesia, Yewen Pu, Nick
    Haber, 和 Noah D. Goodman. 2024. Hypothesis Search: 语言模型的归纳推理。 *ICLR* (2024)。'
- en: 'Wang et al. [2023a] Xinyuan Wang, Chenxi Li, Zhen Wang, Fan Bai, Haotian Luo,
    Jiayou Zhang, Nebojsa Jojic, Eric P. Xing, and Zhiting Hu. 2023a. PromptAgent:
    Strategic Planning with Language Models Enables Expert-level Prompt Optimization.
    (2023). arXiv:2310.16427'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang 等 [2023a] Xinyuan Wang, Chenxi Li, Zhen Wang, Fan Bai, Haotian Luo, Jiayou
    Zhang, Nebojsa Jojic, Eric P. Xing, 和 Zhiting Hu. 2023a. PromptAgent: 通过语言模型进行战略规划以实现专家级提示优化。
    (2023). arXiv:2310.16427'
- en: Wang et al. [2023b] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V. Le, Ed H.
    Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2023b. Self-Consistency
    Improves Chain of Thought Reasoning in Language Models. In *ICLR*.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. [2023b] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V. Le, Ed
    H. Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2023b. 自一致性提高语言模型中的思维链推理。发表于*ICLR*。
- en: Wei et al. [2022] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian
    Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and Denny Zhou. 2022. Chain-of-Thought
    Prompting Elicits Reasoning in Large Language Models. In *NeurIPS*.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei et al. [2022] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian
    Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and Denny Zhou. 2022. Chain-of-Thought提示引发大语言模型的推理。在*NeurIPS*上发表。
- en: 'Wu et al. [2023] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang,
    Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. 2023. AutoGen: Enabling
    Next-Gen LLM Applications via Multi-Agent Conversation Framework. (2023). arXiv:2308.08155'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wu et al. [2023] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang,
    Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. 2023. AutoGen: 通过多代理对话框架启用下一代LLM应用。(2023).
    arXiv:2308.08155'
- en: 'Wu et al. [2024] Shirley Wu, Shiyu Zhao, Michihiro Yasunaga, Kexin Huang, Kaidi
    Cao, Qian Huang, Vassilis N. Ioannidis, Karthik Subbian, James Zou, and Jure Leskovec.
    2024. STaRK: Benchmarking LLM Retrieval on Textual and Relational Knowledge Bases.
    (2024). arXiv:2404.13207'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wu et al. [2024] Shirley Wu, Shiyu Zhao, Michihiro Yasunaga, Kexin Huang, Kaidi
    Cao, Qian Huang, Vassilis N. Ioannidis, Karthik Subbian, James Zou, and Jure Leskovec.
    2024. STaRK: 基于文本和关系知识库的LLM检索基准。(2024). arXiv:2404.13207'
- en: Yang et al. [2024] Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V.
    Le, Denny Zhou, and Xinyun Chen. 2024. Large Language Models as Optimizers. (2024).
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang et al. [2024] Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc
    V. Le, Denny Zhou, and Xinyun Chen. 2024. 大语言模型作为优化器。(2024).
- en: 'Yang et al. [2018] Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W
    Cohen, Ruslan Salakhutdinov, and Christopher D Manning. 2018. HotpotQA: A dataset
    for diverse, explainable multi-hop question answering. *EMNLP* (2018).'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yang et al. [2018] Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William
    W Cohen, Ruslan Salakhutdinov, and Christopher D Manning. 2018. HotpotQA: 用于多跳问题回答的多样化、可解释数据集。*EMNLP*
    (2018).'
- en: 'Yao et al. [2023a] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths,
    Yuan Cao, and Karthik Narasimhan. 2023a. Tree of Thoughts: Deliberate Problem
    Solving with Large Language Models. In *NeurIPS*.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao et al. [2023a] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths,
    Yuan Cao, and Karthik Narasimhan. 2023a. 思维树：利用大语言模型进行深思熟虑的问题解决。发表于*NeurIPS*。
- en: 'Yao et al. [2023b] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik R. Narasimhan, and Yuan Cao. 2023b. ReAct: Synergizing Reasoning and Acting
    in Language Models. In *ICLR*.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yao et al. [2023b] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik R. Narasimhan, and Yuan Cao. 2023b. ReAct: 在语言模型中协同推理和行动。发表于*ICLR*。'
- en: 'Yao et al. [2024] Weiran Yao, Shelby Heinecke, Juan Carlos Niebles, Zhiwei
    Liu, Yihao Feng, Le Xue, Rithesh Murthy, Zeyuan Chen, Jianguo Zhang, Devansh Arpit,
    Ran Xu, Phil Mui, Huan Wang, Caiming Xiong, and Silvio Savarese. 2024. Retroformer:
    Retrospective Large Language Agents with Policy Gradient Optimization. (2024).'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yao et al. [2024] Weiran Yao, Shelby Heinecke, Juan Carlos Niebles, Zhiwei
    Liu, Yihao Feng, Le Xue, Rithesh Murthy, Zeyuan Chen, Jianguo Zhang, Devansh Arpit,
    Ran Xu, Phil Mui, Huan Wang, Caiming Xiong, and Silvio Savarese. 2024. Retroformer:
    回顾性大语言模型代理与策略梯度优化。(2024).'
- en: 'Yasunaga et al. [2021] Michihiro Yasunaga, Hongyu Ren, Antoine Bosselut, Percy
    Liang, and Jure Leskovec. 2021. QA-GNN: Reasoning with Language Models and Knowledge
    Graphs for Question Answering.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yasunaga et al. [2021] Michihiro Yasunaga, Hongyu Ren, Antoine Bosselut, Percy
    Liang, and Jure Leskovec. 2021. QA-GNN: 结合语言模型和知识图谱进行问答推理。'
- en: 'Zeng et al. [[n. d.]] Aohan Zeng, Mingdao Liu, Rui Lu, Bowen Wang, Xiao Liu,
    Yuxiao Dong, and Jie Tang. [n. d.]. AgentTuning: Enabling Generalized Agent Abilities
    for LLMs. ([n. d.]). arXiv:2310.12823'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zeng et al. [[n. d.]] Aohan Zeng, Mingdao Liu, Rui Lu, Bowen Wang, Xiao Liu,
    Yuxiao Dong, and Jie Tang. [n. d.]. AgentTuning: 为LLM启用通用代理能力。([n. d.]). arXiv:2310.12823'
- en: Zhang et al. [2024] Shaokun Zhang, Jieyu Zhang, Jiale Liu, Linxin Song, Chi
    Wang, Ranjay Krishna, and Qingyun Wu. 2024. Training Language Model Agents without
    Modifying Language Models. (2024). arXiv:2402.11359
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. [2024] Shaokun Zhang, Jieyu Zhang, Jiale Liu, Linxin Song, Chi
    Wang, Ranjay Krishna, and Qingyun Wu. 2024. 在不修改语言模型的情况下训练语言模型代理。(2024). arXiv:2402.11359
- en: 'Zheng et al. [2023] Wenqing Zheng, SP Sharan, Ajay Kumar Jaiswal, Kevin Wang,
    Yihan Xi, Dejia Xu, and Zhangyang Wang. 2023. Outline, then details: Syntactically
    guided coarse-to-fine code generation. *ICML* (2023).'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng et al. [2023] Wenqing Zheng, SP Sharan, Ajay Kumar Jaiswal, Kevin Wang,
    Yihan Xi, Dejia Xu, and Zhangyang Wang. 2023. 先概述，再细节：语法指导的粗到细代码生成。*ICML* (2023).
- en: 'Zhong et al. [2024] Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, and Yanlin
    Wang. 2024. MemoryBank: Enhancing Large Language Models with Long-Term Memory.
    In *AAAI*.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhong et al. [2024] Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, 和 Yanlin
    Wang. 2024. MemoryBank: 通过长期记忆增强大语言模型。在 *AAAI*。'
- en: Zhou et al. [2023] Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster,
    Silviu Pitis, Harris Chan, and Jimmy Ba. 2023. Large Language Models are Human-Level
    Prompt Engineers. In *ICLR*.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou et al. [2023] Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster,
    Silviu Pitis, Harris Chan, 和 Jimmy Ba. 2023. 大语言模型是人类水平的提示工程师。发表于 *ICLR*。
- en: 'Zhu et al. [2023] Yutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan
    Liu, Chenlong Deng, Zhicheng Dou, and Ji-Rong Wen. 2023. Large language models
    for information retrieval: A survey. *arXiv:2308.07107* (2023).'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu et al. [2023] Yutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan
    Liu, Chenlong Deng, Zhicheng Dou, 和 Ji-Rong Wen. 2023. 用于信息检索的大型语言模型：一项综述。*arXiv:2308.07107*
    (2023)。
- en: 'Zhuang et al. [2023] Yuchen Zhuang, Yue Yu, Kuan Wang, Haotian Sun, and Chao
    Zhang. 2023. ToolQA: A Dataset for LLM Question Answering with External Tools.
    In *NeurIPS*.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhuang et al. [2023] Yuchen Zhuang, Yue Yu, Kuan Wang, Haotian Sun, 和 Chao
    Zhang. 2023. ToolQA: 一个用于 LLM 外部工具问答的数据集。发表于 *NeurIPS*。'
- en: 'Zong et al. [[n. d.]] Chang Zong, Yuchen Yan, Weiming Lu, Eliot Huang, Jian
    Shao, and Yueting Zhuang. [n. d.]. Triad: A Framework Leveraging a Multi-Role
    LLM-based Agent to Solve Knowledge Base Question Answering. ([n. d.]). arXiv:2402.14320'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zong et al. [[n. d.]] Chang Zong, Yuchen Yan, Weiming Lu, Eliot Huang, Jian
    Shao, 和 Yueting Zhuang. [n. d.]. Triad: 一个利用多角色 LLM 基于的代理解决知识库问答的框架。 ([n. d.]).
    arXiv:2402.14320'
- en: Appendix A Retrieval Tasks
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 检索任务
- en: STaRK. On STaRK benchmark, we are given a relation-text knowledge base, based
    on a knowledge graph $G=(V,E)$ is in.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: STaRK。在 STaRK 基准上，我们获得了一个关系-文本知识库，基于一个知识图谱 $G=(V,E)$。
- en: The query set $Q$ satisfied the relational requirements in knowledge graph and
    textual requirements in its text documents.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 查询集 $Q$ 满足知识图谱中的关系要求以及其文本文档中的文本要求。
- en: Flickr30K Entities. On Flickr30K Entities dataset, we are given a image-text
    knowledge base. We denote an image-text knowledge base of size $n$ represents
    a set of text phrases that describe the entity in the corresponding bounding box.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: Flickr30K Entities。在 Flickr30K Entities 数据集上，我们获得了一个图像-文本知识库。我们表示大小为 $n$ 的图像-文本知识库代表了一组描述对应边界框中实体的文本短语。
- en: In our task, the image captions is served as the text query, therefore all the
    $q_{i}$
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的任务中，图像标题作为文本查询，因此所有的 $q_{i}$
- en: '![Refer to caption](img/f13e641706b4a25b1eb162da0f45af69.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/f13e641706b4a25b1eb162da0f45af69.png)'
- en: 'Figure 7: Example data on Flickr30K Entities. Every entity is an image along
    with its included image patches and associated phrases with the image patches.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '图 7: Flickr30K Entities 上的示例数据。每个实体是一个图像，以及其包含的图像补丁和与图像补丁相关的短语。'
- en: Appendix B Additional Experimental Results
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 额外实验结果
- en: 'In Table [3](#A2.T3 "Table 3 ‣ Appendix B Additional Experimental Results ‣
    AvaTaR: Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval"), we provide
    the results on STaRK using GPT-4 Turbo (0125) as the backbone LLMs.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '在表 [3](#A2.T3 "Table 3 ‣ Appendix B Additional Experimental Results ‣ AvaTaR:
    Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval") 中，我们提供了使用 GPT-4
    Turbo (0125) 作为主干 LLM 的 STaRK 结果。'
- en: 'In Table [4](#A2.T4 "Table 4 ‣ Appendix B Additional Experimental Results ‣
    AvaTaR: Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval"), we demonstrate
    AvaTaR’s ability in generalizing to testing queries with different distributions
    than the question-answering pairs used to optimize the actor agents.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '在表格 [4](#A2.T4 "Table 4 ‣ Appendix B Additional Experimental Results ‣ AvaTaR:
    Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval") 中，我们展示了 AvaTaR 在将测试查询泛化到与用于优化演员代理的问答对不同分布的能力。'
- en: 'In Figure [8](#A3.F8 "Figure 8 ‣ Appendix C Prompts ‣ AvaTaR: Optimizing LLM
    Agents for Tool-Assisted Knowledge Retrieval"), we present the final actions which
    are made'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '在图 [8](#A3.F8 "Figure 8 ‣ Appendix C Prompts ‣ AvaTaR: Optimizing LLM Agents
    for Tool-Assisted Knowledge Retrieval") 中，我们展示了做出的最终操作。'
- en: 'Table 3: Retrieval performance (%) on STaRK benchmark. Last row shows the relative
    improvements over the best metric value among the baselines.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '表 3: 在 STaRK 基准上的检索性能（%）。最后一行显示了相对于基线中最佳指标值的相对改进。'
- en: '|  | Amazon | MAG | Prime |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '|  | 亚马逊 | MAG | Prime |'
- en: '|  | Hit@1 | Hit@5 | R@20 | MRR | Hit@1 | Hit@5 | R@20 | MRR | Hit@1 | Hit@5
    | R@20 | MRR |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '|  | Hit@1 | Hit@5 | R@20 | MRR | Hit@1 | Hit@5 | R@20 | MRR | Hit@1 | Hit@5
    | R@20 | MRR |'
- en: '| Dense Retr. (roberta) | 15.29 | 47.93 | 44.49 | 30.20 | 10.51 | 35.23 | 42.11
    | 21.34 | 4.46 | 21.85 | 30.13 | 12.38 |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| Dense Retr. (roberta) | 15.29 | 47.93 | 44.49 | 30.20 | 10.51 | 35.23 | 42.11
    | 21.34 | 4.46 | 21.85 | 30.13 | 12.38 |'
- en: '| QAGNN (roberta) | 26.56 | 50.01 | 52.05 | 37.75 | 12.88 | 39.01 | 46.97 |
    29.12 | 8.85 | 21.35 | 29.63 | 14.73 |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| QAGNN (roberta) | 26.56 | 50.01 | 52.05 | 37.75 | 12.88 | 39.01 | 46.97 |
    29.12 | 8.85 | 21.35 | 29.63 | 14.73 |'
- en: '| VSS (ada-002) | 39.16 | 62.73 | 53.29 | 50.35 | 29.08 | 49.61 | 48.36 | 38.62
    | 12.63 | 31.49 | 36.00 | 21.41 |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| VSS (ada-002) | 39.16 | 62.73 | 53.29 | 50.35 | 29.08 | 49.61 | 48.36 | 38.62
    | 12.63 | 31.49 | 36.00 | 21.41 |'
- en: '| Multi-VSS (ada-002) | 40.07 | 64.98 | 55.12 | 51.55 | 25.92 | 50.43 | 50.80
    | 36.94 | 15.10 | 33.56 | 38.05 | 23.49 |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| Multi-VSS (ada-002) | 40.07 | 64.98 | 55.12 | 51.55 | 25.92 | 50.43 | 50.80
    | 36.94 | 15.10 | 33.56 | 38.05 | 23.49 |'
- en: '| ReAct (gpt4) | 38.83 | 62.50 | 50.39 | 49.16 | 23.50 | 46.50 | 43.11 | 33.91
    | 10.83 | 30.83 | 32.16 | 19.39 |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| ReAct (gpt4) | 38.83 | 62.50 | 50.39 | 49.16 | 23.50 | 46.50 | 43.11 | 33.91
    | 10.83 | 30.83 | 32.16 | 19.39 |'
- en: '| Reflexion (gpt4) | 41.45 | 64.83 | 53.98 | 52.22 | 33.44 | 51.33 | 49.14
    | 41.34 | 14.27 | 35.11 | 39.29 | 23.61 |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| Reflexion (gpt4) | 41.45 | 64.83 | 53.98 | 52.22 | 33.44 | 51.33 | 49.14
    | 41.34 | 14.27 | 35.11 | 39.29 | 23.61 |'
- en: '| Reranker (gpt4) | 44.79 | 71.17 | 55.35 | 55.69 | 40.90 | 58.18 | 48.60 |
    49.00 | 18.28 | 37.28 | 34.05 | 26.55 |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| Reranker (gpt4) | 44.79 | 71.17 | 55.35 | 55.69 | 40.90 | 58.18 | 48.60 |
    49.00 | 18.28 | 37.28 | 34.05 | 26.55 |'
- en: '| AvaTaR-C (gpt4) | 32.03 | 58.46 | 54.03 | 44.00 | 25.97 | 45.62 | 46.68 |
    35.12 | 9.52 | 26.04 | 32.62 | 17.58 |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| AvaTaR-C (gpt4) | 32.03 | 58.46 | 54.03 | 44.00 | 25.97 | 45.62 | 46.68 |
    35.12 | 9.52 | 26.04 | 32.62 | 17.58 |'
- en: '| AIR (gpt4) | 48.82 | 72.03 | 56.04 | 57.17 | 46.08 | 59.32 | 49.70 | 52.01
    | 20.10 | 39.89 | 42.23 | 29.18 |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| AIR (gpt4) | 48.82 | 72.03 | 56.04 | 57.17 | 46.08 | 59.32 | 49.70 | 52.01
    | 20.10 | 39.89 | 42.23 | 29.18 |'
- en: '| Relative Improvement | 9.0% | 1.2% | 1.3% | 2.7% | 12.7% | 2.1% | -2.2% |
    6.1% | 10.0% | 7.0% | 11.0% | 9.9% |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| 相对改进 | 9.0% | 1.2% | 1.3% | 2.7% | 12.7% | 2.1% | -2.2% | 6.1% | 10.0% |
    7.0% | 11.0% | 9.9% |'
- en: '| (over Best Baseline) |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| （相对于最佳基线） |'
- en: 'Table 4: Retrieval performance (%) on the leave-out sets of human-generated
    queries in STaRK.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：STaRK中人类生成查询的留出集上的检索性能（%）。
- en: '|  | Amazon | MAG | Prime |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '|  | Amazon | MAG | Prime |'
- en: '|  | Hit@1 | Hit@5 | MRR | Hit@1 | Hit@5 | MRR | Hit@1 | Hit@5 | MRR |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '|  | Hit@1 | Hit@5 | MRR | Hit@1 | Hit@5 | MRR | Hit@1 | Hit@5 | MRR |'
- en: '| VSS | 39.50 | 64.19 | 52.65 | 28.57 | 41.67 | 35.81 | 21.20 | 40.37 | 29.84
    |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| VSS | 39.50 | 64.19 | 52.65 | 28.57 | 41.67 | 35.81 | 21.20 | 40.37 | 29.84
    |'
- en: '| Multi-VSS | 46.91 | 72.84 | 58.74 | 23.81 | 41.67 | 31.43 | 25.67 | 40.37
    | 33.77 |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| Multi-VSS | 46.91 | 72.84 | 58.74 | 23.81 | 41.67 | 31.43 | 25.67 | 40.37
    | 33.77 |'
- en: '| ReAct | 45.65 | 71.73 | 58.81 | 27.27 | 40.00 | 33.94 | 21.73 | 33.33 | 28.20
    |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| ReAct | 45.65 | 71.73 | 58.81 | 27.27 | 40.00 | 33.94 | 21.73 | 33.33 | 28.20
    |'
- en: '| Reflexion | 49.38 | 64.19 | 58.96 | 28.57 | 39.29 | 36.53 | 16.52 | 33.03
    | 23.99 |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| Reflexion | 49.38 | 64.19 | 58.96 | 28.57 | 39.29 | 36.53 | 16.52 | 33.03
    | 23.99 |'
- en: '| AvaTaR | 58.02 | 76.54 | 65.91 | 33.33 | 42.86 | 38.62 | 33.03 | 51.37 |
    41.00 |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| AvaTaR | 58.02 | 76.54 | 65.91 | 33.33 | 42.86 | 38.62 | 33.03 | 51.37 |
    41.00 |'
- en: '| Rel. Impr. | 17.5% | 5.1% | 11.8% | 16.7% | 2.9% | 5.7% | 28.7% | 27.3% |
    21.4% |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| 相对改进 | 17.5% | 5.1% | 11.8% | 16.7% | 2.9% | 5.7% | 28.7% | 27.3% | 21.4%
    |'
- en: Appendix C Prompts
  id: totrans-218
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 C 提示
- en: 'We keep only two prompt templates for our framework on all tasks: (1) The prompt
    template given to actor as initially instructions, and (2) the prompt template
    given to the comparator to conduct contrastive reasoning and generate the instructions
    for the actor. Below are the complete templates:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的框架在所有任务中仅保留了两个提示模板：（1）最初给演员的提示模板，以及（2）给比较器的提示模板，用于进行对比推理并生成给演员的指令。以下是完整的模板：
- en: 'This is the prompt given to actor as initially instructions:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最初给演员的提示：
- en: 'You  are  an  expert  user  of  a  knowledge  base,  and  your  task  is  to  answer  a  set  of  queries.  I  will  provide  your  with  the  schema  of  this  knowledge  base:You  have  access  to  several  APIs  that  are  pre-implemented  for  interaction  with  the  knowledge  base:Information  of  queries:  Below  are  several  query  examples  that  you  need  to  carefully  read  through:""Task:  Given  an  input  query,  you  should  write  the  actions  in  Python  code  to  calculate  a  ‘node_score_dict‘  for    node  IDs,  which  are  input  as  a  list.  These  node  IDs,  referred  to  as  ‘candidate_ids‘,  are  a  subset  of  node  IDs  from  the  knowledge  base,  and  the  nodes  belong  to  the  type(s)  .  In  ‘node_score_dict:  Dict[int,  float]‘,  each  key  should  be  a  node  ID,  and  each  value  should  be  the  corresponding  node  score.  This  score  should  indicate  the  likelihood  of  the  node  being  the  correct  answer  to  the  query.Output  format:  Firstly,  you  should  establish  a  connection  between  the  given  queries  and  the  query  patterns  to  the  schema  of  the  knowledge  base.  Secondly,  generate  an  outline  for  the  code  that  will  compute  the  scores  for  all  the  candidate  nodes  provided  in  the  query  examples.  Finally,  develop  the  main  function  named  ‘get_node_score_dict‘,  which  takes  two  required  parameters:  ‘query‘  and  ‘candidate_ids‘,  and  optional  parameters  declared  in  ‘parameter_dict‘.  Note  that  ‘parameter_dict‘  is  a  dictionary  of  parameters  and  their  default  values  where  you  can  declare  any  parameters  or  weights  used  during  computing  the  node  scores.  If  no  optional  parameters  are  needed,  leave  ‘parameter_dict‘  as  an  empty  dictionary.  Overall,  your  output  should  follow  the  structure:‘‘‘python#  import  ...parameter_dict  =  {:  ,:  ,...}def  get_node_score_dict(query,  candidate_ids,  **parameter_dict):node_score_dict  =  {}#  your  codereturn  node_score_dict‘‘‘Hints:-  Observe  the  example  queries  carefully  and  consider  the  key  attributes  to  extract.-  Use  ‘‘‘python  and  ‘‘‘  to  wrap  the  complete  code,  and  do  not  use  any  other  delimiters.-  You  can  use  any  of  the  pre-implemented  APIs  but  should  avoid  modifying  them.-  You  can  include  other  functions  besides  ‘get_node_score_dict‘,  but  ensure  they  are  fully  implemented.-  The  code  should  be  complete  without  placeholders  and  dummy  functions.-  Optimize  the  integrity  of  the  code,  e.g.,  corner  cases.-  Minimize  computational  expenses  by  early  elimination  of  candidate  nodes  that  don’t  meet  relational  requirement  (if  any).-  Avoid  conducting  unnecessary  and  redundant  computations,  especially  when  using  loops.-  Make  use  of  ‘parameter_dict‘  to  avoid  hard-coding  parameters  and  weights.-  Use  the  functions  that  end  with  ‘by_llm‘  wisely  for  more  accurate  searches.-  Use  ‘debug_print‘  smartly  to  print  out  any  informative  intermediate  results  for  debugging.-  Exclude  or  comment  out  any  example  uses  of  ‘get_node_score_dict‘  in  the  output  code.Your  output:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '你是知识库的专家用户，你的任务是回答一组查询。我将提供给你这个知识库的架构：你可以访问多个已经实现的 API
    来与知识库进行交互：查询信息：以下是几个查询示例，你需要仔细阅读：“”任务：给定一个输入查询，你应该编写
    Python 代码来计算一个‘node_score_dict’，该字典包含  个节点 ID，这些节点 ID 作为列表输入。这些节点
    ID 被称为‘candidate_ids’，它们是知识库中节点 ID 的一个子集，这些节点属于  类型。在‘node_score_dict:
    Dict[int, float]’中，每个键应该是一个节点 ID，每个值应该是对应的节点分数。这个分数应该表示节点作为查询正确答案的可能性。输出格式：首先，你应该建立给定查询与知识库架构中查询模式之间的连接。其次，生成计算所有候选节点分数的代码大纲。最后，开发名为‘get_node_score_dict’的主函数，该函数接受两个必需的参数：‘query’和‘candidate_ids’，以及在‘parameter_dict’中声明的可选参数。请注意，‘parameter_dict’是一个参数及其默认值的字典，你可以在其中声明在计算节点分数时使用的任何参数或权重。如果不需要可选参数，则将‘parameter_dict’留为空字典。总体上，你的输出应遵循以下结构：‘’’python#
    import ...parameter_dict = {: ,:
    ,...}def get_node_score_dict(query, candidate_ids, **parameter_dict):node_score_dict
    = {}# your codereturn node_score_dict‘’’提示：-   仔细观察示例查询，并考虑提取的关键属性。-   使用 ‘’’python
    和 ‘’’ 来包裹完整的代码，并且不要使用其他分隔符。-   你可以使用任何已经实现的 API，但应避免修改它们。-   你可以包括其他函数，除了 ‘get_node_score_dict’，但确保它们已完全实现。-   代码应完整，无占位符和虚拟函数。-   优化代码的完整性，例如处理边界情况。-   通过提前排除不符合关系要求的候选节点来最小化计算开销（如果有）。-   避免进行不必要和冗余的计算，特别是在使用循环时。-   使用
    ‘parameter_dict’ 避免硬编码参数和权重。-   明智地使用以 ‘by_llm’ 结尾的函数，以获得更准确的搜索结果。-   智慧地使用 ‘debug_print’
    打印出调试的有用中间结果。-   排除或注释掉代码输出中的 ‘get_node_score_dict’ 的任何示例用法。'
- en: 'This is the prompt given to comparator to generate the instructions for the
    actor:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 这是提供给比较器以生成演员指令的提示：
- en: After  executing  the  above  actions  on  user  queries,  some  queries  have  yielded  good  results,  while  others  have  not.  Below  are  the  queries  along  with  their  corresponding  evaluation  metrics:Well-performing  queries:Poorly-performing  queries:Task:(1)  Firstly,  identify  and  contrast  the  patterns  of  queries  that  have  achieved  good  results  with  those  that  have  not.(2)  Then,  review  the  computational  logic  for  any  inconsistencies  in  the  previous  actions.(3)  Lastly,  specify  the  modification  that  can  lead  to  improved  performance  on  the  negative  queries.  You  should  focus  on  capturing  the  high-level  pattern  of  the  queries  relevant  to  the  knowledge  base  schema.![Refer
    to caption](img/bf8618206c7f874ef5010ed51558a272.png)
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在对用户查询执行上述操作后，某些查询产生了良好的结果，而其他查询则未能产生良好结果。以下是查询及其对应的评估指标：表现良好的查询：表现不佳的查询：任务：（1）首先，识别和对比那些取得良好结果的查询模式与那些未能取得良好结果的查询模式。（2）然后，审查计算逻辑，检查之前操作中的任何不一致之处。（3）最后，指定可以改进负面查询表现的修改。你应该关注于捕捉与知识库模式相关的高层次查询模式。![参见说明](img/bf8618206c7f874ef5010ed51558a272.png)
- en: 'Figure 8: Optimized Action Sequence by AvaTaR on Flickr30K-Entities..'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '图 8: AvaTaR 在 Flickr30K-Entities 上优化的动作序列。'
- en: Appendix D Function library
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 D 函数库
- en: '| Function Name | Input | Output |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| Function Name | 输入 | 输出 |'
- en: '| ParseAttributeFromQuery | query: The string to be parsed, attributes: The
    list of attributes to be extracted from the query | This function parses a ‘query‘
    into a dictionary based on the input list ‘attributes‘ |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| ParseAttributeFromQuery | query: 需要解析的字符串, attributes: 需要从查询中提取的属性列表 | 此函数将‘query‘解析为基于输入列表‘attributes‘的字典
    |'
- en: '| GetTextEmbedding | string: The array of list to be embedded | Embeds N strings
    in a list into N tensors |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| GetTextEmbedding | string: 需要嵌入的字符串数组 | 将 N 个字符串嵌入到 N 个张量中 |'
- en: '| GetRelevantChunk | query: The input query string, node_id: The ID of the
    node | Get the relevant chunk of information for the node based on the query |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| GetRelevantChunk | query: 输入的查询字符串, node_id: 节点的 ID | 根据查询获取与节点相关的信息块 |'
- en: '| GetFullInfo | node_id: The ID of the node | Get the full information of the
    node with the specified ID |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| GetFullInfo | node_id: 节点的 ID | 获取指定 ID 节点的完整信息 |'
- en: '| GetEntityDocuments | node_id: The ID of the node | Get the text information
    of the node with the specified ID |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| GetEntityDocuments | node_id: 节点的 ID | 获取指定 ID 节点的文本信息 |'
- en: '| GetRelationInfo | node_id: The ID of the node | Get the relation information
    of the node with the specified ID |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| GetRelationInfo | node_id: 节点的 ID | 获取指定 ID 节点的关系信息 |'
- en: '| GetRelationDict | node_id: The ID of the node | Get the relation dictionary
    for the node with the specified ID, where the keys are relation type and values
    are neighbor nodes. |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| GetRelationDict | node_id: 节点的 ID | 获取指定 ID 节点的关系字典，其中键为关系类型，值为邻居节点。 |'
- en: '| GetRelatedEntities | node_id: The ID of the node | Get the nodes related
    to the specified node |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| GetRelatedEntities | node_id: 节点的 ID | 获取与指定节点相关的节点 |'
- en: '| GetEntityIdsByType | type: The type of node to retrieve | Get the IDs of
    nodes with the specified type |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| GetEntityIdsByType | type: 要检索的节点类型 | 获取具有指定类型的节点的 ID |'
- en: '| GetEntityTypes | node_id: The ID of the node | Get the type of the node with
    the specified ID |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| GetEntityTypes | node_id: 节点的 ID | 获取指定 ID 节点的类型 |'
- en: '| GetEntityEmbedding | node_ids: An array of candidate node ids to be embedded
    | Get the embedding indices of nodes with ID ‘node_ids‘ |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| GetEntityEmbedding | node_ids: 要嵌入的候选节点 ID 数组 | 获取 ID 为‘node_ids‘的节点的嵌入索引
    |'
- en: '| ComputingEmbeddingSimilarity | embedding_1 and embedding_2 | The cosine similarity
    score of two embeddings |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| ComputingEmbeddingSimilarity | embedding_1 和 embedding_2 | 两个嵌入的余弦相似度分数 |'
- en: '| ComputeQueryEntitySimilarity | query: The input query string, node_ids: An
    array of candidate node id to be compared with the query | Compute embedding similarity
    between ‘query‘ (str) and the nodes’ in ‘node_ids‘ (list) |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| ComputeQueryEntitySimilarity | query: 输入的查询字符串, node_ids: 与查询进行比较的候选节点 ID
    数组 | 计算‘query‘（字符串）与‘node_ids‘（列表）中节点之间的嵌入相似度 |'
- en: '| ComputeExactMatchScore | string: The string to be matched, node_ids: The
    list of candidate node id to be compared with the string | For each node in ‘node_ids‘,
    compute the exact match score based on whether ‘string‘ is included in the information
    of the node |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| ComputeExactMatchScore | string: 待匹配的字符串，node_ids: 与字符串进行比较的候选节点 ID 列表 |
    对于每个‘node_ids’中的节点，根据‘string’是否包含在节点信息中计算精确匹配分数 |'
- en: '| TokenMatchScore | string: The string to be matched, node_ids: The list of
    candidate node id to be compared with the string | For each node in ‘node_ids‘,
    computes recall scores between ‘string‘ and the full information of the node |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| TokenMatchScore | string: 待匹配的字符串，node_ids: 与字符串进行比较的候选节点 ID 列表 | 对于每个‘node_ids’中的节点，计算‘string’与节点的完整信息之间的召回分数
    |'
- en: '| SummarizeTextsByLLM | texts: The list of texts to be summarized | Use LLM
    to summarize the provided texts |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| SummarizeTextsByLLM | texts: 待总结的文本列表 | 使用 LLM 总结提供的文本 |'
- en: '| ClassifyEntitiesByLLM | node_ids: The array of candidate node ids to be classified,
    classes: The list of classes to be classified into | Use LLM to classify each
    node specified by ‘node_ids‘ into one of the given ‘classes‘ or ’NA’ |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| ClassifyEntitiesByLLM | node_ids: 待分类的候选节点 ID 数组，classes: 要分类到的类别列表 | 使用
    LLM 将‘node_ids’指定的每个节点分类到给定的‘classes’之一或’NA’ |'
- en: '| ClassifyByLLM | texts: The list of texts to be classified, classes: The list
    of classes to be classified into | Use LLM to classify each text into one of the
    given ‘classes‘ or ’NA’ |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| ClassifyByLLM | texts: 待分类的文本列表，classes: 要分类到的类别列表 | 使用 LLM 将每个文本分类到给定的‘classes’之一或’NA’
    |'
- en: '| ExtractRelevantInfoByLLM | texts: The list of texts to extract info from,
    extract_term: the terms to identify relevant information | Use LLM to extract
    relevant information from the texts based on extract_term, return sentences or
    ’NA’ |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| ExtractRelevantInfoByLLM | texts: 从中提取信息的文本列表，extract_term: 识别相关信息的术语 | 使用
    LLM 根据 extract_term 从文本中提取相关信息，返回句子或’NA’ |'
- en: '| CheckRequirementsByLLM | node_ids: The array of candidate node ids to be
    checked, requirement: The requirement to be checked | Use LLM to check if node(s)
    with ‘node_ids‘ satisfies to ‘requirement‘ |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| CheckRequirementsByLLM | node_ids: 待检查的候选节点 ID 数组，requirement: 要检查的要求 | 使用
    LLM 检查‘node_ids’中的节点是否满足‘requirement’ |'
- en: '| GetSatisfictionScoreByLLM | node_ids: The array of candidate node ids to
    be scored, query: The input query from user | Use LLM to score the node with ‘node_ids‘
    based on the given ‘query‘ |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| GetSatisfictionScoreByLLM | node_ids: 待评分的候选节点 ID 数组，query: 用户输入的查询 | 使用
    LLM 根据给定的‘query’对‘node_ids’中的节点进行评分 |'
- en: '| FINISH | final_reranked_answer_list: The final answer | This function is
    used to indicate the end of the task |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| FINISH | final_reranked_answer_list: 最终答案 | 此功能用于指示任务的结束 |'
- en: 'Table 5: Function library on STaRK'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 'Table 5: STaRK 上的功能库'
- en: '| Function Name | Input | Output |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| Function Name | Input | Output |'
- en: '| ParseAttributeFromQuery | query: The string to be parsed, attributes: The
    list of attributes to be extracted from the query | This function parses a ‘query‘
    into a dictionary based on the input list ‘attributes‘ |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| ParseAttributeFromQuery | query: 待解析的字符串，attributes: 从查询中提取的属性列表 | 此功能将‘query’解析为一个基于输入列表‘attributes’的字典
    |'
- en: '| GetBagOfPhrases | image_ids: The image id array to get the phrases from |
    Returns a list of phrase list for each image in the image_ids list |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| GetBagOfPhrases | image_ids: 从中获取短语的图像 ID 数组 | 返回一个每个图像的短语列表的列表 |'
- en: '| GetEntityDocuments | image_ids: The image id array to get the text information
    from | Returns a list of text information for each image in the image_ids list
    |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| GetEntityDocuments | image_ids: 从中获取文本信息的图像 ID 数组 | 返回每个图像的文本信息列表 |'
- en: '| GetClipTextEmbedding | string: The list of strings to be embedded | Embed
    a string or list of N strings into N embeddings |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| GetClipTextEmbedding | string: 待嵌入的字符串列表 | 将字符串或 N 个字符串列表嵌入到 N 个嵌入中 |'
- en: '| GetPatchIdToPhraseDict | image_ids: The image list to get the patch_id to
    phrase list dictionary from | Returns a list of patch_id to phrase list dictionary
    for each image |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| GetPatchIdToPhraseDict | image_ids: 从中获取 patch_id 到短语列表字典的图像列表 | 返回每个图像的
    patch_id 到短语列表字典的列表 |'
- en: '| GetImages | image_id_lst: The list of image ids | Return a list of images
    with corresponding ids |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| GetImages | image_id_lst: 图像 ID 列表 | 返回具有相应 ID 的图像列表 |'
- en: '| GetClipImageEmbedding | image_lst: The list of images to be embedded | Embed
    the images of a list of N image_ids into N tensors |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| GetClipImageEmbedding | image_lst: 待嵌入的图像列表 | 将 N 个图像 ID 的图像嵌入到 N 个张量中 |'
- en: '| GetImagePatchByPhraseId | image_id: the id of an image, patch_id: the patch
    id on the image | Return the patch image for the given image_id and patch_id |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| GetImagePatchByPhraseId | image_id: 图像的ID，patch_id: 图像上的补丁ID | 返回给定`image_id`和`patch_id`的补丁图像
    |'
- en: '| ComputingEmbeddingSimilarity | embedding_1 and embedding_2 | The cosine similarity
    score of two embeddings |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| ComputingEmbeddingSimilarity | embedding_1 和 embedding_2 | 两个嵌入的余弦相似度分数 |'
- en: '| ComputeF1 | string_to_match: The key word to be matched, strings: The list
    of strings to be calculated f1 score with the key word | Compute the F1 score
    based on the similarity between ‘string_to_match‘ and each string in ‘strings‘
    |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| ComputeF1 | string_to_match: 需要匹配的关键词，strings: 需要与关键词计算F1分数的字符串列表 | 根据`string_to_match`与`strings`中每个字符串的相似度计算F1分数
    |'
- en: '| TokenMatchScore | string_to_match: The key word to be matched, strings: The
    list of strings to be calculated recall score with the key word | Compute the
    recall score based on the similarity between ‘string_to_match‘ and each string
    in ‘strings‘ |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| TokenMatchScore | string_to_match: 需要匹配的关键词，strings: 需要与关键词计算召回分数的字符串列表 |
    根据`string_to_match`与`strings`中每个字符串的相似度计算召回分数 |'
- en: '| ComputeExactMatchScore | string_to_match: The key word to be matched, strings:
    The list of strings to be exact matched with the key word | Compute the exact
    match score based on whether ‘string_to_match‘ is exactly the same as each string
    in ‘strings‘ |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| ComputeExactMatchScore | string_to_match: 需要匹配的关键词，strings: 需要与关键词精确匹配的字符串列表
    | 根据`string_to_match`是否与`strings`中的每个字符串完全相同来计算精确匹配分数 |'
- en: '| VqaByLLM | question: The question to be answered, image_lst: The list of
    images | Use LLM to answer the given ‘question‘ based on the image(s) |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| VqaByLLM | question: 需要回答的问题，image_lst: 图像列表 | 使用LLM基于图像回答给定的`question` |'
- en: '| ExtractVisualAttributesByLLM | attribute_lst: The list of attributes to be
    extracted, image_lst: The list of images | Use LLM to extract attributes about
    the given ‘attribute_lst‘ from each image |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| ExtractVisualAttributesByLLM | attribute_lst: 需要提取的属性列表，image_lst: 图像列表 |
    使用LLM从每张图像中提取关于给定`attribute_lst`的属性 |'
- en: '| FINISH | final_reranked_answer_list: The final answer | This function is
    used to indicate the end of the task |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| FINISH | final_reranked_answer_list: 最终答案 | 此函数用于表示任务的结束 |'
- en: 'Table 6: Function library on Flickr30K Entities'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '表6: Flickr30K实体函数库'
