- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 18:39:42'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:39:42
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'From Data to Story: Towards Automatic Animated Data Video Creation with LLM-based
    Multi-Agent Systems'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从数据到故事：基于LLM的多智能体系统自动生成动画数据视频
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2408.03876](https://ar5iv.labs.arxiv.org/html/2408.03876)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2408.03876](https://ar5iv.labs.arxiv.org/html/2408.03876)
- en: \onlineid
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \onlineid
- en: 7043 \vgtccategoryResearch \vgtcinsertpkg
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 7043 \vgtccategoryResearch \vgtcinsertpkg
- en: Leixian Shen [\scalerel* —](https://orcid.org/0000-0003-1084-4912)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 沈磊贤 [\scalerel* —](https://orcid.org/0000-0003-1084-4912)
- en: 'The Hong Kong University of Science and Technology, Hong Kong SAR, China e-mail:
    lshenaj@connect.ust.hk    Haotian Li [\scalerel* —](https://orcid.org/0000-0001-9547-3449)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 香港科技大学，中国香港特别行政区 电子邮件：lshenaj@connect.ust.hk    李浩天 [\scalerel* —](https://orcid.org/0000-0001-9547-3449)
- en: 'The Hong Kong University of Science and Technology, Hong Kong SAR, China e-mail:
    haotian.li@connect.ust.hk    Yun Wang [\scalerel* —](https://orcid.org/0000-0003-0468-4043)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 香港科技大学，中国香港特别行政区 电子邮件：haotian.li@connect.ust.hk    王云 [\scalerel* —](https://orcid.org/0000-0003-0468-4043)
- en: Microsoft,
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 微软，
- en: 'Beijing, China e-mail: wangyun@microsoft.com    Huamin Qu [\scalerel* —](https://orcid.org/0000-0002-3344-9694)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 北京，中国 电子邮件：wangyun@microsoft.com    曲华敏 [\scalerel* —](https://orcid.org/0000-0002-3344-9694)
- en: 'The Hong Kong University of Science and Technology, Hong Kong SAR, China e-mail:
    huamin@cse.ust.hk'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 香港科技大学，中国香港特别行政区 电子邮件：huamin@cse.ust.hk
- en: Abstract
  id: totrans-14
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Creating data stories from raw data is challenging due to humans’ limited attention
    spans and the need for specialized skills. Recent advancements in large language
    models (LLMs) offer great opportunities to develop systems with autonomous agents
    to streamline the data storytelling workflow. Though multi-agent systems have
    benefits such as fully realizing LLM potentials with decomposed tasks for individual
    agents, designing such systems also faces challenges in task decomposition, performance
    optimization for sub-tasks, and workflow design. To better understand these issues,
    we develop Data Director, an LLM-based multi-agent system designed to automate
    the creation of animated data videos, a representative genre of data stories.
    Data Director interprets raw data, breaks down tasks, designs agent roles to make
    informed decisions automatically, and seamlessly integrates diverse components
    of data videos. A case study demonstrates Data Director’s effectiveness in generating
    data videos. Throughout development, we have derived lessons learned from addressing
    challenges, guiding further advancements in autonomous agents for data storytelling.
    We also shed light on future directions for global optimization, human-in-the-loop
    design, and the application of advanced multimodal LLMs.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 从原始数据创建数据故事具有挑战性，因为人类的注意力有限且需要专业技能。最近的大型语言模型（LLMs）的进展为开发具有自主智能体的系统以简化数据讲述工作流程提供了极大的机会。尽管多智能体系统有诸如充分实现LLM潜力与任务分解等好处，但设计此类系统也面临任务分解、子任务性能优化和工作流程设计等挑战。为了更好地理解这些问题，我们开发了数据导演，这是一个基于LLM的多智能体系统，旨在自动创建动画数据视频，这是数据故事的一种代表性类型。数据导演解读原始数据，分解任务，设计智能体角色以自动做出明智决策，并无缝整合数据视频的各种组件。案例研究展示了数据导演在生成数据视频方面的有效性。在开发过程中，我们总结了应对挑战的经验教训，指导了数据讲述领域中自主智能体的进一步发展。我们还展望了全球优化、环节设计和先进多模态LLMs应用的未来方向。
- en: 'keywords:'
  id: totrans-16
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Data Storytelling, LLM, Multi-Agent, Data Video
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 数据讲述，LLM，多智能体，数据视频
- en: Introduction
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 引言
- en: The rapid growth of data assets has driven advancements in various domains,
    but it has also presented challenges for human-data interaction. Humans have limited
    attention spans and may lack the specialized skills to extract valuable insights
    and craft engaging data stories across multiple modalities [[11](#bib.bib11)].
    Automating the generation of stories from raw data can greatly enhance the efficiency
    of data analysis and information communication.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 数据资产的快速增长推动了各个领域的发展，但也给人机交互带来了挑战。人类的注意力有限，可能缺乏提取有价值洞察和创建引人入胜的数据故事所需的专业技能[[11](#bib.bib11)]。从原始数据自动生成故事可以大大提高数据分析和信息传递的效率。
- en: Recently, advancements in large language models (LLMs) have showcased robust
    natural language understanding and reasoning capabilities, proving effective across
    various tasks like data analysis [[34](#bib.bib34), [4](#bib.bib4)], document
    generation [[14](#bib.bib14)], and visualization creation [[7](#bib.bib7)]. These
    capabilities open up new avenues to streamline the entire data storytelling workflow
    by developing systems featuring LLM-powered autonomous agents. In this paradigm,
    LLMs serve as the cognitive core of these agents, enabling them to perceive environments
    (Perception), make decisions (Brain), and take responsive actions (Action), thereby
    assisting humans in automating a wide range of tasks [[35](#bib.bib35)].
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，大型语言模型（LLMs）的进展展示了强大的自然语言理解和推理能力，在数据分析[[34](#bib.bib34), [4](#bib.bib4)]、文档生成[[14](#bib.bib14)]和可视化创建[[7](#bib.bib7)]等各种任务中表现出色。这些能力开辟了通过开发具有LLM驱动的自主代理的系统来简化整个数据讲述工作流程的新途径。在这种模式中，LLMs作为这些代理的认知核心，使其能够感知环境（Perception）、做出决策（Brain）并采取响应行动（Action），从而帮助人类自动化广泛的任务[[35](#bib.bib35)]。
- en: 'Therefore, we aim to explore the potential of LLM-based autonomous agents in
    facilitating end-to-end storytelling directly from raw data, which is a new problem
    in the visualization and storytelling community. In this paper, we specifically
    focus on a representative genre of data stories [[19](#bib.bib19)], animated data
    videos, which encompass diverse components and necessitate the coordination of
    these diverse elements [[6](#bib.bib6)]. Existing automatic methods for creating
    data videos either require users to prepare various materials from raw data [[25](#bib.bib25),
    [32](#bib.bib32), [26](#bib.bib26)] or still involve complex and time-consuming
    manual authoring processes [[5](#bib.bib5), [30](#bib.bib30), [8](#bib.bib8),
    [27](#bib.bib27), [3](#bib.bib3)]. We envision that autonomous agents can facilitate
    the automatic transformation of raw data into animated data videos. However, achieving
    this goal involves overcoming several challenges:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们旨在探索基于LLM的自主代理在直接从原始数据中促进端到端讲述的潜力，这是可视化和讲述社区中的一个新问题。本文特别关注数据故事的一种代表性类型[[19](#bib.bib19)]，即动画数据视频，它们包含各种组件，并需要协调这些不同的元素[[6](#bib.bib6)]。现有的自动化数据视频创建方法要么要求用户从原始数据准备各种材料[[25](#bib.bib25),
    [32](#bib.bib32), [26](#bib.bib26)]，要么仍涉及复杂且耗时的手动创作过程[[5](#bib.bib5), [30](#bib.bib30),
    [8](#bib.bib8), [27](#bib.bib27), [3](#bib.bib3)]。我们设想自主代理能够促进将原始数据自动转化为动画数据视频。然而，实现这一目标需要克服几个挑战：
- en: '![Refer to caption](img/cfaad6b7e9d439cbce6e009393af745d.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/cfaad6b7e9d439cbce6e009393af745d.png)'
- en: 'Figure 1: Architecture of Data Director.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：数据导演的架构。
- en: •
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Task Decomposition: Data storytelling involves the generation and coordination
    of diverse elements such as visualizations, text narrations, audio, and animations.
    The system should accurately interpret raw data, break down the storytelling task
    into manageable sub-tasks, and assign appropriate roles to agents specialized
    in handling specific aspects of the task.'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 任务分解：数据讲述涉及生成和协调各种元素，如可视化、文本叙述、音频和动画。系统应准确解释原始数据，将讲述任务分解为可管理的子任务，并将适当的角色分配给专门处理任务特定方面的代理。
- en: •
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Performance Optimization: In each sub-task, the agent is required to make informed
    decisions based on perception inputs and determine the appropriate tools and methods
    to use. Each sub-task often relies on the outputs of preceding stages, highlighting
    the interdependence among these sub-tasks. So ensuring optimal performance for
    each one is crucial.'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 性能优化：在每个子任务中，代理需要根据感知输入做出明智的决策，并确定使用合适的工具和方法。每个子任务通常依赖于前阶段的输出，突显了这些子任务之间的相互依赖性。因此，确保每个子任务的最佳性能至关重要。
- en: •
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Workflow Design: Storytelling involves numerous interconnected sub-tasks with
    diverse sequence schemes. Tasks such as data visualization, crafting narration,
    recording audio, designing animations, and aligning diverse components are typically
    non-linear and their order may vary, presenting challenges in determining the
    optimal approach. The system needs to facilitate a seamless workflow that automates
    and effectively integrates all these sub-tasks.'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 工作流程设计：讲故事涉及众多相互关联的子任务，具有不同的顺序方案。数据可视化、编写叙述、录制音频、设计动画以及对齐各种组件等任务通常是非线性的，其顺序可能会有所不同，这给确定最佳方法带来了挑战。系统需要提供一个无缝的工作流程，自动化并有效整合所有这些子任务。
- en: 'To better understand these issues, we develop Data Director, an LLM-based multi-agent
    system that automates the entire process of transforming raw data into engaging
    animated data videos. The system’s architecture is shown in [Fig. 1](#S0.F1 "In
    From Data to Story: Towards Automatic Animated Data Video Creation with LLM-based
    Multi-Agent Systems"). Specifically, we decompose data video creation into distinct
    sub-tasks based on data video components and their relationships. We design two
    agent roles—data analyst and designer—to manage and conduct these sub-tasks, and
    optimize the performance of each sub-task through prompt design. We also explore
    effective ways to interconnect these sub-tasks and iteratively refine the workflow.
    To demonstrate the effectiveness of Data Director, we conduct a case study where
    Data Director generates a data video about real-world stock price data. Finally,
    we summarize the lessons learned from our system design for task decomposition,
    performance optimization, and workflow design, and provide insights to guide future
    developments in multi-agent systems for the automatic transformation of raw data
    into data stories.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解这些问题，我们开发了Data Director，一个基于LLM的多智能体系统，自动化地将原始数据转换为引人入胜的动画数据视频。该系统的架构如[图1](#S0.F1
    "从数据到故事：基于LLM的多智能体系统的自动化动画数据视频创建")所示。具体而言，我们将数据视频创建分解为基于数据视频组件及其关系的不同子任务。我们设计了两个智能体角色——数据分析师和设计师——来管理和执行这些子任务，并通过提示设计优化每个子任务的性能。我们还探索了有效的方式来互联这些子任务，并迭代优化工作流程。为了展示Data
    Director的有效性，我们进行了一项案例研究，其中Data Director生成了一个关于实际股票价格数据的数据视频。最后，我们总结了从系统设计中学到的关于任务分解、性能优化和工作流程设计的经验教训，并提供了指导未来多智能体系统将原始数据自动转换为数据故事的见解。
- en: '![Refer to caption](img/7ad2892c74292cc2392d20438ca354c8.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/7ad2892c74292cc2392d20438ca354c8.png)'
- en: 'Figure 2: An example walkthrough of Data Director.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：Data Director的示例操作流程。
- en: 1 Data Director
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 Data Director
- en: This section will first give an overview of Data Director’s architecture and
    then introduce our design practices.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将首先概述Data Director的架构，然后介绍我们的设计实践。
- en: 1.1 Overview
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1 概述
- en: 'Data Director is an LLM-based multi-agent system powered by GPT-4 [[2](#bib.bib2)].
    We follow existing conceptual framework of LLM-based agent to design three components:
    perception, brain, and action [[35](#bib.bib35)]. The architecture of Data Director is
    illustrated in [Fig. 1](#S0.F1 "In From Data to Story: Towards Automatic Animated
    Data Video Creation with LLM-based Multi-Agent Systems"), with a central controller
    (a) scheduling all components. User-generated data (b) is directly input into
    Data Director. The perception module (c) preprocesses the data, which is then
    fed into the first agent acting as a data analyst (d). This agent’s tasks include
    extracting insights, visualizing data, and crafting narration text. The generated
    visualization and narration text are passed to the next agent, which acts as a
    designer (e). This agent is responsible for animating and annotating the content,
    as well as coordinating the data video components. Finally, the controller (a)
    utilizes the decisions made by the multi-agent system to generate a data video
    with relevant tools (f).'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Data Director是一个基于LLM的多智能体系统，由GPT-4提供支持[[2](#bib.bib2)]。我们遵循现有的基于LLM的智能体概念框架，设计了三个组件：感知、脑部和行动[[35](#bib.bib35)]。Data
    Director的架构如[图1](#S0.F1 "从数据到故事：基于LLM的多智能体系统的自动化动画数据视频创建")所示，中央控制器(a)负责调度所有组件。用户生成的数据(b)直接输入Data
    Director。感知模块(c)对数据进行预处理，然后送入第一个作为数据分析师的智能体(d)。该智能体的任务包括提取见解、可视化数据和撰写叙述文本。生成的可视化和叙述文本被传递给下一个作为设计师的智能体(e)。该智能体负责为内容添加动画和注释，以及协调数据视频组件。最后，控制器(a)利用多智能体系统做出的决策，使用相关工具(f)生成数据视频。
- en: 1.2 Task Decomposition and Workflow Design
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2 任务分解与工作流程设计
- en: To design multi-agent systems for complex tasks, such as data storytelling,
    it is crucial to decompose the process into patterned sub-tasks, facilitating
    model learning and interpretation [[35](#bib.bib35)]. Task decomposition is a
    balance art between accuracy and efficiency. Coarse tasks may exceed the model’s
    capabilities, leading to hallucinations or non-computational results, while excessively
    fine-grained tasks may overwhelm the model with excessive tasks, affecting efficiency
    and increasing costs.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 设计用于复杂任务的多代理系统，例如数据讲述，至关重要的是将过程分解成模式化的子任务，这有助于模型的学习和解释 [[35](#bib.bib35)]。任务分解是一种在准确性和效率之间的平衡艺术。粗略的任务可能超出模型的能力，导致幻觉或非计算结果，而过于细化的任务可能会使模型因任务过多而不堪重负，影响效率并增加成本。
- en: 'To decompose the tasks in the context of data video creation, we first break
    down data videos into basic components and the relationship between these components,
    following previous research [[32](#bib.bib32), [25](#bib.bib25)]. The basic components
    of data videos include data visualizations, text narrations, and visual animations.
    To make sure these components appear coherently in data videos, three relationships
    need to be taken care of: 1) Animated visualization elements must semantically
    connect with corresponding text narration segments; 2) Animation effects must
    be tailored to the visualization elements they accompany; 3) Text narration should
    align temporally with the animations, serving as the timeline.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在数据视频创建的背景下分解任务，我们首先将数据视频分解为基本组件和这些组件之间的关系，遵循之前的研究 [[32](#bib.bib32), [25](#bib.bib25)]。数据视频的基本组件包括数据可视化、文本叙述和视觉动画。为了确保这些组件在数据视频中出现得连贯，需要处理三个关系：1)
    动画可视化元素必须在语义上与相应的文本叙述片段连接；2) 动画效果必须根据它们所伴随的可视化元素进行调整；3) 文本叙述应与动画在时间上对齐，作为时间轴。
- en: With these identified components and relationships, we assign the three component
    creation tasks and the three relationship management tasks (six sub-tasks in total)
    to two LLM-powered agents, assuming the roles of a data analyst and a designer.
    Additionally, we develop a controller to manage the input and output of each module,
    parse outputs, and invoke appropriate tools for tasks beyond LLM capabilities.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 根据识别出的组件和关系，我们将三个组件创建任务和三个关系管理任务（总共六个子任务）分配给两个由LLM驱动的代理，分别扮演数据分析师和设计师的角色。此外，我们开发了一个控制器来管理每个模块的输入和输出，解析输出，并调用适当的工具来处理超出LLM能力范围的任务。
- en: '[Fig. 2](#S0.F2 "In From Data to Story: Towards Automatic Animated Data Video
    Creation with LLM-based Multi-Agent Systems") illustrates a case study based on
    real-world stock price data of four IT companies.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[图2](#S0.F2 "从数据到故事：基于LLM的多代理系统自动化动画数据视频创建")展示了一个基于四家IT公司真实股票价格数据的案例研究。'
- en: 'Perception. The perception module accepts and processes diverse information
    from external environments, transforming it into understandable representations
    for LLMs [[35](#bib.bib35)]. In Data Director, data tables are inputted directly
    in the prompt as formatted text. During the perception phase (A), a data preprocessing
    module utilizes the dataset’s title and content within an LLM session to generate
    natural language descriptions. As shown in [Fig. 2](#S0.F2 "In From Data to Story:
    Towards Automatic Animated Data Video Creation with LLM-based Multi-Agent Systems")-A,
    the description involves a high-level overview of the data topic, along with a
    detailed elaboration of the semantics of each data column, enhancing contextual
    information for subsequent model processes. The generated NL data description
    and the raw data are then fed into the data analysis brain.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 感知模块。感知模块接受并处理来自外部环境的多种信息，将其转换为LLM可以理解的表示形式 [[35](#bib.bib35)]。在数据总监中，数据表直接以格式化文本的形式输入到提示中。在感知阶段（A），数据预处理模块利用数据集的标题和内容，在LLM会话中生成自然语言描述。如[图2](#S0.F2
    "从数据到故事：基于LLM的多代理系统自动化动画数据视频创建")-A所示，描述包括数据主题的高级概述以及对每列数据语义的详细阐述，为后续模型处理提供上下文信息。生成的自然语言数据描述和原始数据随后被输入到数据分析大脑中。
- en: Role as Data Analyst. Inspired by insight-based visualization and understanding
    techniques [[39](#bib.bib39), [33](#bib.bib33)], when analyzing data, Data Director first
    prompts the LLM to extract top-k interesting data insights (B) from raw data,
    based on data analysis task modeling [[23](#bib.bib23), [21](#bib.bib21)]. These
    insights guide the generation of visualizations (sub-task 1) and text narration
    (sub-task 2). Following the Chain-of-Thought strategy [[9](#bib.bib9)] and carefully
    designed LLM prompts, the brain incrementally derives a list of insights (B),
    declarative Vega-Lite visualizations [[18](#bib.bib18)] (C), and text narrations
    (D) step by step.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分析师角色。受到基于洞察的可视化和理解技术的启发[[39](#bib.bib39)，[33](#bib.bib33)]，在分析数据时，数据总监首先提示
    LLM 从原始数据中提取 top-k 有趣的数据洞察（B），基于数据分析任务建模[[23](#bib.bib23)，[21](#bib.bib21)]。这些洞察引导生成可视化（子任务
    1）和文本叙述（子任务 2）。遵循链式思维策略[[9](#bib.bib9)]和精心设计的 LLM 提示，大脑逐步推导出洞察列表（B）、声明性的 Vega-Lite
    可视化[[18](#bib.bib18)]（C）和文本叙述（D）。
- en: 'Role as Designer. Once the “data analyst” has prepared visualizations and corresponding
    text narrations, the “designer” agent focuses on creating dynamic animations (sub-task
    3) and synchronizing components (sub-task 4 5 6). Animations are categorized into
    two types: visual effects (e.g., fade, grow, fly, zoom, etc.) applied to visualization
    elements, and annotations that introduce additional visual elements at the right
    moments. Animation effects are determined by distilling choices from an animation
    library into natural language prompts (E). The agent is tasked with selecting
    the optimal timing for animation applications, identifying the precise visual
    elements that will be animated, and choosing the appropriate animation effects.
    Furthermore, given the complexity of Vega-Lite-specified annotated visualizations,
    we adopt a hierarchical approach, initially generating base visualizations with
    the data analyst agent and subsequently enhancing them with annotations (with
    Vega-Lite specifications) for improved outcomes (F) using the designer agent.
    Text narration serves as a timeline, transforming temporal synchronization into
    semantic links between static narration segments and visual elements [[32](#bib.bib32),
    [25](#bib.bib25)].'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 设计师角色。一旦“数据分析师”准备好了可视化和相应的文本叙述，“设计师”代理专注于创建动态动画（子任务 3）和同步组件（子任务 4 5 6）。动画分为两种类型：应用于可视化元素的视觉效果（例如，*渐变*、*放大*、*飞入*、*缩放*等）和在适当时刻引入的附加视觉元素的注释。动画效果通过将动画库中的选择提炼为自然语言提示（E）来确定。代理的任务是选择动画应用的最佳时机，识别将被动画化的精确视觉元素，并选择适当的动画效果。此外，鉴于
    Vega-Lite 指定的注释可视化的复杂性，我们采用分层方法，首先由数据分析师代理生成基础可视化，然后由设计师代理通过注释（使用 Vega-Lite 规范）进行增强，以提高效果（F）。文本叙述充当时间轴，将时间同步转化为静态叙述片段与视觉元素之间的语义链接[[32](#bib.bib32)，[25](#bib.bib25)]。
- en: 'Controller. As shown in the middle of [Fig. 2](#S0.F2 "In From Data to Story:
    Towards Automatic Animated Data Video Creation with LLM-based Multi-Agent Systems"),
    based on the NL outputs of the models, the controller first utilizes text-to-speech
    services to convert text narrations into audio with precise timestamps, ensuring
    alignment with the data video timeline. Then, the controller invokes a visualization
    renderer to convert Vega-Lite specifications into SVG files. Each SVG element
    is automatically associated with blackened data and visualization structure information [[25](#bib.bib25),
    [28](#bib.bib28)]. Narration segments are further linked to these SVG visual elements
    based on the text-visual links established by the designer agent, akin to Data
    Player [[25](#bib.bib25)]. Then the corresponding animation effects are applied
    to the SVG elements based on the designer agent’s decisions. Next, annotated visualizations
    are parsed to detect SVG annotation elements, integrating “fade in” animations
    at corresponding timestamps. Finally, the controller calls a video synthesizer
    to merge visualizations, audio narration, and animation sequences into the final
    data video.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 控制器。如[图2](#S0.F2 "从数据到故事：基于LLM的多代理系统实现自动化动画数据视频创建")所示，基于模型的自然语言输出，控制器首先利用文本转语音服务将文本叙述转换为具有准确时间戳的音频，确保与数据视频时间线对齐。然后，控制器调用可视化渲染器，将Vega-Lite规格转换为SVG文件。每个SVG元素自动关联上被黑化的数据和可视化结构信息[[25](#bib.bib25),
    [28](#bib.bib28)]。叙述段落进一步根据设计代理建立的文本-视觉链接与这些SVG视觉元素关联，类似于Data Player[[25](#bib.bib25)]。然后，根据设计代理的决定，应用相应的动画效果到SVG元素上。接下来，解析标注的可视化以检测SVG标注元素，在相应的时间戳处整合“淡入”动画。最后，控制器调用视频合成器，将可视化、音频叙述和动画序列合并成最终的数据视频。
- en: 2 Case Study
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 案例研究
- en: '[Fig. 2](#S0.F2 "In From Data to Story: Towards Automatic Animated Data Video
    Creation with LLM-based Multi-Agent Systems") illustrates a real-world case study
    using stock price data. Data Director generates diverse insights (B) and visualizes
    stock prices over time using line charts (C). The narration followed a structured
    approach (C): starting with an overview, detailing each company’s performance,
    and concluding with a summary. Based on the narration, points and text annotations
    were added to each company’s line to highlight its notable characteristic (F).
    The bottom of [Fig. 2](#S0.F2 "In From Data to Story: Towards Automatic Animated
    Data Video Creation with LLM-based Multi-Agent Systems") displays key animation
    frames (E) from the video, with each frame numbered to correspond with specific
    timestamps in the narration (D). This demonstrates when specific animations are
    triggered. The final data video starts with an entrance animation showcasing all
    elements, and when discussing each company, the respective line is highlighted
    individually. Overall, the entire narrative is well-crafted, with smooth articulation
    and appropriately designed visualizations and animations, resulting in an engaging
    data video.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[图2](#S0.F2 "从数据到故事：基于LLM的多代理系统实现自动化动画数据视频创建")展示了一个使用股票价格数据的实际案例研究。Data Director生成了多种见解（B），并通过折线图（C）可视化了股票价格的变化。叙述遵循了结构化的方法（C）：从概述开始，详细描述每家公司的表现，并以总结结束。根据叙述，向每家公司的折线图上添加了点和文本标注，以突出其显著特征（F）。[图2](#S0.F2
    "从数据到故事：基于LLM的多代理系统实现自动化动画数据视频创建")底部显示了视频中的关键动画帧（E），每个帧都编号以对应叙述中的特定时间戳（D）。这展示了何时触发特定的动画。最终的数据视频以展示所有元素的入场动画开始，在讨论每家公司时，相应的折线图会单独高亮显示。总体而言，整个叙述制作精良，表达流畅，视觉和动画设计得当，生成了一个引人入胜的数据视频。'
- en: 3 Lessons Learned
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 经验教训
- en: This section will discuss the lessons learned throughout the development of
    Data Director, focusing on task decomposition, performance optimization, and workflow
    design.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将讨论在Data Director开发过程中获得的经验教训，重点关注任务分解、性能优化和工作流设计。
- en: 3.1 Task Decomposition
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 任务分解
- en: 'Balancing Accuracy and Efficiency. Task decomposition for data storytelling
    requires balancing accuracy and efficiency. When decomposing tasks, first, it
    is essential to identify which tasks the model excels in (e.g., natural language
    generation, reasoning, and text-based decision-making) and distinguish these from
    tasks that necessitate external tools (e.g., visualization rendering, audio generation,
    and video synthesizing). Second, the sub-tasks resulting from decomposition should
    be well-defined and manageable. These sub-tasks can then be grouped to shape agent
    roles that align with the inherent characteristics of the tasks. For example,
    Data Director breaks down tasks based on the data video components, and organizes
    sub-tasks into analysis-focused tasks that generate static content from raw data,
    and design-focused tasks that require creative input and the derivation of dynamic
    effects from the static content. Third, the suitable combination of sub-tasks
    can enhance both the model’s accuracy and efficiency, as demonstrated in [Section 1.2](#S1.SS2
    "1.2 Task Decomposition and Workflow Design ‣ 1 Data Director ‣ From Data to Story:
    Towards Automatic Animated Data Video Creation with LLM-based Multi-Agent Systems"),
    where animation design and temporal synchronization were merged. Finally, a top-down
    approach can be adopted to dissect tasks progressively, designing suitable and
    efficient models for each sub-task.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 平衡准确性与效率。数据讲述的任务分解需要平衡准确性和效率。在分解任务时，首先，必须识别模型擅长的任务（例如，*自然语言生成*、*推理*和*基于文本的决策制定*），并将这些任务与需要外部工具的任务（例如，*可视化渲染*、*音频生成*和*视频合成*）区分开来。其次，分解后的子任务应当明确定义且易于管理。这些子任务可以被分组以形成与任务固有特征相一致的代理角色。例如，Data
    Director 根据数据视频组件来分解任务，并将子任务组织为以分析为重点的任务，这些任务从原始数据中生成静态内容，以及需要创造性输入和从静态内容中衍生动态效果的设计为重点的任务。第三，适当组合子任务可以提升模型的准确性和效率，正如[1.2节](#S1.SS2
    "1.2 任务分解与工作流设计 ‣ 1 数据总监 ‣ 从数据到故事：基于LLM的多代理系统自动化动画数据视频创作")中所示，其中动画设计和时间同步被合并。最后，可以采用自上而下的方法逐步拆解任务，为每个子任务设计合适且高效的模型。
- en: Data Feeding with Contextual Information. Providing the model with ample contextual
    information has been found to enhance the accuracy and quality of its generation [[34](#bib.bib34)].
    As the model progresses through sub-tasks step by step, the context is enriched
    and updated, offering more information for subsequent operations. For example,
    in the data analyst agent, the model gradually gathers information on data descriptions,
    insights, visualizations, and narrations. However, when an agent perceives data
    from the environment, the data itself is merely numerical with limited context.
    We have found that semantically enriching the data and supplying the model with
    contextual insights significantly enhance its effectiveness. For example, Data
    Director uses the LLM to generate an NL description of a data table with a title.
    Future research could integrate innovative techniques for enhancing data comprehension
    and exploring novel methods for inputting data into LLMs.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 具有上下文信息的数据输入。为模型提供充足的上下文信息已被发现可以提高其生成的准确性和质量[[34](#bib.bib34)]。随着模型逐步完成子任务，上下文被丰富和更新，为后续操作提供更多信息。例如，在数据分析代理中，模型逐渐收集关于数据描述、见解、可视化和叙述的信息。然而，当代理从环境中感知数据时，数据本身仅是有限上下文的数字。我们发现，对数据进行语义丰富处理并为模型提供上下文见解显著提升了其效果。例如，Data
    Director 使用LLM生成带有标题的数据表的NL描述。未来的研究可以整合创新技术以增强数据理解，并探索将数据输入LLM的新方法。
- en: 3.2 Performance Optimization
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 性能优化
- en: 'Effective prompt design is crucial for enhancing the performance and output
    quality of LLM-based agent systems. The complete prompt of Data Director can be
    found in [Appendix A](#A1 "Appendix A Full Prompt ‣ From Data to Story: Towards
    Automatic Animated Data Video Creation with LLM-based Multi-Agent Systems"). The
    key strategies for optimizing prompts within this context are outlined as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 有效的提示设计对提高基于LLM的代理系统的性能和输出质量至关重要。Data Director 的完整提示可以在[附录A](#A1 "附录A 完整提示 ‣
    从数据到故事：基于LLM的多代理系统自动化动画数据视频创作")中找到。在这个背景下，优化提示的关键策略概述如下：
- en: 'Assignment of Appropriate Tasks for LLMs. The foundation of effective prompt
    design lies in the careful design of tasks for LLMs. It is essential to identify
    the tasks where LLMs are good at. Furthermore, assigning the model a specific
    role, such as a data analyst or designer in Data Director, can guide the model
    to produce domain-specific and contextually relevant outputs. In addition, supplying
    the model with precise and comprehensive context can enhance its understanding
    of tasks, thereby improving the accuracy and relevance of its responses. This
    involves crafting well-structured prompts (outlined in [Appendix A](#A1 "Appendix
    A Full Prompt ‣ From Data to Story: Towards Automatic Animated Data Video Creation
    with LLM-based Multi-Agent Systems")) and designing complementary modules like
    data preprocessing in Data Director.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 为 LLM 分配适当的任务。有效提示设计的基础在于精心设计 LLM 的任务。识别 LLM 擅长的任务是至关重要的。此外，为模型分配特定角色，例如数据分析师或设计师（在数据总监中），可以引导模型生成特定领域和上下文相关的输出。此外，向模型提供准确且全面的背景信息可以增强其对任务的理解，从而提高响应的准确性和相关性。这包括设计结构良好的提示（详见
    [附录 A](#A1 "附录 A 完整提示 ‣ 从数据到故事：基于 LLM 的多智能体系统自动化动画数据视频创建")）和设计补充模块，如数据总监中的数据预处理。
- en: Cognitive Processing Time and Task Decomposition. Allowing the model adequate
    cognitive processing time is essential for achieving high-quality outputs and
    alleviating hallucinations. Beyond the task decomposition discussed above, in
    terms of prompt design, the sub-tasks can be clearly defined with sequential steps,
    facilitating the application of the Chain-of-Thought strategy. Moreover, the number
    of tasks within one prompt should be balanced to deduce task difficulty. In addition,
    prompting the model to explain its decisions or outline its solution methodology
    before concluding can promote a more thoughtful and precise response generation
    process. For instance, in the designer agent, Data Director prompts the LLM to
    its choices regarding the animation and annotation design, which enhances the
    decision accuracy and simplifies the debugging of LLM applications during development.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 认知处理时间和任务分解。为模型提供足够的认知处理时间对于实现高质量输出和减少幻觉是至关重要的。除了上述讨论的任务分解，在提示设计方面，子任务可以通过顺序步骤进行明确界定，从而有助于应用思维链策略。此外，一个提示中的任务数量应保持平衡，以推断任务的难度。此外，提示模型在得出结论之前解释其决策或概述其解决方法，可以促进更深思熟虑和精确的响应生成过程。例如，在设计师代理中，数据总监会提示
    LLM 关于动画和注释设计的选择，这可以提高决策准确性并简化开发过程中 LLM 应用的调试。
- en: 'Crafting Precise and Unambiguous Instructions. The clarity and specificity
    of instructions are paramount in effective prompt design. Utilizing delimiters
    (e.g., “‘ “‘, “ ” or )
    to segment prompt sections can reduce ambiguity and aid comprehension. Providing
    fine-grained requirements and employing the correct use of keywords (e.g., “summarize”
    vs. “extract”) ensures that the model adheres closely to the task parameters.
    Furthermore, requesting structured outputs (e.g., JSON and HTML) and offering
    a range of response options can guide the model toward producing organized and
    practical outputs. For example, as shown in [Fig. 2](#S0.F2 "In From Data to Story:
    Towards Automatic Animated Data Video Creation with LLM-based Multi-Agent Systems"),
    Data Director allows LLMs to select insight types (B), animation types (E), and
    annotation types (F) from a set of predefined candidates. Additionally, incorporating
    conditional logic (e.g., if-else statements), employing few-shot or one-shot prompting
    techniques with curated examples, and referencing URLs for concrete examples can
    further enhance the model’s understanding and task execution accuracy. More specific
    examples can be found in [Appendix A](#A1 "Appendix A Full Prompt ‣ From Data
    to Story: Towards Automatic Animated Data Video Creation with LLM-based Multi-Agent
    Systems").'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 精确和明确的指令设计。在有效的提示设计中，指令的清晰度和具体性至关重要。使用定界符（例如，“‘ “‘, “ ” 或 ）来划分提示部分可以减少歧义并帮助理解。提供细化的要求并正确使用关键词（例如，“summarize”
    vs. “extract”）可以确保模型紧密遵循任务参数。此外，要求结构化输出（例如，JSON 和 HTML）并提供多种响应选项可以引导模型生成有组织且实用的输出。例如，如[图
    2](#S0.F2 "在数据到故事：基于 LLM 的多智能体系统的自动动画数据视频创建")所示，Data Director 允许 LLM 从一组预定义的候选项中选择洞察类型（B）、动画类型（E）和注释类型（F）。此外，结合条件逻辑（例如，if-else
    语句）、使用少量示例或单个示例提示技术，并引用具体示例的 URL，可以进一步提升模型的理解和任务执行准确性。更多具体示例见[附录 A](#A1 "附录 A
    完整提示 ‣ 从数据到故事：基于 LLM 的多智能体系统的自动动画数据视频创建")。
- en: 3.3 Workflow Design
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 工作流设计
- en: 'Shared Representation. This paper primarily utilizes the GPT-4 model [[2](#bib.bib2)],
    with natural language serving as the medium for input and output, setting the
    stage for this discussion. Effective communication between agents and between
    agents and external tools requires an appropriate shared NL representation. For
    instance, Vega-Lite is employed in Data Director to represent all visualizations
    and annotations, while insights and animated visual information are encapsulated
    in a JSON format, incorporating specific feature information (see [Fig. 2](#S0.F2
    "In From Data to Story: Towards Automatic Animated Data Video Creation with LLM-based
    Multi-Agent Systems")). Such shared representations must be comprehensible and
    easily generated by the model and readily interpreted by external tools for mapping
    to internal operations. Future work could involve designing a global shared representation
    for specific application scenarios to assist models in better preserving and generating
    contextual information.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 共享表示。这篇论文主要使用 GPT-4 模型[[2](#bib.bib2)]，自然语言作为输入和输出的媒介，为讨论奠定了基础。代理之间以及代理与外部工具之间的有效沟通需要适当的共享自然语言表示。例如，Data
    Director 中使用 Vega-Lite 来表示所有可视化和注释，而洞察和动画视觉信息则以 JSON 格式封装，包含具体的特征信息（见[图 2](#S0.F2
    "在数据到故事：基于 LLM 的多智能体系统的自动动画数据视频创建")）。这种共享表示必须易于模型理解和生成，并且外部工具可以轻松解释以映射到内部操作。未来的工作可能涉及为特定应用场景设计全球共享表示，以帮助模型更好地保留和生成上下文信息。
- en: Iterative Development. Various sub-tasks within the workflow present diverse
    sequencing strategies. For instance, annotations can be generated simultaneously
    with visualizations, during animation generation, or using a hierarchical approach
    as described in Data Director. Similarly, in data analysis, one may opt to produce
    visualizations either before or after narration. Designing the optimal sequencing
    strategy is challenging due to the absence of a quantitative global optimization
    objective. Hence, for applications of LLM-based agents, we adopt an iterative
    design methodology based on task decomposition and local performance optimization [[1](#bib.bib1)].
    This involves a cycle of ideation, implementation, experimental evaluation, and
    error analysis. Striving for consistency in the model’s outputs also necessitates
    adherence to established guidelines and meticulous parameter adjustments. We note
    that Data Director presented here is the result of our iterative optimizations
    and may not necessarily represent the optimal configuration. Our intention in
    developing this prototype tool is to uncover valuable lessons and insights that
    can guide future research.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代开发。工作流程中的各种子任务呈现出不同的排序策略。例如，注释可以与可视化同时生成，在动画生成过程中生成，或者使用如数据总监中所描述的分层方法生成。同样，在数据分析中，可以选择在叙述之前或之后生成可视化。设计最佳的排序策略具有挑战性，因为缺乏定量的全球优化目标。因此，对于基于LLM的智能体应用，我们采用基于任务分解和局部性能优化的迭代设计方法[[1](#bib.bib1)]。这包括一个构思、实施、实验评估和错误分析的循环。追求模型输出的一致性还需要遵循既定的指导方针和细致的参数调整。我们注意到，此处呈现的数据总监是我们迭代优化的结果，可能不一定代表最佳配置。我们开发这个原型工具的目的是发现有价值的经验和见解，以指导未来的研究。
- en: 4 Future Work
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 未来工作
- en: 'Global Optimization and Benchmarking. The iterative development of multi-agent
    systems, as mentioned in [Section 1.2](#S1.SS2 "1.2 Task Decomposition and Workflow
    Design ‣ 1 Data Director ‣ From Data to Story: Towards Automatic Animated Data
    Video Creation with LLM-based Multi-Agent Systems"), suffers from the lack of
    a global optimization and validation framework for end-to-end data video generation [[16](#bib.bib16)].
    Additionally, the community lacks a widely recognized benchmark. The complexity
    of this challenge is compounded by the inherently subjective nature of data storytelling
    quality, which is subject to individual interpretation and the multifaceted decision-making
    involved in various narrative forms. Future work could include summarizing relevant
    rubrics and conducting empirical studies to derive quantitative guidelines. With
    these well-defined metrics, an evaluation agent can also be added to enhance existing
    workflow. Additionally, there is a need to develop a universally shared representation
    for optimization and incorporate domain-specific languages and objectives tailored
    to diverse scenarios [[15](#bib.bib15), [17](#bib.bib17)].'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 全球优化与基准测试。正如在[第1.2节](#S1.SS2 "1.2 任务分解与工作流程设计 ‣ 1 数据总监 ‣ 从数据到故事：基于LLM的多智能体系统自动化动画数据视频创作")中提到的，多智能体系统的迭代开发面临缺乏全球优化和验证框架的问题[[16](#bib.bib16)]。此外，社区还缺乏广泛认可的基准。这一挑战的复杂性还在于数据讲述质量本质上是主观的，受个体解释和多样化叙事形式中的决策因素的影响。未来的工作可能包括总结相关的评分标准并进行实证研究，以制定定量指导方针。通过这些明确定义的指标，还可以添加评估代理来增强现有工作流程。此外，还需要开发一个普遍共享的优化表示，并纳入针对不同场景的领域特定语言和目标[[15](#bib.bib15),
    [17](#bib.bib17)]。
- en: 'Human-in-the-Loop. Data-driven end-to-end generation solutions can result in
    one-size-fits-all outputs. To address the issues, incorporating human-in-the-loop
    is an essential approach to compensate for model limitations and generate more
    personalized results [[11](#bib.bib11), [10](#bib.bib10)]. In data storytelling,
    three paradigms of human-in-the-loop can be further explored: firstly, allowing
    users to input more information in the perception module while maintaining the
    current architecture, articulating their goals and requirements in the forms like
    natural language [[20](#bib.bib20)], example [[36](#bib.bib36), [22](#bib.bib22)],
    and sketch [[14](#bib.bib14)]; secondly, integrating humans into sub-tasks to
    achieve local optimization before proceeding to the next stage, such as generating
    multiple candidates for visualization and annotation after generating data insights;
    thirdly, users providing conversational feedback based on the output [[20](#bib.bib20),
    [31](#bib.bib31)], with the agent generating new end-to-end results based on this
    feedback. Additionally, these methods can also be flexibly combined.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 人机协作。基于数据驱动的端到端生成解决方案可能导致千篇一律的输出。为了解决这些问题，融入人机协作是弥补模型局限性和生成更个性化结果的**关键方法**[[11](#bib.bib11),
    [10](#bib.bib10)]。在数据叙事中，人机协作有三种模式可以进一步探索：首先，允许用户在感知模块中输入更多信息，同时保持现有架构，以自然语言[[20](#bib.bib20)]、示例[[36](#bib.bib36),
    [22](#bib.bib22)]和草图[[14](#bib.bib14)]等形式表达他们的目标和需求；其次，将人类融入子任务以实现局部优化，然后再进入下一个阶段，例如在生成数据洞察后生成多个可视化和注释候选项；第三，用户根据输出提供对话反馈[[20](#bib.bib20),
    [31](#bib.bib31)]，代理根据这些反馈生成新的端到端结果。此外，这些方法也可以灵活组合。
- en: 'Keeping Up with Cutting-Edge Models. This paper primarily uses the GPT-4 model.
    However, with the rapid evolution of large language models (LLMs), GPT-4 is swiftly
    being augmented by the emergence of multimodal LLMs [[38](#bib.bib38)]. These
    advanced models offer expanded functionalities for handling multimodal inputs
    and outputs, significantly impacting task decomposition, performance optimization,
    and workflow design within our established framework ([Fig. 1](#S0.F1 "In From
    Data to Story: Towards Automatic Animated Data Video Creation with LLM-based Multi-Agent
    Systems")). For instance, initial generation of visualization files could be followed
    by refinement in a subsequent multimodal module, potentially leading to direct
    generation of video content. The enhancement of model capabilities presents numerous
    opportunities. Future work should not only track the latest models to develop
    more powerful agents but also leverage diverse models with different capabilities
    to enrich data storytelling. This includes expanding beyond individual static
    charts to incorporate visual and musical content [[29](#bib.bib29)], supporting
    more complex insights and multi-view visualizations [[13](#bib.bib13)], integrating
    existing computational design spaces (e.g., camera [[12](#bib.bib12)] and narrative
    structure [[37](#bib.bib37)]), and accommodating more data types (e.g., unstructured
    graphs [[24](#bib.bib24)]). Achieving these features requires enhancing shared
    representations and designing corresponding prompts (similar to how Data Director integrates
    animation).'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 跟上前沿模型。本论文主要使用**GPT-4**模型。然而，随着大型语言模型（LLMs）的快速发展，GPT-4正迅速被多模态LLMs[[38](#bib.bib38)]的出现所补充。这些先进模型提供了处理多模态输入和输出的扩展功能，对任务分解、性能优化和我们既有框架中的工作流程设计产生了显著影响（[图1](#S0.F1
    "从数据到故事：基于LLM的多智能体系统的自动动画数据视频创作")）。例如，初步生成的可视化文件可以在后续的多模态模块中进行精炼，可能直接生成视频内容。模型能力的提升带来了许多机会。未来的工作不仅应跟踪最新模型以开发更强大的智能体，还应利用具有不同能力的多样化模型来丰富数据叙事。这包括扩展到单个静态图表之外，融入视觉和音乐内容[[29](#bib.bib29)]，支持更复杂的洞察和多视图可视化[[13](#bib.bib13)]，整合现有的计算设计空间（如[相机](#bib.bib12)和叙事结构[[37](#bib.bib37)]），以及适应更多数据类型（如[非结构化图表](#bib.bib24)）。实现这些功能需要增强共享表示和设计相应的提示（类似于**Data
    Director**如何集成动画）。
- en: Inherent Limitations of Large Language Models. LLMs are powerful but exhibit
    several inherent limitations, such as error accumulation, inconsistent results,
    hallucinations, and high time costs. Most importantly, we need to acknowledge
    that the content from LLMs is generative but not truthful. To address error accumulation,
    incorporating a human-in-the-loop approach and providing timely tips can improve
    accuracy. Consistency in results can be improved by strictly following established
    guidelines and creating supplementary rules to handle the model’s output. Hallucinations,
    where the model generates plausible but incorrect information, can be improved
    by implementing some prompt optimization strategies, such as self-repair mechanisms,
    the Chain-of-Thought (CoT) approach, and code-interpreter functionalities [[34](#bib.bib34)].
    Lastly, high-time costs can be managed by breaking down tasks, finding suitable
    solutions for each (e.g., heuristics, basic models, and LLMs). It’s important
    to recognize that LLMs are not a one-size-fits-all solution; sometimes, basic
    models or heuristic rules can be highly effective without the need for LLMs.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型的固有局限性。LLMs功能强大但存在几个固有局限性，如错误积累、不一致的结果、虚假信息和高时间成本。最重要的是，我们需要认识到LLMs生成的内容是生成性的，而非真实的。为了解决错误积累的问题，结合人类参与的方式并提供及时提示可以提高准确性。通过严格遵循既定的指南和制定补充规则来处理模型的输出，可以提高结果的一致性。对于模型生成的看似合理但不正确的信息，可以通过实施一些提示优化策略来改善，如自我修复机制、思维链（CoT）方法和代码解释功能[[34](#bib.bib34)]。最后，通过将任务拆分，寻找适当的解决方案（例如，启发式、基本模型和LLMs）可以管理高时间成本。重要的是要认识到LLMs并不是一种万能解决方案；有时基本模型或启发式规则可以在不需要LLMs的情况下非常有效。
- en: 5 Conclusion
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论
- en: The rapid evolution of LLMs presents new opportunities for creating end-to-end
    multi-agent systems for data storytelling. Through the development of Data Director,
    we have derived valuable insights into task decomposition, local performance optimization
    through prompt design, and workflow design. In addition, we also shed light on
    future directions in the development of globally optimized multi-agents, human-in-the-loop
    systems, integration of cutting-edge multimodal models, and addressing inherent
    LLM limitations.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs的快速发展为创建端到端多代理的数据讲述系统提供了新的机会。通过开发Data Director，我们获得了关于任务分解、通过提示设计进行局部性能优化和工作流程设计的宝贵见解。此外，我们还对全球优化多代理、人类参与系统、前沿多模态模型的整合以及解决LLM固有局限性方面的未来方向提供了见解。
- en: Acknowledgements.
  id: totrans-68
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 致谢。
- en: The authors wish to thank all reviewers for their valuable feedback. This work
    has been partially supported by RGC GRF Grant 16210321.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 作者们感谢所有审稿人提供的宝贵反馈。此项工作部分得到了RGC GRF资助16210321的支持。
- en: References
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Chatgpt prompt engineering for developers. [https://learn.deeplearning.ai/chatgpt-prompt-eng/](https://learn.deeplearning.ai/chatgpt-prompt-eng/).'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Chatgpt提示工程为开发人员提供。 [https://learn.deeplearning.ai/chatgpt-prompt-eng/](https://learn.deeplearning.ai/chatgpt-prompt-eng/)。'
- en: '[2] Openai gpt-4. [https://openai.com/gpt-4](https://openai.com/gpt-4).'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Openai gpt-4. [https://openai.com/gpt-4](https://openai.com/gpt-4)。'
- en: '[3] F. Amini, N. H. Riche, B. Lee, A. Monroy-Hernandez, and P. Irani. Authoring
    data-driven videos with dataclips. IEEE Transactions on Visualization and Computer
    Graphics, 23(1):501–510, 2017.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] F. Amini, N. H. Riche, B. Lee, A. Monroy-Hernandez, 和 P. Irani. 使用数据片段创作数据驱动的视频。IEEE计算机视觉与图形学汇刊,
    23(1):501–510, 2017。'
- en: '[4] C. Beasley and A. Abouzied. Pipe(line) Dreams: Fully Automated End-to-End
    Analysis and Visualization. In Proceedings of the 2024 Workshop on Human-In-the-Loop
    Data Analytics, pp. 1–7\. ACM, 2024.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] C. Beasley 和 A. Abouzied. Pipe(line) 梦想：全自动端到端分析和可视化。见于2024年人类在数据分析中的作用研讨会论文集,
    第1–7页。ACM, 2024。'
- en: '[5] Y. Cao, J. L. E, Z. Chen, and H. Xia. DataParticles: Block-based and Language-oriented
    Authoring of Animated Unit Visualizations. In Proceedings of the 2023 CHI Conference
    on Human Factors in Computing Systems, CHI ’23, pp. 1–15\. ACM, 2023.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Y. Cao, J. L. E, Z. Chen, 和 H. Xia. DataParticles: 基于块和语言导向的动画单元可视化创作。见于2023年CHI计算机系统人因会议论文集,
    CHI ’23, 第1–15页。ACM, 2023。'
- en: '[6] H. Cheng, J. Wang, Y. Wang, B. Lee, H. Zhang, and D. Zhang. Investigating
    the role and interplay of narrations and animations in data videos. Computer Graphics
    Forum, 41(3):527–539, 2022.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] H. Cheng, J. Wang, Y. Wang, B. Lee, H. Zhang, 和 D. Zhang. 探讨叙述和动画在数据视频中的角色和相互作用。计算机图形学论坛,
    41(3):527–539, 2022。'
- en: '[7] V. Dibia. LIDA: A Tool for Automatic Generation of Grammar-Agnostic Visualizations
    and Infographics using Large Language Models. In Proceedings of the 61st Annual
    Meeting of the Association for Computational Linguistics, ACL’23, pp. 113–126\.
    ACL, 2023.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] V. Dibia. LIDA：一个用于自动生成语法无关可视化和信息图的工具，利用大型语言模型。载于《第 61 届计算语言学协会年会论文集》，ACL’23，第
    113–126 页。ACL，2023。'
- en: '[8] T. Ge, B. Lee, and Y. Wang. CAST: Authoring Data-Driven Chart Animations.
    In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems,
    CHI ’21, pp. 1–15\. ACM, 2021.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] T. Ge, B. Lee, 和 Y. Wang. CAST：数据驱动的图表动画创作工具。载于《2021 年 CHI 计算机系统人因会议论文集》，CHI
    ’21，第 1–15 页。ACM，2021。'
- en: '[9] T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and Y. Iwasawa. Large language
    models are zero-shot reasoners. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave,
    K. Cho, and A. Oh, eds., Proceedings of Advances in Neural Information Processing
    Systems, NIPS’22, vol. 35, pp. 22199–22213, 2022.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, 和 Y. Iwasawa. 大型语言模型是零-shot 推理器。载于
    S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, 和 A. Oh 主编的《神经信息处理系统进展论文集》，NIPS’22，第
    35 卷，第 22199–22213 页，2022。'
- en: '[10] H. Li, Y. Wang, Q. V. Liao, and H. Qu. Why is AI not a Panacea for Data
    Workers? An Interview Study on Human-AI Collaboration in Data Storytelling. arXiv
    preprint arXiv:2304.08366, 2023.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] H. Li, Y. Wang, Q. V. Liao, 和 H. Qu. 为什么人工智能不是数据工作者的万灵药？关于人类-人工智能合作在数据讲述中的访谈研究。arXiv
    预印本 arXiv:2304.08366，2023。'
- en: '[11] H. Li, Y. Wang, and H. Qu. Where Are We So Far? Understanding Data Storytelling
    Tools from the Perspective of Human-AI Collaboration. In Proceedings of CHI Conference
    on Human Factors in Computing Systems, CHI’24, pp. 1–28, 2024.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] H. Li, Y. Wang, 和 H. Qu. 我们现在到哪里了？从人类-人工智能合作的角度理解数据讲述工具。载于《CHI 计算机系统人因会议论文集》，CHI’24，第
    1–28 页，2024。'
- en: '[12] W. Li, Z. Wang, Y. Wang, D. Weng, L. Xie, S. Chen, H. Zhang, and H. Qu.
    GeoCamera: Telling Stories in Geographic Visualizations with Camera Movements.
    In Proceedings of CHI Conference on Human Factors in Computing Systems, CHI’23,
    pp. 1–15\. ACM, 2023.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] W. Li, Z. Wang, Y. Wang, D. Weng, L. Xie, S. Chen, H. Zhang, 和 H. Qu.
    GeoCamera：通过相机移动讲述地理可视化中的故事。载于《CHI 计算机系统人因会议论文集》，CHI’23，第 1–15 页。ACM，2023。'
- en: '[13] Y. Lin, H. Li, A. Wu, Y. Wang, and H. Qu. DMiner: Dashboard Design Mining
    and Recommendation. IEEE Transactions on Visualization and Computer Graphics,
    30(7):4108–4121, 2024.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Y. Lin, H. Li, A. Wu, Y. Wang, 和 H. Qu. DMiner：仪表板设计挖掘与推荐。IEEE 视觉化与计算机图形学杂志，30(7)：4108–4121，2024。'
- en: '[14] Y. Lin, H. Li, L. Yang, A. Wu, and H. Qu. InkSight: Leveraging Sketch
    Interaction for Documenting Chart Findings in Computational Notebooks. IEEE Transactions
    on Visualization and Computer Graphics, 30(1):944 – 954, 2024.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Y. Lin, H. Li, L. Yang, A. Wu, 和 H. Qu. InkSight：利用草图交互记录计算笔记本中的图表发现。IEEE
    视觉化与计算机图形学杂志，30(1)：944 – 954，2024。'
- en: '[15] Y. Ouyang, L. Shen, Y. Wang, and Q. Li. NotePlayer: Engaging Jupyter Notebooks
    for Dynamic Presentation of Analytical Processes. arXiv preprint arXiv:2408.01101,
    pp. 1–15, 2024.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Y. Ouyang, L. Shen, Y. Wang, 和 Q. Li. NotePlayer：用于动态展示分析过程的引人入胜的 Jupyter
    笔记本。arXiv 预印本 arXiv:2408.01101，第 1–15 页，2024。'
- en: '[16] J. S. Park, J. O’Brien, C. J. Cai, M. R. Morris, P. Liang, and M. S. Bernstein.
    Generative Agents: Interactive Simulacra of Human Behavior. In Proceedings of
    the Annual ACM Symposium on User Interface Software and Technology, UIST’23, pp.
    1–22\. ACM, 2023.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] J. S. Park, J. O’Brien, C. J. Cai, M. R. Morris, P. Liang, 和 M. S. Bernstein.
    生成代理：人类行为的互动模拟体。载于《年度 ACM 用户界面软件与技术研讨会论文集》，UIST’23，第 1–22 页。ACM，2023。'
- en: '[17] S. Sallam, Y. Sakamoto, J. Leboe-McGowan, C. Latulipe, and P. Irani. Towards
    Design Guidelines for Effective Health-Related Data Videos: An Empirical Investigation
    of Affect, Personality, and Video Content. In Proceedings of CHI Conference on
    Human Factors in Computing Systems, CHI’22, pp. 1–22\. ACM, 2022.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] S. Sallam, Y. Sakamoto, J. Leboe-McGowan, C. Latulipe, 和 P. Irani. 有效健康相关数据视频的设计指南：对情感、个性和视频内容的实证研究。载于《CHI
    计算机系统人因会议论文集》，CHI’22，第 1–22 页。ACM，2022。'
- en: '[18] A. Satyanarayan, D. Moritz, K. Wongsuphasawat, and J. Heer. Vega-Lite:
    A Grammar of Interactive Graphics. IEEE Transactions on Visualization and Computer
    Graphics, 23(1):341–350, 2017.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] A. Satyanarayan, D. Moritz, K. Wongsuphasawat, 和 J. Heer. Vega-Lite：交互图形的语法。IEEE
    视觉化与计算机图形学杂志，23(1)：341–350，2017。'
- en: '[19] E. Segel and J. Heer. Narrative visualization: Telling stories with data.
    IEEE Transactions on Visualization and Computer Graphics, 16(6):1139–1148, 2010.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] E. Segel 和 J. Heer. 叙事可视化：用数据讲故事。IEEE 视觉化与计算机图形学杂志，16(6)：1139–1148，2010。'
- en: '[20] L. Shen, E. Shen, Y. Luo, X. Yang, X. Hu, X. Zhang, Z. Tai, and J. Wang.
    Towards Natural Language Interfaces for Data Visualization: A Survey. IEEE Transactions
    on Visualization and Computer Graphics, 29(6):3121–3144, 2023.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] L. Shen, E. Shen, Y. Luo, X. Yang, X. Hu, X. Zhang, Z. Tai, 和 J. Wang.
    面向数据可视化的自然语言接口：综述。IEEE 计算机图形学与可视化学报, 29(6):3121–3144, 2023年。'
- en: '[21] L. Shen, E. Shen, Z. Tai, Y. Song, and J. Wang. TaskVis: Task-oriented
    Visualization Recommendation. In Proceedings of the 23th Eurographics Conference
    on Visualization (Short Papers), EuroVis’21, pp. 91–95\. Eurographics, 2021.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] L. Shen, E. Shen, Z. Tai, Y. Song, 和 J. Wang. TaskVis: 面向任务的可视化推荐。第23届欧罗图形学可视化会议论文集（简短论文），EuroVis’21，第91–95页。欧罗图形学,
    2021年。'
- en: '[22] L. Shen, E. Shen, Z. Tai, Y. Wang, Y. Luo, and J. Wang. GALVIS: Visualization
    Construction through Example-Powered Declarative Programming. In Proceedings of
    the 31st ACM International Conference on Information & Knowledge Management, CIKM’22,
    pp. 4975–4979\. ACM, 2022.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] L. Shen, E. Shen, Z. Tai, Y. Wang, Y. Luo, 和 J. Wang. GALVIS: 通过示例驱动的声明式编程构建可视化。第31届ACM国际信息与知识管理会议论文集，CIKM’22，第4975–4979页。ACM,
    2022年。'
- en: '[23] L. Shen, E. Shen, Z. Tai, Y. Xu, J. Dong, and J. Wang. Visual Data Analysis
    with Task-Based Recommendations. Data Science and Engineering, 7(4):354–369, 2022.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] L. Shen, E. Shen, Z. Tai, Y. Xu, J. Dong, 和 J. Wang. 基于任务的视觉数据分析。数据科学与工程,
    7(4):354–369, 2022年。'
- en: '[24] L. Shen, Z. Tai, E. Shen, and J. Wang. Graph Exploration With Embedding-Guided
    Layouts. IEEE Transactions on Visualization and Computer Graphics, 30(7):3693–3708,
    2024.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] L. Shen, Z. Tai, E. Shen, 和 J. Wang. 嵌入引导布局的图形探索。IEEE 计算机图形学与可视化学报, 30(7):3693–3708,
    2024年。'
- en: '[25] L. Shen, Y. Zhang, H. Zhang, and Y. Wang. Data Player: Automatic Generation
    of Data Videos with Narration-Animation Interplay. IEEE Transactions on Visualization
    and Computer Graphics, 30(1):109–119, 2024.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] L. Shen, Y. Zhang, H. Zhang, 和 Y. Wang. Data Player: 自动生成带叙述动画互动的数据视频。IEEE
    计算机图形学与可视化学报, 30(1):109–119, 2024年。'
- en: '[26] D. Shi, F. Sun, X. Xu, X. Lan, D. Gotz, and N. Cao. AutoClips: An Automatic
    Approach to Video Generation from Data Facts. Computer Graphics Forum, 40(3):495–505,
    2021.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] D. Shi, F. Sun, X. Xu, X. Lan, D. Gotz, 和 N. Cao. AutoClips: 一种从数据事实自动生成视频的方法。计算机图形学论坛,
    40(3):495–505, 2021年。'
- en: '[27] M. Shin, J. Kim, Y. Han, L. Xie, M. Whitelaw, B. C. Kwon, S. Ko, and N. Elmqvist.
    Roslingifier: Semi-Automated Storytelling for Animated Scatterplots. IEEE Transactions
    on Visualization and Computer Graphics, 29(6):2980–2995, 2023.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] M. Shin, J. Kim, Y. Han, L. Xie, M. Whitelaw, B. C. Kwon, S. Ko, 和 N.
    Elmqvist. Roslingifier: 半自动化讲故事方法用于动画散点图。IEEE 计算机图形学与可视化学报, 29(6):2980–2995, 2023年。'
- en: '[28] L. S. Snyder and J. Heer. DIVI: Dynamically Interactive Visualization.
    IEEE Transactions on Visualization and Computer Graphics, 30(1):403–413, 2024.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] L. S. Snyder 和 J. Heer. DIVI: 动态交互式可视化。IEEE 计算机图形学与可视化学报, 30(1):403–413,
    2024年。'
- en: '[29] T. Tang, J. Tang, J. Lai, L. Ying, Y. Wu, L. Yu, and P. Ren. SmartShots:
    An Optimization Approach for Generating Videos with Data Visualizations Embedded.
    ACM Transactions on Interactive Intelligent Systems, 12(1):1–21, 2022.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] T. Tang, J. Tang, J. Lai, L. Ying, Y. Wu, L. Yu, 和 P. Ren. SmartShots:
    一种用于生成嵌入数据可视化视频的优化方法。ACM 互动智能系统学报, 12(1):1–21, 2022年。'
- en: '[30] J. R. Thompson, Z. Liu, and J. Stasko. Data Animator: Authoring Expressive
    Animated Data Graphics. In Proceedings of the 2021 CHI Conference on Human Factors
    in Computing Systems, CHI’21, pp. 1–18\. ACM, 2021.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] J. R. Thompson, Z. Liu, 和 J. Stasko. Data Animator: 创作富有表现力的动画数据图形。第2021年CHI计算机系统人因会议论文集，CHI’21，第1–18页。ACM,
    2021年。'
- en: '[31] Y. Wang, Z. Hou, L. Shen, T. Wu, J. Wang, H. Huang, H. Zhang, and D. Zhang.
    Towards Natural Language-Based Visualization Authoring. IEEE Transactions on Visualization
    and Computer Graphics, 29(1):1222 – 1232, 2023.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Y. Wang, Z. Hou, L. Shen, T. Wu, J. Wang, H. Huang, H. Zhang, 和 D. Zhang.
    面向自然语言的可视化创作。IEEE 计算机图形学与可视化学报, 29(1):1222 – 1232, 2023年。'
- en: '[32] Y. Wang, L. Shen, Z. You, X. Shu, B. Lee, J. Thompson, H. Zhang, and D. Zhang.
    WonderFlow: Narration-Centric Design of Animated Data Videos. IEEE Transactions
    on Visualization and Computer Graphics, pp. 1–15, 2024.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] Y. Wang, L. Shen, Z. You, X. Shu, B. Lee, J. Thompson, H. Zhang, 和 D.
    Zhang. WonderFlow: 以叙述为中心的动画数据视频设计。IEEE 计算机图形学与可视化学报，第1–15页，2024年。'
- en: '[33] Y. Wang, Z. Sun, H. Zhang, W. Cui, K. Xu, X. Ma, and D. Zhang. DataShot:
    Automatic Generation of Fact Sheets from Tabular Data. IEEE Transactions on Visualization
    and Computer Graphics, 26(1):895–905, 2020.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] Y. Wang, Z. Sun, H. Zhang, W. Cui, K. Xu, X. Ma, 和 D. Zhang. DataShot:
    从表格数据自动生成事实表。IEEE 计算机图形学与可视化学报, 26(1):895–905, 2020年。'
- en: '[34] Y. Wu, Y. Wan, H. Zhang, Y. Sui, W. Wei, W. Zhao, G. Xu, and H. Jin. Automated
    Data Visualization from Natural Language via Large Language Models: An Exploratory
    Study. In Proceedings of the ACM on Management of Data, SIGMOD’24, pp. 1–28\.
    ACM, 2024.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] Y. 吴, Y. 万, H. 张, Y. 隋, W. 韦, W. 赵, G. 许, 和 H. 金. 通过大语言模型自动化数据可视化：探索性研究。发表于
    ACM 数据管理会议论文集, SIGMOD’24, 第1–28页。ACM, 2024年。'
- en: '[35] Z. Xi, W. Chen, X. Guo, W. He, and et al. The Rise and Potential of Large
    Language Model Based Agents: A Survey. arXiv: 2309.07864, pp. 1–86, 2023.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] Z. 西, W. 陈, X. 郭, W. 赫, 等. 基于大语言模型的代理的崛起与潜力：一项调查。arXiv: 2309.07864, 第1–86页,
    2023年。'
- en: '[36] L. Xie, Z. Zhou, K. Yu, Y. Wang, H. Qu, and S. Chen. Wakey-Wakey: Animate
    Text by Mimicking Characters in a GIF. In Proceedings of the 36th Annual ACM Symposium
    on User Interface Software and Technology, UIST’23, pp. 1–14\. ACM, 2023.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] L. 谢, Z. 周, K. 余, Y. 王, H. 瞿, 和 S. 陈. Wakey-Wakey: 通过模仿 GIF 中的角色来动态展示文本。发表于第36届
    ACM 用户界面软件与技术年会论文集, UIST’23, 第1–14页。ACM, 2023年。'
- en: '[37] L. Yang, X. Xu, X. Y. Lan, Z. Liu, S. Guo, Y. Shi, H. Qu, and N. Cao.
    A Design Space for Applying the Freytag’s Pyramid Structure to Data Stories. IEEE
    Transactions on Visualization and Computer Graphics, 28(1):922–932, 2022.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] L. 杨, X. 许, X. Y. 兰, Z. 刘, S. 郭, Y. 石, H. 瞿, 和 N. 曹. 将 Freytag 金字塔结构应用于数据故事的设计空间。IEEE
    可视化与计算机图形学汇刊, 28(1):922–932, 2022年。'
- en: '[38] S. Yin, C. Fu, S. Zhao, K. Li, X. Sun, T. Xu, and E. Chen. A survey on
    multimodal large language models. arXiv:2306.13549, 2023.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] S. 尹, C. 付, S. 赵, K. 李, X. 孙, T. 许, 和 E. 陈. 多模态大语言模型调查。arXiv:2306.13549,
    2023年。'
- en: '[39] L. Ying, Y. Wang, H. Li, S. Dou, H. Zhang, X. Jiang, H. Qu, and Y. Wu.
    Reviving Static Charts into Live Charts. IEEE Transactions on Visualization and
    Computer Graphics, pp. 1–15, 2024.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] L. 英, Y. 王, H. 李, S. 魏, H. 张, X. 姜, H. 瞿, 和 Y. 吴. 将静态图表复活为动态图表。IEEE 可视化与计算机图形学汇刊，第1–15页,
    2024年。'
- en: Appendix A Full Prompt
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 完整提示
- en: 'Listing 1: The prompt of generating text description for data tables'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 1：生成数据表文本描述的提示
- en: 'Give  a  short  and  consistent  description  of  the  following  data  table  and  columns:{{table}}The  title  of  the  data  table  is:  {{title}}The  output  JSON  format  is:{"Description":  [A]}where  [A]  is  the  generated  description.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '给出以下数据表及其列的简短且一致的描述：{{table}} 数据表的标题是：{{title}} 输出的 JSON 格式为：{"Description":
    [A]} 其中 [A] 是生成的描述。'
- en: 'Listing 2: The prompt of the agent acting as a data analyst'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 2：作为数据分析师的代理的提示
- en: 'You  are  a  data  analyst.  You  have  a  data  table  at  hand.{{description}}The  full  data  table  is:{{table}}You  need  to  complete  several  tasks,  please  think  step  by  step.Task  1:  Please  list  the  top  insights  you  can  gather  from  the  following  data  table.Notes  for  insight  extraction:-  The  output  JSON  format  is:[{"insight":  insight  content,"type":  a  list  of  corresponding  insight  types}]-  The  insight  type  belongs  to  the  following  list:  [Change  Over  Time,  Characterize  Distribution,  Cluster,  Comparison,  Correlate,  Determine  Range,  Deviation,  Find  Anomalies,  Find  Extremum,  Magnitude,  Part  to  Whole,  Sort,  Trend].  One  insight  can  correspond  to  multiple  types.-  The  selected  insights  should  be  obvious,  valuable,  and  diverse.-  Double-check  that  the  comparison  of  numerical  magnitudes  is  accurate.  Ensure  that  the  insight  is  right.-  Ignore  the  "index"  column.Task  2:  Please  draw  a  Vega-Lite  visualization  to  tell  the  insights  based  on  the  data  table.Notes  for  visualization  generation:-  Your  title  should  be  less  than  10  words.-  If  you  use  the  color  channel,  refer  to  the  following  color  scheme:  https://vega.github.io/vega/docs/schemes/-  Your  visualization  should  have  the  right  height  and  width.-  If  the  visualization  is  a  line  chart,  it  should  include  data  points.-  If  the  focus  of  the  data  table  presentation  is  on  percentage  information  of  one  single  column,  then  use  a  pie  chart  to  present  it.  The  percentage  of  each  sector  should  be  displayed  on  the  corresponding  sector  via  text  annotation  like  https://vega.github.io/vega-lite/examples/layer_arc_label.html.-  Use  a  single  chart  to  visualize  the  data,  and  the  index  column  should  not  be  visualized.Task  3:  Please  write  a  streamlined  narration  for  the  insights.Notes  for  narration  generation:-  Writing  narration  in  the  tone  of  describing  the  visualization  instead  of  describing  the  data  table.-  Your  logic  should  be  compelling,  linking  insights  into  a  story,  and  avoiding  enumerating  insights.-  Avoid  using  additional  explanations.  Avoid  speculating  on  conclusions  and  redundant  explanations  beyond  the  data.-  Content  should  be  streamlined.-  Ignore  the  "index"  column.The  final  output  JSON  format  is:{"Insights":  [A],"Visualization":  [B],"Visualization_Type":[C]"Narration":  [D]}where  [A]  is  the  listed  insights  in  Task  1,  [B]  is  the  visualization  specification  generated  in  Task  2,  [C]  is  the  visualization  type,  which  is  one  of  the  values  of  [bar,  scatter,  pie,  line],  and  [D]  is  the  narration  text  for  the  insights  in  Task  3.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '你是一名数据分析师。你手头有一张数据表。{{description}}完整的数据表为:{{table}}你需要完成几个任务，请一步一步思考。任务 1:
    请列出你可以从以下数据表中提取的主要见解。见解提取的注意事项: -   输出的 JSON 格式为: [{"insight": 见解内容, "type": 对应见解类型的列表}]
    -   见解类型属于以下列表: [随时间变化, 描述分布, 聚类, 比较, 相关, 确定范围, 偏差, 查找异常, 查找极值, 量级, 部分与整体, 排序,
    趋势]。一个见解可以对应多个类型。 -   选择的见解应明显、有价值且多样。 -   仔细检查数值量级的比较是否准确。确保见解是正确的。 -   忽略“索引”列。任务
    2: 请绘制 Vega-Lite 可视化图表，以基于数据表展示见解。可视化生成的注意事项: -   标题应少于 10 个词。 -   如果使用颜色通道，请参考以下颜色方案:
    https://vega.github.io/vega/docs/schemes/ -   可视化图表应具有正确的高度和宽度。 -   如果可视化图表是折线图，应包含数据点。
    -   如果数据表展示的重点是单一列的百分比信息，则使用饼图展示。每个扇区的百分比应通过文本注释显示在相应扇区上，如 https://vega.github.io/vega-lite/examples/layer_arc_label.html。
    -   使用单一图表来可视化数据，且不应可视化“索引”列。任务 3: 请为见解编写精简的叙述。叙述生成的注意事项: -   叙述应以描述可视化的语气编写，而非描述数据表。
    -   逻辑应有说服力，将见解串联成一个故事，避免列举见解。 -   避免使用额外的解释。避免对数据进行猜测性结论和冗余解释。 -   内容应精简。 -   忽略“索引”列。最终输出的
    JSON 格式为: {"Insights": [A], "Visualization": [B], "Visualization_Type": [C], "Narration":
    [D]} 其中 [A] 为任务 1 中列出的见解, [B] 为任务 2 中生成的可视化规格, [C] 为可视化类型, 即 [bar, scatter, pie,
    line] 之一, [D] 为任务 3 中见解的叙述文本。'
- en: 'Listing 3: The prompt of the agent acting as a designer'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '列表 3: 作为设计师的代理人的提示'
- en: 'You  are  a  data  video  designer.  You  have  a  static  visualization  and  corresponding  insightful  narration  text  at  hand,  as  well  as  the  original  data  table.  If  necessary,  embellish  the  visualization  with  corresponding  annotations  (e.g.,  arrow,  text,  circle,  etc.)  to  tell  the  story  more  vividly  in  the  narration  text.  Please  think  step  by  step.The  visualization  is:  {{visualization}}The  insightful  narration  is:  {{narration}}The  data  table  is:  {{table}}Task  1:  You  want  some  animation  to  appear  on  the  visual  elements  during  the  audio  narration  of  the  video  to  aid  in  telling  the  data  story.  Consider  the  narration  as  a  timeline  for  the  video.  Insert  animations  inside  the  narration  text  where  you  feel  they  are  needed.  The  corresponding  animation  will  be  triggered  when  the  video  reaches  the  corresponding  narration  segment  and  ends  at  the  end  of  the  narration  segment.Notes  for  animation  generation:-  The  output  JSON  format  is:[{"animation":  animation  type,"narration":  narration  segment,"target":  the  visual  elements  that  the  animation  applies  to,"index":  a  list  of  related  data  table  rows  index.  If  empty,  output  [],"explanation":  the  explanation  of  why  the  animation  needs  to  be  added}]-  One  sentence  in  the  narration  can  correspond  to  multiple  animations.-  Output  only  the  part  marked  with  animation.-  Narration  text  cannot  be  modified.-  There  are  three  types  of  animations:  entrance,  emphasis,  and  exit.-  Entrance  animations  include  [Axes-fade-in,  Bar-grow-in,  Line-wipe-in,  Pie-wheel-in,  Pie-wheel-in-and-legend-fly-in,  Scatter-fade-in,  Bar-grow-and-legend-fade-in,  Line-wipe-and-legend-fade-in,  Fade-in,  Float-in,  Fly-in,  Zoom-in].-  Emphasis  animations  include  [Bar-bounce,  Zoom-in-then-zoom-out,  Shine-in-a-short-duration,  Highlight-one-and-fade-others].-  Exit  animations  include  [Fade-out].-  [Axes  fade  in]  animations  can  only  be  used  at  the  beginning  (first  sentence)  of  a  whole  narration.-  Visual  elements  that  have  an  entrance  animation  effect  applied  will  not  appear  on  the  canvas  until  the  animation  is  triggered.  Elements  that  have  an  exit  animation  effect  applied  will  disappear  from  the  canvas  after  the  animation.  Elements  that  do  not  have  any  animation  effect  applied  will  appear  on  the  canvas  by  default.-  Visual  elements  can  only  be  emphasized  or  disappear  after  they  appear  on  the  canvas,  and  elements  cannot  be  emphasized  after  they  disappear.Task  2:  Visualization  embellishment  generationNotes  for  generation:-  Add  annotation  only  when  you  think  you  need  to,  or  export  the  original  visualization  if  you  do  not  feel  the  need  to  add  it.-  Tag  the  narration  text  in  the  format  of:[{"type":  a  list  of  annotation  types,  which  is  one  or  a  set  from  [mark  label,  circle,  text,  rule,  trend  line,  arrow],"description":  annotation  description  and  explanation,"index":  a  list  of  related  data  table  rows  index,  If  empty,  output  [],"nar":  narration  segment}]-  The  tagged  annotations  must  correspond  to  the  annotations  in  the  visualization.-  Only  output  the  narration  segments  marked  with  annotation.  If  the  value  of  key  "type"  is  [],  do  not  output  the  item.-  If  the  annotated  vega-lite  specification  has  a  key  "layer",  then  all  "mark"  and  "encoding"  keys  should  be  inside  the  list  value  of  the  key  "layer".-  The  annotations  should  not  be  complex.-  The  annotation  must  correspond  to  the  narration  segment.  The  annotation  will  appear  when  the  video  reaches  the  corresponding  narration  segment.-  The  text  annotation  should  be  short  (e.g.,  fewer  than  6  words).-  Please  output  the  complete  bug-free  vega-lite  specification.The  final  output  JSON  format  is:{"Annotated_Visualization":  [A],"Annotated_Narration_for_Animation":  [B],"Annotated_Narration_for_Annotation":  [C]}where  [A]  is  the  generated  annotated  Vega-Lite  specification,  [B]  is  the  tagged  narration  text  for  animation,  and  [C]  is  the  tagged  narration  text  for  annotation.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '你是一个数据视频设计师。你手头有一个静态可视化图表和相应的有洞察力的解说文本，还有原始数据表。如果需要，可以用相应的注释（例如，箭头、文本、圆圈等）装饰可视化图表，以便在解说文本中更生动地讲述故事。请一步一步地思考。可视化图表是：{{visualization}}有洞察力的解说是：{{narration}}数据表是：{{table}}任务1：你希望在视频的音频解说过程中，视觉元素上出现一些动画，以帮助讲述数据故事。将解说视为视频的时间线。在你认为需要的地方，在解说文本中插入动画。视频达到相应的解说段落时，将触发对应的动画，并在解说段落结束时结束动画。动画生成注意事项：-
    输出的 JSON 格式是：[{"animation": 动画类型,"narration": 解说段落,"target": 动画应用的视觉元素,"index":
    相关数据表行的索引列表。如果为空，则输出[],"explanation": 为什么需要添加该动画的解释}] - 解说中的一句话可以对应多个动画。- 仅输出标记为动画的部分。-
    解说文本不能修改。- 动画有三种类型：入场、强调和退出。- 入场动画包括 [Axes-fade-in, Bar-grow-in, Line-wipe-in,
    Pie-wheel-in, Pie-wheel-in-and-legend-fly-in, Scatter-fade-in, Bar-grow-and-legend-fade-in,
    Line-wipe-and-legend-fade-in, Fade-in, Float-in, Fly-in, Zoom-in]。- 强调动画包括 [Bar-bounce,
    Zoom-in-then-zoom-out, Shine-in-a-short-duration, Highlight-one-and-fade-others]。-
    退出动画包括 [Fade-out]。- [Axes fade in] 动画只能用于整个解说的开始（第一句）。- 应用入场动画效果的视觉元素在动画触发之前不会出现在画布上。应用退出动画效果的元素将在动画结束后从画布上消失。没有应用任何动画效果的元素默认会出现在画布上。-
    视觉元素只能在它们出现在画布上后被强调或消失，元素不能在消失后被强调。任务2：可视化装饰生成生成注意事项：- 仅在你认为需要时添加注释，否则导出原始可视化图表。-
    用以下格式标记解说文本：[{"type": 注释类型列表，可以是 [mark label, circle, text, rule, trend line,
    arrow] 中的一种或一组,"description": 注释描述和解释,"index": 相关数据表行的索引列表。如果为空，则输出[],"nar": 解说段落}]
    - 标记的注释必须对应于可视化中的注释。- 仅输出标记为注释的解说段落。如果“type”键的值为空，则不输出该项。- 如果标记的 vega-lite 规范中有“layer”键，则所有“mark”和“encoding”键应该在“layer”键的列表值中。-
    注释不应复杂。- 注释必须对应于解说段落。注释将在视频到达相应的解说段落时出现。- 文本注释应简短（例如，不超过 6 个词）。- 请输出完整的无错误的 vega-lite
    规范。最终输出的 JSON 格式是：{"Annotated_Visualization": [A],"Annotated_Narration_for_Animation":
    [B],"Annotated_Narration_for_Annotation": [C]} 其中 [A] 是生成的标注 Vega-Lite 规范，[B]
    是标记的用于动画的解说文本，[C] 是标记的用于注释的解说文本。'
