<!--yml
category: 未分类
date: 2025-01-11 12:44:54
-->

# LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction

> 来源：[https://arxiv.org/html/2403.15464/](https://arxiv.org/html/2403.15464/)

\institutes

${}^{1}$ Department of Computer Science, Emory University, Atlanta, GA
${}^{2}$ School of Computer Science & Engineering, University of Washington, Seattle, WA
${}^{3}$ Department of Computer Science & Engineering, UCSD, San Diego, CA
${}^{4}$ Rollins School of Public Health, Emory University, Atlanta, GA
${}^{5}$ School of Medicine, Emory University, Atlanta, GA

Hejie Cui${}^{1}$    Zhuocheng Shen${}^{1}$    Jieyu Zhang${}^{2}$    Hui Shao    MD    PhD${}^{4,5}$    Lianhui Qin    PhD${}^{3}$    Joyce C. Ho    PhD${}^{1}$    Carl Yang    PhD${}^{1,4}$

## Abstract

Electronic health records (EHRs) contain valuable patient data for health-related prediction tasks, such as disease prediction. Traditional approaches rely on supervised learning methods that require large labeled datasets, which can be expensive and challenging to obtain. In this study, we investigate the feasibility of applying Large Language Models (LLMs) to convert structured patient visit data (e.g., diagnoses, labs, prescriptions) into natural language narratives. We evaluate the zero-shot and few-shot performance of LLMs using various EHR-prediction-oriented prompting strategies. Furthermore, we propose a novel approach that utilizes LLM agents with different roles: a predictor agent that makes predictions and generates reasoning processes and a critic agent that analyzes incorrect predictions and provides guidance for improving the reasoning of the predictor agent. Our results demonstrate that with the proposed approach, LLMs can achieve decent few-shot performance compared to traditional supervised learning methods in EHR-based disease predictions, suggesting its potential for health-oriented applications.

## Introduction

Large Language Models (LLMs) have emerged as a powerful tool in various domains, including healthcare. These models, such as GPT family ^([1](https://arxiv.org/html/2403.15464v1#bib.bib1)) and PaLM ^([2](https://arxiv.org/html/2403.15464v1#bib.bib2)), are trained on vast amounts of text data, allowing them to encode extensive knowledge across multiple fields. In the medical domain, the ability of LLMs to leverage their encoded medical knowledge has been showcased in recent studies ^([3](https://arxiv.org/html/2403.15464v1#bib.bib3); [4](https://arxiv.org/html/2403.15464v1#bib.bib4)), with impressive performance on tasks such as medical question answering ^([5](https://arxiv.org/html/2403.15464v1#bib.bib5)), clinical text summarization ^([6](https://arxiv.org/html/2403.15464v1#bib.bib6)), and clinical decision support ^([7](https://arxiv.org/html/2403.15464v1#bib.bib7)). Certain very large language models demonstrate an emerging ability for few-shot learning, where the model can draw upon their existing understanding to quickly adapt to new tasks with limited examples ^([8](https://arxiv.org/html/2403.15464v1#bib.bib8); [9](https://arxiv.org/html/2403.15464v1#bib.bib9)). This raises the question of whether LLMs can be directly applied to perform few-shot disease predictions using Electronic Health Record (EHR) data.

EHRs contain a wealth of patient data for predictive modeling tasks such as disease prediction, readmission risk assessment, and mortality prediction ^([10](https://arxiv.org/html/2403.15464v1#bib.bib10)). Existing approaches to EHR-based prediction primarily rely on supervised learning methods, including traditional machine learning models, representation learning ^([11](https://arxiv.org/html/2403.15464v1#bib.bib11); [12](https://arxiv.org/html/2403.15464v1#bib.bib12); [13](https://arxiv.org/html/2403.15464v1#bib.bib13)), and graph-based models ^([14](https://arxiv.org/html/2403.15464v1#bib.bib14)). While effective, these supervised approaches require training on large labeled datasets, which can be computationally expensive and challenging to obtain due to the high cost and difficulty of acquiring high-quality labeled EHR data ^([15](https://arxiv.org/html/2403.15464v1#bib.bib15)). In contrast, the capacity for few-shot learning enables LLMs to adapt to new tasks with minimal data, without any finetuning ^([8](https://arxiv.org/html/2403.15464v1#bib.bib8)). This adaptability raises the possibility of employing LLMs for few-shot disease prediction using EHR, a step forward in making healthcare more precise and efficient ^([16](https://arxiv.org/html/2403.15464v1#bib.bib16)).

In this study, we investigate the efficacy of LLMs-based few-shot disease prediction using the EHRs generated from clinical encounters that include three types of medical codes: disease, medications, and procedures. We convert the structured patient visit records into unstructured language narratives by mapping the ICD codes to their names and connecting them with proper conjunctives. This conversion process allows LLMs to better understand clinical records and retrieve related internal knowledge. We assess the zero-shot and few-shot diagnostic performance of LLMs using various prompting strategies, such as considering factor interactions and providing prevalence statistics and exemplars. The results of this evaluation provide insights into the potential of LLMs as a tool for EHR-based disease prediction and highlight the influence of prompting strategies on their performance.

Building upon the findings of our initial evaluation, we propose an innovative approach to further improve the few-shot diagnostic performance of LLMs on EHR data. Studies have shown the promise of specialized LLM agents working collaboratively ^([17](https://arxiv.org/html/2403.15464v1#bib.bib17); [18](https://arxiv.org/html/2403.15464v1#bib.bib18); [19](https://arxiv.org/html/2403.15464v1#bib.bib19)), leveraging their diverse functionalities through few-shot learning. Our approach combines the strengths of predictive agent reasoning and critical agent instruction to create a more robust and accurate prediction system. The overall framework is shown in Figure [1](https://arxiv.org/html/2403.15464v1#Sx2.F1 "Figure 1 ‣ Introduction ‣ LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction"). Specifically, we employ two LLM agents with different roles: a predictor agent and a critic agent. The predictor agent makes few-shot predictions given the unstructured narratives, which are converted from structured records, and generates a reasoning process to support its predictions. The critic agent then takes the predictor’s output alongside the ground-truth disease labels as input and identifies issues or biases in the predictor agent’s reasoning process. Based on the analysis, the critic agent generates a set of instructions that draw the predictor agent’s attention to potentially overlooked factors and offer specific recommendations for refining its reasoning process. These instructions are subsequently appended to the prompts used for the predictor agent, serving as additional context to inform its predictions. Our results show that by refining the prompts based on the critic agent’s feedback, the overall diagnostic accuracy of the LLM-based few-shot prediction system improves significantly. This approach leverages the complementary strengths of predictive reasoning and critical analysis, enabling the system to learn from its mistakes and adapt to the specific challenges of EHR-based disease prediction. In summary, our main contributions are:

*   •

    We investigate the application of LLMs to EHR-based disease prediction tasks by converting structured data into natural language narratives and evaluating zero-shot and few-shot performance using various prompting strategies.

*   •

    We propose a novel approach combining two LLM agents with different roles: a predictor agent that makes predictions and provides reasoning processes, and a critic agent that analyzes incorrect predictions and provides feedback for improvement. The critic agent’s feedback is used to update the predictor agent’s prompts, enabling the system to learn from its mistakes and adapt to EHR-based disease prediction challenges.

*   •

    We summarize a set of insights into the performance of LLMs under various settings and share practical guidance on leveraging LLMs for diagnostic tasks with limited labeled data. We hope this can contribute to developing efficient and effective clinical decision support systems in the era of LLMs.

![Refer to caption](img/a1a7ca27c29d7c530688a510df64f1a8.png)

Figure 1: The framework of EHR-CoAgent employs two LLM agents: a predictor agent that makes predictions and generates reasoning processes and a critic agent that analyzes incorrect predictions and provides guidance for improvement. The critic agent’s feedback is used to update the prompts given to the predictor agent, enabling the system to learn from its mistakes and adapt to the specific challenges of the EHR-based disease prediction task.

## Related Work

Large Language Models for Healthcare LLMs have demonstrated remarkable capabilities in various application scenarios. Recently, there has been a growing interest in applying LLMs to the medical domain ^([20](https://arxiv.org/html/2403.15464v1#bib.bib20); [21](https://arxiv.org/html/2403.15464v1#bib.bib21); [22](https://arxiv.org/html/2403.15464v1#bib.bib22)), particularly for tasks such as clinical note analysis ^([23](https://arxiv.org/html/2403.15464v1#bib.bib23); [24](https://arxiv.org/html/2403.15464v1#bib.bib24)), medical question answering ^([25](https://arxiv.org/html/2403.15464v1#bib.bib25); [26](https://arxiv.org/html/2403.15464v1#bib.bib26)), disease prediction ^([27](https://arxiv.org/html/2403.15464v1#bib.bib27)), clinical trial matching ^([28](https://arxiv.org/html/2403.15464v1#bib.bib28)), medical report generation ^([29](https://arxiv.org/html/2403.15464v1#bib.bib29)). For example, Yang et al. ^([30](https://arxiv.org/html/2403.15464v1#bib.bib30)) introduced GatorTron, an LLM specifically designed for EHRs. They demonstrated the effectiveness of GatorTron in various clinical natural language processing (NLP) tasks, such as named entity recognition and relation extraction, showcasing the potential of LLMs to extract valuable information from unstructured EHR data. Peng et al. ^([22](https://arxiv.org/html/2403.15464v1#bib.bib22)) investigated the use of generative LLMs for medical research and healthcare. They explored the capabilities of LLMs in tasks such as medical question answering, disease prediction, and clinical trial matching, highlighting their potential to support clinical decision-making and assist research.

However, applying LLMs to EHR-based disease prediction tasks remains under-explored. While some studies have investigated the use of LLMs for clinical NLP tasks on EHR ^([30](https://arxiv.org/html/2403.15464v1#bib.bib30)), there is still a lack of research on leveraging the reasoning and instruction-following capabilities of LLMs for few-shot EHR-based prediction. Our research addresses this gap by exploring the use of LLMs for EHR-based disease prediction and proposes new methods to enable accurate prediction with minimal training data.

## Method

In this study, we expand our investigations on two levels: (1) evaluating the zero-shot and few-shot performance of LLMs on EHR-based disease prediction tasks, and (2) proposing a novel approach that leverages collaborative LLM agents to enhance the predictive performance.

LLM Performance on Disease Prediction with EHR The structured patient visit data are typically stored in tabular formats, where each row represents an individual patient visit record generated from clinical encounters, and columns correspond to different medical codes. In this study, we utilize EHR data that includes three types of medical codes $\mathcal{C}$: (1) diseases $\mathcal{C}_{D}$, (2) medications $\mathcal{C}_{M}$, and (3) procedures $\mathcal{C}_{P}$. Each patient visit sample $v_{i}$ in the record $\mathcal{V}$ is represented by a set of medical codes $\{c_{1},c_{2},\ldots,c_{n}\}$, where $c_{j}\in\mathcal{C}$. We convert the structured EHR records into unstructured language narratives, denoted as $\mathcal{H}$, by mapping the medical codes to their names to enable the application of LLMs.

$\diamond$ Zero-Shot: Leveraging Pre-existing Knowledge Prompt engineering has emerged as a powerful technique for guiding the behavior of LLMs and improving their performance on various healthcare-related tasks, such as clinical named entity recognition ^([31](https://arxiv.org/html/2403.15464v1#bib.bib31); [32](https://arxiv.org/html/2403.15464v1#bib.bib32)) and clinical text classification ^([33](https://arxiv.org/html/2403.15464v1#bib.bib33); [34](https://arxiv.org/html/2403.15464v1#bib.bib34)). We develop a set of prompting strategies tailored to EHR-based prediction tasks to provide additional context and guide the reasoning process of LLMs, including:

*   •

    Chain-of-thought (CoT) reasoning ^([35](https://arxiv.org/html/2403.15464v1#bib.bib35)): prompt the LLMs to generate step-by-step explanations;

*   •

    Incorporation of factor interactions: encourage LLMs to consider the interactions and dependencies among different medical factors (e.g., diseases, medications, and procedures);

*   •

    Prevalence information: integrate information about the prevalence statistics to provide additional context.

$\diamond$ Few-Shot: Enhancing Performance with Limited Examples We randomly select a small number of positive and negative samples (e.g., 3 positive and 3 negative) from the training data to serve as exemplars for each prediction category. These exemplars are incorporated into the prompts to provide the LLMs with a limited set of task-specific examples to learn from. This leverages the LLMs’ vast pre-existing knowledge while allowing them to adapt quickly to the specific characteristics of the EHR prediction task. By this, we aim to guide LLMs’ attention toward the most relevant patterns associated with each prediction category.

EHR-CoAgent: Collaborative LLM Agents for Enhanced Prediction Recently, the potential of LLMs has extended beyond single-agent applications. By leveraging the power of multiple LLMs with different roles working together in a collaborative framework, new possibilities have been unlocked for tackling complex problems and enhancing the performance of language models ^([17](https://arxiv.org/html/2403.15464v1#bib.bib17)). In this study, we propose a novel approach called EHR-CoAgent (as demonstrated in Figure [1](https://arxiv.org/html/2403.15464v1#Sx2.F1 "Figure 1 ‣ Introduction ‣ LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction")), which harnesses the potential of collaborative LLM agents for enhanced prediction of EHR. Our framework consists of two components: a predictor agent $\mathcal{P}_{\text{LLM}}$ and a critic agent $\mathcal{K}_{\text{LLM}}$. The predictor agent focuses on generating predictions and providing explanatory reasoning, while the critic agent observes the predictor’s outputs and provides instructional feedback to refine the prediction process. By integrating the feedback from the critic agent into the prompts used by the predictor agent, we aim to create an in-context learning process with feedback to continuously enhance disease prediction accuracy.

$\diamond$ Predictor Agent: Generating Predictions and Reasoning The predictor agent $\mathcal{P}_{\text{LLM}}$ is an LLM that performs few-shot disease predictions and provides explanatory reasoning based on the input EHR data. Given a patient’s medical history $\mathcal{H}_{i}$, the predictor LLM analyzes the relevant information and generates the most likely prediction $\widehat{\mathcal{D}_{i}}$ and provides a step-by-step explanation of its reasoning process $\mathcal{R}_{i}$. Such explanatory reasoning is crucial for enhancing the interpretability of the generated predictions. By highlighting the key factors and evidence influencing the LLM agent’s decision-making process, the reasoning serves as a transparent and informative basis for further analysis and validation. The detailed prompt we used for the predictor agent in EHR-CoAgent is shown in Figure [3](https://arxiv.org/html/2403.15464v1#Sx9.F3 "Figure 3 ‣ LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction").

$\diamond$ Critic Agent: Providing Instructional Feedback The critic agent $\mathcal{K}_{\text{agent}}$ is another LLM that plays a different role in the EHR-CoAgent framework by observing a set of sampled wrong predictions from the predictor agent. Each set, denoted as $\mathcal{B}_{j}=\{(\widehat{\mathcal{D}}_{ji},\mathcal{R}_{ji})\}_{i=1}^{b}$, contains generated prediction $\widehat{\mathcal{D}}_{ji}$ and their accompanying explanatory reasoning $\mathcal{R}_{ji}$ for $b$ instances. The critic agent analyzes the inconsistency of the generated prediction to their corresponding ground truth label $\mathcal{D}_{ji}$ for each batch $\mathcal{B}_{j}$, identifying error patterns for improvement. Based on this analysis, we let the critic agent generate a set of instructional feedback $\{\mathcal{F}_{j}\}$ for batch $\mathcal{B}_{j}$ and repeat this process for $m$ times. The detailed prompt we used for the critic agent in EHR-CoAgent is shown in Figure [4](https://arxiv.org/html/2403.15464v1#Sx9.F4 "Figure 4 ‣ LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction").

To provide concise and coherent guidance, we employ GPT-4 to process the set of instructional feedback $\{\mathcal{F}_{j}\}_{j=1}^{m}$. GPT-4 analyzes the feedback across multiple batches and generates a consolidated set of instructions $\mathcal{F}_{\text{consolidated}}$ that captures the most important and recurring insights. This consolidated feedback highlights common biases or errors in the reasoning process, offers suggestions for considering additional factors, and provides insights into the relationships between different medical concepts.

$\diamond$ Instruction-Enhanced Prompting: Integrating Feedback for Refinement To effectively incorporate the feedback generated by the critic LLM, we introduce an instruction-enhanced prompting mechanism. This mechanism integrates the critic LLM’s instructional feedback $\mathcal{F}_{\text{consolidated}}$ directly into the prompts $\mathcal{P}$ used by the predictor LLM. By augmenting the prompts with specific instructions and guidance, we aim to steer the predictor LLM’s attention toward the most relevant aspects of the input data and encourage it to consider the insights provided by the critic LLM. This iterative process of making predictions, receiving feedback, and refining the prompts allows the predictor LLM to continuously improve its performance and adapt to the specific challenges of EHR-based disease prediction.

## Experimental Settings

Datasets We conducted experiments on two datasets: the publicly accessible MIMIC-III dataset and the privately-owned CRADLE dataset. MIMIC-III ^([36](https://arxiv.org/html/2403.15464v1#bib.bib36)) is a large, publicly accessible dataset comprising de-identified health-related data associated with over forty thousand patients who stayed in critical care units of the Beth Israel Deaconess Medical Center between 2001 and 2012\. Our task is to predict whether acute care conditions will be present during a patient’s next visit, given their current ICU stay records. We focus on a specific chronic phenotype, Disorders of Lipid Metabolism, which is identified using Clinical Classifications Software (CCS) from the Healthcare Cost and Utilization Project (HCUP)¹¹1[https://www.hcup-us.ahrq.gov/toolssoftware/ccs/AppendixASingleDX.txt](https://www.hcup-us.ahrq.gov/toolssoftware/ccs/AppendixASingleDX.txt). During preprocessing, we extract patients with more than one hospital visit and create pairs of adjacent visits for each patient. For each pair, the former visit serves as the input, and the phenotypes in the latter visit are used as labels. This process yields 12,353 records with labels. For budget consideration, we randomly sample 1,000 records based on the data distribution of the prediction target as our testing set.

Project CRADLE (Emory Clinical Research Analytics Data Lake Environment) is a privately-owned database that contains de-identified electronic health records at Emory Healthcare from 2013 to 2017\. In this study, we focus on the patients with type 2 diabetes and predict whether those patients will experience cardiovascular disease (CVD) endpoints within a year after the initial diabetes diagnosis. The CVD endpoints include coronary heart disease (CHD), congestive heart failure (CHF), myocardial infarction (MI), or stroke, which are identified by their ICD-9 and ICD-10 clinical codes. For patients who developed CVD complications within a year (positive cases), we select the earliest recorded encounter within a year of the CVD endpoint presence as the input. For patients without CVD complications (negative cases), we randomly select one encounter as the input from all encounters that occurred at least one year before the last recorded encounter. Patients are excluded if they (1) have less than two encounters at Emory Healthcare, (2) the time interval between their first and last encounter is less than one year, or (3) have a history of CVD conditions. After applying these exclusion criteria, 35,404 patients remain in the dataset. Similar to MIMIC-III, we randomly sample 1,000 records based on the data distribution of the prediction target

Evaluation Metrics Both the MIMIC-III and CRADLE datasets exhibit class imbalance, with the prevalence of Disorders of Lipid Metabolism in MIMIC-III being 27.6% and the prevalence of cardiovascular disease (CVD) endpoints in CRADLE being 21.4%. To account for the imbalanced data distributions, we employ accuracy, sensitivity, specificity, and F1 score as evaluation metrics ^([14](https://arxiv.org/html/2403.15464v1#bib.bib14)). When evaluating LLM methods, we identify the presence of “Yes” or “No” tokens in the LLM responses and extract the top 5 probabilities associated with the predicting token. These probabilities are then normalized over both answers. We observed that GPT family models tend to provide highly confident answers (a confirmed prediction of either “Yes” or “No”, with almost 0.0 probability for the other choice), often resulting in a majority probability of either 0.0 or 1.0.

Baselines We compare the performance of EHR-CoAgent with traditional machine learning (ML), including Decision Trees, Logistic Regression, and Random Forests, which are widely used in EHR-based prediction tasks ^([37](https://arxiv.org/html/2403.15464v1#bib.bib37); [38](https://arxiv.org/html/2403.15464v1#bib.bib38)), and single-agent LLM approaches using GPT-4 (gpt-4-0125-preview) and GPT-3.5 (gpt-35-turbo-16k-0613). The ML models are trained in both fully supervised and few-shot settings, while the LLM approaches are evaluated in pure zero-shot, zero-shot with additional prompt information as mentioned in section [Method](https://arxiv.org/html/2403.15464v1#Sx4 "Method ‣ LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction"), and few-shot learning settings. By comparing EHR-CoAgent with these baselines, we aim to evaluate the effectiveness of diverse LLM agent frameworks in EHR-based disease prediction tasks.

Implementation Details We implemented the empirical study methods in Python. The baseline machine learning models were trained and evaluated using the popular sklearn package, which provides a comprehensive set of tools for machine learning tasks. To access the various GPT models securely, we utilized the Azure OpenAI Service, a trusted and compliant cloud platform. Azure OpenAI offers a secure API interface that allows seamless integration of the GPT capabilities into our research pipeline while maintaining strict privacy and security controls. By leveraging Azure OpenAI, we ensured that the sensitive patient dataset was processed in a protected environment, adhering to necessary regulations and standards, such as HIPAA and GDPR.

## Experimental Results

Table 1: Performance (%) of different models under the zero-shot, few-shot, and fully-supervised settings on MIMIC-III and CRADLE datasets. The proposed method is colored in green. The reference results under the supervised training setting (trained on 11,353 samples for MIMIC-III and 34,404 samples for CRADLE) are colored in gray.

 | Type | Model | MIMIC-III (Pos : Neg = 27.6% : 72.4%) | CRADLE (Pos : Neg = 21.4% : 78.6%) |
| ACC | Sensitivity | Specificity | F1 | ACC | Sensitivity | Specificity | F1 |
| Fully-Supervised | Decision Tree | 81.30 | 76.97 | 84.31 | 76.20 | 80.30 | 53.87 | 88.27 | 52.15 |
| Logistic Regression | 79.70 | 70.48 | 83.56 | 73.18 | 80.90 | 58.34 | 86.15 | 59.74 |
| Random Forest | 78.60 | 66.12 | 83.16 | 70.58 | 80.20 | 56.49 | 86.14 | 57.34 |
| Few-Shot (N=6) | Decision Tree | 71.10 | 53.14 | 77.62 | 51.16 | 31.90 | 54.81 | 25.99 | 31.71 |
| Logistic Regression | 58.70 | 73.40 | 53.44 | 56.78 | 53.30 | 53.95 | 53.13 | 48.16 |
| Random Forest | 69.70 | 62.88 | 72.18 | 63.61 | 65.00 | 51.50 | 68.43 | 51.04 |
| GPT-4 | Zero-Shot | 51.90 | 76.15 | 42.56 | 51.89 | 24.10 | 51.81 | 16.82 | 22.33 |
| Zero-Shot+ | 62.90 | 59.30 | 64.29 | 58.58 | 30.00 | 53.25 | 23.76 | 29.67 |
| Few-Shot (N=6) | 65.70 | 79.35 | 59.89 | 64.72 | 41.20 | 59.05 | 36.33 | 40.88 |
| EHR-CoAgent | 79.10 | 73.11 | 81.43 | 73.88 | 70.00 | 62.88 | 71.72 | 60.21 |
| GPT-3.5 | Zero-Shot | 78.00 | 66.87 | 82.37 | 68.56 | 56.50 | 59.88 | 55.45 | 52.29 |
| Zero-Shot+ | 72.40 | 50.00 | 80.37 | 42.00 | 62.60 | 57.62 | 63.96 | 54.40 |
| Few-Shot (N=6) | 76.30 | 63.73 | 80.93 | 63.84 | 40.80 | 54.56 | 36.96 | 40.32 |
| EHR-CoAgent | 79.30 | 74.49 | 80.98 | 71.59 | 66.60 | 58.31 | 68.83 | 55.83 | 

Table [1](https://arxiv.org/html/2403.15464v1#Sx6.T1 "Table 1 ‣ Experimental Results ‣ LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction") presents the experimental results on the two datasets. The findings highlight several key observations:

$\diamond$ Traditional machine learning (ML) models achieve respectable performance when fully trained on large datasets (11,353 samples for MIMIC-III and 34,404 samples for CRADLE). However, the performance of simpler models, such as Decision Trees and Logistic Regression, substantially deteriorates in the few-shot learning setting, emphasizing their limitations when labeled data is scarce.

$\diamond$ When comparing the performance of zero-shot or few-shot LLMs with ML methods under few-shot settings, we observe that LLMs exhibit higher sensitivity but lower specificity. This finding suggests that LLMs excel at correctly identifying positive cases (i.e., patients with the condition of interest) but at the cost of a higher false positive rate. In other words, LLMs are more prone to classifying a patient as having the condition, even when they do not. This tendency implies that LLMs, particularly GPT-4, adopt a more conservative mindset, possibly due to their alignment to err on the side of caution to mitigate the risk of potentially missing true positive cases.

$\diamond$ Zero-shot with additional prompting strategies (Zero-Shot+) can improve based on pure zero-shot, with occasionally produced errors. This observation underscores the importance of carefully crafting prompts to optimize the performance of LLMs in EHR-based disease prediction tasks.

$\diamond$ Most of the time, adding few-shot demonstrations enhance prediction performance compared to their respective Zero-Shot+ counterparts. This finding emphasizes providing even a limited number of labeled examples can potentially steer language models toward more precise predictions. By leveraging a small set of representative samples, LLMs can quickly adapt to the specific characteristics of the EHR-based disease prediction task.

$\diamond$ Our proposed approach EHR-CoAgent demonstrates remarkable performance, surpassing other methods and even fully supervised ML models in certain scenarios, with GPT-4 generally outperforming GPT-3.5\. On the CRADLE dataset, EHR-CoAgent achieves an F1 score of 60.21%, outperforming all fully trained ML models. Similarly, on the MIMIC-III dataset, EHR-CoAgent obtains an F1 score of 73.88%, comparable to the fully trained Decision Tree model and superior to Logistic Regression and Random Forest.

$\diamond$ Compared with the few-shot setting with a single LLM predictor, EHR-CoAgent improves significantly on all four metrics. This can be attributed to the feedback instructions provided by the critic agent, which analyzes the outputs and identifies issues and biases in LLM’s reasoning process, such as overly relying on conservative thinking or neglecting certain key factors. The feedback instructions generated by the critic agent help to correct these issues, dynamically refining the predictor agent’s reasoning process, thus improving the accuracy of the prediction.

## Generated Instructions

![Refer to caption](img/93b805c83dd81cd8f9ca9f11535a1093.png)

Figure 2: Examples of instructional feedback generated by the GPT-4-based critic agent, which aims to refine the predictor agent’s reasoning process and improve the accuracy of its prediction.

Figure [2](https://arxiv.org/html/2403.15464v1#Sx7.F2 "Figure 2 ‣ Generated Instructions ‣ LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction") showcases examples of the criteria and instructions generated by the critic agent. These examples demonstrate the critic agent’s ability to identify potential issues in the predictor agent’s prediction and reasoning process and provide targeted instructions to address them. For instance, the first instruction for the CRADLE dataset, “Avoid bias towards predicting a positive CVD endpoint based on conservative thinking when the patient is actively monitored and managed for known risk factors. Evaluate the effectiveness of the interventions in place” highlights a possible prediction bias of the predictor agent. This instruction encourages the predictor agent to avoid relying on conservative assumptions when making predictions, as such assumptions may be a result of the over-alignment of advanced AI models. By explicitly addressing this issue, the critic agent aims to guide the predictor agent toward more objective and comprehensive reasoning. Another example for the MIMIC dataset, “Pharmacological Interventions Consideration: Incorporate an evaluation of prescribed drugs, focusing on their relevance to managing the risk factors of the disorders of lipoid metabolism” suggests that the predictor agent should take into account the role of prescribed medications in managing the patient’s condition. By analyzing the relevance and potential impact of these drugs on the risk factors associated with disorders of lipoid metabolism, the predictor agent can make more informed predictions. These examples illustrate how the critic agent’s feedback can guide the predictor agent towards more comprehensive and nuanced reasoning, ultimately leading to improved disease prediction performance.

## Conclusions

In this study, we investigated the application of Large Language Models (LLMs) to Electronic Health Record (EHR) based disease prediction tasks. We evaluated the zero-shot and few-shot diagnostic performance of LLMs using various prompting strategies and proposed a novel collaborative approach combining a predictor agent and a critic agent. This approach enables the system to learn from its mistakes and adapt to the challenges of EHR-based disease prediction. Our work highlights the potential of LLMs as a tool for clinical decision support and contributes to the development of efficient disease prediction systems that can operate with minimal training data.

## Ethical Considerations

To ensure the ethical use of credential data with GPT-based services, we have signed and strictly adhered to the PhysioNet Credentialed Data Use Agreement²²2https://physionet.org/about/licenses/physionet-credentialed-health-data-license-150. We follow the guidelines³³3https://physionet.org/news/post/gpt-responsible-use for responsible use of MIMIC data in online services, including opting out of human review of the data through the Azure OpenAI Additional Use Case Form⁴⁴4https://aka.ms/oai/additionalusecase, to prevent sensitive information from being shared with third parties.

## References

*   1 Achiam J, Adler S, Agarwal S, Ahmad L, Akkaya I, Aleman FL, et al. Gpt-4 technical report. arXiv preprint arXiv:230308774\. 2023.
*   2 Anil R, Dai AM, Firat O, Johnson M, Lepikhin D, Passos A, et al. Palm 2 technical report. arXiv preprint arXiv:230510403\. 2023.
*   3 Singhal K, Azizi S, Tu T, Mahdavi SS, Wei J, Chung HW, et al. Large language models encode clinical knowledge. Nature. 2023;620:172-80.
*   4 Hernandez E, Mahajan D, Wulff J, Smith MJ, Ziegler Z, Nadler D, et al. Do We Still Need Clinical Language Models? In: Conference on Health, Inference, and Learning; 2023\. .
*   5 Singhal K, Tu T, Gottweis J, Sayres R, Wulczyn E, Hou L, et al. Towards expert-level medical question answering with large language models. arXiv preprint arXiv:230509617\. 2023.
*   6 Van Veen D, Van Uden C, Blankemeier L, Delbrouck JB, Aali A, Bluethgen C, et al. Adapted large language models can outperform medical experts in clinical text summarization. Nature Medicine. 2024:1-9.
*   7 Hegselmann S, Buendia A, Lang H, Agrawal M, Jiang X, Sontag D. Tabllm: Few-shot classification of tabular data with large language models. In: AISTATS; 2023\. .
*   8 Brown T, Mann B, Ryder N, Subbiah M, Kaplan JD, Dhariwal P, et al. Language models are few-shot learners. NeurIPS. 2020.
*   9 Schick T, Schütze H. Exploiting cloze questions for few shot text classification and natural language inference. arXiv preprint arXiv:200107676\. 2020.
*   10 Shickel B, Tighe PJ, Bihorac A, Rashidi P. Deep EHR: a survey of recent advances in deep learning techniques for electronic health record (EHR) analysis. IEEE journal of biomedical and health informatics. 2017;22:1589-604.
*   11 Rajkomar A, Oren E, Chen K, Dai AM, Hajaj N, Hardt M, et al. Scalable and accurate deep learning with electronic health records. NPJ digital medicine. 2018;1:1-10.
*   12 Landi I, Glicksberg BS, Lee HC, Cherng S, Landi G, Danieletto M, et al. Deep representation learning of electronic health records to unlock patient stratification at scale. NPJ digital medicine. 2020;3:96.
*   13 Fridgeirsson EA, Sontag D, Rijnbeek P. Attention-based neural networks for clinical prediction modelling on electronic health records. BMC Medical Research Methodology:285.
*   14 Choi E, Xu Z, Li Y, Dusenberry M, Flores G, Xue E, et al. Learning the graphical structure of electronic health records with graph convolutional transformer. In: AAAI; 2020\. .
*   15 Xiao C, Choi E, Sun J. Opportunities and challenges in developing deep learning models using electronic health records data: a systematic review. Journal of the American Medical Informatics Association. 2018;25:1419-28.
*   16 Wornow M, Thapa R, Steinberg E, Fries J, Shah N. Ehrshot: An ehr benchmark for few-shot evaluation of foundation models. NeurIPS. 2023.
*   17 Wu Q, Bansal G, Zhang J, Wu Y, Zhang S, Zhu E, et al. Autogen: Enabling next-gen llm applications via multi-agent conversation framework. arXiv preprint arXiv:230808155\. 2023.
*   18 Talebirad Y, Nadiri A. Multi-agent collaboration: Harnessing the power of intelligent llm agents. arXiv preprint arXiv:230603314\. 2023.
*   19 Jin Q, Yang Y, Chen Q, Lu Z. Genegpt: Augmenting large language models with domain tools for improved access to biomedical information. Bioinformatics. 2024;40:btae075.
*   20 Thirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan TF, Ting DSW. Large language models in medicine. Nature medicine. 2023;29(8):1930-40.
*   21 He K, Mao R, Lin Q, Ruan Y, Lan X, Feng M, et al.. A Survey of Large Language Models for Healthcare: from Data, Technology, and Applications to Accountability and Ethics; 2023.
*   22 Peng C, Yang X, Chen A, Smith KE, PourNejatian N, Costa AB, et al. A study of generative large language model for medical research and healthcare. npj Digital Medicine. 2023;6:210.
*   23 Agrawal M, Hegselmann S, Lang H, Kim Y, Sontag D. Large language models are few-shot clinical information extractors. In: EMNLP; 2022\. .
*   24 Mannhardt N, Bondi-Kelly E, Lam B, O’Connell C, Asiedu M, Mozannar H, et al.. Impact of Large Language Model Assistance on Patients Reading Clinical Notes: A Mixed-Methods Study; 2024.
*   25 Liévin V, Hother CE, Motzfeldt AG, Winther O. Can large language models reason about medical questions? Patterns. 2024;5:100943.
*   26 Han T, Adams LC, Papaioannou JM, Grundmann P, Oberhauser T, Löser A, et al. MedAlpaca–an open-source collection of medical conversational AI models and training data. arXiv preprint arXiv:230408247\. 2023.
*   27 Wang G, Yang G, Du Z, Fan L, Li X. ClinicalGPT: large language models finetuned with diverse medical data and comprehensive evaluation. arXiv preprint arXiv:230609968\. 2023.
*   28 Yuan J, Tang R, Jiang X, Hu X. Large language models for healthcare data augmentation: An example on patient-trial matching. In: AMIA Annual Symposium Proceedings. vol. 2023; 2023\. p. 1324.
*   29 D’Antonoli TA, Stanzione A, Bluethgen C, Vernuccio F, Ugga L, Klontzas ME, et al. Large language models in radiology: fundamentals, applications, ethical considerations, risks, and future directions. Diagnostic and Interventional Radiology. 2024;30:80.
*   30 Yang X, Chen A, PourNejatian N, Shin HC, Smith KE, Parisien C, et al. A large language model for electronic health records. npj Digital Medicine:194.
*   31 Sivarajkumar S, Kelley M, Samolyk-Mazzanti A, Visweswaran S, Wang Y. An empirical evaluation of prompting strategies for large language models in zero-shot clinical natural language processing. arXiv preprint arXiv:230908008\. 2023.
*   32 Hu Y, Chen Q, Du J, Peng X, Keloth VK, Zuo X, et al. Improving large language models for clinical named entity recognition via prompt engineering. Journal of the American Medical Informatics Association. 2024:ocad259.
*   33 Lu Y, Zhao X, Wang J. Medical knowledge-enhanced prompt learning for diagnosis classification from clinical text. In: Clinical Natural Language Processing Workshop; 2023\. p. 278-88.
*   34 Sivarajkumar S, Wang Y. Healthprompt: A zero-shot learning paradigm for clinical natural language processing. In: AMIA Annual Symposium Proceedings. vol. 2022; 2022\. p. 972.
*   35 Wei J, Wang X, Schuurmans D, Bosma M, Xia F, Chi E, et al. Chain-of-thought prompting elicits reasoning in large language models. NeurIPS. 2022;35.
*   36 Johnson AE, Pollard TJ, Shen L, Lehman LwH, Feng M, Ghassemi M, et al. MIMIC-III, a freely accessible critical care database. Scientific data. 2016;3:1-9.
*   37 Wu J, Roy J, Stewart WF. Prediction modeling using EHR data: challenges, strategies, and a comparison of machine learning approaches. Medical care. 2010;48:S106-13.
*   38 Goldstein BA, Navar AM, Pencina MJ, Ioannidis JP. Opportunities and challenges in developing risk prediction models with electronic health records data: a systematic review. Journal of the American Medical Informatics Association: JAMIA. 2017;24:198.

![Refer to caption](img/a32dba535e9a36da98ba185ef4d6a786.png)

Figure 3: Prompt for Predictor Agent in EHR-CoAgent for the CRADLE dataset.

![Refer to caption](img/0770c891189d6ca6fd8849b6785e45df.png)

Figure 4: Prompt for Critic Agent in EHR-CoAgent for the CRADLE dataset.