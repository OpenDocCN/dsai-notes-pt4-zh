- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '类别: 未分类'
- en: 'date: 2024-09-08 18:40:06'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-08 18:40:06'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'WaitGPT: Monitoring and Steering Conversational LLM Agent in Data Analysis
    with On-the-Fly Code Visualization'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'WaitGPT: 在数据分析中通过即时代码可视化监控和引导对话式 LLM 代理'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2408.01703](https://ar5iv.labs.arxiv.org/html/2408.01703)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2408.01703](https://ar5iv.labs.arxiv.org/html/2408.01703)
- en: Liwenhan Xie [liwenhan.xie@connect.ust.hk](mailto:liwenhan.xie@connect.ust.hk)
    [0000-0002-2601-6313](https://orcid.org/0000-0002-2601-6313 "ORCID identifier")
    Hong Kong University of Science and TechnologyHong Kong SARChina ,  Chengbo Zheng
    [cb.zheng@connect.ust.hk](mailto:cb.zheng@connect.ust.hk) [0000-0003-0226-9399](https://orcid.org/0000-0003-0226-9399
    "ORCID identifier") Hong Kong University of Science and TechnologyHong Kong SARChina
    ,  Haijun Xia [haijunxia@ucsd.edu](mailto:haijunxia@ucsd.edu) [0000-0002-9425-0881](https://orcid.org/0000-0002-9425-0881
    "ORCID identifier") University of California San DiegoLa JollaCAUSA ,  Huamin
    Qu [huamin@ust.hk](mailto:huamin@ust.hk) [0000-0002-3344-9694](https://orcid.org/0000-0002-3344-9694
    "ORCID identifier") Hong Kong University of Science and TechnologyHong Kong SARChina
     and  Chen Zhu-Tian [ztchen@umn.edu](mailto:ztchen@umn.edu) [0000-0002-2313-0612](https://orcid.org/0000-0002-2313-0612
    "ORCID identifier") University of MinnesotaMinneapolisMNUSA(2024)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Liwenhan Xie [liwenhan.xie@connect.ust.hk](mailto:liwenhan.xie@connect.ust.hk)
    [0000-0002-2601-6313](https://orcid.org/0000-0002-2601-6313 "ORCID identifier")
    香港科技大学 香港特别行政区 中国， Chengbo Zheng [cb.zheng@connect.ust.hk](mailto:cb.zheng@connect.ust.hk)
    [0000-0003-0226-9399](https://orcid.org/0000-0003-0226-9399 "ORCID identifier")
    香港科技大学 香港特别行政区 中国， Haijun Xia [haijunxia@ucsd.edu](mailto:haijunxia@ucsd.edu)
    [0000-0002-9425-0881](https://orcid.org/0000-0002-9425-0881 "ORCID identifier")
    加州大学圣地亚哥分校 拉荷亚 加利福尼亚 美国， Huamin Qu [huamin@ust.hk](mailto:huamin@ust.hk) [0000-0002-3344-9694](https://orcid.org/0000-0002-3344-9694
    "ORCID identifier") 香港科技大学 香港特别行政区 中国， 以及 Chen Zhu-Tian [ztchen@umn.edu](mailto:ztchen@umn.edu)
    [0000-0002-2313-0612](https://orcid.org/0000-0002-2313-0612 "ORCID identifier")
    明尼苏达大学 明尼阿波利斯 明尼苏达 美国 (2024)
- en: Abstract.
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: Large language models (LLMs) support data analysis through conversational user
    interfaces, as exemplified in OpenAI’s ChatGPT (formally known as Advanced Data
    Analysis or Code Interpreter). Essentially, LLMs produce code for accomplishing
    diverse analysis tasks. However, presenting raw code can obscure the logic and
    hinder user verification. To empower users with enhanced comprehension and augmented
    control over analysis conducted by LLMs, we propose a novel approach to transform
    LLM-generated code into an interactive visual representation. In the approach,
    users are provided with a clear, step-by-step visualization of the LLM-generated
    code in real time, allowing them to understand, verify, and modify individual
    data operations in the analysis. Our design decisions are informed by a formative
    study (N=8) probing into user practice and challenges. We further developed a
    prototype named WaitGPT and conducted a user study (N=12) to evaluate its usability
    and effectiveness. The findings from the user study reveal that WaitGPT facilitates
    monitoring and steering of data analysis performed by LLMs, enabling participants
    to enhance error detection and increase their overall confidence in the results.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）通过对话式用户界面支持数据分析，例如 OpenAI 的 ChatGPT（正式名称为高级数据分析或代码解释器）。本质上，LLMs
    生成代码以完成各种分析任务。然而，展示原始代码可能会掩盖逻辑并阻碍用户验证。为了赋予用户更好的理解和增强对 LLMs 进行的分析的控制，我们提出了一种新颖的方法，将
    LLM 生成的代码转化为交互式视觉表示。在这种方法中，用户可以实时获得 LLM 生成代码的清晰、逐步可视化，使他们能够理解、验证和修改分析中的各个数据操作。我们的设计决策基于一项形成性研究（N=8），该研究探讨了用户实践和挑战。我们进一步开发了一个名为
    WaitGPT 的原型，并进行了用户研究（N=12）以评估其可用性和有效性。用户研究的结果表明，WaitGPT 有助于监控和引导 LLM 执行的数据分析，使参与者能够提高错误检测能力，并增强对结果的整体信心。
- en: 'Conversational Data Analysis, LLM Agent, Human-AI Interaction, Generative AI,
    Code Verification, Visual Programming^†^†journalyear: 2024^†^†copyright: acmlicensed^†^†conference:
    The 37th Annual ACM Symposium on User Interface Software and Technology; October
    13–16, 2024; Pittsburgh, PA, USA^†^†booktitle: The 37th Annual ACM Symposium on
    User Interface Software and Technology (UIST ’24), October 13–16, 2024, Pittsburgh,
    PA, USA^†^†doi: 10.1145/3654777.3676374^†^†isbn: 979-8-4007-0628-8/24/10^†^†conference:
    The ACM Symposium on User Interface Software and Technology; Oct 13–16, 2024;
    Pittsburgh, PA^†^†ccs: Human-centered computing Natural language interfaces^†^†ccs:
    Human-centered computing Graphical user interfaces^†^†ccs: Human-centered computing Information
    visualization![Refer to caption](img/761208af14a507f924354db74119b21b.png)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 对话数据分析、LLM代理、人机交互、生成式AI、代码验证、可视化编程^†^†期刊年份：2024^†^†版权：acm授权^†^†会议：第37届ACM用户界面软件与技术年会；2024年10月13日至16日；美国宾夕法尼亚州匹兹堡^†^†书名：第37届ACM用户界面软件与技术年会（UIST
    ’24），2024年10月13日至16日，宾夕法尼亚州匹兹堡^†^†doi：10.1145/3654777.3676374^†^†isbn：979-8-4007-0628-8/24/10^†^†会议：ACM用户界面软件与技术年会；2024年10月13日至16日；宾夕法尼亚州匹兹堡^†^†ccs：以人为本的计算
    自然语言接口^†^†ccs：以人为本的计算 图形用户界面^†^†ccs：以人为本的计算 信息可视化![参见说明](img/761208af14a507f924354db74119b21b.png)
- en: 'Figure 1\. Monitoring and steering LLM-powered data analysis tools with WaitGPT:
    Beyond viewing the raw code, users can inspect data operations with a transformable
    representation generated on the fly and participate in data analysis proactively.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图1\. 使用WaitGPT监控和引导LLM驱动的数据分析工具：用户不仅可以查看原始代码，还可以通过动态生成的可变表示检查数据操作，并主动参与数据分析。
- en: \Description
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: \描述
- en: 'Figure 1 compares the traditional conversational interface and WaitGPT’s code
    visualization for LLM-powered data analysis. Left side: Traditional interface
    showing challenges users face in tracking data, operations, and results when verifying
    LLM responses. Right side: WaitGPT’s solution displays a node-link diagram generated
    in real time alongside the LLM response. The diagram visualizes tables, operations,
    and results. An expandable box on an operation node allows users to access table
    size, parameters, and outputs and ask contextual questions.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图1比较了传统对话界面和WaitGPT的LLM驱动数据分析的代码可视化。左侧：传统界面展示了用户在验证LLM响应时跟踪数据、操作和结果所面临的挑战。右侧：WaitGPT的解决方案实时显示了与LLM响应一起生成的节点-链接图。该图可视化了表格、操作和结果。操作节点上的可展开框允许用户访问表格大小、参数和输出，并提出上下文相关的问题。
- en: 1\. Introduction
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 介绍
- en: Large language models (LLMs) have significantly lowered the entry point for
    data analysis, empowering users without strong programming skills to engage in
    sophisticated analytical tasks (Cheng et al., [2023](#bib.bib9); He et al., [2024](#bib.bib24);
    Dibia, [2023](#bib.bib13)). Instead of writing scripts or using complex software,
    people can directly talk to conversational LLM agents. Examples of emerging LLM-powered
    data analysis services or tools include ChatGPT Plus (OpenAI, [2024](#bib.bib48)),
    Gemini Advanced (Google, [2024](#bib.bib18)), and CodeActAgent (Wang et al., [2024a](#bib.bib66)).
    Generally, these tools follow a planning framework, where the LLM agent proposes
    a plan to divide the task, then generates code to process data and continues the
    process based on the execution result.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）显著降低了数据分析的入门门槛，使没有强大编程技能的用户也能参与复杂的分析任务（Cheng et al., [2023](#bib.bib9);
    He et al., [2024](#bib.bib24); Dibia, [2023](#bib.bib13)）。用户无需编写脚本或使用复杂软件，只需直接与对话型LLM代理进行交流。出现的LLM驱动的数据分析服务或工具的例子包括ChatGPT
    Plus（OpenAI, [2024](#bib.bib48)）、Gemini Advanced（Google, [2024](#bib.bib18)）和CodeActAgent（Wang
    et al., [2024a](#bib.bib66)）。一般来说，这些工具遵循一个规划框架，LLM代理提出一个计划以分解任务，然后生成代码来处理数据，并根据执行结果继续处理过程。
- en: Despite their potential, real-world deployment of LLM-powered data analysis
    tools has exposed reliability concerns, including hallucinations (Liu et al.,
    [2023a](#bib.bib34); Chen et al., [2024b](#bib.bib7)), subtle bugs (Yang et al.,
    [2021](#bib.bib74); Wu et al., [2024](#bib.bib70)), and mismatch between LLM’s
    understanding of the tasks and under-articulated user intents (Wang et al., [2018](#bib.bib65);
    Li et al., [2024](#bib.bib33)). Such shortcomings necessitate human oversight
    to verify and correct the data analysis process (Chopra et al., [2023](#bib.bib10);
    Gu et al., [2024c](#bib.bib20); Olausson et al., [2024](#bib.bib47)). Current
    tools often present raw data analysis code, shifting the user’s focus to low-level
    details instead of the high-level data analysis process. According to our interview
    with ChatGPT users, individuals, especially those with limited coding skills,
    struggle to comprehensively review the code produced by LLMs, thereby risking
    undetected errors and potentially incorrect results. Moreover, rectifying code
    through conversation can turn into a cumbersome exchange, adding to the inefficiency
    and frustration.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管具有潜力，LLM驱动的数据分析工具在实际部署中暴露了可靠性问题，包括幻觉（Liu et al., [2023a](#bib.bib34); Chen
    et al., [2024b](#bib.bib7)），微妙的错误（Yang et al., [2021](#bib.bib74); Wu et al.,
    [2024](#bib.bib70)），以及LLM对任务的理解与用户意图的不匹配（Wang et al., [2018](#bib.bib65); Li et
    al., [2024](#bib.bib33)）。这些缺陷需要人工监督以验证和纠正数据分析过程（Chopra et al., [2023](#bib.bib10);
    Gu et al., [2024c](#bib.bib20); Olausson et al., [2024](#bib.bib47)）。当前工具经常呈现原始的数据分析代码，使用户的关注点转向低级细节，而不是高层的数据分析过程。根据我们与ChatGPT用户的访谈，特别是那些编码技能有限的个人，难以全面审查LLM生成的代码，从而增加了未检测到错误和可能的错误结果的风险。此外，通过对话纠正代码可能变成繁琐的交流，增加了低效和挫败感。
- en: 'Our goal is to make the data analysis process conducted by LLMs easier to understand
    and navigate for users, in line with current research on designing UIs featuring
    generative AIs (e.g., (Subramonyam et al., [2024](#bib.bib58); Shen et al., [2024](#bib.bib53))).
    Specifically, we aim to support real-time monitoring and proactive intervention
    (steering) at any point. Compared with existing approaches targeting a traditional
    data analysis pipeline (e.g., (Lau et al., [2023](#bib.bib32); Shrestha et al.,
    [2021](#bib.bib56))), this scenario features conversational interaction and on-demand
    generation of unfamiliar code to the users, where the code streams in. Informed
    by a formative study involving 8 users experienced in LLM-powered data analysis,
    we propose a workflow that identifies data operations within the generated code
    and maps them to visual, interactive primitives on the fly ([Figure. 1](#S0.F1
    "Figure 1 ‣ WaitGPT: Monitoring and Steering Conversational LLM Agent in Data
    Analysis with On-the-Fly Code Visualization")). These primitives collectively
    offer an overview of the data analysis process, and surface the details of each
    data operation and their internal runtime states in an intuitive, syntax-independent
    format. Furthermore, users can refine each operation by interacting directly with
    these primitives without regenerating the entire analysis code. Through this approach,
    we augment traditional conversational user interfaces (CUIs) with interactive
    visualization, transforming users from passive recipients of information into
    active participants in the data analysis task.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '我们的目标是使由LLM进行的数据分析过程对用户更易于理解和导航，这与当前关于设计生成式AI用户界面的研究一致（例如，（Subramonyam et al.,
    [2024](#bib.bib58); Shen et al., [2024](#bib.bib53)））。具体来说，我们旨在支持实时监控和主动干预（引导）任何时刻。与针对传统数据分析管道的现有方法相比（例如，（Lau
    et al., [2023](#bib.bib32); Shrestha et al., [2021](#bib.bib56)）），这种场景具有对话交互和按需生成不熟悉代码的特点，其中代码流入。在一项涉及8名有LLM数据分析经验的用户的形成性研究的指导下，我们提出了一种工作流程，该流程能够在生成的代码中识别数据操作，并将其即时映射到视觉、互动原件上（[Figure.
    1](#S0.F1 "Figure 1 ‣ WaitGPT: Monitoring and Steering Conversational LLM Agent
    in Data Analysis with On-the-Fly Code Visualization")）。这些原件共同提供数据分析过程的概述，并以直观的、与语法无关的格式展示每个数据操作及其内部运行状态的细节。此外，用户可以通过直接与这些原件交互来精细化每个操作，而无需重新生成整个分析代码。通过这种方法，我们用互动可视化增强了传统的对话用户界面（CUIs），将用户从信息的被动接收者转变为数据分析任务的积极参与者。'
- en: We have designed and implemented WaitGPT, a prototype system that converts the
    data analysis code generated by an LLM into a visual diagram that consists of
    nodes representing key data operations, composing an overview step by step. This
    diagram progressively evolves along with the code generation process. Furthermore,
    WaitGPT executes the underlying code line by line and updates the visual diagram
    to reflect the code’s intermediate state during runtime. Users can interact with
    these nodes to modify or adjust the operations, thereby refining the data analysis
    process. Execution results are maintained and preserved within a sandbox environment,
    enabling the system to resume or rerun the analysis code after modifications,
    without the need to regenerate the entire code. A user study with 12 participants
    reported an enhanced experience, noting the ease of spotting errors, increased
    agency, and heightened confidence in the results produced by the LLM.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设计并实现了WaitGPT，一个将LLM生成的数据分析代码转换为由表示关键数据操作的节点组成的视觉图表的原型系统，逐步展示概述。该图表随着代码生成过程逐步演变。此外，WaitGPT逐行执行底层代码，并更新视觉图表以反映代码在运行时的中间状态。用户可以与这些节点交互，以修改或调整操作，从而完善数据分析过程。执行结果在沙箱环境中维护和保存，使系统在修改后能够恢复或重新运行分析代码，而无需重新生成整个代码。对12名参与者的用户研究报告了增强的体验，指出了发现错误的容易程度、增加的主动性和对LLM生成结果的信心提高。
- en: In summary, our contributions are three-fold.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，我们的贡献有三方面。
- en: •
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: A formative study (N=8) that summarizes practices, challenges, and expectations
    in conducting data analysis with LLM agents based on conversation.
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一项形成性研究（N=8），总结了基于对话的LLM代理进行数据分析的实践、挑战和期望。
- en: •
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: A novel design that facilitates monitoring and steering LLM-generated data analysis
    script featuring interactive visualizations. We implement a prototype system named
    WaitGPT and evaluate its usability (N=12).
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一种新颖的设计，促进监控和引导LLM生成的数据分析脚本，具有交互式可视化。我们实现了一个名为WaitGPT的原型系统并评估其可用性（N=12）。
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Discussions and implications on user interface design of LLM agents for data
    analysis tasks.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 讨论和对用于数据分析任务的LLM代理用户界面设计的影响。
- en: 2\. Background & Related Work
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2. 背景与相关工作
- en: Here, we review NLI-based data analysis tools, visualization techniques for
    data processing scripts, and user interface design for human-LLM interactions,
    which are closely related to our study.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们回顾了基于NLI的数据分析工具、数据处理脚本的可视化技术以及人类-LLM交互的用户界面设计，这些都与我们的研究密切相关。
- en: 2.1\. Demystifying NLI-based Data Analysis
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1. 揭示基于NLI的数据分析
- en: NLI-based data analysis tools interpret users’ instructions in natural language
    and automatically perform analytic tasks. Existing tools often assemble atomic
    data operations based on a clear categorization of analytical tasks (Shen et al.,
    [2022](#bib.bib54); Zhu-Tian and Xia, [2022](#bib.bib76)). To support more flexible
    user tasks, there has been surging interest in applying LLMs to translate NL-based
    user intents into data-related operations or directly synthesize visualization
    programs (e.g., (Tian et al., [2024](#bib.bib61); Liu et al., [2023b](#bib.bib36),
    [2024](#bib.bib35))).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 基于NLI的数据分析工具可以解释用户的自然语言指令，并自动执行分析任务。现有工具通常根据分析任务的清晰分类组装原子数据操作（Shen et al., [2022](#bib.bib54);
    Zhu-Tian 和 Xia, [2022](#bib.bib76)）。为了支持更灵活的用户任务，对将LLM应用于将基于自然语言的用户意图转换为数据相关操作或直接合成可视化程序（例如，(Tian
    et al., [2024](#bib.bib61); Liu et al., [2023b](#bib.bib36), [2024](#bib.bib35))）的兴趣激增。
- en: However, it remains unrealistic to expect completely correct outputs for reasons
    like language ambiguity and algorithmic or model accuracy (Feng et al., [2024](#bib.bib15);
    Ferdowsi et al., [2023](#bib.bib16); Narechania et al., [2021](#bib.bib45)). This
    issue becomes more pronounced when integrating LLMs into data analysis tools,
    given their black-box nature. This characteristic calls for rigorous inspection
    and verification strategies, as highlighted in prior research (Chopra et al.,
    [2023](#bib.bib10); Podo et al., [2024](#bib.bib50); Gu et al., [2024b](#bib.bib19)).
    Example errors include wrong column selection, data mapping, data transformation,
    etc. In response to the challenge, XNLI (Feng et al., [2024](#bib.bib15)) provides
    a standalone interface that shows one user query to the key aspects in a finite
    set of the traditional NLI pipeline, i.e., attributes, tasks, and visual encodings.
    With LLMs, Huang et al. (Huang et al., [2023](#bib.bib26)) converted the data
    transformation program into a flowchart using intermediate tables as nodes. Under
    a spreadsheet-based interface, Liu et al. (Liu et al., [2023a](#bib.bib34)) proposed
    grounded abstraction matching (GAM) that explains LLM-generated code to end users
    in natural language. ColDeco (Ferdowsi et al., [2023](#bib.bib16)) further augments
    GAM with two complementary views of intermediate results, highlighting how the
    operation changes the result.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，期望完全正确的输出仍然是不现实的，原因包括语言歧义以及算法或模型准确性的问题（Feng et al., [2024](#bib.bib15); Ferdowsi
    et al., [2023](#bib.bib16); Narechania et al., [2021](#bib.bib45)）。当将大型语言模型（LLMs）集成到数据分析工具中时，这一问题尤为突出，因为它们具有黑箱性质。这一特性要求进行严格的检查和验证策略，如先前研究所强调的（Chopra
    et al., [2023](#bib.bib10); Podo et al., [2024](#bib.bib50); Gu et al., [2024b](#bib.bib19)）。例如错误包括错误的列选择、数据映射、数据转换等。为应对这一挑战，XNLI（Feng
    et al., [2024](#bib.bib15)）提供了一个独立的接口，展示了用户查询在有限集的传统自然语言推理（NLI）流程中的关键方面，即属性、任务和视觉编码。通过使用LLMs，Huang
    et al.（Huang et al., [2023](#bib.bib26)）将数据转换程序转化为使用中间表作为节点的流程图。在基于电子表格的界面下，Liu
    et al.（Liu et al., [2023a](#bib.bib34)）提出了基础抽象匹配（GAM），以自然语言向最终用户解释LLM生成的代码。ColDeco（Ferdowsi
    et al., [2023](#bib.bib16)）进一步增强了GAM，提供了中间结果的两种补充视图，突出了操作如何改变结果。
- en: Our work applies to analytic tasks that are more open-ended and concern complex
    data operations, which is under-examined (He et al., [2024](#bib.bib24)). Most
    relevant to our interest in a conversational interface, Gu et al. (Gu et al.,
    [2024c](#bib.bib20)) added a side panel that profiles intermediate data to facilitate
    retrospective examination of the synthesized code. Kazemitabaar et al. (Kazemitabaar
    et al., [2024](#bib.bib29)) proposed to afford editable assumptions, execution
    plans, and code in LLM response for close verification and steering. We complemented
    their design by proposing a transformable representation of the code, aiming to
    lower the abstraction level of the code and enhance user engagement during the
    interaction.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的工作适用于更开放且涉及复杂数据操作的分析任务，但这一领域尚未得到充分研究（He et al., [2024](#bib.bib24)）。与我们对对话界面的兴趣最相关的是，Gu
    et al.（Gu et al., [2024c](#bib.bib20)）增加了一个侧边面板，以概述中间数据，方便对合成代码的回顾性检查。Kazemitabaar
    et al.（Kazemitabaar et al., [2024](#bib.bib29)）提出在LLM响应中提供可编辑的假设、执行计划和代码，以便于紧密验证和调整。我们通过提出代码的可变表示来补充他们的设计，旨在降低代码的抽象层次，并在交互过程中提高用户参与度。
- en: 2.2\. Sense-making of Data Processing Code
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2\. 数据处理代码的意义理解
- en: Simplifying data processing code can support learning  (Lau et al., [2023](#bib.bib32)),
    collaborative work (Pu et al., [2021](#bib.bib51)), and quality control (Xiong
    et al., [2022](#bib.bib73); Shrestha et al., [2023](#bib.bib57)). To give a comprehensive
    view, prior research has condensed the operations into descriptive narratives (Feng
    et al., [2024](#bib.bib15); Liu et al., [2023a](#bib.bib34)) or schematic diagrams (Huang
    et al., [2023](#bib.bib26); Ramasamy et al., [2023](#bib.bib52)). In addition,
    many works focused on visualizing interim results through animation (e.g., (Khan
    et al., [2017](#bib.bib30); Pu et al., [2021](#bib.bib51); Guo et al., [2023](#bib.bib22)))
    or a timeline representation (e.g.,  (Niederer et al., [2017](#bib.bib46); Bors
    et al., [2019](#bib.bib3); Lucchesi et al., [2022](#bib.bib37))). For instance,
    Datamation (Pu et al., [2021](#bib.bib51)) visually maps and links each step of
    the data process to the underlying dataset, providing more context for the audience.
    Smallset Timeline (Lucchesi et al., [2022](#bib.bib37)) intelligently selects
    samples affected by the operation and encodes the changes on a table along the
    timeline.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 简化数据处理代码可以支持学习 (Lau et al., [2023](#bib.bib32))、协作工作 (Pu et al., [2021](#bib.bib51))
    和质量控制 (Xiong et al., [2022](#bib.bib73); Shrestha et al., [2023](#bib.bib57))。为了提供全面的视角，之前的研究将操作浓缩成描述性的叙述
    (Feng et al., [2024](#bib.bib15); Liu et al., [2023a](#bib.bib34)) 或示意图 (Huang
    et al., [2023](#bib.bib26); Ramasamy et al., [2023](#bib.bib52))。此外，许多工作还专注于通过动画
    (例如 (Khan et al., [2017](#bib.bib30); Pu et al., [2021](#bib.bib51); Guo et al.,
    [2023](#bib.bib22))) 或时间线表示 (例如 (Niederer et al., [2017](#bib.bib46); Bors et
    al., [2019](#bib.bib3); Lucchesi et al., [2022](#bib.bib37))) 来可视化中间结果。例如，Datamation
    (Pu et al., [2021](#bib.bib51)) 通过可视化映射和链接数据处理的每一步到基础数据集，为观众提供了更多的背景信息。Smallset
    Timeline (Lucchesi et al., [2022](#bib.bib37)) 智能选择受操作影响的样本，并在时间线上的表格中编码这些变化。
- en: To enhance understanding of atomic data operations, many works investigated
    step-wise examination of the underlying data. This can be achieved by revealing
    the connections and discrepancies between the input and output states. Pandas
    Tutor (Lau et al., [2023](#bib.bib32)) highlights selected rows and links their
    new position with arrows. SOMNUS (Xiong et al., [2022](#bib.bib73)) presents 23
    static glyphs for data transformation operations in table, column, and row granularity,
    respectively. To bridge the mental map between data transform specifications and
    results, some works allow interactive inspection (Kandel et al., [2011](#bib.bib28);
    Shrestha et al., [2021](#bib.bib56), [2023](#bib.bib57)). For instance, Unravel (Shrestha
    et al., [2021](#bib.bib56)) automatically transforms individual data operations
    into summary boxes with key parameters and the table size, which serves as an
    intermediate layer for users to modify and access runtime execution results.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了增强对原子数据操作的理解，许多工作研究了对基础数据的逐步检查。这可以通过揭示输入和输出状态之间的连接和差异来实现。Pandas Tutor (Lau
    et al., [2023](#bib.bib32)) 突出显示选定的行，并用箭头链接其新位置。SOMNUS (Xiong et al., [2022](#bib.bib73))
    以表格、列和行的粒度呈现 23 个静态图形用于数据转换操作。为了弥合数据转换规范与结果之间的心理映射，一些工作允许交互式检查 (Kandel et al.,
    [2011](#bib.bib28); Shrestha et al., [2021](#bib.bib56), [2023](#bib.bib57))。例如，Unravel
    (Shrestha et al., [2021](#bib.bib56)) 自动将单个数据操作转换为包含关键参数和表格大小的摘要框，这作为用户修改和访问运行时执行结果的中间层。
- en: 'WaitGPT addresses a new problem: sense-making of data processing code produced
    by an LLM agent. Compared to previous approaches that deal with complete and static
    scripts, the code is generated in a streaming manner, which may present challenges
    for users in terms of following the LLM’s response during the generation process.
    In addition, some tools (e.g., (Wang et al., [2022](#bib.bib64); Shrestha et al.,
    [2021](#bib.bib56))) require coding proficiency while some have a rigid functionality
    (e.g., (Xiong et al., [2022](#bib.bib73); Feng et al., [2024](#bib.bib15))). However,
    in our scenario, end-users, including data analysts, laypeople, etc., talk to
    an LLM agent for various data analysis tasks. We prioritize intuitive visualization
    designs for immediate understanding and rapid verification, keeping users engaged
    and undistracted during the active code generation phase. General code debugging,
    however, is beyond our scope.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: WaitGPT 解决了一个新问题：对 LLM 代理生成的数据处理代码的意义构建。与处理完整且静态脚本的以往方法相比，代码以流式方式生成，这可能会在生成过程中给用户跟踪
    LLM 响应带来挑战。此外，一些工具（例如，（Wang 等，[2022](#bib.bib64)；Shrestha 等，[2021](#bib.bib56)））需要编码能力，而一些工具功能则比较固定（例如，（Xiong
    等，[2022](#bib.bib73)；Feng 等，[2024](#bib.bib15)））。然而，在我们的场景中，包括数据分析师、普通用户等在内的最终用户与
    LLM 代理进行各种数据分析任务。我们优先考虑直观的可视化设计，以便立即理解和快速验证，使用户在积极的代码生成阶段保持参与和不被分心。一般的代码调试则超出了我们的范围。
- en: 2.3\. Advancing UIs for Human-LLM Interaction
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3\. 促进人类-LLM 互动的用户界面进展
- en: Amidst the wave of LLMs, the HCI community has been advancing user interface
    design to enhance control over LLMs, moving beyond a standard chatbot framework
    or basic API invocations.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在 LLM 发展的浪潮中，人机交互（HCI）社区一直在推进用户界面设计，以增强对 LLM 的控制，超越标准的聊天机器人框架或基本的 API 调用。
- en: Similar to our motivation to facilitate easier comprehension and verification
    of the generated content, some works seek to bridge the gulf of envisioning in
    human-LLM interactions (Subramonyam et al., [2024](#bib.bib58); Tankelevitch et al.,
    [2024](#bib.bib60)). For example, Graphlogue (Jiang et al., [2023](#bib.bib27))
    converts linear text into a diagram that encodes logical structure on the fly
    to assist information-seeking tasks. Zhu-Tian et al. (Zhu-Tian et al., [2024a](#bib.bib77))
    foreshadows LLM-generated code incrementally and instantly during prompt crafting.
    Sensecape (Suh et al., [2023](#bib.bib59)) empowers users with a multilevel abstraction
    of existing conversation and supports information foraging and sense-making. We
    attend to an emerging scenario of conversational data analysis with LLMs, where
    we present novel features like on-the-fly visualization as code streams in, code
    scrolly-telling, and snippet navigation.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们旨在促进生成内容的更容易理解和验证的动机类似，一些研究试图弥合人类-LLM 互动中的想象差距（Subramonyam 等，[2024](#bib.bib58)；Tankelevitch
    等，[2024](#bib.bib60)）。例如，Graphlogue（Jiang 等，[2023](#bib.bib27)）将线性文本转换为图表，实时编码逻辑结构以协助信息检索任务。Zhu-Tian
    等（Zhu-Tian 等，[2024a](#bib.bib77)）在提示词编写过程中逐步且即时地预测 LLM 生成的代码。Sensecape（Suh 等，[2023](#bib.bib59)）为用户提供现有对话的多层次抽象，并支持信息搜寻和意义构建。我们关注于与
    LLM 进行对话数据分析的一个新兴场景，其中我们展示了如实时可视化代码流、代码滚动讲述和片段导航等新功能。
- en: Another stream of research explores novel interaction designs with LLMs that
    surpass the conventional single-text prompt, where more dynamic and progressive
    workflows and interaction modalities are promoted. For instance, Wu et al. (Wu
    et al., [2022](#bib.bib69)) introduced the concept of AI Chains, where users specify
    how the output of one step becomes the input for the next, resulting in cumulative
    gains per step. Many works targeted specific application domains, including writing (Chung
    et al., [2022](#bib.bib11)), graphics design (Masson et al., [2024](#bib.bib38)),
    programming (Angert et al., [2023](#bib.bib2)), etc. Relevant to our interest
    in granular control of LLM-generated code, Low-code LLM (Cai et al., [2024](#bib.bib5))
    allows users to edit the tentative workflow synthesized by a planning LLM, thereby
    providing control over the generated code. DynaVis (Vaithilingam et al., [2024](#bib.bib62))
    leverages LLM to synthesize UI widgets to edit data visualizations dynamically.
    Bearing a similar idea, our work supports user interactions with the intermediate
    visualization to drill down or refine the code in place for more intuitive and
    granular control with LLMs.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 另一项研究方向探索了超越传统单一文本提示的LLM互动设计，推广了更多动态和渐进的工作流程及互动方式。例如，Wu等人（Wu et al., [2022](#bib.bib69)）引入了AI
    Chains的概念，其中用户指定一个步骤的输出如何成为下一个步骤的输入，从而实现每一步的累积收益。许多研究针对特定应用领域，包括写作（Chung et al.,
    [2022](#bib.bib11)）、图形设计（Masson et al., [2024](#bib.bib38)）、编程（Angert et al.,
    [2023](#bib.bib2)）等。与我们对LLM生成代码的细粒度控制的兴趣相关，Low-code LLM（Cai et al., [2024](#bib.bib5)）允许用户编辑由规划LLM综合的暂定工作流程，从而提供对生成代码的控制。DynaVis（Vaithilingam
    et al., [2024](#bib.bib62)）利用LLM合成UI组件，以动态编辑数据可视化。基于类似的理念，我们的工作支持用户与中间可视化的交互，以深入挖掘或精炼代码，从而实现与LLM的更直观和细粒度的控制。
- en: 3\. Formative Study
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3. 形成性研究
- en: We conducted a formative study (N=8) to better understand the glitches in LLM-powered
    data analysis tools and inform the design considerations for contextualized support.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了一个形成性研究（N=8），以更好地理解LLM驱动的数据分析工具中的问题，并为背景化支持的设计考虑提供信息。
- en: 3.1\. Setup
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1. 设置
- en: Recruitment & Screening
  id: totrans-42
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 招募与筛选
- en: We posted recruitment advertisements on social media and university forums.
    Candidate participants were required to complete a questionnaire about their demographic
    information and relevant experience. We selected volunteers who are more experienced
    with data analysis and familiar with LLM-powered data analysis tools.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在社交媒体和大学论坛上发布了招募广告。候选参与者需填写一份关于其人口信息和相关经验的问卷。我们选择了那些在数据分析方面经验更丰富且熟悉LLM驱动的数据分析工具的志愿者。
- en: Protocol
  id: totrans-44
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 协议
- en: The study consisted of a contextual inquiry (20$\sim$40 min) and a structured
    interview (15 min). First, we asked participants to show their interaction history
    with LLM agents in data analysis tasks. If their original dataset is available,
    they will also walk the moderator through the data analysis procedure while thinking
    aloud. For five participants with the original dataset at hand, we asked them
    to replicate one analysis session directly while thinking aloud. The interview
    ended with a list of questions regarding the overall experience. Each participant
    is compensated with $12/hour.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 该研究包括一个背景调查（20$\sim$40 min）和一个结构化访谈（15 min）。首先，我们要求参与者展示他们在数据分析任务中与LLM代理的互动历史。如果他们的原始数据集可用，他们还将一边思考一边带领主持人了解数据分析过程。对于手头有原始数据集的五位参与者，我们要求他们在思考的同时直接重复一个分析会话。访谈以一系列关于整体体验的问题结束。每位参与者的补偿为$12/hour。
- en: Participants
  id: totrans-46
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 参与者
- en: We recruited 8 participants in total (P1–P8), with 3 females and 5 males, aged
    from 20 to 30. Specifically, there are 6 postgraduate students, 1 undergraduate
    student (P3), and 1 data journalist (P4). All are familiar with the data analysis
    mode (formally named as “Advanced Data Analysis” or “Code Interpreter”) embedded
    in OpenAI’s ChatGPT (OpenAI, [2024](#bib.bib48)) and had at least 5 sessions.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们总共招募了8名参与者（P1–P8），其中3名女性和5名男性，年龄在20至30岁之间。具体而言，有6名研究生、1名本科生（P3）和1名数据记者（P4）。所有参与者都熟悉OpenAI的ChatGPT（OpenAI,
    [2024](#bib.bib48)）中嵌入的数据分析模式（正式名称为“高级数据分析”或“代码解释器”），并且至少有5次会话经验。
- en: Analysis
  id: totrans-48
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 分析
- en: All interviews were video-recorded and transcribed into text. Following thematic
    analysis (Braun and Clarke, [2012](#bib.bib4)), the first author applied inductive
    and deductive approaches and derived initial categorized codes and themes. The
    first three authors reviewed transcripts and important screenshots based on weekly
    meetings to agree on the final themes after iterations.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 所有访谈均进行了视频录制并转录成文本。根据主题分析（Braun 和 Clarke，[2012](#bib.bib4)），第一作者应用了归纳和演绎的方法，得出了初步的分类代码和主题。前三位作者根据每周会议审查了记录和重要的屏幕截图，以便在迭代后对最终主题达成一致。
- en: 3.2\. Findings
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2\. 发现
- en: Here, we summarize the key findings from the interview study.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们总结了访谈研究的主要发现。
- en: 3.2.1\. Why do people turn to LLM-powered tools for data analysis?
  id: totrans-52
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1\. 为什么人们在数据分析中转向 LLM 驱动的工具？
- en: Participants recognized the versatility of conversational LLM agents for data
    analysis as a significant advantage. They have utilized it for a diversity of
    data-intensive tasks, including exploratory data analysis (4/8), data wrangling
    (4/8), confirmatory data analysis (2/8), data profiling (2/8), and data retrieval
    (1/8). In addition, participants appreciated its flexibility in open-ended data
    analysis. “Compared with software with rigid functionalities, I enjoy the freedom
    here [in ChatGPT]. I can ask for an explanation based on the result, request recommendations
    for the next step, or insert irrelevant questions.” (P6) Another strength of an
    LLM-powered data analysis tool is its low-code or no-code environment, where end
    users only need to describe the tasks and obtain a well-organized response in
    the form of code or report. For instance, P4, who works in investigative data
    journalism (Showkat and Baumer, [2021](#bib.bib55)) and regularly cleans and organizes
    datasets from various sources, stated “Having code generated from scratch saves
    days of my work”. This feature was particularly valued by participants who were
    not proficient in coding (2/8). “I no longer need to care about detailed operations
    and learn the APIs.” (P2)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者认识到对话型 LLM 代理在数据分析中的多功能性是一个显著的优势。他们利用它进行多种数据密集型任务，包括探索性数据分析 (4/8)、数据清理 (4/8)、确认性数据分析
    (2/8)、数据概况 (2/8) 和数据检索 (1/8)。此外，参与者欣赏其在开放式数据分析中的灵活性。“与功能固定的软件相比，我更喜欢这里 [ChatGPT]
    的自由。我可以根据结果请求解释，请求下一步的建议，或插入无关的问题。”（P6）LLM 驱动的数据分析工具的另一个优点是低代码或无代码环境，用户只需描述任务即可获得以代码或报告形式组织良好的响应。例如，P4，从事调查数据新闻工作（Showkat
    和 Baumer，[2021](#bib.bib55)）并定期清理和组织来自不同来源的数据集，表示“从头生成代码节省了我几天的工作”。这一特性对那些不熟练编码的参与者尤为重要（2/8）。“我不再需要关心详细的操作或学习
    API。”（P2）
- en: Table 1\. Common issues in the code generated by OpenAI’s ChatGPT for data analysis
    tasks.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1\. OpenAI 的 ChatGPT 在数据分析任务中生成的常见问题。
- en: '| Issue Type | Detailed Behaviors of an LLM Agent |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 问题类型 | LLM 代理的详细行为 |'
- en: '| --- | --- |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Incomplete workflow | Misses some important steps, e.g., not excluding empty
    value when computing means. |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 不完整的工作流程 | 漏掉一些重要步骤，例如，计算均值时未排除空值。 |'
- en: '| Non-existing symbols | Invoke a function, configure a parameter, or use a
    variable that is not defined. |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 不存在的符号 | 调用一个未定义的函数、配置一个参数，或使用一个未定义的变量。 |'
- en: '| Data transform failure | Fails to handle edge data value, e.g., accessing
    an attribute that does not exist in all data items. |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 数据转换失败 | 处理边缘数据值失败，例如，访问所有数据项中不存在的属性。 |'
- en: '| Wrong columns | Selects the wrong column(s). |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 错误的列 | 选择了错误的列。 |'
- en: '| Unreasonable values | Sets parameter to an inappropriate value, e.g., using
    an overly high threshold for outliers. |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 不合理的值 | 将参数设置为不适当的值，例如，使用过高的阈值来检测异常值。 |'
- en: \Description
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: \描述
- en: Table 1 lists common issues encountered by interviewees when using ChatGPT for
    data analysis tasks. The first column, ”Issue Type,” categorizes the problems,
    while the second column, ”Detailed Behaviors of LLM Agent,” provides specific
    examples.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1 列出了受访者在使用 ChatGPT 进行数据分析任务时遇到的常见问题。第一列“问题类型”对问题进行了分类，而第二列“LLM 代理的详细行为”则提供了具体的例子。
- en: 3.2.2\. How do people work with LLM-powered tools in data analysis?
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2\. 人们在数据分析中如何使用 LLM 驱动的工具？
- en: 'We categorize participants’ workflows into three phases: code generation, post-verification,
    and iterative refinement.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将参与者的工作流程分为三个阶段：代码生成、后期验证和迭代改进。
- en: By default, ChatGPT collapses the code and communicates the progress in percentage
    only. Correspondingly, participants (7/8) hardly toggled the code panel during
    the generation phase but distracted themselves by turning to personal matters
    or engaging in related side tasks like reviewing previous conversations.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，ChatGPT 会折叠代码，仅以百分比形式传达进度。因此，参与者（7/8）在生成阶段几乎不会切换代码面板，而是通过转向个人事务或进行相关的副任务（如回顾之前的对话）来分散注意力。
- en: 'Upon completion of the code generation, every participant consistently reviewed
    the textual response and, if available, the visualizations to grasp the analysis’s
    implications. Verifying the code’s reliability was a common concern, with most
    (6/8) participants inspecting the generated script, especially when the data insights
    were important. They would look into the entire data processing pipeline and specific
    parameters of individual operands. P4 sometimes posed a validation question to
    verify the code’s correctness, such as requesting the mean value to see if it
    aligned with his prior knowledge. When the generated code was inconsistent with
    expectations, participants (6/8) attempted to recalibrate the agent’s direction
    through refined prompts. P2 mentioned a special strategy: “I try really hard to
    decompose the task into actionable items so that it won’t be too challenging for
    ChatGPT.” Notably, some participants (3/8) regenerated the response instead of
    starting a new conversation. “I am afraid to break the analysis flow with additional
    requirements on a small step.” (P3) For open-ended tasks, after obtaining initial
    results, participants may further drill down through conversation (3/8) or turn
    to a local coding environment (2/8), depending on the trade-off between coding
    and prompting. “With the code, I can easily reuse it on a (computational) notebook.”
    (P1)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码生成完成后，每个参与者都会一致地审查文本响应，以及（如果有的话）可视化结果，以理解分析的含义。验证代码的可靠性是一个共同的关注点，大多数（6/8）参与者会检查生成的脚本，特别是在数据见解非常重要时。他们会查看整个数据处理流程以及各个操作数的具体参数。P4
    有时会提出验证问题以确认代码的正确性，例如请求平均值以查看是否与他之前的知识一致。当生成的代码与预期不符时，参与者（6/8）会通过优化提示尝试重新调整模型的方向。P2
    提到了一个特别的策略：“我会尽力将任务分解为可操作的项，以便 ChatGPT 不会觉得太具有挑战性。”值得注意的是，一些参与者（3/8）会重新生成响应，而不是开始新的对话。“我担心在小步骤上添加额外要求会打断分析流程。”（P3）对于开放性任务，获得初步结果后，参与者可能会进一步通过对话（3/8）深入探讨，或转向本地编码环境（2/8），这取决于编码和提示之间的权衡。“有了代码，我可以轻松地在（计算）笔记本上重用它。”（P1）
- en: 3.2.3\. What hinders human-LLM collaboration in data analysis tasks?
  id: totrans-68
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.3\. 什么阻碍了人类与大型语言模型（LLM）在数据分析任务中的合作？
- en: Three themes emerge regarding glitches for users to participate in data analysis
    assisted by LLM agents actively.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 关于用户在数据分析中积极参与 LLM 代理的故障，出现了三个主题。
- en: $\diamond$  Disrupted workflow negatively impacts user engagement. As code generation
    and execution are sometimes long-winded, it interrupts the analysis flow. Most
    participants (7/8) would shift focus during the process instead of monitoring
    the generated code closely, for code is not as intuitive or accessible as natural
    language. “I feel exhausted when reading the code, so I’d rather leave it alone.”
    (P1) Without timely intervention, tiny errors in the code may propagate and invalidate
    the analysis result, precipitating a need to revisit and revise the work. This
    leads to heightened frustration and a considerable waste of time, as finishing
    one exploratory data analysis task generally takes half to three minutes. To avoid
    such prolonged dialogue exchanges, P3 explicitly requested the agent to ask for
    permission before generating and executing, explaining that “(In this way,) I
    can at least take control over the direction”. (P5)
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 工作流程中断会对用户参与产生负面影响。由于代码生成和执行有时较为冗长，它会打断分析流程。大多数参与者（7/8）在过程中会将注意力转移，而不是密切关注生成的代码，因为代码不像自然语言那样直观或易于访问。“当我阅读代码时感到很疲惫，所以我宁愿不去碰它。”（P1）如果没有及时干预，代码中的微小错误可能会传播并使分析结果无效，从而需要重新审视和修订工作。这会导致挫折感增加和时间的极大浪费，因为完成一个探索性数据分析任务通常需要半到三分钟。为了避免这种长期的对话交流，P3
    明确要求模型在生成和执行之前请求许可，解释说“（这样）我至少可以掌控方向。”（P5）
- en: $\diamond$  Verifying raw code is mentally demanding. While LLMs may provide
    clear annotations to explain each step, many participants (7/8) still found verifying
    the generated code challenging.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 验证原始代码在精神上是要求高的。虽然LLM可能提供清晰的注释来解释每一步，但许多参与者（7/8）仍然觉得验证生成的代码具有挑战性。
- en: On the one hand, reviewing the code snippet is inherently laborious and counter-intuitive,
    particularly when deciphering code from an external source, which can be mentally
    taxing. After all, LLMs may not follow the coding styles the participants are
    comfortable with. “It [LLM] sometimes uses much-advanced syntax, so I ask it to
    write code like a freshman.” (P5) Besides, LLMs may employ unfamiliar packages.
    “I don’t even know what the function parameter is about, let alone correct it.”
    (P3)
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一方面，回顾代码片段本质上是劳动密集型且反直觉的，特别是当解读外部来源的代码时，这可能会让人感到精神疲惫。毕竟，LLM可能不遵循参与者习惯的编码风格。“它[LLM]有时使用更先进的语法，所以我让它像一个新生一样写代码。”（P5）此外，LLM可能会使用不熟悉的包。“我甚至不知道函数参数是什么，更不用说纠正它了。”（P3）
- en: 'On the other hand, LLMs may introduce various unexpected errors in the code
    that require careful inspection, as evidenced in the literature (Feng et al.,
    [2024](#bib.bib15); Chopra et al., [2023](#bib.bib10); Gu et al., [2024b](#bib.bib19)).
    [Table 1](#S3.T1 "Table 1 ‣ 3.2.1\. Why do people turn to LLM-powered tools for
    data analysis? ‣ 3.2\. Findings ‣ 3\. Formative Study ‣ WaitGPT: Monitoring and
    Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization")
    lists example issues. P6 noted LLM hallucinations: “At first look, the logic was
    awfully smooth, yet the parameter was a synthesized constant. It’s very tricky
    (to identify the issue).” Some participants (3/8) were concerned about the finding’s
    reliability but frustrated with limited approaches. “I am not sure if the conclusion
    is correct. I have a tight time budget, so I check the major steps and cross my
    fingers for no other issues.” (P8)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '另一方面，LLM可能会在代码中引入各种意外错误，这些错误需要仔细检查，文献中已有证明（Feng等，[2024](#bib.bib15)；Chopra等，[2023](#bib.bib10)；Gu等，[2024b](#bib.bib19)）。[表1](#S3.T1
    "Table 1 ‣ 3.2.1\. Why do people turn to LLM-powered tools for data analysis?
    ‣ 3.2\. Findings ‣ 3\. Formative Study ‣ WaitGPT: Monitoring and Steering Conversational
    LLM Agent in Data Analysis with On-the-Fly Code Visualization") 列出了示例问题。P6提到LLM的幻觉：“乍一看，逻辑非常流畅，但参数却是合成的常量。这很棘手（识别问题）。”一些参与者（3/8）对发现的可靠性感到担忧，但对有限的解决方法感到沮丧。“我不确定结论是否正确。我时间紧张，所以我检查主要步骤，并祈祷没有其他问题。”（P8）'
- en: $\diamond$  Iterations can be extensively back-and-forth. To fix identified
    issues, users need to formulate instructions regarding what is wrong and how to
    correct the errors and then wait for another generation-execution-report cycle.
    Unfortunately, this process can become time-consuming due to its trial-and-error
    nature and requires substantial effort to communicate the nuances of the desired
    analysis effectively. Therefore, many participants (6/8) were reluctant to embrace
    the conversational workflow fully. For minor issues like refining operational
    details, some participants (5/8) preferred to copy-paste the code to a local environment
    and make adaptations. “It is more convenient to reuse the code than telling ChatGPT
    specifically what to do.” (P7) For major changes like adding a new processing
    step, they were more willing to communicate with the LLM agent since writing code
    becomes tedious. Still, after several trials, they would turn to the local environment
    when losing patience.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 迭代可能会反复进行。为了修复识别出的问题，用户需要制定关于问题所在以及如何纠正错误的指令，然后等待另一个生成-执行-报告周期。不幸的是，由于试错的性质，这一过程可能会变得耗时，并且需要大量的努力来有效地传达所需分析的细节。因此，许多参与者（6/8）不愿完全接受对话工作流。对于像细化操作细节这样的小问题，一些参与者（5/8）更喜欢将代码复制到本地环境并进行调整。“重复使用代码比具体告诉ChatGPT该做什么更方便。”（P7）对于像添加新处理步骤这样的重大更改，他们更愿意与LLM代理沟通，因为编写代码变得繁琐。然而，经过几次尝试后，他们在失去耐心时会转向本地环境。
- en: 3.3\. Design Considerations
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3\. 设计考虑
- en: Informed by the formative study, we draw the following design considerations
    (DC) to guide our conception of an alternative interaction design for LLM-powered
    data analysis tools. Our design goal is to support monitoring and steering LLM-synthesized
    data analysis with interactive visual scaffolding.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 根据形成性研究，我们提出了以下设计考虑（DC），以指导我们对LLM驱动的数据分析工具的替代交互设计的构思。我们的设计目标是支持通过互动视觉支架监控和引导LLM合成的数据分析。
- en: DC1\. Abstract code stream into key data operations for a focused verification.
    In the context of LLM-based data analysis, a primary challenge emerges due to
    the often extensive and complex nature of the generated code. However, users usually
    prefer understanding the analysis process itself over the complex details of the
    code. Echoing a previous study (Gu et al., [2024c](#bib.bib20)), participants
    expressed the need to access data operations, determinant parameters, and their
    outcomes. To address this challenge, we propose to simplify the information to
    digest for verifying the data analysis procedure conducted by LLMs. By extracting
    the layered information concerning individual data operations from the code, such
    as the parametric specifications and execution results, we aim to refocus users’
    attention on the analysis process itself, sparing them from the overwhelming task
    of understanding the raw code.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: DC1\. 将代码流抽象为关键数据操作，以进行集中验证。在基于LLM的数据分析背景下，主要挑战在于生成的代码通常非常庞大和复杂。然而，用户通常更倾向于理解分析过程本身，而非代码的复杂细节。呼应之前的研究（Gu等，[2024c](#bib.bib20)），参与者表示需要访问数据操作、决定性参数及其结果。为应对这一挑战，我们建议简化信息，以便验证LLM执行的数据分析过程。通过从代码中提取有关单个数据操作的分层信息，例如参数规范和执行结果，我们旨在将用户的注意力重新集中于分析过程本身，从而避免理解原始代码的繁重任务。
- en: DC2\. Scaffold data operations and execution results through straightforward
    visualization generated on the fly. Despite the abstraction, users, particularly
    those with limited programming expertise, may still find it challenging to interpret
    the raw, syntax-heavy output produced by LLMs. Drawing inspiration from previous
    works in code visualization (Myers, [1990](#bib.bib43); Victor, [2011](#bib.bib63)),
    we adopt visual representations that abstract away from specific code syntax to
    facilitate quick comprehension of the data analysis process. Thus, the visual
    representation should also expose this information, including the data state before
    and after each operation. Moreover, this process should be executed on the fly
    along the code generation process, ensuring a seamless experience for the user
    aligning to their sense-making process. It is also critical to establish a connection
    between the code and its visual representation. This will allow users to see the
    direct impact of their instructions on the data and to navigate the analysis workflow
    more effectively.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: DC2\. 通过即时生成的简单可视化构建数据操作和执行结果。尽管进行了抽象，用户，特别是那些编程经验有限的用户，仍可能发现理解LLM生成的原始、语法繁重的输出具有挑战性。借鉴之前在代码可视化方面的工作（Myers，[1990](#bib.bib43)；Victor，[2011](#bib.bib63)），我们采用抽象化的视觉表示，以便快速理解数据分析过程。因此，视觉表示还应展示这些信息，包括每次操作前后的数据状态。此外，该过程应在代码生成过程中即时执行，以确保与用户的认知过程相一致的无缝体验。建立代码与其视觉表示之间的联系也至关重要。这将使用户能够看到指令对数据的直接影响，并更有效地导航分析工作流。
- en: DC3\. Support interrogation to the LLM and iterative code generation in the
    visualization. An outstanding issue of LLM-powered data analysis in a conversational
    interface is the tediousness of articulating refinement intents and uncertainties
    in LLMs’ follow-up responses. To overcome this, the visual representations should
    simplify articulating these intents by providing mechanisms to modify the data
    analysis process at a granular level. Users should be able to interact with individual
    steps (data operations) of the generated analysis, allowing them to make precise
    adjustments without the need to rewrite large portions of code or restart the
    conversation. This granular control empowers users to fine-tune the analysis,
    accurately reflects their intentions, and streamlines the iterative refinement
    process.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: DC3\. 支持对LLM的询问和可视化中的迭代代码生成。LLM驱动的数据分析在对话界面中的突出问题是表达细化意图和LLM后续响应中的不确定性时的繁琐。为克服这一问题，视觉表示应简化这些意图的表达，提供在细粒度水平上修改数据分析过程的机制。用户应能够与生成分析的各个步骤（数据操作）互动，使他们可以进行精确调整，而无需重写大量代码或重新启动对话。这种细粒度控制赋予用户精细调整分析的能力，准确反映其意图，并简化迭代优化过程。
- en: 'DC4\. Embed visualization seamlessly into the conversational user interface
    (CUI). As conversational data analysis normally takes place in a CUI (Gu et al.,
    [2024c](#bib.bib20); Chopra et al., [2023](#bib.bib10)), we tailor the design
    to common design patterns of web CUIs in a non-intrusive manner. For instance,
    the visualization should be stably revealed during the progressive generation,
    following the same vertical order as the code. It should offer a lightweight complementary
    view of the code section in the LLM’s response (see [Figure. 2](#S3.F2 "Figure
    2 ‣ 3.3\. Design Considerations ‣ 3\. Formative Study ‣ WaitGPT: Monitoring and
    Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization"))
    and afford a level of visual guidance for the code dependency between conversational
    threads.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 'DC4\. 将可视化无缝嵌入对话用户界面（CUI）中。由于对话数据分析通常发生在CUI中（Gu等，[2024c](#bib.bib20); Chopra等，[2023](#bib.bib10)），我们将设计调整为符合网页CUI的常见设计模式，以非侵入性的方式进行。例如，可视化应在逐步生成过程中稳定地显示，遵循与代码相同的垂直顺序。它应提供对LLM响应中代码部分的轻量级补充视图（见[图2](#S3.F2
    "Figure 2 ‣ 3.3\. Design Considerations ‣ 3\. Formative Study ‣ WaitGPT: Monitoring
    and Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization")），并为对话线程之间的代码依赖关系提供视觉指导。'
- en: '![Refer to caption](img/8300e2d6f7937f9a373a9c04d28d5b9f.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8300e2d6f7937f9a373a9c04d28d5b9f.png)'
- en: Figure 2\. We propose a workflow that identifies data operations within the
    generated code and maps them to visual, interactive primitives on the fly. These
    primitives collectively offer an overview of the data analysis process.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图2\. 我们提出了一种工作流程，能够识别生成代码中的数据操作，并将其映射到即时的可视化交互原语。这些原语共同提供了数据分析过程的概述。
- en: \Description
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: \Description
- en: 'Figure 2 illustrates the proposed workflow. The left side shows the user-LLM
    interaction: users input instructions, and the LLM responds with blocks containing
    code, execution results, and analysis. The middle section depicts the visualization
    workflow: First, the code is parsed into data operations. Second, these operations
    are executed to derive runtime states. Third, the runtime states are combined
    with the static code structure to produce a visual representation that includes
    static and dynamic information. The right side describes the objects extracted
    and the focus at each stage of the visualization workflow, including the data
    operations, runtime states, and visual representations.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图2说明了提出的工作流程。左侧显示了用户与LLM的交互：用户输入指令，LLM则响应包含代码、执行结果和分析的块。中间部分展示了可视化工作流程：首先，将代码解析为数据操作。其次，这些操作被执行以得出运行时状态。第三，将运行时状态与静态代码结构结合，生成包含静态和动态信息的可视化表示。右侧描述了可视化工作流程每个阶段提取的对象和关注点，包括数据操作、运行时状态和可视化表示。
- en: '![Refer to caption](img/d0390231d19a928c7895ba091b68dc47.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d0390231d19a928c7895ba091b68dc47.png)'
- en: Figure 3\. A screenshot of the WaitGPT user interface. (A) An enlarged view
    of the flow diagram representing the code. (B) An illustration of the “table glyphs”
    that flow along the edge showing table dependency and changes during code generation.
    (C) Inspecting intermediate data by toggling the interactive table panel. (D)
    Interrogating LLM based on an operation.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图3\. WaitGPT用户界面的截图。(A) 代码流程图的放大视图。(B) “表格符号”沿边缘流动的示例，显示表格依赖关系和代码生成过程中的变化。(C)
    通过切换交互式表格面板检查中间数据。(D) 基于操作询问LLM。
- en: \Description
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: \Description
- en: Figure 3 shows a screenshot of the user interface. The left side presents an
    overview of a conversation, while the code visualization is enlarged on the right
    side. There are three subfigures. The top subfigure showcases animated glyphs
    during code generation. The middle-right subfigure illustrates an interactive
    table view. The bottom-right subfigure demonstrates contextual inquiry based on
    a specific operation.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图3展示了用户界面的截图。左侧呈现了对话的概述，而右侧则放大了代码可视化。图中有三个子图。顶部子图展示了代码生成过程中的动画符号。中右子图展示了交互式表格视图。底部右侧子图演示了基于特定操作的上下文查询。
- en: '4\. WaitGPT: Usage Scenario'
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. WaitGPT：使用场景
- en: 'Informed by the formative study and design considerations, we propose dynamically
    visualizing the code generation process to help users steer a conversational LLM
    agent during the data analysis process. This is achieved through a workflow that
    identifies data operations within the generated code and maps them to visual primitives
    on the fly (see [Figure. 2](#S3.F2 "Figure 2 ‣ 3.3\. Design Considerations ‣ 3\.
    Formative Study ‣ WaitGPT: Monitoring and Steering Conversational LLM Agent in
    Data Analysis with On-the-Fly Code Visualization")). These visual primitives not
    only illustrate the static aspects of data operations but also display the runtime
    states of the underlying data (i.e., tables) both before and after these operations.
    Moreover, they provide users with rich interaction possibilities, allowing them
    to refine the data operations without regenerating the code entirely.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '根据形成性研究和设计考虑，我们建议动态可视化代码生成过程，以帮助用户在数据分析过程中引导对话式 LLM 代理。这通过一种工作流程实现，该流程识别生成代码中的数据操作并将其映射到可视化原语（见
    [图 2](#S3.F2 "Figure 2 ‣ 3.3\. Design Considerations ‣ 3\. Formative Study ‣ WaitGPT:
    Monitoring and Steering Conversational LLM Agent in Data Analysis with On-the-Fly
    Code Visualization")）。这些可视化原语不仅展示数据操作的静态方面，还显示这些操作前后的底层数据（即，表）的运行时状态。此外，它们为用户提供了丰富的交互可能性，使他们能够在无需完全重新生成代码的情况下，细化数据操作。'
- en: We instantiate this idea with a prototype system, WaitGPT, which enables users
    to proactively guide the data analysis process with an LLM agent, making interventions
    akin to saying, “Wait, GPT, there is something wrong…” This section walks through
    WaitGPT using a hypothetical use case, demonstrating its capacity to transform
    the user’s interaction with LLMs in data analysis tasks.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过一个原型系统 WaitGPT 实现了这一理念，该系统使用户能够主动引导数据分析过程，与 LLM 代理进行类似“等一下，GPT，有些地方不对劲……”的干预。本节通过一个假设的用例来演示
    WaitGPT，展示其在数据分析任务中改变用户与 LLM 交互的能力。
- en: Usage Scenario
  id: totrans-92
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 使用场景
- en: Zoey, a college lecturer, would like to review her students’ performance across
    assignments to inform future teaching strategies. She opened WaitGPT, an LLM-powered
    conversational tool for data analysis that she was familiar with.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Zoey，一名大学讲师，希望回顾她学生在各项作业中的表现，以指导未来的教学策略。她打开了她熟悉的 LLM 驱动的数据分析对话工具 WaitGPT。
- en: 'WaitGPT’s interface resembles a chat box, allowing users to upload spreadsheets
    and inquire about the data in natural language ([Figure. 3](#S3.F3 "Figure 3 ‣
    3.3\. Design Considerations ‣ 3\. Formative Study ‣ WaitGPT: Monitoring and Steering
    Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization")).
    Upon uploading two spreadsheets — one detailing student profiles and the other
    their individual assignment scores — Zoey asks WaitGPT to compare the performance
    of students with different backgrounds. In response, WaitGPT outlines a plan to
    meet her requirements, then crafts a code snippet to conduct analysis. An external
    executor executes this code snippet to yield results.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 'WaitGPT 的界面类似于一个聊天框，允许用户上传电子表格并用自然语言查询数据（[图 3](#S3.F3 "Figure 3 ‣ 3.3\. Design
    Considerations ‣ 3\. Formative Study ‣ WaitGPT: Monitoring and Steering Conversational
    LLM Agent in Data Analysis with On-the-Fly Code Visualization")）。在上传两个电子表格——一个详细描述学生档案，另一个记录他们的个人作业成绩——后，Zoey
    请 WaitGPT 比较不同背景学生的表现。作为回应，WaitGPT 制定了一个满足她需求的计划，然后编写了一段代码片段进行分析。外部执行器执行此代码片段以生成结果。'
- en: 'Unlike similar tools, WaitGPT visualizes the data analysis process instead
    of just presenting raw code and textual execution results ([Figure. 3](#S3.F3
    "Figure 3 ‣ 3.3\. Design Considerations ‣ 3\. Formative Study ‣ WaitGPT: Monitoring
    and Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization")
    A). It dynamically extracts data operations and presents them as nodes within
    a diagram illustrating the data flow. For instance, a “join” operation node would
    display as “merge”. And the node shows the tables being joined, the type of join
    (e.g., left join, cross join, etc.), and the indexing column used for the join.
    These blocks are linked based on dependencies and posited from left to right to
    reflect the procedural order. Notably, WaitGPT breaks down the analysis script
    into executable blocks that are executed immediately instead of executing until
    the entire code snippet is ready. This allows for a progressive understanding
    and debugging process, enabling users to see the effects of each operation in
    real time. The tool also visualizes the runtime state of data tables (e.g., the
    number of data entries/columns, selected columns) as part of the diagram. Specifically,
    the runtime state of each table is visualized as glyphs, which move along the
    linked edges between operation objects.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '与类似工具不同，WaitGPT 可视化数据分析过程，而不仅仅是展示原始代码和文本执行结果（[图 3](#S3.F3 "Figure 3 ‣ 3.3\.
    Design Considerations ‣ 3\. Formative Study ‣ WaitGPT: Monitoring and Steering
    Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization")
    A）。它动态提取数据操作，并将其呈现为图示中的节点，显示数据流。例如，一个“join”操作节点将显示为“merge”。节点展示了被联接的表、联接类型（例如，左联接、交叉联接等）以及用于联接的索引列。这些块根据依赖关系连接，并从左到右排列以反映过程顺序。值得注意的是，WaitGPT
    将分析脚本拆分为立即执行的可执行块，而不是等到整个代码片段准备好才执行。这允许逐步理解和调试过程，使用户能够实时查看每个操作的效果。该工具还将数据表的运行时状态（例如，数据条目/列的数量、选择的列）可视化为图示的一部分。具体而言，每个表的运行时状态被可视化为符号，这些符号沿着操作对象之间的连接边缘移动。'
- en: 'Through the visual representation, Zoey quickly spots a flaw in the diagram—the
    row number reduces ([Figure. 3](#S3.F3 "Figure 3 ‣ 3.3\. Design Considerations
    ‣ 3\. Formative Study ‣ WaitGPT: Monitoring and Steering Conversational LLM Agent
    in Data Analysis with On-the-Fly Code Visualization") B). Rather than requiring
    rewriting the original query and regenerating the entire data analysis code, WaitGPT
    enables users to refine specific operations directly within the visualizations.
    Users can directly update its parameters, inquire about details, and indicate
    refinement intents through natural language. Thus, Zoey adjusts the join parameters
    to student IDs, and then clicks on the re-run button to execute the updated code.
    While the analysis goes on, Zoey inspects the table. She requests the LLM to clean
    the data. The diagram updates, reflecting the corrected scores after the agent
    integrates a data validation operation. Now Zoey is ready to analyze the reliable
    data, her teaching plans are secure on a foundation of accuracy.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '通过可视化表示，Zoey 快速发现了图示中的一个缺陷——行号减少了（[图 3](#S3.F3 "Figure 3 ‣ 3.3\. Design Considerations
    ‣ 3\. Formative Study ‣ WaitGPT: Monitoring and Steering Conversational LLM Agent
    in Data Analysis with On-the-Fly Code Visualization") B）。WaitGPT 使用户能够直接在可视化中细化特定操作，而不是要求重写原始查询并重新生成整个数据分析代码。用户可以直接更新其参数、询问细节，并通过自然语言表示细化意图。因此，Zoey
    将联接参数调整为学生 ID，然后点击重新运行按钮以执行更新后的代码。在分析进行时，Zoey 检查表格。她请求 LLM 清理数据。图示更新，反映了代理整合数据验证操作后的修正得分。现在
    Zoey 已准备好分析可靠的数据，她的教学计划建立在准确性的基础上。'
- en: '5\. WaitGPT: System Design'
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. WaitGPT：系统设计
- en: 'The design of WaitGPT consists of three major components: abstracting the code
    to data operation chains, visualizing these chains, and providing interactions
    to steer the analysis process.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: WaitGPT 的设计包括三个主要组件：将代码抽象为数据操作链、可视化这些链条，以及提供互动以引导分析过程。
- en: 5.1\. Abstracting Code to Operation Chains
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1\. 将代码抽象为操作链
- en: 'Based on the interview, we identified three types of information indispensable
    for code comprehension: table variables, data operations, and execution results.
    In addition, different data operations encapsulate dedicated semantics and independent
    parameters. Therefore, we opt to abstract a data analysis process into a graph
    structure, chaining its nodes with an input-output relationship as follows (DC1).
    The input of each data operation is table(s), whereas the output can be the updated
    table, new table(s), other derived values/visualizations, or none.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 基于访谈，我们识别出三种对代码理解至关重要的信息：表变量、数据操作和执行结果。此外，不同的数据操作封装了专用的语义和独立的参数。因此，我们选择将数据分析过程抽象成图结构，通过输入输出关系将其节点链在一起（DC1）。每个数据操作的输入是表，而输出可以是更新后的表、新的表、其他派生值/可视化，或者没有。
- en: $\ast$
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\ast$
- en: 'Table node: A table node corresponds to a variable for an underlying table
    in the code, such as a dataframe in the Pandas package. It can be either loaded
    from a data file or dynamically generated during code execution as an interim
    variable.'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 表节点：表节点对应于代码中底层表的变量，例如Pandas包中的数据框。它可以是从数据文件加载的，或者在代码执行期间动态生成的临时变量。
- en: $\ast$
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\ast$
- en: 'Operation node: An operation node ties to an atomic data operation. It surfaces
    the detailed parameters of an operation object, e.g.,,  Select ,  Filter , and
     Sort .'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 操作节点：操作节点与原子数据操作相关联。它显示了操作对象的详细参数，例如，Select、Filter和Sort。
- en: $\ast$
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\ast$
- en: 'Result node: A result node is associated with an execution result, such as
    printed values or data visualization.'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果节点：结果节点与执行结果相关联，例如打印值或数据可视化。
- en: 'Additionally, the relationship between these nodes can be one of the following:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，这些节点之间的关系可以是以下之一：
- en: $\ast$
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\ast$
- en: 'Input: From table node(s) to an operation node. It means the data operation
    is based on the input table(s).'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输入：从表节点到操作节点。这意味着数据操作是基于输入表进行的。
- en: $\ast$
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\ast$
- en: 'Assignment: From an operation node to a new table node. It means a new table-typed
    variable is yielded from the operation.'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 分配：从操作节点到新表节点。这意味着从操作中产生了一个新的表类型变量。
- en: $\ast$
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\ast$
- en: 'Result generation: From an operation node to a result node. It means the operation
    outputs some visible results.'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果生成：从操作节点到结果节点。这意味着操作输出了一些可见的结果。
- en: $\ast$
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\ast$
- en: 'Operation chain: From an operation node to an operation node. It means a table
    undergoes the two operations sequentially.'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 操作链：从操作节点到操作节点。这意味着一个表经历了两个操作的顺序。
- en: Extracting the Nodes through Static Analysis.
  id: totrans-116
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 通过静态分析提取节点。
- en: To extract these nodes and relationships, we perform static analysis on the
    abstract syntax tree (AST) of the generated code, where we apply heuristics informed
    by patterns of data analysis scripts and functional interface design of relevant
    packages. WaitGPT currently can parse atomic operations including  Load Data ,
     Inspect ,  Select ,  Filter ,  Sort ,  Transform ,  Group ,  Aggregate ,  Merge ,
     Add
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提取这些节点和关系，我们对生成代码的抽象语法树（AST）执行静态分析，其中应用了由数据分析脚本模式和相关包的功能接口设计提供的启发式方法。WaitGPT目前可以解析包括Load
    Data、Inspect、Select、Filter、Sort、Transform、Group、Aggregate、Merge、Add在内的原子操作。
- en: 'Column , and  Visualize , based on the Pandas, Matplotlib, and Seaborn packages,
    which are the default choices of ChatGPT and widely adopted (Chen et al., [2024b](#bib.bib7)).
    For instance, merge_df  =  df[["attr_1",  "attr_2"]].sort() will be converted
    into two operation objects:  Select  and  Sort . To bind the table targets to
    the operations, we maintain a global variable of existing table variables. This
    is because a table variable can only be created by being loaded from external
    sources (files, database, etc.) or generated as the output of prior operations.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Column、Visualize，基于Pandas、Matplotlib和Seaborn包，它们是ChatGPT的默认选择，并广泛应用（Chen et
    al., [2024b](#bib.bib7)）。例如，merge_df = df[["attr_1", "attr_2"]].sort() 将被转换为两个操作对象：Select和Sort。为了将表目标绑定到操作中，我们维护一个现有表变量的全局变量。这是因为表变量只能通过从外部来源（文件、数据库等）加载或作为先前操作的输出生成。
- en: 5.2\. Visualizing Data Operation Chains
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2\. 数据操作链的可视化
- en: Our goal is to transform the LLM-generated code into easily interpretable visualizations,
    facilitating user inspection of the data analysis process (DC2). To this end,
    we have developed a suite of visual primitives, which present the details of each
    operation and their internal runtime states. These primitives are chained together,
    collectively offering an overview of the data analysis process.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是将LLM生成的代码转换为易于解读的可视化，以便用户检查数据分析过程（DC2）。为此，我们开发了一套可视化原语，这些原语展示了每个操作的细节及其内部运行状态。这些原语被串联在一起，共同提供了数据分析过程的概述。
- en: Visual primitives for the static code
  id: totrans-121
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 静态代码的可视化原语
- en: We utilize a diagram to represent the graph-based data processing procedure
    for individual code snippets. The table node, operation node, and result node
    are visualized as blocks, color-encoded in yellow, pink, and white. A node-style
    visualization is chosen for its familiarity to general users (DC2) and flexibility
    in displaying layered information, expanding with the code stream, and implying
    the operation order (DC4). As LLMs sometimes synthesize long variable names for
    clarification, we considered a rectangular block beneficial for encapsulating
    this information. For simplicity, a table node only shows the corresponding variable
    name, and a result node shows a thumbnail. For an operation node, we use a bold
    font style to prioritize the communication of its type (e.g., filter, group, etc.).
    And we visually differentiate its parameters’ names and values through typography.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们利用图表表示单个代码片段的基于图形的数据处理过程。表格节点、操作节点和结果节点被可视化为块，并分别以黄色、粉色和白色进行编码。选择节点样式是因为它对普通用户较为熟悉（DC2），并且在显示分层信息、随代码流展开以及暗示操作顺序方面具有灵活性（DC4）。由于LLM有时会合成长变量名以便于理解，我们认为矩形块有助于封装这些信息。为了简洁，表格节点仅显示相应的变量名，结果节点显示缩略图。对于操作节点，我们使用**粗体**字体样式来优先传达其类型（例如，筛选、分组等）。并通过排版**视觉区分**其参数的名称和值。
- en: An operation chain spans from top to bottom, following its procedure. For a
    table node, there can be multiple associated operation chains. These chains are
    aligned from left to right with respect to the execution order. A code snippet
    depends on preexisting code as the runtime environment is shared throughout a
    conversation. Therefore, a table node may trace back to previous snippets. To
    reflect such a relationship, a copy is made in such a situation, which is linked
    to its previous occurrence with a cross-conversation curve.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 一个操作链从上到下展开，遵循其过程。对于一个表格节点，可能会有多个相关的操作链。这些链根据执行顺序从左到右对齐。代码片段依赖于现有的代码，因为运行时环境在整个对话中是共享的。因此，表格节点可能会追溯到以前的片段。为反映这种关系，在这种情况下会创建一个副本，并通过跨对话曲线链接到其先前的出现。
- en: Visual primitives for the runtime states
  id: totrans-124
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 运行状态的可视化原语
- en: The diagram is further enriched by visual glyphs that encode the runtime status
    of table variables. A table glyph takes a common visual representation for tables—a
    2D matrix. The number of matrix columns is the same as the column number of the
    table. The number of matrix rows per column is proportional to the number of table
    rows to roughly indicate changes in data size and scale to different data sizes.
    To access precise information about the runtime states, one may interact with
    the associated operation node for details. Through chained operations, the size
    of a table can be updated.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 该图表通过可视化符号进一步丰富，这些符号编码了表变量的运行状态。表符号采用表格的常见可视化表示形式——一个二维矩阵。矩阵列的数量与表格的列数相同。每列的矩阵行数与表格的行数成比例，以大致指示数据大小和不同数据规模的变化。要获取有关运行状态的精确信息，可以与相关的操作节点进行交互。通过链式操作，可以更新表格的大小。
- en: 5.3\. Steering the Data Analysis of LLMs
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3\. 驾驶LLM的数据分析
- en: The diagram goes beyond merely a visual representation of the data analysis
    process. It also acts as an interactive scaffold for users to steer data analysis
    code generated by LLMs, enabling real-time inspection, retrospective examination,
    and granular refinement (DC3). This section introduces interactions supported
    in WaitGPT.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 该图表不仅仅是数据分析过程的可视化表示。它还充当了一个互动的支架，帮助用户引导LLM生成的数据分析代码，实现实时检查、回顾性检查和精细化调整（DC3）。本节介绍了WaitGPT中支持的交互。
- en: 5.3.1\. Real-Time Inspection on the underlying code
  id: totrans-128
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.1\. 实时检查基础代码
- en: 'During code generation, only the diagram is shown to reduce the cognitive load
    of end users. However, they may still toggle on the code panel and juxtapose the
    diagram side-by-side. When a data operation is being activated, i.e., the external
    executor has just run the code, it will be added to the diagram, potentially introducing
    a new table node or a result node. Meanwhile, relevant table glyphs also appear
    and gradually flow from the previous node to the current node. [Figure. 4](#S5.F4
    "Figure 4 ‣ 5.3.1\. Real-Time Inspection on the underlying code ‣ 5.3\. Steering
    the Data Analysis of LLMs ‣ 5\. WaitGPT: System Design ‣ WaitGPT: Monitoring and
    Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization")
    showcases an example of the dynamic process.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '在代码生成过程中，仅显示图表以减少最终用户的认知负担。然而，他们仍然可以切换到代码面板，并将图表并排对比。当数据操作被激活时，即外部执行器刚刚运行代码，它会被添加到图表中，可能会引入一个新的表节点或结果节点。同时，相关的表符也会出现，并逐渐从前一个节点流向当前节点。
    [图 4](#S5.F4 "图 4 ‣ 5.3.1\. 对底层代码的实时检查 ‣ 5.3\. 引导 LLM 数据分析 ‣ 5\. WaitGPT: 系统设计
    ‣ WaitGPT: 通过实时代码可视化监控和引导对话 LLM 代理的数据分析") 展示了动态过程的一个例子。'
- en: '![Refer to caption](img/5ef278c4e4f33a9576eef7904a4aa6df.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/5ef278c4e4f33a9576eef7904a4aa6df.png)'
- en: Figure 4\. An illustration of how the diagram grows with animated table glyphs
    during the code generation process.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4\. 代码生成过程中，图表如何随着动画表符的增长进行说明。
- en: \Description
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: \Description
- en: Figure 4 uses four subfigures to demonstrate animated keyframes of a flow diagram
    during code generation. The first subfigure shows that two datasets are loaded.
    The second subfigure shows the two datasets being merged based on a mutual column
    named ”id”. The third subfigure shows the merged dataset, highlighting the animated
    effect. The last subfigure shows that a new data frame named ”merge_data” is created.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4 使用了四个子图来展示代码生成期间流图的动画关键帧。第一个子图显示两个数据集被加载。第二个子图显示两个数据集根据一个名为“id”的共同列进行合并。第三个子图展示了合并后的数据集，突出显示了动画效果。最后一个子图显示了一个名为“merge_data”的新数据框被创建。
- en: 5.3.2\. Retrospective Investigation on the analysis process
  id: totrans-134
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.2\. 对分析过程的回顾性调查
- en: 'After the code and diagram are completely generated, users may perform a retrospective
    examination to verify the procedure and investigate potential issues. To evaluate
    the analysis flow, users may replay the animation showing diagram expansion or
    utilize scrolly-telling, where they can take control over the animation progress
    using scroll-based interactions (DC4). If the code panel is toggled on, the corresponding
    line(s) of code will be highlighted for activated nodes upon re-play or the user’s
    mouse hover events (see [Figure. 5](#S5.F5 "Figure 5 ‣ 5.3.3\. Granular Refinement
    ‣ 5.3\. Steering the Data Analysis of LLMs ‣ 5\. WaitGPT: System Design ‣ WaitGPT:
    Monitoring and Steering Conversational LLM Agent in Data Analysis with On-the-Fly
    Code Visualization") A). This feature bridges the visual representation and the
    textual code, visual navigation and troubleshooting. Essentially, nodes in a diagram
    are visually displayed in the simplest way to support fast comprehension. To access
    details about the underlying data tables in the runtime context, users may click
    on a node of interest and review an additional panel (see [Figure. 5](#S5.F5 "Figure
    5 ‣ 5.3.3\. Granular Refinement ‣ 5.3\. Steering the Data Analysis of LLMs ‣ 5\.
    WaitGPT: System Design ‣ WaitGPT: Monitoring and Steering Conversational LLM Agent
    in Data Analysis with On-the-Fly Code Visualization") B). The thumbnail of a visualization
    result node is expandable (see [Figure. 5](#S5.F5 "Figure 5 ‣ 5.3.3\. Granular
    Refinement ‣ 5.3\. Steering the Data Analysis of LLMs ‣ 5\. WaitGPT: System Design
    ‣ WaitGPT: Monitoring and Steering Conversational LLM Agent in Data Analysis with
    On-the-Fly Code Visualization") E).'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '在代码和图表完全生成后，用户可以进行回顾性检查，以验证过程并调查潜在问题。为了评估分析流程，用户可以重放展示图表扩展的动画，或利用滚动讲述功能，通过基于滚动的互动来控制动画进度（DC4）。如果代码面板被启用，激活节点的相应代码行将在重放或用户的鼠标悬停事件时被高亮显示（见
    [图. 5](#S5.F5 "Figure 5 ‣ 5.3.3\. Granular Refinement ‣ 5.3\. Steering the Data
    Analysis of LLMs ‣ 5\. WaitGPT: System Design ‣ WaitGPT: Monitoring and Steering
    Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization")
    A）。该功能连接了视觉表示和文本代码，视觉导航和故障排除。本质上，图表中的节点以最简单的方式进行可视化显示，以支持快速理解。要访问运行时上下文中有关底层数据表的详细信息，用户可以点击感兴趣的节点，并查看附加面板（见
    [图. 5](#S5.F5 "Figure 5 ‣ 5.3.3\. Granular Refinement ‣ 5.3\. Steering the Data
    Analysis of LLMs ‣ 5\. WaitGPT: System Design ‣ WaitGPT: Monitoring and Steering
    Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization")
    B）。可视化结果节点的缩略图是可展开的（见 [图. 5](#S5.F5 "Figure 5 ‣ 5.3.3\. Granular Refinement ‣
    5.3\. Steering the Data Analysis of LLMs ‣ 5\. WaitGPT: System Design ‣ WaitGPT:
    Monitoring and Steering Conversational LLM Agent in Data Analysis with On-the-Fly
    Code Visualization") E）。'
- en: 5.3.3\. Granular Refinement
  id: totrans-136
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.3\. 精细化调整
- en: 'The diagram offers new interaction modes for granular refinement through direct
    manipulation and contextual interrogation. Instead of regenerating the entire
    analysis, which may involve multiple code snippets, users can steer the data analysis
    at a finer granularity within the visualization (DC3). Users may directly manipulate
    the operation objects based on their visual representation and update the underlying
    code (see [Figure. 5](#S5.F5 "Figure 5 ‣ 5.3.3\. Granular Refinement ‣ 5.3\. Steering
    the Data Analysis of LLMs ‣ 5\. WaitGPT: System Design ‣ WaitGPT: Monitoring and
    Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization")
    D). The fields of parameters in operation nodes are editable input forms, allowing
    fine-grain updates.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '图表提供了通过直接操作和上下文查询进行精细化调整的新交互模式。用户无需重新生成整个分析（这可能涉及多个代码片段），即可在可视化中以更细粒度控制数据分析（DC3）。用户可以基于可视化表示直接操作对象，并更新底层代码（见
    [图. 5](#S5.F5 "Figure 5 ‣ 5.3.3\. Granular Refinement ‣ 5.3\. Steering the Data
    Analysis of LLMs ‣ 5\. WaitGPT: System Design ‣ WaitGPT: Monitoring and Steering
    Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization")
    D）。操作节点中的参数字段是可编辑的输入表单，允许进行细粒度更新。'
- en: 'Similar to the concept of interrogative debugging (Ko and Myers, [2004](#bib.bib31)),
    users can select specific operation nodes within the diagram and then request
    explanations or suggest revisions to the LLM by focusing on a particular node,
    which offers a targeted context for verification and refinement ([Figure. 5](#S5.F5
    "Figure 5 ‣ 5.3.3\. Granular Refinement ‣ 5.3\. Steering the Data Analysis of
    LLMs ‣ 5\. WaitGPT: System Design ‣ WaitGPT: Monitoring and Steering Conversational
    LLM Agent in Data Analysis with On-the-Fly Code Visualization") C). This provides
    an alternative mode to the common practice of selecting code or table cells and
    posting queries to LLMs (Nam et al., [2024](#bib.bib44)). Inspired by the regeneration
    practice of participants in the formative study, the query is independent of the
    main conversation and, thus, will not affect the memory of LLM agents. The LLM’s
    suggestion of code update will directly apply to the code panel, and the previous
    version will be commented out for comparison. When satisfied with the refinement,
    users can re-run the code snippet to attain updated analysis from LLM agents based
    on the new execution results.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '类似于**Ko**和**Myers**在[2004](#bib.bib31)年提出的质询调试概念，用户可以选择图示中的特定操作节点，然后请求解释或建议对LLM进行修订，通过专注于特定节点来提供有针对性的验证和完善背景（[图5](#S5.F5
    "Figure 5 ‣ 5.3.3\. Granular Refinement ‣ 5.3\. Steering the Data Analysis of
    LLMs ‣ 5\. WaitGPT: System Design ‣ WaitGPT: Monitoring and Steering Conversational
    LLM Agent in Data Analysis with On-the-Fly Code Visualization") C）。这提供了一种与常见的选择代码或表单单元格并向LLM提出查询的做法不同的模式（**Nam**等，[2024](#bib.bib44)）。受到形成性研究中参与者再生实践的启发，查询独立于主要对话，因此不会影响LLM代理的记忆。LLM的代码更新建议将直接应用于代码面板，之前的版本将被注释掉以供比较。当对改进感到满意时，用户可以重新运行代码片段，以根据新的执行结果从LLM代理获得更新的分析。'
- en: '![Refer to caption](img/6ca042b94738e6e4dfd9c3580c631aa1.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/6ca042b94738e6e4dfd9c3580c631aa1.png)'
- en: 'Figure 5\. The visualization offers multiple interactions for inspecting and
    refining the underlying data analysis. Users can: (A) toggle a table node to view
    the underlying data; (B) hover over a node to highlight its corresponding code;
    (C) modify a data operation using natural language; (D) directly manipulate the
    parameters of a node; and (E) view the resulting visualizations from the analysis.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图5。可视化提供了多种交互方式来检查和完善基础数据分析。用户可以：（A）切换表节点以查看基础数据；（B）悬停在节点上以突出显示其对应的代码；（C）使用自然语言修改数据操作；（D）直接操作节点的参数；（E）查看分析结果的可视化效果。
- en: \Description
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: \描述
- en: 'Figure 5 contains three components: the flow diagram on the left, the associated
    code on the top right, and the legend on the bottom right. The analysis diagram
    on the left shows code execution linked to visual elements. ”A” marks the initial
    table node, splitting into two paths: Path one goes to a group operation node,
    then to a plot line operation node, and finally to a line chart. A hand icon at
    the group operation node prompts a ”Why?” inquiry labeled ”C”. Path two leads
    to a ”Filter” operation node, a ”new_data” table node, and then to a ”Plot Bar”
    operation node, resulting in a bar chart. A line from the ”Filter” node to a specific
    line in the code is labeled ”B”. In the ”Plot Bar” node, a dropdown menu with
    a cursor clicking on it is shown, labeled ”D”. A magnifier icon next to the bar
    chart indicates an interactive feature labeled ”E”.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图5包含三个组件：左侧的流程图，右上角的相关代码，以及右下角的图例。左侧的分析图显示了与视觉元素相关联的代码执行。 “A”标记了初始表节点，分为两条路径：路径一到达一个组操作节点，然后是一个绘图线操作节点，最后到达一个折线图。在组操作节点处的手形图标提示了一个标记为“C”的“为什么？”询问。路径二到达一个“过滤”操作节点，一个“new_data”表节点，然后到达一个“绘制条形图”操作节点，最终生成一个条形图。从“过滤”节点到代码中特定行的线标记为“B”。在“绘制条形图”节点处，显示了一个带光标点击的下拉菜单，标记为“D”。在条形图旁边的放大镜图标表示一个标记为“E”的交互特性。
- en: 6\. Implementation
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 实施
- en: WaitGPT is a web-based app implemented in the React (Meta Open Source, [2024](#bib.bib41))
    framework based on TypeScript. We apply the Monaco Editor (Microsoft, [2024](#bib.bib42))
    to display the code with standard syntax highlighting. We adopt the OpenAI’s API,
    with the gpt-4-0125-preview model. To manage user-uploaded files, parse LLM-synthesized
    code into an abstract syntax tree, and obtain its execution result, we also host
    a back-end server implemented in Python with Flask (Pallets, [2024](#bib.bib49)).
    The LLM prompts applied in WaitGPT generally follow the guidance of OpenAI with
    little engineering effort. Our implementation integrates three key mechanisms
    as follows.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: WaitGPT 是一个基于 TypeScript 实现的 React（Meta 开源，[2024](#bib.bib41)）框架的 web 应用。我们使用
    Monaco 编辑器（Microsoft，[2024](#bib.bib42)）来显示具有标准语法高亮的代码。我们采用 OpenAI 的 API，使用 gpt-4-0125-preview
    模型。为了管理用户上传的文件，将 LLM 合成的代码解析为抽象语法树，并获取其执行结果，我们还托管了一个基于 Python 和 Flask（Pallets，[2024](#bib.bib49)）实现的后端服务器。WaitGPT
    中使用的 LLM 提示通常遵循 OpenAI 的指导，工程工作量较小。我们的实现集成了以下三种关键机制。
- en: Session Management
  id: totrans-145
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 会话管理
- en: In addition to the conversation history for each session, WaitGPT maintains
    other contexts to support diagram generation on the fly and granular refinement.
    The associated contexts include a sandbox environment for file storage and code
    execution, a global record of table variables, and specifications of the diagram
    for each data analysis code snippet. In addition to the parsed parameters, the
    runtime status of target tables, and rendering configurations, the specification
    of a data operation node in a diagram also records conversation logs with the
    LLMs based on the code to support iterative refinement.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 除了每个会话的对话历史，WaitGPT 还维护其他上下文以支持即时图表生成和细粒度改进。相关上下文包括用于文件存储和代码执行的沙箱环境、表变量的全局记录以及每个数据分析代码片段的图表规范。除了解析的参数、目标表的运行时状态和渲染配置之外，图表中的数据操作节点的规范还记录了与
    LLM 基于代码的对话日志，以支持迭代改进。
- en: When a user sends a query, the LLM will respond with textual contents or a function
    call to the pre-declared Python executable. For code-based response, WaitGPT first
    decides whether it is about data analysis and then activates the automatic parser.
    The runtime context for each code snippet is cloned from the main process and
    cached for potential rework, thus enabling flexible user interruptions and refinement
    at any point. We enhance user navigation by prompting LLM to summarize the main
    task and build a minimap for existing data analysis snippets.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户发送查询时，LLM 会回应文本内容或调用预先声明的 Python 可执行文件。对于基于代码的响应，WaitGPT 首先判断是否涉及数据分析，然后激活自动解析器。每个代码片段的运行时上下文从主进程中克隆并缓存以备潜在的重新处理，从而实现灵活的用户中断和任何时刻的改进。我们通过提示
    LLM 总结主要任务并为现有数据分析片段构建迷你地图来增强用户导航。
- en: Sandbox Execution
  id: totrans-148
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 沙箱执行
- en: Before running the code in a sandbox environment, WaitGPT refactors the method
    chain into separate standalone statements. Therefore, based on the identified
    targets (i.e., table variables) of data operations, the static parser inserts
    printing statements based on templates to retrieve the intermediate status of
    the table, including the number of rows, the number of columns, and column names.
    The table status is then bonded to the corresponding data operation object. As
    a note, we opt to insert code to the LLM-generated script in a post hoc manner
    to reduce dependency on specific versions. An alternative approach is to inject
    logging facilities into the standard libraries (Pu et al., [2021](#bib.bib51);
    Shrestha et al., [2021](#bib.bib56)).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在沙箱环境中运行代码之前，WaitGPT 将方法链重构为独立的单独语句。因此，基于识别出的数据操作目标（即，表变量），静态解析器根据模板插入打印语句，以检索表的中间状态，包括行数、列数和列名。表状态随后被绑定到相应的数据操作对象。需要注意的是，我们选择以事后插入代码的方式来减少对特定版本的依赖。另一种方法是将日志功能注入到标准库中（Pu
    等，[2021](#bib.bib51)；Shrestha 等，[2021](#bib.bib56)）。
- en: Rendering
  id: totrans-150
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 渲染
- en: The rendering of the flow diagram comprises two steps. Once the static analyzer
    extracts new data operation objects, they will be added to the diagram using a
    graph layout algorithm and maintain inactivated status. When the runtime information
    is bound to the operation object, its animated effect is pushed to a queue to
    play sequentially, where the corresponding node will be activated and the table
    glyph will flow from the prior node to the current node.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 流程图的渲染包括两个步骤。一旦静态分析器提取出新的数据操作对象，它们将通过图布局算法添加到图中并保持未激活状态。当运行时信息绑定到操作对象时，其动画效果将被推送到队列中顺序播放，相应的节点将被激活，表格符号将从前一个节点流向当前节点。
- en: 7\. User Evaluation
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 用户评价
- en: We evaluate WaitGPT through an in-lab user study with 12 participants of various
    backgrounds and data analysis expertise. Specifically, we are interested in the
    following research questions.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过在实验室进行的用户研究来评估 WaitGPT，参与者有 12 位，背景和数据分析专长各异。具体而言，我们对以下研究问题感兴趣。
- en: •
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: How effectively does WaitGPT facilitate intermediate verification during the
    generation process of LLM agents?
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: WaitGPT 在生成 LLM 代理的过程中如何有效地促进中间验证？
- en: •
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: How effectively does WaitGPT support retrospective verification after data analysis
    tasks are completed?
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: WaitGPT 在数据分析任务完成后，如何有效地支持回溯验证？
- en: •
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: To what extent does WaitGPT support the granular refinement of generated code
    snippets?
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: WaitGPT 在多大程度上支持对生成的代码片段进行细粒度的改进？
- en: •
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: How do users perceive the usefulness of WaitGPT in their daily data analysis
    tasks?
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用户如何看待 WaitGPT 在日常数据分析任务中的有用性？
- en: 'Table 2\. The success rate (%) and average duration (seconds) in WaitGPT and
    Baseline for Task A & Task B (N=6/condition). The failure column describes the
    mistake made by LLMs in the task. #Line: No. lines in the code snippet; #Char:
    No. characters. #Df: No. table nodes in the data operation chains, #Op: No. operation
    nodes, #Res: No. result nodes. “(Value)”: standard deviance.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '表 2\. WaitGPT 和基线在任务 A 和任务 B 中的成功率 (%) 和平均持续时间（秒）（N=6/条件）。失败列描述 LLM 在任务中犯的错误。#Line:
    代码片段中的行数；#Char: 字符数。#Df: 数据操作链中的表节点数，#Op: 操作节点数，#Res: 结果节点数。“（值）”：标准差。'
- en: '| Task | Failure | #Line | #Char | #Df | #Op | #Res | Success (%) | Average
    Duration (s) |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | 失败 | #Line | #Char | #Df | #Op | #Res | 成功率 (%) | 平均持续时间 (s) |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| WaitGPT | Baseline | WaitGPT | Baseline |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| WaitGPT | 基线 | WaitGPT | 基线 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| A1 | Sort on string | 14 | 474 | 2 | 5 | 0 | 83 (0.41) | 33 (0.52) | 65.83
    (45.32) | 136.67 (88.69) |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| A1 | 按字符串排序 | 14 | 474 | 2 | 5 | 0 | 83 (0.41) | 33 (0.52) | 65.83 (45.32)
    | 136.67 (88.69) |'
- en: '| A2 | Miss a group condition | 5 | 233 | 2 | 3 | 0 | 50 (0.55) | 50 (0.55)
    | 88.33 (40.21) | 102.50 (68.68) |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| A2 | 漏掉分组条件 | 5 | 233 | 2 | 3 | 0 | 50 (0.55) | 50 (0.55) | 88.33 (40.21)
    | 102.50 (68.68) |'
- en: '| A3 | NA | 47 | 1,836 | 5 | 10 | 1 | 100 (0.00) | 100 (0.00) | 154.00 (103.00)
    | 151.67 (143.69) |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| A3 | NA | 47 | 1,836 | 5 | 10 | 1 | 100 (0.00) | 100 (0.00) | 154.00 (103.00)
    | 151.67 (143.69) |'
- en: '| A4 | Miss a filter condition | 10 | 509 | 3 | 4 | 0 | 67 (0.52) | 83 (0.41)
    | 86.67 (18.62) | 92.50 (34.31) |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| A4 | 漏掉过滤条件 | 10 | 509 | 3 | 4 | 0 | 67 (0.52) | 83 (0.41) | 86.67 (18.62)
    | 92.50 (34.31) |'
- en: '| A5 | Miss dropping duplicates | 24 | 780 | 1 | 5 | 1 | 50 (0.06) | 50 (0.55)
    | 92.50 (58.37) | 87.50 (27.34) |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| A5 | 漏掉重复项 | 24 | 780 | 1 | 5 | 1 | 50 (0.06) | 50 (0.55) | 92.50 (58.37)
    | 87.50 (27.34) |'
- en: '| A6 | NA | 21 | 817 | 1 | 3 | 1 | 100 (0.10) | 100 (0.00) | 144.17 (69.02)
    | 95.83 (22.45) |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| A6 | NA | 21 | 817 | 1 | 3 | 1 | 100 (0.10) | 100 (0.00) | 144.17 (69.02)
    | 95.83 (22.45) |'
- en: '| B1 | NA | 29 | 1,167 | 4 | 7 | 1 | 100 (0.00) | 83 (0.41) | 141.67 (49.97)
    | 160.00 (82.16) |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| B1 | NA | 29 | 1,167 | 4 | 7 | 1 | 100 (0.00) | 83 (0.41) | 141.67 (49.97)
    | 160.00 (82.16) |'
- en: '| B2 | Miss dropping duplicates | 25 | 1,287 | 5 | 6 | 1 | 67 (0.52) | 50 (0.55)
    | 242.50 (167.74) | 221.67 (159.80) |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| B2 | 漏掉重复项 | 25 | 1,287 | 5 | 6 | 1 | 67 (0.52) | 50 (0.55) | 242.50 (167.74)
    | 221.67 (159.80) |'
- en: '| B3 | NA | 25 | 1,262 | 4 | 6 | 1 | 100 (0.00) | 100 (0.00) | 185.00 (113.31)
    | 176.67 (64.94) |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| B3 | NA | 25 | 1,262 | 4 | 6 | 1 | 100 (0.00) | 100 (0.00) | 185.00 (113.31)
    | 176.67 (64.94) |'
- en: '| B4 | Wrong aggregation logic | 10 | 654 | 4 | 6 | 0 | 83 (0.41) | 83 (0.41)
    | 212.50 (145.87) | 138.50 (40.71) |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| B4 | 错误的聚合逻辑 | 10 | 654 | 4 | 6 | 0 | 83 (0.41) | 83 (0.41) | 212.50 (145.87)
    | 138.50 (40.71) |'
- en: \Description
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: \描述
- en: 'Table 2 is structured into eleven rows (one header row and ten tasks) and nine
    columns, providing a side-by-side comparison between WaitGPT and Baseline systems
    across ten tasks (A1-A6 and B1-B4). The header row outlines the column titles:
    ”Task” for task identifiers, ”Failure” detailing mistakes made by LLMs, ”#Line”
    for the number of code lines, ”#Char” for the character count, ”#Df” for the number
    of table nodes, ”#Op” for operation nodes, and ”#Res” for result nodes. The ”Success
    (%)” and ”Average Duration (s)” are split into two columns each to compare the
    performance of WaitGPT and Baseline. Standard deviations for success rates and
    average durations are provided in parentheses.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 表2分为十一行（一个标题行和十个任务行）和九列，提供了WaitGPT和基线系统在十个任务（A1-A6和B1-B4）之间的并排比较。标题行列出了列标题：“Task”表示任务标识符，“Failure”详细说明LLM所犯的错误，“#Line”表示代码行数，“#Char”表示字符数，“#Df”表示表格节点数，“#Op”表示操作节点数，“#Res”表示结果节点数。“Success
    (%)”和“Average Duration (s)”分别分为两列，以比较WaitGPT和基线的性能。成功率和平均时长的标准差以括号形式提供。
- en: 7.1\. Participants
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1\. 参与者
- en: 'We recruited 12 participants (10 males, 2 females; ages 23—30, M = 26.33, SD
    = 2.15) through social media and word-of-mouth. They were postgraduate students
    with diverse backgrounds in databases, machine learning, visual analytics, industrial
    engineering, computational sociology, and HCI. According to their self-rating
    based on a 5-point Likert scale (1: lowest extent, 5: greatest extent), participants
    were generally adept at data analysis (M = 3.67, SD = 1.37) and familiar with
    the Pandas syntax used in WaitGPT (M = 3.5, SD = 1.38). They were experienced
    with LLM-powered chatbots (M = 3.75, SD = 1.06). Specifically, 5/12 participants
    leveraged ChatGPT to analyze more than 20 datasets, whereas 4/12 analyzed less
    than 5 datasets on ChatGPT.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过社交媒体和口碑招募了12名参与者（10名男性，2名女性；年龄23—30岁，平均年龄 = 26.33，标准差 = 2.15）。他们是具有多样背景的研究生，背景包括数据库、机器学习、视觉分析、工业工程、计算社会学和人机交互。根据他们基于5分制李克特量表（1：最低程度，5：最高程度）的自我评估，参与者通常在数据分析方面表现出色（平均值
    = 3.67，标准差 = 1.37），对WaitGPT中使用的Pandas语法较为熟悉（平均值 = 3.5，标准差 = 1.38）。他们也有丰富的使用LLM驱动的聊天机器人经验（平均值
    = 3.75，标准差 = 1.06）。具体来说，5/12的参与者利用ChatGPT分析了超过20个数据集，而4/12的参与者在ChatGPT上分析了少于5个数据集。
- en: 7.2\. Protocol
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2\. 协议
- en: Tasks
  id: totrans-182
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 任务
- en: 'There are three tasks in total. Task A is based on the Employee dataset¹¹1[https://www.kaggle.com/datasets/soorajgupta7/corporate-compensation-insights](https://www.kaggle.com/datasets/soorajgupta7/corporate-compensation-insights)
    with six analysis tasks (A1–A6). Task B is based on the Flight dataset²²2[https://www.kaggle.com/datasets/shubhambathwal/flight-price-prediction](https://www.kaggle.com/datasets/shubhambathwal/flight-price-prediction)
    with four tasks (B1–B4). For Tasks A & B, the participants are required to address
    individual questions by interacting with LLMs and decide if the LLM-generated
    code is error-free. To cover representative cases, we included both confirmation
    and exploratory tasks on two tabular datasets and replicated 4 known errors made
    by LLMs (Gu et al., [2024c](#bib.bib20)). In addition, we prepared dedicated prompts
    for the participants to ensure that the first LLM-generated content was identical
    in each task. These prompts are grounded in the ARCADE (Yin et al., [2023](#bib.bib75))
    and Text2Analysis (He et al., [2024](#bib.bib24)) datasets. Each data analysis
    task is independent of the other, including common data insight types (Ding et al.,
    [2019](#bib.bib14)), e.g., rank, distribution, outlier, etc. Task C is based on
    the synthesized dataset used in the usage scenario (see [Sec. 4](#S4 "4\. WaitGPT:
    Usage Scenario ‣ WaitGPT: Monitoring and Steering Conversational LLM Agent in
    Data Analysis with On-the-Fly Code Visualization")), where participants were asked
    to explore the dataset freely. We also offer a list of self-curated queries for
    their reference.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '总共有三个任务。任务A基于[员工数据集](https://www.kaggle.com/datasets/soorajgupta7/corporate-compensation-insights)¹¹1，包含六个分析任务（A1–A6）。任务B基于[航班数据集](https://www.kaggle.com/datasets/shubhambathwal/flight-price-prediction)²²2，包含四个任务（B1–B4）。对于任务A和B，参与者需要通过与LLMs互动来解决单独的问题，并判断LLM生成的代码是否无误。为了覆盖代表性案例，我们包括了确认任务和探索任务，涉及两个表格数据集，并复制了LLMs已知的4个错误（Gu
    et al., [2024c](#bib.bib20)）。此外，我们为参与者准备了专门的提示，以确保每个任务中的首次LLM生成内容完全一致。这些提示基于ARCADE（Yin
    et al., [2023](#bib.bib75)）和Text2Analysis（He et al., [2024](#bib.bib24)）数据集。每个数据分析任务都是独立的，包括常见的数据洞察类型（Ding
    et al., [2019](#bib.bib14)），例如，排名、分布、离群值等。任务C基于在使用场景中使用的合成数据集（见[第4节](#S4 "4\.
    WaitGPT: 使用场景 ‣ WaitGPT: 监控和引导数据分析中的对话LLM代理与即时代码可视化")），参与者被要求自由探索数据集。我们还提供了一份自我策划的查询列表供他们参考。'
- en: Baseline and Apparatus
  id: totrans-184
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基线和设备
- en: We removed the extended view of the diagram as the baseline system, namely Baseline.
    Baseline retains essential functionalities of ChatGPT that the participants are
    familiar with. The code snippet offers by-line textual comments explaining each
    step for user verification and has standard syntax highlighting for Python. Meanwhile,
    Baseline shares the same visual appearance as WaitGPT. This ensures that any differences
    in user interaction can be attributed to the diagram’s presence or absence rather
    than other factors like aesthetics or layout. Participants joined the study in
    person and finished their tasks on standardized desktop devices to eliminate hardware
    variability as a confounding factor.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们移除了图表的扩展视图作为基线系统，即**基线**。基线保留了ChatGPT的基本功能，参与者对此非常熟悉。代码片段提供了逐行的文本注释，解释了每一步，以供用户验证，并对Python进行了标准语法高亮。同时，基线与WaitGPT具有相同的视觉外观。这确保了用户互动的任何差异可以归因于图表的存在或缺失，而不是其他因素，如美学或布局。参与者亲自参与了研究，并在标准化的桌面设备上完成任务，以消除硬件差异作为干扰因素。
- en: Procedure
  id: totrans-186
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 程序
- en: We opted for a counterbalanced within-subjects design to compare WaitGPT and
    Baseline. There are two groups (I, II) that participants were randomly assigned
    to. In Group I, participants finish A1-3 & B1-2 in Baseline, and A4-6 & B3-4 in
    WaitGPT. Conversely, in Group II, participants finish A1-3 & B1-2 in WaitGPT,
    and A4-6 & B3-4 in Baseline. This approach allowed each participant to experience
    both conditions while performing a balanced set of tasks across the two systems.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了一个平衡的被试内设计来比较WaitGPT和基线。参与者被随机分配到两个组（I组，II组）。在I组中，参与者在基线中完成A1-3和B1-2，在WaitGPT中完成A4-6和B3-4。相反，在II组中，参与者在WaitGPT中完成A1-3和B1-2，在基线中完成A4-6和B3-4。这种方法使每位参与者在执行平衡任务的同时，能够体验这两种条件。
- en: The user study begins with a presentation of the visualization and interaction
    design, where participants can ask for details (5 min). Then, the participant
    should work on Task A1-6 (15-30 min), Task B1-4 (10-20 min), and Task C (5-15
    min) sequentially. The study ends with a semi-structured interview (10-15 min)
    and a questionnaire (5 min). A facilitator conducted one-on-one sessions with
    each participant, closely observing and taking notes of participant behaviors.
    The post-study interview was audio-recorded for later analysis. Participants were
    compensated with $12 per hour.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 用户研究首先展示了可视化和交互设计，参与者可以询问细节（5分钟）。接着，参与者需依次完成任务A1-6（15-30分钟）、任务B1-4（10-20分钟）和任务C（5-15分钟）。研究以半结构化访谈（10-15分钟）和问卷调查（5分钟）结束。研究员与每位参与者进行了单独会话，密切观察并记录参与者行为。研究后的访谈进行了音频录音以便后续分析。参与者的报酬为每小时12美元。
- en: 7.3\. Measures
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3\. 测量
- en: We adopted the NASA-TLX (Hart and Staveland, [1988](#bib.bib23)) questionnaire
    to measure the perceived cognitive load in steering LLM-synthesized data analysis.
    We developed a questionnaire based on a 7-point Likert scale to evaluate the usefulness
    of WaitGPT. For each pre-recorded query, the facilitator records (1) the time
    cost that the participant discerns issues in the result since response generation,
    (2) the time cost that the participant makes a judgment on the correctness, (3)
    whether the data has been examined, and (4) whether the code panel is expanded
    when viewing diagrams only.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们采用了NASA-TLX（Hart和Staveland，[1988](#bib.bib23)）问卷来衡量对引导LLM合成数据分析的感知认知负荷。我们开发了一份基于7点Likert量表的问卷来评估WaitGPT的有用性。对于每个预先录制的查询，研究员记录（1）参与者从响应生成开始识别问题的时间成本，（2）参与者对正确性做出判断的时间成本，（3）数据是否已被检查，以及（4）查看图表时是否展开了代码面板。
- en: 7.4\. Results
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4\. 结果
- en: To compare Baseline and WaitGPT, we analyze task correctness for Task A & B
    and the subjective ratings of the participants. We further report insights from
    the interview,
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较基线和WaitGPT，我们分析了任务A和B的任务正确性以及参与者的主观评分。我们进一步报告了访谈中的见解，
- en: 7.4.1\. Task Correctness
  id: totrans-193
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.4.1\. 任务正确性
- en: '[Table 2](#S7.T2 "Table 2 ‣ 7\. User Evaluation ‣ WaitGPT: Monitoring and Steering
    Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization")
    lists detailed configurations and participant performance in Task A1-6 and B1-4.
    In general, the success rates in the WaitGPT condition are no less than the Baseline
    condition, except for A4. A4 asked for 10 employees with the highest salary currently,
    whereas LLM did not filter out those on leave. Many participants did not notice
    this problem in the response. As for the duration, the two conditions had similar
    time costs ($\leq$ 10s) for Task A3-5 and B3. And WaitGPT took less time in Task
    A1-2 and Task B. However, multiple factors are attributed to the total duration,
    as seen in the relatively large standard deviation values. For instance, we did
    not consider expertise in data analysis when assigning participants to different
    groups. When the participant chose to inspect the code after viewing the diagram,
    there was an additional time cost to browse the code.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '[表2](#S7.T2 "表 2 ‣ 7\. 用户评估 ‣ WaitGPT: 实时代码可视化中的对话LLM代理的监控和引导") 列出了任务A1-6和B1-4的详细配置和参与者表现。总体来说，WaitGPT条件下的成功率不低于基线条件，除了A4。A4要求当前薪水最高的10名员工，而LLM没有排除请假的员工。许多参与者没有注意到这个问题。就时长而言，两种条件下任务A3-5和B3的时间成本相似（$\leq$
    10秒）。WaitGPT在任务A1-2和任务B中耗时较少。然而，多个因素影响总时长，如相对较大的标准差值。例如，在分配参与者到不同组时，我们没有考虑数据分析的专业知识。当参与者选择在查看图表后检查代码时，还会有额外的时间成本用于浏览代码。'
- en: '![Refer to caption](img/0905da90c7a15ec2c86c32a4ac5a73db.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0905da90c7a15ec2c86c32a4ac5a73db.png)'
- en: Figure 6\. User ratings on the baseline (code-only interface) and WaitGPT.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 图6\. 基线（仅代码界面）和WaitGPT的用户评分。
- en: \Description
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: \说明
- en: Figure 6 shows a horizontal stacked bar chart comparing user responses for the
    Baseline and WaitGPT systems against six questions. The chart sequentially presents
    the questions on the left, the corresponding response bars for Baseline and then
    WaitGPT, and concludes with a legend on the right. The legend interprets the color
    gradient from dark red, indicating ”Strongly Disagree”, to dark blue for ”Strongly
    Agree.” Baseline”s bars are mostly red, suggesting neutral to negative responses.
    Meanwhile, WaitGPT”s bars are predominantly blue, showing a tendency towards agreement
    on usability.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6 显示了一个横向堆叠条形图，比较了基线和 WaitGPT 系统在六个问题上的用户响应。图表左侧依次展示了问题，接着是 Baseline 和 WaitGPT
    的对应响应条，最后以右侧的图例结束。图例解释了颜色渐变，从深红色（表示“强烈不同意”）到深蓝色（表示“强烈同意”）。Baseline 的条形图大多为红色，表示中性到负面回应。与此同时，WaitGPT
    的条形图主要为蓝色，显示出对可用性的一致认可倾向。
- en: 7.4.2\. Subjective Ratings
  id: totrans-199
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.4.2\. 主观评分
- en: As the questionnaires are based on an ordinal Likert scale and the sample size
    is relatively small, we performed the Wilcoxon signed-rank test to compare the
    subjective ratings between Baseline and WaitGPT.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 由于问卷基于有序的李克特量表，且样本量相对较小，我们进行了 Wilcoxon 符号秩检验，以比较基线（Baseline）和 WaitGPT 之间的主观评分。
- en: $\diamond$ On the cognitive load. In the NASA-TLX questionnaire, WaitGPT demonstrates
    lower cognitive demand to the participants. According to the statistical tests,
    there are highly significant differences (p¡.001) in the mental and physical demand,
    performance, and affective states between the two conditions. The difference in
    the effort to accomplish self-performance level (p=.010) and the temporal demand
    (p=.050) is also significant.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 关于认知负荷。在 NASA-TLX 问卷中，WaitGPT 向参与者展示了较低的认知需求。根据统计测试，两个条件之间的心理和身体需求、表现以及情感状态存在高度显著的差异（p¡.001）。完成自我表现水平的努力差异（p=.010）和时间需求（p=.050）也显著。
- en: '$\diamond$ On the usefulness. [Figure. 6](#S7.F6 "Figure 6 ‣ 7.4.1\. Task Correctness
    ‣ 7.4\. Results ‣ 7\. User Evaluation ‣ WaitGPT: Monitoring and Steering Conversational
    LLM Agent in Data Analysis with On-the-Fly Code Visualization") compares the distribution
    of the user ratings on Baseline and WaitGPT based on our self-developed questionnaire.
    For each question, WaitGPT attains a higher median rating than Baseline at a confidence
    level of 99.5%, demonstrating its usefulness in demystifying the analysis (Q1-3),
    verifying or correcting the code (Q4-5), and engaging end-users (Q6). Notably,
    while participants varied in task performance, 10/12 people reported increased
    confidence in the correctness of the analysis result (Q1). Besides, based on a
    7-point Likert scale (1: strongly disagree, 7: strongly agree), the participants
    considered it easy to comprehend the visualization design (Med=6.5, M=6.65, SD=.87)
    and interact with the diagram (Med=6.0, M=6.33, SD=.65).'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '$\diamond$ 关于有用性。[图 6](#S7.F6 "Figure 6 ‣ 7.4.1\. Task Correctness ‣ 7.4\.
    Results ‣ 7\. User Evaluation ‣ WaitGPT: Monitoring and Steering Conversational
    LLM Agent in Data Analysis with On-the-Fly Code Visualization") 比较了基于我们自开发问卷的
    Baseline 和 WaitGPT 用户评分的分布。在每个问题上，WaitGPT 的中位评分比 Baseline 高，置信水平为 99.5%，显示其在阐明分析（Q1-3）、验证或纠正代码（Q4-5）以及吸引最终用户（Q6）方面的有效性。值得注意的是，尽管参与者在任务表现上有所不同，10/12
    人报告对分析结果的正确性增加了信心（Q1）。此外，基于 7 点李克特量表（1: 强烈不同意，7: 强烈同意），参与者认为理解可视化设计（中位数=6.5，均值=6.65，标准差=.87）和与图表互动（中位数=6.0，均值=6.33，标准差=.65）是容易的。'
- en: 7.4.3\. General impressions
  id: totrans-203
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.4.3\. 一般印象
- en: The participants were generally positive about WaitGPT and affirmed its support
    in monitoring and steering LLM-generated analysis.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者对 WaitGPT 一般持积极态度，并确认其在监控和引导 LLM 生成分析方面的支持。
- en: $\diamond$ Difference in the UX between conditions. Despite in-line explanations
    and meaningful variable names in the LLM-generated code, the participants found
    it mentally taxing to follow the source code and unguided in verification. The
    reasons include memory demand for excessively long content (8/12), limited runtime
    contexts (3/12), and unfamiliar coding styles (2/12). In comparison, participants
    (12/12) resonated with the ease of understanding and verifying the code in WaitGPT
    with a higher level abstraction. The diagram “strips off unimportant details”
    (P5) and offers an overview of the code. “It [the diagram] has a clean structure
    and can serve as a navigation for the code.” (P11) This also kept participants
    engaged during the code generation. “I felt stressed viewing the code stream,
    but it’s a pleasure to watch the diagram grow.” (P4) The benefits of a visual
    summary were more apparent when the underlying code was long, as the diagram fit
    in the screen without the need to scroll vertically or horizontally (3/12). Lastly,
    many participants (8/12) were positive about the node-based interaction instead
    of sending a new chat. “There’s a chance that a new chat introduces new errors,
    so I prefer to change the code directly.” (P9)
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 条件之间的用户体验差异。尽管LLM生成的代码中有行内解释和有意义的变量名称，参与者发现跟踪源代码具有心理负担，并且在验证过程中没有指导。原因包括对过长内容的记忆需求（8/12）、有限的运行时上下文（3/12）和不熟悉的编码风格（2/12）。相比之下，参与者（12/12）对WaitGPT中较高层次抽象的代码理解和验证的容易性产生了共鸣。该图“去除了不重要的细节”（P5），提供了代码的概述。“它[图]有一个清晰的结构，可以作为代码的导航。”（P11）这也使参与者在代码生成过程中保持了参与感。“我在查看代码流时感到压力，但看着图形增长是一种乐趣。”（P4）当基础代码较长时，视觉摘要的好处更加明显，因为图形适合屏幕，无需垂直或水平滚动（3/12）。最后，许多参与者（8/12）对基于节点的交互表示积极，而不是发送新的聊天。“新的聊天可能会引入新的错误，因此我更喜欢直接修改代码。”（P9）
- en: $\diamond$ Perceived usefulness of the visualization. The current visual design
    was well-received by the participants (12/12). We categorize the perceived usefulness
    of the extended visualization and associated interactions into three dimensions.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 视觉化的感知有用性。目前的视觉设计受到参与者（12/12）的好评。我们将扩展的视觉化及相关交互的感知有用性分为三个维度。
- en: First, the diagram offers an abstract layer to focus on high-level logic and
    task decomposition. As observed by P12, “GPT outputs pretty code with mostly correct
    functional calls. This makes me lose caution for logical errors.” P3 claimed that
    the visualization facilitated LLM alignment—“I have a rough idea of how to process
    the data, and the diagram makes it easy to compare with my mind map.”
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，图形提供了一个抽象层，用于关注高级逻辑和任务分解。正如P12所观察到的，“GPT输出的代码很漂亮，功能调用大多正确。这使我对逻辑错误失去警惕。”P3表示，视觉化有助于LLM对齐——“我对如何处理数据有一个大致的想法，图形使我能够轻松地与我的思维导图进行比较。”
- en: Second, the visualization surfaces information at different layers, including
    the detailed parameters for data operations, profiles of the data table, and navigation
    back to the source code. For instance, the high accuracy rate for Task A1 was
    due to the convenience of inspecting data tables. “It’s great to access the table
    right away. It’s [the diagram] like an information hub.” (P10) P3 appreciated
    the typography applied in the operation nodes, as “it separates the variable names,
    operations, parameter names, and parameters”. P7 noted that the table glyphs suggested
    the semantics of unfamiliar functions through the input-output trace.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，视觉化展示了不同层次的信息，包括数据操作的详细参数、数据表的概况以及返回源代码的导航。例如，Task A1的高准确率得益于检查数据表的便利性。“能够立即访问表格非常棒。它[图]就像一个信息中心。”（P10）P3欣赏了操作节点中应用的排版，因为“它将变量名、操作、参数名和参数分开”。P7注意到，表格图形通过输入输出跟踪暗示了不熟悉函数的语义。
- en: Third, the node-based interactions offer a granular approach to interrogating
    or modifying the code. “I prefer talking to nodes in the diagram because the context
    is preserved, so I don’t need to type much. It’s nice to have something to point
    to make things clearer.” (P9)
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，基于节点的交互提供了一个细化的方法来查询或修改代码。“我更喜欢与图中的节点交互，因为上下文得以保留，这样我就不需要输入太多内容。能够指向某个东西使事情更清晰，这很好。”（P9）
- en: Some participants (2/11) felt more comfortable manipulating the nodes than overwriting
    the code. “Here [in the diagram], I don’t need to care much about syntax but doing
    minimum updates.” (P5) In addition, the context of a node-based interaction is
    constrained to the corresponding code section parallel to the entire conversation.
    “I am happy to maintain a clean conversation thread.” (P11)
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 一些参与者（2/11）觉得操作节点比重写代码更为舒适。“在[图示]中，我不需要过多关注语法，而只需进行最小更新。”（P5）此外，基于节点的交互上下文被限制在与整个对话平行的相应代码部分中。“我乐于保持干净的对话线程。”（P11）
- en: 7.4.4\. Glitches in using WaitGPT
  id: totrans-211
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.4.4\. 使用WaitGPT时的故障
- en: Despite the benefits mentioned, users encountered several glitches while using
    the prototype.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管提到了这些好处，用户在使用原型时遇到了几个故障。
- en: $\diamond$ Diverse needs for level of details. Participants had divergent perspectives
    on the current design of WaitGPT. For instance, P10 expressed the hope of showing
    relevant annotations directly on the operation nodes. For the table glyphs, a
    few participants (2/12) competent in data analysis criticized them as trivial.
    “I’d prefer a small annotation showing the table dimensions.” (P9) However, some
    participants (3/12) embraced the design and commented that its animation double
    encoded the program procedure, in addition to the implicit node layout from left
    to right—“When the code has complex dependencies, I can follow the operations
    step by step with the table glyphs.” (P2) To accommodate diverse needs, a customizable
    interface is anticipated for flexible user configuration.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 对细节水平的多样需求。参与者对WaitGPT当前设计有不同的看法。例如，P10希望在操作节点上直接显示相关注释。对于表格符号，一些在数据分析方面有经验的参与者（2/12）批评它们显得微不足道。“我更喜欢一个小注释显示表格的维度。”（P9）然而，一些参与者（3/12）接受了这一设计，并评论说其动画不仅双重编码了程序过程，还隐含了从左到右的节点布局——“当代码有复杂的依赖关系时，我可以通过表格符号一步步跟踪操作。”（P2）为了满足多样的需求，预计会有一个可定制的界面以便灵活配置用户设置。
- en: '$\diamond$ Concerns in the reliability & expressiveness. Participants with
    a computer science background (8/12) were generally interested in how the code
    was transformed into the diagram and expressed concerns about algorithmic failures
    (1/12) or potential information loss (2/12). Like what P12 asked: “What if it
    [LLM] made errors in parameters not presented in the diagram?” P6 recalled that
    he sometimes copied his code and prompted LLMs to use customized lambda functions
    for data transformation. However, in the current implementation, WaitGPT will
    only tag this as a “lambda function” without presenting more details due to the
    limit of current heuristics. As there are limited datasets on LLM-synthesized
    data analysis code at the moment, it remains challenging to systematically evaluate
    the coverage of our heuristics. To mitigate these concerns, future improvements
    may incorporate automatic verification of the parsing results and generative AI
    to surpass expressiveness limits.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 关于可靠性和表达性的问题。具有计算机科学背景的参与者（8/12）对代码如何转化为图示表示出了普遍的兴趣，并对算法失败（1/12）或潜在的信息丢失（2/12）表示担忧。正如P12所问：“如果[LLM]在图示中未呈现的参数上出错怎么办？”P6回忆道，他有时会复制代码并提示LLM使用自定义的lambda函数进行数据转换。然而，在当前的实现中，WaitGPT仅将其标记为“lambda函数”，而没有提供更多细节，因为当前启发式的限制。目前关于LLM合成数据分析代码的数据集有限，系统评估我们启发式的覆盖面仍然具有挑战性。为缓解这些问题，未来的改进可能会包括对解析结果的自动验证和生成性AI，以超越表达性的限制。
- en: 7.4.5\. Opportunities for Applications
  id: totrans-215
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.4.5\. 应用机会
- en: 'The participants shared several creative ideas for extending WaitGPT. P8 wanted
    to transfer the underlying concept into a visualization authoring context, where
    the encoding specifications are procedural and atomized—“After analyzing the data,
    I need to present it with high-quality visualizations, but tools like ChatGPT
    often fail my expectations.” P7 saw the value of a diagram in communication, especially
    to an audience with limited technical backgrounds. He said: “I can use the scroll-telling
    in my presentation to explain how the data has been transformed.” P3 envisioned
    a visual programming paradigm in which the basic building blocks can be self-composed
    or reused to communicate intention in addition to textual prompts to LLMs.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者分享了若干扩展WaitGPT的创意。P8希望将基础概念转化为可视化创作上下文，其中编码规格是程序化和原子化的——“在分析数据后，我需要用高质量的可视化来展示，但像ChatGPT这样的工具经常不能满足我的期望。”P7看到了图表在沟通中的价值，特别是对于技术背景有限的观众。他说：“我可以在我的演示中使用滚动讲述来解释数据是如何被转换的。”P3设想了一种可视化编程范式，其中基本构建块可以自我组合或重复使用，以传达意图，除了对LLM的文本提示外。
- en: 8\. Discussion
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8. 讨论
- en: In this section, we synthesize the implications and potential avenues for future
    research and reflect on the limitations.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们综合了未来研究的含义和潜在途径，并反思了局限性。
- en: 8.1\. Design Implications
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1. 设计含义
- en: Monitoring LLM agent through “visible hands”
  id: totrans-220
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 通过“可见的手”监控LLM代理
- en: Despite recent progress, known issues like hallucinations in LLM agents warrant
    external steering. In WaitGPT, we abstract the LLM’s generated content into high-level
    operations rather than raw text outputs, which align more closely with human cognitive
    processes. Our approach also enriches the design space of AI resilient interfaces (Gu
    et al., [2024a](#bib.bib21)). Through static analysis, WaitGPT translates synthesized
    programs into abstracted operations. These abstracted operations are brought to
    life through dynamic visual representations, making it possible for end-users
    to monitor the actions of LLM agents, similar to watching “visible hands” in real-time.
    Future design may consider a similar mechanism of semantically rich representation
    and incremental update (Zhu-Tian et al., [2024a](#bib.bib77)) in communicating
    agent actions.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管最近取得了进展，但LLM代理中的幻觉等已知问题仍需外部引导。在WaitGPT中，我们将LLM生成的内容抽象为高级操作，而不是原始文本输出，这与人类认知过程更为贴近。我们的方法还丰富了AI韧性接口的设计空间（Gu
    et al., [2024a](#bib.bib21)）。通过静态分析，WaitGPT将综合程序转换为抽象操作。这些抽象操作通过动态视觉表现形式呈现，使最终用户能够监控LLM代理的行动，类似于实时观看“可见的手”。未来的设计可以考虑类似的语义丰富表示和增量更新机制（Zhu-Tian
    et al., [2024a](#bib.bib77)）来传达代理行为。
- en: Scrollytelling for LLM-generated content
  id: totrans-222
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 用于LLM生成内容的滚动讲述
- en: WaitGPT incorporates a basic form of scrollytelling, guiding users through the
    code by highlighting the corresponding diagrams as they scroll through the generated
    content. By combining the flow diagram with a scroll-triggered revealing mechanism,
    this technique aligns naturally with the generating process of LLM-produced content,
    fostering a deeper engagement and understanding of the content. Looking ahead,
    we advocate developing automated streaming methods to create scrollytelling narratives
    for presenting LLM-generated content. This complements the animation in the steaming
    generation phase, allowing users to control their understanding speed rather than
    passively following a predefined playing timeline.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: WaitGPT融合了基本形式的滚动讲述，通过在用户滚动生成内容时高亮显示相应的图表来引导用户。通过将流程图与滚动触发的揭示机制结合，这种技术自然地与LLM生成内容的过程对齐，促进了对内容的更深入的参与和理解。展望未来，我们倡导开发自动化流媒体方法，以创建滚动讲述叙事来展示LLM生成的内容。这补充了流媒体生成阶段的动画，使用户能够控制他们的理解速度，而不是被动地跟随预定义的播放时间线。
- en: Addressing context composition in different task granularity
  id: totrans-224
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 处理不同任务粒度中的上下文组合
- en: One interesting property of LLMs is that they can provide reasonably high-quality
    responses to a wide variety of user tasks (Subramonyam et al., [2024](#bib.bib58)).
    Echoing our formative study, users may request background information or incorporate
    more contexts when analyzing data. They may start a sub-thread to test their assumptions (Gu
    et al., [2024b](#bib.bib19)). The highly diverse and evolving nature of user tasks
    in LLM-powered data analysis necessitates the development of adaptive user interfaces.
    A more challenging direction is to generate visual representations for miscellaneous
    contexts in unpredictable LLM responses.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的一个有趣特性是它们可以对各种用户任务提供相当高质量的回应（Subramonyam 等，[2024](#bib.bib58)）。与我们的初步研究相呼应，用户可能会请求背景信息或在分析数据时融入更多的上下文。他们可能会开始一个子线程来测试他们的假设（Gu
    等，[2024b](#bib.bib19)）。LLM驱动的数据分析中用户任务的高度多样性和不断发展，要求开发自适应用户界面。一个更具挑战性的方向是为不可预测的LLM响应中的各种上下文生成视觉表示。
- en: 8.2\. Future Works
  id: totrans-226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2\. 未来工作
- en: Democratizing data consumption with verifiable generative AI
  id: totrans-227
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 用可验证的生成性AI实现数据消费的民主化
- en: With nowadays generative AI, individuals without a programming background may
    easily create data visualizations for analysis or communication. However, such
    democratization comes with challenges, particularly in ensuring the accuracy and
    reliability of AI-generated content. There’s a pressing need to navigate users
    to the potential inaccuracies and biases inherent in AI outputs (Chen et al.,
    [2024a](#bib.bib8); Kazemitabaar et al., [2024](#bib.bib29); Zhu-Tian et al.,
    [2024b](#bib.bib78)). We believe that the key to fully leveraging AI’s capabilities
    in data consumption hinges on creating user interfaces that align with the expertise
    levels of the intended users. In addition, different data tasks raise different
    requirements warranting tailored supports, such as an emphasis on the authorial
    intent matching of encoding schemes in expressive visualization design (e.g., (Vaithilingam
    et al., [2024](#bib.bib62); Xie et al., [2024](#bib.bib71))).
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的生成性AI使得没有编程背景的个人也能轻松创建用于分析或沟通的数据可视化。然而，这种民主化也带来了挑战，特别是在确保AI生成内容的准确性和可靠性方面。迫切需要引导用户识别AI输出中固有的潜在不准确性和偏见（Chen
    等，[2024a](#bib.bib8)；Kazemitabaar 等，[2024](#bib.bib29)；Zhu-Tian 等，[2024b](#bib.bib78)）。我们认为，充分利用AI在数据消费中的能力的关键在于创建与预期用户的专业水平相符的用户界面。此外，不同的数据任务提出了不同的要求，需要量身定制的支持，例如，在表达性可视化设计中强调编码方案与作者意图的一致性（例如，（Vaithilingam
    等，[2024](#bib.bib62)；Xie 等，[2024](#bib.bib71)））。
- en: Introducing a “stop” mechanism in human-LLM agent interaction
  id: totrans-229
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 在人类-LLM代理互动中引入“停止”机制
- en: While WaitGPT is based on a chatbot-like interface, such an interaction paradigm
    can apply to a standalone AI assistant integrated into data analysis software
    or notebook platforms (Mcnutt et al., [2023](#bib.bib39)). Essentially, during
    the ongoing conversation with LLM agents, users may be overwhelmed by the token-based
    output and fail to prevent propagating errors in time. WaitGPT integrates proactive
    strategies to identify and rectify potential failures in AI-generated content.
    Similarly, future works may further enrich the design space of visual representations
    of LLM outputs (Gu et al., [2024a](#bib.bib21); Cai et al., [2024](#bib.bib5))
    for instant understanding and explore a low-cost approach to facilitate steering
    content generation based on intermediate outputs.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然WaitGPT基于类似聊天机器人的界面，但这种互动模式也可以应用于集成到数据分析软件或笔记本平台中的独立AI助手（Mcnutt 等，[2023](#bib.bib39)）。本质上，在与LLM代理进行的持续对话中，用户可能会被基于标记的输出所淹没，未能及时防止错误传播。WaitGPT集成了主动策略来识别和纠正AI生成内容中的潜在失败。同样，未来的工作可能进一步丰富LLM输出视觉表示的设计空间（Gu
    等，[2024a](#bib.bib21)；Cai 等，[2024](#bib.bib5)），以实现即时理解，并探索一种低成本的方法来基于中间输出促进内容生成。
- en: Exploiting interaction modalities in conversational data interface
  id: totrans-231
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 发掘对话数据界面中的互动模式
- en: First, beyond textual prompts with simple selections of data slices in ChatGPT,
    future systems may incorporate other input types like direct manipulation (Masson
    et al., [2024](#bib.bib38)), demonstration (Huang et al., [2024](#bib.bib25)),
    and reference (Xie et al., [2023](#bib.bib72)). Second, to navigate users in nuanced
    decisions with drill-down explorations (Gu et al., [2024c](#bib.bib20), [b](#bib.bib19)),
    it is promising to provide explanations on demand (Mehrpour and Latoza, [2023](#bib.bib40)),
    or establish a tighter connection between code, data, textual analysis, and generated
    visualizations (Wang et al., [2024b](#bib.bib67); Cao et al., [2023](#bib.bib6)).
    Last, enabling users to directly reuse the generated code or interact with the
    resulting visualizations for further exploration (Weng et al., [2024](#bib.bib68);
    Gadhave et al., [2022](#bib.bib17)) could augment the flexibility of conversational
    data analysis tools.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，除了 ChatGPT 中通过简单选择数据切片的文本提示外，未来的系统可能会结合其他输入类型，如直接操作（Masson et al., [2024](#bib.bib38)）、演示（Huang
    et al., [2024](#bib.bib25)）和参考（Xie et al., [2023](#bib.bib72)）。其次，为了在细微的决策中引导用户进行深入探索（Gu
    et al., [2024c](#bib.bib20), [b](#bib.bib19)），有前景的是按需提供解释（Mehrpour and Latoza,
    [2023](#bib.bib40)），或在代码、数据、文本分析和生成的可视化之间建立更紧密的连接（Wang et al., [2024b](#bib.bib67)；Cao
    et al., [2023](#bib.bib6)）。最后，使用户能够直接重用生成的代码或与结果可视化进行交互以进一步探索（Weng et al., [2024](#bib.bib68)；Gadhave
    et al., [2022](#bib.bib17)）可能会增强对话数据分析工具的灵活性。
- en: 8.3\. Limitation
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3\. 限制
- en: Threats to validity
  id: totrans-234
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 有效性威胁
- en: The sample size in our formative and evaluation studies is relatively small
    and thus may not be representative of the broader population of data analysts
    and LLM users. In the evaluation study, both conditions were equipped with standard
    syntax highlight for Python language. However, without a careful visual design
    for key operations in the Baseline, participants may favor more on WaitGPT with
    its simplified information. Besides, participants were prompted to view the transformable
    representation of the data analysis script, which may not reflect their natural
    interaction patterns. The reported usability rating may also be subject to response
    bias (Dell et al., [2012](#bib.bib12)) and participants’ familiarity with the
    tasks. Future works may investigate how and how often users leverage this augmented
    view in their natural working space without explicit prompts to capture its real-world
    utility.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的形成性和评估研究中的样本量相对较小，因此可能不能代表更广泛的数据分析师和 LLM 用户群体。在评估研究中，两个条件都配备了 Python 语言的标准语法高亮。然而，由于
    Baseline 中关键操作的视觉设计不够精细，参与者可能更倾向于使用简化信息的 WaitGPT。此外，参与者被提示查看数据分析脚本的可变表示，这可能无法反映他们的自然互动模式。报告的可用性评分也可能受到回应偏差（Dell
    et al., [2012](#bib.bib12)）和参与者对任务的熟悉程度的影响。未来的工作可以研究用户在没有明确提示的情况下如何以及多频繁地利用这种增强视图，以捕捉其实际应用价值。
- en: Scalability issues
  id: totrans-236
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 可扩展性问题
- en: In the framework, translating code into a flow diagram requires static analysis,
    which is dependent on the syntax. WaitGPT is currently tailored to Python language
    and libraries like Pandas and Matplotlib for tubular data. A potential solution
    to improve generalizability is to redesign LLM prompts to allow a mixed output
    stream of code and underlying operation objects, e.g., (Suh et al., [2023](#bib.bib59);
    Kazemitabaar et al., [2024](#bib.bib29)). However, the code stream visualization
    may not work for SQL-like languages with a reversed execution order compared to
    the procedure declaration. Second, the flow diagram assumes a linear structure
    in the code, targeting fluent interfaces (Shrestha et al., [2021](#bib.bib56)).
    Future works can incorporate control flows like loops and visual primitives for
    other data types. Last, the current glyph design may not scale to tables with
    over 20 columns. To address this, unused columns can be aggregated, or important
    ones can be hidden.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在框架中，将代码转换为流程图需要静态分析，这依赖于语法。WaitGPT 当前针对 Python 语言以及 Pandas 和 Matplotlib 等库进行了定制，用于处理表格数据。一种提高普适性的潜在解决方案是重新设计
    LLM 提示，以允许代码和底层操作对象的混合输出流，例如（Suh et al., [2023](#bib.bib59)；Kazemitabaar et al.,
    [2024](#bib.bib29)）。然而，代码流可视化可能不适用于 SQL 类语言，这些语言的执行顺序与过程声明相比是反向的。其次，流程图假设代码中的线性结构，目标是流畅的接口（Shrestha
    et al., [2021](#bib.bib56)）。未来的工作可以整合控制流如循环以及其他数据类型的视觉原语。最后，当前的字形设计可能无法扩展到超过 20
    列的表格。为解决此问题，可以聚合未使用的列，或隐藏重要的列。
- en: 9\. Conclusion
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9\. 结论
- en: In this paper, we introduced WaitGPT, a novel interface design that transforms
    LLM-generated code into an accessible, interactive representation to address the
    reliability issues and user challenges in LLM-powered data analysis tools. Drawing
    from an interview study with general users (N=8) of ChatGPT, we gained insights
    into general perspectives on these nascent tools and glitches in disruptive workflow,
    code verification, and labor-intensive iterations. By translating stream-based
    code into a growing visualization of the key data operations and affording granular
    interactions, WaitGPT empowers users to monitor and steer data analysis performed
    by LLM agents. A user study (N=12) covering basic data analysis tasks demonstrated
    that WaitGPT could enhance error detection rate and improve overall confidence
    in the results.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们介绍了 WaitGPT，这是一种新颖的界面设计，将 LLM 生成的代码转化为易于访问的互动表现形式，以解决 LLM 驱动的数据分析工具中的可靠性问题和用户挑战。通过对
    ChatGPT 普通用户（N=8）的访谈研究，我们获得了对这些新兴工具的总体看法以及在破坏性工作流程、代码验证和劳动密集型迭代中的故障的见解。通过将基于流的代码转化为关键数据操作的不断增长的可视化，并提供细粒度的互动，WaitGPT
    使用户能够监控和引导 LLM 代理执行的数据分析。一项涵盖基础数据分析任务的用户研究（N=12）表明，WaitGPT 可以提高错误检测率，并增强对结果的整体信心。
- en: Our work contributes to the field of human-AI collaboration in data analysis
    by demonstrating the effectiveness of transformable code representations in facilitating
    user understanding and engagement. As LLM applications in data analysis become
    more prevalent, prioritizing user experience and trust through accessible, interactive
    interfaces will be crucial in harnessing the potential of these powerful tools
    while ensuring their reliability and usability. We urge more exploration of novel
    human-LLM interaction paradigms and intuitive visual representation design for
    LLM responses.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的工作通过展示可转换代码表示在促进用户理解和参与中的有效性，为人机协作数据分析领域做出了贡献。随着 LLM 在数据分析中的应用变得越来越普遍，通过可访问的互动界面优先考虑用户体验和信任将对发挥这些强大工具的潜力，同时确保其可靠性和可用性至关重要。我们呼吁进一步探索新的人机-LLM
    互动范式和 LLM 响应的直观可视化设计。
- en: Acknowledgements.
  id: totrans-241
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 致谢
- en: This research is supported by RGC GRF grant 16210321\. The first author thanks
    Prof. Hanspeter Pfister for hosting the visit to the Harvard Visual Computing
    Group. We also thank the anonymous reviewers for their constructive feedback,
    the participants in the formative and user studies, and Zhan Wang, Leixian Shen,
    Xiaofu Jin, Shuchang Xu, Dr. Yanna Lin, Dr. Qingyu Guo, and Dr. Yun Wang for their
    valuable input.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究得到了 RGC GRF 资助 16210321 的支持。第一作者感谢 Prof. Hanspeter Pfister 主办了对哈佛视觉计算组的访问。我们还感谢匿名审稿人提供的建设性反馈、形成性和用户研究的参与者，以及
    Zhan Wang、Leixian Shen、Xiaofu Jin、Shuchang Xu、Dr. Yanna Lin、Dr. Qingyu Guo 和 Dr.
    Yun Wang 的宝贵意见。
- en: References
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: 'Angert et al. (2023) Tyler Angert, Miroslav Suzara, Jenny Han, Christopher
    Pondoc, and Hariharan Subramonyam. 2023. Spellburst: A node-based interface for
    exploratory creative coding with natural language prompts. In *Proceedings of
    the Symposium on User Interface Software and Technology (UIST)*. ACM, New York,
    NY, Article 100, 22 pages. [https://doi.org/10.1145/3586183.3606719](https://doi.org/10.1145/3586183.3606719)'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Angert et al. (2023) Tyler Angert、Miroslav Suzara、Jenny Han、Christopher Pondoc
    和 Hariharan Subramonyam. 2023. Spellburst：一种基于节点的界面，用于自然语言提示的探索性创意编码。见 *用户界面软件与技术研讨会
    (UIST) 论文集*。ACM，纽约，NY，第 100 篇，22 页。 [https://doi.org/10.1145/3586183.3606719](https://doi.org/10.1145/3586183.3606719)
- en: Bors et al. (2019) Christian Bors, Theresia Gschwandtner, and Silvia Miksch.
    2019. Capturing and visualizing provenance from data wrangling. *IEEE Comput.
    Graph. Appl.* 39, 6 (2019), 61–75. [https://doi.org/10.1109/MCG.2019.2941856](https://doi.org/10.1109/MCG.2019.2941856)
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bors et al. (2019) Christian Bors、Theresia Gschwandtner 和 Silvia Miksch. 2019.
    捕获和可视化数据清洗的来源。 *IEEE 计算机图形学与应用* 39, 6 (2019), 61–75. [https://doi.org/10.1109/MCG.2019.2941856](https://doi.org/10.1109/MCG.2019.2941856)
- en: 'Braun and Clarke (2012) Virginia Braun and Victoria Clarke. 2012. Thematic
    analysis. In *APA handbook of research methods in psychology, Vol. 2\. Research
    designs: Quantitative, qualitative, neuropsychological, and biological*. APA,
    Washington D.C. [https://doi.org/10.1037/13620-004](https://doi.org/10.1037/13620-004)'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Braun and Clarke (2012) Virginia Braun 和 Victoria Clarke. 2012. 主题分析。见 *APA
    心理学研究方法手册，第 2 卷。研究设计：定量、定性、神经心理学和生物学*。APA，华盛顿 D.C. [https://doi.org/10.1037/13620-004](https://doi.org/10.1037/13620-004)
- en: 'Cai et al. (2024) Yuzhe Cai, Shaoguang Mao, Wenshan Wu, Zehua Wang, Yaobo Liang,
    Tao Ge, Chenfei Wu, You Wang, Ting Song, Yan Xia, Nan Duan, and Furu Wei. 2024.
    Low-code LLM: Graphical user interface over large language models. In *Proceedings
    of the 2024 Conference of the North American Chapter of the Association for Computational
    Linguistics: Human Language Technologies (Volume 3: System Demonstrations)*. 12–25.
    [https://aclanthology.org/2024.naacl-demo.2](https://aclanthology.org/2024.naacl-demo.2)'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Cai 等人（2024）Yuzhe Cai, Shaoguang Mao, Wenshan Wu, Zehua Wang, Yaobo Liang,
    Tao Ge, Chenfei Wu, You Wang, Ting Song, Yan Xia, Nan Duan 和 Furu Wei. 2024. 《低代码
    LLM：大语言模型的图形用户界面》。发表于 *Proceedings of the 2024 Conference of the North American
    Chapter of the Association for Computational Linguistics: Human Language Technologies
    (Volume 3: System Demonstrations)*。12–25。 [https://aclanthology.org/2024.naacl-demo.2](https://aclanthology.org/2024.naacl-demo.2)'
- en: 'Cao et al. (2023) Yining Cao, Jane L. E, Chen Zhu-Tian, and Haijun Xia. 2023.
    DataParticles: Block-based and language-oriented authoring of animated unit visualizations.
    In *Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI)*.
    ACM, New York, NY, Article 808, 15 pages. [https://doi.org/10.1145/3544548.3581472](https://doi.org/10.1145/3544548.3581472)'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cao 等人（2023）Yining Cao, Jane L. E, Chen Zhu-Tian 和 Haijun Xia. 2023. 《DataParticles：基于区块的和面向语言的动画单位可视化创作》。发表于
    *Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI)*。ACM，纽约，NY，文章
    808，15 页。 [https://doi.org/10.1145/3544548.3581472](https://doi.org/10.1145/3544548.3581472)
- en: 'Chen et al. (2024b) Nan Chen, Yuge Zhang, Jiahang Xu, Kan Ren, and Yuqing Yang.
    2024b. VisEval: A benchmark for data visualization in the era of large language
    models. arXiv:2407.00981'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人（2024b）Nan Chen, Yuge Zhang, Jiahang Xu, Kan Ren 和 Yuqing Yang. 2024b.
    《VisEval：大语言模型时代的数据可视化基准》。arXiv:2407.00981
- en: Chen et al. (2024a) Yida Chen, Aoyu Wu, Catherine Yeh Trevor DePodesta, Kenneth
    Li, Nicholas Castillo Marin, Oam Patel, Jan Riecke, Shivam Raval, Olivia Seow,
    Martin Wattenberg, and Fernanda Viégas. 2024a. Designing a dashboard for transparency
    and control of conversational AI. arXiv:2406.07882
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人（2024a）Yida Chen, Aoyu Wu, Catherine Yeh, Trevor DePodesta, Kenneth Li,
    Nicholas Castillo Marin, Oam Patel, Jan Riecke, Shivam Raval, Olivia Seow, Martin
    Wattenberg 和 Fernanda Viégas. 2024a. 《设计一个用于对话 AI 透明度和控制的仪表盘》。arXiv:2406.07882
- en: 'Cheng et al. (2023) Liying Cheng, Xingxuan Li, and Lidong Bing. 2023. Is GPT-4
    a good data analyst?. In *Findings of the Association for Computational Linguistics:
    EMNLP*. ACL, 9496–9514. [https://doi.org/10.18653/v1/2023.findings-emnlp.637](https://doi.org/10.18653/v1/2023.findings-emnlp.637)'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Cheng 等人（2023）Liying Cheng, Xingxuan Li 和 Lidong Bing. 2023. 《GPT-4 是一个好的数据分析师吗？》。发表于
    *Findings of the Association for Computational Linguistics: EMNLP*。ACL，9496–9514。
    [https://doi.org/10.18653/v1/2023.findings-emnlp.637](https://doi.org/10.18653/v1/2023.findings-emnlp.637)'
- en: 'Chopra et al. (2023) Bhavya Chopra, Ananya Singha, Anna Fariha, Sumit Gulwani,
    Chris Parnin, Ashish Tiwari, and Austin Z Henley. 2023. Conversational challenges
    in AI-powered data science: Obstacles, needs, and design opportunities. arXiv:2310.16164'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chopra 等人（2023）Bhavya Chopra, Ananya Singha, Anna Fariha, Sumit Gulwani, Chris
    Parnin, Ashish Tiwari 和 Austin Z Henley. 2023. 《AI 驱动的数据科学中的对话挑战：障碍、需求与设计机会》。arXiv:2310.16164
- en: 'Chung et al. (2022) John Joon Young Chung, Wooseok Kim, Kang Min Yoo, Hwaran
    Lee, Eytan Adar, and Minsuk Chang. 2022. TaleBrush: Sketching stories with generative
    pretrained language models. In *Proceedings of the ACM Conference on Human Factors
    in Computing Systems (CHI)*. ACM, New York, NY, Article 209, 19 pages. [https://doi.org/10.1145/3491102.3501819](https://doi.org/10.1145/3491102.3501819)'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chung 等人（2022）John Joon Young Chung, Wooseok Kim, Kang Min Yoo, Hwaran Lee,
    Eytan Adar 和 Minsuk Chang. 2022. 《TaleBrush：使用生成预训练语言模型绘制故事》。发表于 *Proceedings
    of the ACM Conference on Human Factors in Computing Systems (CHI)*。ACM，纽约，NY，文章
    209，19 页。 [https://doi.org/10.1145/3491102.3501819](https://doi.org/10.1145/3491102.3501819)
- en: Dell et al. (2012) Nicola Dell, Vidya Vaidyanathan, Indrani Medhi, Edward Cutrell,
    and William Thies. 2012. “Yours is better!” Participant response bias in HCI.
    In *Proceedings of the sigchi conference on human factors in computing systems*.
    ACM, New York, NY, 1321–1330. [https://doi.org/10.1145/2207676.2208589](https://doi.org/10.1145/2207676.2208589)
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dell 等人（2012）Nicola Dell, Vidya Vaidyanathan, Indrani Medhi, Edward Cutrell
    和 William Thies. 2012. “你的更好！” HCI 中的参与者回应偏差。发表于 *Proceedings of the SIGCHI Conference
    on Human Factors in Computing Systems*。ACM，纽约，NY，1321–1330。 [https://doi.org/10.1145/2207676.2208589](https://doi.org/10.1145/2207676.2208589)
- en: 'Dibia (2023) Victor Dibia. 2023. LIDA: A tool for automatic generation of grammar-agnostic
    visualizations and infographics using large language models. In *Proceedings of
    the Annual Meeting of the Association for Computational Linguistics (Volume 3:
    System Demonstrations)*. ACL, Toronto, Canada, 113–126. [https://doi.org/10.18653/v1/2023.acl-demo.11](https://doi.org/10.18653/v1/2023.acl-demo.11)'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dibia（2023）Victor Dibia。2023。LIDA：一种使用大型语言模型自动生成语法无关可视化和信息图的工具。在*计算语言学协会年会（第3卷：系统演示）*上。ACL,
    多伦多, 加拿大, 113–126. [https://doi.org/10.18653/v1/2023.acl-demo.11](https://doi.org/10.18653/v1/2023.acl-demo.11)
- en: 'Ding et al. (2019) Rui Ding, Shi Han, Yong Xu, Haidong Zhang, and Dongmei Zhang.
    2019. QuickInsights: Quick and automatic discovery of insights from multi-dimensional
    data. In *Proceedings of the International Conference on Management of Data (SIGMOD)*.
    ACM, New York, NY, 317–332. [https://doi.org/10.1145/3299869.3314037](https://doi.org/10.1145/3299869.3314037)'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ding等人（2019）Rui Ding、Shi Han、Yong Xu、Haidong Zhang 和 Dongmei Zhang。2019。QuickInsights：从多维数据中快速自动发现洞察力。在*国际数据管理会议（SIGMOD）*上。ACM,
    纽约, NY, 317–332. [https://doi.org/10.1145/3299869.3314037](https://doi.org/10.1145/3299869.3314037)
- en: 'Feng et al. (2024) Yingchaojie Feng, Xingbo Wang, Bo Pan, Kam Kwai Wong, Yi
    Ren, Shi Liu, Zihan Yan, Yuxin Ma, Huamin Qu, and Wei Chen. 2024. XNLI: Explaining
    and diagnosing NLI-based visual data analysis. *IEEE Trans. Vis. Comput. Graph.*
    30, 7 (2024), 3813–3827. [https://doi.org/10.1109/TVCG.2023.3240003](https://doi.org/10.1109/TVCG.2023.3240003)'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Feng等人（2024）Yingchaojie Feng、Xingbo Wang、Bo Pan、Kam Kwai Wong、Yi Ren、Shi Liu、Zihan
    Yan、Yuxin Ma、Huamin Qu 和 Wei Chen。2024。XNLI：解释和诊断基于NLI的视觉数据分析。*IEEE计算机视觉与图形学汇刊*
    30, 7 (2024), 3813–3827. [https://doi.org/10.1109/TVCG.2023.3240003](https://doi.org/10.1109/TVCG.2023.3240003)
- en: 'Ferdowsi et al. (2023) Kasra Ferdowsi, Jack Williams, Ian Drosos, Andrew D
    Gordon, Carina Negreanu, Nadia Polikarpova, Advait Sarkar, and Benjamin Zorn.
    2023. ColDeco: An end user spreadsheet inspection tool for AI-generated code.
    In *Proceedings of the IEEE Symposium on Visual Languages and Human-Centric Computing
    (VL/HCC)*. IEEE, Piscataway, NJ, 82–91. [https://doi.org/10.1109/VL-HCC57772.2023.00017](https://doi.org/10.1109/VL-HCC57772.2023.00017)'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ferdowsi等人（2023）Kasra Ferdowsi、Jack Williams、Ian Drosos、Andrew D Gordon、Carina
    Negreanu、Nadia Polikarpova、Advait Sarkar 和 Benjamin Zorn。2023。ColDeco：用于AI生成代码的最终用户电子表格检查工具。在*IEEE视觉语言与以人为本计算研讨会（VL/HCC）*上。IEEE,
    Piscataway, NJ, 82–91. [https://doi.org/10.1109/VL-HCC57772.2023.00017](https://doi.org/10.1109/VL-HCC57772.2023.00017)
- en: Gadhave et al. (2022) Kiran Gadhave, Zach Cutler, and Alexander Lex. 2022. Reusing
    interactive analysis workflows. *Comput. Graphics Forum* 41, 3 (2022), 133–144.
    [https://doi.org/10.1111/cgf.14528](https://doi.org/10.1111/cgf.14528)
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gadhave等人（2022）Kiran Gadhave、Zach Cutler 和 Alexander Lex。2022。重用交互式分析工作流。*计算机图形学论坛*
    41, 3 (2022), 133–144. [https://doi.org/10.1111/cgf.14528](https://doi.org/10.1111/cgf.14528)
- en: 'Google (2024) Google. 2024. *Gemini Advanced: Release updates*. Google. Retrieved
    June 1, 2024 from [https://gemini.google.com/updates](https://gemini.google.com/updates)
    2024.05.21: updates on data analysis features.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Google（2024）Google。2024。*Gemini Advanced: Release updates*。Google。2024年6月1日检索自
    [https://gemini.google.com/updates](https://gemini.google.com/updates) 2024.05.21：数据分析功能更新。'
- en: Gu et al. (2024b) Ken Gu, Madeleine Grunde-McLaughlin, Andrew M. McNutt, Jeffrey
    Heer, and Tim Althoff. 2024b. How do data analysts respond to AI assistance? A
    wizard-of-oz study. In *Proceedings of the ACM Conference on Human Factors in
    Computing Systems (CHI)*. ACM, New York, NY, Article 1015, 22 pages. [https://doi.org/10.1145/3613904.3641891](https://doi.org/10.1145/3613904.3641891)
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gu等人（2024b）Ken Gu、Madeleine Grunde-McLaughlin、Andrew M. McNutt、Jeffrey Heer
    和 Tim Althoff。2024b。数据分析师如何应对AI辅助？一种“奥兹巫师”研究。在*ACM计算机系统人因会议（CHI）*上。ACM, 纽约, NY,
    文章1015, 22页。 [https://doi.org/10.1145/3613904.3641891](https://doi.org/10.1145/3613904.3641891)
- en: Gu et al. (2024c) Ken Gu, Ruoxi Shang, Tim Althoff, Chenglong Wang, and Steven M
    Drucker. 2024c. How do analysts understand and verify AI-assisted data analyses?.
    In *Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI)*.
    ACM, New York, NY, Article 748, 22 pages. [https://doi.org/10.1145/3613904.3642497](https://doi.org/10.1145/3613904.3642497)
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gu等人（2024c）Ken Gu、Ruoxi Shang、Tim Althoff、Chenglong Wang 和 Steven M Drucker。2024c。分析师如何理解和验证AI辅助的数据分析？在*ACM计算机系统人因会议（CHI）*上。ACM,
    纽约, NY, 文章748, 22页。 [https://doi.org/10.1145/3613904.3642497](https://doi.org/10.1145/3613904.3642497)
- en: Gu et al. (2024a) Ziwei Gu, Ian Arawjo, Kenneth Li, Jonathan K Kummerfeld, and
    Elena L Glassman. 2024a. An AI-resilient text rendering technique for reading
    and skimming documents. In *Proceedings of the ACM Conference on Human Factors
    in Computing Systems (CHI)*. ACM, New York, NY, Article 898, 22 pages. [https://doi.org/10.1145/3613904.3642699](https://doi.org/10.1145/3613904.3642699)
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gu 等人（2024a）**顾子微**、**伊恩·阿劳霍**、**肯尼斯·李**、**乔纳森·K·库默费尔德**、**艾琳娜·L·格拉斯曼**。2024a。AI抗性文本渲染技术，用于阅读和浏览文档。在
    *ACM 人机交互会议（CHI）论文集* 中。ACM, 纽约，NY, 文章898, 22页。 [https://doi.org/10.1145/3613904.3642699](https://doi.org/10.1145/3613904.3642699)
- en: 'Guo et al. (2023) Yi Guo, Nan Cao, Xiaoyu Qi, Haoyang Li, Danqing Shi, Jing
    Zhang, Qing Chen, and Daniel Weiskopf. 2023. Urania: Visualizing data analysis
    pipelines for natural language-based data exploration. arXiv:2306.07760'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo 等人（2023）**郭毅**、**曹楠**、**齐晓雨**、**李昊阳**、**石丹青**、**张静**、**陈青**、**丹尼尔·维斯科普夫**。2023。Urania：用于自然语言数据探索的数据分析流程可视化。arXiv:2306.07760
- en: 'Hart and Staveland (1988) Sandra G Hart and Lowell E Staveland. 1988. Development
    of NASA-TLX (Task Load Index): Results of empirical and theoretical research.
    In *Advances in psychology*. Vol. 52\. Elsevier, 139–183. [https://doi.org/10.1016/S0166-4115(08)62386-9](https://doi.org/10.1016/S0166-4115(08)62386-9)'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hart 和 Staveland（1988）**桑德拉·G·哈特** 和 **洛厄尔·E·斯塔夫兰德**。1988。NASA-TLX（任务负荷指数）的发展：实证与理论研究结果。在
    *心理学进展* 中。第52卷。Elsevier，139–183。 [https://doi.org/10.1016/S0166-4115(08)62386-9](https://doi.org/10.1016/S0166-4115(08)62386-9)
- en: 'He et al. (2024) Xinyi He, Mengyu Zhou, Xinrun Xu, Xiaojun Ma, Rui Ding, Lun
    Du, Yan Gao, Ran Jia, Xu Chen, Shi Han, Zejian Yuan, and Dongmei Zhang. 2024.
    Text2Analysis: A benchmark of table question answering with advanced data analysis
    and unclear queries. *Proceedings of the Annual AAAI Conference on Artificial
    Intelligence (AAAI)* 38, 16 (2024), 18206–18215. [https://doi.org/10.1609/aaai.v38i16.29779](https://doi.org/10.1609/aaai.v38i16.29779)'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He 等人（2024）**何心怡**、**周梦宇**、**徐新润**、**马晓军**、**丁睿**、**杜伦**、**高焰**、**贾然**、**陈旭**、**韩石**、**袁泽见**、**张冬梅**。2024。Text2Analysis：一种具有先进数据分析和模糊查询的表格问答基准。*人工智能年度会议（AAAI）论文集*
    38, 16 (2024), 18206–18215。 [https://doi.org/10.1609/aaai.v38i16.29779](https://doi.org/10.1609/aaai.v38i16.29779)
- en: 'Huang et al. (2024) Yanwei Huang, Yurun Yang, Xinhuan Shu, Ran Chen, Di Weng,
    and Yingcai Wu. 2024. Table Illustrator: Puzzle-based interactive authoring of
    plain tables. In *Proceedings of the ACM Conference on Human Factors in Computing
    Systems (CHI)*. ACM, New York, NY, Article 186, 18 pages. [https://doi.org/10.1145/3613904.3642415](https://doi.org/10.1145/3613904.3642415)'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等人（2024）**黄燕伟**、**杨雨润**、**舒新焕**、**陈冉**、**翁迪**、**吴英才**。2024。Table Illustrator：基于谜题的平面表格互动创作。在
    *ACM 人机交互会议（CHI）论文集* 中。ACM, 纽约，NY, 文章186, 18页。 [https://doi.org/10.1145/3613904.3642415](https://doi.org/10.1145/3613904.3642415)
- en: Huang et al. (2023) Yanwei Huang, Yunfan Zhou, Ran Chen, Changhao Pan, Xinhuan
    Shu, Di Weng, and Yingcai Wu. 2023. Interactive table synthesis with natural language.
    *IEEE Trans. Vis. Comput. Graph.* (2023). [https://doi.org/10.1109/TVCG.2023.3329120](https://doi.org/10.1109/TVCG.2023.3329120)
    Early Access.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等人（2023）**黄燕伟**、**周云凡**、**陈冉**、**潘昌浩**、**舒新焕**、**翁迪**、**吴英才**。2023。自然语言下的互动表格合成。*IEEE
    视觉计算机图形学期刊*（2023）。 [https://doi.org/10.1109/TVCG.2023.3329120](https://doi.org/10.1109/TVCG.2023.3329120)
    早期访问。
- en: 'Jiang et al. (2023) Peiling Jiang, Jude Rayan, Steven P Dow, and Haijun Xia.
    2023. Graphologue: Exploring large language model responses with interactive diagrams.
    In *Proceedings of the Symposium on User Interface Software and Technology (UIST)*.
    ACM, New York, NY, Article 3, 20 pages. [https://doi.org/10.1145/3586183.3606737](https://doi.org/10.1145/3586183.3606737)'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang 等人（2023）**姜佩玲**、**朱德·瑞安**、**斯蒂文·P·道**、**夏海军**。2023。Graphologue：通过交互式图表探索大语言模型的响应。在
    *用户界面软件与技术研讨会（UIST）论文集* 中。ACM, 纽约，NY, 文章3, 20页。 [https://doi.org/10.1145/3586183.3606737](https://doi.org/10.1145/3586183.3606737)
- en: 'Kandel et al. (2011) Sean Kandel, Andreas Paepcke, Joseph Hellerstein, and
    Jeffrey Heer. 2011. Wrangler: Interactive visual specification of data transformation
    scripts. In *Proceedings of the ACM Conference on Human Factors in Computing Systems
    (CHI)*. ACM, New York, NY, 3363–3372. [https://doi.org/10.1145/1978942.1979444](https://doi.org/10.1145/1978942.1979444)'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kandel 等人（2011）**肖恩·坎德尔**、**安德烈亚斯·佩普克**、**约瑟夫·赫勒斯坦**、**杰弗里·赫尔**。2011。Wrangler：交互式数据转换脚本的可视化规范。在
    *ACM 人机交互会议（CHI）论文集* 中。ACM, 纽约，NY, 3363–3372。 [https://doi.org/10.1145/1978942.1979444](https://doi.org/10.1145/1978942.1979444)
- en: Kazemitabaar et al. (2024) Majeed Kazemitabaar, Jack Williams, Ian Drosos, Tovi
    Grossman, Austin Henley, Carina Negreanu, and Advait Sarkar. 2024. Improving steering
    and verification in AI-assisted data analysis with interactive task decomposition.
    arXiv:2407.02651
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kazemitabaar 等 (2024) Majeed Kazemitabaar, Jack Williams, Ian Drosos, Tovi Grossman,
    Austin Henley, Carina Negreanu, 和 Advait Sarkar. 2024. 通过互动任务分解改进 AI 辅助数据分析中的引导和验证。arXiv:2407.02651
- en: 'Khan et al. (2017) Meraj Khan, Larry Xu, Arnab Nandi, and Joseph M Hellerstein.
    2017. Data tweening: Incremental visualization of data transforms. *Proceedings
    of the VLDB Endowment* 10, 6 (2017), 661–672. [https://doi.org/10.14778/3055330.3055333](https://doi.org/10.14778/3055330.3055333)'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khan 等 (2017) Meraj Khan, Larry Xu, Arnab Nandi, 和 Joseph M Hellerstein. 2017.
    数据过渡：数据转换的增量可视化。*VLDB 资助会议论文集* 10, 6 (2017), 661–672. [https://doi.org/10.14778/3055330.3055333](https://doi.org/10.14778/3055330.3055333)
- en: 'Ko and Myers (2004) Amy J Ko and Brad A Myers. 2004. Designing the Whyline:
    A debugging interface for asking questions about program behavior. In *Proceedings
    of the ACM Conference on Human Factors in Computing Systems (CHI)*. ACM, New York,
    NY, 151–158. [https://doi.org/10.1145/985692.985712](https://doi.org/10.1145/985692.985712)'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ko 和 Myers (2004) Amy J Ko 和 Brad A Myers. 2004. 设计 Whyline：一个用于询问程序行为的调试界面。收录于*ACM
    人机交互会议论文集 (CHI)*。ACM, 纽约, NY, 151–158. [https://doi.org/10.1145/985692.985712](https://doi.org/10.1145/985692.985712)
- en: 'Lau et al. (2023) Sam Lau, Sean Kross, Eugene Wu, and Philip J Guo. 2023. Teaching
    data science by visualizing data table transformations: Pandas Tutor for Python,
    Tidy Data Tutor for R, and SQL Tutor. In *Proceedings of the International Workshop
    on Data Systems Education: Bridging Education Practice with Education Research*.
    ACM, New York, NY, 50–55. [https://doi.org/10.1145/3596673.3596972](https://doi.org/10.1145/3596673.3596972)'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lau 等 (2023) Sam Lau, Sean Kross, Eugene Wu, 和 Philip J Guo. 2023. 通过可视化数据表格转换教授数据科学：Python
    的 Pandas Tutor、R 的 Tidy Data Tutor 和 SQL Tutor。收录于*数据系统教育国际研讨会：教育实践与教育研究的桥梁*。ACM,
    纽约, NY, 50–55. [https://doi.org/10.1145/3596673.3596972](https://doi.org/10.1145/3596673.3596972)
- en: 'Li et al. (2024) Boyan Li, Yuyu Luo, Chengliang Chai, Guoliang Li, and Nan
    Tang. 2024. The dawn of natural language to SQL: Are we fully ready? arXiv:2406.01265'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等 (2024) Boyan Li, Yuyu Luo, Chengliang Chai, Guoliang Li, 和 Nan Tang. 2024.
    自然语言到 SQL 的曙光：我们准备好了吗？arXiv:2406.01265
- en: 'Liu et al. (2023a) Michael Xieyang Liu, Advait Sarkar, Carina Negreanu, Ben
    Zorn, Jack Williams, Neil Toronto, and Andy Gordon. 2023a. “What it wants me to
    say”: Bridging the abstraction gap between end-user programmers and code-generating
    large language models. In *Proceedings of the ACM Conference on Human Factors
    in Computing Systems (CHI)*. ACM, New York, NY, 31 pages. [https://doi.org/10.1145/3544548.3580817](https://doi.org/10.1145/3544548.3580817)'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等 (2023a) Michael Xieyang Liu, Advait Sarkar, Carina Negreanu, Ben Zorn,
    Jack Williams, Neil Toronto, 和 Andy Gordon. 2023a. “它希望我说的内容”：弥合最终用户程序员与代码生成大型语言模型之间的抽象差距。收录于*ACM
    人机交互会议论文集 (CHI)*。ACM, 纽约, NY, 31 页. [https://doi.org/10.1145/3544548.3580817](https://doi.org/10.1145/3544548.3580817)
- en: 'Liu et al. (2024) Shusen Liu, Haichao Miao, Zhimin Li, Matthew Olson, Valerio
    Pascucci, and Peer-Timo Bremer. 2024. AVA: Towards autonomous visualization agents
    through visual perception-driven decision-making. *Comput. Graphics Forum* 43,
    3, Article e15093 (2024), 12 pages. [https://doi.org/10.1111/cgf.15093](https://doi.org/10.1111/cgf.15093)'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等 (2024) Shusen Liu, Haichao Miao, Zhimin Li, Matthew Olson, Valerio Pascucci,
    和 Peer-Timo Bremer. 2024. AVA：通过视觉感知驱动决策迈向自主可视化代理。*计算机图形学论坛* 43, 3, 文章 e15093
    (2024), 12 页. [https://doi.org/10.1111/cgf.15093](https://doi.org/10.1111/cgf.15093)
- en: 'Liu et al. (2023b) Shang-Ching Liu, ShengKun Wang, Tsungyao Chang, Wenqi Lin,
    Chung-Wei Hsiung, Yi-Chen Hsieh, Yu-Ping Cheng, Sian-Hong Luo, and Jianwei Zhang.
    2023b. JarviX: A LLM no code platform for tabular data analysis and optimization.
    In *Proceedings of the Conference on Empirical Methods in Natural Language Processing:
    Industry Track*. ACL, 622–630. [https://doi.org/10.18653/v1/2023.emnlp-industry.59](https://doi.org/10.18653/v1/2023.emnlp-industry.59)'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等 (2023b) Shang-Ching Liu, ShengKun Wang, Tsungyao Chang, Wenqi Lin, Chung-Wei
    Hsiung, Yi-Chen Hsieh, Yu-Ping Cheng, Sian-Hong Luo, 和 Jianwei Zhang. 2023b. JarviX：一个用于表格数据分析和优化的
    LLM 无代码平台。收录于*自然语言处理实证方法会议：行业跟踪*。ACL, 622–630. [https://doi.org/10.18653/v1/2023.emnlp-industry.59](https://doi.org/10.18653/v1/2023.emnlp-industry.59)
- en: 'Lucchesi et al. (2022) Lydia R Lucchesi, Petra M Kuhnert, Jenny L Davis, and
    Lexing Xie. 2022. Smallset Timelines: A visual representation of data preprocessing
    decisions. In *Proceedings of the ACM Conference on Fairness, Accountability,
    and Transparency (FAccT)*. ACM, New York, NY, 1136–1153. [https://doi.org/10.1145/3531146.3533175](https://doi.org/10.1145/3531146.3533175)'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lucchesi et al. (2022) Lydia R Lucchesi, Petra M Kuhnert, Jenny L Davis, 和 Lexing
    Xie. 2022. Smallset Timelines：数据预处理决策的可视化表示。在 *ACM 公平性、问责制和透明度会议 (FAccT) 论文集*
    中。ACM，纽约，第 1136–1153 页。 [https://doi.org/10.1145/3531146.3533175](https://doi.org/10.1145/3531146.3533175)
- en: 'Masson et al. (2024) Damien Masson, Sylvain Malacria, Géry Casiez, and Daniel
    Vogel. 2024. DirectGPT: A direct manipulation interface to interact with large
    language models. In *Proceedings of the ACM Conference on Human Factors in Computing
    Systems (CHI)*. ACM, New York, NY, Article 975, 16 pages. [https://doi.org/10.1145/3613904.3642462](https://doi.org/10.1145/3613904.3642462)'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Masson et al. (2024) Damien Masson, Sylvain Malacria, Géry Casiez, 和 Daniel
    Vogel. 2024. DirectGPT：与大型语言模型互动的直接操作界面。在 *ACM 人机因素计算系统会议 (CHI) 论文集* 中。ACM，纽约，第
    975 号文章，16 页。 [https://doi.org/10.1145/3613904.3642462](https://doi.org/10.1145/3613904.3642462)
- en: Mcnutt et al. (2023) Andrew M Mcnutt, Chenglong Wang, Robert A Deline, and Steven M.
    Drucker. 2023. On the design of AI-powered code assistants for notebooks. In *Proceedings
    of the ACM Conference on Human Factors in Computing Systems (CHI)*. ACM, New York,
    NY, Article 434, 16 pages. [https://doi.org/10.1145/3544548.3580940](https://doi.org/10.1145/3544548.3580940)
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mcnutt et al. (2023) Andrew M Mcnutt, Chenglong Wang, Robert A Deline, 和 Steven
    M. Drucker. 2023. AI 驱动的代码助手在笔记本中的设计。在 *ACM 人机因素计算系统会议 (CHI) 论文集* 中。ACM，纽约，第 434
    号文章，16 页。 [https://doi.org/10.1145/3544548.3580940](https://doi.org/10.1145/3544548.3580940)
- en: Mehrpour and Latoza (2023) Sahar Mehrpour and Thomas D. Latoza. 2023. A survey
    of tool support for working with design decisions in code. *Comput. Surveys* 56,
    2, Article 37 (2023), 37 pages. [https://doi.org/10.1145/3607868](https://doi.org/10.1145/3607868)
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mehrpour and Latoza (2023) Sahar Mehrpour 和 Thomas D. Latoza. 2023. 关于代码中设计决策的工具支持调查。*计算机调查*
    56, 2, 第 37 号文章 (2023), 37 页。 [https://doi.org/10.1145/3607868](https://doi.org/10.1145/3607868)
- en: Meta Open Source (2024) Meta Open Source. 2024. *React*. [https://react.dev/](https://react.dev/)
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Meta Open Source (2024) Meta Open Source. 2024. *React*。 [https://react.dev/](https://react.dev/)
- en: Microsoft (2024) Microsoft. 2024. *Monaco Editor*. [https://microsoft.github.io/monaco-editor/](https://microsoft.github.io/monaco-editor/)
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Microsoft (2024) Microsoft. 2024. *Monaco Editor*。 [https://microsoft.github.io/monaco-editor/](https://microsoft.github.io/monaco-editor/)
- en: Myers (1990) Brad A Myers. 1990. Taxonomies of visual programming and program
    visualization. *Journal of Visual Languages & Computing* 1, 1 (1990), 97–123.
    [https://doi.org/10.1016/S1045-926X(05)80036-9](https://doi.org/10.1016/S1045-926X(05)80036-9)
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Myers (1990) Brad A Myers. 1990. 视觉编程和程序可视化的分类法。*视觉语言与计算期刊* 1, 1 (1990), 97–123。
    [https://doi.org/10.1016/S1045-926X(05)80036-9](https://doi.org/10.1016/S1045-926X(05)80036-9)
- en: Nam et al. (2024) Daye Nam, Andrew Macvean, Vincent Hellendoorn, Bogdan Vasilescu,
    and Brad Myers. 2024. Using an LLM to help with code understanding. In *Proceedings
    of the ACM International Conference on Software Engineering (ICSE)*. IEEE, Article
    97, 13 pages. [https://doi.org/10.1145/3597503.3639187](https://doi.org/10.1145/3597503.3639187)
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nam et al. (2024) Daye Nam, Andrew Macvean, Vincent Hellendoorn, Bogdan Vasilescu,
    和 Brad Myers. 2024. 使用 LLM 帮助代码理解。在 *ACM 国际软件工程会议 (ICSE) 论文集* 中。IEEE，第 97 号文章，13
    页。 [https://doi.org/10.1145/3597503.3639187](https://doi.org/10.1145/3597503.3639187)
- en: 'Narechania et al. (2021) Arpit Narechania, Adam Fourney, Bongshin Lee, and
    Gonzalo Ramos. 2021. DIY: Assessing the correctness of natural language to SQL
    systems. In *Proceedings of the International Conference on Intelligent User Interfaces
    (IUI)*. ACM, New York, NY, 597–607. [https://doi.org/10.1145/3397481.3450667](https://doi.org/10.1145/3397481.3450667)'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Narechania et al. (2021) Arpit Narechania, Adam Fourney, Bongshin Lee, 和 Gonzalo
    Ramos. 2021. DIY：评估自然语言到 SQL 系统的正确性。在 *国际用户界面会议 (IUI) 论文集* 中。ACM，纽约，第 597–607
    页。 [https://doi.org/10.1145/3397481.3450667](https://doi.org/10.1145/3397481.3450667)
- en: 'Niederer et al. (2017) Christina Niederer, Holger Stitz, Reem Hourieh, Florian
    Grassinger, Wolfgang Aigner, and Marc Streit. 2017. TACO: Visualizing changes
    in tables over time. *IEEE Trans. Vis. Comput. Graph.* 24, 1 (2017), 677–686.
    [https://doi.org/10.1109/TVCG.2017.2745298](https://doi.org/10.1109/TVCG.2017.2745298)'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Niederer et al. (2017) Christina Niederer, Holger Stitz, Reem Hourieh, Florian
    Grassinger, Wolfgang Aigner, 和 Marc Streit. 2017. TACO：可视化表格随时间变化的情况。*IEEE 视觉计算图形学期刊*
    24, 1 (2017), 677–686。 [https://doi.org/10.1109/TVCG.2017.2745298](https://doi.org/10.1109/TVCG.2017.2745298)
- en: Olausson et al. (2024) Theo X Olausson, Jeevana Priya Inala, Chenglong Wang,
    Jianfeng Gao, and Armando Solar-Lezama. 2024. Is self-repair a silver bullet for
    code generation?. In *Proceedings of the International Conference on Learning
    Representations (ICLR)*. 49 pages. arXiv:2306.09896 Poster.
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Olausson 等 (2024) Theo X Olausson, Jeevana Priya Inala, Chenglong Wang, Jianfeng
    Gao, 和 Armando Solar-Lezama. 2024. 自我修复是否是代码生成的灵丹妙药？收录于 *国际学习表征会议 (ICLR) 论文集*。共
    49 页. arXiv:2306.09896 海报.
- en: OpenAI (2024) OpenAI. 2024. *Data analysis with ChatGPT*. OpenAI. Retrieved
    June 1, 2024 from [https://help.openai.com/en/articles/8437071-data-analysis-with-chatgpt](https://help.openai.com/en/articles/8437071-data-analysis-with-chatgpt)
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'OpenAI (2024) OpenAI. 2024. *使用 ChatGPT 进行数据分析*. OpenAI. 检索日期: 2024 年 6 月 1
    日, 来源 [https://help.openai.com/en/articles/8437071-data-analysis-with-chatgpt](https://help.openai.com/en/articles/8437071-data-analysis-with-chatgpt)'
- en: Pallets (2024) Pallets. 2024. *Flask*. [https://flask.palletsprojects.com/en/3.0.x/](https://flask.palletsprojects.com/en/3.0.x/)
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pallets (2024) Pallets. 2024. *Flask*. [https://flask.palletsprojects.com/en/3.0.x/](https://flask.palletsprojects.com/en/3.0.x/)
- en: Podo et al. (2024) Luca Podo, Muhammad Ishmal, and Marco Angelini. 2024. Toward
    a structured theoretical framework for the evaluation of generative AI-based visualizations.
    In *Proceedings of the EuroVis Workshop on Visual Analytics (EuroVA)*. The Eurographics
    Association, 6 pages. [https://doi.org/10.2312/eurova.20241118](https://doi.org/10.2312/eurova.20241118)
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Podo 等 (2024) Luca Podo, Muhammad Ishmal, 和 Marco Angelini. 2024. 迈向生成性人工智能可视化评估的结构化理论框架.
    收录于 *EuroVis 视觉分析研讨会 (EuroVA) 论文集*。Eurographics 协会, 共 6 页. [https://doi.org/10.2312/eurova.20241118](https://doi.org/10.2312/eurova.20241118)
- en: 'Pu et al. (2021) Xiaoying Pu, Sean Kross, Jake M. Hofman, and Daniel G. Goldstein.
    2021. Datamations: Animated explanations of data analysis pipelines. In *Proceedings
    of the ACM Conference on Human Factors in Computing Systems (CHI)*. ACM, New York,
    NY, Article 467, 14 pages. [https://doi.org/10.1145/3411764.3445063](https://doi.org/10.1145/3411764.3445063)'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Pu 等 (2021) Xiaoying Pu, Sean Kross, Jake M. Hofman, 和 Daniel G. Goldstein.
    2021. Datamations: 数据分析流程的动态解释. 收录于 *ACM 人机交互会议 (CHI) 论文集*。ACM, 纽约, NY, 第 467
    号文章, 共 14 页. [https://doi.org/10.1145/3411764.3445063](https://doi.org/10.1145/3411764.3445063)'
- en: 'Ramasamy et al. (2023) Dhivyabharathi Ramasamy, Cristina Sarasua, Alberto Bacchelli,
    and Abraham Bernstein. 2023. Visualising data science workflows to support third-party
    notebook comprehension: An empirical study. *Empirical Software Engineering* 28,
    3 (2023), 58. [https://doi.org/10.1007/s10664-023-10289-9](https://doi.org/10.1007/s10664-023-10289-9)'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ramasamy 等 (2023) Dhivyabharathi Ramasamy, Cristina Sarasua, Alberto Bacchelli,
    和 Abraham Bernstein. 2023. 可视化数据科学工作流以支持第三方笔记本的理解：一项实证研究. *实证软件工程* 28, 3 (2023),
    58. [https://doi.org/10.1007/s10664-023-10289-9](https://doi.org/10.1007/s10664-023-10289-9)
- en: 'Shen et al. (2024) Hua Shen, Tiffany Knearem, Reshmi Ghosh, Kenan Alkiek, Kundan
    Krishna, Yachuan Liu, Ziqiao Ma, Savvas Petridis, Yi-Hao Peng, Li Qiwei, et al.
    2024. Towards bidirectional human-AI alignment: A systematic review for clarifications,
    framework, and future directions. arXiv:2406.09264'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen 等 (2024) Hua Shen, Tiffany Knearem, Reshmi Ghosh, Kenan Alkiek, Kundan
    Krishna, Yachuan Liu, Ziqiao Ma, Savvas Petridis, Yi-Hao Peng, Li Qiwei, 等. 2024.
    迈向双向人类-人工智能对齐：关于澄清、框架和未来方向的系统评审. arXiv:2406.09264
- en: 'Shen et al. (2022) Leixian Shen, Enya Shen, Yuyu Luo, Xiaocong Yang, Xuming
    Hu, Xiongshuai Zhang, Zhiwei Tai, and Jianmin Wang. 2022. Towards natural language
    interfaces for data visualization: A survey. *IEEE Trans. Vis. Comput. Graph.*
    29, 6 (2022), 3121–3144. [https://doi.org/10.1109/TVCG.2022.3148007](https://doi.org/10.1109/TVCG.2022.3148007)'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen 等 (2022) Leixian Shen, Enya Shen, Yuyu Luo, Xiaocong Yang, Xuming Hu, Xiongshuai
    Zhang, Zhiwei Tai, 和 Jianmin Wang. 2022. 迈向自然语言接口的数据可视化：一项调查. *IEEE 视觉计算图形学期刊*
    29, 6 (2022), 3121–3144. [https://doi.org/10.1109/TVCG.2022.3148007](https://doi.org/10.1109/TVCG.2022.3148007)
- en: Showkat and Baumer (2021) Dilruba Showkat and Eric P. S. Baumer. 2021. Where
    do stories come from? Examining the exploration process in investigative data
    journalism. *Proc. ACM Hum.-Comput. Interact.* 5, CSCW2, Article 390 (2021), 31 pages.
    [https://doi.org/10.1145/3479534](https://doi.org/10.1145/3479534)
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Showkat 和 Baumer (2021) Dilruba Showkat 和 Eric P. S. Baumer. 2021. 故事的来源？调查数据新闻中的探索过程.
    *ACM 人机交互期刊* 5, CSCW2, 第 390 号文章 (2021), 共 31 页. [https://doi.org/10.1145/3479534](https://doi.org/10.1145/3479534)
- en: 'Shrestha et al. (2021) Nischal Shrestha, Titus Barik, and Chris Parnin. 2021.
    Unravel: A fluent code explorer for data wrangling. In *Proceedings of the Symposium
    on User Interface Software and Technology (UIST)*. ACM, New York, NY, 198–207.
    [https://doi.org/10.1145/3472749.3474744](https://doi.org/10.1145/3472749.3474744)'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shrestha 等人（2021）Nischal Shrestha、Titus Barik 和 Chris Parnin。2021。Unravel：一个流畅的数据清洗代码探索工具。载于
    *用户界面软件与技术研讨会论文集（UIST）*。ACM，纽约，NY，198–207。 [https://doi.org/10.1145/3472749.3474744](https://doi.org/10.1145/3472749.3474744)
- en: 'Shrestha et al. (2023) Nischal Shrestha, Bhavya Chopra, Austin Z Henley, and
    Chris Parnin. 2023. Detangler: Helping data scientists explore, understand, and
    debug data wrangling pipelines. In *Proceedings of the IEEE Symposium on Visual
    Languages and Human-Centric Computing (VL/HCC)*. IEEE, Piscataway, NJ, 189–198.
    [https://doi.org/10.1109/VL-HCC57772.2023.00031](https://doi.org/10.1109/VL-HCC57772.2023.00031)'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shrestha 等人（2023）Nischal Shrestha、Bhavya Chopra、Austin Z Henley 和 Chris Parnin。2023。Detangler：帮助数据科学家探索、理解和调试数据清洗管道。载于
    *IEEE 视觉语言与人本计算研讨会论文集（VL/HCC）*。IEEE，Piscataway，NJ，189–198。 [https://doi.org/10.1109/VL-HCC57772.2023.00031](https://doi.org/10.1109/VL-HCC57772.2023.00031)
- en: 'Subramonyam et al. (2024) Hariharan Subramonyam, Roy Pea, Christopher Lawrence
    Pondoc, Maneesh Agrawala, and Colleen Seifert. 2024. Bridging the gulf of envisioning:
    Cognitive design challenges in LLM interfaces. In *Proceedings of the ACM Conference
    on Human Factors in Computing Systems (CHI)*. ACM, New York, NY, Article 1039,
    19 pages. [https://doi.org/10.1145/3613904.3642754](https://doi.org/10.1145/3613904.3642754)'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Subramonyam 等人（2024）Hariharan Subramonyam、Roy Pea、Christopher Lawrence Pondoc、Maneesh
    Agrawala 和 Colleen Seifert。2024。弥合设想鸿沟：LLM 界面的认知设计挑战。载于 *ACM 人机交互会议论文集（CHI）*。ACM，纽约，NY，文章
    1039，19 页。 [https://doi.org/10.1145/3613904.3642754](https://doi.org/10.1145/3613904.3642754)
- en: 'Suh et al. (2023) Sangho Suh, Bryan Min, Srishti Palani, and Haijun Xia. 2023.
    Sensecape: Enabling multilevel exploration and sensemaking with large language
    models. In *Proceedings of the Symposium on User Interface Software and Technology
    (UIST)*. ACM, New York, NY, Article 1, 18 pages. [https://doi.org/10.1145/3586183.3606756](https://doi.org/10.1145/3586183.3606756)'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Suh 等人（2023）Sangho Suh、Bryan Min、Srishti Palani 和 Haijun Xia。2023。Sensecape：利用大型语言模型实现多层次探索与理解。载于
    *用户界面软件与技术研讨会论文集（UIST）*。ACM，纽约，NY，文章 1，18 页。 [https://doi.org/10.1145/3586183.3606756](https://doi.org/10.1145/3586183.3606756)
- en: Tankelevitch et al. (2024) Lev Tankelevitch, Viktor Kewenig, Auste Simkute,
    Ava Elizabeth Scott, Advait Sarkar, Abigail Sellen, and Sean Rintel. 2024. The
    metacognitive demands and opportunities of generative AI. In *Proceedings of the
    ACM Conference on Human Factors in Computing Systems (CHI)*. ACM, New York, NY,
    Article 680, 24 pages. [https://doi.org/10.1145/3613904.3642902](https://doi.org/10.1145/3613904.3642902)
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tankelevitch 等人（2024）Lev Tankelevitch、Viktor Kewenig、Auste Simkute、Ava Elizabeth
    Scott、Advait Sarkar、Abigail Sellen 和 Sean Rintel。2024。生成性 AI 的元认知需求与机遇。载于 *ACM
    人机交互会议论文集（CHI）*。ACM，纽约，NY，文章 680，24 页。 [https://doi.org/10.1145/3613904.3642902](https://doi.org/10.1145/3613904.3642902)
- en: 'Tian et al. (2024) Yuan Tian, Weiwei Cui, Dazhen Deng, Xinjing Yi, Yurun Yang,
    Haidong Zhang, and Yingcai Wu. 2024. ChartGPT: Leveraging LLMs to generate charts
    from abstract natural language. *IEEE Trans. Vis. Comput. Graph.* (2024). [https://doi.org/10.1109/TVCG.2024.3368621](https://doi.org/10.1109/TVCG.2024.3368621)
    Early Access.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tian 等人（2024）Yuan Tian、Weiwei Cui、Dazhen Deng、Xinjing Yi、Yurun Yang、Haidong
    Zhang 和 Yingcai Wu。2024。ChartGPT：利用 LLM 从抽象自然语言生成图表。*IEEE 视觉与计算图形学期刊*（2024）。 [https://doi.org/10.1109/TVCG.2024.3368621](https://doi.org/10.1109/TVCG.2024.3368621)
    早期访问。
- en: 'Vaithilingam et al. (2024) Priyan Vaithilingam, Elena L. Glassman, Jeevana Priya
    Inala, and Chenglong Wang. 2024. DynaVis: Dynamically synthesized UI widgets for
    visualization editing. In *Proceedings of the ACM Conference on Human Factors
    in Computing Systems (CHI)*. ACM, New York, NY, Article 985, 17 pages. [https://doi.org/10.1145/3613904.3642639](https://doi.org/10.1145/3613904.3642639)'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vaithilingam 等人（2024）Priyan Vaithilingam、Elena L. Glassman、Jeevana Priya Inala
    和 Chenglong Wang。2024。DynaVis：动态合成的可视化编辑 UI 小部件。载于 *ACM 人机交互会议论文集（CHI）*。ACM，纽约，NY，文章
    985，17 页。 [https://doi.org/10.1145/3613904.3642639](https://doi.org/10.1145/3613904.3642639)
- en: 'Victor (2011) Bret Victor. 2011. *Up and down the ladder of abstraction: A
    systematic approach to interactive visualization*. Retrieved April 1, 2024 from
    [http://worrydream.com/LadderOfAbstraction/](http://worrydream.com/LadderOfAbstraction/)'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Victor（2011）Bret Victor。2011。*抽象阶梯的上与下：一种系统化的互动可视化方法*。检索于 2024 年 4 月 1 日，来自
    [http://worrydream.com/LadderOfAbstraction/](http://worrydream.com/LadderOfAbstraction/)
- en: 'Wang et al. (2022) April Yi Wang, Will Epperson, Robert A DeLine, and Steven M.
    Drucker. 2022. Diff in the loop: Supporting data comparison in exploratory data
    analysis. In *Proceedings of the ACM Conference on Human Factors in Computing
    Systems (CHI)*. ACM, New York, NY, Article 97, 10 pages. [https://doi.org/10.1145/3491102.3502123](https://doi.org/10.1145/3491102.3502123)'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 (2022) 艾普利·伊·王、威尔·埃普森、罗伯特·A·德莱恩和史蒂文·M·德鲁克。2022。Diff in the loop：在探索性数据分析中支持数据比较。在
    *Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI)*。ACM，纽约，NY，Article
    97，10 页。 [https://doi.org/10.1145/3491102.3502123](https://doi.org/10.1145/3491102.3502123)
- en: 'Wang et al. (2018) April Y Wang, Ryan Mitts, Philip J Guo, and Parmit K Chilana.
    2018. Mismatch of expectations: How modern learning resources fail conversational
    programmers. In *Proceedings of the ACM Conference on Human Factors in Computing
    Systems (CHI)*. ACM, New York, NY, Article 511, 13 pages. [https://doi.org/10.1145/3173574.3174085](https://doi.org/10.1145/3173574.3174085)'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 (2018) 艾普利·Y·王、瑞安·米茨、菲利普·J·郭和帕尔米特·K·奇拉纳。2018。期望不匹配：现代学习资源如何未能满足对话程序员的需求。在
    *Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI)*。ACM，纽约，NY，Article
    511，13 页。 [https://doi.org/10.1145/3173574.3174085](https://doi.org/10.1145/3173574.3174085)
- en: Wang et al. (2024a) Xingyao Wang, Yangyi Chen, Lifan Yuan, Yizhe Zhang, Yunzhu
    Li, Hao Peng, and Heng Ji. 2024a. Executable code actions elicit better LLM agents.
    In *Proceedings of the International Conference on Machine Learning (ICML)*. Article
    PMLR 235, 13 pages. arXiv:2402.01030
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 (2024a) 邢耀·王、杨毅·陈、丽凡·袁、怡哲·张、云竹·李、浩·彭和恒·吉。2024a。可执行代码动作引发更好的 LLM 代理。在
    *Proceedings of the International Conference on Machine Learning (ICML)*。Article
    PMLR 235，13 页。arXiv:2402.01030
- en: 'Wang et al. (2024b) Yun Wang, Leixian Shen, Zhengxin You, Xinhuan Shu, Bongshin
    Lee, John Thompson, Haidong Zhang, and Dongmei Zhang. 2024b. WonderFlow: Narration-centric
    design of animated data videos. *IEEE Trans. Vis. Comput. Graph.* (2024), 17 pages.
    [https://doi.org/10.1109/TVCG.2024.3411575](https://doi.org/10.1109/TVCG.2024.3411575)
    Early Access.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 (2024b) 云·王、雷贤·沈、郑欣·游、辛欢·舒、邦申·李、约翰·汤普森、海东·张和董梅·张。2024b。WonderFlow：以叙事为中心的动画数据视频设计。*IEEE
    Trans. Vis. Comput. Graph.* (2024)，17 页。 [https://doi.org/10.1109/TVCG.2024.3411575](https://doi.org/10.1109/TVCG.2024.3411575)
    早期访问。
- en: 'Weng et al. (2024) Luoxuan Weng, Xingbo Wang, Junyu Lu, Yingchaojie Feng, Yihan
    Liu, and Wei Chen. 2024. InsightLens: Discovering and exploring insights from
    conversational contexts in large-language-model-powered data analysis. arXiv:2404.01644'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Weng 等人 (2024) 洛轩·翁、邢博·王、俊宇·陆、英超杰·冯、义涵·刘和伟·陈。2024。InsightLens：在大语言模型驱动的数据分析中发现和探索对话上下文中的洞见。arXiv:2404.01644
- en: 'Wu et al. (2022) Tongshuang Wu, Michael Terry, and Carrie Jun Cai. 2022. AI
    Chains: Transparent and controllable human-AI interaction by chaining large language
    model prompts. In *Proceedings of the ACM Conference on Human Factors in Computing
    Systems (CHI)*. ACM, New York, NY, Article 385, 22 pages. [https://doi.org/10.1145/3491102.3517582](https://doi.org/10.1145/3491102.3517582)'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等人 (2022) 童双·吴、迈克尔·特里和凯瑞·俊·蔡。2022。AI Chains：通过链式大语言模型提示实现透明和可控的人机互动。在 *Proceedings
    of the ACM Conference on Human Factors in Computing Systems (CHI)*。ACM，纽约，NY，Article
    385，22 页。 [https://doi.org/10.1145/3491102.3517582](https://doi.org/10.1145/3491102.3517582)
- en: 'Wu et al. (2024) Yang Wu, Yao Wan, Hongyu Zhang, Yulei Sui, Wucai Wei, Wei
    Zhao, Guandong Xu, and Hai Jin. 2024. Automated data visualization from natural
    language via large language models: An exploratory study. *Proceedings of the
    ACM on Management of Data* 2, 3, Article 115 (2024), 28 pages. [https://doi.org/10.1145/3654992](https://doi.org/10.1145/3654992)'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等人 (2024) 杨·吴、姚·万、洪宇·张、余磊·隋、吴彩·魏、魏·赵、关东·徐和海·金。2024。通过大语言模型自动化自然语言的数据可视化：一项探索性研究。*Proceedings
    of the ACM on Management of Data* 2, 3, Article 115 (2024)，28 页。 [https://doi.org/10.1145/3654992](https://doi.org/10.1145/3654992)
- en: 'Xie et al. (2024) Liwenhan Xie, Xinhuan Shu, Jeon Cheol Su, Yun Wang, Siming
    Chen, and Huamin Qu. 2024. Creating emordle: Animating word cloud for emotion
    expression. *IEEE Trans. Vis. Comput. Graph.* 30, 8 (2024), 5198–5211. [https://doi.org/10.1109/TVCG.2023.3286392](https://doi.org/10.1109/TVCG.2023.3286392)'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie 等人 (2024) 李文汉·谢、辛欢·舒、全哲洙、云·王、司铭·陈和华敏·屈。2024。创建 emordle：用于情感表达的词云动画。*IEEE
    Trans. Vis. Comput. Graph.* 30, 8 (2024)，5198–5211。 [https://doi.org/10.1109/TVCG.2023.3286392](https://doi.org/10.1109/TVCG.2023.3286392)
- en: 'Xie et al. (2023) Liwenhan Xie, Zhaoyu Zhou, Kerun Yu, Yun Wang, Huamin Qu,
    and Siming Chen. 2023. Wakey-Wakey: Animate text by mimicking characters in a
    GIF. In *Proceedings of the Symposium on User Interface Software and Technology
    (UIST)*. ACM, New York, NY, Article 98, 14 pages. [https://doi.org/10.1145/3586183.3606813](https://doi.org/10.1145/3586183.3606813)'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Xie 等 (2023) Liwenhan Xie, Zhaoyu Zhou, Kerun Yu, Yun Wang, Huamin Qu, 和 Siming
    Chen. 2023. Wakey-Wakey: 通过模仿 GIF 中的字符来使文本生动。发表于*用户界面软件与技术研讨会论文集 (UIST)*。ACM,
    纽约, NY, 文章 98, 14 页。 [https://doi.org/10.1145/3586183.3606813](https://doi.org/10.1145/3586183.3606813)'
- en: Xiong et al. (2022) Kai Xiong, Siwei Fu, Guoming Ding, Zhongsu Luo, Rong Yu,
    Wei Chen, Hujun Bao, and Yingcai Wu. 2022. Visualizing the scripts of data wrangling
    with SOMNUS. *IEEE Trans. Vis. Comput. Graph.* 29, 6 (2022), 2950–2964. [https://doi.org/10.1109/TVCG.2022.3144975](https://doi.org/10.1109/TVCG.2022.3144975)
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xiong 等 (2022) Kai Xiong, Siwei Fu, Guoming Ding, Zhongsu Luo, Rong Yu, Wei
    Chen, Hujun Bao, 和 Yingcai Wu. 2022. 使用 SOMNUS 可视化数据处理脚本。*IEEE 计算机视觉与图形学汇刊* 29,
    6 (2022), 2950–2964。 [https://doi.org/10.1109/TVCG.2022.3144975](https://doi.org/10.1109/TVCG.2022.3144975)
- en: 'Yang et al. (2021) Chenyang Yang, Shurui Zhou, Jin LC Guo, and Christian Kästner.
    2021. Subtle bugs everywhere: Generating documentation for data wrangling code.
    In *Proceedings of the IEEE/ACM International Conference on Automated Software
    Engineering (ASE)*. IEEE, Piscataway, NJ, 304–316. [https://doi.org/10.1109/ASE51524.2021.9678520](https://doi.org/10.1109/ASE51524.2021.9678520)'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yang 等 (2021) Chenyang Yang, Shurui Zhou, Jin LC Guo, 和 Christian Kästner.
    2021. 隐蔽的错误无处不在: 为数据处理代码生成文档。发表于*IEEE/ACM 自动化软件工程国际会议论文集 (ASE)*。IEEE, Piscataway,
    NJ, 304–316。 [https://doi.org/10.1109/ASE51524.2021.9678520](https://doi.org/10.1109/ASE51524.2021.9678520)'
- en: 'Yin et al. (2023) Pengcheng Yin, Wen-Ding Li, Kefan Xiao, Abhishek Rao, Yeming
    Wen, Kensen Shi, Joshua Howland, Paige Bailey, Michele Catasta, Henryk Michalewski,
    Oleksandr Polozov, and Charles Sutton. 2023. Natural language to code generation
    in interactive data science notebooks. In *Proceedings of the Annual Meeting of
    the Association for Computational Linguistics (Volume 1: Long Papers)*. ACL, Toronto,
    Canada, 126–173. [https://doi.org/10.18653/v1/2023.acl-long.9](https://doi.org/10.18653/v1/2023.acl-long.9)'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yin 等 (2023) Pengcheng Yin, Wen-Ding Li, Kefan Xiao, Abhishek Rao, Yeming Wen,
    Kensen Shi, Joshua Howland, Paige Bailey, Michele Catasta, Henryk Michalewski,
    Oleksandr Polozov, 和 Charles Sutton. 2023. 交互式数据科学笔记本中的自然语言到代码生成。发表于*计算语言学协会年会
    (第1卷: 长论文)*。ACL, 多伦多, 加拿大, 126–173。 [https://doi.org/10.18653/v1/2023.acl-long.9](https://doi.org/10.18653/v1/2023.acl-long.9)'
- en: 'Zhu-Tian and Xia (2022) Chen Zhu-Tian and Haijun Xia. 2022. CrossData: Leveraging
    text-data connections for authoring data documents. In *Proceedings of the ACM
    Conference on Human Factors in Computing Systems (CHI)*. ACM, New York, NY, Article
    95, 15 pages. [https://doi.org/10.1145/3491102.3517485](https://doi.org/10.1145/3491102.3517485)'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhu-Tian 和 Xia (2022) 陈 Zhu-Tian 和 Haijun Xia. 2022. CrossData: 利用文本数据连接进行数据文档编写。发表于*ACM
    人机交互系统会议论文集 (CHI)*。ACM, 纽约, NY, 文章 95, 15 页。 [https://doi.org/10.1145/3491102.3517485](https://doi.org/10.1145/3491102.3517485)'
- en: 'Zhu-Tian et al. (2024a) Chen Zhu-Tian, Zeyu Xiong, Xiaoshuo Yao, and Elena
    Glassman. 2024a. Sketch then generate: Providing incremental user feedback and
    guiding LLM code generation through language-oriented code sketches. arXiv:2405.03998'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhu-Tian 等 (2024a) 陈 Zhu-Tian, Zeyu Xiong, Xiaoshuo Yao, 和 Elena Glassman.
    2024a. 先草图后生成: 提供增量用户反馈并通过面向语言的代码草图指导 LLM 代码生成。arXiv:2405.03998'
- en: 'Zhu-Tian et al. (2024b) Chen Zhu-Tian, Chenyang Zhang, Qianwen Wang, Jakob
    Troidl, Simon Warchol, Johanna Beyer, Nils Gehlenborg, and Hanspeter Pfister.
    2024b. Beyond generating code: Evaluating GPT on a data visualization course.
    arXiv:2306.02914'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhu-Tian 等 (2024b) 陈 Zhu-Tian, Chenyang Zhang, Qianwen Wang, Jakob Troidl,
    Simon Warchol, Johanna Beyer, Nils Gehlenborg, 和 Hanspeter Pfister. 2024b. 超越代码生成:
    评估 GPT 在数据可视化课程中的表现。arXiv:2306.02914'
